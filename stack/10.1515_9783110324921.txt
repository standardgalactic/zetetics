Ulrich Berger, Hannes Diener, Peter Schuster, Monika Seisenberger (Eds.) 
Logic, Construction, Computation 

ontos mathematical logic 
edited by Wolfram Pohlers, Thomas Scanlon, Ernest Schimmerling 
Ralf Schindler, Helmut Schwichtenberg
Volume 3 

Ulrich Berger, Hannes Diener,
Peter Schuster, Monika Seisenberger (Eds.) 
Logic, Construction, Computation 

Bibliographic information published by Die Deutsche Bibliothek 
Die Deutsche Bibliothek lists this publication in the Deutsche Nationalbibliographie; 
detailed bibliographic data is available in the Internet at http://dnb.ddb.de
North and South America by 
Transaction Books 
Rutgers University 
Piscataway, NJ 08854-8042 
trans@transactionpub.com 
United Kingdom, Ire Iceland, Turkey, Malta, Portugal by 
Gazelle Books Services Limited 
White Cross Mills 
Hightown
LANCASTER, LA1 4XS 
sales@gazellebooks.co.uk
Livraison pour la France et la Belgique: 
Librairie Philosophique J.Vrin 
6, place de la Sorbonne ; F-75005 PARIS 
Tel. +33 (0)1 43 54 03 47 ; Fax  +33 (0)1 43 54 48 18 
www.vrin.fr 
©2012 ontos verlag 
P.O. Box 15 41, D-63133 Heusenstamm 
www.ontosverlag.com
ISBN 978-3-86838-158-0 
2012
No part of this book may be reproduced, stored in retrieval systems or transmitted  
in any form or by any means, electronic, mechanical, photocopying, microfilming, recording or otherwise  
without written permission from the Publisher, with the exception of any material supplied specifically for the  
purpose of being entered and executed on a computer system, for exclusive use of the purchaser of the work 
Printed on acid-free paper  
ISO-Norm 970-6 
FSC-certified (Forest Stewardship Council) 
This hardcover binding meets the International Library standard 
Printed in Germany 
by CPI buch bücher.de

Helmut Schwichtenberg, April 2012

Preface
Over the last few decades the interest of logicians and mathematicians in construc-
tive and computational aspects of their subjects has been steadily growing. More-
over, researchers from disparate areas have started fruitful collaborations because
they realized that, despite being driven by diﬀerent motivations, they can beneﬁt
enormously from the mutual exchange of techniques concerned with constructivity
and computability. A key ﬁgure in this exciting development is the logician and
mathematician Helmut Schwichtenberg to whom this volume is dedicated. Helmut
Schwichtenberg has pioneered the interaction of logic, mathematics, and computer
science and has made crucial contributions to these disciplines, in particular to
proof theory, recursion theory, normalisation and term rewriting, computable anal-
ysis, constructive mathematics, program extraction, and interactive and automated
theorem proving. The volume is dedicated to him on the occasion of his retirement
and his 70th birthday.
Helmut Schwichtenberg was born on the 5th of April, 1942 in Sagan, Silesia.
From 1961 he studied Mathematics at the FU Berlin and from 1964 at M¨unster
University. He completed his PhD thesis (“Eine Klassiﬁkation der mehrfach rekur-
siven Funktionen”) in 1968 and his Habilitationsschrift (“Einige Anwendungen von
unendlichen Termen und Wertfunktionalen”) in 1973, both at M¨unster University
under the supervision of Dieter R¨odding. In 1974 he was appointed Professor at
the University of Heidelberg and in 1978 he became the successor of Kurt Sch¨utte
as Chair for Mathematical Logic at the Ludwig-Maximilians University in Munich.
He has been a member of the Bayerische Akademie der Wissenschaften since 1986.
Helmut Schwichtenberg has written two books, Basic Proof Theory (with Anne
Troelstra, 2000), and Proofs and Computations (with Stan Wainer, 2012), and co-
edited several volumes (amongst them six Summer School Marktoberdorf proceed-
ings). To date, he has written more than 80 publications. He has been co-editor
of the journals Archive for Mathematical Logic, and Annals of Pure and Applied
Logic, as well as of the series Mathematical Logic of the Ontos-Verlag, and Studies
in Proof Theory of Bibliopolis. He also serves on the advisory board of Higher-
Order and Symbolic Computation. Tirelessly, and very successfully, he has set up
research projects, networks, and cooperations with other universities and industry.
During a research visit at Carnegie Mellon University, Pittsburgh in 1987–88, he
started to develop Minlog, a well respected interactive proof assistant which, among

other things, is known for its strengths in normalization, constructive analysis, and
program extraction.
A primary concern of Helmut Schwichtenberg has always been the promo-
tion of young scientists. He taught at the Summer School Marktoberdorf for two
decades and (co-)directed its biennial logic-oriented ‘blue series’ from 1991 until
2007. He was a member of the Munich Graduiertenkolleg ‘Sprache, Information,
Logic’ and spokesman and co-founder of the Graduiertenkolleg ‘Logic in Com-
puter Science’. For many years he organized logic meetings at the ‘Mathematisches
Forschungsinstitut Oberwolfach’ and served on the Scientiﬁc Committee of the In-
stitute. Most recent is his involvement in the European Marie Curie PhD training
network in Mathematical Logic, MATHLOGAPS and MALOA. Helmut Schwicht-
enberg’s PhD students were: Karl-Adolf H¨owel, Peter P¨appinghaus, Ulf Schmerl,
Klaus Martin H¨ornig, Martin Ruckert, Lew Gordeev, P´all Egerz, Ulrich Berger,
Karl-Heinz Niggl, Ralph Matthes, Thomas Rudlof, Monika Maidl, Wolfgang Zu-
ber, Klaus Weich, Felix Joachimski, Matthias Eberl, Monika Seisenberger, Favio
Miranda Perea, Martin K¨ubler, Dan Hernest, Stefan Schimanski, Luca Chiarabini,
Diana Ratiu, Trifon Trifonov. He is still active as PhD supervisor.
The plan for this Festschrift was formed during the workshops Program Ex-
traction and Constructive Proofs (PECP) and Classical Logic and Computation
(CLAC) which were held in Brno, G¨odel’s birth place, on 21st–22nd August 2010
on the occasion of Helmut Schwichtenberg’s retirement. We asked collaborators
and friends of his to contribute to a book which should be presented to him in the
year of his 70th birthday. The result is a collection of 20 refereed articles writ-
ten by 30 authors which cover a good deal of current research on constructive and
computational aspects of logic, and reﬂect the breadth of Helmut Schwichtenberg’s
research and his scientiﬁc network.
We would like to thank the speakers and participants of PECP and CLAC who
made these workshops scientiﬁcally high proﬁle and memorable events. We are
also grateful to the Deutsche Vereinigung f¨ur Mathematische Logik und f¨ur Grund-
lagenforschung der Exakten Wissenschaften (DVMLG), the Kurt G¨odel Society
(KGS), and the organizers at the University of Brno for their support. We thank
Rafael H¨untelmann from the Ontos Verlag and Ralf Schindler for being very helpful
with publishing this volume, Reinhard Kahle and Stan Wainer for their respective
advice on editorial matters, and Ursula Schwichtenberg for answering questions on
the biographical data. Our special thanks go to the referees, who made a crucial
contribution to the high scientiﬁc standard of this volume.
The articles in this book can be grouped into eight themes: Constructive set the-
ory (Andrea Cantini and Laura Crosilla, Justus Diller, Solomon Feferman, Gerhard
J¨ager and Rico Zumbrunnen), Provably recursive functions (Wilfried Buchholz and
Andreas Weiermann, Wolfram Pohlers and Jan-Carl Stegert, Elliott Spoors and

Stan Wainer), Program extraction (Federico Aschieri and Stefano Berardi, Mark
Bickford and Robert Constable), Theories of truth (Sebastian Eberhard and Thomas
Strahm, Solomon Feferman), Constructive mathematics (Douglas Bridges, Joan
Moschovakis), Classical vs. intuitionistic logic (Gilda Ferreira and Paulo Oliva,
Hajime Ishihara), Inductive deﬁnitions (Grigori Mints, Anton Setzer and Fredrik
Nordvall Forsberg), Continuous functionals and domains (Dag Normann, Dieter
Spreen).
The authors and editors of this Festschrift, and those who responded to our
call but were unable to contribute within the restricted time frame, wish Helmut
Schwichtenberg all the best for his 70th birthday and hope that he will enjoy many
more years of fruitful research.
Leeds, Siegen, and Swansea
Spring 2012
Ulrich Berger
Hannes Diener
Peter Schuster
Monika Seisenberger

Contents
Preface
Contributors
7
A New Use of Friedman’s Translation: Interactive Realizability
Federico Aschieri and Stefano Berardi
11
Polymorphic Logic
Mark Bickford and Robert Constable
51
Constructive Solutions of Ordinary Differential Equations
Douglas S. Bridges
67
A Nonstandard Hierarchy Comparison Theorem
Wilfried Buchholz and Andreas Weiermann
79
Transitive Closure in Operational Set Theory
Andrea Cantini and Laura Crosilla
91
Baire Space in CZF
Giovanni Curi and Michael Rathjen
123
Functional Interpretations of Classical and Constructive Set Theory
Justus Diller
137
Weak Theories of Truth and Explicit Mathematics
Sebastian Eberhard and Thomas Strahm
157
Axiomatizing Truth: Why and How?
Solomon Feferman
185
On the Strength of some Semi-Constructive Theories
Solomon Feferman
201
On the Relation Between Various Negative Translations
Gilda Ferreira and Paulo Oliva
227

A Finite Axiomatisation of Inductive-Inductive Deﬁnitions
Fredrik Nordvall Forsberg and Anton Setzer
259
Some Conservative Extension Results
Hajime Ishihara
289
About the Strength of Operational Regularity
Gerhard J¨ager and Rico Zumbrunnen
305
Epsilon Substitution for ID1
Grigori Mints
325
Another Unique Weak K¨onig’s Lemma WKL!!
Joan Rand Moschovakis
343
The Continuous Functionals as Limit Spaces
Dag Normann
353
Provably Recursive Functions of Reﬂection
Wolfram Pohlers and Jan–Carl Stegert
381
A Hierarchy of Ramiﬁed Theories Below PRA
Elliott J. Spoors and Stanley S. Wainer
475
Representing L-Domains as Information Systems
Dieter Spreen
501

Contributors
Federico Aschieri
Dipartimento di Informatica
Universit`a degli Studi di Torino, Italy
Stefano Berardi
Dipartimento di Informatica
Universit`a degli Studi di Torino, Italy
Mark Bickford
Computer Science Department
Cornell University, Ithaca, NY, USA
Douglas S. Bridges
Department of Mathematics and Statistics
University of Canterbury, Christchurch, New Zealand
Wilfried Buchholz
Mathematisches Institut
Ludwig-Maximilians-Universit¨at M¨unchen, Germany
Andrea Cantini
Dipartimento di Filosoﬁa
Universit`a degli Studi di Firenze, Italy
Robert Constable
Computer Science Department
Cornell University, Ithaca, NY, USA
Laura Crosilla
Department of Philosophy
University of Leeds, UK
Giovanni Curi
Dipartimento di Matematica
Universit`a degli Studi di Padova, Italy
Justus Diller
Institut f¨ur math. Logik und Grundlagenforschung
Westf¨alische Wilhelms-Universit¨at, M¨unster, Germany

Sebastian Eberhard
Institut f¨ur Informatik und angewandte Mathematik
Universit¨at Bern, Switzerland
Solomon Feferman
Department of Mathematics
Stanford University, Stanford, USA
Gilda Ferreira
Departamento de Matematica
Faculdade de Ciencias da Universidade de Lisboa, Portugal
Fredrik Nordvall Forsberg
Department Computer Science
Swansea University, UK
Hajime Ishihara
School of Information Science
Japan Advanced Institute of Science and Technology, Japan
Gerhard J¨ager
Institut f¨ur Informatik und angewandte Mathematik
Universit¨at Bern, Switzerland
Grigori Mints
Department of Philosophy
Stanford University, Stanford, CA, USA
Joan Rand Moschovakis
Occidental College (Emerita)
Graduate Program in Logic and Algorithms, Athens, Greece
Dag Normann
Department of Mathematics
University of Oslo, Norway
Paulo Oliva
School of Electronic Engineering and Computer Science
Queen Mary University of London, UK
Wolfram Pohlers
Institut f¨ur math. Logik und Grundlagenforschung
Westf¨alische Wilhelms-Universit¨at, M¨unster, Germany

Michael Rathjen
Department of Pure Mathematics
University of Leeds, UK
Anton Setzer
Department Computer Science
Swansea University, UK
Elliott J. Spoors
Department of Pure Mathematics
University of Leeds, UK
Dieter Spreen
Department Mathematik
Universit¨at Siegen, Germany
Jan–Carl Stegert
Institut f¨ur math. Logik und Grundlagenforschung
Westf¨alische Wilhelms-Universit¨at, M¨unster, Germany
Thomas Strahm
Institut f¨ur Informatik und angewandte Mathematik
Universit¨at Bern, Switzerland.
Stanley S. Wainer
Department of Pure Mathematics
University of Leeds, UK
Andreas Weiermann
Vakgroep Wiskunde
Universiteit Ghent, Belgium
Rico Zumbrunnen
Institut f¨ur Informatik und angewandte Mathematik
Universit¨at Bern, Switzerland.


A New Use of Friedman’s Translation: Interac-
tive Realizability
Federico Aschieri and Stefano Berardi
Friedman’s translation is a well-known transformation of formulas. The Fried-
man translation has two properties: i) it validates intuitionistic theorems – if
a formula is intuitionistically provable, then so it is its Friedman translation;
ii) it is suitable for program extraction from classical proofs – the intuition-
istic provability of the Friedman translation of the negative translation of a
for-all-exist-formula implies the intuitionistic provability of the formula itself.
However, the Friedman translation does not validate classical principles, like
the Excluded Middle.
Here, we deﬁne a restricted Friedman translation which both validates the
Excluded Middle and Skolem axiom schemata restricted to Σ0
1-formulas and it
is also suitable for program extraction from classical proofs using such prin-
ciples: the intuitionistic provability of the restricted Friedman translation of a
for-all-exist-formula implies the intuitionistic provability of the formula itself.
Then we introduce a learning-based Realizability Semantics for Heyting Arith-
metic with all ﬁnite types, extended with the two previous axiom schemata.
We call this semantics “Interactive Realizability”, and we characterize it as
the composition of our restricted Friedman translation with Kreisel modiﬁed
realizability. As a corollary, we show that Interactive Realizability is, in a
sense, “axiom-driven”, while the other Realizability Semantics for Classical
Arithmetic, like the semantics of Krivine, are “goal-driven”.
1
Introduction
In the past years, many computational interpretations of Classical Arithmetic have
been put forward. Under a ﬁrst classiﬁcation, they fall into two large categories:
direct and indirect interpretations. Among the indirect interpretations one ﬁnds
the negative translations followed either by Dialectica interpretations [13], [30]
(see e.g. Kohlenbach [19]) or by intuitionistic realizability interpretations com-
bined with Friedman’s translation [13] (see e.g. Berger and Schwichtenberg [10]).
Among the direct interpretations, there are diﬀerent versions of Classical Realiz-
ability (Krivine’s [22] and Avigad’s [6]), there is Coquand game semantics [11],

12
Federico Aschieri and Stefano Berardi
cut-elimination and normalization of classical proofs [14] (under Curry-Howard
correspondence of not), and the epsilon substitution method [23] (the Kreisel no-
counterexample interpretation [20] is an easy corollary of the other ones). More
recently, another Classical Realizability interpretation for Heyting Arithmetic with
Excluded Middle and Skolem axioms over Σ0
1-formulas has been introduced by
Aschieri, Berardi and de’ Liguoro [8], [1], [9]: it is based on the notion of learn-
ing and it is called the “Interactive Realizability”. The goal of this paper is to
compare Interactive Realizability with the other notions of Classical Realizability,
using Friedman’s translation and Kreisel modiﬁed Realizability as tools.
On a ﬁrst sight, these computational interpretations of Classical Arithmetic may
appear completely diﬀerent. However, this is not the case and it is often possible
to ﬁnd unifying concepts. A common way of studying and relating the various
computational interpretations of Classical Arithmetic is, ﬁrst, to characterize them
in terms of translations of Classical into Intuitionistic Arithmetic and secondly, to
compare the resulting translations. In the case of Classical Realizability interpreta-
tions one usually has
Classical Realizability
=
Negative Translation + Friedman’s Translation + Modiﬁed Realizability
For example, Avigad [7] characterized its own Classical Realizability in terms
of a special negative translation followed by Friedman’s translation again followed
by Kreisel’s modiﬁed realizability [21]; similarly did Towsner [32]. Oliva and
Streicher [27] managed to do the same for Krivine’s classical realizability for Clas-
sical Analysis. Miquel [25] used their characterization to compare the algorithms
extracted from proofs of Σ0
1-formulas – either obtained by using Krivine’s realiz-
ability or Oliva and Streicher’s characterization – and to conclude they are basically
the same. All these results characterize classical realizability in the following way:
a classical realizer of a formula B is an intuitionistic realizer of some Friedman
translation of some negative translation of B.
In this paper we build over this research line and we investigate the relation-
ship between Interactive Realizability and Friedman’s translation. We shall prove
(from an idea of the ﬁrst author) that Interactive Realizability for Heyting Arith-
metic in all ﬁnite types HAω, with Excluded Middle EM1 and Skolem axioms SK1
over Σ0
1-formulas, can be understood as a new way of using Friedman’s translation,
a way that avoids the use of negative translations for program extraction purposes.
Interactive Realizability restricts the family of goal-formulas in Friedman’s trans-
lation, in order to interpret each instance of Excluded Middle used in the proof
by some constructive principle. While in the usual Friedman’s A-translation the

A New Use of Friedman’s Translation: Interactive Realizability
13
goal-formula A is some Σ0
1-property that one wants to prove (it is “goal-driven”), in
ours the goal is ﬁxed once and for all, does not depend on the particular proof one
is considering and consists in learning something about the Skolem functions in-
terpreting the Excluded Middle. More precisely, we will show that learning-based
realizability can be decomposed in a ﬁxed Friedman A -translation followed by
Kreisel’s modiﬁed realizability, as follows:
Interactive Realizability
=
Friedman’s A -Translation + Modiﬁed Realizability
The ﬁxed formula A has a free variable s : N2 →N and says: “there exists a
counterexample to the fact that s is a Skolem function solving the Halting prob-
lem”. More precisely, A asserts that s is not a Skolem function for the formula
∀xN ∀yN ∃zN T xyz, where T is Kleene’s predicate. In other words, A says that
the familiar full type structure built over natural numbers is not a Tarski model of
HAω + EM1 + SK1, whenever the function s is interpreted as a Skolem function
solving the Halting problem, and that there is a counterexample supporting this
assertion. We observe that a counterexample to the assertion that s is a Skolem
function solving the Halting problem is just a triple of numbers (n, m, l) such that
T nml = True and T nms(n, m) = False. This is true because if s is not such a
Skolem function, it makes false the Skolem axiom:
∀xN∀yN∀zN. T xyz →T xys(x, y)
We shall use this characterization to stress the similarities, but also the diﬀer-
ences, between Interactive Realizability and the other Classical Realizability se-
mantics proposed so far. Namely, all these Realizability semantics are related to
some Friedman’s translation, but in Interactive Realizability the negative translation
is eliminated, and the restricted Friedman translation implicit in Interactive Realiz-
ability validates the Excluded Middle and Skolem axioms (it is “axiom-driven”). In
particular, an interactive realizer of a formula B is characterized just as an intuition-
istic realizer of the Friedman A -translation of B. The result seems to accord with
the intuition that learning-based realizability describes “locally” the constructive
ideas hidden in classical proofs, thanks to the interpretation of classical principles
with Skolem functions and learning algorithms.
1.1
Plan of the Paper
In section §2 we prove that there exists a restricted Friedman’s translation validat-
ing Excluded Middle and Skolem axiom schemata (both restricted to Σ0
1-formulas),

14
Federico Aschieri and Stefano Berardi
which at the same time still allows program extraction from profs of Π0
2-formulas.
In the rest of the paper we deﬁne the Interactive Realizability Semantics, corre-
sponding to such restricted Friedman’s translation.
In section §3 we introduce a term calculus in which Interactive, learning-based
realizers are written, namely an extension of G¨odel’s system T plus a constant sym-
bol for a Skolem function Φ.
In section §4, we extend Interactive Realizability, as described in [1], to HAω +
EM1 + SK1, an arithmetical system with functional variables.
In section §5, we compare Interactive Realizability with Kreisel’s no-counter-
example interpretation and we give an example of interactive realizer.
In section §6 we conclude our characterization of Interactive Realizability in
terms of Kreisel’s modiﬁed Realizability + restricted Friedman’s translation.
2
A restricted version of Friedman’s Translation
In this section we ﬁrst remark how Friedman’s translation does not validate Ex-
cluded Middle for Σ0
1-formulas, and then how a restricted version of it does. In the
rest of the paper we deﬁne the Interactive Realizability Semantics, which may be
deﬁned as the composition of Kreisel’s modiﬁed Realizability with our restricted
Friedman’s translation.
2.1
The Friedman Translation
The Friedman translation is a strikingly simple device introduced by Friedman [13]
in order to prove closure of intuitionistic systems S under Markov’s rule:
S ⊢¬∀xN¬P(x) =⇒S ⊢∃xNP(x)
where P is any decidable quantiﬁer free formula, possibly with some other free
variables besides x.
The translation gives a reasonable semantics to formulas that are derived in
a possibly inconsistent universe, in which some arbitrary universal statement is
assumed to be true. In such a world, false statements can be proved by perfectly
valid arguments, since the assumption of the world may be false. For example, one
may prove
HA + ∀xN¬P(x) ⊢⊥
as lemma in a classical proof of ∃xNP(x). Tarskian semantics is therefore no longer
adequate. The idea of Friedman’s translation is to change the meaning of formulas
in such a way that even false formulas are interpreted by true ones, carrying inter-
esting constructive information. In a universe in which a false assumption is made,

A New Use of Friedman’s Translation: Interactive Realizability
15
the only way of recovering from the disaster of some derived false atomic formula
Q is pointing out the concrete false consequence of the false assumption that is to
blame for deriving Q. If the false assumption is ∀xN¬P(x), the new meaning of Q
is
Q ∨∃xNP(x)
In words, if Q is derived from the assumption ∀xN¬P(x), either Q is true, or Q is
false and thus some false consequence ¬P(n) of ∀xN¬P(x) must have been used in
the derivation of Q. Thus P(n) must be true and ∃xNP(x) must hold.
The following theorem, from [13], is well known and holds for many systems.
Here, we shall focus on the system HAω (see section §4.1 for details):
Theorem 1 (Friedman’s A-Translation). Given any formulas A, B, where A has not
free variables occurring bound in B, let us denote with BA the formula resulting
from B by replacing every atomic formula Q of B with Q ∨A. If Γ is a set of
formulas and
HAω + Γ ⊢B and HAω ⊢FA for every F ∈Γ
then
HAω ⊢BA
The theorem is proved by straightforward induction on proof length (see Fried-
man [13]), and crucially depends on the fact that the A-translation of every axiom
of HAω is provable in HAω.
Now suppose that
HAω ⊢¬∀xN¬Q(x)
where Q is any quantiﬁer-free formula. Then, by theorem 1
HAω ⊢(¬∀xN¬Q(x))∃xNQ(x)
But this latter formula implies ∃xNQ(x) in HA (see Friedman [13]) and thus
HAω ⊢∃xNQ(x)
Therefore HAω is closed under Markov’s rule.
This closure property of HAω is exploited for program extraction purposes, in
connection with G¨odel’s double negation translation (again, see [13]). In particular,
if PAω is the classical version of HAω, one can show that
PAω ⊢∀xN∃yNP(x, y) =⇒HAω ⊢∀xN¬∀yN¬P(x, y)
and thus by closure of HAω under Markov’s rule
PAω ⊢∀xN∃yNP(x, y) =⇒HAω ⊢∀xN∃yNP(x, y)

16
Federico Aschieri and Stefano Berardi
We notice that the preliminary use of the negative translation before Friedman’s
translation is necessary to obtain the above result, since the following generaliza-
tion of theorem 1 is false:
PAω ⊢B =⇒HAω ⊢BA
This is due to the fact that HAω does not prove the A-translation of the Excluded
Middle for every formula A, because if A is refutable then BA ⇔B. A-translation
proves only the A-translation of the double negation translation of Excluded Mid-
dle. Therefore, A-translation alone cannot eliminate classical reasoning. It is thus
intriguing to ask whether Friedman’s translation alone is enough for program ex-
traction from proofs of Π0
2-formulas in the system HAω + EM1 + SK1. More pre-
cisely: is there a formula A such that
HAω ⊢EMA
1
HAω ⊢SKA
1
and for all atomic formulas P(x, y) we have the following correctness property:
HAω ⊢(∀xN∃yNP(x, y))A =⇒HAω ⊢∀xN∃yNP(x, y) ?
If there is such a formula, then by theorem 1 one has:
HAω + EM1 + SK1 ⊢∀xN∃yNP(x, y) =⇒HAω ⊢∀xN∃yNP(x, y)
allowing program extraction from classical proofs in the system HAω + EM1 + SK1
just by using Kreisel’s modiﬁed realizability for HAω. The answer, as we shall see,
is positive: Interactive Realizability deﬁnes in a natural way a formula A with the
desired properties. We observe that this formula does not vary with the particular
Π0
2-formula one wants to prove, whereas in the standard use of Friedman’s trans-
lation the goal formula always does. For the sake of simplicity, in this section we
assume
EM1 := ∀xN∀yN. ∃zN T (x, y, z) ∨∀zN¬BoolT (x, y, z)
since all other instances of the Excluded Middle on Σ0
1-formulas can be derived
from the instance over Kleene’s predicate (see deﬁnition 8 of section §3 ). Simi-
larly, we also assume
SK1 := ∀xN∀yN∀zN. T xyz ⇒Bool T xyΦ(x, y)
2.2
A New Way of using Friedman’s Translation
To the same extent that Friedman’s translation deals with provability under possibly
false assumptions, Interactive, learning-based realizability (see section §4) deals

A New Use of Friedman’s Translation: Interactive Realizability
17
with computations under possibly false computational hypotheses. The ﬁrst repairs
false proved statements by pointing out the actual concrete assumption that causes
the inconsistency; the second repairs wrong computational results by spotting some
wrong value of the Skolem function that produced some mistake. In particular,
the very idea behind learning-based realizability is to make assumptions about the
values of the Skolem function Φ for the predicate T and, thanks to them, carry out
computations even in situations in which one cannot eﬀectively compute the right
values of Φ. By a continuity argument, given any approximation s : N2 →N of Φ,
one knows that if s satisfy the following axiom
SK1[s] = ∀xN∀yN∀zN. T xyz ⇒Bool T xys(x, y)
for a suﬃcient number of particular choices for x, y, z, then a realizer of a Σ0
1-
formula will be able to compute a right witness when using s in place of Φ. If,
instead, the witness computed is incorrect, then one knows that SK1[s] is false, and
the task of the realizer is to spot a wrong value of s and to correct it with a right
one. The realizer eﬀectively ﬁnds out numerals n, m, l such that
T nml ∧¬BoolT nms(n, m)
and thus recognizes that
A (s) := ∃xN∃yN∃zN. T xyz ∧¬BoolT xys(x, y)
holds, which is classically equivalent to the negation of SK1[s]. A (s) asserts that
there exists a counterexample to the fact that s is a Skolem function for T . In
general, the behavior of a learning-based realizer of an atomic formula Q, is to
realize, in Kreisel’s sense, the formula
Q ∨A (s)
(but possibly providing multiple witnesses of A (s)). We choose A (s) as the for-
mula of the Friedman translation we were seeking, where s is a free variable denot-
ing any map of type N2 →N.
We now prove that A (s) is exactly the formula for the Friedman translation we
asked for.
Theorem 2 (A New Use of Friedman’s Translation). Let s : N2 →N be a variable
and let
A (s) := ∃xN∃yN∃zN. T xyz ∧¬BoolT xys(x, y)
Then we have

18
Federico Aschieri and Stefano Berardi
1. HAω ⊢(SK1[s])A (s)
2. HAω ⊢(EM1)A (s)
Proof.
1. Since (SK1[s])A (s) is equal to
∀xN∀yN∀zN.

T xyz ⇒Bool T xys(x, y) ∨∃xN∃yN∃zN.T xyz ∧¬T xys(x, y)

it is immediate to show that
HAω ⊢(SK1[s])A (s)
2. By deﬁnition
EMA (s)
1
= ∀xN∀yN.

∃zN. T (x, y, z) ∨A (s)

∨∀zN.¬BoolT (x, y, z) ∨A (s)
We reason by cases according as to whether T xys(x, y) is true or not:
(a) T xys(x, y) is true. Then also ∃zN. T (x, y, z) is true and so EMA (s)
1
.
(b) T xys(x, y) is false. Then ¬BoolT xys(x, y) is true. Let us consider an
arbitrary z: we want to show that ¬BoolT (x, y, z)∨A (s) holds. If T xyz
holds, then A (s) is true and we have ﬁnished; if ¬BoolT (x, y, z) holds,
we are done again.
We have thus concluded that
HAω ⊢(EM1)A (s)
(1)
□
In the rest of the paper we will deﬁne Interactive Realizability, with hindsight
a semantics corresponding to the Friedman’s translation we just outlined. Using
Interactive Realizability, at the end of this paper we will prove that the restricted
Friedman’s translation of any Π0
2-formula is correct, that is, that for any atomic
formula P(x, y) we have:
Theorem 3 (Correctness of the Restricted Friedman Translation).
HAω ⊢(∀xN∃yNP(x, y))A (s) =⇒HAω ⊢∀xN∃yNP(x, y)

A New Use of Friedman’s Translation: Interactive Realizability
19
It is very easy to see that, classically, if the formula
(∀xN∃yNP(x, y))A (s)
is true for every s, then also the formula
∀xN∃yNP(x, y)
is true. Indeed, from the Axiom of Choice, one obtains the existence of a Skolem
function Φ solving the the Halting problem. Thus, A (Φ) must be false, since
by construction there cannot be any counterexample to the fact that Φ is a Skolem
function for the Halting problem (if we trust classical logic!). Thus P(x, y) is equiv-
alent to P(x, y) ∨A (Φ) and thus
(∀xN∃yNP(x, y))A (Φ) →∀xN∃yNP(x, y)
is true.
However, it requires more work to prove theorem 3. A synopsis of what one has
to show is the following. From a proof in HAω of the formula ∀xN∃yNP(x, y)A (s)
one can extract an interactive realizer t of the formula ∀xN∃yNP(x, y). If one ﬁxes
x = n, from that realizer t, one directly obtains an update procedure (in the language
of [3, 6]), which is a functional
U : (N2 →N) →(N3) ∪∅
that given any function s : N2 →N as argument, either returns the empty set or
a triple (i, j, l) consisting in a new correct value l of the aforementioned Skolem
function Φ on argument (i, j). The idea is that with an update procedure, one can
construct a good enough ﬁnite approximation of Φ, which turns out to be a function
f such that U(f) = ∅. But the existence of such a function f can be proven in HAω
for any update procedure representable in G¨odel’s system T. But then, using f, the
interactive realizer t can compute a witness for the formula ∃yNP(n, y).
The ﬁrst step of our program is to introduce a term calculus TClass in which the
realizers of Interactive Realizability live.
3
The Term Calculus TClass
The content of this section is based on Aschieri and Berardi [1], with a few simpli-
ﬁcations, namely in the notion of state. We shall review the typed lambda calculi
T and TClass in which learning-based realizers are written in [1]. T is a completely

20
Federico Aschieri and Stefano Berardi
standard extension of G¨odel’s system T (see Girard [16]) with some syntactic sugar.
The basic objects of T are numerals, booleans, and its basic computational con-
structs are primitive recursion at all types, if-then-else, pairs, as in G¨odel’s T. T
also includes as basic objects ﬁnite partial functions over N and simple primitive
recursive operations over them. TClass is obtained from T by adding on top of it a
Skolem function symbol Φ : N →N →N, denoting some map Turing-equivalent
to the oracle for the Halting problem. The symbol is totally inert from the com-
putational point of view and realizers are always computed with respect to some
approximation of the Skolem map represented by Φ.
3.1
Updates
In order to deﬁne T , we start by introducing the concept of “update”, which is
nothing but a ﬁnite partial function over N. Realizers of atomic formulas will return
these ﬁnite partial functions, or “updates”, representing new pieces of information
that they have learned about the Skolem function Φ. Skolem functions, in turn,
are used as “oracles” during computations in the system TClass. Updates are new
associations input-output that are intended to correct, and in this sense, to update,
wrong oracle values used in a computation.
Deﬁnition 4 (Updates and Consistent Union). We deﬁne:
1. A binary predicate of T is any closed term P : N2 →Bool of G¨odel’s T.
2. We assume P0, P1, P2, . . . is any suﬃciently expressive recursive enumera-
tion of binary predicates of T. That is, we assume that for each numeral n,
T n = Pm for some m.
3. An update set U, shortly an update, is a ﬁnite set of triples of natural numbers
representing a ﬁnite partial function from N2 to N. We say that U is sound if
for every (i, n, m) ∈U, we have Pinm = True.
4. Two triples (a, n, m) and (a′, n′, m′) of numbers are consistent if a = a′ and
n = n′ implies m = m′.
5. Two updates U1, U2 are consistent if U1 ∪U2 is an update.

A New Use of Friedman’s Translation: Interactive Realizability
21
6. U is the set of all updates.
7. The consistent union U1 U U2 of U1, U2 ∈U is U1 ∪U2 minus all triples of
U2 which are inconsistent with some triple of U1.
We think of a triple (a, n, m) belonging to a sound update as the code of a wit-
ness for ∃yN.Pa(n, y). The fact that every update is a partial function allows in each
update at most one witness for each formula ∃yN.Pa(n, y). We remark that the enu-
meration P0, P1, . . . can be arbitrary, as long as it is recursive, and will not play any
signiﬁcant role throughout the paper: it is just a simple way to give “names” to the
predicates of T and to store witnesses. Only in section 6, for simplicity reasons and
theoretical purposes, we shall assume a particular enumeration. For implementa-
tion purposes, we may assume the enumeration P0, P1, . . . , to be just a computable
list of every binary predicate of T. We also remark that we could have deﬁned an
update to be just a single triple of numbers: all the results of this paper would hold
in this case. However, it will be clear in the following that one obtains more ef-
ﬁcient programs with our deﬁnition of updates: realizers of Post rules will avoid
losing precious witnesses.
The consistent union U1 U U2 is an non-commutative operation: whenever a
triple of U1 and a triple of U2 are inconsistent, we arbitrarily keep the triple of
U1 and we reject the triple of U2, therefore for some U1, U2 we have U1 U U2 ,
U2 U U1. U is a “learning strategy”, a way of selecting a consistent subset of
U1 ∪U2, such that U1UU2 = ∅=⇒U1 = U2 = ∅. Any operator U selecting a
consistent subset of U1 ∪U2 and satisfying U1UU2 = ∅=⇒U1 = U2 = ∅would
produce an alternative Realizability Semantics.
3.2
The System T
T is formally described in ﬁgure 1. Terms of the form ifA t1 t2 t3 will be written
in the more legible form if t1 then t2 else t3. For every update U ∈U, we assume
having in T a constant U : U, where U is a new base type representing U. We write
∅for ∅. In T , there are four operations involving updates (see ﬁgure 1):
1. The ﬁrst operation is denoted by the constant is : U →N2 →Bool. is takes
as arguments an update constant U and two numerals a, n; it returns True if
(a, n, m) ∈U for some m ∈N (that is, if the pair (a, n) is in the domain of the
partial map U); it returns False otherwise.
2. The second operation is denoted by the constant get : U →N2 →N. get
takes as arguments an update constant U and two numerals a, n; it returns m

22
Federico Aschieri and Stefano Berardi
if (a, n, m) ∈U for some m ∈N (that is, if (a, n) belongs to the domain of the
partial function U); it returns 0 otherwise.
3. The third operation is denoted by the constant mkupd : N3 →U. mkupd
takes as arguments three numerals a, n, m and transforms them into (the con-
stant coding in T ) the update {(a, n, m)}.
4. The forth operation is denoted by the constant ⋓: U2 →U. ⋓takes as
arguments two update constants and returns the update constant denoting
their consistent union.
We observe that the constants is, get, mkupd are just syntactic sugar and may
be avoided by coding ﬁnite partial functions into natural numbers; their behaviour
even does not depend on the enumeration P0, P1, . . . of binary predicates, since the
updates in the language of T are not assumed to be sound. System T may thus be
coded in G¨odel’s T.
System T is obtained from system T adding a new atomic type and new opera-
tions on it. The following deﬁnition formalizes what has been done in extending T
to T , and it useful for deﬁning arbitrary extensions of T with arbitrary maps over
natural numbers. We shall need such extensions when we add the non-computable
map Φ to T .
Deﬁnition 5 (Functional set of rules). Let C be any set of constants, each one of
some type A1 →. . . →An →A, for some A1, . . . , An, A ∈{Bool, N, U}. We say
that R is a functional set of reduction rules for C if R consists, for all c ∈C and all
a1 : A1, . . . , an : An closed normal terms of T , of exactly one rule ca1 . . . an 7→a,
for some closed normal term a : A of T .
Any extension of T with constants and even non-computable functional sets of
rules, is strongly normalizing and has the uniqueness-of-normal-form property.
Theorem 6. Assume that R is a functional set of reduction rules for C (def. 5).
Then T +C +R enjoys strong normalization and weak-Church-Rosser (uniqueness
of normal forms) for all closed terms of atomic types.
Proof. As in [3]
□
The following normal form theorem also holds.
Lemma 7 (Normal Form Property for T + C + R). Assume that R is a functional
set of reduction rules for C. Assume A is either an atomic type or a product type.

A New Use of Friedman’s Translation: Interactive Realizability
23
Then any closed normal term t ∈T of type A is: a numeral n : N, or a boolean
True, False : Bool, or an update constant U : U, or a constant of type A, or a pair
⟨u, v⟩: B × C.
Proof. As in [3].
□
In section §2 we made use of the fact that every instance of EM1 (Excluded Mid-
dle over all Σ1
0-formulas) can be proved from the Excluded Middle over Kleene’s
predicate.
Deﬁnition 8 (Kleene’s Predicate T ). With T : N3 →N we denote a predicate of
G¨odel’s T representing Kleene’s predicate (see e.g., Odifreddi [26]). That is, for
any numerals n, m, l, T nml = True if and only if the n-th partial recursive function
is deﬁned on argument m and l codes a computation proving it.
3.3
The System TClass
We now deﬁne a classical extension of T , that we call TClass, with a constant symbol
Φ : N2 →N denoting a non-computable map of the same Turing degree of an
oracle for the Halting problem. We shall use the elements of TClass to represent
non-computable realizers.
Deﬁnition 9 (The System TClass). Deﬁne TClass = T + Φ, where Φ : N2 →N is a new
constant symbol.
For every numeral a, Φa – which we shall denote with Φa – represents a Skolem
function for the formula ∃yN Paxy, taking as argument a number x and returning
some y such that Paxy if any exists, and an arbitrary value otherwise. There is
no set of computable reduction rules for the constant Φ, and therefore no set of
computable reduction rules for TClass.
Each (in general, non-computable) term t ∈TClass is associated to a set {t[s] |s ∈
T , s : N2 →N} ⊆T of computable terms we call its “approximations”, one for
each term s : N2 →N of T , which is thought as a computable approximation of the
oracle Φ.
Deﬁnition 10 (Approximation at state s). We deﬁne:
1. A state is a closed term of type N2 →N of T .
2. Assume t ∈TClass and s is a state. The “approximation of t at state s” is the
term t[s] of T obtained from t by replacing each constant Φ with s.

24
Federico Aschieri and Stefano Berardi
We interpret any t[s] ∈T as a learning process evaluated with respect to the in-
formation taken from an approximation s of Φ. Here we consider an approximation
of Φ to be an arbitrary term s : N2 →N; s may be correctly in agreement with Φ on
some arguments, but wrong on other ones. Consequently, we are going to consider
the set of (a, n) such that Pansa(n) = True as the real “domain” of s (where sa(n)
denotes san). We are also going to deﬁne a term ⊕, which takes as argument a term
f : N2 →N and an update U, and changes the values of f according to U. This
is the fundamental operation of our computational model: realizers correct wrong
oracle approximations with new correct values that they have previously learned
and stored in the updates. Last, using Φ, we are going to deﬁne for every numeral
a the oracle Xa, which takes as argument a numeral n and returns a guess for the
truth value of ∃yN Pany.
Deﬁnition 11 (Domain, Updates of Functions, Oracle Xa). We deﬁne:
1. If s is a state, we denote with dom(s) the set of pairs of numerals (a, n) such
that Pansa(n) = True.
2. We deﬁne a term ⊕: (N2 →N) →U →(N2 →N) as follows:
⊕:= λ f N2→NλuUλxNλyN if (is u x y) then (get u x y) else f xy
We will write t1 ⊕t2 in place of ⊕t1t2.
3. For every numeral a, we deﬁne a term Xa : N →Bool as follows:
Xa := λxN Pax(Φax)
We introduce now a notion of convergence for families of terms {t[si]}i∈N ⊆T ,
deﬁned by some t ∈TClass and indexed over a set {si}i∈N of states. Informally, “t
convergent” means that the normal form of t[s] eventually stops changing when the
approximation si of Φ gets better and better. If s and r are states, we formalize
what it means that r is at least as good an approximation as s by deﬁning:
s ≤r ⇐⇒∀a, n. sa(n) , ra(n) =⇒(a, n) < dom(s) ∧(a, n) ∈dom(r)
Intuitively, if s ≤r, then r can be obtained by changing some of the values of s that
make s a wrong approximation of Φ. We say that a sequence {si}i∈N of states is a
weakly increasing chain of states (is w.i. for short), if si ≤si+1 for all i ∈N.

A New Use of Friedman’s Translation: Interactive Realizability
25
Deﬁnition 12 (Convergence). Assume that {si}i∈N is a w.i. sequence of states, and
u ∈TClass.
1. u converges in {si}i∈N if ∃i ∈N.∀j ≥i. u[sj] = u[si] in T .
2. u converges if u converges in every w.i. sequence of states.
We remark that if u is convergent, we do not ask that u is convergent to the
same value on all w.i. chain of oracle approximations. The limit value of u may
depend on the information contained in the particular chain from which u gets the
knowledge. The chain of approximations, in turn, is selected by the particular
deﬁnition we use for the “learning strategy” U. Diﬀerent “learning strategies” may
produce diﬀerent limit values.
Theorem 13 (Convergence Theorem). Assume t ∈TClass is a closed term of atomic
type A (A ∈{Bool, N, U}). Then t is convergent.
Proof. As in [3].
□
Remark. The idea of the proof of theorem 13 corresponds exactly to the intuition
that during any computation, the oracle Φ is consulted a ﬁnite number of times
and hence asked for a ﬁnite number of values. When the approximation sn of Φ
is great enough, we can substitute Φ with sn and we obtain the same oracle values
and hence the same results.
4
An Interactive Learning-Based Notion of Realizabil-
ity for HAω + EM1 + SK1
In this section we introduce a learning-based notion of realizability for HAω+EM1+
SK1, Heyting Arithmetic in all ﬁnite types (see e.g. Troelstra [31]) plus Excluded
Middle scheme for all Σ0
1-formulas:
EM1 := ∀xN. ∃yNPaxy ∨∀yN¬Paxy
and Skolem axioms for all Σ0
1-formulas:
SK1 := ∀xN∀yN. Paxy →PaxΦa(x)
then we prove our main Theorem, the Adequacy Theorem: “if a closed arithmetical
formula is provable in HAω + EM1 + SK1, then it is realizable”.

26
Federico Aschieri and Stefano Berardi
We ﬁrst deﬁne the formal system HAω + EM1 + SK1. We represent atomic
predicates of HAω + EM1 + SK1 with (in general, non-computable) closed terms of
TClass of type Bool. Terms of HAω +EM1 +SK1 may include the function symbol Φ,
with Φa denoting the Skolem function for ∃yNPaxy. We assume having in G¨odel’s T
some terms ⇒Bool: Bool →Bool →Bool, ¬Bool : Bool →Bool, ∨Bool : Bool →
Bool →Bool . . ., implementing boolean connectives. If t1, . . . , tn, t ∈T have type
Bool and are made from free variables all of type Bool, using boolean connectives,
we say that t is a tautological consequence of t1, . . . , tn in T (a tautology if n = 0) if
all boolean assignments making t1, . . . , tn equal to True in T also make t equal to
True in T.
4.1
Language of HAω + EM1 + SK1
We now deﬁne the language of the arithmetical theory HAω + EM1 + SK1.
Deﬁnition 14 (Language of HAω+EM1+SK1). The language LClass of HAω+EM1+
SK1 is deﬁned as follows.
1. The terms of LClass are all t ∈TClass.
2. The atomic formulas of LClass are all Q ∈TClass such that Q : Bool.
3. The formulas of LClass are built from atomic formulas of LClass by the connec-
tives ∨, ∧, →∀, ∃as usual, with quantiﬁers possibly ranging over variables
xτ, yτ, zτ of arbitrary ﬁnite type τ of T .
We denote with ⊥the atomic formula False. If P is an atomic formula of
LClass in the free variables xτ1
1 , . . . , xτn
n and t1 : τ1, . . . , tn : τn are terms of LClass, with
P(t1, . . . , tn) we shall denote the atomic formula P[t1/x1, . . . , tn/xn].
We deﬁned ⇒Bool: Bool, Bool →Bool as a term implementing implication,
therefore, to be accurate, formulas of the form Pa(t, u) ⇒Bool Pa(t, Φat) are not an
implication between two atomic formulas, but they are equal to the single atomic
formula Q, where
Q := ⇒Bool (Patu)(Pat(Φat))
Any atomic formula A of LClass is a boolean term of TClass, therefore for any
s : N2 →N of T we may form the “approximation” A[s] : Bool, A[s] ∈T of A. In
A[s] we replace the Skolem function Φ we have in A by its approximation s.
From now onwards, for every pair of terms t1, t2 of system T , we shall write
t1 = t2 if they are the same term modulo the equality rules corresponding to the
reduction rules of system T (equivalently, if they have the same normal form).

A New Use of Friedman’s Translation: Interactive Realizability
27
4.2
Interactive (or Learning-Based) Realizability
For every formula A of LClass, we are now going to deﬁne what type |A| a realizer of
A must have.
Deﬁnition 15 (Types for realizers). For each formula A of LClass we deﬁne a type
|A| of TClass by induction on A:
1. |P| = U, if P is atomic,
2. |A ∧B| = |A| × |B|,
3. |A ∨B| = Bool × (|A| × |B|),
4. |A →B| = |A| →|B|,
5. |∀xτA| = τ →|A|,
6. |∃xτA| = τ × |A|.
Let now p0 := π0 : σ0 × (σ1 × σ2) →σ0, p1 := π0π1 : σ0 × (σ1 × σ2) →σ1
and p2 := π1π1 : σ0 × (σ1 × σ2) →σ2 be the three canonical projections from
σ0 × (σ1 × σ2). We deﬁne the realizability relation t ⊪A, where t ∈TClass, A ∈LClass
and t : |A|.
Deﬁnition 16 (Interactive Realizability). Assume s is a state, t is a closed term of
TClass, C ∈LClass is a closed formula, and t : |C|. We deﬁne ﬁrst the relation t ⊪s C
by induction and by cases according to the form of C:
1. t ⊪s Q for some atomic Q if and only if t[s] = U implies:
• U is sound and dom(U) ∩dom(s) = ∅
• U = ∅implies Q[s] = True
2. t ⊪s A ∧B if and only if π0t ⊪s A and π1t ⊪s B
3. t ⊪s A ∨B if and only if either p0t[s] = True and p1t ⊪s A, or p0t[s] =
False and p2t ⊪s B

28
Federico Aschieri and Stefano Berardi
4. t ⊪s A →B if and only if for all u, if u ⊪s A, then tu ⊪s B
5. t ⊪s ∀xτA if and only if for all closed terms u : τ of T , tu ⊪s A[u/x]
6. t ⊪s ∃xτA if and only for some closed term u : τ of T , π0t[s] = u and
π1t ⊪s A[u/x]
We deﬁne t ⊪A if and only if for all closed s : N →N of T , t ⊪s A.
Remark. The ideas behind the deﬁnition of ⊪s in the case of HA + EM1 + SK1
are those we already explained in [3], [1]. The system HAω + EM1 + SK1 has,
w.r.t. the system HA+EM1 +SK1 considered in our previous papers, a new feature:
its quantiﬁers range over terms of arbitrary ﬁnite type, i.e. over the functionals
deﬁnable in LClass. These functionals, in general, are not recursive. However, in
each particular world/state s what is in general uncomputable becomes computable,
since the Skolem function Φ is interpreted by a computable approximation s. Thus,
in the state s every term of LClass becomes recursive and, in fact, a term of G¨odel’s
system T. This is the reason why in the deﬁnition of the realizability relation ⊪s all
quantiﬁers range over terms of system T .
The next proposition tells that realizability at state s respects the notion of
equality of TClass terms, when the latter is relativized to state s. That is, if two
terms are equal at the state s, then they realize the same formulas at the state s.
Proposition 17 (Saturation). If t1[s] = t2[s] and u1[s] = u2[s], then t1 ⊪s B[u1/x]
if and only if t2 ⊪s B[u2/x].
Proof. By straightforward induction on A.
□
Example. The most remarkable feature of our Realizability Semantics is the exis-
tence of a realizer for EM1. Assume that Pa is a predicate of T and deﬁne
Ea := λαN⟨Xaα, ⟨Φaα, ∅⟩, λnN if Paαn then mkupd a α n else ∅⟩
Indeed Ea realizes its associated instance of EM1.
Proposition 18 (Realizer Ea of EM1).
Ea ⊪∀xN. ∃yN Pa(x, y) ∨∀yN¬BoolPa(x, y)
Proof. Let m be any numeral. We have
Eam = ⟨Xam, ⟨Φam, ∅⟩, λnN if Pamn then mkupd a m n else ∅⟩

A New Use of Friedman’s Translation: Interactive Realizability
29
and we want to prove that
Eam ⊪s ∃yN Pa(m, y) ∨∀yN¬BoolPa(m, y)
We have p0Eam = Xam = Pa(m, Φa(m)). There are two cases.
1. Xam[s] = True. Let n = sa(m). Then Pa(m, n) = True and we have to prove
p1Eam ⊪s ∃yN Pa(m, y)
By deﬁnition
p1Eam = ⟨Φam, ∅⟩
Thus
π0(p1EPm)[s] = π0⟨sa(m), ∅⟩= n
and
π1(p1Eam) ⊪s Pa(m, n)
because Pa(m, n) = True. We conclude
p1Eam ⊪s ∃yN P(m, y)
2. Xam[s] = False. We have to prove
p2Eam = λnN if Pamn then mkupd a m n else ∅⊪s ∀yN¬BoolPa(m, y)
i.e. that given any numeral n
if Pamn then mkupd a m n else ∅⊪s ¬BoolPa(m, n)
If Pa(m, n) = False, the thesis follows since ¬BoolPa(m, n) = True. If
Pa(m, n) = True, then
if Pamn then mkupd a m n else ∅= {(a, m, n)} ⊪s ¬BoolPa(m, n)
since Pa(m, sa(m)) = False and thus dom({(a, m, n)}) = {(a, m)} and (a, m) <
dom(s).
□
We now prove that if we start from any term s0 : N2 →N of T and we repeatedly
apply any atomic realizer t : U of TClass, we obtain a “zero” of t, that is a term
sn : N2 →N of T such that t[sn] = ∅. We interpret this by saying that any atomic
realizer t represents a terminating learning process.

30
Federico Aschieri and Stefano Berardi
Theorem 19 (Zero Theorem). Let Q be an atomic formula of LClass and suppose
t ⊪Q. Let s : N2 →N be a closed term of T . Deﬁne, by induction on n, a sequence
{sn}n∈N of terms such that:
s0 := s
sn+1 := sn ⊕t[sn]
def 11
=
λxNλyN if (is t[sn] x y) then (get t[sn] x y) else sn(x, y)
Then, there exists a n such that t[sn] = ∅.
Proof. We ﬁrst prove that s0, s1, s2, . . . is a weakly increasing chain.
Suppose
si(a, n) , si+i(a, n): we have to prove that (a, n) ∈dom(si+1) and (a, n) < dom(si).
By deﬁnition of si+1, if it were is t[si] a n = False, then we would have si(a, n) =
si+i(a, n), contradiction. Thus, is t[si] a n = True, and if we choose an update U
such that U = t[si], we have:
is U a n = True
that is, (a, n) ∈dom(U), and for some m, (a, n, m) ∈U. By deﬁnition of t ⊪si Q we
deduce that U is sound and dom(si) ∩dom(U) = ∅. From dom(si) ∩dom(U) = ∅
and (a, n) ∈dom(U) we obtain (a, n) < dom(si). From U is sound and (a, n, m) ∈U
we obtain Panm = True. By deﬁnition,
si+1(a, n) = get t[si] a n = get U a n = m
Therefore, si+1(a, n) = m and by deﬁnition 11 of dom, we have that (a, n) ∈
dom(si+1). We conclude that s0, s1, s2, . . . is weakly increasing.
Now, by theorem 13, t converges over the chain {si}i∈N: there exists k ∈N such that
for every j ≥k, t[s j] = t[sk]. By choice of k
sk+1 ⊕t[sk+1] = (sk ⊕t[sk]) ⊕t[sk+1]
= (sk ⊕t[sk]) ⊕t[sk]
= sk ⊕t[sk]
= sk+1
and hence it must be that t[sk] = ∅, which is the thesis.
□
The Zero Theorem could be expressed, in an equivalent way, as a ﬁxed point
result, but we skip this reformulation for sake of brevity. As usual for a realizability
interpretation, we may extract from any realizer t ⊪∀xσ∃yτPxy, with P : σ →τ →
Bool closed term of system T , some recursive map f from the set of terms of type
σ to the set of terms of type τ, such that Puf(u) = True for all u : σ.

A New Use of Friedman’s Translation: Interactive Realizability
31
Theorem 20 (Program Extraction via Learning Based Realizability). Let t be a
term of TClass and suppose that t ⊪∀xσ∃yτPxy, with P : σ →τ →Bool closed
term of system T . Then:
1. From t one can eﬀectively deﬁne a recursive function f such that for every
closed term u : σ of system T, f(u) : τ is a term of system T such that
Pu(f(u)) = True.
2. If σ ∈{N, N →N}, then f can be represented in system T .
3. If σ < {N, N →N}, then f can be represented in system T plus Spector’s bar
recursion (see Spector [30]).
Proof.
1. Let
v := λmσ π1(tm)
v is of type σ →U. Since for every closed u : σ of T
vu ⊪Puπ0(tu)
by the zero theorem 19, there exists a recursive function zero from the set
of type-σ terms of system T to the set of type-N2 →N terms of T such that
vu[zero(u)] = ∅for every closed u : σ of T . Deﬁne the function
f := w 7→π0(tw)[zero(w)]
and ﬁx a closed term u : σ of T . By unfolding the deﬁnition of realizability
with respect to zero(u), we have that
tu ⊩zero(u) ∃yτPuy
and hence
π1(tu) ⊩zero(u) Pu(f(u))
that is to say
vu[zero(u)] = ∅=⇒Pu(f(u)) = True
and therefore
Pu(f(u)) = True
which is the thesis.

32
Federico Aschieri and Stefano Berardi
2. The fact that f can be represented in system T follows by the methods of
Aschieri [5]. In particular, by theorem 12 of [5], the function zero is repre-
sentable in system T when σ = N, because λmσλgN→Nvm[g] is a numerable
collection of update procedures (see Avigad [6], Aschieri [5]). A straightfor-
ward generalization of the aforementioned theorem 12 of [5] –taking care of
collection of update procedures indexed by terms of type N →N – extends
the result for σ = N →N.
3. See Aschieri [3], [4] for a proof that the function zero is representable in
system T plus bar recursion.
□
Remark. The function f described in theorem 20, point 1, reduces the problem of
ﬁnding a witness for the formula ∃xτPux to the problem of computing a zero of the
atomic realizer
vu := π1(tu)
This latter problem is solved by f by computing the sequence
s0 := s
sn+1 := sn ⊕vu[sn]
until a n is found such that vu[sn] = ∅. The translation of f in a term of system T ,
which exists by theorem 20, point 2, yields the very same algorithm. The crucial
fact is that the number n can be computed directly in system T and thus the iteration
that allows to compute sn can be expressed by the primitive recursor of T . For
details see [3, 5].
4.3
Curry-Howard Correspondence for HAω + EM1 + SK1
In ﬁgure 2, we deﬁne a standard natural deduction system for HAω+EM1+SK1 (see
[29], for example) together with a term assignment in the spirit of Curry-Howard
correspondence for classical logic.
We replace purely universal axioms (i.e., Π0
1-axioms) with Post rules, which are
inferences of the form
Γ ⊢A1 Γ ⊢A2 · · · Γ ⊢An
Γ ⊢A
where A1, . . . , An, A are atomic formulas of LClass such that for every substitution
σ = [t1/x1, . . . , tk/xk s/Φ] of closed terms t1, . . . , tk of T and closed s : N2 →N
of T , A1σ = . . . = Anσ = True implies Aσ = True. Let now eq : N2 →Bool a

A New Use of Friedman’s Translation: Interactive Realizability
33
term of G¨odel’s system T representing equality between natural numbers. Among
the Post rules, we have the Peano axioms
Γ ⊢eq S(x) S(y)
Γ ⊢eq x y
Γ ⊢eq 0 S(x)
Γ ⊢⊥
and axioms of equality
Γ ⊢eq x x
Γ ⊢eq x y Γ ⊢eq y z
Γ ⊢eq x z
Γ ⊢A(x) Γ ⊢eq x y
Γ ⊢A(y)
and for every A1, A2 such that A1 = A2 is an equation of G¨odel’s system T (equiva-
lently, A1, A2 have the same normal form in T), we have the rule
Γ ⊢A1
Γ ⊢A2
We add also have a Post rule
Γ ⊢A1 Γ ⊢A2 · · · Γ ⊢An
Γ ⊢A
for every classical propositional tautology A1 →. . . →An →A, where for
i = 1, . . . , n, Ai, A are atomic formulas obtained as combination of other atomic
formulas by the G¨odel’s system T boolean connectives. As title of example, we
have the rules
Γ ⊢⊥
Γ ⊢P
Γ ⊢B
Γ ⊢A ⇒Bool B
Γ ⊢A ∧Bool B
Γ ⊢A
Finally, we have a rule of case reasoning for booleans. For any atomic formula P
and any formula A[P] we have:
Γ ⊢A[True] Γ ⊢A[False]
Γ ⊢A[P]
The connectives ∨Bool and ∨have the same meaning but they are syntactically
diﬀerent: for every atomic formula P, we consider P∨Bool¬BoolP an atomic formula
and P ∨¬BoolP a compound formula. P ∨Bool ¬BoolP is an axiom, while we may
derive HAω ⊢P ∨¬BoolP by case reasoning.
Assume u1, . . . , un are realizers of the assumptions of a Post rule. Then a real-
izer of the conclusion of a Post rule is of the form u = u1 ⋓· · · ⋓un. In this case,
we have n diﬀerent realizers, whose learning capabilities are put together through

34
Federico Aschieri and Stefano Berardi
a sort of union. In order to prove that u realizes A, assume that u[s] = ∅, then
u1[s] = . . . = un[s] = ∅, i.e. all ui “have nothing to learn”. In that case, each ui
must guarantee Ai to be true, and therefore the conclusion of the Post rule is true,
because true premises A1, . . . , An spell a true conclusion A. Thus, u realizes A.
If T is any type of T , we denote with dT a dummy term of type T, deﬁned by
dN = 0, dBool = False, dU = ∅, dA→B = λzA.dB (with zA any variable of type A),
dA×B = ⟨dA, dB⟩.
We now prove our main theorem, that every theorem of HAω + EM1 + SK1
is realizable. As usual in adequacy proofs for realizability, we prove a stronger
version of the theorem, suitable to be proved by induction on proofs.
Theorem 21 (Adequacy Theorem). Suppose that Γ ⊢w : A in the system HAω +
EM1+SK1, with Γ = x1 : A1, . . . , xn : An, and that the free variables of the formulas
occurring in Γ and A are among α1 : τ1, . . . , αk : τk. For all states s and for all
closed terms r1 : τ1, . . . , rk : τk of system T , if there are terms t1, . . . , tn such that
for i = 1, . . . , n, ti ⊪s Ai[r1/α1 · · · rk/αk]
then
w[t1/x|A1|
1
· · · tn/x|An|
n
r1/α1 · · · rk/αk] ⊪s A[r1/α1 · · · rk/αk]
Proof. Notation: for any term v and formula B, we denote
v[t1/x|A1|
1
· · · tn/x|An|
n
r1/α1 · · · rk/αk]
with v and
B[r1/α1 · · · rk/αk]
with B. We have |B| = |B| for all formulas B. We denote with = the provable
equality in TClass. We proceed by induction on w. Consider the last rule in the
derivation of Γ ⊢w : A:
1. If it is the rule for variables, then for some i, w = x|Ai|
i
and A = Ai. So
w = ti ⊪s Ai = A.
2. If it is the ∧I rule, then w = ⟨u, t⟩, A = B ∧C, Γ ⊢u : B and Γ ⊢t : C. There-
fore, w = ⟨u, t⟩. By induction hypothesis, π0w = u ⊪s B and π1w = t ⊪s C;
so, by deﬁnition, w ⊪s B ∧C = A.
3. If it is a ∧E rule, say left, then w = π0u and Γ ⊢u : A ∧B. So w = π0u ⊪s A,
because u ⊪s A ∧B by induction hypothesis.

A New Use of Friedman’s Translation: Interactive Realizability
35
4. If it is the →E rule, then w = ut, Γ ⊢u : B →A and Γ ⊢t : B. So
w = ut ⊪s A, for u ⊪s B →A and t ⊪s B by induction hypothesis.
5. If it is the →I rule, then w = λx|B|u, A = B →C and Γ, x : B ⊢u : C.
Suppose now that t ⊪s B; we have to prove that wt ⊪s C. By induction
hypothesis on u, u ⊪s C. By trivial equalities
wt[s] = (λx|B|u)[t1/x|A1|
1
· · · tn/x|An|
n
r1/α1 · · · rk/αk]t[s]
= (λx|B|u)t[t1/x|A1|
1
· · · tn/x|An|
n
r1/α1 · · · rk/αk][s]
= u[t/x|B|][t1/x|A1|
1
· · · tn/x|An|
n
r1/α1 · · · rk/αk][s]
= u[s]
Then by u[s] = wt[s] and saturation (prop. 17), wt ⊪s C.
6. If it is a ∨I rule, say left (the other case is symmetric), then we have w =
⟨True, u, d|C|⟩, A = B ∨C and Γ ⊢u : B. So, w = ⟨True, u, d|C|⟩and hence
π0w[s] = True. We indeed verify that u ⊪s B with the help of induction
hypothesis.
7. If it is a ∨E rule, then
w = if p0u then (λx|B|w1)(p1u) else (λx|C|w2)(p2u)
and Γ ⊢u : B ∨C, Γ, x : B ⊢w1 : D, Γ, y : C ⊢w2 : D, A = D.
Assume p0u[s] = True. By inductive hypothesis u ⊪s B ∨C. Therefore,
p1u ⊪s B. Hence
w[s] = (λx|B|w1)p1u[t1/x|A1|
1
· · · tn/x|An|
n
r1/α1 · · · rk/αk][s]
= w1[p1u/x|B|][t1/x|A1|
1
· · · tn/x|An|
n
r1/α1 · · · rk/αk][s]
= w1[p1u/x|B| t1/x|A1|
1
· · · tn/x|An|
n
r1/α1 · · · rk/αk][s]
= w1[p1u/x|B|][s]
By induction hypothesis, w1[p1u/x|B|] ⊪s D. Thus, by w1[p1u/x|B|] = w[s]
and saturation (prop. 17), also w ⊪s D.
Symmetrically, if p0u[s] = False, we obtain again w ⊪s D.

36
Federico Aschieri and Stefano Berardi
8. If it is the ∀E rule, then w = ut, A = B[t/ατ] and Γ ⊢u : ∀ατB. So, w = ut.
Let v = t[s]. By inductive hypothesis u ⊪s ∀αB and so uv ⊪s B[v/ατ]. Since
ut[s] = uv[s], by saturation (prop. 17), we conclude that ut ⊪s B[t/ατ].
9. If it is the ∀I rule, then w = λατu, A = ∀ατB and Γ ⊢u : B (with ατ not
occurring free in the formulas of Γ). So, w = λατu, since α , α1, . . . , αk. Let
t : τ be a closed term of T ; by saturation (prop. 17), it is enough to prove
that wt = u[t/ατ] ⊪s B[t/ατ], which amounts to show that the induction
hypothesis can be applied to u. For this purpose, we observe that, since
α , α1, . . . , αk, for i = 1, . . . , n we have
ti ⊪s Ai = Ai[t/ατ]
10. If it is the ∃E rule, then
w = (λατλx|B|t)(π0u)(π1u)
Γ, x : B ⊢t : A and Γ ⊢u : ∃ατ.B. Assume v = π0u[s]. Then
t[v/ατ, π1u/x|B|] ⊪s A[v/ατ] = A
by inductive hypothesis, whose application being justiﬁed by the fact, also
by induction, that u ⊪s ∃αN.B and hence π1u ⊪s B[v/ατ]. We thus obtain by
w[s] = t[π0u/ατ π1u/x|B|][s] and saturation (prop. 17) that
w ⊪s A
11. If it is the ∃I rule, then w = ⟨t, u⟩, A = ∃ατB, Γ ⊢u : B[t/ατ]. So, w = ⟨t, u⟩;
and, indeed, π1w = u ⊪s B[π0w/ατ] = B[t/ατ] since by induction hypothesis
u ⊪s B[t/ατ]. By saturation we conclude the thesis.
12. If it is the induction rule, then w = λαNRuvα, A = ∀αNB, Γ ⊢u : B(0) and
Γ ⊢v : ∀αN.B(α) →B(S(α)). So, w = λαNRuvα. We have to prove that
wu ⊪s B[n/α] for all closed normal form of type N. Let n = u[s] be the
normal form of u[s]: then n is a numeral by the Lemma 7. A plain induction
on n shows that
wn = Ruvn ⊪s B[n/α]
for u ⊪s B(0) and vi ⊪s B(i) →B(S(i)) for all numerals i by induction hy-
pothesis. If we set i = n, the thesis follows by saturation and wu[s] = wn[s].

A New Use of Friedman’s Translation: Interactive Realizability
37
13. If it is a Post rule, then w = u1 ⋓u2 ⋓· · · ⋓un and Γ ⊢ui : Ai. So,
w = u1 ⋓u2 ⋓· · · ⋓un. First, suppose that, for i = 1, . . . , n, ui[s] = Ui
and w[s] = U. By induction hypothesis, dom(Ui) ∩dom(s) = ∅, and thus
also dom(U) ∩dom(s) = ∅. Suppose now that U = ∅; then we have to
prove that A[s] = True. It suﬃces to prove that A1[s] = A2[s] = · · · =
An[s] = True. We have U1 = · · · = Un = ∅and by induction hypothesis
A1[s] = · · · = An[s] = True, since ui ⊪s Ai, for i = 1, . . . , n.
14. If is the excluded middle axiom EM1, then w = Ea realizes EM1 by Prop. 18.
15. If it is a Φ-axiom rule, then
w = λxNλyNif (Paxy ⇒Bool Pax(Φax)) then ∅else (mkupd a x y)
and
A = ∀xN∀yN. Pa(x, y) ⇒Bool Pa(x, Φax)
Let n, m be two arbitrary numerals. We have to prove that
wnm ⊪s Pa(n, m) ⇒Bool Pa(n, Φan)
There are two cases:
(a) Pa(n, m) ⇒Bool Pa(n, san) = True. In this case, wnm[s] = ∅and we
have only to check that dom(s) ∩dom(∅) = ∅, which is trivial.
(b) Pa(n, m) ⇒Bool Pa(n, san) = False. Then, Panm = True and Pansa(n) =
False. Moreover
wnm[s] = mkupd a n m = U
with U = {(a, n, m)}. We have ﬁrst to check that U is sound (see deﬁ-
nition 4): this follows from Panm = True. Then we have to check that
dom(s) ∩dom(U) = ∅: indeed, dom(U) = {(a, n)}, and by deﬁnition
11, Pansa(n) = False implies (a, n) < dom(s). Last, we have to check
that U , ∅, which is immediate by U = {(a, n, m)}.
□
As corollary of the Adequacy theorem 21, we obtain the main theorem.
Theorem 22. If A is a closed formula such that HAω + EM1 + SK1 ⊢t : A, then
t ⊪A.

38
Federico Aschieri and Stefano Berardi
5
Interactive Realizability and Kreisel’s No Counterex-
ample Interpretation of Σ0
2-formulas: an example of
realizer
We now want to relate Interactive Realizability with Kreisel No-Counterexample
Interpretation. We construct some terms transforming any witness of Kreisel’s In-
terpretation [20] of any Σ0
2-formula in an interactive realizer of that formula – and
vice versa. Let us ﬁx a Σ0
2-formula, with P(x, y) predicate of G¨odel’s system T:
∃xN∀yNP(x, y)
(2)
We start from the no-counterexample interpretation.
5.1
From the No-Counterexample Interpretation to Interactive Re-
alizability
A witness of the no-counterexample interpretation of (2) is a realizer Ψ – in the
sense of Kreisel’s modiﬁed realizability – of the Herbrand normal form of (2):
∀f N→N∃xNP(x, f(x))
(3)
That is, Ψ : (N →N) →N is a term of T such that:
∀f N→NP(Ψf, f(Ψf))
(4)
As it is well known, one has
HAω + EM1 + SK1 ⊢∀f N→NP(Ψf, f(Ψf)) →∃xN∀yNP(x, y)
The proof is classical and goes as follows. Suppose (4) and assume without loss of
generality that
P0(x, y) ≡¬BoolP(x, y)
We recall that Φ0 is the Skolem map for ∃yN P0(x, y). Let x = ΨΦ0. Then, by (4)
with f = Φ0, we deduce P(ΨΦ0, Φ0(ΨΦ0)), that is
P(x, Φ0(x))
and equivalently
¬BoolP0(x, Φ0(x))

A New Use of Friedman’s Translation: Interactive Realizability
39
By SK1 we obtain the Skolem axiom for Φ, therefore from ¬BoolP0(x, Φ0(x)) we
get
∀yN¬P0(x, y)
which is equivalent to ∀yNP(x, y). Thus we conclude (2).
By the Adequacy theorem 21, we know that an interactive realizer Ωof
∀f N→N∃xNP(x, f(x)) →∃xN∀yNP(x, y)
indeed does exist. Since
λ f N→N⟨Ψf, ∅⟩) ⊪∀f N→N∃xNP(x, f(x))
we have that Ω(λf N→N⟨Ψf, ∅⟩) is a interactive realizer of (2).
It is instructive however to build directly Ω, as example, by using the aforemen-
tioned classical proof as a source of inspiration. The witness to (2) coming from
the proof is just Ψ(Φ0). This latter term is not computable, but we suppose to have
an approximation s : N2 →N of Φ. When we compute
Ψ(Φ0)[s] = Ψ(s0) = n
if we are lucky we obtain a numeral n which is a witness to (2). But in general this
is not the case, and we must be prepared to test the result of our computation and
to correct s if n is a wrong witness. Indeed, the term
λyN if Pny then ∅else mkupd 0 n y
does the job, as the next proposition says.
Proposition 23 (From the N.C.I. to Learning-Based Realizability). Suppose Ψ :
(N →N) →N is a term of T such that:
∀f N→NP(Ψf, f(Ψf))
Then
⟨Ψ(Φ0), λyN if PΨ(Φ0)y then ∅else mkupd 0 Ψ(Φ0) y⟩⊪∃xN∀yNP(x, y)
Proof. Let s : N2 →N be a closed term of T , s0 = Φ0[s] be the corresponding
approximation of the Skolem map Φ0 for ∃yNP0(x, y), and n be the normal form of
Ψ(s0). Then n is a numeral by Lemma 7. By deﬁnition of interactive realizability,
we have to show that, if we compute
Ψ(Φ0)[s] = Ψ(s0) = n

40
Federico Aschieri and Stefano Berardi
then we have
λyN if PΨ(Φ0)y then ∅else mkupd 0 Ψ(Φ0) y ⊪s ∀yNP(n, y)
Thus we must show that, ﬁxed any numeral m,
if PΨ(Φ0)m then ∅else mkupd 0 Ψ(Φ0) m⟩⊪s P(n, m)
Compute
if PΨ(Φ0)m then ∅else mkupd 0 Ψ(Φ0) m[s]
=if Pnm then ∅else mkupd 0 n m
=U
for some U ∈U. There are two cases for U:
1. U = ∅. Then Pnm = True and thus we obtain the thesis:
if PΨ(Φ0)m then ∅else mkupd 0 Ψ(Φ0) m ⊪s P(n, m)
by deﬁnition of realizability for atomic formulas.
2. U = {(0, n, m)}. Then Pnm = False, and hence P0nm = True by P0(x, y) ≡
¬BoolP(x, y). Since
∀f N→NP(Ψf, f(Ψf))
by letting f = s0 and substituting Ψs0 with n, we obtain Pns0(n) = True;
therefore P0nΦ0[s](n) = P0ns0(n) = False. Therefore U is sound and
dom(U) ∩dom(s) = ∅. That is, we have the thesis:
if PΨ(Φ0)m then ∅else mkupd 0 Ψ(Φ0) m ⊪s P(n, m)
□
5.2
From Interactive Realizability to the No-Counterexample In-
terpretation
It is trivial to show that
HAω + EM1 + SK1 ⊢∃xN∀yNP(x, y) →∀f N→N∃xNP(x, f(x))
since any x such that ∀yNP(x, y) is such that P(x, f(x)), whatever f is. Hence, given
any interactive learning-based realizer
t ⊪∃xN∀yNP(x, y)

A New Use of Friedman’s Translation: Interactive Realizability
41
and by following the idea of the trivial proof above, we obtain that
λf N→N⟨π0t, (π1t)f(π0t)⟩⊪∀f N→N∃xNP(x, f(x))
By theorem 20, we obtain a term with the properties of Ψ. According to the proof
of theorem 20, that term takes an f : N →N and computes the sequence
s0 := λxN 0
sn+1 := sn ⊕(π1t)f(π0t)[sn]
until an m such that (π1t)f(π0t)[sm] = ∅is found; then it returns π0t[sm]. It is more
eﬃcient, however, to start with
s0 := f
since by theorem 19 the produced sequence converges as well to a zero.
6
Interactive Realizability as Friedman’s Translation +
Kreisel’s Modiﬁed Realizability
In this subsection we show that the notion of Interactive Realizability for HAω +
EM1 + SK1 represents a new way of using Friedman’s translation. More precisely,
Interactive Realizability is exactly the same as the notion of Kreisel’s modiﬁed
realizability for HAω applied to our restricted Friedman translation of formulas.
More precisely, we claim that the notion t ⊪B is equivalent to the notion ∀sN→N ∈
T . t[s] mr B[s]A (s).
Before we begin our argument, we recall the deﬁnition of modiﬁed realizability
mr (Kreisel [20]). We denote with L the set of terms and formulas obtained from
the terms and formulas of LClass by replacing the constant Φ with some term s :
N2 →N of T .
Deﬁnition 24 (Modiﬁed Realizability). Assume s : N2 →N is a closed term of
T , t is a closed term of T , D ∈L is a closed formula, and t : |D|. We deﬁne by
induction on D the relation t mr D:
1. t mr Q if and only if Q = True
2. t mr A ∧B if and only if π0t mr A and π1t mr B
3. t mr A ∨B if and only if either p0t = True and p1t mr A, or π0t = False and
p1t mr B

42
Federico Aschieri and Stefano Berardi
4. t mr A →B if and only if for all u, if u mr A, then tu mr B
5. t mr ∀xτA if and only if for all closed terms u : τ of T , tu mr A[u/x]
6. t mr ∃xτA if and only for some closed term u : τ of T , π0t = u and
π1t mr A[u/x]
It is technically more convenient to deﬁne directly a realizability relation mrfs
such that t mrfs B[s] is equivalent (modulo some inessential adjustments in the
atomic case) to the relation t mr B[s]A (s). When Q is atomic, by deﬁnition the
relation t mr Q[s]A (s) is
t mr Q[s] ∨∃xN∃yN∃zN. T xyz ∧¬T xys(x, y)
So, either Q[s] = True or p2t contains a triple of numerals n, m, l such that T nml∧
¬T nms(n, m) is true. Thus it is better to deﬁne directly t as term of type U which
reduces to an update, non-empty and containing such numerals n, m, l whenever Q
is false.
Deﬁnition 25 (mr Combined with the A (s)-Translation). Assume s : N2 →N is
a closed term of T , t is a closed term of T , D ∈L is a closed formula of L, and
t : |D|. We deﬁne by induction on D the relation t mrfs D:
1. t mrfs Q if and only if
• t = U implies that for all (n, m, l) ∈U, T nml = True and
T nms(n, m) = False
• t = ∅implies Q = True
2. t mrfs A ∧B if and only if π0t mrfs A and π1t mrfs B
3. t mr A ∨B if and only if either p0t = True and p1t mr A, or π0t = False and
p1t mr B
4. t mrfs A →B if and only if for all u, if u mrfs A, then tu mrfs B
5. t mrf ∀xτA if and only if for all closed terms u : τ of T , tu mrf A[u/x]

A New Use of Friedman’s Translation: Interactive Realizability
43
6. t mrf ∃xτA if and only for some closed term u : τ of T , π0t = u and
π1t mrf A[u/x]
We are now able to characterize learning-based realizability ⊪as a Friedman
translation combined with Kreisel’s modiﬁed realizability.
Theorem 26 (Characterization of Interactive Realizability). Let t ∈TClass and s :
N2 →N ∈T . Then, for every B ∈LClass
t ⊪s B ⇐⇒t[s] mrfs B[s]
Proof. The thesis is proved by routine induction on B.
1. B = Q, with Q atomic. Then t[s] mrfs Q[s], by deﬁnition 25, holds if and
only if:
• t[s] = U implies that T nml = True and T nms(n, m) = False for all
(n, m, l) ∈U
• t[s] = ∅implies Q[s] = True
Indeed, this is exactly the deﬁnition 16 of t ⊪s Q, provided one makes some
additional hypothesis on the enumeration P0, P1, . . . of deﬁnition 4. For ex-
ample, it is enough to assume that for each numeral n, Pn = T n.
2. B = C ∧D. Then t ⊪s C ∧D if and only if π0t ⊪s C and π1t ⊪s D if and
only if (by induction hypothesis) π0t[s] mrfs C[s] and π1t[s] mrfs D[s] if and
only if t[s] mrfs(C ∧D)[s].
3. B = C ∨D. Assume p0t[s] = True (the case p0t[s] = False is symmetrical).
Then, t ⊪s C ∨D if and only if p1t ⊪s C if and only if (by induction hypoth-
esis) p1t[s] mrfs C[s] if and only if t[s] mrf (C ∨D)[s] by the very deﬁnition
25 of mrfs.
4. B = C →D. Assume t ⊪s C →D. We want to prove that t[s] ⊪s
(C →D)[s].
Thus, we have to suppose u mrfs C[s] and conclude that
t[s]u mrfs D[s]. Since u = u[s] (u is a closed term of T by deﬁnition 25),
by induction hypothesis we obtain that u mrfs C and hence that tu ⊪s D. By
induction hypothesis, t[s]u = tu[s] mrfs D[s], which is what we wanted to
show.

44
Federico Aschieri and Stefano Berardi
Conversely, assume t mrfs (C →D)[s]. We want to prove that t ⊪s C →D.
Thus, we have to suppose u mrfs C and conclude that tu mrfs D. By induction
hypothesis, we obtain that u[s] mrfs C[s] and hence that tu[s] ⊪s D[s]. By
induction hypothesis again, tu mrfs D, which is what we wanted to show.
5. B = ∀xτC. Assume t ⊪s ∀xτC and let u : τ an arbitrary closed term of T .
Then tu ⊪s C[u/x] and by induction hypothesis
t[s]u = tu[s] mrfs C[u/x][s] = C[s][u/x]
We have thus proved that t[s] mrfs ∀xτC[s].
Similarly, one proves that
t[s] mrfs ∀xτC[s] implies t ⊪s ∀xτC.
6. B = ∃xτC. Assume p0t[s] = u. Then t ⊪s ∃xτC if and only if p1t ⊪s C[u/x]
if and only (by induction hypothesis)
p1t[s] mrfs C[u/x][s] = C[s][u/x]
if and only if t[s] mrfs ∃xτC[s].
□
Finally, we are able to prove the correctness property of restricted Friedman’s
translation which we claimed in §2.
Theorem 27 (Correctness of the Restricted Friedman Translation). Given any atomic
predicate P(x, y), the following holds:
HAω ⊢(∀xN∃yNP(x, y))A (s) =⇒HAω ⊢∀xN∃yNP(x, y)
Proof. Let us consider an arbitrary Π0
2-formula ∀xN∃yNP(x, y). By applying the
Kreisel modiﬁed realizability to any proof in HAω of (∀xN∃yNP(x, y))A (s), one ob-
tains a term t[s] of G¨odel’s system T such that
∀sN→N. t[s] mr (∀xN∃yNP(x, y))A (s)
and thus
∀sN→N. t[s] mrfs ∀xN∃yNP(x, y)
by deﬁnition of mrf. By theorem 26, for some t′ we have
t′ ⊪∀xN∃yNP(x, y)

A New Use of Friedman’s Translation: Interactive Realizability
45
Moreover, by theorem 20, from t′ one can extract a term u : N →N of G¨odel’s
system T such that for every numeral n, P(n, u(n)) = True. The proof is carried out
in HAω, hence one obtains that
t′ ⊪∀xN∃yNP(x, y) =⇒HAω ⊢∀xN∃yNP(x, y)
Therefore,
HAω ⊢(∀xN∃yNP(x, y))A (s) =⇒HAω ⊢∀xN∃yNP(x, y)
which is the thesis.
□
References
[1] F. Aschieri, S. Berardi, Interactive Learning-Based Realizability for Heyting
Arithmetic with EM1, Logical Methods in Computer Science, 2010.
[2] F. Aschieri, Interactive Learning Based Realizability and 1-Backtracking
Games, Proceedings of Classical Logic and Computation 2010, Electronic
Proceedings in Theoretical Computer Science, 2011.
[3] F. Aschieri, Learning, Realizability and Games in Classical Arithmetic, PhD
Thesis, 2011. http://arxiv.org/abs/1012.4992
[4] F. Aschieri, Transﬁnite Update Procedures for Predicative Systems of Analy-
sis, Proceedings of Computer Science Logic, 2011.
[5] F. Aschieri, A Constructive Analysis of Learning in Peano Arithmetic, Annals
of Pure and Applied Logic, 2011, doi:10.1016/j.apal.2011.12.04
[6] J. Avigad, Update Procedures and 1-Consistency of Arithmetic, Mathematical
Logic Quarterly, volume 48, 2002.
[7] J. Avigad, A realizability Interpretation for Classical Arithmetic, in Buss,
H´ajek, and Pudl´ak eds., Logic Colloquium ’98, Lecture Notes in Logic 13,
AK Peters, 57-90, 2000.
[8] S. Berardi, Classical Logic as Limit Completion, MSCS, Vol. 15, n.1, 2005,
pp.167-200.
[9] S. Berardi and U. de’ Liguoro, Interactive Realizers. A New Approach to Pro-
gram Extraction from non-Constructive Proofs, TOCL, 2010.

46
Federico Aschieri and Stefano Berardi
[10] U. Berger, H. Schwichtenberg, Program Extraction from Classical Proofs,
Logic and Computational Complexity Workshop 1994, Lecture Notes in
Computer Science, vol. 960, Springer, 1995.
[11] T. Coquand, A Semantic of Evidence for Classical Arithmetic, Journal of Sym-
bolic Logic 60, pag 325-337,1995.
[12] H. Friedman, Classically and Intuitionistically Provable Recursive Functions,
Lecture Notes in Mathematics, 1978, Volume 669/1978, 21-27.
[13] K. G¨odel ¨Uber eine bisher noch nicht ben¨utzte Erweiterung des Finiten Stand-
punktes, Dialectica 12, 280–287 (reproduced with English translation, in
[G¨odel 1990], 240–251.
[14] G. Gentzen, Die Widerspruchsfreiheit der reinen Zahlentheorie. Mathema-
tische Annalen, 112:493-565, 1935. English translation: The consistency of
elementary number theory, in Szabo [465], pages 132-200.
[15] G. Gentzen, Untersuchungen ¨uber das logische Schliessen. Mathematische
Zeitschrift, 39:176-210, 405-431, 1935. English translation: Investigations
into logical deduction, in Szabo [465], pages 68-131
[16] J.-Y. Girard, Proofs and Types, Cambridge University Press (1989).
[17] E. M. Gold, Limiting Recursion, Journal of Symbolic Logic 30, pag. 28-48
(1965).
[18] S. C. Kleene, On the Interpretation of Intuitionistic Number Theory, Journal
of Symbolic Logic 10(4), pag 109-124 (1945).
[19] U. Kohlenbach, Applied Proof Theory, Springer-Verlag, Berlin, Heidelberg,
2008.
[20] G. Kreisel, On the Interpretation of non-Finitist Proofs, Part II: Interpretation
of Number Theory, Applications, Journal of Symbolic Logic, vol. 17, 1952.
[21] G. Kreisel, On Weak Completeness of Intuitionistic Predicate Logic, Journal
of Symbolic Logic, vol. 27, 1962.
[22] J-L. Krivine, Typed lambda-calculus in classical Zermelo-Fraenkel set theory,
Archive for Mathematical Logic, 40(3):189–205, 2001.
[23] G. Mints, S. Tupailo, W. Bucholz, Epsilon Substitution Method for Elemen-
tary Analysis, Archive for Mathematical Logic, volume 35, 1996

A New Use of Friedman’s Translation: Interactive Realizability
47
[24] G. Mints, S. Tupailo, Epsilon Substitution Method for the Ramiﬁed Language
and ∆1
1-Comprehension Rule, Logic and Foundations of Mathematics, 1999.
[25] A. Miquel, Relating classical realizability and negative translation for exis-
tential witness extraction. In Typed Lambda Calculi and Applications (TLCA
2009), pp. 188-202, 2009.
[26] P. Odifreddi, Classical Recursion Theory, Studies in Logic and Foundations
of Mathematics, Elsevier, 1989
[27] P. Oliva, T. Streicher, On Krivine Realizability Interpretation of Second-Order
Classical Arithmetic, Fundamenta Informaticae, 2008.
[28] H. Schwichtenberg, A. Troelstra, Basic Proof Theory, Cambridge University
Press, 1996
[29] M. H. Sorensen, P. Urzyczyn, Lectures on the Curry-Howard isomorphism,
Studies in Logic and the Foundations of Mathematics, vol. 149, Elsevier,
2006.
[30] C. Spector, Provably Recursive Functionals of Analysis: a Consistency Proof
of Analysis by an Extension of Principles in Current Intuitionistic Mathemat-
ics, Dekker (ed.), Recursive Function Theory: Proceedings of Symposia in
Pure Mathematics, vol. 5. AMS, Providence, 1962
[31] A. Troelstra, D. van Dalen, Constructivism in Mathematics, vol. I, North-
Holland, 1988.
[32] H. Towsner, A Realizability Interpretation of Classical Analysis, Archive for
Mathematical Logic, vol. 43, 2005.
[33] A. Troelstra, Metamathematical Investigations of Intuitionistic Arithmetic and
Analysis, Lecture Notes in Mathematics, Springer-Verlag, Berlin-Heidelber-
NewYork, 1973.

48
Federico Aschieri and Stefano Berardi
Types
σ, τ ::= N | Bool | U | σ →τ | σ × τ
Constants
c ::= Rτ | ifτ | 0 | S | True | False | is | get | mkupd | ⋓| U (∀U ∈U)
Terms
t, u ::= c | xτ | tu | λxτu | ⟨t, u⟩| π0u | π1u
Typing Rules for Variables and Constants
xτ : τ
0 : N
S : N →N
True, False : Bool
U : U (for every U ∈U)
⋓: U →U →U
is : U →N →N →Bool
get : U →N →N →N
mkupd : N →N →N →U
ifτ : Bool →τ →τ →τ
Rτ : τ →(N →(τ →τ)) →N →τ
Typing Rules for Composed Terms
t : σ →τ
u : σ
tu : τ
u : τ
λxσu : σ →τ
u : σ
t : τ
⟨u, t⟩: σ × τ
u : τ0 × τ1
i ∈{0, 1}
πiu : τi
Reduction Rules All the usual reduction rules for simply typed lambda calculus (see Girard [16]) plus
the rules for recursion, if-then-else and projections
Rτuv0 7→u
RτuvS(t) 7→vt(Rτuvt)
ifτ True u v 7→u
ifτ False u v 7→v
πi⟨u0, u1⟩7→ui, i = 0, 1
plus the following ones, assuming a, n, m be numerals:
is U a n 7→

True
if ∃m. (a, n, m) ∈U
False
otherwise
get U a n 7→

m
if ∃m. (a, n, m) ∈U
0
otherwise
U1 ⋓U2 7→U1 U U2
mkupd a n m 7→{(a, n, m)}
Figure 1: the extension T of G¨odel’s system T

A New Use of Friedman’s Translation: Interactive Realizability
49
Contexts With Γ we denote contexts of the form x1 : A1, . . . , xn : An, with x1, . . . , xn proof variables
and A1, . . . , An formulas of LClass.
Axioms
Γ, x : A ⊢x|A| : A
Conjunction
Γ ⊢u : A Γ ⊢t : B
Γ ⊢⟨u, t⟩: A ∧B
Γ ⊢u : A ∧B
Γ ⊢π0u : A
Γ ⊢u : A ∧B
Γ ⊢π1u : B
Implication
Γ ⊢u : A →B Γ ⊢t : A
Γ ⊢ut : B
Γ, x : A ⊢u : B
Γ ⊢λx|A|u : A →B
Disjunction Intro.
Γ ⊢u : A
Γ ⊢⟨True, u, d|B|⟩: A ∨B
Γ ⊢u : A
Γ ⊢⟨False, d|A|, u⟩: A ∨B
Disjunction Elim.
Γ ⊢u : A ∨B Γ, x : A ⊢w1 : C Γ, x : B ⊢w2 : C
Γ ⊢if p0u then (λx|A|w1)(p1u) else (λx|B|w2)(p2u) : C
Universal Quantiﬁcation
Γ ⊢u : ∀ατA
Γ ⊢ut : A[t/ατ]
Γ ⊢u : A
Γ ⊢λατu : ∀ατA
where t is a term of LClass and αN does not occur free in any formula B occurring in Γ.
Existential Quantiﬁcation
Γ ⊢u : A[t/ατ]
Γ ⊢⟨t, u⟩: ∃ατ.A
Γ ⊢u : ∃ατ.A Γ, x : A ⊢t : C
Γ ⊢(λατλx|A| t)(π0u)(π1u) : C
where ατ is not free in C nor in any formula B occurring in Γ.
Induction
Γ ⊢u : A(0) Γ ⊢v : ∀αN.A(α) →A(S(α))
Γ ⊢λαNRuvα : ∀αNA
Post Rules
Γ ⊢u1 : A1 Γ ⊢u2 : A2 · · · Γ ⊢un : An
Γ ⊢u1 ⋓u2 ⋓· · · ⋓un : A
where n > 0 and A1, A2, . . . , An, A are atomic formulas of LClass, and the rule is a Post rule for
equality, for a Peano axiom or for a classical propositional tautology or for booleans.
Post Rules with no Premises
Γ ⊢∅: A
where A is an atomic formula of LClass and an axiom of equality or a classical propositional
tautology.
EM1
Γ ⊢Ea : ∀xN. ∃yN Pa(x, y) ∨∀yN¬BoolPa(x, y)
SK1
Γ ⊢SP : ∀xN∀yN. Pa(x, y) ⇒Bool Pa(x, Φax)
with SP := λxNλyNif (Paxy ⇒Bool Pax(Φax)) then ∅else (mkupd a x y).
Figure 2: Terms Assignement Rules for HAω + EM1 + SK1

50

Polymorphic Logic
Mark Bickford and Robert Constable
In this article we explore uses of the intersection type as another form of uni-
versal quantiﬁcation. This concept can be expressed naturally in type theories
that allow polymorphic terms, such as Computational Type Theory and Intu-
itionistic Type Theory. We have found this quantiﬁer to be very useful both in
theory and in practice. When we use the uniform universal quantiﬁer, we ob-
tain more eﬃcient realizers of constructive content. Moreover, we have been
able to ﬁnd the computational content in classical results by restating them
using these quantiﬁers.
Theorems stated in terms of the usual universal quantiﬁer and implication
can sometimes be restated with the corresponding polymorphic versions and
given new proofs that construct more uniform, polymorphic, witnesses that are
also more eﬃcient.
We illustrate these ideas in the realm of pure logic. We ﬁrst show how to
prove a lemma from Smullyan’s book First Order Logic and extract its well
hidden computational content. Then we show how to precisely characterize
the computational content of theorems in minimal ﬁrst-order logic, the logic
underlying Minlog which Helmut Schwichtenberg and his collaborators have
used to create many beautiful examples of how to ﬁnd eﬃcient computational
content from both constructive as well as classical proofs.
1
Introduction
It is well known from the propositions as types principle that methods for construct-
ing types can also be seen as methods for constructing propositions. For example
the dependent function type constructor can be seen as universal quantiﬁer and the
subtype relation as a new form of implication [9, 11, 10]. These turn out to be very
natural logical operators which in many cases express a computational interpreta-
tion that is precisely what is needed to express an idea and to create an eﬃcient
computational realizer for it.
In this article we explore uses of the intersection type [13, 9] as another form of
universal quantiﬁcation. This concept can be expressed naturally in type theories
that allow polymorphic terms, such as Computational Type Theory [8, 1] and Intu-
itionistic Type Theory [12]. We have found this quantiﬁer to be very useful both in

52
Mark Bickford and Robert Constable
theory and in practice. When we use the uniform universal quantiﬁer instead of the
normal constructive one, we obtain more eﬃcient realizers of constructive content.
Moreover, we have been able to ﬁnd the computational content in classical results
by restating them using these quantiﬁers.
Many theorems stated in terms of the usual universal quantiﬁer and implication
can be restated with the corresponding polymorphic versions and given new proofs
that construct more uniform, polymorphic, witnesses that are also eﬃcient. We il-
lustrate these ideas in the realm of pure logic. We ﬁrst show how to prove a lemma
from Smullyan’s book First Order Logic [16] and extract its well hidden computa-
tional extract. We show that the same idea can be used to indicate when numerical
arguments are used simply as indexes into computation and need not be present in
the computational content. We illustrate this with a theorem whose computational
extract is precisely the Y combinator [3]. Then we show how to precisely charac-
terize the computational content of theorems in minimal ﬁrst-order logic, the logic
underlying Minlog which Helmut Schwichtenberg and his collaborators have used
to create many beautiful examples of how to ﬁnd eﬃcient computational content
from classical proofs [5, 6, 4, 14, 15].
This article is good background for our recent results on intuitionistic com-
pleteness of minimal and intuitionistic ﬁrst-order logic. In the article Intuitionistic
Completeness of First-Order Logic [7], we show that these logics are complete with
respect to uniform validity using the intended BHK realizability semantics.
2
Universal quantiﬁcation
The standard universal quantiﬁer ∀x: T. P(x) is deﬁned to be the Π-type, Πx: T. P(x),
which we prefer to call the dependent function type and write as x: T →P(x). A
witness f ∈∀x: T. P(x) is therefore a function f ∈x: T →P(x) that maps any
x ∈T to a witness for P(x).
In some cases, there may be a single p that is a uniform witness for P(x) for
any x ∈T. In this case, p is a member of the intersection type, T
x: T P(x). Such a
p is not a function with input x ∈T, but is instead a witness for P(x), polymorphic
or uniform over all x ∈T.
2.1
Polymorphic universal quantiﬁcation
We deﬁne the polymorphic universal quantiﬁer ∀[x: T]. P(x) to be T
x: T P(x). The
brackets around the bound variable indicate that the witness does not “use” the
parameter x. Classically, ∀x: T. P(x) and ∀[x: T]. P(x) have the same meaning,
but constructively they diﬀer. A witness p for the proposition with the polymorphic

Polymorphic Logic
53
quantiﬁer is likely to be more eﬃcient since it does not need to be given an input
x ∈T.
In an extensional computational type theory like Nuprl, types are members of a
hierarchy of universes, Ui, i ∈{0, 1, 2, . . . }. When the universe level i is unimpor-
tant or can be inferred from context, we write Type for Ui. Since propositions are
deﬁned to be types, we deﬁne Pi = Ui and write P when the level is unimportant or
can be inferred from context. P is the type of propositions which we can think of
as truth values. A false proposition is an empty type, so it is extensionally equal to
False = Void. A true proposition is a non-empty type and the members of the type
are the witnesses for the truth of the proposition.
2.2
Rules for ∀[x: T]. P(x)
The rules for proving ∀[x: T]. P(x) are the rules for proving T
x: T P(x). These
make use of contexts with hidden declarations. To prove Γ ⊢T
x: T P(x) we must
prove Γ, [x : T] ⊢P(x). The brackets on the declaration [x : T] added to the context
Γ indicate that it is hidden.
To prove this sequent, we use whatever rules are appropriate for proving P(x),
and no rules use hidden declarations. The hidden declarations are automatically
unhidden once the sequent is reﬁned to one with a conclusion of the form t1 =
t2 ∈T. Because the rules for proving an equality proposition all extract a ﬁxed
witness term Ax (because we consider equality propositions to have no constructive
content) the extract of any proof of Γ, [x : T] ⊢P(x) will not include the hidden
parameter x.
In particular, the proposition t ∈T is simply an abbreviation for t = t ∈T, so
when proving a typing judgement, the hidden declarations are unhidden and may
be used.
More generally, a conclusion C has trivial computational content if we can
construct a closed witness w (independent of the hypotheses) such that C ⇔w ∈C.
Tactics (usually) recognize when the conclusion has trivial computational content
and replace the conclusion with w ∈C, so the hidden declarations can be used
while proving such conclusions as well. These include all of the so-called “Harrop”
formulae that are built from ∀, ⇒, ¬, ∧but do not use ∃, ∨.
3
A polymorphic induction principle
The principle of complete induction over the natural numbers, N, can be written in
higher-order logic as
∀P: N →P. (∀n: N. (∀m: Nn. P(m)) ⇒P(n)) ⇒(∀n: N. P(n))

54
Mark Bickford and Robert Constable
Here, the type Nn is the set type {m: N | m < n} whose members are the natural
numbers less than n.
A witness for the induction principle is a member Ind of the corresponding
dependent function type
P: (N →P) →(n: N →(m: Nn →P(m)) →P(n)) →(n: N →P(n))
The witness Ind will have the form λP. λG. λn. . . . . It takes inputs P, G, and n,
where G has type (n: N →(m: Nn →P(m)) →P(n)), and produces a witness,
Ind(P,G, n), for P(n).
If we restate the induction principle using the polymorphic universal quantiﬁer,
we get
∀[P: N →P]. (∀[n: N]. (∀[m: Nn]. P(m)) ⇒P(n)) ⇒(∀[n: N]. P(n))
Proving this is equivalent to the construction of a witness W of type
\
P: (N→P)
(
\
n: N
(
\
m: Nn
P(m)) →P(n)) →(
\
n: N
P(n))
W will have the form λF. . . . and take an F ∈(T
n: N(T
m: Nn P(m)) →P(n)) and
produce a member, W(F), of (T
n: N P(n)). The input F is a function that takes an
x ∈(T
m: Nn P(m)) and produces a witness, F(x) for P(n). The result W(F) is a
uniform witness for all the P(n), n ∈N.
Such a W appears to be a ﬁxed point operator, and we can, in fact, prove the
polymorphic induction principle using any ﬁxed point combinator ﬁx that satisﬁes
ﬁx(F) ∼F(ﬁx(F))
The relation ∼is the symmetric-transitive closure of 7→, where t1 7→t2 if a single
primitive computation step such as β-reduction, expanding deﬁnitions (δ-reduction),
or reducing another primitive (+, ∗, . . . , on numbers, projections on pairs, etc.)
transforms t1 into t2. In computational type theory all types are closed under ∼, so
we have subject reduction :
x ∈T, x ∼y ⊢y ∈T
Lemma 1.
∀[P: N →P]. (∀[n: N]. (∀[m: Nn]. P(m)) ⇒P(n)) ⇒(∀[n: N]. P(n))
Proof. Given [P ∈N →P] and f : ∀[n: N]. (∀[m: Nn]. P(m)) ⇒P(n) we must
construct a member of (∀[n: N]. P(n)) (without using P).

Polymorphic Logic
55
We show that ﬁx(f) (which is independent of P) is in (∀[n: N]. P(n)). Since
this is a proof of a typing judgement, we may now use the declarations that were
formerly hidden.
Let Γ be the context P : N →P, f : T
n: N(T
m: Nn P(m)) ⇒P(n). We must
show Γ, n : N ⊢ﬁx(f) ∈P(n) and we use the complete induction principle on n.
Thus, we show that ﬁx(f) ∈P(n) follows from the assumptions
Γ, n : N, ∀m: Nn. ﬁx(f) ∈P(m)
But these assumptions imply ﬁx(f) ∈(T
m: Nn P(m)), and therefore, using the poly-
morphic type of f, f(ﬁx(f)) ∈P(n). Since f(ﬁx(f)) ∼ﬁx(f), we have ﬁx(f) ∈
P(n).
□
We carried out this proof in Nuprl using for the ﬁxed point combinator the Y-
combinator,
Y = λf(λx(f(xx)))(λx(f(xx)))
The extract of the proof, computed by the system, is simply the term Y.
4
Uniform wellfoundedness and Brouwer ordinals
We can generalize these results. For a type T, a relation R on T, and a member
x ∈T, we deﬁne TRx to be the subtype {y: T | R(y, x)}. We say that R is uniformly
wellfounded on T if the following polymorphic induction priciple holds:
∀[P: T →P]. (∀[x: T]. (∀[y: TRx]. P(y)) ⇒P(x)) ⇒(∀[x: T]. P(x))
Thus, Lemma 1 states that Y is the witness to the fact that < is uniformly well-
founded on N.
The type N can be seen as an instance of the class of types called Brouwer
ordinals, or following Martin-Lof, W types. These types are parameterized by a
type A and family of types B[a] indexed by a ∈A. In Nuprl we use the general
recursive type constructor to deﬁne the W type
W(A; a.B[a]) = rec(W. a : A× (B[a] →W))
Thus every member of type W = W(A; a.B[a]) is a pair ⟨a, f⟩where a ∈A and
f ∈B[a] →W, and we call this pair wsup(a, f). The members of the set { f(b) | b ∈
B[a]} are the immediate predecessors of wsup(a, f). Following Martin-Lof, we
deﬁne two mutually recursive relations < and ≤on W by:
wsup(a, f) ≤w ⇔∀x : B[a]. f(x) < w

56
Mark Bickford and Robert Constable
w < wsup(a, f) ⇔∃x : B[a]. f(x) ≤w
Using the induction principle for the recursive type, we can show that these deﬁni-
tions are well formed and deﬁne transtive relations on W(A; a.B[a]).
Then, by essentialy the same argument as in Lemma 1, we proved
Lemma 2. For any type A and type family B ∈A →Type, the relation < is
uniformly wellfounded on W(A; a.B[a]) (and any ﬁxed point combinator, such as Y,
is a witness).
Using Lemma 2 we can show that if R is an ordering on a type T and there is an
order-preserving map from ⟨T, R⟩to ⟨W, <⟩for some W type , then R is uniformly
wellfounded, and Y witnesses this.
5
Propositional logic
In this section we carry out some preliminary work to formalize an account of the
classical propositional calculus along the lines of Smullyan’s account in his endur-
ingly used small textbook First-Order Logic [16]. In section 6 we will use this for-
malization as a basis for exposing the hidden computational content in Smullyan’s
elegant classical account of Boolean Valuations.
We cast our account of formulas and Boolean valuations in the Nuprl proof
development environment [8]. All of the deﬁnitions (ABS), theorem statements
(STM), proofs (PRF), and rules (RULE) are taken directly from the system.
5.1
Formulas
Our account of formulas is most closely related to Smullyan’s ﬁnal scheme (“of a
radically diﬀerent sort”) for deﬁning formulas [16, p.7], in that formulas are not
strings to be parsed, but are recursively structured from their immediate subformu-
las:
form ==
rec(form.pvar : v : N +
pnot : U : form +
pand : U : form×V : form +
por : U : form×V : form +
pimp : U : form×V : form)
Deﬁnitions for injections into the form() type, a case operator, tactics for in-
duction (structural, size, and depth), and decidability theorems for equality and

Polymorphic Logic
57
membership in the form() type are all generated automatically from a succinct
description of the desired abstract syntax.
5.2
Subformulas
With this deﬁnition of the type of formulas in place, we are able to follow Smullyan
closely in his deﬁnition of immediate subformula and subformula, which is:
The notion of immediate subformula is given explicitly by the condi-
tions:
I0: Propositional variables have no immediate subformulas.
I1: ¬X has X as an immediate subformula and no others.
I2 −I4: The formulas X ∧Y, X ∨Y, X ⇒Y have X, Y as immediate
subformulas and no others.
The notion of subformula is implicitly deﬁned by the rules:
S 1: If X is an immediate subformual of Y, or if X is identical with Y,
then X is a subformula of Y.
S 2: If X is a subformula of Y and Y is a subformula of Z, then X is a
subformula of Z.
The above implicit deﬁnition can be made explicit as follows: Y is a
subformla of Z iﬀ(i.e., if and only if) there exists a ﬁnite sequence
starting with Z and ending with Y such that each term of the sequence
except the ﬁrst is an immediate subformla of the preceding term. [16,
p. 8]
We formulate the immediate subformula concept as a relation between two for-
mulas, satisﬁed when the ﬁrst is an immediate subformula of the second:
IsImmedS ubForm(X; Z) ==
case(Z);
var(v) ⇒False;
not U ⇒X = U ∈form;
U and V ⇒(X = U ∈form) ∨(X = V ∈form);
U or V ⇒(X = U ∈form) ∨(X = V ∈form);
U implies V ⇒(X = U ∈form) ∨(X = V ∈form))

58
Mark Bickford and Robert Constable
This slightly simpliﬁes the use of the immediate subformula concept, avoiding an
unnecessary detour into membership in a list of immediate subformulas.
The implicit deﬁnition of subformula is diﬃcult to analyze, as S 2 can be ap-
plied an arbitrary number of times by applying S 1 with equal formulas. Hence, we
make deﬁnition that enforces a strict chain of immediate subformulas from X to Z:
IsS ubForm(X; Z) == r
(X = Z ∈form) ∨
((¬(X = Z ∈form)) ∧(∃Y : form.(IsImmedS ubForm(Y; Z)c ∧
IsS ubForm(X; Y))))
We also deﬁne set types (i.e., comprehension types) corresponding to the sets of
immediate sub- and sub-formulas of a given formula:
ImmedS ubForm(X) == {A : form()|IsImmedS ubForm(A; X)}
S ubForm(X) == {A : form()|IsS ubForm(A; X)}
5.3
Valuations, Extensions and Boolean Valuations
Smullyan deﬁnes valuations and extensions as follows:
Now we consider, in addition to the formulas of propositional logic, a
set {t, f} of two distinct elements, t, f as truth-values. For any set S of
formulas, by a valuation of S , we mean a function v from S into the
set {t, f} – i.e., a mapping which assigns to every element X of S one
of the two values t, f.
If S 1 is a subset of S 2 and if v1, v2 are respective valuations of S 1, S 2,
then we say that v2 is an extension of v1 if v2, v1 agree on the smaller
set S 1. [16, pp. 9–10]
For convenience, we identify Smullyan’s set {t, f} with the NuPrl type of Booleans,
B. There is little advantage to deﬁning a speciﬁc abstraction for valuations; NuPrl’s
function type suﬃces. We therefore only deﬁne the ValuationExtension ab-
straction:
ValuationExtension(S 1; f1; S 2; f2) == ∀X : S 1. f1X = f2X ∈B

Polymorphic Logic
59
∀S 1 : U.∀f1 : S 1 →B.∀S 2 : U.∀f2 : S 2 →B.
((S 1 ⊆r S 2) ⇒(ValuationExtension(S 1; f1; S 2; f2) ∈P))
In place of “subset” we use the subtype relation (written A ⊆r B). It is a propo-
sition for any types A and B. Note that the subtype relation is placed in the well-
formedness theorem, rather than in the abstraction. This seems more in the spirit
of Smullyan’s deﬁnition, although the alternative could be used with little compli-
cation.
The deﬁnition of a Boolean valuation is Smullyan’s ﬁrst “formal” deﬁnition:
Now we wish to consider valuations of the set E of all formulas of
propositional logic. We are not really interested in all valuations of E,
but only in those which are “faithful” to the usual “truth-table” rules
for the logical connectives. This idea we make precise in the following
deﬁntion.
Deﬁnition 1. A valuation v of E is called a Boolean valuation if for
every X, Y in E, the following conditions hold:
B1: The formula ¬X receives the gvalue t if X receives the value f and
f if X receives the value t.
B2: The formula X ∧Y receives the value t if X, Y both receive the
value t, otherwise X ∧Y receives the value f.
B3: The formula X ∨Y receives the value t if at least one of X, Y
receives the value t, otherwise X ∨Y receives the value f.
B2: The formula X ⇒Y receives the value f if X, Y receive the re-
spective values t, f, otherwise X ⇒Y receives the value t.
This concludes our deﬁnition of a Boolean valuation. [16, p. 10]
(Note that the set E corresponds to the form() type.) Rather than simply using the
concept of a Boolean valuation for the set of all formulas, we relativize the concept
by deﬁning partial Boolean valuation as a valuation that satisﬁes B1 – B4 on all

60
Mark Bickford and Robert Constable
elements of a given subset of formulas:
PartialBooleanValuation(S ; f) ==
∀X : S.
case(X)
var(v)
⇒
True;
not Y
⇒
f X = ¬b(fY) ∈B;
Y and Z
⇒
f X = (fY) ∧b (fZ) ∈B;
Y or Z
⇒
f X = (fY) ∨b (fZ) ∈B;
Y implies Z
⇒
f X = (fY) ⇒b (fZ) ∈B
Note that this deﬁnition does not make sense when a compound formula X is a
member of the set S but it’s immediate subformulas are not. Therefore, we deﬁne
the predicate DownClosed on subsets of formulas, which is true exactly when all
subformulas of a formula X are members of the set S whenever X is a member of
the set S :
DownClosedForm(S ) == ∀X : S.(S ubForm(X) ⊆r S )
∀S : {S : U|S ⊆r form.(DownClosedForm(S ) ∈P)
With this deﬁnition in hand, we can state and prove the following well-forme-
ness theorem for the PartialBooleanValuation abstraction:
∀S : {S : U|S ⊆r form}.
(DownClosedForm(S ) ⇒
(∀f : S →B.(PartialBooleanValuation(S ; f) ∈P)))
6
An application: constructing valuations
Raymond Smullyan’s ”First order logic” [16] begins with a deﬁnition of proposi-
tional logic. A key concept is the notion of a valuation of a propositional formula
given an assignment to its propositional variables, and Smullyan gives constructive
proofs of the existence and uniqueness of valuations. We would like to construct
the valuations by extraction from the proof of a proposition in our logic, and we

Polymorphic Logic
61
want the extracted algorithm to be eﬃcient. We can attain these goals, while re-
maining faithful to Smullyan’s proofs, by expressing an intermediate subgoal of the
existence theorem using the polymorphic universal quantiﬁer.
Smullyan adopted a purely mathematical, noncomputational approach to the
proof of Valuation Theorem. In his text, he writes:
Consider a single formula X and an interpretation v0 of X – or for that
matter any assignment v0 of truth values to a set of propositional vari-
ables which includes at least all variables of X (and possibly others).
It is easily veriﬁed by induction on the degree of X that there exists
one and only one way of assigning truth values to all subformulas of X
such that the atomic subformulas of X (which are propositional vari-
ables) are assigned the same truth values as under v0, and such that the
truth value of each compound subformula Y of X is determined from
the truth values of the immediate subformulas of Y by the truth-table
rules B1 −B4. [We might think of the situation as ﬁrst constructing a
formation tree for X, then assigning truth values to the end points in
accordance with the interpretation v0, and then working our way up
the tree, successively assigning truth values to the junction and simple
points, in terms of truth values already assigned to their successors, in
accordance with the truth-table rules]. In particular, X being a subfor-
mula of itself receives a truth value under this assignment; if this value
is true then we say that X is true under the interpretation v0, otherwise
false under v0. Thus we have now deﬁned what it means for a formula
X to be true under an interpretation. [16, pp. 10–11]
That is, we wish to show that for any formula Z and interpretation v0 of the
variables of Z, there exists one and only one function f assigning truth values to
the subformulas of Z such that f is an extension of v0 and f is a partial Boolean
valuation on subformulas of Z.
The existence of valuations is expressed in the standard way:
∀x: form. ∀v0 : Var(x) →B. ∃f : Sub(x) →B. valuation(x, v0, f)
The formal deﬁnitions are straightforward. We deﬁne a datatype for the formulas
of propositional logic by:
form := var(Atom) | not (form) | form and form | form or form| form implies form

62
Mark Bickford and Robert Constable
This deﬁnes the type form together with constructors, destructors, and recogniz-
ers for each case, and also an induction principle and an induction operator that
witnesses the induction principle.
Using the induction operator we deﬁne the sub-formula relation q ⊆p on for-
mulas, and show that it is reﬂexive and transitive. The types Var(x) and Sub(x) are
then deﬁned using the set type:
Sub(x)
=
{v: form | v ⊆x}
Var(x)
=
{v: form | v ⊆x ∧var?(v)}
The induction operator for the type can also be used non-inductively as a simple
case operator, and we use this to deﬁne the value of a formula p given an assignment
v0 and a function g deﬁned on the proper sub-formulas of p.
extend(v0, g, p)
=
case(p)
var(v) ⇒v0(v)
not q ⇒bnot(g(q))
q1 and q2 ⇒band(g(q1), g(q2))
q1 or q2 ⇒bor(g(q1), g(q2))
q1 implies q2 ⇒bimp(g(q1), g(q2))
Here, bnot, band, bor, and bimp are the obvious functions deﬁned on B, the
Boolean values.
For a function f of type Sub(x) →B to be a valuation of x given the assignment
v0 of type Var(x) →B it must satisfy the constraint valuation(x, v0, f) deﬁned by
valuation(x, v0, f) ⇔∀p: Sub(x). f(p) = extend(v0, f, p)
This deﬁnes a valuation as a function that correctly extends itself.
Lemma 3.
∀x: form. ∀v0 : Var(x) →B. ∃f : Sub(x) →B. valuation(x, v0, f)
Proof. We use the induction operator on formulas to deﬁne a rank function |x| with
range N that decreases on proper sub-formulas and assigns variables rank 0. Then
we deﬁne a bounded valuation by
bddval(n, x, v0, f) ⇔∀p: Sub(x). |x| < n ⇒f(p) = extend(v0, f, p)

Polymorphic Logic
63
Given the context Γ = x : form, v0 : Var(x) →B we must show Γ ⊢∃f : Sub(x) →
B. valuation(x, v0, f). We use the “cut” rule to assert the (polymorphically quanti-
ﬁed)
∀[n: N]. ∃f : Sub(x) →B. bddval(n, x, v0, f)
From the assertion we easily complete the proof by choosing n to be |x| + 1. To
prove the assertion we use the induction principle in Lemma 1.
We must then prove that from n : N, T
m: Nn ∃f : Sub(x) →B. bddval(m, x, v0, f)
it follows that ∃f : Sub(x) →B. bddval(n, x, v0, f). For this we let f be a member
of the type in the induction hypothesis, and then use
λp.extend(v0, f, p).
□
This existence proof is essentially the proof given by Smullyan [16] pages 10
and 11. We carried out this proof in Nuprl and the extract of the lemma, constructed
by the system, is the term
λx, v0.(Y(λf, p.extend(v0, f, p))).
These results extend unpublished work [2] attempting to faithfully ﬁnd the com-
putational content in Smullyan’s treatment of Boolean evaluation. The draft article
Expressing and Implementing the Computational Content Implicit in Smullyan’s
Account of Boolean Valuations, is available in pdf under Publications at
www.nuprl.org.
References
[1] S. Allen, M. Bickford, R. Constable, R. Eaton, C. Kreitz, L. Lorigo, and E.
Moran. Innovations in computational type theory using Nuprl. Journal of
Applied Logic, 4(4):428–469, 2006.
[2] S. F. Allen, R. Constable, and M. Fluet. Expressing and implementing the
computational content implicit in smullyan’s account of boolean valuations.
Technical Notes at PRL Project Web Site, 2003 Publication, 2003.
[3] H. P. Barendregt. The Lambda Calculus: Its Syntax and Symantics, volume
103 of Studies in Logic. North-Holland, Amsterdam, 1981.
[4] H. Benl, U. Berger, H. Schwichtenberg, et al. Proof theory at work: Program
development in the Minlog system. In W. Bibel and P. G. Schmitt, editors,
Automated Deduction, volume II. Kluwer, 1998.

64
Mark Bickford and Robert Constable
[5] U. Berger and H. Schwichtenberg. Program extraction from classical proofs.
In Daniel Leivant, editor, Logic and Computational Complexity, pages 77–97.
Springer, Berlin, 1994.
[6] U. Berger and H. Schwichtenberg. The greatest common divisor: A case
study for program extraction from classical proofs. In Types for Proofs and
Programs, International Workshop TYPES’95, volume 1158 of Lecture Notes
in Computer Science, June 1995. Workshop on Proofs and Types.
[7] R. Constable and M. Bickford. Intuitionistic Completeness of First-Order
Logic.
Technical Report arXiv:1110.1614v3, Computing and Information
Science Technical Reports, Cornell University, 2011.
[8] R. Constable, S. F. Allen, H. M. Bromley, W. R. Cleaveland, J. F. Cremer,
R. W. Harper, D. J. Howe, T. B. Knoblock, N. P. Mendler, P. Panangaden,
J. T. Sasaki, and S. F. Smith. Implementing Mathematics with the Nuprl Proof
Development System. Prentice-Hall, NJ, 1986.
[9] R. Constable and J. Hickey.
Nuprl’s class theory and its applications. In
Friedrich L. Bauer and Ralf Steinbrueggen, editors, Foundations of Secure
Computation, NATO ASI Series, Series F: Computer & System Sciences,
pages 91–116. IOS Press, 2000.
[10] A. Kopylov. Dependent intersection: A new way of deﬁning records in type
theory. In Proceedings of 18th IEEE Symposium on Logic in Computer Sci-
ence, pages 86–95, 2003.
[11] A. Kopylov and A. Nogin. Markov’s principle for propositional type theory.
In L. Fribourg, editor, Computer Science Logic, Proceedings of the 10th An-
nual Conference of the EACSL, volume 2142 of Lecture Notes in Computer
Science, pages 570–584. Springer-Verlag, 2001.
[12] P. Martin-L¨of. Constructive mathematics and computer programming. In
Proceedings of the Sixth International Congress for Logic, Methodology, and
Philosophy of Science, pages 153–175, Amsterdam, 1982. North Holland.
[13] B. C. Pierce. Programming with Intersection Types and Bounded Polymor-
phism. PhD thesis, Carnegie Mellon University, December 1991. CMU-CS-
91-205.
[14] H. Schwichtenberg and S. J. Bellantoni. Feasible computation with higher
types. In H. Schwichtenberg and R. Steinbr¨uggen, editors, Proof and System-
Reliability, Proceedings of International Summer School Marktoberdorf, July

Polymorphic Logic
65
24 to August 5, 2001, volume 62 of NATO Science Series III. Kluwer Aca-
demic Publishers, Amsterdam, 2002.
[15] M. Seisenberger. On the Constructive Content of Proofs. PhD thesis, Ludwig-
Maximilians-Universit¨at, M¨unchen, September 2003.
[16] R. M. Smullyan. First–Order Logic. Springer-Verlag, New York, 1968.

66

Constructive Solutions of Ordinary Differential
Equations
Douglas S. Bridges
For Helmut Schwichtenberg, with thanks for his friendship and for his hospitality
in Munich on numerous occasions over the past 15 years.
A Bishop-style constructive analysis is given for the Peano existence theorem
for solutions of the diﬀerential equation y′ = f(x, y) with speciﬁed initial con-
dition. In particular, it is shown that the existence of a solution in the general
case implies the omniscience principle LLPO, but that introducing an a pri-
ori hypothesis of uniqueness of a solution can enable the construction of the
solution.
1
Introduction
There is no signiﬁcant constructive problem with the Picard proof (as found in
[15] and many other texts) of the existence of solutions of the ordinary diﬀerential
equation
y′ = f(x, y),
y(x0) = y0
(*)
when f satisﬁes a Lipschitz condition. However, the proofs of the more general
classical result of Peano, stated below in a form suitable for constructive analysis,
use sequential compactness and therefore cannot readily be constructivised.
Peano’s existence theorem:
Let A ⊂R2 be closed, (x0, y0) ∈A◦, and
r > 0 such that if |x −x0| ⩽r and |y −y0| ⩽r, then (x, y) ∈A. Let
f : A →R be uniformly continuous on each compact subset of A, let
M ⩾sup {|f(x, y)| : |x −x0| ⩽r, |y −y0| ⩽r} ,
and let h = min {r, r/M}. Then the diﬀerential equation (*) has a so-
lution y on the interval I ≡[x0 −h, x0 + h] ([15], Theorem 6, page
10).

68
Douglas S. Bridges
In this paper, we discuss Peano’s existence theorem in the setting of Bishop’s
constructive mathematics (BISH), by which we mean mathematics with intuition-
istic logic and some appropriate set- or type-theoretic foundation such as those in
[4, 13, 17, 18, 19].1 We prove that (*) can be solved approximately as closely as we
wish,2 but that the existence of exact solutions in the general case is equivalent to
an essentially nonconstructive principle. We also show how adding diﬀerent forms
of the hypothesis that there exists at most one solution to (*) helps to provide an
exact solution. The natural form of that extra hypothesis gives the solution if we
accept a version of Brouwer’s fan theorem; a stronger, sequential form of the ‘at
most one solution’ hypothesis works without any fan-theoretic assumptions.
2
Peano’s theorem and LLPO
If X is a compact metric space and f : X →R a uniformly continuous function, we
write ∥f∥X ≡supx∈X |f(x)| .
Lemma 1. Under the hypotheses of Peano’s theorem, if y is a solution of the dif-
ferential equation (*) on the interval I ≡[x0 −h, x0 + h] , then
|y(x1) −y(x2)| ⩽M |x1 −x2|
(x1, x2 ∈I)
and
∥y∥I ⩽|y0| + Mh.
Proof. For x1, x2 ∈I we have
|y(x1) −y(x2)| ⩽

Z x2
x1
f(t, y(t))dt
 ⩽M |x1 −x2| .
Also,
∥y∥⩽|y0| + sup
x∈I

Z x
x0
f(t, y(t))dt
 ⩽|y0| + Mh,
as we wanted.
□
Lemma 2. Under the hypotheses of Peano’s existence theorem, let
S = {y ∈C(I) : ∥y −y0∥⩽Mh ∧
∧∀x1,x2∈I (|y(x1) −y(x2)| ⩽M |x1 −x2|)	 .
(5)
1 For more on BISH, see [6, 7, 11, 12]. For information about other varieties of constructive mathe-
matics and their relation to BISH, see [5, 11, 22].
2For a diﬀerent approach to the existence of approximate solutions for (*), using the Schauder ﬁxed-
point theorem, see Section 4 of [14].

Constructive Solutions of Ordinary Differential Equations
69
Then S is a compact subset of C(I). Moreover, if Φ : S →R is deﬁned by
Φ(y) = sup
(y(x) −y0 −
Z x
x0
f(t, y(t)) dt
 : x ∈I
)
,
(6)
then Φ is uniformly continuous on S, and infy∈S Φ(y) = 0.
Proof. First observe that, by (5.6) on page 102 of [7],
T ≡z ∈C(I) : ∥z∥⩽Mh ∧∀x1,x2∈I (|z(x1) −z(x2)| ⩽M |x1 −x2|)	
is compact. Since S = y0 + T, it follows that S is compact. For each y ∈S and
each x ∈I we have |y(x) −y0| ⩽Mh ⩽r, so f(x, y(x)) is deﬁned. Hence Φ(y) is
well deﬁned at (6). Next, since
|Φ (g1) −Φ (g2)| ⩽∥g1 −g2∥+ h sup
t∈I
|f(t, g1(t)) −f(t, g2(t))|
for all g1, g2 in C (I), we see that Φ is uniformly continuous on S. The rest of the
proof follows part of the classical proof of the Peano existence theorem in [15]
(page 10) or [10] (4.7.6). Since f is uniformly continuous on the compact set
K ≡
n
(x, y) ∈R2 : |x −x0| ⩽r, |y −y0| ⩽r
o
,
we can apply the Stone-Weierstraß Theorem, to construct a sequence (pn)n⩾1 of
polynomial functions of two variables such that
sup
(x,y)∈K
|f(x, y) −pn(x, y)| < 2−n
for each n. We may assume that
sup
(x,y)∈K
|pn(x, y)| ⩽M
for each n. Since pn satisﬁes a Lipschitz condition, there exists a unique solution yn
of the diﬀerential equation
y′ = pn(x, y),
y(x0) = y0
on I; see [15] (page 8) or [10] (4.7.4). Note that
h ≡min

r, r
M


70
Douglas S. Bridges
depends on M and not on n. By Lemma 1, yn ∈S. Moreover, for each x ∈I and
each n,
yn(x) −y0 −
Z x
x0
f(t, yn(t)) dt
 ⩽
yn(x) −y0 −
Z x
x0
pn(t, yn(t)) dt

+

Z x
x0
(f(t, yn(t)) −pn(t, yn(t))) dt

⩽2−n |x −x0| ,
⩽2−nh,
so
yn(x) −y0 −
Z x
x0
f(t, yn(t)) dt
 ⩽2−nh.
Hence Φ(yn) →0 as n →∞, and therefore infy∈S Φ(y) = 0.
□
Bishop called the following essentially nonconstructive proposition the lesser
limited principle of omniscience:
LLPO: For each binary sequence (an)n⩾1 with at most one term equal
to 1, either a2n = 0 for all n or a2n+1 = 0 for all n.
This principle is equivalent to the statement
∀x∈R (x ⩾0 ∨x ⩽0)
and to the full form of Peano’s theorem. In fact, it is well known (cf. the proof of
Theorem 2 in [1]) that if, for any a > 0 and some h > 0, the initial value problem
y′ = y1/3, y(0) = a
has a solution on [−h, h], then we can derive LLPO. We now present an alterna-
tive Brouwerian example, whose force derives not from a fuzziness in the initial
condition, but from the behaviour of the solution between x = 0 and x = 1.
Theorem 3. Peano’s existence theorem is equivalent to LLPO.
Proof. The proof of is based on ideas of Aberth [3]. First, for a, b in R we deﬁne
the spike function
spike(·, a, r) : R →R
as the unique (uniformly) continuous function on R that vanishes outside the in-
terval [a −r, a + r], takes the value 1 at a, and is linear on the intervals [a −r, a],

Constructive Solutions of Ordinary Differential Equations
71
[a, a + r]. Let (an)n⩾1 be a binary sequence with at most one term equal to 1. Deﬁne
the mapping h : [0, 1] →[−1, 1] by
h(x) ≡
∞
X
n=1
(−1)n 2−nan spike
 
x, 1
2, 2−n−1
!
(0 ⩽x ⩽1) .
Then h is uniformly continuous on [0, 1]. Note that at most one term of the series
deﬁning h(x) is nonzero; if it is the nth term, then h is 0 everywhere in [0, 1] except
for an interval of length 2−n centred at 1/2, on which it has a (possibly negative)
triangular pulse of height 2−n. It follows that if y : [0, 1] →R satisﬁes
y′(x) = h(x), y(0) = 0,
then
y (1) =
∞
X
n=1
(−1)n 2−2n−1an.
Next deﬁne a continuous function f : [0, 2] × [−2, 2] →[−1, 1] such that
f(x, y) =

h(x)
if 0 ⩽x ⩽1
(x −1) y1/3
if 1 < x ⩽2.
Setting
f(−z, y) = f(z, y)
(−2 ⩽z ⩽0) ,
extend f by uniform continuity to a uniformly continuous mapping of [−2, 2] ×
[−2, 2] into [−1, 1]. (Note that f glues nicely at the lines x = −1, x = 0, and x = 1.)
Next, observe that if y(1) , 0, then the diﬀerential equation
y′ = (x −1) y1/3
has a unique solution
y = sgn(y(1))
 1
3 (x −1)2 + |y(1)|2/3
!3/2
on the interval [1, 2]. Then
y(2) = sgn(y(1))
 1
3 + |y(1)|2/3
!3/2
.
Suppose that the initial value problem
y′ = f(x, y), y(0) = 0
(7)

72
Douglas S. Bridges
has a solution y on the interval [−2, 2]. (In the notation of the Peano existence
theorem, we have x0 = 0 = y0, r = 2). Either y(2) < (1/3)3/2 or y(2) > −(1/3)3/2 .
In the ﬁrst case, if an = 1 for some even n, then y(1) = 2−2n−1, so y(2) > (1/3)3/2 ,
a contradiction. Hence an = 0 for all even n. A similar argument shows that in
the second case, an = 0 for all odd n. We conclude that Peano’s existence theorem
implies LLPO.
In view of Lemma 2, the converse implication is a consequence of Ishihara’s
result that LLPO is equivalent, over BISH, to every uniformly continuous, real-
valued mapping on a compact set attaining its inﬁmum [16].
□
3
Adding uniqueness
The problem in the ﬁrst part of the proof of Theorem 3 is the potential non-unique-
ness of the solution of the diﬀerential equation (7). In an attempt to get over this
barrier, we say that the general diﬀerential equation (*) has at most one solution
on an interval [a, b] containing x0 if
max
i=1,2 sup
x∈[a,b]
yi(x) −y0 −
Z x
x0
f(t, yi(t)) dt
 > 0
whenever y1, y2 are uniformly continuous on [a, b] , y1(x0) = y2(x0), and y1 , y2.
We now show that if, with the function f as in the ﬁrst part of the proof of
Theorem 3, the initial value problem (7) has at most one solution on [−2, 2], then it
has a solution. To that end, let
a ≡
∞
X
n=1
(−1)n 2−2n−1an,
which, if (7) has a solution is the value of that solution at x = 1. Also, deﬁne
uniformly continuous functions
y+, y−: [−2, 2] × [−2, 2] →[−1, 1]
such that
y+(x) =

R x
0 |h(t)| dt
if 0 ⩽|x| < 1
 1
3 (|x| −1)2 + |y+(1)|2/33/2
if 1 ⩽|x| ⩽2
and
y+(x) =

−
R x
0 |h(t)| dt
if 0 ⩽|x| < 1
−
 1
3 (|x| −1)2 + |y−(1)|2/33/2
if 1 ⩽|x| ⩽2.

Constructive Solutions of Ordinary Differential Equations
73
Then y+(2) , y−(2), so y+ , y−. Now assume that the initial value problem (7) has
at most one solution. Then either
sup
|x|⩽2
y+(x) −
Z x
0
f (t, y+(t)) dt
 > 0
or
sup
|x|⩽2
y−(x) −
Z x
0
f (t, y−(t)) dt
 > 0.
(8)
Consider the ﬁrst alternative. There exists x ∈[−2, 2] such that
y+(x) ,
Z x
0
f (t, y+(t)) dt.
By continuity, we may assume that x lies in one of the four intervals (−2, −1) , (−1, 0),
(0, 1) , (1, 2) . Take ﬁrst the case where 0 ⩽x ⩽1. We have
Z x
0
|h(t)| dt = y+(x) ,
Z x
0
f (t, y+(t)) dt =
Z x
0
h(t)dt,
so there exists t ∈(0, x) such that h(t) , |h(t)| and therefore h(t) < 0. It follows that
(7) has the unique solution y−on [−2, 2] . Next, consider the case where 1 < x < 2.
We have
Z x
0
f (t, y+(t)) dt =
Z 1
0
|h(t)| dt +
Z x
1
t
 1
3 (t −1)2 + |y+(1)|2/3
!1/2
dt
= |y(1)| +
Z x
1
t
 1
3 (t −1)2 + |y+(1)|2/3
!1/2
dt.
With u ≡
1
3 (t −1)2 + |y(1)|2/3 , the indeﬁnite version of the integral on the right
becomes
Z 3
2u1/2du = u3/2.
Hence
Z x
0
f (t, y+(t)) dt = |y(1)| +
 1
3 (x −1)2 + |y+(1)|2/3
!3/2
= |y+(1)| + y+(x).
Our choice of x yields
y+(x) , |y+(1)| + y+(x),
from which it follows that y+(1) , 0. If y+(1) > 0, then y+ is the unique solution of
our initial value problem, which is a contraction. Hence y+(a) < 0, and the unique

74
Douglas S. Bridges
solution on I is, in fact, y−. Similar considerations to the foregoing cover the cases
where −2 < x < −1 and −1 < x < 0. Likewise, if (8) obtains, then (*) has the
unique solution y+ on I.
This example suggests that if (*) has at most one solution on an interval I con-
taining x0, then it has a solution on I. However, this is not possible, in view of
Aberth’s recursive example3 in which (*) has no solution [3] (pages 125–139). We
can, however, prove a weaker result in this vein. For this, we require some more
deﬁnitions.
Let (X, ρ) be a metric space, and f : X →R a sequentially continuous function.
that has an inﬁmum. A sequence (xn)n⩾1 in X is said to be minimising for f if
f(xn) →inf f as n →∞. We say that f has
– sequentially at most one minimum point if any two minimising sequences
(xn)n⩾1 ,  x′
n

n⩾1 for f are eventually close in the sense that ρ  xn, x′
n
 →0 as
n →∞;
– uniformly at most one minimum if for each ε > 0, there exists δ > 0 such
that if x, x′ ∈X, f(x) < inf f + δ, and f(x′) < inf f + δ, then ρ (x, x′) < ε;
– a strong minimum at ξ (the strong minimum point) if for each ε > 0, there
exists δ > 0 such that if x ∈X and f(x) < f(ξ) + δ, then ρ (x, ξ) < ε.
Clearly, if f has uniformly at most one minimum, then it has sequentially at most
one minimum. Referring to Proposition 3 of [8], we see that if X is compact and f is
uniformly continuous, then the converse holds, so these two ‘at most one minimum’
conditions are equivalent. In that case there exists a unique ξ ∈X such that f(ξ) =
inf f; moreover, with ε, δ as above, if x ∈X and f(x) < inf f + δ, then ρ (x, ξ) < ε
([20], Proposition 2.1), so ξ is a strong minimum point for f. In view of Lemma 2,
these observations, applied to the compact space S and the uniformly continuous
mapping Φ on S , give us the following result.
Proposition 4. Under the hypotheses of Peano’s theorem, let S and Φ : S →R be
as deﬁned at (5) and (6). Suppose that Φ has sequentially at most one minimum in
S . Then
(i) the diﬀerential equation (*) has a unique solution y on the interval I;
3 It is worth checking to see whether Aberth’s example actually has at most one solution in our strong
sense. If, as is permissible when working in the recursive model of BISH (see Chapter 3 of [11]), we
assume Markov’s principle, then it does. For if y1, y2 ∈S and max {Φ(y1), Φ(y2)} = 0, then Φ(y1) =
Φ(y2) = 0, contradicting Aberth’s result; whence, by Markov’s principle, max {Φ(y1), Φ(y2)} > 0.

Constructive Solutions of Ordinary Differential Equations
75
(ii) for each ε > 0, there exists δ > 0 such that if z ∈S and Φ(z) < δ, then
∥y −z∥I < ε.
Now, it is a truth universally acknowledged that a constructive mathematician
in possession of parametrised solutions must be in want of continuity in those pa-
rameters:
Theorem 5. Let A ⊂R2 be closed, (x0, y0) ∈A◦, and r > 0 such that
A ⊃K ≡
n
(x, y) ∈R2 : |x −x0| ⩽r ∧|y −y0| ⩽r
o
.
Let M > 0, h = min {r, r/M}, and I ≡[x0 −h, x0 + h]. With S as at (5), for each
f ∈S deﬁne Φf on S by
Φf (y) ≡sup
(y(x) −y0 −
Z x
x0
f(t, y(t)) dt
 : x ∈I
)
.
Let S u be the set of those f ∈S such that ∥f∥K ⩽M and Φf has a strong minimum
in S , and for each f ∈S u let yf denote the strong minimum point of Φf . Then the
mapping f ⇝yf is pointwise continuous on S u.
Proof. Fix f ∈S u and ε > 0. Choose δ > 0 such that if g ∈S u and Φf (g) < δ, then
yf −g
 < ε. Consider any g ∈S u with ∥f −g∥K < δ/r. For each x ∈I we have
yg(x) −y0 −
Z x
x0
f(t, yg(t)) dt

⩽
yg(x) −y0 −
Z x
x0
g(t, yg(t)) dt
 +
Z x
x0
 f(t, yg(t)) −g(t, yg(t))
 dt
⩽Φg(yg) + r ∥f −g∥K .
Since Φg(yg) = 0, it follows that
Φf (yg) ⩽r ∥f −g∥K < δ
and therefore that
y f −yg
 < ε.
□
4
Concluding remarks
If we adopt Brouwer’s fan theorem for detachable bars, FTD (see [8] for more
on this), then we can establish the existence of a solution to (*) on the interval

76
Douglas S. Bridges
[x0 −h, x0 + h] with the hypothesis ‘any two minimising sequences for Φ are even-
tually close’ in Proposition 4 replaced by ‘there is at most one solution of (*)’: we
just apply Theorem 5 of [8] to the uniformly continuous function Φ on the com-
pact space S . It is tempting to believe that the ‘at most one solution implies there
is a solution’ version of Peano’s existence theorem is equivalent, over BISH, to
FTD. However, a proof of this equivalence is elusive, perhaps because the Peano
existence problem deals with a very speciﬁc compact space, namely S , whereas
equivalents of FTD normally deal with statements that apply to all compact metric
spaces (see [9]).
Acknowledgements.
Numerous conversations with Josef Berger, Iris Loeb, Pe-
ter Schuster, and Helmut Schwichtenberg have helped clarify my thoughts on the
problems discussed in this paper. The work was supported by the Marsden Fund of
the Royal Society of New Zealand (project UOC0502) and the recurrent, generous
hospitality of the Schwichtenberg logic group at Ludwig-Maximilians-Universit¨at,
M¨unchen.
References
[1] O. Aberth: ‘Computable analysis and diﬀerential equations’, in Intuition-
ism and Proof Theory (A.Kino, J. Myhill, R.E. Vesley, eds), 47–52), North-
Holland Publ. Co., Amsterdam, 1970.
[2] O. Aberth: Computable Analysis, McGraw-Hill, New York, 1980.
[3] O. Aberth: ‘The failure in computable analysis of a classical existence theo-
rem for diﬀerential equations’, Proc. Amer. Math. Soc. 30, 151–156, 1971.
[4] P. Aczel and M. Rathjen: Notes on Constructive Set Theory, Report No. 40,
Institut Mittag-Leﬄer, Royal Swedish Academy of Sciences, 2001.
[5] M.J. Beeson: Foundations of Constructive Mathematics, Springer Verlag,
Heidelberg, 1985.
[6] E.A. Bishop: Foundations of Constructive Analysis, McGraw-Hill, New York,
1967.
[7] E.A. Bishop and D.S. Bridges: Constructive Analysis, Grundlehren der Math.
Wiss. 279, Springer Verlag, Heidelberg, 1985.

Constructive Solutions of Ordinary Differential Equations
77
[8] J. Berger, D.S. Bridges, and P.M. Schuster: ‘The fan theorem and unique
existence of maxima’, J. Symbolic Logic 71(2), 713-720, 2006.
[9] J. Berger and H. Ishihara: ‘Brouwer’s fan theorem and unique existence in
constructive analysis’, Math. Logic Quart. 51(4), 360–364, 2005.
[10] D.S. Bridges: Foundations of Real and Abstract Analysis, Graduate Texts in
Mathematics 174, Springer Verlag, Heidelberg-Berlin-New York, 1998.
[11] D.S. Bridges and F. Richman: Varieties of Constructive Mathematics, London
Math. Soc. Lecture Notes 97, Cambridge Univ. Press, 1987.
[12] D.S. Bridges and L.S. Vˆıt¸˘a: Techniques of Constructive Analysis, Universi-
text, Springer New York, 2006.
[13] H.M. Friedman: ‘Set Theoretic Foundations for Constructive Analysis’, Ann.
Math. 105(1), 1–28, 1977.
[14] M. Hendtlass: ‘Fixed point theorems in constructive mathematics’, preprint,
University of Leeds, 2011.
[15] W. Hurewicz: Lectures on Ordinary Diﬀerential Equations, M.I.T. Press,
Cambridge, Mass., 1958.
[16] H. Ishihara, ‘An omniscience principle, the K¨onig lemma and the Hahn-
Banach theorem’, Z. Math. Logik Grundl. Math. 36, 237–240, 1990.
[17] P. Martin-L¨of: An Intuitionistic Theory of Types: Predicative Part, in Logic
Colloquium 1973 (H.E. Rose and J.C. Shepherdson, eds), 73–118, North–
Holland, Amsterdam, 1975.
[18] J. Myhill: ‘Constructive Set Theory’, J. Symb. Logic 40(3), 347–382, 1975.
[19] G. Sambin and J. Smith: Twenty Five Years of Constructive Type Theory,
Oxford Logic Guides 36, Clarendon Press, Oxford, 1998.
[20] P.M. Schuster: ‘Unique solutions’, Math. Logic Quart. 52(6), 534-539, 2006.
Corrigendum: Math. Logic Quart. 53(2), 214, 2007.
[21] A.S. Troelstra and D. van Dalen: Constructivism in Mathematics: An Intro-
duction (two volumes), North Holland, Amsterdam, 1988.

78

A Nonstandard Hierarchy Comparison Theo-
rem for the Slow and Fast Growing Hierarchy
Wilfried Buchholz and Andreas Weiermann∗
It is folklore that the slow and fast growing hierarchy match up for the ﬁrst
time at the proof-theoretic ordinal of (Π1
1 −CA)0. By results of Sch¨utte and
Simpson it is known that the underlying notation system looses its strength
when the ordinal addition function is no longer present. In this article we
will show that a hierarchy comparison can still be established. Surprisingly
the match of the slow and fast growing hierarchy can be arranged by using
standard fundamental sequences to happen at ω2 which is much smaller than
the ordinal of (Π1
1 −CA)0. We will also show that the slow growing hierarchy
consists of elementary functions only when it is based on a Buchholz style
system of fundamental sequences for the Sch¨utte Simpson ordinal notation
system.
1
Introduction
With Helmut Schwichtenberg (who wrote his PhD thesis about this subject) we
share a deep interest in subrecursive hierarchies. Schwichtenberg [5] and indepen-
dently Wainer gave in the seventies a classiﬁcation of the < ϵ0-recursive functions
which nowadays still forms a classic and which is very useful not even in hierarchy
theory. Over the years Schwichtenberg (and Wainer) also showed continued inter-
est in results related to the comparison of the slow and fast growing hierarchies [6].
This article provides a somewhat surprising result on hierarchy comparisons which
is driven by pure curiosity. What happens in hierarchy comparison results when the
addition is deleted from the context? We show that a modiﬁcation of a new proof
of the hierarchy comparison theorem goes through almost word for word but the
match between the hierarchies now occurs at ω2.
∗This author’s research was partially supported by the John Templeton Foundation and the FWO
and it was partially done whilst this author was a visiting fellow at the Isaac Newton Institute for the
Mathematical Sciences in the programme ‘Semantics & Syntax.

80
Wilfried Buchholz and Andreas Weiermann
2
Tree ordinals for IDω
In this section we recall some facts from the theory of tree ordinals for IDω (cf.,
e.g., [2, 3]).
Deﬁnition 1. Inductive Deﬁnition of tree classes Oν (ω , ν ≤ω + 1).
1. 0 := ∅∈Oν.
2. α ∈Oν =⇒α+1 := {(0, α)} ∈Oν.
3. µ < ν & ∀ξ ∈Oµ(αξ ∈Oν) =⇒(αξ)ξ∈Oµ ∈Oν.
We identify O0 and IN.
Deﬁnition 2. Inductive deﬁnition of | α | for α ∈O1.
1. | 0 |:= 0.
2. | α + 1 |:=| α | +1.
3. | (αi)i∈IN) |:= sup{| αi | +1 : i ∈IN}.
Deﬁnition 3. Inductive deﬁnition of α + β for α, β ∈Oω+1.
1. α + 0 := α.
2. α + (β + 1) := (α + β) + 1.
3. α + (βξ)ξ∈Oµ := (α + βξ)ξ∈Oµ.
Deﬁnition 4. Deﬁnition of ˙Ωµ, ˙ω, ˙Ω.
1. ˙Ωµ+1 := (ξ)ξ∈Oµ+1.
2. ˙Ω0 := ˙ω := (ξ)ξ∈O0.
3. ˙Ωω := ( ˙Ωi)i∈ω.
4. ˙Ω:= ˙Ω1.
Deﬁnition 5. Inductive deﬁnition of Dω : Oω+1 →Oω+1.
1. Dω0 := ˙Ωω.
2. Dω(α + 1) := Dωα + Dωα.
3. Dω((αξ)ξ∈Oµ) := (Dωαξ)ξ∈Oµ.
Deﬁnition 6. Inductive deﬁnition of Dm
ω(α) for α ∈Oω+1.
D0
ω(α) := α,
Dm+1
ω
(α) := Dω(Dm
ω(α)).
We set ˙εΩω+1 := (Di
ω( ˙Ωω + ˙ω + ˙ω))i∈IN.
Deﬁnition 7. Inductive deﬁnition of Dm : Oω+1 →Om+1
(m < ω).
1. Dm0 := ˙Ωm.
2. Dm(α + 1) := Dm(α) + 1.
3. Dm((αξ)ξ∈Oρ) := (Dm(αξ))ξ∈Oρ, if ρ ≤m.
4. Dm((αξ)ξ∈Oρ+1) := (Dmβρ+1,m
ξ
)ξ∈Om if m < ρ + 1
where βρ+1,ρ+1
ξ
:= αξ and βρ+1,n
ξ
:= βρ+1,n+1
Dnβρ+1,n+1
ξ
for n < ρ + 1.

A Nonstandard Hierarchy Comparison Theorem
81
Remark: | D0 ˙εΩω+1 | is the proof-theoretic ordinal of IDω [cf.[2, 3]].
Deﬁnition 8. Inductive deﬁnition of a set T of tree notations.
1. 0, 1 ∈T , lev(0) = lev(1) = 0 and 1 ∈P.
2. If α ∈T and ν ≤ω, and lev(α) ≤ν + 1 then Dνα ∈T , lev(Dνα) = ν and
Dνα ∈P.
3. If α0, ..., αk ∈P
(k ≥1), then α0 + · · · + αk ∈T and lev(α0 + · · · + αk) =
max{lev(αi) : i ≤k}
In the sequel we work only with tree ordinals which are denoted by elements of
T . For those tree ordinals we have in addition a term structure along which we can
carry out syntactical deﬁnitions. Note that α, β ∈T implies α + β ∈T .
For notational reasons we will write in the sequel α[[ξ]] for αξ at several places.
Deﬁnition 9. Inductive deﬁnition of tp(α) for α ∈T and α ∈Oω+1.
1. tp(0) := 0.
2. tp(α + 1) := 1 := {∅}.
3. tp((αξ)ξ∈On) := ˙Ωn.
Lemma 10. Recursive description of α[[ξ]] for α ∈T with tp(α) > 1 and ξ ∈tp(α).
1. (Dn0)[[ξ]] = ξ.
2. (α0 + · · · + αk)[[ξ]] = α0 + · · · + αk[[ξ]].
3. (Dnα)[[ξ]] = Dnα[[ξ]] if lev(tp(α)) ≤n.
4. (Dnα)[[ξ]] = Dn(α[[Dn(α[[ξ]])]]) if lev(tp(α)) > n.
Note that this is conform with the standard interpretation for tree ordinals.
Lemma 11. α, ξ ∈T and ξ ∈tp(α) implies α[[ξ]] ∈T .
Proof. If α = α0 + · · · + αk then tp(α) = tp(αk) and the i.h. yields αk[[ξ]] ∈T . Then
α[[ξ]] = α0 + · · · + αk[[ξ]] ∈T .
If α = Dmβ and tp(α) = tp(β) = Ωm+1 then the i.h. yields β[[ξ]] ∈T hence
α[[ξ]] = Dmβ[[ξ]] ∈T .
If α = Dmβ and tp(α) = tp(β) = Ωρ+1 with ρ + 1 > m then the i.h. yields
β[[ξ]] ∈T hence Dmβ[[ξ]] ∈T . The i.h. yields β[[Dmβ[[ξ]]]] ∈T hence α[[ξ]] =
Dmβ[[Dmβ[[ξ]]]] ∈T .
□
Lemma 12. If α, β ∈T and tp(α) = ˙Ωρ+1 and β ∈Oρ+1 and tp(β) = ˙Ωm then
tp(α[[β]]) = ˙Ωm and (α[[β]])[[ξ]] = α[[β[[ξ]]]] for ξ ∈Om

82
Wilfried Buchholz and Andreas Weiermann
Proof. If α = α0 + · · · + αk then tp(α) = tp(αk) and
α[[β[[ξ]]]]
=
α0 + · · · + αk[[β[[ξ]]]]
=
α0 + · · · + (αk[[β]])[[ξ]]
=
(α0 + · · · + αk[[β]])[[ξ]]
=
((α0 + · · · + αk)[[β]])[[ξ]]
=
(a[[β]])[[ξ]]
If α = Dmγ with tp(γ) = ˙Ωn and n ≤m then tp(α) = tp(γ) and
α[[β[[ξ]]]]
=
Dm(γ[[β[[ξ]]]])
=
Dm((γ[[β]])[[ξ]])
=
(Dmγ[[β]])[[ξ]]
=
(α[[β]])[[ξ]]
If α = Dmγ with tp(γ) = ˙Ωm+1 then tp(α) = ˙Ωm and
α[[β[[ξ]]]]
=
Dmγ[[Dmγ[[β[[ξ]]]]]]
=
Dmγ[[Dm(γ[[β]][[ξ]])]]
=
Dmγ[[Dmγ[[β]][[ξ]]]]
=
Dm(γ[[Dmγ[[β]]]][[ξ]])
=
(Dmγ[[Dmγ[[β]]]])[[ξ]])
=
((Dmγ)[[β]])[[ξ]])
=
(α[[β]])[[ξ]]
□
Lemma 13. If α ∈T and tp(α) = ˙Ωm+1 then Dmα = Dmα[[Dmα[[ ˙Ωm]]]].
Proof.
Dmα[[Dmα[[ ˙Ωm]]]]
=
Dmα[[Dm((α[[ξ]])ξ∈Om)]]
=
Dmα[[(Dmα[[ξ]])ξ∈Om]]
=
Dm((α[[Dmα[[ξ]])]])ξ∈Om)
=
(Dmα[[Dmα[[ξ]])]])ξ∈Om
=
Dmα

A Nonstandard Hierarchy Comparison Theorem
83
□
Deﬁnition 14. Inductive deﬁnition of Fα for α ∈O1 (cf.[1]).
1. F0(n) := n.
2. Fα+1(n) := Fα(n) + 1.
3. F(αi)i∈IN(n) := FαFαn (n)(n).
This is a recursion along the rank of α, | α |. In the sequel we carry out most
calculations along representations for tree ordinals. But at some places we use
induction on the ranks.
Remark: Results in [3] indicate that for every in IDω provably total function f :
IN →IN there is an i < ω such that f(n) < FD0(Diω( ˙Ωω+ ˙ω+ ˙ω))(n) holds for all n ∈
IN [cf.[3]]. To obtain a majorization of the Hardy-hierarchy used in [3] and the
F hierarchy used in this article one can roughly employ an estimate of the form
Fβ(Fα(x)) ≤Fα+β(x). In the sequel we consider (Fα) as one suitable version of the
fast growing hierarchy.
Deﬁnition 15. Inductive deﬁnition of Gα for α ∈O1.
1. G0(n) := 0.
2. Gα+1(n) := Gα(n) + 1.
3. G(αi)i∈IN(n) := Gαn(n).
This is again a recursion along | α |.
3
Proof of the hierarchy comparison theorem follow-
ing the classical lines
We give a proof of the hierarchy comparison theorem using ideas of Wainer ([7]).
The following deﬁnition is carried out by recursion on the (length of the) notation
for a tree ordinal. (In the sequel we identify these notations with the denoted or-
dinal. This causes no intrinsic diﬃculty but one has to be aware of the fact that
diﬀerent notations can denote the same tree ordinal.)
Deﬁnition 16. Inductive deﬁnition of Cx(α) for α ∈T
1. Cx(α) := Gα(x) if α ∈O1.
2. Cx(α0 + · · · + αk) := Cx(α0) + · · · + Cx(αk).
3. Cx(Dm+1α) := DmCx(α).
4. Cx( ˙Ωω) := ˙Ωx.
Lemma 17. If x ∈IN, α ∈T , lev(α) ≤n for some n < ω and tp(α) = ˙ω then
Cx(α) = Cx(αx).

84
Wilfried Buchholz and Andreas Weiermann
Proof. By induction on the length of the notation for α.
1. lev(α) = 0.
Then Cx(α) = Gα(x) = Gαx(x) = Cx(αx).
2. α = β + γ where tp(γ) = ˙ω. Then the induction hypothesis yields
Cx(α) = Cx(β) + Cx(γx) = Cx(β) + Cx(γ) = Cx(α).
3. α = Dm+1β where tp(β) = ˙ω.
Then the induction hypothesis yields Cx(α) = DmCx(β) = DmCx(βx) = Cx(αx).
4. α = Dm+1β where tp(β) = ˙Ωm+2. Then tp(α) = ˙Ωm+1 and this case does not
occur.
□
Lemma 18.
If α ∈T , tp(α) = ˙Ωm, m ≥1 and ξ ∈Om then the tree ordinal Cx(αξ) is the same
as the tree ordinal Cx(α)[[Cx(ξ)]].
Proof. By induction on the length of the notation for α.
1. α = Dm0. Then α[[ξ]] = ξ and the result follows.
2. α = β + γ where tp(γ) = tp(α) = ˙Ωm.
Then Cx(α[[ξ]]) = Cx(β) + Cx(γ[[ξ]]) = Cx(β) + Cx(γ)[[Cx(ξ)]] = Cx(α)[[ξ]].
3. α = Dn+1β and tp(β) = tp(α) = ˙Ωm where m ≤n + 1.
Then Cx(α[[ξ]]) = DnCx(β[[ξ]]) = DnCx(β)[[Cx(ξ)]] = Cx(α)[[Cx(ξ)]].
4. α = Dn+1β where tp(β) = ˙Ωn+2.
Let β′ := β[[Dn+1β[[ ˙Ωn+1]]]].
Then α is the same tree ordinal as Dn+1β′ and tp(α) = ˙Ωn+1.
Moreover Cx(Dn+1β) = DnCx(β). Let β′′ := β′[[Dnβ′[[ ˙Ωn]]]].
Then Cx(α) is the same tree ordinal as Dnβ′′ and tp(Cx(α)) = ˙Ωn.
For ξ ∈On+1 we obtain following identity between tree ordinal values
Cx(α)[[ξ]] = Cx(Dn+1β′[[ξ]]) = Dnβ′′[[Cx(ξ)]] = Cx(α)[[Cx(ξ)]].
□
Theorem 19.
Let α ∈T and lev(α) ≤1. Then GD0α(x) = FCx(α)(x).
Proof. By induction on the tree ordinal which is denoted by α.
1. α = 0.
Then GD00(x) = Gx(x) = x = F0(x) = FCx(0)(x).
2. If α = β + 1, then

A Nonstandard Hierarchy Comparison Theorem
85
GD0α(x)
=
GD0β+1(x)
=
GD0β(x) + 1
=
FCx(β)(x) + 1
=
FCx(β)+1(x) = FCx(α)(x).
3. If tp(α) = ˙ω then
GD0α(x) = GD0αx(x) = FCx(αx)(x) = FCx(α)(x).
4. If tp(α) = ˙Ω1 then
GD0α(x)
=
GD0α[[D0α ˙Ω0]](x)
=
FCx(α[[D0α ˙Ω0]])(x)
=
F(Cx(α))[[Cx(D0α ˙Ω0)]](x)
=
F(Cx(α))[[FCx(α ˙Ω0
)(x)]](x)
=
F(Cx(α))[[F(Cx(α))[[x]](x)]](x)
=
FCx(α)(x).
□
Corollary 20.
GD0D1...DmΩm+1(x) = FD0...Dm−1 ˙Ωm(x).
Remark: If one changes the deﬁnition of Dm by deﬁning a similar function D′
m
by deﬁning D′
m(α + 1) := D′
mα + D′
mα then the proof of Theorem 7 and Corollary
8 go through when one considers a variant F′
α of the fast growing hierarchy which
satisﬁes F′
α+1(n) := F′
α(n) · 2.
Our result raises some immediate questions:
What is the height of D0 ˙Ωω? (By [4] it is known that the height will be bounded
by ε0.)
Is GD0 ˙Ωω in fact slow- or fast growing or is FD0 ˙Ωω slow- or fast growing?
These questions are answered in the following section and the answer is somewhat
surprising.

86
Wilfried Buchholz and Andreas Weiermann
4
A direct proof of the hierarchy comparison theorem
This section is the result of a fruitful interaction of the second author with the
referee during the refereeing procedure after which the referee became the ﬁrst
author. (We follow the tradition of using the lexicographic ranking of authors.) The
ﬁrst author calculated the order type of D0Ωω which is ω2. He further proved some
technical lemmata and showed GD0Ω2(x) , FD0Ω1(x) which provided a counter
example to a claim of the second author in the ﬁrst version of this article. The
second author then took up the ﬁrst author’s suggestions to start with some direct
calculations and was able to correct his original proof. Some further results which
have independent interest are documented in this section.
We drop in this section the superscript˙in ˙Ωto simplify the notation.
Deﬁnition 21. p(n) := 2n+1 −1.
Remark. p(n + 1) = p(n) + p(n) + 1.
Lemma 22.
a) lev(β) < n + 1 ⇒Dn(α + β) = Dnα + β
b) Dn(Ωn+1 · k) = Ωn · p(k)
c) Fω·k(x) = x · p(k).
d) GΩ·k(x) = x · k.
Proof. a) By induction on β.
Proof of b) by induction on k:
Dn(Ωn+1 · 0) = Ωn · 1 = Ωn · p(0).
Lemma 4 and assertion a) yield Dn(Ωn+1·(k+1)) = Dn(Ωn+1·k)+Dn(Ωn+1·k)+Ωn =
Ωn · p(k) + Ωn · p(k) + Ωn = Ωn · p(k+1).
c) Similarly to b).
d) By induction on k.
□
Lemma 23. D0 . . . Dn(Ωn+1 · k) = Ω0 · pn+1(k).
Proof. By induction on n. n = 0: By Lemma 9b, D0(Ω1 · k) = Ω0 · p(k). n ≥1:
D0 . . . Dn(Ωn+1 · k) = D0...Dn−1(Ωn · p(k))
IH= Ω0 · pn(p(k)) = Ω0 · pn+1(k).
□
Lemma 9 and Lemma 10 yield the following version of the hierarchy compari-
son theorem.
Corollary 24.
n ≥1 ⇒GD0...Dn(Ωn+1·k)(x) = x · pn+1(k) = FD0...Dn−1(Ωn·k)(x).
This calculation indicates the surprising fact that F remains rather modestly
growing in the current context and this will be veriﬁed in somewhat more detail.

A Nonstandard Hierarchy Comparison Theorem
87
Deﬁnition 25.
a) T(≥n) := {Ωl · jl + Ωl−1 · jl−1 + · · · + Ωn · jn : l ≥n}
b) T(≤n) := {Ωn · jn + Ωn−1 · jn−1 + · · · + Ω0 · j0 + r}
c) T(< ω) := {Ωl · jl + Ωl−1 · jl−1 + · · · + Ω0 · j0 + r : l ≥0}
Lemma 26.
a) α ∈T(≥n) ⇒(∃j)[Dnα = Ωn · j]
b) α ∈T(< ω) ⇒Dnα ∈T(≤n)
Assertion a) yields that the height of D0Ωω is ω2.
Finally we arrive at an independent proof of the main result of the last section.
Theorem 27.
α ∈T(≤1) ⇒GD0α(x) = FCx(α)(x).
Proof. Assume α = Ω1 · j + Ω0 · k + l.
Then GD0α(x) = GD0(Ω1· j)+Ω0·k+l(x) = GΩ0·(2 j+1−1)+Ω0·k+l(x) = x · (2j+1 −1 + k) + l.
Moreover FCx(α)(x) = FΩ0· j+x·k+l(x) = FΩ0·j(x) + x · k + l = x · (2j+1 −1 + k) + l.
□
Corollary 28.
GD0(D1(Ωn+1·k))(x) = FD0(Ωn·k)(x).
Proof. Note that the term D1(Ωn+1 · k) is not an oﬃcial member of T . But we have
D1(Ωn+1 · k) = Ω1 · j iﬀD0(Ωn · k) = Ω0 · j. The last theorem yields then the
assertion.
□
We close this section with a technical calculation of the value of Dkα. This
allows for rather precise estimates for calculating the values of the involved hierar-
chies.
Deﬁnition 29.
g() := 1, g(x0, ..., xm) = p′(g(x0, ..., xm−1)) + xm, where p′(n) := 2n −1.
Lemma 30.
k ≤m & xr > 0 & k ≤r
⇒
g(xm, ..., xr−1, g(xm, ..., xr−1, 0) + 1, 0i) =
g(xm, ..., xr, 0, 0i).
Proof. Proof by induction on i:
1. i = 0:
g(xm, ..., xr−1, g(xm, ...xr−1, 0) + 1)
=
p′(g(xm, ..., xr−1)) + g(xm, ...xr−1, 0) + 1
=
p′(g(xm, ..., xr−1)) + p′(g(xm, ...xr−1)) + 1
=
p′(g(xm, ..., xr−1) + 1)
=
p′(g(xm, ..., xr)) = g(xm, ..., xr, 0).

88
Wilfried Buchholz and Andreas Weiermann
2. Induction step: trivial.
□
A straightforward modiﬁcation of the proof for Lemma 4 shows the following
Lemma.
Lemma 31. If r > 0 then Dk(β + Ωk+r) = Dk(β + Dk+r−1(β + Ωk+r−1)).
This yields the following general description of the values of the collapsing
function on tree ordinals denoted by elements from T .
Theorem 32.
Dk(Ωm+k · jm + Ωm+k−1 · jm−1 + · · · + Ωk · j0) = Ωk · gm+1(jm, . . . , j0).
Proof. By induction on α = Ωm+k · jm + Ωm+k−1 · jm−1 + · · · + Ωk · j0.
If α = 0 then Dkα = Ωk = Ωk · gm+1(0, . . . , 0).
If α , 0 let r be minimal such that jr > 0.
Let β = Ωm+k · jm + Ωm+k−1 · jm−1 + · · · + Ωr+k · (jr −1).
If r = 0 then
Dkα
=
Dk(β + Ωk) = Dk(β) + Ωk
=
Ωk · (gm+1(jm, . . . , j0 −1) + 1)
=
Ωk · gm+1(jm, . . . , j0)
If r > 0 then
Dkα
=
Dk(β + Dk+r−1(β + Ωk+r−1))
=
Dk(β + Dk+r−1(β) + Ωk+r−1)
=
Dk(β + Ωk+r−1 · gm+2−r(jm, . . . , jr −1, 0) + Ωk+r−1)
=
Ωk · (gm+1(jm, . . . , jr −1, gm+2−r(jm, . . . , jr −1, 0) + 1, 0, . . . , 0)
=
Ω· gm+1(jm, . . . , jr, 0, . . . , 0).
□
Corollary 33.
a) GD0(Ωn+2·k)(x) ≥FD0(Ωn·k)(x).
b) The function x 7→FD0(Ωn·x)(x) is elementary recursive for every ﬁxed n < ω.
c) The function x 7→GD0Ωx(x) is not elementary recursive.
Remark. The results of the last two sections of this article show that it is
possible to match the slow and fast growing hierarchies at level ω2 which thence
might be considered as subrecursively inaccessible. To achieve this goal we used a
slow growing hierarchy which a posteriori turned out to be fast growing in the sense

A Nonstandard Hierarchy Comparison Theorem
89
that it matches up with the elementary functions at level ω2. But our underlying
choice of fundamental sequences is not artiﬁcial since we used a system of natural
fundamental sequences from the existing standard literature.
5
Another hierarchy comparison result
Let us consider the following variant ˆDm : Oω+1 →Om+1 of the collapsing func-
tions Dm.
1. ˆD00 := 1, ˆDk+10 := Ωk+1.
2. ˆDm(α+1) := ˆDm(α) + 1.
3. ˆDm((αξ)ξ∈On) := ( ˆDm(αξ))ξ∈On, if n ≤m.
4. ˆDm((αξ)ξ∈Ok+1) := ( ˆDm(αζi))i∈IN with ζ0 := 0, ζi+1 := ˆDkαζi, if m ≤k.
The signiﬁcance of this variant lies in the fact that ˆDm is so to speak the tree
analogue of the ordinal function πm in [4]. This means that, if π0πi1 . . . πil0 is an
ordinal term in the sense of [4], then | ˆD0 ˆDi1 . . . ˆDil0| = π0πi1 . . . πil0.
In [4], among others, the following result is proved
(1) If a = π0πi0 . . . πil0 is an ordinal term ≥ω, then ωa = π0πi0+1 . . . πil+10.
This can be sharpened to the following
Theorem 34. If α = ˆD0 ˆDi0 . . . ˆDil0 with i0 ≥1, then eωα = ˆD0 ˆDi0+1 . . . ˆDil+10,
where eωα ∈O1 for α ∈O1 is deﬁned by
eωα :=

1
if α ∈{0, 1}
(eωα0 · (i+1))i∈IN if α = α0+1 , 1
(eωαi)i∈IN
if α = (αi)i∈IN
.
On the other side one easily shows
Lemma 35.
For all α ∈O1 we have Geωα = ˆFα, where ˆFα : IN →IN is deﬁned by
ˆFα(x) :=

1
if α ∈{0, 1}
ˆFα0(x) · (x+1) if α = α0+1 , 1
ˆFαx(x)
if α = (αi)i∈IN
In the same way as in Section 4 we have derived Corollary 24 from Lemmata
22 and 23, we now obtain Corollary 36 from Theorem 34 and Lemma 35.
Corollary 36. G ˆD0Ωn+1 = ˆF ˆD0Ωn for n ≥1.

90
Wilfried Buchholz and Andreas Weiermann
References
[1] W. Buchholz: Three contributions to the conference on recent advances in
proof theory. Preprint, Oxford 1980.
[2] W. Buchholz:: Ordinal analysis of IDν. Lecture Notes in Mathematics 897.
234-260.
[3] W. Buchholz: An independence result for (Π1
1 −CA)+ BI. Annals of Pure and
Applied Logic 33 (1987), 131-155.
[4] K.Sch¨utte and S.G. Simpson: Ein in der reinen Zahlentheorie unbeweisbarer
Satz ¨uber endliche Folgen von nat¨urlichen Zahlen. Archiv f¨ur mathematische
Logik und Grundlagenforschung 25 (1985), pp. 75-89.
[5] H. Schwichtenberg. Eine Klassiﬁkation der ε0-rekursiven Funktionen. Z.
Math. Logik Grundlagen Math. 17 1971 61–74.
[6] H. Schwichtenberg, S.S. Wainer: Ordinal bounds for programs. Feasible
mathematics, II (Ithaca, NY, 1992), 387–406, Progr. Comput. Sci. Appl.
Logic, 13, Birkh¨auser Boston, Boston, MA, 1995.
[7] S.S. Wainer: Slow growing versus fast growing. The Journal of Symbolic
Logic 54 (2) (1989), 608-614.
[8] A. Weiermann and G. Wilken: Goodstein sequences for prominent ordinals
up the ordinal of (Π1
1 −CA)0. Preprint 2012. Submitted.

Conservativity of transitive closure over weak
constructive operational set theory
Andrea Cantini and Laura Crosilla∗
Dedicated to Prof. Helmut Schwichtenberg
Constructive set theory `a la Myhill–Aczel has been extended in [10, 11] to
incorporate a notion of (partial, non–extensional) operation. Constructive op-
erational set theory is a constructive and predicative analogue of Beeson’s
Inuitionistic set theory with rules and of Feferman’s Operational set theory
[4, 15, 16, 17, 18]. This paper is concerned with an extension of constructive
operational set theory [11] by a uniform operation of Transitive Closure, τ.
Given a set a, τ produces its transitive closure τa. We show that the theory
ESTE of [11] augmented by τ is still conservative over Peano Arithmetic.
1
Introduction
This article is a follow–up of [10, 11, 9], where we introduced a number of sys-
tems of constructive set theory with operations and studied their proof–theoretic
strength. Constructive Operational Set Theory is a constructive (thus generalised
predicative) theory of sets and operations which has similarities with Feferman’s
classical Operational Set Theory [15, 16, 17, 18] and Beeson’s impredicative Intu-
itionistic Set Theory with Rules [4]. It is an operational analogue of Constructive
Set Theory in the style of Myhill and Aczel [23, 1]. One motivation behind con-
structive operational set theory is to merge a constructive notion of set [23, 1, 3]
with some aspects which are typical of Explicit Mathematics [14]. In particular, one
has non–extensional operations (or rules) alongside extensional constructive sets.
Operations are in general partial and a limited form of self–application is permitted.
In [11] a fully explicit fragment, called ESTE, of operational set theory was singled
∗The research is supported by MIUR, under the national project Thinking and Computing, PRIN
2008 and within the frame of the University of Florence local research unit, sub–project Abstraction
and computation: logical and epistemological aspects. The second author is supported by EPSRC grant
EP/G029520/1.

92
Andrea Cantini and Laura Crosilla
out. This system is ﬁnitely axiomatized and was shown to be proof–theoretically
as strong as Peano Arithmetic, PA [11].
The aim of this note is to investigate an extension of elementary explicit con-
structive set theory ESTE [11] with an operator τ, which uniformly assigns to any
given set a its transitive closure, τa. Formally, we strengthen ESTE with the axiom
TC:
(∃z)(τa ≃z ∧Trans(z) ∧a ⊆z ∧(∀c)(Trans(c) ∧a ⊆c →z ⊆c))
where Trans(z) stands for (∀x)(∀y)(x ∈z ∧y ∈x →y ∈z).
We prove that the resulting extension ESTEt is still conservative over PA in the
sense that it has the same computational content as PA:
• for a closed application term f, if ESTEt proves that f : N →N, then f
deﬁnes a recursive function that is provably total in PA.
The result is achieved in two steps. First of all we consider an extension of Aczel
and Rathjen’s elementary constructive set theory ECST [3] with Myhill’s exponen-
tiation axiom and transitive closure. We recall that ECST is the fragment of con-
structive set theory CZF, which contains, besides extensionality, pairing, union and
strong inﬁnity, the schemata of bounded separation and full replacement. There-
fore, compared with full CZF, the ∈–induction and the subset collection schemata
are dropped and replacement is used instead of the strong collection schema. We
also recall that Myhill’s exponentiation axiom states that for any sets a and b the
collection of all functions from a to b is a set. We here also consider the following
axiom TRANS:
∀a∃b(a ⊆b ∧Trans(b)),
where Trans(b) is deﬁned as above.
We show that if ECST is enriched with the exponentiation axiom and TRANS
then the resulting system ECSTt is conservative over PA.
The proof of conservativity is carried out by interpreting the set theory in a
theory Tc of classical Frege structures with generalized induction principle GID,
similarly as in [10, 11]. This latter theory is conservative over PA [7, 8].
The ﬁrst step in the proof is the extension to ECSTt of the realizability inter-
pretation of [11], which is carried out within Tc and recalls in this context Aczel’s
type–theoretic interpretation of the constructive set theory CZF [1].
We wish to underline two aspects of this proof. First of all, we use the ﬁxed
point theorem of Tc to deﬁne a transitive closure operator underlying the interpre-
tation of the axiom TRANS. This interpretation is thus very much in the spirit of
the operational set theory we here introduce in the ﬁrst place.

Transitive Closure in Operational Set Theory
93
Secondly, the proof relies on the fact that the theory Tc is equipped with the
principle GID (Generalized Inductive Deﬁnitions). As a consequence a useful in-
duction principle is provable in the model construction VN (proposition 17). How-
ever, due to a separation, in the model, between natural numbers and sets, the VN-
-induction scheme of proposition 17 is acquired at no cost from a proof–theoretic
perspective (see also section 2.2).
In the second step of the proof we prove that ESTEt is conservative over ECSTt
by means of proof theoretic techniques (asymmetric interpretation, partial cut elim-
ination). Since the argument is a routine extension of the one given in [11], here it
will be only sketched.
We conclude this introduction by recalling that the status of transitive closure
in weak classical set theory has recently gained a considerable attention. The (quite
surprising) role of transitive closure for determining the relation between classical
set theory without inﬁnity and Peano Arithmetic has been investigated in [20]; see
also [21, 12]. Models of Zermelo set theory (with foundation) in which Transitive
Closure fails have been given for example in [5, 6, 22]. In [13] the authors study
Antifoundation and Transitive Closure on the basis of Zermelo set theory (without
foundation). We are not aware of speciﬁc studies on the proof theoretic strength of
transitive closure on the basis of weak constructive set theories.
For the reader’s convenience we ﬁrst brieﬂy recall the theories we shall be work-
ing in.
1.1
Elementary operational set theory
1.1.1
Language and conventions
The language of ESTE is the following applicative extension, LO, of the usual ﬁrst
order language of Zermelo–Fraenkel set theory, L.
The language includes the predicate symbols ∈and =. The logical symbols are
all the intuitionistic operators: ⊥, ∧, ∨, →, ∃, ∀. We have in addition:
• the combinators K and S;
• a ternary predicate symbol, App, for application; App(x, y, z) is read as x
applied to y yields z;
• el for the ground operation representing membership;
• pair , un , im , sep , exp , for set operations;
• ∅, ω, set constants;

94
Andrea Cantini and Laura Crosilla
For convenience we also use the bounded quantiﬁers ∃x ∈y and ∀x ∈y, as
abbreviations for ∃x (x ∈y ∧. . .) and ∀x (x ∈y →. . .).
As customary, we deﬁne ϕ ↔ψ by (ϕ →ψ) ∧(ψ →ϕ) and ¬ϕ by ϕ →⊥. We
also write a ⊆b for ∀z (z ∈a →z ∈b).
Terms and formulas. Terms and formulas are inductively deﬁned as usual.
To increase perspicuity, we consider a deﬁnitional extension of LO with appli-
cation terms, deﬁned inductively as follows.1
(i) Each variable and constant is an application term.
(ii) If t, s are application terms, then ts is an application term.
Application terms will be used in conjunction with the following abbreviations.
(i) t ≃x for t = x when t is a variable or constant.
(ii) ts ≃x for ∃y ∃z (t ≃y ∧s ≃z ∧App(y, z, x)).
(iii) t ↓for ∃x (t ≃x).
(iv) t ≃s for ∀x (t ≃x ↔s ≃x).
(v) ϕ(t, . . . ) for ∃x (t ≃x ∧ϕ(x, . . . )).
(vi) t1t2 . . . tn for (. . . (t1t2) . . . )tn.
To ease readability we sometimes use the notation t(x, y) for txy.
In the language LO, the notion of bounded formula needs to be appropriately
modiﬁed.
Deﬁnition 1 (Bounded formulas). A formula of LO is bounded, or ∆0, if and only
if all quantiﬁers occurring in it, if any, are bounded and in addition it does not
contain application App.
Classes are introduced similarly as in ordinary set theory: they are abbreviations
for abstracts {x : ϕ(x)}, for any formula ϕ of the language LO. In particular, we
let V
:=
{x : x ↓}. For A and B sets or classes, we write f : A →B for
∀x ∈A (f x ∈B) and f : V →B for ∀x (f x ∈B). By f : A2 →B and f : V2 →B
we indicate ∀x ∈A ∀y ∈A (f xy ∈B) and ∀x ∀y (f xy ∈B), respectively. This can
be clearly extended to arbitrary exponents n > 2. Finally, for set a, f : a →V
means that f is everywhere deﬁned on a.
1 The use of application terms goes back to Feferman[14].

Transitive Closure in Operational Set Theory
95
Truth values. We may represent false and truth by the empty set and the sin-
gleton empty set, respectively; that is, we let ⊥:= ∅and ⊤:= {∅} := pair ∅∅.
Let Ωbe the class P⊤:= {x : x ⊆⊤}. The class Ωintuitively represents the
class of truth values (or of propositions). Note that in the presence of exponentia-
tion, if Ωis taken to be a set, then full powerset follows (see Aczel [1], Proposition
2.3).
Relations and set–theoretic functions. The notions of relation between two
sets, of domain and range of a relation can be deﬁned in the obvious way in ESTE.
In the following we write Dom(R) and Ran(R) to denote the domain and the range
of a relation, respectively2.
We also have a standard notion of set–theoretic function which we can express
by a formula, Fun(F), stating that F is a set encoding a total binary relation which
satisﬁes the obvious uniqueness condition. We shall use upper case letters F,G, . . .
for set–theoretic functions and lower case letters f, g, . . . for operations (that is
if they formally occur as operators in application terms or as ﬁrst coordinates in
App–contexts). In [10, 11] we have investigated the relation between the notions
of operation and set–theoretic functions.
Finally, in deﬁning the axiom of inﬁnity we shall make use of the following
successor operation.
Deﬁnition 2. Let Suc := λx.un (pair x(pair xx)).
1.1.2
Axioms of ESTE
Deﬁnition 3. ESTE is the LO theory whose principles are all the axioms and rules
of ﬁrst order intuitionistic logic with equality, plus the following principles.
Extensionality
• ∀x (x ∈a ↔x ∈b) →a = b
General applicative axioms
• App(x, y, z) ∧App(x, y, w) →z = w
• Kxy = x ∧Sxy↓∧Sxyz ≃xz(yz)
2In [11] we have shown that in ESTE there is an operator opair internally representing the or-
dered pair of two sets. In addition, also the range and the domain of a relation correspond to internal
operations, respectively.

96
Andrea Cantini and Laura Crosilla
Membership operation
• el : V2 →Ωand el xy ≃⊤↔x ∈y
Set constructors
• ∀x (x < ∅)
• pair xy ↓∧∀z (z ∈pair xy ↔z = x ∨z = y)
• un a ↓∧∀z (z ∈un a ↔∃y ∈a(z ∈y))
• (f : a →Ω) →sep fa ↓∧∀x (x ∈sep fa ↔x ∈a ∧f x ≃⊤)
• (f : a →V) →im fa ↓∧∀x (x ∈im fa ↔∃y ∈a(x ≃fy))
Strong inﬁnity
• (ω1)
∅∈ω ∧∀y ∈ω (Suc y ∈ω)
• (ω2)
∀x (∅∈x ∧∀y(y ∈x →Suc y ∈x) →ω ⊆x)
Exponentiation
exp ab ↓∧∀x(x ∈exp ab ↔(Fun(x) ∧Dom(x) = a ∧Ran(x) ⊆b)).
Remark. The principles ruling sep and im embody the explicit character of the
separation and replacement schemata in the present operational context: sep pro-
vides – uniformly in any given f : a →Ω– the set of all elements satisfying the
“propositional function” deﬁned by f; on the other hand, im yields – uniformly in
any given operation f deﬁned on a set a – the image of a under f.
Deﬁnition 4 (The theory ESTEt). The theory ESTEt is obtained from ESTE by
adding a new constant τ to the language together with the axiom TC:
(τa↓∧Trans(τa) ∧a ⊆τa ∧(∀c)(Trans(c) ∧a ⊆c →τa ⊆c))
where Trans(z) stands for (∀x)(∀y)(x ∈z ∧y ∈x →y ∈z).
1.1.3
Elementary Constructive Set Theory
In [3] the authors introduce a subsystem of CZF called ECST (for Elementary
Constructive Set Theory). Such a system is intended to be somehow minimal. On
the one hand, Aczel and Rathjen show that many standard set–theoretic construc-
tions may be carried out already in this fragment of constructive set theory. On the

Transitive Closure in Operational Set Theory
97
other hand, ECST is very weak as for example it does not prove the existence of
the addition function on ω [24].
We shall here be interested in a strengthening of ECST by addition of exponen-
tiation, as such a theory is of the same proof–theoretic strength as Peano Arithmetic.
The language of ECST is the same language as that of Zermelo–Fraenkel set
theory. In this context, the notion of ∆0 formula is the standard one, that is, a
formula is ∆0 or bounded if no unbounded quantiﬁer occurs in it.
Deﬁnition 5. The theory ECST includes the principles of ﬁrst order intuitionistic
logic plus the following set–theoretic principles.
1. Extensionality;
2. Pair;
3. Union;
4. ∆0–Separation (that is separation restricted to ∆0 formulas only);
5. Replacement: for arbitrary ϕ,
∀x ∈a∃!yϕ(x, y) →∃b∀y(y ∈b ↔∃x ∈aϕ(x, y));
6. Strong Inﬁnity:
∃a [Ind(a) ∧∀z (Ind(z) →a ⊆z)],
where we use the following abbreviations:
• Empty(y) for (∀z ∈y) ⊥;3
• S uc(x, y) for ∀z [z ∈y ↔z ∈x ∨z = x];
• Ind(a) for (∃y ∈a)Empty(y) ∧(∀x ∈a)(∃y ∈a)S uc(x, y).
We write ω also for the set deﬁned by strong inﬁnity (which is unique by ex-
tensionality).
Note that ECST diﬀers from the better known system CZF in that it only has
Replacement in place of Strong Collection and it omits both Subset Collection and
∈–Induction.
Let Exponentiation be the axiom:
∀a, b ∃c ∀z (z ∈c ↔(Fun(z) ∧Dom(z) = a ∧Ran(z) ⊆b)),
where as usual Fun(z) is a bounded formula expressing the fact that z is a set–
theoretic function, Dom(z) and Ran(z) are the domain and range of z, respectively.
3⊥stands for the absurd sentence and should be distinguished from ⊥, as used above for the empty
set, or the minimum truth value.

98
Andrea Cantini and Laura Crosilla
Deﬁnition 6. The theory ECSTt is obtained from ECST by adding the axiom of
exponentiation and the axiom TRANS:
∀a∃b(a ⊆b ∧Trans(b)).
2
Constructing the model
The proof–theoretic strength of ECSTt is determined by a realisability interpreta-
tion into a classical axiomatic theory of abstract self–referential truth, Tc. This is
conservative over PA [7, 8]. First of all let us recall the theory Tc.
2.1
The theory Tc
The basic ﬁrst order language LT of Tc comprises the predicate symbols =, T , N,
the binary function symbol ap (application), combinators K, S , successor, prede-
cessor, deﬁnition by cases on numbers, pairing with projections. Terms are induc-
tively generated from variables and individual constants via application. As usual
ts := ap(t, s); missing brackets are restored by associating to the left. Formulas
are inductively generated from atoms of the form t = s, T (t), N(t) by means of
sentential operations and quantiﬁers. We adopt the following conventions:
(i) By [ϕ] we denote a term representing the propositional function associated
with ϕ and such that FV([ϕ]) = FV(ϕ). We ﬁx distinct closed terms ˆ∀, ˆ∃, ˆ¬, ˆ∧,
. . . , naming the logical constants. In addition, ˆ=, ˆN name the equality and the
number predicates, respectively. Then [ϕ] is inductively deﬁned by stipulating
[t = s] = ( ˆ= ts), [N(s)] = ˆNs, [T (s)] = s and closing under application of
the “small hat” operations, noting that [∀xϕ] = ˆ∀(λx[ϕ]), [∃xϕ] = ˆ∃(λx[ϕ]).
(ii) Given a formula ϕ we deﬁne abstraction by letting {x : ϕ} := λx.[ϕ].
(iii) We deﬁne intensional membership, η , as follows:
x η a := T (ax);
x ¯η a := T ( ˆ¬(ax)).
(iv) The notion of class (or classiﬁcation) is so speciﬁed4:
Cl(a) := ∀x (x η a ∨x ¯η a).
4A warning: here ‘class’ is understood in the (non–extensional) sense of the theory of Frege struc-
tures [2, 8].

Transitive Closure in Operational Set Theory
99
(v) A formula ϕ is T –positive iﬀϕ is inductively generated from prime formulas
of the form T (t), t = s, ¬t = s, N(t), ¬N(t) by means of ∨, ∧, ∀, ∃.
(vi) A formula ϕ is T –positive operative in v (in short, T –positive or a positive
operator) iﬀϕ belongs to the smallest class of formulas inductively generated
from prime formulas of the form T (t), s η v, t = s, ¬t = s, N(t), ¬N(t) by
means of ∨, ∧, ∀y, ∃y, where y is distinct from v and v does not occur in t, s.
(vii) For each formula ϕ, ﬁxed points are deﬁned by letting:
I(ϕ) := Y(λv.{x : ϕ(x, v)})
where Y is Curry’s ﬁxed point combinator.
The system Tc comprises the following principles, besides classical predicate
calculus with equality.
1. The base theory TON−(see e. g. [19]), which formalises the notion of total
extensional combinatory algebra expanded with natural numbers. This in-
cludes the obvious axioms on combinators, pairing, projections. In addition,
closure axioms for the predicate N deﬁning a copy of the natural numbers,
together with number theoretic conditions on the basic operations of succes-
sor S UC, predecessor PRED, 0, deﬁnition by cases on the natural numbers.
2. A ﬁxed point axiom (Tr) for abstract truth
Tr(x, T ) ↔T (x).
Here Tr(x, T ) is a formula encoding the following inference rules:
a = b
T [a = b]
¬(a = b)
T [¬(a = b)]
N(a)
T [N(a)]
¬N(a)
T [¬N(a)]
for the basic atomic formulas with = and N. Further, the following additional
clauses for the compound formulas:
T (a)
T ( ˆ¬ ˆ¬a)
T a
T b
T (a ˆ∧b)
T ( ˆ¬a) [ or T ( ˆ¬b)]
T ( ˆ¬(a ˆ∧b))
∀x T (ax)
T (ˆ∀a)
∃x T ( ˆ¬ax)
T ( ˆ¬ˆ∀a)

100
Andrea Cantini and Laura Crosilla
Formally Tr(x, T ) is spelled out by the formula:
∃u∃v∃w
[
(x = [u = v] ∧u = v) ∨
∨
(x = [¬u = v] ∧¬u = v) ∨
∨
(x = [Nv] ∧N(v)) ∨
∨
(x = [¬N(v)] ∧¬Nv) ∨
∨
(x = ˆ¬ ˆ¬v ∧T v) ∨
∨
(x = v ˆ∧w ∧T v ∧T w) ∨
∨
(x = ˆ¬(v ˆ∧w) ∧(T ( ˆ¬v) ∨T ( ˆ¬w))) ∨
∨
(x = ˆ∀v ∧∀z(T (vz))) ∨
∨
(x = ˆ¬ˆ∀v ∧∃z(T ( ˆ¬vz)))]
3. Consistency axiom: ¬(T x ∧T ˆ¬x).
4. Induction on natural numbers Cl −INDN for classes:
Cl(a) ∧ClosN(a) →∀x(N(x) →x η a)
with ClosN(a) := 0ηa ∧∀x (xηa →(S UCx)ηa).
5. The principle GID, ensuring the minimality of the ﬁxed points: if ϕ(x, v) is a
positive operator
Closϕ(ψ) →∀x (xηI(ϕ) →ψ(x))
with Closϕ(ψ) := ∀x (ϕ(x, ψ) →ψ(x)).5
T−is the theory Tc without number theoretic induction.
Let CL be {x : Cl(x)} (which is provably not a class). Then we can show that CL
has natural closure conditions which are essential for the interpretation of ECSTt.
That is, in T−, CL is closed under elementary comprehension, generalized disjoint
union, generalized disjoint product. It satisﬁes a form of positive comprehension:
if ϕ is T –positive, then T [ϕ] ↔ϕ and ∀x (xη{u : ϕ} ↔ϕ[u := x]). Also a version
of the second recursion theorem holds: if ϕ is positive then
∀x (xηI(ϕ) ↔ϕ(x, I(ϕ))).
For the proofs, see [8], II.9B, II.10A.
5Here ϕ(x, ψ) is the formula obtained by replacing each occurrence of the formula t η v in ϕ(x, v) by
means of ψ(t).

Transitive Closure in Operational Set Theory
101
Theorem 7. Tc is proof–theoretically equivalent to PA.
Proof. See [10], Theorem 7.3, or [7].
□
2.2
Tc and the natural numbers
We wish to remark that the principle GID ensures the minimality of the ﬁxed points
that are expressible in the language of Tc. We also underline that Tc includes
induction on natural numbers for classes only.
In the following, let N be the class {x : N(x)}. Clearly, in Tc there are a priori
two distinct notions of natural numbers: on the one hand, there is the class N on
which one can argue by induction only relative to classes; on the other hand by
ﬁxed point one can ﬁnd IN such that
ClosN(ψ) →∀x (xηIN →ψ(x)),
where ClosN(ψ) is the formula ψ(0) ∧∀x(ψ(x) →ψ(S UC(x))). Clearly by GID
one can show that IN ⊆N, but we are not allowed to argue conversely (as there
are models where indeed IN is strictly contained in N and hence N contains non–
standard natural numbers). The main trick in the deﬁnition of the set–theoretic
universe VN below amounts to embed non–standard numbers in it so that they
form a set and satisfy the strong induction axiom, but not the full mathematical
induction schema.
In the following we shall work informally in the theory Tc.
Let (x, y) denote the basic pairing operation which is built–in the axioms of Tc;
(x, y, z) stands for (x, (y, z)), and, if u = (x, y, z), u0 = x, u1 = y and u2 = z. Recall
that N is the class {x : N(x)}; for k ∈N let
Nk := {m : m η N ∧m <N k},
where <N represents the ordering relation on N (deﬁned in the obvious way).
Henceforth, we simply write < instead of <N. Note that Nk is a class for every
k η N.
Lemma 8.
If m η N and k η N then Nm = Nk ↔m = k.
Proof. Obvious from right to left. Conversely, if m , k, we can prove in Tc that
either m < k or k < m; clearly induction on classes suﬃces. To be deﬁnite, assume
m < k. Then mηNk. In Tc we can prove: ¬m < m, and therefore ¬m η Nm. Were
Nk = Nm, then mηNm: contradiction.
□

102
Andrea Cantini and Laura Crosilla
Let F = λgλx(1, x, g). By the ﬁxed point theorem of lambda calculus which
is provable in TON−, there exists a solution ν to the equation Fν = ν and hence ν
satisﬁes:
νx = (1, x, ν).
The idea is that (1, k, ν) is a code in the universe VN of the set listed by ν, when ν
ranges over the ﬁnite class Nk = {0, . . . , k−1}. Thus νk represents the von Neumann
ordinal associated to the number k, since ν0 represents the empty set, ν1 represents
{ν0}, ν2 represents {ν0, ν1}, and so on. This trick is adapted from Rathjen [24].
The universe of sets VN is inductively deﬁned as the least predicate closed
under the two clauses below. The ﬁrst one ensures that initial ﬁnite segments of
natural numbers are represented in VN; the second one introduces arbitrary sets
listed by operations deﬁned on classes with values in VN:
k η N
(1, k, ν) η VN
Cl(a)
∀u η a (fu η VN)
(2, a, f) η VN
Proposition 9. There exists a closed term VN such that
(i)
a η VN ↔∃n η N (a = (1, n, ν))
∨(a = (2, a1, f) ∧Cl(a1) ∧∀u η a1 (( a2u) η VN));
(ii) ∀x(V(x, ϕ) →ϕ(x)) →∀x (xηVN →ϕ(x)),
where ϕ is an arbitrary formula and V(x, ϕ) is an abbreviation for
∃n η N (x = (1, n, ν)) ∨
∨(x = (2, x1, x2) ∧Cl(x1) ∧(∀u η x1)(ϕ( x2u))).
Proof. See [10], Proposition 8.1. Observe that (ii) is an application of GID.
□
Remark. Note that, as Ni is a class for each i η N, and νi = (1, i, ν), we have
(1, i, ν) η VN ↔Cl(Ni) ∧∀k η Ni(νk η VN) ↔(2, Ni, ν) η VN.
(9)
Below we adopt the more perspicuous notation
sup(a, f) := (2, a, f);

Transitive Closure in Operational Set Theory
103
hence by (9) we can restate proposition 9 (i) in the simpler form:
a η VN ↔a = sup(a1, a2) ∧Cl(a1) ∧∀u η a1 (( a2u) η VN).
In the following, applications of proposition 9 (ii) will be simply referred to as
proofs by induction on VN.
Proposition 10. There are operations assigning ¯a and ˜a to each a η VN and such
that Cl(¯a) and ˜a : ¯a →VN (that is ∀xη¯a (˜axηVN)).
Proof. By induction on VN, using the recursion theorem.
□
If a ∈VN, let
Nat(a) := ∃k(k η N ∧a = sup(Nk, ν)).
We next deﬁne recursively an equivalence relation, , on VN.
Lemma 11. There exists a term  such that
a  b ↔a η VN ∧b η VN ∧[∃k(k η N ∧Nk = ¯a = ¯b ∧˜a = ˜b = ν)∨
∨(¬(Nat(a) ∧Nat(b)) ∧∀x η ¯a ∃y η ¯b (˜ax  ˜by) ∧∀y η ¯b ∃x η ¯a (˜ax  ˜by))].
Proof. Apply the recursion theorem for predicates [8], p.63.
□
Lemma 12. For a, b, c η VN the following holds
(i) a  a
(ii) a  b →b  a
(iii) a  b ∧b  c →a  c.
Proof. By induction on VN.
□
Lemma 13. For any a, b η VN the following holds:
a  b ↔∀x η ¯a∃y η ¯b(˜ax  ˜by) ∧∀y η ¯b∃x η ¯a(˜ax  ˜by).
Proof. We need to show that the claim holds in the case Nat(a) and Nat(b). Thus
assume that, say, a = sup(Nk, ν) and b = sup(Nm, ν). Clearly the implication from
left to right holds. Suppose now that
∀i η ¯a∃j η ¯b(˜ai  ˜bj) ∧∀j η ¯b∃i η ¯a(˜ai  ˜bj),

104
Andrea Cantini and Laura Crosilla
that is
∀i η Nk∃j η Nm(νi  ν j) ∧∀j η Nm∃i η Nk(νi  ν j).
By deﬁnition of νi and Lemmata 11 and 8,
∀i < k∃j < m(i = j) ∧∀j < m∃i < k(i = j).
Therefore k = m and the claim is proved.
□
Deﬁnition 14. Let a, b ηVN:
a˙∈b := ∃x η ¯b (a  ˜bx).
The interpretation proceeds similarly as in [10], section 8. We here present only
the most relevant steps of the interpretation.
Lemma 15 (Extensionality). Let a, b η VN.
∀x η VN (x˙∈a ↔x˙∈b) →a  b.
Proof. Suppose z η ¯a. Then ˜az η VN and ˜az˙∈a, so that by hypothesis, also ˜az˙∈b.
Then there exists a y such that y η ¯b and ˜az  ˜by. Similarly one proves the other
conjunct in the deﬁnition of a  b.
□
Lemma 16. For a, b η VN,
T [a  b] ∨T [¬a  b];
T [a˙∈b] ∨T [¬a˙∈b].
Proof. See [10], Lemma 8.12.
□
Let D be distinction by cases, satisfying the following axiom, for n, m in N:
Duvnm =
( ⊤,
if n = m;
⊥,
if n , m.
Below we shall make use of the following conventions.
{a, b}V
=
sup(2, λz.Dabz0)
˙[
a
=
sup(e(a), λz.(f
˜az0)z1)
a ˙∪b
=
˙[
{a, b}V

Transitive Closure in Operational Set Theory
105
where 2 := {x : N(x) ∧(x = 0 ∨x = 1)} and
e(a) := {z|z = (z0, z1) ∧z0 η ¯a ∧z1 η ˜az0}.
As to its intuitive meaning, e(a) roughly represents the domain of the operation
listing the elements of ˙Sa, that is ˙Sa. More closely, look at any pair (z0, z1) of
e(a). This collects the following instructions: (i) compute the element ˜az0 of the
family a indexed by z0; (ii) choose in ˜az0 exactly the element indexed by z1, i.e.
compute f
˜az0 applied to z1.
Note that if a, b η VN, then {a, b}V and ˙Sa are witnesses in VN of the axioms
of pair and union, respectively, while a ˙∪b represents the binary union of a and b in
VN.
Recall that Tc only allows for class induction on the natural numbers, Cl −
INDN. A natural extension of Tc is obtained by allowing induction on the natural
numbers for arbitrary formulas, that is the principle INDN:
ClosN(ψ) →∀x(N(x) →ψ(x)),
with ClosN(ψ) := ψ(0) ∧∀x (N(x) →(ψ(x) →ψ(S UCx))). In [10] the extension
of Tc by adding full induction on the natural numbers was termed Tf. We recall that
this theory has the same proof–theoretic strength as the theory ID1 of one inductive
deﬁnition (and thus is also proof–theoretically equivalent to the system CZF) [10,
Theorem7.3].
Proposition 17 (provably in Tc).
(i) The structure ⟨VN, , ˙∈⟩is a model of the
theory ECSTt without replacement and exponentiation, plus the following
VN–induction schema:
∀iηN.ϕ(sup(Ni, ν)) ∧Progr(˙∈, ϕ) →∀xηVN.ϕ(x),
where Progr(˙∈, ϕ) is an abbreviation for
∀xηVN(∀y˙∈x.ϕ(y) →ϕ(x)).
(ii) If the ground theory is strengthened to include full induction on the natural
numbers, INDN, then it proves
Progr(˙∈, ϕ) →∀xηVN.ϕ(x).
(10)
Proof. As to (i), see Proposition 8.15 of [10]. The main diﬀerence with that propo-
sition concerns strong inﬁnity, for which we follow closely [11, Proposition 5.14].
Deﬁne ˆω := sup(N, j) where, for m η N:
j(m) = sup(Nm, ν).
We need to show that:

106
Andrea Cantini and Laura Crosilla
1. ˆω η VN and ˆω is inductive (i.e. ˆω contains the empty set and is closed under
the set–theoretic successor, as deﬁned within VN);
2. if a η VN and a is inductive, then ˆω ˙⊆a (i. e. ∀x(x˙∈ˆω →x˙∈a)).
The ﬁrst half of the ﬁrst claim is obvious by construction. The second half requires
class induction. As to the second claim, we assume that a is inductive and by class
induction, using Lemma 16, we show that
(∀i η N)(∃v η ¯a)(˜av  ji = sup(Ni, ν)).
If i = 0, we are done by assumption on a. Let i = S UCm and assume by IH
that for some v η ¯a, ˜av  sup(Nm, ν). For c η VN, let’s write (c ˙∪{c}V) also for
the interpretation of the successor in VN. Now ˜av˙∈a; by deﬁnition of inductive
set, we also know that (˜av ˙∪{˜av}V)˙∈a and hence, for some w η ¯a, ˜aw˙∈a and ˜aw 
(˜av ˙∪{˜av}V). Then also (jm ˙∪{jm}V)˙∈a. Since we can easily verify that
(jm ˙∪{jm}V)  j(S UCm)
we have the expected conclusion j(S UCm)  ˜ai.
As to (ii), we now show that VN makes the full schema (10) of set induction
true. For this purpose, we assume
∀xηVN(∀y˙∈x.ϕ(y) →ϕ(x))
(11)
and we check:
∀aηVN.ϕ(a).
(12)
Now (12) is veriﬁed by induction on VN. It is then enough to prove
∀iηN.ϕ(sup(Ni, ν))
(13)
Cl(a) ∧∀uηa.ϕ(fu) →ϕ(sup(a, f)).
(14)
(14) easily follows by (11).
As to (13) we apply full induction on the natural numbers and we verify the
stronger statement:
∀iηN.(∀m ≤i.ϕ(νm))
Therefore it suﬃces to prove:
(i) ϕ(sup(N0, ν));
(ii) for iηN, if ∀m ≤i.ϕ(νm), then ∀m ≤S UC(i).ϕ(νm).

Transitive Closure in Operational Set Theory
107
As to (i), we apply deﬁnition of ν and (11) since ∀y˙∈ν0.ϕ(y) trivially holds. As to
the second item, assume
∀m ≤i.ϕ(νm)
(15)
Then ∀m < S UC(i).ϕ(νm). Now observe that
∀y˙∈ν(S UC(i)).ϕ(y)
Indeed, if y˙∈ν(S UC(i)), there is j ≤i such that y  ν j, and by (15) ϕ(ν j), i.e.
ϕ(y)(since ϕ is extensional modulo ). Then by (11), ϕ(ν(S UC(i))), as desired.
□
2.3
Adding transitive closure
Transitive closure can be introduced by the ﬁxed point theorem and deﬁnition by
cases on N, distinguishing the case of the natural numbers from that of other sets.
Lemma 18. There exists an operation τ such that
τa =
( a,
provided a0 = 1;
a ˙∪˙S sup(¯a, λy.τ(˜ay)),
provided a0 = 2.
Lemma 19 (provably in Tc).
∀aηVN. (τa)ηVN ∧Trans(τa) ∧a ˙⊆τa
(16)
Proof. Let
ψ(a) := (τa)ηVN ∧Trans(τa) ∧a ˙⊆τa
As to (16), by deﬁnition of τ and proposition 9, it is enough to verify:
∀iηN. ψ(νi)
(17)
Cl(a) ∧∀yηa(ψ( fy) →ψ(sup(a, f))).
(18)
Ad (17): since τ(1, i, ν) = (1, i, ν), it is enough to check that νi is transitive. In fact,
by Lemma 16, we can apply Cl −INDN to the class {iηN | Trans(νi)}, and obtain
the claim. Transitivity of νi easily follows from the deﬁnitions.
Ad (18). Assume the antecedent of (18) and let
u˙∈v˙∈τ(sup(a, f))
Now recall that:
τ(sup(a, f))
=
sup(a, f) ˙∪˙[
sup(sup(a, f), λy.τ(
]
sup(a, f)y))
=
sup(a, f) ˙∪˙[
sup(a, λy.τ(fy))

108
Andrea Cantini and Laura Crosilla
There are two cases. If v˙∈sup(a, f), then, for some xηa, v  f x. By assumption,
f x ˙⊆τ(f x), whence u˙∈τ( f x), for some xηa, i.e. u˙∈˙S sup(a, λy.τ(fy)).
Else, v˙∈˙S sup(a, λy.τ(fy)), i.e. v˙∈c, for some c, zηa such that c  τ(fz).
Hence u˙∈v˙∈τ(fz), for some zηa.
By assumption, τ(fz) is transitive, whence
u˙∈τ(fz), some zηa, which implies u˙∈˙S sup(a, λy.τ(fy)). Therefore in any case
u˙∈˙S sup(a, λy.τ(fy)), so that u˙∈τ(sup(a, f)).
□
3
Realizability
In order to give an interpretation of the theory ECSTt (including replacement and
exponentiation), we can deﬁne a suitable notion of realisability in the theory Tc.
First of all, if ϕ is a bounded formula of ECSTt, we inductively deﬁne a map ϕ 7→
∥ϕ∥, where (roughly) ∥ϕ∥collects the proof objects for ϕ, provided the parameters
range over VN.
Let ⊤denote the class which only has the empty class as element, while
a ⊕b := {u : u = (u0, u1) ∧((u0 = 0 ∧u1 η a) ∨(u0 = 1 ∧u1 η b))} represents the
disjoint union of a, b.
Deﬁnition 20.
∥⊥∥
=
{e η ⊤: 0 = 1};
∥a = b∥
=
{e : e = 0 ∧∃k(k η N ∧Nk = ¯a = ¯b ∧˜a = ˜b = ν)}
⊕{e : e = (e0, e1) ∧¬(Nat(a) ∧Nat(b))
∧∀x η ¯a (e0x)0 η ¯b ∧(e0x)1 η ∥˜ax = ˜b(e0x)0∥
∧∀y η ¯b (e1y)0 η ¯a ∧(e1y)1 η ∥˜a(e1y)0 = ˜by∥};
∥a ∈b∥
=
{e : e = (e0, e1) ∧e0 η ¯b ∧e1 η ∥a = ˜be0∥};
∥ϕ ∧ψ∥
=
{e : e = (e0, e1) ∧e0 η ∥ϕ∥∧e1 η ∥ψ∥};
∥ϕ ∨ψ∥
=
∥ϕ∥⊕∥ψ∥;
∥ϕ →ψ∥
=
{e : ∀q η ∥ϕ∥(eq η ∥ψ∥)};
∥∃u ∈a ϕ(u)∥
=
{e : e = (e0, e1) ∧e0 η ¯a ∧e1 η ∥ϕ(˜ae0)∥};
∥∀u ∈a ϕ(u)∥
=
{e : ∀x η ¯a (ex η ∥ϕ(˜ax)∥)}.
Formally speaking, the deﬁnition of ∥ϕ∥above makes sense only after showing by
a ﬁxed point argument that there exists an operation H(a, b) satisfying the equa-
tion for ∥a = b∥(hence the deﬁnition inductively extends H to arbitrary bounded
conditions).
Deﬁnition 21. Let ϕ be an arbitrary formula of ECSTt; we inductively deﬁne a
formula e ⊩ϕ of Tc with the same free variables as ϕ and a fresh variable e:

Transitive Closure in Operational Set Theory
109
1. if ϕ is a bounded formula of ECSTt, then
e ⊩ϕ iﬀe η ∥ϕ∥;
2. else:
e ⊩ϕ →ψ iﬀ∀f(f ⊩ϕ →ef ⊩ψ) ;
e ⊩ϕ ∧ψ iﬀe = (e0, e1) ∧e0 ⊩ϕ ∧e1 ⊩ψ ;
e ⊩ϕ ∨ψ iﬀ(e = (0, e1) ∧e1 ⊩ϕ) ∨(e = (1, e1) ∧e1 ⊩ψ) ;
e ⊩∀u ∈a ϕ(u) iﬀ∀x η ¯a (ex ⊩ϕ(˜ax)) ;
e ⊩∃u ∈a ϕ(u) iﬀe = (e0, e1) ∧e0 η ¯a ∧e1 ⊩ϕ(˜ae0) ;
e ⊩∃u ϕ iﬀe = (e0, e1) ∧e0 η VN ∧e1 ⊩ϕ(e0) ;
e ⊩∀u ϕ iﬀ∀u η VN (eu ⊩ϕ(u)) .
Lemma 22. Let ϕ be a bounded formula of ECSTt. Then Tc proves
⃗x ∈VN →Cl(∥ϕ(⃗x)∥).
(19)
Proof. By induction on the complexity of the formula ϕ. The atomic case a = b
is proved by VN induction. The other cases use the fact that classes are closed
under elementary comprehension, generalized disjoint union, generalized disjoint
product.
□
3.1
Realizability: preparatory computations
In this subsection we assume that a η VN with a0 = 2 (that is we look at the transi-
tive closure for non–natural numbers) and perform some preparatory computations.
Recall that if a0 = 2, then
τa = a ˙∪˙[
sup(¯a, λy.τ(˜ay)).
We obtain:
τa
=
˙[
{a, ˙[
sup(¯a, λy.τ(˜ay))}V
(20)
=
˙[
sup(2, λz.Da( ˙[
sup(¯a, λy.τ(˜ay)))z0) ≡˙[
M(a)
(21)
=
sup(e(M(a)), λz. ]
]
M(a)z0z1)
(22)
Now observe that

110
Andrea Cantini and Laura Crosilla
M(a)
=
2
]
M(a)
=
λz.Da( ˙[
sup(¯a, λy.τ(˜ay)))z0
hence
]
M(a)0
=
a
]
M(a)1
=
˙[
sup(¯a, λy.τ(˜ay)
Lemma 23 (provably in Tc).
τa
=
¯a ⊕{(u0, u1) | u0η¯a ∧u1ητ(˜au0)}
e
τa
=
λz. ]
]
M(a)z0z1
Proof. The second equation follows by deﬁnition of τa and (22) above. We then
complete the computation:
τa
=
e(M(a))
=
{(u0, u1) | u0η2 ∧u1ητ(˜au0)}
=
{(0, u1) | u1η]
M(a)0} ∪{(1, u1) | u1η]
M(a)1}
=
{(0, u1) | u1η¯a} ∪{(1, u1) | u1η ˙[
sup(¯a, λy.τ(˜ay))}
=
¯a ⊕{(u0, u1) | u0η¯a ∧u1ητ(˜au0)}.
□
Remark. Let x˙∈τa: then
∃u(uητa ∧x  e
τau)
If uητa, then by Lemma 23, u is of the form (u0, u1) and there are two cases to take
into account: u0 = 0 or u0 = 1.
Case 1. u0 = 0. Then u1η¯a and x  ˜au1 and hence
x˙∈a.
Case 2. u0 = 1. Then u1 = (v0, v1), v0η¯a and v1ητ(˜av0). Hence x  ]
τ(˜av0)v1. But
this witnesses
∃c˙∈a. x˙∈τc.

Transitive Closure in Operational Set Theory
111
3.2
Realizability: Soundness Theorem
Lemma 24. There are operators F, G such that, provably in Tc, for every a, b ∈
VN:
(i) G(a) ⊩a ⊆τa;
(ii) F(a) ⊩Trans(τa)
Proof. Essentially this holds because the proof of Lemma 19 is constructive.
(i) Let us consider the ﬁrst property. We have to show that, for some G(a), G(a)
realizes a ⊆τa. That is, we must check that some G(a) inhabits
∥∀u ∈a.u ∈τa∥.
Writing e for G(a), this is:
∀iη¯a((ei)0ητa ∧(ei)1η∥˜ai = e
τa(ei)0∥).
In case a0 = 2, for i ∈¯a (by Lemma 23) we can take (ei)0 = (0, i), and
(ei)1 ∈∥˜ai = e
τa(0, i)∥. But (again by Lemma 23):
e
τa(0, i) = (λz. ]
]
M(a)z0z1)(0, i) = ˜ai.
Thus we can take e such that for every iη¯a, ei = ((0, i), f˜ai), where f˜ai is a
realizer of the identity: ˜ai = ˜ai.
In case a0 = 1, for every iη¯a, ei = (i, f˜ai) veriﬁes the inclusion.
(ii) As to the second property, we show:
Sublemma. Assume that
1. there exists an operation J, such that, for every i η N,
J(i) η ∥Trans(τ(ν(i)))∥
2. there exists an operation K, such that, whenever
Cl(a) ∧∀x η a.hx η ∥Trans(τ(f x))∥,
then
K(h, a, f) η ∥Trans(τ(sup(a, f))∥.
Then there exists F such that
∀a η VN.F(a) η ∥Trans(τ(a))∥
Veriﬁcation of (ii). Using deﬁnition by cases on N, there exists an operation Φ,
such that

112
Andrea Cantini and Laura Crosilla
• Φ(F, a) = J(i), if a0 = 1, a1 = i;
• Φ(F, a) = K(F, a1, a2), if a0 = 2.
Choose F(a) = Φ(F, a) by ﬁxed point theorem; F is the required operation (argue
by VN–induction using the assumption on J and H).
Thus it remains to prove that there are operations J, K satisfying the hypotheses
of the sublemma.
As to J, we make the realizers in the proof of Lemma 19 explicit and obtain:
• there exists an operation Ωsuch that, for every k η N, for every f, if ∀i <
k.f(i) η ∥Trans(τ(νi))∥, then
Ω(f, k) η ∥Trans(τ(νk))∥.
Then, by ﬁxed point theorem and Cl −INDN, there exists J such that, for every
i η N, J(i) realizes Trans(τ(ν(i))) (see (17), lemma 19).
Concerning K, assume that a is a class, f : a →VN and
∀x η a.hx η ∥Trans(τ(f x))∥.
(23)
We wish to ﬁnd K(h, a, f) η ∥Trans(τ(sup(a, f))∥. In the following we argue infor-
mally. Let
e η ∥v ∈u∥;
g η ∥u ∈τ(sup(a, f))∥.
Read the realizer g of u ∈τ(sup(a, f)). If (g0)0 = 0, we have a realizer of u ∈
sup(a, f) and also a realizer of u ⊆τu (by the previous step (i)), whence a realizer
of v ∈τu (using e). This readily yields a realizer of v ∈˙S sup(a, λy.τ(fy)) and
hence one of v ∈τ(sup(a, f)).
Else, there is a realizer of u ∈τ( f x), for some x η a. Then by (23) and using e,
we get a realizer of v ∈˙S sup(a, λy.τ(fy)), and hence one of v ∈τ(sup(a, f)).
□
Theorem 25. Every theorem of ECSTt is realized in Tc, i.e. if ECSTt ⊢ϕ(⃗x),
then there exists a closed term e such that, provably in Tc, for ⃗a ∈VN
e⃗a ⊩ϕ(⃗a).
Proof. See Theorem 8.22 of [10]. The new case – the axiom TRANS – is taken
care of by Lemma 24.
□

Transitive Closure in Operational Set Theory
113
4
Reducing ESTEt to ECSTt
We have to show that
Theorem 26. ESTEt is interpretable in ECSTt. Moreover, every ≃–free sequent
provable in ESTEt is already provable in ECSTt.
Theorem 26 is veriﬁed by means of proof–theoretic methods. This is achieved
through two steps. First of all, we give a Gentzen–style formulation of ESTEt,
called Γt, so that the predicate ≃occurs positively, both in the active formulas and
the minor formulas of the relevant inferences for the set constructors and appli-
cation. Consequently, a partial cut elimination theorem holds. Then we give an
asymmetric interpretation of Γt in ECSTt, which yields the ﬁnal result.
4.1
Step 1: sequent style formulation
We only give a sketch of the theory Γt. As usual, capital Greek letters Γ, Λ, . . .
denote ﬁnite sequences of formulas of Γt. Sequents are of the form Γ ⇒Λ. The
system Γt is an extension of the intuitionistic Gentzen calculus [25]. The logical
rules consist of the usual rules for intuitionistic logic, including cut and rules for =.
In addition, there are the structural rules of weakening, exchange and contraction.
In the following we ﬁrst present the axioms and rules involving application; in
particular, we include trivial independence conditions on constants for operations.
Then we state the main rules for the set–theoretic constructors of Γt.
Deﬁnition 27. In order to simplify the statements, we extend the language by
adding new terms as follows:
(*) if t, s are terms, so are Kt, St, pairt, imt, sept, elt, expt, Sts.6
Finally, note that in the following, separation, explicit replacement and tran-
sitive closure are split into distinct rules to ease the asymmetric interpretation of
section 4.2. Indeed, each rule subsumes a clause for generating the application
relation, e.g. the separation and TC–rules show how the separation and transitive
closure operators are introduced.
6Formally, the special terms can be eliminated by means of a set–theoretically deﬁned ordered pair-
ing operation ⟨−, −⟩and 8 distinct sets c1,..., c8, e.g. to be identiﬁed with distinct elements of ω. For
example, Kt, can be identiﬁed with ⟨c1, t⟩.

114
Andrea Cantini and Laura Crosilla
Gentzen–style presentation of non–logical axioms and rules.
Γt in-
cludes (the closure under substitution of) the following sequents and rules:
1. Uniqueness:
Γ, ts ≃p, ts ≃q ⇒p = q
2. let C be a constant among K, S, pair, im, sep, el, exp; then
Γ
⇒
Ct ≃Ct
Γ
⇒
Sts ≃Sts
3. Combinatory completeness:
Γ ⇒Kts ≃t
Γ ⇒tr ≃u
Γ ⇒sr ≃v
Γ ⇒uv ≃w
Γ ⇒Stsr ≃w
4. Independence:
• let C1, C2 ∈{K, S, pair, un , im, sep, el, exp, τ}; then
Γ , C1 = C2 ⇒
• let C1, C2 ∈{K, S, pair, im, sep, el, exp}; then
Γ , C1
t = C2
s ⇒t = s ∧C1 = C2
• let C1, C2 ∈{S}; then
C1
ts = C2
pq ⇒t = p ∧s = q ∧C1 = C2
5. Extensionality:
Γ, ∀x (x ∈p ↔x ∈q) ⇒p = q
6. Empty–set:
Γ ⇒∀x(x < ∅)
7. Representing elementhood:
Γ ⇒∃z[z ⊆⊤∧elab ≃z ∧∀u(u ∈z ↔u = ⊥∧a ∈b)]

Transitive Closure in Operational Set Theory
115
8. Union:
Γ ⇒∃z[una ≃z ∧∀u(u ∈z ↔∃y ∈a (u ∈y))]
9. Pairing:
Γ ⇒∃z[pairab ≃z ∧∀u(u ∈z ↔u = a ∨u = b)]
10. Strong inﬁnity:
Γ ⇒∅∈ω
Γ, t ∈ω ⇒S uct ∈ω
Γ, ∅∈t ∧∀y(y ∈t →Suc y ∈t) ⇒ω ⊆t
11. Separation:
From the premiss:
Γ ⇒(∀u ∈a)(∃y ⊆⊤)( fu ≃y)
infer:
Γ ⇒∃z[(∀u ∈z)( fu ≃⊤∧u ∈a)∧
∧(∀u ∈a)(∀y(fu ≃y →y = ⊤) →u ∈z)]
From the premisses
• Γ ⇒(∀u ∈a)(∃y ⊆⊤)( fu ≃y)
• Γ ⇒(∀u ∈z)( fu ≃⊤∧u ∈a)
• Γ ⇒(∀u ∈a)(∀y(fu ≃y →y = ⊤) →u ∈z)
infer:
Γ ⇒sepa f ≃z

116
Andrea Cantini and Laura Crosilla
12. Explicit replacement:
Γ ⇒(∀x ∈a)∃y(f x ≃y)
Γ ⇒∃z[(∀y ∈z)(∃x ∈a)(f x ≃y) ∧(∀x ∈a)(∃y ∈z)( f x ≃y)]
From the premisses
• Γ ⇒(∀u ∈a)∃y(fu ≃y)
• Γ ⇒(∀y ∈z)(∃x ∈a)(f x ≃y)
• Γ ⇒(∀x ∈a)(∃y ∈z)( f x ≃y)
infer:
Γ ⇒ima f ≃z
13. Exponentiation:
Γ ⇒∃z[expab ≃z ∧∀F(F ∈z ↔(Fun(F) ∧Dom(F) = a∧
∧Ran(F) ⊆b))]
14. Transitive closure:
TC–introduction:
Γ ⇒Trans(b)
Γ ⇒(∀c)(Trans(c) ∧a ⊆c →b ⊆c)
Γ ⇒τa ≃b
TC–existence:
Γ ⇒(∃z)(Trans(z) ∧a ⊆z ∧(∀c)(Trans(c) ∧a ⊆c →z ⊆c))
Proviso: a, b < FV(Γ).
We stress that the active formulas of the inferences and axioms are positive in
≃.
Theorem 28 (Quasi–normal form). A Γt–derivation D can be eﬀectively trans-
formed into a Γt–derivation D∗of the same sequent, such that every cut formula
occurring in D∗is positive in ≃.

Transitive Closure in Operational Set Theory
117
In order to state the required form of the partial cut elimination theorem, one
introduces in the usual way the collections of formulas positive (respectively, neg-
ative) in the application predicate ≃. Γ ⇒∆is ≃–positive if every formula occur-
ring in Γ, ∆is ≃–positive.
Lemma 29 (Quasi–normal form). Every Γt–derivation D of an arbitrary sequent
Γ ⇒∆can be eﬀectively transformed into a Γt–derivation D∗of the same sequent,
such that every cut formula occurring in D∗is positive in ≃.
Corollary 30. Every Γt–derivation D of a ≃-positive sequent Γ ⇒∆can be eﬀec-
tively transformed into a Γt–derivation D∗of the same sequent, which only contains
≃–positive sequents.
4.2
Step 2: the asymmetric interpretation
The starting point is that in the intended interpretation the application predicate
App is inductively generated by an operator, which can be deﬁned by a formula
A(x, y, z, P) positive in P.7 Indeed, A(x, y, z, P) can be directly read oﬀfrom the
the rules of Γt, which take care of introducing the combinators and the set–theoretic
operators (im, sep, el, exp, pair, un and τ); and so we do not bore the reader with
its explicit formalization.
If we temporarily use ⊥also as an abbreviation for K = S, we can deﬁne :
App0(x, y, z) := ⊥
Appk+1(x, y, z) := A(x, y, z, Appk).
Here above A(x, y, z, Appk) is obtained from A(x, y, z, P) by replacing P every-
where with Appk. Now the asymmetric interpretation amounts to replacing the
application predicate by its ﬁnite stages Appn which, for each given n, can be ex-
plicitly deﬁned and proved to exist in the pure set–theoretic language of ECSTt.
Thus the ﬁnite approximations of the rules – τ rules included – can be justiﬁed in
the application–free system ECSTt. The interpretation is asymmetric in the sense
that it depends on a pair of number parameters m ≤n: the positive occurrences
of application are separated from the negative ones (the former being replaced by
Appn and the second by Appm).
7 This formula belongs to the language of ECSTt, except for the ternary predicate symbol P and for
the terms of the form Ct, Sts, where C is a constant among K, S, im, sep, el, exp, pair, see deﬁnition 27
and related footnote.

118
Andrea Cantini and Laura Crosilla
Deﬁnition 31.
(i) We inductively deﬁne A[m, n], where A is a formula of Γt, uniformly in n, m,
by stipulating that A 7→A[m, n] commutes with ∧, ∨, ∀, ∃, and in addition:
A[m, n]
:=
A, provided A has the form t = s or t ∈s;
App(t, s, r)[m, n]
:=
Appn(t, s, r);
(A →B)[m, n]
:=
(A[n, m] →B[m, n]).
(ii) If Γ := {A1, . . . , Ap}, Γ[m, n] := {A1[m, n], . . . , Ap[m, n]};
(iii) (Γ ⇒∆)[m, n] := Γ[n, m] ⇒∆[m, n].
Lemma 32.
(i) For each k ∈ω, Appk is a formula of ECSTt.
(ii) if A is App–positive (negative), then A[m, n] := An (A[m, n] := Am); if A is
App–free, A[m, n] := A.
(iii) Persistence: let m ≤p ≤q ≤n. Then, provably in ECSTt:
A[p, q] →A[m, n];
A[n, m] →A[q, p].
Below it is convenient to adopt the more suggestive notation xy ≃m z instead of
Appm(x, y, z).
Let (Γ ⇒∆)[m, n] be the asymmetric intepretation of the sequent Γ ⇒∆in
the language of Γt. Then by the above, one proves the fundamental lemma, which
readily implies the theorem 26.
Lemma 33. Let D be a Γt–derivation of Γ ⇒∆. Then there exists a natural
number c ≡cD such that, for every m > 0 and every n such that n ≥c + m,
Γ[n, m] ⇒∆[m, n]
is derivable in ECSTt.
Proof. Assume we are given a Γt–derivation D of Γ ⇒∆. Then, by lemma 29 of
step 1, we can assume that every cut formula occurring in D∗is positive in ≃. By
persistence (lemma 32), it is enough to check, for some constant c depending on
D,
(Γ ⇒∆)[m, c + m].
(24)

Transitive Closure in Operational Set Theory
119
We only deal with the interpretation of the rules involving the transitive closure
operator τ (for the interpretation of the other rules see [11]).
Let us consider the TC–existence rule. We argue informally. By IH, we have
for some constant e
(Γ[m, e + m] ⇒Trans(b)
(Γ[m, e + m] ⇒(∀d)(Trans(d) ∧a ⊆d →b ⊆d)
But the two conditions on the right hand side imply, for all n ≥max(e, 1):
Γ[m, n] ⇒τa ≃n b
As to the rule of TC–existence, let TRANS be the axiom stating the mere existence
of a transitive superset for every set
∀a∃b(a ⊆b ∧Trans(b))
ECST with exponentiation EXP and TRANS proves ([3],19.4):
∀a∃b(a ⊆b ∧Trans(b) ∧∀d(Trans(d) ∧a ⊆d →b ⊆d)),
(25)
(25) immediately implies the asymmetric interpretation of TC–existence, choosing
cD = 0
□
Remark. Theorem 26 still holds in presence of full subset collection and strong
collection.
Acknowledgements.
We would like to thank the referee for a careful read-
ing of the paper and for suggesting a number of improvements in the presentation
of the material. We are grateful to Peter Schuster for valuable comments.
References
[1] P. Aczel, The type theoretic interpretation of constructive set theory, Logic
Colloquium ’77 (A. MacIntyre, L. Pacholski, and J. Paris, eds.), North–
Holland, Amsterdam-New York, 1978, pp. 55–66.
[2]
, Frege structures and the notion of proposition, truth and set, The
Kleene Symposium (J. Barwise H. J. Keisler and K. Kunen, eds.), North–
Holland, Amsterdam-New York, 1980, pp. 31–59.
[3] P. Aczel and M. Rathjen, Notes on constructive set theory, 2000.

120
Andrea Cantini and Laura Crosilla
[4] M. Beeson, Towards a computation system based on set theory, Theoretical
Computer Science 60 (1988), 297–340.
[5] M. Boﬀa, Axiome et sch´ema de fondement dans le syst`eme de Zermelo, Bul-
letin de L’acad´emie Polonaise des Sciences 17 (1969), no. 2, 113–15.
[6]
,
Axiom and scheme of foundation,
Bulletin de la Soci´et´e
Math´ematique de Belgique 22 (1970), 242–47.
[7] A. Cantini, Levels of implication and type free theories of partial classiﬁca-
tions with approximation operator, Zeitschrift f¨ur mathematische Logik und
Grundlagen der Mathematik 38 (1992), 107–141.
[8]
, Logical frameworks for truth and abstraction, North–Holland, Am-
sterdam, 1996.
[9]
, Extending constructive operational set theory by impredicative prin-
ciples, Math. Log. Q. 57 (2011), no. 3, 299–322.
[10] A. Cantini and L. Crosilla, Constructive set theory with operations, Logic
Colloquium 2004 (A. Andretta, K. Kearnes, and D. Zambella, eds.), Lecture
Notes in Logic, vol. 29, Cambridge University Press, Cambridge, 2008.
[11]
, Elementary constructive operational set theory, Ways of Proof The-
ory (R. Schindler, ed.), Ontos Series in Mathematical Logic, Frankfurt, 2010,
pp. 199–240.
[12] A. Enayat, J. H. Schmerl, and A. Visser, Omega–models of ﬁnite set theory,
Set theory, Arithmetic, and Foundations of Mathematics: Theorems, Philoso-
phies, Cambridge University Press, 2011.
[13] O. Esser and R. Hinnion, Antifoundation and transitive closure in the system
of Zermelo, Notre Dame Journal of Formal Logic 40 (1999), no. 2, 197–205.
[14] S. Feferman, A language and axioms for explicit mathematics, Algebra and
Logic (J. Crossley, ed.), Lecture Notes in Mathematics, vol. 450, Springer,
Berlin, 1975, pp. 87–139.
[15]
, Operational set theory and small large cardinals, Information and
Computation 207 (2009), 971–979.
[16] G. J¨ager, On Feferman’s operational set theory OST, Annals of Pure and Ap-
plied Logic 150 (2007), 19–39.

Transitive Closure in Operational Set Theory
121
[17]
, Full operational set theory with unbounded existential quantiﬁcation
and powerset, Annals of Pure and Applied Logic 160 (2009), 33–52.
[18]
, Operations, sets and classes, Logic, Methodology and Philosophy
of Science - Proceedings of the Thirteenth International Congress, College
Pubblications, 2009.
[19] G. J¨ager and T. Strahm, Totality in applicative theories, Annals of Pure and
Applied Logic 74 (1995), 105–120.
[20] R. Kaye and T. L. Wong, On interpretations of arithmetic and set theory,
Notre Dame J. Formal Logic 48 (2007), no. 4, 497–510.
[21] A. Mancini and D. Zambella, A note on recursive models of set theories, Notre
Dame Journal of Formal Logic 42 (2001), no. 2, 109–115.
[22] A. R. D. Mathias, Weak systems of Gandy, Jensen and Devlin, Set Theory:
Centre de Recerca Matem´atica, Barcelona 2003-4 (Joan Bagaria and Stevo
Todorcevic’, eds.), Trends in Mathematics, Birkh¨auser Verlag, Basel, 2006,
pp. 149–224.
[23] J. Myhill, Constructive set theory, Journal of Symbolic Logic 40 (1975), 347–
382.
[24] M. Rathjen, The natural numbers in constructive set theory, Mathematical
Logic Quarterly 54 (2008), 83–97.
[25] A. S. Troelstra and H. Schwichtenberg, Basic proof theory, 2nd. ed., Cam-
bridge University Press, Cambridge, 2000.

122

Formal Baire Space in Constructive
Set Theory
Giovanni Curi and Michael Rathjen∗
Introduction
Constructive topology is generally based on the notion of locale, or formal space
(see [10, 9, 8], and [22, pg. 378], for an explanation of why this is the case). Al-
gebraically, locales are particular kinds of lattices that, like other familiar algebraic
structures, can be presented using the method of generators and relations, cf. e.g.
[23]. Equivalently, they may be described using covering systems [9, 13]. Set-
theoretically, ‘generators and relations’ and covering systems can be regarded as
inductive deﬁnitions. Classical or intuitionistic fully impredicative systems, such
as intuitionistic Zermelo-Fraenkel set theory, IZF [2], or the intuitionistic theory of
a topos [11], are suﬃciently strong to ensure that such inductive deﬁnitions do give
rise to a locale or formal space. This continues to hold in (generalized) predicative
systems as for example the constructive set theory CZF augmented by the weak
regular extension axiom wREA (where the covering systems give rise to so-called
inductively generated formal spaces, [1]). However, albeit being much weaker than
classical set theory ZF, the system CZF + wREA is considerably stronger than CZF.
As it turns out, CZF + wREA is a subsystem of classical set theory ZF plus the ax-
iom of choice AC, but not of ZF alone (cf. [17]). Naturally, this lends itself to the
question of what can be proved in the absence of wREA.
In this note we show that working in CZF alone, a covering system may fail
to deﬁne a formal space already in a familiar case. It is easy to see that CZF
can prove that, e.g., the covering systems used to present formal Cantor space C,
and the formal real line R, do deﬁne formal spaces; this is essentially because the
associated inductive deﬁnition is a ﬁnitary one for C, and can be replaced by a
ﬁnitary one, plus an application of restricted Separation, for R (as apparently ﬁrst
noted by T. Coquand, see [7, Section 6] for more details). There has been for some
∗This material includes work supported by the EPSRC of the UK through Grant No. EP/G029520/1.

124
Giovanni Curi and Michael Rathjen
time the expectation that the same does not hold for formal Baire space B. The
main result in this note, Theorem 3.4, will conﬁrm this expectation.
This result, in conjunction with [3, Proposition 3.10] (or [4, B.4]), also answers
in the negative the question, asked in [3], whether CZF proves that the Brouwer
(or constructive) ordinals form a set (although this could in fact also be inferred by
previous results, see Section 3). Independently, this was also shown in [4, Corollary
B.5].1
A corollary of Theorem 3.4 is moreover that the full subcategory FSpi of the
category FSp of formal spaces deﬁned by the inductively generated formal spaces
[1, 5], fails to have inﬁnitary products in CZF, according at least to the received con-
struction. The notion of inductively generated formal space was introduced in [5]
to make it possible to predicatively perform basic constructions on formal spaces
as that of the product formal space; these constructions indeed do not appear to be
possible for general formal spaces without recourse to some strong impredicative
principle [5]. In CZF augmented by the weak regular extension axiom wREA, the
category FSpi of inductively generated formal spaces can instead be proved to have
inﬁnitary products (and more generally, all limits). Exploiting the isomorphism of
the product Q
n∈N N with B, one shows that this need no longer be the case in CZF
alone.
Although CZF does not prove that B is a formal space, it does prove that B is an
imaginary locale [7]. More generally, every covering system deﬁnes an imaginary
locale in CZF. Imaginary locales give rise to a category ImLoc that extends the
category FSp of formal spaces, and that has all limits (in particular all products)
already assuming a fragment of CZF. As the categories FSp and FSpi, ImLoc is
equivalent to the ordinary category of locales in a fully impredicative system as
classical set theory.
1
Constructive set theory and inductive deﬁnitions
The language of Constructive Zermelo-Fraenkel Set Theory, CZF, is the same as
that of Zermelo-Fraenkel Set Theory, ZF, with ∈as the only non-logical symbol.
CZF is based on intuitionistic predicate logic with equality, and has the following
axioms and axiom schemes:
1. Extensionality: ∀a∀b(∀y(y ∈a ↔y ∈b) →a = b).
2. Pair: ∀a∀b∃x∀y(y ∈x ↔y = a ∨y = b).
1At the end of this paper there is a post scriptum explaining the relationship between some of the
ﬁndings in [3], [4], and the present paper.

Baire Space in CZF
125
3. Union: ∀a∃x∀y(y ∈x ↔(∃z ∈a)(y ∈z)).
4. Restricted Separation scheme:
∀a∃x∀y(y ∈x ↔y ∈a ∧φ(y)),
for φ a restricted formula. A formula φ is restricted if the quantiﬁers that
occur in it are of the form ∀x ∈b, ∃x ∈c.
5. Subset Collection scheme:
∀a∀b∃c∀u((∀x ∈a)(∃y ∈b)φ(x, y, u) →
(∃d ∈c)((∀x ∈a)(∃y ∈d)φ(x, y, u) ∧(∀y ∈d)(∃x ∈a)φ(x, y, u))).
6. Strong Collection scheme:
∀a((∀x ∈a)∃yφ(x, y) →
∃b((∀x ∈a)(∃y ∈b)φ(x, y) ∧(∀y ∈b)(∃x ∈a)φ(x, y))).
7. Inﬁnity: ∃a(∃x ∈a ∧(∀x ∈a)(∃y ∈a)x ∈y).
8. Set Induction scheme: ∀a((∀x ∈a)φ(x) →φ(a)) →∀aφ(a).
See [2] for further information on CZF and related systems. We shall denote by
CZF−the system obtained from CZF by leaving out the Subset Collection scheme.
Note that from Subset Collection one proves that the class of functions ba from a
set a to a set b is a set, i.e., Myhill’s Exponentiation Axiom. Intuitionistic Zermelo-
Fraenkel set theory based on collection, IZF, has the same theorems as CZF ex-
tended by the unrestricted Separation Scheme and the Powerset Axiom. Moreover,
the theory obtained from CZF by adding the Law of Excluded Middle has the same
theorems as ZF.
As in classical set theory, we make use of class notation and terminology [2].
The set N of natural numbers is the unique set x such that
∀u[u ∈x ↔(u = ∅∧(∃v ∈x)(u = v ∪{v}))].
A major role in constructive set theory is played by inductive deﬁnitions. An
inductive deﬁnition is any class Φ of pairs. A class A is Φ−closed if:
(a, X) ∈Φ, and X ⊆A implies a ∈A.
The following theorem is called the class inductive deﬁnition theorem [2].

126
Giovanni Curi and Michael Rathjen
Theorem 1.1 (CZF−). Given any class Φ, there exists a least Φ−closed class I(Φ),
the class inductively deﬁned by Φ.
Given any inductive deﬁnition Φ and any class U, there exists a smallest class
containing U which is closed under Φ. This class will be denoted by I(Φ, U).
Note that I(Φ, U) is the class inductively deﬁned by Φ′ = Φ ∪(U × {∅}), i.e.,
I(Φ, U) = I(Φ′). Given a set S , we say that Φ is an inductive deﬁnition on S if
Φ ⊆S × Pow(S ), with Pow(S ) the class of subsets of S . An inductive deﬁnition Φ
is ﬁnitary if, whenever (a, X) ∈Φ, there exists a surjective function f : n →X for
some n ∈N. Φ is inﬁnitary if it is not ﬁnitary.
As is shown in Section 3, even when Φ is a set, I(Φ) need not be a set in CZF.
For this reason, CZF is often extended with the Regular Extension Axiom, REA.
REA: every set is the subset of a regular set.
A set c is regular if it is transitive, inhabited, and for any u ∈c and any set R ⊆u×c,
if (∀x ∈u)(∃y)⟨x, y⟩∈R, then there is a set v ∈c such that
(∀x ∈u)(∃y ∈v)((x, y) ∈R)
∧
(∀y ∈v)(∃x ∈u)((x, y) ∈R).
(26)
c is said to be weakly regular if in the above deﬁnition of regularity the second con-
junct in (26) is omitted. The weak regular extension axiom, wREA, is the statement
that every set is the subset of a weakly regular set.
In CZF + wREA, the following theorem can be proved.
Theorem 1.2 (CZF + wREA). If Φ is a set, then I(Φ) is a set.
The foregoing result holds in more generality for inductive deﬁnitions that are
bounded (see [2]).
The theory CZF has has the same strength as classical Kripke-Platek set theory
or the theory one non-iterated inductive deﬁnitions ID1 by [15, Theorem 4.14]. It
is therefore much weaker than Π1
1-comprehension. The strength of CZF+REA and
CZF + wREA is the same as that of the subsystem of second order arithmetic with
∆1
2-comprehension and Bar induction (see [15, Theorem 5.12] and [16, Theorem
4.7]). Thus it is much stronger than CZF, but still very weak compared to ZF.
ZF+AC proves REA whereas wREA (and a fortiori REA) is not provable in ZF
alone by [17, Corollary 7.1].
Sometimes one considers extensions of CZF by constructively acceptable
choice principles, such as the principle of countable choice:
ACω : for every class A, if R ⊆N × A satisﬁes (∀n ∈N)(∃a ∈A)R(n, a) then
there exists f : N →A such that f ⊆R.

Baire Space in CZF
127
2
Constructive locale theory
Unless stated otherwise we will be working in CZF−. The notion of locale [11, 8, 9]
provides the concept of topological space adopted in intuitionistic fully impredica-
tive systems such as topos logic (Higher-order Heyting arithmetic). In the absence
of the Powerset Axiom, however, as for instance in constructive generalized pred-
icative systems, this notion splits into inequivalent concepts.
A preordered set is a pair (S, ≤) with S and ≤sets, and ≤a reﬂexive and tran-
sitive relation. For U a subset, or a subclass, of S , ↓U abbreviates {a ∈S : (∃b ∈
U)a ≤b}. We also use U ↓V for ↓U ∩↓V.
A generalized covering system on a preordered set (S, ≤) is an inductive deﬁnition
Φ on S such that, for all (a, X) in Φ,
1. X ⊆↓{a},
2. if b ≤a then there is (b, Y) ∈Φ with Y ⊆↓X.
An imaginary locale is a structure of the form
X ≡(S, ≤, Φ),
with Φ a generalized covering system on the preordered set (S, ≤). The set S is
called the base of X.
Given an imaginary locale X ≡(S, ≤, Φ), we let Φ≤denote the class of pairs
Φ ∪{(b, {a}) | b ≤a}. As Φ≤is an inductive deﬁnition, given any subclass U of S ,
by Theorem 1.1, there exists (in CZF−)
A(U) ≡I(Φ≤, U),
i.e. the smallest class containing U closed under Φ≤.
Theorem 2.1 (CZF−). For every a, b ∈S , and for all subclasses U, V of S , the
following hold:
0. ↓{a} ⊆A({a}),
1. U ⊆A(U),
2. U ⊆A(V) implies A(U) ⊆A(V),
3. A(U) ∩A(V) ⊆A(U ↓V).

128
Giovanni Curi and Michael Rathjen
See [7] for the proof of this result and further information on imaginary locales.
Equipped with a suitable notion of continuous function, imaginary locales form the
(superlarge) category ImLoc.
Two full subcategories of this category had been considered earlier as possible
counterpart of the category of locales in constructive (generalized) predicative set-
tings. Let FSp be the full subcategory of ImLoc given by those imaginary locales
X ≡(S, ≤, Φ) which satisfy
(A-smallness)
for every U ∈Pow(S ), A(U) is a set,
and let FSpi be the full subcategory of ImLoc given by those X ≡(S, ≤, Φ) which
satisfy the smallness condition above, and are such that
(Φ-smallness)
Φ is a set,
i.e., such that Φ is an ordinary covering system. FSp and FSpi are respectively
(equivalent to) the category of formal spaces and the category of inductively gen-
erated formal spaces [1, 5].
Formal spaces are generally presented in terms of a covering relation on a pre-
ordered set. Given a (class-)relation ◁⊆S × Pow(S ), let the saturation of a subset
U of S be deﬁned as the class A(U) = {a ∈S : a ◁U}, where we write a ◁U for
◁(a, U). Then, by deﬁnition, ◁is a covering relation if, with the class A(U) thus
re-deﬁned, the A-smallness condition is satisﬁed, and the conditions in Theorem
2.1 are satisﬁed for every U, V ∈Pow(S ).
One passes from one deﬁnition of formal space to the other by associating to
an imaginary locale (S, ≤, Φ) satisfying A-smallness, the structure
(S, ≤, ◁),
where a◁U ⇐⇒a ∈I(Φ≤, U); in the other direction, given a covering relation ◁on
(S, ≤), one obtains a generalized covering system (S, ≤, Φ) satisfying A-smallness
by letting
Φ ≡{(a, U) | a ◁U & U ⊆↓a}.
Note that the same correspondence exists more generally between imaginary
locales and covering relations that are not required to satisfy the A-smallness con-
dition.
Assuming the full Separation scheme Sep, the categories ImLoc and FSp coin-
cide, since the A-smallness condition is always satisﬁed. On the other hand, even
in CZF + Sep, ImLoc is not the same as FSpi, as there are formal spaces of various
types that cannot be inductively generated in this system [6].

Baire Space in CZF
129
In CZF, every formal space X has an associated set-generated class-frame
S at(X), see [1]; the carrier of S at(X) is given by the class {A(U) | U ∈Pow(S )}
of saturated subsets of X (meets and joins are given by U ∧V ≡U ↓V, and
W
i∈I Ui ≡A(S
i∈I Ui)). Note that if X is instead an imaginary locale, S at(X) cannot
be constructed in a generalized predicative setting, as A(U) may fail to be a set for
some U.
With the full Separation scheme and the Powerset axiom available, as e.g., in
IZF, S at(X) is an ordinary frame (locale); in such a system, the categories ImLoc,
FSp, FSpi (coincide, and) are all equivalent to the category of locales.
The concept of formal space was the ﬁrst to be introduced, in [21]. The reason
that led to consider the stronger notion of inductively generated formal space is
that it does not appear to be possible to carry out, in a generalized predicative
setting, standard basic constructions for general formal spaces, such as that of the
product space [5]. The category FSpi has been shown to have all products and
equalizers (hence all limits) [23, 14]. However, this only holds in CZF + REA,
and we shall see in the next section that the given construction of products may in
fact fail to yield, in CZF, an inductively generated formal space from inductively
generated formal spaces. Moreover, as already recalled, the restriction to FSpi rules
out several types of formal spaces of interest [6]. By contrast, the category ImLoc
is complete (has all limits) already over CZF−[7], and, as seen, is an extension of
the category of formal spaces which in a fully impredicative system as IZF is still
equivalent to the category of locales.
We conclude this section noting that, in the absence of REA, an imaginary lo-
cale satisfying Φ-smallness need not satisfy A-smallness (with REA it does, recall
Theorem 1.2). The next section presents an example of such a phenomenon. Imagi-
nary locales of this kind determine a full subcategory of ImLoc, called the category
of geometric locales; this category is itself complete in CZF−[7].
3
Formal Baire space
Recall that Baire space is the set NN, endowed with the product topology. Its point-
free version, formal Baire space, is deﬁned as follows. Let N∗be the set of ﬁnite
sequences of natural numbers; formal Baire space B is the generalized covering
system
B ≡(N∗, ≤, ΦB),
where, for s, t ∈N∗, s ≤t if and only if t is an initial segment of s, and
ΦB = {(s, {s ∗⟨n⟩| n ∈N}) | s ∈N∗}.

130
Giovanni Curi and Michael Rathjen
B is then an imaginary locale in CZF−. Note that ΦB is an inﬁnitary inductive
deﬁnition. The class ΦB is a set in CZF−, so that it is a set in CZF + REA. By
Theorem 1.2, then, AB(U) ≡I(ΦB
≤, U) is a set for every U ∈Pow(N∗). Thus:
Proposition 3.1. CZF + REA proves that B is a formal space.
Recall that a point of a formal space (or, more generally, of an imaginary locale)
X ≡(S, ≤, ΦX) is a inhabited subset α of S such that
(i) for every a, b ∈α there is c ∈{a} ↓{b} with c ∈α,
(ii) for every a ∈S, U ∈Pow(S ), if a ∈α and a ∈I(ΦX
≤, U) then there is b ∈U
such that b ∈α.
Points of B may be identiﬁed with inﬁnite sequences of non-negative integers. For
a ∈S , let ext(a) denote the class of points ‘in a’, i.e. the class of points to which
a belongs. Then, X ≡(S, ≤, ΦX) is spatial whenever, for every a ∈S and U ∈
Pow(S ), one has a ∈I(ΦX
≤, U) if and only if ext(a) ⊆S
b∈U ext(b).
Note that the principle of Monotone Bar Induction BIM is exactly the statement
that B is spatial [8]. Moreover, spatiality of B implies the spatiality of formal
Cantor space and of the formal Real Unit Interval; spatiality of these formal spaces
is in turn respectively equivalent to the Fan Theorem, and to compactness of the
real unit interval (see [8], or [3]).
It is well-known that the compactness of the Real Unit Interval (and hence
Monotone Bar Induction) is inconsistent with Church Thesis, so that the spatial-
ity of the above-mentioned formal spaces is independent from the systems we are
considering.
Contrary to what happens with the Fan Theorem, FT, adding decidable Bar
Induction BID (which is a consequence of monotone Bar Induction, BIM) to CZF
has a marked eﬀect.
Theorem 3.2. ([20, Corollary 4.8],[19, Theorem 9.10(i)])
(i) CZF + BID proves the 1-consistency of CZF.
(ii) CZF and CZF + FT have the same proof-theoretic strength.
On the other hand, BIM has no eﬀect on the proof-theoretic strength in the
presence of REA.
Theorem 3.3. [19, Theorem 9.10(ii)] CZF + REA and CZF + REA + DC + BIM
have the same proof-theoretic strength.
Formal Cantor Space (deﬁned as formal Baire space, but with N∗replaced ev-
erywhere by {0, 1}∗, and with N replaced by {0, 1} in the covering system), and the
formal Real Unit Interval involve ﬁnitary inductive deﬁnitions, and can be proved

Baire Space in CZF
131
formal spaces already over CZF−(the covering system for the formal Real Unit
Interval is in fact given by an inﬁnitary inductive deﬁnition, but this can be seen to
have the same eﬀect of a ﬁnitary one plus an application of the restricted Separation
scheme, cf. [7, Section 6]).
It has been an open question for some time whether CZF alone proves that B is
a formal space.
Theorem 3.4. CZF + ACω does not prove that, for every U ∈Pow(N∗), I(ΦB
≤, U)
is a set. The unprovability result obtains even if one adds the Dependent Choices
Axiom, DC (cf. [2]), and the Presentation Axiom (cf. [2]), PA, to CZF.
Proof. We plan to show, using the axioms of CZF, that from the assertion
∀U ⊆N∗I(ΦB
≤, U) is a set
(27)
it follows that the well-founded part, WF(≺), of every decidable ordering ≺on N
is a set. Here decidability means that ∀n, m ∈N (n ≺m ∨¬ n ≺m) and by an
ordering we mean any transitive and irreﬂexive binary relation (which is also a set).
Recall that WF(≺) is the smallest class X such that for all n ∈N,
∀m ∈N (m ≺n →m ∈X)
implies
n ∈X.
(28)
If one then takes ≺to be the ordering which represents the so-called Bachmann-
Howard ordinal, it follows from [18, 4.13, 4.14] that (27) implies the 1-consistency
of CZF (actually the uniform reﬂection principle for CZF and more), and therefore,
in light of [15, Theorem 4.14], also the 1-consistency of CZF + ACω + DC + PA.
As a result, (27) is not provable in CZF + ACω + DC + PA.
It remains to show that, assuming (27), WF(≺) is a set. Deﬁne U to be the
subset of N∗consisting of all sequences ⟨n1, . . . , nr⟩with r > 1 such that ¬ nj ≺ni
for some 1 ≤i < j ≤r. Observe that ∀s ∈N∗(s ∈U ∨s < U) owing to the
decidability of ≺.
Let s ∈N∗. We say that n is in s if s is of the form s = ⟨n1, . . . , nr⟩with
r ≥1 and n = ni for some 1 ≤i ≤r. Another way of saying that n is in s is that
s = s1 ∗⟨n⟩∗s2 for some s1, s2 ∈N∗. Let V ⊆N be the class deﬁned as follows:
n ∈V
iﬀ
∀s ∈N∗(n in s →s ∈I(ΦB
≤, U)).
(29)
Claim 1: WF(≺) ⊆V. To show this, assume n ∈N and m ∈V for all m ≺
n. Suppose n is in s. For an arbitrary k ∈N we then have s ∗⟨k⟩∈I(ΦB
≤, U),
for ¬k ≺n implies s ∗⟨k⟩∈U and hence s ∗⟨k⟩∈I(ΦB
≤, U), whereas k ≺n
entails s ∗⟨k⟩∈I(ΦB
≤, U) by assumption. Thus s ∈I(ΦB
≤, U) owing to its inductive
deﬁnition. Whence n ∈V.

132
Giovanni Curi and Michael Rathjen
⟨⟩denotes the empty sequence of N∗. Let
Y = {s ∈N∗| s ∈U ∨∃m ∈WF(≺) (m in s) ∨∀m m ∈WF(≺) }.
Claim 2: I(ΦB
≤, U) ⊆Y. By deﬁnition of Y, we have U ⊆Y and whenever s ∈Y
and t ∈N∗then s∗t ∈Y. To conﬁrm the claim it thus suﬃces to show that s∗⟨n⟩∈Y
for all n ∈N implies s ∈Y. So assume s ∗⟨n⟩∈Y for all n ∈N. s ∈U implies
s ∈Y. If s = ⟨⟩, then ⟨n⟩∈Y for all n. Thus s = ⟨⟩implies that for all n, n ∈WF(≺)
or ∀m m ∈WF(≺), and therefore n ∈WF(≺), yielding s ∈Y.
Henceforth we may assume that s < U and s , ⟨⟩. In particular s = t ∗⟨k⟩
for some t ∈N∗, k ∈N, and the components of s are arranged in ≺-descending
order. Let n ≺k. We then have s ∗⟨n⟩= t ∗⟨k⟩∗⟨n⟩< U and hence there is an
l ∈WF(≺) such that l is in s ∗⟨n⟩or else ∀m m ∈WF(≺). Thus n ≺l ∨n = l
for some l ∈WF(≺) or ∀m m ∈WF(≺), yielding n ∈WF(≺). In consequence,
∀n ≺k n ∈WF(≺), thus k ∈WF(≺), and hence s ∈Y. This ﬁnishes the proof of
Claim 2.
As n ∈V implies ⟨n⟩∈I(ΦB
≤, U), we deduce with the help of Claim 2 that ⟨n⟩∈Y.
Hence n ∈WF(≺) or ∀m m ∈WF(≺), whence n ∈WF(≺). Thus V ⊆WF(≺), and
in view of Claim 1, we have V = WF(≺). If I(ΦB
≤, U) were a set, V would be a set,
too. Hence (27) entails that WF(≺) is a set.
□
Corollary 3.5. CZF + ACω + DC + PA does not prove that the imaginary locale B
is a formal space.
This in particular answers the question in footnote 2 of [3]. Note that B is in fact a
geometric locale, since ΦB is a set in CZF−.
Remark 3.6. Direct calculations show that the construction of products for induc-
tively generated formal spaces [23] gives B  Q
n∈N N, where N is the discrete
formal space of the natural numbers, which is trivially inductively generated in
CZF. It is easy to see that the assumption that the imaginary locale Q
n∈N N is a
formal space implies that I(ΦB
≤, U) is a set, for U as in the proof of Theorem 3.4, so
that Q
n∈N N also cannot be proved to be a formal space in CZF + ACω + DC + PA.
This fact shows that the category of inductively generated formal spaces, which
is complete in CZF + REA, is not closed for inﬁnitary products (at least according
to the received construction) in (CZF and) CZF + ACω + DC + PA. Note that
Q
n∈N N  B is the product in the category of imaginary locales [7].
The above theorem also answers the question in footnote 3 of [3], whether
CZF proves that the Brouwer (or constructive) Ordinals form a set. Call a relation
R ⊆S × Pow(S ) set-presented if a mapping D : S →Pow(Pow(S )) is given
satisfying R(a, U) ⇐⇒(∃V ∈D(a)) V ⊆U, for every a ∈S, U ∈Pow(S ).

Baire Space in CZF
133
Lemma 3.7 (CZF−). Let X ≡(S, ≤, Φ) be an imaginary locale. If R(a, U) ≡a ∈
I(Φ≤, U) is set-presented, then X is a formal space.
Proof. The class I(Φ≤, U) is a set for every U ∈Pow(S ), since I(Φ≤, U) = {a ∈S |
(∃V ∈D(a)) V ⊆U}, and the latter class is a set by Replacement and Restricted
Separation.
□
The following result, without mentioning PA, was also independently estab-
lished in [4, Corollary B.5].
Corollary 3.8. CZF + ACω + DC + PA does not prove that the Brouwer Ordinals
form a set.
Proof. The proof of [3, Proposition 3.10] or [4, Proposition B.4] shows that, in
CZF + ACω plus the assertion that the Brouwer Ordinals form a set, the relation
RB(s, U) ≡s ∈I(ΦB
≤, U) is set-presented. But then I(ΦB
≤, U) is a set for every
U ∈Pow(N∗), by Lemma 3.7. So if CZF proves that the Brouwer Ordinals form a
set, CZF + ACω proves that B is a formal space.
□
Implicitly, it has been known for a long time that CZF + ACω + DC + PA
does not prove that the Brouwer ordinals form a set, owing to [15, Theorem 4.14]
and an ancient result due to Kreisel. In [12] Kreisel showed that the intuitionistic
theory IDi(O) of the Brouwer ordinals O is of the same proof-theoretic strength
as the classical theory of positive arithmetical inductive deﬁnitions ID1. IDi(O) is
an extension of Heyting arithmetic via a predicate for the Brouwer ordinals and
axioms pertaining to O’s inductive nature. Thus from [15, Theorem 4.14] it follows
that IDi(O) and CZF + ACω + DC + PA have the same proof-theoretic strength. But
if the latter theory could prove that the Brouwer ordinals form a set, it could easily
prove that IDi(O) has a set model, and in particular the consistency of IDi(O).
Post scriptum.
The research reported in this paper was carried out in June 2011.
The question of whether CZF proves that the Brouwer ordinals form a set, raised
in [3], was also answered (in the negative) by the authors of [3], Benno van den
Berg and Ieke Moerdijk. They posted a new version of their paper on arxiv.org
in November 2011 which in the meantime got published as [4]. In [4, Corollary
B.5] they show that the Brouwer ordinals cannot be proved to be a set on the basis
of CZF+DC. Theirs and our proof both hinge on proof-theoretic results from [20].
Our non-provability result 3.4, however, is stronger than [4, Corollary A.3]. The
latter shows that CZF+DC cannot prove that Baire space has a presentation whereas
the former shows that this theory (or even CZF+PA) does not prove that B is a
formal space.

134
Giovanni Curi and Michael Rathjen
References
[1] P. Aczel, “Aspects of general topology in constructive set theory”, Ann. Pure
Appl. Logic, 137, 1-3 (2006), pp. 3-29.
[2] P. Aczel, M. Rathjen “Notes on Constructive Set Theory”, Mittag-Leﬄer
Technical Report No. 40, 2000/2001.
[3] B. van den Berg, I. Moerdijk, “Derived rules for predicative set the-
ory:
an application of sheaves”. Version of September 18,
2010
[http://arxiv.org/abs/1009.3553v1].
[4] B. van den Berg, I. Moerdijk, “Derived rules for predicative set theory:
an application of sheaves”. Annals of Pure and Applied Logic (2012),
doi:10.1016/j.apal.2012.01.010
[5] T. Coquand, G. Sambin, J. Smith, S. Valentini, “Inductively generated formal
topologies”, Annals of Pure and Applied Logic 124, 1-3 (2003), pp. 71–106.
[6] G. Curi, “On some peculiar aspects of the constructive theory of point-free
spaces”, Mathematical Logic Quarterly, 56, 4 (2010), pp. 375 – 387.
[7] G. Curi, “Topological inductive deﬁnitions”. Ann. Pure Appl. Logic,
doi:10.1016/j.apal.2011.12.005.
[8] M. Fourman and R. Grayson, “Formal Spaces”, in: A.S. Troelstra and D. van
Dalen (eds.), The L.E.J. Brouwer Centenary Symposium, pp. 107–122. North
Holland (1982).
[9] P. T. Johnstone, “Stone Spaces”, Cambridge University Press, 1982.
[10] P. T. Johnstone, “The points of pointless topology”, Bull. Am. Math. Soc. 8 1,
41–53 (1983).
[11] P. T. Johnstone, “Sketches of an elephant. A topos theory compendium. II,”
Oxford Logic Guides 44; Oxford Science Publications. Oxford: Clarendon
Press, 2002.
[12] G. Kreisel “A survey of proof theory”, J. Symbolic Logic 33 (1968) pp. 321–
388.
[13] S. MacLane, I. Moerdijk, “Sheaves in Geometry and Logic - A First Intro-
duction to Topos Theory”, Springer, 1992.

Baire Space in CZF
135
[14] E. Palmgren, “Predicativity problems in point-free topology”, in:
V.
Stoltenberg-Hansen et al. (eds.), Proceedings of the Annual European Sum-
mer Meeting of the Association for Symbolic Logic, held in Helsinki, Finland,
August 14–20, 2003, Lecture Notes in Logic 24, ASL, (AK Peters Ltd, 2006),
pp. 221–231.
[15] M. Rathjen “The strength of some Martin–L¨of type theories”, Department of
mathematics, Ohio State University, Preprint series (1993) 39 pages.
[16] M. Rathjen “The anti-foundation axiom in constructive set theories”, in: G.
Mints, R. Muskens (eds.) Games, Logic, and Constructive Sets. (CSLI Publi-
cations, Stanford, 2003) 87–108.
[17] M. Rathjen, R.S. Lubarsky “On the regular extension axiom and its variants”,
Math. Log. Q. 49, 5 (2003), pp. 511–518.
[18] M. Rathjen “Replacement versus collection in constructive Zermelo-Fraenkel
set theory”, Ann. Pure Appl. Logic 136 (2005) pp. 156–174.
[19] M. Rathjen, “Constructive set theory and Brouwerian principles”, J. Universal
Computer Science 11 (2005), pp. 2008–2033.
[20] M. Rathjen, “A note on bar induction in constructive set theory”, Math. Log.
Q. 52, 3 (2006), pp. 253–258.
[21] G. Sambin, “Intuitionistic formal spaces - a ﬁrst communication”, in: Mathe-
matical Logic and its Applications, D. Skordev, ed. Plenum, (1987), pp. 187-
204.
[22] A. Troelstra and D. van Dalen, “Constructivism in mathematics, an introduc-
tion, Vol. I,II”, Studies in logic and the foundation of mathematics 121, 123
(Amsterdam etc., North-Holland, 1988).
[23] S. Vickers, “Some constructive roads to Tychonoﬀ”, in: L. Crosilla and P.
Schuster (eds.) From Sets and Types to Topology and Analysis: Practica-
ble Foundations for Constructive Mathematics, pp. 223 – 238, Oxford Logic
Guides 48, OUP (2005).

136

Functional Interpretations of Classical and
Constructive Set Theory
Justus Diller
Whereas the Diller-Nahm interpretation of Peano arithmetic in ﬁnite types
PAω is transferred directly to a ∧-interpretation of Kripke-Platek set theory
KPω as well as of its ﬁnite type extension KPωω in the classical version of
the theory of constructive set functionals T∈, the Dialectica interpretation al-
ready of KPω requires an additional non-constructive choice function. By a
suitable translation of existential quantiﬁcation, the ∧-interpretation is further
extended to a functional interpretation of Aczel’s constructive set theory CZF−
and its ﬁnite type extension CZFω−in T∈. We also characterize the strength of
these functional translations and sketch a hybrid interpretation ∧q of CZFω−
in itself which shows closure of CZFω−under, e.g., a weak form of existential
deﬁnability.
1
Introduction
Generalizing G¨odel’s Dialectica interpretation D of Heyting arithmetic HA in his
theory T [12], consider a mathematical theory Th and a theory FT of functionals
of ﬁnite types such that the quantiﬁer-free formulae of L(Th) are also in L(FT). A
functional translation I of Th in FT is a recursively deﬁned map which, with each
formula A of L(Th), associates an expression AI ≡∃v∀wAI[v, w] where AI[v, w]
is a formula of L(FT) and v, w are disjoint tuples of variables of ﬁnite type not
occurring in A. Moreover, AI ≡AI ≡A for quantiﬁer-free A ∈L(Th). The
functional translation I is a functional interpretation of Th in FT, we write
Th
I,→FT ,
if for Th ⊢A and AI as above, there is a tuple of terms b of L(FT) (with variables
among the variables free in A) such that
FT ⊢AI[b, w]
If this last line holds, A is called I-interpretable in FT, and the terms b are called
(a tuple of) I-interpreting terms of A.

138
Justus Diller
In this notation, G¨odel proves in [12]
HA
D
,→T
As we identify Peano arithmetic PA with the negative fragment of HA, this implies
PA
D
,→T
Under this deﬁnition, Shoenﬁeld’s translation [17] is, strictly speaking, not a func-
tional translation. We also do not follow [8] where the Shoenﬁeld translation is
considered the prototype of functional translations of classical theories. We rather
concentrate on functional translations which apply to constructive theories as well
as to their classical counterparts, the latter being formulated in an ∃-free fragment. -
For discussions of the conceptual and foundational background, see [2], [6], [8],
and [20]. In [12], G¨odel in particular justiﬁes his choice of the translation of impli-
cations A →B,
(A →B)D ≡∃WY∀vz(AD[v, Wvz] →BD[Yv, z])
by the existence of characteristic terms for AD[v, w], BD[y, z] which are type o for-
mulae of L(T) and hence also decidable in T. In the absence of equality functionals
- which reduce all equations to equations of type o - , this argument does not ex-
tend to Heyting arithmetic in ﬁnite types HAω, the natural span of HA and T. In
HAω, as in T, equations of higher type do not possess characteristic terms, they are
undecidable and yet translated identically: By Howard’s example (cf. [11]), HAω
is not D-interpretable in T. A way out is shown by the ∧-translation which diﬀers
from the Dialectica translation essentially only in the case of implication:
(A →B)∧≡∃XWY∀vz(∀x < Xvz A∧[v, Wxvz] →B∧[Yv, z])
This translation, of course, requires an extension of G¨odel’s theory T by a bounded
universal quantiﬁer ∀x < t to the theory T∧.
The ∧-translation solves a contraction problem: The D-interpretation of
∀wA[w] →A[b] ∧A[c], even for qf A, calls for a term w0 such that
⊢A[w0] →A[b] ∧A[c] which, for undecidable A, may not exist in T. The more
liberal ∧-interpretation, however, calls for terms X and W satisfying
∀x < XA[Wx] →A[b] ∧A[c]. Such terms are X = 2 and W with W0 = a and
W1 = b. More generally, in [11] is shown:
HAω
∧
,→T∧

Functional Interpretations of Classical and Constructive Set Theory
139
Due to the undecidability of equations of higher type, T and T∧have to be extended
by the schema
S tab(=) :≡{¬¬a = b →a = b | a, b terms of the same type}
to yield classical theories T c and T c
∧. Similarly, Peano arithmetic in all ﬁnite types
PAω is the negative fragment of HAω, again extended by the schema S tab(=).
While, as above, we do not have PAω
D
,→T c, we do have
PAω
∧
,→T c
∧
Whereas in [10], we stressed the analogy between functional interpretations of PAω
and KPωω, here we present the ∧-interpretation of CZFω−as an extension of the
∧-interpretation of KPωω.
2
Constructive set functionals
An intuitionistic theory T∈of constructive set functionals in ﬁnite types is ﬁrst de-
veloped by Burr in [4], following a suggestion by A. Weiermann to study transﬁnite
recursors Rτ with higher types τ as a tool for a functional interpretation of Kripke-
Platek set theory. As in G¨odel’s T, types are o and with σ and τ also (σ →τ). c : τ
indicates that c is a term of type τ. Application is type conforming: If a : σ →τ
and b : σ, then (ab) : τ. Basic functionals of T∈will be given below together
with their deﬁning axioms. Within the language of T∈, we distinguish the class of
∆0-formulae:
(1) ∆0-formulae are built up from atomic formulae s ∈t, s = t (s, t : o) and ⊥by
∧, ∨, →, ∀x ∈t, ∃x ∈t.
(2) T∈-formulae are built up from ∆0-formulae and equations
a = b (a, b : τ) by ∧, →, ∀x ∈t.
The logic of T∈is intuitionistic predicate logic with identity, with the laws for
quantiﬁcation restricted to bounded quantiﬁers (cf. [4]). The logic calculus is a
Hilbert-style calculus with ’short’ axioms and rules. It is presented in detail in [4]
and [11] and is essentially the calculus used by G¨odel in [12].
Basic functionals are
1. combinators K, S - we suppress type indices - with axioms
(K) Kab = a
(S) Sabc = ac(bc)

140
Justus Diller
2. arithmetic constants 0 : o, S uc : o →o →o, ω : o with axioms
(0) ∀x ∈0 ⊥
(Suc) S uc s t = s ∪{t}
The standard one-place successor suc is deﬁned by suc t = S uc t t.
(ω)
0 ∈ω ∧∀x ∈ω suc x ∈ω ∧∀x ∈ω (x = 0 ∨∃y ∈ω x = suc y)
3. constants reﬂecting ∆0-logic for union-replacement, intersection, and impli-
cation
U : (o →o) →o →o, Int : o →o →o; Imp : o →o →o →o,
with axioms
(U)
x ∈U ft ↔∃y ∈t x ∈fy, shorthand
U ft =
[
{f x | x ∈t}
(Int) x ∈Int ts ↔x ∈s ∧∀y ∈t x ∈y, shorthand
Int ts = s ∩
\
t
(Imp) x ∈Imp rst ↔x ∈r ∧(x ∈s →x ∈t), shorthand
Imp rst = {x ∈r | x ∈s →x ∈t}
4. ∈-recursors Rτ : ((o →τ) →o →τ) →o →τ require restriction
functionals ↾τ of type (o →τ) →o →o →τ for the formulation of their
deﬁning axioms. The restriction functionals are deﬁned by recursion on τ.
Writing ( f ↾τ t) or just ( f ↾t) for ↾τ ft, their deﬁning equations are:
(f ↾o t)x = U f({x} ∩t)
(f ↾σ→τ t)xuσ = ((λy.fyuσ) ↾τ t)x
The axiom for the ∈-recursor Rτ now is
(R)
Rτht = h((Rτh) ↾τ t)t
Further axioms and rules of T∈are the ∆0-axiom of set-extensionality
(ext)
(∀x ∈s x ∈t ∧∀x ∈t x ∈s) →s = t,
the rule of type-extensionality
(T-EXT)
A →f x = gx ⊢A →f = g with x : τ not in A, f, g,
ﬁnally the rule of transﬁnite or ∈-induction
(T IND)
∀x ∈y F[x] →F[y] ⊢F[t]
for all formulae F[y] of L(T∈).
This completes the description of the theory T∈.

Functional Interpretations of Classical and Constructive Set Theory
141
The classical version of T∈is simply
T c
∈:≡T∈+ S tab(=)
The restriction functionals ↾τ, deﬁned above, satisfy
(1) T∈⊢∀x ∈t (f ↾t)x = f x
(2) T∈⊢∀x ∈t f x = gx →f ↾t = g ↾t
These properties of ↾τ justify its name restriction and also give axiom (R) its intu-
itive meaning.
The constants reﬂecting ∆0-logic allow for a simple proof of an explicit form of
∆0-separation:
2.1 Explicit ∆0-separation. To any ∆0-formula A[x] and any term t : o with x : o
not in t, there exists a separation term {x ∈t | A[x]} : o such that
T∈⊢y ∈{x ∈t | A[x]} ↔y ∈t ∧A[y]
Any ∆0-formula A possesses a characteristic term {0 | A} = {x ∈1 | A} with x not
in A such that
T∈⊢0 ∈{0 | A} ↔{0 | A} = 1 ↔A
For a proof, see [4] or [9].
Thus, every formula A of L(T∈) is equivalent to a negative formula, and
T c
∈⊢¬¬A →A
Ordered pairs ⟨, ⟩and their projections (
)0, (
)1 may be deﬁned as usual. The
disjoint sum {⟨x, y⟩| y ∈Yx, x ∈X} of {Yx | x ∈X} satisﬁes:
2.2 Contraction of bounds. In T∈is provable
∀x ∈X ∀y ∈Yx F[x, y] ↔∀z ∈{⟨x, y⟩| y ∈Yx, x ∈X} F[(z)0, (z)1]
A principle of generalized induction holds in T∈which is the essential technical tool
for a functional interpretation of (T IND). It is closely related to the corresponding
principle in T∧(Satz 1 in [11] ). Its proof requires some recursion and induction
schemata which we state here without proof. As these schemata - like functional
translations - often handle tuples of terms and types, we insert a
Convention on tuple notation
1. If σ is a type tuple σ1, ..., σl and τ is a type tuple τ1, ..., τk then σ →τ denotes
the type tuple σ1 →... →σl →τ1, ..., σ1 →... →σl →τk (associating to the

142
Justus Diller
right). Hence, for l = 0, σ →τ is τ, and for k = 0, σ →τ is empty.
2. If a is a term tuple a1, ..., ak of type tuple σ →τ and b is a term tuple b1, ..., bl
of type tuple σ, then (ab) denotes the term tuple a1b1...bl, ..., akb1...bl (associating
to the left) of type tuple τ.
2.3 Recursion and induction schemata in T∈
Simultaneous ∈-recursion: Given a non-empty type tuple τ = τ0, ..., τn and terms
gi : (o →τ) →o →τi
(i ≤n), there are terms fi : o →τi
(i ≤n) which solve
the n + 1 equations
(S imR)
fit = gi(f0 ↾t)...(fn ↾t)t
(i ≤n)
ω-induction: In T∈is admissible
F[0] , ∀y ∈ω (F[y] →F[suc y]) ⊢t ∈ω →F[t]
Simultaneous ω-recursion: Given τ = τ0, ..., τn and terms ai : τi and
bi : τ →o →τi
(i ≤n), there are terms fi : o →τi
(i ≤n) which solve the n+1
pairs of equations
fi0 = ai
and
∀x ∈ω fi(suc x) = bi(f0x)...(fnx)x
We are now in a position to prove
2.4 Generalized transﬁnite induction. Given a term X, a term tuple W with vari-
ables a, u, x : o and a tuple of variables z, all not in X, W, such that
(1)
T∈⊢∀u ∈a ∀x ∈Xaz B[u, Wxaz] →B[a, z]
Then
T∈⊢B[t, z]
for any term t : o.
Proof. By simultaneous ω-recursion, we deﬁne a term tuple X1, Z depending on z
and a by
Zy0 = z
∀n ∈ω Z⟨x, y⟩(suc n) = Wxa(Zyn)
X10 = 1
∀n ∈ω X1(suc n) = {⟨x, y⟩| x ∈Xa(Zyn), y ∈X1n}
For n ∈ω, we have by contraction of bounds 2.2
(2)
∀u ∈a (∀y ∈X1(suc n) B[u, Zy(suc n)]
↔∀y ∈X1n ∀x ∈Xa(Zyn) B[u, Wxa(Zyn)])
After substituting Zyn for z in (1) and distributing ∀y ∈X1n, we rewrite (1) under
this equivalence as
∀n ∈ω(∀u ∈a ∀y ∈X1(suc n) B[u, Zy(suc n)] →∀y ∈X1n B[a, Zyn])

Functional Interpretations of Classical and Constructive Set Theory
143
This is of a form ∀n ∈ω(∀u ∈a C[u, suc n] →C[a, n]) which implies
T∈⊢∀u ∈a ∀n ∈ωC[u, n] →∀n ∈ωC[a, n]
(T IND) and 0 ∈ω now yield ⊢C[t, 0] ≡∀y ∈X10 B[t, Zy0], i.e. ⊢B[t, z].
3
Functional interpretations of Kripke-Platek set the-
ory
Kripke-Platek set theory (with inﬁnity) KPω (cf. Barwise [3]) is a classical set
theory which lacks strong non-constructive principles like the powerset axiom or
full separation, but still has a considerable expressive power. In a sense, KPω
collects constructive set theoretic principles in a classical theory. We underline this
aspect by ∧-interpreting KPω as well as its ﬁnite type extension KPωω (cf. [5],
[10]), the natural span of KPω and T c
∈, in the classical theory T c
∈.
KPωω is deﬁned as an extension of T c
∈. Its language is the closure of L(T∈) under
∧, →, ∀x ∈t, and ∀uτ for all types τ; its axioms and rules are those of T c
∈, extended
- with the exception of the rule (T-EXT) - to the full language of KPωω, plus the
laws for the universal quantiﬁer and the axiom schema of ∆0-collection:
(∆0-collection)
∀x ∈t ¬∀y¬A[x, y] →¬∀z¬∀x ∈t ∃y ∈z A[x, y]
where A[x, y] is a ∆0-formula and x, y : o
The rule (T-EXT) remains restricted to the language of T∈(weak extensionality).
Being an extension of T c
∈, KPωω inherits several properties from this subtheory:
(1) KPωω enjoys explicit ∆0-separation.
(2) In KPωω, every formula is equivalent to a negative formula.
(3) KPωω ⊢¬¬A →A
for all formulae A of KPωω.
(4) KPωω satisﬁes classical ∃-free predicate logic.
Moreover, it is easily seen:
(5) KPωω is an extension of KPω.
We consider functional translations D and ∧, as they are obviously transferred from
classical arithmetic PAω to KPωω (cf. [10] where this transfer is treated in detail
and which contains some of the material of the present section). To avoid ambigu-
ities, we give a simultaneous deﬁnition of D and ∧on L(KPωω).
Recursive deﬁnition of the Dialectica- and the ∧-translation
Let I stand for the translations D and ∧simultaneously. To any formula A of
KPωω, I assigns an expression AI ≡∃v∀wAI[v, w], with AI[v, w] a formula of

144
Justus Diller
L(T∈) as follows:
(T∈)I
AI ≡A for A ∈L(T∈)
Let AI be as above and BI ≡∃y∀zBI[y, z], then
(∧)I
(A ∧B)I
≡
∃vy∀wz(AI ∧BI)
(→)D
(A →B)D
≡
∃WY∀vz(AD[v, Wvz] →BD[Yv, z])
(→)∧
(A →B)∧
≡
∃XWY∀vz(∀x ∈Xvz A∧[v, Wxvz] →B∧[Yv, z])
in case the tuple w is not empty
(→)∧
0
(A →B)∧
≡
∃Y∀vz(A∧[v] →B∧[Yv, z]) for empty w
(∀∈)I
(∀x ∈t B[x])I
≡
∃Y∀z(∀x ∈t BI[Yx, z])
(∀)I
(∀uA[u])I
≡
∃V∀uwAI[u, Vu, w]
3.1 Proposition. Already the type o theory KPω is not Dialectica interpretable in
T c
∈.
Proof by example. KPω (with a constant 0 for the empty set) proves
∀x(∀y ¬y ∈x →x = 0)
This has the D-translation
∃Y∀x(¬Yx ∈x →x = 0)
Any Y satisfying this formula is necessarily a classical choice function which is not
a constructive set functional.
However, the ∧-translation of this formula is
∃ZY∀x (∀z ∈Zx ¬Yz ∈x →x = 0),
and ∧-interpreting functionals Z, Y are given by Zx = x and Yz = z.
Besides the contraction problem, the ∧-translation also solves a ∆0 ⊂Π1-problem:
Given an L(T∈)-formula A[xo],
KPωω ⊢∀y(y ∈t →A[y]) →∀y ∈t A[y]
The D-translation of this formula calls for a term s satisfying
(s ∈t →A[s]) →∀y ∈t A[y] which may not exists in T∈, as the example shows.
The ∧-translation, however, is (equivalent to)
∃Y(∀y ∈Y(y ∈t →A[y]) →∀y ∈t A[y])
and is therefore ∧-interpreted by Y = t.

Functional Interpretations of Classical and Constructive Set Theory
145
Here we made use of a simpliﬁcation of the ∧-translation:
3.2 Lemma. A formula ∀y A[y] →B with A, B in L(T∈), y : o may be ∧-translated
as
∃Y(∀y ∈Y A[y] →B)
without changing the concept of ∧-interpretability.
Proof. (∀y A[y] →B)∧is literally ∃XY′(∀x ∈X A[Y′x] →B). Y is obtained from
X, Y′ by putting Y = {Y′x | x ∈X}, and X, Y′ are obtained from Y by X = Y and
Y′x = x. Moreover, in the translation of longer formulae, the tuple of variables
X, Y′ and the variable Y are handled the same way.
3.3 ∧-Interpretation Theorem for KPωω
KPωω
∧
,→T c
∈
Proof by induction on deductions. The ∧-interpretation of the logic of KPωω, in-
cluding identity, may be taken over from [11], replacing < by ∈, augmented by the
above solution of the ∆0 ⊂Π1-problem. Results from T∧which are used there have
to be transferred to T∈. That, however, is easily done, in particular by exploiting
explicit ∆0-separation 2.1 and contraction of bounds 2.2 (cf. [4], [5], and [10]).
Axioms and rules of T c
∈, including type extensionality (T-EXT) are all interpreted
by the empty tuple. Only (T IND) and ∆0-collection remain to be ∧-interpreted.
(T IND) ∀u ∈a F[u] →F[a] ⊢F[t]
By I.H., there are terms and term tuples X, W, Y0 such that
(1)
T c
∈⊢∀x ∈Xavz ∀u ∈a F∧[u, vu, Wxavz] →F∧[a, Y0va, z]
We deﬁne terms Y by simultaneous transﬁnite recursion 2.3
Ya = Y0(Y ↾a)a,
substitute Y ↾a for v in (1), and obtain
T c
∈⊢∀x ∈Xa(Y ↾a)z ∀u ∈a F∧[u, Yu, Wxa(Y ↾a)z] →F∧[a, Ya, z]
Here, the terms Xa(Y ↾a)z, Wxa(Y ↾a)z are terms X′az, W′xaz, and F∧[a, Ya, z]
is a formula B[a, z] satisfying (1) in proposition 2.4. So, by generalized transﬁnite
induction, T c
∈⊢F∧[t, Yt, z].
The ∧-translation of the schema of (∆0-collection) is, simpliﬁed by an application
of lemma 3.2,
∃Z∀Y(∀x ∈t ∃y ∈Yx A[x, y] →∃z ∈ZY∀x ∈t ∃y ∈z A[x, y])

146
Justus Diller
Given Y satisfying the antecedent, there is one canonical z satisfying the conse-
quent, namely z = S{Yx | x ∈t} = UYt. (∆0-collection) is therefore ∧-interpreted
by the term Z with the value ZY = {UYt}.
This completes the proof of the ∧-interpretation theorem. For related proofs using,
however, diﬀerent translations, cf. [5], [7]. An immediate consequence is:
3.4 Conservativity and relative consistency. KPωω is a conservative extension of
T c
∈. The consistency of T c
∈implies the consistency of KPωω.
In order to characterize a functional translation I in a classical theory Th, it must
be kept in mind that an expression AI ≡∃v∀wAI[v, w] is, for non-empty tuple v,
not a formula in L(Th). Instead, one has to consider its negative version
AI−≡¬∀v¬∀wAI[v, w],
and the schema to be characterized is {A ↔AI−}. This complicates the situation
in comparison to the constructive case. For I = D and the type o fragment PAω
0 of
Peano arithmetic in ﬁnite types PAω, this schema is characterized by
(qf −AC)
∀x¬∀y¬A[x, y] →¬∀Y¬∀x A[x, Yx]
with A[x, y] in L(T0) and non-empty tuples x, y of variables,
which is (AC)−with quantiﬁer free matrix A:
3.5 Proposition (Kreisel [13]). PAω
0 + (qf −AC) ≡PAω
0 + {A ↔AD−}
Up to a double negation, (qf −AC) - which, with A in L(T∈), may also be read as
an axiom schema in KPωω - is of the form
B →BD−with B ≡(∀x∃y A[x, y])−
Similarly, for A in L(T∈) and tuples x, y as above, let
(qf −ARC)
∀x¬∀y¬A[x, y] →¬∀S, Y¬∀x¬∀s ∈S x ¬A[x, Ysx]
This quantiﬁer free axiom of restricting choice is literally of the form
B →B∧−with B ≡(∀x∃y A[x, y])−. We therefore put
(q f −ACD) :≡(qf −AC) and (qf −AC∧) :≡(qf −ARC)
and let (q f −ACI) refer to either.
3.6 Lemma. For A, B, A[u] in L(KPωω), u a - possibly empty - tuple of variables,
KPωω proves:
1. AI−↔A for A in L(T∈)
2. (A ∧B)I−↔AI−∧BI−
3. (A →B)I−→AI−→BI−

Functional Interpretations of Classical and Constructive Set Theory
147
4. (∀u¬A[u])I−→∀u¬(A[u])I−; furthermore
5. KPωω + (q f −ACI) ⊢∀u¬(A[u]I−) →(∀u¬A[u])I−
Since prenex formulae B are of the form ∀u1¬...∀un¬C[u1, ..., un] with n ≥0, -
possibly empty - tuples u1, ..., un of variables, and C[u1, ..., un] ∈L(T∈), this lemma
implies:
3.7 Partial characterization of I = D and I = ∧
KPωω + (qf −ACI) ≡KPωω + {B ↔BI−| B prenex}
Proof. Let B be prenex as above. Then KPωω + (qf −ACI) ⊢B ↔BI−follows by
1. and n applications of 4. and 5. in Lemma 3.6.
Conversely, the schema (qf −ACI), as mentioned above, is a set of formulae B →
BI−with prenex B.
Due to the ∧-interpretation theorem 3.3, this implies for I = ∧:
3.8 Characterization theorem for ∧on KPωω
KPωω + (qf −ARC) ≡KPωω + {A ↔A∧−}
Proof. For A ∈L(KPωω), let B be a prenex normal form of A. Then
KPωω ⊢A ↔B . Therefore, by theorem 3.3,
KPωω ⊢(A ↔B)∧−, which by 2. and 3. in 3.6 implies
KPωω ⊢A∧−↔B∧−, and, as shown in 3.7,
KPωω + (q f −ARC) ⊢B ↔B∧−
Put together, these equivalences imply
KPωω + (qf −ARC) ⊢A ↔A∧−
3.9 Corollary. KPωω + (qf −ARC) proves any formula ∧-interpretable in T c
∈.
It may be conjectured that KPωω + (qf −ARC) ⊬(qf −AC) and that therefore
(qf −AC) is not ∧-interpretable in T c
∈. On the other hand, it can be shown:
3.10 Extended ∧-Interpretation Theorem for KPωω
KPωω + (qf −ARC)
∧
,→T c
∈
As stated above, this proof does not transfer to a Dialectica interpretation in T c
∈,
even of KPω only. Following Burr-Hartung [7], we therefore extend the theory T c
∈
by a non-constructive choice function.
3.11 The axiom of uniform choice
Let FC be a new constant of type o →o with the axiom

148
Justus Diller
(uniform AC)
x # 0 →FCx ∈x
t#0, read: t is inhabited, stands for ∃y ∈t y = y.
The extension of the type o fragment of T c
∈by this axiom suﬃces for a Dialectica
interpretation of KPω, even of the type o fragment of KPωω:
3.12 Dialectica interpretation theorem
KPωω
0 + (uniform AC)
D
,→T c
∈0 + (uniform AC)
The proof by induction on deductions parallels the proof of the ∧-interpretation the-
orem above and is, in some aspects, technically simpler. In particular, the induction
steps for
A3
A →B, B →C ⊢A →C
and for (T IND) are special cases of the corresponding steps in 3.3, with the given
bounds being equal to 1. Two induction steps, however, those for contraction A7
and for introduction of the bounded universal quantiﬁer Q3b, require new argu-
ments.
A7
A →B, A →C ⊢A →B ∧C.
By I.H., there are term tuples W1, Y1 and W2, Y2 D-interpreting A →B and A →C,
i.e.
⊢AD[v, W1vz1] →BD[Y1v, z1] and ⊢AD[v, W2vz2] →CD[Y2v, z2]
We look for a term tuple W with
⊢BD[Y1v, z1] →Wvz1z2 = W2vz2 and ⊢¬BD[Y1v, z1] →Wvz1z2 = W1vz1,
because, for such a W,
⊢¬BD[Y1v, z1] →AD[v, Wvz1z2] →⊥and
⊢BD[Y1v, z1] →AD[v, Wvz1z2] →CD[Y2v, z2],
hence, by classical logic,
⊢AD[v, Wvz1z2] →BD[Y1v, z1] ∧CD[Y2v, z2]
Since BD is ∆0, by 2.1, the term tuple W can be deﬁned by
Wvz1z2 = Dτ(W1vz1)(W2vz2){0 | BD[Y1v, z1]}
with Dτ a tuple of case distinction functionals of appropriate type tuple τ. Then
W, Y1, Y2 D-interpret A →B ∧C. - This argument, cut back to Heyting arithmetic
HA, is in fact G¨odel’s original argument for his Dialectica interpretation of A7. It
depends on the formula B being of type o.
Q3b
A →y ∈t →B[y] ⊢A →∀y ∈t B[y].
By I.H., there are term tuples W′, Y such that

Functional Interpretations of Classical and Constructive Set Theory
149
⊢AD[v, W′vyz] →y ∈t →BD[y, Yvy, z].
This certainly implies
⊢∀y ∈t AD[v, W′vyz] →∀y ∈t BD[y, Yvy, z].
If the antecedent of this implication does not hold, then we pick a y ∈t such that
¬AD[v, W′vyz] by applying the choice function FC, that is, we deﬁne
Wvz = W′v(FC{y ∈t | ¬AD[v, W′vyz]})z
and obtain ⊢¬∀y ∈t AD[v, W′vyz] →AD[v, Wvz] →⊥. These two implications
imply by classical logic
⊢AD[v, Wvz] →∀y ∈t BD[y, Yvy, z]
(uniform AC) is D-interpreted trivially. That completes the Dialectica interpretation
of KPωω
0 + (uniform AC).
By an argument analogous to the proof of the ∧-characterization theorem 3.7, it can
be shown:
3.13 Characterization theorem for the D-translation
KPωω
0 + (uni form AC) + (qf −AC) ≡KPωω
0 + (uniform AC) + {A ↔AD−}
Any formula D-interpretable in T c
∈0 is derivable in KPωω
0 + (uniform AC) + (qf −
AC).
Moreover, also the Dialectica interpretation extends to this larger theory, in analogy
to 3.10:
3.14 Extended D-interpretation theorem
KPωω
0 + (uniform AC) + (qf −AC)
D
,→T c
∈0 + (uniform AC)
4
Functional interpretations of Constructive Set The-
ory
Constructive set theory CZF goes back to Myhill [14] and Aczel [1]. Its schema
of subset collection, as shown by Burr [4], needs an additional fullness functional
for a functional interpretation. Here we consider its subtheory CZF−which is CZF
without subset collection. Its ﬁnite type version CZFω−is again deﬁned as an
extension of T∈. Its language is the closure of L(T∈) under ∧, →, ∀x ∈t, and under
unbounded quantiﬁers ∀xτ, ∃xτ for ﬁnite types τ. The bounded existential quantiﬁer

150
Justus Diller
∃x ∈t and disjunction ∨are primitive connectives only within ∆0-formulae. The
logic is intuitionistic predicate logic with identity. The only axiom schema added
to T∈is
(Strong collection)
∀x ∈a ∃y F[x, y] →∃b F′[a, b]
where
F′[a, b] ≡∀x ∈a ∃y ∈b F[x, y] ∧∀y ∈b ∃x ∈a F[x, y]
The rule (T IND) is extended to the full language of CZFω−, whereas the rule (T
-EXT) remains restricted to the language of T∈.
As explicit versions of the axioms of Inﬁnity, Pair, Union and of the schema of
∆0-Separation of CZF are derivable already in T∈, we see:
4.1 Lemma. CZFω−is an extension of CZF−.
A detailed ∧-interpretation of CZFω−is presented in [9]. We refer to this source
for most of the proofs. The ﬁrst functional interpretation of CZFω−is given by
Burr [4], based on his ×-translation improved by Schulte [16]. We extend the ∧-
translation of KPωω by a clause for the existential quantiﬁer which we take over
from Schulte’s ×-translation in [16].
For A[u]∧≡∃v∀wA∧[u, v, w], the clause runs:
(∃)∧
(∃uA[u])∧≡∃XUV∀w(X#0 ∧∀x ∈X A∧[Ux, Vx, w])
Due to this clause, we do not have A∧∧≡A∧for all A, but one easily sees:
4.2 Lemma. 1. If A ≡∀wB with B ∈L(T∈), then A∧≡A.
2. CZFω−⊢(A ∧B)∧↔A∧∧B∧
3. CZFω−⊢(∃uA[u])∧↔∃u(A[u])∧
4. CZFω−⊢A∧∧↔A∧
4. follows from 1. by iterated application of 3.
The ∧-translation of implication given in section 3 solves the
∆0 ⊂Π1-problem for CZFω−in the same way as for KPωω. Its dual is a
∆0 ⊂Σ1-problem: a ∆0-formula ∃x ∈t A[x] may be read as a Σ1-formula
∃x(x ∈t ∧A[x]) with an unbounded quantiﬁer ∃x, having a diﬀerent translation
again. A Dialectica-like translation D of the implication
B ≡∃x ∈t A[x] →∃x(x ∈t ∧A[x])
would lead to a matrix
BD ≡∃x ∈t A[x] →(s ∈t ∧A[s]) ,

Functional Interpretations of Classical and Constructive Set Theory
151
and an interpreting term s which - unlike the situation in arithmetic where
s = µy < t A[y] is a primitive recursive solution - again requires the choice function
FC (cf. 3.11), since
T∈⊢∃x ∈t A[x] →{x ∈t | A[x]}#0 :
T∈+ (uniform AC) ⊢BD
for
s = FC{x ∈t | A[x]}
An adequate translation is given in [4] and [16] by the ×-translation which in this
case coincides with the ∧-translation above: In translating ∃xoC[x] with C[x]∧≡
C[x], one basically looks for an inhabited set X such that all elements x ∈X satisfy
C[x]: There is no need to pick an element from the set X.
For the above B, this asks for a set X satisfying
B∧≡∃x ∈t A[x] →X#0 ∧∀x ∈X(x ∈t ∧A[x])
Obviously, in this case, the ∆0-set X = {x ∈t | A[x]} will do.
So it is just the introduction of an inhabited bound X and of the combination
X#0∧∀x ∈X that solves the ∆0 ⊂Σ1-problem. In general, in translating ∃uA[u], the
variable u may be of arbitrary type τ and the translation of A[u] may already start
with some existential quantiﬁers. Here, we follow [16] in deﬁning (∃uA[u])∧as
above, with the variable X bounding all of U, V. The special case above, however,
is compatible with the general clause (∃)∧:
4.3 Lemma. ∃x A[x] with A[x] ∈L(T∈), x : o may be ∧-translated as
∃X(X#0 ∧∀x ∈X A[x])
without changing the concept of ∧-interpretability.
The proof parallels the proof of lemma 3.2.
Looking at (→)∧and (∃)∧, we see that every existential variable in the preﬁx of
A∧- which is not itself a bound - has an accompanying bound, inhabited or not.
Therefore, if an additional inhabited bound is added in front of A∧, it may, after
distribution over the subformulae of A∧, be contracted with the bounds already
present and be ﬁnally absorbed altogether:
4.4 Lemma on absorption of bounds. Let A∧be ∃v∀wA∧[v, w]. Given terms S, V
(not containing variables from w) there are terms v0 (also not containing variables
from w) such that
T∈⊢S #0 ∧∀s ∈S A∧[Vs, w] →A∧[v0, w]
For a proof, we refer to [9]. A weaker version of this lemma, adapted to the ×-
translations, appears in [4] and [16] as ’distribution lemma’. The absorption lemma

152
Justus Diller
is useful in the proof of
4.5 ∧-Interpretation Theorem for CZFω−
CZFω−
∧
,→T∈
Proof by induction on deductions. The ∧-interpretation of the axioms and rules
of the negative fragment of logic with identity, including (T IND), is the same as
for KPωω in 3.3. As the axioms and rules of T∈, including (T-EXT), are inter-
preted trivially, the only laws that still have to be ∧-interpreted are those governing
disjunction, (bounded and unbounded) existential quantiﬁcation, and (Strong Col-
lection). Here, we consider the laws for disjunction.
As disjunctions occur only between ∆0-formulae, A →A∨B and B →A∨B are ∆0
and hence interpreted by the empty tuple. To illustrate the impact of the absorption
lemma, we look at
A0 →B, A1 →B ⊢A0 ∨A1 →B
Here, A0, A1 are again ∆0, and let B∧≡∃y∀z B∧[y, z]. By I.H. and case distinction,
we have terms Y such that for i ∈2
T∈⊢Ai →B∧[Yi, z]
By ∆0-separation, we deﬁne a bound S := {x ∈1 | A0} ∪{x ∈{1} | A1}.
For this S ⊂2, T∈⊢A0 ∨A1 →S #0 and T∈⊢∀s ∈S B∧[Ys, z], hence
T∈⊢A0 ∨A1 →S #0 ∧∀s ∈S B∧[Ys, z]
By absorption of bounds 4.4, there are terms y0 such that
T∈⊢A0 ∨A1 →B∧[y0, z] :
a combination of ∆0-separation and absorption of bounds gives us the term tuple y0
∧-interpreting A0 ∨A1 →B .
For the interpretation of laws governing the existential quantiﬁer and of the schema
of (Strong collection), we refer to [9].
Since ∧is the identity on L(T∈), the ∧-interpretation theorem implies:
4.6 Corollary. CZFω−is a conservative extension of T∈. The consistency of T∈
implies the consistency of CZFω−.
As in HAω, we adapt Markov’s rule to the ∧-translation so that its conclusion is the
∧-translation of its premise. Admissibility of this rule is then also an immediate
consequence of the ∧-interpretation theorem:

Functional Interpretations of Classical and Constructive Set Theory
153
4.7 Corollary. (Rule-M∈) is admissible in CZFω−:
(Rule-M∈) If ⊢∀wA[w] →B with A, B ∈L(T∈), then
⊢∃XW(∀x ∈X A[Wx] →B)
In contrast to the situation in KPωω, the schema {A ↔A∧} is axiomatized on the
basis of CZFω−along the same lines as in HAω. Due to the ’weak’ translation (∃)∧
of the existential quantiﬁer, however, choice appears here only as a weak axiom of
choice (WAC) which still carries more constructive information than the schema
(ARC) in the previous section.
4.8 The theory CZFω+
WIP∈
(∀wA →∃yB[y]) →∃XY(∀wA →X#0 ∧∀x ∈X B[Yx])
for A ∈L(T∈)
M∈
(∀wA[w] →B) →∃XW(∀x ∈X A[Wx] →B) for A, B ∈L(T∈)
WAC
∀x∃yA[x, y] →∃S Y∀x(S x#0 ∧∀s ∈S x A[x, Ysx])
Here, w, y, and in WAC also x are to be read as tuples of variables of arbitrary type.
Bounds X, S x are single variables resp. terms of type o.
CZFω+ :≡CZFω−+ WIP∈+ M∈+ WAC
In analogy to the characterization of ∧on HAω (cf. [11]), we obtain:
4.9 Characterization Theorem
CZFω+ ≡CZFω−+ {A ↔A∧}
Since CZFω−⊢A∧→B∧implies that A →B is ∧-interpretable in T∈, the charac-
terization theorem implies:
4.10 Extended ∧-Interpretation Theorem
CZFω+
∧
,→T∈
Also CZFω+ is a conservative extension of T∈.The consistency of T∈implies the
consistency of CZFω+.
In order to show closure of CZFω−under relevant rules beyond (Rule-M∈), a hybrid
tranlation is studied in [16] which we present as a q-hybrid ∧q which is related to
∧as modiﬁed q-realizability mq is related to modiﬁed realizability mr in [19] by
Troelstra. The clauses distinguishing it from the ∧-translation are:
(→)∧q
(A →B)∧q ≡∃XWY∀vz(A ∧∀x ∈XvzA∧q[v, Wxvz] →B∧q[Yv, z])

154
Justus Diller
(∃)∧q
(∃uA[u])∧q ≡∃XUV∀w(X#0 ∧∀x ∈X(A[Ux] ∧A∧q[Ux, Vx, w]))
Also for this translation, lemma 4.4 on absorption of bounds holds, and in analogy
to the ∧q-interpretation of HAω (cf. Stein [18]), Schulte [16] essentially shows:
4.11 ∧q-Interpretation Theorem
CZFω−∧q
,→CZFω−
The proof parallels the proof of the ∧-interpretation theorem 4.5. Even more: The
same term-tuples ∧- and ∧q-interpret the theorems of CZFω−. For details, see [16],
though there the theorem is proved for a ×q-translation.
As the ∧q-translation ’remembers’ more of the translated formulae than the ∧-
translation, we obtain admissibility of rules beyond (Rule-M∈):
4.12 Proposition CZFω−satisﬁes weak existential deﬁnability (WED) and is
closed under rules of weak choice and of weak independence of premise:
(WED) If CZFω−⊢∃yτA[y], then there are terms S : o, Y : o →τ s.t.
CZFω−⊢S #0 ∧∀s ∈S A[Ys]
(Rule-WAC) If CZFω−⊢∀xσ∃yτA[x, y], then there are terms S, Y s.t.
CZFω−⊢S x#0 ∧∀s ∈S x A[x, Yxs]
(Rule-WIP∈) If CZFω−⊢∀wA[w] →∃yB[y] with A ∈L(T∈), then there are terms
X, Y s.t.
CZFω−⊢∀wA[w] →X#0 ∧∀x ∈XB[Yx]
One may ask whether we could not do better and get rid of the inhabited bounds
that occur in and weaken these three admissibility statements: Could we not prove
(ED) instead of (WED)? At least, (WED) reduces the problem of (ED) in general
to the question of (ED) for inhabited sets [16]:
4.13 Lemma If for every term S : o for which T∈⊢S #0, there is a term t : o such
that T∈⊢t ∈S , then CZFω−satisﬁes (ED):
(ED) If CZFω−⊢∃yτA[y], then there is a term b : τ s.t.
CZFω−⊢A[b]
The argument above which led us to translate the existential quantiﬁer according to
(∃)∧does not decide the question, but it leaves little hope for establishing (ED) for
CZFω−:

Functional Interpretations of Classical and Constructive Set Theory
155
4.14 Conjecture (¬ED) There is a term S : o such that T∈⊢S #0, but for no term
t
T∈⊢t ∈S .
In the forthcoming paper [15], M. Rathjen proves the existence property (EP) for
CZF−, a version of (ED) for sentences only:
4.15 Theorem (Rathjen) CZF−has the existence property:
(EP) If CZF−proves a sentence ∃x A[x], then there is a formula C[x] with exactly
x free, such that
CZF−⊢∃!x(C[x] ∧A[x])
It may be conjectured that this result transfers from CZF−to CZFω−and from set
variables x to variables of arbitrary ﬁnite type, and that - in the richer language of
CZFω−- the deﬁning formula C[x] may be chosen to be simply x = b for some
functional b of T∈. That would imply that CZFω−satisﬁes (ED) for sentences
∃yτA[y]. Yet, conjecture 4.14 may still hold for some term S : o containing free
parameters.
References
[1] Aczel, P.H.G.: The type theoretic interpretation of constructive set theory, in:
A. McIntyre, L. Pacholski, J. Paris (Eds.), Logic Colloquium ’77, North Holland,
Amsterdam 1978, 55 - 66.
[2] Avigad, J., and S. Feferman: G¨odel’s functional (’Dialectica’) interpretation,
in: S. Buss (Ed.), Handbook of Proof Theory, Studies in Logic and the Foundations
of Mathematics, Vol. 137, Elsevier, Amsterdam 1998, 337 - 406.
[3] Barwise, J.: Admissible Sets and Structures, Springer-Verlag, Berlin Heidel-
berg New York 1975.
[4] Burr, W.: Functional interpretation of Aczel’s constructive set theory, APAL
104 (2000) 31 - 73.
[5] Burr, W.: A Diller-Nahm-style functional interpretation of KPω, Arch. Math.
Logic 39 (2000) 599 - 604.
[6] Burr, W.: Concepts and aims of functional interpretations: Towards a functional
interpretation of constructive set theory, Synthese 133 (2002) 257 - 274.
[7] Burr, W., and V. Hartung: A characterization of Σ1-deﬁnable functions of
KPω + (uniformAC), Arch. Math. Logic 37 (1998) 199 - 214.

156
Justus Diller
[8] Diller, J.: Logical problems of functional interpretations, APAL 114 (2002) 27
- 42.
[9] Diller, J.: Functional interpretations of constructive set theory in all ﬁnite types.
Dialectica 62 (2008) 149 - 177.
[10] Diller, J.: Functional interpretations of classical systems, in: R. Schindler
(Ed.), Ways of Proof Theory, Ontos Mathematical Logic, vol. 2, Ontos Verlag,
Heusenstamm 2010, 241 - 255.
[11] Diller, J., and W. Nahm: Eine Variante zur Dialectica-Interpretation der
Heyting-Arithmetik endlicher Typen, Arch. Math. Logik Grundl. 16 (1974) 49 -
66.
[12] G¨odel, K.:
¨Uber eine bisher noch nicht ben¨utzte Erweiterung des ﬁniten
Standpunktes, Dialectica 12 (1958) 280 - 287.
[13] Kreisel, G.: Interpretation of analysis by means of constructive functionals
of ﬁnite type, in: A. Heyting (Ed.), Constructivity in Mathematics, North Holland
Publ. Co., Amsterdam 1959, 101 - 128.
[14] Myhill, J. 1975: Constructive set theory, J. Symb. Logic 40 (1975) 347 - 382.
[15] Rathjen, M.: The weak existence property as a path to the strong existence
property. To appear.
[16] Schulte, D.: Hybrids of the ×-translation for CZFω, J. Applied Logic 6 (2008)
443 - 458.
[17] Shoenﬁeld, J.R.:
Mathematical Logic, Addison-Wesley Publ.
Comp.,
Reading, MA, 1967.
[18] Stein, M.:
Eine Hybrid-Interpretation der Heyting-Arithmetik endlicher
Typen, Master’s thesis, University of M¨unster, 1974.
[19] Troelstra, A.S.: Metamathematical investigation of intuitionistic arithmetic
and analysis, Lecture Notes in Mathematics 344, Springer, Heidelberg/New York
1973.
[20] Troelstra, A.S.: Introductory Note to 1958 and 1972, in: K. G¨odel, Collected
Works, vol. II, Publications 1938 - 1974, S. Feferman (Ed.), The Clarendon Press,
Oxford University Press, New York 1990.

Weak Theories of Truth and Explicit
Mathematics
Sebastian Eberhard and Thomas Strahm∗
Dedicated to Helmut Schwichtenberg on his retirement
We study weak theories of truth over combinatory logic and their relation-
ship to weak systems of explicit mathematics. In particular, we consider two
truth theories TPR and TPT of primitive recursive and feasible strength. The
latter theory is a novel abstract truth-theoretic setting which is able to interpret
expressive feasible subsystems of explicit mathematics.
1
Introduction
The theories of truth and explicit mathematics considered in this article are all based
on a common applicative ground language for operations in the sense of combina-
tory logic; operations can freely be applied to other operations and strong principles
of recursion are available due to the known expressivity of combinatory algebras.
The ﬁrst order applicative base describes the operational core of Feferman’s ex-
plicit mathematics, cf. [17, 18, 19]; instead of a predicate N for natural numbers
we will consider a predicate W in order to single out those operations which denote
binary words.
Types (or classiﬁcations) in explicit mathematics are extensional collections of
operations. They are generated successively and linked to the applicative ground
structure by a naming relation: the names of a type constitute its intensional or
computational representations. The interplay of types and names on the level of
combinatory operations makes the framework of explicit mathematics very expres-
sive.
An alternative means to extend ﬁrst order applicative theories by a typing dis-
cipline is to extend them by a unary truth predicate T and interpret naive set theory
by stipulating x ∈a as T(ax). The so-obtained axiomatic frameworks of partial,
∗Research supported by the Swiss national Foundation.

158
Sebastian Eberhard and Thomas Strahm
self-referential truth are rooted in Kripke’s seminal work and also yield an inter-
pretation of classical Frege structures (cf. Aczel [1], Beeson [3], and Hayashi and
Kobayashi [27]). For detailed background on the type of truth theories considered
here, see Cantini [6, 7] and Kahle [30, 31]. Of course, the work on axiomatic truth
over combinatory logic is also strongly related to corresponding work in the area of
arithmetical truth theories, see e.g. Feferman [15, 21], Friedman and Sheard [25],
and Halbach [26].
The focus of the present paper is to discuss various weak (positive) truth the-
ories and systems of explicit mathematics as well as their mutual relationship.
Namely we will address two families of theories, capturing the primitive recur-
sive and polynomial time computable functions, respectively. We will see that the
truth theories can interpret corresponding systems of explicit mathematics very di-
rectly, whereas reverse embeddings of truth theories into explicit mathematics are
more elaborate and require additional assumptions.
A further novelty of this paper is the introduction of a natural feasible truth
theory TPT, whose provably total operations are the polynomial time computable
ones, as is shown in Eberhard [12]. TPT can only reﬂect initial segments of the
class W of binary words, but features unrestricted truth induction; it is obtained
as a natural restriction of a truth theory TPR of the strength of primitive recursive
arithmetic. Moreover, TPT can interpret very expressive feasible systems of explicit
mathematics.
We conclude the introduction with a detailed outline of the paper. In Section
2 we will introduce the basic applicative framework which is common to all sys-
tems studied in this paper. Section 3 presents the two central truth theories of this
paper, TPR and TPT. The ﬁrst one was previously introduced in Cantini [7, 10].
Both systems rely on a form of positive truth and embody truth induction. Whereas
TPR can reﬂect the whole predicate W of binary words, TPT only reﬂects initial
segments. In Section 4 we will present two natural systems of explicit mathemat-
ics of polynomial and primitive recursive strength, respectively: the system PETJ
of Spescha and Strahm [36, 37, 38] and a natural explicit system EPCJ; both of
these frameworks are direct subsystems of Feferman’s EM0 plus the join princi-
ple (cf. [17, 19]). For the embedding of truth theories into explicit mathematics,
further principles will be needed, for example, the existence of universes, and Can-
tini’s uniformity principle. Section 5 will be devoted to mutual embeddings of weak
truth theories and systems of explicit mathematics. Firstly, we will see that PETJ
and EPCJ are very directly contained in TPT and TPR, respectively. The reverse
embeddings are more diﬃcult: (i) for the direct embedding of TPR into EPCJ we
assume the existence of a universe and the uniformity principle; (ii) the reduction
of TPT to PETJ proceeds via an intermediate leveled truth theory, which in turn can
be directly modeled in an extension of PETJ by universes. In Section 6 we turn

Weak Theories of Truth and Explicit Mathematics
159
to an extended discussion of the proof theory of the systems considered in this pa-
per; this includes the review of some known results and a discussion of work under
preparation, namely Eberhard’s novel realizability interpretation of TPT, which also
yields that the extensions of the systems of explicit mathematics mentioned before
do not raise the proof-theoretic strength. We conclude this article with an outlook
of future work, namely the application of the feasible truth theory TPT in order
to obtain proof-theoretic upper bounds for the unfolding of schematic systems of
feasible arithmetic.
2
The basic applicative framework
The theories of truth and explicit mathematics studied in this paper are based on
a common applicative base theory. It includes the axioms for a partial or total
combinatory algebra and a basic data type of binary words.
2.1
The applicative language L
Our basic language L is a ﬁrst order language for the logic of partial terms which
includes:
• variables a, b, c, x, y, z, u, v, f, g, h, . . .
• constants k, s, p, p0, p1, dW, ϵ, s0, s1, pW, c⊆, ∗, ×
• relation symbols = (equality), ↓(deﬁnedness), W (binary words)
• arbitrary term application ◦
The meaning of the constants will become clear in the next paragraph.
The terms (r, s, t, p, q, . . . ) and formulas (A, B,C, . . . ) of L are deﬁned in the
expected manner. We assume the following standard abbreviations and syntactical
conventions:
t1t2 . . . tn
:=
(. . . (t1 ◦t2) ◦· · · ◦tn)
s(t1, . . . , tn)
:=
st1 . . . tn
t1 ≃t2
:=
t1↓∨t2↓→t1 = t2
⟨t⟩
:=
t
⟨t1, . . . , tn+1⟩
:=
p⟨t1, . . . , tn⟩tn+1
t ∈W
:=
W(t)
t : Wk →W
:=
(∀x1 . . . xk ∈W)tx1 . . . xk ∈W

160
Sebastian Eberhard and Thomas Strahm
s ≤t
:=
c⊆(1×s, 1×t) = 0
s ≤W t
:=
s ≤t ∧s ∈W
In the following we often write A[⃗x] in order to indicate that the variables ⃗x =
x1, . . . , xn may occur free in A. Finally, let us write w for the canonical closed L
term denoting the binary word w ∈W.
2.2
The basic theory of operations and words B
The applicative base theory B has been introduced in Strahm [40, 41]. Its logic is
the classical logic of partial terms due to Beeson [2, 3]. The non-logical axioms of
B include:
• partial combinatory algebra:
kxy = x,
sxy↓∧sxyz ≃xz(yz)
• pairing p with projections p0 and p1
• deﬁning axioms for the binary words W with ϵ, the binary successors s0, s1
and the predecessor pW
• deﬁnition by cases dW on W
• initial subword relation c⊆
• word concatenation ∗, word multiplication ×1
These axioms are fully spelled out in [40, 41]. Below we will be mainly interested
in extensions of B by the axioms of totality of application and extensionality of
operations:
Totality of application:
(∀x)(∀y)(xy↓)
(Tot)
Extensionality of operations:
(∀f)(∀g)[(∀x)( f x ≃gx) →f = g]
(Ext)
Observe that in the presence of the totality axiom, the logic of partial terms reduces
to ordinary classical predicate logic. In the following we write B+ for the extension
of B by (Tot) and (Ext).
1x×y signiﬁes the length of y fold concatenation of x with itself; note that we write x×y instead of
×xy.

Weak Theories of Truth and Explicit Mathematics
161
Various extensions of B or B+ by suitable induction principles on W have been
proposed in the past. Most relevant for the systems studied in this article are the
theories PT and PR, cf. Strahm [41]. The former includes a form of bounded
induction, namely Σb
W induction, whereas the latter features induction for arbitrary
positive formulas.
Let us turn to the crucial consequences of the axioms about a partial combina-
tory algebra. For proofs of these standard results, the reader is referred to Beeson
[3] or Feferman [17].
Lemma 1 (Explicit deﬁnitions and ﬁxed points).
1. For each L term t there exists an L term (λx.t) so that
B ⊢(λx.t)↓∧(λx.t)x ≃t
2. There is a closed L term ﬁx so that
B ⊢ﬁxg↓∧ﬁxgx ≃g(ﬁxgx)
Let us quickly remind the reader of two standard models of B, namely the
recursion-theoretic model PRO and the term model M(λη). For an extensive dis-
cussion of many more models of the applicative basis, the reader is referred to
Beeson [3] and Troelstra and van Dalen [43].
Example 2 (Recursion-theoretic model PRO). Take the universe of binary words
W = {0, 1}∗and interpret application ◦as partial recursive function application in
the sense of ordinary recursion theory.
Example 3 (The open term model M(λη)).
Take the universe of open λ terms
and consider the usual reduction of the extensional untyped lambda calculus λη,
augmented by suitable reduction rules for the constants other than k and s. Interpret
application as juxtaposition. Two terms are equal if they have a common reduct
and W denotes those terms that reduce to a “standard” word w. Note that M(λη)
satisﬁes both (Tot) and (Ext).
2.3
Provably total functions
We intend to measure the proof-theoretic strength of all the systems treated in this
article by ascertaining their provably total functions. In the following let L be
a language extending our ﬁrst-order language L. The notion of a provably total
function is introduced for an arbitrary L theory Th.

162
Sebastian Eberhard and Thomas Strahm
Deﬁnition 4. A function F : Wn →W is called provably total in an L theory Th,
if there exists a closed L term tF such that
(i) Th ⊢tF : Wn →W and, in addition,
(ii) Th ⊢tFw1 · · · wn = F(w1, . . . , wn) for all w1, . . . , wn in W.
The notion of a provably total word function is divided into two conditions (i)
and (ii). The ﬁrst condition (i) expresses that tF is a total operation from Wn to W,
provably in the L theory Th. Condition (ii), on the other hand, claims that tF indeed
represents the given function F : Wn →W, for each ﬁxed tuple of words ⃗w in Wn.
To give an example, the provably total functions of the above-mentioned theo-
ries PT and PR are the polynomial time computable and primitive recursive func-
tions, respectively.
3
Positive truth
Theories of truth contain a predicate T that mimics the properties of truth. The
axiomatization of this predicate relies on a coding mechanism for formulas. In the
applicative framework, we code formulas using new constants designating logical
operations. In the weak theories of truth discussed in this paper, the Tarski bicon-
ditionals hold only for positive formulas. Therefore no liar paradoxes occur.
In the following we will introduce two weak truth theories TPR and TPT. The
theories will be presented simultaneously since their axioms diﬀer only slightly.
3.1
The language LT of positive truth
The (ﬁrst order) language LT is an extension of the language L by
• a new unary predicate symbol T for truth
• new individual constants ˙=, ˙W, ˙∧, ˙∨, ˙∀, ˙∃
The new constants allow only the coding of positive formulas since we do not add
a constant ˙¬ to code negation. As usual, we will use inﬁx notation for ˙=, ˙∧, and ˙∨.
3.2
Two theories of positive truth
All truth theories considered in this article are based on the applicative theory B+.
Accordingly, their underlying logic is simply ﬁrst order classical predicate logic.
The truth axioms for TPR and TPT diﬀer only in the Tarski biconditionals which are

Weak Theories of Truth and Explicit Mathematics
163
available for the word predicate W. The truth axioms for TPR spell out the expected
clauses according to the compositional semantics of truth as follows.
Compositionality:
T(x ˙= y)
↔
x = y
( ˙=)
T( ˙Wx)
↔
W(x)
( ˙WPR)
T(x ˙∧y)
↔
T(x) ∧T(y)
( ˙∧)
T(x ˙∨y)
↔
T(x) ∨T(y)
( ˙∨)
T(˙∀f)
↔
(∀z)T(fz)
(˙∀)
T(˙∃f)
↔
(∃z)T(fz)
(˙∃)
For the feasible theory TPT, we use instead of ( ˙WPR) the following axiom:
x ∈W →(T( ˙Wxy) ↔y ≤W x)
( ˙WPT)
In contrast to ( ˙WPR), it allows only the reﬂection of initial segments of the set of
words. Both theories contain unrestricted truth induction.
Truth induction:
T(rϵ) ∧(∀x ∈W)(T(rx) →T(r(s0x)) ∧T(r(s1x))) →(∀x ∈W)T(rx)
Next we would like to determine the classes of formulas for which the Tarski truth
biconditionals hold. In the case of TPT this is the class of so-called simple formulas,
which are patterned after similar classes of formulas in explicit mathematics, see
[34, 37] and the next section of this paper.
Deﬁnition 5 (Simple formulas). Let A be a positive LT formula and u be a vari-
able not occurring in A. Then the formula Au which is obtained by replacing each
subformula of the form t ∈W of A by t ≤W u is called simple.
Next we deﬁne coding operations for TPR and TPT which map the positive,
respectively the simple formulas to their codes.
Deﬁnition 6. For each positive formula A of LT we inductively deﬁne a term [A]

164
Sebastian Eberhard and Thomas Strahm
whose free variables are exactly the free variables of A:
[t = s]
:=
t ˙= s
[T(t)]
:=
t
[s ∈W]
:=
˙Ws
[A ∧B]
:=
[A] ˙∧[B]
[A ∨B]
:=
[A] ˙∨[B]
[(∀x)A]
:=
˙∀(λx.[A])
[(∃x)A]
:=
˙∃(λx.[A])
Deﬁnition 7. For each simple formula Au of LT we inductively deﬁne a term ⟨A⟩
whose free variables are exactly the free variables of A:
⟨t = s⟩
:=
t ˙= s
⟨T(t)⟩
:=
t
⟨s ≤W u⟩
:=
˙Wus
⟨A ∧B⟩
:=
⟨A⟩˙∧⟨B⟩
⟨A ∨B⟩
:=
⟨A⟩˙∨⟨B⟩
⟨(∀x)A⟩
:=
˙∀(λx.⟨A⟩)
⟨(∃x)A⟩
:=
˙∃(λx.⟨A⟩)
We have that λx.[A], respectively λx.⟨A⟩can be interpreted as the propositional
function deﬁned by the formula A. For both theories of truth, the Tarski bicondi-
tionals can be proved for the positive, respectively simple formulas.
Lemma 8 (Biconditionals for TPR). Let A be a positive LT formula. We have
TPR ⊢T([A]) ↔A
Lemma 9 (Biconditionals for TPT). Let Au be a simple LT formula. We have
TPT ⊢u ∈W →(T(⟨Au⟩) ↔Au)
An interesting consequence of the biconditionals is a second recursion or ﬁxed
point theorem for positive, respectively simple predicates. This theorem can be
obtained by lifting the ﬁxed point theorem for combinatory logic (cf. Lemma 1) to
the truth-theoretic language, cf. Cantini [6, 10].

Weak Theories of Truth and Explicit Mathematics
165
4
Explicit mathematics
Types in explicit mathematics are collections of operations and must be thought of
as being generated successively from preceding ones. They are represented by op-
erations via a suitable naming relation ℜ. Types are extensional and have (explicit)
names which are intensional. The formalization of explicit mathematics using a
naming relation ℜis due to J¨ager [28].
We will present the two weak theories of explicit mathematics EPCJ and PETJ
and some extensions thereof. We will describe the two theories simultaneously
since their axioms diﬀer only slightly.
4.1
The language L of explicit mathematics
The language L is a two-sorted language extending L by
• type variables U, V, W, X, Y, Z, . . .
• binary relation symbols ℜ(naming) and ∈(elementhood)
• new (individual) constants w (sets of words), id (identity), un (union), int
(intersection), dom (domain), all (forall), inv (inverse image), and j (join)
The formulas (A, B,C, . . .) of L are built from the atomic formulas of L as well as
from formulas of the form
(s ∈X),
ℜ(s, X),
(X = Y)
by closing under the propositional connectives and quantiﬁcation in both sorts of
variables. The formula ℜ(s, X) reads as “the individual s is a name of (or repre-
sents) the type X”.
We use the following abbreviations:
ℜ(s)
:=
(∃X)ℜ(s, X),
s ∈t
:=
(∃X)(ℜ(t, X) ∧s ∈X).
4.2
Two theories of explicit mathematics
In the following we spell out the axioms of the system EPCJ whose characteristic
axioms are elementary positive comprehension and join. The applicative basis of
EPCJ is B+ as for all theories of explicit mathematics studied in this paper. Hence
their underlying logic is ordinary two-sorted classical predicate logic.

166
Sebastian Eberhard and Thomas Strahm
The following axioms state that each type has a name, that there are no
homonyms and that equality of types is extensional.
Ontological axioms:
(∃x)ℜ(x, X)
(O1)
ℜ(a, X) ∧ℜ(a, Y) →X = Y
(O2)
(∀z)(z ∈X ↔z ∈Y) →X = Y
(O3)
The following axioms provide a ﬁnite axiomatization of the schema of positive
elementary comprehension and join.
Type existence axioms:
ℜ(w) ∧(∀x)(x ∈w ↔x ∈W)
(wPR)
ℜ(id) ∧(∀x)(x ∈id ↔(∃y)(x = ⟨y, y⟩))
(id)
ℜ(a) →ℜ(inv(f, a)) ∧(∀x)(x ∈inv( f, a) ↔f x ∈a)
(inv)
ℜ(a) ∧ℜ(b) →ℜ(un(a, b)) ∧(∀x)(x ∈un(a, b) ↔(x ∈a ∨x ∈b))
(un)
ℜ(a) ∧ℜ(b) →ℜ(int(a, b)) ∧(∀x)(x ∈int(a, b) ↔(x ∈a ∧x ∈b))
(int)
ℜ(a) →ℜ(dom(a)) ∧(∀x)(x ∈dom(a) ↔(∃y)(⟨x, y⟩∈a))
(dom)
ℜ(a) →ℜ(all(a)) ∧(∀x)(x ∈all(a) ↔(∀y)(⟨x, y⟩∈a))
(all)
ℜ(a) ∧(∀x ∈a)ℜ( f x) →ℜ(j(a, f))
(j.1)
ℜ(a) ∧(∀x ∈a)ℜ( f x) →(∀x)(x ∈j(a, f) ↔Σ(f, a, x))
(j.2)
where Σ(f, a, x) is the formula
(∃y)(∃z)(x = ⟨y, z⟩∧y ∈a ∧z ∈fy)
The only diﬀerence between EPCJ and PETJ is that for PETJ we replace the axiom
(wPR) by (wPT).
a ∈W →ℜ(w(a)) ∧(∀x)(x ∈w(a) ↔x ≤W a)
(wPT)
In contrast to the comprehension schema available in EPCJ, in PETJ it is not
claimed that the collection of binary words forms a type, but merely that for each
word a, the collection {x ∈W : x ≤a} forms a type, uniformly in a.
Finally, both theories include the principle of type induction along W.
Type induction on W:
ϵ ∈X ∧(∀x ∈W)(x ∈X →s0x ∈X ∧s1x ∈X) →(∀x ∈W)(x ∈X)

Weak Theories of Truth and Explicit Mathematics
167
The ﬁnite axiomatizations of elementary comprehension in EPCJ and PETJ imme-
diately imply corresponding schemes of elementary comprehension with respect to
the characteristic formula classes of EPCJ and PETJ, respectively.
Lemma 10 (Positive Comprehension). Let A[a, ⃗x, ⃗X] be a positive L formula with
exactly the free variables displayed which does neither contain the predicate ℜ
nor second order quantiﬁers. Then there exists a term tA[⃗x,⃗z] with exactly the free
variables displayed such that EPCJ proves
ℜ(⃗z, ⃗X) →ℜ(tA[⃗x,⃗z]) ∧(∀a) a ∈tA[⃗x,⃗z] ↔A[a, ⃗x, ⃗X]
Given a positive L formula A which does neither contain the predicate ℜnor
second order quantiﬁers, the restriction Au is deﬁned in the same way as in Deﬁni-
tion 5. The so-obtained formulas are called simple L formulas.
Lemma 11 (Simple Comprehension). Let Au[u, a, ⃗x, ⃗X] be a simple L formula with
exactly the free variables displayed. Then there exists a term tA[u, ⃗x,⃗z] with exactly
the free variables displayed such that PETJ proves
u ∈W ∧ℜ(⃗z, ⃗X) →ℜ(tA[u, ⃗x,⃗z]) ∧(∀a) a ∈tA[u, ⃗x,⃗z] ↔Au[u, a, ⃗x, ⃗X]
Lemma 10 and Lemma 11 allow us to use set notation. We will sometimes
write {x : A[x]} instead of tA where tA is deﬁned as above.
4.3
Extensions
In standard models of explicit mathematics, the elementhood and naming relation
are constructed in stages; the same applies to standard models of truth theories, see
Feferman [17] and Cantini [6]. Beginning with sentences which can be immedi-
ately seen to be true, we establish the truth of more complex statements. The truth
predicate can then be conceived as joining the truth stage predicates of at least ω
many stages. To interpret this object in explicit mathematics, we will deﬁne re-
cursively types corresponding to particular stages. However the admissibility of an
iterative deﬁnition of types presupposes induction on W for the naming predicate to
prove that the type constructors work as intended. In the following, we will expand
our theories of explicit mathematics such that name induction is possible at least
in a restricted way. But instead of expanding these theories by a type reﬂecting
the name predicate, we vote for the weaker and more usual extension by universes.
This additional expressive power makes it possible to interpret the truth theories
TPR and TPT respectively.
A universe is a type U such that:

168
Sebastian Eberhard and Thomas Strahm
• U is closed under (positive) elementary comprehension and join;
• All elements of U are names.
To introduce universes precisely we deﬁne a closure condition in the following
way: CEPCJ(z, a) holds iﬀone of the following conditions is satisﬁed:
• a = w
• a = id
• (∃x)(∃f)(a = inv( f, x) ∧x ∈z)
• (∃x)(∃y)(a = un(x, y) ∧x ∈z ∧y ∈z)
• (∃x)(∃y)(a = int(x, y) ∧x ∈z ∧y ∈z)
• (∃x)(a = dom(x) ∧x ∈z)
• (∃x)(a = all(x) ∧x ∈z)
• (∃x)(∃f)a = j(x, f) ∧x ∈z ∧(∀y ∈x)(fy ∈z)
For PETJ we have to adapt the ﬁrst condition: we replace a = w by the formula
(∃u ∈W)(a = wu). We call the modiﬁed formula CPETJ(z, a).
Assuming that z is a name, the formula (∀x)(CEPCJ(z, x) →x ∈z) expresses
that z names a type that is closed under the type constructors of the theory EPCJ;
analogously for PETJ. We abbreviate the formula
(∀x)(CEPCJ(z, x) →x ∈z) ∧(∀x)(x ∈z →ℜ(x)) ∧ℜ(z)
by UEPCJ(z); the formula UPETJ(z) is deﬁned analogously.
Next assume that the language L contains two additional constants ℓEPCJ and
ℓPETJ. The following two axioms state that ℓEPCJ and ℓPETJ create an EPCJ or PETJ
universe respectively, if applied to a name.
ℜ(a) →UEPCJ(ℓEPCJ(a)) ∧a ∈ℓEPCJ(a)
(UEPCJ)
ℜ(a) →UPETJ(ℓPETJ(a)) ∧a ∈ℓPETJ(a)
(UPETJ)
In order to keep the notation simple, we write EPCJ + U instead of EPCJ + UEPCJ
and analogously PETJ+U instead of PETJ+UPETJ. Similarly, we drop the subscript
of ℓEPCJ and ℓPETJ if it is clear from the context.
Using the universe it is possible to code the elementhood relation of its types
by using a suitable join.

Weak Theories of Truth and Explicit Mathematics
169
Lemma 12. There exists a closed term e such that for Th = PETJ+U or EPCJ+U
we have that Th proves
ℜ(a) →ℜ(e(a)) ∧(∀x) x ∈e(a) ↔(∃y)(∃z)(x = ⟨y, z⟩∧z ∈ℓ(a) ∧y ∈z
Below, Cantini’s uniformity principle (cf. [10]) is needed for the embedding of
TPR. It claims for each positive L formula A
(∀x)(∃y ∈W)A[x, y] →(∃y ∈W)(∀x)A[x, y]
(UP)
This concludes the description of the relevant extensions of explicit mathematics.
5
Embeddings
We will embed the theories of explicit mathematics with universes into the theories
of truth and vice versa. The embedding of the theories of explicit mathematics with
universes is straightforward. The reverse embeddings are more diﬃcult and work
in a diﬀerent way for both theories of truth: it seems to be impossible to embed TPT
into PETJ + U directly. Instead we embed a leveled theory of truth to which TPT is
reducible by an asymmetric interpretation argument.
In this section we assume an equivalent ﬁrst order formulation of EPCJ and
PETJ. The ﬁrst order formulations postulate the type-theoretic axioms directly via
a unary naming predicate ℜand a binary elementhood relation ∈between individ-
uals. The ﬁrst and the second order versions can be mutually embedded for both
theories of explicit mathematics. For details about the embedding, see e.g. Spescha
[36] or Spescha and Strahm [38].
5.1
Embedding weak theories of explicit mathematics into weak
truth theories
For both weak truth theories introduced in the paper, the embedding works com-
pletely analogously. We take the embedding of EPCJ + U into TPR as example.
The main idea is to interpret the elementhood relation by using the truth predicate
and to trivialize the universes. The translation ∗of a formula s ∈t will be
T(t∗s∗).
To make this translation work, we have to interpret the type constructors in the right
way. The idea is to translate them by predicates, which embody their membership
condition.

170
Sebastian Eberhard and Thomas Strahm
Deﬁnition 13 (Translation of terms). For each term t of L, its translation t∗into LT
is deﬁned recursively on the complexity of t in the following way.
• All applicative constants are left untouched.
• id∗≡λz.˙∃λy. z ˙= ⟨y, y⟩
• w∗≡λz. ˙Wz
• int∗≡λa.λb.λz. az ˙∧bz
• un∗≡λa.λb.λz. az ˙∨bz
• inv∗≡λ f.λa.λz. a(fz)
• dom∗≡λa.λz. ˙∃λy.a⟨z, y⟩
• all∗≡λa.λz. ˙∀λy.a⟨z, y⟩
• j∗≡λf.λa.λz. ˙∃λx.˙∃λy.z ˙= ⟨x, y⟩˙∧ax ˙∧(f x)y
• ℓEPCJ∗≡λa.λz.0 ˙= 0
• st∗≡s∗t∗
Formulas are translated in the following way: atomic formulas commute with
∗except for the formulas of the shape s ∈t whose translation is T(t∗s∗) and the
formulas of the shape ℜ(s) whose translation is 0 = 0. The translation commutes
with negation, propositional connectives and quantiﬁers.
For this translation, the embedding theorem below can be proved without dif-
ﬁculties. Since the name predicate is interpreted trivially, the translations of the
universe axioms hold in TPR. Moreover, the translation can be modiﬁed in the
obvious way in order to provide an embedding of PETJ + U into TPT.
Theorem 14. EPCJ + U and PETJ + U are contained in TPR and TPT via the ∗
translation or a slight modiﬁcation thereof, respectively.
Let us mention that this embedding theorem also holds for expansions of ex-
plicit mathematics by positive uniformity if the truth theories are expanded analo-
gously.

Weak Theories of Truth and Explicit Mathematics
171
5.2
Embedding of TPR into EPCJ + U + UP
First, we deﬁne types corresponding to levels of truth. We construct a truth-level
type τw for each word w. Using join we can then collect all these truth-level types.
Because of UP the resulting type satisﬁes the translated truth axioms.
The types τw for the truth levels all consist of tuples of three elements. The ﬁrst
element contains a code for a logical symbol of LT. All these codes are assumed to
be diﬀerent words. The second and the third element stand for the terms the logical
constant is applied to. The third element is sometimes only a placeholder. Let us
deﬁne the bottom truth level τϵ as
{⟨a, b, c⟩|(a = ⌜˙=⌝∧b = c) ∨(a = ⌜˙W⌝∧W(b) ∧c = ϵ)}.
The types for the higher truth levels are deﬁned recursively (using the ﬁxed point
theorem of B) in the following way:
τ(siw) := τw ∪{⟨a, b, c⟩|
 a = ⌜˙∧⌝∧b ∈τw ∧c ∈τw
∨
 a = ⌜˙∨⌝∧[b ∈τw ∨c ∈τw]
∨
 a = ⌜˙∃⌝∧(∃x)(bx ∈τw) ∧c = ϵ
∨
 a = ⌜˙∀⌝∧(∀x)(bx ∈τw) ∧c = ϵ
}
To justify the type notation, we have to show that the above given terms τw are
names for each w ∈W. Only then, the type constructors work in the intended way
and indeed name the above displayed types. Since ℜ-induction is not available, we
use type induction with the universe ℓEPCJ(id) for this purpose. It is easy to see that
τϵ ∈ℓEPCJ(id) and
(∀w ∈W)(τw ∈ℓEPCJ(id) →τ(siw) ∈ℓEPCJ(id))
hold. We apply type induction and use the fact (∀x) x ∈ℓEPCJ(id) →ℜ(x) to get
the desired result.
Now the stage is set to deﬁne a translation ◦of TPR into EPCJ + U + UP.
In particular, we translate the truth predicate using the above deﬁned hierarchy of
types.
Deﬁnition 15 (Translation of terms). For each term t of LT, its translation t◦is
deﬁned inductively on its complexity in the following way.
• All applicative constants are left untouched.
• ˙=◦≡λx.λy.⟨⌜˙=⌝, x, y⟩
• ˙W◦≡λx.⟨⌜˙W⌝, x, ϵ⟩

172
Sebastian Eberhard and Thomas Strahm
• ˙∧◦≡λx.λy.⟨⌜˙∧⌝, x, y⟩
• ˙∨◦≡λx.λy.⟨⌜˙∨⌝, x, y⟩
• ˙∃◦≡λx.⟨⌜˙∃⌝, x, ϵ⟩
• ˙∀◦≡λx.⟨⌜˙∀⌝, x, ϵ⟩
• (st)◦≡s◦t◦
Deﬁnition 16 (Translation of formulas). For each formula A of LT, its translation
A◦is deﬁned inductively in the following way.
• (s = t)◦≡s◦= t◦
• (s ∈W)◦≡s◦∈W
• T(t)◦≡t◦∈dom(inv(λx.⟨p1x, p0x⟩, j(W, τ)))
• The translation commutes with negation, propositional connectives and
quantiﬁers.
Note that by the type axioms of EPCJ + U, we have
t ∈dom(inv(λx.⟨p1x, p0x⟩, j(W, τ))) ↔(∃w ∈W)(t ∈τ(w))
We are now ready to state the embedding of TPR into EPCJ + U + UP.
Theorem 17. TPR is contained in EPCJ + U + UP via the ◦translation.
Proof. It is clear that the translations of the applicative axioms hold in EPCJ + U.
Further, we can show that the translation of truth induction holds in EPCJ+U using
inv. So let us check the translations of the truth axioms. The direction from right
to left is always trivially fulﬁlled except for (˙∀). Its translation is in EPCJ + U
equivalent to
(∀x)(∃w ∈W)(f x ∈τw) →(∃w ∈W)(⟨⌜˙∀⌝, f, ϵ⟩∈τw).
Using UP, from the antecedens we can derive the existence of a w ∈W such that
(∀x)( f x ∈τw). This implies that ⟨⌜˙∀⌝, f, ϵ⟩is in the successor truth level type
τ(siw).
The direction from left to right is always proved in the same way. We sketch
the proof for the ˙∧-axiom. Let .−be deﬁned in the following way.
• x .−ϵ := x

Weak Theories of Truth and Explicit Mathematics
173
• x .−siw := pW(x .−w)
Let us assume the lefthand side of the ˙∧-axiom. Its translation implies in EPCJ+U
⟨⌜˙∧⌝, a, b⟩∈τw
for a w ∈W unequal ϵ. We deﬁne the formula A[x] as2
⟨⌜˙∧⌝, a, b⟩∈τ(w .−x) ∨(∃y ∈W)(y ⊂w ∧a ∈τy ∧b ∈τy).
Clearly, this formula is progressive in W due to the construction of the truth level
types. By type induction we get
⟨⌜˙∧⌝, a, b⟩∈τϵ ∨(∃y ∈W)(y ⊂w ∧a ∈τy ∧b ∈τy).
Since the bottom level of truth does not contain tuples of the form ⟨⌜˙∧⌝, a, b⟩, the
second disjunct has to be true. This immediately implies the lefthand side of the
˙∧-axiom.
□
Note that we needed only the existence of one single universe to prove this
embedding. In addition, similarly as described in the next paragraph for TPT, it is
also possible to reduce TPR via an intermediate leveled truth theory to EPCJ + U.
This results in a reduction of TPR to EPCJ + U which does not depend on the
uniformity principle.
5.3
Reduction of TPT to PETJ + U
Unfortunately an embedding similar to the one in the previous subsection does not
seem to be possible in this case. This is because we cannot collect the truth levels
for all words, since join can have only initial segments of the type of words as index
type.
5.3.1
The leveled truth theory Tℓ
PT
Because of the above mentioned reasons, we have to reduce the truth theory TPT to
a leveled truth theory Tℓ
PT. This means that the predicate T in Tℓ
PT is a binary pred-
icate, whose ﬁrst argument is written as superscript and interpreted as truth level.
This superscript displays the maximal complexity of formulas the corresponding
unary truth predicate can reﬂect. The logical axioms and rules of Tℓ
PT are the usual
ones. Tℓ
PT has the following non-logical axioms.
2We use s ⊂t as abbreviation for dW(0, 1, s, t) = 1 ∧c⊆st = 0

174
Sebastian Eberhard and Thomas Strahm
• a ∈W →(Ta(x  y) ↔x = y)
• a, b ∈W →(x ≤W b ↔Ta( ˙Wbx))
• a ∈W → Tsia(x ˙∨y) ↔Ta(x) ∨Ta(y)
• a ∈W → Tsia(x ˙∧y) ↔Ta(x) ∧Ta(y)
• a ∈W → Tsia(˙∃f) ↔(∃z)Ta(fz)
• a ∈W → Tsia(˙∀f) ↔(∀z)Ta(fz)
• a0, a1 ∈W ∧a0 ≤a1 ∧Ta0(x) →Ta1(x)
Additionally, we have truth induction in the following form:
Tpϵ(fϵ) ∧(∀x ∈W)Tpx(f x) →Tp(s0x)(f(s0x)) ∧Tp(s1x)(f(s1x))
→(∀x ∈W)(Tpx(f x))
In the following, p will always be a polynomial.
For the asymmetric interpretation of TPT in Tℓ
PT, we bound the truth level and
the W predicate simultaneously. We work as usual with sequent style formulations
of TPT and Tℓ
PT which we call TPT and Tℓ
PT as well. We assume that in these calculi
all axioms are formulated for terms to guarantee a suﬃcient cut elimination.
Deﬁnition 18 (Asymmetric interpretation). Let A be a positive LT formula and let
a, b be variables. The formula Aa,b is deﬁned in the following way.
• (t ∈W)a,b ≡t ≤W a
• T(t)a,b ≡Tb(t)
Other atomic formulas are untouched by the asymmetric interpretation. The
asymmetric interpretation commutes with propositional connectives and quanti-
ﬁers.
Next we state the crucial asymmetric interpretation lemma of TPT into Tℓ
PT. An
immediate consequence of the lemma is that the provably total functions of TPT are
contained in the provably total functions of Tℓ
PT.
Lemma 19. Let Γ ⇒∆be a positive sequent which has a proof of depth k in TPT
containing only positive formulas. Then there exists a polynomial p of degree 2(2k)
such that 3
Tℓ
PT ⊢a, b ∈W, Γa,b ⇒∆pa,pa∗b
3We use the notation pa ∗b to denote the term ∗(pa, b). Analogously for similar notations.

Weak Theories of Truth and Explicit Mathematics
175
Proof. We show the lemma by induction on the depth of the positive proof. The
only diﬃcult case is induction. In this case we have by induction hypothesis poly-
nomials p, q0, q1 of degree 2(2k) with the following properties.
Tℓ
PT ⊢a, b ∈W, Γa,b ⇒Tpa∗b(rϵ), ∆pa,pa∗b
(30)
Tℓ
PT ⊢a, b ∈W, Γa,b, Tb(rx), x ≤W a ⇒Tqia∗b(r(six)), ∆qia,qia∗b
(31)
Let q be a polynomial that bounds q0 and q1. We deﬁne the polynomial g as
g(x, y) := p(x) ∗(q(x) × s0y).
Because of monotonicity of the asymmetric interpretation the following hold:
Tℓ
PT ⊢a, b ∈W, Γa,b ⇒Tgaϵ∗b(rϵ), ∆gaϵ,gaϵ∗b
(32)
Tℓ
PT ⊢a, b ∈W, Γa,gax∗b, Tgax∗b(rx), x ≤W a ⇒
(33)
Tga(six)∗b(r(six)), ∆qa,ga(six)∗b
We use again monotonicity of the asymmetric interpretation to unify the side for-
mulas and thus get:
Tℓ
PT ⊢a, b ∈W, Γa,b ⇒Tgaϵ∗b(rϵ), ∆gaa,gaa∗b
(34)
Tℓ
PT ⊢a, b ∈W, Γa,b, Tgax∗b(rx), x ≤W a ⇒
(35)
Tga(six)∗b(r(six)), ∆gaa,gaa∗b
These are the premises for an induction over an initial segment of W which can
be proved admissible as usual. After using induction, monotonicity delivers the
following.
Tℓ
PT ⊢a, b ∈W, Γa,b, x ≤W a ⇒Tgaa∗b(rx), ∆gaa,gaa∗b
(36)
Since gaa is a polynomial of degree 2(2k) +1 in a this is the desired result. Note that
the degree 2(2k+1) for the bounding polynomial is needed for the cut rule.
□
5.3.2
Embedding of Tℓ
PT into PETJ + U
In analogy to the previous embedding, we construct a closed term τ such that for
all w ∈W the type τ(w) corresponds to the truth level w. We set
τ(ϵ) := {⟨a, b, c⟩|a = ⌜˙=⌝∧b = c ∨a = ⌜˙W⌝∧⟨c, w(b)⟩∈e(id)}.

176
Sebastian Eberhard and Thomas Strahm
The types for the higher truth levels are deﬁned recursively as before:
τ(siw) := τw ∪{⟨a, b, c⟩|
 a = ⌜˙∧⌝∧b ∈τw ∧c ∈τw
∨
 a = ⌜˙∨⌝∧[b ∈τw ∨c ∈τw]
∨
 a = ⌜˙∃⌝∧(∃x)(bx ∈τw) ∧c = ϵ
∨
 a = ⌜˙∀⌝∧(∀x)(bx ∈τw) ∧c = ϵ
}
As above, we show that these levels are all names by type induction with the uni-
verse ℓ(e(id)).
We are now ready to modify the translation ◦from the last subsection in order
to provide a translation from Tℓ
PT into PETJ + U.
Deﬁnition 20 (Translation of terms). For each term t of LT its translation t◦into L
is deﬁned in the same way as above except that we put
˙W◦≡λx.λy.⟨⌜˙W⌝, x, y⟩
Deﬁnition 21 (Translation of formulas). For each formula A of LT its translation
A◦is deﬁned inductively in the following way.
• (s = t)◦≡s◦= t◦
• (s ∈W)◦≡s◦∈W
• Ts(t)◦≡⟨t◦, τ(0 × s◦)⟩∈e(e(id))
• The translation commutes with negation, propositional connectives and
quantiﬁers.
Similarly to the previous embedding theorem, we now obtain the following
result.
Theorem 22. Tℓ
PT is contained in PETJ + U via the ◦translation.
Proof. The translations of the truth axioms can be proved as before; note that the
induction formula is equivalent to a simple formula. Because of the leveling the
uniformity principle is not needed. An easy induction establishes
v, w ∈W ∧v ⊂w ∧Tv(x) →Tw(x),
which implies the translation of monotonicity.
□
Note that the previous lemma and theorem readily imply that the provably total
functions of TPT are contained in those of PETJ + U.4
4The theory TPT can also be reduced to an extension of polynomial strength of PETJ by a single
universe and an additional type constructor to deal with sharply bounded universal quantiﬁcation. In this
case the intermediate reduction theory is a twice leveled theory of truth whose second level designates
the maximal value of s to which formulas of the form t ≤W s are reﬂected. The corresponding truth
levels can be interpreted in this extension of PETJ without using e(id).

Weak Theories of Truth and Explicit Mathematics
177
6
Proof-theoretic analysis
In this section we give an overview of the existing and forthcoming literature re-
garding the proof theory of weak systems of truth and explicit mathematics, includ-
ing the ones discussed in this paper.
6.1
Weak systems of explicit mathematics
Let us start by brieﬂy reviewing some previous proof-theoretic work regarding sys-
tems of explicit mathematics of strength PRA. Early systems of ﬂexible typing of
this strength are extensively studied by Feferman. In [15, 16] he proposes a pro-
gram to use explicit mathematics to analyze properties of functional programs. In
the realm of pure applicative theories, natural systems of strength PRA are proposed
and analyzed in Feferman and J¨ager [22] and J¨ager and Strahm [29]. Theories that
are strongly related to the system EPCJ are considered in Kr¨ahenb¨uhl [33]. Let us
note that all upper bound computations for the systems mentioned above proceed
via embeddings into suitable subsystems of Peano arithmetic of strength PRA.
Let us now turn to the discussion of the proof theory of systems of explicit
mathematics of polynomial strength. Purely ﬁrst order systems were proposed and
analyzed in Calamai [4], Cantini [5, 8, 9, 10], Kahle and Oitavem [32], and Strahm
[39, 40, 41].5 For those theories, a direct embedding into feasible subsystems of
arithmetic does not seem to be possible, as, for example, already the standard in-
terpretation of equality of terms translates into a proper Σ0
1 statement in arithmetic.
Extensions of these weak applicative theories formulated in the full language of
explicit mathematics and featuring weak forms of elementary comprehension were
ﬁrst introduced and studied in Spescha and Strahm [37]. In particular, the system
PET of types and names6 has been proposed whose provably total functions are
exactly the polytime functions. The PhD thesis of Spescha [36] gives a uniform
treatment of various weak systems of explicit mathematics in the spirit of PET,
possibly augmented by the axiom of join. A new syntactical approach to the anal-
ysis of these systems is proposed via a novel realizability interpretation for the
language of types and names, see also the article Spescha and Strahm [38]. The
very recent work of Probst [34] solves the delicate and diﬃcult problem of show-
ing that the provably total operations of the system PET with the join axiom and
classical logic are still the polynomial time computable ones. The article Strahm
[42] surveys most of these results. However, let use mention that the techniques
used in these papers do not validate expansions of PETJ by universes or by the
5For a very diﬀerent and interesting approach to feasibility in the context of Heyting arithmetic and
using notions of ramiﬁcation and linearity for proof terms, see Schwichtenberg [35].
6In the notation of this paper, PET is PETJ without the join axioms.

178
Sebastian Eberhard and Thomas Strahm
assertion ∀ℜclaiming that everything is a name. These additional principles, how-
ever, can be treated by Eberhard’s new realizability techniques [12] discussed in
the next paragraph.
6.2
Weak truth theories
First examples of very expressive and natural truth theories of strength PRA are
presented in Cantini [7]. The proof-theoretic tools used in this article are the tech-
nique of asymmetric interpretation as well as subtle formalizations in the subsystem
of Peano arithmetic with induction restricted to Σ0
1 statements. In his more recent
[10], Cantini studies a rich family of truth theories of strength PRA including ad-
ditional principles such as positive choice and uniformity. Special emphasis is put
on the reduction of classical truth theories to their intuitionistic counterparts using
a forcing relation. The computational content of the intuitionistic truth theories is
analyzed by means of suitable realizability techniques. A direct companion to [10]
is Cantini [11], which deals with further extensions of the theories in [10]. Let
us note that our truth theory TPR can be embedded into PRA plus Σ0
1 induction by
using the formalized term model construction used in the proof of Theorem 9 in
Cantini [11].
Let us now turn to the discussion of truth theories of polynomial strength. First
examples are treated in Cantini [10], where the truth predicate is used as a guiding
technical tool in order to deal with additional principles. One of the core diﬀerences
between our system TPT and the weak truth theories in [10] is the fact that in TPT
we have unrestricted truth induction. This very liberal induction principle makes
the proof-theoretic analysis of TPT complicated. The realization approach used
in [10] does not work; in particular, there are provable sequents which require
exponential realization functions. Nevertheless, it is possible to show that TPT is
feasible by using a new realization approach which is developed in Eberhard [12].
The main idea is to use pointers thanks to which the same piece of realization
information can be used to realize subformulas of several formulas. This allows
to represent and manipulate realization information more eﬃciently. Using this
modiﬁed realization approach, one ﬁnds polynomial time realization functions for
each provable positive sequent. Also the strengthening of TPT by UP can be realized
by the same technique. Finally, let us mention that the same approach can also be
used in order to realize extensions of the system PETJ of explicit mathematics. In
particular, the system PETJ+U used in the embeddings above can be realized using
the techniques developed in [12].

Weak Theories of Truth and Explicit Mathematics
179
6.3
Summary of proof-theoretic results
Let us conclude this section by summarizing the results about the proof-theoretic
strength of the theories of truth and explicit mathematics considered in this article.
Theorem 23 (Systems of primitive recursive strength). The provably total func-
tions of the following theories are the primitive recursive ones:
1. EPCJ, possibly augmented by UP and U;
2. TPR, possibly augmented by UP.
Theorem 24 (Systems of polynomial strength). The provably total functions of the
following theories are the polynomial time computable ones:
1. PETJ, possibly augmented by UP and U;
2. TPT, possibly augmented by UP.
Let us note that for both theories of explicit mathematics, U is a consequence
of ∀ℜ, since under this assumption, ℓa can be interpreted as {x : x = x} for any a.
Moreover, Eberhard’s realization approach trivializes the name predicate and hence
can handle ∀ℜ. Finally, we mention that in the context of TPR, Cantini [10] deals
with further choice and reﬂection principles which do not raise the strength of TPR.
7
Concluding remarks
We have studied two natural truth-theoretic frameworks over combinatory logic
and their relationship to weak systems of explicit mathematics. We have seen that
the embedding of explicit mathematics into truth theories is very straightforward,
whereas the direct reverse embeddings require further (natural) extensions of ex-
plicit mathematics and sometimes even intermediate reduction steps. The corre-
sponding extensions of explicit mathematics do not increase the proof-theoretic
strength of the underlying systems.
The newly proposed feasible truth theory TPT is also an important reference
theory in our recent work on Feferman’s unfolding program (see Feferman [20]
and Feferman and Strahm [23, 24]): in Eberhard and Strahm [13, 14], the system
TPT plays a crucial role in order to obtain proof-theoretic upper bounds for the full
unfolding U(FEA) of a natural schematic system FEA of feasible arithmetic.

180
Sebastian Eberhard and Thomas Strahm
References
[1] Peter Aczel. Frege structures and the notion of proposition, truth and set. In
J. Barwise, H. Keisler, and K. Kunen, editors, The Kleene Symposium, pages
31– 59. North-Holland, 1980.
[2] Michael J. Beeson. Proving programs and programming proofs. In Barcan
Marcus et. al., editor, Logic, Methodology and Philosophy of Science VII,
pages 51–82. North Holland, Amsterdam, 1986.
[3] Michael J. Beeson. Foundations of Constructive Mathematics: Metamathe-
matical Studies. Springer, Berlin, 1985.
[4] Giacomo Calamai. Proof-theoretic contributions to computational complex-
ity. PhD thesis, University of Siena, 2008.
[5] Andrea Cantini. A footnote on the Parsons-Mints-Takeuti theorem. Talk at
Recent Trends in Proof Theory, Bern, July 2008.
[6] Andrea Cantini.
Logical Frameworks for Truth and Abstraction.
North-
Holland, Amsterdam, 1996.
[7] Andrea Cantini. Proof-theoretic aspects of self-referential truth. In Maria
Luisa Dalla Chiara et. al., editor, Tenth International Congress of Logic,
Methodology and Philosophy of Science, Florence, August 1995, volume 1,
pages 7–27. Kluwer, September 1997.
[8] Andrea Cantini. Feasible operations and applicative theories based on λη.
Mathematical Logic Quarterly, 46(3):291–312, 2000.
[9] Andrea Cantini.
Polytime, combinatory logic and positive safe induction.
Archive for Mathematical Logic, 41(2):169–189, 2002.
[10] Andrea Cantini.
Choice and uniformity in weak applicative theories.
In
M. Baaz, Sy Friedman, and J. Kraj´ıˇcek, editors, Logic Colloquium ’01, vol-
ume 20 of Lecture Notes in Logic, pages 108–138. Association for Symbolic
Logic, 2005.
[11] Andrea Cantini. Remarks on applicative theories. Annals of Pure and Applied
Logic, 136:91–115, 2005.
[12] Sebastian Eberhard. A feasible theory of truth over combinatory logic. Pre-
liminary draft, February 2011.

Weak Theories of Truth and Explicit Mathematics
181
[13] Sebastian Eberhard and Thomas Strahm. Unfolding feasible arithmetic and
weak truth. Submitted for publication.
[14] Sebastian Eberhard and Thomas Strahm. Towards the unfolding of feasible
arithmetic (Abstract). Bulletin of Symbolic Logic, to appear.
[15] Solomon Feferman. Logics for termination and correctness of functional pro-
grams.
In Y. N. Moschovakis, editor, Logic from Computer Science, vol-
ume 21 of MSRI Publications, pages 95–127. Springer, Berlin, 1991.
[16] Solomon Feferman.
Logics for termination and correctness of functional
programs II: Logics of strength PRA. In P. Aczel, H. Simmons, and S. S.
Wainer, editors, Proof Theory, pages 195–225. Cambridge University Press,
Cambridge, 1992.
[17] Solomon Feferman. A language and axioms for explicit mathematics. In
J.N. Crossley, editor, Algebra and Logic, volume 450 of Lecture Notes in
Mathematics, pages 87–139. Springer, Berlin, 1975.
[18] Solomon Feferman. Recursion theory and set theory: a marriage of conve-
nience. In J. E. Fenstad, R. O. Gandy, and G. E. Sacks, editors, Generalized
recursion theory II, Oslo 1977, volume 94 of Stud. Logic Found. Math, pages
55–98. North Holland, Amsterdam, 1978.
[19] Solomon Feferman.
Constructive theories of functions and classes.
In
M. Boﬀa, D. van Dalen, and K. McAloon, editors, Logic Colloquium ’78,
pages 159–224. North Holland, Amsterdam, 1979.
[20] Solomon Feferman. G¨odel’s program for new axioms: Why, where, how and
what? In Petr H´ajek, editor, G¨odel ’96, volume 6 of Lecture Notes in Logic,
pages 3–22. Springer, Berlin, 1996.
[21] Solomon Feferman. Axioms for the determinateness of truth. Review of Sym-
bolic Logic, 1:204–217, 2008.
[22] Solomon Feferman and Gerhard J¨ager.
Systems of explicit mathematics
with non-constructive µ-operator. Part I. Annals of Pure and Applied Logic,
65(3):243–263, 1993.
[23] Solomon Feferman and Thomas Strahm. The unfolding of non-ﬁnitist arith-
metic. Annals of Pure and Applied Logic, 104(1–3):75–96, 2000.
[24] Solomon Feferman and Thomas Strahm. Unfolding ﬁnitist arithmetic. Review
of Symbolic Logic, 3(4):665–689, 2010.

182
Sebastian Eberhard and Thomas Strahm
[25] Harvey Friedman and Michael Sheard.
An axiomatic approach to self-
referential truth. Annals of Pure and Applied Logic, 33(1):1–21, 1987.
[26] Volker Halbach. Axiomatic Theories of Truth. Cambridge University Press,
2011.
[27] S. Hayashi and S. Kobayashi. A new fomalization of Feferman’s system of
functions and classes and its relation to Frege structures. International Jour-
nal of Foundations of Computer Science, 6(3):187–202, 1995.
[28] Gerhard J¨ager. Induction in the elementary theory of types and names. In
E. B¨orger, H. Kleine B¨uning, and M.M. Richter, editors, Computer Science
Logic ’87, volume 329 of Lecture Notes in Computer Science, pages 118–128.
Springer, Berlin, 1988.
[29] Gerhard J¨ager and Thomas Strahm. Totality in applicative theories. Annals of
Pure and Applied Logic, 74(2):105–120, 1995.
[30] Reinhard Kahle.
Applikative Theorien und Frege-Strukturen.
PhD thesis,
Institut f¨ur Informatik und angewandte Mathematik, Universit¨at Bern, 1997.
[31] Reinhard Kahle. The Applicative Realm. Habilitation Thesis, T¨ubingen, 2007.
Appeared in Textos de Mathem´atica 40, Departamento de Mathem´atica da
Universidade de Coimbra, Portugal, 2007.
[32] Reinhard Kahle and Isabel Oitavem. An applicative theory for FPH. In Steﬀen
van Bakel, Stefano Berardi, and Ulrich Berger, editors, Proceedings Third In-
ternational Workshop on Classical Logic and Computation CL&C, volume 47
of EPTCS, 2010.
[33] J¨urg Kr¨ahenb¨uhl. Explicit mathematics with positive existential comprehen-
sion and join. Master’s thesis, Institut f¨ur Informatik und angewandte Mathe-
matik, Universit¨at Bern, 2006.
[34] Dieter Probst. The provably terminating operations of the subsystem PETJ of
explicit mathematics. Annals of Pure and Applied Logic, 162(11):934–947,
2011.
[35] Helmut Schwichtenberg.
An arithmetic for polynomial time computation.
Theoretical Computer Science, 357:202–214, 2006.
[36] Daria Spescha. Weak systems of explicit mathematics. PhD thesis, Universit¨at
Bern, 2009.

Weak Theories of Truth and Explicit Mathematics
183
[37] Daria Spescha and Thomas Strahm. Elementary explicit types and polynomial
time operations. Mathematical Logic Quarterly, 55(3):245–258, 2009.
[38] Daria Spescha and Thomas Strahm. Realizability in weak systems of explicit
mathematics. Mathematical Logic Quarterly, 57(6):551–565, 2011.
[39] Thomas Strahm. Polynomial time operations in explicit mathematics. Journal
of Symbolic Logic, 62(2):575–594, 1997.
[40] Thomas Strahm. Proof-theoretic Contributions to Explicit Mathematics. Ha-
bilitationsschrift, University of Bern, 2001.
[41] Thomas Strahm. Theories with self-application and computational complex-
ity. Information and Computation, 185:263–297, 2003.
[42] Thomas Strahm. Weak theories of operations and types. In Ralf Schindler,
editor, Ways of Proof Theory, pages 441–468. Ontos Verlag, 2010.
[43] Anne S. Troelstra and Dirk van Dalen. Constructivism in Mathematics, vol-
ume II. North Holland, Amsterdam, 1988.

184

Axiomatizing Truth: Why and How?
Solomon Feferman∗
For Helmut Schwichtenberg on the occasion of his 70th birthday
Broadly speaking there are two kinds of theories of truth, philosophical and
logical. The philosophical theories of truth go back to the Greeks and forward
to the present day. Among these are the correspondence, coherentist, prag-
matist, deﬂationary and primitivist theories of truth. Logical theories of truth
are roughly of two kinds, semantical (or deﬁnitional) and axiomatic. Tarski
inaugurated semantical theories in the mid 1930s with his deﬁnition of truth
for a logically circumscribed language within a metalanguage for it, i.e. in a
typed setting in order to avoid inconsistency. However, the ordinary use of
truth in natural language is untyped, and so beginning in the 1960s, attempts
were made to obtain useful consistent untyped semantical theories by giving
up some of Tarski’s basic assumptions. One of the most successful was due
to Kripke in 1975, who deﬁned a notion of truth for an untyped three-valued
language. My axiomatization of Kripke’s model a few years later inaugurated
a considerable body of work on a variety of axiomatic theories that continues
to be actively pursued. In this paper general considerations are presented as
to why one should axiomatize theories of truth and what criteria should be
applied to them. These are then illustrated with three examples from my own
work as to how one might try to go about meeting these criteria.
1
Introduction
Broadly speaking there are two kinds of theories of truth, philosophical and logical.
The philosophical theories of truth go back to the Greeks and forward to the present
day, including the correspondence, coherentist, pragmatist, deﬂationary and prim-
itivist theories of truth.1 Logical theories of truth, on the other hand, date only
∗This paper is based on an invited lecture that I gave for the Pillars of Truth conference held at
Princeton University, April 8–10, 2011.
1As sources for these, both Kirkham (1995) and Burgess and Burgess (2011) provide excellent sur-
veys and expositions, while there are several ﬁne collections of original articles such as those of Black-
burn and Simmons (1999) and Lynch (2001).

186
Solomon Feferman
to the 1930s. They are roughly of two kinds, semantical (or deﬁnitional) and ax-
iomatic. Tarski (1935) inaugurated semantical theories with his deﬁnition of truth
for a logically circumscribed language within a metalanguage for it, i.e. in a typed
setting. He argued that this was necessary since a language which contains its own
truth predicate is inconsistent if it satisﬁes a few basic assumptions, namely the
T-scheme, classical propositional logic,2 and the capacity to form self-referential
statements. However, the ordinary use of truth in natural language is untyped and
the constraints of a hierarchical theory seem unduly restrictive. Moreover, mathe-
matics provided an excellent example in replacing the theory of types by untyped
systems of set theory. Thus it was that beginning in the 1960s, attempts were made
to obtain useful consistent untyped semantical theories of truth by giving up some
part of Tarski’s basic assumptions.3 One of the most inﬂuential of these was that
due to Kripke (1975), who deﬁned a notion of truth for an untyped three-valued
language.4 My axiomatization of Kripke’s model a few years later (see Feferman
1991) inaugurated a considerable body of work on a variety of axiomatic theories
that continues to be actively pursued.5 In this paper general considerations are pre-
sented as to why one should axiomatize theories of truth and what criteria ought to
be applied to them. These are then illustrated with three examples from my own
work (because that is what I know best) as to how one might try to go about meeting
these criteria and to what extent one may succeed.
2
Why axiomatize theories of truth?6
1. Axiomatic theories separate out what is needed to justify a given semantical
deﬁnition from what the deﬁnition is designed to achieve. The axiomatic
theory is usually much weaker than the (implicit) ambient theory in which
the semantical construction is carried out. Often the latter includes a consid-
erable portion of set theory.
2Actually, intuitionistic logic suﬃces to derive a contradiction.
3A number of these eﬀorts can be found in the articles collected in Martin (1970) and Martin (1984).
4Martin and Woodruﬀ(1975) independently arrived at a closely related model. Theirs produces a
maximal ﬁxed point for a certain monotonic operator, whereas Kripke obtained minimal ﬁxed points
among others. Among other semantic approaches are those due to Barwise and Etchemendy (1987) and
Gupta and Belnap (1993).
5The ﬁrst book to exposit a number of axiomatic theories was Cantini (1996); much of that has been
brought up to date in the excellent expository work, Halbach (2011); both incorporate original research
by the respective authors. Some of the noteworthy books devoted to speciﬁc axiomatic approaches are
those due to McGee (1991), Maudlin (2004), Field (2008) and Horsten (2011).
6There is some overlap in this section with the motivations for axiomatization given in Ch. 1 of
Halbach (2011).

Axiomatizing Truth: Why and How?
187
2. Many axiomatic theories of truth are based on a given semantic deﬁnition
and are thus automatically consistent. But those that are not may be shown
consistent by providing a suitable model or by proof-theoretical means.
3. Often, particular semantic constructions are designed to realize certain prima
facie required basic properties of truth such as the T-scheme or composition-
ality. What axiomatizing such a construction shows is precisely the extent to
which such properties are met.
4. Moreover, such axiomatization provides the explicit statement of further
properties that were not necessarily part of the original motivations for the
construction.
5. An axiomatization (not necessarily uniquely determined) of a given seman-
tical construction provides a framework in which one can reason systemati-
cally about various aspects of the construction. This helps to assess the value
and possible defects of such a construction.
6. One can compare like and unlike axiomatizations as to their proof-theoretical
strength using an extensive body of well-established metamathematical tech-
niques.
7. Given axiomatizations suggest natural variants such as by extending general
principles from one’s base theory (e.g., induction in arithmetic, or separation
in set theory) to the theory with a truth predicate.
8. A given philosophical conception of truth may suggest a semantical construc-
tion or an axiomatization, and once made more explicit in the latter way, we
are in a better position to assess the underlying conception.
It should be remarked that not all philosophical theories of truth are amenable to
axiomatic representation. How axiomatize, for example, coherence or pragmatic
theories of truth?
3
Criteria for a theory of truth
Various criteria have been proposed for consistent axiomatic theories of truth that
contain their own truth predicate. To my mind, the best articulation of such cri-
teria is one due to Hannes Leitgeb (2007).7 He sets down eight of these, each of
7But see also Sheard (2002). Another interesting discussion of criteria is to be found in McDonald
(2000).

188
Solomon Feferman
which has plausibility in its own right, and various of which are ordinarily taken for
granted, but the combination of all of which cannot simultaneously be realized on
pain of inconsistency. That is why Leitgeb calls his piece, “What theories of truth
should be like (but cannot be)”. His eight criteria (L1-L8) are as follows.
(L1) Truth should be expressed by a predicate (and a theory of syntax should be
available).
(L2) If a theory of truth is added to mathematical or empirical theories, it should
be possible to prove the latter true.
(L3) The truth predicate should not be subject to any type restrictions.
(L4) T-biconditionals [in the T-scheme] should be derivable unrestrictedly.
(L5) Truth should be compositional.
(L6) The theory should allow for standard interpretations.
(L7) The outer logic and the inner logic should coincide.
(L8) The outer logic should be classical.
These can be spelled out more precisely, as follows.
To meet (L1), we have ﬁrst to address the common philosophical issue whether
truth is a predicate of sentences or of propositions. We would certainly grant that if
two sentences, from the same or diﬀerent languages, express the same proposition
then their truth conditions agree. That would seem to argue in favor of truth as a
predicate of propositions. The argument in favor of sentences is that we have ex-
cellent theories of sentences as structured syntactic objects; these can be dealt with
in full precision and with great ﬂexibility in formal theories of syntax as provided
for example in concatenation theory, or elementary set theory, or in arithmetic via
G¨odel coding. The nature of propositions is obscure by comparison; one issue is
whether or not they are structured objects. And what does it mean for a sentence
to express a proposition? When do two sentences express the same proposition?
Are all propositions expressible in some language? Finally, do all sentences in a
given language express a proposition? When we settle, as is customary in work on
axiomatic theories of truth, on sentences being the truth-bearers, one avoids deal-
ing with all but the last of these diﬃcult questions, and concentrates instead in each
axiomatic theory on a more precise question: Which sentences are taken to be the
truth bearers? 8
8Some other arguments in favor of sentences as the truth-bearers can be found in Halbach (2011),
pp. 9–14, and Horsten (2011), pp. 2–3.

Axiomatizing Truth: Why and How?
189
Given that we will take the truth predicate to be applicable to some or all sen-
tences within a speciﬁed formal language, it is standard in the preponderance of the
literature to take Peano Arithmetic (PA) as a base theory, though weaker theories
suﬃce for much of the work. Let L be the language of PA and LT be its extension
by the unary predicate symbol T(x). We shall be considering formal systems S
extending PA whose language L(S ) includes LT. We use A, B,C, . . . to range over
formulas and sentences of L(S ). Given a sentence A of L(S ), let #A be the numeral
of the G¨odel number of A, so we can write T(#A) to express that A is true; for
simplicity in the following, write T(A) for T(#A). Among other things, this choice
of coding means that we can apply G¨odel’s method of constructing self-referential
sentences. That is, given any formula C(x) of L(S ) we can construct a sentence A
such that A ↔C(A) is provable in S . In particular, we can construct the “Liar”
sentence using ¬T(x) for C(x); I’ll use Λ to denote it instead of a Roman cap letter,
i.e. Λ is a sentence of LT and S proves Λ ↔¬T(Λ).9
Now, a minimum requirement for (L2) is that S proves the sentence P: “all
sentences provable in PA are true”.
For (L3), T(A) is syntactically acceptable for every sentence A of L(S ).10
By the T-biconditionals in (L4) is meant the sentences T(A) ↔A for A in L(S ).
Thus (L4) requires that all of these are provable in S .
Compositionality (L5) means that S proves T(¬A) ↔¬T(A), T(A ∨B) ↔
T(A) ∨T(B), T(∀xA(x)) ↔∀xT(A(num.(x))), and so on for the other propositional
operators and the existential quantiﬁer. To formulate more general versions, we
use operations on numbers that correspond to the logical operations, via the “dot”
notation, i.e. ¬., ∨.,∀., etc. Thus, for example ¬.#A = #(¬A). Then we can write
∀x(SentL(S )(x) →[T(¬.x) ↔¬T(x)]), and so on, where SentL(S )(x) is a formula of
L expressing that x is the number of a sentence of L(S ).
(L6) means that S has a model in which the language of PA is given its standard
interpretation.
For (L7), by the “outer logic” of S is meant its basic logical axioms and rules.
By its “inner logic” is meant the laws holding for those A such that S proves T(A).
(L8) simply means that the basic logic of S (its “outer logic”) is classical.
Tarski’s Undeﬁnability Theorem. If S satisﬁes (L1), (L3), (L4) and (L8) then S
is inconsistent.
The proof as usual makes use from (L1) and (L3) of the construction of a Liar
sentence Λ such that S proves Λ ↔¬T(Λ), which when combined with the as-
9Often, ‘λ’ is used for a Liar sentence.
10Actually, as long as the truth predicate T is a predicate of numbers, we would say that T(A) is
syntactically acceptable for every sentence A (via its G¨odel number) even for a typed theory of truth.
The signiﬁcance of (L3) lies in connection with (L4) which would be restricted in the case of a typed
theory; the same holds for the compositionality conditions on truth in (L5).

190
Solomon Feferman
sumption from (L4) that Λ ↔T(Λ), leads to a contradiction under the assumption
in (L8) of classical propositional logic. (In fact, as noted in fn. 2 intuitionistic logic
suﬃces.)
The question in view of Tarski’s theorem is, if one is to axiomatize truth in a
consistent type-free way, which of the criteria to accept and which to reject. Of
course one will also want to give arguments for these. Given the aim, one will
certainly accept (L1), that we are working within an extension S of PA, and (L3),
that all sentences of L(S ) are admissible arguments for the T predicate. Moreover,
if S is to be consistent, we shall certainly want it to have a model, and it is desirable
then to grant (L6) that it has a model which is standard for the natural numbers and
hence in which all axioms of PA are true. It is then reasonable to demand that one
be able to prove that in S , i.e. to accept (L2).
This leaves (L4), (L5), (L7) and (L8) in question. Let me begin with the last
of these, namely that the outer logic of S should be classical. There have been a
number of approaches to the consistent type-free axiomatization of theories of truth
that are based on a restriction of classical logic, such as one form or another of
three-valued logic or many-valued logics more generally, or the rejection of such
principles as ex falso quodlibet in paraconsistent logics. In Feferman (1984), of
the former I wrote that “nothing like sustained ordinary reasoning” can be carried
out in them, and it is my impression that the same holds as well for the latter.
Other approaches have been based on extensions by new connectives, such as a new
conditional or biconditional, which do not satisfy the same laws as the classical (or
even intuitionistic) conditional or biconditional, in terms of which the T-scheme is
rewritten. One such is given in the third example of axiomatization from my own
work below, as an extension of classical logic. I defend such uses, but not those
which make essential restrictions in the logic otherwise, such as in Field (2008).
So in that sense, I strongly favor (L8). But for the cases where the T-scheme (L4)
is not written in terms of a new biconditional, this means that I can only accept it
with some restrictions; that in turn may aﬀect how much of compositionality (L5)
is accepted. Finally, I reject the demand that the outer logic equal the inner logic
(L7), if the inner logic is some essential weakening of classical logic such as those
mentioned above.
4
How to axiomatize: Three examples.
These three examples illustrate how my own choices as to which criteria to accept
and which to modify or reject have been dealt with in my own work on the axiom-
atization of truth. The reader is referred in each case to the publication in question
for the actual presentation of the systems involved; only certain speciﬁc aspects of

Axiomatizing Truth: Why and How?
191
those are discussed here as are needed to explain how they relate to the preceding
criteria. For certain reasons, I present these in reverse order from that of date of
publication.
4.1
Axioms for determinateness and truth (Feferman 2008).
This begins (pp. 206–207) with the statement of a general philosophical position:
Every predicate has a domain of signiﬁcance; it makes sense to apply the predicate
only to objects in that domain (cf. also Russell 1908). In the case of the truth
predicate T, the domain D in question is taken to consist of the sentences that
are meaningful and determinate, i.e. have a deﬁnite truth value, true or false.11 D
includes various but not necessarily all grammatically correct sentences that involve
the notion of truth itself, for example the statement P that each sentence provable
in PA is true. At any rate, T(A) →D(A) holds for each sentence A. Write F(A) for
T(¬A); then also F(A) →D(A) for each A. It follows that D(A) can here be deﬁned
as T(A) ∨F(A), but there is a reason for keeping it as an additional basic predicate,
namely to state conditions on it that are prior to those for T. Thus, in the case of
this example, L(S ) is the extension of L by T and D, and S itself is denoted DT. In
accordance with the preceding, (L1), (L3) and (L8) are accepted but (L4) and (L5)
need to be restricted. Namely, the restriction of the T-scheme is to take the form,
(L4)* D(A) →(T(A) ↔A) for each sentence A in L(DT).
Similarly, compositionality for T should hold only under assumption of D for all
the formulas involved. The basic logical operations of DT are ¬, ∨, →, and ∀,
with →not deﬁned in terms of ¬ and ∨, but its logic is the standard one of the
classical conditional, so that (L8) holds in full. Every L sentence satisﬁes D. The
(strong) compositionality axioms for both D and T come in pairs and are expressed
in generality via variables that are taken to range over the formulas of L(DT). For
example, we assume
D(x ∨.y) ↔D(x) ∧D(y) ,
i.e. D holds of a disjunction iﬀit holds of both disjuncts, and then as usual,
D(x ∨.y) →[T(x ∨.y) ↔T(x) ∨T(y)] .
The axioms for negation and universal quantiﬁcation are treated similarly. How-
ever, A →B behaves diﬀerently from ¬A ∨B within the context of the D predicate
11Some authors, e.g. Kripke (1975) regard the Liar sentence as meaningful though not determinate.
I do not agree, but in order to avoid controversy on this point, allow for the possibility of meaningful
statements that are not determinate.

192
Solomon Feferman
for a technical reason to be explained below. Namely, we take as axiom
D(x →.y) ↔D(x) ∧[T(x) →D(y)] ,
but we still assume as usual
D(x →.y) →[T(x →.y) ↔(T(x) →T(y))] .
The restricted T-scheme (L4)* above is then proved as a direct consequence of
these axioms and we have full compositionality for T under D, i.e. a form (L5)* of
(L5). Coming back to the D axiom for the conditional, it turns out that if →were
deﬁned as usual in terms of ¬ and ∨, we could prove the sentence
P := ∀x[SentL(x) ∧ProvPA(x) →T(x)].
This may be enough to satisfy (L2), depending on how we interpret it. A stronger
reading of (L2) is that we should also be able to prove T(P) as well, and for that we
need the above condition on D for conditionals.
The consistency of DT is proved by exhibiting a model which is standard for
the natural numbers, so that (L6) is met. Moreover, we have D(A) for each sentence
A of the language L of arithmetic, so we have the standard truth conditions for those
sentences.
Let us turn ﬁnally to (L7) and the relation of the outer logic to the inner logic
in this system. Constructing a Liar sentence Λ as usual, i.e. one for which Λ ↔
¬T(Λ) is provable, we see that ¬D(Λ) must hold, otherwise we would derive a
contradiction from (L4)*. It follows that ¬D(Λ∨¬Λ) holds, by our axioms for D on
disjunctions. Since T(Λ∨¬Λ) implies D(Λ∨¬Λ), we then also have ¬T(Λ∨¬Λ).
But in DT we of course prove Λ ∨¬Λ, so the outer logic does not equal the inner
logic in this case.12 The situation here is similar in this respect to what was met in
the system KF, discussed next.
4.2
The system KF (Feferman 1991).
My axiomatization of the (minimal) three-valued ﬁxed point construction in Kripke
(1975) was circulated as notes in 1979. Reinhardt (1985, 1986) took that up for con-
sideration and dubbed the system “Kripke-Feferman”, which has since stuck with
the abbreviation KF. It then played a central role in the work of McGee (1991)
on the axiomatization of truth. The purpose of my own publication involving KF,
“Reﬂecting on incompleteness” (Feferman 1991) was instead completely instru-
mental, namely to use an axiomatic type-free theory of truth in order to establish
12The situation is similar for the sentence called the “Revenge of the Liar.”

Axiomatizing Truth: Why and How?
193
transﬁnitely iterated reﬂection principles without requiring a transﬁnite hierarchy
of truth theories. KF was the basic system introduced for that purpose; it was used
there to deﬁne the notion of reﬂective closure of a schematic axiom system. How-
ever, that was subsequently replaced by a more general notion of unfolding of a
schematic system, which did not make use of a theory of truth; cf. Feferman (1996)
and Feferman and Strahm (2000, 2010).
Since KF took on a life of its own within the work on axiomatic theories of
truth, let me consider only one problem about it that has been given much atten-
tion, namely that it violates criterion (L7) according to which the outer logic and the
inner logic of truth should coincide. In the KF case, the outer logic is classical and
the inner one is Kleene’s strong three valued logic. Despite the prima facie plausi-
ble arguments made by Leitgeb, Halbach, Horsten, and others for criterion (L7) I
have several reasons why I reject it in this and similar cases; it is not necessary to
know the details of the system KF to understand these.
(i) First of all, the distinction between outer and inner logics is only a problem
if one conﬂates two notions of truth, namely the notion of grounded truth
given by Kripke’s least ﬁxed-point construction, and our everyday notion of
truth not tied to any particular semantical construction or theory. Thus, in
KF, T(A) expresses that the sentence A is a grounded truth while A itself, if
provable, is counted as true in the informal sense. So on that reading there is
no conﬂict between accepting both ¬T(Λ ∨¬Λ) and Λ ∨¬Λ for a formal liar
sentence Λ.
(ii) For me, the main direct use of KF is to reason systematically about the prop-
erties of the Kripke construction under the Why purposes 4 and 5 above.
But as I have written in Feferman (1984) p. 264 concerning Kleene’s and
Lukasiewicz’ three valued logic, “nothing like sustained ordinary reasoning
can be carried out in either logic.”
I admire the success of Halbach and
Horsten (2006) in axiomatizing the Kripke construction in Kleene 3-valued
logic in a system PKF, but inspection of the result has given me all the more
reason to disagree with the criterion (L7). In addition, even though Halbach
(2011) sec. 16.1 presents a variant of PKF, all the other systems he deals with
in his book are based on classical logic, and in Ch. 20 he gives at length a
number of reasons for preferring classical systems even where those violate
(L7).
(iii) Still, examples like that above with the Liar sentence Λ, or related sentences
like the Revenge of the Liar, may give one pause. As to this, I wrote toward
the end of (Feferman 2008) where we met the similar problem:

194
Solomon Feferman
[T]he provability in DT of sentences ¬T(A) for which A is prov-
able might be regarded as “unintended consequences” or “anoma-
lies” or “little monsters”. In a way, this is analogous to other sit-
uations in mathematics. For example, to develop a good theory
of integration, Lebesgue introduced his theory of measure; that
has many excellent properties but also the unintended consequence
that there are nonmeasurable sets; [however, their] existence does
not aﬀect the positive applications of the theory .... Another ex-
ample is the existence of space-ﬁlling curves as a consequence of
a good theory of continuous mappings formulated in purely topo-
logical terms.
(iv) One of the reasons (number 6) given for axiomatization at the beginning of
this article is that one can compare like and unlike axiomatizations as to their
proof-theoretic strength. In Feferman (1991) I introduced two extensions of
KF for the notion of reﬂective closure, Ref(PA) and Ref∗(PA), and deter-
mined their strengths to be the same as that of the union of the ramiﬁed sys-
tems RAα for α < ε0 and α < Γ0, resp. At the end of Feferman (2008) I
conjectured that one would obtain the same strengths for the systems DT and
a suitable extension DT ∗, resp. These conjectures were subsequently veriﬁed
in Fujimoto (2010). By contrast, the system PKF is relatively weak, as shown
in Halbach (2011) sec. 16.2, namely its proof-theoretic strength is the same
as the union of the RAα for α < ωω.13
4.3
An axiomatization of deﬂationism using an intensional equiv-
alence operator (from Feferman 1984).14
Deﬂationism is one of the most popular theories of truth these days. Actually, as ex-
plained in Ch. 3 of Burgess and Burgess (2011), this has been spelled out in a great
variety of ways, starting with the so-called redundancy theory of Ramsey (1927),
according to which there is nothing more to the assertion of truth of a sentence than
the assertion of the sentence itself. One of the foremost recent proponents of de-
ﬂationism is Horwich (1990) under the label minimalism. Aside from the fact that
13In Feferman and Strahm (2000) it was shown that the strength of the full unfolding U∗(NFA) of a
basic schematic system NFA of non-ﬁnitist arithmetic is the same as that of the union of the RAα for
α < Γ0, the least impredicative ordinal.
14The article Feferman (1984) was presented as Part I of a two-part article, with the second part to
be devoted of the formalisms developed to applications to mathematics, especially the foundations of
category theory in an unrestricted sense. But the second part was never written, because the applications
did not work out as hoped; instead I have pursued quite diﬀerent approaches to the foundations of
category theory.

Axiomatizing Truth: Why and How?
195
Horwich treats truth as a predicate of propositions, rather than sentences, his view
is that
for one to understand the truth predicate is for one to have the disposi-
tion to accept any T-biconditional proposition...Against a background
of classical logic, this is more or less the same as having the disposi-
tion to infer the conclusion proposition from the premise proposition
in any T-introduction or T-elimination...(Burgess and Burgess 2011,
p. 44)
Considered axiomatically and taking the language to include the truth predicate as
well as using sentences rather than propositions, these are actually two diﬀerent
ideas. The ﬁrst is that one accepts all T-biconditionals in the language of LT, i.e.
all equivalences T(A) ↔A. The second is that one accepts all inference rules of
the form A/T(A) and T(A)/A. These are quite diﬀerent since as we know, over
Peano arithmetic in classical logic, the set of T-biconditionals is inconsistent. On
the other hand, Friedman and Sheard (1987) have shown that one can consistently
accept both all T-Introduction rules and all T-Elimination rules; cf. also Halbach
(2011), Ch. 14.
I shall here interpret deﬂationism in the form that, by deﬁnition, each T(A) eval-
uates out to truth (t) or falsity (f) in the same way as A, allowing for the possibility
that both A and T(A) may lack a truth value. Equivalence or equality by deﬁnition
is taken to be a new connective ≡diﬀerent from the truth-functional biconditional
↔, applicable to instances where both sides may fail to be deﬁned.15 So, in general,
A ≡B is informally taken to mean that A and B evaluate out to truth or falsity in
the same way when deﬁned.
In the following, a system of axioms S formulated within the classical ﬁrst
order predicate calculus with equality is presented in the language L of PA extended
by the unary predicate symbol T and with the binary sentential operation symbol
applicable to all pairs of formulas A, B of L(S ) to form A ≡B. In this case we
write t for the formula (0 = 0) and f for its negation, and then take D(A) =def
(A ≡t ∨A ≡f); A is called deﬁnite (or determinate) if D(A) holds. For simplicity,
several of the axioms of S are stated informally to encompass a number of formal
statements. In the following, unless otherwise speciﬁed ‘A’ is taken to range over
the formulas of L(S ). For A(x, y, . . . ) with possible free variables x, y, . . . , T(A)
is written for T(A(num.x, num.y, ...)). In addition to the axioms of PA, S has the
15This is a frequent situation in analysis, for example where one takes
f ′(x) =def lim
u→0( f(x + u) −f(x)/u) .

196
Solomon Feferman
following axioms for ≡, T and D.16
Ax. 1 T(A) ≡A
Ax. 2 ≡is an equivalence relation
Ax. 3 ¬(t ≡f)
Ax. 4 ≡preserves ¬, ∨, ≡and ∀
Ax. 5 D(A) holds for each atomic formula A of L
Ax. 6 D is closed under ¬, ∨,and ∀
Ax. 7 [A ≡t →A] ∧[A ≡f →¬A], for each A.
Theorem (Aczel and Feferman 1980, Feferman 1984). S is a conservative exten-
sion of PA.
NB. In Aczel and Feferman (1980), we wrote T(A) for A ≡t, while here T(x) is
a basic predicate. Ax. 1 replaces the Abstraction Principle (AP) y ∈{x : A(x)} ≡
A(y) used there; that is essentially the same as the scheme (T0)≡of Feferman (1984),
p.268. Note also that a more general theorem is proved op. cit. using S as the
extension by the axioms 1-6 of any given extension S 0 of PA in the language of
PA.
There are two proofs of this theorem. The ﬁrst, due to me in the 1980 article
with Aczel, makes use of a combinatory style reduction relation for formulas,
A ≥B, which is shown to satisfy the Church-Rosser theorem. An N-standard
model for S is deﬁned in which one takes A ≡B to hold just in case there exists
a C such that A ≥C and B ≥C. The second proof, due to Aczel, and presented
in Feferman (1984), pp. 268-269, is carried out by turning the 3-valued model of
Kripke (1975) into a 2-valued model in an unexpected way.
NB. The connective ≡fails to satisfy some expected laws such as to infer B from
A ≡B and A. For example, if we take a Liar sentence Λ such that S proves
Λ ↔¬T(Λ), we have T(Λ) ≡Λ by Ax. 1, and thus ¬T(Λ) ≡T(Λ) by Ax. 2. But
¬T(Λ) is true in the just indicated model of S , so if the rule held with A = ¬T(Λ)
and B = T(Λ), we would have a contradiction.
We next show that in combination with a few of the other axioms Ax. 1 leads
to the usual truth biconditionals for deﬁnite formulas.
16I am indebted to Kentaro Fujimoto for his suggestions to improve the formulation of S and its
consequences that had been given in a draft of this paper.

Axiomatizing Truth: Why and How?
197
Lemma 1. D(T(A)) ↔D(A) for each formula A of L(S ).
Proof. By Ax. 1 and Ax. 2.
□
Lemma 2. D(A) ∧(A ≡B) →D(B).
Proof. By Ax. 2.
□
Lemma 3. D(A) ∧(A ≡B) →(A ↔B).
Proof. By Ax. 7 and Lemma 2. Suppose D(A), (A ≡B), and A. Then A ≡t, for
if A ≡f then ¬A by Ax. 7; so B ≡t, so B by Ax. 7. Thus A →B; similarly,
B →A.
□
Lemma 4. D(A) →(T(A) ↔A).
Proof. By Ax. 1 and Lemma 3.
□
It may then be seen that the truth conditions for ¬ , ∨, and ∀are as usual for
deﬁnite formulas. Using the methods of Feferman (2008), the axioms of S can be
strengthened to having D be strongly compositional in Ax. 6 (i.e. the implications
are replaced by equivalences) and still have the system be conservative over PA.
Discussion. Since S is a conservative extension of PA, it does not satisfy the con-
dition (L2). For if S proved the sentence P expressing that all provable sentences
of PA are true, it would follow that S and hence PA itself proves the consistency of
PA. Also, S is not immune to the “generalization” problem that has been raised for
deﬂationary theories, i.e. the provability of formal versions of statements such as
that for any deﬁnite proposition p, p ∨¬p is true. For, that cannot be expressed in
L(S ) with the use of D as an operator, not a predicate. However, we can consistently
extend the axioms DT of Part I (i.e., of Feferman 2008) into the language L(S ) by
addition of Ax. 1 and some of the other axioms of S , in which such generalizations
can be expressed and proved, since there D(x) is written for T(x) ∨T(¬.x).
5
Conclusion
Most of the preceding has been devoted to the considerations in each example of
which of the Leitgeb criteria (L1)-(L8) are to be accepted and which are to be
rejected, and little to the reasons for axiomatization given in Sec. 1, though those
are always in the background. But given those reasons, I would urge the pursuit
of axiomatizations of semantical or deﬁnitional approaches that have not yet been
thus treated, and the close examination of them in the light of the given criteria.

198
Solomon Feferman
Acknowledgments
I would like to thank Kentaro Fujimoto and the referee for a number of useful
comments on a draft of this paper. Thanks also to Hannes Diener for converting it
from a Word ﬁle to a LATEXﬁle.
References
Aczel, Peter and Solomon Feferman (1980), Consistency of the unrestricted ab-
straction principle using an intensional equivalence operator, in (J. P. Seldin
and J. R. Hindley, eds.), To H. B. Curry: Essays on Combinatory Logic,
Lambda Calculus and Formalism, Academic Press, New York, 67-98.
Barwise, Jon and John Etchemendy (1987), The Liar: An Essay on Truth and
Circularity, Oxford University Press, Oxford.
Blackburn, Simon and Keith Simmons (eds.), (1999), Truth, Oxford University
Press, Oxford.
Burgess, Alexis G. and John P. Burgess (2011), Truth, Princeton University Press,
Princeton.
Cantini, Andrea (1996), Logical Frameworks for Truth and Abstraction: An Ax-
iomatic Study, vol. 135 of Studies in Logic and the Foundations of Mathe-
matics, Elsevier, Amsterdam.
Feferman, Solomon (1984), Toward useful type-free theories I, J. Symbolic Logic
49, 75–111; reprinted in Martin (1984), 237–287.
(1991), Reﬂecting on incompleteness, J. Symbolic Logic 56, 1–49.
(1996), G¨odel’s program for new axioms: Why, where, how and what? in
(P. Hajek, ed.) G¨odel ’96, vol. 6 of Lecture Notes in Logic, 3–22.
(2008), Axioms for determinateness and truth, Review Symbolic Logic 1,
204–217.
Feferman, Solomon and Thomas Strahm (2000), The unfolding of non-ﬁnitist
arithmetic, Annals of Pure and Applied Logic 104, 75-96.
(2010), The unfolding of ﬁnitist arithmetic, Review of Symbolic Logic 3,
665–689.

Axiomatizing Truth: Why and How?
199
Field, Hartry (2008), Saving Truth from Paradox, Oxford University Press, Ox-
ford.
Friedman, Harvey and Michael Sheard (1987), An axiomatic approach to self-
referential truth, Annals of Pure and Applied Logic 40, 1–10.
Fujimoto, Kentaro (2010), Relative truth deﬁnability of axiomatic theories, Bull.
Symbolic Logic 16, 305-344.
Gupta, Anil and Nuel Belnap (1993), The Revision Theory of Truth, MIT Press,
Cambridge MA.
Halbach, Volker (2011), Axiomatic Theories of Truth, Cambridge University
Press, Cambridge.
Halbach, Volker and Leon Horsten (2006), Axiomatizing Kripke’s theory of truth,
J. Symbolic Logic 71, 677–712.
Horsten, Leon (2011), The Tarskian Turn: Deﬂationism and Axiomatic Truth,
MIT Press, Cambridge, MA.
Horwich, Paul (1990), Truth, Basil Blackwell, Oxford; 2nd edition, 1998, Claren-
don Press, Oxford.
Kirkham, Richard L. (1995), Theories of Truth: An Introduction, MIT Press, Cam-
bridge MA.
Kripke, Saul (1975), Outline of a theory of truth, J. of Philosophy 72, 690-712;
reprinted in Martin (1984), 53–81.
Leitgeb, Hannes (2007), What theories of truth should be like (but cannot be),
Blackwell Philosophy Compass 2/2, 276–290.
Lynch, Michael P. (ed.) (2001), The Nature of Truth: Classical and Contemporary
Perspectives, MIT Press, Cambridge, MA.
Martin, Robert L. (ed.) (1970) Paradox of the Liar; reprinted (1978), Ridgeview
Pub. Co., Reseda, CA.
(ed.) (1984), Recent Essays on Truth and the Liar Paradox, Oxford Uni-
versity Press, New York.
Martin, Robert L. and Peter Woodruﬀ(1975), On representing “True-in-L” in L,
Philosophia 5, 213-217; reprinted in Martin (1984), 47–51.

200
Solomon Feferman
Maudlin, Tim (2004), Truth and Paradox: Solving the Riddles, Clarendon Press,
Oxford.
McDonald, B. E. (2000), On meaningfulness and truth, J. Philosophical Logic 29,
433–482.
McGee, Vann (1991), Truth, Vagueness and Paradox: An Essay on the Logic of
Truth, Hackett Pub. Co., Indianapolis.
Ramsey, Frank (1927), Facts and propositions, Aristotelian Society Supplement
7, 153–170; reprinted in part in Blackburn and Simmons (1999), 106–107.
Reinhardt, William (1985), Remarks on signiﬁcance and meaningful applicability,
in (L. P. de Alcantara, ed.) Mathematical Logic and Formal Systems: A
Collection of Papers in Honor of Professor Newton C. A. Da Costa, vol. 94
of Lecture Notes in Pure and Applied Mathematics, 227–242.
(1986), Some remarks on extending and interpreting theories, with a par-
tial predicate for truth, J. Philosophical Logic 15, 219–251.
Russell, Bertrand (1908), Mathematical logic as based on the theory of types,
Amer. J. of Mathematics 30, 222–262; reprinted in (J. van Heijenoort, ed.)
From Frege to G¨odel: A Source Book in Mathematical Logic (1967), Har-
vard University Press, Cambridge MA, 150–182.
Sheard, Michael (2002), Truth, provability, and na¨ıve criteria, in (V. Halbach and
L. Horsten, eds.), Principles of Truth, Dr. H¨ansel-Hohenhausen, Frankfurt a.
M., 169–181.
Tarski, Alfred (1935), Der Wahrheitsbegriﬀin die formalisierten Sprachen, Stu-
dia Philosophica 1, 261–405, English translation: The concept of truth in
formalized languages, in Tarski (1956), 152–278.
(1956), Logic, Semantics and Metamathematics: Papers from 1923 to
1938 (translated into English by J. H. Woodger), Clarendon Press, Oxford;
2nd revised edition (1983), (J. Corcoran, ed.) Hackett Pub. Co., Indianapolis.

On the Strength of some Semi-Constructive
Theories
Solomon Feferman
Most axiomatizations of set theory that have been treated metamathematically
have been based either entirely on classical logic or entirely on intuitionistic
logic. But a natural conception of the set-theoretic universe is as an indeﬁ-
nite (or “potential”) totality, to which intuitionistic logic is more appropriately
applied, while each set is taken to be a deﬁnite (or “completed”) totality, for
which classical logic is appropriate; so on that view, set theory should be ax-
iomatized on some correspondingly mixed basis. Similarly, in the case of pred-
icative analysis, the natural numbers are considered to form a deﬁnite totality,
while the universe of sets (or functions) of natural numbers are viewed as an
indeﬁnite totality, so that, again, a mixed semi-constructive logic should be the
appropriate one to treat the two together. Various such semi-constructive sys-
tems of analysis and set theory are formulated here and their proof-theoretic
strength is characterized. Interestingly, though the logic is weakened, one can
in compensation strengthen certain principles in a way that could be advanta-
geous for mathematical applications.1
1
Introduction
There are various foundational frameworks in which the full universe or domain of
its objects is considered to be indeﬁnite but for which certain predicates and logical
operations on restricted parts of the universe are considered to be deﬁnite. For ex-
ample, on one view in the case of set theory, each set is considered to be a deﬁnite
(or “completed”) totality, so that the membership relation and bounded quantiﬁca-
tion are deﬁnite, while the universe of sets at large is an indeﬁnite (or “potential”)
totality. The idea carries over to frameworks with more than one universe, some of
which may be regarded as deﬁnite while others are indeﬁnite. For example, in the
case of predicativity, the natural numbers are considered to form a deﬁnite totality,
1This is a reprint, with the author’s permission, of an article which appeared in the volume “Proofs,
Categories and Computations. Essays in Honor of Grigori Mints”, Solomon Feferman and Wilfried
Sieg, eds., College Publications, London, 2010. Some minor corrections have been made.

202
Solomon Feferman
while the universe of sets (or functions) of natural numbers forms an indeﬁnite to-
tality. Thus quantiﬁcation over the natural numbers is taken to be deﬁnite, but not
quantiﬁcation applied to variables for sets or functions of natural numbers. Most
axiomatizations of set theory that have been treated metamathematically have been
based either entirely on classical logic or entirely on intuitionistic logic, while al-
most all axiomatizations of predicative systems have been in classical logic. But it
has been suggested on philosophical grounds that it is more appropriate to restrict
the application of classical logic to deﬁnite predicates and quantiﬁers and to take the
basic logic otherwise to be intuitionistic. We shall show here, for various examples
— including the ones that have been mentioned — that while this may provide a
more philosophically satisfying formal model of the given foundational framework
— there is no diﬀerence in terms of proof-theoretical strength from the associated
system based on full classical logic; in that respect they are equally justiﬁed. On
the other hand, the semi-constructive systems in general have a further advantage
that they admit more formally powerful principles — such as the unrestricted ax-
iom of choice — without increase of strength, and this can be advantageous when
considering what mathematics can be accounted for in the given systems.
The initial stimulus for my work here was the paper of Coquand and Palmgren
(2000) in which they give a constructive sheaf model for a theory of ﬁnite types over
the natural numbers together with a domain of countable tree ordinals, formulated
in intuitionistic logic plus the so-called numerical omniscience scheme for φ an
arbitrary formula:
(NOS)
∀n[φ(n) ∨¬φ(n)] →∀nφ(n) ∨∃n¬φ(n)
A special case of this non-constructive principle is what Errett Bishop (1967)
called the limited principle of omniscience:
(LPO)
∀nf(n) = 0 ∨∃nf(n) , 0
Bishop pointed out that all the results in classical analysis for which he
found constructive substitutes follow from those substitutes plus LPO. In Fefer-
man (2001) I reported determination of a bound on the proof-theoretical strength
of the Coquand-Palmgren system by means of an extension of G¨odel’s Dialectica
(functional) interpretation interpretation using non-constructive operators. That
method goes back to Feferman (1971), with further applications in Feferman
(1977), (1979); semi-constructive systems there played an essential intermediate
role in the use of the method to determine the proof-theoretical strength of various
classical systems. Here, by contrast, they are at the center of our attention.
What’s needed in the following about G¨odel’s (D-)interpretation is reviewed in
section 2; the reader is referred to the exposition of the basic interpretation and var-
ious of its extensions in Avigad and Feferman (1998) for more details. In section 3,

On the Strength of some Semi-Constructive Theories
203
we take up the particular extension by means of the non-constructive minimum op-
erator, where it is also shown by a simple argument that (NOS) follows from (LPO)
under the assumption of the Axiom of Choice (AC), as expressed in our ﬁnite type
systems and veriﬁed by the D-intepretation. This is followed in section 4 by deter-
mination of the strength of some semi-constructive theories of ﬁnite type over the
natural numbers, and then in section 5 the same augmented by the type of count-
able tree ordinals. Both sections 4 and 5 make direct use of previously established
results. The main new results are in section 6, which deals with the strength of
some semi-constructive systems of admissible set theory with strong choice princi-
ples plus a generalization of NOS called the Bounded Omniscience Scheme (BOS)
and where the method of non-constructive D-interpretation is adapted in a new
way. I conclude in section 7 with comparison with work on various related systems
and some open questions, in particular with strong systems of semi-intuitionistic
set theory due to Poszgay (1971, 1972), Tharp (1971), Friedman (1973) and Wolf
(1974) and, by contrast, a system conservative over PA, due to Friedman (1980).
The reader familiar with the material of Avigad and Feferman (1998) through
its section 8 is encouraged to skip directly to the new results here in section 6, after
taking note of Theorem 2 in section 3.2 below.
2
Review of G¨odel’s Dialectica interpretation
The main basic notions, notation and results concerning this interpretation are re-
called here from Avigad and Feferman (1998). For each formula φ, the double-
negation (or negative) translation of φ is denoted by φN, and the Dialectica (or
D-) interpretation of φ is denoted by φD. The N-translation in general takes one
from classical theories to formally intuitionistic theories, and the D-interpretation
is then applied to take one to a quantiﬁer free theory of functionals of ﬁnite type.
The basic example is given by the N-translation of Peano Arithmetic PA into Heyt-
ing Arithmetic HA (G¨odel, Gentzen) followed by the D-interpretation of HA into
a quantiﬁer-free theory T of primitive recursive functionals of ﬁnite type (G¨odel).
The latter extends directly to a D-interpretation of a ﬁnite type extension HAω of
HA into T, and then by making a similar extension PAω of PA, we obtain a com-
posite ND-interpretation of that system into T. Finally, T has a model in HEO,
the Hereditarily Extensional (Recursive) Operations of ﬁnite type, and that can be
formalized in PA. Thus all these systems are of the same proof-theoretical strength.
For the ﬁnite type theories involved, the ﬁnite type symbols (t.s.) σ, τ, . . . are
generated as follows: (1) 0 is a t.s. and (ii) if σ, τ are t.s., then so also is σ →
τ. These theories have inﬁnitely many variables xτ, yτ, zτ, . . . of each type τ; type
superscripts are suppressed when there is no ambiguity. We occasionally use other

204
Solomon Feferman
kinds of letters like f, g, . . . n, m, . . . as well as capital letters X, Y, . . . for variables
of appropriate types. Terms s, t, . . . are generated from the variables and constants
(to be described) by closure under application ts (or t(s)) when t is of a type σ →τ
and s is of type σ, the result being of type τ.
Application in terms such as rst is read by association to the left, while the t.s.
ρ →σ →τ is read by association to the right. Each higher type symbol σ can be
written in the form σ = (σ1 →. . . →σk →0); then equality s = t at type σ is
informally regarded as an abbreviation for sx1 . . . xk = tx1 . . . xk where the xi are
fresh variables of type σi for i = 1, . . . , k. The formal axioms and rules that we take
to govern equality at higher types are given by the so-called weakly extensional
approach due to Spector and described in Avigad and Feferman (1998), p. 350.
The type 0 →0 is also denoted 1, and the type 1 →0 is denoted 2. The constant
symbols include 0 of type 0 and Sc of type 1. In addition we have symbols K, S
for the usual combinators in all appropriate types, satisfying equations of the form
Kst = s and S rst = rt(st); the typed λ-calculus is then introduced by deﬁnition
as usual. Finally we have constant symbols R for the recursors in all appropriate
types, satisfying equations of the form
Rxy0 = x and Rxyn′ = yn(Rxyn)
where n is a variable of type 0 and n′ = Sc(n). The formulas φ, ψ, . . . of T are
generated from the equations s = t and the falsity ⊥by closure under φ ∧ψ, φ ∨ψ,
and φ →ψ; then ¬φ is deﬁned as φ →⊥. The formulas of PAω and HAω are in
addition closed under universal and existential quantiﬁcation, ∀xφ and ∃xφ, w.r.t.
variables x of all ﬁnite types. The underlying logic of PAω is classical while that
of HAω and T is intuitionistic. The axioms in all three systems are as usual for 0
and Sc, and as indicated above for the symbols K, S and R. The induction axiom
scheme is given as usual in these systems, while it is formulated as a rule in T. One
may show that quantiﬁer-free (QF) formulas (with all equations restricted to terms
of type 0) are decided, i.e. satisfy the law of excluded middle (LEM) in all of these
systems.
For a formula φ of the quantiﬁed ﬁnite type language, the D-interpretation of φ
is of the form
φD = ∃x∀yφD(x, y)
where x, y are sequences (possibly empty) of ﬁnite type variables and φD is a QF
formula whose free variables are those of φ in addition to those of x and y. The
inductive deﬁnition of the D-interpretation for formulas φ, ψ with φD as above, and
ψD = ∃u∀vψD(u, v) is as follows:
(i) For φ an atomic formula, x and y are both empty and φD = φD = φ.

On the Strength of some Semi-Constructive Theories
205
(ii) (φ ∧ψ)D = ∃x, u∀y, v[φD(x, y) ∧ψD(u, v)]
(iii) (φ ∨ψ)D = ∃z, x, u∀y, v[(z = 0 ∧φD(x, y)) ∨(z = 1 ∧ψD(u, v))]
(iv) (∀zφ(z))D = ∃X∀y, zφD(Xz, y, z)
(v) (∃zφ(z))D = ∃x, z∀yφD(x, y, z)
(vi) (φ →ψ)D = ∃U, Y∀x, v[φD(x, Yxv), →ψD(Ux, v)]
With ¬φ deﬁned as φ →⊥, we have
(vii) (¬φ)D = ∃Y∀x¬φD(x, Yx)
The reasoning behind (iv) lies in the constructive acceptance of the Axiom of
Choice, here taken as the following scheme in all ﬁnite types:
(AC)
∀x∃yφ(x, y) →∃Y∀xφ(x, Yx)
The reasoning behind (vi) lies in a chain of steps2, an intermediate one of which
lies in transforming [∃x∀yφD(x, y) →∃u∀vψD(u, v)] into
(vi)∗∀x∃u∀v∃y[φD(x, y) →ψD(u, v)]
Implicitly, that makes use of a principle called Independence of Premises (IP)
that is not intuitionistically justiﬁed. Moreover, another one of the steps to (vi)
implicitly makes use of the ﬁnite type forms of Markov’s Principle,
(MP)
∀x(¬¬∃yφ →∃yφ) for QF φ
which is also not justiﬁed intuitionistically. Nevertheless, G¨odel’s interpretation
gives a constructive reduction of both AC and MP.3 In the case of AC this is imme-
diate, and in the case of MP, it is quite easy given that all QF formulas in the systems
we’re dealing with are decided. The additional power of the D-interpretation below
comes from the fact that (AC)D and (MP)D are veriﬁed quite generally.
The following is the direct extension from HA to its ﬁnite type version of
G¨odel’s main result (1958):
Theorem 1. If HAω + AC + MP proves φ and φD = ∃x∀yφD(x, y) then for some
sequence of terms t of the same type as the sequence x of variables, T proves
φD(t, y).
2See Avigad and Feferman (1998) pp. 346-347 for all the steps involved.
3It also veriﬁes the interpretation of IP, but we shall not make use of that fact.

206
Solomon Feferman
The main use of the recursor constants R is in verifying the D-interpretation of
the induction axiom scheme in HAω.
By QF-AC we mean the scheme AC restricted to QF formulas φ. Since for such
φ we have φN equivalent to φ, we see that (QF-AC)ND is also veriﬁed in T.
Corollary 2. PAω + QF-AC is N interpreted in HAω and so it is ND interpreted in
T.
By an analysis of the reduction of the terms of T to normal form, one sees that
its closed terms denote recursive functions deﬁned by ordinal recursions on proper
initial segments of the natural well-ordering of order type ϵ0. Hence all the systems
PA, PAω, HA, HAω and T have this same class of provably recursive functions.
3
The non-constructive minimum operator and inter-
pretation of NOS
3.1
The non-constructive minimum operator
One way to arrange for arithmetical formulas to satisfy the Law of Excluded Mid-
dle, LEM, in a system based as a whole on intuitionistic logic is to make them
equivalent to QF formulas by adjunction of a numerical quantiﬁcation operator E0
of type 2 satisfying the axiom
(E0)
E0 f = 0 ↔∃x(f x = 0)
for f, x variables of type 1 and 0, resp.
In order for this to satisfy the ND-
interpretation we need to verify the following two implications:
f x = 0 →E0 f = 0 and E0 f = 0 →∃x(f x = 0)
The ﬁrst of these is automatically taken care of, and the N-interpretation of the
second is taken care of by the veriﬁcation of MP, but in order to get its further D-
interpretation we need to have a functional X which satisﬁes E0 f = 0 →f(X f) =
0, and hence f x = 0 →f(X f) = 0. To take care of this we adjoin a new constant
symbol µ with axiom:
(µ)
f x = 0 →f(µf) = 0
We call µ the non-constructive minimum operator, though properly speaking that
would need an additional axiom specifying that µf is the least x such that f x = 0
if ∃x(f x = 0) and (say) is 0 otherwise; in fact, that is deﬁnable from µ using the
primitive recursive bounded minimum operator.

On the Strength of some Semi-Constructive Theories
207
3.2
The LPO axiom and the Numerical Omniscience Scheme
As stated, under the axiom (µ) every arithmetical formula is equivalent to a QF
formula in intuitionistic logic; various consequences of this for semi-constructive
systems incorporating that axiom will be dealt with in the next section. In particu-
lar, we can derive the NOS scheme for arithmetical formulas from that assumption.
But in the presence of AC we can do even more. We here understand by the NOS,
the scheme described in sec. 1 where we allow φ to be any formula of the language
of HAω, and by LPO the statement given in sec. 1, where ‘f’ is a variable of type
1.
Theorem 3.
(i) HAω + (µ) proves LPO.
(ii) HAω + (LPO) + AC proves NOS.
Proof. (i) is immediate, and for (ii) we note that if ∀n[φ(n) ∨¬φ(n)] holds, then
so also does ∀n∃k[k = 0 ∧φ(n) ∨k = 1 ∧¬φ(n)]. Hence by AC there exists f of
type 1 such that ∀n[( f(n) = 0 ↔φ(n)) ∧(f(n) = 1 ↔¬φ(n))]. □
4
Semi-constructive systems of ﬁnite type over the
natural numbers
4.1
Primitive recursion in a type 2 functional and Kleene’s variant
The system HAω + (µ) + (AC) oﬀers itself immediately for consideration as a
semi-constructive system of interest; this is a predicative system that is somewhat
stronger than PA. But we shall also consider systems using operators F of type 2
stronger than µ. Given any such F, Shoenﬁeld deﬁned a hierarchy HF
α of functions
for α less than the ﬁrst ordinal not recursive in F, such that the 1-section of F (i.e.,
the totality of type 1 functions recursive in F) consists of all those functions that
are primitive recursive in the usual sense in some such HF
α . Now the normalization
of terms of the system T augmented by such an F shows that its 1-section consists
of all those functions primitive recursive in some HF
α for α < ϵ0. In particular, the
1-section of the functionals deﬁned by closed terms of T augmented by µ consists
of the functions in the HYP hierarchy up to (but not including) ϵ0.
We shall also consider an interesting subsystem of T augmented by such type
2 functionals F, obtained by restricting the induction and recursion principles. The
motivation for that restriction lies in the fact that the recursors R with values of
higher type have a kind of impredicative character. For example, for values of
Rfgn of type 2, thought of as λh.Rfgnh, we have Rfgn′ = gn(λh.Rfgnh)) and that
evaluated at a given function h1 makes prima-facie reference to the values of Rfgn

208
Solomon Feferman
at all functions h. It is easily shown that non-primitive recursive functions such as
the Ackermann function may be generated in this way. Kleene (1959) introduced
restricted recursors ˆR satisfying the recursion equations
ˆRxy0z and ˆRxyn′z = y( ˆRxynz)
where z is a sequence of variables such that xz is of type 0. He showed that the
1-section of the functionals generated from 0, Sc, the K, S combinators and the ˆR
recursors by closure under application are exactly the primitive recursive functions.
Thus taking ˆT to be the subsystem of T with constants ˆR in place of the constants
R, and corresponding change of axioms, we have that the 1-section of ˆT consists
exactly of the primitive recursive functions in the usual sense. Now all this may
be relativized to a type 2 functional F to show that the 1-section of ˆT augmented
by F consists exactly of the functions primitive recursive in HF
n for some n < ω.
In particular, the 1-section of ˆT + (µ) consists of all the arithmetically deﬁnable
functions.
By Res-PAω and Res-HAω we mean the systems using the ˆR recursors in place
of the R recursors and with the axiom of induction restricted to QF-formulas.
4.2
The strength of some semi-constructive systems based on
the non-constructive minimum operator
We begin with semi-constructive variants of predicative systems, i.e.
systems
whose strength is at most that of ramiﬁed analysis up to the Feferman-Sch¨utte or-
dinal Γ0, or equivalently, the union of the (Π0
1-CAα) systems for α < Γ0.
Theorem 4.
(i) The systems Res-HAω + (AC) + (MP) + (µ) and Res-PAω +
(QF-AC) + (µ) are proof-theoretically equivalent to and conservative exten-
sions of PA; furthermore they are conservative extensions of the 2nd order
system ACA0 for Π1
2-sentences.
(ii) The systems HAω + (AC) + (MP) + (µ) and PAω + (QF-AC) + (µ) are proof-
theoretically equivalent to — and conservative extensions for Π1
2-sentences
of — the 2nd-order systems (in decreasing order) Σ1
1-DC, Σ1
1-AC, and the
union of the (Π0
1-CAα) systems for α < ϵ0.
(iii) The systems HAω + (AC) + (MP) + (µ) + (Bar-Rule) and PAω + (QF-AC)
+ (µ) + (Bar-Rule) are proof-theoretically equivalent to — and conservative
extensions for Π1
2 sentences of — the 2nd order systems (in decreasing order)
Σ1
1-DC + (Bar-Rule), Σ1
1-AC + (Bar-Rule), and the union of the (Π0
1-CAα)
systems for α < Γ0.

On the Strength of some Semi-Constructive Theories
209
(iv) There is no increase in strength when the NOS scheme is added to the semi-
constructive systems in (i)-(iii).
Proofs. The result (i) is from Feferman (1977), (ii) is from Feferman (1971) and
(iii) is from Feferman (1979). The ideas for their proofs are exposited in Avigad
and Feferman (1998), sec. 8. Brieﬂy, the proof of (i) uses the fact that the D-
interpretation of the semi-constructive system Res-HAω + (AC) + (µ) and the ND-
interpretation of the classical system Res-PAω + (QF-AC) + (µ) both take us into
ˆT + (µ), which is interpreted in PA preserving arithmetical sentences (as translated
using µ). For the conservation statement, one notes that under the µ axiom, every
Π1
2 sentence is equivalent to one of the form ∀f∃gφ(f, g), where φ is quantiﬁer-free,
hence if provable, it is preserved under the N-translation using (MP) and then under
the D-interpretation one obtains a type 2 term t such that ˆT + (µ) proves φ(f, t f).
That term deﬁnes g = t f arithmetically from f. The main steps of the proof of
(ii) follow the same lines, concluding with the interpretation in T + (µ), whose
1-section consists of the functions in the HYP hierarchy up to (but not including)
ϵ0, as described in 4.1 above. For (iii) the main new work goes ﬁrst into the D-
interpretation of HAω + (AC) + (MP) + (µ) + (Bar-Rule) in the extension of T + (µ)
by two new rules, (BR) and (TR). These rules involve expressing in QF form, well-
foundedness of any speciﬁc segment ⪯a of a given arithmetical well-ordering as the
open formula ∀x[∀y(y ≺a x →y ∈X) →x ∈X], denoted I(⪯a, X), where X is a set-
variable (i.e., a characteristic function at type 1). Then, for the natural well-ordering
≺of order type Γ0, the version BR of the Bar-Rule used in this context allows one
to pass from I(⪯a, X) for any speciﬁc a to the result I(⪯a, φ) of substituting in it any
formula φ(x) of the system for the formula x ∈X, while the rule (TR) allows one
to introduce a transﬁnite recursor on the given segment under the same hypothesis.
One gets up to each ordinal less than Γ0 by a boot-strapping argument, and the
proof that one doesn’t go beyond is via a normalization argument. See Feferman
(1979) pp. 87-89 for more details. Finally, (iv) is immediate by Theorem 2.
4.3
The strength of some semi-constructive systems based on µ
plus the Suslin-Kleene operator
For a given f, let Tree(f) be the tree consisting of all ﬁnite sequence numbers s such
that f(s) = 0. This tree is not well-founded if and only if ∃g∀x f(g | x) = 0, where
for any type 1 function g, g | x is the number s of the ﬁnite sequence g0, . . . , g(x−1).
The Suslin-Kleene operator is the associated type 2 choice functional µ1, obtained
by taking the left-most descending branch in Tree(f) if that tree is not well-founded.
It satisﬁes the axiom
(µ1)
∀x f(g | x) = 0 →∀x f((µ1 f) | x) = 0

210
Solomon Feferman
which may be re-expressed in QF form using the µ operator. From the work of
Feferman (1977) and Feferman and J¨ager (1983) one then obtains characterizations
of the proof-theoretical strength of the semi-constructive systems HAω + (AC) +
(MP) + (µ) + (µ1), its restricted version, and its extension under the Bar-Rule, in a
form analogous to Theorem 3. For example, in analogy to part (ii) of that theorem,
the strength of HAω + (AC) + (MP) + (µ) + (µ1) is characterized as that of the
iterated Π1
1-CA systems up to ϵ0, which is the same as that of (Σ1
2-DC). See Avigad
and Feferman (1998) pp. 384-385 for full statement of results and indication of
proofs. An alternative characterization may be given in terms of the iterated ID
systems up to ϵ0. And, ﬁnally, addition of the NOS comes for free by Theorem 2.
5
The strength of a semi-constructive theory of ﬁnite
type over the natural numbers and countable tree
ordinals.
Here we can draw directly on Avigad and Feferman (1998), sec. 9, which reports
the work of an unpublished MS, Feferman (1968). The type structure is expanded
by an additional ground type for abstract constructive countable tree ordinals, de-
noted Ω, and lower case Greek letters α, β, γ, . . . are used to range over Ω. But now
we use ‘N’ to denote the type symbol 0. The constants are augmented by 0Ωof
type Ω, Sup of type (N →Ω) →Ω, Sup−1 of type Ω→(Ω→N), and for each
σ, RΩσ of type (Ω→(N →σ) →σ) →σ →Ω→σ. The subscript ‘σ’ is
omitted from the ordinal recursor RΩσ when there is no ambiguity. The constant
0Ωrepresents the one-point tree, and for f of type (N →Ω), Sup( f) represents the
tree obtained by joining together the subgrees fn for each natural number n. For
α = Sup(f), Sup−1(α) = f is the constructor of α; in that case we write αn for
(Sup−1(α))n. For each type σ the ordinal recursor RΩworks to take an element a
of type σ, a functional f of type (Ω→(N →σ) →σ), and a tree ordinal α to an
element RΩfaα satisfying the recursion equations
(RΩ)
RΩfa0Ω= a, and for α , 0Ω, RΩfaα = fα(λn.RΩfaαn)
We also take the language to include the constant µ. In it, we form three theories
of countable tree ordinals of ﬁnite type, ﬁrst a classical theory COω
Ω+ (µ), then a
semi-intuitionistic theory SOω
Ω+ (µ), both with full quantiﬁcation at all ﬁnite types,
and ﬁnally a quantiﬁer free theory TΩ.4 The basic axioms of COω
Ω+ (µ) and SOω
Ω
+ (µ) are the same, consisting of the following:
4In Avigad and Feferman (1998), p. 387, we wrote ORω
1 for the system COω
Ω+ (QF-AC).

On the Strength of some Semi-Constructive Theories
211
(1) The axioms of HAω + (µ), with the induction scheme extended to all formulas
of the language;
(2) Sup(f) , 0Ωand Sup−1(Sup(f)) = f, for f of type N →Ω
(3) Sup(Sup−1(α)) = α for α , 0Ω
(4) (0Ω)x = 0Ω
(5) the (RΩ) equations
(6) φ(0Ω) ∧∀α[α , 0Ω∧∀xφ(αx) →φ(α)] →∀αφ(α) for each formula φ(α)
The theory TΩ+ (µ) has as axioms:
(1)∗The axioms of T + (µ)
(2)∗-(5)∗The same as (2)-(5)
(6)∗The rule of induction on ordinals for QF formulas φ
Note that this last is to be expressed in quantiﬁer free form using the µ operator.
In the next statement, ID1 and ID(i)
1 are respectively the classical and intuitionistic
theory of non-iterated positive inductive deﬁnitions given by arithmetical φ(x, P+).
Theorem 5. The following theories are all of the same proof-theoretical strength:
(i) ID1
(ii) COω
Ω+ (µ) + (QF-AC)
(iii) SOω
Ω+ (µ) + (AC) + (NOS)
(iv) TΩ+ (µ)
(v) ID(i)
1
Proof. It is shown in Avigad and Feferman (1998) pp. 388-389 how to translate
ID1 into COω
Ω+ (µ). That system is then carried into SOω
Ω+ (µ) by the N-translation.
By a direct extension of the work described in secs. 2-4 above, we see that SOω
Ω
+ (µ) + (AC) + (NOS) is D-interpreted in TΩ+ (µ); this also veriﬁes the classical
(QF-AC) under the ND-interpretation. Next, as in op. cit. pp. 390-391, TΩ+ (µ)
has a model in HRO(2E), the indices of operations hereditarily recursive in 2E in
the sense of Kleene (1959), interpreting the type Ωobjects as the members of a
version O of the Church-Kleene ordinal notations. That model can be formalized

212
Solomon Feferman
in ID1 so as to reduce TΩ+ (µ) to ID1. Finally, the reduction of ID1 to ID(i)
1 is due
to Buchholz (1980), in fact to the theory of an accessibility inductive deﬁnition.5
The language of the theory W of Coquand and Palmgren (2000) is close to that
of SOω
Ω, but does not contain the Sup−1 operator or the (µ) operator. Its axioms are
essentially the same as those of SOω
Ωwithout the axioms for those two operators. In
addition, it has three special choice axiom schemata, unique choice (AC!), count-
able choice (AC0) and dependent choice (DC) — all of which follow from (AC) —
as well as the Numerical Omniscience Scheme (NOS). Thus W is a subtheory of
SOω
Ω+ (AC) + (NOS), and so the proof-theoretic strength of W is no greater than
that of ID(i)
1 . Presumably, the latter (at least for accessibility inductive deﬁnitions)
can be interpreted in W, but I have not checked that. The main part of Coquand
and Palmgren (2000) is devoted to producing a constructive sheaf-theoretic model
of W in Martin-L¨of type theory with generalized inductive deﬁnitions; an obvious
question is whether their argument provides an alternative reduction of W to ID(i)
1 .
Finally, as noted in Theorem 2, NOS already follows in their system from LPO
from countable choice.
6
Semi-constructive systems of set theory.
The basic idea for semi-constructive systems of set theory was stated in the intro-
duction: each set is considered to be a deﬁnite totality, so that the membership
relation and bounded quantiﬁcation are deﬁnite, i.e. classical logic apply to both,
while the universe as a whole is considered to be indeﬁnite, so that only intuitionis-
tic logic applies to that. This suggests considering axiomatic systems of set theory
based on intuitionistic logic for which it is assumed that classical logic applies to
all ∆0 formulas. The latter is accomplished by assuming the following restricted
scheme for the Law of Excluded Middle,
(∆0-LEM)
φ ∨¬φ, for all ∆0 formulas φ
In this context, we also take Markov’s principle in the form:
(MP)
¬¬∃xφ →∃xφ, for all ∆0 formulas φ
Let IKPω be the system KP with logic restricted to be intuitionistic. To be more
precise, IKPω takes the following as its non-logical axioms:
1. Extensionality
5Avigad and Towsner (2009) have obtained an interesting alternative proof of the reduction of ID1
to an accessibility ID(i)
1 , using a variant of the functional interpretation method.

On the Strength of some Semi-Constructive Theories
213
2. Unordered pair
3. Union
4. Inﬁnity, in the speciﬁc form that there is a smallest set containing the empty
set 0 and closed under the successor operation, x′ = x ∪{x}.
5. ∆0-Separation
6. ∆0-Collection
7. The ∈-Induction Rule
By 7, we mean the rule which allows us to infer ∀xψ(x) from
∀x[(∀y ∈x)ψ(y) →ψ(x)]
for any formula ψ(x). This is easily seen to imply the ∈-Induction Scheme
∀x[(∀y ∈x)φ(y) →φ(x)] →∀xφ(x)
by taking ψ(x) = {∀z[(∀y ∈z)φ(y) →φ(z)] →φ(x)}.
Some further schemata in the language of set theory shall be added to IKPω,
ﬁrst of all the Bounded Omniscience Scheme:
(BOS)
∀x ∈a[φ(x) ∨¬φ(x)] →∀x ∈a(φ(x)) ∨∃x ∈a(¬φ(x))
for all formulas φ(x). The set-theoretical form of NOS is the special case of this
in which a = ω, the unique set speciﬁed by Axiom 4. We shall strengthen IKPω
by (∆0-LEM) and BOS; but we can make a further considerable strengthening by
adding the following form of the Axiom of Choice,
(ACSet)
∀x ∈a∃yφ(x, y) →∃r[Fun(r) ∧Dom(r) = a ∧(∀x ∈a)φ(x, r(x))]
for all φ, where Fun(r) expresses in usual set theoretic form that the binary relation
r is a function, and Dom(r) = a expresses that a is the domain of r; both of these
may be given as ∆0 formulas. Note that in the presence of (ACSet) with axioms 1-3
and 5 we can infer Full Collection and Full Replacement i.e. these schemes for
arbitrary formulas.
Theorem 6. The semi-constructive theory of sets, SCS = IKPω + (∆0-LEM) +
(MP) + (BOS) + (ACSet), is of the same strength as KPω and thence of ID(i)
1 . The
same holds for a natural ﬁnite type extension SCSω over the universe of sets.

214
Solomon Feferman
Proof. The proof is in three parts.
I. First, we show that KPω is interpretable in SCS via the N-translation. Since
φN is provably equivalent to φ for every ∆0 formula f in IKPω + (∆0-LEM), one
readily checks that the N-translation of each of the axioms 1-5 holds in that sub-
system of SCS. In the case of ∆0-Collection, the N-translation is of the form
(∀x ∈a)¬¬∃yφ(x, y) →¬¬∃b(∀x ∈a)(∃y ∈b)φ(x, y)
where φ is a ∆0 formula. But then by (MP) this follows from ∆0-Collection in
SCS. Finally, the N-translation of an instance of the ∈-induction rule is an instance
of the same.
II. Next we introduce a new system TV and deﬁne a D-interpretation of SCS
into TV; by following through the interpretation, one may see what natural ﬁnite
type extension SCSω of SCS is also veriﬁed in the process. The language of TV
is typed, with a ground type V for sets, and function types σ →τ for each types
σ and τ. Variables for sets will be at the beginning or end of the alphabet, while
variables for functions will generally be f, g, h, . . .. Capital letters will be used for
constants, except for 0 and ω; the constants are 0 (empty set), ω (natural num-
bers), D (disjunction operator), N (negation operator), E (characteristic function of
equality), M (characteristic function of membership), C (bounded choice operator),
P (unordered pair function), U (union function), S (separation operator), R∗(range
operator) and Rσ (recursion operators). Terms are generated from variables and
constants by closure under well-typed application, ts. Atomic formulas are equa-
tions between terms, s = t, and membership of terms, s ∈t. Formulas φ, ψ, . . . are
generated by closing the atomic formulas under the propositional operations and
bounded quantiﬁcation, (∀y ∈t)φ and (∃y ∈t)φ. Truth values are represented in V
by using 0 for True and any other value for False. The axioms of TV fall into three
groups (A, B and C), as follows; these also implicitly determine the types of the
various constants.
A. Equality and logical operation axioms.
1. (Decidability) x = y ∨x , y
2. (Equality) Exy = 0 ↔x = y
3. (Membership) Mxy = 0 ↔x ∈y
4. (Disjunction) Dxy = 0 ↔x = 0 ∨y = 0
5. (Negation) Nx = 0 ↔x , 0
6. (Bounded choice) x ∈a ∧f x = 0 →Caf ∈a ∧f(Caf) = 0
Note by 6 that (∃x ∈a)f x = 0 ↔Caf ∈a∧f(Caf) = 0. The following is then
a direct consequence of the group A axioms.

On the Strength of some Semi-Constructive Theories
215
Lemma 7. For each ∆0 formula φ of set theory, all of whose free variables are
among the list x = x1, . . . xn, we have a closed term tφ such that the following is
provable in TV:
tφ(x) = 0 ↔φ(x)
For the next group of axioms we write a ⊆b for (∀x ∈a)(x ∈b).
B. Set theoretic axioms.
7. (Extensionality) a ⊆b ∧b ⊆a →a = b
8. (Empty set) ¬(x ∈0)
9. (Unordered pair) x ∈Pab ↔x = a ∨x = b
10. (Union) x ∈Ua ↔(∃y ∈a)(x ∈y)
11. (Inﬁnity) (i) 0 ∈ω ∧(∀x ∈ω)(x′ ∈ω)
(ii) 0 ∈a ∧(∀x ∈a)(x′ ∈a) →ω ⊆a
12. (Separation) x ∈S af ↔x ∈a ∧f x = 0
13. (Range) y ∈R∗af ↔(∃x ∈a)(f x = y)
As usual, for Axiom 11 in the preceding, we write {x, y} for Pxy, {x} = {x, x},
x ∪y = U{x, y}, and x′ = x ∪{x}. We also deﬁne ⟨x, y⟩= {{x}, {x, y}} as usual in set
theory, and use it to prove the following:
Lemma 8. There is a closed term Grph such that TV proves
z ∈(Grph)af ↔(∃x ∈a)(∃y ∈R∗af)[z = ⟨x, y⟩∧f x = y]
Proof. (Grph)a f is the graph of f restricted to a, considered as a set; it is
formed by separation from the Cartesian product a × (R∗af). This depends on the
proof in general of the existence of Cartesian products a × b, as follows. First let
g be such that for each x, y, gxy = ⟨x, y⟩, so that gx is λy.⟨x, y⟩. Then for x ∈a,
gx : b →{x} × b and R∗(b, gx) = {x} × b. Finally, take h = λx.R∗(b, gx) so that
a × b = U(R∗(a, h)). □
In the following I shall write f|a for (Grph)af.
The ﬁnal group of axioms is for recursion and induction. The latter is formu-
lated as a rule in a way speciﬁcally to enable the D-interpretation of the ∈-Induction
scheme in KPω.
C. Recursion Axiom and Induction Rule.

216
Solomon Feferman
14. (Recursion) For each type σ, Rσ is of type (V →V →σ) →(V →σ).
Then for f a variable of type (V →V →σ) and x of type V and for
g = Rσ f we have the equation
gx = f(g|x)x
15. (Induction) Suppose that θ(x, g, u) is a formula and that G and Z are
closed terms for which the following has been inferred:
(∀y ∈x)θ(y,Gy, Zxu) →θ(x,Gx, u)
Then we may infer θ(x,Gx, u).
NB. In the preceding, g and u may be sequences of variables (possibly
empty) of arbitrary type, while x is of type V.
This completes our description of the system TV.
Lemma 9. SCS is D-interpreted in TV.
Proof. The D-interpretation of each of the axioms 1-6 of IKPω in TV is straight-
forward. Furthermore, by the general facts about the D-interpretation established in
section 2 above, we obtain without further work the D-interpretations of (∆0-LEM),
(MP), and (AC), this last in the functional form ∀x∃yφ(x, y) →∃f∀xφ(x, f x),
where φ is an arbitrary formula. To obtain the D-interpretation of (ACSet) from
this, suppose (∀x ∈a)∃yφ(x, y). Then under the D-interpretation, we also have
∀x∃y(x ∈a →φ(x, y)), so there exists an f such that (∀x ∈a)φ(x, f x). Let r = f|a;
then by Lemma 2, Fun(r) and Dom(r) = a and (∀x ∈a)φ(x, r(x)), as required by
(ACSet). To prove the D-interpretation of BOS, we argue just as for Theorem 2
in the proof of NOS, but now combining AC with the bounded choice operator C
instead of the operator µ.
So the only thing left to deal with is the D-interpretation of the ∈-Induction
Rule 7 of IKPω. For that, let ψ(x)D = ∃g∀uψD(x, g, u), where g, u are sequences
of variables (possibly empty) of various types. We write θ for ψD. Then to form
the D-interpretion of the hypothesis of the ∈-Induction Rule, we pass through the
following sequence of formulas
∀x{(∀y ∈x)∃h∀wθ(y, h, w) →∃f∀uθ(x, f, u)},
∀x{∃g∀w∀y[y ∈x →θ(y, gy, w)] →∃f∀uθ(x, f, u)},
∀g, x∃f∀u∃w, y{[y ∈x →θ(y, gy, w)] →θ(x, f, u)},
∃f ′, y′, w′∀g, x, u{[y′gxu ∈x →θ(y′gxu, g(y′gxu), w′gxu)] →θ(x, f ′gx, u)}.

On the Strength of some Semi-Constructive Theories
217
So ﬁnally, by induction hypothesis we have closed terms F, Y, W, such that the
following is provable in TV:
[Ygxu ∈x →θ(Ygxu, g(Ygxu), Wgxu)] →θ(x, Fgx, u).
Then the following is also provable in TV:
(∀y ∈x)θ(y, gy, Wgxu) →θ(x, Fgx, u).
Now apply the Recursion Axiom of TV to obtain G satisfying the equation
Gx = F(G|x)x.
Substituting G|x for g throughout the preceding, and taking
Zxu = W(G|x)u, it follows that (∀y ∈x)θ(y,Gy, Zxu) has been inferred. Hence by
the Induction Rule 15 of TV we may infer θ(x,Gx, u), which is the D-interpretation
of ∀xψ(x).
III. To complete the proof of Theorem 5, we need to interpret TV in a system of
strength KPω. This is provided by the system of Operational Set Theory, OST, for
a type-free applicative structure over set theory introduced in Feferman (2001a);
see also Feferman (2009) and J¨ager (2007). The language of OST extends the
language L of set theory by a binary operation symbol A for application, a unary
relation symbol ↓for deﬁnedness and various constants. The terms r, s, t, . . . of
the extended language are generated from the variables a, b, c, . . . , f, g, h, . . . , x, y, z
and constants by closing under application, A(s, t). We write st for A(s, t), and think
of s as a partial function (coded as a set) whose value at t exists if (st)↓holds; this
allows interpretation of a partial combinatory type-free calculus in OST. The logic
of OST is the classical logic of partial terms due to Beeson.6 The axioms of OST
come in four groups:
(1) Axioms for the applicative structure given by the (partial) combinators k, s.
(2) Axioms for logical operations for negation, disjunction and bounded quan-
tiﬁcation, along with the characteristic function for membership, as in TV.
(3) Basic set-theoretic axioms for extensionality, empty set, unordered pair,
union, inﬁnity and the ∈-Induction Scheme, as in KPω.
(4) Operational set-theoretic axioms for Separation, Range (or Replacement) as
in TV; in addition there is a Universal Choice operator C satisfying ∃x(f x =
0) →(C f)↓∧f(C f) = 0.
For each type symbol σ of TV, we deﬁne Mσ(x) inductively as follows to ex-
press in the language of OST that x is an object of type σ:
6See Troelstra and van Dalen (1988) pp. 50-51, where Et is written for t↓and the logic of partial
terms is called E-logic.

218
Solomon Feferman
(i) MV(x) is (x = x)
(ii) Mσ→τ(x) is ∀y[Mσ(y) →xy↓∧Mτ(xy)]
We may treat the predicates Mσ as classes and write f : Mσ →Mτ for
Mσ→τ(f). The translation of the constants of TV into those of OST except for
the recursors is immediate; for each of these we may check that if the constant is
of type σ then its translation is a closed term of OST that is provably in Mσ.
So now consider any recursor Rσ; this is of type (V →V →σ) →(V →σ).
As its interpretation we make use of the type-free form of the recursion theorem
that is a consequence of the applicative axioms of OST; this provides a closed term
rec such that for any f, rec f↓and for g = rec f and any x, we have gx ≃fgx, i.e.
either both sides are deﬁned and equal or both are undeﬁned. We also make use of
Lemma 5 of Feferman (2009), according to which there is a closed term fun such
that for any f, x such that (∀y ∈x)fy↓we have funf x↓, and funf x is the graph
of f restricted to x considered as a set; in other words fun may be taken as the
interpretation of Grph and we also write f|x for funf x. Finally, using the recursor
rec, we obtain a closed term r such that rf↓for all f, and for g = rf, the following
is provable:
gx ≃f(g|x)x
We claim each Rσ can be translated by this same term r. That is, no matter what
σ we take, we have
r : (V →V →Mσ) →(V →Mσ)
For, suppose given any f : (V →V →Mσ); and let g = rf. It is to be shown
that g : (V →Mσ), i.e. that for each x, gx↓and gx is in Mσ. This is proved
by ∈-induction on x; if it holds for all y ∈x, then fungx↓, i.e. g|x is in V, so by
assumption, f(g|x)x is in Mσ, and hence the same holds for gx. QED
Lemma 10. Under this translation, TV is interpreted in OST.
Proof. The veriﬁcation of all the axioms of TV by the corresponding axioms of
OST up to those for Recursion and Induction are immediate. The Recursion axiom
is taken care of in the way just described, so it is only left to check the Induction
Rule. So suppose that θ(x, v, u) is a formula which is a translation of a formula
of TV for which v is a sequence of variables of type σ = σ1, . . . , σn and u is a
sequence of variables of type τ = τ1, . . . , τm; we write Mσ(v) for the conjunction
of statements Mσi(vi) and similarly for Mτ(u). Suppose further that G and Z are
closed terms of OST for which the following has been inferred:
∀x∀u{Mσ(Gx) ∧[Mτ(u) →Mτ(Zxu)] ∧[(∀y ∈x)θ(y,Gy, Zxu) →θ(x,Gx, u)]}

On the Strength of some Semi-Constructive Theories
219
Then we conclude
∀x{(∀y ∈x)∀u[Mτ(u) →θ(y,Gy, u)] →∀u[Mτ(u) →θ(x,Gx, u)}
Thus by the Induction Scheme in OST we conclude ∀x∀u[Mτ(u)
→
θ(x,Gx, u)], which veriﬁes the translation of the conclusion of the Induction Rule
in TV. □
We may now complete the proof of Theorem 5 by means of the fact established
in Feferman (2009) (and in another way in J¨ager (2007)) that OST is of the same
proof-theoretical strength as KPω. Finally, the fact that KPω is of the same proof-
theoretical strength of ID1 is due to J¨ager (1982); it is then of the same strength as
ID(i)
1 by Buchholz (1980). □
If the power set operation is considered as a deﬁnite operation, which is sug-
gested by one philosophical view of set theory which still regards the universe of
all sets as an indeﬁnite totality, we are led to a semi-constructive system for which
we can prove the following theorem in the same way as was done for Theorem 5.
Theorem 11. The system IKPω + (Pow) + (∆0-LEM) + (MP) + (BOS) + (AC) has
proof-theoretical strength between the classical systems KPω + (Pow) and KPω +
(Pow) + (V=L).
This makes use of the result proved in J¨ager (2007) that the proof-theoretical
strength of OST + (Pow) is bounded by that of KPω + (Pow) + (V=L). It is con-
jectured but it is not known whether the strength of the latter is the same as that
of KPω + (Pow); the standard argument to eliminate the Axiom of Constructibility
does not apply in any obvious way.
7
A miscellany of related work and questions
7.1
Kohlenbach’s “Lesser” NOS
Kohlenbach (2001) considers the following weakening of NOS that he calls the
Lesser Numerical Omniscience Scheme:
(LNOS)
∀n[(φ(n) ∨¬φ(n)) ∧(ψ(n) ∨¬ψ(n))] ∧¬∃nφ(n) ∧¬∃nψ(n)
→∀n¬φ(n) ∨∀n¬ψ(n)
His main result is that the semi-constructive system Res-HAω + (AC) + (MP)
+ (LNOS) is conservative over PRA for Π0
2 sentences. The proof is by means of
functional interpretation combined with the method of majorization. Kohlenbach
also shows that the system in question proves WKL, i.e. K¨onig’s Lemma for binary

220
Solomon Feferman
trees (“weak K¨onig’s Lemma”). Ferreira and Oliva (2005) have introduced another
method, called bounded functional interpretation, which they show may be used
to obtain the same results in a simpler way. It would be interesting to see if their
majorization and/or bounding techniques can be used to amplify the results of the
present paper.
Kohlenbach (2008), p. 154, has also observed that WKL implies KL over Res-
HAω + AC0,0, so in such contexts, the diﬀerence between “weak” and “usual”
K¨onig’s Lemma disappears; this is in accord with the advantage of beeﬁng up con-
structive and semi-constructive systems stressed here.
Since PRA is considered by many to be the limit of ﬁnitism, it would also be
interesting to produce a natural semi-constructive system of ﬁnite type over the
natural numbers for which all bounded formulas are decidable and whose proof-
theoretical strength is equal to that of PRA. Finally, one may speculate that there
are suitable such systems equivalent in strength to feasible arithmetic.
7.2
Friedman’s system ALPO
Friedman (1980) introduced a semi-constructive system ALPO (for “Analysis with
the Limited Principle of Omniscience”) in the language of set theory with the nat-
ural numbers as a set of urelements, for which the main result is conservation of
ALPO over PA for all arithmetic sentences.7 For comparison with the system SCS
= IKPω + (∆0-LEM) + (MP) + (BOS) + (AC) of Theorem 5 above, here are the ax-
ioms of ALPO: A. Ontological (urelements and sets), B. Urelement extensionality,
C. Successor axioms, D. Inﬁnity, E. Sequential induction, F. Sequential recursion,
G. Pairing (unordered), H. Union, I. Exponentiation, J. Countable choice, K. ∆0-
separation, L. Strong collection, M. Limited principle of omniscience. By E is
meant that any sequence (i.e. function) a of natural numbers which is such that
a(0) = 0 ∧∀n(a(n) = 0 →a(n′) = 0) then ∀n(a(n) = 0). Axiom E guarantees def-
inition by primitive recursion. The axiom J is of course a consequence of ACSet in
our system, as is the strong collection axiom L (i.e. collection applied to arbitrary
formulas). Other than Axiom I, all of these are thus derivable in SCS. That axiom
asserts the existence for any sets a, b, of the set of all functions from a to b, which
is not a consequence of SCS or even of its ﬁnite type extension SCSω (at least not
in any obvious way). In his paper, Friedman makes use of a special model-theoretic
argument in order to eliminate Axiom I before completing the proof that ALPO is
conservative over PA. It would be of great interest to see whether the methods of
functional interpretation employed here can be adapted to prove the same. Note
that Axiom I does follow from the power set axiom used in the extension of SCS
7I was reminded of Friedman’s work by Jeremy Avigad.

On the Strength of some Semi-Constructive Theories
221
for Theorem 6.
7.3
Burr’s interpretation of KPω
A useful variant functional interpretation due to Shoenﬁeld (1967) sec. 8.3 in ∀∃
form that is sometimes used applies directly to a classical system without requiring
initial passage through the N-translation. The straightforward attempt to give such
an interpretation of KPω meets an immediate obstacle if the constant 0 is to be part
of the language; namely, it follows from provability of ∀x∃y(x , 0 →y ∈x) that
one must have a term t(x) such that x , 0 →t(x) ∈x is provable in the target
QF system. In other words one must have a non-constructive (“choice”) operator
for bounded quantiﬁcation (of the sort provided in the system TV by the bounded
choice operator C). In order to avoid this, Burr (1998, 2000) gives a further Diller-
Nahm (1974) ∀∃-variant interpretation of KPω in a QF theory of primitive recursive
set functionals of ﬁnite type. It is quite diﬀerent from the interpretation given here
in sec. 6, but there may be interesting relationships that are worth pursuing.
7.4
Some systems of semi-intuitionistic set theory with the power
set axiom
The study of such subsystems of ZF formulated in intuitionistic logic with LEM
for bounded formulas was apparently initiated by Poszgay (1971, 1972) and then
studied more systematically by Tharp (1971), Friedman (1973) and Wolf (1974).8
Poszgay had conjectured that his system is as strong as ZF, but Tharp and Friedman
proved its consistency in ZF using a modiﬁcation of Kleene’s method of realizabil-
ity. Wolf established the equivalence in strength of several related systems. The
ﬁrst is K1, a system with axioms of Extensionality, Pairing, Union, Inﬁnity and
Power Set, the full Induction Scheme, and with Replacement restricted to formulas
in which all quantiﬁers are bounded or subset bounded. K2 is K1 + LEM, and K3 is
K1 plus a certain strong axiom scheme of Transﬁnite Recursive Deﬁnitions which
implies the Full Replacement and Collection axiom schemes; ﬁnally K∗
3 is K3 +
MP. (In this notation, what Tharp and Friedman proved is consistency in ZF of an
extension of K1 plus Full Replacement and the usual Axiom of Choice.) Wolf’s
main results include equiconsistency of K1, K2 + V=L, and K∗
3. The system K∗
3 is
close in many respects to the system IKPω + (Pow) + (∆0-LEM) + (MP) + (BOS)
+ (ACSet) dealt with here in Theorem 6, except for BOS and ACSet (Full Axiom
of Choice scheme), and which also implies Full Replacement and Collection. It
8I am indebted to Harvey Friedman and Robert Wolf for bringing this work to my attention, after the
body of this paper was completed.

222
Solomon Feferman
should be of interest to make a detailed comparison between these systems and of
the methods involved.
7.5
Mathematics in semi-constructive systems
Coquand and Palmgren (2000) give a couple of examples of mathematical theorems
in their semi-constructive system for countable tree ordinals (described in sec. 5
above) that can be provided with a constructive foundation via their constructive
sheaf-theoretic model of the system. The ﬁrst is K¨onig’s Lemma for binary trees;
but in fact, as shown by Kohlenbach in the work described in 7.1 above, a much,
much weaker system (conservative over PRA) suﬃces to do the same. The second
is Dickson’s Lemma, according to which if u : N →N and v : N →N are
two sequences of natural numbers then there exist p < q such that u(p) ≤u(q)
and v(p) ≤v(q). That follows from a prior lemma, that for any sequence u :
N →N of natural numbers, there exists a sequence n0 < n1 < n2 < . . . such that
u(n0) ≤u(n1) ≤u(n2) ≤. . .. To obtain Dickson’s Lemma from this, one ﬁrst ﬁnds a
strictly increasing sequence of natural numbers on which u is increasing, and then
a strictly increasing subsequence of that on which v is increasing, to get a sequence
n0 < n1 < n2 < . . . on which both u and v are increasing. We may then take p = n0
and q = n1. Again, what is needed can be proved in a much, much weaker system,
namely that of Theorem 3(i) conservative over PA. The truth of Dickson’s Lemma
implies that we can obtain p, q as recursive functionals of u and v; simply search for
the ﬁrst p, q which make it true. The constructive model of Coquand and Palmgren
can hardly be expected to provide more useful information about the complexity of
that functional.
More generally, all of the semi-constructive systems treated in Theorem 3 are
candidates of potential interest in which to carry out predicative mathematics. The
actual pursuit of that part of mathematics in various classical systems of explicit
mathematics, as described, e.g., in (Feferman 1975 and Feferman and J¨ager 1993,
1996) as well as in theories of ﬁnite type over the natural numbers (Feferman 1977,
1979) make systematic use of explicit witnessing data. For example, a uniformly
continuous function on a closed interval of real numbers is treated as a pair con-
sisting of a function of real numbers on that interval and a uniform modulus of
continuity functions. As pointed out by Friedman at the outset of his (1980) arti-
cle, such padding is unnecessary in semi-constructive systems in which the Axiom
of Choice holds in suﬃciently strong form, as it does in ALPO and in the various
systems considered here. How far this freedom takes us is another matter, but the
actual development of predicative mathematics in these systems should certainly
be revisited in that light. In addition, one should see how much mathematics can
be conveniently carried out in the impredicative semi-constructive systems of secs.

On the Strength of some Semi-Constructive Theories
223
5 and 6. Finally, it would be worth pursuing the formulation and determination of
the proof-theoretical strength of semi-constructive systems of explicit mathematics
and operational set theory, neither of which has been directly handled here, and in
both of which mathematics can in general be carried out in a more ﬂexible manner
than in typed systems or even in set theoretical systems.
Acknowledgements: I wish to thank the two referees for their useful comments
on a draft of this paper, and Shivaram Lingamneni for his help in transforming it
into a LATEX ﬁle.
References
J. Avigad and S. Feferman (1998), G¨odel’s functional (“Dialectica”) Interpreta-
tion, in (S. Buss, ed.) Handbook of Proof Theory, Elsevier, Amsterdam,
337-405.
J. Avigad and H. Towsner (2009), Functional interpretation and inductive deﬁni-
tions, J. Symbolic Logic (to appear).
E. Bishop (1967), Foundations of Constructive Analysis, McGraw Hill, New
York.
W. Buchholz (1980), The Ωµ+1-rule, in (W. Buchholz, et al., eds.) Iterated induc-
tive deﬁnitions and subsystems of analysis. Recent proof theoretical studies,
Lecture Notes in Mathematics 897, 188-233.
W. Burr (1998), Functionals in Set Theory and Arithmetic, Doctoral Dissertation,
M¨unster.
W. Burr (2000), A Diller-Nahm-style functional interpretation of KPω, Archive
for Mathematical Logic 39, 599-604.
T. Coquand and E. Palmgren (2000), Intuitionistic choice and classical logic,
Archive for Mathematical Logic 39, 53-74.
J. Diller and W. Nahm (1974), Eine Variante zur Dialectica Interpretation der
Heyting Arithmetik endlicher Typen, Arch. Math. Logik u. Grundlagen-
forschung 16, 49-66.
S. Feferman (1968), Ordinals associated with theories for one inductively deﬁned
set. (Unpublished notes.)
S. Feferman (1971), Ordinals and functionals in proof theory, in Proc. Int’l Cong.
Mathematicians, Nice 1970, vol. 1, Gauthier-Villars, Paris, 229-233.

224
Solomon Feferman
S. Feferman (1975), A language and axioms for explicit mathematics, in (J. N.
Crossley, ed.), Algebra and Logic, Lecture Notes in Mathematics 450, 87-
139.
S. Feferman (1977), Theories of ﬁnite type related to mathematical practice, in
(J. Barwise, ed.) Handbook of Mathematical Logic, North-Holland, Amster-
dam, 913-971.
S. Feferman (1979), A more perspicuous system for predicativity, in (K. Lorenz,
et al. eds.) Konstruktionen vs. Positionen I, de Gruyter, Berlin , 87-139.
S. Feferman (2001), On the strength of some systems with the numerical omni-
science scheme, (abstract) Bull. Symbolic Logic 7, 111.
S. Feferman (2001a), Notes on operational set theory, I. Generalization of small
large cardinals in classical and admissible set theory.
http://math.
stanford.edu/˜feferman/papers/OperationalST-I.pdf.
S. Feferman (2009), Operational set theory and small large cardinals, Proceedings
of WoLLIC ’06, Information and Computation 207, 971-979; see http://
dx.doi.org/10.1016/j.ic.2008.04.007.
S. Feferman and G. J¨ager (1993), Systems of explicit mathematics with non-
constructive µ-operator, I, Annals of Pure and Applied Logic 65, 243-263.
S. Feferman and G. J¨ager (1996), Systems of explicit mathematics with non-
constructive µ-operator, II, Annals of Pure and Applied Logic 79, 37-52.
F. Ferreira and P. Oliva (2005), Bounded functional interpretation, Annals of Pure
and Applied Logic 135, 73-112.
H. Friedman (1973), Some applications of Kleene’s methods for intuitionistic sys-
tems, Lecture Notes in Mathematics 337.
H. Friedman (1980), A strong conservative extension of Peano Arithmetic, in (J.
Barwise, et al., eds.) The Kleene Symposium, North-Holland, Amsterdam,
113-122.
G. J¨ager (1982), Zur Beweistheorie der Kripke-Platek-Mengenlehre ¨uber den
nat¨urlichen Zahlen, Archiv f. Math. Logik u. Grundlagenforschung 22.
G. J¨ager (2007), On Feferman’s operational set theory OST, Annals of Pure and
Applied Logic 150, 19-39.

On the Strength of some Semi-Constructive Theories
225
U. Kohlenbach (2001), Intuitionistic choice and restricted classical logic, Mathe-
matical Logic Quarterly 47, 455-460.
U. Kohlenbach (2008), Applied Proof Theory. Proof interpretations and their use
in mathematics, Springer-Verlag, Berlin.
L. Pozsgay (1971), Liberal intuitionism as a basis for set theory, in Axiomatic Set
Theory, Proc. Symp. Pure Math. XIII, Part 1, 1971, 321-330.
L. Pozsgay (1972) Semi-intuitionistic set theory, Notre Dame J. of Formal Logic
13, 546-550.
J. R. Shoenﬁeld (1967), Mathematical Logic, Addison-Wesley, Reading, MA.
L. H. Tharp (1971), A quasi-intuitionistic set theory, J. Symbolic Logic 36, 456-
460.
A. S. Troelstra and D. van Dalen (1988), Constructivism in Mathematics. An
introduction,vol. 1, North-Holland, Amsterdam.
R. S. Wolf (1974), Formally Intuitionistic Set Theories with Bounded Predicates
Decidable, PhD Thesis, Stanford University.

226

On the Relation Between Various Negative
Translations
Gilda Ferreira∗and Paulo Oliva†
Several proof translations of classical mathematics into intuitionistic (or even
minimal) mathematics have been proposed in the literature over the past
century. These are normally referred to as negative translations or double-
negation translations. Amongst those, the most commonly cited are transla-
tions due to Kolmogorov, G¨odel, Gentzen, Kuroda and Krivine (in chronolog-
ical order). In this paper we propose a framework for explaining how these
diﬀerent translations are related to each other. More precisely, we deﬁne a no-
tion of a (modular) simpliﬁcation starting from Kolmogorov translation, which
leads to a partial order between diﬀerent negative translations. In this derived
ordering, Kuroda, Krivine and G¨odel-Gentzen are minimal elements. A new
minimal translation is introduced.
1
Introduction
Several proof translations of classical mathematics into intuitionistic (or even mini-
mal) mathematics have been proposed in the literature over the past century. These
are normally referred to as negative translations or double-negation translations.
The ﬁrst such translation is due to Kolmogorov [21] in 1925. He observed that
placing a double negation ¬¬ in front of every subformula turns a classically valid
formula into an intuitionistically valid one. Formally, deﬁning
(A ∧B)Ko
:≡
¬¬(AKo ∧BKo)
PKo
:≡
¬¬P,
for P atomic
(A ∨B)Ko
:≡
¬¬(AKo ∨BKo)
(∀xA)Ko
:≡
¬¬∀xAKo
(A →B)Ko
:≡
¬¬(AKo →BKo)
(∃xA)Ko
:≡
¬¬∃xAKo,
∗The
ﬁrst
author
thanks
Fundac¸˜ao
para
a
Ciˆencia
e
a
Tecnologia
-
FCT
(grant
SFRH/BPD/34527/2006 and project PTDC/MAT/104716/2008), Centro de Matem´atica e Aplicac¸˜oes
Fundamentais CMAF-Universidade de Lisboa e N´ucleo de Investigac¸˜ao em Matem´atica NIM-
Universidade Lus´ofona.
†The
second
author
gratefully
acknowledges
support
of
the
Royal
Society
(grant
516002.K501/RH/kk).
We would like to thank Ulrich Kohlenbach for suggesting the ﬁner mea-
sure of counting implications instead of just negations.

228
Gilda Ferreira and Paulo Oliva
one can show that A is provable classically if and only if AKo is provable intuition-
istically. Kolmogorov’s translation, however, was apparently not known to G¨odel
and Gentzen who both came up with similar translations [9, 10, 12] a few years
later. Gentzen’s translation (nowadays known as G¨odel-Gentzen negative trans-
lation [4, 18, 29]) simply places a double negation in front of atomic formulas,
disjunctions, and existential quantiﬁers, i.e.
(A ∧B)GG
:≡
AGG ∧BGG
PGG
:≡
¬¬P,
for P atomic
(A ∨B)GG
:≡
¬¬(AGG ∨BGG)
(∀xA)GG
:≡
∀xAGG
(A →B)GG
:≡
AGG →BGG
(∃xA)GG
:≡
¬¬∃xAGG.
As with Kolmogorov’s translation, we also have that CL ⊢A if and only if
IL ⊢AGG, where CL and IL stand for classical and intuitionistic logic, respectively.
G¨odel’s suggested translation was in fact somewhere in between Kolmogorov’s and
Gentzen’s, as it also placed a double negation in front of the clause for implication,
i.e.
(A →B)GG :≡¬(AGG ∧¬BGG) ⇔IL ¬¬(AGG →BGG).
In the 1950’s, Kuroda revisited the issue of negative translations [23], and proposed
a diﬀerent (somewhat simpler) translation:
(A ∧B)Ku
:≡
AKu ∧BKu
PKu
:≡
P,
for P atomic
(A ∨B)Ku
:≡
AKu ∨BKu
(∀xA)Ku
:≡
∀x¬¬AKu
(A →B)Ku
:≡
AKu →BKu
(∃xA)Ku
:≡
∃xAKu.
Let AKu :≡¬¬AKu. Similarly to Kolmogorov, G¨odel and Gentzen, Kuroda showed
that CL ⊢A if and only if IL ⊢AKu. In particular, if A does not contain universal
quantiﬁers then CL ⊢A if and only if IL ⊢¬¬A, since (·)Ku is the identity mapping
on formulas not containing universal quantiﬁers. Finally, relatively recently, fol-
lowing the work of Krivine [22], yet another diﬀerent translation was developed1,
namely
(A ∧B)Kr
:≡
AKr ∨BKr
PKr
:≡
¬P,
for P atomic
(A ∨B)Kr
:≡
AKr ∧BKr
(∀xA)Kr
:≡
∃xAKr
(A →B)Kr
:≡
¬AKr ∧BKr
(∃xA)Kr
:≡
¬∃x¬AKr.
Letting AKr :≡¬AKr, we also have that CL ⊢A if and only if IL ⊢AKr. This negative
translation in fact already appears implicitly in Shoenﬁeld’s classical variant [30]
of G¨odel’s dialectica interpretation [13], as recently observed in [3, 31].
1Throughout the paper this translation is going to be called “Krivine negative translation” as cur-
rently done in the literature (see [20, 31]) even though it should be better called Streicher-Reus transla-
tion. Although inspired by the Krivine’s work in [22] it is the syntactical translation studied by Streicher
and Reus [32] in a version presented in [3, 31] we are using here.

On the Relation Between Various Negative Translations
229
More than translating CL into IL, it is well known that some negative transla-
tions produce embeddings of CL into minimal logic ML (i.e. intuitionistic logic
without ex-falso-quodlibet). More precisely
CL ⊢A
iﬀ
ML ⊢A∗,
where ∗∈{Ko,GG, Kr}, for instance. For Kuroda negative translation, however,
we only have CL ⊢A iﬀIL ⊢AKu (see [34]). Nevertheless, we observe that a
small change in Kuroda negative translation produces an embedding in ML. More
precisely, deﬁning
(A ∧B)mKu
:≡
AmKu ∧BmKu
PmKu
:≡
P,
for P atomic
(A ∨B)mKu
:≡
AmKu ∨BmKu
(∀xA)mKu
:≡
∀x¬¬AmKu
(A →B)mKu
:≡
¬AmKu ∨BmKu
(∃xA)mKu
:≡
∃xAmKu
and letting AmKu :≡¬¬AmKu we have CL ⊢A if and only if ML ⊢AmKu. We call the
translation (·)mKu, minimal Kuroda negative translation.
It is also known that all these translations into IL (or ML respectively) lead to
intuitionistically (or minimally) equivalent formulas, in the sense that, for instance,
AKo, AGG, AKu and AKr are all provably intuitionistically equivalent. As such, one
could say that they are all essentially the same. On the other hand, it is obvious
that they are intrinsically diﬀerent, some being much more expensive in terms of
negations than others. The goal of the present paper is to explain the precise sense
in which G¨odel-Gentzen, Kuroda (or minimal Kuroda) and Krivine translations
are systematic simpliﬁcations of Kolmogorov’s original translation, and show that,
in a precise sense, they are optimal (modular) translations of classical logic into
intuitionistic (or minimal) logic. A new optimal variant is discussed in Section 5
below.
Till Section 5 we develop our study in the more restricted framework of ML.
In Section 6, we show how our analysis can easily be adapted to the framework of
IL. Finally on Section 7, we discuss non-modular negative translations and some
future and related work.
For more comprehensive surveys on the diﬀerent negative translations, with
more historical background, see [19, 20, 24, 33, 34].
Note. This is an extended version of our Classical Logic and Computation (CL&C)
workshop 2010 paper, which appeared in [6]. The main diﬀerences to the work-
shop version are that here all proofs are included, and the analysis of the negative
translations is ﬁrst done over the weaker setting of minimal logic (rather than intu-
itionistic logic). Moreover, following a suggestion of Ulrich Kohlenbach, we judge
the optimality of the translations not just by the number of negations it introduces,

230
Gilda Ferreira and Paulo Oliva
but rather by the number of implications introduced (counting a negation as a par-
ticular form of implication).
1.1
Some useful results
Our considerations on the diﬀerent negative translations is based on the fact that
formulas with various implications (note that negations are a particular kind of
implications) can be simpliﬁed to equivalent formulas with fewer implications. The
cases when this is (or is not) possible are outlined in the following lemma.
Lemma 1. The following equivalences are provable in ML:
1.
¬¬(¬¬A ∧¬¬B) ↔¬¬(A ∧B)
9.
¬¬(¬¬A ∧¬¬B) ↔(¬¬A ∧¬¬B)
2.
¬¬(¬¬A ∨¬¬B) ↔¬¬(A ∨B)
10.
¬¬(¬¬A →¬¬B) ↔(¬¬A →¬¬B)
3.
¬¬(¬¬A →¬¬B) ↔¬¬(¬A ∨B)
11.
¬¬∀x¬¬A ↔∀x¬¬A
4.
¬¬∃x¬¬A ↔¬¬∃xA
5.
¬¬(¬A ∧¬B) ↔¬(A ∨B)
12.
¬(¬¬A ∧¬¬B) ↔(¬¬A →¬B)
6.
¬¬(¬A ∨¬B) ↔¬(A ∧B)
13.
¬(¬¬A ∨¬¬B) ↔(¬A ∧¬B)
7.
¬¬(¬A →¬B) ↔¬(¬A ∧B)
14.
¬(¬¬A →¬¬B) ↔(¬¬A ∧¬B)
8.
¬¬∀x¬A ↔¬∃xA
15.
¬∃x¬¬A ↔∀x¬A.
The following equivalences are provable in CL but not in IL (and hence not in ML):
16.
¬¬∀x¬¬A ↔¬¬∀xA
20.
¬¬∃x¬¬A ↔∃x¬¬A
17.
¬¬∃x¬A ↔¬∀xA
21.
¬∀x¬¬A ↔∃x¬A
18.
¬¬(¬¬A ∨¬¬B) ↔(¬¬A ∨¬¬B)
22.
¬(¬¬A ∧¬¬B) ↔(¬A ∨¬B)
19.
¬¬(¬¬A →¬¬B) ↔(¬¬¬A ∨¬¬B).
The following equivalence is provable in IL but not in ML:
23.
¬¬(¬¬A →¬¬B) ↔¬¬(A →B).
Proof.
The fact that 1 – 15 are valid in ML are easy to show directly. Equivalences
4, 8, 11, 15, which involve quantiﬁers, are in fact discussed in [16]. It is also easy to
see that 16 – 22 are classically valid. That 16 – 22 are not valid intuitionistically can
be shown by constructing diﬀerent appropriate Kripke models or using statements
already known not to be provable in IL (see [33] pages 324 – 328 and [35] pages
12, 75 – 86). 23 is shown to be provable in IL in [33] (page 9). See also [34, 35].
Finally, we claim that ¬¬(¬¬A →¬¬B) →¬¬(A →B) is not provable in ML. If
it was we could replace falsity ⊥by the formula A and the premise would be ML-
provable, whereas the conclusion would not as it becomes an instance of Peirce’s
law.
□

On the Relation Between Various Negative Translations
231
1.2
Logical framework
In the language of classical logic and minimal logic ML, we consider as primitive
the constants ⊥, ⊤, the connectives ∧, ∨, →and the quantiﬁers ∀and ∃. We write
¬A as an abbreviation for A →⊥. Note that CL can be formulated using a proper
subset of the symbols we consider as primitive. It would be suﬃcient, for instance,
to consider the fragment {⊥, →, ∨, ∃} or {⊥, →, ∧, ∀} (as adopted by Schwichten-
berg in [28]). Our choice of dealing directly with the full set {⊥, ⊤, →, ∧, ∨, ∀, ∃} in
the classical framework has two main reasons: First, it emphasises which symbols
are treated in a similar or diﬀerent manner in classical and minimal logic. Second,
in some embeddings of CL into ML we are going to analyse, the translations of cer-
tain formulas are syntactically diﬀerent to the derived translations we would obtain
considering just a subset of primitive symbols. In fact, usually when we choose to
work with a subset of the logical connectives in classical logic, we are implicitly
committing ourselves to one of the particular negative translations.
2
Modular Translations
Let us ﬁrst observe that all negative translations mentioned above are in general
not optimal – in the sense of introducing the least number of implications (count-
ing negations as implications) in order to turn a classically valid formula into a
minimally valid one. For instance, minimal Kuroda translation of a purely uni-
versal formula ∀xP(x) is ¬¬∀x¬¬P(x), whereas G¨odel-Gentzen would give the
optimal translation ∀x¬¬P(x). On the other hand, for purely existential formulas
∃xP(x) we have that Kuroda gives the optimal translation, whereas G¨odel-Gentzen
introduces unnecessary negations. The important property of all these translations,
however, is that they are modular, i.e. except for a single non-modular step applied
to the whole formula, the translation of a formula is based on the translation of its
immediate subformulas. The following deﬁnition makes this precise.
Deﬁnition 2 (Modular negative translations). We say that a translation (·)Tr from
CL to ML is modular if there are formula constructors ITr
□(·, ·) for □∈{∧, ∨, →},
ITr
Q (·, ·) for Q ∈{∀, ∃}, ITr
at (·) and ITr
⊢(·) called translation of connectives, quantiﬁers,
atomic formulas and the provability sign, respectively, such that for each formula
A of CL:
ATr ≡ITr
⊢(ATr)

232
Gilda Ferreira and Paulo Oliva
where (·)Tr is deﬁned inductively as:
(A ∧B)Tr
:≡
ITr
∧(ATr, BTr)
PTr
:≡
ITr
at (P), for P atomic
(A ∨B)Tr
:≡
ITr
∨(ATr, BTr)
(∀xA)Tr
:≡
ITr
∀(x, ATr)
(A →B)Tr
:≡
ITr
→(ATr, BTr)
(∃xA)Tr
:≡
ITr
∃(x, ATr).
A modular translation is called a negative translation if (i) A ↔CL ITr
⊢(ATr) and (ii)
ML ⊢ITr
⊢(ATr) whenever CL ⊢A.2
For instance, Krivine negative translation is a modular translation with
IKr
∧(A, B)
:≡
A ∨B
IKr
at (P)
:≡
¬P, for P atomic
IKr
∨(A, B)
:≡
A ∧B
IKr
∀(x, A)
:≡
∃xA
IKr
→(A, B)
:≡
¬A ∧B
IKr
∃(x, A)
:≡
¬∀x¬A
and IKr
⊢(A) :≡¬A. Similarly, one can easily see how Kolmogorov, G¨odel-Gentzen,
and minimal Kuroda translations are also modular translations.
Deﬁnition 3 (Relating modular translations). We deﬁne a relation ∼between mod-
ular translations as follows: Given translations T1 and T2 we deﬁne T1 ∼T2 if the
following equivalences are valid in minimal logic:
IT1
□(A, B)
↔ML
IT2
□(A, B)
IT1
at (P)
↔ML
IT2
at (P)
IT1
Q (x, A)
↔ML
IT2
Q (x, A)
IT1
⊢(A)
↔ML
IT2
⊢(A),
for all formulas A, B, and atomic formulas P, □∈{∧, ∨, →} and Q ∈{∀, ∃}.
In other words, two modular translations are related via ∼if the corresponding
translations of connectives, quantiﬁers, atoms and provability are equivalent for-
mulas in ML. It is immediate that ∼is an equivalence relation. In what follows we
say that two modular translations are the same if they are in the same equivalence
class for the relation ∼(i.e. they are the same mod ∼). When two translations
are not the same (in the previous sense), we say they are diﬀerent. Two diﬀerent
translations T1 and T2 from CL to ML are said to be equivalent if for each for-
mula A, the two translations of A, namely AT1 and AT2, are equivalent formulas
in ML. For instance, changing the clause for ∃xA in the G¨odel-Gentzen transla-
tion to (∃xA)GG :≡¬∀x¬AGG does not change the interpretation, since we have
that ¬∀x¬A is equivalent (in ML) to ¬¬∃xA. So, these would be just two ways
of writing the same translation. On the other hand, minimal Kuroda translation is
diﬀerent from G¨odel-Gentzen’s since, for instance, we do not normally have that
IGG
∀(x, A) ≡∀xA is equivalent, in minimal logic, to ImKu
∀
(x, A) ≡∀x¬¬A.
2A negative translation is usually assumed to satisfy a third condition (iii) ITr
⊢(ATr) ↔ML B for some
B constructed from doubly negated atomic formulas by means of ∀, ∧, →, ⊥; ensuring that all negative
translations are equivalent (see [33] for negative translations into IL).

On the Relation Between Various Negative Translations
233
3
Simpliﬁcations
Noticing that the G¨odel-Gentzen negative translation could be reached (in a mod-
ular way) from Kolmogorov translation via equivalences in ML, arose the idea of
looking for a general strategy covering the standard negative translations.
Thus, our goal is to show that the diﬀerent negative translations are obtained
via a systematic simpliﬁcation of Kolmogorov translation. For that, we need the
concept of “simpliﬁcation” we deﬁne below. Intuitively, the idea of a simpliﬁca-
tion is to transform formulas into equivalent formulas in minimal logic with fewer
implications (counting negations also as implications) preserving the modularity of
the translation. The reason why our “metric of simpliﬁcation” counts implications
instead of just negations is because the logical complexity of a formula increases
with the introduction of implications, as we view a negation as a particular form of
implication.
Deﬁnition 4 (Simpliﬁcation from inside/outside). A simpliﬁcation r from inside
is a set of transformations (at most one for each connective and quantiﬁer) of the
following form:
¬¬(NA □NB)
r⇒
N(N1A □rN2B)
¬¬QxNA
r⇒
N(QrxN1A),
where □, □r ∈{∧, ∨, →}, and Q, Qr ∈{∀, ∃}, N stands for a single or a double
negation (same choice in all the set of transformations), and N1 and N2 are negations
(possible none and not necessarily the same in all transformations) such that
(i) both sides are equivalent formulas in ML and
(ii) the number of implications (counting negations as implications) on the right
side is strictly smaller than on the left side.
A simpliﬁcation r from outside is deﬁned in a similar way replacing the shape of
the transformation before by
N(¬¬A □¬¬B)
r⇒
N1NA □rN2NB
NQx¬¬A
r⇒
QrxN1NA.
Intuitively, in the ﬁrst case we are moving negations N outwards over the outer
double negation ¬¬, whereas in the second case we are moving N inwards over
the inner ¬¬. The moving of negations is done so that we reduce the number of
negations and implications on total while keeping the modularity of the translation.
Deﬁnition 5 (Maximal simpliﬁcation). A simpliﬁcation is maximal if

234
Gilda Ferreira and Paulo Oliva
(i) it is not properly included in any other simpliﬁcation, i.e. including new
transformations for other connectives prevents the new set of being a simpli-
ﬁcation, and
(ii) it is not possible to replace □r, Qr, N1 and N2 so as to reduce the number
of implications (counting negations as implications) on the right side of any
transformation.
Intuitively, a simpliﬁcation being maximal means that we can not get ride of
more negations/implications.
Proposition 6. Let r1 and r2 be the set of transformations:
¬¬(¬¬A ∧¬¬B)
r1⇒
¬¬(A ∧B)
¬¬(¬A ∧¬B)
r2⇒
¬(A ∨B)
¬¬(¬¬A ∨¬¬B)
r1⇒
¬¬(A ∨B)
¬¬(¬A ∨¬B)
r2⇒
¬(A ∧B)
¬¬(¬¬A →¬¬B)
r1⇒
¬¬(¬A ∨B)
¬¬(¬A →¬B)
r2⇒
¬(¬A ∧B)
¬¬∃x¬¬A
r1⇒
¬¬∃xA,
¬¬∀x¬A
r2⇒
¬∃xA,
respectively. The sets r1 and r2 are maximal simpliﬁcations from inside.
Proof.
The transformations in r1 have the shape of transformations in a simpli-
ﬁcation from inside. Just take N :≡¬¬, N1 :≡¬ in the third transformation, the
other N1 and the N2 as being the zero negations, and ∧r1 :≡∧, ∨r1 :≡∨, →r1:≡∨
and ∃r1 :≡∃. Moreover they satisfy the conditions of decreasing the number of
implications (counting negations as implications) and of equivalence in ML (see
Lemma 1). Therefore r1 is a simpliﬁcation from inside. To see that r1 is a max-
imal simpliﬁcation note ﬁrst that no two transformations for the same connective
are allowed in a simpliﬁcation. Hence, any new transformation would have to have
¬¬∀x¬¬A on the left-hand side. Neither of the possible formulas for the right-hand
side (that we know have at most three negations): ¬¬∀xA, ¬¬∀x¬A, ¬¬∃xA and
¬¬∃x¬A is equivalent in ML to the left-hand side. For ¬¬∀xA see Lemma 1. So,
the set r1 can not be included properly in any simpliﬁcation. Secondly, in the three
transformations where N1 and N2 are already zero no other choice of N1, N2, ∧r1,
∨r1 and ∃r1 would lead to fewer implications. In the third transformation the re-
duction of implications would just be possible if we replace the right-hand side by
¬¬(A ∧B) or ¬¬(A ∨B). Neither of this two possibilities is a valid option because
we lose the required equivalence in ML. Therefore r1 is a maximal simpliﬁcation.
The case of r2 can be analysed in a similar way, noticing that N :≡¬, ∧r2 :≡∨,
∨r2 :≡∧, →r2:≡∧and ∀r2 :≡∃. In this case the transformation for implication has
again N1 :≡¬, and alternatives introducing fewer implications would be ¬(A ∧B)
and ¬(A∨B). In each of the two cases we have no simpliﬁcations since none of the
formulas is equivalent to ¬¬(¬A →¬B).
□

On the Relation Between Various Negative Translations
235
Proposition 7. Let r3 and r4 be the set of transformations:
¬¬(¬¬A ∧¬¬B)
r3⇒
¬¬A ∧¬¬B
¬(¬¬A ∧¬¬B)
r4⇒
¬¬A →¬B
¬¬(¬¬A →¬¬B)
r3⇒
¬¬A →¬¬B
¬(¬¬A ∨¬¬B)
r4⇒
¬A ∧¬B
¬¬∀x¬¬A
r3⇒
∀x¬¬A,
¬(¬¬A →¬¬B)
r4⇒
¬¬A ∧¬B
¬∃x¬¬A
r4⇒
∀x¬A,
respectively. The sets r3 and r4 are maximal simpliﬁcations from outside.
Proof.
Taking N :≡¬¬, ∧r3 :≡∧, →r3:≡→and ∀r3 :≡∀, we see that the shape of
the transformations in the set r3 is compatible with the shape of the transformations
in a simpliﬁcation from outside. Again, by Lemma 1, we have the equivalences
needed and the decreasing of implications also happens. Thus, r3 is a simpliﬁcation
from outside. Possible extensions of this simpliﬁcation would have to have as left-
hand side the formula ¬¬(¬¬A ∨¬¬B) or the formula ¬¬∃x¬¬A. But the former
formula is not equivalent in ML to any of the formulas ¬¬A ∧¬¬B, ¬¬A ∨¬¬B,
¬¬A →¬¬B, ¬¬¬A ∧¬¬B, ¬¬A ∧¬¬¬B, ¬¬¬A ∨¬¬B and ¬¬A ∨¬¬¬B. And
the latter formula is not equivalent in ML to ∀x¬¬A, ∀x¬¬¬A, ∃x¬¬A, neither
to ∃x¬¬¬A (see Lemma 1). So the simpliﬁcation can not be extended. In terms
of introducing fewer implications the only transformation to analyse is the one
concerning implication. The two possible cases ¬¬A∧¬¬B and ¬¬A∨¬¬B are not
equivalent to ¬¬(¬¬A →¬¬B). So r3 is a maximal simpliﬁcation. The set r4 can
be analysed in a similar way, this time taking N :≡¬, ∧r4 :≡→(N1 :≡¬), ∨r4 :≡∧,
→r4:≡∧(N1 :≡¬) and ∃r4 :≡∀. Concerning maximality, by Lemma 1, we know
that ¬∀x¬¬A is not equivalent in minimal logic to ∃x¬A, so we can not extend
the simpliﬁcation. And it is not possible to reduce the number of implications
because neither ¬(¬¬A ∧¬¬B) nor ¬(¬¬A →¬¬B) is equivalent in ML to a
formula with two implications, i.e. of the shape ¬A□¬B with □equal to ∧or ∨
and ¬(¬¬A ∧¬¬B) is also not equivalent to any formulas with three implications:
¬¬A ∨¬B, ¬A ∨¬¬B, ¬¬A ∧¬B, ¬A ∧¬¬B and ¬A →¬B.
□
Proposition 8. The simpliﬁcations r1, r2, r3 and r4 are the only maximal simpliﬁ-
cations.
Proof.
Considering the potential simpliﬁcations from outside that are maximal,
we can have two cases N :≡¬¬ or N :≡¬. In the ﬁrst case, as can be no-
ticed from the proof of Proposition 7, transformations with left-hand side equal to
¬¬(¬¬A ∨¬¬B) or ¬¬∃x¬¬A can never appear in the simpliﬁcation. Since in r3
we have N1 = N2 = no negations, for ∧, →and ∀, other maximal simpliﬁcation
would have to have other choices for □, N1, N2 for those transformations keeping
the number of implications. Obviously changing the connectives in ∧and ∀we

236
Gilda Ferreira and Paulo Oliva
lose the equivalences. In the transformation for →, all the other possible formulas
with ﬁve implications on the right-hand side are not equivalent in ML to the for-
mula ¬¬(¬¬A →¬¬B) (see Lemma 1). So r3 is the only maximal simpliﬁcation
from outside with N :≡¬¬. In the second case (N :≡¬) we already know that a
transformation with left-hand side of the form ¬∀x¬¬A never occurs. We can also
check that the only possibilities for the transformations of ∧, ∨, →and ∃giving
rise to equivalences in ML (with a minimum number of implications) are the ones
in r4. So r4 is the only maximal simpliﬁcation from outside when N :≡¬.
Similarly, considering the potential simpliﬁcations from inside that are maxi-
mal, we can also divide them into two cases: N :≡¬¬ or N :≡¬. In the case
N :≡¬¬, as showed in the proof of Proposition 6, no transformation with left-
hand side of the form ¬¬∀x¬¬A can appear. For ∧, ∨, and ∃any transformation
in a maximal simpliﬁcation has to have N1, N2’s introducing no negations. Note
that this happens with r1. With this restriction on negations, we can check that
the transformations for these connectives presented in r1 are the only possibilities
for a maximal simpliﬁcation. For →, we already know that any transformation
in a maximal simpliﬁcation should have three implications. The alternatives are
¬¬(A →B), ¬¬(¬A ∨B), ¬¬(¬A ∧B), ¬¬(A ∧¬B) and ¬¬(A ∨¬B). Obviously,
the last three formulas are not equivalent in ML to ¬¬(¬¬A →¬¬B) and since the
ﬁrst one is equivalent to ¬¬(¬¬A →¬¬B) in IL but not in ML (see Lemma 1), we
conclude that the only possible choice is the one in r1. Thus r1 is the only maximal
simpliﬁcation from inside with N :≡¬¬.
In the case N :≡¬, and since r2 is a maximal simpliﬁcation, we know that no
transformation with left-hand side of the form ¬¬∃x¬A can appear. For ∧, ∨and ∀
since the transformation in r2 add no negations nor implication (apart from the one
corresponding to N), any other transformation in a maximal simpliﬁcation has to
add no negations or implications either. Because the two sides of a transformation
have to be equivalent over ML, the only possibilities are, in fact, the ones in r2. The
transformation that has left-hand side of the form ¬¬(¬A →¬B), as we proved in
Proposition 6, has to have a right-hand side with exactly two implications. Easily
we can see that the only possible choice for N1, N2 and □is ¬(N1A □N2B) :≡
¬(¬A ∧B), which is exactly the transformation for →in r2. Thus r2 is the only
maximal simpliﬁcation from inside when N :≡¬.
□
4
Kolmogorov Simpliﬁed
Deﬁnition 4 identiﬁes a class of transformations which can be applied to Kol-
mogorov negative translation without spoiling the modularity property of the trans-
lation. We now present standard ways of simplifying Kolmogorov translation via

On the Relation Between Various Negative Translations
237
the maximal (or proper subsets of the maximal) simpliﬁcations introduced above.
Deﬁnition 9 (Simpliﬁcation path). Applying a simpliﬁcation to a formula A con-
sists in changing the formula through successive steps, applying in each step a
transformation allowed by the simpliﬁcation (i.e. transforming a subformula hav-
ing the shape of the left-hand side of the transformation by the corresponding right-
hand side), till no longer be possible to simplify the expression via that simpliﬁca-
tion. We call the path of formulas starting in A we obtain this way a simpliﬁcation
path.
Note that every step in a simpliﬁcation path acts over a particular connective
or quantiﬁer and all formulas in a simpliﬁcation path are equivalent formulas in
ML. The process of applying a simpliﬁcation is not unique and can lead to diﬀerent
formulas. Nevertheless, all simpliﬁcation paths are obviously ﬁnite since in each
step the number of implications is decreasing. From now on, we consider that all
simpliﬁcation paths start with formulas in Kolmogorov form (i.e. formulas of the
form AKo).
Deﬁnition 10 (Length of simpliﬁcation path). The length of a simpliﬁcation path
P, denoted s(P), is the number of steps in P, or equivalently the number of nodes
in P minus one, where by node we refer to each formula in P.
Clearly, it is not true that two simpliﬁcation paths with the same length lead to
the same formula, i.e. have the same ﬁnal node. For instance, consider applying
simpliﬁcation r1 to the formula below in two diﬀerent ways:
¬¬(¬¬(¬¬A ∧¬¬B) ∧¬¬∃x¬¬A)
¬¬(¬¬(¬¬A ∧¬¬B) ∧¬¬∃xA)
¬¬(¬¬(A ∧B) ∧¬¬∃x¬¬A)
¬¬((¬¬A ∧¬¬B) ∧∃xA)
¬¬((A ∧B) ∧∃x¬¬A)



HHH
Nevertheless, we prove that if a simpliﬁcation is maximal or is a subset of a max-
imal simpliﬁcation then the length of the longest paths is determined by the initial
formula and, moreover, all the paths with longest length lead to the same formula.
In other words, we have a kind of conﬂuence property for longest paths. First some
deﬁnitions and auxiliary results.
Notation. In order to simplify the formulation of Lemmas 11 and 12 we use the
following abbreviations:

238
Gilda Ferreira and Paulo Oliva
• Removing the double negation from outside over □or Q, with □∈{∧, →} and
Q ∈{∀, ∃} consists in replacing the formula ¬¬(¬¬A□¬¬B) by ¬¬A□¬¬B,
or replacing ¬¬Qx¬¬A by Qx¬¬A.
• Removing the double negations from inside over □∈{∧, ∨} or Q, stands for
replacing ¬¬(¬¬A□¬¬B) by ¬¬(A□B), or ¬¬Qx¬¬A by ¬¬QxA.
• Removing the double negation from inside over →consists in replacing the
formula ¬¬(¬¬A →¬¬B) by ¬¬(¬A ∨B).
• Removing single negations (from inside or outside) over □∈{∨, →} in the
formula ¬¬(¬¬A□¬¬B) consists in transforming the double negations in sin-
gle negations, replacing □by ∧and in the case □≡→adding a negation
before A. Removing a single negation (from inside or outside) over a quan-
tiﬁer symbol Q in the formula ¬¬Qx¬¬A consists in replacing the double
negations by single negations and replacing Q by its dual.
• Removing a single negation from inside (respectively outside) over ∧in the
formula ¬¬(¬¬A ∧¬¬B) consists in replacing this formula by ¬(¬A ∨¬B)
(or replacing this formula by ¬(¬¬A →¬B) respectively).
We denote by #A
□and #A
Q the number of symbols □and Q respectively, occur-
ring in the formula A. For the sake of counting symbols, the negation symbols ¬
introduced by the translations are considered as primitive, and hence do not change
the value of #A
→. For example (#A
→) = (#AKo
→).
Lemma 11. For the simpliﬁcation r1 and for any formula AKo there is a simpliﬁ-
cation path Pr1 from AKo such that
s(Pr1) = (#AKo
∧) + (#AKo
∨) + (#AKo
→) + (#AKo
∃)
and the formula in the last node can be obtained from AKo locating in this for-
mula all the occurrences of conjunctions, disjunctions, implications and existential
quantiﬁcations and removing at once all the double negations from inside these
connectives and quantiﬁers.
Any simpliﬁcation r′
1 obtained from r1 by removing one or more transformations
admits a similar result discounting and disregarding the logical symbols in the left-
hand side of the transformations removed.
Proof.
The proof is by induction on the complexity of the formula A, simpli-
fying ﬁrst the subformulas and later the more external connectives and quantiﬁers
whenever possible. If A is an atomic formula then AKo :≡¬¬A and we can apply
no steps. So, the only simpliﬁcation path is the path with a single node ¬¬A which

On the Relation Between Various Negative Translations
239
satisﬁes the lemma.
For A :≡B∧C, we know that by induction hypothesis there is a simpliﬁcation path
P1 from BKo :≡¬¬B′ such that
s(P1) = (#BKo
∧) + (#BKo
∨) + (#BKo
→) + (#BKo
∃)
and the last node of P1 can be obtained from BKo removing the double negations
from inside all the conjunctions, disjunctions, implications and existential quantiﬁ-
cations. We denote that formula by ¬¬B′
−. Also, by induction hypothesis, there is
a path P2 from CKo :≡¬¬C′ such that
s(P2) = (#CKo
∧) + (#CKo
∨) + (#CKo
→) + (#CKo
∃)
and the last node of P2 can be obtained from CKo removing the double negations
from inside all the conjunctions, disjunctions, implications and existential quantiﬁ-
cations. We denote that formula by ¬¬C′
−. Consider the following simpliﬁcation
path from AKo ≡(B ∧C)Ko ≡¬¬(BKo ∧CKo) ≡¬¬(¬¬B′ ∧¬¬C′), which incor-
porates the two paths P1 and P2:
¬¬(¬¬B′ ∧¬¬C′)
¬¬(¬¬B′
−∧¬¬C′)
¬¬(¬¬B′
−∧¬¬C′
−)
¬¬(B′
−∧C′
−)
P1
P2
This path has length
s(P1) + s(P2) + 1 = #BKo
∧
+ #CKo
∧
+ 1 + #BKo
∨
+ #CKo
∨
+ #BKo
→+ #CKo
→+ #BKo
∃
+ #CKo
∃
=
(#AKo
∧) + (#AKo
∨) + (#AKo
→) + (#AKo
∃).
And, by induction hypothesis, easily we can see that the formula in the last node
coincide with the formula AKo after removing the double negations from inside the
conjunctions, disjunctions, implications and existential quantiﬁcations.
The case A :≡B ∨C, is done in the same way replacing ∧by ∨.
For A :≡B →C the simpliﬁcation path becomes:

240
Gilda Ferreira and Paulo Oliva
¬¬(¬¬B′ →¬¬C′)
¬¬(¬¬B′
−→¬¬C′)
¬¬(¬¬B′
−→¬¬C′
−)
¬¬(¬B′
−∨C′
−)
P1
P2
This path has length
s(P1) + s(P2) + 1 = #BKo
∧
+ #CKo
∧
+ #BKo
∨
+ #CKo
∨
+ #BKo
→+ #CKo
→+ 1 + #BKo
∃
+ #CKo
∃
=
(#AKo
∧) + (#AKo
∨) + (#AKo
→) + (#AKo
∃).
For A :≡∃xB, the strategy is similar considering, by induction hypothesis, that we
have the path P1 from BKo :≡¬¬B′ in the conditions of the lemma and constructing
the simpliﬁcation path:
¬¬∃x¬¬B′
¬¬∃x¬¬B′
−
¬¬∃xB′
−
P1
For A :≡∀xB we just need to take the path P1 that exists by induction hypothesis:
¬¬∀x¬¬B′
¬¬∀x¬¬B′
−
P1
That concludes the proof.
□
The proof above in fact provides an algorithm to construct a simpliﬁcation path
for the simpliﬁcation r with r ≡r1 or r ≡r′
1. The simpliﬁcation path from AKo
constructed this way is called standard path for r.

On the Relation Between Various Negative Translations
241
Lemma 12. For the simpliﬁcations r2, r3, r4 and for any formula AKo, there are
simpliﬁcation paths Pr2, Pr3, Pr4 such that
s(Pr2) = (#AKo
∧) + (#AKo
∨) + (#AKo
→) + (#AKo
∀),
s(Pr3) = (#AKo
∧) + (#AKo
→) + (#AKo
∀) and
s(Pr4) = (#AKo
∧) + (#AKo
∨) + (#AKo
→) + (#AKo
∃).
Moreover, in Pr2 the last node can be obtained from AKo removing at once the single
negations from inside all the conjunctions, disjunctions, implications and univer-
sal quantiﬁcations; the formula in the last node in Pr3 can be obtained from AKo
by removing at once the double negations from outside the conjunctions, implica-
tions and universal quantiﬁcations; and the formula in the last node of Pr4 can
be obtained from AKo by removing at once the single negations from outside the
conjunctions, disjunctions, implications and existential quantiﬁcations.
The result can be adapted in the expected way to simpliﬁcations obtained from
r2, r3 or r4 by removing one or more transformations.
Proof.
The proof is similar to the proof of the preceding lemma but, contrarily
to the simpliﬁcations from inside, the paths for r3, r4 and its subsets are obtained
transforming ﬁrst the more external logical symbols and just then the symbols in
the proper subformulas. For r2, we have the following inductive path constructions:
(B ∧C)Ko ≡¬¬(¬¬B′ ∧¬¬C′)
¬¬(¬B′
−∧¬¬C′)
¬¬(¬B′
−∧¬C′
−)
¬(B′
−∨C′
−)
P1
P2
(B →C)Ko ≡¬¬(¬¬B′ →¬¬C′)
¬¬(¬B′
−→¬¬C′)
¬¬(¬B′
−→¬C′
−)
¬(¬B′
−∧C′
−)
P1
P2
The case of (B ∨C)Ko is exactly as (B ∧C)Ko, replacing ∧by ∨and ∨by ∧.

242
Gilda Ferreira and Paulo Oliva
(∃xB)Ko ≡¬¬∃x¬¬B′
¬¬∃x¬B′
−
P1
(∀xB)Ko ≡¬¬∀x¬¬B′
¬¬∀x¬B′
−
¬∃xB′
−
P1
For r3 we have these other path constructions:
(B ∧C)Ko ≡¬¬(¬¬B′ ∧¬¬C′)
¬¬B′ ∧¬¬C′
B′
−∧¬¬C′
B′
−∧C′
−
P2
P1
(B ∨C)Ko ≡¬¬(¬¬B′ ∨¬¬C′)
¬¬(B′
−∨¬¬C′)
¬¬(B′
−∨C′
−)
P1
P2
The case (B →C)Ko is like the case (B ∧C)Ko, replacing ∧by →.
(∃xB)Ko ≡¬¬∃x¬¬B′
¬¬∃xB′
−
P1
(∀xB)Ko ≡¬¬∀x¬¬B′
∀x¬¬B′
∀xB′
−
P1
For r4 we have:

On the Relation Between Various Negative Translations
243
(B ∧C)Ko ≡¬¬(¬¬B′ ∧¬¬C′)
¬(¬¬B′ →¬C′)
¬(¬B′
−→¬C′)
¬(¬B′
−→C′
−)
P∗
2
P1
(B ∨C)Ko ≡¬¬(¬¬B′ ∨¬¬C′)
¬(¬B′ ∧¬C′)
¬(B′
−∧¬C′)
¬(B′
−∧C′
−)
P∗
2
P∗
1
The case (B →C)Ko is like the case (B ∧C)Ko, swapping ∧with →.
(∀xB)Ko ≡¬¬∀x¬¬B′
¬¬∀x¬B′
−
P1
(∃xB)Ko ≡¬¬∃x¬¬B′
¬∀x¬B′
¬∀xB′
−
P∗
1
The notation P∗is used in the following sense. We know, by induction hypothesis,
that there is a path P from BKo :≡¬¬B′. The last node of this path results from
¬¬B′ removing the single negations from outside all conjunctions, disjunctions,
implications and existential quantiﬁcations occurring in BKo. We can show that
the last node has the shape ¬B′
−, where B′
−can possibly start with a negation.
Moreover, it is possible to prove that every node in the path P starts with a
negation and that removing the starting negation in each step along all path we
get a sequence of formulas that can be part of a path, i.e. we get a sequence of
valid steps in our simpliﬁcation. We call this sequence of steps P∗. In the above
we are using the fact that, after applying a simpliﬁcation to a symbol □or Q,
we can no longer apply a simpliﬁcation to the symbol □r4 or Qr4, since at least
one of the negations inside is not a double negation and never will became (note
that in r4 the number of negations in each position remains the same or decrease). □
Again, the proof above provides algorithms to construct simpliﬁcation paths
for the simpliﬁcations r2, r3, r4 and its subsets. The simpliﬁcation paths from AKo
constructed via these algorithms are called standard paths.

244
Gilda Ferreira and Paulo Oliva
Lemma 13. If the simpliﬁcation is a subset of a maximal one, in each step of a
simpliﬁcation path we act over a connective or a quantiﬁer already occurring in
the initial formula, and we never act twice over the same connective or quantiﬁer.
Proof.
Let r be a subset of a maximal simpliﬁcation. It is enough to prove that
in each step of a simpliﬁcation path we never act over □r or Qr. By Proposition
8, we know that the transformations in r are between the ones in r1, or between
the ones in r2, or the ones in r3, or the ones in r4. In the case of r1, the formulas
¬¬(¬¬A □¬¬B), with □∈{∧, ∨}, ¬¬(¬¬A →¬¬B) and ¬¬∃x¬¬A are trans-
formed into ¬¬(A □rB), ¬¬(¬A →r B) and ¬¬∃rxA respectively. In all the cases
we can no longer apply any transformations over □r, →r or ∃r since they do not
have (and since the negations in every position are kept or reduced they will never
became till the last node with) double negations inside them. The cases of r2, r3
and r4 can be checked in a completely similar way.
□
Note that, in the previous lemma, the hypothesis of considering just subsets
of maximal simpliﬁcations is essential. In the example below we present a (non
maximal) simpliﬁcation from inside that contradicts the lemma. Consider the sim-
pliﬁcation:
¬¬(¬A ∧¬B)
⇒
¬(A ∨¬¬B)
¬¬(¬A ∨¬B)
⇒
¬(A ∧B).
From ¬¬(¬¬A ∧¬¬(¬¬B ∧¬¬C)) we can construct the following two paths:
¬¬(¬¬A ∧¬¬(¬¬B ∧¬¬C))
¬(¬A ∨¬¬¬(¬¬B ∧¬¬C))
¬¬(¬¬A ∧¬(¬B ∨¬¬¬C))
¬(¬A ∨¬¬(¬B ∨¬¬¬C))
¬(¬A ∨¬(B ∧¬¬C))



HHH
HHH



The two corollaries below are now immediate:
Corollary 14. For each formula AKo and each simpliﬁcation that is a subset of r1,
r2, r3 or r4, any simpliﬁcation path from AKo has length smaller or equal to the
length of the corresponding standard path.

On the Relation Between Various Negative Translations
245
Corollary 15. If the simpliﬁcation is a subset of a maximal one, two simpliﬁcation
paths with the longest length lead to the same formula.
The result above justiﬁes the next deﬁnition:
Deﬁnition 16. Let r be a subset of a maximal simpliﬁcation and AKo a formula in
Kolmogorov form. We denote by r(AKo) the formula in the last node of a simpliﬁ-
cation path with longest length.
5
Standard Translations
Simplifying the Kolmogorov negative translation via the maximal simpliﬁcations
r1, r2 and r3 we obtain exactly minimal Kuroda, Krivine and G¨odel-Gentzen nega-
tive translations.
Proposition 17. r1(AKo) ≡AmKu, r2(AKo) ≡AKr and r3(AKo) ≡AGG.
Proof.
The proof is done by induction on the complexity of the formula A and
in order to reach the formula r1(AKo) we always assume we are going through the
standard path (s.p.).
If A is an atomic formula, then r1(AKo) :≡r1(¬¬A) ≡¬¬A :≡AmKu.
For A :≡B ∧C, writing BKo in the form ¬¬B′ and CKo as ¬¬C′, we know that
r1(¬¬B′) ≡r1(BKo)
I.H.
≡BmKu ≡¬¬BmKu and similarly r1(¬¬C′) ≡r1(CKo) ≡
CmKu ≡¬¬CmKu. Therefore
r1((B ∧C)Ko)
≡
r1(¬¬(BKo ∧CKo))
≡
r1(¬¬(¬¬B′ ∧¬¬C′))
s.p.
≡
¬¬(BmKu ∧CmKu)
≡
(B ∧C)mKu.
The case A :≡B ∨C can be analysed in a similar way.
For A :≡B →C we have:
r1((B →C)Ko)
≡
r1(¬¬(BKo →CKo))
≡
r1(¬¬(¬¬B′ →¬¬C′))
s.p.
≡
¬¬(¬BmKu ∨CmKu)
≡
(B →C)mKu.
For the quantiﬁers we have:

246
Gilda Ferreira and Paulo Oliva
r1((∃xB)Ko) ≡r1(¬¬∃xBKo) ≡r1(¬¬∃x¬¬B′)
s.p.
≡¬¬∃xBmKu ≡(∃xB)mKu
and
r1((∀xB)Ko)
≡
r1(¬¬∀xBKo)
≡
r1(¬¬∀x¬¬B′)
s.p.
≡
¬¬∀x¬¬BmKu
≡
(∀xB)mKu.
Therefore r1(AKo) ≡AmKu.
In the case of r2, the proof is done in a similar way, by induction on the complexity
of the formula A considering standard paths.
If A is an atomic formula, then r2(AKo) :≡r2(¬¬A) ≡¬¬A ≡¬AKr :≡AKr.
For A :≡B ∧C, we know that r2(¬¬B′) ≡r2(BKo)
I.H.
≡BKr ≡¬BKr and similarly
r2(¬¬C′) ≡r2(CKo) ≡CKr ≡¬CKr. But then
r2((B ∧C)Ko) ≡r2(¬¬(BKo ∧CKo)) ≡r2(¬¬(¬¬B′ ∧¬¬C′))
s.p.
≡¬(BKr ∨
CKr) ≡(B ∧C)Kr.
Analogously, for A :≡B ∨C and A :≡B →C we have the following identities:
r2((B ∨C)Ko) ≡r2(¬¬(BKo ∨CKo)) ≡r2(¬¬(¬¬B′ ∨¬¬C′))
s.p.
≡¬(BKr ∧
CKr) ≡(B ∨C)Kr
and
r2((B →C)Ko) ≡r2(¬¬(BKo →CKo)) ≡r2(¬¬(¬¬B′ →¬¬C′))
s.p.
≡
¬(¬BKr ∧CKr) ≡(B →C)Kr.
For the quantiﬁers we have:
r2((∃xB)Ko)
≡
r2(¬¬∃xBKo)
≡
r2(¬¬∃x¬¬B′)
s.p.
≡
¬¬∃x¬BKr
≡
¬(∃xB)Kr ≡(∃xB)Kr
and
r2((∀xB)Ko) ≡r2(¬¬∀xBKo) ≡r2(¬¬∀x¬¬B′)
s.p.
≡¬∃xBKr ≡(∀xB)Kr.
Thus r2(AKo) ≡AKr.
We illustrate the case r3 with the conjunction, since the others are completely sim-
ilar.
r3((B ∧C)Ko)
≡
r3(¬¬(BKo ∧CKo)) ≡r3(¬¬(¬¬B′ ∧¬¬C′))
s.p.
≡
r3(¬¬B′) ∧r3(¬¬C′) ≡r3(BKo) ∧r3(CKo)
I.H.
≡
BGG ∧CGG ≡(B ∧C)GG.

On the Relation Between Various Negative Translations
247
□
This study concerning maximal simpliﬁcations led us not only to the three stan-
dard negative translations above but also to the discovery of a new minimal modular
embedding from CL to ML. Consider the translation described below:
(A ∧B)E
:≡
¬AE →BE
PE
:≡
¬P, for P atomic
(A ∨B)E
:≡
AE ∧BE
(∀xA)E
:≡
¬∀x¬AE
(A →B)E
:≡
¬AE ∧BE
(∃xA)E
:≡
∀xAE
with AE :≡¬AE, which is similar to Krivine except that negations are introduced
in the {∧, ∀}-clauses whereas Krivine introduces negations on the ∃-clause.
Immediately as a corollary of the next proposition, we have that the transla-
tion (·)E is an embedding from CL to ML, diﬀerent but equivalent to the standard
embeddings considered previously.
Proposition 18. r4(AKo) ≡AE.
Proof.
We just sketch the case of conjunction A :≡B ∧C. The other cases can
be done using the same strategy.
Take BKo :≡¬¬B′ and CKo :≡¬¬C′. Consider, by induction hypothesis, that
r4(¬¬B′) ≡r4(BKo)
I.H.
≡BE ≡¬BE and r4(¬¬C′) ≡r4(CKo) ≡BE ≡¬CE. Then
r4((B ∧C)Ko)
≡
r4(¬¬(BKo ∧CKo)) ≡r4(¬¬(¬¬B′ ∧¬¬C′))
s.p.
≡
¬(¬BE →CE) ≡¬(B ∧C)E ≡(B ∧C)E.
That concludes the proof.
□
6
Simpliﬁcations over IL
In the previous section we analysed the various negative translation of classical
logic CL into minimal logic ML. In the present section we shall also consider trans-
lations that map into intuitionistic logic. In this (less strict) framework, a negative
translation is an embedding from CL into IL (not necessarily ML) and simpliﬁ-
cations are based on equivalences in IL (not necessarily ML). Working over the
stronger system of IL will mean that more equivalences are provable, which in turn
will mean that new maximal simpliﬁcations are possible.
Obviously, in this context, r1, r2, r3 and r4 are still simpliﬁcations because an
equivalence provable in ML is also provable in IL. Using a strategy similar to the

248
Gilda Ferreira and Paulo Oliva
one applied on Section 3 in the proofs of Propositions 6, 7, and 8, we can also
see that r1, r2, r3 and r4 are maximal simpliﬁcations, but there is a ﬁfth one. The
simpliﬁcation r′
1 (that only diﬀers from r1 in the transformation for →) deﬁned
below
¬¬(¬¬A ∧¬¬B)
r′
1⇒
¬¬(A ∧B)
¬¬(¬¬A ∨¬¬B)
r′
1⇒
¬¬(A ∨B)
¬¬(¬¬A →¬¬B)
r′
1⇒
¬¬(A →B)
¬¬∃x¬¬A
r′
1⇒
¬¬∃xA
is also a maximal simpliﬁcation from inside. This appears as no surprise since by
Lemma 1, we know that ¬¬(¬¬A →¬¬B) ↔¬¬(A →B) in IL but not in ML.
Mimicking Sections 4 and 5, this time in the context of IL, apart from obtaining
minimal Kuroda, Krivine, G¨odel-Gentzen and the new (·)E negative translation as
maximal simpliﬁcations of the Kolmogorov negative translation via r1, r2, r3 and
r4 respectively, we also have the following result:
Proposition 19. r′
1(AKo) ≡AKu.
Proof.
As in Proposition 17, the proof is done by induction on the complexity of
the formula A considering standard paths.
Since the only case that diﬀers is A :≡B →C, we sketch it below:
For A :≡B →C, writing BKo in the form ¬¬B′ and CKo as ¬¬C′, we know that
r′
1(¬¬B′) ≡r′
1(BKo)
I.H.
≡BKu ≡¬¬BKu and similarly r′
1(¬¬C′) ≡r′
1(CKo) ≡CKu ≡
¬¬CKu. Therefore
r′
1((B →C)Ko)
≡
r′
1(¬¬(BKo →CKo))
≡
r′
1(¬¬(¬¬B′ →¬¬C′))
s.p.
≡
¬¬(BKu →CKu)
≡
(B →C)Ku.
□
Hence, simplifying the Kolmogorov negative translation via the (maximal in
IL) simpliﬁcation r′
1 we obtain exactly Kuroda negative translation.
As previously observed, Kuroda negative translation is a translation from CL
into IL, not into ML. But a small change in the translation of implications, namely
(A →B)mKu :≡¬¬(¬AmKu ∨BmKu) produces a negative translation not only in IL

On the Relation Between Various Negative Translations
249
but also in ML. Both translations (·)Ku and (·)mKu are minimal elements in the partial
order induced by the simpliﬁcations (the former in IL via r′
1 and the latter in ML and
IL via r1). In what follows, we present another way of changing Kuroda negative
translation so as to obtain an embedding into ML. Consider that we change in r1
the clause for implication to
¬¬(¬¬A →¬¬B)
˜r1⇒¬¬(A →¬¬B).
This way, we obtain a non-maximal simpliﬁcation (in IL) which corresponds to a
modular translation (·) ˜Ku between Kolmogorov and Kuroda negative translations.
Since ¬¬(¬¬A →¬¬B) ↔ML ¬¬(A →¬¬B), ˜r1 is also a (non-maximal) simpli-
ﬁcation in ML. Therefore, the modular translation (·) ˜Ku that inserts ¬¬ in (i) the
beginning of the formula, (ii) after each universal quantiﬁer, and (iii) in front of the
conclusion of each implication is such that CL ⊢A iﬀML ⊢A ˜Ku. This is the variant
of Kuroda considered by Murthy in [25].
7
Final remarks
We conclude with a few remarks on other negative translations, some related work
and avenues for further research.
7.1
On non-modular negative translations
Working with modular translations brings various beneﬁts. For instance, we can
prove properties of the translation by a simple induction on the structure of the
formulas, and when applying the translation to concrete proofs this can be done in
a modular fashion. On the other hand, if we allow a translation to be non-modular,
we can of course construct simpler embeddings, i.e. we can simplify Kolmogorov
negative translation even more, getting ride of more implications.
For example, consider the simpliﬁcation r3 followed by one more transforma-
tion ¬¬∃x¬¬A ⇒¬∀x¬A to be applied, whenever possible, at the end of the
simpliﬁcation path. As such we could ﬁrst simplify ¬¬(¬¬A ∧¬¬∃x¬¬B) using
r3 to the formula ¬¬A ∧¬¬∃x¬¬B and then apply the ﬁnal simpliﬁcation to ob-
tain ¬¬A ∧¬∀x¬B. Although non-modular, these kind of procedures also give rise
to translations of classical into minimal or intuitionistic logic (depending on the
framework ML or IL of the simpliﬁcations).
Avigad [2] presented a more sophisticated non-modular translation of CL into IL
that results from a fragment of r′
1, avoiding unnecessary negations. More precisely,

250
Gilda Ferreira and Paulo Oliva
Avigad’s M-translation is deﬁned as:
(A ∧B)M
:≡
¬(∼A∨∼B)M
PM
:≡
P, for P atomic
(A ∨B)M
:≡
AM ∨BM
¯PM
:≡
¬P
(∀xA)M
:≡
¬(∃x ∼A)M
(∃xA)M
:≡
∃xAM,
where in classical logic we consider the negations of atomic formulas ¯P as primitive
and the formula ∼A is obtained from A replacing ∧, ∀, P respectively by ∨, ∃and
¯P and conversely. Avigad showed that
(1) ⊢IL ¬AM ↔¬AS
(2) If ⊢CL A then ⊢IL ¬(∼A)M,
where AS stands for any of the standard equivalent translations from CL into IL
mentioned before such as G¨odel-Gentzen, Kolmogorov, Kuroda or Krivine negative
translation.
Lemma 20. ¬(∼A)M ↔IL ¬¬AM
Proof.
The proof follows from an easy analysis of all the possibilities for the
formula A. If A is an atomic formula then ¬(∼A)M :≡¬ ¯AM :≡¬¬A :≡¬¬AM.
For A :≡¯P, we have ¬(∼¯P)M :≡¬PM :≡¬P ↔¬¬¬P ↔¬¬ ¯PM.
If A :≡B ∧C then ¬(∼(B ∧C)M :≡¬(∼B∨∼C)M ↔¬¬¬(∼B∨∼C)M :≡
¬¬(B ∧C)M.
The disjunction case ¬(∼(B ∨C))M :≡¬(∼B∧∼C)M :≡¬¬(∼∼B∨∼∼C)M :≡
¬¬(B ∨C)M.
The quantiﬁcations are studied below:
¬(∼∀xB)M :≡¬(∃x ∼B)M ↔¬¬¬(∃x ∼B)M :≡¬¬(∀xB)M,
and
¬(∼∃xB)M :≡¬(∀x ∼B)M :≡¬¬(∃x ∼∼B)M¬¬(∃xB)M.
That concludes the proof.
□
Although the translation (·)M, as presented by Avigad, is not modular, notice
that it can be equivalently written in a modular way as
(A ∧B)M′
:≡
¬¬AM′ ∧¬¬BM′
PM′
:≡
P, for P atomic
(A ∨B)M′
:≡
AM′ ∨BM′
¯PM′
:≡
¬P
(∀xA)M′
:≡
∀x¬¬AM′
(∃xA)M′
:≡
∃xAM′,

On the Relation Between Various Negative Translations
251
since (∀xA)M :≡¬(∃x ∼A)M :≡¬∃x((∼A)M) ↔IL ∀x¬(∼A)M
(Lemma 20)
↔
IL
∀x¬¬AM and
(A ∧B)M
:≡
¬(∼A∨∼B)M :≡¬((∼A)M ∨(∼B)M)
↔IL
¬(∼A)M ∧¬(∼B)M (Lemma 20)
↔
IL ¬¬AM ∧¬¬BM.
The translation (·)M′ can be obtained from Kolmogorov negative translation via a
non-maximal simpliﬁcation, more precisely the simpliﬁcation r′
1 (corresponding to
Kuroda translation) without the transformation ¬¬(¬¬A ∧¬¬B)
r′
1⇒¬¬(A ∧B).
Avigad’s translation (·)M is a non-modular simpliﬁcation of (·)M′ since for uni-
versal quantiﬁcations, for conjunctions and for provability we replace ¬¬AM by
¬(∼A)M which, although equivalent, has possibly fewer negations, as we see in
the proof of Lemma 20. Moreover, as pointed by Avigad in [2], we can simplify
the translation (·)M even further deﬁning (A ∧B)M as being AM ∧BM. The corre-
sponding modular version in this case is exactly Kuroda negative translation.
7.2
On G¨odel-Gentzen negative translation
Although nowadays it is common to name the translation (·)GG, presented in Section
1, by G¨odel-Gentzen negative translation, a few remarks should be made at this
point. The translations due to G¨odel and Gentzen ([12] and [10], respectively)
where introduced in the context of number theory translating an atomic formula P
into P itself. Later Kleene [19] considered the translation of the pure logical part,
observing that double-negating atomic formulas was necessary, since one does not
have stability ¬¬P →P in general.
Rigorously, Gentzen’s original formulation instead of double negating disjunc-
tions and existential quantiﬁers used the following equivalent (in IL and ML) def-
initions (A ∨B)GG :≡¬(¬AGG ∧¬BGG) and ∃xAGG :≡¬∀x¬AGG, since, as such,
one can then work in the {∃, ∨}-free fragment of minimal or intuitionistic logic.
Moreover, as pointed in Section 1 already, G¨odel’s original double-negation
translation diﬀers from Gentzen’s negative translation in the way implication is
treated. In the context of IL, G¨odel’s translation also introduces a double negation
before implications. We can easily see, that this translation can be obtained from
Kolmogorov negative translation via the non-maximal simpliﬁcation consisting in
r3 without the transformation ¬¬(¬¬A →¬¬B) ⇒¬¬A →¬¬B, being, there-
fore, more expensive in term of implications than Gentzen’s negative translation.
Another non-maximal simpliﬁcation, more precisely r3 without the transformation
¬¬(¬¬A ∧¬¬B) ⇒¬¬A ∧¬¬B, leads to Aczel’s (·)N variant [1].
Finally, we observe that sometimes in Kolmogorov or G¨odel-Gentzen negative
translations, ⊥is transformed diﬀerently from the other atomic formulas, not into

252
Gilda Ferreira and Paulo Oliva
¬¬⊥but into ⊥itself. This change is easily adapted to our framework, considering
in the modular deﬁnition of a translation an extra operator ITr
⊥(⊥) and deﬁning
⊥Tr :≡ITr
⊥(⊥). Note that the translations where ITr
⊥(⊥) :≡⊥are the same as the
ones with ITr
⊥(⊥) :≡¬¬⊥, since ⊥↔¬¬⊥in IL and ML.
7.3
Translations from IL into ILL
In the present paper, we saw that the standard translations from CL to IL result from
systematic simpliﬁcations on Kolmogorov negative translation. Motivated by this
idea, we observe that something similar can be said about the embeddings from
intuitionistic logic to intuitionistic linear logic (ILL). In the linear framework, and
replacing the moves of the double negations from inside or outside by moves of the
exponential ! (whenever allowed by linear equivalences), we obtain the standard
Girard (·)∗and (·)◦-translation from a Kolmogorov-like translation from IL into ILL.
We start by reminding the reader of the Girard translations (·)∗and (·)◦[11]
P∗
:≡P
P◦
:≡!P,
for P atomic, P . ⊥
⊥∗
:≡0
⊥◦
:≡0
(A ∧B)∗
:≡A∗& B∗
(A ∧B)◦
:≡A◦⊗B◦
(A ∨B)∗
:≡!A∗⊕!B∗
(A ∨B)◦
:≡A◦⊕B◦
(A →B)∗
:≡!A∗⊸B∗
(A →B)◦
:≡!(A◦⊸B◦)
(∀xA)∗
:≡∀xA∗
(∀xA)◦
:≡!∀xA◦
(∃xA)∗
:≡∃x!A∗
(∃xA)◦
:≡∃xA◦
which satisfy the following: if IL ⊢A then ILL ⊢A∗and ILL ⊢A◦. Consider also the
following translation, which we denote by (·)lKo since it mimics the Kolmogorov
approach:
PlKo
:≡
!P, for P atomic
(A ∧B)lKo
:≡
!(AlKo ⊗BlKo)
(A ∨B)lKo
:≡
!(AlKo ⊕BlKo)
(A →B)lKo
:≡
!(AlKo ⊸BlKo)
(QA)lKo
:≡
!QAlKo,
for Q ∈{∀x, ∃x}.
One also has:
Proposition 21. If IL ⊢A then ILL ⊢AlKo.
This result, however, follows (as we are going to see throughout this section)
from the homologous results for (·)∗and (·)◦-translations. Not surprisingly, (·)lKo is

On the Relation Between Various Negative Translations
253
an unpolished translation, i.e. it is possible to simplify it by removing some bangs
while still maintaining an equivalent (over intuitionistic linear logic) embedding.
Mimicking the simpliﬁcations from outside of Sections 3 and 4, start with AlKo
and systematically remove, from outside to inside the formula, the exponential !
from all multiplicative conjunctions, disjunctions, existential quantiﬁcations and
before 0. Example: if !(!A⊗!B) appears in the formula we change it to !A⊗!B.
Lemma 22. The following equivalences are provable in ILL:
!0  0
!(!A⊗!B)  !A⊗!B
!(!A⊕!B)  !A⊕!B
!∃x!A  ∃x!A.
It is easy to see that with the previous strategy we obtain exactly Girard’s em-
bedding A◦. Once we notice that AlKo  !AlKo and ILL ⊢!(!A⊗!B)  !(!A & !B),
we realise that in (·)lKo we can deﬁne the translation of A ∧B by !(AlKo & BlKo).
On the other hand, mimicking the simpliﬁcations from inside, start with AlKo
and systematically remove, from inside to outside the formula, the exponential !
from all additive conjunctions, universal quantiﬁcations and in the consequent of
the implications. Example: if !(!A & !B) appears in the formula we change it to
!(A & B). The next lemma justiﬁes this approach:
Lemma 23. The following equivalences are provable in ILL:
!(!A & !B)  !(A & B)
!(!A ⊸!B)  !(!A ⊸B)
!∀x!A  !∀xA.
Again, it is easy to see that applying the strategy above to AlKo we obtain exactly
!A∗.
7.4
Other related work
Strong monads. Part of the present study could have been developed in a more
general context, as done in [5]. Let T be a (logical operator having the proper-
ties of a) strong monad and consider the translation (·)T that inserts T in the be-
ginning of each subformula. Assuming that (TA)T ↔TAT what we obtain is a
translation of ML + (TA →A) into ML. We name such embedding Kolmogorov

254
Gilda Ferreira and Paulo Oliva
T-translation. It can be seen that all the transformations in simpliﬁcations ˜r1 and r3
remain valid equivalences in ML when we replace ¬¬ by any strong monad T. Thus,
from Kolmogorov T-translation we can obtain, by means of the previous simpliﬁ-
cations, the corresponding Kuroda (non-maximal ML variant) and G¨odel-Gentzen
T-translations. As particular cases we have
• TA :≡¬¬A (recovering the standard double-negation translations),
• TB :≡(B →A) →A (corresponding to Friedman A-translations [7]),
• TA :≡¬A →A or TA :≡(A →R) →A (Peirce translations [5]).
As references on these more general embeddings see [1, 5].
Semantical approaches. In this paper we did not discuss semantical approaches
to the negative translations. Some considerations concerning conversions between
Heyting and Boolean algebras whose valuation of formulas is related via negative
translations can be found in [14, 27] and more abstract treatment of negative trans-
lations in terms of categorical logic can be found in [17].
Other “metrics”. The key ingredient to establish a partial order between negative
translations here is the notion of a simpliﬁcation. The deﬁnition of simpliﬁcation
used throughout this study is based on the counting of the total number of impli-
cations involved in a formula. More sophisticated “metrics” could be tried in the
future, for instance one that instead of just counting implications could be sensible
to the “nesting” eﬀect. For instance, an immediate consequence of considering the
“nesting” of implications would be that r4 would no longer be a simpliﬁcation. No-
tice that the transformation ¬(¬¬A∧¬¬B)
r4⇒¬¬A →¬B, would have depth three
on both the left and the right-hand sides.
Translations from CL to CLL. Although not addressed in this paper, we could try
to adapt the notion of simpliﬁcation to translations from classical logic into clas-
sical linear logic. As future work we intend to focus in this question not only to
capture and motivate standard translations such as Girard ?!-translation [11], but to
see which new translations could be revealed with this approach.
CPS transformations.
There is a close connection between negative transla-
tions and continuation passing style (CPS) transformations.
In the literature
[8, 15, 26, 32], we can ﬁnd various CPS-translations from λµ-calculus into λ-
calculus that correspond (at the type level) to the standard negative translations.
Note that the CPS technique captures evaluation ordering for the source lan-
guage, such as call-by-name, call-by-value or call-by-need. The two schemes be-
low sketch how Kolmogorov negative translation (·)Ko simulates call-by-name in

On the Relation Between Various Negative Translations
255
a call-by-value interpreter and Kuroda negative translation (·) ˜Ku simulates call-by-
value in a call-by-name interpreter. Consider ﬁrst the proof-tree of the soundness
for Kolmogorov translation of the cut rule
[AKo →BKo]: α
AKo: N
BKo: αN
[¬B∗]: k
⊥: αNk
¬(AKo →BKo): λα.αNk
¬¬(AKo →BKo): M
⊥: M(λα.αNk)
¬¬B∗: λk.M(λα.αNk)
where (A →B)Ko :≡¬¬(AKo →BKo) and B∗is such that BKo ≡¬¬B∗. If the strat-
egy used is call-by-value the term N which proves A would be ﬁrst evaluated and
then passed to the function M which proves A →B. After the Kolmogorov trans-
lation, however, N (the proof of A) is encapsulated into a λ-term in head normal
form. That then forces the evaluation of M (the proof of A →B) instead, hence,
simulating call-by-name.
On the other hand, consider the proof-tree of the soundness of the Kuroda trans-
lation of the cut rule
[A ˜Ku]: a
[A ˜Ku →¬¬B ˜Ku]: α
¬¬B ˜Ku: αa
[¬B ˜Ku]: k
⊥: αak
¬A ˜Ku: λa.αak
¬¬A ˜Ku: N
⊥: N(λa.αak)
¬(A ˜Ku →¬¬B ˜Ku): λα.N(λa.αak)
¬¬(A ˜Ku →¬¬B ˜Ku) : M
⊥: M(λα.N(λa.αak))
¬¬B ˜Ku : λk.M(λα.N(λa.αak))
where (A →B) ˜Ku :≡¬¬(A →B) ˜Ku :≡¬¬(A ˜Ku →¬¬B ˜Ku) is the Kuroda neg-
ative translation presented on Section 6. In a call-by-name setting the proof of
A →B would be the ﬁrst to be evaluated. In order to force the argument (the proof
of A) to be evaluated ﬁrst the Kuroda translation puts N (the proof of the translation
of A) in the function position with input λa.αak. That forces the evaluation of N
(the proof of A) ﬁrst, hence simulating call-by-value.
For more on this subject see [26] and Chapters 9 and 10 in [25]. It would
be interesting to see if our simpliﬁcations linking the standard negative trans-
lations can be expressed and are meaningful at the calculus reduction strategy level.

256
Gilda Ferreira and Paulo Oliva
References
[1] P. Aczel (2001): The Russel-Prawitz modality. Math. Structures Comput. Sci.
11(4), pp. 541–554.
[2] J. Avigad (2000): A realizability interpretation for Classical Arithmetic. In:
P H¨ajek S. R. Buss & P. Pudl¨ak, editors: Logic Colloquium’98, Lecture Notes
in Logic 13, AK Peters, pp. 57–90.
[3] J. Avigad (2006): A variant of the double-negation translation. Technical
Report 179, Carnegie Mellon Technical Report CMU-PHIL.
[4] J. Avigad & S. Feferman (1998): G¨odel’s functional (“Dialectica”) interpre-
tation. In: S. R. Buss, editor: Handbook of proof theory, Studies in Logic
and the Foundations of Mathematics 137, North Holland, Amsterdam, pp.
337–405.
[5] M. H. Escard´o & P. Oliva (2010): The Peirce Translation and the Double
Negation Shift. In: F. Ferreira, B. L¨owe, E. Mayordomo & L. M. Gomes,
editors: Programs, Proofs, Processes - CiE 2010, LNCS 6158, Springer, pp.
151–161.
[6] G. Ferreira & P. Oliva (2011): On various negative translations. In: Pro-
ceedings of Classical Logic and Computation 2010, Electronic Proceedings
in Theoretical Computer Science 47, EPTCS, pp. 21–33.
[7] H. Friedman (1978): Classically and intuitionistically provably recursive
functions. In: D. Scott & G. M¨uller, editors: Higher Set Theory, Lecture
Notes in Mathematics 669, Springer, Berlin, pp. 21–28.
[8] K. Fujita (1995): On embedding of classical substructural logics. In: Proc.
Theory of Rewriting Systems and Its Applications, Kyoto University 918,
RIMS, pp. 178–195.
[9] G. Gentzen (1933): Ueber das verh¨altnis zwischen intuitionistischer und klas-
sischer arithmetik, Galley proof (received in 1933). Mathematische Annalen.
[10] G. Gentzen (1936): Die Widerspruchsfreiheit der reinen Zahlentheorie. Math-
ematische Annalen 112, pp. 493–565.
[11] J.-Y. Girard (1987): Linear Logic. Theoretical Computer Science 50(1), pp.
1–102.

On the Relation Between Various Negative Translations
257
[12] K. G¨odel (1933): Zur intuitionistischen Arithmetik und Zahlentheorie. Ergeb-
nisse eines Mathematischen Kolloquiums 4, pp. 34–38.
[13] K. G¨odel (1958):
¨Uber eine bisher noch nicht ben¨utzte Erweiterung des
ﬁniten Standpunktes. Dialectica 12, pp. 280–287.
[14] K. G¨odel (1986): Introduction to paper “Zur intuitionistischen Arithmetik
und Zahlentheorie”. In: S. Feferman et al., editor: Collected Works, Vol. I,
Oxford University Press, Oxford, pp. 286–295.
[15] P. de Groote (1994): A CPS-Translation of the λµ-Calculus. In: S. Tison, ed-
itor: Proc. of the Colloquium on Trees in Algebra and Programming, Lecture
Notes in Computer Science 787, Springer-Verlag, pp. 85–99.
[16] A. Heyting (1946): On weakened quantiﬁcation. The Journal of Symbolic
Logic 11(4), pp. 119–121.
[17] J. M. E. Hyland (2002): Proof theory in the abstract. Annals of Pure and
Applied Logic 114, pp. 43–78.
[18] H. Ishihara (2000): A note on the G¨odel-Gentzen Translation. Mathematical
Logic Quarterly 46(1), pp. 135–137.
[19] S. C. Kleene (1952): Introduction to Metamathematics. D. Van Nostrand Co.,
Inc., New York, N. Y.
[20] U. Kohlenbach (2008): Applied Proof Theory: Proof Interpretations and their
Use in Mathematics. Monographs in Mathematics. Springer.
[21] A. N. Kolmogorov (1925): On the principle of the excluded middle (Russian).
Mat. Sb. 32, pp. 646–667.
[22] J. Krivine (1990): Op´erateurs de mise en m´emoire et traduction de G¨odel.
Arch. Math. Logic 30(4), pp. 241–267.
[23] S. Kuroda (1951):
Intuitionistische Untersuchungen der formalistischen
Logik. Nagoya Mathematical Journal 3, pp. 35–47.
[24] H. Luckhardt (1973): Extensional G¨odel Functional Interpretation: A Con-
sistency Proof of Classical Analysis, Lecture Notes in Mathematics 306.
Springer, Berlin.
[25] C. Murthy (1990): Extracting Constructive Content from Classical Proofs.
Ph.D. thesis, Cornell University.

258
Gilda Ferreira and Paulo Oliva
[26] G. D. Plotkin (1975): Call-by-name, Call-by-value and the λ-calculus. The-
oretical Computer Science 1, pp. 125–159.
[27] H. Rasiowa & R. Sikorski (1963): The mathematics of metamathematics.
Warsaw. PWN (Polish Scientiﬁc Publishers).
[28] H. Schwichtenberg (2006): Proof Theory-Notes for a lecture course, Som-
mersemester 2006.
Mathematisches Institut der Ludwig-Maximilians-
Iniversit¨at.
[29] M. Shirahata (2006): The Dialectica interpretation of ﬁrst-order classical lin-
ear logic. Theory and Applications of Categories 17(4), pp. 49–79.
[30] J. R. Shoenﬁeld (1967): Mathematical Logic. Addison-Wesley Publishing
Company.
[31] T. Streicher & U Kohlenbach (2007): Shoenﬁeld is G¨odel after Krivine. Math-
ematical Logic Quarterly 53, pp. 176–179.
[32] T. Streicher & B. Reus (1998): Classical logic, continuation semantics and
abstract machines. J. Funct. Prog. 8(6), pp. 543–572.
[33] A. S. Troelstra (1973):
Metamathematical Investigation of Intuitionistic
Arithmetic and Analysis, Lecture Notes in Mathematics 344. Springer, Berlin.
[34] A. S. Troelstra & H. Schwichtenberg (2000): Basic Proof Theory. Cambridge
University Press, Cambridge (2nd edition).
[35] A. S. Troelstra & D. van Dalen (1988): Constructivism in Mathematics. An In-
troduction, Studies in Logic and the Foundations of Mathematics 121. North
Holland, Amsterdam.

A Finite Axiomatisation of Inductive-Inductive
Deﬁnitions
Fredrik Nordvall Forsberg and Anton Setzer ∗
Induction-induction is a principle for mutually deﬁning data types A : Set and
B : A →Set. Both A and B are deﬁned inductively, and the constructors for
A can refer to B and vice versa. In addition, the constructor for B can refer
to the constructor for A. Induction-induction occurs in a natural way when
formalising dependent type theory in type theory. We give some examples of
inductive-inductive deﬁnitions, such as the set of surreal numbers. We then
give a new ﬁnite axiomatisation of the principle of induction-induction, and
prove its consistency by constructing a model.
1
Introduction
When using Martin-L¨of type theory [20] for programming and theorem proving,
one soon notices the need for more complex data types which are syntactically
closer to their intended meaning. Examples include indexing data types with ex-
tra information in order to express properties of their elements, or constructing a
universe in order to quantify over a large collection.
The programming language and proof assistant Agda [25] supports many such
data types, however without a complete theoretical foundation. The proof assistant
Coq [11], on the other hand, does not at present support some of the more advanced
data types that Agda does. With the current article, we wish to address both these
issues for a form of data type which we call inductive-inductive deﬁnitions, for
reasons that will become clear below. Inductive-inductive deﬁnitions have been
used by several researchers in diﬀerent areas – see Section 1.1 for some examples.
Let us now look at some examples of inductive deﬁnitions, such as the natural
numbers, lists, well-orderings, the identity set, ﬁnite sets, and a universe `a la Tarski.
These examples can be categorised as diﬀerent kinds of inductive deﬁnitions.
∗Both authors are supported by EPSRC grant EP/G033374/1, Theory and applications of induction-
recursion.

260
Fredrik Nordvall Forsberg and Anton Setzer
The ﬁrst few (up to well-orderings) are just ordinary inductive deﬁnitions,
where a single set is deﬁned inductively. A typical example is the type W(A, B)
of well-orderings, parameterised by A : Set, B : A →Set. The introduction rule
is:
a : A
f : B(a) →W(A, B)
sup(a, f) : W(A, B)
Here a : A is a non-inductive argument, whereas f : B(a) →W(A, B) is an induc-
tive argument because of the occurrence of W(A, B). Note how the later argument
depends on the earlier non-inductive argument.
The identity type and the ﬁnite sets are examples of inductive families, where
a family X : I →Set for some ﬁxed index set I is deﬁned inductively simultane-
ously [13]. For the family Fin : N →Set of ﬁnite sets, the index set is N, and we
have introduction rules
n : N
zn : Fin(n + 1)
n : N
m : Fin(n)
sn(m) : Fin(n + 1)
Thus the type Fin(n + 1) has n + 1 elements zn, sn(zn−1), sn(sn−1(zn−2)) up to
sn(sn−1(· · · s1(z0))). The type of the inductive argument m : Fin(n) of the sec-
ond rule has index n, which is diﬀerent from the index n + 1 of the type of the
constructed element. Thus the whole family has to be deﬁned simultaneously.
The universe `a la Tarski is an example of an inductive-recursive deﬁnition,
where a set U is deﬁned inductively together with a recursive function T : U →
Set [14]. The constructors for U may depend negatively on T applied to elements
of U, as is the case if U, for example, is closed under dependent function spaces:
a : U
b : T(a) →U
π(a, b) : U
with T(π(a, b)) = (x : T(a)) →T(b(x)).1
Here, T : U →Set is deﬁned recursively. Sometimes, however, one might not
want to give T(u) completely as soon as u : U is introduced, but instead deﬁne T
inductively as well. This is the principle of induction-induction. A set A is induc-
tively deﬁned simultaneously with an A-indexed set B, which is also inductively
deﬁned, and the introduction rules for A may also refer to B. Typical introduction
rules might take the form
a : A
b : B(a)
. . .
introA(a, b, . . .) : A
a0 : A
b : B(a0)
a1 : A
. . .
introB(a0, b, a1, . . .) : B(a1)
1The notation for the dependent function space and other type-theoretical constructs is explained in
Section 2.

A Finite Axiomatisation of Inductive-Inductive Definitions
261
Notice that this is not a simple mutual inductive deﬁnition of two sets, as B is
indexed by A. It is not an ordinary inductive family, as A may refer to B. Finally,
it is not an instance of induction-recursion, as B is constructed inductively, not
recursively (see Section 1.2 for the diﬀerence).
Coq does at present not support inductive-inductive deﬁnitions, whereas Agda
does, without a theoretical foundation. Working towards a justiﬁcation of Agda’s
inductive-inductive deﬁnitions, and an inclusion of such deﬁnitions in Coq, we give
a new ﬁnite axiomatisation of a type theory with inductive-inductive deﬁnitions.
It diﬀers from our earlier axiomatisation [24] in that it is ﬁnite, and is hopefully
easier to understand. The current article is also somewhat diﬀerent in scope from
our CALCO paper [5], which focuses on a categorical semantics and shows that
the elimination rules (not treated here) are equivalent to the initiality of certain
algebras.
Related work
Backhouse et. al. [7, 6] and Dybjer [13, 14] gave external schemas
for ordinary inductive sets, inductive families and inductive deﬁnitions, which later
Dybjer and Setzer [15, 16, 17] internalised. This is where we take most of our
inspiration from. Recently, Ghani and Hancock [18] have shed new light on this
construction.
The idea of a universe of data types is also present in Epigram 2 [9], and has
previously been used by Altenkirch, Ghani, Morris and McBride to study strictly
positive types [23] and strictly positive families [22] (see also Morris’ thesis [21]).
Here data types are given a more semantic account via the theory of containers [1]
and indexed containers [4].
1.1
Examples of inductive-inductive deﬁnitions
In this section, we give some examples of inductive-inductive deﬁnitions, starting
with the perhaps most important one:
Example 1 (Contexts and types). Danielsson [12] and Chapman [8] model the
syntax of dependent type theory in the theory itself by inductively deﬁning contexts,
types (in a given context) and terms (of a given type). To see the inductive-inductive
nature of the construction, it is enough to concentrate on contexts and types.
Informally, we have an empty context ε, and if we have any context Γ and a
valid type σ in that context, then we can extend the context with a fresh variable
x : σ to get a new context Γ, x : σ. This is the only way contexts are formed. We
end up with the following inductive deﬁnition of the set of contexts (with Γ ▷σ

262
Fredrik Nordvall Forsberg and Anton Setzer
meaning Γ, x : σ since we are using de Bruijn indices):
ε : Ctxt
Γ : Ctxt
σ : Ty(Γ)
Γ ▷σ : Ctxt
Moving on to types, we have a base type ι (valid in any context) and dependent
function types: if σ is a type in context Γ, and τ is a type in Γ, x : σ (x is the
variable from the domain), then Π(σ, τ) is a type in the original context. This leads
us to the following inductive deﬁnition of Ty : Ctxt →Set:
Γ : Ctxt
ιΓ : Ty(Γ)
Γ : Ctxt
σ : Ty(Γ)
τ : Ty(Γ ▷σ)
ΠΓ(σ, τ) : Ty(Γ)
Note that the deﬁnition of Ctxt refers to Ty, so both sets have to be deﬁned
simultaneously. Note also how the introduction rule for Π explicitly focuses on a
speciﬁc constructor in the index of the type of τ.
■
Often, one wishes to deﬁne a set A where all elements of A satisfy some prop-
erty P : A →Set. If P is inductively deﬁned, one can deﬁne A and P simultane-
ously and achieve that every element of A satisﬁes P by construction. One example
of such a data type is the type of sorted lists:
Example 2 (Sorted lists). Let us deﬁne a data type consisting of sorted lists (of
natural numbers, say). With induction-induction, we can simultaneously deﬁne the
set SortedList of sorted lists and the predicate ≤L: (N × SortedList) →Set with
n ≤L ℓtrue if n is less than or equal to every element of ℓ.
The empty list is certainly sorted, and if we have a proof p that n is less than or
equal to every element of the list ℓ, we can put n in front of ℓto get a new sorted
list cons(n, ℓ, p). Translated into introduction rules, this becomes:
nil : SortedList
n : N
ℓ: SortedList
p : n ≤L ℓ
cons(n, ℓ, p) : SortedList
For ≤L, we have that every m : N is trivially smaller than every element of the
empty list, and if m ≤n and inductively m ≤L ℓ, then m ≤L cons(n, ℓ, p):
trivm : m ≤L nil
q : m ≤n
pm,ℓ: m ≤L ℓ
≪q, pm,ℓ≫: m ≤L cons(n, ℓ, p)
This makes sense even if the order ≤is not transitive. If it is (as the standard order
on the natural numbers is, for example), the argument pm,ℓ: m ≤L ℓcan be dropped
from the constructor ≪· ≫, since we already have q : m ≤n and p : n ≤L ℓ, hence
by transitivity we must have m ≤L ℓ.

A Finite Axiomatisation of Inductive-Inductive Definitions
263
Of course, there are also many alternative ways to deﬁne such a data type using
ordinary induction (or using e.g. induction-recursion, similarly to C. Coquand’s
deﬁnition of fresh lists as reported by Dybjer [14]).
■
Example 3 (Conway’s surreal numbers). Conway [10] informally uses induction-
induction (but couched in ZF set theory, not type theory) in order to deﬁne his
surreal numbers. The class 2 of surreal numbers is deﬁned inductively, together
with an order relation on surreal numbers which is also deﬁned inductively:
• A surreal number X = (XL, XR) consists of two sets XL and XR of surreal
numbers, such that no element from XL is greater than any element from XR.
• A surreal number Y = (YL, YR) is greater than another surreal number X =
(XL, XR), X ≤Y, if and only if
– there is no x ∈XL such that Y ≤x, and
– there is no y ∈YR such that y ≤X.
Both rules can be understood as inductive deﬁnitions. Notice how the second
deﬁnition only makes sense in the presence of the ﬁrst deﬁnition, and how the ﬁrst
deﬁnition already refers to the second.
As an inductive deﬁnition, the negative occurrence of ≤in the deﬁnition of
the class of surreal numbers is problematic. We can get around this by simultane-
ously deﬁning the class Surreal : Set together with two relations ≤: Surreal →
Surreal →Set and ≰: Surreal →Surreal →Set as follows:
• If XL and XR are sets of surreal numbers, and for all x ∈XL, y ∈XR we have
x ≰y, then (XL, XR) is a surreal number.
• Assume X = (XL, XR) and Y = (YL, YR) are surreal numbers. If
– for all x ∈XL we have Y ≰x, and
– for all y ∈YR we have y ≰X,
then X ≤Y.
• Assume X = (XL, XR) and Y = (YL, YR) are surreal numbers.
– If there exist x ∈XL such that Y ≤x, then X ≰Y.
– If there exist y ∈YR such that y ≤X, then X ≰Y.
2The surreal numbers form a class, not a set, since they contain the class of ordinals. This can be
avoided by referring to a universe.

264
Fredrik Nordvall Forsberg and Anton Setzer
We see that Surreal : Set together with ≤, ≰: Surreal →Surreal →Set are deﬁned
inductive-inductively.
Mamane [19] develops the theory of surreal numbers in the proof assistant Coq,
using an encoding to reduce the inductive-inductive deﬁnition to an ordinary induc-
tive one.
■
Note that these examples strictly speaking refer to extensions of inductive-
inductive deﬁnitions as presented in this article. Example 1 in full would be an ex-
ample of a deﬁning of a telescope A : Set, B : A →Set, C : (x : A) →B(x) →Set,
...inductive-inductively. In Example 2, A : Set and B : A →I →Set for some
previously deﬁned set I is deﬁned, and Example 3 gives an inductive-inductive def-
inition of A : Set, B, B′ : A →A →Set. In the future, we plan to publish an
axiomatisation which captures all these examples in full. For pedagogical reasons,
we think it is preferable to ﬁrst only treat the simpler case A : Set, B : A →Set as
in the current article.
1.2
Inductive-inductive deﬁnitions versus inductive-recursive def-
initions
In both an inductive-inductive and an inductive-recursive deﬁnition, a set U and
a family T : U →Set are deﬁned simultaneously. The diﬀerence between the
two principles is how T is deﬁned: inductively or recursively. We discuss in the
following ﬁrst the diﬀerence between an inductive and a recursive deﬁnition. To
exemplify this diﬀerence, consider the following two deﬁnitions of a data type
Nonempty : N →Set of non-empty lists of a certain length (with elements from a
set A):
Inductive deﬁnition The singleton list [a] has length 1, and if a is an element, and
the list ℓhas length n, then cons(a, ℓ) is a list of length n+1. As an inductive
deﬁnition, this becomes
a : A
[a] : Nonemptyind(1)
a : A
ℓ: Nonemptyind(n)
cons(a, ℓ) : Nonemptyind(n + 1)
Notice that there is no constructor which constructs elements in the set
Nonemptyind(0).
Recursive deﬁnition If the recursive deﬁnition of the data type, we deﬁne the set

A Finite Axiomatisation of Inductive-Inductive Definitions
265
Nonemptyrec(n) for every natural number:
Nonemptyrec(0) = 0
Nonemptyrec(1) = A
Nonemptyrec(n + 2) = A × Nonemptyrec(n + 1)
In the recursive deﬁnition, Nonemptyrec(k) is deﬁned in one go, whereas the
inductively deﬁned Nonemptyind(k) is built up from below. In order to prove that
the instance Nonemptyind(0) of the inductive deﬁnition is empty, one has to carry
out a proof by induction over Nonemptyind.
This diﬀerence is now carried over to an inductive-recursive/inductive-inductive
deﬁnition of U : Set, T : U →Set. In an inductive-inductive deﬁnition, T is
generated inductively, i.e. given by a constructor introT : (x : F(U, T)) →T(i(x))
for some (strictly positive) functor F. In an inductive-recursive deﬁnition, on the
other hand, T is deﬁned by recursion on the way the elements of U are generated.
This means that T(introU(x)) must be given completely as soon as the constructor
introU : G(U, T) →U is introduced.
There are some practical diﬀerences between the two approaches.
An
inductive-inductive deﬁnition gives more freedom to describe the data type, in the
sense that many diﬀerent constructors for T can contribute to the set T(introU(x)).
However, because of the inductive generation of T, T can only occur positively in
the type of the constructors for U (and T), whereas T can occur also negatively in
an inductive-recursive deﬁnition.
2
Type-theoretical preliminaries
We work in a type theory with at least two universes Set and Type, with Set : Type
and Set a subuniverse of Type, i.e. if A : Set then A : Type. Both Set and Type
are closed under dependent function types, written (x : A) →B, where B is a set or
type depending on x : A. Abstraction is written as λx : A.e, where e : B depending
on x : A, and application as f(x). Repeated abstraction and application are written
as λx1 : A1 . . . xk : Ak.e and f(x1, . . . , xk). If the type of x can be inferred, we
simply write λx.e as an abbreviation. Furthermore, both Set and Type are closed
under dependent products, written (x : A) × B, where B is a set or type depending
on x : A, with pairs ⟨a, b⟩, where a : A and b : B[x B a]. We also have β- and
η-rules for both dependent function types and products.
We add an empty type 0 : Set, with elimination !A : 0 →A for every A : Set
(we will write ! for !A if A can be inferred from the context). We also add a unit
type 1 : Set, with unique element ⋆: 1 and an η-rule stating that if x : 1, then

266
Fredrik Nordvall Forsberg and Anton Setzer
x = ⋆: 1. Moreover, we include a two element set 2 : Set, with elements tt : 2,
ff : 2 and elimination constant if · then · else · : (a : 2) →A(tt) →A(ff) →
A(a) where i : 2 ⇒A(i) : Type. It satisﬁes the obvious computation rules, i.e.
if tt then a else b = a and if ff then a else b = b.
With if ·
then ·
else · and dependent products, we can now deﬁne the
disjoint union of two sets A + B B (x : 2) × (if x then A else B) with con-
structors inl = λa : A.⟨tt, a⟩and inr = λb : B.⟨ff, b⟩, and prove the usual for-
mation, introduction, elimination and equality rules. Importantly, we get large
elimination for sums, since we have large elimination for 2. We can deﬁne the
eliminator [f, g] : (c : A + B) →C(c), where x : A + B ⇒C(x) : Type and
f : (a : A) →C(inl(a)), g : (b : B) →C(inr(b)), satisfying the deﬁnitional
equalities
[f, g](inl(a)) = f(a) ,
[f, g](inr(b)) = g(b) .
Intensional type theory in Martin-L¨of’s logical framework extended with de-
pendent products and 0, 1, 2 has all the features we need. Thus, our development
can be seen as an extension of the logical framework.
3
A ﬁnite axiomatisation
In this section, we give a ﬁnite axiomatisation of a type theory with inductive-
inductive deﬁnitions. This axiomatisation diﬀers slightly from our previous ax-
iomatisation [24], and is hopefully easier to understand. However, the deﬁnable
sets should be the same for both axiomatisations.
The main idea, following Dybjer and Setzer’s axiomatisation of inductive-re-
cursive deﬁnitions [15], is to construct a universe consisting of codes for inductive-
inductive deﬁnitions, together with a decoding function, which maps a code ϕ to
the domain of the constructor for the inductively deﬁned set represented by ϕ. We
will actually use two universes; one to describe the constructors for the index set A,
and one to describe the constructors of the second component B : A →Set. Just as
the constructors for B : A →Set can depend on the constructors for the ﬁrst set A,
the universe SP0
B : SP0
A →Type of codes for the second component will depend
on the universe SP0
A of codes for the ﬁrst.

A Finite Axiomatisation of Inductive-Inductive Definitions
267
3.1
Dissecting an inductive-inductive deﬁnition
We want to formalise and internalise an inductive-inductive deﬁnition given by
constructors
introA : ΦA(A, B) →A
and
introB : (x : ΦB(A, B, introA)) →B(θ(x))
for some ΦA(A, B) : Set, ΦB(A, B, introA) : Set and θ : ΦB(A, B, introA) →A.
Here, θ(x) is the index of introB(x), i.e. the element a : A such that introB(x) : B(a).
Not all expressions ΦA and ΦB give rise to acceptable inductive-inductive deﬁ-
nitions. It is well known, for example, that the theory easily becomes inconsistent
if A or B occur in negative positions in ΦA or ΦB respectively. Thus, we restrict our
attention to a class of strictly positive functors.
These are based on the following analysis of what kind of premises can occur
in a deﬁnition. A premise is either inductive or non-inductive. A non-inductive
premise consists of a previously constructed set K, on which later premises can
depend. An inductive premise is inductive in A or B. If it is inductive in A, it is of
the form K →A for some previously constructed set K. Premises inductive in B
are of the form (x : K) →B(i(x)) for some i : K →A.
If K = 1, we have the special case of a single inductive premise. In the case
of B-inductive arguments, the choice of i : 1 →A is then just a choice of a single
element a = i(⋆) : A so that the premise is of the form B(a).
3.2
The axiomatisation
We now give the formal rules for an inductive-inductive deﬁnition of A : Set,
B : A →Set. These consists of a set of rules for the universe SP0
A of descriptions
of the set A and its decoding function Arg0
A, a set of rules for the universe SP0
B and
its decoding function Arg0
B, and formation and introduction rules for A : Set, B :
A →Set deﬁned inductive-inductively by a pair of codes γA : SP0
A, γB : SP0
B(γA).
3.2.1
The universe SP0
A of descriptions of A
We introduce the universe of codes for the index set with the formation rule
Aref : Set
SPA(Aref) : Type
The set Aref should be thought of as the elements of A that we can refer to in the
code that we are deﬁning. To start with, we cannot refer to any elements in A, and

268
Fredrik Nordvall Forsberg and Anton Setzer
so we deﬁne SP0
A B SPA(0). After introducing an inductive argument a : A, we
can refer to a in later arguments, so that Aref will be extended to include a as well
for the construction of the rest of the code.
The introduction rules for SPA reﬂects the informal discussion in Section 3.1.
The rules are as follows (we suppress the global premise Aref : Set):
nil : SPA(Aref)
The code nil represents a trivial constructor c : 1 →A (a base case).
K : Set
γ : K →SPA(Aref)
non-ind(K, γ) : SPA(Aref)
The code non-ind(K, γ) represents a non-inductive argument x : K, with the rest of
the arguments given by γ(x).
K : Set
γ : SPA(Aref + K)
A-ind(K, γ) : SPA(Aref)
The code A-ind(K, γ) represents an inductive argument with type K →A, with
the rest of the arguments given by γ. Notice that γ : SPA(Aref + K), so that the
remaining arguments can refer to more elements in A (namely those introduced by
the inductive argument).
K : Set
hindex : K →Aref
γ : SPA(Aref)
B-ind(K, hindex, γ) : SPA(Aref)
Finally, the code B-ind(K, hindex, γ) represents an inductive argument with type (x :
K) →B(i(x)), where the index i(x) is determined by hindex, and the rest of the
arguments are given by γ.
Example 4. The constructor ▷: ((Γ : Ctxt) × Ty(Γ)) →Ctxt is represented by the
code
γ▷= A-ind(1, B-ind(1, λ(⋆: 1) .bΓ, nil)) ,
where bΓ = inr(⋆) is the representation of Γ in Aref = 0 + 1.
■
We now deﬁne the decoding function ArgA, which maps a code to the domain
of the constructor it represents. In addition to a set Xref and a code γ : SPA(Xref),
ArgA will take a set X and a family Y : X →Set as arguments to use as A and
B in the inductive arguments. These will later be instantiated by the sets deﬁned
inductive-inductively. We also require a function repX : Xref →X which we think

A Finite Axiomatisation of Inductive-Inductive Definitions
269
of as mapping a “referable” element to the element it represents in X. Thus, ArgA
has the following formation rule:
Xref : Set
γ : SPA(Xref)
X : Set
Y : X →Set
repX : Xref →X
ArgA(Xref, γ, X, Y, repX) : Set
Notice that if γ : SP0
A, i.e. if Xref = 0, then we can choose repX = !X : 0 →X
(indeed, extensionally, this is the only choice), so that we can deﬁne
Arg0
A : SP0
A →(X : Set) →(Y : X →Set) →Set
by Arg0
A(γ, X, Y) = ArgA(0, γ, X, Y, !X).
The deﬁnition of ArgA follows the informal description of what the diﬀerent
codes represent above3:
ArgA( , nil, , , ) = 1
ArgA( , non-ind(K, γ), , , ) = (x : K) × ArgA( , γ(x), , , )
ArgA(Xref, A-ind(K, γ), X, , repX) =
(j : K →X) × ArgA(Xref + K, γ, , , [repX, j])
ArgA( , B-ind(K, hindex, γ), , Y, repX) =
((x : K) →Y((repX ◦hindex)(x))) × ArgA( , γ, , , )
Example 5. Recall the code γ▷= A-ind(1, B-ind(1, λ(⋆: 1) . inr(⋆), nil)) for the
constructor ▷: ((Γ : Ctxt) × Ty(Γ)) →Ctxt. We have
Arg0
A(γ▷, Ctxt, Ty) = (Γ : 1 →Ctxt) × (1 →Ty(Γ(⋆))) × 1
which, thanks to the η-rules for 1, × and →, is isomorphic to the domain of ▷.
■
3.2.2
Towards descriptions of B
As we have seen in Example 1, it is important that the constructor introB for
the second set B : A →Set can refer to the constructor introA for the ﬁrst set
A. This means that inductive arguments might be of type B(introA(a)) for some
a : Arg0
A(γA, A, B)
or
even
B(introA(. . . introA . . . (a)))
for
some
a : Arg0
A(γA, . . . Arg0
A(γA, A, B) . . . , B′). Thus, we need to be able to represent such
indices in the descriptions of the constructor introB.
First, it is no longer enough to only keep track of the referable elements Xref
of X – we need to be able to refer to elements of B as well, since they could be
3For readability, we have replaced arguments which are simply passed on with “ ” in the recursive
call, and likewise on the left hand side if the argument is not used otherwise.

270
Fredrik Nordvall Forsberg and Anton Setzer
used as arguments to introA. We will represent the elements of Y we can refer to
by a set Yref, together with functions repindex : Yref →X and repY : (x : Yref) →
Y(repindex(x)) ; the function repindex gives the index of the represented element, and
repY the actual element.
We want to represent elements in Arg0
A(γA, X, Y). We claim that the elements
in Arg0
A(γA, Xref + Yref, [λx . 0, λx . 1]) are suitable for this purpose. To see this, ﬁrst
observe that we can deﬁne functions
f : Xref + Yref →X ,
g : (x : Xref + Yref) →[λx . 0, λx . 1](x) →Y(f(x))
by f = [repX, repindex] and g = [λx . !, λx ⋆. repY(x)]. Then, we can lift these
functions to a function
Arg0
A(γA, f, g) : Arg0
A(γA, Xref + Yref, [λx . 0, λx . 1]) →Arg0
A(γA, X, Y)
by observing that Arg0
A(γA) is functorial:
Lemma 6. For each γ : SP0
A, Arg0
A(γ) extends to a functor from families of sets to
sets, i.e. given f : X →X′ and g : (x : X) →Y(x) →Y′(f(x)), one can deﬁne
Arg0
A(γ, f, g) : Arg0
A(γ, X, Y) →Arg0
A(γ, X′, Y′).
Remark 7. In extensional type theory, one can also prove that Arg0
A(γ, f, g) :
Arg0
A(γ, X, Y) →Arg0
A(γ, X′, Y′) actually is a functor, i.e. that identities and com-
positions are preserved, but that will not be needed for the current development.
Proof. This is straightforward in extensional type theory. In intensional type theory
without propositional identity types, we have to be more careful. The function
Arg0
A(γ, f, g) is deﬁned by induction over γ. In order to do this, we need to refer
inductively to the case when Xref is no longer 0. Hence, we need to consider the
more general case where X, Y, X′, Y′, f and g have types as above, and Xref : Set,
repX : Xref →X, rep′
X : Xref →X′. One expects the equality f(repX(x)) = rep′
X(x)
to hold for all x : Xref. In order to avoid the use of identity types, we state this in a
form of Leibniz equality, specialised to the instance we actually need; we require a
term
p : (x : Xref) →Y′(f(repX(x))) →Y′(rep′
X(x)) .
Thus we deﬁne
ArgA(γ, f, g, p) : ArgA(Xref, γ, X, Y, repX) →ArgA(Xref, γ, X′, Y′, rep′
X)

A Finite Axiomatisation of Inductive-Inductive Definitions
271
by induction over γ:
ArgA(nil, f, g, p, ⋆) = ⋆
ArgA(non-ind(K, γ), f, g, p, ⟨k, y⟩) = ⟨k, ArgA(γ(k), f, g, p, y)⟩
ArgA(A-ind(K, γ), f, g, p, ⟨j, y⟩) = ⟨f ◦j, ArgA(γ, f, g, [p, λx . id], y)⟩
ArgA(B-ind(K, hindex, γ), f, g, p, ⟨j, y⟩) =
⟨λk . p(hindex(k), g(repX(hindex(k)), j(k))), ArgA(γ, f, g, p, y)⟩
Finally, we can deﬁne Arg0
A(γ, f, g) : Arg0
A(γ, A, B) →Arg0
A(γ, A′, B′) by
Arg0
A(γ, f, g) B ArgA(γ, f, g, !) .
□
Recall that we want to use the lemma to represent elements in Arg0
A(γA, X, Y)
by elements in Arg0
A(γA, Xref + Yref, [λx . 0, λx . 1]). We can actually do better, and
represent arbitrarily terms built from elements in X and Y with the use of a con-
structor
introA : Arg0
A(γA, X, Y) →X.
For
this,
deﬁne
the
set
A-Term(γA, Xref, Yref) of terms “built from introA, Xref and Yref” with introduction
rules
x : Xref
aref(x) : A-Term(γA, Xref, Yref)
x : Yref
bref(x) : A-Term(γA, Xref, Yref)
x : Arg0
A(γA, A-Term(γA, Xref, Yref), B-Term(γA, Xref, Yref))
arg(x) : A-Term(γA, Xref, Yref)
Here, B-Term(γA, Xref, Yref) : A-Term(γA, Xref, Yref) →Set is deﬁned by
B-Term(γA, Xref, Yref, aref(x))
=
0
B-Term(γA, Xref, Yref, bref(x))
=
1
B-Term(γA, Xref, Yref, arg(x))
=
0
Note that this is formally an inductive-recursive deﬁnition. The intuition behind the
deﬁnition of B-Term is that all elements of Y we know are represented in Yref, and
only in Yref.
All elements in A-Term(γA, Xref, Yref) represents elements in X, given that we
have a function introA : Arg0
A(γA, X, Y) →X and the elements of Xref and Yref
represents elements of X and Y respectively (i.e. we have repX : Xref →X, repindex :
Yref →X and repY : (x : Yref) →Y(repindex(x))). Formally, we can simultaneously

272
Fredrik Nordvall Forsberg and Anton Setzer
deﬁne the following two functions:
γA : SP0
A
introA : Arg0
A(γA, X, Y) →X
repX : Xref →X
repindex : Yref →X
repY : (x : Yref) →Y(repindex(x))
repA(. . .) : A-Term(γA, Xref, Yref) →X
repB(. . .) : (x : A-Term(γA, Xref, Yref)) →B-Term(γA, Xref, Yref, x) →Y(repA(. . . , x))
The deﬁnition of repA is straightforward. The interesting case is arg(x), where
we make use of the constructor introA, the functoriality of Arg0
A and the mutually
deﬁned repB:
repA(γA, introA, repX, repindex, repY, aref(x)) = repX(x)
repA(γA, introA, repX, repindex, repY, bref(x)) = repindex(x)
repA(γA, introA, repX, repindex, repY, arg(x)) =
introA(Arg0
A(γA, repA(. . .), repB(. . .), x))
The simultaneously deﬁned repB is very simple:
repB(γA, introA, repX, repindex, repY, aref(x), y) = !(y)
repB(γA, introA, repX, repindex, repY, bref(x), ⋆) = repY(y)
repB(γA, introA, repX, repindex, repY, arg(x), y) = !(y)
Example 8. We deﬁne some terms in A-Term(γ▷, Xref, Yref), where
γ▷= A-ind(1, B-ind(1, λ(⋆: 1) . inr(⋆), nil))
is the code for the constructor
▷:  (Γ : 1 →A) × (1 →B(Γ(⋆))) × 1 →A .
Suppose that we have ˆa : Xref with repX(ˆa) = a : A and ˆb : Yref with repindex(ˆb) = a
and repY(ˆb) = b : B(a). We then have
• aref(ˆa) : A-Term(γ▷, Xref, Yref) with repA(γ▷, ▷, . . . , ˆa) = a (so elements from
Xref are terms).
• bref(ˆb) : A-Term(γ▷, Xref, Yref) with repA(γ▷, ▷, . . . , bref(ˆb)) = a (so elements
from Yref are terms, representing the index of the element in B they represent).
Furthermore repB(γ▷, ▷, . . . , bref(ˆb), ⋆) = b.

A Finite Axiomatisation of Inductive-Inductive Definitions
273
• d
a, b B arg(⟨(λ ⋆. bref(ˆb)), ⟨(λ ⋆. ⋆), ⋆⟩⟩) : A-Term(γ▷, Xref, Yref) with
repA(γ▷, ▷, . . . , d
a, b) = (repindex(ˆb)) ▷(repY(ˆb)) = a ▷b .
■
3.2.3
The universe SP0
B of descriptions of B
We now introduce the universe SPB of descriptions for B. It has formation rule
Aref, Bref : Set
γA : SP0
A
SPB(Aref, Bref, γA) : Type
Again, we are interested in codes which initially do not refer to any elements and
deﬁne SP0
B : SP0
A →Type by SP0
B(γA) B SPB(0, 0, γA).
The introduction rules for SPB are similar to the ones for SPA. However, we
now need to specify an index for the codomain of the constructor, and indices for
arguments inductive in B can be arbitrary terms built up from introA and elements
we can refer to.
a : A-Term(γA, Aref, Bref)
nil(a) : SPB(Aref, Bref, γA)
The code nil(ba) represents a trivial constructor c : 1 →B(a) (a base case), where
the index a is encoded byba : A-Term(γA, Aref, Bref).
K : Set
γ : K →SPB(Aref, Bref, γA)
non-ind(K, γ) : SPB(Aref, Bref, γA))
The code non-ind(K, γ) represents a non-inductive argument x : K, with the rest of
the arguments given by γ(x).
K : Set
γ : SPB(Aref + K, Bref, γA)
A-ind(K, γ) : SPB(Aref, Bref, γA)
The code A-ind(K, γ) represents an inductive argument with type K →A, with the
rest of the arguments given by γ.
K : Set
hindex : K →A-Term(Aref, Bref, γA)
γ : SPB(Aref, Bref + K, γA)
B-ind(K, hindex, γ) : SPB(Aref, Bref, γA)
At last, the code B-ind(K, hindex, γ) represents an inductive argument with type (x :
K) →B(i(x)), where the index i(x) is determined by hindex, and the rest of the
arguments are given by γ. Notice how the index is now encoded by arbitrary terms
in A-Term(Aref, Bref, γA).

274
Fredrik Nordvall Forsberg and Anton Setzer
Example 9. The constructor
Π :  (Γ : Ctxt) × (σ : Ty(Γ)) × Ty(Γ ▷σ) →Ty(Γ)
is represented by the code
γΠ = A-ind(1, B-ind(1, λ ⋆.bΓ, B-ind(1, λ ⋆.
[
in⟨Γ, σ⟩, nil(bΓ))))
where bΓ = aref(inr(⋆)) is the element representing the ﬁrst argument Γ : Ctxt and
[
in⟨Γ, σ⟩= arg(⟨(λ ⋆.bref(inr(⋆))), ⟨λ ⋆.⋆, ⋆⟩⟩) is the element representing Γ ▷σ.
■
The deﬁnition of ArgB should now not come as a surprise. First, we have a
formation rule:
γA : SP0
A
Xref, Yref : Set
γ : SPB(Xref, Yref, γA)
X : Set
Y : X →Set
introA : ArgA(γA, X, Y) →X
repX : Xref →X
repindex : Yref →X
repY : (x : Yref) →Y(repindex(x))
ArgB(Xref, Yref, γA, X, Y, introA, repX, repindex, repY, γ) : Set
The deﬁnition can be simpliﬁed for codes in SP0
B(γA):
Arg0
B(γA, X, Y, introA, γ) B ArgB(0, 0, γA, X, Y, introA, !, !, !, γ)
We deﬁne4:
ArgB( , , , , , , , , , nil(a)) = 1
ArgB( , , , , , , , , , non-ind(K, γ)) = (x : K) × ArgB( , , , , , , , , , γ(x))
ArgB(Xref, , , X, , , repX, , , A-ind(K, γ))
= (j : K →X) × ArgB(Xref + K, , , , , , [repX, j], , , γ)
ArgB( , Yref, γA, , Y, introA, repX, repindex, repY, B-ind(K, hindex, γ))
= (j : (x : K) →Y((repA(γA, introA, repX, repindex, repY) ◦hindex)(x))) ×
ArgB( , Yref + K, , , , , , [repindex, repA(. . .) ◦hindex], [repY, j], γ)
Finally, we need the function Index0
B(. . .) : ArgB(γA, γB, X, Y, introA) →X
which to each b : ArgB(γA, γB, X, Y, introA) assigns an index a : X such that the
element constructed from b is in Y(a).
γA : SP0
A
Xref, Yref : Set
γ : SPB(Xref, Yref, γA)
X : Set
Y : X →Set
introA : ArgA(γA, X, Y) →X
repX : Xref →X
repindex : Yref →X
repY : (x : Yref) →Y(repindex(x))
IndexB(Xref, Yref, γA, X, Y, introA, repX, repindex, repY, γ) : ArgB(. . .) →X
4Once again, we have for readability replaced arguments which are simply passed on with “ ” in the
recursive call, and likewise on the left hand side if the argument is not used otherwise.

A Finite Axiomatisation of Inductive-Inductive Definitions
275
For codes in SP0
B(γA), we deﬁne Index0
B : Arg0
B(γA, X, Y, introA, γB) →X by
Index0
B(γA, X, Y, introA, γB) B IndexB(0, 0, γA, X, Y, introA, !, !, !, γB).
The equations by neccessity follows the same pattern as the equations for ArgB.
For the base case γB = nil(a), we use repX(. . . , a), and for the other cases, we just
do a recursive call5
IndexB( , , γA, , , introA, repX, repindex, repY, nil(a), ⋆)
= repA(γA, introA, repX, repindex, repY, a)
IndexB( , , , , , , , , , non-ind(K, γ), ⟨k, y⟩)
= IndexB( , , , , , , , , , γ(k), y)
IndexB(Xref, , , X, , , repX, , , A-ind(K, γ), ⟨j, y⟩)
= IndexB(Xref + K, , , , , , [repX, j], , , γ, y)
IndexB( , Yref, γA, , Y, introA, repX, repindex, repY, B-ind(K, hindex, γ), ⟨j, y⟩)
= IndexB( , Yref + K, , , , , , [repindex, repA(. . .) ◦hindex], [repY, j], γ, y)
Example 10. The constructor Π :  (Γ : Ctxt) × (σ : Ty(Γ)) × Ty(Γ ▷σ) →Ty(Γ)
from Example 1 is represented by the code
γΠ = A-ind(1, B-ind(1, (λ ⋆.bΓ), B-ind(1, (λ ⋆. [
Γ ▷σ, nil(bΓ))))) : SP0
B(γ▷) ,
where bΓ = aref(inr(⋆)) : A-Term(0 + 1, 0, γ▷) and
[
Γ ▷σ = arg(⟨(λ ⋆.bref(inr(⋆))), ⟨λ ⋆.⋆, ⋆⟩⟩) : A-Term(0 + 1, 0 + 1, γ▷) .
We have
Arg0
B(γ▷, Ctxt, Ty, ▷, γΠ) =
(Γ : 1 →Ctxt) × (σ : 1 →Ty(Γ(⋆))) × (1 →Ty(Γ(⋆) ▷σ(⋆)) × 1
and Index0
B(γ▷, Ctxt, Ty, ▷, γΠ, ⟨Γ, σ, τ, ⋆⟩) = Γ(⋆).
■
3.2.4
Formation and introduction rules
We are now ready to give the formation and introduction rules for A and B. They
all have the common premises γA : SP0
A, γB : SP0
B(γA), which will be omitted.
Formation rules:
AγA,γB : Set
BγA,γB : AγA,γB →Set
5Simply passed on and otherwise not used arguments have been replaced with “ ” for readability.

276
Fredrik Nordvall Forsberg and Anton Setzer
Introduction rule for AγA,γB:
a : Arg0
A(γA, AγA,γB, BγA,γB)
introAγA,γB (a) : AγA,γB
Introduction rule for BγA,γB:
a : Arg0
B(γA, AγA,γB, BγA,γB, introAγA,γB , γB)
introBγA,γB (a) : BγA,γB(Index0
B(γA, AγA,γB, BγA,γB, introAγA,γB , γB, a))
3.2.5
Elimination rules by example
Elimination rules can also be formulated [5]. Here, we just give the elimination
rules for the data type of sorted lists (Example 2) as an example, and show how one
can use them to deﬁne a function which inserts a number into a sorted list.6
Example 11. The elimination rules for sorted lists and the ≤L predicate state that
functions elimSortedList and elim≤L with the following types exist:
elimSortedList : (P : SortedList →Set) →
(Q : (n : N) →(ℓ: SortedList) →n ≤L ℓ→P(ℓ) →Set) →
(stepnil : P(nil)) →
 stepcons : (n : N) →(ℓ: SortedList) →(p : n ≤L ℓ) →(eℓ: P(ℓ))
→Q(n, ℓ, p,eℓ) →P(cons(n, ℓ, p)) →
 steptriv : (m : N) →Q(m, nil, trivn, stepnil) →
 step≪·≫: (m : N) →(n : N) →(ℓ: SortedList) →(p : n ≤L ℓ)
→(q : m ≤n) →(p′ : m ≤L ℓ) →(eℓ: P(ℓ))
→(ep : Q(n, ℓ, p,eℓ)) →(ep′ : Q(m, ℓ, p′,eℓ))
→Q(m, cons(n, ℓ, p), ≪q, p′ ≫, stepcons(n, ℓ, p,eℓ, ep)) →
(ℓ: SortedList) →P(ℓ) ,
6The inductive-inductive deﬁnition of the data type of sorted lists falls outside the axiomatisation
presented in this article, as remarked at the end of Section 1.1. We still include this example, as it shows
the use of elimination rules in a real computer science example.

A Finite Axiomatisation of Inductive-Inductive Definitions
277
elim≤L : (P : SortedList →Set) →
(Q : (n : N) →(ℓ: SortedList) →n ≤L ℓ→P(ℓ) →Set) →
(stepnil : . . .) →
 stepcons : . . .  →
 steptriv : . . .  →
 step≪·≫: . . .  →
(n : N) →(ℓ: SortedList) →(p : n ≤L ℓ)
→Q(n, ℓ, p, elimSortedList(. . . , ℓ)) .
with computation rules
elimSortedList(P, Q, stepnil, stepcons, steptriv, step≪·≫, nil) = stepnil
and
elimSortedList(P, Q, stepnil, stepcons, steptriv, step≪·≫, cons(n, ℓ, p))
= stepcons(n, ℓ, p, elimSortedList(. . . , ℓ), elim≤L(. . . , n, ℓ, p))
for elimSortedList, and
elim≤L(P, Q, stepnil, stepcons, steptriv, step≪·≫, m, nil, trivm) = steptriv(m)
and
elim≤L(P, Q, stepnil, stepcons, steptriv, step≪·≫, m, cons(n, ℓ, p), ≪q, p′ ≫)
= step≪·≫(m, n, ℓ, p, q, p′, elimSortedList(. . . , ℓ),
elim≤L(. . . , n, ℓ, p), elim≤L(. . . , m, ℓ, p′))
for elim≤L. Notice how the computation rules for elim≤L are well-typed because of
the computation rules for elimSortedList.
Now, suppose that we want to deﬁne a function insert : SortedList →N →
SortedList which inserts a number m into its appropriate place in a sorted list ℓto
create a new sorted list. From a high-level perspective, this is easy: the elimination
rules allows us to make case distinctions between empty and non-empty lists, so it
suﬃces to handle these two cases separately. The empty list is easy to handle, and
for non-empty lists, we compare m with the ﬁrst element n of the list ℓ= [n, . . .],
which is possible since ≤on natural numbers is decidable. If m ≤n, the result
should be [m, n, . . .], otherwise we recursively insert m into the tail of the list.
In detail, we choose P(ℓ) = N →SortedList and, in our ﬁrst attempt,
we choose Q(n, ℓ, p,eℓ) = 1, since we are only interested in getting a function

278
Fredrik Nordvall Forsberg and Anton Setzer
elimSortedList(. . .) : SortedList →N →SortedList. We need to give functions
stepnil : (m : N) →SortedList and stepcons(n, ℓ, p) : (eℓ: N →SortedList) →
Q(n, ℓ, p,eℓ) →(m : N) →SortedList to use when inserting into the empty list
or the list cons(n, ℓ, p) respectively. The argument eℓ: N →SortedList gives the
result of a recursive call on ℓ.
The function stepnil is easy to deﬁne: it should be
stepnil(m) = cons(m, nil, trivm)
For stepcons, the decidability of ≤(combined with the fact that ≤is total) allows us
to distinguish between the cases when m ≤n and n ≤m, and we are entitled to a
proof q : m ≤n or q : n ≤m of this fact. We try:
stepcons(n, ℓ, p,eℓ, ⋆, m)
=

cons(m, cons(n, ℓ, p), ≪q, tra≤L(q, p) ≫)
where q : m ≤n
cons(n,eℓ(m), {?} )
where q : n ≤m
Here, tra≤L : m ≤n →n ≤L ℓ→m ≤L ℓwitnesses a kind of transitivity of ≤and
≤L. It can be straightforwardly deﬁned with the elimination rules. The question is
what we should ﬁll the hole {?} with. We need to provide a proof that n ≤L el(m),
i.e. that n ≤L insert(l, m) if we remember thatel is the result of the recursive call on
ℓ. We need to prove this simultaneously as we deﬁne insert! Fortunately, this is
exactly what the elimination rules allow us to do if we choose a more meaningful
Q.
Thus, we try again, but this time with
Q(n, ℓ, p,eℓ) = (m : N) →n ≤m →n ≤L el(m) .
The argument ⋆: 1 to stepcons in our ﬁrst attempt has now been replaced with the
argument ep : (m : N) →n ≤m →n ≤L el(m), and we can deﬁne
stepcons(n, ℓ, p,eℓ, ep, m)
=

cons(m, cons(n, ℓ, p), ≪q, tra≤L(q, p) ≫)
where q : m ≤n
cons(n,eℓ(m), ep(m, q))
where q : n ≤m
Now we must also deﬁne steptriv : (n : N) →Q(n, nil, trivn, stepnil) and step≪·≫
with type as above for our choice of P and Q. This presents us with no further
diﬃculties. For steptriv, expanding Q(n, nil, trivn, stepnil) and replacing steptriv with
its deﬁnition, we see that we should give a function of type
steptriv : (n : N) →(m : N) →n ≤m →n ≤L cons(m, nil, trivm) ,

A Finite Axiomatisation of Inductive-Inductive Definitions
279
so we can deﬁne steptriv(n, m, p) =
≪p, trivn ≫. The deﬁnition of step≪·≫
follows the pattern of stepcons above. Rather than trying to explain it, we just give
the deﬁnition:
step≪·≫(m, n, ℓ, p, q, p′,eℓ, ep, ep′, x, r) =

≪r, ≪q, p′ ≫≫
where s : m ≤n
≪q, ep′(x, r) ≫
where s : n ≤m
With all pieces in place, we can now deﬁne insert : SortedList →N →SortedList
as insert = elimSortedList(P, Q, stepnil, stepcons, steptriv, step≪·≫).
■
3.3
The examples revisited
We show how to ﬁnd γA, γB for some well-known sets, including the examples in
Section 1.1.
3.3.1
Encoding multiple constructors into one
The theory we have presented assumes that both A and B have exactly one con-
structor each. This is no limitation, as multiple constructors can always be encoded
into one by using non-inductive arguments. Suppose that intro0 : F0(A, B) →A
and intro1 : F1(A, B) →A are two constructors for A. Then we can combine them
into one constructor
intro0+1 :  (i : 2) × Fi(A, B) →A
by deﬁning intro0+1(i, x) = introi(x).
If intro0 is described by the code γ0 and intro1 by γ1, then intro0+1 is described
by the code
γ0 +SP γ1 B non-ind(2, λx.if x then γ0 else γ1) .
3.3.2
Examples of codes for inductive-inductive deﬁnitions
Well-orderings Ordinary inductive deﬁnitions can be interpreted as inductive-in-
ductive deﬁnitions where we only care about the index set A and not about
the family B : A →Set. A canonical choice is to let B have construc-
tor introB : (x : A) →B(x), which is described by the code γdummy B
A-ind(1, nil(aref(inr(⋆))))7.
For every A : Set, B : A →Set, let
γW(A,B) B non-ind(A, λx . A-ind(B(x), nil))
7Another choice is γdummy = non-ind(0, !SP0
B(γA)), which makes B(x) an empty type.

280
Fredrik Nordvall Forsberg and Anton Setzer
and deﬁne W(A, B) B AγW(A,B),γdummy. Then W(A, B) has constructor
introW(A,B) :  (x : A) × (B(x) →W(A, B)) × 1 →W(A, B) .
Finite sets Also indexed inductive deﬁnitions can be interpreted as inductive-
inductive deﬁnitions, namely those where the index set just is an isomorphic
copy of a previously constructed set (i.e. with constructor introA : I →A for
some I : Set).
For the family Fin : N →Set of ﬁnite sets, the index set is N, so we deﬁne
γA B non-ind(N, λn . nil) : SP0
A
and
γFin B γz +SP γs : SP0
B(γA)
where
γz B non-ind(N, λn . nil(arg(⟨n + 1, ⋆⟩))) ,
γs B non-ind(N, λn . B-ind(1, (λ ⋆.arg(⟨n, ⋆⟩)), nil(arg(⟨n + 1, ⋆⟩)))) .
Then the constructor introAγA,γFin : N × 1 →AγA,γFin is one part of an isomor-
phism N  N × 1  AγA,γFin, and if we deﬁne Fin : N →Set by
Fin(n) = BγA,γFin(introAγA,γFin (⟨n, ⋆⟩)) ,
then we can deﬁne constructors
n : N
zn : Fin(n + 1)
n : N
m : Fin(n)
sn(m) : Fin(n + 1)
by zn = introBγA,γFin(⟨tt, ⟨n, ⋆⟩⟩) and
sn(m) = introBγA,γFin (⟨ff, ⟨n, ⟨(λ ⋆. m), ⋆⟩⟩⟩.
Contexts and types The codes for the contexts and types from Example 1 are as
follows:
γCtxt
=
nil +SP A-ind(1, B-ind(1, (λ ⋆. inr(⋆)), nil)) : SP0
A
γι
=
A-ind(1, nil(aref(inr(⋆))))
γΠ
=
A-ind(1, B-ind(1, (λ ⋆. aref(inr(⋆))), B-ind(1,
(λ ⋆.arg(⟨ff, ⟨(λ ⋆.bref(inr(⋆))), ⟨λ ⋆.⋆, ⋆⟩⟩⟩),
nil(aref(inr(⋆))))))
γTy
=
γι +SP γΠ : SP0
B(γCtxt) .

A Finite Axiomatisation of Inductive-Inductive Definitions
281
We have Ctxt = AγCtxt,γTy and Ty = BγCtxt,γTy and we can deﬁne the usual
constructors by
ε : Ctxt
ι : (Γ : Ctxt) →Ty(Γ)
ε = introAγCtxt,γTy (⟨tt, ⋆⟩) ,
ιΓ = introBγCtxt,γTy (⟨tt, ⟨(λ ⋆.Γ), ⋆⟩⟩) ,
▷: (Γ : Ctxt) →Ty(Γ) →Ctxt
Γ ▷σ = introAγCtxt,γTy (⟨ff, ⟨(λ ⋆.Γ), ⟨(λ ⋆.σ), ⋆⟩⟩⟩) ,
Π : (Γ : Ctxt) →(σ : Ty(Γ)) →Ty(Γ ▷σ) →Ty(Γ)
Π(Γ, σ, τ) = introBγCtxt,γTy (⟨ff, ⟨(λ ⋆.Γ), ⟨(λ ⋆.σ), ⟨(λ ⋆.τ), ⋆⟩⟩⟩⟩) .
4
A set-theoretic model
Even though SPA and SPB themselves are straightforward (large) inductive deﬁni-
tions, this axiomatisation does not reduce inductive-inductive deﬁnitions to indexed
inductive deﬁnitions, since the formation and introduction rules are not instances
of ordinary indexed inductive deﬁnitions. (However, we do believe that the theory
of inductive-inductive deﬁnitions can be reduced to the theory of indexed inductive
deﬁnitions with a bit of more work, and plan to do this in the future.) To make sure
that our theory is consistent, it is thus necessary to construct a model.
We will develop a model in ZFC set theory, extended by two inaccessible car-
dinals in order to interpret Set and Type. Our model will be a simpler version of
the models developed by Dybjer and Setzer [15, 17] for induction-recursion. See
Aczel [3] for a more detailed treatment of interpreting type theory in set theory.
4.1
Preliminaries
We will be working informally in ZFC extended with the existence of two strongly
inaccessible cardinals i0 < i1, and will be using standard set theoretic constructions,
e.g.
⟨a, b⟩B {{a}, {a, b}} ,
λx ∈a.b(x) B {⟨x, b(x)⟩| x ∈a} ,
Πx∈ab(x) B {f : a →
[
x∈a
b(x) | ∀x ∈a.f(x) ∈b(x)} ,
Σx∈ab(x) B {⟨c, d⟩| c ∈a ∧d ∈b(c)} ,
0 B ∅, 1 B {0}, 2 B {0, 1} ,
a0 + . . . + an B Σi∈{0,...,n}ai

282
Fredrik Nordvall Forsberg and Anton Setzer
and the cumulative hierarchy Vα B
[
β<α
P(Vβ). Whenever we introduce sets Aα
indexed by ordinals α, let
A<α B
[
β<α
Aβ.
For every expression A of our type theory, we will give an interpretation ⟦A⟧ρ,
regardless of whether A : Type or A : B or not. Interpretations might however be
undeﬁned, written ⟦A⟧ρ ↑. If ⟦A⟧ρ is deﬁned, we write ⟦A⟧ρ ↓. We write A ≃B
for partial equality, i.e. A ≃B if and only if A ↓⇔B ↓and if A ↓, then A = B. We
write A :≃B if we deﬁne A such that A ≃B.
Open terms will be interpreted relative to an environment ρ, i.e. a function
mapping variables to terms. Write ρ[x7→a] for the environment ρ extended with
x 7→a, i.e. ρ[x7→a](y) = a if y = x and ρ(y) otherwise. The interpretation ⟦t⟧ρ of
closed terms t will not depend on the environment, and we omit the subscript ρ.
4.2
Interpretation of Expressions
The interpretation of the logical framework is as in [15]:
⟦Set⟧:≃Vi0
⟦Type⟧:≃Vi1
⟦(x : A) →B⟧ρ :≃Πy∈⟦A⟧ρ⟦B⟧ρ[y7→x]
⟦λx : A.e⟧ρ :≃λy ∈⟦A⟧ρ.⟦e⟧ρ[y7→x]
⟦(x : A) × B⟧ρ :≃Σy∈⟦A⟧ρ⟦B⟧ρ[y7→x]
⟦⟨a, b⟩⟧ρ :≃⟨⟦a⟧ρ, ⟦b⟧ρ⟩
⟦0⟧:≃0
⟦1⟧:≃1
⟦2⟧:≃2
⟦⋆⟧:≃0
⟦tt⟧:≃0
⟦ff⟧:≃1
⟦if x then a else b⟧ρ :≃

⟦a⟧ρ
if ⟦x⟧ρ = 0
⟦b⟧ρ
if ⟦x⟧ρ = 1
undeﬁned
otherwise
⟦!A⟧ρ :≃∅(the unique inclusion ∅→⟦A⟧ρ )
To interpret terms containing SPA, SPB, ArgA, ArgB, IndexB, and the codes nil,
non-ind, A-ind and B-ind, we ﬁrst deﬁne ⟦SPA⟧, ⟦SPB⟧, ⟦ArgA⟧, ⟦nil⟧, ⟦non-ind⟧,
...and interpret
⟦SPA(Xref)⟧ρ B ⟦SPA⟧(⟦Xref⟧ρ)
...
⟦ArgA(Xref, γ, X, Y, repX)⟧ρ B ⟦ArgA⟧(⟦Xref⟧ρ, ⟦γ⟧ρ, ⟦X⟧ρ, ⟦Y⟧ρ, ⟦repX⟧ρ)
...

A Finite Axiomatisation of Inductive-Inductive Definitions
283
⟦non-ind(K, γ)⟧ρ B ⟦non-ind⟧(⟦K⟧ρ, ⟦γ⟧ρ)
...
etc.
In all future deﬁnitions, if we are currently deﬁning ⟦F⟧ρ where F : D →E, say,
let ⟦F⟧ρ(d) ↑if d < ⟦D⟧ρ.
⟦SPA⟧(Xref) is deﬁned as the least set such that
⟦SPA⟧(Xref) = 1 +
X
K∈⟦Set⟧
(K →⟦SPA⟧(Xref)) +
X
K∈⟦Set⟧
⟦SPA⟧(Xref + K)
+
X
K∈⟦Set⟧
X
h:K→Xref
⟦SPA⟧(Xref) .
The constructors are then interpreted as
⟦nil⟧:≃⟨0, 0⟩
⟦B-ind⟧(K, h, γ) :≃⟨3, ⟨K, ⟨h, γ⟩⟩⟩
⟦non-ind⟧(K, γ) B ⟨1, ⟨K, γ⟩⟩
⟦A-ind⟧(K, γ) :≃⟨2, ⟨K, γ⟩⟩
⟦SPB⟧and its constructors are deﬁned analogously. The functions ⟦ArgA⟧, ⟦ArgB⟧
and ⟦IndexB⟧are deﬁned according to their equations, e.g.
⟦ArgA⟧(Xref, ⟦nil⟧, X, Y, repX) :≃1
⟦ArgA⟧(Xref, ⟦non-ind⟧(K, γ), X, Y, repX) :≃
X
k∈K
⟦ArgA⟧(Xref, γ(k), X, Y, repX)
⟦ArgA⟧(Xref, ⟦A-ind⟧(K, γ), X, Y, repX) :≃
X
j:K→A
⟦ArgA⟧(Xref + K, γ, X, Y, [repX, j])
⟦ArgA⟧(Xref, ⟦B-ind⟧(K, h, γ), X, Y, repX) :≃
X
j∈Πk∈KB(repX(h(k)))
⟦ArgA⟧(Xref, γ, X, Y, repX).
Finally, we have to interpret AγA,γB, BγA,γB, introAγA,γB and introBγA,γB . The high-
level idea is to iterate Arg0
A until a ﬁxed point is reached, then apply Arg0
B once, and
repeat. This is necessary since Arg0
B expects an argument introA : Arg0
A(γA, A, B) →
A, which can be chosen to be the identity if A is a ﬁxed point of Arg0
A(γA, A, B) (with
B ﬁxed). In more detail, let
⟦AγA,γB⟧:≃Ai0 ,
⟦BγA,γB⟧(a) :≃Bi0(a) ,
⟦introAγA,γB ⟧(a) :≃a ,
⟦introBγA,γB ⟧(b) :≃b ,
where Aα and Bα are simultaneously deﬁned by recursion on α as
Aα B least ﬁxed point containing A<α of λX . ⟦Arg0
A⟧(γA, X, B<α) ,
Bα(a) B {b | b ∈⟦Arg0
B⟧(γA, Aα, B<α, id, γB)
∧⟦Index0
B⟧(γA, Aα, B<α, id, γB, b) = a} .

284
Fredrik Nordvall Forsberg and Anton Setzer
The (graph of the) eliminators can then be built up in the same stages.
Having interpreted all terms, we ﬁnally interpret contexts as sets of environ-
ments:
⟦∅⟧:≃∅
⟦Γ, x : A⟧:≃{ρ[x7→a] | ρ ∈⟦Γ⟧∧a ∈⟦A⟧ρ}.
4.3
Soundness of the Rules
A detailed veriﬁcation of the soundness of all the rules falls outside the scope of this
paper. The main diﬃculty lies in proving that ⟦SPA⟧and ⟦SPB⟧are well-deﬁned,
and that ⟦AγA,γB⟧∈⟦Set⟧and ⟦BγA,γB⟧: ⟦AγA,γB⟧→⟦Set⟧. Full details of the
proof will be provided in a future publication (in preparation).
⟦SPA⟧is obtained by iterating the appropriate operator Γ : (⟦Set⟧→⟦Set⟧) →
(⟦Set⟧→⟦Set⟧) up to i0 times. Since Xref ∈⟦Set⟧, we have (Xref +K), (K →Xref)
∈⟦Set⟧for all K ∈⟦Set⟧= Vi0 by the inaccessibility of i0. Hence all “premisses”
have cardinality at most i0, which is regular, so that the operator has a ﬁxed point
after i0 iterations, which must be an element of ⟦Type⟧= Vi1 by the inaccessibility
of i1.
To see that ⟦AγA,γB⟧∈⟦Set⟧and ⟦BγA,γB⟧: ⟦AγA,γB⟧→⟦Set⟧, one ﬁrst veriﬁes
that ⟦Arg0
A⟧, ⟦Arg0
B⟧, ⟦Index0
B⟧are monotone in the following sense:
Lemma 12. For all γA ∈⟦SP0
A⟧and γB ∈⟦SP0
B⟧(γA):
(i) If A ⊆A′ and B(x) ⊆B′(x) then ⟦Arg0
A⟧(γA, A, B) ⊆⟦Arg0
A⟧(γA, A′, B′).
(ii) If in addition introA(x) = intro′
A(x) for all x ∈Arg0
A(γA, A, B), then
⟦Arg0
B⟧(γA, A, B, introA, γB) ⊆⟦Arg0
B⟧(γA, A′, B′, intro′
A, γB)
and
⟦Index0
B⟧(γA, A, B, introA, γB, x) = ⟦Index0
B⟧(γA, A′, B′, intro′
A, γB, x)
for all x ∈⟦Arg0
B⟧(γA, A, B, introA, γB).
□
We can then adapt the standard results [2] about monotone operators. First, we
note that one application of ⟦Arg0
A⟧and ⟦Arg0
B⟧is not enough to take us outside of
⟦Set⟧:
Lemma 13. For all γA ∈⟦SP0
A⟧and γB ∈⟦SP0
B⟧(γA):
(i) If X ∈⟦Set⟧and Y(x) ∈⟦Set⟧for each x ∈X, then ⟦Arg0
A⟧(γA, X, Y) ∈
⟦Set⟧.

A Finite Axiomatisation of Inductive-Inductive Definitions
285
(ii) If X ∈⟦Set⟧and Y(x) ∈⟦Set⟧for each x ∈X, ⟦Arg0
B⟧(γA, X, Y, introX, γB) ∈
⟦Set⟧.
□
We then iterate, using Aα and Bα, in order to reach a ﬁxed point. This uses that
fact that both ⟦Arg0
A⟧and ⟦Arg0
B⟧are κ-continuous for large enough κ:
Lemma 14.
(i) For α < i0, Aα ∈⟦Set⟧and Bα : Aα →⟦Set⟧.
(ii) For α < β, Aα ⊆Aβ and Bα(a) ⊆Bβ(a) for all a ∈Aα.
(iii) There is κ < i0 such that for all α ≥κ, Aα = Aκ and Bα(a) = Bκ(a) for all
a ∈Aα.
□
Now we are done, since ⟦AγA,γB⟧= Ai0 = Aκ ∈⟦Set⟧, and similarly for
⟦BγA,γB⟧.
References
[1] Michael Abbott, Thorsten Altenkirch, and Neil Ghani. Containers: Construct-
ing strictly positive types. Theoretical Computer Science, 342(1):3 – 27, 2005.
[2] Peter Aczel. An introduction to inductive deﬁnitions. In Handbook of Math-
ematical Logic, pages 739–782. Elsevier, 1977.
[3] Peter Aczel. On relating type theories and set theories. Lecture Notes In
Computer Science, 1657:1–18, 1999.
[4] Thorsten Altenkirch and Peter Morris. Indexed containers. In Logic In Com-
puter Science, pages 277 –285, 2009.
[5] Thorsten Altenkirch, Peter Morris, Fredrik Nordvall Forsberg, and Anton Set-
zer. A categorical semantics for inductive-inductive deﬁnitions. In Andrea
Corradini, Bartek Klin, and Corina Cirstea, editors, Conference on Algebra
and Coalgebra in Computer Science, volume 6859 of Lecture Notes in Com-
puter Science, pages 70 – 84. Springer, 2011.
[6] Roland Backhouse. On the meaning and construction of the rules in Martin-
L¨of’s theory of types. In A. Avron, R. Harper, F. Honsell, I. Mason, and
G. Plotkin, editors, Proceedings of the Workshop on general logic, Edinburgh,
February, 1987, volume ECS-LFCS-88-52, 1988.

286
Fredrik Nordvall Forsberg and Anton Setzer
[7] Roland Backhouse, Paul Chisholm, Grant Malcolm, and Erik Saaman. Do-it-
yourself type theory. Formal Aspects of Computing, 1(1):19–84, 1989.
[8] James Chapman. Type theory should eat itself. Electronic Notes in Theoreti-
cal Computer Science, 228:21–36, 2009.
[9] James Chapman, Pierre-´Evariste Dagand, Conor McBride, and Peter Morris.
The gentle art of levitation. In ICFP, volume 45, pages 3–14. ACM, 2010.
[10] John Conway. On numbers and games. AK Peters, 2001.
[11] The Coq team. Coq. http://coq.inria.fr/, 2012.
[12] Nils Anders Danielsson. A formalisation of a dependently typed language as
an inductive-recursive family. Lecture Notes in Computer Science, 4502:93–
109, 2007.
[13] Peter Dybjer. Inductive families. Formal aspects of computing, 6(4):440–465,
1994.
[14] Peter Dybjer. A general formulation of simultaneous inductive-recursive def-
initions in type theory. Journal of Symbolic Logic, 65(2):525–549, 2000.
[15] Peter Dybjer and Anton Setzer. A ﬁnite axiomatization of inductive-recursive
deﬁnitions. In Typed lambda calculi and applications: 4th international con-
ference, TLCA’99, L’Aquila, Italy, April 7-9, 1999: proceedings, pages 129–
146. Springer Verlag, 1999.
[16] Peter Dybjer and Anton Setzer. Induction–recursion and initial algebras. An-
nals of Pure and Applied Logic, 124(1-3):1–47, 2003.
[17] Peter Dybjer and Anton Setzer. Indexed induction–recursion. Journal of logic
and algebraic programming, 66(1):1–49, 2006.
[18] Neil Ghani and Peter Hancock. Containers, monads and induction recursion.
To appear in MSCS, 2012.
[19] Lionel Mamane. Surreal numbers in Coq. In Jean-Christophe Filliˆatre, Chris-
tine Paulin-Mohring, and Benjamin Werner, editors, Types for Proofs and Pro-
grams: International Workshop TYPES 2004, volume 3839 of Lecture Notes
in Computer Science, pages 170 – 185. Springer, 2006.
[20] Per Martin-L¨of. Intuitionistic type theory. Bibliopolis Naples, 1984.

A Finite Axiomatisation of Inductive-Inductive Definitions
287
[21] Peter Morris. Constructing Universes for Generic Programming. PhD thesis,
University of Nottingham, 2007.
[22] Peter Morris, Thorsten Altenkirch, and Neil Ghani. A universe of strictly
positive families. International Journal of Foundations of Computer Science,
20(1):83–107, 2009.
[23] Peter Morris, Thorsten Altenkirch, and Conor McBride. Exploring the regular
tree types. Types for Proofs and Programs, pages 252–267, 2006.
[24] Fredrik Nordvall Forsberg and Anton Setzer. Inductive-inductive deﬁnitions.
In Anuj Dawar and Helmut Veith, editors, Computer Science Logic, volume
6247 of Lecture Notes in Computer Science, pages 454–468. Springer, 2010.
[25] Ulf Norell. Towards a practical programming language based on dependent
type theory. PhD thesis, Department of Computer Science and Engineering,
Chalmers University of Technology, 2007.

288

Some Conservative Extension Results on
Classical and Intuitionistic Sequent Calculi
Hajime Ishihara
We present some conservative extension results of classical sequent calculus
over intuitionistic sequent calculus with respect to classes of formulas. The
classes of formulas are simultaneously inductively generated by clauses which
are variants of those in Ishihara (2000).
1
Introduction
It is well known that classical predicate logic is conservative over intuitionistic
predicate logic with respect to negative formulas; see Troelstra and van Dalen [13,
2.3.6] or van Dalen [3, 5.2.9]. A number of papers in the literature contain ex-
tensions of the conservative extension result, such as Mints and Orevkov [7] and
Cellucci [2]. Leivant [6] gave another systematization of the conservative extension
results, not only for predicate logic but also for mathematical theories; see also [13,
2.3.11–26].
In 2000, the author showed the following conservative extension result. We
deﬁne simultaneously classes R, J, Q and K of formulas as follows. Let P range
over atomic formulas, R and R′ over R, J and J′ over J, Q and Q over Q, and K
and K′ over K. Then R, J, Q and K are inductively generated by the clauses
1. ⊥, R ∧R′, R ∨R′, ∀xR, J →R ∈R;
2. ⊥, P, J ∧J′, J ∨J′, ∃xJ, R →J ∈J;
3. ⊥, P, Q ∧Q′, Q ∨Q′, ∀xQ, ∃xQ, J →Q ∈Q;
4. J, K ∧K′, ∀xK, Q →K ∈K.
We showed that
if Γ ⊆Q and A ∈K, then Γ ⊢c A implies Γ ⊢i A,
where ⊢c and ⊢i denote derivability in classical and intuitionistic logic, respectively;
see [5, Theorem 10].

290
Hajime Ishihara
An application of the result is the conservative extension result, Barr’s theorem,
for geometric theories, that is, theories axiomatized by (universal closures of) im-
plications, called geometric implications, between formulas which do not contain
→nor ∀; note that (universal closure of) geometric implications belong to Q and K.
See Palmgren [11] and Negri [8] for other syntactic proofs of Barr’s theorem, and
Section 4 for an application of the result to ﬁrst-order arithmetic; see also Berger,
Buchholz and Schwichtenberg [1] and Schwichtenberg and Wainer [12, Chapter 7]
for related classes of formulas in extracting computational content of proofs.
Helmut Schwichtenberg has asked the author about a possibility of introducing
∃and ∀in the clauses for the classes R and J, respectively. This paper answers
him with the following result.
We deﬁne simultaneously classes R0, J0, Qm and Km (m = 1, 2) of formulas
as follows. Let P range over atomic formulas, R and R′ over R0, J and J′ over J0,
Qm and Q′
m over Qm, and Km and K′
m over Km (m = 1, 2). Then R0, J0, Qm and Km
(m = 1, 2) are inductively generated by the clauses
1. ⊥, R ∧R′, R ∨R′, ∀xR, ∃xR, J →R ∈R0;
2. ⊥, P, J ∧J′, J ∨J′, ∀xJ, ∃xJ, R →J ∈J0;
3. P, R, Q1 ∧Q′
1, Q1 ∨Q′
1, ∃xQ1, J →Q1 ∈Q1;
4. P, R, Q2 ∧Q′
2, ∀xQ2, ∃xQ2, J →Q2 ∈Q2;
5. J, Km ∧K′
m, ∀xKm, Qm →Km ∈Km (m = 1, 2).
In Theorem 4 below, we will show that, for each m = 1, 2,
if Γ ⊆Qm and A ∈Km, then ⊢c Γ ⇒A implies ⊢i Γ ⇒A,
where ⊢c and ⊢i denote derivability of sequent Γ ⇒A in the classical and intuition-
istic sequent calculi G3c and G3i, respectively.
2
Preliminaries
We refer to Troelstra and Schwichtenberg [14] for the necessary background on
sequent calculi; see also Negri and von Plato [9]. We use the standard language
of (many-sorted) ﬁrst-order predicate logic containing ∧, ∨, →, ⊥, ∀and ∃as
primitive logical operators, and introduce the abbreviation ¬A ≡A →⊥. The sets
of free variables in a formula A and in a ﬁnite multiset Γ of formulas are denoted by
FV(A) and FV(Γ), respectively. We deﬁne positive, strictly positive and negative
occurrence of a formula in the usual way (see [14, 1.1.3] or [13, 3.9,3.11,3.23]

Some Conservative Extension Results
291
for details), and deﬁne strictly positive occurrences of ∨and ∀by occurrences in
strictly positive subformulas D ∨D′ and ∀xD, respectively.
The sequent calculus G3c is speciﬁed by the following axioms and rules:
P, Γ ⇒∆, P
Ax
⊥, Γ ⇒∆
L⊥
A, B, Γ ⇒∆
A ∧B, Γ ⇒∆L∧
Γ ⇒∆, A
Γ ⇒∆, B
Γ ⇒∆, A ∧B
R∧
A, Γ ⇒∆
B, Γ ⇒∆
A ∨B, Γ ⇒∆
L∨
Γ ⇒∆, A, B
Γ ⇒∆, A ∨B R∨
Γ ⇒∆, A
B, Γ ⇒∆
A →B, Γ ⇒∆
L→
A, Γ ⇒∆, B
Γ ⇒∆, A →B R→
∀xA, A[x/t], Γ ⇒∆
∀xA, Γ ⇒∆
L∀
Γ ⇒∆, A[x/y]
Γ ⇒∆, ∀xA
R∀
A[x/y], Γ ⇒∆
∃xA, Γ ⇒∆
L∃
Γ ⇒∆, A[x/t], ∃xA
Γ ⇒∆, ∃xA
R∃
where in Ax, P is atomic, and in R∀and L∃, y < FV(Γ, ∆), y ≡x or y < FV(A).
The intuitionistic version G3i of G3c has the following form:
P, Γ ⇒P
Ax
⊥, Γ ⇒A
L⊥
A, B, Γ ⇒C
A ∧B, Γ ⇒C L∧
Γ ⇒A
Γ ⇒B
Γ ⇒A ∧B
R∧
A, Γ ⇒C
B, Γ ⇒C
A ∨B, Γ ⇒C
L∨
Γ ⇒A
Γ ⇒A ∨B R∨1
Γ ⇒B
Γ ⇒A ∨B R∨2
A →B, Γ ⇒A
B, Γ ⇒C
A →B, Γ ⇒C
L→
A, Γ ⇒B
Γ ⇒A →B R→
∀xA, A[x/t], Γ ⇒C
∀xA, Γ ⇒C
L∀
Γ ⇒A[x/y]
Γ ⇒∀xA
R∀
A[x/y], Γ ⇒C
∃xA, Γ ⇒C
L∃
Γ ⇒A[x/t]
Γ ⇒∃xA
R∃
where in Ax, P is atomic, in R∀, y < FV(Γ), y ≡x or y < FV(A), and in L∃,
y < FV(Γ,C), y ≡x or y < FV(A).
The structural rules (weakening, contraction and cut) are admissible in G3c and
in G3i; see [14, 3.4.3,3.4.5,4.1.2]. Those structural rules are formulated in G3i as
follows:
Γ ⇒C
Γ, ∆⇒C LW
A, A, Γ ⇒C
A, Γ ⇒C
LC

292
Hajime Ishihara
Γ ⇒A
A, Γ′ ⇒C
Γ, Γ′ ⇒C
Cut.
We write ⊢c Γ ⇒∆and ⊢i Γ ⇒A for derivability of sequents Γ ⇒∆and
Γ ⇒A in G3c and in G3i, respectively.
We introduce the symbol “∗” as a special proposition letter (a place holder) and
an abbreviation ¬∗A ≡A →∗. It is straightforward to see that if ⊢i Γ ⇒A, then
⊢i Γ, ¬∗A ⇒∗, if ⊢i Γ, ¬∗¬∗A ⇒∗, then ⊢i Γ ⇒¬∗A, and ⊢i Γ, A ⇒∗if and only if
⊢i Γ ⇒¬∗A.
We have the following lemma for the logical operators and the operators ¬ and
¬∗.
Lemma 1.
1. ⊢i Γ, ¬∗¬⊥⇒∗,
2. ⊢i ¬∗¬(A ∧B) ⇒¬∗¬A ∧¬∗¬B,
3. ⊢i ¬∗¬∗A ∧¬∗¬∗B ⇒¬∗¬∗(A ∧B),
4. ⊢i ¬∗¬(A ∨B) ⇒¬∗¬∗(¬∗¬A ∨¬∗¬B),
5. ⊢i ¬∗(¬∗A ∧¬∗B) ⇒¬∗¬∗(A ∨B),
6. ⊢i A →B ⇒¬∗¬∗A →¬∗¬∗B,
7. ⊢i ¬∗¬(A →B) ⇒¬∗¬∗A →¬∗¬B,
8. ⊢i ¬∗¬A →¬∗¬∗B ⇒¬∗¬∗(A →B),
9. ⊢i ¬∗¬∀xA ⇒∀x¬∗¬A,
10. ⊢i ∃x¬∗¬∗A ⇒¬∗¬∗∃xA.
Proof. Easy exercise.
□
We say that C is free for ∗in A and in Γ if no variable free in C becomes bound
by a variable binding operator in A and in Γ, respectively, when the occurrences of
∗are replaced by C; see [3, 2.3.14] for a precise deﬁnition.
Lemma 2. If ⊢i Γ ⇒A and C is free for ∗in Γ, A, then
⊢i Γ[∗/C] ⇒A[∗/C].
Proof. By induction on the depth of a derivation of ⊢i Γ ⇒A. It is straightforward
to see basis. For induction step, since the cases of the rules for the propositional
operators are straightforward, we review the rules L∀and L∃(the rules R∀and R∃
are treated similarly).

Some Conservative Extension Results
293
Case 1. The last rule applied is L∀. Then the derivation ends with
∀xB, B[x/t], Γ′ ⇒A
∀xB, Γ′ ⇒A
L∀.
Therefore, since C is free for ∗in B[x/t], we have
⊢i (∀xB)[∗/C], B[x/t][∗/C], Γ′[∗/C] ⇒A[∗/C]
by the induction hypothesis. Since C is free for ∗in ∀xB, we have x < FV(C), and
hence B[x/t][∗/C] ≡B[∗/C][x/t]. Thus
⊢i ∀x(B[∗/C]), Γ′[∗/C] ⇒A[∗/C]
by L∀, and so ⊢i (∀xB)[∗/C], Γ′[∗/C] ⇒A[∗/C].
Case 2. The last rule applied is L∃. Then the derivation ends with
B[x/y], Γ′ ⇒A
∃xB, Γ′ ⇒A
L∃,
where y < FV(Γ′, A), y ≡x or y < FV(B). Let z be a variable such that z <
FV(B, Γ′, A,C) and z is free for y in B[x/y], Γ′, A. Then, since
⊢i B[x/y], Γ′ ⇒A
we have ⊢i B[x/z], Γ′ ⇒A, without changing the depth of the deduction, by the
substitution lemma [14, 3.4.2], and therefore, since C is free for ∗in B[x/z], we
have
⊢i B[x/z][∗/C], Γ′[∗/C] ⇒A[∗/C]
by the induction hypothesis. Since C is free for ∗in ∀xB, we have x < FV(C), and
hence B[x/z][∗/C] ≡B[∗/C][x/z]. Thus
⊢i ∃x(B[∗/C]), Γ′[∗/C] ⇒A[∗/C]
by L∃, and so ⊢i (∃xB)[∗/C], Γ′[∗/C] ⇒A[∗/C].
□
3
Conservative extension results
If “c” is an operator, such as ¬ and ¬∗, and Γ ≡A1, . . . , An is a ﬁnite multiset of
formulas, then we write cΓ for the multiset cA1, . . . , cAn.
We will show the following proposition.

294
Hajime Ishihara
Proposition 3. If either Γ ⊆Q1 or Γ ⊆Q2, ∆⊆R0 and Σ ⊆J0, then ⊢c Γ, ∆⇒Σ
implies ⊢i Γ, ¬∗¬∆, ¬∗Σ ⇒∗.
The following theorem follows from the proposition.
Theorem 4. For each m = 1, 2, if Γ ⊆Qm and A ∈Km, then ⊢c Γ ⇒A implies
⊢i Γ ⇒A.
Proof. By induction on the deﬁnition of Km.
Basis. Suppose that A ∈J0 and ⊢c Γ ⇒A. Then ⊢i Γ, ¬∗A ⇒∗, by Proposition 3.
Therefore, since A is free for ∗in Γ, ¬∗A, ∗, we have
⊢i Γ, A →A ⇒A
by Lemma 2, and so ⊢i Γ ⇒A.
Induction step. For induction step, we have to review all the cases A ≡K ∧K′,
A ≡∀xK and A ≡Q →K.
Case 1. A ≡K ∧K′. Suppose that ⊢c Γ ⇒K ∧K′. Then ⊢c Γ ⇒K and ⊢c Γ ⇒K′,
and hence ⊢i Γ ⇒K and ⊢i Γ ⇒K′, by the induction hypothesis. Therefore
⊢i Γ ⇒K ∧K′, by R∧.
Case 2. A ≡∀xK. Suppose that ⊢c Γ ⇒∀xK. Then ⊢c Γ ⇒K[x/y] for y such that
y < FV(Γ, K), and hence ⊢i Γ ⇒K[x/y] by the induction hypothesis. Therefore
⊢i Γ ⇒∀xK, by R∀.
Case 3. A ≡Q →K. Suppose that ⊢c Γ ⇒Q →K. Then ⊢c Q, Γ ⇒K, and hence
⊢i Q, Γ ⇒K, by the induction hypothesis. Therefore ⊢i Γ ⇒Q →K, by R→.
□
To prove Proposition 3, we need a couple of lemmas.
Lemma 5. If ⊢i ∗n, Γ, ¬∗∆⇒A, where ∗n stands for n copies of ∗, and ∗does not
occur in Γ negatively nor positively in A, then ⊢i Γ ⇒A.
Proof. By induction on the depth of a deduction of ⊢i ∗n, Γ, ¬∗∆⇒A.
Basis. If the deduction is an instance of Ax, then, since A . ∗, it must be of the
form ∗n, P, Γ′, ¬∗∆⇒P, and hence ⊢i P, Γ′ ⇒P. If the deduction is an instance of
L⊥, then it is of the form ∗n, ⊥, Γ′, ¬∗∆⇒A, then ⊢i ⊥, Γ′ ⇒A.
Induction step. For induction step, since the cases of all the rules except L→are
straightforward, we review the rule L→, and distinguish cases.
Case 1. The derivation ends with
∗n, B →C, Γ′, ¬∗∆⇒B
∗n,C, Γ′, ¬∗∆⇒A
∗n, B →C, Γ′, ¬∗∆⇒A
L→.
Then, since ∗does not occur in B positively nor negatively in C, we have
⊢i B →C, Γ′ ⇒B
and
⊢i C, Γ′ ⇒A

Some Conservative Extension Results
295
by the induction hypothesis, and hence ⊢i B →C, Γ′ ⇒A, by L→.
Case 2. The derivation ends with
∗n, Γ, ¬∗B, ¬∗∆′ ⇒B
∗n+1, Γ, ¬∗∆′ ⇒A
∗n, Γ, ¬∗B, ¬∗∆′ ⇒A
L→.
Then ⊢i Γ ⇒A, by the induction hypothesis applied to the right premiss.
□
Lemma 6. If ⊢i Γ, ¬∗A[x/y], ¬∗∆⇒∗, where ∗does not occur in the antecedent
negatively, there is no strictly positive occurrence of ∀in Γ, and y < FV(Γ), y ≡x
or y < FV(A), then ⊢i Γ, ¬∗∀xA, ¬∗∆⇒∗.
Proof. By induction on the depth of a deduction of ⊢i Γ, ¬∗A[x/y], ¬∗∆⇒∗.
Basis. If the deduction is an instance of Ax, then it is of the form
∗, Γ′, ¬∗A[x/y], ¬∗∆⇒∗
and hence we have ⊢i ∗, Γ′, ¬∗∀xA, ¬∗∆⇒∗. If the deduction is an instance of L⊥,
then it is of the form ⊥, Γ′, ¬∗A[x/y], ¬∗∆⇒∗, hence we have
⊢i ⊥, Γ′, ¬∗∀xA, ¬∗∆⇒∗.
Induction step. For induction step, since there is no formula of the form ∀xD in Γ
and the cases for the rules L∧and L∨are straightforward, we review the rules L→
and L∃.
Case 1. When the last rule applied is L→, we distinguish subcases.
Case 1a. The derivation ends with
B →C, Γ′, ¬∗A[x/y], ¬∗∆⇒B
C, Γ′, ¬∗A[x/y], ¬∗∆⇒∗
B →C, Γ′, ¬∗A[x/y], ¬∗∆⇒∗
L→.
Then, since ∗does not occur in B positively, we have ⊢i B →C, Γ′ ⇒B, by Lemma
5, and hence
⊢i B →C, Γ′, ¬∗∀xA, ¬∗∆⇒B
by LW. Since there is no negative occurrence of ∗nor strictly positive occurrence
of ∀in C, we have ⊢i C, Γ′, ¬∗∀xA, ¬∗∆⇒∗, by the induction hypothesis, and
therefore ⊢i B →C, Γ′, ¬∗∀xA, ¬∗∆⇒∗, by L→.
Case 1b. The derivation ends with
Γ, ¬∗A[x/y], ¬∗B, ¬∗∆′ ⇒B
∗, Γ, ¬∗A[x/y], ¬∗∆′ ⇒∗
Γ, ¬∗A[x/y], ¬∗B, ¬∗∆′ ⇒∗
L→.
Then, since ∗does not occur in B positively, we have ⊢i Γ ⇒B, by Lemma 5, and
hence ⊢i Γ, ¬∗B ⇒∗. Therefore ⊢i Γ, ¬∗∀xA, ¬∗B, ¬∗∆′ ⇒∗, by LW.

296
Hajime Ishihara
Case 1c. The derivation ends with
Γ, ¬∗A[x/y], ¬∗∆⇒A[x/y]
∗, Γ, ¬∗∆⇒∗
Γ, ¬∗A[x/y], ¬∗∆⇒∗
L→.
Then, since ∗does not occur in A[x/y] positively, we have ⊢i Γ ⇒A[x/y], by
Lemma 5, and, since y < FV(Γ), and y ≡x or y < FV(A), we have
⊢i Γ ⇒∀xA
by R∀. Therefore ⊢i Γ, ¬∗∀xA ⇒∗, and so ⊢i Γ, ¬∗∀xA, ¬∗∆⇒∗, by LW.
Case 2. The last rule applied is L∃. Then the derivation ends with
B[z/u], Γ′, ¬∗A[x/y], ¬∗∆⇒∗
∃zB, Γ′, ¬∗A[x/y], ¬∗∆⇒∗
L∃,
where u < FV(Γ′, A[x/y], ∆), u ≡z or u < FV(B). Let v be a variable such that
v . y, v < FV(B, Γ′, ∀xA, ∆) and v is free for u in B[z/u], Γ′, A[x/y], ∆. Then, since
⊢i B[z/u], Γ′, ¬∗A[x/y], ¬∗∆⇒∗, we have
⊢i B[z/v], Γ′, ¬∗A[x/y], ¬∗∆⇒∗
without changing the depth of the deduction, by the substitution lemma [14, 3.4.2],
and hence
⊢i B[z/v], Γ′, ¬∗∀xA, ¬∗∆⇒∗
by the induction hypothesis. Thus ⊢i ∃zB, Γ′, ¬∗∀xA, ¬∗∆⇒∗, by L∃.
□
Lemma 7. If ⊢i Γ, ¬∗A, ¬∗∆⇒∗, where ∗does not occur in the antecedent
negatively, and there is no strictly positive occurrence of ∨in Γ, then either
⊢i Γ ⇒A, or ⊢i Γ, ¬∗∆⇒∗.
Proof. By induction on the depth of a deduction of ⊢i Γ, ¬∗A, ¬∗∆⇒∗.
Basis. If the deduction is an instance of Ax, then it is of the form
∗, Γ′, ¬∗A, ¬∗∆⇒∗
and hence we have ⊢i ∗, Γ′, ¬∗∆⇒∗. If the deduction is an instance of L⊥, then it
is of the form ⊥, Γ′, ¬∗A, ¬∗∆⇒∗, and hence we have ⊢i ⊥, Γ′ ⇒A.
Induction step. For induction step, since there is no formula of the form D ∨D′ in
Γ and the cases for the rules L∧, L∀and L∃are straightforward, we review the rule
L→. We distinguish cases.

Some Conservative Extension Results
297
Case 1. The derivation ends with
B →C, Γ′, ¬∗A, ¬∗∆⇒B
C, Γ′, ¬∗A, ¬∗∆⇒∗
B →C, Γ′, ¬∗A, ¬∗∆⇒∗
L→.
Then, since ∗does not occur in B positively, we have ⊢i B →C, Γ′ ⇒B, by Lemma
5, and, since there is no negative occurrence of ∗nor strictly positive occurrence
of ∨in C, we have either ⊢i C, Γ′ ⇒A, or ⊢i C, Γ′, ¬∗∆⇒∗, by the induction
hypothesis. In the former case, we have ⊢i B →C, Γ′ ⇒A, by L→, and in the latter
case, since ⊢i B →C, Γ′, ¬∗∆⇒∗, by LW, we have ⊢i B →C, Γ′, ¬∗∆⇒∗, by L→.
Case 2. The derivation ends with
Γ, ¬∗A, ¬∗B, ¬∗∆′ ⇒B
∗, Γ, ¬∗A, ¬∗∆′ ⇒∗
Γ, ¬∗A, ¬∗B, ¬∗∆′ ⇒∗
L→.
Then, since ∗does not occur in B positively, we have ⊢i Γ ⇒B, by Lemma 5, and
hence ⊢i Γ, ¬∗B ⇒∗. Therefore ⊢i Γ, ¬∗B, ¬∗∆′ ⇒∗, by LW.
Case 3. The derivation ends with
Γ, ¬∗A, ¬∗∆⇒A
∗, Γ, ¬∗∆⇒∗
Γ, ¬∗A, ¬∗∆⇒∗
L→.
Then, since ∗does not occur in A positively, we have ⊢i Γ ⇒A, by Lemma 5.
□
Corollary 8. If ⊢i Γ, ¬∗A[x/y], ¬∗∆⇒∗, where ∗does not occur in the antecedent
negatively, there is no strictly positive occurrence of ∨in Γ, and y < FV(Γ), y ≡x
or y < FV(A), then ⊢i Γ, ¬∗∀xA, ¬∗∆⇒∗.
Proof. Suppose that ⊢i Γ, ¬∗A[x/y], ¬∗∆⇒∗, where ∗does not occur in the an-
tecedent negatively, there is no strictly positive occurrence of ∨in Γ, and y < FV(Γ),
y ≡x or y < FV(A). Then either ⊢i Γ ⇒A[x/y], or ⊢i Γ, ¬∗∆⇒∗, by Lemma 7.
In the former case, we have ⊢i Γ ⇒∀xA, by R∀, and hence ⊢i Γ, ¬∗∀xA ⇒∗.
Therefore
⊢i Γ, ¬∗∀xA, ¬∗∆⇒∗
by LW. In the latter case, we have ⊢i Γ, ¬∗∀xA, ¬∗∆⇒∗, by LW.
□
Now we are able to give a proof of Proposition 3.
Proof of Proposition 3. By induction on the depth of a deduction of ⊢c Γ, ∆⇒Σ.
Basis. If the deduction is an instance of Ax, then it must be of the form
P, Γ′, ∆⇒Σ′, P

298
Hajime Ishihara
and hence ⊢i P, Γ′, ¬∗¬∆, ¬∗Σ′, ¬∗P ⇒∗. If the deduction is an instance of L⊥,
then it must be either of the form ⊥, Γ′, ∆⇒Σ, or of the form Γ, ⊥, ∆′ ⇒Σ. In
the former case, we have ⊢i ⊥, Γ′, ¬∗¬∆, ¬∗Σ ⇒∗, and, in the latter case, we have
⊢i Γ, ¬∗¬⊥, ¬∗¬∆′, ¬∗Σ ⇒∗, by Lemma 1 (1).
Induction step. For induction step, we distinguish the cases: (A) the last rule ap-
plied is an L-rule and the principal formula is in ∆, (B) the last rule applied is an
L-rule and the principal formula is in Γ, and (C) the last rule applied is an R-rule.
Case A. The last rule applied is an L-rule, and the principal formula is in ∆.
Case A1. The last rule applied is L∧. Then the derivation ends with
Γ, R, R′, ∆′ ⇒Σ
Γ, R ∧R′, ∆′ ⇒Σ L∧.
Hence ⊢i Γ, ¬∗¬R, ¬∗¬R′, ¬∗¬∆′, ¬∗Σ ⇒∗, by the induction hypothesis, and there-
fore ⊢i Γ, ¬∗¬R ∧¬∗¬R′, ¬∗¬∆′, ¬∗Σ ⇒∗, by L∧. Thus
⊢i Γ, ¬∗¬(R ∧R′), ¬∗¬∆′, ¬∗Σ ⇒∗
by Cut with Lemma 1 (2).
Case A2. The last rule applied is L∨. Then the derivation ends with
Γ, R, ∆′ ⇒Σ
Γ, R′, ∆′ ⇒Σ
Γ, R ∨R′, ∆′ ⇒Σ
L∨.
Hence ⊢i Γ, ¬∗¬R, ¬∗¬∆′, ¬∗Σ ⇒∗, and ⊢i Γ, ¬∗¬R′, ¬∗¬∆′, ¬∗Σ ⇒∗, by the
induction hypothesis, and therefore
⊢i Γ, ¬∗¬R ∨¬∗¬R′, ¬∗¬∆′, ¬∗Σ ⇒∗
by L∨. Thus ⊢i Γ, ¬∗¬∗(¬∗¬R ∨¬∗¬R′), ¬∗¬∆′, ¬∗Σ ⇒∗, and so
⊢i Γ, ¬∗¬(R ∨R′), ¬∗¬∆′, ¬∗Σ ⇒∗
by Cut with Lemma 1 (4).
Case A3. The last rule applied is L→. Then the derivation ends with
Γ, ∆′ ⇒Σ, J
Γ, R, ∆′ ⇒Σ
Γ, J →R, ∆′ ⇒Σ
L→.
Hence ⊢i Γ, ¬∗¬∆′, ¬∗Σ, ¬∗J ⇒∗and ⊢i Γ, ¬∗¬R, ¬∗¬∆′, ¬∗Σ ⇒∗, by the in-
duction hypothesis, and therefore, since ⊢i Γ, ¬∗¬∆′, ¬∗Σ ⇒¬∗¬∗J, we have
⊢i Γ, ¬∗¬∗J →¬∗¬R, ¬∗¬∆′, ¬∗Σ ⇒¬∗¬∗J, by LW. Thus
⊢i Γ, ¬∗¬∗J →¬∗¬R, ¬∗¬∆′, ¬∗Σ ⇒∗

Some Conservative Extension Results
299
by L→, and so
⊢i Γ, ¬∗¬(J →R), ¬∗¬∆′, ¬∗Σ ⇒∗
by Cut with Lemma 1 (7).
Case A4. The last rule applied is L∀. Then the derivation ends with
Γ, ∀xR, R[x/t], ∆′ ⇒Σ
Γ, ∀xR, ∆′ ⇒Σ
L∀.
Hence ⊢i Γ, ¬∗¬∀xR, ¬∗¬R[x/t], ¬∗¬∆′, ¬∗Σ ⇒∗, by the induction hypothesis.
Therefore, since ⊢i Γ, ¬∗¬∀xR, ∀x¬∗¬R, ¬∗¬R[x/t], ¬∗¬∆′, ¬∗Σ ⇒∗, by LW, we
have ⊢i Γ, ¬∗¬∀xR, ∀x¬∗¬R, ¬∗¬∆′, ¬∗Σ ⇒∗, by L∀, and hence
⊢i Γ, ¬∗¬∀xR, ¬∗¬∀xR, ¬∗¬∆′, ¬∗Σ ⇒∗
by Cut with Lemma 1 (9). Thus ⊢i Γ, ¬∗¬∀xR, ¬∗¬∆′, ¬∗Σ ⇒∗, by LC.
Case A5. The last rule applied is L∃. Then the derivation ends with
Γ, R[x/y], ∆′ ⇒Σ
Γ, ∃xR, ∆′ ⇒Σ
L∃.
Hence ⊢i Γ, ¬∗¬R[x/y], ¬∗¬∆′, ¬∗Σ ⇒∗, by the induction hypothesis. If Γ ⊆Q1,
then there is no strictly positive occurrence of ∀in Γ, and if Γ ⊆Q2, then there is
no strictly positive occurrence of ∨in Γ. Hence
⊢i Γ, ¬∗∀x¬R, ¬∗¬∆′, ¬∗Σ ⇒∗
by Lemma 6 and Corollary 8. Therefore, since ⊢i ¬∗¬∃xR ⇒¬∗∀x¬R, we have
⊢i Γ, ¬∗¬∃xR, ¬∗¬∆′, ¬∗Σ ⇒∗, by Cut.
Case B. The last rule applied is an L-rule, and the principal formula is in Γ. Since
the cases for the rules L∧, L∨, L∀and L∃are straightforward, we review the case
when the principal formula is in R0 and the case for the rule L→.
Case B1. The principal formula is in R0. Then the conclusion is of the form
R, Γ′, ∆⇒Σ, and we have
⊢i ¬∗¬R, Γ′, ¬∗¬∆, ¬∗Σ ⇒∗
by Case A, Therefore, since ⊢i R ⇒¬∗¬R, we have ⊢i R, Γ′, ¬∗¬∆, ¬∗Σ ⇒∗, by
Cut.
Case B2. The last rule applied is L→. Then the derivation ends with
Γ′, ∆⇒Σ, J
Q, Γ′, ∆⇒Σ
J →Q, Γ′, ∆⇒Σ
L→.

300
Hajime Ishihara
Hence ⊢i Γ′, ¬∗¬∆, ¬∗Σ, ¬∗J ⇒∗and ⊢i Q, Γ′, ¬∗¬∆, ¬∗Σ ⇒∗, by the induction
hypothesis. Therefore, since ⊢i Γ′, ¬∗¬∆, ¬∗Σ ⇒¬∗¬∗J, we have
⊢i ¬∗¬∗J →¬∗¬∗Q, Γ′, ¬∗¬∆, ¬∗Σ ⇒¬∗¬∗J
by LW, and ⊢i ¬∗¬∗Q, Γ′, ¬∗¬∆, ¬∗Σ ⇒∗. Thus
⊢i ¬∗¬∗J →¬∗¬∗Q, Γ′, ¬∗¬∆, ¬∗Σ ⇒∗
by L→, and so ⊢i J →Q, Γ′, ¬∗¬∆, ¬∗Σ ⇒∗, by Cut with Lemma 1 (6).
Case C. The last rule applied is an R-rule.
Case C1. The last rule applied is R∧. Then the derivation ends with
Γ, ∆⇒Σ′, J
Γ, ∆⇒Σ′, J′
Γ, ∆⇒Σ′, J ∧J′
R∧.
Hence ⊢i Γ, ¬∗¬∆, ¬∗Σ′, ¬∗J ⇒∗and ⊢i Γ, ¬∗¬∆, ¬∗Σ′, ¬∗J′ ⇒∗, by the induction
hypothesis, and therefore
⊢i Γ, ¬∗¬∆, ¬∗Σ′ ⇒¬∗¬∗J
and
⊢i Γ, ¬∗¬∆, ¬∗Σ′ ⇒¬∗¬∗J′.
Thus ⊢i Γ, ¬∗¬∆, ¬∗Σ′ ⇒¬∗¬∗(J ∧J′), by R∧and Cut with Lemma 1 (3), and so
⊢i Γ, ¬∗¬∆, ¬∗Σ′, ¬∗(J ∧J′) ⇒∗.
Case C2. The last rule applied is R∨. Then the derivation ends with
Γ, ∆⇒Σ′, J, J′
Γ, ∆⇒Σ′, J ∨J′ R∨.
Hence ⊢i Γ, ¬∗¬∆, ¬∗Σ′, ¬∗J, ¬∗J′ ⇒∗, by the induction hypothesis, and hence
⊢i Γ, ¬∗¬∆, ¬∗Σ′, ¬∗J ∧¬∗J′ ⇒∗, by L∧. Therefore
⊢i Γ, ¬∗¬∆, ¬∗Σ′ ⇒¬∗(¬∗J ∧¬∗J′)
and so ⊢i Γ, ¬∗¬∆, ¬∗Σ′ ⇒¬∗¬∗(J ∨J′), by Cut with Lemma 1 (5). Thus ⊢i
Γ, ¬∗¬∆, ¬∗Σ′, ¬∗(J ∨J′) ⇒∗.
Case C3. The last rule applied is R→. Then the derivation ends with
Γ, R, ∆⇒Σ′, J
Γ, ∆⇒Σ′, R →J R→.
Hence ⊢i Γ, ¬∗¬R, ¬∗¬∆, ¬∗Σ′, ¬∗J ⇒∗, by the induction hypothesis, and there-
fore, since ⊢i Γ, ¬∗¬R, ¬∗¬∆, ¬∗Σ′ ⇒¬∗¬∗J, we have
⊢i Γ, ¬∗¬∆, ¬∗Σ′ ⇒¬∗¬R →¬∗¬∗J

Some Conservative Extension Results
301
by R→. Thus ⊢i Γ, ¬∗¬∆, ¬∗Σ′ ⇒¬∗¬∗(R →J), by Cut with Lemma 1 (8), and so
⊢i Γ, ¬∗¬∆, ¬∗Σ′, ¬∗(R →J) ⇒∗.
Case C4. The last rule applied is R∀. Then the derivation ends with
Γ, ∆⇒Σ′, J[x/y]
Γ, ∆⇒Σ′, ∀xJ
R∀,
where y < FV(Γ, ∆, Σ′), y ≡x or y < FV(J). Hence
⊢i Γ, ¬∗¬∆, ¬∗Σ′, ¬∗J[x/y] ⇒∗
by the induction hypothesis. If Γ ⊆Q1, then there is no strictly positive occurrence
of ∀in Γ, and if Γ ⊆Q2, then there is no strictly positive occurrence of ∨in Γ.
Therefore ⊢i Γ, ¬∗¬∆, ¬∗Σ′, ¬∗∀xJ ⇒∗, by Lemma 6 and Corollary 8.
Case C5. The last rule applied is R∃. Then the derivation ends with
Γ, ∆⇒Σ′, J[x/t], ∃xJ
Γ, ∆⇒Σ′, ∃xJ
R∃.
Hence ⊢i Γ, ¬∗¬∆, ¬∗Σ′, ¬∗J[x/t], ¬∗∃xJ ⇒∗, by the induction hypothesis, and
hence ⊢i Γ, ¬∗¬∆, ¬∗Σ′, ¬∗∃xJ ⇒¬∗¬∗J[x/t]. Therefore
⊢i Γ, ¬∗¬∆, ¬∗Σ′, ¬∗∃xJ ⇒∃x¬∗¬∗J
by R∃, and so ⊢i Γ, ¬∗¬∆, ¬∗Σ′, ¬∗∃xJ, ⇒¬∗¬∗∃xJ, by Cut with Lemma 1 (10).
Thus
⊢i Γ, ¬∗¬∆, ¬∗Σ′, ¬∗∃xJ, ¬∗∃xJ ⇒∗
and so ⊢i Γ, ¬∗¬∆, ¬∗Σ′, ¬∗∃xJ ⇒∗, by LC.
□
4
Concluding Remarks
Orevkov [10] introduced the notions of a σ-class and a completely Glivenko class.
An occurence of a logical operator ◦(∈{∧, ∨, →, ¬, ∀, ∃}) in a sequent is of the
type ◦+ and of the type ◦−if it is a positive occurence and a negative occurence,
respectively, in the sequent. A σ-class {τ1, . . . , τn} is the set of sequents which
do not contain any occurence of the type τi (i = 1, . . . , n), and it is a completely
Glivenko class if ⊢c Γ ⇒A implies ⊢i Γ ⇒A for each sequent Γ ⇒A in the
σ-class. Orevkov proved that a σ-class is a completely Glivenko class if and only
if it is contained in one of the σ-classes:
1: {→+, ¬+, ∀+},
2: {→+, ¬+, ∨−},
3: {→+, ¬+, ∀−},
4: {→−, ¬−, ∨+, ∃+},
5: {→−, ¬−, ∨+, →+, ∀+},
6: {→−, ¬−, ∨+, →+, ∨−},
7: {→−, ¬−, ∨+, →+, ∀−}.

302
Hajime Ishihara
Our results extend some of the σ-classes, because, for a sequent Γ ⇒A, if it is in
the σ-class (1) or (4), then Γ ⊆Q and A ∈K; if it is in the σ-class (2), then Γ ⊆Q2
and A ∈K2; if it is in the σ-class (3), then Γ ⊆Q1 and A ∈K1.
The previous work [5] was based on a translation A$ ≡Ag[⊥/$] where Ag
is the G¨odel-Gentzen negative translation (note that the place holder was denoted
by $ instead of ∗there). A set Γ of formulas is closed under the translation (·)$ if
Γ ⊢i A$[$/C] for each A in Γ and each formula C which is free for $ in A$. Theorem
10 in [5] was stated in a general form:
if Γ is a set of formulas closed under (·)$ and A ∈K, then Γ ⊢c A
implies Γ ⊢i A,
and formulas in Q were proved to be closed under (·)$ in [5, Proposition 7]. Since
it is straightforward to show that the axioms and the axiom schema of ﬁrst-order
arithmetic are closed under (·)$, we have as an application of the theorem:
if A ∈K, then PA ⊢A implies HA ⊢A.
As a corollary, we have the well known result that PA is conservative over HA with
respect to Π0
2 formulas, whose proof employs the Friedman A-translation [4]. Note
that ⊢i (Bg)A ↔B$[$/A], where (·)A denotes the A-translation.
Moreover, we can extend the class R (and hence the classes J, Q and K) by
the clause
⊥, P, R ∧R′, R ∨R′, ∀xR, J →R ∈R,
because, for atomic P, since HA ⊢P ∨¬P, we have HA ⊢¬$¬P →P$, and
Proposition 7 in [5] holds for the extended classes in HA.
In the following, we look at where the proof of Proposition 3 collapses when
we introduce this trick into it. (Of course, if the atomic formulas were included
in R0, then the classes R0 , J0, Qm and Km (m = 1, 2) would be the class of all
formulas, and HA would be equivalent to PA, though.)
We try to show that ⊢i Π, Γ, ¬∗¬∆, ¬∗Σ ⇒∗, by induction on the depth of a
derivation of ⊢c Γ, ∆⇒Σ, where Π consists of (universal closure of) theorems of
HA. (Note that Π must consist of closed formulas to meet the variable conditions
imposed by the rules R∀and L∃.) Suppose that the deduction is an instance of Ax.
Then it is of the form Γ, P, ∆′ ⇒Σ′, P. Although we have
⊢i ∀⃗z(P ∨¬P), Γ, ¬∗¬P, ¬∗¬∆′, ¬∗Σ′, ¬∗P ⇒∗,
there are strictly positive occurrences of ∀and ∨in ∀⃗z(P ∨¬P), and hence we
cannot apply Lemma 6 nor Corollary 8 in the cases A5 and C4. We may replace
the formula P ∨¬P by its equivalent
D ≡∃x[(x = 0 →P) ∧(∃y(x = S y) →¬P)]

Some Conservative Extension Results
303
in HA, and there is no strictly positive occurrence of ∨in the universal closure of
D. However, in this case, we need additional theorems Π′ of HA, and have
⊢i Π′, ∀⃗zD, Γ, ¬∗¬P, ¬∗¬∆′, ¬∗Σ′, ¬∗P ⇒∗.
Unfortunately, Π′ contains (the universal closure of) a special case of induction of
the form
(x = 0 →∗) ∧∀y(x = S y →∗) →∀y(x = y →∗)
in which ∗occurs negatively, and, again, we cannot apply Corollary 8 in the cases
A5 and C4.
Acknowledgments. The author thanks the Japan Society for the Promotion of Sci-
ence (Grant-in-Aid for Scientiﬁc Research (C) No.23540130) for partly supporting
the research.
References
[1] Ulrich Berger, Wilfried Buchholz and Helmut Schwichtenberg, Reﬁned pro-
gram extraction from classical proofs, Ann. Pure Appl. Logic 114 (2002),
3–25.
[2] Carlo Cellucci, Un’ osservazione sul theorema di Minc-Orevkov, Boll. Un.
Mat. Ital. 1 (1969), 1–8.
[3] Dirk van Dalen, Logic and Structure, 4th ed., Springer-Verlag, Berlin-
Heidelberg, 2004.
[4] Harvey Friedman, Classically and intuitionistically provably recursive func-
tions, In: Higher set theory (Proc. Conf., Math. Forschungsinst., Oberwol-
fach, 1977), Lecture Notes in Math., 669, Springer, Berlin, 1978, 21–27.
[5] Hajime Ishihara, A note on the G¨odel-Gentzen translation, MLQ Math. Log.
Q. 46 (2000), 135–137.
[6] Daniel Leivant, Syntactic translations and provably recursive functions, J.
Symbolic Logic 50 (1985), 682-688.
[7] Grigori Mints and Vladimir Orevkov, On imbedding operators, Sem. Math.
V.A. Steklov 4 (1967), 64–66.
[8] Sara Negri, Contraction-free sequent calculi for geometric theories with an
application to Barr’s theorem, Arch. Math. Logic 42 (2003), 389–401.

304
Hajime Ishihara
[9] Sara Negri and Jan von Plato, Structural Proof Theory, Cambridge University
Press, Cambridge, 2001.
[10] Vladimir Orevkov, On Glivenko sequent classes, in: Logical and logico-
mathematical calculi I, Trudy Matematicheskogo Instituta imeni V.A.
Steklova, 98 (1968), 131–154; English translation, The calculi of symbolic
logic I, Proceedings of the Steklov Institute of Mathematics, 98 (1971), 147–
173.
[11] Erik Palmgren, An intuitionistic axiomatisation of real closed ﬁelds, MLQ
Math. Log. Q. 48 (2002), 297–299.
[12] Helmut Schwichtenberg and Stanley S. Wainer, Proofs and Computations,
Cambridge University Press, Cambridge, 2011.
[13] Anne S. Troelstra and Dirk van Dalen, Constructivism in Mathematics, Vol. I
and II, North-Holland, Amsterdam, 1988.
[14] Anne S. Troelstra and Helmut Schwichtenberg, Basic Proof Theory, Cam-
bridge Tracts in Theoretical Computer Science, 43, Cambridge University
Press, Cambridge, 1996.

About the Strength of Operational Regularity
Gerhard J¨ager and Rico Zumbrunnen
Dedicated to Helmut Schwichtenberg on his retirement
We analyze the consistency strength of regularity on the basis of Feferman’s
operational set theory OST. Our main result shows that regularity over OST
for operations corresponds to regularity with respect to set-theoretic functions
in frameworks like Kripke-Platek set theory. As a consequence, we obtain that
OST plus the operational axiom (Inac) is consistency-equivalent to Kripke-
Platek set theory with inﬁnity extended by the strong limit axiom (SLim)
stating that any ordinal is majorized by a functionally regular ordinal. Thus
OST + (Inac) is signiﬁcantly stronger than originally expected.
1
Introduction
Operational set theory OST has been introduced in Feferman [9] and further dis-
cussed, from various perspectives, in Cantini [5], Cantini and Corosilla [6, 7], Fe-
ferman [10], and J¨ager [13, 14, 15]. The basic theory OST is proof-theoretically
equivalent to Kripke-Platek set theory KP with inﬁnity (cf. Feferman [9, 10] and
J¨ager [13]). On the other hand, OST plus unbounded existential quantiﬁcation
and power set has the same consistency strength as von Neumann-Bernays-G¨odel
set theory NBG plus ∈-induction for arbitrary formulas and a class version of Σ1
1
choice (cf. J¨ager [14] and J¨ager and Kr¨ahenb¨uhl [16]). Also, there exists a natural
subsystem of OST with unbounded existential quantiﬁcation and power set which
is conservative over ZFC (cf. J¨ager [13]).
The program of operational set theory is described in detail in Feferman [10]
and summarized in the abstract of this article as follows: A new axiomatic system
OST of operational set theory is introduced in which the usual language of set the-
ory is expanded to allow us to talk about (possibly partial) operations applicable
both to sets and to operations. OST is equivalent in strength to admissible set the-
ory, and a natural extension of OST is equivalent in strength to ZFC. The language
of OST provides a framework in which to express “small” large cardinal notions
– such as those of being an inaccessible cardinal, a Mahlo cardinal, and a weakly

306
Gerhard J¨ager and Rico Zumbrunnen
compact cardinal – in terms of operational closure conditions that specialize to
the analogue notions on admissible sets. This illustrates a wider program whose
aim is to provide a common framework for analogues of large cardinal notions that
have appeared in admissible set theory, admissible recursion theory, constructive
set theory, constructive type theory, explicit mathematics, and systems of recursive
ordinal notations that have been used in proof theory.
In this paper we concentrate on the simplest form of small large cardinals ax-
ioms, conﬁne ourselves to operational regularity and the operational axiom (Inac)
which claims that any ordinal is majorized by an operationally regular ordinal,
prove some conjectures made in the literature, and disprove others. Our main result
states that operational regularity corresponds in strength to regularity with respect
to set-theoretic functions. As it turns out, sets Lκ, with κ a functionally regular ordi-
nal, have strong closure properties and satisfy, for example, separation for arbitrary
ﬁrst order formulas.
From this analysis of operational regularity we deduce that OST + (Inac) is
equiconsistent with KP plus the axiom (SLim) which claims that any ordinal is
majorized by a functionally regular ordinal. Hence we also know that OST+(Inac)
is very strong, certainly going (in strength) beyond full second order arithmetic.
2
OST and operational regularity
In this section we brieﬂy recapitulate the syntax of Feferman’s OST and some of its
properties needed below. Then we turn to the formulation of operational regularity,
as proposed in Feferman [9, 10]. We follow J¨ager [13, 14] very closely and even
use the same formulations whenever it seems adequate.
Let L be a typical language of ﬁrst order set theory with countably many set
variables a, b, c, f, g, u, v, w, x, y, z, . . . (possibly with subscripts) and a symbol for
the element relation as its only relation symbol. In addition, we have the constant
ω for the ﬁrst inﬁnite ordinal. The formulas of L are deﬁned as usual.
L◦, the language of OST, augments L by the binary function symbol ◦for
partial term application, the unary relation symbol ↓(deﬁned), and the following
constants: (i) the combinators k and s; (ii) ⊤, ⊥, el, non, dis, and e for logical
operations; (iii) S, R, and C for set-theoretic operations. The meaning of these
constants follows from the axioms below.
The terms (r, s, t, r1, s1, t1, . . .) of L◦are inductively generated as follows:
1. The variables and constants of L◦are terms of L◦.
2. If s and t are terms of L◦, then so is ◦(s, t).

About the Strength of Operational Regularity
307
In the following we often abbreviate ◦(s, t) as (s ◦t), (st), or simply as st. We
also adopt the convention of association to the left so that s1s2 . . . sn stands for
(. . . (s1s2) . . . sn). In addition, we often write s(t1, . . . , tn) for st1 . . . tn if this seems
more intuitive. Moreover, we frequently make use of the vector notation ⃗s as short-
hand for a ﬁnite string s1, . . . , sn of L◦terms whose length is either not important
or evident from the context.
Self-application is possible and meaningful, but not necessarily total, and there
may be terms not denoting an object. We make use of the deﬁnedness predicate ↓
to single out those which do, and (t↓) is read “t is deﬁned” or “t has a value”.
The formulas (A, B,C, D, A1, B1,C1, D1, . . .) of L◦are inductively generated as
follows:
1. All expressions of the form (s ∈t) and (t↓) are formulas of L◦, the so-called
atomic formulas.
2. If A and B are formulas of L◦, then so are ¬A, (A ∨B) and (A ∧B).
3. If A is a formula of L◦and if t is a term of L◦which does not contain x, then
(∃x ∈t)A, (∀x ∈t)A, ∃xA and ∀xA are formulas of L◦.
We will be working within classical logic so that the remaining logical connectives
can be deﬁned as usual. Parentheses and brackets are often omitted whenever there
is no danger of confusion. The free variables of t and A are deﬁned in the conven-
tional way; the closed L◦terms and closed L◦formulas, also called L◦sentences,
are those which do not contain free variables. Equality of sets is introduced by
(s = t) := (s↓) ∧(t↓) ∧∀x(x ∈s ↔x ∈t).
Given an L◦formula A and a variable u not occurring in A, we write Au for
the result of replacing each unbounded set quantiﬁer ∃x(. . .) and ∀x(. . .) in A by
(∃x ∈u)(. . .) and (∀x ∈u)(. . .), respectively. Suppose now that ⃗u = u1, . . . , un and
⃗s = s1, . . . , sn. Then A[⃗s/⃗u] is the L◦formula which is obtained from A by simulta-
neously replacing all free occurrences of the variables ⃗u by the L◦terms ⃗s; in order
to avoid collision of variables, a renaming of bound variables may be necessary. If
the L◦formula A is written as B[⃗u], we often simply write B[⃗s] instead of B[⃗s/⃗u].
Further variants of this notation will be obvious.
The logic of OST is the classical logic of partial terms due to Beeson and Fe-
ferman with the usual strictness axioms (cf. Beeson [2, 3]), including the common
equality axioms. Partial equality of terms is introduced by
(s ≃t) := (s↓∨t↓→s = t)
and says that if either s or t denotes anything, then they both denote the same object.

308
Gerhard J¨ager and Rico Zumbrunnen
The non-logical axioms of OST comprise axioms about the applicative struc-
ture of the universe, some basic set-theoretic properties, the representation of el-
ementary logical connectives as operations, and operational set existence axioms.
They divide into four groups.
I. Applicative axioms.
(A1) k , s,
(A2) kxy = x,
(A3) sxy↓∧sxyz ≃(xz)(yz).
Thus the universe is a partial combinatory algebra. We have λ-abstraction and thus
can introduce for each L◦term t a term λx.t whose variables are those of t other
than x such that
λx.t↓∧(λx.t)y ≃t[y/x].
Furthermore, there exists a closed L◦term ﬁx, a so-called ﬁxed point operator, with
ﬁx(f)↓∧(ﬁx(f) = g →gx ≃f(g, x)).
II. Basic set-theoretic axioms. They comprise: (i) the existence of the empty set;
(ii) pair, union and inﬁnity; (iii) ∈-induction is available for arbitrary formulas A[x]
of L◦,
∀x((∀y ∈x)A[y] →A[x]) →∀xA[x].
(L◦-I∈)
To increase readability, we will freely use standard set-theoretic terminology, for
example,
Tran[a] := (∀x ∈a)(x ⊆a)
and
Ord[a] := Tran[a] ∧(∀x ∈a)Tran[x].
Also, if A[x] is an L◦formula, then {x : A[x]} denotes the collection of all sets
satisfying A; it may be (extensionally equal to) a set, but this is not necessarily the
case. In particular, we set
V := {x : x↓}
and
B := {x : x = ⊤∨x = ⊥}
so that V denotes the collection of all sets, but is not a set itself, and B stands for the
unordered pair consisting of the truth values ⊤and ⊥, which is a set by the previous
axioms. The following shorthand notations, for n an arbitrary natural number,
(f : a →b)
:=
(∀x ∈a)(f x ∈b),
(f : an+1 →b)
:=
(∀x1, . . . , xn+1 ∈a)(f(x1, . . . , xn+1) ∈b)

About the Strength of Operational Regularity
309
express that f, in the operational sense, is a unary and (n+1)-ary mapping from a
to b, respectively. They do not say, however, that f is a unary or (n+1)-ary function
in the set-theoretic sense (see below). In this deﬁnition the set variables a and/or b
may be replaced by V and/or B. So, for example, (f : a →V) means that f is total
on a, and (f : V →b) means that f maps all sets into b.
III. Logical operations axioms.
(L1) ⊤, ⊥,
(L2) (el : V2 →B) ∧∀x∀y(el(x, y) = ⊤↔x ∈y),
(L3) (non : B →B) ∧(∀x ∈B)(non(x) = ⊤↔x = ⊥),
(L4) (dis : B2 →B) ∧(∀x, y ∈B)(dis(x, y) = ⊤↔(x = ⊤∨y = ⊤)),
(L5) ( f : a →B) →(e(f, a) ∈B ∧(e(f, a) = ⊤↔(∃x ∈a)(f x = ⊤))).
The ∆0 formulas of L◦are those L◦formulas which do not contain the function
symbol ◦, the relation symbol ↓or unbounded quantiﬁers. Hence they are the usual
∆0 formulas of set theory, possibly containing additional constants. The logical
operations make it possible to represent all ∆0 formulas by constant L◦terms.
Lemma 1. Let ⃗u be the sequence of variables u1, . . . , un. For every ∆0 formula
A[⃗u] of L◦with at most the variables ⃗u free, there exists a closed L◦term tA such
that the axioms introduced so far yield
tA↓∧(tA : Vn →B) ∧∀⃗x(A[⃗x] ↔tA(⃗x) = ⊤).
For a proof of this lemma see Feferman [9, 10]. Now we turn to the operational
versions of separation, replacement, and choice.
IV. Set-theoretic operations axioms.
(S1) Separation for deﬁnite operations:
(f : a →B) →(S( f, a)↓∧∀x(x ∈S(f, a) ↔(x ∈a ∧f x = ⊤))).
(S2) Replacement:
(f : a →V) →(R(f, a)↓∧∀x(x ∈R( f, a) ↔(∃y ∈a)(x = fy))).
(S3) Choice:
∃x(f x = ⊤) →(C f↓∧f(C f) = ⊤).

310
Gerhard J¨ager and Rico Zumbrunnen
This ﬁnishes our description of the non-logical axioms of OST. From Feferman
[9] and J¨ager [13] we know that, provably in OST, there exist closed L◦terms ∅
for the empty set, uopa for forming unordered pairs, un for forming unions, p for
forming ordered pairs (Kuratowski pairs) and prod for forming Cartesian products.
In addition, there are closed L◦terms pL and pR which act as projections with
respect to p, i.e.
pL(p(a, b)) = a
and
pR(p(a, b)) = b.
To comply with the set-theoretic conventions, we generally write {a, b} instead
of uopa(a, b), ∪a instead of un(a), ⟨a, b⟩instead of p(a, b) and a × b instead of
prod(a, b). Remember that ω is a constant for the ﬁrst inﬁnite ordinal and belongs
to the base language L.
We end this section with a few remarks concerning the relationship between
functions in the set-theoretic sense and operations in the sense of our form of term
application. Similar questions for similar operational set theories are discussed in
Beeson [4] and in Cantini and Crosilla [6].
It is well-known (see, for example, Barwise [1]) that there are ∆0 formulas
Rel[a] and Fun[a] of our basic language L, stating that the set a is a binary relation
and function, respectively, in the typical set-theoretic sense. It can also be expressed
in ∆0 form that a is a relation with domain b, abbreviated as Dom[a] = b, and that a
is a relation with range b, abbreviated as Ran[a] = b. If Fun[a] holds and u belongs
to the domain of a we often write a ′u for the unique v such that ⟨u, v⟩∈a.
Lemma 2. There exist closed L◦terms dom, ran, op, and fun so that OST proves
the following assertions:
1. dom(f)↓∧ran( f)↓∧op(f)↓.
2. Rel[a] →(Dom[a] = dom(a) ∧Ran[a] = ran(a)).
3. (Fun[f] ∧a ∈dom(f)) →f ′a = op(f, a).
4. (f : a →V) →(Fun[fun(f, a)] ∧Dom[fun(f, a)] = a).
5. (f : a →V) →(∀x ∈a)(fun(f, a) ′x = f x).
This lemma, whose proof can be found in Feferman [9, 10] as well, implies
that: (i) each set-theoretic function can be translated into an operation acting on
the same domain and yielding the same values; (ii) to each operation total on a
set a corresponds a set-theoretic function with domain a so that the values of this
operation and of this function on a agree.
We use the lower case Greek letters α, β, γ, κ, λ, ζ, η, ξ, . . . (possibly with sub-
scripts) to range over the ordinals; also, as customary in the context of ordinals,

About the Strength of Operational Regularity
311
we write 0 instead of ∅. Following the usual set-theoretic deﬁnition of regular-
ity as closely as possible, Feferman [9, 10] suggests the following formulation of
operational regularity.
Deﬁnition 3. Ordinal κ is called operationally regular, in symbols Org[κ], if and
only if ω < κ and
∀f(∀α < κ)(( f : α →κ) →(∃β < κ)(f : α →β)).
This deﬁnition also is meaningful in ZFC if we let the variable f range over
ordinary set-theoretic functions. Under this interpretation Org[κ] implies that κ is
identical to its coﬁnality and thus regular in the usual set-theoretic sense.
Clearly, the existence of operationally regular ordinals cannot be proved in
OST. However, Feferman [10] suggests to consider the axiom
∀α∃β(α < β ∧Org[β]),
(Inac)
stating that any ordinal is majorized by an operationally regular ordinal. It is con-
jectured in Feferman [10] that OST + (Inac) is consistency equivalent to the theory
KPi of iterated admissible sets – see (for example) J¨ager [12] for a detailed descrip-
tion of this system – which describes a recursively inaccessible universe.
It will turn out, however, that OST + (Inac) is dramatically stronger than KPi.
To give a precise characterization of OST + (Inac) we show it to be equivalent
to Kripke-Platek set theory with inﬁnity plus an axiom stating that any ordinal is
smaller than a so-called functionally regular ordinal.
3
The theories KP and KP + (SLim)
We begin this section with brieﬂy recalling the system KP of Kripke-Platek set
theory with inﬁnity. Then we turn to the notion of a functionally regular ordinal and
say something about the closure properties of the constructible sets Lκ for κ being
functionally regular. We end this section with a theorem about speciﬁc inductive
deﬁnitions, which later will be used to model OST. For further reading about KP,
its proof-theoretic analysis and some interesting subsystems and extensions consult,
for example, J¨ager [11, 12] and Rathjen [18].
KP is formulated in our basic language L with ∈as its only relation symbol and
equality of sets deﬁned by
(a = b) := (∀x ∈a)(x ∈b) ∧(∀x ∈b)(x ∈a).
The collections of ∆0, Σ, and Π formulas are introduced as usual. If T is a theory in
L containing KP and A a formula of L, then A is ∆over T if there is a Σ formula B

312
Gerhard J¨ager and Rico Zumbrunnen
and a Π formula C, both with the same free variables as A, such that T proves the
equivalence of A and B plus that of A and C. Also, as in the case of OST, we make
use of other standard set-theoretic terminology.
The underlying logic of KP is classical ﬁrst order logic with equality, its non-
logical axioms are: pair, union, inﬁnity (i.e. the assertion that ω is the least inﬁnite
ordinal), ∆0 separation and ∆0 collection, i.e.
∃x(x = {y ∈a : B[y]}),
(∆0-Sep)
(∀x ∈a)∃yC[x, y] →∃z(∀x ∈a)(∃y ∈z)C[x, y]
(∆0-Col)
for arbitrary ∆0 formulas B[u] and C[u, v] of L, as well as ∈-induction for arbitrary
formulas A[x] of L,
∀x((∀y ∈x)A[y] →A[x]) →∀xA[x].
(L-I∈)
Clearly, the formula Ord[a], which says that a is an ordinal, is a ∆0 formula of L,
and we use the lower case Greek letters α, β, γ, κ, λ, ζ, η, ξ (possibly with subscripts)
to range over the ordinals, as we do in OST. In the following we will be working
within the constructible universe, but cannot introduce it here. Most relvant details
can be found, for example, in Barwise [1] or Kunen [17].
Very brieﬂy, (a ∈Lα) states that the set a is an element of the αth level Lα of
the constructible hierarchy and a ∈L is short for ∃α(a ∈Lα). Given a set a ∈L,
we write rkL[a] for the least ordinal α such that a ∈Lα+1 and (a <L b) means that
a is smaller than b according to the well-ordering <L on the constructible universe
L. The axiom of constructibility is the statement (V=L), i.e. ∀x∃α(x ∈Lα). It is
well-known that the assertions (a ∈Lα) and (a <L b) are ∆over KP and that the
systems KP and KP + (V=L) are of the same consistency strength; both systems
prove the same absolute sentences.
Now we turn to the more common set-theoretic variant of operational regularity
obtained by working with set-theoretic functions rather than operations. To make
this distinction also notationally clear, we speak of functional regularity in this case.
Deﬁnition 4. Ordinal κ is called functionally regular, in symbols Frg[κ], if and
only if ω < κ and
∀f(∀α < κ)(Fun[ f] ∧Dom[f] = α ∧Ran[f] ⊆κ →(∃β < κ)(Ran[ f] ⊆β)).
Functionally regular ordinals κ and the corresponding sets Lκ have fairly strong
closure properties. We will discuss some of those, and in doing so, frequently make
use of notions and results of the theory of admissible sets as presented, for example,
in Barwise [1]. We begin with an immediate observation.

About the Strength of Operational Regularity
313
Lemma 5. KP proves that any functionally regular ordinal is a limit ordinal.
The next remark is about a property of the constructible hierarchy which is con-
venient for proving Lemma 7 below. For a proof we refer to Kunen [17], verifying
that all arguments work for the restricted framework of KP + (V=L).
Lemma 6. KP + (V=L) proves for any limit ordinal α ≥ω that there exists a
bijective set-theoretic function from α to Lα.
We are now ready lift the regularity property from functionally regular ordinals
κ to the corresponding constructible sets Lκ.
Lemma 7. Provable in KP + (V=L), we have for all functionally regular ordinals
κ that
a ∈Lκ ∧Fun[f] ∧Dom[f] = a ∧Ran[f] ⊆Lκ →(∃b ∈Lκ)(Ran[ f] ⊆b).
Proof. Assume that a ∈Lκ and f is a set-theoretic function from a to Lκ. Then there
exists an α such that ω < α < κ and a ⊆Lα. We apply the previous lemma and
let g be a set-theoretic bijection from α to Lα. Now we introduce the set-theoretic
function h from α to κ with
h ′ξ =

rkL[f ′(g ′ξ)]
if g ′ξ ∈a,
0
if g ′ξ < a
for all ξ < α. We see immediately that h is a set-theoretic function from α to κ.
Hence the functional regularity of κ provides us with an ordinal β < κ for which
Ran[h] ⊆β. Hence Ran[f] ⊆Lβ.
□
Lemma 8. KP + (V=L) proves that for any functionally regular κ the set Lκ is
admissible.
Proof. Let κ be functionally regular. Then κ is a limit ordinal greater than ω, and so,
apart from ∆0 collection, all axioms of KP are trivially satisﬁed by Lκ. To treat ∆0
collection, let A[v, w] be a ∆0 formula of L, posssibly with additional parameters,
and assume
a ∈Lκ ∧(∀x ∈a)(∃y ∈Lκ)A[x, y].
Now let f be the set-theoretic function from a to Lκ with
f ′x = min({ξ < κ : (∃y ∈Lξ)A[x, y]})
for all x ∈a. The previous lemma tells us that there is a b ∈Lκ for which Ran[f] ⊆
b. For β := sup({ξ : ξ ∈b}) we thus have β < κ, thus Lβ ∈Lκ, and
(∀x ∈a)(∃y ∈Lβ)A[x, y].
Hence Lβ is a possible witness as required for satisfying ∆0 collection.
□

314
Gerhard J¨ager and Rico Zumbrunnen
The sets Lκ with κ being functionally regular have even much stronger closure
properties. In particular, as we will see below, that they satisfy full separation.
Before turning to this theorem, we prove a useful lemma.
Lemma 9. For all L formulas A[⃗u, v, w] with all its free variables in ⃗u, v, w, the
theory KP + (V=L) proves
Frg[κ] ∧a,⃗u ∈Lκ →
(∃b ∈Lκ)(∀x ∈a)((∃y ∈Lκ)ALκ[⃗u, x, y] ↔(∃y ∈b)ALκ[⃗u, x, y]).
Proof. If z is a non-empty set, we write minL[z] for the with respect to the well-
ordering <L least element of z. Given a functionally regular κ and a,⃗u ∈Lκ, we
consider the function f from a to Lκ deﬁned by, for x ∈a,
f ′x :=

minL[{z ∈Lκ : ALκ[⃗u, x, z]}]
if (∃y ∈Lκ)ALκ[⃗u, x, y],
∅
otherwise.
Since κ is functionally regular, Lemma 7 implies the existence of a set b ∈Lκ such
that Ran[f] ⊆b. Consequently,
(∀x ∈a)((∃y ∈Lκ)ALκ[⃗u, x, y] →(∃y ∈b)ALκ[⃗u, x, y]).
Since the converse of this implication is obvious, our lemma is proved.
□
If ⃗x = x1, . . . , xn and ⃗a = a1, . . . , an, we often write ⃗x ∈⃗a and ⟨⃗x⟩∈×(⃗a) instead
of (x1 ∈a1 ∧. . . ∧xn ∈an) and ⟨x1, . . . , xn⟩∈a1 × . . . × an, respectively.
Theorem 10. For all L formulas A[⃗u,⃗v] with all its free variables in ⃗u,⃗v, the theory
KP + (V=L) proves
Frg[κ] →(∀⃗a ∈Lκ)(∀⃗x ∈Lκ)(∃b ∈Lκ)(b = {⟨⃗y⟩∈×(⃗a) : ALκ[⃗x,⃗y]}).
Proof. We show this assertion by induction on the formula A[⃗u,⃗v]. If A[⃗u,⃗v] is an
atomic formula, a negation, a disjuction, a conjunction, or a formula beginning with
a bounded quantiﬁer, then the assertion is obvious or an immediate consequence of
the induction hypothesis. This leaves the two interesting cases of A[⃗u,⃗v] beginning
with an unbounded quantiﬁer.
Assume that A[⃗u,⃗v] is of the form ∃zB[⃗u,⃗v, z]. For any functionally regular κ
and ⃗a, ⃗x ∈Lκ the previous lemma gives us a set c ∈Lκ such that
(∀⃗y ∈⃗a)((∃z ∈Lκ)BLκ[⃗x,⃗y, z] ↔(∃z ∈c)BLκ[⃗x,⃗y, z]).
(*)

About the Strength of Operational Regularity
315
By the induction hypothesis there exists a set b0 ∈Lκ such that
b0 = {⟨⃗y, z⟩∈×(⃗a, c) : BLκ[⃗x,⃗y, z]},
and with this b0 as parameter we deﬁne by ∆0 separation in Lκ the set
b := {⟨⃗y⟩∈×(⃗a) : (∃z ∈c)(⟨⃗y, z⟩∈b0)}.
Clearly, b ∈Lκ, and for all ⃗y we have because of (*) that
⟨⃗y⟩∈b
↔
⃗y ∈⃗a ∧(∃z ∈c)BLκ[⃗x,⃗y, z]
↔
⃗y ∈⃗a ∧(∃z ∈Lκ)BLκ[⃗x,⃗y, z]
↔
⃗y ∈⃗a ∧ALκ[⃗x,⃗y].
Therefore b is a set in Lκ as required. The remaining case of A[⃗u,⃗v] beginning with
an unbounded universal quantiﬁer is left to the reader.
□
In view of this theorem we can deduce that, within KP + (V=L), for any func-
tionally regular κ the set Lκ is a standard model of the theory ZFC−, the subsystem
of ZFC without the power set axiom.
The referee has pointed out that Lemma 6 can be proved in KP alone, mak-
ing use of Lemma II.6.7 of Devlin [8]. Clearly, (V=L) is not used elsewhere in
the proofs of the following Lemmas 7–9 and in the proof of Theorem 10. Hence
the extra hypothesis (V=L) can be eliminated there and, as a consequence, KP is
suﬃcient to prove that for any functionally regular κ, Lκ is a model of ZFC−.
Now we add to Kripke-Platek set theory the strong limit axiom which states
that any ordinal is majorized be a functionally regular ordinal,
∀α∃β(α < β ∧Frg[β])
(SLim)
and write KPS for the theory KP + (SLim). Observe that the ordinals of KPS
form an admissible limit of functionally regular ordinals, but are not necessarily
functionally regular.
For any L formula A we write AL for the L formula obtained from A by re-
placing all unbounded quantiﬁers ∃x(. . .) and ∀x(. . .) by ∃x(x ∈L ∧. . .) and
∀x(x ∈L →. . .), respectively. As the following theorem states, L is an inner
model of KPS.
Theorem 11. For the universal closure A of any axiom of KPS we have that
KPS ⊢AL.

316
Gerhard J¨ager and Rico Zumbrunnen
Proof. It is a folklore result in admissible set theory that KP proves AL for the
universal closure of any axiom of KP. Hence we can conﬁne ourselves to verifying
(SLim)L in KPS.
To do so, let α be an arbitrary ordinal. Then (SLim) implies the existence of
a functionally regular ordinal β which contains α. Trivially, this implies that β is
functionally regular in L, i.e. FrgL[β]. Thus we have (SLim)L.
□
Hence the usual inner model considerations yield the following result about the
equiconsistency of KPS and KPS + (V=L).
Corollary 12. The theory KPS and its extension KPS + (V=L) are equiconsistent;
both systems prove the same absolute formulas.
For establishing the equiconsistency of OST + (Inac) and KPS it is thus suﬃ-
cient to embed KPS into OST + (Inac) and to reduce OST + (Inac) to the theory
KPS + (V=L).
We end this section with a speciﬁc form of Σ recursion over the universe which
helps us in modeling OST + (Inac) within KPS + (V=L). Let R be a fresh (n + 1)-
ary relation symbol and extend L to the language L(R) with expressions R(α,⃗a)
as additional atomic formulas. Given a formula A[R] of L(R) and another formula
B[⃗a] of L with distinguished free variables ⃗a, we write A[B[.]] for the result of
substituting B[⃗s] for each occurrence of the form R(⃗s) in A[R], renaming bound
variables as necessary to avoid collision.
Theorem 13 (Σ recursion). Let R be a fresh n-ary relation symbol and A[R, α,⃗a]
a formula of L(R) with distinguished free variables ⃗a = a1, . . . , an which is ∆over
KP. Then there exists a Σ formula B[α,⃗a] of L such that KP proves
B[α,⃗a] ↔(⃗a ∈Lα ∧A[(∃ξ < α)B[ξ, .], α,⃗a]).
Proof. We proceed similarly to the proof of the theorem about deﬁnition by Σ re-
cursion in Barwise [1]. Let n = 1 to simplify notation and let C[f, α, b] be the L
formula given by the conjunction of
(i) Fun[f] ∧Dom[f] = α,
(ii) (∀β < α)( f ′β = {x ∈Lβ : A[S
ξ<β f ′ξ, β, x]}),
(iii) b = {x ∈Lα : A[S
ξ<α f ′ξ, α, x]}.
Clearly, C[f, α, a] is ∆over KP, and we let D[ f, α, a] be the Σ formula provably
equivalent to C[f, α, a] in KP. By transﬁnite induction on α we can then show that
D[ f, α, b] ∧D[g, α, c] →f = g ∧b = c,
(37)
∃f∃bD[f, α, b].
(38)

About the Strength of Operational Regularity
317
The proof of (1) is straightforward, the proof of (2) requires Σ reﬂection or Σ re-
placement, which both follow (in KP) from ∆0 collection. Now set
B[α, a] := ∃f∃b(D[ f, α, b] ∧a ∈b).
Obviously, B[α, a] is a Σ formula, and it is now easy to check that it has the property
required in our theorem.
□
4
Modeling OST + (Inac) within KPS + (V=L)
The following model construction is a modiﬁcation of that in J¨ager [13]. We begin
with the similar notational preliminaries:
• For any natural number n greater than 0 and any natural number i we select
a ∆0 formulas Tupn(a) and (a)i = b formalizing that a is an ordered n-tuple
and b the projection of a on its ith component; hence Tupn(⟨a0, . . . , an−1⟩)
and (⟨a0, . . . , an−1⟩)i = ai for 0 ≤i ≤n −1.
• Then we ﬁx pairwise diﬀerent constructible sets bk, bs, b⊤, b⊥, bel, d
non, c
dis,
be, bS, bR, and bC making sure that they all do not belong to the collection of
ordered pairs and triples; they will later act as the codes of the corresponding
constants of L◦.
We are going to code the L◦terms kx, sx, sxy, . . . by the ordered tuples ⟨bk, x⟩,
⟨bs, x⟩, ⟨bs, x, y⟩, . . . of the corresponding form. For example, to satisfy kxy = x we
interpret kx as ⟨bk, x⟩, and “⟨bk, x⟩applied to y” is taken to be x.
Next let R be a fresh 3-place relation symbol and extend L to the language
L(R) as above. The following deﬁnition introduces the L(R) formula A[R, α, a, b, c]
which will lead to the interpretation of the application relation (ab = c).
Deﬁnition 14. We choose A[R, α, a, b, c] to be the L(R) formula deﬁned as the
disjunction of the following formulas (1) – (22):
(1) a = bk ∧c = ⟨bk, b⟩,
(2) Tup2(a) ∧(a)0 = bk ∧(a)1 = c,
(3) a =bs ∧c = ⟨bs, b⟩,
(4) Tup2(a) ∧(a)0 =bs ∧c = ⟨bs, (a)1, b⟩,
(5) Tup3(a) ∧(a)0 =bs ∧
(∃x, y ∈Lα)(R((a)1, b, x) ∧R((a)2, b, y) ∧R(x, y, c)),

318
Gerhard J¨ager and Rico Zumbrunnen
(6) a = bel ∧c = ⟨bel, b⟩,
(7) Tup2(a) ∧(a)0 = bel ∧(a)1 ∈b ∧c = b⊤,
(8) Tup2(a) ∧(a)0 = bel ∧(a)1 < b ∧c = b⊥,
(9) a = d
non ∧b = b⊤∧c = b⊥,
(10) a = d
non ∧b = b⊥∧c = b⊤,
(11) a = c
dis ∧c = ⟨c
dis, b⟩,
(12) Tup2(a) ∧(a)0 = c
dis ∧(a)1 = b⊤∧c = b⊤,
(13) Tup2(a) ∧(a)0 = c
dis ∧(a)1 = b⊥∧b = b⊤∧c = b⊤,
(14) Tup2(a) ∧(a)0 = c
dis ∧(a)1 = b⊥∧b = b⊥∧c = b⊥,
(15) a =be ∧c = ⟨be, b⟩,
(16) Tup2(a) ∧(a)0 =be ∧(∃x ∈b)R((a)1, x, b⊤) ∧c = b⊤,
(17) Tup2(a) ∧(a)0 =be ∧(∀x ∈b)R((a)1, x, b⊥) ∧c = b⊥,
(18) a = bS ∧c = ⟨bS, b⟩,
(19) Tup2(a) ∧(a)0 = bS ∧(∀x ∈b)(R((a)1, x, b⊤) ∨R((a)1, x, b⊥)) ∧
(∀x ∈c)(x ∈b ∧R((a)1, x, b⊤)) ∧(∀x ∈b)(R((a)1, x, b⊤) →x ∈c),
(20) a = bR ∧c = ⟨bR, b⟩,
(21) Tup2(a) ∧(a)0 = bR ∧(∀x ∈b)(∃y ∈c)R((a)1, x, y) ∧
(∀y ∈c)(∃x ∈b)R((a)1, x, y),
(22) a = bC ∧R(b, c, b⊤) ∧(∀x ∈Lα)(x <L c →¬R(b, x, b⊤)) ∧
(∀x ∈Lα)¬R(bC, b, x).
It is a matter of routine to check that A[R, α, a, b, c] is ∆over KP. It is also
easy ro verify that A[R, α, a, b, c] is deterministic in the following sense: from
A[R, α, a, b, c] we can conclude that exactly one of the clauses (1)–(22) of the pre-
vious deﬁnition is satisﬁed for these α, a, b and c.
We continue with applying Theorem 13 to this formula A[R, α, a, b, c]: any
formula B[α, a, b, c] provided by this theorem may be used to describe the αth level
of the interpretation of the OST application (ab = c). Accordingly, we proceed as
follows.

About the Strength of Operational Regularity
319
Deﬁnition 15. Let BA[α, a, b, c] be a Σ formula of L associated to the formula
A[R, α, a, b, c] according to Theorem 13 such that KP proves
BA[α, a, b, c] ↔(a, b, c ∈Lα ∧A[(∃ξ < α)BA[ξ, .], α, a, b, c]).
(A)
Then we deﬁne
B<α
A [a, b, c] := (∃β < α)BA[β, a, b, c],
ApA[a, b, c] := ∃αBA[α, a, b, c].
As we will see, ApA[a, b, c] is functional in its third argument. The next lemma
takes care of the only critical case in the proof of this property and motivates the
rather complicated clause (22) of Deﬁnition 14 above.
Lemma 16. We can prove in KP that
BA[α,bC, f, a] ∧BA[β, bC, f, b] →α = β ∧a = b.
Proof. Working informally in KP, we assume BA[α,bC, f, a], BA[β, bC, f, b], and,
without loss of generality, α ≤β. Then bC, f, a ∈Lα and b ∈Lβ. In view of (A) and
clause (22) the assumption BA[β, bC, f, b] also implies
(∀x ∈Lβ)¬B<β
A [bC, f, x].
We also have BA[α,bC, f, a], hence α = β is an immediate consequence. Moreover,
(A) and clause (22) plus the two assumptions BA[α,bC, f, a] and BA[α,bC, f, b] also
give us
B<α
A [f, a, b⊤] ∧(∀x ∈Lα)(x <L a →¬B<α
A [f, x, b⊤]),
B<α
A [f, b, b⊤] ∧(∀x ∈Lα)(x <L b →¬B<α
A [f, x, b⊤]).
Consequently, we also have a = b, as desired.
□
Lemma 17. We can prove in KP:
1. B<α
A [a, b, u] ∧B<α
A [a, b, v] →u = v.
2. ApA[a, b, u] ∧ApA[a, b, v] →u = v.
Proof. Since the previous lemma is at our disposal, the ﬁrst assertion is easily
proved by induction on α. The second assertion is a straightforward consequence
of the ﬁrst.
□

320
Gerhard J¨ager and Rico Zumbrunnen
Now we proceed as in J¨ager [13] and associate to each term t of L◦a formula
⟦t⟧A(u) of L expressing that u is the value of t under the interpretation of the oper-
ational application via the formula ApA.
Deﬁnition 18. For each L◦term t we introduce an L formula ⟦t⟧A(u), with u not
occurring in t, which is inductively deﬁned as follows:
1. If t is a variable or the constant ω, then ⟦t⟧A(u) is the formula (t = u).
2. If t is another constant, then ⟦t⟧A(u) is the formula (bt = u).
3. If t is the term (rs), then we set
⟦t⟧A(u) := ∃x∃y(⟦r⟧A(x) ∧⟦s⟧A(y) ∧ApA[x, y, u]).
For every term t of L◦its translation ⟦t⟧A(u) is a Σ formula of L. This treatment
of terms leads to a canonical translation of formulas of L◦into formulas of L.
Deﬁnition 19. The translation of an L◦formula A into the L formula A⋆is induc-
tively deﬁned as follows:
1. For the atomic formulas of L◦we stipulate
(t↓)⋆
:=
∃x⟦t⟧A(x),
(s ∈t)⋆
:=
∃x∃y(⟦s⟧A(x) ∧⟦t⟧A(y) ∧x ∈y).
2. If A is a formula ¬B, then A⋆is ¬B⋆.
3. If A is a formula (B ⋄C) for ⋄being the binary junctor ∨or ∧, then A⋆is
(B⋆⋄C⋆).
4. If A is a formula (∃x ∈t)B[x], then
A⋆:= ∃y(⟦t⟧A(y) ∧(∃x ∈y)B⋆[x]).
5. If A is a formula (∀x ∈t)B[x], then
A⋆:= ∀y(⟦t⟧A(y) →(∀x ∈y)B⋆[x]).
6. If A is a formula QxB[x] for a quantiﬁer Q, then A⋆is QxB⋆[x].

About the Strength of Operational Regularity
321
We notice immediately that the translation A⋆of any L◦formula A which does
not contain the application operation (i.e. all terms occuring in A are constants of
variables) is equivalent to A.
Based on this interpretation of L◦in L we can now turn to the desired em-
bedding of OST + (Inac) into KPS + (V=L). A substantial part of the work has
been done in J¨ager [13] already, where a corresponding translation has been used to
embed OST into KP + (V=L). The strong limit axiom together with the following
obsrvation will take care of the axiom (Inac).
Lemma 20. In KP + (V=L) we can prove that
Frg[κ] →Org⋆[κ].
Proof. Working in KP, let κ be a functionally regular ordinal. For any f and α < κ
we have to show that
(f : α →κ)⋆→(∃β < κ)(f : α →β)⋆.
Hence assume (f : α →κ)⋆, and thus
(∀η < α)(∃ξ < κ)ApA[f, η, ξ].
This is a Σ formula, and therefore Σ reﬂection implies
(∀η < α)(∃ξ < κ)Apa
A[f, η, ξ].
for a suitable set a. Let g be the set-theoretic function from α to κ which maps
any η < κ to the uniquely determined ξ < κ for which Apa
A[f, η, ξ]. Since κ is
functionally regular there exists a β < κ such that Ran[g] ⊆β. This yields
(∀η < α)(∃ξ < β)Apa
A[f, η, ξ].
Thus ( f : α →β)⋆by Σ persistency, as desired.
□
Theorem 21. The theory OST + (Inac) is ⋆-interpreted in KPS + (V=L); i.e. for
all L◦formulas A we have
OST + (Inac) ⊢A
=⇒
KPS + (V=L) ⊢A⋆.
Proof. Our treatment of operational application is so that the axioms of the logic of
partial terms fall oﬀdirectly. For verifying the interpretations of the mathematical
axioms of OST simply follow J¨ager [13]. So it remains to prove (Inac)∗in KPS +
(V=L).

322
Gerhard J¨ager and Rico Zumbrunnen
Following our ⋆-translation this means that we have to show that the theory
KPS + (V=L) proves ∀α∃β(α < β ∧Org⋆[β]). But given any α, the strong limit
axiom (SLim) guarantees the existence of a functionally regular ordinal β which
contains α and, by the previous lemma, satisﬁes Org⋆[β].
So we know that the ⋆-translations of all axioms of OST + (Inac) are provable
in KPS + (V=L). Since KPS + (V=L) is closed under (the translations of) all rules
of inference of OST, our theorem is established.
□
5
Reducing KPS to OST + (Inac)
Since KP ⊆OST has been established in Feferman [9, 10] and J¨ager [13] not much
is left to be done for establishing the reduction of KPS to OST + (Inac). We can
immediately turn to the desired theorem.
Theorem 22. The theory OST + (Inac) contains the theory KPS; i.e. for all L
formulas A we have
KPS ⊢A
=⇒
OST + (Inac) ⊢A.
Proof. As just mentioned, we have KP ⊆OST, and thus only the axiom (SLim)
remains to be proved in OST + (Inac). Hence pick an arbitrary ordinal α. We have
to show that there exists a functionally regular ordinal β which contains α.
From (Inac) we conclude that there exists an ordinal β which contains α and is
operationally regular, and thus
ω < β ∧∀f(∀η < β)((f : η →β) →(∃ξ < β)( f : η →ξ)).
(*)
To prove that this β is functionally regular, let η be an arbitrary ordinal less than β
and g be an arbitrary set-theoretic function from η to β. Now we apply the closed
term op to g and conclude with Lemma 2 that op(g)↓and, for all x ∈Dom[g] = η,
op(g, x) ≃g ′x.
(**)
Hence (op(g) : η →β), and because of (*) there exists a ξ < β such that (op(g) :
η →ξ). Together with (**) this implies Ran[g] ⊆ξ, as needed for establishing the
functional regularity of β.
□
Corollary 23. The three theories OST + (Inac), KPS, and KPS + (V=L) are
equiconsistent and prove the same absolute formulas of the language L.

About the Strength of Operational Regularity
323
This corollary is an immediate consequence of Theorem 21, Theorem 22, and
Theorem 11.
The purpose of this article was to clarify the proof-theoretic strength of op-
erational regularity as introduced in Feferman [9, 10]. The main question in this
context is now to ﬁnd out whether there exist a natural variant (Inac)′ of the axiom
(Inac) complying with the ideology of operational set theory:
(i) OST + (Inac)′ is proof-theoretically equivalent to the theory KPi and thus “de-
scribes” a recursively inaccessible universe,
(ii) if interpreted in the sense of classical set theory, (Inac)′ nevertheless provides
for a weakly inaccessible universe.
References
[1] K. J. Barwise. Admissible Sets and Structures, volume 7 of Perspectives in
Mathematical Logic. Springer, 1975.
[2] M. J. Beeson. Foundations of Constructive Mathematics: Metamathematical
Studies, volume 3/6 of Ergebnisse der Mathematik und ihrer Grenzgebiete.
Springer, 1985.
[3] M. J. Beeson. Proving programs and programming proofs. In R. Barcan
Marcus, G. J. W. Dorn, and P. Weingartner, editors, Logic, Methodology, and
Philosophy of Science VII, volume 114 of Studies in Logic and the Founda-
tions of Mathematics, pages 51–82. North-Holland, 1986.
[4] M. J. Beeson. Towards a computation system based on set theory. Theoretical
Computer Science, 60(3):297–340, 1988.
[5] A. Cantini. Extending constructive operational set theory by impredicative
principles. Mathematical logic Quarterly, 57(3):299–322, 2011.
[6] A. Cantini and L. Crosilla. Constructive set theory with operations. In A. An-
dretta, K. Kearnes, and D. Zambella, editors, Logic Colloquium 2004, vol-
ume 29 of Lecture Notes in Logic, pages 47–83. Association for Symbolic
Logic and Cambridge University Press, 2008.
[7] A. Cantini and L. Crosilla. Elementary constructive operational set theory.
In R. Schindler, editor, Ways of Proof Theory, pages 199–240. Ontos Verlag,
2010.

324
Gerhard J¨ager and Rico Zumbrunnen
[8] K. J. Devlin.
Constructibility, volume 6 of Perspectives in Mathematical
Logic. Springer, 1984.
[9] S. Feferman. Notes on Operational Set Theory, I. Generalization of “small”
large cardinals in classical and admissible set theory. Technical Notes, 2001.
[10] S. Feferman. Operational set theory and small large cardinals. Information
and Computation, 207:971–979, 2009.
[11] G. J¨ager. Zur Beweistheorie der Kripke-Platek-Mengenlehre ¨uber den nat¨ur-
lichen Zahlen. Archiv f¨ur Mathematische Logik und Grundlagenforschung,
22:121–139, 1982.
[12] G. J¨ager. Theories for Admissible Sets: A Unifying Approach to Proof Theory,
volume 2 of Studies in Proof Theory, Lecture Notes. Bibliopolis, 1986.
[13] G. J¨ager. On Feferman’s operational set theory OST. Annals of Pure and
Applied Logic, 150(1–3):19–39, 2007.
[14] G. J¨ager. Full operational set theory with unbounded existential quantiﬁcation
and power set. Annals of Pure and Applied Logic, 160(1):33–52, 2009.
[15] G. J¨ager. Operations, sets and classes. In C. Glymour, W. Wei, and D. West-
erstahl, editors, Logic, Methodology and Philosophy of Science - Proceedings
of the Thirteenth International Congress, pages 74–96. College Publications,
2009.
[16] G. J¨ager and J. Kr¨ahenb¨uhl. Σ1
1 Choice in a Theory of Sets and Classes. In
R. Schindler, editor, Ways of Proof Theory, pages 283–314. Ontos Verlag,
2010.
[17] K. Kunen. Set Theory. An Introduction to Independence Proofs, volume 102
of Studies in Logic and the Foundations of Mathematics.
North-Holland,
1980.
[18] M. Rathjen. Fragments of Kripke-Platek set theory. In P. Aczel, H. Simmons,
and S. Wainer, editors, Proof Theory, pages 251–273. Cambridge University
Press, 1992.

Non-Deterministic
Epsilon
Substitution
for
ID1: Effective Proof
Grigori Mints
In a previous paper we deﬁned a simpliﬁed non-deterministic ϵ-substitution
process for PA and ID1 and gave a simple non-eﬀective termination proof.
Here we present an eﬀective termination proof via cut-elimination.
1
Introduction
In another paper [7] we deﬁned a simpliﬁed non-deterministic epsilon substitution
method for PA and ID1 and gave a short but non-eﬀective termination proof for it.
Here we present an eﬀective termination proof via cut-elimination using ideas from
[4] and [6]. For historical introduction and motivation (including a comparison with
the ﬁrst eﬀective termination proof for a more complicated formulation by T. Arai
in [1]) see [7]. Deﬁnitions and proofs in the present paper are independent of [7].
To simplify technical details we use a formulation with a special (but still uni-
versal) form of inductive deﬁnition: the system S 1 of constructive ordinals [9]. It
was introduced by S. Kleene [3] using a slightly diﬀerent notation. The general
scheme of the termination proof for the ϵ-substitution method and the resulting
proof-theoretic analysis is as follows:
1. The problem of termination is reduced to provability of some existential
statement: existence of a solving substitution for a given ﬁnite set E of ax-
ioms (critical formulas).
2. The simple (but non-eﬀective) recursion-theoretic proof of existence of such
a solving substitution is expanded into a proof (called original derivation)
in an inﬁnitary system with a rule similar to the Ω-rule introduced by W.
Buchholz [2].
3. The cut-elimination procedure from [2] with suitable adjustments is applied
to the original derivation.

326
Grigori Mints
4. The result of cut-elimination is a “complete protocol” including all steps of
the epsilon substitution method leading from the empty substitution to a so-
lution of the system E from 1.
I would like to acknowledge long discussions with many colleagues including H.
Towsner, S. Feferman, W. Tait, A. Ryota, W. Buchholz, T. Arai, U. Buchholtz. The
dialog with the anonymous referee who invested much more eﬀorts than the duty
required was especially constructive. It helped to correct errors in several proofs
and essentially improved presentation.
2
A Representation of Constructive Ordinals
A typical inductively deﬁned set is the set S 1 of constructive ordinals introduced
by A. Church and S. Kleene (cf. [3], [9]). Every other arithmetically inductively
deﬁned set is primitive recursive in S 1. Let’s describe one particularly simple in-
ductive deﬁniton of S 1. The author has not found exactly this description in the
literature.
Deﬁnition 1. n ∈S 1 :≡
n = 0 ∨∃e(n = 2e&e ∈S 1) ∨∃e(n = 3 · 5e&∀x∃y(T(e, x, y)&U(y) ∈S 1))
where the last disjunct means that the e-th partial recursive function is total and
all its values are in S 1.
Let R0(n) :≡n = 0 ∨(∃e < n)(n = 2e ∨n = 3 · 5e).
Consider for every n the following primitive recursive tree Tn whose nodes are
ﬁnite sequences of natural numbers. Every node is labeled by a natural number.
The root ∅is labeled by n.
If the node a is labelled by 0 then a is a leaf node: it has no predecessors.
If the node a is labelled by 2e then the immediate predecessor a ∗⟨0⟩of a is
labeled by e and no node a ∗⟨k + 1⟩is in the tree (and similarly below when only
one predecessor is labeled).
If the node a is labeled by 3·5e, then its immediate predecessor a∗⟨x⟩is labeled
by 3 · 5e · 7x+1.
If the node a is labeled by 3 · 5e · 7x+1 then the immediate predecessor a ∗⟨0⟩is
labeled by 3 · 5e · 7x+1 · 111.
If the node a is labeled by 3 · 5e · 7x+1 · 11y+1 and T(e, x, y) is false then the
immediate predecessor a ∗⟨0⟩is labeled by 3 · 5e · 7x+1 · 11y+2.
If the node a is labeled by m = 3 · 5e · 7x+1 · 11y +1 and T(e, x, y)&R0(U(y)) is
true then the immediate predecessor a ∗⟨0⟩is labeled by U(y).

Epsilon Substitution for ID1
327
If the node a is labelled by a number m > 0 that does satisfy one of the con-
ditions above then the immediate predecessor a ∗⟨0⟩of a is labeled by the same
number m.
Deﬁnition 2. R(n) :≡R0(n) ∨(∃e, x, y < n)
(n = 3 · 5e · 7x+1 ∨n = 3 · 5e · 7x+1 · 11y+1)
p(n, l) :=

e
if n = 2e
3 · 5e · 7l+1
if n = 3 · 5e
3 · 5e · 7x+1 · 11
if n = 3 · 5e · 7x+1
3 · 5e · 7x+1 · 11y+2
if n = 3 · 5e · 7x+1 · 11y+1 and ¬T(e, x, y)
U(y)
if n = 3 · 5e · 7x+1 · 11y+1 and
T(e, x, y)&R0(U(y))
n
otherwise
Let WF mean “well-founded”.
Lemma 3. Tn ∈WF ⇐⇒[n = 0 ∨(R(n) & ∀l(Tp(n,l) ∈WF))].
Therefore the relation Tn ∈WF can be inductively deﬁned by the equivalence
In ⇐⇒(n = 0 ∨(R(n)&∀l Ip(n, l)).
(39)
Proof. ⇒. Assume Tn ∈WF and n , 0. If ¬Rn then p(n, l) = n for all l, and all
nodes of the tree Tn are non-empty and labeled n. Therefore for all l ¬(Tp(n,l) ∈
WF). This contradiction proves R(n).
Consider now cases in R(n).
If n = 2e then the only predecessor < 0 > of ∅in Tn is labeled e, hence Te ∈WF
but p(n, l) = e for all l. The argument is similar for all cases when the node labeled
n has one predecessor in Tn. In the remaining case
n = 3 · 5e
for every l the number p(n, l) is the label of the l-th immediate predecessor < l > of
∅in Tn, hence Tp(n,l) ∈WF as required.
⇐. Assume n = 0∨(R(n) & ∀l(Tp(n,l) ∈WF)). If n = 0 then Tn consists only of
∅. Assume R(n)&∀l(Tp(n,l) ∈WF)) and consider cases in R(n). Since p(n, l) covers
all predecessors of ∅in Tn, we have Tn ∈WF as required.
⊢
Lemma 4. n ∈S 1 iﬀR0(n)& Tn ∈WF.

328
Grigori Mints
Proof. ⇐. Prove by bar induction on Tn that for every node a ∈Tn with a label
m ∈{0, 2e, 3 · 5e}, m ∈S 1 and
for every node with a label 3·5e·7x+1·11y+1 such that T(e, x, y) is true, U(y) ∈S 1
and
for every node with a label 3 · 5e · 7x+1 · 11y+1 such that ¬T(e, x, y) there is a
z > y such that T(e, x, z)&R0(U(z)).
Note that every label in Tn has one of these forms since otherwise the node
generates an inﬁnite branch in the tree.
2. If n ∈S 1 then Tn is well-founded. Proved similarly by transﬁnite induction
on the inductive deﬁnition of S 1.
⊢
We see that S 1 is primitive recursive in an inductively deﬁned relation.
3
System ID1ϵ
The language L1 has individual variables denoted by x, y, z, x1, . . ., a monadic sym-
bol I for inductively deﬁned predicates, constant 0, succesor function symbol S, all
primitive recursive predicates including equality = and Boolean connectives, say
→, ¬. ¯It := ¬It.
There are no quantiﬁers, but ϵ-terms ϵxF[x] are formed for all formulas F[x] of
this language. Quantiﬁers are deﬁned, and these deﬁnitions determine a translation
Fϵ of the arithmetical formulas with quantiﬁers into the ϵ-language:
(∃xF[x])ϵ := Fϵ[ϵxFϵ[x]];
(∀xF[x])ϵ := Fϵ[ϵx¬Fϵ[x]]
Recall that there is an inverse translation of ϵ-terms back into the language with
quantiﬁers:
A[ϵxF[x]] ⇐⇒(∀x¬F[x]&A[0]) ∨∃x(F[x]&(∀y < x)¬F[y]&A[x])
(40)
The terms are ϵ-terms, numerals Sn0 and expressions S nx for variables x and n ≥0.
ID1ϵ has all axioms and inference rules of ﬁrst order logic with equality, all
substitution instances of deﬁning axioms for the predicate constants including the
predicates of addition and multiplication, Peano axioms for successor S,
Hilbert’s minimality axioms
ϵxF[x] = St →¬F[t],
and critical formulas for ϵ and S:
F[t] →F[ϵxF[x]]

Epsilon Substitution for ID1
329
s , 0 →F[ϵxF[x]] with F := (s = Sx)
Special for ID1ϵ are critical formulas:
A[I, t] →It
(41)
and axiom schema TI of transﬁnite induction:
(∀x(A[F, x] →F[x]))ϵ&It →F[t]
(42)
where
A[I, x] ≡(∀y(x = 0 ∨(R(x)&Ip(x, y))))ϵ
(43)
for a primitive recursive p(x, y) and R from Section 2.
One proves in a standard way that that the system ID1ϵ is equivalent to the
system ID(S 1) with inductive deﬁnition for S 1 from Section 2.
4
System GID1ϵ
The system GID1ϵ operates with ϵ-substitutions for ID1ϵ. Let’s deﬁne them and
extend some deﬁnitions from [6].
Note that in ϵ-language we can express p(x, y) in (43) by the term ϵzP(x, y, z)
where P is the graph of the function p(x, y).
4.1
ϵ-substitions and Computations with Them
Deﬁnition 5. A closed ϵ-term is canonical if it does not contain proper closed
ϵ-subterms or expressions It with a closed term t.
Canonical expressions are canonical ϵ-terms and expressions In, ¯In with a nu-
meral n.
Eps denotes the set of all canonical ϵ-terms. The rank rk(t) of a term t is a
measure of nesting of bound variables.
Deﬁnition 6. rk(t) = 0 if t does not contain ϵ.
For a canonical term t ≡ϵxF[x, t1[x], . . . , tk[x]] where t1[x], . . . , tk[x] are all
subterms containing only x free,
rk(t) := max(rk(t1[x]), . . . , rk(tk[x])) + 1.
For a non-canonical closed term t[s1, . . . , sn] where s1, . . . , sn are all closed proper
ϵ-subterms,
rk(t[s1, . . . , sn]) := max(rk(s1), . . . , rk(sk), rk(t[0, . . . , 0])).
rk(F) for a closed formula F is the maximum of ranks of closed ϵ-subterms of F.

330
Grigori Mints
Deﬁnition 7. A component is any expression of the form
(e, ?), (e, n), In, ¯In
where e is a canonical ϵ-term, n is a numeral.
An ϵ-substitution is a ﬁnite set of components which is a function on ϵ-terms,
i.e., (e, v), (e, v′) ∈S implies v = v′.
The domain domS consists of all ϵ-terms e such that (e, v) ∈S plus all expres-
sions In, ¯In in S .
For a given substitution S that does not contain components In, ¯In with the same
n, computation under S goes by replacing ϵ-terms and expressions In, ¯In according
to S .
Deﬁnition 8. If (e, n) ∈S then t[e] ,→S t[n] for any term or formula t;
If (e, ?) ∈S then t[e] ,→S t[0];
If In ∈S then t[In] ,→S t[0 = 0] for any term or formula t;
If ¯In ∈S then t[In] ,→S t[0 = 1] for any term or formula t.
We use the same symbol ,→S for multi-step reduction.
A ,→S TRUE(FALSE) means that A reduces to a true (false) ϵ-free closed
formula which does not contain expression In.
The default extension ¯S of the substitution S is the result of adding all compo-
nents (ϵzP(m, n, z), k) for k = p(m, n) and (e, ?) for all remaining canonical ϵ-terms
not in domS , as well as components In for all n such that ¯In < S .
For computations with ¯S the same rules are used.
Lemma 9. If an ϵ-substitution S does not contain In, ¯In then every term or formula
t has a unique normal (irreducible) form
||[1]S
with respect to reduction ,→S . When S has values for all needed subterms (for
example S = ¯U for some substitution U) then ||[1]S is a numeral for a closed term
t and ||[1]S ∈TRUE or ||[1]S ∈FALSE for any closed formula F.
Proof. The proof is standard, since reductions do not overlap and are performed
“from inside”.
⊢
Deﬁnition 10. F[[n]] := F[n]&¬F[n −1]& . . . &¬F[0]
A substitution S is correct if for every (ϵxF[x], n) ∈S
(F[[n]] ,→S TRUE)

Epsilon Substitution for ID1
331
Let F (S ) :≡{F[[n]] : (ϵxF[x], n) ∈S }.
A solution (or solving substitution) for a system E of critical formulas is a cor-
rect substitution S making E true:
E ,→S TRUE
Deﬁnition 11. Let S be a substitution. We say that an expression e is S -computable
(or that S computes e) iﬀ||[1]S does not contain closed ϵ-terms or closed expres-
sions It.
S is computing iﬀif for every (ϵxF[x], n) ∈S the formula F[[n]] is S -
computable.
S is deciding with respect to a system E of critical formulas iﬀS is computing
and all critical formulas in E are S -computable.
4.2
Terms e(t), Virtual Critical Formulas, Rule He,n
With the function p(x, y) expressed by the term ϵzP(x, y, z) the formula A in our
inductive deﬁnition takes the form:
A[I, x] ≡(∀y(x = 0 ∨(R(x)&IϵzP(x, y, z))))ϵ
Let’s denote
B[I, y, x] :≡(x = 0 ∨(R(x)&IϵzP(x, y, z)))
e(t) := ϵy¬B[I, y, t];
e(F, t) := ϵy¬B[F, y, t]
Then we have
A[I, x] ≡B[I, e(x), x],
axiom (41) becomes
B[I, e(x), x] →Ix,
and schema (42) becomes ﬁrst
(A[F, X] →F[X]) →(It →F[t])
where X := ϵx¬(A[F, x] →F[x]), then
(B[F, e(F, X), X] →F[X]) →(It →F[t]).
Now let a ﬁnite system of critical formulas
E :≡{Cr0, . . . ,CrN}
(44)

332
Grigori Mints
be ﬁxed. Our goal is to arrive to a solving substitution for E by a process of gen-
erating new substitutions beginning with the empty substitution ∅by an extension
of the method in [6]. This process includes construction of a certain inﬁnite deriva-
tion (cf. Introduction and Section (5.2) below) and applying cut-elimination to this
derivation.
Deﬁnition 12. A sequent is an expression
Γ; Σ
where Γ is a substitution, Σ is a ﬁnite set of components.
For Θ ≡Γ; Σ we write
Θf := Γ (the ﬁxed part),
Θa := Σ (the added part),
F (Θ) := F (Θ f ) cf. Deﬁnition 10.
The maximal rank of components in Θf is called the rank of the sequent Θ and
denoted rk(Θ).
A sequent Θ is called computing (deciding, correct, solving, etc.) if the substi-
tutiton Θf has this property.
Cut-elimination steps will transfer some of the cut formulas to the added part to
constitute (together with the ﬁxed part) a pool for choosing a solving substitution.
Another useful heuristic is to translate components (ϵxF[x], n) of Θf as F[[n]],
then back into ﬁrst order arithmetic by (40), so that the resulting formulas in arith-
metic have the quantiﬁer complexity corresponding to ranks of ϵ-terms. A compo-
nent (ϵxF[x], ?) is translated into ∀x¬F[x] with further translation of F[x].
Corresponding “reading” of the added part
Θa = c1, . . . , cn
is an existential (i.e., Σ0
1)-formula: there is a solution (of the system E) consisting
of (not necessary all) components c1, . . . , cn. Under such reading adding a new
component to Θa can be treated as a new instantiation of a Σ0
1-formula.
The ﬁrst-order part of the ϵ-substitution process adds new components (e, n)
when some critical formula “calls for it”.
Deﬁnition 13. Let S be a substitution, Cr ≡(F[t] →F[ϵxF[x]]) be a critical
formula or virtual critical formula (see below). Assume that Cr is S -computable
and Cr ,→S FALSE. Then ϵx||[1]S is called the H-term and
n := µm ≤||[1]S (F[m] ,→S TRUE)
is the H-value for S and Cr.
In this case we say that He,n (where e = ϵx|F[x]|) applies to S .

Epsilon Substitution for ID1
333
4.3
The rules of GID1ϵ
Derivable objects of GID1ϵ are sequents.
Deﬁnition 14 (Virtual critical formulas). For every critical formula
(∀x(A[F, x] →F[x]))ϵ&It →F[t]
in a given system E of critical formulas all formulas
¬(A[F, n] →F[n]) →¬(A[F, X] →F[X])
(45)
where X ≡ϵx¬(A[F, x] →F[x]) are virtual critical formulas for E.
For every critical formula A[I, t] →It all formulas
¬B[I, l, n] →¬B[I, e(n), n]
are virtual critical formulas.
Virtual critical formulas can be used in the He,n-proviso below to justify H-
steps, but are not required to be satisﬁed by the ﬁnal solving substitution.
He,n-proviso: there is a substitution S ⊆Γ, Σ and a critical formula Cr ∈E such
that e, n are the H-term and H-value for S and Cr.
Deﬁnition 15. A substitution S is contained in a sequent Γ; ∆is S ⊂Γ ∪∆.
Deﬁnition 16. A substitution S is computationally inconsistent (c.i.) if one of the
following three conditions is satisﬁed:
1. There is (ϵxF[x], n) ∈S such that F[[n]] ,→S FALSE;
2. In, ¯In ∈S for some n;
3. ¯I0 ∈S ;
Otherwise S is computationally consistent (c.c.).
Axioms:
AxF(Θ) if
Θf is c.i.;
AxS(Θ)
if Θ contains a solving substitution for E;
AxHe,n(Θ)
if He,n applies to Θf .

334
Grigori Mints
4.4
Inference rules
4.4.1
¯In, ϵ-rules
Γ; (e, ?), Σ
Γ; Σ
H;e
Γ; In, Σ
Γ; Σ
H;In
Γ; (e, k), Σ
Γ; Σ
He,k H(e,k)−
proviso
. . . ¯I|p(n, k)|, ¯In, Γ; Σ . . . k ∈IN
¯In, Γ; Σ
Cln
provided
n , 0, Rn ∈TRUE
Deﬁnition 17. A sequent Θ is negative if Θ f has components only of the form ¯Im.
A negative derivation is a derivation of a negative sequent by ¯In, ϵ-rules.
For a sequent Γ let Dn be the set of all negative derivations d of sequents ∆, ¯In
where ¯In belongs to the ﬁxed part and Γ f , In, ∆f is a substitution.
4.4.2
Other Rules
(e, ?), Γ; Σ . . .
(e, n), Γ; Σ . . .
(n ∈IN)
Γ; Σ
Cute
In, Γ; Σ
¯In, Γ; Σ
Γ; Σ
CutIn
. . .
q : ∆, ¯In
dq : ∆, In, Γ . . .
q ∈Dn
In, Γ
Ω
Γ, ¯In
. . .
q : ∆, ¯In
dq : ∆, Γ . . .
q ∈Dn
Γ
˜˜Ω
In more detail, the rule Ωderiving a sequent In, Γ has a separate premise for each
derivation q ∈Dn. The derivation of that premise is denoted by dq. Similarly for the
rule ˜Ω. Explicitly shown formulas In, ¯In belong to the ﬁxed parts of corresponding
sequents.
Deﬁnition 18. A deduction d ∈GID1ϵ from a set S of sequents is a well-founded
tree where each leaf is an axiom or an element of S and all passages are done by
the rules of inference.
r is a rank of a deduction if all cut formulas have rank < r.
A derivation is a deduction from ∅, that is only from the axioms.
An example. Assume n , 0, Rn ∈FALSE. Then the sequent
In

Epsilon Substitution for ID1
335
is derived by one application of the rule Ωin the following way:
axiom
∆, ¯In
∆, In, Γ
In
Indeed, conditions n , 0, ¬Rn imply that ¯In cannot be a principal formula of the
ClIn-rule in a negative derivation of ∆, ¯In. Such a derivation cannot contain AxHe,m
since ∆does not contain components (e, v) in the ﬁxed part. Hence the only pos-
sibilities for an axiom in such a derivation are either AxF with mi = 0, or AxS.
In both cases the component ¯In is redundant. This proves that the same derivation
derives ∆, as needed for the application of the Ω-rule.
5
Construction of the original derivation
Here we construct the tree of ﬁnite ϵ-substitutions mentioned in the Introduction.
The general idea here is the same as in [4],[6].
The construction begins with the empty sequent ∅. At each stage leaves of
the tree are extended (by the bottom-up application of Cut and similar rules) to
make them “more computed” until the axioms are reached. Subterms of the non-
computed (but needed) ϵ-terms of maximum rank and terms t in needed formulas
It are computed until such ϵ-terms and I-formulas can be reduced to a canonical
form and then computed.
Deﬁnition 19.
1. d(x) := d(0) := 0
2. d(pe1 . . . en) := d(e1) + . . . + d(en), for p , I
3. d(It) := 1 + d(t) if t is closed
4. d(ϵxF) :=

1 + d(F)
if ϵxF is closed
d(F)
otherwise.
Note. d(e) < ω.
Deﬁnition 20.
dr(F) :=

0
if rk(F) < r
d(F)
otherwise.
In particular if φ is a formula of rank 0 then d0(φ) is the number of subformulas
of the form In in φ.
Note that the following deﬁnitions are stated for a given substitution S , and not
for its completion S .

336
Grigori Mints
Deﬁnition 21. Let S be an ϵ-substitution and Φ a ﬁnite set of closed formulas.
ρS (Φ) := max{rk(|A|S ) : A ∈Φ, d(|A|S ) > 0} ∪{0},
νS (Φ) := ω · r + #S (Φ, r) where r = ρS (Φ),
#S (Φ, r) := dr(|A1|S ) + . . . + dr(|An|S ),
where Φ = {A1, . . . , An} without repetitions.
Note that
ρS (Φ) < ω, #S (Φ, r) < ω, νS (Φ) < ω2.
Lemma 22. If S ⊆S ′ then
ρS ′(Φ) ≤ρS (Φ) and νS ′(Φ) ≤νS (Φ).
Proof. Easy to check.
⊢
Lemma 23. (Extension by Cute)
Let S be an ϵ-substitution and Φ a ﬁnite set of closed formulas.
Let e = ϵξF < dom(S ) be a canonical ϵ-subterm of a formula ||[1]S with
A0 ∈Φ, rk(||[1]S ) = ρS (Φ).
Let u ∈IN ∪{?}, S ′ := S ∪{(e, u)}, and
Φ′ :=
if u = ? then Φ else Φ ∪{F[[u]]}.
Then ρS ′(Φ′) ≤ρS (Φ) and νS ′(Φ′) < νS (Φ).
Proof. Since S ⊆S ′, we have ||[1]S ′ = ||[1]S ′ and thus rk(||[1]S ′) ≤rk(||[1]S ),
d(||[1]S ′) ≤d(||[1]S ) for each w.
Let r := ρS (Φ) and r′ := ρS ′(Φ′).
One easily sees that r′ ≤r.
Let r′ = r (for r′ < r the claim is trivial: νS ′(Φ′) < ω · (r′ + 1) ≤ω · r).
For each A ∈Φ we have rk(||[1]S ′) ≤rk(||[1]S ), d(||[1]S ′) ≤d(||[1]S ) and thus
dr(||[1]S ′) ≤dr(||[1]S ).
Moreover ||[1]S is S ′-reducible and rk(||[1]S ) = r.
Hence dr(||[1]S ′) <
dr(||[1]S ).
⊢
Deﬁnition 24. We refer to the construction of the previous Lemma as bottom-up
application of the rule Cute to decide the term e = ϵξF.
Lemma 25. (Extension by CutIn)
Let S be an ϵ-substitution and Φ a ﬁnite set of closed formulas.
Let In < dom(S ) be a subformula of a formula |A0|S with
A0 ∈Φ, rk(|A0|S ) = ρS (Φ).
Let I′ be either In or ¯In, S ′ := S ∪{I′}.
Then ρS ′(Φ) ≤ρS (Φ) and νS ′(Φ) < νS (Φ).

Epsilon Substitution for ID1
337
Proof. Similar to the previous Lemma.
⊢
Lemma 26. (ρ-rank reduction) Let Θ be a sequent, L a ﬁnite set of closed formulas,
and r := ρΘ(F (Θ) ∪L).
Then there is a deduction d of Θ by cuts of ranks ≤r from computing sequents
Υ containing Θ and computing all formulas in L. Moreover, for the ordinal height
h(d) of this deduction we have
h(d) ≤νΘ(F (Θ) ∪L).
Proof. Proof by induction on νΘ(F (Θ) ∪L):
Let Φ := F (Θ) ∪L. If Θ computes all formulas in Φ we are done. Otherwise
there exists either
1. a canonical subterm e = ϵξF of a formula ||[1]Θ with
A0 ∈Φ, rk(||[1]Θ) = r, or
2. a number n such that In occurs in ||[1]Θ with A0 ∈Φ, rk(||[1]Θ) = r.
In the ﬁrst case let u ∈IN ∪{?} and Θ′ := (e, u), Θ. Then we have
F (Θ′) =
if u =? then F (Θ) else F (Θ) ∪{F[[u]]}.
We have r′ := ρΘ′(F (Θ′) ∪L) ≤r and νΘ′(F (Θ′) ∪L) < νΘ(F (Θ) ∪L).
Hence (by I.H.) there exists a deduction du of Θ′ by cuts of ranks ≤r′ from
computing sequents Υ containing Θ′ and computing all formulas in L, and h(du) ≤
νΘ′(F (Θ′) ∪L).
Application of Cute yields the desired deduction d.
In the second case apply CutIn in a similar way.
⊢
5.1
Substitution Operation and TI-axiom
We need an analog of the substitution operation In/F[n] in Takeuti-Buchholz’ treat-
ment of ID
d : ∆[I], ¯In
Γ, (∀x(A[F, x] →F[x]))ϵ, ∆[F], ¬F[n] S
where d ∈Dn. However the conclusion of this ﬁgure violates our syntax: formulas
(∀x(A[F, x] →F[x]))ϵ, ¬F[n] are not legal components. We “cut out” these formu-
las requiring that they should be false under the given substitution. To treat the ﬁrst
of them we use abbreviation X :≡ϵx¬(A[F, x] →F[x]).

338
Grigori Mints
Lemma 27. If
d : ¯In1, . . . , ¯Ink; Σ
d negative
and
(A[F, X] →F[X]) ,→Γ TRUE,
(46)
F[n1] ,→Γ FALSE, . . . , F[nk] ,→Γ FALSE
(47)
then
Γ; Σ is derivable.
Proof. Induction on d. We abbreviate:
¯In := ¯In1, . . . , ¯Ink;
Applying if needed suitable cuts bottom-up we can assume that Γ decides every
subterm t of the following formulas (that is |t|Γ is a numeral):
A[F, X] →F[X],
(48)
and for every i ∈{1, . . . , k} and n = ni
A[F, m] →F[m]
all m ≤n,
(49)
B[F, j, n] ≡R(n) ∨F[p(n, j)]
all j ≤l := |e(F, n)|Γ.
(50)
If (A[F, n] →F[n]) ,→Γ FALSE then since (X, ?) ∈Γ by (46), Γ is AxHX,m for
some m ≤n, and we are done, hence we can assume
(A[F, n] →F[n]) ,→Γ TRUE.
(51)
Together with F[n] ,→Γ FALSE this implies
A[F, n] ≡R(n) ∨F[p(n, e(F, n))] ,→Γ R(n) ∨F[p(n, l)] ,→Γ FALSE,
and hence
Rn ∈FALSE and F[p(n, l)] ,→Γ FALSE.
(52)
Induction base. ¯In; Σ is an axiom. Since the f-part is ¯In, the sequent can be
AxF only if n = ni = 0 for some i. Then we use disjunct n = 0 in
A[F, n] ≡(n = 0 ∨(Rn&F[p(n, e(F, n))]) ,→Γ TRUE
Hence by (51) F[0] ,→Γ TRUE contradicting (47). If given sequent is AxS then
every sequent, in particular Γ; Σ is AxS with the same justiﬁcation.
Induction step for the rules other than Cln follows from IH: apply the same rule.

Epsilon Substitution for ID1
339
Suppose the derivation d ends in Cln inference:
. . . ¯Ip(n, j), ¯In, ¯In; Σ . . .
¯In, ¯In; Σ
Cln
By (52) the induction hypothesis is applicable with j = l = |e(F, n)|Γ.
⊢
Lemma 28. The TI-axiom is derivable, more precisely:
If (A[F, X] →F[X]) ,→Γ TRUE, It ,→Γ TRUE and F[t] ,→Γ FALSE then Γ is
derivable.
Proof. Use the previous Lemma.
⊢
5.2
Original Derivation
Theorem 29. There exists an r < ω and a derivation d of the empty sequent with
rank r + 1.
Proof. Note that because of the Ω-rule we do not have an estimate of the height
of d without using ordinal notation systems involving a constant for the cardinal Ω
(cf. [8]).
First apply Lemma 26 to the empty sequent and the set L := E := {Cr0, ...,CrN}
(Cf. (44)). Let r := ρ∅(L) and let d′ be the resulting r+1-deduction. Consider an
arbitrary top sequent Θ in d′ which is not an axiom. Then Θ is c.c., nonsolving and
deciding: it computes all formulas in E. Since the only inferences in d′ changing
the f-part are cuts of rank ≤r, and the endsequent is ∅, rk(e) ≤r for each e ∈
dom(Θf ). We show how to extend Θ to an axiom. Since Θ is nonsolving we have
Cr ,→Θ FALSE
(53)
for some formula Cr ≡Cri, 0 ≤i ≤n. Consider the possible cases.
1. Cr ≡(F[t] →F[ϵxF]).
Let e := ϵxA for A := ||[1]Θ. We have F[t] ,→Θ TRUE and F[e] ,→Θ FALSE.
Since Θ is deciding, ||[1]Θ = |e| ¯Θ and (e, v) ∈Θ for some v. Then (e, ?) ∈Θ,
since (e, k) ∈Θ implies F[e] ,→Θ F[k] ,→Θ FALSE then Θ is an axiom AxF.
Let n := ||[1]Θ. Since Θ is not an axiom AxH, it follows that some of the
formulas in
L′ := {A[n−1], . . . , A[0]}
are not computed. We have ρΘ(F (Θ) ∪L′) ≤r. Apply Lemma 26 to Θ, L′ and
consider any c.c. top sequent Υ of the resulting r+1-deduction. Υ contains Θ and

340
Grigori Mints
computes all formulas in L′. Assuming that Υ is c.c., this means that Υ is an axiom
AxHe,v with
v := µk ≤n(A[k] ,→Υ TRUE).
2. Cr ≡(A[I, t] →It) ≡((t = 0 ∨(Rt&Ip(t, e(t)))) →It).
Let n = ||[1]Θ. Since Θ is decided, ||[1]Θ is a natural number and e(n) ∈
dom(Θ). We have
A[I, n] ≡(n = 0 ∨(Rn&Ip(n, e(n)))) ,→Θ TRUE,
(54)
In ,→Θ FALSE, which implies ¯In ∈Θ. If (e(n), l) ∈Θ for some l, then Θ is AxF by
(54). Otherwise
(e(n), ?) ∈Θ.
(55)
If n = 0, the sequent Θ is AxF since ¯In ∈Θ. Otherwise, since Rn ∈TRUE by
(54), apply the rule Cln bottom-up resulting in premises Θl ≡Θ, ¯Ip(n, l) for all l.
Each of Θl that is not AxF satisﬁes ¬B[I, l, n] ,→Θl TRUE. In view of (55), the
sequent Θl can be extended to AxH(e(n),l) for a virtual critical formula ¬B[I, l, n] →
¬B[I, e(n), n].
3. Cr is a TI-axiom. Apply Lemma 28.
⊢
6
Cut Elimination
Deﬁnition 30. A derivation d is cut-free if it does not contain Cute, CutIn, i.e.,
rk(d) = 0. A derivation d is completely cut-free if it does not contain Cute, CutIn
and ˜Ω.
Theorem 31 (The Structure of derivations). 1. A completely cut-free derivation of
∅is a ﬁnite sequence of H-inferences beginning with AxS.
2. A cut-free derivation of ∅contains only sequents of the form
¯In; Σ
It contains at most , ClIn, ˜Ω, H-rules applied to the a-part, axioms AxS, and axioms
AxF of the form ¯I0, Γ; Σ.
Proof. 1. Since there are no cuts or ˜Ωand the endsequent is ∅, the f-part (followed
from the bottom-up) stays empty. Hence only H-rules are applied, and the whole
(well-founded) ﬁgure is ﬁnite. AxH, AxF require non-empty f-part, and hence the
only possible axiom is AxS.
2. Now ClIn and ˜Ωcan contribute to the f-part (followed from the bottom-up),
and axioms ¯I0, Γ; Σ can appear, but Ω-inference is impossible.
⊢

Epsilon Substitution for ID1
341
Theorem 32 (Collapsing). Every cut-free derivation of a negative sequent Γ can be
transformed into a completely cut-free derivation of Γ by deleting some sequents.
Proof. By transﬁnite induction on the derivation. ˜Ω-inferences are eliminated in
a standard way. The leftmost premise is a negative sequent derived by a negative
derivation q0. Collapse ˜Ωto the corresponding derivation dq0.
⊢
Theorem 33. Any derivation can be transformed into a cut-free derivation of the
same sequent.
Any derivation of a negative sequent Γ can be transformed into a completely
cut-free derivation of Γ.
Proof. Induction on cut-rank. Rank m + 1 is reduced to m for m > 0 in a way
standard for the ϵ-substitution method ([6] and especially [5], sections 3.2,3.3):
AxHe,n
(e, ?), Γ; Σ
... d
(e, ?), Π; Φ
... d′
(e, n), Π; Φ
Π; Φ
Cute
is replaced by
... d′ ∗Γ; Σ
Γ, Π; (e, n), (e, ?), Σ, Φ
Γ, Π; (e, ?), Σ, Φ
He,n
... d
Π; (e, ?), Φ
Π; Φ
H;e,?
where ∗Γ; Σ means adding Γ; Σ with suitable adjustments. In particular Cute(n) is
treated in a standard way.
I-cut (the case of m = 0)
d0 : In, Γ; Σ
d1 : ¯In, Γ, Σ
Γ; Σ
is pushed up along the In-premise till it meets an Ω-inference and becomes an
˜Ω-inference unless it meets axioms.
Important case: d0 ends in an He,k inference:
d00
In, Γ; (e, k), Σ
d0 : In, Γ; Σ
He,k

342
Grigori Mints
Then the cut is pushed over He,k inference, but a H;In inference is added to ensure
that the relevant critical formula is still computed:
d00∗; In
In, Γ; (e, k), In, Σ
¯In, Γ; Σ
Γ; (e, k), In, Σ
He,k
Γ; In, Σ
H;In
Γ; Σ
If d0 is an axiom AxF with {In, ¯In} ⊆In, Γ then Γ, Σ is the endsequent of d1 since
¯In, Γ = Γ.
d0 cannot be an axiom AxHe,k since m = 0, and hence Γ contains no components
(e, ?) while Deﬁnition 13 implies that (e, ?) ∈Γ.
Cuts with remaining axioms result in axioms of the same kind.
This leads to a cut-free derivation. Then collapsing is applied.
⊢
References
[1] T. Arai, Epsilon substitution method for ID1(Π0
1 ∨Σ0
1). Ann. Pure Appl. Logic
121, No.2-3, 163-208 (2003).
[2] W. Buchholz, Explaining the Gentzen-Takeuti Reduction Steps, Arch. Math.
Logic, 40, pp. 255-272, 2001
[3] S. Kleene, On notation for ordinal numberrs, J. Symb. Log., 3, 150-155, 1938
[4] G. Mints, Gentzen-type Systems and Hilbert’s Epsilon Substitution Method. I.
In: D. Prawitz, B.Skyrms, D. Westerstahl (Eds.), Logic, Method. and Philos.
of Sci. IX, Elsevier, 1994, 91-122
[5] G. Mints, Cut Elimination for a Simple Formulation of Epsilon Calculus,
APAL 152, 2008, 148-160
[6] G. Mints, S. Tupailo, W. Buchholz, Epsilon Substitution Method for Elemen-
tary Analysis, Archive for Math. Logic 35 (1996) 103-130
[7] G. Mints, Non-deterministic substitution method for ID1, submitted to
Gentzen volume
[8] W.Pohlers, Proof theory : the ﬁrst step into impredicativity, Cambridge Uni-
versity Press, 2009
[9] Rogers H., Theory of Recursive Functions and Eﬀective Computability,
McGraw-Hill, New York, 1967

Another Unique Weak K¨onig’s Lemma WKL!!
Joan Rand Moschovakis
For Helmut Schwichtenberg, with respect and appreciation for his encourage-
ment and friendship.
In [2] J. Berger and Ishihara proved, via a circle of informal implications in-
volving countable choice, that Brouwer’s Fan Theorem for detachable bars on
the binary fan is equivalent in Bishop’s sense to various principles including
a version WKL! of Weak K¨onig’s Lemma with a strong eﬀective uniqueness
hypothesis. Schwichtenberg [9] proved the equivalence directly and formal-
ized his proof in Minlog. We verify that his result does not require countable
choice, and derive a separation principle SP from the Fan Theorem, in a mini-
mal intuitionistic system M of analysis with function comprehension.
In contrast, WKL!! comes from Weak K¨onig’s lemma WKL by adding
the hypothesis that any two inﬁnite paths must agree. WKL!! is interderivable
over M with the conjunction of a consequence of Markov’s Principle and the
double negation of WKL. This decomposition is in the spirit of Ishihara’s [4]
and J. Berger’s [1]. Kleene’s function realizability and the author’s modiﬁed
realizability establish that WKL!! is strictly weaker than WKL and strictly
stronger than WKL!.
1
Preliminaries
As in [8] let IA1 be a two-sorted theory with number variables a, b, c, . . . and
choice sequence variables α, β, γ, . . . (with or without subscripts); Kleene’s ﬁnite
list ([6], [5]) of constants for particular primitive recursive functions and function-
als, with their deﬁning axioms; Church’s λ, parentheses denoting function appli-
cation, and the axiom schema of λ-reduction; the single relation constant = for
number-theoretic equality, with the axioms of reﬂexivity, symmetry and transitiv-
ity; the open equality axiom x = y →α(x) = α(y); mathematical induction for all
formulas of the two-sorted language; and intuitionistic two-sorted logic. Let M

344
Joan Rand Moschovakis
result from IA1 by adding the function comprehension schema AC00!:
∀x∃!yA(x, y) →∃α∀xA(x, α(x)).1
This is the “minimal” theory of [5], which Kleene used to formalize the theory
of recursive partial functionals and his function-realizability for intuitionistic anal-
ysis. Pairs (x, y) and ﬁnite sequences ⟨x0, . . . , xk⟩of natural numbers are coded
and decoded primitive recursively; if u, v code sequences then u ∗v codes their
concatenation, and lh(u) is the length of the sequence coded by u.
Finite ini-
tial segments of α are denoted by α(0) = ⟨⟩= 1 (the empty sequence code) and
α(n + 1) = ⟨α(0) . . . , α(n)⟩.
G. Vafeiadou has shown that M is essentially equivalent to Troelstra’s EL plus
an axiom schema CFd asserting that every decidable relation on the natural numbers
has a characteristic function (cf. [8]). It seems natural to choose M as a basis for
general studies of constructive entailment.
Proposed Terminology. Two schemas E and F will be called constructively
equivalent if every instance of each is derivable in M from instances of the other.
If every instance of F is derivable in M from instances of E, then E constructively
entails F (and F is a constructive consequence of E).
The tree of all ﬁnite sequences of 0s and 1s is called the binary fan. Let 2∗
abbreviate the set of all codes of ﬁnite binary sequences, and 2N the set of all inﬁnite
binary sequences, so w ∈2∗↔∃α ∈2N[w = α(lh(w))] and α ∈2N ↔∀xα(x) ≤1.
In M, a classically and intuitionistically correct statement of Brouwer’s Fan
Theorem for detachable bars on the binary fan is FTd:
∀α ∈2N∃xρ(α(x)) = 0 →∃y∀α ∈2N∃x ≤yρ(α(x)) = 0.
Intuitionistic mathematics also accepts the full Fan Theorem FT:
∀α ∈2N∃xR(α(x)) →∃y∀α ∈2N∃x ≤yR(α(x)),
with no restrictions on the predicate R(w) except for the obvious ones on the vari-
ables. Classically (but not constructively), FT and FTd are interderivable with each
other and with the restriction KL of K¨onig’s Lemma to the binary fan.
WKL or “Weak K¨onig’s Lemma,” which plays a signiﬁcant role in reverse con-
structive mathematics, is the restriction of K¨onig’s Lemma to detachable subtrees
of the binary fan. Formally, WKL is obtained from KL by adding a decidability
hypothesis so WKL is constructively equivalent to
∀y∃α ∈2N∀x ≤yρ(α(x)) = 0 →∃α ∈2N∀xρ(α(x)) = 0.
1In general, ∃!yB(y) abbreviates ∃yB(y) & ∀y∀z(B(y) & B(z) →y = z). With intuitionistic logic,
AC00! is weaker than countable choice AC00 (without the “!”).

Another Unique Weak K¨onig’s Lemma WKL!!
345
Adding a strong eﬀective uniqueness hypothesis gives a principle WKL!:
∀y∃α ∈2N∀x ≤yρ(α(x)) = 0
& ∀α ∈2N∀β ∈2N[∃xα(x) , β(x) →∃xρ(α(x)) , 0 ∨∃xρ(β(x)) , 0]
→∃α ∈2N∀xρ(α(x)) = 0.
which is constructively equivalent to FTd.2
J. Berger’s and Ishihara’s round-robin proof in [2] of the equivalence of WKL!
with FTd implicitly used (monotone) countable choice to provide a modulus of
uniform continuity for an arbitrary uniformly continuous real-valued function on
Cantor space; however, their proof that WKL! entails FTd was constructive in the
present sense. Schwichtenberg ([9]) gave a direct proof of the equivalence in a
language which anticipated conversion to a Minlog program; he then carried out
the formalization in Minlog. His proof that Fan (his version of FTd) entails WKL!
used an auxiliary proposition PFan concerning pair nodes, but did not appear to use
countable choice.
To verify that WKL! holds in M + FTd, Section 2 of this note introduces and
uses a separation principle SP which follows constructively from FTd. The remain-
ing sections develop a third version WKL!! of Weak K¨onig’s Lemma which is
strictly intermediate in strength between WKL! and WKL from the present con-
structive standpoint.
2
Veriﬁcation that FTd constructively entails WKL!
The proof of FTd from WKL! in [2] and [9] evidently does not need countable
choice, so can be formalized in M. The reverse entailment also holds constructively,
as we now verify.
Lemma 1. FTd constructively entails the separation principle
SP :
∀α ∈2N∀β ∈2N[∃x ρ(α(x)) , 0 ∨∃x σ(β(x)) , 0]
→∀α ∈2N∃x ρ(α(x)) , 0 ∨∀β ∈2N∃x σ(β(x)) , 0.
Proof. The proof requires an abbreviation for the fair merge of two sequences. For
α, β ∈2N or NN and for n ∈N, let [α, β](2n) = α(n) and [α, β](2n + 1) = β(n).
Every function τ which is deﬁned on the set 2∗= {0, 1}∗of codes of ﬁnite binary
sequences and takes values in {0, 1}, with the properties
2In this case, since both WKL! and FTd are open axioms with just the variable ρ free, their construc-
tive equivalence means that their universal closures are provably equivalent in M.

346
Joan Rand Moschovakis
(a) τ(⟨⟩) = 0 and
(b) ∀u ∈2∗∀v ∈2∗(τ(u ∗v) = 0 →τ(u) = 0),
is the characteristic function of a detachable subtree Tτ = {u ∈2∗|τ(u) = 0} of the
binary tree 2∗. Conversely, every detachable subtree of 2∗is Tτ for a unique such
τ. Thus (the universal closure of) FTd is constructively equivalent to (the universal
closure of)
τ(⟨⟩) = 0 & ∀u ∈2∗∀v ∈2∗(τ(u ∗v) = 0 →τ(u) = 0)
→[∀α ∈2N∃xτ(α(x)) , 0 →∃y∀α ∈2Nτ(α(y)) , 0].
Now assume ∀α ∈2N∀β ∈2N[∃x ρ(α(x)) , 0 ∨∃x σ(β(x)) , 0]. If ρ(⟨⟩) , 0 or
σ(⟨⟩) , 0 there is nothing to prove. If ρ(⟨⟩) = σ(⟨⟩) = 0, deﬁne τ ∈22∗so that
τ(u) = 0 if and only if either
∃α ∈2N∃β ∈2N∃k ≤lh(u)[u = [α, β](2k)
& ∀j ≤k ρ(α(j)) = 0 & ∀j ≤k σ(β(j)) = 0] or
∃α ∈2N∃β ∈2N∃k < lh(u)[u = [α, β](2k + 1)
& ∀j ≤k + 1 ρ(α(j)) = 0 & ∀j ≤k σ(β(j)) = 0].
Then τ is the characteristic function of a subtree of 2∗and ∀γ ∈2N∃y τ(γ(y)) , 0
by the hypothesis of the lemma, so by FTd: ∃y∀γ ∈2Nτ(γ(y)) , 0. Let y be a
witness; since τ(γ(y)) , 0 →τ(γ(y + 1)) , 0, we may assume y = 2k for some k.
Then
(∗)
∀α ∈2N∀β ∈2N[∃x ≤k ρ(α(x)) , 0 ∨∃x ≤k σ(β(x)) , 0],
and there are only ﬁnitely many u ∈2∗with lh(u) ≤k. Suppose for contradiction
that ∃α ∈2N∀x ≤k ρ(α(x)) = 0 & ∃β ∈2N∀x ≤k σ(β(x)) = 0. Then [α, β] ∈2N &
∀x ≤2k τ([α, β](x)) = 0, contradicting (*). So
∀α ∈2N∃x ≤k ρ(α(x)) , 0 ∨∀β ∈2N∃x ≤k σ(β(x)) , 0,
and the lemma is proved.
□
Proposition 2. FTd constructively entails WKL!

Another Unique Weak K¨onig’s Lemma WKL!!
347
Proof. Assume ρ satisﬁes the two hypotheses ∀y∃α ∈2N∀x ≤yρ(α(x)) = 0 and
∀α ∈2N∀β ∈2N[∃xα(x) , β(x) →∃xρ(α(x)) , 0 ∨∃xρ(β(x)) , 0] of WKL!. For
w ∈2∗deﬁne
τ(w) = 0 ↔∀u ≤w∀v ≤w(w = u ∗v →ρ(u) = 0),
otherwise τ(w) = 1. Then τ satisﬁes (a) and b from the proof of Lemma 1, hence
(c) ∀y∃α ∈2N τ(α(y)) = 0 and
(d) ∀α ∈2N∀β ∈2N[∃xα(x) , β(x) →∃xτ(α(x)) , 0 ∨∃xτ(β(x)) , 0].
Claim: ∀n∃!u ∈2n∀y∃α ∈2N τ(u ∗α(y)) = 0.
Basis: n = 0. Then ∀y∃α ∈2N τ(⟨⟩∗α(y)) = 0 by (c), and u = ⟨⟩is the unique
element of 20.
Ind. Step: If there is a unique u ∈2n such that ∀y∃α ∈2N τ(u ∗α(y)) = 0, then
(e) ∀y[∃α ∈2Nτ(u ∗⟨0⟩∗α(y)) = 0 ∨∃β ∈2Nτ(u ∗⟨1⟩∗β(y)) = 0] by (c),
and
(f) ∀α ∈2N∀β ∈2N[∃x τ(u ∗⟨0⟩∗α(x)) , 0 ∨∃x τ(u ∗⟨1⟩∗β(x)) , 0] from
(b) and (d). Hence by SP (which follows constructively from FTd by Lemma 2):
(g) ∀α ∈2N∃x τ(u ∗⟨0⟩∗α(x)) , 0 ∨∀β ∈2N∃x τ(u ∗⟨1⟩∗β(x)) , 0.
First consider the case ∀α ∈2N∃x τ(u ∗⟨0⟩∗α(x)) , 0. If τ(u ∗⟨0⟩) , 0 then
∀y∃β ∈2Nτ(u ∗⟨1⟩∗β(y)) = 0 and ¬∀y∃α ∈2Nτ(u ∗⟨0⟩∗α(y)) = 0 by (e) and
(b). If τ(u ∗⟨0⟩) = 0 then (a) and (b) hold with λv.τ(u ∗⟨0⟩∗v) in place of τ and
so by FTd there is a z such that ∀α ∈2N∃x ≤z τ(u ∗⟨0⟩∗α(x)) , 0, whence
∀y∃β ∈2Nτ(u ∗⟨1⟩∗β(y)) = 0
and ¬∀y∃α ∈2Nτ(u ∗⟨0⟩∗α(y)) = 0 by (e) and (b). Hence if
∀α ∈2N∃x τ(u ∗⟨0⟩∗α(x)) , 0
then u ∗⟨1⟩is the unique element w of 2n+1 such that ∀y∃α ∈2Nτ(w ∗α(y)) = 0.
Similarly, if ∀β ∈2N∃x τ(u ∗⟨1⟩∗β(x)) , 0 then u ∗⟨0⟩is the unique element
w of 2n+1 such that ∀y∃α ∈2Nτ(w ∗α(y)) = 0. Thus the induction step is complete
and the claim is established.
Now apply AC00! to obtain a (unique) γ such that
∀n[γ(n) ∈2n & ∀y∃α ∈2Nτ(γ(n) ∗α(y)) = 0].
For each n let δ(n) be the last element of the sequence of length n + 1 coded by
γ(n + 1).3 A straightforward induction now shows that ∀n(γ(n) = δ(n)), whence
∀n τ(δ(n)) = 0 and ∀xρ(δ(x)) = 0. So WKL! is indeed a constructive consequence
of FTd.
□
3Using the formal versions of Kleene’s coding ⟨a0, . . . , an⟩= pa0+1
0
· . . . pan+1
n
of ﬁnite sequences,
where pi is the ith prime number with p0 = 2, and decoding in which (v)i is the exponent of pi in the
prime factorization of v, the precise deﬁnition of δ is δ(n) = (γ(n + 1))n ˙−1.

348
Joan Rand Moschovakis
3
A stronger version of Weak K¨onig’s Lemma with
uniqueness
By weakening the uniqueness requirement in the hypothesis of WKL! to the (clas-
sically, but not constructively, equivalent) demand that any two witnesses to the
conclusion must be equal, we obtain the schema WKL!!:
∀y∃α ∈2N∀x ≤yρ(α(x)) = 0
& ∀α ∈2N∀β ∈2N[∀xρ(α(x)) = 0 & ∀xρ(β(x)) = 0 →∀xα(x) = β(x)]
→∃α ∈2N∀xρ(α(x)) = 0.
Evidently WKL constructively entails WKL!!, and WKL!! constructively entails
WKL!. Hence WKL!! constructively entails FTd.
To show that FTd does not entail WKL!! and that WKL!! does not entail
WKL, we ﬁrst decompose WKL!! into a logical principle and a mathematical one,
following the example of Ishihara’s decomposition [4] of WKL and Berger’s [1] of
WKL!. Then we use this decomposition, with Kleene’s function-realizability [6]
and the author’s Grealizability [7], to ﬁnish the argument.
4
WKL!! is constructively equivalent to MP∨+ ¬¬WKL
In [3] Ishihara introduced a “disjunctive version of Markov’s Principle” MP∨:
¬¬∃x(α(x) , 0 ∨β(x) , 0) →¬¬∃xα(x) , 0 ∨¬¬∃xβ(x) , 0,
and used it in a decomposition of Markov’s Principle MP. Let “¬¬WKL” denote
the double negation of the open axiom WKL, i.e.
¬¬[∀y∃α ∈2N∀x ≤yρ(α(x)) = 0 →∃α ∈2N∀xρ(α(x)) = 0],
or equivalently
∀y∃α ∈2N∀x ≤yρ(α(x)) = 0 →¬¬∃α ∈2N∀xρ(α(x)) = 0.4
Theorem 3. WKL!! constructively entails MP∨.
4Since double negation does not commute constructively with universal quantiﬁcation, the universal
closure of ¬¬WKL is weaker than the double negation of the universal closure of WKL.

Another Unique Weak K¨onig’s Lemma WKL!!
349
Proof. Assume the hypothesis of MP∨:
(a) ¬¬∃x(α(x) , 0 ∨β(x) , 0), whence
(b) ¬(∀xα(x) = 0 & ∀xβ(x) = 0). If α(0) , 0 or β(0) , 0 the conclusion of
MP∨follows. Otherwise, deﬁne ρ(w) for w ∈2∗by setting ρ(w) = 0 if and only if
either
(i) w = λt.0(lh(w)) & ∀x < lh(w)(∀y < x α(y) = 0 →β(x) = 0), or
(ii) w = λt.1(lh(w)) & ∀x < lh(w)(∀y ≤x β(y) = 0 →α(x) = 0),
otherwise ρ(w) = 1. Then ρ satisﬁes the ﬁrst hypothesis of WKL!! because
(c) ρ(⟨0⟩) = ρ(⟨1⟩) = ρ(⟨⟩) = 0,
(d) ρ(u) = 0 →[u = λt.0(lh(u)) ∨u = λt.1(lh(u))],
(e) ρ(u ∗v) = 0 →ρ(u) = 0, and
(f) ∀y¬[ρ(λt.0(y)) = 1 & ρ(λt.1(y)) = 1].
If γ is a witness for the conclusion of WKL!!, then
(g) [γ(0) = 0 →∀xγ(x) = 0] & [γ(0) = 1 →∀xγ(x) = 1]; so either
(h) ∀xρ(λt.0(x)) = 0 & ¬∀xρ(λt.1(x)) = 0, in which case ¬∀xα(x) = 0, so
¬¬∃xα(x) , 0, or
(j) ∀xρ(λt.1(x)) = 0 & ¬∀xρ(λt.0(x)) = 0, in which case ¬∀xβ(x) = 0, so
¬¬∃xβ(x) , 0.
The second hypothesis of WKL!! follows, so WKL!! guarantees the existence of a
witness γ for its conclusion, hence the conclusion ¬¬∃xα(x) , 0 ∨¬¬∃xβ(x) , 0
of MP∨holds also.
□
Theorem 4. WKL!! constructively entails ¬¬WKL. In fact, WKL!! →¬¬WKL
is provable in M.
Proof. Assume (a) ∀y∃α ∈2N∀x ≤yρ(α(x)) = 0 and
(b) ¬∃α ∈2N∀xρ(α(x)) = 0. Then vacuously
(c) ∀α ∈2N∀β ∈2N[∀xρ(α(x)) = 0 & ∀xρ(β(x)) = 0 →∀xα(x) = β(x)],
so ρ satisﬁes the hypotheses of WKL!!, so WKL!! guarantees
(d) ∃α ∈2N∀xρ(α(x)) = 0, contradicting (b) and completing the proof.
□
Theorem 5. WKL!! is a constructive consequence of MP∨and ¬¬WKL.
Proof. Assume the hypotheses of WKL!!:
(a) ∀y∃α ∈2N∀x ≤yρ(α(x)) = 0 and
(b) ∀α ∈2N∀β ∈2N[∀xρ(α(x)) = 0 & ∀xρ(β(x)) = 0 →∀xα(x) = β(x)].
For each u ∈2∗, a primitive recursive binary functor u ∗λt.0 can be deﬁned by
(u ∗λt.0)(lh(u)) = u & ∀x ≥lh(u) (u ∗λt.0)(x) = 0,

350
Joan Rand Moschovakis
so (a) is equivalent to (a)′: ∀y∃u ∈2y ∀x ≤y ρ((u ∗λt.0)(x)) = 0. If we can prove
(∗)
∀n∃!u ∈2n ∀y∃v ∈2y ∀x < n + y ρ((u ∗v ∗λt.0)(x)) = 0,
then AC00! will guarantee ∃!α∀xρ(α(x)) = 0.
Let A(n, u, y) abbreviate u ∈2n & ∃v ∈2y ∀x < n + y ρ((u ∗v ∗λt.0)(x)) = 0.
We prove ∀n∃!u∀yA(n, u, y) by induction on n.
Basis. ∀yA(0, ⟨⟩, y) holds by (a)′ since ⟨⟩is the only sequence number of length
0. Hence ∃!u∀yA(0, u, y).
Induction Step. Assume ∃!u∀yA(n, u, y) and in particular assume ∀yA(n, u, y).
By ¬¬WKL:
(c) ∀yA(n + 1, u ∗⟨0⟩, y) →¬¬∃α ∈2N(∀xρ(α(x)) = 0 & α(n) = 0) and
(d) ∀yA(n + 1, u ∗⟨1⟩, y) →¬¬∃α ∈2N(∀xρ(α(x)) = 0 & α(n) = 1).
Suppose for contradiction
∀yA(n + 1, u ∗⟨0⟩, y) & ∀yA(n + 1, u ∗⟨1⟩, y).
Then by (c) and (d) (since double negation commutes with conjunction):
¬¬[∃α ∈2N(∀xρ(α(x)) = 0 & α(n) = 0) & ∃β ∈2N(∀xρ(β(x)) = 0 & β(n) = 1)]
so ¬¬∃α ∈2N∃β ∈2N(∀xρ(α(x)) = 0 & ∀xρ(β(x)) = 0 & α(n) , β(n)), hence
¬∀α ∈2N∀β ∈2N[∀xρ(α(x)) = 0 & ∀xρ(β(x)) = 0 →α(n) = β(n)] ,
contradicting (b). So
(e) ¬[∀yA(n + 1, u ∗⟨0⟩, y) & ∀yA(n + 1, u ∗⟨1⟩, y)], so if γ, δ are binary and
satisfy γ(y) = 0 ↔A(n + 1, u ∗⟨0⟩, y) and δ(y) = 0 ↔A(n + 1, u ∗⟨1⟩, y) then
¬[∀y γ(y) = 0 & ∀y δ(y) = 0],
so ¬∀y γ(y) = 0 ∨¬∀y δ(y) = 0 by MP∨, so
(f) ¬∀yA(n + 1, u ∗⟨0⟩, y) ∨¬∀yA(n + 1, u ∗⟨1⟩, y).
In the ﬁrst case ∀yA(n + 1, u ∗⟨1⟩, y) and in the second case ∀yA(n + 1, u ∗⟨0⟩, y),
by the induction hypothesis with (a)′. So ∃!v∀yA(n + 1, v, y), completing the proof
of (*).
□
5
Constructively, WKL!! lies strictly between WKL!
and WKL
Corollary 6. M +FTd does not prove WKL!!. In fact, Kleene and Vesley’s for-
mal system FIM for intuitionistic analysis, which extends M +FTd, does not prove
WKL!!.

Another Unique Weak K¨onig’s Lemma WKL!!
351
Proof. . In [7] a modiﬁed realizability notion (Grealizability) was introduced and
used to show the consistency of FIM with a weak form ∀α¬¬GR(α) of Church’s
Thesis, where GR(α) abbreviates ∃e∀x∃y[T(e, x, y) & U(y) = α(x)]. It follows that
every theorem of FIM, a fortiori every theorem of M + FTd, is Grealizable; and
every constructive consequence of Grealizable sentences is Grealizable.
But MP∨is not Grealizable, as we now demonstrate using notation and re-
sults from [7]. If σ Grealizes ∀α∀β[¬¬∃x(α(x) , 0 ∨β(x) , 0) →¬¬∃xα(x) , 0∨
¬¬∃xβ(x) , 0] then σ is recursive and F(α, β) = ({{{σ}[α]}[β]}[Λγ.λt.0](0))0 is
a continuous function of α and β with values in {0, 1}. If F(λt.0, λt.0) depends
only on λt.0(n), then if γ(n) = 1 and γ(x) = 0 for all x , n we must have
F(γ, λt.0) = F(λt.0, γ) = F(λt.0, λt.0). Since γ and λt.0 are recursive, the hy-
pothesis on σ requires that F(γ, λt.0) = 0 and F(λt.0, γ) = 1; contradiction. By
Theorem 3 it follows that WKL!! is not a constructive consequence of FTd, nor of
WKL! by [2].
□
Corollary 7. M + WKL!! does not prove WKL. In fact, FIM + WKL!! is consis-
tent relative to M and does not prove WKL.
Proof. Classically, MP∨and ¬¬WKL are Kleene function-realizable. Hence by
Theorem 5, with Theorem 9.3 of [6], every theorem of FIM + WKL!! is Kleene
function-realizable, and so FIM + WKL!!
is consistent relative to M by [5].
Kleene’s example ([6] Lemma 9.8) of an inﬁnite, recursive subtree of 2N with no
inﬁnite recursive branch shows that the universal closure of WKL is not realized
by any recursive function, since there are recursive functions ε and ρ such that ε
realizes-ρ ∀y∃α ∈2N∀x ≤yρ(α(x)) = 0 but there is no recursive function which
realizes-ρ ∃α ∈2N∀xρ(α(x)) = 0. Hence WKL is not a constructive consequence
of WKL!!.
□
References
[1] J. Berger. A decomposition of Brouwer’s fan theorem. Jour. Logic and Anal.,
1:1–8, 2009.
[2] J. Berger and H. Ishihara. Brouwer’s fan theorem and unique existence in
constructive analysis. Math. Log. Quart. 51:360–364, 2005.
[3] H. Ishihara. Markov’s principle, Church’s thesis and Lindel¨of’s theorem.
Indag. Mathem., N. S., 4:321–325, 1993.
[4] H. Ishihara. Constructive reverse mathematics: Compactness properties. From
Sets and Types to Topology and Analysis: Towards Practicable Foundations

352
Joan Rand Moschovakis
for Constructive Mathematics, L. Crosilla and P. Schuster, eds., Oxford Univ.
Press, 2005, 245–267.
[5] S. C. Kleene. Formalized recursive functionals and formalized realizability.
Memoirs, no. 89, Amer. Math. Soc., 1969.
[6] S. C. Kleene and R. E. Vesley. The foundations of intuitionistic mathematics,
especially in relation to recursive functions. North Holland, 1965.
[7] J. R. Moschovakis. Can there be no nonrecursive functions?
Jour. Symb.
Logic, 36:309–315, 1971.
[8] J. R. Moschovakis and G. Vafeiadou. Some axioms for constructive analysis.
Arch. Math. Logic, to appear, 2012.
[9] H. Schwichtenberg. A direct proof of the equivalence between Brouwer’s
fan theorem and K¨onig’s lemma with a uniqueness hypothesis. Jour. Uni-
versal Comp. Sci., 11:2086–2095, 2005.

The Continuous Functionals as Limit Spaces
Dag Normann
In this survey paper we introduce the Kleene-Kreisel continuous functionals via
the limit space characterization. We show how the density theorem, Kreisel’s
representation theorem with some applications and the continuity of the S1 -
S9 -computable functionals can be proved in this setting.
Then we see that the ﬁxed point construction of the Gamma-functional
and the fan functional use the unique ﬁxed point of total functionals. We in-
troduce the externally computable functionals via the domain representation
of the continuous functionals, and characterize them as the functionals obtain-
able from mu-recursion using certain ﬁxed point constructions. We restrict
ourselves to ﬁxed points of total functionals where the least ﬁxed point of the
domain representative itself is total. The ﬁnal argument is an adjustment of an
earlier construction due to the author.
1
Introduction
In [9], Kleene introduced what he called the countable functionals, and in [10],
Kreisel introduced what he called the continuous functionals.
Kleene’s countable functionals are not countable objects in the set theoretical
sense, but they can, to some extent, be described using countable means. They are
elements of the typed hierarchy of total functionals of pure type deﬁned as follows:
We let Tp(0) = N and, by recursion, Tp(k + 1) is the set of all total functions
mapping Tp(k) into N.
The countable functionals is a subclass of this hierarchy. They are deﬁned via the
associates, functions on N coding how the functional acts on countable arguments.
More precisely, we let elements of N and NN be their own associates, while for
higher types we consider the total functionals with realizers in the following variant
of Kleene’s second model:
f ◦g = m if f(¯g(t)) = m + 1 for the least t such that f(¯g(t)) > 0, if there is
such k.
f ◦g is undeﬁned otherwise.

354
Dag Normann
All elements in N and NN are countable, while for k > 0, Φ : Tp(k + 1) →N is
countable if Φ has an associate. An associate for Φ is an f ∈NN such that f ◦g = m
whenever g is an associate for some F ∈Tp(k) and Φ(F) = m.
An associate for a functional will only describe the action on inputs described by
associates, so an associate does not fully describe the object.
Kreisel’s continuous functionals are deﬁned for all ﬁnite types, not only the
pure ones. The ﬁnite types are deﬁned by the grammar
type σ
σ ::= 0 | (σ →σ).
We drop inessential parentheses. The intuition is that 0 is somehow interpreted
as the integers, while σ = δ →τ is interpreted as a class of functions from the
interpretation of δ to the interpretation of τ. Kreisel deﬁned, for each type, an
ordered class of formal neighborhoods. His continuous functionals are technically
equivalence classes of ideals of such neighborhoods. The only diﬀerence from
todays approach using domain theory is that he did not consider the neighborhoods
to be partial functionals themselves.
In spite of the diﬀerence in the set of types, and in the choice of domains for the
functionals in the models, the constructions were considered to be equivalent by
the two authors.
In [8] Kleene introduced his celebrated schemes S1 - S9 deﬁning what it means
to compute relative to any functional of any type. A key result in Kleene [9] is that
if Ψ is S1 - S9 -computable relative to the countable functionals Ψ1, . . . , Ψn, then
Ψ itself is countable.
It soon became more standard to work over the extensional collapse of Kleene’s
original structure of countable functionals, and this collapse is exactly what Kreisel
deﬁned in an alternative way when we restrict his deﬁnition to pure types. These
objects are still not countable in the set theoretical sense, but now they are at least
fully determined by any associate, so they are countably presented.
Kreisel’s motivation was to use the functionals for interpreting statements in
analysis, or second order number theory, and in particular to analyze the construc-
tive content of such statements. Of course it is then of importance that the proper-
ties of the functionals themselves can be expressed in the language of second order
number theory. To Kleene, it seemed to be a point that his objects can be coded
by number theoretical functions. In the original form, S1 - S9 cannot be expressed
in second order number theory, even for the countable functionals. This changed
with the restriction to the extensional collapse. We will use Ct(k) for the continuous
functionals of pure type k and Ct(σ) for the continuous functionals of the ﬁnite type
σ.

The Continuous Functionals as Limit Spaces
355
In the early days, the eﬀect of Kleene’s S1 - S9 on the continuous function-
als was investigated, see Normann [14] for a detailed account of the status of art
around 1980. There were important early contributions by Tait [22], Gandy, Hyland
[7, 5], Bergstra [2] and the author. Gandy inspired much of the research in the late
60’s and early 70’s. These investigations were mostly based on Kleene’s deﬁnition.
Kreisel deﬁned a functional to be recursive, or computable as we would say today,
if it is represented by a computably enumerable ideal. This kind of computability
is actually more powerful than Kleene’s notion, though having less complex deﬁni-
tions. It was one of the objectives of the research around 1980 to establish how the
two approaches to computability for continuous functionals relate. Tait [22] proved
that the fan functional, producing the modulus of uniform continuity of a continu-
ous function from Cantor space to N, is not computable in the sense of Kleene. It
is, however, computable in the sense of Kreisel.
One might think that it does not really matter if the objects we investigate are
countable functionals in the original sense of Kleene or continuous functionals in
the sense of Kreisel, but for the interpretation of Kleene’s S1 - S9 it certainly does.
The reason is that the interpretations of the scheme for applications of functionals
are not equivalent. Written without indices, the scheme is as follows:
If Ψ(y, x1, . . . , xn) is partially computable, y is a variable of type k and x1 is a
variable of type k + 2 then
Φ(x1, . . . , xn) = x1(λy.Ψ(y, x1, . . . , xn))
is partially computable.
The point is that the requirement of termination is that Ψ(y, x1, . . . , xn) terminates
for all y in the domain. If that domain consists of all total objects of type k, this re-
quirement is harder to satisfy than if it consists only of the hereditarily continuous
ones. This diﬀerence is reﬂected in the diﬀerent complexities of relative semicom-
putability for the two options. If 40 is the constant zero functional of type 4, any
complete Π1
2-set of integers will be semicomputable relative to 40 in the meager
world of hereditarily continuous functionals, while every set of integers semicom-
putable relative to 40 in the fat world of all total functionals will be Π1
1. Increasing
the type, the complexity in the ﬁrst case will increase, while it remains the same
in the second case. We will not give the full proof of this observation, but what
is behind it is a L¨owenheim - Skolem argument showing that a computation will
terminate in the full type structure if and only if it does so in all reasonably closed
countable hierarchies of functionals.
Another problem with Kleene’s original deﬁnition is that one associate may
represent several diﬀerent total functionals, and the eﬀect of S1 - S9 on functionals

356
Dag Normann
represented by the same associate may diﬀer. These two observations explain why
the hereditarily continuous functionals is a more natural environment for interpret-
ing S1 - S9 than the countable ones.
In 1969 Scott [21] constructed a typed structure of partial continuous function-
als, thereby inventing domain theory. Ershov [3] discovered the same structure in-
dependently, and proved that the continuous functionals can be characterized using
hereditarily total objects in this hierarchy. The typed structure of partial continuous
functionals is an important model for functional programming. This was the orig-
inal motivation of Scott, and his typed structure caught the interest of theoretical
computer scientists. In [17] the author surveyed the history of the theory of total
and partial continuous functionals, seen both as computability theory and theoreti-
cal computer science.
These days there are two standard constructions of the total continuous function-
als, using Kleene’s second applicative structure K2 and using Scott domains. It is
possible to see directly that the deﬁnitions are equivalent, but an alternative way to
establish this equivalence is using a joint characterization in terms of limit spaces.
Diﬀerent approaches trigger diﬀerent ways of thinking, and one of the main advan-
tages of the domain theoretical approach is the establishing of sequential algorithms
for total objects requiring partial objects in order to terminate. Berger [1] showed
how to compute the fan functional, Normann [16] extended this to other externally
computable functionals. More recently, Escard´o [4] have shown how quantiﬁcation
over some predicates and search for objects for which certain predicates are true,
can be computed sequentially in a reasonably eﬀective way.
In this paper we will ﬁrst develop the theory of continuous functionals in a way it
could have been developed, by taking the limit space approach as the prime one.
One advantage is that deﬁnitions and arguments get less technical this way. We
will introduce S1 - S9 and see how they give rise to continuous functionals without
introducing associates or domains. The paper is mainly a survey paper, there are
no new facts about the computability theory of the continuous functionals proved.
What is new, is that we show how much we can develop of the basic machinery
independently of representations. Towards the end, we will see how we may use
unique ﬁxed points of certain total continuous operators to construct all externally
computable functionals of any type. In order to give a complete description of
which ﬁxed points we accept as ﬁxed point computable, we need to introduce the
domain-theoretical construction of these functionals as well.

The Continuous Functionals as Limit Spaces
357
2
Limit spaces and the continuous functionals
In this section we will deﬁne the hierarchy of continuous functionals of ﬁnite types
within the category of limit spaces. We formulate the deﬁnition as a deﬁnition on
the pure types. It is not hard to extend the construction and main results to mixed
types as well, but there are two reasons why we concentrate on the pure types:
- All proofs will be notationally simpler and thus more easy to follow.
- One of our main interests is Kleene’s concept of computable functionals, and
this is deﬁned for the pure types.
We let 0 ∈N as a convention.
We will add ∞as a cluster point to N. We let ¯N be N ∪{∞}. We will write {xn}n∈N
for a sequence, and {xn}n∈¯N for a sequence with an alleged limit point. When we
use this notation, we will simply write x, and not x∞, for this alleged limit point.
Deﬁnition 1 (Kuratowski [11]). A Limit Space is a set X with a set L of sequences
{xn}n∈¯N from X (writing x = limn→∞xn for {xn}n∈¯N ∈L) such that
1. If xn = x for almost all n ∈N then
x = lim
n∈N xn.
(An almost constant sequence converges.)
2. If x = limn∈N xn and f : N →N is strictly increasing, then x = limn→∞xf(n).
(A subsequence of a convergent sequence is convergent.)
3. If {xn}n∈¯N < L then there is a strictly increasing function f : N →N such that
for no strictly increasing g : N →N we have that
x = lim
n→∞xf(g(n)).
(There is a subsequence such that no subsubsequence has x as a limit.)
For any topological space X, if L is the set of convergent sequences with limits
in X, then ⟨X, L⟩will be a limit space.
Conversely, a limit space ⟨X, L⟩will induce a topology deﬁned as follows: O ⊆
X is open if xi ∈O for all but ﬁnitely many i ∈N whenever x = limi→∞xi and
x ∈O. A limit space ⟨X, L⟩is topological if it is the limit space of its induced
topology. A topological space is sequential if it is the induced topology of its limit
space. We will only be concerned with topological limit spaces here.

358
Dag Normann
Deﬁnition 2. Let ⟨X, L⟩and ⟨Y, N⟩be two limit spaces. We deﬁne the set of contin-
uous functions and organize it to a limit space as follows:
a) Let F : X →Y. We let F ∈(X →Y), F is continuous, if
{F(xn)}n∈¯N ∈N whenever {xn}n∈¯N is in L.
b) When {Fn}n∈¯N is a sequence from X →Y, we let {Fn}n∈¯N ∈(L →N) if
{Fn(xn)}n∈¯N ∈N whenever {xn}n∈¯N ∈L.
It is a matter of routine to verify that ⟨(X →Y), (L →N)⟩will be a limit
space. The category where limit spaces are objects and continuous functions are
morphisms is cartesian closed, in contrast to the category of topological spaces. A
ﬁnite product of limit spaces is organized to a limit space by considering sequences
converging in each coordinate. The standard product of two sequential spaces is
not always sequential, so it is important that products are taken in the category of
limit spaces.
We will now deﬁne the continuous functionals as the canonical typed hierarchy
of limit spaces with N at the base:
Deﬁnition 3. We let Ct(0) = N where the convergent sequences are exactly those
obeying the ﬁrst axiom.
We let Ct(k + 1) consist of all continuous functions from Ct(k) to N with the limit
structure of Deﬁnition 2.
We will end this section by oﬀering an easy, but important characterization of
the convergent sequences.
Deﬁnition 4. Let {an}n∈N be an inﬁnite sequence from N. A modulus for this se-
quence is a number n such that ∀m ≥n(am = an).
Let {Fn}n∈¯N be a sequence from Ct(k + 1).
G : Ct(k) →N is a modulus function for the sequence if G(x) is a modulus for
{Gn(x)}n∈N for each x ∈Ct(k), or spelled out:
∀x ∈Ct(k)∀n ≥G(x)(Fn(x) = F(x)).
Clearly, the existence of a modulus function is equivalent to pointwise conver-
gency of the sequence. We have
Lemma 5. Let {Fn}n∈¯N be a sequence from Ct(k + 1). Then the following are
equivalent:
1. F = limn→∞Fn in the sense of the limit space.

The Continuous Functionals as Limit Spaces
359
2. There is a continuous modulus function for the sequence.
Proof. 2. ⇒1. is trivial, so let F = limn→∞Fn, and let
G(x) = µn.∀m ≥n(F(x) = Fm(x)).
It suﬃces to prove that G is continuous, so let x = limn→∞xn be given. We will
prove that G(x) = limn→∞G(xn) by contradiction, so assume that this is not the
case. Then there is a subsequence {xnj} j∈N such that one of two will hold:
i) {G(xnj)} j∈N is a constant sequence diﬀerent from G(x).
ii) {G(xnj)}j∈N is strictly increasing.
i) is impossible since F and each Fi are continuous. ii) is impossible since ii)
implies that F is not the limit of {FG(xn j)−1} j∈N, violating axiom 2. of limit spaces.
□
Remark 6. The limit space characterization of the continuous functionals has its
roots in Scarpellini [20]. We have used his characterization as our basic deﬁnition.
3
The ﬁne structure
A topological space is separable if it contains a countable, dense subset. In this
section we will, for each k, construct a countable subset of the limit space Ct(k)
that is dense in the following strong sense: We will show that we, uniformly in any
object x ∈Ct(k), can compute a sequence {(x)n}n∈N from this set converging to x.
Though we postpone the discussion of what we might mean by being computable
to the next sections, our construction will be so explicit that the computability is
indisputable:
Deﬁnition 7.
If x ∈N and x ≤n we let (x)n = x.
If x ∈N and n < x we let (x)n = n.
If x ∈Ct(k + 1) and y ∈Ct(k) we let (x)n ∈Ct(k + 1) be deﬁned by
(x)n(y) = (x((y)n))n.
Lemma 8.
a) If x ∈Ct(k) and n ≤m ∈N then
((x)m)n = (x)n.

360
Dag Normann
b) For each k ∈N and n ∈N, the set
{(x)n | x ∈Ct(k)}
is ﬁnite.
Proof. a) is trivial by induction on k. The simplest, and most instructive, way to
prove b) is to consider the sets Finn(k) deﬁned by recursion:
Finn(0) = {0, . . . , n}
Finn(k + 1) = { f | f : Finn(k) →Finn(0)}.
For each type we construct a total embedding ek,n : Finn(k) →Ct(k) and a total
projection pk,n : Ct(k) →Finn(k) by simultaneous recursion as follows:
- e0,n(m) = m
- p0,n(m) = m if m ≤n while p0,n(m) = n if n < m.
- ek+1,n(φ)(g) = φ(pk,n(g)) where φ ∈Finn(k + 1) and g ∈Ct(k).
- pk+1,n(ψ)(f) = p0,n(ψ(ek,n(f))) where ψ ∈Ct(k + 1) and f ∈Finn(k).
Then the range of ek,n is exactly the set {(x)n | x ∈Ct(k)}.
□
An element in Ct(k) is said to be of ﬁnite character if it is of the form (x)n for
some n ∈N. By the previous lemma, the set of functionals of ﬁnite character of
any ﬁxed type is countable.
Lemma 9. Let x = limn→∞xn be a convergent sequence from Ct(k).
Then
x = lim
n→∞(xn)n.
Proof. We use induction on k. For k = 0, this is trivial, so assume that the lemma
holds for k and let F ∈Ct(k + 1) be the limit of the sequence {Fn}n∈N. Let x =
limn→∞xn in Ct(k).
By the induction hypothesis and the deﬁnition we have
F(x) = lim
n→∞Fn((xn)n) = lim
n→∞(Fn((xn)n))n = lim
n→∞(Fn)n(xn).
By deﬁnition then, F = limn→∞(Fn)n.
□

The Continuous Functionals as Limit Spaces
361
We say that a set Y in a limit space⟨X, L⟩is dense if every x ∈X is the limit of
a sequence from Y. Thus this lemma shows that the countable set of functionals of
ﬁnite character of a ﬁxed type is dense.
Throughout, we will let {ξk
i }i∈N be an eﬀective enumeration of the functionals
of type k of ﬁnite character. We show how to do this in a primitive recursive way:
We may enumerate Finn(k) uniformly in n and k such that the application operator
on Finn(k+1)×Finn(k) is uniformly primitive recursive. We may enumerate Finn(k)
by, using recursion on k, identifying the function
f : {0, . . . , m −1} →{0, . . . , n}
with the number
m−1
X
i=0
f(i) · (n + 1)i.
Composing these enumerations with the embeddings ek,n and the projections pk,n
yields the result. Further details are left for the reader.
Remark 10. Both Kleene and Kreisel proved that there will be computably enumer-
able dense subsets at each type. Kleene proved this by showing that the set of ﬁnite
sequences that can be extended to an associate is computable. Kreisel showed that
all his formal neighborhoods are elements of total ideals and gave an algorithm
for constructing such ideals. Since we have not based our deﬁnition on associates
or neighborhoods, we of course do not obtain this, so in a sense our result is not
as strong as the original density theorems by Kleene and Kreisel. On the other
hand, our proof is technically simpler. Moreover, we obtain that we can compute
the sequence from this dense set converging to an object uniformly from the object
itself. Of course, this can be achieved by a closer analysis of the original proofs
by Kleene and by Kreisel, while their full theorems can be obtained elaborating on
our argument as well. After all it is mainly a matter of choice of exposition.
Deﬁnition 11. Let F ∈Ct(k + 1). The trace of F is the function
hF(i) = F(ξk
i ).
Since two continuous functions into N that agree on a dense set will be equal,
the trace of F determines F completely. This is not new, what is of interest here is
that using the limit space approach, we get to this trace in a cheap way. The next
result originates from Kreisel [10] and we ad no new insight compared to existing
proofs. Thus we just state the result. Recall that a Π1
k set is a set deﬁnable from an
arithmetical set using k alternating quantiﬁers over NN, starting with ∀f. A Σ1
k-set
is the complement of a Π1
k-set.

362
Dag Normann
Theorem 12. Let A ⊆NN be Π1
k where k ≥1. Then there is a primitive recursive
predicate R such that
f ∈A ⇔∀F ∈Ct(k)∃n ∈N R(n, f, hF).
The proof is by induction on k ≥1, and, as an intermediate step, one proves
Theorem 13. Let B ⊆NN be Σ1
k where k ≥1. Then there is a primitive recursive
predicate S such that
1. f ∈B ⇔∀G ∈Ct(k + 1)∃n ∈N S (n, f, hG)
2. If f < B there is a G f ∈Ct(k + 1) uniformly computable in f such that
∀n ∈N ¬S (n, f, hG f ).
3. The map f 7→G f is extended to a partial computable function in such a way
that
f 7→hG f
is total.
Proofs can be found in the original paper [10], and in Normann [14, 15]
Remark 14. We still have not deﬁned what we mean by being computable. However,
the algorithm used in the proof of Theorem 13 is based on the use of the µ-operator,
and this use will be covered by our internal concept.
Let (x)n be the n’th approximation to x, where x ∈Ct(k) for some k > 0. We
know that there will be a modulus function for the sequence {(x)n}n∈N. Now we will
see that we may compute this modulus function uniformly in x. We will use the
µ-operator.
Observation 15. Given a sequence {Fn}n∈N of functionals and a modulus function
G for the sequence, we can compute the least modulus function H from the data at
hand by
H(x) = µn ≤G(x)∀m(n ≤m ≤G(x) ⇒Fn(x) = Fm(x)).
Lemma 16. Let x ∈Ct(k) for some k ∈N.
Then the modulus function Mk for
x = lim
n→∞(x)n,
where x varies over Ct(k), is uniformly µ-recursive.

The Continuous Functionals as Limit Spaces
363
Proof. We use induction over k, where the cases k = 0 and k = 1 are trivial. The
induction step is generalized in Lemma 17, and we leave the rest of the proof for
this
□
Let σ be a ﬁnite type. We deﬁne Ct(σ) in the category of limit spaces in the
obvious way. The level of the type 0 is 0, while, by recursion, the level of δ →τ
is the maximum of the level of τ and 1 + the level of δ. One reason why we
concentrate on the pure types is that when the level of σ is bounded by k, then
Ct(σ) can be viewed as a computable retract of Ct(k). We will not need the details
of this.
4
Kleene computability
Kleene [8] deﬁned a global relation
{e}(Φk1
1 , . . . , Φkn
n ) ≃a
where e, n, ki vary over N and we let Φki
i vary over Tp(ki). a may either be in N
or undeﬁned, and ≃means that either both sides are undeﬁned or both sides are
deﬁned and equal. When we use =, we mean that both sides are deﬁned and equal.
The deﬁnition is by a positive induction, using nine clauses known as the schemes
S1 - S9.
In the deﬁnition, we will let x and y be natural numbers. We will ignore the su-
perscripts ki indicating the arity of the {e}, but of course, {e} will have diﬀerent
interpretations for diﬀerent arities. In some expositions, the arity is coded into the
index e.
S1 If e = ⟨1⟩then {e}(x, Φ2, . . . , Φn) = x + 1.
S2 If e = ⟨2, q⟩then {e}(Φ1, . . . , Φn) = q.
S3 If e = ⟨3⟩then {e}(x, Φ2, . . . , Φn) = x.
S4 If e = ⟨4, e1, e2⟩then
{e}(Φ1, . . . , Φn) ≃{e1}({e2}(Φ1, . . . , Φn), Φ1, . . . , Φn).
S5 If e = ⟨5, e1, e2⟩then
{e}(0, Φ2, . . . , Φn) ≃{e1}(Φ2, . . . , Φn)
{e}(x + 1, Φ2, . . . , Φn) ≃{e2}(x, {e}(x, Φ2, . . . , Φn), Φ2, . . . , Φn).

364
Dag Normann
S6 If e = ⟨6, d, τ(1), . . . , τ(n)⟩where τ is a permutation of {1, . . . , n}, then
{e}(Φ1, . . . , Φn) ≃{d}(Φτ(1), . . . , Φτ(n)).
S7 If e = ⟨7⟩then {e}(x, f 1, Φ3, . . . , Φn) = f(x)
S8 If e = ⟨8, e1⟩then
{e}(Φk+2
1
, Φ2, . . . , Φn) ≃Φ1(λξk{e1}(ξ, Φ1, . . . , Φn)).
S9 If e = ⟨9, m⟩where 2 ≤m ≤n, then
{e}(d, Φ2, . . . , Φn) ≃{d}(Φ2, . . . , Φm).
- {e}(Φ1, . . . , Φn) is undeﬁned otherwise.
In a sense, S9 axiomatizes the existence of a universal algorithm. The S m
n -theorem
can be proved, and the recursion theorem follows. As we have claimed before,
S1 - S9 preserves continuity. We will give a proof on the basis of the limit space
deﬁnition, but need a lemma that goes back to Grilliot [6]:
Lemma 17. Let Φ = limt→∞Φt with a modulus function Ψ be of type k + 1 and
F = limt→∞Ft with a modulus function G be of type k (just a modulus, if k = 0).
Then we can compute the least modulus of {Φt(Ft)}t∈N with limit Φ(F) uniformly in
the data.
Proof. If k = 0, the lemma is trivial, so let k > 0 and let x vary over elements of
Ct(k −1) and y over elements of Ct(k). We deﬁne Hn of type k and Θn of type k + 1
as follows:
Hn(x) = Ft(x) for the least t such that n ≤t ≤G(x) and Φt(Ft) , Φ(F) if
there is such t.
Hn(x) = F(x) if there is no such t.
Θn(y) = Φt(y) for the least t such that n ≤t ≤Ψ(y) and Φt(Ft) , Φ(F) if
there is such t.
Θn(y) = Φ(y) if there is no such t.
Claim
Φ(F) , Θn(Hn) ⇔∃t ≥n(Φ(F) , Φt(Ft))
and in this case
(Θn, Hn) = (Φt, Ft)

The Continuous Functionals as Limit Spaces
365
for the least such t.
Proof of Claim: It is easy to see that if Φ(F) = Φt(Fn) for all t ≥n, then H = F and
Θ = Φ.
Let t ≥n be minimal such that Φ(F) , Φt(Ft). In the deﬁnition of Hn(x) we see that
either will t ≤G(x) and we let Hn(x) = Ft(x) or t > G(x), and we let Hn(x) = F(x),
which will be Ft(x) since t > G(x).
By the same argument, we get that Θn(y) = Φt(y) for all y.
This ends the proof of the claim.
From the information given in the claim, we can compute the least modulus of the
sequence using the µ-operator.
□
We do not use that Ψ and G are continuous in this proof, but since the least
modulus function of a convergent sequence from Ct(k) is continuous, we cannot
expect to make use of this observation.
Theorem 18. Assume that
{e}(Φ1, . . . , Φn) ≃a
and that
Φi = lim
t→∞Φi,t
with modulus functions Ψi for i = 1, . . . , n. Assume further that
{e}(Φ1,t, . . . , Φn,t) ≃at
for each t ∈N.
Then a = limt→∞at, and we can compute the modulus uniformly in the data.
Proof. We use the recursion theorem to provide the uniform algorithm, and we use
induction on the ordinal rank of the computation tree for {e}(Φ1, . . . , Φn) in order
to prove that the algorithm works.
Our construction of the algorithm is by 9 cases, following S1 - S9. In the case of
S8 we use Lemma 17 and the other cases are trivial in view of Observation 15. We
leave the details for the reader.
□
Remark 19. The µ-operator is S1 - S9 -computable. This is so, because the re-
cursion theorem is available from S1 - S9. There are actually good reasons for
replacing S9 with a scheme Sµ (see below) for the µ-operator. The main reason in
this context is that there is hardly any need for the full enumeration scheme, the µ-
operator seems always to be suﬃcient for the positive applications. Kleene’s origi-
nal motivation for introducing S1 - S9 was to investigate transﬁnite deﬁnability, e.g.

366
Dag Normann
generalizing the hyperarithmetical hierarchy to a hyperanalytical hierarchy. In this
endeavor, S9 is essential. His motivations for introducing the countable functionals
might be to understand S1 - S9 -computability better. Thus, when we now see the
continuous functionals as a mathematical structure of interest in itself, it may be
that replacing S9 with Sµ gives us a more natural concept of computing. Bergstra
[2] showed that S9 is strictly stronger than Sµ over the continuous functionals in
the context of S1 - S8.
Sµ: If e = ⟨10, d⟩, then
{e}(Φ1, . . . , Φn) ≃µx({d}(x, Φ1, . . . , Φn) = 0)
with the standard interpretation of µx for partial functions.
5
Fixed point deﬁnability
In the previous section we showed that Kleene’s deﬁnition of computability can be
deﬁned and justiﬁed without any reference to representing associates or ideals, i.e.
without introducing algorithms on approximations to the continuous functionals.
We do know, however, that there are externally computable objects that are not
Kleene computable. In this section we will deﬁne a class that we call ﬁxed point
deﬁnable functionals. We will discuss a few examples from the literature on the
continuous functionals. It turns out that if we try to use ﬁxed point constructions
as a tool for deﬁning new functionals, there is a serious risk for us to get too much.
We will come back to this.
5.1
Examples
Since Platek’s thesis [19], partial functionals and the least ﬁxed point operator have
been important tools in the computability theory of functionals. We will see, by
considering some special and general examples, that we do not need the super-
structure of partial functionals in order to construct ﬁxed points. The simple idea,
standard in topology, is that if ∆: Ct(k) →Ct(k) is continuous with certain contrac-
tion properties, then we may ﬁnd a ﬁxed point as the limit of the iterated sequence
∆n(F), where F ∈Ct(k) is arbitrarily chosen. We aim at proving the existence of
such ﬁxed points avoiding domain theory or other means of representations, but of
course, we will essentially give the same proofs when we imitate a theorem known
from domain theory. One of the methods is bar induction, in its most crude form:
Deﬁnition 20. If ⃗s = (s0, . . . , sk−1) is a sequence from N, we let
B⃗s = {f : N →N | ∀i < k(f(i) = si)}.

The Continuous Functionals as Limit Spaces
367
Let F ∈Ct(2). Let TF = {⃗s | F is not constant on B⃗s.}
TF will be a well founded tree, and by bar induction we will mean induction
on the ordinal rank of this tree. Since the map F 7→TF is not even continuous, our
version of bar induction is not constructive, and there is no corresponding form of
bar recursion.
5.1.1
Gandy’s Gamma-function
We deﬁne the functional Γ of pure type 3 by the equation
Γ(F) = F0(λx ∈N.Γ(Fx+1)),
where Fx(f) = F(x∗f) and ∗is concatenation. If we try to compute Γ using the
recursion theorem, we simply get the everywhere undeﬁned function. However,
using the partial functionals, it is easy to see that there is an object satisfying this
equation, there is a ﬁxed point of the functional
∆Γ(Φ)(F) = F0(λn.Φ(Fn+1)).
We will see that this can be established directly on the basis of our approach via
limit spaces.
Claim 1. ∆Γ has at most one ﬁxed point.
Proof. If Γ1 and Γ2 are two ﬁxed points, we see that for each object F = (F)m of
ﬁnite character we have that Γ1(F) = Γ2(F). This is proved by induction on the
complexity of F, or by induction on m. If two continuous functions into N agree
on a dense set, they are equal.
□
Claim 2. There exists a Γ ∈Ct(3) that is a ﬁxed point of ∆Γ.
Proof. We can prove a much stronger statement. Let F = limn→∞Gn be a conver-
gent sequence from Ct(2) and let Γ0 be an arbitrary element of Ct(3). We see by
bar induction on F that
lim
n→∞∆n
Γ(Γ0)(Gn)
exists, and is independent of {Gn}n∈N.
Moreover, we may prove, also by bar
induction, that there is a modulus for this sequence, independent of Γ0.
Thus
Γ = limn→∞∆n
Γ(Γ0) is well deﬁned and continuous, and with some modulus func-
tion independent of Γ0.
The details of the argument are left for the reader.
□

368
Dag Normann
5.1.2
The fan functional
The fan functional discussed in the introduction will be the functional Φ ∈Ct(3)
deﬁned by
Φ(F) is the least n such that whenever f and g in {0, 1}N agree on the n ﬁrst
arguments 0, . . . , n −1, then F(f) = F(g).
Φ is well deﬁned because a continuous F will be uniformly continuous on the
compact topological space {0, 1}N, and it is easy to see that Φ is continuous, using
that any sequence on {0, 1}N will have a convergent subsequence.
Tait [22] proved that Φ is not Kleene computable in the original sense, while Berger
[1] showed that there is a partial continuous representation of Φ that is computable
in the Scott sense. We will transform Berger’s proof to a ﬁxed point representation
of Φ. In order to do so, we must ﬁrst deﬁne a test function δ : Ct(2) →Ct(1) that
for every F ∈Ct(2) will check if F is constant on the Cantor space or not.
Let
δ(F) =

0ω
if
F(0ω) = F(0∗δ(F0)) = F(1∗0ω) = F(1∗δ(F1))
1∗δ(F1)
if
F(0ω) = F(0∗δ(F0)) = F(1∗0ω) , F(1∗δ(F1))
1∗0ω
if
F(0ω) = F(0∗δ(F0)) , F(1∗0ω)
0∗δ(F0)
if
F(0ω) , F(0∗δ(F0))
δ is the unique ﬁxed point of the operator
∆δ(η)(F) =

0ω
if
F(0ω) = F(0∗η(F0)) = F(1∗0ω) = F(1∗η(F1))
1∗η(F1)
if
F(0ω) = F(0∗η(F0)) = F(1∗0ω) , F(1∗η(F1))
1∗0ω
if
F(0ω) = F(0∗η(F0)) , F(1∗0ω)
0∗η(F0)
if
F(0ω) , F(0∗η(F0))
It follows by induction on the rank of TF restricted to 0 - 1 -sequences that
lim
n→∞∆n
δ(δ0)
exists, is independent of δ0 and has a continuous modulus function for the sequence,
independently of δ0.
We can then deﬁne the fan functional Φ, via the equation
Φ(F) =
(
0
if F(0ω) = F(δ(F))
max{Φ(F0), Φ(F1)} + 1
otherwise,
as the ﬁxed point of a total operator ∆Φ. This ﬁxed point will be the unique limit
of sequences ∆n
Φ(Ψ), where a continuous modulus function for {∆n
Φ(Ψ)}n∈N can be
found independently of Ψ. This ends the construction.

The Continuous Functionals as Limit Spaces
369
In the examples above, we have taken the liberty to deﬁne functionals of several
typed variables as unique ﬁxed points of basic computable operators ∆, and the ∆’s
in question have to take functionals of mixed types as arguments in order for the
constructions to make sense. We may, however, redeﬁne each ∆as an operator on
some Ct(k), using the fact that the interpretation of a type is a computable retract
of the interpretation of the pure type of the same level
5.2
Fixed points
We will now use the experience from the examples considered.
Deﬁnition 21. Let ∆: Ct(k) →Ct(k) be continuous.
We say that ∆is a contractor if
i) limn→∞∆n(F) exists in Ct(k) for all F ∈Ct(k), and the limit is independent
of F.
ii) There is a continuous modulus function for {∆n(F)}n∈N independently of F ∈
Ct(k).
Remark 22. If ∆is of type Ct(k) →Ct(k) and k > 0, it makes perfect sense to
say that ∆is Kleene computable, since ∆can be viewed as a function from Ct(k) ×
Ct(k −1) to N.
Remark 23. The existence of a contractor does not make the space contractive in
the standard sense of topology. Still, the intuition is that a contractor ∆will bring
any point closer to the unique ﬁxed point, in the sense that, like we have in ﬁxed
point theory for metric spaces, any iteration of ∆will bring any point as close to
the ﬁxed point as we like.
We will explore the following concept, a concept that seems natural from the
point of view of the category of limit spaces:
Deﬁnition 24. We deﬁne the class of ﬁxed point deﬁnable functionals as the least
class of functionals closed under µ-recursion, that is S1 - S8, Sµ, and in addition
satisfying
Let ∆: Ct(k) →Ct(k) be ﬁxed point deﬁnable and a contractor.
Then the unique ﬁxed point of ∆is ﬁxed point deﬁnable.
We use the term deﬁnable, and not computable for the elements of this class,
since there is no genuine mentioning of internal algorithms in the deﬁnition. In
fact, there will be non computable ﬁxed point deﬁnable functions, and in order to
use the extraction of ﬁxed points as a means for extending the class of computable
functionals in the limit space approach, we must put further restrictions on the set
of contractors that we consider.

370
Dag Normann
5.3
The overﬂow
The class of ﬁxed point deﬁnable functionals has far too liberal closure properties
for our purposes. We prove a general theorem, and a consequence will be that the
set of functions f : N →N that are ﬁxed point deﬁnable will be closed under the
jump operator.
Theorem 25. Let {Φn}n∈N be a ﬁxed point deﬁnable sequence from Ct(k) and as-
sume that
Φ = lim
n→∞Φn.
Then Φ is ﬁxed point deﬁnable.
Proof. If k = 0, there is nothing to prove, so we let k > 0, and we let x range over
Ct(k −1).
We will show that the least modulus function for the sequence will be ﬁxed point
deﬁnable, and thus Φ will be so.
If {ai}i∈N is a sequence from N, we let
mod n({ai}i∈N) be the least number m such
that
∀i(m ≤i ≤n ⇒ai = an).
This approximation to the modulus will of course be bounded by n.
Now let ξ : N × Ct(k −1) →N. We deﬁne ∆by
∆(ξ)(n, x) =
mod max{n+1,ξ(i,x)|i≤n+1}({Φi(x)}i∈N).
Let Ψ be the minimal modulus functional for the given sequence. For any x, ξ and
n ≥Ψ(x) we see that ∆(ξ)(n, x) = Ψ(x).
It then follows by reversed recursion that if n < Ψ(x) we will, for any ξ, have that
∆Ψ(x)−n(ξ)(n, x) = Ψ(x).
As a consequence ∆m(ξ)(n, x) = Ψ(x) whenever m ≥Ψ(x), so ∆is a contractor with
λ(n, x)Ψ(x)
as its unique ﬁxed point.
□
In order to separate the good examples from this general construction, we notice
that with the ∆constructed above, the iteration requires more and more information
from the original input, in the sense that if we try to use a partial ξ, the whole
construction of the ﬁxed point will be ruined.
It would of course be nice to have a characterization of when a contractor is good
that does not refer to external representations of the total objects, but we must leave

The Continuous Functionals as Limit Spaces
371
that for further research. For us, this is the time to realize that in order to give a
general treatment of when a contractor can be used to deﬁne functionals that are in
a sense computable, we need the underlying representations, and we will stick to
domain representations.
6
Domain representations
Fortunately, we do not need to introduce the full machinery of domain theory. We
will deﬁne what will correspond to the compact elements of the domain repre-
sentations of these functionals, and then represent the functionals directly as ide-
als of compact elements. This is close to the original construction due to Kreisel
[10]. Historically, Kleene [9] deﬁned the continuous functionals using associates,
and Kreisel [10] deﬁned them using ﬁlters of formal neighborhoods. Ershov [3]
characterized the functionals essentially using domain theory, and Scarpellini [20]
characterized them using limit spaces. Our exposition is based on the fact that
both Ershov and Scarpellini characterized the functionals deﬁned by Kleene and
by Kreisel, and we will not give speciﬁc reference to claims following from this
fact.
Recall that N⊥is the set of integers plus an element ⊥for the “undeﬁned”, and that
N⊥is ordered in a ﬂat way, with ⊥⊑a for all a, and the integers are not ordered
among themselves.
Deﬁnition 26. We let D(0) = N⊥considered as a partial ordering.
By recursion, we let D(k + 1) consist of all monotonously increasing functions p :
D(k) →N⊥with ﬁnite support.
We use the pointwise ordering to order D(k + 1).
Each D(k) will be countable, due to the restriction to functionals with ﬁnite
support, and there will be an enumeration of the elements such that the following
are primitive recursive:
i) p ⊑q.
ii) {p, q} is bounded.
iii) r is the least upper bound of p and q.
When a ﬁnite set in D(k) is pairwise bounded, there will be a least upper bound of
the whole set.
An ideal in D(k) will be a set of pairwise bounded elements closed downwards and
under least upper bounds of ﬁnite subsets. If α is an ideal in D(k + 1) and β is an

372
Dag Normann
ideal in D(k), we let α(β) be the least upper bound of the elements p(q) ∈N⊥for
p ∈α and q ∈β.
Deﬁnition 27.
The ideal {⊥, a} will represent the number a.
An ideal α in D(k + 1) represents a function F : Ct(k) →N if whenever β is
an ideal that represents x ∈Ct(k) then α(β) = F(x).
Ct(k + 1) will be exactly the set of functions that have ideal representations.
The proof is not extensively hard, but too space consuming for this paper. Actually,
the set ID(k) of all ideals in D(k), with the inclusion ordering, is isomorphic to the
Scott-continuous partial functionals of type k, and the ideals representing elements
in Ct(k) will correspond to the hereditarily total objects.
Deﬁnition 28. Let Φ be a continuous functional. We say that Φ is externally com-
putable if Φ is represented by a computably enumerable ideal of compacts.
We use the expression “externally” to express that this concept of being com-
putable is imposed on the structure from the outside. µ-recursion and S1 - S9 -
computability are internal concepts, because they grow out of the structure itself.
Kleene’s schemes S1 - S9 make sense also for the typed structure {ID(k)}k∈N, and if
we use the recursion theorem to ﬁnd an index for the ﬁxed points used to deﬁne Γ or
the fan functional, we actually get an index for computing a representative for these
total functionals within this superstructure. This shows that the interpretations of
S1 - S9 are not absolute. One further reason to restrict the attention to µ-recursion is
that with this restriction the interpretations will be absolute. Normann and Rørdam
[18] proved
Theorem 29. Let Φ ∈Ct(k) have a representative α that is µ-recursive in the sense
of the partial continuous functionals.
Then Φ is µ-recursive in the sense of the Ct(k)-hierarchy, using he same algorithm.
S1 - S9 is suitable for investigating the computability theory of the continuous
functionals, but when we consider the superstructure of partial continuous function-
als we actually ad objects that are completely irrelevant for the interpretation of S1 -
S9. There are elements in D(k) that will not be in any S1 - S9 -deﬁnable functional,
total or partial. Computer scientists say that the typed structure of partial continu-
ous functionals is not fully abstract for S1 - S9 (or PCF, the programming language
they prefer instead). In particular, the set of primitive recursive functionals is not a
dense set in ID(k) for k ≥2.
Deﬁnition 30. We deﬁne the relation p ≺x where p ∈D(k) and x ∈Ct(k) as
follows:

The Continuous Functionals as Limit Spaces
373
If p ∈N⊥and x ∈N we let p ≺x if p ⊑x.
If p ∈D(k + 1) and x ∈Ct(k + 1) we let p ≺x if whenever q ∈D(k), p(q) = a
and q ≺y ∈Ct(k) we have that x(y) = a.
The classical density theorem actually tells us that uniformly in p ∈D(k) there
is a primitive recursive x ∈Ct(k) such that p ≺x. We will give a guide to a simple
argument:
• If we replace N with Nn = {0, . . . , n} we may construct both the partial func-
tionals Dn(k) of type k and the total functionals Finn(k) of type k, and both
type structures will be ﬁnite at each level.
• We may then restrict the deﬁnition of ≺to this situation, and with ease prove
that for any p ∈Dn(k) there is an x ∈Finn(k) such that p ≺x.
• Using the canonical embedding ek,n of Finn(k) into Ct(k) as deﬁned in Section
3, we get p ≺ek,n(x).
If ∆: Ct(k) →Ct(k) is continuous, there will be a ˜∆: ID(k) →ID(k) representing
∆. If the least ﬁxed point of ˜∆is hereditarily total, it will represent a unique ﬁxed
point for ∆. We actually have
Lemma 31. If ˜∆: ID(k) →ID(k) represents a total ∆: Ct(k) →Ct(k) and the least
ﬁxed point of ˜∆is hereditarily total, then ∆is a contractor.
Proof. Let pn = ˜∆n(⊥k) where ⊥k is the everywhere undeﬁned object in ID(k).
For every Ψ ∈Ct(k), ∆n(Ψ) will have a representative extending pn. The lemma
then follows from the fact that {pn}n∈N converges to a total object, and that the
modulus function for this sequence will be continuous.
□
When we deﬁne the ﬁxed point computable functionals, we will deﬁne it as
a class of pairs (F, ˜F) where ˜F is a domain representative of F, F is ﬁxed point
deﬁnable and ˜F is deﬁned simultaneously over the ID(k)-hierarchy using the least
ﬁxed point operator. Since the least ﬁxed point operator is continuous, this will
ensure that all ﬁxed point computable functionals are continuous.
Deﬁnition 32. We let the ﬁxed point computable pairs be the least family of pairs
(Φ, ˜Φ) where Φ ∈Ct(k) for some k and ˜Φ is a representative in ID(k) for Φ such that
the class is simultaneously closed under S1 - S8 and Sµ, and such that the following
holds:
If (∆, ˜∆) is a ﬁxed point computable pair of type Ct(k) →Ct(k) such that the
least ﬁxed point of ˜∆is total, then (Φ, ˜Φ) is ﬁxed point computable, where Φ
is the unique ﬁxed point of ∆and ˜Φ is the least ﬁxed point of ˜Φ.

374
Dag Normann
We say that Φ ∈Ct(k) is ﬁxed point computable if there is a representative ˜Φ such
that the pair is ﬁxed point computable.
It is more or less a consequence of the deﬁnition that every ﬁxed point com-
putable functional is externally computable. Our ﬁnal result will be that the con-
verse is also true, every externally computable functional will be ﬁxed point com-
putable. Our argument will be an adjustment of the proof in Normann [16], and
one reason for including it here is to give an updated exposition of the proof. We
do this by separating out a lemma that requires the key idea behind the proof.
Lemma 33. Let f : N →N be computable.
Let T ⊆Ct(k)×N2 be a ﬁxed point computable predicate such that for all φ ∈Ct(k)
and all n1 and n2, if
∀mT(φ, n1, m) ∧∀mT(φ, n2, m)
then f(n1) = f(n2).
Assume further that the corresponding predicate ˜T satisﬁes that for all total α ∈
ID(k) there are inﬁnitely many n such that ˜T(α, n, ⊥).
Finally assume
∗It is decidable when ξk
i , i.e. the i’th element of the countable dense subset of
Ct(k), satisﬁes ∀mT(ξk
i , n, m).
Let Φ(φ) = f(n) when ∀mT(φ, n, m). Then Φ is ﬁxed point computable.
Proof. Let Ψ ∈Ct(k) × N →N, φ ∈Ct(k) and n ∈N.
Deﬁne ∆(Ψ)(φ, n) by the following algorithm:
- Search for the least m such that 1. or 2. below holds:
1. ¬T(φ, n, m)
2. T(φ, n, m), m > n and T(φ, m, Ψ(φ, m)).
- In case of 1., let ∆(Ψ)(φ, n) = m while case 2. splits into two sub cases:
- If f(n) = f(m) we let ∆(Ψ)(φ, n) = m.
- If f(n) , f(m) we search for the least t such that
¬T(φ, n, t)
and let ∆(Ψ)(φ, n) = t.

The Continuous Functionals as Limit Spaces
375
We let ˜∆be the corresponding functional on the partial objects.
As deﬁned, it will not be the case that ∆is total, we may risk that the ﬁnal search
goes on for ever. We will show that the least ﬁxed point of ˜∆is total, and then we
will see how ∆can be adjusted to a total ∆1 with the same least ﬁxed point.
Let ψ0 be the ⊥-element of the type k×0 →0 and let ψt+1 = ˜∆(ψt). Let ψ = ⊔t∈Nψt.
Let α ∈ID(k) be a representative for φ ∈Ct(k).
Let X = {n ∈N | ˜T(α, n, ⊥)} and let a = f(n) for n ∈X. Then Φ(φ) = a.
We will show that for all n, ψ(α, n) ∈N and if ˜T(α, n, ψ(α, n)) then f(n) = a. This
will not only ensure that ψ is the representative of a ﬁxed point computable Ψ, but
that we can compute Φ by Φ(φ) = f(n) for the least n such that T(φ, n, Ψ(n)).
We will prove, simultaneously for all n and by induction on t > 0, that if n + t ∈X
then
- ψt(α, n) ∈N
- If ˜T(α, n, ψt(α, n)) then f(n) = a.
So assume that the claim holds for all t′ with 0 < t′ < t and let n + t ∈X.
Let us consider the algorithm for ψ(ψt−1)(α, n).
- First we search up to n for an m such that ¬ ˜T(α, n, m), and if we ﬁnd one, we
let ψt(α, n) be that value. If we ﬁnd one, there is nothing more to prove.
- If we do not ﬁnd such m ≤n we continue to search, and this search will stop
for three possible reasons:
i) We ﬁnd m such that n < m < n + t and ¬ ˜T(α, n, m).
ii) We ﬁnd m such that n < m < n + t and ˜T(α, m, ψt−1(α, m)).
iii) We ﬁnd m
=
n + t and realize that ˜T(α, m, ψt−1(α, m)) because
˜T(α, m, ⊥).
By the induction hypothesis, the test in the search will terminate for all m
with n < m < n + t since ψt−1(α, m) ∈N for these m, and our search will halt
with m = n + t at the latest.
We will now split the rest of the proof into these three cases:
i) This is like the ﬁrst case, we let ψt(α, n) = m, and since
¬ ˜T(α, n, ψt(α, n)) there is nothing more to prove.
ii) The construction now splits into two sub cases, f(n) = f(m) and f(n) , f(m).
In the ﬁrst sub case, the induction hypothesis tells us that f(m) = a. It follows
that f(n) = a, so part two of the claim holds. In the second sub case, we know

376
Dag Normann
by the induction hypothesis that f(m) = a, so by the assumptions there must
be a t such that ¬ ˜T(α, n, t), and we will ﬁnd one via the continued search.
iii) We can argue as in ii), except that we do not need any induction hypothesis
to ensure that f(m) = a when we are in case iii).
Now let Ψ be the total object represented by the least ﬁxed point of ˜∆, and let Ξ
be an arbitrary functional of the same type. We will deﬁne ∆1(Ξ) using exactly the
same algorithm as we used for ∆(Ξ) unless there is information available demon-
strating that Ξ , Ψ. Recall the deﬁnition of the trace functions hΨ and hΞ. hψ is
outright computable and hΞ is computable in Ξ. In Case 2, f(m) , f(n), the idea is
to deﬁne ∆1(φ, n) by searching for the least t such that ¬T(φ, n, t) or hΨ(t) , hΞ(t).
The obstacle here is that the totality of ˜∆ω
1 (⊥) does not follow anymore. Unless we
choose the enumeration of the countable dense subset of Ct(k) × N with some care,
we risk that h ˜∆ω
1 (⊥) is not total. This is where the condition ∗will be used.
If ∀mT(ξk
i , n, m), our algorithm will ensure that ˜∆1(˜ξk
i , n) is deﬁned. Let g be com-
putable such that
∃m¬T(ξk
i , n, m) ⇒∃m ≤g(i, n)¬T(ξk
i , n, m).
If we enumerate all pairs (i, n) as t(i, n) such that t ≥g wherever g is deﬁned, and
use this enumeration when we deﬁne hΞ, we avoid this obstacle. We prove by in-
duction on t that hψ(t) ∈N where ψ is the least ﬁxed point of ˜∆1.
Thus the pair ( ˜∆1, ∆1) shows that the unique ﬁxed point Ψ of ∆is ﬁxed point com-
putable.
□
Our main application of Lemma 33 is
Theorem 34. Let Φ ∈Ct(k) be externally computable.
Then Φ is ﬁxed point computable.
Proof. We give the details for k = 3. For k < 3, the result is trivial. For k > 3 we
refer to Normann [16], where the adjustments needed for the general theorem were
given in detail.
Let {(pn, an)}n∈N be a computable sequence, where each pn ∈D(2), an ∈N and if
φ ∈Ct(2) and α ∈ID(2) then Φ(φ) = a if and only if there is an n ∈N such that
pn ∈α and a = an. We may well assume that if there is one such n, there will be
inﬁnitely many.
Since each pn has ﬁnite support, there will be (qn,1, bn,1), . . . , (qn,rn, bn,rn) where
each qn,r ∈D(1), each bn,r ∈N and pn is the least monotone extension of the map
{qn,r 7→bn,r | 1 ≤r ≤rn}.
We let T(φ, n, m) when φ agrees with pn on the m’th total extension (in a dense

The Continuous Functionals as Limit Spaces
377
set of possible extensions) of qn,1, . . . , qn,rn. We design the algorithm for the m’th
extension of qn,r such that qn,r itself is the ⊥’th extension. In this way we obtain the
required property of ˜T.
For φ ∈Ct(2) we will have that ∀mT(φ, n, m) is equivalent to pn ≺φ. Since this is
decidable when φ is a known element of our countable dense subset of Ct(2), the
assumption ∗in Lemma 33 is also satisﬁed.
Finally, we let f(n) = an, apply he lemma, and see that Φ is ﬁxed point computable.
□
We can use the same argument to prove the following characterization:
Corollary 35. Let Φ ∈Ct(k) for some k.
Then the following are equivalent:
1. Φ is ﬁxed point deﬁnable.
2. Φ has a representation in ID(k) that is arithmetical.
Proof. 1. ⇒2. is proved by induction on the rank of the construction of Φ as ﬁxed
point deﬁnable.
2. ⇒1. is proved by a relativized version of Lemma 33.
□
7
Summary and conclusions
We have shown that the classical computability theory of the Kleene-Kreisel con-
tinuous functionals can be developed within the framework of limit spaces, i.e. in
a strictly topological setting. We may strengthen S1 - S9 by adding unique ﬁxed
points of computable functionals. However, our conclusion so far is that we need
an external way of representing the functionals in order to decide when we allow
one such ﬁxed point to be computable.
This paper is partly a survey paper and partly an experiment with the concept of
ﬁxed point deﬁnable functional. Our conclusion so far is that we may construct
all externally computable functionals using constructions that are absolute for the
functionals themselves and the commonly used set of realizers, the domains of par-
tial continuous functionals.
It is a fact that the least ﬁxed point operator is continuous as an operator on
domains, while the unique ﬁxed point operator is discontinuous on the set of con-
tractors. We leave it as an open problem to ﬁnd out if this naive observation can be
used to ad one partial computable functional of type (k →k) →k for each k, rep-
resenting legal ﬁxed point constructions such that they, together with µ-recursion,
generate all externally computable functionals. We know from Normann [13] that

378
Dag Normann
there is a sequence of computable master functionals, one for each type ≥4, that
together with µ-recursion generate all externally computable functionals. These are
constructed in an ad hoc way using theorem 13, and do not serve as a justiﬁable
basis for an internal computability theory on the continuous functionals.
Acknowledgement
I am grateful to an anonymous referee for suggesting improvements of the exposi-
tion.
References
[1] U. Berger, Total sets and objects in domain theory, Annals of Pure and Ap-
plied Logic, 60: 91 - 117, 1993.
[2] J. Bergstra, Computability and Continuity in Finite Types, Thesis, University
of Utrecht, 1976.
[3] Yu. L. Ershov, Computable functionals of ﬁnite type, Algebra and Logic 11:
203 - 277, 1972.
[4] M. H. Escard´o, Exhaustible sets in higher-type computation, Logical Methods
in Computer Science, Volume 4, Issue 3, Paper 3, 2008.
[5] R. O. Gandy and J. M. E. Hyland, Computable and recursively countable
functions of higher type, in Gandy and Hyland (eds.) Logic Colloquium ’76:
407 - 438, North Holland, 1977
[6] T. Grilliot, On eﬀectively discontinuous type-2 objects, Journal of Symbolic
Logic, 36: 245 - 247, 1971.
[7] J. M. R. Hyland Recursion on the countable functionals, Dissertation, The
University of Oxford, 1975.
[8] S. C. Kleene, Recursive functionals and quantiﬁers of ﬁnite types I, Trans.
Amer. Math. Soc. , 91: 1 - 52, 1959.
[9] S. C. Kleene, Countable functionals, in A. Heyting (ed.) Constructivity in
Mathematics: 81 - 100, North-Holland,1959.
[10] G. Kreisel, Interpretation of analysis by means of functionals of ﬁnite type,
in A. Heyting (ed.) Constructivity in Mathematics: 101 - 128, North-Holland,
1959.

The Continuous Functionals as Limit Spaces
379
[11] K. Kuratowski, Topologie, vol 1, Warsawa, 1952.
[12] J. R. Longley and D. Normann, Computability at Higher Types(tentative title),
in preparation.
[13] D. Normann, The Continuous Functionals; Computations, Recursions and
Degrees, Annals of Mathematical Logic 21: 1-26, 1981.
[14] D. Normann, Recursion on the Continuous Functionals, Lecture Notes in
Mathematics, Vol 811, Springer Verlag , 1980.
[15] D. Normann, The Continuous Functionals, in E. R. Griﬀor (ed.) Handbook of
Computability Theory: 251 - 275, 1999.
[16] D. Normann, Computability over the partial continuous functionals, The Jour-
nal of Symbolic Logic 65: 1133 - 1142, 2000.
[17] D. Normann, Computing with functionals - Computability theory or Com-
puter science?, The Bulletin of Symbolic Logic 12: 43 - 59, 2006.
[18] D. Normann and C. Rørdam, The computational power of Mω, Mathematical
Logic Quarterly 48: 117-124, 2002.
[19] R. A. Platek, Foundations of recursion theory, Thesis, Stanford University,
1966.
[20] B. Scarpellini, A model for bar recursion of higher types, Comp. Math. 23:
123-153, 1971.
[21] D. Scott, A type-theoretical alternative to ISWIM, CUCH, OWHY, unpub-
lished notes, Oxford, 1969.
[22] W. W. Tait, Continuity properties of partial recursive functionals of ﬁnite type,
unpublished notes, 1958.

380

Provably Recursive Functions of Reﬂection
Wolfram Pohlers and Jan–Carl Stegert
In this paper we give a characterization of the recursive number theoretic func-
tions whose totality is provable within the theory Ref, which is Kripke–Platek
set theory with the full reﬂection scheme. This is done in two steps. In the ﬁrst
part, Sections 2 through 5, we compute the proof theoretic ordinal of Ref and
show in the second part, Section 6, how this computation can be modiﬁed into
a characterization of the provable recursive functions of Ref.
Contents
1
Introduction
382
2
Preliminaries
384
2.1
The theory Ref . . . . . . . . . . . . . . . . . . . . . . . . . . .
384
2.2
Reﬂecting– and indescribable ordinals . . . . . . . . . . . . . . .
385
2.3
Heuristic . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
387
2.4
Iterated Skolem–hull operators . . . . . . . . . . . . . . . . . . .
391
3
Reﬂection conﬁgurations and their instances
394
3.1
Reﬂection conﬁgurations and their instances . . . . . . . . . . . .
394
3.2
Basic Structure Theory . . . . . . . . . . . . . . . . . . . . . . .
399
3.3
The existence proof . . . . . . . . . . . . . . . . . . . . . . . . .
404
3.4
Ordinal comparison . . . . . . . . . . . . . . . . . . . . . . . . .
411
3.5
A primitive recursive characterization of Vα({0, Ξ})
. . . . . . .
414
3.6
Fine Structure Theory . . . . . . . . . . . . . . . . . . . . . . . .
416
4
Ramiﬁed set theory
429
4.1
The language of ramiﬁed set theory
. . . . . . . . . . . . . . . .
429
4.2
The inﬁnitary calculus Π∞
ω
. . . . . . . . . . . . . . . . . . . . .
431
4.3
Embedding of Ref
. . . . . . . . . . . . . . . . . . . . . . . . .
434
381

5
Π1
1 –ordinal analysis of Ref
437
5.1
Predicative cut–elimination . . . . . . . . . . . . . . . . . . . . .
437
5.2
Elimination of reﬂection rules
. . . . . . . . . . . . . . . . . . .
439
5.3
The ordinal analysis . . . . . . . . . . . . . . . . . . . . . . . . .
450
6
Characterization of the Π0
2–Skolem functions of Πω–reﬂection
451
6.1
The theory Ref∗. . . . . . . . . . . . . . . . . . . . . . . . . . .
451
6.2
The subrecursive hierarchy . . . . . . . . . . . . . . . . . . . . .
452
6.3
Fragmented Skolem hull operators . . . . . . . . . . . . . . . . .
455
6.4
Embedding of Ref∗. . . . . . . . . . . . . . . . . . . . . . . . .
458
6.5
Predicative cut–elimination . . . . . . . . . . . . . . . . . . . . .
461
6.6
Reﬂection elimination for fragmented controlled derivations
. . .
464
6.7
The characterization theorem . . . . . . . . . . . . . . . . . . . .
467
Index
473
1
Introduction
The content of this paper should be viewed as a contribution to the part of Hilbert’s
Programme that deals with the elimination of “ideal elements”. In his 1927 talk
in Hamburg [12] he compares the work of a mathematician with the work of a
physicist and states that only few conclusions of physical theories are veriﬁable
by experiments and compares theses conclusions to the “real statements” of his
prooftheory.1 The mathematical analog of a physical statement that is veriﬁable by
experiments are Π0
2–theorems. Whenever we have a Π0
2–theorem (∀x)(∃y)F(x, y)
there is an algorithm that computes y from a given input x. Here the algorithm
corresponds to the “experiment” done by the physicist. In the present paper we
present such an algorithm for the Π0
2–theorems that are provable within a Kripke–
Platek set theory with full reﬂection scheme. The algorithm is given in terms of a
subrecursive hierarchy. Clearly this algorithm is only of hypothetical value since
1The original citation in German is: “Der Physiker verlangt gerade von einer Theorie, daß ohne
die Heranziehung anderweitiger Bedingungen aus den Naturgesetzen oder Hypothesen die besonderen
S¨atze allein durch Schl¨usse, also auf Grund eines reinen Formelspiels abgeleitet werden. Nur gewisse
Kombinationen und Folgerungen der physikalischen Gesetze k¨onnen durch das Experiment kontrolliert
werden — so wie in meiner Beweistheorie nur die realen Aussagen unmittelbar einer Veriﬁkation f¨ahig
sind.”
that loosely translated says:
“The physicist requires for a theory that its theorems can be formally derived from the laws of nature
and its hypotheses alone without referring to outside perceptions. Only certain combinations and con-
clusions of physical laws are checkable by experiments — this is also true for my prooftheory in which
only “real statements” are veriﬁable.”
382
Wolfram Pohlers and Jan–Carl Stegert

its computation requires resources that are widely outside the realm of all realiz-
able possibilities. Nevertheless we regard it as an interesting problem to gauge the
amount of resources that are needed for verifying a Π0
2–theorem proved by abstract
(i.e., ideal) principles.
The subrecursive hierarchy developed in this paper is based on the ordinals that
arise in an ordinal analysis of the theory of reﬂections. By an ordinal analysis
of a theory we understand the computation of its proof theoretic ordinal, i.e., the
supremum of the ordinals that can be represented by a recursive ordering on the
natural numbers whose well–foundedness is provable in the theory. For reasons
which we will not discuss here this ordinal is also known as the Π1
1–ordinal of the
theory.
The key in the ordinal analysis of a theory is the elimination of all “ideal” prin-
ciples that are used in a proof of a Π1
1–statement. This is achieved by unravelling a
formal proof into a proof within the framework of an inﬁnitary system that allows
the elimination of all “ideal” principles by a reduction procedure. The eventually
obtained irreducible inﬁnitary derivation of a Π1
1–sentence is then freed from all
“ideal” assumptions.
When dealing with subsystems of set theory, the Π1
1–sentences correspond to
Σ
LωCK
1
1
–sentences and an irreducible inﬁnitary derivation of such a sentence can be
viewed as a veriﬁcation of the sentence in the constructible hierarchy. Building
up the constructible hierarchy we need no ideal principles. The Π1
1–ordinal of
subtheories of set theory can therefore equivalently be characterized as the least
stage in the constructible hierarchy at which its provable Σ
LωCK
1
1
–sentences become
true. This is clearly an ordinal below the ﬁrst non–recursive ordinal ωCK
1 .
Sections 3 through 5 are devoted to the ordinal analysis of the theory Ref. We
compute |Ref|Π1
1 as Ψε Ξ+1
Ω
, the collapse of the ﬁrst ε–number bigger than Ξ — the
ﬁrst ordinal that is Π1
n–indescribable for all ﬁnite n — below ωCK
1 . In Section 6
we show how the ordinal analysis can be extended to a Π0
2–analysis of Ref, i.e., to
a characterization of the subrecursive hierarchy majorizing the Skolem functions
of the Π0
2–sentences provable in Ref. We obtain that the Π0
2–Skolem functions —
which coincide with the provably recursive functions of Ref — are the primitive
recursive hull of a hierarchy {Fα α < |Ref|Π1
1} which is an extension of the Hardy
hierarchy.
The paper is based on the ﬁrst part of the doctoral thesis [23] of the second author
which, in turn, is mostly based on the papers [17], [21] by Michael Rathjen, the
dissertation [3] of Benjamin Blankertz, basing on the work of Andreas Weiermann
(cf. [8],[24],[4],[25]), and the dissertation [10] of Christoph Duchhardt. The results
in the thesis of the second author are, however, essentially further–reaching and
include an analysis of a Kripke–Platek set theory with stability axiom.
Provably Recursive Functions of Reflection
383

The structure and the notions of this paper differ from those given in [23]. This
is especially true for the notion of fragmented controlled derivations — one of the
innovative key notions in [23]. Due to an alternative approach to subrecursive hier-
archies it was easy to built a collapsing feature into the deﬁnition of a fragmented
controlled derivation. In [23] the same result is obtained by an extra collapsing
theorem.
2
Preliminaries
2.1
The theory Ref
The theory of reﬂection is a subtheory of Zermelo–Fraenkel set theory. The lan-
guage of Ref is ﬁrst order logic with equality whose only non–logical constant is
the membership symbol ∈.
Its ontological axioms are the axiom of extensionality
(Ext)
(∀x)(∀y)

(∀z ∈x)[z ∈y] ∧(∀z ∈y)[z ∈x]

→x = y,
and the scheme of foundation, which is the universal closure of
(FOUND)
(∃x)F(x) →(∃x)

F(x) ∧(∀y ∈x)[¬F(y)]

.
Its set–existence axiom is the null–set axiom
(Nullset)
(∃x)(∀y)[y /∈x].
Its closure axioms are ‘closure under unordered pairs’
(Pair)
(∀x)(∀y)(∃z)[x ∈z ∧y ∈z],
‘closure under unions’
(Union)
(∀u)(∃z)(∀x ∈u)[x ⊆z]2
the ‘scheme of ∆0–separation’ which is the universal closure of
(∆0–Sep)
(∀u)(∃z)

(∀x ∈z)[x ∈u ∧F(x)] ∧(∀x ∈u)[F(x) →x ∈z]

,
where F is a ∆0–formula, i.e., a formula that contains only bounded quantiﬁers,
and the ‘reﬂection scheme’
(REF)
(∀⃗y)

F(⃗y) →(∃z)

(∃u ∈z)[u ∈z] ∧Tran(z) ∧⃗y ∈z ∧F z
where Tran(z) is the formula (∀u ∈z)(∀x ∈u)[x ∈z] and F z stands for the for-
mula that is obtained from F by restricting all unbounded quantiﬁers to z. For con-
venience we abbreviate the right formula in the above implication by (∃z)[z |= F].
2Where z ⊆u stands for (∀x ∈z)[x ∈u],
384
Wolfram Pohlers and Jan–Carl Stegert

On should observe that the familiar formulations of pairing and union are deriv-
able from the above versions by the ∆0–separation scheme.
Ordinals can be characterized as hereditarily transitive sets. Agreeing that lower
case Greek letters range over ordinals we obtain (∀α)(∃β)[α ∈β] with α ∪{α} as
a witness for β that exists by (Pair) and (Union). Reﬂecting this sentence we get
(∃z)(∀α ∈z)(∃β ∈z)[α ∈β]
which is an inﬁnity axiom.
Still essentially weaker than full ZFC, the theory Ref is already a pretty strong
theory. In the following we will give an ordinal analysis of Ref and, based on this
ordinal analysis, a characterization of its Π0
2–Skolem functions. This includes a
characterization of the provably recursive functions of Ref.
2.2
Reﬂecting– and indescribable ordinals
All (published) developments of the ordinal theory needed in the ordinal analysis
of impredicative axiom systems suffer from the same drawback. In the proof theo-
retical analysis we work in G¨odel’s constructible hierarchy L. The relevant ordinals
needed there are “reﬂecting ordinals” which can be understood as “recursive” coun-
terparts of “large” cardinals in the von Neumann hierarchy V . Most important is
ωCK
1 , the ﬁrst “Π2–reﬂecting” ordinal, which is equal to the ﬁrst ordinal that cannot
be represented by a recursively deﬁnable well–ordering on the naturals numbers.
So ωCK
1
is the “recursive” counterpart of Ω, the ﬁrst ordinal, that cannot be repre-
sented by well–ordering on the natural numbers.
Simultaneously ωCK
1
is the ﬁrst admissible ordinal above ω and the hierarchy
of admissible ordinals is, roughly speaking, the “recursive” counterpart of the the
hierarchy of regular cardinals. So it would be consequent to develop the ordinal
theory on the basis of “recursive” ordinals. Although possible in principle, this
turns out to be extremely complicated. Therefore the necessary ordinal theory has
always been developed on the basis of cardinals instead of admissible ordinals and
only afterwards attempts were made to justify the so obtained theory also on the
basis of admissible ordinals instead of cardinals (cf. [18]). However, this situation
should perhaps not only be viewed as a drawback but rather as another example
of the beauty of introducing “ideal” notions in mathematical work. The use of the
“ideal” large cardinals simpliﬁes all considerations considerably. However, once
the ordinal notation system is obtained, it turns out to be primitive recursively de-
ﬁnable. We thus may forget all we used about large cardinals and work only with
ordinal notations (what we will not do in this paper).3 This may be viewed as
3This is the argument against the objection that “large” cardinals are used for the justiﬁcation of
theories considerably weaker than ZFC. However, consistency is not the goal of our studies, although
Provably Recursive Functions of Reflection
385

another example for an “elimination of ideal elements” in Hilbert’s sense on the
meta–level.
Here we will use the correspondence between indescribable cardinals and re-
ﬂecting ordinals, their “recursive” counterparts. The “recursive counterpart” of a
Π1
n+1–indescribable cardinal is a Πn+3–reﬂecting ordinal. A profound study of
large cardinals and their recursive counterparts by Peter Aczel and Wayne Richter
is in [22].
2.1 Deﬁnition A formula F in the language of set theory is a ∆0–formula if all
quantiﬁers in F are bounded.
We call F a ( pure) Πn–formula if it has the form (∀x1) . . . (Qxn)G(x1, . . . , xn)
for a block of n alternating quantiﬁers and a ∆0–formula G(x1, . . . , xn).
Dually we deﬁne (pure) Σn–formulas as formulas (∃x1) . . . (Qxn)G(x1, . . . , xn)
with a block of n alternating quantiﬁers and a ∆0–formula G(x1, . . . , xn).
A formula F in the second order language of set theory is a (pure) Π1
n–formula
iff F has the form (∀X1) . . . (QXn)G(X1, . . . , Xn) for a block of n alternating
second order quantiﬁers and a ﬁrst order formula G(X1, . . . , Xn). Dually we de-
ﬁne (pure) Σ1
n–formulas.
The Πn (Σn, Π1
n, Σ1
n)–formulas are the closure of the pure Πn (Σn, Π1
n, Σ1
n)–
formulas under the positive boolean operations ∧and ∨.
An ordinal π is Πn–reﬂecting iff for any Πn–formula F(a1, . . . , an) with pa-
rameters a1, . . . , an in Lπ such that Lπ |= F(a1, . . . , an) there is an ordinal κ < α
such that a1, . . . , an ∈Lκ and Lκ |= F(a1, . . . , an).
We call π Πn reﬂecting on a class M ⊆On iff Lπ |= F(a1, . . . , an) entails that
there is an ordinal κ ∈M ∩π such that a1, . . . , an ∈Lκ and Lκ |= F(a1, . . . , an).
An ordinal π is Π1
n–indescribable if for every Π1
n–formula F(P1, . . . , Pn) with
second order parameters ⃗P := P1, . . . , Pn such that (Vπ, ⃗P) |= F(⃗P) there is
an ordinal κ < π such that (Vκ, ⃗P ∩κ) |= F(⃗P). The ordinal π is called Π1
n–
indescribable on a class M ⊆On if the above mentioned ordinal κ is in M ∩π.
Clearly these deﬁnition carry over to all other possible complexity classes for
formulas.
It is easy to see that all Π1
n–indescribable ordinals are cardinals.
To simplify notations we write F α instead of F Lα. Observe that Lα |= F is equiv-
alent to L |= F α as soon as all parameters in F belong to Lα. Similarly we write
mostly (∃xα) and (∀xα) instead of (∃x ∈Lα) and (∀x ∈Lα). By Ππ
n (Σπ
n) we
denote the complexity class {F π F a Πn(Σn)–formula }.
We need a few of the classical results on indescribable cardinals.
the consistency of the analyzed theory follows from the well–foundedness of the eventually obtained
ordinal notation system. A “constructive” consistency proof therefore would only need a constructive
proof of the well–foundedness of the ordinal notation system.
386
Wolfram Pohlers and Jan–Carl Stegert

2.2 Theorem An ordinal κ is Π1
0–indescribable iff κ is strongly inaccessible.
Proof
Cf. [9] Chapter 9, §1, Theorem 1.3.
□
2.3 Theorem Let κ be a strongly inaccessible cardinal then the set
{σ ∈κ (Vσ, P ∩Vσ) ≺(Vκ, P)}4
is closed and unbounded in κ.
Proof
Cf. e.g. [13] Lemma 6.1.
□
2.4 Theorem For every n ∈ω there is a Π1
n–formula ψn(X1, . . . , Xk, x) that is
universal for the Π1
n–sentences, i.e., for any Π1
n–sentence φ( ⃗X) there is a parame-
ter φ such that for any limit ordinal λ > ω and parameters Pi ⊆Vλ we have
(Vλ, ∈, P1, . . . , Pk) |= φ(X1, . . . , Xk) ↔ψn(X1, . . . , Xk, φ ).
Proof
Cf. [9] Chapter 9, §1, Lemma 1.9 for the case n > 0. A reinspection of the
proof given there also shows the existence of a ∆1
0–formula ψ0 that is universal for
Π1
0–sentences.
□
2.5 Corollary The Π1
n–indescribability on a set M is deﬁnable by an Π1
n+1–formu-
la with parameter M. I.e. there is a Π1
n+1–formula φ(P) such that
(Vπ, ∈, M) |= φ(P) iff π is Π1
n–indescribable on M.
Proof
Deﬁne
φ(P) :⇔(∀⃗X)(∀x)

ψn( ⃗X, x) →(∃κ ∈P)[κ ̸= 0 ∧ψn( ⃗X ∩Vκ, x)Vκ]

where ψn is the formula universal for Π1
n–formulas.
□
2.3
Heuristic
The characterization of the provably recursive functions is based on the ordinal
analysis of Ref. Since already the ordinal analysis is technically rather involved we
want to give a heuristic (and thus pretty vague) description how it is obtained.
An ordinal analysis of a subtheory of set theory can be understood as a com-
putation of the least upper bound for the stages in the constructible hierarchy at
which all provable ΠωCK
1
2
–sentences are satisﬁed. This is commonly achieved by
deﬁning a language LRS of ramiﬁed set theory in which there is a name for every
4where ≺stands for elementary substructure.
Provably Recursive Functions of Reflection
387

constructible set. This canonically induces an inﬁnitary veriﬁcation calculus whose
essential inﬁnite rule is
αt ∆, F(t) for all t ∈Lπ and αt < α ⇒
α ∆, (∀x ∈Lπ)F(x)
where αt and α are ordinals and ∆is a ﬁnite set of LRS–formulas, the side formulas
of the rule, and ∆, F is to be interpreted as the ﬁnite disjunction of the formulas in
∆and F.
This inﬁnitary calculus is correct, i.e.,
α ∆entails L |= W∆. Whenever we
succeed to show that Ref ⊢F ωCK
1 implies
α F π for a ΠωCK
1
2
–sentence we know
that π is an upper bound for the proof theoretic ordinal of Ref.5 In order to obtain
an embedding of Ref we have to augment the veriﬁcation calculus by reﬂection
rules and a cut rule. We denote by
α
ρ ∆that there is a derivation of ∆in this
enriched calculus whose cut formulas have complexities less than ρ. Then a deriva-
tion
α
ρ ∆π with ρ and π less than ωCK
1
cannot contain applications of reﬂection
rules (since these rules always lead to stages ≥ωCK
1 ). A derivation
α
ρ ∆π with
ρ, π < ωCK
1
is therefore “nearly” a veriﬁcation
α ∆π and thus entails L |= W∆π.6
Therefore it sufﬁces to show that Ref
F for a ΠωCK
1
2
–sentence entails
α
ρ F π for
ρ, π < ωCK
1
to obtain reasonable upper bounds. The central problems thus consist
in the elimination of the reﬂection rules that are needed for the embedding of a
Ref–proof of a ΠωCK
1
2
–sentence and in collapsing the involved ordinals below ωCK
1 .
For the collapsing task we can rely on the proven technique of derivations con-
trolled by iterated Skolem hull operators, developed by W. Buchholz in [7], which
we introduce in Section 2.4.
The breakthrough in the elimination of reﬂections with complexities above Π2 is
due to M. Rathjen in [17]. In his later papers he extended this method also to much
stronger systems. Although the basic idea of his technique is beautifully simple
its eventual realization turns out to be extremely cumbersome. Therefore we try to
give a heuristic description of its basic ideas.
Its main feature is the introduction of thinning hierarchies.7 An example for a
thinning operation for a set X of ordinals is
Rn(X) := {ξ ∈X ξ is Πn–reﬂecting on X}.8
Since we are working with inﬁnitely long derivations we need transﬁnitely iter-
5This of course only yields relevant information if we succeed in ﬁnding a π < ωCK
1
.
6By “semantical cut elimination” (cf. [15] Theorem 11.10.2) it is in fact easily transformed into a
veriﬁcation.
7This is the crucial progress in comparison to local predicativity which lead to ordinal analyzes of
theories below Π3–reﬂections.
8According to the already mentioned fact that we will develop the ordinal theory on the basis of
388
Wolfram Pohlers and Jan–Carl Stegert

ated thinning hierarchies, e.g. hierarchies given by R0
n(π) = π, Rα+1
n
(π) :=
Rn(Rα
n(π)) and Rλ
n(π) := ∆R<λ
n (π) = {κ < λ (∀ξ < κ)[κ ∈Rn(Rξ
n(π))]}.
Sticking to this example of a thinning hierarchy the goal is to show
(A)
α
ρ ∆for a ﬁnite set of Σπ
n–formulas entails
α′
α′ ∆π,ξ for all ξ ∈Rα
n(π),
where α′ is some ordinal depending on α, π, ξ and ρ.9
Here we write Qxα instead of (Qx ∈Lα) and denote by ∆π,ξ that all quanti-
ﬁers (Qx ∈Lπ) in ∆have been replaced by (Qx ∈Lξ). Putting ψRn(π)(α) :=
min Rα
n(π) and choosing π as the ordinal needed for the canonical embedding of
Ref into the inﬁnitary system, we get by (A) the ordinal ψR1(π)(α) as an upper
bound for the proof theoretic ordinal because every ΠωCK
1
2
–sentence can be recov-
ered from a ΣωCK
1
1
–formula with (arbitrary) parameters.
The way to prove (A) is of course by induction on α. To indicate how we can
get rid of an application of a Πn+1 reﬂection rule during this procedure we assume
that the last inference is a Πn+1–reﬂection rule
α0
ρ ∆, F
⇒
α
ρ ∆, (∃xπ)[x |= F]
(i)
where F = (∀xπ)G(x) is a Ππ
n+1–formula. But then we also have
α0
ρ ∆, G(a) for
all a ∈Lπ and may thus apply the induction hypothesis to get
α0
′
α0
′ ∆π,ζ, G(a)π,ζ
for all a ∈Lπ and ζ ∈Rα0
n (π). Since Lζ ⊆Lπ this entails
α1
α0
′ ∆π,ζ, F π,ζ by the
inﬁnitary rule. Pick ξ ∈Rα
n(π) ⊆Rα0
n (π) so large that ζ and all set parameters in
∆, F belong to Lξ. This is possible because Rα
n(π) is unbounded in Lπ. Since Lζ
is transitive, non void and an element of Lξ we obtain
α2
α0
′ ∆π,ζ, (∃xξ)[x |= F]
(ii)
with Lζ as a witness for x. In the case that n = 1 we are already done since we
then may raise ζ to ξ by upwards persistency of Σ1–formulas. For n > 1 we have
to work harder. Here we observe that (ii) holds for all ζ ∈Rα0
n (π) ∩Lξ by which
we obtain
α3
α0
′ (∀xξ)[x ∈Rα0
n (π) →W∆π,x], (∃xπ)[x |= F] .
(iii)
Clearly the inﬁnitary calculus derives the tautology
β
0 ∆π,ξ, ¬W∆π,ξ for a not too
big β. The formula ¬W∆π,ξ is a Πξ
n–formula. Now we need additional reﬂection
indescribable cardinals instead of reﬂecting ordinals the corresponding thinning operations will rather
be based on the Mahlo–operations mentioned in Section 2.4.
9We suppress all ordinal computations in the heuristic considerations.
Provably Recursive Functions of Reflection
389

rules
(R<α
n (ξ)–Ref)
If ξ ∈Rα
n(π) and G is a Πξ
n–formula such that
β0
ρ Γ, G then we
get
β
ρ Γ, (∃xξ)[ξ ∈Rα0
n (π) ∧x |= G] for all α0 < α and β > β0.
Applying an instance of the additional rule to the above tautology we obtain
β1
0 ∆π,ξ, (∃xξ)[x ∈Rα0
n (π) ∧¬W∆π, x] .
(iv)
Cutting (iii) and (iv) — ξ ∈Rα
n(π) secures ξ < α′ and the complexity of the
cut formula is essentially ξ — yields
α′
α′ ∆π.ξ, (∃xξ)[x |= F] and we have shown
that we can avoid a Ππ
n+1–reﬂection rule for the cost of introducing a family of
relativized Πξ
n rules for ξ < π.
Of course this is not the end of the story. We have now also get rid of the new
reﬂection rules. Using the above strategy to eliminate also a new reﬂection rule we
have to prove (A) also for π replaced by κ ∈Rδ
n+1(π) and thus need a thinning
hierarchy Kα
n(κ) for κ. Instead of (ii) we then have to prove
α2
α0
′ ∆π,ζ, (∃xξ)[x ∈Rβ
n+1(π) ∧x |= F]
(v)
for all ξ ∈Kα
n(κ) and all β < δ. But for this we need to know that Kα
n(κ) ⊆
Rβ
n+1(π) holds true for all β < δ. This is of course impossible since for a limit or-
dinal δ, κ := ψRn+1(π)(δ) and ξ ∈Kβ
n(κ) we get ξ ∈T
β<δ Rβ
n+1(π) ⊆Rδ
n+1(π)
in contradiction to the minimality of κ. Therefore we have to deﬁne thinning hierar-
chies Kα
n,β(κ) that satisfy Kα
n,β(κ) ⊆Rβ
n+1(π) for every β < δ simultaneously but
separately. In order to obtain the equivalent of (iv) we moreover have to introduce
(K<α
n,β(κ)–Ref) rules for all κ ∈Rδ
n+1(π) and β < δ.
To meet all these requirements we are going to deﬁne reﬂection instances X =
(π, M, m, Z, δ) where π is the reﬂecting ordinal, M is the set on which π is re-
ﬂecting and the integer m −1 indicates the formula–complexity for which π is
reﬂecting10, Z denotes the (possible) predecessor instance and δ indicates the iter-
ation degree of X. Moreover we assign to every reﬂecting ordinal π a reﬂection
string ⃗R(π) the entries of which are reﬂection expressions of the form M<α
F – Pm,
indicating which additional reﬂection rules are needed to reach (iv) in the above
heuristic. To reﬂection instances X of reﬂection degree ≥0 and ordinals α ≥δ we
deﬁne a set Mα
X which corresponds to the thinning hierarchy for π but also depends
on the reﬂection string ⃗R(π).11 By Ψα
X we denote the least element of Mα
X. Then
10For technical reasons, that are connected with the fact that we will work with indescribable cardinals
instead of reﬂecting ordinals, m will indicate that π is Π1
m−1–indescribable on M.
11The letter M is reminiscent of Mahlo, since the thinning hierarchies are based on the Mahlo opera-
tions M(X) := {κ ∈X X ∩κ is stationary in κ}.
390
Wolfram Pohlers and Jan–Carl Stegert

Ψα
X can serve as an example for the ordinal κ in the above heuristic. To obtain
the thinning hierarchies for Ψα
X for all β < α separately we deﬁne for α ≥δ a
successor reﬂection conﬁguration Xα which maps ordinals β ∈[δ, α) to reﬂection
instances with reﬂection point Ψα
X and a reﬂection set Mβ
Y where Y depends on
the reﬂection string ⃗R(Ψα
X). The details of this pretty involved deﬁnition are in
Section 3.1.
Another difﬁculty arises for reﬂections with complexities above Π3. It may well
happen that ordinals simultaneously belong to different thinning hierarchies, i.e.,
that Ψα
X is an element of Mβ
Y for β, Y different from α and X. In order to reach
step (iv) in the above heuristic we then have to secure that ΨX
α satisﬁes the reﬂec-
tion rules for both thinning hierarchies. To take care of this situation we need the
ﬁne structure theory of Section 3.6, that characterizes the elements of Mβ
Y, and the
subsidiary reﬂection rules introduced in Section 5.2 that are based on this charac-
terization.
2.4
Iterated Skolem–hull operators
Eliminating the reﬂection rules is, however, only one of the problems we have to
meet in an ordinal analysis. The other task is to collapse the involved ordinals
below ωCK
1 . As already mentioned we will base our studies on cardinals instead of
admissible ordinals, so we aim at a collapsing below Ω:= ω+, the ﬁrst uncountable
cardinal. However, already a rough analysis of the eventually obtained transitive
segment of the ordinals will show that it is primitive recursively deﬁnable. So in
fact we obtain a collapsing below ωCK
1 .
Clearly, ordinals as transitive sets are incollapsible. Therefore we have to work
with sets of ordinals that contain (large) gaps. This can be achieved by opera-
tor controlled derivations as introduced by Buchholz in [7] as a simpliﬁcation of
the method of local predicativity (cf. [14]). The heuristic in Section 2.3 has indi-
cated that we have to deal with thinning hierarchies. Therefore we have to combine
Skolem hull operators and thinning hierarchies.12 The basis of the following sec-
tion are therefore iterations of Skolem–hull operators based on thinning hierarchies
Mα
X. Since we have to deﬁne a series of notions simultaneously the deﬁnitions are
pretty involved and will only become clear after the last notions have been deﬁned.
Nevertheless we try to give some motivation for the coming deﬁnitions.
For the basic notions for ordinals, e.g, additively indecomposable ordinals, Ve-
blen function, normal forms etc., we refer to Chapter 3 of [15].
2.6 Deﬁnition A Skolem–hull operator H is a mapping that maps sets of ordinals
to sets of ordinals satisfying the following properties:
12The ﬁrst combination of these methods is in [17].
Provably Recursive Functions of Reflection
391

(SH1)
A ⊆H(A)
(SH2)
If B ⊆H(A) then H(B) ⊆H(A).
Let F := {fξ ξ ∈I} be a set of nξ–ary functions fξ: Onnξ −→On. The
operator HF is then deﬁned inductively by
H0(A) = A
Hn+1(A) = Hn(A) ∪{fξ(⃗α) ⃗α ∈Hn(A)nξ}
HF (A) :=
[
n∈ω
Hn(A).
It is easily checked that HF is a Skolem–hull operator. We call F a generating set
for HF . The functions in F are the generators of HF . From now on we will only
regard Skolem–hull operators that are induced by a set of generators.
A Skolem–hull operator is Cantorian–closed iff ordinal addition is among its
generators. We call it Veblen–closed iff it is Cantorian–closed and the Veblen–
function λξ, η. ϕξ(η), viewed as a binary function, also belongs its the generating
set. By C we denote the Skolem–hull operator H{+} and by V the operator H{+,ϕ}.
By property (SH2) Skolem–hull operators are idempotent, i.e., H(H(A)) = H(A).
Therefore Skolem–hull operators are non–iterable. We will, however, later need
iterations of Skolem–hull operators. To obtain non–trivial iterations we have to
enlarge the set of generating functions during the iteration procedure. Therefore
we deﬁne the functions ψH(α) := min {κ κ /∈Hα(∅)} and require that ψH↾α
belongs to the generating functions of Hα. Then we easily see that in the case of
the operator C we get ψC(0) = 0, ψC(1) = 1, ψC(n + 1) = ωn, ψC(ω) = ωω =
ψC(ψC(ψC(0))) and ﬁnally min {α Cα(∅) = C<α(∅)} = ε0, the ﬁrst ordinal that
is closed under ω–powers.
We get, however, much stronger iterations if we replace ψH by a function ψH
Ω(α)
:= min {κ κ /∈Hα({Ω})}, where Ωdenotes the ﬁrst uncountable cardinal. Then
we similarly have ψC
Ω(0) = 0,
ψC
Ω(n + 1) = ωn, but ψC
Ω(Ω) is already an ordi-
nal that is closed under all ﬁnite iterations of the ψC
Ω–function and the eventually
obtained transitive initial segment of the iterations exceeds the common Veblen hi-
erarchy.13 This is Bachmann’s original idea of employing higher number classes
for the notation of a segment of the countable ordinals. (Cf. [2]). This approach
is well studied and not the topic of this paper.14 We just want to recall some basic
facts which may be helpful in the understanding of the following deﬁnitions.
13The transitive initial segment is the Howard–Bachmann ordinal ψC
Ω(εΩ+1). Cf. [15] Chapter 9.
14The history of these studies starts with Heinz Bachmann’s work (see e.g. [1], [2]) continued by
Solomon Feferman (see e.g. [11]), Peter Aczel, Jane Bridge (Kister) ([5]), Wilfried Buchholz ([6]) and
especially Michael Rathjen ([16],[17],[21],[20]). The presentation of the reﬂection conﬁgurations here
is based on Stegert’s dissertation
392
Wolfram Pohlers and Jan–Carl Stegert

The iterated application of a Skolem–hull operator to a non–transitive set of or-
dinals (such as {Ω} in the above example) will in general result in sets that are
not longer transitive. The role of the uncountable ordinal Ωin the iteration pro-
cess is to stay safely outside of the eventually obtained transitive initial segment
of the ordinal sets generated by the iterated application of the operator.15 Since
κ ⊆Hα(κ ∪{Ω}) holds by deﬁnition, we can combine the condition ψH
Ω(α) =
min {κ κ /∈Hα({Ω})} with the condition that Ωis supposed to lie safely outside
the transitive initial segment by the requirement
ψH
Ω:= min {κ Hα(κ ∪{Ω}) ∩Ω= κ}.
To reduce the notational expense we deﬁne the extension H[B] of an operator H by
a set B of ordinals by
H[B](A) := H(B ∪A).
(1)
Then we can deﬁne ψH
Ω(α) = min {κ Hα(κ) ∩Ω= κ} for any operator H that
extends C[{Ω}].
Another necessity is to express the βth–iteration of an already α–times iter-
ated operator. The ﬁrst and crucial step in showing that (Hα)β(A) = Hα+β(A)
holds under certain preconditions is to prove (Hα)1(A) = Hα+1(A). Still stick-
ing to the simple example of the operator H := C[{Ω}] we see that ψHα
Ω(0) =
min {κ Hα(κ) ∩Ω= κ} = ψH
Ω(α). Albeit Hα+1(A) ⊆(Hα(A))1 holds clearly,
the opposite inclusion will not hold in general. In case that α /∈Hα(A) the sets
Hα(A) and Hα+1(A) will coincide since ψΩ↾α + 1 will not add new elements.
However, under the additional normal–form condition α ∈Hα(∅) we in fact get
(Hα)1 = Hα+1. The normal–form condition α ∈Hα(∅) plays also a crucial
role in other contexts (see [15] Section 9.6 for more details in case of the operator
H = V[{Ω}]). Among other consequences it has the effect to make the function ψH
Ω
a one–to–one function. Therefore it makes sense to restrict all ordinals in Hα(A)
to those that satisfy a normal–form condition, e.g., to alter the deﬁnition of ψH
Ωto
ψH
Ω(α) := min {κ α ∈Hα(κ) ∧Hα(κ) ∩Ω= κ}.
Since predicative proof theory is ruled by the Veblen–function and impredicative
proof theory extends predicative proof theory it is convenient to work with oper-
ators that extend the Veblen–operator V. In fact this is not absolutely necessary,
since the Veblen–functions are reobtained in the iterations of the Cantor–operator
C. The form in which they appear there looks, however, so unfamiliar that we prefer
to include them into the generating set of the starting operators.
Pretty far reaching impredicative axiom system can be ordinally analyzed by
extensions of the Veblen–operator (or even the Cantor–operator). For the analysis
15Cf. [15] Section 9.7 for a discussion of the role of Ω.
Provably Recursive Functions of Reflection
393

of reﬂection axioms (above Π2–reﬂection), however, we have to equip the iterations
of Skolem–hull operators with additional constraints. This ﬁrst paper in which
such constraints became essential was the ordinal analysis of Π3–reﬂection by M.
Rathjen (cf. [17], [19]). Here “thinning operations”, like the Mahlo–operation
M(A) := {κ ∈A κ ∩A is stationary in κ}
came into play. The common iteration of the Mahlo–operation is given by M0 =
Lim (the class of limit ordinals), Mα+1 = M(Mα) and for limit ordinals λ by the
diagonalization Mλ = ∆(M<λ) := {κ ∈λ (∀ξ < κ)[κ ∈M(Mξ)]}. In com-
bination with the Skolem–hull operator H := V[{K}], where K denotes the ﬁrst
Π1
1–indescribable cardinal, the thinning hierarchy based on the Mahlo–operation
has to be modiﬁed by only allowing ordinals in H–normal form, i.e., by deﬁning
Mλ
H := {κ (∀ξ ∈Hξ(κ) ∩λ)[κ ∈M(Mξ
H)]}.
For a regular cardinal π we then deﬁne
ψH
π (α) := min {κ ∈Mα ∩π α ∈Hα(κ) ∧Hα(κ) ∩π = κ}
and augment the generating functions for Hα by the all the functions ψH
π ↾α. As
shown by Rathjen, the so obtained iteration hierarchy sufﬁces for an ordinal analy-
sis of Π3–reﬂection.
Stronger reﬂections, however, need essentially more constraints which we are
going to develop in the following section.
3
Reﬂection conﬁgurations and their instances
3.1
Reﬂection conﬁgurations and their instances
We are interested in Πn–reﬂecting ordinals for all n ≥3. As stated in [22] the car-
dinal counterpart for a Πn+3–reﬂecting ordinal is a Π1
n+1–indescribable cardinal.
We will therefore develop the ordinal theory on the basis of indescribable cardinals.
Let Ξ be the least cardinal that is Π1
n–indescribable for all n ∈ω.
To analyze the theory Ref it is not sufﬁcient just to regard ordinals κ that are re-
ﬂecting (i.e. indescribable) on a single set but we need reﬂection on families of sets.
We express this by saying that κ satisﬁes a reﬂection expression. We are therefore
going to equip κ with a ﬁnite string of reﬂection–expressions.16 These reﬂection–
strings will be denoted by ⃗R(κ). The entries in these strings are reﬂection-ex-
pressions of the form M<α
F – Pm where F is a reﬂection–conﬁguration . Reﬂection
conﬁgurations map tuples of ordinals to reﬂection instances X.
16For even stronger theories, e.g. a theory with an axiom of stability, we even need inﬁnitely long
reﬂection strings.
394
Wolfram Pohlers and Jan–Carl Stegert

Starting with a Skolem–hull operator H that extends V[{0, Ξ}] and, for conve-
nience, also has the cardinal successor function π 7→π+ among its generating
functions, we deﬁne its iterations Hα relative to a thinning hierarchy Mα
X together
with the functions ψH
X where X is a reﬂection–instance of a reﬂection–conﬁguration
F. So there are many notions that have to be deﬁned simultaneously. This will be
done in Deﬁnition 3.2 below. However, we ﬁrst recall the deﬁnition of the iteration
of a Skolem hull operator.
3.1 Deﬁnition The set Hα(A) is the least set that contains A and is closed under
the generating functions of H and the functions ΨH
X ↾α deﬁned below.
We commonly ﬁx H and write Ψα
X instead of ψH
X (α).
The above mentioned normal form condition α ∈Hα(A) will play an important
role. Therefore it is convenient to introduce for an ordinal α, a set B of ordinals
and a tuple ⃗α = α1, . . . , αn of ordinals the abbreviations
α ∈H⋆(A) :⇔α ∈Hα(A)
⃗α ∈H⋆(A) :⇔(∀i ∈{1, . . . , n})[αi ∈H⋆(A)]
B ⊆H⋆(A) :⇔(∀ξ ∈B)[ξ ∈H⋆(A)]
(2)
and for a set M ⊆On the notions
α ∈M↾H⋆(A)
:⇔α ∈M ∧α ∈H⋆(A)
⃗α ∈M↾H⋆(A)
:⇔(∀i ∈{1, . . . , n})[αi ∈M ∧αi ∈H⋆(A)].
(3)
Reﬂection instances X will come with a set Par(X) of ordinal parameters. It is
convenient to introduce the abbreviation
X ∈H⋆(κ) :⇔Par(X) ⊆H⋆(κ).
3.2 Deﬁnition A reﬂection instance is a tuple
X = (π; M; m; Z; δ)
where
•
π =: i(X) is an ordinal ≤Ξ, the reﬂection point of X,
•
M ⊆On ∩Ξ =: RS(X) is the reﬂection range of X,
•
j(X) := min RS(X) is the lower reﬂection bound of X,
•
m =: rdh(X)+1 is a non–negative integer. We call rdh(X) the reﬂection degree
of X
•
Z =: Pd(X) is a reﬂection instance, the predecessor instance of X
•
δ =: o(X) is an ordinal, the iteration degree of X.
A reﬂection conﬁguration is a map F that assigns a reﬂection instance F(⃗ν ) to a
tuple ⃗ν of ordinals. Here we allow the empty tuple ϵ as a legal input.
Provably Recursive Functions of Reflection
395

For a reﬂection conﬁguration F we use the following notations
•
I(F) := {i(F(⃗ν )) ⃗ν ∈dom(F)}
•
i(F) := min I(F)
•
Rdh(F) := {rdh(F(⃗ν )) ⃗ν ∈dom(F)}
•
O(F) := {o(F(⃗ν )) ⃗ν ∈dom(F)}
•
o(F) := min O(F).17
•
Par(F) the set of ordinal parameters of F.
•
For ⃗ν = (ν1, . . . , νn) ∈dom(F) we deﬁne Par(F(⃗ν )) = Par(F)∪{ν1, . . . , νn}.
A reﬂection expression is an expression of the form
M<α
F – Pm
where
•
F =: RC(M<α
F – Pm) is a reﬂection conﬁguration,
•
m =: rdh(M<α
F – Pm) is an integer, the reﬂection degree of M<α
F – Pm,
•
α =: od(M<α
F – Pm) is an ordinal ≥o(F).
For an ordinal κ and a reﬂection expression M<α
F – Pm we deﬁne
κ |= M<α
F – Pm
:⇔







true
if m = −1
κ is Π1
m–indescribable
if α = o(F)
κ is Π1
m–indescribable on Mζ
F(⃗η ) for all
ζ ∈[o(F), α)↾H⋆(κ) and all ⃗η ∈dom(F)↾H⋆(κ).
if o(F) < α.
A reﬂection string is a ﬁnite string of reﬂection expressions. For an ordinal κ and a
reﬂection string ⃗R = (M<ρ1
R1 – Pr1, . . . , M<ρn
Rn – Prn) we deﬁne
•
κ |= ⃗R
:⇔

true,
if ⃗R = ϵ
κ |= M<ρi
Ri – Pri for i = 1, . . . , n,
otherwise,
•
rd(⃗R ) := r1,
•
RE(⃗R ) := R1,
•
od(⃗R ) := ρ1.
For the coming deﬁnitions we introduce some useful notations.
•
⃗Rri := M<ρi
Ri – Pri for ri ∈{r1, . . . , rn}
17We will see in a moment that O(F) is in fact a singleton.
396
Wolfram Pohlers and Jan–Carl Stegert

•
⃗R<ri := (M<ρi+1
Ri+1 – Pri+1, . . . , M<ρn
Rn – Prn)
•
⃗R>ri := (M<ρ1
R1 – Pr1, . . . , M<ρi−1
Ri−1 – Pri−1) 18
Similarly we deﬁne ⃗R≤ri, ⃗R≥ri and ⃗R[rk,rj] where [rk, rj] for k ≥j denotes the
sequence ⟨rk, rk−1, . . . , rj+1, rj⟩. Also the notions of semi–open intervals [rk, rj)
etc. should be obvious.
In the following deﬁnition steps we simultaneously deﬁne reﬂection conﬁgura-
tions F together with their set Par(F) of ordinal parameters, their reﬂection in-
stances X = F(⃗ν ), their thinning hierarchies Mα
X, the ordinals i(F) and i(F(⃗ν ))
and the reﬂection strings ⃗R(i(F))
1. Beginning conﬁgurations
1.1.
The reﬂection conﬁguration A is a beginning conﬁguration with domain
ω \ {0}. We put
•
i(A) = i(A(m + 1)) = Ξ,
•
RS(A(m + 1)) = Ξ, hence j(A(m + 1)) = 0,
•
rdh(A(m + 1)) = m and Rdh(A) = ω,
•
o(A) = o(A(m + 1)) = ω,
•
Par(A) = ∅,
•
the reﬂection conﬁguration A has no predecessors.
I.e.
A(m + 1) = (Ξ; Ξ; m + 1; ∅; ω).
Let
•
⃗R(Ξ) := ε.
1.2. The reﬂection conﬁguration K is a beginning reﬂection conﬁguration whose
domain is the set of inﬁnite cardinals < Ξ. We put
•
i(K(π)) = π+ and I(K) = Card+, the set of successor cardinals below Ξ,
•
RS(K(π)) = Ξ, hence j(K(π)) = 0,
•
rdh(K) = rdh(K(π)) = −1,
•
o(K) = o(K(π)) = 0,
18This looks weird at ﬁrst sight but we will soon see that the components of a reﬂection string are
always ordered by decreasing reﬂection degrees.
Provably Recursive Functions of Reflection
397

•
Par(K) = ∅,
•
the conﬁguration K has no predecessors instances.
I.e.,
K(π) = (π+; Ξ; 0; ∅; 0).
We put
•
⃗R(π+) := (M<ω
A – P0).
2. Successor conﬁgurations.
Let us assume that X is a reﬂection instance of a reﬂection conﬁguration F. For
an ordinal α ≥o(X) we deﬁne
Mα
X :={κ ∈RS(X) ∩i(X) X, α∈H⋆(κ)∧Par(X) ⊆Hα(κ)∧Hα(κ)∩i(X) = κ
∧κ |= ⃗R(i(X))≤rdh(X) ∧κ |= M<α
F – Prdh(X)}
and
Ψα
X :=

min Mα
X
if Mα
X ̸= ∅
i(X)
otherwise.
If rdh(X) = −1 let ⃗R(Ψα
X) = ϵ and for rdh(X) ≥0 we put
⃗R(Ψα
X) =
(
(M<α
A – Pm, M<α
A – Pm−1, . . . , M<α
A – P0)
if X = A(m + 1)
(⃗R(j(X))>rdh(X), eM
<α
F – Prdh(X), ⃗R(i(X))<rdh(X))
otherwise
where eM
<α
F – Pm is deﬁned by
eM
<α
F – Pm =
 ⃗R(i(F))m
if o(F) = α and F ̸= A
M<α
F – Pm
otherwise
and deﬁne the successor conﬁguration Xα. We put
i(Xα) := Ψα
X,
Pd(Xα) := X,
rdh(Xα) =
 rdh(X) −1
if j(X) = 0
rd(⃗R(j(X)) −1)
otherwise
Par(Xα) = Par(X) ∪{α}
and
o(Xα) = α + 1.
Let ⃗R(Ψα
X)rdh(Xα)+1 =: M<ρ
R – Pr. We distinguish the following subcases
398
Wolfram Pohlers and Jan–Carl Stegert

2.1. ρ = o(R). Then dom(Xα) = {ϵ} and
•
RS(Xα(ϵ)) = Ξ.
2.2. ρ > o(R). Then
dom(Xα) = [o(X), ρ)↾H⋆(Ψα
X ) × (dom(R)↾H⋆(Ψα
X ) \ (rdh(Xα) + 1))
and we put
•
RS(Xα(ζ,⃗ν )) := Mζ
R(⃗ν ) for ζ ∈[o(X), ρ)↾H⋆(Ψα
X ) and ⃗ν ∈dom(R)↾H⋆(Ψα
X )
such that rdh(Xα) + 1 < ⃗ν if ⃗ν ̸= ϵ.
For the remaining entities we deﬁne
•
i(Xα(ζ,⃗ν )) = i(Xα)
•
o(Xα(ζ,⃗ν )) = o(Xα)
•
rdh(Xα(ζ,⃗ν )) = rdh(Xα)
•
Pd(Xα(ζ,⃗ν )) = Pd(Xα)
The predecessor conﬁguration Pdc(Xα) of Xα is F, the reﬂection conﬁguration
of its predecessor instance X.
3.2
Basic Structure Theory
It is not yet clear that the sets Mα
X are not empty. This is of course a crucial point
because otherwise the deﬁnition of Ψα
X becomes trivial. However, we postpone this
“existence proof” to the next section and study ﬁrst some of the basis consequences
of Deﬁnition 3.2.
3.3 Deﬁnition The set of pre–conﬁgurations of a reﬂection conﬁguration F or a
reﬂection instance X of F is recursively deﬁned by
Prcnf(X) = Prcnf(F) = {F} ∪Prcnf(Pdc(F)) and
Prcnf(F) = Prcnf(Pdc(F)).
Similarly we deﬁne for a reﬂection–instance X the set of predecessor instances by
Prinst(X) = {X} ∪Prinst(Pd(X)) and
Prinst(X) = Prinst(Pd(X)).
For reﬂection conﬁgurations G in the predecessor conﬁgurations of an instance X
of a reﬂection conﬁguration F we deﬁne
ranα
F(G) := ranα
X(G) :=

min {δ Gδ ∈Prcnf(X)}
if this exists
α
otherwise.
Provably Recursive Functions of Reflection
399

For Z = G(⃗µ) ∈Prinst(X) we deﬁne
ranα
F(Z) := ranα
X(Z) := ranα
X(G).
The following three lemmas are obvious from the deﬁnition.
3.4 Lemma For o(F) ≤α, ⃗ν ∈dom(F) and ⃗µ ∈dom(G) we have ranα
F(G) =
ranα
F(⃗ν )(G) = ranα
F(⃗ν )(G(⃗µ)) ≤α.
3.5 Lemma Let F be a reﬂection–conﬁguration. Then we get
1. If F ̸= K then I(F) is a singleton.
2. If F ̸= A then Rdh(F) is a singleton.
3. If X is a reﬂection instance of a reﬂection conﬁguration F then o(F) = o(X).
4. If rdh(X) ̸= −1 then Ψα
X is an uncountable regular cardinal.
5. If i(X) = i(Y) then o(X) = o(Y).
3.6 Lemma For X = F(⃗ν ) we obtain.
1. o(Pd(X)) < o(X), hence o(Z) < o(X) for Z ∈Prinst(X).
2. X ∈H⋆(i(X)).
3. If Y ∈Prinst(X) then Par(Y) ⊆Par(X) and F ∈Prcnf(G) implies Par(F) ⊆
Par(G).
4. If RS(Pd(X)) = Ξ then rdh(X) = rdh(Pd(X)) −1.
5. If RS(Pd(X)) = Mζ
M(⃗η ) then rdh(X) = rd(⃗R(j(X))) −1.
6. ⃗R(Ψα
X)rdh(X) = eM
<α
F – Prdh(X).
Proof
All these claims follow directly from Deﬁnition 3.2. The second claim in
1. and claim 3. need induction on o(X) or o(G), respectively.
□
Also the next lemma is a consequence of Deﬁnition 3.2. Its proof, however, is less
straightforward and needs a cumbersome simultaneous induction on the iteration
height of Y. We present the full proof since it helps to clarify Deﬁnition 3.2.
3.7 Lemma Let G be a reﬂection–conﬁguration and (ζ, ⃗µ) ∈dom(G).
1. The reﬂection–instance Y := G(ζ, ⃗µ) has the following properties.
400
Wolfram Pohlers and Jan–Carl Stegert

1.1. If o(G) ̸= 0 and ⃗ν ∈dom(G) then ⃗ν < o(G). 19
1.2. If o(Y) ̸= 0 then Par(Y) ⊆o(Y).
1.3. If RS(Y) = Mζ
R(⃗µ) ̸= Ξ then
1.3.1. R ∈Prcnf(G)
1.3.2. rdh(Y) < rdh(R(⃗µ)).
1.3.3. Par(R(⃗µ)) ∪{ζ} ⊆Par(Y).
2. Assume o(Y) ̸= 0 and ⃗R(Ψβ
Y) = (M<ρ1
R1 – Pr1, . . . , M<ρk
Rk – Prk). Then we get
for i ∈{1, . . . , k}
2.1. Ri ∈Prcnf(G) and dom(Ri) ≤β.
2.2. ρi ≤ranβ
G(Ri) and Ri = A if ρi = o(Ri).
2.3. ρi ∈Par(Y) ∪{β}.
2.4. r1 ≥rdh(Y) and (r1, . . . , rk) = (k −1, k −2, . . . , 1, 0).
2.5. There is a ⃗µi ∈dom(Ri) such that rdh(Ri(⃗µi)) = ri.
2.6. If Ri ̸= A then rdh(Ri) = ri for all ⃗µi ∈dom(Ri).
Proof
We prove the lemma simultaneously by induction on the iteration height
o(G) of G.
1.1 If G = A then dom(G) = ω = o(G).
If G is a successor conﬁgu-
ration Xα and ⃗R(Ψα
X)rdh(G)+1 = M<ρ
R – Pr then dom(G) ⊆[o(X), ρ)↾H⋆(Ψα
X ) ×
dom(R)↾H⋆(Ψα
X ). By the induction hypothesis for 2.2 applied to Ψα
X we have ρ ≤
ranα
X(R) ≤α < o(G) and dom(R) ≤ρ ≤α follows from the induction hypothesis
for 2.1.
1.2 For Y = A(m + 1) we have Par(Y) = {m + 1} < ω = o(Y). The case
Y = K(π) is excluded. For G = Xα we get Par(G) = Par(X)∪{α}. By induction
hypothesis we have Par(X) < o(X) ≤α < α+1 = o(Y) and for (ζ,⃗ν ) ∈dom(G)
that ζ ≤α and ⃗ν ∈dom(R) for R = RC(⃗R(Ψα
X)rdh(Y)+1). Hence ⃗ν < α < o(Y)
by induction hypothesis for 2.1 applied to ⃗R(Ψα
X).
1.3.
Y is an instance of a successor conﬁguration G = Xα since RS(Y) ̸= Ξ.
Let X be an instance of a conﬁguration F and ⃗R(Ψα
X)rdh(Y)+1 = M<ρ
R – Pr. Since
RS(Y) ̸= Ξ we have ρ > o(R).
1.3.1 We get R ∈Prcnf(F) ⊆Prcnf(G) by the induction hypothesis for 2.1
applied to ⃗R(Ψα
X).
19For a tuple ⃗ν = ν1, . . . , νn we denote by ⃗ν < β that νi < β holds true for i = 1, . . . , n.
Similarly we deﬁne ⃗ν ≤β. If M is a set of tuples, we mean by M < β that ⃗ν < β holds true for all
⃗ν ∈M. Similarly we deﬁne M ≤β.
Provably Recursive Functions of Reflection
401

1.3.2. It is rdh(Y) = r −1. If R ̸= A we get rdh(R(⃗µ)) = r > rdh(Y) by
the induction hypothesis for 2.6. If R = A we have µ = n for some ω > n >
rdh(Y) + 1 and rdh(A(n)) = n −1 > rdh(Y).
1.3.3. By 1.3.1 and Lemma 3.6 claim 3 we have Par(R) ⊆Par(G). Since
Par(Y) = Par(G) ∪{ζ, ⃗µ} the claim is clear.
2. Assume ﬁrst Y = A(m). Then Ri = A and ρi = β ≥ω ⊇dom(A) for
i = 1, . . . , n and claims 2.1 and 2.3 hold trivially. Since ranβ
A(A) = β also 2.2 is
clear. By deﬁnition we have r1 = rdh(Y) and r1, . . . , rn = (k −1, k −2, . . . , 0).
Hence claim 2.4, and rdh(A(ri + 1)) = ri which also shows claim 2.5.
So assume that G is a successor conﬁguration Xα where X is an instance of a
conﬁguration F and let ⃗R(Ψα
X)rdh(Y)+1 = M<ρ
R – Pr. Then
⃗R(Ψβ
Y) = (⃗R(Ψζ
R(⃗µ))≥r, eM
<β
G – Pr−1, ⃗R(Ψα
X)<r−1)
where ⃗R(Ψζ
R(⃗µ))≥r is empty in case that that o(R) = ρ. If ρ > o(R) we have
R ∈Prcnf(G), hence o(R) < o(G) by 1.3.1. Therefore we can apply the induction
hypothesis to ⃗R(Ψζ
R(⃗µ)) and ⃗R(Ψα
X). Let j be such that eM
<β
G – Pr−1 = M<ρj
Rj – Prj.
Then for i < j we get by induction hypothesis
Ri ∈Prcnf(R) ⊆Prcnf(G), dom(Ri) ≤ζ ≤α < β,
ρi ≤ranζ
R(Ri) = ranβ
G(Ri) and Ri = A if ρi = o(Ri)
ρi ∈Par(R(⃗µ)) ∪{ζ} ⊆Par(Y)
Likewise we get for i > j by induction hypothesis
Ri ∈Prcnf(F) ⊆Prcnf(G), dom(Ri) ≤α < β,
ρi ≤ranα
F(Ri) = ranβ
G(Ri) and Ri = A if ρi = o(Rj)
ρi ∈Par(X) ∪{α} ⊆Par(Y).
Therefore claims 2.1 through 2.3 hold for i ̸= j. For i = j we get M<ρi
Ri – Pri =
eM
<β
G – Pr−1. If G = A or o(X) < β we thus have M<ρi
Ri – Pri = M<β
G – Pr−1 which
implies G ∈Prcnf(G) and dom(G) ≤max{dom(F), α} < β. Moreover we have
β = ranβ
G(G) and β ∈Par(Y)∪{β}. If R ̸= A and β = o(G) we get M<ρi
Ri – Pri =
⃗R(Ψα
X)r−1 and obtain by induction hypothesis that Ri ∈Prcnf(F) ⊆Prcnf(G),
dom(Ri) ≤α < β, ρi ≤ranα
F(Ri) = ranβ
G(Ri), Ri = A if ρi = o(Ri) and
ρi ∈Par(X) ∪{α} ⊆Par(Y). So we proved 2.1 – 2.3 for all cases.
The induction hypothesis for 2.4 applied to ⃗R(Ψα
X)<r−1 yields rj ≥rdh(X) and
(rj+1, . . . , rn) = (r −2, r −3, . . . , 0). Applying it to ⃗R(Ψζ
R(⃗µ))≥r yields r1 ≥
rdh(R(⃗µ)) ≥rdh(Y) and (r1, . . . , rj+1) = (r1, r1 −1, . . . , r). Since rj = r −1
402
Wolfram Pohlers and Jan–Carl Stegert

we get that (r1, . . . , rk) = (r1, r1 −1, . . . , 0), i.e., r1 = k −1. This proves claim
2.4.
For i ̸= j claims 2.5 and 2.6 follow directly from the induction hypothesis. For
i = j we either have Ri = G and rdh(G(ζ, ⃗µ)) = r −1 = ri or we get the claim
from the induction hypothesis applied to ⃗R(Ψα
X)r−1.
□
3.8 Corollary Let X be a successor instance such that RS(X) = Mζ
M(⃗µ). Then
rdh(X) + 1 ∈Rdh(M). If M ̸= A then rdh(X) = rdh(M) −1.
Proof
We have by deﬁnition that ⃗R(i(X))rdh(X)+1 = M<γ
M – Pr for some r. By
claims 2.5 and 2.6 of the above lemma we get rdh(X) + 1 = r ∈Rdh(M) and
rdh(M) = r = rdh(X) + 1 for M ̸= A.
□
3.9 Lemma If Y is a reﬂection instance of a reﬂection–conﬁguration G ̸= A then
rd(⃗R(i(Y))) = rdh(Y) + 1 and
⃗R(i(Y))rdh(Y)+1 =
(
M<ω
A – Prdh(Y)+1
if RS(Y) = Ξ
M<ρ
R – Prdh(Y)+1 for some ρ > ζ
if RS(Y) = Mζ
R(⃗µ).
Proof
Assume ﬁrst hat Y = K(π).
Then rdh(Y) = −1, rd(π+) = 0 and
⃗R(i(Y))0 = ⃗R(π+)0 = (M<ω
A – P0).
Now assume that G = Xα. Then i(Y) = Ψα
X. We have rd(⃗R(Ψα
X)) = rdh(X) =
rdh(Y)+1 if j(X) = 0 and rd(⃗R(Ψα
X)) = rd(⃗R(j(X))) = rdh(Y)+1 for j(X) ̸= 0.
Let M<ρ
R – Pr := ⃗R(i(Y))rdh(Y)+1. If RS(Y) = Ξ then ρ = o(R) and by Lemma 3.7
claim 2.2 we obtain R = A and ρ = ω. Otherwise we have RS(Y) = Mζ
R(⃗µ) for
some ζ < ρ.
□
3.10 Lemma Let Y be a reﬂection–instance of a reﬂection–conﬁguration G ̸= K.
Then all κ ∈Mβ
Y satisfy κ |= ⃗R(Ψβ
Y).
Proof
We induct on o(Y). Recall that κ ∈Mβ
Y entails κ |= M<β
G – Prdh(Y) and
κ |= ⃗R(i(Y))≤rdh(Y).
Let ﬁrst Y = A(m + 1). Then ⃗R(Ψβ
Y) = (M<β
A – Pm, . . . , M<β
A – P0). But κ |=
M<β
A – Pm clearly implies κ |= M<β
A – Pj for all j ≤m.
Now assume G = Xα for some α ≥o(X). Then
⃗R(Ψβ
Y) = (⃗R(j(Y))>rdh(Y), eM
<β
G – Prdh(Y), ⃗R(i(Y))<rdh(Y)).
For β > o(G) it is eM
<β
G – Prdh(Y) = M<β
G – Prdh(Y) and eM
<β
G – Prdh(Y) = ⃗R(i(Y))rdh(Y)
for β = o(G).
So we have κ |= eM
<β
G – Prdh(Y) in both cases and thus κ |=
Provably Recursive Functions of Reflection
403

⃗R(Ψβ
Y)≤rdh(Y). In case that RS(Y) = Ξ we are therefore done. If RS(Y) = Mζ
R(⃗µ),
hence j(Y) = Ψζ
R(⃗µ), we also have κ ∈Mζ
R(⃗µ) and therefore by induction hypoth-
esis κ |= ⃗R(j(Y)), hence also κ |= ⃗R(j(Y))>rdh(X).
□
It is often convenient to deﬁne a reﬂection string associated to a reﬂection conﬁgu-
ration F ̸= K. We deﬁne
⃗R(F) := ⃗R(i(F))≤rdh(F).20
If X is reﬂection instance of a reﬂection conﬁguration F we deﬁne
⃗R(X) := ⃗R(F).
3.3
The existence proof
The next important step is to show that Ψα
X < i(X) holds true for every reﬂection–
instance X. This is proved as soon as we realize that for any reﬂection–instance
X and every α ≥o(X) the set Mα
X is not void. We start with some preparatory
observations.
3.11 Lemma Let α ≤β and κ ≤π. Then
3. Hα(κ) ⊆Hβ(π).
4. Hα(κ) = max{ℵ0, κ}.
5. Hλ(κ) = H<λ(κ) := S
ξ<λ Hξ(κ) and Hα(λ) = S {Hα(ξ) ξ < λ} hold true
for all limit ordinals λ.
The proofs are all obvious.
3.12 Lemma Let π be an uncountable regular cardinal. Then the set
Mπ := {κ ∈π Hα(κ) ∩π = κ}
is club in π. This can be sharpened that for X, α ∈H⋆(π) and Par(X) ⊆Hα(π)
also the set
M α,X
π
:= {κ ∈π X, α ∈H⋆(κ) ∧Par(X) ⊆Hα(κ) ∧Hα(κ) ∩π = κ} (4)
is club in π.
20For a reﬂection instance X = F(⃗ν ) it is immediate from the deﬁnition that ⃗R(i(X))≤rdh(F) does
not depend on the argument ⃗ν . This is not true for ⃗R(i(X))>rdh(F).
404
Wolfram Pohlers and Jan–Carl Stegert

Proof
We only show the sharpened version of the lemma. So let π be a regular
uncountable cardinal and assume X, α ∈H⋆(π) and X ⊆Hα(π). By Lemma 3.11
claim 5 there is a µ < π such that X, α ∈H⋆(µ) and Par(X) ⊆Hα(µ). Let ρ < π
and put ρ0 = max{ρ, µ}. Then ρ0 < π, X, α ∈H⋆(ρ0) and Par(X) ⊆Hα(ρ0).
Now deﬁne ρn+1 := sup Hα(ρn) ∩π. Then we obtain by induction on n that
ρn < π, hence ρn < π, Par(X) ⊆Hα(ρn) and X, α ∈H⋆(ρn), for all all n ∈ω.
Since π is regular and bigger than ω we then get ρ∗:= supn∈ω ρn < π and
Hα(ρ∗) ∩π ⊆S
n∈ω Hα(ρn) ∩π ⊆supn∈ω ρn+1 ⊆ρ∗,
X, α ∈H⋆(ρ∗) and
Par(X) ⊆Hα(ρ∗). So M α,X
π
is unbounded in π.
To prove also closedness in π let N ⊆M α,X
π
, N < π and λ := sup N. Then
we get X, α ∈H⋆(µ) and Par(X) ⊆Hα(µ) for all µ ∈N ∩λ, hence also X, α ∈
H⋆(λ), Par(X) ⊆Hα(λ) and Hα(λ)∩π = S
µ∈N∩λ Hα(µ)∩π = S
µ∈N∩λ µ =
λ. So λ ∈M α,X
π
.
□
3.13 Lemma Let X be a reﬂection instance and π an uncountable regular cardinal
such that α, X ∈H⋆(π) and Par(X) ⊆Hα(π). If M α,X
π
is unbounded in a limit
ordinal κ < π then
α, X ∈H⋆(κ), Par(X) ⊆Hα(κ) and Hα(κ) ∩π = κ.
Proof
Since M α,X
π
is unbounded in κ we have Hξ(κ) = S
σ∈Mα,X
π
∩κ Hξ(σ) for
any ξ. Hence α, X ∈H⋆(κ) and Par(X) ⊆Hα(κ). Similarly we get Hα(κ) ∩π =
S
σ∈Mα,X
π
∩κ Hα(σ) ∩π = supσ∈Mα,X
π
∩κ σ = κ.
□
3.14 Lemma Let X = K(κ) and α, X ∈H⋆(κ). Then Mα
X ̸= ∅and κ < Ψα
X < κ+
for all α > 0. Especially Ψα
K(κ) is not regular. Conversely is X an instance of K if
Ψα
X is not a regular cardinal.
Proof
Since κ+ is an uncountable regular cardinal we get by Lemma 3.12 that
Mα
X = M X,α
κ+ is club in κ+ and therefore not void. Hence Ψα
X < κ+. On the other
hand we have κ ∈Par(X) ⊆Ψα
X ∩κ+ = Ψα
X.
If X = F(⃗ν ) for F ̸= K then rdh(X) ≥0. Therefore Ψα
X is Π1
0–indescribable,
hence regular.
□
3.15 Lemma Let X
be an instance of a reﬂection conﬁguration
F
such that
rdh(X) ≥0.
1. Assume that ξ ≥o(X) and let π be a Mξ
X–Π1
0–indescribable cardinal. Then the
set Mξ
X is stationary in π.
2. If X is an instance of a reﬂection conﬁguration F ̸= K and α ≥o(X) then the
set Mξ
X is stationary in κ for all κ ∈Mα
X and ξ ∈[o(X), α)↾H⋆(Ψα
X ).
Provably Recursive Functions of Reflection
405

Proof
To prove 1 let π be Mξ
X–Π1
0–indescribable and C ⊆π club in π. Then
‘C is unbounded in κ’
⇔(∀α ∈κ)(∃β ∈C)[α ≤β]
⇔(Vκ, C) |= (∀α)(∃β ∈C)[α ≤β].
Therefore there is a κ0 ∈Mξ
X∩π such that (Vκ0, C ∩Vκ0) |= (∀α)(∃β ∈C)[α ≤β]
i.e. (∀α < κ0)(∃β ∈C)[α ≤β ≤κ0]. Hence κ0 = sup {β ∈κ0 β ∈C} which
entails κ0 ∈C since C is closed. So Mξ
X ∩C ̸= ∅.
To show 2. observe that κ ∈Mα
X and rdh(X) ≥0 implies κ |= M<α
F – Prdh(X).
So κ is Mξ
X–Π1
0–indescribable for all ξ ∈[o(X), α)↾H⋆(Ψα
X ).
□
The next aim is to show that also for X ̸= K(κ) the sets Mα
X are non void and
therefore Ψα
X < i(X). This is exactly the point where we use indescribability in-
stead of reﬂection properties. The following considerations will illuminate that a
development of the ordinal theory on the basis of reﬂecting ordinals requires much
more sophisticated arguments.
We are going to work within the cumulative hierarchy VΞ where Ξ denotes the
ﬁrst cardinal that is Π1
n–indescribable for all ﬁnite n.
The ordinals in an iterated Skolem Hull operator Hα(π) can be represented by
terms that are built up from parameters in H(∅) ∪π by the generators of H and the
functions ΨX↾α. We use this fact to deﬁne for β ∈Hα(π) the code β
α,π relative
to Hα(π). However, since we do not yet know that the term notation is unique, we
will rather deﬁne a set β
α,π of codes for β relative to an arbitrary ordinal α and an
ordinal π ∈Reg∪{0}.21 As a preparation we have to represent reﬂection instances
as sets in VΞ. Here it is unimportant which coding machinery we use. But observe
that the proof of Theorem 2.4, which we did not give here, needs a ﬂat coding.
3.16 Deﬁnition (Representing vectors for reﬂection instances). Let Y be a reﬂec-
tion instance. We deﬁne its representing vector ⃗Y by the following rules.
⃗Y :=



⟨m⟩
if Y = A(m)
⟨κ⟩
if Y = K(κ)
⟨α, ⃗X, ⃗µ⟩
if Y is a successor instance Xα(⃗µ).
3.17 Lemma Let Y and Z be reﬂection instances such that ⃗Y = ⃗Z. Then Y = Z.
Proof
Obvious by induction on o(X).
21In order not to complicate the notations unnecessarily we restrict ourselves to the case that the
Skolem-hull-operators are generated by +, ϕ and the cardinal successor functions. It should be obvious
how this can be generalized to operators that are generated by any ﬁnite set of functions.
406
Wolfram Pohlers and Jan–Carl Stegert

3.18 Deﬁnition Let π be an uncountable regular cardinal less than Ξ. For some
ordinals β we inductively deﬁne the set β
α,π ∈Lπ of codes for β relative to α
and π by the following clauses.
1. If β = Ξ then 1 ∈β
α,π.
2. If ξ < π then ξ ∈ξ
α,π.
3. If β =NF β1 +· · ·+βn and ai ∈βi
α,π for i = 1, . . . , n then ⟨1, a1, . . . , an⟩∈
β
α,π.
4. If β =NF ϕβ1(β2) and ai ∈βi
α,π for i = 1, 2 then ⟨2, a1, a2⟩∈β
α,π.
5. If β = κ+ and a ∈κ
α,πthen ⟨3, a⟩∈β
α,π.
6. If β = Ψδ
X, δ < α, ⃗X = ⟨ξ1, . . . , ξn⟩, a0 ∈
δ
α,π and ai ∈
ξi
α,π for
i = 1, . . . , n then ⟨4, a0, a1, . . . , an⟩∈β
α,π.
3.19 Remark If +, ϕ and
+ are the only generating functions for H we clearly
get β
α,π ̸= ∅for every β ∈Hα(π) .
Moreover it is evident how to deﬁne the value |a| ∈On for every code a ∈
η
α,π. It is easy to see that for a, b ∈
η
α,π we get |a| = |b| = η. But observe
that η
α,π is in general not a singleton. E.g., for ξ, ζ < π the value of ⟨2, ξ, ζ⟩will
be ϕξ(ζ) =: η which again is an ordinal below π. Hence |η| = η = |⟨2, ξ, ζ⟩| and
we have η, ⟨2, ξ, ζ⟩∈η
α,π although η and ⟨2, ξ, ζ⟩are different sets.
Of course this ambiguity can be avoided by restricting cases 3. – 6. to ordinals
≥π. But even then it is not yet clear that we get unique codes since we do not yet
know that Ψβ0
X = Ψβ1
Y entails X = Y and β0 = β1.
According to the deﬁnition of the codes we obtain
η
α,π ∩Vκ = η
α,κ.
(5)
3.20 Lemma There is a Π1
0–formula Unb(P, a, u1, . . . , un) such that for a reﬂec-
tion instance X with ⃗X = (ξ1, . . . , ξn),
α ≥o(X) and an uncountable regular
cardinal π we have
M α,X
π
is unbounded in π iff (Vπ, M α,X
π
) |= Unb(P, α
α,π, ξ1
α,π, . . . , ξn
α,π),
where M α,X
π
is the set deﬁned in (4).
Proof
Deﬁne
Unb(P, a, u1, . . . , un)
Provably Recursive Functions of Reflection
407

:⇔(∀ξ)(∃η)(∃⃗y)[ξ ≤η ∧η ∈P(⃗y) ∧⃗y ∈a × u1 × · · · × un].
□
We are now going to code also the reﬂections sets Mα
X for reﬂection instances X
that are instances of a reﬂection conﬁguration F. We deﬁne
M<ξ
F
α,π :=
[
{ ζ
α,π × η1
α,π × · · · × ηn
α,π × Mζ
F(⃗η ) | ζ ∈[o(F), ξ)↾H⋆(π)
∧⃗η ∈dom(F)↾H⋆(π)}.
Clearly we again obtain
M<ξ
F
α,π ∩Vκ = M<ξ
F
α,κ.
(6)
For a reﬂection conﬁguration F we denote by M<ξ
F
̸= ∅that Mζ
F(⃗η ) ̸= ∅for all
⃗η ∈dom(F)↾H⋆(π) and ζ ∈[o(F), ξ)↾H⋆(π).
The following lemma is a consequence of Corollary 2.5.
3.21 Lemma Let F be a reﬂection conﬁguration of arity k ≥0. Then there is a
Π1
m+1–sentence eψm(P) such that for any regular cardinal κ ≤π := i(F) and
ordinal ξ such that M<ξ
F
̸= ∅we have
κ |= M<ξ
F – Pm iff (Vκ, M<ξ
F
α,κ) |= eψm(P).
Proof
Deﬁne
eψm(P) :⇔
(∀x1) . . . (∀xk)(∃y)

(x1, . . . , xk, y) ∈P →
(∀X)(∀z)

ψm(X, z) →(∃σ)[(x1, . . . , xk, σ) ∈P ∧ψm(X ∩Vσ, z)Vσ]

where ψm is the universal formula for Π1
m–formulas (cf. Theorem 2.4).
□
3.22 Theorem Let X be a reﬂection instance and α ≥o(X) such that α∈H⋆(i(X)).
Then Mα
X ̸= ∅.
Proof
We induct on α. Let X = F(ξ,⃗ν ) and π := i(X). Then ξ,⃗ν ∈H⋆(π).
1. Let rdh(X) = −1.
1.1. RS(X) = Ξ. Then we either have F = K and obtain Mα
X ̸= ∅by Lemma 3.14
or X is an instance of a successor conﬁguration whose predecessor has reﬂection
degree 0. Hence π |= M<ω
A – P0, i.e., π is Π1
0–indescribable and thus uncountable
and regular. By Lemma 3.12 we thus get that Mα
X is club in π and therefore not
void.
408
Wolfram Pohlers and Jan–Carl Stegert

1.2.
RS(X) = Mξ
M(⃗ν ). Then X ̸= A(m) for any m and Mα
X = Mξ
M(⃗ν ) ∩
M α,X
π
.22 Since ξ ∈Par(X) ⊆o(X) ≤α (by Lemma 3.7 claim 1.2) we have
Mξ
M(⃗η ) ̸= ∅by induction hypothesis. By Lemma 3.9 and Lemma 3.10 it follows
π = i(X) |= M<γ
M – P0 for some γ > ζ. Therefore π is Mξ
M(⃗ν )–Π1
0–indescribable
and by Lemma 3.15 2. we get that Mξ
M(⃗ν ) is stationary in π. Since M α,X
π
is club
in π it is MX
α ̸= ∅.
2. Let rdh(X) =: m −1 ≥0. We have to show that there is an ordinal κ ∈
RS(X) ∩π satisfying
X, α ∈H⋆(κ) and Par(X) ⊆Hα(κ),
(i)
Hα(κ) ∩π = κ,
(ii)
κ |= ⃗R(X) and
(iii)
κ |= M<α
F – Pm−1.
(iv)
Clearly Ξ ̸= ∅and for RS(X) =: Mξ
M(⃗ν ) we get Mξ
M(⃗ν ) ̸= ∅by the induction
hypothesis as in case 1.2. By Lemmata 3.10 and 3.9 we also have
π |= ⃗R(X) =: (M<ρ1
R1 – Pr1, . . . , M<ρk
Rk – Prk)
(v)
and
π |= M<ω
A – Pm if RS(X) = Ξ,
(vi)
π |= M<γ
M – Pm for some γ > ξ, otherwise .
(vii)
In both cases we get that π is RS(X)–Π1
m–indescribable and thus uncountable and
regular. By Lemma 3.12 we therefore obtain
M α,X
π
is club in π.
(viii)
If π = Ξ we trivially have X ∈H⋆(π). If π = Ψδ
Y then δ < α and we have
Mδ
Y ̸= ∅by induction hypothesis. Hence Y, δ ∈H⋆(π). Since Par(X) = Par(Y)∪
{δ} ∪{ξ,⃗ν } we again get X ∈H⋆(π).
Let ⃗X =: (ξ1, . . . , ξn). From Lemma 3.20 it then follows
(Vπ, M α,X
π
) |= Unb(P, α
α,π, ξ1
α,π, . . . ξn
α,π)
(ix)
where Unb(P, . . .) is the formula described there.
For β ≤α we are going to prove
22cf. (4) for a deﬁnition of Mα,X
π
.
Provably Recursive Functions of Reflection
409

π is Mζ
F(⃗η )–Π1
m–indescribable for all ζ ∈[o(X), β]↾H⋆(π) and
all ⃗η ∈dom(F)↾H⋆(π)
(x)
by side–induction on β. For β ∈H⋆(π) ∩(α + 1) the induction hypothesis postu-
lates
π is Mζ
F(⃗η )–Π1
m–indescribable for all ζ ∈[o(X), β)↾H⋆(π) and
all ⃗η ∈dom(F)↾H⋆(π), i.e. π |= M<β
F – Pm
(xi)
which by the main induction hypothesis and trivially implies
M<β
F
̸= ∅and π |= M<β
F – Pm−1.
(xii)
By Lemma 3.7 claim 2.3 we have ρi < α and thus by the main induction hypothesis
and (iii)
M<ρi
Ri
̸= ∅and π |= M<ρi
Ri – Pri for i = 1, . . . , k.
(xiii)
Together with (ix) this yields
Vπ |= Unb(M α,X
π
) ∧eψm−1( M<β
F
α,π) ∧Vk
i=1 eψri( M<ρi
Ri
α,π)
(xiv)
by Lemma 3.21, and the formula in (xiv) is Π1
m. For any Π1
m formula F(X) and
P ⊆Vπ such that (Vπ, P) |= F(X) we thus get a κ ∈π ∩RS(X) such that
Vκ |= Unb(M α,X
π
∩Vκ) ∧eψm−1( M<β
F
α,π ∩Vκ) ∧
Vk
i=1 eψri( M<ρi
Ri
α,π ∩Vκ) ∧F(P ∩Vκ).
(xv)
Therefore M α,X
π
∩Vκ is unbounded in κ which entails α, X ∈H⋆(κ), Par(X) ⊆
Hα(κ) and Hα(κ) ∩π = κ by Lemma 3.13. So (i) and (ii) are fulﬁlled. By (6) we
get from (xv)
Vκ |= eψm−1( M<β
F
α,κ) ∧Vk
i=1 eψri( M<ρi
Ri
α,π) ∧F(P ∩Vκ)
and ﬁnally from Lemma 3.21 together with (xiii) and (xiv)
κ |= M<β
F – Pm−1 ∧Vk
i=1κ |= M<ρi
Ri – Pri.
Hence κ ∈Mβ
F(⃗η ) and π is thus Mβ
F(⃗η )–Π1
m–indescribable. This proves (x) and
simultaneously shows that κ fulﬁlls (iii). However, for α ∈H⋆(π) we get by (x)
also κ |= M<α
F – Pm−1, i.e. (iv), and are done.
□
3.23 Corollary Let X be a reﬂection instance. Then Ψα
X < i(X) holds true iff
α ∈H⋆(i(X)) and α ≥o(X). Moreover Ψα
X < i(X) implies X, α ∈H⋆(Ψα
X) and
Par(X) ⊆Hα(Ψα
X).
410
Wolfram Pohlers and Jan–Carl Stegert

Proof
It is Ψα
X ≤i(X). We just proved that o(X) ≤α ∈H⋆(i(X)) implies Ψα
X <
i(X). If Ψα
X < i(X) then Ψα
X ∈Mα
X. Hence o(X) ≤α and α, X ∈H⋆(Ψα
X) which
entails α ∈H⋆(i(X)). By deﬁnition of Ψα
X we also have Par(X) ⊆Hα(Ψα
X).23
□
From now on we use the shorthand Ψα
X↓to denote that o(X) ≤α and Ψα
X < i(X).
3.24 Lemma Let X be a reﬂection instance and α ≥o(X). Then Par(X) ⊆
Hα(A) implies i(X) ∈Hα(A)
Proof
The claim is clear for X = A(m). If X = K(κ) then κ ∈Par(X) ⊆
Hα(A). Hence i(X) = κ+ ∈Hα(A) by closure under cardinal successor.
In all other cases we have i(X) = Ψδ
Z for Z ∈Prcnf(X) and δ < o(X). Hence
Par(Z) ⊆Par(X) ⊆Hα(A) and δ ∈Hα(η)∩α and therefore i(X) ∈Hα(A).
□
3.25 Corollary Let X be a reﬂection instance and α ≥o(X).
Then i(X) ∈
Hα(Ψα
X).
Proof
Since Par(X) ⊆Hα(Ψα
X) this follows directly from the Lemma.
□
3.4
Ordinal comparison
For tuples ⃗α and ⃗β we denote by ⃗α <l ⃗β that ⃗α precedes ⃗β in the lexicographical
ordering.
3.26 Lemma Let F be a reﬂection conﬁguration, κ an ordinal and ⃗η ∈dom(F)
such that rdh(F(⃗η )) =: m ≥0 and ⃗η ∈H⋆(κ). If κ ∈Mα
F(⃗η ) then for any β ≤α
and ⃗ν ∈dom(F) such that β,⃗ν ∈H⋆(κ) and (β,⃗ν ) <l (α, ⃗η ) the ordinal κ is
Mβ
F(⃗ν )–Π1
m–indescribable.
Proof
We induct on o(F). Let ⃗η = η1, . . . , ηn and ⃗ν = ν1, . . . , νn.
1. Assume ﬁrst β < α. Since κ ∈Mα
F(⃗η ) and rdh(F) = m we have κ |= M<α
F – Pm
and therefore that κ is Mβ
F(⃗ν )–Π1
m–indescribable.
2. Now assume that α = β and ⃗ν <l ⃗η . We have RS(F(⃗η )) = Mη1
M(η2,...,ηn) and
RS(F(⃗ν )) = Mν1
M(ν2,...,νn) for some reﬂection conﬁguration M ∈Prcnf(F) and
Mα
F(⃗η ) ⊆Mη1
F(η2,...,ηn) as well as Mα
F(⃗ν ) ⊆Mν1
F(ν2,...,νn). Then o(M) < o(F) by
Lemma 3.6 and rdh(M(η2, . . . , ηn)) ≥m + 1 by Lemma 3.7 claim 1.3.2. Thus by
induction hypothesis κ is Mν1
M(ν2,...,νn)–Π1
m+1–indescribable.
23This is in fact only of importance in case that o(X) = 0. In all other cases we have Par(X) ⊆α by
Lemma 3.7 claim 1.2.
Provably Recursive Functions of Reflection
411

Clearly κ is regular. Since α = β and β ∈H⋆(κ) as well as ⃗ν ∈H⋆(κ)
and Par(F(⃗η )) < o(F) by Lemma 3.7 claim 1.2, we have α, F(⃗ν ) ∈H⋆(κ) and
Par(F(⃗ν )) ⊆Hα(κ). By Lemma 3.12 we obtain that
M α,F(⃗ν )
κ
is unbounded in κ.
(i)
From κ ∈Mα
F(⃗ν ) we moreover get
κ |= ⃗R(F) and
(ii)
κ |= M<α
F – Pm.
(iii)
Let F be a Π1
m–formula such that (Vκ, P) |= F. Due to Lemmata 3.20 and 3.21
we can express (i) – (iii) by a Π1
m+1–formula ψ with parameters in Vκ and set
parameters Q1, . . . , Qr ⊆Vκ. Hence
(Vκ, P, ⃗Q) |= F ∧ψ
and by the Π1
m+1–indescribability of κ there is a κ0 < κ such that
(Vκ0, P ∩Vκ0, ⃗Q ∩Vκ0) |= F ∧ψ.
So M α,F(⃗ν )
κ
is unbounded in κ0, hence α, F(⃗ν ) ∈H⋆(κ)0 and Hα(κ0) ∩κ = κ0
by Lemma 3.13, and by (6) and Lemma 3.21 we get κ0 |= ⃗R(F(⃗ν )) and κ0 |=
M<α
F(⃗ν )– Pm. Therefore κ0 ∈Mα
F(⃗ν ) = Mβ
F(⃗ν ) and κ is Mβ
F(⃗ν )–Π1
m–indescribable.
□
3.27 Theorem (Ordinal comparison) Let F and G be reﬂection conﬁgurations,
⃗η ∈dom(F) and ⃗ν ∈dom(G), put X := F(⃗η ) and Y := G(⃗ν ). For ordinals
α ≥o(X) and β ≥o(Y) we have Ψα
X ↓< Ψβ
Y ↓iff one of the following cases is
satisﬁed
(A)
i(X) ≤Ψβ
X.
(B)
Ψα
X < i(Y), X, α ∈H⋆(Ψβ
Y) and (α < β ∨(F = G ∧(α, ⃗η ) <l (β,⃗ν )))
(C)
Y, β /∈H⋆(Ψα
X) and β ≤α.
Proof
We distinguish the following cases:
1. α < β: By Corollary 3.23 we have X, α ∈H⋆(Ψα
X). So if Ψα
X < Ψβ
Y we get
X, α ∈H⋆(Ψβ
Y) and Ψα
X < i(Y), since Ψβ
Y < i(Y) by Theorem 3.22. Therefore we
have (B).
If we conversely assume (B), we have X ∈H⋆(Ψβ
Y) and α ∈H⋆(Ψβ
Y) ∩β and
therefore Ψα
X ∈Hα(Ψβ
Y) ∩i(Y) = Ψβ
Y. Hence Ψα
X < Ψβ
Y.
412
Wolfram Pohlers and Jan–Carl Stegert

2. β < α: The assumption Y, β ∈H⋆(Ψα
X) entails Ψβ
Y ∈Hα(Ψα
X) ∩i(X) = Ψα
X.
So Ψα
X < Ψβ
Y implies (C).
From Ψβ
Y ≤Ψα
Y and Y, β ∈H⋆(Ψβ
Y) we get Y, β ∈H⋆(Ψα
X) and thus ¬(C).
Since β < α we clearly have ¬(B). Hence (B) or (C) imply Ψα
X < Ψβ
X by contra-
position.
3. α = β: Here we have three subcases
3.1. i(X) < i(Y): From Ψα
X < Ψβ
X we obtain from Lemma 3.24 i(X)∈Hα(Ψα
X)∩
i(Y) ⊆Hβ(Ψβ
Y) ∩i(Y) = Ψβ
Y. Hence (A).
Conversely (A) immediately implies Ψα
X < i(X) ≤Ψβ
Y.
3.2. i(Y) < i(X) Assume ﬁrst: Ψα
X < Ψβ
Y and ¬(C), i.e., Y, β ∈H⋆(Ψα
X). Then
we get Ψβ
Y < i(Y) ∈Hα(Ψβ
Y) ∩i(X) = Ψα
X. Contradiction. Hence Ψα
X < Ψβ
Y
implies (C).
For the opposite direction assume Ψβ
Y ≤Ψα
X. Then we obtain Y, β ∈H⋆(Ψβ
Y)
and thus also Y, β ∈H⋆(Ψα
X), i.e., ¬(C).
3.3.
i(X) = i(Y): Then F = G. Assume ﬁrst Ψα
X < Ψβ
Y. Then X ̸= Y and
therefore dom(F) = dom(G) ̸= {ϵ}. Thus RS(X) ̸= Ξ and Ψα
X ∈RS(X) implies
that Ψα
X is an uncountable regular cardinal.
The assumption rdh(Y) = −1 means that Mβ
Y = M β,Y
i(Y) (cf. (4)) which is club
in Ψα
X by Lemma 3.12. Hence Ψβ
Y < Ψα
X in contradiction to our assumption. Thus
rdh(Y) = rdh(G(⃗ν )) ≥0.
Now assume also ¬(B) and ¬(C). Since X, α ∈H⋆(Ψα
X), hence also X, α ∈
H⋆(Ψβ
Y), and Ψα
X < i(X) = i(Y) we get (β,⃗ν ) ≤l (α, ⃗η ). Equality implies X = Y
and is thus excluded. So we have ⃗ν <l ⃗η . Together with the assumption ¬(C),
i.e., Y, β ∈H⋆(Ψα
X), this implies by Lemma 3.26 that Ψα
X is Mβ
G(⃗ν )–Π1
rdh(G(⃗ν ))–
indescribable. By Lemma 3.15 Mβ
G(⃗ν ) is stationary in Ψα
X, hence Ψβ
Y < Ψα
X in
contradiction to our hypothesis. So we have shown that Ψα
X < Ψβ
Y implies (B) or
(C).
For the converse implication assume ﬁrst Ψβ
Y ≤Ψα
X. Then we immediately get
Y, β ∈H⋆(Ψβ
Y), hence also Y, β ∈H⋆(Ψα
X) and thus ¬(C).
Now assume (B). Then we have X, α ∈H⋆(Ψβ
Y) and ⃗η <l ⃗ν which especially
means dom(F) = dom(G) ̸= {ϵ}. As we have just seen this entails that Ψβ
Y is
an uncountable regular cardinal which, in turn, implies that rdh(X) = −1 entails
Ψα
X < Ψβ
Y. If rdh(X) ≥0 then Ψβ
Y is Mα
X–Π1
rdh(X)–indescribable by Lemma 3.26
and thus Ψα
X < Ψβ
Y.
□
Provably Recursive Functions of Reflection
413

3.28 Corollary Let X and Y be reﬂection instances, α ≥o(X) and β ≥o(Y).
Then Ψα
X↓= Ψβ
Y↓iff X = Y and α = β.
Proof
The direction from right to left is clear. So assume X = F(⃗η ), Y = G(⃗ν )
and Ψα
X = Ψβ
Y. If α < β we have Ψα
X = Ψβ
Y < i(Y),
X, α ∈H⋆(Ψα
X) =
H⋆(Ψβ
Y)24, hence Ψα
X < Ψβ
Y by Theorem 3.27 (B). The case β < α is symmetric. If
α = β and i(X) < i(Y) then we obtain the contradiction Ψα
X < i(X) ∈Hα(Ψα
X) ∩
i(Y) ⊆Hβ(Ψβ
Y) ∩i(Y) = Ψβ
Y. The case i(Y) < i(X) is again symmetrical, hence
i(X) = i(Y) and thus F = G. If X ̸= Y then ⃗η <l ⃗ν or ⃗ν <l ⃗η and we obtain
Ψα
X ̸= Ψβ
Y by Theorem 3.27 (B).
□
3.5
A primitive recursive characterization of Vα({0, Ξ})
In this section we are going to indicate that the ordinal segment that is eventually
obtained by iterating Skolem operators can be primitive recursively characterized.
Since K(π) is the only reﬂection instance whose reﬂection point is a successor
cardinal π+ we will write Ψα
π+ instead of Ψα
K(π). By induction on α it is not hard
to prove that Hα(π) ∩π+ is transitive set, namely the ordinal Ψα
π+.25 Since all
ordinals Ψα
X are less than Ξ we immediately get
•
Vα({0, Ξ}) ⊆ΓΞ+1 for any ordinal α
where V again denotes the least Veblen closed operator and ΓΞ+1 is the ﬁrst strongly
critical ordinal above Ξ. Therefore the largest transitive segment that can be reached
by iterations of V[{0, Ξ}] is the ordinal ΨΓΞ+1
Ω
for Ω:= ω+.
We have seen in Corollary 3.28 that α and X are uniquely determined if Ψα
X ↓.
As indicated in Remark 3.19 this implies that β
α,π becomes a singleton for β ∈
Hα(π) provided that clauses 3 – 6 in Deﬁnition 3.18 are restricted to β ≥π. Then
properties (5) and (6) remain only true under the additional hypothesis Hα(κ)∩π =
κ.
This shows that every β ∈Hα(π) possesses a uniquely determined code relative
to α and π that only uses parameters in Vπ. This remains true for ordinals β ∈
Vα({0.Ξ}). The only parameters needed here are 0 and Ξ. Therefore every ordinal
in VΓΞ+1[{0, Ξ}] can be represented by an ordinal term built up from the basic
symbols 0, Ξ, using the functions +, ϕ, .+ and Ψ.
Giving all the details of a simultaneous primitive course–of–values deﬁnition of
ordinal terms, the “less than” relation between ordinal terms and the auxiliary no-
24It should be clear that this stands for X, α ∈H⋆(Ψα
X) ⇔X, α ∈H⋆(Ψβ
Y).
25This is the usual proof that is independent from the fact that we mingled the iterated Skolem hull
operators and thinning hierarchies.
414
Wolfram Pohlers and Jan–Carl Stegert

tions as “κ is a cardinal”, “⃗R(π) codes a reﬂection string”, ‘”X codes a reﬂection
instance” etc. means an awkward and boring formalization of Deﬁnition 3.2. We
will therefore only give so much details that it becomes clear that the comparison
relation between ordinal terms is primitive recursively decidable.
3.29 Deﬁnition The set T(Ξ) of ordinal terms is recursively deﬁned by the follow-
ing clauses
1. {0, Ξ} ⊆T(Ξ).
2. If α =NF α1 + · · · + αn and αi ∈T(Ξ) for i = 1, . . . , n then α ∈T(Ξ).
3. If α =NF ϕα1(α2) and αi ∈T(Ξ) then α ∈T(Ξ).
4. If κ ∈T(Ξ) and κ ∈Card then κ+ ∈T(Ξ).
5. If X, ξ ∈T(Ξ), o(X) ≤ξ and X, α ∈V[{0, Ξ}]∗(i(X)) then Ψα
X ∈T(Ξ).
Since T(Ξ) and VΓΞ+1({0, Ξ}) share the same closure properties we easily get
3.30 Lemma The sets T(Ξ) and VΓΞ+1({0, Ξ}) coincide.
From Deﬁnition 3.29 and Theorem 3.27 we see that the crucial point in showing
that T(Ξ) and < ↾T(Ξ) are primitive recursively deﬁnable is the decision of α ∈
Hβ(γ). To secure this there is, however, a proven technique by deﬁning a ﬁnite set
of subterms Kβ(α) of an ordinal α ∈T(Ξ).
3.31 Deﬁnition For ordinal terms in α, β ∈T(Ξ) we deﬁne
Kβ(α) =











∅
if α < β or α ∈{0, Ξ}
S {Kβ(αi) i = 1, . . . , n}
if α =NF α1 + · · · + αn
Kβ(α1) ∪Kβ(α2)
if α =NF ϕα1α2
Kβ(κ)
if α = κ+ for a cardinal κ
{ξ} ∪Kβ(ξ) ∪{Kβ(η) η ∈Par(X)}
if α = Ψξ
X < i(X)
3.32 Lemma For ordinal terms α, β ∈T(Ξ) we get α ∈Hξ(β) iff Kβ(α) < ξ.
Proof
We show by induction on the stage n in the generation of Hξ(α) that α ∈
Hξ
n(α) holds true iff Kβ(α) < ξ.
□
As a consequence of Theorem 3.27 and Lemma 3.32 (together with some obvious
facts that we did not spell out in detail) we get that T(Ξ) and the less than relation
for ordinal terms in T(Ξ) (together with some auxiliary notions) are deﬁnable by
simultaneous course–of–values recursion.
Provably Recursive Functions of Reflection
415

3.33 Theorem The set VΓΞ+1({0, Ξ}) and the relation < ↾VΓΞ+1({0, Ξ}) are prim-
itive recursively deﬁnable.
As an immediate corollary we thus obtain that ΨΩcollapses ordinals below ωCK
1 .
3.34 Corollary The ordinal ΨΓΞ+1
Ω
is less than ωCK
1 .
3.6
Fine Structure Theory
Our ﬁrst proof theoretical aim will be to eliminate all reﬂection rules in an inﬁ-
nite derivation of a ΣωCK
1
1
–sentence. This is a step by step procedure. We have to
eliminate π–reﬂection rules by reﬂection rules of “lower” complexity. Therefore
a reﬂecting ordinal π has to be provided with all the information that is needed in
the elimination procedure. This information is coded in the reﬂection string ⃗R(π).
The aim of the present section is to show that in fact all the necessary information
can be obtained from ⃗R(π). This requires a considerable amount of bookkeeping
which will be given in this (pretty technical) section.
We start with a simple observation concerning the ran–function deﬁned in Deﬁ-
nition 3.3.
3.35 Lemma Let X be a reﬂection instance and α an ordinal such that Ψα
X↓. Then
for every Z ∈Prinst(X) and ζ := ranα
X(Z) we have Ψα
X ≤Ψζ
Z. If Z ∈Prinst(X)
then Mα
X ⊆Ψζ
Z.
Proof
We induct on o(X). For Z = X we get ranα
X(Z) = α and the claim is
trivial. If Z ∈Prinst(X) then o(X) = δ + 1 and i(X) = Ψδ
Y for some ordinal δ and
Y = Pd(X). Then Z ∈Prinst(Y) and ζ = ranα
X(Z) = ranδ
Y(Z). By deﬁnition and
induction hypothesis we thus have Mα
X ⊆Ψδ
Y ≤Ψζ
Z.
□
3.36 Corollary If G ∈Prcnf(F) then i(F) < i(G).
Proof
Let F = Xα for α ≥o(H). Then i(F) = Ψα
X. Let Y := G(⃗η ) such that
Y ∈Prinst(X) and δ := ranα
X(Y). Then Ψα
X ≤Ψδ
Y < i(Y) = i(G) by Lemma 3.35.
□
3.37 Lemma Let X and Y be reﬂection instances, X′ ∈Prinst(X), Y′ ∈Prinst(Y),
α′ := ranα
X(X′), β′ := ranβ
Y(Y′) and Ψα
X↓≤Ψβ′
Y′. If Ψβ′
Y′ < Ψα′
X′ then there is an
X′′ ∈Prinst(X) such that Prinst(X′) ⊆Prinst(X′′) and Ψα
X ≤Ψα′′
X′′ ≤Ψβ′
Y′ <
i(X′′) ≤Ψα′
X′ for α′′ := ranα
X(X′′).
416
Wolfram Pohlers and Jan–Carl Stegert

Proof
Let X0 := (Ψα′
X′; . . . ; X′; α′ + 1) ∈Prinst(X). We induct on the number n
of elements in Prinst(X) \ Prinst(X0). If n = 0 then X = X0 and ranα
X(X0) = α.
Putting X′′ := X0 we get Ψα′′
X′′ = Ψα
X ≤Ψβ′
Y′ < Ψα′
X′ = i(X′′). Clearly Prinst(X′) ⊆
Prinst(X0). If n > 0 we put X1 := (Ψα0
X0; . . . ; X0, α0 + 1) ∈Prinst(X) with α0 :=
ranα
X(X0). Then there are less than n many elements in Prinst(X) \ Prinst(X1). By
induction hypothesis there is an X′′ ∈Prinst(X) such that Ψα
X ≤Ψα′′
X′′ ≤Ψβ′
Y′ <
i(X′′) ≤Ψα0
X0 < i(X0) = Ψα′
X′. Clearly Prinst(X′) ⊆Prinst(X1) ⊆Prinst(X′′) by
induction hypothesis.
□
3.38 Theorem Let X be a reﬂection instance of a reﬂection conﬁguration F and Y
a reﬂection instance of a reﬂection conﬁguration G ̸= K such that rdh(Y) ≥0.
Let α be an ordinal such that Ψα
X ↓. Then Ψα
X ∈Mβ
Y implies G ∈Prcnf(F),
β ≤ranα
F(G) and Ψβ
Y ≤Ψα
X < i(X) ≤i(Y).
Proof
Assume Ψα
X ∈Mβ
Y. Then Ψβ
Y ≤Ψα
X and Hβ(Ψα
X) ∩i(Y) = Ψα
X. From
Ψα
X↓we get X, α ∈Hα(Ψα
X). Hence β ≤α and we have Ψα
X ≤i(Y) ∈Hβ(Ψβ
Y) ⊆
Hα(Ψα
X) and Hα(Ψα
X) ∩i(X) = Ψα
X. Thus i(X) ≤i(Y).
Assuming F ∈Prcnf(G) we obtain the contradiction i(Y) = i(G) < i(F) = i(X)
by Corollary 3.36.
To show G ∈Prcnf(F) by contradiction we assume G /∈Prcnf(F).
Since
rdh(Y) ≥0 the elements of Mβ
Y are uncountable regular cardinals. Hence F ̸= K
by Lemma 3.14. This entails that A ∈Prcnf(F) ∩Prcnf(G), hence Prcnf(F) ∩
Prcnf(G) ̸= ∅.
So there are a reﬂection conﬁguration H ∈Prcnf(F) ∩Prcnf(G), ⃗η and ⃗ν in
dom(H) and ordinals α′ ≥o(X′) and β′ ≥o(Y′) for X′ := H(⃗η ) and Y :=
H(⃗ν ) such that X′ ∈Prinst(X), Y′ ∈Prinst(Y) and Prcnf(F) ∋X′α′ ̸= Y′β′ ∈
Prcnf(G). Then α′ := ranα
X(X′), β′ := ranα
Y(Y′) and (α′, ⃗η ) ̸= (β′,⃗ν ). Hence
Ψα′
X′ ̸= Ψβ′
Y′ and we distinguish the following cases.
1. Ψα′
X′ < Ψβ′
Y′.
Since Ψβ
Y ≤Ψα
X < Ψα′
X′ we get by Lemma 3.37 a Y′′ ∈Prinst(Y)
such that Ψβ
Y ≤Ψβ′′
Y′′ ≤Ψα′
X′ < i(Y′′) ≤Ψβ′
Y′ for β′′ := ranβ
Y(Y′′) and Prinst(Y′) ⊆
Prinst(Y′′). Thus Par(Y′) ∪{β′} ⊆β′′, i.e, β′ < β′′.
1.1. Let β′ < α′. Since Par(Y′) ∪{β′} ⊆Par(Y′′), Par(Y′) < o(Y′) ≤β′ and
Y′′ ∈H⋆(Ψβ′′
Y′′) we get Y′, β′ ∈Hα′(Ψβ′′
Y′′) ⊆Hα′(Ψα′
X′). Hence Ψα′
X′ ≤Ψβ′
Y′ ∈
Hα′(Ψα′
X′) ∩i(H) = Ψα′
X′. Contradiction.
1.2.
Assume α′ ≤β′. Since Par(X′) ⊆α′ and Par(X′) ∪{α′} ⊆Par(X) and
X ∈H⋆(Ψα
X) we get α′, X′ ∈Hα′(Ψα
X), hence Ψα′
X′ ∈Hβ′′(Ψα
X).
Provably Recursive Functions of Reflection
417

If Y′′ ∈Prinst(Y) we have Ψα
X ∈Mβ
Y ⊆Ψβ′′
Y′′ and obtain Ψα′
X′ ∈Hβ′′(Ψβ′′
Y′′) ∩
i(Y′′) = Ψβ′′
X′′. Contradiction.
So assume Y′′ = Y. Then β′′ = β and we obtain Ψα′
X′ ∈Hβ(Ψα
X) ∩i(Y) = Ψα
X,
contradicting X′ ∈Prinst(X).
2. Ψβ′
Y′ < Ψα′
X′. Since Ψα
X ∈Mβ
Y ⊆Ψβ′
Y′ we also have Ψα
X < Ψβ′
Y′. By Lemma 3.37
we therefore obtain a reﬂection instance X′′ ∈Prinst(X) such that Prinst(X′) ⊆
Prinst(X′′) and Ψα
X ≤Ψα′′
X′′ ≤Ψβ′
Y′ < i(X) ≤Ψα′
X′.
2.1.
Let α′ < β′. We have Par(X′) ∪{α′} ⊆Par(X′′) and obtain from X′′ ∈
H⋆(Ψα′′
X′′) that Ψβ′
Y′ ≤Ψα′
X′ ∈Hβ′(Ψα′′
X′′) ∩i(H) ⊆Hβ′(Ψβ′
Y′) ∩i(H) = Ψβ′
Y′.
Contradiction.
2.2. Assume β′ ≤α′. First we observe that Par(X′) ∪{α′} ⊆α′ + 1 ≤o(X′′) ≤
ranα
X(X′′) = α′′, hence α′ < α′′. Interchanging α and β we get as in case 1.2
Ψβ′
Y′ ∈Hα′′(Ψβ
Y) ∩i(X) ⊆Hα′′(Ψα
X) ∩i(X). If X′′ ∈Prinst(X) we get α ≥
o(X) > ranα
X(X′′) = α′′. Hence Ψβ′
Y′ ∈Hα(Ψα
X) ∩i(X) = Ψα
X. Contradiction. If
X′′ = X we have α = α′′ and obtain the same contradiction.
So we have G ∈Prcnf(F). The remaining open claim is β ≤ranα
F(G). If F = G
we get ranα
F(G) = α and we already proved β ≤α. So assume G ̸= F, i.e.
G ∈Prcnf(F). Choose ⃗η ∈dom(G) such that Y′ := G(⃗η ) ∈Prinst(X) and put
β′ := ranα
X(Y′) = ranα
F(G). Then Par(Y′) ⊆β′ and Par(Y′) ∪{β′} ⊆Par(X),
and X ∈H⋆(Ψα
X) implies Y′, β′ ∈Hβ′(Ψα
X). The assumption β′ < β then leads to
the contradiction Ψα
X ≤Ψβ
Y ≤Ψβ′
Y′ ∈Hβ(Ψα
X) ∩i(Y′) = Hβ(Ψα
X) ∩i(G) = Ψα
X.
Hence β ≤β′ = ranα
F(G).
□
3.39 Deﬁnition For a reﬂection expression M<α
M – Pm we deﬁne its derivative by
(M<α
M – Pm)′ := ⃗R(i(M))m
Its transitive closure is deﬁned by
TC(M<α
M – Pm) = {M<α
M – Pm} ∪TC((M<α
M – Pm)′).
The predecessor relation between reﬂection expressions of the same degree is de-
ﬁned by
M<α
F – Pm ⪯M<β
G – Pm
:⇔there is an ordinal ζ ≥α
such that M<ζ
F – Pm ∈TC(M<β
G – Pm).
M<α
F – Pm ≺M<β
G – Pm stands for
M<α
F – Pm ⪯M<β
G – Pm and M<α
F – Pm ̸= M<β
G – Pm.
418
Wolfram Pohlers and Jan–Carl Stegert

For ﬁnite strings ⃗R and ⃗Q of reﬂection expressions ⃗R ⪯⃗Q means Ri ⪯Qi for
every component Ri and Qi. To deﬁne this relation also between strings of different
length it is useful to declare ϵ ⪯R for any reﬂection expression R.
For a ﬁnite string ⃗R = (R1, . . . , Rn) of reﬂection expressions we deﬁne its
derivative by
⃗R ′ = (R′
1, R2, . . . Rn).
Clearly ⪯is a reﬂexive and transitive relation and there are no inﬁnite ≺–descending
sequences. It follows directly from the deﬁnition that for all reﬂection conﬁgura-
tions M, all α, β ≥o(M) and all e ∈Rdh(M) we have
(M<α
M – Pm)′ ⪯M<β
M – Pm and (M<α
M – Pm)′ ⪯eM
<β
M – Pm
(7)
for all m ≤e + 1. For strings ⃗R we also directly obtain
⃗R ′ ⪯⃗R .
(8)
From the deﬁnition of eM
<α
M – Pm we immediately obtain
eM
<α
M – Pm ⪯M<α
M – Pm.
(9)
We ﬁrst state an obvious property of the beginning conﬁguration A.
3.40 Lemma Let F ̸= K be a reﬂection conﬁguration and e ∈Rdh(F). Then
M<ω
A – Pm ⪯M<α
F – Pm holds true for all α ≥o(F) and all m ≤e + 1.
Proof
We induct on o(F). The claim is obvious for F = A. If F ̸= A and
m ≤rdh(F) + 1 we have ⃗R(i(F))m ̸= ϵ and TC(M<α
F – Pm) = {M<α
F – Pm} ∪
{TC(M<β
M – Pm)} for M<β
M – Pm := ⃗R(i(F))m. Then o(M) < o(F) and we get
M<ω
A – Pm ⪯M<β
M – Pm ⪯M<α
F – Pm by induction hypothesis.
□
Other useful observations are the following two lemmas.
3.41 Lemma Let F ̸= K be a reﬂection conﬁguration, X a conﬁguration instance
of F and α an ordinal such that Ψα
X↓. Then ⃗R(i(X))≤rdh(X) ⪯⃗R(Ψα
X)≤rdh(X).
Proof
By deﬁnition of ⃗R(Ψα
X) we have ⃗R(Ψα
X)rdh(X) = eM
<α
F – Prdh(X) as well
as ⃗R(i(X))<rdh(X) = ⃗R(Ψα
X)<rdh(X). Since ⃗R(i(X))rdh(X) ⪯eM
<α
F – Prdh(X) holds
obviously the claim is clear.
□
3.42 Lemma Let X be a reﬂection conﬁguration and α an ordinal such that Ψα
X↓.
Then ⃗R(i(X))′ ⪯⃗R(Ψα
X).
Provably Recursive Functions of Reflection
419

Proof
By Lemma 3.41 we only have to show ⃗R(i(X))′
rdh(X)+1 ⪯⃗R(Ψα
X)rdh(X)+1.
If RS(X) = Ξ we get by Lemma 3.9 ⃗R(i(X))rdh(X)+1 = M<ω
A – Prdh(X)+1 and the
claim is trivial by Lemma 3.40. If RS(X) = Mζ
M(⃗ν ) we have ⃗R(i(X))rdh(X)+1 =
M<γ
M – Prdh(X)+1 for some γ > ζ and ⃗R(Ψα
X)rdh(X)+1 = eM
<ζ
M – Prdh(X)+1. But by (7)
we have (M<γ
M – Prdh(X)+1)′ ⪯eM
<ζ
M – Prdh(X)+1.
□
The next lemma shows that essential properties of reﬂection instances are already
shared by their predessors.
3.43 Lemma Let X be a reﬂection instance of a reﬂection conﬁguration F, α ≥
o(X) and κ < i(X) ordinals satisfying Hα(κ) ∩i(X) = κ and X, α ∈H⋆(κ). Let
Z ∈Prinst(X) and β := ranα
X(Z). Then we get
1. Hβ(κ) ∩i(Z) = κ and Z, β ∈H⋆(κ).
2. E(⃗η ) ∈H⋆(κ) for all E ∈Prcnf(F) and ⃗η ∈dom(E) ∩Par(X).
Proof
Let X0 := X and Xi+1 := Pd(Xi),
α0 := α,
αi+1 := ranα
X(Xi+1),
π0 := i(X) and πi+1 := i(Xi+1). Then we have for all i ∈ω
κ < πi < πi+1,
αi+1 < αi and Hαi+1(πi) ∩πi+1 = πi
(i)
and
Par(Xi) ∪{αi} ⊆Par(X) ∪{α}.
(ii)
Now we prove
Hαi(κ) ∩πi = κ
(iii)
by induction on i ∈ω. For i = 0 this is true by hypothesis and in the successor
step we argue
Hαi+1(πi) ∩πi+1 = πi ⇒Hαi+1(κ) ∩πi+1 ⊆πi
⇒Hαi+1(κ) ∩πi+1 = Hαi+1(κ) ∩πi ⊆Hαi(κ) ∩πi = κ
where we used the induction hypothesis in the last equation. Hence Hαi(κ) ∩πi ⊆
κ and the opposite inclusion holds by deﬁnition. This proves (iii).
For Z ∈Prinst(X) there is an i ∈ω such that Z = Xi. Then Hranα
X (Z)(κ)∩i(Z) =
κ follows from (iii). Since Par(Z)∪{ranα
X(Z)} ⊆Par(X)∪{α} and X, α ∈H⋆(κ)
we also get Z, ranα
X(Z) ∈H⋆(κ). This proves 1.
Claim 2. follows immediately from Par(E(⃗η )) ⊆Par(X) and X ∈H⋆(κ).
□
The predecessor relation for reﬂection expressions preserves indescribability in the
sense expressed by the following lemma.
420
Wolfram Pohlers and Jan–Carl Stegert

3.44 Lemma
Let F be a reﬂection conﬁguration and ⃗η ∈dom(F) such that
rdh(X) ≥m holds true for X := F(⃗η ). Let κ be an ordinal satisfying X ∈H⋆(κ)
and α ≥o(F) such that κ |= eM
<α
F – Pm. Then κ |= M<ζ
M – Pm for all M<ζ
M – Pm ⪯
eM
<α
F – Pm.
Proof
We induct on o(M). The claim is trivial if F is not a successor conﬁgura-
tion. For successor conﬁgurations there is an ordinal δ such that o(F) = δ + 1.
If α = δ + 1 then eM
<α
F – Pm = ⃗R(i(F))m =: M<ε
E – Pm with o(E) < o(F) and
the claim follows from the induction hypothesis. So assume δ + 1 < α. Then
eM
<α
F – Pm = M<α
F – Pm and TC(M<α
F – Pm) = {M<α
F – Pm} ∪TC(⃗R(i(F))m).
From M<ζ
M – Pm ⪯eM
<α
F – Pm we obtain either o(M) ≤ζ < α and M = F or
M<ζ
M – Pm ⪯⃗R(i(F))m. In the ﬁrst case we get κ |= M<ζ
M – Pm directly from the
hypothesis κ |= M<α
F – Pm. In the second case we have to show κ |= M<ζ
M – Pm, i.e.,
that for any ξ ∈[o(M), ζ)↾H⋆(κ), any ⃗ν ∈dom(M)↾H⋆(κ) and any Π1
m–formula F
with parameters ⃗P ⊆Vκ such that (Vκ, ⃗P) |= F there is a κ0 ∈Mξ
M(⃗ν ) ∩κ such
that (Vκ0, ⃗P ∩Vκ0) |= F.
Fix ξ and ⃗ν and assume (Vκ, ⃗P) |= F. Since κ |= M<α
F – Pm we know that
κ is Mρ
F(⃗η )–Π1
m–indescribable for all ρ ∈[o(F), α)↾H⋆(κ) and thus inaccessible.
For any ν ∈⃗ν ∪{ξ} the set M ν
κ := {σ ∈κ ν ∈H⋆(σ) ∧Hν(σ) ∩κ = σ} is
club in κ by Lemma 3.12 and Mρ
F(⃗η ) is stationary in κ by Lemma 3.15. Since the
set {σ ∈κ (Vσ, ⃗P ∩Vσ) |= F} contains a club subset, we ﬁnd a κ′
0 ∈Mρ
F(⃗η ) ∩
T
ν M ν
κ ∩κ such that (Vκ′
0, ⃗P ∩Vκ′
0) |= F. By deﬁnition of Mρ
F(⃗η ) this entails κ′
0 |=
⃗R(i(F))m =: M<ε
E – Pm. By Lemma 3.7 claim 2.5 there is a tuple ⃗µ ∈dom(E) such
that rdh(E(⃗µ)) = m. Summing up we have
M<ζ
M – Pm ⪯M<ε
E – Pm, κ′
0 |= M<ε
E – Pm, rdh(E(⃗µ)) = m
X ∈H⋆(κ′
0) because of κ′
0 ∈Mρ
F(⃗η )
and
E(⃗µ) ∈H⋆(κ′
0) because of Par(E(⃗µ) ⊆Par(X)).
Since o(E) < o(F) we can apply the induction hypothesis to obtain κ′
0 |= M<ζ
M – Pm.
Since κ′
0 ∈T
ν M ν
κ we have (ξ,⃗ν ) ∈[o(M), ζ)↾H⋆(κ′
0) ×dom(M)↾H⋆(κ′
0) and thus
that κ′
0 is Mξ
M(⃗ν )–Π1
m–indescribable. Therefore there is a κ0 ∈Mρ
M(⃗ν ) such that
(Vκ0, ⃗P ∩Vκ0) |= F and κ0 < κ′
0 < κ.
□
Provably Recursive Functions of Reflection
421

3.45 Lemma Let X be a reﬂection instance of a reﬂection conﬁguration F ̸= K
such that rdh(X) ≥0 and assume Ψα
X ↓. Let E be a reﬂection conﬁguration and
e ∈Rdh(E) such that ⃗R(Ψα
X)e = M<β
E – Pe. Then eM
<ε
E – Pe ⪯M<β
E – Pe for some
ε ≥o(E) implies ⃗R(Ψζ
E(⃗µ))≤e ⪯⃗R(Ψα
X)≤e for all ε ≤ζ ≤α and e < ⃗µ ∈
dom(E).
Proof
We induct on o(X). First assume X = A(m + 1). Since then ⃗R(Ψα
X) =
(M<α
A – Pm, . . . , M<α
A – P0) we have E = A, ε ≤α, β = α and e ≤m. But then
⃗R(Ψζ
A(n))≤e ⪯⃗R(Ψα
X)≤e holds true for all ε ≤ζ ≤α and n > e.
Now assume that F = Zδ is a successor conﬁguration. Let m := rdh(X). Then
we have
⃗R(Ψα
X) = (⃗R(j(X))>m, eM
<α
F – Pm, ⃗R(Ψδ
Z)<m).
If e = m we get E = F and
⃗R(Ψζ
E(⃗µ))≤m = (eM
<ζ
E – Pm, ⃗R(Ψδ
Z)<m) ⪯(eM
<α
E – Pm, ⃗R(Ψδ
Z)<m) = ⃗R(Ψα
X)≤e
since ζ ≤α.
If e < m then ⃗R(Ψα
X)≤e = ⃗R(Ψδ
Z)≤e and the claim follows immediately from
the induction hypothesis.
Assume now e > m. Then j(X) = Ψξ
M(⃗ν ) for RS(X) = Mξ
M(⃗ν ) and ⃗R(Ψα
X)[e,m)
= ⃗R(j(X))[e,m). The induction hypothesis applied yields
⃗R(Ψζ
E(⃗µ))≤e ⪯⃗R(Ψξ
M(⃗µ))≤e, hence ⃗R(Ψζ
E(⃗µ))[e,m) ⪯⃗R(Ψα
X)[e,m).
(i)
By Lemma 3.9 we have ⃗R(Ψδ
Z)m+1 = M<ρ
M – Pm+1 for some ρ > ξ. By Corol-
lary 3.8 we have m + 1 ∈Rdh(M). Since eM
<ξ
M – Pm+1 ⪯M<ρ
M – Pm+1 we can
apply the induction hypothesis to M and Ψδ
Z to obtain
⃗R(Ψξ
M(⃗µ))≤m+1 ⪯⃗R(Ψδ
Z)≤m+1.
(ii)
Since ⃗R(Ψδ
Z)≤m ⪯⃗R(Ψα
X)≤m by Lemma 3.41, the claim follows from (i) and (ii).
□
3.46 Lemma Let X be a reﬂection instance of a reﬂection conﬁguration F, α and κ
ordinals such that Ψα
X↓, Hα(κ) ∩i(X) = κ and X, α ∈H⋆(κ). Then κ |= ⃗R(Ψα
X)
implies κ ∈Mα
X.
Proof
We induct on o(X). The claim holds trivially if rdh(X) = −1. So assume
m := rdh(X) ≥0. Since κ |= ⃗R(Ψα
X) we have κ |= ⃗R(X) and κ |= eM
<α
F – Pm.
If eM
<α
F – Pm ̸= M<α
F – Pm then α = o(X) and κ |= (M<α
F – Pm)′. Therefore κ
422
Wolfram Pohlers and Jan–Carl Stegert

is Π1
m–indescribable which entails κ |= M<α
F – Pm. So we obtain κ ∈Mα
X in
case that RS(X) = Ξ. If RS(X) ̸= Ξ we still have to show κ ∈RS(X). So let
RS(X) =: Mξ
M(⃗µ). From κ |= ⃗R(Ψα
X) we obtain
κ |= ⃗R(Ψξ
M(⃗µ))>m.
(i)
It is m + 1 ∈Rdh(M) and ⃗R(i(X))m+1 = M<γ
M – Pm+1 for some γ > ξ. Hence
eM
<ξ
M – Pm+1 ⪯M<γ
M – Pm+1and thus ⃗R(Ψξ
M(⃗µ))≤m+1 ⪯⃗R(i(X))≤m+1 by Lem-
ma 3.45. This entails especially
⃗R(Ψξ
M(⃗µ))≤m ⪯⃗R(i(X))≤m = ⃗R(Ψα
X)≤m.
According to Lemma 3.7 claim 2.2 we get R = A for those components M<ρ
R – Pr
of ⃗R(Ψα
X) for which we have ρ = o(R). Hence eM
<ρ
R – Pr = M<ρ
R – Pr for all
components which implies κ |= eM
<ρ
R – Pr for all r. By Lemma 3.44 we thus get
κ |= ⃗R(Ψξ
M(⃗µ))≤m which together with (i) yields κ |= ⃗R(Ψξ
M(⃗µ)). Since ξ, M(⃗µ) ∈
H⋆(κ) and Hξ(κ) ∩i(M) = κ by Lemma 3.43 we obtain κ ∈Mξ
M(⃗µ) by induction
hypothesis.
□
3.47 Corollary Let X be a reﬂection instance of a reﬂection conﬁguration F such
that rdh(X) ≥0. Then κ ∈Mα
X holds true iff X, α ∈H⋆(κ), Hα(κ) ∩i(X) = κ
and κ |= ⃗R(Ψα
X).
Proof
The direction from left to right is Lemma 3.10. The opposite direction
follows from Lemma 3.46.
□
3.48 Deﬁnition Let M and D be reﬂection conﬁgurations. Let
(M<α
M – Pm)D :=

M<ξ
D – Pm
if M<ξ
D – Pm ∈TC(M<α
M – Pm)
ϵ
otherwise.
For a string ⃗R = (M<ρ1
R1 – Pr1, . . . , M<ρn
Rn – Prn) we deﬁne
⃗R D := ((M<ρ1
R1 – Pr1)D, . . . , (M<ρn
Rn – Prn)D).
3.49 Lemma Let B, C ∈Prcnf(F). Then B ∈Prcnf(C) or C ∈Prcnf(B).
Proof
Induction on o(F). If C = F then B ∈Prcnf(C). If B = F then C ∈
Prcnf(B). If B ̸= F and C ̸= F then B, C ∈Prcnf(Pd(F)) and the claim follows
from the induction hypothesis.
□
Provably Recursive Functions of Reflection
423

3.50 Lemma Let X be a reﬂection instance of a reﬂection conﬁguration F such
that rdh(X) ≥0 and α an ordinal such that Ψα
X ↓.
Assume E ∈Prcnf(F),
D ∈Prcnf(E) and g ≤min{rd(⃗R(E)), rd(⃗R(Ψα
X))}. Then ⃗R(E)≤g ⪯⃗R(Ψα
X)≤g
implies ⃗R(E)D
≤g = ⃗R(Ψα
X)D
≤g.
Proof
We induct on o(X). Since Prcnf(A) = ∅we have nothing to show for
F = A. The case F = K is excluded by rdh(X) ≥0. So assume that F is a
successor conﬁguration Zδ with rdh(F) =: m. Then
⃗R(Ψα
X) = (⃗R(j(X))>m, eM
<α
F – Pm, ⃗R(i(X))<m)
and i(X) = Ψδ
Z. Assume that Z is an instance of a conﬁguration H.
1.
Let g ≤m.
1.1. If E = F then D ̸= F. But then ⃗R(Ψα
X)D
≤g = (⃗R(Ψα
X)′
≤g)D = ⃗R(i(F))D
≤g =
⃗R(i(E))D
≤g.26
1.2. Let E ̸= F. Then E ∈Prcnf(Z) and still g ≤min{rd(⃗R(i(E))), rd(⃗R(Ψα
X))}.
From ⃗R(E)≤g ⪯⃗R(Ψα
X)≤g and E ̸= F we get (cf. footnote 26) ⃗R(E)≤g ⪯
⃗R(i(F))≤g and the induction hypothesis together with D ̸= F yields
⃗R(E)D
≤g = ⃗R(i(F))D
≤g = ⃗R(Ψα
X)D
≤g.
2.
Assume m < g. Then j(X) ̸= 0. Put Mζ
M(⃗µ) := RS(X). Since g > m =
rdh(X) and rd(⃗R(E)) = rdh(E) it is rdh(E) > m and thus E ̸= F.
Hence
E ∈Prcnf(Z). Towards a contradiction assume M ∈Prcnf(E). From ⃗R(E)≤g ⪯
⃗R(Ψα
X)≤g we get ⃗R(E)≤g ⪯⃗R(i(X))≤g since E ̸= F. Since rd(⃗R(i(X))) >
rdh(X) = m we get m + 1 ≤min{rd(⃗R(E)), rd(⃗R(Ψδ
Z))} and, applying the in-
duction hypothesis to M, E and Ψδ
Z, we get together with Lemma 3.9 for some
ρ > ζ
M<ρ
M – Pm+1 = ⃗R(Ψδ
Z)M
m+1 = ⃗R(E)M
m+1 ⪯⃗R(Ψα
X)m+1 = eM
<ζ
M – Pm+1
which contradicts ζ < ρ. Hence M /∈Prcnf(E) and thus
E ∈Prcnf(M) ⊆Prcnf(H) and o(D) < o(E) ≤o(M) ≤o(H) < o(X).
(i)
We want apply the induction hypothesis to Ψζ
M(⃗ν ) and thus have to secure
26Since this situation returns over and over again we explain the argument a bit further. For r ≤
rdh(F) we have TC(eM
<α
F – Pr) ⊆{M<α
F – Pr} ∪TC((M<α
F – Pr)′) = {M<α
F – Pr} ∪TC(⃗R(i(F))r).
If D ̸= F then everything that can happen in TC(eM
<α
F – Pr) with D involved already happens in
TC(⃗R(i(F))r).
424
Wolfram Pohlers and Jan–Carl Stegert

⃗R(E)≤g ⪯⃗R(Ψζ
M(⃗ν ))≤g.
(ii)
By hypothesis we already have
⃗R(E)[g,m) ⪯⃗R(Ψα
X)[g,m) = ⃗R(Ψζ
M(⃗ν ))[g,m).
(iii)
So it remains to show
⃗R(E)≤m ⪯⃗R(Ψζ
M(⃗ν ))≤m.
(iv)
Since ⃗R(E)≤m ⪯⃗R(Ψα
X)≤m and E ̸= F we also have ⃗R(E)≤m ⪯⃗R(Ψδ
Z)≤m. For
any D ∈Prcnf(E) we thus get by induction hypothesis
⃗R(E)D
≤m = ⃗R(Ψδ
Z)D
≤m.
(v)
Moreover we have eM
<ζ
M – Pm+1 ⪯M<ρ
M – Pm+1 = ⃗R(Ψδ
Z)m+1. By Lemma 3.45 we
therefore have ⃗R(M)≤m ⪯⃗R(Ψζ
M(⃗µ))≤m ⪯⃗R(Ψδ
Z)<m. Applying the induction
hypothesis to M and Ψδ
Z we obtain
⃗R(M)D
≤m = ⃗R(Ψδ
Z)D
≤m for all D ∈Prcnf(M).
(vi)
Let ⃗R(E)≤m = (M<ε1
E1 – Pe1, . . . , M<εk
Ek – Pek). Then Ei ∈Prcnf(E) ⊆Prcnf(M)
and we get by (v) and (vi) M<εi
Ei – Pei = ⃗R(E)Ei
ei = ⃗R(Ψδ
Z)Ei
ei = ⃗R(M)Ei
ei ⪯⃗R(M)ei
for all ei ≤m, hence ⃗R(E)≤m ⪯⃗R(M)≤m. Since ⃗R(Ψζ
M(⃗ν ))≤m = ⃗R(M)≤m, we
have (iv). Applying the induction hypothesis to D, E and M we obtain
⃗R(E)D
[g,m) = ⃗R(Ψζ
M(⃗ν ))D
[g,m)] = ⃗R(Ψα
X)[g,m)D.
(vii)
Because of D ̸= F we have together with (v)
⃗R(Ψα
X)D
≤m = ⃗R(i(X))D
≤m = ⃗R(Ψδ
Z)D
≤m = ⃗R(E)D
≤m.
(viii)
Combining (vii) and (viii) the lemma is proved.
□
The next lemma is central for this section. It prepares the following theorem which
is the main theorem of this section.
3.51 Lemma (Main Lemma) Let F ̸= K be a reﬂection conﬁguration and E ∈
Prcnf(F). Let X be a reﬂection instance of F and α and ε ordinals such that
Ψα
X ↓and o(E) ≤ε ≤ranα
F(E). If eM
<ε
E – Pe ̸⪯⃗R(Ψα
X)e for some e ∈Rdh(E)
then any ordinal κ < i(X) that satisﬁes X, α ∈H⋆(κ), Hα(κ) ∩i(X) = κ,
κ |= eM
<ε
E – Pe and κ |= ⃗R(Ψα
X)<e is Mα
X–Π1
rdh∗(X)–indescribable for rdh∗(X) :=
max{0, rdh(X)}.
Proof
We induct on o(X). Let F be a Π1
rdh∗(X)–formula with parameters ⃗P ⊆Vκ
such that (Vκ, ⃗P) |= F. We distinguish cases according to the shape of X.
Provably Recursive Functions of Reflection
425

1. Assume ﬁrst F = A. Then X = A(m + 1) for some m ∈ω and E = A. Then
⃗R(Ψα
X) = (M<α
A – Pm, . . . , M<α
A – P0) and rdh(X) = m. From eM
<ε
E – Pe ̸⪯⃗R(Ψα
X)e
we get m < e. The hypothesis κ |= M<ε
E – Pe implies that κ is Π1
e–indescribable.
Therefore there is a κ0 < κ such that (Vκ0, ⃗P ∩Vκ0) |= F. Since X, α ∈H⋆(κ)
and Hα(κ) ∩i(X) are (via coding) expressible by Π1
e sentences and, because of
m < e, also κ |= ⃗R(Ψα
X) is by Corollary 2.5 expressible by a Π1
e–formula, we get
X, α ∈H⋆(κ0), Hα(κ0) ∩i(X) = κ0 and κ0 |= ⃗R(Ψα
X). Therefore κ0 ∈Mα
X and
κ is Mα
X–Π1
m–indescribable.
2.
Assume next that X is a successor instance with predecessor conﬁguration
Zδ. Put m := rdh(X). Towards a contradiction assume e ≤m. The assumption
E = F entails e = m, ranα
F(E) = α and M<ε
E – Pm ⪯eM
<α
F – Pm = ⃗R(Ψα
X)m
contradicting the hypothesis M<ε
E – Pe ̸⪯⃗R(Ψα
X)e. Hence E ̸= F and thus E ∈
Prcnf(F) ⊆Prcnf(Z). Putting δ := ranα
F(Z) we get Hδ(κ) ∩i(Z) = κ,
Z, δ ∈
H⋆(κ) by Lemma 3.43. Clearly ranα
F(E) = ranδ
Z(E) and κ |= ⃗R(Ψα
X)<e entails
κ |= ⃗R(Ψδ
Z)<e because of e ≤m. Since ⃗R(Ψα
X)m = eM
<α
F – Pm ⪰⃗R(Ψδ
Z)m
we also have eM
<ε
E – Pe ̸⪯⃗R(Ψδ
Z)e. Applying the induction hypothesis we thus
get that κ is Mδ
Z–Π1
rdh∗(Z)–indescribable. Since Hα(κ) ∩i(X) = κ this entails
κ < i(X) = Ψδ
Z contradicting the minimality of Ψδ
Z. Hence m < e.
2.1. If j(X) = 0 the hypothesis κ |= ⃗R(Ψα
X)<e means κ |= ⃗R(Ψα
X). Since κ |=
M<ε
E – Pe we know that κ is Π1
e–indescribable. Therefore there is a κ0 < κ such that
(Vκ0, ⃗P ∩Vκ0) |= F and α, X ∈H⋆(κ0), Hα(κ0) ∩i(X) = κ0 and κ0 |= ⃗R(Ψα
X)
since all these facts are expressible by Π1
m–formulas. By Corollary 2.5 we thus get
κ0 ∈Mα
X and κ is Mα
X–Π1
rdh∗(X)–indescribable.
2.2. Assume j(X) ̸= 0 and let RS(X) =: Mζ
M(⃗µ). Then
⃗R(Ψα
X) = (⃗R(Ψζ
M(⃗µ))>m, ⃗R(Ψα
X)≤m).
(i)
2.2.1. If m+1 ≤rd(⃗R(j(X))) < e then κ |= ⃗R(Ψα
X)<e means again κ |= ⃗R(Ψα
X)
and we are in the case 2.1.
2.2.2. If e = m + 1 we get E ̸= F since Rdh(F) = {m}. Hence E ∈Prcnf(Z)
and the assumption eM
<ε
E – Pe ̸⪯⃗R(Ψδ
Z)e together with Lemma 3.43 yields that
κ is Mδ
Z–Π1
rdh∗(Z)–indescribable contradicting the minimality of Ψδ
Z. Therefore
eM
<ε
E – Pe ⪯⃗R(Ψδ
Z)e = eM
<γ
M – Pe for some γ > ζ. The assumption M ̸= E
would thus imply eM
<ε
E – Pe ⪯⃗R(i(M))e ⪯M<ζ
M – Pe = ⃗R(Ψα
X)e contradicting
426
Wolfram Pohlers and Jan–Carl Stegert

our hypothesis eM
<ε
E – Pe ̸⪯⃗R(Ψα
X)e = eM
<ζ
M – Pe. Hence M = E and therefore
ζ < ε ≤γ. Since ζ,⃗ν ∈dom(F)↾H⋆(Ψα
X ) we obtain from κ |= eM
<ε
E – Pe that κ
is Mζ
M(⃗ν )–Π1
e–indescribable. Moreover we have κ |= ⃗R(Ψα
X)<e, i.e., κ |= ⃗R(X),
which by Lemma 2.5 is expressible by a Π1
m–formula. Let F be a Π1
m–formula
with parameters ⃗P ⊆Vκ. Since m < e there is a κ0 ∈Mζ
M(⃗ν ) ∩κ such that
X, α ∈H⋆(κ0), Hα(κ0) ∩i(X) = κ0, κ0 |= eM
<α
F – Pm, κ0 |= ⃗R(X) and (Vκ0, ⃗P ∩
Vκ0) |= F. Hence κ0 ∈Mα
X and κ is Mα
X–Π1
rdh∗(X)–indescribable.
2.2.3. Let m+1 < e ≤rd(⃗R(j(X))). We have m+1 ∈Rdh(M) and ⃗R(Ψα
X)m+1 =
eM
<ζ
M – Pm+1. By Lemma 3.45 we therefore obtain ⃗R(Ψζ
M(⃗µ))≤m+1 ⪯⃗R(Ψα
X)≤m+1.
Since ⃗R(Ψζ
M(⃗µ))(e,m+1] = ⃗R(Ψα
X)(e,m+1] we have ⃗R(Ψζ
M(⃗µ))<e ⪯⃗R(Ψα
X)<e.
From κ |= ⃗R(Ψα
X)<e we therefore obtain by Lemma 3.44
κ |= ⃗R(Ψζ
M(⃗µ))<e.
(ii)
Since e ∈Rdh(E) we have eM
<ε
E – Pe = ⃗R(Ψε
E(⃗ν ))e for any ⃗ν ∈dom(E). Let
M<ε0
E0 – Pe := eM
<ε
E – Pe. Then
M<ε0
E0 – Pe ̸⪯⃗R(Ψα
X)e = ⃗R(Ψζ
M(⃗µ))e.
(iii)
This implies ε0 > o(E0) since ε0 = o(E0) entails E0 = A by Lemma 3.7 claim
2.2 and M<ω
A – Pe ⪯⃗R(Ψζ
M(⃗µ))e by Lemma 3.40.
2.2.3. 1.
If E0 ∈Prcnf(M) we get by Lemma 3.7 claim 2.2 ε0 ≤ranε
E(E0) ≤
ranα
X(E0). If ε0 > ranζ
M(E0) then E0 = M since otherwise ε0 > ranζ
M(E0) =
ranα
X(E0) ≥ε0. Since e ∈Rdh(E0) = Rdh(M) we have ⃗R(Ψζ
M(⃗µ))e = eM
<ζ
M – Pe.
Thus M<ε0
M – Pe ̸⪯eM
<ζ
M – Pe implies ζ < ε0. From the hypothesis κ |= eM
<ε
E – Pe =
M<ε0
M – Pe we therefore obtain that κ is Mζ
M(⃗µ)–Π1
e–, hence Mζ
M(⃗µ)–Π1
m+1–, inde-
scribable.
So assume ε0 ≤ranζ
M(E0). By Lemma 3.7 claim 1.3.1 we have M ∈Prcnf(X),
hence Mζ ∈Prcnf(X) and thus ranα
X(M) = ζ. By Lemma 3.43 we therefore obtain
M(⃗µ), ζ ∈H⋆(κ) and Hζ(κ) ∩i(M) = κ.
(iv)
From (ii), (iii), (iv) and rdh(M) = m + 1 we get by induction hypothesis that κ is
Mζ
M(⃗µ)–Π1
m+1–indescribable.
Moreover we have X, α ∈H⋆(κ), Hα(κ) ∩i(X) = κ, κ |= ⃗R(X) and κ |=
Provably Recursive Functions of Reflection
427

M<α
F – Pm and all these facts are expressible by Π1
m+1–formulas. Therefore there
is a κ0 ∈Mζ
M(⃗µ) ∩κ such that (Vκ0, ⃗P ∩Vκ0) |= F, Hα(κ0) ∩i(X) = κ0 and
κ0 |= ⃗R(X). Hence κ0 ∈Mα
X and κ is Mα
X–Π1
m–indescribable.
2.2.3. 2.
It remains to study the case that M ∈Prcnf(E0). Then E0 ̸= A. Hence
e = rdh(E0). We proceed by subsidiary induction on d := e −(m + 1). Then
d > 0.27 Putting β := o(E0) we get from κ |= eM
<ε
E – Pe that κ is Mβ
E0(⃗ν )–Π1
e–
indescribable for any ⃗ν ∈dom(E0)↾H⋆(κ). Therefore there is a κ0 ∈Mβ
E0(⃗ν )
that shares all the properties of κ that are Π1
e–expressible. Towards a contradiction
assume
⃗R(E0)<e ⪯⃗R(Ψα
X)<e.
(v)
Since E0 ̸= F and m + 1 < e this entails ⃗R(E0)≤m+1 ⪯⃗R(i(X))≤m+1. Since
E0 ∈Prcnf(Z) and m+1 ≤min{rd(⃗R(E0)), rd(⃗R(i(X)))} we get by Lemma 3.50
and the fact that ⃗R(i(X))m+1 = M<γ
M – Pm+1 for some γ > ζ the absurdity
⃗R(E0)M
m+1 ⪯⃗R(E0)m+1 ⪯⃗R(Ψα
X)m+1 = eM
<ζ
M – Pm+1
≺M<γ
M – Pm+1 = ⃗R(i(X))m+1 = ⃗R(E0)M
m+1.
So (v) is false and we have ⃗R(E0)<e ̸⪯⃗R(Ψα
X)<e, i.e., that for
⃗R(E0)<e =: (M<ε1
E1 – Pe1, . . . , M<εp
Ep – Pep)
there is a j ∈1, . . . , p such that
M<εj
Ej – Pej ̸⪯⃗R(Ψα
X)ej.
(vi)
Hence Ej ̸= A which implies o(Ej) < εj. Moreover we get by Lemma 3.7
Ej ∈Prcnf(E0) ⊆Prcnf(F), ej ∈Rdh(Ej), εj ≤ranε0
E0(Ej) = ranα
X(Ej) and
from ej < e also κ |= ⃗R(Ψα
X)<ej. By the Mβ
E0(⃗µ)–Π1
e–indescribability of κ we
get a κ0 ∈Mβ
E0(⃗µ) also satisfying κ0 |= ⃗R(Ψα
X)<e1. Since κ0 ∈Mβ
E0(⃗µ) we also
have κ0 |= ⃗R(E0), hence κ0 |= M<εj
Ej – Pej. As in the beginning of Case 2 we get
m < ej.
If m + 1 = ej we get that κ0 is Mα
X–Π1
m–indescribable as in Case 2.2.2.
If m + 1 < ej < rd(⃗R(j(X))) and Ej ∈Prcnf(M) then κ0 is Mα
X–Π1
m–
indescribable as shown in Case 2.2.3. 1.
If m + 1 < ej < rd(⃗R(j(X))) and M ∈Prcnf(Ej) we have ej −(m + 1) <
e −(m + 1) and obtain by the subsidiary induction hypothesis that κ0 is Mα
X–
Π1
m–indescribable. Therefore there is a κ1 ∈Mα
X ∩κ0 ⊆Mα
X ∩κ such that
27The case d = 0 is case 2.2.2
428
Wolfram Pohlers and Jan–Carl Stegert

(Vκ1, ⃗P ∩Vκ1) |= F and κ is Mα
X–Π1
m–indescribable.
□
3.52 Theorem Let X and Y be reﬂection instances with rdh(Y) ̸= −1 and α and
β ordinals. Then Ψα
X↓∈Mβ
Y implies ⃗R(Ψβ
Y) ⪯⃗R(Ψα
X).
Proof
Let Y be an instance of G and X an instance of F. From Ψα
X ∈Mβ
Y and
rdh(Y) ̸= −1 we get that Ψα
X is a regular cardinal, hence F ̸= K. Towards a con-
tradiction assume ⃗R(Ψβ
Y) ̸⪯⃗R(Ψα
X). Let ⃗R(Ψβ
Y) = (M<γ1
G1 – Pg1, . . . , M<γn
Gn – Pgn).
Then there is a k ∈{1, . . . , n} such that M<γk
Gk – Pgk ̸⪯⃗R(Ψα
X)k. From Ψα
X ∈Mβ
Y
we get by Theorem 3.38 and Lemma 3.7 G ∈Prcnf(F), β ≤ranα
F(G), Gk ∈
Prcnf(G) ⊆Prcnf(F), o(Gk) ≤γk ≤ranβ
G(Gk) ≤ranα
F(Gk) and gk ∈Rdh(Gk).
Moreover we have X, α ∈H⋆(Ψα
X) and Hα(Ψα
X) ∩i(X) = Ψα
X since Ψα
X↓. From
Ψα
X ∈Mβ
Y we obtain Ψα
X |= ⃗R(Ψβ
Y) and Ψα
X |= ⃗R(Y). Hence Ψα
X |= eM
<γk
Gk – Pgk.
From Ψα
X ∈Mα
X we also have Ψα
X |= ⃗R(Ψα
X)<gk. By the main lemma we therefore
obtain that Ψα
X is Mα
X–Π1
rdh∗(X)–indescribable. But this contradicts the minimality
of Ψα
X.
□
4
Ramiﬁed set theory
In this section we follow quite closely Section 11.9 in [15]. However, to make
the paper more self contained, we repeat (and sometimes also slightly modify) the
deﬁnitions given there.
4.1
The language of ramiﬁed set theory
The language LRS of ramiﬁed set theory is obtained from the language L(∈) of
set theory by adding constants Lα for all stages of the constructible hierarchy and
names for constructible sets. To keep notations simple we will not introduce special
symbols for the names of constructible sets but identify sets {x ∈Lα F} and their
names. The LRS–terms and –formulas are therefore inductively deﬁned by
• For any ordinal α we have the LRS–term Lα of stage α.
• If F is an LRS–formula then {x ∈Lα F} is an LRS–term of stage
max{α, St(F)}.
• If F(x1, . . . , xn) is a L(∈)–formula28 with no further free variables and
a1, . . . , an are LRS–terms, then F(a1, . . . , an)Lα is an LRS–formula the stage
of which is max{α, St(a1), . . . , St(an)}.
Provably Recursive Functions of Reflection
429

By Tα we denote the sequence of LRS–terms of stages less than α in a ﬁxed
ordering (whose exact deﬁnition is inessential).
We use the Tait language for ramiﬁed set theory, i.e., we use ∈and /∈as basic
relation symbols and deﬁne the negation of a formula by using deMorgan’s laws.
Recall that we write F α instead of F Lα and likewise (∃xα) and (∀xα) instead of
(∃x ∈Lα) and (∀x ∈Lα), respectively.
An LRS–formula F is ∆π
0 iff all the terms occuring in F have stages less than
π. We call F a pure Σπ
1(Ππ
1)–formula if F has the form (∃xπ)F(x) ((∀xπ)F(x))
where F(L0) is a ∆π
0–formula. The Σπ
1 (Ππ
1)–formulas are the closure of the pure
Σπ
1 (Ππ
1)–formula under the positive boolean operations ∧and ∨.
By recursion on n we deﬁne the pure Σπ
n+1–formulas as formulas of the shape
(∃xπ)G(x) where G(L0) is a Ππ
n–formula and F as pure Ππ
n+1 iff ¬F is pure Σπ
n+1.
The Σπ
n+1 (Ππ
n+1)–formulas are the closure of the pure Σπ
n+1 (Ππ
n+1)–formulas
under ∨and ∧.
The formulas of ramiﬁed set theory are divided into two types. The W–type
comprises formulas of the shape t ∈s, F ∨G and (∃x ∈s)F while the V–type
contains their negations, i.e., formulas of the shape t /∈s, F ∧G and (∀x ∈s)F.
To every formula F we assign its characteristic subformula sequence CS(F) =

Gι ι ∈I

. Sometimes it is convenient to write
F b≡V
Gι ι ∈I

and F b≡W
Gι ι ∈I

for formulas in V–type and W–type, respectively. For the formulas in W–type
we deﬁne
CS(s ∈Lα) :=

s = a a ∈Tα

CS(s ∈{x ∈Lα F}) :=

s = a ∧F(a) a ∈Tα

CS(Wn
i=1Fi) = ⟨F1, . . . , Fn⟩
CS((∃x ∈Lα)F(x)) :=

F(a) a ∈Tα

CS((∃x ∈{y ∈Lα G(y)})F(x)) :=

G(a) ∧F(a) a ∈Tα

.
For a formula F in V–type we obviously have ¬F ∈W–type and deﬁne
CS(F) =

¬G G ∈CS(¬F)

.
For F in W–type we clearly get L |= F iff L |= G for some G ∈CS(F) and dually
L |= F iff L |= G for all G ∈CS(F) if F is a formula in V–type.
If CS(F) =

Gι ι ∈I

we put ι(F) := Gι for ι ∈I.
28As a peculiarity we do not count the equality symbol among the basic symbols but regard s = t as
an abbreviation for (∀x ∈s)[x ∈t] ∧(∀x ∈t)[x ∈s].
430
Wolfram Pohlers and Jan–Carl Stegert

To avoid the case distinction in the deﬁnition of the characteristic subformula
sequence it is convenient to introduce the relation symbols ∈and /∈deﬁned by
s ∈t :⇔
 true
if t is a term Lα
F(a)
if t is a term {x ∈Lα F(x)}
and
s /∈t :⇔
 false
if t is a term Lα
¬F(a)
if t is a term {x ∈Lα F(x)},
where true and false can be chosen as an arbitrary true or respectively false for-
mula29. This has the technical advantage that the characteristic subformula se-
quences simplify to
CS(s ∈t) =

s = a ∧a ∈t a ∈TSt(t)

and
CS((∃x ∈t)F(x)) =

a ∈t ∧F(a) a ∈TSt(t)

independent of the shape of t. This holds dually for the characteristic sequences of
the corresponding formulas in V–type.
For every formula F we can deﬁne an ordinal rnk(F) that measures the com-
plexity of the formula F such that rnk(G) < rnk(F) holds true for all G ∈CS(F).
We will not give this deﬁnition here but refer for the details to Section 11.9 in [15].
All we need to know is
rnk(F) = ω · St(F) + n for some ﬁnite ordinal n.
(10)
The (ordinal) parameters Par(F) of an LRS–formula F are the ordinals α such that
Lα occurs in F. We clearly have Par(F) ⊆St(F) + 1.
4.2
The inﬁnitary calculus Π∞
ω
There is a canonical inﬁnitary veriﬁcation calculus associated to the language of
ramiﬁed set theory. We deﬁne the veriﬁcation relation
α ∆for an ordinal α and
a ﬁnite set of RS–formulas, which should be regarded as a veriﬁcation for the dis-
junction of the formulas in ∆(cf. Chapter 11 of [15]). It comprises two rules
(V–rule) If F is a formula in V–type belonging to ∆and we have
αG ∆, G and
αG < α for all G ∈CS(F) then
α ∆.
(W–rule) If F is a formula in W–type belonging to ∆and we have
α0 ∆, Γ for
some ﬁnite set Γ ⊆CS(F) then
α ∆holds true for all α > α0.
29E.g. true as the sentence L0 /∈L0, i.e. as a sentence in V–type with empty characteristic sequence,
and dually false as L0 ∈L0.
Provably Recursive Functions of Reflection
431

By an easy induction on α we obtain
α ∆⇒L |= W∆.
(11)
For sentences true in L there is a least ordinal α such that
α F. We call α the
veriﬁcation length of F.
In order to compute upper bounds for the veriﬁcation length of formulas that are
provable in Ref we have to extend the veriﬁcation calculus to an inﬁnitary calculus
Π∞
ω by adding a cut– and a reﬂection rule.
4.1 Deﬁnition The inﬁnitary proof relation
α
ρ ∆is inductively deﬁned by the fol-
lowing rules
(V–rule) If F is a formula in V–type belonging to ∆and we have
αG
ρ
∆, G and
αG < α for all G ∈CS(F) then
α
ρ ∆.
(W–rule) If F is a formula in W–type belonging to ∆and we have
α0
ρ ∆, Γ for
some ﬁnite set Γ ⊆CS(F) then
α
ρ ∆holds true for all α > α0.
(cut)
If
α0
ρ ∆, C and
α0
ρ ∆, ¬F for a formula C of rank less than ρ then
α
ρ ∆holds true for all α > α0.
(Ππ
m+2-Ref) Let F be a Ππ
m+2–formula such that (∃xπ)[x |= F] ∈∆,
α0
ρ ∆, F
and there is a reﬂection instance X such that rdh(X) = m −1, i(X) = π
and j(X) = 0 then then
α
ρ ∆holds for all α > α0.
We refer to the formula F in the above rules as the main–formula of the rule. The
cut rule does not possess a main–formula.
It is not obvious that
α
ρ ∆also implies L |= W∆. The reason is an imbalance in the
reﬂection rules of Π∞
ω . The rule axiomatizes a Πm+2–reﬂecting ordinal while the
ordinal i(X) of the associated reﬂection instance is a Π1
m–indescribable cardinal.30
However, a proof
α
ρ ∆µ with µ, ρ < ω+ = i(K(ω)) cannot contain applications
of reﬂection rules. According to Theorem 11.10.2 in [15] we therefore get
4.2 Theorem If µ, ρ < ω+ then
α
ρ ∆µ implies
α ∆µ, hence also L |= W∆µ.
This theorem sufﬁces for an ordinal analysis of Ref. Therefore our ﬁrst aim is to
collapse µ and ρ below ω+ =: Ω. To this end we introduce operator controlled
derivations.
30Here it would be more adequate to develop the theory of reﬂection conﬁgurations on the basis
of reﬂecting ordinals instead of indescribable cardinals. But, as already mentioned, this increases the
amount of work that is necessary for the existence proof by dimensions.
432
Wolfram Pohlers and Jan–Carl Stegert

4.3 Deﬁnition Let H be a Skolem hull operator. We say that H controls an inﬁnite
derivation
α
ρ ∆— written as H
α
ρ ∆— iff α ∈H(Par(∆)) and in case of an
inference
αi
ρ ∆ι for ι ∈I
⇒
α
ρ ∆
whose main–formula is not universal we also have Par(∆ι) ⊆H(Par(∆)).31
Clearly H
α
ρ ∆µ implies
α
ρ ∆µ and, for ρ, µ < ω+, thus also L |= W∆µ.
To save notations we write
H(∆)
and
H[∆]
instead of H(Par(∆)) and
H[Par(∆)],
respectively. For ﬁnitely many formulas F, G, . . . we also write
H[F, G, . . .] instead of H[ Par(F) ∪Par(G) ∪· · ·].
Working with inﬁnite derivations is cumbersome because of the bookkeeping of
the assigned ordinals. However, in most case we do not really need optimal bounds
but can content ourselves with rough upper bounds. Therefore we introduce an
auxiliary calculus
◦∆that derives multisets.32 For details see Chapter 11 in [15].
Nevertheless we repeats its deﬁnition.
4.4 Deﬁnition Let J := C[{0, Ξ}] be the least Cantorian closed Skolem hull op-
erator that comprises 0 and Ξ as points. There are two rules
(V◦)
If F is in V–type and
◦Γ, G holds for all G ∈CS(F) then
◦Λ for all
Λ ⊇Γ, F viewed as multisets. If F is not universal we require Par(G) ⊆
J (Λ).
(W◦)
If F is in W–type and
◦Γ, ∆holds for a ﬁnite subset ∆⊆CS(F) and
Par(G) ⊆J (Λ) then
◦Λ for all Λ ⊇Γ, F viewed as multisets.
For a multiset ∆we deﬁne drnk(∆) as the natural sum of ω and ωrnk(F ) for all
F ∈∆counted in its multiplicity.33 For a multiset ∆it is convenient to have the
notion
•
0 ∆
:⇔H
drnk(∆)
0
∆for all Skolem hull operators H extending J .
31This differs from the deﬁnition given in [15]. There we concentrated on Π1
1–ordinal analysis for
which ﬁnite ordinal parameters are inessential. Finite parameters are, however, essential in the charac-
terization of the provable recursive functions. In Section 6 we therefore need the more liberal deﬁnition
given here, which allows us to infer universal quantiﬁers bounded by ﬁnite ordinals without having to
control the parameters of the premises. Observe moreover that this condition means only a restriction
for cuts and W–inferences whose main–formula is existential. In all other cases we automatically have
Par(∆ι) ⊆Par(∆).
32A multiset is a sequence of elements. Two multisets Γ and ∆are supposed to be equal if Γ is a
permutation of ∆. Note that in a multiset all elements are counted in their multiplicity.
33Unfortunately the deﬁnition of the derivation rank drnk(∆) is lacking in [15]. It apparently has
been clandestinely confused with a later mathline during the printing process.
Provably Recursive Functions of Reflection
433

By Lemma 11.10.6 in [15] we then obtain
◦∆
⇒
•
0 ∆
(12)
and may use the other results of Sections 11.10 and 11.12 to obtain
•
0 a = a for every term a.
(13)
•
0 Lλ ̸= ∅∧Tran(Lλ) ∧a ∈Lλ for all λ ̸= 0 and a ∈Tλ.
(14)
•
0 F, ¬F
for all formulas F.
(15)
•
0 s ̸= t, ¬F(s), F(t) for all formulas F(s) and terms s and t.
(16)
4.3
Embedding of Ref
To get an embedding of the theory of reﬂections into the inﬁnitary system we again
rely on Section 11.12 of [15]. There it is shown that we have
•
0 (Ext)λ for all λ ∈Lim.
(17)
•
0 (Pair)λ for all λ ∈Lim.
(18)
•
0 (Union)λ for all λ ∈Lim.
(19)
•
0 (∆0–Sep)λ for all λ ∈Lim.34
(20)
The axiom (Nullset) – which is not explicitly proved there – is easily obtained.
Since s /∈L0 is for any term s a formula in V–type with empty characteristic
subformula sequence we have H
0
0 s /∈L0 . Thus we obtain for any ordinal λ > 0
•
0 (Nullset)λ
(21)
by an inference (V) followed by (W) with L0 as witness for an element in Lλ.
By Theorem 11.12.8 in [15] we get
H
ω(λ+1)
0
(∀⃗xλ)

(∃zλ)F(z, ⃗x)λ →(∃zλ)[F(z, ⃗x)λ ∧(∀y ∈z)¬F(y, ⃗x)λ]

(22)
for every limit ordinal λ and every H extending J , i.e., H
ω·(λ+1)
0
(Found)λ .
To derive all instances of (REF)Ξ let F(v1, . . . , vn) be a formula in the language
of set theory. Pick any a1, . . . , an ∈TΞ. We have
•
0 F(a1, . . . , an)Ξ, ¬F(a1, . . . , an)Ξ
34Which means
•
0 F λ for every instance F of the scheme (∆0–Sep).
434
Wolfram Pohlers and Jan–Carl Stegert

by (15). Choose m so big that F(a1, . . . , an) becomes a ΠΞ
m+2–formula. Since
i(A(m)) = Ξ and rdh(A(m)) = m −1 we can apply a rule (ΠΞ
m+2–Ref) followed
by an inference (W) and obtain
•
0 F(a1, . . . , an)Ξ →(∃zΞ)[z |= F(a1, . . . , an)Ξ] .
By an application of a rule (V) we ﬁnally obtain
•
0 (∀⃗y Ξ)

F(⃗y)Ξ →(∃z Ξ)[z |= F Ξ]

,
i.e.,
•
0 (REF)Ξ
(23)
for any H extending J .
To embed logic we modify Theorem 11.12.3 in [15] to obtain
4.5 Lemma Let F(v1, . . . , vn) be a ﬁrst order formula in the language of set the-
ory that is logically valid. Then for every ordinal α and any tuple a1, . . . , an ∈Tα
there are ﬁnite ordinals m and n such that H
ωω·α+m
ω·α+n F(a1, . . . , an)α holds true
for any Cantorian closed Skolem hull operator H.
Gluing these facts together we obtain an embedding theorem.
4.6 Theorem (Embedding Theorem) Assume that the theory Ref proves a sentence
F. Then there are ﬁnite ordinals m and n such that H
ω Ξ+m
Ξ+n
F Ξ for every Skolem
operator H extending J .
In order to be able to talk about F ωCK
1 –formulas in Ref we deﬁne a predicate Ad
such that Ad(x) expresses that x is an admissible set containing ω as an element.
Then (∀x)[Ad(x) →F x] expresses that F is restricted to all admissible ordinals
containing ω as element, i.e., that F is restricted to LωCK
1 .
There are various ways to deﬁne Ad within the theory Ref. Either by using
the formula σ0 of Theorem 2.4 in [22] or by an extension by deﬁnitions with an
additional predicate Ad together with its deﬁning axiom schemes
(Ad.1) (∀x)[Ad(x) →Tran(x)]
(Ad.2) (∀x)(∀y)[Ad(x) ∧Ad(y) →x ∈y ∨x = y ∨y ∈x]
(Ad.3) (∀x)[Ad(x) →x |= KPω].35
To get an embedding for the second variant we extend LRS by an additional predi-
cate f
Ad and put
35The theory KPω comprises the axioms of Ref where the scheme (REF) is replaced by ∆0–
collection and an inﬁnity axiom. Cf. [15] Chapter 11 for details.
Provably Recursive Functions of Reflection
435

s ∈f
Ad b≡W
s = Lπ π ∈Reg

.
Replacing Ad by f
Ad we then obtain a canonical translation of the languages. We
will, however, make no notational distinction between a formula F and its transla-
tion.
From Chapter 11.12 in [15] we obtain ﬁnite ordinals m such that
H
ωωλ+m
0
(Ext)λ ∧(Pair)λ ∧(Union)λ ∧(∆0–Sep)λ ∧(FOUND)λ
for every limit ordinal λ. Since there is a (Ππ
2–Ref)–rule for every regular cardinal
π we get
H
ωωλ+m
0
(∆0–Coll)π ∧(Inf)π
for every regular cardinal π.36 Therefore we obtain H
ωωπ+m
0
KPωLπ for all π ∈
Reg ∩Ξ. Since
◦Lπ ̸= ∅∧Tran(Lπ) ∧a ∈Lπ holds true for all a ∈Tπ and
π > 0 we obtain together with (16) by some inferences (including a cut) a ﬁnite m
such that
H
ωω Ξ+m
Ξ
(∀xΞ)[¬(x ∈f
Ad) ∨KPωx] .
Similarly, though even simpler, we also get the translations of the axioms (Ad.1)
and (Ad.2).
Summing up we can extend the embedding Theorem 4.6 to the extended theory
Ref + Ad into ramiﬁed set theory augmented by f
Ad.
4.7 Theorem Assume that Ref + Ad proves a sentence F. Then there are ﬁnite
ordinals m and m such that H
ω Ξ+m
Ξ+n
F Ξ holds true for all Skolem hull operators
extending J .
As a corollary we obtain the embedding of ΠωCK
1
2
sentences.
4.8 Corollary Assume that Ref + Ad proves a sentence (∀x)[Ad(x) →F x]. Then
there are ﬁnite ordinals m and n such that H
ω Ξ+m
Ξ+n
F Ω.
Proof
We observe that we have
•
0 LΩ= LΩand thus also
•
0 LΩ∈f
Ad . By the
theorem and inversion we get H
ω Ξ+m0
Ξ+n0
LΩ/∈f
Ad, F Ωand by a cut the claim.
□
36In fact we even have full collection.
436
Wolfram Pohlers and Jan–Carl Stegert

5
Π1
1 –ordinal analysis of Ref
5.1
Predicative cut–elimination
To eliminate the reﬂection rules in derivations of ΠωCK
1
2
–sentences we need addi-
tional reﬂection rules. Therefore we enlarge the language of ramiﬁed set theory by
additional predicates σMξ
X and deﬁne their characteristic sequences by
s ∈σMξ
X b≡W
s = Lβ σ < β ∈Mξ
X

and dually
s /∈σMξ
X b≡V
s ̸= Lβ σ < β ∈Mξ
X

.
The ordinal parameters of the new predicates are
Par(σMξ
X) := {σ, ξ} ∪Par(X).
We need two additional reﬂection rules.
5.1 Deﬁnition (Side– and subsidiary reﬂection rules.) Let F be a Ππ
m+2–formula,
σ an ordinal less than π, M a reﬂection conﬁguration, ⃗ν ∈dom(M), ξ an ordinal
and ∆a ﬁnite set of formulas such that (∃zπ)[z ∈σMξ
M(⃗ν ) ∧z |= F] belongs to
∆. Then
α0
ρ
∆, F implies
α
ρ ∆if α0 < α and one of the following conditions is
satisﬁed.
1. There is a reﬂection instance X such that i(X) = π, rdh(X) = m −1 and
RS(X) = Mξ
M(⃗ν ).
2. There is a reﬂection instance X such that i(X) = π, ξ ∈H⋆(π) and
M<ξ+1
M
– Pm ⪯⃗R(π)′
m.
Reﬂection rules according to Case 1. are referred to as side reﬂections, rules
according to Case 2. as subsidiary reﬂections. Subsidiary and side reﬂection rules
are summarized as ( σMξ
M(⃗ν )–Ππ
m+2–Ref) rules.
In a ﬁrst step we show that the so extended inﬁnitary system satisﬁes all properties
that are need for the familiar predicative cut elimination. We list these properties
below. By H1 ⊆H2 for Skolem hull operators we mean that H1(X) ⊆H2(X)
holds true for all X.
(Weakening)
If H1
α
ρ ∆, α ≤β, ρ ≤σ, ∆⊆Γ, H1 ⊆H2 and β ∈H2(Γ) then
H2
β
σ Γ holds true, too.
(Hull) If H[X]
α
ρ ∆and X ⊆H(∆) then H
α
ρ ∆.
Provably Recursive Functions of Reflection
437

(V–inversion)
If H
α
ρ ∆, F and F ∈V–type then H[F]
α
ρ ∆, G holds true for
all G ∈CS(F).
( ∨–exportation)
If H
α
ρ ∆, Wn
i=1Fi then also H
α
ρ ∆, F1, . . . , Fn .
( ∧–exportation)
If H
α
ρ ∆, Vn
i=1Fi then also H
α
ρ ∆, F1, . . . , Fn .
(upwards persistency) If H
α
ρ ∆, (∃xσ)F(x) for rnk((∃xσ)F(x)) < ρ and σ < τ
for additively indecomposable ordinals σ and τ then
H[{σ}]
α+σ+1
ρ
∆, (∃xτ)F(x) .
(downwards persistency)If H
α
ρ ∆, (∀xτ)F(x) for rnk((∀xτ)F(x)) < ρ and σ <
τ for additively indecomposable ordinals σ and τ then
H[{τ}]
α+τ+1
ρ
∆, (∀xσ)F(x) .
All these claims with the exception of persistency are easily proved by induction
on α. To show upwards persistency we ﬁrst prove H
2·rnk(F (t))
0
∆, ¬F(t), F(t) for
all t ∈Tσ ⊆Tτ by induction on rnk(F(t)). This yields
H
2·rnk(F (t))+1
0
∆, ¬F(t), (∃xτ)F(x)
for all t ∈Tσ and thus H
σ
0 ∆, ¬(∃xσ)F(x), (∀xτ)F(x) by an inference V. Since
rnk((∃xσ)F(x)) < ρ and Par((∃xσ)F(x)) ⊆H[{σ}](∆, (∃xτ)F(x)) and α, σ <
α + σ + 1 ∈H[{σ}](∆, (∃xτ)F(x)) we obtain the claim by a cut. Downwards
persistency is proved dually.
5.2 Deﬁnition For a ﬁnite set ∆of LRS–formulas and ordinals σ ≤π we denote
by ∆π,σ the set of formulas that is obtained from ∆by replacing all restricted
quantiﬁers (Qxπ) by (Qxσ).
As a consequence of upwards persistency we obtain that for a ﬁnite set ∆of Σ1–
formulas H
α
ρ ∆σ, Γ with σ < ρ, σ a strongly critical ordinal, entails
H
α+σ+1
ρ
∆σ,τ, Γ
for all τ ≥σ. The reason is that for a Σσ
1–formula (∃xσ)F(x) with strongly critical
σ we have rnk((∃xσ)F(x)) = σ and there are no universal quantiﬁers in ∆σ that
are restricted by σ.
Clearly we have predicative cut elimination for the inﬁnitary system Π∞
ω , i.e., a
theorem that corresponds to Theorem 9.3.15 in [15]. We cannot use Theorem 9.3.15
directly since there are additional reﬂection rules in Π∞
ω . The reduction lemma
(Lemma 9.3.14 of [15]) does not hold in the same generality. To copy the proof
given there we have to avoid the case that the critical formula F is obtained as the
438
Wolfram Pohlers and Jan–Carl Stegert

main formula of an application of a reﬂection rules. Since all such formulas have
regular rank we can modify the reduction lemma in the following way.
5.3 Lemma (Reduction Lemma) Let F be in V–type, ρ = rnk(F) not a regular
ordinal and Par(F) ⊆H(Γ). Then H
α
ρ ∆, F and H
β
ρ Γ, ¬F imply H
α+β
ρ
∆, Γ .
Proof
See Lemma 9.3.14 in [15].
□
From the Reduction Lemma we obtain predicative cut elimination in the following
form.
5.4 Theorem Let H be a Veblen closed Skolem hull operator. Then H
α
β+ωρ ∆for
(β, β + ωρ) ∩Reg = ∅and ρ ∈H(∆) imply H
ϕρ(α)
β+1
∆.
Proof
See Theorem 9.3.15 in [15].
□
5.2
Elimination of reﬂection rules
5.5 Remark We have developed the thinning hierarchies Mα
X, the functions Ψα
X
and the iterations Hα on the basis of a ﬁxed Skolem–hull operator H extending
V[{0, Ξ}]. In the inductive proof of the Elimination Theorem 5.9 below we actu-
ally need iterations (Hα)β of Hα. The simultaneous deﬁnition of reﬂection con-
ﬁgurations and their reﬂection instances makes the computation of (Hα)β rather
cumbersome. Instead of doing this cumbersome computation we prove the Elimi-
nation Theorem in a more specialized version. We restrict ourselves to a Skolem–
hull operator H that is V[{0, Ξ}] containing also the generating function π 7→π+
and formulate the hypothesis of the Elimination Theorem with an already iterated
operator Hγ+1.37
For the following considerations it sufﬁces to restrict ourselves to ordinals that
belong to the set HΓΞ+1(∅), which we declare as a general hypothesis for the fol-
lowing sections.
The following theorem is central for the elimination of reﬂection rules. It is exactly
this theorem that forced us to develop the ﬁne–structure theory of Section 3.6.
For a reﬂection conﬁguration F let dom(F)≥n := {⃗η ∈dom(F) rdh(F(⃗η ) ≥n)}.
5.6 Theorem Let X be a reﬂection instance of a reﬂection conﬁguration F such
that rdh(X) =: n ≥0. Let α ≥o(F) and κ be ordinals such that κ ∈Mα
X. Then
we obtain.
37This technique has already been used by Buchholz in his seminal paper [7].
Provably Recursive Functions of Reflection
439

1. For every τ < κ, α0 ∈[o(X), α)↾H⋆(κ) and ⃗η ∈dom(F)≥n
↾H⋆(κ) there is a
reﬂection rule ( τMα0
F(⃗η )–Πκ
n+2–Ref).
2. For any τ < κ, any reﬂection conﬁguration M, any ζ ∈H⋆(κ) and ⃗η ∈
dom(M)↾H⋆(κ) for which there is a subsidiary reﬂection rule ( τMζ
M(⃗η )–Πi(X)
m+2–Ref)
there is also reﬂection rule ( τMζ
M(⃗η )–Πκ
m+2–Ref).
Proof
1. The claim is trivial for α = o(X) or dom(F)≥n
↾H⋆(κ) = ∅. So assume
o(X) < α and dom(F)≥n
↾H⋆(κ) ̸= ∅. Since rdh(X) ≥0 the ordinals in Mα
X are
at least Π1
0–indescribable. Therefore (and by our general hypothesis38) κ = Ψβ
Y
for some reﬂection instance Y and ordinal β ≥o(Y). By Theorem 3.52 we have
⃗R(Ψα
X) ⪯⃗R(κ). From o(X) < α we obtain ⃗R(Ψα
X)n = M<α
F – Pn ⪯⃗R(κ)n.
1.1. If M<α
F – Pn ⪯⃗R(κ)′
n then ( τMα0
F(⃗η )–Πκ
n+2–Ref) exists as subsidiary reﬂection
rule.
1.2. Assume M<α
F – Pn ̸⪯⃗R(κ)′
n. Let ⃗R(κ) = (M<γ
G – Pg, . . .). Then ⃗R(Ψα
X) ⪯
⃗R(κ) entails g = n and M<α
F – Pn ̸⪯(M<γ
G – Pn)′. Therefore there is no ξ ≥α such
that M<ξ
F – Pn ∈TC((M<γ
G – Pn)′). However, we have M<ξ
F – Pn ∈TC(M<γ
G – Pn) =
{M<γ
G – Pn} ∪TC((M<γ
G – Pn)′) for some ξ ≥α. Therefore G = F and o(F) ≤γ.
Hence ⃗R(κ) = ⃗R(Ψβ
Y) = (M<γ
F – Pn, . . .). Then H := Yβ is a reﬂection conﬁg-
uration with rdh(Yβ) = n −1, dom(H) = [o(F), γ)↾H⋆(κ) × dom(F)↾H⋆(κ) and
RS(H(α0, ⃗η )) = Mα0
F(⃗η ) and i(H(α0, ⃗η )) = Ψβ
Y = κ. According to Deﬁnition 5.1
case 1 there is a ( τMα0
F(⃗η )–Πκ
n+2–Ref) rule.
2. Let ( τMζ
M(⃗η )–Πi(X)
m+2–Ref) be a subsidiary reﬂection rule. Then M is a reﬂection
conﬁguration fulﬁlling M<ζ+1
M
– Pm ⪯⃗R(i(X))′
m ⪯⃗R(Ψα
X)m ⪯⃗R(κ)m, where
we used Lemma 3.42. So we are in the situation of case 1.1 with n replaced by m,
α by ζ + 1 and α0 replaced by ζ < ζ + 1.
□
To prepare the proof of Lemma 5.8 below we need a simple technical lemma.
5.7 Lemma Let α ≤β and κ ≤π. Then ρ ∈Hα(π)∩Hβ(κ) and Hβ(κ)∩π = κ
imply ρ ∈Hα(κ).
Proof
The operator Hα is generated by the generating functions of H augmented
by the functions ΨX↾α. Let Hn,α denote the nth stage in the generating process of
Hα. We show by induction on n
ρ ∈Hn,α(π) ∩Hβ(κ) and Hβ(κ) ∩π = κ ⇒ρ ∈Hα(κ).
For n = 0 we have ρ = Ξ ∈Hα(κ) or ρ < π, hence ρ < κ ⊆Hα(κ).
38This is in fact the only place where we need this hypothesis.
440
Wolfram Pohlers and Jan–Carl Stegert

If ρ = f(ξ1, . . . , ξn) where f belongs to the generating functions of H and
ξ1, . . . , ξn ∈Hn−1,α(π) we get ξ1, . . . , ξn ∈Hα(κ) by induction hypothesis and
thus ρ ∈Hα(κ).
If ρ = Ψξ
X for some ξ < α with ξ, X ∈Hn−1,α(π) we have ξ, X ∈Hα(κ) by
induction hypothesis and thus also Ψξ
X ∈Hα(κ).
□
Let A be a set of terms, formulas and ordinals. Put |A| := sup {Par(t) t ∈A}.
5.8 Lemma Let X be a reﬂection instance of a reﬂection conﬁguration F and put
δ := o(F). Let γ be an ordinal and µ a cardinal such that γ, X, µ ∈Hγ+1(A),
ω, δ ≤γ + 1 and σ := |A| < π := i(X) ≤µ. Deﬁne ˆα := γ =∥ωα=
∥µ. Then we
obtain:
1. If α0, α ∈Hγ+1(A) and α0 < α then ∅̸= Mˆα
X ⊆Mˆα0
X and for any κ ∈σMˆα
X
and any reﬂection instance Y = F(⃗η ) with ⃗η ∈dom(F) ∩Hγ+1(A) we have
Ψˆα0=
∥κ
Y
↓< Ψˆα=
∥κ
X
↓∈Hˆα=
∥κ+1(A ∪{κ}).
2. It is π ∈Hγ+1(A) and for all κ ∈Card for which there is a ρ ∈Hγ+1(A)
satisfying π ≤κ ≤ρ ≤κ+ we get κ, κ+ ∈Hγ+1(A).
3. For π ≤µ ∈Hγ+1(A) ∩Reg there exists a reﬂection instance Z such that
i(Z) = µ, o(Z) ≤γ + 1 and Z ∈Hγ+1(A).
Proof
1. Since σ = |A| we clearly have Hγ+1(A) ⊆Hγ+1(σ + 1) and ˆα =∥σ ∈
H⋆(π). Therefore we have Ψˆα=
∥σ
X
↓=: κσ. Hence σ ∈Hˆα=
∥σ(κσ) ∩π = κσ. Since
ˆα < ˆα =∥σ and γ, α, X ∈Hγ+1(σ + 1) ⊆Hˆα(κσ) we have κσ ∈σMˆα
X.
Let κ′ ∈σMˆα
X. We have ˆα0 < ˆα and γ, α0, µ ∈Hγ+1(σ + 1) ⊆Hˆα0(κ′).
Hence ˆα0 ∈H⋆(κ) and thus κ′ ∈σMˆα0
X , i.e., σMˆα
X ⊆σMˆα0
X .
Since κ < π = i(X) we have ˆα =∥κ ∈H⋆(π) and therefore
Ψˆα=
∥κ
X
↓∈Hˆα=
∥κ+1(A ∪{κ}).
If dom(F) = {ϵ} then Y = X and we get ˆα0 =∥κ < ˆα =∥κ as well as ˆα0 =∥κ ∈
H⋆(π). Hence Ψˆα0=
∥κ
X
↓< Ψˆα=
∥κ
X
by Lemma 3.27. So assume ϵ ̸= ⃗η ∈dom(F) ∩
Hγ+1(A) and Y = F(⃗η ). As before we obtain Ψˆα0=
∥κ
Y
↓=: κY. Towards a contra-
diction assume κX := Ψˆα=
∥κ
X
≤κY. Because of ˆα0 < ˆα equality is excluded by
Lemma 3.27. So we have κX < κY. From σ < κ ∈Hˆα=
∥κ(κX) ∩π = κX we get
Hγ+1(A) ⊆Hγ+1(σ + 1) ⊆Hˆα=
∥κ(κX). Therefore we have X, ˆα0 =∥κ ∈H⋆(κX)
which entails by Lemma 3.27 (C) that there is a component ηi of ⃗η such that
ηi /∈H⋆(κX). By hypothesis we have ⃗η ∈Hγ+1(A). Hence ηi < ˆα =∥κ. How-
ever, from ⃗η ∈dom(F) we get ηi ∈Par(Y) and therefore ηi ∈Hηi(κY) which
implies ηi ∈Hˆα=
∥κ(κX)∩Hηi(κY). Moreover we also have κX = Hˆα=
∥κ(κX)∩π =
Hˆα=
∥κ(κX) ∩κY. By Lemma 5.7 it therefore follows ηi ∈Hηi(κX). Contradiction.
Provably Recursive Functions of Reflection
441

2. If F = A we have π = Ξ ∈Hγ+1(A) and for X = K(σ) we have σ ∈Par(X) ⊆
Hγ+1(A) and, since the cardinal successor function is among the generating func-
tions of H, also π = σ+ ∈Hγ+1(A). So assume that F is a successor conﬁguration
Zδ0. Then Par(Z) ∪{δ0} ⊆Par(X) ⊆Hγ+1(A) and δ0 + 1 = o(X) = δ ≤γ + 1.
Hence i(X) = Ψδ0
Z ∈Hγ+1(A).
To prove the second claim in 2 we show by induction on n that π ≤κ ≤ρ ≤κ+
and ρ ∈Hn,γ+1(A) imply κ, κ+ ∈Hγ+1(A). The case n = 0 is excluded because
of σ < ρ and our tacitly assumed hypothesis κ+ ≤Ξ.
If ρ = f(ξ1, . . . , ξn) for a function f among the generating functions of H,
different from the cardinal successor function, and ξ1, . . . , ξn ∈Hn−1,γ+1(A) we
have π ≤κ ≤ξi ≤κ+ for a i = 1, . . . , n and obtain the claim by the induction
hypothesis and the closure of Hγ+1(A) under f.
If ρ = κ+ then κ ∈Hn−1,γ+1(A) ⊆Hγ+1(A) since κ /∈Par(A) and for ρ = κ
we get κ+ ∈Hγ+1(A) by closure under cardinal successor.
So assume that ρ = Ψβ
Y. Then ρ is either inaccessible, hence ρ = κ and we
have κ, κ+ ∈Hγ+1(A) by closure under cardinal successor, or κ < ρ < κ+. By
Lemma 3.14 we then get Y = K(κ), hence κ ∈Par(Y) ⊆Hγ+1(A) which again
also entails κ+ ∈Hγ+1(A).
3. Let π ≤µ ∈Hγ+1(A) ∩Reg. If µ = Ξ we choose Z := A(m + 1) and get
i(Z) = Ξ, o(Z) = ω ≤γ + 1 and Par(Z) = {m + 1} ⊆Hγ+1(A) because
1 = ϕ0(0) ∈H(∅) and H is closed under addition.
If µ is a successor cardinal κ+ we choose Z := K(κ) and obtain i(Z) = κ+ = µ,
o(Z) = 0 ≤δ + 1 and Par(Z) = {κ} ⊆Hγ+1(A) by 2.
Finally assume µ = Ψβ
Y for some reﬂection instance Y. Then Y, β ∈Hγ+1(A) ⊆
Hγ+1(σ + 1) and β ≤γ, since σ < π ≤µ, and Y is not an instance of K, since
µ ∈Reg. Choosing the successor conﬁguration Yβ we have i(Yβ) = Ψβ
Y and
o(Yβ) = β + 1 ≤γ + 1. We have Par(Yβ) = Par(Y) ∪{β} ⊆Hγ+1(A).
Let M<ρ
R – Pm := ⃗R(Ψβ
Y)rdh(Yα). If ρ = o(R) then dom(Yβ) = {ϵ} and we put
Z := Yβ(ϵ). If o(R) < ρ then dom(Yβ) = [o(R), ρ)↾H⋆(µ) × dom(R)↾H⋆(µ) and
there is an ⃗η ∈dom(R) such that R(⃗η ) ∈Prinst(Y) which entails ⃗η ∈Par(Y) ⊆
Hγ+1(A). Choosing Z := Yβ(o(R), ⃗η ) we also get Par(Z) = Par(Y) ∪{β} ⊆
Hγ+1(A).
□
To formulate the main theorem of this section we introduce the notations
µ :=

µ + 1
if µ ∈Reg
µ
otherwise,
(24)
Fπ := Par(F) \ {π} and ∆π := Par(∆) \ {π}
for a sentence F and a ﬁnite set ∆of sentences.
442
Wolfram Pohlers and Jan–Carl Stegert

5.9 Theorem (Reﬂection elimination) Let ∆be a ﬁnite set of Σπ
m+1–formulas and
µ a cardinal. Assume Hγ+1 α
µ ∆and let X be a reﬂection instance with rdh(X) =
m −1 such that σ := |∆π| < i(X) =: π ≤µ, o(X) =: δ ≤γ + 1 and γ, X, µ ∈
Hγ+1(∆π). Then we obtain
Hˆα=
∥κ+1 Ψ ˆ
α=
∥κ
X
·
∆π,κ
for all κ ∈σMˆα
X where ˆα := γ =∥ωα=
∥µ.
Proof
We show the theorem by main induction on µ with side induction on α and
start with a general observation.
From γ, X, µ ∈Hγ+1[∆π] and |∆π| < σ < π ≤µ we get by claim 2. in
Lemma 5.8 π ∈Hγ+1(∆π). Hence Hγ+1(∆) = Hγ+1[{π}](∆π) = Hγ+1(∆π).
Therefore we have
Hξ(Γ) = Hξ[{π}](Γπ) = Hξ(Γπ)
(i)
for all ξ ≥γ + 1 and Γ ⊇∆. We will often use this tacitly.
1. Assume that the last inference is according to a W–rule. Then there is a formula
F ∈W–type ∩∆and we have the premise
Hγ+1 α0
µ ∆, Γ
for a ﬁnite formula set Γ ⊆CS(F). Then Γ is again a set of Σπ
m+1–formula and
we have Par(Γ) ⊆Hγ+1(∆) and α0, α ∈Hγ+1(∆, Γ) = Hγ+1(∆π, Γπ). By the
side induction hypothesis we thus get
Hˆα0=
∥κ+1 Ψ ˆ
α0=
∥κ
X
·
∆π,κ, Γπ,κ
(ii)
for all κ ∈σΓMˆα0
X where σΓ := |∆π, Γπ|. For κ ∈σMˆα
X we get Par(Γπ,κ) ⊆
Hγ+1(∆π,κ) ∩π ⊆Hγ+1(σ + 1) ∩π ⊆Hˆα(κ) ∩π = κ, hence κ ∈σΓMˆα
X and
σΓMˆα
X ⊆σΓMˆα0
X by Lemma 5.8 claim 1, since α0 < α and α0, α ∈Hγ+1(∆π, Γπ)
⊆Hγ+1(∆π). Moreover Lemma 5.8 also shows
Ψˆα0=
∥κ
X
< Ψˆα=
∥κ
X
∈Hˆα=
∥κ+1(∆π ∪{κ}) ⊆Hˆα=
∥κ+1(∆π,κ).
Since Γπ,κ ∈CS(F π,κ) and Par(Γπ,κ) ⊆Hˆα=
∥κ+1(∆π,κ) we get the claim from
(ii) by an inference (W).
2. Assume that the last inference is according to the (V)–rule. Then there is a
formula F ∈V–type ∩∆and we have the premises
Hγ+1 αG
µ
∆, G
(iii)
for all G ∈CS(F). Then we have by side induction hypothesis
Provably Recursive Functions of Reflection
443

HˆαG=
∥κ+1[{π}]
Ψ
ˆ
αG=
∥κ
X
·
∆π,κ, Gπ,κ
(iv)
for all G ∈CS(F) and κ ∈σGMˆαG=
∥κ
X
with σG = |∆π, Gπ|. Let κ ∈σMˆα
X.
Clearly CS(F π,κ) ⊆CS(F) and for G ∈CS(F π,κ) we have Gπ,κ = G and
Par(G) ⊆κ. Therefore κ ∈σGMˆα
X for all G ∈CS(F π,κ). Since αG < α and
γ, X, αG, α ∈Hγ+1(∆π, G) and σG = |∆π, G| < π ≤µ we get by Lemma 5.8
claim 1. σGMˆα
X ⊆σGMˆαG
X
and ΨˆαG=
∥κ
X
< Ψˆα=
∥κ
X
. Since γ, α, X, κ ∈Hγ+1(∆π,κ)
entails Ψˆα=
∥κ
X
∈Hˆα=
∥κ+1(∆π,κ) we obtain the claim from (iv) by an inference (V).
3. Assume that the last inference is a cut with the premises
Hγ+1 α0
µ ∆, (¬)F
(v)
where rnk(F) < µ and Par(F) ⊆Hγ+1(∆).
3.1. If rnk(F) < π then F and ¬F are again Σπ
1–formulas and we can apply the
side induction hypothesis to obtain
Hˆα0=
∥κ+1 Ψ ˆ
α0=
∥κ
X
·
∆π,κ, (¬)F π,κ
(vi)
for all κ ∈σMˆα0
X . By Lemma 5.8 we again get σMˆα
X ⊆σMˆα0
X and Ψˆα0=
∥κ
X
<
Ψˆα=
∥κ
X
∈Hˆα=
∥κ+1(∆π ∪{κ}) ⊆Hˆα=
∥κ+1(∆π,κ). Moreover we have
Par(F π,κ) ⊆Hγ+1(∆) ∩π ⊆Hˆα(κ) ∩π = κ
for κ ∈σMˆα
X, hence also rnk(F π,κ) < Ψˆα=
∥κ
X
and obtain the claim from (vi) by
(cut).
3.2.
Let π ≤rnk(F) < µ. If rnk(F) = µ then µ is regular and we get by
claim 3 of Lemma 5.8 a reﬂection instance Z such that i(Z) = µ, o(Z) ≤γ + 1
and Z ∈Hγ+1(∆π). If rnk(F) < µ we let
µ0 := sup {µ′ ∈Card µ′ ≤rnk(F)}.
Then π ≤rnk(F) < µ+
0 ≤µ. If π < rnk(F) we put Z := K(µ0). Then i(Z) = µ+
0
and o(Z) = 0 < γ + 1. Since Par(F) ⊆Hγ+1(∆) we have µ+
0 ∈Hγ+1(∆) by
Lemma 5.8 claim 2. In case that π = rnk(F) we put Z := X. So in any case we
have a reﬂection instance Z with π ≤rnk(F) ≤i(Z) =: µ1 ≤µ, µ1 ∈Hγ+1(∆)
and o(Z) < γ +1. Without loss of generality we may assume that F is a pure Σµ1
1 –
formula, hence ¬F a pure Πµ1
1 –formula. Applying the side induction hypothesis to
(v) we thus obtain
Hˆα0=
∥λ+1 Ψ ˆ
α0=
∥λ
Z
·
∆µ1,λ, F µ1,λ
(vii)
444
Wolfram Pohlers and Jan–Carl Stegert

for all λ ∈
σ0Mˆα0
Z
for σ0 := |∆µ1, Fµ1|. Since ¬F is not necessarily a Σµ1
1 –
formula we cannot apply the induction hypothesis to ¬F directly. However, all
formulas G ∈CS(¬F) are Σµ1
1 –formulas and we may therefore ﬁrst apply inver-
sion to (v) and then the induction hypothesis to obtain
Hˆα0=
∥λ+1 Ψ ˆ
α0=
∥λ
Z
·
∆µ1,λ, Gµ1,λ
(viii)
for all G ∈CS(¬F) and λ ∈σGMˆα0
Z where σG = |∆µ1, Gµ1|. Let λ ∈σMˆα0
Z .
Since Par(Fµ1) ⊆Hγ+1(∆) ∩µ1 ⊆Hˆα0(λ) ∩µ1 = λ this implies λ ∈σ0Mˆα0
Z .
For G ∈CS(¬F µ1,λ) we get λ ∈σGMˆα0
Z by the same consideration. An inference
(V) applied to (viii) yields
Hˆα0=
∥λ+1 Ψ ˆ
α0=
∥λ
Z
+1
·
∆µ1,λ, ¬F µ1,λ
(ix)
for all λ ∈σMˆα0
Z . For λ ∈σMˆα0
Z we have Par(F µ1,λ) ⊆Hγ+1(∆∪{λ})∩µ1 ⊆
Hˆα0=
∥λ(σ + 1 ∪{λ})∩µ1 ⊆Hˆα0=
∥λ(Ψˆα0=
∥λ
Z
)∩µ1 = Ψˆα0=
∥λ
Z
. Hence rnk(F µ1,λ) <
Ψˆα0=
∥λ
Z
and we get from (vii) and (ix) by cut
Hˆα0=
∥λ+1 Ψ ˆ
α0=
∥λ
Z
+2
·
∆µ1,λ
(x)
for all λ ∈σMˆα0
Z .
If π = µ1 then Z = X and
Ψˆα0=
∥λ
X
< Ψˆα=
∥λ
X
∈Hˆα=
∥λ+1(∆∪{λ}) ⊆Hˆα=
∥λ+1(∆µ1,λ)
holds true for all λ ∈σMˆα
X and we get the claim from (x).
If π < µ1 then ∆µ1,λ = ∆for any λ, µ1 = µ+
0 ∈Hγ+1(∆) and Z = K(µ0).
Let λ0 := Ψˆα0=
∥σ
Z
and η := Ψˆα0=
∥λ0+1
Z
. Then we obtain (as in case 1 of Lemma 5.8)
that λ0 ∈σMˆα0
Z . From (x) we get by weakening
Hˆα0=
∥λ0+2 η
· ∆.
(xi)
It follows from Lemma 3.14 that µ0 < η < µ+
0 .
Applying predicative cut–
elimination to (xi) we obtain
Hˆα0=
∥λ0+2 ϕη(η)
µ0
∆
(xii)
Putting φ := ˆα0 =∥λ0 + 1 =∥ωϕη(η)=
∥µ0 we get from (xii)
Hφ=
∥κ+1 Ψφ=
∥κ
X
·
∆π,κ
(xiii)
for all κ ∈
σMφ
X by the main induction hypothesis. Let κ ∈
σMˆα
X. We have
φ ∈Hˆα0=
∥λ0+2(∆) because of ˆα0 =∥σ ∈Hγ+1(∆), λ0 ∈Hˆα0=
∥σ+1(∆), η ∈
Provably Recursive Functions of Reflection
445

Hˆα0=
∥λ0+2(∆) and µ+
0 ∈Hγ+1(∆). Moreover we have
φ = γ =∥ωα0=
∥µ =∥λ0 =∥ωϕη(η)=
∥µ0 + 1 < γ =∥ωα=
∥µ = ˆα
since α0 =∥µ < α =∥µ, λ0, η < µ+
0 ≤µ < α =∥µ, hence also ϕη(η) < µ+
0 <
α =∥µ. Therefore we have κ ∈σMφ
X and obtain
Ψφ=
∥κ
X
< Ψˆα=
∥κ
X
∈Hˆα=
∥κ+1(∆∪{κ}) ⊆Hˆα=
∥κ+1(∆π,κ)
and we get the claim from (xiii) by weakening.
4. Assume that the last inference is a main reﬂection rule with reﬂection point π.
Then there is a Ππ
n+2–formula F such that (∃zπ)[z |= F] ∈∆, a reﬂection instance
Z such that rdh(Z) = n −1, i(Z) = π and j(Z) = 0 and we have the premise
Hγ+1 α0
µ ∆, F
(xiv)
with Par(F) ⊆Hγ+1(∆).
4.1. Assume π = Ξ, then X = A(m) and Z = A(n). Let n′ := max{m, n} +
2. Then ∆, F ∈Σπ
n′+1 and, putting Y = A(n′), we get by the side induction
hypothesis
Hˆα0=
∥λ+1 Ψ ˆ
α0=
∥λ
Y
·
∆π,λ, F π.λ
(xv)
for all λ ∈σMˆα0
Y since still σ = |∆π, Fπ|. Let κ ∈Mˆα
X. We have σ < Ψˆα0=
∥σ
Y
∈
Mˆα0
Y . From Y, ˆα0, σ ∈Hγ+1(σ + 1) and ˆα0 =∥σ < ˆα we get σ < Ψˆα0=
∥σ
Y
∈
Hˆα(κ) ∩Ξ = κ, hence σMˆα0
Y ∩κ ̸= ∅. Let λ ∈σMˆα0
Y ∩κ. By (14) we have
•
0 Lλ ̸= ∅∧Tran(Lλ) ∧Vk
i=1(ai ∈Lλ)
(xvi)
where a1, . . . , ak are the terms in |F|π. From (xvi) and (xv) we obtain by (V) and
(W)–inferences
Hˆα0=
∥λ+1 Ψ ˆ
α0=
∥λ
Y
+ω
·
W∆π,λ, (∃zκ)[z |= F] .
(xvii)
By (15) and (16) we get for s ∈Tκ
•
0 Lλ ̸= s, V¬∆π,λ, W∆π,s .
(xviii)
Cutting (xvii) and (xviii) — we clearly have rnk(W∆π,λ) < Ψˆα0=
∥λ
Y
— we get
Hˆα0=
∥λ+1 Ψ ˆ
α0=
∥λ
Y
+ω+1
·
Lλ ̸= s, W∆π,s, (∃zκ)[z |= F]
(xix)
for all λ ∈σMˆα0
Y ∩κ. From (xix) we get by weakening and an (V)–inference
446
Wolfram Pohlers and Jan–Carl Stegert

Hˆα0=
∥κ+1 Ψ ˆ
α0=
∥κ
Y
·
s /∈σMˆα0
Y , s = ∅, ¬Tran(s), Wp
i=1[bi /∈s],
W∆π,s, (∃zκ)[z |= κ]
(xx)
for all s ∈Tκ where b1, . . . , bp are the terms in ∆∩Tπ. By W–importation and an
inference (V) we get
Hˆα0=
∥κ+1 Ψ ˆ
α0=
∥κ+ω
Y
·
(∀xκ)[x /∈σMˆα0
Y ∨x ̸|= V¬∆π,κ], (∃zκ)[z |= F] . (xxi)
Now V¬∆π,κ is a Πκ
n′+1–formula and by Tautology (i.e. (15)) we have
•
0
V¬∆π,κ, W∆π,κ .
Moreover we have σ < κ ∈Mˆα
X,
ˆα0 < ˆα, ˆα0 ∈H⋆(κ) and rdh(A(n′)) = n′ −1.
By Theorem 5.6 claim 1 there is a ( σMˆα0
A(n′)–Πκ
n′+1–Ref)–rule and we therefore
obtain
Hˆα0=
∥κ+1 Ψ ˆ
α0=
∥κ
Y
·
(∃xκ)[x ∈σMˆα0
Y ∧x |= V¬∆π,κ], W∆π,κ .
(xxii)
Cutting (xxii) and (xxi) — again rnk((∃xκ)[x ∈σMˆα0
Y ∧x |= V¬∆π,κ]) < Ψˆα=
∥κ
X
and Ψˆα0=
∥κ
Y
< Ψˆα=
∥κ
X
— we get the claim by weakening and W–exportation.
4.2.
Assume π < Ξ. If n < m then ∆, F is a set of Σπ
m+1–formulas and we
proceed as in Case 4.1, with Y replaced by X.
Let n ≥m > 0. Then ∆is still a set of Σπ
m+1–formulas and F a Ππ
n+2 formula.
Using W– and V–exportations we obtain derivations Hγ+1[F]
α0
µ ∆, Γi where Γi
is a set of pure Ππ
n+2–formulas (∀xπ)Gi,j(x) for ﬁnitely many j ∈I. Using again
V–inversion we get Hγ+1[F]
α0
µ ∆, {Gi,j(t) j ∈I} for all terms t ∈Tλ and
∆, {Gi,j(t) j ∈I} is a set of Σπ
n+1–formulas. Using the induction hypothesis we
arrive at Hˆα0=
∥λ+1[F]
Ψ ˆ
α0=
∥λ
Z
·
∆π,λ, {Gij(t) j ∈I} for all λ ∈σtMˆα0
X and t ∈Tλ
with σt := |∆π, Gi,j(t)π|. By ﬁnitely many (V)–inferences we get
Hˆα0=
∥λ+1[F]
Ψ ˆ
α0=
∥λ
Z
+l
·
∆π,λ, {(∀xλ)Gi,j(x) j ∈I}
(xxiii)
for some l < ω. By further (V) and (W)–inferences we ﬁnally obtain
Hˆα0=
∥λ+1 Ψ ˆ
α0=
∥λ
Z
+ω
·
∆π,λ, F π,λ
(xxiv)
for all λ ∈σMˆα0
Z . Now we are in the situation of (xv) of Case 4.1 with an addi-
tional summand ω. Since this summand is at the latest absorbed in step (xxi) we
may now proceed as in this case.
Provably Recursive Functions of Reflection
447

If m = n = 0 we are talking about Σ1–formulas and may thus shorten the pro-
cedure by applying upwards persistency to (xvii) in Case 4.1, which immediately
yields the claim.39
5. Assume that the last inference is a side reﬂection rule ( τMξ
M(⃗ν )–Ππ
n+2–Ref).
Then we have a reﬂection instance Z = F(ξ,⃗ν ) with rdh(Z) = n −1, τ < i(Z) =
π < Ξ and RS(Z) = Mξ
M(⃗ν ) and have the premise
Hγ+1 α0
µ ∆, F
(xxv)
for some Ππ
n+2–formula F and there is a formula (∃xπ)[x ∈τMξ
M(⃗ν ) ∧x |= F]
in ∆. If n < m we may again proceed as in Case 4.1. So assume m ≤n.
As in Case 4.2 we obtain by W–exportations and V–inversions, the side induction
hypothesis, V– and W–inferences
Hˆα0=
∥λ+1 Ψ ˆ
α0=
∥λ
Z
+l
·
∆π,λ, F π,λ
(xxvi)
for all λ ∈σMˆα0
Z and an l < ω. Let κ ∈σMˆα
X. As in Case 4.2 we get σMˆα0
Z ∩
κ ̸= ∅. By deﬁnition we have Mˆα0
Z
⊆Mξ
M(⃗ν ). For λ ∈
σMˆα0
Z
∩κ we get
τ ∈Hγ+1(∆) ∩π ⊆Hˆα0(σ + 1) ∩π ⊆Hˆα0(λ) ∩π = λ and obtain
◦Lλ ∈τMξ
M(⃗ν ) ∧Lλ ̸= ∅∧Vp
i=1(ai ∈Lλ)
(xxvii)
where a1, . . . , ap is the list of terms in F of stage < π. By (xxvi) and (xxvii) we
obtain
Hˆα0=
∥λ+1 Ψ ˆ
α0=
∥λ
Z
+ω
·
W∆π,λ, (∃xκ)[x ∈τMξ
M(⃗ν ) ∧x |= F]
(xxviii)
for all λ ∈
σMˆα0
Z
∩κ. If m = 0 then ∆π,λ contains only Σλ
1–formulas and,
choosing λ = Ψˆα0=
∥σ
Z
∈σMˆα
X ∩κ, we obtain the claim from (xxvii) and Ψˆα0=
∥λ
Z
<
Ψˆα=
∥κ
X
by upwards persistency and weakening.
So assume m > 0. Letting G := (∃xκ)[x ∈
τMξ
M(⃗ν ) ∧x |= F] we have
G ∈∆π,κ and obtain as in (xx) and (xxi) in Case 4.1 from (xxviii)
Hˆα0=
∥κ+1 Ψ ˆ
α0=
∥κ
Z
+ω
·
(∀xκ)[x /∈σMˆα0
Z ∨x ̸|= V¬∆π,κ], G .
(xxix)
By tautology we have
•
0
V¬∆π,κ, W∆π,κ .
(xxx)
39This is the reason why the ordinal analysis of Π2–reﬂection is so much simpler. There is no need
for reﬂection conﬁgurations and –instances.
448
Wolfram Pohlers and Jan–Carl Stegert

Again V¬∆π,κ is a Ππ
n+1–formula. By Lemma 5.8 we have Ψˆα0=
∥κ
Z
↓< Ψα=
∥κ
X
↓
and obtain ˆα0, ˆα ∈H⋆(κ) and Z = F(ξ,⃗ν ) ∈H⋆(κ) for κ ∈
σMˆα
X. Since
σ < π = i(Z), rdh(Z) = n −1 and ˆα0 < ˆα we obtain by Theorem 5.6 the
existence of a ( σMˆα0
F(ξ,⃗ν )–Πκ
n+1–Ref)–rule. Applying this rule to (xxx) yields
Hˆα=
∥κ+1 Ψ ˆ
α0=
∥κ
Z
·
(∃x ∈σMˆα0
Z )[x |= V¬∆π,κ], W∆π,κ
(xxxi)
and we obtain the claim by cutting (xxxi) and (xxix), W–exportation and weaken-
ing.
6. Assume that the last inference is a subsidiary reﬂection rule ( τMξ
M(⃗ν )–Ππ
k+2–Ref).
Then there is a reﬂection instance Z such that σ < i(Z) = π,
ξ ∈H⋆(π) and
M<ξ+1
M
– Pk ⪯⃗R(π)′
k. Hence k ≤rd(⃗R(π)) = rd(⃗R(i(X))) = rdh(X) + 1 = m
by Lemma 3.9. We have the premise
Hγ+1 α0
µ ∆, F
(xxxii)
for a Ππ
k+2–formula F and its main formula G := (∃xπ)[x ∈τMξ
M(⃗ν ) ∧x |= F]
belongs to ∆. Then we have ˆα0 < ˆα, ξ,⃗ν ∈Hγ+1(∆) and ⃗ν ∈dom(M)≥k. Since
k ≤m we have Γ, F ∈Ππ
m+2. Again we proceed as in Case 4.2 to conclude
Hˆα0=
∥κ+1 Ψ ˆ
α0=
∥κ
X
·
∆π,κ, F π,κ
(xxxiii)
By Lemma 3.7 claim 1 and claim 5 of Lemma 3.5 we have ξ,⃗ν < o(Z) = o(X) ≤
γ + 1. Moreover we have ξ,⃗ν ∈H⋆(π) and ξ,⃗ν ∈Hγ+1(σ + 1) ⊆Hγ+1(κ)
and Hγ+1(κ) ∩π = κ for all κ ∈Mˆα
X. Therefore we get by Lemma 5.7 ξ,⃗ν ∈
H⋆(κ) for all κ ∈
σMˆα
X. For κ ∈
σMˆα
X we also get τ ∈Hγ+1(∆) ∩π ⊆
Hˆα(κ) ∩π = κ, i.e., τ < κ. Theorem 5.6 claim 2 therefore show the existence of
a ( τMξ
M(⃗ν )–Πκ
k+2–Ref)–rule. Applying this rule to (xxxiii) yields the claim.
7. Assume that the last inference is a ( τMξ
M(⃗ν )–Ππ0
k+2–Ref)–rule which is either a
main, a side or a subsidiary reﬂection rule with reﬂection point π0 ∈(τ, π). Then
we have the premise
Hγ+1 α0
µ ∆, F
(xxxiv)
for a Ππ0
k+2–formula F. Because of π0 < π we have ∆, F ⊆Σπ
m+1 and the
induction hypothesis applied to (xxxiv) yields
Hˆα0=
∥κ Ψ ˆ
α0=
∥κ
X
·
∆π,κ, F π,κ
(xxxv)
for all κ ∈Mˆα0
X . By Lemma 5.8 we again have Mˆα
X ⊆Mˆα0
X and Ψˆα0
X < Ψˆα
X and
for κ ∈Mˆα
X we have π0 ∈Hγ+1(∆) ∩π ⊆Hˆα(κ) ∩π = κ, hence F π,κ = F.
Provably Recursive Functions of Reflection
449

Therefore we can apply a ( τMξ
M(⃗ν )–Ππ0
k+2–Ref)–rule to (xxxv) and obtain the claim
by weakening.
□
5.3
The ordinal analysis
Recall V, the minimal Veblen operator, i.e., the operator generated by +, the Veblen
function ϕ and the cardinal successor function, and put H = V[{0, Ξ}]. Moreover
let α0 := Ξ + ω and αn := ϕ0(αn) = ωαn. Then supn∈ω αn = ϕ1(Ξ + 1) =
εΞ+1.
Since K(ω) is the only reﬂection instance with i(K(ω)) = ω+ := Ωwe can
write Ψα
Ωinstead of (the more clumsy looking) Ψα
K(ω).
5.10 Theorem Let F be a Π2–sentence and assume that the theory Ref proves the
sentence (∀x)[Ad(x) →F x]. Then there is a k < ω such that for ˜α := ωαk=
∥Ξ we
have
H˜α=
∥Ψ ˜
α
Ω+1 Ψ
˜
α=
∥Ψ ˜
α
Ω+ω
Ω
·
F Ψ ˜
α
Ω.
Proof
By Theorem 4.8 we get
H
ωΞ+n
Ξ+m F Ω
for ﬁnite ordinals m and n if (∀x)[Ad(x) →F x] is provable in Ref (+Ad). By
predicative cut–elimination it follows
H
αm
Ξ+1 F Ω.
(i)
Since ω, Ξ ∈H(∅) we clearly have K(ω), ˜α ∈H⋆(Ψ˜α
Ω). Moreover we have
H˜α(Ψ˜α
Ω) ∩Ω= Ψ˜α
Ω, hence Ψ˜α
Ω∈M˜α
K(ω). W.l.o.g. assume that F is a pure
Π2–sentence (∀x)(∃y)G(x, y). Let a ∈TΨ ˜
α
Ω. Then (∃yΩ)G(a, y) is is ΣΩ
1 and
|(∃yΩ)G(a, y)Ω| < Ψ˜α
Ω. Therefore we can apply (V)–inversion and reﬂection
elimination (Theorem 5.9) to (i) and obtain
H˜α=
∥Ψ ˜
α
Ω+1 Ψ
˜
α=
∥Ψ ˜
α
Ω
Ω
·
(∃yΨ ˜
α
Ω)G(a, y) .
Since this holds for all a ∈TΨ ˜
α
Ωwe obtain
H˜α=
∥Ψ ˜
α
Ω+1 Ψ
˜
α=
∥Ψ ˜
α
Ω+1
Ω
·
(∀xΨ ˜
α
Ω)(∃yΨ ˜
α
Ω)G(x, y)
by an inference according to (V). In the case of a general Π2–sentence we need
ﬁnitely many V–inversions, possibly W–exportations, V–inferences and additional
W–importations which increase the derivation height below Ψ˜α=
∥Ψ ˜
α
Ω+ω
Ω
.
□
450
Wolfram Pohlers and Jan–Carl Stegert

5.11 Theorem Every ΠωCK
1
2
–sentence that is provable in Ref (+Ad) becomes true
at some stage below ΨεΞ+1
Ω
in the constructible hierarchy.
Proof
To simplify notations we may again restrict us to the case that F is a pure
Π2–sentence (∀x)(∃y)G(x, y) such that Ref (+Ad) proves
(∀z)[Ad(z) →(∀x ∈z)(∃y ∈z)G(x, y)].
According to Theorem 5.10 and Theorem 4.2 we then get LΨ ˜
α
Ω|= (∀x)(∃y)G(x, y)]
for ˜α = ωαk=
∥Ξ. Since ˜α < εΞ+1, Ψ˜α
Ω< Ω= i(K(ω)) and K(ω), ˜α ∈H⋆(Ψ˜ε Ξ+1
Ω
)
we have Ψ˜α
Ω< ΨεΞ+1
Ω
.
□
We see that the theory Ref again follows the familiar pattern, by which the Π1
1–
ordinal of an L–sound theory T is Ψ
ενT +1
Ω
where νT denotes the least stage in the
constructible hierarchy at which T has a model and ΨΩis a collapsing function that
collapses ordinals below ωCK
1 . The tricky part is in fact the deﬁnition of ΨΩ.
6
Characterization of the Π0
2–Skolem functions of
Πω–reﬂection
In the previous section we have given a Π1
1–ordinal analysis of reﬂection. In this
section we want to show that this analysis can be easily extended to a Π0
2–analysis.
6.1
The theory Ref∗
In a ﬁst step we have to clarify what we understand by a Π0
2–sentence. The ori-
gin of Π0
2 ordinal analysis comes from subsystems of second order number theory
containing symbols for all primitive recursive functions (either explicitly or as ex-
tensions by deﬁnitions). Since all primitive recursive functions are deﬁnable in Lω
the sentences that correspond to Π0
2–sentences in our setting are the Πω
2 –sentences.
Some care is needed in the deﬁnition of Lω in Ref. The obvious idea to deﬁne it
as the least admissible set, i.e., as the least transitive set that satisﬁes the axioms
of KP does not work. To obtain an embedding of ∆0-collection we would already
need a Skolem function. Fortunately we can alternatively characterize Lω as the
set of hereditarily ﬁnite sets. Therefore we introduce a new predicate Ad0 with the
deﬁning schemes
(Ado.1)
(∀x)[Ad0(x) →Tran(x)]
(Ado.2)
(∀x)[Ad0(x) →(Ext)x ∧(Nullset)x ∧(Pair)x ∧(Union)x ∧(∆0–Sep)x]
and a scheme that expresses that any x in Ad0 contains only ﬁnite elements. Put
Provably Recursive Functions of Reflection
451

Fin(y) :⇔(∃z)(∃f ∈z)(∃n ∈z)[Fct(f) ∧n ∈N ∧f: n
1−1
−→
onto y],
where n ∈N :⇔n ∈On ∧n /∈Lim ∧(∀y ∈n)[y /∈Lim].
The formula Fin(y) expresses that y is ﬁnite and we introduce the axiom
(Ado.3)
(∀x)[Ad0(x) →((∀y)Fin(y))x].
Therefore any a satisfying Ad0(a) is a set the elements of which are hereditarily
ﬁnite.
It is easy to prove that for any formula χ(x) (in the language of set theory) that
characterizes Lω the theory Ref∗(or even an extension–by–deﬁnitions of a weaker
theory ) proves
(∀x)[χ(x) ↔Ad0(x)].
(25)
By a Πω
2 –sentence we thus mean a sentence of the form (∀x)[Ad0(x) →F x]
for Π2–formulas F. The Πω
2 –sentences which correspond to the Π0
2–sentences in
subsystems of (second order) number theory are those which only contain ﬁnite
ordinals as parameters and whose quantiﬁers range only over ordinals.
To obtain a translation into the language of ramiﬁed set theory we extend f
Ad to
f
Ad0 and put
s ∈f
Ad0 b≡W
s = Lπ π ∈Reg ∪{ω}

.
Clearly there is no ﬁnite ordinal n such that F n holds true for all Πω
2 –sentences that
are provable in Ref. All we can expect is a dynamical bound given by a function
that takes the parameters of any instance of a Πω
2 –sentence as inputs and delivers
an upper bound for the ∃–quantiﬁer. In this section we are going to characterize
such functions as members of a subrecursive hierarchy.
In view of this dynamical process we have to alter the notion of a Skolem hull
operator into a dynamical operator. Such operators have been called “fragmented”
by Stegert in his dissertation [23].40
6.2
The subrecursive hierarchy
For the ordinals in the range of a Skolem hull operator there is a canonical norm
deﬁned below.
6.1 Deﬁnition The norm NH(A)(α) of an ordinal α ∈H(A) is its stage in the
inductive generation of H(A), i.e.,
NH(A)(α) := min {n α ∈Hn(A)}.
40Although the deﬁnition given here differs from that in [23].
452
Wolfram Pohlers and Jan–Carl Stegert

We have seen in the previous section that all the ordinals that are needed in a Π1
1–
analysis of Ref belong to VεΞ+1({0, Ξ}). In a Π0
2–analysis we can therefore restrict
ourselves to operators that operate on VΓΞ+1({0, Ξ}). Therefore it sufﬁces to deﬁne
norms for the ordinals in this set. We put
N(α) := NVΓΞ+1({0,Ξ})(α).
Observe that with this deﬁnition we get
N(α) =





0
if α ∈{0, Ξ}
max{N(α1), . . . , N(αn)} + 1
if α =NF α1 + . . . + αn
max{N(α1), N(α2)} + 1
if α =NF ϕα1(α2)
max {N(η), N(ξ) ξ ∈Par(X)} + 1
if α = Ψη
X < i(X).
This especially entails N(0) = N(Ξ) = 0, N(n) = n for ﬁnite ordinals n
and N(ω) = 2. Moreover we have N(α + n) ≤N(α) + n for ﬁnite n and
N(ωα1 =∥· · · =∥ωαn) ≤max {N(αi) i = 1, . . . , n} + n.
In the following part we will orient ourselves on Chapter 10 in [15]. Let Φ be
deﬁned by
Φ(0) = 1 and Φ(n + 1) = 2Φ(n).
Then Φ and Φ2 are primitive recursive.
6.2 Deﬁnition Let H be a Skolem hull operator (that is tacitly assumed to take
values in HΓΞ+1({0, Ξ}), we will not mention that any longer). In generalizing
Deﬁnition 10.3.1 in [15] we deﬁne for α ∈H(A) functions
ψH(A)(α) := sup {ψH(A)(β) + 1 β ∈H(A) ∩α ∧N(β) ≤Φ2(N(α))}∪{0}.
Since there are only ﬁnitely many ordinals in H(A)∩α the norm of which is below
Φ2(N(α)) we get ψH(A)(α) < ω.41
As shown in [15] Lemma 10.3.3 the functions ψH satisfy
ψH(A)(α + ψH(A)(β)) ≤ψH(A)(α =∥β).
(26)
By deﬁnition we get ψH(A)(n) = n and ψH(A)(ω) = Φ2(2) + 1, since N(ω) = 2.
More generally we have ψH(A)(ω + n) = Φ2(2+n)+1. As shown in [15] all prim-
itive recursive function are eventually majorized by the function λx.ψC(∅)(ωω +x)
and λx.ψC(∅)(ε0 + x) eventually majorizes the provably recursive functions of
Peano arithmetic.
If H1 and H2 are Skolem hull operators such that H1(A) ⊆H2(B) then we
obviously have ψH1(A)(α) ≤ψH2(B)(α).
Deﬁning
41The function Φ2 is primitive recursive and thus a suitable starting function in the sense of [15]. It
will become clear in Lemma 6.11 why we choose Φ2 as starting function.
Provably Recursive Functions of Reflection
453

α ≪β
:⇔α < β ∧N(α) ≤Φ2(N(β))
α ≪
−β
:⇔α ≪β ∨α = β
we obtain for α, β ∈H(A)
α ≪β
⇒ψH(A)(α) < ψH(A)(β)
α ≪
−β
⇒ψH(A)(α) ≤ψH(A)(β).
(27)
In [15] Chapter 10 we deﬁned functions Fα: ω −→ω by
Fα(x) = ψC(∅)(ω · α + x).
For the purpose of this paper we ﬁrst have to extend this to a family of functions
fH(A)
X,α
(x) := ψH(A)(Ψα
X + x),
(28)
where we tacitly assume Ψα
X↓.
If α ≪β and α, β ∈H⋆(i(X)) we obtain Ψα
X ≪Ψβ
X and thus by (26)
α+y ≪β+y ∧α, β ∈H⋆(i(X)) ∧H1 ⊆H2 ⇒fH1(A)
X,α
(x) < fH2(A)
X,β
(y). (29)
As another consequence of (26) we get
fH(A)
X,α
(fH(A)
X,β
(x)) ≤fH(A)
X,α=
∥β(x)
(30)
which holds since
fH(A)
X,α
(fH(A)
X,β
(x)) = ψH(A)(Ψα
X + ψH(A)(Ψβ
X + x))
≤ψH(A)(Ψα
X =∥Ψβ
X + x) ≤ψH(A)(Ψα=
∥β
X
+ x) = fH(A)
X,α=
∥β(x).
In a similar way we also have
fH(A)
X,α
((fH(A)
X,α
)k(x)) ≤fH(A)
X,α+1(x)
(31)
for k ≤x2, which follows since Ψα
X · k + x ≪Ψα+1
X
+ x.42
This entails that Φ2(fH(A)
X,α
(x)) < fH(A)
X,α
(fH(A)
X,α
(x)) ≤fH(A)
X,α+1(x) and thus
n < fH(A)
X,α
(x) ⇒4 · n2 < Φ2(fH(A)
X,α
(x)) ≤fH(A)
X,α+1(x).
(32)
Since N(α) < Φ2(N(α)) ≪Ψα
X for we obtain
N(α) < Φ2(N(α)) < ψH(A)(Ψα
X) ≤fH(A)
X,α
(x)
(33)
for any X, α ≥o(X), any H, any A and any ﬁnite ordinal x.
Another immediate consequence of the deﬁnition of fH(A)
X,α
(x) is
fH(A)
X,α
(x + y) = ψH(A)(Ψα
X + x + y) < ψH(A)(Ψ(α+x)
X
+ y) = fH(A)
X,α+x(y). (34)
42Claim (31) holds for all k such that N(α)+x+k ≤Φ2(N(α)+x+1), e.g., k ≤8 · (Φ2(x))2−x.
454
Wolfram Pohlers and Jan–Carl Stegert

6.3
Fragmented Skolem hull operators
For the Π1
1–ordinal analysis of Ref the ﬁnite parameters of a formula are inessen-
tial. The situation changes when we try to characterize the Skolem functions for
Π2
0–sentences that are provable in Ref. In the characterization of the Π0
2–Skolem
functions of Ref the control of the ﬁnite parameters in a derivation is essential.
Therefore we ﬁrst have to clarify what the ﬁnite parameters of a sentence are.
6.3 Deﬁnition For a term t and a formula F in the language of ramiﬁed set theory
we deﬁne its ﬁnite norm inductively by.
N(Lα) := 2 · N(α)
N({x ∈Lα F(x)}) := max{N(Lα) + 1, N(Fx(L0)) + 2}
N(f
Ad0) := 9
N(τMξ
X) = max {N(τ), N(ξ), N(ρ) ρ ∈Par(X)}
N(s ∈t) = N(s /∈t) := max{N(s) + 5, N(t) + 1}
N(A ∧B) = N(A ∨B) = max{N(A), N(B)} + 1
N((Qx ∈s)F(x)) = max{N(s), N(Fx(L0)) + 2}.
For a ﬁnite set A consisting of ordinals, terms and formulas we deﬁne
|A|N := max {A, N(φ) φ ∈A} + 1.
We also extend the ordinal parameters of a ﬁnite set of LRS–formulas by its ﬁnite
norm. We deﬁne
Par(∆) := Par(∆) ∪{|∆|N}.
(35)
The following claims are straight forward (though sometimes cumbersomely to
check) consequences of Deﬁnition 6.3.
6.4 Lemma Let φ be a term or a formula and F a formula and s a term of ramiﬁed
set theory. Then
1. N(stg(φ)) ≤N(rnk(φ)) ≤N(φ) < ω,
2. N(s) ≤N(Fx(s)) ≤N(Fx(L0)) + N(s),
3. For G ∈CS(F) we have N(G) < N(F) + N(ιF (G)) + 7.
6.5 Deﬁnition Let H be a Skolem hull operator and X a reﬂection instance. The
fragmentation FH
X,γ of a Skolem hull operator H is deﬁned by
Provably Recursive Functions of Reflection
455

FH
X,γ(A) := {α ∈H(A) N(α) < fH(A)
X,γ
(|A|N)}.
For a ﬁnite set Γ of formulas let
f
H[A]
X,γ (Γ) := fH[A](Par(Γ))
X,γ
(|A ∪Γ|N)
and deﬁne
FH
X,γ(Γ) := {α ∈H(A) N(α) < f
H
X,γ(Γ)}.
The following lemma is an extension of (31).
6.6 Lemma 1. Let ξ ≪
−η + k · f
H
X,γ+r(∆) for k < |∆|N and r < N(η). Then
f
H
X,γ=
∥ξ(∆) ≤f
H
X,γ=
∥η+1(∆), hence FH
X,γ=
∥ξ(∆) ⊆FH
X,γ=
∥η+1(∆) for any ﬁnite set ∆
of formulas.
2. Let ξ ≪
−η =∥(f
H
X,γ+r)k(∆) for k < |∆|N and r < N(η). Then f
H
X,γ=
∥ξ(∆) ≤
f
H
X,γ=
∥η+1(∆), hence FH
X,γ=
∥ξ(∆) ⊆FH
X,γ=
∥η+1(∆) for any ﬁnite set ∆of formulas.
Proof
By (29) and (26) we get from γ =∥ξ ≪
−γ =∥η + k · f
H
γ+1(∆)
f
H
X,γ=
∥ξ(∆) ≤f
H
X,γ=
∥η(k · f
H
X,γ+r(∆) + |∆|N)
= ψH(∆)(Ψγ=
∥η
X
+ k · f
H
X,γ+r(∆) + |∆|N)
= ψH(∆)(Ψγ=
∥η
X
+ k · (ψH(∆)(Ψγ+r
X
+ |∆|N)) + |∆|N)
≤ψH(∆)(Ψγ=
∥η
X
=∥Ψγ+r
X
· k + |∆|N · (k + 1))
≤ψH(∆)(Ψγ=
∥η+1
X
+ |∆|N) = f
H
X,γ=
∥η+1(∆)
since
N(Ψγ=
∥η
X
=∥Ψγ+r
X
· k + |∆N| · (k + 1))
≤N(Ψγ=
∥η
X
) + N(γ =∥η + 1) · |∆|N + (|∆|N)2
< Φ2(N(Ψγ=
∥η+1
X
) + |∆|N).
The proof of the second claim is similar. Here we compute
456
Wolfram Pohlers and Jan–Carl Stegert

f
H
X,γ=
∥ξ(∆) ≤f
H
X,γ=
∥η((f
H
X,γ+r)k(∆) + |∆|N)
= ψH(∆)(Ψγ=
∥η
X
+ (f
H
X,γ+r)k(∆) + |∆|N)
= ψH(∆)(Ψγ=
∥η
X
+ ψH(∆)(Ψγ+r
X
+ (f
H
X,γ+r)k−1(∆)) + |∆|N)
≤ψH(∆)(Ψγ=
∥η
X
=∥Ψγ+r
X
+ (f
H
X,γ+r)k−1(∆) + |∆|N) ≤· · ·
≤ψH(∆)(Ψγ=
∥η
X
=∥Ψγ+r
X
· k + 2|∆|N)
≤ψH(∆)(Ψγ=
∥η+1
X
+ |∆|N) = f
H
X,γ=
∥η+1(∆).
□
6.7 Deﬁnition A derivation
α
ρ ∆is controlled by a fragmented Skolem hull oper-
ator FH
X,γ — denoted by FH
X,γ
α
ρ ∆— if Ψγ
X↓, γ, α ∈FH
X,γ(∆) and in case of an
inference
αι
ρ ∆ι for ι ∈I
⇒
α
ρ ∆,
whose main formula is not universal, we moreover require that Par(∆ι) ⊆FH
X,γ(∆)
hold true for all ι ∈I.
The main difference between Skolem hull operators and their fragmentations is that
they loose their idempotency. Therefore the (Hull) rule (as in Section 5.1) does not
hold for fragmented controlled derivations. Nevertheless, most of the derived rules
of Section 5.1 remain valid with the slight modiﬁcations listed below.
A special role is played by the fragmented operator FH
K(ω),α. Therefore we in-
troduce the abbreviations
f
H
α (x) := f
H
K(ω),α(x) and FH
α := FH
K(ω),α.
Recall that we write Ψα
Ωinstead of Ψα
K(ω). First we check that tautologies are also
fragmented controlled derivable. We prove
(TAUT)
FH
0
2·rnk(F )
0
∆, ¬F, F
for any H, any ∆and any F by induction on rnk(F). This is the standard proof
augmented by the argument that we have 2 · N(rnk(F)) < Φ2(N(rnk(F))) <
f
H
0 (F) and thus certainly N(2 · rnk(F)) < f
H
0 (∆, ¬F, F).
(Weakening)
If FH1
X,γ
α
ρ ∆, α ≤β, ρ ≤σ, ∆⊆Γ, H1 ⊆H2, and β ∈FH2
X,γ(Γ)
then FH2
X,γ
β
σ Γ holds true, too.
(Extension)
If FH1
X,γ
α
ρ ∆, ∆⊆Γ, H1 ⊆H2 and f
H1
X,γ(∆) ≤f
H2
X,δ(Γ) then
FH2
X,δ
α
ρ Γ .
Provably Recursive Functions of Reflection
457

(V–inversion)
If FH
X,γ
α
ρ ∆, F and F ∈V–type then FH
X,γ[F]
α
ρ ∆, G holds
true for all G ∈CS(F).
( ∨–exportation)
If FH
X,γ
α
ρ ∆, Wn
i=1Fi then also FH
X,γ+1
α
ρ ∆, F1, . . . , Fn .
( ∧–exportation)
If FH
X,γ
α
ρ ∆, Vn
i=1Fi then also FH
X,γ+1
α
ρ ∆, F1, . . . , Fn .
(upwards persistency) If FH
X,γ
α
ρ ∆, (∃xσ)F(x) for rnk((∃xσ)F(x)) < ρ and
σ < τ for additively indecomposable ordinals σ and τ then
FH
γ+1[{σ}]
α+σ+1
ρ
∆, (∃xτ)F(x) .
(downwards persistency) If FH
X,γ
α
ρ ∆, (∀xτ)F(x) for rnk((∀xτ)F(x)) < ρ and
σ < τ for additively indecomposable ordinals σ and τ then
FH
γ+1[{τ}]
α+τ+1
ρ
∆, (∀xσ)F(x) .
All the proofs, except persistency, are straightforward by induction on α. The
reason for the raise to γ + 1 in the exportations is that k := |∆, Wn
i=1Fi|N may be-
come N(Wn
i=1Fi)+1 which might be m+n for m := max {N(Fi) i = 1, . . . , n}
while |∆, F1, . . . , Fn|N is only m + 1. But then n ≤m and we get k ≤2 · m ≤
Φ2(m + 1). Using (30) we are on the safe side by raising γ to γ + 1.
For persistency we copy the proof of Section 5.1 and use (32) to secure that
N(α) < f
H
X,γ(∆, (∃xσ)F(x)) and N(σ) + 1 < f
H[{σ}]
X,γ
(∆, (∃xτ)F(x)) entail
N(α + σ + 1) < f
H[{σ}]
X,γ+1 (∆, (∃xτ)F(x)).
6.4
Embedding of Ref∗
To obtain an embedding of Ref∗we follow Section 4.3. We extend the auxil-
iary calculus
◦∆in Deﬁnition 4.4 by augmenting the parameter condition in
the clauses (V◦) by N(G) ≤Φ2(|Λ|N) if F is not universal and in (W◦) by
|Γ|N ≤Φ2(|Λ|N). For notational convenience we extend the deﬁnition of
•
0 ∆to
•
0 ∆
:⇔FH
0
drnk(∆)
0
∆for all Skolem hull operators extending J .
Now we show
◦Λ
⇒
•
0 Λ
(36)
by induction on the deﬁnition of
◦Λ . First we observe that drnk(Λ) ∈H(Λ)
holds obviously for every Veblen closed operator H. Since N(drnk(Λ)) ≤2 ·
|Λ|N < f
H
0 (Λ) we always have drnk(Λ) ∈FH
0 (Λ).
458
Wolfram Pohlers and Jan–Carl Stegert

If the last inference was an inference according to (V)◦we have the premises
◦∆, G for all G ∈CS(F) and ∆, F ⊆Λ, viewed as multisets. Deﬁning α0 :=
drnk(∆, G) we get α0 < drnk(Λ) =: α and obtain FH
0
α0
0
∆, G by the induction
hypothesis. By an inference (V) we then obtain FH
0
α
0 Λ , i.e.,
•
0 Λ .
Now let the last inference be according to (W)◦. Then we have the premise
◦∆, Γ for a ﬁnite set Γ ⊆CS(F) and ∆, F ⊆Λ viewed as a multiset. Deﬁning
α0 := drnk(∆, Γ) we have the induction hypothesis FH
0
α0
0
∆, Γ . Moreover we
have Par(Γ) ⊆H(Λ) and |Γ|N ≤Φ2(|Λ|N) ≤f
H
0 (Λ). Hence Par(Γ) ⊆FH
0 (Λ).
Again α0 < ˜α := drnk(∆, F) ≤drnk(Λ) =: α and we obtain the claim by (W)–
inferences.
□
It is easy to check that all the properties of the
◦∆calculus as shown in Sections
11.10 and 11.12 of [15] remain valid also with the additional constraints.43 The
fact that we get
◦∆, s ̸= t, ¬F(s), F(t) sufﬁces for the embedding of ﬁrst order
logic. We thus obtain
6.8 Lemma If F(v1, . . . , vn) is a logically valid ﬁrst order formula in the language
of set theory then there is ﬁnite ordinal n such that FH
0
ωω·α+n
ω·α+n F(a1, . . . , an)α
holds true for all ordinals α and all terms a1, . . . , an ∈Tα.
Moreover we also have
◦Tran(Lλ) ∧(Ext)λ ∧(Nullset)λ ∧(Pair)λ ∧(Union)λ ∧(∆0–Sep)λ (37)
for every limit ordinal λ which, letting λ := ω, also yields
FH
0
ω Ξ+m
Ξ
(Ado.1)Ξ and FH
0
ω Ξ+m
Ξ
(Ado.2)Ξ
(38)
for some ﬁnite ordinal m. Completely analogous to (23) we also get a ﬁnite m such
that
FH
0
ω Ξ+m
0
(REF)Ξ .
(39)
In order to obtain also a translation of the axiom (Ado.3) we have to show that the
restricted inﬁnitary system proves ((∀y)Fin(y))ω. Here we need to show that the
inﬁnitary system is strong enough to prove all ∆0–sentences that are true in Lω.
To see this we exploit the fact that the constructible hierarchy L and the von
Neumann V hierarchy coincide up to ω. We use this to deﬁne a set ˜Tω of canonical
terms.
43A bit care is needed in the proof of Lemma 11.12.6 (the derivability of ∆0–separation). Here we
have to secure that in the passage from (vi) to (vii) in the proof of 11.12.6 we have N(b) < Φ2(N(G)+
1) for b = {x ∈Lβ x ∈a ∧F(x,⃗a)} and G the formula in (vii). But this is clear since for β :=
max{St(a), St(⃗a)} we get N(β) ≤max{N(a), N(⃗a)} and thus N(b) < Φ2(N(G) + 1) since a
and ⃗a occur in G.
Provably Recursive Functions of Reflection
459

6.9 Deﬁnition Let ˜T0 := ∅and let D( ˜Tn) consist of all terms that have the form
{x ∈Ln x = t1 ∨· · · ∨x = tk} with ti ∈˜Tn and k ≤Φ(n). Then deﬁne
˜Tn+1 := D( ˜Tn) ∪{Ln}
and
˜Tω := S
n∈ω ˜Tn.
For the ﬁnite norm of a term t = {x ∈Ln x = t1 ∨· · · ∨x = tk} we obtain
N(t) ≤max {2n + 1, 8, N(ti) + k + 4 i = 1, . . . , k} and thus by induction on n
t ∈˜Tn
⇒N(t) < Φ(n + 1).
(40)
By induction on n we also get for every constructible set s ∈Ln a canonical term
˜s ∈˜Tn such that L |= s = ˜s. This is trivial for n = 0 and for s ∈Ln+1 there are
sets s1, . . . , sk ∈Ln such that s = {s1, . . . , sk} and k ≤Φ(n) since Ln < Φ(n).
By induction hypothesis there are terms ˜s1, . . . , ˜sk ∈˜Tn such that L |= si = ˜si
for i = 1, . . . , k, hence {˜s1, . . . , ˜sk} ∈˜Tn+1 and L |= s = ˜s. From (40) we then
obtain that N(s) < Φ(|s|L + 1).
The extended Lω–diagram consists of all ∆0–sentences F the parameters of
which belong all to Lω such that Lω |= F.
6.10 Lemma For every sentence F in the extended Lω–diagram there is an equiv-
alent sentence F ′ such that
◦F ′ .
Proof
Let Lω |= F(s1, . . . , sn). We put F ′
:⇔
F(˜s1, . . . , ˜sn). By the above
remark we have Lω |= F(˜s1, . . . , ˜sn) ↔F ′. A straight forward induction on
rnk(F ′), using (40), then shows
◦F(˜s1, . . . , ˜sn) .
□
6.11 Lemma It holds
◦((∀y)Fin(y))ω .
Proof
Let a ∈Lω. Then there is a n > 0 such that a ∈Ln. Since Ln = Φ(n −1)
we obtain a function f: a
1−1
−→
onto a ∈LΦ(n)+4 . We also have a ∈LΦ(n) and obtain
{f, a} ∈LΦ(n)+5. For every a ∈Ln there is therefore a canonical b ∈˜TΦ(n)+5
such that
L |= (∃f ∈b)(∃m ∈b)[Fct(f) ∧m ∈N ∧f: m
1−1
−→
onto a].
Call this formula G(a, b). Then Fin(a) ⇔(∃z)G(a, z). By Lemma 6.10 we have
◦G(a, b) .
(i)
It is N(G(a, b)) = max{N(a), N(b)} + k for a ﬁnite constant k that is essentially
the number of logical symbols occurring in G(a, b). We have b ∈˜TΦ(n)+6 and thus
460
Wolfram Pohlers and Jan–Carl Stegert

N(b) < Φ(Φ(n)+6) ≤Φ(Φ(n+3)) by (40). Since n ≤N(a) we also have Φ(n+
3) ≤Φ(N((∃zω)G(a, z))) and k < N((∃zω)G(a, z)). Hence N(G(a, b)) =
N(b) + k ≤Φ(Φ(n + 3)) + k ≤Φ2(N((∃zω)G(a, z)) + 1) = Φ2(|Fin(a)ω|N).
We can therefore apply an inference (W)◦to (i) to obtain
◦Fin(a)ω .
(ii)
Since this holds true for all a ∈Tω we ﬁnally have
◦(∀yω)Fin(y)ω .
□
Since we also have
◦s ̸= Lω, ¬((∀y)Fin(y))ω, ((∀y)Fin(y))s for all terms s ∈TΞ
we obtain by (36) together with Lemma 6.11
FH
0
ωΞ+m
Ξ
(∀xΞ)[x /∈f
Ad0 ∨((∀y)Fin(y))x] , i.e., FH
0
ωΞ+m
Ξ
(Ado.3)Ξ . (41)
To obtain the embedding of Ref∗we still need to show that the foundation scheme
is derivable. However, an inspection of the proof of Theorem 11.12.8 in [15] shows
that we get
•
0 (Found)α
(42)
for all ordinals α.
Collecting (37), (39), Lemma 6.8, Lemma 6.11 and (42) we obtain
6.12 Theorem If the theory Ref∗proves a sentences F then there are ﬁnite ordi-
nals m and n such that FH
0
ω Ξ+m
Ξ+n
F Ξ holds true for the canonical translation of
F.
6.5
Predicative cut–elimination
Because of the strengthened constraints for fragmented controlled derivations we
have to check also predicative cut elimination. Already the reduction lemma needs
some extra care.
6.13 Lemma Assume FH
X,γ
α
ρ ∆, F and FH
X,γ
β
ρ Γ, ¬F for a formula F ∈V–type
such that rnk(F) = ρ /∈Reg and Par(F) ⊆FH
γ (∆) then FH
X,γ+1
α+β
ρ
∆, Γ .
Proof
We ﬁrst check that α + β ∈FH
X,γ+1(∆, Γ). We have α ∈H(∆, F) ⊆
H(∆, Γ) and β ∈H(Γ, ¬F) ⊆H(∆, Γ) since Par(F) ⊆H(∆). Moreover we
have N(α) < f
H
X,γ(∆, F) ≤f
H
X,γ+1(∆, Γ) since |F|N < f
H
X,γ(∆). Similarly we
get N(β) < f
H
X,γ+1(∆, Γ). Hence N(α + β) < f
H
X,γ+1(∆, Γ).
We prove the lemma by induction on β. Assume ﬁrst that the last inference is
(J)
FH
X,γ
βι
ρ Γι, ¬F
for ι ∈I
⇒FH
X,γ
β
ρ Γ, ¬F
Provably Recursive Functions of Reflection
461

the main–formula of which is different from ¬F. If (J) is not an (V)–inference
whose main formula is universal we moreover have Par(Γι) ⊆FH
X,γ(Γ, ¬F). Since
βι < β we obtain by the induction hypothesis
FH
X,γ+1
α+βι
ρ
∆, Γι .
(i)
In case that the main formula is not universal we get from Par(F) ⊆FH
X,γ(∆) also
Par(Γι) ⊆FH
X,γ+1(Γ, ∆). Therefore we get FH
X,γ+1
α+β
ρ
∆, Γ by an inference (J).
If ¬F is the main formula of the last inference we have the premise
FH
X,γ
β0
ρ Γ, ¬F, ¬G
(ii)
for some G ∈CS(F) and Par(G) ⊆FH
X,γ(Γ, F). By induction hypothesis we thus
have
FH
X,γ+1
α+β0
ρ
∆, Γ, ¬G .
(iii)
By inversion we get from the ﬁrst hypothesis
FH
X,γ
α
ρ ∆, G
(iv)
Since α + β0 < α + β, Par(G) ⊆FH
X,γ+1(∆, Γ) and γ ≪γ + 1 we obtain the
claim by a cut.
□
As a consequence of the reduction lemma we obtain for ρ /∈Reg and γ ≥1
FH
X,γ
α
ρ Γ
⇒FH
X,γ=
∥ωα+1
ωα
ρ
Γ .
(43)
We prove (43) by induction on α. If the last inference is
(J)
FH
X,γ
αι
ρ Γι for ι ∈I
⇒FH
X,γ
α
ρ Γ
we have the induction hypothesis FH
X,γ=
∥ωαι+1
ωαι
ρ
Γι together with Par(Γι) ⊆
FH
X,γ(Γ) ⊆FH
X,γ=
∥ωα+1(Γ) in case that its main formula is not universal.
By
αι ∈FH
X,γ(∆ι) we have N(αι) < f
H
X,γ(Γι). Since N(ωαι + 1) = N(αι) + 2 <
f
H
X,γ(Γι) + 2 ≤f
H
X,γ+1(Γι) we have ωαι + 1 ≪ωα + f
H
X,γ+1(Γι). By Lemma 6.6
we thus obtain f
H
X,γ=
∥ωαι+1(Γι) ≤f
H
X,γ=
∥ωα+1(Γι), hence FH
X,γ=
∥ωα+1
ωαι
ρ
Γι for all
ι ∈I. If (J) is not a cut of rank ρ we obtain the claim by an application of (J).
If the last inference was a cut of rank ρ we have FH
X,γ=
∥ωα0+1
ωα0
ρ
∆, (¬)F by
induction hypothesis. Applying the reduction lemma we obtain
FH
X,γ=
∥ωα0+2
ωα0·2
ρ
∆.
(i)
462
Wolfram Pohlers and Jan–Carl Stegert

Now we have N(ωα0 + 2) = N(α0) + 3 < f
H
X,γ(∆, F) + 4 ≤f
H
X,γ+1(∆). Hence
ωα0 + 2 ≪ωα + f
H
X,γ+1(∆).
By Lemma 6.6 this entails f
H
X,γ=
∥ωα0+2(∆) <
f
H
X,γ=
∥ωα+1(∆). Therefore we obtain the claim from (i) by extension and weak-
ening.
□
Claim (43) is the ﬁrst step in extending the predicative elimination theorem to frag-
mented controlled derivations.
6.14 Theorem If FH
X,γ
α
β+ωρ ∆for ρ ∈FH
X,γ(∆) and [β, β + ωρ) ∩Reg = ∅then
FH
X,γ=
∥ϕρ(α)+1
ϕρ(α)
β
∆.
Proof
The proof is by induction on ρ with side–induction on α. The case ρ = 0
is (43). So assume ρ > 0. Let the last inference be
(J)
FH
X,γ
αι
ρ ∆ι for ι ∈I
⇒FH
X,γ
α
ρ ∆.
By the side–induction hypothesis we then have
FH
X,γ=
∥ϕρ(αι)+1
ϕρ(αι)
β
∆ι for all ι ∈I.
(i)
Since N(ϕρ(αι) + 1) ≤max{N(αι), N(ρ)} + 2 < f
H
X,γ(∆ι) + 2 ≤f
H
X,γ+1(∆ι)
we obtain by Lemma 6.6 f
H
X,γ=
∥ϕρ(αι)+1(∆ι) < f
H
X,γ=
∥ϕρ(α)+1(∆ι). If (J) is not a
cut of degree ≥β we obtain the claim from (i) by an application of (J).
So assume that (J) is a cut with cut–formula F such that β ≤rnk(F) < β +
ωρ. Then σ := rnk(F) =NF β + ωσ1 + · · · ωσk, hence σ < β + ωσ1 · k +
ωσ1 and Par(F) ⊆FH
X,γ(∆) implies σ1 ∈FH
X,γ(∆) and k < |F|N < f
H
X,γ(∆).
Since f
H
X,γ=
∥ϕρ(α0)+1(∆, F) < f
H
X,γ=
∥ϕρ(α0)+2(∆) and Par(F) ⊆FH
X,γ(∆, F) ⊆
FH
X,γ+1(∆) ⊆FH
X,γ=
∥ϕρ(α0)+2(∆) we obtain from (i) by cut
FH
X,γ=
∥ϕρ(α0)+2
ϕρ(α0)+1
β+ωσ1·(k+1) ∆
(ii)
Now let β0 := γ =∥ϕρ(α0) + 2 and βm+1 := βm =∥ϕm
σ1(ϕρ(α0) + 1) + 1 where
ϕ0
σ(µ) := µ and ϕm+1
σ
(µ) := ϕσ(ϕm
σ (µ)). Since σ1 < ρ we get by k + 1–fold
application of the main induction hypothesis
FH
X,βk+1
ϕk+1
σ1 (ϕρ(α0)+1)
β
∆.
(iii)
Clearly ϕk+1
σ1 (ϕρ(α0) + 1) < ϕρ(α) and βk+1 < γ =∥ϕρ(α). We get
N(ϕm+1
σ1
(ϕρ(α0) + 1)) ≤max{N(σ1), N(ρ), N(α0)} + m + 3
for m ≤κ + 1 and
Provably Recursive Functions of Reflection
463

N(βm) ≤max{N(σ1), N(ρ), N(α0), N(γ)} + 4 + 2m ≤f
H
X,γ+1(∆),
since σ1 ∈FH
X,γ(∆), m < |F|N < f
H
X,γ(∆) and α0 ∈FH
X,γ(∆, F) ⊆FH
X,γ+1(∆).
Hence βm ≪ϕρ(α) + f
H
X,γ+1(∆), which implies f
H
X,βm(∆) ≤f
H
X,γ=
∥ϕρ(α)+1(∆)
by Lemma 6.6. Setting m := k + 1 we obtain the claim from (iii) by extension and
weakening.
□
6.6
Reﬂection elimination for fragmented controlled deriva-
tions
This section repeats Section 5.2 for fragmented controlled derivations. We will not
redo all the proofs but restrict ourselves to emphasize the changes that are needed
to adapt the proofs given there to fragmented controlled derivations. Again we ﬁx
a Skolem hull operator H that extends the Veblen operator V[{0, Ξ}]. Let A be a
ﬁnite set consisting of ordinals, terms and formulas. We write
N γ
X (A) for FHγ
X,γ(A) and hγ
X(A) for f
Hγ
X,γ(A)
Since Hγ ⊆Hα for γ ≤α we get from Lemma 6.6
β ≪
−α+k · hγ+r
X
(A) for k<|A|N, r<N(α) ⇒N γ=
∥β
X
(A) ⊆N γ=
∥α+1
X
(A). (44)
The ﬁrst lemma we have to adapt is Lemma 5.8.
6.15 Lemma Let X be a reﬂection instance of a reﬂection conﬁguration F and put
δ := o(F). Let γ be an ordinal and µ a cardinal such that γ, X, µ ∈N γ+1
X
(A),
ω, δ ≤γ + 1 and σ := |A| < π := i(X) ≤µ. Deﬁne ˆα := γ =∥ωα=
∥µ. Then we
obtain:
1. If α0, α ∈N γ+1
X
(A), α0 < α and j < f
H
X,γ+r(A, κ) for 0 < r < N(α) then
∅̸= Mˆα
X ⊆Mα0
X and N ˆα0=
∥κ+j+1
X
(A, κ) ⊆N ˆα=
∥κ+1
X
(A, κ). For any κ ∈σMˆα
X
and any reﬂection instance Y = F(⃗η ) with ⃗η ∈dom(F) ∩N γ+1
X
(A) we have
Ψˆα0=
∥κ
Y
↓< Ψˆα=
∥κ
X
↓+j ∈N ˆα=
∥κ+1
X
(A, κ).
2. It is π ∈N γ+2
X
(A) and for all κ ∈Card for which there is a ρ ∈N γ+1
X
(A)
satisfying π ≤κ ≤ρ ≤κ+ we get κ, κ+ ∈N γ+2
X
(A).
3. For π ≤µ ∈N γ+1
X
(A) ∩Reg there exists a reﬂection instance Z such that
i(Z) = µ, o(Z) ≤γ + 1 and Z ∈N γ+2
X
(A).
Proof
We have all the hypotheses of Lemma 5.8, thus also all its consequences
and we follow the proof given there and show only the additional claims.
464
Wolfram Pohlers and Jan–Carl Stegert

1. From j < f
H
X,γ+r(A, κ)) and N(α0) < hγ+1
X
(A) we get ωα0=
∥µ =∥κ + j + 1 ≪
ωα=
∥µ =∥κ + 2 · hγ+r
X
(A, κ), hence
N γ=
∥ωα0=
∥µ=
∥κ+j+1
X
(A) ⊆N γ=
∥ωα=
∥µ=
∥κ+1
X
(A, κ) = N ˆα=
∥κ
X
(A, κ).
by (44) since 2 ≤{A, κ} < |A, κ|N. To show the second claim we observe
N(Ψˆα=
∥κ
X
) ≤max {N(γ), N(α), N(µ), N(κ), N(ξ) ξ ∈Par(X)} + 4
≤hγ+1
X
(A, κ) + 4 ≤hγ+2
X
(A) ≤hˆα=
∥κ+1
X
(A, κ),
hence Ψˆα=
∥κ
X
∈N ˆα=
∥κ+1
X
(A, κ). Moreover we have N(Ψˆα=
∥κ
X
+ j) ≤N(Ψˆα=
∥κ
X
) +
j ≤hγ+1
X
(A, κ) + hγ+1
X
(A, κ) ≤hγ+2
X
(A, κ) ≤hˆα=
∥κ+1
X
(A, κ), hence Ψˆα=
∥κ
X
∈
N ˆα=
∥κ+1
X
(A, κ).
2. If F = A we trivially have Ξ ∈N γ+2
X
(A) and if F = K we have σ ∈Par(X) ⊆
N γ+1
X
(A), hence N(π) = N(σ)+1 ≤N γ+2
X
(A). If π = Ψδ0
X we obtain Par(X)∪
{δ0} ⊆N γ+1
X
(A), hence π ∈N γ+2
X
(A). For the second claim we easily modify
the induction in the proof to obtain κ ∈N γ+1
X
(A). This then implies κ, κ+ ∈
N γ+2
X
(A).
3. Following the proof of Lemma 5.8 we choose for π = Ξ an m ≤hγ+1
X
(A) and
obtain Z ∈N γ+1
X
(A). If µ = κ+ we have Par(Z) = {κ} ⊆N γ+2
X
(A) by 2. For
µ = Ψβ
Y we put Z := Yβ(ϵ) or Z := Y(o(R), ⃗η ) and obtain N(ξ) ≤hγ+1
X
(A) for
ξ ∈Par(Z). Hence Z ∈N γ+2
X
(A).
□
6.16 Theorem (Reﬂection elimination for fragmented controlled derivations) Let
∆be a ﬁnite set of Σπ
m+1–formulas and µ a cardinal. Assume N γ+1
X
α
µ ∆for a
reﬂection instance X with rdh(X) = m −1 such that σ := |∆π| < i(X) =: π ≤µ,
o(X) =: δ ≤γ + 1 and γ, X, µ ∈N γ+1
X
(∆). Then we obtain
N ˆα=
∥κ+1
X
Ψ ˆ
α=
∥κ
X
·
∆π,κ
for all κ ∈σMˆα
X where ˆα := γ =∥ωα=
∥µ.
Proof
Here again we follow the proof of Theorem 5.9 and show only the addi-
tional claims. In the cases 1. through 3.1. we only have to replace H by NX and
apply Lemma 6.15 claim 1. instead of Lemma 5.8 claim 1.
The ﬁrst case that needs a more serious modiﬁcation is 3.2. Here we obtain
µ1 ∈N γ+2
X
(∆) and thus
N ˆα0=
∥λ+2
X
Ψ ˆ
α0=
∥λ
Z
·
∆µ1,π, F µ1,π
(i)
instead of (vi). Then (viii) turns into
Provably Recursive Functions of Reflection
465

N ˆα0=
∥λ+2
X
Ψ ˆ
α0=
∥λ
Z
+1
·
∆µ1,λ, F µ1,λ .
(ii)
Again we get rnk(F µ1,λ) < Ψˆα0=
∥λ
Z
and
Par(F µ1,λ) ⊆N γ+1
X
(∆∪{λ}) ⊆N ˆα0=
∥λ+2
X
(∆µ1,λ)
and thus by cut
N ˆα0=
∥λ+2
X
Ψ ˆ
α0=
∥λ
Z
+2
·
∆µ1,λ .
(iii)
If µ1 = π we get the claim by Lemma 6.15 claim 1, extension and weakening.
If π < µ1 we obtain η ∈N ˆα0=
∥λ0+2
X
(∆) and thus
N ˆα0=
∥λ0+2
X
η
· ∆.
(iv)
Applying predicative cut–elimination we thus obtain
N ˆα0=
∥λ0=
∥ϕη(η)+3
X
ϕη(η)
µ0
∆.
(v)
Now we deﬁne φ′ := ˆα0 =∥λ0 =∥ϕη(η) =∥ωϕη(η)=
∥µ0 + 3 and obtain
N φ′=
∥κ+1
X
Ψφ′=
∥κ
X
·
∆π,κ
(vi)
by the main induction hypothesis. We clearly have
φ′ ≪ˆα + N(η) + N(α0),
hence
N φ′=
∥κ+1
X
(∆π,κ) ⊆N ˆα=
∥κ+N(η)+N(α0)
X
(∆π,κ)
(vii)
It is λ0 = Ψˆα0=
∥σ
Z
and η := Ψˆα0=
∥λ0+1
Z
. Since all components of η are in N γ+1
X
(∆)
we have N(η) < hγ+2
X
(∆). Since also N(α0) < hγ+1
X
(∆) we get by (44)
N ˆα=
∥κ+N(η)+N(α0)
X
(∆π,κ) ⊆N ˆα=
∥κ+1
X
(∆π,κ)
(viii)
and obtain the claim from (vi), (vii) and (viii) by extension and weakening.
In the case 4.1 we obtain
N ˆα0=
∥λ+1
X
Ψ ˆ
α0=
∥λ
Y
·
∆π,λ, F π.λ
(ix)
instead of (xv), which leads to
N ˆα0=
∥λ+1
X
Ψ ˆ
α0=
∥λ
Y
+1
·
Lλ ̸= s, · · · ..
(x)
instead of (xvix). Since λ belongs to the parameters of Lλ ̸= s, . . . we can modify
this to
466
Wolfram Pohlers and Jan–Carl Stegert

N ˆα0=
∥κ+1
X
Ψ ˆ
α0=
∥λ
Y
+ω+1
·
Lλ ̸= s, W∆π,s, (∃zκ)[z |= F] .
(xi)
By weakening and and a (V) rule and the fact that Ψˆα0=
∥κ+1
Y
≤Ψˆα=
∥κ
X
we thus
obtain
N ˆα=
∥κ
X
Ψ ˆ
α0=
∥κ
Y
·
s /∈σMˆα0
Y · · ·
(xii)
Since α0 is among the parameters of the derived formulas in (xxi) and (xxii) we
use the same argument to replace (xxi) and (xxii) by
N ˆα=
∥κ
X
Ψ ˆ
α0=
∥κ+ω
Y
·
(∀xκ)[x /∈σMˆα0
Y ∨· · ·
and
N ˆα=
∥κ
X
Ψ ˆ
α0=
∥κ+ω
Y
·
(∃xκ)[x ∈σMˆα0
Y ∨· · · ,
respectively. Then N ˆα=
∥κ+1
X
Ψ ˆ
α=
∥κ
X
·
∆π,κ follows by cut and W–exportation.
In case 4.2 we have the additional difﬁculty that we need W and V–exportations
before we can apply the induction hypothesis. So we start with
N γ+n
X
[F]
α0
·
∆, {Gi,j(t) j ∈I}
for some n < |F|N and I < |F|N. Since l in (xxiii) is less or equal to I we obtain
instead of (xxiv)
N ˆα0=
∥λ+ω
X
Ψ ˆ
α0=
∥λ
Z
+ω
·
∆π,κ, F π,κ .
Because of N ˆα0=
∥λ+ω
X
(∆π,κ) ⊆N ˆα=
∥λ
X
(∆π,κ) we then can proceed as in the case
4.1.
No further going modiﬁcations are needed in the remaining case. So we obtain
them in a similar way.
□
6.7
The characterization theorem
6.17 Lemma (Detachment Lemma) Let Γ be a ﬁnite set of formulas F such that
¬F is in the extended Lω–diagram. Then FH
X,γ
α
0 ∆, Γ implies FH
X,γ=
∥ωα+1[Γ]
α
0 ∆
Proof
Induction on α. Assume ﬁrst that the main–formula of the last inference
(J)
FH
X,γ
αι
0 ∆ι, Γ for ι ∈I
⇒FH
X,γ
α
0 ∆, Γ
belongs to ∆.
If the main formula is not universal we also have Par(∆ι) ⊆
FH
X,γ(∆, Γ) ⊆FH
X,γ=
∥ωα+1[Γ](∆). By induction hypothesis we then get
Provably Recursive Functions of Reflection
467

FH
X,γ=
∥ωαι+1[Γ]
αι
0 ∆ι
Since ωαι+1 << ωα + N(αι) ≪ωα + f
H
X,γ(∆ι)we have FH
X,γ=
∥ωαι+1[Γ](∆ι) ⊆
FH
X,γ=
∥ωα+1[Γ](∆ι), hence FH
X,γ=
∥ωα+1[Γ]
αι
0 ∆ι , by Lemma 6.6 and obtain
FH
X,γ=
∥ωα+1[Γ]
α
0 ∆
with an inference (J).
If the main formula F of the last inference is in Γ we have the premises
FH
X,γ
αι
0 ∆, Γ, Γι
for Γι ⊆CS(F). If F ∈W–type all the formulas in Γι are false. If F ∈V–type
then Γι = {Gι} and there is a ι ∈I such that Gι is false. In both cases we get
FH
X,γ=
∥ωαι+1[Γ, Γι]
αι
0 ∆, hence FH
X,γ=
∥ωα+1[Γ, Γι]
αι
0 ∆,
(i)
by induction hypothesis and Lemma 6.6. If F is not universal we have Par(Γι) ⊆
FH
X,γ(∆) and thus obtain FH
X,γ=
∥ωα+1[Γ, Γι](∆) ⊆FH
X,γ=
∥ωα+1[Γ](∆). If F is a
universal formula (∀x ∈s)G(x) then St(s) =: n is ﬁnite. Then Γι = {G(t)} for
some term t ∈Tn. According to Deﬁnition 6.9 there is a term ˜t ∈˜Tn such that G(t)
and G(˜t) are equivalent and N(˜t) < Φ(n) < Φ(|F|N). Hence |Γι|N < Φ2(|Γ|N)
which entails FH
X,γ=
∥ωα+1[Γ, Γι](∆) ⊆FH
X,γ=
∥ωα+1[Γ](∆) and we get the claim
from (i).
□
6.18 Theorem (Witnessing Theorem) Assume that FH
X,γ
α
0 (∃xω)F(x) holds true
for a Σω
1 –sentence (∃xω)F(x). Then there is a t ∈Lm such that Lω |= F(t) and
m < f
H
X,γ=
∥ωα+1((∃xω)F(x)).
Proof
We induct on α. The only possibly premise is FH
X,γ
α0
0
(∃xω)F(x), F(s)
where we have Par(F(s)) ⊆FH
X,γ((∃xω)F(x)). If F(s) is true we have St(s) <
f
H
X,γ((∃xω)F(x)) ≤f
H
X,γ=
∥ωα+1((∃xω)F(x)) and s is a witness for t. Otherwise we
get by the detachment lemma FH
X,γ=
∥ωα0+1[F(s)]
α0
0
(∃xω)F(x) . By the induction
hypothesis there is a term t ∈Lm with m < f
H
X,γ=
∥ωα0+1[F(s)]((∃xω)F(x)) <
f
H
X,γ=
∥ωα0+1+1((∃xω)F(x)) such that F(t) is true. Now we have
ωα0+1 ≪ωα + N(α0) ≪
−ωα + f
H
X,γ((∃xω)F(x))
and obtain by Lemma 6.6 f
H
X,γ=
∥ωα0+1+1((∃xω)F(x)) ≤f
H
X,γ=
∥ωα+1((∃xω)F(x)).
□
For the following theorems we ﬁx H as the Skolem–hull operator V[{0, Ξ}]. In-
stead of N γ
K(ω)(A) we write N γ
Ω(A). Instead of hγ
K(ω)(A) we write hγ
Ω(A).
468
Wolfram Pohlers and Jan–Carl Stegert

6.19 Theorem (First Characterization Theorem) Assume that the theory Ref proves
a Πω
2 –sentence (∀⃗xω)(∃y ω)F(⃗x, y). Then for every tuple ⃗s ∈Lω there is a set t in
Lm and an ordinal α < εΞ+1 such that L |= F(⃗s, t) and m < hα
Ω((∃xω)F(⃗s, x)).
Proof
If χ(x) is a formula deﬁning Lω we have, according to (25), that Ref∗
proves (∀x)[χ(x) ↔Ad0(x)]. So we assume that Ref∗proves
(∀z)[Ad0(z) →(∀xz)(∃yz)F(⃗x, y)].
By Theorem 6.12, inversion and W–exportation we thus obtain
N 0
Ω
ω Ξ+m
Ξ+n
¬Ad0(Lω), (∀⃗xω)(∃y ω)F(⃗x, y)
(i)
Since we have
◦Lω = Lω we also get
◦Ad0(Lω) and thus obtain from (i) by cut
and iterated application of (43), inversion, extension and weakening
N β
Ω
β
Ξ+1 (∃y ω)F(⃗s, x)
(ii)
for an ordinal β < εΞ+1. Put ˆβ := β+ωβ=
∥Ξ+1 then ˆβ < εΞ+1. Since Ψ
ˆβ
Ω∈M
ˆβ
Ω
we obtain by applying reﬂection elimination (Theorem 6.16)
N δ+1
Ω
Ψδ
Ω
·
(∃y ω)F(⃗s, x)
(iii)
for δ := ˆβ =∥Ψ
ˆβ
Ω< εΞ+1. Finally deﬁning ρ := ϕΨδ
Ω(Ψδ
Ω) < εΞ+1 we get
N δ=
∥ρ+2
Ω
ρ
0 (∃y ω)F(⃗s, x)
(iv)
by predicative cut elimination. Since δ =∥ρ+2 =∥ωρ+1 < εΞ+1 we obtain the claim
by the Witnessing Theorem.
□
Recall the functions Fα(x) := ψH(ω · α+x) from [15].44 It has been shown there
that all primitive recursive functions are eventually majorized by Fωω, the provably
recursive functions of Peano arithmetic are eventually majorized by Fε0 and that
the subrecursive hierarchy Fα (at least for ordinals below Γ0) corresponds to the
Hardy hierarchy.
Reformulating the First Characterization Theorem we therefore obtain
6.20 Corollary Assume that Ref proves a Πω
2 –sentence (∀⃗xω)(∃y ω)F(⃗x, y). Then
for every tuple ⃗s ∈Lω there is a set t in Lm and an ordinal α < εΞ+1 such that
L |= F(⃗s, t) and m < FΨα
Ω((∃xω)F(⃗s, x)).
To obtain the characterization of the provably recursive functions of Ref we call a
Πω
2 –sentence of the form (∀αω)(∃βω)F((∀, )β) — where we use the convention
44In fact it would have been wiser to deﬁne Fα(x) = ψH(ωα + x).
Provably Recursive Functions of Reflection
469

that lower case Greek letters range over ordinals — a Π0
2–sentence. The following
theorem then follows directly from Corollary 6.20.
6.21 Theorem (Second Characterization Theorem) Assume that the theory Ref
proves a Π0
2–sentence (∀αω)(∃β ω)F(α, β). Then the function fF : ω −→ω de-
ﬁned by fF (x) := min {y L |= F(x, y)} is eventually majorized by a function Fα
for α < Ψε Ξ+1
Ω
= |Ref|Π1
1.
Summing up we have the following theorem.
6.22 Theorem The provably recursive functions of Ref are contained in the prim-
itive recursive closure of the subrecursive hierarchy {Fα α < Ψε Ξ+1
Ω
}.
6.23 Remark The conjecture is of course that the provably recursive functions
of Ref are exactly the primitive recursive closure of the subrecursive hierarchy
{Fα α < Ψε Ξ+1
Ω
}.
What is still lacking is the well–ordering proof for Ψε Ξ+1
Ω
within Ref.
References
[1] H. BACHMANN, Die Normalfunktionen und das Problem der ausgezeich-
neten Folgen von Ordnungszahlen, Vierteljahresschrift der naturforschen-
den Gesellschaft in Z¨urich, vol. 95 (1950), pp. 5–37.
[2]
, Transﬁnite Zahlen, Ergebnisse der Mathematik und ihrer Grenzgebi-
ete, vol. 1, Springer-Verlag, Berlin, 1955.
[3] B. BLANKERTZ, Beweistheoretischen Techniken zur Bestimmung von
Π0
2–Skolem Funktionen, Dissertation, Westf¨alische Wilhelms-Universit¨at,
M¨unster, 1997.
[4] B. BLANKERTZ AND A. WEIERMANN, How to characterize provably total
functions by the Buchholz operator method, Lecture Notes in Logic, vol. 6,
Springer-Verlag, Heidelberg/New York, 1996.
[5] J. BRIDGE, A simpliﬁcation of the Bachmann method for generating large
countable ordinals, Journal of Symbolic Logic, vol. 40 (1975), pp. 171–185.
[6] W. BUCHHOLZ, Normalfunktionen und konstruktive Systeme von Ordi-
nalzahlen, |= ISILC Proof Theory Symposium (J. Diller and G. H. M¨uller,
editors), Lecture Notes in Mathematics, vol. 500, Springer-Verlag, Heidel-
berg/New York, 1975, pp. 4–25.
470
Wolfram Pohlers and Jan–Carl Stegert

[7]
, A simpliﬁed version of local predicativity, Proof theory (P. Aczel et al.,
editors), Cambridge University Press, Cambridge, 1992, pp. 115–147.
[8] W. BUCHHOLZ, E. A. CICHON AND A. WEIERMANN, A uniform approach
to fundamental sequences and hierarchies, Mathematical Logic Quarterly,
vol. 40 (1994), pp. 273–286.
[9] F. R. DRAKE, Set Theory: An introduction to large cardinals, Studies in
Logic and the Foundations of Mathematics, vol. 76, North-Holland Publishing
Company, Amsterdam, 1974.
[10] C. DUCHHARDT, Thinning operators and Π4–reﬂection, Ph.D. Thesis,
Westf¨alische Wilhelms-Universit¨at, M¨unster, 2008.
[11] S. FEFERMAN, Hereditarily replete functionals over the ordinals, Intuition-
ism and proof theory (A. Kino et al., editors), Studies in Logic and the
Foundations of Mathematics, North-Holland Publishing Company, Amster-
dam, 1970, pp. 289–301.
[12] D. HILBERT, Die Grundlagen der Mathematik. Vortrag gehalten auf Ein-
ladung des Mathematischen Seminars im Juli 1927 in Hamburg, Hamburger
Mathematische Einzelschriften, vol. 5. Heft (1928), pp. 1–21.
[13] A. KANAMORI, The higher inﬁnite, Perspectives in Mathematical Logic,
Springer-Verlag, Berlin, Heidelberg, New York, 1994.
[14] W. POHLERS, Proof-theoretical analysis of IDν by the method of local pred-
icativity, Iterated inductive deﬁnitions and subsystems of analysis: Re-
cent proof-theoretical studies (W. Buchholz et al., editors), Lecture Notes
in Mathematics, vol. 897, Springer-Verlag, Heidelberg/New York, 1981,
pp. 261–357.
[15]
, Proof theory. The ﬁrst step into impredicativity, Universitext,
Springer-Verlag, Berlin/Heidelberg/New York, 2009.
[16] M. RATHJEN, Ordinal notations based on a weakly Mahlo cardinal, Archive
for Mathematical Logic, vol. 29 (1990), pp. 249–263.
[17]
, Eine Ordinalzahlanalyse der Π3-Reﬂexion, Habilitationsschrift,
Westf¨alische Wilhelms-Universit¨at, M¨unster, 1992.
[18]
, How to develop proof-theoretic ordinal functions on the basis of admis-
sible ordinals, Mathematical Logic Quarterly, vol. 39 (1993), pp. 47–54.
Provably Recursive Functions of Reflection
471

[19]
, Proof theory of reﬂection, Annals of Pure and Applied Logic, vol. 68
(1994), pp. 181–224.
[20]
, An ordinal analyis of parameter free Π1
2-comprehension, Archive for
Mathematical Logic, vol. 48/3 (2005), pp. 263–362.
[21]
, An ordinal analyis of stability, Archive for Mathematical Logic,
vol. 48/2 (2005), pp. 1–62.
[22] W. H. RICHTER AND P. ACZEL, Inductive deﬁnitions and reﬂecting prop-
erties of admissible ordinals, Generalized recursion theory I (J. E. Fenstad
and P. G. Hinman, editors), Studies in Logic and the Foundations of Math-
ematics, vol. 79, North-Holland Publishing Company, Amsterdam, 1974,
pp. 301–381.
[23] J.-C. STEGERT, Ordinal proof theory of Kripke–Platek set theory
augmented by strong reﬂection principles, Ph.D. Thesis, Westf¨alische
Wilhelms-Universit¨at, M¨unster, 2011.
[24] A. WEIERMANN, How to characterize provably total functions by local pred-
icativity, Journal of Symbolic Logic, vol. 61 (1996), pp. 52–69.
[25]
, Classifying the provable recursive functions of PA, Bulletin of Sym-
bolic Logic, vol. 12 (2006), pp. 177–190.
472
Wolfram Pohlers and Jan–Carl Stegert

Index
Notations
F α, 386
(∀xα), (∃xα), 386
Qxα, 389
Ω, 391
C, Cantorian closed operator, 392
V, Veblen closed operator, 392
H[A], 393
Hα, 395
α ∈H⋆(A), 395
α ∈M↾H⋆(A), 395
X ∈H⋆(κ), 395
i(X), 395
RS(X), 395
j(X), 395
rdh(X), 395
o(X), 395
Par(F), 396
reﬂection expression M<α
F – Pm, 396
κ |= M<α
F – Pm, 396
reﬂection string ⃗R , 396
rd(⃗R ) := r1, 396
RE(⃗R ) := R1, 396
od(⃗R ) := ρ1, 396
⃗Rri, 397
⃗R<ri, 397
⃗R>ri, 397
A beginning reﬂection conﬁguration,
397
K beginning reﬂection conﬁguration,
397
Xα successor reﬂection conﬁguration,
398
Mα
X, 398
Ψα
X, 398
⃗R(Ψα
X), 398
eM
<α
F – Pm, 398
Prcnf(X), 399
Prcnf(F), 399
Prcnf(F), 399
Prinst(X), 399
Prinst(X), 399
ranα
X, 400
⃗ν < β, ⃗ν ≤β, M < β, M ≤β,
401
⃗R(F) for reﬂection conﬁgurations F,
404
M α,X
π
, 404
Ψα
X↓, 411
TC(M<α
M – Pm), transitive closure, 418
M<α
F – Pm ⪯M<β
G – Pm, 418
⃗R ′, derivative of a reﬂection string,
419
Tα, 430
W–type, 430
V–type, 430
CS(F), characteristic sequence, 430
t ∈s, t /∈s, 431
α ∆, 431
α
ρ ∆, 432
H
α
ρ ∆, 433
H(∆), H[∆], H[F, G, . . .], 433
J , 433
drnk(F), 433
◦∆,
•
0 ∆, 434
Ad, 435
σMξ
X, 437
H1 ⊆H2, 437
∆π,κ, 438
dom(F)≥n, 439
|A|, 441
µ, 442
Fπ, ∆π, 442
Ad0, 451
Provably Recursive Functions of Reflection
473

N(α), 452
ψH(A)(α), 453
α ≪β, 454
Fα, 454
fH(A)
X,α
(x), 454
Par(∆), 455
f
H[A]
X,γ (Γ), 456
FH
X,γ
α
ρ ∆, 457
f
H
α (x) := f
H
K(ω),α(x), 457
FH
α := FH
K(ω),α, 457
FH
X,α, f
H
X,α(x), 457
◦∆fragmented, 458
•
0 ∆fragmented, 458
hγ
X(A), N γ
X (∆), 464
474
Wolfram Pohlers and Jan–Carl Stegert

A Hierarchy of Ramiﬁed Theories
Below PRA
Elliott J. Spoors and Stanley S. Wainer
For Helmut Schwichtenberg on becoming emeritus -
with much friendship and respect.
A two-sorted arithmetic EA(I;O) of elementary recursive strength, based on
the Bellantoni-Cook variable separation, is ﬁrst enriched by addition of quan-
tiﬁers over “input” or “normal” variables, and then extended in two diﬀerent
ways to a hierarchy of theories whose provably computable functions coincide
with the levels of the Grzegorczyk hierarchy.
1
Introduction
The theory EA(I;O) of Ostrin–Wainer [9],[10] (see also [15]) is a stripped-down
version of the ramiﬁed intrinsic theories of Leivant [8], designed to incorporate
the “normal/safe” variable discipline of Bellantoni–Cook [4] in a two-sorted ana-
logue of Peano arithmetic, but with a weaker, “pointwise” or “predicative” induc-
tion scheme:
A(0) ∧∀a(A(a) →A(a + 1)) →A(x)
where a is a safe variable and x is normal. We prefer to call them “output” vari-
ables and “input” variables respectively; hence the I;O notation. Input variables are
not (at this stage) quantiﬁed, so they act as uninterpreted constants. The usual proof
theoretic methods apply just as for PA (e.g. embedding and cut elimination in an in-
ﬁnitary arithmetic with ω-rule). But now, because the inductions are only “up to x”,
the natural bounding functions are supplied by the “slow growing” hierarchy rather
than the “fast growing” one. Since the slow growing functions below ε0 are the
exponential polynomials, and those below ωω are just polynomials, it follows (as
Leivant had already previously shown, but by diﬀerent methods) that the provably
computable functions of EA(I;O) are the elementary functions (Grzegorczyk’s E3)
and those provably computable in its Σ1-inductive fragment are the sub-elementary

476
Elliott J. Spoors and Stanley S. Wainer
E2 functions, i.e. those Turing–machine computable in linear space. (By shift-
ing to a binary, rather than our unary, representation of numbers, one sees that the
Σ1-inductive fragment then characterizes polytime.)
Though quite simple in its formulation, EA(I;O) is not very “user friendly”, as
it does not permit quantiﬁcation over inputs x, y, z, and therefore one cannot even
show straightforwardly that the provably computable functions – as functions on in-
puts – are closed under composition. Of course it is true, and Wirz [16] supplies a
variety of delicate proof theoretic analyses enabling the derivation of such results,
but they also serve to highlight the awkwardness of the logic of EA(I;O). Here,
we rectify this by extending the theory conservatively to a new theory EA(I;O)+
which allows quantiﬁcation over inputs and incorporates also a certain “Σ1 Reﬂec-
tion Rule”. The induction however, continues to apply only to formulas of the base
theory EA(I;O). One then sees that EA(I;O)+ forms just the ﬁrst level of a ramiﬁed
hierarchy of input/output theories, whose provably computable functions coincide,
level-by-level, with the Grzegorczyk hierarchy. A diﬀerent approach to extending
EA(I;O) was taken by the ﬁrst author in his thesis [14], where the reﬂection rule
and the quantiﬁer rules on inputs were replaced by an “internalized” version of
the ω–rule restricted to Σ1 formulas. This “Σ1 Closure Rule” allows one to derive
∀aA(a) from a proof of A(x), and is a perfectly natural device given that in EA(I;O)
inputs x act as uninterpreted constants. Thus EA(I;O)+Σ1-Closure has the same
computational strength as IΣ1. This too is described in the ﬁnal section.
Many diﬀerent approaches to predicative induction and recursion have been de-
veloped over the last twenty years, inspired by the normal/safe variable separation
of Bellantoni and Cook. Our aim has been to formulate theories (and obtain proof-
theoretic analyses) by close analogy with classical arithmetic and classical proof-
theoretic methods. The Σ1 reﬂection rule gives an alternative view on Bellantoni’s
[2] “raising” rule, which was taken up again as (RW1) in Cantini [7]. Bellantoni
and Niggl [5] ramiﬁed primitive recursions by a delicate assignment of ranks in
order to characterize the Grzegorczyk classes above “sub-elementary”, and Bellan-
toni [3] already developed a corresponding notion of proof-rank for subtheories of
Σ1-induction. Later, Schwichtenberg and Bellantoni [12] gave a feasible arithmetic
of higher type functionals whose provable functions are exactly the polytime ones
(see also chapter 8 in Schwichtenberg and Wainer [13]).
2
Input-Output Arithmetic EA(I;O)
EA(I;O) has the language of arithmetic, with quantiﬁed “output” (or “safe”) vari-
ables a, b, c, . . . and unquantiﬁed “input” (or “normal”) variables x, y, z, . . .. For
convenience other terms and deﬁning axioms are added, for a pairing function

A Hierarchy of Ramified Theories Below PRA
477
π(a, b) (:= 1/2(a + b)(a + b + 1) + a + 1) with inverses π0, π1, from which sequence
numbers can be constructed using π(s, a) to append a to s, and deconstructed by
functions (s)i extracting the i-th component.
All of these initial functions are
quadratically bounded. The induction axioms are:
A(0) ∧∀a(A(a) →A(a + 1)) →A(t)
where t = t(⃗x) is a term on inputs only, controlling induction-length. Note that if
A(a) is progressive then so is ∀b ≤a.A(b) ≡∀b(b ≤a →A(b)), and so a more
revealing instance of induction is
A(0) ∧∀a(A(a) →A(a + 1)) →∀b ≤t.A(b) .
In other words, EA(I;O) is, in a sense, a theory of bounded induction, the (im-
plicit) bounds being terms t(⃗x) dependent on inputs ⃗x which cannot be universally
quantiﬁed and then later re-instantiated, as they can be in PA. Call this “input” or
“predicative” induction. Note however that there is no restriction on the formula A.
Deﬁnition 1. A numerical function f : Nk →N is “provably computable” or
“provably recursive” in EA(I;O) if there is a Σ1 formula C f (⃗x, a) (i.e. a bounded
formula preﬁxed by unbounded existential quantiﬁers) such that f(⃗n) = m if and
only if C f (⃗n, m) is true, and EA(I;O) ⊢∃!aC f (⃗x, a), i.e. f is provably total on inputs.
We shall occasionally use the shorthand f(⃗x)↓for the formula ∃aC f (⃗x, a).
Theorem 2. [Leivant, Ostrin-Wainer] The provably computable functions of
EA(I;O) are exactly the Csillag-Kalmar elementary functions.
By carefully restricting the witnessing terms in the existential introduction rule
and in induction, to the so-called “basic” ones (i.e. those built out of unary term
constructors only: successor, predecessor, πi) one may also characterize the sub-
elementary functions as those provably computable in the Σ1 inductive fragment.
Then increasing induction complexity in EA(I;O) characterizes the successive lev-
els of the Ritchie-Schwichtenberg hierarchy between sub-elementary and elemen-
tary. See [10].
3
Enriching EA(I;O) to EA(I;O)+
One sees immediately the deﬁciencies in the logic of EA(I;O) if one tries to show,
simply and directly, that the provably computable functions are closed under com-
position. For suppose one has proved that f(x)↓and g(x)↓, i.e. ∃aCg(x, a). Then
one needs ﬁrst to reﬂect the value a of g(x) as an input – the guiding principle here,

478
Elliott J. Spoors and Stanley S. Wainer
is that values a computable from inputs only may themselves be used as inputs.
Thus one obtains ∃yCg(x, y) and by generalizing over inputs, ∀y(f(y)↓). By logic,
∃yCg(x, y), ∀y(f(y)↓) ⊢∃a, b(Cg(x, b) ∧C f (b, a))
so by two cuts one immediately derives ∃a, b(Cg(x, b) ∧C f (b, a)) which is the de-
sired ∃aC f◦g(x, a).
We therefore now extend EA(I;O) to the new theory EA(I;O)+ by adding Input-
quantiﬁer rules (in Tait style):
Γ, A(t)
Γ, ∃xA(x)
Γ, A(y)
Γ, ∀xA(x)
(provided t contains only input variables and y is not free in Γ) and also the Σ1
Reﬂection rule:
Γ(⃗x), ∃⃗aA(⃗x,⃗a)
Γ(⃗x), ∃⃗yA(⃗x,⃗y)
where Γ(⃗x), ∃⃗aA(⃗x,⃗a) is a set of Σ1 formulas all of whose free variables are inputs.
The induction in EA(I;O)+ is the same as that of EA(I;O), it only applies to
formulas without input quantiﬁers.
Our ﬁrst task is to show that this extension of EA(I;O) is conservative, in that
no new provably recursive functions are produced.
An alternative, simpler way of directly proving closure under composition is
provided by the “Closure Rule”: from f(x) ↓derive ∀b(f(b) ↓). The proof of
∃a, b(Cg(x, b) ∧C f (b, a)) from ∃bCg(x, b) then follows in the same way as above,
but without any further apparatus needed. As we shall later show, adding the Σ1
Closure rule to EA(I;O) produces a version of primitive recursive arithmetic.
4
The Inﬁnitary System EA(I;O)+
∞
Upper bounds on provable recursiveness in EA(I;O)+ are obtained by the usual
proof theoretic process – embedding into a suitable inﬁnitary system which admits
cut elimination.
The inﬁnitary system EA(I;O)+
∞derives Tait-style sequents
n:I; m:O ⊢α Γ
where Γ is a ﬁnite set of closed formulas, n bounds the input parameters, m declares
a bound on any initial output values and the ordinal heights α are, for our purposes
here, in fact “tree ordinals” (with assigned fundamental sequences) generated from

A Hierarchy of Ramified Theories Below PRA
479
0 and ω = supi(i + 1) by addition, multiplication and exponentiation. Thus, as set-
theoretic ordinals, they all lie below ε0, and have standard fundamental sequences.
For shorthand we write simply n; m ⊢α Γ or n; ⊢α Γ when m = 0.
Most of the rules are unsurprising and we don’t list the ∨, ∧rules explicitly.
The axioms are n; m ⊢α Γ where the set Γ contains a true atom.
The Cut rule, with cut formula C, is
n; m ⊢β0 Γ, ¬C
n; m ⊢β1 Γ,C
n; m ⊢α Γ
.
There are two ∃-rules, one for ∃a and one for ∃x, each with two premises:
n; m ⊩β0 m′
n; m ⊢β1 A(m′), Γ
n; m ⊢α ∃aA(a), Γ
n; ⊩β0 m′
n; m ⊢β1 A(m′), Γ
n; m ⊢α ∃xA(x), Γ
.
Here the left-hand premise “computes” witness m′ from m which we denote with
a diﬀerent proof gate ⊩(not the forcing notation). We deﬁne such computations
according to the following simple rules – The computational axiom is n; m ⊩α m′
provided m′ ≤q(m), where q is a suitable quadratic function which bounds all the
term-constructors. The computation rule (call-by-value) is:
n; m ⊩β0 m′′
n; m′′ ⊩β1 m′
n; m ⊩α m′
and this is also allowed to interact with the logic in the form:
n; m ⊩β0 m′′
n; m′′ ⊢β1 Γ
n; m ⊢α Γ
.
The universal quantiﬁers ∀a and ∀x are introduced by versions of the ω-rule:
{n; max(m, i) ⊢β A(i), Γ}i∈N
n; m ⊢α ∀aA(a), Γ
{max(n, i); m ⊢β A(i), Γ}i∈N
n; m ⊢α ∀xA(x), Γ
.
Note that here, the ordinal bound β on the premises does not vary with i. This is
what keeps the theory “weak”.
4.1
The ordinal assignment
In all of the above rules the declared input n controls the ordinal assignment in the
following way: if n; m′ ⊢β Γ′ is any premise of a rule with conclusion n; m ⊢α Γ
then the requirement is that β ∈α[n] where α[n] = ∅if α = 0, or β[n] ∪{β}
if α = β + 1, or αn[n] if α = supi αi is a limit. Thus, while input n is ﬁxed,

480
Elliott J. Spoors and Stanley S. Wainer
derivations not containing the ∀x rule are in fact of ﬁnite height because n; m ⊢α Γ
implies n; m ⊢Gα(n) Γ where Gα(n) = |α[n]| is the “slow growing” hierarchy. It
is not diﬃcult to check that for each ﬁxed n, the map α 7→Gα(n) preserves the
arithmetic operations such as addition, multiplication and exponentiation. Thus
by choosing ω = sup(i + 1) one sees that Gω(n) = n + 1 and for each α, Gα(n)
is the exponential polynomial which results by replacing ω by n + 1 throughout.
The following Bounding Lemma is easy by inductions on α; recall that q is a ﬁxed
quadratic chosen to bound all the term-constructors, and qk denotes its k-times
iterate. (Note the Bellantoni-Cook-style variable separation.)
Lemma 3. n; m ⊩α m′ if and only if m′ ≤qk(m) where k = 2Gα(n).
4.2
Cut elimination in EA(I;O)+
∞
The standard methods apply here, just as for PA∞.
Theorem 4. (i) If n; m ⊢γ Γ, ¬C and n; m ⊢α Γ,C are both derivable with cut
formulas of “size” ≤r, where C is a formula of size r + 1 with shape ∨, ∃a or a
true atom and α[n] ⊆γ[n], then n; m ⊢γ+α Γ is also derivable with cuts of size ≤r.
(ii) If n; m ⊢α Γ is derivable with cut formulas of size at most r + 1 with shape
∨or ∃a, then n; m ⊢2α Γ is derivable with cut formulas of size at most r.
Repeated application of (ii) eliminates cuts on formulas beginning ∨or ∃a, at
the expense of an iterated exponential increase in the ordinal bound. (It does not
eliminate cuts on formulas beginning with an input quantiﬁer, but these can anyway
be kept down to the Σ1 level, as we shall see below.)
This gives an immediate glimpse of why the provably computable functions of
EA(I;O) are elementary. For if an EA(I;O) proof of f(x)↓≡∃aC f (x, a) is embedded
in the inﬁnitary system, a cut-free derivation is obtained with ordinal bound |α| <
ε0. Then for each x := n a witness m may be read oﬀsuch that C f (n, m) holds
and n; ⊩α m. Therefore, by the bounding principle above, the elementary function
qk(0), where k = 2Gα(n), bounds the quantiﬁers in the Σ1 deﬁning formula of f, so
f is an elementary function.
4.3
Embedding EA(I;O)+ in EA(I;O)+
∞
Deﬁnition 5. By a “Σ(I) formula” (dually Π(I)) is meant a Σ1 (resp. Π1) formula
beginning with at least one unbounded input quantiﬁer ∃x (∀x). We write n; m ⊢α
Σ(I)
Γ to signify that there is a derivation of n; m ⊢α Γ in which all cut formulas are Σ(I)
(dually Π(I)).

A Hierarchy of Ramified Theories Below PRA
481
Theorem 6. If EA(I;O)+ ⊢Γ(⃗x;⃗a) then there is an α with |α| < ε0 such that for all
⃗x := ⃗n = n1, . . . , nr ≤n and all ⃗a := ⃗m = m1, . . . , mℓ≤m,
n; m ⊢α
Σ(I) Γ(⃗n; ⃗m) .
Proof. First, as preparation, note that in EA(I;O)+ we can directly eliminate all
“free” cuts in which the cut formula C contains unbounded input quantiﬁers and is
of greater logical complexity than Σ(I) or Π(I). Very roughly, the procedure goes
as follows: if the premises of the cut are Γ, ¬C and Γ,C where C begins, say, with
an existential quantiﬁer, then it cannot be the result of an induction or a reﬂection
rule (since it’s neither an EA(I;O) formula nor Σ(I)), and so could only arise by an
∃rule from a Γ, D(t) where C ≡∃aD(a) or C ≡∃xD(x). Then by inverting the
other premise to Γ, ¬D(t) one sees that the original cut on C may now be replaced
by a cut on its subformula D. (Similarly if C ≡D1 ∨D2.) Repeating this process
successively eliminates all such cuts from EA(I;O)+ proofs, and we shall henceforth
assume this to have been done.
The theorem is now proved by induction over the height of this (revised) proof
of Γ(⃗x;⃗a) in EA(I;O)+, with cases according to the last rule applied. The cut elimi-
nation of the last subsection ensures that cuts on EA(I;O) formulas may continually
be eliminated without increasing the ordinal bounds above the superexponential
level. Thus only Σ(I) cuts will remain.
The non-inductive axioms, the ∨, ∧-rules and the cuts on Σ(I) formulas all
carry over easily to the inﬁnitary setting, as do the ∀a and ∀x rules.
If Γ, ∃aA(a) comes about by an ∃-rule from the premise Γ, ∃aA(a), A(t(⃗x;⃗a))
then we may inductively assume there is a β such that for all ⃗n ≤n, ⃗m ≤m,
n; m ⊢β
Σ(I) Γ, ∃aA(a), A(t(⃗n; ⃗m)).
Now the value m′ of t(⃗n; ⃗m) is polynomially
bounded, and certainly m′ ≤qk(m) where k = 2Gω+d(n) for some suitable d. There-
fore n; m ⊩ω+d m′ and, by weakening the ordinal bound β and replacing t(⃗n; ⃗m) by
its value, n; m ⊢ω+d+β
Σ(I)
Γ, ∃aA(a), A(m′). An application of the ∃a rule then gives
n; m ⊢α
Σ(I) Γ, ∃aA(a) as required, with α = ω + d + β + 1. The ∃x rule is handled
similarly but with m = 0.
An induction axiom, in Tait style, is Γ, ¬A(0), ∃a(A(a) ∧¬A(a + 1)), A(t) with
A an EA(I;O) formula and t a term on input variables only.
We suppress the
other free variables ⃗x,⃗a from Γ, A.
As above, let m′ be the value of t(⃗n) and
choose γ = ω + d so that n; m ⊩γ m′.
Next, note that for some ﬁxed k de-
pending on the size of the formula A, simple logic gives a cut-free derivation of
n; m′ ⊢k Γ, ¬A(0), ∃a(A(a) ∧¬A(a + 1)), ¬A(i), A(i) for any i. Therefore if one as-
sumes n; m′ ⊢k+2(i−1) Γ, ¬A(0), ∃a(A(a) ∧¬A(a + 1)), A(i −1) with i ≤m′, then by
the ∧-rule followed by the ∃a rule (noting n; m′ ⊩0 i −1) one immediately obtains
n; m′ ⊢k+2i Γ, ¬A(0), ∃a(A(a) ∧¬A(a + 1)), A(i) . Hence by induction on i up to

482
Elliott J. Spoors and Stanley S. Wainer
m′ we have n; m′ ⊢k+2m′ Γ, ¬A(0), ∃a(A(a) ∧¬A(a + 1)), A(m′). But an easy tree
ordinal computation shows (k + 2ω)[m′] = {0, . . . , k, k + 1, . . . , k + 2m′ + 1} and
so n; m′ ⊢k+2ω Γ, ¬A(0), ∃a(A(a) ∧¬A(a + 1)), A(m′). A computation rule with
n; m ⊩γ m′ gives n; m ⊢γ+k+2ω+1 Γ, ¬A(0), ∃a(A(a) ∧¬A(a + 1)), A(m′). Since m′
is the value of the term t, ¬A(m′), A(t) is derivable with height k and then an elim-
inable cut on A(m′) yields
n; m ⊢α
Σ(I) Γ, ¬A(0), ∃a(A(a) ∧¬A(a + 1)), A(t)
as required.
Finally we must show that the Σ1 reﬂection rule: from Γ(⃗x), ∃⃗aA(⃗x,⃗a) derive
Γ(⃗x), ∃⃗yA(⃗x,⃗y), embeds into EA(I;O)+
∞, where Γ, ∃⃗aA(⃗a) is a set of Σ1 formulas
with only the input variables ⃗x free. Assume then, as induction hypothesis, that
there is a β such that for all ⃗n ≤n, n; ⊢β
Σ(I) Γ(⃗n), ∃⃗aA(⃗n,⃗a). We need to prove, for
a suitable α, n; ⊢α
Σ(I) Γ(⃗n), ∃⃗xA(⃗n, ⃗x). This follows immediately from the following
lemma with m = 0.
As a preliminary, note that only ﬁnitely many terms t(⃗x;⃗a) will be involved in
the embedding of any EA(I;O)+ proof, and each one is polynomially bounded. So
there will be a γ = ω + d for some ﬁxed d, such that for all ⃗n ≤n, ⃗m ≤m and
every such term, n; m ⊩γ val(t(⃗n; ⃗m)) or equivalently val(t(⃗n; ⃗m)) ≤qk(m) where
k = 2Gγ(n). We then say that the derivation is “term controlled” by γ.
□
Lemma 7. Suppose n; m ⊢β
Σ(I) Γ(⃗n; ⃗m) where Γ is a set of Σ1 formulas. Suppose
also that the derivation is term controlled by γ, and that m is such that n; ⊩γ m.
Then for some ﬁxed k we have n; ⊢γ+kβ
Σ(I) Γ′ where Γ′ results from Γ by replacing some
(possibly all) unbounded output quantiﬁers ∃a by input quantiﬁers ∃x.
Proof. We proceed by induction on β with cases according to the last rule applied.
The choice of k will become clear, and it is easy to show that if δ ∈β[n] then
kδ ∈kβ[n] so a derivation with ordinal bound β may be “weakened” to one with
ordinal bound kβ.
If Γ is an axiom (i.e. contains a true atom) then so will be n; m ⊢γ Γ′, and the
computation rule with n; ⊩γ m gives n; ⊢γ+kβ Γ′ since γ ∈(γ + kβ)[n].
The ∨and ∧rules are handled easily, by applying the induction hypothesis to
each premise and then re-applying the rule.
If n; m ⊢β Γ comes about by a computation rule with premises n; m ⊩β0 m′
and n; m′ ⊢β1 Γ then, ﬁrst, set δ = max(β0, β1) ∈β[n]. We have n; ⊩γ+kδ·2 m′
by the computation rule, and so by the induction hypothesis, with γ replaced by
γ + kδ · 2, we obtain n; ⊢γ+kδ·3 Γ′. Since δ ∈β[n], if one chooses k ≥3 then either
γ + kδ · 3 = γ + kβ or γ + kδ · 3 ∈(γ + kβ)[n], so n; ⊢γ+kβ Γ′ as required, and still with
only Σ(I) cuts.

A Hierarchy of Ramified Theories Below PRA
483
Suppose n; m ⊢β Γ arises from premises n; m ⊩β0 m′ and n; m ⊢β1 Γ, A(m′) by
an ∃a or ∃x rule where (respectively) ∃aA(a) or ∃xA(x) belongs to Γ. Then, again
with δ = max(β0, β1) ∈β[n], the computation rule and the induction hypothesis
yield n; ⊩γ+kδ m′ and n; ⊢γ+kδ Γ′, A′(m′). Since kδ ∈kβ[n] the appropriate ∃a or ∃x
rule may then be applied to give n; ⊢γ+kβ
Σ(I) Γ′.
If the last rule applied is a universal quantiﬁcation then it can only occur in a
bounded context since the formulas are all Σ1. The premises will then have the form
{n; max(m, i) ⊢δ Γ, i ̸≤t∨B(i)}i∈N where δ ∈β[n] and ∀a ≤tB(a) belongs to Γ. Since
the derivation is term controlled by γ we have n; m ⊩γ val(t), so n; ⊩γ+kδ max(m, i)
for each i ≤val(t). For i > val(t) the atom i ̸≤t is true and derivable with any side
formulas and any ordinal height. Therefore by the induction hypothesis, with γ
replaced by γ +kδ and m replaced by max(m, i), we obtain n; i ⊢γ+kδ·2 Γ′, i ̸≤t ∨B(i)
for all i. Then (assuming k ≥3 again) a ﬁnal re-application of the ∀-rule gives
n; ⊢γ+kβ
Σ(I) Γ′.
Finally, suppose the last rule applied is a cut on a Σ(I) formula, say ∃⃗cB(⃗c)
where B contains only bounded quantiﬁers and the variables ⃗c are either inputs
or outputs. Then the premises are n; m ⊢β0
Σ(I) Γ, ∀⃗c¬B(⃗c) and n; m ⊢β1
Σ(I) Γ, ∃⃗cB(⃗c).
(Any “dummy” variables not in ⃗n, ⃗m are assumed to have been set to 0.) Again let
δ = max(β0, β1) ∈β[n]. Applying the induction hypothesis to the second premise
yields n; ⊢γ+kδ
Σ(I) Γ′, ∃⃗yB(⃗y) with new input variables ⃗y. By inverting the ∀⃗c in the ﬁrst
premise, max(n,⃗i); max(m,⃗i) ⊢δ Γ, ¬B(⃗i) for all⃗i. Now the induction hypothesis can
be applied to this, since max(n,⃗i); ⊩γ max(m,⃗i). Thus max(n,⃗i); ⊢γ+kδ Γ′, ¬B(⃗i),
and then by applying the ∀y rule as many times as necessary, n; ⊢γ+kδ+r
Σ(I)
Γ′, ∀⃗y¬B(⃗y).
We may now do a cut on ∃⃗yB(⃗y) to obtain n; ⊢γ+kδ+r+1
Σ(I)
Γ′ and the ordinal bound
may be increased to γ + kβ as required, provided we choose k > the length r of any
quantiﬁer-preﬁx occurring in the embedded EA(I;O)+ proof.
This completes the lemma and the proof of the theorem.
□
4.4
Extracting elementary bounds for EA(I;O)+
The embedding of EA(I;O)+ in EA(I;O)+
∞preserves the Σ(I) cuts, and since these
are not allowed as induction formulas, it means that there must be a ﬁnite up-
per bound on the “depth of nesting” of such Σ(I) cuts in any embedded EA(I;O)+
∞
derivation. We call this the “cut height” of the derivation and denote it h.
Deﬁnition 8. For α in the additive, multiplicative, exponential closure of {0, ω}, let
Bα(n, m) be the elementary function qk(m) where k = 2Gα(n), so n; m ⊩α m′ if and

484
Elliott J. Spoors and Stanley S. Wainer
only if m′ ≤Bα(n, m). Then deﬁne B(0)
α = Bα and, for any ﬁxed h > 0,
B(h)
α (n, m) := B(h−1)
α
(B(h−1)
α
(n, m), B(h−1)
α
(n, m)) .
Since B(h)
α is a ﬁnite compositional term built up from Bα, it too is elementary.
If β ∈α[n] then Gβ(n) < Gα(n) and so Bβ(n, Bβ(n, m)) ≤Bα(n, m) and similarly,
B(h)
β (n, Bβ(n, m)) ≤B(h)
α (n, m).
Deﬁnition 9. A closed Σ1 formula ∃⃗cA(⃗c), with A a bounded formula and ⃗c a
mixture of input or output variables, is said to be “true at b” if there are witnesses
⃗m ≤b such that A(⃗m) is true (in standard arithmetic). If there are no unbounded
existential quantiﬁers then the bounded formula A is true at b if it is true. A set of
Σ1 formulas is true at b if at least one of them is.
Lemma 10. Let Γ be a set of Σ1 formulas such that n; m ⊢α
Σ(I) Γ with ﬁnite cut
height ≤h. Assume that the derivation is term controlled by γ. Then Γ is true at
B(h)
α′ (n, m) where α′ = γ + α.
Proof. We use induction on h with sub-induction on α. To save having to decorate
each ordinal with a “dash”, we may as well assume, by weakening, that γ has
already been “added in” to each ordinal bound in the derivation. Then if n; m ⊢β Γ
each closed term in Γ has value ≤Bβ(n, m). Let (*) denote the given derivation of
n; m ⊢α
Σ(I) Γ.
If (*) is an axiom then Γ contains a true atom and is true at any b.
If (*) comes about by the ∨or ∧rule then the premise(s) are of the form
n; m ⊢β
Σ(I) Γ′, D and n; m ⊢β
Σ(I) Γ′, D′ where D, D′ are bounded formulas and of
course, β ∈α[n]. By the induction hypothesis, either Γ′ is true at B(h)
β (n, m) or, if
not, D, D′ are true. In this case Γ = Γ′, D ∨D′ or = Γ′, D ∧D′ is true at B(h)
β (n, m)
and hence at B(h)
α (n, m).
If (*) arises by the ∀rule then it can only occur in a bounded context, so the
premises are {n; max(m, i) ⊢β Γ′, i ̸≤t ∨B(i)}i∈N where Γ = Γ′, ∀i ≤tB(i). Ei-
ther ∀i ≤tB(i) is true (and hence the result) or else there is an i ≤val(t) such
that Γ′ is true at B(h)
β (n, max(m, i)).
But by term control, i ≤Bβ(n, m) and so
B(h)
β (n, max(m, i)) ≤B(h)
β (n, Bβ(n, m)) ≤B(h)
α (n, m). Therefore Γ′ and hence Γ is
true at B(h)
α (n, m).
If (*) arises by an ∃rule then there are two premises: n; m ⊢β Γ, A(m′) and
either n; m ⊩β m′ in case it’s a ∃a rule, or n; ⊩β m′ if it’s a ∃x rule. Here Γ
contains ∃cA(c) with the variable c being either an a or an x. By the induction
hypothesis, either some formula in Γ is already true at B(h)
β (n, m) or else A(m′)

A Hierarchy of Ramified Theories Below PRA
485
is true at B(h)
β (n, m) and hence ∃cA(c) is also true at B(h)
β (n, m) because the new
witness m′ is ≤Bβ(n, m) ≤B(h)
β (n, m). Either way, Γ is true at B(h)
β (n, m) and hence
at B(h)
α (n, m).
If (*) comes about by a computation rule with premises n; m′ ⊢β Γ and
n; m ⊩β m′ then by the induction hypothesis Γ is true at B(h)
β (n, m′), and also we
have m′ ≤Bβ(n, m). Therefore Γ is true at B(h)
β (n, Bβ(n, m)) ≤B(h)
α (n, m) as required.
Finally suppose (*) arises by a cut from the premises n; m ⊢β Γ, ∃⃗cA(⃗c) and
n; m ⊢β Γ, ∀⃗c¬A(⃗c) with A(⃗c) a bounded formula and where ⃗c is a sequence of input
or output variables. Since Γ is derived with cut height ≤h, both of the premises
must be derived with cut height ≤h −1. By the induction hypothesis applied to the
ﬁrst premise, and letting k = B(h−1)
β
(n, m), either Γ is true at k or else there are⃗i ≤k
such that A(⃗i) is true. Now inverting the ∀⃗c in the second premise, k; k ⊢β Γ, ¬A(⃗i).
The set Γ, ¬A consists solely of Σ1 formulas, so the induction hypothesis may be
applied again, yielding Γ, ¬A(⃗i) true at B(h−1)
β
(k, k). Since ¬A(⃗i) is false, we have Γ
true at B(h−1)
β
(k, k) = B(h)
β (n, m) ≤B(h)
α (n, m) and this completes the proof.
□
Theorem 11. The provably computable functions of EA(I;O)+ are exactly the ele-
mentary functions.
Proof. Every elementary function is provably computable in EA(I;O), and hence in
EA(I;O)+. For the converse suppose f(⃗x) has the deﬁning formula ∃aC f (⃗x, a) prov-
able in EA(I;O)+. Then by the embedding, n; ⊢α
Σ(I) ∃aC f (⃗n, a) with ﬁxed cut height
h, where n = max(⃗n), and we may assume that this derivation is term controlled
by some γ. Therefore by Lemma 10, there are true witnesses for the existentially
quantiﬁed variables preﬁxing ∃aC f (⃗n, a) and they are all bounded by the elemen-
tary function B(h)
γ+α(n, 0). This holds uniformly for all inputs ⃗n. Thus the graph
of f is elementarily decidable and its value is elementarily bounded, so it is an
elementary function.
□
5
A Hierarchy of Theories above EA(I;O)+
We now introduce a new level of input variables, and a new tier of inductions over
EA(I;O)+ formulas. Henceforth denote I by I1, and call x, y, z the I1 variables. Then
the I2 variables are new variables, denoted u, v, w. Add to EA(I;O)+ these new I2
variables and the new induction principle:
A(0) ∧∀x(A(x) →A(x + 1)) →A(t)

486
Elliott J. Spoors and Stanley S. Wainer
where A is an EA(I;O)+-formula, possibly with free I2 parameters, and t = t(⃗u)
is a term containing only I2 variables. This theory is denoted EA(I2; I1; O). Its
extension EA(I2; I1; O)+ is obtained by further adding I2-quantiﬁer rules and a Σ1
reﬂection rule at level 2:
Γ(⃗u), ∃⃗xA(⃗u, ⃗x)
Γ(⃗u), ∃⃗vA(⃗u,⃗v)
where Γ(⃗u), ∃⃗xA(⃗u, ⃗x) is a set of Σ1 formulas all of whose free variables are I2
inputs.
Deﬁnition 12. A function f is provably computable in EA(I2; I1; O)+ if, on level-2
inputs ⃗u, its deﬁning formula f(⃗u)↓≡∃aC f (⃗u, a) is provable.
Every function provably computable in EA(I;O)+ is provably computable in
EA(I2; I1; O), for by trivial applications of the level-2 induction principle above, if
∃aC f (⃗x, a) is provable in EA(I;O)+ then ∃aC f (⃗u, a) is provable in EA(I2; I1; O).
Lemma 13. The functions of Grzegorczyk’s E4 are all provably computable in
EA(I2; I1; O)+.
Proof. It is only necessary to show that every function computable by a register-
machine in a number of steps bounded by some ﬁnite iterate of the superexponential
2u(u) is provably computable in EA(I2; I1; O)+. Here, 2u(v) is deﬁned by 20(v) = v
and 2u+1(v) = 22u(v).
First note that 2u(u) ↓is provable in EA(I2; I1; O)+. This is because 2x ↓is
already provable in EA(I;O) and so ∃y(2x = y) and ∀x∃y(2x = y) are provable in
EA(I;O)+ by the level-1 reﬂection rule and the ∀-rule. Therefore ∃y(20(z) = y) and
∃y(2x(z) = y) →∃y(2x+1(z) = y) are provable. Now the level-2 induction comes
into play, yielding ∃y(2u(z) = y) and hence 2u(u)↓. Arbitrary ﬁnite compositions of
this are then provable in EA(I2; I1; O)+ by the level-2 reﬂection and quantiﬁcation
rules, as done earlier at level-1.
Letting f(u) be any such ﬁnite iteration of 2u(u), suppose g(⃗v) is register-
machine computable in a number of steps bounded by f(max⃗v). Associate with
the register machine program a bounded formula Cg(s,⃗v, i, r1, . . . , rk) representing
the well-deﬁnedness of all successive internal conﬁgurations of the machine up to
step s. Thus i stores the sequence of next-to-be-obeyed program-instructions start-
ing at step 0, and each rj is a sequence-number recording the numerical content of
the j-th working register at each step up to s. The basic instructions either update a
register by a successor or predecessor, or jump to another instruction according to
the value in one register being zero or nonzero. The initial conﬁguration on input ⃗v
is (1, 0, . . . , 0). It is therefore easy to prove, in EA(I2; I1; O),
∃i∃⃗rCg(0,⃗v, i,⃗r) ∧∀s(∃i∃⃗rCg(s,⃗v, i,⃗r) →∃i∃⃗rCg(s + 1,⃗v, i,⃗r)) .

A Hierarchy of Ramified Theories Below PRA
487
Hence ∃i∃⃗rCg(u,⃗v, i,⃗r) is provable in EA(I2; I1; O) and ∀u∃i∃⃗rCg(u,⃗v, i,⃗r) is prov-
able in EA(I2; I1; O)+. Therefore so is ∃i∃⃗rCg(f(max⃗v),⃗v, i,⃗r), using level-2 reﬂec-
tion and quantiﬁcation. But this is the termination condition for g, so g is provably
computable in EA(I2; I1; O)+.
□
5.1
The inﬁnitary system EA(I2; I1; O)+
∞
As before, upper bounds on provable recursiveness in EA(I2; I1; O)+ are obtained
by embedding into a suitable inﬁnitary system which admits cut elimination.
The inﬁnitary system EA(I2; I1; O)+
∞derives Tait-style sequents
n2:I2 ; n1:I1 ; m:O ⊢α,γ Γ
where Γ is a ﬁnite set of closed formulas, n2, n1 bound level-2 and level-1 inputs
respectively, and m declares a bound on the output values. The tree-ordinals α, γ
are still exponential forms to the base ω, i.e. generated by addition, multiplication
and exponentiation from 0, ω. As before, we use the shorthand n2; n1; m ⊢α,γ Γ.
Only the α and n2 control the derivations in the sense that if β, γ are the bounds
on a premise with conclusion n2; n1; m ⊢α,γ Γ then β ∈α[n2]. The γ remains ﬁxed
throughout, and only plays a role in the following axiom which layers the new
system on top of the old one EA(I;O)+
∞:
n2; n1; m ⊢α,γ Γ if n1; m ⊢γ Γ′ where Γ′ ⊆Γ
with α and n2 arbitrary.
The rules of EA(I2; I1; O)+
∞are those of EA(I;O)+
∞appropriately redecorated
with n2 and α, together with new level-2 rules:
The ∃u-rule is
n2; 0; 0 ⊩β0,γ m′
n2; n1; m ⊢β1,γ A(m′), Γ
n2; n1; m ⊢α,γ ∃uA(u), Γ
and the ∀u-rule is
{max(n2, i); n1; m ⊢β,γ A(i), Γ}i∈N
n2; n1; m ⊢α,γ ∀uA(u), Γ
.
The new computation axiom is:
n2; n1; m ⊩α,γ m′ if n1; m ⊩γ m′ in EA(I;O)+
∞.
The new computation rule is:
n2; n1; 0 ⊩β0,γ n′
1
n2; n′
1; m ⊩β1,γ m′
n2; n1; m ⊩α,γ m′

488
Elliott J. Spoors and Stanley S. Wainer
and this can interact with the logic in the form:
n2; n1; 0 ⊩β0,γ n′
1
n2; n′
1; m ⊢β1,γ Γ
n2; n1; m ⊢α,γ Γ
.
Deﬁnition 14. (Bounding Functions)
Bα,γ(n2, n1, m) =

Bγ(n1, m)
if α = 0,
Bα−1,γ(n2, Bα−1,γ(n2, n1, 0), m)
if α is a successor,
Bαn2,γ(n2, n1, m)
if α is a limit.
Lemma 15. For each ﬁxed pair α, γ, the function Bα,γ lies in E4.
Proof. This is because, by an easy induction on α,
Bα,γ(n2, n1, m) = Bγ(f k(n1), m) with f(n) = Bγ(n, 0) and k = 2Gα(n2) −1 .
Since the binary Bγ is elementary, f is elementary, and so its iterate function f k(n)
lies in E4, because one iteration jumps up to the next level of the Grzegorczyk
hierarchy. But k is also an elementary function of n2. Therefore Bα,γ ∈E4.
□
Lemma 16. (Bounding Lemma)
n2; n1; m ⊩α,γ m′ if and only if m′ ≤Bα,γ(n2, n1, m)
provided (in the “only if” part) that γ is at least ω.
Proof. For the “if” suppose m′ ≤Bα,γ(n2, n1, m) and proceed by induction on α.
If α = 0 then m′ ≤Bγ(n1, m), so n1; m ⊩γ m′ and hence n2; n1; m ⊩α,γ m′ by
the computation axiom. If α is a successor then m′ ≤Bα−1,γ(n2, n′, m) where
n′ = Bα−1,γ(n2, n1, 0).
Hence by the induction hypothesis, n2; n1; 0 ⊩α−1,γ n′
and n2; n′; m ⊩α−1,γ m′.
One application of the computation rule then yields
n2; n1; m ⊩α,γ m′. If α = supi αi is a limit the result follows immediately from
the induction hypothesis at αn2.
For the “only if” direction assume n2; n1; m ⊩α,γ m′ and call this sequent
(*).
If it comes about from a computation axiom then we have n1; m ⊩γ m′
and therefore m′ ≤Bγ(n1, m) = B0,γ(n2; n1; m) ≤Bα,γ(n2, n1, m). Now assume
(*) arises from the level-2 computation rule with premises n2; n1; 0 ⊩β0,γ n′ and
n2; n′; m ⊩β1,γ m′. Inductively, we may therefore assume m′ ≤Bβ1,γ(n2, n′, m) where
n′ ≤Bβ0,γ(n2, n1, 0). Since β0, β1 ∈α[n2] it then follows from the deﬁnition of Bα,γ
that m′ ≤Bα,γ(n2, n1, m). Finally suppose (*) arises from an application of the level-
1 computation rule, with premises n2; n1; m′′ ⊩β1,γ m′ and n2; n1; m ⊩β0,γ m′′. Then

A Hierarchy of Ramified Theories Below PRA
489
m′ ≤Bβ1,γ(n2, n1, m′′) and m′′ ≤Bβ0,γ(n2, n1, m). Letting β = max(β0, β1) ∈α[n2],
the desired result will follow immediately from
Bβ,γ(n2, n1, Bβ,γ(n2, n1, m)) ≤Bβ,γ(n2, Bβ,γ(n2, n1, 0), m)
since the latter is ≤Bα,γ(n2, n1, m). But this is checked by a careful induction on
β. If β = 0 the left hand side of the inequality is Bγ+1(n1, m) = qk(m) where
k = 2Gγ(n1)+1. The right hand side is qk′(m) with k′ = 2Gγ(Bγ(n1,0)). Then k ≤k′
provided γ is at least ω. If β is a limit the result is immediate by applying the
induction hypothesis on βn2. Now suppose β is a successor. Then, unravelling the
left hand side, one obtains
Bβ−1,γ(n2, Bβ−1,γ(n2, n1, 0), Bβ−1,γ(n2, Bβ−1,γ(n2, n1, 0), m))
and, by the induction hypothesis, one sees that this is less than or equal to
Bβ−1,γ(n2, Bβ−1,γ(n2, Bβ−1,γ(n2, n1, 0), 0), m)
= Bβ−1,γ(n2, Bβ,γ(n2, n1, 0), m)
≤Bβ,γ(n2, Bβ,γ(n2, n1, 0), m)
as required.
□
5.2
E4 bounds for provable Σ1 formulas in EA(I2; I1; O)+
The procedure for extracting numerical bounds now runs along the same lines as
before for EA(I;O)+. Suppose EA(I2; I1; O)+ ⊢∃⃗aC(⃗u,⃗a) with C a bounded
formula. First, remove all cuts on formulas of complexity greater than Σ1 or Π1
containing at least one unbounded level-2 quantiﬁer (recall that these cannot be
induction formulas, nor the results of reﬂection rules, so they are “free cuts” which
can be eliminated straightforwardly within EA(I2; I1; O)+). Next, by the same
methods as in Theorem 6, embed this proof into EA(I2; I1; O)+
∞, simultaneously
eliminating all cuts on EA(I2; I1; O) formulas (cut elimination works for the new
extended inﬁnitary system just as it did for the old one, and the ordinal bounds
remain exponential forms to the base ω). The result is a derivation of
k ; 0; 0 ⊢α,γ
Σ(I) ∃⃗aC(⃗k,⃗a)
for some ﬁxed α, γ and all ⃗k = k1, . . . , kr ≤k. The subscript Σ(I) now indicates
that the only cuts remaining are on Σ1 (dually Π1) formulas which contain a level-2
quantiﬁer. A bounding result similar to that of Lemma 10 then shows that ∃⃗aC(⃗k,⃗a)
is true at f(max⃗k) where f is some ﬁnite iterate of Bα,γ.
Theorem 17. The provably computable functions of EA(I2; I1; O)+ are exactly the
E4 functions.

490
Elliott J. Spoors and Stanley S. Wainer
5.3
Extending the hierarchy upwards
The theory EA(Ij; . . . ; I2; I1; O)+ is formed from EA(I j−1; . . . ; I2; I1; O)+ at each
stage j, by adding new level-j variables, inductions “up to” level-j terms on EA(I j−1;
. . . ; I2; I1; O)+ formulas, and then adding level-j quantiﬁers and a level-j reﬂection
rule. It is then embedded into an inﬁnitary system:
n j; nj−1; . . . ; n2; n1; m ⊢α,⃗γ Γ
whose computation rules determine bounding functions Bα,⃗γ deﬁned by one further
iteration from B⃗γ. Since this latter is in Ej+1 the new bounding functions Bα,⃗γ, and
their ﬁnite compositions, will therefore lie in Ej+2. The methods, at each stage, are
essentially those already described.
Theorem 18. The provably computable functions of EA(Ij; . . . ; I2; I1; O)+ are
exactly the Ej+2 functions.
6
Extending EA(I;O) with a Closure Rule
The theory EA(I;O)∗extends EA(I;O) with the Σ1 Closure rule:
∆(⃗x;⃗b)
Γ, ∆(⃗a,⃗b)
where ∆is a set of Σ1 formulas, Γ is an arbitrary set of formulas and the variables
⃗a are free for ⃗x in ∆.
The rule replaces the uninterpreted (arbitrary) input constants ⃗x in the premise
by fresh output variables which may then be universally quantiﬁed (note how the
semi-colon separating the inputs/outputs in ∆is dropped from premise to conclu-
sion). Thus it resembles a formalized ω-rule for Σ1 formulas in EA(I;O)∗. This
causes a collapse of the variable separation and thus strengthens EA(I;O) consider-
ably. For a given EA(I;O)∗derivation of a Σ1 formula A(⃗x) (such as that deﬁning a
provably computable function) we may now deduce ∀⃗aA(⃗a). The universal quanti-
ﬁers ∀⃗a could be regarded as quantiﬁers with computational content in the sense of
Schwichtenberg [11] (also Berger [6]).
Deﬁnition 19. In EA(I;O)∗, provably computable functions are now deﬁned on
output variables. That is, f : Nk →N is “provably computable” if there is a Σ1
formula C f (⃗a, b) such that f(⃗n) = m if and only if C f (⃗n, m) is true, and EA(I;O)∗⊢
∀⃗a∃!bC f (⃗a, b).

A Hierarchy of Ramified Theories Below PRA
491
Theorem 20. The primitive recursive functions are provably computable in
EA(I;O)∗.
Proof. Clearly if a function is provably computable in EA(I;O) it is also provably
computable in EA(I;O)∗using the closure rule and universal quantiﬁcation. Fur-
thermore, closure under composition comes immediately from the logic. Hence
we need only show that the provably computable functions of EA(I;O)∗are closed
under primitive recursion.
Without loss of generality assume that the function f is deﬁned by the prim-
itive recursion f(0, b) = g(b), f(a + 1, b) = h(f(a, b)) where g and h are already
provably computable. Then we have derivations of ∀b∃dCg(b, d) and ∀c∃dCh(c, d).
It is straightforward to deﬁne a computational formula C f (a, b, d) for f such that
we may prove ∃dC f (0, b, d) and ∃dC f (a, b, d) →∃dC f (a + 1, b, d). Applying
predicative induction yields ∃dC f (x; b, d) from which the closure rule and uni-
versal quantiﬁcations leave ∀a, b∃dC f (a, b, d). Thus f is provably computable in
EA(I;O)∗.
□
6.1
Reﬁnements of EA(I;O)∗
We may now reﬁne the previous result by deﬁning a hierarchy of theories below
EA(I;O)∗which carefully control the applications of the closure and predicative
induction rules.
Deﬁnition 21. Let EA(I;O) be denoted EA0(I;O). Then for any natural number
k > 0 the theories EAk and EAk(I;O) are generated inductively. EAk is a theory
with just one type of variable, outputs, and the usual rules of inference and axioms.
EAk has no induction rule but we do add one non-logical axiom schema: the Σ1
closure axiom
EAk ⊢Γ, ∆(⃗a,⃗b)
if
EAk−1(I; O) ⊢∆(⃗x;⃗b)
where ∆is a set of Σ1 formulas, Γ is an arbitrary set of formulas and the variables
⃗a are free for ⃗x in ∆.
EAk(I;O) is then deﬁned as a two sorted extension of EAk. We add an inﬁnite
supply of input constants x, y, x0, x1, . . . as symbols of the language along with the
predicative induction rule
Γ, A(0)
Γ, ¬A(a), A(a + 1)
Γ, A(x)
where Γ is an arbitrary set of formulas and a is not free in Γ, A(0).

492
Elliott J. Spoors and Stanley S. Wainer
Note that if a function is provably computable in EA(I;O)∗and the derivation
contains at most k nested applications of the closure rule then this derivation may
be replicated in EAk(I;O).
Theorem 22. For each natural number k > 0, the functions in Grzegorczyk’s class
Ek+2 are provably computable in EAk
Proof. We use induction over k. The basis of the induction follows immediately
since the elementary functions are provably computable in EA(I;O) and thus also
EA1. Now assume the result holds for k. By a result of Axt [1], for i ≥3, the
Grzegorczyk class Ei+1 may be characterized as the smallest class of functions con-
taining Ei which is closed under composition and closed under a single primitive
recursion. Thus if f ∈Ek+3 we need only consider three cases for its deﬁnition and
we use a sub-induction according to these cases.
i. If f ∈Ek+2 then by the induction hypothesis for k we know f is provably
computable in EAk and hence also in EAk+1.
ii. If f is deﬁnable by composition where the auxiliary functions gi are in Ek+3
then by the sub-induction hypothesis gi is provably computable EAk+1. As in the
proof of Theorem 20, closure under composition of provably computable functions
in EAk+1 is straightforward from the logic without any appeal to predicative induc-
tion. Hence, f is provably computable in EAk+1.
iii. Finally it may be the case that f ∈Ek+3 is deﬁned by a primitive recursion
using auxiliary functions gi ∈Ek+2. Using the main induction hypothesis for k we
have gi provably computable in EAk. Following the proof of closure under primitive
recursion in Theorem 20 we may, with a single use of predicative induction, show
f is provably computable in EAk(I;O) and thus also provably computable in EAk+1.
□
6.2
The Inﬁnitary System EA(I;O)∗
∞
We now show that the provably recursive functions of EA(I;O)∗are at most the
primitive recursive functions using the inﬁnitary system EA(I;O)∗
∞. Its Tait-style
sequents take the form
n; m ⊢α,⃗γ Γ
where Γ is a ﬁnite set of closed formulas, n declares a bound on input parameters
and m declares a bound on output values. The tree ordinals α,⃗γ are again expo-
nential forms to the base ω. Here ⃗γ represents a ﬁnite (possibly empty) sequence
γk, . . . , γ1.
With one key exception, the rules of EA(I;O)∗
∞are controlled by α and n with
⃗γ remaining ﬁxed. That is to say from premise(s) with ordinal bounds β,⃗γ the con-
clusion takes the bound α,⃗γ where β ∈α[n]. We have an axiom rule in which α,⃗γ

A Hierarchy of Ramified Theories Below PRA
493
are arbitrary and the usual conjunction, disjunction and cut rules. Quantiﬁcation
rules only apply to outputs, hence there is one ∃-rule
n; m ⊩β0,⃗γ m′
n; m ⊢β1,⃗γ Γ, A(m′)
n; m ⊢α,⃗γ Γ, ∃aA(a)
and one ∀-rule
{n; max(m, i) ⊢β,⃗γ Γ, A(i)}i∈N
n; m ⊢α,⃗γ Γ, ∀aA(a)
where again β does not vary with i. The exception arises in the addition of the
closure rule
n′; m′ ⊢⃗γ ∆
n; max(n′, m′) ⊢α,⃗γ Γ
where ∆is Σ1, ∆⊆Γ, α and n are arbitrary and ⃗γ is non-empty. In this rule a new
ordinal α is preﬁxed to the existing sequence ⃗γ such that subsequent applications
of the other rules are now controlled by this new α and n.
We have three rules governing computations.
The computational axiom is
n; m ⊩α,⃗γ l where l ≤q(m) for some suitable quadratic function which bounds
all the term-constructors. The computational cut rule is
n; m ⊩β0,⃗γ m′
n; m′ ⊩β1,⃗γ l
n; m ⊩α,⃗γ l
which interacts with the logic in the form
n; m ⊩β0,⃗γ m′
n; m′ ⊢β1,⃗γ Γ
n; m ⊢α,⃗γ Γ
.
Finally we have a computational closure rule
n′; m′ ⊩⃗γ l
n; max(n′, m′) ⊩α,⃗γ l
where α and n are arbitrary and ⃗γ is non-empty.
The closure rule is analogous to the closure rule in EA(I;O)∗in that input dec-
larations in the premise become output declarations in the conclusion (hence any
semi-colon in ∆is dropped in applying the rule). As the declarations have shifted
we require a corresponding computational closure rule. Thus the inﬁnitary theory
here resembles one for EA(Ij; . . . ; I2; I1; O)+ in which multiple levels of declara-
tions nj; nj−1; . . . ; n1; m are reduced to just two: nj and max(n j−1; . . . ; n1; m).
We now broadly follow the usual methods for extracting numerical bounds on
derivations of Σ1 sets beginning by deﬁning a suitable bounding function.

494
Elliott J. Spoors and Stanley S. Wainer
Deﬁnition 23. (Bounding Functions)
Bα,⃗γ(n; m) =

q(m)
if α,⃗γ = 0,
B⃗γ(m; m)
if α = 0,
Bα−1,⃗γ(n; Bα−1,⃗γ(n; m))
if α is a successor,
Bαn,⃗γ(n; m)
if α is a limit.
Lemma 24. For each ﬁxed α,⃗γ and for a ﬁxed d ∈N, Bd,⃗γ lies in Ek+2 and Bα,⃗γ
lies in Ek+3.
Proof. We use induction over the length of the sequence ⃗γ. When the sequence is
empty k = 0 and Bd(n; m) is bounded by a polynomial. Thus it is contained in E2.
Bα lies in E3 since Bα(n; m) = qd(m) where q := 2Gα(n) and Gα(n) is elementary.
Now assume the result holds for ⃗γ := α′, γk−1, . . . , γ1. Then B⃗γ ∈Ek+2. For a ﬁxed
d ∈N, Bd,⃗γ ∈Ek+2 since it is deﬁned by composition from B⃗γ. An easy induction of
α shows Bα,⃗γ(n; m) is equal to Bd,⃗γ(n; m) where d := Gα(n). Hence we may deﬁne
Bα,⃗γ by a primitive recursion whose auxiliary functions lie in Ek+2 and we conclude
Bα,⃗γ ∈Ek+3.
□
Lemma 25. (Bounding Lemma)
n; m ⊩α,⃗γ l if and only if l ≤Bα,⃗γ(n; m).
Proof. Tackling the “if” part ﬁrst we use induction on the length of α,⃗γ with a
sub-induction on α. Assume that ⃗γ is empty. Then if α = 0 we have l ≤B0(n; m) =
q(m) and the result follows immediately by the computational axiom. If α is a
successor β + 1 then l ≤Bβ+1(n; m) = Bβ(n; m′) where m′ = Bβ(n; m). Using the
induction hypothesis for α we have the derivations n; m ⊩β m′ and n; m′ ⊩β l and
the result follows by a computational cut rule. Now assume α is a limit supn(λn) so
l ≤Bλ(n; m) = Bλn(n; m). Then for every n we may apply the induction hypothesis
for α to give n; m ⊩λn l. We must use a sub-induction on this derivation to change
the proof height from λn to λ. The axiom case is self-evident. Now assume an
application of a computational cut was the last rule of inference from premises of
heights βi. Then since βi ∈λn[n] = λ[n] we may have in each case taken the new
height to be λ. Hence n; m ⊩λ l.
Now, assuming the result for ⃗γ, if α = 0 then l ≤B0,⃗γ(n; m) = B⃗γ(m; m) and
the main induction hypothesis gives m; m ⊩⃗γ l. Applying the computational closure
rule we get n; m ⊩0,⃗γ l as required. The cases where α is a successor or a limit
follow just as above.
For the “only if” we use induction over the derivation of n; m ⊩α,⃗γ l with a
case distinction according to the ﬁnal rule of inference applied. We rely heavily

A Hierarchy of Ramified Theories Below PRA
495
upon certain majorization properties of the functions Bα,⃗γ(n; m), namely that they
are increasing in n, m and α,⃗γ. These properties follow by simple inductions on
α,⃗γ. If the derivation is a computational axiom then l ≤q(m) ≤Bα,⃗γ(n; m). If the
last rule of inference were a computational cut from premises n; m ⊩β0,⃗γ m′ and
n; m′ ⊩β1,⃗γ l then inductively m′ ≤Bβ0,⃗γ(n; m) and l ≤Bβ1,⃗γ(n; m′). Taking β to be
the maximum of β0, β1, since β ∈α[n] we ﬁnd
l ≤Bβ,⃗γ(n; Bβ,⃗γ(n; m)) = Bβ+1,⃗γ(n; m) ≤Bα,⃗γ(n; m).
The only other possibility is that the derivation results from the computational
closure rule. Using the induction hypothesis we have l ≤B⃗γ(n′; m′) for some
n′, m′ ≤m. Hence l ≤B⃗γ(m; m) ≤Bα,⃗γ(n; m).
□
6.3
Extracting bounds for EA(I;O)∗
The standard methods of cut-elimination apply in EA(I;O)∗
∞except that the cut-
rank reduction becomes stuck in the presence of the closure rule. However, since
this rule only applies where the formulas in the premise are at worse Σ1, we are able
to reduce cuts to the Σ1 level. It is straightforward to show that EA(I;O)∗
∞admits
weakening, conjunction inversion and universal quantiﬁer inversion as well as the
following:
Theorem 26. (i) If n; m ⊢α,⃗γ Γ, ¬C and n; m ⊢α′,⃗γ Γ,C are both derivable with cut
formulas of size ≤r, where C is a formula of size r + 1 which is either a true atom,
or has shape ∨or ∃a but is not Σ1, then n; m ⊢α+α′,⃗γ Γ is also derivable with cuts of
size ≤r provided α′[n] ⊆α[n].
(ii) Let ⃗2γ := 2γk, . . . , 2γ1. If n; m ⊢α,⃗γ Γ is derivable with cut formulas of size at
most r + 1 then n; m ⊢2α, ⃗2γ Γ is derivable with cut formulas either of size at most r
or Σ1.
Repeated applications of (ii) will therefore eliminate cuts down to the Σ1 level
at the cost of iterated exponential increases in each of the ordinals α,⃗γ.
Theorem 27. (Embedding) If EA(I;O)∗⊢Γ(⃗x;⃗a) then this derivation determines
some d ∈N such that for all ⃗x := ⃗n = n1, . . . , nr ≤n and all ⃗a := ⃗m = m1, . . . , mℓ≤
m, EA∗
∞derives
n; m ⊢α,⃗γ Γ(⃗n; ⃗m)
where each of α,⃗γ is of the form ω · di for some di ≤d.
Proof. We proceed by induction on the height of the proof of Γ(⃗x;⃗a) in EA(I;O)∗
with a case distinction according to the ﬁnal rule applied. The axioms, rules for

496
Elliott J. Spoors and Stanley S. Wainer
∨, ∧and ∀a as well as cuts all carry over easily using the corresponding inﬁnitary
rules. The cases for ∃a and predicative induction follow the reasoning in the proof
of Theorem 6 except that we need not eliminate cuts as we go thus restricting the
heights to ordinals of the form ω · d.
The only case remaining is Σ1 Closure. Assume Γ(⃗x;⃗a) came about via such
a rule and without loss of generality, for clarity, let ⃗a := a, b, c and ⃗x = x so that
Γ(⃗x;⃗a) :≡Γ′(x; c), ∆(a, b) where ∆is a Σ1 set of formulas. Then the premise is of
the form ∆(y; b) where y is an input which changes to the output a in the conclusion.
Appealing to the induction hypothesis we obtain
i, m′ ⊢α′,⃗γ′ ∆(i; m′).
The result follows immediately since the closure rule of EA∗
∞and weakening yield
n; max(i, m′, m) ⊢ω·0,⃗γ Γ′(n; m), ∆(i, m′)
where i has become an output declaration and an additional ordinal ω · 0 has been
introduced in front of ⃗γ := α′, ⃗γ′.
□
Lemma 28. Let Γ be a set of Σ1 formulas such that n; m ⊢α,⃗γ Γ using only Σ1 cuts
and assume that the derivation is term controlled by δ. Then Γ is true at Bα′,⃗γ′(n, m)
where α′ = δ + α and each γ′
i = δ + γi.
Proof. We use induction over the derivation of n; m ⊢α,⃗γ Γ with a case distinction
according to the last rule applied. We follow closely the proof of Lemma 10 but
simpliﬁed in this context – we do not have a ∀x rule so there are no substitutions
on inputs in the cut case. We shall only expand on the cases for the cut and closure
rules where, as before, we dispense with the use of “dashes” on ordinals by assum-
ing each ordinal bound in the derivation has been weakened to “add in” δ. Hence
n; m ⊢β,⃗γ Γ implies that any closed term in Γ is bounded by Bβ,⃗γ(n; m). We also
assume that ordinal bounds in premises have been matched by weakening.
Assume that the derivation comes from a Σ1 cut with premises of the form
n; m ⊢β,⃗γ Γ, ∃⃗cA(⃗c) and n; m ⊢β,⃗γ Γ, ∀⃗c¬A(⃗c) where A is a bounded formula. Let
k = Bβ,⃗γ(n; m). The induction hypothesis applies to the ﬁrst premise to reveal
Γ, ∃⃗cA(⃗c) is true at k. Either Γ is true at k and we are done since k ≤Bα,⃗γ(n; m),
or else there are⃗i ≤k such that A(⃗i) is true. Inverting the universal quantiﬁers ∀⃗c
in the second premise gives n; max(m, k) ⊢β Γ, ¬A(⃗i). This allows an application of
the induction hypothesis so that Γ, ¬A(⃗i) is true at Bβ,⃗γ(n; k). Therefore, as ¬A(⃗i) is
false, Γ is true at Bβ,⃗γ(n; k) = Bβ,⃗γ(n; Bβ,⃗γ(n; m)) ≤Bα,⃗γ(n; m).
Now assume we have an application of closure from premise n′; m′ ⊢⃗γ Γ′ where
n′, m′ ≤m. By the induction hypothesis Γ′, and hence Γ, is true at B⃗γ(n′; m′) ≤
B⃗γ(m; m) ≤Bα,⃗γ(n; m).
□

A Hierarchy of Ramified Theories Below PRA
497
Theorem 29. (i) The provably computable functions of EA(I;O)∗are exactly the
primitive recursive functions.
(ii) The provably computable functions of EAk, for each k > 0, are exactly
Grzegorczyk’s class Ek+2.
Proof. (i) We have shown that the primitive recursive functions are provably com-
putable in EA(I;O)∗in Theorem 20. For the converse, if f(⃗a) is provably com-
putable in EA(I;O)∗then we must have a derivation of ∀⃗a∃bC f (⃗a, b) where C f
is a deﬁning formula for f. Successively applying the embedding theorem, uni-
versal inversion of ∀⃗a and then cut-reduction we ﬁnd that EA(I;O)∗
∞will prove
0; m ⊢α,⃗γ ∃bC f (⃗m, b) with only Σ1 cuts where m := max(⃗m) and α,⃗γ is some ﬁnite
sequence of tree-ordinals with |α|, |γi| < ε0 for each i. We may assume the deriva-
tion is term controlled using weakening so that the witnessing result above tell us
∃bC f (⃗m, b) is true with existential witnesses bounded by Bα,⃗γ(0; m) (a primitive re-
cursive function by Lemma 24). Hence the graph of f is decidable using primitive
recursive functions and its value is bounded by a primitive recursive function, so f
is itself a primitive recursive function.
(ii) Theorem 22 shows that any Ek+2 function is provably computable in EAk.
For the converse we begin by proving the following:
(*) For k > 0, EAk embeds into EA(I;O)∗
∞with ordinal bound d, γk, . . . , γ1
where d ∈N and each |γi| < ε0 whilst EAk(I;O) embeds into EA(I;O)∗
∞with ordinal
bound γk+1, . . . , γ1.
Proof of (*): We use induction on k. First we note that EA0(I;O) is just EA(I;O)
and, following the proof of Theorem 27, it will embed into the inﬁnitary theory
with only one ordinal γ1 since the closure rule never applies. Now assume k = 1.
EA1 contains no induction rule but it does have the closure axiom which reads:
EA1 ⊢Γ, ∆(⃗a,⃗b) if EA0(I;O) ⊢∆(⃗x;⃗b). When embedding EA1 into EA(I;O)∗
∞
we deal with this axiom by appealing to the previously mentioned embedding of
EA0(I;O) with ordinal height γ1 from which the closure rule will give a derivation
of height d, γ1 for any d. All the other rules of EA1 are just logic and will embed
with a ﬁnite measure d in front of the (now ﬁxed) γ1. Furthermore, without any
inputs present in EA1, the input declaration n may be set to 0.
EA1(I;O) is formed from EA1 by the addition of the predicative induction rule
up to input constants x. We must therefore extend the embedding of EA1 to include
this case. The γ1 will remain ﬁxed whilst embedding inductions will force the
ﬁnite measure d to become inﬁnite. Hence embedding EA1(I;O) into EA(I;O)∗
∞
yields ordinal bounds γ2, γ1.
The induction step is straightforward using the same argument as the base case.
Assume the result holds for k so that EAk(I;O) embeds with ordinals γk+1, . . . , γ1.
Then using this result to embed any use of the closure axiom in EAk+1 we obtain

498
Elliott J. Spoors and Stanley S. Wainer
ordinal bounds d, γk+1, . . . , γ1 for d ∈N. From here, an embedding of EAk+1(I;O)
will require the ﬁnite d to become an inﬁnite γk+2. This completes the proof of (*).
The result now follows by the usual argument. Let ⃗γ denote γk, . . . , γ1. For
a provably computable function f, we embed the EAk proof of ∀⃗a∃bC f (⃗a, b) into
EA(I;O)∗
∞which by (*), inversions and cut reduction gives 0; m ⊢d,⃗γ ∃bC f (⃗m, b) for
some |γi| < ε0. This derivation may be term controlled by weakening the d to some
d′ ∈N and each γi to some δ+γi. The witnessing result now shows that ∃bC f (⃗m, b)
is true at Bd,⃗γ(0; m) which by Lemma 24 is a function in Ek+2. Hence f itself is in
Ek+2.
□
References
[1] P. Axt. Iteration of primitive recursion. Zeitschrift f¨ur Mathematische Logik
und Grundlagen der Mathematik, 11:253–255, 1965.
[2] S. Bellantoni. Predicative recursion and computational complexity. Ph.D. the-
sis, University of Toronto, 1992.
[3] S. Bellantoni. Ranking arithmetic proofs by implicit ramiﬁcation. In Proof
of Complexity and Feasible Arithmetics, DIMACS Ser. Discrete Math. and
Theoretical Computer Science, 39:37–57, 1998.
[4] S. Bellantoni and S. Cook. A new recursion-theoretic characterization of the
polytime functions. Computational Complexity, 2:97–110, 1992.
[5] S. Bellantoni and K-H. Niggl. Ranking primitive recursions: the low Grze-
gorczyk classes revisited. SIAM Journal on Computing, 29:401–415, 2000.
[6] U. Berger. Program extraction from normalization proofs. In Typed Lambda
Calculi and Applications, LNCS, 664:91–106, 1993.
[7] A. Cantini. Polytime, combinatory logic and positive safe induction. Archive
for Mathematical Logic, 41:169-189, 2002.
[8] D. Leivant. Intrinsic theories and computational complexity. In Logic and
Computational Complexity, LNCS, 960:177–194, 1995.
[9] G.E. Ostrin and S.S. Wainer. Proof theoretic complexity. In Proof and System-
Reliability, NATO Science Series II, 62:369–397, 2002.
[10] G.E. Ostrin and S.S. Wainer. Elementary arithmetic. Annals of Pure and Ap-
plied Logic, 133:275–292, 2005.

A Hierarchy of Ramified Theories Below PRA
499
[11] H. Schwichtenberg. Content in proofs of list reversal. In Formal Logical Meth-
ods for System Security and Correctness, NATO Science for Peace and Secu-
rity Series, D: Information and Communication Security, 14:267–285, 2008.
[12] H. Schwichtenberg and S. Bellantoni. Feasible computation with higher types.
In Proof and System-Reliability, NATO Science Series II, 62:399–415, 2002.
[13] H. Schwichtenberg and S.S. Wainer. Proofs and computations. ASL Perspec-
tives in Logic, Cambridge University Press, 2012.
[14] E.J. Spoors. A hierarchy of ramiﬁed theories below primitive recursive arith-
metic. Ph.D. thesis, University of Leeds, 2010.
[15] S.S. Wainer. Computing bounds from arithmetical proofs. In Ways of Proof
Theory, Ontos Mathematical Logic, 2:469–486, 2010.
[16] M. Wirz. Wellordering two sorts: a slow-growing proof theory for variable
separation. Ph.D. thesis, Universit¨at Bern, 2005.

500

Representing L-Domains as Information
Systems
Dieter Spreen∗
A logic-oriented representation of L-domains in the style of Scott’s informa-
tion systems is introduced. The category of these new (L-)information sys-
tems with approximable mappings is shown to be equivalent to the category
of L-domains with Scott continuous functions. As a consequence it is Carte-
sian closed. In the paper direct constructions for products and exponents of
L-information systems are presented.
1
Introduction
Information systems and approximable mappings have been introduced by Dana
Scott [15] as a logic-oriented approach to domain theory. As was shown by Larsen
and Winskel [14], the category of bounded-complete algebraic domains with Scott
continuous functions is equivalent to the category of information systems with
approximable mappings. Information system allow the exact solution of domain
equations. As is well known, using domains such solutions are only obtained up to
isomorphism.
In the sequel similar structures were introduced to represent various other im-
portant classes of domains, like dI-domains, coherence spaces or SFP domains
[19, 7, 21, 23, 24], to mention just a few.
Nearly all these formalisms represent only subclasses of algebraic domains.
Hoofman [10] and Vickers [18] were the ﬁrst to present a generalization of infor-
mation systems to the continuous case. Hoofman’s continuous information systems
are in the spirit of Scott’s information systems. They consist of a set of tokens rep-
resenting bits of information, a consistency predicate on ﬁnite sets of tokens and
an entailment relation between consistent sets of tokens, but they capture only the
bounded-complete continuous domains. Vicker’s approach is more general and
∗This research has been supported by the German Research Foundation (DFG) under grants no. 446
CHV 113/240/0-1, no. 436 RUS 113/850/0-1(R) and no. 445 SUA-113/20/0-1

502
Dieter Spreen
allows to represent all continuous domains. However, it is not Scott-style: he con-
siders transitive dense relations.
In [16] a Scott-style treatment of the general case was presented. Continu-
ous information systems were introduced and the equivalence of the category of
these information systems with approximable mappings with the category of ab-
stract bases and approximable relations was derived. As is well known, the latter
category is equivalent to the category of continuous domains and Scott continu-
ous functions [1]. Moreover, the continuous information systems corresponding
to several important types of continuous domains were characterized. The case of
L-domains, however, was left open.
L-domains were independently introduced by Coquand [5] and Jung [11]. As
was shown by Jung [11, 12], they form a maximal Cartesian closed full subcat-
egory of the continuous domains. In the present paper a subclass of continuous
information systems, called L-information systems, is deﬁned capturing exactly
the L-domains.
It is shown that the category of L-information systems and approximable map-
pings is equivalent to the category of L-domains and Scott continuous functions.
As a consequence many important properties such as the existence of a terminal el-
ement, ﬁnite products and exponents carry over from L-domains to L-information
systems. We will, however, present direct constructions in all these cases. This
provides a way to explicitly identifying basis sets in these cases, in particular for
function spaces and Cartesian products.
Scott’s original motivation for the introduction of information systems was to
provide a more concrete approach to (abstract) domain theory. Therefore, he pre-
sented information system analogues of the domain constructions usually needed
in giving a denotational programming language semantics.
Especially, the construction of exponents requires special attention in our case.
Due to the rather weak conditions which in the L-domain case allow the con-
struction of step functions from single-step functions, it turned out to be not just
a straightforward generalization of Scott’s construction for algebraic bounded-
complete domains. The construction resembles the one for biﬁnite domains [21]. In
the L-domain case, however, ﬁnite sets of base elements may have inﬁnitely many
minimal upper bounds.
Note that a logic-oriented approach to L-domains has also been presented by
Zhang [22]. However, the representation considered in that paper is motivated by
Gentzen-style proof systems and therefore diﬀers from Scott’s original approach.
Moreover, only algebraic L-domains are captured and the function space construc-
tion is not considered.
Information systems possess basic features of a logic. Its language, however, is
too parsimonious to serve as a basis for program logics. In his Domain Theory in

Representing L-Domains as Information Systems
503
Logical Form Abramsky [2] allowed information tokens be combined by proposi-
tional connectives. Following this approach, Chen and Jung [4] developed a logic
for describing algebraic L-domains. A similarly rich logic for coherent continuous
domains was presented in [13].
Central results of the present research have been presented at the workshops
“Logic and Information: From Logic to Constructive Reasoning”, Berne, 2007,
and “PCC—Proof, Computation, Complexity”, Swansea, 2007.
The paper is organized as follows: Section 2 gives a short introduction to do-
mains. In Section 3 continuous information systems are deﬁned and important
facts from [16] are recalled. Moreover, a terminal object and ﬁnite products are
constructed. L-information systems are introduced in Section 4. It is shown that
under the relationship between informations systems and domains considered in
[16], L-information systems and L-domains correspond to each other. In Section 5
approximable mappings are studied and the equivalence between the category of
L-information systems and approximable mappings and the category of L-domains
and Scott continuous functions is derived. The function space construction is pre-
sented in Section 6 and in Section 7 it is veriﬁed that the L-information system thus
obtained is indeed the categorical exponent. As a consequence the Cartesian clo-
sure of the category of L-information systems follows. Final remarks can be found
in Section 8.
2
Domains: basic deﬁnitions and results
For any set A, we write X ⊆ﬁn A to mean that X is ﬁnite subset of A.
Let (D, ⊑) be a poset. D is pointed if it contains a least element ⊥. For an
element x ∈D, ↓x denotes the principal ideal generated by x, i.e., ↓x = { y ∈D |
y ⊑x }. A subset S of D is directed, if it is nonempty and every pair of elements in
S has an upper bound in S . D is a directed-complete partial order (dcpo), if every
directed subset S of D has a least upper bound F S in D.
Assume that x, y are elements of a poset D. Then x is said to approximate y,
written x ≪y, if for any directed subset S of D the least upper bound of which
exists in D, the relation y ⊑F S always implies the existence of some u ∈S with
x ⊑u. Moreover, x is compact if x ≪x. A subset B of D is a basis of D, if
for each x ∈D the set ↓↓Bx = { u ∈B | u ≪x } contains a directed subset with
least upper bound x. Note that the set of all compact elements of D is included in
every basis of D. A directed-complete partial order D is said to be continuous (or
a continuous domain) if it has a basis and it is called algebraic (or an algebraic
domain) if its compact elements form a basis. In the sequel we will always assume
that continuous domains come equipped with a regular basis. Standard references

504
Dieter Spreen
for domain theory and its applications are [9, 8, 1, 17, 3, 6].
Deﬁnition 1. Let D and D′ be posets. A function f : D →D′ is Scott continuous if
it is monotone and for any directed subset S of D with existing least upper bound,
G
f(S ) = f(
G
S ).
With respect to the pointwise order the set [D →D′] of all Scott continuous
functions between two dcpo’s D and D′ is a dcpo again. Observe that it need not
be continuous even if D and D′ are. This is the case, however, if D′ is an L-domain
[1].
Deﬁnition 2. A pointed continuous domain D is an L-domain, if each pair x, y ∈D
bounded by z ∈D has a least upper bound x ⊔z y in ↓z.
As has been shown by Jung [11, 12], the category L of L-domains is one of
the two maximal Cartesian closed full subcategories of the category CONT⊥of
pointed continuous domains and Scott continuous maps. The same holds for the
category aL of algebraic L-domains with respect to the category ALG⊥of pointed
algebraic domains. The one-point domain is the terminal object in these categories
and the categorical product D × E of two domains D and E is the Cartesian product
of the underlying sets ordered coordinatewise.
Lemma 3 ([6]). Let D be an L-domain and x1, x2 ∈D with upper bounds y, z ∈D.
Then the following two statements hold:
1. If y, z have an upper bound in D, then x1 ⊔y x2 = x1 ⊔z x2.
2. If x1 ≪y and x2 ≪y, then x1 ⊔y x2 ≪y.
Deﬁnition 4. A basis B of a pointed directed-complete partial order is an L-basis if
for each w ∈B the poset ↓↓Bw contains a least upper bound Fw F, for each nonempty
F ⊆ﬁn ↓↓Bw.
Proposition 5. Let D be an L-domain with basis B. Then
L(B) = {
w
G
F | w ∈B ∧F ⊆ﬁn ↓↓Bw }
is an L-basis of D.
Proof. Note that because of the interpolation property also B′ = { u ∈B | (∃v ∈
B)u ≪v } is a basis of D. Let u ∈B′. Then there is some v ∈B with u ≪v. Hence,
u = Fv{u}, which shows that B′ ⊆L(B). Thus, L(B) is a basis of D as well.

Representing L-Domains as Information Systems
505
Now, let Fu F, Fv G, Fw H ∈L(B) with Fu F, Fv G ≪Fw H. Then x ⊑
Fu F ≪w, for all x ∈F; similarly for G. Thus, Fw F ⊑Fu F ≪u, which
implies that Fu F = Fw F. In the same way we obtain that Fv G = Fw G. With
Lemma 3(2) it therefore follows that Fw(F ∪G) = Fu F ⊔w Fv G ≪Fw H.
□
L-bases have also been studied in [20].
3
Continuous information systems
As has been shown in [16], continuous domains can be represented in a logic-
oriented way by information systems.
Deﬁnition 6. Let A be a set, Con a collection of ﬁnite subsets of A and ⊢⊆Con ×A.
Then (A, Con, ⊢) is a continuous information system if the following six conditions
hold for all sets X, Y ∈Con, elements a ∈A and ﬁnite subsets F of A:1
1. {a} ∈Con,
2. X ⊢a ⇒X ∪{a} ∈Con,
3. (Y ⊇X ∧X ⊢a) ⇒Y ⊢a,
4. (X ⊢Y ∧Y ⊢a) ⇒X ⊢a,
5. X ⊢a ⇒(∃Z ∈Con)(X ⊢Z ∧Z ⊢a),
6. X ⊢F ⇒(∃Z ∈Con)(Z ⊇F ∧X ⊢Z),
where X ⊢Y means that X ⊢b, for all b ∈Y.
In the general case of continuous domains no canonical witness for a ﬁnite set
to be consistent is at hand. So, every consistent set is required to contain its consis-
tency witness. As a consequence subsets of consistent sets may be not consistent:
its consistency witness has to be added ﬁrst. The explains the presence of Condi-
tion 6(6).
Note that Conditions 6(5) and (6) can be replaced by a single requirement.
Proposition 7 ([16]). Let A be a nonempty set, Con be a collection of ﬁnite subsets
of A and ⊢⊆Con ×A such that Conditions 6(2, 3) hold. Then Requirements 6(5, 6)
together are equivalent to the following statement:
(∀X ∈Con)(∀F ⊆ﬁn A)[X ⊢F ⇒(∃Z ∈Con)(X ⊢Z ∧Z ⊢F)].
1Note that the restriction in the original deﬁnition that F should be nonempty has to be dropped.
With the stronger notion all results in [16] hold.

506
Dieter Spreen
If (A, Con, ⊢) is a continuous information system then the elements of A are usu-
ally called tokens, the sets in Con consistent and the relation ⊢entailment relation.
Tokens should be thought of as atomic propositions giving information about data
and consistent sets as representing consistent ﬁnite conjunctions of such proposi-
tions. The entailment relation then tells us which propositions are derivable from
what.
In this formalism each element of a data structure corresponds to the set of all
atomic statements that can be made about it. Characteristic properties of such col-
lections of tokens are that any ﬁnite subcollection is consistent, the collection is
closed under deduction, and any of its tokens is derivable from some ﬁnite consis-
tent subcollection.
Deﬁnition 8. Let (A, Con, ⊢) be a continuous information system. A subset x of A
is a state of (A, Con, ⊢) if the next three conditions hold:
1. (∀F ⊆ﬁn x)(∃Y ∈Con)(F ⊆Y ∧Y ⊆x),
2. (∀X ∈Con)(∀a ∈A)(X ⊆x ∧X ⊢a ⇒a ∈x),
3. (∀a ∈x)(∃X ∈Con)(X ⊆x ∧X ⊢a).
Similarly to Proposition 7 the requirement that F ⊆Y in 8(1) can be replaced
by an entailment condition.
Proposition 9 ([16]). Let (A, Con, ⊢) be a continuous information system and x be
a subset of A such that Condition 8(3) holds. Then Requirement 8(1) is equivalent
to the following statement:
(∀F ⊆ﬁn x)(∃Y ∈Con)(Y ⊆x ∧Y ⊢F).
With respect to set inclusion the states of A form a partially ordered set which
we denote by |A|.
Proposition 10 ([16]). Let (A, Con, ⊢) be a continuous information system. Then
D(A) = (|A|, ⊆) is a continuous domain with regular basis d
Con = { bX | X ∈Con },
where bX = { a ∈A | X ⊢a }. Moreover, for x, y ∈|A|,
x ≪y ⇔(∃V ∈Con)(V ⊆y ∧V ⊢x).
If, conversely, (D, ⊑) is a continuous domain with basis B, set
Con = { X ⊆ﬁn B | X directed with respect to ⊑}
and deﬁne
X ⊢u ⇔(∃v ∈X)u ≪v,
for X ∈Con and u ∈B. Then the next statement follows as in [16].

Representing L-Domains as Information Systems
507
Proposition 11. Let D be a continuous domain with basis B. Then C(D, B) =
(B, Con, ⊢) is a continuous information system so that the domains D(C(D, B)) and
D are isomorphic.
The isomorphism is given by the two functions dsD ∈[D →|C(D, B)|] and
spD ∈[|C(D, B)| →D]:
dsD(x) = ↓↓Bx,
spD(z) =
G
z.
The next two results characterize those continuous information systems that
generate algebraic and/or pointed domains.
Proposition 12. Let (A, Con, ⊢) be a continuous information system. Then |A| is
algebraic if, and only if, (A, Con, ⊢) satisﬁes the following requirement
(∀X, Y ∈Con)[X ⊢Y ⇒(∃Z ∈Con)(X ⊢Z ∧Z ⊢Z ∧Z ⊢Y)].
(ALG)
Obviously, the extra requirement (ALG) entails Condition 6(5). A continuous
information system satisfying Condition (ALG) is also called algebraic informa-
tion system.
Proposition 13. Let (A, Con, ⊢) be a continuous information system. Then |A| is
pointed if, and only if, ∅∈Con or there is some a ∈A with X ⊢a, for all X ∈Con.
Deﬁnition 14. Let (A, Con, ⊢) be a continuous information system. A truth element
of A is an element t ∈A satisfying the following two conditions:
1. (∀X ∈Con)X ⊢t
2. (∀X ∈Con)(∀c ∈A)[U ∪{t} ⊢c ⇒U ⊢c]
Next we will show how the one-point domain and the product of continuous
domains can be generated from continuous information systems.
Proposition 15. Let T = ({•}, {{•}}, {({•}, •)}). Then T is an algebraic information
system and |T| is the one-point domain.
Now, let (A0, Con0, ⊢0) and (A1, Con1, ⊢1) be continuous information systems
and pr0 and pr1, respectively, be the canonical projections of A0 × A1 onto the ﬁrst
and second component. Set A× = A0 × A1,
Con× = { X ⊆ﬁn A× | pr0(X) ∈Con0 ∧pr1(X) ∈Con1 }
and for X ∈Con× and (a0, a1) ∈A× deﬁne
X ⊢× (a0, a1) ⇔pr0(X) ⊢0 a0 ∧pr1(X) ⊢a1.
Then (A×, Con×, ⊢×) is a continuous information system, the product of (A0,
Con0, ⊢0) and (A1, Con1, ⊢1).

508
Dieter Spreen
Lemma 16. For z ∈|A×| and i = 0, 1 the following two statements hold:
1. pri(z) ∈|Ai|.
2. z = pr0(z) × pr1(z).
Proof. (1) Without restriction let i = 0 and z be nonempty. We only verify Con-
dition 8(2), the other two being obvious. Let Y0 ∈Con0 be a subset of pr0(z) and
a0 ∈A0 with Y0 ⊢0 a0. Then there is some X ∈Con× with X ⊆z. Let a1 be some
element of pr1(z). By Condition 8(3) there is some Z ⊆z with Z ∈Con× so that
pr1(Z) ⊢1 a1. Apply Condition 8(1) to obtain some V ∈Con× with X ∪Z ⊆V ⊆z.
It follows that V ⊢× (a0, a1), which implies that (a0, a1) ∈z. Hence a0 ∈pr0(z).
(2) follows similarly.
□
Proposition 17. Let (A0, Con0, ⊢0) and (A1, Con1, ⊢1) be continuous information
systems. Then (A×, Con×, ⊢×) is a continuous information system as well and the
domains |A×| and |A0| × |A1| are isomorphic. Moreover:
1. If both A0 and A1 have a truth element, so does A×.
2. If A0 and A1 are both algebraic, then A× is algebraic too.
4
L-information systems
The following deﬁnition captures essential properties of local least upper bounds.
Deﬁnition 18. Let (A, Con, ⊢) be a continuous information system and F ⊆ﬁn A.
Deﬁne Sup(F) to be the collection of all sets Z ∈Con with F ⊆Z such that for all
Y ∈Con with F ⊆Y, if for some V ∈Con, V ⊢Z ∪Y, then
1. Z ∪Y ∈Con,
2. (∀X ∈Con)[X ⊢Y ⇒X ⊢Z],
3. (∀c ∈A)[Z ∪Y ⊢c ⇒Y ⊢c].
As follows from the correspondence between continuous information systems
and continuous domains, ﬁnite sets in Con represent existing ﬁnite least upper
bounds in the corresponding domain. The conditions above express the idea that,
if Y represents an upper bound of the elements represented by the tokens in F, then
the information coming with Z representing the least upper bound of these elements
must already be contained in the information coming with Y.
Lemma 19.
1. If F ∈Con then F ∈Sup(F).

Representing L-Domains as Information Systems
509
2. If A has a truth element t, then {t} ∈Sup(∅).
The sets in Sup(F) are thought of as representations of local least upper bounds
of the ﬁnite set represented by F. A least upper bound of ﬁnitely many elements
of a principal ideal may have several representations, but they should at least be
equivalent.
Deﬁnition 20. Let (A, Con, ⊢) be a continuous information system and F ⊆ﬁn A.
Two consistent sets Y and Z are equivalent with respect to F, written Y ∼
F Z, if the
following conditions are satisﬁed:
1. F ⊆Y ∧F ⊆Z,
2. (∀X ∈Con)[X ⊢Y ⇔X ⊢Z],
3. (∀c ∈A)[Y ⊢c ⇔Z ⊢c].
Lemma 21. Let F ⊆ﬁn A and Z, Z′ ∈Sup(F) such that V ⊢Z ∪Z′, for some
V ∈Con. Then Z ∼
F Z′.
Let us now introduce the notion of an L-information system. The deﬁnition is
motivated by the second statement in Lemma 3.
Deﬁnition 22. A continuous information system (A, Con, ⊢) is an L-information
system if it contains a truth element and the following condition (L) holds for all
X ∈Con and all nonempty ﬁnite subsets F of A:
X ⊢F ⇒(∃Z ∈Sup(F))X ⊢Z.
(L)
Obviously, Condition (L) strengthens Condition 6(6). An algebraic information
system that has a truth element and satisﬁes Condition (L) is called algebraic L-
information system.
Proposition 23. Let D be an L-domain with L-basis B. Then C(D, B) is an L-
information system.
Proof. As is easily veriﬁed, the smallest element of D is a truth element of C(D, B).
Because of Proposition 11 it remains to show that Condition (L) is satisﬁed. Let to
this end F be a nonempty ﬁnite subset of B and X ∈Con with X ⊢F.
Without restriction, let F < Con. Since X is directed and ﬁnite, it has a maximal
element F X. Moreover, F ⊆↓↓B
F X. Hence F has a least upper bound z in ↓↓B
F X.
Set Z = F ∪{z}. Then Z ⊇F. In addition, Z is directed. Hence Z ∈Con.
Now, let Y ∈Con with Y ⊇F and assume that V ⊢Y ∪Z, for some V ∈Con.
We have to verify Conditions 18(1–3).

510
Dieter Spreen
(1) Since Y and V, respectively, are directed ﬁnite subsets of D, they contain
greatest elements, say y and v. Then we have that y, z ≪v. Moreover, y and z are
upper bounds of F. Let z′ be the least upper bound of F in ↓↓Bv. Then z′ ⊑z. Hence
z′ ≪F X, which implies that z′ = z. As a consequence we have that z ⊑y. Thus
Y ∪Z is directed, i.e. Y ∪Z ∈Con.
(2) Let X′ ∈Con with X′ ⊢Y. Then y ≪x, for some x ∈X′. As we have just
seen, z ⊑y. Thus, z ≪x as well, i.e. X′ ⊢Z.
(3) Let c ∈B with Z ∪Y ⊢c. Then c ≪y, as y is the greatest element of Z ∪Y.
Consequently Y ⊢c.
It follows that Z ∈Sup(F). Since z ≪F X we also have that X ⊢Z.
□
Conversely, we have that every L-information system generates an L-domain.
Proposition 24. Let (A, Con, ⊢) be an L-information system. Then D(A) is an L-
domain with L-basis L(d
Con).
Proof. Because of Propositions 5, 10 and 13 we only have to show that ﬁnite least
upper bounds exist in every principal ideal of D(A).
Let z1, z2, x ∈|A| with z1, z2 ⊆x and set
z = { a ∈A | (∃F ⊆ﬁn z1 ∪z2)(∃X ∈Con)
(∃Z ∈Sup(F))(X ⊆x ∧X ⊢Z ∧Z ⊢a) }.
Then z ⊆x. We will show that z is the least upper bound of z1 and z2 in ↓x.
Claim 3 zi ⊆z, for i = 1, 2.
Proof of Claim. Let a ∈zi. Then, by 8(3), there is a consistent set Y ⊆zi with Y ⊢a.
Since zi ⊆x, we obtain that also Y ⊆x. By Proposition 9, there is then a consistent
set X ⊆x with X ⊢Y. Note that Y ∈Sup(Y). Moreover, Y ⊆z1 ∪z2. It follows that
a ∈z.
Claim 4 z ∈|A|.
Proof of Claim. We have to verify Conditions 8(1–3).
(1) Let G ⊆ﬁn z. We will show that there is a set Y ∈Con with G ⊆Y ⊆z.
For any a ∈G there are sets Fa ⊆ﬁn z1 ∪z2, Xa ∈Con and Za ∈Sup(Fa) so that
Xa ⊢Za, Xa ⊆x and Za ⊢a. Set eF = S{ Fa | a ∈G } and eX = { Xa | a ∈G }. Then
eX ⊆ﬁn x. Hence there is some X ∈Con with eX ⊆X ⊆x. It follows that X ⊢Za, for
every a ∈G. Since Za ⊇Fa, we thus have that X ⊢eF. By Condition (L) there is
some Z ∈Sup(eF) with X ⊢Z. Then Z ⊇eF ⊇Fa, for every a ∈G. Since X ⊢Za and

Representing L-Domains as Information Systems
511
Za ∈Sup(Fa), we obtain for each c ∈A with Za ⊢c that also Z ⊢c. Thus Z ⊢G.
With 6(6) we have that there is some consistent superset Y of G with Z ⊢Y.
It remains to show that Y ⊆z. Let c ∈Y. Then Z ⊢c. Since eF ⊆ﬁn z1 ∪z2,
Z ∈Sup(eF) and X ∈Con such that X ⊢Z and X ⊆x, it follows from the deﬁnition
of z that c ∈z.
(2) Let X ∈Con and a ∈A with X ⊆z and X ⊢a. We need to show that a ∈z.
As above we have for any c ∈X that there are sets Fc ⊆ﬁn z1 ∪z2, Xc ∈Con
und Zc ∈Sup(Fc) such that Xc ⊆x, Xc ⊢Zc and Zc ⊢c. Set eF = S{ Fc | c ∈X } and
eX = S{ Xc | c ∈X }. Then eX ⊆ﬁn x and hence, by 8(1), there is some X ∈Con with
eX ⊆X ⊆x. Since X ⊇Xc, Xc ⊢Zc and Zc ⊇Fc, for c ∈X, we have that X ⊢Fc,
for every c ∈X, i.e. X ⊢eF. Apply Condition (L) to obtain a set Z ∈Sup(eF) with
X ⊢Z. Then Z ⊇eF ⊇Fc, for each c ∈X. Since X ⊢Z ∪Zc and Zc ∈Sup(Fc),
we have for all b ∈A with Zc ⊢b that also Z ⊢b. Remember that Zc ⊢c, for all
c ∈X. Thus Z ⊢X, from which we obtain that Z ⊢a, as X ⊢a, by our assumption.
In addition we have that X ∈Con, eF ⊆ﬁn z1 ∪z2 and Z ∈Sup(eF) with X ⊆x and
X ⊢Z. It follows that a ∈z.
(3) Let a ∈z. We have to show that there is some Y ∈Con with Y ⊆z and
Y ⊢a.
Since a ∈z, there are sets F ⊆ﬁn z1 ∪z2, X ∈Con and Z ∈Sup(F) so that
X ⊆x, X ⊢Z and Z ⊢a. With Condition 6(5) we moreover obtain that there is
some Y ∈Con with Z ⊢Y ⊢a. It remains to show that Y ⊆z. Note hereto that
Z ⊢b, for every b ∈Y, Z ∈Sup(F), F ⊆ﬁn z1 ∪z2, X ⊢Z and X ⊆x.
Claim 5 (∀y ∈|A|)[z1, z2 ⊆y ⊆x ⇒z ⊆y].
Proof of Claim. Let y ∈|A| with z1, z2 ⊆y ⊆x and a ∈z. Then there are sets
F ⊆ﬁn z1 ∪z2, X ∈Con and Z ∈Sup(F) so that X ⊆x, X ⊢Z and Z ⊢a. Since
z1, z2 ⊆y, it follows that F ⊆ﬁn y. By Proposition 9 there is therefore some Y ∈Con
with Y ⊆y and Y ⊢F. With Condition 6(6) we obtain the existence of some set
V ∈Con such that V ⊇F and Y ⊢V. Then V ⊆y, by 8(2). Since y ⊆x, we have
that X ∪V ⊆ﬁn x. Thus there is some X ∈Con with X ⊆x and X ⊢X ∪V. It follows
that X ⊢Z ∪V. Remember that Z ⊢a and Z ∈Sup(F). Therefore V ⊢a as well.
Because V ⊆y, we obtain that a ∈y.
Finally, we prove that d
Con is an L-basis. Let to this end U, V, X ∈Con with b
U, bV ∈
d
Con(bX). Then X ⊢U ∪V. By Condition (L) there is then some Z ∈Sup(U ∪V)
with X ⊢Z. Thus bZ ∈d
Con(bX). Moreover, as Z ⊇U ∪V, we obtain with Condition
6(3) that b
U, bV ⊆bZ.
□
Obviously the one-point information system T is an L-information system.

512
Dieter Spreen
Proposition 25. Let (A0, Con0, ⊢0) and (A1, Con1, ⊢1) be L-information systems.
Then (A×, Con×, ⊢×) is also an L-information system.
Note here that for F ⊆ﬁn A0 × A1 and Zi ∈Supi(pri(F)) (i = 0, 1), Z0 × Z1 ∈
Sup×(F).
The next result shows that self-derivability properties as used in Condition
(ALG) inherit to sets representing local least upper bounds.
Lemma 26. Let (A, Con, ⊢) be an L-information system and U, X1, . . . , Xn ∈Con
such that U ⊢Xi and Xi ⊢Xi, for i = 1, . . . , n. Then Y ⊢Y, for all Y ∈Sup(X1 ∪
· · · ∪Xn) with U ⊢Y.
Proof. Since Y ⊇X1 ∪· · · ∪Xn and Xi ⊢Xi, for i = 1, . . . , n, we have that Y ⊢
X1 ∪· · · ∪Xn. Therefore, by Condition (L), there is some Z ∈Sup(X1 ∪· · · ∪Xn)
with Y ⊢Z. Because U ⊢Y, it follows that U ⊢Y ∪Z. Thus
Y
∼
X1∪···∪Xn Z,
by Lemma 21. As Y ⊢Z, we obtain that Y ⊢Y.
□
5
Approximable mappings
In order to study the relationship between information systems and domains from a
category-theoretic point of view, appropriate morphisms between information sys-
tems have to be introduced.
Deﬁnition 27. Let (A, Con, ⊢) and (A′, Con′, ⊢′) be continuous information sys-
tems. An approximable mapping H between A and A′, written H : A ⊩A′, is a
relation between Con and A′ satisfying for all X, X′ ∈Con, Y ∈Con′ and b ∈A′, as
well as all ﬁnite subsets F of A′ the following six conditions, where Condition (6)
is only required, if A and A′ have truth elements t and t′, respectively:2
1. (XHY ∧Y ⊢′ b) ⇒XHb,
2. XHF ⇒(∃Z ∈Con′)(F ⊆Z ∧XHZ),
3. (X ⊢X′ ∧X′Hb) ⇒XHb,
4. (X ⊇X′ ∧X′Hb) ⇒X′Hb,
5. XHb ⇒(∃Z ∈Con)(∃Z′ ∈Con′)(X ⊢Z ∧ZHZ′ ∧Z′ ⊢′ b),
2Similar to Deﬁnition 6 the restriction on F to be nonempty stated in [16] needs to be dropped.

Representing L-Domains as Information Systems
513
6. {t}Ht′,
where XHY means that XHc, for all c ∈Y.
As follows from Deﬁnition 6, entailment relations are special approximable
morphisms. For X ∈Con and a ∈A set X Id a if X ⊢a. Then Id: A ⊩A such
that for all H : A ⊩A′, H ◦IdA′ = H = IdA ◦H, where for approximable mappings
H : A ⊩A′ and G: A′ ⊩A′′ their composition H ◦G: A ⊩A′′ is deﬁned by
X(H ◦G)c ⇔(∃Y ∈Con′)(XHY ∧YGc).
Let LINF be the category of L-information systems and approximable map-
pings and aLINF the full subcategory of algebraic L-information systems.
Proposition 28. The one-point information system T is a terminal object in aLINF
and LINF.
Proof. Let (A, Con, ⊢) be an L-information system and F = Con ×{•}. It suﬃces
to show that F : A ⊩T. We will only verify Condition 27(5), the other ones being
obvious.
Let to this end X ∈Con and t ∈A be a truth element of A. Then X ⊢t.
Moreover, {t} ∈Con, {t}F{•} and {•} ⊢T •.
□
For two L-information systems (A0, Con0, ⊢0) and (A1, Con1, ⊢1) deﬁne the re-
lations Pri ⊆Con× ×Ai (i = 0, 1) by
X Pri ai ⇔pri(X) ⊢i ai
Lemma 29. For i = 0, 1, Pri : A× ⊩Ai
Proof. Again, we only verify Condition 27(5). Let X ∈Con× and ai ∈Ai with
X Pri ai. Then pri(X) ⊢i ai. Hence there are Zi, Z′
i ∈Coni so that pri(X) ⊢i Zi ⊢i Z′
i ⊢i
ai. Let t1−i be a truth element of A1−i. Then pr1−i(X) ⊢1−i t1−i. Set Z = Z0 × {t1}, if
i = 0, and Z = {t0} × Z1, otherwise. We obtain that X ⊢× Z Pri Z′
i ⊢i ai.
□
Proposition 30. For L-information systems A0 and A1, (A×, Pr0, Pr1) is their cate-
gorical product.
Note that for approximating mappings F0 : A ⊩A0 and F1 : A ⊩A1 the mediat-
ing morphism ⟨F0, F1⟩: A ⊩A× is given by
X⟨F0, F1⟩(a0, a1) ⇔pr0(X)F0a0 ∧pr1(X)F1a1.

514
Dieter Spreen
As we have seen above, there is a close connection between L-information sys-
tems and L-domains. It can be extended to the corresponding morphisms, i.e. ap-
proximable mappings and Scott continuous functions, so that we obtain an equiva-
lence between LINF and L.
Let D and D′ be L-domains with L-bases B and B′, respectively. For f ∈[D →
D′] deﬁne the relation C( f) ⊆ConC(D,B) ×B′ by
XC( f)a ⇔(∃c ∈X)a ≪′ f(c).
Lemma 31. C( f): C(D, B) ⊩C(D′, B′)
Next, let A, A′ be L-information systems and H : A ⊩A′. For x ∈|A| set
D(H)(x) = { b ∈A′ | (∃X ∈ConA)(X ⊆x ∧XHb) }.
Lemma 32. D(H) ∈[D(A) →D(A′)].
Both results follow as in [16]. It is readily seen that C: L →LINF and D :
LINF →L are functors. As will be shown in what follows, they constitute an
equivalence between both categories.
For a category C let IC be the identical functor on C. We ﬁrst show that there
is a natural isomorphism τ: IL →D ◦C. Let to this end D be an L-domain
with L-basis B. Then D(C(D, B)) = (|B|, ⊆). As we have seen in Section 3, the
domains D and D(C(D, B)) are isomorphic via the functions dsD ∈[D →|B|] and
spD ∈[|B| →D]. Set τD = dsD.
Proposition 33. τ: IL →D ◦C is a natural isomorphism.
Proof. It remains to show that for L-domains D and D′ with L-bases B and B′,
respectively, and a function f ∈[D →D′],
τD′ ◦f = D(C(f)) ◦τD.
Let x ∈D and remember that τD(x) = ↓↓Bx. Then
τD′(f(x))
= { u ∈B′ | u ≪′ f(x) }
= { u ∈B′ | (∃v ∈B)(v ≪x ∧u ≪′ f(v)) }
= { u ∈B′ | (∃v ∈τD(x))u ≪′ f(v) }
= { u ∈B′ | (∃X ∈ConC(D,B))(X ⊆τD(x) ∧(∃v ∈X)u ≪′ f(v)) }
= { u ∈B′ | (∃X ∈ConC(D,B))(X ⊆τD(x) ∧XC( f)u) }
= D(C(f))(τD(x)).
□

Representing L-Domains as Information Systems
515
Next, we show that there is also a natural isomorphism η: ILINF →C ◦D.
Let (A, Con, ⊢) be an L-information system. Then C(D(A)) = (d
Con, ConC(D(A)),
⊢C(D(A)))3, where ConC(D(A)) is the collection of all ﬁnite subsets of d
Con that are
directed with respect to set inclusion, and
X ⊢C(D(A)) bX ⇔(∃bZ ∈X)(∃U ∈Con)(Z ⊢U ∧U ⊢bX),
for X ∈ConC(D(A)) and bX ∈d
Con. Set
S A = { (X, bY) ∈Con ×d
Con | {bX} ⊢C(D(A)) bY },
TA = { (X, a) ∈ConC(D(A)) ×A | (∃bZ ∈X)Z ⊢a }.
Lemma 34.
1. S A : A ⊩C(D(A)).
2. TA : C(D(A)) ⊩A.
Proof. (1) Conditions 27(1–4, 6) are readily veriﬁed. We only verify the remaining
one. Let to this end X ∈Con and bY ∈d
Con with XS AbY. Then {bX} ⊢C(D(A)) bY. Hence
there is some Z ∈ConC(D(A)) such that {bX} ⊢C(D(A)) Z ⊢C(D(A)) bY. The ﬁrst of the
two entailment statements means that {bX} ⊢C(D(A)) bZ, for all bZ ∈Z. It follows that
there are UbZ, U′
bZ ∈Con, for each bZ ∈Z, with X ⊢UbZ ⊢U′
bZ ⊢Z. As a consequence
there is some V ∈Con such that V ⊇S{ UbZ | bZ ∈Z }, X ⊢V and V ⊢U′
bZ ⊢bZ.
So we have that there is some V ∈Con and some Z ∈ConC(D(A)) with X ⊢V,
{bV} ⊢C(D(A)) Z and Z ⊢C(D(A)) bZ.
(2) Again we only consider Condition 27(5). Let X ∈ConC(D(A)) and a ∈A with
XTAa. Then there is some X ∈X with X ⊢a. It follows that there are U, V, Z ∈Con
so that X ⊢U ⊢V ⊢Z ⊢a. Thus X ⊢U ⊢bV. Set Z = {bV}. Then we have that
X ⊢C(D(A)) Z, ZTAZ and Z ⊢a.
□
Lemma 35.
1. S A ◦TA = IdA.
2. TA ◦S A = IdC(D(A)).
3Since the basis is clear from the context, we write C(D(A)) instead of C(D(A), d
Con) in this case.

516
Dieter Spreen
Proof. (1) Let X ∈Con and a ∈A. Then we have that
X(S A ◦TA)a
⇔(∃Y ∈ConC(D(A)))(XS AY ∧YTAa)
⇔(∃Y ∈ConC(D(A)))(∀bY ∈Y)({bX} ⊢C(D(A)) bY ∧(∃bY ∈Y)Y ⊢a)
⇔(∃Y ∈ConC(D(A)))(∀bY ∈Y)
(∃U ∈Con)(X ⊢U ∧U ⊢bY ∧(∃bY ∈Y)Y ⊢a)
⇔X ⊢a.
The left-to-right implication in the last line is obvious. For the converse direction
note that from X ⊢a we obtain that X ⊢U ⊢Z ⊢a, for some U, Z ∈Con. Set
Y = {bZ}.
(2) Next, let X ∈ConC(D(A)) and bX ∈d
Con. Then we obtain
X(TA ◦S A)bX
⇔(∃Y ∈Con)(XTAY ∧YS AbX)
⇔(∃Y ∈Con)(∃Z ∈X)(Z ⊢Y ∧{bY} ⊢C(D(A)) bX)
⇔(∃Y ∈Con)(∃Z ∈X)(Z ⊢Y ∧(∃U ∈Con)Y ⊢U ∧U ⊢bX)
⇔(∃Z ∈X)(∃U ∈Con)(Z ⊢U ∧U ⊢bX)
⇔X ⊢C(D(A)) bX.
□
Let ηA = S A.
Proposition 36. η: ILINF →C ◦D is a natural isomorphism.
Proof. We only have to show that for L-information systems (A, Con, ⊢) and (A′,
Con′, ⊢′) and an approximable mapping H : A ⊩A′
ηA ◦C(D(H)) = H ◦ηA′.
Note to this end that for X ∈ConC(D(A)) and X′ ∈C(D(A′)),
XC(D(H))b
X′
⇔(∃bZ ∈X)b
X′ ≪D(A′) D(H)(bZ)
⇔(∃bZ ∈X)(∃V ∈Con′)(V ⊆D(H)(bZ) ∧V ⊢′ b
X′)
⇔(∃bZ ∈X)(∃V ∈Con′)(∃U ∈Con)(U ⊆bZ ∧UHV ∧V ⊢′ b
X′)
⇔(∃bZ ∈X)(∃V ∈Con′)(∃U ∈Con)(Z ⊢U ∧UHV ∧V ⊢′ b
X′)
⇔(∃bZ ∈X)(∃V ∈Con′)(ZHV ∧V ⊢′ b
X′).

Representing L-Domains as Information Systems
517
Then we have for X ∈Con and b
Y′ ∈C(D(A′)) that
X(ηA ◦C(D(H)))b
Y′
⇔(∃V ∈ConC(D(A)))(XS AV ∧VC(D(H))b
Y′)
⇔(∃V ∈ConC(D(A)))({bX} ⊢C(D(A)) V ∧VC(D(H))b
Y′)
⇔{bX}C(D(H))b
Y′
⇔(∃V ∈Con′)(XHV ∧V ⊢′ b
Y′)
⇔(∃W, V ∈Con′)(XHW ∧W ⊢′ V ∧V ⊢′ b
Y′)
⇔(∃W ∈Con′)(XHW ∧{b
W} ⊢C(D(A′)) b
Y′)
⇔(∃W ∈Con′)(XHW ∧WS A′ b
Y′)
⇔X(H ◦ηA′)b
Y′.
□
Together with Proposition 33 we now obtain what we were aiming for in this
section.
Theorem 37. The category LINF of L-information systems and approximable
mappings is equivalent to the category L of L-domains and Scott continuous func-
tions.
Corollary 38. The category aLINF of algebraic L-information systems and ap-
proximable mappings is equivalent to the category aL of algebraic L-domains and
Scott continuous functions.
6
The function space construction
As has already been mentioned, the categories L and aL are Cartesian closed. Be-
cause of the equivalence of these categories with LINF and aLINF, respectively,
we know that the latter categories are Cartesian closed as well. However, this means
that in concrete cases we have to pass back and forth between information systems
and domains in order to construct the exponent of two L-information systems. In
this and the next section we show how this can be done within LINF and aLINF,
respectively. To this end we show how the collection of approximable mappings
between two L-information systems can be represented as an L-information sys-
tem again. We start with discussing what will be the tokens of this new information
system.
Let (A1, Con0, ⊢0) and (A1, Con1, ⊢1) be L-information systems. Moreover, for

518
Dieter Spreen
V ⊆ﬁn Con0 × Con1 and Y ∈Con0 set
ET0(Y, V) =
[
{ X ∈pr0(V) | Y ⊢0 X },
ET1(Y, V) =
[
{ E ∈Con1 | (∃X ∈Con0)((X, E) ∈V ∧Y ⊢0 X) }.
Deﬁnition 39. Let V ⊆ﬁn Con0 × Con1. W ⊆Con0 × Con1 is a joinable extension
of V, if V ⊆W and the following ﬁve conditions hold:
1. For all Y ∈Con0 there are S ∈Sup0(ET0(Y, V)) and T ∈Sup1(ET1(Y,
V)) so that Y ⊢0 S and (S, T) ∈W.
2. For all (S, T) ∈W either (S, T) ∈V or there is some Y ∈Con0 such that
S ∈Sup0(ET0(Y, V)), Y ⊢0 S , and T ∈Sup1(ET1(Y, V)).
3. For all (S, T), (S ′, T ′) ∈W \ V and all Y ∈Con0,
(S
∼
ET0(Y,V) S ′ ∧T
∼
ET1(Y,V) T ′) ⇒(S, T) = (S ′, T ′).
4. For all (S, T), (S ′, T ′) ∈W, if there are Y, Y′ ∈Con0 such that S
∈
Sup0(ET0(Y, V)) and T ∈Sup1(ET1(Y, V)) as well as S ′ ∈Sup0(ET0(Y′, V))
and T ′ ∈Sup1(ET1(Y′, V)), and if Y′′ ⊢0 S ∪S ′, for some Y′′ ∈Con0, then
there is some Z ∈Con1 with Z ⊢1 T ∪T ′.
Let JE(V) be the set of all joinable extensions of V.
Lemma 40. Let V ⊆ﬁn Con0 × Con1, W ∈JE(V) and Y ∈Con0. Then the following
two statements hold:
1. { (X, E) ∈W | Y ⊢0 X } is ﬁnite.
2. ET0(Y, W) ∈Con0 and ET1(Y, W) ∈Con1.
Proof. (1) Let (X′, E′), (X′′, E′′) ∈W\V with Y ⊢0 X′∪X′′. Then there are Y′, Y′′ ∈
Con0 such that Y′ ⊢0 X′, X′ ∈Sup0(ET0(Y′, V)) as well as E′ ∈Sup1(ET1(Y′, V)),
and Y′′ ⊢0 X′′, X′′ ∈Sup0(ET0(Y′′, V)) as well as E′′ ∈Sup1(ET1(Y′′, V)). Assume
that { eX ∈pr0(V) | Y′ ⊢0 eX } = { eX ∈pr0(V) | Y′′ ⊢0 eX }. Then ET0(Y′, V) =
ET0(Y′, V) (= G, say) and ET1(Y′, V) = ET1(Y′′, V) (= H, say). Since Y ⊢0
X′ ∪X′′, it follows with Lemma 21 that X′ ∼
G X′′. Moreover, because of 39(4),
there is some V ∈Con1 with V ⊢1 E′ ∪E′′. Therefore we also have that E′ ∼
H E′′.
Thus (X′, E′) = (X′′, E′′), by 39(3).
This shows that the number of pairs (X, E) ∈W \ V with Y ⊢0 X is bounded by
the cardinality of the powerset of pr0(V). Since V is ﬁnite, the powerset of pr0(V)
is ﬁnite as well. Consequently, there are only ﬁnitely many (X, E) ∈W with Y ⊢0 X.

Representing L-Domains as Information Systems
519
(2) By Condition 39(1) there is some (S, T) ∈W such that Y ⊢0 S , S ∈
Sup0(ET0(Y, V)), and T ∈Sup1(ET1(Y, V)). In particular we have that S ∈Con0
and T ∈Con1. As we have seen in (1), there are only ﬁnitely many (X, E) ∈W
with Y ⊢0 X, say (X0, E0), . . . , (Xn, En). Without restriction, let (X0, E0) = (S, T)
and assume for i < n that X0 ∪· · · ∪Xi ∈Con0 as well as E0 ∪· · · ∪Ei ∈Con1.
By construction (Xi+1, Ei+1) ∈V or there is some Y ∈Con0 such that Y ⊢0 Xi+1,
Xi+1 ∈Sup0(ET0(Y, V)) and Ei+1 ∈Sup1(ET1(Y, V)). In the ﬁrst case, Xi+1 ⊆
ET0(Y, V) ⊆X0 and Ei+1 ⊆ET1(Y, V) ⊆E0.
In the other case, if (U, V) ∈V with Y ⊢0 U, then U ⊆Xi+1. Thus, Y ⊢0 U,
which implies that ET0(Y, V) ⊆ET0(Y, V) ⊆X0 ⊆X0 ∪· · · ∪Xi and ET1(Y, V) ⊆
ET1(Y, V) ⊆E0 ∪· · · ∪Ei. Moreover, Y ⊢0 X0 ∪· · · ∪Xi+1. As we have just
seen, for j = 1, . . . , i + 1, (X j, E j) is such that either Xj ⊆X0 and E j ⊆E0, or
(Xj, E j) ∈W \ V. Therefore, by Condition 39(4), there is some Z ∈Con1 so that
Z ⊢1 E0 ∪· · · ∪Ei+1. With 18(1) we thus obtain that X0 ∪· · · ∪Xi+1 ∈Con0 and
E0 ∪· · · ∪Ei+1 ∈Con1. This concludes the induction. For i = n we obtain that
ET0(Y, W) ∈Con0 and ET1(Y, W) ∈Con1.
□
Lemma 41. Let t0 and t1, respectively, be truth elements of A0 and A1, and (X, Z) ∈
Con0 × Con1 such that Z′ ⊢1 Z, for some Z′ ∈Con1. Then {(X, Z)} ∈JE({(X, Z)}), if
Y ⊢0 X, for all Y ∈Con0. Otherwise, {(X, Z), ({t0}, {t1})} ∈JE({(X, Z)}).
Lemma 42. Let U′ ⊆ﬁn Con0 × Con1 and U be a family of pairs (XY, ZY) ∈
Con0 × Con1, for Y ∈Con0, with the following properties:
1. Y ⊢0 XY,
2. XY ∈Sup0(ET0(Y, U′)),
3. ZY ∈Sup1(ET1(Y, U′)),
4. (∀Y, Y′, Y ∈Con0)(∃Z ∈Con1)(Y ⊢0 XY ∪XY′ ⇒Z ⊢1 ZY ∪ZY′).
Then there is some U ∈JE(U′) such that
1. U ⊆U′ ∪U,
2. (∀(X, Z) ∈U)(∃(S, T) ∈U)(∃Y ∈Con0)(X
∼
ET0(Y,U′) S ∧Z
∼
ET1(Y,U′) T).
Proof. For every Y ∈Con0, let { (S i, Ti) | i ∈IY } be a system of representatives of
the set { (S, T) ∈U | S ∈Sup0(ET0(Y, U′)) ∧T ∈Sup1(ET1(Y, U′)) } with respect to
the equivalence relation
∼
ET0(Y,U′) ×
∼
ET1(Y,U′) .

520
Dieter Spreen
Set U = U′ ∪{ (S i, Ti) | (∃Y ∈Con0)i ∈IY }. We will show that U ∈JE(U′).
By construction, U′ ⊆U. The remaining conditions in Deﬁnition 39 are sat-
isﬁed as well: For (1) let Y ∈Con0. Then there is some (XY, ZY) ∈U with the
required properties. It follows that the corresponding representative in U has the
same properties. Conditions (2) and (3) hold by construction and (4) is a conse-
quence of Assumption (4).
□
Now deﬁne
A0 →A1 = { W ⊆Con0 × Con1 | (∃V ⊆ﬁn Con0 × Con1)W ∈JE(V) },
Con→= { W ⊆ﬁn A0 →A1 | (∀Y ∈Con1) ET1(Y,
[
W) ∈Con1 },
W ⊢→V ⇔(∀(Y, Z) ∈V) ET1(Y,
[
W) ⊢1 Z.
Lemma 43. Let W ∈Con→and U, V ∈A0 →A1 such that W ⊢→V and U ⊆V.
Then W ⊢→U.
Proposition 44. Let (A0, Con0, ⊢0) and (A1, Con1, ⊢1) be L-information systems.
Then (A0 →A1, Con→, ⊢→) is an L-information systems as well.
Proof. We ﬁrst have to verify Conditions 6(1–5).
Claim 6 (A0 →A1, Con→, ⊢→) satisﬁes Condition 6(1).
Proof of Claim. Let W ∈A0 →A1 and Y ∈Con0. Then ET1(Y, W) ∈Con1, by
Lemma 40(2), which means that {W} ∈Con→.
Claim 7 (A0 →A1, Con→, ⊢→) satisﬁes Condition 6(2).
Proof of Claim. Assume that W ⊢→V. Then we have for all (Y, Z) ∈V that
ET1(Y,
[
W) ⊢1 Z.
(56)
We have to show that for all Y ∈Con0, ET1(Y, S(W ∪{V})) ∈Con1. Let to this
end Y ∈Con0. Then
ET1(Y,
[
(W ∪{V})) = ET1(Y,
[
W) ∪ET1(Y, V).
Note that ET1(Y, V) is ﬁnite, by Lemma 40. Since W ∈Con→, we have that
ET1(Y, S W) ∈Con1.
With (56) and Conditions 6(2, 3) it follows that also
ET1(Y, S W) ∪Z ∈Con1.

Representing L-Domains as Information Systems
521
Claim 8 (A0 →A1, Con→, ⊢→) satisﬁes Condition 6(3).
Proof of Claim. Let U, W ∈Con→and V ∈A0 →A1 such that U ⊇W and
W ⊢→V. We have to show that also U ⊢→V. Let for this (Y, Z) ∈V. Then
ET1(Y, S W) ⊢→Z. Since U ⊇W, we have that ET1(Y, S W) ⊆ET1(Y, S U).
Thus ET1(Y, S U) ⊢1 Z.
Claim 9 (A0 →A1, Con→, ⊢→) satisﬁes Condition 6(4).
Proof of Claim. Let U, W ∈Con→and V ∈A0 →A1 and assume that U ⊢→
W ⊢→V. We need to show that U ⊢→V. Let (Y, Z) ∈V. Then ET1(Y, S W) ⊢→
Z. For W ∈W and (X, E) ∈W we moreover have that ET(X, S U) ⊢1 E. Since
[
{ ET1(X,
[
U) | (∃W ∈W)(X ∈pr1(W) ∧Y ⊢0 X) } ⊆ET1(Y,
[
U),
it follows that ET1(Y, S U) ⊢1 ET1(Y, S W) and hence that ET1(Y, S U) ⊢1 Z.
Claim 10 (A0 →A1, Con→, ⊢→) satisﬁes Condition 6(5).
Proof of Claim. Let W ∈Con→and V ∈A0 →A1 with W ⊢→V. We have to
construct some U ∈Con→so that W ⊢→U ⊢→V. Let again (Y, Z) ∈V. Then
ET1(Y, S W) ⊢2 Z. Because of Condition 6(5) there is thus some Na ∈Con1, for
each a ∈Z, with ET1(Y, S W) ⊢2 Na ⊢2 a.
In the same way we have for each W ∈W, each X ∈pr0(W) with Y ⊢0 X, and
each d ∈X that there is some MY,X
d
∈Con0 so that Y ⊢0 MY,X
d
⊢0 d. Because of
Lemma 40, ET0(Y, W) is ﬁnite. Since also W is ﬁnite, it follows that ET0(Y, S W)
is ﬁnite as well. By Proposition 7 there is thus some MY ∈Con0 such that
MY ⊇
[
{ MY,X
d
| d ∈ET0(Y,
[
W) }
and
Y ⊢0 MY ⊢0 ET0(Y,
[
W).
Moreover, for every (Y, Z) ∈V there is some NY,Z ∈Con1 so that
NY,Z ⊇
[
{ Na | a ∈Z }
and
ET1(Y,
[
W) ⊢1 NY,Z ⊢1 Z.
Let V′ ⊆ﬁn Con0 × Con1 with V ∈JE(V′) and deﬁne U′ = { (MY, NY,Z) |
(Y, Z) ∈V′ }. Then U′ ⊆ﬁn Con0 × Con1. Now, let Y ∈Con0 and (MY, NY,Z)
∈U′ with Y ⊢0 MY. Then we have for every X ∈pr0(S W) with Y ⊢0 X that
MY ⊢0 X. Hence ET1(Y, S W) ⊆ET1(MY, S W). Therefore,
ET1(MY,
[
W) ⊢1 NY,Z,
(57)

522
Dieter Spreen
which implies that ET1(Y, S W) ⊢1 NY,Z. By Condition (L) it follows that there
are sets S Y ∈Sup0(ET0(Y, U′)) with Y ⊢0 S Y, and TY ∈Sup1(ET1(Y, U′)) with
ET1(Y,
[
W) ⊢1 TY.
(58)
Set U = { (S Y, TY) | Y ∈Con0 }. Then the requirements in Lemma 42 are
satisﬁed. For Condition (4) let Y, Y′ ∈Con0 and (S Y, TY), (S Y′, TY′) ∈U such that
Y ⊢0 S Y ∪S Y′, for some Y ∈Con0. Then ET0(Y, U′) ∪ET0(Y′, U′) ⊆S Y ∪S Y′,
which implies that for all X ∈pr0(U′) with Y ⊢0 X or Y′ ⊢0 X also Y ⊢0 X.
Since by (58), ET1(Y, S W) ⊢1 TY as well as ET1(Y′, S W) ⊢1 TY′, we obtain that
ET1(Y, S W) ⊢1 TY ∪TY′.
Let U ∈JE(U′) be constructed from U′ and U as in Lemma 42. Then U ∈A0 →
A1. It remains to show that W ⊢→{U} ⊢→V.
Let to this end (Y, Z) ∈V. If (Y, Z) ∈V′ then we obtain by the above construc-
tion that there is some (MY, NY,Z) ∈U′ such that NY,Z ⊢1 Z as well as Y ⊢0 MY. It
follows that also ET1(Y, U) ⊢1 Z.
If (Y, Z) ∈V \ V′, there is some Y ∈Con0 so that Y ⊢0 Y, Y ∈Sup0(ET0(Y, V′))
and Z ∈Sup1(ET1(Y, V′)). As we have just seen, for every (X, E) ∈V′ there is
some (MX, NX,E) ∈U′ with NX,E ⊢1 E and X ⊢0 MX. Assume that Y ⊢0 X. Since
X ⊆Y in this case, it follows that also Y ⊢0 MX. Since U ∈JE(U′), there is some
(S Y, TY) ∈U such that Y ⊢0 S Y, S Y ∈Sup0(ET0(Y, U′)) and TY ∈Sup1(ET1(Y, U′)).
Then NX,E ⊆TY and hence TY ⊢1 E, which shows that TY ⊢1 ET1(Y, U′). Because
of Condition (L) there is thus some Z′ ∈Sup1(ET1(Y, V′)) with TY ⊢1 Z′.
By the construction of U and (58), ET1(Y, S W) ⊢1 TY. Since W ⊢→V, we
moreover have that also ET1(Y, S W) ⊢1 Z. With Lemma 21 it follows that
Z′
∼
ET1(Y,V′)
Z.
Thus also TY ⊢1 Z. Consequently we have that ET1(Y, U) ⊢1 Z.
This proves that {U} ⊢→V. It remains to show that W ⊢→U as well. Let to
this end (S, T) ∈U. If (S, T) ∈U′, there is some (Y, Z) ∈V′ with S = MY and
T = NY,Z. By (57) we have that ET1(MY, S W) ⊢1 NY,Z.
If (S, T) ∈U, there is some Y ∈Con0 such that S = S Y with Y ⊢0 S Y and
S Y ∈Sup0(ET0(Y, U′)), as well as T = TY with TY ∈Sup1(ET1(Y, U′)). Because of
(57) we have for (P, Q) ∈U′ with Y ⊢0 P that ET1(P, S W) ⊢1 Q. Since for all such
P, P ⊆S Y, we also have that ET1(S Y, S W) ⊢1 ET1(Y, U′). By Condition (L) there
is then some R ∈Sup1(ET1(Y, U′)) with ET1(S Y, S W) ⊢1 R. Because Y ⊢0 S Y,
we obtain that ET1(S Y, S W) ⊆ET1(Y, S W) and hence that ET1(Y, S W) ⊢1 R.

Representing L-Domains as Information Systems
523
As a consequence of Lemma 21 and (58),
TY
∼
(ET1(Y,U′)
R.
It follows that also ET1(S Y, S W) ⊢1 TY. This shows that W ⊢→U.
Claim 11 (A0 →A1, Con→, ⊢→) has a truth element.
Proof of Claim. Let t0 and t1, respectively, be truth elements of A0 and A1. Deﬁne
t = {({t0}, {t1})}. As is readily veriﬁed, t ∈A0 →A1 and W ⊢→t, for all W ∈
Con→. Moreover, we have for W ∈Con→and V ∈A0 →A1 with W ∪{t} ⊢→V
that W ⊢→V. Note here that for (Y, Z) ∈V, ET1(Y, S(W ∪{t})) = ET1(Y, S W)∪
{t1}. Thus, t is a truth element of A0 →A1.
Claim 12 (A0 →A1, Con→, ⊢→) satisﬁes Condition (L).
Proof of Claim. Let W ∈Con→and F ⊆ﬁn A0 →A1 such that W ⊢→F. We need
to construct a Z ∈Sup→(F) with W ⊢→Z. Without restriction we assume that
F < Con→.
We have for all V ∈F and all (P, Q) ∈V that
ET1(P,
[
W) ⊢1 Q.
(59)
For every V ∈F ﬁx some V′ ⊆ﬁn Con0 × Con1 with V ∈JE(V′) and let F ′ be
the collection of these V′. Then S pr0(S F ′) and S pr1(S F ′) are ﬁnite.
Let Y ∈Con0. According to the deﬁnition of Con→, ET1(Y, S W) ∈Con1.
As a consequence of (59) we obtain that for all (P, Q) ∈S F ′ with Y ⊢0 P,
ET1(Y, S W) ⊢1 Q. By Condition (L) there are therefore S Y ∈Sup0(ET0(Y,
S F ′)) with Y ⊢0 S Y, and TY ∈Sup1(ET1(Y, S F ′)) so that
ET1(Y,
[
W) ⊢1 TY.
(60)
Construct the set ZF by applying Lemma 42 to S F ′ and { (S Y, TY) | Y ∈
Con0 }. Then ZF ∈JE(S F ′), which implies that ZF ∈A0 →A1. We show that
W ⊢→ZF .
Let to this end (P, Q) ∈ZF . In case (P, Q) ∈S F ′, (59) is what needs to
be shown. Otherwise, there is some Y ∈Con0 so that (P, Q) = (S Y, TY), where
S Y ∈Sup0(ET0(Y, S F ′)) with Y ⊢0 S Y, and TY ∈Sup1(ET1(Y, S F ′)).
By (59) we have for (P′, Q′) ∈S F ′ with Y ⊢0 P′ that ET1(P′, S W) ⊢1
Q′. Since all these sets P′ are contained in S Y, it follows that ET1(S Y, S W) ⊢1

524
Dieter Spreen
ET1(Y, S F ′). Because of Condition 6(6) there is now some R ∈Con1 such that
R ⊇ET1(Y, S F ′) and
ET1(S Y,
[
W) ⊢1 R.
Since Y ⊢0 S Y, we have that ET1(S Y, S W) ⊆ET1(Y, S W). Hence ET1(Y,
S W) ⊢1 R. With Lemma 21 and (60) we therefore obtain that also ET1(S Y, S W)
⊢1 TY.
This shows that W ⊢→ZF . Set Z = F ∪{ZF }. As W ⊢→F by assumption,
it follows that W ⊢0 Z.
It remains to show that Z ∈Sup→(F ). First, we prove that Z ∈Con→. Let
F = {V1, . . . , Vn}. We show by induction on i that {ZF , V1, . . . , Vi} ∈Con→.
Since ZF ∈A0 →A1, Claim 6 tells us that {ZF } ∈Con→. Assume that
{ZF , V1, . . . , Vi} ∈Con→, for i < n. We need to show that then {ZF , V1, . . . ,
Vi+1} ∈Con→as well.
Let to this end Y ∈Con0. We have to prove that ET1(Y, ZF ∪V1 ∪· · · ∪Vi+1) ∈
Con1 and we know that ET1(Y, ZF ∪V1 ∪· · · ∪Vi) ∈Con1.
Assume that Vi+1 ∈JE(V′i+1) with V′i+1 ∈F ′.
By Lemma 40(1) there
are only ﬁnitely many (X, E) ∈Vi+1 so that Y ⊢0 X, say (X1, E1), . . . , (Xmi+1,
Emi+1). We will show that
ET1(Y, ZF ∪V1 ∪· · · ∪Vi ∪{(X1, E1), . . . , (Xj, E j)}) ∈Con1
(61)
by induction on j. Let to this end j < mi+1 and suppose that (61) holds.
If (Xj+1, E j+1)
∈
V′i+1, then (Xj+1, E j+1)
∈
ZF .
Otherwise, if (Xj+1,
E j+1) ∈Vi+1 \ V′i+1, then there is some Y ∈Con0 with Y ⊢0 Xj+1 such that Xj+1 ∈
Sup0(ET0(Y, V′i+1)) and E j+1 ∈Sup1(ET1(Y, V′i+1)). Since ET0(Y, V′i+1) ⊆X j+1
and Y ⊢0 X j+1, we obtain for X′ ∈pr0(V′i+1) with Y ⊢0 X′ that also Y ⊢0 X′. As
moreover V′i+1 ⊆ZF , we have that
ET1(Y, V′
i+1) ⊆ET1(Y, ZF ∪V1 ∪· · · ∪Vi ∪{(X1, E1), . . . , (Xj, E j)}).
By assumption, W ⊢→F . In addition, we have shown that W ⊢→ZF . Because
V1, . . . , Vi+1 ∈F , it therefore follows for (X, E) ∈ZF ∪V1 ∪· · · ∪Vi+1 that
ET1(X,
[
W) ⊢1 E.
Hence ET1(Y, S W) ⊢1 E j+1 ∪ET1(Y, ZF ∪V1 ∪· · · ∪Vi ∪{(X1, E1), . . . ,
(Xj, E j)}). With Condition 18(1) we thus obtain that
ET1(Y, ZF ∪V1 ∪· · · ∪Vi ∪{(X1, E1), . . . , (Xj+1, E j+1)}) ∈Con1 .

Representing L-Domains as Information Systems
525
For j = mi+1 it follows that ET1(Y, ZF ∪V1 ∪· · · ∪Vi+1) ∈Con1, which
concludes our main induction. Consequently, ET1(Y, S Z) ∈Con1, for all Y ∈
Con0, i.e. Z ∈Con→.
It remains to verify Conditions 18(1–3). Let to this end V, Y ∈Con→so that
Y ⊇F and V ⊢→Y ∪Z.
Note that S F ′ ⊆S F ⊆S Y.
Therefore (X, E) ∈S(Y ∪Z), exactly
if (X, E) ∈S Y or (X, E) ∈ZF \ S F ′.
By construction we have for any
(X, E) ∈ZF \ S F ′ that there is some Y(X,E) ∈Con0 such that Y(X,E) ⊢0 X,
X ∈Sup0(ET0(Y(X,E), S F ′)) and E ∈Sup1(ET1(Y(X,E), S F ′)).
(1) Let U ∈Con0. We need to show that ET1(U, S(Y ∪Z)) ∈Con1. By
Lemma 40(1) there are only ﬁnitely many (X, E) ∈ZF \ S F ′ with U ⊢0 X, say
(X1, E1), . . . , (Xn, En). We will prove by induction on i = 0, . . . , n that
ET1(U,
[
Y) ∪E1 ∪· · · ∪Ei ∈Con1 .
Observe that ET1(U, S Y) ∈Con1, by the deﬁnition of Con→Now, let i < n
and assume that ET1(U, S Y) ∪E1 ∪· · · ∪Ei ∈Con1. Since V ⊢→Y ∪Z, we have
for (P, Q) ∈S(Y ∪Z) that ET1(P, S V) ⊢1 Q. For those (P, Q) ∈S(Y ∪Z) with
U ⊢0 P we thus obtain that ET1(U, S V) ⊢1 Q. It follows that ET1(U, S V) ⊢1
ET1(U, S Y) ∪E1 ∪· · · ∪Ei+1.
Note that ET1(Y(Xi+1,Ei+1), S F ′) ⊆ET1(U,
S Y)), as S F ′ ⊆S Y, ET0(Y(Xi+1,Ei+1), S F ′) ⊆Xi+1 and U ⊢0 Xi+1. Because
of Condition 18(1), we therefore have that ET1(U, S Y) ∪E1 ∪· · · ∪Ei+1 ∈Con1.
(2) Let U ∈Con→with U ⊢→Y. We have to demonstrate that U ⊢→Z.
Obviously, it suﬃces to prove that U ⊢→ZF \ S F ′, i.e., we must show that for
any (X, E) ∈ZF \ S F ′, ET1(X, S U) ⊢1 E.
Let (X, E) ∈ZF \ S F ′. Since U ⊢→Y, we have for all (P, Q) ∈S Y that
ET1(P, S U) ⊢1 Q. This is true in particular for those (P, Q) ∈S Y with Y(X,E) ⊢0
P. Thus
ET1(Y(X,E), U) ⊢1 ET1(Y(X,E),
[
Y).
Similarly, by considering only (P, Q) ∈S F ′ with Y(X,E) ⊢0 P and using that
ET0(Y(X,E),
[
F ′) ⊆X,
we obtain that ET1(X, S U) ⊢1
ET1(Y(X,E), S F ′).
As the information sys-
tem A1 satisﬁes Condition (L), there is thus some T ∈Con1 such that T ∈
Sup1(ET1(Y(X,E), S F ′)) and
ET1(X,
[
U) ⊢1 T.
(62)
Remember that Y(X,E) ⊢0 X. Then we also have that ET1(Y(X,E), S U) ⊢1 T. Hence,
ET1(Y(X,E),
[
U) ⊢1 ET1(Y(X,E),
[
Y) ∪T.
(63)

526
Dieter Spreen
By our general assumption, V ⊢→Y∪Z. In particular V ⊢→ZF and V ⊢→Y.
It follows that ET1(X, S V) ⊢1 E and consequently
ET1(Y(X,E),
[
V) ⊢1 E.
(64)
Moreover, we obtain as above that ET1(Y(X,E), S V) ⊢1 ET1(Y(X,E), S Y). Note
that ET1(Y(X,E), S Y) ⊇ET1(Y(X,E), S F ′). With (63) and Condition 18(2) it now
follows that ET1(Y(X,E), S V) ⊢1 T. Because of (64), Lemma 21 implies that
T
∼
ET1(Y(X,E),S F ′) E.
Therefore, as a consequence of (62), we have that ET1(X, S U) ⊢1 E.
(3) Let W ∈A0 →A1 such that Y ∪Z ⊢→W. We need to prove that also
Y ⊢→W, i.e. we must show for (X, E) ∈W that ET1(X, S Y) ⊢1 E.
By our assumptions we have for (X, E) ∈W that
ET1(X,
[
(Y ∪Z)) ⊢1 E
(65)
and for (P, Q) ∈S(Y ∪Z) that ET1(P, S V) ⊢1 Q. In particular we have for
(P, Q) ∈S(Y ∪Z) with X ⊢0 P that
ET1(X,
[
V) ⊢1 Q.
(66)
Let (X, E) ∈W and remember that (P, Q) ∈S(Y ∪Z), just if (P, Q) ∈S Y or
(P, Q) ∈ZF \ S F ′. By Lemma 40(1) we know that there are only ﬁnitely many
(P, Q) ∈ZF \ S F ′ with X ⊢0 P, say (P1, Q1), . . . , (Pn, Qn). For i = 1, . . . , n, set
eYi = ET1(X,
[
Y) ∪Q1 ∪· · · ∪Qn−i.
By induction on i we show that eYi ⊢1 E.
Because of (65) the statement holds for i = 0. Assume that it holds for i < n. By
deﬁnition, eYi = eYi+1 ∪Qn−i. Note that ET0(Y(Pn−i,Qn−i), S F ′) ⊆Pn−i and X ⊢0 Pn−i.
Therefore,
ET1(Y(Pn−i,Qn−i),
[
F ′) ⊆ET1(X,
[
F ′) ⊆eYi+1.
Since Qn−i ∈Sup1(ET1(Y(Pn−i,Qn−i), S F ′)) it follows with Condition 18(3) and the
induction hypothesis that eYi+1 ⊢1 E.
□
Proposition 45. Let (A0, Con0, ⊢0) and (A1, Con1, ⊢1) be algebraic L-information
systems. Then (A0 →A1, Con→, ⊢→) is algebraic as well.

Representing L-Domains as Information Systems
527
Proof. Because of Lemma 26 it suﬃces to show for W ∈Con→and V ∈A0 →A1
that there is some U ∈Con→with W ⊢→U ⊢→U ⊢→V. Let V′ ⊆ﬁn Con0 × Con1
with V ∈JE(V′) and (Y, Z) ∈V′. As shown in the proof of Claim 10 of the
preceding proposition, there are MY ∈Con0 and NY,Z ∈Con1 such that
Y ⊢0 MY ⊢ET0(Y,
[
W)
and
ET1(Y,
[
W) ⊢1 NY,Z ⊢1 Z.
By Condition (ALG) there are e
MY ∈Con0 and eNY,Z ∈Con1 with
MY ⊢0 e
MY ⊢0 e
MY ⊢0 ET0(Y,
[
W)
and
ET1(Y,
[
W) ⊢1 eNY,Z ⊢1 eNY,Z ⊢1 NY,Z.
Construct U ∈A0 →A1 as in the proof of Claim 10 by using ( e
MY, eNY,Z) instead of
(MY, NY,Z). Then it follows as above that W ⊢→{U} ⊢→V. It remains to prove that
{U} ⊢→U.
Let (S, T) ∈U. Then S ⊢0 S and T ⊢1 T, by Lemma 26. Hence T ⊆ET1(S, U)
which means that ET1(S, U) ⊢1 T, as was to be shown.
□
Let f ∈|A0 →A1|. Then f ⊆A0 →A1, i.e., f is a subset of the powerset
of Con0 × Con1. We will now show that the states of A0 →A1 correspond to the
approximable mappings between A0 and A1 in a one-to-one way.
Lemma 46. For f ∈|A0 →A1|, let AM(f) = S f. Then AM(f): A0 ⊩A1.
Proof. In order to show that AM(f) is an approximable mapping we need to verify
Conditions 27(1–5).
(1) Let X ∈Con0, Y ∈Con1 and b ∈A1 with (X, Y) ∈AM(f) and Y ⊢1 b. We
must show that (X, {b}) ∈AM(f).
Since (X, Y) ∈AM(f), there is some V ∈f with (X, Y) ∈V. Moreover,
because of 8(3), there is some W ∈Con→with W ⊆f and W ⊢→V. Therefore,
ET1(X, S W) ⊢1 Y, from which it follows that also ET1(X, S W) ⊢1 b. Apply the
construction in Lemma 41 to (X, {b}). Then we have for the resulting set U that
W ⊢→U. With Condition 8(2) we obtain that U ∈f, i.e., (X, {b}) ∈AM(f).
(2) Let X ∈Con0 and F be a ﬁnite subset of A1 with (X, {b}) ∈AM(f), for all
b ∈F. We need to construct a Z ∈Con1 so that F ⊆Z and (X, Z) ∈AM(f).
As (X, {b}) ∈AM(f), for all b ∈F, there is some Vb ∈f with (X, {b}) ∈Vb, for
each such b. By Proposition 9 there is moreover some W ∈Con→such that W ⊆f
and W ⊢→Vb, for all b ∈F. Hence, we have for all such b that ET1(X, S W) ⊢2 b.

528
Dieter Spreen
It follows that ET1(X, S W) ⊢2 F. Because of Condition 6(6) there is thus some
Z ∈Con1 with F ⊆Z and ET1(X, S W) ⊢2 Z. Now, apply the construction in
Lemma 41 to (X, Z). We obtain a set U ∈A0 →A1 with W ⊢→U. Since W ⊆f,
it follows that U ∈f as well. Consequently, (X, Z) ∈AM(f).
(3) Let X, X′ ∈Con0 and b ∈A1 such that X ⊢0 X′ and (X′, {b}) ∈AM(f). We
need to show that (X, {b}) ∈AM(f).
As (X′, {b}) ∈AM(f), there is some V ∈f with (X′, {b}) ∈V.
More-
over, there is some W ∈Con→so that W ⊆f and W ⊢→V. It follows that
ET1(X′, S W) ⊢2 b. Since X ⊢0 X′, we have that ET1(X′, S W) ⊆ET1(X, S W).
Thus, ET1(X, S W) ⊢1 b.
As in the case of Condition 27(1), we obtain that
(X, {b}) ∈AM(f).
(4) follows similarly.
(5) Let X ∈Con0 and b ∈A1 with (X, {b}) ∈AM(f). We have to show that there
are X′ ∈Con0 and Y ∈Con1 such that X ⊢0 X′, (X′, Y) ∈AM(f) and Y ⊢1 b.
Let V ∈f with (X, {b}) ∈V and W ∈Con→with W ⊆f and W ⊢→V. Then
ET1(X, S W) ⊢1 b. Because of Condition 6(5) there is some Y ∈Con1 so that Y ⊢1
b and ET1(X, S W) ⊢1 Y. As a consequence of Lemma 40(1) we have that there
are only ﬁnitely many pairs (P, Q) ∈S W with X ⊢0 P, say (P1, Q1), . . . , (Pn, Qn).
Then X ⊢0 P1 ∪· · · ∪Pn. With Proposition 7 it follows for some X′ ∈Con0 that
X ⊢0 X′ and X′ ⊢0 P1∪· · ·∪Pn. Then ET1(X, S W) ⊆ET1(X′, S W) and therefore
ET1(X′, S W) ⊢1 Y. As above it follows that (X′, Y) ∈AM(f).
(6) We have seen in the proof of Claim 11 of Proposition 44 that t = {({t0}, {t1})}
is a truth element of A0 →A1. By Condition 8(2) a truth element is contained in
any state. Thus, t ∈f, i.e. ({t0}, {t1}) ∈AM(f).
□
Lemma 47. For G: A0 ⊩A1 let ST(G) = { V ∈A0 →A1 | V ⊆G }. Then
ST(G) ∈|A0 →A1|.
Proof. In order to verify that ST(G) is a state of A0 →A1, we need to check
Conditions 8(1–3).
(1) Let F be a nonempty ﬁnite subset of ST(G), say F = {V1, . . . , Vm}. We
have to show that there is some Z ∈Con→with F ⊆Z ⊆ST(G).
For i = 1, . . . , m, let V′i ⊆ﬁn Con0 × Con1 such that Vi ∈JE(V′i). Set F ′ =
{V′1, . . . , V′m}. Then S F ′ ⊆G.
Now, let Y ∈Con0. By Condition (L) there is some S Y ∈Sup0(ET0(Y, S F ′))
with Y ⊢0 S Y. It follows for (P, Q) ∈F ′ that P ⊆S Y. Since, in addition, PGQ,
we have that S YGQ. Thus, S YG ET1(Y, F ′). Note that all Vi and hence S F ′
are ﬁnite. Consequently, there is some Z ∈Con1 such that Z ⊢1 ET1(Y, S F ′)
and S YGZ. With Condition (L) we obtain some TY ∈Sup1(ET1(Y, S F ′)) with
Z ⊢1 TY. Thus S YGTY. By applying Lemma 42 to S F ′ and { (S Y, TY) | Y ∈Con0 }
we obtain some set ZF ∈JE(S F ′). Then ZF ∈A0 →A1. Set Z = F ∪{ZF )}.

Representing L-Domains as Information Systems
529
Then it follows as in the proof of Claim 12 of Proposition 44 that Z ∈Con→. By
construction, ZF ⊆G. Hence F ⊆Z ⊆ST(G).
(2) Let W ∈Con→and V ∈A0 →A1 with W ⊆ST(G) and W ⊢→V. We
need to show that V ∈ST(G).
Let (X, Y) ∈V. Then ET1(X, S W) ⊢1 Y. Moreover, let (P1, Q1), . . . , (Pn, Qn)
be the ﬁnitely many pairs (P, Q) ∈S W with X ⊢0 P. Then ET1(X, S W) =
Q1 ∪· · · ∪Qn. Since W ⊆ST(G), we have that PiGQi, for i = 1, . . . , n. Because
X ⊢0 Pi, for these i, it follows that XG ET1(X, S W) and hence that XGY. This
shows that V ⊆G, i.e. V ∈ST(G).
(3) Let V ∈ST(G). We have to show that there is some W ∈Con→such that
W ⊆ST(G) and W ⊢→V.
Note that V ⊆G and let V ∈JE(V′) with V′ = {(P1, Q1), . . . , (Pn, Qn)}. Then
there are Pi ∈Con0 and Qi ∈Con1, for i = 1, . . . , n, such that Pi ⊢0 Pi, PiGQi and
Qi ⊢1 Qi. Set U′ = {(P1, Q1), . . . , (Pn, Qn)}
Now, let (X, Y) ∈V \ V′. Then there is some U ∈Con0 such that U ⊢0 X,
X ∈Sup0(ET0(Y, V′)) and Y ∈Sup1(ET1(U, V′)). It follows that X ⊢0 ET0(U, U′).
Therefore, by Condition (L), there is some S U ∈Sup0(ET0(U, U′)) with X ⊢0 S U.
Then S UG ET1(U, U′). Thus, there is some V ∈Con1 so that S UGV and V ⊢1
ET1(U, U′). Applying Condition (L) again we obtain some TU ∈Sup1(ET1(U, U′))
with V ⊢1 TU.
Since TU ⊢1 ET1(U, V′), it follows with Condition (L) that there is some E′ ∈
Sup1(ET1(U, V′)) with TU ⊢1 E′. Thus XG(E ∪E′). Hence, there is some Z ∈Con1
with XGZ and Z ⊢1 (E ∪E′). With Lemma 21 it follows that
E
∼
ET1(U,V′) E′,
from which we obtain that TU ⊢1 E as well.
Construct U by applying Lemma 42 to U′ and { (S U, TU) | U ∈Con0 }. Then
U ∈JE(U′), which means that U ∈A0 →A1 and {U} ∈Con→. It remains to show
that {U} ⊢→V.
If (P, Q) ∈V′ then we have for some (P, Q) ∈U′ that P ⊢0 P and Q ⊢1 Q.
Thus ET1(P, U) ⊢1 Q. If, on the other hand, (X, Y) ∈V \ V′, we have for some
(S U, TU) ∈U that X ⊢0 S U and TU ⊢1 E. Therefore ET1(X, U) ⊢1 E again. This
shows that {U} ⊢→V.
□
Lemma 48.
1. ST(AM( f)) = f, for all f ∈|A0 →A1|.
2. AM(ST(G)) = G, for all G: A0 ⊩A1.
Proof. (1) Obviously f ⊆{ V ∈A0 →A1 | V ⊆AM(f) }. Conversely, if V ∈
AM(f), then there is some U(X,Y) ∈f with (X, Y) ∈U(X,Y), for every (X, Y) ∈

530
Dieter Spreen
V. Moreover, there is some V′ ⊆ﬁn Con0 × Con1 with V ∈JE(V′). Since V′ is
ﬁnite, we obtain some W ∈f such that W ⊢→U(P,Q), for all (P, Q) ∈V′. Thus,
ET1(P, S W) ⊢1 Q, for each such pair (P, Q).
Now, let (X, Y) ∈V \ V′. Then there exists U ∈Con0 so that U ⊢0 X, X ∈
Sup0(ET0(U, V′)) and Y ∈Sup1(ET1(U, V′)). It follows that ET0(U, V′) ⊆X.
Thus, ET1(X, S W) ⊢1 ET1(U, V′). By Condition (L) there is hence some Z ∈
Sup1(ET1(U, V′)) with ET1(X, S W) ⊢1 Z. In addition, as W ∪{U(X,Y)} ⊆ﬁn f,
there is some V ∈Con→with V ⊆f and V ⊢→W ∪{U(X,Y)}. It follows that
ET1(X, S V) ⊢1 Y ∪Z. Consequently,
Y
∼
ET1(U,V′) Z,
by Lemma 21, which implies that ET1(X, S W) ⊢1 Y. This shows that W ⊢→V.
Therefore, V ∈f.
(2) By deﬁnition, AM(ST(G)) ⊆G. Conversely, let (X, Y) ∈G. Note that there
is some Z ∈Con1 with Z ⊢1 Y by Condition 27(5). Thus, Lemma 41 can be applied
again and we obtain that (X, Y) ∈AM(ST(G)).
□
Proposition 49. Let (A0, Con0, ⊢0) and (A1, Con1, ⊢1) be L-information systems.
Then the states of A0 →A1 and the approximable mappings between A0 and A1
correspond to each other in a one-to-one way:
1. { S f | f ∈|A0 →A1| } is the set of approximable mappings from A0 to A1.
2. |A0 →A1| is the collection of all sets { V ∈A0 →A1 | V ⊆G }, where G is
an approximable mapping between A0 and A1.
In Section 5 we have already studied how approximable mappings between two
information systems A0 and A1 correspond to Scott continuous functions from |A0|
to |A1|, and vice versa. As we will see now, this correspondence establishes an
isomorphism between the domains |A0 →A1| and [|A0| →|A1|].
Let f ∈|A0 →A1|. Then AM(f): A0 ⊩A1 and hence D(AM( f)) ∈[|A0| →
|A1|]. Set
fct(f) = D(AM( f)).

Representing L-Domains as Information Systems
531
Then fct ∈[|A0 →A1| →[|A0| →|A1|]]. Note that for x ∈|A0|,
fct(f)(x)
= { b ∈A1 | (∃X ∈Con0)X ⊆x ∧(X, {b}) ∈AM(f) }
= { b ∈A1 | (∃X ∈Con0)(∃V ∈A0 →A1)X ⊆x ∧V ∈f ∧(X, {b}) ∈V }
= { b ∈A1 | (∃X ∈Con0)(∃V ∈A0 →A1)(∃W ∈Con→)X ⊆x ∧W ⊆f
∧W ⊢→V ∧(X, {b}) ∈V }
= { b ∈A1 | (∃X ∈Con0)(∃W ∈Con→)X ⊆x ∧W ⊆f
∧ET1(X,
[
W) ⊢1 b },
where the equality in the last line follows with Lemma 41.
Conversely, let g ∈[|A0| →|A1|]. Then C(g): C(|A0|) ⊩C(|A1|) and S A0 ◦C(g) ◦
TA1 : A0 →A1. Set
st(g) = { V ∈A0 →A1 | V ⊆S A0 ◦C(g) ◦TA1 }.
By the preceding proposition, st(g) ∈|A0 →A1|. As is readily veriﬁed, st is Scott
continuous.
We will show now that the functions fct and st are inverse to each other.
Lemma 50. st ◦fst = id|A0→A1| .
Proof. Let f ∈|A0 →A1|. As we have seen in the proof of Proposition 36, S A0 ◦
C(D(AM(f))) = AM(f) ◦S A1. Moreover, S A1 and TA1 are inverse to each other.
With Lemma 48(1) we therefore obtain that
st(fct(f))
= { V ∈A0 →A1 | V ⊆S A0 ◦C(D(AM( f)) ◦TA1 }
= { V ∈A0 →A1 | V ⊆AM(f) }
= f.
□
Lemma 51. fst ◦st = id[|A0|→|A1|].
Proof. Let g ∈[|A0| →|A1|] and note that D(S A0) = τ|A0| and D(TA1) = sp|A1|,
where the function sp|A1| deﬁned in Section 3 is the inverse of τ|A1|. As we have
seen in the proof of Proposition 33, τ|A1| ◦g = D(C(g)) ◦τ|A0|. With Lemma 48(2)

532
Dieter Spreen
we hence obtain for x ∈|A0| that
fct(st(g))(x)
= D(
[
{ V ∈A0 →A1 | V ⊆S A0 ◦C(g) ◦TA1 })(x)
= D(S A0 ◦C(g) ◦TA1)(x)
= D(TA1)(D(C(g))(D(S A0)(x)))
= sp|A1|(D(C(g))(τ|A0|(x)))
= sp|A1|(τ|A1|(g(x)))
= g(x).
□
Proposition 52. Let (A0, Con0, ⊢0) and (A1, Con1, ⊢1) be L-information systems.
Then the domains |A0 →A1| and [|A0| →|A1|] are isomorphic.
7
Cartesian closure
We will show now that for two L-information systems (A0, Con0, ⊢0) and (A1,
Con1, ⊢1), A0 →A1 is the exponent of A0 and A1 in the category LINF.
For Z ∈Con(A0→A1)×A0 and b ∈Con1 let
Z EV b ⇔ET1(prA0(Z),
[
prA0→A1(Z)) ⊢1 b.
Lemma 53. EV: (A0 →A1) × A0 ⊩A1.
Proof. We only verify Conditions 27(3, 5), the others being obvious.
(3) Let X, X′ ∈Con(A0→A1)×A0 and b ∈A1 so that X ⊢(A0→A1)×A0 X′and X′ EV b.
We need to prove that X EV b.
We have that prA0(X) ⊢0 prA0(X′) and ET1(prA0(X′), S prA0→A1(X′)) ⊢1 b.
It follows that also ET1(prA0(X), S prA0→A1(X′)) ⊢1 b. Moreover, we have that
prA0→A1(X) ⊢A0→A1 prA0→A1(X′). Thus ET1(P, S prA0→A1(X)) ⊢1 Q, for all (P, Q) ∈
S prA0→A1(X′) with prA0(X) ⊢0 P. As a consequence,
ET1(prA0(X),
[
prA0→A1(X)) ⊢1 ET1(prA0(X),
[
prA0→A1(X′)).
Hence ET1(prA0(X), S prA0→A1(X)) ⊢1 b, i.e. X EV b.
(5) Let X ∈Con(A0→A1)×A0 and b ∈A1 with X EV b. We have to show that there
are Z ∈Con(A0→A1)×A0 and U ∈Con1 such that X ⊢(A0→A1)×A0 Z, Z EV U and U ⊢1 b.
By assumption, ET1(prA0(X), S prA0→A1(X))]
⊢1
b.
According to Lem-
ma 40(1) there only ﬁnitely many (P, Q) ∈S prA0→A1(X) with prA0(X) ⊢0 P,

Representing L-Domains as Information Systems
533
say (P1, Q1), . . . , (Pn, Qn). Therefore, because of Condition 6(5), there is some
Y ∈Con0 such that prA0(X) ⊢0 Y ⊢0 P1 ∪· · · ∪Pn. Thus
ET1(Y,
[
prA0→A1(X)) = ET1(prA0(X),
[
prA0→A1(X)),
which implies that ET1(Y, S prA0→A1(X)) ⊢1 b. This shows that
prA0→A1(X) ⊢A0→A1 U,
where U ∈JE({(Y, {b})}) as in Lemma 41.
It follows that prA0→A1(X) ⊢A0→A1
V ⊢A0→A1 U, for some V ∈ConA0→A1. Hence ET1(Y, S V) ⊢1 b. Using Con-
dition 6(5) again we obtain some U ∈Con1 so that ET1(Y, S V) ⊢1 U ⊢1 b. Set
Z = Y × V. Then we have that X ⊢(A0→A1)×A0 Z, Z EV U and U ⊢1 b.
□
Let (A2, Con2, ⊢2) be a further L-information system. For H : A2 × A0 ⊩A1,
V ∈Con2 and V ∈A0 →A1 deﬁne
VΛ(H)V ⇔(∀(X, E) ∈V)(V × X)HE.
Lemma 54. Λ(H): A2 ⊩A0 →A1.
Proof. Again we have to verify Conditions 27(1–6).
(1) Let V ∈Con2, W ∈ConA0→A1 and V so that VΛ(H)W and W ⊢A0→A1 V.
Moreover, let (P, Q) ∈V. We have to show that (V × P)HQ.
Since W ⊢A0→A1 V, ET1(P, S W) ⊢1 Q. Moreover, we have that (V × X)HE,
for all (X, E) ∈S W with P ⊢0 X. Thus,
(V × ET0(P,
[
W))H ET1(P,
[
W).
As P ⊢0 ET0(P, S W), we obtain that (V × P)HQ.
(2) Let V ∈Con2 and F ⊆ﬁn A0 →A1 with VΛ(H)F . We have to construct
some Z ∈ConA0→A1 such that Z ⊇F and VΛ(H)Z. Without restriction we
assume that F < ConA0→A1.
By our assumption we have for (P, Q) ∈S F that (V × P)HQ. Now, for V ∈F ,
ﬁx some V′ ⊆ﬁn A0 × A1 with V ∈JE(V′) and let F ′ be the collection of these V′.
Then S prA0(S F ′) and S prA1(S F ′) are ﬁnite.
Let Y ∈Con0. Then Y ⊢0 ET0(Y, S F ′). By Condition (L) there is thus some
XY ∈Sup0(ET0(Y, S F ′)) with Y ⊢0 XY. It follows that
(V × XY)H ET1(Y,
[
F ′).
Hence there is some U ∈Con1 with (V × XY)HU and U ⊢1 ET1(Y, S F ′). Using
Condition (L) again we obtain some EY ∈Sup1(ET1(Y, S F ′)) with U ⊢1 EY.

534
Dieter Spreen
Now construct the set ZF by applying Lemma 42 to S F ′ and { (XY, EY) | Y ∈
Con0 }. Then ZF ∈JE(S F ′), which implies that ZF ∈A0 →A1. By construction
(V × X)HE, for all (X, E) ∈ZF . Set Z = F ∪{ZF }. Then VΛ(H)Z. As in the
proof of Proposition 44, Claim 12 it follows that Z ∈ConA0→A1.
(3) Let V, V′ ∈Con2 and V ∈ConA0→A1 so that V ⊢2 V′ and V′Λ(H)V. We have
to verify that for all (X, E) ∈V, (V × X)HE.
Let (X, E) ∈V. Then there is some U ∈ConA2×A0 with (V′ × X) ⊢A2×A0 U and
UHE. It follows that V ⊢2 V′ ⊢2 prA2(U) and X ⊢0 prA0(U). Therefore V ⊢2 prA2(U)
and hence (V × X) ⊢A2×A0 U, which implies that (V × X)HE.
(4) is obvious, as is (6).
(5) Let V ∈Con2 and V ∈A0 →A1 with VΛ(H)V. Then
(V × X)HE,
(67)
for all (X, E) ∈V. We have to construct Z ∈Con2 and Z ∈ConA0→A1 so that
V ⊢2 Z, ZΛ(H)Z and Z ⊢A0→A1 V.
Let V′ ⊆ﬁn Con0 × Con1 with V ∈JE(V′). Then we have for all (P, Q) ∈V′
that (V × P)HQ. Hence there are M(P,Q) ∈ConA2×A0 and N(P,Q) ∈Con1 so that (V ×
P) ⊢A2×A0 M(P,Q), M(P,Q)HN(P,Q) and N(P,Q) ⊢1 Q. It follows that V ⊢2 prA2(M(P,Q)),
for all (P, Q) ∈V′. Thus, there is some Z ∈Con2 so that Z ⊇S{ prA2(M(P,Q)) |
(P, Q) ∈V′ } and V ⊢2 Z. Moreover, Z × prA0(M(P,Q))HN(P,Q), for all (P, Q) ∈V′.
Now, let (X, E) ∈V \ V′. Then there is some Y ∈Con0 such that Y ⊢0 X,
X ∈Sup0(ET0(Y, V′)) and E ∈Sup1(ET1(Y, V′)). For (P, Q) ∈V′ with Y ⊢0 P
we have that X ⊢0 prA0(M(P,Q)), as P ⊆X. Thus, X ⊢0
S{ prA0(M(P,Q)) | (P, Q) ∈
V′ ∧Y ⊢0 P }. By Condition (L) there is hence some MY ∈Sup0(S{ prA0(M(P,Q)) |
(P, Q) ∈V′ ∧Y ⊢0 P }) with X ⊢0 MY. It follows that (Z × MY)H S{ N(P,Q) |
(P, Q) ∈V′ ∧Y ⊢0 P }. Consequently, there is some T Y ∈Con1 with (Z × MY)HT Y
and T Y ⊇S{ N(P,Q) | (P, Q) ∈V′ ∧Y ⊢0 P }. Applying Condition (L) again we
obtain some
NY ∈Sup1(
[
{ N(P,Q) | (P, Q) ∈V′ ∧Y ⊢0 P })
with T Y ⊢1 NY.
Furthermore, since NY ⊢1 ET1(Y, V′), there is some E′ ∈
Sup1(ET1(Y, V′)) with NY ⊢1 E′. Because of (67) we have that (V × X)H(NY ∪E).
Thus there is some U ∈Con1 with (V × X)HU and U ⊢1 (NY ∪E). Hence
U ⊢1 (E ∪E′). With Lemma 21 we obtain that also NY ⊢1 E.
Construct U ∈JE(U′) with Lemma 42 by starting from
U′ = { (prA0(M(P,Q)), N(P,Q)) | (P, Q) ∈V′ }
and { (MY, NY) | Y ∈Con0 }. Then we have for (P, Q) ∈V′ that V × P ⊢A2×A0
Z × pr0(M(P,Q)), Z × prA0(M(P,Q))HN(P,Q) as well as N(P,Q) ⊢1 Q, and
V × X ⊢A2×A0 Z × MY,
Z × MYHNY
and
NY ⊢1 E,

Representing L-Domains as Information Systems
535
for (X, E) ∈V \ V′ and Y ∈Con0 such that Y ⊢0 X, X ∈Sup0(ET0(Y, V′)) and
E ∈Sup1(ET1(Y, V′)). Since NY ⊆ET1(X, U), we also have
ET1(X, U) ⊢1 E.
It follows that V ⊢1 Z, ZΛ(H)U and {U} ⊢A0→A1 V.
□
Lemma 55. (Λ(H) × IdA0) ◦EV = H, for all H : C × A0 ⊩A1.
Proof. Let U ∈ConA2×A0 and b ∈A1 with U((Λ(H) × IdA0) ◦EV)b. Then there
is some U′ ∈ConA2×A0 such that U ⊢A2×A0 U′ and U′((Λ(H) × IdA0) ◦EV)b. It
follows that for some Z ∈Con(A0→A1)×A0, U′(Λ(H) × IdA0)Z and Z EV b. Thus,
prA2(U′)Λ(H) prA0→A1(Z), prA0(U′) ⊢0 prA0(Z) and
ET1(prA0(Z),
[
prA0→A1(Z)) ⊢1 b.
By deﬁnition of Λ(H) we have that (prA2(U′) × X)HE, for all (X, E)
∈
S prA0→A1(Z). Hence
(prA2(U′) × ET0(prA0(Z),
[
prA0→A1(Z)))H ET1(prA0(Z),
[
prA0→A1(Z)).
Since prA0(U′) ⊢0 prA0(Z) ⊢0 ET0(prA0(Z), S prA0→A1(Z)), it follows that (prA2(U′)×
prA0(U′))Hb and thus that UHb.
Conversely, if UHb, there are U′, U′′ ∈ConA2×A0 and V ∈Con1 such that
U ⊢A2×A0 U′ ⊢A2×A0 U′′, U′′Hb and V ⊢1 b. Let U ∈JE({(prA0(U′′), V)}) according
to Lemma 41. Then U ∈A0 →A1 and prA2(U′′)Λ(H)U. Thus U(ΛH × IdA0)Z,
for Z = {U} × prA0(U′). Note that ET1(prA0(U′), U) ⊇V. Therefore, we have that
U(ΛH × IdA0)Z and Z EV b, i.e. U((ΛH × IdA0) ◦EV)b.
□
Lemma 56. Λ((G × IdA0) ◦EV) = G, for all G: A2 ⊩A0 →A1.
Proof. Let V ∈Con2 and V ∈A0 →A1 with VΛ((G × IdA0) ◦EV)V. Then
(V × X)((G × IdA0) ◦EV)E, for each (X, E) ∈V. It follows that there is some
Z(X,E) ∈Con(A0→A1)×A0, for each such (X, E), so that (V × X)(G × IdA0)Z(X,E)
and Z(X,E) EV E, which means that VG prA0→A1(Z(X,E)), X ⊢0 prA0(Z(X,E)) and
ET1(prA0(Z(X,E)), S prA0→A1(Z(X,E))) ⊢1 E. Thus,
ET1(X,
[
prA0→A1(Z(X,E))) ⊢1 E,
(68)
for all (X, E) ∈V.

536
Dieter Spreen
Now, let V′ ⊆ﬁn Con0 × Con1 with V ∈JE(V′). Then there is some U ∈
ConA0→A1 with VGU and U ⊇prA0→A1(Z(P,Q)), for all (P, Q) ∈V′. Moreover, by
(68), we have for all such (P, Q) that
ET1(P,
[
U) ⊢1 Q.
(69)
Next, let (X, E) ∈V \ V′. Then there is some Y ∈Con0 so that Y ⊢0 X,
X ∈Sup0(ET0(Y, V′)) and E ∈Sup1(ET1(Y, V′)).
With (69) it follows that
ET1(X, S U) ⊢1 ET1(Y, V′).
Because of Condition (L) we obtain some T ∈
Sup1(ET1(Y, V′)) with
ET1(X,
[
U) ⊢1 T.
As VG(U ∪prA0→A1(Z(X,E))), there is some U′ ∈ConA0→A1 with U′ ⊇U ∪
prA0→A1(Z(X,E)) and VGU′. It follows that ET1(X, S U′) ⊢1 T ∪E. By Lemma 21
we therefore have that
E
∼
ET1(Y,V′) T.
As a consequence, ET1(X, S U) ⊢1 E.
This shows that U ⊢A0→A1 V. Since moreover VGU, we obtain that VGV.
Conversely, if VGV, then there is some Z ∈ConA0→A1 with VGZ and Z ⊢A0→A1
V. It follows that for all (X, E) ∈V, ET1(X, S Z) ⊢1 E. Since X ⊢0 ET0(X, S Z)
and the latter set is ﬁnite by Lemma 40(1), we obtain some X′ ∈Con0 with X ⊢0
X′ ⊢0 ET0(X, S Z). Then
ET0(X′,
[
Z) = ET0(X,
[
Z).
Therefore, ET1(X′, S Z) ⊢1 E. Set Z = Z × X′. Then Z ∈Con(A0→A1)×A0, (V ×
X)(G × IdA0)Z and Z EV E. Thus, VΛ((G × IdA0) ◦EV)V.
□
Proposition 57. Let A0 and A1 be L-information systems. Then (A0 →A1, EV) is
their exponent in LINF.
With Propostion 45 we moreover have that if A0 and A1 are both algebraic, then
(A0 →A1, EV) is their exponent in aLINF.
As we have already seen, LINF as well as aLINF contain a terminal object.
Moreover, we have shown how to construct the categorical product of information
systems.
Theorem 58. The category LINF of L-information systems and approximable
mappings as well as its full subcategory aLINF of algebraic L-information sys-
tems are Cartesian closed.

Representing L-Domains as Information Systems
537
A well-known result of Jung [11, 12] states that the categories L and aL are
maximal among the Cartesian closed full subcategories of CONT⊥and ALG⊥,
respectively. As was shown in [16], CONT⊥is equivalent to the category CINFt
of continuous information systems with truth element and ALG⊥is equivalent to
the category AINFt of algebraic information systems with truth element. Note here
that the functors involved in establishing the equivalence result in the present paper
are restrictions of those used in [16].
Theorem 59. The categories LINF and aLINF, respectively, are maximal among
the Cartesian closed full subcategory of CINFt and AINFt.
8
Concluding remarks
In this paper the information system representation of L-domains was studied. Con-
tinuous information systems were introduced in [16], the equivalence of their cat-
egory with the category of continuous domains was shown and the information
systems of many important classes of domains were derived. The L-domain case,
however, was left open.
In information systems base elements of domains are represented by ﬁnite con-
sistent sets of tokens. The main problem in ﬁnding an information system descrip-
tion of L-domains was the characterization of those consistent sets that represent
local suprema, i.e., the least upper bounds a ﬁnite set can have with respect to
diﬀerent principal ideals. As was demonstrated, the category of L-information sys-
tems with approximating mappings is equivalent to the category of L-domains with
Scott continuous functions, which shows that the right notion of L-information
system was found. By this result many important properties like the existence of
exponents transfer from L-domains to L-information systems. In concrete cases,
however, one has to go back and forth between information systems and domains
in order to construct the exponent of two information systems. Instead, we pre-
sented a direct construction within L-information systems in this paper.
In the case of information systems for bounded-complete domains [15, 10] to-
kens in A0 →A1 correspond to single-step functions (u ↘v) and ﬁnite consistent
sets of tokens correspond to the least upper bounds of ﬁnite bounded sets of such
functions, i.e. step functions. In the case of L-domains such sets do not deﬁne a
function, in general. Consider e.g. the domain D deﬁned by the diagram in Fig-
ure 1.
Then (a ↘b) as well as (b ↘a) are single-step functions in [D →D], but (a ↘
b) ⊔(b ↘a) is not deﬁned. What e.g. should be the value for ci? Unfortunately,
this problem can not be solved by adding ﬁnitely many single-step functions, e.g.

538
Dieter Spreen
Figure 1: An inﬁnite L-domain D
c1
c2
. . .
cn
cn+1
. . .
a
b
⊥
(ci ↘ci+1), as is the case for SFP domains. For every ci one has to add what should
be the corresponding function value.
This information can no longer be described by a ﬁnite set in Con. Therefore
we have taken the descriptions of such functions as elements of the information
system A0 →A1. The ﬁniteness of the starting objects which is characteristic
for information systems is hidden in the fact that these objects now correspond to
functions which are generated from a ﬁnite set of single-step functions by adding
pairs of least upper bounds.
References
[1] S. Abramsky, A. Jung. Domain theory. In: S. Abramsky et al. (Eds.). Hand-
book of Logic in Computer Science, Vol. 3. Clarendon Press, Oxford, 1994,
pp. 1–168.
[2] S. Abramsky. Domain theory in logical form. Ann. Pure Appl. Logic, 51:1–77,
1991.
[3] R. M. Amadio, P.-L. Curien. Domains and Lambda-Calculi. Cambridge Uni-
versity Press, Cambridge, 1998.
[4] Y.-X. Chen, A. Jung. A logical approach to stable domains. Theoret. Com-
put. Sci., 368:124–148, 2006.
[5] T. Coquand. Categories of embeddings. Theoret. Comput. Sci., 68:221–238,
1989.
[6] G. Gierz, K. H. Hoﬀmann, K. Keimel, J. D. Lawson, M. W. Mislove,
D. S. Scott. Continuous Lattices and Domains. Cambridge University Press,
Cambridge, 2003.

Representing L-Domains as Information Systems
539
[7] J. Y. Girard. The system F of variable types, ﬁfteen years later. Theoret. Com-
put. Sci., 45:159–192, 1986.
[8] C. A. Gunter. Semantics of Programming Languages. MIT-Press, Cambridge,
MA, 1992.
[9] C. A. Gunter, D. S. Scott. Semantic domains. In: J. van Leeuwen (Ed.). Hand-
book of Theoretical Computer Science, Vol. B, Formal Models and Semantics.
Elsevier, Amsterdam, 1990, pp. 633–674.
[10] R. Hoofman. Continuous information systems. Inform. and Comput., 105:42–
71, 1993.
[11] A. Jung. Cartesian Closed Categories of Domains. CWI Tracts, Vol. 66. Cen-
trum voor Wiskunde en Informatica, Amsterdam, 1989.
[12] A. Jung. The classiﬁcation of continuous domains. In: Proc., Fifth Annual
IEEE Symposium on Logic in Computer Science. IEEE Computer Society
Press, New York, 1990, pp. 35–40.
[13] A. Jung, A.Kegelmann, M. A. Moshier. Multi lingual sequent calculus and
coherent spaces. Fund. Inform., 20:1-42, 1999.
[14] K. G. Larsen, G. Winskel. Using information systems to solve domain equa-
tions eﬀectively. In G. Kahn et al. (Eds.). Semantics of Data Types. Lecture
Notes in Computer Science, Vol. 173. Springer, Berlin, 1984, pp. 109–129.
[15] D. Scott. Domains for denotational semantics. In: M. Nielsen et al. (Eds.). Au-
tomata, Languages and Programming, Aarhus, 1982. Lecture Notes in Com-
puter Science, Vol. 140. Springer, Berlin, 1982, pp. 577–613.
[16] D. Spreen, L. Xu, X. Mao. Information systems revisited: the general contin-
uous case. Theoret. Comput. Sci., 405:176–187, 2008.
[17] V. Stoltenberg-Hansen, I. Lindstr¨om, E. R. Griﬀor. Mathematical Theory of
Domains. Cambridge University Press, Cambridge, 1994.
[18] S. Vickers. Information systems for continuous posets. Theoret. Comput. Sci.,
114:201–229, 1993.
[19] G. Winskel. An introduction to event systems. In: J. W. de Bakker (Ed.).
Linear Time, Branching Time and Partial Order in Logics and Models for
Concurrency. Lecture Notes in Computer Science, Vol. 354. Springer, Berlin,
1989, pp. 364–397.

540
Dieter Spreen
[20] L. Xu, X. Mao. When do abstract bases generate continuous lattices and L-
domains. Algebra Univers., 58:95–104, 2008.
[21] G.-Q. Zhang. Logic of Domains. Birkh¨auser, Boston, Basel, Berlin, 1991.
[22] G.-Q. Zhang. Disjunctive systems and L-domains. In: W. Kuich (Ed.). Au-
tomata, Languages and Programming, Wien, 1992. Lecture Notes in Com-
puter Science, Vol. 623. Springer, Berlin, 1992, pp. 284–295.
[23] G.-Q. Zhang. DI-domains as prime information systems. Inform. and Com-
put., 100:151–177, 1992.
[24] G.-Q. Zhang. A representation of SFP. Inform. and Comput., 110:233–263,
1994.

