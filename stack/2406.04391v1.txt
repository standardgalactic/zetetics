Why Has Predicting Downstream Capabilities of
Frontier AI Models with Scale Remained Elusive?
Rylan Schaeffer∗
Stanford CS
Hailey Schoelkopf
EleutherAI
Brando Miranda
Stanford CS
Gabriel Mukobi
Stanford CS
Varun Madan
Stanford CS
Adam Ibrahim
MILA
Herbie Bradley
University of Cambridge
Stella Biderman
EleutherAI
Sanmi Koyejo∗
Stanford CS
Abstract
Predictable behavior from scaling advanced AI systems is an extremely desirable
property. Although a well-established literature exists on how pretraining perfor-
mance scales, the literature on how particular downstream capabilities scale is
significantly muddier. In this work, we take a step back and ask: why has predict-
ing specific downstream capabilities with scale remained elusive? While many
factors are certainly responsible, we identify a new factor that makes modeling
scaling behavior on widely used multiple-choice question-answering benchmarks
challenging. Using five model families and twelve well-established multiple-choice
benchmarks, we show that downstream performance is computed from negative
log likelihoods via a sequence of transformations that progressively degrade the sta-
tistical relationship between performance and scale. We then reveal the mechanism
causing this degradation: downstream metrics require comparing the correct choice
against a small number of specific incorrect choices, meaning accurately predicting
downstream capabilities requires predicting not just how probability mass concen-
trates on the correct choice with scale, but also how probability mass fluctuates on
specific incorrect choices with scale. We empirically study how probability mass
on the correct choice co-varies with probability mass on incorrect choices with
increasing compute, suggesting that scaling laws for incorrect choices might be
achievable. Our work also explains why pretraining scaling laws are commonly
regarded as more predictable than downstream capabilities and contributes towards
establishing scaling-predictable evaluations of frontier AI models.
1
Introduction
Predictable scaling behavior of frontier AI systems such as GPT-4 [61, 62], Claude [5] and Gemini [73,
64] is crucial for anticipating their capabilities and informing key decisions around their development
and deployment [4, 60, 22]. While scaling laws describing relationships between parameters, data,
compute, and pretraining loss are well-established [37, 65, 34, 44, 30, 35, 42, 77, 38, 16, 59, 36, 52,
69, 58, 7], the literature is less conclusive concerning predicting specific downstream capabilities
with scale. For instance, prior work has observed that performance on standard natural language
processing (NLP) benchmarks can exhibit emergent abilities [14, 26, 72, 74] where performance
changes unpredictably with scale, with further work demonstrating that such unpredictable changes
∗Correspondence to rschaef@cs.stanford.edu and sanmi@cs.stanford.edu.
Preprint. Under review.
arXiv:2406.04391v1  [cs.LG]  6 Jun 2024

Figure 1: Multiple-choice benchmark accuracy is computed from negative log-likelihoods via
a sequence of transformations that degrades predictability. Computing Accuracy begins with
computing the negative log-likelihoods of each choice, then negating and exponentiating each to
obtain the probability of each choice (A). Choices are then restricted to a set of available choices by
masking invalid continuations, and renormalizing to obtain relative probability mass on each choice
(B). Lastly, the model’s choice is defined as arg maxi{pChoices(Available Choicei)}, and Accuracy
is 1 if and only if the model’s choice is the correct choice (C).
might at times be artifacts of researchers’ analyses, i.e., choices of metrics and lack of resolution
[72, 70, 39]. More recently, Du et al. [23] claim that downstream capabilities can be predicted, but
only after the pretraining cross-entropy loss falls below a certain threshold, and Gadre et al. [25]
claim that while performance on individual tasks can be difficult to predict, aggregating results across
dozens of diverse benchmarks yields clearer scaling trends. In this work, we take a step back and ask:
why has predicting specific downstream capabilities with scale remained elusive?
While many factors are certainly responsible, we identify a new factor that makes modeling the
scaling behavior on widely used multiple-choice question-answering benchmarks challenging. We
demonstrate that common multiple-choice metrics like Accuracy, Brier Score, and Probability Correct
are computed from raw model outputs (log probabilities) via a sequence of transformations that
progressively degrades the statistical relationship between those metrics and the scaling parameters
(parameters, data, compute). The cause is that these metrics rely on a direct comparison between the
ground truth output and a small set of specific incorrect outputs. As a result, accurately predicting
downstream performance requires modeling not only the concentration of probability mass on the
correct output with increasing compute, but also modeling the fluctuations of probability mass on
particular incorrect alternatives, which (to date) is a necessary but unaddressed step. We then
empirically study how probability mass on incorrect choices fluctuates with increasing compute. Our
findings help explain the apparent unpredictability of individual downstream metrics and the greater
robustness of pretraining loss scaling laws, which do not depend on specific incorrect choices. More
broadly, we argue that a precise understanding of the factors affecting downstream performance is
essential for designing evaluations that can reliably track the progression of frontier AI capabilities.
2
Methodology: Data for Studying Scaling of Downstream Capabilities
To study how downstream capabilities on specific tasks change with scale for different model families,
we generated per-sample scores from a large number of model families and multiple-choice NLP
benchmarks. To ensure the computed scores were consistent with prior work, we used EleutherAI’s
Language Model (LM) Evaluation Harness [29] rather than implementing our own evaluations.
Model Families
Because our goal was to explore the scaling behavior of evaluations with increasing
compute, we chose to evaluate model families with dense combinations of parameter counts and
token counts. This includes the following families (additional details in App. D):
1. Pythia [9]: The Pythia family contains 8 models from 70M to 12B parameters trained on the
Pile [27] for 300B tokens. We use 8 checkpoints per size of the non-deduplicated variants.
2

2. Cerebras-GPT [21]: The Cerebras-GPT family contains 7 models ranging from 111M to
13B parameters. The models were trained on the Pile [27] for different durations as part of a
scaling study with ∼20× tokens to parameters in a “Chinchilla”-optimal manner [38].
3. OLMo [31]: The OLMo family contains a 1B parameter model trained for 3T tokens and
two 7B parameter models trained for 2T-2.5T tokens. We selected 7 checkpoints for 1B
(spanning 84B2 to 3T tokens) and 7 checkpoints for 7B (spanning 4B to 2.4T tokens).
4. INCITE [2]: The INCITE family contains 3B and 7B parameter models, trained on 0.8T
and 1T tokens of RedPajama-v1[18]. The 3B model has only a single checkpoint, so we
excluded it. We found this family to be a slight outlier from other families, which we
speculate is because its pretraining data were contaminated by benchmarks [24].
5. LLM360 [50]: LLM360 includes two 7B parameter LLMs trained on 1.3T and 1.4T tokens.
We selected 13 checkpoints of Amber spaced approximately logarithmically.
NLP Benchmarks
We evaluated the above model families on widely-used multiple-choice bench-
marks for assessing comprehension, reasoning, and world knowledge: AI2 Reasoning Challenge
(ARC) Easy and Hard [17], HellaSwag [76], MathQA [3], MCTACO [78], MMLU [32], Open-
bookQA [55], PIQA [11], RACE [49], SciQ [75], SIQA [67], WinoGrande [45] and XWinoGrad En
[57]. For MMLU, we analyzed each of the 57 subjects (e.g., Abstract Algebra) independently. For
each benchmark, we used default evaluation settings from the LM Evaluation Harness [29].
Performance Metrics
We used three common multiple-choice metrics [72, 70, 23]: Accuracy,
Brier Score [13], and probability mass on the correct choice relative to the available choices.
Compute Budget Calculations
Following prior work [44], we approximated3 the pretraining
compute C (in terms of training FLOP) of a given model checkpoint as a function of the parameter
count (excluding the embedding layer) N and the amount of training data seen in tokens D:
C = C(N, D) ≈6 N D
3
What Makes Predicting Downstream Performance Difficult?
Performance on multiple choice benchmarks is commonly presented as Accuracy, Brier Score
[70], or probability mass on the correct choice out of the available choices [23]. These quantities
are computed via a sequence of transformations that begins with the negative log-likelihood of the
correct choice on this particular benchmark sample as some function f(·, ·) of compute:
LVocab
θ
(Correct Choice) = f(Compute, Benchmark Datum)
(1)
Two details are critical. Firstly, this negative log-likelihood is not computed in expectation over a
corpus; it is specific to this particular singular datum in the benchmark. All the scores we discuss are
per-datum. Secondly, this negative log-likelihood is computed over the vocabulary of the model. One
can then compute the probability mass of the correct choice, again with respect to the vocabulary:
pVocab
θ
(Correct Choice) = exp
 −LVocab
θ
(Correct Choice)

(2)
Next, probabilities are restricted to the set of available choices {Available Choicei}|Available Choices|
i
by
masking invalid continuations and normalizing again with respect to this set:
pChoices
θ
(Correct Choice)
def
=
pVocab
θ
(Correct Choice)
P
i pVocab
θ
(Available Choicei)
(3)
2OLMo 1B checkpoints below 84B tokens were unfortunately accidentally lost by their creators.
3This approximation neglects FLOP costs associated with attention calculations over sequence length;
however, such operations are negligible so long as dmodel >> nctx/12, and this approximation is therefore
standard in most language model scaling law analyses.
3

−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0
1
2
3
4
5
6
7
% of Samples
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - CDF
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
Benchmark: ARC-Challenge
Performance Metric: log pVocab
θ
(Correct Choice)
Correlation Metric: Spearman
Figure 2: Distributions of score-compute correlations and their corresponding complementary
cumulative distribution functions. Left: For each benchmark, model family, performance metric,
and correlation metric, one can compute how scores correlate with compute. This yields a distribution
(over samples) of score-compute correlations. Note: the uniform (yellow) distribution is small
but non-zero everywhere. Right: To easily extract what fraction of samples in a benchmark have
score-compute correlations above any given threshold, we convert the probability distributions to
complementary cumulative distribution functions, i.e., 1 minus the (empirical) cumulative distribution
function (CDF). Top: Schematic idealized distributions. Bottom: Real data on ARC Challenge [17].
We emphasize the support over the token space of the model versus over the set of available choices
in the benchmark’s question because, as we will show, this crucially affects predictability. Finally,
one uses the choices-normalized probability masses to compute standard downstream metrics:
Accuracyθ
def
= 1

Correct Choice == arg max
i
n
pChoices
θ
(Available Choicei)
o
(4)
Brier Scoreθ
def
=
X
i

1(Available Choicei == Correct Choice)−pChoices
θ
(Available Choicei)
2
(5)
where 1(·) is an indicator variable. We demonstrate that this sequence of transformations degrades
how predictable performance is with scale before identifying the underlying mechanism.
To quantify how this sequence of transformations affects predictability of performance, we mea-
sured how per-sample scores correlate with pretraining compute, and then studied how the dis-
tribution (over samples) of correlation values shifted as one transitions from loglikelihoods to
pVocab
θ
(Correct Choice) to pChoices
θ
(Correct Choice) to Accuracy or Brier Score. Specifically, for
each combination of (model family, benchmark, performance metric, correlation metric), we com-
puted a correlation value for each sample in the benchmark between pretraining compute and scores.
This yielded a distribution (over samples) of correlation values for the combination (Fig. 2 left).
Visualizing the distribution of correlations for the combination told us what fraction of samples in the
benchmark yielded scores that are correlated, uncorrelated or anticorrelated with compute (Fig. 2
right). We used three standard correlation metrics - Pearson, Kendall [46] and Spearman [71]) - and
found consistent results.
4

0.0
0.2
0.4
0.6
0.8
1.0
1 - CDF
A
Metric: log pVocab
θ
(Correct Choice)
B
Metric: pChoices
θ
(Correct Choice)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - CDF
C
Metric: Brier Score
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
D
Metric: Accuracy
Distributions of Score-Compute Correlations by Metric
Benchmark: ARC-Challenge
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
Figure 3: Multiple-choice metrics like Accuracy and Brier Score are computed via a sequence
of transformations that degrades correlations between performance scores and pretraining
compute. (A) Initially, scores under log pVocab
θ
(Correct Choice) and compute are highly correlated.
Transforming log pVocab
θ
(Correct Choice) into pVocab
θ
(Correct Choice) has no effect for rank corre-
lations. (B) Transforming pVocab
θ
(Correct Choice) into pChoices
θ
(Correct Choice) decorrelates scores
from compute. (C) Transforming pChoices
θ
(Correct Choice) into Brier Score minorly decreases
score-compute correlations. (D) Transforming pChoices
θ
(Correct Choice) into Accuracy more substan-
tially decorrelates scores from compute. Benchmark: ARC Challenge [17]. Correlation: Spearman.
Results are consistent across benchmarks and all three correlation metrics; for more, see App. G.
We present ARC Challenge [17] as an illustrative benchmark to demonstrate how the sequence of
transformations affects the distribution of score-compute correlations, but note that all other bench-
marks exhibited similar patterns (App. G). We visualized the distributions via their complementary
(empirical) cumulative distribution functions (complementary CDFs) (App. B):
ˆS(c)
def
= 1
N
N
X
n=1
1{Cn > c},
(6)
where N is the number of data in the benchmark and Cn is the correlation (over the models in the
model family) between compute and scores on the n-th datum in the benchmark. For a given threshold
c, the complementary CDF ˆS(c) returns the fraction of the benchmark’s samples with score-compute
correlations greater than the threshold c (Fig. 3A). Beginning with log likelihoods, approximately
90% of samples exhibit score-compute correlations > 0.75, regardless of the model family (Fig.
3A). Transforming negative log-likelihoods into probability masses pVocab
θ
(Correct Choice) does
not affect the distribution of score-compute correlations for Spearman and Kendall. However,
transforming pVocab
θ
(Correct Choice) into pChoices
θ
(Correct Choice) decreases the distribution of score-
compute correlations (Fig. 3B), with only 40% of samples having score-compute correlations
> 0.75. Transforming pChoices
θ
(Correct Choice) into Brier Score has little-to-no effect (Fig. 3C)
but transforming into Accuracy (Fig. 3D) furthers decreases score-compute correlations. To
quantitatively test whether these transformations indeed decrease the correlation between scores and
5

0.4
0.6
0.8
1.0
1.2
1.4
1.6
1.8
2.0
Statistic Value
ARC-Challenge
ARC-Easy
HellaSwag
MathQA
MC-TACO
MMLU Abstract Algebra
MMLU Anatomy
MMLU Astronomy
MMLU Business Ethics
MMLU Clinical Knowledge
MMLU College Biology
MMLU College Chemistry
MMLU College Comp Sci
MMLU College Maths
MMLU College Medicine
MMLU College Physics
MMLU Comp Security
MMLU Conceptual Physics
MMLU Econometrics
MMLU Electrical Engineering
MMLU Elementary Maths
MMLU Formal Logic
MMLU Global Facts
MMLU HS Biology
MMLU HS Chemistry
MMLU HS Comp Sci
MMLU HS Euro History
MMLU HS Geography
MMLU HS Govt & Politics
MMLU HS Macroeconomics
MMLU HS Maths
MMLU HS Microeconomics
MMLU HS Physics
MMLU HS Psychology
MMLU HS Statistics
MMLU HS US History
MMLU HS World History
MMLU Human Aging
MMLU Human Sexuality
MMLU International Law
MMLU Jurisprudence
MMLU Logical Fallacies
MMLU Machine Learning
MMLU Management
MMLU Marketing
MMLU Medical Genetics
MMLU Miscellaneous
MMLU Moral Disputes
MMLU Moral Scenarios
MMLU Nutrition
MMLU Philosophy
MMLU Prehistory
MMLU Professional Accounting
MMLU Professional Law
MMLU Professional Medicine
MMLU Professional Psychology
MMLU Public Relations
MMLU Security Studies
MMLU Sociology
MMLU US Foreign Policy
MMLU Virology
MMLU World Religions
OpenBookQA
PIQA
PubMedQA
RACE
SciQ
Social Interaction QA
TriviaQA
Winogrande
XWinograd-EN
Benchmark (and Optional Task)
AUC of Correlations’ Complementary Cumulative Distribution Function
Pearson Correlations
Metric
log pVocab
θ
(Correct Choice)
pVocab
θ
(Correct Choice)
pChoices
θ
(Correct Choice)
Brier Score
Accuracy
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
Figure 4: All four statistics of score-compute correlation distributions demonstrate that trans-
forming log pVocab
θ
(Correct Choice) into Accuracy causes score-compute correlations to dete-
riorate. We find a consistent trend across benchmarks and model families for three correlation
metrics (Spearman, Pearson and Kendall) and for four statistics of correlation distributions (mean,
median, the area under the survival function, and negative Wasserstein distance from perfect cor-
relation or perfect anti-correlation) that the sequence of transformations degrades score-compute
correlations, as shown by the right-to-left log pVocab
θ
(Correct Choice)-to-pVocab
θ
(Correct Choice)-
to-pChoices
θ
(Correct Choice)-or-Brier Score-to-Accuracy vertical stripes. See App. Figs. 7, 8, 9
for other correlation metrics and other score-compute correlation distribution statistics.
compute, we measured four statistics of these score-compute correlation distributions: the mean, the
median, the area under the complementary CDF and the negative4 of the minimum of two Wasserstein
distances: between the empirical correlation distribution and an ideal distribution of all correlations
= 1, and between the empirical distribution and an ideal distribution of all correlations = −1. Across
the four summary statistics, for most benchmarks and for most model families, we discovered a
consistent ordering of metrics of the score-compute correlation distributions (Fig. 4):
Corr
 Compute, log pVocab
θ
(Correct Choice)

≥Corr
 Compute, pVocab
θ
(Correct Choice)

> Corr
 Compute, pChoices
θ
(Correct Choice)

≥Corr
 Compute, Brier Score

> Corr
 Compute, Accuracy

4
Probability Masses on Incorrect Choices Cause Unpredictability
What is the mechanism that degrades how correlated scores are with compute? All three metrics
with degraded correlations - pChoices
θ
(Correct Choice), Accuracy, and Brier Score - depend not
just on how the model’s probability mass pVocab
θ
(Correct Choice) concentrates on the correct choice
4We chose the negative Wasserstein distance for consistency with the other statistics: higher values correspond
to higher correlations between scores and compute.
6

Figure 5: Predictability deteriorates because of probability mass fluctuating on specific incorrect
choices with scale. Left: Transitioning from pVocab
θ
(Correct Choice) to pChoices
θ
(Correct Choice)
demonstrates that pVocab
θ
(Correct Choice) contains little information about pChoices
θ
(Correct Choice)
and vice versa; loosely speaking, any value of one can map to any value of the other. Center: While
pChoices
θ
(Correct Choice) > 0.5 must yield Accuracy = 1, for any pChoices
θ
(Correct Choice) < 0.5,
knowing pChoices
θ
(Correct Choice) contains little information about Accuracy and vice versa. Right:
Brier Score is more predictable from pChoices
θ
(Correct Choice) than Accuracy, but still quite
variable. Three benchmarks shown: MathQA [3], MMLU Conceptual Physics [32], SciQ [75].
as compute increases, but also depend on how the model’s probability mass fluctuates on incorrect
available choices {pVocab
θ
(Incorrect Choice)}Incorrect Choices as compute increases. As an example,
suppose pV ocab
θ
(Correct Choice) = 0.4 on a 4-way multiple-choice question; what is the accuracy?
Spreading the remaining mass uniformly on the incorrect choices will make Accuracy = 1, whereas
concentrating mass on a single incorrect choice will make Accuracy = 0.
To demonstrate how drastically the probability mass placed on incorrect choices can alter per-
formance, we visualized the relations between pairs of metrics immediately preceding and fol-
lowing a given transformation (Fig. 5). For negative log-likelihood of the correct choice and
pV ocab
θ
(Correct Choice) (not pictured), we observed a clean correspondence between performance
under the metric and compute: one can reliably map a given value of these metrics to compute,
and vice versa. In contrast, once performance is evaluated using a metric that is a function of the
incorrect choices - pChoices
θ
(Correct Choice), Accuracy or Brier Score - nearly any value of a
score under one metric can map to any value of pVocab
θ
(Correct Choice) or pChoices
θ
(Correct Choice)
respectively (Fig. 5), breaking the chain along which one can cleanly infer compute from an observed
metric. We can see that Brier Score, a metric meant to produce more continuous scores [70],
7

Figure 6: Probability mass on the correct choices and the incorrect choices are correlated, but
can fluctuate substantially. Probability mass on correct choices and incorrect choices positively
covaries and typically increases with compute. However, the spread is large: for any given value of
pVocab
θ
(Correct Choice), the mass on incorrect choices can vary by many orders of magnitude.
is less variable than Accuracy provided a known pChoices
θ
(Correct Choice), but it cannot recover
information about pVocab
θ
(Correct Choice) that is lost when shifting to pChoices
θ
(Correct Choice). We
next show that this is because of the additional information regarding the underdetermined values of
pChoices
θ
(Incorrect Choice) for each incorrect choice.
5
Scaling Behavior of Probability Mass on Incorrect Choices
In order to accurately predict performance on multiple-choice question-answering benchmarks, one
must predict not just how probability mass concentrates on correct choices with scale, but also
how probability mass fluctuates on incorrect choices with scale. For metrics like Accuracy, these
predictions must be made for each sample because knowing the average mass (across many data)
placed on incorrect choices says little about how much mass is placed on any single incorrect choice
for a single sample. We conclude by providing preliminary evidence that achieving such a feat might
be possible. Specifically, we test how probability masses on correct choices and probability masses
on incorrect choices covary with increasing compute (Fig. 6). Multiple benchmarks display strong
positive relationships between mass on correct choices and mass on incorrect choices, suggesting
that fitting per-sample scaling trends for each incorrect choice might be possible; doing so would
enable predicting changepoints in metrics like Accuracy or Brier Score. However, whether per-
benchmark per-sample per-choice scaling trends can be fit and accurately extrapolated is unclear
since the spread varies by several orders of magnitude. We leave this challenge to future work.
8

Takeaway #1: Think through your metrics!
If one cares about scaling-predictable evaluations, then one needs to think through how their
evaluations transform raw model outputs into useful signals to know what to expect.
Takeaway #2: Continuous metrics are insufficient to guarantee predictable changes.
As shown by pChoices
θ
(Correct Choice) & Brier Score, even “continuous” metrics can be
unpredictable, e.g., if the metric weighs correct behavior against specific incorrect behaviors.
Takeaway #3: Recommended scaling-predictable metrics for pretraining practitioners.
Pretraining practitioners seeking scaling-predictable signals for capabilities should perhaps
focus on pVocab
θ
(Correct Choice) on relevant benchmarks. Scores under this metric provide
smoother scaling trends and are arguably more interpretable than the pretraining loss.
Takeaway #4: Evaluations should be reshaped based on intended desiderata.
Too often, we take evaluations as frozen static objects, but evaluations should be adapted
to pertinent goals. For instance, if the goal is to predict capabilities with scale, evaluations
should be designed or adapted to be scaling-predictable.
6
Discussion, Related Work and Future Directions
This work identifies a factor that induces unpredictability in multiple-choice assessments of frontier AI
models, as well as the underlying mechanism: probability mass on incorrect choices. Our results have
implications for the design of future evaluations for frontier AI models that are reliably predictable
with scaling. We hope that our work will be extended to further the science of scaling-predictable
evaluation of AI systems, especially for complex and important model capabilities. We note several
future directions for extension of our work and we hope that the community also adopts our framing
to further improve scaling-predictable evaluations.
Related Work
For a comprehensive exposition of related work, please see App. A.
Direction 1: Beyond Multiple Choice Benchmarks
Our study is restricted to benchmarks evalu-
ated via loglikelihood-based multiple-choice formats. While we believe this is inherently valuable
due to the usefulness and prevalence of such tasks, this limits the application of our findings. We hope
that our discoveries and proposed mechanisms may be used to inform the study of predictable and
reliable evaluation writ large, and that future work should explore the extent to which our findings
can be generalized to more complex capabilities. Our findings corroborate those of Lyu et al. [51],
who find that multiple-choice answer scores often diverge from generative evaluations. Consequently,
a particularly important direction for further study is to investigate generative evaluations, which may
contain similar transformations distancing performance from the observed loss.
Direction 2: Predicting Benchmark Performance A Priori
Our work provides an explanation
why multiple-choice benchmark performance is not easily predictable for metrics such as Accuracy
and Brier Score, as observed in the literature [23]. However, our analyses assume access to entire
model families’ scores across several orders of magnitude of pretraining FLOPs, and do not employ
backtesting, as sensibly recommended by Owen [63]. A predictive model should be able to identify
change points well in advance on standard metrics like Accuracy or Brier Score.
9

References
[1] J. Achiam, S. Adler, S. Agarwal, L. Ahmad, I. Akkaya, F. L. Aleman, D. Almeida,
J. Altenschmidt, S. Altman, S. Anadkat, et al.
Gpt-4 technical report.
arXiv preprint
arXiv:2303.08774, 2023.
[2] T. AI. Releasing 3b and 7b redpajama-incite family of models including base, instruction-
tuned & chat models. https://www.together.ai/blog/redpajama-models-v1, 2023.
Accessed: 2024-05-19.
[3] A. Amini, S. Gabriel, S. Lin, R. Koncel-Kedziorski, Y. Choi, and H. Hajishirzi. MathQA: To-
wards interpretable math word problem solving with operation-based formalisms. In J. Burstein,
C. Doran, and T. Solorio, editors, Proceedings of the 2019 Conference of the North Amer-
ican Chapter of the Association for Computational Linguistics: Human Language Tech-
nologies, Volume 1 (Long and Short Papers), pages 2357–2367, Minneapolis, Minnesota,
June 2019. Association for Computational Linguistics. doi: 10.18653/v1/N19-1245. URL
https://aclanthology.org/N19-1245.
[4] Anthropic. Anthropic’s responsible scaling policy. https://www.anthropic.com/news/
anthropics-responsible-scaling-policy, 2023. Accessed: 2024-05-19.
[5] Anthropic. Introducing the next generation of claude. https://www.anthropic.com/news/
claude-3-family, 2024. Accessed: 2024-05-19.
[6] E. Beeching, C. Fourrier, N. Habib, S. Han, N. Lambert, N. Rajani, O. Sanseviero, L. Tunstall,
and T. Wolf. Open llm leaderboard. https://huggingface.co/spaces/HuggingFaceH4/
open_llm_leaderboard, 2023.
[7] T. Besiroglu, E. Erdil, M. Barnett, and J. You. Chinchilla scaling: A replication attempt, 2024.
[8] S. Biderman, U. S. Prashanth, L. Sutawika, H. Schoelkopf, Q. Anthony, S. Purohit, and E. Raff.
Emergent and predictable memorization in large language models, 2023.
[9] S. Biderman, H. Schoelkopf, Q. Anthony, H. Bradley, K. O’Brien, E. Hallahan, M. A. Khan,
S. Purohit, U. S. Prashanth, E. Raff, A. Skowron, L. Sutawika, and O. van der Wal. Pythia: A
suite for analyzing large language models across training and scaling, 2023.
[10] S. Biderman, H. Schoelkopf, L. Sutawika, L. Gao, J. Tow, B. Abbasi, A. F. Aji, P. S. Ammana-
manchi, S. Black, J. Clive, A. DiPofi, J. Etxaniz, B. Fattori, J. Z. Forde, C. Foster, M. Jaiswal,
W. Y. Lee, H. Li, C. Lovering, N. Muennighoff, E. Pavlick, J. Phang, A. Skowron, S. Tan,
X. Tang, K. A. Wang, G. I. Winata, F. Yvon, and A. Zou. Lessons from the trenches on
reproducible evaluation of language models. arXiv preprint, 2024.
[11] Y. Bisk, R. Zellers, R. L. Bras, J. Gao, and Y. Choi. Piqa: Reasoning about physical common-
sense in natural language. 2020.
[12] S. R. Bowman. Eight things to know about large language models, 2023.
[13] G. W. Brier. Verification of forecasts expressed in terms of probability. Monthly weather review,
78(1):1–3, 1950.
[14] T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam,
G. Sastry, A. Askell, et al. Language models are few-shot learners. Advances in neural
information processing systems, 33:1877–1901, 2020.
[15] E. Caballero, K. Gupta, I. Rish, and D. Krueger. Broken neural scaling laws, 2023.
[16] A. Clark, D. De Las Casas, A. Guy, A. Mensch, M. Paganini, J. Hoffmann, B. Damoc, B. Hecht-
man, T. Cai, S. Borgeaud, et al. Unified scaling laws for routed language models. In International
Conference on Machine Learning, pages 4057–4086. PMLR, 2022.
[17] P. Clark, I. Cowhey, O. Etzioni, T. Khot, A. Sabharwal, C. Schoenick, and O. Tafjord. Think
you have solved question answering? try arc, the ai2 reasoning challenge. arXiv preprint
arXiv:1803.05457, 2018.
[18] T. Computer. Redpajama: An open source recipe to reproduce llama training dataset, 2023.
URL https://github.com/togethercomputer/RedPajama-Data.
[19] W. contributors.
Survival function, 2023.
URL https://en.wikipedia.org/wiki/
Survival_function. [Online; accessed 22-May-2024].
10

[20] DeepSeek-AI, :, X. Bi, D. Chen, G. Chen, S. Chen, D. Dai, C. Deng, H. Ding, K. Dong, Q. Du,
Z. Fu, H. Gao, K. Gao, W. Gao, R. Ge, K. Guan, D. Guo, J. Guo, G. Hao, Z. Hao, Y. He, W. Hu,
P. Huang, E. Li, G. Li, J. Li, Y. Li, Y. K. Li, W. Liang, F. Lin, A. X. Liu, B. Liu, W. Liu, X. Liu,
X. Liu, Y. Liu, H. Lu, S. Lu, F. Luo, S. Ma, X. Nie, T. Pei, Y. Piao, J. Qiu, H. Qu, T. Ren, Z. Ren,
C. Ruan, Z. Sha, Z. Shao, J. Song, X. Su, J. Sun, Y. Sun, M. Tang, B. Wang, P. Wang, S. Wang,
Y. Wang, Y. Wang, T. Wu, Y. Wu, X. Xie, Z. Xie, Z. Xie, Y. Xiong, H. Xu, R. X. Xu, Y. Xu,
D. Yang, Y. You, S. Yu, X. Yu, B. Zhang, H. Zhang, L. Zhang, L. Zhang, M. Zhang, M. Zhang,
W. Zhang, Y. Zhang, C. Zhao, Y. Zhao, S. Zhou, S. Zhou, Q. Zhu, and Y. Zou. Deepseek llm:
Scaling open-source language models with longtermism, 2024.
[21] N. Dey, G. Gosal, Zhiming, Chen, H. Khachane, W. Marshall, R. Pathria, M. Tom, and
J. Hestness. Cerebras-gpt: Open compute-optimal language models trained on the cerebras
wafer-scale cluster, 2023.
[22] A.
Dragan,
H.
King,
and
A.
Dafoe.
Introducing
the
frontier
safety
framework.
https://deepmind.google/discover/blog/
introducing-the-frontier-safety-framework/, 2024. Accessed: 2024-05-19.
[23] Z. Du, A. Zeng, Y. Dong, and J. Tang. Understanding emergent abilities of language models
from the loss perspective, 2024.
[24] Y. Elazar, A. Bhagia, I. H. Magnusson, A. Ravichander, D. Schwenk, A. Suhr, E. P. Walsh,
D. Groeneveld, L. Soldaini, S. Singh, et al. What’s in my big data? In The Twelfth International
Conference on Learning Representations, 2023.
[25] S. Y. Gadre, G. Smyrnis, V. Shankar, S. Gururangan, M. Wortsman, R. Shao, J. Mercat, A. Fang,
J. Li, S. Keh, R. Xin, M. Nezhurina, I. Vasiljevic, J. Jitsev, A. G. Dimakis, G. Ilharco, S. Song,
T. Kollar, Y. Carmon, A. Dave, R. Heckel, N. Muennighoff, and L. Schmidt. Language models
scale reliably with over-training and on downstream tasks, 2024.
[26] D. Ganguli, D. Hernandez, L. Lovitt, A. Askell, Y. Bai, A. Chen, T. Conerly, N. Dassarma,
D. Drain, N. Elhage, et al. Predictability and surprise in large generative models. In 2022 ACM
Conference on Fairness, Accountability, and Transparency, pages 1747–1764, 2022.
[27] L. Gao, S. Biderman, S. Black, L. Golding, T. Hoppe, C. Foster, J. Phang, H. He, A. Thite,
N. Nabeshima, S. Presser, and C. Leahy. The pile: An 800gb dataset of diverse text for language
modeling, 2020.
[28] L. Gao, J. Schulman, and J. Hilton. Scaling laws for reward model overoptimization, 2022.
[29] L. Gao, J. Tow, B. Abbasi, S. Biderman, S. Black, A. DiPofi, C. Foster, L. Golding, J. Hsu,
A. Le Noac’h, H. Li, K. McDonell, N. Muennighoff, C. Ociepa, J. Phang, L. Reynolds,
H. Schoelkopf, A. Skowron, L. Sutawika, E. Tang, A. Thite, B. Wang, K. Wang, and A. Zou. A
framework for few-shot language model evaluation, 12 2023. URL https://zenodo.org/
records/10256836.
[30] M. A. Gordon, K. Duh, and J. Kaplan. Data and parameter scaling laws for neural machine
translation. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language
Processing, pages 5915–5922, 2021.
[31] D. Groeneveld, I. Beltagy, P. Walsh, A. Bhagia, R. Kinney, O. Tafjord, A. H. Jha, H. Ivison,
I. Magnusson, Y. Wang, S. Arora, D. Atkinson, R. Authur, K. R. Chandu, A. Cohan, J. Dumas,
Y. Elazar, Y. Gu, J. Hessel, T. Khot, W. Merrill, J. Morrison, N. Muennighoff, A. Naik,
C. Nam, M. E. Peters, V. Pyatkin, A. Ravichander, D. Schwenk, S. Shah, W. Smith, E. Strubell,
N. Subramani, M. Wortsman, P. Dasigi, N. Lambert, K. Richardson, L. Zettlemoyer, J. Dodge,
K. Lo, L. Soldaini, N. A. Smith, and H. Hajishirzi. Olmo: Accelerating the science of language
models, 2024.
[32] D. Hendrycks, C. Burns, S. Basart, A. Zou, M. Mazeika, D. Song, and J. Steinhardt. Measuring
massive multitask language understanding. arXiv preprint arXiv:2009.03300, 2020.
[33] D. Hendrycks, C. Burns, S. Kadavath, A. Arora, S. Basart, E. Tang, D. Song, and J. Steinhardt.
Measuring mathematical problem solving with the math dataset. 2021.
[34] T. Henighan, J. Kaplan, M. Katz, M. Chen, C. Hesse, J. Jackson, H. Jun, T. B. Brown, P. Dhari-
wal, S. Gray, et al. Scaling laws for autoregressive generative modeling. arXiv preprint
arXiv:2010.14701, 2020.
11

[35] D. Hernandez, J. Kaplan, T. Henighan, and S. McCandlish. Scaling laws for transfer. arXiv
preprint arXiv:2102.01293, 2021.
[36] D. Hernandez, T. Brown, T. Conerly, N. DasSarma, D. Drain, S. El-Showk, N. Elhage,
Z. Hatfield-Dodds, T. Henighan, T. Hume, et al. Scaling laws and interpretability of learning
from repeated data. arXiv preprint arXiv:2205.10487, 2022.
[37] J. Hestness, S. Narang, N. Ardalani, G. Diamos, H. Jun, H. Kianinejad, M. Patwary, M. Ali,
Y. Yang, and Y. Zhou. Deep learning scaling is predictable, empirically. arXiv preprint
arXiv:1712.00409, 2017.
[38] J. Hoffmann, S. Borgeaud, A. Mensch, E. Buchatskaya, T. Cai, E. Rutherford, D. d. L. Casas,
L. A. Hendricks, J. Welbl, A. Clark, et al. Training compute-optimal large language models.
arXiv preprint arXiv:2203.15556, 2022.
[39] S. Hu, X. Liu, X. Han, X. Zhang, C. He, W. Zhao, Y. Lin, N. Ding, Z. Ou, G. Zeng, Z. Liu, and
M. Sun. Predicting emergent abilities with infinite resolution evaluation, 2024.
[40] Y. Huang, J. Zhang, Z. Shan, and J. He. Compression represents intelligence linearly, 2024.
[41] B. Isik, N. Ponomareva, H. Hazimeh, D. Paparas, S. Vassilvitskii, and S. Koyejo. Scaling laws
for downstream task performance of large language models, 2024.
[42] A. L. Jones. Scaling scaling laws with board games. arXiv preprint arXiv:2104.03113, 2021.
[43] M. Joshi, E. Choi, D. Weld, and L. Zettlemoyer. triviaqa: A Large Scale Distantly Supervised
Challenge Dataset for Reading Comprehension. arXiv e-prints, art. arXiv:1705.03551, 2017.
[44] J. Kaplan, S. McCandlish, T. Henighan, T. B. Brown, B. Chess, R. Child, S. Gray, A. Rad-
ford, J. Wu, and D. Amodei.
Scaling laws for neural language models.
arXiv preprint
arXiv:2001.08361, 2020.
[45] S. Keisuke, L. Ronan, B. Chandra, and C. Yejin. Winogrande: An adversarial winograd schema
challenge at scale. 2019.
[46] M. G. Kendall. A new measure of rank correlation. Biometrika, 30(1/2):81–93, 1938.
[47] D. G. Kleinbaum and M. Klein. Survival Analysis: A Self-Learning Text. Springer, 3 edition,
2012. ISBN 978-1441966452. doi: 10.1007/978-1-4419-6646-9.
[48] T. Kwiatkowski, J. Palomaki, O. Redfield, M. Collins, A. Parikh, C. Alberti, D. Epstein,
I. Polosukhin, M. Kelcey, J. Devlin, K. Lee, K. N. Toutanova, L. Jones, M.-W. Chang, A. Dai,
J. Uszkoreit, Q. Le, and S. Petrov. Natural questions: a benchmark for question answering
research. Transactions of the Association of Computational Linguistics, 2019.
[49] G. Lai, Q. Xie, H. Liu, Y. Yang, and E. Hovy. RACE: Large-scale ReAding comprehension
dataset from examinations. In Proceedings of the 2017 Conference on Empirical Methods in
Natural Language Processing, pages 785–794, Copenhagen, Denmark, Sept. 2017. Association
for Computational Linguistics. doi: 10.18653/v1/D17-1082. URL https://aclanthology.
org/D17-1082.
[50] Z. Liu, A. Qiao, W. Neiswanger, H. Wang, B. Tan, T. Tao, J. Li, Y. Wang, S. Sun, O. Pangarkar,
R. Fan, Y. Gu, V. Miller, Y. Zhuang, G. He, H. Li, F. Koto, L. Tang, N. Ranjan, Z. Shen, X. Ren,
R. Iriondo, C. Mu, Z. Hu, M. Schulze, P. Nakov, T. Baldwin, and E. P. Xing. Llm360: Towards
fully transparent open-source llms, 2023.
[51] C. Lyu, M. Wu, and A. F. Aji. Beyond probabilities: Unveiling the misalignment in evaluating
large language models. arXiv preprint arXiv:2402.13887, 2024.
[52] A. Maloney, D. A. Roberts, and J. Sully. A solvable model of neural scaling laws. arXiv preprint
arXiv:2210.16859, 2022.
[53] S. McCandlish, J. Kaplan, D. Amodei, and O. D. Team. An empirical model of large-batch
training, 2018.
[54] I. McKenzie, A. Lyzhov, A. Parrish, A. Prabhu, A. Mueller, N. Kim, S. Bowman, and E. Perez.
The inverse scaling prize, 2022. URL https://github.com/inverse-scaling/prize.
[55] T. Mihaylov, P. Clark, T. Khot, and A. Sabharwal. Can a suit of armor conduct electricity? a
new dataset for open book question answering. In EMNLP, 2018.
[56] S. Muckatira, V. Deshpande, V. Lialin, and A. Rumshisky. Emergent abilities in reduced-scale
generative language models, 2024.
12

[57] N. Muennighoff, T. Wang, L. Sutawika, A. Roberts, S. Biderman, T. L. Scao, M. S. Bari,
S. Shen, Z.-X. Yong, H. Schoelkopf, X. Tang, D. Radev, A. F. Aji, K. Almubarak, S. Albanie,
Z. Alyafeai, A. Webson, E. Raff, and C. Raffel. Crosslingual generalization through multitask
finetuning, 2023.
[58] N. Muennighoff, A. Rush, B. Barak, T. Le Scao, N. Tazi, A. Piktus, S. Pyysalo, T. Wolf, and
C. A. Raffel. Scaling data-constrained language models. Advances in Neural Information
Processing Systems, 36, 2024.
[59] O. Neumann and C. Gros. Scaling laws for a multi-agent reinforcement learning model. arXiv
preprint arXiv:2210.00849, 2022.
[60] OpenAI.
Openai’s approach to frontier risk.
https://openai.com/global-affairs/
our-approach-to-frontier-risk/, 2023. Accessed: 2024-05-19.
[61] OpenAI. Hello gpt-4o. https://openai.com/index/hello-gpt-4o/, 2024. Accessed:
2024-05-16.
[62] OpenAI, J. Achiam, S. Adler, S. Agarwal, L. Ahmad, I. Akkaya, F. L. Aleman, D. Almeida,
J. Altenschmidt, S. Altman, S. Anadkat, R. Avila, I. Babuschkin, S. Balaji, V. Balcom, P. Bal-
tescu, H. Bao, M. Bavarian, J. Belgum, I. Bello, J. Berdine, G. Bernadett-Shapiro, C. Berner,
L. Bogdonoff, O. Boiko, M. Boyd, A.-L. Brakman, G. Brockman, T. Brooks, M. Brundage,
K. Button, T. Cai, R. Campbell, A. Cann, B. Carey, C. Carlson, R. Carmichael, B. Chan,
C. Chang, F. Chantzis, D. Chen, S. Chen, R. Chen, J. Chen, M. Chen, B. Chess, C. Cho,
C. Chu, H. W. Chung, D. Cummings, J. Currier, Y. Dai, C. Decareaux, T. Degry, N. Deutsch,
D. Deville, A. Dhar, D. Dohan, S. Dowling, S. Dunning, A. Ecoffet, A. Eleti, T. Eloundou,
D. Farhi, L. Fedus, N. Felix, S. P. Fishman, J. Forte, I. Fulford, L. Gao, E. Georges, C. Gibson,
V. Goel, T. Gogineni, G. Goh, R. Gontijo-Lopes, J. Gordon, M. Grafstein, S. Gray, R. Greene,
J. Gross, S. S. Gu, Y. Guo, C. Hallacy, J. Han, J. Harris, Y. He, M. Heaton, J. Heidecke, C. Hesse,
A. Hickey, W. Hickey, P. Hoeschele, B. Houghton, K. Hsu, S. Hu, X. Hu, J. Huizinga, S. Jain,
S. Jain, J. Jang, A. Jiang, R. Jiang, H. Jin, D. Jin, S. Jomoto, B. Jonn, H. Jun, T. Kaftan, Łukasz
Kaiser, A. Kamali, I. Kanitscheider, N. S. Keskar, T. Khan, L. Kilpatrick, J. W. Kim, C. Kim,
Y. Kim, J. H. Kirchner, J. Kiros, M. Knight, D. Kokotajlo, Łukasz Kondraciuk, A. Kondrich,
A. Konstantinidis, K. Kosic, G. Krueger, V. Kuo, M. Lampe, I. Lan, T. Lee, J. Leike, J. Leung,
D. Levy, C. M. Li, R. Lim, M. Lin, S. Lin, M. Litwin, T. Lopez, R. Lowe, P. Lue, A. Makanju,
K. Malfacini, S. Manning, T. Markov, Y. Markovski, B. Martin, K. Mayer, A. Mayne, B. Mc-
Grew, S. M. McKinney, C. McLeavey, P. McMillan, J. McNeil, D. Medina, A. Mehta, J. Menick,
L. Metz, A. Mishchenko, P. Mishkin, V. Monaco, E. Morikawa, D. Mossing, T. Mu, M. Murati,
O. Murk, D. Mély, A. Nair, R. Nakano, R. Nayak, A. Neelakantan, R. Ngo, H. Noh, L. Ouyang,
C. O’Keefe, J. Pachocki, A. Paino, J. Palermo, A. Pantuliano, G. Parascandolo, J. Parish,
E. Parparita, A. Passos, M. Pavlov, A. Peng, A. Perelman, F. de Avila Belbute Peres, M. Petrov,
H. P. de Oliveira Pinto, Michael, Pokorny, M. Pokrass, V. H. Pong, T. Powell, A. Power,
B. Power, E. Proehl, R. Puri, A. Radford, J. Rae, A. Ramesh, C. Raymond, F. Real, K. Rimbach,
C. Ross, B. Rotsted, H. Roussez, N. Ryder, M. Saltarelli, T. Sanders, S. Santurkar, G. Sastry,
H. Schmidt, D. Schnurr, J. Schulman, D. Selsam, K. Sheppard, T. Sherbakov, J. Shieh, S. Shoker,
P. Shyam, S. Sidor, E. Sigler, M. Simens, J. Sitkin, K. Slama, I. Sohl, B. Sokolowsky, Y. Song,
N. Staudacher, F. P. Such, N. Summers, I. Sutskever, J. Tang, N. Tezak, M. B. Thompson,
P. Tillet, A. Tootoonchian, E. Tseng, P. Tuggle, N. Turley, J. Tworek, J. F. C. Uribe, A. Vallone,
A. Vijayvergiya, C. Voss, C. Wainwright, J. J. Wang, A. Wang, B. Wang, J. Ward, J. Wei,
C. Weinmann, A. Welihinda, P. Welinder, J. Weng, L. Weng, M. Wiethoff, D. Willner, C. Winter,
S. Wolrich, H. Wong, L. Workman, S. Wu, J. Wu, M. Wu, K. Xiao, T. Xu, S. Yoo, K. Yu,
Q. Yuan, W. Zaremba, R. Zellers, C. Zhang, M. Zhang, S. Zhao, T. Zheng, J. Zhuang, W. Zhuk,
and B. Zoph. Gpt-4 technical report, 2024.
[63] D. Owen. How predictable is language model benchmark performance?, 2024.
[64] M. Reid, N. Savinov, D. Teplyashin, D. Lepikhin, T. Lillicrap, J.-b. Alayrac, R. Soricut,
A. Lazaridou, O. Firat, J. Schrittwieser, et al. Gemini 1.5: Unlocking multimodal understanding
across millions of tokens of context. arXiv preprint arXiv:2403.05530, 2024.
[65] J. S. Rosenfeld, A. Rosenfeld, Y. Belinkov, and N. Shavit. A constructive prediction of the
generalization error across scales. In International Conference on Learning Representations,
2019.
[66] Y. Ruan, C. J. Maddison, and T. Hashimoto. Observational scaling laws and the predictability
of language model performance, 2024.
13

[67] M. Sap, H. Rashkin, D. Chen, R. Le Bras, and Y. Choi. Social iqa: Commonsense reasoning
about social interactions. In Proceedings of the 2019 Conference on Empirical Methods in
Natural Language Processing and the 9th International Joint Conference on Natural Language
Processing (EMNLP-IJCNLP), 2019.
[68] M. Sap, H. Rashkin, D. Chen, R. LeBras, and Y. Choi. Socialiqa: Commonsense reasoning
about social interactions, 2019.
[69] N. Sardana and J. Frankle. Beyond chinchilla-optimal: Accounting for inference in language
model scaling laws, 2023.
[70] R. Schaeffer, B. Miranda, and S. Koyejo. Are emergent abilities of large language models a
mirage? In A. Oh, T. Naumann, A. Globerson, K. Saenko, M. Hardt, and S. Levine, editors,
Advances in Neural Information Processing Systems, volume 36, pages 55565–55581. Curran
Associates, Inc., 2023. URL https://proceedings.neurips.cc/paper_files/paper/
2023/file/adc98a266f45005c403b8311ca7e8bd7-Paper-Conference.pdf.
[71] C. Spearman. The proof and measurement of association between two things. 1961.
[72] A. Srivastava, A. Rastogi, A. Rao, A. A. M. Shoeb, A. Abid, A. Fisch, A. R. Brown, A. Santoro,
A. Gupta, A. Garriga-Alonso, et al. Beyond the imitation game: Quantifying and extrapolating
the capabilities of language models. arXiv preprint arXiv:2206.04615, 2022.
[73] G. Team, R. Anil, S. Borgeaud, Y. Wu, J.-B. Alayrac, J. Yu, R. Soricut, J. Schalkwyk, A. M.
Dai, A. Hauth, et al. Gemini: a family of highly capable multimodal models. arXiv preprint
arXiv:2312.11805, 2023.
[74] J. Wei, Y. Tay, R. Bommasani, C. Raffel, B. Zoph, S. Borgeaud, D. Yogatama, M. Bosma,
D. Zhou, D. Metzler, et al. Emergent abilities of large language models. arXiv preprint
arXiv:2206.07682, 2022.
[75] J. Welbl, N. F. Liu, and M. Gardner. Crowdsourcing multiple choice science questions. In
L. Derczynski, W. Xu, A. Ritter, and T. Baldwin, editors, Proceedings of the 3rd Workshop
on Noisy User-generated Text, pages 94–106, Copenhagen, Denmark, Sept. 2017. Association
for Computational Linguistics. doi: 10.18653/v1/W17-4413. URL https://aclanthology.
org/W17-4413.
[76] R. Zellers, A. Holtzman, Y. Bisk, A. Farhadi, and Y. Choi. Hellaswag: Can a machine really
finish your sentence? arXiv preprint arXiv:1905.07830, 2019.
[77] X. Zhai, A. Kolesnikov, N. Houlsby, and L. Beyer. Scaling vision transformers. In Proceedings
of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 12104–12113,
2022.
[78] B. Zhou, D. Khashabi, Q. Ning, and D. Roth. “going on a vacation” takes longer than “going for a
walk”: A study of temporal commonsense understanding. In K. Inui, J. Jiang, V. Ng, and X. Wan,
editors, Proceedings of the 2019 Conference on Empirical Methods in Natural Language Pro-
cessing and the 9th International Joint Conference on Natural Language Processing (EMNLP-
IJCNLP), pages 3363–3369, Hong Kong, China, Nov. 2019. Association for Computational
Linguistics. doi: 10.18653/v1/D19-1332. URL https://aclanthology.org/D19-1332.
14

A
Related Work
Language Model Evaluation
The capabilities of AI models are typically evaluated using con-
structed datasets to assess performance on a specific task, acting as a proxy for some real-world usage
scenario. However, performing robust and reliable evaluations is a challenge, with many potential pit-
falls and unsolved problems [10]. For example, we might prefer to ask models open-ended questions
and evaluate their answers in natural language, but it then often becomes difficult to robustly score the
resulting model outputs, especially for partial correctness. For this reason, it is common practice for
evaluation benchmarks to simplify their scoring via approximations, such as extracting a sub-string
from free-form outputs heuristically [43, 48, 33] and checking that it matches a specific gold target
string, or casting a task to a multiple-choice format, in which a closed set of correct and incorrect
answers is known, and the model’s answer is determined by selecting the most likely option among
these strings. For more details on the precise procedures typically used for multiple choice elsewhere
in the literature, see Biderman et al. [10]. We believe that the multiple-choice format is valuable, due
to its flexibility, popularity and relevance [14, 6, 10], but we discuss its limitations in Section ??.
Scaling Laws
Many neural networks exhibit power-law scaling of the pretraining loss as a function
of the amount of compute, data, or parameters used for training [37, 14, 38]. These neural scaling
laws demonstrate that the pretraining loss can be highly predictable as a function of these fundamental
inputs, which has a number of practical applications: Scaling laws fit to smaller training runs can
be used to predict the pretraining loss of a much larger training run, and can be used to determine
effective hyperparameters [53, 20], or the optimal allocation of dataset and model size for a given
compute budget [38, 58, 21, 69, 7]. In some cases, such laws can be used to predict performance of a
larger model in a particular domain, such as coding [1]. The existence of scaling laws turns deep
learning into a predictable science at the macro level by providing a simple recipe for improving
model quality and de-risking returns on increasing investment into scale [26, 12].
Emergent Abilities
Language models have been observed to exhibit apparent emergent abilities—
behaviors on downstream task performance that cannot be predicted from smaller scales [74, 72].
Emergence appears not to be simply a product of training compute or model size, but is also
dependent on other factors such as dataset composition [56, 74]. Schaeffer et al. [70] find that some
emergent phenomena can be a “mirage” arising due to choices made by researchers such as the use
of discontinuous metrics and insufficient resolution. However, Du et al. [23] note that for many tasks,
emergence remains despite the use of continuous metrics. Additionally, discontinuous metrics have
been argued to often be the most reflective of real-world usefulness, so emergence in these hard
metrics is important. Hu et al. [39] found that for generative evaluations, infinite resolution can be
achieved but requires significant compute and that generated answer be verifiable.
Predicting Downstream Task Performance
Although predicting macroscopic pretraining loss is
useful, a far more useful goal is to predict the scaling of model performance on particular downstream
tasks or domains. If this was possible, then model developers could tune their datasets and training
procedures in a more fine-grained way before launching computationally intensive training runs.
Model performance on a particular downstream task is typically correlated with compute, albeit with
a few exceptions [54, 40]. However, despite attempts to fit scaling laws to values other than loss,
including benchmark scores [25, 41], model memorization [8], or reward [28], these downstream
performance metrics are usually more noisy or require more compute to fit accurately. Owen [63]
and Gadre et al. [25] both find that while aggregate benchmark performance with more compute
can be predicted, the scaling behaviour of individual tasks can be noisy. Additionally, Owen [63],
Du et al. [23] and Gadre et al. [25] claim that predicting scaling behavior on a task without access
to models exhibiting better-than-random performance (i.e., “before emergence occurs”) cannot be
done reliably. Concurrently to our work, Ruan et al. [66] propose Observational Scaling Laws by
mapping model capabilities from compute to a shared low-dimensional space of capabilities across
model families before predicting performance on novel tasks. Our goal in this work is to investigate
the comparative unpredictability of individual downstream performance scores, and advise how to
create more scaling-predictable evaluations that are closely coupled with real-world use-cases.
15

B
Definition of Survival Function
The survival function SX(x) – also known as the reliability function, the tail distribution, or the
complementary cumulative distribution function – gives the probability that a random variable X
exceeds a certain value x [47, 19]:
SX(x)
def
= Pr[X > x] =
Z ∞
x
fX(x′) dx′ = 1 −FX(x)
(7)
where FX(x) = Pr[X ≤x] is the cumulative distribution function (CDF) and fX(x) is the
probability density function (pdf) or probability mass function (pmf) of the random variable X. The
CDF FX(x) gives the probability that the random variable X is at most x, while the survival function
SX(x) gives the probability that X exceeds x.
When the true distribution of X is unknown, we can use the empirical CDF (ECDF) ˆFX(x) and the
empirical survival function (ESF) ˆSX(x):
ˆSX(x)
def
= 1
n
n
X
i=1
1{xi > x} = 1 −ˆFX(x)
(8)
where n is the number of observations, xi is the realized value of the random variable X for
observation i, and 1{xi > x} is the indicator function. The empirical survival function ˆSX(x)
specifies the fraction of observations for which the sampled random variable X exceeds x.
C
Compute Resources for Experiments
Experiments were done across a wide family of model families and sizes. The GPUs we used for
medium-sized models (7B parameters and above) used a single A100s with 80GB of vRAM. For
smaller models (≤8B) we used A100s with 80GB of vRAM, Quadro RTX 8000 with 48GB of vRAM,
or RTX A4000 with 16GB of vRAM. For 70B parameter models, we used at least 2 A100 GPUs with
80GB of vRAM.
D
Additional Model Family Details
Here we provide further experimental details regarding our selection of model families.
1. Pythia [9]: We consider two “families” for Pythia in our experiments. Pythia (Parameter
Scaling) refers to the use of fully-trained checkpoints from 9 different model sizes (all
model sizes documented in Biderman et al. (2023), as well as a 14M parameter model
trained later by the authors). Pythia-12B (Data Scaling) refers to the use of 8 checkpoints
across training for the Pythia-12B model, namely having seen 2M, 64M, 2B, 6B, 20B, 60B,
200B, and 300B tokens in training.
2. Cerebras-GPT [21]: Cerebras (Parameter and Data Scaling) refers to our use of 1
checkpoint per model in the Cerebras-GPT family, each fully trained for differing quantities
of data as documented by the model creators, for 7 checkpoints in total.
3. OLMo [31]: OLMo (7B Data Scaling) refers to the use of 7 checkpoints for OLMo-7B
across training, namely, checkpoints having seen 4B, 44B, 133B, 442B, 885B, 1.5T, and
2.4T tokens.
4. INCITE [2]: INCITE-7B (Data Scaling) considers 6 checkpoints over training for the 7B
parameter model, having seen 240B, 280B, 400B, 500B, 700B, and 1T tokens.
5. LLM360 [50]: LLM360 Amber (Data Scaling) considers 13 checkpoints of the Amber
model, having seen 0B, 3.5B, 7B, 10.5B, 17.5B, 31.5B, 49B, 87.5B, 147B, 252B, 430B,
738B, and 1.26T tokens.
E
Broader Impact
This paper contributes to a better understanding of the predictability of large language models
(LLMs), which can have both positive and negative societal impacts. On the positive side, by making
16

LLM benchmarks more predictable, this research can help society anticipate and plan for potential
challenges associated with their development and deployment. This increased predictability can
facilitate proactive measures to mitigate risks and ensure the responsible use of AI technologies.
However, the increased predictability of LLMs could theoretically be exploited by malicious actors
to accelerate the development of AI systems designed for malicious purposes. We also stress the
importance of proactive risk assessment and the implementation of safeguards to prevent the misuse
of AI technologies.
17

F
Score-Compute Correlation Distributions’ Statistics
F.1
Pearson Correlations
−0.4
−0.2
0.0
0.2
0.4
0.6
0.8
1.0
Mean(Correlations)
ARC-Challenge
ARC-Easy
HellaSwag
MathQA
MC-TACO
MMLU Abstract Algebra
MMLU Anatomy
MMLU Astronomy
MMLU Business Ethics
MMLU Clinical Knowledge
MMLU College Biology
MMLU College Chemistry
MMLU College Comp Sci
MMLU College Maths
MMLU College Medicine
MMLU College Physics
MMLU Comp Security
MMLU Conceptual Physics
MMLU Econometrics
MMLU Electrical Engineering
MMLU Elementary Maths
MMLU Formal Logic
MMLU Global Facts
MMLU HS Biology
MMLU HS Chemistry
MMLU HS Comp Sci
MMLU HS Euro History
MMLU HS Geography
MMLU HS Govt & Politics
MMLU HS Macroeconomics
MMLU HS Maths
MMLU HS Microeconomics
MMLU HS Physics
MMLU HS Psychology
MMLU HS Statistics
MMLU HS US History
MMLU HS World History
MMLU Human Aging
MMLU Human Sexuality
MMLU International Law
MMLU Jurisprudence
MMLU Logical Fallacies
MMLU Machine Learning
MMLU Management
MMLU Marketing
MMLU Medical Genetics
MMLU Miscellaneous
MMLU Moral Disputes
MMLU Moral Scenarios
MMLU Nutrition
MMLU Philosophy
MMLU Prehistory
MMLU Professional Accounting
MMLU Professional Law
MMLU Professional Medicine
MMLU Professional Psychology
MMLU Public Relations
MMLU Security Studies
MMLU Sociology
MMLU US Foreign Policy
MMLU Virology
MMLU World Religions
OpenBookQA
PIQA
PubMedQA
RACE
SciQ
Social Interaction QA
TriviaQA
Winogrande
XWinograd-EN
Benchmark (and Optional Task)
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Median(Correlations)
0.4
0.6
0.8
1.0
1.2
1.4
1.6
1.8
2.0
AUC of Correlations’ Complementary Cumulative Distribution Function
ARC-Challenge
ARC-Easy
HellaSwag
MathQA
MC-TACO
MMLU Abstract Algebra
MMLU Anatomy
MMLU Astronomy
MMLU Business Ethics
MMLU Clinical Knowledge
MMLU College Biology
MMLU College Chemistry
MMLU College Comp Sci
MMLU College Maths
MMLU College Medicine
MMLU College Physics
MMLU Comp Security
MMLU Conceptual Physics
MMLU Econometrics
MMLU Electrical Engineering
MMLU Elementary Maths
MMLU Formal Logic
MMLU Global Facts
MMLU HS Biology
MMLU HS Chemistry
MMLU HS Comp Sci
MMLU HS Euro History
MMLU HS Geography
MMLU HS Govt & Politics
MMLU HS Macroeconomics
MMLU HS Maths
MMLU HS Microeconomics
MMLU HS Physics
MMLU HS Psychology
MMLU HS Statistics
MMLU HS US History
MMLU HS World History
MMLU Human Aging
MMLU Human Sexuality
MMLU International Law
MMLU Jurisprudence
MMLU Logical Fallacies
MMLU Machine Learning
MMLU Management
MMLU Marketing
MMLU Medical Genetics
MMLU Miscellaneous
MMLU Moral Disputes
MMLU Moral Scenarios
MMLU Nutrition
MMLU Philosophy
MMLU Prehistory
MMLU Professional Accounting
MMLU Professional Law
MMLU Professional Medicine
MMLU Professional Psychology
MMLU Public Relations
MMLU Security Studies
MMLU Sociology
MMLU US Foreign Policy
MMLU Virology
MMLU World Religions
OpenBookQA
PIQA
PubMedQA
RACE
SciQ
Social Interaction QA
TriviaQA
Winogrande
XWinograd-EN
Benchmark (and Optional Task)
−1.0
−0.8
−0.6
−0.4
−0.2
0.0
-Min(Wasserstein(Correlations, 1), Wasserstein(Correlations, -1))
Correlation Distribution Statistics by Benchmark and Metric (Pearson Correlations)
Metric
log pVocab
θ
(Correct Choice)
pVocab
θ
(Correct Choice)
pChoices
θ
(Correct Choice)
Brier Score
Accuracy
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
Figure 7: Statistics for empirical distributions of correlations between scores and compute
for all benchmarks and model families. These correlation values were computed with Pearson
correlation and are consistent with the main text’s results computed with Spearman correlation (Fig.
4): The sequence of transformations from log pVocab
θ
(Correct Choice) →pVocab
θ
(Correct Choice) →
pChoices
θ
(Correct Choice) →Accuracy degrades predictability.
18

F.2
Spearman Correlations
−0.4
−0.2
0.0
0.2
0.4
0.6
0.8
1.0
Mean(Correlations)
ARC-Challenge
ARC-Easy
HellaSwag
MathQA
MC-TACO
MMLU Abstract Algebra
MMLU Anatomy
MMLU Astronomy
MMLU Business Ethics
MMLU Clinical Knowledge
MMLU College Biology
MMLU College Chemistry
MMLU College Comp Sci
MMLU College Maths
MMLU College Medicine
MMLU College Physics
MMLU Comp Security
MMLU Conceptual Physics
MMLU Econometrics
MMLU Electrical Engineering
MMLU Elementary Maths
MMLU Formal Logic
MMLU Global Facts
MMLU HS Biology
MMLU HS Chemistry
MMLU HS Comp Sci
MMLU HS Euro History
MMLU HS Geography
MMLU HS Govt & Politics
MMLU HS Macroeconomics
MMLU HS Maths
MMLU HS Microeconomics
MMLU HS Physics
MMLU HS Psychology
MMLU HS Statistics
MMLU HS US History
MMLU HS World History
MMLU Human Aging
MMLU Human Sexuality
MMLU International Law
MMLU Jurisprudence
MMLU Logical Fallacies
MMLU Machine Learning
MMLU Management
MMLU Marketing
MMLU Medical Genetics
MMLU Miscellaneous
MMLU Moral Disputes
MMLU Moral Scenarios
MMLU Nutrition
MMLU Philosophy
MMLU Prehistory
MMLU Professional Accounting
MMLU Professional Law
MMLU Professional Medicine
MMLU Professional Psychology
MMLU Public Relations
MMLU Security Studies
MMLU Sociology
MMLU US Foreign Policy
MMLU Virology
MMLU World Religions
OpenBookQA
PIQA
PubMedQA
RACE
SciQ
Social Interaction QA
TriviaQA
Winogrande
XWinograd-EN
Benchmark (and Optional Task)
−0.6
−0.4
−0.2
0.0
0.2
0.4
0.6
0.8
1.0
Median(Correlations)
0.6
0.8
1.0
1.2
1.4
1.6
1.8
2.0
AUC of Correlations’ Complementary Cumulative Distribution Function
ARC-Challenge
ARC-Easy
HellaSwag
MathQA
MC-TACO
MMLU Abstract Algebra
MMLU Anatomy
MMLU Astronomy
MMLU Business Ethics
MMLU Clinical Knowledge
MMLU College Biology
MMLU College Chemistry
MMLU College Comp Sci
MMLU College Maths
MMLU College Medicine
MMLU College Physics
MMLU Comp Security
MMLU Conceptual Physics
MMLU Econometrics
MMLU Electrical Engineering
MMLU Elementary Maths
MMLU Formal Logic
MMLU Global Facts
MMLU HS Biology
MMLU HS Chemistry
MMLU HS Comp Sci
MMLU HS Euro History
MMLU HS Geography
MMLU HS Govt & Politics
MMLU HS Macroeconomics
MMLU HS Maths
MMLU HS Microeconomics
MMLU HS Physics
MMLU HS Psychology
MMLU HS Statistics
MMLU HS US History
MMLU HS World History
MMLU Human Aging
MMLU Human Sexuality
MMLU International Law
MMLU Jurisprudence
MMLU Logical Fallacies
MMLU Machine Learning
MMLU Management
MMLU Marketing
MMLU Medical Genetics
MMLU Miscellaneous
MMLU Moral Disputes
MMLU Moral Scenarios
MMLU Nutrition
MMLU Philosophy
MMLU Prehistory
MMLU Professional Accounting
MMLU Professional Law
MMLU Professional Medicine
MMLU Professional Psychology
MMLU Public Relations
MMLU Security Studies
MMLU Sociology
MMLU US Foreign Policy
MMLU Virology
MMLU World Religions
OpenBookQA
PIQA
PubMedQA
RACE
SciQ
Social Interaction QA
TriviaQA
Winogrande
XWinograd-EN
Benchmark (and Optional Task)
−1.0
−0.8
−0.6
−0.4
−0.2
0.0
-Min(Wasserstein(Correlations, 1), Wasserstein(Correlations, -1))
Correlation Distribution Statistics by Benchmark and Metric (Spearman Correlations)
Metric
log pVocab
θ
(Correct Choice)
pVocab
θ
(Correct Choice)
pChoices
θ
(Correct Choice)
Brier Score
Accuracy
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
Figure 8: Statistics for empirical distributions of correlations between scores and compute for all
benchmarks and model families. These correlation values were computed with Spearman correla-
tion. The sequence of transformations from log pVocab
θ
(Correct Choice) →pVocab
θ
(Correct Choice) →
pChoices
θ
(Correct Choice) →Accuracy degrades predictability.
19

F.3
Kendall Correlations
−0.4
−0.2
0.0
0.2
0.4
0.6
0.8
1.0
Mean(Correlations)
ARC-Challenge
ARC-Easy
HellaSwag
MathQA
MC-TACO
MMLU Abstract Algebra
MMLU Anatomy
MMLU Astronomy
MMLU Business Ethics
MMLU Clinical Knowledge
MMLU College Biology
MMLU College Chemistry
MMLU College Comp Sci
MMLU College Maths
MMLU College Medicine
MMLU College Physics
MMLU Comp Security
MMLU Conceptual Physics
MMLU Econometrics
MMLU Electrical Engineering
MMLU Elementary Maths
MMLU Formal Logic
MMLU Global Facts
MMLU HS Biology
MMLU HS Chemistry
MMLU HS Comp Sci
MMLU HS Euro History
MMLU HS Geography
MMLU HS Govt & Politics
MMLU HS Macroeconomics
MMLU HS Maths
MMLU HS Microeconomics
MMLU HS Physics
MMLU HS Psychology
MMLU HS Statistics
MMLU HS US History
MMLU HS World History
MMLU Human Aging
MMLU Human Sexuality
MMLU International Law
MMLU Jurisprudence
MMLU Logical Fallacies
MMLU Machine Learning
MMLU Management
MMLU Marketing
MMLU Medical Genetics
MMLU Miscellaneous
MMLU Moral Disputes
MMLU Moral Scenarios
MMLU Nutrition
MMLU Philosophy
MMLU Prehistory
MMLU Professional Accounting
MMLU Professional Law
MMLU Professional Medicine
MMLU Professional Psychology
MMLU Public Relations
MMLU Security Studies
MMLU Sociology
MMLU US Foreign Policy
MMLU Virology
MMLU World Religions
OpenBookQA
PIQA
PubMedQA
RACE
SciQ
Social Interaction QA
TriviaQA
Winogrande
XWinograd-EN
Benchmark (and Optional Task)
−0.4
−0.2
0.0
0.2
0.4
0.6
0.8
1.0
Median(Correlations)
0.6
0.8
1.0
1.2
1.4
1.6
1.8
2.0
AUC of Correlations’ Complementary Cumulative Distribution Function
ARC-Challenge
ARC-Easy
HellaSwag
MathQA
MC-TACO
MMLU Abstract Algebra
MMLU Anatomy
MMLU Astronomy
MMLU Business Ethics
MMLU Clinical Knowledge
MMLU College Biology
MMLU College Chemistry
MMLU College Comp Sci
MMLU College Maths
MMLU College Medicine
MMLU College Physics
MMLU Comp Security
MMLU Conceptual Physics
MMLU Econometrics
MMLU Electrical Engineering
MMLU Elementary Maths
MMLU Formal Logic
MMLU Global Facts
MMLU HS Biology
MMLU HS Chemistry
MMLU HS Comp Sci
MMLU HS Euro History
MMLU HS Geography
MMLU HS Govt & Politics
MMLU HS Macroeconomics
MMLU HS Maths
MMLU HS Microeconomics
MMLU HS Physics
MMLU HS Psychology
MMLU HS Statistics
MMLU HS US History
MMLU HS World History
MMLU Human Aging
MMLU Human Sexuality
MMLU International Law
MMLU Jurisprudence
MMLU Logical Fallacies
MMLU Machine Learning
MMLU Management
MMLU Marketing
MMLU Medical Genetics
MMLU Miscellaneous
MMLU Moral Disputes
MMLU Moral Scenarios
MMLU Nutrition
MMLU Philosophy
MMLU Prehistory
MMLU Professional Accounting
MMLU Professional Law
MMLU Professional Medicine
MMLU Professional Psychology
MMLU Public Relations
MMLU Security Studies
MMLU Sociology
MMLU US Foreign Policy
MMLU Virology
MMLU World Religions
OpenBookQA
PIQA
PubMedQA
RACE
SciQ
Social Interaction QA
TriviaQA
Winogrande
XWinograd-EN
Benchmark (and Optional Task)
−1.0
−0.8
−0.6
−0.4
−0.2
-Min(Wasserstein(Correlations, 1), Wasserstein(Correlations, -1))
Correlation Distribution Statistics by Benchmark and Metric (Kendall Correlations)
Metric
log pVocab
θ
(Correct Choice)
pVocab
θ
(Correct Choice)
pChoices
θ
(Correct Choice)
Brier Score
Accuracy
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
Figure 9: Statistics for empirical distributions of correlations between scores and compute
for all benchmarks and model families. These correlation values were computed with Kendall
correlation and are consistent with the main text’s results computed with Spearman correlation (Fig.
4): The sequence of transformations from log pVocab
θ
(Correct Choice) →pVocab
θ
(Correct Choice) →
pChoices
θ
(Correct Choice) →Accuracy degrades predictability.
20

G
Per-Benchmark Score-Compute Correlation Distributions
G.1
NLP Benchmark: ARC Challenge [17]
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
ARC-Challenge
log pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
ARC-Challenge
pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
ARC-Challenge
pChoices
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
ARC-Challenge
Accuracy
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
Figure 10: ARC Challenge: Downstream performance is computed via a sequence of transfor-
mations that deteriorate correlations between scores and pretraining compute.
21

G.2
NLP Benchmark: ARC Easy [17]
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
ARC-Easy
log pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
ARC-Easy
pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
ARC-Easy
pChoices
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
ARC-Easy
Accuracy
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
Figure 11: ARC Easy: Downstream performance is computed via a sequence of transformations
that deteriorate correlations between scores and pretraining compute.
22

G.3
NLP Benchmark: HellaSwag [76]
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
HellaSwag
log pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
HellaSwag
pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
HellaSwag
pChoices
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
HellaSwag
Accuracy
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
Figure 12: HellaSwag: Downstream performance is computed via a sequence of transformations
that deteriorate correlations between scores and pretraining compute.
23

G.4
NLP Benchmark: MathQA [3]
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MathQA
log pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MathQA
pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MathQA
pChoices
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MathQA
Accuracy
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
Figure 13: HellaSwag: Downstream performance is computed via a sequence of transformations
that deteriorate correlations between scores and pretraining compute.
24

G.5
NLP Benchmark: MC TACO [78]
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MC-TACO
log pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MC-TACO
pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MC-TACO
pChoices
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MC-TACO
Accuracy
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
Figure 14: MC TACO: Downstream performance is computed via a sequence of transformations
that deteriorate correlations between scores and pretraining compute.
25

G.6
NLP Benchmark: MMLU Abstract Algebra [32]
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Abstract Algebra
log pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Abstract Algebra
pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Abstract Algebra
pChoices
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Abstract Algebra
Accuracy
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
Figure 15: MMLU Abstract Algebra: Downstream performance is computed via a sequence of
transformations that deteriorate correlations between scores and pretraining compute.
26

G.7
NLP Benchmark: MMLU Anatomy [32]
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Anatomy
log pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Anatomy
pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Anatomy
pChoices
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Anatomy
Accuracy
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
Figure 16: MMLU Anatomy: Downstream performance is computed via a sequence of transfor-
mations that deteriorate correlations between scores and pretraining compute.
27

G.8
NLP Benchmark: MMLU Astronomy [32]
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Astronomy
log pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Astronomy
pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Astronomy
pChoices
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Astronomy
Accuracy
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
Figure 17: MMLU Astronomy: Downstream performance is computed via a sequence of
transformations that deteriorate correlations between scores and pretraining compute.
28

G.9
NLP Benchmark: MMLU Business Ethics [32]
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Business Ethics
log pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Business Ethics
pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Business Ethics
pChoices
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Business Ethics
Accuracy
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
Figure 18: MMLU Business Ethics: Downstream performance is computed via a sequence of
transformations that deteriorate correlations between scores and pretraining compute.
29

G.10
NLP Benchmark: MMLU Clinical Knowledge [32]
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Clinical Knowledge
log pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Clinical Knowledge
pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Clinical Knowledge
pChoices
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Clinical Knowledge
Accuracy
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
Figure 19: MMLU Clinical Knowledge: Downstream performance is computed via a sequence
of transformations that deteriorate correlations between scores and pretraining compute.
30

G.11
NLP Benchmark: MMLU College Biology [32]
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU College Biology
log pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU College Biology
pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU College Biology
pChoices
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU College Biology
Accuracy
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
Figure 20: MMLU College Biology: Downstream performance is computed via a sequence of
transformations that deteriorate correlations between scores and pretraining compute.
31

G.12
NLP Benchmark: MMLU College Chemistry [32]
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU College Chemistry
log pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU College Chemistry
pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU College Chemistry
pChoices
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU College Chemistry
Accuracy
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
Figure 21: MMLU College Chemistry: Downstream performance is computed via a sequence of
transformations that deteriorate correlations between scores and pretraining compute.
32

G.13
NLP Benchmark: MMLU College Computer Science [32]
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU College Comp Sci
log pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU College Comp Sci
pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU College Comp Sci
pChoices
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU College Comp Sci
Accuracy
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
Figure 22: MMLU College Computer Science: Downstream performance is computed via
a sequence of transformations that deteriorate correlations between scores and pretraining
compute.
33

G.14
NLP Benchmark: MMLU College Mathematics [32]
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU College Maths
log pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU College Maths
pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU College Maths
pChoices
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU College Maths
Accuracy
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
Figure 23: MMLU College Mathematics: Downstream performance is computed via a sequence
of transformations that deteriorate correlations between scores and pretraining compute.
34

G.15
NLP Benchmark: MMLU College Medicine [32]
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU College Medicine
log pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU College Medicine
pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU College Medicine
pChoices
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU College Medicine
Accuracy
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
Figure 24: MMLU College Medicine: Downstream performance is computed via a sequence of
transformations that deteriorate correlations between scores and pretraining compute.
35

G.16
NLP Benchmark: MMLU College Physics [32]
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU College Physics
log pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU College Physics
pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU College Physics
pChoices
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU College Physics
Accuracy
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
Figure 25: MMLU College Physics: Downstream performance is computed via a sequence of
transformations that deteriorate correlations between scores and pretraining compute.
36

G.17
NLP Benchmark: MMLU Computer Security [32]
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Comp Security
log pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Comp Security
pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Comp Security
pChoices
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Comp Security
Accuracy
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
Figure 26: MMLU Computer Security: Downstream performance is computed via a sequence
of transformations that deteriorate correlations between scores and pretraining compute.
37

G.18
NLP Benchmark: MMLU Conceptual Physics [32]
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Conceptual Physics
log pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Conceptual Physics
pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Conceptual Physics
pChoices
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Conceptual Physics
Accuracy
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
Figure 27: MMLU Conceptual Physics: Downstream performance is computed via a sequence
of transformations that deteriorate correlations between scores and pretraining compute.
38

G.19
NLP Benchmark: MMLU Econometrics [32]
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Econometrics
log pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Econometrics
pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Econometrics
pChoices
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Econometrics
Accuracy
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
Figure 28: MMLU Econometrics: Downstream performance is computed via a sequence of
transformations that deteriorate correlations between scores and pretraining compute.
39

G.20
NLP Benchmark: MMLU Electrical Engineering [32]
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Electrical Engineering
log pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Electrical Engineering
pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Electrical Engineering
pChoices
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Electrical Engineering
Accuracy
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
Figure 29: MMLU Electrical Engineering: Downstream performance is computed via a sequence
of transformations that deteriorate correlations between scores and pretraining compute.
40

G.21
NLP Benchmark: MMLU Elementary Mathematics [32]
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Elementary Maths
log pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Elementary Maths
pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Elementary Maths
pChoices
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Elementary Maths
Accuracy
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
Figure 30: MMLU Elementary Mathematics: Downstream performance is computed via a
sequence of transformations that deteriorate correlations between scores and pretraining
compute.
41

G.22
NLP Benchmark: MMLU Formal Logic [32]
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Formal Logic
log pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Formal Logic
pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Formal Logic
pChoices
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Formal Logic
Accuracy
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
Figure 31: MMLU Formal Logic: Downstream performance is computed via a sequence of
transformations that deteriorate correlations between scores and pretraining compute.
42

G.23
NLP Benchmark: MMLU Global Facts [32]
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Global Facts
log pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Global Facts
pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Global Facts
pChoices
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Global Facts
Accuracy
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
Figure 32: MMLU Global Facts: Downstream performance is computed via a sequence of
transformations that deteriorate correlations between scores and pretraining compute.
43

G.24
NLP Benchmark: MMLU High School Biology [32]
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU HS Biology
log pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU HS Biology
pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU HS Biology
pChoices
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU HS Biology
Accuracy
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
Figure 33: MMLU High School Biology: Downstream performance is computed via a sequence
of transformations that deteriorate correlations between scores and pretraining compute.
44

G.25
NLP Benchmark: MMLU High School Chemistry [32]
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU HS Chemistry
log pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU HS Chemistry
pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU HS Chemistry
pChoices
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU HS Chemistry
Accuracy
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
Figure 34: MMLU High School Chemistry: Downstream performance is computed via a
sequence of transformations that deteriorate correlations between scores and pretraining
compute.
45

G.26
NLP Benchmark: MMLU High School Computer Science [32]
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU HS Comp Sci
log pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU HS Comp Sci
pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU HS Comp Sci
pChoices
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU HS Comp Sci
Accuracy
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
Figure 35: MMLU High School Computer Science: Downstream performance is computed via
a sequence of transformations that deteriorate correlations between scores and pretraining
compute.
46

G.27
NLP Benchmark: MMLU High School Chemistry [32]
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU HS Chemistry
log pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU HS Chemistry
pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU HS Chemistry
pChoices
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU HS Chemistry
Accuracy
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
Figure 36: MMLU High School Chemistry: Downstream performance is computed via a
sequence of transformations that deteriorate correlations between scores and pretraining
compute.
47

G.28
NLP Benchmark: MMLU High School European History [32]
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU HS Euro History
log pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU HS Euro History
pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU HS Euro History
pChoices
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU HS Euro History
Accuracy
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
Figure 37: MMLU High School European History: Downstream performance is computed via
a sequence of transformations that deteriorate correlations between scores and pretraining
compute.
48

G.29
NLP Benchmark: MMLU High School Geography [32]
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU HS Geography
log pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU HS Geography
pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU HS Geography
pChoices
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU HS Geography
Accuracy
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
Figure 38: MMLU High School Geography: Downstream performance is computed via a
sequence of transformations that deteriorate correlations between scores and pretraining
compute.
49

G.30
NLP Benchmark: MMLU High School Government & Politics [32]
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU HS Govt & Politics
log pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU HS Govt & Politics
pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU HS Govt & Politics
pChoices
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU HS Govt & Politics
Accuracy
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
Figure 39: MMLU High School Government & Politics: Downstream performance is computed
via a sequence of transformations that deteriorate correlations between scores and pretraining
compute.
50

G.31
NLP Benchmark: MMLU High School Macroeconomics [32]
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU HS Macroeconomics
log pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU HS Macroeconomics
pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU HS Macroeconomics
pChoices
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU HS Macroeconomics
Accuracy
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
Figure 40: MMLU High School Macroeconomics: Downstream performance is computed via
a sequence of transformations that deteriorate correlations between scores and pretraining
compute.
51

G.32
NLP Benchmark: MMLU High School Mathematics [32]
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU HS Maths
log pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU HS Maths
pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU HS Maths
pChoices
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU HS Maths
Accuracy
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
Figure 41: MMLU High School Mathematics: Downstream performance is computed via
a sequence of transformations that deteriorate correlations between scores and pretraining
compute.
52

G.33
NLP Benchmark: MMLU High School Microeconomics [32]
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU HS Microeconomics
log pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU HS Microeconomics
pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU HS Microeconomics
pChoices
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU HS Microeconomics
Accuracy
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
Figure 42: MMLU High School Microeconomics: Downstream performance is computed via
a sequence of transformations that deteriorate correlations between scores and pretraining
compute.
53

G.34
NLP Benchmark: MMLU High School Physics [32]
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU HS Physics
log pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU HS Physics
pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU HS Physics
pChoices
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU HS Physics
Accuracy
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
Figure 43: MMLU High School Physics: Downstream performance is computed via a sequence
of transformations that deteriorate correlations between scores and pretraining compute.
54

G.35
NLP Benchmark: MMLU High School Psychology [32]
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU HS Psychology
log pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU HS Psychology
pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU HS Psychology
pChoices
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU HS Psychology
Accuracy
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
Figure 44: MMLU High School Psychology: Downstream performance is computed via a
sequence of transformations that deteriorate correlations between scores and pretraining
compute.
55

G.36
NLP Benchmark: MMLU High School Statistics [32]
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU HS Statistics
log pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU HS Statistics
pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU HS Statistics
pChoices
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU HS Statistics
Accuracy
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
Figure 45: MMLU High School Statistics: Downstream performance is computed via a sequence
of transformations that deteriorate correlations between scores and pretraining compute.
56

G.37
NLP Benchmark: MMLU High School US History [32]
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU HS US History
log pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU HS US History
pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU HS US History
pChoices
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU HS US History
Accuracy
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
Figure 46: MMLU High School US History: Downstream performance is computed via a
sequence of transformations that deteriorate correlations between scores and pretraining
compute.
57

G.38
NLP Benchmark: MMLU High School World History [32]
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU HS World History
log pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU HS World History
pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU HS World History
pChoices
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU HS World History
Accuracy
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
Figure 47: MMLU High School World History: Downstream performance is computed via
a sequence of transformations that deteriorate correlations between scores and pretraining
compute.
58

G.39
NLP Benchmark: MMLU Human Aging [32]
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Human Aging
log pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Human Aging
pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Human Aging
pChoices
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Human Aging
Accuracy
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
Figure 48: MMLU Human Aging: Downstream performance is computed via a sequence of
transformations that deteriorate correlations between scores and pretraining compute.
59

G.40
NLP Benchmark: MMLU Human Sexuality [32]
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Human Sexuality
log pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Human Sexuality
pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Human Sexuality
pChoices
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Human Sexuality
Accuracy
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
Figure 49: MMLU Human Sexuality: Downstream performance is computed via a sequence of
transformations that deteriorate correlations between scores and pretraining compute.
60

G.41
NLP Benchmark: MMLU International Law [32]
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU International Law
log pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU International Law
pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU International Law
pChoices
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU International Law
Accuracy
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
Figure 50: MMLU International Law: Downstream performance is computed via a sequence of
transformations that deteriorate correlations between scores and pretraining compute.
61

G.42
NLP Benchmark: MMLU Jurisprudence [32]
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Jurisprudence
log pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Jurisprudence
pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Jurisprudence
pChoices
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Jurisprudence
Accuracy
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
Figure 51: MMLU Jurisprudence: Downstream performance is computed via a sequence of
transformations that deteriorate correlations between scores and pretraining compute.
62

G.43
NLP Benchmark: MMLU Logical Fallacies [32]
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Logical Fallacies
log pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Logical Fallacies
pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Logical Fallacies
pChoices
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Logical Fallacies
Accuracy
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
Figure 52: MMLU Logical Fallacies: Downstream performance is computed via a sequence of
transformations that deteriorate correlations between scores and pretraining compute.
63

G.44
NLP Benchmark: MMLU Machine Learning [32]
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Machine Learning
log pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Machine Learning
pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Machine Learning
pChoices
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Machine Learning
Accuracy
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
Figure 53: MMLU Machine Learning: Downstream performance is computed via a sequence of
transformations that deteriorate correlations between scores and pretraining compute.
64

G.45
NLP Benchmark: MMLU Management [32]
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Management
log pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Management
pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Management
pChoices
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Management
Accuracy
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
Figure 54: MMLU Management: Downstream performance is computed via a sequence of
transformations that deteriorate correlations between scores and pretraining compute.
65

G.46
NLP Benchmark: MMLU Marketing [32]
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Marketing
log pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Marketing
pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Marketing
pChoices
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Marketing
Accuracy
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
Figure 55: MMLU Marketing: Downstream performance is computed via a sequence of
transformations that deteriorate correlations between scores and pretraining compute.
66

G.47
NLP Benchmark: MMLU Medical Genetics [32]
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Medical Genetics
log pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Medical Genetics
pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Medical Genetics
pChoices
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Medical Genetics
Accuracy
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
Figure 56: MMLU Medical Genetics: Downstream performance is computed via a sequence of
transformations that deteriorate correlations between scores and pretraining compute.
67

G.48
NLP Benchmark: MMLU Miscellaneous [32]
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Miscellaneous
log pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Miscellaneous
pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Miscellaneous
pChoices
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Miscellaneous
Accuracy
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
Figure 57: MMLU Miscellaneous: Downstream performance is computed via a sequence of
transformations that deteriorate correlations between scores and pretraining compute.
68

G.49
NLP Benchmark: MMLU Moral Disputes [32]
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Moral Disputes
log pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Moral Disputes
pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Moral Disputes
pChoices
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Moral Disputes
Accuracy
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
Figure 58: MMLU Moral Disputes: Downstream performance is computed via a sequence of
transformations that deteriorate correlations between scores and pretraining compute.
69

G.50
NLP Benchmark: MMLU Moral Scenarios [32]
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Moral Scenarios
log pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Moral Scenarios
pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Moral Scenarios
pChoices
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Moral Scenarios
Accuracy
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
Figure 59: MMLU Moral Scenarios: Downstream performance is computed via a sequence of
transformations that deteriorate correlations between scores and pretraining compute.
70

G.51
NLP Benchmark: MMLU Nutrition [32]
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Nutrition
log pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Nutrition
pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Nutrition
pChoices
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Nutrition
Accuracy
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
Figure 60: MMLU Nutrition: Downstream performance is computed via a sequence of transfor-
mations that deteriorate correlations between scores and pretraining compute.
71

G.52
NLP Benchmark: MMLU Philosophy [32]
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Philosophy
log pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Philosophy
pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Philosophy
pChoices
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Philosophy
Accuracy
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
Figure 61: MMLU Philosophy: Downstream performance is computed via a sequence of
transformations that deteriorate correlations between scores and pretraining compute.
72

G.53
NLP Benchmark: MMLU Prehistory [32]
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Prehistory
log pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Prehistory
pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Prehistory
pChoices
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Prehistory
Accuracy
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
Figure 62: MMLU Prehistory: Downstream performance is computed via a sequence of trans-
formations that deteriorate correlations between scores and pretraining compute.
73

G.54
NLP Benchmark: MMLU Professional Accounting [32]
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Professional Accounting
log pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Professional Accounting
pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Professional Accounting
pChoices
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Professional Accounting
Accuracy
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
Figure 63: MMLU Professional Accounting: Downstream performance is computed via a
sequence of transformations that deteriorate correlations between scores and pretraining
compute.
74

G.55
NLP Benchmark: MMLU Professional Law [32]
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Professional Law
log pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Professional Law
pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Professional Law
pChoices
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Professional Law
Accuracy
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
Figure 64: MMLU Professional Law: Downstream performance is computed via a sequence of
transformations that deteriorate correlations between scores and pretraining compute.
75

G.56
NLP Benchmark: MMLU Professional Medicine [32]
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Professional Medicine
log pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Professional Medicine
pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Professional Medicine
pChoices
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Professional Medicine
Accuracy
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
Figure 65: MMLU Professional Medicine: Downstream performance is computed via a sequence
of transformations that deteriorate correlations between scores and pretraining compute.
76

G.57
NLP Benchmark: MMLU Professional Psychology [32]
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Professional Psychology
log pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Professional Psychology
pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Professional Psychology
pChoices
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Professional Psychology
Accuracy
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
Figure 66: MMLU Professional Psychology: Downstream performance is computed via a
sequence of transformations that deteriorate correlations between scores and pretraining
compute.
77

G.58
NLP Benchmark: MMLU Public Relations [32]
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Public Relations
log pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Public Relations
pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Public Relations
pChoices
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Public Relations
Accuracy
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
Figure 67: MMLU Public Relations: Downstream performance is computed via a sequence of
transformations that deteriorate correlations between scores and pretraining compute.
78

G.59
NLP Benchmark: MMLU Security Studies [32]
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Security Studies
log pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Security Studies
pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Security Studies
pChoices
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Security Studies
Accuracy
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
Figure 68: MMLU Security Studies: Downstream performance is computed via a sequence of
transformations that deteriorate correlations between scores and pretraining compute.
79

G.60
NLP Benchmark: MMLU Sociology [32]
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Sociology
log pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Sociology
pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Sociology
pChoices
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Sociology
Accuracy
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
Figure 69: MMLU Sociology: Downstream performance is computed via a sequence of transfor-
mations that deteriorate correlations between scores and pretraining compute.
80

G.61
NLP Benchmark: MMLU US Foreign Policy [32]
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU US Foreign Policy
log pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU US Foreign Policy
pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU US Foreign Policy
pChoices
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU US Foreign Policy
Accuracy
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
Figure 70: MMLU US Foreign Policy: Downstream performance is computed via a sequence of
transformations that deteriorate correlations between scores and pretraining compute.
81

G.62
NLP Benchmark: MMLU Virology [32]
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Virology
log pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Virology
pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Virology
pChoices
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU Virology
Accuracy
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
Figure 71: MMLU Virology: Downstream performance is computed via a sequence of transfor-
mations that deteriorate correlations between scores and pretraining compute.
82

G.63
NLP Benchmark: MMLU World Religions [32]
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU World Religions
log pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU World Religions
pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU World Religions
pChoices
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
MMLU World Religions
Accuracy
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
Figure 72: MMLU World Religions: Downstream performance is computed via a sequence of
transformations that deteriorate correlations between scores and pretraining compute.
83

G.64
NLP Benchmark: OpenBookQA [55]
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
OpenBookQA
log pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
OpenBookQA
pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
OpenBookQA
pChoices
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
OpenBookQA
Accuracy
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
Figure 73: OpenBookQA: Downstream performance is computed via a sequence of transforma-
tions that deteriorate correlations between scores and pretraining compute.
84

G.65
NLP Benchmark: PIQA [11]
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
PIQA
log pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
PIQA
pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
PIQA
pChoices
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
PIQA
Accuracy
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
Figure 74: PIQA: Downstream performance is computed via a sequence of transformations that
deteriorate correlations between scores and pretraining compute.
85

G.66
NLP Benchmark: RACE [49]
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
RACE
log pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
RACE
pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
RACE
pChoices
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
RACE
Accuracy
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
Figure 75: RACE: Downstream performance is computed via a sequence of transformations
that deteriorate correlations between scores and pretraining compute.
86

G.67
NLP Benchmark: SciQ [75]
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
SciQ
log pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
SciQ
pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
SciQ
pChoices
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
SciQ
Accuracy
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
Figure 76: SciQ: Downstream performance is computed via a sequence of transformations that
deteriorate correlations between scores and pretraining compute.
87

G.68
NLP Benchmark: Social IQA [68]
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
Social Interaction QA
log pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
Social Interaction QA
pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
Social Interaction QA
pChoices
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
Social Interaction QA
Accuracy
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
Figure 77: Social IQA: Downstream performance is computed via a sequence of transformations
that deteriorate correlations between scores and pretraining compute.
88

G.69
NLP Benchmark: Winogrande [45]
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
Winogrande
log pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
Winogrande
pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
Winogrande
pChoices
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - ECDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
Winogrande
Accuracy
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
Figure 78: Social IQA: Downstream performance is computed via a sequence of transformations
that deteriorate correlations between scores and pretraining compute.
89

G.70
NLP Benchmark: XWinograd English [57]
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - CDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
XWinograd-EN
log pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - CDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
XWinograd-EN
pVocab
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - CDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
XWinograd-EN
pChoices
θ
(Correct Choice)
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
0.0
0.2
0.4
0.6
0.8
1.0
1 - CDF
Correlation: spearman
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: pearson
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Correlation Between FLOPs and Scores (Per Sample)
Correlation: kendall
XWinograd-EN
Accuracy
Model Family
Cerebras (Param. and Data Scaling)
INCITE 7B Param. (Data Scaling)
LLM360 Amber 7B Tokens (Param Scaling)
OLMo 7B Param. (Data Scaling)
Pythia 12B Param. (Data Scaling)
Pythia 300B Tokens (Param. Scaling)
Figure 79: XWinograd English: Downstream performance is computed via a sequence of
transformations that deteriorate correlations between scores and pretraining compute.
90

