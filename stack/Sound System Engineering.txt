
Sound System Engineering


Sound System Engineering
Fourth Edition
Don Davis
Eugene Patronis, Jr.
Pat Brown
Edited by
Glen Ballou

First published 1975
by Howard W. Sams & Co., Inc.
Indianapolis, Indiana 46268
This edition published 2013
by Focal Press
70 Blanchard Road, Suite 402, Burlington, MA 01803
Simultaneously published in the UK
by Focal Press
2 Park Square, Milton Park, Abingdon, Oxon OX14 4RN
Focal Press is an imprint of the Taylor & Francis Group, an informa business 
© 2013 Don Davis, Eugene Patronis, Jr. and Pat Brown
The right of Don Davis, Eugene Patronis, Jr. and Pat Brown to be identified as the authors of 
this work has been asserted by them in accordance with sections 77 and 78 of the Copyright, 
Designs and Patents Act 1988.
All rights reserved. No part of this book may be reprinted or reproduced or utilised in any form 
or by any electronic, mechanical, or other means, now known or hereafter invented, including 
photocopying and recording, or in any information storage or retrieval system, without 
permission in writing from the publishers.
Notices
Knowledge and best practice in this field are constantly changing. As new research and 
experience broaden our understanding, changes in research methods, professional practices, 
or medical treatment may become necessary.
Practitioners and researchers must always rely on their own experience and knowledge in 
evaluating and using any information, methods, compounds, or experiments described herein. 
In using such information or methods they should be mindful of their own safety and the 
safety of others, including parties for whom they have a professional responsibility. 
Product or corporate names may be trademarks or registered trademarks, and are used only 
for identification and explanation without intent to infringe.
Library of Congress Cataloging in Publication Data
CIP data has been applied for
ISBN: 978-0-240-81846-7 (hbk)
ISBN: 978-0-240-81847-4 (ebk)
Typeset in Times New Roman and Optimum 
by Glen Ballou

The fourth edition of Sound System Engineering is dedicated to
Carolyn Davis
who is the catalyst that made it happen
and is the glue that held it all together.


   Contents
vii
Preface  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .xv
Chapter 1 Why Sound System Engineering? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .1
Prerequisites . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .3
Basic Electrical Training . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .3
Mathematics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .3
Hearing Versus Listening . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .3
Craftsmanship  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .4
Rigging  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .4
Literacy  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .4
The Art, Philosophy, and Science of Sound. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .4
Fields . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .4
Chapter 2 Voices Out of the Past. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .7
Significant Figures in the History of Audio and Acoustics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .9
1893—The Magic Year . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .11
Bell Laboratories and Western Electric . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .11
Harvey Fletcher (1884–1981)  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .12
Harry Nyquist (1889–1976) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .12
The dB, dBm, and the VI . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .12
Sound System Equalization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .13
Acoustic Measurements—Richard C. Heyser (1931–1987) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .13
Calculators and Computers  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .14
The Meaning of Communication . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .14
Historical Notes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .14
Chapter 3 Sound and Our Brain. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .17
The Human Brain  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .19
The Current Era . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .19
Unexpected Validation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .22
Chapter 4 Psychoacoustics. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .23
Motivations  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .25
Sound Reproduction  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .25
Is it Better to be Born Blind or Deaf ? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .26
Recording Sound at the Eardrum . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .27
Psychoacoustics via a Metaphysical Foundation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .27
Barks, Bands, Equivalent Rectangular Bandwidths (ERBs), Phons and Sones  . . . . . . . . . . . . . . . . . . . . .28
Chapter 5 Digital Theory . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .33
Shannon’s Theory  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .35
Dynamic Range . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .36
The Steps from Art to Science . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .40
Moravec’s Warning  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .41
Digital Nomenclature  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .42
What Is a Bit of Data? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .43
Bayesian Theory  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .47
Planck System  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .47
Bits, Nats, and Bans . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .48
A Communication System . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .48
Holography  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .49
Chapter 6 Mathematics for Audio Systems. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .51
Engineering Calculations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .53
Precision, Accuracy, and Resolution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .54
Simple Numbers  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .54
How to Add Gains and Losses Algebraically  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .54
The Factor-Label System . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .55

viii
Contents
Basic Physical Terms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .58
Mathematical Operations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .60
Complex Number Operations  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .64
Decade Calibration  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .65
Converting Linear Scales to Logarithmic Scales . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .66
Finding the Renard Series for Fractional Octave Spacing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .66
Radians and Steradians  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .67
Calculating Percentages and Ratios . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .70
Useful Math Tables  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .72
Angles  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .75
A Little Trigonometry  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .75
The Origin of the Base of the Natural Logarithm, e  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .76
The Complex Plane . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .77
Euler’s Theorem  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .77
Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .78
Phasors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .79
Rates of Change . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .80
Chapter 7 Using the Decibel . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .85
The Decibel  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .87
The Neper  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .87
Concepts Underlying the Decibel and Its Use in Sound Systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .88
Measuring Electrical Power . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .90
Levels in dB . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .91
The Decibel in Acoustics—LP, LW, and LI  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .92
Acoustic Intensity Level (LI), Acoustic Power Level (LW), and Acoustic Pressure Level (LP) . . . . . . . . .93
Inverse Square Law . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .93
Directivity Factor . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .94
Ohm’s Law  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .94
A Decibel Is a Decibel Is a Decibel . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .95
The Equivalent Level (LEQ) in Noise Measurements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .96
Combining Decibels  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .97
Combining Voltage  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .99
Using the Log Charts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .99
Finding the Logarithm of a Number to Any Base . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .100
Semitone Intervals . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .101
System Gain Changes  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .101
The VU and the VI Instrument  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .101
Calculating the Number of Decades in a Frequency Span  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .104
Deflection of the Eardrum at Various Sound Levels . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .105
The Phon  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .105
The Tempered Scale  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .106
Measuring Distortion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .106
The Acoustical Meaning of Harmonic Distortion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .106
Playback Systems in Studios . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .108
Decibels and Percentages  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .109
Summary  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .110
Chapter 8 Interfacing Electrical and Acoustic Systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .111
Alternating Current Circuits  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .113
Impedance  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .115
Electric Power  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .117
Properties of the LCR Circuit  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .120
Filters . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .121
Impedance Bridge  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .126

Contents
ix
Constant Resistance Networks  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .128
Impedance Properties of Moving Coil Loudspeakers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .129
Network Theorems  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .132
The Technician’s Viewpoint  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .135
Impedance Defined  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .135
Handling the Acoustic Input and Output of the System  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .137
Total Electrical Gain of a System  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .142
Interfacing the Electrical Output Power to the Acoustic Environment . . . . . . . . . . . . . . . . . . . . . . . . . . .143
Gain Structure Revisited  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .145
Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .150
Chapter 9 Loudspeaker Directivity and Coverage . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .151
Essential Definitions  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .153
Describing Q More Accurately  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .158
Relationship Between C∠ and Q in an Idealized Case  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .159
Idealized Loudspeaker Geometry  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .160
Class D Audio Amplifiers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .165
Sound as a Weapon  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .166
An Older View of Q . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .166
Summary  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .167
Chapter 10 The Acoustic Environment. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .169
The Acoustic Environment  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .171
Dispersion and Diffusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .171
Inverse Square Law . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .172
Atmospheric Absorption  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .172
Velocity of Sound  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .173
Isothermal vs. Adiabatic  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .173
Temperature-Dependent Velocity  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .174
The Effect of Altitude on the Velocity of Sound in Air . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .175
Typical Wavelengths  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .175
Doppler Effect . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .175
Reflection and Refraction  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .176
Effect of a Space Heater on Flutter Echo  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .177
Absorption . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .177
Definitions in Acoustics  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .178
Classifying Sound Fields . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .178
The Acoustic Environment Indoors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .181
Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .186
Chapter 11 Audio and Acoustic Measurements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .189
Acoustic Analysis Sans Instrumentation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .191
Initial Parameters . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .191
Acoustic Tests of Sound Systems  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .192
Examining AC Outlets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .193
The ETC Plot . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .195
Site Surveys and Noise Criteria Curves  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .203
An Improper Use of Real Time Analysis  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .203
Evaluation of Listener Response . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .205
Fractional Bandwidth Filter Analyzers  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .206
Measuring Electromagnetic Pollution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .209
Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .211
Chapter 12 Large Room Acoustics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .213
What Is a Large Room? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .215
Levels Defined: Sound Power Level (LW), Sound Intensity Level (LI), and Sound Pressure Level (LP)  220

x
Contents
Levels in Enclosed Spaces . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .221
Differentiating Between Reverberant Level and Reverberation Time  . . . . . . . . . . . . . . . . . . . . . . . . . . .224
Evaluation of Signal-to-Noise Ratio, SNR  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .225
Analyzing Reflections and Their Paths . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .226
Critical Distance  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .228
Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .233
Chapter 13 Small Room Acoustics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .235
Non-Statistical Spaces . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .237
Small Room Acoustical Parameters  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .238
Small Room Reverberation Times . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .238
Small Room Resonances . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .239
Modes  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .239
What Is an Eigen Mode?  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .239
Small Room Geometry  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .240
The Initial Signal Delay Gap (ISD) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .240
Reflections . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .242
Reflection Free Zone . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .244
Diffusion  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .245
Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .248
Chapter 14 Designing for Acoustic Gain  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .251
Maximum Physical Distance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .253
Establishing an Acceptable Signal-to-Noise Ratio (SNR) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .253
Establishing an EAD  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .254
Needed Acoustic Gain (NAG) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .254
The Number of Open Microphones . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .255
The Feedback Stability Margin  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .255
Calculating Potential Acoustic Gain  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .256
Obtaining ΔDx Values  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .258
Measuring Acoustic Gain  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .259
Achieving Potential Acoustic Gain . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .259
Limiting Parameters in Sound Reinforcement System Design . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .260
How Much Electrical Power Is Required?  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .260
Finding the Required Electrical Power (REP) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .261
Summary  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .263
Chapter 15 Designing for Speech Intelligibility . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .265
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .267
Articulation Losses of Consonants in Speech . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .268
Maxfield’s Equation  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .270
Speech Power and Articulation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .270
Signal-to-Noise Ratio (SNR) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .271
Speech Intelligibility Calculations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .271
Non-Acoustic Articulation Problems  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .275
Relationship Between QMIN and D2(MAX) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .276
High Density Overhead Distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .276
%ALCONS Variables . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .277
A Little History—Intelligibility Workshop 1986  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .278
Summary  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .279
Chapter 16 What is Waving and Why. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .281
General Properties of Air . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .283
Plane Waves . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .288
Non-Planar Wave Motion in a Tube  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .297
Plane Wave Tubes having Arbitrary Terminations  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .299

Contents
xi
Impedance Tube . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .303
More General Waves . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .305
Acoustic Intensity  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .308
Boundaries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .309
Acoustic Dipole . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .310
Chapter 17 Microphones . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .313
The Microphone as the System Input  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .315
Microphone Sensitivity  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .315
Thermal Noise . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .317
Microphone Selection  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .324
Nature of Response and Directional Characteristics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .325
Boundary Microphones . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .330
Wireless Microphones . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .335
Microphone Connectors, Cables, and Phantom Power . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .339
Measurement Microphones . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .341
Microphone Calibrator  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .342
Chapter 18 Loudspeakers and Loudspeaker Arrays . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .345
Loudspeaker Types  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .347
Radiated Power  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .358
Axial Sound Pressure Level  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .363
Efficiency . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .363
Loudspeaker Electrical Impedance  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .364
Loudspeaker Directivity Factor . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .365
Loudspeaker Sensitivity  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .365
Direct Radiator Example Calculations  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .366
Horns and Compression Drivers  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .368
Practical Considerations Involving Horns . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .374
Horn Compression Drivers  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .376
Crossover Networks  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .378
Loudspeaker Arrays . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .392
Bessel Array  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .398
Line Arrays  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .400
Vented Enclosure Bass Loudspeakers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .412
Large Signal Behavior of Loudspeakers  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .420
Chapter 19 Power Ratings for Amplifiers and Loudspeakers . . . . . . . . . . . . . . . . . . . . . . . . .423
Loudspeaker Power Ratings  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .425
Active Loudspeaker Systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .428
Non-Linear Operation  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .428
The Amplifier as a Voltage Source  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .429
The Equivalent Amplifier Size–EAS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .430
Power from a Voltage Source  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .431
Burst Testing  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .433
Power Rating Possibilities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .434
Putting It All Together . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .435
Multi-way Loudspeakers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .438
System Gain Structure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .439
Combining MIV and EAS  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .439
Chapter 20 Computer-Aided System Design  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .441
Spherical Loudspeaker Data  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .443
Near Field vs. Far Field . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .444
The Measurement Process . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .445
Loudspeaker Arrays . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .447

xii
Contents
Direct Field Modeling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .449
Room Model Detail . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .449
Room Acoustics—An Overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .451
Absorption . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .453
Realistic Room Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .457
Universal Room Modeling Tips  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .460
Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .461
Chapter 21 Signal Delay and Signal Synchronization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .463
Signal Delay  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .465
Useful Signal Delay Equations  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .466
Synchronization and Alignment of Arrays  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .469
Finding Acoustic Origins of Unlike Devices  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .470
Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .472
Chapter 22 Signal Processing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .475
Spectra . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .477
Analog to Digital Conversion  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .497
System Theory . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .502
Digital Systems and the Z Transform  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .520
Dynamics Processing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .528
Chapter 23 Digital Audio Formats and Transports . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .533
The Analog Waveform  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .535
Quantization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .535
Digital Signal Processing—DSP . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .542
Two Data Camps  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .543
How Does Ethernet Work?  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .545
Ethernet Protocols  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .546
An Open Standard  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .549
AES3 vs. AoE  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .549
Hybrid and Proprietary Systems  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .549
Analog vs. Digital Audio . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .550
Chapter 24 Sound System Equalization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .553
System Criteria  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .555
Early Research on Equalization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .555
The Transient Nature of Acoustic Feedback . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .556
Introduction of Real-Time Analyzers  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .559
Band-Rejection, Bandpass, and Band-Boost Filters  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .562
TEF Analysis in Equalization  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .567
How to Approach Equalization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .568
What Can an Equalizer Equalize? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .570
A Real-Time Regenerative-Response Method of Equalizing a Sound System . . . . . . . . . . . . . . . . . . . . .572
Equalizing for Playback . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .573
An Improper Use of Real Time Analysis in Monitoring Music and Speech . . . . . . . . . . . . . . . . . . . . . . .574
Diaphragmatic Absorbers  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .574
Don’t Equalize for Hearing Loss . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .575
Proximity Modes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .575
Checking Microphone Polarity  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .575
Loudspeaker Polarity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .576
Summary  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .576
Chapter 25 Putting It All Together. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .577
Acoustical Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .579
Alternative Solutions for a Given Space . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .579
Device Interconnections  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .582

Analog Interconnection Circuitry Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .583
Signal Cables—Analog Audio, Digital Audio, and Video  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .590
AES3  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .597
Computer Control and Communication of Digital Audio . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .602
Appendix . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .605
Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .609


   Preface
vii
There are two worlds in audio—one of wave equations, Fourier, Hilbert, and Laplace transforms, and the other
of Ohm’s Law, Sabine and Hopkins Stryker. Eugene Patronis, Jr., straddles both like a colossus, as he is able to
theorize in Quantum Mechanics and design, build, and service, with his own hands, all components used in
audio.
Pat Brown is our new co-author and brings to this volume unique tools he has developed in the course of
his loudspeaker testing, particularly directivity measurements, into the twenty-first century. He has taught
Syn-Aud-Con seminars all over the world in person as well as through his internet training programs. He is a
longtime friend of both Dr. Patronis and Don Davis, and like them, a man who delights in fully sharing his
knowledge of sound system engineering with others. We welcome his participation in this volume.
The authors come from two quite different backgrounds: one is academic, the others are industrial and field
oriented. “The lion is known by his claw” was said of Newton, whereas the technician approach uses a broad
brush to get a workable, if not elegant, answer. Therefore, we have identified each author’s contribution sepa-
rately. It’s your privilege to select the approach most applicable to your need. With today’s generation of com-
puter users and the wealth of available software it’s you, the reader, who chooses the boundaries of your
interests and academic skills. It is our wish that whatever background you bring to the subject you will find
new tools for that level and hints of the next.
Sound System Engineering is a widely sold, widely used text on sound system design. The first editions
were oriented toward those planning systems from components available in the existing marketplace, i.e., they
were treated as boxes on a diagram. The first editions ignored component design and analysis other than their
interconnecting parameters.
When Don and Carolyn Davis, the authors of the first two editions, sought specific advice on component
design and in-depth analysis of given components they turned to their long time friend and mentor, Eugene
Patronis, Jr. to provide the in-depth analysis he excels in. You will find in this edition both approaches, allow-
ing newcomers to operate efficiently while providing the more experienced an opportunity to achieve a more
advanced viewpoint. We know that one can start reading on one level, but as our experience and expertise
develops, we are grateful for the more advanced approach. What we read as our learning process starts is much
different years later and we become very grateful for the more advanced material.
Those who have benefited from a rigorous and thorough academic background will find that Eugene
Patronis’ work is a succinct summary of all you should have absorbed intellectually whereas the less sophisti-
cated approach may contain useful nuggets that have surmounted “gray” areas in system compromises. This
dual approach provides some seemingly uneven interconnects but benefits from the diverse experience of the
authors.
The authors have retained their own mental images of who they are writing for, often a combination of both
approaches. We hope that you will find this volume useful in pursuit of our mutual goal of truly engineered
rather than merely assembled sound systems.
Thanks to Glen Ballou
Our special thanks to Glen Ballou, who transcribed our material into a publishable format. These simple words
can’t begin to describe the agony he has endured.
Pat Brown,
Don Davis,
Eugene Patronis, Jr.


Chapter 1
Why Sound System Engineering?
by Don Davis
1
1.1 Prerequisites . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3
1.2 Basic Electrical Training  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3
1.3 Mathematics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3
1.4 Hearing Versus Listening . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3
1.5 Craftsmanship  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4
1.6 Rigging . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4
1.7 Literacy  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4
1.8 The Art, Philosophy, and Science of Sound.  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4
1.9 Fields  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4


   
Why Sound System Engineering?
3
“Sound” has over the centuries been associated with
human hearing (i.e.: “Is there a sound if a tree falls
in the forest without a listener present?”) According
to Webster, “The sensation perceived by the sense of
hearing.” Also from Webster: “Audio, on the other
hand, has largely been associated with electrical
communication circuits.”
“System” is a word we use to describe any
“experience cluster” that we can map as a set of
interacting elements over time. Typically a system is
mapped by identifying the pathways of information
flow, as well as possibly the flow of energy, matter,
and other variables. But the flow of information is
special; because only information can go from A to
B while also staying at A. (Consider: photocopy
machines would be useless if one didn’t get to keep
the original). Digital systems, analog systems,
acoustic systems, etc. should be regarded by a
system engineer as so many “black boxes” that need
to be matched, interconnected, and adjusted. The
internal circuitry should be the interest of the
component designer/manufacturer.
1.1 Prerequisites
What kind of background should an aspiring sound
system engineer possess is an often asked question.
A list of desirable experiences would include:
1.
Some basic electrical training.
2.
An interest in mathematics.
3.
A good ear (a love of quality sound and acute
aural senses).
4.
Skill with basic tools.
5.
Some appreciation of the perils of rigging.
6.
Good reading and writing skills.
7.
A genuine appreciation for the art, philosophy,
and science of sound.
1.2 Basic Electrical Training
Time spent as an apprentice electrician is not
wasted. In many cases, large sound systems deal
with separate power systems, and safety springs
from knowledge of the power circuits that are
involved. Conduits, cable sizes, and types of
grounding and shielding can be complex even at
power frequencies. Knowledge of the electrical
codes is a necessary fundamental tool.
1.3 Mathematics
From Ohm’s law to the bidding process, an ability
to quickly learn new algorithms both speeds up
processes and ensure profits. In today’s markets “cut
and try” is too expensive of both time and money to
allow avoidance of basic computer skills; the use of
programs such as Mathcad for both technical and
financial calculations is important. Knowing what
the formulae actually used are doing is essential. In
order to trust any computer program, having done it
first on paper the hard way, provides knowledge and
confidence in the fast way and leaves you capable of
detecting unexpected anomalies that might occur.
Yes! You do need more than arithmetic.
1.4 Hearing Versus Listening
We all hear. But what we listen to depends to a large
degree on our previous listening experiences. I have
often stood in the center of an acoustic anomaly
such as a reflection from an undesirable angle,
distance, and level, that was destroying speech intel-
ligibility, and watched the startled expression on the
face of a person sitting in the pew as a piece of
acoustical material is passed between his ears and
the reflection, which restored intelligibility.
Once experienced, your eyes, ears, and brain, can
recognize such problems by simply walking through
them. Sensitive listening is a great plus in sound
system work, and it is a sufficient reason to hear as
many venues as possible under normal usage condi-
tions. I am always surprised when I see engineers
trying to design a church sound system from a set of
drawings without ever having attended a service to
see what their actual needs are versus what they’d
like to provide them.
Because all sound system design starts in the
acoustic environment and works back from there to
the input, failure to experience the normal use of the
space can be fatal to the ultimate end result. On one
occasion I was listening in a mammoth cathedral
from a position behind the altar, when asked by the
administrator, if our design could solve their intelli-
gibility problem. The priest about to conduct the
service spoke to me, and because of a combination
of a speech defect and in a foreign accent, I was
unable to understand him to sufficiently compre-
hend his message. I had to tell the administrator that
our system could only raise the priest’s audio level,
not his intelligibility.
Watching successful ministers, politicians, and
other public figures use microphones reveals a
world of problems unaddressed by the most compe-

4
Chapter 1
tent engineer. In one case the engineer was asked if
he could “put more soul in the monitor.”
1.5 Craftsmanship
Possession of a guitar does not make one a musician
nor do tools make a craftsman. Skill with basic tools
manifests itself in clean solder joints, orderly
cabling, careful labeling on panels and terminals.
Construction of successful loudspeaker arrays is a
challenge to both artistry and craftsmanship. In my
experience craftsmanship is a direct expression of
character.
1.6 Rigging
Rigging, in itself, is a business as complex and diffi-
cult as engineering the sound system and often
behooves sound contractors to seek out professional
assistance when required to hang large, heavy, and
expensive loudspeaker arrays.
I was involved in a consulting job for a major
public arena venue where the owner intended to
hang the new array from the previous array’s
rigging. (A complicated system of cables and drums
for raising and lowering the arrays). I insisted on
their hiring a notable rigging authority who went up
into the rigging with a camera and came down with
a dozen photographs of impending disasters, such as
grooves worn in the drums by the cables, frayed
cables, unsafe connectors, and a lack of safety
cables, to cite but a few of the problems. There are
recorded fatalities from falling arrays. It is not a
business for amateurs.
1.7 Literacy
This would seem obvious, but is often a weak link in
an otherwise successful background experience.
Sales presentations, bid offers, instruction manuals
for the operators of your systems, all require reading
and writing skills. Communications with customers,
suppliers, and consultants needs to be thoughtfully
and concisely written. For example, the contractor
should be on record telling the customer that the
design will function properly only if the HVAC
contractor meets the specified noise criteria that is
provided in the Specification. Failure to do so can be
disastrous. A memo on file with the owner can save
the sound contractor and/or consultant from having
to take the blame.
1.8 The Art, Philosophy, and Science of Sound
The design of well-engineered sound systems stands
on the shoulders of the giants who created the
communication industry. “Art precedes science” is
an axiom that is eternally true. Prof. Higgins as
portrayed in the film, “My Fair Lady,” exemplified
the majesty of language, the science of studying its
proper sounds, and meanings, and the engineering
systems used in that earlier day. Even today the most
difficult sound systems to design, build, and operate
are those used in the reinforcement of live speech.
Systems that are notoriously poor at speech rein-
forcement often pass reinforcing music with flying
colors. Mega churches find that the music reproduc-
tion and reinforcement systems are often best sepa-
rated into two systems
1.9 Fields
From my first view of the rainbow depiction of the
electromagnetic spectrum from dc to gamma ray I
have striven to gain a conceptual mental view of
various fields, Fig. 1-1. Physical science, during the
past century, has come to the conclusion that the
Universe is some sort of field. The nature of this
universal field remains controversial—is it matter
which has mass? Or something more ethereal such
as information?
Michael Faraday, 1831, said “Perhaps some
force is emanating from the wire.”
 A Cambridge man said “Faraday, let me assure
you, at Cambridge our electricity flows through the
wire.”
Oliver Heaviside, 1882, from his book, Electrical
Papers, Vol. 1:
Had we not better give up the idea
that energy is transmitted through the
wire altogether? That is the plain
course. The energy from the battery
neither goes through the wire one way
nor the other. Nor is it standing still, the
transmission takes place entirely
through the dielectric. What, then, is the
wire? It is the sink into which the energy
is poured from the dielectric and there
wasted, passing from the electrical
system altogether.
John Ambrose Fleming in 1898 wrote:
It is important that the student should
bear in mind that, although we are
accustomed to speak of current as
flowing through the wire in one direc-
tion or the other, this is a mere form of

   
Why Sound System Engineering?
5
words. What we call the current in the
wire is, to a large extent, a process
going on in the space or material
outside the wire….
Ernst Guillmin, Communications Networks, Vol.
II, 1935
Heaviside is the only one who
considers the nature of the sources as
well as the boundary effects both for the
initial buildup or transient behavior and
for the steady-state condition. He is the
first also, to consider the leakage
through the insulation, in view of which
the true significance of the inductance
parameter may be appreciated…. His
work is a first approximation only as
compared with other, more rigorous
treatments. For the engineer, however,
this first approximation is usually suffi-
cient….
Further,
The concept of guided waves, before
Maxwell, the physical picture of the
propagation of electricity through a
long circuit was more or less that which
is frequently presented in elementary
textbooks, where the hydraulic analogy
to an electric circuit is given for
purposes of visualization. That is, the
seat of the phenomenon was taken to be
within the conductor. What occurred
outside the conductor could be neither
definitely formulated nor described. The
electrical energy was thought of as
being transmitted through the conductor
which, therefore, became of prime
importance. In fact, if we accept this
point of view altogether, it becomes
impossible to conceive of a flow of elec-
trical energy from one point to another
without the aid of an intervening
conductor of some sort. It has been the
writer’s experience that many students
are quite wedded to this point of view, so
much so, in fact, that to them the propa-
gation of energy without wires (wireless
transmission) becomes a thing alto-
gether apart from other forms of trans-
mission involving an intervening
conducting medium.
An appreciation of Maxwell’s theory of electro-
magnetic wave propagation brings the so-called
wireless and wired forms of transmission under the
same roof, so to speak. They merely appear as
special cases of the same fundamental phenom-
enon…. The presence of a conductor merely causes
the field be broken up into various components,
some of which are assigned to the conductor itself,
others to the surrounding medium, and still others to
the surface separating the two media.
From the Standard Handbook for Electrical
Engineers by Donald G. Fink and H. Wayne
Beaty…. There is a section entitled, “Electromag-
netic Wave Propagation Phenomenon.”
The usually accepted view that the conductor
current produces a magnetic field surrounding it
must be displaced by the more appropriate one that
the electromagnetic field surrounding the conductor
produces, through a small drain on the energy
supply, the current in the conductor. Although the
value of the latter may be used in computing trans-
mitted energy, one should clearly recognize that
physically this current produces only a loss and in
no way has a direct part in the phenomenon of
power transmission.
Ralph Morrison’s website has some comments
on electromagnetic laws.
The laws I want to talk about are the basic laws
of electricity. I’m not referring to circuit theory laws
as described by Kirchhoff or Ohm but the laws
governing the electric and magnetic fields. These
fields are fundamental to all electrical activity
whether the phenomenon is lightning, electrostatic
display, radar, antennas, sunlight, and power gener-
ation, analog or digital circuitry. These laws are
often called Maxwell’s equations. Light energy can
be directed by lenses, radar energy can be directed
by waveguides and the energy and power frequen-
cies can be directed by copper conductors. Thus we
direct energy flow at different frequencies by using
different materials. For utility power the energy
travels in the space between conductors not in the
conductors. In digital circuits the signals and energy
travel in the spaces between traces or between the
traces and the conducting surfaces. Buildings have
halls and walls. People move in the halls not the
walls. Circuits have traces and spaces, signals and
energy moves in the spaces not in the traces.
Scanning the Electromagnetic Spectrum Chart
from dc through radio waves, light itself, out to
gamma rays we can see that electromagnetic fields
play a key part in our lives, Fig. 1-1.
Researchers studying human consciousness are
finding electromagnetic phenomenon in addition to
the previously known electrical phenomena. When
EMI (electromagnetic interference) occurs in audio
systems RF spectrum analyzers can be useful tools.

6
Chapter 1
Figure 1-1. Electromagnetic spectrum chart.

Chapter 2
Voices Out of the Past
by Don Davis
7
2.1 Significant Figures in the History of Audio and Acoustics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 9
2.2 1893—The Magic Year  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11
2.3 Bell laboratories and Western Electric . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11
2.4 Harvey Fletcher (1884–1981)  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12
2.5 Harry Nyquist (1889–1976) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12
2.6 The dB, dBm, and the VI . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12
2.7 Sound System Equalization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13
2.8 Acoustic Measurements—Richard C. Heyser (1931–1987)  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13
2.9 Calculators and Computers  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14
2.10 The Meaning of Communication . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14
2.11 Historical Notes  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14


   
Voices Out of the Past
9
During the fall of 1978, we stopped in Williams-
burg, Virginia. As is our habit, we explored the
old-bookstores and asked whether they had any
books on acoustics. We were told they had just one,
an old one. They brought out a vellum bound first
edition dated 1657, Magiae Universalis by Gaspare
P. Schotto (1608–1666).
He was a colleague of Athanasius Kircher
(1602–1680) whose work was discussed in Fred-
erick Vinton Hunt’s valuable book Origins in
Acoustics. The book, written in Latin, was published
at Herbipoli, the modern Wurzburg, Germany. Some
of the plates from it are shown in Figs. 2-1 through
2-6.
In researching the history of this book we found
that it was mentioned in the Edinburgh magazine
(volume 12, page 322) in 1790, as well as in Hunt’s,
Origins in Acoustics, regarding Boyle and Hooke’s
work. Magiae Universalis was used by Robert
Boyle (1627–1691) and his assistant Robert Hooke
(1635–1703) as they worked to improve air pumps
and experiment with ticking watches in vacuums.
This book described Otto Von Guericke’s work
with air pumps.
An erudite discussion of Athanasius Kircher’s
book, Phonurgia Nova by Lamberto Tronchin in
January 2009 edition of Acoustics Today, provides
one of the best surveys of the period under discus-
sion. Richard C. Heyser put it best when he said,
“You don’t really own that book, you are its tempo-
rary custodian.”
These men were Galileo’s contemporaries and
were representative of the desire for scientific
knowledge, as well as the collectors of all the myths
of their age.
2.1 Significant Figures in the History of Audio 
and Acoustics*
Often, in the modern scheme of things, history is not
mandatory in engineering classes taught at the
university level. Significant historical figures are
encountered as Faraday’s ice-pail experiment,
Maxwell’s equations, Ohms’ law etc., but not
studied in depth.
Electrical engineers encounter the SI terms, poten-
tial difference in volts (Alessandro Volta), current in
amperes (Andre Marie Ampere), capacitance in
farads (Michael Faraday), and thermodynamic
temperature in Kelvin (Lord Kelvin), as units of
measurement. These were living breathing men who
had occasion to interact with each other and inter-
mingle their ideas to the benefit of science. Great
seminal ideas belong to the individual, but the inter-
Figure 2-1. Frontpiece of a book published in 1857 at
Herbipoli, the modern Wurzburg, Germany.
Figure 2-2. Water-powered musical instrument that
fascinated our forefathers as much as computers
interest us today. From Magiae Universalis.
*.
Significant Figures in the History of Audio
and Acoustics is an edited version of the
chapter, “Audio & Acoustic DNA—Do you
Know Your Audio and Acoustic Ancestors?” in
the 4th Edition of the Handbook for Sound Engi-
neers, edited by Glen Ballou.

10
Chapter 2
mingling of them leads industries. Their predeces-
sors and contemporaries such as Joule (work, energy,
heat), Charles Coulomb (electric charge), Isaac
Newton (force), Hertz (frequency), Watt (power,
radiant flux), Weber (magnetic flux), Tesla (magnetic
flux density), Henry (inductance), and Siemens
Figure 2-3. The first bugging system. Horns such as
these were used by Athanasius Kircher, a contempo-
rary of Kasper Schott, to speak to the gatekeeper from
his quarters and to eavesdrop on the conversation
taking place in the courtyard. His experimental horn
was 22 palms long. (A palm is about 8.7 inches, so his
horn was about 16 feet long). From Magiae Universalis.
Figure 2-4. The basic rules for sound reflection as a
geometric problem. From Magiae Universalis.
Figure 2-5. How oracles talk or music can be trans-
mitted from one space to another. From Magiae Univer-
salis.
Figure 2-6. Illustrations of reflections, focusing, diffu-
sion, time delay, and creeping. From Magiae Univer-
salis.

   
Voices Out of the Past
11
(conductance), are immortalized as international SI
derived units. Kelvin and Ampere alone have names
inscribed as SI base units. Kirchhoff diagrams define
the use of these units in circuit theory.
What the study of these men’s lives provides, to
the genuinely interested reader, is the often unique
way the great ideas came to these men, the persistent
pursuit of the first glimmer, and the serendipity that
comes from sharing ideas with other talented minds.
As all of this worked its way into the organized
thinking of mankind, one of the most important
innovations was the development of technical soci-
eties formed around the time of Newton, where
ideas could be heard by a large receptive audience.
Some of the world’s best mathematicians strug-
gled to quantify sound in air, in enclosures and in all
manner of confining pathways. Since the time of
Euler (1707–1783), Lagrange (1736–1813), and
d’Alembert (1717–1783), mathematical tools existed
to analyze wave motion and develop field theory.
By the birth of the twentieth century, workers in
the telephone industry comprised the most talented
mathematicians and experimenters in both what was
to become electronics and in acoustics. At MIT, the
replacement of Oliver Heaviside’s operational
calculus by Laplace transforms gave them an envi-
able technical lead in education.
2.2 1893—The Magic Year
At the April 18, 1893 meeting of the American Insti-
tute of Electrical Engineers in New York City,
Arthur Edwin Kennelly (1861–1939) gave a paper
entitled “Impedance.”
That same year General Electric, at the insistence
of Edwin W. Rice, purchased Rudolph Eicke-
meyer’s company for his transformer patents. The
genius, Charles Proteus Steinmetz (1865–1923),
worked for Eickemeyer. In the saga of great ideas, I
have always been as intrigued by the managers of
great men, as much as the great men themselves. E.
W. Rice of General Electric personified true leader-
ship when he looked past the misshaped dwarf that
was Steinmetz, to the mind present in the man.
General Electric’s engineering preeminence, in
those years, proceeded directly from Rice’s extraor-
dinary hiring of Steinmetz.
Dr. Michael I. Pupin of Columbia University was
present at the Kennelly paper. Pupin mentioned
Oliver Heaviside’s use of the word impedance in
1887. This meeting established the correct definition
of the word and established its use within the elec-
tric industry. Kennelly’s paper, along with the
groundwork laid by Oliver Heaviside in 1887, was
instrumental in introducing the terms being estab-
lished in the minds of Kennelly’s peers.
The truly extraordinary Arthur Edwin Kennelly,
(1861–1939) left school at the age of thirteen and
taught himself physics while working as a telegra-
pher. He is said to “have planned and used his time
with great efficiency,” which is evidenced by his
becoming a member of the faculty of Harvard in
1902 while also holding a joint appointment at MIT
from 1913–1924. He was the author of ten books
and the co-author of eighteen more, as well as
writing more than 350 technical papers. Edison had
employed A. E. Kennelly to provide physics and
mathematics to Edison’s intuition and “cut and try”
experimentation. The reflecting ionosphere theory is
jointly credited to Kennelly and Heaviside, and
known as the Kennelly-Heaviside layer. One of
Kennelly’s PhD students was Vannevar Bush, who
ran America’s WWII scientific endeavors.
Steinmetz was not at the April 18, 1893 meeting,
but sent in a letter-of-comment which included:
It is however, the first instance here,
so far as I know, that the attention is
drawn by Mr. Kennelly to the corre-
spondence between the electrical term
‘impedance’ and the complex numbers.
The importance hereof lies in the
following: the analysis of the complex
plane is very well worked out, hence by
reducing the technical problems to the
analysis of complex quantities they are
brought within the scope of a known and
well understood science.
Nikola Tesla (1856–1943) working with West-
inghouse designed the ac generator that was chosen
in 1893 to power the Chicago World’s Fair.
2.3 Bell laboratories and Western Electric
The University of Chicago, at the end of the Nine-
teenth Century and the beginning of the Twentieth
Century, had Robert Millikan, America’s foremost
physicist. Frank Jewett, who had a doctorate in
physics from MIT, and now worked for Western
Electric, was able to recruit Millikan’s top students.
George A. Campbell (1870–1954) had by 1899 devel-
oped successful “loading coils” capable of extending
the range and quality of the, at that time, unamplified
telephone circuits. Unfortunately, Prof. Michael
Pupin had also conceived the idea and beat him to the
patent office. Bell telephone paid Pupin $435,000 for
the patent and by 1925, the Campbell designed
loading coils had saved Bell Telephone Company
$100,000,000 in the cost of copper wire alone.

12
Chapter 2
To sense the ability of loading coils to extend the
range of unamplified telephone circuits, Bell had
reached New York to Denver by their means alone.
Until Thomas B. Doolittle evolved a method in 1877
for the manufacture of hard drawn copper, the metal
had been unusable for telephony due to its inability
to support its own weight over usable distances.
Copper wire went from a tensile strength of 28,000
pounds per square inch with an elongation of 37%,
to a tensile strength of 65,000 pounds per square
inch and a elongation of 1%.
H. D. Arnold, with the advent of usable copper
wire, the vacuum tube amplifier, 130,000 telephone
poles, and 25 tons of copper wire was able to estab-
lish transcontinental telephony in the year 1915.
There was also a public address system at those
ceremonies celebrating this accomplishment.
2.4 Harvey Fletcher (1884–1981)
In 1933, Harvey Fletcher, Steinberg and Snow,
Wente and Thuras and a host of other Bell Labs
engineers gave birth to “Audio Perspective” demon-
strations of three channel stereophonic sound
capable of exceeding the dynamic range of the live
orchestra. Their exhaustive study led to the conclu-
sion that to reproduce the sound field would require
an infinite number of sources and that the best
compromise lay in three channels. They also
demonstrated that two channels were sufficient over
headphones for binaural recordings. They under-
stood that for stereophonic reproduction each of the
three channels had to cover all of the audience, a
fact many contemporaries are unaware of. Early in
my career at Altec, I had the privilege of working
with William Snow and having full discussions of
their 1933 system.
Edward C. Wente and Albert L.Thuras were
responsible for the full range, low distortion,
high-powered sound reproduction using condenser
microphones, compression drivers, multicellular
exponential horns, and horn loaded low-frequency
enclosures, all of which were their original designs.
The Fletcher loudspeaker, as designed by Wente and
Thuras, was a three-way unit consisting of an 18
inch low-frequency driver horn loaded woofer, the
incomparable W. E. 555 as a mid range, and the
W. E. 597A high-frequency unit.
The power amplifiers and transmission lines
were capable of full dynamic range from 30 Hz to
15,000 Hz, capabilities often claimed today but
seldom realized.
In 1959, Carolyn and I repeated the original
geometry tests of the 1933 experiments while
working for Klipsch and Associates. Mr Klipsch and
I then traveled to Bell Telephone Laboratories in
New Jersey, where we made a demonstration of our
results using Klipsch horns in the Arnold Audito-
rium. After our demonstration we were shown one
of the original Fletcher loudspeakers.
A perspective can be gained, compared to
today’s products, when it is realized that Western
Electric components like the 555 and the 597 are to
be found today in Japan, where originals sell for up
to five figures. It is estimated that 99% of the
existing units are in Japan. It is of interest to note
that many of today’s seekers of quality sound repro-
duction are still building tube-type amplifiers
employing the W. E. 300 B vacuum tubes.
2.5 Harry Nyquist (1889–1976)
The word inspired means “to have been touched by
the hand of God.” Harry Nyquist’s thirty-seven
years and 138 US patents while at Bell Telephone
Laboratories personifies “inspired.” In acoustics the
Nyquist plot is, by far, my favorite for a first look at
an environment driven by unknown source. Nyquist
also worked out the mathematics that allowed
amplifier stability to be calculated leaving us the
Nyquist plot which is one of the most useful audio
and acoustic analysis tools ever developed. His
cohort, Hendrik Bodie, gave us the frequency and
phase plots as separate measurements.
Karl Kupfmuller (1897–1977) was a German
engineer who paralleled Nyquist work, indepen-
dently deriving fundamental results in information
transmission, in closed loop modeling, including a
stability criterion. Kupfmuller as early as 1928 used
block diagrams to represent closed loop linear
circuits. He is believed to be the first to do so.
Today’s computers, as well as digital audio
devices, were first envisioned in the mid-1800s by
Charles Babbage.  The mathematics discussed by
Lady Lovelace, the only legitimate daughter of Lord
Byron, even predicted the use of a computer to
generate musical tones.
Claude Shannon went from Nyquist’s paper on
the mathematical limit of communication to develop
“Information Theory,” which is so important to
today’s communication channels.
2.6 The dB, dBm, and the VI
The development of the dB from the mile of stan-
dard cable by Bell Labs, their development and
sharing of the decibel, the dBm, and the VU via the

   
Voices Out of the Past
13
design of VI devices, changed system design into an
engineering design.
The first motion pictures were silent. Fortunes
were made by actors who could convey visual
emotion. When motion pictures acquired sound in
1928, again via Western Electric’s efforts, a large
number of these well-known personalities failed to
make the transition from silent to sound. The faces
and figures failed to match the voices the minds of
the silent movie viewers had assigned them. Later,
when radio became television almost all the radio
talent was able to make the transition because the
familiar voices predominated over any mental visual
image the radio listener had assigned to that
performer. Often, at the opera, the great voices will
not look the part, but just a few notes nullify any
negative visual impression for the true lover of
opera, whereas appearance will not compensate for
a really bad voice.
In 1928, a group of Western Electric engineers
became the Electrical Research Products, Inc.
(ERPI), in order to service the motion picture
theaters using Western Electric sound equipment. At
the termination of World War II, the standard for the
best bass reproduction was the loudspeakers
installed in the better motion picture theaters. The
goal of the designers of consumer component audio
reproduction was to approach the motion picture
theater quality. Western Electric had decimated their
competition, RCA, in the theater business, so RCA
went to court and obtained a consent decree which
restricted Western Electric in the field of motion
picture sound. At this point some of the engineers
involved formed All Technical Services (Altec),
which is why it is pronounced all tech, not al-tect.
One of the pioneer engineers told me, “Those days
were the equivalent of one ohm across Fort Knox.”
They bought the Western Electric theater inventory
for pennies on the dollar.They also bought the
Lansing Manufacturing Company and Peerless
Manufacturing which brought James B. Lansing,
Ercel Harrison and Bill Martin (Jim Lansing’s
brother) into Altec.
2.7 Sound System Equalization
Dr. Wayne Rudmose was the earliest researcher to
perform meaningful sound system equalization.
Dr. Rudmose published a truly remarkable paper in
Noise Control (a supplementary Journal of the
Acoustical Society of America) in July 1958. At the
AES session in the fall of 1967, I gave the first
paper on the one-third of an octave contiguous
equalizer, which Altec named Acousta-Voicing.
Dr. Rudmose was chairman of that AES session.
The control these equalizers allowed over acoustic
feedback in live sound systems quickly led to much
more powerful sound reinforcement systems.
I introduced variable system equalization in
special sessions at the screening facilities in August
1969 to the head sound men, Fred Wilson at MGM,
Herb Taylor at Disney, and Al Green at Warner Bros.
Seven Arts. These demonstrations were prior to my
leaving Altec to start Synergetic Audio Concepts and
others reaped the benefits of this work.
Some early workers in equalization imagined
they were equalizing the room; equalization is elec-
trical, not acoustical, and what it always adjusts is
the input to the loudspeaker terminals. It allowed
feedback in a reinforcement system, containing a
highly efficient, but uneven amplitude response
loudspeaker, to be controlled, while increasing the
acoustic energy in the room.
2.8 Acoustic Measurements—Richard C. 
Heyser (1931–1987)
Plato said, “God ever geometrizes.” Richard Heyser,
the geometer, should feel at ease with God. To those
whose minds respond to the visual, Heyser’s
measurements shed a bright light on difficult mathe-
matical concepts. Working from Dennis Gabor’s
(1900–1979) analytic signal theory, the Heyser spiral
displays the concept of the complex plane in a single
visual flash. Heyser was a scientist in the purest
sense of the word, employed by NASA, and audio
was his hobby. When I first met Richard C Heyser in
the mid-1960s, Richard worked for Jet Propulsion
Laboratory as a senior scientist. He invited me to his
home to see his personal laboratory. The first thing
he showed me on his Time Delay Spectrometry
(TDS) equipment was the Nyquist plot of a crossover
network he was examining.
I gave the display a quick look and said, “That
looks like a Nyquist plot!”
He replied, “It is.”
“But,” I said, “no one makes a Nyquist analyzer.”
“That’s right,” he replied.
At this point I entered the modern age of audio
analysis. It was a revelation to watch Dick tuning in
the signal delay between his microphone and the
loudspeaker he was testing until the correct band-
pass filter Nyquist display appeared on the screen.
Seeing the epicycles caused by resonances in the
loudspeaker, and the passage of non-minimum
phase responses back through all quadrants, opened
up a million questions.
Heyser’s work led to loudspeakers with vastly
improved spatial response, something totally unrec-
ognized in the amplitude-only days. Arrays became

14
Chapter 2
predictable and coherent. Signal alignment entered
the thought of system designers. Heyser’s Envelope
Time Curve (ETC) technology resulted in the
chance to meaningfully study loudspeaker–room
interactions.
Because the most widely taught mathematical
tools proceed from impulse responses, Heyser’s
transform is perceived “through a glass darkly.” It is
left in the hands of practitioners to further research
into the transient behavior of loudspeakers. The
decades-long lag of academia will eventually apply
the lessons of the Heyser transform to transducer
signal delay and signal delay interactions.
I hold Harry Olson of RCA in high regard
because, as the editor of the Journal of the Audio
Engineering Society in 1969, he found Richard C.
Heyser’s original paper in the wastebasket; it had
been rejected by means of that society’s inadequate,
at that time, peer review system.
2.9 Calculators and Computers
Richard C. Heyser gave us the instrumentation and
Tom Osborne of Hewlett-Packard gave us the mathe-
matical tools to begin to understand what we were
actually doing in both electronics and acoustics as
applied to sound reinforcement systems. Back in the
1960s, we utilized test equipment from
Hewlett-Packard, General Radio,Tektronics, and
Bruel and Kjaer. I purchased one of the very first
Hewlett-Packard 9100 computer calculators
designed by Tom Osborne. The 9100’s transcen-
dental functions, memory, and print out facilities led
to lengthy acoustic design algorithms. Many of these
same algorithms are still used in today’s computers.
When the HP 35 handheld calculator, so named
for its thirty-five keys, appeared we immediately put
it to use in our teaching. The proliferation of
easy-to-use, accurate software such as Mathcad,
Matlab, and Mathematica in today’s computers
encourages engineers to explore more precise
avenues of design. It was of interest to me that a
correspondent, to the best Listserv in the business,
stated to his peers that he had entered the audio
industry via digital equipment and its operation, and
was at a loss to understand analog audio.
I first explored the magic of communication via a
crystal radio, then the vacuum tube technology,
followed by transistors, integrated circuits, and now
fully digital equipment electronically; it is
comforting to turn to the acoustic side of sound rein-
forcement as an old familiar friend. When, as I
expect in the not too distant future, the reinforce-
ment system reaches the human brain sans passage
via air the cycle will be complete.
2.10 The Meaning of Communication
The future of audio and acoustics stands on the
Shoulders of the Giants that we have discussed, and
numerous ones that we have inadvertently over-
looked. The discoverers of new and better ways to
generate, distribute, and control sound will be
measured consciously or unconsciously by their
predecessor’s standards. Fad and fundamentals will
be judged eventually, and put into their proper place.
Age councils that “the ancients are stealing our
inventions.” Understanding an old idea that is new
to you can be as thrilling as it was to the first person
to make the discovery.
The history of audio and acoustics is the saga of
the mathematical understanding of fundamental
physical laws. Hearing and seeing are illusionary,
restricted by the inadequacy of our physical senses.
That the human brain processes music and art in
a different hemisphere from speech and mathe-
matics suggests the difference between information,
that can be mathematically defined, and communi-
cation that cannot. A message is the flawless trans-
mission of the text. Drama, music, and great oratory
cannot be flawlessly transmitted by known physical
systems. For example, the spatial integrity of a great
orchestra in a remarkable acoustic space is today,
even with our astounding technological strides, only
realizable by attending the live performance. The
complexity of the auditory senses defies efforts to
record or transmit it faithfully.
The devilish power that telecommunications has
provided demagogues is frightening, but shared
communication has revealed to a much larger audi-
ence the prosperity of certain ideas over others, and
one can hope that the metaphysics behind progress
will penetrate a majority of the minds out there.
That the audio industry’s history has barely
begun is evidenced every time one attends a live
performance. We will, one day, look back on the
neglect of the metaphysical element, perhaps after
we have uncovered the parameters, at present easily
heard but unmeasurable, by our present sciences.
History awaits the ability to generate the sound field
rather than a sound field. When a computer is finally
offered to us that are capable of such generation, the
question it must answer is, “how does it feel?”
2.11 Historical Notes
When I first ventured into audio in 1951 with
nothing more than a background in amateur radio
(Ham) and some exposure to engineering in general,
at the university level, it was interest in classical
music and its reproduction that led the way.

   
Voices Out of the Past
15
Fortunately, the postwar revolution in audio was at
its height and our operation of a small but eclectic
“hi-fi” shop, The Golden Ear, led to personally
meeting many of the pioneers of that movement.
Paul Klipsch, Rudy Bozak, Avery Fisher, Frank
McIntosh, Herman Hosmer Scott, Saul Marantz and
others, literally came to our little shop to help us sell
the products they had designed and manufactured.
Purdue University faculty and students were among
our customers; listening to the conversations
between these customers and the manufacturers
participating soon made us aware of the names and
fame of the communication industry’s giants, as
well as the early acoustic giants such as Rayleigh,
Sabine, and Helmholtz.
In 1951, there was no such thing as the Internet
and the only way to get to know these giants was to
haunt old bookstores and gradually collect their
written works. Our book collecting continued and
gradually grew to over 750 volumes on audio and
acoustics.
In late 1958, I joined Klipsch & Associates as
vice president which gave me the chance to travel
nationally and internationally, including sound
demonstrations at the Brussels World’s Fair, and at
the American National Exhibition in Moscow,
where we spent two-and-half months during the
summer of 1959.
In late 1959, I joined Altec Lansing where I was
privileged to work with three unique innovators in
audio technology: John Hilliard, Art Davis, Jim
Noble, and a host of employees that had originally
been part of ERPI, the motion picture service divi-
sion of Western Electric. These were men who had
known Wente and Thuras, Harvey Fletcher, Black,
Bode, Nyquist, and Jim Lansing prior to his tragic
early death. I was a vice president of Altec when I
left in December 1972 to start Synergetic Audio
Concepts (Syn Aud Con).
The next twenty-three years were spent teaching
classes in the basics of audio and acoustics,
consulting and writing texts including Sound System
Engineering, Acoustic Tests and Measurements and
How to Build Loudspeaker Enclosures, plus many
papers for the Journal of the Audio Engineering
Society, Audio Magazine, and other popular publica-
tions, in addition to hundreds of articles in the
Syn-Aud-Con Newsletters.
I have been led to these reminiscences because of
the usefulness of knowing how we got here, as the
only sure guide to where we might be going. There-
fore, I hope you will not ignore our attempts to share
these underlying concepts with you to encourage
you to become a professional in the communication
industry. Many of the best of tomorrow’s innova-
tions will be found by studying the best of the old,
combined with the new materials and techniques of
the present. “The ancients are still stealing our
inventions” is all too true and many papers written
at the turn of the Twentieth Century have ideas not
able to be implemented when the article was written,
but are now possible.


Chapter 3
Sound and Our Brain
by Don Davis
17
3.1 The Human Brain . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19
3.2 The Current Era  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 19
3.3 Unexpected Validation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22
Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22


Sound and Our Brain
19
3.1 The Human Brain
Over the course of my lifetime my audio experi-
ences ran from using a tickler on a crystal in order to
hear audio from a local radio station, to the vacuum
tube era, transistors, integrated circuits, to today’s
digital wizardry. Back in the early 1970s, it was
clear that digital circuitry would prevail. It took
forty years for that insight to come to full fruition. I
truly believe that now mental control of such
systems will come to full fruition in the next 10
years. There are already in existence neuron chips,
axon chips and synapse chips from the scientists at
IBM working to understand the brain.
In this chapter it is pointed out the interweaving
of some of the most useful audio engineering tools
such as the Fourier transform, Gabor wavelets, and
quantum research to the holographic behavior of
human consciousness. For those of you young
enough and well-educated enough to want to pursue
this insight, this chapter provides guidance for the
scientist, the engineer, and the technician. It leaves
one free to choose the level of your study while still
providing future material that is challenging, hence
this chapter about the thinkers behind this revolution.
As it is reinforced several times in this book,
“Sharing an idea is communication, understanding
the idea is metaphysical.” Buckminster Fuller.
The earliest evidence we can find where man
first recognized that the brain was associated with
consciousness was Alkmaion of Kroton (500 BC)
who discerned, based on anatomical evidence, that
the brain was essential for perception. The Hippo-
cratic School preserved his view regarding the
mental primacy of the brain to vision. Nothing in
early medical systems claimed any intellectual
capacity for the brain. The Egyptians, normally so
fastidious in their care for the afterlife, heedlessly
discarded the brain in funerary practices. Most early
civilizations thought of the heart as primary to
understanding.
In the early sixteenth century George Berkeley,
Bishop of Cloyne, published a book in 1710 enti-
tled, “Treatise concerning the principle of human
knowledge.” In this work he clearly pointed out the
unreality of the external world by demonstrating the
illusions of the senses as witnesses in this case. Over
100 years later Ernst Mach (1838–1916) carried
Berkeley’s “Du Motu” into Mach’s principle which
then led Albert Einstein’s thought to dwell on
relativity.
Whether space is an independent entity of its
own, a number of relations between material objects
or a mere subjective notion superimposed on the
world is a question of long tradition and probably
rooted in our common impression of the distinct
differences between objects and the empty space
between them.
If you truly enjoy “mind-bending” reading
Newton, Euler, Kant and Helmholtz’s views of
objects, space, and relativity are there for the taking.
Mach insists that absolute motion and absolute
space, i.e. motion and space in them selves, reside
only in our minds and cannot be revealed by experi-
ence, hence they are meaningless, idle metaphysical
concepts and must not be used in a scientific
context. In quantum mechanics, mass and spin are
both measures of inertia. Therefore, there are inertial
affects proportional to Planck’s constant, such as
spin–rotation coupling, which is due to the inertia of
intrinsic spin.
3.2 The Current Era
We are currently afloat in “field” theories of the
human brain and its distinction from mind and
Mind. Francis Crick (of DNA fame), E. Roy John
(brain research laboratories NYU school of medi-
cine), and Johnjoe McFadden (University of Surrey)
have all made significant contributions to the elec-
tromagnetic fields in human beings, as well as
providing support for wider sweeps of these fields
into conjunction with the universe’s field such as
suggested by K. H. Pribram in “Proposal for a
quantum physical basis for selective learning.”
What has all this to do with audio? Fourier,
Gabor, Shannon et al. have had an immeasurable
effect on audio. Pribram writes,
Gabor wavelets are windowed
Fourier transforms that convert complex
spatial (and temporal) patterns into
component waves whose amplitude at
their intersections become reinforced or
diminished.
Fourier processes are the basis of holography.
Holograms can correlate and store a huge amount of
information and have the advantage that the inverse
transform returns the results of correlation into the
spectral and temporal patterns that provide guid-
ance in navigating our universe.
Let me share with you some of the jewels and
lumps present in the papers of these researchers with
the hope that you, too, possess ideas that might be
triggered by these suggestions. One materialistic
view by Richard Amoroso written as a criticism of
John Bell (of Cern fame),
He mistakenly thought that mind was immaterial;
it has only seemed this way for the last 300 years
because the material aspects of the normal nounenon
of consciousness have been hidden behind the

20
Chapter 3
nonlocal Planck barriers. If this were not so, minds
would not be safe from external influences and
mental problems would be the norm rather than the
exception and strong-willed individuals would be
easily able to harm weaker psyches.
I am left with the feeling that Mr. Amoroso
hasn’t peered from his academic cloistered ivory
tower to observe current human behavior and the
total mental manipulation of large groups of psyche.
Another material view of consciousness is that of
Francis Crick in his paper, “A framework for
consciousness,” written with Christop Koch,
There has been a great selective
advantage in reacting very rapidly, for
both predatory and prey; for this reason
the best is the enemy of the good.
Col. Jeff Cooper taught many successful SWAT
team members that proper shooting speed was
measured by about 10% of your fast shots missing
the center of mass of your target.
Crick further wrote,
More recently we have supported this
suggestion that in addition to a slower,
all—purpose conscious mode, the brain
has many ‘zombic modes,’ which are
characterized by rapid and somewhat
stereotyped response.
Driving a race car to its limits is not an intellec-
tual but a highly programmed reflex.
Crick also wrote,
The conscious system may interfere
somewhat with the concurrent zombic
mode…it seems to be a great evolu-
tionary advantage to have zombic modes
that respond rapidly, in a stereotyped
manner, together with a slightly slower
system that allows time for thinking and
planning more complex behavior.
 Col. Cooper’s response to this was his famous
color-coded awareness. His students trained to a
zombic mode by over 10,000 repeats of the neces-
sary physics of the quick reasonably accurate shot.
The color code was designed to get them out of the
unalert – unready “white” condition to a relaxed
“yellow” where one looked about to see if all was
normal. Where something wasn’t normal then
consciousness rose to a condition “orange.” Orange
alertness can go to “red” when danger is now immi-
nent—the zombic mode is then released, but note, if
truly alert, it’s not a mindless act.
Driving a car in an unalert mode can be
dangerous. If in yellow any darker patch on a winter
road may lead to orange because it could be
ice—you slow, it is ice—your zombic mode
responds because you have raised your conscious
awareness and are able to handle red.
It turns out that Mr. Crick is annoyed by physi-
cists when he writes,
Many people have said that
consciousness is “global” or has unity
(whatever that is), but have provided
few details about such unity. For many
years Baars (MIT) has argued that
consciousness must be widely distrib-
uted. We are not receptive to physicists
trying to apply exotic physics to the
brain, about which they seem to know
very little, and even less about
consciousness.
It seems to this humble observer that since the
physicists have measurably shown the presence of
fields in the brain that employ the same components
as fields in the universe that the possibility of simi-
larity is not to be dismissed so cavalierly. I do
suggest that Mr. Crick’s paper is an exceptionally
interesting read, especially where he sticks to his
own expertise.
Turning to the other schools of thought such as
John’s, “The Neurophysics of Consciousness,”
global theories by Penrose and Hameroff invoking
quantum mechanical concepts, and by Tononi and
Edelman introducing measurements of system
entropy and complexity have been proposed to
account for the emergence of consciousness.
Perhaps the most audacious and comprehensive
approach to the explication of global intricate to
process has been made by Pribram who contends
that a holographic encoding of the nodes of interfer-
ence patterns contains all of the information about
the environment described by Gabor’s elementary
functions, quantum of information. He has expli-
cated the relations between entropy, chaotic attrac-
tors, and the organization of the ensembles of
Gabor’s Quanta.
John says,
In critical observations about depen-
dence of information encoding upon
synchronicity within a region, disper-
sion of features extractors across brain
regions, coherence among regions and
the relevance of statistical consider-
ations to explain brain functions cannot
be reconciled with the hypotheses based
upon discrete processes in dedicated
cells. It is not plausible that a neuron
can encompass the global information
content of the multidimensional system
to which it belongs.

Sound and Our Brain
21
This paper is backed up by positron emission
tomographs of living human brains and a complete
schematic of the sources of some of the fields.
Again a paper worth reading completely. The 216
listings in the bibliography are priceless to the
researcher.
We now come to Johnjoe McFadden’s “Synchro-
nous firing and its influence on the brains’ electro-
magnetic field.”
It has been known for more than a
century that the brain generates its own
electromagnetic [EM] field. The elec-
trical field at any point in the brain will
be a superposition of the induced fields
from all of the neurons in the vicinity
(superimposed on the fields generated
by ion movement) and will depend on
their firing frequency, geometry and the
dielectric properties of the tissue. Direct
measurements of local field potentials
within the human brain tissue has
become possible in patients who for
therapeutic reasons, have had EEG
recordings obtained from sub dural
cortical or in-depth electrodes
implanted in their cerebral cortex. A
striking feature of EEG is the differences
in electrical activity from electrode to
electrode even on less than 1 mm apart
indicating that the brain generates a
highly structured and dynamic extracel-
lular electrical field. Further measure-
ments revealed that the human (and
animal) brains therefore contain a
highly structured (in time and space)
endogenous extracellular EM field, with
a magnitude of up to several tens of
volts per meter.
The superposition principle states that for over-
lapping fields, the totally EM field strength at any
point is an algebraic sum of the component fields
acting at that point.
Like all wave phenomenon field modulations due
to nerve firing will demonstrate constructive or
destructive interference depending on the relative
phase of the component fields. Temporal random
nerve firing will generally generate incoherent field
modulations leading to destructive interference and
zero net fields. In contrast synchronous nerve firing
will phase lock the field modulations to generate a
coherent field of magnitude that is the vector sum
(the geometric sum – taking into account the direc-
tion of the field) and its components.
Why such emphasis on this subject in a book on
sound system engineering? It is my belief that nano-
technology and digital technology will within a
generation be speaking directly to an audience’s
brain sans the acoustic link.
In humans, the strongest evidence for the sensi-
tivity of the brain to relatively weak EM fields
comes from the therapeutic use of transcranial
magnetic stimulation (TMS). McFadden states:
TMS has been shown to generate a
range of cognitive disturbances in
subjects including: modification of reac-
tion time, induction of Phosphenes,
suppression of visual perception, speech
arrest, disturbances of high movements,
and mood changes.
Repetitive TMS is subject to strict safety guide-
lines to prevent inducing seizures in normal
subjects. It is striking how well shielded the human
brain is from electrical signals cell phones et al, but
such tremendous sensitivity to magnetic influences.
The suggestion naturally arises as to what external
fields can communicate with the human brain’s
internal fields directly.
McFadden’s “Conscious electromagnetic infor-
mation field (CEMI) field theory” states:
Digital information within neurons is
pooled and integrated to form an elec-
tromagnetic field in the brain.
Consciousness is the component of the
brain’s electromagnetic information
field that is transmitted to motor
neurons and is thereby capable of
communicating its state to the outside
world.
McFadden further notes that:
Thanks to the Fourier transforms and
wavelet transforms, linear superposi-
tions or Laplacian information tech-
nology already exploits the advantage of
EM information transmission in optical
fiber communications.
McFadden, unlike many of the more materialistic
of his brethren, appreciates the work of physicist,
Bernard J. Baars, and finds that his work and Baars
support one another.
In this CEMI field theory, we are not simply
automatons that happen to be aware of our actions,
our awareness; (the global CEMI field) plays a
causal role in determining our conscious actions.
Creating communication that results in conscious
stimulation is our business. The B. Friedlaenders
have also pointed out a similarity between their
concept of relative inertia and induction effects in
electromagnetism: just as a change in the magnitude

22
Chapter 3
of the current, or distance, will generate induction
effects, only changes in velocity attractive will
generate attractive, or repulsive, effects.
Strange as it is, quantum theory offers features
which may be relevant to consciousness. One is that
large collections of quantum particle/waves can
merge into unitary coherent states of microscopic size
and influence. Superconductors, Bose-Einstein
condensates, and lasers are unitary states in which
component atoms or molecules give up individual
identity and behavior. Such coherent quantum states
have been suggested to occur among brain proteins to
provide unitary “binding” in vision and sense of self.
We now know that at very small scales, space
and time are not smooth, but quantized. This granu-
larity occurs at the incredibly small dimensions of
the Planck scale (10 - 3 3centimeters and
10-43 seconds). Penrose suggests thus everything is
in reality particular arrangements of space-time
geometry. Lee Smolin likens spin network volumes
to Leibniz monads and suggests that self organizing
processes at this level constitute a flow of time,
raising the issue of whether the universe is in some
sense alive.
3.3 Unexpected Validation
On December 20, 2011, IBM predicted mind
reading machines. The announcement stated that
IBM scientists are among those researching how to
link your brain to your devices, such as a computer
or a smart phone. IBM gave the examples of ringing
someone up just by thinking it, or willing a cursor to
move on a computer screen. They further state that
biological makeup will become the key to personal
identity, with retina scans, recognition of faces, or
voices, used to confirm who people are rather than
typing in passwords.
The metaphysics of such technical develop-
ments’ ability to access our conscious thinking
process (which this chapter on brain has discussed
as electromagnetic energy) leaves open the possi-
bility of two way transmission along the same paths.
The current prediction that 80% of the population
will have means of intercommunication with hand-
held devices such as I Pads and cellular telephones
suggests that addressing large crowds will not
require large sound systems but rather control of the
individual devices carried by the majority of the
population. Just as my use of digital voice recogni-
tion has allowed me to “type” these words
(requiring an effort on my part to enunciate more
clearly than was my normal pattern and allowing the
program to learn the characteristics of my speech),
so will we be required to obtain control of our often
many layered consciousness when in the presence of
mind reading devices.
We have had an exponential growth rate of hard-
ware over recent decades, and it is now apparent that
some of the software is beginning to grow exponen-
tially as well. The earlier advent of neuron, axon,
and synapse chips by IBM (see Chapter 5 Digital
Theory) coupled to this most recent announcement
regarding access to the internal signals of the human
brain suggests that Orwell was only in error by 100
years in the means of human control to be accom-
plished in 2080.
Bibliography
B. J. Baars & K McGovern (1988), A Theory of Consciousness, New York: Cambridge University Press.
F. Crick & C. Koch, “A Framework for Consciousness”, Nature Neuroscience, 6 (2), February 2003.
E. R. John, “The Neurophysics of Consciousness”, Brain Research Reviews 39 (2002) pp. 1–28.
S. Martine-Conde, “A Review of Christof Koch’s The Quest for Consciousness”, Psyche 10 (2), September
2004.
http//www.merkle.com/humanMemory.html, No. 4, October 1988.
J. McFadden, “Synchronous Firing and Its Influence on the Brain’s Electromagnetic Field”, Journal of
Consciousness Studies, 9 (4), 2002, pp. 23–50.
H. Moravec. “When will Computer Hardware Match the Human Brain?” Journal of Evolution & Technology,
(1) (1998).
V. Vinge, “The Coming Technological Singularity: how to survive in the Post-Human Era”, Whole Earth
Review, Winter (1993).

Chapter 4
Psychoacoustics
by Don Davis
23
4.1 Motivations  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25
4.2 Sound Reproduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25
4.3 Is it Better to be Born Blind or Deaf ? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 26
4.4 Recording Sound at the Eardrum . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27
4.5 Psychoacoustics via a Metaphysical Foundation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27
4.6 Barks, Bands, Equivalent Rectangular Bandwidths (ERBs), Phons and Sones  . . . . . . . . . . . . . . . . . . . . 28
Phon Level . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29
Sones  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29


Psychoacoustics
25
4.1 Motivations
As I mentioned elsewhere in the book, my original
motivation for pursuing audio studies came from
extensive listening to classical music. This listening
begun, in a serious way in 1949, and by 1952, I was
engaged in the custom construction of what was
then called high fidelity systems. Parallel to these
activities I had the opportunity to hear many large
orchestras and many fine artists due to the fact that
we lived in a University town. In attempting to
match the sound level, low distortion, and wide
frequency range of a large orchestra we encoun-
tered many unmeasurable qualities that led us to
understand the difference between “high fidelity”
and fidelity. The difference was vast then, and it is
still vast today.
Richard C. Heyser once remarked that the scene
boards used on motion picture sets (the scene tech-
nical data is written on the board and a sound clap is
made with a hinged section of the board) provided
the necessary impulse data to let us, years later, if
we ever acquired the ability, to reproduce the
acoustic environment present on that soundstage.
Some of the better classical recordings, such as
those made by EMI years ago, allow the listener to
hear the room’s reverberation and unique ambient
noises. The spaces between crescendos can have
important emotional content, especially in operas.
There may be many significant signals in modern-day
recordings that contain emotional content, if not
processed out by modern digital technology.
The world’s psychoacoustians have made great
strides in aiding digital recording technology to
remove meaning and emotion while retaining infor-
mation. It is indeed true that Shannon ignored both
meaning and emotion as irrelevant to his goal of
transmitting and preserving information, but the
technology has hidden within it possibilities as yet
unimagined. None of these comments are intended
to deprecate the remarkable gains that digital tech-
nology has provided us, but rather to encourage
exploration into what constitutes true fidelity. I
would encourage anyone making archival record-
ings today to never use less than 96 kHz sampling
rate and twenty-four bit depth for two channel
recordings
I am not a fan of “tested in the home,”
double-blind tests, etc. Over the decades, it has been
shown that subtle flaws in recordings are detected
by listening over and over again to favorite selec-
tions without any thought of conscious analysis.
Often the realization will sneak in that the recording
caused undue fatigue compared to other recordings
of the same material. This has been true for both
analog and digital recordings.
I have, in sixty years in audio, encountered a few
individuals whose hearing, experience and intelli-
gence provided exceptional judgmental capabilities
that rank at the top of the Gaussian curve for human
hearing. Such individuals can be an interesting
guide to new listening experiences. A music critic
detected in the recording of an older diva that a
single high note had been dubbed in for her. He then
identified the artist who had supplied the single
note. A music critic who can do that demands our
recognition and respect, both for his aural acuity and
experience.
4.2 Sound Reproduction
Pundits, measurements, friends’ advice, etc., can all
serve as rough guides to seeking out a satisfactory
reproduction system. The truly critical listener,
however, is you. When listening to loudspeakers for
the reproduction of music, previous experience
plays an enormous role. True musical fidelity is in
the live performance of gifted artists, and the greater
the experience in hearing such artists the more likely
the ability to detect unfaithful musical qualities in a
loudspeaker.
The halls the artists perform in not only affect the
acoustical quality of the signal they produce; but
affect the sense the artist has of his own perfor-
mance. Even partial reproduction of the performing
environment in a recording is a rare occasion. Thus
we begin the selection of a loudspeaker system for
musical reproduction as a compromise.
I have read books, tested in the home reports,
published laboratory reports, emotional evaluations;
none of which ended up bearing any relation to what
I heard when I had a chance to hear the loudspeakers
they described. In my sixty years of involvement in
audio systems I have found that the choices I made
in my youth are not the choices I make in my matu-
rity. In most cases this was not due to the technical
advances made in the sixty years, but to my
increasing experience in listening to loudspeakers.
The all-horn loaded devices I so enjoyed in the
1950s, because of their dynamic range and direc-
tional control, was tempered by the reproduction of
violins by the better direct radiators, coupled to suit-
able bass re-producers.
Surprisingly, the best electronics of sixty years
ago are still the best electronics today, though not
readily available as a consumer product. Interest-
ingly, the professional monitor manufacturers
produce the most reliable loudspeakers, which are
least likely to fatigue with age, or be damaged by
excessive levels. Horn loaded low-frequency loud-
speakers lead by a substantial margin any other kind

26
Chapter 4
in the reproduction of transients, especially in piano
music, percussion, and sound affects.
The best test of any loudspeaker system is the
human voice. It’s what we know best and is the
easiest to judge for fidelity, simply by asking the
listener to identify the talker. Remembering that the
simple telephone circuit also allows this over a
limited range, we need to add the tests of walking
across the loudspeaker’s pattern and listening to the
tonal changes that occur with changing position.
Signal delay and phase difficulties reveal them-
selves to the experienced listener with such changes
in listening positions.
Pipe organ, coupled with orchestra recordings,
reveal intermodulation distortion, when such distor-
tion is present. In some early, very inefficient direct
radiators, intermodulation removed the sound from
higher frequency instruments, as the pipe organ
pedals were utilized. This was not an electronic
affect, but an electroacoustic effect.
In the final analysis when choosing a loud-
speaker for critical listening purposes, select the one
that sounds best to you, sans the advice of others.
My best advice is to select the best one you can’t
afford because you will grow into it and growing
into it is far better than growing past it.
The most reliable test of a loudspeaker is that
you can listen to your favorite music by the hour.
When your listening experience results in early
fatigue and subconscious irritability, you have
grown past your unit. In the purchase of an expen-
sive loudspeaker system for your home arrange,
with the dealer for its use in your home for several
days prior to final purchase.
One of the joys of life in audio is when a highly
experienced colleague is able to guide you to hear,
over your loudspeaker, sounds previously inaudible
to you that increase your listening pleasure.
Don’t expect others to appreciate the choice you
made. Engineers make radically different choices
than musicians. Musicians upon hearing the
harmonics will mentally replace the missing funda-
mental. Engineers will cringe at gross harmonic
distortion whereas, musicians may not hear it. In a
working environment such as a recording studio, the
comparison of the monitoring loudspeaker and the
live sound is but a step through the door to the
studio, whereas in the home it’s a trip across town to
the concert hall.
Pass off as abused children anyone who would
criticize your choice of a personal loudspeaker.
4.3 Is it Better to be Born Blind or Deaf ?
Helen Keller’s statement on this subject:
I am just as deaf as I am blind. The
problems of deafness are deeper and
more complex, if not more important,
than those of blindness. Deafness is a
much worse misfortune. For it means
the loss of the most vital stimulus—the
sound of the voice that brings language,
sets thought astir, and keeps us in the
intellectual company of man.
From an unknown author:
Let’s focus on the blind/deaf ques-
tion. Genius overcomes many difficul-
ties. As evidence we have the pantheon
of blind and deaf artists, ranging from
Beethoven to Goya to Milton to Ray
Charles. According to neurophysiolo-
gist and author, Oliver Sacks (in his
book Seeing Voices), whether it’s better
to be blind or deaf depends on how old
you are. For an adult, blindness and
deafness are about equally problematic.
But for a child, there is no question: it is
better to be blind. Anyone who has had
the opportunity to teach a deaf child
knows this. Hearing is the primary
channel through which we receive
language, and all of those incoming
words downloaded into our brains carry
a wealth of emotional and cognitive
apparatus that structures and empowers
our imagination. Language is the mind’s
apposable thumb.
Victor Peutz, who made a lifelong study of intel-
ligibility and the percent of Articulation Loss of
Consonants, often stated that it would be better to be
born blind than deaf as language is necessary to the
development of the intellect. The key word here is
“born.” Helen Keller was finally reached by Anne
Sullivan when Helen made the connection from
water out of a pump to the hand signals that Sullivan
used for water. Helen, as an infant just before the
illness that destroyed her visual and auditory senses,
had experienced water.
For older adults it’s a moot question. It’s worth
noting video images require only eight bits of digital
information compared to audio which requires
twenty-four bits for full fidelity. I have a neighbor
whose hearing was restored via a cochlear implant.
She was born with limited hearing. By the time she
was 40 she was completely deaf, though she raised a
family and operated a successful beauty shop by
reading lips.
Modern hearing protectors are a very worth-
while investment especially when you’re in the pres-
ence of impulsive sounds, such as gunfire, stapling

Psychoacoustics
27
guns, and various trip hammer devices. While
extremely high-level non-impulsive sounds can
cause discomfort and even temporary threshold shift
in the human hearing, high-level impulsive sounds
can cause loss on a single exposure.
4.4 Recording Sound at the Eardrum
Binaural recording has a history dating from the
1880s. True binaural recordings are two channels
for reproduction through headphones. When Mead
Killion, Eytomotic Research, developed wide-range
probe microphones capable of being used at the
human eardrum, I utilized them for measurement
work in recording control rooms and for musical
recordings in theaters with audience present. Using
this new ITE (in-the-ear—at the eardrum) system,
employing the pinna acoustic response recording
techniques, we experienced for the first time in our
lives, listeners unable to tell a live talker from a
recorded talker when the recording is played back
and the talker on the recording is also present in the
listening room. The first time I listened to a play-
back made in our classroom I got up twice and went
to the door to answer a knock, before realizing that
the knock had come during the recording session.
Harvey Fletcher in the SMPTE Journal Volume 61,
September 1953 stated:
It is important to recognize the differ-
ence between a stereophonic system and
a binaural system. The former system
uses loudspeakers, but requires an infi-
nite number of channels for perfect
reproduction. The latter requires only
two channels for perfect reproduction,
but involves the use of a pair of head
phones held tightly to the ears for each
listener. All listeners with such a system
can be given the illusion of sitting in the
best seat in the concert hall. 
Most binaural recording today is done with an
artificial or “dummy” head replicating the human
head not only in average dimensions and details but
also in approximate hardness and softness of skin
and bone. Some of the recording heads also model
the shoulders, and many have hair on the head,
because all these details have an effect on the sound
picked up by the two microphones.
These microphones are usually tiny omnidirec-
tional condensers mounted at or near the entrance to
the ear canals. Some designs place the microphones
at the same location as the eardrums. In every case it
is attempted to preserve the head related transfer
functions (HRTFs), Fig. 4-2.
The notable difference between ITE recordings
made in a live human head and more conventional
techniques might be due to otoacoustic emissions or
efferent stimuli that originates in the auditory cortex
and terminates at the sensor of the organ of Corti.
Throughout its descending course the efferent
auditory pathway interacts with the afferent auditory
path through feedback loops and is identified with
producing muscular and other reactions. The
afferent pathway is the one from the cochlea to the
brain areas associated with hearing. The efferent
pathways are the ones desending from the brain
back to the cochlea area. The descending (efferent)
are known to have modulatory control of the medial
efferent auditory system. (Nina Kraus at North-
western University in Evanston Illinois) has written
numerous publications addressing this subject.
The use of in-ear recordings allows later labora-
tory judgments about which direction undesired
energy came from, and in the case of recording
control rooms, shows a remarkable difference in
envelope time curves from those made by conven-
tional omnidirectional microphones. One obvious
use for the better quality “dummy” heads is the
ability to place them inconspicuously out in the
audience so that a control room removed from the
audience can have meaningful auditory input from
the auditorium.
In the years when we made the original ITE
recordings, the phase response between DAT
recorders was not consistent. Today’s solid-state
digital recorders have the required phase stability to
allow the interchange of recordings from one unit to
the other via data cards.
One remarkable use of a precision artificial head
was in the Acoustics Lab at Mercedes Benz in Stutt-
gart whereby they traced the noise sources and their
directivity as part of a project to silence diesel
engine noise in cars. I recently had the experience of
riding in a Mercedes sedan where I could detect no
difference in noise level from their gasoline fueled
cars, inside and outside the car.
4.5 Psychoacoustics via a Metaphysical 
Foundation
I would like to take a moment of the reader’s time to
discuss psychoacoustics from a metaphysical, rather
than a materialistic foundation. The measurements
made to explore the vulnerability of humans to illu-
sions, while valuable “leaves out all that is near and
dear to our hearts.”
Buckminster Fuller has said, To share an idea is
communication, to understand the idea is metaphys-
ical. As a young man I resisted musical training.

28
Chapter 4
Military bands and marches were my only connec-
tion emotionally to music. At the university level, I
encountered Vladimir Horowitz, large orchestras,
and opera. The impact of Tosca sung by Maria
Callis, the Mozart sonatas, and Beethoven’s Ninth
Symphony had lasting emotional effect on my state
of mind.
At this period in my life, a close friend, a painter
of unusually sensitive skill, pointed out that
listening to music of a given period, while viewing
paintings of the same time in history, and reading
history of that period, led to a remarkably increased
understanding of all three unobtainable when
looking at only one of them.
Viewing the films made in the 1930s at Hitler’s
Nurenberg rallies, listening to the German National
Anthem, and viewing the response of the audience,
contrasts sharply with films made after the war of
large crowds hearing the German National Anthem
in Germany.
Artists, demagogues, political leaders, ministers,
and teachers all communicate to their audiences, and
on rare occasions, reach them metaphysically. The
frenzies observed at rock concerts, the fury of Third
World mobs aroused by a demagogue with a
powerful sound system, and the connection of an
inspired preacher to his audience through a large
powerful sound system, are modern-day examples
of psychoacoustics in the metaphysical sense.
From an engineering standpoint we know how to
contribute to such events by properly enhancing the
music, the speech, and the lighting. I recall one
sound contractor being approached by an evangelical
minister who requested he put more “soul” into the
monitor. I didn’t ask him to divulge this trade secret.
In Europe, “tone meisters” are taught technology,
music and history. In historic venues the sound
system engineer should emulate the medical physi-
cian by “first do no harm” as a goal before trying to
introduce sound apparatus. The design goal should
always be so unobtrusive that the audience does not
realize a sound system is present until it is turned off
unexpectedly and its presence is missed.
At the Opera house in Wiesbaden Germany, we
congratulated the tone meister for the quality of the
children’s choir in Hansel and Greta without sound
reinforcement. He replied “oh, but we did reinforce
them,” and then showed us an extremely clever
loudspeaker system built into the arch of the stage
opening, and used so sensitively as to be undetect-
able while reinforcing the children significantly.
We witnessed this particular performance while
seated in the Kaiser’s box, as guests of the tone
meister. It was this experience that led me to remark
that “I’d be willing to live in a class system but only
if I could be King.”
In today’s world of tight budgets, compressed
timescales, and isolation of the designer from the
end-user, all of the above may be wishful thinking,
but when possible, exceptional results can be
obtained.
4.6 Barks, Bands, Equivalent Rectangular 
Bandwidths (ERBs), Phons and Sones
Psychoacoustics is employed in many areas of audio
to manipulate the acoustic experience. Digital audio
uses knowledge of phon levels and critical band-
widths to remove unnecessary data from being
encoded into the digital stream. Filter design has
utilized critical bandwidths as optimal numbers
required to obtain desired equalization.
The concept of critical bandwidths first appeared,
to the very best of my knowledge, in Harvey
Fletcher’s work with regard to masking. An article
in “Acustica” in 1956 by H. Bauch entitled, “The
Relevance of Critical Bands for the Loudness of
Complex Sounds,” was used by me in the 1960s to
justify the bandwidth chosen in the design of equal-
izing filters.
The Bark scale ranges from 1 to 24 Barks, corre-
sponding to the first twenty-four critical bands of
hearing. The Bark scales are found in Table 4-1.
Bark number, center frequency, and upper and lower
−3dB points are indicated. Critical bands shaped
masking patterns should be seen as forming around
specific stimuli in the ear, rather than being associ-
ated with a specific fixed filter bank in the ear. The
equation for finding the bandwidth knowing the
center frequency is:
(4-1)
where,
.
For example, using a center frequeny of 1080 Hz:
To find the critical band z, use equation 4-2:
BW
25
75 1
1.4f 2
+
(
)
0.69
+
=
f
Center frequency
1000
-----------------------------------------
=
f
1080
1000
------------
=
1.08
=
BW
25
75 1
1.4 1.08
(
) 2
+
(
)
0.69
+
=
171 Hz
=

Psychoacoustics
29
(4-2)
4.6.1 Phon Level
Fig. 4-1 shows the equal loudness contours from
which phon levels are obtained. How widely indi-
viduals might vary from such curves, especially in
the 2 to 4 kHz octave bands can be seen in Fig. 4-2
for pinnae responses. Fig. 4-3 compares one octave,
one third of an octave, one sixth of an octave, ERBs
and critical bands on a frequency versus bandwidth
basis. ERBs are filters that are “Equivalent Rectan-
gular Bandwidths” of critical bandwidth filters. To
determine the ERB when the center frequency is
known use:
(4-3)
If we have a center frequency of 19,285 Hz, the
bandwidth would be
To find the center frequency of the band when
the bandwidth is known use:
(4-4)
For example, for a bandwidth of 142 Hz, the center
frequency would be:
Table 4-2 shows the equivalent rectangular band-
width for the 41 center frequencies.
For a majority of uses, the one third octave-type
filter (also the most available) will suffice. For over-
lapping critical bands the phon scales may be added
on a power basis. Power basis is used instead of
sound pressure level basis because of the definition
of the phon as related to the sone.
4.6.2 Sones
We can take two adjacent one-third octave bands
that lie on the 70 phon scale, add them as power
ratios, and then convert the result to sones, Eqs. 4-3
and 4-4.
(4-5)
where,
LP1 and LP2 are the individual sound levels in dB.
For example:
This allows a subjective sense of increased or
decreased “loudness” on a scale thought comparable
to human hearing. The chart shows that a change of
10 dB can be seen as doubling the sone value, hence
twice the “loudness.” Going from one sone to two
sones equals 10 dB by definition.
Table 4-1. Bark Number, Center Frequency, and 
Upper and Lower −3dB Points
z
26.81
f 
×
1960
f
+
-----------------------
⎝
⎠
⎛
⎞
=
9 Bark
=
ERB
0.108f
24.7
+
=
ERB
0.108 19285
(
)
24.7
+
=
2107.5 Hz
=
f
bw
24.7
–
(
)
0.108
----------------------------
=
f
142
24.7
–
(
)
0.108
------------------------------
=
1028  Hz
=
PT
10
10
LP1
10
---------
10
LP2
10
---------
 
+
⎝
⎠
⎜
⎟
⎛
⎞
log
=
x phons 
=
PT
10
10
70
10
------
10
70
10
------
 
+
⎝
⎠
⎜
⎟
⎛
⎞
log
=
73 phons 
=

30
Chapter 4
To determine the number of sones 73 phons is
used:
(4-6)
or
Table 4-2. Equivalent Rectangular Bandwidth Center 
Frequencies vs. Bandwidth
fc
fc
bw
bw
S
2
PT
40
–
10
------------------
=
S
2
73
40
–
10
------------------
=
9.8 sones
=
Figure 4-1. Equal loudness contours at various SPLs.
Figure 4-2. Pinnae responses.
Figure 4-3. A plot of critical bandwidths of the human
auditory system compared to constant percentage
bandwidths of filter sets commonly used in acoustical
measurements.
120
100
80
60
40
20
0
−10
50  100      300 500  1k       3k  5k  10k 20k
Sound pressure level–dB
Frequency–Hz
Loudness Level–Phons
100
120
110
100
90
80
70
60
50
40
30
20
10
Minimum
audible
100     200         500      1k        2k           5k     10k
Center frequency–Hz
1000
500
200
100
50
20
10
Bandwidth–Hz
1 octave
1/6 octave
1/3 octave
Critical band (ERB)

Psychoacoustics
31
To go from sones to phons use:
(4-7)
Therefore changing 8 sones to phons we find:
Table 4-3 gives music levels vs. phons and sones.
P
10 ln S
( )
ln 2
( )
------------
⎝
⎠
⎛
⎞
40
+
=
P
10 ln 8
( )
ln 2
( )
------------
⎝
⎠
⎛
⎞
40
+
=
70 phons
=
Table 4-3. Relationship Between Music, Phons and 
Sones
Music
phons
sones
fff
100
64
ff
90
32
f
80
16
-
70
8
p
60
4
pp
50
2
ppp
40
1


Chapter 5
Digital Theory
by Don Davis
33
5.1 Shannon’s Theory  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35
5.2 Dynamic Range  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36
Cognitive Computing  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37
Digital Recording Techniques . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37
Frequency Dependent Case . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39
A Stochastic Process  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40
5.3 The Steps from Art to Science . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40
5.4 Moravec’s Warning  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 41
5.5 Digital Nomenclature . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42
5.6 What Is a Bit of Data?  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43
The Physical Dimensions of One Bit  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 44
Reading Binary Numbers  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 45
Text into Binary, Octal, Hexadecimal . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46
5.7 Bayesian Theory  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47
5.8 Planck System  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47
5.9 Bits, Nats, and Bans . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48
5.10 A Communication System . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 48
5.11 Holography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49
Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 49


Digital Theory
35
Theorists have postulated a holographic universe.
Alex Harley Reeves wrote: “The Bicken-
stein-Hawking conjecture asserts proportionality
between surface area of a gravitationally closed
structure like a black hole or a hypersphere, and its
internal entropy.” Richard C. Heyser commented
during a lecture on Holography at the Audio Engi-
neering Society meeting in Los Angeles that “It
pains me to give away in 10 minutes what it took me
10 years to learn.” I remember thinking that it will
take 10 years to assimilate everything he has shared
in 10 minutes. See section 5.11 Holography for a
discussion of Holography. The Claude Shannon
Information Theory relates information to entropy.
One Kelvin can be defined as a requirement of
 or 86.2  ueV of energy input per
increase of the log state count by 1.0 Nat.
Combined these theories lead to the idea of a
holographic universe in which each Planck unit of
the surface of the universe carries one bit of infor-
mation. These bits of information served to define
what happens in all Planck volumes within the
universe. Lord Rayleigh’s, The Theory of Sound,
had similar challenges to thought and the reliability
of the evidence of the senses.
Kelvin says that ideal engines cannot exist, and
Clausius says that ideal refrigerators can’t exist.
Landauer’s Principal states:
There is no machine whose sole
effect is the erasure of information.
There is a price to forgetting. One has to
generate at least Kt (ln 2) to get rid of
one bit of information.
Shannon’s great insight was that it is possible to
associate entropy with any set of probabilities,
Fig. 5-1.
5.1 Shannon’s Theory
In our increasingly digital world we need to recall
that the term bit “binary digit” first appeared in
Claude Elwood Shannon’s 1948 paper, “A Mathe-
matical Theory of Communication,” from the Bell
System Technical Journal. (Given to Shannon by
John W.Tukey, a Bell Lab coworker.)
The essential elements of Shannon’s formula are:
1.
Proportionality to bandwidth W.
2.
Signal power S.
3.
Noise power N.
4.
A logarithmic function.
(5-1)
where,
C = bits of information that can be transmitted
without error per second, Eq. 5-1.
Fig. 5-2 is a Mathcad printout of Information
Theory.
The seminal work of Alex Harley Reeves in 1937
when he patented PCM (pulse code modulation)
quickly led to several conclusions.
Implicit in Reeves patent were two important
principles:
1.
An analog signal such as speech could be repre-
sented with accuracy by means of sufficiently
frequent sampling and by quantizing each
sample to one of a large number of predeter-
mined levels, Fig. 5-3.
2.
These samples can be transmitted with small
probability of error provided the signal-to-noise
ratio (SNR) is sufficiently large. This implied
that such a channel could handle an infinite
amount of information in an arbitrarily small
bandwidth.
To encode an analog audio voltage into a digital
audio number stream, analog-to-digital converters
(ADCs) sample the waveform in both time—hori-
zontal slices or samples—and in vertical voltage
slices or quantization, usually expressed as some
number of bits.
Professional audio devices typically use a 96 kHz
sample rate, but other common rates are 32 kHz
1.38
10 23
–
J
×
Figure 5-1. The information is stored as entropy on the
area of the black hole’s event horizon. Each bit
(1s or 0s) corresponding to one unit of entropy, occu-
pies four Planck areas. The area of the horizon is a
measure of black hole’s entropy.
Black hole
event
horizon
One
Planck
area
One unit of
entropy
C
W
log2 1
S
N----
+
⎝
⎠
⎛
⎞
×
=

36
Chapter 5
(broadcast), 44.1 kHz (audio CDs), and 48 kHz or
192kHz for high-end recording or audiophile appli-
cations. Quantization, the number of bits used in
professional equipment, is typically 24 bits with
16bits for CDs.
“Shannon Space” for human hearing appears in
Fig. 5-4.
5.2 Dynamic Range
Dynamic range theoretically for 24-bit quantization
equals:
(5-2)
or 146.25 dB and for 16-bit quantization equals
98.09dB.
To find the bit rate when the SNR is known use:
(5-3)
Indeed digital recordings and electronics can in
theory deliver increased dynamic range. Like distor-
tion figures, dynamic ranges in real life sound rein-
forcement systems, while desirable, are usually
constrained by the acoustic possibilities.
Consumer digital devices, cell phones, music
players etc. are low-cost throw-away consumer
items in today's market place. In professional sound
systems, that operate in the presence of live audi-
ences, battery operated analog backup systems for at
least safety purposes, i.e. voice communication
during a power failure, are still necessary adjuncts to
a fully digital system. Latency problems also
deserve special attention as many digital devices
contain significant signal delay.
The digital world still falls short of what man can
do inasmuch as the human brain has a storage
capacity of from 1015 to 1017 bits of information and
a processing rate of 100,000 Teraflops per second.
The modern computing devices have reached the
stage of being on a par with the brain of a Guppy,
Fig. 5-5. The computer approach is a linear
approach to a very nonlinear system called thinking.
Humans have the very real ability to process very
nonlinear information, distorted information, and
even the ability to draw correct conclusions from
false information.
In discussing neural networks David J. C.
MacKay in his book, Information Theory Inference
and Learning Algorithms, points out that digital
devices suffer from:
Figure 5-2. Information Theory.
Figure 5-3. Effects of sampling rates on quality.
Sample Rate
Higher
And Higher
Large
Error
Less
Error
No
Error
Bit Depth
More
And More
SNR
10log10 6
2
2
bits
×
(
)
2
–
[
]
×
(
)
=
Figure 5-4. ‘Shannon Space’ for human hearing.
Threshold NSD
11 bits @52 kHz
CD Channel
18.2 bits @ 96 kHz
Noise shaper
0 Hz
10 kHz
20 kHz
30 kHz        40 kHz
140
120
100
80
60
40
20
0
−20
−40
SPL
bits
10
SNR
10
-----------
6
--------------
⎝
⎠
⎜
⎟
⎜
⎟
⎛
⎞
ln
2
ln
-------------------------------
2
+
2
-----------------------------------------
=

Digital Theory
37
1.
Address space memory is not associative.
2.
Address space memory is not robust or fault
tolerant.
3.
Address-based memories are not distributed.
In the case of biological memory:
1.
Biological memory is associative memory. Recall
is content addressable.
2.
Biological memory is error tolerant and robust.
For example: “An American politician who was
very intellectual and whose political father did
not like broccoli” leads many people to think of
President Bush (remember the author of this
book is British) even though one of the cues
contains an error.
3.
Hardware faults can be tolerated. Memory often
persists through brain damage.
4.
Biological memory is parallel and distributed, and
has a remarkable ability to work through loops.
The above is not to deprecate digital devices, but it
merely intends to make the point that a live operator
with multiple backup capabilities is wise insurance.
5.2.1 Cognitive Computing
August 18, 2011, IBM announced a series of chips
that would allow a computer with processors that
mimic the human brain’s cognition, perception, and
action abilities. It is described as:
The first cognitive computing core
that combines computing in the form of
neurons, memory in the form of
synapses, and communications in the
form of axons all working in silicon, and
not PowerPoint. These chips can enable
biological ‘senses’ such as sight, sound,
smell, and touch, and drive multiple
motor modes while consuming less than
20  W (of power) and occupying less
volume than a 2 L bottle of soda, and
weighing less than 3 pounds.
IBM hopes:
To weave the building blocks
together into a scalable network and
progressively scale it to a mammalian
scale system with 10,000,000,000
neutrons, 100,000,000,000,000
synapses, all while consuming 1 kW of
power and fitting in a shoebox some-
time between now and the year 2018.
Many brain researchers make a distinction
between the brain and “Mind,” and the role of each
in consciousness. (See Chapter 3 Sound and Our
Brain for further clarification of these distinctions).
5.2.2 Digital Recording Techniques
In 1928, Harry Nyquist wrote that sampling a signal
at more than twice the desired bandwidth was a neces-
sary limit on digital signaling. It is an error to say that
it should be equal to twice the necessary bandwidth; it
must be greater than the desired bandwidth.
Shannon termed the zeros and the ones as bits
(binary digits), and employed the logarithmic base 2
in his calculations. From this sprang the concepts of
sampling rate (samples per second), and quantiza-
tion of the amplitude in bits. In audio recordings the
sampling rate multiplied by the time in seconds,
multiplied by the quantum value in bits, multiplied
by the number of channels, divided by the channel
reciprocal multiplied by bits equals the file size,
Fig. 5-4. Eight bits equal one byte, four bits equals a
nibble, and sixteen bits equals a word. File sizes are
normally stated in bytes.
An example of decimal numbers as digital code
is given in Table 5-2 where it can be seen that the
decimal number is the addition of the exponents
related to base 2; conversely you can by repeated
division find a digital code from a decimal number.
Logarithms are used with many bases: the
Napieran base e, the Briggsian base 10 (used for
bans in code breaking during World War II), and
base 2 for information. In the physical science
world, one “Nat” has the physical dimensions of a
square two Planck lengths on a side. The world-
Figure 5-5. Raw Computing Muscle, as exemplified by
a plot of 120 top machines of their time since 1940, is
today on par with the brain of a guppy. It may reach
human equivalent around 2040.
1940       1960        1980       2000         2020        2040
Year
Brain Power (instructions per second)
Mac G5/Dual 2.0 GHz
Sony Playstation II
Cray-1
DEC VAX
11/780
IBM 7040
ENIAC
UNIVAC
Apple II
Commodore 64
IBM PC
Gateway
486DX2/66+
Human
Mouse
Guppy
Worm
Bacterium
1015
1012
109
106
103
1

38
Chapter 5
renowned physicist, John Wheeler, declared reality
was “It’s from bits.”
Digital file size can be calculated with the
following equation:
(5-4)
where,
Sr is the sampling rate,
ts is the time in seconds,
bits is the quantum value. 8 bits equal 1 byte,
chan is the number of channels.
An example is; if we have a sampling rate of
44,100Hz, a time of 60 s, 16 bits, and 2 channels, we
would have:
To find the file depth use:
(5-5)
or
To find the file depth in dB use;
(5-6)
or
(5-7)
The download time can be found by:
(5-8)
where,
ts is 1 for seconds, 60 for minutes, and 3600 for
hours.
Assuming the modem speed is 0.056 mbps, the
download time would be:
Dr. Thomas Stockham made the very first 16-bit
PCM recording in the United States in 1976 for the
Santa Fe Opera on his Sound Stream recorder. When
I first measured the “ringing” associated with the
early digital recorders (antialiasing filters), Dr.
Stockham was the only one I knew that had both
understood and avoided this anomaly.
Studer, upon seeing the measurements, withheld
their professional recorder until the problem was
corrected; others failed to do so, which led, in our
opinion, to some of the artifacts that so disturbed
“sensitives” during that early period (1982). The
Motion Picture Expert Group (MPEG) within the
International Organization for Standardization (ISO),
worked out a series of audio coding standards for
storage and transmission of various digital media.
Digital versatile disc (DVD), High definition
television HDTV, and ongoing competing methods
make the description of each system chronologically
challenging. Currently the Dolby AC-3 is the preva-
lent coding standard for the U. S. Phillips PASC
(Precision Adaptive Subband Coding) is similar to
the ISO/MPEG/1 layer 1; Sony has ATRAC (Adap-
tive TRansform Acoustic Coding) with its ability to
manipulate psychoacoustic principles to both bit
allocation and the time frequency mapping. Further
digital details, mathematics and circuitry are in
Chapter 22, Signal Processing and Chapter 25,
Putting It All Together.
The broad parameters discussed here have not
changed in the decades since Shannon’s paper.
Encoding and transmission techniques will continue
to evolve, but the fundamental parameters continue
to be usable guideposts when looking at devices and
their claims.
All audio devices contain some latency. In digital
devices such as crossovers (inadvertent delay) and
deliberate (delay lines) can be acoustically signifi-
cant in live sound reinforcement. In one sound
system I was hired to evaluate, the delay in a digital
crossover was 30 ms and rendered signal alignment
a matter of putting one part of the loudspeaker
system physically 30  ft behind the other part.
Numerous occasions occurred wherein measuring
the time domain behavior of a system left us with a
blank screen on the analyzer until we remembered
the fundamental rule to always measure globally
before measuring specifically.
file size
Sr
ts
bits
×
chan
×
×
(
)
1
chan
------------
bits
×
106
×
--------------------------------------------------------
=
file size
44 100
,
60
16
×
2
×
×
(
)
1
2---
16
×
106
×
--------------------------------------------------------
=
10.584 mb
=
file depth
2bits
=
file depth
216
=
6.554
104
×
=
file depth in dB
20
file depth
(
)
log
=
file depth in dB
20
6.554
104
×
(
)
log
=
96.33 dB
=
download time
file size
modem speed
ts
×
1
chan
------------
bits
×
----------------------------------------------
----------------------------------------------
=
download time
10.54
106
×
 0.056
106
×
(
)
60
×
1
2---
16
×
-----------------------------------------------
-----------------------------------------------
=
25.2 min
=

Digital Theory
39
The sound system engineer must keep in mind
that we start with an acoustic signal in an acoustic
environment and end up with an acoustic signal in
an acoustic environment in a vast majority of cases.
In broadcasting and recording up to 90% of the
actual signal material can be removed in the
processing of the digital signal at hand. These were
some of the early lessons in using digital equipment.
Antialiasing filters, i.e. brick wall filters with attenu-
ation rates as high as −146 dB per octave, were tried
by some early CD manufacturers, resulting in a
group delay at 20 kHz of 1 ms, and a relative phase
shift of some 3000° which was clearly audible. The
problem was finally solved and then only on replay
by the use of over sampling techniques that moved
the aliasing frequency from 22 kHz up to as high as
some cases as 154 kHz. This allowed controlled
filter design well away from the desired pass band.
Richard C. Heyser liked to point out how much
the human listener can detect that can’t be
measured. He said:
The end product of audio is the
listening experience. The end product is
a result of perception and cognition and
evaluation processes occurring in the
mind. What do we know about such
processes—the answer is very little. 
Heyser went on to elaborate:
My own research into nonlinear
behavior has caused me to introduce
three divisions to what is universally
spoken of as perception. These are the
divisions of:
1.  Sensory contact and stimulus.
2.  Association of stimulus with memory
and past experience and ongoing
stimuli of other nature.
3. Evaluation of stimulus in light of
ongoing experience I call them
perception, cognition, and valuation.
We can like something today and not
like the same tomorrow even though
the program and the stimulus are
essentially identical in both cases. The
perception was unchanged, but cogni-
tion and evaluation were altered.
Pre-emphasis
The signal-to-noise ratio can be improved by using
high-frequency pre-emphasis. The choice of the
pre-emphasis characteristic must be made with care.
The curve for pre-emphasis is designed making
assumptions about the program content spectrum.
Dither
At low levels, only a small number of states are
available. This can lead to audible distortion such as
the decay of a piano note. It has been found that
adding a small amount of random noise significantly
improves the perceived quality. This noise “dithers”
the LSB and can be regarded as the digital equiva-
lent of bias in magnetic recording.
Aliasing
It is important that the sampling process is protected
from out-of-band frequencies. It was in the design of
antialiasing filters in the early days of digital audio
that artifacts became audible to the listener.
Over-sampling
A common technique to reduce the burden on the
filters is over sampling. By reading the data two,
four, or eight times, the spurious frequencies are
raised one, two, or four octaves; therefore, need less
severe filters to attenuate them to insignificant
proportions.
Bit rate reduction
Bit reduction allows more audio to be processed in a
given time. Halving the audio bit rate on the hard
disk system can double the number of audio signals
that can be simultaneously output from it. This is
done for economic reasons.
5.2.3 Frequency Dependent Case
Where the additive noise is not white or that the
signal-to-noise is not constant with frequency over
the bandwidth, the following equation can be used
by treating a series of channels as narrow, indepen-
dent Gaussian channels in parallel.
(5-9)
where,
C is channel capacity in bits per second,
C
log2
0
W
∫
⎝
⎠
⎜
⎟
⎜
⎟
⎛
⎞
1
S f( )
N f( )
----------
+
⎝
⎠
⎛
⎞df
=

40
Chapter 5
W is the bandwidth of the channel in Hz,
S (f) is the signal power spectrum,
N (f) is the noise power spectrum,
f is the frequency in Hz.
These equations can be used to demonstrate how
spread spectrum communication systems make it
possible to transmit signals which are actually much
weaker than the background noise level.
There are three predominant types of noise;
1.
White—equal energy per hertz.
2.
Pink—equal energy per octave.
3.
Black—silence.
Errors in digital transmission are considered as
noise, as well as the naturally occurring thermal
noise, and the effects of radio frequency interference
(RFI). Relations between bandwidth and time
similar to the one found by Nyquist was discovered
simultaneously by Karl Kupfmuller in Germany.
And even more stringent analysis of the relation was
carried out in Gabor’s, Theory of Communication.
As was pointed out by Tuller (1949), a funda-
mental deficiency of the theories of Nyquist,
Hartley, Kupfmuller and Gabor, was that their
formulae did not include noise. The role of noise is
that it sets a fundamental limit to the number of
levels that can be reliably distinguished by a
receiver. Each of these scientist-engineers had
worked with the fundamentals of noise and had
fundamental papers that included the earliest
measurements and mathematical derivations, rela-
tive to noise, but chose to treat the analysis of a
communications channel as noiseless. Claude
Shannon’s genius was to unite all these disparate
theories into one.
5.2.4 A Stochastic Process
A system which produces a sequence of symbols
(letters of the alphabet or musical notes) according
to certain probabilities is called a stochastic process,
and the special case of a stochastic process in which
the probabilities depend on the previous events, is
called a Markov process or a Markov chain. Of the
Markov processes which might conceivably
generate messages, there is a special class which is
of primary importance for communication theory,
these being what are called ergodic processes.
An ergodic process is one which produces a
sequence of symbols which would be a poll taker’s
dream, because any reasonably large sample tends
to be representative of the sequence as a whole. A
truly reverberant auditorium is an excellent example
of an ergodic process, in as much as, any one point
of measurement would give the same result as any
other point of measurement.
The world is full of non-Markov processes. A
Markov process is one in which the future depends
only on the conditions in the past. If your awareness
of something is changed irrevocably by the intro-
duction of some new piece of knowledge, then the
altered awareness is non-Markovian.
In discussing the signal delay between a
low-frequency driver and a high-frequency driver
with a world-renowned psychoacoustic authority
who had stated that 3 ms was inaudible, I asked had
he walked the polar pattern. The lesson was
non-Markovian as the polar response had been
altered by the seemingly innocuous signal delay,
while the amplitude etc. had not. Audio, acoustic,
and digital measurement systems are helpless when-
ever nonlinear phenomenon is present. All our
measurement systems are Markovian inasmuch as
we expect the input to predict the output. All our
measurement systems are dependent upon linear
equations. This is not to imply that they are useless
because the skilled and experienced operator can
often read ambiguous data.
As a guide to a new listening experience,
Dr. John Diamond’s detection of serious flaws in the
early CDs did lead to correction of the antialiasing
problems, but not, unfortunately, to his being prop-
erly acknowledged as having brought it to the
recording world’s attention other than as a
non-Markovian moment for many overconfident
engineers.
5.3 The Steps from Art to Science
Art usually precedes science, i.e. the musical scale
followed by the discovery of logarithms. Many of the
present-day entertainment systems—disco, rock
concerts, etc, satisfy listeners emotionally, and when
they do so it is wise to search amid the cacophony for
the psychoacoustic clues, if only for tolerance levels
of audiences. If this sounds facetious, remember the
FBI used rock music at high levels to attempt to
disorient the victims at Waco, and L Rad systems
have been employed to repel pirates. The delight with
which engineers embrace digital audio is remarkable
in as much as the foreseeable future dictates
computers more than likely making them obsolete.
Prior to Shannon’s Theory, bandwidth, signal
power, and modulation types were well-established,
but the word “bit” was seen in print for the first time
in his paper. From 1948 to the present time the
hyperbolic growth of digital communication has

Digital Theory
41
literally exploded to the point where it is feared,
politicized, and omnipresent. Our TV, internet,
computers, cell phones, motion pictures, and yes,
even audio are the outcome of Shannon’s
Information Theory.
Thomas K. Landauer worked at Bell Communi-
cations Research and used the concept of viewing
human memory as a novel telephone line that
carried information from the past to the future. He
came to the conclusion by actual measurements, that
human beings remember very nearly 2 bits per
second under all experimental conditions—visual,
verbal, musical—two bits per second. Landauer’s
numbers are unusual due to their small size. Von
Neumann’s early estimate had been many orders of
magnitude higher because of the brain’s 1015
capacity. Landauer’s estimate taken literally would
suggest lifetime memory storage of 109 bits.
There are other ways to look at the brain. There
are roughly 1050 synapses operating at about 1010
pulses per second giving an estimated 1016 synapses
operations per second. The total energy consump-
tion of the brain is about 25 W. The computation
thinking part uses about 10 W—the remainder
controls the pumps, etc. The MIPW of the brain has
to give AI researchers pause. In the attempt to digi-
tally automate mankind, the theoretical limits are
fundamentals, like the speed of light and Planck’s
constant. In the meantime mankind’s demagogues,
aided substantially by TV and sound systems may
bring civilization as we know it to an end. Hitler’s
giant rallies, Third World mob scenes, all required
powerful sound systems as do more subtle
corrupters of freedom and liberty. As you study
these very simple equations and their vocabulary
perhaps you'll be among the numbers that see the
concept that will supersede them if proper progress
is to continue. In any case, the simplicity that under-
lies the hardware of digital brings forth the
complexity of future software to control it.
Information is ultimately constrained by the
fundamental laws of physics. It should not therefore
be surprising that physics and information share a
rich interface. Richard Feynman’s lecture in 1959,
where he discusses storing and manipulating infor-
mation on the atomic level, has now been brought to
pass. In 2006, IBM announced a circuitry on a
30nm scale which indeed makes it possible to write
the Encyclopedia Britannica on the head of a pin.
Ironically Feynman’s speculative remark in 1959 is
now just a marker of the current scale of computa-
tion. To make it clear how close this is to the atomic
scale, a square with sides of length 30 nm contains
about 1000 atoms.
5.4 Moravec’s Warning
Moravec has warned us of the consequences of the
digital age:
Advancing computer performance is
like water slowly flooding the land-
scape. Half-century ago it began to
drown the low lands, driving out human
calculators and record clerks, but
leaving most of us dry. Now the flood
has reached the foothills, and our
outposts there are contemplating
retreat. We feel safe on our peaks, but at
the present rate, those too will be
submerged within another half-century.
He proposed that we build an ark. For
now, though, we must rely on our repre-
sentatives in the low lands to tell us
what the water is really like.
Summarizing
Information is always conserved. If this were not
true, it would violate energy conservation and the
temperature of the universe would’ve risen to
1031 degrees in a fraction of a second. Physicists
have found that “black holes” have event horizons.
Simply put, the black hole horizon, by some mecha-
nism, stores all the in-falling information. The
entropy of a black hole, its area, and the in-falling
information are correlated, Fig. 5-1. 
There is thermodynamic entropy. It measures the
number of different microscopic configurations that
a system can be in. Shannon entropy is a measure of
the information contained in a message. Thermody-
namic entropy is measured in units of energy
divided by temperature, whereas Shannon entropy is
measured in bits. There exists a correlation between
entropy and information–entropy is hidden informa-
tion i.e. it is the Information in the hidden details of
the system. The difference between information
storage and information communication is only a
difference in one’s inertial frame of reference.
Communication from point A to point B is ulti-
mately just bit transportation i.e. (a form of storage)
but in a state of relative motion. Likewise storage is
just communication across zero distance (but
through time).
“Coding High Quality Digital Audio” by
J. Robert Stuart relates Shannon’s formula to digital
coding practices, Fig. 5-4. In another paper; “The
Physics of Information” by F. Alexander Bais and
J. Doyne Farmer, we find:

42
Chapter 5
The theory of thermodynamics taken
by itself does not connect entropy with
information. This only comes about
when the results are interpreted in terms
of a microscopic theory, in which case
temperature can be interpreted as being
related to uncertainty and incoherence
in the position of particles.
The role of quantum theory in the relationship of
information and entropy is properly explored in this
paper.
What originally triggered my renewed interest in
“Information Theory” back in 2008 was reading
Prof. Chris Bissell’s writings on Karl Kupfmuller:
If today, we recognize information
along with energy and matter as a third
fundamental building block of the world.
I was left with the challenge to my thinking to
bring information into a meaningful relationship with
physics. This is being done today using Planck
values and quantum mechanics.
The physical dimensions of one bit are:
1.
One Nat of information has the area of a square
exactly two Planck lengths on a side.
2.
One Nat equals 0.693 bits.
3.
One Planck length equals
(5-10)
where,
G is the gravitational constant,
 is the reduced Planck constant, 
C is the speed of light.
4.
Planck area equals:
(5-11)
(5-12)
(5-13)
5.
 
 is the length of
one side of the bit square.
6.
 is the
length of one side of the Nat square.
7.
8.
bits per Nat.
The physical dimensions of one bit provide an
insight into the use of the bit in physics. That such
dimensions seem unimaginable today reminds us that
less than a decade ago nanotechnology provided the
same challenges. Frank Wilczek of MIT has written:
The wave patterns that describe
protons, neutrons, and their relatives
resemble the vibration patterns of
musical instruments. In fact the mathe-
matical equations that govern these
superficially very different realms are
quite similar.
Some physicists today have described reality as
“It’s from bits.” Where Newtonians saw the universe
as some form of giant mechanism, and early
computer enthusiasts saw the universe as a form of
giant computer, it is increasingly viewed as some
form of Information. The singularity problem
provides interesting reading where those who are
sharing deep thinking about the role of information
in our lives describe the undesirable possibilities of
artificial intelligences governing man.
5.5 Digital Nomenclature
Table 5-1 is a list of the most popular nomenclatures
used in digital circuitry
LP
h
G
×
C
-------------
=
1.616252 81
(
)
10 35
–
 m
×
=
h
h
h
2π
------
⎝
⎠
⎛
⎞
=
LP
2
h
G
×
C
-------------
=
2.61223
10 70
–
m2
×
 
=
1.0 Nat
2
LP
×
(
)2
=
1.044909 2.61223
(
)
10 69
–
m2
×
 
=
1.0 bit
1.0 Nat
ln 2
------------------
=
1.507485 2.61223
(
)
10 69
–
m2
×
 
=
Table 5-1. Digital Nomenclature
Bit
binary digit
Nibble
4 bits
Byte
8 bits
Word
16 bits
Double word
32 bits
Quad word
64 bits
Binary
base 2, log2
Octal
base 8, log8
Denary
base 10, log10
1 bit
3.88263
10 35
–
m
×
=
1 Nat
3.232506 3.88263
(
)
10 35
–
m
×
=
bitPl
NatPl
-------------
1.201122
2Pl
×
=
2.402244  Pl 
=
2.4Pl
(
)2
2Pl
2
--------------------
0.693
=

Digital Theory
43
5.6 What Is a Bit of Data?
The transmission of communications
signals is accomplished by means of a
transmission of energy, generally of
electromagnetic or of acoustic energy.
In contrast to the case of power trans-
mission, it is not energy itself which is of
interest, but rather the changes in this
energy in the course of time. The more
complicated the function which repre-
sents, as a function of time, the change
in voltage, current, pressure, or any
other carrier, the greater is the amount
of information carried by the trans-
mitted energy.(J. Ville)
Communications theory has up to
now developed mainly on mathematical
lines, taking for granted the physical
significance of the quantities which
figure in this formalism. But communi-
cation is the transmission of physical
effects from one system to another,
hence communication theory should be
considered as a branch of physics. Thus
it is necessary to embody in its founda-
tions such fundamental physical data as
a quantum of action, and the discrete-
ness of electrical charges. This is not
only of theoretical interest. With the
progress of electrical communications
toward higher and higher frequencies
we are approaching a region in which
quantum effects become all-important.
Nor must one forget that vision, one of
the most important paths of communica-
tion, is based essentially on quantum
effects. (D. Gabor)
Reading from the book The Mathematical
Theory of Communication by Claude E Shannon:
If the number of messages in the set
is finite then this number or any mono-
tonic function of this number can be
regarded as a measure of the informa-
tion produced when one messages
chosen is from the set, all choices being
equally likely. As was pointed out by
Hartley the most natural choice is the
logarithmic function. Although this defi-
nition must be generalized considerably
when we consider the influence of the
statistics of the message and when we
have a continuous range of messages,
we will in all cases use an essentially
logarithmic measure.
The logarithmic measure is more convenient for
various reasons:
1.
It is practically more useful. Parameters of engi-
neering importance such as time, bandwidth,
number of relays, etc., tend to vary linearly with
the logarithm of the number of possibilities. For
example, adding one relay to a group doubles the
number of possible states of the relays. It adds 1
to the base 2 logarithm of this number. Doubling
Hexadecimal
base 16, log16
MSB
most significant bit
LSB
least significant bit
Bit rate
bits × sampling frequency × channels
SNR
signal-to-noise ratio, 10 × log10 (6 × (2(b − 2))
FLOP
floating point operations per second
MIPS
million instructions per second
MIPW
million instructions per watt
RISC
reduced instruction set computer
WAV
wave format
BWF
broadcast wave format
CPU
central processing unit
GPU
graphics processing unit
PCM
pulse code modulation
PDF
portable document format
ASCII
American Standard Code for Information 
Interchanges
CD
compact disc
DVD
digital versatile disc
MPEG
motion picture experts group
ISO
International Organization for Standardization
AAC
advanced audio coding
MDCT
modified discrete cosine transform
TNS
temporal noise shaping
HDTV
high-definition television
VBR
variable bit rate
CBR
constant bit rate
Codec
compressor/decompressor
IO
input – output
Fs
sampling frequency
V ⁄ 2bits
Quantization level
DSP
digital signal processor
ADC
analog to digital converter
DAC
digital to analog converter
ERB
equivalent rectangular bandwidth
HTML
 hypertext markup language
BAUD
a rate defined as Xbaud × Y bits ⁄ baud = 
Z bits/s. (Baud is changes of state/s) Named 
after French engineer Jean Maurice Emile 
Baudot.
Table 5-1.  (cont.) Digital Nomenclature

44
Chapter 5
the time roughly squares the number of possible
messages, or doubles the logarithm, etc.
2.
It is nearer to our intuitive feeling as to the
proper measure. This is closely related to (1)
above, since we intuitively measure entities by a
linear comparison with the common standards.
One feels, for example, that two punch cards
should have twice the capacity of one for infor-
mation storage, and two identical channels twice
the capacity of one for transmitting information.
3.
It is mathematically more suitable. Many of the
limiting operations are simple in terms of the
logarithm but would require clumsy restatement
in terms of the number of possibilities.
The choice of a logarithmic base corresponds to
the choice of a unit for measuring information. If the
base 2 is used, the resulting units may be called
binary digits, or more briefly bits, a word suggested
by J. W. Tukey. A device with two stable positions,
such as a relay or a flip-flop circuit can store one bit
of information. N such devices can store N bits, since
the total number of possible states is 2N and log22N =
N. If the base 10 is used the units may be called
decimal digits. Fig. 5-6 gives the definition of binary.
Since 
, a
decimal digit is about 31⁄3bits. A digital wheel on a
desk computing machine has ten stable positions
and therefore has a storage capacity of one decimal
digit. In analytical work where integration and
differentiation are involved, the base e is sometimes
useful. The resulting units of information will be
called natural units (Nats). Change from the base a
to base b merely requires multiplication by logba.
Mathematically the number of bits is defined by:
(5-14)
and
2Bits = P
(5-15)
where,
P is the number of possibilities.
5.6.1 The Physical Dimensions of One Bit
One Nat of information has the area of a square
exactly two Planck lengths on a side.
One Nat equals 0.693 bits,
One Planck length equals
(5-16)
where,
G is the gravitational constant,
 is the reduced Planck constant, where 
C is the speed of light.
Planck area equals
(5-17)
(5-18)
(5-19)
M
log10N log102
3.32log10N
=
⁄
=
log2P
Bits
=
LP
h
G
×
C
-------------
=
1.616252 81
(
)
10 35
–
 m
×
=
Figure 5-6. Binary choices.
A. Mathematically:
 The simplest numbering scheme possible, there are 
only two symbols:
 
 
1 and 0
B. Logically:
 A system of thought in which there are only two 
states:
 
 
True and False
C. Binary information is not subject to misinterpretation:
 
 
Black   White
 
 
In   Out
 
 
Guilty   Innocent
D. Variables or non-binary terms:
 
Somewhat  
Undecided
 
Probably  
Not proven
 
Grey  
Under par
+ + + + +
− − − − −
S - N
Control
Transmission
High/Low voltage
Optical
Light/Dark
Mechanical
Presence/ Absence
Magnetic
Polarity
Radio
Carrier On/Off
Electrostatic
Charged/Discharged
1
0
N - S
h
h
h
2π
------
⎝
⎠
⎛
⎞
=
LP
2
h
G
×
C
-------------
=
2.61223
10 70
–
m2
×
 
=
1.0 Nat
2
LP
×
(
)2
=
1.044909 2.61223
(
)
10 69
–
m2
×
 
=
1.0 bit
1.0 Nat
ln 2
------------------
=
1.507485 2.61223
(
)
10 69
–
m2
×
 
=

Digital Theory
45
 
 the length of one side
of the bit square
 the length 
of one side of the Nat square
(5-20)
(5-21)
bits per Nat.
(5-22)
5.6.2 Reading Binary Numbers
Table 5-2, Binary to Decimal to Hexadecimal to
Octal allows you to see the essential simplicity of
binary coding. Pick any decimal number and see
how the 1s add up on the exponential scales at the
top of the chart. For example the decimal number 27
in binary is found to be 16+8+2+1 =27. The hexa-
decimal number 1B is in the second rotation through
the hexadecimal encoding, and octal number 33 is in
the third rotation for octal encoding, see Table 5-2.
Fortunately today many scientific calculators
include easy conversions from decimal to octal to
hexadecimal to binary code. Children can bring this
kind of coding home from school for your help in
solving their problems in high school mathematics
classes. Cryptography is replete with many system
bases including the Ban that was used in World War
II by the English code breakers, see Fig. 5-7
defining Bits, Nats, and Bans. Digital test equipment
is expensive can be complex and requires training in
its use. We increasingly see requirements in specifi-
cations demanding certification of the engineers
setting these systems into operation.
1 bit
3.88263
10 35
–
m
×
=
1 Nat
3.232506 3.88263
(
)
10 35
–
m
×
=
bitPl
NatPl
-------------
1.201122
2Pl
×
=
2.402244 Pl 
=
2.4Pl
(
)2
2Pl
2
--------------------
0.693
=
Table 5-2. Binary to Decimal to Hexadecimal to Octal
Binary
MSB
LSB
25 (32)
24 (16)
23 (8)
22 (4)
21 (2)
20 (1)
Decimal
Hex
Octal
0
0
0
0
0
0
0
0
0
0
0
0
0
0
1
1
1
1
0
0
0
0
1
0
2
2
2
0
0
0
0
1
1
3
3
3
0
0
0
1
0
0
4
4
4
0
0
0
1
0
1
5
5
5
0
0
0
1
1
0
6
6
6
0
0
0
1
1
1
7
7
7
0
0
1
0
0
0
8
8
10
0
0
1
0
0
1
9
9
11
0
0
1
0
1
0
10
A
12
0
0
1
0
1
1
11
B
13 
0
0
1
1
0
0
12
C
14
0
0
1
1
0
1
13
D
15
0
0
1
1
1
0
14
E
16
0
0
1
1
1
1
15
F
17
0
1
0
0
0
0
16
10
20
0
1
0
0
0
1
17
11
21 
0
1
0
0
1
0
18
12
22
0
1
0
0
1
1
19
13
23
0
1
0
1
0
0
20
14
24
0
1
0
1
0
1
21
15
25
0
1
0
1
1
0
22
16
26
0
1
0
1
1
1
23
17
27
0
1
1
0
0
0
24
18
30

46
Chapter 5
5.6.3 Text into Binary, Octal, Hexadecimal
ASCII printable characters
Codes 32–127 are common for all the different vari-
ations of the ASCII table; they are called printable
characters and represent letters, digits, punctuation
marks, and a few miscellaneous symbols. ASCII
control characters number from 0–31 and are
unprintable control codes that are used to control
peripherals such as printers, Table 5-3.
The ASCII code of a character is found by
combining its Column Number (given in 3-bit
binary)  with its Row Number (given in 4-bit
binary).
The Column Number forms bits 6, 5 and 4 of the
ASCII, and the Row Number forms bits 3, 2, 1  and
0 of the ASCII.
Example of use: to get ASCII code for letter “n”,
locate it in Column 110, Row 1110. Hence its
ASCII code is 1101110.
The Control Code  mnemonics are given in
italics above; e.g. CR  for Carriage Return, LF  for
Line Feed, BELL  for the Bell, DEL  for Delete. The
Space is ASCII 0100000, and is shown as ◊  here.
To write Don Davis in binary, octal, and hexadec-
imal, refer to Table 5-3.
The text, Don Davis, in binary code is
01000100 01101111 01101110 00100000 01000100
01100001 01110110 01101001 01110011.
The text, Don Davis, in octal code is
104 157 156 040 104 141 166 151 163.
The text, Don Davis, in hexadecimal code is
44 6f 6e 20 44 61 76 69 73.
The binary code is called “machine language”
inasmuch as it is the code the computer understands.
The compactness that base 8 and base 16 offers over
base 2 for use in program editors that then convert
these more compact codes into machine language is
apparent.
Sound System Engineering in binary code is
01010011 01101111 01110101 01101110 01100100
00100000 01010011 01111001 01110011 01110100
01100101 01101101 00100000 01000101 01101110
01100111 01101001 01101110 01100101 01100101
01110010 01101001 01101110 01100111.
In octal code is
123 157 165 156 144 040 123 171 163 164 145 155
040 105 156 147 151 156 145 145 162 151 156 147.
In hexadecimal code is
53 6f 75 6e 64 20 53 79 73 74 65 6d 20 45 6e 67 69
6e 65 65 72 69 6e 67.
0
1
1
0
0
1
25
19
31
0
1
1
0
1
0
26
1A
32
0
1
1
0
1
1
27
1B
33
0
1
1
1
0
0
28
1C
34
0
1
1
1
0
1
29
1D
35
0
1
1
1
1
0
30
1E
36
0
1
1
1
1
1
31
1F
37
0
1
0
0
0
0
0
32
20
40
MSB most significant bit
LSB least significant bit
Table 5-2.  (cont.) Binary to Decimal to Hexadecimal to Octal
Table 5-3. ASCII Code
Row 
Number
Column Number
000
001
010
011
100
101
110
111
0000
NUL
DLE
à
0
@
P
`
p
0001
SOH
DC1
!
1
A
Q
a
q
0010
STX
DC2
"
2
B
R
b
r
0011
ETX
DC3
#
3
C
S
c
s
0100
EOT
DC4
$
4
D
T
d
t
0101
ENQ
NAK
%
5
E
U
e
u
0110
ACK
SYN
&
6
F
V
f
v
0111
BELL
ETB
'
7
G
W
g
w
1000
BS
CAN
(
8
H
X
h
x
1001
HT
EM
)
9
I
Y
i
y
1010
LF
SUB
0
:
J
Z
j
z
1011
VT
ESC
0
;
K
[
k
{
1100
FF
FS
,
<
L
\
l
|
1101
CR
GS
-
=
M
]
m
}
1110
SO
RS
.
>
N
^
n
~
1111
SI
US
/
?
O
_
o
DEL
Table 5-3.  (cont.) ASCII Code

Digital Theory
47
5.7 Bayesian Theory
Bayesian probability theory is sometimes called
“common sense, amplified.” The rules of probability
insure that if two people make the same assumptions
and receive the same data, then they will draw iden-
tical conclusions. This more general use of proba-
bility to quantify beliefs is known as the Bayesian
viewpoint. It is also known as the subjective inter-
pretation of probability since the probabilities
depend on assumptions. Advocates of a Bayesian
approach to data modeling and pattern recognition
do not view this subjectivity as a defect, since in
their view you cannot do inference without making
assumptions.
Laplace, a contemporary of the Reverand
Thomas Bayes, gave the first mathematical interpre-
tation of this theory, followed by its being ignored
for the next century. In Laplace’s interpretation,
probability theory is just common sense reduced to
numbers, and a probability represents a reasonable
degree of belief; not a frequency of occurrence. In
the mid-1930s Sir Harold Jeffreys rediscovered the
works of Laplace and derived probability theory as
an axiomatic theory of inference. E. T. Jaynes, using
the methodology of Shannon, the mathematics of
Abel, Cox, and the qualitative principles of Laplace,
proved that if one represents a reasonable degree of
belief as a real number, then the only consistent
rules for manipulating probabilities are those given
by Laplace. In this wider interpretation of proba-
bility theory, called Bayesian probability theory,
problems of the form, “what is the best estimate of a
parameter one can make from the data and one’s
prior information” make perfect sense.
Thomas Bayes lived in exciting times, the
contemporary of Newton, Berkeley, Laplace,
Maclaurin, etc., was a Fellow of the Royal Society.
Probability theory as extended logic reproduces
many aspects of human mental activity, sometimes
in surprising and even disturbing detail. Equations
have been found examining the phenomenon of a
person who tells the truth and is not believed, even
though the disbelievers are reasoning consistently.
The theory explains why and under what circum-
stances this will happen. (I have been the victim of
this when the listener heard the facts, but lacked the
experience to evaluate facts.)
Jaynes goes on to say:
The equations also reproduce a more
complicated phenomenon, divergence of
opinions. One might expect that open
discussion of public issues would tend to
bring about a general consensus. On the
contrary, we observe repeatedly that
when some controversial issue has been
discussed vigorously for a few years,
society becomes polarized into two
opposite extreme camps; it is almost
impossible to find anyone who retains a
moderate view.
Probability theory as logic shows how two
persons given the same information, may have their
opinion driven in opposite directions by it, and what
must be done to avoid this.
In such respects, it is clear that probability theory
is telling us something about the way our own minds
operate when we form intuitive judgments, of which
we may not have been consciously aware. Some
may feel uncomfortable at these revelations; others
may see in them useful tools for psychological,
sociological, legal research or artificial intelligence.
It is believed that Sir Harold Jeffreys influenced
Alan Turing’s work in breaking the enigma code.
Jeffreys’s book The Theory of Probability, published
in 1939, would have been accessible to Turing.
Since both men were connected to Cambridge
University the likelihood that they would have
conferred is high.
5.8 Planck System
John Archibald Wheeler (1912 to 2008) was the
physicist who developed the system described here,
inspired by a similar system by Max Planck.
Planck units represent the smallest possible mass,
length, and time possible in our present universe.
Some theorists are more willing to speculate than
others. But even the boldest acknowledge the
“Planck scales” as an ultimate barrier. We cannot
measure distances smaller than the Planck length;
we cannot distinguish two events, or decide which
came first, when the time interval between them is
less than the Planck time. These scales are smaller
than atoms by just as much as atoms are smaller
than stars. There is no prospect of any direct
measurement in this domain. It would require parti-
cles with energies million, billion times higher than
can be produced in the laboratory.
From a practical standpoint, much of the conve-
nience of using Planck units, comes from the fact
that the values of the main natural constants, G,
H-bar, c, are one when expressed in terms of natural
units. To some extent this convenience carries over
to several human scale Planck systems in which the
natural units have been scaled by powers of ten to
make them handier to use.
1.
Planck mass 2.1767 × 10–8 kilogram.

48
Chapter 5
2.
Planck length 1.6160 × 10–35 meter.
3.
Planck time 5.3906 × 10–44 second.
4.
Planck frequency is 1045 per minute, because it
is defined as passing through one radian of
phase in each Planck interval of time. As a result
the Planck frequency is 1040 higher than middle
D on the piano.
Planck constant is considered as the fundamental
constant of nature.
(5-23)
The reduced Planck constant called h-bar is:
(5-24)
If, as John Wheeler felt, the universe is “it’s from
bits,” then these parameters are of vital importance.
5.9 Bits, Nats, and Bans
Bits are to the logarithmic base (2), Nats are to the
logarithmic base (e), and Bans are to the logarithmic
base (10). Bits are used in information work, Nats in
physics and Bans have been used in code breaking.
In physics, one Nat has an area of two Planck
lengths on a side.
The relationship between Bits, Nats, and Bans is
shown in Fig. 5-6.
5.10 A Communication System
Any communication system (acoustic, audio, visual,
data, etc.) will consist of a source, message, trans-
mitter, signal path (with the possibility of interfering
noise joining the desired signal), a received signal, a
receiver, a message, and a destination, Fig. 5-8.
In a sound reinforcement system, the source will
be human (talker, artisan, orchestra, etc.) the
message will pass through a transducer into elec-
tronics and become an electrical signal. Undesired
noise may enter the system from the original
acoustic environment or from the electronic path
followed. The received signal will again pass
through a transducer, i.e., a loudspeaker system or
headphones. The message received will then be
understood, distorted, or misunderstood.
Our ability to test the system’s performance with
precision starts at the input transducer and ends at
the output transducer. The performer’s input and the
listener’s perception are parameters not readily
quantified. Speech intelligibility estimates and
speech intelligibility tests of a sufficiently large
group of listeners, in the case of talkers, are costly
and difficult.
An example of the above was the communication
system employed at an airbase in a foreign country
to alert personnel to danger. The most expected form
of attack was thought to be from the air. The output
transducer was a siren. When an unexpected attack
occurred, on the ground, by guerrilla warriors, the
siren was sounded, but resulted in the wrong actions
by the personnel involved on the base.
The system was later replaced by a very
high-powered voice system which could issue
explicit instructions. Many fire alarm systems share
the same problem, such as a large hotel where the
fire began in the sound system’s central amplifier
room, chosen for economic reasons, over a floor-
by–floor distributed system. Many survivors could
have been saved by a helicopter that landed on the
roof, but there was no way to tell the victims to go
up to the roof, rather than down the fire stairs.
We hear with regularity the failure of rigging
systems installed by unqualified personnel. Over-
head canopies collapsing, suspended loudspeaker
arrays falling, collapse of staging etc., are often the
result of not including all the required professional
input at the design stage of a public venue.
Figure 5-7. Bits, Nats, and Bans.
h
6.6262
10 27
–
erg s
×
=
6.6262
10 34
–
J s
×
=
h 2π
⁄
Conversion of Bits, Nats, and Bans
bits = 1 
nats = ln(2)  (bits) 
bans = bits / log210
nats = 0.693 bits 
bans = 0.301 bits
nats = 1
bits = nats / ln2 
bans = nats / ln10
bits = 1.443 nats 
bans = 0.434 nats
bans = 1
bits = log210 × (bans) 
nats = ln10 × (bans)
bits = 3.322 bans 
nats = 2.303 bans
Figure 5-8. A general communications system. (Cred-
ited to Claude Shannon.)
Information
Source
Message
Signal
Noise
Source
Receiver
Destination
Message
Received
Signal
Transmitter

Digital Theory
49
All of the above are examples of failure at the
design stage to articulate the needs in a language
that the architect, engineers, and owners can under-
stand and comprehend. That is the initial communi-
cation problem.
5.11 Holography*
Holography was invented in 1947 with the advance-
ment of laser technology. It is a photographic
process which does not capture an image of the
object being photographed, as in the case with the
conventional technique, but rather records the
phases and amplitudes of light waves reflected from
the object. The wave amplitudes are readily encoded
on an ordinary photographic film. The phases are
recorded as interference patterns produced by the
reflected light and a reference coherent light (from
the same laser.) Each point on the hologram
received light reflected from every part of the illu-
minated object, and therefore, contains the complete
visual record of the object as a whole. When the
hologram obtained from the development of a film
exposed in this way is placed in a beam of coherent
light, two sets of strong diffracted waves are
produced—each an exact replica of the original
signal bearing waves that impinged on the plate
when the hologram was made. One set of diffracted
waves produces a virtual image, which can be seen
by looking through the hologram. It appears in a
complete three-dimensional form with highly real-
istic perspective affects. In fact, the reconstructed
picture has all the visual properties of the original
object.
The holographic and universal information
bounds are far beyond the data storage capacities of
any current technology and they greatly exceed the
density of information on chromosomes and the
thermodynamic entropy of water. The maximum
allowable information on the surface area can be
interpreted as the maximum allowable number of
smallish units on each surface. This smallest unit
has the size of Planck area as envisioned in quantum
theory. According to this theory, the Planck area is a
single quantum of space time—it cannot get any
smaller than that.
Bibliography
F. A. Bais and J. D. Farmer, The Physics of Information, Cornell University Library.
C. E. Shannon, “The Mathematical Theory of Communication,” Bell System Technical Journal.
J. R. Stuart, Coding High Quality Digital Audio.
J. R. Stuart, The Psychoacoustics of Multichannel Audio, Meridian Audio Lts, Stonehill, Huntingdon,
E18 6ED, England.
* From Universe Review


Chapter 6
Mathematics for Audio Systems
by Don Davis and Eugene Patronis, Jr.
51
6.1 Engineering Calculations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53
6.2 Precision, Accuracy, and Resolution  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54
6.3 Simple Numbers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54
6.4 How to Add Gains and Losses Algebraically  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 54
6.5 The Factor-Label System . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55
Developing a Conversion Factor . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55
The Foot Pound System . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 56
Non-SI Audio Terms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 56
Generating US Dimensions from SI Dimensions  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 57
Simplified SI to US and US to SI Conversions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 57
6.6 Basic Physical Terms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 58
Conversion Factors from Base Units . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59
6.7 Mathematical Operations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 60
Addition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 60
Subtraction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 60
Multiplication  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 60
Division . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 60
Powers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 60
Roots  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 60
Logarithms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 60
Antilogs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 61
Log Multipliers  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 61
Antilogs of Multiplied Logarithms  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 61
Comparing Arithmetic and Exponential Notation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 61
Comparing Arithmetic, Exponential, and Logarithmic Forms  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62
6.8 Complex Number Operations  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 64
6.9 Decade Calibration . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 65
6.10 Converting Linear Scales to Logarithmic Scales . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 66
6.11 Finding the Renard Series for Fractional Octave Spacing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 66
Determining the Number of Octaves in a Given Bandwidth  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 67
6.12 Radians and Steradians  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 67
The Radian . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 67
Steradians (Solid Angles)  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 67
Symbols . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 68
Equations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 68
Complementary Angle for a Given Square Angle and a Desired Arbitrary Angle . . . . . . . . . . . . . . . . . 68
Finding Q for a Given Square Angle . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 69
Percentage of Spherical Surface Area Covered for a Given Q . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 69
6.13 Calculating Percentages and Ratios . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 70
Decibels and Percentages  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 71
Power Changes Downward . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 71
Power Changes Upward  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 71
Voltage Changes Downward . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 71
Voltage Changes Upward  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 71
Decibels for Percent Below Reference  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 72
Decibels for Percent Above Reference  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 72
6.14 Useful Math Tables  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 72
Scientific Metrology  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 73

52
6.15 Angles . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .75
6.16 A Little Trigonometry . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .75
6.17 The Origin of the Base of the Natural Logarithm, e . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .76
6.18 The Complex Plane . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .77
6.19 Euler’s Theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .77
6.20 Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .78
Addition of Complex Numbers. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .78
Subtraction of Complex Numbers. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .78
Products of Complex Numbers  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .78
Quotients of Complex Numbers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .78
A Little Digression . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .78
6.21 Phasors  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .79
Addition of Phasors  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .80
6.22 Rates of Change  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .80
Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .82

Mathematics for Audio Systems
53
6.1 Engineering Calculations
In my high school days (World War II), I had
learned to use simple slide rules. Later at the
University level log log duplex decitrig slide rules
were a constant companion. At Altec Lansing I used
an ancient book of ten place logarithms (Vega) and a
Friden mechanical calculator to compute K numbers
(the anti-logarithm of a decibel). As I became more
involved in acoustic calculations I purchased one of
the very first HP 9100s because of its ability to do
transcendental functions. This led in the late 1960s
to my being selected as one of the guinea pigs for
the HP 35 calculator and the opportunity to meet
Tom Osborne who had headed the project.
One of my favorite English movies directly after
World War II was The Man in the White Suit, about
an eccentric English inventor who worked his way
into large industrial laboratories in the attempt to
develop his invention. He would work without
charge just to be near the instrumentation that he
needed to do his work. In the early 1960s Tom
Osborne worked for SCM Corporation (Smith
Corona Marchant.)
In the fall of 1963, Osborne told them that he
could no longer help them produce a calculator that,
in his opinion, was doomed to failure (it was, and it
did). He offered to design a machine for them at no
cost if they would give him lab space. Later, if they
liked what they saw, they could pay him for the time
he had spent in the design and construction.
They did not take him up on his offer, but did get
excited about his having not given them the plans
for the calculator that he must have designed. It
seems that they couldn’t understand that Osborne
could confidently state that he could design a calcu-
lator without having already designed it. Much like
Mozart, when a client asked him where the score
was, Mozart replied, “It’s in my head.” Osborne and
SCM parted company at that point.
Later in that decade after having encountered
companies willing to steal his ideas or tie them up so
that they never became competitors to them, he
encountered Barney Oliver of Hewlett Packard and
a remarkable engineering staff capable of not only
implementing his ideas but capable of going with
him into new realms of technology. The HP 35 (so
called because it had thirty-five keys) destroyed
slide rules and changed engineering calculations
forever.
Bill Hewlett, when asked by the press if he
thought the HP 35 would be a success, said he didn't
know. When further asked how he justified the
expenditure for its creation, he replied that he wanted
one. Before it was introduced on the market, analysis
by a major consulting firm, had determined that it
would fail because of the tiny keys and the reverse
Polish notation, (RPN). In Tom Osborne’s opinion it
succeeded for those very reasons. The HP 35 was so
well received that overnight it made the slide rule a
relic. Every calculator designed into a computer
today came from those pioneer algorithms.
When I showed my HP 35 to Paul Klipsch he
asked for the 12th root of 2 (the semitone interval)
and with three key punches I showed him
1.0594630944. No more calculations were asked
for. Log, trig, square root, etc. tables were retired.
A side note—Hewlett Packard was willing to
consider having Altec distribute the HP 35 to the
electronic parts industry—Altec owned Allied
Radio at that point.  I discussed this possibility with
the president of Altec, who replied, “We are not in
the calculator business,” to which I replied, “Neither
was HP.”  It wasn’t long before I resigned at Altec
and started Synergetic Audio Concepts,
Syn-Aud-Con, to teach sound system design to
sound contractors.
To quote Richard Heyser:
Most of us think of mathematics as
those chicken tracks—little wiggle signs.
That isn’t math! That’s the fossil
remnants of a thought.
The thought is the math. The struc-
tured reasoning is the math. And when
you start taking things we refer to as
common sense and observation to
structure that in a reasoning mode—
that’s math.
The axioms and postulates of that
which most of us would call common
sense is math. When it’s dried up and
withered and appears as little chicken
tracks on a piece of paper, that isn’t
math! That’s just the residue of it, just
the shorthand that lets people know that
a mind went past here on this page.
Math is structured learning.
Mathematics and physics are the foundation
stones that underlie real competence in audio engi-
neering. The mathematical tool most used by audio
engineers in describing the physics of sound is the
decibel.
A knowledge of mathematics and physics is
essential to a realistic understanding of audio
engineering. The more background you have in
these two disciplines, the greater your ability will be
to look past the evidence of the senses to the facts of
science. James Moir once told us, “Anything
obvious in acoustics is usually wrong.” Therefore,
we encourage every reader of this book to seek out
as much experience in mathematics and physics as

54
Chapter 6
is available. This chapter, however, is designed not
to review the vast and fascinating horizons available
to the scholar but, rather, to outline the minimum
requirements that must be reached if you are to
know what’s going on in an audio system.
The basic tools you must have to understand
audio engineering are included in this chapter. With
these tools you can make an intelligent choice about
the specialized forms of mathematics you might
want to study next. We sincerely hope you will
study this chapter thoroughly before reading any
further inasmuch as the concepts derived here, the
terminology developed, and the statements of funda-
mentals are not repeated.
6.2 Precision, Accuracy, and Resolution
The term “precision” as used in audio engineering is
defined as: “The quality of being exactly or sharply
defined or stated…which is sometimes indicated by
the number of significant digits it contains.”
The term “accuracy” as used in audio
engineering usually refers to “accuracy rating,”
which is defined as: The accuracy classification of
the instrument. It is given as the limit, usually
expressed as a percentage of full-scale value, that
errors will not exceed when the instrument is used
under reference conditions.
“Resolution” as used in audio engineering is “the
act of deriving from a sound, scene, or other form of
intelligence a series of discrete elements where from
the original may subsequently be synthesized.”
You may, for example, have a calculator with a
precision to ten digits on which you calculate
frequency to a resolution of one-third of an octave
using an analyzer with an accuracy of 10%. In such
a circumstance, it makes no sense to read out a
frequency to ten places on the calculator. One-third
octave at 1000 Hz is 230 Hz; plus 10% would be
253Hz and minus 10% would be 207 Hz. Therefore,
you can say with some assurance when tuned to the
center of the band, “I’m within 50 Hz of the right
answer.”
6.3 Simple Numbers
When we use the digits 1, 2, 3, etc., we uncon-
sciously assume that:
1.
Numbers have magnitude—Two is larger than
one; three is larger than two, etc.
2.
Numbers have signs—If we wrote down our
assumption, we would write +1, +2, +3, etc.
3.
Numbers are ratios—We recognize this every
time we do a decibel problem: 1/1, 2/1, 3/1, etc.
4.
Numbers have exponents—We don’t always
indicate them, but we assume them. For
example, we could write 11, 21, 31, etc.
5.
Zero has no magnitude, ratio, exponent, or sign.
Zero is the symbol for the idea of nothingness. It
is the placeholder in large numbers.
6.
Any digit raised to the exponent of zero equals
unity—For example, 100, 1000, 10000 equal 1.
7.
Digits raised to positive number exponents
produce larger numbers: 
.
8.
Digits raised to fractional number exponents are
roots of numbers and produce smaller numbers:
.
9.
Digits raised to negative number exponents are
fractional numbers:
.
10. Numbers are reciprocals:
.
11. Numbers are roots:
.
When labels are added to numbers, they can no
longer be thought of as simple. Yet even in their
simple forms the meanings they have can easily be
overlooked by the casual observer. The preceding
list certainly does not exhaust the assumptions you
can make, but it does suggest how simple numbers
are perceived.
6.4 How to Add Gains and Losses 
Algebraically
The mathematical signs plus (+) and minus (−) are
directional indicators. Imagine a line with zero at its
center. Negative numbers proceed from zero to the
left and positive numbers proceed to the right of the
same zero point.
To sum the following gains and losses:
−148 + 100 + 47.5 + 48 + 56.5 − 10.5, the following
procedure is suggested:
Add all the negative numbers
−148.0
−10.5
−158.5
22
4
=
21 2
⁄
2
1.414…
=
=
2 2
–
1 4
⁄
 ,  2 1
⁄
(
) 2
–
0.25 1
⁄
(
)1
=
0.25
=
=
1
1 1
⁄
(
) ,   2
1 0.5
⁄
(
) ,   3
1 0.33
⁄
=
=
=
1
1 ,  2
4 ,  3
9
=
=
=

Mathematics for Audio Systems
55
Add all the positive numbers
Sum the two results:
This procedure is easy. Most systems exhibit
gain (positive numbers are the largest value). Where
a system exhibits loss (negative numbers are the
largest value).
To sum the following gains and losses:
−148 + 100 + 40 − 60 use the following procedure:
1.
Sum all of the negative numbers:
2.
Sum all of the positive numbers: 
3.
Determine whether the negative numbers are
larger in value than the positive numbers:
208 > 140.
4.
Change the signs of the negative to positive and
the positive to negative, and subtract the smaller
value from the larger value: 
5.
Reverse the sign of the answer—The reverse
sign of +68 is −68.
6.5 The Factor-Label System
The factor-label system is most useful. Factors are
numbers that represent quantities of something or a
measure of something on a measurement scale.
Labels are the actual units or titles used on our
measurement scale. When combined, a factor-label
results. Given 2 apples, “2” is the factor and
“apples” is the label, or 60°F, “60” is the position on
the measurement scale, and “F” is the label.
Careless use of labels has led to such statements
as “It’s a watt,” when what is meant is “It’s one
watt.” In this example, the factor is implied when
the label is used.
6.5.1 Developing a Conversion Factor
Suppose we had a statement that we are at a velocity
of 88 feet per second (88 ft/s). This can be written as:
where, 
“88” and “1.0” are factors,
“ft” and “s” are labels.
Velocity in miles per hour (mi/h), can be written as:
(6-1)
Change the labels by developing a conversion factor
as follows:
where,
,
.
Cancel labels to get the correct factor relation-
ship for the labels that remain:
so that 
To find the conversion factor, take the factors
employed to obtain the new labels as the conversion
factor (3600/5280 = 0.6818818…). The original
factor, (88), is not used to generate the conversion
factor because it is what we want to convert:
88 (0.681818…) = 60
+100.0
+47.5
+48.0
+56.5
+252.0
+252.0
−158.5
+93.5
−148
−60
−208
+100
+40
+140
+208
−140
+68
V
88 ft
1 s
-----------
=
V
x mi
1.0  h
-----------
=
x mi
1.0  h
-----------
88 ft
1.0 s
-----------
3600 s
1.0 h
---------------
×
1.0 mi
5280  ft
-----------------
×
=
3600  s
1.0 h
---------------
1
=
1.0  mi
5280  ft
-----------------
1
=
88 ft
1 s
3600 s
1 h
1.0 mi
5280 ft
×
×
88
(
) 3600
(
)
5280  h
----------------------------
60  mi
1.0 h
-------------
=

56
Chapter 6
We can now write in a table of conversion factors.
The reciprocal of 0.681818 or (1/0.681818) will
do the inverse (change mi/h to ft/s).
The orderliness of this technique, especially in
programming computers and calculators, recom-
mends its use by audio engineers.
In this book we have chosen to use those labels
most conveniently at hand without undue regard to
various labeling systems. The two principal labeling
systems in current use are:
1.
The United States system (US), formerly called
the English system.
2.
The Systeme International d’Unites (SI).
To our best knowledge, no country in the world
is exclusively on either system. Consequently, you
must know how to operate any system encountered
in the world of practical engineering.
6.5.2 The Foot Pound System
In parallel with the development of the CGS system
came what was seen as its Imperial equivalent, the
foot-pound-second system proposed by W. Stroud in
1880. It became very widely employed in all
branches of engineering, and most technical papers
written in Britain, the USA, and other parts of the
English-speaking world before about 1960 would
have used these units, although scientific papers
tended to use CGS units.
Its popularity in engineering was due not only to
the use of Imperial units as its base, but also because
the pound and the foot were felt to be more conve-
nient for engineers than the too-small centimeter and
gram, and the too-large meter and kilogram.
Although it was strictly speaking, a non-decimal
system, this was technically irrelevant since quanti-
ties could be expressed in decimals of feet, pounds,
etc., so that the criticism of complexity and calcula-
tions usually aimed at the Imperial system did not
necessarily apply.
Its main problem was that the pound had long
been in common use as a unit of both weight and
mass. This makes no difference in general and
commercial usage, since, because of the Earth’s
gravity, a mass of 1 pound weighs exactly 1 pound.
Because the moon’s gravitational force is about
one-sixth that of the Earth, the 1 pound mass would
weigh only one-sixth of a pound, although the mass
itself would not have changed. Weight, therefore, is
the force with which a mass is attracted by gravity,
and, since it is an entirely different quantity, it
requires a different unit.
However, because in general use the pound had
always been appreciated as a unit of weight, there
was a tendency among engineers to continue to use
it in this way. Therefore in the United States a
variant of the FPS system usually termed, technical,
gravitational, or engineer’s units, the pound-force
(lbf) was taken as a base unit, and the unit of mass
was derived from it. This unit was named the slug,
and was the mass which when acted upon by one
pound force experienced an acceleration of 1 ft ⁄ s2,
so it was equal to 32.17 pounds.
It is worth noting that there is nothing inherently
inconsistent in a system based on the foot and the
pound. Decimalized, with a single set of force and
mass units, and integrated with electrical and molar
quantities, it could've been just as consistent and
international as the metric-based SI.
There is a feeling among human beings that units
spaced on the human body are somehow more
comprehensible than those derived from the circum-
ference of the earth, or referred to the energy level
of an atom. Today’s engineers need to be thoroughly
conversant with any system that provides usefully
dimensioned units. A case in point, the use of
Planck units in information theory.
6.5.3 Non-SI Audio Terms
There is a vast list of units outside the accepted SI
(System International) list that may be used because
of their obvious utility. These are listed in a series of
addendum in the SI standards. Two key ones regard
digital terms and level terms:
1.
The dB is used rather than arithmetic ratios or
percentages because when circuits are connected
in tandem, expressions of power level, in dB,
may be arithmetically added and subtracted. For
example, in an optical link, if a known amount
of optical power in dBm is launched into a fiber,
and the losses, in dB, of each component (e.g.,
connectors, splices, and lengths of fiber) are
known, the overall link loss may be quickly
calculated with simple addition and subtraction.
2.
The neper is often used to express voltage and
current ratios, whereas the decibel is usually
used to express power ratios.
 The above notes are frequently ignored, but they
do represent notes in the SI standards. The now
prevalent use of voltage and current ratios expressed
To Find
Multiply 
By
MPH (mi/h)
ft/s
0.681818

Mathematics for Audio Systems
57
as levels in decibels and its carryover in some stan-
dards, in order to placate technicians, is in my
opinion, a mistake.
The digital situation is even messier than the
level situation as evidenced by the quotes below
written by Bruce Barrow for the IEEE. 
Once upon a time, computer profes-
sionals noticed that 210 was very nearly
equal to 1000 and started using the SI
prefix ‘kilo’ to mean 1024. That worked
well enough for a decade or two because
everybody who talked kilobytes knew
that the term implied 1024 bytes. But,
almost overnight a much more numerous
‘everybody’ bought computers, and the
trade computer professionals needed to
talk to physicists and engineers and even
to ordinary people, most of whom know
that a kilometer is 1000 m and a kilo-
gram is 1000 g.
Then data storage for gigabytes, and
even terabytes, became practical, and
the storage devices were not constructed
on binary trees, which meant that for
many practical purposes, binary arith-
metic was less convenient than decimal
arithmetic. The result is that today
‘everybody’ does not ‘know’ what a
megabyte is. When discussing computer
memory, most manufacturers use mega-
byte to mean 220 =1 048 576 bytes, but
the manufacturers of computer storage
devices usually use the term to mean 1
000 000 bytes. Some designers of local
area networks have used megabit per
second to mean 1 048 576 bits per
second, but all telecommunications engi-
neers use it to mean 10 6 bits per second.
And as if two definitions of the megabyte
are not enough, a third megabyte of
1 024 000 bytes is the megabyte used to
format the familiar 90 mm ( 3 ½ inch ),
‘1.44 MB’ diskette. The confusion is real,
as is the potential for incompatibility in
standards and in implemented system.
Faced with this reality, the IEEE
standards Board decided that IEEE
standards will use the conventional,
internationally adopted definitions of
the SI prefixes. Mega will mean
1 000 000, except that the base 2- defini-
tions may be used (if such usage is
explicitly pointed out on a case - by -
case basis) until such time that prefixes
for binary multiples are adopted by an
appropriate standards body.
The NIST reference on constants, units, and
uncertainty with regard to the international system of
units, should be required reading for any engineer.
6.5.4 Generating US Dimensions from SI 
Dimensions
If we remember that there are 2.54 cm/1.0 in, it is
simple to convert SI linear dimension to the US
system.
Example
Suppose we are in Europe and traveling with a
friend in his Porsche; we notice that he cruises the
Autobahn at 230 kilometers per hour (230 km/h). (SI
dimensions are not the only difference between
Americans and Europeans.) This seems a little fast,
so you check it. The conversion factor from kilome-
ters per hour (km/h) to miles per hour (mi/h) is:
which means that to convert km/h to mi/h, multiply
km/h by 0.62137…. To convert mi/h to km/h, take
the reciprocal (1⁄x) of the SI to US conversion factor
(0.6213) to obtain a US to SI conversion factor:
, which, for most purposes,
can be rounded to 1.61 km/h to each 1.0mi ⁄ h.
To feel comfortable with 230 km/h (i.e., 143mph),
you don’t need to be an expert in SI, but an expert
driver. The same can be said about audio and
acoustic measurements. It matters little which system
you use or how expert you are with it if you mismea-
sure the audio or acoustic parameter under test.
6.5.5 Simplified SI to US and US to SI 
Conversions
When making conversions, use the following logic.
The statement defines the answer desired:
All factor-labels have to equal unity. They can be
any set of dimensions so long as they equal 1.0.
100,000 cm
1 km
----------------------------
1 mi
5280 ft
-----------------
×
1  ft
12  in
------------
×
1  in
2.54 cm
-------------------
×
0.62  mi
1  km
------------------
=
1 0.6213
⁄
1.60934
=
Statement                          Factor Label
mi
1.0 mi
1.0 ft
1.0 in
100,000 cm
km
5280 ft
12 in
2.54 cm
1.0 km
×
×
×
0.621 mi
km
=
=

58
Chapter 6
They should be arranged so that the cancelling
labels are adjacent and the only labels left after the
cancellations are the two that were in the statement.
At that point all the factors are multiplied and
divided to give the desired answer. In the case
above, the statement is “miles per kilometer.” The
answer is 0.621 mi/km.
It could have been mi/km for 100 km.
1.
Meters to feet (m to ft)
(6-2)
2.
Feet to meters (ft to m)
(6-3)
3.
Square meters to square feet (m2 to ft2)
(6-4)
4.
Square feet to square meters (ft2 to m2)
(6-5)
5.
Cubic meters to cubic feet (m3 to ft3)
(6-6)
6.
Cubic feet to cubic meters (ft3 to m3)
(6-7)
The SI base units and their US counterparts are
seen in Table 1-1 along with a listing of derived
units of interest to sound system engineers in
Table 1-2.
Decimal notation can be used with either system
and is not an exclusive feature of either. Time has
not been decimalized. Universal physical constants
continue to defy humanly contrived measurements
in search of a coherent system.
The Planck system shows promise based on the
Planck second where:
1.
Planck second = 10−44 s.
2.
Planck length = 10−33 cm.
3.
Planck mass = 10−6 gm.
6.6 Basic Physical Terms
Force. Force is described as one kilogram moved
one meter per second per second (1 kg(m)/s2) which
is equal to one newton:
(6-8)
where,
F is the force in newtons,
M is mass in kilograms,
A is acceleration in meters per second per second.
(6-9)
Pressure. Pressure is the amount of force that is
acting on each unit area. A pressure of one newton
per square meter (N/m2) equals one pascal (Pa):
(6-10)
Work and Energy. When we do work we expend
energy. The energy that a mass has, as a result of its
position, is called potential energy. The energy that
a mass has, as a result of its motion, is called kinetic
energy. Work (in joules) equals force (in newtons)
times distance moved in the direction of the force
(in meters):
(6-11)
Power. Power is the rate at which work is done. The
average power (in watts) is equal to the work (in
joules) divided by the time in seconds:
Statement                          Factor Label
mi
1.0 mi
1.0 ft
1.0 in
10,000,000 cm
km
5280 ft
12 in
2.54 cm
100 km
×
×
×
0.621 mi
km
=
=
ft
m----
1  in
2.54 cm
-------------------
100  cm
1  m
-----------------
×
1 ft
12  in
------------
×
=
m
ft----
2.54 cm
1  in
-------------------
1  m
100  cm
-----------------
×
12  in
1  ft
------------
×
=
ft2
m2
-------
1 in
2.54  cm
-------------------
100 cm
1 m
-----------------
×
1 ft
12 in
------------
×
2
=
m2
ft2
-------
2.54 cm
1 in
-------------------
1 m
100 cm
-----------------
×
12 in
1  ft
------------
×
2
=
ft3
m3
-------
1 in
2.54  cm
-------------------
100 cm
1 m
-----------------
×
1 ft
12 in
------------
×
3
=
m3
ft3
-------
2.54 cm
1 in
-------------------
1 m
100 cm
-----------------
×
12 in
1  ft
------------
×
3
=
F
MA
=
N
kg
m
×
s 2
–
×
=
N
m2
-------
Pa
=
kg
m
s2
×
---------------
=
m 1
–
kg
×
=
s 2
–
×
W
F
D
×
=
kg
m2
×
s2
-------------------
=
m2
kg
×
s 2
–
×
=

Mathematics for Audio Systems
59
(6-12)
6.6.1 Conversion Factors from Base Units
To generate a factor for converting pounds force per
square foot (lbf / ft2 into pascals (Pa):
(6-13)
The pascal is a newton per square meter (N/m2),
therefore,
(6-14)
or
(6-15)
A pound of force (lbf) will accelerate a slug of
mass one foot per second per second. Therefore a
pound of force per square foot is given by:
(6-16)
From Table 6-1, a kilogram is equivalent to
0.06852 slug. This means there are 1/0.06852 kilo-
grams per slug. Similarly, there is 0.3048 meter per
foot. Substituting into Eq. 6-16
The conclusion is
(6-17)
Atmospheric pressure is 2116.2 lb/ft2 at the
earth’s surface (sea level). Therefore 47.880260 Pa ×
2116.2 lb/ft2 produces 101,324.2055 Pa. Our zero
reference sound pressure is 0.00002 Pa (20 μPa), so
full modulation of atmospheric pressure would be a
sound pressure level of
Table 6-1. Commonly Used Conversions
Quantity
Base SI unit
Symbol
Relationship
Base US unit
Symbol
Length
Meter
m
m = 3.281 ft
Feet
ft
Mass
Kilogram
kg
kg = 0.06852 slg
Slug
slg
Time
Second
s
s = s
Second
s
Electric current
Ampere
A
A = A
Ampere
A
Thermodynamic 
temperature
Kelvin
K
K = (°F + 459.67)/1.8
Degree 
Fahrenheit
°F
Amount of Substance
Mole
mol
mol = mol
Mole
mol
Luminous intensity
Candela
cd
cd =cd
Candela
cd
Plane angle
Radian
rad
2π rad = 360°
Degree
∠°
Solid angle
Steradian
sr
4πsr = sphere
Sphere
sph
Table 6-2. Common Electrical and Acoustical Derived 
Units
Quantity
Unit
Symbol
Pressure
Pascal
Pa = kg•m−1•s−2
Power
Watt
W = m2•kg•s-3
Force
Newton
N = m•kg•s−2
Work
Joule
J = m2•kg•s−2
Electromotive force
Volt
V = m2•kg•s−3•A−1
Electrical resistance
Ohm
Ω = m2•kg•s−3•A−2
Frequency
Hertz
Hz = s−1
Capacitance
Farad
F = m-2•kg−1•s4•A2
Inductance
Henry
H = m2•kg•s−2•A−2
P
J
s--
=
kg
m2
×
s3
-------------------
=
m2
kg
×
s 3
–
×
=
746  W
1 hp
58.73 dBm
=
=
(
)
N
m
kg
×
s2
----------------
=
m
kg
×
s 2
–
×
(
)
=
Pa
m
kg
×
s 2
–
×
m 2
–
×
=
Pa
kg
m
s2
×
---------------
=
lbf
ft2
------
slug
ft
s
×
2
--------------
=
lbf
ft2
------
slug
ft
s
×
2
--------------
14.594 kg
slug
-----------------------
×
ft
0.3048  m
----------------------
×
=
47.880  kg
m
s2
×
---------------
=
lbf
ft2
------
47.880260  Pa
=
20
101,324.2055  Pa
0.00002  Pa
----------------------------------------
log
194.0937  dB
=

60
Chapter 6
6.7 Mathematical Operations
Rule 1
If a number has a (+) sign, starting at zero, go in a
straight line along the x-axis toward 0°, Fig. 6-1. If a
number has a (−) sign, starting at zero go along the
x-axis toward 180°. (Regard a (−) sign as an instruc-
tion to revolve the sign assignment 180°.)
The length of the line toward either 0° or 180° is
determined by the magnitude of the number. For
example, +4 goes farther along the 0° axis line than
+2. All + signs add in magnitude toward 0°. All
−signs add in magnitude toward 180°. When minus
signs are added to plus signs, the number having the
greatest magnitude determines the sign.
Rule 2
Multiplying and dividing magnitudes follow the
same rules with the following variations. Every
minus sign encountered rotates the magnitude sign
180°. Therefore, +2 × (−2) = (2 × 2) + 180°, or −4.
But (−2) × (−2) = 2 × 2 + 360° or +4. Remember
every minus sign rotates the sign assignment 180°;
therefore, (−2) × (−2) × (−2) = (2 × 2 × 2) + 540°, or
−8. This is due to the fact that the symbol “−” is
both an operator and a sign.
6.7.1 Addition
Adding is taking the sum of two numbers (1 + 1 = 2)
or counting the total number.
6.7.2 Subtraction
Subtracting is changing the direction of addition
from 0° to 180°. As shown in Fig. 6-2, +2 −3 means
we first move two marks in the positive direction
from 0 to +2. We then move three marks in the
negative direction from that mark (+2). This results
in a final position on the marks of −1.
6.7.3 Multiplication
Multiplication is a form of repeated addition. The
notations 3 × 6, 3 ⋅ 6, and (3)(6) all mean add three
sixes together: 6 + 6 + 6 = 18.
6.7.4 Division
Division is a form of repeated subtraction. The nota-
tions 6 ÷ 3, 6/3, and  all mean find the number that
when subtracted from 6 three times results in zero:
+6 − 2 − 2 − 2 = 0.
6.7.5 Powers
Taking numbers to higher powers (exponents) is a
form of repeated multiplication. Both 24, and 2 exp4
mean multiply 2 by itself four times: 2 × 2 × 2 ×
2 = 16.
6.7.6 Roots
Roots are a form of repeated division. The notations
161/4, 
, and 16  exp  0.25 all mean find the
number that can be divided into 16 four times with a
remainder of zero. In this example the answer is 2.
6.7.7 Logarithms
Taking the logarithm of a number is a method of
expressing that number as an exponent of some
chosen base number. Using the base 10 allows
simple illustrations to be formed.
Figure 6-1. Basic notation.
Zero
+y
90o
0o
180o
270o
−y
−x
+x
10
8
6
4
2
−2
−4
−6
−8
−10
−2
−4
−6
−8
−10
2
4
6
8
10
Figure 6-2. Directions for addition and subtraction.
0
+1 +2 +3 +4
−1
−2
−3
−4
2 Marks +
3 Marks −
0°
180°
6
3---
16
4

Mathematics for Audio Systems
61
Logarithm operation means take the log of the
number to the base.
6.7.8 Antilogs
The inverse of this operation is the number ratio
expressed as an exponent of the base. Both log−1,
and antilog, mean:
(6-18)
6.7.9 Log Multipliers
Logarithmic multipliers are used in audio and acous-
tics such that
(6-19)
where,
M is the multiplier,
logb(a ⁄c)M is identical to M logb a ⁄c,
b is the base (it may be any value other than zero or
unity),
a ⁄c is the ratio being converted into a logarithm,
NM is the logarithm times the multiplier.
6.7.10 Antilogs of Multiplied Logarithms
To find the antilog of multiplied logarithms, the first
step is to remove the multiplier so the quantity can
be treated as a normal logarithm. The inverse opera-
tion is, of course, division so that NM⁄M = N is
obtained. Then the antilog is found by the standard
method bN = a ⁄c. These two valuable tools are
written as:
(6-20)
(6-21)
6.7.11 Comparing Arithmetic and Exponential 
Notation
Arithmetic and exponential notation are compared
in Table 6-3. Note that positive exponents move the
decimal point to the right. Negative exponents move
the decimal point to the left of the first numeral by a
number equal to the exponent. Also note that roots
are indicated by fractional exponents. For example:
10 0 . 5 × 10 0.5 = 10 (0.5  + 0 .5) = 10; therefore,
100.5 =
.
General Rule
Any positive real ratio a/c can be expressed by two
numbers, b and n, in exponential form:
(6-22)
10 x 10 = 100 = 102
    log10 100 = 2
number
logarithm
base
antilog102
102
=
M logb
a
c---
NM
=
M logb
a
c---
NM           (Log form)
=
antilogb
a
c---
b
NM
M
---------
          (Antilog form)
=
Table 6-3. Comparison of Arithmetic and Exponential
Notation
Arithmetic Notation
Exponential
Notation
Result
10 × 10
102
100
10 × 10 × 10
103
1000
10 × 10 × 10 × 10
104
10,000
10 × 10 × 10 × 10 × 10
105
100,000
104
10,000
103
1000
102
100
101
10
100
1
10−1
0.1
10−2
0.01
10−3
0.001
10−4
0.0001
10−5
0.00001
100 × 1000
102 × 103 or 10(2 + 3)
100,000
10 × 100
101 × 102 or 10(1 + 2)
1000
 or 10(5 − 3)
100
 or 10(3 − 2)
10
100.5 or 101⁄2
3.162
100.33 or 101⁄3
2.154
100.25 or 101⁄4
1.778
100.2 or 101⁄5
1.585
10
100,000 10
⁄
10,000 10
⁄
1000
(
) 10
⁄
100 10
⁄
10 10
⁄
1 10
⁄
0.1 10
⁄
0.01
(
) 10
⁄
0.001 10
⁄
0.0001 10
⁄
100,000 1000
⁄
105 103
⁄
1000 100
⁄
103 102
⁄
10
10
3
10
4
10
5
a
c---
bn
=

62
Chapter 6
Either b or n can be chosen arbitrarily, with
certain obvious restrictions, but the choice of one
determines the other. If a value of 10 is assigned to b
and a = 10 and c = 1, 10 ⁄1 = 101 consequently, n = 1.
Another way to express the same quantities is in
the logarithmic form:
(6-23)
or
(6-24)
Each element in the logarithmic and exponential
forms has an equivalent element in the other form:
The arrows indicate how the quantities transpose
from one form to the other. The logarithmic form is
read, “log to the base b of a over c equals n.” The
exponential form is read, “a over c equals the base b
raised to the power n.”
6.7.12 Comparing Arithmetic, Exponential, and 
Logarithmic Forms
Since the logarithm of a number is the exponent that
the base must be raised to in order to equal that
number, we can write logarithmic equivalents of
arithmetic equations by remembering how expo-
nents are manipulated, see Table 6-4. Table 16-5
shows the terms and symbols for logarithmic scales.
Once we recognize that logarithms are the expo-
nents of some base and that they follow exponential
rules of manipulation, we will understand decibel
notation, which also uses a logarithmic system of
notation. Practice with these very basic concepts can
serve an audio professional well.
Rule
The reciprocal of an exponent of a base may be used
as the root of the base without a change in value (of
the antilog):
logb
a
c---
logbb
n
×
=
logb
a
c---
logbb
-------------
∴
n
=
logbb
1
=
logb
a
c---
∴
n
=
Logb
a
c
= n
a
c
= b
n
Logarithmic form
Exponential form.
Table 6-4. Equivalent Arithmetic, Exponential, and 
Logarithmic Forms
Arithmetic 
Exponential 
Logarithmic
A⋅B
A1⋅B1
2⋅3
21⋅31
Ax
Ax
23
23
A1⁄x
31⁄2
Ax⋅Ay
A(x + y)
32⋅33
3(2 + 3)
(A⋅B)x
Ax⋅Bx
(2⋅3)4
24⋅34
(Ax)y
Axy
(23)4
2(3 × 4)
A1⁄x
21⁄3
A(x−y)
2(4−3)
100.5
10
=
10
A
log
B
log
+
(
)
10
2
log
3
log
+
(
)
A B
⁄
A1 B1
⁄
10
A
log
B
log
–
(
)
4 2
⁄
41 21
⁄
10
4
log
2
log
–
(
)
10x
A
log
103
2
log
A
x
10
A
log
x
-----------
3
2
10
3
log
2
-----------
10 x
A
log
y
A
log
+
(
)
10 2
3
log
3
3
log
+
(
)
10 x
A
log
x
B
log
+
(
)
10 4
2
log
4
3
log
+
(
)
A B
⁄
x
A
x(
)
B
x(
)
⁄
10
A
log
x
-----------
b
log
x
-----------
–
⎝
⎠
⎛
⎞
3 2
⁄
4
3
4(
)
2
4(
)
⁄
10
3
log
4
-----------
2
log
4
-----------
–
⎝
⎠
⎛
⎞
10xy
A
log
103
4
×
2
log
A B
⋅
x
A
x
B
x
⋅
10
A
log
x
-----------
b
log
x
-----------
+
⎝
⎠
⎛
⎞
2 3
⋅
4
2
4
3
4
⋅
10
3
log
4
-----------
2
log
4
-----------
+
⎝
⎠
⎛
⎞
A
x
10
A
log
x
-----------
⎝
⎠
⎛
⎞
2
3
10
2
log
3
-----------
⎝
⎠
⎛
⎞
Ax Ay
⁄
10(x
y)
A
log
–
24 23
⁄
10 4
3
–
(
)
2
log
A B
⁄
(
)x
Ax Bx
⁄
10x
A
log
x
B
log
–

Mathematics for Audio Systems
63
Rule
The reciprocal of a root of a base may be used as the
exponent of the base without a change in value (of
the antilog):
Rule
Exponents of a base, multiplied together, are equiva-
lent to the antilog of one exponent raised to the
second exponent:
Rule
One exponent of a base, divided by a second
exponent, is equivalent to the antilog of the first
exponent taken to the root of the second exponent:
Rule
One exponent of a base, divided by a second expo-
nent, is the equivalent to the second exponent taken
as the root of the base, raised to the first exponent:
Example
Find the decimal equivalent of 102.5.
Solution
Using the arithmetic form:
Using the exponential form:
Using the logarithmic form:
A−x
2−4
Ax⁄y
23⁄4
A0
1
Table 6-5. Terms and Symbols for Logarithmic Scales*
Physical
Quantity
Base
Name of One 
Order
Symbol
Power attenuation 
or gain
10
Bel
B
Stellar magnitude 
(Brightness−1)
1001⁄5 = 2.512
Magnitude
Musical pitch and 
other harmonic 
analysis 
(frequency)
,
where fL is the 
lower frequency, 
fH is the higher 
frequency, and n 
is the number of 
octaves.
Octave
OC
Photographic 
exposure settings
103⁄10 = 1.995
Step or Stop
ST
Various electrical, 
acoustic, and 
mechanical 
(proposed for 
general use)
e = 2.718
Neper
Np or 
ln
Proposed for 
general use
10
Brigg
Br
Proposed for 
general use
b
Order to base 
b
ORDb
* Proposed by Calvin S. McCamy, N.B.S.
Table 6-4.  (cont.) Equivalent Arithmetic, Exponential, 
and Logarithmic Forms
Arithmetic 
Exponential 
Logarithmic
3 2
⁄
(
)4
34 24
⁄
104
3
log
4
2
log
–
1 Ax
⁄
10 x
A
log
–
1 24
⁄
10 4
2
log
–
A
 y
x
A
xy
10
A
log
xy
-----------
⎝
⎠
⎛
⎞
4
 3
2
4
2
3
×
10
4
log
2
3
×
------------
⎝
⎠
⎛
⎞
Ax
y
10
x
A
log
y
---------------
⎝
⎠
⎛
⎞
23
4
10
3
2
log
4
--------------
⎝
⎠
⎛
⎞
Axy
A xy
(
)
1010
A
log
log
y
x
log
+
(
)
234
2 34
(
)
1010
2
log
log
4
3
log
+
(
)
100
A
log
fH fL
⁄
2n
=
(
)
10
2
100.5
=
102
3
×
1003
10002
=
=
104 2
⁄
10,000
2
=
104 2
⁄
104
2
=
102.5
10
5
2---
10
5
1
2---
×
105
(
)
1
2---
=
=
105
2
100,000
2
=
=
316.227
=
102.5
10
5
2---
10
5
1
2---
×
 
10
1
2---
⎝
⎠
⎜
⎟
⎛
⎞
=
5
10
2(
)
5
=
=
=
10
10
×
10
×
10
×
10
×
=
316.227
=

64
Chapter 6
This example shows that complex exponents
may be subdivided into powers and roots or, where a
common denominator can be found, into a series of
roots. If we are comfortable with addition, subtrac-
tion, multiplication, division, powers, and roots, we
have an adequate knowledge of arithmetic so far as
audio systems are concerned. If, for example, we
find that the addition of negative numbers causes us
difficulty, then some review is well worthwhile.
6.8 Complex Number Operations
To work with complex numbers, refer to Fig. 6-3.
1.
To add complex numbers, use rectangular form
(a + jb). Add real parts and then add imaginary
parts.
2.
To subtract complex numbers, use rectangular
form. Subtract real parts and then subtract imag-
inary parts.
3.
To multiply complex numbers, use the polar
form, (M∠θ or Mejθ), where M = (a2 + b2)1/2.
Multiply the magnitudes and add the angles. To
calculate magnitude and angle, use Eqs. 6-25
and 6-26.
4.
To divide complex numbers, use the polar form,
(M∠θ). Divide magnitudes and subtract angles.
5.
To obtain a complex number raised to the power
n use the polar form. Raise the magnitude to the
power n, (Mn), and then multiply the angle by n,
(einθ).
6.
To obtain n roots of complex numbers, use the
polar form (M∠θ) or Me jθ. Extract the root of
the magnitude (M 1/n). Divide the angles by n.
Example: To find the cube root of 8∠90°,
81⁄3 = 2. Then 90° ⁄ 3 = 30°, (90° + 360°) ⁄ 3 =
150°, and (90° = 720° ⁄ 3 = 270°). The three
roots are then 2∠30°, 2∠150°, and 2∠270°.
7.
We can use the foregoing method to calculate
impedance. If we measured an ac resistance R of
12.26 Ω and a total reactance X of 10.28 Ω we
could plot it as shown in Fig. 6-3. The angle θ is
called the angle of impedance and, in this illus-
tration, is the number of degrees or radians the
voltage leads the current. ELI THE ICE MAN is
an easy way to remember that E (voltage) leads I
(current) when L (inductance) is involved and
that I (current) leads E (voltage) when C (capac-
itance) is involved. M from the previous
Figure 6-3. Complex numbers expressed in rectangular
form.
102.5
102
0.5
+
102
100.5
×
=
=
102
10
×
102
10
2
×
=
=
100
3.16227
×
=
316.227
=
+j4
−j4
3−j4 (Rectangular)
5∠ −53.13 (Polar)
3
3+j4 (Rectangular)
5∠ 53.13 (Polar)
o
−j4
+j4
−3−j4 (Rectangular)
5∠ −126.87 (Polar)
−3
−3+j4 (Rectangular)
5∠126.87 (Polar)
∠
∠
∠
∠
3
j4
+
+3
j4
–
6
j0
+
-----------------
6
=
3
j4
+
3
j4
–
(
)
–
0
j8
+
----------------------
j8
=
3
j4
+
(
) 3
j4
–
(
)
5
53.13
∠
=
5
53.13
–
∠
25
0 0°
(
)
∠
25
=
--------------------------------------
3
j4
+
3
j4
–
--------------
5
53.13
∠
5
53.13
–
∠
------------------------
=
1
106.26
∠
=
0.28
–
j0.96
+
(
)
=

Mathematics for Audio Systems
65
examples is now the magnitude of the imped-
ance. We would write the data as:
(6-25)
To find the magnitude of the impedance we can
use the Pythagorean theorem:
(6-26)
and trigonometrically: 
(6-27)
(tan −1 simply means the inverse of the tangent).
 It is problems of this type that the advent of low
cost scientific electronic calculators have made so
accessible without undue stress and strain on the
mental system.
6.9 Decade Calibration
A decade in history is 10 years, but a decade in
audio is any ten-part interval (decade resistance
boxes have controls calibrated from 0 to 9 on each
knob). A decade in frequency would be defined as: 
(6-28)
where,
H.F. is the highest frequency,
L.F. is the lowest frequency.
This means that we can write a general case
expression for the calculation of how many decades
there are in a given bandpass by:
(6-29)
and
(6-30)
where,
ln is the natural logarithm or the logarithm to the
base e.
Example
Using a frequency span of 30–15,000  Hz in
discussing octaves, we can see that it represents
2.7 decades:
The question might arise in a different form. For
example, what upper frequency limit would I have if
I extended 2.5 decades from 30 Hz?
Or, what if I wish a 2.5 decade span with an upper
limit of 5000 Hz? What is my low-frequency cutoff?
Division into decades is electronically conve-
nient (witness 1⁄10 decade rather than 1⁄3 octave filter
designs), the general case equation for equally
spaced logarithmic intervals can be derived from our
approach above:
(6-31)
where,
N is the number of intervals of equal logarithmic
spacing (i.e., on a log scale are equally spaced).
Using the earlier data, suppose we want each
frequency from 30 to 9486.8 Hz spaced ½ decade
apart. That means we want N = 5.
Using equation 6-31:
As shown in Fig. 6-4, the first mark is 30 Hz; the
second mark is 94.87, which is 30 × 3.16, while the
R
jX
±
12.26
j10.28
+
=
Z
R2
X2
+
=
θ
tan 1
–
X
R--- 
⎝
⎠
⎛
⎞
=
H.F.
L.F.
-----------
101
1 decade
=
=
H.F.
L.F.
-----------
10 x decades
(
)
=
 H.F.
ln
 L.F.
ln
–
10
ln
-----------------------------------------
x decades
=
x decades
15,000
ln
30
ln
–
10
ln
---------------------------------------
=
2.7 decades
=
30
300
3000
30,000
1 decade
1 decade
1 decade
15,000
2.7 decades
H.F.
e
10
ln
2.5
(
)
ln 30
+
9486.8 Hz
=
=
L.F.
e
5000
ln
10
ln
2.5
(
)
–
[
]
15.8 Hz
=
=
H.F.
L.F.
-----------
1
N----
multiplier
(
)
=
30 Hz
94.87
300
948.68
3000
9486.8 Hz
0.5 decades
9486.8  Hz
30  Hz
------------------------
1
5---
3.16
=

66
Chapter 6
third frequency is 300 or 3.16 × 94.87. The fourth
frequency is 948.68 or 300 × 3.16, and the next
frequency is 3000. The last frequency is 9486.8Hz,
where 2.5 are spaced at ½ decade calibration.
6.10 Converting Linear Scales to Logarithmic 
Scales
A linear frequency scale is one on which each equal
length division represents an equal number of Hz.
Thus, addition of this equal number of Hz to the last
frequency gives the next frequency in the series.
A logarithmic scale is one on which equal length
divisions represent an exponential constant. Thus,
multiplying the last frequency by the exponential
constant gives the next frequency in the series.
Example
To divide a linear scale into six equal parts (seven
points including the first and the last with six equal
length intervals enclosed between the points) with
the maximum value equal to 300 and the beginning
at zero, divide the maximum value by the number of
equal intervals desired:
The first point is 0; the second point is 50
(enclosing one interval); the third point is 100
(enclosing the second interval); the fourth point is
150 (enclosing the third interval); the fifth point is
200 (enclosing the fourth interval); the sixth point is
250 (enclosing the fifth interval); and the seventh
point is 300 (enclosing the sixth interval).
Example
To divide the same length scale into six equal loga-
rithmic intervals from 1 to 300, find the multiplier
constant:
The first point is then 1.0; the second point is
2.59 (enclosing the first interval); the third point is
6.69 (2.59 × 2.59) (enclosing the second interval);
the fourth point is 17.32 (2.59 × 2.59 × 2.59)
(enclosing the third interval); the fifth point is 44.8
(2.594) (enclosing the fourth interval); the sixth
point is 115.95 (2.595) (enclosing the fifth interval);
the seventh point is 300 (2.596) (enclosing the sixth
interval). These two scales are illustrated in Fig. 6-5.
Both linear and logarithmic scales are used
repeatedly in sound system engineering. One-third
octave scales are logarithmic spaced intervals.
Signal delay anomalies are equally spaced on linear
scales. The decibel scale is a logarithmic scale. The
voltmeter scale is a linear scale. We need to cultivate
familiarity with both types of scales and often real
insights are gained by transferring data from one of
these scales to the other.
6.11 Finding the Renard Series for Fractional 
Octave Spacing
Renard numbers are equally spaced intervals on a
logarithmic scale. In the number system, one octave
300
6
---------
50 interval
⁄
=
300
1
---------
1
6---
2.59
=
Figure 6-4. Decade calibration.
1.0 Decade
1.5 Decades
2.0 Decades
2.5 Decades
30 Hz       94.87 Hz      94.87 Hz × 3.16 = 300 Hz
30 Hz       94.87 Hz          300  Hz       300 Hz × 3.16 = 948.68 Hz
30 Hz      94.87 Hz           300 Hz        948.68 Hz     948.68 Hz × 3.16 = 3000 Hz
30 Hz         94.87 Hz          300 Hz         948.68 Hz        3000 Hz     3000 × 3.16 = 9486.8 Hz
2.5 Decades
1.0 Decade                          1.0 Decade               0.5 Decade
0.5 Decade
30 Hz      30 Hz × 3.16 = 94.87 Hz

Mathematics for Audio Systems
67
is specified as the 31⁄3 series (i.e., 101⁄3.33 is the
multiplier m used to increment each interval). To
find any other Renard series, multiply 31⁄3 by the
reciprocal of the fractional octave desired: (i.e.,
1⁄6 octave = 6 × 31⁄3 = 20 series; 
1⁄10 octave = 10 × 31⁄3 = 331⁄3 series):
(6-32)
Example
Obtain 1⁄3 octave intervals from 100 Hz up.
Solution
6.11.1 Determining the Number of Octaves in a 
Given Bandwidth
One octave is a 2 to 1 change in frequency such that
from 1 Hz to 2 Hz is one octave. So is 1000 Hz to
2000 Hz or 10,000 Hz to 20,000 Hz. This can be
written mathematically as:
(6-33)
where,
fH is the higher frequency,
fL is the lower frequency,
n is the number of octaves.
For example, 4 Hz/1 Hz = 22 or 2 octaves. Using
natural logarithms, we can easily formulate this rela-
tionship into a general case equation:
(6-34)
therefore,
(6-35)
Example
How many octaves are there between 30 Hz and
15,000 Hz?
Solution
Using Eq. 6- 35,
This is a very wide range high fidelity system
(measured not advertised). Very few technological
systems are asked to span such a range. All of
visible light is but one octave. Audio is more
complex than is often realized.
6.12 Radians and Steradians
6.12.1 The Radian
The radian is the plain angle between two radii of a
circle that cuts off, on the circumference, an arc
equal to the radius from the center of that circle to
the circumference.
As a full circle is 2π radians which = 360°, then
π is a half circle,
π/2 is a 1/4 circle,
π/3 is a 1/6 circle,
etc. See Fig. 6-6.
Fig. 6-7 is the MathCAD program printout of
radians and degrees.
6.12.2 Steradians (Solid Angles)
The “solid angle” is the angle that, seen from the
center of a sphere, includes a given area on the
surface of that sphere. While dimensionless the solid
angle is given a label steradians (sr). One steradian is
Figure 6-5. Linear and logarithmic scaling of equally
spaced intervals from 0 to 300.
0           50         100       150        200         250      300
1         2.59       6.69      17.32     44.81     115.95    300
Linear scale
(6 intervals – 7 points
Logarithmic scale
(6 intervals – 7 points
Each interval = Highest value label   = 300  = 50/interval
                        Number of intervals      6
f intervals
Lf
m
×
(
)m…m
=
f  intervals
100
10
1
10
------
⎝
⎠
⎜
⎟
⎛
⎞
10
1
10
------
⎝
⎠
⎜
⎟
⎛
⎞
×
10
1
10
------
⎝
⎠
⎜
⎟
⎛
⎞
×
…
10
1
10
------
⎝
⎠
⎜
⎟
⎛
⎞
×
 for a total of n multiplications where n is
the number of intervals
=
fH
fL
-----
2n
=
fH
fL
-----
ln
2
ln
n
×
=
n
fH
fL
-----
ln
2
ln
----------------
=
n
15 000
,
30
------------------
ln
2
ln
-----------------------------
8.97 octaves
=
=

68
Chapter 6
the solid angle that cuts off an area of the surface of a
sphere equal to that of a square with sides of length
equal to the radius of the sphere when its vertex is in
the center of the sphere. The numerical value of the
solid angle is equal to the size of that area divided by
the square of the radius of the sphere.
6.12.3 Symbols
1.
sr is the solid angle in steradians.
2.
A is the area on the surface of the sphere.
3.
r is the radius of the sphere.
4.
rd is the angle (∠) in radians.
5.
Q is the geometric directivity factor.
6.
C∠ is the equivalent coverage angle for squares
or rectangles on the sphere’s surface (also
expressed as θ for horizontal angles and φ for
vertical angles).
Caution
When working with trigonometric functions,
computers and calculators need to select either the
radians or degrees mode. Attention must be paid to
the use of π with radians and 180° with degrees in
the equations where trigonometric functions occur.
6.12.4 Equations
(6-36)
(6-37)
(6-38)
(6-39)
(6-40)
(6-41)
(6-42)
C∠θ and φ from a Q for a square area
(6-43)
(6-44)
6.12.5 Complementary Angle for a Given Square 
Angle and a Desired Arbitrary Angle
Given:
C∠S (square angle) in rd,
IF
Figure 6-6. Directivity factors and directivity indexes.
Area 1 unit square
~1 steradian
Radius
1 unit
DF = 1
DI = 0 dB
1/1 space
DF = 2
DI = 3 dB
1/2 space
DF = 4
DI = 6 dB
1/4 space
DF = 8
DI = 9 dB
1/8 space
A
sr
(
)r2
=
4πr2
Q
-----------
=
sr
A
r2----
=
4π
Q
------
=
r
A
sr
-----
=
QA
4π
--------
=
Q
4π
sr
------
=
4πr2
A
-----------
=
Q
π
θ
 2 
------
⎝
⎠
⎛
⎞
sin
φ
 2 
------
⎝
⎠
⎛
⎞
sin
×
asin
-------------------------------------------------------------
=
where θ and φ are in radians
Q
180
θ
 2 
------
⎝
⎠
⎛
⎞
sin
φ
 2 
------
⎝
⎠
⎛
⎞
sin
×
asin
-------------------------------------------------------------
=
where θ and φ are in degrees
sr
4
arc
θ
sin
2
-----------
φ
sin
2
-----------
⋅
sin
×
=
where θ and φ are in radians
C∠
2
π
Q----
⎝
⎠
⎛
⎞
sin
asin
=
radian mode
C∠
2
180
Q
---------
⎝
⎠
⎛
⎞
sin
asin
=
degree mode

Mathematics for Audio Systems
69
C∠A (arbitrary angle) in rd,
C∠C (complementary angle) in rd.
(6-45)
6.12.6 Finding Q for a Given Square Angle
(6-46)
(6-47)
6.12.7 Percentage of Spherical Surface Area 
Covered for a Given Q
(6-48)
Figure 6-7. Radians and degrees.
C
C
∠
2
C
S
∠
2
---------
⎝
⎠
⎛
⎞
sin
2
C
A
∠
2
----------
⎝
⎠
⎛
⎞
sin
-------------------------  in radians
asin
=
Conversions
rd 180
π
---------
⋅
degrees
=
degrees
π
180
---------
⋅
rd
=
Q
π
C
S
∠
2
---------
⎝
⎠
⎛
⎞
2
sin
asin
------------------------------------------
=
rd mode
Q
180
C
S
∠
2
---------
⎝
⎠
⎛
⎞
2
sin
asin
------------------------------------------
=
degree mode
% Area
100 1
Q----
⎝
⎠
⎛
⎞
=
100 sr
4π
------
⎝
⎠
⎛
⎞
=
1.0sr
square angle of 1.041198 rd
=
59.65589°
=
Q of 4π
=
7.958% of spherical surface area
=

70
Chapter 6
6.13 Calculating Percentages and Ratios
The story is told of the “least likely to succeed”
member of a class returning to the class reunion. He
arrived in a Rolls Royce attended by a chauffeur,
footman, bodyguards, etc. Someone asked him how
he made so much money. He replied, “I found a
small item everyone wanted and marked it up 10%
and the money rolled in. I bought it for a dollar and
sold it for $10.00, and that 10% really added up.”
Fig. 6-8 and the following equations are used in
financial percentage problems:
(6-49)
(6-50)
(6-51)
(6-52)
(6-53)
(6-54)
(6-55)
(6-56)
where,
%PoSP is the % profit on selling price,
%MoCP is the % markup on the cost price,
SP is the selling price,
CP is the cost price,
MR is the markup ratio.
Example
Suppose you pay $50.00 for an item (CP) and sell it
for $75.00 (SP). What is your % profit on selling
price (%PoSP) on that sale?
Solution
Using Eq. 6-49:
Example
Suppose you are buying an article for $75.00 and
later are told that the dealer makes 331⁄3% on it.
What did the dealer pay for the article (CP)?
Solution
Using equation 6-50:
Example
Suppose you pay $50.00 for an article and wish to
have a 331⁄3% profit. What selling price should you
receive to do this?
Solution
Using Eq. 6-52:
Figure 6-8. Financial percentage terms.
Selling Price
SP
Profit on
Selling Price
PoSP
Cost Price
CP
%PoSP
100 1
CP
SP
--------
–
⎝
⎠
⎛
⎞
=
CP
SP 1
%PoSP
100
------------------
–
⎝
⎠
⎛
⎞
=
CP
SP
MR*
-----------
=
SP
CP
1
%PoSP
100
------------------
–
---------------------------
=
SP
MR*
CP
×
=
MR*
100
1
100
%PoSP
–
---------------------------------
⎝
⎠
⎛
⎞
=
MR*
SP
CP
--------
=
* Markup ratio
%MoCP
100 SP
CP
--------
1
–
⎝
⎠
⎛
⎞
=
%PoSP
100 1
50
75
------
–
⎝
⎠
⎛
⎞ 
=
333
1
=
CP
$75.00 100% 
33.333%
–
100%
-------------------------------------------
⎝
⎠
⎛
⎞
=
$50.00
=

Mathematics for Audio Systems
71
Note here that it is not possible to make a 100%
profit on the selling price unless you receive the
article as a gift. These questions can also arrive as
markup ratios MR or as percent markup on cost
price %MoCP.
Example
Suppose you pay $50.00 for the article, sell it for
$75.00, and realize a 331⁄3% profit. What is the
markup ratio?
Solution
Using Eq. 6-54:
In other words, 1.5 × $50.00 = $75.00. Thus, any
cost multiplied by 1.5 will give the correct selling
price whenever the percent profit on selling price is
to be 331⁄3%.
Example
When the cost price is $50.00 and the selling price
$75.00, what is the percent markup on cost price?
Solution
Using Eq. 6-56:
Using these equations, we can see that the
successful class member had a 90% PoSP or a 900%
MoCP, not a 10% profit as he had assumed.
6.13.1 Decibels and Percentages
The decibel indicates a change in ratio. Provided all
voltages are measured across the same resistance or
impedance voltage or current ratios can be found as
well, Fig. 6-9.
6.13.2 Power Changes Downward
(6-57)
6.13.3 Power Changes Upward
(6-58)
6.13.4 Voltage Changes Downward
(6-59)
6.13.5 Voltage Changes Upward
(6-60)
Example
An anechoic chamber absorbs 99% of the power put
into it and reflects only 1%. What percent of the
initial sound pressure level (SPL) is reflected?
SP
$50.00
1
33.33%
100
------------------
–
---------------------------
=
$75.00
=
MR
100
1
100
33.33
–
----------------------------
⎝
⎠
⎛
⎞
=
1.5
=
%MoCP
100 75.00
50.00
-------------
1
–
⎝
⎠
⎛
⎞
=
50%
=
Figure 6-9.  Scale with 0 dB reference.
0
2
6
8
4
2
4
6
8
0 dB reference
Decibels above reference
  % change = 100(b+db/M1)
Decibels below reference
  % change = 100(1bdb/M)
where,
  b is the base (usually 10 or 2.718…),
  M is the multiplier (usually 10, power, or 20, voltage.)
%Change
100 1
10
dB
–
10
----------
–
⎝
⎠
⎜
⎟
⎛
⎞
=
%Change
100 10
+dB
10
----------
1
–
⎝
⎠
⎜
⎟
⎛
⎞
=
%Change
100 1
10
−dB
20
-----------
–
⎝
⎠
⎜
⎟
⎛
⎞
=
%Change
100 10
+dB
20
----------
1
–
⎝
⎠
⎜
⎟
⎛
⎞
=

72
Chapter 6
Solution
First, if we put 100 acoustic watts into the room you
will have 1 W reflected:
20 dB = 99% of the power absorbed.
Therefore, reflection will be 20 dB below where it
started. Since the LP is a voltagelike quantity, it also
will be −20 dB:
Thus 90% of the LP was absorbed. Since we started
with 100%:
which is the reflection percentage for LP .
Example
Having equalized a sound system and raised its gain
15 dB, what percent power increase is now called for?
Solution
6.13.6 Decibels for Percent Below Reference
(6-61)
6.13.7 Decibels for Percent Above Reference
(6-62)
Example
If a harmonic is 1% (i.e., 99% below reference)
Example
An acoustic signal is reflected off of a surface that is
80% absorptive, the reflected signal will drop
6.99dB.
Example
If the input voltage to loudspeaker is raised by 30%,
we should add 2.28 dB to its LP
Fig. 6-10 shows the relationship between deci-
bels and percentages for power and for voltage,
current, LP , and distances.
6.14 Useful Math Tables
A table of the basic relationships is shown in
Table 6-6. Table 6-7 shows widely used exponential
prefixes. Basic trigonometry is frequently useful in
sound system work, Table 6-8. Table 6-9 illustrates a
simple but practical application.
10
100
1
---------
log
20 dB
=
% Change
100 1
10
20
–
20
---------
–
⎝
⎠
⎜
⎟
⎛
⎞
90%
=
=
100
90
–
10%
=
%Change
100 10
+15
10
---------
1
–
⎝
⎠
⎜
⎟
⎛
⎞
3062%
=
=
dB
M logb 1
%Change
100
-------------------------
–
⎝
⎠
⎛
⎞
=
dB
M logb %Change
100
-------------------------
1
+
⎝
⎠
⎛
⎞
=
Figure 6-10. Relationship of decibels and percentages.
dB
20* log10 1
99% 
100
------------
–
⎝
⎠
⎛
⎞
40 dB
=
=
* Voltagelike ratios
dB
10*log10 1
80
100
---------
–
⎝
⎠
⎛
⎞
6.99  dB
=
=
* Powerlike ratios
dB
20 log10 30%
100
-----------
1
+
⎝
⎠
⎛
⎞
+2.28 dB
=
=
0
10
20
30
40
50
60
70
0.01            0.1               1.0                10            100
Decibels below fundamental
Relationship of decibels and percentages
10log Power
20log Voltage, SPL, Distance

Mathematics for Audio Systems
73
6.14.1 Scientific Metrology
It appears that a slow shift (beginning with active
minorities such as cosmologist and string theorists) is
underway in physics which will gradually cause the
metric system to be abandoned in favor of practical
versions of the Planck units. These will be conve-
niently scaled by powers of 10, the way scientific
units always are, and some will be ascribed conven-
tional values to provide exact metric convertibility.
Units
In a totally fascinating article in Physics Today,
February 2003, by Frank Wilczek, the Herman
Feshback Professor of Physics at MIT, entitled,
“Life Parameters” is the best discussion of how to
scale measurement parameters that I have ever read.
I have a definite preference for “scaling” to human
dimensions, and a “foot” is human indeed. The
professor prefers CGS (grams, centimeter and
seconds) for the same reason, rather than reflexing
to SI (kilograms, meters and seconds).
In the United States of America there remains to
the present time a preference for pounds, feet,
seconds and their derivatives. Engineering conve-
niences aside, any audio engineer talking to a
layman (translate clients) who presents room data in
SI alienates that client. Most of you have lived
jointly with the US and the SI systems without harm
while being non-bilingual, whereas the Europeans
are bilingual, yet they often stare blankly at US
dimensions. I guess you could call Americans
bi-dimensional.
Planck’s Units
The focus of Professor Wilczek’s article is Planck’s
units. These are, expressed in his preferred CGS
format, the smallest mass, the shortest length, and
the shortest time.
1.
10-6 g for mass.
2.
10-33 cm for length.
3.
10-44 s for time. 
Table 6-6. Trigonometric Functions in Terms of Each Other
sin θ
sin θ
cos θ
cos θ
tan θ
tan θ
cot θ
cot θ
sec θ
sec θ
csc θ 
csc θ
1
cos2θ
–
θ
tan
1
tan2θ
+
---------------------------
1
1
cot2θ
+
---------------------------
sec2θ
1
–
θ
sec
--------------------------
1
θ
csc
-----------
1
sin2θ
–
1
1
tan2θ
+
----------------------
θ
cot
1
cot2θ
+
---------------------------
1
θ
sec
-----------
csc2θ
1
–
θ
csc
--------------------------
θ
sin
1
sin2θ
–
--------------------------
1
cos2θ
–
θ
cos
---------------------------
1
θ
cot
-----------
sec2θ
1
–
1
csc2θ
1
–
--------------------------
1
sin2θ
–
θ
sin
--------------------------
θ
cos
1
cos2θ
–
---------------------------
1
θ
tan
-----------
1
sec2θ
1
–
--------------------------
csc2θ
1
–
1
1
sin2θ
–
--------------------------
1
θ
cos
------------
1
tan2θ
+
1
cot2θ
+
θ
cot
---------------------------
θ
csc
csc2θ
1
–
--------------------------
1
θ
sin
-----------
1
1
cos2θ
–
---------------------------
1
tan2θ
+
θ
tan
---------------------------
1
cot2θ
+
θ
sec
sec2θ
1
–
--------------------------
Table 6-7. SI Prefixes
Number
Power 
Ten Is 
Raised To
Prefix
Symbol 
1024
Yotta
Y
1021
Zetta
Z
1018
Exa
E
1015
Peta
P
1,000,000,000,000.
1012
Tera
T
1,000,000,000.
109 
Giga
G
1,000,000.
106
Mega
M
1000.
103
kilo
k
100.
102
hecto
h
10.
101
deka
da
Table 6-7.  (cont.) SI Prefixes
Number
Power 
Ten Is 
Raised To
Prefix
Symbol 

74
Chapter 6
The professor goes on in exquisite detail to relate
mass to “brain mass” as limited by the mother’s
ability to give birth to a given size head. Length is
worked on from the Bohr radius (a centimeter is
roughly a 108 Bohr radii or atomic sizes), and so a
cubic centimeter is just what encompasses those
same 1024 atoms that make a gram. Time is immedi-
ately humanized by “So, why does it take about a
second to have a thought?” Also how gravity relates
to restricting the pace of human movement. Planck’s
units are constructed from suitable combinations of:
1.
C = the speed of light.
2.
h = the quantum of action.
3.
G = the Newtonian gravitational constant.
These quantities are the avators of Lorentz
symmetry: wave—particle duality, and the bending
of space time by matter, respectively.
I am once again reminded that Wigner deplored
that physics, or any other entity for that matter, had
ever been able to define consciousness. When one
works in a dimensional system of human propor-
tions, wrong answers often appear ridiculous,
whereas a system far removed from human sense
perception often befuddles the user. The following
reveals a richness that decimals will never attain:
8 furlongs = 1 mile = 5280 feet = 1760 yards =
8000 links = 320 rods = 80 chains = 0.86838249
nautical miles = 880 fathoms = 0.289 league =
63,360 inches.
The acre was originally a measure of a field’s
production rather than its dimension. All these
dimensions were the basis of property division in
the Western United States (the South preferred a
more human-based system of “meets and bounds,”
i.e., from that tree to that corner, etc.) This has
ingrained itself in the American psyche so solidly as
to require draconian measures by a dictatorial power
to change it.
My sense of all this is that SI is just one more set
of dimensions to be aware of and when I want to be
truly scientific, I’ll resort to Planck’s units. 
1.
100
—
—
0.10
10−1
deci
d
0.01
10−2
centi
c
0.001
10−3
milli
m
0.000 001
10−6
micro-
µ
0.000 000 001
10−9
nano
n
0.000 000 000 001
10−12
pico
p
0.000 000 000 000 001
10−15
femto
f
10−18
atto
a
10−21
zepto
z
10−24
yocto
y
Table 6-8. Basic Trigonometry
Radians
2π = 6.2832 = 360°
π⁄4 = 0.7854 = 45°
π = 3.1416 = 180°
π⁄6 = 0.5235 = 30°
π ⁄ 2 = 1.5708 = 90°
π⁄12 = 0.26180 = 15°
π ⁄ 3 = 1.0472 = 60°
Table 6-7.  (cont.) SI Prefixes
Number
Power 
Ten Is 
Raised To
Prefix
Symbol 
A
C
B
c
b
a
A
sin
a
c---
=
A
csc
c
a---
=
A
cos
b
c---
=
exsecA
A
sec
1
–
=
A
tan
a
b---
=
versA
1
A
cos
–
=
A
cot
b
a---
=
coversA
1
A
sin
–
=
A
sec
c
b---
=
havA
0.5
=
versA
Table 6-9. Finding an Unknown Height
∠
tanθ
∠
tanθ
∠
tanθ
15°
0.2679
26°
0.4877
37°
0.7536
16°
0.2867
27°
0.5095
38°
0.7813
θ
φ
H
A
Eye height
0 = A tan θ
When θ = 45° A = O
Walk back from elevation to be measured until q is at 45° or, if that is
not possible, at some angle between 15° and 45°. Adjust your distance
A to allow a whole angle to be measured. Add your eye height to O
O

Mathematics for Audio Systems
75
6.15 Angles
Fig. 6-11 represents a sector of a circle or “a piece of
pie.” It is also a piece of pi (π) as will become
evident in the following.
The radius of the circle from which the sector
was taken is r, the portion of the circle’s perimeter
belonging to the sector is the arc length S. The angle
associated with the sector is θ and by definition,
(6-63)
It is apparent from the definition that θ is given
by the ratio of two lengths and hence is itself dimen-
sionless. Imagine now that one examines larger and
larger sectors from the same circle. In fact, one
could go “full circle” and examine the entire circle.
In this instance S has become the perimeter of the
circle, which is 2πr and θ has become
(6-64)
Going “full circle” yields an angle of 2π. One
may well ask, “two pi what?” Even though θ is
dimensionless, a nametag is usually appended to
angular measure. This tag is the radian. Going “full
circle” therefore involves an angle of 2π radians.
Imagine now that one starts with a very small
sector with θ approximately zero and that θ is
allowed to grow uniformly with the passage of time
such that at any time t, θ is given by
(6-65)
Here, ω is the uniform growth rate of θ with
elapsed time, i.e.,
(6-66)
What time is required for θ to go “full circle”?
This time is called the period T and from Eq. 6-66
(6-67)
The reciprocal of the period is called the
frequency, f, and represents the number of times in
one second that θ goes “full circle.”
(6-68)
where,
f is measured in reciprocal seconds or Hertz,
ω is called the angular frequency or radian
frequency because from Eq. 6-68
(6-69)
where ω is expressed in radians per second.
Alternatively, one might begin with a sector for
which θ has some initial value, say α, but in which θ
is allowed to grow uniformly with time at the same
rate as before. In this instance the value of θ will be
given by
(6-70)
Relations (Eq. 6-67), (Eq. 6-68), and (Eq. 6-69)
will be the same as before because α is a constant
angle independent of time. α is called the epoch
angle, that is to say the angle from which one starts.
6.16 A Little Trigonometry
Fig. 6-12 is constructed from Fig. 6-11 by the
addition of a perpendicular so as to form a right
triangle within the sector. The right triangle has a
hypotenuse of length r, an opposite side of length b,
17°
0.3057
28°
0.5317
39°
0.8098
18°
0.3249
29°
0.5543
40°
0.8391
19°
0.3443
30°
0.5774
41°
0.8693
20°
0.3640
31°
0.6009
42°
0.9004
21°
0.3839
32°
0.6249
43°
0.9325
22°
0.4040
33°
0.6494
44°
0.9657
23°
0.4245
34°
0.06745
45°
1.000
24°
0.4452
35°
0.7002
25°
0.4663
36°
0.7265
Figure 6-11. Sector of a circle.
Table 6-9.  (cont.) Finding an Unknown Height
r
r
S
Q
θ
S
r---
=
θ
2πr
r
---------
2π
=
=
θ
ωt
=
ω
θ
t---
=
T
2π
ω
------
=
1
T---
f
=
ω
2π
------
=
ω
2πf
=
θ
ωt
α
+
=

76
Chapter 6
and adjacent side of length a. We are indebted to
Pythagoras for determining the relationship which
exists between r, a, and b.
(6-71)
 The sine of the angle θ written as sin θ is defined
to be
(6-72)
while the cosine of the angle θ is defined to be
(6-73)
and the tangent of the angle θ is defined to be
(6-74)
Even though the Eqs. 6-72, 6-73, and 6-74 are the
defining equations for the sin θ, cos θ, and tan θ,
respectively, there are other equivalent ways for
determining the sine or cosine of a given angle. For
example, the sine of the angle θ can be determined to
any accuracy required by the following infinite series
(6-75)
while the cosine of the angle θ is given by the series
(6-76)
In Eqs. 6-75 and 6-76 the notation 2! means two
multiplied by one, the notation 3! means three
multiplied by two and then multiplied by one, and 4!
means four multiplied by three then multiplied by
two and finally multiplied by one, etc. The notation
… means continued in the same manner ad
infinitum.
Returning now to Eq. 6-72, it is observed that
sinθ as well as the other trigonometric functions are
dimensionless. The utility of the equation exists in
the fact that given r and θ one can determine b as
(6-77)
It is not necessary that r and b be distances as
they are in the triangle of Fig. 6-12. They can have
any dimensions you please as long as they have the
same dimension and as long as they follow the trian-
gular relationship for the right triangle given by
Pythagoras.
6.17 The Origin of the Base of the Natural 
Logarithm, e
The statement that y is a function of x simply means
that the value of a dependent variable which is y
depends on the value of an independent variable
which is x. Let us investigate one such functional
relationship as expressed by the equation
(6-78)
The equation states that in order to obtain y for a
given x, you add one to x and raise the resulting
quantity to the power, one divided by x. When x is
very large, y is approximately one. When x is one, y
is two. When x is 0.5, y is about 2.25. As x is
allowed to get closer and closer to zero, y gets closer
and closer to a number called e. In fact, e is the
limiting value of y as x approaches zero in Eq. 6-78.
This behavior is illustrated in Fig. 6-13.
Figure 6-12. Sector containing a right triangle.
r2
a2
b2
+
=
r
a
S
Q
b
θ
sin
b
r---
≡
θ
cos
a
r---
≡
θ
tan
b
a---
≡
θ
sin
θ
θ3
3!
-----
θ5
5!
-----
θ7
7!
-----
–
…
+
+
–
=
θ
cos
1
θ2
2!
-----
–
θ4
4!
-----
θ6
6!
-----
–
…
+
+
=
Figure 6-13. Base of the natural logarithm, e.
b
r
θ
sin
=
y
1
x
+
(
)
1
x---
=
2.8
2.6
2.4
2.2
2.0
1.8
1.6
1.4
1.2
Origin of the Number e
0      1      2      3     4     5      6      7     8      9     10
x
Function Value

Mathematics for Audio Systems
77
One of the consequences of defining e as the
limiting value of Eq. 6-78 when x approaches zero is
that e can be calculated to any degree of accuracy
required from the infinite series
(6-79)
Furthermore, e raised to any power such as u, is
given to any degree of accuracy desired by
(6-80)
6.18 The Complex Plane
The normal algebraic operations such as addition,
subtraction, multiplication, and division amount to
locating points on the real number line of Fig. 6-14.
There is, however, no real number which when
squared yields a negative real number. This is a
consequence of how the operation of multiplication
is defined for the numbers on the line of Fig. 6-14.
We therefore invent a new kind of number whose
square is a negative number. Historically such a
number has been termed “imaginary” but really is
no more imaginary than is any other number. This
new type of number is distinguished by writing the
symbol j in front of the number with the under-
standing that when j is multiplied by itself it yields
−1, that is j is the square root of −1. A place is
provided for these new numbers in a modification of
Fig. 6-14 by extending a line upward and downward
through zero thus arriving at a two dimensional
space called the complex plane as depicted in
Fig. 6-15.
Given a complex number having a real part a and
an imaginary part b where the entire number is
denoted by c, that is c = a + jb. What is c? c is a
point in the complex plane which is located by
beginning at the origin and then moving out a units
on the real axis followed by then moving b units
parallel to the imaginary or j axis. Alternatively, c
could be located by moving r units along a line from
the origin, where this line makes an angle θ with the
real axis as shown in Fig. 6-16.
The relationships existing in Fig. 6-16 are as
follows:
1.
, this is called the magnitude
or modulus of the complex number c.
2.
tan θ = b/a where θ is called the angle of the
complex number.
Note also that a = r cos θ and b = r sin θ.
6.19 Euler’s Theorem
There is a famous theorem by Euler which states
(6-81)
This can be easily proven. Take Eq. 6-80 and let
u = jθ to obtain
(6-82)
Write Eq. 6-76
Figure 6-14. Real number line.
e
1
1
1!
-----
1
2!
-----
1
3!
-----
1
4!
-----
1
5!
-----
…
+
+
+
+
+
+
=
eu
1
u
u2
2!
-----
u3
3!
-----
u4
4!
-----
u5
5!
-----
…
+
+
+
+
+
+
=
4    3       2      1      0       1       2         3       4
Figure 6-15. The complex plane.
Figure 6-16. The complex quantity c.
j4
j3
j2
j1
j1
j2
j3
j4
                                                                   
r
a2
b2
+
(
)z
=
a
θ
b
Point c
Real Axis
j Axis
r
e jθ
θ
cos
j
θ
sin
+
=
e jθ
1
jθ
θ2
2!
-----
–
jθ3
3!
-----
–
θ4
4!
-----
jθ5
5!
-----
…
–
+
+
+
=

78
Chapter 6
Multiply Eq. 6-75 by j to obtain
(6-83)
Now add Eq. 6-76 and 6-83 to yield
(6-84)
which is Eq. 6-82. Return now to the original
complex number c = a + jb. Through the use of
Euler’s theorem, it should be apparent that c may be
expressed in a variety of forms, each of which is
equally valid
(6-85)
(6-86)
Eq. 6-86 is called the rectangular form for c
whereas Eq. 6-85 is called the exponential form for
c. They are equivalent in every respect. When
adding or subtracting complex numbers, the rectan-
gular form is the most convenient while the expo-
nential form facilitates the operations of
multiplication or division.
6.20 Examples
6.20.1 Addition of Complex Numbers.
Let c = 5 + j7 while d = 4 + j3. What is the sum
c + d ?
Step one: Add the real parts 5 + 4 to obtain 9.
Step two: Add the imaginary parts 7 + 3 to obtain 10.
Step three: Write c + d = (5 + 4) + j(7 + 3) = 9 + j10.
6.20.2 Subtraction of Complex Numbers.
Let c = 5 + j7 and d = 4 + j3. What is the difference
c − d ?
Step one: Subtract the real part of d from the real
part of c to obtain 5 − 4 = 1.
Step two: Subtract the imaginary part of d from the
imaginary part of c to obtain 7 − 3 = 4.
Step three: Write c − d = (5 − 4) + j(7 − 3) = 1 + j4.
Before proceeding to multiplication and division
of complex numbers, c and d are converted to the
exponential form.
6.20.3 Products of Complex Numbers
The product of two complex numbers is a complex
number whose magnitude is the product of the indi-
vidual magnitudes and whose angle is the sum of the
individual angles
6.20.4 Quotients of Complex Numbers
The quotient of two complex numbers is a complex
number whose magnitude is the quotient of the indi-
vidual magnitudes and whose angle is the differ-
ence of the individual angles
6.20.5 A Little Digression
Complex numbers are interesting and fun to play
with and for most of their history were the province
of pure mathematicians and later, a few physicists.
An intellectual giant, Charles Proteus Steinmetz
(1865–1923) was the first to introduce them into the
engineering curriculum. Steinmetz arrived in the US
in 1889 as a political refugee from Germany where
he had been educated in mathematics, chemistry,
and electrical engineering. He was hired as a
consulting engineer by the fledgling General
Electric Company and his contributions enabled GE
to become an early industrial giant. Unfortunately,
θ
cos
1
θ2
2!
-----
–
θ4
4!
-----
θ6
6!
-----
–
…
+
+
=
j
θ
sin
jθ
jθ3
3!
-----
jθ5
5!
-----
jθ7
7!
-----
–
…
+
+
–
=
θ
cos
j
θ
sin
+
1
jθ
θ2
2!
-----
–
jθ3
3!
-----
–
θ4
4!
-----
jθ5
5!
-----
θ6
6!
-----
–
jθ7
7!
-----
–
+
+
+
…
=
c
re jθ
r
θ
cos
j
θ
sin
+
(
)
=
=
c
a
jb
+
r a
r---
jb
r---
+
⎝
⎠
⎛
⎞
=
=
c
5
j7
+
=
52
72
+
e
j
7
5---
atan
=
8.6e j0.95
=
d
4
j3
+
=
42
32
+
e
j
3
4---
atan
=
5e j0.644
cd
8.6
(
) 5
( )e j 0.95
0.644
+
(
)
43e j 1.594
(
)
=
=
c
d---
8.6
5
-------e j 0.95
0.644
–
(
)
1.72e j 0.306
(
)
=
=

Mathematics for Audio Systems
79
Steinmetz suffered from a congenital birth defect,
which evidenced itself in the form of a hunched
back. Steinmetz never married for fear of passing on
his deformity. Nevertheless he loved young people
and devoted many hours toward training young
engineers as a professor at Union College all in
addition to his work at GE. The introduction of the
complex exponential notation into the electrical
engineering curriculum greatly simplified ac circuit
calculations and his mathematical techniques soon
became standard industry wide. These techniques
are not limited to just ac circuits but are equally
applicable to any linear system in which the
behavior has a sinusoidal time dependence.
6.21 Phasors
This section will be explored through an example
dealing with the motion of a loudspeaker cone. Let x
represent the displacement of the loudspeaker cone
from its normal rest or equilibrium position. If a
sinusoidal current of fixed frequency drives the
loudspeaker, its displacement from equilibrium can
be given by
(6-87)
In this expression, x is considered to be positive
when the cone moves so as to compress the air in
front of it, xm is the maximum value or amplitude of
the displacement, and ω is the angular frequency.
For the sake of definiteness, let
and
The loudspeaker displacement at any time is then
This function can readily be represented by the
complex exponential
provided it is understood that only the real part of
the complex exponential represents the true
displacement. Recall, from Euler’s theorem,
the real part of which is only cosθ. The function
when depicted in the complex plane, is called a 
phasor. The depiction of this phasor at the instant 
t = 0 appears in Fig. 6-17A. The length or magni-
tude of this phasor is the same as the amplitude of 
the loudspeaker’s cone motion. The angle of the 
phasor at any instant is
so the phasor rotates counterclockwise about the
origin at the rate
Fig. 6-17B displays the position of the phasor at
an instant one-eighth of a period later than is
displayed in Fig. 6-17A. Note that the projection of
the phasor onto the real axis at any instant is
which is the description of the loudspeaker motion.
x
xm
ωt
(
)
cos
=
xm
10 6
– meter
=
ω
2π1000
s
-------------------
=
x
10 6
– meter 
2π1000
s
-------------------t
⎝
⎠
⎛
⎞
cos
×
=
x
10 6
– meter 
e
j 2π1000
s
-------------------t
⎝
⎠
⎛
⎞
×
=
e jθ
θ
cos
j
θ
sin
+
=
Figure 6-17. Phasor describing cone motion.
x
10 6
– meter 
e
j 2π1000
s
-------------------t
⎝
⎠
⎛
⎞
×
=
θ
2π1000
s
-------------------t
=
ω
2π1000
s
-------------------
=
x
10 6
– meter 
2π1000
s
-------------------t
⎝
⎠
⎛
⎞
cos
×
=
Real Axis
Real Axis
j Axis
j Axis
A.
B.
Q

80
Chapter 6
6.21.1 Addition of Phasors
Consider two loudspeakers operating at a frequency
of 1000  Hz and positioned so that they each
contribute to the total acoustic pressure at an obser-
vation point. The first loudspeaker acting alone
produces an acoustic pressure given by the phasor
The second loudspeaker acting alone produces an
acoustic pressure given by the phasor
Each of these acoustic pressures is small enough
such that the air behaves linearly for these small
disturbances. The total acoustic pressure at the
observation point with both loudspeakers in opera-
tion will be the sum of the individual acoustic pres-
sures. The total acoustic pressure at the observation
point will be described by a phasor which is the sum
of the individual phasors. Symbolically, the total
acoustic pressure is described by
(6-88)
As each of the phasors is complex and complex
quantities are most easily added when expressed in
the rectangular form, the first step in finding the sum
is to express each of the phasors in rectangular form.
In doing this, it should be recalled that the length of
a phasor does not depend upon the time of evalua-
tion. Time does determine a phasor’s angular posi-
tion in the complex plane, but not its length. For
convenience, the rectangular components are deter-
mined for the instant when t = 0. Therefore,
The next step is to add the real parts and
separately to sum the imaginary parts. When the
appropriate values for the sines and cosines are
inserted, the result appears as
In the final step, the rectangular sum is converted
to exponential form and the time dependence is
re-inserted to obtain
This process is depicted graphically in Fig. 6-18
which displays the individual phasors as well as
their sum at the instant t = 0. As time increases, the
entire figure rotates counterclockwise at the angular
speed of 2000π radians per second. The actual
acoustic pressure at the observation point is given
by the real part of pt and is
6.22 Rates of Change
Most of the laws of physics deal with the relation-
ships between physical quantities and the rates at
which these quantities change with respect to time
or position, or both. As an example, Newton’s
second law of motion states that the time rate of
change of linear momentum of a body is equal to the
applied force. Linear momentum itself is the product
of mass and linear velocity, but linear velocity is the
time rate of change of linear position or displace-
ment. In dealing with sinusoidal functions of time or
position, or both, it is important to have mathemat-
ical tools for calculating the rates of change of these
quantities. Lacking such a tool, Sir Isaac Newton
was forced to develop one in the form of what is
now known as differential calculus. The full power
of the differential calculus will not be introduced
here as it is possible to learn the answers at this
point by employing only algebra and a little trigo-
nometry in what follows. Attention should now be
returned to the motion of the loudspeaker cone
which was first described in the section on phasors
p1
1 pascal e
j 2π1000
s
------------t
⎝
⎠
⎛
⎞
=
p2
2 pascal e
j 2π1000
s
------------t
π
4---
+
⎝
⎠
⎛
⎞
=
pt
p1
p2
+
=
p1
1 pascal 
0
( )
cos
j1 pascal 
0
( )
sin
+
=
p2
2 pascal 
π
4---
⎝⎠
⎛⎞
cos
j2 pascal 
π
4---
⎝⎠
⎛⎞
sin
+
=
p1
1 pascal
j0
+
=
p2
2
2
------- pascal
j 2
2
------- pascal
+
=
pt
2.4142 pascal
j1.4142 pascal
+
=
Figure 6-18. Phasor addition of acoustic pressures.
pt
2.7979 pascal e
j 2π1000
s
-------------------t
0.53
+
⎝
⎠
⎛
⎞
=
pt
2.7979 pascal 
2π1000
s
-------------------t
0.53
+
⎝
⎠
⎛
⎞
cos
=
Real Axis
j Axis
p2
pt
p1

Mathematics for Audio Systems
81
Fig. 6-19 is a plot of the cone displacement
versus time where the period has been divided into
20 equal increments of 5 × 10−5  s. This is the
familiar cosine curve.
Fig. 6-20 is a curve constructed by taking succes-
sive differences between the points on Fig. 6-19 and
dividing these differences by the time interval
between points. Fig. 6-20 is thus a plot of change in
position divided by change in time plotted versus
time. This is known as the average velocity plotted
versus time. Denote this average velocity as <u>.
The curve of <u> appears to be a negative sine
curve. The information used in plotting Figs. 6-19
and 6-20 is summarized in Table 6-10. There are
tabular entries for t, x, and <u> as calculated. There
is an additional entry which represents
If one performs the same analysis taking smaller
and smaller time increments, it is observed that the
discrepancy between columns 3 and 4 of Table 6-10
becomes smaller and smaller and in the limit
column 3 becomes identical with column 4 which is
the instantaneous velocity u.
The foregoing conclusion can be arrived at
through a more analytical approach as follows. Use
the phasor description of the motion of the loud-
speaker cone.
(6-89)
Multiply Eq. 6-89 by jω to obtain
(6-90)
Use Euler’s identity to expand the complex expo-
nential to obtain
(6-91)
Finally, take only the real part of Eq. 6-91 and
substitute numerical values to obtain
(6-92)
Eq. 6-92 is the exact expression for the instanta-
neous velocity of the loudspeaker cone. The conclu-
sion to be drawn is that the time rate of change of a
sinusoidal quantity may be obtained by multiplying
the phasor description of the quantity by jω. This
process creates a new phasor, the real part of which
is the true instantaneous time rate of change of the
original sinusoidal time dependent quantity. In the
language of the differential calculus, when working
with phasors, the derivative with respect to time is
obtained simply through multiplication by jω. In
equation form, using calculus notation
(6-93)
Observe, Eq. 6-93 may be solved for x in terms
of u to obtain
.
(6-94)
Figure 6-19. Loudspeaker cone displacement.
Figure 6-20. Average cone velocity.
x
10 6
– meter 
2π1000
s
-------------------t
⎝
⎠
⎛
⎞
cos
×
=
1.0
0.8
0.6
0.4
0.2
0
−0.2
−0.4
−0.6
−0.8
−1.0
0        20        40        60        80       100
Time multiplied by 105
Displacement multiplied by 106
8
6
4
2
0
−2
−4
−6
−8
0       20       40       60       80      100
Time multiplied by 105
<u> multipied by 103
u
2π10
–
3
–  meter
s
-------------
2π103
s
---------------t
⎝
⎠
⎛
⎞
sin
=
Table 6-10. Points of Figs. 1-19 and 1-20
Time (105) 
x (106)
<u> (103) 
u (103)
0
1
2.5
−0.980
−0.982
5.0
0.951
x
xme jωt
=
jωx
jωxme jωt
=
jωx
ωxm j
ωt
(
)
cos
ωt
(
)
sin
–
(
)
=
u
2π10
–
3
–  meter
s
---------------
2π103
s
---------------t
⎝
⎠
⎛
⎞
sin
=
u
dx
dt
------
jωx
=
=
x
u
jω
------
=

82
Chapter 6
This implies that if the time rate of change of a
quantity is known, the quantity itself can be
obtained by dividing its time rate of change by jω.
The process of undoing differentiation with respect
to time is called integration with respect to time.
This is a tool not of the differential calculus but
rather of the integral calculus. In the language of the
integral calculus 
(6-95)
This is the beauty of working with phasors. The
mathematical operations of addition, subtraction,
multiplication, division, differentiation, and integra-
tion can all be carried out employing only arith-
metic, algebra, and a little trigonometry.
Bibliography
J. Backus. The Acoustical Foundations of Music. New York: Norton, 1969.
N. M. Cooke and H. F. R. Adams. Basic Mathematics for Electronics. New York: McGraw-Hill/Gregg Div.,
1976.
A. H. Davis. Modern Acoustics. New York: Macmillan, 1934.
D. Davis. “Calculating Percentages and Ratios,” Syn-Aud-Con Tech Topics, Vol. 6, No. 3 (1979).
O. W. Eschbach. Handbook of Engineering Fundamentals, 2nd ed. New York: Wiley, 1952.
W. Gellert, H. Kustner, M. Hellwich, and H. Kastner, Eds. The VNR Concise Encyclopedia of Mathematics.
New York: Van Nostrand Reinhold, 1977.
H. L. F. Helmholtz, On the Sensations of Tone as a Physiological Basis for the Theory of Music, 2nd ed. New
York: Dover, 1954.
ITT. Reference Data for Radio Engineers, 5th ed. Indianapolis, Ind.: Howard W. Sams, 1968.
M. Kaufman and A. H. Seidman, Eds. Handbook of Electronics Calculations: For Engineers and Techni-
cians. New York: McGraw-Hill, 1979.
H. F. Olson. Solutions of Engineering Problems by Dynamical Analogies, 2nd ed. Princeton, N.J.: van
Nostrand, 1943.
7.5
−2.840
−2.850
10.0
0.809
12.5
−4.420
−4.440
15.0
0.588
17.5
−5.580
−5.590
20.0
0.309
22.5
−6.180
−6.200
25.0
0.000
27.5
−6.180
−6.200
30.0
−0.309
32.5
−5.580
−5.590
35.0
−0.588
37.5
−4.420
−4.440
40.0
−0.809
42.5
−2.840
−2.850
45.0
−0.951
47.5
−0.980
−0.982
50.0
−1.000
52.5
0.980
0.982
55.0
−0.951
57.5
2.840
2.850
60.0
−0.809
62.5
4.420
4.440
65.0
−0.588
67.5
5.580
5.590
70.0
−0.309
72.5
6.180
6.200
Table 6-10.  (cont.) Points of Figs. 1-19 and 1-20
Time (105) 
x (106)
<u> (103) 
u (103)
75.0
0.000
77.5
6.180
6.200
80.0
0.304
82.5
5.580
5.590
85.0
0.588
87.5
4.420
4.440
90.0
0.809
92.5
2.840
2.850
95.0
0.951
97.5
0.980
0.982
100.0
1.000
Table 6-10.  (cont.) Points of Figs. 1-19 and 1-20
Time (105) 
x (106)
<u> (103) 
u (103)
x
u td
∫
u
jω
------
=
=

Mathematics for Audio Systems
83
M. R. Schroeder. “Computers in Acoustics: Symbiosis of an Old Science and a New Tool,” J. Acoust. Soc.
Am., Vol. 45, No. 5 (1969).
————. Number Theory in Science and Communication: With Applications in Cryptography, Physics,
Biology, Digital Information, and Computing. New York: Springer-Verlag, 1984.
R. Story. “Converting Tables to Equations Cuts Program Length for Calculator Use,” Electronics, Vol. 47
(Apr. 18, 1974), pp. 114-115.
S. P. Thompson, Calculus Made Easy. New York: Macmillan, 1937.
H. M. Tremaine, Audio Cyclopedia, 2nd ed. Indianapolis, Ind.: Howard W. Sams, 1969.


Chapter 7
Using the Decibel
by Don Davis
85
7.1 The Decibel  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 87
7.2 The Neper . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 87
7.3 Concepts Underlying the Decibel and Its Use in Sound Systems  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 88
Converting Voltage Ratios to Power Ratios  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 88
The dBV  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 88
The Decibel as a Power Ratio . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 89
The Decibel as a Power Quantity  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 90
7.4 Measuring Electrical Power . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 90
Expressing Power as an Audio Level  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 90
7.5 Levels in dB . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 91
Practical Variations of the dBm Equations  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 91
7.6 The Decibel in Acoustics—LP, LW, and LI  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 92
7.7 Acoustic Intensity Level (LI), Acoustic Power Level (LW), and Acoustic Pressure Level (LP)  . . . . . . . . 93
Acoustic Intensity Level, LI . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 93
Acoustic Power Level, LW . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 93
Acoustic Pressure Level, LP  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 93
7.8 Inverse Square Law  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 93
7.9 Directivity Factor . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 94
7.10 Ohm’s Law . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 94
7.11 A Decibel Is a Decibel Is a Decibel . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 95
Older References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 96
7.12 The Equivalent Level (LEQ) in Noise Measurements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 96
7.13 Combining Decibels . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 97
Adding Decibel Levels  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 97
Subtracting Decibels  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 98
Combining Levels of Uncorrelated Noise Signals  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 98
To Add Levels . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 99
To Subtract Levels . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 99
7.14 Combining Voltage . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 99
7.15 Using the Log Charts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 99
The 10Log x Chart . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 99
The 20Log x Chart . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 100
7.16 Finding the Logarithm of a Number to Any Base . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 100
7.17 Semitone Intervals  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 101
7.18 System Gain Changes  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 101
7.19 The VU and the VI Instrument  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 101
Crest Factor . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 102
The VU Impedance Correction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 102
How to Read the VU Level on a VI Instrument  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 103
Calibrating a VI Instrument . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 104
Reading a VI Instrument on Program Material . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 104
Reading Apparent VU Levels . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 104
7.20 Calculating the Number of Decades in a Frequency Span . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 104
7.21 Deflection of the Eardrum at Various Sound Levels  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 105
7.22 The Phon  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 105
7.23 The Tempered Scale . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 106
7.24 Measuring Distortion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 106
7.25 The Acoustical Meaning of Harmonic Distortion  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 106

86
Calculating the Maximum Allowable Total Harmonic Distortion in an Arena Sound System . . . . . . .107
7.26 Playback Systems in Studios  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .108
Choosing an Amplifier . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .108
7.27 Decibels and Percentages . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .109
7.28 Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .110
Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .110

Using the Decibel
87
With a foundation in mathematics and physics,
audio engineers can accurately describe sound and
manipulate its effects with the decibel. The decibel,
however, has worked its way into common usage. In
the beginning, it was among several units of
measurement.
Prior to 1923 “gains” and “losses” of telephone
circuits were labeled in miles of standard cable
(MSC). A “standard” cable was a 19 gauge open
wire cable with a resistance of 88 Ω/mi and a capaci-
tance of 0.054 µF⁄mi. The standard carbon trans-
mitter’s electrical output level with normal speech
as an input was considered as “zero level” (at that
time 0.006 W). The loss that occurred over one mile
of this “standard” cable very nearly equaled what
Harvey Fletcher was measuring in the Bell Tele-
phone Laboratories as the smallest increment easily
detected by a normal listener and which he labeled
the sensation unit (SU).
In 1923 W. H. Martin wrote in the Bell System
Technical Journal an article introducing the trans-
mission unit (TU) devised to replace both the MSC
and the SU while reconciling both uses to the tele-
phone system as a whole. The TU was defined as:
(7-1)
where,
TU was the transmission unit,
P1 was the power measured,
P2 was the power used as a reference,
N is the numerical value to be labeled as (N) TU.
There were 0.947 MSC to 1.0 TU or 1.056 TU to
1.0MSC.
7.1 The Decibel
In 1929 W. H. Martin wrote again in the Bell System
Technical Journal an article entitled “Decibel The
Name for the Transmission Unit.” As a result of Bell
Telephone’s participation as invited attendees, the
European International Advisory Committee recom-
mended to the various European telephone adminis-
trations that they adapt either the decibel or the
Naperian unit and designate them the “Bel” and the
“neper,” respectively. The Bell system adopted the
Bel, converting it into the deci-Bel (one tenth of a
Bel) for the convenience of higher resolution of the
measured level. Over the 20 years in which they had
used the MSC they found that they could meaning-
fully resolve 0.1 mi. The decibel was defined as the
logarithmic form of that power ratio having a value
of 100.1. Two amounts of power differ by 1 dB
where they are in the ratio of 100.1 and any two
amounts of power differ by (N) dB when they are in
the ratio of 10N (0.1):
(7-2)
where,
N units are labeled dB.
Hereafter it is assumed that log is to the base 10 in
this book unless otherwise stated.
7.2 The Neper
The neper (Np) is defined as:
(7-3)
One neper is a voltage ratio such that:
N nepers is a voltage ratio such that:
or alternatively:
The question arises as to what is the relationship
between the neper and the decibel. Take the voltage
N
(
)TU
10
P1
P2
------
log
=
P1
P2
------
10N 0.1
(
)
=
log10
P1
P2 
-------
⎝
⎠
⎛
⎞
log10 10
N
×
0.1
×
(
)
=
log1010
1
=
log10
P1
P2
------
0.1
-------------------
N
=
10log10
P1
P2
------
N dB
=
E1
E2
------
⎝
⎠
⎛
⎞
ln
N(nepers)
=
E1
E2
------
⎝
⎠
⎛
⎞
e1
=
2.718
=
E1
E2
------
eN
=
2.718…N
=
E1
E2
------
⎝
⎠
⎛
⎞
ln
e
N
×
ln
=
e
ln
1
=
E1
E2
------
ln
N (nepers)
=

88
Chapter 7
ratio corresponding to one neper and square it to put
it into the form of a power ratio and manipulate as
follows:
(7-4)
The conclusion is that one neper is equivalent to
1/8.686 dB which is 0.115 Np ⁄dB. Alternately you
can use the decineper dNp (1 dB = 1.15 dNp).
7.3 Concepts Underlying the Decibel and Its 
Use in Sound Systems
Most system measurements of level start with a
voltage amplitude. Relative level changes at a given
point can be observed on a voltmeter scale when it is
realized that:
(7-5)
which is only true if both values are measured at an
identical point in their circuit. A common usage has
been to remove the exponent from the ratio and
apply it to the multiplier.
(7-6)
Bear in mind that the decibel is always and only
based upon a power ratio. Any other kind of ratio
(i.e., voltage, current, or sound pressure) must first
be turned into a power ratio by squaring and then
converted into a power level in decibels.
7.3.1 Converting Voltage Ratios to Power Ratios
Many audio technicians are confused by the fact that
doubling the voltage results in a 6 dB increase while
doubling the power only results in a 3 dB increase.
Fig. 7-1 demonstrates what happens if we simulta-
neously check both the voltage and power in a
circuit where we double the voltage. Note that for a
doubling of the voltage, the power increases four
times.
7.3.2 The dBV
One of the most common errors when using the
decibel is to regard it as a voltage ratio (i.e., so many
decibels above or below a reference voltage). To
compound the error, the result is referred to as a
“level.” The word “level” is reserved for power; an
increase in the voltage magnitude is properly
referred to as “amplification.”
However, the decibel can be legitimately used
with a voltage reference. The reference is 1.0 V.
When voltage magnitudes are referenced to it loga-
rithmically, they are called dBV (i.e., dB above or
below 1.0 V). This use is legitimate because all such
measurements are made open circuit and can easily
be converted into power levels at any impedance
interface.
The following definition is from the IEEE Stan-
dard Dictionary of Electrical and Electronics
Terms, Second Edition:
244.62
Voltage Amplification (1) (general). An
increase in signal voltage magnitude in
transmission from one point to another or
the process thereof. See also: amplifier.
P1
P2
------
E1
E2
------
⎝
⎠
⎛
⎞
2
=
e2
=
10
P1
P2
------
log
10
e2
log
=
8.686 dB
neper
---------------------
=
10
E1
2
E2
2
--------
log
10
P1
P2
------
log
=
2
10
×
E1
E2
------
log
20
E1
E2
------
log
=
Figure 7-1. Voltage and power relationships in a circuit.
R1=10 Ω
R2=10 Ω
Rs
Rs
10 V
20 V
P1 = E1
2
R1
= 100
10
=10 W
P2 = E2
2
R2
= 400
10
=40 W
A. Initial voltage.
B. Voltage doubled.
10
P1
P2
------
log
10
40  W
10  W
-------------
log
=
6.02  dB
=
10
E1
2
E2
2
--------
log
20
20 V
10 V
-----------
log
=
6.02 dB
=

Using the Decibel
89
210 (2) (transducer). The scalar ratio of the
signal output voltage to the signal input
voltage. Warning: By incorrect extension
of the term decibel, this ratio is sometimes
expressed in decibels by multiplying its
common logarithm by 20. It may be
currently expressed in decilogs. Note: If
the input and/or output power consist of
more than one component, such as multi-
frequency signal or noise, then the partic-
ular components used and their weighting
must be specified. See also: Transducer.
239.210
Decilog (dg). A division of the logarithmic
scale used for measuring the logarithm of
the ratio of two values of any quantity.
Note: Its value is such that the number of
decilogs is equal to 10 times the logarithm
to the base 10 of the ratio. One decilog
therefore corresponds to a ratio of 100.1
(that is 1.25829+).
7.3.3 The Decibel as a Power Ratio
Note that 20 W⁄10 W and 200 W⁄100 W both equal
3.01 dB, which means that a 2 to 1 (2:1) power ratio
exists but reveals nothing about the actual powers.
The human ear hears the same small difference
between 1 W and 2 W as it does between 100 W and
200 W.
Changing decibels back to a power ratio (expo-
nential form) is the same as for any logarithm with
the addition of a multiplier, Fig. 7-2. The arrows in
Fig. 7-2 indicate the transposition of quantities.
Table 7-1 shows the number of decibels corre-
sponding to various power ratios.
Finding Other Multipliers
Occasionally in acoustics, we may need multipliers
other than 10 or 20. Once the ΔdB (the number of
dB for a 2:1 ratio change) is known, calculate the
multiplier by:
(7-7)
For example, if a 2:1 change is equivalent to
3.01dB, then:
or
If a 2:1 change is equivalent to 6.02 dB, then:
or
Finally, if a 2:1 change is equivalent to 8 dB, then:
or
For any ΔdB corresponding to a 2:1 ratio change
involving logarithms to the base 10, this may be
reduced to:
(7-8)
Figure 7-2. Conversion of dB from logarithmic form to
exponential form.
M  logb  a   =   NM 
c
a
c = b
NM
M
(
)
10  log10 2 =   3.01 dB
=10
3.01
10
(
)
2
Logarithmic Form
Exponential Form
Table 7-1. Power Ratios in Decibels
Power Ratio
Decibels (dB)
2
3.01030
3
4.77121
4
6.02060
5
6.98970
6
7.78151
7
8.45098
log multiplier
Base
(
)
log
ΔdB
×
Ratio
(
)
log
-------------------------------------------
=
log multiplier
Base
(
)
log
3.01
×
2
log
------------------------------------------ 
=
10
=
10
2
log
3.01
=
log multiplier
Base
(
)
log
6.02
×
2
log
------------------------------------------ 
=
20
=
20
2
log
6.02
=
log multiplier
Base
(
)
log
8
×
2
log
----------------------------------- 
=
26.58
=
26.58
2
log
8
=
log multiplier
3.332
ΔdB
×
=

90
Chapter 7
7.3.4 The Decibel as a Power Quantity
We have seen that a number of decibels by them-
selves are only ratios. Given any reference (such as
50 W), we can use decibels to find absolute values.
A standard reference for power in audio work is
10−3W (0.001 W) or x V across Z Ω . Note that when
a level is expressed as a wattage, it is not necessary
to state an impedance, but when it is stated as a
voltage, an impedance is mandatory. This power is
called 0dBm. The small “m” stands for milliwatt
(0.001W) or one-thousandth of a watt.
Example
The power in watts corresponding to +30 dBm is
calculated as follows:
For a power of −12 dBm:
The voltage across 600 Ω is:
Note that this −12 dBm power level can appear
across any impedance and will always be the same
power level. Voltages will vary to maintain this
power level. In constant-voltage systems the power
level varies as the impedance is changed. In
constant-current systems the voltage changes as the
impedance varies. (i.e.: −12  dBm across
8Ω =
7.4 Measuring Electrical Power
(7-9)
(7-10)
(7-11)
where,
W is the power in watts,
E is the electromotive force in rms volts,
I is the current in rms amperes,
Z is the magnitude of the impedance in ohms [in
audio (ac) circuits Z (impedance) is used in place
of R (ac resistance)],
θ is the phase difference between E and I in degrees.
These equations are only valid for single frequency
rms sine wave voltages and currents.
Most Common Technique
1.
Measure Z and θ.
2.
Measure E across the actual load Z so that
.
7.4.1 Expressing Power as an Audio Level
The reference power is 0.001 W (one milliwatt).
When expressed as a level, this power is called
0dBm (0 dB referenced to 1 mW).
Thus, to express a power level we need two
powers—first the measured power W1 and second
the reference power W2. This can be written as a
power change in dB:
(7-12)
This can be written as a power level:
8
9.03090
9
9.54243
10
10.00000
100
20.00000
1000
30.00000
10,000
40.00000
100,000
50.00000
1,000,000
60.00000
Table 7-1.  (cont.) Power Ratios in Decibels
Power Ratio
Decibels (dB)
10
x
0.001
-------------
log
30
=
where x
0.001
10
30
10
------
×
=
1 W
=
0.001
10
12
–
10
---------
×
0.00006309 W
=
E
WR
=
0.00006309
600
×
=
0.195 V
=
0.00006309
8
×
0.022 V)
=
W
EI
θ
cos
=
W
I2Z
θ
cos
=
W
E2
Z------
θ
cos
=
W
E2 Z
⁄
(
)
θ
cos
=
W1
W2
-------
E1
2
1
--------
E2
2
1
--------
--------
⎝
⎠
⎜
⎟
⎜
⎟
⎜
⎟
⎜
⎟
⎛
⎞
1
R1
------
1
R2
------
------
⎝
⎠
⎜
⎟
⎜
⎟
⎜
⎟
⎛
⎞
=
E1
2
E2
2
--------
⎝
⎠
⎜
⎟
⎛
⎞R2
R1
------
⎝
⎠
⎛
⎞
=

Using the Decibel
91
(7-13)
or
(7-14)
Special Circumstance
When R1 = R2 and only then:
(7-15)
where,
E2 is the voltage associated with the reference
power.
Conventional Practice
When calculating power level in dBm, we
commonly make E2 = 0.775 V and R2 = 600 Ω . Note
that E2 may be any voltage and R2 any resistance so
long as together they represent 0.001 W.
7.5 Levels in dB
1.
The term “level” is always used for a power
expressed in decibels.
2.
when R1 = R2
3.
Power definitions:
Apparent power = E × I or E2 ⁄ Z,
The average real or absorbed power is
(E2⁄Z)cosθ,
The reactive power is (E2 ⁄ Z)sin θ,
Power factor = cos θ.
4.
The term “gain” or “loss” always means the
power gain or power loss at the system’s output
due to the device under test.
7.5.1 Practical Variations of the dBm Equations
When the reference is the audio standard, i.e.,
0.77459 V and 600 Ω, then:
(7-16)
where,
E2 = 0.77459...V,
R2 = 600 Ω.
then:
and 1⁄1000 = 0.001. Note that any E2 and R2 that
result in a power of 0.001 W may be used. We can
then write:
(7-17)
and
(7-18)
(7-19)
See Fig. 7-3.
For all of the values in Table 7-2 the only thing
known is the voltage. The indication is not a level.
The apparent level can only be true across the actual
reference impedance. Finally, the presence or
absence of an attenuator or other sensitivity control is
not known. See Section 7.20 for explanation of VU.
The power output of Boulder Dam is said to be
approximately 3,160,000,000 W. Expressed in dBm,
this output would be:
.
10
E1
2
E2
2
--------
⎝
⎠
⎜
⎟
⎛
⎞R2
R1
------
⎝
⎠
⎛
⎞ 
power change in dB
=
log
20
E1
E2
------
log
10
R2
R1
------ 
power change in dB
=
log
+
Power level in dB
20
E1
E2
------
log
=
10
E1
2
E2
2
--------
log
10
W1
W2
-------
log
=
2
10
E1
E2
------
log
×
20
E1
E2
------
log
=
10
W1
W2
-------
log
=
dB level to a reference
10
E1
2
E2
2
--------
⎝
⎠
⎜
⎟
⎛
⎞R2
R1
------
⎝
⎠
⎛
⎞
log
=
R2
E2
2
--------
1000
=
Level (in dBm)
10
E1
2
0.001R1
-------------------
log
=
E1
0.001R1 10
dBm 
10
-------------
⎝
⎠
⎜
⎟
⎛
⎞
=
R1
E2
0.001 10
dBm 
10
-------------
⎝
⎠
⎜
⎟
⎛
⎞
-----------------------------------
=
10
3.16
109
×
10 3
–
-------------------------
log
125 dBm
=

92
Chapter 7
7.6 The Decibel in Acoustics—LP, LW, and LI
In acoustics, the ratios most commonly encountered
are changes in pressure levels. First, there must be a
reference. The older level was 0.0002 dyn ⁄ cm2, but
this has recently been changed to 0.00002 N ⁄ m2
(20µN ⁄ m2). Note that 0.0002 dyn ⁄ cm2 is exactly the
same sound pressure as 0.00002 N ⁄ m2. Even more
recently the standards group has named this same
pressure pascals (Pa) and arranged this new unit so
that:
(7-20)
This means that if the pressure is measured in
pascals:
(7-21)
If the pressure is measured in dynes per square
centimeter (dyn ⁄ cm2), then:
(7-22)
The root mean square sound pressure P can be
found by:
(7-23)
where,
Prms is in pascals, 
f is the frequency in Hertz (Hz),
A is particle displacement in meters (rms value),
ρ is the density of air in kilograms per cubic meter
(kg/m3),
c is the velocity of sound in meters per second (m/s),
ρc = 406 RAYLS and is called the characteristic
acoustic resistance (this value can vary),
or
(7-24)
These are identical sound pressure levels bearing
different labels. Sound pressure levels were identi-
fied as dB-SPL, and sound power levels were identi-
fied as dB-PWL. Currently, LP is preferred for sound
pressure level and LW for sound power level. Sound
intensity level is LI:
(7-25)
At sea level, atmospheric pressure is equal to
2116 1b/ft2. Remember the old physics lab stunt of
partially filling an oil can with water, boiling the
water, and then quickly sealing the can and putting it
under the cold water faucet to condense the steam so
that the atmospheric pressure would crush the can as
the steam condensed, leaving a partial vacuum?
therefore,
This represents the complete modulation of
atmospheric pressure and would be the largest
possible sinusoid. Note that the sound pressure (SP)
is analogous to voltage. An LP of 200 dB is the pres-
sure generated by 50 lb of TNT at 10 ft. Table 7-3
shows the equivalents of sound pressure levels.
Figure 7-3. Power in dB across a load versus available
input power.
Table 7-2. Root Mean Square Voltages Used as 
Nonstandard References
Voltage–V
Meter
Indication
Apparent 
Level–VU
User
1.950
0
+8
Broadcast
1.230
0
+4
Recording
0.245
0
−10
Home recording
0.138
0
−15
Musical instruments
RS
RS
RL
RIN
EIN
ES
EL
A. Power across a load in dBm.
B. Available input power in dBm.
20μPa
0.0002  dyn
cm2
--------------------------
=
LP
20
x Pa
20 μPa
------------------
log
=
LP
20
x dyn cm2
⁄
(
)
0.0002 dyn cm2
⁄
(
)
----------------------------------------------
log
=
Prms
2πfAρc
=
LP
20
Prms
20 μPa
-----------------
log
=
LI
10
x W/m2
10 12
–
 W/m2
-----------------------------
log
=
1Atm
101,300 Pa
=
LP
20
101,300 
0.00002
---------------------
log
=
194  dB
=

Using the Decibel
93
For additional insights into these basic relation-
ships, the Handbook of Noise Measurement by
Peterson and Gross is thorough, accurate, and
readable.
7.7 Acoustic Intensity Level (LI), Acoustic 
Power Level (LW), and Acoustic Pressure Level 
(LP)
7.7.1 Acoustic Intensity Level, LI
The acoustic intensity Ia (the acoustic power per unit
of area—usually in W/m2 or W/cm2 is found by:
(7-26)
7.7.2 Acoustic Power Level, LW
The total acoustic power can also be expressed as a
level (LW):
(7-27)
7.7.3 Acoustic Pressure Level, LP
To identify each of these parameters more clearly,
consider a sphere with a radius of 0.282 m. (Since
the surface area of a sphere equals 4πr2, this yields a
sphere with a surface area of 1 m2.) An omnidirec-
tional point source radiating one acoustic watt is
placed into the center of this sphere. Thus, we have,
by definition, an acoustic intensity at the surface of
the sphere of 1W/m2. From this we can calculate the
Prms:
(7-28)
where,
Wa is the total acoustic power in watts,
ρc equals 406 RAYLS and is called the characteristic
acoustic resistance.
Knowing the acoustic watts, Prms is easy to find:
Thus, the LP must be:
And the acoustic power level in LW must be:
Thus, the LP , LI , and LW at 0.282 m are the same
numerical value if the source is omnidirectional, see
Fig. 7-4.
7.8 Inverse Square Law
If we double the radius of the sphere to 0.564 m, the
surface area of the sphere quadruples because the
radius is squared in the area equation (A = 4πr2).
Thus, our intensity will drop to one-fourth its former
value. (Note, however, that the total acoustic power
is still 1 W so the LW still is 120 dB.) Now an inten-
sity change from 1 W to 0.25 W/m2 can be written as
a decibel change. The acoustic intensity (i.e., the
power per unit of area), has dropped 6 dB in any
given area:
Table 7-3. Equivalents of Pressure Levels
Older values of a similar nature are:
1 microbar ≅ 1⁄1,000,000 of atmospheric pressure
≅ 74 dB
therefore,
1 Pa = 10 dyn⁄cm2
Other interesting figures:
Atmospheric pressure fully modulated LP ≅ 194 dB
1 lb/ft2 LP = 127.6 dB
1 lb/in2 LP = 170.8 dB
50 lb of TNT measured at 10 ft LP = 200 dB
12 inch cannon, 12 ft in front of and below muzzle LP  
= 220+ dB
Courtesy GenRad Handbook
LP
20
1 N m2
⁄
0.00002  N m2
⁄
------------------------------------
log
=
93.98  dB
=
LI
10
xW m2
⁄
10 12
–
W m2
⁄
------------------------------
log
=
LI
10
1.0W m2
⁄
10 12
–
 W m2
⁄
-------------------------------
log
=
120 dB
=
LW
10
Total acoustic watts
10 12
–
 W
------------------------------------------------
log
=
Prms
10Wa
ρc
×
=
Prms
10Wa
406
×
=
20.15  Pa
=
LP
20
20.15 Pa
20 μPa
--------------------
log
=
120  dB
=
LW
10
1 W
10 12
–
 W
--------------------
log
=
120  dB
=

94
Chapter 7
Therefore, our LP had to also drop 6 dB and
would now be approximately 114 dB.
This effect is commonly called the inverse square
law change in level. Gravity, light, and many other
physical effects exhibit this rate of change with
varying distance from a source. Obviously, if you
halve the radius, the levels all rise by 6 dB.
7.9 Directivity Factor
Finally, make the point source radiating one acoustic
watt a hemispherical radiator instead of an omnidi-
rectional one. Thus, at 0.282 m the surface area is
now half of what our sphere had or 0.5 m2. There-
fore, our intensity is now 1 W ⁄ 0.5 m2 or the equiva-
lent 2 W ⁄ m2:
Therefore, our LP is 123.01 dB. Lw remains 120 dB.
This 3.01 dB change represents a 2:1 change in the
power per unit area; thus, a hemispherical radiator is
said to have twice the directivity factor a spherical
radiator has. Directivity factor is identified by a
number of symbols—DF , Q, Rθ, λ, M, etc. Q is the
most widely used in the United States so we have
chosen it for this text. (See Chapter 4 Loudspeaker
Directivity and Coverage for a complete definition
of Q.)
Directivity can also be expressed as a solid angle
in steradians or sr = 4π/Q.
7.10 Ohm’s Law
Recall that the use of the term “decibel” always
implies a power ratio. Power itself is rarely
measured as such. The most common quantity
measured is voltage. If in measuring the voltage of a
sinewave signal (oscillators are the most reliable and
common of the test-signal sources) you obtain the
root-mean square (rms) voltage, you can calculate
the average power developed by using Ohm’s law.
Fig. 7-5 is a reminder of its many basic forms and
uses the following definitions:
1.
W is the average electrical power in watts (W).
IF
Figure 7-4. Relationship of spherical surface area to
radius.
A = 1 m2
A = 4 m2
A = 4πr2
r = 0.564 m
r = 0.282 m
A. Sphere and radius.
B. Area increases with the square of the radius.
A
A
A
A
C. Area increases with the square of the radius
when both angles diverge.
D Area increases as the radius increases
when only one angle diverges.
LI
10
0.25 W/m2
(
) new measurement
(
)
1 W/m2
(
)
original reference
at the shorter radius
⎝
⎠
⎛
⎞
--------------------------------------------------------------------------------
log
=
6.02  dB
–
=
10
2  W m2
⁄
1  W m2
⁄
---------------------
log
3.01  dB
=

Using the Decibel
95
2.
I is the rms electrical current in amperes (A).
3.
R is the electrical resistance in ohms (Ω).
4.
E is the electromotive force in rms volts (V).
5.
PF is the power factor (cos θ).
7.11 A Decibel Is a Decibel Is a Decibel
The decibel is always a power ratio; therefore, when
dealing with quantities that are not power ratios, i.e.,
voltage, use the multiplier 20 in place of 10. As we
encounter each reference for the dB, we will indi-
cate the correct multiplier. Table 7-4 lists all the
standard references, and Tables 7-5 through 7-8
contain additional information regarding reference
labels and quantities. The decibel is not a unit of
measurement like an inch, a watt, a liter, or a gram.
It is the logarithm of a nondimensional ratio of two
powerlike quantities.
For Lp = 20log(x Pa ⁄ 0.00002 Pa) use Eq.7-29.
(7-29)
Figure 7-5. Ohm’s law nomograph for ac or dc.
Table 7-4. Common Decibel Notations and 
References
Quantity
Standard
Reference
Symbol
Log
Multiplier
Sound pressure
water: 1 dyn/cm2
air: 0.0002 dyn/cm2
or 0.00002 N/m2 SPL or LP
20
Sound intensity 10−16 W/cm2
10−12 W/m2
10
Sound power
10−12 W (new)
10−13 W (old)
PWL
or Lw
10
Audio power
10−3 W
dBm
10
EMF
1 V
dBV
20
Amperes
1 mA
20
WR
(PF)
WZ
or
EI or EI(PF)
W
W
W
W
W
W
W
W
W
W
I
I(PF)
or
IR or IZ
E2
E2
(PF)
or
I2
I2(PF)
or
E
I
R or Z
R
or
(PF)
(PF)
E
E
or
W
I
E
E2
E2
R
Z (PF)
or
E
R
E
Z
or
(PF)
I2R or I2Z
Z
Acceleration
1 grms
20
Acceleration
Spectral density
1 g2/Hz
10
Volume units
10−3 W
VU
10
Distance
1 ft or 1 m
ΔDx
20
Noise-ref
−90 dBm at 1 kHz
dBm
10
Table 7-5. Preferred Reference Labels for Acoustic Levels
Name
Definition
Sound pressure squared level
LP = 20 log (p ⁄po) dB
Vibratory acceleration level
La = 20 log (a ⁄ao) dB
Vibratory velocity level
LV = 20 log (v ⁄vo) dB
Vibratory force level
LF = 20 log (F⁄ Fo) dB
Power level
LW = 10 log (P⁄ Po) dB
Intensity level
LI = 10 log (I ⁄ Io) dB
Energy density level
LE = 10 log (E ⁄ Eo) dB
Table 7-6. A-Weighted Recommended Descriptor List
Term
Symbol
A-weighted sound level
LA
A-weighted sound power level
LWA
Maximum A-weighted sound level
Lmax
Peak A-weighted sound level
L pk
Level exceeded x% of the time
Lx
Equivalent sound level
Leq
Equivalent sound level over time (T)
Leq(T)
Day sound level
Ld
Night sound level
Ln
Day-night sound level
Ldn
Yearly day-night sound level
Ldn(Y)
Sound exposure level
LSE
Table 7-7. Associated Standard Reference Values
1 atm = 1.013 bar = 1.033 kpa/cm2 = 14.70 lb/in2 = 
760 mm Hg = 29.92 in Hg
Acceleration of Gravity: g = 980.665 cm⁄s2 =32.174 ft ⁄s2 
(standard or accepted value)
Sound Level: The common reference level is the 
audibility threshold at 1000 Hz, i.e., 0.0002 dyn ⁄cm2, 
2 × 10-4µbar, 2 × 10-5 N ⁄m2, 10-16 W⁄cm2
Table 7-4.  (cont.) Common Decibel Notations and 
References
Quantity
Standard
Reference
Symbol
Log
Multiplier
dB
Logarithm Multiplier
Quantity
Standard Reference
-----------------------------------------------
log
×
=
LP
20
x Pa
log
94
+
(
) dB
=

96
Chapter 7
7.11.1 Older References
Much earlier, but valuable, literature used 10−13 W
as a reference. In that case, the LP value approxi-
mately equals the LW value at 0.282 ft from an omni-
directional radiator in a free field (i.e., the number
values are the same but, of course, different quanti-
ties are being measured). For 1 W using 10−12 W at
0.283 m, LW ≅ LP = 120 dB. For 1 W using 10−13 W at
0.282  ft, LW ≅ LP = 130  dB as found with the
equation:
(7-30)
where,
LW is 10log the wattage divided by the reference
power 10−13,
r is the distance in meters from the center of the
sound source.
Fig. 7-6 requires that you either know the
distance from the source or assumes you are in the
steady reverberant sound field of an enclosed space.
LP readings without one of these is meaningless.
Fig. 7-7 shows typical power and LW values for
various acoustic sources.
7.12 The Equivalent Level (LEQ) in Noise 
Measurements
Increasingly, acoustical workers in the noise control
field are erecting an interesting edifice of measure-
ment systems. A number of these measurement
systems are based on the concept of average energy.
Suppose, for example, that we have some means of
collecting all of the A-weighted sound energy that
arrives at a particular location over a certain period
of time such as 90 dBA for 3.6 s (this could be a
series of levels that lasted seconds, hours, or even
days). We can then calculate the decibel level of
steady noise for, say, 1 h that would be the equiva-
lent level of the dBA for 3.6 s. That is, we wish to
find the energy equivalent level for 1 h:
(7-31)
where,
PA is the acoustic pressure,
Po is the reference acoustic pressure,
3600 s is the averaging time interval.
This integration reduces to
Table 7-8. Recommended Descriptor List
Term
A-Weighting
Alternative*
A-Weighting
Other Weighting†
Unweighted
Sound (pressure) level**
LA
LpA
LB, LpB
LP
Sound power level
LWA
LWB
LW
Max sound level
Lmax
L Amax
LBmax
Lpmax
Peak sound (pressure) level
LApk
L Bpk
Lpk
Level exceeded x% of the time
Lx
LAx
LBx
LPx
Equivalent sound level
Leq
L Aeq
LBeq
Lpeq
Equivalent sound level over time (T)‡
Leq(T)
LAeq(T)
LBeq(T)
Lpeq(T)
Day sound level
Ld
LAd
LBd
Lpd
Night sound level
Ln
LAn
LBn
Lpn
Day-night sound level
Ldn
LAdn
LBdn
Lpdn
Yearly day-night sound level
Ldn(Y)
LAdn(Y)
LBdn(Y)
Lpdn(Y)
Sound exposure level
LS
LSA
LSB
LSp
Energy average value over (nontime 
domain) set of observations
Leq(e)
LAeq(e)
LBeq(e)
Lpeg(e)
Level exceeded x% of the total set of 
(nontime domain) observations
Lx(e)
LAx(e)
LBx(e)
Lpx(e)
Average Lx value
Lx
LAx
LBx
Lpx
*“Alternative” symbols may be used to assure clarity or consistency.
†Only B-weighting shown. Applies also to C, D, E weighting.
**The term “pressure” is used only for the unweighted level.
‡Unless otherwise specified, time is in hours (e.g., the hourly equivalent level is Leq(1)). Time may be specified in nonquanti-
tative terms (e.g., could be specified as Leq(WASH) to mean the washing cycle noise for a washing machine).
LP
LW
10
4πr2
(
)
log
–
=
LEQ
10
1
3600s
--------------
PA
2
Po
2
--------- td
0
3.6s
∫
⎝
⎠
⎜
⎟
⎜
⎟
⎛
⎞
 in decibels
log
=

Using the Decibel
97
Thus, 1.0 hour of noise energy at 60 dBA is the
equivalent energy exposure of 90 dBA for 3.6 s.
LDN (day-night level), CNEL (community noise
level), etc., all follow similar schemes with variation
in weightings for differing times of day, etc.
It is of interest that shooting a 0.458 magnum
174.7 LP (peak) for 2.5 ms translates into:
of steady sound for 1 h. OSHA allows only 15 min of
exposure to levels of 110dBA–115dBA. As Howard
Ruark’s African guide, Harry Selby, remarked after
Ruark had accidentally set off both barrels at once of
a 0.470 express rifle while being charged by a Cape
buffalo, “One of you ought to get up.”
7.13 Combining Decibels
7.13.1 Adding Decibel Levels
The sum of two or more levels expressed in dB may
be found as follows:
(7-32)
If, for example, we have a noisy piece of
machinery with an LP = 90 dB, and wish to turn on a
second machine with an LP = 90 dB, we need to
know the combined LP . Since both measured levels
are the result of the power being applied to the
machine, with some percentage being converted into
acoustic power, we can determine LT by using
Eq. 7-33. Therefore:
Doubling the acoustic power results in a 3  dB
increase.
An alternative dB addition technique is given
through the courtesy of Gary Berner.
(7-33)
Example
If we wish to add 90 dB to 96 dB, using Eq. 7-33,
take the difference in dB (6 dB) and put it in the
equation:
Input signals to a mixing network also combine
in this same manner, but the insertion loss of the
LEQ
10
10
90
10
------
3.6 s
×
3600  s
----------------------------
⎝
⎠
⎜
⎟
⎜
⎟
⎛
⎞
log
=
LEQ
10
10
174.7
10
-------------
0.0025 s
×
3600 s
------------------------------------------
⎝
⎠
⎜
⎟
⎜
⎟
⎛
⎞
log
=
113.12 dB
=
LT
10
10
L1
10
------
10
L2
10
------
…
10
LN 
10
--------
+
+
+
⎝
⎠
⎜
⎟
⎛
⎞
log
=
LT
10
10
90
10
------
10
90
10
------
+
⎝
⎠
⎜
⎟
⎛
⎞
log
=
10
109
10
+
9
(
)
log
=
10
2
109
×
(
)
log
=
93 dB
=
Figure 7-6. Typical A-weighted sound levels as
measured with a sound level meter. (Courtesy GenRad)
50 hp siren (100 ft)
Jet takeoff (200 ft)
Riveting machine*
Cut-off saw*
Pneumatic hammer*
Textile weaving plant*
Subway train (20 ft)
Pneumatic drill (50 ft)
Freight train (100 ft)
Vacuum cleaner (10 ft)
Speech (1 ft)
140
130
120
110
100
90
80
70
60
50
40
30
20
10
0
Large transformer (200 ft)
Soft whisper (5 ft)
At a given distance
from the source
Decibels
re: 20 mN/m2
Environmental
Casting shakeout area
Electric furnace area
Boiler room
Printing press plant
Tabulating room
Inside sport car (50 mph)
Near freeway (auto traffic)
Large store
Accounting office
Private business office
Light traffic (100 ft)
Average residence
Minimun levels - residential
Areas in Chicago at night
Studio (speech)
Studio (sound recording)
Threshold of hearing
youths–1000 to 4000 Hz
*operator position
LT
10
10
diff in dB
(
)
–
10
------------------------------
1
+
⎝
⎠
⎜
⎟
⎛
⎞
log
smallest number
+
=
LT
10
10
6
10
------
1
+
⎝
⎠
⎜
⎟
⎛
⎞
log
90
+
=
96.97 dB
=

98
Chapter 7
network must be subtracted. Two phase-coherent
sinewave signals of equal amplitude will combine to
give a level 6 dB higher than either sinewave.
The general case equation for adding either
sound pressure, voltages, or currents is:
(7-34)
Table 7-9 shows the effects of adding two equal
amplitude signals with different phase together
using Eq. 7-36.
7.13.2 Subtracting Decibels
The difference of two levels expressed in dB may be
found as follows:
(7-35)
7.13.3 Combining Levels of Uncorrelated Noise 
Signals
When the sound level of a source is measured in the
presence of noise, it is necessary to subtract out the
effect of the noise on the reading. First, take a
reading of the source and the noise combined
(LS + N). Then take another reading of the noise
alone (the source having been shut off ). The second
reading is designated LN. Then:
(7-36)
To combine the levels of uncorrelated noise
signals we can also use the chart in Fig. 7-8 as
follows
Figure 7-7. Typical power and LW values for various
acoustic sources.
170
160
150
140
130
120
110
100
90
80
70
60
50
40
30
100,000
10,000
1000
100
10
1
0.1
0.01
0.001
0.0001
0.000 01
0.000 001
0.000 000 1
0.000 000 01
0.000 000 001
Power
(watts)
Power Level
dB re: 10-12W
Source
20 to 40 million 195 Saturn  rocket
Ram jet
Turbojet engine with afterburner
Turbojet engine (7000 lb thrust)
4 propeller airliner
75-piece orchestra
Pipe organ
Small aircraft engine
Large chipping hammer
Piano
BBb tuba
Blaring radio
Centrifugal ventilating fan (13,000 CFM)
4-ft loom
Auto on highway
Vane axial ventilating fan (1500 CFM)
Voice—shouting (average long term rms)
Voice—conversational level
(average long-time rms)
Voice—very soft wisper
Peak rms values
in 1/8 s intervals
Peak rms values
in 1/8  s intervals
}
}
Combined LP =
20
10
E1
20
------
⎝
⎠
⎜
⎟
⎛
⎞
2
10
E2
20
------
⎝
⎠
⎜
⎟
⎛
⎞
2
2 10
E1
20
------
⎝
⎠
⎜
⎟
⎛
⎞10
E2
20
------
⎝
⎠
⎜
⎟
⎛
⎞
a1 a2
–
[
]
cos
(
)
+
+
log
Table 7-9. Combining Pure Tones of the Same 
Frequency but Differing Phase Angles
Signal 1 
Amplitude,
LP in dB
Signal 1 
Phase,
in 
Degrees
Signal 2 
Amplitude,
LP in dB
Signal 2 
Phase,
in 
Degrees
Combined 
Signal 
Amplitude, 
LP in dB
90
0
+90
0
96.02
90
0
+90
10
95.99
90
0
+90
20
95.89
90
0
+90
30
95.72
90
0
+90
40
95.48
90
0
+90
50
95.17
90
0
+90
60
94.77
90
0
+90
70
94.29
90
0
+90
80
93.71
90
0
+90
90
93.01
90
0
+90
100
92.18
90
0
+90
110
91.19
90
0
+90
120
90.00
90
0
+90
130
88.54
90
0
+90
140
86.70
90
0
+90
150
84.28
90
0
+90
160
80.81
90
0
+90
170
74.83
90
0
+90
180
−∞
Ldiff
10
10
Total Level
10
-------------------------------
Level with one
source off
10
-----------------------------------------
–
⎝
⎠
⎜
⎟
⎜
⎟
⎜
⎟
⎛
⎞
log
=
LS
10
10
LS
N
+
10
---------------
10
LN 
10
--------
–
⎝
⎠
⎜
⎟
⎛
⎞
log
=

Using the Decibel
99
7.13.4 To Add Levels
Enter the chart with the numerical difference
between the two levels being added (top of chart).
Follow the line corresponding to this value to its
intersection with the curved line; then move left to
read the numerical difference between the total and
larger levels. Add this value to the larger level to
determine the total.
Example
To add 75 dB to 80 dB, subtract 75 dB from 80 dB;
the difference is 5 dB. In Fig. 7-8, the 5 dB line inter-
sects the curved line at 1.2 dB on the vertical scale.
Thus the total value is 80 dB + 1.2 dB, or 81.2dB.
7.13.5 To Subtract Levels
Enter the chart in Fig. 7-8 with the numerical differ-
ence between the total and larger levels if this value
is less than 3 dB. Enter the chart with the numerical
difference between the total and smaller levels if this
value is between 3 dB and 14 dB. Follow the line
corresponding to this value to its intersection with
the curved line, then either left or down to read the
numerical difference between total and larger
(smaller) levels. Subtract this value from the total
level to determine the unknown level.
Example
Subtract 81 dB from 90 dB; the difference is 9 dB.
The 9 dB vertical line intersects the curved line at
0.6 dB on the vertical scale. Thus the unknown level
is 90 dB − 0.6 dB, or 89.4 dB.
7.14 Combining Voltage
To combine voltages, use the following equation:
(7-37)
where,
ET is the total sound pressure, current, or voltage,
E1 is the sound pressure, current, or voltage of the
first signal,
E2 is the sound pressure, current, or voltage of the
second signal,
a1 is the phase angle of signal one,
a2 is the phase angle of signal two.
7.15 Using the Log Charts
7.15.1 The 10Log x Chart
There are two scales on the top of the 10log10 x chart
in Fig. 7-9. One is in dB above and below a 1W
reference level, and the other is in dBm (reference
0.001 W). Power ratios may be read directly from
the 1 W dB scale.
Example
How many decibels is a 25:1 power ratio?
1.
Look up 25 on the Power–watts scale.
2.
Read 14 dB directly above the 25.
Figure 7-8. Chart used for determining the combined
level of uncorrelated noise signals.
2.0
1.2
0     1      2    3     4     5    6     7   8    9  10 11 12  13
Numerical difference between two levels being added–dB
3    4    5     6    7     8    9   10   11   12  13  14
Numerical difference between total
and larger levels–dB
3.0
1.0
0.6
0
Numerical difference between total
and smaller levels–dB
ET
E1
2
E2
2
2E1E2
a1
a2
–
(
)
cos
[
]
+
+
=
Figure 7-9. The 10log10 x chart.
1000    400   200   100  60 40     20     10   6   4       2       1   0.6 0.4    0.2    0.1      0.04  0.02  0.01    0.004 0.002 0.001
30                          20                         10                           0                        −10                        −20                        −30 
60                          50                         40                          30                        20                         10                           0
Decibels above and below a one-watt reference level
dBm
Power–watts

100
Chapter 7
Example
We have a 100 W amplifier but plan to use a 12 dB
margin for “head room.” How many watts will our
program level be?
1.
Above 100 W find +50 dBm.
2.
Subtract 12 dB from 50 dBm to obtain +38dBm.
Just below +38 dBm find approximately 6 W.
Example
A 100 W amplifier has 64 dB of gain. What input
level in dBm will drive it to full power?
1.
Above 100 W read +50 dBm.
2.
+50 dBm − 64 dB gain = −14 dBm.
Example
A loudspeaker has a sensitivity of LP = 99 dB at 4ft
with a 1 W input. How many watts are needed to
have an LP of 115 at 4 ft?
1.
115 LP − 99 LP = +16 dB.
2.
At +16 on the 1 W scale read 39.8 W.
7.15.2 The 20Log x Chart
Refer to the chart in Fig. 7-10. A 2:1 voltage,
distance, or sound pressure change is found by
locating 2 on the ratio or D scale and looking
directly above to 6 dB.
Example
A loudspeaker has a sensitivity of LP = 99 dB at 4 ft
with 1 W of input power. What will the level be at
100 ft?
1.
Find the relative dB for 4 ft (dBRel = 12dB).
2.
Find the relative dB for 100 ft (dBRel = 40dB).
3.
Calculate the absolute dB (40 dB − 12 dB =
28dB).
4.
LP = 99 dB − 28 dB = 71 dB.
Example
If we raise the voltage from 2 V to 10 V, how many
decibels would we increase the power?
1.
Find the relative dB for a ratio of 2 (dBRel = 6dB).
2.
Find the relative dB for a ratio of 10 (dBRel =
20dB).
3.
Absolute dB change = 20 dB − 6 dB = 14 dB.
4.
Since a dB is a dB, the power also changed by
14dB.
7.16 Finding the Logarithm of a Number to 
Any Base
In communication theory, the base 2 is used. Occa-
sionally other bases are chosen. To find the loga-
rithm of a number to any possible given base, write:
(7-38)
where,
x is the number for which a logarithm is to be found,
b is the base,
n is the logarithm.
Then write:
(7-39)
and
(7-40)
x
bn
=
x
log
n
b
log
=
x
log
b
log
-----------
n
=
Figure 7-10. The 20log10 x chart.
0             5            10           15            20           25            30           35           40            45           50            55           60
1                2                4         6      8   10              20               40       50    80 100            200            400     600       1000 
0                  -10                  -20                  -30                 -40
1.0      0.6    0.4         0.2         0.1    0.06   0.04       0.02       0.01
ΔD–dB
Ratio or D–feet
Ratio or D–feet
ΔD–dB

Using the Decibel
101
Suppose we want to find the natural logarithm of
2 (written ln2). The base of natural logarithms is
e = 2.7188281828. Then:
To verify this result:
To find log2 of 26:
The general case is:
(7-41)
7.17 Semitone Intervals
Suppose that we need 
 (the semitone interval in
music). We could write:
(7-42)
Therefore,
This is the same as multiplying 1.05946 by itself 12
times to obtain 2.
100.02508 is called the antilog of 0.02508. The
antilog is also written as log−1, antilog 10, or 10 exp.
All these terms mean exactly the same thing.
7.18 System Gain Changes
Imagine a noise generator driving a power amplifier
and a loudspeaker, Fig. 72-11. If the voltage out of
the noise generator is raised by 6 dB, what happens?
This means that, in a linear system, a level
change ahead of any components results in a level
change for that same signal in all subsequent
components, though it might be measured as quite
different voltages or wattages at differing points.
The change in level at any point would be the same.
We will work with this concept a little later when
we plot the gains and losses through a total system.
7.19 The VU and the VI Instrument
Volts, amperes, and watts can be measured by
inserting an appropriate meter into the circuit. If all
audio signals were sinewaves, we could insert a
dBm meter into the circuit and get a reading that
would correlate with both electrical and acoustical
variations. Unfortunately, audio signals are complex
waveforms, and their rms value is not 0.707 times
peak but can range from as small as 0.04 times peak
to as high as 0.99 times peak, Fig. 7-12. To solve
this problem, broadcasting and telephone engineers
got together in 1939 and designed a special instru-
ment for measuring speech and music in communi-
cation circuits. They calibrated this new type of
instrument in units called VU. The dBm and the VU
are almost identical, the only difference being in
their usage. The instrument used to measure VU is
called the volume indicator (VI) instrument. (Some
users ignore this and incorrectly call it a VU meter.)
Both dBm meters and volume indicator instruments
are specially calibrated voltmeters. Consequently,
the VU and dBm scales on these meters give correct
readings only when the measurement is being made
across the impedance for which they are calibrated
(usually 150 Ω or 600 Ω). Readings taken across the
2 
log
e
log
-------------
0.30103
0.43425
-------------------
=
0.69315
=
e0.69315
2
=
26
log
2
log
--------------
1.41497
0.30103
-------------------
=
4.70044
=
log10 of the number
log10 of the base
-----------------------------------------------
logbase of the number
=
2
12
2
log
12
-----------
2
12
log
=
10
2
log
12
-----------
10
0.30
12
----------
=
100.02508
=
1.05946
=
2
12
=
Voltage
Electrical
Power
LP
LW
Doubled 
Quadrupled 
Doubled 
Quadrupled
+6 dB
+6 dB
+6 dB
+6 dB
Figure 7-11. Voltage, electrical power, Pw, and sound
pressure, compared.
Reads twice the
voltage +6 dB
Four times the
power +6 dB
Loudspeaker
ac
high Z
meter
Noise
generator
Power
amplifier
Twice the
S.P. +6 dB
Sound
level
meter

102
Chapter 7
design impedance are referred to as true levels,
whereas readings taken across other impedances are
called apparent levels.
Apparent levels can be useful for relative
frequency response measurements, for example.
When the impedance is not 600 Ω , the correction
factor of 10log (600 ⁄new impedance) can be added
to the formula containing the reference level as in
the following equation:
(7-43)
The result is the true level.
7.19.1 Crest Factor
The crest factor (CF) is the ratio of the peak output
to the average output. It is typically graphed in terms
of the output power and is expressed in dB. For
example, the CF of a sine wave is 3 dB. The CF of
music may vary between 6 dB and 24 dB.
Crest factor is defined as ten times the logarithm
of peak power out divided by average power. The
actual measurements are often made using voltage.
In that case we divide the peak voltage squared by
the rms voltage squared. The root mean square
integral is;
(7-44)
 The rms voltage squared divided by the impedance
is average power.
 Using voltage implies that both measurements
were made across identical impedances or (open
circuit). Crest factor applied to voltage waveforms is
a common practice but not the defined term. Powers
are chosen because when impedances vary widely
over the bandwidth of interest, and consequently the
bandwidth is divided into components, the powers
can be added to obtain the overall crest factor. The
Texas Instruments “Guidelines for Measuring Audio
Power Amplifier Performance” page 25 displays
actual measurements and the usefulness of power
measurements. When we remember that power
describes heat dissipation in power amplifiers then
CF as a ratio of powers becomes evident.
7.19.2 The VU Impedance Correction
When a VI instrument is connected across 600 Ω
and is indicating 0 VU on a sinewave signal, the true
level is 4 dB higher, or +4 dBm, instead of 0 dBm or
zero level. The reason this is so is shown in
Fig. 7-13. The VI instrument uses a 50  µA
Figure 7-12. Sinewave voltage values. The average
voltage of a sine wave is zero.
rms
Peak
Peak
to
peak
Max
neg
One
alteration
One cycle
Max
pos
90°
180°
0°
270°
360°
               rms = 0.707 × peak voltage
               rms = 0.3535 × peak to peak voltage
              peak = 1.414 × rms voltage
 peak-to-peak = 2.828 × rms voltage
True VU
Apparent VU
10
600
Z measured
----------------------------
log
+
=
erms
1
T---
e2 td
0e
T
∫
⎝
⎠
⎜
⎟
⎜
⎟
⎛
⎞0.5
=
Figure 7-13. VI instrument circuit.
600  Ω
600  Ω
3900  Ω
3900  Ω
300  Ω
7500  Ω
3600  Ω
3900  Ω
3900  Ω
3900  Ω
Line
Load
Attenuator
3900  Ω constant impedance
Meter

Using the Decibel
103
D’Arsonval movement in conjunction with a
copper-oxide bridge-type rectifier. The impedance
of the instrument and rectifier is 3900 Ω . To mini-
mize its effect when placed across a 600 Ω line, it is
“built-out” an additional 3600 Ω to a total value of
7500 Ω. The addition of this build-out resistance
causes a 4  dB loss between the circuit being
measured and the instrument. Therefore, when a
properly installed VI instrument is fed with 0 dBm
across a 600 Ω line, the meter would actually read
−4VU on its scale. (When the attenuator setting is
added, the total reading is indeed 0 VU.)
Presently, no major U.S. manufacturer offers for
sale a standard volume indicator that complies with
the applicable standard (C16.5). The standard
requires that an attenuator be supplied with the
instrument and none of the manufacturers do so.
What they are doing requires some attention. The
instruments (usually high-impedance bridge-types)
are calibrated so as to act as if the attenuator were
present. When the meter reads 0 VU (on a sinewave
for calibration purposes), the true level is +4 dBm.
This means a voltage of 1.23 V across 600 Ω will
cause the instrument to read an apparent 0 VU. Note
that when reading sine wave levels, the label used is
“dBm.” When measuring program levels, the label
used is “VU.” The VU value is always the instru-
ment indication plus the attenuator value.
Two different types of scales are available for VI
meters, Fig. 7-14. Scale A is a VU scale (recording
studio use), and scale B is a modulation scale
(broadcast use). On complex waveforms (speech
and music), the readings observed and the peak
levels present are about 10 dB apart. This means that
with a mixer amplifier having a sinewave output
capability of +18 dBm, you are in danger of distor-
tion with any signal indicating more than +8VU on
the VI instrument (+18 dBm − [+10 dB] peaking
factor or meter lag equals +8 VU).
Fig. 7-15 shows an example of commercially
available VI instrument panels used in the past that
included the VI instrument and 3900 Ω attenuator,
which also contains the 3600 Ω build-out resistor.
7.19.3 How to Read the VU Level on a VI Instru-
ment
A VI instrument is used to measure the level of a
signal in VU. In calibration: 0 VU = 0 dBm and a
1.0VU increment is identical to a 1.0dB increment.
The true level reading in VU is found by:
(7-45)
or
where,
Apparent level = Instrument indication + Attenuator
or sensitivity indicator.
Thus, we can have:
1.
A direct reading from the face of the instrument
(zero preferred).
2.
The reading from the face of the instrument plus
the reading from the attenuator or other sensi-
tivity adjustment—normally a minimum of
+4dB or higher. When the instrument indicates
zero, the apparent level is the attenuator setting.
3.
The correction factor for impedance other than
the reference impedance. 600 Ω is the normal
impedance chosen for a reference, but any value
Figure 7-14. VI instrument scales.
A. Recording and test equipment.
B. Broadcast monitoring.
Figure 7-15. Examples of commercial-type VI instru-
ment panels.
True VU level
Apparent level
Impedance correction
+
=
True VU level 
Instrument indication
10
600
Zact
--------- 
⎝
⎠
⎛
⎞
log
+
=

104
Chapter 7
can be used so long as the voltage across it
results in 0.001 W, Fig. 7-16.
Example
We have an indication on the instrument of −4 VU.
The sensitivity control is at +4. We are across 50 Ω
(a 100 W amplifier 70.7 V output). Using Fig. 7-16,
our true VU would be −4 VU + (+4 VU) + 10.8
correction factor = 10.8VU.
7.19.4 Calibrating a VI Instrument
The instrument should be calibrated to read a true
level of zero VU when an input of a 1000  Hz
steady-state sinewave signal of 0 dBm (0.001 W) is
connected to it. For example, typical calibration is
when the instrument indicates −4, the attenuator
value is +4, and it is connected across a 600 Ω
circuit. Levels read on a VI instrument when the
source is the aforementioned sinewave signal should
be stated as dBm levels.
7.19.5 Reading a VI Instrument on Program 
Material
Because of the ballistic properties of VI instruments,
they exhibit what has been called “instrument lag.”
On short-duration peak levels, they will “lag” by
approximately 10 dB. Stated another way, if we read
a true VU level of +8 VU on a speech signal, then
the level in dBm becomes +18 dBm. This means that
the associated amplification equipment, when fed a
true VU level of +8 VU, must have a steady-state
sinewave capability of +18 dBm to avoid overload.
Rule
Levels stated in VU are assumed to be program
material and levels stated in dBm are assumed to be
steady-state sinewave.
7.19.6 Reading Apparent VU Levels
VI instruments can be used to read apparent or rela-
tive levels. If, for example, you know that overload
occurs at some apparent level. You can use that
reading as a satisfactory guide to the system’s oper-
ation, even though you do not know the true level.
When adjusting levels using the instrument to read
the relative change in level, such as turning the
system down 6 dB, you do not need to do so in true
level readings. Instrument indication serves effec-
tively in such cases.
 When being given a level, be sure to ascertain
whether it is:
1.
An instrument indication.
2.
An apparent level.
3.
A true level.
4.
A relative level.
5.
A calibration level.
6.
A program level.
7.
None of the above but simply an arbitrary meter
reading.
Special Note: Well-designed mixers have instru-
ments that indicate the available input power level
to the device connected to its output. Such levels are
true levels.
7.20 Calculating the Number of Decades in a 
Frequency Span
To find the relationship of the number of decades
between the lowest and highest frequencies, use the
following equations:
(7-46)
therefore:
(7-47)
or
Figure 7-16. Relationship between circuit impedance
and the dB correction value.
Circuit impedance–Ω
30
25
20
15
10
5
0
dB correction factor
1     2          5    10     20      50   100  200      500 1K
True VU = Instrument indication + attenuator
setting + 10log (600/Zact)
H.F.
L.F.
-----------
101
1 decade
=
=
H.F.
L.F.
-----------
10x decade
=
H.F.
ln
L.F.
ln
–
10
ln
--------------------------------------
x decades
=

Using the Decibel
105
(7-48)
Further:
(7-49)
and
(7-50)
Example
How many decades does the bandpass 500 Hz to
12,500 Hz contain? Using Eq. 7-48:
If we had 12,500 Hz as a H.F. limit and wished to
know the low frequency that would give us
1.4 decades, we would calculate:
If we had the L.F. limit and wished to know the
H.F., then:
7.21 Deflection of the Eardrum at Various 
Sound Levels
If we make the assumption that the eardrum
displacement is the same as that of the air striking it
we can write:
(7-51)
or
(7-52)
where,
Din is the displacement in inches (the rms ampli-
tude) of the air,
Dcm is the displacement in cm,
f is the frequency in Hz,
LP is the sound level in decibels referred to
0.00002 N/m2.
Example
What is the displacement of the eardrum in inches
for a tone at 1000 Hz at a level of 74 dB? Using
Eq. 7-51:
which is a displacement of approximately one-one-
millionth of an inch (0.000001 in).
7.22 The Phon
Fig. 7-17 shows free-field equal-loudness contours
for pure tones (observer facing source), determined
by Robinson and Dadson at the National Physical
Laboratory, Teddington, England, in 1956
(ISO/R226-1961). The phon scale is of equal loud-
ness level contours. At 1000 Hz every decibel is the
equivalent loudness of a phon unit.
For two different sounds within a critical band
(for most practical purposes, using 1⁄3 octave bands
suffices) they are added in the same manner as
decibel readings.
H.F.
ln
L.F.
ln
–
10
x decades
(
)
×
ln
=
H.F.
e x decades
(
)
10
ln
(
)
×
L.F.
ln
+
=
L.F.
e
H.F.
ln
x decades
10
ln
×
(
)
–
[
]
=
12,500
ln
500
ln
–
10
ln
------------------------------------------
1.39794 decades
=
L.F.
e
12,500
ln
1.4 decades
10
ln
×
(
)
–
[
]
=
497.63 Hz
=
H.F.
e 1.4 decades
10
ln
×
(
)
497.63
ln
+
=
12,500 Hz
(
)
=
Din
3
10 7
–
10
LP
20
------
f
-----------
⎝
⎠
⎜
⎟
⎜
⎟
⎜
⎟
⎛
⎞
×
=
Dcm
39
10 3
–
0.0002
10
×
LP
20
------
f
----------------------------------
⎝
⎠
⎜
⎟
⎜
⎟
⎜
⎟
⎛
⎞
×
=
Figure 7-17. Equal loudness contours.
Din
3
10 7
–
10
74
20
------
1000
------------
⎝
⎠
⎜
⎟
⎜
⎟
⎛
⎞
×
=
0.0000015 in
=
120
100
80
60
40
20
0
−10
50  100      300 500  1k       3k  5k  10k 20k
Sound pressure level–dB
Frequency–Hz
Loudness Level–Phons
100
120
110
100
90
80
70
60
50
40
30
20
10
Minimum
audible

106
Chapter 7
(7-53)
where,
LP1 and LP2 are the individual sound levels in dB.
For example, suppose that within the same critical
band we have two tones each at 70phons. Using
Eq. 7-53:
An interesting experiment in this regard is to start
with two equal level signals 10 Hz apart at 1000 Hz
and gradually separate them in frequency while
maintaining their phon level.
They will increase in apparent loudness as they
separate. This is one of the reasons a distorted
system sounds louder than an undistorted system at
equal power levels. One final factor worthy of
storage in your own mental “read only memory” is
that in the 1000 Hz region most listeners judge a
change in level of 10 dB as twice or half the loud-
ness of the original tone.
Fig. 7-18 is a chart of frequency and dynamic
range for various musical instruments and the upper
and lower frequency range of the average young
adult.
7.23 The Tempered Scale
The equal tempered musical scale is composed of 12
equally spaced intervals separated by a factor of
. All notes on the musical scale (excluding
sharps and flats) however, are not equally spaced.
This is because there are two ½ step intervals on the
scale: that between E and F, and that between B and
C. The 12 tones, therefore, go as follows: C, C#, D,
D#, E, F, F#, G , G#, A, A#, B, C, see Table 7-10.
7.24 Measuring Distortion
Fig. 7-19 illustrates one of the ways of measuring
harmonic distortion. Two main methods are
employed. One uses a band rejection filter of narrow
bandwidth having a rejection capability of at least
80dB in the center of the notch. This deep notch
“rejects” the fundamental of the test signal (usually
a known-quality sinewave from a test audio oscil-
lator) and permits reading the noise voltage of
everything remaining in the rest of the bandpass.
Unfortunately, this also includes the hum and noise
as well as the harmonic content of the equipment
being tested, Fig. 7-20
The second method is more useful. It uses a
tunable wave analyzer. This instrument allows the
measurement of the amplitudes of the fundamental
and each harmonic, as well as identifying the hum,
amplitude, and the noise spectrum shape, Fig. 7-20.
Such analyzers come in many different bandwidths,
with a 1⁄10 octave unit allowing readings down to 1%
of the fundamental (it is −45 dB at 2f ). By looking at
Fig. 7-20, it is easy to see that harmonic distortion
appears as a spurious noise. Today tracking filter
wave analysis allows nonlinear distortion behavior
to be “tracked” or measured.
7.25 The Acoustical Meaning of Harmonic 
Distortion
The availability of extremely wide-band amplifiers
with distortions approaching the infinitesimal and
the gradual engineering of a limited number of loud-
speakers with distortions just under 1% at usable
levels (90–100 dB SPL at 10 –12 ft) brings up an
interesting question: “How low a distortion is really
needed?”
PT
10
10
LP1
10
---------
10
LP2
10
---------
+
⎝
⎠
⎜
⎟
⎛
⎞
log
=
phons 
=
PT
10
10
70
10
------
10
70
10
------
+
⎝
⎠
⎜
⎟
⎛
⎞
log
=
73  phons
=
2
12
Table 7-10. Tempered Scale
Note
Frequency Ratio
Frequency–Hz
C
1.000
262
C#, D
1.059
277
D
1.122
294
D#, E
1.189
311
E
1.260
330
F
1.335
349
F#, G
1.414
370
G
1.498
392
G#, A
1.587
415
A
1.682
440
A#, B
1.782
466
B
1.888
494
C
2.000
523

Using the Decibel
107
7.25.1 Calculating the Maximum Allowable 
Total Harmonic Distortion in an Arena Sound 
System
The most difficult parameter to achieve in the
typical arena sound system is sufficient
signal-to-noise ratio (SNR) to ensure acceptable
articulation losses for consonants in speech. It must
be at least 25 dB. In that case, the total harmonic
distortion should be at least 10 dB below the 25 dB
Figure 7-18. Audible frequency range.
Lower limit of
organ scale
Upper limit of
ordinary piano scale
Upper limit of
concert piano scale
20k
10k
5k
2k
1k
500
40
60
100
20
Lower limit of
ordinary piano scale
Cymbals
Snare Drum
Bass Drum
Kettle Drum
Violin
Piano
Cello
Bass Violin
Piccolo
Flute
Oboe
Soprano Saxophone
Trumpet
Clarinet
French Horn
Trombone
Bass Clarinet
Bassoon
Bass Saxophone
Bass Tuba
Female Voice
Male Voice
Handclapping
Footsteps
Frequency range necessary
for understanding speech
Upper limit of
organ scale
Lower limit 
of audibility
Upper limit 
of audibility
Frequency–Hz

108
Chapter 7
SNR to avoid the addition of the two signals. If both
signals were at the same level, a 3 dB increase in
level would occur. Therefore, (−25 dB) + (−10 dB)
means that the total harmonic distortion (THD)
should not exceed −35dB.
(7-54)
Therefore, we could calculate:
This is why carefully thought-out designs for use in
heavy-duty commercial sound work have a THD of
0.8 to 0.9%:
Since the 0.8% already represents (100 − 99.2), we
can write
Now, suppose an amplifier has 0.001% distortion.
What sort of dynamic range does this represent?
That is a power ratio of:
We can conclude that if such a figure were
achievable, it would nevertheless not be useful in
arena systems.
7.26 Playback Systems in Studios
Assume that a monitor loudspeaker can develop
LP = 110 dB at the mixer’s ears and that in an excep-
tionally quiet studio we reach LP = 18 dB at 2000 Hz
(NC-20). We then have
(7-55)
which is equal to 92 dB. Adding 10 dB to avoid the
inadvertent addition of levels gives 102 dB. The
distortion now becomes:
In this case, extraordinary as it is, the previously
esoteric figure becomes a useful parameter.
7.26.1 Choosing an Amplifier
As we pointed out earlier, the loudspeaker will
establish equilibrium around 1% with its acoustic
distortion. To the builder of systems, this means that
extremely low distortion figures cannot be used
within the system as a whole. Therefore,
systems-oriented amplifier designers have not
attempted to extend the bandpass to extreme limits.
They know that they must balance bandpass, distor-
tion, noise, and hum against stability with all types
of loads, extensions of mean time-before-failure
characteristics. Most high quality sound reinforce-
ment amplifiers incorporate an output transformer,
giving us 70 V, 25 V, and 4 Ω, 8 Ω, and 16 Ω outputs.
In fact, connecting across the 4 Ω and 8 Ω taps yields
a 0.69 Ω output.
Example:
Let the rms speech value be LP = 65 dB at 2 ft in the
1000–2000  Hz octave band, Fig. 7-21. Let the
ambient noise level be LP = 32 dB with the air condi-
tioning on and 16 dB with the air conditioning off in
the same octave band, Fig. 7-22. With the air condi-
tioning on the signal to noise ratio (SNR) is:
Figure 7-19. Measurement of harmonic distortion.
Figure 7-20. Methods of measuring distortion.
Use if available
Sound
system
loudspeaker
Sound
level
meter
Sound system
power
amplifier
Sinewave
oscillator
1/3 Octave
wave
analyzer
Graphic level
recorder
Response–dB
Ambient
noise
"Band rejection"
distortion analyzer
"Band pass"
wave analyzer
f = 0 dB down
5 dB
3f = 25 dB down
2f = 36 dB down
500         1k               2k                    5k
Frequency–Hz
Percentage
100
10
dB
±
20
----------
×
=
100
10
35
–
20
---------
×
1.78%
=
20
100 ± x%
100
------------------------
log
dB change
=
20
0.8
100
---------
log
42  dB
–
=
20
0.001
100
-------------
log
100
–
=
10
100
10
---------
10,000,000,000
=
LPDiff
LPTotal
LPNoise
–
=
100
10
102
–
20
------------
×
0.00078%
=

Using the Decibel
109
(7-56)
and with the air conditioning off:
For a harmonic to be equal to −33 dB, its percentage
would be:
For a harmonic to be equal to −49 dB, its percentage
would be:
7.27 Decibels and Percentages
The comparison of data in decibels often needs to be
expressed as percentages. The measurement of THD
compares the harmonics with the fundamental. After
finding out how many dB down each harmonic is
compared to the fundamental, sum up all the
harmonics and then compare their sum to the funda-
mental value. The difference is expressed as a
percentage. The efficiency of a loudspeaker in
converting electrical energy to acoustic energy is
also expressed as a percentage. We know that:
Therefore, a signal of −20 dB is 1⁄10 of the funda-
mental, or 100 × 1⁄10 = 10%. A signal of −40 dB is
1⁄100 of the fundamental, or 100 × 1⁄100 = 1%. A signal
of −60  dB is 1⁄ 1 0 0 0 of the fundamental, or
100 × 1⁄1000 = 0.1%. We can now turn this into an
equation for finding the percentage when the level
difference in decibels is known. For such ratios as
voltage, SPL, and distance:
(7-57)
For power ratios:
(7-58)
Occasionally we are presented with two percent-
ages and need the decibel difference between them.
For example, two loudspeakers of otherwise iden-
tical specifications have differing efficiencies: One
is 0.1% efficient, and the other is 25% efficient. If
the same wattage is fed to both loudspeakers, what
will be the difference in level between them in dB?
Since we are now talking about efficiency, we are
talking about power ratios, not voltage ratios. We
know that:
and so forth.
A 0.1% efficiency is a power ratio of 1000 to 1, or
−30 dB. We also know that −3 dB is 50% of a signal,
so −6 dB would be 25%; (−6) − (−30) = 24dB. In
other words, there would be a 24 dB difference in
level between these two loudspeakers when fed by
the same signal. Some consumer market loud-
speakers vary this much in efficiency.
Figure 7-21. Male speech, normal level 2 feet from the
microphone.
Figure 7-22. Ambient noise levels.
SNR
65 dB
32  dB
–
=
33 dB
=
SNR
65 dB
16  dB
–
=
49 dB
=
100
10
33
–
20
---------
×
2.24%
=
100
10
49
–
20
---------
×
0.355%
=
90
80
70
60
50
40
30
LP–dB
16   31.5  63  125  250  500  1k    2k    4k    8k  16k
Frequency–Hz
Peak
rms
50
40
30
20
10
0
−10
LP–dB
16   31.5  63  125  250  500  1k    2k    4k    8k  16k
Frequency–Hz
Air conditioning "on"
Instrument threshold
Air conditioning "off"
20
10
log
20 dB
=
20
100
log
40 dB
=
20
1000
log
60 dB
=
Percentage
100
10
dB
±
20
----------
×
=
Percentage
100
10
dB
±
10
----------
×
=
10
10
log
10 dB
=
10
100
log
20 dB
=
10
1000
log
30 dB
=

110
Chapter 7
7.28 Summary
The decibel is the product of the greatest engi-
neering minds in communications early in the last
century. When it is combined with the work of
Oliver Heaviside and others on impedance at the
turn of the 20th century, we are equipped to handle
audio levels. The concepts of dB, Z, and dBm are
the tools of the professional as well as their
language.
Bibliography
V. M. Albers. The World of Sound. New York: Barnes, 1970.
F. Jay, Ed. IEEE Standard Dictionary of Electrical and Electronics Terms, 2nd ed. New York: The Institute of
Electrical and Electronics Engineers, 1977.
D. N. Keast. Measurement in Mechanical Dynamics. New York: McGraw-Hill, 1967.
O. Read. The Recording and Reproduction of Sound. Indianapolis, Ind.: Howard W. Sams, 1952.
Research Council of the Academy of Motion Picture Arts and Sciences, Motion Picture Sound Engineering.
New York: Van Nostrand, 1938.
A. Wood. The Physics of Music. New York: Dover, 1966.

Chapter 8
Interfacing Electrical and Acoustic
Systems
by Don Davis and Eugene Patronis, Jr.
111
8.1 Alternating Current Circuits . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 113
8.2 Impedance  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 115
8.3 Electric Power  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 117
8.4 Properties of the LCR Circuit  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 120
8.5 Filters . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 121
Octave Bandpass Filter  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 121
Low Pass Filter  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 122
High Pass Filter . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 123
Parallel Circuits . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 123
Circuit Models for Physical Inductors, Capacitors, and Resistors  . . . . . . . . . . . . . . . . . . . . . . . . . . . . 125
8.6 Impedance Bridge  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 126
8.7 Constant Resistance Networks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 128
8.8 Impedance Properties of Moving Coil Loudspeakers  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 129
8.9 Network Theorems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 132
8.10 The Technician’s Viewpoint . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 135
8.11 Impedance Defined  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 135
Making Reactance Visible . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 136
Impedance Notation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 136
Amplifier and Loudspeaker Impedances . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 137
Complex Impedance  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 137
8.12 Handling the Acoustic Input and Output of the System  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 137
The EIA Microphone Rating . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 139
The Mixer Output  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 140
Available Input Power . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 140
Open and Matched Circuits . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 140
When to Measure Z . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 141
System Problems Located by Z Measurements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 141
Gain and Loss Blocks  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 141
Typical Mixer Amplifier  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 142
8.13 Total Electrical Gain of a System . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 142
A More Complicated System  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 142
8.14 Interfacing the Electrical Output Power to the Acoustic Environment . . . . . . . . . . . . . . . . . . . . . . . . . 143
Simplified Efficiency Calculations  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 143
Damping factor  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 143
Electrical Gain of a Typical System  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 144
Treating Equalizer Loss . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 144
Example of Gains and Losses  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 144
Power Amplifier  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 145
8.15 Gain Structure Revisited  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 145
Two Port Devices  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 146
Field Adjustment by Voltage Only Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 146
Voltage from Input to Output  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 148
Thermal Noise Levels  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 149
Microphone and Loudspeaker Polarity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 149
Microphone Interconnections  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 149

112
8.16 Conclusion  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .150
Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .150

Interfacing Electrical and Acoustic Systems
113
8.1 Alternating Current Circuits
If it were not for fear of being plagiaristic, this
chapter might well be entitled Alice in Wonderland,
with sincere apologies to Lewis Carroll. This thought
stems from the puzzled expressions observed
appearing on the faces of countless students when
they first encounter this subject matter. This puzzle-
ment follows from the fact that most students know
quite a bit about steady state dc circuits and their
mindset is to try to push the hearsay knowledge they
have of ac circuits into this same framework. This
does not work well at all and is similar to working on
an automobile with a set of English wrenches when
all of the nuts and bolts are metric. A few wrenches
will fit and then only approximately. Any real
craftsman knows that in order to do jobs properly,
one must have the appropriate tools. If your knowl-
edge of this subject matter is only cursory, it might
be well to put aside what you may already know and
begin acquiring a new set of tools or concepts as they
are introduced in the following. The goal is to arrive
at a thorough basic understanding rather than try to
memorize a set of mysterious rules. When you thor-
oughly understand something, you are able to write
the rulebook yourself.
The first circuit to be considered appears as
Fig. 8-1. The British physicist who first analyzed
this circuit is one of the boyhood heroes of many
budding physics students. His name was William
Thomson, later Lord Kelvin. Thomson was
Professor of Physics at Glasgow University from
1846 to 1899. The analysis of this circuit, in about
1850, was perhaps the least of his achievements but
was a crucial step toward making possible modern
communications.
The circuit of Fig. 8-1 is a series connection of
the three idealized passive circuit elements. It
consists of a pure resistor, a pure capacitor, and a
pure inductor all connected in series (departure from
ideal behavior exhibited by real resistors, capacitors,
and inductors will be discussed after development of
the necessary tools). In a series circuit, the electrical
current is taken as a reference as it is common to
each of the circuit elements. The arrow in the
diagram indicates the sense of the current when it is
considered to be a positive current. This circuit, as is
true of most circuits, exhibits two types of behavior.
These are referred to as the transient solution and
the steady state solution. For the moment, only the
steady state solution will be considered. As the
name implies, the steady state solution describes the
behavior of the circuit after it has been connected
for a reasonable time. What constitutes a reasonable
time can only be answered after a study of the tran-
sient solution which will be treated in Chapter 22
Signal Processing on Laplace transforms.
Alternating currents are currents which either
periodically or aperiodically reverse sense, i.e., are
sometimes positive and sometimes negative. Peri-
odic currents alternate between positive and nega-
tive and back again after the elapse of a definite
interval of time or period, T. Even periodic alter-
nating currents exist in many waveforms. The wave-
form is the form of the current as viewed on an
oscilloscope or plotted on a piece of graph paper.
Some common waveforms are sine, cosine,
sawtooth, triangle, square, etc. Of these, the sine and
cosine are essentially the same in that they differ
only in the starting point reference on the oscillo-
scope sweep. Additionally, the sine and cosine,
unlike the others, contain only a single frequency
component, f. This single frequency, f, is the recip-
rocal of the period T. The other waveforms, even
though they each have a definite period, are made up
of a fundamental frequency component, which is the
reciprocal of the period, as well as harmonic
frequency components which are multiples of the
fundamental frequency. This understanding is the
result of the work of the French mathematician and
physicist Jean Fourier (1768-1830). Fourier’s work
will be studied in more detail later.
The analysis of the circuit of Fig. 8-1 is begun by
assuming the circuit current is given by
(8-1)
In this statement the dependent variable is the
electrical current which is denoted by the symbol i.
The current is called the dependent variable because
its value at any instant depends on the value which
is assigned to the independent variable which is the
time, t. The value of i is linked to the value of t
through the functional properties of the cosine. The
cosine function, of course, is tabulated in terms of
an angle such as θ. In this instance the angle θ is
given by
(8-2)
Figure 8-1. Series LCR circuit.
L
C
R
i
Im
2πft
(
)
cos
=
θ
2πft
=

114
Chapter 8
The angle θ is called the phase angle of the
current. It should be noted that the value of the phase
angle is directly proportional to the value of t.
Starting at t = 0, the time which must elapse before θ
takes on the value 2π is called the period, T. That is,
(8-3)
or
(8-4)
This last equation says that the frequency is the
reciprocal of the period. Finally, one defines a quan-
tity called the angular frequency or radian frequency
as follows:
(8-5)
The current can now be expressed as
(8-6)
The maximum value that the cosine function
attains is one and hence the maximum value that the
current can take on is Im. Im is called the amplitude
of the current. The current at any instant as well as
the current amplitude is measured in amperes, A. An
ampere is a coulomb of charge per second. Elapsed
time and the period are measured in seconds, the
frequency is measured in reciprocal seconds or hertz
(Hz), and the angular frequency is measured in
radians per second (rad/s). Fig. 8-2 is a graph of the
assumed current over two periods where t is
expressed in units of the period T.
The question to be answered is “What voltage
must be applied across the input terminals such that
the current in the circuit will be the assumed
current?” This question is answered by the applica-
tion of Kirchhoff’s laws I and II. Law I is based on
the conservation of electric charge and for a series
circuit requires that the current everywhere be the
same. Law II is based on the conservation of energy
and requires that the voltage applied across the input
terminals be equal to the sum of the voltages across
the individual circuit elements in the series
connected circuit. Therefore it is necessary only to
determine the voltage which must exist across each
circuit element and then add them up.
Unlike Lord Kelvin, who pursued the analysis by
means of the differential and integral calculus, use
will be made of the tools provided by Steinmetz
when working with phasors. In what follows, the
current will be represented by a phasor where it is
understood that only the real part of the phasor
represents the actual current.
(8-7)
One can easily determine the voltage that must
exist across the resistance. By the definition of resis-
tance, the voltage across a resistance is the product
of the resistance and the current. Therefore,
(8-8)
That was easy enough! The phasor representation
of the voltage across the resistance is the same as the
current when scaled by a factor equal to the resis-
tance. In particular, it should be noted that the phase
angle of this voltage phasor is the same as that of the
current. Therefore the voltage across a resistance is
in phase with the current.
When one considers the voltage across the induc-
tance, however, the going gets a little tougher. The
definition of self-inductance requires that the
product of the inductance with the slope of the
current curve gives the voltage across an inductance
at any instant, that is,
(8-9)
The last equation introduces the mathematical
operator d/dt. This operator is called the derivative
with respect to time. In this instance, the operation is
to be applied to the function representing the current
and tells one to generate a new function whose value
at any instant is the same as the slope of the current
curve at that instant. In the language of phasors, this
is accomplished simply by multiplying the current
phasor by jω. Hence,
Figure 8-2. The circuit current over an interval of two
periods.
2π
2πf T
=
f
1
T---
=
ω
2πf
≡
i
Im
ωt
(
)
cos
=
1.0
0.8
0.6
0.4
0.2
0
−0.2
−0.4
−0.6
−0.8
−1.0 0   0.2   0.4   0.6   0.8      1    1.2   1.4   1.6   1.8      2
t in units of the period T
Instantaneous current in units of
the current amplitude
i
Ime jωt
=
vR
Ri
RIme jωt
=
=
vL
Ldi
dt
-----
=

Interfacing Electrical and Acoustic Systems
115
(8-10)
At this point it is worth noticing that whereas the
phase angle of the circuit current is ωt, the phase
angle of the voltage across the inductance is
ωt + (π⁄2). The phase angle of the voltage across the
inductance is greater than the phase angle of the
current by an amount of π⁄2. This is the reason for
the expression; “The voltage across an inductance
leads the current.”
Now for the capacitor voltage, one again goes
back to fundamentals. The capacitance is defined to
be the transferred charge divided by the resulting
potential difference or voltage. The charge and the
current are related by
(8-11)
Therefore, the voltage across the capacitor is given by
(8-12)
In the language of phasors, integration with
respect to time is accomplished simply by division
by jω. Therefore,
(8-13)
Note that the phase angle of the voltage across
the capacitance is ωt − (π⁄2) and is less than the
phase angle of the current by an amount of π⁄2. This
is the origin of the statement; “The voltage across a
capacitor lags the current.”
The voltage that must be applied across the input
terminals of this circuit in order to produce the
assumed current is then 
.
Fig. 8-3 depicts the phasor sum of the individual
voltages. The figure is drawn for the instant of time
such that t = 0. In the construction of the figure, it is
arbitrarily assumed that the voltage across the
inductance is greater than the voltage across the
capacitance.
An examination of Fig. 8-3 will indicate that the
phasor sum of the individual voltages yields
(8-14)
8.2 Impedance
All of the foregoing analysis can be made much
more compact by defining a new term called the
circuit impedance, Z. The circuit impedance, Z, is
defined to be the ratio of the complex applied
voltage to the complex current which results from
the application of that voltage.
(8-15)
Upon applying this definition, the impedance of
the series LCR is found to be
(8-16)
The last expression is the complex circuit imped-
ance written in rectangular form. When written in
the complex exponential form it appears as
(8-17)
with the angle ϕ being given by
(8-18)
vL
jωLIme jωt
=
e
jπ
2---
=
ωLIme jωt
ω
=
LIme
j ωt
π
2---
+
⎝
⎠
⎛
⎞
q
i td
∫
=
vC
1
C---- i td
∫
=
vC
1
jωC
----------Ime jωt
=
e
=
j
– π
2--- 1
ωC
--------Ime jωt
1
ωC
--------Ime
j ωt  π
2---
–
⎝
⎠
⎛
⎞
=
vin
vR
vL
vC
+
+
=
Figure 8-3. Phasor sum of resistor, capacitor, and
inductor voltages.
ϕ
j(ωL−         )Im
1
ωC
jωLIm
−jIm
ImR
ωC
vin
Im R
j ωL
1
ωC 
----------
–
⎝
⎠
⎛
⎞
+
e jωt
=
Z
vin
i------
≡
Z
vin
i------
=
Im R
j ωL
1
ωC 
----------
–
⎝
⎠
⎛
⎞
+
e jωt
Ime jωt
----------------------------------------------------------------
=
R
j ωL
1
ωC 
----------
–
⎝
⎠
⎛
⎞
+
=
Z
R2
ωL
1
ωC 
----------
–
⎝
⎠
⎛
⎞2
+
e jϕ
=
ϕ
ωL
1
ωC 
----------
–
⎝
⎠
⎛
⎞
R
-----------------------------
atan
=

116
Chapter 8
In general, the definition of the impedance
implies a knowledge of two quantities. One is called
the magnitude of the impedance, which is the ratio
of the applied voltage amplitude to the amplitude of
the resulting current. The other is called the angle of
the impedance, which is the phase angle of the
applied voltage minus the phase angle of the current
that results from the application of that voltage. The
magnitude of the impedance is denoted by |Z|. For
the case at hand,
(8-19)
where,
Vm is the amplitude of the applied voltage,
Im is the amplitude of the circuit current.
At this point, it is well to re-examine the circuit
in a slightly different way. The circuit consists of a
pure inductor, a pure capacitor, and a pure resistor
connected in series. Each of these circuit elements
has its own impedance. These respective imped-
ances are
(8-20)
(8-21)
(8-22)
The impedance of the inductance is purely imagi-
nary. Such an impedance is termed a reactance. In
this instance it is a positive reactance as it falls on
the positive imaginary axis. This reactance is
denoted by XL with
(8-23)
The impedance of the capacitance is also purely
imaginary indicating that it is also a reactance. In
this case, however, it is a negative reactance as it
falls on the negative imaginary axis. This reactance
is denoted by XC with
(8-24)
Finally, the impedance of the resistance is purely
real with
(8-25)
The total impedance of the circuit is thus
(8-26)
when written in rectangular form, or
(8-27)
when written in exponential form. Notice that the
magnitude of the total impedance is the square root
of the sum of the resistance squared and the net
reactance squared while the angle of the impedance
is the angle whose tangent is the ratio of the net
reactance to the resistance.
Impedances may be summed as was done above
or they may be summed graphically by drawing a
diagram in the complex plane. This diagram is
similar to a phasor diagram as they are both drawn
in the complex plane. Unlike the phasor diagram,
the impedance diagram does not rotate with the
passage of time. An impedance diagram is fixed, not
changing with time as long as the circuit compo-
nents remain unchanged. Fig. 8-4 is an impedance
diagram for the present circuit.
Now that the concept of impedance has been
introduced and, hopefully, is understood, circuit
analysis is greatly simplified. The procedure to be
employed is outlined in the following steps
assuming that the current is a known quantity.
1.
Calculate the total circuit impedance and
express it in exponential form.
2.
Express current as a phasor.
3.
Multiply current phasor by the total impedance
to obtain the voltage phasor.
4.
Take the real part of the voltage phasor to obtain
the actual voltage as a function of time.
Z
Vm
Im
-------
=
R2
ωL
1
ωC 
----------
–
⎝
⎠
⎛
⎞2
+
=
ZL
jωL
=
ZC
j
–
ωC
--------
=
ZR
R
=
XL
ωL
=
XC
1
–
ωC
--------
=
ZR
R
=
Figure 8-4. Impedance diagram for the series LCR
circuit.
Z
ZL
ZC
ZR
+
+
=
R
j ωL
1
ωC 
----------
–
⎝
⎠
⎛
⎞
+
=
Z
R2
ωL
1
ωC 
----------
–
⎝
⎠
⎛
⎞2
+
e
j
ωL
1
ωC
--------
–
R
----------------------
⎝
⎠
⎜
⎟
⎜
⎟
⎛
⎞
atan
=
ϕ
j(ωL −       )
1
ωC
jωL
−j
R
ωC
Z

Interfacing Electrical and Acoustic Systems
117
When the applied voltage is a known quantity,
the procedure is listed in the following steps:
1.
Calculate the total circuit impedance and
express it in exponential form.
2.
Express the applied voltage as a phasor.
3.
Divide the voltage phasor by the circuit imped-
ance to obtain the current phasor.
4.
Take the real part of the current phasor to obtain
the actual current as a function of time.
All of this is best illustrated through a numerical
example.
A series LCR circuit supports a current 
The series inductance is 0.04 henry (H), the series
capacitance is 0.0002 farad (F), and the series resis-
tance is 20 ohms (Ω). Find the voltage (V) which
must be applied to produce the given current (I).
The impedance of the resistor is 20 Ω
The impedance of the inductance is
The impedance of the capacitor is
The total impedance is
The current phasor is
The voltage phasor is
The actual voltage is thus
Alternately let the voltage applied to the same
circuit be
What is the circuit current in this case?
The total impedance is
The voltage phasor is
The current phasor is
The actual current is thus
8.3 Electric Power
Power is the rate of doing work. In this regard, one
considers both instantaneous power and average
power. Instantaneous power is the slope of the work
curve versus time and thus is the work done in a
vanishingly small interval of time divided by the
small interval of time. The average power over an
appreciable interval of time is the total work done in
the interval of time divided by the length of the time
interval. In electrical systems, the voltage repre-
sents electrical energy per unit of electric charge
while the current represents charge per unit time.
The instantaneous electric power is the product of
the instantaneous applied voltage at a given point in
time with the instantaneous current at that same
point in time.
Consider a pure resistance in which there exists a
sinusoidal current. From our previous work, it is
possible to write the following relationships.
i
3 A
500
s
---------t
⎝
⎠
⎛
⎞
cos
=
jωL
j 500
s
---------
⎝
⎠
⎛
⎞0.04 H
(
)
=
j
=
20  Ω
j
–
ωC
--------
j
–
500
s
---------
⎝
⎠
⎛
⎞0.0002 F
(
)
-----------------------------------------
=
j10  Ω
–
=
Z
20
j 20
10
–
(
)
+
=
202
20
10
–
(
)2
+
e
j
20
10
–
20
------------------
⎝
⎠
⎛
⎞
atan
=
22.361e j0.464 Ω
=
i
3 Ae
j 500
s
---------t
⎝
⎠
⎛
⎞
=
v
iZ
=
67.083
=
Ve
j 500
s
---------t
0.464
+
⎝
⎠
⎛
⎞
v
67.083  V 
500
s
---------t
0.464
+
⎝
⎠
⎛
⎞
cos
=
v 
25  V 
500
s
---------t
⎝
⎠
⎛
⎞
cos
=
Z
22.361e j0.464Ω
=
v
25  V e
j 500
s
---------t
⎝
⎠
⎛
⎞
=
i
v
Z---
1.118 A e
j 500
s
---------t
0.464
–
⎝
⎠
⎛
⎞
=
=
i
1.118 A 
500
s
---------t
0.464
–
⎝
⎠
⎛
⎞
cos
=

118
Chapter 8
(8-28)
(8-29)
(8-30)
(8-31)
The instantaneous power is symbolized by p and
is displayed in Fig. 8-5 for an interval equal to one
period, T. The area beneath the curve is colored.
This area is equal to the electrical energy converted
into heat in the resistance in the time T.
The total work done by the applied alternating
voltage in the time T is denoted by W with W being
given by
(8-32)
The average power in the resistance is the total
work done divided by the time spent in performing
the work, hence the average power in the resistance,
denoted by P, appears as
(8-33)
At this juncture it is reasonable to inquire, “What
constant dc voltage applied to the resistance would
produce the same average power as does the sinu-
soidal alternating voltage?” As is well known, the
power developed in a resistance by a steady dc
voltage V is the voltage squared divided by the resis-
tance. The posed question may be answered by
solving the equation
from which
(8-34)
This is called the effective or root mean square
value of the sinusoidal alternating voltage. This
same analysis could have been done in terms of the
current rather than the voltage with the result that
the effective or root mean square current would have
been found to be
(8-35)
A word of caution, the numerical factor of square
root of two in these equations is appropriate for a
sinusoidal voltage or current. In general, however,
other wave shapes such as triangle, square, etc. will
have different numerical values associated with their
root mean square values.
Turn now to a pure inductance in which there
exists a sinusoidal current. Again from the previous
work, it is possible to write
(8-36)
(8-37)
(8-38)
(8-39)
The instantaneous power curve for the induc-
tance is displayed in Fig. 8-6. With regard to
Fig. 8-6, the function being plotted is 
Figure 8-5. Instantaneous power developed in a
resistance by a sinusoidal current.
i
Im
2πt
T
--------
⎝
⎠
⎛
⎞
cos
=
vR
Vm
2πt
T
--------
⎝
⎠
⎛
⎞
cos
=
Vm
ImR
=
p
ivR
=
Vm
2
R
---------
=
cos2 2πt
T
--------
⎝
⎠
⎛
⎞
1.0
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
0    0.1   0.2   0.3   0.4    0.5   0.6    0.7   0.8    0.9   1.0
Period
Resistance Power Curve
Instantaneous power in units
of peak power
W
0.5 Vm
2
R
---------
⎝
⎠
⎜
⎟
⎛
⎞T
=
P
W
T-----
=
0.5 Vm
2 
R
----------
⎝
⎠
⎜
⎟
⎛
⎞
=
0.5 Vm
2 
R
----------
⎝
⎠
⎜
⎟
⎛
⎞
V2
R
------
=
V
Vm
2
-------
=
I
Im
2
-------
=
i
Im
2πt
T
--------
⎝
⎠
⎛
⎞
cos
=
vL
Vm
2πt
T
--------
π
2---
+
⎝
⎠
⎛
⎞
cos
=
Vm
ImωL
=
p
ivL
=
Vm
2
ωL
---------
2πt
T
--------
⎝
⎠
⎛
⎞
2πt
T
--------
π
2---
+
⎝
⎠
⎛
⎞
cos
cos
=

Interfacing Electrical and Acoustic Systems
119
(8-40)
where,
Furthermore, the product of the two cosine func-
tions has a maximum value of 0.5 so the maximum
ordinate on the graph is 0.5 when the vertical axis is
labeled in units of VmIm.
Note that in contrast to the resistive case where
the power curve was always positive, here the power
curve is alternately negative and positive. Further-
more, when p is negative, the area bounded by the
curve is also negative. When p is positive, the area
bounded by the curve is also positive. The inter-
esting point here is that over an interval of one period
or any integral number of periods, the net area and
hence the total work done is zero. This means that the
average electrical power in a pure inductance and,
indeed, in any reactance is zero. When the power
curve is positive, the inductance is receiving energy
from the external circuit and is storing this energy in
the magnetic field which surrounds the inductance.
When the power curve is negative, the inductance’s
stored magnetic energy is being converted back into
electrical energy which is returned to the external
circuit. A similar phenomenon occurs with a capaci-
tive reactance except here the storage medium is the
electric field in the capacitance. In summary, the
average power in any reactance, positive or negative,
is zero. This means that the average power dissipated
in any impedance is associated only with the real or
resistive part of the impedance.
In conclusion, consider a general impedance in
which there exists a sinusoidal current. The appro-
priate equations are
(8-41)
(8-42)
(8-43)
Fig. 8-7 is the instantaneous power curve for this
general case where an arbitrary positive value has
been assigned to the angle of the impedance.
From Fig. 8-7 it is apparent that the instanta-
neous power has both positive and negative excur-
sions with the positive excursions being larger than
the negative ones. The positive areas bounded by the
curve are larger than the negative areas and hence,
there is an average power greater than zero. The
average power in this case is given by
(8-44)
The quantity cosine of the angle of the imped-
ance is called the power factor. The angle ϕ falls in
the interval ±π/2. The cosine is always positive in
this interval, therefore the average power is equal to
or greater than zero. The multiplication of the
magnitude of the impedance by the cosine of the
angle of the impedance has the effect of selecting
Figure 8-6. Instantaneous power developed in an
inductance by a sinusoidal current.
p
ivL
=
Vm
2
ωL
---------
2π
T
------
⎝
⎠
⎛
⎞
2π
T
------
π
2---
+
⎝
⎠
⎛
⎞
cos
cos
=
Vm
2
ωL
---------
VmIm
=
0.5
0.4
0.3
0.2
0.1
0
−0.1
−0.2
−0.3
−0.4
−0.5
0    0.1   0.2   0.3   0.4    0.5    0.6   0.7    0.8   0.9   1.0
Period
Inductance Power Curve
Instantaneous power in units of VmIm
Figure 8-7. Instantaneous power in a general
impedance.
i
Im
2πt
T
--------
⎝
⎠
⎛
⎞
cos
=
v
Im Z
2πt
T
--------
ϕ
+
⎝
⎠
⎛
⎞
cos
=
p
Im
2 Z
2πt
T
--------
⎝
⎠
⎛
⎞
cos
2πt
T
--------
ϕ
+
⎝
⎠
⎛
⎞
cos
=
1
0.8
0.6
0.4
0.2
0
−0.2
−0.4 0   0.1    0.2    0.3   0.4    0.5   0.6    0.7    0.8   0.9   1.0
Period
General Impedance Power Curve
Instantaneous power in arbitrary units
P
0.5Im
2 Z
ϕ
cos
=

120
Chapter 8
out just the real part of the general impedance and
hence the equation could just as well be written
(8-45)
8.4 Properties of the LCR Circuit
It is now possible to explore the very useful proper-
ties of the series LCR circuit. This is facilitated by
an examination of Fig. 8-8 which is a modification
of Fig. 8-1.
Consider the generator to be an ideal variable
frequency voltage source in which the frequency can
take on any value between zero and infinity. The
subject to be studied is the relationship which exists
in the steady state between the output voltage, which
is the voltage across the resistor, and the input
voltage, which is the voltage applied to the entire
circuit. Therefore,
(8-46)
The objective at this point is to extract as much
information as is possible from this equation. The
first observation, of course, is that the relationship is
complex which implies both magnitude as well as
phase information. The magnitude information will
be explored first. The magnitude of the ratio of the
voltage out to the voltage in is given by
(8-47)
This expression takes on its largest value when
the denominator is the least. The denominator has its
least value when the term in the parentheses is zero.
There is one positive value of ω for which this is
true. Call this value ω0. This value is found through
the following steps.
(8-48)
When ω is equal to ω0, the ratio is 1 and the size
of the output voltage is the same as that of the input
voltage. For any other value of the angular
frequency, the parentheses quantity is not zero and
the ratio is less than one. This unique value of the
angular frequency is called the resonant angular
frequency. The resonant frequency itself is f0 which,
of course, is ω0 divided by 2π. The output voltage,
which is the voltage across the resistor, is at a
maximum at resonance. The output power, consid-
ered to be the power in the resistance, is also at a
maximum at resonance and is equal both instanta-
neously and on the average to the power supplied by
the generator.
There are two other angular frequencies of
particular interest. One of these is higher than ω0
while the other is lower. Denote these by ωH and ωL,
respectively. At these values of the angular
frequency, the voltage ratio magnitude is reduced to
. For these values of the angular frequency,
the power, which depends on the voltage squared, is
one-half of its maximum value. These values of the
angular frequency constitute the half-power points.
At these points, it must be true that
(8-49)
This leads to two other quadratic equations
(8-50)
(8-51)
Solving these equations leads to the result
(8-52)
(8-53)
Figure 8-8. A revised drawing of the LCR circuit.
P
0.5Im
2R
I2R
=
=
L
C
R
Vout
Vin
Vout
Vin
----------
iR
iZ
-----
=
R
R
j ωL
1
ωC 
----------
–
⎝
⎠
⎛
⎞
+
-----------------------------------------
=
R
R2
ωL
1
ωC 
----------
–
⎝
⎠
⎛
⎞2
+
-------------------------------------------------
ω0L
1
ω0C
----------
–
0
=
ω0
2L
1
C----
=
ω0
1
LC
-------
=
1
2
⁄
ωL
1
ωC 
----------
–
⎝
⎠
⎛
⎞2
R2
=
ωH
2L
ωHR
–
1
C----
–
0
=
ωL
2L
ωLR
1
C----
–
+
0
=
ωH
R2
4L2
---------
ω0
2
+
R
2L
------
+
=
ωL
R2
4L2
---------
ω0
2
+
R
2L
------
–
=

Interfacing Electrical and Acoustic Systems
121
It is instructive to examine the width of the reso-
nance represented by the difference between the
higher and lower half-power point angular frequen-
cies. This difference is
(8-54)
Whether the resonance is well defined or sharp or
whether it is poorly defined or broad is gauged by a
quantity called the quality factor or Q. Q is defined
in such a way that it is a large number for a sharp,
well-defined resonance and is small for a poorly
defined or broad resonance.
(8-55)
Substitution of the known width of the resonance
leads to
(8-56)
A few final observations before leaving the
subject of the magnitude behavior of the voltage
ratio. An inspection of the magnitude expression
reveals that the voltage ratio is zero at the angular
frequency extremes of zero and infinity. Addition-
ally, after some algebra, one finds that
(8-57)
This last relationship describes the fact that the
half power points are disposed about the maximum
power point with geometric rather than arithmetic
symmetry. This will be readily apparent after
graphing the voltage ratio function.
In order to explore the phase behavior of the ratio
of the output voltage to the input voltage, it is neces-
sary to express this ratio in the exponential rather
than the rectangular form.
(8-58)
Inspection of the equation indicates that ϕ, which
in this case is the phase angle of the output voltage
less the phase angle of the input voltage, appears as
(8-59)
When ω is zero, ϕ is +π ⁄ 2. When ω approaches
infinity, ϕ approaches −π ⁄ 2. When ω = ω0, ϕ = 0.
Finally, at the half power points, ϕ = ±(π ⁄ 4) while
being positive at the lower half power point. It is
worth repeating that when ω = ω0 not only is the
magnitude of the voltage out equal to the magnitude
of the voltage in, but also the phase of the voltage
out is identical to the phase of the voltage in. At this
particular frequency, it is just as if the series combi-
nation of the inductor and capacitor constitute a
short circuit! The LCR circuit, when arranged in the
manner of Fig. 8-8 constitutes the original bandpass
filter from which all others have followed. This fact
alone makes Kelvin’s contribution so significant.
An even better appreciation for the behavior of this
filter can be had from an examination of its response
curves. This will be explored in two ways by
employing linear axes and combinations of loga-
rithmic axes. In doing this, numerical values will be
employed that yield a bandpass filter that might well
be encountered in audio engineering.
8.5 Filters
8.5.1 Octave Bandpass Filter
The exercise is to design a simple bandpass filter
which has a bandwidth of one octave, a band center
frequency of 1 kHz, and a termination resistance of
600 Ω . Two things are known immediately from the
statement of the problem. It is a given that
R = 600Ω and that f0 = 1000 Hz. This requires that
ω0 = 2000π rad/s. The problem then becomes one of
determining the appropriate values required of L and
C. As there are two unknowns, two linearly inde-
pendent equations, which may be solved simultane-
ously, are required. Such equations have been
presented in the course of the analysis. Those equa-
tions are
(8-60)
(8-61)
ω0 is known thus taking care of the first equation,
but what is the value of Q? The value required of Q
ωH
ωL
–
R
L---
=
Q
ω0
ωH
ωL
–
--------------------
≡
Q
ω0L
R
----------
=
L
C----
R
--------
=
ω0
ωHωL
=
Vout
Vin
----------
R
R2
ωL
1
ωC 
----------
–
⎝
⎠
⎛
⎞2
+
-------------------------------------------------e
j
ωL
1
ωC
--------
–
R
----------------------
⎝
⎠
⎜
⎟
⎜
⎟
⎛
⎞
atan
–
=
ϕ
ωL
1
ωC 
----------
–
⎝
⎠
⎛
⎞
R
-----------------------------
atan
–
=
ω0
1
LC
-------
=
Q
L
C----
R
--------
=

122
Chapter 8
is implicit in the statement of the problem. The
bandwidth of the filter is to be one octave. Band-
width is defined to be the frequency interval
between the half power points of the filter. An
octave bandpass filter is then one in which ωH is
twice as large as ωL. Therefore by consulting the
defining equation for Q and substituting the relation-
ship between the half power points for the octave
filter, Q can be extracted as
With a value of Q in hand, separate values can be
extracted for L and C. The results are
R = 600 Ω,
L = 0.135 H,
C = 0.1876 μF.
Fig. 8-9 is a plot of the behavior of the magni-
tude of the ratio of the output voltage to the input
voltage for the filter. This is referred to as the ampli-
tude response. In this instance, linear axes are
employed and the lack of symmetry is readily
apparent.
Fig. 8-10 is the amplitude response of the filter
depicted with log axis for frequency and with the
magnitude expressed in decibels which also consti-
tutes a log axis.
In Fig. 8-10 the symmetry is obvious. The fact
that the symmetry is obvious on a log axis tells one
that the function being plotted is geometrically
symmetric. This is just one of the reasons why
response curves are usually drawn with log
frequency axes.
Fig. 8-11 is the phase response of the octave
bandpass filter displayed with a linear frequency
axis while Fig. 8-12 displays the phase response
with a logarithmic frequency axis.
8.5.2 Low Pass Filter
In the equations describing the amplitude and phase
response of the bandpass filter, one can readily
extract the corresponding ones for a low pass filter
by letting C become infinite mathematically. Physi-
cally this amounts to replacing the capacitor with a
short circuit. If this appears puzzling, imagine
increasing the capacitance by placing the plates
Figure 8-9. Amplitude response of filter with linear axes.
Q
ω0
ωH
ωL
–
--------------------
=
ωHωL
ωH
ωL
–
--------------------
=
2ωL
2
2ωL
ωL
–
----------------------
=
2
=
1.0
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
Frequency–Hz
0        2000       4000      6000      8000    10,000
Voltage Ratio
Magnitude of voltage ratio
Figure 8-10. Amplitude response of the filter displayed
with logarithmic axes.
Figure 8-11. Phase response with linear frequency axis.
Voltage Ratio
0
−5
−10
−15
−20
−25
102                             103                             104
Frequency–Hz
Magnitude of voltage ratio–dB
Frequency–Hz
0         2000      4000      6000      8000   10,000
2
1.5
1.0
0.5
0
−0.5
−1.0
−1.5
Phase Response
Phase

Interfacing Electrical and Acoustic Systems
123
closer and closer together until in the limit the sepa-
ration is zero. The low pass equations are then
(8-62)
(8-63)
These responses are displayed in Figs. 8-13 and
8-14 employing the previous values for L and R.
8.5.3 High Pass Filter
The general equations for the bandpass filter can
similarly be converted to those for a high pass filter
by letting L become equal to zero. In this instance,
the amplitude and phase response equations become
(8-64)
(8-65)
The results appear in Figs. 8-15 and 8-16 while
again using the given values of R and C.
8.5.4 Parallel Circuits
In the course of an ordinary day it is not uncommon
to encounter a sign which proclaims NO
ADMITTANCE. This could just as logically read
INFINITE IMPEDANCE because admittance is
defined to be the ratio of the resulting current to the
applied voltage. Admittance and impedance are
reciprocally related quantities.
Figure 8-12. Phase response with logarithmic
frequency axis.
Figure 8-13. Amplitude response of low pass filter.
Phase Response
1.5
1
0.5
0
−0.5
−1.0
−1.5
102                             103                             104
Frequency–Hz
Phase
Vout
Vin
----------
R
R2
ωL
(
)2
+
-------------------------------
=
ϕ
ωL
R
-------
⎝
⎠
⎛
⎞
atan
–
=
Voltage Ratio
102                              103                              104
Frequency–Hz
0
−5
−10
−15
−20
−25
Magnitude of voltage ratio–dB
Figure 8-14. Phase response of low pass filter.
Figure 8-15. Amplitude response of high pass filter.
Vout
Vin
----------
R
R2
1
ωC 
----------
⎝
⎠
⎛
⎞
2
+
-----------------------------------
=
ϕ
1
–
RωC 
--------------
⎝
⎠
⎛
⎞
atan
–
=
Phase Response
102                              103                             104
Frequency–Hz
0
−0.2
−0.4
−0.6
−0.8
−1.0
−1.2
−1.4
−1.6
Phase
Voltage Ratio
0
−5
−10
−15
−20
−25
102                               103                              104
Frequency–Hz
Magnitude of voltage ratio–dB

124
Chapter 8
(8-66)
In series circuits, the current is the common
factor and it is necessary to sum the voltages across
the individual elements. This leads to the result that
the total circuit impedance is the sum of the imped-
ances of the individual circuit elements. In a parallel
circuit, the voltage is the common element and one
must sum the individual currents. This leads to the
result that the total circuit admittance is the sum of
the admittances of the individual circuit elements
which are connected in parallel.
The admittance of a pure resistor is called the
conductance and is symbolized by the letter G with
(8-67)
G has the dimension of reciprocal ohms with a
reciprocal ohm being called a siemen.
The admittance of a pure inductance is called a
negative susceptance and is symbolized by the letter
B with
(8-68)
The admittance of a pure capacitance is called a
positive susceptance and is symbolized by the letter
B with
(8-69)
A generalized admittance would appear then as
(8-70)
A parallel circuit of interest and of practical
application consists of a pure inductance, a pure
capacitance, and a pure conductance all connected.
This circuit is said to be the dual of the circuit
displayed in Fig. 8-8. In a dual, constant voltage
sources are replaced by constant current sources. A
series connection is replaced by a parallel connec-
tion. Voltages are replaced by currents and imped-
ances are replaced by admittances. The total
admittance of a parallel combination is the sum of
the admittances in the individual parallel branches.
The voltage across the parallel combination, from
the definition of admittance, is the total current
divided by the total admittance. Therefore,
(8-71)
(8-72)
(8-73)
(8-74)
This circuit also displays a resonance condition
which occurs again with 
. When
ω = ω0, the net susceptance is zero. The currents in
the inductance and the capacitance are of equal
magnitude but of opposite polarity such that their
sum is zero. All of the current furnished by the
current source passes through the conductance.
The useful power in this circuit is considered to
be that which appears in the conductance. This
power is a maximum at resonance and is zero at the
Figure 8-16. Phase response of high pass filter.
Phase Response
102                             103                             104
Frequency–Hz
1.6
1.4
1.2
1.0
0.8
0.6
0.4
0.2
0
Phase
Y
i
v--
1
Z---
=
≡
G
1
R---
=
B
1
ωL
-------
–
=
B
ωC
=
Y
G  jB
±
=
Figure 8-17. This is the dual of the series LCR with a
voltage source.
L
C
G
iout
iin
Constant current source
Y
G
j ωC
1
ωL 
---------
–
⎝
⎠
⎛
⎞
+
=
v
iin
Y-----
iin
G
j ωC
1
ωL 
---------
–
⎝
⎠
⎛
⎞
+
------------------------------------------
=
=
iout
vG
iinG
G
j ωC
1
ωL 
---------
–
⎝
⎠
⎛
⎞
+
------------------------------------------
=
=
iout
iin
--------
G
G
j ωC
1
ωL 
---------
–
⎝
⎠
⎛
⎞
+
------------------------------------------
=
ω0
1
LC
(
)
⁄
=

Interfacing Electrical and Acoustic Systems
125
frequency extremes. The half power points for this
circuit are
(8-75)
(8-76)
Finally, the quality factor for this circuit appears as
(8-77)
This circuit is a workhorse for bandpass ampli-
fiers wherein the current source is an active element
such as a bipolar or field effect transistor or even a
pentode vacuum tube. The parallel L and C form
what is termed a tank circuit with the conductance
representing the useful load which the amplifier
feeds. The center of the pass band is determined by
the LC combination while the width of the bandpass
is governed by Q. An octave bandpass filter is
readily constructed using this topology. Requiring
the resonance to occur at 1 kHz with a width of one
octave requires the following values for the circuit
parameters:
1.
L = 0.06752 H.
2.
C = 0.3751 μF.
3.
G = 0.001667 S.
The performance of such a circuit is depicted in
Fig. 8-18 which should be compared with Fig. 8-10.
8.5.5 Circuit Models for Physical Inductors, 
Capacitors, and Resistors
In the previous analyses, the circuit components
were considered to be pure with each acting as pure
inductance, capacitance or resistance, respectively.
Physical inductors, capacitors, and resistors exhibit
behaviors that can and do depart from the ideal. This
departure from ideal behavior may or may not be
significant depending upon the degree. One must at
least be aware of the possibility and be familiar with
tools that are capable of quantifying any departure
from the ideal.
A pure inductance is an energy storage element
that stores energy in the magnetic field in the space
surrounding the inductance with no attendant loss of
energy. This energy is often referred to as kinetic
energy as the amount of this stored energy is propor-
tional to the square of the current and the current
exists because charge is in motion. A physical
inductor is usually made by taking an insulated wire
formed from a good conductor, such as copper, and
winding this wire into a coil. Such a coil will exhibit
an amount of self-inductance, which depends on the
geometry of the coil. Additionally, the inductance
value increases generally with the square of the
number of turns used in forming the coil. Finally, the
inductance value can be greatly influenced by the
presence of a core of ferromagnetic material. The
wire, from which the inductor is wound, and a ferro-
magnetic core, if present, are sources of energy loss.
A ferromagnetic core provides two loss mecha-
nisms for time varying currents. The first of these is
due to eddy currents induced in the core by the time
varying magnetic field. This effect can be minimized
by constructing the core from insulated laminations
of the core material or by casting the core from
ceramic ferrites. The second effect is magnetic
hysteresis, which is an inherent property of ferromag-
netism. The core losses also amount to the conver-
sion of electrical energy into heat. The conductive
losses and the core losses can together be represented
by some equivalent resistance being associated with
the inductor. A simple model for a physical inductor,
which accounts for these effects, consists of a pure
resistance in series with a pure inductance. These
elements must be sized so as to account for the actual
behavior of the physical inductor.
A pure capacitance is an energy storage element
that stores energy in the electric field which exists in
the space between the conductors forming the
capacitor. This energy is called potential energy, as
the amount of stored energy is proportional to the
square of the amount of static charge on the conduc-
tors. Most capacitors employ dielectric materials
filling the space between the conducting plates
Figure 8-18. Current driven bandpass filter.
ωH
G
2C
-------
G2
4C2
---------
ω0
2
+
+
=
ωL
G
2C
-------
–
G2
4C2
---------
ω0
2
+
+
=
Q
C
L----
G
--------
=
Current Ratio
0
−5
−10
−15
−20
−25
102                              103                              104
Frequency–Hz
Magnitude of current ratio–dB

126
Chapter 8
forming the capacitor. The dielectric serves as insu-
lation between the plates. Additionally, the polariza-
tion occurring in the molecular structure of the
dielectric greatly enhances the amount of
capacitance obtainable.
Dielectrics, however, are not perfect insulators
and attendant to molecular polarization is a relax-
ation phenomenon. Both of these properties lead to
energy losses. For example, an isolated charged
capacitor will slowly discharge over a period of
time. A simple model for a capacitor then, consists
of a pure capacitance in parallel with a pure conduc-
tance adequately sized to account for the actual
behavior of the physical capacitor in question. In
general, it is possible to construct actual capacitors,
which more closely approach ideal behavior than
can be the case with actual inductors. The simple
models for both the physical inductor and the phys-
ical capacitor appear in Fig. 8-19.
Both of these models require modifications when
working at high frequencies and, in particular,
frequencies above the audio band. In this region, the
effect of distributed capacitance between the turns
of the coil forming the inductor becomes significant.
This is accounted for by placing a suitably sized
capacitance connected in parallel with the terminals
of Fig. 8-19A.
In the case of the capacitor, in the high frequency
region the leads and the conductors forming the
capacitor plates exhibit some inductance of signifi-
cance. This is accounted for by placing a small
inductance in series with the terminals of Fig. 8-19B.
Physical resistors of the molded composition or
metal film type are more nearly ideal, at least at
audio frequencies. Wire wound power resistors can
and do exhibit inductance unless special winding
techniques are employed in their construction. Such
components can be modeled as in Fig. 8-19A with
the series resistance being the dominant term. Even
non-inductive resistors at sufficiently high frequen-
cies will suffer from some stray capacitance existing
between the resistor terminals. The size of this
capacitance depends in part on the immediate envi-
ronment of the resistor. For low values of resistance,
high conductance, even this effect is usually negli-
gible. For large values of resistance, low conduc-
tance, the stray capacitance becomes significant.
When this is the case, the model of Fig. 8-19B
becomes appropriate.
The figure of merit, which assesses how closely a
physical inductor approaches being a pure induc-
tance in a given case, is the inductor quality factor,
denoted by the symbol Q. The Q for an inductor is
the ratio of the magnitude of the inductive reactance
to the resistance associated with the inductor. Q then
is given by
(8-78)
The figure of merit in the capacitive case is
called the dissipation factor; denoted by the symbol
D. The D for a capacitor is the ratio of the conduc-
tance to the magnitude of the capacitive suscep-
tance. D then is given by
(8-79)
An instrument, which facilitates the direct
measurement of these properties of circuit compo-
nents, is discussed in the next section.
8.6 Impedance Bridge
Fig. 8-20 depicts a generalized bridge circuit. The
determination of the currents that exist in such a
circuit is an interesting problem in itself. This
problem will be solved in the course of gaining an
understanding of the operation of an impedance
bridge.
In the bridge circuit of Fig. 8-20, the voltage
source is an oscillator that furnishes a constant
amplitude sinusoidal voltage with a selected
frequency. In circuits of this type in which the
connections are not simply series and parallel
combinations, the procedure is to first assign identi-
fiable currents to each closed conducting loop or
mesh. The loops are arbitrary as long as they
provide for the existence of a current in each of the
circuit impedances. The impedances in Fig. 8-20 are
assumed to be general in nature. In a particular case,
an individual element may be real, imaginary, or
complex. In the case of an impedance bridge, the
Figure 8-19. Simple models for a physical inductor and
physical capacitor.
Rs
Ls
Gp
Cp
A. Inductor
B. Capacitor
Q
ωLs
Rs
---------
=
D
Gp
ωCp
----------
=

Interfacing Electrical and Acoustic Systems
127
element Zd represents the impedance of an alter-
nating current indicating instrument such as a meter.
For audio frequencies, this meter might be as simple
as a pair of headphones.
The next step is to set up a system of linearly
independent equations that will allow the determina-
tion of the unknown currents. In the case at hand
there are three unknown currents and a system of
three simultaneous linearly independent equations is
required. These equations are obtained by applying
Kirchhoff’s second law to each of the chosen closed
loops. These equations are then solved for the indi-
vidual currents by applying the rules of algebra to the
set of simultaneous equations. The set of equations
applicable to the loops indicated in Fig. 8-20 are
The solution for the current in the first loop is
(8-80)
The current in the second loop is
Finally, the current in the third loop is
Where in each case, the determinant of the coef-
ficients is
The equations above constitute the general solu-
tion to the problem where each of the impedance
elements is a known quantity. In the case of an
impedance bridge, the object is to determine an
unknown impedance element in terms of three
known impedance elements occupying the
remaining positions in the bridge, i.e., to determine
an unknown, say Z1, in terms of known values for
Z2, Z3, and Z4. In accomplishing this, the bridge
must be forced into a balanced condition wherein
the current in the detecting element, Zd, is made
equal to zero. If the current in Zd is to be zero, it is
necessary that the current i2 be equal to the current
i3. As these currents exist in Zd in the opposite sense,
if these currents are equal, the net current in this
element will be zero. Upon equating these two
currents, the balanced condition is extracted as
follows:
from which
One of the keys to constructing a successful
impedance bridge is the ability to construct a nearly
pure capacitance whose dissipation factor is so small
as to be negligible. Such capacitors exist in the form
of either carefully constructed silvered mica or poly-
styrene capacitors. Such capacitors are quite expen-
sive particularly for units that have very exact
values and thus are not for universal use.
An examination in detail of a bridge circuit for
determining the series resistance and inductance of a
physical inductor will conclude this section. Fig. 21
displays a bridge configuration designed to measure
the inductance and quality factor of physical
inductors.
In the circuit of Fig. 8-21 the resistor R2 can be
selected in decade steps from one ohm to one
megohm and constitutes a range selector. Resistors
R3 and R4 are continuously variable calibrated resis-
tors. The capacitor C, as mentioned previously, is
Figure 8-20. A general bridge circuit.
Z1
Z3
Z2
Z4
Zd
i2
i3
i1
v
Z3
Z4
+
(
)i1
Z3i2
–
Z4i3
–
v
=
Z
–
3i1
Z1
Z3
Zd
+
+
(
)i2
Zdi3
–
+
0
=
Z
–
4i1  Zdi2
–
Z2
Z4
Zd
+
+
(
)i3
+
0
=
i1
v
Z1
Z3
Zd
+
+
(
) Z2
Z4
Zd
+
+
(
)  Zd
2
–
[
]
Δ
---------------------------------------------------------------------------------------------
=
i2
v ZdZ4
Z3 Z2
Z4
Zd
+
+
(
)
+
[
]
Δ
-------------------------------------------------------------------
=
i3
v Z3Zd
Z4 Z1
Z3
Zd
+
+
(
)
+
[
]
Δ
-------------------------------------------------------------------
=
Δ
Z3
Z
+
4
(
)
Z1
Z3
Zd
+
+
(
) Z2
Z4
Zd
+
+
(
)
Zd
2
–
[
]
Z3 ZdZ4
Z3
+
Z2
Z4
Zd
+
+
(
)
[
]
Z4 Z3Zd
Z4
+
Z1
Z3
Zd
+
+
(
)
[
]
–
–
=
v ZdZ4
Z3Z2
Z3Z4
Z3Zd
+
+
+
[
]
Δ
-----------------------------------------------------------------------
v Z3Zd
Z4Z1
Z4Z3
Z4Zd
+
+
+
[
]
Δ
-----------------------------------------------------------------------
=
Z1
Z2Z3
Z4
-----------
=

128
Chapter 8
essentially pure with a precise fixed value. The
inductor whose properties are to be determined is
represented by Ls and Rs. The current indicator is Zd .
The balancing procedure is as follows. Start with the
continuously variable resistors set at about the
middle of their respective ranges. Step through the
possible decade values of R2 until the value is found
which minimizes the indicated current. Next vary R3
until the current is reduced even further. Then adjust
R4 to obtain an even lower current. At this point,
alternately adjust R3 and R4 until the current is the
least obtainable value. At this point the bridge has
reached its null or balanced condition. At this point
the following relationships hold.
(8-81)
Though differing in details, a similar bridge
circuit is possible for measuring the properties of an
unknown capacitor. An attentive student should be
able to draw such a circuit at this point.
8.7 Constant Resistance Networks
There is an important class of networks called
constant resistance networks which are of particular
interest to sound system engineers. The members of
this class, even though they contain reactive
elements, have an impedance which is a constant
resistance at all frequencies. Certain members of
this class of networks find employment as passive
loudspeaker crossover networks. Fig. 8-22 displays
the simplest configuration of such a network.
The impedance which exists between the termi-
nals of the network of Fig. 8-22 can be made equal
to the value assigned to the resistance R provided
that L and C bear a particular relationship to each
other. This relationship is discovered through the
following steps. First, sum the admittances of the
upper and lower branches to obtain
(8-82)
Second, inspect the result of the addition and
note that if the term in the parentheses of the denom-
inator is adjusted to equal the numerator, then all of
the reactive terms cancel out. This adjustment
simply requires that
(8-83)
or
(8-84)
After this adjustment is made, the total admit-
tance becomes 1 ⁄R and the impedance then is the
reciprocal of the admittance and is simply the value
of the resistance.
This particular circuit is often employed as a first
order two-way passive crossover network. The
constant resistance feature examined above sets one
relationship between L and C. The other relationship
necessary to allow unique determination of values
for L and C comes from the specification of the
Figure 8-21. An impedance bridge circuit for measuring
an unknown physical inductor.
Ls
Rs
R2
Zd
R3
R4
C
Rs
jωLs
+
R2R3
R
–
4
j
ωC
--------
R4
j
ωC
--------
–
--------------------
⎝
⎠
⎜
⎟
⎜
⎟
⎜
⎟
⎛
⎞
--------------------------
=
Rs
jωLs
+
R2R3
R4
------------
jR2R3ωC
+
=
Ls
R2R3C
=
Rs
R2R3
R4
------------
=
Q
ωR4C
=
Figure 8-22. Example of a constant resistance network.
L                        R
C                         R
1
R
jωL
+
-------------------
1
R
j
ωC
--------
–
------------------
+
2R
j
ωC
--------
–
jωL
+
R R
j
ωC
--------
–
jωL
L
RC 
---------
+
+
⎝
⎠
⎛
⎞
------------------------------------------------------------
=
L
RC
--------
R
=
L
C----
R
=

Interfacing Electrical and Acoustic Systems
129
crossover frequency. In the crossover application,
the upper branch forms the low pass filter with the
assumption that the low frequency loudspeaker
furnishes a load equal to R. (This assumption will be
investigated presently.) The lower branch forms the
high pass filter with the assumption that the high
frequency loudspeaker furnishes an identical resis-
tive load. The crossover angular frequency is that at
which the response of each filter is 3 dB down. This
requires that
(8-85)
(8-86)
As a numerical example, take R = 8 Ω and take
the crossover frequency to be 800 Hz. The required
inductance value is then
Similarly, the required capacitance value is
In order for this network’s performance to be
exact, it is necessary that the load resistance in each
branch be a constant 8 Ω . Fortunately, departures
from this condition are not serious provided that the
departures, if any, occur at frequencies well
removed from the desired crossover frequency. A
study will be made in the next section dealing with
actual loudspeaker behaviors and the corrections
required to make loudspeakers serve as loads for
passive crossover networks. Additionally, more
involved crossover networks will be studied in
Chapter 18 Loudspeakers and Loudspeaker Arrays.
8.8 Impedance Properties of Moving Coil 
Loudspeakers
The voice coil of a moving coil loudspeaker
certainly possesses resistance associated with the
conductor forming the coil and it has self-inductance
associated with the coil and the magnetic structure
in its environment. When taken together, these two
factors constitute the electrical impedance of the
loudspeaker when the voice coil is at rest. The
resting condition, however, is of absolutely no
interest acoustically. The cases of importance are
when the loudspeaker is being driven into motion
either electrically or mechanically. With electrical
drive, the loudspeaker is a sound producer. With
mechanical drive, such as from an impinging sound
wave, the loudspeaker acts as a microphone. The
case of interest here involves electrical drive and
sound production. This situation is represented in
Fig. 8-23.
In Fig. 8-23 Re and Le are the voice coil resis-
tance and self-inductance, respectively. The voltage
source of strength Blu on the right represents the
voltage induced in the voice coil as a result of its
motion in the magnetic gap of the magnet structure.
B is the value of the magnetic induction in the gap
measured in teslas. The length of the voice coil
conductor in the gap is l measured in meters. The
instantaneous velocity of the voice coil is u
measured in meters per second. The voltage source
on the left is the applied voltage to the loudspeaker
and i is the current which results from this applied
voltage. The electrical impedance to be determined
is that as viewed by the voltage source on the left
and is the ratio of v to i. The voltage source on the
right is an induced voltage and consequently is
subject to Lenz’s law. Lenz’s law states that an
induced voltage acts so as to oppose the cause which
produces it. The primary cause in this case is the
current i which has a positive sense in the direction
of the arrow in Fig. 8-23. Therefore the current in
the circuit is given by
ω0L
1
ω0C
----------
=
R
=
ω0
1
LC
-----------
=
L
R
ω0
------
=
8 Ω
2π800 Hz
------------------------
=
1.59 mH
=
C
1
ω0R
----------
=
1
2π800 Hz
8 Ω
×
----------------------------------------
=
24.9  
=
μF
Figure 8-23. Model for determining loudspeaker
electrical impedance.
V
Blu
Le
Re
i

130
Chapter 8
Without knowledge of u, this would amount to a
dead end. Fortunately, it is possible to make an inde-
pendent statement about u that also involves the
current. The applied force experienced by the voice
coil results from the interaction of the current
existing in the conductor residing in the magnetic
gap with the magnetic field existing in the gap. This
force has the form
(8-87)
In mechanical systems, it is possible to draw
strong analogies with electrical systems in those
instances where the governing equations have the
same mathematical structure as the structure exhib-
ited in the electrical case. In the electrical case, the
complex electrical impedance is defined to be the
ratio of the complex applied voltage to the resulting
complex current. In the mechanical case, the
complex mechanical impedance is defined to be the
ratio of the complex applied force to the resulting
complex velocity. Mechanical impedances have the
dimensions of kilograms per second. This combina-
tion is called a mechanical ohm. The mechanical
impedance thus appears as
(8-88)
Assuming, for the moment, that the mechanical
impedance is known, it is possible to solve for u in
terms of i to obtain
(8-89)
This can now be substituted in the first equation
above involving i and u to obtain
(8-90)
It is now a simple matter to solve for the elec-
trical impedance of the loudspeaker when in opera-
tion. The last equation is solved for the ratio of v to i
to obtain
(8-91)
The question at this point becomes “What is the
structure of Zm?” In order to answer this question it
is necessary to further explore the electrical-
mechanical analogy. Table 8-1 contains one possible
set of analogies which is drawn from the mathemat-
ical structure of the differential equations describing
the behaviors of electrical and mechanical systems.
A moving coil loudspeaker has a mass associated
with its motional elements. The suspension elements
of the loudspeaker such as the spider and surround
act like springs. If the back side of the loudspeaker
is enclosed in a closed box, the air in the box acts
like a spring having a stiffness inversely propor-
tional to the air volume in the box. The sound
energy carried away by sound waves represents a
loss of mechanical energy and thus appears as an
additional friction constant or mechanical resistance.
This particular mechanical resistance is called the
radiation resistance. The air mass in direct contact
with and in the immediate vicinity of the loud-
speaker also adds to the moving mass of the loud-
speaker. This effect is represented by the radiation
reactance. When all of these factors are taken into
account, the mechanical impedance appears as
(8-92)
Additional explanation of the terms appearing in
the expression for the mechanical impedance is
useful. The term Rm is the mechanical resistance
which accounts for the frictional losses occurring in
the suspension when the loudspeaker is in motion.
i
v
Blu
–
Re
jωLe
+
------------------------
=
F
Bli
=
Zm
F
u---
≡
u
Bli
Zm
-------
=
i
v
B2l2i
Zm
------------
–
Re
jωLe
+
------------------------
=
v
Re
jωLe
B2l2
Zm
----------
+
+
-----------------------------------------
=
Table 8-1. Analogies Drawn from the Mathematical 
Structure of the Differential Equations Describing the 
Behaviors of Electrical and Mechanical Systems
Electrical
Mechanical
Applied voltage
Applied force
Charge
Displacement
Current
Velocity
Time derivative of current Acceleration
Resistance
Kinetic friction constant
Inductance
Mass
Capacitance
Compliance or reciprocal stiffness 
(spring constant)
Ze
v
i--
=
Re
jωLe
B2l2
Zm
----------
+
+
⎝
⎠
⎛
⎞
=
Zm
Rm
Rr ω
(
)
jXr ω
(
)
j ωM
Ks
Kb
+
ω
------------------
–
⎝
⎠
⎛
⎞
+
+
+
=

Interfacing Electrical and Acoustic Systems
131
The term Rr(ω) is the mechanical resistance associ-
ated with radiation energy losses. Unlike Rm,
however, this term is frequency dependent with a
rather involved frequency dependence, the exact
nature of which is not important for the present
discussion. The term Xr(ω) is the radiation reactance
which also has an involved frequency dependence.
The term in the parentheses describes the resonant
interaction between the moving mass and the stiff-
ness of the suspension along with the stiffness of the
air in the box. This resonance ordinarily occurs at a
low frequency in which case the radiation reactance
simply adds a small amount to the term ωM, thus in
effect slightly increasing the moving mass. Fig. 8-24
is a plot of the magnitude of the total electrical
impedance typical of a 10 inch cone type moving
coil loudspeaker.
The effect of the mechanical resonance of this
loudspeaker is clearly displayed in Fig. 8-24 as
occurring at a frequency of 70 Hz with an impedance
magnitude of nearly 45 Ω . The nominal impedance
of this loudspeaker is the minimum value above
mechanical resonance and is a little over 6 Ω . This
value is not to be confused with the dc resistance of
the voice coil which is always lower. If this loud-
speaker is to be employed in a two-way system with
a passive crossover at 1000 Hz or above, it is neces-
sary to add a network in parallel with the loud-
speaker which will render the overall impedance to
be resistive and constant in value. Above the
minimum in the curve, the impedance magnitude
increases with frequency as one would suspect from
the voice coil inductance. In this region there is only
a minor influence from the mechanical impedance
and this influence is diminishing as the frequency
increases. The loudspeaker itself behaves as a
combination of a series resistance and inductance.
The corrective network to be placed in parallel then
must be a series resistance and capacitance as was
learned from the discussion of constant resistance
networks. In arriving at values for this network, one
selects a resistance which equals the minimum value
on the impedance curve. Call this value Rnom. Then
one solves for a capacitance using the constant resis-
tance network equations to obtain
(8-93)
The resistance Rnom and the capacitance C are
then connected in series with the combination subse-
quently connected in parallel with the loudspeaker
terminals. The impedance curve of the combination
is then measured. If the measured impedance is now
flat with zero angle through the desired crossover
region, the correction is proper and no further work
is required. If this is not the case, small modifica-
tions are alternately made to both Rnom and C until
the desired performance is required. Figs. 8-25 and
8-26 display the magnitude and impedance angle
behaviors for a properly corrected system.
It is important to emphasize that the presence of
the correction network in parallel with the loud-
speaker terminals does not alter either the electrical
or acoustical performance of the loudspeaker in any
way. Instead, the combination of the loudspeaker
and the parallel connected correction network now
constitutes a proper resistive load to properly termi-
nate a passive constant resistance crossover
network. The corrective network is called a Zoebel
network to honor one of the pioneers of electric
filter technology. In Fig. 8-25, it is apparent that the
impedance magnitude is constant above 1000 Hz.
Equally important, Fig. 8-26 illustrates that the
Figure 8-24. Electrical impedance magnitude typical of
a moving coil loudspeaker.
Electrical Impedance Magnitude
102                   103                 104
Frequency–Hz
45
40
35
30
25
20
15
10
5101
Magnitude of Ze
Figure 8-25. Impedance magnitude after correction.
C
Le
Rnom
2
--------------
=
Loudspeaker with Zoebel Correction
102                  103                 104
Frequency–Hz
45
40
35
30
25
20
15
10
5
101
Impedance magnitude

132
Chapter 8
angle of the overall impedance is zero, that is purely
resistive above 1000 Hz.
8.9 Network Theorems
Much reference has been made to voltage and
current sources as well as passive circuit elements in
all of the previous work. Voltage sources and
current sources are also circuit elements, which are
further classified as being active circuit elements.
The distinction between an active circuit element
and a passive one is that the active circuit element
contains or controls a source of electrical energy. It
is true that capacitors and inductors can temporarily
store energy but they do not inherently contain inde-
pendent sources of energy and hence are classified
as passive elements.
Active elements or networks must contain
devices or agencies which have the ability, in the
thermodynamic sense, to reversibly convert some
other form of energy into electrical energy. The
amount of energy so converted in the device or
agency per unit of charge passing through the device
or agency has historically been called the electromo-
tive force or emf. The appearance of the word force
in the historical terminology is a misnomer as
energy rather than force is the applicable concept.
An emf is measured in volts and a volt is a joule of
energy per coulomb of electric charge. In the case of
an emf, the energy referred to is the amount of some
other form of energy converted into electrical
energy per unit of electrical charge. Potential differ-
ence, previously referred to as simply voltage, is
also measured in volts. Potential difference,
however, represents the change in electrical poten-
tial energy per unit of electrical charge experienced
in moving between two points. The letter E will be
used here to represent a sinusoidal emf. The letter v
will continue to be used to represent a time depen-
dent potential difference.
In order to sustain a current in a closed
conducting circuit, the circuit must contain a source
of electrical energy provided by an emf. The only
exception to this statement occurs in a closed super-
conducting coil. Even in the superconducting coil
case, an emf is necessary in order to first establish a
direct current in the coil. Sources of emf appear in
many forms. A mechanically driven alternating
current generator is a source of emf in which a
portion of the mechanical energy of rotation of the
generator shaft is converted into electrical energy.
Chemical electric cells of both the primary and
secondary categories are sources of a dc emf. In this
instance an exoergic chemical reaction in the cell
makes electrical energy available. A solar panel is a
source of a dc emf. Here a portion of the luminous
energy from the sun impinging on the cell is
converted into electrical energy. One could easily
list many other examples. A common property of all
of these sources of emf is that they must possess a
conducting path between their terminals and along
this path will occur losses. For example, the coils in
a mechanically driven alternating current generator
will possess both resistance and inductance and
perhaps significant distributed capacitance. This
means that any source of emf will also have some
impedance internal to its structure. This situation is
depicted in its simplest form in Fig. 8-27.
The elements depicted on the left in Fig. 8-27
represent a physically realizable source of emf. The
element on the right in Fig. 8-27 represents the
impedance of some circuit which is connected
across the terminals of the source of emf. The source
of emf is represented by two elements. A circle
containing one period of a sine curve, this being the
representation of an ideal source of alternating emf
(one without losses) and a rectangle representing the
internal impedance of the conducting path through
the source of emf. The internal impedance of the
Figure 8-26. Impedance angle after correction.
Corrected Impedance Angle
102                  103                 104
Frequency–Hz
0.8
0.6
0.4
0.2
0
−0.2
−0.4
−0.6
−0.8
−1.0101
Impedance angle
Figure 8-27. A source of alternating emf and its exter-
nally applied load.
E
Z0
Zx

Interfacing Electrical and Acoustic Systems
133
source of emf is Z0 and the impedance of the
external circuit is Zx. The arrow indicates the posi-
tive sense of the current in the circuit. The sustained
current which will exist in a simple conducting loop
is the algebraic sum of the emfs (if there are more
than one) divided by the total series impedance of
the loop including all source internal impedances. In
this instance the current is given by
(8-94)
The first circuit theorem to be discussed is the
Maximum Power Transfer Theorem. This theorem
deals with the proposition that given a particular
source having a fixed emf and a fixed internal
impedance, what value of load impedance must be
connected to the terminals of the emf such that the
power dissipated in the external load will be a
maximum? In answering this question, first rewrite
the equation for the current in the circuit of
Fig. 8-27 by explicitly displaying the complex
nature of both the internal and external impedances.
(8-95)
Earlier it was learned that the power dissipated in
a load is directly proportional to the square of the
current multiplied by the real part of the load imped-
ance. The next step is to examine the expression for
the current and inquire what adjustment can be made
to the load impedance that will not change its real
part but will make the denominator in the current
expression smaller and consequently, the current
larger. Upon recalling that reactances can be both
positive and negative, the denominator can be made
smaller by having the reactance of the load be just the
negative of the reactance of the source thus yielding a
net reactance of zero. The current now becomes
(8-96)
The average power dissipated in the external load is
then
(8-97)
where,
Em is the amplitude of the sinusoidal emf.
The next and final step is to find the value of Rx
which will make the power expression a maximum.
Readers familiar with the differential calculus would
differentiate the power expression with respect to Rx
and set the derivative equal to zero thus obtaining a
simple algebraic expression which can easily be
solved for the magic value of Rx satisfying the
problem. Those readers not familiar with calculus
can still arrive at the answer after the expenditure of
some additional effort. It is only necessary to let Rx
be a variable expressed in fractions and multiples of
R0 and graph the function
(8-98)
A carefully drawn graph will have a maximum
occurring when Rx equals R0.
The conclusion is that the power in the external
load is a maximum when the load impedance is the
complex conjugate of the source impedance. As a
reminder, complex conjugate means equal real parts
with imaginary parts equal but opposite in sign.
It is important to note, however, that when the
power dissipated in the load has been maximized, the
power transfer efficiency is only 50% as an equal
amount of power is being dissipated within the
source itself. Additionally, under these conditions,
the voltage applied to the load is only one-half of the
open circuit voltage of the source. This type of match
is often desirable in communications systems where
a premium is placed on signal power. It is not
employed in commercial power systems where a
premium is placed on voltage regulation and overall
efficiency. Note also, this theorem can not be applied
to audio power amplifiers because the emf associated
with the power amplifier output is not a constant as
required by the theorem, but rather is a function of
the load impedance to which it is connected. Power
amplifiers are purposely designed to have low output
impedances (high damping factors) and are designed
to work into load impedances equal to or greater than
a specified minimum which is significantly larger
than the output impedance.
The second theorem to be discussed is
Thévenin’s Theorem. This theorem deals with the
proposition that a linear network of any number of
emfs and any combination of impedances which
communicates with the external world through only
two terminals is equivalent to a single emf E0 in
series with a single impedance Z0. E0 is equal to the
voltage present between the actual network’s termi-
nals when it is disconnected from the external world
and Z0 is the impedance measured between the
actual network’s terminals when it is disconnected
from the external world and all internal emfs are
inactive. The value of this theorem and an elabora-
i
E
Z0
Zx
+
-----------------
=
i
E
R0
jX0
+
(
)
Rx
jXx
+
(
)
+
--------------------------------------------------------
=
i
E
R0
Rx
+
------------------
=
P
0.5
Em
2
R0
Rx
+
(
)2
-------------------------Rx
=
G
Rx
R0
Rx
+
(
)2
-------------------------
=

134
Chapter 8
tion of the terminology used therein can best be
explored through an example problem.
Fig. 8-28A displays a circuit problem where the
objective is to determine the current which exists in
the physical inductor located in the central branch.
The circuit contains two sinusoidal generators each
having a time dependence of cos(ωt) and each
having internal resistance as indicated. The emfs
associated with the generators are the rms values.
The inductor is connected between the points
labeled a and b. One could solve this problem by
assuming mesh currents similar to the technique
employed in the section dealing with the impedance
bridge. One would then have to write two simulta-
neous equations, solve them, and then use knowl-
edge of the mesh currents to determine the net
current in the central branch. The Thévenin
approach is simpler in this instance. First, discon-
nect the inductor between a and b and find the
potential difference or open circuit voltage which
exists between a and b under these conditions. This
circuit appears in Fig. 8-28B. In Fig. 8-28B the net
emf is 10 V − 5 V = 5 V and the total series imped-
ance is 2 Ω + 3 Ω = 5 Ω . The current in the loop is
then 5 V divided by 5 Ω or 1 A. From the generator
on the left, Vab is then 10 V less the drop across its
internal resistance which is 1 A times 2 Ω giving
10V − 2 V = 8 V. Now one determines the imped-
ance which exists between a and b when the emfs of
the generators are set equal to zero but with the
generators still in place. In this instance, one has 2 Ω
paralleled by 3 Ω giving a value of 1.2  Ω. The
Thévenin equivalent of the outer loop is then a
generator having an emf of 8 V and an internal
impedance which is a pure resistance of 1.2 Ω.
Finally, in Fig. 8-28C, this source is connected to the
load inductor and it is a simple matter to determine
the current. The impedance of this series loop is
The current in this loop which is the current in the
inductor has an rms value of 8 V divided by 5 Ω or
1.6A and the current lags behind the voltage of the
generator by an angle of 0.927 radian.
In summary, Thévenin’s theorem says that any
linear two terminal active network can be replaced
by an ideal source of emf in series with an imped-
ance. The value of the emf is equal to the open
circuit voltage of the network between the two
terminals and the impedance is the measured imped-
ance between the terminals when the sources
internal to the network are inactive.
A related network theorem is called Norton’s
Theorem. Norton’s Theorem states that any linear
two terminal active network can be replaced by an
ideal current source paralleled by an admittance. The
value of the current source is the short circuit current
which could exist between the two terminals of the
actual network and the admittance is the admittance
measured between the two terminals of the network
when the sources internal to the network are inactive.
The Norton equivalent which could replace the
Thévenin equivalent of the sample problem can be
derived from the Thévenin equivalent and is shown
in Fig. 8-29. The Norton values are determined as
follows. When a is shorted to b in the Thévenin
equivalent, the current is 8 V⁄1.2 Ω = 62⁄3 A. The
admittance between a and b with the voltage set
equal to zero in the Thévenin equivalent is the recip-
rocal of 1.2 Ω or 5⁄6 siemen (S).
In order for each and every one of the foregoing
network theorems to be valid, it is necessary that the
circuit or system be linear. Being linear means that
the laws of physics governing the system appear in
the form of linear differential equations. One of the
properties of such equations is that if there exist
1.2
1.8
j4
+
+
(
) Ω
32
42
+
Ωe
j
4
3---
atan
=
5 Ω j0.927
=
Figure 8-28. Application of Thévenin’s theorem.
a
b
a
b
b
a
3 Ω
3 Ω
2 Ω
2 Ω
1.8 Ω
1.8 Ω
1.2 Ω
Vab = 8 V
j4 Ω
j4 Ω
10 V
5 V
8 V
I = 1.6 A
I = 1 A
A.
B.
C.
10 V
5 V

Interfacing Electrical and Acoustic Systems
135
several solutions to a particular linear differential
equation, then a sum of these solutions is also a solu-
tion to the equation. This leads to what is termed the
principle of superposition or the Superposition
Theorem. In a network containing several sources,
either voltage or current, and several impedances,
one applies superposition by calculating the effects
of each source acting individually with all other
sources set equal to zero. This is done for each
source in turn. When this is done, it is important to
note that even though a source may be inactive, its
impedance still remains in the circuit. The final solu-
tion when all sources are active simultaneously is
just the sum of the solutions obtained when the
sources are acting one at a time. As an example,
superposition will be applied to the circuit of
Fig. 8-28B in order to determine the potential differ-
ence between a and b. Consider that the 10 V source
is active with the 5 V source set equal to zero. In this
instance, the 3 Ω and 2 Ω resistors form a voltage
divider across the 10 V source and Vab is then
Now consider that the 5 V source is active with
the 10 V source set equal to zero. The situation here
has the 2 Ω and the 3 Ω resistors forming a voltage
divider across the 5 V source yielding a value of Vab
of
When both sources act simultaneously, Vab is the
sum of these two individual solutions yielding the
value of 6 V + 2 V or 8 V. There are many more
network theorems, many of which are more
specialized. The ones studied here are the ones most
often invoked in routine circuit analysis.
8.10 The Technician’s Viewpoint
The following section of Interfacing Electrical and
Acoustic Systems is written from the viewpoint of
the technician with a handheld impedance meter
seeking to confirm values and adjust them where
necessary. We treat the values as resistances which
in the case of mixer output, amplifier inputs, etc.,
are reasonable. Microphones and loudspeakers
present more complex values (covered by
Dr. Patronis in the first section of this chapter).
8.11 Impedance Defined
What is impedance? Many technicians have put an
ohmmeter across the voice coil of a 16 Ω loud-
speaker and been surprised to read 4.5 Ω or less.
What have they read with the ohmmeter? The dc
resistance of the voice coil. Is this the impedance?
No.
Now, let us use a bridge circuit to read the ac
resistance (R) of the loudspeaker. Is this the imped-
ance? No, but it is part of the impedance.
What is impedance? It is defined as the total
opposition, including resistance and reactance, a
circuit offers to the passage of alternating current.
We all know what resistance is, but what do “oppo-
sition” and “reactance” mean? Opposition is a resis-
tance, a restraint, or a hindrance. From this we can
conclude that in ac circuits there exists some other
resistance-like component, and this additional
restraint, which adds to that of the ac resistance, is
called reactance.
There are two kinds of reactance, capacitive
reactance (XC) and inductive reactance (XL). Reac-
tance varies with frequency, whereas ac resistance
tends to stay the same with frequency (certainly
over the audio range).
Now, let’s add two more terms to our collection
and proceed to measure impedance. Let us designate
|Z| as the magnitude of the impedance and the power
factor (PF), giving us the following terms which are
terms for use in steady state circuits:
1.
R is ac resistance.
2.
X is reactance. 
3.
XC is capacitive reactance.
4.
XL is inductive reactance.
5.
|Z| is the magnitude of the impedance (Z is
complex).
6.
PF is power factor or cos θ where θ is the angle
of the phase difference between the voltage and
the current.
Figure 8-29. Norton equivalent derived from the
Thévenin equivalent.
a
b
a
b
1.2 Ω
8 V
62/3 A
5/6 S
Thévenin                                       Norton
10 V
3 Ω
2
3
+
(
) Ω
-----------------------
×
6 V
=
5 V
2 Ω
2
3
+
(
) Ω
-----------------------
×
2 V
=

136
Chapter 8
If we now measure voltage and current in a real
circuit, the current lags behind the voltage in phase
when an inductor-like device is in the circuit, and
the current leads the voltage in phase when a capac-
itor-like device is in the circuit. ELI THE ICE MAN
helps us remember this relationship: E (voltage) is
ahead of I (current) when L (inductance) is predomi-
nant and I is ahead of E when C (capacitance) is
predominant in the circuit. These are root mean
square (rms), voltage and current values.
8.11.1 Making Reactance Visible
By setting up a standard way of plotting resistance
and reactances, their action and interaction become
obvious. We can do this with rectangular coordi-
nates. Components 90° apart in their phase are
represented by vectors that are 90° apart, see
Fig. 8-30. From Fig. 8-30, we can write the
following equations for impedance:
(8-99)
where,
|Z| is the magnitude of the impedance,
R is the resistance,
X is the total reactance,
X = (XL and XC).
This describes how to plot the action in
Fig. 8-30. The impedance angle can be found by:
(8-100)
where,
θ is the angle of the impedance in degrees or
radians.
8.11.2 Impedance Notation
The following equations are also used when
working with impedance.
(8-101)
(8-102)
(8-103)
(8-104)
(8-105)
(8-106)
(8-107)
(8-108)
(8-109)
(8-110)
where,
|Z| is the magnitude of impedance,
θ is the angle of impedance,
cos θ is the power factor,
R is the resistance,
X is the reactance,
Z is the magnitude and angle = 
.
These equations describe how to obtain the
magnitude of the impedance vector and the angle
between it and 0º on the ac-resistance axis.
In Fig. 8-30 we can see that, when angles are
small, the impedance value approaches the ac-resis-
tance value. Conversely, when angles are large, the
reactive component must be carefully measured.
The performance of transformers, loudspeaker voice
coils, and the like exemplifies conditions in which
there are large angles. (A loudspeaker has a blocked
impedance—cone cannot move—and a motional
impedance. When the loudspeaker impedance does
Figure 8-30. Calculation of impedance.
Z
R2
X2
+
=
+ X axis (XL)
− X axis (XC)
R axis
|Z|
The angle of
Impedance θ
R
XL
tan 1
–
X 
R-----
⎝
⎠
⎛
⎞
θ
=
R2
X
 2
+
Magnitude of Impedance
=
Z
θ
cos
(
)
R
=
Z
θ
sin
(
)
X
=
tan 1
–
X 
R-----
⎝
⎠
⎛
⎞
θ
=
R
θ
cos
------------
Z
=
X
θ
sin
-----------
Z
=
R
Z
------
PF
=
θ
cos
=
X
Z
------
θ
sin
=
cos 1
–
R
Z------
⎝
⎠
⎛
⎞
θ
=
sin 1
–
X
Z
------
⎝
⎠
⎛
⎞
θ
=
Z e jθ

Interfacing Electrical and Acoustic Systems
137
not rise or fall with a change in frequency, it is
essentially resistive within that frequency range.
The ac resistance plus the motional impedance equal
the total impedance measured.)
8.11.3 Amplifier and Loudspeaker Impedances
Amplifiers can present outputs for loudspeakers
rated for 4 Ω , 8 Ω , 16 Ω , etc. The actual source
impedance of modern amplifiers is quite low,
usually on the order of 0.1 Ω or less.
Amplifiers also can provide constant voltage
output ratings, 25 V, 70.7 V, 100 V, and 200 V, as well
as, on occasion, constant current output.
Once the type of interface has been ascertained
and the appropriate amplifier chosen, then the next
device back towards the input of the system needs to
be ascertained. This may be a series of pads, resis-
tive matching networks, or an active device. It is
important that:
1.
It can output its full output for best signal-
to-noise ratio, SNR.
2.
It is an appropriate match in circuit type,
balance, unbalanced, etc., and in circuit
impedance.
It has been found over the years that most signal
processing equipment should be in the system near
the input of the power amplifier. The signal through
a sound system should emphasize SNR near its
input, and spectrum shaping and other frequency-
dependent level changes near the output where the
signal levels are more robust. We will treat all
devices between the mixer and the power amplifier
as “black boxes” in order to define the treatment of
their inputs and outputs.
8.11.4 Complex Impedance
For those desiring a look at loudspeaker values of
real and imaginary parts, angle of impedance, etc.,
use of a modern analyzer is helpful, in this case a
Goldline TEF, see Figs. 8-31 through 8-37.
The published EIA data of reputable manufac-
turers is used for acoustic devices such as micro-
phones and loudspeakers with predictable results in
terms of matching and levels. A system designer not
using standard components but rather starting from
zero to a system of unique components has a wide
horizon of options.
8.12 Handling the Acoustic Input and Output 
of the System
Knowing the expected performer’s maximum LP
allows for an intelligent choice of microphone
sensitivities. The choice of microphones can be
affected by:
1.
Appearance.
2.
Sensitivity.
3.
Reliability.
4.
Circuit types—wired, wireless, dynamic con-
denser, etc.
5.
Directivity characteristics.
6.
Freedom from wind noise, extraneous electrical
field pickup, and handling noise.
For our purpose of interface, sensitivity and imped-
ance need explanation.
Figure 8-31. Complex impedance Nyquist plot.
Figure 8-32. How the plots in Fig. 8-33through 8-37
were made.
20
10
0
−10
−20
0                   10                   20                   30                  40
Resistance–ohms
Reactance–ohms
+j = XL
−j = XC
20 kHz
10 kHz
1 kHz
58 Hz
20 Hz
Osc.
Pwr.
Amp.
Analyzer
Load
M1
10K
S1
1. Close S1 and set M to 0.1 V.
2. Open S1 attach test load and measure.
3. Adjust analyzer input sensitivity until you read
    test load value.
4. Measure desired load.

138
Chapter 8
Figure 8-33. A resistive input (10 Ω, 5% resistor).
Figure 8-34. A single cone in an enclosure box. Cursor at the lowest value magnitude 8.4 Ω. Manufacturer rating is 8Ω.
Figure 8-35. A two way system. Cursor at the lowest value 5.3 Ω. Rating chosen by manufacturer is 8 Ω.
Phase
Magnitude and phase response
Nyquist plot
Magnitude
Magnitude
Phase
Magnitude and phase response
Nyquist plot
Magnitude
Magnitude
Magnitude and phase response
Nyquist plot
Phase
Magnitude
Magnitude

Interfacing Electrical and Acoustic Systems
139
8.12.1 The EIA Microphone Rating
The EIA has chosen to rate microphone sensitivity
as:
(8-111)
where,
SV = 20log EO – Test LP + 74,
RMR is the center value of the impedance range,
typically 38 Ω , 150 Ω , 600 Ω , Table 8-2,
EO is the open circuit voltage at Test LP ,
LP is the Test LP (usually either 94 dB or 74 dB),
*50 dB = 10log (1 ⁄ 0.001 + (94 − 74).
To obtain GM from other ratings use:
(8-112)
then insert SV into the GM equation (typical Test LP
is either 94 dB or 74 dB).
GM provides the microphone’s output level in
dBm (theoretical) for an input LP = 0 dB. This
allows the output of the microphone to be added
directly to the performer’s LPMAX for the total elec-
trical output of the microphone at the mixer’s input.
Low sensitivity microphones, suitable for “rock”
concerts, can have an output level, when used by
quiet talkers, too near the noise floor—for example,
Figure 8-36. A smaller two way system. Cursor at the lowest point 3.7 Ω. Rating chosen by manufacturer is 4 Ω.
Figure 8-37. A “rock” performer’s microphone specified to operate into an “open” circuit.
Phase
Magnitude
Magnitude
Magnitude and phase response
Nyquist plot
Magnitude
Phase
Magnitude
Magnitude and phase response
Nyquist plot
GM
SV
10
RMR
log
–
50  dB*
–
=
SV
20
EO
log
Test Lp
–
74
+
=
Table 8-2. RMR defined
Ranges (Ω)
Values Used (Ω)
20–80
38
80–300
150
300–1250
600
1250–4500
2400
4500–20,000
9600
20,000–70,000
40,000
1 dyn/cm2 = 1 μbar = 0.1 Pa = 0.1 N/m2

140
Chapter 8
in conference rooms, by ministers, anyone speaking
softly. Conversely a very high sensitivity micro-
phone choice for the high level performer can result
in input overload at the mixer’s input amplifier.
This is an “available input power” figure. An other-
wise noiseless device has a thermal noise floor of
−132dBm (for a spectrum from 20Hz–20,000Hz).
The GM figure allows an instant estimate of SNR at
the very beginning of the system; however, the
acoustic SNR at the microphone is a separate case.
8.12.2 The Mixer Output
The audio engineer needs to know the source
voltage and source impedance of the device. This is
depicted in Fig. 8-38.
Using Fig. 8-38, we can find Rs with the
following equation:
(8-113)
Example
Let,
RADD = 600 Ω ,
EO = 1.0 V,
EADD = 0.8 V,
The source voltage can be found with the
following equation:
(8-114)
8.12.3 Available Input Power
From this we can find the available input power in
dBm to the input of the device following the mixer
(8-115)
Each subsequent device is handled in exactly the
same manner. We only care about AIP from the
previous device and the AIP at the output of the
device itself, in order to specify the gain or loss the
device occasions, Fig. 8-39.
At the output of the power amplifier we compute
the actual power into the load rather than its AIP
(8-116)
or
(8-117)
where,
P is the power in watts.
8.12.4 Open and Matched Circuits
Fig. 8-40 shows an open circuit and a matched
circuit. For each circuit:
(8-118)
Figure 8-38. Finding Rs from voltage measurements.
RS
RS
ES
ES
RADD
EO
EO
EADD
Rs
RADD
EO
EADD
-------------
1
–
⎝
⎠
⎛
⎞
=
Measure EO, close switch, measure EADD
RS
600 1.0 V
0.8 V
--------------
1
–
⎝
⎠
⎛
⎞
=
150 Ω
=
Figure 8-39. AIP of a system.
ES
EIN
RS
RIN
+
RIN
---------------------
⎝
⎠
⎛
⎞
=
AIP in dBm
10
ES
(
)2
0.001RS
-------------------
θ
cos
×
⎝
⎠
⎜
⎟
⎛
⎞ 6.01 dB
–
log
=
Rs
Es
Eo
Ein
Rs
Eo
RL
Rin
P
EOUT
(
)2
ZLOAD
--------------------
⎝
⎠
⎜
⎟
⎛
⎞
θ
cos
(
)
=
10
P
0.001 W
--------------------
⎝
⎠
⎛
⎞
log
dBm
=
EL
Es
RL
RL
Rs
+
------------------
⎝
⎠
⎛
⎞
=

Interfacing Electrical and Acoustic Systems
141
where,
EL is the load voltage,
Es is the source voltage,
RL is the load resistance.
In the circuits of Fig. 8-40, assume the voltage E
is 1 V in both cases. The open circuit load voltage,
Fig. 8-40A would be:
For the matched circuit, Fig. 8-40B:
The ratio of the two load voltages, converted to
decibels, is:
8.12.5 When to Measure Z
Knowing the actual source, input, output, and load
|Z| is necessary if systems are to be installed prop-
erly. The installer must be aware of the difference
between the values normally specified by the manu-
facturers of equipment and the actual measured
values needed by the installer for matching.
There is usually a rated Rs, RIN, ROUT, and RL as
well as an actual value. Rs is the actual source
impedance (often an electroacoustic transducer) and
RIN is the actual input impedance of a system device.
ROUT is the actual output impedance of a system
device (as distinguished from its output impedance
rating) and RL is the load impedance (output imped-
ance ratings are usually the desired RL). Rated input
impedances are often the desired Rs.
The term “matching” may be read as “appro-
priate match.” Normally, only in the case of passive
devices is the appropriate value also the exact value.
There are two types of reactance—inductive and
capacitive. Resistance also has two components—ac
and dc. Impedance also can be seen as being
composed of lumped parameters (circuit compo-
nents all in one place) or distributed parameters such
as 100 miles of telephone cable.
8.12.6 System Problems Located by Z 
Measurements
Problems detectable via Z measurements vary. They
can detect such problems as reactive 70 V trans-
formers overloading power amplifiers, woofers in
incorrectly ported enclosures, link circuits not
matching passive devices to be inserted in them, and
discovery of intermittent circuits.
8.12.7 Gain and Loss Blocks*
Gain blocks are available in increments as small as
30 dB and as large as 100 dB. Very useful gain incre-
ments fall in the 40 dB area. If a high SNR is to be
maintained with variable gain blocks (e.g., mixers
and power amplifiers with gain control) while a
proper peaking factor and low distortion are
preserved, the variable gain control must be prop-
erly set. In the case of fixed gain blocks, variable or
fixed loss blocks will need to be inserted as required.
Loss blocks can be attenuators, mixing networks,
equalizers, and pads. A rule of thumb for a typical
sound system is that after algebraically totaling all
the gains and losses, you should have an overall gain
figure of approximately 115 dB. For example, assume
a microphone is calculated to have a sensitivity level
of −59 dBm in a sound field with an LP of 94 dB
Figure 8-40. Comparison of open and matched circuit.
RS
130 Ω
100,000 Ω
RL
RS
130 Ω
130 Ω
RL
A. Open circuit
B. Closed circuit
EL
1.0 100,000
100,130
-------------------
⎝
⎠
⎛
⎞
=
EL
1 V
≅
EL
1.0 130
260
---------
⎝
⎠
⎛
⎞
=
0.5 V
=
20
0.5
1
-------
log
6 dB
–
=
*Gain describes what “level” change occurs at the
system output upon insertion of the device into the
system. If the level goes down it is a “loss”. If the
level goes up it is a “gain”.

142
Chapter 8
receives an acoustic input of 88  dB. Then
94 dB −88 dB = 6  dB, and −59  dBm − 6  dBm =
−65dBm. If the sound system has a 100 W output
(+50 dBm), then we need 115 dB of gain to get from
the level at the mixer input to the level at the loud-
speaker at full power.
8.12.8 Typical Mixer Amplifier
A typical mixer amplifier has the following
specifications:
We know we must allow 10 dB as a meter lag
factor, so the −65 dBm program level out of the
microphone should cause the output of the mixer to
reach +8 dBm. Therefore, we need to adjust the
overall gain of the mixer to 73 dB. (The attenuators
in the mixer can be set back approximately
87dB −73 dB = 14 dB of working loss.) Suppose,
for the moment, that we are going to connect the
output of this mixer directly to the input of a power
amplifier having the following characteristics:
8.13 Total Electrical Gain of a System
The total electrical gain of a system is found using
the following equations:
(8-119)
where,
Gain in dB is the electrical gain of the total system,
 is the voltage amplification,
 is the coupling factor,
 is the impedance mismatch,
6.02 dB is the difference between a matched circuit
and an open circuit.
This means the amplifier will reach full output
from 50 dBm − 64 dB = −14 dBm. Again, to provide
our 10 dB meter lag factor, the most output we
would want to see at the output of the power ampli-
fier would be +40 dBm (10 W) of program material.
Therefore, the maximum input power would be:
The mixer amplifier is putting out a program
level of +8 dBm, and it should continue to do so to
ensure the maximum SNR. Consequently, we need
to insert +8 to −24 dB (32 dB) of attenuation in the
form of a pad or an input attenuator. This set of
circumstances is illustrated in Fig. 8-41. Note that
the pad has replaced the gain overlap.
8.13.1 A More Complicated System
Fig. 8-42 illustrates a more complex system, and the
graph below the block diagram is an example of a
gain chart. When first inspecting the total losses in
the system (10 dB + 14 dB + 14 dB + 14 dB = 52dB),
you should recognize that you had exceeded the
gain overlap available in the mixer and amplifier of
the previous example. This immediately suggests
that you need a line amplifier. It is highly desirable
never to come closer than 10 dB to the original input
level at any point in the system beyond the input.
This practice assures audio designers that the noise
voltages do not become additive—two equal noise
levels add to increase the noise 3 dB. For this reason,
the required gain block is placed between two loss
blocks rather than following the last gain block.
Observe, too, that the second gain block is also
adjusted to its highest program level, which leaves it
a 10 dB meter lag factor.
Gain
87 dB
Power output
+18 dBm (with low distortion)
Output noise
80 dB below full output 
Power output
100 W
=
50 dBm
=
Gain
64 dB
=
Gain in dB
20
EOUT
EO
-------------
log
20
RIN
RS
RIN 
+
-----------------------
⎝
⎠
⎛
⎞
log
10
RS
RL
------
⎝
⎠
⎛
⎞
log
6.02  dB
+
+
+
=
20
EOUT
EO
-------------
⎝
⎠
⎛
⎞
log
20
RIN
RS
RIN
+
---------------------
⎝
⎠
⎛
⎞
log
10
RS
RL 
-------
⎝
⎠
⎛
⎞
log
Figure 8-41. Simple system for gain overlap.
14  dBm
–
10 dB
–
24  dBm
–
=
88 dB-SPL
−65 dBm
+73 dB
+8 dBm
+40 dBm
−24 dBm
−32 dB
+64 dB
Microphone
Mixer
amplifier
Loss pad
Power
amplifier
−69 dBm to +18 dBm (87 dB gain) 
−14 dBm to +50 dBm
(64 dB gain) 
Gain overlap = −14 to +18 = 32 dB
Mixer
Power amplifier

Interfacing Electrical and Acoustic Systems
143
8.14 Interfacing the Electrical Output Power 
to the Acoustic Environment
The final electrical signal power in dBm can be
directly added to the loudspeaker’s EIA sensitivity
rating in dBm (i.e., the 30 ft, 0.001 W rating). The
EIA standards, both for microphones and for loud-
speakers, wherein LPs are directly converted to dBm
and the reverse, offer the quickest, easiest, and surest
technique for systems engineers. While compo-
nent-oriented individuals occasionally express a
desire for a voltage system rather than a power
system, they almost totally ignore the requirement of
converting from the acoustic to electrical domain and
back again to the acoustic. The very real final
product of a sound system is acoustic power and its
equitable distribution to listeners and a significant
diminution of it to nonlistener areas. Certainly a
systems approach can be constructed along lines
other than power, but we will be surprised if a more
logical and consistent technique than that of the dBm
method is arrived at by such advocates.
8.14.1 Simplified Efficiency Calculations
A 100% efficient radiator for a Q equal 1.0 at a
radius of 0.282 m and an electrical input of 1.0 W
would produce an acoustic level of Lp = 120. There-
fore the same radiator would produce
for 100% efficiency from 1.0 W at 1.0 m, with a
Q = 1.0.
A radiator with100% efficiency from 0.001 W at
30ft with a Q equal 1.0 would produce
The  following are the changes in SPL with
varying Q at two different references.
3.281 ft = 1.0 m.
To change from 0.001 W to 1.0 W add 30 dB.
To change from 1.0 m to 30 ft subtract 19.22 dB.
8.14.2 Damping factor**
A loudspeaker is intended to transfer energy through
air, by setting the air in motion alternately creating
high-and low-pressure zones near the cone. In order
to move air, the speaker cone must move. The cone
has some non-zero mass, so it has kinetic energy
which is non-zero. The energy is stored when the
cone is accelerated, and given up when it slows
down. Because of this storage, the cone does not
instantly reach full speed when a “step” of voltage is
applied to the voice coil, nor does it instantly stop
and reverse direction when the polarity of the volt-
ages is reversed. When the cone is moving, its
kinetic energy must be removed in order to stop it.
That is, since work equals force times distance, and
also work done on the moving body equals the
change in kinetic energy of the body, a force must be
applied while the cone moves some distance, in
order to stop it. The force applied may be due to
suspension friction, it may be due to the air resisting
cone motion, or it may be due to electrical damping.
If the rate of energy removal is low, (low damping,
low friction, and poor coupling to the air,) oscilla-
tions may occur at the resonant frequency of the
Figure 8-42. More complex system.
−65 dBm
+8 dBm
−2 dBm
−16 dBm
−30 dBm
+8 dBm
−6 dBm
+40 dBm
+73 
−10
−14
−14
+38
−14
+46
88 dB-SPL
Peak levels
Program levels
Noise floor
50
40
30
20
10
0
−10
−20
−30
−40
−50
−60
−70
−80
−90
120 dB
20log10
0.282 m
1.0  m
-------------------
+
109 dB
=
1.0 W, 1.0 m
Q  
 0.001 W, 30 ft
Q
109 dB
1.0
59.78 dB
1.0
112 dB
2.0
62.78 dB
2.0
115 dB
4.0
65.78 dB
4.0
118 dB
8.0
68.78 dB
8.0
121 dB
16.0
71.78 dB
16.0
**Damping Factor article was published in the
Syn-Aud-Con Newsletter, Vol.15, No. 2, P 30. Winter
1988 with permission from Gerald Tiers. The article
here is an edited version of the Newsletter article.
120 dB
20log100.282 m
9.144  m
-------------------
10log10
0.001  W
1.0  W
--------------------
+
+
59.78 dB
=

144
Chapter 8
speaker – the characteristic “hangover” or “tubbi-
ness” in the bass, (ringing also occurs in tweeters,
and is often controlled by adjusting the suspension
friction.) The damping force “F” is dependent on the
current, “I” which is inversely proportional to the
sum of the resistances, including the voice coil resis-
tance! The voice coil resistance is the largest resis-
tance in the circuit typically 5–7 Ω for nominal 8Ω
loudspeaker, it is the determining element.
Often neglected is an additional resistor which is
the acoustic radiation resistance. This provides addi-
tional damping, varying from little, in an inefficient
acoustic suspension speaker, to a possibly dominant
effect in a high-efficiency horn system. The horn
system is likely to be very tolerant of low damping
ratios, as the cone is coupled to a greater mass of air,
so that its own mass becomes less important by
comparison. The effect is similar to suppressing the
“ringing” of an L-C filter by properly terminating the
output. Speakers generally have an optimum amount
of damping, with which they perform best, and the
designer picks a trade-off involving efficiency, size,
range, and then adjusts the damping to conform to
the desired filter function response. To conclude:
Electromagnetic forces in the loudspeaker are a
function of the current in the voice coil. For a given
voltage, the current in the coil is determined by the
total circuit resistance, including that of the coil. It is
incorrect to leave voice coil resistance out. Those
wonderful damping ratios in the 30s and 40s are
wholly imaginary, and those amplifier damping
ratios of 1,000 will not be attainable in practice.
High-efficiency horn loaded loudspeakers are
necessary in large venues. The least number of loud-
speakers introduced into a system that adequately
covers the audience is good engineering practice.
The famous Klipschorn utilized the corner of a room
in order to horn load its low-frequency driver. The
Klipschorn’s vastly superior transient response to
low frequencies was demonstrated to me when I
connected one to a Hammond electronic organ
followed by hearing the clicks every time a key was
depressed. The performance of the Hammond
organs of that era was entirely dependent upon loud-
speakers with much uncontrolled mechanical
damping. The Klipschorn was carefully designed for
reproducing accurate sound whereas the speaker in
the Hammond was designed to produce sound.
Our thanks for much of the above to Jerrold S.
Tiers, Clayton, Mo. the key facts appeared as a
“Letter to the Editor” of a popular audio magazine,
correcting an erroneous article that had appeared
there.
8.14.3 Electrical Gain of a Typical System
When insertion gains and losses of sound system
components have been correctly measured, their
individual values give the level changes we will read
on a sound level meter at the listener’s ears in the
auditorium if we remove the component in question.
8.14.4 Treating Equalizer Loss
The passive equalizer poses an interesting problem
in that its loss is frequency-dependent. We suggest
taking an estimated working loss value of 10−14dB
if the sound system is to be a reinforcement system
and 4–6  dB if it is a playback system. In this
example, we would take a 10 dB loss. (Active
devices include gain makeup internally.)
8.14.5 Example of Gains and Losses
The following is an example of how to find the
gains and losses and outputs of various devices in a
sound system.
Microphone
Given:
Eo = 0.008 V (open circuit),
LP = 94 dB (test SPL),
Rmr = 150 Ω (manufacturers specified impedance),
Lm = 70 dB (talker’s level at microphone).
Find:
SV
20
Eo
log
LP
–
74
+
=
61.9  dB re 1.0 V
–
=
Gm
SV
10
Rmr
log
–
50
–
=
133.7 dBm for  LP = 0
–
=
Gm
Lm
+
63.7 dBm at the mixer input
–
=

Interfacing Electrical and Acoustic Systems
145
Mixer
Given:
ES = 9.1 V (output of this device),
ZS = 150 (output impedance of this device),
θ = 0° (angle of impedance).
Find:
8.14.6 Power Amplifier
Given:
LAIP = 21.4 dBm (output of preceding device),
EP = 15.5 V,
ZP = 8 Ω,
θ = 0°.
Find:
The following equations are reciprocal.
Voltage Amplitude:
(8-120)
Signal Amplitude:
(8-121)
Note: Voltages are not levels. Voltage amplification
is not gain. Level and gain are clearly defined in
existing standards. Misuse, even by a majority, is
not recognized by the authors.
8.15 Gain Structure Revisited
The earliest patented electrical sound reinforcement
system was the product of Western Electric. In the
patent application the system was referred to as
“Loudspeaking Telephone Outfit.” The foregoing
treatment of gain structure in Sections 8.13 and 8.14
is based on the concept of available power. This type
of analysis is applicable to all audio systems from
Western Electric’s earliest effort to the ones being
installed on the day this is being written in 2005.
Western Electric’s first patent date for their system
occurred in the year 1907. The employment of elec-
trical sound reinforcement systems appears then to
be just shy of being a century old.
In the period 1907 to 2005 the technologies
involved in the individual elements of a sound rein-
forcement system have undergone many revolu-
tionary changes from the simplest vacuum electron
tube to the latest VLSI (very large-scale integrated
circuits). In fact, the physical size of a single early
vacuum electron tube was about the same as that of
a modern handheld real time analyzer even though
the analyzer contains the equivalent of 100,000 or
more vacuum tubes. Incidentally, a single vacuum
tube wasted more power as heat than the power
required to operate a handheld RTA.
In spite of all of the changes in sound system
amplifying and signal processing technology, gain
structure analysis via the concept of available power
is applicable to all. This universality results because
this analysis technique does not depend upon
whether the system employs matched impedances or
not nor does it depend on whether impedances are
high or low or mixed values. A tool of such
all-encompassing applicability is worthy of being
studied and understood. The available power
method, however, is not without faults. It is cumber-
some to apply in the field because the available
power at either the input or output of a general
device cannot be determined by a single measure-
ment. One requires at least two measurements, an
open circuit voltage measurement with signal
present accompanied by an impedance measurement
in the absence of signal. We will now explore an
alternative system of level analysis, which though
dBm in
63.7 dBm (output of preceeding device),
–
=
LAIP
10
ES
2
0.001ZS
-------------------
θ
cos
×
log
6.02
–
=
21.4 dBm (AIP to next device)
=
LAIP
dBm
–
85.1  dB (mixer gain)
=
dBamp
10
EP
2
0.001ZP
--------------------
θP
cos
×
log
=
44.8 dBm (output)
=
dBamp
LAIP
–
23.4  dB (amplifier gain)
=
dBamp
dBm
–
108.5  dB (system gain)
=
Eo
0.001Rs
(
)
10
Laip
6.02
+
θ
cos
---------------------------
⎝
⎠
⎛
⎞
10
---------------------------------
×
=
Laip
10
Eo
2
0.001Rs
-------------------
⎝
⎠
⎜
⎟
⎛
⎞
θ
cos
log
6.02
–
=

146
Chapter 8
restricted in its applicability, is well adapted to the
present day electrical properties of the various elec-
tronic subsystems from which a sound reinforce-
ment system is constructed.
8.15.1 Two Port Devices
The subsystems constituting an overall sound rein-
forcement system are members of a class of devices
called two port devices. The symbol as well as the
significant external variables for an electrical two
port such as an amplifier, signal delay, equalizer,
transformer, etc. appear in Fig. 8-43.
The device of Fig. 8-43 features an input port
where the quantities of interest are the input voltage
Vi and input current ii. Similarly at the output port
the quantities are the output voltage V0 and output
current i0. The input voltage and current as well as
the output voltage and current in general are both
time and frequency dependent. At a given
frequency, they each may be described by phasors.
As drawn, where all four terminals are unique, the
device being represented would have a balanced
input and a balanced output. If the two lower termi-
nals were each connected to ground, the device
being represented would be unbalanced at both input
and output. An unbalanced input with balanced
output would have only the lower input terminal
connected to ground. An unbalanced output with
balanced input would have only the lower output
terminal connected to ground. In any event, the four
quantities are connected by a set of equations the
exact form of which depends upon the choice of
dependent and independent variables and whether or
not the device being described is linear or non-linear
in its behavior. In the case of a linear device the
describing equations are linear with coefficients
whose size do not depend on either voltage or
current. Even in a linear system the coefficients can
be frequency dependent. In a non-linear device, the
coefficients in the describing equation are functions
of the various voltages and currents. The coeffi-
cients are called the device parameters. These
parameters are crucial to the device designer but not
of importance here.
8.15.2 Field Adjustment by Voltage Only 
Analysis
The easiest and most convenient measurement made
in the field is that of potential difference between
two terminals. Such a measurement should prefer-
ably be made by an accurately calibrated wide band
scopemeter. Scopemeters combine the functions of
oscilloscope, dc volt-ohmmeter, and true rms ac
voltmeters. The advantage of such instruments is
that one can simultaneously display numeric values
of the desired voltage quantity as well as view the
signal waveform versus time. By making observa-
tions both with test signal applied as well as test
signal off it is possible to measure signal voltages as
well as determine noise floor voltages and detect if
unwanted oscillations are present.
It is necessary at this point to inquire what condi-
tions must be satisfied in order to make voltage only
analysis an accurate and viable technique. This can
be answered by examining a simplified generic two
port along with a source and a load as displayed in
Fig. 8-44.
The signal source has a time and frequency
dependent open circuit voltage denoted as vs and an
output impedance denoted as Zs. The input imped-
ance of the two port defined to be vi ⁄ii is Zi. The
action of the output port is described by a voltage
generator whose open circuit voltage is Avi in series
with an output impedance Zo. The complex voltage
amplification, A, describes the function performed
by the two port. If the device being represented were
a simple amplifier, A would be a description of its
frequency response. If it were an equalizer, A would
describe all of the amplitude peaks and dips along
with the associated phase changes all as a function
of frequency. If the device were a signal delay unit,
A would have an all pass character while intro-
ducing a negative phase shift proportional to
frequency. In sum, the arrangement of Fig. 8-44 can
describe any subsystem employed in the overall
sound reinforcement system.
What is of importance is the relationship between
the source voltage and the voltage that appears
Figure 8-43. An electrical two port device.
V0
i0
Vi
ii
+
+
−
−
Figure 8-44. Simplified generic two port with signal
source and load.
Z0
Zi
Zs
Zl
Vi
V0
Vs
AVi

Interfacing Electrical and Acoustic Systems
147
across the load connected to the output port. This
relationship can be written as
(8-122)
Now let’s examine the last of Eq. 8-122. Suppose
all of the devices composing the system were
constructed such that their output impedances were
very much smaller than their input impedances.
Remember that in a cascade of devices, the output
impedance of the first is the source impedance of the
following device. Additionally, the input impedance
of a following device constitutes the load impedance
for the previous device. Then the last equation
above could be written
(8-123)
The justification being that (Zs ⁄ Zl) << 1 and
(Zo⁄Zl) << 1. Suppose, for example, that the source
impedance magnitude whether it is real or complex
has an absolute magnitude of the order of 100Ω while
the load impedance similarly has an absolute magni-
tude of 10,000 Ω or greater. This being the case, the
error in each of the approximations above is always
less than 1% producing a total error that is always less
than 2%. Field voltage measurements themselves are
seldom made with such accuracy. When the imped-
ance ratios are satisfied, the magnitude of the voltage
amplification expressed in decibels will have at most
an inherent error of less than 0.2 dB.
Caution! The effect of interconnecting cable
capacitance must be included in calculating the
impedance Zi. To that end, consider Fig. 8-45.
Fig. 8-45 depicts a signal source, the shunt
capacitance of the interconnecting cable, and the
elements composing the input impedance of a two
port device. The cable capacitance CC can be readily
accounted for by incorporating its effect into a
calculation of a new value for Zi. CC and Ci are in
parallel so their values add to produce a total capaci-
tance Ct. Zi now becomes the parallel combination
of Ct and Ri. The magnitude of this impedance is
given by
(8-124)
What is needed is an equation that allows us to
calculate how much shunt capacitance can be toler-
ated. Eq. 8-115, when solved for Ct , produces
(8-125)
It should be clear from Eq. 8-116 that Ri must be
greater than the target value of the magnitude of Zi.
Taking 10,000 Ω as the target value, a realistic value
for Ri is 15,000 Ω . Additionally we desire the rela-
tion to be true throughout the system pass band so ω
is taken to be 2π times 20,000 Hz. Upon employing
these values Ct becomes 0.59 nF. Even if one allows
Ci to be 0.1 nF, a generous value, Cc becomes
0.49 nF. This value would allow several feet of
typical interconnecting cable to be employed without
the slightest departure from the previously stated
error limit. Raising the value of Ri and/or accepting a
lower value for the magnitude of Zi allows for larger
values of the total capacitance thus accommodating
longer cables. Even when the magnitude of Zi is
allowed to fall to 5000 Ω the error made in the
approximation of Eq. 8-114 is still negligible.
The majority, if not all of the subsystems of
current manufactures, satisfy the impedance ratio
conditions mentioned above including microphones
as well as power amplifier-loudspeaker combina-
tions. Microphones present source impedances
between about 50 Ω to 300 Ω while amplifiers have
inherent output impedances much smaller than the
loudspeaker load impedances that they must drive.
Now that the voltage analysis only technique has
been demonstrated to be a practical approach it will
be applied in setting up an example system.
vi
vs
Zi
Zs
Zi
+
----------------
=
vo
Avi
Zl
Zo
Zl
+
----------------
=
vo
Avs
Zi
Zs
Zi
+
----------------
Zl
Zo
Zl
+
----------------
=
vo
Avs
1
Zs
Zi
-----
1
+
--------------
1
Zo
Zl
-----
1
+
---------------
=
Avs
≈
Figure 8-45. Accounting for interconnecting cable
capacitance.
Zs
Cc
Vs
Ci
Ri
Zi
Ri
ωCt
---------
Ri
2
1
ωCt
---------
⎝
⎠
⎛
⎞2
+
------------------------------------
=
Ct
Ri
2
Zi
2
–
ωRi Zi
---------------------------
=

148
Chapter 8
8.15.3 Voltage from Input to Output
Voltage values in volts may be expressed on a loga-
rithmic scale by referencing to a convenient voltage
value. There are two reference voltages in common
use, one volt and 0.775 V. A voltage of one volt
when referenced to one volt and then expressed in
decibels becomes 0 dBV. Similarly a voltage of
0.775  V when referenced to 0.775  V and then
expressed in decibels becomes 0 dBu. The one-volt
reference value is obvious and simple. The 0.775V
reference stems from the fact that the voltage
required to produce a power level of 0 dBm in a
600Ω resistance is 0.775 V. A voltage value of one
volt when expressed in dBu is 2.21 dBu. Voltage
amplification or attenuation can also be expressed in
decibels. Here one is looking at a ratio of two volt-
ages namely output voltage to input voltage. If the
voltage ratio is 10, the voltage amplification
expressed in decibels is 20 dB. Notice the absence of
any third or trailing letter. Suppose the output
voltage value is 10 V. This becomes 20 dBV when
referenced to one volt. The input voltage must be
one volt. This becomes 0 dBV when referenced to
one volt. The amplification is the difference
between these two values or 20 dB. Similarly the
same output voltage in dBu is 22.21 while the input
is 2.21 dBu and again the difference is 20 dB. The
conclusion is that statements regarding voltage
amplification are independent of the choices of
voltage reference values.
Mixers are designed so as to minimize noise
while maximizing headroom at all points internal to
the mixer. This is often accomplished by employing
unity amplification at all stages beyond the micro-
phone or line input preamplifiers. The amplifica-
tions of these preamplifiers being adjusted as
necessary to bring the input signal in question up to
the internal operating “zero” value for the mixer in
question. Common practice in mixers is to refer-
ence signal voltages to 0.775 V with “zero” corre-
sponding to either 0 dBu or +4 dBu on the mixer’s
metering system. Headroom values in most mixers
fall in the range from 10 dB to 20 dB with 20dB
being quite common. Signal to noise ratio is best
preserved in an overall system when each subsystem
reaches clipping simultaneously. Consider the
system of Fig. 8-46.
The mixer features a meter “zero” of +4dBu,
operates with a +15 dB headroom, and clips at
+19 dBu. The equalizer operates with 0  dB net
voltage amplification, can accept an input of
+16 dBu at clipping, and produces an output of
+16dBu at clipping. The amplifier has a voltage
amplification of +34.3 dB, is rated at 200 W into 8Ω,
and clips when delivering 400 W into 8 Ω . The upper
row of numbers in Fig. 8-46 gives the voltage values
expressed in dBu at various points in the system
when driven to the clip point. The maximum power
output at clipping is 400  W. The lower row of
numbers represents normal operating conditions. The
system is designed to maintain headroom of +15 dB
throughout. In order to accomplish this, two attenua-
tors or voltage sensitivity adjustments are required.
As the equalizer can at most see or supply +16 dBu,
the output of the mixer must be dropped by 3dB. If
the equalizer’s input voltage sensitivity adjustment
precedes any internal active circuitry in the equal-
izer it may be used to accomplish the required atten-
uation. The same statement can be made with regard
to the power amplifier. When external attenuators are
required they are placed on the device requiring
attenuation. The attenuators themselves when
required are designed such that the preceding device
always sees the required high impedance.
Although the system has been analyzed with
regard to only voltage considerations internally,
power must be considered at the system output.
Loudspeakers inefficiently convert electric power
into acoustic power. The acoustic power is then radi-
ated into space. The electric power converted, the
acoustic power radiated, and the distributions of this
power in space are all frequency dependent. The
questions of the power required and how it should
be distributed in space to produce good listening
conditions in a given space are subjects that will be
treated in detail in the coming chapters.
Figure 8-46. Voltage structure of a simple system.
Mixer
Attenuator
−3 dB
Equalizer
0 dB
Attenuator
−13 dB
Amplifier
+34.3 dB
Load
8 Ω
+16 dBu
+16 dBu
+3 dBu
+37.3 dBu
400 W
+4 dBu
+1 dBu
+1 dBu
−12 dBu
+22.3 dBu
12.6 W
+19 dBu

Interfacing Electrical and Acoustic Systems
149
8.15.4 Thermal Noise Levels
Just by being an impedance, a microphone generates
thermal noise (TN ). If no acoustic signal were
present, the microphone would still produce a
minute output voltage. The open circuit thermal
noise relative to 1 V is −198 dB at 1 Hz bandwidth
(BW ) and 1 Ω resistance at a temperature of 293Κ
(68°F). Therefore we can write 
(8-126)
where,
the bandwidth is in Hz.
Taking our sample microphone with its SV of
−80 dB, we can see that for a bandwidth of
30 Hz–15,000 Hz and a resistance of 150 Ω, we
would have:
The available input power level from this micro-
phone’s thermal noise is given by
The EIA sensitivity of this microphone is
If a talker into the microphone produces a level of 
Lp = 74 dB, then the available talker signal power 
from the microphone will be
The SNR thus becomes:
8.15.5 Microphone and Loudspeaker Polarity
It is important to inspect microphone polarity before
using multiple microphones in a system. Keep
clearly in mind the distinction between polarity and
phase and give due consideration to each in the
setup of multiple microphone systems. Fig. 8-47
shows impulse responses of in-polarity and out-
of-polarity. Loudspeaker polarity needs to be exam-
ined as well.
8.15.6 Microphone Interconnections
Very low cost PA components may, on occasion,
use unbalanced, high-impedance outputs. The micro-
phone cable will in such cases be a single wire with
shield cable. If such a microphone must be used in an
emergency with a professional mixer, a high-imped-
ance unbalanced to a low-impedance balanced trans-
former must be used. In the case of a professional
low-impedance, balanced output microphone
needing to be connected to the high-impedance
unbalanced input of a PA component, a reversal of
the same transformer will serve the needs.
Microphone interconnections should also be
examined to see if phantom powering is present (be
sure phantom power is switched off when measuring
mixer input impedance).
Low-impedance balanced circuits use two wires
with a shield. The overall cable should, of course, be
sheathed in a nonconducting jacket. One of the most
frequent causes of extraneous noise in a sound
system is the microphone-cable combination that is
noisy when touched by the user. Be sure to test the
microphone-cable combination by rubbing along the
cable with your fingers while listening to the sound
system set at a high gain.
TN 1V
⁄
198
–
10
BW
log
10
R
log
+
+
=
198
–
10
14,970
(
)
log
10
150
log
+
+
134 dBV
–
=
LAIPN
198
–
10
BW
(
)
log
30
6.02
–
+
+
=
132 dBm
–
=
Gm
80
–
10
150
log
–
50
–
=
152  dBm for an Lp
0
=
–
=
Gm
Lp
+
152
–
74
+
=
78 dBm
–
=
Talker level
Noise level
–
78
–
1
132
–
(
)
–
=
54 dB
=
Figure 8-47. The effects of polarity on impulse
response.
Impulse Response
0.06
0.04
0.02
0.0
−0.02
−0.04
−0.06
0         620       1250     1875     2500     3150
Time in ms × 1000
Impulse Response
0.06
0.04
0.02
0.0
−0.02
−0.04
−0.06
0         620       1250     1875     2500     3150
Time in ms × 1000
A. In polarity
B. Out of polarity

150
Chapter 8
8.16 Conclusion
The authors take genuine delight in seeing well-
designed sound systems drawn in simple line block
diagrams with each block labeled as to its gain or
loss, input and output impedances (actual and
nominal), and link circuit voltages. Such systems are
easy to evaluate or to input with an external signal
or access a system signal.
Bibliography
G. Chory. “Measuring a Power Amplifier’s True Output Impedance,” Syn-Aud-Con Newsletter, Vol. 1, No. 3
(1974).
D. Davis. “Fundamentals of Audio Transmission,” Syn-Aud-Con Tech Topics, Vol. 12, No. 6 (1985).
D. Davis and C. Davis. “Electrical Gain and Loss from Voltage and Impedance Measurements,” Syn-Aud-Con
Tech Topic, Vol. 7, No. 3 (1979).
W. J. Kessler. “Vector Impedance Determination with a Simple Electronic Voltmeter,” Syn-Aud-Con Tech
Topic, Vol. 2, No. 4 (1975).
Radio Div., Western Electric Co. Sound Systems: General Theory and Practice. Western Electric Co., 1947.
M. C. Sprinkle. The Gain of Audio Amplifiers. Page Engineering, Inc., R-1152-0068 (July 1965).
_______. “The Ultimate Noise,” db Magazine   (June 1969) 
_______. “How Much Amplifier Power,” Audio (June 1971).
_______. “The Gain of Audio Amplifiers,” Syn-Aud-Con Tech Topics, Vol. 7, No. 7 (1980).

Chapter 9
Loudspeaker Directivity and Coverage
by Don Davis
151
9.1 Essential Definitions  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 153
Loudspeaker Coverage (C∠)  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 153
The Acoustic Origin  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 153
The Acoustic Center  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 153
Directivity Factor (Q) and Coverage Angle (C∠)  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 153
Directivity Plots . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 155
Loudspeaker Directivity Factor (Q)  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 155
Definition of Q  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 156
Geometric Q Transformed to Steradians, sr  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 156
Using Steradians for Site Surveys . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 157
C∠ , Q, and D1 for Spherical Segments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 158
Determining Minimum Geometric Q by Loudspeaker Placement  . . . . . . . . . . . . . . . . . . . . . . . . . . . . 158
9.2 Describing Q More Accurately  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 158
A Subtlety Regarding Q by Placement  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 159
9.3 Relationship Between C∠ and Q in an Idealized Case . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 159
9.4 Idealized Loudspeaker Geometry  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 160
Classic Method of Obtaining Axial Q . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 160
Equal-Angle, Weighted-Area Method . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 161
Processing the Polar Plots . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 162
The Critical Distance Method . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 164
Architectural Mapping . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 165
The Dangers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 165
9.5 Class D Audio Amplifiers  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 165
9.6 Sound as a Weapon  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 166
9.7 An Older View of Q . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 166
9.8 Summary  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 167
Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 167


   
Loudspeaker Directivity and Coverage
153
For decades, in the manufacturing of professional
sound equipment, the cost of facilities necessary for
the accurate measurement of loudspeaker directivity
led to closely held data by the manufacturers. Their
reasoning was two fold. One, the expense dictated
secrecy regarding methods and applications thus
withholding from competition. Second, many of
them felt that “honest” data was subject to misinter-
pretation by other than the few experienced users.
Since the first edition of Sound System
Engineering thirty years ago, a literal revolution in
data gathering, data sharing, and skill in data inter-
pretation has occurred worldwide. Once the key
parameters had been clearly identified and a cadre
of trained users had been developed, the advent of
field usable accurate analysis completed the explo-
sion of superior directional devices and their use by
competent designers and installers.
9.1 Essential Definitions
9.1.1 Loudspeaker Coverage (C∠)
Fig. 9-1 illustrates patterns for loudspeakers having
the same C∠ for a given plane but with differing Q.
Fig. 9-2 shows patterns for loudspeakers having the
same Q but different C∠. It can be seen that the C∠
assigned to a given plane of radiation is that angle
formed by the –6 dB points (referred to the on-axis
reading) and the source center.
The –6 dB point is of interest to the sound engi-
neer inasmuch as that angle should, in the ideal case,
intersect the audience area halfway back to the
source as compared to where the on-axis beam inter-
sects the audience.
The C∠ should be specified for as many planes as
are felt necessary. The usual case is to specify it for
the horizontal and vertical planes.
The new techniques evolving for use in array
mapping combined with analysis techniques that tell
you with precision the exact distance to the acoustic
origin rather than relying on geometry (which may
have nothing to do with the real acoustic origin
when “off axis”), allow prediction of acoustic
performance at the drawing board stage.
9.1.2 The Acoustic Origin
The acoustic origin is the apparent point in space
from which the sound emits as measured by the time
from the source to the measuring microphone. The
physical origin and the acoustic origin do not
normally coincide and the acoustic origin is
frequency dependent. To obtain signal alignment,
knowledge of the acoustic origins is essential.
9.1.3 The Acoustic Center
The acoustic center is found by projecting back to
the source from measured C∠s and finding where
they intersect at the source. On occasion, the
acoustic center will be in different locations for
vertical C∠s as compared to horizontal C∠s. This
results in a form of acoustic astigmatism that in turn
causes a divergence between the array mapping
prediction and the measured end result. The acoustic
center is normally in front of the driver mounted on
a horn and, in many constant directivity devices, it is
near the junction of the extended throat and the first
cross sectional perspective change.
Accurate mapping of coverage is dependent upon
all of these factors:
1.
Acoustic origin location (signal alignment).
2.
Acoustic center (acoustic astigmatism).
3.
The angular plot of level changes (making
source overlays).
4.
The on-axis Q value (for plotting relative Q and
changes in %ALCONS).
It is evident to most workers in the field that a
great deal of work remains to be done in terms of
mapping array coverage, adjusting coverage to its
maximum potential, and creatively using
mis-coverage for special effects. The tools, for the
first time, are available to allow a sufficient number
of talented workers at a reasonable cost to foster an
explosion of improved concepts, theories, and tech-
niques regarding the directional control of acoustic
energy.
9.1.4 Directivity Factor (Q) and Coverage Angle 
(C∠)
Directivity factor (Q) is always at a point. An area
may have an infinite number of points with the same
Q, but the area never has a Q. By definition, the
average Q around any loudspeaker or array is
always unity (Q = 1.0).
When loudspeakers are combined in arrays and
they are not at wavelengths where mutual coupling
operates, the energy from one device may interact
with a second device in such a way as to halve one
of the C∠s, such as the vertical in the case of stacked
horns. This narrowing of the vertical C∠ can, on
occasion, be highly desirable and help reduce
unwanted excitation of a too reverberant room by

154
Chapter 9
Figure 9-1. Polar response charts for loudspeakers possessing a coverage angle of 100° but different directivity 
factors. (Courtesy Altec)
A. Q =3.5
B. Q = 4.9
C. Q = 6.9
D. Q = 8.3
E. Q = 11.4
F. Q = 13.4

   
Loudspeaker Directivity and Coverage
155
not allowing that energy to fall on the more reflec-
tive surfaces but rather confining it to first strike a
highly absorptive area. This angular narrowing,
however, does not normally increase the Q. While
the angle is smaller, all the energy being produced is
not passing through the smaller angle, hence, gener-
ating more acoustic power per unit area but, rather,
is being dissipated in spurious “lobes” generated by
the same phase differences that also helped narrow
the C∠. We can talk about woofers in a bin at wave-
lengths where mutual coupling occurs as a single
device.
9.1.5 Directivity Plots
Both Qs and C∠s are derived from polar response
data. This data can take a multitude of forms, but at
the present time three techniques are most useful.
Polar Charts. Polar charts look like a polar map of
the earth. The transducer being measured is placed
on a turntable and rotated in synchronization with
the chart revolution in the level recorder.
Frequency Charts. Frequency charts are standard
frequency response plots done as overlays on the
same chart for every 10° or other chosen increments.
The 3-D Plot. The newest techniques are the 3-D
plots that allow angular information to be viewed
simultaneously with frequency and amplitude infor-
mation. Fascinating conceptual viewpoints of
beaming, lobing, and other aberrations become
completely accessible in these plots.
Such uniform level changes allow us to place the
farthest listener on-axis (this is hopefully the listener
requiring the highest Q) and to orient the device so
that listeners closer to the device are on the uniform
change in level with angle that exactly compensates
for their change in level due to being closer to the
source. A loudspeaker that does not change level
uniformly with angle would not allow such
compensation.
9.1.6 Loudspeaker Directivity Factor (Q)
If it were possible to construct a loudspeaker which
radiated sound energy only over its C∠ and nowhere
else, then it would be possible to describe its Q from
its C∠. While this is not the case in real-life loud-
speakers, and would not really be desirable from the
viewpoint of coverage, it is useful to imagine such a
case in order to gain a conceptual view of what Q is
and how it affects the results we wish to achieve
with the loudspeaker.
Figure 9-2. Polar response charts for loudspeakers with
similar values of Q but different useful coverage angles.
(Courtesy Altec).
C. Q = 11.4, CD = 85°
A. Q = 11.8, CD = 16°
B. Q = 11.1, CD = 68°

156
Chapter 9
9.1.7 Definition of Q
First, let us turn to a rigorous, authoritative defini-
tion of Q. In Appendix V of the Handbook of Noise
Measurement, Seventh Edition, by Arnold P. G.
Peterson and Ervin E. Gross, Jr.:
The directivity factor of a transducer
used for sound emission is the ratio of
sound pressure squared, at some fixed
distance and specified direction, to the
mean squared sound pressure at the
same distance averaged over all direc-
tions from the transducer. The distance
must be great enough so that the sound
appears to diverge spherically from the
effective acoustic center of the source.
Unless otherwise specified, the refer-
ence direction is understood to be that
of maximum response.
Arnold P. G. Peterson has asked the author to
point out that while the author uses various forms of
Q to explain room effects, it should be kept in mind
that only axial Q is recognized as a property of the
loudspeaker by acoustic authorities.
In a note to the above definition, the following
additional statement is made:
This definition may be extended to
cover the case of finite frequency bands
whose spectrum may be specified. The
average free field response may be
obtained, for example, by integration of
one or two directional patterns when-
ever the pattern of the transducer is
known to possess adequate symmetry.
Fortunately, high-quality commercial sound
loudspeakers do usually possess adequate symmetry
to allow acceptable accuracy with a vertical and
horizontal polar response. In cases where the polar
response of the loudspeaker is unusually lobed,
diagonal polar plots can be taken in addition to the
usual horizontal and vertical plots.
9.1.8 Geometric Q Transformed to Steradians, sr
Imagine a perfect spherical radiation pattern from a
loudspeaker—and imagine is all you can realisti-
cally do with real-life loudspeakers. Fig. 9-3 illus-
trates the spherical surface surrounding such a
source. In this case, the average sound pressure, LP ,
for the entire surface would equal the LP measured
on any specific axis. Therefore, the directivity ratio
would be unity, Q = 1.
The next logical question is, “What C∠ should
such a loudspeaker be given?” To compute two
angles that represent a sphere we can reason as
follows: Traditionally loudspeaker coverage was
specified in terms of horizontal and vertical
coverage angles in degrees. This was thought of by
many as a radius from a point that rotated in a 360°
circle horizontally followed by the rotation of the
same radius vertically for 360°. In fact, measure-
ments were carried out in exactly this manner. A
loudspeaker was rotated on a turntable 360° hori-
zontally and then 360° vertically in front of a fixed
microphone position. As a consequence many when
asked what would be the coverage angle for a spher-
ical radiator would answer 360° by 360°. Fig. 9-7A
uses this labeling method.
The advent of directivity factor Q measurements
led to thinking of loudspeaker coverage as area
covered. The rotation of a radius of fixed length in a
plane through an angle 360° defines all of the points
on the circumference of a circle contained in the
plane. Now if this circle is rotated about a diameter
of the circle through an angle of 180°, the figure so
generated is the surface of a sphere whose radius is
the same as that of the circle. This is the reason for
the rotation limits in spherical coordinates. The
azimuthal angle ranges from zero to 360° in the
complete description of the spherical surface. It is
important to realize that the rotation of a fixed
length radius through 360° regardless of the plane in
which it occurs describes only a circle.
The equations in Fig. 9-4 do this for all angles
for sr, Q, and percent of spherical surface covered
greater than 180° × 180°. For angles less than
180° × 180°, use Eq. 9-6.
Polar lunes, see Fig. 9-12, can describe angles
greater than 180° × 180° as is depicted in Fig. 9-4. It
does this by summing steradians. In restudying
steradians for this volume, it became apparent that
Figure 9-3. Spherical radiation surface.
Q = 1
A

   
Loudspeaker Directivity and Coverage
157
steradians should have been used instead of Q for
Directivity Factor. Both units essentially define area
in sound system usage; the audience area is the ideal
case. Hopkins-Stryker, critical distance, directivity
index, etc., have been re-written for both steradians
and Q in this book. When large arrays are involved,
the ability to sum all of the individual steradians to
obtain the total steradians for the computation of
total LW is invaluable. Additionally, the audience
area can be defined as a steradian value
(9-1)
where,
sr is the solid angle in steradians,
A is the audience area,
r is the distance from the source to the listener.
Sr is the SI unit, Q is not. It thus behooves us to
become more familiar with this parameter because it
is more versatile, internationally accepted, and until
now, neglected in audio.
9.1.9 Using Steradians for Site Surveys
When surveying existing sites, such as church audi-
toriums, gymnasiums, public halls, etc., a superior
sales tactic is to provide a demonstration of your
capabilities as part of your presentation. Many
contractors employ portable hoists allowing quick
setups of suitable equipment to match the
auditorium’s needs.
A quick way to arrive at an accurate estimate of
what directivity should be of the loudspeakers to be
used is to measure the audience area (in any dimen-
sion you wish, feet, meters, inches,) and the radius
from that area to a preferred test location. The direc-
tivity in Steradians can then be calculated by:
(9-2)
(9-3)
where,
A is the area of the audience,
sr is the directivity in Steradians,
R is the radius from the audience area to the desired
source location.
We use Steradians because when it becomes
apparent that more than one device will be required,
the total directivity factor can be determined by
simply adding the Steradians of the individual
devices and converting the sum to a Q value.
Figure 9-4. MathCAD program depicting great circle coverage.
sr
A
r2----
=
sr
A
R2
------
=
Q
4π
sr
------
=

158
Chapter 9
Knowledge of the total Q value is then used in the
estimation of the intelligibility that will be achieved.
Knowledge of the radius allows levels to be
calculated by the inverse square law for the direct
sound. From these simple parameters you will have
already gained an excellent idea of what equipment
will properly fit in the space.
See Table 9-1 for table of directivity factors
expressed as Q.
9.1.10 C∠ , Q, and D1 for Spherical Segments
Fig. 9-5 depicts a sphere, a hemisphere, a quarter of
a sphere, and an eighth of a sphere. Fig. 9-6 also
provides additional help in visualizing Q and loud-
speaker placement. Always keep in mind, however,
that real-life loudspeakers do not follow these
simple relationships.
9.1.11 Determining Minimum Geometric Q by 
Loudspeaker Placement
(9-4)
For Q = 1.0 (4π sr), solid angle = 4π.
9.2 Describing Q More Accurately
The measurement of the directivity factor (Q) is
always at a point. There can be a series of points
within an area that have the same Q thus allowing
the concept of an average of Qs within an area. It is
normal practice to measure Q on axis (the zero angle
axis usually, but not always, being the highest
output as well). Let’s call this measurement Qaxis.
The value Q is both frequency dependent, Qaxis(f),
and, for real life devices, angularly dependent. Qaxis
specifies the angle relative to the transducer. For
angles other than the “on axis” position we could
specify a Qrel.
(9-5)
where,
±C∠ dB indicates the level in dB of the particular
angle relative to the level in dB on axis.
A complete descriptive may be specified by:
(9-6)
where,
f is the frequency at which the measurement is
made.
Another useful convention would be to agree that
where no “f ” is specified then the 1⁄3 octave band at
2000 Hz is indicated.
In the design of a sound system we use:
(9-7)
where,
Table 9-1. Loudspeaker Q and Directivity Index DI
Q
DI
Q
DI
Q
DI
1
0.00
12
10.79
50
16.99
2
3.01
13
11.14
60
17.78
3
4.77
14
11.46
70
18.45
4
6.02
15
11.76
80
19.03
5
6.99
16
12.04
90
19.54
6
7.78
17
12.30
100
20.00
7
8.45
18
12.55
—
—
8
9.03
19
12.79
—
—
9
9.54
20
13.01
—
—
10
10.00
30
14.77
260
24.15
11
10.41
40
16.02
Figure 9-5. Spherical segments.
Sphere
Q = 1
Hemisphere
Q = 2
One-quarter sphere
Q = 4
One-eighth sphere
Q = 8
Solid 
angles
Q
1. Suspended equidistant from all surfaces
 4π
1
2. Mounted at center of ceiling or wall surface
2π
2
3. Mounted at intersection of any two surfaces
π 
4
4. Mounted at intersection of any three surfaces
 π/2 
8
Q
4π
sr
------
=
Qrel
Qaxis10
C∠
±
dB 
10
-----------------------
⎝
⎠
⎛
⎞
=
Qrel
Qaxis10
C∠
±
dB 
10
-----------------------
⎝
⎠
⎛
⎞
f
=
Qmin SS
(
)

   
Loudspeaker Directivity and Coverage
159
SS stands for single source and which usually is
synonymous with Qaxis but may, on occasion, actu-
ally be a Qrel.
The term “min” indicates that it is the minimum
value that will allow the %AlCONS required at that
point.
If more than one source is used, we encounter the
term NQmin wherein we increase the Q of the first
device proportionately to the number (N) of addi-
tional devices (of equal acoustic power output).
We also employ the term Qavail whereby we can
calculate the N required for a multiple source system
(9-8)
A further refinement is the direct calculation of a
distance, D2, at which the Qavail results in the same
ratio of direct-to-reverberant sound as NQmin would
have provided.
At the current time we utilize the following Q
descriptives: Qrel, Qavail, Qaxis, Qmin along with the
descriptive modifiers: SS, ±C∠, dB, N, and f.
9.2.1 A Subtlety Regarding Q by Placement
An often misinterpreted point with regard to estab-
lishing a directivity factor, Q, by placement of the
source near a reflecting surface (mirror images) is
that the source must be at, not in, the surface,
Fig. 9-6A and B.
Loudspeakers mounted in the wall will, at lower
frequencies, exhibit “mutual coupling” as shown in
Fig. 9-6B. When a single speaker is mounted in a
wall, half the power goes into another space, if the
rear of the loudspeaker is not enclosed. When
mounted near the wall, half the power is reflected
back into the space.
9.3 Relationship Between C∠ and Q in an 
Idealized Case
Fig. 9-7 is intended to further assist you in devel-
oping a conceptional view of Q and DI in terms of
C∠. Fig. 9-7A shows the angular distribution of a
point source defined as the angles formed by the
interception of two spherical surface segments. This
figure shows what the Q and DI would be for
various combinations of C∠ if all radiation were
confined to the angular coverage. While looking at
these idealized coverages, remember that real loud-
speakers with these same coverage angles also have
side, back, top, and bottom lobes that lower the Q,
often drastically.
Fig. 9-7B shows that an idealized cone loud-
speaker column (C∠ = 180° × 40°) would be limited
to a Q of 9. This is because with cones the hori-
zontal coverage would be close to 180°. While the
vertical beam narrows, it does not become narrower
than 40° anywhere in the useful frequency spectrum.
Again, keep in mind that this would be for a perfect
unit that had no back, side, top, or bottom radiation.
In contrast, Q would theoretically be 26 for an
idealized multicellular horn (C∠ = 40° × 40°). This,
again, assumes that no back, side, top, or bottom
radiation exists.
Raising Q gives useful on-axis increases of LP .
For example, in the case of the ideal column versus
the ideal multicell, a DI of approximately 14 minus a
DI of 9.5 = 4.5 dB of useful on-axis sensitivity
improvement. The multicell would allow the neces-
sary power requirement to be almost 1⁄3 less than that
of the sound column.
N
Qmin
Qavail
--------------
=
Figure 9-6. Q by placement. (From Henney’s Hand-
book of Engineering)
6R
3R
F
D
E
C C
B
A
B
B
C
C
C
C
D
E
E
D
F
F
1 2
3 4
C
B. Effect of adding pistons and reflecting planes on
radiation impedance. All pistons marked with the same
letter see the same radiation impedance.
A. Primary images 2, 3, 4 of piston 1 introduced by
planes Y and Z.
X
Y
Z

160
Chapter 9
9.4 Idealized Loudspeaker Geometry
Loudspeaker directional geometry is of interest to
the audio engineer because it allows the develop-
ment of relative areas associated with different C∠.
The basic formula for finding Q in the idealized case
of all energy passing through C∠ is:
(9-9)
Since Q is the inverse of area, we can then write:
(9-10)
These geometrical equations are useful in deter-
mining the minimum apparent Q that could theoreti-
cally be associated with a given requirement of C∠.
One of the authors was instrumental in the first Q
measurements ever published by a commercial
sound manufacturer. The methods available today
include:
1.
The equal-area, multiple-microphone method.
2.
The equal-angle, weighted-area method.
3.
The critical-distance method.
9.4.1 Classic Method of Obtaining Axial Q
In the noise-measurement field, a relatively standard
measurement procedure has been in effect since
1953 (first outlined by Gross and Peterson in the
1953 edition of the Noise Measurement Handbook).
This method calls for a series of measuring points
spaced about the sound source so as to allow each
measuring point to represent an equal area on the
surface of the sphere. Because of the nature of such
geometric patterns, only six such sets of uniformly
distributed points are possible. These six sets have
2, 4, 6, 8, 12, and 20 uniformly distributed points.
Fig. 9-8 illustrates plane views of such points. The
coordinates are given in terms of distances from the
center along three mutually perpendicular axes (x, y,
z). The “+” refers to the existence of two points, one
above the x-y reference plane and one below. When
measurements are to be made on a hemisphere, only
the four points above the plane are used. Fig. 9-9
shows how such coordinates are utilized to find the
desired points.
The length of the vector to the point is found by:
(9-11)
The angle between the z-axis and the vector is
found by:
(9-12)
The LP measured at each of the equal-area points
is averaged by converting to power ratios, adding
them (dividing them by 2 if only hemispherical
measurements are taken, as is often the case), taking
10 times the logarithm of the sum of the powers, and
subtracting 10 times the logarithm of the number of
points sampled. This gives the average LP around
the sound source being measured; this is identified
as 
.
(9-13)
Figure 9-7. Coverage angles, directivity ratio, and
directivity index.
β
α
α–Degrees
β–Degrees
Directivity index–Decibels
Ideal Sound Column
Ideal Multicell Horn
D1
Q
B. C∠, Q, and DI compared in idealized case
A. Angular distribution
Q
180
arc
θ
2---
sin
⎝
⎠
⎛
⎞
φ
2---
sin
⎝
⎠
⎛
⎞
×
sin
-------------------------------------------------------------
=
Relative area
arc
θ
2---
sin
⎝
⎠
⎛
⎞
φ
2---
sin
⎝
⎠
⎛
⎞
×
sin
180
-------------------------------------------------------------
=
Vector length r
x2
y2
z2
+
+
=
Angle
z( )
acos
=
LP
LP
10
10
LP 1
( ) 10
⁄
10
LP 2
( ) 10
⁄
…
10
LP n
( ) 10
⁄
+
+
+
(
)
log
10
Number of points
(
)
log
–
=

   
Loudspeaker Directivity and Coverage
161
Then Q is found by taking the point of the
highest level (usually the on-axis point) and
subtracting from it the 
. The power antilog of this
becomes Q.
(9-14)
This is called the axial Q. If some other point
instead of the on-axis point is chosen, then the
calculation becomes the relative Q. This may be
further modified into apparent Q by multipliers that
will be introduced later.
Manufacturers of loudspeakers have not used this
method but rather have concentrated over the years
on gathering polar response data, usually in the hori-
zontal and vertical planes only. Various methods of
utilizing such data in order to obtain Q have been
tried over the years. While recognizing that the first
attempts were crude, it should also be recognized
that at the time the cruder methods were used, the
alternative was no Q data at all.
9.4.2 Equal-Angle, Weighted-Area Method
Real-life loudspeakers radiate sound over the C∠
and out of the sides, top, and bottom. In order to find
the axial Q, it is necessary to average the SPL over
the entire space surrounding the source. The method
proposed by the author is one derived out of work
done by Ben Bauer, C. T. Molloy, and Bob Beavers.
This method requires a horizontal and vertical polar
plot for each of seven octave bands—125 Hz,
250Hz, 500 Hz, 1000 Hz, 2000 Hz, 4000 Hz, and
8000 Hz.
Fortunately, octave intervals offer more than
enough detail to allow accurate planning of the
effect of Q on such variables as gain, articulation
loss of consonants, etc. Also, most commercial
loudspeakers are sufficiently symmetrical in their
polar responses to allow the use of a horizontal and
vertical polar plot at each octave interval. In some
Figure 9-8. Plan views of points uniformly distributed
on the surface of a sphere of unit radius.
A. Eight points
B. Twelve points
C. Twenty points
LP
Q
10
LP on axis
(
)
LP
–
(
) 10
⁄
=
Figure 9-9. Locating measuring points on a spherical
surface.
r has been normalized to unity so that
arccos of z is arccos of z/r

162
Chapter 9
rare cases, additional diagonal plots have to be
taken, see Fig. 9-10.
Since both a vertical and a horizontal polar
response are taken at each frequency, the manufac-
turer must then process fourteen polar plots in order
to obtain the desired data for a particular loud-
speaker.
9.4.3 Processing the Polar Plots
The method of processing the polar plots is illus-
trated in Table 9-2. Starting at the 0° on-axis point
of the polar plot, assign an arbitrary value of 100dB
to the 0° point. Tabulate the relative differences in
level, referred to this level, for each 10° point all the
way around the horizontal plot. Continue on the
Table 9-2. Weighting Polar Data Taken at 10° Intervals to Correspond to Measurements Taken from Points 
Surrounded by Equal Surface Areas
Angles
LP
Rel LP
Weighting
LW
0° (on axis)
100
1.000000 × 1010
0.002418 
2.418000 × 107
10° & 350°
99
7.943282 × 109
0.004730(2)
7.514345 × 107
20° & 340°
97
5.011872 × 109
0.008955(2)
8.976263 × 107
 30° & 330°
96
3.981072 × 109
0.012387(2)
9.862707 × 107
 40° & 320°
94
2.511886 × 109
0.014990(2)
7.530636 × 107
 50° & 310°
93
1.995262 × 109
0.016868(2)
6.731217 × 107
 60° & 300°
93
1.995262 × 109
0.018166(2)
7.249187 × 107
 70° & 290°
92
1.584893 × 109
0.019007(2)
6.024813 × 107
 80° & 280°
91
1.258925 × 109
0.019478(2)
4.904270 × 107
 90° & 270°
88
6.309574 × 108
0.019630(2)
2.477139 × 107
100° & 260°
86
3.981072 × 108
0.019478(2)
1.550866 × 107
110° & 250°
85
3.162278 × 108
0.019007(2)
1.202108 × 107
120° & 240°
85
3.162278 × 108
0.018166(2)
1.148919 × 107
130° & 230°
83
1.995262 × 108
0.016868(2)
6.731217 × 106
140° & 220°
82
1.584893 × 108
0.014990(2)
4.751510 × 106
150° & 210°
81
1.258925 × 108
0.012387(2)
3.118862 × 106
160° & 200°
80
1.000000 × 108
0.008955(2)
1.791000 × 106
170° & 190°
80
1.000000 × 108
0.004730(2)
9.460000 × 105
180° (off axis)
80
1.000000 × 108
0.002418
2.418000 × 105
Total
6.934851 × 108
Example Vertical Polar Data at 1000 Hz
Angles
LP
Rel LP
Weighting
LW
 10° & 350°
100
1.000000 × 1010
0.004730(2)
9.460000 × 107
 20° & 340°
100
1.000000 × 1010
0.008955(2)
1.791000 × 108
 30° & 330°
100
1.000000 × 1010
0.012387(2)
2.477400 × 108
 40° & 320°
99
7.943282 × 109
0.014990(2)
2.381396 × 108
 50° & 310°
96
3.981072 × 109
0.016868(2)
1.343054 × 108
 60° & 300°
94
2.511886 × 109
0.018166(2)
9.126186 × 107
 70° & 290°
93
1.995262 × 109
0.019007(2)
7.584790 × 107
 80° & 280°
92
1.584893 × 109
0.019478(2)
6.174110 × 107
 90° & 270°
91
1.258925 × 109
0.019630(2)
4.942541 × 107
100° & 260°
89
7.943282 × 108
0.019478(2
3.094385 × 107
110° & 250°
87
5.011872 × 108
0.019007(2)
1.905213 × 107
120° & 240°
85
3.162278 × 108
0.018166(2)
1.148919 × 107
130° & 230°
79
7.943282 × 107
0.016868(2)
2.679746 × 106
140° & 220°
75
3.162278 × 107
0.014990(2)
9.480509 × 105
150° & 210°
72
1.584893 × 107
0.012387(2)
3.926414 × 105

   
Loudspeaker Directivity and Coverage
163
vertical plot in the same manner but skipping the 0°
and 180° points (already recorded). Convert each LP
level to a relative power ratio (Rel LP). Multiply the
ratio by a weighting factor proportional to the area
surrounding the measuring point in terms of a
sphere with a surface of unity. Total all the
weighted power ratios (LPW). Then subtract 10
times the logarithm of the sum from the on-axis
reading of 100 dB and take the power antilog. This
is the axial Q. Figs. 9-11 and 9-12 depict two
methods of dividing a sphere into relative areas
surrounding each 10° point. Fig. 9-11 shows the
zonal method (best for a cone loudspeaker or
exactly symmetrical one-cell horns). Fig. 9-12
shows the quadrangle method (best for loudspeaker
types other than a single cone or an exactly
symmetrical one-cell horn). The dash lines are an
extension of the great circles forming the bound-
aries of the area under consideration. To avoid an
overcrowded diagram, only a few such areas are
shown in either view. Table 9-3 shows spherical
areas.
Obviously, the same polar charts used to calculate
Q can also be used to obtain C∠ (the 6 dB-down
points from the on-axis reading expressed as an
angle). During the calibration of the equipment for
the polar responses, the on-axis sensitivity can be
measured at the 1 m–1 W, 4 ft–1 W, etc. This should
then be translated into the EIA rating, 30 ft at 0.001W.
The four primary measurements are:
160° & 200°
74
2.511886 × 107
0.008955(2)
4.498789 × 105
170° & 190°
72
1.584893 × 107
0.004730(2)
1.499309 × 105
Total
 1.238267 × 109
10log [6.934851 × 108 + 1.238267 × 109] = 92.86 LP
10(100–92.86)/10 = 5.18 = Q at 1000 Hz
10log 5.18 = 7.14 dB = DI at 1000 Hz
Table 9-2.  (cont.) Weighting Polar Data Taken at 10° Intervals to Correspond to Measurements Taken from Points 
Surrounded by Equal Surface Areas
Angles
LP
Rel LP
Weighting
LW
Figure 9-11. Sphere divided into polar lunes. (Courtesy
The Audio Engineering Society).
φ = 0°
φ = 90°
θ = 0°
sin θdθ = cos θ1 − cos θ2
θ2
θ1
Figure 9-10. Sphere divided into zones.
90° Vert
90° 
Horiz
270° 
Horiz
270° Vert
180°
"Off axis"
0°
"On axis"
Horizontal
polar plot
Vertical
polar plot
90° Vert
90° 
Horiz
270° 
Horiz
270° Vert
180°
"Off axis"
0°
"On axis"
Horizontal
polar plot
Vertical
polar plot
45°
left
45°
right
A. Vertical and horizontal only
B. Diagonal plots added

164
Chapter 9
1.
Q in octave bands.
2.
C∠ in octave bands.
3.
Axial sensitivity in octave bands.
4.
Power handling (program levels).
9.4.4 The Critical Distance Method
The technique most widely used in the actual testing
of arrays in large auditoriums and arenas is the
measurement of the critical distance, Dc, on the axis
of interest. If the engineer has a calibrated Q loud-
speaker on hand the measurement of LD and LR
allows
(9-15)
and
(9-16)
where,
Dc is the critical distance in ft or m,
Ref distance is a distance in ft or m from the speaker
in the free field of the loudspeaker that is  ≥10 dB
above the reverberant sound field,
LD is the sound level at the reference distance,
LR is the sound level in the, hopefully, steady rever-
berant sound field,
S
 is the total absorption in ft2 or m2 (this will auto-
matically include any modifiers that may be
present as well),
Q is the directivity factor of the test loudspeaker at
that frequency, octave band, etc.
Having obtained the needed absorption figure,
measure the Dc of the array in the same way and use
the S
 obtained from the first measurement to
calculate:
(9-17)
Figure 9-12. Polar response alignments.
Table 9-3. The 10° Spherical Areas for Zones and 
Quadrangles
10° Intervals
Area of Spherical 
Zone
Area of Spherical 
Quadrangle
0° (on axis)
0.003805302
0.004835888
10°
0.030268872
0.037841512
20°
0.059618039
0.071640216
30°
0.087155743
0.099098832
40°
0.112045263
0.119916888
50°
0.133530345
0.134945232
60°
0.150958174
0.145327696
φ = 0°
φ = 90°
θ = 0°
A1 A2 A3
β
α
A1 =
arcsin (sin    × sin
θ
2
2
φ)
180
φ = 0°
φ = 90°
θ = 0°
A. Side view 
B. Front view
70°
0.163799217
0.152053952
80°
0.171663302
0.155822296
90°*
0.087155744
0.078517492
Total = 1.000000001
Total = 1.000000004
* The 90° area is to the hemisphere dividing point only. For 
horizontal and vertical plots there are two on-axis areas, 
eight areas for angles between 0° and 90°, and four areas at 
90°. When right and left diagonal polar plots are added, then 
there are two on-axis areas, 16 areas for angles between 0° 
and 90°, and eight areas at 90°.
Table 9-3.  (cont.) The 10° Spherical Areas for Zones 
and Quadrangles
10° Intervals
Area of Spherical 
Zone
Area of Spherical 
Quadrangle
Dc
Ref distance for LD
10
LD
LR
–
(
)
20
------------------------
×
=
Sa
Dc
2
0.019881Q
---------------------------
=
a
a
Q
Dc
2
0.019881Sa
-----------------------------
=

   
Loudspeaker Directivity and Coverage
165
When measuring Dc, the first measurement is
made as far into the reverberant sound field as it is
convenient to get—2 to 3 times Dc is ideal.
The second measurement is made by walking
toward the loudspeaker (usually on the axis) until
the sound level is a minimum of 10 dB higher than
the reverberant sound field measurement—again,
typically 10 to 15 dB. This insures that the rever-
berant sound field does not significantly influence
the direct sound field measurement. An excellent
idea of how steady the reverberant sound field is can
be quickly reached during the sampling of it for the
reverberant measurement.
The accuracy of this method is defined by
precisely the same constraints that apply to the use
of Sabine’s reverberation equations. This technique
should not be used wherever Sabine’s reverberation
equations cannot be applied.
9.4.5 Architectural Mapping
Since the Pharaoh Zoser and his architect-astron-
omer-scientist-magician-visier, Imhotep, first built
pyramids approximately 6000 years ago (i.e., 3000–
4000 B.C.), architectural renderings have changed
little. The floor plan and section view are still the
architectural mainstays.
Unfortunately, attempting to distort the essen-
tially spherical wavefronts of various kinds as they
intersect with linear dimensions on drawings into
readily recognizable patterns has, for that same
period, defied solution thus leading to Astrolabes’,
Orrery’s, and other spherical devices that allow
accurate measurements to be undertaken with visu-
alization of the answer.
Over the centuries, map-makers have exhibited
great ingenuity in creating flat maps of spherical
areas but always with serious distortion hidden
somewhere in the rendering.
The design of the loudspeaker coverage of an
audience area has traditionally followed this centu-
ries old pattern to the consequent discomfort of the
listener located in one of the hot or dead spots over-
looked by these “flat earth” techniques. Today repu-
table companies provide remarkably useful data and
design programs that allow full manipulation of
such data in 3-D visual presentations.
9.4.6 The Dangers
It is the temptation to become so involved in
obtaining superior coverage that you overlook the
very real problems of:
1.
When to vary the Q of a device and when you
can vary its LW instead.
2.
The cumulative “N ” factor.
3.
The necessity to use the LW of only the devices
supplying LD to a point of measurement or
observation vs. the total LW supplying LR.
4.
When to turn from the Peutz equation using Q,
V, RT60, etc., to the Peutz equation using LD, LR,
LN, and RT60. (This is, in our opinion, one of the
most serious flaws in several of the most
promoted “flat earth” techniques and one, we
fear, not even understood by those advocates.)
5.
Solving the %ALCONS and PAG = NAG before N
is accurately determined leads to nonsense such
as %AlCONS predicted from relative dB values
obtained from range and device coverage but
divorced from the shifting LW due to N.
You will find in other chapters of this book the
constraints placed on how coverage is achieved by
the necessity to achieve useful intelligibility, acoustic
gain, and the utilization of existing devices. Often
beautiful coverage can be achieved by a multiple
driver array only to find that the number of sources
has reduced intelligibility to an intolerable level,
which results in a shortening of the distance that
sound can be successfully projected and which, in
turn, leads to a whole new approach to coverage—
perhaps from high density overhead distribution
rather than a multi-driver single source array.
9.5 Class D Audio Amplifiers
Class D audio amplifiers in the multiple kilowatt
range can be held in the palm of your hand. A class
D amplifier works in very much the same way as a
pulse width modulation (PWM) power supply.
Starting with the assumption that the input signal
is a standard audio line level signal that is sinusoidal
for the frequency ranging from 20 Hz to 20 kHz, this
signal is compared with a high-frequency triangle or
sawtooth waveform to create the PWM signal. The
PWM signal is then used to drive the power stage,
creating an amplified digital signal, and finally a
low pass filter is applied to the signal to filter out the
PWM carrier frequency and retrieve the sinusoidal
audio frequency.
Linear amplifiers are inherently very linear in
terms of their performance, but are also very ineffi-
cient at about 50% typically for a class AB ampli-
fier, whereas a class D amplifier is much more
efficient with values in the order of 90% in practical
designs. With linear amplifiers, the gain is constant
irrespective of bus voltage variations; however with
class D amplifiers the gain is proportional to the bus

166
Chapter 9
voltage. This means that the power supply rejection
ratio (PSRR) of a class D amplifier is zero dB,
whereas the PSRR of a linear amplifier is very good.
It is common in class D amplifiers to use feedback
to compensate for the bus voltage variations.
In linear amplifiers the energy flow was always
from supply to the load, and in full bridge class D
amplifiers this is also true. In half bridge class D
amplifiers the situation is different as the energy
flow can be bidirectional which can lead to the “bus
pumping” phenomenon. Bus pumping is caused
when the bus capacitors are charged up by the
energy flow from the load back to the supply; this
occurs mainly at the low audio frequencies, i.e.,
below 100 Hz.
At the present time at least two major audio
manufacturers are utilizing 4 kw multichannel class
D amplifiers in conjunction with loudspeaker arrays
specifically designed to match the parameters of
their amplifiers. Previously, most class D amplifiers
have been utilized in automotive sound system
applications. Using dedicated DSPs to control the
amplitude, phase, and delay to the multiple loud-
speakers in the array introduces the possibility of
more controlled audience coverage.
9.6 Sound as a Weapon
The frequency of a sound, or the level of a sound,
can be used as a weapon. Infra sound is low
frequency audio that is below the human range of
hearing. Infra sound constantly surrounds us, gener-
ated naturally (wind, waves, earthquakes) and by
man, building activity, traffic, air conditioners. At
higher volumes infra sound of around 7–20 Hz can
directly affect the human central nervous system
causing disorientation, anxiety, panic, nausea, and
eventually unconsciousness. The effect can be
generated by the extreme low frequencies in church
pipe organ music, thereby creating certain emotional
effects. (The Broadway play, Emperor Jones, used
sub-sonic air couplers to cause a feeling of appre-
hension prior to the Voodoo scenes at the beginning
of the 2nd act.) Low-frequency sound generated
naturally or by building work in traffic is said to be
the cause of reported apparitions and hauntings
blamed on the ghostly 19 Hz frequency, which
matches the resonate frequency of the human
eyeball.
There is currently on the market, as I write this
book, a long-range acoustic device capable of gener-
ating levels at 1 m of over 152 dB. The LRAD - RX
uses directivity and focused acoustic output to
clearly transmit critical instructions and warnings
well beyond 3000 m. Through the use of powerful
voice commands and deterrent tones, large safety
zones can be created while determining the intent
and influencing the behavior of an intruder. Pitts-
burgh, Pa. police used such a device to disperse
protesters gathered outside the G-20 summit held
there, the first time such a device had been used on
civilians in the United States.
A spokesman for the authorities said:
We believe this is highly preferable
to the real instances that happen almost
every day around the world where
officials use guns and other lethal and
nonlethal weapons to disperse
protesters.
This device has been successfully deployed
against pirates in the Indian Ocean off Somalia by at
least one shipping company.
There have been cases reported of entire groups
of employees suffering undefined headaches and
illnesses until the cause was traced to failure to
correctly isolate heavy-duty air conditioning appa-
ratus on the top of the building. Any specification
for a sound system must include maximum allow-
able environmental sound levels, whether from the
HVAC system, or from external sources such as
nearby railway, airport, or freeway systems.
Carnegie Hall in New York City was built
directly above the subway providing a true isolation
challenge. In an art museum in Southern California I
found the HVAC system mounted in the main
exhibit area with no isolation whatsoever, not even a
wall.
Sound engineers, utilizing today’s very powerful
audio amplifiers, and the highly directional loud-
speaker arrays, that digital signal processors allow
to be constructed, need to make their clients aware
of potential hazardous use by unwary operators.
Particular care should be exercised in the construc-
tion of powerful systems to avoid the generation of
high-level impulses from switching circuits and the
like.
9.7 An Older View of Q
Q, directivity factor, is a valued parameter in the
sound engineer’s toolbox.
Recently while watching the television news, I
found that I was having difficulty hearing the
“talking head.” My hearing aid was in the bedroom
so I just cupped my earlobe. The TV has a calibrated
gain control and it was set where I use it with my
hearing aid. Much to my surprise I was hearing
better with a cupped ear than with a hearing aid
on—though it does a good job also. Thinking about

   
Loudspeaker Directivity and Coverage
167
what was actually going on, I realized that, yes,
cupping my pinna did give me the required gain
(about 6 dB) but also removing a good deal of early
reflections, allowing me to hear the direct sound
more clearly. In fact, the effect of cupping my ears
was much like what you hear when comparing one
loudspeaker with two that are misaligned. Our living
room has large floor to ceiling glass windows as
well as a cathedral ceiling and these surfaces were
providing sufficiently high level delayed signals to
affect speech intelligibility.
As Deward Timothy has demonstrated using
PET (Polar Energy Time) measurements, speech
intelligibility can be directly influenced not only by
gain but also by awkwardly spaced early reflections.
We attempt in intelligibility measurements to
account for gain, audience coverage, reverberation,
when present, and noise.
Years ago while measuring a speech intelligi-
bility problem on the USS Belleau Wood, we found
in a narrow walkway above the internal harbor a
series of overhead loudspeakers, too-widely spaced,
that almost completely destroyed speech intelligi-
bility. A proper solution would have been essentially
a line array overhead because of all the steel
surrounding surfaces. These were easily the most
destructive early reflections we had ever encoun-
tered. Experience has taught us awareness of this
problem, but there are no easy design criteria for
solution at the drawing board stage. I have come to
appreciate the effectiveness of the large ear horns
used two centuries ago.
9.8 Summary
A general caveat we can give is to use no software
in audio or acoustic design work that you have not
personally reviewed step-by-step and found to be
based on correct basic principles. Computers can
generate, at stunning speed and with overwhelming
quantity, totally incorrect data when operating from
inadequately researched software. Many of the flat
earth approaches allow no intuitive safeguards as the
mapping employed resembles nothing encountered
in real life.
Bibliography
R. J. Bobber. Underwater Electroacoustic Measurements. Washington, D.C.: Naval Research Laboratory,
1970.
S. Bridges. “High Q Measurements Confirmed in the Field,” Syn-Aud-Con Tech Topic, Vol. 3, No. 5 (1975).
P. M. Kending and R. E. Mueser. “Simplified Method for Determining Transducer Directivity Index,”
J. Acoust. Soc. Am., Vol. 19, No. 4 (July 1947), pp. 691-694.
Wolff and L. Malter. “Directional Radiation of Sound,” J. Acoust. Soc. Am. (Oct. 1930), pp. 201-241.


Chapter 10
The Acoustic Environment
by Don Davis
169
10.1 The Acoustic Environment  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 171
10.2 Dispersion and Diffusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 171
10.3 Inverse Square Law  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 172
10.4 Atmospheric Absorption  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 172
10.5 Velocity of Sound . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 173
10.6 Isothermal vs. Adiabatic  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 173
10.7 Temperature-Dependent Velocity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 174
10.8 The Effect of Altitude on the Velocity of Sound in Air . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 175
10.9 Typical Wavelengths  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 175
10.10 Doppler Effect  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 175
10.11 Reflection and Refraction  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 176
10.12 Effect of a Space Heater on Flutter Echo . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 177
10.13 Absorption  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 177
10.14 Definitions in Acoustics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 178
10.15 Classifying Sound Fields . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 178
10.16 The Acoustic Environment Indoors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 181
The Mean Free Path (MFP) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 184
The Build-Up of the Reverberant Sound Field  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 184
10.17 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 186
Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 186


The Acoustic Environment
171
10.1 The Acoustic Environment
We are concerned about the effect the acoustic envi-
ronment has on sound. We need to know the effect
of a particular acoustic environment on the unaided
talker or musician, on the sound system, if installed,
and on unwanted sounds (noise) that may be present
in the same environment.
An outdoor environment can often be a “free
field.” “A sound field is said to be a free field if it is
uniform, free from boundaries, and is undisturbed
by other sources of sound. In practice it is a field
where the effects of the boundaries are negligible
over the region of interest.” (From the GenRad
instruction manual for their precision microphones.)
“Free from boundaries” is the catch phrase here.
Anyone who has designed a sound system into a
football stadium, a replica of a Greek theater, or a
major motor racing course knows first-hand the
primary influence of a boundary.
We must also consider:
1.
Inverse-square-law level change.
2.
Excess attenuation by frequency due to
humidity and related factors.
Other factors that can materially affect sound
outdoors include:
3.
Reflection by and diffraction around solid
objects.
4.
Refraction and shadow formation by wind and
temperature and wind variations.
5.
Reflection and absorption by the ground surface
itself.
Research in recent years has advanced knowl-
edge of atmospheric absorption significantly from
the original base laid by Kneser, Knudsen, followed
later by Harris, and more recently by the work of
Sutherland, Piercy, Bass, and Evans, Fig. 10-1. This
prediction graph is felt to be reliable within +5% for
the temperature indicated (20°C) and 10% over a
range of 0°C to 40°C.
The June 1977 Journal of the Acoustical Society
of America had an exceptional tutorial paper entitled
“Review of Noise Propagation in the Atmosphere”
pages 1403-1418, and included a 96 reference
bibliography.
10.2 Dispersion and Diffusion
Dispersion is the process of sorting the rays of light,
sound, etc., into their respective wavelengths. Leo
Beranek stated:
Diffusion concerns the spatial orien-
tation of the reverberant sound. Diffu-
sion is considered best when the
reverberant sound seems to arrive at the
listener’s ears from all directions in
about equal amounts.
The basic audio parameters are: frequency, wave-
length, amplitude, phase (both absolute and rela-
tive), polarity, velocity, and time.
Frequency. is related to the sense of pitch in music.
Figure 10-1. Predicted atmospheric absorption in
dB/100 m for a pressure of 1 atm, temperature of 20°C,
and various values of relative humidity.
10−6
10−5
10−4
10−3
10−2
10−1
100
101
102
Absorption coefficient–dB/m
101
102
103
105
104
10-6
Frequency–Hz
0%
Classical
100%
10%

172
Chapter 10
Knowledge of wavelength. is necessary to under-
stand reflection.
Amplitude. is related to loudness.
Absolute phase. is related to time whereas relative
phase can be vital to the shape of the wavefront.
Polarity. is of little consequence in a single channel
or a truly stereophonic system, but key in a multi-
channel system.
The velocity of sound. varies with temperature and
temperature gradients can change the direction of a
wavefront.
Time. is a river that flows endlessly on, but in audio
systems latency (signal delay) can cause problems.
10.3 Inverse Square Law
The geometrical spreading of sound from a coherent
source (inverse square law rate of level change)
which is a change in level of 6 dB for each doubling
of distance for a spherical expansion from a point
source is well known to most sound technicians.
(10-1)
where,
Dr is the reference distance,
Dm is the measured distance.
Not as well recognized is the change in level of
3dB per doubling of distance for cylindrical expan-
sion from an infinite line source. The ambient noise
from a motor race track with the field of cars evenly
spread during the early stages of a race can come
very close to being effectively an infinite line source.
(10-2)
Finally, there is the case of the parallel “loss
free” propagation from an infinite area source—the
crowd noise viewed from the center of the audience.
Descriptions of the spreading out of sound for
coherent sources remains true for incoherent sources
as well. The size of the near field may be more
restricted and the propagation less directional but
the general rate of level change remains the same.
Note that this “spreading out” of sound does not
constitute absorption or other loss but merely the
reduction of power per unit of area as the distance is
increased. Unfortunately, other processes also are
going on.
10.4 Atmospheric Absorption
These other processes represent actual dissipation of
sound energy. Energy is lost due to the combined
action of the viscosity and heat conduction of the air
and relaxation of behavior in the rotational energy
states of the molecules of the air. These losses are
independent of the humidity of the air. Additional
losses are due to a relaxation of behavior in the
vibrational states of the oxygen molecules in the air,
because this behavior is strongly dependent on the
presence of water molecules in the air (absolute
humidity). Both of these energy loss effects cause
increased attenuation with increased frequency,
Fig. 10-2.
This frequency-discriminative attenuation is
referred to as excess attenuation and must be added
to the level change due to divergence of the sound
wave. Total level change is the sum of inverse-
square-law level change and excess attenuation.
LP at measurement point
Ref distanceLP
20
Dr
Dm
-------
log
+
=
LP at measurement point
Ref distanceLP
10
Dr
Dm
-------
log
+
=
Figure 10-2. Absorption of sound for different frequen-
cies and values of relative humidity.
100K  50K      20K  10K    5K      2K     1K    500    200 100
0.001
0.002
0.005
0.001
0.002
0.05
0.1
0.2
0.5
1.0
0.02
0.01
0.005
Frequency–Hz
Attenuation constant–dB/m
Temperature–20° C
20% RH
40% RH
60% RH
80% RH

The Acoustic Environment
173
Fig. 10-3 shows the excess attenuation difference
between 1000  Hz and 10,000  Hz at various
distances.
10.5 Velocity of Sound
For a given frequency, the relation of the wave-
length to the velocity of sound in the medium is
(10-3)
where,
λ is the wavelength in ft or m,
c is the velocity of sound in ft/s or m/s,
f is the frequency in Hz.
In dealing with many acoustic interactions, the
wavelength involved is significant and the ability to
calculate it is important. Therefore, we need to be
able to both calculate and measure the velocity of
sound quickly and accurately.
The velocity of sound varies with temperature to
a degree sufficient to require our alertness to it. A
knowledge of the exact velocity of sound when
using signal delayed signal analysis allows very
precise distance measurements to be made by
observing the frequency interval between comb
filters from two sources and then converting from
frequency to time and finally to distance.
The velocity of sound under conditions likely to
be encountered in connection with architectural
acoustic considerations is dependent upon three
fundamental factors. These are:
1.
ϒ is the ratio of specific heats and is 1.402 for
diatomic molecules (air molecules).
2.
PS is the equilibrium gas pressure in Newtons
per square meter (1.013 × 105 N/m2).
3.
ρ is the density of air in kilograms per cubic
meter (kg/m3).
(10-4)
where,
c is the velocity of sound in m/s.
The density of air varies with temperature and an
examination of the basic equations reveals that,
indeed, temperature variations are the predominant
influence on the velocity of sound in air.
The equation for calculating the density of air is
(10-5)
where,
Density of air is in kg/m3,
H is the barometric pressure in cm of mercury, Hg,
°C is the temperature in degrees Celsius,
9⁄5 (°C) + 32 = °F,
5⁄9 (°F) – 32 = °C,
Hg in inches times 2.54 equals Hg in centimeters.
10.6 Isothermal vs. Adiabatic
Newton, relying on the simple pressure density rela-
tion, came up with the speed of sound as 968 ft/s,
which is too low by about 16%.
In the intervening century and a half, Lambert
identified no less than nineteen different tempera-
ture “scales” that had been proposed by authors of
different schemes of thermometry. Among these
were the tools that eventually would let the measure-
ment of the change in temperature, caused by rapid
compression of the air, to be properly evaluated.
According to Hunt in his truly exceptional book,
The Origin of Acoustics,
The laborious trail from Amontons to
Gay–Lussac and Dalton, stretch from
the beginning to the end of the eigh-
teenth century, and the prize at its end
was merely the fact that the constant in
the Towneley–Boyle law is proportional
to temperature….
As for the raw facts about adiabatic
heating and cooling, these were
exploited, observed, mis-explained,
Figure 10-3. Excess attenuation for different frequen-
cies and distances from the source.
Distance from source–feet
10    20      50   100  200    500   1K    2K     5K 10K
140
120
100
80
60
40
20
0
Excess attenuation–dB
10,000 Hz
3000 Hz
1000 Hz
9.14 dB
45.7 dB
68°F and 20% RH
2000 Hz
λ
c
f--
=
c
λf
=
f
c
λ---
=
c
γPS
ρ
--------
=
Density of air
1.293H
1
0.00367 °C
(
)
+
[
] 76
(
)
--------------------------------------------------------
=

174
Chapter 10
inadequately measured, and generally
misunderstood, in about that order
before enough understanding came to
allow them to be used in a final resolu-
tion of the sound–speed dilemma.
John Dalton finally brought this episode to a
close with this definitive review of 1802 in which
the adiabatic constant for air was defined as 1.4. The
rapid temperature changes that occur with increased
pressure and decreased pressure in sound, adiabatic,
as differentiated from isothermal, where constant
temperature is maintained, allowed the calculation
of the velocity of sound to match the actual
measurements.
Frederick Vinton Hunt’s remarkable book is a
treasure trove, not only historically, but more impor-
tantly for its insight into the multiple side trips and
misinterpretations before truly intelligent
researchers finally got the message the data at hand
contained. Hunt’s narrative reveals how publication
of experimental data finally congeals in the minds of
many, and at the same time, leads to useful progress.
The serendipity of research, as well as its science,
suggests care in accepting first explanations. As is
often the case, reliance on the five physical senses,
alone, leads astray.
I recently came across an article “Physical Limits
of Computing” by Michael P. Frank, currently at the
University of Florida, CISE Department, where he
describes the first fully adiabatic central processing
unit named, “Pendulum.” Mr. Frank was part of a
team of graduate students at MIT who designed,
outsourced fabrication, and tested the unit.
Pendulum was a 12 bit fully adiabatic CPU designed
to achieve much lower power requirements than
similar devices.
Mr. Frank’s paper is outstanding in its outlining
of the limits that computing will eventually have to
deal with.
Example
If we were to measure a temperature of 72°F and a
barometric pressure of 29.92 in, we would first
calculate the density of the air according to the data
gathered:
Having made the metric conversions and
obtained the density figure, we can then use the
basic equation for velocity
(10-6)
Since we started with the dimensions commonly
used here in the United States, we then convert back
to them by
Typical velocities in other media are shown in
Table 10-1.
10.7 Temperature-Dependent Velocity
The velocity of sound is temperature dependent. The
approximate formula for calculating velocity is:
(10-7)
where,
c is the velocity in feet per second (ft/s),
°F is the temperature in degrees Fahrenheit. 
5
9--- 72
32
–
(
)
22.22°C
=
29.92 in Hg
2.54
×
76 cm Hg
=
Table 10-1. Typical Sound Velocities in Various Media (at 
Approximately 15°C)
Media
Velocity
m/s
 ft/s
Air
341
1119
Water (Pure)
1440
4724
Water (Sea)
1500
4921
Oxygen
317
1040
Ice
3200
10,499
Marble
3800
12,467
Glass (Soft)
5000
16,404
Glass (Hard)
6000
19,685
Cast Iron
3400
11,155
Steel
5050
16,568
Lead
1200
3937
Copper
3500
11,483
Beryllium
8400
27,559
Aluminum
5200
17,060
Density
1.293 76
(
)
1
0.00367 22.22
(
)
+
[
] 76
(
)
---------------------------------------------------------------
=
1.1955  kg/m3
=
c
1.402 1.013
105
×
(
)
1.1955
----------------------------------------------
=
344.67  m/s
=
344.67 m
100 cm
1.0 in
1 ft
1 s
1 m
2.54 cm
12 in
×
×
×
1130.81 ft
s
=
c
49 459.4
°F
+
=

The Acoustic Environment
175
For Celsius temperatures:
(10-8)
where,
c is the velocity in meters per second (m/s),
°C is the temperature in degrees Celsius.
Therefore, at a normal room temperature of
72.5°F, we can calculate:
10.8 The Effect of Altitude on the Velocity of 
Sound in Air
The theoretical expression for the speed of sound, c,
in an ideal gas (air, for example) is:
(10-9)
where,
c is the velocity in m/s,
P is the ambient pressure,
ρ is the gas density,
γ is the ratio of the specific heat of the gas at a
constant pressure to its heat at constant volume.
Consider the equation
(10-10)
where,
P is the ambient pressure,
V is the volume,
R is the gas constant,
T is the absolute temperature.
Considering the definition of density (ρ), our first
equation can be rewritten as:
(10-11)
where,
M is the molecular weight of the gas.
It can be seen that the velocity is dependent only
on the type of gas and the temperature and is inde-
pendent of changes in pressure. This is true because
both P and ρ decrease with increasing altitude and
the net effect is that atmospheric pressure has only a
very slight effect upon sound velocity. Therefore,
the speed of sound at the top of a mountain would
be the same as at the bottom of the mountain if the
temperature is the same at both locations.
10.9 Typical Wavelengths
Some typical wavelengths for midfrequency octave
centers are:
Now suppose the temperature increases 20°F to
92.5°F.
The table of frequencies and wavelengths is
shown in Table 10-3.
Suppose we had “tuned” to the peak of a 1000Hz
standing wave in a room first at 72.5°F and then later
at 92.5°F. The apparent frequency shift would be:
where,
1151 is the velocity (ft/s) at the temperature of
measurement,
1.13 is the wavelength at the original temperature.
10.10 Doppler Effect
We have all experienced the Doppler effect—
hearing the pitch change from a higher frequency to
a lower frequency as a train whistle or a car horn
comes toward a stationary listener and then recedes
c
20.6 273
°C
+
=
49 459.4
72.5
+
1130  ft/s
=
c
γP
ρ
------
=
PV
RT
=
c
γRT
M
----------
=
Table 10-2. Typical Wavelengths for Mid- frequency 
Octave Centers
Frequency–Hz
Wavelength–ft
250
4.52
500
2.26
1000
1.13
2000
0.57
4000
0.28
8000
0.14
16,000
0.07
Table 10-3. Frequencies and Wavelengths
Frequency (Hz)
Wavelength (ft)
250
4.60
500
2.30
1000
1.15
2000
0.58
4000
0.29
8000
0.14
16,000
0.07
49 459.4
92.5
+
1151  ft/s
=
1151
1.13
------------
1000
–
18.58  Hz
=

176
Chapter 10
into the distance. The frequency heard by the
listener due to the velocity of the source, the listener,
or some combination of both, is found by:
(10-12)
where,
FL is the frequency heard by the listener (observer in
Hz),
FS is the frequency of the sound source in Hz,
c is the velocity of sound in ft/s,
VL is the velocity of the listener in ft/s,
VS is the velocity of the sound source in ft/s.
Use minus (–) if VS in the denominator is coming
toward the listener. If the listener, VL, in the numer-
ator is moving away from the source, use minus (–),
and for the listener moving toward the source, use
plus (+).
Example
Assume c = 1130  ft/s, VL = 0, VS = 60  mi/h
(approaching listener), and fS = 1000 Hz
As the sound source passes the listener and
recedes, the pitch swings from 1084 Hz to
This rapid sweep of 156 Hz is called the Doppler
effect. A very large excursion low frequency driver
can exhibit Doppler distortion of its signal. Moving
vanes in reverberation chambers can produce
Doppler effects in the reflected signals that can
cause unexpected difficulties in modern spectrum
analyzers.
10.11 Reflection and Refraction
Sound can be reflected by hitting an object larger
than one-quarter wavelength of the sound. When the
object is one-quarter wavelength or slightly smaller,
it also causes diffraction of the sound (bending
around the object). Refraction occurs when the
sound passes from one medium to another (from air
to glass to air, for example, or when it passes
through layers of air having different temperatures).
The velocity of sound increases with increasing
temperature. Therefore, sound emitted from a source
located on the frozen surface of a large lake on a
sunny day will encounter warmer temperatures as
the wave diverges upward, causing the upper part of
the wave to travel faster than the part of the wave
near the surface. This causes a lens-like action to
occur which bends the sound back down toward the
surface of the lake, Fig. 10-4.
Sound will travel great distances over frozen
surfaces on a quiet day. Wind blowing against a
sound source causes temperature gradients near the
ground surface that result in the sound being
refracted upward. Wind blowing in the same direc-
tion as the sound produces temperature gradients
along the ground surface that tend to refract the
sound downward. We hear it said, “The wind blew
the sound away.” That is not so; it refracted away.
Even a 50 mph wind (and that’s a strong wind)
cannot blow away something traveling 1130 ft/s:
770.45 mi/h is the velocity of sound at sea level at
72.5°F.
Wind velocities that vary with elevation can also
cause “bending” of the sound velocity plus or minus
the wind velocity at each elevation.
Reflections from large boundaries, when delayed
in time relative to the direct sound, can be highly
destructive of speech intelligibility. It is important to
remember, however, that a reflection within a
nondestructive time interval can be extremely
useful. Reflections that are at or near (within 10 dB)
equal amplitude and that are delayed more than
50ms require careful attention on the part of a sound
system designer. Fig. 10-5 shows how to calculate
FL
c  VL
±
c  VS 
±
-----------------
⎝
⎠
⎛
⎞ FS
=
60 mi
1 h
5280 ft
1 h
3600 s
1 mi
×
×
88 ft
s
=
F
1130
0
–
1130
88
–
------------------------
⎝
⎠
⎛
⎞1000
=
1084 Hz
=
F
1130
0
–
1130
88
+
------------------------
⎝
⎠
⎛
⎞1000
=
928 Hz
=
Figure 10-4. Effect of temperature differences between
the ground and the air on the propagation of sound.
Cooler
Cooler
Warmer
Warmer
1130  ft
1 s
-----------------
3600  s
1  h
---------------
×
1 m
5280  ft
-----------------
×
770.45 mi/h
=

The Acoustic Environment
177
probable levels from a reflection. Fig. 10-6 shows
other influences. Calculation of the time interval is
found by:
(10-13)
where,
c is the velocity of sound in ft/s or m/s,
DR is the distance in ft or m traveled by the
reflection,
DD is the distance the direct sound traveled in ft
or m.
A large motor speedway used to make very
effective use of ground reflections on the coverage
of the grandstands behind the pit area. The very high
temperature gradients encountered warp the sound
upward during the hot part of the day and in the cool
of the morning, the ground reflection helps with the
coverage of the near seating area. The directional
devices are aimed straight ahead along the ground
rather than up at an angle and when the temperature
gradient “bends” the sound upward, it’s still
covering the audience area effectively, Fig. 10-4.
One caution about using ground reflections in
northern climes. A heavy snow fall can provide
unbelievable attenuation as the authors can attest
after trying to demonstrate, years ago, a high level
sound system the day after a blizzard in Minnesota.
10.12 Effect of a Space Heater on Flutter 
Echo
Velocity of sound increases with an increase in
temperature; therefore, the effect of an increase in
temperature with an increase in height is a down-
ward bending of the sound path. This illustrates why
feedback modes change as air conditioners, heating,
or crowds dramatically change the temperature of a
room, Fig. 10-7.
10.13 Absorption
Absorption is the inverse of reflection. When sound
strikes a large surface, part of it is reflected and part
of it is absorbed. For a given material, the absorp-
tion coefficient, (a) is:
Figure 10-5. Calculating relative levels of reflections.
Ds
Dm
2Ds + Dm
S1*
Loudspeaker
Image
source
Microphone
Case  No. 1
Influence of surface S1 on measured signal at
microphone equals: 
Reflected signals relative level = 20 log [2Ds + Dm
Dm ]
Dm
Dms
S1*
Loudspeaker
Microphone
Influence of surface S1 on measured signal at
microphone equals: 
Case  No. 2
Reflected signals relative level = 20 log [  Dm + 2Dms
Dm
]
Where S1 is absorptive then the equation becomes:
 20 log [
Dm ] + 10 log (1 − a)
Reflected signals relative level =
In the case of substantial transmission loss then
these losses can be added as required.
T.L. = 20 log fw − 47 dB
*Assuming S1 is nonabsorptive, nondiffuse,
and nonfocusing.
Image
source
  Dm + 2Dms
1000
c
------------ DR
DD
–
(
)
Time interval  (in ms)
=
Figure 10-6. Absorption, reflection, and transmission of
boundary surface areas.
Change in media
hence change
in velocity
Reflected
sound
Transmitted
sound
Reflected
sound (1 − a)
Flanking path
Absorption (a)
Sound
source
Mass Law
T.L. = 20 log [fw] − 47 dB
f = frequency in Hz
w = weight of barrier in kg/m2
a = 1 − 10(−dB/10)
dB = 10 log (1 − a)

178
Chapter 10
(10-14)
where,
EA is the absorbed acoustic energy,
EI is the total incident acoustic energy (i.e., the total
sound),
(1 – a) is the reflected sound.
This theoretically makes the absorption coeffi-
cient some value between 0 and 1. For a = 0, no
sound is absorbed; it is all reflected. If a material has
an a of 0.25, it will absorb 25% of all sound energy
having the same frequency as the absorption coeffi-
cient rating, and it will reflect 75% of the sound
energy having that frequency.
Example
An anechoic room absorbs 99% of the energy
received from the sound source. What percentage of
the LP from the source is reflected? Assume 10W of
total energy output from the source. Then the
chamber absorbs 9.9 W of it.
Therefore, the LP drops by 20 dB also
In other words, 10% of the LP returns as a reflec-
tion. If the sound source had directed an LP of 100dB
signal at the wall of the chamber, a signal of 80dB
would be reflected back. Remembering how dB are
combined, we can see that this reflection will not
change the 100 dB reading of the direct sound by a
discernible amount on any normal sound level meter.
The desirability of a reflective surface can be
seen when it is realized that the direct sound and the
reflected sound from a single surface can combine
to be as much as 3 dB higher than the direct sound
alone. If the loudspeakers are directed to reflect off
the ground during the cool early morning hours;
then when the refraction effect of the sun on the
hard surfaces causes the sound to bend upward
during the hot part of the day, the sound bends up
into the grandstand area. Most of the time, the
reflected sound is assisting the direct sound, thereby
saving audio power.
10.14 Definitions in Acoustics
Sound Energy Density—is the sound per unit
volume measured in joules per cubic meter.
Sound Energy Flux—is the average rate of flow of
sound energy through any specified area. The unit is
joules per second (joules per second are called
watts).
The Sound Intensity—(or sound energy flux
density) in a specified direction at a point is the
sound energy transmitted per second in the specified
direction through unit area normal to this direction
at the point. The unit is watts per square meter.
Sound Pressure—is exerted by sound waves on any
surface area. It is measured in Newtons per square
meter (now called pascals). The sound pressure is
proportional to the square root of the sound density.
The Sound Pressure Level—(in decibels of a
sound)—20 times the logarithm to the base 10 of the
ratio of the pressure of this sound to the reference
pressure. Unless otherwise specified, the reference
pressure is understood to be 0.00002  N/m2
(20micropascals or 20 µPa).
The Velocity Level—(in decibels of a sound) 20
times the logarithm to the base 10 of the ratio of the
particle velocity of the sound to the reference
particle velocity. Unless otherwise specified, the
reference particle velocity is understood to be
50 × 10–9 meters per second (m/s).
The Intensity Level—(in decibels of a sound) 10
times the logarithm to the base 10 of the ratio of the
intensity of this sound to the reference intensity.
Unless otherwise specified, the reference intensity
shall be 10–12 watts per square meter (W/m2).
10.15 Classifying Sound Fields
Free Fields. A sound field is said to be a free field if
it is uniform, free of boundaries, and is undisturbed
Figure 10-7. Effect of thermal gradients in a room.
Temperature
Reflective path
heater on
Space
heater
+
−
Reflective path
heater off
a
EA
EI
------
=
10
10 W
0.1 W
---------------
log
20 dB
=
100
10 dB
–
20
⁄
×
10% reflected LP
=

The Acoustic Environment
179
by other sources of sound. In practice, it is a field in
which the effects of the boundaries are negligible
over the region of interest. The flow of sound energy
is in one direction only. Anechoic chambers and
well-above-the-ground outdoors are free fields. The
direct sound level from a sound source in a free field
is labeled LD.
Diffuse (Reverberant) Fields. A diffuse or rever-
berant sound field is one in which the time average
of the mean square sound pressure is everywhere the
same and the flow of energy in all directions is
equally probable. This requires an enclosed space
with essentially no acoustic absorption. The rever-
berant sound level is labeled LR.
Semireverberant Fields. A semireverberant field is
one in which sound energy is both reflected and
absorbed. The flow of energy is in more than one
direction. Much of the energy is truly from a
diffused field; however, there are components of the
field that have a definable direction of propagation
from the noise source. The semireverberant field is
the one encountered in the majority of architectural
acoustic environments. The early reflections, i.e.,
under 50 ms after LD, are labeled LRE.
Pressure Fields. A pressure field is one in which
the instantaneous pressure is everywhere uniform.
There is no direction of propagation. The pressure
field exists primarily in cavities, commonly called
couplers, where the maximum dimension of the
cavity is less than 1⁄6 of the wavelength of the sound.
Because of the ease of repeatability, this type of
measurement is used by the National Bureau of
Standards, NBS, when they calibrate microphones.
At low frequencies the pressure field can be large,
i.e., big enough for a listener to sit in.
Ambient Noise Field. The ambient noise field is
comprised of those sound sources not contributing to
the desired LD, (i.e., active sources). The ambient
noise level is labeled LN.
Outdoor Acoustics. If, for example, the ambient
noise level measured 70dBA (a not unreasonable
reading outdoors) and the most SPL you could
generate at 4 ft was 110dB LP how far could you
reach before your signal was submerged in noise?
The problem actually is more complicated than
this outdoors, but this serves as an illustration of
how to begin.
We have now touched on the most important
basics of the acoustics environment outdoors.
Before going indoors, let us apply some of this
knowledge to a series of ancient outdoor problems.
A simple rule of thumb dictates that when a change
of +10 dB occurs, the higher level will be subjec-
tively judged as approximately twice as loud as the
level 10 dB below it. While the computation of loud-
ness is more complex than this, the rule is useful for
midrange sounds. Using such a rule, we could
examine a sound source radiating hemispherically
due to the presence of the surface of the earth.
Fig. 10-8 shows sound in an open field with no
wind. The sound at 100 ft is one-half as loud as that
at 30ft, although the amplitude of the vibration of
the air particles is roughly one-third. Similarly, the
sound at 30 ft is one-half as loud as the sound at
10ft. Because the sound is outdoors, atmospheric
effects, ambient noise, etc., cause difficulty for the
talker and listener. The ancients learned to place a
back wall behind the talker, and many Native Amer-
ican council sites were at the foot of a stone cliff so
the talker could address more of the tribe at one
time. Fig. 10-9 illustrates how a reflecting structure
can double the loudness as compared to the totally
open space. The weather and some noise still inter-
fere with listening.
Fig. 10-10 illustrates the absorptive effect of an
audience on the sound traveling to the farthest
Figure 10-8. Sound in an open field with no wind.
110LP
70LP
–
40 dB
=
20
x
4---
log
40 dB
=
x
4
1040 20
⁄
×
=
400 ft
=
4
8
8
4
Arbitrary loudness units
100           50            0           50          100
Noise
Noise
Noise
Distance–ft

180
Chapter 10
listener. Fig. 10-11 shows the right way and the
wrong way to arrange a sound source on a hill. In
Fig. 10-11A the loudness of the sound at the rear of
the audience is enhanced by sloping the seating
upward. In addition, the noise from sources on the
ground is reduced. Fig. 10-11B is a poor way to
listen outdoors. The sound at the rear is one-half as
loud as it is at the rear in Fig. 10-11A.
While the Bible doesn’t say which way Jesus
addressed the multitudes, we can deduce from the
acoustical clues present in the Bible text that the
multitude arranged themselves above him because:
1.
He addressed groups as large as 5000. This
required a very favorable position relative to the
audience and a very low ambient noise level.
2.
Upon departing from such sessions, He could
often step into a boat in the lake, suggesting He
was at the bottom of a hill or mountain.
We can further surmise that the reason Jesus led
these multitudes into the countryside was to avoid
the higher noise levels present even in small country
villages.
The Greeks built their amphitheaters to take
advantage of these acoustical facts:
1.
They provided a back reflector for the
performer.
2.
They increased the talker’s acoustic output by
building megaphones into the special face
masks they held in front of their faces to portray
various emotions.
3.
They sloped the audiences upward and around
the talker at an included angle of approximately
120° realizing, as many modern designers do
not seem to, that man does not talk out of the
back of his head.
4.
They defocused the reflective “slapback” by
changing the radius at the edges of the seating
area.
Figure 10-9. Sound from an orchestra enclosure in an
open field with no wind.
Figure 10-10. Sound from an orchestra enclosure with
an audience.
0                       50                     100
Distance–ft
16
8
Noise
Noise
Arbitrary loudness units
0                       50                     100
Distance–ft
16
4
Noise
Noise
Arbitrary loudness units
Figure 10-11. Sound sources and audiences on a hill.
16
8
Noise
Arbitrary loudness units
A. Correct way
B. Wrong way
16
4
Noise
Arbitrary loudness units
A. Correct way

The Acoustic Environment
181
Because there were no aircraft, cars, motorcy-
cles, air conditioners, etc., the ambient noise levels
were relatively low, and large audiences were able
to enjoy the performances. They had discovered
absorption and used jars partially filled with ashes
(as tuned Helmholtz resonators) to reduce the return
echo of the curved stepped seats back to the
performers. It remained only for some unnamed
innovative genius to provide walls and a roof to
have the first auditorium, “a place to hear,”
Fig. 10-12. No enhancement of sound is provided in
Fig. 10-12 because there is no reverberation in a
room whose walls are highly sound absorbent.
Sometimes acoustic progress was backward. For
example, the Romans, when adopting Christianity,
took over the ancient echo ridden pagan temples and
had to convert the spoken service into a chanted or
sung service pitched to the predominant room
modes of these large, hard structures. Today,
churches still often have serious acoustical short-
comings and require a very carefully designed sound
system in order to allow the normally spoken word
to be understood.
It is also of real interest to note that in large halls
and arenas the correct place for the loudspeaker
system is most often where the roof should have
gone if the building had been designed specifically
for hearing. A loudspeaker is therefore usually an
electroacoustic replacement for a natural reflecting
surface that has not been provided.
10.16 The Acoustic Environment Indoors
The moment we enclose the sound source, we
greatly complicate the transmission of its output.
We have considered one extreme when we put the
sound source in a well-elevated position and
observed the sound being totally absorbed by the
“space” around it. Now, let us go to the opposite
extreme and imagine an enclosed space that is
completely reflective. The sound source would put
out sound energy, and none of it would be absorbed.
If we continued to put energy into the enclosure
long enough, we could theoretically arrive at a pres-
sure that would be explosive. Human speech power
is quite small. It has been stated by Harvey Fletcher
in his book Speech and Hearing in Communication
that it would take “…500 people talking continu-
ously for one year to produce enough energy to heat
a cup of tea.” Measured at 39.37 in (3.28  ft), a
typical male talker generates 67.2  dB-SPL, or
34microwatts (µW) of power, and a typical female
talker generates 64.2 dB-SPL, or 18 µW. From a
shout at this distance (3.28 ft) to a whisper, the dB
LP ranges from 86 dB to 26 dB, or a dynamic range
of about 60dB. Not only does the produced sound
energy tend to remain in the enclosure (dying out
slowly), but it tends to travel about in the process.
Let us now examine the essential parameters of a
typical room to see what does happen. First, an
enclosed space has an internal volume (V ), usually
measured in cubic feet. Second, it has a total
boundary surface area (S ), measured in square feet
(ft2) (floor, ceiling, two side walls, and two end
walls). Next, each of the many individual surface
areas has an absorption coefficient. The average
absorption coefficient (a) for all the surfaces together
is found by
(10-15)
where,
s1,2,...n are the individual boundary surface areas in ft2,
 are the individual absorption coefficients
of the individual boundary surface areas,
S is the total boundary surface area in ft2.
The reflected energy is 1 – 
.
Table 10-4 gives typical absorption coefficients
for common materials. These coefficients are used
to calculate the absorption of boundary surfaces
(walls, floors, ceilings, etc).
Table 10-5 gives typical absorption units in
sabins rather than percentage figures. Sabins are
either in per-unit figures or in units per length.
Finally, the room will possess a reverberation
time, RT60. This is the time in seconds that it will
take a steady-state sound, once its input power is
terminated, to attenuate 60 dB. For the sake of
illustration, assume a room with the following
characteristics:
V = 500,000 ft3,
S = 42,500 ft2,
Figure 10-12. Means of eliminating noise and weather
while preserving outdoor conditions.
16
8
Arbitrary loudness units
Sound absorbent
ceiling and walls
a
s1a1
s2a2
…
snan
+
+
+
S
--------------------------------------------------------
=
a1, 2,… n
,
a

182
Chapter 10
Table 10-4. Sound Absorption Coefficients of General Building Materials and Furnishings
Materials
Coefficients
125 Hz
250 Hz 500 Hz
1 kHz
2 kHz
4 kHz
Acoustical plaster (“Zonolite”)
½ in. thick trowel application
0.31
0.32
0.52
0.81
0.88
0.84
1 in. thick trowel application
0.25
0.45
0.78
0.92
0.89
0.87
Acoustile, surface glazed and perforated structural clay tile, perforate 
surface backed with 4 in. glass fiber blanket of 1 lb/ft2 density
0.26
0.57
0.63
0.96
0.44
0.56
Air (Sabins per 1000 ft3)
2.3
7.2
Brick, unglazed
0.03
0.03
0.03
0.04
0.05
0.07
Brick, unglazed, painted
0.01
0.01
0.02
0.02
0.02
0.03
Carpet, heavy
on concrete
0.02
0.06
0.14
0.37
0.60
0.65
on 40 oz hairfelt or foam rubber with impermeable latex backing
0.08
0.24
0.57
0.69
0.71
0.73
on 40 oz hairfelt or foam rubber
40 oz hairfelt or foam rubber
0.08
0.27
0.39
0.34
0.48
0.63
Concrete block
coarse
0.36
0.44
0.31
0.29
0.39
0.25
painted
0.10
0.05
0.06
0.07
0.09
0.08
Fabrics
light velour, 10 oz/yd2, hung straight in contact with wall
0.03
0.04
0.11
0.17
0.24
0.35
medium velour, 10 oz/yd2, draped to half area
0.07
0.31
0.49
0.75
0.70
0.60
heavy velour, 18 oz/s yd2 draped to half area
0.14
0.35
0.55
0.72
0.70
0.65
Fiberboards, ½ in. normal soft, mounted against solid backing
unpainted
0.05
0.10
0.15
0.25
0.30
0.3
some painted
0.05
0.10
0.10
0.10
0.10
0.15
Fiberboards, ½ in. normal soft, mounted over 1 in. air space
unpainted
0.30
0.15
0.10
some painted
0.30
0.15
0.10
Fiberglass insulation blankets
AF100, 1 in., mounting # 4
0.07
0.23
0.42
0.77
0.73
0.70
AF100, 2 in., mounting # 4
0.19
0.51
0.79
0.92
0.82
0.78
AF530, 1 in., mounting # 4
0.09
0.25
0.60
0.81
0.75
0.74
AF530, 2 in., mounting # 4
0.20
0.56
0.89
0.93
0.84
0.80
AF530, 4 in., mounting # 4
0.39
0.91
0.99
0.98
0.93
0.88
Flexboard, 3⁄16 in. unperforated cement asbestos board mounted over 
2 in. air space
0.18
0.11
0.09
0.07
0.03
0.03
Floors
concrete or terrazzo
0.01
0.01
0.015
0.02
0.02
0.02
linoleum, asphalt, rubber, or cork tile on concrete
0.02
0.03
0.03
0.03
0.03
0.02
wood
0.15
0.11
0.10
0.07
0.06
0.07
wood parquet in asphalt on concrete
0.04
0.04
0.07
0.06
0.06
0.07
Geoacoustic, 13½ in. × 13½ in., 2 in. thick cellular glass tile installed 
32 in. o.c. per unit
0.13
0.74
2.35
2.53
2.03
1.73
Glass
large panes of heavy plate glass
0.18
0.06
0.04
0.03
0.02
0.02
ordinary window glass
0.35
0.25
0.18
0.12
0.07
0.04
Gypsum board, ½ in. nailed to 2 in. × 4 in., 16 in. o.c.
0.29
0.10
0.05
0.04
0.07
0.09
Hardboard panel, 1⁄8 in., 1 lb/ft2 with bituminous roofing felt stuck to 
back, mounted over 2 in. air space
0.90
0.45
0.25
0.15
0.10
0.10
Marble or glazed tile
0.01
0.01
0.01
0.01
0.02
0.02
Masonite, ½ in., mounted over 1 in. air space
0.12
0.28
0.19
0.18
0.19
0.15

The Acoustic Environment
183
Mineral or glass wool blanket, 1 in., 5-15 lb/ft2 density mounted 
against solid backing
covered with open weave fabric
0.15
0.35
0.70
0.85
0.90
0.90
covered with 5% perforated hardboard
0.10
0.35
0.85
0.85
0.35
0.15
covered with 10% perforated or 20% slotted hardboard
0.15
0.30
0.75
0.85
0.75
0.40
Mineral or glass wool blanket, 2 in., 5-15 lb/ft2 density mounted over 
1 in. air space
covered with open weave fabric
0.35
0.70
0.90
0.90
0.95
0.90
covered with 10% perforated or 20% slotted hardboard
0.40
0.80
0.90
0.85
0.75
Openings
stage, depending on furnishings
0.25–0.75
deep balcony, upholstered seats
0.50–1.00
grills, ventilating
0.15–0.50
Plaster, gypsum or lime
smooth finish, on tile or brick
0.013
0.015
0.02
0.03
0.04
0.05
rough finish on lath
0.02
0.03
0.04
0.05
0.04
0.03
smooth finish on lath
0.02
0.02
0.03
0.04
0.04
0.03
Plywood panels
2 in., glued to 2½ in. thick plaster wall on metal lath
0.05
0.05
0.02
¼ in., mounted over 3 in. air space, with 1 in. glassfiber batts right 
behind the panel
0.60
0.30
0.10
0.09
0.09
0.09
3⁄8 in.
0.28
0.22
0.17
0.09
0.10
0.11
Rockwool blanket, 2 in. thick batt (Semi-Thik)
mounted against solid backing
0.34
0.52
0.94
0.83
0.81
0.69
mounted over 1 in. air space
0.36
0.62
0.99
0.92
0.92
0.86
mounted over 2 in. air space
0.31
0.70
0.99
0.98
0.92
0.84
Rockwool blanket, 2 in. thick batt (Semi-Thik),covered with 3⁄16 in. 
thick perforated cement-asbestos board (Transite), 11% open area 
mounted against solid backing
0.23
0.53
0.99
0.91
0.62
0.84
mounted over 1 in. air space 
0.39
0.77
0.99
0.83
0.58
0.50
mounted over 2 in. air space
0.39
0.67
0.99
0.92
0.58
0.48
Rockwall blanket, 4 in. thick batt (Full-Thik)
mounted against solid backing
0.28
0.59
0.88
0.88
0.88
0.72
mounted over 1 in. air space
0.41
0.81
0.99
0.99
0.92
0.83
mounted over 2 in. air space
0.52
0.89
0.99
0.98
0.94
0.86
Rockwool blanket, 4 in. thick batt (Full-Thik), covered with 3⁄16 in. 
thick perforated cement-asbestos board (Transite), 11% open area
mounted against solid backing
0.50
0.88
0.99
0.75
0.56
0.45
mounted over 1 in. air space
0.44
0.88
0.99
0.88
0.70
0.30
mounted over 2 in. air space
0.62
0.89
0.99
0.92
0.70
0.58
Roofing felt, bituminous, two layers, 0.8 lb/ft2, mounted over 10 in. 
air space
0.50
0.30
0.20
0.10
0.10
0.10
Spincoustic blanket
1 in., mounted against solid backing
0.13
0.38
0.79
0.92
0.83
0.76
2 in., mounted against solid backing
0.45
0.77
0.99
0.99
0.91
0.78
Spincoustic blanket, 2 in., covered with 3⁄16 in. perforated cement- 
asbestos board (Transite), 11% open area
0.25
0.80
0.99
0.93
0.72
0.58
Sprayed “Limpet” asbestos
3⁄4 in., 1 coat, unpainted on solid backing
0.08
0.19
0.70
0.89
0.95
0.85
1 in.,  1 coat, unpainted on solid backing
0.30
0.42
0.74
0.96
0.95
0.96
Table 10-4.  (cont.)  Sound Absorption Coefficients of General Building Materials and Furnishings
Materials
Coefficients
125 Hz
250 Hz 500 Hz
1 kHz
2 kHz
4 kHz

184
Chapter 10
 = 0.128.
therefore the RT60 is
(See Chapter 12 Large Room Acoustics, for a more
detailed development of this subject.)
10.16.1 The Mean Free Path (MFP)
The mean free path is the average distance between
reflections in a space. For our sample space:
If a sound is generated in the sample space, part
of it will travel directly to a listener and undergo
inverse-square-law level change on its way. Some
more of it will arrive after having traveled first to
some reflecting surface, and still more will finally
arrive having undergone several successive reflec-
tions (each 47 ft apart on the average). Each of these
signals will have had more attenuation at some
frequencies than at others due to divergence, absorp-
tion, reflection, refraction, diffraction, etc.
We can look at this situation in a different
manner. Each sound made will have traveled
4.5s × 1130 ft/s, or 5085 ft. Since the mean free path
is 47ft, then we can assume each sound underwent
approximately 108 reflections in this sample space
before becoming inaudible. The result is a lot
different than hearing the sound just once.
10.16.2 The Build-Up of the Reverberant Sound 
Field
Fig. 10-13 shows the paths of direct sound and
several reflected sound waves in a concert hall.
3⁄4 in., 1 coat, unpainted on metal lath
0.41
0.88
0.90
0.88
0.91
0.81
Transite, 3⁄16 in. perforated, cement-asbestos board, 11% open area
mounted against solid backing
0.01
0.02
0.02
0.05
0.03
0.08
mounted over 1 in. air space
0.02
0.05
0.06
0.16
0.19
0.12
mounted over 2 in. air space
0.02
0.03
0.12
0.27
0.06
0.09
mounted over 4 in. air space
0.02
0.05
0.17
0.17
0.11
0.17
paper-backed board, mounted over 4 in. air space
0.34
0.57
0.77
0.79
0.43
0.45
Water surface, as in a swimming pool
0.008
0.008
0.013
0.015
0.02
0.025
Wood paneling, 3⁄8 in. to ½ in. thick, mounted over 2 in. to 4 in. air 
space
0.30
0.25
0.20
0.17
0.15
0.10
Table 10-5. Absorption of Seats and Audience*
Materials
125 Hz
250 Hz
500 Hz
1 kHz
2 kHz
4 kHz
Audience, seated, depending on spacing and upholstery 
of seats
2.5–4.0
3.5–5.0
4.0–5.5
4.5–6.5
5.0–7.0
4.5–7.0
Seats
heavily upholstered with fabric
1.5–3.5
3.5–4.5
4.0–5.0
4.0–5.5
3.5–5.5
3.5–4.5
heavily upholstered with leather, plastic, etc.
2.5–3.5
3.0–4.5
3.0–4.0
2.0–4.0
1.5–4.0
1.0–3.0
lightly upholstered with leather, plastic, etc.
1.5–2.0
wood veneer, no upholstery
  0.15
  0.20
  0.25
  0.30
 0.50
0.50
Wood pews
no cushions, per 18 in. length
0.40
cushioned, per 18 in. length
1.8–2.3
*Values given are in sabins per person or unit of seating
Table 10-4.  (cont.)  Sound Absorption Coefficients of General Building Materials and Furnishings
Materials
Coefficients
125 Hz
250 Hz 500 Hz
1 kHz
2 kHz
4 kHz
a
RT60
0.049V
Sa
-----------------
=
4.5 s
=
MFP
4V
S---
=
4 500,000
42,500
-------------------
⎝
⎠
⎛
⎞
=
47 ft
=

The Acoustic Environment
185
Reflections also occur from balcony faces, rear wall,
niches, and any other reflecting surfaces. We can
obtain a chart such as that shown in Fig. 10-14 if we
plot the amplitude of a short-duration signal verti-
cally and the time interval horizontally. This
diagram shows that at listener’s ears, the sound that
travels directly from the performer arrives first, and
after a gap, reflections from the walls, ceiling, stage
enclosure, and other reflecting surfaces arrive in
rapid succession. The height of a bar suggests the
loudness of the sound. This kind of diagram is
called a reflection pattern. The initial-signal-delay
gap (ISDG) can be measured from it.
Fig. 10-14 illustrates the decay of the reverberant
field. Here the direct sound enters at the left of the
diagram. The initial-signal-delay gap is followed by
a succession of sound reflections. The reverberation
time of the room is defined as the length of time
required for the reverberant sound to decay 60 dB.
We will encounter the effects of delay versus
attenuation again when we approach the calculation
of articulation losses of consonants in speech.
Fig. 10-15 shows measurements from an
analyzer made in both large and small rooms.
Fig. 10-16 shows that the sound arriving at the
listener has at least three distinct divisions:
Figure 10-13. Sound paths in a concert hall.
Figure 10-14. Time relationship of direct and reflected
sounds.
Wall
reflection R5
Ceiling
reflection R2
Direct sound wave
Stage reflection R4
Wall
reflection R3
Wall
reflection R1
Direct
sound
Reflections
Initial-Time-Delay
Gap t1
R1
R2
R3
R4
R5
R6
Time–ms
Loudness
Figure 10-15. Vivid proof that there is a fundamental
difference between a small reverberant space and a
large reverberant hall.
A. Envelope Time Curve (ETC) of a small room
showing lack of a dense field of reflections
B. Small room without reverberant sound field but
with room modes
C. Small room without reverberant sound field
showing decay side of room modes
D. Large room with reverberant sound field

186
Chapter 10
1.
The direct sound level LD.
2.
The early reflections level LRE.
3.
The reverberant sound level LR.
The direct sound, by definition, undergoes no
reflections and follows inverse-square-law level
change. The reverberant sound tends to remain at a
constant level if the sound source continues to put
energy into the room at a reasonably regular rate.
This gives rise to a number of basic sound fields,
Fig. 10-17:
1.
The near field.
2.
The far free field.
3.
The far reverberant field.
The near field does not behave predictably in
terms of LP versus distance because the particle
velocity is not necessarily in the direction of travel
of the wave, and an appreciable tangential velocity
component may exist at any point. This is why
measurements are usually not made closer than
twice the largest dimension of the sound source. In
the far free field, inverse-square-law level change
prevails. In the far reverberant field, or diffuse field,
the sound-energy density is very nearly uniform.
Measuring low-frequency loudspeakers is an excep-
tion to the rule, and such measurements are often
made in the pressure response zone of the device.
10.17 Conclusion
The study of acoustics for sound system engineers
divides into outdoors and indoors with indoor acous-
tics again divided into large room acoustics and
small room acoustics. Classical Sabinian acoustics
are rapidly being refined where applicable,
discarded where misapplied, and reexamined where
the “fine structure of reverberation” is the mean-
ingful parameter. The digital computer has fueled
basic research into the mathematics of enclosed
spaces and modern analyzers have served to verify
or deny the validity of the theories put forward.
Bibliography
Acoustical Materials Assoc. The Use of Architectural Materials—Theory and Practice, 335 East 45 ST.,
NewYork, N.Y. 10017.
D. Davis and C. Davis. “What Reverberation Is and What It Is Not,” Syn-Aud-Con Tech Topic, Vol. 12, No.
13 (1985).
L. E. Kinsler and A. R. Frey. Fundamentals of Acoustics, 2nd ed. New York: Wiley, 1962.
V. O. Knudsen and C. M. Harris. Acoustical Designing in Architecture, New York: Wiley, 1950
H. Kuttruff. Room Acoustics. New York: Halstead Press, 1973.
B. R. Lindsay. Acoustics—Historical and Philosophical Development. Stroudsburg, Penn.: Dowden,
Hutchinson & Ross, 1973.
Figure 10-16. Comparison of direct, early, and rever-
berant sound fields in an auditorium (reflection angles
adjusted for purposes of illustration).
Source
1
2
2
2
2
3
3
3
3
3
3
1 Direct field
2 Early field
3 Reverberant field
Figure 10-17. Graphic representation of near field, free
field, and reverberant field.
log r
SPL
Reverberant
field
Free
field
Near
field
Far
field

The Acoustic Environment
187
R. MacKenzie, Ed. Auditorium Acoustics. London: Applied Science Publishers, 1975.
H. F. Olson. Music, Physics, and Engineering. New York: Dover, 1966.
A. D. Pierce. Acoustics: An Introduction to Its Physical Principles and Applications. New York:
McGraw-Hill, 1981.
J. R. Pierce. The Science of Musical Sound. New York: Scientific American Books, 1983.
T. D. Rossing. The Science of Sound. Reading, Mass.: Addison-Wesley, 1982.
P. E. Sabine. Acoustics and Architecture. New York: McGraw-Hill, 1932.
W. C. Sabine. Collected Papers on Acoustics. Cambridge, Mass.: Harvard Univ. Press, 1922.
L. J. Sivian, H. K. Dunn, and S. D. White. “Absolute Amplitudes and Spectra of Certain Musical Instruments
and Orchestras,” IRE Trans. on Audio (May-June 1959), pp. 47-75.
J. W. Strutt and B. Rayleigh. The Theory of Sound, Vols. I and 11, 2nd ed. New York: Dover, 1945.


Chapter 11
Audio and Acoustic Measurements
by Don Davis
189
11.1 Acoustic Analysis Sans Instrumentation  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 191
11.2 Initial Parameters . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 191
11.3 Acoustic Tests of Sound Systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 192
Acoustic Test Signals  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 192
Where to Place the Microphone  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 193
Measurement Analyzers  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 193
11.4 Examining AC Outlets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 193
First, Look and Listen  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 195
11.5 The ETC Plot  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 195
Impulse Response  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 195
The Heyser Spiral  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 196
The Magnitude and Phase Response . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 196
Three Parameter Measurements  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 198
The Nyquist Plot  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 200
The Polar Envelope Time (PET) Plots  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 201
History of Polar Time Measurements  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 201
11.6 Site Surveys and Noise Criteria Curves . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 203
Constant Percentage Bandwidth Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 203
11.7 An Improper Use of Real Time Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 203
11.8 Evaluation of Listener Response  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 205
11.9 Fractional Bandwidth Filter Analyzers  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 206
Series . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 207
Other Uses . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 207
Useful Tools . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 208
Using the Decade Exponents . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 208
Decibels . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 208
Label Frequencies  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 208
11.10 Measuring Electromagnetic Pollution  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 209
11.11 Conclusion  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 211
Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 211


   
Audio and Acoustic Measurements
191
In order to better understand what we hear we often
turn to measurements. As one authority in theory
once remarked, “When the number of variables
approached an order of magnitude, I turn in despair
to my measurement apparatus.”
The finest acoustical measurement apparatus
available cannot duplicate what a trained human
listener can achieve. If we examine an unknown
signal with all extant equipment we can’t tell if its
music, noise, speech, or gibberish, but a $2 loud-
speaker allows the trained human listener to tell
which, and if speech, what language.
Instrumentation is used to measure room parame-
ters before the design begins, to compute design
factors, to install the system, and, finally, to operate
and maintain the system. The greatest single
division between professional work and nonprofes-
sional work in the system business is the use and
understanding of basic audio and acoustic instru-
mentation.
The following quote is pertinent to the intent of
this chapter:
I often say that when you can
measure what you are speaking about,
and can express it in numbers, you know
something about it; but when you cannot
measure it, when you cannot express it
in numbers, your knowledge is of a
meager and unsatisfactory kind. It may
be the beginning of knowledge but you
have scarcely advanced to the stage of
science whatever the matter may be…
Lord Kelvin 1824-1907
11.1 Acoustic Analysis Sans Instrumentation
What defines a difficult acoustic space? Excessive
noise, too-long a reverberation time at the wrong
frequencies, faulty geometry resulting in focused
high-level reflections, inappropriate materials for the
function at hand such as marble in conference rooms,
inappropriate physical locations such as recording
studios too near railroads and airports.
These are but a few of the problems that owners,
architects, and enthusiastic volunteer consultants
can generate.
When an acoustic space physically exists the
number one priority is to visit it, especially when it
is in its normal use, and listen to it using the two
channel analyzer our maker provided us, namely
two ears, a rotating head, and a right and left hemi-
sphere in our brain. Cupping our earlobes provides
us with a highly directional antenna that can by
walking through anomalies in the room locate areas
for more detailed analysis by conventional equip-
ment. Carrying a small square of an absorptive
material, such as Sonex, allows focused reflections
to be blocked for acoustic evaluation.
Walking large arenas will often result in the
detection of localized, very high level noise sources
from air-conditioning ducts, inadequate isolation of
machinery spaces, flanking paths from other spaces,
all of which might not interfere with the main audi-
ence, but guarantees violent criticism from the
customers seated in those areas.
A careful walk-through a church auditorium
often reveals seats not only acoustically isolated, but
visually isolated, such as under balconies or in
various side areas. It is disturbing to see designers
that are totally unaware of the differences in church
liturgy, and proceed to design to their own church’s
standard, regardless of the inappropriateness to the
church at hand.
In one case when I entered the church the
organist told me that it was the deadest space he had
ever played in, followed a few minutes later by the
minister saying it was the most reverberant church
he had ever preached in. Walkabout analysis
revealed that the bass frequencies were being sucked
out of the room by the beautifully paneled ceiling
into the attic space, and that the hard oak pews were
making it difficult for speech when a full audience
wasn't present. After detailed conventional analysis,
stiffening the ceiling panels, and providing pew
cushions, resulted in a completely satisfactory space
for both the organist and the minister.
In one case when asked what they could do to
remedy an extremely difficult space a famous
consultant replied “pray for a high wind” as the
space was in tornado country. Fortunately in many
cases what disturbs highly trained listeners will,
with minor modifications, satisfy the ultimate users.
That is reason enough to proceed step-by-step in the
correction of existing difficult spaces to allow for
acceptability to be detected by the ultimate end-user.
Learn and understand what the space is used for,
listen to it in actual use, and whenever possible, in
the company of one of the ultimate users so that you
can see his or her response to the anomalies that you
detect, and then proceed with confidence to more
detailed measurements that your ultimate user will
then be more likely to understand and accept.
11.2 Initial Parameters
To make a measurement, choose the initial parame-
ters by one of the three following techniques:
1.
Experience with similar devices.

192
Chapter 11
2.
Mathematical analysis of the device and its most
likely performance.
3.
Cut and try experimentation.
Component designers often, justifiably, use
Step 3. System designers must not. System
designers need to specify proven, trusted compo-
nents. Systems are complex by their very nature of
combining components from many manufacturers.
To increase that complexity with untried compo-
nents is irresponsible.
11.3 Acoustic Tests of Sound Systems
Once all the electrical tests of the sound system are
completed and any electrical problems are corrected
meaningful acoustic tests can be performed to verify:
1.
Output levels and areas of coverage for indi-
vidual transducers comprising the acoustic
output of the system.
2.
The phase and polarity of the individual trans-
ducers.
3.
The signal synchronization between different
transducers sharing identical areas of coverage,
i.e., overlap zones.
4.
The absence of any undesired spurious energy
returns from any reflective surface.
5.
The measurement of the relationship of LD − LR
to confirm the %AlCONS at selected audience
locations.
6.
The equalization of LD as required.
7.
The loudspeaker impedances, see Fig. 11-1.
11.3.1 Acoustic Test Signals
Sound engineers have available many different test
sources:
Music and speech. Excellent if the listener is highly
trained—a rarity.
The steady-state sine wave. While perhaps our
most useful electrical signal, it is rarely useful in
acoustic tests.
Swept sine wave. This source is our single most
useful test signal.
Random noise. White, pink, USASI (or ANSI), and
other special forms of noise are useful for magni-
tude measurements, but they pose too great a
complexity in the acquisition of phase measure-
ments.
Impulse sources. These sources represent the worst
possible choice for acoustic measurements, espe-
cially when used in conjunction with FFT analysis.
They offer the least effective use possible of the test
signal’s energy.
The starting point for any serious acoustic
measurement system is the calibrated measurement
microphone. Fig. 11-2 allows the comparison of the
human ear with a quality electret microphone.
Notice that “intelligent design” has allowed the
microphone, in some parameters, to exceed the
human ear and in others to equal it for all practical
purposes. One of the authors worked for a company
that built a microphone capable of LP = 220 dB (for
measuring the pressure wave from a hydrogen bomb
explosion which produced a spike well above atmo-
spheric pressure).
Figure 11-1. Loudspeaker impedances.
Just a glance at the Nyquist 
display reveals which 
frequencies are predominately 
resistive, capacitance, or 
inductive impedance values.
Z = |Z| ejθ
where,
|Z| is the magnitude of the impedance
θ is the angle of the impedance
Reactance = |Z| sin θ
Resistance = |Z| cos θ
Angle = arctan (Reactance
Resistance)
25
20
15
10
5
0
Ohms
119 Hz
129 Hz
139 Hz
148 Hz
158 Hz
168 Hz
177 Hz
187 Hz
400 Hz
768 H z
1358 Hz
4165 Hz
cursor
90
180
270
0
45°
−45°
Frequency 
400 Hz
Phase angle  −9.88°
Impedance  8.41 Ω
Resistance  
8.29 Ω
Reactance  −1.44 Ω
0°
100           200    300  400 500  700    1k             2k      3k    4k  5k    7k    10k
Cursor = 8.4 Ω at 400.0 Hz (−9.9°)
Magnitude
4165 Hz
148 Hz
1358 Hz
Phase

   
Audio and Acoustic Measurements
193
11.3.2 Where to Place the Microphone
This frequent query has an easy answer: where your
ears tell you there is a problem, or where you need to
look at the radiation pattern for adjustment. For
example, the point equally distant from two loud-
speakers where you desire to “signal align” them for
minimum polar response interferences, see
Figs. 11-3A and 11-3B. Another example, the area
where your ears tell you that intelligibility has
suffered for no visually apparent reason and the
measurement of the Envelope Time Curve, ETC,
reveals an unexpected focused reflection damaging
the direct sound level in that area.
11.3.3 Measurement Analyzers
The authors prefer Richard C. Heyser’s analysis
system as exemplified in a TEF instrument. This is
not to deprecate other devices but is the result of the
superior signal-to-noise parameters so vital to field
measurements. The Heyser Integral Transform is
unique, Fig. 11-4. While it has yet to realize its full
potential in real instruments, its embodiment in
what’s currently available has radically changed how
we measure. Indeed the frequency modulation func-
tion identified by Heyser has found an embodiment
in HP’s modulation domain analysis, Fig. 11-5A,
11-5B, and 11-5C.
11.4 Examining AC Outlets
Prior to plugging any valuable equipment into an ac
outlet it should be examined for  unsuspected dc, (in
one case a light dimming circuit,in a motel meeting
room, was also wired to a three wire wall recep-
tacle), correct ac voltage, proper frequency, hot,
neutral and ground conductor impedances and proper
wiring in a three wire receptacles. GFCIs (ground
fault circuit interrupters) and AFCIs (arc fault circuit
interrupters) should have their proper performance
tested and verified. When anomalies appear in such
Figure 11-2. Comparison of an ear and a microphone.
(Courtesy Dr. Mead Killion.)
Specification  
Ear  
Mic*  Units
Size 
12  
0.17  cm3
Power Consumption 
50  
25   μW
Vibration Sensitivity (1 g) 
100  
75  dB SPL
Shock Resistance 
100  
20,000  g 
Noise Level (A-weighted) 
20  
20  dB SPL
Overload Level (10% THD) 
100  
140  dB SPL
Dynamic Range (Pure Tone) 100  
140  dB
Acoustic Input Z  
1.4  
0.03  cm3
(low frequency)
Frequency response 
25—16,000 10—25,000 Hz
 *Small electret
Figure 11-3. The effect of mis-alignment on loud-
speaker output.
Figure 11-4. Heyser Integral Transform.
A. Horizontal polar response of two loudspeakers
one stacked  on top of the other and in physical
alignment.
B. Horizontal polar response of two loudspeakers
one stacked on top of the other and out of physical
alignment by 3 inches.
x1
x2
x3
f(y,x)
g(y) =      ∫eiφ (y,x)f(x)dx
1
Κ
y = y1,y2,…ym
x = x1,x2,…xn
m ≤ n
≥
f(y,x) is a hypersurface, defined in parameters y
and expressed over all x.

194
Chapter 11
testing a careful examination of the wiring system
should be undertaken both for safety reasons and for
control of electrical noise in your system.
I can recall one case where a student of mine, a
sound contractor, called for the wiring inspection of
his new building. When the inspector arrived he was
handed a check for his work and turned to go out the
door. The student asked, “Aren’t you going to check
anything?” The inspector gave the check a long look
and said, “It looks all right to me.”
Figure 11-5. Processing TEF signals.
Auto
correlation
Cepstrum
Envelope-time
curve
Magnitude
Real
Phase
Imaginary
Imaginary
Phase
Magnitude
Real
Instant
frequency
Group
delay
?
Modulation
transfer
function
Time
Frequency
Doublet
Quadrature
response
d
dF
d
dt
H
H
H
H
Frequency
domain
Amplitude
Impulse response  coincident response
R2 + I2
R2 + I2
arctan I
R
arctan I
R
Time
domain
log a
log a
a2
a2
t
time
f
frequency
f
modulation
(frequency shift)
t
delay
(time shift)
Principle of
swept
measurements
Fourier
Consequence
of swept
measurements
A. TEF measurements.
B. When the frequency response of a time invariant 
system is measured as a function of time the (time) delay 
response is converted to a (frequency) modulation 
function.
C. The same signal can be represented in the time 
domain on an oscilloscope (bottom) and in the frequency 
domain on a spectrum analyzer (left). Hewlett-Packard's 
5371A frequency and time-interval analyzer shows the 
signal's frequency against time, inaugurating what HP calls 
the modulation domain. The analyzer simplifies such 
measurements as timing jitter, frequency drift, and 
modulation on communications signals.

   
Audio and Acoustic Measurements
195
11.4.1 First, Look and Listen
Upon arrival at a measurement site, first look and
listen. We should visually inspect the site and then
listen, sans sound system. Take time to walk the
audience area and listen to a live talker standing
where the performer will be. Listen for noise
masking of the talker—echoes, focused reflections,
and strange level dropouts, i.e., cancellations.
Cupping your ears allows some directional discrimi-
nation with regard to reflections. This exercise helps
to quickly ascertain if it’s the room or the system or
both that need correction. Many existing sound
systems in difficulty exist in rooms where the
unaided voice can be heard clearly.
A first look and listen allows identification of
logical measurement points. Once a given point is
selected make a global Envelope Time Curve, ETC.
The time base needs to be at least twice the room’s
largest dimension, or longer than the “by the ear”
estimate of the room’s RT60. The source used should
be one loudspeaker from the array that has the micro-
phone in its path. If inspecting the room before the
sound installation is possible, use a test loudspeaker
suitable for such a space or if that is not possible, at a
minimum, use one with a known Q. Whenever
possible, mount the loudspeaker, via a portable hoist,
in a logical location for a proposed system.
A global view of the time domain insures that
late arriving energy is not overlooked and at the
same time allows estimating the shorter time scales
that will be employed to obtain more detail. A rule
to remember is that you can truncate long time to
shorter time but not the reverse. From the first
global measurement, we looked at the Heyser Spiral.
See Fig. 11-6A, followed by the ETC in Fig. 11-6B.
See Fig. 11-6C for the truncated ETC of a shorter
interval which revealed a missynchronized package
loudspeaker that was non-minimum phase. See Fig.
11-6D for the Nyquist, where the curve encircled the
origin.
These initial measurements revealed a few of the
items needing correction in a minimum amount of
time.
11.5 The ETC Plot
The Envelope Time Curve, ETC, is related to a well-
established concept in communication theory known
as the modulation envelope. The Envelope Time
Curve is the magnitude of the analytic signal descrip-
tion of the impulse response.
In the acoustical measurement case, let I repre-
sent the impulse response which is a real function of
time and let 
 represent the Hilbert Transform of
the impulse response. Also, let IA represent the
analytic impulse response. Then, 
(11-1)
Now, consider the quantity
(11-2)
This is the quantity plotted versus time in forming
the curve known as the ETC. This is similar to a
smoothed version of the impulse squared response. It
has proven its worth over the years in identifying
detrimental reflections, locating the desired signal
delay corrections for magnitude measurements in the
frequency domain, usually “fine tuned” by micro-
second adjustments of the phase response, and in
examining the density or lack of density of the
reflected sound field at any given point in space.
11.5.1 Impulse Response
Today impulse responses are acquired in the
frequency domain both to address undue stress on the
loudspeaker system and to obtain an improved
signal-to-noise ratio, SNR. It is then inverse Fourier
transformed to the time domain where it can be
displayed in a number of forms, see Chapter 22
Signal Processing, for an explanation of Fourier
transform. The Fourier transform takes both the real
and the imaginary parts, from the amplitude and
phase measurements in the frequency domain, to
compute the impulse response in the time domain,
Fig. 11-7A. Additionally, the impulse response can
be Hilbert transformed to produce the doublet
response. The impulse response forms the real part of
the complex ETC while the doublet response forms
the imaginary part of the complex ETC, Fig. 11-7B.
Fig. 11-7C shows the relationship between the real
and imaginary parts on the Heyser Spiral.
Modern analyzers provide differing viewpoints
of the same information. A good example is the
comparison of the log squared amplitude of the
impulse response, Fig. 11-7D, to the ETC,
Fig. 11-7E. The impulse response contains all the
data but the ETC clearly shows some arrivals with
greater clarity due to the modulation domain aspect
of the envelope.
I 
IA
I
jI 
+
=
20
I2
I 
2
+
2
10 5
–
×
---------------------
log
20
IA
2
10 5
–
×
--------------------
log
=

196
Chapter 11
11.5.2 The Heyser Spiral
Richard C. Heyser’s remarkable insights, so often
copied, so seldom acknowledged, that signal acquisi-
tion in the frequency domain via a swept sine wave
(chirp) tracked by a time offset tracking filter yields
vastly superior SNR in both the frequency domain
and the inverse Fourier transformed time domain.
The easiest visualization of these processes is the
Heyser Spiral display. Fig. 11-8A shows the
frequency domain Heyser Spiral composed of the
complex signal on the frequency axis, the real and
imaginary parts shadowed on the appropriate planes,
and the Nyquist trace of the complex signal.
An inverse Fourier transform of both the real and
imaginary parts in the frequency domain produces
the impulse response (real) in the time domain,
Fig. 11-8B.
A Hilbert transform of the impulse response
(real) produces the doublet response (imaginary),
Fig. 11-8C. These real and imaginary parts yield the
Envelope Time Curve.
11.5.3 The Magnitude and Phase Response
Prior to Heyser, real life data from manufacturers
was usually frequency vs. level responses and rarely
phase response. The magnitude response is the most
familiar measurement to many. It has limited value
without the accompanying phase response. The
phase response requires “fine tuning” via the micro-
second adjustments available in modern analyzers.
The adjustment is used to bring the phase response to
0° wherever the magnitude response is uniform.
Once this has been done, if the device is minimum
phase the peaks and dips on the phase response will
be opposite the “slopes” on the magnitude response.
Why all the emphasis on minimum phase
response? It is because you cannot apply conven-
tional inverse equalization to the magnitude
response unless that portion of the magnitude
response is minimum phase. Non-minimum phase
usually implies a significant signal delay.
Magnitude response has a vertical decibel scale
and a horizontal frequency scale. Phase has a
vertical scale in plus or minus degrees and a hori-
zontal frequency scale. In all measurements it is
Figure 11-6. Variety of TEF displays.
A. A Heyser spiral of the room
in the time domain.
D. Nyquist display showing non minimum
phase encirclement of origin.
B. The Envelope Time Curve (ETC). Note that the cursors
(readout above plot) solve for RT60, %ALCONS, and direct
to reflected levels.
C. ETC with shorter time interval than Heyser spiral revealing a
non synchronized loudspeaker.
cursor
cursor
integration

   
Audio and Acoustic Measurements
197
vital to know what the frequency resolution is.
Resolution that is too broad gives optimistic
smoothing whereas resolution too narrow includes,
in many cases, undesired reflected information.
Measuring phase instead of magnitude provides
greater sensitivity and resolution. For example,
finding resonant frequencies (phase passes through
zero at resonance), the phase response will typically
be 10 times more sensitive than the magnitude
response. Acoustic delay problems jump out in phase
and can be difficult, at best, with magnitude
response. The pairing of magnitude and phase,
Fig. 11-9 (upper two curves), allows detection of
non-minimum phase frequencies—the phase inflec-
Figure 11-7. Time domain displays.
A. TEF impulse.
B. TEF doublet.
1.37 ms
1.35 ms
Polar
Imaginary
l
R
F
Real
C. Heyser response in the time domain.
1.37 ms
1.35 ms
Polar
R
Real
Imaginary
Time 
14 ms
Phase Angle 
−47.75 Deg
Magnitude 
0.012 Pascals
Real 
0.008 Pascals
Imaginary 
−0.009 Pascals
F
I

198
Chapter 11
tion points don’t intersect the center of the magni-
tude slopes. Further, a flattened phase response over
a selected range reveals that the magnitude correc-
tion was properly done, Fig. 11-9 (lower two curves).
A non-minimum phase system is one that
exhibits an excess delay of the signal over that
termed the phase delay. Since an increasing number
of audio devices include, either deliberately or acci-
dentally, all-pass components, phase measurements
are of ever increasing importance.
11.5.4 Three Parameter Measurements
In the arsenal of analysis today are the three param-
eter measurements where the resolution of two
parameters is “smeared” to allow a conceptual view
of what is occurring. We can choose to compromise
the frequency magnitude resolution for higher time
resolution, or we can compromise the time resolution
for higher frequency magnitude resolution. The
typical choice, because we have both ETC and EFC,
energy frequency curve, for detailed individual
views, is to smear both frequency and time resolu-
tions for a compromise view of what some decaying
frequency areas do over time. Typical display
parameters are frequency on the horizontal scale,
magnitude on the vertical scale, and time on the
diagonal scale, Fig. 11-10.
While it always remains true that the reciprocal
of the frequency bandwidth determines the time
resolution and the reciprocal of the time window
determines the frequency resolution, it is possible by
“smearing” each parameter to gain an insight into
the frequency vs. time behavior of a system, espe-
cially when some frequencies are longer in decaying
than other frequencies.
(11-3)
where,
Δf is frequency resolution,
ΔT is time resolution.
Figure 11-7. (cont) Time domain displays.
D. Log2 implulse.
E. ETC.
Δf
ΔT
×
1
≥

   
Audio and Acoustic Measurements
199
Figure 11-8. Using the Hilbert Transform of a function of time (convolution with 1/πt) yields the imaginary (doublet) 
in the time domain.
Figure 11-9. Equalized and unequalized transfer functions.
20log( 0.030 Pa
0.00002 Pa ) = 63.5 dB
atan(
-0.007
0.029 ) = -13°
A. Heyser Spiral in the frequency domain.
B. Fourier transform from frequency domain to time
domain of real and imaginary parts in the frequency
domain yields the impulse response.
magnitude = 20log(
0.00002 Pa ) = 55.6 dB
0.012 Pa
magnitude in Pa = 
0.005 Pa ) = 65.6 dB
0.011 Pa
20log(
0.00002 Pa
) = 63.5 dB
(0.029)2 + (0.007)2
(0.029)2 + (0.007)2
= 0.030 Pa
phase angle = atan(
C. Heyser Spiral in the time domain.
Unequalized magnitude
Equalized magnitude
Unequalized phase
Equalized phase

200
Chapter 11
11.5.5 The Nyquist Plot
A Nyquist plot provides simultaneously the real part,
the imaginary part, the magnitude, the phase, the
frequency and the identification of minimum and
non-minimum phase. It is easily one of the most
useful frequency domain measurements either elec-
trically or acoustically. Modern analyzers provide
cursor read out of the entire plot in addition to identi-
fying non-minimum phase frequencies when they
encircle the origin.
The zero axis is the real component, the 90° axis
the imaginary component, and the length from the
origin to any chosen frequency on the plot is the
magnitude component. Any range of frequency for
which the Nyquist plot completely encircles the
origin is a range of non-minimum phase behavior.
The angle between the zero axis and the cursor set
on a given frequency is the phase angle,
Figs. 11-11A and 11-11B.
Nyquist Complex Impedance Plots
Many of the points discussed here appeared in an
Audio Magazine article written by Richard Heyser in
June 1984.
The electrical impedance of a loudspeaker is a
measure of the amount by which it impedes the
passage of current. Impedance is measured by deter-
mining the voltage required to pass a fixed amount
of current. There is a resistive component and a
reactive component to impedance. A loudspeaker
can temporarily store some of that energy it gets
from the amplifier as well as dissipate the energy in
the form of heat and sound. The part that represents
dissipation is resistance, the part that represents
storage is reactance. The unit of measurement is the
ohm. 1.0 A current produces one volt drop across
one ohm impedance. If a loudspeaker were a pure
resistance load, energy would only pass from the
amplifier to the speaker, where it could be converted
to heat and sound, but a loudspeaker is not a pure
resistor. Loudspeakers store energy and send it back
to the amplifier as the amplifier attempts to maintain
control of the signal volt.
Heyser’s preferred mode of plotting impedance
was the Nyquist plot.  The Nyquist plot always curls
clockwise as it progresses upward in frequency. The
plot looks like, and is, circles on circles. The circle
form is a fundamental expression of energy
Figure 11-10. Three parameter measurement.
Magnitude (dB)
Frequency (Hz)
Figure 11-11. Minimum and non-minimum Nyquist plots.
B. Non-minimum phase Nyquist plot.
A. Minimum phase Nyquist plot.
Imaginary
Real
Imaginary
Real
Note: Non minimum phase angle for cursor
(dark line) is −346.27°
cursor

   
Audio and Acoustic Measurements
201
exchange. As an electromechanical device, the loud-
speaker will have a number of impedance reso-
nance modes. A sealed low-frequency driver will
have one bass resonance circle, while most vented
low-frequency units have two. An epicycle on the
low-frequency plot of a sealed system often indi-
cates a poorly sealed enclosure with a leak.
Sometimes separate drivers in a
system will talk to each other. Acoustic
coupling between drivers is always
unavoidable, but if improper crossover
design allows two or more drivers to
carry on simultaneous conversations in
the same frequency range, each driver
will hear the other talking and show it
as a change in impedance. Small extra
loops which look like pigtails added to
the curve are telltale clues to this inter-
speaker chitchat.
Because present-day loudspeakers are designed
to produce sound pressure based upon constant
voltage applied to the speaker terminals, it would
make sense to measure the amount of current that is
drawn at this rated voltage. This is just the inverse
of impedance. Whereas impedance is a measure of
the voltage drop produced by a fixed amount of
current, admittance is a measure of the current
drawn when a fixed voltage is applied in the simple
case of the loudspeaker, admittance is the inverse of
impedance.
Heyser preferred admittance measurements
which also comes in two parts and are related to
dissipation and storage of energy.
The part related to dissipation is
called conductance, and the part related
to storage is called susceptance. The
units of measurement for these parts are
the inverse of the units of measurement
for impedance and are expressed in
Siemens.
Heyser liked to point out that loudspeakers are
notoriously nonlinear in their electromechanical
properties. Impedance (and admittance) is a function
not only of instantaneous drive level, but of the
immediate past history of the signal which has been
applied to the speaker. They are non-Markovian in
their signal handling properties. Clearly one of the
most meaningful measurements one can ask in the
specification of loudspeakers is a carefully made
Nyquist plot of its impedance.
11.5.6 The Polar Envelope Time (PET) Plots
The polar envelope time plot allows for any given
point of measurement, instant values of:
1.
The direction from which the reflection came.
2.
The time of travel and distance.
3.
The level.
11.5.7 History of Polar Time Measurements
During WWII, Dr. Sidney Bertram developed a
Sonar system for submarines named by its users as
“Hells Bells.” It consisted of a rotating hydrophone
connected to an oscilloscope display through a bank
of bandpass filters and associated electronics that
displayed direction to target as an angle on the oscil-
loscope screen and the range to target as variable
frequency sound. Close range—low bell-like tones,
long range—higher bell-like tones. This system was
used to put five U.S. submarines through a dense
minefield into the Sea of Japan where they played an
effective part in intercepting shipments from the
Asian continent.
Today’s system uses the input from six direc-
tional microphone measurements—forward, right,
rear, left, and up and down. Farrel Becker developed
PET for use with TEF analysis. It was after Farrel
had programmed the software that a report from +30
years after WWII that we read in an IEEE journal
gave recognition of Bertram’s work.
The PET measurement is easily one of the most
usable measurements ever devised for mapping
reflections in architectural spaces. The use of a cali-
brated cursor gives precise distance, time, and
bearing. One sound designer with deep experience
in difficult acoustic environments, Deward Timothy
of Poll Sound in Salt Lake City, uses the measure-
ment in the orientation of arrays to minimize the
detrimental reflections.
Each direction measured produces an individual
ETC measurement. These are combined to produce
the PET. Samples of each type of display are shown
in Figs. 11-12A through 11-12F. To read a PET
measurement, identify on the circumference the
parameters for that plot, i.e., up, down, etc., or
forward, back, left, right, etc.
The cursor can be placed on any dot on the
screen and its length is the distance, its angle is the
bearing, and its magnitude is read on the cursor
printout. LD arrives first and its source is apparent as
the shortest distance.
Figs. 11-12A and 11-12B, with the title “Flutter,”
are of a severe left-to-right flutter echo. The

202
Chapter 11
Figure 11-12. PET measurements.
A. Flutter
B. Flutter
C. Room acoustics—front.
D. Room acoustics—front.
E. Room acoustics—front.
F. Conventional ETC.

   
Audio and Acoustic Measurements
203
conventional ETC is one of the four used to make
the Polar Time Plot, in this case the left ETC
(microphone facing left).
Fig. 11-12C, “Room Acoustics—Front” is from
the Intelligibility Workshop. There are three Polar
Time Plots. The one with the floor values, first two
text lines below the graph, set at 20.0 dB is in the
horizontal plane and shows just the strongest reflec-
tions. The cluster of reflections in the forward direc-
tion, just above the origin, is from the rear wall of
the orchestra shell.
Figs. 11-12D and 11-12E have the floor set at
24.0dB and show more reflections. One is in the
horizontal plane and the other is in the median plane.
The reflections from the orchestra shell and rear wall
of the auditorium are clearly seen in both plots.
Fig. 11-12F is a conventional ETC taken omnidi-
rectionally and from the same location as the polar
plots.
11.6 Site Surveys and Noise Criteria Curves
An important test that needs to be made at the site
prior to building anything is a noise survey. This can
be from a few minutes up to 24 hours. It consists of
noise level analysis measurements, NLA, weighted
consistent with the existing facts and the expected
use of the building. Fig. 11-13A illustrates the
variety of data that can be gathered in a one minute
example NLA.
Coupled with such measurements should be the
established noise criteria desired in order to estimate
the required noise isolation the structure must
provide, Fig. 11-13B, i.e., the difference between
NLA levels and desired criteria.
Once the building is finished, the NC is
measured for compliance with the chosen design
criteria, Fig. 11-13C. The 2 kHz octave band is the
one most often used for the SNR figure for %ALCONS
calculation.
A very useful estimator of listener response is
shown in Fig. 11-13D where the many variables that
help shape human responses are considered and
tabulated.
The most commonly encountered violation
measured is a too-noisy HVAC system. Often
balancing of the HVAC can provide the difference
between “fail” and “pass.” Because speech intelligi-
bility is directly dependent upon SNR failure to
specify correct noise criteria, and further failure to
measure the violation can doom an otherwise
successful sound system installation.
NC curves are plotted in 1⁄1 octave bands. They
allow, at a glance, a comparison of the acoustic
response at a listener from the sound system to the
NC value for the signal-to-noise evaluation. Criteria
exist for most common applications.
11.6.1 Constant Percentage Bandwidth Analysis
Constant percentage bandwidth analyzers are widely
used. One-third of an octave, 23% of center
frequency, one-sixth of an octave, 11.5% of center
frequency, or one-twelfth of an octave, 5.76% of
center frequency filters allow essentially “real time”
analysis of non-stationary signals. (See Section 11.9
Fractional Bandwidth Filter Analyzers.) One of the
authors was instrumental in seeing the first 1⁄3 octave
filter analyzers come to the market in 1968. The term
“third octave” is often employed for 1⁄3 of an octave
but is incorrect as it describes a filter for every third
octave. See Fig. 11-14A for a 1⁄6 octave display and
Fig. 11-14B for a 1⁄12 octave RTA display.
11.7 An Improper Use of Real Time Analysis
Constant percentage bandwidth filters have absolute
widths that increase in direct proportion to the center
frequency of the filter. When performing spectrum
analysis with instruments based on such filters it is
necessary to employ a random noise source whose
spectrum has constant energy per octave, i.e., pink
noise as opposed to a noise source that has constant
energy per unit bandwidth, i.e., white noise.
A system possessing a uniform or flat response
on a per unit bandwidth basis that is excited with
pink noise will produce a flat display on a constant
percentage bandwidth analyzer. Such a system
excited with white noise would produce a response
that rises at 3 dB/octave on a constant percentage
bandwidth analyzer. Therefore, when constant
percentage bandwidth analyzers are employed to
study the spectra of program material where it is
desired to determine the response displayed on a per
unit bandwidth basis, it is necessary to precede such
an analyzer by a filter that has a response that falls at
the rate of 3 dB/octave. Any evaluation of program
material without such a device is invalid.
It is the authors’ belief that this uncorrected error
is why so many professional mixing engineers still
use meters and indicators in place of the much more
useful real time analyzer. Trained ears didn’t agree
with the uncorrected visual display. The noise
control people made their criteria constant
percentage bandwidth based, thereby judging rela-
tive results. The recording engineers, home hi-fi
enthusiasts, and other researchers did not realize the
need and therefore failed to compensate for it.

204
Chapter 11
Figure 11-13. Noise criteria.
A. NLA sample.
ST:60
Time
 
A Weighted 
NC
Residences                                                
  Private homes 
25-35 
20-30
  (rural and suburban)
  Private homes (urban) 
30-40 
25-35
  Apartment houses, 2- and 3-family units 35-45  
30-40
Hotels  
  Individual rooms or suites  
35-45  
30-40
  Ball rooms, banquet rooms  
35-45  
30-40
  Halls and corridors, lobbies  
40-50  
35-45
  Garages  
45-55  
40-50 
  Kitchens and laundries  
45-55  
40-50
Hospitals and Clinics  
  Private rooms  
30-40  
25-35
  Operating rooms, wards  
35-45  
30-40
  Laboratories, halls and corridors, 
40-50  
35-45
    lobbies and waiting rooms
  Washrooms and toilets  
45-55  
40-50
Offices  
  Board room  
25-35  
20-30
  Conference rooms  
30-40  
25-35
  Executive office  
35-45  
30-40
  Supervisor office, reception  
35-40  
30-45
  General open offices, drafting rooms 
40-55  
35-50
  Halls and corridors  
40-55  
35-55
  Tabulation and computation  
45-65  
40-60
Auditoriums and Music Halls   
  Concert and opera halls, studios   
25-35  
20-25
    for sound reproduction
  Legitimate theaters, multipurpose halls 
30-40  
25-30
  Movie theaters, TV audience studios, 
35-45  
30-35
    semi-outdoor amphitheaters,
    lecture halls, planetarium 
  Lobbies  
40-50  
35-45
 
A Weighted 
NC
Churches and Schools   
  Sanctuaries  
25-35  
20-30
  Schools and classrooms   
35-45  
30-40
  Laboratories  
40-50  
35-45
  Recreation halls  
40-55  
35-50
  Corridors and halls  
40-55  
35-50
  Kitchens  
45-55  
40-50
Public Buildings  
  Public libraries, museums, court rooms 35-45  
30-40
  Post offices, general banking areas, 
40-50  
35-45
    lobbies 
  Washrooms and toilets  
45-55  
40-50
Restaurants, cafeterias, lounges  
  Restaurants  
40-50  
35-45
  Cocktail lounges  
40-55  
35-40
  Night clubs  
40-50  
35-45
  Cafeterias  
45-55  
40-50
Stores retail  
  Clothing stores, department stores 
40-50  
35-45
    (upper floors) 
  Department stores (main floor), 
45-55  
40-50
    small retail stores 
  Supermarkets  
45-55  
40-50
Sports activities—Indoor  
  Coliseums  
35-45  
30-40
  Bowling alleys, gymnasiums  
40-50  
35-45
  Swimming pools  
45-60  
40-55
Transportation (rail, bus, plane)  
  Ticket sales offices  
35-45  
30-40
  Lounges and waiting rooms  
40-55  
35-50
B. Ranges of indoor design goals for air-conditioning system sound control

   
Audio and Acoustic Measurements
205
11.8 Evaluation of Listener Response
Measurements that correlate well with listener
response are those with a frequency resolution
approximating “critical bandwidths.” This falls
between 1⁄3 and 1⁄6 of an octave, Fig. 11-15. One of
the authors once walked into a church auditorium to
be told by the organist that it was the “deadest”
church acoustically he had ever played in, followed a
minute later when he met the minister who stated it
was “too live” to preach in. Measurements of the
reverberation time vs. frequency revealed that some-
thing was passing low frequencies from the room but
the mid-band frequencies were excessively rever-
berant. The low frequencies were being diaphrag-
matically absorbed by the paneling in the ceiling
which, when braced, allowed the bass to remain in
the room to the satisfaction of the organist. Absorp-
tive treatment on the rear walls and seat cushions
controlled the mid-frequency excess to the satisfac-
tion of the minister.
Listener response can vary drastically due to the
pinnae response of the individual. For a uniform
(flat) frequency response to the ear, these pinnae
Figure 11-13. (cont) Noise criteria.
C. NC in residence.
D. Annoyance of neighborhood sound levels.

206
Chapter 11
responses are measured at the individual’s eardrum.
The combined ear canal resonance and the “comb
filtering” of the folds in the pinnae give the resulting
responses. Listener response is important because in
existing structures, the complaints become micro-
phone positions for measurements that need to be
made, Fig. 11-16.
The science and art of measurement begin in the
brain of the measurer and the apparatus either
confirms the hypothesis or provides the opportunity
for serendipity to lead thought in a new direction.
11.9 Fractional Bandwidth Filter Analyzers
Fractional bandwidth filter analyzers are the most
commonly used; therefore, we have included their
mathematical structure for evaluation of frequency
spacing, frequency resolution, and frequency labels
from 1⁄1 to 1⁄24 octave equivalents and 100.3 to 100.0125
decades. For example, series 80 increments yield
Figure 11-14. RTA displays.
A. 1/6 octave RTA display.
B. 1/12 octave RTA display.
Figure 11-15. A plot of critical bandwidths of the
human auditory system compared to constant
percentage bandwidths of filter sets commonly used in
acoustical measurements.
100     200         500      1k        2k           5k     10k
Center frequency–Hz
1000
500
200
100
50
20
10
Bandwidth–Hz
1 octave
1/6 octave
1/3 octave
Critical band (ERB)

   
Audio and Acoustic Measurements
207
series 40 upper and lower crossover frequencies
between center frequencies in the 40 series.
The coincidence of 1⁄3 octaves and 1⁄10 decades in
value has led to wide use of decade filters in both
equalizers and analyzers.
1.
21/3(1.259921050).
2.
100.1(1.258925412).
difference = 0.000995638
100.1 was named the “10” Series because
(11-4)
There are 10 bands per decade.
Band numbers were N = 0 and up (100 = 1.0).
This allowed a very simple equation to be written
that would serve for any series and any N in decade
intervals. From this equation, any center frequency
fC could then be easily calculated.
(11-5)
simplified to:
(11-6)
11.9.1 Series
If the reciprocal of 0.1 is 10 Series, then the 1⁄1 octave
equivalent in decades would be 10/3 = 31/3 Series
(because there are three 1⁄10 decade fCs in the
1⁄1 octave decade equivalent). That makes the decade
100.3 for the 1⁄1 octave equivalent. A 2⁄3 octave decade
equivalent would become 2⁄3(0.3) = 1000.2. We can
now write out for the most used equivalents.
The series tells how many Ns are in one decade
(i.e., N = 1 to N for the first decade). The Ns then
repeat with only the decimal point moved to the
right for each higher decade.
11.9.2 Other Uses
The pass band for filters can be found (for the −3 dB
power points) by:
(11-7)
and
(11-8)
where,
fxU is the upper −3 dB point,
fxL is the lower −3 dB point.
The Q of the filter is found by:
(11-9)
where,
fC is the center frequency of the filter.
The percent bandwidth is found by calculating
the bandwidth for 100 Hz. For example:
(11-10)
Figure 11-16. Pinnae responses.
1
0.1
-------
10
=
fC
100.1N
=
10
N
series
----------------
Octave 
Equiv.
Decade
Series 
N = 1.0
1⁄1 
100.3
31⁄3
1.995262
2⁄3
2⁄3 × 0.3 = 100.2
1⁄0.2 = 5
1.584893
1⁄2
1⁄2 × 0.3 = 100.15
1⁄0.15 = 62⁄3
1.412538
1⁄3
1⁄3 × 0.3 = 100.1 
1⁄0.1 = 10
1.258925
1⁄6
1⁄6 × 0.3 = 100.05 
1⁄0.05 = 20
1.220180
1⁄12
1⁄12 × 0.3 = 100.025
1⁄0.025 = 40
1.059254
fxU
10
N
0.5
+
series
-----------------
=
fxL
10
N
0.5
–
series
-----------------
=
fxU
fxL
–
Bandwidth in Hz
=
Q
fC
BW
---------
=
N
series
fC
log
×
=
N
10
100
log
20
=
=
10
20
0.5 
+
10
---------------------
⎝
⎠
⎜
⎟
⎛
⎞
10
20
0.5 
–
10
---------------------
⎝
⎠
⎜
⎟
⎛
⎞
–
23.076752%
=
Q
100
23.076752
-------------------------
=
4.33
=

208
Chapter 11
11.9.3 Useful Tools 
To rapidly calculate for any series all fxU, fC, and fxL
you can repeatedly multiply:
(11-11)
The value for N = 1⁄2 is the first fxL. The next
number is N = 1fC. The next number is fxU for N = 1
and fxL for N = 2. Again, the next number is fC for
N = 2, etc. Having thus calculated all the fxs you can
extract all the bandwidths.
11.9.4 Using the Decade Exponents
Writing out again the decade exponents we find that
by using the 1⁄10 decade bandwidths we can multiply
that bandwidth by 10 times the exponent to obtain
the other bandwidths and percentages.
For values of Q we can take the 100 Hz/BW for
the series 10 and again multiplying the exponents by
10 we can divide them into the series 10 value to
obtain all the other Q values.
The difference in power bandwidths expressed in
decibels is
(11-12)
Also band 43–13 is 30 bands or 30 dB in the case of
series 10.
11.9.5 Decibels
Once again, using series 10 every step in the
repeated multiplication of
is a 1.0 dB step on the 20log scale. Every other step
(i.e., the fCs) is 1.0 dB on the 10log scale.
11.9.6 Label Frequencies
The equations discussed in this article are for the
exact frequencies you would use as center frequen-
cies and crossover frequencies for equalizers and
analyzers. In actual practice the center frequencies
are labeled in a simplified manner. Table 11-1
outlines these labels for the 1⁄1, 1⁄2, 2⁄3, 1⁄3, 1⁄6, and 1⁄12
devices in use today.
100.3
3 × 23.029 = 69.087
100.2
2 × 23.029 = 46.085
100.15
1.5 × 23.029 = 35.544
100.1
1.0 × 23.029 = 23.029
100.05
0.5 × 23.029 = 11.515
100.025
0.25 × 23.029 = 5.757
fxU fC fxL
,
,
10
N
0.5
–
series
-----------------
=
100.3
4.342/3.0 = 1.447
100.2
4.342/2.0 = 2.171
100.15
4.342/1.5 = 2.895
100.1
4.342/1.0 = 4.342
100.05 
4.342/0.5 = 8.685
100.025 
4.342/0.25 = 17.369
dB
10
Highest frequency bandwidth
Lowest frequency bandwidth
----------------------------------------------------------------------
log
=
10
N
0.5
–
10
-----------------
10
N
0.5
–
10
-----------------
…
×
×
Table 11-1. Frequency Labels for Audio Components
1⁄12 Octave
40 Series
1⁄6 Octave
20 Series
1⁄3 Octave
10 Series
1⁄2 Octave
62⁄3 Series
2⁄3 Octave
5 Series
1⁄1 Octave
31⁄3 Series
Exact Value 
1.0
1.0
1.0
1.0
 1.0
1.0
1.000000000
1.06
1.059253725
1.12
1.12
1.122018454
1.18
1.188502227
1.25 
1.25 
1.25 
1.258925411 
1.32 
1.333521431 
1.4 
1.4 
1.4 
1.412537543 
1.5 
1.496235654 
1.6 
1.6 
1.6 
1.6 
1.584893190 
1.7 
1.678804015 
1.8 
1.8 
1.778279406 
1.9 
1.883649085 

   
Audio and Acoustic Measurements
209
Table 11-2 is the first decade for all the filters
discussed and includes all center frequencies and
cross-over frequencies. As a final bonus, from the
one exponent, each step is 1⁄8 dB on the 10log scale
and 1⁄4 dB the 20log scale.
1.
All even numbers are the 1⁄12 octave center
frequencies.
2.
Every 4th number is a 1⁄6 octave center frequency.
3.
Every 8th number is 1⁄3 octave center frequency.
4.
Every 12th number is a 
1⁄2 octave center
frequency.
5.
Every 16th number is a 
2⁄3 octave center
frequency.
6.
Every 24th number is a 
1⁄1 octave center
frequency.
7.
All odd numbers are 
1⁄12 octave crossover
frequencies.
8.
Every other 1⁄12 octave center frequency is a 1⁄6
octave crossover frequency.
9.
Every other 1⁄6 octave center frequency is a 1⁄3
octave crossover frequency.
10. Every other 1⁄3 octave center frequency is a 1⁄2
octave crossover frequency.
11. Every other 1⁄2 octave center frequency is a 1⁄1
octave crossover frequency.
12. 2⁄3 octave crossover frequencies start at the sixth
line and every 12th line thereafter.
11.10 Measuring Electromagnetic Pollution
The proliferation of electromagnetic fields, even in
rural areas, such as cross-country power lines, some-
times using exotic new techniques, cell phone
towers, wireless Internet providers, powerful
weather radars, etc., should be identified and dealt
with when designing and installing complex audio
and visual systems.
2.0
2.0
2.0
2.0
2.0 
1.995262310
2.12
2.113489034 
2.24 
2.24 
2.238721132 
2.36 
2.371373698 
2.5 
2.5 
2.5 
2.5 
2.511886423 
2.65 
2.660725050 
2.8 
2.8 
2.8 
2.818382920 
3.0
2.985382606 
3.15 
3.15 
3.15 
3.162277646 
3.35 
3.349654376 
3.55 
3.55 
3.548133875 
3.75 
3.758374024 
4.0 
4.0 
4.0 
4.0 
4.0 
4.0 
3.981071685 
4.25 
4.216965012 
4.5 
4.5 
4.466835897 
4.75 
4.731512563 
5.0
5.0 
5.0 
5.011872307 
5.3 
5.308844410 
5.6 
5.6 
5.6 
5.623413217 
6.0
5.956621397 
6.3 
6.3 
6.3 
6.3 
6.309573403 
6.7 
6.683439130 
7.1 
7.1 
7.079457794 
7.5 
7.498942039 
8.0 
8.0 
8.0 
8.0 
8.0 
7.943282288 
8.5 
8.413951352 
9.0
9.0
8.912509312 
9.5 
9.440608688 
Table 11-1.  (cont) Frequency Labels for Audio Components
1⁄12 Octave
40 Series
1⁄6 Octave
20 Series
1⁄3 Octave
10 Series
1⁄2 Octave
62⁄3 Series
2⁄3 Octave
5 Series
1⁄1 Octave
31⁄3 Series
Exact Value 

210
Chapter 11
The ability to detect concealed radio frequency
transmitters, weak electric fields from wall switches
and concealed wiring, poorly grounded wiring,
dimmer switches, TV and computers, microwave
devices, diathermy apparatus, and other unexpected
EMF sources in or near the environment where your
system will be installed is vital.
The tri-field ™ meter allows such measurements
to be made relatively inexpensively. Their extended
range broadband meter has a minimum sensitivity
for magnetic fields of one mill gauss and an electric
field sensitivity of 10 volts per meter (V/m). Its RF
microwave sensitivity is 0.01 kV/m. This handheld
direct reading meter can help clarify many otherwise
baffling effects.
When doing site surveys sensitivity to
high-voltage power lines, RF antennas, substations,
in addition to the usual audio noise sources, is an
important part of the survey.
Another highly valuable handheld instrument is
the GLIT (ground loop impedance tester) which
momentarily shorts a power line and measures the
loop impedance without causing the breaker to
open. These are more costly than the electromag-
netic meter but are used much more frequently.
It is surprising that so many people will plug a
valuable electronic instrument into a power socket
without first testing it to see if it is ac or dc, the
proper voltage, proper frequency and properly
grounded. In one case, a $5000 analyzer was
plugged into a circuit with a dimmer switch on it,
which in this case, fortunately only blew the fuse in
the analyzer.
While involved in helping provide sound for the
American National exhibition in Moscow in 1959,
we had only 40 Hz Russian voltage sources and our
American amplifiers power transformers drew too
much exciting current, after a short period the
amplifiers would send up a small mushroom cloud.
Inasmuch as this was going to occur in the presence
of high officials from both Russia and the U. S. at
the opening of the National Exhibition, we advised
the security personnel of the possibility, with the
result that they gathered around the amplifier and
did witness the cloud arise. A spare was immedi-
ately available and helped finish the ceremony. An
emergency 50 Hz generator was flown in from
Berlin to power our pavilion allowing our equip-
ment to work satisfactorily.
These antidotical experiences led me to approach
every wall socket with a liberal amount of paranoia.
Hopefully the manufacturers of contemporary
equipment are more international in their design of
protection circuits for their electronics and more
tolerant of unexpected power sources.
Table 11-2. 80 Series fCs
1.0292005272 
1.8302061063 
3.2546178350 
5.7876198835 
1.0592537252 
1.8836490895 
3.3496543916 
5.9566214353 
1.0901844924 
1.9386526360 
3.4474660657 
6.1305579215 
1.1220184543 
1.9952623150 
3.5481338923 
6.3095734448 
1.1547819847 
2.0535250265 
3.6517412725 
6.4938163158 
1.1885022274 
2.1134890398 
3.7583740429 
6.6834391757 
1.2232071190 
2.1752040340 
3.8681205463 
6.8785991231 
1.2589254118 
2.2387211386 
3.9810717055 
7.0794578438 
1.2956866975 
2.3040929761 
4.0973210981 
7.2861817451 
1.3335214322 
2.3713737057 
4.2169650343 
7.4989420933 
1.3724609610 
2.4406190680 
4.3401026364 
7.7179151559 
1.4125375446 
2.5118864315 
4.4668359215 
7.9432823472 
1.4537843856 
2.5852348396 
4.5972698853 
8.1752303794 
1.4962356561 
2.6607250598 
4.7315125896 
8.4139514165 
1.5399265261 
2.7384196343 
4.8696752517 
8.6596432336 
1.5848931925 
2.8183829313 
5.0118723363 
8.9125093813 
1.6311729092 
2.9006811987 
5.1582216507 
9.1727593539 
1.6788040181 
2.9853826189 
5.3088444423 
9.4406087629 
1.7278259805 
3.0725573653 
5.4638654988 
9.7162795158 
1.7782794100
3.1622776602 
5.6234132519 
10.0000000000 
10
0.5
40
-------
⎝
⎠
⎛
⎞N
1–20
=
10
0.5
40
-------
⎝
⎠
⎛
⎞N
21–40
=
10
0.5
40
-------
⎝
⎠
⎛
⎞N
41–60
=
10
0.5
40
-------
⎝
⎠
⎛
⎞N
61–80
=

   
Audio and Acoustic Measurements
211
11.11 Conclusion
Acoustic tests are a mental exercise assisted by
measured hints. It’s when measurements don’t agree
with the trained ear that a chance for serendipity is at
hand.
Bibliography
A. P. G. Peterson and E. E. Gross, Jr. Handbook of Noise Measurement, 7th ed. General Radio Co., Concord,
MA, 1972.
B. M. Oliver and J. M. Cage. Electronic Measurements and Instrumentation. New York: McGraw-Hill, 1971.
D. Davis. Acoustical Tests and Measurements. Indianapolis, Ind.: Howard W. Sams, 1965.
_______. “70 Volt Line Tester During Installation,” Syn-Aud-Con Newsletter, Vol. 1, No. 3 (1974).
_______. “Real Time Audio Spectrometry,” Record. Eng./Prod. (1971).
_______. “The Twenty-TDS Workshop,” Syn-Aud-Con Tech Topics, Vol. 6, No. 13 (1979).
General Radio Co. Useful Formulas, Tables, Curves for Random Noise. Tech. Letter, June 1963.
R. C. Heyser. “Acoustical Measurements by Time Delay Spectrometry,” J. Audio Eng. Soc., Vol. 15 (1967),
p. 370.
________. “Breakthrough in Speaker Testing,” Audio (Nov. 1973), pp. 20-30.
________. “Determination of Loudspeaker Arrival Times: Part I,” J. Audio Eng. Soc., Vol. 19 (Oct. 1971),
pp. 734-743.
________. “Determination of Loudspeaker Arrival Times: Part II,” J. Audio Eng. Soc., Vol. 19 (Nov. 1971),
pp. 829-834.
________. “Determination of Loudspeaker Arrival Times: Part III,” J. Audio Eng. Soc., Vol. 19 (Dec. 1971),
pp. 902-905.
________. “Loudspeaker Phase Characteristics and Time Delay Distortion: Part 1,” J. Audio Eng. Soc., Vol.
17 (1969), p. 30.
________. “Loudspeaker Phase Characteristics and Time Delay Distortion: Part 2,” J. Audio Eng. Soc., Vol.
17 (1969), p. 130.
R. Morrison. Instrumentation Fundamentals and Applications. New York: Wiley-Interscience, 1984.
W. R. Kundert and A. P. G. Peterson. “Spectrum Analyses of Stationary Noise Signals,” Sound and Vibration
(June 1969).


Chapter 12
Large Room Acoustics
by Don Davis
213
12.1 What Is a Large Room?  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 215
Use of the Sabinian Equations in Large Reverberant Spaces  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 215
The Sabine Equation  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 217
Specific Versus Statistical  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 218
Calculating the Rate of Decay of Reverberant Sound Energy  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 218
Improved Reverberation Time Calculations  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 219
Importance of Sabine . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 219
Limitations of All Acoustic Equations Based on Geometry and Statistics . . . . . . . . . . . . . . . . . . . . . . 220
12.2 Levels Defined: Sound Power Level (LW), Sound Intensity Level (LI), and Sound Pressure Level (LP)  220
Sound Power Level (LW) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 220
Sound Intensity Level (LI) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 220
Sound Pressure Level (LP) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 220
12.3 Levels in Enclosed Spaces . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 221
Hopkins-Stryker—US and SI  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 222
Other Terms Derived from Hopkins-Stryker . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 222
12.4 Differentiating Between Reverberant Level and Reverberation Time . . . . . . . . . . . . . . . . . . . . . . . . . . 224
12.5 Evaluation of Signal-to-Noise Ratio, SNR . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 225
12.6 Analyzing Reflections and Their Paths  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 226
Sound System Near Regeneration . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 226
How Harmful Is High RT60? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 226
Effect of Reverberation on Intelligibility  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 226
Variations in the Measurement of Reverberation  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 227
12.7 Critical Distance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 228
Q Versus  for Controlling Dc . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 229
Dc Multipliers and Dividers  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 229
Theory of Ma . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 230
The Effect of the N Factor . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 230
Factors to Watch for in Rooms  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 231
12.8 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 233
Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 233


Large Room Acoustics
215
12.1 What Is a Large Room?
Manfred Schroeder has defined a large room
frequency (FL) as the frequency above which a large
number of room modes will be excited to vibrate at
the source frequency.
(12-1)
where,
FL is the large room frequency in Hz,
K is 2000 in the SI and 11,885 in the U.S.,
RT60 is the apparent reverberation time for 60 dB of
decay in seconds,
V is the volume of the room in m3 or ft3.
If we assume for sound systems:
1.
A low frequency limit of 80 Hz for speech systems.
2.
A low frequency limit of 30 Hz for music systems.
3.
An RT60 of 1.6 s approximates the decay time
expected for a minimum density sound field,
then a large room volume for speech becomes
approximately:
or
and for very wide range music:
or
Therefore, in this book a large room will be one
in which, for speech, the internal volume is
35,000ft3 or greater and, for very wide range music,
the internal volume is 250,000 ft3 or greater.
Since FL is frequency dependent, we can employ
our standard audio analysis technique. First divide
the audio spectrum into three decades on a linear
frequency scale so that we may treat the first decade
as a “small room” acoustic problem while
approaching the upper two decades as a “large
room” design problem.
Bolt, Beranek and Newman have long utilized an
almost identical equation with a K for US system of
11,250 which would, by conversion, be 1,893.14 for
the SI, see Fig. 12-1. Also, the equation originally
used in LEDE control room work yields almost
identical results in practical cases.
(12-2)
FL is a transition area and should be viewed as
such and not as a rigid fixed frequency. The critical
frequency ( fc) is synonymous with FL and both nota-
tions are used in small-room literature.
12.1.1 Use of the Sabinian Equations in Large 
Reverberant Spaces
Spaces that qualify as “large rooms” can effectively
utilize the myriad of equations based on the original
FL
K RT60
V
------------
=
V
K2RT60
FL
2
------------
=
2000
(
)2 1.6
80
(
)2
-------------
=
1000 m3
=
V
K2RT60
FL
2
------------
=
11,885
(
)2 1.6
80
(
)2
-------------
=
35,313 ft3
=
V
K2RT60
FL
2
------------
=
2000
(
)2 1.6
302
--------
⎝
⎠
⎛
⎞
=
7111 m3
=
Figure 12-1. Controllers of steady-state room acoustic
response. In physically small rooms fc moves to a
frequency of 250 Hz–500 Hz. (Courtesy Bolt, Beranek,
and Newman.)
V
K2RT60
FL
2
------------
=
11,885
(
)2 1.6
30
(
)2
-------------
=
251,116.84 ft3
=
FL
3
velocity of sound
(
)
×
Room's smallest dimension
-----------------------------------------------------------------
=
Normal
modes
Diffusion
Absorption
(Specular reflections)
Pressure
zone
Sound pressure level
f1/0/0
fc
4fc
Frequency
fc = 11,250
T
V
T = 0.049V
SaSAB

216
Chapter 12
assumptions of Sabine for his reverberation equa-
tions. In spaces exceeding these volumes and with
an RT60 of 1.6 s or greater, we will find mixing
homogeneous sound fields of sufficient density to
allow accurate engineering estimates of the level of
each.
Harvard University found in 1885 that its newly
completed Fogg Art Museum had severe acoustical
difficulties. President Eliot, head of the university,
turned to a young physics professor named Wallace
Clement Sabine with the request to “do something”
about the problem.
Sabine didn’t follow the practices of past genera-
tions and hang draperies, place carpets, etc., to
“deaden” such a “live” room. Instead he turned from
qualitative approaches in finding the solution to a
study of the problem on a quantitative basis.
Sabine had at his disposal a number of useful
tools to aid in the investigation of the problem. First,
there was the troubled lecture room in the Fogg Art
Museum. Second, there was nearby Saunders
Theater which was considered to have excellent
acoustics. Third, the constant-temperature room in
the subbasement of the Jefferson Physical Labora-
tory turned out to be a reverberation chamber.
Finally, he had a middle-of-the-road room consid-
ered acoustically tolerable, but not much more, in
the large lecture room, also in the Jefferson Physical
Laboratory building.
With these environments as laboratories, Sabine
used the seat cushions from Saunders Theater as his
portable absorption, organ pipes and a portable
windchest as his sound source, and a stopwatch and
his own remarkable hearing as his acoustic test
instruments.
After more than two years of intensive research
(he often taught classes during the day and did
research at night, existing on just a few hours of
sleep), Sabine not only had corrected the troubled
room by adding the correct amount of acoustical
absorption, but as it turned out, he had gathered the
raw data for the first important breakthrough in the
science of architectural acoustics.
One Saturday evening on the 29th of October,
1898, staring at some of his curves, Sabine called
out to his mother (who was living with him at the
time), “Mother, it’s a hyperbola!” This simple, but
inspired, observation took architectural acoustics out
of the dark ages of cut-and-try into the sunlight of
calculation and measurement.
The insight that came to Sabine, revealing the
fundamental relationship between the size of a room
and the absorption needed, resulted from his unbe-
lievably precise measurements coupled with his
intuitive genius. Thereafter, the reverberation time
of a room was calculable prior to construction.
In September, 1975, some 77 years later,
W. B. Joyce, in an article entitled, “Sabine’s Rever-
beration Time and Ergodic Auditoriums” in the
Journal of the Acoustical Society of America,
showed the relationship between the second law of
thermodynamics and Sabine’s equation. This
talented Bell Laboratories scientist derived Sabine’s
equation from a literature search that could have
been done at Sabine’s time since the necessary ther-
modynamic concepts were extant by 1895. See box.
In 1929, M. J. O. Strutt considered reverberation
by regarding it as a case of free damped vibration of
the volume of the air enclosed in a room (this was
before computers). The analysis involves the general
wave equations, with suitable boundary conditions
imposed. Strutt regarded as unsatisfactory the theo-
ries which dealt with the paths of separate sound rays
(geometric acoustics). The various Eigen Tones or
modes of the resonant vibration of the air columns in
the room appear in the analysis. This analysis
revealed Sabine’s law as an asymptotic property
toward which the reverberation tends, as the
Sabine’s Reverberation Time and Ergodic
Auditoriums
by Wm. B. Joyce
Published: J. Acoust. Soc. Am. Vol. 58, No. 3, pp. 
643-655, September 1975
Abstract: It is shown in geometrical acoustics that 
ergodic specular enclosures do exist and that in 
such auditoriums, but not in general, 4V/S’ is the 
exact mean directed path length (V is volume and 
S’ is any part of surface area S). Sabine’s expression 
is then demonstrated to yield the exact 
reverberation time, provided the enclosure is 
mixing 
and 
provided 
the 
inhomogeneous 
anisotropic surface absorptivity is sufficiently weak. 
It is further proven that the fundamental form of 
Sabine’s expression cannot be modified so as to 
become correct for large absorption. In an attempt 
to reassign credit and reconcile these results with 
influential findings to the contrary, a short historical 
account is added. Conditions imposed upon the 
surface reflectivity—whether the reflectivity be 
reversible (specular) or other or irreversible 
(statistical)—by the second law of thermodynamics 
and by the principle of detailed balance are 
evaluated. Extensions (e.g. mean length of curved 
paths in an ergodic auditorium with a thermal 
gradient) and other applications (electrolumine- 
scent diode design) are noted.

Large Room Acoustics
217
frequency of the (forcing) sound becomes infinitely
great compared with the wavelength of the sounds.
Later work at MIT by Philip Morse and Richard
Bolt led to the honest but humorous conclusion that
“The practical role of wave acoustics is that it can
indicate how to design an enclosure for which
geometrical acoustics and statistical acoustics are
valid, and in which there is no need of wave
acoustics.”
Fig. 12-2 illustrates the typical measurement
setup. Pink noise is emitted by the loudspeaker until
a steady state level is produced in the enclosure (i.e.,
the rate of acoustic energy emission is equal to the
the rate of acoustical energy absorption). Then the
amplifier is disconnected from the loudspeaker. The
microphone signal is fed through a bandpass filter
(typically either an octave or 1⁄3 octave), and the
decay rate is observed on the display unit (which
may be a digital meter, a graphic level recorder, or
an oscilloscope screen). When a graphic level
recorder is used, Fig. 12-3 shows how the trace
produced is analyzed.
12.1.2 The Sabine Equation
William Joyce at Bell Telephone Labs has demon-
strated that the Sabine Equation is fundamental to
the decay of energy in a light emitting diode just as
it is in an enclosed acoustic space.
The accuracy of this remarkable equation is
dependent upon a space being ergodic. There must
be a sufficient number of reflections, of a statistical
nature, that allow the concept of the mean free path
to be meaningful.
In physics, the mean free path is defined as:
(12-3)
where,
V is the volume of the space enclosed in some unit
of length, l 3,
S is the internal surface area in l2. This allows any
convenient system to be used, i.e., inches, feet,
yards, millimeters, centimeters, meters, etc.
The amount of time it takes a sound field to
decay to one-one-millionth of its original energy,
–60dB, after the sound source is turned off is called
the reverberation time, RT60.
The principle cause of the energy decay is the
amount of acoustic absorption available in sabin,
. Materials are rated in absorption units (dimen-
sionless 
) that range from 0.0 (totally reflective) to
1.0 (totally absorptive.) Absorption becomes dimen-
sional when multiplied by the area it is on which
makes 
 in l 2 (see Table 10.4 in Chapter 10 The
Acoustic Environment for absorption coefficients
commonly encountered).
We can write an equation that predicts the
number of reflections (N) that will occur during a
60dB decay
(12-4)
or
(12-5)
where,
 is the average absorption coefficient of all coeffi-
cients present in the enclosure:
(12-6)
Figure 12-2. Measuring the RT60 of an enclosure.
Figure 12-3. Chart recorder method of measuring RT60.
Bandpass
filter
1/1 or 1/3 octave
Display
Random
noise
generator
Loudspeaker
Termination
On-off
switch
Enclosed space
Microphone
Time increasing
Direction
of pen
20 dB
20 dB/0.7 s = 60 dB/x s
20x = 60 (0.7)
 x = 2.10 s
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7
Seconds
Direction of paper
MFP
4V
S
-------
=
Sa
a
Sa
N
6
10
(
) 1
a 
----
⎝
⎠
⎛
⎞
ln
=
e
10
(
)
ln
10
=
e6
10
(
)
ln
106
=
N
2.30
106
(
) 1
a 
----
⎝
⎠
⎛
⎞
log
=
10
(
)
ln
2.303
=
e
2.303
106
(
)
log
106
=
a
a
s1a1
s2a2
…
snan
+
+
+
ST
--------------------------------------------------------
=

218
Chapter 12
where,
s1,2,3… are the surfaces 1, 2, 3,
a1,2,3… are the coefficients of similarly numbered
areas,
ST is the total boundry surface area.
With these tools at hand it is possible to find the
number of reflections per second.
(12-7)
where,
c is the velocity of sound, light, etc., in l/s.
It then becomes possible to compute the reverbera-
tion time with the equation:
(12-8)
Defined dimensionally:
(12-9)
For those who work consistently in some
preferred dimensional system and prefer to elimi-
nate c from the equation
results in
(12-10)
Example:
Let:
V = 500,000 ft3.
S = 42,000 ft2.
 = 0.128.
then
12.1.3 Specific Versus Statistical
One hundred eight reflections allow a reasonable
statistical sample. When small absorptive spaces
such as control rooms in recording studios, small
classrooms, etc., are computed the inapplicability of
statistical equations becomes apparent because of
the low N. Such enclosures do indeed have a finite
number of reflections that are best handled by
careful Envelope Time Curve (ETC) analysis and
specific rather than statistical treatment of the indi-
cated surfaces.
12.1.4 Calculating the Rate of Decay of 
Reverberant Sound Energy
The classic Sabine equation is
(12-11)
Because the reverberation time in seconds is
calculated to be the time required for the sound
energy to decay to 1⁄1,000,000th (–60 dB) of its orig-
inal value prior to switching off the sound source,
we can further write decay rate in dB/s = 60dB ⁄RT60
and, because
(12-12)
we can derive the following direct equation for
decay rate in dB/s:
RPS
c
MFP
-------------
=
RT60
N
RPS
-----------
=
N Dimensionless
(
)
l s
⁄
4l3
l2
-------
--------
----------------------------------------------
s
=
4 2.303
(
)
106
(
)
log
55.26
=
RT60
55.26
Sa c
( )
--------------
=
55.26
1130
-------------
0.049
=
55.26
344.42
----------------
0.161
=
RT60
0.049V
Sa
-----------------    U.S. equation
=
RT60
0.161V
Sa
-----------------    SI equation 
=
a
MFP
4 500,000
(
)
42,500
---------------------------
=
47 ft
=
N
2.303
106
(
)
1
0.128
-------------  
⎝
⎠
⎛
⎞
log
=
108 reflections
=
RPS
1130
47
------------
=
24 reflections per second
=
RT60
108
24
---------
=
4.5 s
=
RT60
0.049V
Sa
-----------------
=
Sa
0.049V
-----------------
1
RT60
------------
=

Large Room Acoustics
219
(12-13)
For example, in a church that has an RT60 of
and a decay rate of
To check, we can take
12.1.5 Improved Reverberation Time 
Calculations
The works of Joyce and Gilbert have increased our
appreciation for the fundamental integrity of the orig-
inal Sabine equation when used in spaces where it
can properly be applied. Our work with the TEF
analysis process has confirmed that the simple equa-
tions that work so well in “live” rooms should simply
not be applied in any form in small dead rooms.
One of the confusions that can arise is that
absorption is useful for the control of specular
reflections in rooms where no real reverberant sound
field exists and application of the statistical formulas
is nonsensical. Indeed, application of absorption in
these cases is immediately audible, often dramati-
cally so, whereas massive absorption in large “live”
rooms that meet the classic criteria do indeed
provide a lowering of the statistical reverberant field
level but is a much more subtle audible affect. In the
“grey areas”, we find influences from both
approaches and care must be taken to use a suffi-
ciently conservative design approach that allows for
“worst case” possibilities.
It has been our experience that the majority of
listeners who declare a room as “live” or “dead” do
so on the basis of initial signal delay gap and the
level of the first reflections and not on the level of
the reverberant sound field.
Now that we can view instrumentally the density
and spectral uniformity, as well as the changes in
frequency with time exhibited by sound fields in
real spaces, the true cause and effect relationships
exerted by the boundary surfaces of a space will
become even more accessible than at present. One
aspect that is particularly interesting is the length of
time required to see the first effect of the presence of
absorption in a large hall, see Figs. 12-4A and
12-4B for two ETCs of before and after absorption.
12.1.6 Importance of Sabine
The work of Wallace Clement Sabine founded the
entire field of architectural acoustics and is funda-
mental to the successful interface of any electroa-
coustic system to the acoustic environment. A
partial list of present day equations directly based on
Sabine’s work is:
1.
Critical distance.
2.
Reverberation.
3.
Reverberant sound field.
4.
Transmission loss.
5.
Hopkins-Stryker and its many variations.
60Sa
0.049V
-----------------
60
RT60
------------
=
1224.5Sa
V
-----------------------
=
RT60
0.049 500,000
(
)
9800
--------------------------------------
=
2.5 s
=
dB/s
1224.5 9800
(
)
500,000
---------------------------------
=
24 dB/s
=
60
2.5
-------
24  dB/s
=
Figure 12-4. RT60 measurement made with and without
absorption.
6 dB
1–2 dB of absorption
0
360.5
ft
0
319
ms
A. With absorption curtain extended in an auditorium
(absorption present), 1 dB–2 dB of absorption is
very audible.
B. Auditorium with curtain retracted (without
absorption).
0
360.5
ft
0
319
ms

220
Chapter 12
6.
Articulation loss of consonants.
7.
Q relative to the adjustment of direct-to-rever-
berant ratios.
The genius of the man is apparent, important, and
yet relatively unheralded. Encyclopedias rarely
mention him. Outside of the field of architectural
acoustics, students fail to recognize his name.
Wallace Clement Sabine deserves our honored
respect and acknowledgment.
12.1.7 Limitations of All Acoustic Equations 
Based on Geometry and Statistics
It should always be considered that, insofar as the
reverberation formulas depend upon statistical aver-
ages, they presuppose a complete mixing of sound
in the room. In very absorptive rooms, the sound
dies away in a few reflections, and the statistical
basis of the formulas is weakened. In recent studies
done with time energy frequency analysis, typical
meeting rooms in hotels have been found in some
cases, RT60 = 0.5 s, to develop no reverberant sound
field, whereas in others, RT60 = 0.7 s, a field barely
appears.
Our experience with time-energy-frequency
measurements causes us to state unequivocally that
recording studio control rooms are not proper
subjects for use of classic statistical equations.
In very large rooms, such as the Astrodome and
the Superdome, because the sound cannot cross the
room many times during a measured reverberation
period of a few seconds, the validity of the formula
is affected.
12.2 Levels Defined: Sound Power Level (LW), 
Sound Intensity Level (LI), and Sound 
Pressure Level (LP)
12.2.1 Sound Power Level (LW)
LW is the total acoustic power level in dB radiated by
a sound source.
(12-14)
where,
Wa is the acoustic watts,
10-12 W is the specified reference.
For an output of 1.0 W we can write
This means that a device radiating a total
acoustic power of 1.0 W will have an LW = 120 dB
regardless of radius, r, from the source or how
confined a directivity factor, Q, happens to be.
12.2.2 Sound Intensity Level (LI)
If we imagine a sphere with a surface area A of
1.0 m2, the radius r becomes
The 1.0 W radiating from an omnidirectional
point source through a spherical surface area of
1.0 m2 would have a sound intensity level of
(12-15)
Which can again be written as
We would also find at the surface of our imagi-
nary sphere a sound intensity of 1 W ⁄m2.
12.2.3 Sound Pressure Level (LP)
The root mean square acoustic pressure is given by
where,
Ia is the acoustic intensity in W/m2,
LW
10
Wa
10 12
–
 W
--------------------
⎝
⎠
⎛
⎞
log
=
LW
10
Wa
(
)
log
120 dB
+
=
10
1.0  W
(
)
log
120 dB
+
=
120  dB
=
r
A
4π
------
=
0.282 m
=
LI
10
Wa
m2
-------
10 12
–
 W
m2
--------------------
--------------------
⎝
⎠
⎜
⎟
⎜
⎟
⎜
⎟
⎜
⎟
⎛
⎞
log
=
LI
10
Wa
m2
-------
⎝
⎠
⎛
⎞
120
+
log
=
10
1.0W
m2
-------------
⎝
⎠
⎛
⎞
120
+
log
=
120 dB
=
PRMS
Iaρc
=
1.0 W
m2
------- 400
(
)
=
20  Pa
=

Large Room Acoustics
221
ρc is the specific acoustic resistance of air. ρ is
expressed in kg/m3 and c is the sound speed in m/s.
ρc has a value of 400.
There is a sound pressure reference value of
20micropascals (μPa) = 0.00002 Pa.
or
and for 20 Pa
At a radius of 0.282 m, a sphere has a surface
area of 1.0  m2 and 1.0  acoustic watt radiating
through that surface area produces at that surface an
LW = 120 dB,
LI = 120 dB,
LP = 120 dB.
This means only that these three parameters are
numerically identical.
Next, imagine a hemisphere with a radius of
0.282 m. The source is radiating 1.0 acoustic watt;
therefore, the LW = 120 dB. The surface area is now
0.5 m2 and the 1.0 W now produces an intensity of
1.0 W/0.5 m2 or 2.0 W/m2. This results in LI = 123dB
and an LP = 123 dB. The difference between LI and
LW is called the directivity index, DI in dB.
The directivity factor, Q, describes the increase
in power per unit of area that results from confining
available power to a smaller area. The comparison is
between the Q confined area versus that over the
spherical power per unit of area. Today Qs of 50+
are available from devices that cover 1⁄50 of a
spherical surface, thus simultaneously achieving
controlled coverage of an audience area and
supplying that area with an LP that required 1⁄50 the
power an omnidirectional device would require for
the same LP, thus yielding a +17 dB advantage
(20log50 ⁄1 = 16.99 dB).
Finally, increase the radius of the original sphere
by a factor of 2 such that r = (2)(0.282) m.
The result in a surface area of 4 m2 and 1.0 acoustic
watt now produces:
LW = 120 dB.
LI = 114 dB.
LP = 114 dB.
Or for each doubling of distances we drop 6 dB
in level.
20log (D1 ⁄D2) = Change in level of LP
20log (0.282) – 20log (0.564) = −6.02 dB
The rate of change in level is a consequence of
the inverse square law that governs radiation from
point sources.
A given LW is independent of both distance and
area covered. We can state that LI and LP each vary
with both distance, r, and directivity, Q as:
10log Q or 20log r
LI or LP = LW + 10logQ
(12-16)
(12-17)
where,
r is greater than 0.282 m (0.925 ft).
As will be seen further on we can use these iden-
tities to predict efficiencies, power, and pressure
relationships.
12.3 Levels in Enclosed Spaces
When a loudspeaker radiates sound into an enclo-
sure, its acoustic performance as determined under
open air conditions is modified by the acoustic prop-
erties of the space, but the total power LW radiated is
essentially unchanged. When a sound source is
turned on in a room, the energy spreads from the
source and then strikes the various wall surfaces, S,
where it is partially absorbed, a, and partially
reflected 1 − a to other surfaces which, in turn,
absorb and reflect. This process continues until the
energy in the room reaches a steady value, i.e., when
the rate of energy absorption by the surfaces and in
LP (sound pressure level)
20
Prms
0.00002 Pa 
----------------------------
⎝
⎠
⎛
⎞
log
=
20
Prms
1  Pa 
------------
⎝
⎠
⎛
⎞
log
94  dB
+
Lp
20
20
(
)
94 dB
+
log
=
120  dB
=
10
DI
10
------  
⎝
⎠
⎛
⎞
Q
=
10
3.01
10
----------
⎝
⎠
⎛
⎞
2
=
A
4πr2
=
4π 2 0.2821
(
)
[
]2
=
4
=
 m2
LI  or LP
LW
20
r
0.282  m
-------------------
⎝
⎠
⎛
⎞
log
–
=

222
Chapter 12
the air becomes equal to the rate of energy emission
by the source.
This energy is made up of the total reverberant
energy, LR, assumed uniform in distribution, and the
total direct energy LD. This division is expressed as
 U.S.
(12-18)
and
 U.S.
(12-19)
Interestingly 
 considered as a radius to a
sphere suggests that the volume of such a sphere and
the room volume, for all rooms of reasonable
proportions, will be nearly equal, thus allowing a
simplification of terms. From these relatively simple
relationships it becomes evident that LW and 
determine the reverberant levels and that LW , Q, and
r2 determine the direct sound level at any given
position. In fact the design goal in most cases is to
insure that any listener receives at the least an
LD = LR and at the best that LD ≥ LR.
12.3.1 Hopkins-Stryker—US and SI
The interplay of directivity factor, Q, distance from
the sound source to the listener, D2, the total
acoustic absorption in the room, 
 and the
expected sound pressure level, Lp, at the listener, can
all be combined in a single equation called the
Hopkins-Stryker.
 US (12-20)
 SI
(12-21)
Fig. 12-5A illustrates the levels for the direct
sound pressure level, LD, with the distance, the
reverberant sound level, LR, and the total sound
level, LT , for a Q = 45, D2 from 10 ft to 1000 ft, a
total room absorption of 5000 ft2, and a sound power
level, Lp , of 105.6 dB.
Fig. 12-5B is a table of log multiplier and ratio
exponents for curves that are neither inverse square
law, or totally reverberant, but rather fall between
−2 dB per doubling of distance to −5  dB per
doubling of distance i.e., for 3 dB per doubling of
distance beyond Dc use:
or
Finally, Fig. 12-5C shows a fully implemented
set of modifiers and multipliers for LD, LT  ,
−2 dB ⁄doubling of distance, −3 dB/doubling of
distance, −4dB/doubling of distance, and
−5dB/doubling of distance.
Fig. 12-5C is the same case as Fig. 12-5A with
the modifiers added of N = 1.0, Me = 1.5, and
Ma = 5.0 where the Hopkins-Stryker equation
becomes
(12-22)
When knowledge of the dB per doubling of
distance has been ascertained either by experience
or by measurement, the appropriate multiplier or
exponents can be inserted into the calculation. Note
that these modifications apply only to distances
beyond critical distance, see vertical axis notation
on Fig. 12-5B.
For those who would like to use solid angle data
in place of Q, the Hopkins-Stryker becomes
(12-23)
where,
LT is the sound pressure level,
LW is the sound power level,
sr is the solid angle in steradians,
r is the distance in meters,
 is the total absorption in sabins meters squared.
Remember that the solid angle in steradians = 4π/Q.
12.3.2 Other Terms Derived from 
Hopkins-Stryker
For those unfamiliar with these terms, the following
definitions are useful.
(12-24)
(12-25)
LD
LW
10
Q
4πr2
-----------
⎝
⎠
⎛
⎞
10.5
+
log
+
=
LR
LW
10
4
Sa 
--------
⎝
⎠
⎛
⎞
10.5
+
log
+
=
4V S
⁄
Sa
Sa,
LP
LW
10
Q
4πD2
2
----------------
4
Sa
------
+
⎝
⎠
⎜
⎟
⎛
⎞
10.5
+
log
+
=
LP
LW
10
Q
4πD2
2
----------------
4
Sa
------
+
⎝
⎠
⎜
⎟
⎛
⎞
0.2
+
log
+
=
9.966
D2
log
D2
0.996
log
LP
LW
10
Q Me
(
)
4πD2
2
-----------------
4N
SaMa
---------------
+
10.5
+
log
+
=
LT
LW
10
1
sr
D2
2
×
--------------------
⎝
⎠
⎜
⎟
⎛
⎞
4
Sa 
--------
⎝
⎠
⎛
⎞
+
log
0.2
+
+
=
Sa
DI
10
4π
sr
------
⎝
⎠
⎛
⎞
log
=
sr
4π
Q
------
=

Large Room Acoustics
223
(12-26)
(12-27)
(12-28)
(12-29)
One advantage of using sr is that they can be
summed to obtain a total sr for two adjoining areas.
That this has been widely overlooked is apparent in
the book, Units, Dimensional Analysis and Physical
Similarity by D. S. Massey:
The magnitude of solid angle may be
related to that of plane angle to give the
dimensional formula (A2). However, as
the results seem to have no practical
use, we shall not discuss further the
dimensional formula of solid angle.
Figure 12-5A. MathCAD program of Hopkins-Stryker plot for system design parameters shown above.
LT
LR
LD
Q
4π
sr
------
=
Dc
0.5 Sa
sr
------
=
Radians
Degrees
π
180
---------
⎝
⎠
⎛
⎞
=
Degrees
Radians 180
π
---------
⎝
⎠
⎛
⎞
=

224
Chapter 12
It would seem that radar, sonar, and acoustics are
not practical applications, in this author’s mind. The
book, nevertheless, is excellent and worthy of study.
The direct sound level alone can be expressed as
 US
(12-30)
 SI
(12-31)
and the reverberant sound level, LR, from
 US
(12-32)
 SI
(12-33)
Finally, critical distance, Dc , is obtained from the
fact that when r = Dc
 both in US and SI
(12-34)
At Dc the two levels, LR and LD are equal; there-
fore LT will be +3 dB higher. For a sound system in
an enclosed space it is highly desirable to keep as
many listeners as possible at or closer to the sound
source than Dc.
Bringing the sound source closer to the listener
raises the LD and often, because of being physically
closer, inverse square law allows lower power, thus
lower LR. Also raising the directivity factor, Q, of
the sound source results in higher LD for lower
power also. Raising the number of sabins in the
space lowers LR.
The accuracy of these equations will get you into
the “ball park.” They will bring you into the right
order of magnitude. Ideally when the space already
exists, testing with a sound source of the indicated Q
allows much more exact numbers to be computed.
Prediction of sound levels outdoors and in very
small non-reverberant spaces will follow inverse
square law quite accurately.
Extremely large sporting arenas, domes, etc.,
have ls of such length as to again produce a low
number of reflections.
12.4 Differentiating Between Reverberant 
Level and Reverberation Time
Thanks to present day measurement techniques both
LT and LD are readily accessed.
When non-uniform reverberant sound fields are
encountered, measurements made at repeated
doubling of distance beyond critical distance, Dc,
allows accessing the Hopkins-Stryker modifier for
plotting level versus distance.
(12-35)
where,
Figure 12-5B. MathCAD program of Hopkins-Stryker
plot for system design parameters in Figure 5A.
Logarithm Modifiers and Exponents for use in 
Hopkins-Stryker Equations in 0.5 dB Steps for Changes 
in Level per Doubling of Distance
Example
For 3.5 dB change for each time the distance is doubled
11.62675log(2) = 3.5dB  or  10log(21.16267) = 3.5 dB
LD
LW
10
Q
4πr2
-----------
⎝
⎠
⎛
⎞
log
10.5
+
+
=
LD
LW
10
1
sr
(
) r2
(
)
-------------------
⎝
⎠
⎛
⎞
log
0.2
+
+
=
LR
LW
10
4
Sa 
--------
⎝
⎠
⎛
⎞
log
10.5
+
+
=
LR
LW
10
4
Sa 
--------
⎝
⎠
⎛
⎞
log
0.2
+
+
=
Q
4πDc
2
---------------
4
Sa
------
=
Dc
QSa
16π
-----------
=
0.141 QSa
=
0.5 Sa
sr
------
=
LP
LW
10
Q
4πDx
2
---------------
4
Sa
------
–
⎝
⎠
⎜
⎟
⎛
⎞
log
10
Dc
Dx
------
⎝
⎠
⎛
⎞
exp
⎝
⎠
⎛
⎞
K
+
⎝
⎠
⎛
⎞
log
+
+
=

Large Room Acoustics
225
,
LW is the sound power level in dB,
Dx is any distance l beyond Dc,
K = 10.5 US, 0.2 SI.
12.5 Evaluation of Signal-to-Noise Ratio, SNR
In my experience you can very seldom turn room
noise off, therefore the first measurements are those
of room noise levels at various positions with the
sound system on but inactive. Subsequent measure-
ments of total level, direct level, and reverberant
level can then be corrected for the noise level contri-
bution in those instances where the noise level
makes a significant contribution.
Having obtained LT, LD, and LR at any given
point, it becomes possible to separate the contribu-
tion of the noise level, LN, by using the measurement
of LT with the noise “on” and then with the noise
“off.” LT – LN is the signal-to-noise ratio expressed
in dB. Noise “on” refers to lighting, HVAC, and
other man-made noise sources.
Figure 12-5C. MathCAD program depicting Hopkins-Stryker plots for varying values of attenuation with distance 
doubling for system design parameters in Figure 12-5B.
LT
Dc
LD
LR
−2 dB/doubling
−3 dB/doubling
−4 dB/doubling
−5 dB/doubling
exp
dB/Doubling of distance
2
log
10
-----------
-----------------------------------------------------------
⎝
⎠
⎜
⎟
⎜
⎟
⎛
⎞
=

226
Chapter 12
In listening to an auditorium where measure-
ments are to be made, always attempt an aural esti-
mate of each of these levels at differing locations at
both less than the expected Dc and well beyond Dc.
Good sound system design practice tries to mini-
mize the reverberant level while recognizing that
changing the reverberation time is a room treatment
problem. When a 25 dB SNR at 2 kHz is unattain-
able, recommend the job to a competitor. (See
Chapter 11 Audio and Acoustic Measurements, for
detailed SNR analysis.)
12.6 Analyzing Reflections and Their Paths
In sound system analysis, sets of linearly spaced
notches and peaks in the amplitude response are
called “comb filters.” These are the result of a
reflection or reflections converging with the direct
sound from the desired sound source. Even a low
resolution 1⁄3 octave real-time analyzer can see the
lower frequency notch. The reflective path distance,
rp, can be ascertained from:
(12-36)
where,
c is the velocity of sound. The velocity unit, l ⁄s, can
be in ft, inches, mm, m, etc. The reflection
distance is in the units chosen,
Fn is the frequency of the first notch.
Because comb filters are spaced linearly, NRn or
NFp (first peak frequency), this allows the computa-
tion of all higher frequency comb filters. For
example, a reflection 0.5 mm such as the spacing of
a Pressure Zone Microphone, PZM, capsule above
its plate results in a first notch at
which could be disregarded in normal use. If, on the
other hand, a low pass filter at 20 kHz, for anti-
aliasing purposes, could be begun acoustically near
the bandpass by
Figs. 12-6A and 12-6B illustrate the usefulness of
comb filters as well as how to analyze harmful ones.
12.6.1 Sound System Near Regeneration
A sound system operating too near positive acoustic
feedback amplifies the room’s natural reverberation
time by many times (as many as 4 to 5 times). Be
sure that your subjective judgment of the space has
not been influenced by the presence of a malfunc-
tioning sound system.
See Fig. 12-7 from the work of William Snow of
Bell Labs. Note that the decay rate changes from
92dB/s to 22 dB/s as the sound system is brought
near sing point (feedback), a 4.2 magnification
factor.
12.6.2 How Harmful Is High RT60?
How harmful is a high RT60? In a truly diffuse
acoustic field it is surprisingly not harmful to “live”
speech until reverberation times around 3 s to 4 s at
2 kHz are reached. The trouble in many “rever-
berant” spaces is that it is focused energy returns
over long path lengths that are the culprit and not the
length of time they take to decay. This can usually
be demonstrated by using a large sheet of Sonex
(4ft × 5 ft) and circling the listener while a talker
speaks from the podium. When the Sonex passes
between the focused energy and the listener, speech
intelligibility will return. Remove the Sonex and the
speech will again be interfered with. By noting the
position of the Sonex relative to the listener and the
room surfaces, you can usually detect the offending
area. Cupping your ears and moving around the
room surfaces will also tell much about reflections
in the room.
Troy Savings Bank Concert Hall has a 3+ second
reverberation time (empty), yet normal conversa-
tion level can be heard clearly from the stage at the
back of the upper balcony. Troy Concert Hall has no
absorption in a conventional sense (all wood) but is
very diffuse.
12.6.3 Effect of Reverberation on Intelligibility
The effect of reverberations on intelligibility is far
less than single late high level reflections, inade-
quate SNR, or comb filters generated by sources
within one foot or less of the primary source.
rp
0.5c
Fn
----------
=
Fn
0.5c
diff
----------
=
0.5
344
103
×
(
)
×
0.5 mm
------------------------------------------
=
344,420 Hz
=
Spacing
0.5c
diff
----------
=
0.5
13,560
(
)
×
20,000 Hz
-----------------------------------
=
0.34 inches
=

Large Room Acoustics
227
Fig. 12-8 shows three highly audible late reflec-
tions (over 100 ms). We were told that this space
was so reverberant that it was difficult to use the
reinforcement system. Yet, when we put Sonex
around the person in this seat and isolated him from
the reflections, one could understand clearly the
unaided voice from the stage. Without the Sonex,
speech was unintelligible.
12.6.4 Variations in the Measurement of 
Reverberation
TEF analysis has revealed some unexpected details
in the measurement of reverberation time. Anyone
working with high Q transducers (Qs of 50+) has
subjectively experienced the apparent change in
RT60. This has always been explained as due to a
Figure 12-6. Reflections and comb filters.
A. MathCAD program showing reflections and comb filter equations.
d1
Microphone
Loudspeaker
h
h
Reflection
d1
2 + 2h2  =  d2
B. How to determine path lengths. 

228
Chapter 12
lower reverberant sound field and consequently
what decay of energy was present did not last as
long before being masked by the ambient noise
floor. Various orientations of the sound source
reveal that the way a high Q source should be
oriented to cover an audience does not excite as
many normal room modes as does a lower Q device.
Thus it would appear from the evidence available
that:
1.
The classic method is flawed when being Q
dependent.
2.
The higher Q sources literally do not excite all
the room modes.
3.
We possibly need a new, as yet undetermined,
method of analyzing the envelope time behavior
of large rooms.
Fig. 12-9 shows ETCs of the same room excited
from the same source location by three different
sources. Source number one has a Q = 1. Source
number two has a Q = 5. Source number three has a
Q = 50.
It cannot be overemphasized that analysis reveals
that a large number of smaller volume, acoustically
absorptive rooms do not develop a reverberant
sound field that rises above the ambient noise floor
normally present in a space. In such spaces statis-
tical analysis is an exercise in futility. Study of the
fine structure of the early reflection, LRE, is of
benefit and leads directly to improved performance.
To obtain accurate information about the pres-
ence or lack of a reverberant sound field, both suffi-
cient distance from the source must be established
and sufficient time must be provided for it to
develop, see Fig. 12-10.
12.7 Critical Distance
One of the most important concepts regarding the
statistical acoustic space is Dc. First, we assume that
Dc is within 3 dB of the maximum acoustic separa-
tion between the microphones in a given room.
Again, if we have a microphone in a steady rever-
berant field, we could wander all over the rever-
berant area without encountering a sudden change in
level that can cause feedback. In fact, we will make
use of Dc in determining the following limits in our
design of sound systems:
1.
The loudspeaker and the microphone should be
at least as far apart as Dc. D1 = Dc < 45 ft, where
D1 is the distance between the loudspeaker and
the microphone.
2.
In rooms with a reverberation time exceeding
1.6 s you will not be able to have any listener
beyond 3.16 Dc. As the time raises more, this
multiplier will become even lower. (Discussed
in detail in Chapter 14 Designing for Acoustic
Gain. Also see Fig. 12-5C.)
Figure 12-7. Sound system near feedback. (Courtesy
William Snow.)
Figure 12-8. Three audible late reflections that seriously
affected articulation.
2.2 dB/s
92 dB/s
Reverberation time = 0.65 s
Handclaps near sing point
6 dB
LD
ITD
Three audible
reflections
Horizontal: 39.55 – 239.77 ft
Scale: 5.4742E +01 ft/in
Source Number
Q
D1 (10log Q)
1
1.0
0 dB
2
5.0
7 dB
3
50.0
17 dB

Large Room Acoustics
229
12.7.1 Q Versus 
 for Controlling Dc
In examining the equation for Dc, it is apparent that
both Q and 
 have the same relative weight. This
means that in a space that requires a doubling of 
to be acceptable, we could just as well leave 
alone and double Q. In typical church systems, for
example, the doubling of 
 can easily cost
$100,000 and change the entire visual appearance of
the structure as well as making the music director
very unhappy. Doubling Q usually costs under
$10,000. While the array may be huge, it does
occupy only one spot and not whole walls and ceil-
ings. This is a relatively new concept and not widely
practiced, though certain acoustic consultants have
effectively used the general idea for years. We can
now enumerate a few of the factors proceeding from
the existence of Dc in a space:
1.
Dc determines the maximum acoustic separa-
tion hence maximum acoustic gain.
2.
Dc determines the ratio of direct-to-reverberant
sound.
3.
Dc determines the required directivity of the
loudspeaker in an already existing room.
4.
Dc can determine the required room characteris-
tics in a space being planned if a chosen loud-
speaker is desired.
12.7.2 Dc Multipliers and Dividers
Just as N operates as a Dc divider, there are factors
that can operate as Dc multipliers. First, let’s take an
extreme case in which the C∠ contains all the useful
energy. It is aimed at an audience area that is 100%
absorptive as shown in Fig. 12-11A. For example, if
the loudspeaker has an axial Q of 5, the room has an
Figure 12-9. ETCs made in a room excited from the
same source location by three different sources.
6 dB
A. Q = 1.
B. Q = 5.
( Note the drop in reverberant level over Q = 1).
C. Q = 50 with a substantial drop in level
of the reverberant field.
12 dB
18 dB
Figure 12-10. Definition of sound field levels vs. time.
Early reflections
LRE
Direct sound
LD
Reverberation LR
dB
TREF     T0           T1                           TN                         T2
Time
T0 − TREF = Signal travel time to observer (D0)
T1 − T0 = Initial Time Delay (ITD) gap
TN − TREF = Natural room delay
T2 − T1 = 3-D measurement limits (variable from TREF to T2)
Ambient
Noise level
LAMB
Sa
Sa
Sa
Sa
Sa

230
Chapter 12
 of 0.01, and the audience area has an 
 of 1, the
apparent Q would be
(12-37)
Even if the room were highly reverberant, this
loudspeaker would cause no reverberation.
A more typical case is shown in Fig. 12-11B. In
this case the loudspeaker still has an axial Q of 5,
the room has an 
 of 0.16, and the audience area
has an 
 of 0.32. The apparent Q would be
12.7.3 Theory of Ma
The Dc modifier (Ma) results from the removal of
additional energy from the signal emitted upon its
first encounter with a selected absorbent boundary
surface than would have been expected, had the
same energy first encountered a surface possessing
the average absorption coefficient of the space as a
whole.
In the limiting case, if the area the sound energy
first encountered were 100% absorptive and if none
of the energy encountered any other surface, there
would be no reverberation. Thus, such an Ma makes
the source act as if it were in a free field. It would
appear that Ma is only of interest for some very high
Q devices.
Consider what is actually happening at a
listener’s ears. As Ma increases the ratio of
direct-to-reverberant sound heard increases if the
listener is situated on the absorbing surface that the
energy first encounters. The main purpose of
increasing Q or Ma is to increase this ratio at the
listeners ears.
Another parameter available to us that allows us
to accomplish the same results is to move the loud-
speaker closer to the listener. If we move a loud-
speaker of any given Q in a room of any given Ma
to half its former distance from the listener’s ears,
we raise the direct-to-reverberant ratio by 6 dB. This
could also be accomplished by leaving the loud-
speaker at its original position and raising its Q by a
factor of four.
The relation of the loudspeaker’s angular
discrimination relative to a microphone’s angular
discrimination is referred to as an electroacoustic
modifier of Dc (Me) and is discussed in detail in
Chapter 18 Loudspeakers and Loudspeaker Arrays
which discusses the planning of loudspeaker arrays
and acoustic gain.
Additionally, a tilted rear wall may raise the
apparent Q at the rear seats in an auditorium even
more. When you measure Q in a room with a cali-
brated loudspeaker, the difference between what you
calculate and the calibration includes all the multi-
pliers and dividers. Therefore, such a calibrated test
source allows you to do several things:
1.
Measure the room absorption, 
, by the rever-
beration time method and calculation. Then
measure the apparent Q. This will include all
multipliers and dividers. By changing such vari-
ables as position of materials and position of
sources, you can investigate the effect of such
phenomena.
2.
Measure the room absorption, 
, by the crit-
ical-distance method using the Q of your cali-
brated sources in your calculations. By using
this room absorption, which includes all the
multipliers and dividers, you can accurately
measure the axial Q of unknown loudspeakers.
12.7.4 The Effect of the N Factor
N is the ratio of the acoustic power produced by all
loudspeakers to the acoustic power produced by the
loudspeaker or loudspeaker groups providing the
Figure 12-11. Dc multiplier, Ma, illustrated.
a
a
QApp
QAxial
1
a of total room
–
1
a of audience area 
–
-------------------------------------------------------
⎝
⎠
⎛
⎞
=
5 1
0.01
–
1
1
–
-------------------
⎝
⎠
⎛
⎞
=
∞
=
100% absorptive
All energy in this beam
A. No reverberation.
B. More typical case.
a
a
QApp
QAxial
1
a of total room
–
1
a of audience area 
–
-------------------------------------------------------
⎝
⎠
⎛
⎞
=
5 1
0.16
–
1
0.32 
–
---------------------
⎝
⎠
⎛
⎞
=
6.18
=
Sa
Sa

Large Room Acoustics
231
listener with direct sounds. In its simplest form as
shown in Fig. 12-12, two loudspeakers are
furnishing direct sound to the listener and there are
four loudspeakers producing equal acoustic power.
Therefore
To demonstrate the “N ” effect, sound fields were
compared using a loudspeaker on stage as a substi-
tute for a talker into the sound system microphone,
Figs. 12-13,12-14 and 12-15.
1.
Loudspeaker on stage only (a talker from the
stage).
2.
Loudspeaker on stage plus a center cluster
(Q = 11).
3.
Loudspeaker on stage plus two low-Q stereo
loudspeakers (Q = 2).
4.
All loudspeakers on at the same time.
The effects of the complex N factor are clearly
evident. Some interesting effects from discrete early
reflections that affect the ratio of direct (defined
here as the first 50 ms) sound level versus rever-
berant sound level are also apparent. The effect of N
is a 10log function. If all four sources developed
equal acoustic power then the expected deterioration
would be 10log 5 ≈ 7 dB.
This rule follows within a few decibels at all
sampled locations, see Table 12-1.
12.7.5 Factors to Watch for in Rooms
The following factors can be serious trouble for the
sound system if they are not properly controlled:
Figure 12-12. Visualization of N.
N
Total number of loudspeakers
Number of loudspeakers producing
direct sound to the listener
------------------------------------------------------------------------------------
=
2
=
Direct to reverberant ratio = 17 dB
Direct to reverberant ratio = 17 dB
Direct to reverberant ratio = 14 dB
N = 1
N = 1
N = 2
Table 12-1. Summary of Direct to Reverberant Ratios
Row
Stage
Center
Stereo
All
1
14
6
4
4
6
14
7
3
3
11
13
5
5
4
16
12
4
5
3
21
10
9
0
4
26
9
6
4
3
31
8
4
1
1
Direct = 0–50 ms
Reverberant = 50 ms–444 ms
Figure 12-13. Measurement parameters for sound 
system study in Fig. 12-14
Microphone
On stage
4 ft 1 in
Sound
system
Center
Left
Right
Microphone
B&K SLM
Input
TEF
analyzer
Test setup.
Test signal output
Measurement parameters.
1. Loudspeaker on stage only
2. 1 + center cluster
3. 1 + L & R stereo
4. 1 + 2 + 3
Frequency range: 1500 Hz–2400 Hz
Time span: 444 ms with 10 ms offset (10 ms–454 ms)
Sweep rate: 200 Hz
Single pole integration: 5 ms
Microphone locations: Rows 1, 6, 11, 16, 21, 31 (last)
Center: 2 Renkus Heinz GBH1250-9 83° x 50°; Q=11
L & R: Bes Q = 2
1
2
3
4

232
Chapter 12
Figure 12-14. Complete study of a sound system where the direct-to-reverberant ratio is degraded as each loud-
speaker is added. Prepared by Rollins Brook of BBN.
Row 1
Row 6
Row 11
Row 16
Row 21
6 dB
6 dB
6 dB
6 dB
6 dB
6 dB
6 dB
6 dB
6 dB
6 dB
6 dB
6 dB
6 dB
6 dB
6 dB
6 dB
6 dB
6 dB
6 dB
6 dB
Direct to reverberant ratio: 14.32 dB 
Direct to reverberant ratio: 5.95 dB 
Direct to reverberant ratio: 4.13 dB
Direct to reverberant ratio: 4.08 dB
Direct to reverberant ratio: 3.49 dB
Direct to reverberant ratio: 3.39 dB
Direct to reverberant ratio: 7.15 dB
Direct to reverberant ratio: 14.40 dB
Direct to reverberant ratio: 13.31 dB
Direct to reverberant ratio: 5.49 dB
Direct to reverberant ratio: 4.74 dB
Direct to reverberant ratio: 4.06 dB
Direct to reverberant ratio: 2.73 dB
Direct to reverberant ratio: 4.96 dB
Direct to reverberant ratio: 4.03 dB
Direct to reverberant ratio: 12.25 dB
Direct to reverberant ratio: 10.24 dB
Direct to reverberant ratio: 8.83 dB
Direct to reverberant ratio: 0.03 dB
Direct to reverberant ratio: 4.31 dB
1
2
3
1
2
3
4
4
2
3
4
4
3
2
1
1
1
2
3
4

Large Room Acoustics
233
1.
Curved surfaces, especially concave curved
surfaces.
2.
Absolutely parallel walls. Such walls cause
flutter-echo. A splay of 1 inch per foot will avoid
this problem.
3.
Absorption on the ceiling. Unless the ceiling is
very high (over 60 ft), the placement of absorp-
tion on it means the sound system has lost some
useful reflecting surfaces. Absorption belongs
on rear walls (large spaces only), rear ceilings,
in the seats, etc.
4.
Potential ambient noise sources—air handlers,
unenclosed machinery, etc.
5.
Extra wide or round audience seating.
12.8 Conclusion
The meaningful use of acoustical absorption is not
limited to its statistical application. Indeed sound
systems are more often installed in spaces where the
statistical equations are invalid than in spaces where
they are valid.
In semireverberant spaces and in very “dead”
spaces the use of absorption to control discrete spec-
ular reflections is quite valid in spite of the applica-
tion of the material having no real meaning in a
statistical sense. Even in spaces where the statistical
equations are valid, intelligibility can be, and often
is, degraded by a specular reflection which must, of
course, be isolated and corrected directly, not statis-
tically. Therefore, as we proceed into Chapter 13
Small Room Acoustics, it is well to bear in mind that
many “large rooms” have some small room proper-
ties at certain frequencies, especially with regard to
specular reflections.
Bibliography
D. Davis. “Contemporary Electro-Acoustic Investigations,” Syn-Aud-Con Tech Topics, Vol. 7, No. 11 (1980).
_______. “Uses, Abuses, and Misuses of the Critical Distance Concept,” Syn-Aud-Con Tech Topics, Vol. 7,
No. 12, (1980).
D. Davis and C. Davis, “What Reverberation is and What it is Not,” Syn-Aud-Con Tech Topics, Vol. 12, No.
13 (1985).
_______. “Sabine’s Reverberation Time and Ergodic Auditorium,” J. Acousti. Soc. Am., Vol. 58 (1975), pp.
643-655.
Figure 12-14. (cont.) Complete study of a sound system where the direct-to-reverberant ratio is degraded as each 
loudspeaker is added. Prepared by Rollins Brook of BBN.
6 dB
6 dB
6 dB
6 dB
1
2
3
4
6 dB
6 dB
6 dB
6 dB
1
2
3
4
Row 26
Row 31
Direct to reverberant ratio: 8.55 dB 
Direct to reverberant ratio: 6.17 dB 
Direct to reverberant ratio: 4.17 dB
Direct to reverberant ratio: 3.31 dB
Direct to reverberant ratio: 7.51 dB
Direct to reverberant ratio: 4.29 dB
Direct to reverberant ratio: 0.87 dB
Direct to reverberant ratio: 1.17 dB

234
Chapter 12
W. B. Joyce. “Power Series for the Reverberation Time.” Paper presented at 97th Convention of the Acous-
tical Society of America, Cambridge, MA (June 13, 1979).
D. L. Klepper. “Sound Systems in Reverberant Rooms for Worship,” J. Audio Eng. Soc., Vol. 18 (Aug. 1970).
_______. “Improved Reverberation Time Calculations,” Syn-Aud-Con Tech Topics, Vol. 6, No. 14 (1979).
R. F. Norris. “Appendix II: A Discussion of the True Coefficient of Sound Absorption—A Derivation of the
Reverberation Formula,” Architectural Acoustics, pp. 603-665. New York: Wiley, 1932.
B. Rayleigh. The Theory of Sound, Vols. I and II, 2nd ed. New York: Dover, 1945.
W. C. Sabine. Collected Papers on Acoustics, Cambridge, MA: Harvard Univ. Press, 1922.
M. R. Schroeder. “Computers in Acoustics: Symbiosis of an Old Science and a New Tool,” J. Acoust. Soc.
Am., Vol. 45, No. 5 (1969).
R. S. Shankland. “Acoustics of Greek Theaters,” Physics Today (Oct. 1973), pp. 30-35.
William B. Snow. “Frequency Characteristics of a Sound Reinforcing System,” J. Acoust. Soc. Am. (April
1955).

Chapter 13
Small Room Acoustics
by Don Davis
235
13.1 Non-Statistical Spaces  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 237
13.2 Small Room Acoustical Parameters . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 238
13.3 Small Room Reverberation Times . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 238
13.4 Small Room Resonances  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 239
13.5 Modes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 239
Damped and Undamped Modes  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 239
Modal Decay Rates  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 239
13.6 What Is an Eigen Mode?  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 239
Normal Modes Defined . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 240
13.7 Small Room Geometry . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 240
Desirable Room Ratios  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 240
13.8 The Initial Signal Delay Gap (ISD)  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 240
Selecting an Initial Signal Delay Gap (ISD)  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 241
13.9 Reflections . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 242
Useful Definitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 242
13.10 Reflection Free Zone  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 244
Development of the Reflection Zone  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 244
13.11 Diffusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 245
Quadratic Residue Diffusors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 248
13.12 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 248
Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 248


Small Room Acoustics
237
13.1 Non-Statistical Spaces
Sound systems are more frequently installed in
spaces where the statistical equations are invalid
than in spaces where they are valid. Consequently,
the meaningful use of acoustic absorption is not
limited to its statistical application. We use absorp-
tion to control discrete specular reflections in semi-
reverberant and very dead spaces in spite of the fact
that the material has no statistical meaning. Even in
spaces where the statistical equations are valid,
intelligibility can be degraded by a specular reflec-
tion that must be isolated and corrected directly, not
statistically. Therefore, as we examine the properties
of small-room acoustics bear in mind that many
large rooms have small room properties at certain
frequencies, especially with regard to specular
reflections. The “acoustical” size of a room is a
frequency dependent phenomenon.
We are dealing here with room modes rather than
a statistical reverberant sound field. One glance at
the illustrations of the 3-D TEF plots of the reflected
sound in an acoustically “small” room and a “large”
room reveals the dramatic differences in the energy
density with time, see Fig. 13-1.
How many reflections can occur in such a small
space in 0.1 s?
(13-1)
In 0.1 s the sound travels 0.1 s (1130 ft/s) = 113 ft so
the number of reflections is
MFP
4V
S
-------
=
4 2288  ft2
(
)
672  ft2
----------------------------
=
16 ft
=
Figure 13-1. Proof that there is a fundamental difference between small and large reverberant spaces.
A. ETC of a small room showing lack of a
dense field of reflections. After 150,000 Ms
150 ms or 150 ft, all reflections have died
out. (Courtesy Charles Bilello.)
B. 3-D of same room without a reverberant sound
field but with room modes. (Courtesy Charles Bilello.)
C. ETC of a large room where a sound field
is still present at 1,134 ms or approximately
1000 ft. (Courtesy Ruth Eckerd Hall.)
D. 3-D of a large concert hall with a good
reverberant field.

238
Chapter 13
Obviously this does not comprise a mixing,
homogeneous, statistical reverberant sound field and
indeed the illustrations demonstrate this quite effec-
tively. fc is the acoustic juncture between large and
small rooms. fc coincides with the dimension of the
room equal to the lowest wavelength that can fully
develop across that dimension. In physically small
rooms, fc can be as high as 500 Hz, whereas it falls
below 30  Hz in physically large rooms. Bolt,
Beranek and Newman developed an important chart
that it calls controllers of steady-state room acoustic
response, Fig. 13-2.
The frequency dependency of the pressure zone,
the modal zone, the diffusion zone, and the specular
reflection zone determine, how room treatment is
used. In rooms that are both physically and acousti-
cally small, the pressure zone may be useful to
nearly 100 Hz. Diaphragmatic absorbers are useful
from 80 Hz to perhaps 500 Hz, whereas quadratic
residue diffusors are useful from 500 Hz to 2000 Hz.
Above 2000 Hz discrete reflections must be specifi-
cally controlled. Application of a good technique at
an incorrect frequency is as disastrous as choosing
the wrong technique.
13.2 Small Room Acoustical Parameters
It is rare to need to reinforce in these small spaces as
even a weak voice can carry 12 to 20 ft. Teleconfer-
encing may change this but primarily even in small
meeting rooms with teleconferencing “soft
switching” is employed, making the system into
essentially a reproduction rather than a reinforce-
ment system. Because of this, looking at these small
rooms in terms of their use by live talkers (Q = 2.5
in the articulation frequency region) is a good
starting point for designers. Free field equations plus
identification and tracking of early reflections are
usually the total environmental analysis required in
terms of the usable sound field. Ambient noise level,
room geometry, and any unusual modifiers (i.e., a
totally absorptive rear wall) receive the usual
consideration.
13.3 Small Room Reverberation Times
To quote the late Ted Schultz (formerly of BB&N):
In a large room, if one has a sound
source whose power output is known,
one can determine the total amount of
absorption in the room by measuring the
average pressure throughout the room.
This total absorption can then be used to
calculate the reverberation time from
the Sabine formula. This method fails
badly in a small room, however, where a
large part of the spectrum of interest lies
in a frequency range where the reso-
nant modes of the room do not overlap
but may be isolated…. In this case the
microphone, instead of responding to a
random sound field (as required for the
validity of the theory on which these
methods depend), will delineate a
transfer function of the room…. It does
not provide a valid measurement of the
reverberation time in the room.*
What is often overlooked in the attempted
measurement of RT60 in small rooms is that the defi-
nition of RT60 has two parts, the first of which is
unfortunately commonly overlooked.
1.
RT60 is the measurement of the decay time of a
well-mixed reverberant sound field well beyond
Dc.
2.
RT60 is the time in seconds for the reverberant
sound field to decay 60  dB after the sound
source is shut off.
Since, in small rooms, there is no Dc, no
well-mixed sound field, hence, no reverberation but
merely a series of early reflected energy, the
Figure 13-2. Controllers of steady-state room acoustic
response. (Courtesy Bolt, Beranek, and Newman.)
No of reflections
Distance the sound travels
MFP
---------------------------------------------------------------
=
113  ft
16 ft
--------------
=
7
=
Normal
Modes
Diffusion
Absorption
(Specular
reflections)
Frequency
Pressure
zone
f 1/0/0
fc
4fc
Sound pressure level
fc = 11,250 T
V
T =
0.049 V
SaSab
*T. Schultz, ASA unpublished paper, 1984.

Small Room Acoustics
239
measurement of RT60 becomes meaningless in such
environments.
What becomes most meaningful is the control of
the early reflections because there is no reverbera-
tion to mask them.
13.4 Small Room Resonances
Many of us have listened in small rooms to the low
frequency resonances that occur when one of the
dimensions of the room supports a particular
frequency like a “tuned” tube. Fig. 13-3A is such a
resonance (about 125 Hz). Fig. 13-3B is the same
measurement made after the construction of a
diaphragmatic absorber.
13.5 Modes
13.5.1 Damped and Undamped Modes
In Fig. 13-4, the effect of “undamped” modes are
plotted, as a decay time, for a small broadcast
studio. The damping is provided by diaphragmatic
absorption at the lower frequencies. Such low
frequency absorption (the flexing of panels at the
low frequencies passing the energy from the small
room to a calculated cavity) not only reduces the
peak amplitude of the mode but broadens its band-
width (lowers its resonant Q).
13.5.2 Modal Decay Rates
Fundamental point: modal decay rates are not rever-
beration. Reverberation is “the time in seconds that
it takes a diffuse sound field, well beyond a real crit-
ical distance, to lower in level by 60 dB when the
sound source is turned off.” Modal decay rates are
dB-per-second (dB/s) rate of decay for a specific
modal frequency.
Eigen Modes are sometimes referred to as “Eigen
Tones” which has led some users in the United
States to regard them as “Eigen Frequencies.” This
is a dangerous misconception inasmuch as they are
dependent upon wavelength and as the velocity of
sound varies as the temperature in the space, Eigen
Modes shift in apparent frequency in order to
maintain the same wavelength relationship with the
boundary surfaces. A more correct English transla-
tion would be “Eigen Wavelengths.”
13.6 What Is an Eigen Mode?
An Eigen Mode is the European name for a standing
wave. Standing waves are dependent upon the
Figure 13-3. Small broadcast control room. (Courtesy
Doug Jones and WFMT.)
Figure 13-4. Controlling normal mode damping and
bandwidth.
A. Resonance at 125 Hz
B. After construction of a Helmholtz resonator
10                     100                     1k                  10k
Frequency–Hz
Reverberation time–s
32
28
24
20
16
12
8
4
0
12
3

240
Chapter 13
internal dimensions of an enclosure. The first mode
will be found at
(13-2)
where,
fo is the frequency in Hz of the first mode,
λ is the wavelength of the frequency and is equal to
twice the longest dimension of the enclosure,
c is the velocity of sound in the air.
See Figs. 13-5 through 13-7 for standing waves.
13.6.1 Normal Modes Defined
Axial modes. in which the component waves move
parallel to an axis (one dimensional), the (Nx, 0, 0),
(0, Ny , 0), and (0, 0, Nz ) modes of vibration.
Tangential modes. in which the component waves
are tangential to one pair of surfaces, but are oblique
to the other two pairs (two dimensional), the (Nx, Ny ,
0), (Nx, 0, Nz) and (0, Ny , Nz) modes of vibration.
Oblique modes. in which the component waves are
oblique to all three pairs of the walls (three dimen-
sional), the (Nx, Ny , Nz) modes of vibration.
Plot axial, tangential, and oblique modes indepen-
dently on three lines, Fig. 13-8.
13.7 Small Room Geometry
13.7.1 Desirable Room Ratios
This might more meaningfully read “Undesirable
Room Ratios.” Figs. 13-9 and 13-10 show, within
the enclosed curve, the ratios that have been found
to be acceptable. Here the criterion is simply to
avoid falling outside the enclosed area in your basic
room dimensional ratios.
13.8 The Initial Signal Delay Gap (ISD)
The initial signal delay gap is a fundamental room
parameter. It was first clearly identified and
described by Leo J. Beranek. This “gap” is defined
as the time between the arrival of the direct sound,
LD, at a listener’s ears and the arrival of the first
significant reflection. “Significant” is intended to
mean the first reflection whose level approximates
that of the peak of the exponentially growing and
decaying reverberant sound field. Since in a small
room we don’t have a reverberant sound field as
defined in the classic sense, we look for the first
reflection within 6 dB of the highest level reflection.
In small rooms, the ISD is normally quite short,
on the order of 1 to 5 ms. In a special design of
control rooms for monitoring recording studios, a
principle called “Live End Dead End,” LEDE, is
used that allows ISDs of from 10 to 20 ms to be
developed in rooms with dimensions as small as
2000 ft3. Before the use of the TEF analyzer during
the building of LEDE rooms, the front half of the
room was made as absorptive as possible (only the
diffusion and spectral frequencies are necessary)
and the other half (the half to the rear of the listener)
was (and still is) made as reflective and diffusive
(highly important and often overlooked) as possible.
It’s in the reflective half that a thorough plotting of
reflections becomes a necessity. See Table 13-1 for
Figure 13-5. Generating standing waves.
Figure 13-6. Normal modes in a rectangular room
where the Eigen Tones are generated by standing
waves.
f0
c
2L
------
=
c
λ---
=
First Mode
Second Mode
Third Mode = 3/0, Fourth Mode = 4/0, etc.
Length (L) = λ/2
2f0
f0 = c
2L = c
λ
Z
X
Y
Lz
LY
LX
Tiny source of sound at x = y = z = 0
where Nx, Ny, and Nz can be 0, 1, 2, 3, …
fN = c
2
Nx
Lx(
(
2 +
Ny
Ly(
(
2
Nz
Lz(
(
2
+

Small Room Acoustics
241
sound fields present in a control room and
combining of closely spaced signals.
13.8.1 Selecting an Initial Signal Delay Gap 
(ISD)
To select an initial signal delay (ISD) gap you need
to know the ISD of the studio or other environment
surrounding the musicians.
Additionally, the control room’s ISD must be
made longer than the studio’s ISD if it is to allow
reproduction of the studio’s gap over the monitor
loudspeakers, Figs. 13-11 and 13-12.
The control room’s first significant reflection
should fall within the Haas zone (see Chapter 15
Designing for Intelligibility for a discussion of the
Haas zone). Experience indicates that all subse-
quent reflected energy should appear as a sloping
straight line on the analyzer’s display of the
Figure 13-7. Sound distribution in a rectangular room.
Sound pressure
Sound pressure pattern, mode (4,0,0)
Sound pressure contours on a section through
the room, mode (2,0,0)
Particle velocity contours, mode (2,0,0)
Energy density contours, mode (2,0,0) —
For an axial mode the energy density is uniform.
A. Axial mode. (Courtesy B & K Technical Review.)
B. Tangential mode
C. Oblique mode
Figure 13-8. Plotting modal wavelengths as frequencies.
Frequency–Hz
Decibels
Oblique
Tangential
Axial

242
Chapter 13
Envelope Time Curve, ETC, i.e., an exponential
decay rate. It is also known that energy that exceeds
this slope is detrimental and audible, particularly so
should its time interval fall outside the “Haas zone,”
Fig. 13-13. The difference between the ETC of a
small room (control room) and a concert hall is
illustrated in Fig. 13-14. Note the time scales and
the difference in ISD gaps.
13.9 Reflections
13.9.1 Useful Definitions
The LEDE concepts are physically simple but
psychoacoustically complex. The goal of an LEDE
control room is to let mixing engineers, who sit at
the console, hear the first reflections from the
recording studio over the control room loud-
speakers before they hear any from the control room
they are sitting in.
Figure 13-9. Acceptable room ratios. Courtesy Bolt,
Beranek, and Newman.
Figure 13-10. Recommended small room dimension
ratios.
y dimension
2.6
2.4
2.2
2.0
1.8
1.6
1.4
+
Bolt
1.0:1.5:2.0
(mean)
Ratio = 1.0 : x : y
1.0         1.2            1.4           1.6          1.8        2.0
x dimension
ASHRAE:               1 : 1.17 : 1.47
 
              1 : 1.45 : 2.10
 
2
3
2
2
:
BOLT: 
              1 : 1.28 : 1.54
IAC: 
              1 : 1.25 : 1.60
SEPMEYER              1 : 1.14 : 1.39
1 :    
              1 : 1.26 : 1.41
Table 13-1. Sound Fields Present in Control Rooms
(13-3)
(13-4)
where,
LT is the total sound in decibels,
LD is the direct sound level in decibels,
LR is the reverberant sound level in decibels,
Ln is the ambient noise level in decibels.
All levels are in decibels re 20 µPa.
The addition of two signals having the same frequency but 
different levels and phases is given by:
(13-5)
where,
Lcomb = combined sound level of two signals in decibels,
L1 = sound level of first signal in decibels,
L2 = sound level of second signal in decibels,
a1 = phase angle of L1,
a2 = phase angle of L2.
The following illustrates the effect of phase on equal-level
signals. A 6 dB addition signifies a dominant direct sound
field at a precise point. It does not signify a sound power
increase over a given area.
L1
a1 (deg)
L2
a2 (deg)
Lcomb (dB)
90
0
90
0
96.02
90
0
90
10
95.99
90
0
90
20
95.89
90
0
90
30
95.72
90
0
90
40
95.48
90
0
90
50
95.17
90
0
90
60
94.77
90
0
90
70
94.29
90
0
90
80
93.71
90
0
90
90
93.01
90
0
90
100
92.18
90
0
90
110
91.19
90
0
90
120
90.00
90
0
90
130
88.54
90
0
90
140
86.70
90
0
90
150
84.28
90
0
90
160
80.81
90
0
90
170
74.83
90
0
90
180
−∞
LT
10
10
LD 10
⁄
10
LR 10
⁄
10
Ln 10
⁄
+
+
(
)
log
=
LR
10
10
LT 10
⁄
10
Ln 10
⁄
–
10
LD 10
⁄
–
(
)
log
=
Lcomb
20
10
L1
20
------
⎝
⎠
⎜
⎟
⎜
⎟
⎛
⎞
2
10
L2
20
------
⎝
⎠
⎜
⎟
⎜
⎟
⎛
⎞
2
2
10
L1
20
------
⎝
⎠
⎜
⎟
⎜
⎟
⎛
⎞
10
L2
20
------
⎝
⎠
⎜
⎟
⎜
⎟
⎛
⎞
a1
a2
–
(
)
cos
(
)
+
+
log
=

Small Room Acoustics
243
Dead End. This simply means that no early reflec-
tions can be allowed to occur in the front half of the
control room. This may be accomplished by using
absorption, reflection-free zones (RFZ), or any other
method that meets the criteria of having no reflec-
tions from the front half of the control room before
the deliberately installed diffuse energy occurs.
Live End. The live end consists of three functions:
a. Haas effect—A first reflection strong enough
from the studio, as heard over the control room’s
loudspeakers, to provide the Haas effect.
Figure 13-11. ISD in a studio and a control room.
Figure 13-12. Energy density versus time for an LEDE
control room.
DRC
DDC
A. LEDE control room.
DRS
DDS
B. Studio.
DRS − DDS = ISDS
DRC − DDC = ISDC
(ISDC should be > ISDS
DRS = Distance (or time) first reflection travels in studio.
DRC = Distance (or time) first reflection travels in control room.
DDS = Distance (or time) direct sound travels in studio.
DDC = Distance (or time) direct sound travels in control. 
Distance between sound source and microphone
Direct sound
Initial signal-delay gap
First significant reflection
Second significant reflection
Third significant reflection
Time
Diffuse sound
Energy density
Figure 13-13. Häas zone for a single reflection.
Figure 13-14. Master Sound Astoria recording studio.
(Courtesy Charles Bilello.)
0     5    10    15   20    25   30    35    40   45  50
Echo delay–ms
Decibel difference to
restore equal loudness
12
10
8
6
4
2
0
ETCs of Master Sound Astoria recording studio (top) 
and a great concert hall (bottom). Note the clean ISD 
level of the clump of early reflections compared to 
the direct sound. Also note the exponential decay of 
ETCs of Master Sound Astoria recording studio (top) 
and a great concert hall (bottom). Note the clean ISD 
level of the clump of early reflections compared to 
the direct sound. Also note the exponential decay of
the diffused sound.
ISD
Diffuse sound
0                        50                        100
Time–ms
Time–ms
50                         100                        200  
6 dB
6 dB
Direct sound
Energy–dB
Energy–dB

244
Chapter 13
b. Diffusion—Our preference is for Schroeder’s
quadratic residue diffusors (QRD). We believe
that the optimum placement of these is behind the
mixer’s position at the rear wall—a good distance
from the mixer is from 7 to 15 ft. The diffusors
should not be in the on-axis path of the monitors
since undesired specular reflections at frequen-
cies above the diffusion frequencies can occur.
c. Specular reflectors—Care must be taken to
provide subsequent early reflections. Each
reflection should follow an exponential change
in level with increasing time. Be sure not to
space them at equal delay intervals. These spec-
ular reflections should again drive signals back
into the diffusors so that the entire audible decay
period is diffuse.
13.10 Reflection Free Zone
When studio designers began to use analyzers in the
control room during the building and during retrofit-
ting of the control room, it was found that less
absorption was needed in the front of the control
room to control early reflections.
It is necessary to create a reflection free zone, as
Peter D’Antonio calls it, Fig. 13-15. When early
control room designers were not using TEF, it was
necessary to make the entire front half absorptive.
Comb filters caused by early reflections mimic
the pinnae and torso transfer function, which is very
destructive to stereo imagery. If the room can be
constructed to keep sound off the walls and ceiling,
it is not necessary to use heavy absorption in the
front of the room. If speakers do cause early reflec-
tions, absorption can be strategically placed to mini-
mize the early reflections. Reflections less than 1 ms
occur from reflections off the console, from the face
of speaker cabinets, and from near-field monitors.
Absorption is the best answer.
13.10.1 Development of the Reflection Zone
It has been a synergetic development. A little history
would help.
Carolyn “Puddie” Rodgers received her
doctorate from Northwestern University in localiza-
tion and pinna transformations. At Northwestern she
worked with Gary Kendall.
Shortly after receiving her Ph.D. she attended a
Heyser TDS class. When she saw the comb filters
generated by misaligned loudspeakers* on the TDS
she remarked that it gave her an idea in future
research. To quote from the abstract of her AES
Journal article (April 1981, Vol. 29, No. 4,
p. 226–234)
Many studies have shown that the
pinna transform incoming signals,
superimposing upon the original signal a
comb-filter-like spectrum. This spectral
shaping has been shown to add an addi-
tional cue to the now classic hierarchy of
localization cues: interaural intensity,
phase, and time of arrival differences.
Recent evaluations of misaligned* loud-
speakers using time delay spectrometry
reveal spectral shapes which are strik-
ingly similar to pinna transformations.
The implication is that misaligned loud-
speakers*, poorly placed microphones,
or other early reflections introduce spec-
tral aberrations which may be decoded
by the auditory system as cues to source
position. The possible consequences of
the pinna transformations to the inter-
pretation of psychoacoustic phenomena
such as auditory imaging, the cocktail
party effect, and the precedence effect
are discussed.
Doug Jones of Chicago, working with a TEF
analyzer in the retrofit of control rooms, met Gary
Kendall at Northwestern. A fine paper was written
Figure 13-15. Plan view of an RFZ/RPG control room
with low-frequency diffusers. Limiting reflections from
surface boundaries form a symmetrical six-sided RFZ.
(Courtesy Peter D’Antonio.)
+
RFZ
RPG
LFD
*The term misaligned as used here refers to
drivers whose acoustic origins are at different
distances from the listener.

Small Room Acoustics
245
by Doug Jones, Gary Kendall, and William Martens.
They performed the following work.
The design of controlled listening environments
is an often overlooked part of the total environment
in which computer musicians work. Recording engi-
neers know the importance of being able to listen to
their production and mixing work in an environment
that supports clarity of image and which sounds the
same every time they use it. At the Northwestern
University Computer Music Studio we have recently
finished construction of a sound room that we intend
to use both as a general audio listening environment
and as a controlled sound environment for psycho-
acoustic research into localization.
Experience in many studio monitoring rooms has
established that good audio imaging requires the
control of reflections. This knowledge has been put
to use in the contemporary style of control room
design called “Live End—Dead End” or “LEDE.”
Unwanted reflected sound can distort stereo imagery
and degrade the sense of total sound space.
Until recently, most localization research was
performed over headphones or in anechoic cham-
bers and the results of that work have not been
applicable to normal listening situations with
speakers. Our research required that we be able to
alter the reverberant characteristics of our room in
very selective ways. With the aid of the Crown TEF
(Time, Energy, Frequency) analyzer, we have been
able to make changes in the placement of
sound-absorbent panels on the walls and immedi-
ately evaluate the effect of the changes. The TEF
analyzer provides us with a higher degree of accu-
racy and resolution in the detail of room acoustics
than has been possible before.
Using the TEF, we have been able to build a
room that is selectively anechoic. It is anechoic
between the loudspeaker and listener positions,
while it appears otherwise reverberant to the
listener. This enables us to conduct localization
experiments in an environment that can be demon-
strated to be free from early reflections, while
allowing the subject to experience it as a normal
room, not an anechoic chamber. While this environ-
ment shares some design goals in common with
“Live End—Dead End” studio monitoring rooms, it
is intended to be a flexible environment that can be
easily altered to fit many different uses.
Fig. 13-16 shows a cutaway view of a small
room with a loudspeaker in the corner. Figs. 13-17
through 13-22 show Sonex being added and the
effect of each piece of absorption measured. Note
that all reflections were removed (in his time
window) without total absorption in front of the
room. Of course, a control room is much more
complex but it shows the direction they are taking.
13.11 Diffusion
Noted authorities have dealt with this problem of
diffusion. T. F. W. Embleton stated:
In a large, irregular enclosure it is
possible, in principle, to have a diffuse
sound field, one that consists of a super-
position of sound waves traveling in all
directions with equal probability. This
characteristic ensures that the average
energy density (ensemble-average
energy density) is the same at all points.
If this were actually so, there would be
no net flow of power in any direction.
Hence, a diffuse sound field never actu-
ally exists because there is always a net
Figure 13-16. Cutaway of a small room with a loudspeaker in the corner. (Courtesy Doug Jones.)
A.
B.
C.

246
Chapter 13
flow of power away from the source to
the places where the energy is ultimately
absorbed. Nevertheless, the concept of a
diffuse sound field is useful in rooms
that are not highly absorptive and
where, in addition, the measurement
position is neither in the vicinity of the
source nor near any small area that is
highly absorptive.
James Moir noted:
In an acoustically large room some
approach to complete diffusion can exist
during the decay period because of the
close spacing of the resonant mode
frequencies even at the lower audio
frequencies.
Morse and Ingard also noted:
Figure 13-17. Effect of Sonex being added to the small room in Fig. 13-16. (Courtesy Doug Jones.)
Figure 13-18. Effect of Sonex being added to the small room in Fig. 13-17. (Courtesy Doug Jones.)
Figure 13-19. Effect of Sonex being added to the small room in Fig. 13-18. (Courtesy Doug Jones.)
A.
B.
C.
A.
B.
C.
A.
B.
C.

Small Room Acoustics
247
A sound wave is scattered, not only
by a solid object, but also by a region in
which the acoustic properties of the
medium…. Turbulent air scatters, as
well as generates sound…. A rough
patch on a plane surface scatters, as
well as reflects, sound.
Pick up any book with pretensions to knowledge
about recording studios and almost without excep-
tion the material on the internal acoustics exhibits an
enormous void of accurate or useful information.
Implied is that all you have to do is add absorption,
with the aid of some devil’s apprentice with infor-
mation from the dark domain, and all is well.
TEF has clearly shown us that the reflection free
zone is easy. The tough part is obtaining the
optimum diffusion from the “live” end. In fact, the
difference in quality of control rooms is the differ-
ence in diffusion present at the mixer’s ears. The
more diffuse and mixed the total sound field at the
mixer’s ears the better the quality of the sound.
Figure 13-20. Effect of Sonex being added to the small room in Fig. 13-19. (Courtesy Doug Jones.)
Figure 13-21. Effect of Sonex being added to the small room in Fig. 13-20. (Courtesy Doug Jones.)
Figure 13-22. Effect of Sonex being added to the small room in Fig. 13-21. (Courtesy Doug Jones.)
A.
B.
C.
A.
B.
C.
A.
B.
C.

248
Chapter 13
13.11.1 Quadratic Residue Diffusors
The first AES paper on LEDE design (D. Davis and
C. Davis, 1978) stated that Schroeder’s quadratic
residue diffusors would be ideal for the diffuse rear
wall. Dr. Peter D’Antonio made the Schroeder equa-
tions practical. Dr. D’Antonio’s hobby is recording.
He built an LEDE control room in his basement and
used quadratic residue diffusors.
He gave a paper at AES in the fall of 1983 in
New York (a poster session). Robert Todrank, who
was building an LEDE control room for Jimmy
Tarbutton at Acorn Studios in Nashville and was
struggling with the diffuse rear wall, attended the
session. Todrank built and installed the first diffu-
sors in a commercial control room. Russ Berger, key
in the use of the diffusors, was also present, as we
were. Berger was to shortly host a Syn-Aud-Con
sponsored LEDE workshop at the Dallas Sound
Labs. He invited D’Antonio and his diffusors to
attend the workshop. The diffusor measurements are
shown in Fig. 13-23. The diffusors took the design
of the diffuse rear wall out of “art” and made it a
predictable success. Subsequently Peter D’Antonio
became a manufacturer of diffusors and Russ Berger
became the foremost studio control room designer in
the world.
13.12 Conclusion
The acoustical properties of rooms are basic to the
successful design of sound systems. This chapter on
small room acoustics has looked at the ambient
noise level LN in a room, the relationship of direct
sound level LD, to the reverberant sound level LR
(i.e., LD – LR), and the reverberation time RT60.
We’ll now turn our attention to how our sound appa-
ratus can be chosen and adjusted to optimize
acoustic gain.
Bibliography
P. D’Antonio and J. H. Konnert. “The Reflection Phase Grating Diffusor: Design Theory and Application,” J.
Audio Eng. Soc., Vol. 32, No. 4 (Apr. 1984), pp. 228-238.
P. D’Antonio, J. H. Konnert, and F. Becker. “The RPG Reflection Phase Grating Diffusor: Experimental
Measurements.” Paper presented at 76th AES Convention, New York (Oct. 1984). Preprint No. 2158.
P. D’Antonio, J. Konnert, and R. E. Berger. “Control Room Design Utilizing a Reflection Free Zone and
Reflection Phase Grating Diffusors: A Case Study.” Paper presented at 78th AES Convention, Anaheim,
Calif. (May 1985).
Figure 13-23. These TEF measurements were made at the Dallas Sound Lab LEDE Workshop. What the class heard 
and the measurement they saw assured the future success of diffusors.
A.
B.
6 dB
6 dB

Small Room Acoustics
249
C. Davis and D. Davis. “(LEDE)” Live End—Dead End Control Room Acoustics... (TDS) Time Delay Spec-
trometry...(PZM) Pressure Zone Microphones,” Record. Eng. Prod. (Feb. 1979).
D. Davis. “Putting It All Together in a Control Room,” Syn-Aud-Con Tech Topics, Vol. 5 (Apr. 1978).
D. Davis. “Nashville LEDE™ Workshop,” Syn-Aud-Con Tech Topics, Vol. 12, No. 1 (Fall 1984).
D. Davis and C. Davis. “LEDE and the Diffused Rear Wall,” Syn-Aud-Con Tech Topics, Vol. 11, No. 7
(1984).
_______. “The LEDE Concept for the Control of Acoustic and Psychoacoustic Parameters in Recording
Control Rooms,” J. Audio Eng. Soc., Vol. 28, No. 9 (Sept. 1980), pp. 585-595.
H. Häas. “The Influence of a Single Echo on the Audibility of Speech,” J. Audio Eng. Soc., Vol. 20 (Mar.
1972), pp. 145-159.
J. Henry. “On Acoustics Applied To Public Buildings.” Paper presented at the American Association for the
Advancement of Science, August 1856; later published in the Smithsonian Institution publication.
D. R. Jones. “Designing a Stereo Room for Spatial Hearing Research on Stereo Imagery Using the TEF”
(Unpublished).
D. R. Jones, W. L. Martens, and G. S. Kendall. “Optimizing Control Rooms for Stereo Imagery.” Paper
presented at the Acoustical Society of America, Nashville, Tenn. (Nov. 5, 1985).
H. Kuttruff. Room Acoustics. New York: Halstead Press, 1973.
J. Moir. High Quality Sound Reproduction. New York: Macmillan, 1958.
C. A. P. Rodgers. “Pinna Transformations and Sound Reproduction,” J. Audio Eng. Soc., Vol. 29 (1981), pp.
226-234.
M. R. Schroeder. “Progress in Architectural Acoustics and Artificial Reverberation: Concert Hall Acoustics
and Number Theory,” J. Audio Eng. Soc., Vol. 32, No. 4 (Apr. 1984), pp. 194-203.
W. B. Snow. “Application of Acoustical Engineering Principles to Home Music Rooms,” IRE Trans. on Audio
(Nov.-Dec. 1957), pp. 153-159.
R. Todrank. “Incorporating Reflection Phase Grating Diffusors on the Rear Wall to Enhance Spatial Imaging
and Stereo Ambiance,” Record. Eng. Prod., Vol. 15, No. 6 (Dec. 1985), pp. 122-125.


Chapter 14
Designing for Acoustic Gain
by Don Davis
251
14.1 Maximum Physical Distance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 253
14.2 Establishing an Acceptable Signal-to-Noise Ratio (SNR) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 253
14.3 Establishing an EAD  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 254
14.4 Needed Acoustic Gain (NAG)  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 254
14.5 The Number of Open Microphones . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 255
14.6 The Feedback Stability Margin  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 255
14.7 Calculating Potential Acoustic Gain  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 256
Acoustic Gain Parameters . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 258
Effect of Directional Devices on Acoustic Gain . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 258
14.8 Obtaining ΔDx Values  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 258
14.9 Measuring Acoustic Gain . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 259
14.10 Achieving Potential Acoustic Gain  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 259
14.11 Limiting Parameters in Sound Reinforcement System Design  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 260
14.12 How Much Electrical Power Is Required? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 260
14.13 Finding the Required Electrical Power (REP) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 261
Loudspeaker Efficiency . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 262
Conversions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 262
100% Efficiency Values  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 263
14.14 Summary  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 263
Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 263


   
Designing for Acoustic Gain
253
Years of experience with acoustic gain equations
have demonstrated their usefulness and accuracy in
identifying the maximum acoustic level possible in a
sound reinforcement system. Direct sound levels at
the furthest listener have been found to be of greater
importance than the total sound level.
A number of factors must be present at the
listener’s position for easily understood communi-
cation to take place:
1.
The sound must be sufficiently loud, and it must
be at least 25 dB above the ambient noise level at
midfrequencies (2000  Hz) in rooms with
RT60 ≥1.6 s).
2.
The sound must reasonably approximate the
same spectrum shape as that produced by the
talker or other source.
3.
The sound must reasonably approximate a ratio
of direct-to-reverberant sound within the rules for
acceptable articulation loss. Temporal misalign-
ment of arrays with the resultant changes in polar
response (lobing) is the most common cause of
an unexpectedly poor direct-to-reverberant ratio
(D/R).
14.1 Maximum Physical Distance
Using a sample acoustic environment where:
V = 500,000 ft3,
S = 42,500 ft2,
= 0.206,
RT60 = 2.5 s,
and testing it for the maximum physical distance a
talker and a listener could stand apart and easily be
heard and understood without a sound system, we
would find that we have indeed fulfilled the three
criteria mentioned above. This physical distance is
typically 6–10 ft in the environment for this sample.
For example, if a weak talker produced 65dBA at
2ft in a very quiet room and the ambient noise was
28 dBA, then:
(14-1)
where,
LN is the noise level,
SNR is the signal-to-noise ratio,
Lreq is the required level.
This example shows that a distance of 8 ft from
the talker is the maximum physical distance at
which a listener can stand and be sure of hearing
clearly if no sound system is present. If we use a
normal male voice level of 71 dB at 2 ft, then the
maximum physical distance would be:
Fig. 14-1 allows these calculations to be made at
a glance. For example, our normal voice of 71 dBA
at 2 ft becomes 83 dBA at 0.5 ft. Going up the normal
voice line to 53 dB results in an EAD ≈16 ft. “Weak
voice” and “normal voice” are relatively
self-explanatory. The expected voice level is a very
real effect that can be relied upon in marginal
communication circumstances or that must be care-
fully avoided in the case of speech privacy systems,
for example.
If a talker and a listener were 10 ft apart and we
raised the noise level by means of a speech privacy
system to an LP of approximately 58 dB overall, then
the talker would involuntarily raise his or her voice
to overcome the noise. If we kept the noise at
55 dBA, then masking would be effective at
distances of 12–15 ft from the talker, who would
continue to converse at normal voice level. A talker
can raise Q slightly by using cupped hands in front
of the mouth, megaphone fashion; a listener can
raise Q by using cupped hands behind the ears.
The limit shown for amplified speech is not due
to an inability to amplify but because these levels
represent dangerous LP conditions for the listener’s
ears. Fig. 14-1 outlines the parameters of the
possible and impossible sound system solutions and
is simple enough for laymen to understand during
presentations.
Having arrived at the maximum physical
distance between a talker and a listener with no
sound system present, we now adopt that distance as
our goal for a successful sound system. We want the
equivalent acoustic distance (EAD) to be established
at the farthest listener (D2), even though this listener
may be over 100 ft away.
14.2 Establishing an Acceptable 
Signal-to-Noise Ratio (SNR)
Establishing an acceptable signal-to-noise ratio,
SNR, is a major factor in achieving intelligibility.
We typically want at least 25 dB of SNR in the
2000Hz octave band. Establishing such a ratio can
a
LN
SNR
+
Lreq
=
28
25
+
53 dB
=
65 dBA talker
53 dBA required
–
12  dB
=
2 ft
10
12  dB
20  dB
--------------
×
8 ft
=
71 dBA
53  dBA
–
18 dBA
=
2 ft
10
18  dB
20  dB
--------------
×
16 ft
=

254
Chapter 14
be a problem itself. Consider, for example, one
segment of a large audience area that is affected by a
noisy air handler so its EAD is different than the rest
of the room. Where the level of the ambient noise
field is relatively constant throughout the listening
area, we can use the equivalent acoustic distance
(EAD) everywhere.
14.3 Establishing an EAD
The EAD requires that we meet the following
criteria:
1.
Establish at the listener’s ears (at 125 ft, for
example) the same LP , via the sound system, that
would have been heard at the maximum phys-
ical distance (in the sample case, the same LP
that would have been heard 8 ft from the talker).
2.
Establish at the listener’s ears, via the sound
system, the same spectrum shape that would have
been heard at the maximum physical distance.
3.
Establish at the listener’s ears, via the sound
system, a ratio of direct-to-reflected sound that
does not deteriorate the articulation loss of conso-
nants (%ALCONS) by more than 15%. In other
words, the equivalent acoustic distance estab-
lishes a set of conditions that are the same as the
maximum physical distance without a sound
system at some much greater distance from the
source through the use of a sound system.
14.4 Needed Acoustic Gain (NAG)
Using the standard sound system notation, we can
look at Fig. 14-2 and see that we have a real listener
at some distance from the talker (D0). The talker is a
given distance from the microphone (Ds). To find
the needed acoustic gain (NAG) find the attenuation
over distance D0 minus the attenuation over distance
EAD. For example, we are outdoors and the
inverse-square-law level change applies. The
following distances are known:
DS = 2 ft,
EAD = 8 ft, 
D0 = 128 ft.
We can then write:
(14-2)
or simply:
(14-3)
which in the example is:
where,
EAD is the equivalent acoustic distance,
D0 is the distance from talker to farthest listener,
Figure 14-1. Nomograph for finding the EAD. (Courtesy John Webster.)
Meters 
Feet
6.096 
20
4.877 
16
3.048 
10
2.438 
8
1.829 
6
1.219 
4
0.9144 
3
0.696 
2
0.3048 
1
0.1524 
0.5
50  53 dBA  60               70                80               90               100             110             120              130
Noise level − dBA + 25 dB SIN
Area where face-to
-face communications
are possible using
 "normal voice"
Weak voice
Expected voice level
Shout
Maximum vocal effort
Area where face-to-face
communications
are impossible
Area where
face-to-face
communications
are difficult
Normal voice
Raised voice
Communicating voice
Very low voice
Limit for amplified speech
Distance from speaker to listener
NAG
20
D0
Ds
------
log
20
EAD
Ds
------------
log
–
=
NAG
20
D0
log
20
EAD
log
–
=
NAG
20
128
log
20
8
log
–
=
24  dB
=

   
Designing for Acoustic Gain
255
Ds is the distance from talker to microphone.
We can also calculate NAG the long way. If the
talker produced 70 dBA at a microphone 2 ft away,
then the talker would produce 64 dBA at 4 ft and
58dBA at 8 ft (6 dB loss with doubling of distance).
Continuing on, at 16 ft the level would be down to
52 dBA, at 32 ft it would be 46 dBA, at 64 ft it would
be 40 dBA, and at 128 ft it would be 34 dBA. The LP
we need is that at 8 ft, or 58 dBA. Then:
We thus need 24 dB of acoustic gain to have an
EAD of 8 ft at 128 ft.
14.5 The Number of Open Microphones
If we raise two microphones to the same level in a
reinforcement system, we will have to reduce the
overall gain 3 dB to avoid the system going into
feedback (remember how decibels combine). Since
each microphone is sampling the sound field, every
time you double the number of open microphones
(NOM), we will have to lower the gain 3  dB,
Fig. 14-3. Therefore the loss in gain caused by more
than one open microphone is:
.
(14-4)
If we decide to operate a sound system with more
than one open microphone, we must add the deci-
bels we will lose through having these extra micro-
phones active to the gain required so NAG now
becomes:
(14-5)
14.6 The Feedback Stability Margin
In a paper that turned out to be remarkably ahead of
its time, William B. Snow, in the April 1955 AES
Journal, described the detrimental effects of oper-
ating a sound system too near the acoustic feedback
point. The paper, Frequency Characteristics of a
Sound Reinforcing System, contained a set of super-
lative illustrations made by Snow on his level
recorder. These illustrations are used here to point
out the main features of this pioneer paper.
Fig. 14-4 shows the effect on the response of the
system as it approaches unity gain. The 10, 20, 30,
and 40 markings are arbitrary settings on an ampli-
fier’s gain control. For example, the curve marked
20 was 15 dB below feedback. Note that, even at
25dB below feedback (30 on the chart), significant
irregularities are evident. Note also that large
corrections are not necessary and that “bumps”
corrected by less than 1 dB at −25 dB below feed-
back will not grow into bumps when the gain is
again raised. When a sound system is unequalized,
at least 12 dB of feedback stability margin (FSM) is
required. When carefully equalized, 6 dB of FSM is
adequate to ensure a stable system free of spurious
regenerative sounds.
Boost devices require excessive FSM to be safe
to use. Fig. 14-5 illustrates the nonlinear behavior of
such minor aberrations in response when bass boost
is used too near regeneration. Fig. 14-6 illustrates
the same effect at the opposite end of the spectrum
when treble boost is used.
Figure 14-2. Distances involved in determining NAG.
Figure 14-3. Chart relating NOM and NOM in decibels.
Ds
EAD
D0
Microphone
Talker
Listener at
EAD distance
Listener at
D0 distance
NAG
dB SPL at  8 ft
dB SPL at 128 ft
–
=
58
=
 dB
34  dB
–
24  dB
=
NOM (in dB)
10
NOM
log
=
0                         10                         20                      30
ΔNOM—dB
1      2       4   6   10     20    40  60  100  200  400    1K
NOM
Figure 14-4. Response of a sound system as it operates
with gain. Sing frequency is 5 dB. Therefore, 30 is 25 dB
below feedback.
NAG
ΔD0
ΔEAD
–
10
NOM
log
+
=
Electrical response
Sing point = approximately 5
Sing frequency
100     200             500         1K            2K               5K         10K
Frequency—Hz
10
20
30
40

256
Chapter 14
Fig. 14-7 explains a still different phenomenon.
As a sound system is brought near feedback, not
only does the amplitude response behave nonlin-
early but the transient response also does so. The
natural reverberation time of the room is magnified
by the sound system. In Snow’s demonstration
room, RT60 = 0.65 s. When the sound system was
just below feedback, RT60 was 2.7 s, a multiplication
factor of 4.2 times:
(14-6)
where,
x is the decay rate in dB/s.
Fig. 14-8 shows an example of the amplitude
non-linearity as seen on a 1⁄3 octave analyzer.
Many early experiments in the art of equalization
mistook the regenerative amplitudes for the true
amplitude and used filters that were set too deep.
Although any small irregularity in response can be
magnified as shown here, some won’t be for a given
position of microphone and loudspeaker because of
the total room system phase response. Consequently,
it becomes apparent that the free-field response of
desirable transducers for sound-reinforcement work
must exhibit relatively smooth changes in response
without peaks or dips that have rapid slope rate
changes.
Snow (1955), Davis (1967), Mankovsky (1971),
and Yamamoto (1971) have found a FSM of 6 dB
necessary. We thus need to add to our NAG this 6dB
FSM. We now can write a general formula for
finding the needed acoustic gain of a sound-rein-
forcement system:
(14-7)
14.7 Calculating Potential Acoustic Gain
Assuming that inverse-square-law level change will
serve in an outdoor situation and indoors for LD, we
can construct the set of sound system parameters
shown in Fig. 14-9. In conjunction with these calcu-
lations, we can use the nomograph in Fig. 14-10.
Figure 14-5. Nonlinear response of system using bass
boost.
Figure 14-6. Nonlinear response of system using treble
boost.
50     100        200        500              1K         2K            5K
Frequency—Hz
Sing frequency
Bass boost full
17
20
30
Sing point = approximately 15
Alternate sing frequencies
30
15
9
Treble boost full
100     200             500         1K            2K               5K         10K
Frequency—Hz
Sing point = approximately 8
RT60
60
x------
=
Figure 14-7. Nonlinear behavior of amplitude and tran-
sient response.
Figure 14-8. Regenerative swelling of normal response
15 dB, 5 dB, and 2 dB below feedback.
2.2 dB/s
92 dB/s
Handclaps near sing point
Handclaps 12 dB below sing point
Reverberation time = 0.65 s
5 db below
feedback
2 dB below
feedback
15 dB below
feedback
125      250       500         1K          2K         4K          8K       16K
Frequency—Hz
NAG
ΔD0
ΔEAD
–
10
NOM
log
6 dB FSM
+
+
=

   
Designing for Acoustic Gain
257
If the required gain (ΔD 0 − ΔEAD) is
24 dB + 6 dB FSM and one microphone is open,
substituting in the equation gives:
If we assign the following values to the parame-
ters in Fig. 14-9, we can find their dB equivalents by
using Fig. 14-10:
D0 = 128 ft,
ΔD0 = 42 dB,
DS = 2 ft,
ΔDs = 6 dB,
D1 = 45 ft,
ΔD1 = 33 dB,
D2 = 90 ft,
ΔD2 = 39 dB.
We can write the following equation for potential
acoustic gain (PAG):
(14-8)
where,
D0 is the distance from talker to farthest listener,
D1 is the distance from the microphone to the loud-
speaker,
Ds is the distance from talker to microphone,
D2 is the distance from the loudspeaker to the
farthest listener.
In our example:
Since PAG = NAG, we have sufficient acoustic
gain. We can write this another way:
(14-9)
If we actually write the equations in this manner, we
discover:
(14-10)
or
(14-11)
The ΔD0s cancel, and we arrive at a most useful
general formula:
(14-12)
Our original requirement was a NAG of 30 dB
with an EAD of 8 ft and a Ds of 2 ft. We could have
written the general equation in the following manner
to find ΔD2:
(14-13)
Because signal delay would become a factor if
we made D1 greater than 45 ft, we chose 45 ft as a
limit on D1:
(14-14)
We could now write:
or
Looking on the dB part of the scale in Fig. 14-10,
we find that 39 dB is equivalent to 90 ft.
Now that we have seen how our values are
found, we can simplify the process by removing the
Δ operator and using the following ratio equations:
Figure 14-9. Basic parameters of a single-source
system.
Figure 14-10. Calculation of relative changes in level
with distance (inverse square law).
Loudspeaker
Talker
Ds
D2
D0
D1
Listener
0       5      10      15      20     25     30      35     40      45     50      55    60
ΔD—dB
1         2         4     6   8 10       20        40   60   100     200     400  600  1K
D—ft
ΔD—dB
0         −10         −20         −30        −40
1.0  0.6 0.4   0.2     0.1 0.06      0.02   0.01
D—ft
NAG
24  dB
0  dB
6 dB
+
+
=
30  dB
=
PAG
ΔD0
ΔD1
ΔDs
–
ΔD2
–
+
=
PAG
42  dB
33 dB
6 dB
–
39  dB
–
+
=
30  dB
=
PAG
NAG
–
0
=
ΔD0
ΔD1
ΔDs
–
ΔD2
–
+
ΔD0
ΔEAD
–
10
NOM
log
+
6
+
=
ΔD0
ΔD0
–
ΔD1
EAD
ΔDs
–
ΔD2
10
NOM
log
–
6
0
=
–
–
+
+
ΔD1
ΔEAD
ΔDs
–
ΔD2
10
NOM
log
–
6
0
=
–
–
+
ΔD1
ΔEAD
ΔDs
–
10
NOM
log
–
6
ΔD2
=
–
+
Optimum D1
DC
≥
45  ft
<
Δ45 ft
Δ8  ft
Δ2 ft
–
10
1
log
–
6
–
+
ΔD2
=
33 dB
18  dB
6  dB
–
0  dB
–
6 dB
–
+
39  dB
=

258
Chapter 14
(14-15)
(14-16)
(14-17)
(14-18)
(14-19)
All parameters are now in feet or meters, except
NOM, which is the number of open microphones.
14.7.1 Acoustic Gain Parameters
Using Figs. 14-9 and 14-10, we have already deter-
mined that the maximum D2 possible is 90 ft. Why is
it the maximum distance? Let’s examine what
happens as we change each of these basic parame-
ters, one at a time.
If D1 is increased, what happens to the acoustic
gain? Since the loudspeaker and microphone are
separated further, the gain can be turned up more
before the sound from the loudspeaker reaches the
microphone at the same level as the talker’s voice
(unity gain). In fact, let’s look at the series of level
changes that makes a sound system necessary and
allows it to work at all.
If, as in our example for the calculation of NAG,
we again assume that the talker generates 70 dBA at
a microphone 2 ft away, we can also assume that the
loudspeaker can deliver 70 dBA at the microphone
just as feedback begins. If we work backward with
inverse-square-law level change, we find that at 4 ft,
the loudspeaker is providing:
Therefore, increasing D1 increases the acoustic gain
until Dc acts as a limit.
Going away from the loudspeaker in the direc-
tion of the listener (D2), we see that at 8 ft we have
85dBA, at 16 ft we have 79 dBA, at 32 ft we have
73dBA, at 64 ft we have 67 dBA, and at 90 ft we
have 64 dBA. Note that 64 dBA is just 6 dB greater
than 58 dBA. Now, if D2 is increased, the level
beyond 90  ft would also decrease; therefore,
increasing D2 lowers the apparent acoustic gain.
If Ds is increased, the result is obvious. Any time
we move farther away from the microphone, we lose
apparent acoustic gain.
Finally, what happens if D0 is increased? The
level change between the talker and the listener
increases. Since the sound arriving from the loud-
speaker has remained the same (remember we are
changing only one parameter at a time), the apparent
gain has increased.
Eq. 14-7, 
, shows
by means of the signs (+ or −) which parameters will
increase apparent gain if they are increased (all plus
signs do this) and which parameters will decrease
apparent gain if they are increased (all minus signs
do this).
Note that the absolute acoustic gain of the system
is determined by the true acoustic separation
between the microphone and the loudspeaker (D1).
All other parameters change the apparent acoustic
gain (as observed by the listener).
14.7.2 Effect of Directional Devices on Acoustic 
Gain
To find the effect of directional devices on acoustic
gain, do the following:
1.
Find PAG for an omnidirectional source (PAGomni).
2.
Take the difference in dB between the level on the
microphone polar plot at the angle toward the
talker and the angle toward the loudspeaker, MS∠.
3.
Take the difference in dB between the level on
the loudspeaker’s polar plot at the angle toward
the listener and the angle toward the micro-
phone, SM∠.
4.
.
5.
PAGomni + (MS∠ + SM∠) = Total gain (free field),
Fig. 14-11.
14.8 Obtaining ΔDx Values
In obtaining ΔDx values (distances converted into
relative levels) for use in acoustic gain equations,
the following techniques are the basic ones:
1.
Use inverse-square-law level change for free-
field conditions:
Max Ds
D1
EAD
×
2D2 NOM
----------------------------
=
Min D1
2Ds
D2
×
NOM
×
EAD
-----------------------------------------------
=
Max D2
D1
EAD
×
2Ds NOM
----------------------------
=
Min EAD
2Ds
D2
×
NOM
×
D1
-----------------------------------------------
=
Max NOM
D1
EAD
×
(
)2
Ds
2D2
×
(
)2
--------------------------------
=
70 dBA
20
45 ft
4  ft
-----------
log
+
91 dBA
=
PAG
ΔD0
ΔD1
ΔDs
–
ΔD2
–
+
=
Me
10
MS∠
SM∠
+
20
------------------------------------
⎝
⎠
⎛
⎞
=

   
Designing for Acoustic Gain
259
(14-20)
This automatically makes the reference
distance unity and since it is nondimensional,
either U.S. or SI lengths may be used.
2.
Use the Hopkins-Stryker equation as a relative
level generator for reverberant spaces, especially
when specific dB per doubling of distance
beyond Dc are known.
14.9 Measuring Acoustic Gain
It is one thing to calculate gains at the drawing-board
stage of a construction project. The real thrill comes
when, after having written your calculation into a
specification, many months later you actually
measure the acoustic gain of the sound system after
installation. The architects, engineers, owners, and
other interested parties know your prediction. When
your actual measurements come within ±2 dB of
your calculation, which has happened in literally
hundreds of jobs, these professionals have no choice
but to regard you as a fellow professional.
Measuring the acoustic gain of a finished sound
system is described below and in Fig. 14-12:
1.
With the sound system turned off and the room
made as quiet as possible (air conditioning or
heating turned off ), adjust the test amplifier (use
pink noise input) to give a 75–80dBA reading
over the test loudspeaker at the sound system
microphone (substitute the sound level meter
temporarily for the microphone). The micro-
phone should be placed at its design position.
2.
Carry the sound level meter to the farthest D2
position and measure the level from the test
loudspeaker. Exercise care that the signal
arriving from the test speaker is at least 6 dB
greater than the ambient noise reading. Record
this reading in dBA.
3.
Turn on the sound system (use the same test
loudspeaker feeding a 75–80 dBA signal into the
microphone) and adjust below self-sustaining
feedback (the system will ring, but upon cutting
off the signal, the feedback should not
continue).
4.
Again read the sound level meter at the farthest
D2 position and record in dBA.
5.
The reading taken with the sound system on
minus the reading taken with the sound system
off equals the total acoustic gain. The total
acoustic gain should be within ±2 dB of the calcu-
lated PAG.
14.10 Achieving Potential Acoustic Gain
The potential gain figures illustrated in this chapter
depend on the performance of room-sound-system
equalization (Chapter 24 Sound System Equaliza-
tion) to ensure unity gain at all frequencies of
interest.
Equally important to achieving potential acoustic
gain is freedom from misaligned loudspeakers and
focused energy coming back into the microphone.
Either of these two problems will seriously deterio-
rate intelligibility and gain.
A piece of sound absorbing material moved
about the microphone, the loudspeaker, and a
listener in the audience seating area will enable you
to determine where the problem originates. Once the
problem is isolated, the solution is often easy.
Be sure to measure what sound is emitting from
the back and bottom of the loudspeaker as well as
from the front. Remember that bass is omnidirec-
tional, Fig. 14-13. Frequency curve A is what the
audience would have heard had the microphone not
heard Curve B from the back and bottom of the
loudspeaker. Enormous equalization was required in
the 200 Hz to 500 Hz region, totally destroying male
voice intelligibility.
Figure 14-11. Sound radiation patterns.
Loudspeaker
Ds
D2
D0
D1
Listener
Bottom lobe
from loudspeaker
Main loudspeaker
polar pattern
Microphone
polar pattern
Talker
ΔDx
20
D
log
x
=
Figure 14-12. Method of measuring acoustic gain.
RNG
AMP
AMP
SLM
La
Test system
Sound system
Microphone      Loudspeaker
2 ft
Loudspeaker 

260
Chapter 14
14.11 Limiting Parameters in Sound Rein-
forcement System Design
Certain choices of parameters limit the choice of
approach to the system design. For example, if we
wish to use a single-source system (and all other
room parameters allow it) because of its inherently
more economical approach and ability to blend
acoustically with the live talker, then we cannot
have an EAD of less than twice Ds. For example, if
we must have a Ds of 2 ft, then the EAD cannot be
less than 4 ft:
(14-21)
Naturally, the other limit on EAD is that it not
exceed Dc:
(14-22)
This limitation (EAD ≥ 2Ds) for a single-source
sound system is on account of the FSM. Fig. 14-14
illustrates the limiting case. When EAD must equal
Ds, a distributed sound system becomes mandatory.
When D s = EAD, then D 1 must ≥ 2D s, see
Fig. 14-15. Fig. 14-16 shows how D1 and D2 are
handled in calculating the acoustic gain of a distrib-
uted system.
14.12 How Much Electrical Power Is 
Required?
While the calculation of acoustic gain is pertinent
only to sound-reinforcement systems, the same tech-
nique can be applied to finding out how to achieve a
desired level at some distance point from a sound
source. Rock groups, especially, make heavy
Figure 14-13. Sound measured from front and back of
speaker—40–12,000 Hz.
A.
B.
5 dB
EAD
2Ds
≥
EAD
Dc
≤
Figure 14-14. Effect of FSM on acoustic gain.
Figure 14-15. Requirement if Ds is equal to EAD.
Figure 14-16. Basic parameters of a distributed system.
16 ft
16 ft
2 ft
4 ft
8 ft
16 ft
70 dB  64 dB         58 dB                              52 dB
70 dB − 6 dB FMS = 64 dB
8 ft
4 ft
76 dB − 6 dB FSM = 70 dB
2 ft
4 ft
8 ft
16 ft
70 dB
64 dB
58 dB
52 dB
D1
D2
To closest
loudspeaker
To closest
loudspeaker
D0
Ds

   
Designing for Acoustic Gain
261
demands on the power-handling capabilities of
sound equipment. The ability to predict accurately
what they will get for their investment in different
locations can be useful. When you have some defi-
nite acoustic sound-pressure-level (LP) goal in mind
at some given distance (D2) from the loudspeaker,
you need to know two important details:
1.
The EIA sensitivity rating of the loudspeaker,
measured at 30 ft on axis when the loudspeaker is
fed an input signal of 0.001 electrical watt,
Fig. 14-17.
2.
The acoustic level change and attenuation
between the loudspeaker as measured at its refer-
ence distance for sensitivity and the farthest
listener position.
Once the desired acoustic level at the farthest
listener has been determined by actual measure-
ment, experience, or calculation, then the desired
acoustic level plus the acoustic level change over
distance D2 equals the 30 ft rating the loudspeaker
will be required to produce. EIA rating + 30 ft dB
rating = power required in dBm.
14.13 Finding the Required Electrical Power 
(REP)
Every dB of gain achieved by careful design and
equalization requires power to support that gain at
the output of the sound system. The advent of acous-
tical gain formulas and their optimization via equal-
ization marked the onset of more powerful sound
systems than had previously been the case.
The electrical power required to produce a pres-
sure level LP at a distance D2 is given by:
(14-23)
For example, to produce an LP = 90 dB at a distance
of 128 ft:
In our example we have chosen a medium
efficiency loudspeaker that has a power rating of
50W. This leaves us with two choices:
1.
Select a more efficient loudspeaker.
2.
Accept a lower level at the listener.
If we choose the first alternative, larger size,
higher cost, we can find the new power level by:
If we embrace choice two (2) we can find the
listener’s maximum level LP( MAX ) by:
(14-24)
The first loudspeaker was a medium efficiency
loudspeaker. The second was a very high efficiency
professional sound horn system. Imagine this same
requirement using a “home” type low efficiency
system with an LEIA of 41.5 dB
Figure 14-17. Sensitivity ratings.
                Sensitivity Ratings Currently in Use
1. 
N dB at 4 ft from 1.0 W input
2. 
N dB at 30 ft from 0.001 W Input
3. 
N dB at 1.0 m from 1.0 W input
4. 
N  W needed to produce 1.0 Pa at 1.0 m
                   European Sensitivity Rating
There are 3.280839895 ft/m. That is, a power of 0.21 W 
will produce a sound pressure of 1.0 Pa at 1 m. (1 Pa is 
a sound pressure level of 94 dB.)
While in Europe (March 1982) we were told that they 
are rating loudspeaker sensitivity as: Watts needed for 
a sound pressure of 1 Pa at 1 m (W/Pa/m)
Example
Given a loudspeaker rated at 99 dB at 4 ft for an electric 
power Input of 1 W, then:
10
94 - 99 + 20 log
4
3.28
= 0.21 W/Pa/m
10
(
)
REP =
10
LP
10
+
(
)
20
D2
log
(
)
20
DREF
log
–
LSENSI
–
+
[
]
10
--------------------------------------------------------------------------------------------------------------------------
WREF
×
REP =
10
90
10
+
(
)
20
128
log
(
)
20
30
log
–
51.5
–
+
[
]
10
----------------------------------------------------------------------------------------------------------
0.001 W
×
REP 
1228  
=
W
REP =
10
90
10
+
(
)
20
128
log
(
)
20
30
log
–
61.5
–
+
[
]
10
----------------------------------------------------------------------------------------------------------
0.001 W
×
REP 
51 W
=
LP MAX
(
)
dBm
LSENSI
20
D2
log
–
20
DREF
log
+
+
=
LP MAX
(
)
47*  dBm
51.5
20
128
log
–
20
30
log
+
+
=
85.9 dB
=
*50  W
REP =
10
90
10
+
(
)
20
128
log
(
)
20
30
log
–
41.5
–
+
[
]
10
----------------------------------------------------------------------------------------------------------
0.001 W
×
REP
12,882 W
=

262
Chapter 14
All three of these examples actually exist in the
market place and illustrate the necessity to monitor
both sensitivity ratings and efficiency values.
14.13.1 Loudspeaker Efficiency
You will often hear the specious argument, “Watts
are cheap, so don’t worry about loudspeaker effi-
ciency.” This might be partially true in very small
apartment living rooms but it is not true in profes-
sional sound work. To find the % efficiency when
the LEIA and Q are known, use:
(14-25)
For a Q of 7:
For a Q of 20:
For a Q of 3:
To find the EIA sensitivity from any sensitivity
rating use:
(14-26)
14.13.2 Conversions
• 4 ft = 1.219 m.
• 30 ft = 9.144 m.
• 3.281 ft = 1.0 m.
For an omnidirectional spherical radiator of 0.282m
(surface area = 1.0 m2), 1.0 W produces an LW , LI ,
and LP numerically equal to 120 dB.
Ratings
• %Effici for 1.0 m, 1.0 W sensitivity.
• %Effici for 4.0 ft, 1.0 W sensitivity.
• %Effici for 30 ft, 1.0 W sensitivity.
• %Effici for W/Pa/m sensitivity.
Calculations
For 1.0 W, 1.0 m:
(14-27)
For 1.0 W, 4 ft:
(14-28)
For 0.001 W, 30 ft:
(14-29)
For W/Pa/m:
(14-30)
Derivations
For 1.0 W, 1.0 m:
(14-31)
For 1.0 W, 4 ft:
(14-32)
For 0.001 W, 30 ft:
% Effici
10
LEIA
10
Q
log
–
59.78
–
10
--------------------------------------------------------
100%
×
=
% Effici
10
51.5
10
7
log
–
59.78
–
10
-----------------------------------------------------
100%
×
=
2.1%
=
% Effici
10
65.5
10
20
log
–
59.78
–
10
--------------------------------------------------------
100%
×
=
18.7%
=
% Effici
10
41.5
10
3
log
–
59.78
–
10
-----------------------------------------------------
100%
×
=
0.5%
=
LEIA
LSENSI
20
DMEAS
DREF
----------------
⎝
⎠
⎛
⎞
log
10
WREF
WMEAS 
------------------
⎝
⎠
⎛
⎞
log
+
+
=
% Effici
1
Q----
10
SENSI
10
-----------------
10.9
–
⎝
⎠
⎛
⎞
×
⎝
⎠
⎜
⎟
⎛
⎞
100
×
=
% Effici
1
Q----
10
SENSI
10
-----------------
10.728
–
⎝
⎠
⎛
⎞
×
⎝
⎠
⎜
⎟
⎛
⎞
100
×
=
% Effici
1
Q----
10
SENSI
10
-----------------
5.978
–
⎝
⎠
⎛
⎞
×
⎝
⎠
⎜
⎟
⎛
⎞
100
×
=
% Effici
1
Q----
10
94 dB
120
10.9
–
10
1 W
W/Pa 
---------------
⎝
⎠
⎛
⎞
log
–
–
10
---------------------------------------------------------------------------------------------
×
⎝
⎠
⎜
⎟
⎜
⎟
⎜
⎟
⎜
⎟
⎛
⎞
100
×
=
120
20
1 m
0.282 m 
---------------------
⎝
⎠
⎛
⎞
log
–
10
--------------------------------------------------------
10.9
=
120
20
1.219  m
0.282 m 
---------------------
⎝
⎠
⎛
⎞
log
–
10
--------------------------------------------------------
10.782
=

   
Designing for Acoustic Gain
263
(14-33)
For W/Pa/m:
(14-34)
14.13.3 100% Efficiency Values
100% Effici = 109 dB at 1.0 W, 1.0 m, Q = 1.
100% Effici = 107.29 dB at 1.0 W, 4 ft, Q = 1.
100% Effici = 59.78 dB at 0.001 W, 30 ft, Q = 1.
100% Effici = 0.031 W for 1 Pa at 1.0 m, Q = 1.
14.14 Summary
Increased gain requires power. The complex combi-
nation of acoustic gain, loudspeaker sensitivity, effi-
ciency, and required electrical power (manifested as
a voltage at the loudspeaker backed by a sufficient
current source) is a tapestry that properly woven
yields dynamic powerful audio.
Bibliography
H. S. Antman. “Extension to the Theory of Howlback in Reverberant Rooms,” J. Acoust. Soc. Am., Vol. 39
(Feb. 1966).
W. K. Connor. “Experimental Investigation of Sound-System-Room Feedback,” J. Audio Eng. Soc., Vol. 21
(Jan. 1973).
D. Davis. “Equivalent Acoustic Distance,” J. Audio Eng. Soc., Vol. 21 (Oct. 1973), pp. 646-649.
V. V. Furduev. “Limiting Amplification of Sound in Closed Rooms,” Soviet Phys.-Acoust., Vol. 11 (Jan.-Mar.
1966).
William B. Snow. “Frequency Characteristics of a Sound Reinforcing System,” J. Acoust. Soc. Am., (April
1955).
W. Symmes. “Simplified Method of Calculating PAG/NAG Formulas Without Use of Logs,” Syn-Aud-Con
Newsletter, Vol. 1., No. 2 (1973).
R. V. Waterhouse. “Theory of Howlback in Reverberant Rooms,” J. Acoust. Soc. Am., Vol. 37 (May 1965).
120
20
9.144 m
0.282  m
-------------------
⎝
⎠
⎛
⎞
log
–
10
1 W
0.001  W
--------------------
log
–
10
------------------------------------------------------------------------------------------------
5.978
=
1.0
10
LEIA
44.78* 
–
10
------------------------------------
⎝
⎠
⎛
⎞
-------------------------------------
* 94
10
0.001  W 
1 W
----------------------
⎝
⎠
⎛
⎞
log
20
1  m
9.144  m 
---------------------
⎝
⎠
⎛
⎞
log
+
+


Chapter 15
Designing for Speech Intelligibility
by Don Davis
265
15.1 Introduction  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 267
The Talker or Performer  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 267
The Microphone  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 267
The Electronics System . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 267
The Loudspeaker System  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 267
The Acoustic Environment  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 267
The Receiver-Listener . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 267
15.2 Articulation Losses of Consonants in Speech  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 268
Prediction, Measurements, and Anomalies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 268
Calculating %ALCONS  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 269
Usable Percentages  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 269
15.3 Maxfield’s Equation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 270
15.4  Speech Power and Articulation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 270
15.5 Signal-to-Noise Ratio (SNR)  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 271
15.6 Speech Intelligibility Calculations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 271
Calculating the Minimum Q  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 271
Calculation of the Maximum RT60  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 271
Factors Affecting %ALCONS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 272
Measuring Intelligibility  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 272
Evaluating Speech Intelligibility Measurements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 273
Causes of Reduced Intelligibility  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 274
15.7 Non-Acoustic Articulation Problems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 275
15.8 Relationship Between QMIN and D2(MAX)  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 276
15.9 High Density Overhead Distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 276
15.10 %ALCONS Variables . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 277
The Role of Q in %ALCONS  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 277
The Role of  
and Ma in %ALCONS  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 277
Choosing the Correct %ALCONS Equation  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 277
Using a 1/3 Octave RTA to Obtain %ALCONS  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 278
Detecting the Presence of Detrimental Reflections Without Analyzers  . . . . . . . . . . . . . . . . . . . . . . . . 278
Relationship Between Acoustic Gain and %ALCONS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 278
15.11 A Little History—Intelligibility Workshop 1986 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 278
The Results  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 279
15.12 Summary  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 279
Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 279
Sa


Designing for Speech Intelligibility
267
15.1 Introduction
The acoustic properties of rooms are basic to the
successful design of sound systems. In this chapter
we see that the ambient noise level in a room, the
relationship of the direct sound to the reverberant
sound level, and the reverberation time all affect the
intelligibility of speech. Sound apparatus can be
chosen and adjusted to optimize speech intelligi-
bility.
The complete sound reinforcement system
consists of:
1.
Talker or other performer.
2.
Microphone.
3.
Electronics system.
4.
Loudspeaker system.
5.
Acoustic environment.
6.
Receiver-listener.
15.1.1 The Talker or Performer
The performers are acoustic. They may use
electro-acoustic adjuncts such as electronic instru-
ments, guitars, and they may mix the input to the
sound system by direct injection as well as acoustic
inputs. The acoustic environment surrounding the
microphone is unique unto itself and deserves sepa-
rate analysis.
15.1.2 The Microphone
The microphone is an electro-acoustic transducer.
Directional characteristics meaningful in free field
can become meaningless in a reverberant sound
field. A microphone’s directivity is highly dependent
on the acoustic environment. If it is used beyond Dc
in a highly reverberant space it is essentially an
omnidirectional device so far as its ability to discrim-
inate against signals from loudspeakers, reflections,
etc. When the signal, that is, the talker or some
nearby performer, is within Dc, its directional charac-
teristics come into play.
15.1.3 The Electronics System
Here correct initial sensitivity choices for micro-
phones, careful gain structure and gain overlap, and
the choice of adequate power to realize the potential
acoustic gain desired can all be computed with great
accuracy.
15.1.4 The Loudspeaker System
The loudspeaker system is another electro-acoustic
transducer, which in many cases can act as both an
input and an output device. The interaction of the
driver and the applied coupling devices, horns, cross-
overs, etc., is a significant design choice.
15.1.5 The Acoustic Environment
It has been truly said that most sound system design
ends about 4 ft in front of the loudspeaker. In actual
fact, all sound system design should begin with the
analysis of the acoustic environment in which the
sound system is to operate. Noise levels, reverbera-
tion, delayed reflections, focusing, difficult geom-
etry, and a myriad of other difficulties in the
environment, must be recognized, analyzed, and
corrected or adjusted to compromise in the system
design.
15.1.6 The Receiver-Listener
Herein is the most challenging component. It can be
analyzed but you have no direct control over it. Inar-
ticulate talkers or handicapped listeners or some
combination of both may be insurmountable and
become the critics of your design.
Speech intelligibility centers on the 2 kHz octave
band and so does the peaked response at the
listener’s eardrums, see Fig. 15-1. Note that at
2500Hz the highest pinnae response is 72 dB and the
lowest is 58 dB or a 14 dB difference. In tests that we
conducted during an intelligibility workshop at
Indiana University, we found that a person with a
high pinnae response in the 2500 Hz region but with
a poor frequency response, will score higher on an
Figure 15-1. Composite of 30 left ears.

268
Chapter 15
intelligibility word test than the person with a low
pinnae response at 2500 Hz but with a near perfect
frequency response curve. This information was
gathered from 30 listeners that had very acceptable
audiometric charts of their hearing. The pinnae
response is largely due to the ear lobe configuration
and their individual ear canal resonances. Hearing
sensitivity, ear configurations that allow significant
differences between ears, and training in focusing
on speech can all provide very significant variations
in speech intelligibility scores in individual
listeners. For example, musicians will often ignore
high harmonic distortion in a recording but immedi-
ately detect a wrong note or a pitch due to wow or
flutter. Analysis of listeners is a psycho- acoustic
task and awareness of listener types—ministers,
choir directors, organists, allows “weighting” of
their testimony.
15.2 Articulation Losses of Consonants in 
Speech 
The articulation losses of consonants in speech
(%ALCONS) are deeply interwoven into the total
system design. They may be regarded as a separate
acoustic entity only when the entire electroacoustic
system is performing flawlessly. The widespread use
of analysis promises increasingly analytical psychoa-
coustic research. In the meantime, the Peutz equa-
tions have usefully extended the work of the early
pioneers of speech intelligibility to the point where
their everyday use has proven their accuracy and
practicality in sound system engineering.
15.2.1 Prediction, Measurements, and 
Anomalies
Sound system designers need to be able to predict
speech intelligibility, measure it accurately, and
understand the anomalies present in real environ-
ments that are not currently easily detected in
advance of measurements.
Key parameters affecting speech intelligibility are:
1.
Signal-to-noise ratio (SNR).
2.
Reverberation time (RT60), especially the level
difference between the direct level and the
reverberant level.
3.
Distance from the source.
4.
Source misalignments.
5.
Reflections under 1 ft of path length difference.
6.
Reflections that are late in time (100+ ms) and
higher in level than energy near them.
The first three parameters are predictable within
reasonable tolerances at the drawing-board stage.
The last three are classified as anomalies that occur
through oversight or error.
When the authors began their career in audio
there was no practical way to predict speech intelli-
gibility at the drawing-board stage of a sound
system design. By 1953 Harvey Fletcher had written
his remarkable book Speech and Hearing in
Communications which did provide the means of
measuring the intelligibility of a sound system
through the use of articulation testing developed at
the Bell Telephone Laboratories during the 1930s.
Lochner and Burger provided insight into the role of
signal-to-noise ratio (SNR) influence on speech
intelligibility in a 1964 paper in The Journal of
Sound and Vibration, Fig. 15-2.
Meaningful prediction at the drawing board stage
of articulation scores had to wait until 1971 when V.
M. A. Peutz published his equation for the percent of
articulation loss of consonants (%ALCONS) in speech.
Over a decade later, in the 1980s, Houtgast and
Steeneken published their adaptation of the modula-
tion transfer function (MTF) (first used in optics) to
Figure 15-2. Signal-to-noise influence on speech
intelligibility. (Courtesy Journal of Sound and Vibration.)
Lochner and Burger
where,
P(t) is the impulse response of the system,
a(t) is the weighing function for the hearing system's
  integration properties.
Modulation Transfer Function (MTF)
Houtgast and Steeneken Speech Transmission Index (STI)
Schroeder's MTF equation
SNR effective = ∫P2(t) a(t) dt
0
95 ms
∫P2(t) dt
95 ms
∞
MTF = ∫P2(t) e-jωt dt
0
∞
∫P2(t) dt
0
∞
In words, the MTF is proportional to the magnitude of the
  Fourier Transform of the squared impulse response.
J.P.A. Lochner and J.F. Burger, "The influence of Reflections
  on Auditorium Acoustics," Journal of Sound and Vibration,
  Vol. 1 (1964), pp. 426 - 454.
T. Houtgast and J.M. Steeneken, " A review of the MTF
  Concept in Room Acoustics and its use for Estimating
  Speech Intelligibility in Auditoria," Journal of the Acoustical
  Society of America, Vol. V (March 1985), p 77.
M. R. Schroeder, "Modulation Transfer Functions: Definition
  and Measurement," Acoustica, Vol. V (1981), p. 49.

Designing for Speech Intelligibility
269
the speech transmission index (STI). During that
same decade Peutz had evolved a most satisfactory
measurement that computed the %ALCONS from the
measured LD, LR, LN, and RT60. At the present time
only the Peutz equations allow a workable estimate
of %ALCONS at the drawing board stage, i.e., prior to
any measurement. The MTF technique is a usable
computation once actual measured data is obtained.
As of the year 2005 there are computer programs
that can model a room sufficiently to approximate
the impulse response of the proposed room. See
Fig. 15-2 for Lochner and Burger’s as well as
Mr. Schroeder’s MTF integral defining the Hoult-
gast-Steeneken technique.
For the reasons given here, we will concentrate
on the V. M. A. Peutz equations and their techniques.
They have the very real advantage of having soft-
ware available that directly computes the %ALCONS
from Envelope Time Curve (ETC)* measurements.
At this time, TEF analyzers are the most widely
available analyzer in the hands of working sound
contractors and acoustic consultants and allow, with
existing programs, both the prediction and measure-
ment of %ALCONS with the same unit.
When we talk, the sounds we make can be
broadly classified into consonants and vowels. The
vowels are a, e, i, o, and u. Combinations like ba, pa,
da, ta, ga, and tha contain consonant sounds.
V. M. A. Peutz spent a number of years resolving
that the percent of articulation loss of consonants
determined the articulation score in various acous-
tical spaces. Formulas for %ALCONS, the articulation
loss for consonants as a percentage, were then
developed and published by V. M. A. Peutz and
W. Klein of Nijmegen, Holland, in the December
1971 Audio Engineering Journal. The formulas
have been adapted for this text by adding Q and
presenting all their alternative forms. They can be
useful in matching the room to the sound system.
15.2.2 Calculating %ALCONS
The formula for calculating the articulation loss of
consonants as a percentage is:
(15-1)
where,
D2 is the distance from the loudspeaker to the
farthest listener,
RT60 is the reverberation time in seconds,
V is the volume of the room in cubic feet,
Q is the directivity ratio,
N is the power ratio of LW causing LD to the LW of all
devices except those causing LD,
M is the Dc modifier (usually 1 is chosen except in
special instances).
The above formula is used for D2 ≤ DL, and
DL = 3.16 Dc. When D2 ≥ DL, the formula becomes:
(15-2)
NOTE: It is necessary to assume a required SNR
of 25 dB at the 2 kHz octave band to make these
calculations valid. When meters are used for
distances and volumes, the constant becomes 200.
15.2.3 Usable Percentages
Mr. Peutz states, “If the AL is below 10%, the intelli-
gibility is very good. Between 10 and 15%, the intel-
ligibility is good and only if the message is difficult
and the speaker (talker) and/or listeners are not good
will the intelligibility be insufficient. Above 15% the
intelligibility is only sufficient for good listeners
with speakers (talkers) and/or messages.”
In comparing Peutz’ method with known data
from many installations, an ALCONS of 15% is
considered to be a practical working limit, yet many
feel that one should strive for nothing more than
10%. The basic formula can be converted into the
following useful forms:
(15-3)
(15-4)
(15-5)
(15-6)
*The ETC is related to a well-established
concept in communication theory known as the
modulation envelope. The ETC is the magni-
tude of the analytic signals description of the
impulse response.
%ALCONS
656D2
2RT60
2 N
(
)
VQM
------------------------------------------
=
%ALCONS
9RT60
=
Max D2 for 15% ALCONS
15VQM
656 RT60
2 N
(
)
----------------------------------
=
Max RT60 for 15% ALCONS
15VQM
656 D2
2 N
(
)
-----------------------------
=
Min V for 15% ALCONS
656D2
2RT60
2 N
(
)
15QM
------------------------------------------
=
Min Q for 15% ALCONS
656D2
2RT60
2 N
(
)
15VM
------------------------------------------
=

270
Chapter 15
For a room with a volume of 250,000  ft3 (a
medium-sized church) with a D2 = 75 ft and for
which a single horn with a Q = 20 has coverage
angles that fit the audience areas, we could calculate
the number of sabins we would like to have in the
room by
and:
15.3 Maxfield’s Equation
Peutz’ formula was adapted to their data from one
used by Western Electric’s J. P. Maxfield for finding
the “liveness” of a microphone pickup for broad-
casting use in the late 1930s.
(15-7)
where,
DS is the distance from the talker to the microphone.
Acceptable values of L for speech range from
0.167 to 0.666. This equation can be manipulated in
the same manner as the Peutz and Klein formula.
(15-8)
(15-9)
(15-10)
(15-11)
15.4  Speech Power and Articulation
There are two primary frequency response parame-
ters of speech that require consideration by the sound
system engineer. The first is the speech power as a
function of frequency. Fig. 15-3 shows the typical
distribution on a per cycle basis over the range
60–10,000 Hz for both men and women, and the
ANSI curve (the third spectrum available from the
GR 1382 RNG) is included for reference.
It is the spectrum shape that is important here as
it gives an excellent idea of which frequencies will
most likely receive the greatest power demands and
the differences likely between one frequency and
another in dB.
The second parameter is the relative contribution
to intelligibility of each 1⁄3 octave band expressed as
a percent of contribution to the articulation index,
Fig. 15-4. Adding the percent contribution of each
of the bands shown between 200 Hz and 4000 Hz
equals 91.5% of the total contribution. The largest
percentage, by far, is the 31.5% contribution in the
1.0 octave band centered on 2000 Hz. It can be seen
why the telephone with its limited response works
so well as do small radios with well-designed
4–8 inch loudspeakers covering the range of
125–5000 Hz.
It is of much greater importance to provide very
smooth frequency response rather than extended
frequency response and to control or eliminate
specific nonlinearities in transducers that give rise to
resonances, distortions, and other forms of color-
ation over the chosen response. When comparing a
wide range high fidelity music system to a
table-model radio, few realize how little difference
the increased frequency response makes as
compared to the differences in smoothness of
Max RT60
10% 
V
×
Q
×
656
D2
2
×
---------------------------------
=
Max RT60
10% 
250,000
×
20
×
656
75
×
2
--------------------------------------------------
=
3.7 s
=
Sa
0.049V
RT60
-----------------
=
0.049
250,000
×
3.7
---------------------------------------
=
3311 sabins
=
L
1000 RT60
2DS
2
VQ
--------------------------------------
=
Max DS
LVQ
31.6 RT60
------------------------
=
Min Q
1000 RT60
2DS
2
VL
--------------------------------------
=
Min V
1000 RT60
2DS
2
LQ
--------------------------------------
=
Max RT60
LVQ
31.6 DS
-------------------
=
Figure 15-3. Relative speech power as a function of
frequency for men and woman. (Courtesy Journal of the
Acoustical Society of America.)
ANSI curve
Composite for
six men
Composite for
five women
0 dB = 1 μW
50    100   200       500    1K      2K        5K  10K
−10
−20
−30
−40
−50
Frequency–Hz
Total speech power per Hertz—dB

Designing for Speech Intelligibility
271
response through the very critical area from
250–5000 Hz.
Fig. 15-4 also confirms that if you can have the
Q, RT60, or sabins data at only one frequency, that
one frequency should be the octave or 1⁄3 octave
band centered on 2000 Hz.
15.5 Signal-to-Noise Ratio (SNR)
Fig. 15-5 illustrates the effect of signal-to-noise
ratio, SNR, on the %ALCONS. The %ALCONS improves
steadily with improving SNR until it reaches 25 dB.
After that, the articulation does not improve as the
SNR is further extended.
This chart reveals that in rooms with an RT60 of
1.5 s, we would not want to accept an SNR of less
than 25 dB. However, in a room of RT60 = 0.5 s, we
could maintain a %ALCONS of 15% with only an
11dB SNR.
15.6 Speech Intelligibility Calculations
15.6.1 Calculating the Minimum Q
Given a room for which V = 150,000  ft3 and
RT60 = 1.92 s, we can now calculate the minimum Q
that will allow an ALCONS of 15% at 125 ft in this
room.
or
Therefore, if you can locate a loudspeaker with
proper angular coverage specifications that also has
Q ≥ 16.8, you can be sure of acceptable articulation
at 125 ft.
There have been many striking confirmations of
the accuracy of these formulae.
15.6.2 Calculation of the Maximum RT60
Fig. 15-6 illustrates the %ALCONS formulas in a
simplified form. (The equations describe a curve,
whereas the graph is a conservative straight-line
approximation of the formula.) Referring again to
Fig. 15-6, we see a baseline along the bottom
expressing the source to listener distance in units of
DL. DL is the limiting distance beyond which no
further increase in articulation loss occurs. For a
given acoustical environment, the limiting distance is
related to the critical distance by
(15-12)
The left-hand vertical scale is %ALCONS cali-
brated in percent, and the right-hand vertical scale is
RT60 calibrated in seconds. Here we note that articu-
lation losses continue to increase until DL is reached.
Figure 15-4. Variation of an articulation Index contribu-
tion with speech components in 1⁄3 octaves.
31    63   125   250  500    1K    2K    4K     8K 16K
Midfrequencies of 1/3 octave band–Hz
12
10
8
6
4
2
0
1/3 octave band contribution to articulation index
Min Q
656D2
2RT60
2
15V
---------------------------------
=
Figure 15-5. Effect of SNR on %ALCONS at DL.
−10   −5       0      5      10    15    20     25    30 
100
2
5
10
20
50
%ALCONS
10.0
9.0
8.0
6.0
5.0
4.0
3.5
3.0
2.5
2.0
7.0
1.5
1.0
0.75
0.50
0.25
RT60–s
SNR–dB
Min Q
656
1252
×
1.922
×
15
150,000
×
----------------------------------------------
=
16.8
=
DL
3.16DC
=

272
Chapter 15
Beyond DL, the articulation losses remain constant.
Therefore, if we had a room with RT60 ≤1.6 s and
SNR of 25 dB, we could go any distance from the
sound source without exceeding an ALCONS of 15%.
Suppose, however, that we keep the SNR of
25 dB, but RT60 is now 4.5 s. We would follow
downward between the slanting lines corresponding
to 4 and 5 until we intersected the 15%ALCONS hori-
zontal line (or any other value of %ALCONS being
sought), and then drop straight down to the base line
at 0.61 DL. This would now be the new maximum
distance from the source for which the articulation
loss would be 15%.
Still another use of these very helpful equations
is the determination of the limiting room parame-
ters if an architect prefers a specific loudspeaker
array for esthetic reasons. Say the architect has
chosen a certain loudspeaker that has a Q = 5 and is
designing a building having a maximum distance
between the preferred loudspeaker location and the
farthest listener of 150 ft. You can then use the equa-
tions to inform him of the maximum RT60 that will
allow an ALCONS of 15% at 150 ft from a loud-
speaker with Q = 5. (Assume V is 150,000 ft3.)
Using Eq. 15-12 for calculating DL and if 
 for this
room is
The desired distance falls outside DL, and the value
of ALCONS is 15% only because the limit 1.6 s was not
exceeded.
15.6.3 Factors Affecting %ALCONS
The %ALCONS at a listener is dependent upon LD, LR,
LN, RT60. It is also dependent upon a too-early or
too-late return of reflected energy. A too-early return
is usually under 3 ft and a too-late return is usually
over 50 ft. The distance traveled or the signal delay is
not the only factor. The amount of interference detri-
mental to %ALCONS is also very “level” dependent. A
too-early return that is visible on the analyzer, and
audible to the ears will alter the amplitude response
of the system and its polar response. A too-late
return capable of interference will stand out above
the normal exponentially decaying reverberation.
Much as the acoustic gain equations are made
valid by the use of an equalizer when an amplitude
aberration appears, so these too-early and too-late
reflections are detected by measurements analysis
and corrected by more careful placement of devices
or selective absorption or diffusion.
The general case %ALCONS equations work quite
well provided no extraneous parameters such as the
above go undetected at installation time.
15.6.4 Measuring Intelligibility
Prior to any measurements the area to be measured
needs to be walked and listened to. Cup your ears to
Figure 15-6. %ALCONS as a function of source distance
in units of DL for various values of RT60.
100
70
50
30
20
15
10
7
5
3
2
1.5
10.10    0.15  0.20     0.30       0.50   0.70    1.00    1.50
10.0
9.0
8.0
7.0
6.0
5.0
4.0
3.0
2.0
1.5
1.0
0.75
0.50
0.25
%ALCONS
RT60−s
1.0 DL = 3.16 Dc
Max RT60
15VQ
656 D2
2
--------------------
=
15
150,000
5
×
×
656
1502
×
 
-----------------------------------------
=
0.873  s
=
Sa
Sa
0.049V
RT60
-----------------
=
0.049 150,000
(
)
0.873
--------------------------------------
=
8419 sabins
=
DL
3.16
0.141
×
5
8419
×
=
91  ft
=

Designing for Speech Intelligibility
273
listen for focused reflections. Listen for high noise
levels, lack of coverage, and any other anomaly.
Intelligibility has to be investigated coverage area by
coverage area.
Commissioning a sound system without full
analysis that its speech intelligibility has been maxi-
mized is irresponsible. Audience areas should be
carefully walked with speech information on the
sound system (counting is very good), and question-
able areas subsequently measured and corrected.
Only then can you assuredly say this system is ready
for use. The authors subscribe to the view that the
most capable analyzer is still a trained pair of human
ears, but “a trained pair of human ears” comes when
ears have been calibrated by hours of listening
coupled with using good measurement tools.
The trained listener has extraordinary capabilities
not matched by any known measurement device.
Take, for example, the oscilloscope, wave analyzer,
etc., we can never be sure if its speech, music, or
some randomly generated signal, but the connection
of an inexpensive 2 inch loudspeaker will allow the
listener to instantly determine which type of sound
is present.
When a sound system has intelligibility problems
in a given acoustic environment, the first test to
make is to turn the sound system off and see if the
same problems exist for a “live” talker. A live talker
can be assumed to have a Q = 2.5 at the 2kHz octave
band with a coverage angle of 90° vertically by 120°
horizontally for the same 2 kHz octave band.
Many mistake speech quality with speech intelli-
gibility. It is important to separate judgment of
sound quality from the issue of speech intelligibility.
Speech intelligibility is defined by the score attained
by live listeners to a live talker over the system in
question. Sometimes intelligibility is sacrificed in
order to present a wider bandwidth to the listener.
Aircraft radios have high speech intelligibility but
relatively strident sound quality. Speech over the
telephone is intelligible but not necessarily wide
range fidelity to the nuances of a given voice.
Current measurement tools quantify only the speech
intelligibility score. Quality, a subjective judgment,
remains with the installer-user decision making.
When the design revolves around an existing
building the time and expense of making measure-
ments is very worthwhile. An ideal measurement
technique is to take a portable hoist to the site, raise
a loudspeaker of known directivity, and both talk
and measure under and beyond critical distance, Dc.
A great deal of room analysis is done with
impulse testing utilizing essentially omni-directional
sources in order to maximize the excitement of the
space. Since the goal of a successful sound system is
the minimum excitation of the room, all measure-
ments should use likely devices, on portable lifts, if
necessary, to test from the proposed loudspeaker
locations. In existing systems all tests should be
conducted with the entire system in operation—one
of the few times everything should be turned on at
the same time when setting up the sound system.
Far too often measurements are made and correc-
tions are undertaken without someone having stood
in the presenter’s position and talked unaided to the
room. Often it is revealed that the room is unblem-
ished and the deprecation of the sound quality and
speech intelligibility over the sound system is due to
the sound system itself. The authors have witnessed
too many sound systems that raised the sound level
but lowered the intelligibility.
In the past the only way to measure intelligi-
bility was to use lengthy word lists and a group of
live listeners. Elaborate testing procedures grew up
around such processes and only on rare occasions
was an effort made to actually check real life sound
systems. Today we have very accurate and rapid
methods of measuring intelligibility with acoustic
instruments:
1.
The Percent of Articulation Loss of Constants,
%ALCONS.
2.
The Speech Transmission Index, STI, Fig. 15-7.
15.6.5 Evaluating Speech Intelligibility Measure-
ments
STI, Speech Transmission Index, measurements are
a go-no-go-type analysis. They tell you there is a
problem but do not contain any analysis of the cause
or causes. If SNR happens to be the problem, STI
works adequately.
The TEF analyzer’s %AlCONS measurements are
more complex to make and to evaluate but they do
contain the evidence necessary to allow the cause or
causes to be isolated. Fig. 15-8 shows how to
convert STI measurements to %AlCONS. Expecting
close correlations between SI estimates and real life
listeners is overly optimistic. Fine tuning of sound
systems for maximum SI is done by ETCs, with
careful attention to signal synchronization and
equalization of the direct sound.
The ETCs obtained in this manner should, in a
properly designed sound system, have no early
reflections, under 10 ms. The proper place to divide
direct from reflected sound is to measure only the
direct sound. It is my opinion, though controversial,
that early reflections under 30 ms of the direct sound
do not aid intelligibility. They do raise the sound
level perceived. To the best of my knowledge, it has

274
Chapter 15
not been shown that the brain integrates early reflec-
tions except as loudness.
The Envelope Time Curve, ETC, is a very useful
way to obtain data relative to speech intelligibility.
Not only are ETCs reliable ways to gather LN, LD,
LR, and RT60, but at the same time view the actual
cause, if any, of poor intelligibility. Easily seen on
the ETC screen is whether the causes are statistical,
specific, or mixed.
As we have seen in our study of large-and
small-room acoustics, the statistical basis behind the
use of Sabinean-based equations is no longer valid
when the reverberation time becomes small. Neither
is prediction based upon those equations when used
in such spaces. Fortunately, when the Sabi-
nean-based equations are no longer valid, we are in
an acoustical environment that cannot harm intelli-
gibility through reverberation.
15.6.6 Causes of Reduced Intelligibility
1.
Poor SNR.
2.
Excessive reverberation (i.e., reduces LD – LR).
3.
Specific long, delayed, high-level reflections.
4.
Loudspeaker misalignment between alike devices.
5.
Lack of synchronization (electronic).
6.
Misequalization.
7.
Poor quality devices (i.e., low Q when high Q is
needed).
8.
The distance from the source (i.e., increase
LD – LR by shortening D2).
Following are some of the methods to correct the
problems causing reduced intelligibility.
SNR and Excessive RT60. The sound system engi-
neer should have handled SNR by specifying a
reasonable noise criteria (NC) curve as well as a suit-
able RT60 for octave bands 500Hz, 1 kHz, and 2kHz.
Specific Reflections. Correcting specific long,
delayed, high-level reflections becomes a matter of
loudspeaker placement and/or orientation. Only in
rare cases is it a matter of room treatment.
Synchronization. Synchronization is usually used
when electronic means are employed, usually a
digital delay device, to synchronize two devices that
must be physically separated but must be
Figure 15-7. STI intelligibility measurement. (Courtesy
B & K Instruments.)
   STI Intelligibility Measurement.
Speech Transmission Index, STI, is a method of
quan tifyin g t he in tellig ibil ity  of trans mitted
speech. Perfect transmission of speech implies that
the temporal speech envelope at the listener’s posi-
tion replicates the speech envelope at the speaker’s
mouth. Speech intelligibility can be quantified in
terms of the changes brought about in the modula-
tion of the speech envelope as a result of noise and
reverberation in the room. 
The reduction in modulation can be described by a
modul ati on red uction factor. The modu lation
reduction factor expressed as a function of modu-
lation frequency is called the Modulation Transfer
Function, MTF. This function provides an objec-
tive means of assessing the quality of the speech
transmission, and from it, the STI value is derived.
Both measurement metho ds are indep endent of
statistical prediction as both measure in one form
or another the modulation of the signal caused by
whatever is helping or reducing the intelligibility.
Transmitted Speech Signal
Modulation Index = 1
Received Speech Signal
Modulation Index = m < 1t
t
t
1/f
1/f
Figure 15-8. Converting STI measurements to
%ALCONS. (Courtesy Farrel Becker.)
 
STI 
%ALCONS 
 
STI 
%ALCONS
 
0.20 
57.7 
 
0.60 
6.6
 
0.22 
51.8 
 
0.62 
5.9
BAD 
0.24 
46.5 
       GOOD 0.64 
5.3
 
0.26 
41.7 
 
0.66 
4.8
 
0.28 
37.4 
 
0.68 
4.3
 
0.30 
33.6 
 
0.70 
3.8
 
0.32 
30.1 
 
0.72 
3.4
 
0.34 
27.0 
 
0.74 
3.1
POOR 0.36 
24.2 
 
0.76 
2.8
 
0.38 
21.8 
 
0.78 
2.5
 
0.40 
19.5 
 
0.80 
2.2
 
0.42 
17.5 
 
0.82 
2.0
 
0.44 
15.7 
 
0.84 
1.8
 
0.46 
14.1 
 
0.86 
1.6
 
0.48 
12.7 
  EXCELLENT 0.88 
1.4
 
0.50 
11.4 
 
0.90 
1.3
FAIR 
0.52 
10.2 
 
0.92 
1.2
 
0.54 
9.1 
 
0.94 
1.0
 
0.56 
8.2 
 
0.96 
0.9
 
0.58 
7.4 
 
0.98 
0.8
 
 
 
 
1.00 
0.0
ALCONS = 170.5405 × e(−5.419 × STI)
STI = [−0.1845 × ln(%ALCONS)] + 0.9482
i.e.: [−0.1845 × ln(10.2)] + 0.9482 = 0.52
170.5405 × e(−5.419 × 0.52) = 10.2%

Designing for Speech Intelligibility
275
acoustically brought into identical arrival times at the
listener’s ears, Figs. 15-9, 15-10, and 15-11.
Misalignment. Loudspeaker misalignment of alike
devices is probably the most common cause of
reduced intelligibility of sound systems. Misalign-
ment causes spurious lobes to be radiated by the
loudspeakers, which can excite wall surfaces. This
causes an increase in the level of the reverberant
sound field.
Misequalization. Misequalization also occurs more
often than would be suspected. The missetting of
levels often associated with the misuse of equalizers
can result in intelligibility reduction because of
premature distortion occurring ahead of the power
amplifier.
Improper Q and Coverage Angles. There are loud-
speakers in use today that have low intelligibility
outdoors, to say nothing of their performance in a
difficult acoustic environment. The most frequent
misuse of devices is to use, in a reverberant space, a
Q that is too low.
Distance from the Source. When all else fails,
reducing the distance from the source to the listener
will solve the problem. We have never been in an
environment, where it’s legal to work, that you could
not communicate face to face.
15.7 Non-Acoustic Articulation Problems
Mispolarization of electronic components, mis-
equalization of electronic components, or spurious
Figure 15-9. Show the before and after ETCs as
measured in the audience area as a result of signal
aligning (synchronizing) two horns. The measurements
were made in the overlap area of the two devices.
A. Between a far throw and near throw horn
misaligned by 300 Ms.
B. With a precision signal delay device correcting
300 Ms misalignment (note increase in LD.)
Figure 15-10. Shows the before and after frequency
response in the overlap area.
B. Signal alignment used to delay the near throw
horn 300 ms.
A. Two horns on at the same time.

276
Chapter 15
oscillations due to miswiring or misgrounding can all
lead to significantly reduced intelligibility.
The %AlCONS equations presume that a properly
designed, properly installed system is at hand and
that the only remaining parameters to be considered
are those in the acoustic environment. When there is
poor intelligibility it is more often due to system
problems than it is to acoustic environment problems.
15.8 Relationship Between QMIN and D2(MAX)
It is not unusual to find that the QMIN(SS) does not
provide the necessary C∠s required for even
coverage of the audience area. If more than one
device is to be tried at the original single source loca-
tion (i.e., a “long throw” device of higher Q and a
“short throw” device of lower Q), then the proce-
dure is to increase QMIN(SS) by N times.
QMIN(long throw) = NQMIN (SS)
(15-13)
The Q of “short throw” horns is found by:
(15-14)
Dividing by a factor of four results in a
short-throw device that has an on-axis level 6 dB
lower than the long throw device for the same power
input. It is important to note here that the LR is deter-
mined by the power output of the devices and not by
their sensitivity ratings. In a real reverberant sound
field we want equal power contribution from each
device. In a free field situation, you can vary the
actual power to the device to obtain desired levels
since your listener hears essentially only LD. It can
be disastrous to %ALCONS to vary power inputs to
devices in a truly reverberant space.
When NQMIN(SS) exceeds a realizable value, we
resort to shortening D2. When this option is called for,
we usually choose a device with desirable coverage
characteristics without paying undue attention to its
Q. We then find N for the devices chosen by:
(15-15)
Because N is increased and Q is not increased, we
calculate a new D2(MAX)
(15-16)
This type of system has substituted a shorter D2
for a required NQ(SS) and has maintained the D/R or
LD − LR required for the %ALCONS involved. Signal
delay is usually employed and the listener in the
audience area receives a signal undistinguishable
from a multiple device array at a single point.
Failure to either increase Q or shorten D2 when N is
increased can dramatically affect %ALCONS.
15.9 High Density Overhead Distribution
Multiple sources generate “comb filter” amplitude
responses. Interestingly, however, if enough sources
are employed, the peaks of one comb filter response
tend to fill the void of another comb filter response
and our resultant curve smooths out. D2 can, on rare
occasions, become so short that the only answer
becomes “pew back” loudspeaker systems (i.e., loud-
speakers mounted in the back of pews or seats,
usually with one loudspeaker for every two or three
listeners).
Figure 15-11. Shows the effect in the same audience
area of the polar responses before and after alignment
(synchronization).
A. Out of physical alignment by 3 inches.
B. In physical alignment.
QMIN short throw
(
)
NQMIN SS
(
)
4
--------------------------
=
N
QMIN SS
(
)
Qavail
----------------------
=
D2 MAX
(
)
D2 SS
(
)
N
---------------
=

Designing for Speech Intelligibility
277
15.10 %ALCONS Variables
15.10.1 The Role of Q in %ALCONS
Fig. 15-12 illustrates the effect for a loudspeaker
with a Q = 1, a loudspeaker with a Q = 5, and a loud-
speaker with a Q = 50. The effect of such dramatic
changes in LD − LR may or may not have dramatic
effect on %ALCONS. Once the reverberant sound field
level has dropped below a certain point, it, like SNR,
no longer really has any effect on the calculations or
measurements at hand.
15.10.2 The Role of 
 and Ma in %ALCONS
When the LD − LR is too negative a value, it can be
altered by either changing LD (i.e., increase Q or Me
thus allowing LW hence LR to be lowered, or decrease
D2) or by changing LR by lowering N or increasing
Ma or 
. Whenever given the opportunity to
increase 
 (assuming such an increase is needed),
always do so first in a manner that directly increases
Ma unless some special constraint such as a distant
echo demands priority. Remember that in terms of
%ALCONS we prefer diffusion of the far reverberant
sound field more than absorption as a means of
altering its level; the Ma factor eliminates early
reflections of potentially dangerous short intervals
while at the same time reducing the acoustic power
sent to the far reverberant sound field.
15.10.3 Choosing the Correct %ALCONS 
Equation
The Hopkins-Stryker equation provides an orderly
analysis of LW , Q, DX, Me, N, 
 and Ma and their
contributions to LD and LR.
1.
LD is dependent upon LW , Q, Dx, Me.
2.
LR is dependent upon 
, Ma, N, LW .
Therefore, we prefer the original Peutz equation
for design purposes when at the drawing board stage
as it keeps us in mind of the same key parameters:
D2, Q, Me, Ma, N, and RT60 (contains 
).
If the building already exists or we are at the
installation checkout stage, then the equations are
our choice because their parameters are instantly
accessible via analysis:
Sa
Sa
Sa
Sa,
Sa
Sa
Figure 15-12. The role of Q in %ALCONS.
C. Q = 50.
A. Q = 1.
B. Q = 5.

278
Chapter 15
(15-17)
where,
LD is the direct sound level in dB expressed as a
power ratio 
,
LR is the reverberant sound level in dB expressed as
a power ratio 
,
LN is the ambient noise level in dB expressed as a
power ratio 
,
RT60 is the reverberation time in seconds for 60 dB
of decay,
ALCONS is the articulation loss of consonants
expressed as a fraction.
15.10.4 Using a 1/3 Octave RTA to Obtain 
%ALCONS
LD, LR, LN , and RT60 are also accessible through the
use of conventional analyzers, albeit with some extra
calculations. By measuring LD near the source (“near
the source” being defined as at least 10 dB above
Dc), it can be extrapolated by inverse square law
attenuation to the desired D2. By measuring LT at D2
and LN we can get an excellent idea of the LR by:
(15-18)
The RT60 is obtained in the usual manner.
15.10.5 Detecting the Presence of Detrimental 
Reflections Without Analyzers
If, in an otherwise acceptable environment, you find
an audience area with unacceptable %ALCONS, a very
useful tool is a panel of 4 inch “Sonex” with dimen-
sions of approximately 4 ft × 4 ft. While someone
“talks” the sound system, move the Sonex panel
around the listener—above the listener, behind the
listener, to the side of the listener, etc. Sometimes
dual reflections are responsible and blocking at least
two paths is advisable. Many first time users of this
technique are startled at how dramatically %ALCONS
can improve as the Sonex panel intercepts the
offending delayed signal that has too high a level for
its arrival time.
One of the benefits of the recent practice of
making the first three to four feet surrounding the
loudspeaker grille as absorbent as possible is the
elimination of many too early reflections (absorbent
here means at the specular frequencies; such absorp-
tion is not active at the lower frequencies where, due
to their wavelength, hard surfaces are not as
detrimental).
15.10.6 Relationship Between Acoustic Gain and 
%ALCONS
Not only does the SNR constrain the maximum
equivalent acoustic distance (EAD), but when there
is failure to provide the necessary feedback stability
margin (FSM) (6 dB as a minimum), then the sound
system will be operated too near regeneration with
the consequent result of nonlinear behavior of the
peak energies. Coloration of this type is clearly
audible and as a result %ALCONS suffers.
15.11 A Little History—Intelligibility Work-
shop 1986
In the late summer of 1986 a major workshop on
Speech Intelligibility was held under the auspices of
Synergetic Audio Concepts with major participating
manufacturers. Over 100 attendees participated in
tests at three sites using three different sound
systems at each site. One site was a reverberant
Catholic cathedral, the second a national monument
pre-sound film theater that had ideal speech acous-
tics due to its low noise, low reverberation environ-
ment. The third site was a new university concert
hall with questionable geometry and severe speech
intelligibility problems. At each site one sound
system was low Q (1), a medium Q (approximately
7.0), and a high Q (over 25).
Three groups of thirty each took classic speech
intelligibility tests in each of the three sites over
each of the three systems. The intelligibility
measurements were made using subjective word
tests and Modified Rhyme Tests, MRT tapes by
Dynastat. This was followed by TEF measurements
and the B&K, then new RASTI instrument. All tests
were monitored by three world renowned acoustical
consultants, Rollins Brooks, David Klepper, and
Victor Peutz plus the engineering personnel from
the participating manufacturers.
0.32
LR
LN
–
(
)
log
–
10LD
LR
LN
+
+
----------------------------------------------
A
=
0.32
LN
10LR
LN
+
-------------------------
RT60
12
------------
2
------------
log
⎝
⎠
⎜
⎟
⎜
⎟
⎛
⎞
log
–
B
=
10 2
A
B
+
(
)
AB
–
[
]
–
0.015
+
ALCONS
=
LD
10 dBD
(
) 10
⁄
=
LR
10 dBR
(
) 10
⁄
=
LN
10 dBN
(
) 10
⁄
=
LR
10
10
LT 10
⁄
10
LD 10
⁄
–
10
LAMB 10
⁄
–
(
)
log
=

Designing for Speech Intelligibility
279
15.11.1 The Results
1.
Lobing that strikes multiple reflective surfaces in
reverberant spaces is detrimental to intelligibility.
2.
When well-behaved devices were used the orig-
inal Peutz equation is remarkably accurate.
3.
RT60 measurements should be of the Schroeder
integration type.
4.
High Q is only beneficial if aimed at listeners
(absorptive). It is not beneficial aimed at walls,
etc.
5.
10% is really about the maximum loss accept-
able. Designing for 15% loss of constants sans
audience usually results in 10% with audience.
6.
The N factor is directly detrimental as it increases.
7.
Delayed reflections at levels above that for other
energy in the same zone are detrimental.
8.
The signal-to-noise ratio, SNR, is vital to both
prediction and measurement of speech intelligi-
bility and should be at least 25 dB for the one
octave band centered at 2 kHz.
9.
Early returns, within 3 ft, at levels equal to or
greater than the direct sound do affect speech
intelligibility.
10. Misalignment and missynchronization measur-
ably affect speech intelligibility.
11. High quality sound and high intelligibility are
separate goals and not necessarily coincident.
12. In order to predict intelligibility scores you must
have accurate, truthful, pertinent technical infor-
mation. Q, directivity factor, is useless unless
accompanied by truthful polar data for the
region from 250 to 3000 Hz.
We wrote following the 1986 workshop that we
sincerely doubted that a like-sized effort of this type
would be made again and at this time, that is true.
15.12 Summary
You have become acquainted with calculating sound
attenuation and level change under a variety of
circumstances and have further found a way to calcu-
late the effects of reverberation, directivity, and
sound level on articulation losses at the listener’s
ears. TEF analysis, STI measurements, constant
directivity loudspeakers, precision 10 µs signal
delays, and an increasing understanding of the phys-
ical parameters underlying speech intelligibility in
sound systems are leading the way to significantly
improved speech reinforcement systems.
Bibliography
Don Davis and Carolyn Davis. “Application of Speech Intelligibility to Sound Reinforcement,” J. Audio Eng.
Soc., Vol. 37, No. 12 (Dec. 1989).
H. Fletcher. Speech and Hearing in Communication. New York: Van Nostrand, 1953.
W. Klein. “Articulation Loss of Consonants as a Basis for the Design and Judgement of Sound Reinforcement
Systems,” J. Audio Eng. Soc., Vol. 19 (Dec. 1971).
V. M. A. Peutz. “Speech Reception and Information,” Syn-Aud-Con Tech Topic, Vol. 5, No. 12 (1978).
__________. “Articulation Loss of Consonants as a Criterion for Speech Transmission in a Room,” J. Audio
Eng. Soc., Vol. 19 (Dec. 1971).


Chapter 16
What is Waving and Why
by Eugene Patronis, Jr.
281
16.1 General Properties of Air . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 283
16.2 Plane Waves . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 288
16.3 Non-Planar Wave Motion in a Tube  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 297
16.4 Plane Wave Tubes having Arbitrary Terminations  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 299
16.5 Impedance Tube . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 303
16.6 More General Waves  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 305
Pulsating Sphere  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 305
16.7 Acoustic Intensity  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 308
16.8 Boundaries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 309
16.9 Acoustic Dipole  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 310
Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 311


What is Waving and Why
283
Unlike electromagnetic waves that can exist in a
vacuum as well as in material substances, sound
waves are mechanical waves and require a material
medium in which to exist. The medium may be either
a solid such as a bar of steel or a fluid such as water
or air. Fluids are distinguished from solids in that a
fluid will assume the shape of the container in which
it is placed. If the fluid in question is a liquid of small
volume, however, it will not occupy all of the space
provided by a container of larger interior volume
whereas a gaseous fluid will occupy all of the interior
space provided by the container. In the process of
doing so, the pressure, temperature, and the energy
content of the gas must undergo adjustments to make
this possible. The objective here is to learn in a
fundamental way that wave properties such as speed,
dispersion, momentum transfer, energy transport, and
guidance depend upon both physical law and the
properties of the host medium. Along the way we
will encounter all of the familiar wave properties
such as interference, diffraction, and refraction as
well as phase and group velocity. It is a fact that air
borne sound plays a dominant role in sound rein-
forcement and room acoustics so we will begin our
study with air considered to be the supporting
medium for our treatment of sound waves.
16.1 General Properties of Air
Air is a mixture of several different gaseous compo-
nents with the principal ones being displayed in
Table 16-1 as molecular fractions of the total
composition. The numbers displayed as decimal
fractions are for dry air. Normal air also contains
water vapor. This does not appear in the table, as it is
a varying quantity depending upon the weather
conditions. The major acoustic influence of the
moisture content of air is that of a frequency depen-
dent conversion of sound energy into heat. This
process will be described at the appropriate time.
Note that if you sum the fraction column the
result will be slightly less than one. The reason for
this is that dry air also contains trace amounts of
hydrogen, helium, neon, krypton, xenon, radon, and
methane. The fractions presented in the table are the
molecular fractions rather than the mass fractions.
This means that if you take a sample of dry air at sea
level 78.040% of the molecules in the sample will be
diatomic molecules of nitrogen while 20.946% will
be diatomic molecules of oxygen, etc. We could
construct a similar table where fractions of the total
mass rather than fractions of the total number of
molecules represent the various components. The
mass fractions would be different because, for
example, molecules of oxygen have greater mass
than do molecules of nitrogen. In discussing molec-
ular masses associated with a sample of substance
that you might encounter in everyday life, i. e., a
macroscopic sample we usually refer to a mole of the
substance. The mole is one of the seven SI base units
and is called quantity of substance. The mole has the
value 6.02(1023) which is Avogadro’s number. You
can have a mole of anything. A mole of dollars
would be $6.02(1023). With that amount of money
you could give to each person on earth an amount
equal to the national debt of the United States and
never miss it! A mole of dry air has a mass of
0.02898 kilogram (kg). This is called the molar mass
of dry air. The molar mass will be represented in this
article by M.
Reference conditions for a standard atmosphere
are usually taken as the pressure at sea level with a
temperature of 0° C. This temperature on the Celsius
or centigrade scale corresponds to 273.15 K on the
absolute or Kelvin temperature scale. You should
note that we did not write °K because K alone stands
for degrees on the absolute temperature scale. Note
also that the degree increments on each scale are the
same size so any temperature reading on the Celsius
scale can be converted to absolute simply by adding
273.15. The standard atmosphere has a static or
undisturbed pressure of 1.01325(105) Pascals (Pa)
and a density of 1.293 kg•m-3. A sound with a SPL of
94dB corresponds to an rms acoustic pressure of
1Pa. This moderately loud sound, which represents a
disturbance away from static conditions, perturbs the
atmospheric pressure less than one part in 105.
Accompanying the pressure disturbance there are
also disturbances in the local air’s density and
temperature. In order to understand this we must
consult what is called the equation of state of a gas.
Furthermore the sound source feeds acoustic energy
into the air. In order to get a handle on this we must
consult the first law of thermodynamics.
The equation of state of an ideal gas as given by
the ideal gas law says
(16-1)
where,
P is the total pressure exerted by the gas on the walls
of the containing vessel,
V is the interior volume of the container,
T is the absolute temperature of the gas,
Table 16-1. Principal components of dry air at sea 
level
Gas
Symbol
Fraction
Nitrogen
N2
0.78040
Oxygen
O2
0.20946
Argon
Ar
0.00934
Carbon dioxide
CO2
0.00038
PV
nRT
=

284
Chapter 16
n is the number of moles of the gas in the container,
R is the universal gas constant.
The value of R is 8.3145 J•mole-1•K-1. Joule is
abbreviated J. An ideal gas would be one in which
collisions between individual molecules of the gas as
well as collisions with the walls of the container
would be perfectly elastic, in which both momentum
and kinetic energy are conserved in the collision
processes. Real gases do not obey the ideal gas law
under all possible conditions. The ideal gas law was
determined by experimentally studying the behavior
of real gases as a function of the gas density. With
sufficiently low densities all real gases were found to
follow the same equation of state that has become to
be known as the ideal gas law. The behavior of air in
the temperature and pressure ranges that we normally
encounter in everyday life follows the ideal gas law
with little error. We should note at this point that the
ideal gas law could be expressed by using the gas
density rather than the gas volume as a variable of
interest. Let the total mass of our sample of gas be
represented by m. Then the number of moles in our
sample of gas would become 
 and we can write
the following sequence of equations:
(16-2)
(16-3)
In the last equation the mass per unit volume or
density of the gas is represented by the Greek letter
rho (
).
The first law of thermodynamics in simple terms
states that the change in the internal energy of a phys-
ical system is equal to the heat energy added to the
system less the work done by the system. If we let Q
represent the added heat energy and W represent the
work done, then 
, where ΔU stands for
the change in internal energy. In the case of a system
composed of an ideal gas, the internal energy is asso-
ciated only with the kinetic energies of the molecules
composing the gas. The individual molecules in such
a gas undergo random motions throughout the
volume of the gas and have speeds that can change
from moment to moment as a result of collisions with
other molecules or with the walls of the containing
vessel. Monatomic molecules such as Ar can only
have kinetic energies associated with translations in
the three perpendicular spatial directions. We say
such molecules have three degrees of freedom.
Diatomic molecules such as N2 and O2 in addition to
translation can have kinetic energies associated with
rotations about two perpendicular axes. Such mole-
cules are said to have five degrees of freedom.
Finally, polyatomic molecules such as CO2 can
potentially perform distinct rotations about three
mutually perpendicular axes and have six degrees of
freedom. Kinetic theory tells us that for each mole-
cule in the gas there is, on the average, a kinetic
energy that is proportional to kT where k is
Boltzman’s constant with k being equal to R divided
by Avogadro’s number or 1.38(10–23) J•K-1. The
significance of this is that the internal energy of an
ideal gas or a real gas that behaves as an ideal gas is
directly proportional to the absolute temperature
alone. Regardless of the complexity of a molecule’s
structure, each molecule in the gas has an average
translational kinetic energy of 
. Knowledge
of a molecule’s average kinetic energy allows the
calculation of the root mean square molecular speed.
The formula for this calculation is
(16-4)
If you apply this formula to air at standard condi-
tions vrms will be found to be 485 m•s–1.
As a result of many experiments it has been deter-
mined there are two types of air compression and
expansion processes associated with sound waves.
The first and simplest of these occurs normally at
ultrasonic frequencies, well above the audible spec-
trum but can also occur in a sealed box loudspeaker
enclosure which is completely filled (except for the
volume occupied by the loudspeaker) with loosely
packed fiberglass. This is the isothermal process. The
second process is known as the adiabatic process and
is applicable in free air throughout the audible spec-
trum and beyond. An isothermal process is one in
which the gas temperature and hence its internal
energy remains constant. An inspection of the ideal
gas law for a fixed quantity of gas and a fixed
temperature reveals that the isothermal process is
described by 
 where CT is just a constant.
For one mole of air at standard conditions CT = 2270
J. An adiabatic process is one in which heat energy is
neither added nor subtracted. For an adiabatic
process not only must the pressure-volume relation-
ship follow the ideal gas law it must also satisfy
 where CQ is a constant that depends on
the state of the gas and γ is a constant for the partic-
ular mixture composing the gas. For air γ has the
value of 1.402 and is dimensionless whereas for one
mole of air at standard conditions CQ has the value
493 with the strange dimensions of 
. A
mole of any ideal gas under the standard conditions
m M
⁄
PV
nRT
=
m
M
-----RT
=
P
m
V---- R
M
-----T
=
ρ R
M
-----T
=
ρ
ΔU
Q
W
–
=
3 2
⁄
kT
vrms
3RT
M
----------
=
PV
CT
=
PVγ
CQ
=
Pa
m3
(
)γ
•

What is Waving and Why
285
of sea level atmospheric pressure and a temperature
of 273.15K occupies a volume of 0.0224m3 regard-
less of the type of expansion or compression process
that may occur. This is illustrated in Fig. 16-1 for one
mole of air where a comparison is made between
plots of the pressure-volume relationship for both an
isothermal and an adiabatic process.
At the intersection point of the two curves, the gas
pressures, volumes, and temperatures are the same.
In the isothermal process, the first law of thermody-
namics tells us that when air does an amount of work
W against an outside agency in expanding beyond the
intersection point, an amount of heat Q equal to W
must be added to the air in order to maintain the
temperature T at a fixed value. Conversely when an
outside agency compresses the gas and thus does
work on the gas while reducing its volume, a corre-
sponding amount of heat energy must be removed
from the gas in order to maintain a constant T. With a
constant temperature there is no change in the
internal energy of the gas in either circumstance. In
the adiabatic process, however, no heat energy is
added or removed so when the gas does work during
expansion, the gas itself must supply this energy. As
a consequence the internal energy of the gas
decreases and the gas temperature drops. Conversely,
of course, when an outside agency compresses the
gas adiabatically, work is done on the gas rather than
by the gas and the internal energy of the gas increases
by an amount equal to the work done. This manifests
itself as an increase in gas temperature.
We have mentioned the work done on or by a gas
several times without divulging how the work is
determined. We hasten now to remove that omission.
Suppose the gas is air and it is contained in a cylinder
that has a tightly fitted piston upon which we can
exert a sufficient force to move the piston inward so
as to compress the gas adiabatically. Alternatively,
we can relax our force on the piston somewhat and
allow the gas to expand adiabatically and thus push
the piston outward. In order to do this the entire
apparatus must be thermally insulated from the
external environment so that heat energy cannot leak
in or out during the process. The formal definition of
the work done by the gas in the process of the
volume changing from an initial value Vi to a final
value Vf is given by the following integral equation.
(16-5)
This integral has a geometrical interpretation. It
actually calculates the area that lies beneath the plot
of pressure versus volume between the limits of Vi
and Vf. When the final value of volume is greater
than the initial value the numerical value of the
calculation is positive indicating that the gas has
done work against the piston while expanding. If the
opposite is true, final volume less than initial
volume, the numerical value is negative indicating
that the piston has done work on the gas by
compressing it. We should also observe that if we
multiply the dimensions of pressure by the dimen-
sions of volume we obtain the dimensions of energy
thusly, Newton•m–2•m3 = Newton•m. A Newton•m
is of course a Joule. An example of this is displayed
in Fig. 16-2 where a mole of air is compressed from
an initial volume of 0.022 m3 to a smaller volume of
0.018 m3.
Figure 16-1. Isothermal-Adiabatic comparison. The two
curves have a common point at standard pressure and
temperature with a volume of 0.0224 m3.
Isothermal
adiabatic
Volume in Cubic Meters
Pressure in Pascals
Isothermal - Adiabatic Comparison
1.1
1.05
1
0.95
x105
0.021 0.0215 
0.022 
0.0225       0.023      0.0235
Figure 16-2. Adiabatic compression of air. The cross-
hatched area represents the work done on the gas dur-
ing compression.
W
P V
d
Vi
Vf
∫
=
0.01 0.012 0.014 0.016 0.018 0.020 0.022 0.024 0.026 0.028 0.03
2
1.8
1.6
1.4
1.2
1.0
0.8
0.6
0.4
0.2
0
Volume in Cubic Meters
Pressure in Pascals
105
×

286
Chapter 16
The value of the integral is −478 J with the minus
sign indicating that work was done on the gas. In
other words, the agency pushing the piston did a
work of 478 J in compressing the gas. This amount of
energy is potential energy stored in the compressed
gas because the gas could do this amount of work on
the piston in expanding back to its original state. You
can visually do a rough calculation of the area under
the graph by noting that each complete crosshatched
block has an area of 0.002•20,000 or 40 J and there
are 11 complete blocks and a slightly less than
complete partial block. The eleven complete blocks
correspond to 440 J.
Finally, we are ready for an acoustical calculation
of some importance. We previously mentioned that
an adiabatic process was described by 
where the constant CQ depends on the quantity of air
involved. An alternative description of an adiabatic
process for air in the atmosphere that is independent
of the amount of air involved is
(16-6)
In this equation P is the total air pressure when the
air density is ρ and P0, ρ0 are the values of the air
pressure and density under standard conditions.
Fig. 16-3 illustrates this behavior.
If we examined the curve in the vicinity of the
marker on a greatly magnified scale the curve would
appear to be a straight line and we could determine
its slope graphically. This slope describes the ratio of
a small change in pressure to a small change in
density. Alternatively, we could employ the methods
of differential calculus and precisely determine a
value for the slope. Calling this slope c2, the slope of
the curve at the position of the marker is
(16-7)
Upon inserting the values for standard air pres-
sure and density c2 is found to be 109866.71 with the
dimensions of Newton•m•kg–1 = m2•s–2. The obvious
next step is to extract the square root to find
c = 331.46 m•s-–1. This result should be familiar as it
is the speed of sound in air at a temperature of
273.15K! This of course is interesting and the expla-
nation for it will be forthcoming. It is not, however,
the calculation that we seek at this point. Let us turn
our attention to a cubic centimeter of air under stan-
dard conditions. A cubic centimeter (cm3) is 10–6
cubic meter (10–6 m3) so our sample contains a mass
of 1.293(10–6)kg of air. Let our air sample be in
contact with some vibrating object such that the
sample is momentarily compressed by a very small
amount. The sample of air now occupies a smaller
volume so its density has increased and this is
accompanied by an increase in the air pressure in the
sample itself. Let the new pressure be P = 101326Pa.
The undisturbed pressure was P0 = 101325 Pa. What
we call acoustic pressure, p, is the difference between
these two numbers so 
 Pa. Now we
can use the slope on Fig. 16-3 to calculate the change
in density from 
. Remember the
slope is pressure change divided by density change.
We can solve for ρ to find ρ = 1.293009102 kg•m-3.
We started with a mass of air of 1.293(10–6) kg that
was contained in an initial volume V0 of 10–6 m3. We
still have the same mass of air but now in a smaller
volume V so we can write 
. Solving for
V we find that 
. The
change in volume in the compression process is then
. The result of
this is that there is now energy stored in our
compressed sample of air. A portion of this stored
energy is called acoustical potential energy and is
represented by the work that can be performed by the
acoustic pressure as the sample expands back to its
original volume against the external pressure of the
surrounding air. This work can be determined from
Fig.16-4 in which the acoustic pressure is plotted
versus the size of the volume change.
The work that can be performed by the acoustic
pressure as the sample expands back to normal size is
the area included in the triangle and in this case is
one-half the altitude times the base or
0.5•7.039393602(10–12) Pa•m3 = 3.5197(10–12)J. We
can calculate this directly using the equation for
acoustical potential energy that is obtained through
the full use of calculus.
Figure 16-3. Air pressure versus density. The marker
indicates the location of the point (P0, ρ0).
PVγ
CQ
=
P
ρ
ρ0
-----
⎝
⎠
⎛
⎞γ
P0
=
0
0.2
0.4
0.6
0.8
1.0
1.2 1.4
1.6
1.8
2.0
2
1.8
1.6
1.4
1.2
1.0
0.8
0.6
0.4
0.2
0
Density in kg.m–3
Pressure in Pascals
105
×
c2
γP0
ρ0
------
=
p
P
P0
–
1
=
=
p
c2 ρ
ρ0
–
(
)
=
ρ0V0
ρV
=
V
9.99929606 10–7
(
) m3
=
V
V0
–
−7.039393602 10–12
(
) m3
=

What is Waving and Why
287
(16-8)
The equation given above is essential to the calcula-
tion of a part of the energy transported by a sound
wave.
You will recall that the acoustic pressure is given
by 
. In this equation, p is the acoustic
pressure at some point in space and some instant in
time. Similarly, P is the disturbed total atmospheric
pressure at the same point in space and the same
instant in time while P0 is the static or undisturbed
atmospheric pressure at the location of interest.
The acoustic pressure is perhaps the premier
acoustic variable. The root mean square value of the
acoustic pressure at a particular location expressed in
Pascals is what is used in determining the sound pres-
sure level at that location through the relationship
(16-9)
There are, however, many other important
acoustic variables whose values depend upon loca-
tion in both space and in time. A listing of the ones to
be employed here appears in Table 16-2.
Table 16-2 introduces three acoustic variables that
we have not yet discussed. The acoustic condensa-
tion symbolized by s is simply the ratio of the change
in air density brought about by an acoustic distur-
bance to the normal static or undisturbed air density
as expressed by the equation
(16-10)
In this equation the Greek letter rho, 
, represents
the total density of air under the disturbed condition
while 
 represents the undisturbed or static air
density. The acoustic variable that is termed the
particle displacement and is symbolized by the Greek
letter xi, ξ, will require a more lengthy explanation.
The question that immediately arises is what consti-
tutes an air particle? It cannot be a single molecule as
air is always composed of a collection of a variety of
molecules in the proportions tabulated in the begin-
ning of this chapter. The particle size, whatever its
value, must be sufficiently large so as to encompass
millions of molecules in order to yield valid statis-
tical averages and thus behave as an apparently
continuous fluid while at the same time it must be
small enough that the acoustic variables are essen-
tially constant throughout the volume occupied by
the particle. This latter condition requires the dimen-
sions of the particle to be very much smaller than any
sound wavelength under consideration. Let’s do a
simple calculation in order to determine a reasonable
size for what we will call an air particle. What
volume would say two million molecules of air
occupy under standard conditions? We learned
earlier on that Avogadro’s number of molecules
would occupy about 0.0224 m3 under standard condi-
tions. If we consider a cube of edge dimension l then
by simple proportion we can write
When this is solved for l the result is found to be
4.2(10–7) m. This distance is orders of magnitude
smaller than the wavelengths encountered in air even
at ultrasonic frequencies so both of our requirements
are satisfied. We might even round this number
upward to a value easier to remember and say that an
air particle is that amount of air under standard
conditions that occupies a cube having an edge
dimension of about 0.5micron. When we consider
such a small cubical volume of air that we now will
call an air particle we realize that even in the absence
of an acoustical disturbance, the air molecules are
constantly undergoing random thermal motion. As a
result of this thermal motion, some molecules move
out of the volume but other molecules having the
same properties also move into the volume. The
volume has been chosen large enough so that the
randomness of the thermal motion averages to zero
Figure 16-4. The acoustical potential energy is the area
of the triangle.
Table 16-2. A Partial Listing of Acoustic Variables
Name of Variable
Symbol
Unit
Acoustic Pressure
p
Pa
Air Density
ρ
kg•m-3
Condensation
s
dimensionless
Particle Displacement
ξ
m
Particle Velocity
u
m•s-1
–8
–7
–6
–5
–4
–3
–2
–1
0
1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
Volume Change in Cubic Meters
Acoustic Pressure in Pascals
x 10–12
EP
1
2---
p2
ρ0c2
-----------
⎝
⎠
⎜
⎟
⎛
⎞V0
=
p
P
P0
–
=
SPL
20 dB 
prms
2 10–5
(
)
-------------------
⎝
⎠
⎛
⎞
log
=
s
ρ
ρ0
–
ρ0
---------------
=
ρ
ρ0
l3
2 106
(
)
----------------
0.0224
6.02 1023
(
)
--------------------------
=

288
Chapter 16
so that in effect the air contained in the particle is at
rest. An acoustical disturbance, as we shall see,
imposes a preferred direction of motion and thus can
bring about a displacement of the air particle as a
whole. Particle displacement is a vector quantity and
as such has both a magnitude and a direction that are
measured relative to a coordinate frame of reference.
In addition to particle displacement we will also be
concerned with another acoustic variable that
describes the instantaneous rate at which the particle
displacement changes with time. This is a vector
quantity also and is called the particle velocity. As
the table indicates the symbol employed for the
particle velocity is the letter u.
In the absence of any acoustical disturbance the
acoustic variables of Table 16-2 are all zero with the
exception of ρ for which the value becomes the static
atmosphere value ρ0. When an acoustical disturbance
is present all of the acoustic variables listed in the
table will have values that depend upon both location
in space and time. For simplicity let’s center our
attention on just the acoustic pressure as an example.
Mathematically we say that the acoustic pressure is a
function of the positional coordinates and time. If we
were employing general Cartesian coordinates this
mathematical statement would be written in the
manner, 
.
The entry immediately above is read as, “The
acoustic pressure is a function of x, y, z, and t.” It
does not tell you what particular mathematical func-
tion but only that there is such a function. In certain
situations not all spatial coordinates may be
involved. If the acoustic pressure depends only on
the z coordinate and time then p = p(z,t) would be
appropriate. From either theory or experiment we
may find what the particular mathematical functional
dependence is. For example, the answer might be
.
In this answer pm, ω, and k are constants and we
are informed that the acoustic pressure varies as the
cosine of the difference of two angles one of which is
directly proportional to time and the other of which is
directly proportional to the value of the z coordinate.
As we shall see shortly this function describes a
plane wave propagating in the direction of increasing
values of the z coordinate.
16.2 Plane Waves
Now that we have covered the preliminaries, we turn
our attention to a physical system of some impor-
tance consisting of a long, rigid-wall air filled pipe.
The inner diameter of the pipe is d, its inner radius
is a. The interior wall is smooth and the pipe is
straight. The wall thickness of the pipe is immaterial
as long as it is reasonably rigid. We will employ
cylindrical coordinates for locating positions in the
pipe. These are the coordinates best suited for such a
structure. In cylindrical coordinates space points are
located by the variables r, θ, and z. The z coordinate
is familiar from the usual Cartesian set. The relation-
ship between r, θ and the familiar x, y can be
extracted by viewing Fig. 16-5.
We have selected an air filled pipe as the starting
point for our discussion of acoustic waves because of
the ease with which the simplest of wave motions,
namely plane waves, can be established in such a
structure. Our first step will be to concentrate on a
small mass of air in the pipe under static conditions
and on the same mass of air after it has been acousti-
cally disturbed. The physical situation is depicted in
Fig. 16-6.
The pipe has an inner cross-sectional area
. The undisturbed air is that contained in
the cylindrical volume between the planes defined by
z and z + Δ z. The mass, m, of this air is the static air
p
p x y z t
, , ,
(
)
=
p
pm
ωt
kz
–
(
)
cos
=
Figure 16-5. Cartesian to cylindrical conversion. The z
axis points toward the reader.
Figure 16-6. Undisturbed (solid) and disturbed (dashed)
air mass in a long rigid pipe.
y axis
x axis
r
x = r cosθ 
y = r sinθ
z = z
r2 = x2 + y2
θ = atan(y/x)
θ
z + ξ 
z + Δ z + ξ + Δξ 
z
z + Δ z
S
πa2
=

What is Waving and Why
289
density multiplied by the volume of the cylinder
between the solid lines.
(16-11)
Imagine now that a closely fitting piston is
inserted into the pipe on the left and quickly
displaces the air particles that were originally on the
plane at z to the new dashed planar position z + ξ
such that all of the air particles that were originally at
z are now located at z + ξ. In other words, the air
particles originally located at the spatial coordinate z
have undergone an amount of displacement equal to
ξ. Note also that the particle displacement does not
depend on the spatial coordinates r or θ. All air parti-
cles having a particular value of the z coordinate are
displaced the same amount such that the particle
displacement depends only on z and on time, t. Now
if air were incompressible, all of the particles origi-
nally on the plane at 
 would be displaced to a
new plane at 
. Air is compressible
however, so we must allow for the particle displace-
ment to undergo a change over the space interval of
 so that the right extremity of our disturbed mass
of air is located at 
. Our original
mass of air is now contained in the cylinder defined
by the two dashed planes. The air has been
compressed as a result of the piston motion. As a
consequence, the volume of the disturbed cylinder is
slightly less than that of the undisturbed one and this
simply requires that Δξ be a negative number. The
mass of air was conserved in the process so the
density of air in the disturbed cylinder has increased.
The volume of the undisturbed cylinder is 
 while
that of the disturbed cylinder is 
 so we
may write
(16-12)
This equation readily simplifies to
(16-13)
In words this last equation says that the undis-
turbed density of air is equal to the disturbed density
multiplied by one plus the average slope of the
particle displacement function over the interval Δ z.
This slope is negative however as the particle
displacement decreases as z increases and thus the
number in the parenthesis is less than one. The
average slope is not good enough. We need to make
our calculation independent of our choice of the size
of Δ z. At this point I recognize that many readers
have not had an opportunity to study calculus much
less partial differential equations. Both of these are
required in order to do a rigorous derivation of the
wave equation. In much of the following then, I will
substitute word descriptions for what is going on
rather than adhering to pure mathematical formalism.
In the density equation above we take successively
smaller and smaller sizes for Δ z or in other words let
Δ z approach zero all the while studying the ratio
 and look to see what limiting value is
approached by the quotient of 
. This limit is
called the partial derivative of the particle displace-
ment with respect to the z coordinate and the density
relation is then written as
(16-14)
The reason for doing this is to find the value of
the disturbed air density in the immediate vicinity of
the point z and at time t. Among other things, we
want to learn how the air density behaves under
disturbed conditions as a function of position and
time. This last equation tells us how to calculate the
density behavior once we know how the particle
displacement behaves. Recall that the condensation
is given by
(16-15)
This can be solved for the disturbed density to
yield 
. This is now substituted in the
density relation to yield
(16-16)
(16-17)
(16-18)
 In order for the remainder of our development to
be as simple as possible we must restrict the size of
the acoustical disturbance to that for which the air
behaves as a linear medium. Even with this restric-
tion the equations that we develop will accommodate
sound pressure levels up to 120 dB with little error.
With this restriction, we can observe that in the last
equation written above both s and the partial deriva-
tive of the displacement with respect to z are small
quantities individually and that the product of the
two of them is very small indeed. Hence neglecting
the product term introduces negligible error. This
final equation can then be rewritten as
m
ρ0SΔz
=
z
Δz
+
z
Δz
ξ
+
+
Δz
z
Δz
ξ
Δξ
+
+
+
SΔz
S Δz
Δξ
+
(
)
ρ0SΔz
ρS Δz
Δξ
+
(
)
=
ρSΔz 1
Δξ
Δz
------
+
⎝
⎠
⎛
⎞
=
ρ0
ρ 1
Δξ
Δz
------
+
⎝
⎠
⎛
⎞
=
Δξ Δz
⁄
Δξ Δz
⁄
ρ0
ρ 1
∂ξ
∂z
------
+
⎝
⎠
⎛
⎞
=
s
ρ
ρ0
–
ρ0
---------------
=
ρ
ρ0 1
s
+
(
)
=
ρ0
ρ0 1
s
+
(
) 1
∂ξ
∂z
------
+
⎝
⎠
⎛
⎞
=
1
1
s
+
(
) 1
∂ξ
∂z
------
+
⎝
⎠
⎛
⎞
=
1
1
∂ξ
∂z
------
s
s∂ξ
∂z
------
+
+
+
=

290
Chapter 16
(16-19)
Previously we learned that for small disturbances
the acoustic pressure is given by
(16-20)
and in terms of the condensation this may be written as
(16-21)
Alternatively, we may express the acoustic pressure as
(16-22)
One other observation is appropriate at this point.
The particle displacement, ξ, is in general a function
of both z and t. This means that ξ = ξ(z,t). In fact, one
of our objectives is to find the exact nature of this
function for a given type of acoustical excitation.
Once we determine the nature of this function we can
determine the value of the particle displacement for
any value of the spatial coordinate z and time coordi-
nate t. Additionally we will also be able to determine
the particle velocity, u, as the particle velocity at any
particular value of the z coordinate and time t is the
rate at which the particle displacement is changing
with time at the fixed value of z. The particle velocity
is given by the partial derivative of the particle
displacement with respect to time and is written as
(16-23)
Similarly, the local particle acceleration or rate of
change of velocity is calculated from
(16-24)
Thus far we have required only a few definitions,
the law of conservation of mass, and knowledge of
the behavior of air while undergoing small adiabatic
compression or expansion. Now with the help of Sir
Isaac Newton’s second law of motion we will be able
to finally arrive at the plane wave equation. First we
must list the forces that could possibly affect the air
particle motion in the tube. The principal force is that
exerted by the piston as it first begins to compress the
air at the left face of our undisturbed cylinder of air
as depicted in Fig. 16-7 The pressure exerted by the
piston must exceed static atmospheric pressure in
order to produce compression so we write this as (P0
+ p)S where p is the acoustic pressure at z. Similarly,
the pressure at the right face is the static pressure
plus the acoustic pressure at the right face which we
must allow to be different from that at the left face.
We write the force at the right face then as
. In principle, the force of gravity
would tend to make the static pressure at the bottom
of the tube minutely greater than that at the top. This
effect is insignificant for tubes of ordinary diameters.
Finally, we should mention the possibility of viscous
effects. Viscous frictional forces occur principally at
the tube walls and manifest themselves as a small
attenuation in very long tubes. We will neglect such
effects for reasons of simplicity.
From Fig. 16-7, the net force in the positive z
direction is −ΔpS. According to Newton’s second
law the net force acting on the mass of air in the
element must be equated to the mass multiplied by
the acceleration or
(16-25)
Upon canceling common factors and taking the limit
as we have done in a previous case this equation
becomes
(16-26)
In words this result says that the negative of the
space rate of change of the acoustic pressure at a
given point and time is the undisturbed density of air
multiplied by the particle acceleration at the same
space point and time t.
Two more steps and we will be at the punch line.
One of our previous results while studying the
particle displacement was
From this relation we need to calculate the space rate
of change or the slope of the acoustic pressure. This
is done by calculating the partial derivative with
respect to the z coordinate on both sides of the equa-
tion. The result is
s
–∂ξ
∂z
------
=
p
c2 ρ
ρ0
–
(
)
=
p
ρ0c2s
=
p
-ρ0c2∂ξ
∂z
------
=
u
∂ξ
∂t
------
=
∂u
∂t
------
∂2ξ
∂t2
--------
=
Figure 16-7. Forces acting on undisturbed element at
the onset of compression by the piston. S is the cross-
sectional area of the pipe.
P0
p
Δp
+
+
(
)S
z
z + Δ z
(P0 + p)S
(P0 + p + Δp)S
–Δp
Δz
-------ΔzS
ρ0ΔzS∂2ξ
∂t2
--------
=
–∂p
∂z
------
ρ0
∂2ξ
∂t2
--------
=
p
–ρ0c2∂ξ
∂z
------
=

What is Waving and Why
291
(16-27)
This is now substituted into the equation derived
employing Newton’s second law to produce
(16-28)
This second order partial differential equation is
the governing equation for plane waves that depend
on only one space coordinate and time as the inde-
pendent variables. The dependent variable in this
instance is the air particle displacement. Instead of
concentrating on the particle displacement as the
dependent variable, we could have just as well done a
parallel development while centering our attention on
the acoustic pressure to obtain
(16-29)
In other words, the acoustic pressure and the
particle displacement are governed by the same
partial differential equation. In order for some mathe-
matical function to be a solution to a physical
circumstance involving the plane wave equation it
must accomplish three things. Firstly, when substi-
tuted into the wave equation it must yield an identity.
Secondly, it must satisfy the conditions that exist at
t = 0. Finally, it must satisfy the conditions that exist
at the coordinate boundaries for all values of t ≥0.
There are many functions that satisfy the first condi-
tion. In fact, there are an infinite number of such
functions. All of these functions, however, have one
feature in common and that is whenever the space
and time independent variables appear in one of the
functions, this appearance must be of the form
. The two other requirements play the role of
sorting through this infinite set to find the one and
only solution that fits the problem at hand. We are
assured that there is only one genuine solution to the
wave equation that satisfies the three stated require-
ments because of the existence of a uniqueness
theorem governing solutions to the wave equation. In
order to make this really meaningful, we must seek a
solution to this equation for a realizable physical
circumstance. First, let’s illustrate the significance of
. Suppose we have a very long plane wave
tube with the origin of coordinates at the mid-point
of the tube. Further suppose at t = 0 that some distur-
bance produces an acoustic pressure matching only
the solid curve in Fig. 16-8.
Refer now to Fig. 16-8 and imagine that only the
solid curve is present. This would represent the first
frame of a movie describing the acoustic pressure
versus time and position in space. The second frame
would show the initial disturbance beginning to split
into two equal parts with one part displaced slightly
to the left and the other displaced an equal amount to
the right. Many frames later, the solid curve would
no longer be present and the two dashed curves
would represent a snapshot at the instant when
. In other words the initial static distur-
bance has evolved into two traveling disturbances
moving in opposite directions along the z-axis. The
functions involved would be
(16-30)
and
(16-31)
Let’s concentrate on just the p+ term. If we are to
always observe the same peak pressure for this term,
what must we do as an observer? Remember that we
have no control over time. It increases uniformly
whether we want it to or not. As ct increases
uniformly then we must increase our location on the
z-axis at the same rate such that ct – z maintains a
value of, in this case, zero. The rate at which ct
increases is the speed of sound, c. Therefore an
observer must race in the direction of increasing z
with a speed equal to c in order to keep up with the
pressure pulse on the right. Similarly, an observer
must race in the direction of decreasing z with a
speed c in order to keep up with the pressure pulse on
the left.
Thus we have the plane wave equation in hand
and have learned the properties that must be exhib-
ited by a mathematical function if it were to be a
solution to the plane wave equation for a given set of
physical circumstances. It is now time to apply what
we have learned towards the study of the wave
∂p
∂z
------
–ρ0c2∂2ξ
∂z2
--------
=
∂2ξ
∂z2
--------
1
c2
-----∂2ξ
∂t2
--------
=
∂2p
∂z2
--------
1
c2
-----∂2p
∂t2
--------
=
ct
z
±
(
)
ct
z
±
(
)
Figure 16-8. Plane wave tube with an initial disturbance
(solid) at its center.
–5
–4
–3
–2
–1
0
1
2
3
4
5
2
1.8
1.6
1.4
1.2
1.0
0.8
0.6
0.4
0.2
0
z in Meters
p in Pascals
ct
4m
=
p+
p ct
z
–
(
)
=
p–
p ct
z
+
(
)
=

292
Chapter 16
motion in a plane wave tube that is excited by an
oscillating piston at one end as depicted in Fig. 16-9.
For simplicity, we will consider the circumstance
where the piston, depicted in gray, has been forced to
undergo oscillatory motion for some time by a mech-
anism not shown in the figure and continues to do so
as we study the problem. We will start measuring
time from the instant when the right face of the
piston is just passing z = 0 and is moving to the right
such that the piston’s displacement from z = 0 is
described by
(16-32)
where,
ξm is the amplitude of the piston displacement,
ω = 2πf with f being the frequency of oscillation in Hz,
t is the time.
Now we want to find a solution to the wave equa-
tion for air particle displacement in the tube that
satisfies these conditions. The tube is infinitely long
so there can be no reflections from the receiving end.
As a consequence, we need only a solution that
describes a wave traveling to the right. The air in
contact with the piston undergoes the same motion as
does the piston itself so we propose as a solution an
expression that duplicates the piston motion when we
let z = 0
(16-33)
We also have learned that in order for a solution
to legitimately describe a plane wave propagating in
the direction of increasing z that the space and time
variables must appear in the form 
. We can
easily show that our proposed solution satisfies this
requirement as follows. The quantity k is called the
propagation constant and is defined as 
where λ is the wavelength. Now as ω is 2πf and 
is 
, then if we factor k out of our parenthesis
in our proposed solution, the solution will take the
form
(16-34)
Since the two expressions for the particle
displacement are equivalent we may use either form
to suit our convenience. Next, it is necessary to show
that our proposed solution when substituted into the
wave equation produces an identity. In accom-
plishing this it is necessary to take partial derivatives
of our proposed solution first with respect to z and
then with respect to t. The first partial derivative with
respect to z finds the slope of the solution when z is
allowed to change while t is held at a constant value.
Similarly, the second partial derivative with respect
to z finds the slope of the slope curve while z is
allowed to change with t being held constant. The
process is then repeated except now t is allowed to
change while z is held at a constant value. The results
are found to be
(16-35)
(16-36)
The wave equation tells us to divide the second
partial derivative with respect to t by c2 and equate
the result to the second partial derivative with respect
z. If an identity results from this action then our
proposed solution does indeed satisfy the wave equa-
tion. Upon dividing the second equation immediately
above by c2 and equating it to the first equation
immediately above we obtain
(16-37)
This is indeed an identity because
. Finally, when we
let z = 0, our air particle displacement agrees with the
piston motion at all times t including t = 0. Therefore
our proposed solution satisfies all of the require-
ments necessary to be the one and only solution to
the problem.
What about the particle velocity and the acoustic
pressure? We obtain the particle velocity from the
partial derivative of the particle displacement with
respect to t.
(16-38)
The acoustic pressure is obtained from
. We learned this in the
beginning of this chapter.
(16-39)
Figure 16-9. Plane wave tube that is fitted with an oscil-
lating piston.
z = 0
To Infinity
ξ
ξm
ωt
(
)
sin
=
ξ
ξm
ωt
kz
–
(
)
sin
=
ct
z
–
(
)
k
2π λ
⁄
=
ω k
⁄
λf
c
=
ξ
ξm
k ct
z
–
(
)
[
]
sin
=
∂2ξ
∂z2
--------
–k2ξm
ωt
kz
–
(
)
sin
=
∂2ξ
∂t2
--------
–ω2ξm
ωt
kz
–
(
)
sin
=
ω2
c2
------
–
ξm
ωt
kz
–
(
)
sin
k
– 2ξm
ωt
kz
–
(
)
sin
=
k
2π λ
⁄
2πf
c
( )
⁄
ω c
⁄
=
=
=
u
∂ξ
∂t
------
ωξm
ωt
kz
–
(
)
cos
=
=
ρ0
(
)
–
(
)c2
∂ξ
(
)
∂z
(
)
⁄
(
)
p
ρ0c2kξm
ωt
kz
–
(
)
cos
=

What is Waving and Why
293
It is important to note that if we divide the
acoustic pressure expression by that of the particle
velocity we obtain a quantity called the specific
acoustic impedance of air for plane waves namely,
(16-40)
Here the capital letter Z represents impedance
rather than the spatial coordinate and the subscript s
stands for specific. The specific acoustic impedance
of air for plane waves is a real number denoting the
fact that the acoustic pressure and particle velocity
are in phase. The dimensions of Zs are kg•m–2•s–1.
This combination is called a Rayl in honor of Lord
Rayleigh who was a pioneer in the study of sound
and acoustics.
Now we will put the theory into practice with a
realistic numerical example. Let the frequency of
oscillation of the piston be 1000 Hz and let its
displacement amplitude be 10–6 m. Let the static air
pressure be the sea level value but let the temperature
be a comfortable 70°F. This corresponds to 21.11°C
or 294.26 K. The static air density is inversely
proportional to the absolute temperature so then
ρ0 = 1.293(273.15 ⁄ 294.26 = 1.20 kg •m–3. The speed
of sound is directly proportional to the square root of
the 
absolute 
temperature 
so
 = 344 m•s–1. The
air particle displacement amplitude matches that of
the piston so ξm = 10–6 m. The angular frequency
. The propagation
constant 
 = 18.265  m–1. The velocity
amplitude is um = ckξm = ωξm = 6.283(10–3) m•s-1.
The 
acoustic 
pressure 
amplitude 
is
pm = ρ0cum = 2.5937Pa. The rms pressure for sinu-
soidal time dependence is the amplitude multiplied
by 0.7071 and is 1.834 Pa. This corresponds to a SPL
of 99.25dB. The wavelength 
.
Our solutions for the acoustic variables expressed as
functions of both position and time are then
(16-41)
(16-42)
(16-43)
Given that the piston has been oscillating for
some time, Fig. 16-10 depicts the acoustic pressure
wave propagation along a one-wavelength interval of
the z-axis versus elapsed time commencing from the
instant when the piston is located at z = 0 and is
moving in the positive z direction.
Now for a pop quiz! If we were to construct a
ninth entry to Fig. 16-10 corresponding to
t = 0.001sec, how would it look? Hint: 0.001sec
corresponds to the period of the motion of the piston
and is equal to the time required for the pressure
wave to travel a distance of one wavelength along the
z-axis. This being the case, the ninth entry would
look exactly like the first. Furthermore, a slight
modification of Fig. 16-10 would allow it to describe
the particle velocity as well. This modification would
involve only a change of scale and label for the
vertical axes as the particle velocity is in phase with
the acoustic pressure for a plane wave in air.
Now that we have established the behavior of the
sound wave in the tube it is appropriate to consider
what the piston’s motion must accomplish to bring
about this behavior. The piston of course is
p
u---
Zs
ρ0c2k
ω
--------------
ρ0c
=
=
=
c
331.46 294.26 273.15
⁄
(
)0.5
=
ω
2πf
6283 radians s
⁄
=
=
k
ω c
⁄
=
λ
c f⁄
0.344 m
=
=
ξ
10–6m
6 283
,
sec
---------------t
18.265
m
----------------z
–
⎝
⎠
⎛
⎞
sin
•
=
u
6.283 10–3
(
)m
sec–1
•
6 283
,
sec
---------------t
18.265
m
----------------z
–
⎝
⎠
⎛
⎞
cos
•
=
p
2.5937Pa
6 283
,
sec
---------------t
18.265
m
----------------z
–
⎝
⎠
⎛
⎞
cos
•
=
Figure 16-10. A depiction of successive shifts of the
pressure waveform along the z-axis as time increases.
2
0
–2
0
0.2
z
t = 0.000125
Pressure
2
0
–2
0
0.2
z
t = 0.000250
Pressure
2
0
–2
0
0.2
z
t = 0.0
Pressure
2
0
–2
0
0.2
z
t = 0.000375
Pressure
2
0
–2
0
0.2
z
t = 0.000750
Pressure
2
0
–2
0
0.2
z
t = 0.000625
Pressure
2
0
–2
0
0.2
z
t = 0.000875
Pressure
2
0
–2
0
0.2
z
t = 0.0005
Pressure

294
Chapter 16
displacing the air adjacent to its right hand face. The
piston must exert a force on the air in order to
displace it and this requires that the piston perform
work on the air. The force, F, exerted by the piston at
any instant is the acoustic pressure at z = 0 multiplied
by the cross-sectional area of the tube namely, S.
(16-44)
The rate at which the piston is performing work
on the air is the instantaneous power or P and is
obtained by multiplying the applied force by the rate
of displacement at z = 0. The rate of displacement at z
= 0 is just the particle velocity at the origin so
(16-45)
Fig. 16-11 is a plot of this result for one period of
the piston motion using the values from our numer-
ical example when applied to a plane wave tube
having an inner diameter of 1 in or 0.0254 m.
Fig. 16-11 displays two items of interest: the plot
of the instantaneous power versus time and the area
beneath the power curve that is shaded gray. Since
the average value of the cos2 over one period is 1⁄2
the area under the curve is 1 ⁄ 2 Pm•0.001 sec. For our
example this would be 4.1288(10-9) J. This area
accounts for the total acoustic energy delivered to the
sound wave during one period of the piston’s motion.
One can reasonably inquire as to where this energy
resides in the sound wave. The acoustical energy
associated with a plane wave appears in two forms.
First there is acoustic kinetic energy associated with
the motion of the air particles themselves and then
there is acoustic potential energy associated with the
existence of acoustic pressure. We encountered the
concept of acoustic potential energy earlier in this
chapter. This acoustic energy is not localized at a
point but rather is distributed throughout the volume
occupied by the wave with an energy density that
varies as a function of position and time. If we let e
represent the total acoustic energy density while ek
and ep represent the kinetic and potential energy
densities, respectively, then
(16-46)
The last step in the above equation is justified
because for a plane wave in air the particle velocity
and acoustic pressure are related through
 thus making the kinetic and potential
energy densities equal with each being one-half of
the total energy density. The total acoustic energy
density is also a function of position and time. Using
the data from our numerical example the total acous-
tical energy density expression becomes
(16-47)
Fig. 16-12 is a plot of this energy density for a
one-wavelength interval along the z-axis at the
instant when t = 0.001 sec. This corresponds to an
elapsed time of one period of the piston motion.
Now we are in a position to calculate the total
acoustic energy contained in the plane wave tube for
a one-wavelength interval along the z-axis. If we
draw a horizontal line across the peaks of the curve,
we will now have a rectangle whose area numerically
is 0.344•4.7374(10–5). By visual inspection,
however, the actual area beneath the curve indicated
in gray is only 1 ⁄ 2 of this value so the average height
of the curve is 1 ⁄ 2 of its peak value meaning that the
average value of the energy density in this interval is
2.3687(10–5) J•m–3. (This is just an illustration of the
fact that the average value of cos2 over one period is
1 ⁄ 2.) Here is the punch line. The total energy in the
wave for this one-wavelength interval is the average
energy density in the wave multiplied by the volume
occupied by the wave. This is 
 where 
 is
the average value of the acoustic energy density.
Calling this energy W, we have
Figure 16-11. Instantaneous power delivered by the pis-
ton to the air in the plane wave tube. The grey area is
the acoustic energy delivered to the sound wave in one
period of the piston’s motion.
F
Spm
ωt
(
)
cos
=
P
Spm
ωt
(
)
cos
um
ωt
(
)
cos
•
=
Spmum
2 ωt
(
)
cos
=
0 
0.2 
0.4 
0.6 
0.8 
1
Time
x10–3
9
8
7
6
5
4
3
2
1
0
Instantaneous Power
x10–6
e
ek
ep
+
=
1
2---ρ0u2
1
2--- p2
ρ0c2
-----------
+
⎝
⎠
⎜
⎟
⎛
⎞
=
p2
ρ0c2
-----------
=
u
p
ρ0c
(
)
⁄
=
e
4.7374 10–5
(
)J
m–3
•
2 6 283
,
sec
---------------t
18.265
m
----------------z
–
⎝
⎠
⎛
⎞
cos
•
=
Sλ e
〈〉
e
〈〉

What is Waving and Why
295
This is just the amount of energy supplied by the
piston in the previous 0.001 sec!
Now if an observer is positioned at any fixed
value of the z-coordinate in the plane wave tube, this
same amount of acoustical energy will pass the
observation point while being transported in the posi-
tive z direction in a time of 0.001 sec so the average
acoustical power over this interval of time is 
where W is the acoustical energy and T is the period
of the sinusoidal piston motion. 
 denotes this
average power and in this instance has the value
4.1288 (10–6) Watt. The average acoustical intensity
denoted by 
 is a vector quantity defined to be the
average directed power flow per unit area. As it is a
vector quantity 
 has both a magnitude and direc-
tion. For a fixed location the magnitude of 
amounts to the total acoustical energy flow averaged
over the time of the flow per unit of area through
which the energy passes. In this instance the magni-
tude of 
 where S is the cross-sectional
area of the tube. In the present case the magnitude of
 is 8.1482(10–3) Watt•m–2 and the direction of
 is the same as that of the wave propagation,
namely the positive z-direction. The instantaneous
intensity I(z, t) is a related physical quantity that is
also a vector quantity. I(z, t) is a function of both
position and time and is a measure of the instanta-
neous power flow per unit area at a particular loca-
tion z and time t. It is calculated from the product of
the acoustic pressure with the particle velocity at the
z-coordinate and time coordinate of interest so
. For a plane wave propa-
gating in the direction of increasing z,
. For the case at hand, the
direction of I(z, t) is always that of the positive z-axis.
It is true that the particle velocity alternates between
the positive and negative z direction, but the acoustic
pressure is in phase with the particle velocity so that
when the particle velocity is instantaneously in the
negative z direction the acoustic pressure is negative
and the overall product remains positive. Now 
 at
some fixed point z can be calculated from the time
average of 
 at the same value of z and hence
. 
The 
quantity
by definition is just the mean value of
the square of the acoustic pressure so it is possible to
write this equation as
(16-48)
This is a very useful equation. Even though it was
derived by considering only a plane wave it is
equally valid for a spherical wave.
It is probably safe to say that the most often made
measurement in acoustics is that of sound pressure
level. Levels are logarithmic comparisons of a power
or power-like quantity with regard to some standard
reference value for the quantity in question. When
the quantity is acoustic pressure, the power-like
quantity is 
 and the reference is [20(10–6)]2 Pa2.
Strictly speaking, the sound pressure level in decibels
would be written with the form
(16-49)
We have previously learned that the root mean
square acoustic pressure for the sound wave in this
plane wave tube has a value of 1.834 Pa. When this
value is substituted into the equation for SPL, the
calculated sound pressure level becomes 99.25dB.
Additionally, when prms is substituted along with ρ0c
having a value matching the ambient conditions,
namely 412.8 Rayls, the magnitude of 
 is found to
be 8.1482(10–3)  Watt•m–2. Now 
 is a true
power-like quantity and the reference value for
average acoustic intensity is 10–12Watt•m–2. The
intensity level or IL is then calculated from
Figure 16-12. Acoustic energy density at t = 0.001 sec
for a one-wavelength interval along the z-axis.
x10–5
5
4.5
4.0
3.5
3.0
2.5
2.0
1.5
1.0
0.5
0 0 
0.05 
0.1 
0.15 
0.2 
0.25 
0.3
Distance Along z
W
Sλ e
=
π 0.0254 m
2
-----------------------
⎝
⎠
⎛
⎞
2
0.344 m 2.3687
(
)10–5
=
4.1288 10–9
(
) J
=
W T
⁄
P
〈〉
I 
〈〉
I 
〈〉
I 
〈〉
I 
〈〉
P
〈〉S
⁄
=
I 
〈〉
I 
〈〉
I z t,
(
)
p z t,
(
)
u z t,
(
)
•
=
u z t,
(
)
p z t,
(
) ρ0
⁄
c
=
I 
〈〉
I z t,
(
)
I 
〈〉
p z t,
(
)
[
]2
〈
〉
ρ0c
(
)
⁄
=
p z t,
(
)
[
]2
〈
〉
I 
〈〉
prms
2
ρ0c
----------
=
prms
2
SPL
10 dB 
10
prms
20 10–6
(
)
----------------------
⎝
⎠
⎛
⎞
2
log
=
20 dB 
10
prms
20 10–6
(
)
----------------------
⎝
⎠
⎛
⎞
log
=
I 
〈〉
I 
〈〉
IL
10  dB log10
I 
〈〉
10–12
-------------
⎝
⎠
⎛
⎞
=
99.1 dB
=

296
Chapter 16
There are two reasons for the small discrepancy in
a given physical situation between the numerical
values for SPL and IL. Firstly, the reference values,
although close, are not exactly equivalent and the
specific acoustic impedance of air for plane waves
varies dependent upon the ambient total atmospheric
pressure and the absolute temperature. For the range
of ambient conditions usually encountered in practice
they will agree within a fraction of a decibel as was
the case in our example. For all practical purposes,
then, the SPL and the IL can be taken as one and the
same.
Plane wave tubes are often used for measuring the
properties of transducers in general and high
frequency compression drivers in particular. We have
seen that a uniformly constructed tube of infinite
length with excitation at one end allows the existence
of a single traveling plane wave in just one direction.
Such a device is obviously not physically possible.
We need to visualize a device of finite length that
maintains uniform geometry and does not produce
reflections because of its finite length. Two such
possibilities are suggested in Figs. 16-13 and 16-14.
Figs. 16-13 and 16-14 are cross-sectional draw-
ings of viable plane wave tube structures. In each
instance the inner tube diameter is greatly exagger-
ated as compared with the actual tube length. Typical
inner diameters for use with compression drivers
must exactly match the exit apertures of the drivers
of interest. The inner diameters would then be of the
order of an inch or so but the tube must be ten or
more feet in length. In both instances the structure is
a figure of revolution about the central axis so that
cylindrical symmetry is maintained over the entire
length of the structure. As a result there are no abrupt
changes in geometry. The interior shaded regions in
both instances are occupied by a uniform open cell
acoustical foam that has a specific acoustical imped-
ance that matches as closely as possible that of air in
the range of 410 to 415 Rayls. The tubes must be
mounted vertically because acoustical foam is flex-
ible and a horizontal mount would lead to sag of the
foam that would destroy the cylindrical symmetry.
This would be particularly true for the conical foam
structure of Fig. 16-13. The hollow tube employed in
the structure in both instances must have smooth
interior walls of sufficient thickness to be rigid.
The rationale behind the proposed structure is
quite straightforward. Having an exact match
between driver exit diameter and the tube’s inner
diameter ensures two things. In the first instance the
driver’s compression ratio will not be influenced by
its attachment to the tube and secondly, there will not
be an abrupt change in geometry that would cause a
reflection back into the driver. In the air-filled space
near the driver the plane wave propagates in the
normal fashion and as the wave progresses down the
tube it encounters no abrupt geometry changes and is
always in media having a common value of specific
acoustical impedance. The portion of the wave in the
free air is undergoing an adiabatic process and loses
no acoustical energy. The portion of the wave in the
acoustical foam on the other hand is in a medium of
much higher thermal conductivity and is undergoing
a predominantly isothermal process where acoustical
energy is being dissipated as heat. Finally the greatly
attenuated wave enters a region entirely filled with
foam for a sufficient length that the remaining acous-
tical energy for all practical purposes is completely
absorbed by the time the end of the tube is reached.
In summary, there are no reflections back towards the
source. The downside associated with these struc-
tures is the necessity of the vertical orientation,
where ceiling heights are restricted, and the expense
involved in accurately shaping the acoustical foam.
As an alternative, Fig. 16-15 depicts what might
be called a poor man’s plane wave tube. In viewing
Fig. 16-15 the reader should be aware that the dimen-
sional scales associated with the driver mounting
flange, the microphone port, and the tube diameter
are greatly magnified relative to the tube length in
order to show construction details. The microphone
port should be as close to the driver as possible and
should make a tight fit with the body of a pressure
sensitive microphone assumed to be cylindrical in
shape. The microphone should be no more than 0.5in
in diameter with a 0.25 in diameter microphone being
preferred. In either case the microphone capsule’s
protective grid should be removed and the micro-
phone should be positioned such that its diaphragm’s
surface is just tangent with the inner wall of the plane
wave tube. Half of the length of the tube is to be
filled with graduated stuffing of ordinary fiberglass
building insulation. The shaded interior portion of
the drawing in Fig. 16-15 indicates this. The gradu-
ated stuffing is prepared in the following way. The
final one-foot length near the end of the tube should
Figure 16-13. Possible plane wave tube structure.
Figure 16-14. Alternative plane wave tube structure.

What is Waving and Why
297
be compacted firmly and then the amount of compac-
tion should be gradually reduced until the midpoint
of the tube is reached. Thick-walled PVC piping of
the appropriate inner diameter may be employed for
the plane wave tube and a smaller pipe with a
plugged end with incremental length markings can
be employed as a stuffing plunger while working
with small tuffs of the fiberglass. The principal tube
may be mounted horizontally if it is provided with
adequate supports to keep the tube level. Several
squares of ¾ in plywood with an appropriate center
hole sized to fit the outside diameter (o.d.) of the
plane wave tube are adequate. The graded absorber is
admittedly not perfect. If care is taken in making it,
however, any reflections will be close to 40 dB down.
If the distance between the microphone port and the
face of the graded absorber is at least 5 ft then the
first possible reflection will return to the measuring
port after a time of 10ft/1128ft/s or approximately
0.009s. Furthermore, if one employs a TEF, Sysid, or
similar measurement program the contribution from
any reflections can be screened out with only a
moderate loss in the frequency resolution of the
measurement. If sufficient horizontal space is avail-
able, a tube of 20 ft of overall length with 10ft of
graduated stuffing will allow accurate measurement
to as low as 50 Hz.
There is one caution related to high frequency
operation. A cylindrical wave guide can support
modes of wave propagation other than that of plane
waves if the guide is suitably excited above a
frequency as given by the following equation,
 where d is the inner diameter of
the wave-guide.
This frequency is approximately 8 kHz for a
one-inch diameter guide and of course 4 kHz for a
two-inch diameter guide. This matter as well as
wave-guide behavior for various impedance
miss-matches will be the topic of a later discussion.
16.3 Non-Planar Wave Motion in a Tube
When a plane wave tube is excited at its origin by a
tightly fitting, oscillating piston as illustrated in
Fig. 16-16, the resulting wave motion is that of a
plane wave propagating in the direction of
increasing z. In this motion, the acoustic pressure
and the particle velocity are uniform over the
cross-section of the tube and the particle velocity
oscillates only in the z-direction. The phase velocity
of this plane wave motion is independent of the
frequency of excitation. This is not the case for an
arbitrary type of excitation nor is it necessarily true
when a compression driver excites a plane wave
tube as the emerging wave front from such a device
may have some curvature. In such instances, one
must consider a more general solution to the wave
equation consistent with the geometry of the plane
wave tube.
In terms of the cylindrical coordinates, (r, θ, and
z), that are the simplest ones to employ for the geom-
etry at hand the general solution to the wave equation
for acoustic pressure is expressed as a product of
three different functions. The first of these functions
describes how the acoustic pressure depends on the
radial distance from the central or z-axis of the tube.
The second function describes how the acoustic pres-
sure varies with the polar angle measured about the
central axis. The third function describes how the
acoustic pressure varies with regard to both position
along the z-axis and with time.
The radial behavior is described by a Bessel func-
tion of the first kind of which there are many choices
depending upon exactly what mode of wave motion
is involved. These Bessel functions are ordered by a
subscript m. Bessel functions with orders 0 through 3
are depicted in Fig. 16-17.
As can be seen from Fig. 16-17 the Bessel func-
tions of the first kind appear almost as damped sine
or cosine functions of the variable x although they
are not, as the zero crossings are not periodic. One
needs to refer to math tables or computer based math
programs to obtain detailed behaviors. The variable x
employed in Fig. 16-17 does not refer to the space
variable x but rather to the combination kmnr where r
is the radial distance from the z-axis and kmn is the
Figure 16-15. Poor man’s plane wave tube for horizon-
tal mounting.
Driver Mounting Flange
Microphone Port
5 ft or More
10 ft or More
f
1.84c
πd
(
)
⁄
=
Figure 16-16. Plane wave tube excited by an oscillating
piston at the origin.
z = 0
To Infinity

298
Chapter 16
radial wave motion propagation constant. The radial
propagation constant kmn requires some extended
discussion. First off it has two integral indices m and
n. The index m refers to the order of the Bessel func-
tion while the index n refers to the order of the posi-
tion of the variable x in Fig. 16-17 where the
particular Bessel function at hand has zero slope.
This zero slope is important because an acceptable
solution can only be one for which the radial compo-
nent of the particle velocity must vanish at the rigid
wall of the waveguide and this radial component of
particle velocity is proportional to the derivative of
the acoustic pressure with respect to the variable r.
When r = a, the derivative of the pressure with
respect to r, that is the slope, must be zero. For
example, let m = 1. The first value of x beyond the
origin at which the slope of this curve is zero is at the
point x = 1.841. This requires then that k11 must be
 in order for k11r = 1.841 when r becomes
equal to a. Similarly, when m = 2, the first occurrence
of zero slope is for x = 3.054 requiring k21 be
. The significance of this can be learned
from the relationship between the radial propagation
constant kmn and the propagation constant along the
z-axis that is k z. This relationship is
. In order to have a
propagating mode along the z-axis, kz must be a real
number. This will be true only for those operating
frequencies where 
 or when
. Consider the mode where m = 1 and
n = 1. The frequency below which this mode cannot
propagate, that is the cutoff frequency, is given by
and
Table 16-3 lists all of the modal cutoff frequen-
cies in the 20 kHz audio band for a one-inch diameter
(0.0254 m) plane wave tube. The cutoff frequencies
for a two-inch diameter tube are one-half those for a
one-inch diameter tube.
The modes listed in Table 16-3 are dispersive
modes. They propagate at operating frequencies
above their respective cutoff frequencies, but do so
with a frequency dependent phase velocity. This
means that different frequency components of a
wideband signal above cutoff propagate with
different speeds and wave shapes are not preserved.
The phase velocity measured along the z-axis is
given by 
. Below its respec-
tive cutoff frequency, each mode becomes evanes-
cent. This means that the mode does not propagate or
transport energy along the z-axis but rather its pres-
sure contribution attenuates exponentially with
distance from the origin.
A reasonable question to ask at this point is,
“What does the solution look like with all of these
added complications?” The answer is a sum over all
indices that can contribute for a given operating
frequency or range of operating frequencies of pres-
sure terms of the following structure
(16-50)
In the above equation Amn are amplitude factors
determined by the conditions at the exciting source.
These amplitude factors differ depending on the
values of m and n, namely on the particular mode
involved. All of these non-planar modes have
non-uniform pressures as well as polarities over the
cross section of the waveguide. The next question
should be, “Where is our familiar plane wave solu-
tion in all of this?” The answer again lies in a further
examination of Fig. 16-17. Notice that when m = 0,
the function J0 has zero slope when x = 0, that is right
at the origin. For this case, not only is m = 0 but n and
k00 are zero as well while J0(k00r) has the value of
one independent of r. As m = 0, cos(mθ) is unity
independent of the angle θ and the solution becomes
the familiar 
 with A being
the pressure amplitude at the face of the piston that is
uniform over the cross section of the tube. Further-
Figure 16-17. Bessel functions Jm(x) for orders m = 0
through m = 3.
m = 0
m = 1
m = 2
m = 3
1
0.5
0
–0.5
0 
1 
2 
3 
4 
5 
6 
7 
8 
9 
10
Value Function
x
Bessel Functions of the First Kind
1.841 a
⁄
3.054 a
⁄
kz
ω c
⁄
(
)2
kmn
(
)2
–
[
]1 2
⁄
=
ω c
⁄
(
)2
kmn
(
)2
>
ω
kmnc
>
f11
1.841c
(
)
2πa
(
)
⁄
=
f21
3.054c
(
)
2πa
(
)
⁄
=
Table 16-3. Cutoff Frequencies in the Audio Band 
for a One-inch Diameter Plane Wave Tube
m
n
kmn
fmn in Hz
1
1
1.841 / a
7936
2
1
3.054 / a
13,166
0
2
3.832 / a
16,520
3
1
4.20 / a
18,106
ω
ω c
⁄
(
)2
kmn
2
–
[
]1 2
⁄
⁄
pmn r θ z t
, , ,
(
)
AmnJm kmnr
(
)
mθ
(
)
ωt
kzz
–
(
)
cos
cos
=
p z t,
(
)
A
ωt
kzz
–
(
)
cos
=

What is Waving and Why
299
more, as k00 is zero, the phase velocity is a constant
value c at all frequencies.
16.4 Plane Wave Tubes having Arbitrary 
Terminations
Next we turn our attention to tubes of finite length
that are excited only with plane waves but have arbi-
trary terminations. A good starting point is a tube
with length L excited by a piston as in our original
case but which is terminated by a rigid barrier at its
receiving end. This situation is depicted in the upper
half of Fig. 16-18.
As the piston begins to move in the actual struc-
ture a plane wave propagates in the positive z-direc-
tion reaching the rigid barrier after a time lapse of
L ⁄c. As the barrier is rigid, there can be no particle
displacement or velocity at the barrier at any time.
The wave is reflected and then travels in the negative
z-direction back to the source where it is again
reflected but now by the moving piston. This process
continues to repeat itself over and over and after
numerous transits back and forth arrives at a steady
state condition with the boundary conditions at the
piston matching those of the piston’s motion and
those at the barrier corresponding to zero particle
displacement as well as velocity. In the region
 we ultimately have the superposition of
two waves traveling in opposite directions. The wave
equation is linear so the principle of superposition is
applicable in arriving at a solution for a particular
case. Furthermore, the solution to the wave equation
that satisfies the given boundary conditions is unique
so we can treat the problem by analyzing the equiva-
lent structure in the lower half of Fig. 16-18 that is
based on the method of images. In this technique the
left (light colored) piston is the actual source and the
right (dark colored) piston is the image source that is
located just as far to the right of the barrier as the
actual source is located to the left of the barrier.
When the left piston displaces to the right, the right
piston displaces similarly to the left. In the equivalent
structure there is no barrier at z = L although its posi-
tion is indicated in the drawing. In the active interval
 in which our solution will apply we sum
the individual waves generated by the real source and
the image source. When the left piston moves to the
right the air in front of it is compressed so it produces
a pressure wave given by 
where pm is the pressure amplitude and k is the prop-
agation constant along the z-axis. Here we have
dropped the subscript on the propagation constant as
we are dealing only with a plane wave. Similarly,
when the image piston moves to the left it produces a
pressure wave 
. The situation
with regard to the particle velocity is decidedly
different however. The particle velocity wave gener-
ated by the left piston is 
,
however when the right piston moves to the left, the
air particles are moving in the negative direction so
. Furthermore, 
so in the active interval 
 the total acoustic
pressure is given by
(16-51)
while the total particle velocity is given by
(16-52)
These composite expressions describe standing
waves. Our traveling waves in opposite directions
have combined to form standing waves of both
acoustic pressure and particle velocity. Now at the
barrier where z = L, the acoustic pressure is
. This means that the pres-
sure amplitude is doubled signifying that a normally
incident pressure wave is reflected in phase at a
rigid barrier. On the other hand, the particle velocity
(u) 
at 
the 
barrier 
as 
given 
by
 is identi-
cally zero at all times, indicating that a normally
incident particle velocity wave is reflected with a
change of polarity or a phase shift of π radians at a
rigid barrier. The important question is, “What are
the conditions at the origin where the left piston is
located?” Upon setting z = 0 in the general equa-
tions we find that the total acoustic pressure at the
origin is now 
.
Now it is important to remember at this point that
all angles are expressed in radians. Suppose that the
length L is exactly 
 at the operating frequency
Figure 16-18. Tube terminated by a rigid barrier.
z = 0
z = L
z = 0
z = L
 z’ = –L
z’ = 0
 z = 2L
Actual Structure
Equivalent Structure
0
z
L
≤
≤
0
z
L
≤
≤
pl
pm
ωt
kz
–
(
)
cos
=
pr
pm
ωt
kz′
+
(
)
cos
=
ul
um
ωt
kz
–
(
)
cos
=
ur
u
– m
ωt
kz′
+
(
)
cos
=
z′
z
2L
–
=
0
z
L
≤
≤
p
pm
ωt
kz
–
(
)
cos
pm
+
ωt
kz
2kL
–
+
(
)
cos
=
u
um
ωt
kz
–
(
)
cos
um
–
ωt
kz
2kL
–
+
(
)
cos
=
p
2pm
ωt
kL
–
(
)
cos
=
u
um
ωt
kL
–
(
)
cos
um
–
ωt k
– L
(
)
cos
=
p
pm
ωt
(
)
cos
pm
+
ωt
2kL
–
(
)
cos
=
λ 4
⁄

300
Chapter 16
of the piston. Upon remembering that
, then 
.
When this is the case, the two pressure terms differ
in phase by π and their sum is zero at all times t.
This is a resonant condition. The acoustic pressure
being identically zero means that the piston motion
is completely unimpeded. This will be true also
when L is any odd integral multiple of 
. This
ideal is never exactly achieved in practice because
there are always some very small viscous losses at
the walls of the tube and the amplitude of the right
piston motion is always slightly less than that of the
left piston.
The conditions that exist at the exciting piston for
a tube of arbitrary length L terminated in a rigid
barrier are usually studied by means of the mechan-
ical impedance presented to the piston as a result of
its interaction with the air at the origin. This mechan-
ical impedance is the ratio of the complex force
acting on the air at the piston face to the complex
particle velocity of the air at the piston face. The
complex force is the acoustic pressure at the origin
expressed as a complex exponential or phasor multi-
plied by the cross sectional area of the tube. The
complex particle velocity is the complex exponential
statement of the particle velocity also at the origin.
Complex exponentials and phasors are described in
detail in Chapter 6. The mechanical impedance then
is calculated from
(16-53)
This can be simplified by factoring and canceling
common terms in both the numerator and denomi-
nator to yield,
(16-54)
The conclusion is that the mechanical impedance
presented to the piston is a negative reactance for
positive values of the cotangent as indicated by the
–j in the final statement. If there were no viscous
losses this impedance would be zero at the resonant
condition where L equals odd integral multiples of
 and would be infinite for the anti-resonant
condition where L equals integral multiples of 
.
The fact that the mechanical impedance is purely
reactive means that once steady state conditions are
reached the average power supplied by the piston
becomes zero in the ideal case. It also means that the
acoustic pressure and particle velocity in the
standing wave differ in phase by 
 radians or
90°.
Next we will explore the general technique that is
applicable to plane wave tubes having arbitrary
terminations including that of a rigid barrier, an
open-ended tube, and any other given mechanical
impedance. Finally, we will consider the interaction
between a small loudspeaker employed to excite the
tube and an improperly terminated plane wave tube.
As a reminder, the mechanical impedance is
defined to be the ratio of the complex mechanical
force applied to an object divided by the resulting
complex mechanical velocity of the object
(16-55)
Additionally, at any point in a sound field the ratio
of the complex acoustic pressure to the resulting
particle velocity is called the specific acoustic
impedance at the point in question.
(16-56)
Now consider a plane wave tube that is fitted with
a piston at z = 0 and mechanical impedance of ZL at
the spatial point z = L. Let the piston displacement at
any time be described by the phasor
(16-57)
where,
ξm is the amplitude of the piston displacement,
ω is the angular frequency of piston oscillation.
Remember that the actual piston motion is given
only by the real part of this phasor namely
. In the general case ZL does not
properly terminate the tube so we must allow for both
a primary wave and a reflected wave. In which case
the phasor description of the two waves becomes
(16-58)
At the origin where z = 0, the boundary condition
is satisfied by having this last expression match the
given piston motion from which it is learned that
. 
Another independent equation is required in order
to determine A and B uniquely. This equation is
obtained by recognizing that at z = L the ratio of the
k
2π
(
) λ
⁄
=
2kL
2 2π λ
⁄
(
) λ 4
⁄
(
)
π
=
=
λ 4
⁄
Zm
pmS
um
---------
e jωt
e j ωt
2kL
–
(
)
+
e jωt
e j ωt 2
– kL
(
)
–
---------------------------------------
×
=
Zm
pmS
um
---------
1
e-j2kL
+
1
e-j2kL
–
----------------------
×
=
pmS
um
---------
e-j2kL
e-j2kL
-------------
×
e jkL
e-jkL
+
e jkL
e-jkL
–
--------------------------
×
=
pmS
um
---------
kL
(
)
cos
j
kL
(
)
sin
---------------------
×
=
j
–  pmS
um
---------
kL
(
)
cot
=
λ 4
⁄
λ 2
⁄
π 2
⁄
Zm
F
u---
=
Zs
p z t,
(
)
u z t,
(
)
---------------
=
ξ
ξmejωt
=
ξ
ξm
ωt
(
)
cos
=
ξ z t,
(
)
Ae j ωt
kz
–
(
)
Be j ωt
kz
+
(
)
+
=
ξm
A
B
+
=

What is Waving and Why
301
acoustic force to the particle velocity at that point
must be equal to the mechanical impedance at that
point. It is necessary then to write the general expres-
sions for the acoustic pressure and the particle
velocity that are valid anywhere in the tube and
particularly at z = L.
(16-59)
(16-60)
where,
s(z, t) is the condensation,
ρ0 is the undisturbed air density.
Now the force at z = L is the acoustic pressure at
that point multiplied by the cross-sectional area, S, of
the tube. Dividing the force by the particle velocity at
z = L leads to the second equation involving A and B.
(16-61)
The two independent equations for A and B are now
solved simultaneously to obtain
(16-62)
(16-63)
Knowing the values for A and B it is now possible
to evaluate ξ(z, t), p(z, t), and u(z, t) anywhere in the
tube. In particular, at the input of the tube where z is
zero we can determine the mechanical load or imped-
ance that the tube presents to the motion of the
piston. This term is called Z0 and is calculated to be
(16-64)
This last result is quite general and applies not
only to tubes but other shapes as well as long as the
operating wavelength is large compared with the
largest dimension associated with the structure’s
cross-section. Our previous result for a tube termi-
nated with a rigid barrier that was calculated earlier
can be readily obtained from the general expression
for Z0 by dividing both numerator and denominator
by ZL and then allowing ZL to approach infinity.
Another observation with regard to this general case
that is worthy of note is the behavior that occurs
when the tube is driven at a frequency or frequencies
such that the tube length is an integral number of half
wavelengths. When this is true, the tangent terms in
Z0 are exactly zero and Z0 becomes identically equal
to ZL and the tube’s mechanical impedance opposing
the piston’s motion is the same as the mechanical
impedance that terminates the tube. The half wave-
length tube then acts as an ideal transformer having a
turns ratio of 1:1.
Rather than being terminated in a rigid barrier or
cap, suppose that the tube just ends abruptly at z = L
while being surrounded by a very large, ideally infi-
nite, plane baffle. What is the terminating mechanical
impedance in this instance? The answer is not zero
because the air particles at the end of the tube must
push against the outside air contained within a 2π
solid angle when they suffer displacement by the
forward traveling wave contained within the tube. In
fact, the air particles at the end of the tube experience
exactly the same impedance as that experienced by
the front face of a piston that is radiating into a half
space or 2π solid angle. Alternatively, the truncated
end of the tube might just end in open space in which
case the radiation is almost unconfined or experi-
ences nearly a 4π solid angle. In the latter case the
acoustic pressure is approximately one half of that of
the former case. Since the force is directly propor-
tional to the pressure, the impedance experienced by
the truncated tube less the baffle is also approxi-
mately one-half that of the infinite baffle case. In
either case, the terminating impedance is calculated
through the employment of what is termed the piston
impedance function. The piston impedance function
has real and imaginary parts that are written as
 where 
 and a is the
piston radius or, in this case, the inner radius of the
tube. The real part of the piston impedance function
can be expressed in terms of the first order Bessel
u z t,
(
)
∂ξ z t,
(
)
∂t
------------------
=
jωξ z t,
(
)
=
jω Ae j ωt
kz
–
(
)
Be j ωt
kz
+
(
)
+
[
]
=
p z t,
(
)
ρ0c2s z t,
(
)
=
ρ
–
0c2∂ξ z t,
(
)
∂z
------------------
=
ρ0c2  jk
(
) Ae j ωt
kz
–
(
)
Be j ωt
kz
+
(
)
–
[
]
=
ZL
ρ0cS Ae–jkL
Be jkL
–
(
)
Ae–jkL
Be jkL
+
(
)
----------------------------------------
=
A
ξm
2------
1
ZL
ρ0cS
------------
+
1
j
kL
(
)
tan
+
[
]
1
j ZL
ρ0cS
------------
kL
(
)
tan
+
---------------------------------------------------------------
×
=
B
ξm
2------
1
ZL
ρ0cS
------------
–
1 j
–
kL
(
)
tan
[
]
1
j ZL
ρ0cS
------------
kL
(
)
tan
+
------------------------------------------------------------
×
=
Z0
Sp 0 t,
(
)
u 0 t,
(
)
-------------------
=
ZL
jρ0cS
kL
(
)
tan
+
1
j ZL
ρ0cS
------------
kL
(
)
tan
+
----------------------------------------------
=
R 2ka
(
)
jX 2ka
(
)
+
k
2π
(
) λ
⁄
=

302
Chapter 16
function of the first kind that we encountered previ-
ously in this chapter while the imaginary part can be
expressed in terms of the first order Struve function.
(16-65)
(16-66)
These functions are graphed in Fig. 16-19.
The terminating impedance of a truncated tube
with a baffle expressed in terms of the piston imped-
ance function is 
while that of the truncated tube without a baffle is
approximately one half this amount.
It is very important to note that all of the fore-
going takes no account of energy losses occurring
within the air or at the interior surfaces of the tube.
Air has both a viscous shear modulus that is a loss
factor at the tube surfaces and a viscous bulk
modulus that is a loss factor throughout the enclosed
volume. Heat generation and conduction in the body
of the gas and at the tube walls are even further
considerations with regard to energy loss. A pursuit
of these topics would carry us much further into the
physics of fluids than we are prepared to go here.
Even though the losses are small for short tubes of
reasonable diameter, their inclusion significantly
complicates the mathematics of the description of the
process. The losses could be accounted for in our
equations by allowing the propagation constant k to
be complex with the form 
. Replacing k in our
equations by this complex form forces the particle
displacement in our description to become
(16-67)
In addition to having to redo the analysis
employing this starting point, the problem is further
complicated by the fact that both α and β are
frequency dependent in a complicated fashion. The
frequency dependence of β is particularly trouble-
some because the phase velocity being 
 will no
longer be independent of frequency. The problem can
be handled exactly but the mathematics is more
tedious. We will consider our results to be a first as
well as useful approximation to the more exact ones.
Now we will use our approximate results to
calculate the lowest resonant frequencies of a
two-inch diameter loudspeaker whose front face is
attached to a short tube of two inches inner diameter
with the far end of the tube being terminated in a
rigid cap. The back of the loudspeaker is enclosed
by a small box. The air trapped in the box and the
loudspeaker’s suspension together act as a spring
with a total stiffness of K. The suspension also
furnishes a mechanical resistance Rm. The moving
mass of the loudspeaker cone is M and the loud-
speaker itself has a total mechanical impedance Zls
with 
. As we previously
learned the closed tube loads the front face of the
loudspeaker with a mechanical impedance that is
. The total mechanical impedance
presented to the agency that drives the loudspeaker
is then the sum of these two impedances with
. 
The
driven loudspeaker will be at resonance for those
frequencies where the total reactance in the
mechanical impedance expression becomes zero or
where 
. In this last
equality, we replace k by ω/c and then replace ω by
2πf so that both sides can be plotted versus f. The
intersection points of the two resulting curves iden-
tify the resonant frequencies. This was done by
employing the parameters typical of a two-inch
loudspeaker mounted on a two-inch tube of
one-meter length. The results are presented in Fig.
16-20. For comparison purposes, the same calcula-
tion was performed taking account of air losses in
the tube. These results are presented in Fig. 16-21.
The mechanical impedance at the input of a capped
tube when the air losses in the tube are small is
Figure 16-19. Real and Imaginary parts of the piston
impedance function.
R 2ka
(
)
1
J1 2ka
(
)
ka
-------------------
–
=
X 2ka
(
)
H1 2ka
(
)
ka
---------------------
=
Real
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
00
5
10
15
20
2ka
X(2ka)
0
5
10
15
20
2ka
X(2ka)
Imaginary
1.2
1.0
0.8
0.6
0.4
0.2
0
ZL
ρ0cS R 2ka
(
)
jX 2ka
(
)
+
[
]
=
β
jα
–
ξ
Ae–αze j ωt
βz
–
(
)
Be+αze j ωt
βz
+
(
)
+
=
ω β
⁄
Z1s
Rm
j ωM
K ω
⁄
–
(
)
+
=
–jρ0cS
kL
(
)
cot
Zm
Rm
j ωM
K
–
ω
⁄
ρ0cS
kL
(
)
cot
–
(
)
+
=
ωM
K ω
⁄
–
ρ0cS
kL
(
)
cot
=

What is Waving and Why
303
(16-68)
The real part of this expression is a mechanical resis-
tance and along with the mechanical resistance of
the loudspeaker broadens the shape of a resonance
but does not effect its location. Setting α equal to
zero reduces the impedance expression to that which
was derived without considering air loss. There are
resonances beyond the frequency range depicted, but
the height of the dotted curve eventually exceeds
that of the solid and there will be no further intersec-
tions beyond such a point.
16.5 Impedance Tube
The analyses discussed in the preceding section
form the basis for a device employed in the determi-
nation of the mechanical impedance properties of
materials that are often employed as acoustical
energy absorbers. The structure of such a device is
illustrated by Fig. 16-22.
An impedance tube consists of a hollow, rigid
walled tube that is fitted with a driven piston whose
right hand face has a rest position at 
. Begin-
ning at 
, the remainder of the volume of the
tube is fitted with the sample of interest through
which passes a thin, calibrated rod whose purpose is
to control the position of a miniature pressure sensi-
tive microphone. The piston undergoes an oscillatory
motion with amplitude of 10-6 m at a frequency of
1000 Hz in the example to be presented here. In this
example the static density of air, 
, is 1.2kg•m-3
and the sound speed, c, is 344m•sec-1. The wave-
length of the plane wave generated by the piston’s
motion is 0.344m and the distance L is adjusted to
this value. The plane wave generated by the piston
propagates toward the sample where a portion of the
wave energy is reflected back towards the piston and
the remainder is transmitted into the sample where it
is subsequently absorbed assuming the sample is
homogeneous and of sufficient length. Under steady
state conditions the air-filled space in the interval
 contains a plane wave traveling in the
direction of increasing z and a wave of lower ampli-
tude and shifted phase traveling in the direction of
decreasing z. The superposition of these oppositely
directed traveling waves produces a stationary or
standing wave pattern in this space an example of
which can be experimentally determined by posi-
tioning the movable miniature microphone at succes-
sive values of the coordinate z in the air filled space
Figure 16-20. The solid curve is a plot of the cotangent
reactance function with the vertical lines indicating the
points of discontinuity of this function. The dashed
curve is the loudspeaker reactance curve. Discounting
the intersections at the discontinuous jumps, in the
depicted frequency range the lowest resonance is
165Hz, the middle resonance at 281 Hz is close to the
loudspeaker’s natural resonance without front loading
of 290Hz, and the upper resonance is at 362 Hz.
Figure 16-21. The solid curve is the reactance pre-
sented by the tube including the effect of air losses. The
dashed curve is the loudspeaker reactance curve. The
resonant frequencies indicated here are essentially the
same as those of Fig. 16-20.
Z0
ρ0cS
αL
j
kL
(
)
cos
kL
(
)
sin
–
sin2 kL
(
)
αL
(
)2cos2 kL
(
)
+
----------------------------------------------------------------
=
100
80
60
40
20
0
−20
−40
−60
−80
−1000 
50 
100 
150 
200 
250 
300 
350 
400 
450 
500
Frequency
Reactance
100
80
60
40
20
0
−20
−40
−60
−80
−100
0 
50 
100 
150 
200 
250 
300 
350 
400 
450 
500
Frequency
Reactance
Figure 16-22. The illustration is an example of an
impedance tube’s basic structure.
z = 0
z = L
z
0
=
z
L
=
ρ0
0
z
L
≤
≤

304
Chapter 16
and measuring the acoustic pressure at each position.
The results of such observations obtained with a
particular sample are displayed in Fig. 16-23.
The standing wave pattern of Fig. 16-23 features
both minima and maxima. The minima are called
nodes and the maxima are anti-nodes. Knowledge of
the location of the first node and its associated pres-
sure along with the pressure at the anti-node are
sufficient experimental information to allow us to
learn the mechanical impedance of the sample under
test, as we will subsequently demonstrate. The first
node is located at z = 0.043  m and is exactly
one-eight of a wavelength from the origin. The
acoustic pressure at this node has a value of
1.40Pascals. The first anti-node has an acoustic pres-
sure of 3.38Pascals. The standing wave ratio or SWR
is the quotient of these two values and is 2.414.
In our original discussion of a piston driven plane
wave tube with an arbitrary termination we found the
following two phasor equations describing the
particle displacement and acoustic pressure present
in the tube as well as the general expression for the
terminating impedance at z = L.
(16-69)
(16-70)
(16-71)
Identities for these three equations in a more conve-
nient form for the present purpose appear with the
following structure.
(16-72)
(16-73)
(16-74)
Recall that A and B are in general complex ampli-
tude factors and that the magnitude of B is less than
that of A. We will then represent their quotient as
Fe jθ, where F is less than one and is the magnitude of
B divided by the magnitude of A and the angle theta
is the angle of B minus the angle of A. Making use of
this form of the quotient, the equation for the
acoustic pressure takes on the following form.
(16-75)
The pressure amplitude will have its first
minimum when the term in the bracket first
acquires a minimum value. This minimum is
simply 1 − F. This occurs when 
 first
becomes equal to zero because Euler’s theorem
states that 
. Recall
that 
 and that the first node in the pres-
sure curve occurs at 
 so
(16-76)
At the pressure node the value of the exponential
term multiplying F is just one so that the minimum
pressure is proportional to 1 − F. By the same token,
the pressure at the anti-node occurs when the value
of the exponential term multiplying F is minus one
and the maximum pressure is proportional to 1 + F.
The standing wave ratio or SWR was experimentally
found to be 2.414. Therefore we may write
(16-77)
Finally, we are now in position to determine the
value of the terminating mechanical impedance ZL.
We purposely chose the length L to be a wavelength
at the operating frequency. This choice makes the
angle in the exponential factors of the equation for ZL
have the value of either +4π or −4π for which the
cosine of the angle is one and the sine of the angle is
zero in either case, so ZL is simplified to
Figure 16-23. Pressure standing wave produced in an
impedance tube.
0 
0.05 
0.1 
0.15 
0.2 
0.25 
0.3
0.35
3.4
3.2
3.0
2.8
2.6
2.4
2.2
2.0
1.8
1.6
1.4
Acoustic Pressure Standing Wave
Pressure Amplitude in Pascals
Value of the z coordinate in meters
ξ z t,
(
)
Ae j ωt
kz
–
(
)
Be j ωt
kz
+
(
)
+
=
p z t,
(
)
ρ0c2jk Ae j ωt
kz
–
(
)
Be j ωt
kz
+
(
)
–
[
]
=
ZL
ρ0cS Ae jkL
–
Be jkL
–
(
)
Ae jkL
–
Be jkL
+
(
)
----------------------------------------
=
ξ z t,
(
)
A 1
B
A---e j2kz
+
e j ωt
kz
–
(
)
=
p z t,
(
)
ρ0c2jkA 1
B
A---e j2kz
–
e j ωt
kz
–
(
)
=
ZL
ρ0cS
1
B
A---e j2kL
–
⎝
⎠
⎛
⎞
1
B
A---e j2kL
+
⎝
⎠
⎛
⎞
------------------------------
=
p z t,
(
)
ρ0c2jkA 1
Fe j θ
2kz
+
(
)
–
[
]e j ωt
kz
–
(
)
=
θ
2kz
+
e j 0
( )
0
( )
cos
j
0
( ) 
1
=
sin
+
=
k
2π λ
⁄
(
)
=
z
λ 8
⁄
=
θ
22π
λ
------λ
8---
+
0
θ
∴
π
2---
–
=
,
=
1
F
+
1
F
–
-------------
2.414 from which, F
0.4142
=
,
=

What is Waving and Why
305
(16-78)
Upon substituting the magnitude of F = 0.4142 in
the above equation we arrive with the result
(16-79)
S is just the cross-sectional area of the impedance
tube and if we divide the mechanical impedance of
the terminating medium by S we will be left with the
specific acoustic impedance of the medium in this
instance, 
.
An acoustic pressure wave propagating in a medium
having a complex specific acoustic impedance as in the
above example loses energy as both a function of the
distance traveled as well as the frequency and has a
phase velocity that is frequency dependent.
16.6 More General Waves
The foregoing might leave the false impression that
plane waves exist only in pipes, tubes, or other
bounded structures. This is far from the truth. Plane
waves can readily exist in unbounded regions. In
fact, acoustic radiation from any source of finite
dimensions will eventually approach plane wave
status at sufficiently large distances from the source.
We will observe this effect in the next section
dealing with simple spherical waves.
Pulsating Sphere
If we were asked to visualize the simplest possible
structure that could generate sound waves in three
dimensions based only on what we have learned so
far along with all our experiences from childhood
onward we probably would imagine a pulsating,
impermeable spherical surface. Such a surface might
have a nominal radius, a, and would be alternately
expanding and contracting with all motion being
along radial lines. No loudspeaker has ever been
constructed in exactly this way though if one did
exist it would have the useful property of radiating
uniformly in all directions. Imagine that the sphere is
pulsating at a fixed frequency f and that the radial
velocity at any point on the surface of the sphere is
given by the real part of 
 where 
and um is the amplitude of the radial surface velocity.
Under these conditions the alternate small expan-
sions and contractions of the sphere will be radiating
an acoustic signal at the frequency f that will have
some constant average power. As this signal
diverges uniformly into the space surrounding the
pulsating sphere, this power will be spreading out
and flowing through concentric surfaces having
progressively increasing radii. The amount of power
is constant but the area through which it must flow is
growing at a rate that is proportional to the radial
distance from the center of the pulsating sphere
quantity squared. As a result, the intensity of the
radiated acoustic signal is decreasing at a rate that is
inversely proportional to the square of the distance
from the origin at the center of the pulsating sphere.
The intensity in general is proportional to the square
of the acoustic pressure. Therefore, the acoustic
pressure amplitude must be decreasing inversely
with the first power of the radial distance from the
origin. In other words, the pressure amplitude at any
distance r when multiplied by r is a constant for any
value of r equal to or greater than the nominal radius
of the sphere. In the case of plane waves it was
found that the pressure amplitude was constant inde-
pendent of the distance from the origin and that the
wave equation governing the acoustic pressure was
(16-80)
In the spherical wave case under examination, the
product of the pressure with radial distance from the
origin is a constant independent of the choice of
distance from the origin so we propose as a wave
equation
(16-81)
where,
r is the radial distance from the center of the pulsat-
ing sphere
, where a is the nominal radius of the pulsating
sphere.
A solution to the proposed wave equation can be
obtained through the same considerations that were
made in the plane wave case if one recognizes that
the dependent variable is now pr rather than just p
itself thus,
(16-82)
where,
ZL
ρ0cS
1
Fe
j
π
2---
–
⎝
⎠
⎛
⎞
–
1
Fe
j
π
2---
–
⎝
⎠
⎛
⎞
+
--------------------------------
=
ZL
ρ0cSe
j π
4---
⎝⎠
⎛⎞
=
ρ0ce j π 4
⁄
(
)
ume j ωt
(
)
ω
2πf
=
∂2p
∂z2
--------
1
c2
----- ∂2p
∂t2
--------
=
∂2 pr
(
)
∂r2
----------------
1
c2
----- ∂2 pr
(
)
∂t2
----------------
=
r
a
≥
p
A
r---e j ωt
kr
–
(
)
=

306
Chapter 16
A is a complex amplitude factor that must be deter-
mined by the acoustic pressure at the surface of the
pulsating sphere where r has the value a. At this
point, we only know the radial velocity at the sur-
face of the sphere. It is necessary then to explore
the relationship between the acoustic pressure and
the particle velocity in the spherical wave case.
When Newton’s second law was applied in the der-
ivation of the plane wave case it was learned that
(16-83)
A similar application to the present case yields
(16-84)
Substitution of Eq. 16-82 into the left side of
Eq. 16-84 yields
 
(16-85)
Upon solving Eq. 16-85 for the ratio of the
acoustic pressure to the particle velocity one obtains
a quantity that is called the specific acoustic imped-
ance of air for spherical waves.
(16-86)
where,
the angle θ as depicted in Fig. 16-24 represents the
phase difference between the acoustic pressure and
the particle velocity at the radial distance r from
the source,
 is the pressure amplitude divided by
the particle velocity amplitude at the same radial
distance from the source.
Now p = Zsu which means that at the surface of the
sphere where r = a,
(16-87)
When Eq. 16-87 is solved, A is found to be
(16-88)
When this value of A is substituted into Eq. 16-82
the result becomes
(16-89)
Such a formidable equation might evoke thoughts
of a career change. Fortunately, matters can be
considerably simplified by restricting attention to
pulsating spheres which are small such that ka 〈〈1. It
is desirable to do this particularly when this theory is
to be applied to sound sources that are other than of
spherical shape. For ka 〈〈1,
(16-90)
When this approximate expression for A is substi-
tuted into Eq. 16-82 the pressure becomes
(16-91)
Finally, it is useful to introduce the area of the radi-
ating source that for a sphere of radius a is
 so that Eq. 16-91 becomes
(16-92)
A few extra words might be of value here with
regard to the mathematical technique employed in
the above analysis dealing with a real physical vari-
able such as acoustic pressure or particle velocity. In
physical situations where the time t enters the picture
in the form of a harmonic function such
as
 or 
, the mathematical
operations of differentiation and integration with
respect to time are greatly expedited when the
harmonic function is written in the complex
∂p
∂z
------
–
ρ0
∂u
∂t
------
=
∂p
∂r
------
–
ρ0
∂u
∂t
------
=
1
r---
jk
+
⎝
⎠
⎛
⎞p
ρ0
∂u
∂t
------
=
ρ0 jωu
=
Zs
ρ0ckr
1
k2r2
+
-----------------------e
j arctan 1
kr
-----
⎝
⎠
⎛
⎞
=
ρ0c
(
)
θ
( )e jθ
cos
=
ρ0c
(
)
θ
( )
cos
A
a---e j ωt
ka
–
(
)
ρ0cka
1
k2a2
+
------------------------ume
j ωt
arctan 1
ka
------
+
⎝
⎠
⎛
⎞
=
A
ρ0cka2
1
k2a2
+
------------------------ume
j ka
arctan 1
ka
------
+
⎝
⎠
⎛
⎞
=
Figure 16-24. The angle θ is the angle of the specific
acoustic impedance of air for spherical waves.
kr
1
θ
1 + k2r2
p
ρ0cka2
r 1
k2a2
+
---------------------------ume
j ωt k
– r
ka
+
arctan 1
ka
------
+
⎝
⎠
⎛
⎞
=
A
ρ0cka2ume
j π
2---
⎝⎠
⎛⎞
jρ0ωa2um
=
≈
p
jρ0ωa2
r
------------------ume j ωt
kr
–
(
)
=
S
4πa2
=
p
jρ0ωS
4πr
---------------ume j ωt
kr
–
(
)
=
2πft
α
±
(
)
cos
ωt
α
±
(
)
cos

What is Waving and Why
307
exponential form. The angle α may be any angle or
collection of angles that are not time dependent
though they may be frequency dependent. After the
necessary operations have been performed, the actual
real physical quantity is obtained by taking only the
real part of the final complex exponential expression.
An example is perhaps in order. Recall Euler’s
theorem that 
 where β is
any angle, so we write the leading j in Eq. 16-92 as
 and rewrite the equation as 
(16-93)
Next we expand Eq. 16-93 according to Euler to
obtain separated real and imaginary parts.
(16-94)
Finally, it is only the real part of Eq. 16-94 that
describes the actual acoustic pressure as a function
of position and time so
(16-95)
where,
pm is the acoustic pressure amplitude,
ρ0 is the undisturbed air density,
ω is the angular frequency,
S is the surface area of the radiating source,
um is the amplitude of the surface velocity of the
source,
r is the radial distance from the source.
Now that the acoustic pressure is known it
becomes possible to calculate the particle velocity of
the air. The specific acoustic impedance of air for
spherical waves is inherently a complex quantity so
we first represent both Zs as well as p(r,t) as complex
exponentials and make use of the fact that
(16-96)
where,
ua(r,t) is the particle velocity of the air at the dis-
tance r,
pm is the acoustic pressure amplitude at the distance r,
(ρ0c)cos(θ) is the magnitude of the specific acoustic
impedance of air at the distance r.
The physical value for the actual particle velocity is
just the real part of the result of Eq. 16-96 and is
given by
(16-97)
Two items are worthy of note in examining
Eq. 16-97. Firstly, the amplitude of the particle
velocity is the amplitude of the acoustic pressure
divided by the magnitude of the specific acoustic
impedance and secondly, the phase difference
between the acoustic pressure and the particle
velocity is the angle of the specific acoustic imped-
ance as displayed in Fig. 16-24. When we expand
Eq. 16-86, that is the definition of the specific
acoustic impedance of air for spherical waves, into
its separated real and imaginary parts we obtain
(16-98)
As an observer approaches more and more distant
points from a simple spherical source or monopole as
it is called, the term k2r2 grows larger and larger as
compared with one and the real part of Eq. 16-98
approaches the value ρ0c. Additionally, in these
distant regions the imaginary part of Zs is getting
smaller and smaller and is approaching zero with the
result that Zs is approaching the value that is charac-
teristic of plane waves in air where the acoustic pres-
sure and particle velocity are in phase. So at very
large distances from a simple source plane and spher-
ical waves are indistinguishable by only local
measurements.
e j β
( )
β
( )
cos
j
β
( )
sin
+
=
e j π 2
⁄
(
)
p
ρ0Sum
4πr
---------------e
j ωt
kr
–
π
2---
+
⎝
⎠
⎛
⎞
=
p
ρ0ωSum
4πr
--------------------
ωt
kr
–
π
2---
+
⎝
⎠
⎛
⎞
cos
=
+ jρ0ωSum
4πr
--------------------
ωt
kr
–
π
2---
+
⎝
⎠
⎛
⎞
sin
p r t,
(
)
ρ0ωSum
4πr
--------------------
ωt
kr
–
π
2---
+
⎝
⎠
⎛
⎞
cos
=
pm
ωt
kr
–
π
2---
+
⎝
⎠
⎛
⎞
cos
=
ua r t,
(
)
p r t,
(
)
Zs
---------------
=
ρ0ωSum
4πr
--------------------e
j ωt
kr
π
2---
+
–
⎝
⎠
⎛
⎞
ρ0c
kr
1
k2r2
+
-----------------------e jθ
-------------------------------------------------
=
pm
ρ0c
(
)
θ
( )
cos
------------------------------e
j ωt
kr
–
π
2---
θ
–
+
⎝
⎠
⎛
⎞
=
ua r t,
(
)
pm
ρ0c
(
)
θ
( )
cos
------------------------------
ωt
kr
–
π
2---
θ
–
+
⎝
⎠
⎛
⎞
cos
=
Zs
ρ0ck2r2
1
k2r2
+
-------------------
j ρ0ckr
1
k2r2
+
-------------------
+
=

308
Chapter 16
16.7 Acoustic Intensity
Acoustic intensity is a statement of the value of the
acoustic energy flow per unit area per unit of time.
This is the same as acoustic power per unit of area.
We measure and speak of both instantaneous intensity
and average intensity. The instantaneous intensity is
the product of the acoustic pressure with the particle
velocity at any given instant and at the same point in
space as expressed in the following statement.
(16-99)
I(t) is a vector quantity whose direction at any
moment is that of the instantaneous transmission of
acoustic power. The acoustic pressure is a scalar
quantity that has no direction in space although it
does possess an algebraic sign that may change from
moment to moment. The vector character of the
intensity arises from the particle velocity that is
inherently a directed quantity. The average intensity
over a specified time interval is the acoustic energy
per unit area transmitted through an area perpendic-
ular to the direction of wave propagation in the spec-
ified time interval averaged over the specified time
interval. Mathematically this amounts to
(16-100)
In the case of harmonic plane waves, the acoustic
pressure and particle velocity are in phase while the
amplitude of the particle velocity is that of the pres-
sure divided by ρ0c. In this instance Eq. 16-100
becomes
(16-101)
where,
T is the period or an integral number of periods cor-
responding to the particular frequency involved.
In the case of sinusoidal functions of time, which
is true of Eq. 16-101, one may replace the pressure
amplitude by the root mean square value of the
pressure to obtain the simpler result
. This is possible for sinusoids
because the root mean square value of such functions
is the amplitude divided by the square root of two. I
hasten to add, however, that this is not true of time
functions in general.
In the case of spherical harmonic waves from a
simple source, the calculation is a little more
involved as the acoustic pressure and particle
velocity may well differ in phase. This is similar to
the electrical case in ac circuits where the sinusoidal
voltage and current are not necessarily in phase. The
phase difference between the voltage and the current
is compensated for by introducing the power factor
into the calculation of the average power. The power
factor in the electrical case is the cosine of the angle
of the electrical impedance where as in our case it is
the cosine of the angle that represents the phase
difference between acoustic pressure and particle
velocity, i.e., the angle of the specific acoustic
impedance. The formal statement of the average
intensity appears as
(16-102)
In the process of performing the integration in
Eq. 16-102 use is made of a trigonometric identity in
which 
where we identify 
 as A and θ as B. We
apply this identity to the second cosine function in the
integral. Next, we recognize that the sine terms in the
expansion will not make any contribution to the integral
over a complete period of the signal so the integral now
appears in the following form
(16-103)
The final result is identical to that of the plane wave
case so for both cases
(16-104)
All of the foregoing analysis with regard to a
simple spherical source has applications to sources of
other shapes as long as the largest nominal dimension
of the source, say a, is such that ka 〈〈1 and all
portions of the surface of the source displace in
phase.
I t( )
p t( )u t( )
=
<I t( )>
1
T--- p t( )u t( ) td
0
T
∫
=
<I t( )>
1
T---
pm
2
ρ0c
--------
2(
cos
ωt
kz)
–
td
0
T
∫
=
1
2--- pm
2
ρ0c
--------
=
<I t( )>
prms
2
ρ0c
⁄
=
<I t( )> =
1
T--- pm
ωt
kr
–
π
2---
+
⎝
⎠
⎛
⎞
cos
pm
ρ0c
(
)
θ
( )
cos
-------------------------------
(
cos ωt
kr
π
2---
θ
–
+
⎠
⎞
–
td
0
T
∫
A
B
–
(
)
cos
A
( )
cos
B
( )
cos
A
( )
sin
B
( )
sin
+
=
ωt
kr
π 2
⁄
+
–
<I t( )> =
1
T---
pm
2
ρ0c
(
)
θ
( )
cos
------------------------------
0
T
∫
2 ωt
kr
–
π
2---
+
⎝
⎠
⎛
⎞
cos
θ
( ) td
cos
<I t( )>
1
2--- pm
2
ρ0c
--------
=
prms
2
ρ0c
----------
=

What is Waving and Why
309
16.8 Boundaries
The simple spherical source in all of the preceding
analysis has been assumed to be completely isolated
from other sources as well as any environmental
boundaries. Next we need to consider what happens
when the simple source is placed very close to a
large rigid barrier such as indicated in the simple
profile sketch of Fig. 16-25.
We have learned that all air particle motion must
occur along radial lines directed away from the center
of the source. At the barrier itself however, there can
be no air particle motion perpendicular to the barrier
itself because of its rigidity while there is no restric-
tion on air particle motion tangential to the barrier
surface. In the language of mathematics, the normal
component of the air particle velocity must vanish at
the barrier. For all of the space to the right of the
barrier, doing two things can readily satisfy this
condition. First we replace the barrier by an imagi-
nary plane surface with the real source located to the
right of the plane by exactly the same distance as it
was from the actual barrier. Next we consider an
image source with identical properties to that of the
real source placed just as far to the left of the plane as
the real source is to the right. This new situation is
depicted in Fig. 16-26 where the distance between the
source and the plane has been exaggerated for clarity.
In the three dimensional space to the right of the
infinite plane defined by x = 0 the acoustic pressure
and particle velocity are exactly described by the
actual simple spherical source along with its image.
We illustrate this by making calculations at three
points. In the figure the z-axis is pointed towards the
reader. At the origin x, y, and of course z are each
equal to zero. The real source is located at (δ, 0, 0)
while the image source is located at (-δ, 0, 0). At the
origin the particle velocities of the real and image
sources are of the same magnitude, oppositely
directed, and both perpendicular to the plane. Their
vector sum is of course zero thus satisfying the
required boundary condition. Specifying a z value
other than zero will produce the same change in the
magnitudes of the particle velocities of the two
sources while adding an equal tangential component
to each. The normal components of each are still
equal and oppositely directed so that the boundary
condition remains satisfied. At the point (0, y, 0) the
radial lines drawn from each source intercept the
plane such that the x components of particle
velocity along the lines are oppositely directed thus
canceling at the plane while the y components are in
the same direction and thus add to that double what
a single source alone could produce. Finally at the
point (x, 0, 0) we may deal with the acoustic pres-
sure directly as there is no boundary condition to be
dealt with. The acoustic pressure amplitude at this
point produced by the actual source is
 while that produced by the
image source is 
. Now if 
 is
very small compared with x meaning that the actual
source is placed very close to the barrier then the
combination of these two pressure terms yields the
result 
 a value that is twice that
of a single source without a barrier. Finally, consider
a general point with coordinates (x, y, z). For the
actual source we would have a pressure amplitude
of 
 while for the
image source the amplitude would be
.
Again if the actual source is very close to the
barrier such that 
 is very small compared with x
then the combined pressure amplitude is double that
produced by the actual source without the presence
of a barrier. This result is termed half space radia-
tion from a single source as expressed by
Figure 16-25. A simple spherical source located very
close to an ideally infinite rigid barrier.
Figure 16-26. The method of real source and image as
applied to a single source with nearby infinite rigid barrier.
To Infinity
To Infinity
(0.0.0)
(0,y,0)
(x,0,0)
ρ0ωSum 4π x
δ
–
(
)
⁄
ρ0ωSum 4π x
δ
+
(
)
⁄
δ
pm
ρ0ωSum 2πx
⁄
=
ρ0ωSum 4π
⁄
x
δ
–
(
)2
y2
z2
+
+
ρ0ωSum 4π
⁄
x
δ
+
(
)2
y2
z2
+
+
δ

310
Chapter 16
(16-105)
where,
The method of images can be applied in any
circumstance when a barrier is present even when
no restriction is placed on the actual source’s loca-
tion. One simply defines separate radial distances
from the actual and image source and uses these
different values of radial distance in both the
amplitude calculation as well as the phase calcula-
tion. For example, suppose the actual source has
the coordinates (xa, 0, 0) where xa is any positive
value. The radial distance from the actual source
to any space point to the right of the barrier is then
while the radial distance
from the image source is 
.
The acoustic pressure at the general space point
(x, y, z) to the right of the barrier is then
(16-106)
A cone type loudspeaker mounted in a
back-enclosed box far from any boundaries will act
as a simple spherical source radiating into all of
space at low frequencies where the wavelengths are
large compared with the dimensions of the enclosure.
Similarly, such a loudspeaker placed on the floor in
the middle of a large room will act as a simple spher-
ical source radiating into a half space again only at
low frequencies.
16.9 Acoustic Dipole
An acoustic dipole consists of two simple spherical
sources separated by a small distance d and whose
properties are identical with the exception that their
surface velocities differ by pi radians or 180°. Such
an arrangement is depicted in Fig. 16-27.
Fig. 16-27 is a sketch of an acoustic dipole
located in the yz plane. The x- axis is towards the
reader. The radial lines converge on a general space
point. The radial distance from the origin is
represented by r, while the radial distance from the
expanding or positive source is r1, and that from the
contracting or negative source is r2. These distances
are all related in that:
and
.
The general expression for the acoustic pressure
produced by the dipole without any approximations
would have the form
(16-107)
Viewing what has been developed so far, some
general observations can be made without having to
solve any equations. When the observation point is
such that the angle theta is 90° then the observation
point is equidistant from both sources and the
acoustic pressure is zero. When the angle theta is less
than 90° the positive source is dominant as the obser-
vation point is always closer to the positive source
while for theta greater than 90° the negative source
becomes dominant with r2 being less than r1. If we
sacrifice total generality by placing some restrictions
on the size of the source separation, that is, the size
of d, we can make some useful simplifying approxi-
mations that lead to interesting conclusions with
regard to the behavior of the acoustic pressure ampli-
tude. When it is required that the separation between
the two sources, d, be much less than the radial
distance, r, as well as the wavelength, 
, then the
following approximations are quite accurate.
(16-108)
When the approximations expressed in Eq. 16-108
are substituted into the general Eq. 16-107 the
resulting equation can be simplified to show that the
combined acoustic pressure amplitude produced by
the dipole can be found from the relatively simple
expression
p r t,
(
)
ρ0ωSum
2πr
--------------------
ωt
kr
–
π
2---
+
⎝
⎠
⎛
⎞
cos
=
r
x2
y2
z2
+
+
=
ra
x
xa
–
(
)2
y2
z2
+
+
=
ri
x
xa
+
(
)2
y2
z2
+
+
=
p x y z t
, , ,
(
)
ρ0ωSum
4πra
--------------------
ωt
kra
–
π
2---
+
⎝
⎠
⎛
⎞
cos
ρ0ωSum
4πri
--------------------
ωt
kri
π
2---
+
–
⎝
⎠
⎛
⎞
cos
+
=
r1
r2
dr
θ
( )
cos
–
d 2
⁄
(
)2
+
=
Figure 16-27. The out of polarity simple sources are
located at z = d/2 and z = −d/2.
+
-
d
r1
r
r2
θ
r2
r2
dr
θ
( )
cos
d 2
⁄
(
)2
+
+
=
p
ρ0ωSum
4πr1
--------------------
ωt
kr1
–
π
2---
+
⎝
⎠
⎛
⎞
cos
ρ0ωSum
4πr2
--------------------
ωt
kr2
–
π
2---
+
⎝
⎠
⎛
⎞
cos
–
=
λ
r1
r 1
1
2---d
r---
θ
( )
cos
–
⎝
⎠
⎛
⎞
≈
r2
r 1
1
2---d
r---
θ
( )
cos
+
⎝
⎠
⎛
⎞
≈

What is Waving and Why
311
(16-109)
where,
c is the sound phase velocity,
um is the amplitude of the surface velocity of each
source,
 is the angular frequency,
r is the radial distance from the center of the dipole.
It should be apparent from Eq. 16-108 that the dipole
is a poor radiator particularly at low frequencies as
the pressure amplitude has a quadratic dependence
on the angular frequency. This amplitude expression
has been written so as to also exhibit the change in
polarity that occurs when theta exceeds 90°.
Fig. 16-28 displays a polar plot of the normalized
directivity of an acoustic dipole. The axis of the
dipole is along the horizontal axis.
An obvious example of an acoustic dipole is a
bare frame cone type loudspeaker where the separa-
tion distance, d, is the actual loudspeaker frame
diameter. When such a loudspeaker is mounted at the
center of a large flat baffle the source separation
distance then becomes the diameter of the baffle and
the loudspeaker radiates more efficiently at all
frequencies because of the enlarged value of d.
Bibliography
Lawrence E. Kinsler, Austin Frey, et. al. Fundamentals of Acoustics, 4th ed. New York: John Wiley and Sons,
2000.
Allan D. Pierce. Acoustics: An Introduction to Physical Principles and Applications, New York: Mc-Graw
Hill, 1981
pm
ρ0ω2Sum
4πcr
---------------------- d
θ
( )
cos
(
)
=
ω
Figure 16-28. Polar plot of the normalized directivity of
an acoustic dipole.
90
60
30
0
330
300
270
240
210
180
150
120
1
0.8
0.6
0.4
0.2


Chapter 17
Microphones
by Eugene Patronis, Jr.
313
17.1 The Microphone as the System Input  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 315
17.2 Microphone Sensitivity  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 315
17.3 Thermal Noise  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 317
17.4 Microphone Selection  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 324
Carbon . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 324
Capacitor  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 324
Moving Coil . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 324
Ribbon . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 325
Piezoelectric  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 325
Matching Talker to Microphone  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 325
17.5 Nature of Response and Directional Characteristics  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 325
17.6 Boundary Microphones  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 330
17.7 Wireless Microphones  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 335
17.8 Microphone Connectors, Cables, and Phantom Power  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 339
17.9 Measurement Microphones  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 341
Measurement Microphone Types  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 341
17.10 Microphone Calibrator . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 342
Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 344


   
Microphones
315
Microphones are the input components of an
extended voice reinforcement sound system. In
earlier chapters it has been established that there is a
relationship between the choice of type and location
of microphone, loudspeaker, talker, and listener that
affects achievable acoustic gain and intelligibility.
The next concern is what happens to the signal from
the acoustic input, into the microphone, through the
electrical gains and losses of the sound system
components, until sufficient electrical power reaches
the loudspeaker or loudspeaker array.
17.1 The Microphone as the System Input
There are many excellent texts on how the various
microphone types transduce acoustic pressure into
an electrical signal. Such texts also explore the
particular microphone structures necessary to
achieve particular polar response patterns.
Microphones can be divided into several
categories:
1. Measurement.
2. Entertainment.
3. Reinforcement.
4. Broadcast.
5. Recording.
Each category has its own special characteris-
tics. For example, an entertainment microphone may
feature the proximity effect to add body to a thin
voice and the presence effect to add sparkle. On the
other hand, measurement microphones feature a
wide-band uniform pressure response. It is a fact
that visual appearance, tactile qualities, and certain
accessory convenience features in addition to tech-
nical characteristics play major roles in the profes-
sional choice of a microphone. The following
parameters are of concern to sound system
engineers:
1. Sensitivity.
2. Polar response.
3. Amplitude response.
4. Impedance rating.
5. Polarity.
6. Phase response.
7. Maximum acoustical input level.
8. Distortion properties.
9. Special features such as noise cancellation, wire-
less, and internal filters.
Knowledge of certain technical parameters is
required in order to integrate a commercial micro-
phone into a workable sound system. When reliable
technical data is not at hand it becomes necessary to
make field measurements to gain the information
required.
17.2 Microphone Sensitivity
In order to determine the electrical input level to a
sound system we need to measure the electrical
output generated by the system microphone when it
is subjected to a known sound pressure (SP). In
making such measurements an LP of 94 dB (1 Pa) is
recommended as this value is well above the
normally encountered ambient noise levels.
Everyone seriously interested in the field of
professional sound should own or have easy access to
a precision sound level meter (SLM). Among other
uses, a SLM is required to measure ambient noise, to
calibrate sources, and on occasion to serve as input
for frequency response, reverberation time, signal
delay, distortion, and acoustic gain measurements.
Setting up the microphone measurement system
shown in Fig. 17-1 requires a pink noise generator, a
micro-voltmeter, a high-pass and low-pass filter set
such as the one illustrated in Fig. 17-2, a power
amplifier, and a well-constructed test loudspeaker in
addition to the SLM.
Select a measuring point (about 5 ft to 6 ft) in
front of the loudspeaker, and place the SLM there.
Adjust the system until the SLM reads an LP of
94dB (a band of pink noise from 250–5000Hz is
excellent for this purpose). Now substitute the
microphone to be tested for the SLM. Take the
microphone open circuit voltage reading on the
micro-voltmeter. The voltage sensitivity of the
microphone can then be defined as
(17-1)
where,
SV is the voltage sensitivity expressed in decibels
referenced to 1 volt for a 1 Pa acoustic input to the
microphone,
Figure 17-1. Measuring microphone sensitivity.
Pink
noise
Filter
set
Power
amplifier
Sound
level
meter
Microvolt
meter
94 dB-SPL
Test
loudspeaker
SV
20 dB
Eo
(
)
log
=

316
Chapter 17
Eo is the open circuit output of the microphone in
volts.
The open circuit voltage output of the micro-
phone when exposed to some other arbitrary acous-
tic level LP is calculated from
(17-2)
where,
Eo is now the open circuit voltage output of the micro-
phone for an arbitrary acoustic input of level LP..
For example suppose a sample microphone is
tested by the conditions of Fig. 17-1 with the result
that the open circuit voltage is found to be 0.001V.
The voltage sensitivity of this microphone as calcu-
lated from Eq. 17-1 is then
This result would be read as −60 dB referenced to
0dB being 1 volt per pascal (1V/Pa). If this same
microphone were exposed to an acoustic input level
of 100 dB rather than the test value of 94 dB, then its
open circuit output voltage from Eq. 17-2 would
become
Many current microphone preamplifiers have
input impedances that are at least an order of magni-
tude or larger than the output impedances of
commonly encountered microphones. In such
instances, Eq. 17-2 can be employed to determine the
maximum voltage that a given microphone and
sound field will supply to the preamplifier input. The
voltage sensitivity of Eq. 17-1 is the one currently
employed by most microphone manufacturers.
Another useful sensitivity rating for a micro-
phone is that of power sensitivity. In this instance
the focus is placed upon the maximum power that
the microphone can deliver to a successive device
such as a microphone preamplifier when the micro-
phone is exposed to a reference sound field. In this
instance the reference power is one milliwatt or
0dBm and the reference sound field pressure is one
pascal or 94 dB. This rating is more complicated as
it involves the microphone output impedance. All
microphones regardless of whether the construction
is moving coil, capacitor, ribbon, etc. have intrinsic
output impedance that in general is complex and
frequency dependent. Strictly speaking, in order for
such a device to deliver maximum power, it must
work into a load that is matched on a conjugate basis
with the reactance of the load being the negative of
the reactance of the source and the resistance of the
load being equal to the resistance of the source (see
Chapter 8 Interfacing Electrical and Acoustic
Systems, Section 8.1, Alternating Current Circuits).
Suppose then that the real part of the micro-
phone’s output impedance is Ro. This being the case,
the available input power in watts that the micro-
phone can deliver to the input of a successive
device, AIP, is given by
(17-3)
If AIP is referenced to one milliwatt and the
microphone is exposed to a sound field of one
pascal then,
(17-4)
Figure 17-2. Response characteristics of a passive filter
set. (Courtesy United Recording Electronics Industries.)
0
-10
-20
-30
-40
-50
Loss–dB
20       50    100  200     500    1k    2k        5k   10k 
Frequency–Hz
0
-10
-20
-30
-40
-50
Loss–dB
20       50    100  200     500    1k    2k       5k    10k 
Frequency–Hz
70 Hz
100 Hz
150 Hz
250 Hz
500 Hz
2000 Hz
3000 Hz
5000 Hz
7500 Hz
1000 Hz
250 Hz
10 kHz
5 kHz
6 kHz
4 kHz
3 kHz
2 kHz
1 kHz
500 Hz
8 kHz
600
600
600
600
A. Low pass section
B. High pass section
Eo
10
SV
LP
94
–
+
20
-------------------------------
⎝
⎠
⎛
⎞
=
SV
20 dB
0.001
(
)
log
=
60
–
 dB
=
Eo
10
60
–
100
94
–
+
20
-------------------------------------
⎝
⎠
⎛
⎞
=
0.002 V
=
AIP
1
4---
⎝⎠
⎛⎞Eo
2
(
)
1
Ro 
-------
⎝
⎠
⎛
⎞
=
AIP
0.001
-------------
1
4---
⎝⎠
⎛⎞103
(
) 10
SV
10
------
⎝
⎠
⎜
⎟
⎛
⎞
1
Ro
------
⎝
⎠
⎛
⎞
=

   
Microphones
317
This can be converted to a power level by taking
the logarithm to the base ten of Eq. 17-4 and then
multiplying by 10 dBm to yield
(17-5)
LAIP expresses the power sensitivity of a micro-
phone in terms of dBm/Pa. If our example micro-
phone has an Ro of 200 Ω along with its voltage
sensitivity of −60 then its power sensitivity would be
−6 + 30 − 60 − 23 = −59 dBm/Pa
Another useful way to express the power sensi-
tivity of a microphone would be to reference the
available input power to a sound field of 0.00002Pa.
This would produce a result 94 dBm lower than that
of Eq. 17-5. If we symbolize this rating by GAIP
then,
(17-6)
In this rating system the example microphone
would produce −153 dBm at the threshold of hear-
ing. The advantage of this system is that the power
level supplied by a given talker’s microphone is
obtained by simply adding GAIP to the pressure level
of the talker’s voice at the microphone’s position.
GAIP as defined here is very similar to the EIA rating
for microphones. The EIA rating system differs in
that rather than employing the actual output resis-
tance of the microphone, a nominal microphone
impedance rating is employed instead.
17.3 Thermal Noise
In 1927, while investigating the noise properties of
vacuum tube amplifiers, J. B. Johnson of Bell Tele-
phone Laboratories discovered that the input resis-
tance of the subject amplifiers was the source of a
noise signal. This resistor noise was found to be
separate and apart from other known noise sources
associated with vacuum electron tubes. This resistor
noise was found to be related to the temperature of
the resistor itself and thus was termed thermal noise
even though it is also often called Johnson noise in
honor of the discoverer. Johnson communicated his
experimental data to Harry Nyquist who was a physi-
cist also employed by Bell Labs. Nyquist was able to
derive from theory the exact quantitative description
of the thermal noise of the resistor and hence this
noise source is sometimes also called Nyquist noise.
Later Onsager showed that the thermal noise of a
resistor results from a much larger theorem known
as the fluctuation-dissipation theorem that is appli-
cable to a larger class of physical systems. In this
theorem it is found that the noise signals are proper-
ties of only the dissipative elements of a system and
not of the energy storage elements. As a conse-
quence, thermal noise in an electrical system is asso-
ciated only with the real part of the circuit
impedance and not with the imaginary or reactive
component. Any passive electrical network consist-
ing of resistors, inductors, and capacitors thus
contains voltage sources of a thermal origin associ-
ated with each of the resistive elements. Further-
more, any passive electroacoustical or
electromechanical system at a uniform absolute
temperature T can be described by substituting for
these systems the corresponding electrical equiva-
lent circuits also at the same absolute temperature.
The fluctuating thermal voltage in a resistor is
brought about by thermally induced variations in
conduction electron distribution throughout the
body of the resistance. An instantaneous
non-uniform charge distribution produces an instan-
taneous voltage difference between the ends of the
resistor. Although this voltage difference has an
average value of zero, it instantaneously displays a
random polarity and size resulting in a non-vanish-
ing root mean square value.
From the Nyquist theorem, each resistor can be
represented as a voltage generator in series with the
resistance as depicted in Fig. 17-3A where the root
mean square voltage of the generator for ordinary
temperatures and frequencies is given by
(17-7)
where,
k is Boltzmann’s constant = 1.38 × 10−23 J/°K,
T is the absolute temperature on the Kelvin scale,
R is the resistance in Ω ,
B is the observation bandwidth in Hz.
Fig. 17-3A depicts a thermal noise source whose
open circuit voltage between the indicated terminals
is given by Eq. 17-7. The spectrum of the noise
signal generated by such a source for all practical
purposes is independent of frequency meaning that
it is a white noise source. Quantum mechanics
dictates a frequency dependence of the form
where,
h is Planck’s constant = 6.62 × 10 –34 J-s,
T is the absolute temperature,
k is Boltzmann’s constant = 1.38 × 10 −23 J/°K,
LAIP
6
–
30
SV
10
Ro
log
–
+
+
(
)  dBm
=
GAIP
SV
10
Ro
70
–
log
–
(
) dBm
=
V
4kTRB
=
hf
kT
------
e
hf
kT
------
1
–
----------------

318
Chapter 17
f is the frequency in Hz.
This expression begins to differ from unity only
at frequencies in the microwave region and beyond
and hence can be neglected for the present purposes.
Although thermal noise of a resistor is flat, the
frequency dependence is modified by connection to
either a capacitor or inductor. In Fig. 17-3B the root
mean square noise voltage between the indicated
terminals is conditioned by the fact that the RC
combination forms a low pass filter. The mean value
of the square of the noise voltage generated in the
resistor between the frequencies f and f + df can be
written as
(17-8)
The resistor and capacitor form a voltage divider.
The mean square voltage across the capacitor in the
frequency interval between f and f + df is obtained by
multiplying Eq. 17-8 by the square of the magnitude
of the frequency dependent action of this voltage
divider. The result of this multiplication is found to be
(17-9)
In order to obtain the mean square voltage across
the capacitor in a finite frequency interval between
the lower frequency f1 and an upper frequency f2 it is
necessary to integrate Eq. 17-9 over the frequency
interval with the result
(17-10)
The root mean square voltage across the capaci-
tor will just be the square root of the expression on
the right in Eq. 17-10. This is a general result. When
RCf2 is small the arc tangent terms may be replaced
by their arguments with the result that
(17-11)
On the other hand if RCf2 is quite large with
 then the difference in the arc tangent terms is
π/2 and the limiting result becomes
(17-12)
A more interesting and practical case is that of
Fig. 17-3C. Through the application of the principle
of superposition, it is possible to determine the
circuit current when each source acts alone.
(17-13)
We are now in position to determine the noise
power delivered by each source to the other. Let P12
be the noise power delivered by source 1 to source 2
and similarly let P21 be the noise power delivered by
source 2 to source 1. Then,
Figure 17-3. Nyquist voltage sources.
A.
B.
C.
R
R
C
V
V
V1
V2
R1
R2
V2
〈
〉
4kTRdf
=
VC
2
〈
〉
4kTRdf
4π2f 2R2C2
1
+
-------------------------------------
=
VC
2
〈
〉
2kT
πC
---------
2πRCf2
(
)
atan
2πRCf1
(
)
atan
–
[
]
=
VC
2
〈
〉
4kTR f2
f1
–
(
)
=
4kTRB
=
f2
f1
»
VC
2
〈
〉
kT
C
------
=
I1
V1
R1
R2
+
------------------
=
4kT1R1B
R1
R2
+
--------------------------
=
I2
V2
R1
R2
+
------------------
=
4kT2R2B
R1
R2
+
--------------------------
=

   
Microphones
319
(17-14)
It should be observed from Eqs. 17-14 that both
lines are the same with the exception of the tempera-
ture factor. The source having the lower temperature
receives a net power from the higher temperature
source regardless of the individual source resistance.
Only when temperature equilibrium exists with
T1 = T2 = T will P12 = P21. Another point of interest
is the noise voltage that appears between the indi-
cated terminals of Fig. 17-3C.
This can also be calculated by superposition. One
first calculates the voltage existing there when
source 1 acts alolne and then when source 2 acts
alone. The voltage when both sources act simultane-
ously is obtained by the appropriate combination of
these two individual voltages. The appropriate
combination in this case is the quadratic sum rather
than the linear sum as the two generators have
completely random phases. The quadratic sum is
obtained by taking the square root of the sum of the
squares of the individual voltages when acting
alone. Let this sum be denoted by V ′, then
(17-15)
If both resistors are at the same temperature, i.e.,
T1 = T2 = T the expression simplifies to
(17-16)
Clearly, Eq. 17-16 is equivalent to the open
circuit voltage of a single resistor whose value is the
parallel combination of the two resistors R1 and R2.
Suppose now that there is a large disparity between
the sizes of the two resistors, for instance
R2 = 100R1. In this instance upon dividing R2 into
both the numerator and the denominator underneath
the radical Eq. 17-16 becomes
(17-17)
The conclusion for such a situation is that the
root mean square noise voltage is essentially that of
the significantly smaller resistor in the parallel
combination. This is the situation often encountered
with present day microphone amplifiers with R1
corresponding to the microphone’s output resis-
tance and R2 corresponding to the amplifier’s input
resistance.
Now let the two resistors be equal and each of
size Ro. This would be the situation if a microphone
were feeding into an amplifier under matched condi-
tions. In this instance
(17-18)
Eq. 17-18 tells us that the total thermal noise volt-
age appearing across the amplifier input would be
3dB less than if the microphone were operating into
an open circuit or into a load whose resistance was
very much larger than Ro. At the same time, however,
the performer’s electrical signal generated by the
microphone will be reduced by 6 dB. This would
indicate that the signal to noise ratio at the system
input is worsened by operating into a matched load.
This fact should not be considered in isolation
however. The important consideration is the signal to
noise ratio available from a system consisting of both
a microphone and its associated amplifier.
Amplifiers contain several noise sources of their
own. In addition to thermal noise associated with
circuit resistances there are several noise sources asso-
ciated with the active amplifying devices themselves.
Such noise sources are shot noise, flicker noise, parti-
tion noise, and recombination noise. Aside from shot
noise whose origin is quantization of electric charge
and has a flat spectrum at audio frequencies, the other
noise sources do not in general have flat spectra. Even
though an amplifier can have several cascaded stages
of amplification, in a well-designed system the overall
noise behavior is dominated by the first high gain
stage of amplification.
A figure of merit with regard to noise behavior of
amplifiers can be obtained by considering the
degrading effect that the amplifier has upon the
signal to noise ratio of the signal source. Fig. 17-4A
depicts a signal source consisting of a signal genera-
tor of mean square voltage VS2 and a source
P12
I1
2R2
=
4kT1R1BR2
R1
R2
+
(
)2
-----------------------------
=
P21
I2
2R1
=
4kT2R2BR1
R1
R2
+
(
)2
-----------------------------
=
V′
4kBR1R2 T1R2
T2R1
+
(
)
R1
R2
+
(
)2
-----------------------------------------------------------
=
V′
4kBTR1R2
R1
R2
+
(
)
--------------------------
=
V′
4kTBR1
R1
100R1
---------------
1
+
⎝
⎠
⎛
⎞
------------------------------
=
4kTBR1
≈
V′
1
2
------- 4kTBRo
=

320
Chapter 17
resistance RS. Along with the source resistance is a
thermal noise generator having a mean square volt-
age in a narrow frequency interval of amount Vn2.
The ratio of the mean square voltages of the
signal and the thermal noise is the best obtainable as
allowed by nature and will be called the source
signal to noise ratio denoted as SNRs.The situation
changes when the source is attached to the ampli-
fier’s input resistance as depicted in Fig. 17-4B. Rin
affects the operation of the signal source by intro-
ducing signal attenuation and contributing thermal
noise of its own as discussed previously. Addition-
ally, the presence of RS affects the operation of the
amplifier as it provides a parallel path for amplifier
generated input circuit noise currents. This means
that the amplifier’s noise performance will be sensi-
tive to source resistance.
What matters of course is the signal to noise ratio
at the amplifier’s output. This ratio can be written as
(17-19)
where,
 
is the amplifier mean square signal output in a
narrow band centered on the signal frequency,
is the amplifier mean square noise output in a
narrow band centered on the signal frequency.
Finally, the figure of merit of noise performance
can be written as
(17-20)
Most audio amplifiers in current use have input
resistances that are considerably larger than the
usual source resistances. This being the case,
(17-21)
In Eq. 17-21 the term A2 is the square of the volt-
age amplification of the amplifier and VnA2 is the
mean square noise voltage at the amplifier output
contributed by the amplifier alone when operating
from a noiseless source resistance equal to RS. The
expression noiseless source resistance requires some
explanation.
Recall from the discussion leading to Eq. 17-17
that the thermal noise at the amplifier output in this
case is fully accounted for by the first term in the
denominator of the amplifier’s signal to noise ratio
expression. Additionally, the size of the second term
hinges in part on the size of the source resistance
independent of the resistor’s thermal noise. It is
convenient to refer the amplifier’s output noise
contribution to its input circuit by picking a suitably
sized mean square noise voltage, Vnin2, such that
(17-22)
Finally, we will pick a resistor whose thermal
noise mean square voltage is equivalent to that of
the amplifier when referred to the amplifier’s input.
(17-23)
The noise figure of merit now becomes
(17-24)
A word of caution is called for here. Unlike ther-
mal noise that has a flat spectrum, amplifier associ-
ated noise is dependent on frequency so Re is itself
frequency dependent.
Remember also that the size of Re is different for
different choices for the source resistance. The noise
figure of an amplifier is denoted by NF and is
related to the figure of merit discussed here.
Figure 17-4. Signal source and associated thermal
noise.
RS
VS
RS
VS
Rin
Vn
Vn
A.
B.
SNRA
VoS
2
Von
2
-----------
=
VoS
2
Von
2
F
SNRS
SNRA
--------------
=
SNRS
VS
2
4kTRSΔf
----------------------
=
SNRA
A2VS
2
4kTRSΔf
VnA
2
+
----------------------------------------
=
VnA
2
A2Vnin
2
=
4kTReΔf
Vnin
2
=
F
A24kTRsΔf
A24kTReΔf
+
A24kTRSΔf
---------------------------------------------------------------
=
RS
Re
+
RS
------------------
=

   
Microphones
321
(17-25)
In the foregoing discussion we considered a
narrow band of frequency centered about the
frequency of the signal source. The noise figure as
well as the equivalent noise resistor so derived is
that for the operating frequency of the signal source.
Notice, however, that the expression for the noise
figure does not contain any factor involving the size
of the genuine signal.
In the experimental determination of noise figure
one simply requires that a resistance equal to the
intended source resistance be connected directly to
the amplifier input. This resistor brings along its
associated thermal noise as required. This resistor’s
temperature must be maintained fixed at whatever
absolute temperature is required. The total noise
signal at the output of the amplifier must pass
through a narrow bandpass filter centered on the
particular frequency of interest before being
observed on a true rms voltmeter of sufficient
sensitivity. The voltage gain of the amplifier must be
accurately known or measured and the noise contri-
bution of the source resistor can be calculated.
Special measurement techniques may be required
because Δf is quite small and the amplifier noise
observed in a narrow frequency interval is conse-
quently also small. If one is interested in the average
noise figure over the entire audio band, then one
employs a maximally flat bandpass filter of appro-
priate width. Regardless of whether the observation
bandwidth is small, Δf, or broad, B, the appropriate
width is not the frequency interval between the half
power points as conventionally defined for the
following reason.
The thermal noise spectrum is flat and the
frequency interval employed in those equations is for
an ideal filter. Depending on the steepness of the
slopes of a conventional filter significant noise power
may be passed for frequencies outside of the conven-
tional pass band. The width of such filters must be
decreased until they pass the same power as would
be passed by an ideal filter in the frequency interval
of interest when supplied with a flat spectrum.
The noise properties of amplifiers may be
reported in a related but different fashion from that
of NF. This is done by reporting the amplifier’s
equivalent input noise expressed as a power level
relative to one milliwatt. This expression is called
the EIN. The EIN in dBm is calculated from
(17-26)
EIN in effect is the available input power level of
a fictitious noise generator having an open circuit
voltage equal to the quadratic sum of that produced
by the source resistance and the equivalent noise
resistance of the amplifier. The internal resistance of
this fictitious noise generator is set equal to the
source resistance. If you subtract the noise figure of
the amplifier expressed in dB from EIN you arrive at
the thermal noise available input power level of the
source resistance alone.
If interest is centered on a system’s noise floor,
then EIN is the answer without further calculation. If
interest is directed toward degradation of signal to
noise ratio (SNR), the important quantity to know is
NF. The signal to noise ratio expressed in decibels at
the amplifier output is less than that of the signal to
noise ratio of the signal source by an amount equal
to NF. Upon employing the notation of Eq. 17-21
(17-27)
At this point it is worthwhile to examine some
sample calculations. One must start with both the
microphone specifications and the amplifier specifi-
cations appropriate to the source impedance
presented by the microphone as well as the pressure
level of the talker.
The object is to determine the signal to noise
ratio at the amplifier output expressed in dB. The
calculation will be carried out by employing two
different techniques. First it should be observed that
the output resistance of the microphone serves as the
source resistance for the amplifier and that the
amplifier data is appropriate for use with this
microphone.
First, employ Eq. 17-2 to determine the talker’s
root mean square signal voltage produced by the
microphone.
Next employ Eq. 17-7 to determine the root
mean square thermal noise voltage produced by the
microphone’s output resistance.
NF
10 dB
F
( )
log
=
EIN
NF
10
kTB
(
)
log
30
+
+
=
Talker
Microphone
Amplifier
LP = 80 dB
SV = −60 dB
RS = 200 Ω
GAIP = −153 dBm
NF = 5 dB
Ro = 200 Ω
B = 20,000 − 20 = 19,980 Hz
10 dB
SNRA
(
)
log
10 dB
SNRS
(
)
NF
–
log
=
Eo
10
60
–
80
94
–
+
20
----------------------------------
⎝
⎠
⎛
⎞
=
10
74
–
20
---------
⎝
⎠
⎛
⎞
=
199.5 μV
=

322
Chapter 17
In the above step the ambient temperature was
taken as 20°C which corresponds to 293° on the
absolute or Kelvin temperature scale. The SNR of
the signal source expressed in decibels is then
Finally, the signal to noise ratio at the amplifier
output expressed in dB from Eq. 17-27 is
Before we begin the alternative calculation it
should be pointed out that when Eq. 17-4 is applied
to a thermal noise source and then referenced to one
milliwatt the result expressed as an available noise
power level is given by
(17-28)
The noise available input power level of the
microphone is then
The microphone produces a signal available
input power level that is the sum of GAIP and LP .
This results in a signal whose available input power
level is
The source signal to noise ratio in decibels is just
the difference between these two levels or
The signal to noise ratio at the amplifier output
expressed in dB is then
(17-29)
This mediocre result is a consequence of an
insensitive microphone combined with a noisy
amplifier.
The noise figure of an amplifier based on bipolar
junction transistors is strongly dependent on the
resistance of the signal source. Such amplifiers
perform at their best with source resistances falling
in the range of 5 kΩ to 20 kΩ . Any given amplifier
has an optimum source resistance for which its noise
figure is the least. It appears then that optimum
noise performance will be obtained with low imped-
ance microphones when their output resistance can
be made to appear to be the optimum source resis-
tance required by the amplifier at hand.
Noise figures as low as 1 dB are obtainable in
this fashion. In such cases it is reasonable to employ
a quality step up transformer of the appropriate turns
ratio at the amplifier input. A step up transformer
with a turns ratio of 1:n will transform Ro by a factor
of n2. The signal voltage from the microphone as
well as the thermal noise voltage of the microphone
are increased by the same factor n. The signal to
noise ratio of the microphone is thus unchanged
provided that the amplifier’s input resistance as
viewed from the microphone is still large compared
with Ro.
The foregoing analysis is somewhat simplified in
that no consideration was given to the possible exis-
tence of reactances being associated with the micro-
phone’s output impedance. This is reasonably
accurate with regard to capacitor microphones that
incorporate low noise field effect transistor source
followers internal to the microphone housing. This
internal circuitry operates from either local battery
or externally applied phantom power. These source
followers offer output impedances of the order of
50Ω that is purely real and hence resistive. The
microphone cable does introduce shunt capacitance
and this capacitance in conjunction with Ro forms a
first order low pass filter. For reasonable cable
lengths, the corner frequency of this filter is well
beyond the audio spectrum and does not impact
signal to noise calculations.
Further treatment is required when dynamic
microphones are involved. Consider a typical
dynamic microphone. The capsule of the micro-
phone is similar to a miniature loudspeaker. The
capsule has a diaphragm and an attached coil that
moves in the air gap of a magnetic structure. The
diaphragm’s motion is driven by acoustic pressure
variations impinging on its surface. The coil typi-
cally has a resistance of only a few ohms and an
inductance that is a small fraction of a millihenry. A
small step up transformer is included in the micro-
phone housing that transforms the resistance to a
few hundred ohms and the inductance to a few
V
4
( ) 1.38
(
) 10 23
–
(
) 293
(
) 200
(
) 19,980
(
)
=
0.25 μV
=
20 dB
Eo
V
------
⎝
⎠
⎛
⎞
log
20 dB
199.5
10 6
–
×
0.254
10 6
–
×
------------------------------
⎝
⎠
⎜
⎟
⎛
⎞
log
=
57.9  dB
=
10 dB SNRA
(
)
57.9 dB
5  dB
–
=
52.9 dB
=
LAIPNoise
10
kTB
(
)
30
+
log
[
] dBm
=
10
1.38
(
) 10 23
–
(
) 293
(
) 19,980
(
)
[
]
30
+
log
130.9 dBm
–
=
153
–
80
+
73  dBm
–
=
73
–
130.9
–
(
)
–
57.9  dB
=
57.9 dB  NF
–
57.9  dB
5  dB
–
=
52.9  dB
=

   
Microphones
323
millihenries. The capsule has a low frequency
mechanical resonance that influences the imped-
ance behavior of the overall assembly. With the
exception of scale, the output impedance magnitude
has a dependence on frequency similar to a dynamic
loudspeaker as depicted in Fig. 18-22 of Chapter 18
Loudspeakers and Loudspeaker Arrays.
The manufacturer’s rated impedance is usually
the magnitude found at the minimum of the curve
located above the mechanical resonance frequency.
For frequencies well above the mechanical reso-
nance, the microphone’s output impedance is that of
a series resistance Ro and a series inductance Lo
shunted by the capacitance Cc of any attached
microphone cable. This structure is depicted in
Fig. 17-5A. This structure as viewed from the
vantage point of the microphone amplifier is
displayed in Fig. 17-5B.
As depicted in Fig. 17-5A the internal impedance
of the dynamic microphone along with the shunt
capacitance of the cable connecting the microphone
to the amplifier form a second order low pass filter
that is terminated by the amplifier’s input resistance.
The open circuit voltage of the microphone is repre-
sented by the voltage generator of size Vo. Typical
values for the circuit components are Ro = 200 Ω ,
Lo = 2 mH, Cc = 2 nF, and Rin = 1 MΩ . The ampli-
tude behavior of this circuit is best described by
plotting the attenuation versus frequency where the
attenuation is 
 and Vin is the volt-
age appearing across the amplifier input resistance.
This result appears as Fig. 17-6.
The filter’s behavior is innocuous up to about
2kHz. Above 2 kHz the filter begins to exhibit a
gain rather than a loss. This is the result of an under
damped resonance that occurs at a frequency far
above the normal audio band. The filter gain at
20kHz is less than 0.6 dB and is actually slightly
beneficial in compensating for the natural high
frequency fall off of the microphone’s natural
response. The microphone’s talker signal as well as
its thermal noise signal experiences this same gain
and signal to noise behavior is not affected. The
other consideration with regards to noise behavior is
that of the source impedance as viewed from the
standpoint of the amplifier. This impedance is
depicted in Fig. 17-5B. The magnitude of this
source impedance is plotted in Fig. 17-7.
The source impedance is resistive at a constant
value of 200 Ω until about 2 kHz. Above that point up
to 20 kHz the source impedance has a frequency
dependent reactive component in addition to the
resistance of 200 Ω. This behavior will have a modest
effect on the signal to noise ratio in the frequency
decade from 2 kHz to 20 kHz. This modest effect may
well be an improvement as most amplifiers prefer
source impedances greater than 200 Ω . In summary,
neglecting the reactive component of the micro-
phone’s output impedance apparently leads to only
minor errors in signal to noise ratio calculations.
Figure 17-5. Dynamic microphone equivalent circuit
and amplifier source impedance.
Lo
Cc
Rin
Ro
Lo
Ro
Cc
A.
B.
20dB
Vin Vo
⁄
(
)
log
Figure 17-6. Filter amplitude behavior.
Figure 17-7. Source impedance viewed by amplifier.
101                102                103                104
Frequency–Hz
100
Filter Transmission
Attenuation–dB
1.0
0.8
0.6
0.4
0.2
0
−0.2
−0.4
−0.6
−0.8
−1.0
101                102                103                104
Frequency–Hz
100
Source Impedance
350
300
250
200
150
100
50
0
Magnitude–ohms

324
Chapter 17
17.4 Microphone Selection
Microphones are usually selected on the basis of
mechanism, sensitivity, nature of response, polar
response pattern, and handling characteristics.
Mechanism refers to the physical nature of the trans-
ducing element of the microphone. Sensitivity in
current practice refers to the voltage sensitivity SV .
Nature of response refers to whether the microphone
output is proportional to acoustic pressure, acoustic
pressure gradient, or acoustic particle velocity. Polar
response patterns summarize a microphone’s direc-
tional characteristics. Handling characteristics are a
result of whether or not the structure of the micro-
phone housing is mechanically isolated from the
transducing structure of the microphone. Below is a
listing of popular microphones according to the
transducing mechanism.
1. Carbon.
2. Capacitor.
3. Moving coil.
4. Ribbon.
5. Piezoelectric.
Carbon
Carbon microphones made their advent as transmit-
ters in early telephones. Pressure variations on a
metallic diaphragm actuated a metallic button
contact to either increase or decrease the compaction
of carbon granules contained in a brass cup so as to
decrease or increase the resistance of the assembly.
The impinging sound thus modulated the direct
current in a circuit containing a battery and the
microphone element. Carbon microphones are quite
sensitive and inexpensive to construct. In addition to
the normal thermal noise, such microphones suffer
from fluctuations in contact resistance between
carbon granules even in the absence of acoustic
excitation. The high noise floor and restricted
frequency response limit the application of such
microphones in sound reinforcement systems.
Capacitor
Capacitor microphones exist in two basic forms. In
one form a capacitor has a front plate formed by a
flexible low-mass, metallic, or metal film diaphragm
separated by an air gap from an insulated, rigid
metallic perforated back plate. Air motion through
the perforations in the back plate serves to damp the
mechanical resonance of the diaphragm. This reso-
nance occurs at a high frequency as a result of a
stiff, low mass diaphragm. The diaphragm is oper-
ated at ground potential while the back plate is
charged through a very high resistance by a dc volt-
age source ranging up to 200 V.
In a second form, a permanently polarized
dielectric or electret is positioned on the surface of
the back plate removing the necessity for an external
polarizing voltage source. In both instances the
capacitor circuit is completed through a resistance of
the order of 109 Ω and the charge on the capacitor
remains approximately constant. Pressure variations
on the flexible diaphragm produce changes in the air
gap dimension thus raising or lowering the capaci-
tance by a small amount depending upon the degree
of diaphragm displacement. With a constant charge
on the variable capacitor, the voltage variations
track the diaphragm displacement variations.
The capacitor circuitry itself is of high imped-
ance and requires that a field effect transistor (FET)
source follower be contained within the microphone
housing. The source follower may be energized by a
local battery in the case of the electret form or may
derive its power from the polarizing voltage source
in the pure air capacitor form. These microphones,
though not the most rugged, can be of extremely
high quality with regard to frequency response. As
will be discussed later, the construction details of
the microphone capsule may be varied to make the
microphone capsule sensitive to either acoustic pres-
sure or acoustic pressure gradient.
Moving Coil
The moving coil microphone and the ribbon micro-
phone are collectively referred to as being dynamic
microphones. Much discussion has been given
previously with regard to some of the features of the
moving coil microphone. The mechanical reso-
nance of the moving coil structure is usually made
to occur at the geometric mean of the low frequency
and high frequency limits describing the micro-
phone’s pass band. In a typical case this resonance
occurs at about 630 Hz. In the pressure responsive
version of such a microphone the back chamber to
the rear of the diaphragm contains an acoustic resis-
tance that highly damps the diaphragm mechanical
resonance. This damping greatly broadens the reso-
nance forcing the response to be uniform except at
the frequency extremes.
Oftentimes a small resonant tube tuned to a low
frequency and vented to the outside is incorporated
in the rear cavity. In addition to extending the
response at low frequencies, this tube allows the
static air pressure in the rear chamber to track slow
changes in atmospheric pressure. Even in

   
Microphones
325
microphone structures featuring an otherwise sealed
rear cavity a slow leak must always be provided for
static pressure equalization. A small air chamber
that is resonant at a high frequency may also be
located in the rear cavity in order to enhance
response at high frequencies. Moving coil micro-
phone structures are usually quite rugged.
Ribbon
The ribbon microphone employs a conductor in a
magnetic field as does a moving coil microphone.
Unlike the moving coil, which is located in a radi-
ally directed magnetic field, the conductor in a
ribbon microphone is a narrow, corrugated metal
ribbon located in a linearly directed magnetic field
that is perpendicular to the length of the ribbon. The
ribbon itself constitutes the diaphragm, both faces of
which are exposed to external sound fields.
The driving force on the ribbon is directly
proportional to the pressure difference acting on the
two faces of the ribbon and hence is proportional to
the space rate of change of acoustic pressure. The
space rate of change of pressure is called the pres-
sure gradient. The ribbon responds to the acoustic
particle velocity with maximum response occurring
when the incident sound is normal to a face of the
ribbon. This microphone is inherently directional
with a figure eight polar pattern. Though featuring
excellent performance over a wide frequency range,
the structure is inherently fragile and is not suitable
for exterior use under windy conditions.
Piezoelectric
Piezoelectric microphones depend on a structural
property possessed by certain dielectric crystals and
especially prepared ceramics. The nature of this
property is that if the crystal or ceramic is subjected
to a mechanical stress, its shape will be distorted.
When this occurs, an electric field appears in the
substance as a result of shifted ion positions within
the structure. A capacitor can be formed employing
such a dielectric that will generate a voltage that is
proportional to the mechanical stress. The mechani-
cal stress can be made to result from the motion of a
diaphragm exposed to acoustic pressure. In this
fashion it is possible to construct a relatively simple,
inexpensive pressure sensitive microphone. Piezo-
electric microphones have very high capacitive
output impedances. In the past the high voltage
sensitivity of such microphones made them popular
for recorders and simple public address applications
where quite short connecting cables were possible.
They are still employed in some sound level meters
but other professional application is quite restricted.
Matching Talker to Microphone
Distant or bashful talkers require microphones of
higher voltage sensitivity in order to produce volt-
age levels matching those required by microphone
input amplifiers. Nearby and professional talkers
require microphones of less sensitivity in order to
match amplifier input requirements without the use
of pads in the input circuitry. Rock singers are an
extreme case requiring the least input sensitivity and
further requiring both breath blast and pop filters
particularly when pressure gradient microphones are
employed. Table 17-1 lists representative voltage
sensitivity ranges typical of microphones classified
according to mechanism.
17.5 Nature of Response and Directional 
Characteristics
Pressure microphones are those where only one side
of the diaphragm is exposed to the actuating sound
field. Such devices are basically insensitive to the
direction of the arriving sound as long as the wave-
length is large compared with the diaphragm
circumference. At high frequencies when the wave-
length becomes comparable to or even less than the
diaphragm circumference, two directional effects
become evident. For sound directly incident on the
exposed face of the diaphragm, the partial reflection
of the pressure waveform at the diaphragm surface
increases the acoustic pressure amplitude over that
which would exist in an undisturbed sound field. For
sound incident from the rear of the exposed face of
the diaphragm, the active face of the diaphragm is in
the shadow of the microphone’s housing structure
and experiences a pressure less than that of the
undisturbed sound field. This front to back discrimi-
nation can only be avoided by employing physi-
cally small microphone structures. This is the reason
why measurement microphones often have capsules
of ¼ inch diameter or even less.
Table 17-1. Microphone Sensitivity Comparison
Microphone Mechanism
SV in dBV/Pa Range
Carbon
−20 to 0
Capacitor
−50 to −25
Dynamic
−60 to −50
Piezoelectric
−40 to −20

326
Chapter 17
A controlled directional response can be obtained
by employing a sensing diaphragm both faces of
which are exposed to the sound field of interest.
Such diaphragms experience a driving force that
depends on the spatial rate of change of pressure
rather than on the pressure itself. Consider the situa-
tion shown in Fig. 17-8.
Fig. 17-8 is a bare bones illustration of a
diaphragm stripped of details of the transducing
mechanism. Both sides of the diaphragm are
exposed to a sound wave that is propagating along
the horizontal axis. The diaphragm may be circular
as in a capacitor or moving coil microphone or rect-
angular as in a ribbon microphone. The principal
axis of the microphone is directed perpendicular to
the plane containing the diaphragm and as illustrated
forms an angle θ with the direction of the incident
sound. When θ has the value π ⁄ 2, both faces of the
diaphragm experience identical pressures and the
net driving force on the diaphragm is zero. Now
when θ is 0, the sound wave is incident normally on
the diaphragm and the driving force on the left face
of the diaphragm will be the pressure in the sound
wave at the left face’s location multiplied by the
area of the left face.
The diaphragm material however is not porous so
sound must follow an extended path around the
diaphragm along which the sound pressure can
undergo a change before reaching the right face. The
net driving force on the diaphragm will be the
difference in the pressures on the two faces multi-
plied by the common diaphragm surface area. The
pressure difference can be calculated by taking the
product of the space rate of change of acoustic pres-
sure, known as the pressure gradient, with the effec-
tive acoustical distance separating the two sides of
diaphragm. The least value of this distance is the
diaphragm diameter in the case of a circular
diaphragm.
For a ribbon diaphragm the appropriate value
would approximate the geometric mean of the
diaphragm’s length and width. Details of a particu-
lar microphone housing structure that provide a
baffle- like mounting will tend to increase the effec-
tive separation. If θ is not zero, the microphone axis
is inclined to the direction of the incident sound and
the pressure difference is lowered according to the
cosine of the angle. Before reading the following
mathematical analysis, it might be useful to review
the material on phasor mathematics in Chapter 6
Mathematics for Audio Systems.
As a first case consider that the sound source is
quite distant from the microphone location so that
that the incident sound can be described by a plane
wave. The mathematical description of such a wave
where the direction of propagation is that of the
x-axis is
(17-30)
where,
pm = the acoustic pressure amplitude,
ω = angular frequency = 2πf,
k = propagation constant = ω ⁄ c = 2π ⁄ λ,
c = phase velocity,
λ = wavelength.
Under this circumstance, the net driving force
acting on the diaphragm in the direction of increas-
ing x is given by evaluating the following expres-
sions with x set equal to the coordinate of the
diaphragm’s center.
(17-31)
where,
S is the surface area of one side of the diaphragm,
 is the gradient of the acoustic
pressure in the direction of increasing x.
The pressure gradient is calculated by taking the
partial derivative with respect to x of Eq. 17-30 as
follows
(17-32)
Figure 17-8. Compliantly mounted diaphragm with
both sides exposed to sound field.
θ
p x t,
(
)
pmej ωt
kx
–
(
)
=
F t( )
p x t,
(
)
p x t,
(
)
∂
∂x
-----p x t,
(
)d
θ
cos
+
⎩
⎭
⎨
⎬
⎧
⎫
–
S
=
∂
∂x
-----p x t,
(
)d
θ
cos
–
S
=
∂∂x
⁄
(
)p x t,
(
)
∂
∂x
-----p x t,
(
)
jkp
–
me ωt
kx
–
(
)
=
jkp x t,
(
)
–
=

   
Microphones
327
Upon substituting the result of Eq. 17-32 into
Eq. 17-31, the driving force becomes
(17-33)
In a given sound wave of normally encountered
intensities there exists a relationship between the
acoustic pressure and the acoustic particle velocity.
The ratio of the acoustic pressure to the particle
velocity is called the specific acoustic impedance of
air for the wave type in question. This ratio for plane
waves is a real number equal to the normal density
of air multiplied by the phase velocity of sound. One
then can substitute for the acoustic pressure in
Eq. 17-33 in terms of the particle velocity to obtain
an alternative expression for the driving force.
(17-34)
The significance of the imaginary operator j in
this equation simply means that the phase angle of
the driving force leads that of the particle velocity
by π ⁄ 2 radians or 90°. The amplitude of the driving
force would be
(17-35)
where,
um is the particle velocity amplitude.
The more often encountered case is where the
source is nearby to the microphone location. In such
an instance the appropriate wave description is that
of a spherical wave propagating along a radial line
from the sound source. Mathematically, such a wave
is described by
(17-36)
where,
 is the pressure amplitude that is now
position dependent,
A is a constant determined by the sound source.
The pressure gradient is now more complicated
as the space variable r appears in both the denomi-
nator and the exponent of the expression for the
acoustic pressure.
(17-37)
If the center of the diaphragm is located at a
distance r from the sound source then the driving
force on the diaphragm for the spherical wave
becomes
(17-38)
The driving force now has two components, one
of which is in phase with the acoustic pressure while
the other leads the acoustic pressure by 90°. The
specific acoustic impedance of air for spherical
waves is not as simple as was the plane wave case.
The ratio of the acoustic pressure to the particle
velocity is now
(17-39)
Upon solving Eq. 17-39 for the acoustic pressure
in terms of the particle velocity and substituting into
Eq. 17-38 one obtains the very important result
(17-40)
The importance of this result is apparent when
Eq. 17-40 is compared with Eq. 17-34. With the
exception of the identity of the space variable, the
two equations are identical implying that pressure
gradient microphones respond to the particle veloc-
ity in exactly the same fashion whether the incident
sound wave is plane, spherical, or a combination of
the two. In contrast, pressure sensitive microphones
respond to acoustic pressure whether the source is
nearby (spherical case) or distant (plane case). In
fact, for a pressure sensitive microphone the driving
force depends only on the acoustic pressure and is
given by the direction independent expression
(17-41)
Another very important aspect of pressure gradi-
ent microphones is the proximity effect. This
phenomenon becomes apparent by a rearrangement
of Eq. 17-39. This equation is solved for the particle
velocity in terms of the pressure and the terms then
multiplied in both numerator and denominator by
the radial distance while making use of the fact that
 to obtain
(17-42)
F t( )
jkp x t,
(
)Sd
θ
cos
=
F t( )
jkρ0cu x t,
(
)Sd
θ
cos
=
j
=
ωρ0u x t,
(
)Sd
θ
cos
Fm
ωρ0umSd
θ
cos
=
p r t,
(
)
A
r---ej ωt
kr
–
(
)
=
A
r---
pm
=
∂
∂r
----p r t,
(
)
1
r---
jk
+
⎝
⎠
⎛
⎞p r t,
(
)
–
=
F t( )
1
r---
jk
+
⎝
⎠
⎛
⎞p r t,
(
)Sd
θ
cos
=
p r t,
(
)
u r t,
(
)
---------------
jωρ0
1
r---
jk
+
--------------
=
F t( )
jωρ0u r t,
(
)Sd
θ
cos
=
F t( )
p r t,
(
)S
=
k
ω c
⁄
=
u r t,
(
)
1
jkr
+
jkr
---------------- p r t,
(
)
ρ0c
---------------
⎝
⎠
⎛
⎞
=

328
Chapter 17
The significance of this result is more
pronounced when one examines the magnitude of
the particle velocity.
(17-43)
When the radial distance is large or the wave-
length is short or of course both of these are true,
then Eq. 17-43 reduces to 
with the significance that the particle velocity is
directly proportional to the acoustic pressure. On the
other hand, when r is small or the wavelength is
large or a combination is true, the reduction becomes
 with the signifi-
cance that the particle velocity varies inversely with
frequency. As a consequence, when a sound source is
in close proximity to a pressure gradient microphone
the lower frequencies of the source produce a larger
response than do the higher frequencies. This is the
basis for the proximity effect.
One final observation with regards to the direc-
tional characteristics of pressure gradient micro-
phones. From Eq. 17-38, when θ is in the range
, the cosine of θ is itself a negative
quantity and the polarity of the driving force as well
as the electrical output signal of the microphone is
reversed. A use will now be made of this fact in
discussing a microphone structure that possesses a
variety of several different directional patterns.
A structure consisting of both a pressure gradi-
ent microphone element and a pressure microphone
element makes possible a microphone possessing
adjustable directional characteristics. The elements
should individually be small and located close
together with the diaphragms of the two elements
located in the same plane. A single signal based on a
linear sum of the signals from the individual
elements is generated by the combination. The root
mean square open circuit electrical output of the
assembly can be written as
(17-44)
where,
α is a dimensional constant,
β is the fraction of the pressure microphone
electrical signal,
γ is the fraction of the pressure gradient microphone
electrical signal,
θ is the angle of incidence of the acoustic signal.
The fractional signals can be formed and
summed through the employment of passive
circuitry contained within the microphone housing.
The polar response curve of the microphone for a
given choice of coefficients is obtained by allowing
θ to range continuously from 0 to 2π while plotting
the curve
(17-45)
where,
r is the radial distance from the origin and has a
maximum value of 1,
β and γ are fractional coefficients with β + γ = 1,
θ is the angle of incident sound relative to principal
axis of microphone.
Although β and γ are arbitrary within the
constraint that they sum to unity, there are particular
values that have proven to be quite useful. This
information is listed in Table 17-2.
Some practitioners prefer to employ directional
microphones because such microphones respond to
reverberant acoustical power arriving from all direc-
tions with reduced sensitivity as compared with the
same acoustical power arriving along the principal
axis of the microphone. This property is expressed
by the entry labeled RE in Table 17-2. RE stands for
random efficiency. The hypercardioid pattern, for
example, has a random efficiency of ¼. The
response to power distributed uniformly over all
possible directions is thus only ¼ that for the same
total power arriving on axis.
The entry labeled DF in Table 17-2 compares the
working distance of a directional microphone to that
of an omnidirectional microphone. The DF for a
hypercardioid microphone is 2 meaning that the
working distance for a source on axis for this micro-
phone can be twice as large as that for an omni in
order to achieve the same direct to reverberant
sound ratio in the output signal.
These factors when considered alone would lead
one to believe that higher gain before acoustic feed-
back instability would be achievable through the
employment of directional microphones. This is not
necessarily the case. As a class, omnidirectional
u r t,
(
)
1
k2r2
+
kr
-----------------------
p r t,
(
)
ρ0c
------------------
⎝
⎠
⎛
⎞
=
u r t,
(
)
p r t,
(
)
ρ0c
⁄
=
u r t,
(
)
1 ωr
⁄
(
) p r t,
(
)
ρ0
⁄
(
)
=
π 2
⁄
θ
3π 2
⁄
<
<
Eo
α β
γ
θ
cos
+
(
)
=
Table 17-2. Polar Pattern Parameters for Microphone
Directional Characteristics
Polar Pattern
β
γ
RE *
DF *
Omni
1
0
1
1.0
Gradient
0
1
0.33
1.7
Subcardioid
0.7
0.3
0.55
1.3
Cardioid
0.5
0.5
0.33
1.7
Supercardioid
0.37
0.63
0.268
1.9
Hypercardioid
0.25
0.75
0.25
2.0
*Based on data from Shure Incorporated.
r
β
γ
θ
cos
+
=

   
Microphones
329
microphones exhibit smoother frequency responses
than do directional microphones. The frequencies of
oscillation triggered by acoustic feedback, the ring
frequencies, depend upon a number of factors.
Prominent causative agents are peaks in micro-
phone response and peaks in loudspeaker response
coupled with antinodes in the normal modes of the
room. Room modes at even moderate frequencies
can be quite dense. As a consequence, a single peak
in either microphone or loudspeaker response may
trigger an entire chorus of slightly different ring
frequencies. This set of facts would tend to favor
omnidirectional microphones over directional ones.
The deciding factor is usually not immunity to feed-
back from the reverberant field but rather the neces-
sity to reject a nearby source of objectionable sound
including possible strong discrete reflections.
A microphone consisting of a separate pressure
and pressure gradient element is quite versatile in
that it offers all of the polar response patterns listed
in Table 17-2 assuming that it contains the appropri-
ate switch selectable passive circuitry necessary to
properly combine the signals from the individual
elements. Such a microphone, however, inherently
has a shortcoming in that the centers of the two
elements are physically offset.
Sound waves incident on the device in other than
the principal plane arrive at the two elements at
slightly different times. The difference in arrival
times introduces a phase difference between the
electrical signals generated by the two elements.
This phase difference can be significant at high
frequencies and can distort the directional response
pattern in the high frequency region. Fortunately, it
is possible to avoid the offset problem through the
design of a single diaphragm device that also has
useful directional characteristics.
Fig. 17-9 is a bare bones illustration of a compli-
antly mounted diaphragm and a back enclosure that
is vented through a porous screen to the external
environment. The diaphragm may be part of either a
capacitor or moving coil type of transducer, the
details of which are not shown for simplicity. A
sound wave is incident on the left face of the
diaphragm. The direction of the incident wave
makes an angle θ with the principal axis of the
system. The principal axis is perpendicular to the
plane that contains the diaphragm. The acoustic
pressure on the left face of the diaphragm assuming
a spherical wave is given by
(17-46)
The center of the porous screen to the right of the
diaphragm is separated from the corresponding
point at the center of the diaphragm by an acoustical
distance that amounts to (d + L) where d is the diam-
eter of the diaphragm. We need now to calculate the
acoustic pressure at a point just to the right of the
center of the porous screen. The acoustic pressure in
the incident wave on the diaphragm is a known
quantity p1. As was done in the case of the pressure
gradient microphone, we first calculate the rate of
pressure change with distance along the direction of
propagation. Next we find the component of this
change in the direction of interest. Finally we multi-
ply this component by the acoustical distance
between the points of interest. This last step yields
the pressure change. What is desired of course is the
pressure at the second point. This is the pressure at
the initial point plus the change in pressure. Upon
letting p2 represent the acoustical pressure at a point
immediately to the right of the center of the porous
screen then,
(17-47)
The driving force that actuates the diaphragm,
however, is the pressure difference between p1 and
the pressure in the cavity to the rear of the
diaphragm multiplied by the surface area of one side
of the diaphragm. A detailed analysis would show
that the pressure in the cavity, pe, depends upon both
p1 and p2. Recall that for a pressure sensitive micro-
phone the diaphragm driving force is directly
proportional to the acoustic pressure whereas for a
p1
A
r---e j ωt k
– r
(
)
=
Figure 17-9. Simplified illustration of a single dia-
phragm that is sensitive to a combination of pressure
and pressure gradient.
p2
p1
d
L
+
(
)
θ ∂
∂r
----p1
cos
+
=
θ
L

330
Chapter 17
pressure gradient microphone it is directly propor-
tional to the gradient of the acoustic pressure.
In the capsule described above the driving force
on the diaphragm is proportional to a linear combi-
nation of the pressure and pressure gradient terms.
The sizes of the coefficients in the linear combina-
tion and consequently the particular directional polar
pattern hinge on the volume of the cavity, the areas
occupied by the diaphragm and the porous screen,
the mechanical properties of the diaphragm, and the
porosity of the screen. Such microphones are usually
constructed having a dedicated directional pattern.
The majority of the cardioid family of directional
microphones is constructed in this fashion.
Most microphones have cylindrical symmetry
and basically circular diaphragms. The principal
axis of such a microphone is centered on the
diaphragm, perpendicular to the plane of the
diaphragm, and directed along the cylindrical axis as
illustrated in Fig. 17-10. The directional polar
pattern in a plane is obtained by varying the angle of
incident sound relative to the principal axis of the
microphone.
The three dimensional directional response of
such a microphone is obtained by revolving the
directional polar pattern about the cylindrical axis of
the microphone. Ribbon microphones, however,
don’t follow the above rules, as their diaphragms do
not possess cylindrical symmetry. Such micro-
phones are usually designed to be addressed from
the side as illustrated in Fig. 17-11.
The directional response in the horizontal plane
of the depicted ribbon microphone is a figure eight.
Revolving this pattern about the principal axis
generates two spheres that describe the micro-
phone’s response in three dimensions. The polar
directional patterns listed in Table 17-2 are
displayed in Fig. 17-12A while the three dimen-
sional directional response is sketched in
Fig. 17-12B.
The polar patterns of Fig. 17-12A are the theoret-
ical ideals and have a linear radial axis consistent
with the form of the describing equations. Real
microphones fall short of the theoretical ideal in two
ways. They never display complete nulls in response
and the polar response curves are frequency depen-
dent. Compare the measured polar response curves
of a cardioid microphone presented in Fig. 17-13
with its counterpart in Fig. 17-12A.
Manufacturer’s polar response data is usually
presented employing a logarithmic polar axis while
excluding a small region in the vicinity of the origin.
Such a presentation for yet again a different cardioid
microphone is given in Fig. 17-14.
In examining Fig. 17-14 note that the reference
axis has a different orientation and that the radial
coordinate represents attenuation expressed in deci-
bels relative to the on axis value.
17.6 Boundary Microphones
All microphones can suffer anomalies in their
responses depending upon the relative location of
the sound source and nearby reflecting surfaces. A
commonly encountered incidence of this is illus-
trated in Fig. 17-15.
The combination of the direct sound with the late
arriving and slightly attenuated reflected sound
produces a comb filter amplitude response pattern.
The notches in the pattern occur at those frequencies
where the two signals differ in phase by an odd
integral multiple of π radians. This corresponds to
the total distance traveled by the reflected sound
being an odd integral multiple of λ ⁄ 2 greater than
that traveled by the direct sound. Such a condition
results in destructive interference. If dr is the total
distance traveled by the reflected sound in arriving
at the microphone and dd is the distance traveled by
the direct sound in reaching the microphone, then
the notches occur at those wavelengths where
(17-48)
Figure 17-10. Illustration of the principal axis of a
cyindrically symmetric microphone.
Figure 17-11. Position of the principal axis of a classic
ribbon microphone.
λn
2
n--- dr
dd
–
(
)
=

   
Microphones
331
Figure 17-12A. Standard polar patterns.
180°
150°
120°
90°
60°
30°
0°
330°
300°
270°
240°
210°
0.8
0.4
0.6
1.0
180°
150°
120°
90°
60°
30°
0°
330°
300°
240°
210°
0.8
0.4
0.6
1.0
180°
150°
120°
90°
60°
30°
0°
330°
300°
270°
240°
210°
0.2
0.8
0.4
0.6
1.0
180°
150°
120°
90°
60°
30°
0°
330°
300°
270°
240°
210°
0.2
0.8
0.4
0.6
1.0
Supercardioid Polar Pattern.
Pressure Gradient Pattern.
Cardioid Polar Pattern.
Hypercardioid Polar Pattern.
180°
150°
120°
90°
60°
30°
0°
330°
300°
270°
240°
210°
0.8
1.0
Subcardioid Polar Pattern.
0.2
0.6
0.4
0.2
0.2
270°

332
Chapter 17
where,
n is any odd integer.
The interference frequencies corresponding to
these wavelengths can be easily calculated by
making use of the fact that f = c/λ. This yields
(17-49)
The lowest interference frequency occurs for
n = 1. The next interference frequency has n = 3.
These frequencies are
(17-50)
Three conclusions are worthy of note. The differ-
ence between adjacent interference frequencies is a
Figure 17-12B. Microphone three dimensional direc-
tional response. (Courtesy Shure Incorporated.)
Figure 17-13. Measured polar response of cardioid
microphone at 250 Hz and 2 kHz.
250 Hz dotted
2 kHz solid
Measured response
of cardioid mic
180°
150°
120°
90°
60°
30°
0°
330°
300°
270°
240°
210°
0.2
0.8
0.4
0.6
1.0
fn
n
c
2 dr
dd
–
(
)
------------------------
=
Figure 17-14. Polar response of a cardioid microphone.
Figure 17-15. Microphone that receives direct sound
and delayed reflected sound. (Courtesy Bruce Bartlett.)
0
−5
−10
−15
−20
330°
330°
30°
30°
300°
300°
60°
270°
90°
240°
120°
210°
150°
180°
150°
210°
60°
90°
270°
120°
240°
Soundwave
0°
1000 Hz
3000 Hz
Source
Microphone
Direct sound
Reflective surface
or boundary
Reflected sound
A. Situation
Level - dB
Frequency - linear scale
B. Frequency response
f1
c
2 dr
dd
–
(
)
------------------------
=
f3
3
c
2 dr
dn
–
(
)
------------------------
=

   
Microphones
333
constant equal to 
, this separation
is just twice the value of the lowest interference
frequency, and the smaller the path difference
between the reflected and direct sound, the higher
the frequency of the first interference notch. The
fact that the difference between successive interfer-
ence frequencies is a constant means that this
phenomenon is best viewed on an analyzer with a
linear frequency axis. Additionally, reducing the
path difference between the reflected and direct
sound shifts the first interference frequency to a
higher value. This is illustrated in Fig. 17-16.
Referring to Fig. 17-15 upon taking the direct
and reflected paths to form an equilateral triangle
and assuming a typical height for a young girl, the
difference between the direct and reflected path
lengths will be a little over 5 ft. The first interference
notch will occur at about 100 Hz. The notch separa-
tion would then be about 200 Hz. Contrast this with
the circumstance of Fig. 17-16 where the path length
difference could be as small as an inch. The first
notch would now occur between 6 kHz and 7 kHz.
This suggests that it might be possible to make the
first interference notch occur at a frequency above
20kHz thus placing it beyond the audio band.
Suppose that a pressure sensitive microphone is
oriented to face the reflecting surface directly while
having the diaphragm only 0.25  inch from the
boundary. The path length difference is now also of
the order of 0.25 inch. The first interference notch
now falls between 25 kHz and 30 kHz. Such consid-
erations as well as others led Edward Long and
Ronald Wickersham to point out the need for a pres-
sure calibrated capsule when used in the pressure
zone near a boundary.
Kenneth Wahrenbrock built the first commer-
cially successful microphone systems to incorporate
the basic principles enunciated by Long and Wicker-
sham. Ken employed a miniature electret capacitor
microphone element with the capsule’s diaphragm
being spaced a millimeter or less above a mounting
plate. This small spacing places the first interference
notch at more than two octaves above the audio
spectrum thus allowing a smooth amplitude
response throughout the normal audio band. Micro-
phones constructed in this manner are called pres-
sure zone microphones or PZMs. Fig. 17-17
illustrates the structure of a PZM where the intent is
to mount the entire plate on a larger plane boundary.
At this juncture it is appropriate to consider the
conditions imposed on acoustic wave propagation at
a boundary surface. Initially we will consider that
the boundary is perfectly rigid. With this in mind,
examine the situation depicted in Fig. 17-18.
When the spherical source is radiating at a single
frequency, the air particles are oscillating back and
forth along lines directed radially outward from the
surface of the source while the pressure alternates a
small amount above and below normal atmospheric
pressure. This disturbance away from static condi-
tions begins at the surface of the small spherical
source and propagates outward along radial lines.
The wavefronts are spherical in shape and represent
surfaces all points of which have the same phase.
The drawing of Fig. 17-18 depicts in two dimen-
sions an instantaneous snapshot of this situation
where the spherical wavefronts appear in cross
Figure 17-16. Microphone on floor that receives direct
sound and slightly delayed reflected sound. (Courtesy
Bruce Bartlett.)
2 c 2 dr
dd
–
(
)
⁄
[
]
A. Situation
Level − dB
Frequency − linear scale
B. Frequency response
Figure 17-17. Construction of a typical PZM. (Courtesy
Bruce Bartlett.)
Three-quarter
view
Plate
Microphone
capsule
Capsule
holder
Microphone
capsule
Side View

334
Chapter 17
section as concentric circles with the radial spacing
between successive circles being arbitrarily set
equal to the wavelength indicating a phase change
of 2π from one circle to the next. As time goes on
each spherical wavefront will expand so that its
radius will increase by one wavelength as the
elapsed time increases by one period. The air parti-
cle velocity is a vector oscillating along any radial
line while the acoustic pressure has no direction and
is a scalar quantity.
We assume a simple spherical source for the
purpose of analysis because even complicated
acoustical fields can be described by a superposition
of distributed simple spherical sources of adjustable
strengths, positions, and phases. The chore of calcu-
lating the acoustic pressure at an arbitrary point such
as X in the drawing is quite difficult in the general
case where the boundary may not be rigid and may
have arbitrary dimensions.
The problem is greatly simplified when the
boundary is considered to be perfectly rigid, its
dimensions are large compared with the wavelength,
and the source is not positioned near the boundary
edge. When the boundary is perfectly rigid there can
be no air particle motion at the boundary surface
that is perpendicular to the boundary surface. At the
boundary surface then, the normal component of the
air particle velocity must be zero implying that this
component of the air particle velocity must be
reflected with a reversal of polarity or a phase
change of π.
A plane wave, for instance, could have complete
normal incidence at the boundary and would be
reflected back on itself while undergoing a reversal
in its direction of propagation. The reversal of the
particle velocity that occurs at the rigid boundary
fully accounts for the reversal in the direction of
propagation provided that the pressure is reflected
without a change in phase. When the conditions of
simplification are satisfied, the problem can readily
be analyzed by the method of images as depicted in
Fig. 17-19.
In the method of images one replaces the rigid
physical boundary by an image plane at the bound-
ary location and an image source positioned just as
far below the plane as the actual source is above it.
The properties of the image source are taken to be
identical to those of the actual source. The acoustic
pressure for any point in the half space on or above
the image plane is readily calculated by adding the
contribution of the actual source to that of the image
source. The acoustic pressure at the point X for
example is given by
(17-51)
The composite signal of Eq. 17-51 is exactly the
same as the direct wave to point X from the actual
source combined with the wave which would have
been reflected from the physical boundary. This
composite signal will display all of the usual comb
filter effects. When the point X is located on the
image plane, the distances ra and ri become equal
Figure 17-18. Simple spherical source in the presence
of a rigid boundary.
X
Figure 17-19. Boundary solution by the method of
images.
X
ra
ri
p
pa
pi
+
=
A
ra
----e
j ωt
kra
–
(
)
A
ri
---e
j ωt
kri
–
(
)
+
⎝
⎠
⎛
⎞
=

   
Microphones
335
indicating that the composite pressure becomes
twice that of the actual source operating in a free
field at the same distance. This doubling of pressure
at the image plane surface is the consequence of the
pressure in the reflected wave being in phase with
the pressure of the incident wave. Such a situation is
depicted in Fig. 17-20.
When the observation point is located on the
image plane, the normal or vertical components of
the particle velocity from the two sources are equal
in magnitude but oppositely directed forcing the net
normal component to be zero thus satisfying the
required boundary condition for a rigid boundary.
On the other hand, the horizontal or tangential
components of the particle velocity contributed by
the two sources are equal in magnitude and in the
same direction. The net tangential particle velocity
is thus twice as large as it would have been for a
single source operating in a free field at the same
radial distance.
A solution to a problem in wave acoustics
involves finding a mathematical function that satis-
fies three conditions. First and foremost, the func-
tion must satisfy the wave equation. Secondly, it
must satisfy the conditions that exist at the surface
of the source or sources. Thirdly, it must satisfy the
conditions that exist at any and all boundaries.
The boundary condition at the surface of a rigid
boundary is that the normal component of particle
velocity must be zero. The method of images is
constructed so that it forces satisfaction of the
condition on the normal component of particle
velocity. Fortunately, there exists a mathematical
uniqueness theorem that is applicable to problems in
wave acoustics. This means that once one finds the
function that fulfills the three conditions listed
above it will be the sole solution to the problem.
The exact doubling of the acoustic pressure and
tangential component of the particle velocity only
occurs on the surface of a truly large, rigid bound-
ary. Real surfaces of course are not perfectly rigid
and may also be porous to some degree in which
case the boundary conditions will be different and
the pressure increase will be less than ideal. In such
instances a detailed knowledge of the specific
acoustic impedance of the boundary surface is
necessary in predicting the exact behavior.
Furthermore, we assumed that the boundary
dimensions were large compared with the source
wavelength. Even with a rigid boundary, a 6 dB
increase in pressure above free field conditions will
occur only for those frequencies where the linear
dimensions are large compared with the wavelength.
When the dimensions of the boundary are
comparable to the wavelength the pressure increase
begins to fall and becomes equal to the free field
value when the wavelength is large compared with
the dimensions of the boundary. Shelving filters
may be employed to compensate for this behavior.
17.7 Wireless Microphones
Modern wireless microphones allowing untethered
motion of the user have proven themselves to be
indispensable in concerts, religious services, dramatic
arts, and motion picture or video production.
Wireless microphones for use in the performing
arts and sound reinforcement first made their
appearance about 1960. The first transmitter units
were designed to operate in the broadcast FM band
between 88 MHz and 108 MHz. The receivers were
conventional FM broadcast units. The transmitters
did not have to be licensed as the low radiated
powers involved complied with Part 15 of the FCC
rules. Frequency modulation was accomplished in
the transmitter by allowing the audio voltage signal
to vary the junction capacitance of a bipolar transis-
tor connected as a Hartley or other simple oscillator
tuned to the desired carrier frequency in the FM
band. Such oscillators were prone to drift in operat-
ing frequency as the transistor characteristics were
sensitive to both temperature and supply voltage
Figure 17-20. Observation point located on the image
plane.

336
Chapter 17
variations. This required periodic retuning of the
receiver to compensate for transmitter frequency
drift. This was particularly true of the very early
units that employed germanium transistors. Signifi-
cant improvement in this regard was made possible
with the availability of suitable silicon transistors.
One of the authors well remembers hand crafting
several body pack transmitters in 1965 for use by
lecturers at Georgia Tech. The receivers employed
were H. H. Scott units that had been modified to
incorporate automatic frequency control circuitry to
compensate for the transmitter drift within reason-
able limits. These early units had acceptable audio
bandwidths but the simple modulation technique
employed did not produce large frequency devia-
tions resulting in a small dynamic range of the
recovered audio signal.
Those of us who have experienced the entire
history of wireless microphones consider the present
day versions to be truly remarkable. Not only have
the early shortcomings been addressed but also
features not even envisioned by the early practitio-
ners have been added. The modern history of wire-
less microphone technology can be divided into two
periods. The first period corresponds to the time
when commercial television broadcasting employed
only analog techniques and the second period
commenced with the required changeover to digital
television broadcasting techniques. In the first
period frequency space was made available in both
the VHF and UHF frequency bands and the wire-
less microphones all employed analog technology.
In the second period of wireless microphone
employment frequency allocation is restricted to
UHF and the most recent wireless microphone trans-
mitters and receivers employ digital technology. At
the beginning of the second period wireless micro-
phone manufacturers had to surmount many techni-
cal problems. Fortunately, they did their jobs very
well and managed to produce digital transmitters
and receivers with increased dynamic range as well
as stability and ease of management as compared
with the former analog systems. Additionally,
required receiving antenna lengths are much more
manageable in the UHF band. For example, with a
carrier frequency of 900 MHz and a wave speed of
3 × 108 m/s , the wavelength becomes one third of a
meter or about 13 inches. The required receiving
antennas range between ¼ to ½ wavelength and thus
have lengths falling between about 3 to 6 inches.
Both analog and digital wireless systems have many
features in common and both systems remain in use
where allowed. This discussion will begin with the
analog systems of the first period of employment.
There are several significant technical innova-
tions incorporated in current analog wireless micro-
phone systems that are worthy of note. Each of these
will be discussed in turn.
1. Receiver Assisted Setup.
2. Space Diversity Reception.
3. Transmitter Pre-emphasis–Receiver De-emphasis.
4. Transmitter Compression–Receiver Expansion.
A difficult problem associated with setting up
wireless microphone systems in the past has been
that associated with determining interference free
operating frequencies. This was particularly true
when the application required the simultaneous
operation of a large number of separate audio chan-
nels each of which required an individual radio
frequency assignment. Receivers having assisted
setup facilities have built in protocols for scanning
the entire operating band and identifying those
potential operating frequencies that are free of any
radio frequency carrier at the time of scan. Several
such scans performed over a period of time usually
are quite successful in defining interference free
operating frequencies.
Space diversity reception solves a problem
depicted in Fig. 17-21A by means of an arrangement
suggested by Fig. 17-21B.
In Fig. 17-21A a single receiving antenna is
employed. This antenna receives a signal via a direct
path to the transmitter as well as a transmitter signal
Figure 17-21. Multipath and space diversity reception.
Transmitter
Receiver
Transmitter
Receiver
Reflecting object
Reflecting object
A. Multipath Reception
B. Space Diversity Reception

   
Microphones
337
that has been reflected by a nearby object and thus
follows a longer more indirect path along its way to
the receiving antenna. The phases of these two
signals having the same frequency are different and
hence they can interfere with each other. The inter-
ference may be either constructive or destructive
according to the degree of phase difference. When
the interference is destructive, the resultant signal
may be so weak that the receiver will not be able to
recover the program material. The arrangement
shown in Fig. 17-21B greatly reduces the probabil-
ity that there will be a complete loss of program
material. In this arrangement two antennas located
somewhat less than a wavelength apart are
employed. In this arrangement the reflected signal
may not even arrive at the second antenna as shown.
Even when this is not the case or when there are
other reflecting objects, the chances that both anten-
nas are subjected to destructive interference simulta-
neously is greatly reduced.
There are several techniques for handling the
signals that appear in the space diversity antennas.
In one technique the space diversity receiver is fitted
with separate radio frequency amplifiers for each
antenna. The signals from each of these amplifiers is
compared as to strength with the stronger signal at
any instant being switched to the remainder of the
single receiver circuitry. In a variation on this tech-
nique, the signals from both radio frequency ampli-
fiers are summed and then fed to the rest of the
circuitry of a single receiver with no switching
being involved. Lastly, two receivers set to receive
the same carrier frequency are employed, one for
each receiving antenna. The automatic gain control
voltages that are developed at each receiver's detec-
tion stage are compared with the audio output
circuitry being switched to that of the receiver
having the larger control voltage. This last technique
is the most expensive and even though it involves
switching has perhaps the best performance overall.
Analog wireless microphone transmitters employ
a relatively small frequency deviation in the
frequency modulation process. The modulation
index is thus small. This restricts the dynamic range
that is available for program material and weak
signals may be lost in the noise floor. A long term
average of the spectral density associated with both
voice and music programs exhibit a broad maximum
in the vicinity of 500 Hz accompanied by a roll off
in density beyond about 2 kHz. The spectral density
is the average power per unit frequency interval.
This being the case, it is necessary to pre-emphasize
the higher frequencies in the audio material prior to
further signal processing. The normal range of the
audio material to be transmitted may well be as
large as 80 dB while the available range in the small
deviation FM transmitter may be only 40 dB. The
80dB range of the audio material is squeezed into
the 40 dB range available by 2 into 1 compression
prior to the modulation process. After transmission
and reception at the receiver, the recovered audio
material occupying a 40 dB range is first subjected
to a 1 into 2 expansion in order to restore the full
dynamic range of 80 dB. This is then followed by a
de-emphasis of the audio material above 2 kHz in
order to restore the natural spectral balance of the
audio material. Fig. 17-22 displays typical
pre-emphasis and complimentary de-emphasis
curves with the upper curve being that of
pre-emphasis. The combination of the two yields
flat response across the audio band.
The process of compressing the audio dynamic
range prior to transmission and expanding the range
of the audio material following reception has been
termed compansion. A typical compression curve
employed in the audio circuitry of the transmitter
followed by the complimentary expansion curve
employed in the audio circuitry of the receiver are
displayed in Fig. 17-23.
Transmitter units may be hand-held with a built
in microphone element or a body pack unit provided
with a mini receptacle for a microphone connection.
The microphones employed with body pack units
are usually miniature dynamic or electret capacitor
microphones attached to short cables fitted with
mating connectors to that of the transmitter. The
microphone elements are fitted with clips for attach-
ment to the user's clothing. Occasionally, the micro-
phone element may be part of a head microphone
boom structure.
Figure 17-22. Typical pre-emphasis and de-emphasis
curves.
                     102                    103                      104
Frequency–Hz
Magnitude–dB
20
15
10
5
0
−5
−10
−15
−20
Transmitter Pre-emphasis and Receiver De-emphasis

338
Chapter 17
Typical transmitter features are:
1. Power on-off switch.
2. Carrier frequency selection and indicator.
3. Battery level indicator.
4. Audio gain control.
5. Audio overload indicator.
6. Audio mute switch on body pack units.
7. 9 volt battery.
Receiver units may be stand-alone or
rack-mounted and are usually powered from
conventional power mains. Audio outputs are
provided at both line and microphone level.
A typical space diversity receiver providing
assisted setup has the following features:
1. Power on-off switch.
2. Scan or operate control.
3. Carrier frequency indicator.
4. Squelch control.
5. Active receive antenna indicator.
6. Radio frequency level indicator.
7. Transmitted audio level indicator.
8. Transmitter battery life indicator.
9. Audio output level control.
One final note with regard to analog wireless
microphone systems that has been distilled from
years of sad personal experience. The first three rules
for dealing with wireless microphone systems are:
1. Batteries.
2. Batteries.
3. Batteries!
Wireless transmitters are usually powered by
9volt batteries that may be composed from primary
or non-rechargeable cells or secondary cells that are
rechargeable. Even if one ordinarily uses recharge-
able batteries, it is well to keep a fresh supply of
non-rechargeable units on hand. The histories of
rechargeable batteries must be carefully managed in
order to assure their proper performance. Many
practitioners prefer to employ only fresh non-
rechargeable batteries along with frequent replace-
ment because of sad experiences with rechargeable
units. Battery failure at a critical moment can lead to
years of bad dreams.
Although details vary dependent on the various
manufacturers a high quality digital wireless system
would typically feature 24 bit digital audio along
with AES standard encryption for privacy, ethernet
networking setup capability for multiple receivers,
and spectral scanning capability for choosing inter-
ference-free operating frequencies. Some advanced
systems even offer frequency diversity operation for
remotely changing the operating frequency of body
packs or handheld transmitters while in use in the
case of a transiently interrupting signal. Both hand
held and body pack transmitters offer selectable
radiated power in the range of one to twenty mW.
The outstanding feature of the digital systems is the
increased available dynamic range that can have an
A weighted value in excess of 120 dB. The mobile
transmitter units usually employ rechargeable Li-ion
batteries. A photograph of a space diversity digital
wireless microphone system complete with both
hand held and body pack transmitters is presented in
Fig. 17-24.
Figure 17-23. Dynamic range compression at the trans-
mitter and complimentary expansion at the receiver.
Output level–dB
−80  −70    −60   −50   −40    −30   −20    −10      0
Input level–dB
Compansion
0
−10
−20
−30
−40
−50
−60
−70
−80
Receiver
expansion
Transmitter
compression
Figure 17-24. Wireless microphone system. (Courtesy
Shure Incorporated.)

   
Microphones
339
17.8 Microphone Connectors, Cables, and 
Phantom Power
It is almost universal practice in professional audio
to provide signal sources with male connectors and
signal receivers with female connectors. Addition-
ally, it is common practice to employ balanced
circuits for both input and output in those instances
where the signal levels are low and susceptible to
electrical noise or cross talk interference. Indeed,
many systems maintain balanced linking circuits
throughout regardless of the signal levels.
If one excludes miniature microphones that
constitute a special case, the de facto standard
microphone connector is the XLR-3. The male and
female versions of this connector are illustrated in
Fig. 17-25.
Through the years the assignment of functions to
the various pins has varied. The present standard
assignment of the male connector at the microphone
has pin 1 connected to the microphone case. Pin 2 is
connected to the microphone circuitry such that a
positive pressure on the microphone diaphragm
drives the voltage at pin 2 in the positive sense. Pin 3
is connected to the microphone circuitry such that a
positive pressure on the microphone diaphragm
drives the voltage at pin 3 in the negative sense. Pins
2 and 3 are balanced with respect to pin 1.
Quality microphone cables consist of a twisted
pair of insulated, color-coded inner conductors
formed from stranded copper wire covered by a
tightly woven copper braided shield with the combi-
nation encased in an insulating jacket. The conduc-
tors may be tinned although this is not always the
case. The cable is fitted with a female connector at
one end and a male connector at the other. The
connector pin assignments in this instance have pin
1 connected to the shield with the option of also
strapping the connector shell to pin 1. Pin 2 is
connected to the positive signal conductor while
pin 3 is connected to the negative signal conductor.
Microphone cable is also often used as the connect-
ing cable in link circuits between mixers, subse-
quent signal processing units, and power amplifiers.
Shielded, twisted pairs in balanced circuits are an
absolute necessity in handling low level signals in
order to avoid electromagnetic interference. The
braided shield alone offers protection from electro-
static fields but offers very little protection from
changing magnetic fields. The practice of employ-
ing twisted pair conductors stems from experience
gleaned from the early days of the telephone
industry.
In former times long distance circuits between
cities and local circuits in rural areas employed open
bare wire pairs affixed to separate glass insulators
attached to multiple cross arms which were in turn
elevated by poles. It was learned early on that
open-air electrical power lines that often followed
parallel paths caused interference. It was found that
by periodically transposing the positions occupied
by the two conductors of a given circuit pair that the
interference could be greatly reduced if not elimi-
nated altogether. This transposition amounted to
periodically twisting without touching one conduc-
tor of a circuit pair over the other, in effect forming
an insulated, twisted pair even though the distance
between twists was relatively large. The explana-
tion for this annulment of the interference appears in
Fig. 17-26.
In Fig. 17-26 imagine that the twisted pair of
conductors is replicated both to the right as well as
to the left to form an extended circuit. Imagine also
that in the vicinity a magnetic field is instanta-
neously directed into the figure as indicated by the
X’s and that the field strength is increasing with
time. Examine the two closed paths as indicated by
the circles. According to Lenz’s law, the induced
voltage acting in the loops has the sense indicated
by the arrows. Now look at the white conductor in
the upper left, the induced voltage in this portion of
conductor is in the same direction as is the arrow
Figure 17-25. Pin arrangements of XLR-3 connectors.
2
3
1
1
2
3
Male
Female
XLR-3 Connectors
Figure 17-26. Twisted pair exposed to a time changing
magnetic field.
Twisted pair
X
X

340
Chapter 17
adjacent to it. Compare that with the induced volt-
age in the white conductor in the lower right in
which the induced voltage is oppositely directed.
The same analysis applied to the two similar
segments of the black conductor yields identical
results. There is no voltage induced in either
conductor in the transposition region as the arrows
in the adjacent circles are oppositely directed. In
practice, the magnetic field alternates but as it
changes its direction of growth, the induction in the
loops reverses direction also while the net voltage
induced in the transposed conductors remains at
zero. Static magnetic fields are of no consequence
unless a conductor is moving through them. Even
so, a twisted pair translated through a magnetic field
that is static in time will experience a net induced
voltage only if the magnetic field varies rapidly with
position in space.
Air capacitor microphones require a source of
polarization voltage as well as a dc power source for
operating the source follower that handles the
microphone signal. Electret capacitor microphones
are self-polarized but still require power for the
source follower signal circuitry. This power is
usually supplied by the microphone mixer via the
cable connecting the microphone to the mixer. The
circuitry employed for accomplishing this must
maintain balance of the microphone signal circuitry.
Dc circuits that perform this task are called phantom
power supplies. One such arrangement is depicted in
Fig. 17-27.
The arrangement of Fig. 17-27 features an output
transformer internal to the microphone housing as
well as an input transformer internal to the mixer.
The dc voltage is applied equally to the microphone
signal conductors at pins 2 and 3. The dc return
circuit is through the shield on the microphone cable
at pin 1. Conductors 2 and 3 have the same dc
potential and hence there is no direct current in the
transformer windings. In order to accomplish this
the resistors denoted as R must be carefully matched
to be equal to within ±0.1%. This precision is
required not only for dc balance but also to maintain
a large common mode rejection ratio. Commonly
encountered voltage and resistor values are listed
below.
There is a trend by some designers to employ
electronically balanced inputs in the mixer input
microphone circuitry. In such instances blocking
capacitors must be employed to isolate the differen-
tial mixer input from dc while maintaining continu-
ity for the microphone signal. Such an arrangement
appears in Fig. 17-28.
The phantom power circuits of Figs. 17-27 and
17-28 work well but both have an undesirable
feature. The necessity of the employment of
matched balancing resistors in both instances limits
the current that may be supplied to power the micro-
phone circuitry. This limitation can be removed
through the employment of transformers that are
center tapped on the appropriate windings. Such
transformers would be quite expensive because of
the necessity of very accurately having both an
equal number of turns on either side of the center tap
as well as exact resistance of the turns on either side
of the center tap. If this is not accomplished direct
current will exist in the transformer winding and the
signal circuit will no longer be exactly balanced.
Finally, a word of caution is in order. Sound
systems may employ just a few or a very large
number of microphone cables not only for micro-
phones but also for link circuits. It is important to
maintain correct signal polarity in all microphones,
microphone cables, link circuits, all processing elec-
tronics, loudspeaker wiring, and loudspeakers.
Figure 17-27. Phantom power arrangement for capaci-
tor microphones.
2
1
3
Mic signal
Power return
Phantom
supply
To preamp
Mic power
Supply Voltage
Resistor Value
12 V
680 Ω ± 0.1%
24 V
1200 Ω ± 0.1%
48 V
6800 Ω ± 0.1%
Figure 17-28. Phantom power circuit when electroni-
cally balanced inputs are employed.
2
1
3
Mic power
Mic signal
Power return
Phantom
supply
To preamp
+
−

   
Microphones
341
There are convenient commercial devices called
polarity checkers that can be employed to check
individual microphones, cables, and overall system
polarity. An investment in such devices is modest,
time saving, and will earn its keep many times over.
17.9 Measurement Microphones
A collection of measurement microphones whether
residing in sound level meters or stand alone devices
is an absolute necessity for both sound system
installers as well as acoustical consultants. Such a
collection must also be supported by an appropriate
microphone calibrator system that consists of both
the calibrator itself as well as a set of adapters to
accommodate the various individual sizes of the
microphones in the collection.
For many years there were only two suppliers of
quality measurement microphones. Brüel and Kjaer,
a Danish firm, and GenRad, a domestic firm. Brüel
and Kjaer still exists though not under the original
ownership while GenRad no longer exists. Fortu-
nately there are now several new domestic suppliers
of quality measurement microphones.
Measurement microphones are dominantly air
capacitor or electret capacitor microphones while
ceramic piezoelectric units may still be encountered.
The standard sizes in terms of capsule diameter are
1 inch, ½ inch, ¼ inch, and 1⁄8 inch. The larger units
have higher sensitivity and lower noise floors. The
1 inch unit is favored for making measurements in
quiet environments at frequencies below about
8 kHz. The ½ inch unit is a general purpose one but
has high frequency limitations.
Broad frequency band measurements usually
require the ¼ inch or 1⁄8 inch variety particularly if
high sound levels are to be encountered. All sizes
can have low frequency responses that extend
almost to 0 Hz with 3 Hz to 5 Hz being typical with
even lower values being possible. A slow leak for
allowing the capsule’s rear chamber pressure to
follow weather induced atmospheric pressure varia-
tions determines the low frequency limit.
The geometry of a measurement microphone’s
physical structure is that of a cylinder with the
central axis of the cylinder being perpendicular to
the plane that contains the microphone capsule’s
circular diaphragm. This central axis serves as a
reference direction for sound incident on the micro-
phone. Direct sound arrives at 0° relative to this axis
while grazing incidence occurs at 90° as illustrated
in Fig. 17-29.
Any measurement microphone should be
encased in such a fashion that the microphone’s
physical structure disturbs the sound field in which
it is immersed to a minimum degree. When the
microphone capsules are smaller than ½ inch in
diameter it is impossible to incorporate the neces-
sary circuitry and connector in a uniform cylinder
having a diameter equal to that of the capsule. In
such instances it is necessary to enclose the circuitry
and connector in a larger cylinder that is joined to
the capsule by a smoothly tapered section matching
the larger diameter to the smaller diameter. A nota-
ble example of this is displayed in Fig. 17-30.
Measurement Microphone Types
In spite of the smoothness of the microphone enclo-
sure one can not escape the fact that at high frequen-
cies the microphone capsule diameter, d, is
comparable to the sound wavelength, λ. When this
occurs, the sound field is disturbed by both reflec-
tion from the capsule’s diaphragm as well as diffrac-
tion by the capsule’s protective grid and the
microphone housing. The degree of this disturbance
depends on the angle of incidence of the sound and
is greatest for direct incidence.
The acoustic pressure at the diaphragm for
directly incident sound at high frequencies can in
fact exceed by several decibels that which would
have existed in the free field. The free field pressure
is that which would have existed if the obstacle
presented by the microphone had not been present.
It is desirable in such instances to structure the
microphone’s direct field response such that it is
proportional to the free field pressure over as wide a
frequency range as possible. It is possible to do so
by properly choosing the diaphragm’s mechanical
resonance frequency and the degree of damping of
the mechanical resonance when the microphone
capsule is designed.
Figure 17-29. Illustration of direct and grazing sound
incidence.
Figure 17-30. An example of a well-engineered tapered
microphone structure. (Photo courtesy of Alex Khenkin
of Earthworks, Inc.)
Direct at 0°
Grazing at 90°

342
Chapter 17
Measurement microphones designed in this fash-
ion are referred to as being direct or free field micro-
phones. They are valuable for measurements close
to sound sources in any environment where direct
sound dominates or for measurements at any
distance from sound sources in unenclosed spaces.
Measurements made in reverberant environments
require a measurement microphone having a differ-
ent set of characteristics. Here the emphasis is on a
microphone response that is flat over a wide
frequency range for sound that impinges on the
microphone from all directions. Such microphones
are referred to as random incidence microphones.
As one would suspect, microphone capsule
mechanical structures are different for free field and
random incidence microphones. Oftentimes, how-
ever, measurements must be made in reverberant
environments that also contain directive sound
sources. When this is the case, the best results are
obtained when the random incidence microphone is
oriented such that the direct sound from the source
makes an angle of 70° with the microphone axis.
Response characteristics of a family of both free
field and random incidence measurement micro-
phones are displayed in Fig. 17-31.
In viewing Fig. 17-31 for both the 1 inch and
½inch capsules, the upper curve in each instance is
associated with a capsule optimized for free field
measurement. Note also that the upper curve has
two branches. One branch is labeled F for free field
and corresponds to direct or 0° incidence. The other
branch is labeled P and is the pressure response of
the same capsule as measured by an electrostatic
actuator as described under the next topic. The
lower curve in each case is the pressure response of
a capsule optimized for random incidence. It should
also be noted that the flattest response over the
entire audio band is associated with the smallest
capsule size.
17.10 Microphone Calibrator
There are several very precise and accurate labora-
tory techniques for determining a measurement
microphone’s pressure response as a function of
frequency. Manufacturers routinely employ one or
more of these techniques to supply a measured cali-
bration curve for each of their measurement micro-
phone capsules. The most often employed technique
for laboratory calibration is that of electrostatic actu-
ation. In this technique the microphone capsule is
subjected to a combination of static and time vary-
ing electric fields. This combination of fields exerts
a uniform force over the surface of the diaphragm
and in effect allows a measurement of the capsule’s
pressure response over any frequency range desired.
All laboratory calibration techniques usually
require the use of several different instruments.
These instruments in turn must periodically be
subjected to a calibration process. It is impractical to
attempt to employ these laboratory techniques for
calibration purposes in the field. Fortunately
measurement microphone capsules are quite stable
and will maintain their characteristics over long
periods of time unless subjected to abuse.
Measurement microphone capsules of different
types and sizes can usually be used interchangeably
with the same preamplifier provided that differing
capsule sensitivities are properly accounted for. This
can be done quite readily if one has at hand a device
that can subject a given microphone to a known
acoustic pressure to within a few percent. Extreme
accuracy is not required. For example, a pressure
level uncertainty as small as ±0.5 dB corresponds to
an acoustic pressure accuracy of ±5.9%.
Acoustic calibrators suitable for field use are
based on a relatively simple equation from linear
acoustics that relates the acoustic pressure to the
change of air density,
(17-52)
where,
p = acoustic pressure (pascals),
γ = 1.402 (dimensionless),
Figure 17-31. A comparison of response characteris-
tics of a family of both free field and random incidence
measurement microphones versus capsule sizes. (Data
courtesy of Noland Lewis of ACO Pacific, Inc.)
Frequency
Frequency Response
Open circuit output
Type 1.5
1/2 inch capsules
high sensitivity
1/2 inch capsules
standard sensitivity
1/4 inch capsules
Electric capsules
1 inch capsules
p
γP0
ρ
ρ0
–
ρ0
---------------
=

   
Microphones
343
P0 = static atmospheric pressure (pascals),
ρ = density of disturbed air (kgm per m3),
ρ0 = static air density (kgm/m3).
The last factor in Eq. 17-52 is the change in air
density as a result of compression or expansion
divided by the undisturbed air density. This quantity
is called the condensation and is positive when the
air is compressed and negative when the air is
allowed to expand. The compressions and expan-
sions that occur in sound waves in free air are
described as being adiabatic. This means that during
the compression or expansion heat energy is neither
added nor subtracted from the air and the air temper-
ature undergoes changes. The adiabatic process for
sound waves results from the fact that air itself is a
relatively poor thermal conductor. If air were a good
thermal conductor the process would become
isothermal. Eq. 17-52 has the same form for an
isothermal process except the constant γ would be
replaced by 1.
We will now pursue Eq. 17-52 and see what it
suggests. The only variable at our disposal in this
equation is the disturbed air density ρ. Suppose we
have a small container that is filled with air at
normal atmospheric pressure. Let the interior
volume of this container be V0. Further suppose that
we can introduce some mechanism that periodically
can vary the volume of the container above and
below V0 by a small amount ΔV, such that at any
instant the volume of the container is V = V0 + ΔV. If
we let the mass of air in the container be represented
by m, then the condensation term of Eq. 17-52 can
be written as
(17-53)
In Eq. 17-53 the density has been represented by
the mass divided by the appropriate volume
followed by algebraic simplification. Taking the
simplification one step further,
(17-54)
The last step can be justified by simply requiring
that the magnitude of ΔV be small as compared with
V0. The conclusion to this point then becomes
(17-55)
Eq. 17-55 suggests the following possible struc-
ture for a practical microphone calibrator for use in
the field.
Fig. 17-32 depicts a rigid enclosure that is fitted
with the subject microphone on the right and a bush-
ing mounted movable piston on the left. A motor
actuated mechanical linkage, the details of which
are not shown in the figure, drives the piston. The
nature of the drive is such that the piston is forced to
undergo a linear displacement between the indicated
limits with the displacement at any instance being a
sinusoidal function of time. The piston is depicted at
its equilibrium position at which the total enclosed
volume of air is V0.
Let the piston have a cross-sectional area A and
let its displacement from equilibrium at any instant
be given by 
 This being the case,
the change of volume at any instant will be in the
form of 
 The alge-
braic sign is negative because a positive displace-
ment of the piston decreases the available volume.
The acoustic pressure in the enclosure will be every-
where the same as long as the linear dimensions of
the enclosure are small as compared with the sound
wavelength corresponding to the operating
frequency f. This being the case, the acoustic pres-
sure experienced by the microphone’s diaphragm
will be
ρ
ρ0
–
ρ0
---------------
m
V----
m
V0
------
–
m
V0
------
----------------
=
1
V---
1
V0
------
–
1
V0
------
----------------
=
V0
V
–
V
---------------
=
Figure 17-32. Possible microphone calibrator structure.
V0
V
–
V
---------------
V0
V0
ΔV
+
(
)
–
V0
ΔV
+
-------------------------------------
=
ΔV
–
V0
----------
≈
p
γP0
ΔV
V0
-------
–
≈
P
Microphone
x
xm
2πft
(
).
cos
=
ΔV
Ax
Axm
2πft
(
).
cos
–
=
=

344
Chapter 17
(17-56)
This structure of microphone calibrator is called
a piston phone. A variation on this structure replaces
the piston and its mechanical drive with a precisely
made small loudspeaker powered by an electrical
oscillator. For a given piston phone, the piston area,
the maximum piston displacement, the equilibrium
value of enclosed volume, and the operating
frequency are determined at the time of manufac-
ture. The root mean square value of the acoustic
pressure produced by such a unit can then be written
as
(17-57)
where,
C = a constant for the device.
In the foregoing, it has been assumed that the air
in the enclosure is operating under true adiabatic
conditions. A correction to this assumption must be
considered. The walls of the piston phone must be
rigid and usually are made of metal. Even though a
body of air has poor thermal conductivity, some air
is in contact with the walls of the enclosure where
heat transfer can occur because of the high thermal
conductivity of the metal walls. In accounting for
this a small correction factor must be applied to Eq.
17-57 as the true acoustic pressure under this condi-
tion is slightly less than predicted. The size of this
correction factor hinges on the ratio of the interior
volume to the wall surface area. Larger such ratios
have smaller correction factors usually only a frac-
tion of 1%. The effect of including this correction
factor simply slightly reduces the size of the
constant in Eq. 17-57.
The acoustic pressure produced by the device is
directly proportional to the ambient atmospheric pres-
sure. For precise work it is necessary to measure the
local atmospheric pressure at the time of use. Calibra-
tors are usually supplied with conversion tables for
converting barometric atmospheric pressure
expressed in mm of Hg to pascals. True piston phones
operate at frequencies of a few hundred Hz.
Loudspeaker versions operate at 1000 Hz for
convenience in calibrating the A, B, and C scales of
sound level meters. All three scales should produce
identical readings at 1000 Hz. Typical pressure
levels produced by field calibrators are 94 dB,
114 dB, or 124 dB. The loudspeaker versions of cali-
brators can offer one or more of the above levels as
well as operate at frequencies other than 1000 Hz.
Fig. 17-32 was drawn for the largest diameter
microphone to be accommodated by the calibrator.
Smaller microphone diameters can be accepted
when an adapter sized to maintain the interior
volume is employed.
Bibliography
Glen M. Ballou. Handbook for Sound Engineers, 4th ed. Boston: Focal Press, 2008.
Leo L. Beranek. Acoustics, New York: Mc-Graw-Hill, 1954.
Brüel and Kjaer Technical Review. Measuring Microphones. Naerum: 1972.
John Eargle. The Microphone Book, 2nd ed. Boston: Focal Press, 2004.
P. M. Morse, Vibration and Sound, 2nd ed. New York: Mc-Graw-Hill, 1948.
p
γP0
Axm
2πft
(
)
cos
V0
----------------------------------
=
prms
γP0
2
-------- Axm
V0
----------
⎝
⎠
⎛
⎞
=
CP0
=

Chapter 18
Loudspeakers and Loudspeaker Arrays
by Eugene Patronis, Jr.
345
18.1 Loudspeaker Types . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 347
Direct Radiators . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 347
Direct Radiator Spatial Response  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 353
Far Field Directivity of a Direct Radiator . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 354
Loudspeaker Cone Behavior . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 356
Dome Radiators . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 358
18.2 Radiated Power  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 358
18.3 Axial Sound Pressure Level . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 363
18.4 Efficiency . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 363
18.5 Loudspeaker Electrical Impedance  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 364
18.6 Loudspeaker Directivity Factor . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 365
18.7 Loudspeaker Sensitivity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 365
18.8 Direct Radiator Example Calculations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 366
18.9 Horns and Compression Drivers  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 368
Conical Horn . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 370
Cylindrical Horn  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 371
Plane Wave Tubes  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 371
Catenoidal Horn . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 372
Exponential Horn . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 373
Constant Directivity Horns  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 374
18.10 Practical Considerations Involving Horns . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 374
18.11 Horn Compression Drivers  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 376
18.12 Crossover Networks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 378
Origin . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 378
Electric Filters . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 379
Transfer Functions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 379
Higher Order Networks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 383
Three-Way and Higher Crossover Networks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 387
Synthesized Crossover Networks  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 390
18.13 Loudspeaker Arrays . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 392
Acoustic Order of Choices of System Structure  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 392
Design Process . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 393
Arraying Techniques . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 395
Increase Coverage Angle . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 395
Increase of Level on Axis  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 395
18.14 Bessel Array . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 398
18.15 Line Arrays  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 400
Line Array of Discrete Elements . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 404
Processed Line Arrays . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 405
Distributed Systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 409
Hybrid Arrays  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 411
Split Identical Sources . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 411
18.16 Vented Enclosure Bass Loudspeakers  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 412
Equal Slope Bandpass Subwoofer . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 416
Unequal Slope Bandpass Subwoofer . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 418
18.17 Large Signal Behavior of Loudspeakers  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 420
18.18 Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 420


   
Loudspeakers and Loudspeaker Arrays
347
A loudspeaker, with the possible exception of the
listener’s ear, is the final transducer in the sound
system chain. The burdens placed on a loudspeaker
are both numerous and demanding. The primary
burden is to faithfully convert the electrical energy
supplied by an amplifier into acoustical energy.
Once the conversion is accomplished, the further
burden is to direct the acoustical energy through the
medium of air to the listening audience while the
audience itself may be widely dispersed. Further-
more, the acoustical energy must be directed in such
a fashion that the acoustic pressure experienced by
all listeners is reasonably uniform. A single device
seldom, if ever, can shoulder these burdens. The
human audible spectrum encompasses a range of at
least ten octaves from 20 Hz to 20 kHz. In the case of
sinusoidal excitation, the simple form of the funda-
mental relationship determining the acoustic pres-
sure in a spherical wave produced by a transducer is
written as the proportionality:
(18-1)
where,
p is the acoustic pressure,
ρ0 is the undisturbed density of air,
ω is the angular frequency,
S is the effective radiating surface area,
u is the surface velocity.
The product Su is called the volume velocity. The
surface velocity in turn is the product of the surface
displacement with the angular frequency hence, the
relationship might well be written as
(18-2)
where,
ξ is the surface displacement.
Αt low frequencies where ω is small, a signifi-
cant acoustic pressure will require a large product of
Sξ. The displacement itself is limited by mechan-
ical constraints, which requires an even larger
surface area and possibly leads to the necessity for
multiple units acting in concert. Large surface areas
are attended by significant mass.
At high frequencies where ω is large, the acceler-
ation which is the product ω2ξ becomes quite large.
As a result, the required net driving force, which is
the product of the moving mass with the accelera-
tion, becomes excessive. The required force may be
made reasonable by a reduction in the moving mass
which can be accomplished by a reduction in S. One
is thus faced with diametrically opposed constraints
in that low frequencies require large S and high
frequencies require small S in order to achieve a
given appreciable acoustic pressure. In addition
there are the questions of uniformity of acoustic
pressure with regard to frequency as well as unifor-
mity of radiation pattern with frequency. Taken
together, these considerations require that the
audible spectrum be divided into two or more bands
with appropriately sized transducers operating in the
individual bands. This introduces the additional
complication of designing the appropriate electrical
filters for insertion in the signal paths of the various
transducers and arranging the various transducers in
such a way that their acoustical outputs combine
seamlessly. This is a formidable task indeed and
more often than not is only approximately satisfied
in practice.
18.1 Loudspeaker Types
Loudspeakers may be broadly classified as being
either direct radiators or horns. Further classification
can be made with regard to moving surface or
diaphragm structure and the physical nature of the
driving force. Additionally, a loudspeaker, as distin-
guished from a loudspeaker system, is often classi-
fied as being a low, mid, or high frequency device
depending on the portion of the audible spectrum in
which its design parameters allow it to excel.
Direct Radiators
The most often employed direct radiators in sound
reinforcement systems are based on the pioneering
work of Chester W. Rice and Edward W. Kellogg. A
tribute to the thoroughness and ingenuity of this
work is evidenced by the fact that even though it
was first published in 1925, only minor improve-
ments and modifications have been made to the
basic design up to the present day. In their initial
research, Rice and Kellogg studied a wide range of
possible devices for use as a loudspeaker. The
devices examined included among others a thermo-
phone, an electrostatic panel, a modulated air stream
device, small diaphragm moving coil instruments,
and an induction device.
The best results were obtained with an electro-
static panel and a moving coil device having a light
paper cone diaphragm mounted on a flat baffle.
They found that the electrostatic panel produced
quality sound but insulation problems and the neces-
sity for large panels in order to produce significant
low frequency output forced their abandonment in
favor of the moving coil devices. A diaphragm in
the shape of a shallow cone was employed in the
preferred moving coil device because this shape was
p
ρ0ωSu
∝
p
ρ0ω2Sξ
∝

348
Chapter 18
found to offer the most rigidity for the light
diaphragm materials employed.
The modern moving coil or electrodynamic loud-
speaker is changed little from the original versions
of Rice and Kellogg. The modern versions employ
permanent magnets rather than the electromagnets
in the originals. Modern technology offers a much
wider range of cone materials and modern adhesives
improve long term longevity even under conditions
of hard usage. Additionally, there is now a
well-developed theory of enclosure design which
was not available to Rice and Kellogg.
Fig. 18-1 is illustrative of a typical modern elec-
trodynamic loudspeaker.
The parameters necessary to characterize the
small signal behavior of this form of direct radiator
are partly electrical, partly mechanical, and partly
acoustical. The mechanical parameters are denoted
as M, K, S, and Rm. M is the effective moving mass
of the cone or diaphragm. It includes all of the cone
mass as well as that of the voice coil and the voice
coil former with some additional fractional contribu-
tion from the centering spider and the outer
surround. K is the stiffness constant of the suspen-
sion and is constituted of contributions from both
the centering spider and the surround. S is the effec-
tive radiating area. This is not the actual surface area
of the cone, which is a larger quantity, but rather, is
the area of a circle whose diameter is slightly larger
than the cone diameter. It is slightly larger than the
actual cone diameter because the inner portion of
the surround moves with the cone and contributes to
the radiating surface. Rm is the mechanical resis-
tance associated with the suspension elements
including both the surround and the spider.
The electrical parameters are denoted as being
Re, Le, B, and l. Re is the direct current resistance of
the voice coil, Le is the self inductance of the voice
coil, B is the radially directed magnetic induction in
the magnetic air gap in which the voice coil resides,
and l is the total length of voice coil conductor
residing in the magnetic air gap. The acoustical
parameters are denoted as Rr and Xr. Rr is a
frequency dependent function called the radiation
resistance. In addition to its frequency dependence,
the radiation resistance depends also on the radiating
surface area S and on boundaries in the vicinity of
the radiator. The radiation resistance is quite small at
low frequencies and as a consequence, has little
influence on the motion of the radiating surface in
the low frequency limit.
Xr is also a frequency dependent function. Its
value at any frequency depends on the radiating
surface area and the radiator boundaries. Its prin-
cipal physical effect at low frequencies is to act as if
a small additional mass is attached to the cone or
diaphragm. In other words, at low frequencies it
increases the cone’s inertia. Values of the electrical
and mechanical parameters that are typical for a mid
range direct radiator are listed in Table 18-1.
It should be noted that the values listed in
Table 18-1 all employ SI units. These are the units
currently employed in all scientific work. In the
United States, the past common practice was to
express loudspeaker sizes in terms of a diameter
expressed in inches with the common sizes being
2, 4, 6, 8, 10, 12, 15, and 18 inches. In many other
countries the practice was to express the diameter in
millimeters. In any event, the stated sizes are
misleading in that hardly any feature of the device
corresponds to the stated size. Fortunately there is a
rule of thumb which is accurate to within about 5%.
This rule is that the stated diameter in inches is
approximately equal to the effective radius of the
radiator expressed in centimeters. For example, the
parameters of Table 18-1 are those of a 10 in diam-
eter driver. The rule would say that the effective
radius of this device is then 10  cm. Ten  cm
Figure 18-1. Loudspeaker structure.
Dust cover
Spider
Magnetic yoke
Voice coil former
Voice coil
Magnet
Frame
Surround
Cone Clamp ring
Table 18-1. Electrical and Mechanical Parameters of a
Typical Mid Range Direct Radiator.
Parameter Description
Symbol and 
Dimensions
Typical
Values
Radiator radius
a (meter)
0.10
Radiator area
S = πa2 (meter2)
0.0314
Moving mass
M (kilogram)
0.03
Suspension stiffness
K (Newton-meter-1)
3000.0
Suspension resistance
Rm (kilogram-s-1)
2.5
Voice coil resistance
Re (Ohm)
6.0
Voice coil inductance
Le (Henry)
0.001
Magnetic induction in gap
B (Tesla)
1.0
Length of conductor in gap l (meter)
10.0

   
Loudspeakers and Loudspeaker Arrays
349
correspond to 0.1 m and that is indeed the effective
radiator radius.
Regardless of whether one is dealing with a low,
mid, or high frequency direct radiator, at the low end
of the respective operating range, the device is
considered to act as a flat piston for the purpose of
analyzing the dynamics and acoustics of the radiator.
This is justified because at the lower frequencies the
cone undergoes axial motion as a unit and the wave-
lengths are larger than the dimensions of the radi-
ator. If such a radiator is suspended in free air devoid
of any baffle or back enclosure it would attempt to
radiate from its rear side as well as its front side. In
this circumstance when the piston moves so as to
compress the air in front of it, the air to the rear will
be rarefied, meaning that the front side and the rear
side are out of polarity. Such an arrangement consti-
tutes what is called an acoustic dipole and is a poor
radiator particularly at low frequencies.
It is necessary to separate acoustically the front
side from the back side either by means of a large
flat baffle or by enclosing the rear side. The latter
option is more convenient in practice even though
the back enclosure itself introduces further compli-
cations. If one can manage to keep the back enclo-
sure dimensions small compared with any
wavelength in the pass band of the transducer, the
air trapped in an unvented back enclosure acts
simply as a spring effectively increasing the overall
stiffness of the loudspeaker. This additional stiffness
associated with the enclosure is given by
(18-3)
where,
γ is dimensionless with a value of 1.4 and is the
adiabatic constant for air,
P0 is the static air pressure,
S is the effective radiator surface area,
V0 is the actual air volume in the interior of the back
enclosure.
Clearly, the back enclosure does influence the
dynamics of the radiator, as the overall stiffness is
now larger than that of the radiator alone. The total
stiffness now becomes
(18-4)
When a direct radiator having a rear enclosure of
small dimensions is suspended freely in air far from
an external bounding surface, it radiates into all of
space, into a total solid angle of 4π steradians. On
the other hand, if it is positioned on a large plane
surface it radiates into a solid angle only half as
large, namely 2π steradians. In both instances the
radiation load acts only on the exposed face of the
radiating piston. This radiation load is characterized
by what is termed the radiation impedance. This
radiation impedance in the instance of half space
radiation (2π solid angle) is given by
(18-5)
where,
ρ0 is the undisturbed density of air,
c is the speed of sound,
S is the effective piston area,
The expression in the brackets is called the piston
function.
The piston function is obviously complex. If one
lets x represent 2ka where k in turn is 2π/λ then the
real and imaginary parts of the piston function may
be written as
(18-6)
(18-7)
In Eq. 18-6, J1(x) is the first order Bessel func-
tion of the first kind and in Eq. 18-7, H1(x) is the
first order Struve function. The real part of the
piston function is displayed graphically in Fig. 18-2
while the behavior of the imaginary part of the
piston function is exhibited in Fig. 18-3.
It should be noted that at high frequencies where
2ka is large, the piston resistance function
approaches unity whereas the piston reactance func-
tion approaches zero. On the other hand when 2ka is
small, one needs only to retain the first term in the
infinite series description of either R(x) or X(x).
Now if one does this and replaces x by 2ka the result
becomes
(18-8)
and
Kb
γP0S2
V0
--------------
=
K′
K
Kb
+
=
Zr
Rr
jXr
+
=
ρ0cS R 2ka
(
)
jX 2ka
(
)
+
[
]
=
R x
( )
1
2J1 x
( )
x
----------------
–
=
x2
2 4
⋅
----------
x4
2 42 6
⋅
⋅
--------------------
–
x6
2 42 62 8
⋅
⋅
⋅
------------------------------
…
–
+
⎝
⎠
⎜
⎟
⎛
⎞
=
X x
( )
2H1 x
( )
x
------------------
=
4
π
--- x
3
---
x3
32 5
⋅
------------
–
x5
32 52 7
⋅
⋅
----------------------
…
–
+
=
R 2ka
(
)
1
2--- ka
(
)2
≈

350
Chapter 18
(18-9)
It is now possible to obtain a simple expression
for the frequency dependence of the radiation
impedance in the range of frequencies where the
radiated wavelengths are large compared with the
dimensions of the piston radiator. In doing so, it is
necessary to recognize that
(18-10)
where,
λ is the wavelength,
ω is the angular frequency,
c is the speed of sound.
One needs to simply substitute the results of
Eqs. 18-8, 18-9, and 18-10 into Eq. 18-5 to obtain
(18-11)
In the high frequency limit where the wavelength
is small compared with the dimensions of the radi-
ator, the corresponding result is
(18-12)
For intermediate frequencies between the
limiting extremes it is necessary to employ the
complete expression of Eq. 18-5 where numerical
evaluation can be facilitated by extracting values
from the graphs of Figs. 18-2 and 18-3. In all cases,
if the radiator works into a solid angle of 4π
meaning a full space rather than a half space, the
radiation impedance values will be halved because
the acoustic pressure will be only half as large in
this instance.
In order to determine the acoustic pressure
produced by a direct radiator, it is first necessary to
obtain an expression for the piston velocity. This can
be accomplished by solving what is termed the
equation of motion of the direct radiator. The equa-
tion of motion is obtained by writing an expression
for the net force acting on the radiating piston and
equating this to the product of the piston mass with
the piston acceleration as expressed in Newton’s
second law of motion. In the general case this leads
to a second order differential equation. The labor is
greatly reduced by seeking only the steady state
solution while employing only a sinusoidal excita-
tion expressed as a complex exponential function of
time as employed in Chapter 6 Mathematics for
Audio. This procedure will allow the conversion of
the differential equation into an algebraic equation
with the piston velocity being the dependent vari-
able. Under these conditions, the general equation
for the piston velocity becomes
(18-13)
where,
u is the piston velocity expressed as a complex
exponential function of time, i.e., as a phasor,
v is a phasor representing the voltage applied across
the voice coil terminals of the radiator,
Zm is the mechanical impedance of the radiator
which is given by
(18-14)
Practitioners are often faced with the problem of
determining the optimum volume of a simple back
Figure 18-2. Real part of piston function.
Figure 18-3. Imaginary part of piston function.
X 2ka
(
)
8ka
3π
---------
≈
1.2
1.0
0.8
0.6
0.4
0.2
0
R(2ka)
0       2      4       6      8      10    12     14    16   18
2ka
Piston Resistance Function
1.2
1.0
0.8
0.6
0.4
0.2
0
X(2ka)
0       2      4       6      8      10    12     14    16   18
2ka
Piston Reactance Function
k
2π
λ
------
=
ω
c----
=
Zr
ρ0S2ω2
2πc
------------------
jρ08Saω
3π
--------------------
+
≈
Zr
ρ0cS
≈
u
vBl
Re
jωLe
+
------------------------
Zm
B2l2
Re
jωLe
+
------------------------
+
-------------------------------------
=
Zm
Rm
Rr 2ka
(
)
j ωM
Xr 2ka
(
)
K′
ω
-----
–
+
+
+
=

   
Loudspeakers and Loudspeaker Arrays
351
enclosure for a direct radiator. The pursuit of a solu-
tion to this problem is facilitated by examining the
simplifications that occur in Eqs. 18-13 and 18-14
when the operating angular frequency is small. For
this circumstance, ωLe is considerably smaller than
Re and Eq. 18-13 simplifies to become
(18-15)
Additionally, when ω is small, the radiation
impedance takes on the form of Eq. 18-11 and the
mechanical impedance can now be written as
(18-16)
In examining Eq. 18-16 it should be noted that at
low frequencies the effect of the radiation reactance
is to increase the overall mass to a new value M'
with
(18-17)
It is also true that for small ω the radiation resis-
tance is small when compared with the mechanical
resistance so Eq. 18-15 now becomes
(18-18)
Eq. 18-18 exhibits a resonance behavior in that there
exists a particular value of ω called ω0 such that the
denominator of Eq. 18-18 takes on a minimum value
and the amplitude of u takes on a maximum value.
Additionally, when ω = ω0, the denominator is
purely real and the piston velocity is in phase with
the driving voltage. This will occur when
(18-19)
Upon solving Eq. 18-19 we obtain
(18-20)
As is usual the resonance frequency as distin-
guished from the resonance angular frequency is
given by
(18-21)
In describing a resonance, in addition to a speci-
fication of the resonance frequency or angular
frequency, one needs to give an indication of
whether the resonance is well defined and sharp or
whether it is poorly defined and broad. This is done
by a specification of the quality factor or Q of the
resonance. The quality factor in this instance is
referred to as being the total quality factor and is
defined to be 
(18-22)
Now if one were to multiply both the numerator
and denominator of Eq. 18-18 by the quantity
jω/ω02M′, rearrange terms and identify Qt where it
appears, the result will appear as
(18-23)
Upon having the equation for the piston velocity
in hand, it is now possible to write the expression
for the acoustic pressure produced on the axis of the
direct radiator for distances much greater than the
radius a of the radiator. In doing so, it also must be
remembered that this result is valid only at low
frequencies where the wavelength is very much
larger than the radius of the piston.
(18-24)
Eq. 18-24 contains the product of three bracketed
terms. The bracketed term on the left contains the
essential amplitude factors among which is the
amplitude of the applied driving voltage denoted by
u
vBl
Re
--------
Zm
B2l2
Re
----------
+
-----------------------
=
Zm
Rm
ρ0S2ω2
2πc
------------------
j ω M
ρ08Sa
3π
---------------
+
⎝
⎠
⎛
⎞
K′
ω
-----
–
+
+
=
M′
M
ρ08SA
3π
----------------
+
=
u
vBl
Re
--------
Rm
B2l2
Re
----------
j ωM′
K′
ω
-----
–
+
+
-------------------------------------------------------------
=
ω0M′
K′
ω0
------
–
0
=
ω0
K′
M′
------
=
f0
ω0
2π
------
=
1
2π
------
K′
M′
------
=
Qt
ω0M′
Rm
B2l2
Re
----------
+
------------------------
≡
u
jωvBl
ω0
2M′Re
----------------------
1
ω2
ω0
2
--------
–
jω
Qtω0
------------
+
-------------------------------------
≈
p
VmBlρ0S
2πrM′Re
----------------------
ω2
–
ω0
2
---------
1
jω
Qtω0
------------
ω2
ω0
2
--------
–
+
-------------------------------------
e j ωt
kr
–
(
)
[
]
≈

352
Chapter 18
Vm and the axial radial distance between the
observer and the source which is denoted by r. The
bracketed term on the right describes the wave prop-
agation. The middle bracketed complex term
embodies the frequency response of the radiator
including both amplitude and phase information.
The amplitude response of the radiator is given by
the magnitude of the complex quantity in the brack-
eted term in the middle. This magnitude is given by
(18-25)
The smoothest and most flat response is termed
the maximally flat response and occurs when Qt is
assigned the value 
. The behavior of
Eq. 18-25 is exhibited in Fig. 18-4 for three choices
of Qt, including the optimum choice that yields the
maximally flat behavior. The plots are presented in
the form 20  dBlog(Mag) versus log(x) where
x = ω ⁄ω0.
Upon imposing the condition of optimum
response, one learns that
(18-26)
Turn now to the situation that exists when the
direct radiator operates without a back enclosure and
is far from any boundary. Both faces of the radiator
are now operating in free air and each radiates into a
4π solid angle. In this instance, there is a radiation
impedance acting on each face the value of which is
one-half of the former value. There are now two
such impedances so that the total radiation imped-
ance is the same as that for the back enclosed device
positioned on a large plane boundary. The overall
stiffness, however, is just that of the suspension. The
resonance angular frequency is now denoted as the
free air value and is given by
(18-27)
Similarly, the quality factor for the free air reso-
nance appears as
(18-28)
It must be noted that 
(18-29)
and
(18-30)
Two conclusions can be drawn immediately from
Eqs. 18-29 and 18-30. The resonance with a back
enclosure is higher than that of free air and in order
for a direct radiator to be a candidate for application
with an enclosed back, its quality factor when oper-
ating in free air must be less than 0.7071. These
consequences result because in both instances the
multiplying factor is greater than one. Upon setting
Qt = 0.7071 and substituting for K′, Eq. 18-30
becomes
(18-31)
Mag
ω2
ω0
2
--------
1
ω2
ω0
2
--------
–
⎝
⎠
⎜
⎟
⎛
⎞2
ω2
Qt
2ω0
2
-----------------
+
------------------------------------------------------
=
1
2
(
)
⁄
Qt
1
2
-------
=
0.7071
=
ω0M′
Rm
B2l2
Re
----------
+
------------------------
=
K′M′
Rm
B2l2
Re
----------
+
------------------------
=
Figure 18-4. Relative amplitude response for Qt = 2.0
(upper curve), Qt = 0.707 (middle curve), and Qt = 0.2
(lower curve).
10−1 
100 
101
X
10
0
−10
−20
−30
−40
−50
Amplitude Response
Relative Amplitude
ωfa
K
M′
------
=
Qfa
KM′
Rm
B2l2
Re
----------
+
------------------------
=
ω0
K′
K
-----ωfa
=
Qt
K′
K
-----Qfa
=
0.7071
K
γP0S2
V0
--------------
+
K
-------------------------Qfa
=

   
Loudspeakers and Loudspeaker Arrays
353
Eq. 18-31 can now be solved for the required
back enclosure volume to obtain
(18-32)
There are some techniques other than a simple
back enclosure that can be employed to enhance the
low frequency performance of a direct radiator.
These techniques involve the employment of a
vented enclosure or passive radiators. A discussion
of these techniques is given in Section 18-16.
In arriving at the expressions for the acoustic
pressure in the foregoing analyses it must be remem-
bered that the calculations are based on certain
assumptions. The first assumption is that the point of
observation of the pressure is on the axis of the radi-
ator at a distance that is large in comparison with the
radius of the radiator, actually in what is called the
far field. The second assumption is that the frequency
range is that for which 2ka is less than one. In exam-
ining more general cases, one must first explore the
general expression for the acoustic pressure on the
axis of the direct radiator for half space radiation.
Direct Radiator Spatial Response
Fig. 18-5 represents a piston radiating into a half
space. The radius of the piston is a and the overall
frontal surface area is S. The piston undergoes sinu-
soidal motion along the z-axis with a surface
velocity described by ume jωt. If the piston were very
small such that its radius was small compared to the
wavelength for all frequencies for which it is
employed, the acoustic pressure at the observation
point O could be stated simply as
(18-33)
where,
p is the acoustic pressure,
k is 2π divided by the wavelength,
r is the radial distance measured from the center of
the piston,
t is the independent variable time,
ρ0 is the undisturbed density of air,
ω is the angular frequency,
S is the piston area,
um is the piston velocity amplitude.
For the more general case where the piston radius
is of the order of or exceeds the wavelength, it is
necessary to consider the piston’s surface to be made
up of an infinitely large number of infinitesimally
small elements each of which has an infinitesimal
area dS and contributes an infinitesimal pressure dp.
Such an element is depicted in the figure by a black
dot. This element is a distance ρ from the center of
the piston where ρ makes an angle ϕ with the x-axis.
The radial distance from the position of the element
to the observation point O is denoted as r′. The radial
distance from the center of the piston to the observa-
tion point is r and this radial line makes an angle θ
with the z-axis. The total acoustic pressure at the
observation point is obtained by summing the contri-
butions from all elements taking due account of the
fact that the phase of the individual contributions
varies because r' varies as one travels over the
piston’s surface. The general mathematical statement
in its simplest form appears as
(18-34)
The calculation indicated in Eq. 18-34 is
extremely difficult to carry out for the general case.
Fortunately there are two very useful special cases
for which the calculation may be made in closed
form. The first of these yields the acoustic pressure
at all axial points. This calculation yields the
acoustic pressure on the axis that is valid for all axial
distances, all piston sizes, and all frequencies. In this
calculation the angle θ is always zero. The second
special case calculation yields the acoustic pressure
for points on or off the axis that is valid for all piston
sizes and frequencies but is restricted to observation
points which are in the far field. The conditions that
constitute the far field will emerge in the course of
the examination of the first special case.
When one sets θ = 0, Eq. 18-34 takes on the form
V0
γP0S2
K
0.7071
Qfa
----------------
⎝
⎠
⎛
⎞2
1
–
-------------------------------------------
=
p r t,
(
)
jρ0ωSum
2πr
----------------------e j ωt
kr
–
(
)
=
Figure 18-5. Piston radiating into a half space.
O
x
y
ρ
θ
ϕ
z
r'
r
p r θ t
, ,
(
)
jρ0ωum
2π
------------------- 1
r′----e
S∫
j ωt
kr′
–
(
)
dS
=

354
Chapter 18
(18-35)
where,
ϕ is the azimuthal angle in Fig. 18-5.
Eq. 18-35 can be integrated to obtain
(18-36)
The information with regards to the spatial variation
of the acoustic pressure given by Eq. 18-36 is
contained in the term contained within the braces. It is
instructive to plot the magnitude of this term to obtain
the result that is displayed in the following figure.
Fig. 18-6 is plotted by assigning ka a value of 5π,
where ka is the circumference of the piston divided
by the wavelength. This choice was made in order to
clearly delineate three regions of interest. Note that
when r⁄a is ten or above the axial pressure variation
falls inversely with distance. In this region r is much
greater than a and if in addition r is also greater than
S ⁄ λ, then one is in a region that is called the far
field. In this region Eq. 18-36 becomes
(18-37)
On the other hand, if r is much smaller than a and if
ka is considerably smaller than one, then Eq. 18-36
becomes
(18-38)
where,
a is the piston radius.
Equation 18-38 describes the axial acoustic pres-
sure in what is called the extreme near field. If one
divides Eq. 18-37 by Eq. 18-38, one obtains
(18-39)
where,
pf is the far field acoustic pressure calculated by
Eq. 18-37,
pn is the near field acoustic pressure calculated by
Eq. 18-38.
This is a very important result that was first
pointed out by Keele. The quantity e -jkr is a phase
factor whose magnitude is always one, hence
Eq. 18-39 implies that the pressure amplitude in the
far field can be accurately predicted by a near field
pressure amplitude measurement. Furthermore, this
prediction is independent of frequency provided that
true near field measurement conditions are satis-
fied. Near field conditions require that ka be small
compared with one or ka should not exceed about
0.1. Eq. 18-39 is the justification for measuring the
frequency response of low frequency loudspeakers
in the near field. Finally, the region between r
greater than 0.1a and r less than 10a is called the
intermediate field. The pressure maxima and
minima in this region result from interference
effects of radiations emanating from different spatial
zones on the piston surface. This extended region is
thus a poor choice of one in which to perform
frequency response measurements.
Far Field Directivity of a Direct Radiator
When far field conditions are satisfied, the acoustic
pressure on or off of the piston axis is given by the
following integral that sums radiation from all
portions of the piston face while taking proper
account of phase differences.
Figure 18-6. Axial distance pressure variation for a
piston radiator.
p r t,
(
)
jρ0ωum
2π
-------------------
e
jk r2
ρ2
+
–
⎝
⎠
⎛
⎞
r2
ρ2
+
----------------------------- ϕρ
d
ρ
d
0
2π
∫
0
a
∫
=
p r t,
(
)
ρ0ωum
k
---------------- 1
e
jkr
1
a2
r2
-----
+
1
–
⎝
⎠
⎜
⎟
⎛
⎞
–
⎩
⎭
⎨
⎬
⎧
⎫
–
⎩
⎭
⎪
⎪
⎨
⎬
⎪
⎪
⎧
⎫
ej ωt
kr
–
(
)
=
 
Piston Axial Pressure
0 
1 
2 
3 
4 
5 
6 
7 
8 
9 10
r/a
Relative Pressure
2.0
1.8
1.6
1.4
1.2
1.0
0.8
0.6
0.4
0.2
0
p r t,
(
)
jρ0ωSum
2πr
----------------------e j ωt
kr
–
(
)
=
p r t,
(
)
jρ0ωSum
πa
----------------------e jωt
=
pf
pn
-----
a
2r
-----e jkr
–
=

   
Loudspeakers and Loudspeaker Arrays
355
(18-40)
This integration can be carried out in closed form
resulting in
(18-41)
where,
J1 is the first order Bessel function of the first kind.
When one compares Eq. 18-41 which describes
the far field acoustic pressure for arbitrary observa-
tion points with Eq. 18-37 which describes the far
field acoustic pressure for points on the axis of the
radiator, it is found that the two equations differ by
the factor
(18-42)
This factor is called the directivity function. This
function is of the form 2J1(x)/x where J1(x) is the
Bessel function of the first kind and first order. The
behavior of Eq. 18-42 is readily explored in two
ways. Initially, the value of the function is plotted
versus a range of values for the product kasinθ. This
plot is depicted in Fig. 18-7.
Fig. 18-7 indicates several points of interest. It
should be noted that when the angle θ is zero, which
is true for all axial points, the directivity function has
the value of unity regardless of the value of ka. Addi-
tionally, when ka is greater than zero, an increase in
the value of  θ brings about a decrease in the value of
the function meaning that the pressure off axis is less
than the pressure on axis. This means that the radi-
ator has a directional behavior. Finally, there are
regions where the directivity function is negative. A
negative value of the directivity function is an indi-
cation of a polarity change or a phase shift of π. The
directional character of the piston behavior will be
explored through a series of polar plots.
Fig. 18-8A displays the polar plot of half space
radiation as calculated from Eq. 18-42 with a direct
radiator piston radius of 0.1 m (a 10 inch diameter
loudspeaker) at a frequency of 125 Hz. The radial
value in the figure represents the absolute magnitude
of the directivity function on a linear scale. At this
low frequency the directivity is essentially indepen-
dent of the polar angle.
In Fig. 18-8B the operating frequency is now
2kHz. At this frequency the directivity function is
nearly zero when the angle takes on the value of
±π⁄2 or ±90°. At this frequency, the acoustic pres-
sure for points perpendicular to the piston axis is
essentially zero.
As the frequency increases above 2 kHz for this
piston, side lobes begin to form. Fig. 18-8C illustrates
this behavior where the operating frequency is now
4kHz. At a frequency of 4 kHz for this piston, there is
very nearly closure of the first pair of side lobes.
The operating frequency beyond which side
lobes will be formed for a given piston size can be
determined by the following considerations. The
directivity function first becomes zero when kasinθ
takes on the value of 3.83. In order to have at most a
single lobe in the radiation pattern, this value must
occur when the absolute value of sin θ is one, i.e.,
when θ is ±π ⁄ 2. Therefore,
(18-43)
As an example, if a piston of 0.1 m radius is to
have at most a single lobe when c is 344 m ⁄s, then
the maximum operating frequency will be given by
This frequency is approximately that for which
Fig. 18-8B was drawn.
Figure 18-7. Piston far field directivity function.
p r θ t
, ,
(
)
jρ0ωSum
2πr
----------------------e j ωt
kr
–
(
) e jka
θ
sin
ϕ
cos
0
π
∫
sin2ϕdϕ
=
p r θ t
, ,
(
)
jρ0ωSum
2πr
---------------------- 2J1 ka
θ
sin
(
)
kasinθ
------------------------------- e j ωt
kr
–
(
)
=
2J1 ka
θ
sin
(
)
ka
θ
sin
-------------------------------
Directivity Function
1.2
1.0
0.8
0.6
0.4
0.2
0
−0.2 0 
2 
4 
6 
8 
10 
12 
14 
18
ka sinθ
Value of Function
ka
3.83
=
or
f
3.83c
2πa
-------------
=
f
3.83
344
×
2π
0.1
×
-------------------------
=
2096 Hz
=

356
Chapter 18
A useful datum for all radiators is the coverage
angle. In loudspeaker coverage calculations, the
coverage angle is usually defined as the angular
interval between the half pressure points. These are
the points where the pressure response is −6 dB
relative to the pressure on axis.
All piston radiators are non-directional at suffi-
ciently low frequencies and become increasingly
directional as the operating frequency increases and
eventually arrive at the closure of a single lobe at the
maximum frequency calculated according to
Eq. 18-43. It is reasonable to inquire as to the
coverage angle at this frequency. In order to have
just a closed single lobe ka must have the value
3.83. The question to be answered becomes what
value assigned to kasinθ will cause the directivity
function to become 0.5. This value may be extracted
by a close examination of Fig. 18-7 or by consulting
a tabulation of the directivity function. This value is
found to be 2.2. Therefore,
This angle is measured relative to the axis hence the
total coverage angle is twice this value or 70º.
Table 18-2 relates piston size to the maximum oper-
ating frequency that results in closure of a single
lobe yielding a minimum coverage angle of 70°.
Although the foregoing is correct for true
pistonic motion in which all elements of the piston
surface execute axial motion in phase with a
common surface velocity, one must question
whether actual loudspeaker cones mimic this
behavior. This is explored in the next section.
Loudspeaker Cone Behavior
There are several reasons why actual loudspeaker
cones have broader radiation patterns than those
possessed by true pistons. In some instances, special
cone construction techniques are employed which
progressively allow the outer portions of the cone to
decouple from the inner portions as the cone oper-
ating frequency increases.
As an example, a cone of 0.1 m actual radius may
have all portions moving as a unit at 200 Hz. As a
result of decoupling of an outer portion its effective
radius at 2 kHz may be only 0.05 m. By the time
20 kHz is reached, further decoupling may have
reduced the effective radius to 0.015  m. This
behavior is accomplished by molding the cone with
several concentric corrugations or ribs that act as
springs or compliances connecting the various inter-
vening cone sections. Furthermore, the nature of
wave propagation in the cone material itself can
influence the effective radius of the cone. The
internal wave in the cone material begins at the
voice coil-cone juncture and moves through the
material of the cone towards the surround with a
speed governed by the nature of the wave and the
material properties of the cone. There is thus a phase
lag between the radiations emitted by the inner and
outer portions of the cone. This phase lag is insignif-
icant at low frequencies but can produce dips in the
Figure 18-8. Piston directivity at 125 Hz, 2 kHz, and
4kHz.
90
60
30
0
330
300
270
1.0
0.8
0.6
0.4
0.2
90
60
30
0
330
300
270
1.0
0.8
0.6
0.4
0.2
90
60
30
0
330
300
270
1.0
0.8
0.6
0.4
0.2
A. 125 Hz
B. 2 kHz
C. 4 kHz
θ
arc
2.2
3.83
----------
⎝
⎠
⎛
⎞
sin
=
35°
=
Table 18-2. Piston Size as Related to Maximum
Frequency for Single Lobe Pattern
Approximate Diameter
(in)
Piston Radius
(m)
Maximum
Frequency (kHz)
1.0
0.01
21.0
3.0
0.03
7.0
5.0
0.05
4.2
8.0
0.08
2.6
10.0
0.1
2.1
12.0
0.12
1.75
15.0
0.15
1.4

   
Loudspeakers and Loudspeaker Arrays
357
high frequency response of the cone. This internal
wave propagation can also lead to the existence of
complicated resonances in the cone. Resonance
behaviors in cones are generally referred to as “cone
breakup.” In order to obtain some understanding of
these phenomena one must explore the character of
the driving force acting on a typical cone. This situa-
tion is depicted in Fig. 18-9.
Fc in the figure represents the driving force
exerted at the truncated apex of the cone by the
voice coil. This driving force is resolved into the
two components Fl and Ft. Fl is the longitudinal
component of the driving force acting parallel to the
cone’s surface while Ft is the transverse component
of the driving force acting perpendicular to the
cone’s surface. This is better understood by an
examination of Fig. 18-10 in which is displayed an
enlarged drawing of a small element of the cone
attached to the voice coil. This drawing displays not
only the driving force acting on the element but also
the forces acting on the element produced by the rest
of the cone which is beyond the element under
consideration.
In Fig. 18-10A, Fl is the longitudinal component
of the driving force acting on the element while Flc
is the longitudinal component of the force on the
element exerted by the rest of the cone beyond the
element. The result of these forces is to distort the
normal shape of the element, which is shown as
being shaded, into a deformed state displayed as
white. Along the longitudinal direction this defor-
mation is that of compression and produces a wave
motion of the type in which the disturbance is in the
direction of propagation just as is the case for a
sound wave in air. In this instance, however, the
longitudinal wave is in the cone material itself and
has a sound speed determined by the properties of
the cone material. Additionally, the deformation of
the element exerts a stress indicated by the black dot
acting normal to the plane of the drawing. This will
be considered later.
Similarly in Fig. 18-10B, Ft is the transverse
component of the driving force acting on the element
and Ftc is the transverse force acting on the element
exerted by the rest of the cone beyond the position of
the element. These shearing forces deform the shape
of the element transverse to the direction of propaga-
tion of the disturbance. These composite actions,
then, induce both longitudinal and transverse waves
traveling in the cone material from the voice
coil-cone juncture to the outer surround.
Even though the differential equation describing
the propagation of the composite disturbance in the
cone is well known, the solution to the equations is
not. The mathematical complexity presented by this
relatively simple appearing structure is immense.
The solutions are strongly influenced by the cone
shape, the homogeneity or lack thereof of the cone
material, and the boundary conditions that exist at
the voice coil and at the surround. Furthermore, the
wave which travels in the cone is a damped wave,
i.e., its amplitude is attenuated as it travels through
the material of the cone and this disturbance, when it
arrives at the surround, is subject to reflection at this
boundary thus giving rise to standing waves. At
certain resonant frequencies the amplitude of these
standing waves is quite large and becomes one
contributing factor to what is termed cone breakup.
These resonant frequencies or normal modes are
determined by the cone size as well as shape and are
influenced by the properties of the cone material as
well as the surround. These resonant standing wave
modes are called the concentric modes. This type of
undesirable resonant effect is best treated by careful
treatment of the terminating impedance that exists at
Figure 18-9. Driving force acting on a loudspeaker
cone.
FC
FC
F1
F1
Ft
Ft
Axis
Surround
Surround
Figure 18-10. Detail of forces acting on a cone
element.
F1C
FtC
F1
Ft
A.
B.

358
Chapter 18
the surround so as to absorb the wave energy of the
cone rather than reflect it.
Attention is now returned to the stress indicated
by the black dot at A in Fig. 18-10. This stress is
called a hoop stress because of the geometrical
shape of a cone element that is subjected to this
stress. Such an element is formed by slicing the cone
by two parallel planes separated by a small distance
with both planes being perpendicular to the loud-
speaker axis. Hoop stress is the origin of a different
type of modal vibrations in loudspeaker cones. The
resonant modes of hoop stress induced vibration are
referred to as being bell or radial modes.
Radial modes are particularly troublesome in that
they occur at lower frequencies and require smaller
amounts of energy to excite them as compared with
the concentric modes. After an extensive study,
Krüger has evolved a voice coil former, cone, and
surround structure that is almost completely free of
radial modes. Taken together, the resonant modes
lead to what is referred to as coloration as the loud-
speaker will have peaks and dips in the pressure
response as a function of the driving frequency.
Fig. 18-11 illustrates in a plan view of a loudspeaker
cone the lowest order of both the concentric and
radial resonance modes. The shading in the figure
represents motion away from the observer while the
unshaded portion represents motion towards the
observer.
Dome Radiators
Many mid and high frequency devices do not
employ the conical structure at all but rather have
diaphragms that are shaped like domes or partial
hemispheres. This is particularly true with regard to
compression drivers employed with high frequency
horns. Fig. 18-12 is a section view of such a device.
The driving force is applied by the voice coil at
the base of the dome to initiate the acoustical distur-
bance in the material constituting the dome. This
disturbance is communicated to the other parts of
the dome with the speed of sound in the dome mate-
rial. As long as the material has finite stiffness, this
speed also will be finite and just as was the case
with the cone, there is a transmission delay or phase
lag between the various parts of the dome.
For an impulsive type of driving force, the distur-
bance starts out as a wrinkle around the base of the
dome and moves across the dome surface in the
direction indicated by the arrows. The circumfer-
ence of the wrinkle is decreasing as it moves upward
over the dome’s surface, collapses on itself as it
crosses over the dome’s top, and expands again as it
continues across to the other side. This implies that a
disturbance originating on the extreme right in the
figure must be terminated on the extreme left and
vice versa. This means that the surround, which is
attached at the base where the disturbance originates,
must also act as the appropriate absorber for the
disturbance once it has traversed the entire dome’s
surface. Again, just as in the case of the cone shape,
there exists a termination problem. An improper
termination results in wave reflection and introduces
the possibility of resonant standing waves on the
dome’s surface. The behavior of a dome radiator is
thus qualitatively similar to that of a cone differing
only in the degree of participation of the phase lag
and breakup effects. Dome style direct radiators
excel in high frequency applications where their
small size contributes to good angular dispersion.
Modern laser optic based instrumentation now
allows detailed observation of diaphragm motion
regardless of diaphragm shape and thus provides
guidance in the search for improved diaphragm
structures possessing minimal breakup effects.
Phase lag effects will always remain, however,
because of finite wave speed in the cone material.
18.2 Radiated Power
It is a relatively simple task to calculate the power
radiated by a piston type device under sinusoidal
excitation provided that both the piston velocity and
the radiation resistance are known quantities. The
relationships are
Figure 18-11. Lowest order resonance modes.
A. Concentric Mode                      B. Radial Mode
Figure 18-12. Dome radiator.
Dome
Voice coil
Surround

   
Loudspeakers and Loudspeaker Arrays
359
(18-44)
where,
Pr is the average radiated power,
urms is the root mean square velocity,
um is the velocity amplitude,
u is the piston velocity expressed as a phasor,
Rr is the radiation resistance.
The notation |u|2 reads as the square of the abso-
lute magnitude of the phasor representing the piston
velocity. The value of the radiation resistance at any
frequency may be calculated with the aid of
Fig. 18-2. The determination of the piston velocity,
however, is a more difficult problem. In solving this
problem one must return to the basics and inquire
what does a voltage source “see” when driving a
piston-like loudspeaker. This is presented in
Fig. 18-13.
In the figure, Es is the open circuit voltage or emf
of the source, Rs is the source resistance, Re is the
electrical resistance of the voice coil, Le is the elec-
trical self-inductance of the voice coil, and Blu is the
emf induced in the voice coil as a result of its
motion in the magnetic field of the magnetic gap. As
is true of any induced emf, Blu acts counter to the
causative agent which is the current in the voice
coil. As a result of this the expression for the voice
coil current may be written as
(18-45)
The mechanical driving force acting on the voice
coil because of the current is just Bli and the
velocity in the steady state that results from the
application of this force is just the force divided by
the mechanical impedance hence the velocity is
given by
(18-46)
The mechanical impedance at frequencies below
and immediately above driver resonance is
adequately represented by Eq. 18-14. This will need
some adjustment at higher frequencies and will be
so noted where appropriate. When Eqs. 18-45 and
18-46 are solved simultaneously for the piston
velocity, the resulting expression is found to be
(18-47)
The numerator of Eq. 18-47 has the dimensions
of mechanical force or Newtons while the denomi-
nator has the dimensions of mechanical impedance
or kg/s. The quotient of the two has the dimensions
of mechanical velocity or m/s. It is possible to
construct an analogous “mechanical circuit” which
may be analyzed to obtain the result of Eq. 18-47.
Such a circuit appears as Fig. 18-14.
In a purely electrical case, one determines the
circuit current by dividing the applied emf by the
total circuit electrical impedance. Similarly, one
determines the mechanical velocity in this model by
dividing the mechanical force of the generator by
the total mechanical impedance of the “circuit.” It is
instructive to see how this model conforms to the
conditions stated in Eq. 18-47. Obviously, the force
term is the term written adjacent to the generator in
Figure 18-13. The circuit as “seen” by a voltage source
driving a dynamic loudspeaker.
Pr
urms
2Rr
=
1
2---um
2Rr
=
1
2---
=
u 2Rr
Rs
Re
Le
Es
Blu
i
i
Es
Blu
–
Rs
Re
jωLe
+
+
------------------------------------
=
Figure 18-14. Loudspeaker analogous circuit model.
u
Bli
Zm
-------
=
u =
EsBl
Rs
Re
jωLe
+
+
------------------------------------
B2l2
Rs
Re
jωLe
+
+
------------------------------------
R m
Rr
j ωM
Xr
K
Kb
+
ω
----------------
–
+
+
+
+
-----------------------------------------------------------------------------------------------------------------------
Rm
M
Rr
Xr
Kb
1
1
K
u
Le
(Bl)2
(Bl)2
RS
Re
+
RS
Re + jωLe
+
ESBl

360
Chapter 18
Fig. 18-14. How then does one arrive at an expres-
sion for the total mechanical impedance? The
answer lies in the choice of symbols in the model.
The symbol for a resistor is manipulated as one
would do for a resistor in an electrical circuit and
similarly for capacitors and inductance. For
example, consider the parallel combination of resis-
tance and capacitance immediately to the right of
the generator in the figure. The rule is
One needs only to take the reciprocal of the final
term above to obtain
This result is the first term appearing in the
denominator of Eq. 18-47. The remaining terms in
the circuit are series connected and treated as such.
Upon combining the resistive elements one has
The positive reactance terms are inductors and give
a total
The capacitive terms combine as capacitors
connected in series giving
Thus the total capacitance is the reciprocal of the
last term above or
The impedance of such a capacitance is
The total mechanical impedance of the model is just
the sum of all of the individual terms found above.
The addition of these terms yields
This final expression is just the term in the denomi-
nator of Eq. 18-47. The foregoing analysis illustrates
the validity of the model.
The employment of the full model as displayed
in Fig. 18-14 is not always required in order to
obtain useful information. One almost universal
simplification is associated with the appearance of
the source resistance Rs.
Most modern power amplifiers have source resis-
tances that are only a small fraction of an ohm and
hence are considerably smaller than typical voice
coil resistances that are several ohms in size. If the
wiring between the amplifier and the loudspeaker
also represents a fraction of an ohm, then the omis-
sion of the source resistance creates negligible error.
Additionally, depending upon the frequency
range of interest, other simplifications are possible.
For example, in the low frequency range well
below driver resonance where ω is quite small, the
term ωLe is also quite small and can be ignored.
Furthermore, the mechanical impedance repre-
sented by the series connected capacitances is
considerably larger than that of the other elements.
For the purposes of calculating the piston velocity
in this range the greatly simplified model of
Fig. 18-15 can be employed.
Employing Fig. 18-15, the velocity at very low
frequencies is given by,
1
Zt
----
1
ZR
------
1
ZC
------
+
=
1
B2l2
Re
Rs
+
-----------------
------------------
1
jB2l2
–
ωLe
---------------
----------------
+
=
Re
Rs
jωLe
+
+
B2l2
------------------------------------
=
Zt
B2l2
Re
Rs
jωLe
+
+
------------------------------------
=
Rr
Rm
+
jωM
jXr
+
1
Ct
-----
1
1
K----
----
1
1
Kb
------
------
+
=
K
Kb
+
=
K′
=
1
K′
-----
Figure 18-15. Loudspeaker model at very low
frequencies.
ZC
j
–
ωC
--------
=
jK′
–
ω
-----------
=
B2l2
Rs
Re
jωLe
+
+
------------------------------------
Rm
Rr
j ωM
Xr
K
Kb
+
ω
----------------
–
+
+
+
+
Kb
K
1
1
u
ESBl
Re

   
Loudspeakers and Loudspeaker Arrays
361
(18-48)
where,
u is the phasor representing the piston velocity,
Es is the phasor representing the open circuit voltage
of the electrical source driving the loudspeaker.
This equation as it stands gives both amplitude and
phase information. For the purposes of a power
calculation one requires only the absolute magnitude
or amplitude of the piston velocity expressed as
(18-49)
where,
Esm is the open circuit voltage amplitude of the
generator.
The conclusion here is that the velocity ampli-
tude is directly proportional to the angular
frequency. The radiation resistance in this frequency
range is found from
(18-50)
According to Eq. 18-44, then, the average radi-
ated power in this frequency range will be
(18-51)
If one increases the operating frequency in this
range by a factor of two or a span of an octave, the
radiated power will increase by a factor of two
raised to the fourth power or 16. This is a power
increase of 12 dB over a span of one octave hence,
the power curve rises at the rate of 12 dB ⁄octave in
the very low frequency range.
In the range of frequencies immediately below
and immediately above the driver resonant
frequency the significant terms of the model are
different. Here the voice coil inductance and the
radiation resistance can still be neglected in calcu-
lating the velocity. The model now becomes that of
Fig. 18-16.
In making calculations of the velocity in this
frequency range, the radiation reactance Xr
combines with M to become M′ and the two capaci-
tors combine to form 1⁄K′. The velocity is then
found from
(18-52)
As discussed earlier, the velocity in this region
may exhibit a peak, flatten out smoothly and rapidly,
or slowly approach a nearly constant value
depending upon the system total quality factor as in
the earlier discussion. At resonance, of course, the
reactance becomes zero and the average radiated
power at resonance becomes
(18-53)
where,
Qt is the driver total quality factor.
In the intermediate frequency range above reso-
nance, the significant components of the model are
again different. A significant component is one
whose impedance is large enough that it must be
considered in making numerical calculations. The
model in this frequency range has the appearance
presented in Fig. 18-17.
In this frequency range, the impedance of the
mass and radiation reactance are still directly
proportional to the frequency and are much larger
than any of the other circuit impedances. The radia-
tion resistance is still growing as the frequency
squared but is small. The other impedance terms are
constants as is the force of the generator. The net
u
EsBl
Re
-----------
jK′
–
ω
-----------
-----------
=
jEsBl
ReK′
-------------ω
=
um
EsmBl
ReK′
---------------ω
=
Rr
ρ0S2ω2
2πc
------------------
=
Pr
EsmBl 
ReK′
-----------------
⎝
⎠
⎛
⎞
2ρ0S2
4πc
-----------ω4
=
Figure 18-16. Model for frequencies in the vicinity of
driver resonance.
Rm
M
Xr
Kb
1
1
K
u
Re 
ESBl
(Bl)2
RS
Re
+
u
EsBl
Re
-----------
Rm
B2l2
Re
----------
j ωM′
K′
ω
-----
–
+
+
-------------------------------------------------------------
=
Pr
EsmBl
Re
---------------
Rm
B2l2
Re
----------
+
------------------------
⎝
⎠
⎜
⎟
⎜
⎟
⎜
⎟
⎜
⎟
⎛
⎞2
ρ0S2
4πc
-----------ωo
2
=
EsmBl 
ReM′
-----------------
⎝
⎠
⎛
⎞
2ρ0S2
4πc
-----------Qt
2
=

362
Chapter 18
result is that um is proportional to reciprocal
frequency and um2 is then proportional to the square
of the reciprocal frequency. Therefore,
(18-54)
In this frequency range, then, the radiated power
is a constant. Also in this range, one first encounters
the effects of radial and concentric resonant modes
of loudspeaker cones. Break up resonant modes are
not explained by the present model as it is fashioned
after a true rigid piston radiator.
As the high frequency range is approached the
significant components of the model undergo
another shift as displayed in Fig. 18-18.
In this range the effect of the voice coil self-
inductance becomes of importance. In fact, if the
voice coil inductance is large enough such that the
capacitance in the parallel combination is dominant
over the parallel resistance, there exists the possi-
bility of another resonance between the negative
reactance of this capacitance with the positive reac-
tance of the mass inductance and the radiation reac-
tance. Also in this range, the radiation resistance is
ceasing its growth and is approaching a constant
value while the radiation reactance is diminishing.
The resonance, if it occurs, will give a lift and a
peak to the power curve in this region. On the other
hand, if the parallel resistance term dominates over
the capacitive term, this second resonant peak will
not appear and the radiated power will begin to
slowly diminish.
Finally in the high frequency range the inductive
reactance of the force generator becomes much
larger than the voice coil resistance. The impedance
of the capacitance in the parallel combination
becomes quite small and thus approaches being a
short circuit as compared with the parallel resis-
tance. The positive reactance of the mass being
directly proportional to frequency becomes very
large and dominates over other impedance terms.
The radiation reactance has become quite small in
this frequency range and the radiation resistance has
attained a constant value of ρ0cS. Additionally, the
wavelengths are now smaller than the dimensions of
the back enclosure and the piston is now radiating
into the back cavity as well as from its exposed face
so that the model radiation resistance and reactance
must now be doubled. Provision must be made in
the back cavity to absorb this radiant energy through
the employment of a dissipative lining. The useful
acoustic power remains that which is radiated from
the exposed face of the piston. This form of the
model is presented in Fig. 18-19.
An examination of Fig. 18-19 indicates that the
driving force is inversely proportional to the
frequency. The circuit impedance is dominated by
the mass reactance and this term grows linearly with
frequency. The piston velocity depends on the
quotient of the force and the impedance and thus is
inversely proportional to the square of the
frequency. The radiation resistance is now a
Figure 18-17. Significant model features for interme-
diate frequencies above resonance.
Figure 18-18. Significant model features in the near
high frequency range.
Rm
M
Xr
u
Re 
ESBl
(Bl)2
Re
Rr
um
2
1
ω2
------
∝
Rr
ω2
∝
Pr
1
2---Rrum
2
a constant
∝
=
Rm
M
Rr
Xr
u
Le
(Bl)2
(Bl)2
Re
Re + jωLe
ESBl
Figure 18-19. Model in the high frequency range.
Rm
M
2Rr
2Xr
u
 jωLe
ESBl

   
Loudspeakers and Loudspeaker Arrays
363
constant. The radiated power is proportional to the
product of the radiation resistance and the square of
the velocity with the result that the radiated power is
decreasing with the fourth power of the frequency.
This is a rate of −12 dB/octave.
18.3 Axial Sound Pressure Level
The axial sound pressure level in the far field in all
instances is proportional to the product ωum. In the
preceding analysis it was found that in the range
well below driver mechanical resonance that the
velocity was growing linearly with frequency which
means that the pressure is increasing as the square of
the frequency. This implies that the level is growing
at the rate of 12 dB/octave as was true also of the
power. The sound pressure level curve in fact
mimics that of the power level curve everywhere
except in the high frequency range. In the high
frequency range the velocity amplitude is falling as
the square of the frequency. The pressure, however,
depends upon the product of the velocity amplitude
with the frequency. This product is inversely propor-
tional to frequency and thus has a rate of only
−6dB/octave.
Many attribute this departure between the power
curve and the pressure curve to the increasing direc-
tivity of the radiator at high frequencies. This depar-
ture, as shown, depends on the behavior of the
velocity rather than increasing directivity as the
directivity function on axis has a value of unity at all
frequencies. The behavior of both the radiated
power and the axial sound pressure for a driver
optimized for mid bass operation is displayed in
Fig. 18-20.
18.4 Efficiency
A loudspeaker efficiency coefficient is the ratio of
the average acoustical power radiated by the loud-
speaker to the total average power supplied to the
loudspeaker by the driving source. If the average
radiated power is denoted as <Pr> and the average
electrical power supplied by the source is denoted as
<Pe> then the efficiency coefficient η is simply
(18-55)
The efficiency when expressed as a percentage is
this number multiplied by 100. A portion of the
electrical power supplied is wasted as heat in the
voice coil electrical resistance. A further portion
appears as heat in the mechanical resistance of the
suspension. Lastly, a portion of the electrical power
supplied is converted into useful radiated power. It
is possible to express the efficiency coefficient in
terms of the loudspeaker parameters in the following
way. First it is necessary to relate the piston velocity
to the voice coil current. The phasor representing the
piston velocity is given by the quotient of the
driving force with the mechanical impedance of the
loudspeaker.
(18-56)
The term in the denominator of Eq. 18-56 is the
mechanical impedance first presented in Eq. 18-14.
In making power calculations one requires only the
velocity amplitude which is
(18-57)
The denominator of Eq. 18-57 is the magnitude
of the complex mechanical impedance. The average
radiated power is now
(18-58)
If one were to employ the rms value of the
velocity rather than the amplitude, the factor of 1⁄2
would not appear in Eq. 18-58. The average elec-
trical power as stated earlier consists of the sum of
three terms. The first of these terms is the rate of
heat production in the voice coil resistance
(18-59)
Figure 18-20. Mid bass driver calculated power and
pressure responses.
Frequency
101
103
102
0
−1
−2
−3
−4
−5
−6
−7
−8
−9
−10
Mid Bass Driver
Relative Response
η
<Pr>
<Pe>
----------------
=
u
Bli
Zm
-------
=
um
Blim
Zm
-----------
=
<Pr>
1
2---Rrum
2
=
<P1>
1
2---im
2Re
=

364
Chapter 18
The second of these terms is the rate of heat produc-
tion in the mechanical resistance of the suspension
(18-60)
The final term is the average radiated power of
Eq. 18-58. Thus far then, the efficiency coefficient
can be written as
(18-61)
where the common factor of ½ has been dropped in
writing Eq. 18-61.
Finally, upon solving Eq. 18-57 for the current
amplitude and substituting into Eq. 18-61, the final
result appears as
(18-62)
The efficiency coefficient is highly frequency
dependent and reaches its maximum value in the
vicinity of the mechanical resonance of the piston.
The plot of the efficiency coefficient curve of the
mid-bass loudspeaker of Fig. 18-20 appears in
Fig. 18-21.
The maximum efficiency of this particular driver
is just a little over 3%. This low value is not unusual
for direct radiator loudspeakers.
18.5 Loudspeaker Electrical Impedance
The electrical impedance of a loudspeaker when the
cone is clamped preventing cone motion is simply
Re + jωLe. When the cone is free to move, however,
the counter emf induced by the voice coil’s motion
in the magnetic field greatly alters the impedance as
viewed by a voltage source driving the loudspeaker.
The electrical impedance presented to the voltage
source under these conditions is now
(18-63)
This electrical impedance behavior is usually
displayed in the form of a plot of the magnitude of
this complex quantity versus the frequency or log
frequency. Such a theoretical plot for the mid bass
driver of Fig. 18-20 appears in Fig. 18-22.
The maximum on the curve occurs essentially at
the mechanical resonant frequency and is signifi-
cantly larger than the minimum of the curve that
occurs above the mechanical resonance. The
minimum on the curve is usually taken to be what is
called the nominal impedance of the loudspeaker.
The rising impedance at high frequencies is contrib-
uted by the voice coil inductance. If this had been a
measured rather than theoretical curve, the presence
of break up modes would be evident by a series of
small bumps beginning in the vicinity of 400 Hz and
continuing into the higher frequency regions. This
topic is discussed in greater detail in Chapter 8
Interfacing Electrical and Acoustic Systems.
Figure 18-21. Mid bass efficiency coefficient curve.
<P2>
1
2---um
2Rm
=
η
um
2Rr
im
2Re
um
2Rm
um
2Rr
+
+
---------------------------------------------------------
=
η
Rr
Zm
2
Bl
(
)2
------------Re
Rm
Rr
+
+
--------------------------------------------
=
Efficiency Coefficient
Coefficient
Frequency
0.035
0.03
0.025
0.02
0.015
0.01
0.005
0.000
101
104
103
102
Figure 18-22. Loudspeaker electrical impedance.
Ze
Re
jωLe
B2l2
Zm
----------
+
+
=
Loudspeaker Electrical Impedance
Impedance Magnitude
Frequency
101
104
103
102
45
40
35
30
25
20
15
10
5

   
Loudspeakers and Loudspeaker Arrays
365
18.6 Loudspeaker Directivity Factor
Acoustic intensity is a vector quantity that describes
both the magnitude and direction of the instanta-
neous acoustic energy flow per unit area per unit
time. Its direction at any point is the direction of
acoustic wave propagation at that point. The time
average of the magnitude of the intensity, which is
not a vector quantity, can readily be related to the
acoustic pressure at the point in question. In the case
of sinusoidal excitation this relation between the
average intensity and the acoustic pressure is
(18-64)
where,
pm is the amplitude of the sinusoidal acoustic
pressure.
As usual, if one employs the rms acoustic pres-
sure, the factor of 1/2 can be dropped from the equa-
tion. The concept of source directivity can be
applied to any acoustic source regardless of its
shape. The directivity in acoustic work, unfortu-
nately, is usually symbolized by the letter Q. This is
unfortunate in the sense that Q with various
subscripts is also used to denote quality factor which
is an entirely different concept. In words, Q is the
ratio of the average intensity at some point in the far
field of the actual source divided by the average
intensity at the same point that would be produced
by a point source radiating the same total power as
does the actual source. Point sources of course
radiate isotropically. This means the radiation is
uniform in all directions. Q, then, is written as
(18-65)
The variables r, θ, and ϕ define the location of
the point in space where Q is being evaluated rela-
tive to a spherical polar coordinate system fixed in
the source. The symbol <P> represents the average
radiated power. Even though not indicated in the
equation, Q is also a function of the frequency as
both acoustic power and acoustic pressure are
frequency dependent. The term in the denominator
of Eq. 18-65 is the average intensity of a point
source. Both the numerator and denominator of
Eq. 18-65 vary inversely with r2 so Q is independent
of r provided that the evaluation is made in the far
field. If the source is symmetrical about the polar
axis as would be the case for a direct radiator then Q
will depend on the polar angle θ but will be inde-
pendent of the azimuthal angle ϕ. The axial Q of
such a radiator is the value of Q when θ is set equal
to zero. Fig. 18-23 displays the behavior of the axial
Q of a piston radiating into a half space.
In viewing Fig. 23 it should be remembered that
k = ω/c and thus the values of the abscissa are
proportional to the product of the operating
frequency with piston radius and thus are applicable
to all piston sizes. For small values of the abscissa Q
has a nearly constant value of 2. Q begins to grow
when the abscissa exceeds one and becomes quite
large as the abscissa approaches ten or greater.
An often used quantity related to the axial Q is
called the Directivity Index symbolized as DI. The
definition of DI is given by Eq. 18-66.
(18-66)
18.7 Loudspeaker Sensitivity
A specification of loudspeaker sensitivity is a way
of stating what axial sound pressure level will be
produced at a given distance by some standard elec-
trical input to the loudspeaker. The distance most
usually specified is 1 m but that does not mean that
the measurement is made at 1 m. In order to properly
assess the loudspeaker performance the measure-
ment must be made in the far field. If r is the far
field distance expressed in meters, then the pressure
level at 1 m is the pressure level at a distance r plus
the correction which accounts for the inverse varia-
tion of pressure with distance so
(18-67)
<I>
1
2--- pm
2
ρ0c
--------
=
Q θ ϕ
,
(
)
1
2---
pm
2 r θ ϕ
, ,
(
)
ρ0c
-----------------------------
×
<P>
4πr2
--------------
--------------------------------------
=
Figure 18-23. Axial Q of a piston radiator.
ka
10−1 
100 
101
Axial Q of a Piston Radiator
Axial Q
102
101
100
DI
10 dBlog Q
=
Lp @1 m
Lp r( )
20 dB
r
1  m
---------
⎝
⎠
⎛
⎞
log
+
=

366
Chapter 18
The standard electrical input is most often stated
as being an average power of 1 W although the
common practice has become one where the power
supplied is not a true measured watt. What is usually
applied to the loudspeaker is a specified band of
pink noise. The rms voltage of this pink noise is
adjusted so that it would produce an average power
of 1 W in a pure resistance equal to the rated imped-
ance of the loudspeaker. This rated impedance is
somewhat at the discretion of the manufacturer and
may or may not be the nominal impedance of the
loudspeaker as extracted from a measured imped-
ance curve. If the average power as determined
above is different from 1 W the pressure level must
be adjusted according to 10 dBlog(<P>⁄ 1 W).
Therefore if Lp is the sensitivity of the loud-
speaker at 1 m for 1 W, then the far field sound pres-
sure level will be given by
(18-68)
18.8 Direct Radiator Example Calculations
The loudspeaker data employed in the following
calculations unless otherwise pointed out are
extracted from Table 18-1. Additionally, static air
pressure will be taken as 1.013 × 105 pascals, static
air density as 1.2 kg/m3, and sound speed as 344m/s.
1.
What air volume in the back enclosure
employed with this driver will allow maximally
flat response for half space radiation at low
frequencies?
Solution: The governing equation is Eq. 18-32
which contains the unknown term Qfa which in
turn is given by Eq. 18-28. Eq. 18-28 contains
the unknown term M ′ which in turn is given by
Eq. 18-17. Eq. 18-17 then serves as the starting
point.
2.
What is the frequency of mechanical resonance
of this driver when mounted in the back enclo-
sure that yields maximally flat response?
Solution: The governing equation here is
Eq. 18-21 that contains the unknown term K′
which is given by Eq. 18-4. Eq. 18-4 contains the
unknown term Kb that in turn leads to Eq. 18-3.
Eq. 18-3 then serves as the starting point.
3.
Assuming that the driver is appropriately back
enclosed, what is the radiation resistance for half
space radiation at the frequency of mechanical
resonance?
Solution: The governing equation is Eq. 18-50
with ω set equal to ω0.
4.
4. If a 20 Vrms sinusoid is applied to this loud-
speaker at the frequency of mechanical reso-
nance, what will be the axial sound pressure
level at a distance of 5 m?
Solution: One can employ Eq. 18-24 with the
help of Eq. 18-25 to determine either the pres-
sure amplitude or rms pressure. As the voltage is
stated as being rms, its employment will lead to
an rms value of the pressure. Evaluation of the
first bracketed term in Eq. 18-24 yields
Lp r( )
Lp
20  dB
r
1 m 
----------
⎝
⎠
⎛
⎞
10 dB
<P>
1 W
--------------
⎝
⎠
⎛
⎞
log
+
log
–
=
M′
0.03
1.2
(
) 8
( ) π
( ) 0.1
(
)2 0.1
(
)
3π
--------------------------------------------------------
+
=
0.0332
=
Qfa
3000
(
) 0.0332
(
)
2.5
12
(
) 102
(
)
6
-----------------------
+
------------------------------------------
=
0.521
=
V0
1.4
(
) 1.013
105
×
(
)
π
( ) 0.12
(
)
(
)
2
3000
0.7071
0.521
----------------
⎝
⎠
⎛
⎞
2
1
–
----------------------------------------------------------------------------
=
0.0554 m3
=
Kb
1.4
(
) 1.013
105
×
(
)
π
( ) 0.12
(
)
(
)
2
0.0554
----------------------------------------------------------------------------
=
2527  N/m
=
K′
3000
2527
+
=
5527
=
f0
1
2π
------
5527
0.0332
----------------
=
65 Hz
=
Rr
1.2
π
( ) 0.1
(
)2
(
)
2 2π65
(
)2
2π344
-----------------------------------------------------------
=
0.0914 kg/s
=
20
(
) 1
( ) 10
(
) 1.2
(
) π
( ) 0.1
(
)2
(
)
2π 5
( ) 0.0332
(
) 6
( )
-----------------------------------------------------------------------
1.2 Pa
=

   
Loudspeakers and Loudspeaker Arrays
367
Upon setting ω = ω0, the magnitude of the
second bracketed term in Eq. 18-24 becomes
The rms pressure is then the product of these
two or 0.849 pascal. The sound pressure level is
then
5.
What is the efficiency coefficient of this loud-
speaker at the frequency of mechanical
resonance?
Solution: From Eq. 18-16 the mechanical
impedance at resonance is purely real and is just
the sum of the mechanical resistance and the
radiation resistance. The radiation resistance
was calculated in problem 3. Therefore making
use of Eq. 18-62
6.
What is the average power radiated by this loud-
speaker when driven by the 20 V sinusoid at its
frequency of mechanical resonance?
Solution: The axial sound pressure at 5 m found
in problem 4 is 0.849 Pa. The axial intensity at
5m is then
The radiation at this low frequency is isotropic
in a half space hence the average radiated power
is the intensity multiplied by the area of a hemi-
sphere whose radius is 5 m or
7.
What average electrical power must be supplied
to produce the radiated acoustical power of
problem 6?
Solution: The input electrical power is the radi-
ated power divided by the efficiency coefficient.
8.
What are the piston velocity amplitude and the
piston displacement amplitude under the condi-
tions of problem 6?
Solution: The pressure amplitude is the rms
pressure multiplied by 
.
The displacement amplitude is the velocity
amplitude divided by the angular frequency.
9.
The subject back enclosed loudspeaker is now
suspended in space far from any external
bounding surface such that it now radiates into
all of space. What changes now occur in the
operation of the loudspeaker assuming the
applied voltage remains the same?
1
1
1
–
(
)2
1
0.7071
(
)2
-----------------------
+
-----------------------------------------------------
0.7071
=
Lp
20
0.849
2
10 5
–
×
--------------------
log
=
93  dB
=
η
0.0914
2.5
0.0914
+
(
)2
102
------------------------------------- 6
( )
2.5
0.0914
+
+
----------------------------------------------------------------------------------
=
0.0305
=
I
p2
ρ0c
--------
=
0.849
(
)2
1.2
(
) 344
(
)
--------------------------
=
1.75
10 3
–
×
 W/m2
=
P
I 2πr2
(
)
=
1.75
10 3
–
×
(
) 2π52
(
)
=
0.275 W
=
Pe
Pr
η-----
=
0.275
0.0305
----------------
=
9.02  W
=
2
pm
prms 2
=
0.849 2
=
1.2 Pa
=
um
pm2πr
ρ0ωS
----------------
=
1.2 2π
(
) 5
( )
1.2 2π65
(
) π
( ) 0.1
(
)2
-------------------------------------------------
=
2.45 m/s
=
ξm
um
ω
------
=
2.45
2π 65
(
)
-----------------
=
6
10 3
–
×
 m
=

368
Chapter 18
Solution:  The starting point here is the radia-
tion impedance. In going from half space to all
space the radiation impedance will be halved.
This means that M ′ will be a slightly different
value because Eq. 18-17 now becomes
This causes a modest change in the frequency of
resonance.
The driving signal is still at 65 Hz and hence the
loudspeaker is operating slightly below its
present resonant frequency. The change in the
overall mechanical impedance, however, is so
small that the piston velocity and displacement
are changed by only a negligible amount. Even
though the piston velocity is essentially
unchanged the acoustic pressure is reduced by a
factor of two because the radiation now is into a
whole space rather than a half space. The radia-
tion resistance is now half of its former value.
As the piston velocity is essentially unchanged,
the radiated power will track the change in radi-
ation resistance and will become half of its
former value. The efficiency coefficient is also
essentially half of its former value. As a conse-
quence, the required electrical power is changed
by a negligible amount. The fact that the axial
acoustic pressure is halved means that the sound
pressure level is reduced by 6  dB and thus
becomes 87 dB.
10. The back enclosure is now removed from this
driver and the driver is mounted in the center of
a large flat wall that serves as a partition
between two large rooms. Alternatively, the
driver might be mounted in a rigid ceiling
having a large air space above it. What are the
operational conditions of the driver under these
mounting conditions?
Solution: The driver now radiates freely into a
half space on both its front and rear faces. The
radiation impedance acting on each face is given
by Eq. 18-5 and hence the total radiation imped-
ance acting on the driver is just twice that given
by Eq. 18-5. At low frequencies the mass
contributed by the radiation reactance is twice
the former value so that M ′ becomes
Additionally, there is now no stiffness contrib-
uted by a back enclosure so that K ′ is identical
to K. The frequency of mechanical resonance
will now be
The total quality factor as calculated by
Eq. 18-22 has a new value.
The new total quality factor is less than the
optimum value of 0.7071 so that the low end
response is no longer maximally flat. It is
possible to raise the quality factor by connecting
additional resistance in series with the voice coil
thus making Re appear to be larger. If a resistor
of 2.14 Ω is added in series with the loudspeaker
thus making Re appear to be 8.14Ω , the total
quality factor will become the optimum value
for maximally flat response. The adverse effect
of raising the total quality factor in this fashion
is the significant reduction that occurs in the
efficiency coefficient.
18.9 Horns and Compression Drivers
Horns play two fundamental roles in acoustics.
Firstly, they are directional control devices serving
to guide the airborne acoustic energy into particular
M′
M
ρ04Sa
3π
---------------
+
=
0.03
1.2 4
( ) π
( ) 0.1
(
)2 0.1
(
)
3π
----------------------------------------------------
+
=
0.0316 kg
=
f0
1
2π
------
K′
M′
------
=
1
2π
------
5527
0.0316
----------------
=
66.6 Hz
=
M′
M
2ρ08Sa
3π
-------------------
+
=
0.03
0.0064
+
=
0.0364
=
f0
1
2π
------
K
M′
------
=
1
2π
------
3000
0.0364
----------------
=
45.7 Hz
=
Qt
ω0M
Rm
B2l2
Re
----------
+
------------------------
=
2π 45.7
(
) 0.0364
(
)
2.5
100
6
---------
+
--------------------------------------------
=
0.545
=

   
Loudspeakers and Loudspeaker Arrays
369
directions or regions and as such they might well be
called waveguides. The familiar plane wave tube
may well be considered to be a special case of a
horn as it certainly constitutes a waveguide.
Secondly, horns act as impedance matching devices
similar to the action of an electrical transformer.
Horn surfaces define a bounded region whose
cross-sectional area increases from the input to the
output in a loudspeaker application. The acoustic
power flowing through a cross section of area S,
when the acoustic pressure and particle velocity are
in phase, is the product puS. The product uS is called
the volume velocity and is denoted by U therefore
the acoustic power flow is pU. At the input end of
the horn where S is small and the acoustic pressure p
is large, the volume velocity for a given acoustic
power is small.
At the output end of the horn where S is large, the
volume velocity is large and the acoustic pressure is
small for the same acoustic power. This behavior is
analogous to an electrical step down transformer
that has a large voltage and small current in the
primary and a small voltage and large current in the
secondary.
Horns were used in acoustics long before their
principles of operation were even partially under-
stood. The earliest hearing aid devices were based
on horns with sound transmission in the reversed
sense in that the object was to convert large U and
small p into large p with small U to accommodate
the fact that the ear is a pressure sensitive organ.
Some of the earliest acoustic recordings also
employed horns operating in reverse with the mouth
of the horn collecting energy over a large area and
concentrating it into a small area to actuate a small
diaphragm mechanically coupled to a recording
stylus. This procedure was reversed in the reproduc-
tion process wherein the horn was employed in the
more conventional sense.
Horns have also been employed as the basis of
many musical instruments. The requirements of a
horn to be used for sound generation are radically
different from that of sound reproduction or rein-
forcement. In the case of sound generation, reso-
nances in the horn are desirable and in fact,
essential. In sound reproduction or reinforcement,
however, resonances are undesirable and steps must
be taken to minimize their existence. This under-
scores the necessity for having an underlying theory
of horn operation to guide the construction for
various applications.
Horn theory stems from the original work of
Euler, Lord Rayleigh, and Webster. Webster was the
first to introduce the concepts of specific acoustic
impedance and analogous acoustic impedance, both
of which have proven to be very valuable in acoustic
analysis. What is known as Webster’s horn equation
is a wave equation that in the strictest sense is
correctly applicable to only three waveguide struc-
tures. These are the plane wave tube, the conical
horn, and the cylindrical horn. Webster’s equation
employs only a single space variable in the axial
direction implying that the acoustic pressure is
uniform over an appropriately drawn cross section
of the guide or horn structure. This is satisfied
exactly in a plane wave tube of limited diameter that
is excited at the input by a plane wave.
The equation is also exact for a conical horn that
is excited with a spherical wave and for a cylindrical
horn that is excited by a cylindrical wave. The appli-
cation of the equation to other horn structures is
only approximately correct and then only when the
horn opens up or flares very slowly. It is this last
requirement that is often lost sight of in practice.
The simplest horn geometry is that of a trun-
cated cone wherein acoustic energy in the form of a
diverging spherical wave is introduced into the
small end of the cone and subsequently propagates
freely within the cone as an outgoing wave as
suggested in Fig. 18-24.
In order for this horn to work properly, the
acoustic wave introduced at its small or throat end
must have a radius of curvature equal to r0, where r0
is measured from the virtual apex of the truncated
cone. The “natural fit” means that the spherical
wavefronts diverging from the apex would every-
where be normal to the bounding surface provided
by the cone and all energy flow would be radially
directed. The particle velocity in such a wave
motion would be tangent to the interior walls of the
Figure 18-24. A spherical wave has a natural coordi-
nate fit in a conical horn.
r0

370
Chapter 18
horn and there would be no reflections at the interior
wall surface. Internal reflections occur when the
particle velocity has a component normal to an inte-
rior wall surface. Plane waves, as another example,
form a natural fit in a straight tube of constant cross
section. In both instances the wave motion can be
described using only a single spatial coordinate and
as such are called single parameter waves. A third
geometry that provides a natural fit is that of a horn
formed from a sector of a cylinder. Here, however,
the wave introduced at the throat must have a cylin-
drical wavefront. So far as is presently known these
three geometries are the only ones that satisfy the
natural fit or single parameter conditions exactly.
As a straight tube of constant cross section of
course is not a horn in the strictest sense, that leaves
only two natural horns. Many other horn shapes
have been employed with varying degrees of
success, however, but they are only approximately
single parameter devices and all suffer from
bounding wall reflections to a greater or lesser
degree. An analysis by Morse concludes that in
order for a horn shape to approximately fall under
the conditions necessary to satisfy Webster’s horn
equation, the rate of change of the square root of the
cross-sectional area with respect to the single axial
parameter must be much less than one. To what
degree some common horns satisfy or fail to satisfy
this criterion is a point worthy of examination.
Webster’s equations for single parameter horns
are
(18-69)
In these equations χ is the appropriate single
space variable and the other symbols have their
usual meanings. The area symbol S must be treated
carefully. In a true one parameter horn it is the
surface area of the appropriately shaped wavefront
as a function of position. In other horns the assump-
tion is made that the wavefronts are approximately
plane and S is the true cross sectional area of the
horn as a function of position.
The first of Eq. 18-69 when applied to the
conical horn becomes just the spherical wave equa-
tion. The second of these equations allows the deter-
mination of the specific acoustic impedance at the
throat of the horn. The specific acoustic impedance
is the ratio of the complex acoustic pressure to the
complex particle velocity. The mechanical imped-
ance is thus the product of the specific acoustic
impedance with the wavefront area S. With a suit-
able horn driver, these expressions are identical to
those of a pulsating sphere of radius r0 with the
exception that all of the energy diverges through the
horn rather than through the surface area of a sphere
of radius r0. The sound intensity on the axis of the
horn is thus increased by the ratio of the area of the
sphere to the wave entrance area of the horn. This
ratio is 
 where θ is the angle between
the horn axis and the interior surface of the horn.
For example, if the coverage angle of the horn is
40º, θ is 20º and this ratio is 33.16. This number is
identical to the axial Q of the horn. This corresponds
to a pressure level increase of about 15 dB on the
axis of the horn as compared with that produced by
a pulsating sphere without the aid of a horn. Thus
far the horn has been treated as if there were only an
outgoing wave. This would strictly be true if the
horn were infinitely long. For any horn of finite
length a reflection will occur at the mouth and a
portion of the original energy will be directed along
the horn back towards the driver. Such reflections
can lead to the production of standing waves having
resonant frequencies related to the horn length. It
has been found in practice that there is only a negli-
gible mouth reflection if the mouth perimeter is
about 3 times the free space wavelength at the
frequency of operation. Horns intended for use at
low frequencies are thus large, unwieldy devices.
Salmon has described a family of horns that can
have approximately single parameter behavior when
they flare slowly enough. Members of this family
are described by
(18-70)
S0 is the cross-sectional area at the throat where χ
is 0. A scale factor denoted as h is indicative of the
rapidity of flare with small values of h corre-
sponding to rapid expansion. T is a shape factor
determining the general properties of the horn near
the throat. When T = 0, Eq. 18-70 generates a
catenoidal horn. When T = 1, an exponential horn
results. When T = h/χ0 and is allowed to approach ∞
by letting h become very large, a conical horn
results. Each of these horns merits individual atten-
tion. The descriptions given in each instance assume
the horn is long enough so that mouth reflections
can be ignored.
Conical Horn
No approximations are involved in the conical horn
provided that it is excited at its throat by a spherical
1
S---
∂S∂p
∂χ
------
⎝
⎠
⎛
⎞
∂χ
-------------------
×
1
c2
----- ∂2p
∂t2
--------
=
∂u
∂t
------
1
ρ0
-----
–
 ∂p
∂χ
------
=
2
1
θ
cos
–
(
)
⁄
S
S0
χ
h 
----
⎝
⎠
⎛
⎞
cosh
T
χ
h 
----
⎝
⎠
⎛
⎞
sinh
+
2
=

   
Loudspeakers and Loudspeaker Arrays
371
wavefront. If mouth reflections are ignored the
equations are
(18-71)
In these equations, r is measured from the throat
and r0 is the distance from the virtual apex of the
cone to the throat of the horn. It should be observed
from Eq. 18-71 that the acoustic pressure varies
inversely with distance from the virtual apex of the
horn and the phase velocity in the horn is just c.
Horns are often compared in terms of their transmis-
sion coefficient. The transmission coefficient, τ, is
defined to be the ratio of the real part of the throat
specific acoustic impedance to the specific acoustic
impedance of air for plane waves, this latter value
being just ρ0c. The transmission coefficient
behavior for a conical horn is displayed in
Fig. 18-25.
Conical horns transmit at all frequencies and thus
do not possess a characteristic cut off frequency.
Unfortunately, however, the transmission coeffi-
cient is small at low frequencies. The pressure atten-
uation in the horn is the same as that for a spherical
wave in free space being a drop of 6 dB for each
doubling of distance traveled in the horn.
Cylindrical Horn
A cylindrical horn is constructed by taking a sector
from a cylinder of large radius and truncating it at
some smaller radius r0 from the axis of the cylinder
so as to provide a throat opening. The top and
bottom plates of the horn are flat and separated by a
constant distance. The nominal coverage angle of
the horn is the angular opening between the vertical
plates. The difficulty with this type of horn is the
necessity of providing uniform cylindrical wave
excitation over the entire throat area. If mouth
reflections are ignored the equations are
(18-72)
The transmission characteristics of a cylindrical
horn are identical to those of a conical horn and thus
such a horn does not exhibit a cut off frequency. The
pressure attenuation within the cylindrical horn, as
is true of cylindrical waves in general, is only 3 dB
per doubling of distance traveled within the horn.
Plane Wave Tubes
Plane wave tubes are used as acoustic delay lines
and as aids in testing compression drivers. A plane
wave tube is a straight tube of constant diameter d.
Such a structure will support only plane waves
provided that the frequency of excitation is less than
0.586(c ⁄d). If the exciting frequency exceeds this
limit, non-planar dispersive modes can be excited in
the tube. This limit corresponds to about 8000 Hz for
a one inch diameter tube. A semi-infinite plane
wave tube would be one which extends along the
x-axis say from x = 0 to x = ∞. Such a tube, when
properly excited at x = 0, would only support a wave
traveling in the direction of increasing x and thus
there would be no reflections. Under these
S
S0 1
r
r--
0
+
2
=
p
p0
1
r
r0
----
+
--------------
e
j ωt
ω
c----r
–
⎝
⎠
⎛
⎞
×
=
Z0
ρ0c
1
1
c
ωr0
---------
2
+
--------------------------
j
c
ωr0
---------
1
c
ωr0
---------
2
+
--------------------------
+
 
=
Figure 18-25. Transmission coefficient for a conical
horn.
S
S0 1
r
r--
0
+
=
p
p0
1
r
r0
----
+
1
2---
----------------------
e
j ωt
ω
c----r
–
⎝
⎠
⎛
⎞
×
=
Z0
ρ0c
1
1
c
ωr0
---------
⎝
⎠
⎛
⎞2
+
--------------------------
j
c
ωr0
---------
1
c
ωr0
---------
⎝
⎠
⎛
⎞2
+
--------------------------
+
=
0 
1000 
2000 
3000 
4000 5000
Frequency
Typical Conical Horn Transmission
1.0
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
Transmission Coefficient

372
Chapter 18
conditions, the specific acoustic impedance at the
origin of the tube would be just ρ0c and the mechan-
ical impedance presented to a driver would be ρ0cS
where S is the planar cross-sectional area of the
tube. Thus, in order to make a tube of finite length
appear to be infinite, it must be terminated by a
material which has a specific acoustic impedance
matching that of air. There are several materials that
closely match this requirement including certain
grades of fiberglass and acoustic foam. Gradually
tapered wedges of such materials usually terminate
those plane wave tubes that are intended to be
reflection free. The acoustic pressure attenuation in
such plane wave tubes depends on the viscous
effects of air and is negligible at the frequencies for
which such tubes are normally employed. The trans-
mission coefficient of such tubes is thus unity at all
frequencies. The equations for such a tube are
(18-73)
When a plane wave tube of finite length is termi-
nated in a manner which is not reflection free, the
mechanical impedance presented by the tube at
x = 0 depends on both the mechanical impedance at
the termination, ZL, and the length of the tube, L. In
this instance the mechanical impedance at x = 0 is
denoted as Z0 given by
(18-74)
Two special applications of Eq. 18-74 occur
quite often in practice. Often the tube is terminated
by a rigid wall in which instance the particle
velocity at the barrier is zero and the mechanical
impedance at x = L is then infinite. When ZL is ∞, Z0
becomes
(18-75)
In all instances k = ω ⁄c = 2π ⁄ λ. When the tube is
left open at x = L, ZL becomes the complex radiation
impedance of a piston of diameter equal to that of
the tube with the piston radiating into all of space.
From Eq. 18-74, if L = nλ ⁄ 2 with n equal to any
integer, the tangent terms are identically zero and
the mechanical impedance presented by the tube is
equal to the termination impedance. An open-ended
tube satisfying the half wavelength condition, then,
presents a mechanical load to its driving generator
equal to the radiation resistance and reactance of a
direct radiator whose diameter is equal to that of the
tube. If there were some way to cancel the radiation
reactance, all of the energy supplied by the gener-
ator would be radiated acoustically at the end of the
tube. This is indeed possible.
A close examination of Eq. 18-74 reveals that if
the tube length is only slightly less than that speci-
fied by the half wavelength criterion, then the tube
itself will supply the negative reactance necessary to
cancel the positive radiation reactance at its end.
Under this circumstance the driving generator will
see only the radiation resistance presented by the
open end. This would constitute the resonant condi-
tion for an open-ended tube. Finally, notice from
Eq. 18-75 that if L = nλ ⁄ 4 where n is an odd integer
then the cotangent is zero and the mechanical
impedance of the tube becomes zero and the tube
can be driven freely at those frequencies for which
this is true. This constitutes the resonance condition
for a closed end tube.
Catenoidal Horn
The catenoidal horn has a behavior that is quite
interesting. In the absence of reflections the equa-
tions are
(18-76)
Firstly, this horn exhibits a cut off frequency
fc = c ⁄ 2πh below which true wave motion in the
horn ceases to exist. Secondly, unless the operating
frequency is well above the cutoff frequency, the
phase velocity in the horn is frequency dependent
and thus suffers envelope distortion for complex
waveforms. A favorable point, however, is that
above cut off, the specific acoustic impedance,
S
a constant
=
p
p0e
j ωt
ω
c----x
–
⎝
⎠
⎛
⎞
=
z0
ρ0c
=
Z0
ρ0cS
1
ZL
ρ0cS 
-------------
+
⎝
⎠
⎛
⎞1
j
kL
[
]
tan
+
(
)
1
ZL
ρ0cS 
-------------
+
⎝
⎠
⎛
⎞1
j
kL
[
]
tan
+
(
)
-----------------------------------------------------------------
=
1
ZL
ρ0cS 
-------------
–
⎝
⎠
⎛
⎞
–
1
j
kL
[
]
tan
–
(
)
+ 1
ZL
ρ0cS 
-------------
–
⎝
⎠
⎛
⎞1
j
kL
[
]
tan
–
(
)
--------------------------------------------------------------------
Z0
jρ0cS
kL
(
)
cot
[
]
–
=
S
S0cosh2 x
h 
----
⎝
⎠
⎛
⎞
=
p
p0
x
h 
----
⎝
⎠
⎛
⎞
cosh
----------------------e
j ωt
ω
c----
1
c
ωh 
---------
⎝
⎠
⎛
⎞2
–
 x
–
⎝
⎠
⎜
⎟
⎛
⎞
=
Z0
ρ0c
1
c
ωh 
---------
⎝
⎠
⎛
⎞2
–
------------------------------
=

   
Loudspeakers and Loudspeaker Arrays
373
though frequency dependent, is purely real.
Additionally, the slope of the horn walls at the horn
throat is zero and this forms a good match to a plane
wave tube when the horn is operated well above its
cut off frequency. This horn should always be oper-
ated well above cut off as the specific acoustic
impedance at the throat is infinite at the cut off
frequency.
Exponential Horn
The exponential horn is a time-honored device. It
performs at its best when the cut off frequency is
chosen to be well below the lowest frequency at
which the horn is intended to be employed.
Neglecting reflections, the equations are
(18-77)
An exponential horn also exhibits a cut off
frequency of fc = c/2πh. Below the cut off frequency,
the throat specific acoustic impedance is purely reac-
tive while above cut off it is part resistive and part
reactive. In the transmission band above cut off, the
phase velocity is frequency dependent becoming less
so as the frequency increases above cut off. It is thus
desirable to operate the horn well above cut off in
order to reduce group delay distortion and increase
transmission. Additionally, the horn comes closer to
satisfying the Morse criterion if the cut off frequency
is chosen to be very low thus making h large and
producing a slowly expanding cross section. Unfor-
tunately, with high throat pressures the non-linear
distortion produced in the air is exacerbated by a
slowly flaring horn. As is true in many design areas
involving loudspeakers, one is often faced with
diametrically opposed requirements and compro-
mises must be made. The transmission coefficient for
an exponential horn appears in Fig. 18-26.
If one were to apply the Morse criterion to most
commercial horns for determining if a given horn
structure satisfies the conditions necessary for
Webster’s equations to be valid, the results would
be a cause of great dismay. Recall the Morse crite-
rion requires the rate of growth of the square root of
the cross-sectional area with distance must be much
less than one. With the possible exception of a
single cell in a multi-cellular horn having a very low
cut off, none of the common exponential horns
come even close to satisfying the slowness of
growth criterion. This does not mean that the horns
do not work. It simply means that the solutions of
Webster’s equations do not adequately describe how
they work. The actual wave motion in the horn is
much more complex than is assumed and involves a
variety of modes as well as internal reflections.
With the exception of the cylindrical horn, all of
the early horns were figures of revolution about the
principal horn axis and thus had circular cross
sections. This is not a necessary constraint as the
required area growth with distance within the horn
can be obtained with other cross sectional shapes.
Most modern horns have rectangular cross sections
so as to produce coverage patterns that are wider
horizontally than vertically. This shape more nearly
conforms to the general audience-seating pattern.
Most if not all horn drivers have circular exit aper-
tures which means that horns that are ultimately
rectangular must be circular at the throat and hence
must include a smooth transitional section. If the
horn walls near the mouth are to approximately
determine the coverage angles of the horn, however,
very narrow mouths are to be avoided as mouth
diffraction will greatly broaden the coverage angle
in what was to be the narrow direction.
Horns and horn drivers cannot be treated as
separate entities without the payment of penalties in
the resulting overall performance. For example, a
cylindrical tube needs to be driven by a piston as
does a catenoidal horn whereas a conical horn
requires spherical excitation. If the chosen driver
does not supply the excitation that matches the horn
throat, a reflection will occur at the juncture of the
horn throat with the driver. Additionally, in many
compression drivers, area expansion begins within
the phase plug of the driver. In effect then, the horn
actually begins in the phase plug. The point is that
S
S0e
2x
h------
=
p
p0e
x
h---
–
e
j ωt
ω
c----
⎝⎠
⎛⎞2
1
h 
----
⎝
⎠
⎛
⎞2
–
x
( )
–
⎝
⎠
⎜
⎟
⎛
⎞
=
zo
ρ0c
1
c
hω 
---------
⎝
⎠
⎛
⎞
2
–
j c
hω
-------
+
=
Figure 18-26. Transmission coefficient of a 125 Hz
exponential horn.
0 
1000 
2000 
3000 
4000 
5000
Frequency
Typical Exponential Horn Transmission
1.0
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
Transmission Coefficient

374
Chapter 18
the driver and the horn with which it is to be used
should be designed as a system rather than as
separate entities.
All of the horns so far, other than conical and
cylindrical, exhibit behavior that departs from that
predicted by the simple theory particularly at higher
frequencies. As long as the wavelength is large
compared with the horn diameter of the horn at any
point, the conditions required by the simple theory
are approximately satisfied and operation is close to
prediction. When the wavelength becomes compa-
rable to or less than the horn diameter at any point
the wave will no longer fill the entire horn cross
section and the beam width is no longer determined
by the horn geometry. This is a diffraction-related
phenomenon in which the acoustic energy is
concentrated in an increasingly narrower lobe about
the horn axis as the frequency increases. The
coverage angle of such a device narrows as the
frequency is increased. This behavior has been
circumvented in recent years by a different horn
design technique that leads to a horn having a more
nearly frequency independent coverage pattern.
Constant Directivity Horns
A constant directivity horn is a hybrid design incor-
porating aspects from several other horn types. A
typical design begins with a throat section having an
exponential taper with a cut off frequency well
below the lowest operating frequency for which the
horn is to be employed. This assures an adequate
acoustic load for the horn driver. This throat section
furnishes additionally a smooth transition from a
circular cross section to a skinny rectangular cross
section such that the exit from the throat section is in
the form of a slot.
The wave fronts in the interior of the throat
section have very little curvature. When these waves
encounter the slot two different events occur. A
portion of the wave is reflected back towards the
driver as the exit from the throat section represents a
discontinuity in the wave medium. The portion of
the wave which emerges from the slot undergoes
diffraction at the edges of the slot and emerges as a
diverging wave such that the wavefront has a small
radius of curvature in a plane perpendicular to the
length of the slot and a larger radius of curvature in
a plane parallel to the length of the slot.
The diverging wave is allowed to expand into a
bounded region whose cross-sectional area expands
conically except that the horizontal angle is greater
than the vertical angle so as to match the differing
radii of curvature formed at the slot. Wave propaga-
tion in the expanding conical section is well
behaved as the horn walls provide a reasonable
match for the diverging wavefronts. The wavefronts,
of course, are astigmatic by virtue of the differing
radii of curvature in the horizontal and vertical
planes. With a sufficiently large mouth, the horn
coverage angles will be independent of frequency up
to a limit where the wavelength becomes compa-
rable to the width of the slot. Beyond this limit the
horn will begin to beam. In spite of the constant
directivity property, horns of this type have two
distinct and serious drawbacks. The internal reflec-
tion that occurs at the diffraction slot gives rise to
standing wave production with associated reso-
nances occurring in the throat section. The astigma-
tism associated with the emerging wavefronts from
the horn implies separated sources of sound rather
than a single point source, as would be the case for a
purely spherical wavefront. This makes it difficult to
combine two or more horns so as to have enlarged
coverage. Such horns require one placement for a
horizontal combination and a completely different
placement for a vertical combination.
Horn theory is still a work in progress. In the mid
1970s Benade described the wave motion in
axi-symmetric horns of conventional shapes in
terms of spherical waves possessing both radial and
axial modes. A large body of experimental measure-
ments illustrating the usefulness of this approach
accompanied his theoretical work. Recently Geddes
has proposed new horn shapes based on oblate
spherical coordinates.
18.10 Practical Considerations Involving 
Horns
Horns are seldom employed as single stand alone
devices except in simple paging systems. More often
they are employed as mid or high frequency devices in
conjunction with vented enclosure type low frequency
direct radiator devices in forming a full range loud-
speaker. Additionally, they are often employed in
large two-way systems where they are arrayed either
to increase coverage or pressure level or both. In this
instance, low frequency support is provided by a sepa-
rate array of low frequency devices.
In the early 1980s a full range loudspeaker
design was introduced that at low frequencies
performed as a vented enclosure, in the mid frequen-
cies was loaded by a large mouth horn, and for the
high frequencies featured a co-axially mounted high
frequency horn located in the interior of the mid
frequency horn. The coverage angles, acoustic
origins, and acoustic centers of the horns were
similar enough that the combination acted as a
single device and thus could be readily arrayed with
similar devices. Since that time many manufacturers

   
Loudspeakers and Loudspeaker Arrays
375
have developed similar full range loudspeakers. The
current trend is to build arrays based on such full
range devices. In developing and subsequently
arraying such devices knowledge of common horn
properties must be available. These properties are
sensitivity, directional Q, acoustic origin, acoustic
center, loudspeaker efficiency, and polar response.
Sensitivity, Q, and efficiency have been defined
previously. The other terms require definition and
further discussion.
If one measures the impulse response of a loud-
speaker at some remote point in space, it is found
that a finite time elapses between the application of
the loudspeaker excitation and the reception of the
response. This time interval is called the transit
time. The product of the transit time with the value
of the speed of sound that prevails under the condi-
tions of measurement defines a distance.
When this distance is projected from the
observing microphone towards the loudspeaker
along the loudspeaker axis, the terminus of this
projection defines a point in space from which the
signal appears to originate. This point is called the
acoustic origin. On the other hand, the acoustic
center is the point in space from which the spherical
wavefronts appear to diverge as observed in the far
field. Fig. 18-27 illustrates the location of these
points for a variety of horns.
In viewing Fig. 18-27, it should be observed that
only the cylindrical and conical horns have co-inci-
dent locations for both the acoustic origin and
acoustic center.
The polar response of a loudspeaker, whether the
loudspeaker is a full range system or an individual
device, is a quantitative way of describing the loud-
speaker’s directional characteristics. It is in effect a
radiation pattern. One is accustomed to viewing
manufacturer’s condensed specification sheets
wherein one often encounters what are called hori-
zontal and vertical polars. Such plots are useful but
by no means do they constitute a complete descrip-
tion of a device’s directional characteristics.
In order to obtain a complete description it is
necessary to make an extensive series of measure-
ments in the far field of the device. In making these
measurements, it is necessary to excite the device
with various bands of pink noise as the polar
response is frequency dependent. Additionally, pres-
sure level observations must be made versus the
angular orientation of the device. The angles
involved are the axial angle that measures rotation
about the device’s principal axis and the azimuthal
angle that measures rotation about the device’s
acoustic center. These rotations are illustrated in
Fig. 18-28.
There is not a unique procedure that must be
followed in making polar measurements. What will
be described is a possible procedure that will accu-
mulate the required data. The measurement session
starts with both the axial and azimuthal angles set at
zero with the measuring microphone located on the
principal axis of the device in the far field. One then
excites the device sequentially with the pertinent
bands of pink noise. These noise bands should be no
wider than one octave.
The pressure level on axis for each noise band is
separately recorded. The device is then rotated about
the azimuthal axis through a fixed angular increment
such as five degrees. Again the sequence of noise
bands is applied with the corresponding pressure
levels being recorded. The azimuthal angle is again
incremented and the pressure levels are recorded
appropriately.
One proceeds in this fashion until the device is
swept through one complete revolution about the
acoustic center. What results are the horizontal
polars. Now starting again with the azimuthal angle
Figure 18-27. Typical locations of acoustic origins and
acoustic centers.
Exponential
CD Horizontal
CD Vertical
Conical & Cylindrical
Legend
       Acoustic Origin
       Acoustic Center
Figure 18-28.  Rotational axes for polar measurements.
Axial Rotation
Azimuthal Rotation

376
Chapter 18
back at zero degrees, one now increments the axial
angle by a fixed increment such as five degrees and
then repeats the previous set of observations
wherein the azimuthal angle is again swept through
a complete revolution. At the conclusion of this
second sweep, one again increments the axial angle
by an additional five degrees. Again one makes
observations as the azimuthal angle is swept through
one complete revolution. This process continues
until the axial increments total 90° for a device that
has mirror symmetry in a plane containing the
principal axis.
For other devices, the process must continue
until the axial increments sum to 180°. The sweep
where the axial increments sum to 90° generates the
vertical polars. The pressure levels thus obtained
usually are normalized to the values obtained on the
principal axis with zero azimuth and zero axial
angles. For each band of pink noise, one arrives at
an m by n array of pressure values where m is the
number of azimuthal angle positions and n is the
number of axial angle positions. These values
constitute the polar response at least to the precision
that is set by the size of the angular increments
employed. Polar response data in this or similar
form is required for use in computer generated loud-
speaker coverage plots.
The foregoing procedure suffers in two respects.
Firstly, only magnitude response data is accumu-
lated and secondly, the measurement microphone
must truly be in the far field for accurate results.
Most facilities with the controlled environments
necessary for unperturbed measurements are not
large enough to allow far field measurements on
large devices at high frequencies. Measurements in
such facilities are usually made at distances in the
transition region between the near and far fields and
have inaccuracies as a result.
Gunness and Mihelich, however, have introduced
techniques for accurately predicting far field direc-
tional response based upon near field measurements
made on a geometrical surface surrounding the loud-
speaker under test. The adoption of such procedures
will lead to more accurate descriptions of loud-
speaker directional characteristics of both magni-
tude and phase in the future.
On a final note, there is a useful relationship
between loudspeaker sensitivity, loudspeaker axial
Q, and loudspeaker electrical efficiency coefficient.
This relationship appears as Eq. 18-78.
(18-78)
where,
η is the efficiency coefficient,
Lp is the 1 watt @ 1 m sensitivity,
Q is the axial directivity factor.
When employing Eq. 18-78 it is important to
remember that each of the variables is frequency
dependent. It is necessary that the values employed
must be those for a given frequency or for a given
band of frequencies.
18.11 Horn Compression Drivers
A typical structure for a compression driver appears
in Fig. 18-29.
The view presented in Fig. 18-29 is a sectional
view in the median plane of the driver. The magnet,
which is actually in the form of a ring, is sand-
wiched between the pole pieces. The pole pieces
define the air gap in which the voice coil resides. A
portion of the front pole piece also forms part of the
phase plug. The depicted phase plug has concentric
annular slits as openings to expanding air channels.
These channels provide air paths of equal length as
measured from the rear face of the phase plug. The
rear face of the phase plug and the front face of the
diaphragm define the front air cavity. The rear face
of the diaphragm and the rear cover of the driver
define the back air cavity.
Area expansion actually begins in the phase plug
and continues up to the driver’s front face. An
η
1
Q----10
Lp
10
------
10.9
–
⎝
⎠
⎛
⎞
=
Figure 18-29. Typical compression driver displayed in
cross section. M is the magnet, B is the back cavity, D
is the diaphragm, F is the front cavity, and P is the
phase plug.
P
P
D
M
M
B
P
F

   
Loudspeakers and Loudspeaker Arrays
377
attached horn is ideally just an extension of this
expansion. The horn behavior, then, actually begins
in the phase plug. The compression ratio of such a
driver is the ratio of the front surface area of the
diaphragm to the entrance area of the air channels in
the phase plug. The area of the diaphragm is taken
to be SD while that of the phase plug entrance area is
ST . The compression ratio is thus SD ⁄ ST . This ratio
typically has a value of 10. The electrical and
mechanical behavior of a compression driver is
similar to that of a back enclosed direct radiator as
far as the back cavity of the driver is concerned. The
loading on the front face of the diaphragm, however,
is markedly different from that of a direct radiator.
On its front face, the diaphragm must compress or
expand the air in a cavity of small volume with
relief only being supplied through air flow in the
restricted entrance area of the channels in the phase
plug. The appropriate model accounting for this
behavior is presented in Fig. 18-30.
The model of Fig. 18-30 is drawn for the circum-
stance where the driver is loaded by a plane wave
tube or an ideal horn operating well above its cut off
frequency. This load is coupled into the driver
through an ideal transformer whose turns ratio is
just the compression ratio of the driver. The
mechanical impedance acting directly on the back
side of the diaphragm is ZD.
(18-79)
where,
Rm is the mechanical resistance of the diaphragm,
Rr is the radiation resistance on the back side of the
diaphragm,
MD is the diaphragm effective mass,
Xr is the radiation reactance on the back side of the
diaphragm,
KD is the diaphragm suspension stiffness,
VB is the back cavity volume.
The mechanical impedance acting directly on the
front side of the diaphragm is ZF .
(18-80)
where,
VF is the front cavity volume.
An analysis of the “circuit diagram” provided by
the model leads to expressions for the velocity of the
diaphragm, uD, and the air particle velocity at the
entrance to the phase plug, uT . The velocity of the
diaphragm is
(18-81)
The air particle velocity at the entrance to the
phase plug is the “current” in the ideal transformer
secondary and is
(18-82)
The detailed solution of these last two equations is
the province only of the driver design engineer as
numerical values of the driver parameters are not
generally available. Nevertheless a few general
conclusions may be formed. If one considers the
frequency range in the vicinity of the middle of the
pass band of the driver, the total impedance in the
denominator of Eq. 18-81 can be made almost
purely resistive.
This occurs as follows: In this frequency range
the reactance of the front cavity acts as an open
circuit so that ZF is then purely resistive with a value
of 
. If now ZD is tuned to reso-
nance in this frequency range, this resonance will
necessarily be of low Q because of the dominating
large resistive terms. As a consequence, there will
exist a broad frequency range where uD will be
constant and the power response of the driver will
be flat. Above this frequency range, the positive
mass reactance of the diaphragm will begin to domi-
nate and the power response will fall at the rate of
6dB ⁄octave. This will continue until the frequency
becomes high enough that one can no longer ignore
the front cavity reactance. In this range, one has the
front cavity negative reactance acting in parallel
with the resistive load on the driver with this combi-
nation in series with the positive mass reactance of
the diaphragm. This combination now constitutes a
second order low pass filter forcing the power
response to now fall at 12 dB/octave.
ZD
Rm
Rr
j ωMD
Xr
KD
ρ0c2SD
2
VB
--------------------
+
ω
---------------------------------------
–
+
+
+
=
ZF
ρ0c2SD
2
jωVF
--------------------ρ0cST
ρ0c2ST
2
jωVF
-------------------
ρ0cST
+
-----------------------------------------
=
uD
ESBl
Re
jωLe
+
------------------------
Bl
(
)2
Re
jωLe
+
------------------------
ZD
ZF
+
+
--------------------------------------------------
=
uT
SD
ST 
-------
⎝
⎠
⎛
⎞ρ0c2ST
2
jωVF
-------------------
ρ0c2ST
2
jωVF
-------------------
ρ0cST
+
-----------------------------------------uD
=
SD ST
⁄
(
)2ρ0cST

378
Chapter 18
Eventually, however, the voice coil inductance
will become important, forcing the power response
to ultimately fall at 18 dB/octave. This behavior is
accurately accounted for in the model, but the model
is ignorant of breakup modes that occur in the
diaphragm. The artifacts of these modes usually are
superimposed in the region where the model
predicts a fall of 12 dB/octave.
In this region there will be response peaks and
valleys as a result of resonances occurring in the
diaphragm material itself. There is one alternative
construction that can force a modification of the
behavior described above. If the front cavity volume
is made very small indeed, it is possible to force a
series resonance between the negative reactance of
this cavity and the positive mass reactance of the
diaphragm in the region where the response would
have previously been falling at 6 dB/octave.
This resonance will also be of low Q and will
extend the range of driver flat power response to
higher frequencies than before. This extended
response will come with a large penalty. In making
the front cavity volume very small, one has seri-
ously restricted the maximum allowable displace-
ment of the diaphragm and consequently the
maximum driver power output. This is another
instance where a trade off must be made in the
design process. Typical alternative behaviors
predicted by the model are the two curves appearing
in Fig. 18-31.
The measured performance of driver-horn
combinations can and does depart markedly from
that depicted in Fig. 18-31. Firstly there are artifacts
of diaphragm breakup previously mentioned and
secondly, there are the effects of resonances from
both mouth and internal reflections occurring in the
attached horn. The overall performance is consider-
ably less smooth than that implied by Fig. 18-31. As
an illustration of this fact, Fig. 18-32 is the
measured response of a compression driver mounted
on a constant directivity horn.
18.12 Crossover Networks
Origin
Crossover networks or frequency dividing networks
have their origin with the development of two-way
loudspeakers in the motion picture industry during
Figure 18-30. Mechanical impedance model of a compression driver.
uD
MD
Rm+ Rr
Xr
KD
KB
SD : ST
KF
Re
ESBl
Re + jωLe
ρ0cST
1
1
1
Le
(Bl)2
(Bl)2
Figure 18-31. Theoretical high frequency performance
of a compression driver.
Figure 18-32. Compression driver on a constant
directivity horn.
103
104
Frequency
Power Response Curve
10
5
0
−5
−10
−15
−20
−25
−30
dB
200
500
1k
2k
5k
10k
20k
Frequency
80
70
60
50
40
30
Amplitude–dB
TEF 20

   
Loudspeakers and Loudspeaker Arrays
379
the decade of the 1930s. The early networks were
passive systems interposed between the single
power amplifier typical of the time and the high and
low frequency stage loudspeakers positioned behind
the perforated projection screen. These networks
were either constant-k or combinations of constant-k
with m-derived sections based on the filter tech-
nology that had been developed by Bell Telephone
Laboratories.
In the 1940s and 1950s constant resistance cross-
over networks made their appearance based upon
the newer filter technology which involved Laplace
transforms and pole-zero analysis. In the 1950s and
1960s active crossover networks made their initial
appearance with ever increasing importance being
displayed in the 1970s attendant with the growth of
integrated circuits. Increasing attention was also
being given at this time to phase behavior, driver
physical positioning, and driver phase response. The
1980s presented not only a well-developed body of
theory for network design but also new acoustical
measuring instruments for assessing overall system
performance in the acoustical domain. This work
continues to the present day.
Electric Filters
Electric filters are circuit assemblies which modify a
signal’s properties as a function of frequency. This
modification may involve amplitude, phase, or both.
One category of filter freely transmits signals over
certain ranges of frequency while attenuating or
failing to transmit in other ranges. This attenuation
is accompanied by a frequency dependent phase
shift. Minimum phase shift filters fall in this cate-
gory. There is another category of filter which trans-
mits freely at all frequencies without affecting signal
amplitude but rather introduces a frequency depen-
dent phase shift. All pass filters fall into this cate-
gory and they find application in modern crossover
networks both active and passive.
Transfer Functions
In order to understand crossover networks and,
indeed, even to be able to read current literature on
the subject it is necessary to have some knowledge
of transfer functions. The relationship which exists
in the steady state between the output signal and the
input signal of a two port device such as a filter is
called the transfer function. The transfer function
has a magnitude and an angle with each, in general,
being frequency dependent. The magnitude of a
transfer function is an expression of the ratio of the
output signal amplitude to the input signal ampli-
tude. The angle of a transfer function is the phase
difference between the output signal and the input
signal. This is best illustrated by means of a simple
example. Fig. 18-33 depicts a simple low pass filter
consisting of an inductance and a resistance.
Through the employment of the techniques of ac
circuit analysis, one may write the relationship
between the output voltage and the input voltage of
the circuit of Fig. 18-33 as
(18-83)
Alternatively, this may be written in the complex
exponential form
(18-84)
and finally as
(18-85)
where,
H is the complex transfer function,
S is the Laplace transform variable whose steady
state value is jω,
ω0 = R/L.
The form presented in Eq. 18-85 is the statement
of the transfer function of the example low pass
filter in the language of the Laplace transform. In
the general case which includes the transient state, S
can have both real and imaginary parts. In this case,
S can be written as S = σ + jω. S is called the
complex frequency variable. If S is allowed to
assume any possible value whether it be real, imagi-
nary, or complex such that all points in a two dimen-
sional complex plane are accessible, there would be
Figure 18-33. Simple low pass filter.
L
R
H
R
L---
jω
R
L---
+
----------------
=
H
R
L---
ω2
R
L---
⎝⎠
⎛⎞
2
+
----------------------------e
j
ω
–
R
L---
-------
⎝
⎠
⎜
⎟
⎜
⎟
⎛
⎞
atan
=
H
ω0
S
ω0
+
---------------
=

380
Chapter 18
only one value of S for which the denominator of
Eq. 18-85 would become zero.
This value of S is S = −ω0. When S takes on this
value, the denominator becomes zero and the
magnitude of the transfer function becomes infinite.
It is said then that this transfer function has a single
“pole” located at S = −ω0. The pole order of a
transfer function is determined by the highest power
of S appearing in the denominator.
A two pole filter would have an S 2, a three pole
would have an S 3, etc., appearing in the denomi-
nator of the transfer function. In the steady state as
opposed to the transient state S is restricted to the
values S = jω and the only accessible points lie on
the positive imaginary axis. In the steady state, even
though the value of S never coincides with the loca-
tion of the example pole, the pole location neverthe-
less influences the operation of the filter.
Changing the pole location changes the value of
ω0 and hence changes the value of the transfer func-
tion at all frequencies other than zero. A further
study of the Laplace transform and the inverse
Laplace transform indicates that the transfer func-
tion is also a description of the filter’s impulse
response in the complex frequency plane. Addition-
ally, the inverse Laplace transform of the transfer
function is the description of the filter’s response to
an impulse described in the time domain, i.e., it is
the filter’s transient response to an impulsive excita-
tion expressed as a function of time.
An important consequence of this is that in order
for a filter to exhibit a transient response that decays
with increasing time, all of the poles of the filter’s
transfer function must have negative real parts. The
filter under discussion satisfies this criterion as its
single pole is located at −ω0, and hence its transient
response decays with time thus allowing the filter to
exhibit a stable steady state response.
The information contained in a filter’s transfer
function may be depicted in a variety of ways, the
two most popular of which are the Bode plot and the
Nyquist diagram. In exploring this it should be
noted that Eq. 18-84 is of the form
(18-86)
The Bode plot displays Eq. 18-86 in the form of
a graph of 20 dBlog|H| versus log(ω) and a graph of
ϕ versus log(ω). This behavior is displayed in
Figs. 18-34A and 18-34B.
In Fig. 18-34A, the pass band ranges from zero
frequency to the point where ω = ω0 where the
attenuation has become −3 dB. Note that in the stop
band (the region of increasing attenuation beyond
the −3 dB point) the slope approaches
−20 dB/decade or equivalently −6  dB/octave.
Fig. 18-34B suggests that the phase shift is zero at
zero frequency, −π/4 at ω = ω0, and approaches −π/2
at high frequencies.
The behavior of this single pole low pass filter is
displayed in a different manner by means of a
Nyquist diagram. A Nyquist diagram is a graph of
the real part of a frequency dependent complex
quantity versus the imaginary part of the same
complex quantity. In making this graph, the
frequency is treated as a parameter and is allowed to
range from zero to infinity. Fig. 18-35 is the Nyquist
diagram for the single pole low pass filter.
The same information displayed in the Bode plot
is also contained in the Nyquist diagram. The
magnitude of the transfer function at any frequency
corresponds to the length of a line drawn from the
origin to the point on the curve in Fig. 18-35 which
corresponds to the frequency value in question. The
angle of the transfer function at any frequency is the
angle between the magnitude line described above
and the real axis.
Corresponding to the first order low pass filter of
the previous example is a complementary first order
high pass filter. The circuit for this filter appears in
Fig. 18-36.
H
H ejϕ
=
Figure 18-34. Low pass filter response.
ω/ω0
10−1 
100 
101
0
−2
−4
−6
−8
−10
−12
−14
−16
−18
−20
dB Magnitude
A. Single pole low pass amplitude response. 
B. Single pole low pass phase response.
10−1 
100 
10
Phase difference in radians
0.0
−0.5
−1.0
−1.5
ω/ω0

   
Loudspeakers and Loudspeaker Arrays
381
The high pass filter equations written in the same
order as before are
(18-87)
(18-88)
(18-89)
where,
ω0 = 1/RC.
The performance of this filter is depicted in the
Bode plots of Figs. 18-37A and 18-37B as well as
the Nyquist diagram of Fig. 18-37C.
Upon returning to Eq. 18-89, it is apparent that
this transfer function has a pole located at ω = −ω0.
In addition there is an S appearing in the numerator
of the equation. In the complex plane, if there is a
value of S which makes the numerator of a transfer
function equal to zero, such a value is called a
“zero” of the transfer function. A pole-zero diagram
is a useful way of displaying this information.
Fig. 18-38A is the pole-zero diagram for the first
order low pass filter while Fig. 18-38B is that for the
corresponding high pass filter.
Figure 18-35. Nyquist diagram for a single pole low
pass filter.
Figure 18-36. Simple high pass filter.
Increasing ω
0.1
0.0
–0.1
–0.2
–0.3
–0.4
–0.5
–0.6
Imaginary
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 
1
Real
Nyquist
H
R
R
1
jωC
----------
+
--------------------
=
jω
jω
1
RC
--------
+
--------------------
=
H
ω
ω2
1
RC
--------
⎝
⎠
⎛
⎞
2
+
---------------------------------e
j π
2---
ωRC
(
)
atan
–
=
H
S
S
ω0
+
---------------
=
C
R
Figure 18-37. High pass filter response.
10−1 
100 
101
0
−2
−4
−6
−8
−10
−12
−14
−16
−18
−20
dB Magnitude
ω/ω0
10−1 
100 
101
Phase difference in radians
1.5
1.0
0.5
0.0
ω/ω0
A. Single pole high pass amplitude response.
B. Single pole high pass phase response.
C. Nyquist diagram for a single pole high pass filter.
Increasing ω
Imaginary
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 
1
Real
0.6
0.5
0.4
0.3
0.2
0.1
0.0
−0.1

382
Chapter 18
When one superimposes the amplitude response
curves of the low pass and high pass filter as is done
in Fig. 18-39, it is found that the two curves cross
each other at ω = ω0. This behavior is the origin of
the term crossover network. At this point each of the
terminating resistors is receiving ½ of the total
power supplied.
This pair of filters could constitute a simple
crossover network for a two-way loudspeaker
system. The implementation can be accomplished
either actively or passively. The active implementa-
tion can be accomplished in either the analog or
digital domain. A discussion of the digital imple-
mentation appears in Chapter 22 Signal Processing.
Examples of active analog and passive implementa-
tions are shown in Fig. 18-40.
In order for the passive version to work properly,
the terminating loads must be constant resistances at
least for an octave below and an octave above cross-
over. These loads are represented by R in the circuit
diagram. In practice the loads are the impedances of
the low and high frequency loudspeakers. Moving
coil loudspeakers, as displayed in Fig. 18-20, have
impedances which are far from constant, nor are
they purely resistive. As is shown in Chapter 8
Interfacing Electrical and Acoustic Systems, Section
8.1, Alternating Current Circuits, however, it is
possible to parallel the loudspeaker with a Zoebel
network which will produce a combination having a
sufficiently constant resistance provided that the
chosen crossover frequency is well removed from
the driver’s mechanical resonance frequency. When
one calculates the electrical impedance presented to
the power amplifier in the passive version of the
network in Fig. 18-40 while employing the compo-
nent values indicated, the impedance is found to be
R at all frequencies. This network, then, falls into a
category termed as being a constant resistance
network. The filters in this simple network possess
many other interesting and useful properties. These
filters have an amplitude response that is maximally
flat which means they are Butterworth filters. As
each of the filters has a single pole, they are first
order Butterworth filters. If one sums the transfer
functions of the low pass and the high pass as is
done in Eq. 18-90 it is found that the sum is unity.
This implies that the combination forms a special all
pass filter having a constant amplitude response at
all frequencies with zero phase shift at all
Figure 18-38. Pole-zero diagram.
Figure 18-39. Illustration of crossover point for single
pole low and high pass filters.
jω
jω
−ω0
−ω0
Pole
s
s
Pole
Zero
A. Low pass.                       B. High pass.
10−1 
100 
101
0
−2
−4
−6
−8
−10
−12
−14
−16
−18
−20
dB Magnitude
ω ⁄ ω0
Amplitude Response
Figure 18-40. Active and passive versions of first order
crossover.
A. Active network.
R
C
R
C
To low
amp
To high
amp
B. Passive network.
Power
Amp
Low
R
R
High
L=R ⁄ 2πf0
C=1 ⁄ 2πf0R
f0 = 1 ⁄ 2πRC
+
+
−
−

   
Loudspeakers and Loudspeaker Arrays
383
frequencies. This means that the summed response
would exactly replicate the original input signal.
(18-90)
Additionally, the power response of a filter is
given by the square of the absolute magnitude of the
filter’s transfer function. If one adds the power
responses of the filters comprising this simple first
order crossover network, as is done in Eq. 18-91, it
is found that the combined power response of this
network is also unity.
(18-91)
This unity power summation is a property that is
shared, in fact, by all orders of Butterworth two-way
crossover networks. Uniform power response gener-
ally leads to improved intelligibility in semi-rever-
berant and highly reverberant fields. This fact is
responsible for the popularity of Butterworth cross-
overs for employment in speech reinforcement
systems.
In summary, this first order Butterworth two-way
crossover network appears to be ideal. The network
is simple in construction, is maximally flat, has
unity summed amplitude response with no
frequency dependent phase shift, and has an overall
unity power response. In fact, it is the only two-way
network of any order possessing all of these desir-
able properties. This network’s sole shortcoming is
the modest attenuation rate of 6 dB/octave either
side of crossover. This small attenuation rate does
not adequately protect high frequency drivers
against low frequency signals except in low power
systems where the network may be employed quite
successfully. In high power systems higher order
networks are usually required.
Higher Order Networks
The need for greater attenuation slope leads immedi-
ately to filters and networks of second or higher
order. For many years the “standard” crossover
network of the constant resistance variety was the
second order Butterworth. This type was chosen
because of its increased attenuation rate, maximally
flat amplitude response, and unity power summation
property. The active and passive realizations of the
second order Butterworth crossover are given in
Fig. 18-41.
The transfer function describing the low pass section
behavior is
(18-92)
while that for the high pass section is
(18-93)
The Bode plots for these functions are given in
Figs. 18-42 and 18-43.
The increased attenuation slopes of 12 dB/octave
are evident in Fig. 18-42. When one examines the
summed frequency response as given in Eq. 18-94,
however, it is found that all is not well.
(18-94)
ω0
S
ω0
+
---------------
S
S
ω0
+
---------------
+
1
=
ω0
2
ω2
ω0
2
+
---------------------
ω2
ω2
ω0
2
+
---------------------
+
1
=
Figure 18-41. Second order Butterworth crossover.
A. Active network.
R
C
2R
C
To low
amp
To high
amp
B. Passive network.
Power
Amp
Low
R
R
High
L = 0.707R/πf0
C = 1/2.828πf0R
f0 = 1/(2.828πRC)
+
+
−
−
2C
C
R
C
L
R
Hl
ω0
2
S2
2Sω0
ω0
2
+
+
--------------------------------------------
=
Hh
S2
S2
2Sω0
ω0
2
+
+
--------------------------------------------
=
Hl
H
+
h
S2
ω0
2
+
S2
2Sω0
ω0
2
+
+
--------------------------------------------
=

384
Chapter 18
The summed frequency response is not indepen-
dent of frequency as it was in the first order case.
This summed response has a value of unity at the
frequency extremes when S is either very small or
very large while at the crossover frequency, where S
is jω0, the summed response is zero! The reason for
this is graphically displayed in Fig. 18-43. The
response magnitudes of the low pass and high pass
sections are equal at the crossover but the phase of
the high pass is +90° or π/2 while that of the low
pass is −90° or −π/2 and this phase difference leads
to a net sum of zero.
This behavior led one audio company to include
a third driver in their basically two-way loudspeaker
system to “fill the hole in the middle.” Much adver-
tising copy was generated by this approach. Another
approach, taken by others, is to reverse the polarity
of the driver in the low frequency section of a
two-way loudspeaker system. This has the effect of
taking the difference between Hh and Hl for the
summed frequency response as given in Eq. 18-95.
(18-95)
Eq. 18-95 has a value of −1 at very low frequen-
cies, a value of 1.414j at crossover, and a value of +1
at very high frequencies. The corresponding values
in the language of the Bode plots would be 0dB with
an angle of π at low frequencies, +3 dB with an angle
of π ⁄ 2 at crossover, and 0 dB with an angle of 0° at
high frequencies. This technique greatly improves
the summed amplitude response while requiring an
overall phase change of π radians between the
frequency extremes. Regardless of which of these
two possible connections are employed, the summed
power responses will still be unity.
An examination of the third order Butterworth
network will enable some general statements about
subsequent higher order networks. The transfer
functions for the third order Butterworth are
(18-96)
and
(18-97)
The Bode plots for this network appear in Figs.
18-44 and 18-45.
From Fig. 18-44 it should be apparent that the
attenuation slopes are now 18 dB/octave or equiva-
lently 60 dB/decade. From Fig. 18-45 it is seen that
the phase shift in each filter between frequency
Figure 18-42. Magnitude response of second order
Butterworth crossover.
Figure 18-43. Phase response of second order Butter-
worth crossover.
10−1 
100 
101
dB Magnitude
ω/ω0
0
−5
−10
−15
−20
−25
−30
−35
−40
Amplitude Response
10−1 
100 
101 
Phase in Degrees
ω/ω0
200
150
100
50
0
−50
−100
−150
−200
Phase Response
High Pass
Low Pass
Figure 18-44. Magnitude response of third order
Butterworth crossover.
Hh
H
+
l
S2
ω0
2
–
S2
2Sω0
ω0
2
+
+
--------------------------------------------
=
Hl
ω0
3
S3
2S2ω0
2Sω0
2
ω0
3
+
+
+
-----------------------------------------------------------------
=
Hh
S3
S3
2S2ω0
2Sω0
2
ω0
3
+
+
+
-----------------------------------------------------------------
=
10−1 
100 
101
dB Magnitude
ω/ω0
0
−10
−20
−30
−40
−50
−60
−70
Amplitude Response

   
Loudspeakers and Loudspeaker Arrays
385
extremes is 270° with exactly half of the overall
having been accomplished at the crossover frequency.
In each instance these values are just three times the
corresponding values for the first order network. The
summed frequency response of the third order Butter-
worth network appears in Eq. 18-98.
(18-98)
The Nyquist diagram of Eq. 18-98 as presented in
Fig. 18-46 best illustrates the behavior of this sum.
The fact that the Nyquist diagram of Fig. 18-46 is
a circle of unit radius centered on the origin means
that the summed frequency response has a magni-
tude of unity or 0 dB at all frequencies and hence an
all pass character. At zero frequency, the phasor
representing the summed response is a horizontal
line extending from the origin at (0,0) to the point
(1,0j). The sum at zero frequency thus has a magni-
tude of one and an angle of zero. At each successive
increasing value of frequency, the sum phasor main-
tains a constant length while having been rotated
through increasing angles in the clockwise direction.
When infinite frequency has been reached, the
phasor will have rotated through one complete revo-
lution. Exactly one-half of this rotation is accom-
plished as ω increases from zero to ω0. This means
that when ω = ω0, the sum phasor extends from the
origin to the point (−1, j0). The remainder of the
complete rotation is accomplished as the angular
frequency increases from ω0 to an infinite value.
The properties of the Butterworth polynomials
are such that regardless of the order, the poles of the
transfer functions always lie on a semi-circle of
radius ω0 in the left half of the complex plane. The
poles are uniformly spaced with regard to angle with
odd orders having a single pole on the negative real
axis. Additionally, the zeros for the high pass func-
tion are all located at the origin. The consequence of
this arrangement of poles and zeros is as follows.
The low pass function starts with a phase shift of
zero and tends toward a phase shift of −nπ ⁄ 2 where n
is the network order, having accomplished one-half
of this total phase shift at the crossover frequency.
The high pass section starts with a phase shift of
+nπ ⁄ 2 and tends toward zero as the frequency
increases having accomplished a change of one-half
of the total at the crossover frequency. Furthermore,
the magnitude of the functions is equal at crossover
with each having a value of 
 or −3  dB.
Fig. 18-47 is a phasor diagram, at crossover,
expressing these results for all orders through the
seventh. The phasors in each case represent the
signals passed by both the low and high frequency
sections at crossover as well as the phasor sum.
A study of Fig. 18-47 reveals that even orders
never sum to the appropriate value at the crossover
frequency. The odd orders always sum properly at
crossover and indeed at all frequencies even though
the phase may or may not be correct. It was previ-
ously observed that the first order filters sum
correctly in both magnitude and phase at all
frequencies. It is unique in this respect. The present
popularity of the higher odd order Butterworths is
attributable to the fact that they sum to the appro-
priate magnitude at all frequencies including the
crossover frequency. The transfer function
describing this sum is of an all pass character but
with a frequency dependent phase shift.
Figure 18-45. Phase response of third order
Butterworth crossover.
Figure 18-46. Nyquist diagram of summed frequency
response of third order Butterworth.
10−1 
100 
101
Phase in Degrees
ω/ω0
Phase Response
High Pass
Low Pass
300
200
100
0
−100
−200
−300
Hl
Hh
+
S3
ω
+
0
3
S3
2S2ω0
2Sω0
2
ω0
3
+
+
+
-----------------------------------------------------------------
=
Imaginary
Real
Nyquist
Increasing Frequency
1
0.8
0.6
0.4
0.2
0
−0.2
−0.4
−0.6
−0.8
−1
Unit Radius
Start and Finish
Increasing Frequency
 −1 
−0.5 
0 
0.5 
1 
1
2
⁄

386
Chapter 18
All of the foregoing statements with regard to the
summation properties of two-way crossover
networks were made in reference to the summation
of the electrical signals. In practice, however, it is
the acoustical summation of the signals radiated by
the low and high frequency loudspeakers which is of
interest. In addition to correct crossover network
behavior, the correct acoustical summation imposes
additional conditions that must be satisfied by the
loudspeakers employed.
In order to have correct power summation the
loudspeakers must have reasonably flat amplitude
and phase response in their respective pass bands.
The loudspeakers must have equal axial Q and
adjusted sensitivity at least for an octave both above
and below crossover. Finally, proper amplitude
response summation requires that the high and low
frequency loudspeakers have a common acoustic
center and acoustic origins which have been
adjusted by signal delay techniques to be the same.
This latter condition can be satisfied exactly only by
co-axial loudspeakers. Other physical arrangements
greatly restrict the region in the listening space in
which the summation will be correct.
There are other possibilities for higher order
crossover filters such as the Bessel or Chebyshev.
Mathematically, these filters are distinguished by
different sets of coefficients in the various terms of
the polynomials in S in the filter transfer functions.
The Bessel filters offer maximally flat group delay.
This means that the phase response of this filter type
is linear in the filter’s pass band. The Chebyshev
filters offer maximum attenuation rate at the edge of
the filter stop band accompanied by ripple in the
amplitude response in the pass band. Neither of
these filter types is constant resistance in the passive
implementation. Additionally these filters are
lacking in unity summation properties. Their
employment in crossover networks is usually driven
by considerations other than those mentioned.
There is one other two-way crossover network
which is of more than just passing interest. This is
the Linkwitz-Riley or second order Butterworth
squared network. This network is almost always
implemented as an active network by cascading two
second order Butterworth networks as shown in the
circuit of Fig. 18-48.
This network is fourth order, but it is not a fourth
order Butterworth as it has a different set of polyno-
mial coefficients. The low pass section has the
transfer function of Eq. 18-99.
(18-99)
The transfer function for the high pass section
appears in Eq. 18-100.
(18-100)
Figure 18-47. Butterworth amplitude summation
properties for various orders.
High
High
High
High
High
High
High
Low
Low
Low
Low
Low
Low
Low
n = 1
n = 7
n = 6
n = 5
n = 4
n = 3
n = 2
Figure 18-48. Linkwitz-Riley fourth order network.
R
C
R
C
f0 = 1/(2.828πRC)
+
+
−
−
+
−
C
R
+
−
R
R
C
C
C
2R
2R
2C
2C
R
Low
High
Hl
ω0
4
S4
2 2S3ω0
4S2ω0
2
2 2Sω0
3
ω0
4
+
+
+
+
--------------------------------------------------------------------------------------------------------
=
Hh
S4
S4
2 2S3ω0
4S2ω0
2
2 2Sω0
3
ω0
4
+
+
+
+
--------------------------------------------------------------------------------------------------------
=

   
Loudspeakers and Loudspeaker Arrays
387
The behavior of the Linkwitz-Riley network is
summarized in Figs. 18-49, 18-50, and 18-51. From
Fig. 18-49 it is apparent that this network offers
attenuation rates of 24 dB/octave and at the cross-
over frequency the response of each section is down
by 6 dB rather than 3 dB as would be true for all
orders of the Butterworth networks. Fig. 18-50 indi-
cates that at the crossover frequency, the low
frequency signal is in phase with the high frequency
signal as +180° and −180° locate the same point on
a unit circle. This implies that at the crossover
frequency the total amplitude response is at 0 dB.
Finally from Fig. 18-51, the Nyquist diagram is a
circle of unit radius thus indicating that the summed
amplitude response is 0 dB not only just at crossover
but at all frequencies. Therefore the network is of an
all pass character with an overall phase shift of 2π
radians between frequency extremes. The short-
coming of this network lies only in its lack of unity
power summation. In spite of this one shortcoming,
the Linkwitz-Riley is often employed because of its
structural simplicity and its steep slopes.
Three-Way and Higher Crossover Networks
The traditional approach for constructing a three-
way crossover has been to employ a low pass at a
low frequency and a high pass at a considerably
higher frequency. These in turn border a bandpass
whose lower half power point corresponds to that of
the low pass and whose upper half power point
corresponds to that of the high pass. A circuit for a
simple version of such a network is illustrated in
Fig. 18-52.
The transfer functions for the network of
Fig. 18-52 are given in the following equations.
Figure 18-49. Linkwitz-Riley amplitude response.
ω/ω0
10−1 
100 
101
dB Magnitude
0
−10
−20
−30
−40
−50
−60
−70
−80
−90
Magnitude Response
Figure 18-50. Linkwitz-Riley phase response.
Figure 18-51. Linkwitz-Riley Nyquist diagram.
Figure 18-52. Simple passive three-way crossover
circuit.
10−1 
100 
101
Phase in Degrees
ω/ω0
Phase Response
High Pass
Low Pass
400
300
200
100
0
−100
−200
−300
−400
Imaginary
Real
Nyquist
Increasing Frequency
1
0.8
0.6
0.4
0.2
0
−0.2
−0.4
−0.6
−0.8
−1
Unit Radius
Start and Finish
Increasing Frequency
 −1 
−0.5 
0 
0.5 
1
Ch
Cm
Lm
Ll
R
High
R
R
Mid
Low

388
Chapter 18
(18-101)
(18-102)
(18-103)
In Eq. 18-101, ωl is the angular frequency of the
half power point of the low pass filter. A specifica-
tion of this value allows one to determine the
required value of the inductance in this filter as, also
from Eq. 18-101,
(18-104)
Similarly, in Eq. 18-103, ωh is the angular
frequency of the half power point of the high pass
filter. A specification of this value allows one to
determine the required value of the capacitance in
this filter.
(18-105)
The situation with regard to the bandpass or mid
band filter described by Eq. 18-102 is a little more
involved. Such filters are geometrically symmetric
which is equivalent to the requirement that
(18-106)
Additionally, the Q or quality factor of this filter can
be expressed as
(18-107)
Equations 18-106 and 18-107 may be solved
simultaneously to obtain separate expressions for
the required inductance and capacitance necessary
for the construction of this filter.
(18-108)
(18-109)
The choice of crossover frequencies to be
employed in three-way systems is driven by both the
properties of the available drivers and acoustical
considerations. From an acoustical point of view, it
is highly desirable to make the reinforcement of
speech as natural as is possible. This is greatly facil-
itated by having the mid range element handle all of
the range of frequencies in which the energy of
speech is dominant. A reasonable choice for the
operating range of the mid range element would
then be 300–3000 Hz. Employing these crossover
frequencies with eight-ohm drivers leads to the
following component values.
Hl
R
LlS
R
+
------------------
=
R
Ll
----
S
R
Ll
----
+
--------------
=
ωl
S
ωl
+
--------------
=
Hm
R
1
CmS
----------
Lm
+
S
R
+
-------------------------------------
=
R
Lm
------S
S2
R
Lm
------S
1
LmCm
--------------
+
+
-------------------------------------------
=
ωm
Q
-------S
S2
ωm
Q
-------S
ωm
2
+
+
---------------------------------------
=
Hh
R
1
ChS
---------
R
+
--------------------
=
S
S
1
RCh
----------
+
--------------------
=
S
S
ωh
+
---------------
=
Ll
R
ωl
-----
=
Ch
1
ωhR
----------
=
ωm
ωhωl
=
Q
ωm
ωh
ωl
–
------------------
=
ωmLm
R
--------------
=
1
ωmCmR
-------------------
=
Lm
R
ωh
ωl
–
------------------
=
Cm
ωh
ωl
–
ωm
2R
------------------
=
Ll
R
2πfl
----------
=
8
2π
(
) 300
(
)
-------------------------
=
4.24  mH
=
Ch
1
2πfhR
---------------
=
1
2π
(
) 3000
(
)8
--------------------------------
=
6.63 μF
=

   
Loudspeakers and Loudspeaker Arrays
389
The performance properties of a three-way
network constructed with the above component
values are best illustrated in a sequence of figures.
Fig. 18-53 displays the amplitude performance of
the simple three-way network.
From Fig. 18-53 it is apparent that the low to mid
transition occurs at 300 Hz while the mid to high
transition occurs at 3000 Hz. Additionally the band-
pass center frequency occurs at the geometric mean
of 300 Hz and 3000 Hz which is 949 Hz. The filter
skirts have slopes of 6 dB/octave in each instance.
The behavior of the summed frequency response
appears in Fig. 18-54.
The summed frequency response of the simple
three-way network is found to be not quite ideal.
The ideal sum would be unity corresponding to zero
dB at all frequencies. In practical terms, the worst
case deviation is only a little over 1.4 dB and is not
severe. Similarly, Fig. 18-55 displays the summed
power behavior.
Ideally the summed power response would be
unity corresponding to 0 dB. The departure from
ideal of a little over 0.7 dB displayed by the simple
three-way is actually trivial in practical terms. The
major shortcoming of this simple three-way lies in
the low attenuation rate.
There are artful techniques for improving the
performance of multi-way crossover networks. In
fact, the simple three-way network can be greatly
improved through a simple circuit change. As an
example, consider the circuit of Fig. 18-56.
The low pass transfer function is the same as in
the simple three-way.
Figure 18-53. Amplitude response of a simple
three-way crossover network.
Lm
R
ωh
ωl
–
------------------
=
8
2π
(
) 3000
300
–
(
)
-------------------------------------------
=
0.472 mH
=
Cm
ωh
ωl
–
ωm
2R
------------------
=
2π
(
) 3000
300
–
(
)
2π
(
)2 3000
(
) 300
(
) 8
( )
-----------------------------------------------------
=
59.7 μF
=
0
−5
−10
−15
−20
−25
−30
−35
−40
102                         103                    104
Amplitude Response
Frequency
dB Magnitude
Figure 18-54. Simple three-way summed frequency
response behavior.
Figure 18-55. Simple three-way summed power
response behavior.
101             102              103             104           105
1.6
1.4
1.2
1.0
0.8
0.6
0.4
0.2
0.0
−0.2
dB
Frequency
Amplitude of Summed Frequency Response
101             102              103             104           105
dB
Frequency–Hz
Summed Power Response
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0.0
−0.1
−0.2

390
Chapter 18
(18-110)
The bandpass transfer function is now
(18-111)
and the high pass transfer function becomes
(18-112)
Upon taking 300 Hz and 3000 Hz as the transition
points, the component values are found to be
This rather modest change in the circuit arrange-
ment and, as it turns out, a slight modification of
two component values brings about marked
improvement of performance in several areas. The
improved network is a true constant resistance
network. This was not the case for the original
version. The summed frequency response is ideal in
that the sum of the transfer functions is identically
equal to one. The summed power response is also
identically equal to one. Last, but by no means least,
the slope of the high frequency filter is now
12dB/octave rather than 6 dB/octave as is true for
the former case. This increased slope of the high
frequency filter offers more protection to the high
frequency driver. The performance curves appear in
the Figs. 18-57, 18-58, and 18-59.
Synthesized Crossover Networks
Most current installed sound reinforcement systems
employ active crossover networks with subsequent
power amplification. Though more costly, this
method offers a number of technical advantages.
Differences in speaker sensitivities are readily
compensated by power amplifier level adjustments.
All speakers are fed from the low impedance
sources offered by the power amplifier outputs.
Additionally, the active crossover systems
whether analog or digital offer greater flexibility in
Figure 18-56. Improved three-way network.
Ch
Cl
Lm
Ll
R
High
R
R
Mid
Low
Hl
R
Ll
----
S
R
Ll
----
+
--------------
=
ωl
S
ωl
+
--------------
=
S R
Lm
------
S2
S
1
RCl
---------
R
Lm
------
+
⎝
⎠
⎛
⎞
1
LmCl
------------
+
+
--------------------------------------------------------------
Hh
S2
S2
S
1
RCl
---------
1
RCh
----------
+
⎝
⎠
⎛
⎞
1
R2ClCh
------------------
+
+
------------------------------------------------------------------------
=
Ll
R
2πfl
----------
=
8
2π
(
) 300
(
)
-------------------------
=
4.24 mH
=
Cl
1
2πflR
--------------
=
1
2π
(
) 300
(
)8
-----------------------------
=
66.3  μF
=
Lm
R
2πfh
-----------
=
0.424 mH
=
Figure 18-57. Amplitude response of improved
three-way.
Ch
1
2πfhR
---------------
=
1
2π
(
) 3000
(
)8
--------------------------------
=
6.63 μF
=
0
−5
−10
−15
−20
−25
−30
−35
−40
 
102 
103 
104
Amplitude Response
Frequency
dB Magnitude

   
Loudspeakers and Loudspeaker Arrays
391
generating filter transfer functions and, in the case of
digital systems, variable signal delays for adjusting
acoustic origins are readily available. The greater
flexibility in generating filter transfer functions is
manifested through the fact that in active systems,
one may readily add or subtract signals. As an
example, suppose one is working with a two-way
system in which the high frequency drivers require at
least a second order high pass filter in order to have
adequate protection from low frequency signals.
Additionally, it is required that the low pass be
such that the low and high frequency signals sum in
such a way that the sum exhibits an all pass char-
acter with zero phase shift. This can be accom-
plished very simply in an active system. Consider
the block diagram of Fig. 18-60.
In Fig. 18-60 the full audio spectrum signal is
applied to both a conventional high pass filter of
choice and to the non-inverting terminal of a unity
gain difference amplifier. The output of the high
pass filter is supplied as a separate output and is also
applied to the inverting terminal of the unity gain
difference amplifier. The signal passed by the high
pass filter is thus subtracted from the total spectrum
with the difference being constituted only of low
frequency signals. In practice, the high pass could
be any order desired even though for the present
example a second order will be employed. In the
language of transfer functions, the low pass transfer
function generated by this arrangement will be
simply
(18-113)
This procedure forces the sum of the high pass
and low pass to be the ideal value of unity because
(18-114)
In particular, if the high pass filter selected is a
second order Butterworth, the high pass transfer
function is
(18-115)
while the synthesized low pass becomes
(18-116)
Fig. 18-61 displays the amplitude responses asso-
ciated with the network where 500 Hz has been
chosen as the half power point for the high
frequency section.
This technique, however, does have its own
shortcomings. The low pass function necessary to
guarantee unity summation in frequency response
behavior is not maximally flat but rather exhibits a
2dB peak. The attenuation slope of the low pass
Figure 18-58. Summed frequency response behavior of
improved three-way.
Figure 18-59. Summed power behavior of improved
three-way.
 
102 
103 
104
Amplitude of Summed Frequency Response
Frequency
dB
1
0.8
0.6
0.4
0.2
0.0
−0.2
−0.4
−0.6
−0.8
−1.0
 
102 
103 
104
Summed Power Response
Frequency
dB
1
0.8
0.6
0.4
0.2
0.0
−0.2
−0.4
−0.6
−0.8
−1.0
Figure 18-60. Synthesized low pass filter.
−
+
High
Pass
Filter
Difference
Amplifier
High Pass Out
Low Pass Out
Full
Spectrum In
Hl
1
Hh
–
=
Hl
Hh
+
1
Hh
–
Hh
+
=
1
=
Hh
S2
S2
2Sωh
ωh
2
+
+
--------------------------------------------
=
Hl
2Sωh
ωh
2
+
S2
2Sωh
ωh
2
+
+
--------------------------------------------
=

392
Chapter 18
section is only 6 dB/octave and the low frequency
speaker must operate well at frequencies well
beyond 500 Hz. Finally, even though the amplitude
summation is unity as is also displayed in the figure,
the power summation is not. The power behavior
appears in Fig. 18-62.
Fig. 18-62 displays the relative power curves in
the synthesized low pass section, the high pass
section, and the overall summed value. The summed
power curve exhibits a bump of about 3 dB that is
reasonably localized and, though not ideal, is not all
that severe.
18.13 Loudspeaker Arrays
Loudspeakers and loudspeaker systems are arrayed
in order to produce coverage patterns that are unat-
tainable from a single loudspeaker or loudspeaker
system acting alone. Arraying, depending upon the
techniques involved, can increase or decrease the
total coverage angles. Arrays of two or more loud-
speakers can be employed to increase the attainable
sound pressure level.
Certain arrays of loudspeakers can modify the
normal attenuation rate with distance at least in the
intermediate field and open the possibility of electri-
cally steering the directional pattern of the array. In
former times arrays were built up of separate collec-
tions of low frequency and high frequency loud-
speaker units. The low frequency units being either
direct radiators, vented enclosures, or horn loaded.
The high frequency units were almost universally
horn loaded.
Such systems were obviously of the two-way
variety. The trend in recent times has been to
construct arrays from individual complete two or
three way loudspeaker systems. The better of these
systems are horn loaded with co-axial and or
co-entrant arrangements between elements. The
electrical drive signals applied to the low, mid, and
high frequency elements are appropriately delayed
to produce a common acoustic origin for all
elements. In the best designs, the elements also
share a common acoustic center. As a result, each
such loudspeaker system can be considered as a
single device for the purpose of constructing arrays.
Acoustic Order of Choices of System Structure
An array of loudspeaker systems is not always
necessary. In a given environment, if the required
level, coverage, and intelligibility can be obtained
from a single, suitably installed loudspeaker nothing
further is required or desired. In such an instance,
particularly with regard to speech reinforcement
systems, the only other consideration is source
identification.
Source identification is the technique of locating
the source of reinforced sound near the area where
the original sound is produced. A case in point
would be that of a live talker at a podium. If the
loudspeaker is elevated above the podium by a few
meters and pointed downward into the audience, the
visual cues of the speaker’s mouth movements and
the audible cues of the natural and reinforced sound
will fuse to give the overall impression that the total
sound is emanating from the speaker’s mouth.
In contrast, visualize the situation where you are
facing the talker and the reinforced sound is coming
from behind you. This is a situation not found in
nature and leads to both confusion and fatigue. In
addition, the downward projection of the loud-
speaker into the audience leads to a useful value for
Figure 18-61. Amplitude response of two-way cross-
over with synthesized low pass.
Figure 18-62. Power behavior of two-way with synthe-
sized low pass filter.
100 
101 
102 
 
103 
104
Amplitude Response
Frequency
dB
10
5
0
−5
−10
−15
−20
−25
−30
−35
−40
100 
101 
102 
 
103 
104
Power Response
Frequency
dB
10
5
0
−5
−10
−15
−20
−25
−30
−35
−40

   
Loudspeakers and Loudspeaker Arrays
393
the acoustic modifier, Ma. This in itself lowers the
power driving the reverberant field and improves
intelligibility. Similar such considerations lead to
the following order of system choices to be explored
in the design phase.
The system to be selected is the first one from this
listing which satisfies the level, coverage, and intelli-
gibility requirements for the acoustic space at hand.
1.
A single source loudspeaker system.
2.
An array of single source devices all at the same
location.
3.
A single source system accompanied by delayed
satellite systems with each covering a distinct
audience area.
4.
High-density overhead distributed system.
5.
Pew-back-type individual coverage.
6.
Headphones for each listener.
Design Process
The prime considerations in system choice are those
of coverage and intelligibility. One begins the
design process by assuming a single source loud-
speaker system and then determines what the system
Q must be in order to satisfy intelligibility require-
ments for the most distant listener in the acoustical
space at hand. If the space under consideration is an
existing space, it is possible to make direct measure-
ment of the reverberation times in octave or
one-third octave bands. When the space exists only
on architectural drawings one must rely on calcu-
lated values for reverberation times. In this instance
a premium is placed on an accurate description of
surface materials and treatments. In either case one
takes the conservative approach and treats the space
as if it is unoccupied. A fully occupied space has
significantly lower reverberation times, which in
turn produce higher intelligibility. If a system meets
intelligibility requirements in an unoccupied space,
its intelligibility only improves as the space is filled.
The only exception to this rule is if the crowd noise
worsens the signal to noise ratio such that it falls
below 25dB.
Consider a large multipurpose space that has a
volume of 500,000 ft3 and a reverberation time of 4.3s
in the octave band centered on 2 kHz. An area devoted
to lectures and other oral presentation is contained
within this larger space. Fig. 18-63 is an elevation
view through the centerline of the lecture space.
The relevant equation for determining the
required Q for a single loudspeaker covering a
distant listener is
(18-117)
where,
QMIN is the minimum required Q in the direction of
the listener,
656 is a constant appropriate for English units,
D is the distance to the listener in feet,
RT60 is the reverberation time in seconds,
%ALCONS is the percentage articulation loss of
consonants,
V is the room volume in ft3.
When calculating with SI units, the constant 656
becomes 200, the distance is expressed in meters
(m), and the volume is expressed in m3.
For the case depicted in Fig. 18-63, the most
distant listener on axis is at a distance of 100 ft. The
calculated minimum Q will then be the axial Q of
the loudspeaker. From the equation then,
QMIN
656 D
(
)2 RT60
(
)2
%ALCONS
(
) V
( )
----------------------------------------
=
QMIN
656 100
(
)2 4.3
(
)2
15
(
) 500,000
(
)
----------------------------------------
=
16.2
=
Figure 18-63. Elevation view.
D3 = 25 ft
41° off axis
D2 = 50 ft
12° off axis
D1 = 100 ft
on axis

394
Chapter 18
As this is the minimum Q required, only an
improvement will result by selecting a standard loud-
speaker whose Q is slightly larger than the minimum.
In this instance a loudspeaker whose nominal
coverage is 60° by 40° with a Q on axis of 18 is a
reasonable choice. The chosen loudspeaker has a
sensitivity of 114 dB at a distance of 4 ft for a nominal
electric power of 1 watt. The performance evaluation
of this loudspeaker at the listening positions depicted
in Fig. 18-62 consists of evaluating the direct sound
levels at the respective seating positions and deter-
mining the %ALCONS at these same positions.
The propagation distances to the various posi-
tions introduce a 
 attenuation given by
 where Di corresponds to the
respective listener distance. For those listeners not
on the axis of the loudspeaker, there is an additional
attenuation that must be obtained by consulting the
polar response curves of the loudspeaker.
In this particular instance only the vertical polars
are involved. The direct sound level at each position
with one watt of excitation is then given by adding
114 dB to the total attenuation while remembering that
the total attenuation is a negative value. The appro-
priate values are displayed in the following table.
The difference between the highest and lowest
sound level is less than 3 dB and is quite acceptable.
Now it is necessary to determine the %ALCONS at the
various listener positions. In order to do this it is
necessary to have values for the loudspeaker Q in
the direction of the listener in question. The Q for
the most distant listener whose location is on axis is
just the axial Q value of 18 for the loudspeaker in
question. For the intermediate listener as well as the
nearest listener the appropriate Qs can be calculated
by making use of the polar attenuation data.
The polar attenuation data tells one how much
the sound intensity is reduced in the given angular
direction. The governing equation is
(18-118)
where,
Qθ, ϕ is the Q in the specified direction,
QAXIAL is the axial Q,
A is the attenuation in the specified angular
direction.
Once the various Qs have been calculated, one
may determine the %ALCONS from
(18-119)
The results for the case in hand appear in the
following table.
The maximum value of articulation loss is less
than 15% thus indicating acceptable behavior. Based
on the examination so far, the single loudspeaker
solution appears to be satisfactory, as indeed it
would be if all listeners were seated only on the
centerline.
The seating pattern in this space is fan shaped
being 50 ft wide at the rear tapering to 25 ft wide at
the front. From both of the above tables, it appears
that the nearest row will constitute the most severe
problem. The outermost seat on the front row is 28ft
from the loudspeaker and thus has an increased
distance attenuation of −16.9 dB. Furthermore this
position is even further off axis of the loudspeaker
such that the polar curves indicate an angle
attenuation which has now become −15.8dB. The
sound level at this seat is thus reduced to
(114 −16.9 −15.8) dB = 81.3 dB. The Q in the direc-
tion of this seating position from Eq. 18-118 now
becomes only 0.47. The articulation loss at this seat
as calculated from Eq. 18-119 is found to be 40%!!
Clearly, a single loudspeaker cannot adequately
supply reinforcement in this space. This space is a
candidate for a loudspeaker array type of solution.
When faced with such a problem, the recommended
practice is to employ a computer based loudspeaker
design program. Not only will such programs save
time in calculation, they also feature other important
advantages.
An outstanding characteristic of such programs is
the built-in loudspeaker database containing detailed
information on polar response characteristics and
other important operational parameters for
commonly applied loudspeakers and loudspeaker
systems. Additionally, provisions are made for
updating the database or entering data manually.
Many such programs feature extensive documenta-
tion capabilities for plotting both coverage and intel-
ligibility patterns. Regardless of whether one is
employing manual calculation or a computer based
Listener Position
Distance 
Attenuation
Polar
Attenuation
Net Sound 
Level
Most Distant
−28.0 dB
0.0 dB
86.0 dB
Intermediate
−22.0 dB
−3.6 dB
88.5 dB
Nearest
−15.9 dB
−12.3 dB
85.8 dB
1 r
⁄
20 dB
4 Di
⁄
(
)
log
Qθ ϕ
,
QAXIAL10
A
10
------
=
Position
Polar Attenuation Q Value
%ALCONS
On Axis
0.0 dB
18.00
13.5%
12° Below Axis
−3.6 dB
7.86
7.7%
41° Below Axis
−12.3 dB
1.06
14.3%
%ALCONS
656 D
(
)2 RT60
(
)2
Qθ ϕ
,
(
) V
( )
----------------------------------------
=

   
Loudspeakers and Loudspeaker Arrays
395
design program, it is necessary to have knowledge
of successful loudspeaker array techniques.
Arraying Techniques
Arraying techniques are many and varied. Many of
the early techniques evolved through trial and error.
In more recent times the approach has become more
increasingly based upon the physics of wave propa-
gation. This became particularly true following the
ready availability of computers capable of solving
complicated wave propagation problems associated
with multiple sources. In modern times, inexpen-
sive digital signal processing techniques have made
possible very versatile and finely tuned arrays
whose characteristics can be modified under
computer control.
Increase Coverage Angle
There are two well-recognized techniques for
increasing coverage angle. These are stack and splay
and trapezoidal array. The stack and splay can be
applied to loudspeakers in general while the trape-
zoidal array is best applied to loudspeakers having
an enclosure construction purposely designed for the
application of this particular technique. Fig. 18-64
illustrates the stack and splay technique as applied to
two alike constant directivity horns.
Even though the illustration is drawn for horns,
the technique is applicable to any loudspeaker
system that possesses a well-defined acoustic center.
An increase of horizontal coverage angle is obtained
by splaying the loudspeakers about a vertical axis
passing through the acoustic centers of both devices.
Alternatively, an increase of vertical coverage
angle is obtained by splaying the loudspeakers about
a horizontal axis passing through the acoustic centers
of both loudspeakers. In both instances the angle of
splay is the total angle between the central axis of
each loudspeaker and is set equal to the common
nominal coverage angle of each loudspeaker. This
arrangement allows the radiation patterns of the indi-
vidual loudspeakers to overlap at the half pressure
points of the individual loudspeakers.
For the combination when so arrayed, the angle
between the half pressure points of the combination
will be just twice the nominal coverage angle of
each loudspeaker in the plane of splay. To be
specific, suppose one is splaying two devices each
having a nominal coverage of 60° horizontal by 40°
vertical with the objective of doubling the horizontal
coverage angle to 120°.
One first stacks one device above the other
followed by a rotation of one device clockwise
through an angle 30° about a vertical axis passing
through its acoustic center. Finally, the second
device is rotated counter-clockwise through an angle
of 30° about this same vertical axis. As observed in
the far field, the horizontal coverage will now be
120° while the vertical coverage, though not as
smooth as for an individual device, will approximate
the original value of 40°.
The trapezoidal or trap array requires a loud-
speaker system construction such that the acoustic
centers of the devices in the plane of the array are
located very near the rear of the loudspeaker system
enclosures. The enclosures themselves have trape-
zoidal cross sections with the side angles being each
equal to one-half of the coverage angle of the indi-
vidual devices in the plane of the array. If the trap
construction involves a constant directivity horn, the
horn must be so oriented that its smaller coverage
angle is in the plane of the array as the acoustic
center for the smaller angle is the one closer to the
rear of the horn. Fig. 18-65 depicts such an array of
three trap elements each having a coverage angle of
40° horizontally by 60° vertically. The total coverage
angle in the plane of such an array would be 120°.
With the arrangement of Fig. 18-65, the acoustic
centers of the devices, though on a tight circular arc,
are not coincident on the splay axis. In this arrange-
ment, then, the combined coverage about the splay
axis is reasonably smooth though not perfect
whereas the vertical coverage is unperturbed from
the original value.
Increase of Level on Axis
In those instances where insufficient acoustic
pressure can be obtained from a single device, it is
Figure 18-64. Stack and splay as applied to constant
directivity horns.

396
Chapter 18
possible to stack two or more devices one above the
other or to array two or more devices side by side. In
both instances, the devices are alike and the device
axes must be parallel. The physics and mathematics
underlying this process will be explored in detail, as it
will also be required in the study of line arrays.
Fig. 18-66 depicts a stack of two devices though any
number might be employed through simple extension.
The objective is to determine an expression for
the total acoustic pressure at the point O in terms of
the variables r, θ, and the transducer properties. If
the upper and lower transducers were simple sources
of spherical waves, their individual acoustic
pressures at O would be
(18-120)
where,
A1 and A2 are the individual transducer amplitude
factors,
ϕ1 and ϕ2 are arbitrary individual phase factors.
The total acoustic pressure at O is then the
phasor sum of p1 and p2. When the objective is
simply an increase of level, the individual amplitude
factors are set equal and denoted by A while the
individual phase factors are set equal to 0. Addition-
ally, one examines the results in the far field where r
is very much larger than d. When this is the case, it
is possible to obtain a relatively simple expression
for the total pressure through the following analysis.
Upon applying the law of cosines to the two trian-
gles of Fig. 18-66, the individual radial distances
can be written exactly as
(18-121)
Noting that r is very much larger than d, the above
equations may be written with very little error as
(18-122)
From the binomial theorem, it is known that the
square root of one plus a quantity small compared
with one is very nearly equal to one plus one-half of
the small quantity. Therefore, Eq. 18-122 becomes
(18-123)
If one sets the source amplitudes equal and sets
the individual phase factors to zero, then substitu-
tion of Eq. 18-123 into Eq. 18-120 yields
(18-124)
Now, in the denominators of Eq. 18-124 in each
instance the second term is much smaller than the
first and can be neglected with little error. Further-
more, the common terms in the exponential can be
factored producing the result
Figure 18-65. Three element trap array of 40° devices.
Figure 18-66. A stack of two devices for increasing
acoustic pressure.
40°
40°
r1
r2
r
θ
d
O
p1
A1
r1
------e
j ωt
kr1
–
ϕ1
–
(
)
=
p2
A2
r2
------e
j ωt
kr2
–
ϕ2
–
(
)
=
r1
2
r2
d2
4-----
rd
θ
( )
sin
+
+
=
r2
2
r2
d2
4-----
rd
θ
( )
sin
–
+
=
r1
r 1
d
r---
θ
( )
sin
+
≈
r2
r 1
d
r---
θ
( )
sin
–
≈
r1
r
d
2---
θ
( )
sin
+
≈
r2
r  d
2---
–
θ
( )
sin
≈
p1
A
r
d
2---
θ
( )
sin
+
----------------------------e
 j ωt
k r
d
2---
θ
( )
sin
+
–
⎝
⎠
⎛
⎞
=
p2
A
r
d
2---
θ
( )
sin
–
---------------------------e
 j ωt
k r
d
2---
θ
( )
sin
–
–
⎝
⎠
⎛
⎞
=

   
Loudspeakers and Loudspeaker Arrays
397
(18-125)
The total pressure is the phasor sum of p1 and p2 that
can now be written as
(18-126)
One final simplification is now possible. Recall
that from Euler’s identity, e jx = cos(x) + jsin(x) and
e–jx = cos(x) − jsin(x). Upon applying this to
Eq. 18-126, the result appears as
(18-127)
The acoustic pressure of Eq. 18-127 is the
product of three distinctly different factors. The first
factor, 
, is essentially an amplitude term. The
factor, 
, is a directional modi-
fier of the amplitude and as such is a directivity
term. Lastly, the factor 
 is a complex
exponential that describes wave propagation and has
a magnitude that is always one. Information with
regard to the pressure variation with regard to
source strength, radial distance, direction, and
frequency is all contained in the product of the first
two factors. At the outset it was assumed that the
two sources were simple spherical radiators with no
directional characteristics of their own. In practice,
each of the identical sources would have a direc-
tional characteristic in the plane of the array that in
this instance is the vertical plane. As the devices are
separated by only a small distance and observations
are being made in the far field, the angle between
either loudspeaker’s principal axis and its own
radial line is negligibly different from the angle θ.
Upon denoting this common directional character-
istic or vertical polar behavior as f (θ), the acoustic
pressure amplitude of the two source arrays can now
be written as
(18-128)
The pressure amplitude of Eq. 18-128 differs from
the corresponding equation for a single device
located at the origin in two significant ways. Firstly,
the on axis pressure is twice as large and secondly,
there is an additional directivity term that accounts
for the interference between two sources that are not
equidistant from the observer for all non-axial points.
At low frequencies, where k is small, and for
small spacing between transducers, where d is small,
this additional directivity term is nearly unity for all
values of the polar angle. Above a critical frequency
when the wavelength first becomes 2d, this addi-
tional directivity term takes on more and more
significance. As an example, consider two devices
separated by a distance of 0.344 m (a little more than
one foot) with each device having a half space
vertical coverage angle of 40°. The critical
frequency corresponding to this spacing is 500 Hz.
Fig. 18-67A displays the vertical polar behavior of
each device. Fig. 18-67B, C, and D display the array
polar behavior at the critical frequency, at one
octave, and two octaves above the critical frequency.
Below the critical frequency, the array vertical
polar behavior is that of a single device from which
the array is formed. At the critical frequency there is
a small narrowing of the single lobe associated with
the array vertical polar behavior. One octave above
the critical frequency the central lobe is narrowed
further and side lobes are first becoming evident.
Two octaves above the critical frequency the side
lobes have become significant and the central lobe is
narrower still. Further increases in operating
frequency bring about an exacerbation of this
behavior with more numerous side lobes bordering
an increasingly narrow central lobe. In this region,
f(θ) serves only as an envelope of the multi-lobe
pattern. A successful application of this technique at
high frequencies will require high frequency devices
that are physically small in order to achieve small
device spacing thus making possible a large value
for the critical frequency.
In the median horizontal plane, an observer is
equidistant from each device and there is no depar-
ture from the normal horizontal directivity associ-
ated with each device. Many full range loudspeaker
systems employ two bass, two mid range, and two
high frequency devices. When this is the case, the
bass loudspeakers are positioned at the extremities
of the enclosure. The large separation being toler-
ated as the critical frequency is above the bass loud-
speaker pass band.
The mid range speakers are sandwiched between
the bass units and the high frequency units are sand-
wiched between the mid range devices. This
arrangement allows medium spacing for the mid
range and small spacing for high frequency devices
thus allowing reasonable though not perfect opera-
tion of all devices in their respective pass bands.
p1
A
r---e
jk
–
d
2---
θ
( )
sin
e j ωt
kr
–
(
)
=
p2
A
r---e
jkd
2---
θ
( )
sin
e j ωt
kr
–
(
)
=
p
A
r--- e
jk
–
d
2---
θ
( )
sin
e
jkd
2---
θ
( )
sin
+
⎝
⎠
⎜
⎟
⎛
⎞
=
e j ωt
kr
–
(
)
p
2A
r-------
kd
2---
θ
( )
sin
e j ωt
kr
–
(
)
cos
=
2A r
⁄
k d 2
⁄
(
)
θ
( )
sin
[
]
cos
e j ωt
kr
–
(
)
pm
2A
r-------f θ
( )
kd
2---
θ
( )
sin
cos
=

398
Chapter 18
18.14 Bessel Array
The Bessel array is another technique for increasing
the attainable pressure level. This technique is not
efficient from a power point of view but offers the
distinct advantage that the array has a coverage
pattern that is essentially identical to that of the indi-
vidual loudspeakers constituting the array and
without any frequency limitations. The successful
operation of the array requires that all listeners truly
be in the far field of the array. The far field require-
ment restricts Bessel arrays that are physically large
(several feet in extent) to employment in large
indoor arenas or in outdoor stadiums.
The Bessel array was first commercialized by
Philips Corporation. The name of the array stems
from the fact that the individual device amplitudes
must have ratios mimicking those possessed by a
sequence of Bessel functions. Bessel functions are
solutions of Bessel’s differential equation and were
encountered previously with regard to the piston
impedance and directivity functions. Bessel func-
tions, when displayed graphically, have the general
appearance of decaying sines or cosines though they
are not periodic as are sinusoids. Bessel functions of
various orders have been tabulated and can be
generated by macros in most computer based math
programs.
There are a variety of arrangements of devices
for constituting a Bessel array. The most practical
arrangement consists of five devices. The indi-
vidual devices may in fact be full range loud-
speakers but must be of the same type. The five
devices may be arrayed either vertically or horizon-
tally with the principal axes of the devices being
exactly parallel. Fig. 18-68 depicts such a five
element vertical array. The figure is not drawn to
true scale for to do so would lose sight of speaker
placement detail.
Figure 18-67. Array vertical polar behavior.
Device Polar Directivity
1.0
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
 
−100 −80 −60 −40 −20 0 20 40 60 80 100
Vertical polar angle
 
−100 −80 −60 −40 −20 0 20 40 60 80 100
Vertical polar angle
 
−100 −80 −60 −40 −20 0 20 40 60 80 100
Vertical polar angle
 
−100 −80 −60 −40 −20 0 20 40 60 80 100
Vertical polar angle
Polar Behavior at 500 Hz
Polar Behavior at 1000 Hz
Polar Behavior at 2000 Hz
2
1.8
1.6
1.4
1.2
1
0.8
0.6
0.4
0.2
0
2
1.8
1.6
1.4
1.2
1
0.8
0.6
0.4
0.2
0
2
1.8
1.6
1.4
1.2
1
0.8
0.6
0.4
0.2
0
A. Vertical polar behavior of each device.
B. Array vertical polar behavior at the critical frequency.
C. Array vertical polar behavior one octave
above critical frequency.
D. Array vertical polar behavior two octaves
above critical frequency.
Magnitude
Pressure relative to single device
Pressure relative to single device
Pressure relative to single device

   
Loudspeakers and Loudspeaker Arrays
399
The observer at point 0 is positioned in the far
field where all of the radial distances in the figure are
very large compared with the dimensions of the
array. Furthermore, the angle between any radial line
and the principal axis of its respective device departs
from the value θ by a negligible amount. The direc-
tivity function common to each device is f (θ,ϕ).
After applying the same type of analysis that was
employed in treating the two element’s array but
now considering the angle to be negative as drawn,
the total acoustic pressure at point 0 is found to be
(18-129)
The As in Eq. 18-129 are amplitude coefficients
that are proportional to the drive signals applied to
the individual loudspeakers. The objective at this
point is to find a magic assignment of amplitude
coefficients that will make the term in the brackets
equal to a constant or nearly so. This is the point at
which Bessel functions enter the picture. One of the
identity properties of Bessel functions can be
expressed as
(18-130)
In the above equation, x and α are any real inde-
pendent variables. Eq. 18-130 requires a sum over
an infinite number of terms in order for the absolute
magnitude of the sum to take on an exact value of
unity. A useful though not quite exact result can be
obtained by employing only five terms from this
infinite sum and placing them in correspondence to
the sum of the five terms in Eq. 18-129. Upon
setting α equal to (kdsinθ), the five terms from the
sum of Eq. 18-130 are
(18-131)
The argument of the Bessel functions is the inde-
pendent variable x with x allowed to take on any
arbitrary real value. The task at this point is to find a
value of x for which the ratios of the values of the
various Bessel functions form a useful and conve-
nient sequence. This may be accomplished by trial
and error or more realistically by overlaying plots of
the various functions versus x. Upon taking the latter
approach it is found that if x is assigned the value of
1.5 then
(18-132)
When this assignment is made in Eq. 18-129 the
result can be written as
(18-133)
Now if one applies Euler’s identity to the expo-
nential terms in the bracket and collects terms, the
pressure expression can be written as
(18-134)
The factor before the bracket in Eq. 18-134
describes a pressure wave of double strength
emanating from a single loudspeaker having all of
the usual directional and frequency characteristics of
the radiating device. It remains only to explore the
behavior of the bracketed expression. The expres-
sion in the brackets can be written as a complex
exponential that expresses both the magnitude and
phase behavior of the expression. Denoting this as a
function D with D depending on d, k, and polar
angle θ, the result is
(18-135)
Figure 18-68. Five elements Bessel array.
0
θ
r2
r1
r
r3
r4
A2
A1
A
A3
A4
d
p
f θ ϕ
,
(
)
r
----------------e j ωt
kr
–
(
) A4e 2jkd
θ
sin
–
A3e jkd
θ
sin
–
A
A1e jkd
θ
sin
A2e2jkd
θ
sin
+
+
+
+
[
]
=
Jn x
( )e jnα
n
∞
–
=
n
∞
=
∑
1
=
J 2
–
x
( )e 2jkd
θ
sin
–
J 1
–
x
( )e jkd
θ
sin
–
+
+
J0 x
( )
J1 x
( )ejkd
θ
sin
J2 x
( )e2jkd
θ
sin
+
+
J 2
–
1.5
(
) : J 1
–
1.5
(
) : J0 1.5
(
) : J1 1.5
(
) : J2 1.5
(
)
0.5 : 1 : 1 : 1 : 0.5
–
≈
p
A
r---f θ ϕ
,
(
)e j ωt
kr
–
(
) 0.5e 2jkd
θ
sin
–
1
– e jkd
θ
sin
–
1
1e jkd
θ
sin
0.5e2jkd
θ
sin
+
+
+
[
]
=
p
2A
r-------f θ ϕ
,
(
)e j ωt
kr
–
(
)
⎝
⎠
⎛
⎞×
=
cos2 kd
θ
sin
(
)
j
kd
θ
sin
(
)
sin
+
[
]
D d k θ
, ,
(
)
Me jΦ
=
cos4 kd
θ
sin
(
)
sin2
+
kd
θ
sin
(
)
=
e
ja
kd
θ
sin
(
)
sin
cos2 kd
θ
sin
(
)
---------------------------------
⎝
⎠
⎛
⎞
tan
⎝
⎠
⎜
⎟
⎜
⎟
⎛
⎞
×

400
Chapter 18
One can readily evaluate both the magnitude and
the phase of D for the on axis position where θ is
zero. For θ = 0, sinθ = 0 making the radical expres-
sion, and consequently M have the value unity at all
frequencies. Remember that the frequency enters
through the appearance of k as k = ω ⁄c = 2πf ⁄c.
Additionally, when θ = 0, the angle Φ or phase of D
is zero at all frequencies. In summary, for those
listeners located on axis, D plays no role whatso-
ever. For observers located off axis, the magnitude
of D will ripple between unity and 0.866 in a contin-
uous fashion as the operating frequency increases.
This is of little concern as this variation amounts
to only 1.25 dB peak to peak. Of perhaps more
concern, though apparently undetected by most
observers, is that the phase of D also ripples contin-
uously between plus and minus π/2 or 90° as the
operating frequency increases. The rapidity of this
variation is more pronounced for larger device sepa-
ration. This behavior is displayed in Figs. 18-69 and
18-70 where the device spacing is 0.6 m (about 2ft)
and the polar angle is fixed at 45°.
The required voltage drive to the elements
constituting the Bessel array of Fig. 18-68 may be
accomplished by employing a single amplifier to
drive all five loudspeakers or by using five indi-
vidual amplifiers. Recall that A4 and A2 must present
half value amplitudes. This can be accomplished by
connecting these two devices in series before
connecting the combination to a single amplifier or
by using two amplifiers with each being attenuated
by 6 dB. A3 must present full value amplitude with
negative polarity. The connections to this element
then require just a reversal of polarity. A1 and A
must present full amplitude with normal polarity. A,
A1, and a reversed polarity A3 can be placed in
parallel with the series connected A2 and A4 with the
entire combination being connected to a single
power amplifier.
Alternatively, one can employ individual ampli-
fiers for each element in the array. This would
require two amplifiers attenuated by 6 dB with
normal polarity, two unattenuated amplifiers with
normal polarity, and one unattenuated amplifier with
reversed polarity.
18.15 Line Arrays
A true continuous line source is modeled as depicted
in Fig. 18-71. The construction is that of an elon-
gated cylinder of small radius wherein the radius
alternatively expands and contracts by a small
amount about its nominal value. If the cylinder were
infinitely long, this would be a source of cylindrical
waves for which the attenuation rate with perpendic-
ular distance from the cylinder would be 3 dB for
each doubling of the distance.
Even with a cylinder of finite length, when
observations are made in the median plane close to
the cylinder this same attenuation rate is found to be
true. At larger distances, however, the attenuation
rate transitions to the far field value of 6 dB for
doubling of distance typical of any small source
having in phase surface velocity. The distance at
which the far field begins depends on both the
length of the continuous line source and the oper-
ating frequency. A simple analysis provides an
insight on where the far field begins. Consider the
situation depicted in Fig. 18-72.
For the observation point depicted in the figure,
radiation from the end of the source must travel a
distance that is 
 greater than that traveled from
Figure 18-69. Ripple in Bessel array off-axis amplitude
response.
 
1000 
 
2000 
 
3000 
 
4000 
 5000
Frequency
Magnitude Behavior of D
1.0
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
500
Magnitude
Figure 18-70. Ripple in Bessel array off-axis phase
response.
 
1000 
 
2000 
 
3000 
 
4000 
 5000
Frequency
Phase Behavior of D
100
80
60
40
20
0
−20
−40
−60
−80
−100
500
Phase in degrees
λ 4
⁄

   
Loudspeakers and Loudspeaker Arrays
401
the center of the source. These two component radi-
ations differ in phase by 90° and hence combine
quadratically rather than linearly. This addition is
still constructive as the phasor sum is greater than
the individual component values. On the other hand,
if the observation point is moved to a position
slightly closer to the source thus shortening r, the
arc will now intercept the line drawn between the
end of the source and the new observation point at a
distance that slightly exceeds 
. The phase
difference between the two component radiations
now will exceed 90° by a small amount and the
phasor sum will be less. By the contrary argument,
for observation points more remote than those indi-
cated in the figure, the phase difference tends to zero
as r is progressively increased. The present position
of O defines the transition point between the near
and far fields for the continuous line source. A rela-
tionship among the pertinent quantities is obtained
by applying the Pythagorean Theorem to the triangle
in the figure.
(18-136)
As will soon be learned, successful employment
of line arrays requires that the array length is equal to
or exceeds the wavelength throughout the operating
frequency range. This allows the extraction from
Eq. 18-136 of the following approximate statement
of the radial distance at which the far field begins.
(18-137)
The length of the array, L, is dictated by the
lowest operating frequency where the wavelength is
the largest. The radial distance constituting far field
operation, however, is proportional to the operating
frequency, being quite large where the wavelength is
the least. These results will be of importance later
when continuous line sources are approximated by
arrays of discrete loudspeaker elements.
The items of interest to the sound system practi-
tioner are the acoustic pressure amplitude and the
directivity characteristics of a line source built up
with a discrete collection of loudspeakers. More
importantly, perhaps, are answers to the questions
relating to how to arrange a collection of loud-
speakers so as to obtain a particular pressure ampli-
tude and coverage pattern in a given direction.
Interestingly, this is best pursued by studying
continuous line sources and then modifying the
results to accommodate a discrete source collection.
Fig. 18-73 is the starting point for calculating the
acoustic pressure produced in the far field by a
continuous line source of finite length.
In Fig. 18-73 the shaded infinitesimal cylinder
has a nominal radius a and a lateral surface area of
2πadx. This cylindrical element is alternately
expanding and contracting a small amount about its
Figure 18-71. Continuous line source.
Figure 18-72. Far field calculation aid. 
L
L
r
λ/4
0
r
λ 4
⁄
L
2 
----
⎝
⎠
⎛
⎞
2
r2
+
r
λ
4 
----
+
⎝
⎠
⎛
⎞2
=
Figure 18-73. Continuous line source.
r
L2
2λ
------
≥
L/2
−L/2
θ
r
x
O
dx
x
r'

402
Chapter 18
nominal radius such that its surface velocity is
represented by the phasor u = ume jωt. The accelera-
tion attendant to this motion is jωu. This element
produces an infinitesimal acoustic pressure whose
phasor description at the observation point O is
given by
(18-138)
The total acoustic pressure at the observation
point involves integrating the above expression over
the entire length of the line. Recalling that k = ω/c,
the integral expression becomes
(18-139)
The observation point is taken to be in the far
field where r' ≈ r − xsinθ. Upon making this substi-
tution, the integral becomes
(18-140)
Note that in writing Eq. 18-140 r' in the denomi-
nator has been replaced simply by r. This is justified
because in the far field the very small difference
between r' and r makes an insignificant difference in
the amplitude. On the other hand this small differ-
ence may be significant as compared with the wave-
length and may cause an appreciable phase shift.
This requires that the complete expression for r' be
employed in the exponential expression. The inte-
gration can be readily performed to obtain the result
(18-141)
The significant results of the calculation are
twofold. Firstly, the pressure amplitude for all far
field points in the median plane where θ = 0 is just
the magnitude of the leading factor in the equation.
(18-142)
Secondly, the radiation in the far field is also
controlled by a directivity function D(θ) where
(18-143)
The function (sin α)/α is an often encountered
function known as sinc α. A plot of this function
conveniently displays the general behavior of the
directivity associated with a continuous line
radiator. This plot is presented in Fig. 18-74.
The more conventional manner of examining the
directivity is by viewing polar plots of the absolute
magnitude of the directivity versus the polar
angle θ. This is done in the following sequence
presented in Fig. 18-75 wherein the emphasis is on
the relationship between the line length L and the
wavelength of the radiation emitted.
The far field radiation from a continuous line
radiator whose length is much shorter than the
wavelength at its operating frequency is isotropic.
This means that the radiation pattern in the far field
is the same at all angles with no control of direc-
tivity. When the operating frequency is increased to
the point that the radiator length is the same as the
wavelength as depicted in Fig. 18-75A, directivity is
well established with exactly just a single central
lobe. The pattern in three dimensions would be
obtained by rotating the figure about a line through
the 90° and 270° positions. This line is the same as
the axis of the continuous line radiator.
dp
ρ0jωum2πadx
4πr′
-----------------------------------e j ωt
kr′
–
(
)
=
p r′ t,
(
)
jρ0cumka
2
-----------------------
e j ωt
kr′
–
(
)dx
r′
-----------------------------
L
–
2
------
L
2---
∫
=
p r θ t
, ,
(
)
jρ0cumka
2r
-----------------------e j ωt
kr
–
(
)
e jkx
θ
sin dx
L
–
2------
L
2---
∫
=
p r θ t
, ,
(
)
jρ0cumakL
2r
---------------------------
1
2---kL
θ
sin
⎝
⎠
⎛
⎞
sin
1
2---kL
θ
sin
----------------------------------
⎝
⎠
⎜
⎟
⎜
⎟
⎜
⎟
⎛
⎞
e j ωt
kr
–
(
)
=
Figure 18-74. The behavior of the sinc function.
pm r( )
ρ0cumakL
2r
-------------------------
=
D θ
( )
α
sin
α
-----------
=
1
2---kL
θ
sin
⎝
⎠
⎛
⎞
sin
1
2---kL
θ
sin
----------------------------------
=
1
0.8
0.6
0.4
0.2
0
−0.2
−0.4
 
0 
1 
2 
3 
4 
5 
6 
7 
8 
9 
10
α in units of π
sinc(α)

   
Loudspeakers and Loudspeaker Arrays
403
In Fig. 18-75B, the operating frequency has been
doubled so that the line has become two wave-
lengths long. The pattern now contains a narrower
central lobe bordered by two side lobes. This trend
continues in Fig. 18-75C and 18-75D wherein
raising the operating frequency further narrows the
central lobe and introduces more side lobes.
Obviously, a uniformly excited continuous line
source is not a constant directivity device. It could
be made so, however, if its length could be altered
such that it was inversely proportional to the oper-
ating frequency. This cannot be accomplished in a
practical sense but it does suggest a possible alterna-
tive. Suppose it were possible to vary the drive
amplitude as a function of position along the line.
One out of many possibilities would be to linearly
taper the drive amplitude in both directions from the
center such that the drive amplitude falls uniformly
from a maximum at the center to zero at x = ±L ⁄ 2.
The calculation of Eq. 18-140 must now be
repeated with the positional dependent amplitude
function included under the integral. This results in
a modified directivity function given by
(18-144)
The polar pattern of this new directivity function
appears in Fig. 18-76. This figure is to be compared
with Fig. 18-75B.
D θ
( )
1
4---kL
θ
sin
⎝
⎠
⎛
⎞
sin
1
4---kL
θ
sin
----------------------------------
⎝
⎠
⎜
⎟
⎜
⎟
⎜
⎟
⎛
⎞
2
=
Figure 18-75. Continuous line polar patterns for various wavelengths.
90
60
30
0
330
300
270
240
120
1
0.8
0.6
0.2
0.4
90
60
30
0
330
300
270
240
210
180
150
120
1
0.8
0.6
0.2
0.4
90
60
30
0
330
300
240
210
180
150
120
1
0.8
0.6
0.2
0.4
90
60
30
0
330
300
240
210
180
150
120
1
0.8
0.6
0.2
0.4
270
270
A. Line length = λ
B. Line length = 2λ
C. Line length = 3λ
D. Line length = 4λ
210
180
150

404
Chapter 18
In comparing the two figures it should be noted
that linear amplitude tapering offers the dual bene-
fits of greatly attenuating the side lobes while simul-
taneously widening the main lobe.
Line Array of Discrete Elements
Continuous line arrays are mostly theoretical
constructs as the technology necessary to the
construction of a truly continuous line array does
not presently exist. The conclusions drawn from a
study of continuous line arrays do provide useful
guidance toward the construction of line arrays of
discrete elements.
The study of the continuous line showed that the
line length had to be comparable to the wavelength
at the lowest operating frequency in order to obtain
directional control. On the other hand, when the line
is several wavelengths long, the central lobe
becomes quite narrow with significant acoustic
energy going into a multiplicity of side lobes.
Furthermore, the study of the interaction of just two
discrete devices concluded that the device spacing
needed to be comparable to the wavelength at the
highest frequency of operation.
These conclusions, when taken together, suggest
that separate distinctly designed arrays be employed
for low, mid, and high frequency portions of the
spectrum. Fortunately the design equations are the
same regardless of the frequency range to be
covered. The number of discrete elements, size of
element, and element spacing will vary, however,
depending on the frequency range involved.
Fig. 18-77 depicts the spatial description of a
generic discrete element line array. The total number
of elements involved is arbitrary. It is assumed,
however, that the elements have identical properties.
The black circles in Fig. 18-77 represent discrete
loudspeakers that may be in individual enclosures or
all mounted in a common enclosure. In either event
all of the loudspeakers possess a common directivity
function D(θ, ϕ) that is independent of the direc-
tivity function brought about by their physical
arrangement in a line. Each of the loudspeakers may
in fact be horn loaded for example. In the first
approach to this problem it will be considered that
the line is operating without any processing. This
means that each source is driven with the same
strength and all sources are driven in phase. The
acoustic pressure produced at a far field observation
point O located in the plane of the figure by any
individual source is then
(18-145)
In writing the second of Eq. 18-145 use has been
made of the fact that rn ≈ r0 − ndsinθ and the usual
far field substitutions were made. The total acoustic
pressure at the observation point is the phasor sum
of the individual contributions expressed as
(18-146)
Figure 18-76. Amplitude tapered line of length 2λ.
90
60
30
0
330
300
270
240
210
180
150
120
1
0.8
0.6
0.2
0.4
Figure 18-77. Generic line array of N elements.
(N−1)/2
4
3
2
1
0
−1
−2
−3
−4
−(N−1)/2
r3
r0
r−3
θ
0
N = Total number of elements
n  = Individual element identifier
d  = Distance between elements
pn
A
rn
----D θ,ϕ
(
)e
j ωt
krn
–
(
)
=
A
r0
----D θ ϕ
,
(
)e
j ωt
kr0
–
(
)
e jnkd
θ
sin
≈
p r0 t θ ϕ
, , ,
(
)
A
r0
----D θ ϕ
,
(
)e
j ωt
kr0
–
(
)
e jnkd
θ
sin
n
−N
1
–
(
)
2
----------------------
=
n
+ N
1
–
(
)
2
---------------------
=
∑
⎝
⎠
⎜
⎟
⎜
⎟
⎜
⎟
⎜
⎟
⎛
⎞
≈

   
Loudspeakers and Loudspeaker Arrays
405
Through the use of Euler’s identity and some
trigonometric identities the summation can be
carried out to produce the result
(18-147)
The quantity of interest to most observers is the
acoustic pressure amplitude as it depends on
distance and direction. This can be extracted from
Eq. 18-147 and can be written as
(18-148)
where,
.
(18-149)
Dl (θ) is the directivity function of the line array
itself independent of other factors. The two direc-
tivity factors D(θ, ϕ) and Dl (θ) can independently be
positive or negative. This is the reason for the abso-
lute magnitude symbol, | |, bracketing the right hand
of Eq. 18-148 as the pressure amplitude is always
positive. Additionally, the expression for Dl(θ)
appearing in Eq. 18-149 is valid for any number of
elements composing the array as long as the
elements are identical, in phase, and of equal ampli-
tude. The directional behavior of such an array is
best viewed as a polar plot of the absolute magni-
tude of Dl(θ) versus the angle θ. Such plots are
presented in Fig. 18-78.
In Fig. 18-78A through 18-78D the operating
frequency is successively increased in octave steps.
In Fig. 18-78A, the operating wavelength is twice
the length of the array and there is little directional
control. In Fig. 18-78B where there is equality
between line length and operating wavelength,
directional control is well established except for the
small side lobes. The trend of a narrowing main lobe
with increasing number of side lobes as the oper-
ating frequency continues to increase is evidenced in
Fig. 18-78C and 18-78D.
The desirable attribute of the line array to this
point is simply that the maximum acoustic pressure
amplitude in the main lobe is N times that produced
by a single source. Fortunately, however, the ready
availability of digital signal processing technology
affords many tools for improving the behavior of
discrete element line arrays. These features will be
explored in the next section.
Processed Line Arrays
The availability of economical programmable
digital signal processing circuitry as well as compact
power amplifiers makes possible the complete
tailoring of the drive signal applied to each element
of an extended line array. The drive signals to the
individual elements can be separately filtered,
equalized, delayed, adjusted for level, and ampli-
fied before application to the individual trans-
ducers. This flexibility allows the shaping of the
beam width of the radiation pattern of the array, the
steering of the beam over a range of directions,
focus of the beam at a particular point in space, and
adjustment of the effective line length as a function
of frequency. These properties will be explored
through a sequence of examples beginning with
beam steering. Fig. 18-79 depicts the geometrical
situation in the immediate vicinity of an array of
nine elements where it is desired that the radiation
from the individual elements progresses in phase
along a particular angular direction denoted by a
steering angle θ.s.
From the figure it is apparent the source denoted
as 4 is nearest to the far field point. The source
denoted as 3 is more distant by 
, the source
denoted as 2 is more distant by 
, etc., until
one reaches the source denoted as −4 that is more
distant by 
. The basic incremental radial
distance between elements, Δr, is thus 
. The
basic incremental signal delay between elements is
then Δr⁄c. In order for the signals to progress in
phase in the chosen direction, the most distant
element, −4, must be driven directly, −3 must have a
signal delay of Δr⁄c, −2 must have a signal delay of
2 Δr⁄c, etc. The delay sequence continues in this
fashion until one reaches source 4 where the
required signal delay is 8 Δr⁄c. This procedure can be
applied to an array of an arbitrary number of
elements. When the appropriate delays are inserted
in the summation of Eq. 18-146, the directivity
function associated with the steered line alone
becomes
(18-150)
p r0 t θ ϕ
, , ,
(
)
A
r0
----D θ ϕ
,
(
)e
j ωt
kr0
–
(
)
N
N
2----kd
θ
sin
⎝
⎠
⎛
⎞
sin
N
1
2---kd
θ
sin
⎝
⎠
⎛
⎞
sin
--------------------------------------
⎝
⎠
⎜
⎟
⎜
⎟
⎜
⎟
⎛
⎞
≈
pm r0 t θ ϕ
, , ,
(
)
N A
r0
----D θ ϕ
,
(
)Dl θ
( )
=
Dl θ
( )
N
2----kd
θ
sin
⎝
⎠
⎛
⎞
sin
N
1
2---kd
θ
sin
⎝
⎠
⎛
⎞
sin
--------------------------------------
⎝
⎠
⎜
⎟
⎜
⎟
⎜
⎟
⎛
⎞
≡
d
θs
sin
2d
θs
sin
8d
θs
sin
d
θs
sin
Dl θ
( )
N
2----kd
θ
θs
sin
–
sin
(
)
sin
N
1
2---kd
θ
θs
sin
–
sin
(
)
sin
--------------------------------------------------------------
⎝
⎠
⎜
⎟
⎜
⎟
⎜
⎟
⎛
⎞
≡

406
Chapter 18
Fig. 18-80 illustrates both the unsteered and
steered behavior of an array of nine elements where
the array length is twice the wavelength at the oper-
ating frequency. The angular interval between the
half pressure points of the principal lobe in this
example is about 30°.
The behavior of discrete element line arrays may
be modified in a fashion similar to that employed
with the continuous line array. Modifications are
brought about by changing the amplitude and or the
phase of the exciting signal applied to each element
of the array. Digital signal processing allows the
modifications themselves to be frequency depen-
dent. When properly applied such processing can
make an array segment’s behavior nearly indepen-
dent of the operating frequency. As an example,
when amplitude tapering is applied to the
nine-element array of Fig. 18-80 the improvements
evidenced in Fig. 18-81 result.
Figure 18-78. Eight element unprocessed line array polar behavior.
90
60
30
0
330
300
270
240
210
180
150
120
1
0.8
0.6
0.2
90
60
30
0
330
300
270
240
210
180
150
120
1
0.8
0.6
0.2
90
60
30
0
330
300
240
210
180
150
120
1
0.8
0.6
0.2
90
60
30
0
330
300
240
210
180
150
120
1
0.8
0.6
0.2
0.4
270
270
A. Line length = λ/2
B. Line length = λ
C. Line length = 2λ
D. Line length = 4λ
0.4
0.4
0.4
Figure 18-79. Steered array geometry.
4
3
2
1
0
−1
−2
−3
−4
θs
To far field point
d

   
Loudspeakers and Loudspeaker Arrays
407
Amplitude tapering applied to the nine-element
array greatly suppresses the side lobes formerly
present and increases the beam width from 30° to
45°. As beneficial as amplitude tapering can be it
must also be remarked that amplitude tapering also
reduces the attainable pressure amplitude produced
by the array. Linear amplitude tapering for example
can bring about as much as a 6 dB reduction in
attainable pressure amplitude as compared with a
non-tapered array.
Arrays may be combined with the objective of
producing coverage patterns with adjustable beam
widths. Discrete line arrays of small transducers
may be placed side by side and steered indepen-
dently to produce results similar to those appearing
in Fig. 18-82.
The pattern of Fig. 18-82 is obtained from arrays
of nine elements placed side by side as closely as
possible. The center array is unsteered, the left array
is steered upward through a chosen angle, and the
right array is steered downward through the same
angle. The resulting beam width of the combination
in this instance is 100°.
In summary, line arrays of discrete elements for
employment in the far field operate best when sepa-
rate lines are arranged for the low, mid, and high
frequency ranges. Regardless of the frequency
range, the length of the line determines the low
frequency limit while the high frequency limit is
determined by the minimum obtainable spacing
between line elements. A minimum line length
equal to λ is required to obtain directional control.
Figure 18-80. Steering behavior of an array of nine
elements.
90
60
30
0
330
300
270
240
210
180
150
120
1
0.8
0.6
0.2
90
60
30
0
330
300
270
240
210
180
150
120
1
0.8
0.6
0.2
Unsteered
Steered +20°
0.4
0.4
Figure 18-81. Steered nine-element array after
amplitude tapering.
90
60
30
0
330
300
270
240
210
180
150
120
1
0.8
0.6
0.2
0.4
90
60
30
0
330
300
270
240
210
180
150
120
1
0.8
0.6
0.4
Unsteered
Steered +20°
0.2

408
Chapter 18
Constant directivity operation is possible by altering
the line length inversely with the operating
frequency by means of digital signal processing.
Additional processing principally involving signal
delay and amplitude adjustment versus line element
position allows for beam steering as well as beam
shape adjustment.
Line Arrays in the Near Field
Large line arrays of discrete elements designed for
near field listening are usually composed of several
full range loudspeakers, each of which is
constructed similar to that displayed in Fig. 18-83.
The typical module consists of two 15 in woofers
housed in separate vented enclosures on the extreme
left and right of the assembly. These enclosures
border a mid-range horn featuring several
co-entrantly mounted mid-range cone drivers. The
mid-range horn has a co-axially mounted high
frequency element. The high frequency element
itself is designed to be an approximate continuous
radiator with a height only slightly less than that of
the total enclosure. The structure of the high
frequency element approximates a cylindrical
radiator and can occur in several possible forms. Its
structure might be that of a planar diaphragm
driving a vertical slot radiator, a wave guide driven
by multiple compression drivers, or a continuous
ribbon type tweeter.
When several of these modules are stacked one
above the other the overall vertical extent may well
be several meters in extent. The principal axis of a
vertical array of these modules is the axis perpendic-
ular to the line of the array passing through its
center. The acoustic pressure along this axis falls off
approximately at the rate of 3 dB per doubling of the
distance for observation points in the near field
along this axis. The extent of the near field is
proportional to the frequency as indicated in the
approximate relationship expressed in Eq. 18-137.
Consider an array that has a length of 7 m. An
application of Eq. 18-137 predicts that the near field
for an operating frequency of 5 kHz extends to over
350 m. The corresponding values at 500 Hz and
50Hz would be 35 m and 3.5 m, respectively. Such
an array when elevated above the stage would be
capable of projecting intense mid and high
frequency sound toward the distant nosebleed seats
in a large arena or theatre. This statement is
supported by the following simple analysis. The
distant seating area is tiered. In a typical space the
nearest seating may be at about 60 m with the most
distant at about 80 m. This entire interval is in the
near field zone for high frequencies where the
distance attenuation rate is uniform at 3 dB per
doubling of distance.
This is not the case for the mid frequencies. This
interval is entirely in the far field for the mid-range.
The median distance to the seating area is 70 m. In
the interval from 35 m to 70 m, the mid-range is
attenuated approximately 6 dB while the high range
is attenuated approximately 3  dB. This can be
readily compensated by a simple pre-emphasis of
3dB applied to the mid-range.
The situation is not so happy for the low range.
Between 3.5 m and 35 m, a decade, the low range is
attenuated approximately 20  dB. In this same
interval the mids and highs would have been attenu-
ated by approximately half of this amount or only
10dB. It is not likely that this large discrepancy can
be adequately compensated without encountering
power handling and headroom problems. The sound
in these less expensive nosebleed seats can be quite
intelligible while suffering from a lack of normal
spectral balance.
Many practitioners employ a modification of the
line array discussed above to provide coverage for
the entire seating area of an arena. In this instance
there is a straight line array segment that is usually
tilted so that its principal axis is normal to the tiered
seating plane of the distant nosebleed seats.
Figure 18-82. Array beam width shaping.
Figure 18-83. Full range loudspeaker module.
90
60
30
0
330
300
270
240
210
180
150
120
1
0.8
0.6
0.2
0.4

   
Loudspeakers and Loudspeaker Arrays
409
Attached to the bottom of this straight section is a
curved section that is directed toward the floor
seating area. This lower curved section is composed
of modules identical to those of the straight section.
The curvature of the lower section constitutes a
splay of the modules and affords a wide angular
coverage as a result. The overall structure is termed
a J array because its profile is similar to that of the
letter for whom it is named. This lower portion of
the array features individual drive and equalization
to each of the modules constituting the curved
section so as to produce a fairly uniform sound field
over the entire floor seating space. The space attenu-
ation rate for this curved section falls somewhere
between that of a point source and a line source.
Distributed Systems
Distributed systems are employed in difficult acous-
tical spaces where speech intelligibility cannot be
obtained by any of the foregoing techniques.
Distributed systems raise the %ALCONS by posi-
tioning sources of direct sound closer to the
listeners. As a consequence the operating levels of
the sources can be reduced thereby reducing the
total acoustic power injected in the listening space.
The net effect is an increase in the ratio of the direct
sound level to the reverberate sound level, that in
turn increases intelligibility.
Distributed systems can take many forms
depending upon the conditions of the particular
space involved. In spaces where the seating area is
long with a small width, an inline system of two or
more identical loudspeaker systems displaced along
the central axis and operating with signal delay is a
first consideration. Such a system is sketched in
Fig. 18-84. Where it can be employed, this arrange-
ment offers the advantage of maintaining source
identification.
A related treatment is that which is applicable to
fan shaped seating and is often encountered in some
church construction. In this situation an often viable
solution consists of a central source system attended
by satellite systems displaced along successive
radial arcs. Source identification is still maintained
when appropriate signal delays are applied to the
satellite loudspeakers. A typical plan view is
sketched in Fig. 18-85. For equal area coverage by
each satellite, the number of units employed must
grow as the square of the radial distance from the
origin of the fan.
The most often encountered distributed system is
that of a pattern of overhead loudspeakers. The
important considerations for such systems are
pattern geometry, individual loudspeaker coverage
angle, vertical distance between loudspeaker posi-
tion and listening plane, and loudspeaker coverage
pattern overlap. The starting point in the design of
an overhead distributed system is the footprint that
an individual loudspeaker has in the listening plane.
Most loudspeakers employed in overhead systems
have coverage patterns exhibiting cylindrical
symmetry, i.e., the footprint in the listening plane is
a circle whose radius can be calculated with the aid
of Fig. 18-86.
The loudspeaker sizes employed in overhead
systems are typically 5 inch, 8 inch, 8 inch co-axial,
and 12 inch co-axial units. The coverage angle, α, in
the critical speech range for the 5 inch as well as
both of the co-axial units is usually taken as 90°
Figure 18-84. Inline array elevation view.
Figure 18-85. Satellite distributed system plan view.
Figure 18-86. Single loudspeaker in an overhead
distributed system.
h
H
2r
Loudspeaker
Ceiling or
Mounting plane
Listening plane
a

410
Chapter 18
while that of the 8 inch non-co-axial is closer to 60°.
The radius of the circular footprint of a single loud-
speaker in the listening plane is calculated from
(18-151)
Loudspeaker layout patterns are based upon the
geometrical properties of two regular polygons.
Topological properties dictate that the chosen
regular polygons be either a square or a hexagon.
The implementation involving the square is simpler
while that involving the hexagon affords a larger
loudspeaker density attended by more uniform
coverage. In both instances a choice must be made
as to the degree of loudspeaker pattern overlap. The
choice is usually made among the three presented in
both Figs. 18-87 and 18-88 dealing with the square
and hexagon, respectively.
The dimensions of the basic cell employed
depend upon the radius of the individual loudspeaker
coverage pattern and the choice of overlap. The edge
to edge choice is most economical with regard to the
number of loudspeakers ultimately required while
leaving gaps in the overall coverage. Quality instal-
lations employ either minimum overlap or center to
center overlap. Of the two basic cells, the hexagonal
structure provides higher loudspeaker density as
illustrated in the following example.
A large meeting room has a width of 75 ft and a
length of 125 ft with the loudspeaker mounting plane
located 25 ft above ear level. The loudspeakers to be
employed have a nominal coverage angle, α, of 90°.
An application of Eq. 18-151 indicates that r = 25 ft.
Taking uniformity of coverage as the chief goal, it is
decided at the outset to employ the center to center
overlap choice.
This being the case, the dimension of a square
cell is 25 ft on edge. The dimensions of a hexagonal
cell would be 25 ft and 21.65 ft. Layout patterns are
to be generated for both basic cells. A possible
layout procedure in which symmetry is assured
consists of placing the chosen basic cell at the center
of the space and attaching and/or overlaying addi-
tional cells up to the point where the overall pattern
remains within the confines of the seating space.
Fig. 18-89 presents two possible solutions obtained
when square cells are employed.
Figure 18-87. Overlap choices for a pattern based on a
square cell.
Figure 18-88. Overlap choices based on a hexagonal cell.
r
H
h
–
(
)
α
2---
⎝⎠
⎛⎞
tan
=
A. Edge to edge                    B. Minimum overlap
C. Center to center
2r
1.414r
r
A. Edge to edge                     B. Minimum overlap
C. Center to center overlap
2r
1.732r
r
0.866r
1.732r
1.5r
Figure 18-89. Loudspeaker positions employing square
cells.
75 ft
75 ft
125 ft

   
Loudspeakers and Loudspeaker Arrays
411
In the first solution the square cell, in its normal
orientation, is placed in the center of the seating
space and is replicated two times for a total of three
cells. Further replications would place speakers on
or beyond the boundaries. This solution involves a
total of eight loudspeakers. The second solution
presented in Fig. 18-89 involves a simple re-orienta-
tion of the basic square cell. In this instance the cell
is rotated into the diamond or diagonal position.
Starting again with a rotated cell in the center
only two replications are possible, yielding a total of
three cells as before. In this instance, however, a
total of ten loudspeakers fill the space thus
improving the uniformity of coverage. Fig. 18-90
presents the two solutions obtained when the basic
cell is a hexagon.
The first solution presented in Fig. 18-90 starts
with a hexagonal cell of normal orientation placed at
the center. Cells are replicated to both the right and
left yielding a total of three cells. This solution gives
a total of thirteen loudspeaker positions. This is a
significant improvement in coverage as compared
with either of the solutions based on a square cell. In
the second solution presented in the Fig. 18-90 the
center cell is in the rotated or diagonal position.
Replication of this pattern again yields a total of 13
loudspeakers. This second solution yields slightly
improved uniformity of coverage near the bound-
aries. Other procedures are possible for laying out
the basic loudspeaker position patterns. Enerson has
formulated algorithms that are useful aids in pattern
organization.
Hybrid Arrays
Many theaters and churches have deep balcony
overhangs beneath which there is no line of sight
communication with a central cluster position. In
such instances the central cluster is designed to
cover the non-obscured seating spaces and a sepa-
rate distributed system is designed to cover the
obscured areas beneath the balcony. The distributed
system is operated with a signal delay consistent
with direct arrival from the central cluster. If the
balcony is very deep it is necessary to zone the
distributed array and to employ stepped signal
delays appropriate to the zone positions.
Split Identical Sources
Unfortunately there exist many school and other
small auditorium installations where identical loud-
speakers are positioned symmetrically to the left and
right of the stage. Such installations guarantee that
all listeners other than those seated exactly on the
centerline are subjected to a spectrum filled with
comb filters. This type of installation is to be
avoided where possible.
Comb filters always occur with spatially separated
sources handling identical program material. Comb
filters are produced by overhead distributed systems
also. In this instance, though, there are several
sources at different locations and the comb filters are
very dense. A system consisting of N spatially sepa-
rated sources has [N(N – 1)] ⁄ 2 distinct pairs.
For an overhead system of 10 sources there will
be 45 distinct pairs of sources. The peaks formed
from one pair of speakers often fill the notches
caused by another pair of loudspeakers. The
resulting spectral distortion is thus not as severe as
that caused by a single pair of sources. Fig. 18-91
depicts the amplitude response through the critical
speech intelligibility range in the direct sound field
at a typical seating position not on the centerline in
an auditorium having split sources.
As can be seen from Fig. 18-91 the notches are
quite deep and the peaks are nearly 6 dB relative to
those produced by a single source. Attenuating one
source by 3 dB can produce a slight improvement.
This produces the result displayed in Fig. 18-92.
The notches now are considerably less deep
while the peaks are less than 5 dB. The price for this
improvement is that one side of the auditorium will
be less loud than the other side. All of this can be
avoided through the employment of a single source
suitably placed.
Figure 18-90. Loudspeaker positions employing
hexagonal cells.
75 ft
75 ft
125 ft

412
Chapter 18
18.16 Vented Enclosure Bass Loudspeakers
Three types of vented enclosure bass loudspeakers
will be covered here. The first type is the classic
bass reflex loudspeaker to be followed by a closely
related symmetrical bandpass subwoofer. The
section will close with an analysis of an asymmetric
bandpass subwoofer that has gained popularity in
home theater systems.
A vented or ported loudspeaker is one in which
the main loudspeaker enclosure is not sealed but
rather has an opening or openings into the enclosure.
A simple such classic structure is shown in
Fig. 18-93. This particular structure is also called a
bass reflex enclosure.
The volume available for free air in the enclo-
sure, V0, is the total interior volume of the enclosure
less the volume occupied by the loudspeaker driver
and less the volume occupied by the vent structure.
The vent structure has an overall depth of T. The
vent is preferably circular with a radius av , and an
area Sv .. In all of the following, the static air density
will be represented by ρ0 and the speed of sound by
c. The properties of the vent can be listed as:
a.
 = vent air mass.
b.
 = vent air mass plus 
contribution from vent radiation reactance.
c.
 = stiffness of vent.
d.
 = vent resonant angular frequency.
e.
 = vent radiation resistance.
f.
 = vent mechanical 
impedance.
Similarly, the properties of the driver may be listed
as:
a.
Ze = Re + jωLe = blocked electrical impedance of 
driver.
b.
ad = effective radius of driver.
c.
Sd = effective area of driver.
d.
Kd = stiffness of driver in free air.
Figure 18-91. Comb filter response at a seat not on
centerline.
Figure 18-92. Result with one source attenuated 3 dB.
 
1000 
2000  2500 
3000 
3500 4000
Frequency–Hz
Split Cluster Interference
500
10
0
−10
−20
−30
−40
−50
Relative direct level
 
1000 
2000  2500 
3000 
3500 4000
Frequency
Split Cluster Interference
500
6
4
2
0
−2
−4
−6
−8
−10
−12
Relative direct level
Figure 18-93. Cross section of a simple vented loud-
speaker.
V0
T
Mv
ρ0SvT
=
Mv
′
Mv
ρ08Svav
3π
--------------------
+
=
Kv
′
ρ0c2Sv
2
V0
-------------------
=
ωv
Kv
′
Mv
′
--------
=
Rrv
ρ0Sv
2ω2
2πc
--------------------
=
Zmv
Rrv
j ωMv
′
Kv
′
ω
-------
–
⎝
⎠
⎛
⎞
+
=

   
Loudspeakers and Loudspeaker Arrays
413
e.
 = stiffness of driver in 
sealed enclosure of volume V0.
f.
Md = effective moving mass of driver.
g.
 = moving mass of driver 
including effect of radiation reactance.
h.
Rmd = mechanical resistance of driver suspen-
sion and surround.
i.
 = radiation resistance of driver.
j.
Bl = motor strength of driver.
k.
 = total quality factor of 
driver in free air.
l.
 = free air resonant angular 
frequency of driver.
m.
 = resonant angular frequency of 
driver in sealed enclosure of volume 
V0.
 = 
mechanical impedance of driver.
n.
i = phasor describing voice coil current.
o.
E = phasor description of drive voltage from 
source having negligible impedance.
The motions of the driver diaphragm and the air
mass contained within the volume of the vent
interact with each other. As an example, suppose for
the moment that the air in the vent remains at rest.
Further suppose that the driver diaphragm is
displaced inward thus reducing the volume available
for the air in the box. This would elevate the pres-
sure in the box thus producing an outwardly directed
force to act on the air in the vent. Similarly, one
could suppose the driver to be at rest with the plug
of air in the vent being displaced inward. This would
cause an outwardly directed force to act on the
driver diaphragm. The motions of the driver
diaphragm and the air plug in the vent are coupled.
The mutual coupling factor is given by
 = vent-diaphragm displace-
ment mutual coupling factor.
Having provided this framework it is now
possible to write the equations of motion for both
the driver and the plug of air contained in the vent.
(18-152)
(18-153)
Eq. 18-153 can be solved immediately to obtain
(18-154)
This result can then be substituted into Eq. 18-152
to obtain
(18-155)
The voice coil current can now be written as
(18-156)
Combining Eqs. 18-155 and 18-156 leads to
(18-157)
Combining Eqs. 18-154 and 18-157 produces
(18-158)
The driver velocity and vent velocity
Eqs. 18-157 and 18-158 are phasor quantities
because the form taken for the driving emf is given
by
(18-159)
where,
Em = amplitude of driving emf in volts.
At low frequencies both the driver and the vent
act as simple spherical sources radiating into a half
space. The phasors representing the acoustic
Kd
′
Kd
ρ0c2Sd
2
V0
-------------------
+
=
Md
′
Md
ρ08Sdad
3π
--------------------
+
=
Rrd
ρ0Sd
2ω2
2πc
--------------------
=
Qt
KdMd
′
Rmd
Bl
(
)2
Re
------------
+
-----------------------------
=
ωr
Kd
Md
′
--------
=
ωd
Kd
′
Md
′
--------
=
Zmd
Rmd
Rrd
j ωMd
′
Kd
′
ω
-------
–
⎝
⎠
⎛
⎞
+
+
=
μ
ρ0c2SdSv
(
) V0
⁄
=
Zmdud
μ uv
jω
------
+
Bli
=
Zmvuv
μud
jω
------
+
0
=
uv
μ
Zmv 
---------- ud
jω
------
–
=
Zmd
μ2
Zmvω2
---------------
+
⎝
⎠
⎜
⎟
⎛
⎞ud
Bli
=
i
E B
– lud
Ze
------------------
=
ud
BlE
Ze
---------
Zmd
μ2
Zmvω2
---------------
Bl
(
)2
Ze
------------
+
+
---------------------------------------------------
=
uv
μ
–
Zmv jω 
-------------------
⎝
⎠
⎛
⎞
BlE
Ze
---------
Zmd
μ2
Zmvω2
---------------
Bl
(
)2
Ze
------------
+
+
---------------------------------------------------
=
E
Eme jωt
=

414
Chapter 18
pressures produced on axis in the far field at a radial
distance r are given by
(18-160)
(18-161)
Both of these quantities are complex. One deter-
mines the magnitudes of the individual pressures by
taking the absolute magnitude of the corresponding
complex quantity. The quantity of principal interest
is the total pressure produced by the loudspeaker.
This is obtained by first adding the two phasor
expressions of Eqs. 18-160 and 18-161 to obtain the
phasor expression for the total pressure
(18-162)
The amplitude of the total acoustic pressure is
then found by taking the absolute magnitude of the
complex quantity of Eq. 18-162
(18-163)
The amplitude performance of the loudspeaker is
obtained by plotting 20 dB log(pmt ⁄ 0.00002 Pa)
versus log(ω) over the frequency range of interest.
The phase performance can be displayed by plot-
ting the angle associated with the complex exponen-
tial statement of Eq. 18-162 versus log(ω).
The foregoing equations are perfectly general
and are applicable regardless of the choice of loud-
speaker parameters, enclosure volume, and vent
properties. As such, they furnish little or no guid-
ance as to what choices need to be made for the
various parameters in order to obtain a particular
frequency response. If we neglect the radiation
resistances and the voice coil inductance at the
lowest frequencies it is possible to write Eq. 18-162
in the following form:
(18-164)
where,
.
The exponential term on the extreme right of
Eq. 18-164 describes wave propagation, has a
magnitude of one, and plays no role in determining
the performance of the loudspeaker. Mathemati-
cally it describes the increasing phase lag as the
radial distance increases. The shape of the frequency
response is governed by the frequency factors in the
numerator along with the coefficients associated
with the polynomial in the denominator. At very low
frequencies the denominator has a value of one
while the numerator grows with the fourth power of
the angular frequency. At higher frequencies the
denominator magnitude is also growing with the
fourth power of the frequency so the response is that
of a fourth order high pass filter. Whether the
response has steps, ripples, is very slow in reaching
its final value, or is maximally flat is determined
solely by the nature of the polynomial in the denom-
inator. The polynomial structure that leads to the
optimum transient response as well as the maxi-
mally flat amplitude response is that of the fourth
order Butterworth. This is the response that will be
detailed here. In order to obtain this response, the
denominator must have the form
This stringent requirement will be satisfied if and
only if 
, and
The physical significance of ω0 is that this is the
angular frequency for which the response is down
by 3 dB. Note that the free air resonant angular
frequency of the driver as well as the resonant
angular frequency of the vent must be equal to ω0.
This means that the −3 dB point of the system
occurs at the free air resonant frequency of the
driver and that the vent must be designed to reso-
nate at this frequency. Furthermore, the total
quality factor of the driver in free air must
be
 The interior
volume of the enclosure is dictated by
. This requirement leads to
pd
ρ0 jωSdud
2πr
-------------------------
=
pv
ρ0 jωSvuv
2πr
-------------------------
=
pt
pd
pv
+
=
pmt
pt
=
pt
ρ0SdEmBlω4
2πrMd
′Reω0
4
----------------------------------
ω4
ω0
4
--------
jω3
Qtω0
3
---------------
–
ωv
2
ωd
2
+
ω0
4
------------------------ω2
–
jωv
2ω
Qtω0
3
---------------
1
+
+
---------------------------------------------------------------------------------------------------e j ωt
kr
–
(
)
=
ω0
KdKv
′
Mv
′Md
′
-----------------
4
=
ω4
ω0
4
--------
j 4
2 2
+
ω3
ω0
3
--------
–
2
2
+
[
] ω2
ω0
2
--------
–
j
4
2 2
+
[
] ω
ω0
------
1
+
+
ωv
ωr
ω0 ωd
ω
=
0 1
2
+
,
=
=
Qt
1
4
2 2
+
------------------------
=
Qt
1
4
2 2
+
⁄
0.383.
=
=
ωd
ω0 1
2
+
=

   
Loudspeakers and Loudspeaker Arrays
415
where,
P0 is the static atmospheric pressure.
The requirement that the Butterworth response
places on the driver total quality factor means that
drivers should be specifically tailored for this partic-
ular application. Fortunately, the response is not
extremely sensitive to variations in Qt so reasonable
tolerances in this value are allowed. In summary, to
construct a vented enclosure with the Butterworth
B4 alignment:
1.
Select a driver whose free air resonance matches
the system’s desired −3 dB point and whose total
quality factor is 0.38 ± 20%.
2.
Determine the driver suspension stiffness and
use this in determining required enclosure
volume.
3.
Pick a reasonable vent area and determine vent
stiffness.
4.
Determine vent air mass necessary to make vent
resonate at the system’s −3 dB point.
5.
Use vent area and air mass to determine vent
length T.
It may be necessary to iterate steps 3 through 5 to
obtain reasonable vent dimensions.
6.
Pick enclosure dimensions to provide required
free air volume consistent with accommodating
volume occupied by both driver and vent.
7.
For large enclosures where standing waves may
fall within the pass band of the system, employ
dimension ratios that do not exacerbate standing
waves.
8.
The enclosure must be rigidly braced and the
volume occupied by bracing cannot be allowed
to detract from free air interior volume.
The above equations and procedures will now be
employed to explore the performance of a system
designed around the properties of a commercially
available woofer. The given woofer parameters are:
a.
Re = 6.6 Ω .
b.
Le = 0.003 H.
c.
fr = 18.3 Hz.
d.
Kd = 1339 N ⁄ m.
e.
Md′ = 0.102 kg.
f.
Qt = 0.379.
g.
Rm = 4.07 kg ⁄ s.
h.
Bl = 13.28 Tm.
i.
Sd = 0.0847 m2.
An application of the design equations yields the
following derived values:
a.
V0 = 0.537 m3.
b.
Kv′ =118.7 N ⁄ m.
c.
Mv′ = 0.00898 kg.
d.
Sv = 0.0212 m2.
e.
av = 0.0821 m.
f.
T = 0.283 m.
The performance of the system is first explored
by determining the amplitude response at one meter
when the driving voltage has an amplitude of 1 volt.
Curves are produced for the vent pressure response,
driver pressure response, and the system pressure
response, Fig.18-94.
It is worthy of note that the vent response has a
bandpass shape centered on the system’s half power
point located at 18.3 Hz and that the driver has a
minimum output at this same point. Additionally,
the driver output and the vent output interfere
destructively for frequencies below the half power
point. This is even more apparent upon examination
of the separate phase responses presented in
Fig. 18-95.
Note that for frequencies below the half power
point the phase difference between the driver and
the vent is uniformly π radians. They shift into
phase as the frequency passes through the half
power point and remain in phase for frequencies
above the half power point.
V0
ρ0c2Sd
2
Kd 2
-------------------
=
1.4P0Sd
2
Kd 2
----------------------
=
Figure 18-94. Amplitude performance of maximally flat
vented bass loudspeaker system.
100
80
60
40
20
0
−20
100                           101                          102                         103
Magnitude–dB
Frequency–Hz
Total
Vent
Driver

416
Chapter 18
A final very important consideration is that of the
displacement demanded of the driver. The displace-
ment equation is obtained by dividing Eq. 18-157 by
jω. One then takes the absolute magnitude of the
result and plots this quantity as the frequency is
allowed to vary over the range of interest. The result
for the present maximally flat system appears in
Fig. 18-96.
It should be noted that the maximum displace-
ment occurs at the lowest drive frequency. The
driver displacement at the half power point
frequency is almost but not quite zero. At 1 Hz, the
displacement amplitude is 1.5 × 10−3 m, 1.5 mm, or
about 0.06 in. Curves of this type are important in
determining the maximum allowable voltage drive
as all drivers have linear displacement limits.
Equal Slope Bandpass Subwoofer
The design objective of bandpass subwoofers is the
production of a device that radiates solely from the
system vent or vents depending on the complexity
of the design. The role of the driver in such devices
is simply to excite air motion in the radiating vents.
Fig. 18-97 depicts the simplest of such structures.
The properties of the vent can be listed as:
a.
Mv = ρ0SvT = vent air mass.
b.
 = vent air mass plus 
contribution from vent radiation reactance.
c.
 = stiffness of vent.
d.
 = vent resonant angular frequency.
e.
 = vent radiation resistance.
f.
 = vent mechanical 
impedance.
Similarly, the properties of the driver may be
listed as:
a.
Ze = Re + jωLe = blocked electrical impedance of 
driver.
b.
ad = effective radius of driver.
c.
Sd = effective area of driver.
d.
Kd = stiffness of driver in free air.
e.
 = stiffness of 
driver as mounted.
f.
 = stiffness of driver 
considering only rear volume.
g.
Md = effective moving mass of driver.
Figure 18-95. Phase response of vent and driver.
Figure 18-96. Driver displacement for one volt drive.
100                           101                          102                         103
Phase–rad
Frequency–Hz
Vent
Driver
4
3
2
1
0
−1
−2
−3
−4
100                    101                    102                 103
Frequency–Hz
Displacement–m × 10−3
1.5
1
0.5
0
Figure 18-97. Simple bandpass subwoofer structure.
V2
V1
T
Mv
′
Mv
ρ08Svav
3π
--------------------
+
=
Kv′
ρ0c2Sv
2
V2
-------------------
=
ωv
Kv′
Mv
′
--------
=
Rrv
ρ0Sv
2ω2
2πc
--------------------
=
Zmv
Rrv
j ωMv
′
Kv
′
ω
-------
–
⎝
⎠
⎛
⎞
+
=
Kd′
Kd
ρ0c2Sd
2 V1
V2
+
(
)
V1V2
-------------------------------------------
+
=
Kd′′
Kd
ρ0c2Sd
2
V1
-------------------
+
=

   
Loudspeakers and Loudspeaker Arrays
417
h.
 = resonant angular frequency of 
driver considering only rear volume.
i.
Rmd = mechanical resistance of driver suspen-
sion and surround.
j.
Bl = motor strength of driver.
k.
 = quality factor of driver 
considering only rear volume.
l.
 = mechanical 
impedance of driver.
m. i = phasor describing voice coil current.
n.
E = phasor description of drive voltage from 
source having negligible impedance.
o.
= vent-diaphragm displacement 
mutual coupling factor.
The equations of motion are:
(18-165)
(18-166)
Note the reversal of sign of the mutual coupling
term as compared with the bass reflex example. In
this case, the vent is driven by the front of the driver
rather than the rear. At very low frequencies, posi-
tive displacement of the driver produces a positive
displacement of the vent unlike the former case.
As before the voice coil current is
(18-167)
The procedure employed in the bass reflex case
produces
(18-168)
(18-169)
The phasor describing the acoustic pressure
produced by the vent is obtained by solving
Eq. 18-169 and then substituting the result into
(18-170)
The pressure response of this system is that of a
fourth order bandpass. In order for the denominator
polynomial to conform to that of the fourth order
Butterworth, the following conditions must be
satisfied:
a.
ω0 = ωv = ωd = bandpass center angular 
frequency.
b.
Qd = 0.383.
c.
.
One must start with a driver whose free air reso-
nance frequency is well below the desired pass band
center frequency. The total quality factor of the
driver in free air must also be well below 0.383. The
volume V1 is then determined from
Knowing the value of V2, it is possible to deter-
mine the vent area and depth by following the
procedure employed in the bass reflex example.
This procedure was applied to a small driver
whose parameters met the above criterion with
regard to free air resonance frequency but whose
free air total quality factor was too high. This is
often the case with small drivers so the performance
might be more typical of actual practice than the
theoretical ideal. The given parameters were:
a.
Kd = 1088 N/m.
b.
Md = 0.0199 kg.
c.
ad = 0.0847 m.
d.
Re = 6.8 Ω.
e.
Le = 0.001 H.
f.
Rm = 3 kg ⁄ s.
g.
Bl = 7.94 Tm.
ωd
Kd′′
Md
----------
=
Qd
Kd′′Md
Rmd
Bl
(
)2
Re
------------
+
-----------------------------
=
Zmd
Rmd
j ωMd
Kd′
ω
--------
–
⎝
⎠
⎛
⎞
+
=
μ
ρ0c2SdSv
V2
----------------------
=
Zmdud
μ uv
jω
------
–
Bli
=
Zmvuv
μud
jω
------
–
0
=
i
E B
– lud
Ze
------------------
=
ud
BlE
Ze
---------
Zmd
μ2
Zmvω2
---------------
Bl
(
)2
Ze
------------
+
+
---------------------------------------------------
=
uv
μ
Zmv jω
-----------------
BlE
Ze
---------
Zmd
μ2
Zmvω2
---------------
Bl
(
)2
Ze
------------
+
+
---------------------------------------------------
=
pv
ρ0 jωSvuv
2πr
------------------------
=
V2
ρ0c2Sd
2
2Kd
′′
-------------------
1.4P0Sd
2
2Kd
′′
----------------------
=
=
V1
1.4P0Sd
2
ω0
2Md
Kd
–
-----------------------------
=

418
Chapter 18
The calculated parameters are:
a.
V1 = 0.0469 m3.
b.
V2 = 0.0194 m3.
c.
T = 0.325 m.
The pressure amplitude response for a distance of
one meter with a drive voltage amplitude of 1 volt is
given in Fig. 18-98.
The slopes are symmetrical on either side of band
center and are 12 dB/octave. The bandpass extends
from just over 30  Hz to just over 100  Hz. The
response is not as smooth across the top as it should
be because with this driver Qd is 50% larger than it
should be to generate a true maximally flat perfor-
mance. The displacement required of the driver in
producing the above vent response is equally impor-
tant. This curve appears as Fig. 18-99.
The peak displacement at any frequency with a
one volt drive amplitude is 0.5 mm. This driver can
tolerate a displacement of ten times this value. The
system should be capable then of producing a pres-
sure response curve elevated by 20 dB more than
depicted in Fig. 18-98.
Unequal Slope Bandpass Subwoofer
A popular subwoofer for home theater systems
features a small driver whose effective radius is a
little over 5 cm while incorporating two vents. One
vent is for the air volume in front of the driver as in
the equal slope bandpass device discussed above.
The second vent is for the air volume to the rear of
the driver. The area of each of the radiating vents is
equal to the effective area of the driver. The parame-
ters for the system are:
a.
Rmd = mechanical resistance of driver = 1.33kg/s.
b.
Md = effective moving mass of driver = 
0.0133kg.
c.
Kd = stiffness of driver = 1261 N/m.
d.
Sd = effective driver area = 0.00894 m2.
e.
V1 = rear of driver air volume = 0.006 m3.
f.
V2 = front of driver air volume = 0.0015 m3.
g.
Bl = driver motor strength = 6.6 Tm.
h.
Re = voice coil resistance = 3.1 Ω .
i.
Le = voice coil self-inductance = 0.00128 H.
j.
Sv1 = rear vent area = 0.00894 m2.
k.
Sv2 = front vent area = 0.00894 m2.
l.
Mv1′ = effective moving mass of rear vent = 
0.0234kg.
m. Mv2′ = effective moving mass of front vent = 
0.0143kg.
The electroacoustic properties are:
a.
.
b.
 = rear vent radiation 
resistance.
c.
 = front vent radiation 
resistance.
d.
driver mechanical impedance.
Figure 18-98. Amplitude response of single vent
subwoofer.
Figure 18-99. Driver displacement versus frequency
with a voltage amplitude of one volt.
100                        101                        102
Frequency–Hz
Magnitude–dB
80
75
70
65
60
55
50
100                    101                    102                  103
Frequency–Hz
Displacement–m × 10−4
6
5
4
3
2
1
0
Ze
Re
jωLe
+
=
Rr1
ρ0Sv1
2ω2
2πc
-----------------------
=
Rr2
ρ0Sv2
2ω2
2πc
-----------------------
=
Zmd
Rmd
j ωMd
Kd
ω
------
–
⎝
⎠
⎛
⎞
ρ0c2Sd
2 V1
V2
+
(
)
V1V2 jω
-------------------------------------------
Bl
(
)2
Ze
------------
+
+
+
=
=

   
Loudspeakers and Loudspeaker Arrays
419
e.
 = rear mutual coupling factor.
f.
 = front mutual coupling factor.
g.
 = rear vent 
mechanical impedance.
h.
 = front vent 
mechanical impedance.
At this point it is possible to write the equations of
motion.
(18-171)
(18-172)
(18-173)
where,
ud = driver diaphragm velocity,
uv1 = rear vent particle velocity,
uv2 = front vent particle velocity.
Eqs. 18-171 through 18-173 constitute a system
of linearly independent equations that can be solved
simultaneously for the three unknown velocity vari-
ables. The results are:
(18-174)
(18-175)
(18-176)
where,
.
The phasor expression for the acoustic pressure
produced by the system is then
(18-177)
The amplitude response of the system is obtained
by plotting 
 versus
log(ω)or log(f ). Such a plot appears in Fig. 18-100.
The driver displacement required for the pressure
performance of Fig. 18-100 appears in Fig. 18-101.
The half power points of the amplitude response
curve occur at about 45 Hz and 180 Hz. The low
frequency slope rate is 24 dB⁄octave while the high
frequency slope rate is 18 dB⁄octave. This perfor-
mance is exceptional considering the size of the
driver involved. The displacement curve, however,
requires a displacement maximum of over 1.6 mm
and drivers of this size hardly exceed 3 mm max.
The maximum output of the system is thus quite
μ1
ρ0c2Sv1Sd
V1
-------------------------
=
μ2
ρ0c2Sv2Sd
V2
-------------------------
=
Zm1
Rr1
j ωMv1
′
ρ0c2Sv1
2
V1ω
---------------------
–
⎝
⎠
⎜
⎟
⎛
⎞
+
=
Zm2
Rr2
j ωMv2
′
ρ0c2Sv2
2
V2ω
---------------------
–
⎝
⎠
⎜
⎟
⎛
⎞
+
=
Zmdud
μ2
jω
------uv2
–
μ1
jω
------uv1
+
BlE
Ze
---------
=
Zm1uv1
μ1
jω
------ud
+
0
=
Zm2uv2
μ2
jω
------ud
–
0
=
ud
BlEme jωt
Ze
------------------------
Zm1Zm2
Δ
------------------
×
=
uv1
B
– lEme jωt
Ze
---------------------------
μ1
jω
------
Zm2
Δ
---------
×
×
=
uv2
BlEme jωt
Ze
------------------------
μ2
jω
------
×
Zm1
Δ
---------
×
=
Δ
ZmdZm1Zm2
μ1
2
ω2
--------Zm2
μ2
2
ω2
--------Zm1
+
+
=
Figure 18-100. One volt one meter amplitude response
of unequal slope subwoofer.
Figure 18-101. Driver displacement required by
unequal slope subwoofer.
pt
ρ0 jω
2πr
-------------- Sv1uv1
Sv2uv2
+
(
)
=
20
pt
0.00002 Pa
⁄
(
)
log
100                           101                          102                         103
Magnitude–dB
Frequency–Hz
90
85
80
75
70
65
60
55
50
100                          101                          102
Frequency–Hz
Displacement–m × 10−3
1.6
1.4
1.2
1
0.8
0.6
0.4
0.2
0

420
Chapter 18
limited unless the drive signal is high passed above
10Hz. Doing this, of course, would unfavorably
impact the low frequency half power point.
18.17 Large Signal Behavior of Loudspeakers
The loudspeaker models presented earlier in the
present chapter accurately describe a loudspeaker’s
performance under linear and time invariant condi-
tions. These conditions exist when a loudspeaker is
being driven by signals sufficiently small that the
displacements experienced by the voice coil fall in a
range that provoke only linear restoring forces from
the loudspeaker suspension. Continuous operation
with small signals will produce an elevated voice
coil temperature through the heating effect of the
small currents involved. This in turn leads to a
slightly higher voice coil resistance that remains
relatively stable as long as operation with small
signals persists. This is accounted for in small signal
parameter measurement procedure by exercising the
loudspeaker before parameter measurement takes
place. In this small signal regime the motor strength
Bl and the voice coil self inductance Le can be
treated as constant parameters and as the voice coil
currents are small any magnetic hysteresis effects in
the magnetic structure are negligible. None of the
above statements remain true when the loudspeaker
operation involves operation with large signals
where now the stiffness of the suspension, the motor
strength, and the voice coil self inductance all
become functions of the amount of voice coil
displacement. Under such conditions the loudspeaker
is operating nonlinearly. Nonlinearity of operation is
evidenced by a distorted acoustical output wherein
frequency components appear in the output that were
not present in the exciting signal at the input to the
loudspeaker. Furthermore, the loudspeaker opera-
tion is no longer time invariant as the voice coil
temperature as well as magnetic hysteresis effects
through the elevated voice coil currents involved
depend upon the previous time history of the exciting
signals. Furthermore, the type of loudspeaker
mounting or enclosure may play a much more signif-
icant role under large signal conditions. If a cone
type loudspeaker is mounted in a sealed enclosure of
small interior volume large cone displacements will
provoke nonlinear behavior of the air trapped in the
enclosure while for vented enclosures turbulence
may occur in the vent air flow.
Practically all workers in audio at one time or
another have performed distortion measurements
associated with transducers while a smaller number
have done significant work toward analysis and
reduction of distortion properties. In the last decade
or so one worker merits particular mention. Wolf-
gang Klippel of Dresden, Germany during this
period has worked almost exclusively on the devel-
opment of a system of analyzers for measuring and
identifying the sources of distortion in loudspeakers
and other transducers while operating under large
signal conditions. Many of Klippel’s papers as well
as references to the work of others are available for
download  from Klippel’s company website
www.klippel.de.
Bibliography
A. H. Benade and E. V. Jansson. “On Plane and Spherical Waves in Horns with Nonuniform Flare. 1: Theory
of Radiation, Resonance Frequencies, and Mode Conversion,” Acustica, Vol. 31, No. 2. (1974) pp. 80-98.
Leo L. Beranek. Acoustics. New York: McGraw-Hill, 1954.
C. Enerson. “Distributed System Pattern Analysis,” Syn-Aud-Con Tech Topics, Vol. 5, No. 1 (1977).
Earl Geddes. “Acoustic Waveguide Theory,” J. Audio Eng. Soc., Vol. 37, No. 7 (1989).
D. W. Gunness and N. D. Butler. “Implementation of a Wide-Bandwidth, Digitally Steered Array.” Paper
presented at the 115th Convention of the Audio Engineering Society (2003).
David W. Gunness and Ryan J. Mihelich. “Loudspeaker Acoustic Field Calculations with Application to
Directional Response Measurement.” Paper presented at the 109th Convention of the Audio Engineering
Society, Los Angeles (September 22-25, 2000).
E. V. Jansson and A. H. Benade. “On Plane and Spherical Waves in Horns with Nonuniform Flare. 2: Predic-
tion and Measurements of Resonance Frequencies and Radiation Losses,” Acustica, Vol. 31, No. 4. (1974)
pp. 185-202.
D. B. Keele, Jr. “Low-Frequency Loudspeaker Assessment by Nearfield Sound-Pressure Measurement,” J.
Audio Eng. Soc., Vol. 22 (May 1974), pp. 330-338.
Lawrence E. Kinsler, Austin Frey, et. al. Fundamentals of Acoustics, 4th ed. New York: John Wiley and Sons,
2000.

   
Loudspeakers and Loudspeaker Arrays
421
Helmut Krüger. “Mechanical Equalising—On the Design of Loudspeaker Diaphragms.” Paper presented at
the 86th Convention of the Audio Engineering Society, Hamburg (March 7-10, 1989), Preprint No. 2775.
P. M. Morse. Vibration and Sound, 2nd ed. New York: McGraw-Hill, 1948.
Allan D. Pierce. Acoustics: An Introduction to Its Physical Principles and Applications, New York:
Mc-Graw-Hill, 1981.
Chester W. Rice and Edward W. Kellogg, “Notes on the Development of a New Type of Hornless Loud-
speaker.” Paper presented at the Spring Convention of A.I.E.E., St. Louis (April 13-17, 1925).


Chapter 19
Power Ratings for Amplifiers and
Loudspeakers
by Pat Brown
423
19.1 Loudspeaker Power Ratings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 425
The Amplifier/Loudspeaker Interface . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 425
The Power Rating  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 428
19.2 Active Loudspeaker Systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 428
19.3 Non-Linear Operation  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 428
The Voltage Rating  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 429
Mechanical Limit Testing  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 429
Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 429
19.4 The Amplifier as a Voltage Source  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 429
19.5 The Equivalent Amplifier Size–EAS  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 430
19.6 Power from a Voltage Source . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 431
19.7 Burst Testing  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 433
19.8 Power Rating Possibilities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 434
Real World Power Generation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 434
Things Amplifiers Hate . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 435
Burst Testing Results . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 435
Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 435
19.9 Putting It All Together . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 435
A Warning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 435
A Common Misconception  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 436
The Input Sensitivity Control  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 436
The 30/30 Guideline  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 437
19.10 Multi-way Loudspeakers  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 438
Fixed Gain Settings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 439
Powered Loudspeakers  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 439
19.11 System Gain Structure  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 439
19.12 Combining MIV and EAS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 439


Power Ratings for Amplifiers and Loudspeakers
425
Power ratings enjoy two distinctions in the field of
sound system engineering.
1.
From a technical perspective, a proper power
rating yields the deepest insight into the perfor-
mance of the “black boxes” that make up our
sound systems. It establishes the relationship
between voltage, current and impedance with
regard to the input and output signal to a device,
allowing us to account for all of input and output
energy. From that perspective, we should have a
power rating, expressed as a level in either dBm
or dBW, for every device in the signal chain. But,
2.
Power ratings are among the most abused and
misunderstood specifications in audio. They are
almost never measured correctly, and they are
seldom presented in a way that can be validated.
The power ratings of amplifiers and loudspeakers
in today’s audio marketplace are usually so ambig-
uous as to be useless to the sound system designer. I
am not a fan of power ratings. Claims such as “the
amplifier is putting out 1000 watts” or “the loud-
speaker needs 500 watts” are almost never correct,
or even meaningful. Such loose usage is the norm
rather than the exception, and has diminished the
usefulness amplifier and loudspeaker power ratings
to the audio practitioner. It is my intent for this
chapter to connect the dots for those who wish to
understand the theory behind the numbers, and to
equip audio practitioners with what they need to
design and calibrate sound systems, namely what
will be read on a true-rms voltmeter at component
interfaces. This information must either be
measured, or mined from the power rating of the
product. In order to understand how to extract this
voltage from a power rating, we must look at its role
in establishing the power rating. Any power rating
that cannot yield the correct voltage at an interface
is useless.
I will show some shortcuts to finding these inter-
face voltages that can allow the use of power ratings
to be avoided altogether in some cases. This does
not detract from the technical validity of the power
rating, but it can allow us to reserve it for in-depth
investigations rather than field work.
My objective is not to replace any presently
existing standards, but rather to provide safe guid-
ance through a subject that is often very confusing
to beginners and veterans alike in sound system
design and installation. The suggested procedures
are appealing for several reasons. First, and perhaps
foremost, only the most familiar basic instrumenta-
tion and measurements are required in the setup
procedures. Secondly, safeguards are incorporated
to protect against damage to both loudspeakers as
well as amplifiers. Thirdly, indicators of system
satisfactory performance or lack thereof are clearly
identified.
19.1 Loudspeaker Power Ratings
The role of the amplifier is to provide the voltage
and current needed by the loudspeaker to produce the
desired LP at the listener. Voltage times current
equals power. Once the loudspeaker’s voltage needs
and limitations are determined, an appropriate ampli-
fier can be selected. Since much of the applied power
is converted to heat, the loudspeaker has a power
rating which describes the maximum electrical
power that it can continuously dissipate while it is
producing acoustical power. Exceed this power limit,
and the loudspeaker will be permanently damaged.
The power rating need only be considered when
there is a chance that it will be exceeded. It is good
system design practice to stay well below the power
ratings of both amplifiers and loudspeakers. This
assures optimal performance and longer life.
The following describes the method that I use to
determine loudspeaker power ratings. I developed it
for testing loudspeaker power ratings for manufac-
turers. Key to the method is the use of the real-time
transfer function to assess when loudspeaker’s
response is changing due to the heat build-up. This
allows a limit to be established without destroying
the loudspeaker. An understanding of how the test is
performed and the specification established will
provide some insights into how to avoid thermal
damage in the field, as well as how to select an
appropriate amplifier to drive the loudspeaker.
19.1.1 The Amplifier/Loudspeaker Interface
Amplifiers are interfaced with loudspeakers using a
constant voltage interface. The power flow to the
loudspeaker will predictably track the applied
voltage under normal, linear operating conditions.
When this voltage is applied to the loudspeaker’s
terminals, current will flow as determined by the
impedance of the loudspeaker. A loudspeaker power
rating requires the determination of the maximum
continuous applicable rms voltage to the loud-
speaker that will not cause thermal damage. I will
call this the Maximum Input Voltage–MIV. The
power rating is calculated from the MIV and rated
impedance using the power equation.
(19-1)
W
MIV
 2
R
--------------
=

426
Chapter 19
where,
W is the continuous power rating in watts,
R is the rated impedance of the loudspeaker, simpli-
fied to an equivalent resistance,
MIV is the maximum rms voltage to the loud-
speaker.
The Method
To find the MIV of the loudspeaker, the following
parameters must be monitored.
1.
The drive voltage to the loudspeaker.
2.
The output voltage of the power amplifier.
3.
The axial frequency response magnitude of the
loudspeaker.
Various types of broad band stimuli can be used.
Pink noise is a logical choice. Some standards shape
the spectrum of the pink noise to more closely
resemble musical waveforms. The IEC and EIA
noise spectra are shown in Fig. 19-1.
The noise can also be clipped to allow a higher
rms voltage to be produced by a given amplifier size.
Most standards mandate a 2-to-1 voltage ratio (crest
factor = 6 dB), which requires severe clipping of the
noise signal. Pink noise has an approximate 4:1
peak-to-rms ratio (12  dB crest factor), which
emulates slightly clipped (or peak-limited) program
material. IEC and EIA noise have a 2:1 peak-to-rms
ratio (6 dB crest factor). The spectral shaping and
clipping, once performed by a passive network, can
be performed in any wave editor. Of course, the
clipped waveform is distressing to listen to, but this
is a heat test, not a sound quality test. The original
motivation for this “pre-clipping” of the test wave-
form was to allow a higher rms voltage to be
achieved prior to clipping the amplifier. In this age of
amplifiers with 200 V rails, the pre-clipping is gener-
ally considered to be unnecessary and future stan-
dards will not likely mandate it. It has little if any
effect on the MIV, which is based on the rms voltage.
The relationship between the drive voltage to the
loudspeaker and the axial frequency response
magnitude can be monitored on a two-channel
analyzer that has the ability to subtract the two
responses and display their difference in real time.
Fig. 19-2 shows the test setup.
Under normal operating conditions all three
parameters have a linear relationship—a 1 dB drive
voltage increase produces a 1 dB increase of output
voltage from the amplifier, as well as a 1 dB increase
in the axial LP from the loudspeaker. The objective
of the MIV test is to determine when this relation-
ship becomes non-linear due to heating of the
loudspeaker.
A Starting Point
I usually start by applying 3 Vrms to the loudspeaker.
This is the approximate voltage used for the sensi-
tivity test, and produces about 1 W into an 8 Ω resis-
tive load. The analyzer displays the loudspeaker’s
response. This response is stored as a reference, and
the analyzer is placed in “subtract” mode. This
produces a straight line on the screen, indicating that
there is no difference between the ongoing measure-
ment and the response stored in memory. This line
will remain flat so long as nothing causes a differ-
ence between the stored response and ongoing
measurement.
The drive voltage is increased by turning up the
generator. Since the analyzer sees both the refer-
ence signal and the loudspeaker response increase,
the line remains flat because the same change
Figure 19-1. Test signal spectra for determining
Maximum Input Voltage.
0
−5
−10
−15
−20
−25
−30
−35
dB
0
−5
−10
−15
−20
−25
−30
−35
dB
31 63 125 250 500 1k 2k 4k 8k 16k Hz
31 63 125 250 500 1k 2k 4k 8k 16k Hz
Max input voltage uses IEC-268-1 spectrum
Max input voltage uses EIA-426-B spectrum

Power Ratings for Amplifiers and Loudspeakers
427
happened to both signals. This demonstrates that the
relationship between the two signals is linear, or 1:1.
Power Compression
The resistive portion of the loudspeaker’s impedance
dissipates electrical power in the form of heat. Loud-
speakers can become very hot during use. Trans-
ducer designers use various mechanisms to keep
them cool, including air flow and ferrous fluids.
As the heat increases the resistance of the voice
coil wire increases, resulting in less current draw
from the amplifier. This creates a non-linear rela-
tionship between the drive voltage and the resultant
acoustic power. This change can be observed in the
axial response of the loudspeaker. In short, power
compression is occurring when some portion of the
loudspeaker’s frequency response magnitude no
longer tracks the level increase of the applied
voltage. Of course, it is important to make sure that
some other part of the chain is not being overdriven,
such as the measurement microphone.
For single transducers, the effect is usually
broadband. For multi-way loudspeaker systems and
for those with passive crossovers, it may be
frequency-dependent. Which is unimportant. By
monitoring the loudspeaker’s response in the
frequency domain, the frequency-dependence can be
observed in real time.
Turn It Up!
The drive voltage to the amplifier is increased at
regular time intervals. A 3 dB increase at one minute
intervals is a good general approach. At the onset of
power compression, the trace will start to drop in
level, indicating that the output of the loudspeaker is
no longer tracking the increase in drive voltage. A
relationship that was once linear is now non-linear due
to the heat produced in the loudspeaker’s voice coil.
When To Stop?
There is no clear directive on when to conclude the
test. Even the standards are ambiguous in this
regard. The purist might say that the test is over at
the onset of power compression, as indicated by a
1dB change to any one-third octave band in the
loudspeaker’s response curve. I wouldn’t disagree,
except that the MIV and resultant power rating based
on this criteria are quite conservative. Since the
uninformed often purchase loudspeakers on the
basis of their power rating alone, conservative
ratings are shunned by manufacturers since they
may produce a disadvantage in the marketplace. The
influence of marketing forces on published ratings
cannot be ignored.
One could ask “How hard can I drive the loud-
speaker before its response is permanently
changed?” After testing hundreds of units, I would
suggest that the answer is about 3  dB to any
one-third octave band, since the failure rate at 10 dB
of change approaches 100% and the failure rate at
6dB of change is still unacceptably high. Failures at
a 3 dB change are rare, and the loudspeaker system
typically recovers to its low power response when
the drive voltage is reduced.
In a perfect world, we would like to know:
1.
The voltage at the onset of power compression.
Figure 19-2. Setup for measuring the MIV.
Wav Player
True rms
voltmeter
Audio
Interface
Big Amp
(bridged mono)
Loudspeaker 
under test
Mic
(High SPL)
Computer
Line input
USB/Firewire
Mic Input
Real-time
transfer function
(subtract mode)
+
−

428
Chapter 19
2.
The voltage that produces 3 dB of power com-
pression in any one-third octave band in the
passband of the loudspeaker.
3.
The voltage at which thermal failure occurs,
which unfortunately requires a destructive test.
Of the three, item 2 is the most important. I
conclude the test at a 3 dB response change to estab-
lish the MIV. The loudspeaker is driven for 3
minutes at this level (the length of a typical song).
The drive voltage is then reduced to the original 3
Vrms drive. If no damage occurred, the analyzer
trace should return to the flat line response after a
few minutes.
If the loudspeaker’s sensitivity is measured at
2.83  Vrms  @  1  m and the MIV is determined as
described, the maximum LP at one meter can be
approximated by
(19-2)
This can be extrapolated to any listener distance
using the inverse-square law.
19.1.2 The Power Rating
The MIV can be directly read from the true-rms volt-
meter. How many watts is this? It depends on the
loudspeaker’s impedance. We will use the rated
impedance of the loudspeaker along with the MIV to
determine the power rating. Remember that this
approach treats the loudspeaker like a resistor,
simplifying the calculation.
We can simplify the complex impedance to an
equivalent resistance, and even round to a typical
value (i.e. 8 Ω). This is because once the MIV is
known, the power rating is somewhat superfluous.
We need to present the power rating in a form that
allows the MIV to be determined by calculation, so
whatever impedance is used basically falls out of the
equation, so long as the same value is used in the
establishment of the power rating as is used to
calculate the MIV from it.
These extra steps are required due to the insis-
tence of our industry on the use of power ratings,
even for a constant voltage interface. This may
change in the future.
19.2 Active Loudspeaker Systems
The same procedure can be used to test
self-powered loudspeakers. The only difference is
that the MIV will be a line level signal. The MIV is
monitored at the input rather than at the output of
the amplifier. This method can also be used on
passive loudspeakers that are packaged as a system
with amplifiers and signal processing, Fig. 19-3.
19.3 Non-Linear Operation
It is becoming increasingly common for a loud-
speaker system response to become nonlinear by
design as its thermal or mechanical limits are
approached. This may be due to the use of electronic
compression or limiting, either analog or digital, or
by the use of a passive network within the loud-
speaker enclosure. The test method previously
dB
20
MIV
3
-----------
⎝
⎠
⎛
⎞
log
SensAVG
+
=
Figure 19-3. MIV test setup for internally powered loudspeaker.
Wav Player
True rms
voltmeter
Audio
Interface
Self-Powered Loudspeaker
Mic
(High SPL)
Computer
Line input
USB/Firewire
Mic Input
Real-time
Transfer Function
(Subtract Mode)

Power Ratings for Amplifiers and Loudspeakers
429
described cannot distinguish between power
compression due to heat build-up, and intentional
compression designed to yield higher LP from the
system. The MIV can be tested as previously
described to produce the maximum voltage for
linear output. It can then be increased beyond this
point to determine a new MIV using different failure
criteria, such as a 1 dB change to the total LP vs. the
applied voltage. This will typically be several dB
higher than MIV resulting from the one-third octave
criteria. In effect, the signal processing is impeding
the MIV of the raw transducers from being reached.
The burden is on the loudspeaker manufacturer to
provide a different failure criteria than 3 dB of
change to any one-third octave band if that is appli-
cable to their loudspeaker. The tester and end user
are not privy to the inner workings of the loud-
speaker system, nor need they be. The loudspeaker is
treated as a “black box” with an electrical voltage
input and an acoustical voltage (pressure) output.
19.3.1 The Voltage Rating
It should be apparent that at the conclusion of the
test that we know the maximum rms drive voltage
that the loudspeaker can handle. This is all that a
technician needs to know to avoid thermal damage
to the loudspeaker when setting amplifier levels in
the field. It is also all we need to know to select an
appropriate power amplifier. The expression of this
as a power rating is an optional step that can be
muddied by how the loudspeaker’s impedance is
determined, as well as marketing pressure to publish
large power ratings. Loudspeaker manufacturers are
encouraged to include the MIV along with power
ratings on the specification sheet. This frees the
technician from having to calculate the MIV from a
(possibly exaggerated) power rating and ambiguous
rated impedance.
19.3.2 Mechanical Limit Testing
In addition to thermal testing, it may be desirous to
test the loudspeaker’s mechanical excursion limits.
This test requires an impulsive stimulus in lieu of
continuous noise. Don Keele has produced a peak
tone-burst that is suitable for mechanical limit
testing. The stimulus is a 6.5 cycle sinusoid in a
cosine envelope at the desired test frequency. This
short duration signal has a bandwidth of one-third
octave. Three such signals spaced at one-third
octave centers and mixed produce a one-octave test
bandwidth. A duty cycle can be selected to emulate
repetition rate of a kick drum used in electronic
music. The output waveform of a measurement
microphone is monitored on an oscilloscope as the
drive voltage to the loudspeaker is increased. Visual
deformation from the low voltage response indicates
that the mechanical limits of the loudspeaker have
been reached.
The MIV-burst voltage determined by this test
can be very high. When used along with the rated
impedance to calculate power, the result is a very
high “burst power” rating for the loudspeaker. It is
important to note that the actual power flow to the
loudspeaker is fairly low due to the transient nature
of the signal, which yields a very high crest factor.
For example, if the MIV-thermal is 40 Vrms and the
MIV-burst is 200 Vrms it is defensible to publish the
loudspeaker’s voltage rating as follows:
1.
MIVrms = 40 V (IEC noise, 3-minutes).
2.
MIVpeak = 200 V.
3.
Equivalent Amplifier Size = 400 W (sine wave,
8 Ω).
4.
Burst MIV = +14 dB.
These can be used to determine the power ratings
by calculation using the rated impedance. I will
describe the Equivalent Amplifier Size (EAS) later in
this chapter. If the system designer specifies the
amplifier based on the EAS, it will not have suffi-
cient peak room to reach the MIV-burst, so there
should be no danger of over-excursion. If the system
designer specifies an amplifier that can pass the
MIV-burst, then it will be capable of thermally
destroying the loudspeaker. Which is used depends
on many factors, including the application and the
competence of the end user.
19.3.3 Conclusion
That’s the basic test. Some of the details, such as
stimulus type, duration and failure criteria vary per
standard. The method I’ve just demonstrated is just
one of many possibilities. It is logical, repeatable,
objective and easy to implement with readily avail-
able instrumentation. It should suffice to demon-
strate the nature of power testing and loudspeaker
power ratings.
19.4 The Amplifier as a Voltage Source
An amplifier has a maximum voltage amplitude that
it can produce, as determined by its power supply
rails. This establishes the highest peak that can pass
through the amplifier. If excessive gain is applied to
the signal, the waveform will be clipped as it tries to

430
Chapter 19
exceed the rail voltage. Most amplifiers provide a
visual indicator for the onset of clipping.
The ideal amplifier is a constant voltage source.
This means that the voltage of the audio waveform
is not affected by the presence of, or changes to, the
load impedance. As an example, let’s fix the output
voltage to 28 Vrms (about 100 W continuous into 8 Ω)
and consider what happens as the load impedance
changes, Fig. 19-4. An ideal (theoretical)constant
voltage amplifier is an unlimited source of current.
As the load impedance drops, the voltage is
unchanged and the current increases, satisfying the
power equation. Each halving of the load impedance
doubles the output current and therefore the power
into the load, so long as the voltage remains
constant, which it can for this hypothetical amplifier.
So, the more paralleled loudspeakers, the lower the
load impedance, and the more current (and watts)
from the amplifier. This makes it seem like a good
thing to parallel more loads onto the amplifier, or to
reduce the load impedance of the loudspeaker to a
very low value to “get more watts,” Fig. 19-5.
A real-world amplifier is not an unlimited source
of current, so this behavior no longer holds with
decreasing load impedance. The voltage eventually
drops as you daisy-chain additional loudspeakers
onto the amplifier. The output power may continue
to increase (the shaded region of Fig. 19- 6) but the
voltage is dropping. Below about 4 Ω, this amplifier
is no longer a constant voltage source. If these loud-
speakers were spread along a parade route, this
voltage drop will result in an audible drop in the LP
from the first loudspeaker as additional loud-
speakers are daisy-chained along the route. So,
adding more loads may increase the output power
from the amplifier, but the sound level from each
loudspeaker is reduced because the voltage is drop-
ping. You get the highest LP from the first loud-
speaker if you disconnect the other ones. In short,
the amplifier’s best performance is achieved when it
is operating as a constant voltage source, or stated
another way, when it is not excessively loaded.
19.5 The Equivalent Amplifier Size–EAS
If the MIV of the loudspeaker is known, we can
calculate the required voltage capabilities of the
power amplifier. The MIV was measured using a
shaped-noise spectrum with 6 dB crest factor. This
means that the peak voltage will be twice the rms
voltage. For MIV = 30 Vrms, the Vpeak will be 60 V.
Since amplifiers are rated using sine waves (3 dB
crest factor), to pass a 60 V peak the sine wave
rating must be 60 (0.707) = 42.4 Vrms.
The amplifier is a constant voltage source into
8 Ω, and an 8  Ω rating is typically given for a
commercial amplifier, the sine wave power rating of
the amplifier must be
(19-3)
Eq. 19-3 calculates EAS from MIV (assumes 6 dB
crest factor noise)
So, an amplifier with a sine wave power rating of
225 W will be able to pass the MIV = 30 Vrms to the
loudspeaker for 6 dB crest factor noise. We can
create a general equation for determining the EAS
Figure 19-4. Audio power from an ideal voltage source.
Figure 19-5. Audio power from a real-world voltage
source.
28 Vrms
28 Vrms
28 Vrms
28 Vrms
28 Vrms
28 Vrms
28 Vrms
1.75 A
3.5 A
7 A
14 A
28 A
56 A
112 A
16 Ω
8 Ω
4 Ω
2 Ω
1 Ω
0.5 Ω
0.25 Ω
50 W
100 W
200 W
400 W
800 W
1600 W
3200 W
CAW = Continous Average Watts
Esine
Isine
Zload
CAW
28 Vrms
28 Vrms
24 Vrms
20 Vrms
?
?
?
1.75 A
3.5 A
6 A
10 A
16 Ω
8 Ω
4 Ω
2 Ω
1 Ω
0.5 Ω
0.25 Ω
50 W
100 W
150 W
200 W
Esine
Isine
Zload
CAW
?
?
?
?
?
?
Not Recommended
Figure 19-6. Real-world voltage source is current-
limited.
Amplifier Loading
(ideal voltage source above 4 Ω)
Excessive
Loading
Volts
Load Impedance–Ω
0           2            4            8            16         32
Constant Voltage
W
E2
R
------
=
42.42
8
------------
=
225 W
=

Power Ratings for Amplifiers and Loudspeakers
431
from the MIV. The EAS is the 8 Ω sine wave rating
of the amplifier that can pass the test waveform at
the conclusion of the MIV test.
Eq. 19-4 is the general equation to calculate EAS
from MIV.
(19-4)
The EAS assumes a 6 dB crest factor signal. It
gives a practical amplifier rating for a given loud-
speaker, assuming that it is desirous to achieve the
maximum possible LP without damage, which
requires application of the MIV to the loudspeaker.
The EAS gives a simple, one number specification
for purchasing an appropriate amplifier for a given
loudspeaker. It frees the designer from calculating
the required amplifier size from the loudspeaker
power rating, which is often exaggerated or ambig-
uous due to the impedance-dependence. It should be
possible to drive this EAS amplifier to the onset of
clipping without thermally damaging the loud-
speaker. Of course, it is never a good idea to drive
something to its thermal or mechanical limits, so
operating the amplifier below clipping ensures a
long life for the loudspeaker.
In contrast to a loudspeaker power rating, the
EAS is an amplifier rating that is part of the loud-
speaker’s specifications.
Note that this is for 6 dB crest factor program
material. In practice, it is likely that the crest factor
will be higher. So, if the EAS-rated amplifier is
driven to clipping with typical speech or music, the
rms voltage to the loudspeaker should be below the
MIV (due to the higher crest factor of real-world
program material) and the loudspeaker should not be
in danger of thermal damage.
The expression of the MIV as an EAS is only
necessary because of the industry’s insistence on
rating amplifiers in terms of watts. If all loudspeakers
were specified using the MIV, and amplifiers were
rated in Vrms into a minimum Z (ideally expressed in
dBV), power ratings could be avoided altogether.
What matters is the voltage that the amplifier can
produce across the load. Stated another way, for the
amplifier to be a constant voltage source, it must be
able to source the current demanded by the load
impedance. If the load impedance is not too low, its
current demands can be satisfied by the amplifier and
need not be considered further. This allows the signal
transfer between amplifier and loudspeaker to be
assessed by voltage only. If not, then the combination
of voltage and impedance, or voltage and current,
must be considered. Power is just a way to express
this as a single number. Eq. 19-5 are power equations.
(19-5)
where,
W is the power in watts,
E is the electro-motive force in volts,
I is the current in amperes,
R is the resistance in ohms.
A power rating alone is useless, because it
doesn’t yield sufficient information for determining
the amplifier’s output voltage. A “100 W” amplifier
could be 33 V @ 3 A, 3 V @ 33 A, 100 V @1 A, or
1V @ 100 A.
19.6 Power from a Voltage Source
Let’s move past the practicality, simplicity and
elegance of considering only the voltage from the
amplifier. This can be necessary when handling
exceptions and special cases. The ability of the
amplifier to maintain its output voltage depends on
its ability to source the current required by the load.
If the current demand gets too high, the voltage may
sag. Let’s examine some factors that tax the current
production of the amplifier.
Amplifiers don’t make power—they convert it.
The audio power that comes from an amplifier must
in turn come from the utility outlet that it is
connected to. This is why the wire gauge of the line
cord matters, and why long extension cords can be a
problem due to voltage drop across the wire’s resis-
tance (line loss). The maximum output voltage from
an amplifier can be determined by measuring it into
an open circuit, which is a load with a very high
impedance relative to the amplifier’s source imped-
ance. For modern amplifiers, this typically means
8Ω or higher, given the fractional output impedance
(0.01 Ω or less) of modern amplifiers.
With a resistive load present, the power flow can
be determined by the power equations previously
given in Eq. 19-5.
This is the “apparent power” from the source.
Apparent power (in volt-amperes) assumes that the
voltage and current are in phase, which is only the
case for a purely resistive load. The actual power in
watts is likely less than the apparent power given the
nature of real-world loads, where reactive (storage)
properties reflect some of the power back to the
amplifier from the load. In depth calculations
account for this by considering the phase angle
EAS
10
20
MIV
log
6
–
10
-----------------------------------
=
W
E2
R
------
=
IE
=
I 2R
=

432
Chapter 19
between the voltage and impedance, or a “power
factor.” I’ll assume a resistive load for now and use
watts as the unit. The power equation says that the
apparent power from a 120 Vrms, 20 A utility power
circuit is 2,400 W. If an amplifier were 100% effi-
cient, it could produce 2,400 W or 34 dBW of audio
power from the 120 V, 20 A outlet when passing a
sine wave. The conversion efficiency of modern
switch-mode amplifiers–Class D and its vari-
ants–can exceed 80%, meaning that an amplifier
with a sine wave rating of 2 kW continuous is a
possibility. In effect, the largest amplifiers can
produce sine waves that are very close in voltage,
current and therefore power to a household electrical
circuit in the USA—an incredible achievement in
amplifier evolution. Of course utility power is a
60 Hz sine wave. Music and speech signals are
broad band, and will produce considerably less
power than a pure sine wave due to their higher crest
factor. Let’s go with this theoretical 2,400 W ampli-
fier (34 dBW) for now. How much audio power can
you really expect from this amplifier?
The amplifier’s job is to accurately reproduce the
signal voltage presented to its input. It’s not techni-
cally correct to call it a power amplifier, because the
output power has nothing to do with the input
power—only the input voltage. It has to amplify this
voltage and preserve the wave shape while sourcing
the current being demanded by the load. As I
showed earlier, this gets tougher as the load imped-
ance drops. For a constant voltage interface (any
modern power amplifier), current, and therefore
power, is a responder. It is the “result” of the drive
voltage and load impedance. Since the load imped-
ance is fixed (unless your loudspeaker overheats,
causing its impedance to rise), the current (and the
resultant power) can only be changed by adjusting
the drive voltage to the amplifier. For this reason, I
always do my initial assessment of an amplifier by
measuring its maximum open circuit sine wave
output voltage, followed by verifying that this
voltage can be maintained into an 8 Ω resistor. Next
I consider the minimum load impedance for which
the amplifier can sustain this voltage, using a1 dB
drop as the failure criteria. The maximum output
voltage can be measured with an rms voltmeter or
oscilloscope. It can be determined by calculation
from the 8 Ω power rating provided by the manufac-
turer using the power equation, solved for voltage.
(19-6)
where,
W is the 8 Ω power rating,
R is the load resistance.
It is normal to find excellent correlation with the
amplifier’s published specifications. I looked at
several of the largest available amplifiers and
assessed their voltage output. An increasing number
of them have approximate maximum sine wave volt-
ages in the 130 Vrms range, which is a peak voltage
close to 200 V, found by multiplying Vrms by 1.414.
The term “200 volt rails” is gaining popularity
among the amplifier crowd. A sine wave of 140 Vrms
will produce the following wattages into a test
resistor from an ideal amplifier (one that can source
the required current):
1.
2,500 W into 8 Ω..
2.
5,000 W into 4 Ω..
3.
10,000 W into 2 Ω.*
*theoretical value only!
Note that all of these rated powers exceed the
2400 W that is available from the electrical outlet,
especially if the amplifier has multiple channels. At
these wattages, the available utility power may be
the limiting factor with regard to what amplifier can
output. To assess the music/speech power, I’ll take
the rail voltage and convert to dB, and subtract the
crest factor of the program material. I’ll be generous
and assume a crest factor of 10 dB, which is typical
of slightly clipped pink noise, in other words, an
amplifier being driven pretty hard. I’ll then convert
the level back to voltage, the field quantity upon
which all power ratings are based.
When applied to an 8 Ω resistive load the power is:
This is a far cry from the sine wave power rating
of the amplifier, and well within the ability of the
utility power circuit.
If this amplifier can sustain 63 Vrms into a 4 Ω load
(it probably can), the power doubles to
E
WR
=
dBVpeak
20
200
log
=
46 dBV
=
dBVavg
46  dBV
10 dB
–
=
36  dBV
=
Emax
10
36
20
------
=
63 Vrms
=
W
632
8
--------
=
496 W
=

Power Ratings for Amplifiers and Loudspeakers
433
As you can see, the power drops dramatically
when you substitute real-world program material for
the sine wave. Now, keep in mind that sometimes
real world program material is a sine wave. A
synthesizer can produce very low crest factor signals
that can trip circuit breakers and burn-up a
subwoofer connected to the amplifier. But, this is
the exception, not the rule. The vast majority of
loudspeakers in the marketplace have rated imped-
ances of 4 Ω or higher. The average impedance is
higher yet, which is what the amplifier sees if you
are playing broadband program material (speech or
music). So, to say that we can draw 1 kW from a
“2400 W” amplifier is being generous.
It would not be unusual to be able to drive our
2,400 W amplifier to clipping into a modern line
array box using a pink noise signal. Does that mean
that the box is “handling” 2,400 W? No. The high
crest factor of the pink noise and the real-world
higher-than-rated average impedance of the loud-
speaker means that the power flow is far less than
2,400 W. It is handling the full voltage swing of the
amplifier, but not its full output power. The high
crest factor signal and real world loudspeaker
impedance can allow me to access the full voltage
swing of a theoretical amplifier rated at
5kW/channel into 4 Ω. But, the amplifier will run
out of voltage swing before it runs out of power.
The impedance of a real-world loudspeaker is
higher than its “rated” impedance over most of its
bandwidth, Fig. 19-7. While some amplifiers can
drive “2 Ω loads” it would be rare to ever encounter a
true 2 Ω load in practice other than with a bank of test
resistors. Besides the voltage drop, there are other
reasons why very low impedance loads (i.e. 2Ω) are
problematic, including the requirement for very
heavy loudspeaker cable, and the detrimental affect
on damping factor. While you may “get the most
watts” into a 2 Ω load, the amplifier will perform
better if it is not so heavily loaded. We wouldn’t
dream of putting weights in the trunk of our car to
make it produce more power to attain a target speed.
It is equally silly to load down an amplifier for the
sole purpose of “getting more watts.”
19.7 Burst Testing
If the power from a source cannot be sustained over
time, it may be interrupted periodically to avoid
damage to the source or the production of excessive
heat in the load. Examples include pumping the
brakes on your car when descending a steep hill, or
breaking a long weld into shorter segments. A source
that cannot run continuously without overheating
may be given a duty cycle rating. Playing a repetitive
waveform (like a kick drum) is like pumping the
brakes on your car. The power and heat production
are reduced when compared to the steady-state
condition. That’s a good thing, since otherwise we’d
be tripping circuit breakers and burning voice coils.
Ironically, the largest power ratings on an amplifier
spec sheet result from “Burst testing.” This is a
method developed for measuring cell phone signals,
and it is also used on power amplifiers. A burst test
hits the amplifier with a signal that lasts only a few
milliseconds, Fig. 19-8. These bursts produce some
very high amplitude peaks, but only for a very short
period of time. Looked at another way, burst testing
can prevent the circuit breaker from tripping (a good
thing) and allow our 2,400 W amplifier to drive a 2 Ω
load at its full output voltage. This theoretically
doubles the power to nearly 5 kW from a single
amplifier channel. Is this a legitimate power rating
for the amplifier?
W
632
4
--------
=
992 W
=
Figure 19-7. Load impedance seen by amplifier.
Figure 19-8. 6.5 cycle tone burst for 1⁄1 octave band
centered at 80 Hz.
Resistive Dummy Load
Reactive Dummy Load
Full-Range Loudspeaker System
Ω
20
10
0
Impedance
0.05           0.2      0.5     1      2         5    10 kHz
200
160
120
80
40
0
−40
−80
−120
−160
−200
−46.6 −26.6  −6.6   13.4    33.4    53.4   73.4   93.4   113.4  133.4 153.4
Clipped Signal at
160 V Rail
Time–ms
Volts

434
Chapter 19
The moment-by-moment voltage amplitude
values of an audio waveform can be very high.
Multiplying the instantaneous voltage by the instan-
taneous current yields the instantaneous power.
Instantaneous power is a means to an end, not the
end itself. It must be integrated overtime to find the
root-mean-square voltage and the average power.
While marketing types love to publish burst power
specifications, and end users will make buying deci-
sions based on them, it is ill-advised to allow charac-
teristics that are transient and difficult to assess (i.e.
peaks) to strongly influence the buying decision.
While burst signals can have very high ampli-
tudes, they are quite short in duration. The wave-
form produced by a kick drum is made up of multiple
frequencies that are not phase coherent in the load
due to the non-linear phase response of the
subwoofer, which increases the crest factor of the
waveform. The audio power produced by a kick
drum is not all that high, due to its high crest factor
and low duty cycle. A far more punishing waveform
would be the continuous sine or square wave output
from a synthesizer. This is the only way that you will
challenge an amplifier to produce its full rated power,
and you may burn up your subwoofer in the process.
While it is a good thing for an amplifier to be able to
produce waveforms with very high instantaneous
power, it is not often clear to consumers what this
means and under what conditions it is measured (the
fine print). All they see is a huge number with
“watts” after it and may assume that it is a contin-
uous rating and consider it as such. Or worse yet,
they may think that it is something they need and
something that the loudspeaker has to handle.
19.8 Power Rating Possibilities
There are many possible tests for rating the power
output of an amplifier. The most brutal is the use of
a continuous sine wave, with the amplifier
connected to a resistive load and operated for a
specified period of time—“continuous” implies
“indefinitely.”
I am a big fan of this method, for several reasons.
1.
It’s a simple test. There’s no way to fudge it,
fool it, fake it or misrepresent it.
2.
The rating can be easily verified in the field with
simple instrumentation.
3.
I can easily determine the output power with
other waveforms (music or speech) by substitut-
ing the crest factor of the waveform for that of
the sine wave. This always results in less power
flow due to the higher crest factor of the more
complex waveforms.
4.
The distortion of a sine wave is much easier to
measure than the distortion of more compli-
cated waveforms, so it is easy to determine
when the amplifier has reached its maximum
linear output level.
As a system designer, I want a simple, no-
nonsense conservative rating of what the amplifier
can do with a known waveform (i.e. a sine wave). I
can increase the crest factor (de-rate the amplifier)
to know the level that will be produced by music or
speech. Note that it is unlikely that the amplifier will
ever have to pass a full-scale sine wave into a load
for an extended period of time in an audio applica-
tion, but the continuous sine wave power rating is
still a useful rating method and benchmark.
While the term “power amplifier” enjoys wide-
spread use, it has led to a “power mind set” when
interfacing amplifiers to loudspeakers. This is unfor-
tunate, and has contributed to many misconceptions
in the marketplace. The frequency response of a
loudspeaker is a function of the drive voltage to the
loudspeaker, not the applied power. The voltage
delivered to the loudspeaker by the amplifier is
independent of the loudspeaker’s impedance. I can
sweep a 2.83 Vrms sine wave from 20 Hz to 20 kHz
and the loudspeaker gets exactly 2.83 Vrms at every
frequency. The current drawn from the amplifier,
and therefore the power, varies as a function of
frequency due to the complex impedance curve of
the loudspeaker. An attempt to feed a loudspeaker
the same power in each 1 ⁄ N-octave band would
result in a very uneven acoustical frequency
response from the loudspeaker.
Adjustments to this drive voltage are directly
observable in the loudspeaker’s frequency response.
Loudspeaker equalization is accomplished by modi-
fying the drive voltage, not the applied power. It is
proper to consider the amplifier as a voltage source
with sufficient available current to satisfy the
demands of the loudspeaker’s impedance. While the
product of voltage and current can be expressed as
power in watts, keeping them separate yields much
more insight into the amplifier/loudspeaker inter-
face. As I have shown, it is the applied voltage to
the loudspeaker which is the primary quantity of
interest.
19.8.1 Real World Power Generation
To summarize, it is theoretically possible for a
highly efficient audio power amplifier to produce
continuous sine wave power in the 2 kW range when
connected to a 2400 W utility circuit. For it to actu-
ally have to do this is unlikely, given the nature of

Power Ratings for Amplifiers and Loudspeakers
435
music and speech signals and the real-world imped-
ance of loudspeakers. Rating the amplifier based on
a very low load impedance, tone burst signal and in
linear units (“watts”) is definitely putting the best
face on its performance. Since no standard exists for
“burst testing” amplifiers, you can bet that it is done
differently by every manufacturer, since the burst
duration and duty cycle affect the results. This
doesn’t make the numbers meaningless, but you
won’t be able to use them to compare different
makes and models.
It would be better to say that this amplifier has a
rail voltage of 200 V for passing the peaks in the
audio waveform, and that it can sustain a sine wave
with this peak value indefinitely into an 8 Ω load,
and for a few cycles into lower load impedances. All
of this can be determined from a simple 8 Ω sine
wave power rating.
19.8.2 Things Amplifiers Hate
There are two conditions that power amplifiers don’t
like—low crest factor signals and 2 Ω loads. The
continuous sine wave testing is by far the most
revealing with regard to how much power the ampli-
fier (and the electrical outlet) can source. Few if any
power amplifiers can maintain their output voltage
into 2 Ω with a sine wave source. This makes the 8 Ω
sine wave rating attractive to the system designer as
a guaranteed performance measure.
19.8.3 Burst Testing Results
Amplifiers get their largest power ratings from tone
burst testing. Ironically, that is the easiest signal for
most amplifiers to pass, allowing them to produce
their maximum voltage for a few tens of millisec-
onds, even into 2 Ω with both channels driven. It’s a
shame that this number wields so much influence in
the marketplace.
19.8.4 Conclusion
Some general conclusions regarding amplifier
power ratings can now be drawn. Here are some of
the more important ones.
1.
A 1 kHz sine wave rating into 8 Ω is the best
measure of an amplifier’s performance for a
sound system designer. The amplifier acts as a
constant voltage source into 8 Ω, and its output
voltage is typically independent of frequency
over the vast majority of the amplifier’s pass
band. The sine wave voltage can be scaled to
any crest factor by calculation. This makes
amplifier selection and accurate sound pressure
level calculations at the drawing board possible.
2.
Don’t load your amplifiers to 2 Ω to “get more
watts.” When the voltage sags, even if the power
increases, you are losing output level and engag-
ing protection mechanisms.
3.
Amplifiers don’t like low crest factor signals. If
you excessively compress or limit the program
material, and drive the amplifier to clipping,
you are likely engaging the amplifier’s protec-
tion mechanisms, with potentially audible
ramifications.
4.
Don’t compare amplifiers using power ratings
derived from burst testing. These are vanity
specs that look impressive but reveal very little
about the amplifier’s performance.
The sound system designer is well-served by the
simplest amplifier testing and rating method. Sine
waves are commonly used to establish the maximum
output level of the other constant voltage sources in
the signal chain, such as mixers and signal proces-
sors. Sine wave amplifier ratings, ideally expressed
in dBW rather than watts, provide a simple, logical
way of rating power amplifiers.
19.9 Putting It All Together
Part of the commissioning process for any sound
system is the establishment of the LP at the listener’s
ears. Here is a step-by-step approach.
With the mixer producing an average level of
+4dBu for broad band program material, pink noise
or music, and the signal processing appropriately
configured and set at or near unity, a line level
signal should be present at the amplifier’s input. The
amplifier’s sensitivity control determines the output
voltage produced by the amplifier in response to this
input voltage. This ultimately determines the elec-
trical power applied to the loudspeaker, as well as
the LP produced from the loudspeaker.
19.9.1 A Warning
Before proceeding, a word of warning. Improper
setting of the amplifier’s sensitivity can damage
loudspeakers and hearing. Before turning on ampli-
fiers be sure that:
1.
Any signal processing required by the loud-
speaker is in place and properly configured,
especially crossover networks.

436
Chapter 19
2.
The amplifier(s) is properly connected to the
loudspeaker. Be especially careful with biamped
and tri-amped systems, as there are no standards
that govern the wiring of multi-pin connectors.
3.
The amplifier(s) is appropriate for the loud-
speaker, based on the MIV described previously.
4.
The LP is properly monitored during adjustment
and kept at safe levels.
19.9.2 A Common Misconception
The amplifier’s input sensitivity does not affect nor
determine the maximum voltage that can be
produced by the amplifier or the power rating of the
amplifier. Some users feel that unless the input
sensitivity is maximized, they can’t get all of the
power. Not true. This control determines the input
voltage required to produce a given output voltage.
If you turn it down, you can still drive the amplifier
to clipping. It just takes more input voltage to do so.
19.9.3 The Input Sensitivity Control
The input sensitivity control may be on the front or
back of the amplifier. One can make an argument for
either. Consider the extreme settings of this control.
Fully counter-clockwise is the minimum sensi-
tivity setting. On most amplifiers, this is”off.”
Simple enough.
Fully clockwise is the maximum sensitivity
setting. This produces the highest output voltage
from a given input voltage. Many use this as the
default setting, but there can be ramifications.
Some amplifiers have selector switches that scale
the sensitivity range.
There exists several philosophies for setting the
amplifier’s sensitivity, justified by the various appli-
cations for which the amplifier may be used. I’ll
consider the major ones here.
Before I get into the details, I’ll start by saying
that for quick setups and for simple systems, the
final step of system gain structure is to simply
power up the amplifier and increase input sensitivity
until the desired LP is produced. For many systems,
it really is that easy. Just make sure that there is a
strong meter reading on the mixer’s meter (i.e.
0VU) so that you have a visual level reference while
mixing.
This is the correct sensitivity setting so long as
the amplifier isn’t clipping, the LP isn’t dangerous,
and the loudspeaker isn’t overheated. Don’t let the
following discussion of the details confuse you. If
done in the proper order, setting the amplifier’s
sensitivity is no more difficult than adjusting the
volume of your radio or TV.
Doing it in reverse order by starting with the
amplifier at maximum sensitivity can make it much
harder, or even impossible, to achieve a good system
gain structure. In some cases we may end up with it
fully clock-wise, but we don’t want to start at
maximum sensitivity.
The Details
At their maximum sensitivity setting, most ampli-
fiers can be driven to full output voltage by just over
one volt at the input. A common example is a sine
wave of +4 dBu or 1.23 Vrms that falls within the
rated bandwidth of the amplifier. It may be a bit
higher or lower, depending on the make and model.
At full operating level the mixer should be
producing about +4 dBu average, plus peaks of
+20 dB, for typical program material. This is a
maximum output level of about +24 dBu. The signal
processing is passing this level at unity. This means
that the signal level at the amplifier input is about
+20  dB relative to what the amplifier needs to
produce its full output. That’s fine, as it simply
means we have more voltage than what we need to
access the amplifier’s full voltage swing. The ampli-
fier’s sensitivity can be reduced accordingly. It’s
usually better to have too much of something than
not enough. By giving the amplifier a higher sensi-
tivity than is needed, manufacturers assure broader
compatibility. Input sensitivity can be reduced by
the simple adjustment of a control.
In a modern system, the signal level presented to
an amplifier may be far lower than +4 dBu. The
most common cause is the integration of consumer
gear into professional systems. It’s also becoming
increasingly common for digital signal processors
(DSP) to introduce 10 dB or more of attenuation to
the signal rather than operating at unity. This is one
way that they can handle the high voltages produced
by some mixers. If a crossover network is part of the
DSP configuration, the dividing of the spectrum
reduces the signal level.
Amplifiers need adequate “gain reach” to handle
any of these situations.
Setting the Amplifier’s Sensitivity
Amplifiers should always be set using a broadband
signal. Pink noise works especially well, as it
emulates an intense music signal in both spectral
content and crest factor. Unlike music or speech, it
is easily measured with a digital voltmeter.

Power Ratings for Amplifiers and Loudspeakers
437
Ultimately, the amplifier’s sensitivity setting
determines the LP produced at the listener.
That becomes the main consideration for the
correct setting. When the LP is right, the sensitivity
is right. Of course the LP should be appropriate for
the application and not pose a danger to listeners.
Here’s an orderly, logical method for setting the
control.
Step 1 is to set the amplifier sensitivity to the
fully counter-clockwise position. The mixer should
be producing about 1 Vrms of pink noise. The signal
processing should be in place and configured
correctly for the loudspeaker attached to the
amplifier.
Advance the input sensitivity slowly until:
1.
It’s loud enough, or
2.
The amplifier clips, or
3.
The MIV of the loudspeaker is reached.
Hopefully Item 1 is realized before Items 2 or 3.
Let’s consider some caveats of each.
1.
It’s loud enough. For many systems this can be
accomplished by just listening to some familiar
program material, ideally similar to what the
system will be used for. This empirical approach
is the fastest way to set the sensitivity. You may
want to involve the client, and if you’re brave, a
committee. 
Simple listening can be used if there is no
danger of clipping the amplifier or overpow-
ering the loudspeaker. It’s always interesting to
get a measured LP on what you have determined
by listening, for documentation.
Pink noise and a sound level meter may be
required if the system has a specified LP that it
must produce. Always make sure that this is a
realistic target that will not expose listeners to
damaging levels.
2.
The amplifier clips. The clip light on the ampli-
fier lets you know when you have hit the power
supply rails with the signal peaks. Unlike line
level devices, amplifier lights usually illuminate
at actual clipping. Slight clipping is usually not
audible and poses no threat to loudspeakers if
the peaks are within the loudspeaker’s excursion
limits.
In any event, when the clip light comes on,
you must stop increasing the sensitivity. If the
LP must be higher, you’ll need a larger ampli-
fier or a more efficient loudspeaker.
3.
The MIV of the loudspeaker is reached. A true
rms voltmeter can be used to monitor the ampli-
fier voltage as the sensitivity is increased. If you
reach the MIV and it’s still not loud enough, you
should assess the situation carefully. Higher LP
may be ill-advised.
Fig. 19-9 shows the voltmeter connection and
“stop criteria” for setting the amplifier’s sensitivity.
19.9.4 The 30/30 Guideline
Many systems can be “roughed in” using the 30/30
guideline. Here’s how it works:
• At 30 ft from the loudspeaker, about 10 m, the
sound level will be about −20 dB relative to the
level at 1 m, due to inverse-square law level
change.
Figure 19-9. Criteria for setting the amplifier’s sensitivity.
Setting the Amplifier Level
1. Target reached.
or
2. Amplifier clips.
or
3. Loudspeaker MIV reached.
Emax =    WR
Example
Power rating =  200 Wcont
Emax =    200 × 8 = 40 Vrms (noise)

438
Chapter 19
• At 30 Vrms applied to the loudspeaker, the power
is approximately 100 W continuous into an 8 Ω
loudspeaker. This is about +20 dB relative to the
2.83Vrms used to measure the loudspeakers sensi-
tivity. Also, this is well within the power handling
capabilities of most full-range medium to large
format sound reinforcement loudspeakers.
• The average sensitivity of the loudspeaker can be
read from its specification sheet or data viewer,
Fig. 19-10.
This means that if you adjust the amplifier
input sensitivity to produce the loudspeaker’s
average sensitivity at 30 ft, you are feeding about
100 W continuous to the loudspeaker. This is a
good place to pause when setting the playback
level of the system. You can then assess the
situation.
Of course, you can use any target LP. The
loudspeaker’s average sensitivity is just a guide-
line. If the system is loud enough at a lower LP,
stop there.
• Is it loud enough? If not how much more level is
needed? Every additional 3 dB doubles the power
to the loudspeaker, and the required size of the
amplifier. Proceed with caution!
• Is the amplifier clipping? If it is, reduce the
sensitivity.
• Is the loudspeaker strained? If the sonic character
of the noise changes as you approach this level,
turn it down!
A Word of Warning
An amplifier set to maximum sensitivity can be a
disaster waiting to happen. Any applied signal will
be passed on to the loudspeaker at a potentially very
high amplitude, including pops, glitches, feedback
and other undesirables. The sensitivity control is the
last line of defense against such signals, so be
VERY careful when max-ing out amplifiers—espe-
cially big ones!
Some Practical Considerations
While it is technically correct and in most cases
advisable to operate amplifiers at less than their
maximum sensitivity, for some types of systems this
can present problems. Consider the following:
1.
Exposed sensitivity controls can be tampered
with. A passer-by or ill-informed user may
max-out your carefully adjusted sensitivity knob
and think they are doing you a favor.
2.
Systems that have many amplifiers, such as
arenas and touring rigs, are usually controlled by
a computer network. If the physical sensitivity
control is reduced, the full control range may
not be accessible from the PC. In either case, it
is a common practice to operate amplifiers with
their sensitivity control at its maximum setting.
The level is attenuated by software or by turning
down the output stage of the device directly
preceding the amplifier, usually a digital signal
processor (DSP). The down side is that some
amplifiers are noisy with their sensitivity set at
maximum.
You can easily arrive at the required attenuation
ahead of the amplifier to allow maximizing the
amplifier’s sensitivity if the control is marked in dB.
“Gain trading” transfers the “dB below maximum”
from the amplifier’s input sensitivity control, to the
output of the previous stage, Fig. 19-11.
19.10 Multi-way Loudspeakers
Some loudspeakers require more than one amplifier.
For tri-amped systems start by setting the sensitivity
for the mid-frequency component for the target LP.
Advance the LF and HF sections to balance with MF.
Figure 19-10. Average loudspeaker sensitivity as shown
in the Common Loudspeaker File format viewer.
(Courtesy www.clfgroup.org.)
dB
20
3.28 30
⁄
(
)
log
=
20
–
 dB
=
dB
20
30 3.28
⁄
(
)
log
=
20 dB
=
dB
90
85
80
75
70
65
60
55
50
45
40
35
63  125 250 500 1k   2k   4k   8k  16k Hz
Sensitivity
Avg.

Power Ratings for Amplifiers and Loudspeakers
439
This can be done by listening, or better yet, with a
1⁄3octave real-time spectrum analyzer.
For bi-amped systems, start with the LF section
and then add HF for the proper balance.
19.10.1 Fixed Gain Settings
Some amplifiers allow the voltage gain to be fixed
to a certain value, such as 26 dB or 32 dB. The input
sensitivity control is then operated at maximum.
This can facilitate driving multi-way loudspeakers
from DSPs, where the spectral balance set in the
DSP needs to be preserved through the various sized
amplifiers that drive the loudspeaker system. It can
also facilitate mixing multiple brands of amplifiers.
In this application the amplifier just becomes a
voltage gain block in between the amplifier and
loudspeaker.
A specific amplifier gain setting may be required
for the limiter stages in the DSP to function correctly
for a given loudspeaker model. Consult the DSP
manufacturer for the proper setting of these switches.
Note that these don’t change the maximum
possible output voltage of the amplifier, only the
input voltage required to reach it.
19.10.2 Powered Loudspeakers
Some loudspeakers have internal amplifiers. If a
sensitivity control is provided, it is adjusted exactly
as if the amplifier were separate from the
loudspeaker.
If no control is provided, then the level is set in
the last stage of the signal processor driving the
loudspeaker. This allows the mixer to be operated in
its proper level range (i.e. 0 VU) without producing
excessive LP in the audience. If no signal processor
is present, add one. In some cases it is necessary to
externally attenuate the mixer’s signal if it is
directly connected to a powered loudspeaker that
has no sensitivity control.
19.11 System Gain Structure
The best system gain structure results when each
component in the signal chain is operating in the
optimum part of its dynamic range. Mixers and
signal processors incorporate metering to provide
visual indication that this has been established. The
amplifier’s job is to produce the gain needed to
achieve the desired LP at the listener. The ampli-
fier’s input sensitivity is variable for this reason. It’s
setting is correct when the desired LP is achieved in
the house with the mixer’s meter indicating that it is
operating with good signal-to-noise ratio and suffi-
cient peak room. Historically this is 0 VU on a
volume indicator, or an average level of −20 dB rela-
tive to the full output voltage of the mixer.
19.12 Combining MIV and EAS
The CLF data viewer gives all of the informa-
tion needed by the sound system designer for
selecting a loudspeaker and amplifier. Fig. 19-12
shows the freeware CLF Viewer.
Note that this loudspeaker has an average sensi-
tivity of 88 dB, and an MIV of 30 Vrms. The EAS is
224 W, so if an amplifier with a sine wave rating of
this value is used with the loudspeaker, about 20 dB
of gain above the average sensitivity can be
expected at 1  m. This is for 6  dB crest factor
program. The LP can be reduced accordingly for
Figure 19-11. Gain trading to maximize amplifier input sensitivity
Program
Source
Mixer
Signal
Processor
Amplifier
Loudspeaker
Before “Gain Trading”
Output Stage
Gain Setting
Input Sensitivity
Setting
Output Stage
Gain Setting
Input Sensitivity
Setting
After “Gain Trading”
 0 dB
−12 dB
 −12 dB
 0 dB

440
Chapter 19
higher crest factor signals. This amplifier, if driven
to the threshold of clipping with typical program
material, should pose no thermal danger to the loud-
speaker. The 1 m maximum LP can be extrapolated
to any distance using the inverse-square law.
Most computer room modeling programs can
utilize this data file directly for predicting the
performance of a system.
Figure 19-12. The CLF Viewer. (Courtesy www.clfgroup.org.)

Chapter 20
Computer-Aided System Design
by Pat Brown
441
20.1 Spherical Loudspeaker Data  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 443
20.2 Near Field vs. Far Field  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 444
20.3 The Measurement Process . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 445
20.4 Loudspeaker Arrays . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 447
The Dynamic Link Library—DLL  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 447
Magnitude vs. Phase Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 448
20.5 Direct Field Modeling  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 449
20.6 Room Model Detail  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 449
Predicting Room Reflections . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 450
The Objective of Room Modeling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 451
20.7 Room Acoustics—An Overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 451
The Room Impulse Response—RIR  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 451
Post-Processing the RIR  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 452
20.8 Absorption  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 453
Modeling with Absorption Coefficients  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 453
Sound Behavior . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 454
The Direct Sound Field . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 454
The Early-Reflected Sound Field  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 455
Late Reflections or Echoes  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 455
Reverberation  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 456
Room Measures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 457
20.9 Realistic Room Models  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 457
20.10 Universal Room Modeling Tips . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 460
20.11 Conclusions  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 461
References  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 461


Computer-Aided System Design
443
My first foray into sound system design was in the
late 1970’s. I had installed a sound system in an
octagonal worship space, designed for pipe organ
support. The poor speech intelligibility of my design
was obvious to all, including me. It was then that I
found the first edition of this book, Sound System
Engineering by Don and Carolyn Davis at the local
electronics parts house. The now famous “yellow
book” consumed much of my time from that point
on, clearly showing that I was making some serious
mistakes in my system designs. Every principle
learned has proven timeless. What we have gained in
the last 40 years is the ability to crunch the numbers
faster and display the prediction results with stun-
ning graphics. But, the underlying principles have
remained unchanged. Any serious designer must
begin with those. Only then should one consider
using software tools to speed up the process. Before
using a computer, one must learn what to compute. It
is truly humbling to contribute to the fourth edition
of the book that has formed my career.
I’ll begin this chapter with a surprising state-
ment—“Computers can’t design sound systems.”
While this may not be true in the future, it is true
now. Many potential sound system designers have
been dismayed after purchasing a sophisticated
room modeling program, only to find out that it is
basically a calculator that executes algorithms that
are based on approximations and assumptions
regarding sound wave behavior. They are further
dismayed to find that the usefulness of the program
is limited by their own understanding of basic
acoustics and electro-acoustics. That is not to say
that these programs aren’t sophisticated. Some are
incredibly complex, even artistic—a mixture of
deterministic calculations and software-specific
algorithms for simulating acoustic behavior based
on geometric principles. But, there will always be a
difference between acoustic predictions and reality.
Do sound waves behave like light rays? “Yes,” in
some ways, but “no” in others. A failure to realize
this will lead to surprises.
For an excellent overview of the history of room
acoustics modeling, see The Early History of Ray
Tracing in Room Acoustics by Peter Svensson. This
work clearly shows that acoustics modeling is a
game of approximations, assumptions and compro-
mise. It’s not simply a matter of number crunching.
Faster processor speeds and breathtaking graphics
have not removed the fundamental limitations of
modeling sound geometrically based on optical prin-
ciples, known as Geometrical Acoustics or GA.
That said, I am an enthusiastic supporter and
advocate of computerized room modeling as a tool
for the sound system designer. I would go as far as
to say that it is the only practical way to handle the
myriad of variables that influence the performance
of a sound system in an enclosed or semi-enclosed
space. Knowing the limitations of a tool allows its
capabilities to be fully exploited. This chapter is
devoted to enabling the sound system designer to
integrate computerized room modeling into the
design process.
Major principles of electro-acoustic behavior
have been presented elsewhere in this text. It is
requisite for the sound system designer to under-
stand how sound radiates from loudspeakers, and
how it interacts with the acoustic environment.
Acoustical prediction software attempts to model
this interaction, and provides a valuable tool that
allows the sound system designer to investigate
various loudspeaker selection and placement
scenarios—the crux of sound system design.
Selecting amplifiers and signal processing is trivial
when compared to selecting and placing loud-
speakers. In fact, the latter defines the former.
The principles presented in this chapter are
universal in their application to room modeling
programs. That is not to say that all room modeling
programs are created equal. When you buy one of
these programs, you are buying the knowledge,
skill, experience, prejudices and assumptions of the
developer. When terms like “perfect,” “accurate,”
and “precise” are used to market an acoustical
modeling program, you should run away.
The examples in this chapter were done using
CATT-AcousticTM.
The acoustical prediction process takes the
measured data of a loudspeaker, and injects it into a
virtual environment. It is our desire that the virtual
environment emulates the acoustical behavior of the
actual physical space. Given the complexities of
sound wave behavior in an enclosed space, one can
clearly see the challenge, as well as the utility of a
program that can even get close.
20.1 Spherical Loudspeaker Data
I’ll begin the discussion of room modeling by
focusing on the loudspeaker data. Garbage in,
garbage out. Data that is collected improperly will
produce erroneous results, no matter how sophisti-
cated the program is that uses it.
Axial and polar measurements have long been
used to characterize the performance of loud-
speakers. Room modeling programs utilize spherical
sound radiation data for modeling the behavior of a
loudspeaker in a room. A spherical data set is
measured over a full sphere of spaced positions
around the loudspeaker, and is therefore able to
characterize the loudspeaker’s directivity, Fig. 20-1.

444
Chapter 20
I have built a spherical loudspeaker measurement
system from scratch that currently produces loud-
speaker data files for many loudspeaker manufac-
turers for use in room modeling programs. The
many years of invested time and money have
provided some insights into what matters, and what
doesn’t with regard to loudspeaker data. Some of
my assertions may surprise you. “More” is not
necessarily “better.”
20.2 Near Field vs. Far Field
A modeling program assumes that the emerging
wavefront from a source is a sphere, and that it
expands spherically as the sound propagates away
from the source—like inflating a balloon. This is only
true in the far field of the source. The loudspeaker
data must be measured in the loudspeaker’s far field
for the spherical spreading assumption to be correct.
The term “point source” has both theoretical and
common-usage meanings in audio engineering. A
literal point source is infinitely small. Since direc-
tivity is achieved by interference, and interference
requires mass, a literal point source is omnidirec-
tional by definition and would emit acoustic power
that produces the same sound intensity in all direc-
tions. The spherical waves, simulated as rays or
particles emerging from the point, fall off at the
inverse-square law rate of level change as they prop-
agate outward from the source, Fig. 20-2. This
means that when the radius of the sphere doubles,
the area that the sound passes through quadruples.
Since the same sound energy is passing through a
progressively larger area, the sound intensity level
(LI) and resultant sound pressure level (LP) are
predictably reduced with increasing distance.
A physically realizable loudspeaker has size and
mass. The sound may not radiate evenly from all of
its surfaces, sides and edges, so the wavefront may
not be spherical near the source. This is definitely
true of multi-way devices as well as line arrays.
Even though the wavefronts from these devices are
not spherical when they are formed, the sound
travels at the same speed in all directions. This
means that the waves become increasingly spherical
as the distance from the source increases, since the
propagation distance, which is equal for all rays,
swamps out any differences in the length of rays
near the source. The distance from the source at
which the waves can be considered to be spherical is
the beginning of the far field. The inverse-square
law applies from this distance outward. So, all loud-
speakers obey the inverse-square law at remote
distances, but not necessarily up close. Note that
“spherical wave” does not mean that the loud-
speaker is omnidirectional. While the balloon shape
is spherical in the far-field, the sound from a useful
loudspeaker is likely more intense in the axial direc-
tion due to the use of horns, wave guides or baffles,
Fig. 20-3.
A loudspeaker has a near field where the
emerging wavefront is not spherical. It has a far
field where it is. There is a frequency-dependent
transition between the near field and the far field.
The loudspeaker’s axial transfer function is
distance-dependent in the near field. It is indepen-
dent of distance in the far-field, except for the
frequency-dependent effects of air absorption.
There are both low frequency and high frequency
criteria for the beginning of the far field. To be in
the far field the point of observation must be:
Figure 20-1. Example grid of measurement positions
around a loudspeaker.
Figure 20-2. Emitted rays from a sound source in a box.
A0
-
18.0 ms
 
0
5
0 1k
1k
-
 
 
18.0 ms
No of rays
No of rays 998
998
Max time
Max time
200.0 ms
200.0 ms
Time s tep
Time s tep 2.0 ms
2.0 ms
Max order
Max order 33
Min level
Min level
-30.0 dB
−30.0 dB
Los t rays
Los t rays
shown
shown
Ray color
Ray color
SPL
SPL
Specular fraction only
90
90
85
85
80
80
75
75
70
70
65
65
60
60
55
55
50
50
45
45
40
40
35
35
30
30
dB
dB
S PL
S PL
1k
1k

Computer-Aided System Design
445
1.
At least one wavelength from the source at the
lowest frequency of interest. This satisfies the
low frequency criteria.
2.
At least 10 times the longest dimension of the
source normal to the aiming axis. This satisfies
the high frequency criteria. This assumes that the
high frequency sound energy emanates from the
entire surface of the device. Often it does not,
and the 10 times distance criteria can be relaxed.
Using these criteria, a 1 meter (m) tall full-range
loudspeaker radiating high frequency energy from
its entire length would have a far-field that begins at
approximately 10 m for frequencies above 30 Hz
(10m is the acoustic wavelength of 30 Hz). One can
immediately see the challenge to collecting accurate
spherical far field data. In practical cases this
required distance can be relaxed. If uncertain, it can
be determined by measurement with a pull-away test
that compares the axial response of measurements
made at varying distances from the source. If the
axial frequency response magnitude changes with
increasing distance (other than losses due to air
absorption), the measurement position is in the near
field.
A practical distance for measuring spherical data
is approximately 8 m. Significant issues arise for
lesser or greater distances. 8 m allows measurements
above 43 Hz for a device up to 0.8 m (longest dimen-
sion of the device). If a shorter distance is used, the
data may be inaccurate for the higher octave bands.
If a greater distance is used, air absorption and
thermal gradients become serious issues, especially
if phase data is being measured. If a device is too
large to be measured at 8 m, it can sometimes be
broken down into smaller elements that are indepen-
dently measured and re-assembled in software. Line
arrays of discrete sources are an example, Fig. 20-4.
In practice, devices up to 2 m in length can often
be measured at 8 m. This is because many (most)
loudspeakers do not emit significant high frequency
energy from their entire frontal area. The 10x
distance criteria can be relaxed with an acceptable
loss of high frequency accuracy. For room modeling
purposes, data is only needed through the 8 kHz
octave band for predicting speech intelligibility,
Fig. 20-5.
20.3 The Measurement Process
The radiation properties of a loudspeaker must be
determined by measurements made on the surface of
the far field sphere previously described. The loud-
speaker is placed in a free field—an environment
that is free of acoustic reflections. A measurement
microphone is placed on-axis and in the far field of
the loudspeaker. The axial impulse response (time
domain) or transfer function (frequency domain) is
measured and recorded. The loudspeaker is then
rotated horizontally by the desired angular resolu-
tion, typically 5°, and the measurement repeated.
This continues until the microphone is 180° off-axis,
Fig. 20-6. The series of 37 measurements is referred
to as an “arc.” The loudspeaker is returned to the
axial position, rotated 5° about its aiming axis, and
Figure 20-3. Spherical radiation with non-uniform
intensity.
Front
Left
Up
Re on-axis
0
-10
-20
-30
-40
Figure 20-4. Line array of discrete sources (Nexo
GEOTM). (Courtesy CATT-A.)
Figure 20-5. Octave bands that can be meaningfully
simulated in room modeling programs.
 
 
Dn (-z)
Each line array element
has its own balloon
Rt (-y)
Bk (-x)
Lt (+y)
Fr (+x)
Up (+z)
LF
MF
HF
200
20
2k
20k
125
250
500
1k
2k
4k
8k
Frequency − Hz

446
Chapter 20
another arc is collected. The process continues until
a sufficient number of arcs have been measured to
fully characterize the spherical radiation from the
loudspeaker. The exact number of arcs depends on
the required number of quadrants, which in turn
depends on the acoustical symmetry of the loud-
speaker, Fig. 20-7.
The end result, using 5° resolution, is a set of
about 2600 impulse responses. The IRs can be trans-
formed to the frequency domain using the Fourier
Transform to yield the transfer function, or frequency
response magnitude and phase, for each measure-
ment position. This data set is then processed into a
set of loudspeaker balloon plots. There is one balloon
plot for each 1/n-octave band. One octave resolution
is generally used for room acoustics work. One-third
octave may be used for loudspeaker coverage
mapping and special investigations.
The balloon data is assumed by the prediction
program to represent the directional behavior of the
device at any distance, even though it was measured
at 8  m. But, it will be inaccurate for the loud-
speaker’s near field. In other words, while the data
balloon shape measured at 8 m may not be accurate
for shorter distances in the near field, it is accurate
in the far field. If the data were actually measured at
one meter, and this distance is in the near field due
to the loudspeaker’s size, there would be a
compounding error in the data as the sound propa-
gates outward. Far field data is necessary to allow
the balloon to be accurately extrapolated to remote
listener positions, which are typically more abun-
dant in large rooms than seats near the loudspeaker.
We have to trade off “up close” accuracy to get “far
away” accuracy. Since a main objective of the sound
system design process is to achieve a positive
direct-to-reverberant sound energy ratio, and since
this becomes increasingly difficult with increasing
distance, this trade-off is warranted.
The 1 m sensitivity of the loudspeaker (also
measured in the far field and corrected to 1 m using
the inverse-square law) is used by the prediction
software to scale the relative balloon data to an
absolute level. The room modeling program extrap-
olates the balloon until it intersects with an audience
plane, and properly scales it to the axial sensitivity.
The resultant LP is presented as a coverage map of
the audience area, Fig. 20-8. The loudspeaker data
file also includes the maximum rms voltage that can
be applied to the loudspeaker. I describe how this is
determined in Chapter 19 Power Ratings for Ampli-
fiers and Loudspeakers. The level difference
between this voltage and the voltage used to
measure the sensitivity is used to calculate the
maximum LP possible from the device.
Figure 20-6.  Arc of measurement positions around
loudspeaker.
Figure 20-7. Loudspeaker symmetry and the required
number of measurements.
Measurement
Positions
Axial Position
All arcs the same
37 measurements
Polar Symmetry - 
Full Symmetry - 
One-half Symmetry - 
No Symmetry - 
All quadrants the same
~900 measurements
Two hemispheres the same
~1800 measurements 
All arcs unique
~2600 measurements
Figure 20-8. Direct field coverage map of audience
area (CATT-A).

Computer-Aided System Design
447
A loudspeaker that can be accurately measured
and presented in this manner is commonly referred
to as a point source.
20.4 Loudspeaker Arrays
Small loudspeaker arrays, such as non-steered line
arrays of 1 m length or less, may be measured and
modeled as point sources. Longer arrays are broken
down into multiple point sources. This requires that
one of the sources be measured, and then replicated
in the room model. The relative arrival time of each
source can be computed for any listener position
within the model. This allows the complex (magni-
tude and phase) interaction to be calculated. Some
modeling programs offer dedicated modules to facil-
itate array construction.
Array predictions are only estimates for a
number of reasons. These include:
1.
Interference of adjacent boxes. In real life, if the
balloon data for a single box is measured, and a
second box (no signal) is placed next to it, we
have essentially created a new loudspeaker. The
physical presence of the second box changes the
radiation pattern of the first box, Fig. 20-9. The
effect might be subtle for a pair of highly direc-
tional horns. It will be extremely significant for
low directivity sources, which of course
includes virtually all loudspeakers as frequency
is decreased. In the array modeling program,
none of the boxes know about the presence of
the other boxes.
2.
Consistency of array element behavior. A manu-
facturer typically supplies a single loudspeaker
to a measurement lab for production of the data
file used in room modeling programs. This loud-
speaker can be measured to any practical resolu-
tion, and the trend has been to use increasingly
higher angular and frequency resolution. The
resolution may be as low as 10° ⁄ 1⁄1-octave, or as
high as 1° ⁄ 1⁄24-octave. It is tempting to think that
“more is better” and it is an easy sell to market
the use of higher resolution as being more accu-
rate. Unfortunately an inverse relationship exists
here. The higher the angular and frequency reso-
lution, the less “general” the data will be. No
two loudspeakers are identical, so there is a
danger of resolving a sample to the nth-degree
and producing a data file that is only accurate
for the sample measured, Fig. 20-10. There
exists at least two possible solutions. The first is
for the manufacturer to tighten their quality
control standards to produce loudspeakers that
have less variance from unit-to-unit. If you have
ever priced a pair of matched microphones for
stereo recording, you will understand the
impracticality of this solution. If a manufacture
must start rejecting drivers to a tight tolerance,
the price goes way up. The market responds by
users buying cheaper brands, so the manufac-
turer that is trying to “do it right” is soon out of
business. The second choice is to reduce the
angular and frequency resolution to something
that is less sensitive to device variance. Practical
resolutions are 10°⁄ 1⁄1-octave and 5°⁄ 1⁄3-octave.
There are some cases where 2.5° data may be
argued for a device with a very narrow beam
width, such as a line array. But given the other
variables that can’t be controlled, this is typi-
cally unwarranted.
20.4.1 The Dynamic Link Library—DLL
Some array types require considerable input from
the user. For example, a line array may consist of
eight elements. Each must have the desired relative
Figure 20-9. Errors caused by box interactions.

448
Chapter 20
position and aiming angle. Some of the elements
may require delay, or custom filters. The data entry
can be greatly simplified by use of a DLL. The DLL
concept was first introduced in CATT-Acoustic v7.1
in 1998. Other softwares have since implemented
DLLs in various forms. A DLL can allow sophisti-
cated and complicated array configurations to be
created with minimal data entry. The DLL is typi-
cally custom-coded for a manufacturer by the soft-
ware developer. Fig. 20-11 shows the DLL setup for
a popular line array.
20.4.2 Magnitude vs. Phase Data
A loudspeaker data balloon may consist of magni-
tude-only or magnitude plus phase data. Phase data
can improve the prediction results for some array
types, namely those that rely on complex
Figure 20-10. Magnitude and phase response varia-
tions of 10 “same model” loudspeakers.
Figure 20-11. A DLL can allow efficient configuration
of an array, and then calculate the acoustical behavior.
(CATT-A).

Computer-Aided System Design
449
interactions between the individual elements to form
the radiation pattern, and are too large to measure as
a single unit. But, phase data is difficult to measure
accurately at distances that are in the far field of the
source. A temperature change of a few degrees over
a multi-hour measurement session can cause signifi-
cant errors. If a microphone array is used to speed
up the measurement time, the microphones interfere
with each other in the same way that the loud-
speakers in an array interfere with each other.
So, while it seems plausible to measure all loud-
speakers at 1° angular resolution, and to include
both magnitude and phase data, in practice the
predicted response of an array is still only an esti-
mate. If the individuals writing the software and the
Standards are not involved with loudspeaker testing,
or strongly influenced by those who are, there is a
danger of a disconnect. Balance is brought to the
discussion by considering the reason for measuring
the loudspeaker in the first place—drawing board
sound system design. No matter how accurate, the
loudspeaker data will be used in a room modeling
program that can only estimate the acoustical
behavior of a space.
20.5 Direct Field Modeling
Direct field LP and coverage predictions can be done
without consideration of the room’s acoustics. There
is no need to build a complete, enclosed room model
if all you need to know are the required mounting
height and aiming angle for the loudspeaker.
Modeling programs are extremely useful and accu-
rate at showing how the spherical data balloon inter-
sects the flat audience planes. This assures that an
appropriate loudspeaker(s) has been positioned as to
allow even direct field LP over the audience area.
The direct field coverage map considers the LP
radiated from each point around the loudspeaker and
the distance to the audience area. The resultant LP is
frequency-dependent, so independent maps are
produced at the desired 1/n-octave resolution. The
1/n-octave bands can be summed and weighted to
produce broadband LP maps.
Coverage is not intuitive, and failure to model
can lead to gross errors. Direct field coverage
mapping should be the first step of any sound
system design process, whether or not room acous-
tics modeling is performed, Fig. 20-12.
6+
 
20.6 Room Model Detail
Once the designer is satisfied that the direct field
coverage is acceptable, the reflected energy from the
room must be considered. A virtual wire-frame model
of the room geometry is constructed for this purpose.
The amount of detail required in the room model
is the subject of ongoing debate. It would seem intu-
itive that an accurate visual model is an accurate
acoustical model. This would also allow the conve-
nience of using an existing CAD model as provided
by an architect. Unfortunately this is generally not
the case. A good visual model is not necessarily a
good acoustic model.
The interaction of sound with room objects is
quite complex, being a combination of reflection,
resonance and diffraction. Ray tracing or
image-source methods can only approximate the
behavior of sound, so they can never be described as
“accurate” regardless of the detail used in the model.
Too much detail can dramatically increase the calcu-
lation time, without increasing the accuracy of the
predictions. The room model should be viewed as an
acoustic “sketchpad,” and is the acoustic equivalent
to the architect’s scale model made from foam board
and paper, Fig. 20-13. It is a highly programmable
reverberation processor that can be tailored to the
room’s geometry while considering the directivity
of the source.
The accuracy of acoustic predictions tends to
follow the nature of the sound from the source. The
direct field emitted by the loudspeaker can be
measured with very high accuracy, and its behavior
in the far free field can be accurately estimated
using the inverse-square law. This means that direct
field measures, such as LP and coverage can be
predicted with high accuracy. Once the sound
reflects, the term “accuracy” no longer applies. We
are now dealing with approximations, as each ray
that encounters a room boundary produces a new
acoustic source that is as complex as the original
source. The behavior of the sound becomes
Figure 20-12. Direct field coverage map for 2 kHz
octave band—audience area only.

450
Chapter 20
increasingly complex with each reflection order,
eventually becoming diffuse and defying determin-
istic prediction completely. Fortunately, the needs of
the sound system designer tend to track this accu-
racy progression. I can have high confidence in the
direct field predictions and possibly a few reflection
orders if the surfaces are large and smooth. But, the
errors compound as the sound propagates and the
higher order reflections and the reverberant field
behaviors are only estimates.
Modeling programs usually provide specialized
modules for creating the 3D surface model. Alter-
nately the model may be created in a third party
CAD program and imported. Each room boundary
(or plane) is given an absorption coefficient that
determines the how much the LP of the reflection is
reduced when the ray encounters a room surface.
The plane can also be given a scattering coefficient,
which randomizes some of the reflected energy.
Scattering coefficients are invaluable for estimating
the behavior of complex room surfaces. Both
absorption and scattering coefficients are estimates,
and their determination is one of the major chal-
lenges in the modeling process, Fig. 20-14.
20.6.1 Predicting Room Reflections
Room modeling programs primarily use two
methods to predict room reflections. An
image-source method is deterministic, and can be
visualized by considering the room surfaces to be
mirrors. If you were seated at the listener position,
the image of the loudspeaker would be visible in
each boundary that produces a specular reflection
for your seat. Similarly, in the real room if the
source were replaced with a laser-like directivity,
and the images replaced with mirrors, the laser dot
would end up on you. So, by using optical principles
and geometry, the surfaces producing specular
reflections can be identified, Fig. 20-15.
The computational intensity of this method
increases as the reflection order is increased, while
the accuracy decreases with each successive reflec-
tion. This suggests that a different approach is
needed to simulate the late decay of the room. A ray
tracing algorithm and its variants (e.g., cone tracing)
emits thousands of virtual rays from the source,
“traces” them to a user-specified reflection order,
and then counts the ones that arrive at the listener
position. The listener in the model is actually a
“counting balloon”—a target sphere of fixed or vari-
able radius. The exact method of predicting the
reflected field differs between modeling programs,
as do the results. The method used may be unique to
a modeling program, and is influenced by the
knowledge, skills, intuition and prejudices of the
programmer, Fig. 20-16.
Figure 20-13. Simple 3D surface model of a fan-shaped
room, showing proposed loudspeaker positions.
Figure 20-14. Absorption and scattering coefficients at
1⁄1-octave resolution.
Figure 20-15. First order image sources for a single
source at a single listener position. The level and arrival
time for each source are shown in the echogram
(CATT-A).

Computer-Aided System Design
451
20.6.2 The Objective of Room Modeling
For any given source/listener combination in an
enclosed or semi-enclosed space, there are a myriad
of variables that determine the room impulse
response (RIR). The RIR, in turn, is the best
summary that we have regarding what that seat
sounds like. In a physical room, the collection of the
RIR is the single most important task for the investi-
gator, for within it are found the physical reasons for
the sound quality at that listener position.
The objective of the design process is to synthe-
size an approximation of the RIR. There are
numerous similarities and parallels between the
synthesized RIR, which in modeling may be referred
to as an echogram, and the actual measured RIR for
the same seat in the physical room. For one to be a
good modeler, one must first be a good measurer. It
is through an appreciation for the sensitivities of
measured data that one can grasp the difficulty of
predicting the RIR. Only then can we avoid wasting
time on the fine details and subtleties that many
assume are accounted for by the mathematics used
by the modeling software.
The measured RIR provides a reference for
creating a virtual environment whose behavior
emulates the actual room to the degree necessary to
select and place loudspeakers. Measuring and
modeling go hand-in-hand, and what is learned
about one can aid one’s understanding of the other.
The following sections apply to both measured
and modeled acoustical data.
20.7 Room Acoustics—An Overview
The speed of sound perturbations that propagate
through air is very slow compared to the speed of
light. This results in a human-detectable time offset
between the direct sound from the loudspeaker
arriving at the listener and the reflections produced
from room surfaces within the space. The art and
science of room acoustics deals with these
reflections.
The room is passive and produces no sound of its
own. When sound is produced in the room from a
source, reflections are produced by the various room
surfaces. Rooms are initially analyzed in the time
domain since the arrival of reflections is a function
of time. For any listener position, there exists a ratio
between the direct sound and the reflected “room
sound.” This ratio influences how well the informa-
tion from the sound system is conveyed to the audi-
ence. Let’s look at how the room response is
evaluated.
While the “frequency response” is a much more
popular way of describing the sound from a system,
the frequency response is determined by the time
response—the complex interaction of the direct field
and multiple reflections that are unique for each
listener position. Most signal processing tools (i.e.
equalizers) are “time blind” and therefore fail to
address the real causes of poor sound quality. Since
an equalizer affects all of the sound fields heard at a
listener position, it cannot alter the ratio between
them, which is the root of most sound clarity and
speech intelligibility problems.
20.7.1 The Room Impulse Response—RIR
A hand clap in the space will produce a series of
reflections at a listener position, Fig. 20-17. Each
reflection is a modified facsimile of the original
event. This series can be broken down into several
distinct sound fields. The hand clap results in a
crude RIR. In formal investigations the hand clap is
replaced by methods that are calibrated and consis-
tent. It is important to understand that regardless of
the method used to collect it, the RIR is the most
fundamental acoustic test. It is the primary means of
analyzing the acoustic behavior of a room, and its
synthesis is the ultimate goal of the design process.
The room will have the same affect on any sound
coming from the loudspeaker, that it has on the
impulse that was sent out. A 3D surface scale model
of the room provides a virtual environment for
sculpting the synthesized RIR.
The sound fields that the impulse produces
include
1.
The Direct Sound Field.
2.
The Early-Reflected Sound Field.
3.
The Late-Reflected Sound Field.
4.
The Reverberant Sound Field.
For pure acoustics work, the impulse may be a
balloon pop or starter’s pistol. For sound system
Figure 20-16. Full echogram for a single listener posi-
tion (2 kHz octave band) (CATT-A).

452
Chapter 20
work the stimulus may be pseudo-random pink
noise or a sine wave sweep that is played through a
loudspeaker, recorded and mathematically processed
to yield the impulse response by an analyzer. This
technique allows the impulse response to be
collected without emitting an actual impulse with
it's attendant drawbacks. These include the require-
ment for a very quiet room as well as possible
damage to the loudspeaker if the level is too high.
In the same way that a sound source and receiver
position are placed in a physical room to measure
the RIR, a virtual source and receiver are placed in
the computer model to predict the RIR. The room
model serves as a virtual measurement environment.
The RIR is shown in Fig. 20-18. It is a time
domain plot where sound pressure (in this example)
is the dependent variable and time is the indepen-
dent variable. The vertical axis is linear.
20.7.2 Post-Processing the RIR
To aid in evaluating the RIR, the absolute values of
the amplitudes are displayed on a vertical axis of
relative dB. This is the log-squared RIR. All
log-squared RIRs have some similar attributes,
allowing the sound arrivals to be classified. I will
represent it with a general plot, Fig. 20-19. Please
pause and carefully consider the plot shown. It is the
time domain representation of the relative levels of
sound arrivals produced by an impulsive source
placed at a unique position in the room, and
collected from a different unique position.
Since an infinite number of such positions exist,
the investigator must select each based on what they
are investigating. The answer to “Why?” deter-
mines “Where.” Strategically meaningful source and
receiver positions are selected for both making room
measurements and for evaluating the system perfor-
mance in a computer model. Both are heavily influ-
enced by answers to three questions:
1.
“Where can a loudspeaker(s) be placed?”
2.
“Which model(s) will I use?”
3.
“Where will the listener(s) be located?
Figure 20-17. Hand clap and resultant reflections.
Figure 20-18. The Room Impulse Response—RIR.
Figure 20-19. General representation of the
log-squared RIR.
0 ms
(actual)
0 ms
(rel)
50 ms
(rel)
Direct
Relative Level (dB)
Time (s)
Early
Late
Reverberation
DIFFUSE
ENERGY
Reflections
Reflections

Computer-Aided System Design
453
The RIR is profoundly affected by these deci-
sions, which is the whole point of using computer
modeling to estimate the performance of the system
at the drawing board. A “measure” or “metric” is a
score used to quantify some aspect of the RIR. One
popular basic measure is the reverberation time in
seconds.
20.8 Absorption
A sound absorber terminates the sound wave at a
room surface by converting part of the sound energy
into heat. A rating that describes the absorptiveness
of a material is the absorption coefficient or ABS.
The ABS is a number between zero and one, where
zero is a perfect reflector and one is equivalent to an
open window from which no sound returns. The
ABS is frequency-dependent and is usually speci-
fied at one-octave resolution, Fig. 20-14.
In both the actual room and the room model, the
ABS is multiplied by the surface area of the
boundary to produce the sabins of absorption
contributed by that boundary to the space, named for
Wallace Clement Sabine, considered by many to be
the father of architectural acoustics. Each surface
can have only one ABS, and large surfaces can be
subdivided if they have multiple coverings. One
English sabin is one square foot of open window.
One metric sabin is one square meter of open
window. The more sabins, the less reflected sound.
Sabins can be added or removed to modify the
sound of the room.
If all room surfaces have an ABS = 1 for all
octave bands, the room would be anechoic, or
without echoes. An anechoic chamber utilizes heavy
ABS to simulate this condition. In practice complete
absorption is not possible and one criteria for an
anechoic environment is that all reflections must be
−20dB relative to the direct sound at the measure-
ment microphone.
Absorptive materials have an acoustic impedance
similar to air. Effective absorbers include soft, fuzzy
materials such as fiberglass and mineral wool as
well as some types of foams. Low frequency absorp-
tion may be accomplished by diaphragmatic action,
a sometimes unintentional result of gypsum board or
thin panel wall construction. Adding surface relief
increases the surface area and yields more sabins for
a given area. The ideal minimum thickness of an
absorber is ¼-wavelength at the lowest frequency of
interest. This makes low frequency absorption diffi-
cult to accomplish for practical reasons due to the
required material thickness.
ABS coefficients are most often measured in a
reverberation chamber. This accounts for the energy
loss (or more correctly, the conversion to heat) of
sound striking the material at random angles. The
material’s effect on a specular reflection may be quite
different. Remember, these are estimates. Be conser-
vative if you have to guess at an ABS coefficient.
20.8.1 Modeling with Absorption Coefficients
The absorption coefficient also plays a central role
in the computer model. Here, the coefficient is a
percentage. Each surface in the room model is given
an absorption coefficient, usually taken from tables
of values created from actual measurements of
various surface coverings, often with obscure
origins where the details of how they were measured
are rarely given. Practical values range from 1% to
99%. A practical resolution is 1⁄1-octave. While there
is a push toward higher (i.e. 1⁄3-octave) ABS data,
“more” is not necessarily “better” for several
reasons. These include:
1.
No matter how complete your ABS materials
library, there is always some educated guess-
work involved in assigning a coefficient to a
room surface. 1⁄3-octave resolution complicates
the guessing process, requiring the designer to
guess at 3 times as many values.
2.
Sharp spikes in the absorptive characteristics of
a material tend to support the case for higher
frequency resolution, but such spikes (or dips)
tend to be very sensitive to the variables that
cause them. Even high resolution ABS data may
not properly quantify the behavior of such a
surface.
3.
The predicted performance of both loudspeakers
and rooms must be done at a practical resolu-
tion. It is a time-intensive task to characterize
the direct field sound coverage and various
performance measures at 1⁄1-octave resolution,
let alone 1⁄3-octave.
The “appropriate resolution” discussion also
applies to loudspeakers. Well-behaved loud-
speakers typically do not have sharp directivity
changes as function of frequency. One can usually
visually interpolate the loudspeaker’s performance
between the 1⁄1-octave bands. Ironically, the poorest
loudspeaker designs can require the highest
measurement resolution to characterize, as higher
angular resolution may be required to resolve their
erratic response. Is is better to increase the resolu-
tion to quantify such a device, or select a device that
can be characterized by a lower angular resolution?
The debate goes on.

454
Chapter 20
20.8.2 Sound Behavior
When the acoustic wavelengths are short relative to
the surface sizes that take part in the reflection,
sound is modeled as rays of light that behave
geometrically. The angle of incidence will equal the
angle of reflection, as with a mirror. As frequency
decreases, the light model becomes increasingly
inaccurate and the sound must be modeled as a
wave, which is much more difficult to handle
computationally. The transition of a room from “ray
behavior” to “wave behavior” is a gradient with no
clear single transition frequency. The “ray assump-
tion” is why we can use straight lines with arrows to
indicate the direction of sound travel. One must
always be mindful of the limitations of their
assumptions. It’s a big jump to consider the sound
as a wave rather than as a ray, which is why most
acoustic prediction methods don’t work well at low
frequencies, Fig. 20-20.
The Schroeder Frequency estimates the transition
region from “wave” behavior to “ray” behavior. In
practical cases, the ray model for sound has validity
to possibly 100 Hz, and even then only for a very
large space. This means that the octave band centered
at 125 Hz is the lowest band that can be considered in
the room model. At the other end of the spectrum, the
8 kHz octave band extends to beyond 10 kHz. The
very short wavelengths beyond the 8 kHz octave
band may not predict well. They also have little if
any influence on speech intelligibility.
Room modeling programs assume geometric
behavior of sound, treating it as a ray or particle that
is emitted from a source. For this reason, sound
system performance predictions, including room
acoustics predictions are best limited to the 125 Hz
through 8 kHz octave bands, see Fig. 20-5.
The following discussion assumes that the room
size is very large, and the individual surfaces large
and smooth, relative to the wavelength of the sound,
and therefore the sound behaves geometrically. This
is usually the case for most of the audible spectrum
for rooms sufficiently large to require a sound rein-
forcement system. The computer modeling
programs used by sound system designers assume
geometric sound behavior, and should therefore
restrict acoustic calculations to the 125 Hz-octave
band and above. They should also warn you
regarding the useful low frequency limit, Fig. 20-21.
20.8.3 The Direct Sound Field
The direct field is the sound that travels straight
from the source to the listener. It arrives first since it
has the shortest distance to travel. The direct field is
the “engineered” sound field. Loudspeaker and
amplifier selection are often based on it alone, as
though the system were to be used outdoors with no
reflections (a free-field). The spectrum of the direct
field may be equalized by modifying the drive
voltage to the loudspeaker with electronic filters—a
process referred to as equalization. The direct field
is independent of the room, and direct field
Figure 20-20. Critical frequency chart, showing a
simplified equation. Room modeling works best in the
absorption region, and its accuracy diminishes with
decreasing frequency.
Fc = 3c
RSD
Normal Modes
Pressure
Zone
Diffusion
Absorption
(Specular Reflections)
Frequency
Behavior
Fc
4Fc
where c is the speed of sound
and RSD is the Room’s Smallest Dimension
Figure 20-21. Reverberation time estimation. Note the
indication of the Schroeder Frequency for this gymna-
sium-sized room, along with a recommended low
frequency limit for acoustical predictions.

Computer-Aided System Design
455
equalization can be performed off-site when certain
conditions are met. The measurement of the direct
field is “Step 1” of the system equalization process
in real rooms, and Step 1 of the design process in the
virtual room.
In the computer model, the direct field is used to
model the LP and coverage of the source over the
selected room planes. The prediction is based on
measured loudspeaker data as previously described.
20.8.4 The Early-Reflected Sound Field
The early-reflected field includes the reflections that
arrive close enough in time to be integrated, or fused
with the direct field by the ear-brain system. This
integration time is frequency-dependent, ranging
from a few ms at high frequencies to tens of ms at
low frequencies. 35 to 50 ms is often used as a “one
number” integration time.
Early reflections increase the perceived level of
the sound, and may be the primary means of ampli-
fication in a lecture or recital hall. They are often
called “supporting” reflections. Acousticians often
use “clouds” and “shells” to provide supporting
reflections to listeners or musicians. The chart in
Fig. 20-22 is useful for evaluating how a reflection
will be perceived based on arrival time and level.
Early-reflections also produce tonal coloration as
the reflected sound acoustically superposes with the
direct sound at a listener. This can be either good or
bad depending on the application. It is good sound
system design practice to maintain some distance
between loudspeakers and room surfaces to mini-
mize coloration of the loudspeaker’s sound. Surface
treatment can be substituted for distance, as can
increasing the source’s directivity to reduce the
energy striking the surface. The result is an initial
time gap ITG between the direct sound and first
reflection that can be observed on the log-squared
impulse response (measured) or echogram
(predicted), Fig. 20-23. The presence of an ITG of
ten or more ms can dramatically improve the fidelity
of a loudspeaker, and is considered essential in crit-
ical listening spaces such as recording studio control
rooms. It is equally important in an auditorium
system, where the objective is to achieve a similar
response from seat-to-seat. Strong very early reflec-
tions can make this impossible (the Image Shift
region of Fig. 20-22).
In the room model, the early-reflected field is
determined by an image-source prediction algo-
rithm. Rather than rely on the probability of sound
striking a room surface, as does ray tracing, the
image-source method uses a deterministic approach.
This method has computational issues for high order
reflections, so most modeling programs transition
from image-source methods to ray or cone tracing in
order to synthesize the room echogram so that the
full decay can be estimated, see Fig. 20-15.
20.8.5 Late Reflections or Echoes
Late-reflections arrive beyond the ear’s integration
time. They are perceived as a blurring of the sound
and in extreme cases as echoes. Hall designers use
room geometry and acoustic treatment to control
late reflections. Sound system designers utilize
loudspeaker pattern control and placement to the
same end.
In most cases, strong, late reflections that are
perceived as echoes are low in order. Common
offenders include rear walls, balcony faces,
windows, etc. The predicted echogram can often
identify the surfaces that are likely to be offending
for a given listener position. As in physical rooms,
the most likely problem spots—seats that receive
echoes from the rear of the room—are the first rows
of the audience and the stage.
Figure 20-22. Chart for evaluating a reflection.
0
−10
+10
−20
20
6.8
40
13.6
60
20.4
80
27.2
−30
ms
M
Relative dB
Image Shift
Echoes
Tonal
Changes
Useful Reflections
Reverb-
eration
Masked Reflections
Evaluating a Reflection
Figure 20-23. The Initial Time Gap—ITG.
0 ms
(actual)
0 ms
(rel)
50 ms
(rel)
Direct
Relative Level–dB
Time–s
Early
Late
Reverberation
DIFFUSE
ENERGY
  
  
ITG
Reflections
Reflections
In
i
t
i
a
l
   
Ti
m
e
   
Ga
p

456
Chapter 20
20.8.6 Reverberation
The reverberation time of a room is a measure of
“sound persistence.” By definition, the RT is the
time required for the sound from an interrupted
source to decay by 60 dB. 60 dB was chosen for
largely practical reasons, as it roughly represents the
amount of decay that can be heard in a quiet space.
The RT was more formally termed the RT60. This
has been shortened in later standards to T60 to be
consistent with other time domain measures. The
most common measure implemented by acoustical
measurement platforms is the T 30, which is the time
required for 60 dB of decay, extrapolated from the
time required for 30 dB of decay. It is described in
ISO 3382—“Measurement of the Reverberation
Time of Rooms with Reference to Other Acoustical
Parameters”. The RT is the easiest acoustic param-
eter to measure, and casual investigations may only
require counting or a stop watch.
Reverberation time is frequency-dependent, with
one-octave being a practical resolution, see
Fig. 20-21.
Reverberant energy results from the sound
persisting in a space long enough to produce so
many reflections that the sound becomes diffuse and
random. While there is energy decay, there is no net
direction of energy flow. Contrast this with a reflec-
tion which had a definitive direction of travel and
that can be attributed to a specific room surface. A
diffuse sound field is noise-like with regard to
perception, except that it is repeatable. The two
characteristics of reverberation that are of interest
are the reverberation time and the reverberation
level. I have previously defined reverberation time.
The reverberant level is the level that the rever-
berant sound field builds to as the room is continu-
ously excited by a source. A room may have a long
reverberation time, but if the reverberant level is
made low by careful loudspeaker selection and
placement, communication may not be impaired by
the reverberant field.
The reverberation time can be estimated mathe-
matically with the Sabine equation and its variants,
for rooms that meet certain criteria. These include
low average absorption, uniform absorption distri-
bution and a mixing geometric shape1. Few rooms
meet these criteria, so the reverberation equations
only provide estimates, that in some cases can have
large errors. Due to its random and mixing nature,
the reverberant field tends to be consistent
throughout spaces where a significant reverberant
field develops.
It is intuitive to think that if we just let a ray
tracing or cone tracing algorithm run long enough,
we will eventually get a diffuse reverberant field in
the room model. This is not true. A major obstacle
to predicting the reverberant “tail” in the room
model is how to handle ray growth. In the real
world, rays beget rays. Every encounter of a ray
with a room surface essentially creates a new sound
source in the room, which produces a hemisphere of
rays into the room, each of which creates a new
sound source when it encounters a boundary. Rever-
beration results when the reflections at a listener
position become so dense that there is no specific
direction of sound flow. Room modeling programs
must estimate this ray growth, and they all do it
differently. The algorithms tend to be soft-
ware-specific, and sometimes more than one choice
is given, depending on how the designer intends to
use the data. For example, a simple, fast algorithm
may be used for general RT estimates, but a more
complex one is provided for auralization (listening).
The more sophisticated algorithm may require a
much longer run time.
So, the synthesis of the RIR transitions from
deterministic number crunching for the direct field
and specular reflections, to sophisticated algorithms
for reverberant field. It was once popular for the
reverberant field to be synthesized based on statis-
tical reverberation equations (i.e. Sabine) and then
spliced onto the end of the RIR. A major problem
was achieving a natural transition between the spec-
ular arrivals and the dense, reverberant tail. As
computers have become more powerful, so have the
algorithms, and this time saving method is
becoming unnecessary.
Once the computer model performs the direct
field calculations, deterministic reflected field calcu-
lations, and diffuse field calculations, we have the
RIR for the seat under investigation. The T 30 can be
determined from this data. Of all of the acoustic
measures, the T 30 is the least “seat-specific,”
meaning that it tends to vary less than the other
measures as one moves around the space. It can
serve as a general measure of sound persistence for
a space, and it is meaningful to speak of working in
a “3-second room.” Fig. 20-21 shows a special ray
tracing sub-program for quickly estimating a
“global” T 30. This is useful for achieving a general
match between a measured T 30 and the T 30 of the
model.
Reverberation is often used as a “catch-all” term
for reflected sound, but it is important for sound
system designers to consider the type of reflected
sound as outlined here. Most rooms are semi-rever-
berant and all of the sound field types, plus noise,
may exist at a given listener position. The investi-
gator must determine which sound field is relevant
to the problem being investigated.

Computer-Aided System Design
457
20.8.7 Room Measures
The sound arriving at a listener position can be
given ratings based on the previous sound field
descriptions. In actual rooms, this task is handled by
an acoustic analyzer that collects the RIR and
processes the data, Fig. 20-24.
Useful measures for sound system design include
T 30, Early-Decay Time - EDT, Clarity—C and one
or more speech intelligibility scores.
Room acoustics is a field of study in and of itself.
So is the measurement and characterization of the
intelligibility of a sound system. Both are presented
here as an introduction to familiarize you with their
existence, and their importance in the sound system
design process. Sound system practitioners must
recognize the influence of room acoustics on the
sound from their systems. It is possible, and even
commonplace, to achieve adequate LP and direct
field coverage, only to have it swamped out by a
high reverberant field level, or degraded by an echo.
One objective of computer room modeling is to
identify these problems at the drawing board.
20.9 Realistic Room Models
Computer room modeling programs create a virtual
acoustic environment to aid in loudspeaker selection
and placement. It is important to build a bridge
between the physical environment and the modeled
one using measured data. Skipping this step can lead
to wildly inaccurate predictions that over or under
Figure 20-24. Acoustics module of RoomCaptureTM measurement program.

458
Chapter 20
estimate the clarity of the system. Following is the
method that I use to qualify the room model based
on a few measurements made in the physical space,
assuming that the room exists.
Step 1—Field measurements
1.
A well-controlled loudspeaker is placed on
stage, well away from room boundaries (other
than the floor). A properly measured data file
for your room modeling program for this loud-
speaker is mandatory, and should be provided by
the manufacturer. It is not so important what
loudspeaker you use as that what you use is
well-defined. The loudspeaker in Fig. 20-25 is
internally processed and powered, has an
extremely smooth axial transfer function, and a
well-defined directivity characteristic similar to
a human talker. Its acoustic output is similar to
that of a human talker, so a quiet room is
preferred.
General acoustics investigations are often
made using a low-directivity source, Fig.
20-26. This produces maximal room excita-
tion—exactly the opposite of what we want
from a sound reinforcement loudspeaker.
2.
The furthest measurement position is selected,
on-axis with the loudspeaker and near the back
row of the auditorium but away from room
boundaries (other than the floor). The RIR is
collected at this position.
3.
The distance is halved, and the measurement
repeated.
4.
The distance is halved again, and the measure-
ment repeated.
I actually prefer to mark the positions first, and
then begin the measurement session at the shortest
distance. This prevents the measurement system
from being accidentally over-driven from starting at
the remote distance and moving closer to the source.
This gives me three axial positions for a
well-defined source for which I can easily determine
the direct field level, RT, clarity, speech intelligi-
bility, etc. They are related by the inverse square
law, as the direct field level should change by
approximately 6  dB between these proportion-
ally-spaced locations, Fig. 20-27. This allows the
measures for in-between positions to be roughly
estimated if they are needed. The RIR can be
analyzed in a measurement program and listened to
using convolution.
These measured positions are the gold standard
for the performance of the room model. In a perfect
world, they would be replicated exactly in the
modeling environment. In the real world we will
have to be content to get “close enough to dance.”
Step 2—Wire-Frame Generation
1.
A wire-frame model of the room’s geometry is
produced in the modeling program or other
CAD environment. Each room boundary may be
assigned a color and a descriptor, i.e. wall,
ceiling, floor, audience plane. These will be
useful later for assigning absorption and scat-
tering coefficients. The exact procedure will
vary depending on the room modeling platform.
Figure 20-25. NTI TalkboxTM.
Figure 20-26. Low directivity source for room measure-
ments. (Courtesy OutlineTM.)

Computer-Aided System Design
459
2.
In the room modeling program, I initially set the
ABS for all room surfaces to 0.1, or 10%. For
most spaces this underestimates the ABS, there-
fore overstating the RT. The RT is then calcu-
lated in the model and compared to the
measured RT from the room. 1⁄1-octave is an
appropriate resolution. Take note whether the
predicted RT is higher or lower than the
measured RT, as this indicates whether the
average ABS must increase or decrease.
3.
Refine the model by estimating the ABS coeffi-
cients for the walls, ceiling, floor etc. Since the
largest room surfaces have the most influence,
start with them. These values may be taken from
tables of measured data, guessed at, or both.
Continue this process until the 1⁄1-octave
predicted values are similar to the measured
values.
4.
Visually identify the room surfaces with signifi-
cant relief and assign scattering coefficients
based on depth of the relief to the wavelength
ratio for the octave band of interest, Fig. 20-28.
If the relief equals half the wavelength, assign a
scattering coefficient of 0.5. Increase it by 10%
for each successively higher octave and halve it
by 10% for each successively lower octave. This
should result in a graph of scattering vs.
frequency that looks like Fig. 20-14. The
purpose of this step is to “de-specularize” room
surfaces that will not likely produce a specular
reflection due to their complex physical shape.
Audiences, pews and organ pipes are examples
of room surfaces that will have a high scattering
coefficient.
The use of scattering coefficients can dramati-
cally simplify the modeling process. They
allow a surface to be modeled as a flat plane,
but then given a complex, frequency-depen-
dent acoustical reflection characteristic. This
allows the room surfaces that produce high
level specular reflections to be more easily
identified. There is no level of detail that you
can use in the model to accurately quantify the
acoustic behavior of a scattering surface using
geometric acoustics. Attempting to do so will
bog down the design process with no increase
in the accuracy of the echograms.
Figure 20-27. Log-spaced measurement positions.
Figure 20-28. 3D surface model showing audience
plane absorption and scattering coefficients at
1⁄1-octave resolution.

460
Chapter 20
Step 3—Correlation
We now have sufficient information to evaluate the
correlation between the measured data and the room
model.
1.
Place a virtual source in the room model at the
same position as the source in the physical
room. Specify the data file for your test loud-
speaker.
2.
Place listener positions in the room model at the
same coordinates as those used for the measured
data.
3.
Generate an echogram for each listener position.
4.
Compare the Clarity-C50 for the measured and
modeled data. Tweak the room model until the
Clarity scores are reasonably close (3 dB toler-
ance) for measured vs. modeled, for each
1⁄1-octave band. This can take some time, and
illustrates why 1⁄1-octave resolution is preferred
to a higher resolution for modeling.
Step 4—Design the System
You now have a qualified room model for trying
your design ideas. Substitute different loudspeaker
makes and models at the positions you choose. Place
additional listener seats as needed. Use coverage
maps (overall) and echograms (seat-specific) to
assure that the Clarity is acceptable at all listeners.
Listen to your measured data using convolution, and
compare it to auralizations of your predicted data.
They should be similar, assuming that you use the
same microphone pattern for each.
20.10 Universal Room Modeling Tips
Having been involved with the use of room modeling
programs from their inception, I have learned a few
things over the years that make the process more
efficient and general. You do not want to turn off
your brain and blindly accept what a modeling
program tells you. It is providing calculated results
based on your assumptions regarding the room and
the assumptions of the algorithms used by the
program. It if doesn’t seem right, investigate further.
Try to bring it back to a simplified, known condition
that you can verify or correlate with measured data.
Here are a few tips to aid in the process.
1.
Use 
platform-independent 
programs 
(i.e.
SketchupTM or AutoCADTM) for producing the
3D surface model. This can allow the same
model to be imported into multiple modeling
programs. It also shortens the learning curve for
changing modeling platforms.
2.
Particle/wave duality applies. Wave methods
(i.e. Finite Element Analysis—FEA) work best
for low frequencies. Particle (ray) methods work
best for high frequencies. There is a continuous,
frequency-dependent transition between the two
behaviors. Most room modeling programs use
particle/ray methods for the entire spectrum.
This makes accurate acoustical predictions
based on geometric acoustics below the 250 Hz
octave band problematic.
3.
Ray tracing and image-source methods cannot
fully characterize the acoustic behavior of a
room surface. They provide estimates. Adding
more detail to the model does not alleviate this,
even though it may make the room model more
visually appealing.
4.
A good visual model is not necessarily a good
prediction model. Too much detail can increase
the calculation time without necessarily
increasing the accuracy of the results.
5.
The required model detail is frequency-depen-
dent. Surfaces that are acoustically random at
high frequencies may be acoustically flat at low
frequencies. An example would be a large floor
area covered with folding chairs. Model such a
surface as a flat plane and use frequency-depen-
dent scattering coefficients to randomize the
high frequency behavior.
6.
It is conceptually better to think of the room
model as a highly programmable reverb unit
than as an accurate acoustical model. It is an
acoustical scratch pad that allows variables to be
wiggled and isolated. All acoustical data (loud-
speakers/room surfaces) are approximations.
Accuracy and generality are mutually exclu-
sive. The room modeling process requires
educated guessing!
7.
Establish a hierarchy for the design process.
Here is a logical progression, along with what
must be modeled to determine each.
Step 1—Direct Field –Audience areas only.
Step 2—Direct Field + Statistical Acous-
tics–Audience areas and room with correct
volume and total absorption.
Step 3—Specular Reflections—Actual room
geometry. Remember that the required detail is
dependent on distance from source. The rays or
particles spread with distance, see Fig. 20-2. If a
surface(s) is close to the loudspeaker then detail
can be more important since more rays hit it. If a
surface(s) is distant from the loudspeaker, detail
is less important, because even with high detail
few rays may strike it.

Computer-Aided System Design
461
8.
Break very large spaces up into smaller spaces,
if they are acoustically isolated. The acoustics of
the gate area of an airport typically has little
influence on what is being heard in the check-in
area, even though technically they may be in the
same room.
9.
1⁄1-octave resolution is usually adequate to
qualify a design. Higher resolutions increase the
complexity of every aspect of the process,
making it more cumbersome to use the model as
an extension of the thought process.
10. You are building a calculator/estimator to help
you quantify/qualify your ideas. You’re the
designer, not the computer.
20.11 Conclusions
As with making room measurements, modeling may
or may not be a time-intensive task. The modeled
environment allows you to do many things that are
not practical or possible in real rooms. The ques-
tions raised by the modeling process may be as
important as the answers that it gives. Remember to
keep it simple and emphasize the majors without
getting bogged down with the minors.
Philosophy is an important aspect of room
modeling. One must understand what is possible to
predict with reasonable accuracy and what is not.
Some important attributes of the sound system
designer beyond a working knowledge of
electro-acoustics and room acoustics include
common sense, creativity and practicality. A knowl-
edgeable designer can likely produce a better sound
system without the aid of room modeling, than a
novice can with the aid of room modeling. A knowl-
edgeable designer armed with a compe-
tently-authored room modeling program is indeed a
tour de force.
Allow plenty of time to learn the modeling
process before trying to use it on an actual project.
Read the manual. Work through the tutorials. Start
with simple, “shoebox” spaces before tackling a
complex space. Over time you will develop the intu-
ition and skill for meaningful modeling.
References
1. CATT-Acoustic User’s Manual


Chapter 21
Signal Delay and Signal
Synchronization
by Don Davis
463
21.1 Signal Delay . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 465
What Is Time? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 465
Why Signal Delay?  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 465
Definitions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 465
Useful Values to Keep in Mind . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 465
21.2 Useful Signal Delay Equations  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 466
Temperature Effect on the Speed of Sound . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 466
Time . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 466
Travel Equations  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 466
Conventional Distance, Velocity, and Time Equations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 467
Delay  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 467
A More Accurate Velocity Equation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 467
Finding the Velocity of Sound with an Analyzer  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 467
The Henry, Fay-Hall, Haas Effect . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 468
A Typical Case  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 468
Setting Signal Delay  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 469
Signal Synchronization, Alignment and Convergence Defined  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 469
21.3 Synchronization and Alignment of Arrays  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 469
The High-Frequency Units  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 470
21.4 Finding Acoustic Origins of Unlike Devices . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 470
A Church Loudspeaker Missynchronization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 470
Removal of the Reflected Energy  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 471
Polar Response  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 471
21.5 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 472
Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 474


Signal Delay and Signal Synchronization
465
21.1 Signal Delay
When working with sound systems, as much as one
might wish to do so, we can’t delay time. We can’t
even delay relative time. What we can and do delay
is the signal. Alas, we just as often wish for a
noncausal anticipating signal device as we do for a
time delay. Neither is, or is likely to be, available.
21.1.1 What Is Time?
“Time flows endlessly like a river and you can’t put
your foot into the same river twice” so spake the
ancient philosopher in bygone Greece. Clock time is
based on the rotation of our planet and its base unit,
the second has a specific definition, “The duration
of 9,192,631,770 periods of the radiation corre-
sponding to the transition between the two hyperfine
levels of the ground state of the cesium—133 atom.”
The IEEE Standard Dictionary of Electrical and
Electronics Terms.
The concept of time is nebulous and has been
shown to dilate with increased velocity. No one
knows the resultant velocity of the planet earth as a
result of all the possible influences. Since the “big
bang” or whatever other theory one prefers, we can’t
be sure how universal our concept of time is, but at
least locally, it can be a useful parameter.
When a parameter has the dimensions in seconds
(s), be sure to find out which of the many ways time
is being looked at by the measurement. The words
we have discussed here are quite often misused or
distorted in their meaning. You don’t have to wear
four wrist watches (for the four U.S. time zones) and
a pocket watch set to GMT plus a portable WWV
receiver to be timely. Many of us rely on our Heath
Master time clock synchronized to WWV and settle
for the time to the nearest millisecond. Others write
Greenwich and ask for the exact GMT as “they
don’t trust the time given out by those little southern
radio stations.”
21.1.2 Why Signal Delay?
If the acoustic signals had the same velocity of prop-
agation, c, as the electrical signals, there would be
no need for signal delay devices. The difference in
velocity, unfortunately, is vast. Electromagnetic
waves in free space travel at approximately
982,080,000 ft/s. Such a wave requires only 101.8ns
(nanoseconds) to cross 100 ft.
21.1.3 Definitions
Acoustic waves traveling at 1130 ft/s require
88.5ms to travel the same distance. This is a differ-
ence of 869,000 to 1.
Signal delay devices typically offer resolutions
of 1.0 ms steps and precision delays of 10 μs steps.
21.1.4 Useful Values to Keep in Mind
1.
1.13 ft/ms.
2.
13.56 in/ms.
3.
0.01356 in/µs.
4.
0.1356 in/10 µs, approximately 1⁄8 in.
Our sense of hearing can detect the results of as
little as 15–20  µs difference in path length,
Fig. 21-1. Very short misalignment of devices
causes high frequency notches. Note that the
measurements in Fig. 21-1 are differenced measure-
ments, meaning that it was first normalized “flat” by
the analyzer so that only the differenced signal was
seen. The scale vertically is 6 dB/div. The horizontal
scale is 6561 Hz/in (linear). Delays from as small as
100 µs to those greater than 50 ms can actually inter-
fere with speech intelligibility. At the turn of the last
century, rubber tubes of unequal length were
inserted into the ears of listeners and spoken through
to determine sensitivity to sound delay paths as
short as 1.0 µs.
One test brought to our attention by Carolyn
“Puddie” Rodgers, as well conducted and signifi-
cant, was that of Hebrank, Wright, and Wilson at
Duke University. “They used noise added to delay
of itself and presented monaurally as their test
stimuli…. They found that on A/B tests, differences
in delays on the order of 7 µs could be detected.”
That translates into d = ct = 1130 (0.000007) (12) =
0.095 in of acoustic path difference if that form of
measurement were to be used. In far more casual
experimentation, we found that large groups could
easily hear the difference on speech signals of 20 µs
and 30 µs.
It is common practice in sound system design to
use a single point array in the front of an auditorium
to cover the main audience area and overhead loud-
speakers in the ceiling of under-balcony areas that
are shadowed from the main array. The resulting
signal delay, due to the length of the main array’s
longer path to the under balcony area and the very
0.001 s
=
1 ms (millisecond)
0.000001 s
=
1 µs (microsecond)
0.000000001 s
=
1 ns (nanosecond)
0.000000000001 s
=
1 ps (picosecond)

466
Chapter 21
short path from the overhead speakers, requires that
the overhead loudspeakers be signal delayed to
compensate for the difference in path length.
Today digital delay devices dominate the market.
The delay through analog-digital and digital-
to-analog converters is finite. Additionally, some
digital configurations in filters can provide signifi-
cant unsuspected delays. In real time sound rein-
forcement systems, the internal delays of all
components should be known prior to inclusion. On
one occasion in the author’s experience, a 30 ms
delay was hidden in a digital crossover network in a
packaged loudspeaker system. This loudspeaker, in
order to be used in the sound system, had to be
placed 34 ft in front of other loudspeakers associated
in the system.
21.2 Useful Signal Delay Equations
21.2.1 Temperature Effect on the Speed of 
Sound
(21-1)
where,
c is the velocity of sound in ft/s,
ºF is the Fahrenheit temperature.
Example
(21-2)
Example
21.2.2 Time
(21-3)
where,
c is the velocity in ft/s,
Time (in ms) = Distance (x ms/ft).
Example
100 ft × 0.885 ms/ft = 88.5 ms
21.2.3 Travel Equations
(21-4)
where,
c is the velocity of sound in air in ft/s.
(21-5)
Figure 21-1. Our hearing can detect 20 μs difference in path length.
Signal delay: 20 ms
Signal delay: 30 ms
Vertical: 6 dB differentiated data
Horizontal: Auto 0.00–23,998.60 Hz
Scale 6561.46 Hz/in
Vertical: 6 dB differentiated data
Horizontal: Auto 0.00–23,998.60 Hz
Scale 6561.46 Hz/in
A. 20 ms signal delay is more audible on music than on speech.
B. 30 ms signal delay is 0.41 inches out of alignment.
c
49 459.4
°F
+
=
49 459.4
72.42
+
1130 ft/s
=
°F
c2
492
--------
459.4
–
=
11302
492
--------------
459.4
–
72.42°
=
x ms
ft
-----------
1
c---
1000  ms
s
--------------------
×
=
1
1130  ft/s
---------------------
1000  ms
1  s
--------------------
×
0.885 ms
ft
---------------------
=
x ft
 ms
--------
c
1
1000  ms
--------------------
×
=
Distance
Time (in ms)
x ft
1  ms
-----------
×
=

Signal Delay and Signal Synchronization
467
Examples
88.5 ms × 1.13 ft/ms = 100 ft
21.2.4 Conventional Distance, Velocity, and 
Time Equations
(21-6)
(21-7)
(21-8)
where,
T is the time,
c is the speed of sound,
d is the distance.
Examples
186,000 mi/s × 0.016 s = 3000 mi
21.2.5 Delay
(21-9)
where,
d is distance,
c is the speed of sound in air.
Example
21.2.6 A More Accurate Velocity Equation
The velocity of sound c in air for normal tempera-
tures at sea level is dependent upon the density ρ of
the air. (The temperature of the air has a major influ-
ence on its density.) The barometric pressure exerts
a lesser effect under normal circumstances, the ratio
of specific heats γ for air = 1.402 and the equillib-
rium gas pressure Ps = 1.013 × 105 N/m2 (the atmo-
spheric pressure). The velocity c of sound can then
be expressed as:
(21-10)
The variable here is the density ρ and density can be
found accurately in specific cases by:
(21-11)
where,
H is the barometric pressure in centimeters of
mercury,
K is the temperature in Kelvins.
21.2.7 Finding the Velocity of Sound with an 
Analyzer
Place two identical loudspeakers exactly 1 ft apart,
having first observed the 6 dB add on the ETC for
the initial alignment. Two loudspeakers that are
equal amplitude and equal phase, i.e., identical
distances, from a measuring microphone will add
+6  dB whereas equal amplitude but random phase
only adds +3 dB. The +6 dB add insures the exact
overlap of the two loudspeaker patterns. Because
they are identical, we do know that they are exactly
1 ft apart even though we do not know exactly where
their acoustic origins are. See Fig. 21-2 for an expla-
nation of loudspeaker separation and how comb
filters are generated.
Now measure the frequency interval between the
“nulls” of the comb filter. This frequency interval
(the lower frequency null subtracted from the higher
frequency null) is the velocity of sound in ft/s. If SI
dimensions are desired, separate the two loud-
speakers by one meter.
This is true because the null frequency interval
(NFI ) is equal to the velocity (c) of the medium
divided by the distance (d ).
(21-12)
1130 ft
s
-----------------
1  s
1000  ms
--------------------
×
1.13 ft/ms
=
T
d
c---
=
d
cT
=
c
d
T---
=
1000 ms
1 s
--------------------
0.016  s
1
-----------------
×
16 ms
=
3000 mi
0.016  s
-------------------
186,000 mi/s
=
Delay (in ms)
d 1
c---
1000 ms
s
--------------------
×
⎝
⎠
⎛
⎞
=
Tms = 100 ft  ×  
1 s
1130 ft
1000 ms
1 s
= 88.5 ms
×
c
γPs
ρ
--------
=
ρ*
0.00129H
1
0.00367 K
(
) 76
(
)
+
-------------------------------------------------103
=
*In kilograms per cubic meter
NFI
c
d---
=

468
Chapter 21
Thus, if d is made unity (equal to 1.0) then:
The beauty of this technique is that any set of
arbitrary marks on the two loudspeakers, so long as
they are in identical locations on the loudspeakers,
can serve as the measuring points for the determina-
tion of “d.” The frequency calibration of the
analyzer is not dependent upon the velocity of the
media but upon the accuracy and stability of the
internal clock.
It is important to align the microphone exactly on
a line equal angle from the two loudspeakers, both
vertically and horizontally (remember, one loud-
speaker is to the rear of the other). The analyzer is
“tuned” for the maximum depth of notch (i.e., half-
way between the two loudspeakers). Every effort
should be made to achieve a high frequency resolu-
tion, fR, at the sacrifice of some slight reflective inter-
ference. When the NFI is exactly the same between
the null frequencies, then you are reasonably assured
that the geometric alignment between the loud-
speakers and the measuring microphone is correct.
21.2.8 The Henry, Fay-Hall, Haas Effect
The Henry, Fay-Hall, Haas effect phenomenon has a
lengthy history starting with Joseph Henry’s
remarkable experimentation at the Smithsonian in
the 1840s. Henry used a child’s “clicker” to listen to
reflections from a large brick wall to determine the
zone of inaudibility of the reflected energy.
A listener equidistant from two loudspeakers
with identical levels at his or her ears will develop a
phantom halfway between the two, see Fig. 21-3.
However, if one of the loudspeakers has a signal to
it delayed by 20 ms, then all the sound appears to
come from the loudspeaker with the undelayed
signal. In fact, the delayed-signal loudspeaker will
have to be raised 10 dB to again seem equal to the
listener. This effect occurs in anechoic chambers
and over headphones from about 1 ms up to about
30+  ms. In real spaces with real loudspeakers,
20–25ms works best.
21.2.9 A Typical Case
A typical case would be the single source system
discussed earlier with the overhead under balcony
loudspeaker covering the shaded areas the front
loudspeaker cannot see into directly. The distance,
D2 (1), from the loudspeaker in front to the listener
in the under balcony area is 100 ft. The distance,
D2 (2), from the overhead ceiling loudspeaker to the
same listener is 10 ft. The needed delay is
Best practice dictates not stopping there but
adding from 5–20 ms extra to obtain the Haas effect,
keeping the illusion that all the sound is from the
front loudspeaker.
With single source systems the Haas effect can
be obtained naturally by placement of the single
source loudspeaker above and behind the talker so
that D2 exceeds D0 by 20  ms. For a 100  ft D0
(88.5 + 20) × 1.13 ft = 122.6 ft, see Fig. 21-4. The
Doak and Bolt criteria provide a guide to determine
when a delay is detrimental, see Fig. 21-5.
Where loudspeakers have to be mounted above,
but well forward of the talker’s position, signal
delay can be used to localize the source as the talker.
Listeners to such systems sometimes say the system
is doing nothing and they are hearing only the talker
until they are given a demonstration of the system
“on” followed by the system “off ” and discover that
the loudspeaker was indeed 10 dB higher than the
talker.
Figure 21-2. Measuring the velocity of sound using the
Gold Line TEF analyzer.
Loudspeaker
Microphone
Placed on line shared
by both loudspeakers
Resultant comb
filter exposure
(correct alignment of
loudspeakers - microphone
results in all NFIs being
the same)
NFI = c/d
Let d = 1 then: c = NFI
*NFI is null frequency interval in Hz
1 ft
or
1 m
NFI*
c
NFI
=
Figure 21-3. The Henry, Fay-Hall, effect.
Undelayed
signal
Delayed
signal
2 ms
Phantom when
neither loudspeaker
is delayed
Listener
dB
0
10
Tms
D2 1
( )
D2 2
( )
–
[
]
0.885
×
=
100
10
–
[
]
0.885
×
=
79.7  ms
=

Signal Delay and Signal Synchronization
469
21.2.10 Setting Signal Delay
A clever but accurate way to set signal delays is to
use “clicks” at the performer’s microphone with the
listener wearing a headphone on one ear standing
out in the audience area where the delay is to be
applied. The delay is adjusted until the electrical
signal, in the head phone, synchronizes with the
acoustic signal through the air. The delay should be
adjusted past synchronization to missynchroniza-
tion from too much rather than too little delay in the
delay device. Halfway between these two points on
the delay device should be optimum. (Credit Rick
Clarke of London.)
21.2.11 Signal Synchronization, Alignment and 
Convergence Defined
Signal alignment is usually a physical adjustment. It
can be the attempt to physically adjust a L. F. device
to a H. F. device in the crossover region. This can
rarely be accomplished without a high resolution
analyzer. Signal alignment can also mean two like
devices, i.e., two H. F. horns, where arbitrary mark-
ings on one can be aligned with identical markings
on the other.
Synchronization is usually used when electronic
means are employed, usually a digital delay device,
to synchronize two devices that must be physically
separated but must be acoustically brought into
identical arrival times at the listener’s ears. Another
use of synchronization is the adjustment of under-
balcony loudspeaker delay to match the arrival of
the single source front array. Usually such synchro-
nization is not exact but includes the additional
delay for the Haas effect to occur.
Where the pattern converges is called the
acoustic center. Where the sound emits from in rela-
tive time is called the acoustic origin. Ideally we
would like to have both the origins and the centers
aligned whenever possible. Sometimes physical
alignment of one requires that we electronically
synchronize the other, i.e., long-throw horns with
short-throw horns in the area where the −6 dB over-
laps between their polar responses occur.
A “fly in the ointment” in either method can be
convergence, where the apparent emergence of the
spreading wave is different for the horizontal and
vertical planes. Such a condition is called acoustic
astigmatism. When such devices (they are usually
high Q devices) are used singly it is acceptable, but
attempts to array them can cause serious
compromises.
Knowledge of these terms is necessary in evalu-
ating the compatibility of devices in an overall array.
21.3 Synchronization and Alignment of 
Arrays
Since we cannot delay time or otherwise manipu-
late it, we can use audio devices to delay one signal
relative to another by various methods of storage
and retrieval of the signal or by adjusting the posi-
tion of one source relative to another as measured at
some other relative time, neither of which is depen-
dent upon absolute time for its operation.
In signal synchronization a millisecond is a long
time unit. A significant parameter to remember is
74µs = in (73.75 to be tediously exact). The dimen-
sions from one inch to about three feet are audible
on-axis but the real danger is that they change the
polar response of two devices covering the same
frequency range and audience area. The lobes in
many cases go straight to the “hot” microphone and
are higher in level than the “on-axis” lobe.
Figure 21-4. Using natural signal delay.
Figure 21-5. Doak and Bolt delay-versus-level criteria.
D0 = 100 ft
D2 = 122.6 ft
D2 = D0 + 20 ms
Undelayed sound
source 2
Undelayed sound
source 2
Natural delay = 200 ms
Listener’s head
A. Relative delay at listener.
10
0
−10
−20
−30
−40
Delayed signal levels
difference–dB
Signal-delay correction required
if delayed signal level and time
difference fall above line.
Signal-delay correction not required
if delayed signal level and time
difference fall below line.
0           100          200          300          400         500
Time–ms
ms
Feet
B. Signal delay versus relative levels.

470
Chapter 21
Critics of synchronization often say that full
synchronization can only be achieved at a single
point in space. What’s overlooked is that signal
synchronization, when performed at the overlaps
between devices, results in the patterns retaining
their directional integrity whereas just inches of
missynchronization cause the polar responses of
both devices to be corrupted.
The synchronization and alignment of arrays is
no longer an open question, but rather a pressing
necessity. While alignment at the crossover
frequency between the low-frequency devices and
the high-frequency devices is indeed desirable, it is
not the highest priority. The signal synchronization
that is absolutely critical is the synchronization
between identical or similar devices that share the
same frequency range while at the same time
sharing a portion of the same coverage area.
In very high quality, powerful sound systems, the
frequency spectrum from 500–5,000 Hz must be
carefully tailored by equalization, signal alignment,
signal synchronization and coverage. In terms of
coverage and signal alignment or synchronization, it
is highly desirable to have devices whose character-
istics are not dramatically frequency dependent over
the 500–5,000 Hz range. When multiple devices
must be employed in order to achieve coverage,
their overlap zones must be brought into signal
synchronization. Some devices won’t allow signal
synchronization because their acoustic centers and
their acoustic origins are not compatible.
Two or more devices covering the same
frequency range at the same levels but with one
signal delayed relative to the other is the most serious
case. It can be repeatedly demonstrated that 30 μs
(thirty-one- millionths of a second) is clearly audible
on speech signals over a single loudspeaker but with
two signals only 30 µs apart, see Fig. 21-1. The iden-
tical effect occurs if we use two loudspeakers with
one 0.41 in behind the other, i.e., 30µs.
21.3.1 The High-Frequency Units
We take the same approach with the high-frequency
devices. In this case, however, we must take great
care to ascertain acoustic origins and align them
because at these shorter wavelengths misalignment
of acoustic origins can cause changes in the ampli-
tude response of the system. (See Chapter 18 Loud-
speakers and Loudspeaker Arrays for a discussion
of acoustic origins, centers, etc.) If misalignment of
acoustic origins simply cannot be avoided in a given
case, then we must be sure it is not a small misalign-
ment or one that causes a null frequency interval
(NFI) to fall in the array’s crossover region.
The advent of digital signal delay devices that
allow signal-delay adjustments in 10 µs steps has
provided array designers with enviable freedom on
the geometry of the array while preserving the
synchronization criteria.
The ETC display shown in Fig. 21-6A is of two
measurements overlaid on the screen. The first curve
shows the energy arrival in time for two like devices
that are 0.170 ms (2.3 in) apart. The second curve
shows the result of dialing in 0.170 ms delay to the
loudspeaker that originally arrived first. Note partic-
ularly the 6 dB increase that occurs for coherent addi-
tion of the two signals once they are aligned.
The energy frequency curve, EFC, display,
Fig. 21-6B, is again two measurements overlaid on
the screen. The first curve shows the comb filtering
produced by two like devices being 0.170 ms out of
synchronization. The second curve shows the result
of the 0.170 ms delay being used.
We frequently encounter a school of thought that
feels that all one really has to do is get coverage. N
factors, signal synchronization, Q selection, all give
place to coverage. We really do not know what set
of values dominated in this design of an array. Since
all horns are identical, we might guess that coverage
was the main consideration. The measurements tell
the story, see Fig. 21-7.
21.4 Finding Acoustic Origins of Unlike 
Devices
When both the directional control device, DCD, and
the transducer of two high-frequency units are iden-
tical, even though we do not know where their
acoustic origins actually are, we can know that they
are in the same place for both. This means that any
arbitrary mark made in exactly the same place on
both units allows accurate alignment of the two
devices to each other. Whenever either the trans-
ducers or the DCDs differ from each other, then this
simple method no longer is applicable. It is worth-
while to repeat that the alignment of acoustic origins
is absolutely necessary when the devices being
aligned cover the same frequency range. Some
devices won’t allow such alignment due to acoustic
astigmatism, i.e., their acoustic centers and their
acoustic origins are not compatible.
21.4.1 A Church Loudspeaker 
Missynchronization
An excellent illustration of what can occur when
seemingly minor missynchronization is present is

Signal Delay and Signal Synchronization
471
shown in the case of a Catholic church with an RT60
of 2.4 s at 2 kHz.
A loudspeaker array consisting of a 15 inch
low-frequency unit, a ten-cell short-throw horn, and
a two-cell long-throw horn was installed in this
church. In the area about mid-church where the
patterns of the two horns overlapped, there was a
complaint of poorer quality than seats either further
forward or further back. ETC measurements
revealed a 30 µs missynchronization. The EFC
showed severe comb filtering in the acoustic
response. The measurement of %AlCONS was 10.5%.
A precision signal-delay unit was then connected
to the array just ahead of the power amplifiers. The
device arriving first (the near-throw horn) was
connected to a delay output on the precision signal
delay and was delayed by exactly 300 µs, approxi-
mately 4 inches, the far-throw device was connected
to the reference output of the precision signal delay.
Fig. 21-8 shows the before and after ETCs. Fig. 21-9
shows the before and after EFCs. Note the tremen-
dous increase in LD at the measurement point. The
EFC reveals the corrected acoustic response; the
%AlCONS is now 6.9%.
21.4.2 Removal of the Reflected Energy
The removal of the undesired polar pattern, due to
missynchronization, striking the offending walls
was startling. I was standing in the overlap area of
the two devices and hearing sound from the
surrounding walls when the correction was inserted.
It was as if the walls had fallen away. Subjectively
the most startling effect was the almost total
removal of audible reflected energy from the room
when the synchronization correction was turned on.
Prior to switching to synchronization, sound from
the rear wall was nearly as loud as from the array,
and substantial side wall reflections were apparent.
21.4.3 Polar Response
It was apparent that the missynchronization caused
more than comb filtering of the signal on the
measurement axis. We later duplicated the missyn-
chronization by misaligning two loudspeakers by
the same 4 in distance and measured the polar
response. Fig. 21-10 shows the before and after
synchronization ETCs. Fig. 21-11 shows the polar
response before and after synchronization.
When a missynchronization as small as a few
inches is present, it destroys a planned polar
response. In this church, the polar response of the
synchronized speakers encountered a usable Ma
factor, which resulted in very little excitation of the
reverberant sound field. The missynchronized array
sent significant energy to the side walls and to the
floor and ceiling, generating an audibly higher rever-
berant level. It also supplied energy via the ceiling to
the rear wall where it was focused and returned to
the measurement position. The change in energy
ratio, LD − LR, was from −5.76 dB for the unsynchro-
nized and +0.75 dB for the synchronized system.
Figure 21-6. Two loudspeakers misaligned.
B. EFC of two loudspeakers where the bottom trace
shows the comb filters from misalignment and the
top response is in alignment.
Frequency
Time
A. ETC of two loudspeakers 2.3 inches apart—
note the 6 dB gain when in alignment.

472
Chapter 21
21.5 Conclusion
A good, basic understanding of these simple but
important relationships is vital to the creative design
of sound systems today. Signal delay relationships
complete the chain of necessary criteria for the
proper placement of a loudspeaker.
1.
Location allows an ALCONS of 15% or less at D2.
Location allows PAG = NAG.
2.
Location ensures that no signal delay shall
exceed 40 ms (approximately 45 ft) at either the
listener’s location or the performer’s location
without sufficient remedial measures (earphones
for the announcer at a basketball arena, monitor
loudspeakers, or similar facilities).
Figure 21-7. Effect of combining unaligned loudspeakers in an array.
H.F. 1
H.F. 2
H.F. 3
H.F. 5
H.F. 7
H.F. 4
H.F. 6
H.F. 8
L.F.
A. Loudspeaker array configuration.
B. Measurement of a single horn #7.
C. Measurement of high frequency horn #5.
D. Measurement of high frequency horns #3 and #5.
E. Measurement of high frequency horns #3, #5, and #7.
F. Measurement of high frequency horns #3 through #8.
6 dB
6 dB
6 dB
6 dB
6 dB
FR = 250 Hz
Linear 0 Hz–10,000 Hz
FR = 250 Hz
Linear 0 Hz–10,000 Hz
FR = 250 Hz
Linear 0 Hz–10,000 Hz
FR = 250 Hz
Linear 0 Hz–10,000 Hz
FR = 250 Hz
Linear 0 Hz–10,000 Hz

Signal Delay and Signal Synchronization
473
Figure 21-8. ETCs of a church sound system.
Figure 21-9. Frequency response of unaligned and synchronized horns.
Figure 21-10. Stacked monitors.
Vertical: 6 dB/division
Horizontal: 0 - 1,971,547 ms
Both horns: Near -throw delayed 300 ms
B. Both horns synchronized with near-throw horn.
Vertical: 6 dB/division
Horizontal: 0 - 1,971,547 ms
No delay
A. Near-throw and far-throw horns out of alignment
3 inches (mouths of the horns were aligned).
Vertical: 6 dB/division
Horizontal: 50.33 - 10,001.20 Hz
Resolution: 5.3674E+02 Hz
Both horns: Near -throw delayed 300 ms
B. Frequency response of synchronized horns.
Vertical: 6 dB/division
Horizontal: 50.33 - 10,001.20 Hz
Resolution: 5.3674E+01 Hz
Both horns: No delay
A. Unaligned horns.
Vertical: 6 dB/division
Horizontal: 4000–16,639 ms
A. In alignment.
Vertical: 6 dB/division
Horizontal: 4000–16,639 ms
B. Out of alignment—note 6 dB drop in level.

474
Chapter 21
The wise use of digital delay devices in audio
systems required the development of low noise, reli-
able devices, precision measurement analyzers, and
last, but certainly not least, a cadre of trained
personnel capable of applying the tools and tech-
niques developed over the years. Modern day tools,
techniques, and engineers handle these challenges
successfully.
Bibliography 
H. Haas. “The Influence of a Single Echo on the Audibility of Speech,” J. Audio Eng. Soc., Vol. 20 (Mar.
1972), pp. 145-159.
J. Henry. “On Acoustics Applied to Public Buildings.” Paper presented at the American Association for the
Advancement of Science, August 1856; later published in the Smithsonian Institution publication.
J. K. Hilliard. “Notes on How Phase and Delay Distortions Affect the Quality of Speech, Music and Sound
Effects,” IEEE Trans. on Audio (Mar.-Apr. 1964).
Figure 21-11. Two monitors in and out of alignment.
A. In alignment.
B. Out of alignment.

Chapter 22
Signal Processing
by Eugene Patronis, Jr.
475
22.1 Spectra  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 477
Fourier Trigonometric Series . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 477
Fourier Exponential Series  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 481
Fourier Integral  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 483
General Properties of Fourier Transforms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 484
Unit Impulse  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 487
Spectrum of a Periodic Impulse Sampled Signal  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 489
Sampling Theorem  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 493
Aliasing  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 494
Realistic Sampling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 495
22.2 Analog to Digital Conversion  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 497
22.3 System Theory . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 502
Pole and Zero Analysis  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 508
Further Considerations  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 512
Equalization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 514
Equalization—Global or Local  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 517
22.4 Digital Systems and the Z Transform  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 520
Recursive or IIR Filters . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 524
Linear Phase Filters . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 527
22.5 Dynamics Processing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 528
Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 531


   
Signal Processing
477
One could reasonably argue that anything interposed
between the original source of sound and the listener
constitutes signal processing. Many recording and
sound reinforcement engineers, for example, select
microphones based upon how the microphone alters
the quality of the sound in the final product. Some
microphones provide a boost in the 2 kHz to 4 kHz
region and are said to add “presence.” Cardioid
microphones when worked at a close distance
exhibit a “proximity effect” that amounts to a bass
boost that can add body to a weak or thin voice.
For the present purpose, however, signal
processing will be confined to certain properties of
the signal chain that exist between the microphone
or microphones and the loudspeaker or loud-
speakers. Much of this processing is linear and time
invariant in that it does not depend on the signal
amplitude or the time of occurrence of the signal in
question. In some instances the processing is
non-linear such as noise gates, downward
expanders, and compressors as well as limiters.
Amplifiers also exist in this signal chain. Wide
bandwidth linear amplifiers, other than offering
voltage and or power amplification, are essentially
benign and as such are not considered as signal
processors per se.
Linear signal processing will be considered to be
any and all filtering that modifies a signal’s ampli-
tude and phase as a function of frequency. System
equalization falls in this category. Linear signal
processing will also include all pass filters that
modify only phase as a function of frequency while
leaving the amplitude untouched. All pass filters
also include signal delay units. Signal delay units,
while delaying the appearance of a signal as viewed
on the time axis, accomplish this by providing a
phase lag that is proportional to frequency while
leaving the amplitude untouched.
Signal processing functions are often distributed
among several devices in the overall signal chain.
Mixers, for example, often contain several boost/cut
bandpass or shelving filters associated with each
input channel. Additionally, loudspeaker manage-
ment systems generally offer loudspeaker crossover
networks as well as signal delay for individual loud-
speaker elements.
Originally, signal processing was accomplished
solely through the employment of analog circuitry.
Currently, both analog as well as digital circuitry are
employed with more and more digital circuitry
being introduced almost on a daily basis. In this
regard, analog to digital and digital to analog
converters are necessary adjuncts to the dedicated
digital signal processors. These devices will be
referred to as ADCs, DACs, and DSPs, respec-
tively. The ADC employs a process known as signal
sampling while the DAC employs a process termed
signal reconstruction. The DSP can be programmed
to perform digital filtering, signal delay, equaliza-
tion, and other signal processing functions. In order
to understand the operations involved in signal
processing it is necessary to know how signals are
described in the frequency domain. Furthermore, the
interactions between the various components in a
signal processing chain are best understood in terms
of subject matter known as system theory. These
two areas will be reviewed briefly before exam-
ining the details of signal processing itself.
22.1 Spectra
Jean Baptiste Joseph Fourier (1768-1830) was a
French mathematician and theoretical physicist.
While working on a problem dealing with heat
conduction in solids, Fourier made a mathematical
discovery which has had significance far beyond the
bounds of his original problem. Fourier’s original
discovery has led to the development of the modern
mathematical tools that allow a frequency domain
description of events which occur in the time
domain.
22.1.1 Fourier Trigonometric Series
In Fourier’s original problem, a source of heat was
placed at some point within a thin disc and the
objective was to describe the temperature as a func-
tion of position on the circular periphery of the disc.
The geometry of the disc suggested polar coordi-
nates as the coordinates of choice for describing
position both in the interior of the disc as well as on
the periphery. The describing function for the
temperature distribution on the periphery of the disc
for this choice of coordinates is periodic in the polar
angle with a period of 2π. This is true because
starting with any initial angle θ, an increase of angle
by 2π brings one back to the same point having, of
course, the same temperature. Fourier found that
upon letting y equal the temperature at a given point
on the periphery that 
(22-1)
In the above expression, n takes on the value of
each positive integer. The coefficient a0 is the
average value of y over the interval 0 to 2π.
y
f θ
( )
=
a0
an
nθ
(
)
cos
bn
nθ
(
)
sin
+
n
1
=
∞
∑
+
⎝
⎠
⎜
⎟
⎜
⎟
⎛
⎞
=

478
Chapter 22
(22-2)
The coefficients in the infinite series sum repre-
senting y are given by
(22-3)
and
(22-4)
The expression for f (θ) is now called the Fourier
trigonometric series. Pursuant to Fourier’s work, it
was soon discovered that the Fourier trigonometric
series were members of a much larger set of mathe-
matical functions, called orthogonal functions,
having similar properties. The orthogonal proper-
ties of the members of the Fourier series are summa-
rized in the following statements of fact where m
and n are integers. When m and n are any integers,
(22-5)
(22-6)
(22-7)
In the event that m and n are different integers,
(22-8)
(22-9)
Finally, for the case of m and n being equal integers,
(22-10)
(22-11)
Now that the essential tools are in place, the fore-
going can be made more meaningful by performing
a Fourier analysis on some common periodic wave-
forms which are often encountered in audio and
electronics. A useful waveform often employed in
amplifier testing and evaluation is the square wave.
The square wave to be considered here has an
amplitude of 1 V and a period of T. This square wave
is depicted in Fig. 22-1.
The depiction in Fig. 22-1 employs the indepen-
dent variable θ along the horizontal axis. The inde-
pendent variable can easily be converted to time by
recognizing that
(22-12)
The objective at this point is to determine the
terms in the Fourier trigonometric series which when
added together will produce the shape depicted in
Fig. 22-1. Initially, two observations should be made
about the waveform in the figure. The first observa-
tion is that the average value of the waveform over
any period or any integral number of periods is zero.
Thus any collection of terms employed to describe
the waveform must also have an average value of
zero. The second observation is that
(22-13)
In words, this says that the algebraic sign of the y
axis value or ordinate of the waveform reverses as
one goes from a positive point on the x axis or
abscissa of the waveform to the corresponding
negative value of the abscissa. Mathematically, such
a0
<y>
=
1
2π
------
f θ
( ) θ
d
0
2π
∫
=
an
1
π---
f θ
( )
nθ
(
)
cos
θ
d
0
2π
∫
=
bn
1
π---
f θ
( )
nθ
(
)
sin
θ
d
0
2π
∫
=
mθ
(
)
cos
θ
d
0
2π
∫
0
=
mθ
(
)
sin
θ
d
0
2π
∫
0
=
mθ
(
)
nθ
(
)
cos
sin
θ
d
0
2π
∫
0
=
mθ
(
)
cos
nθ
(
)
cos
θ
d
0
2π
∫
0
=
mθ
(
)
nθ
(
)
sin
sin
θ
d
0
2π
∫
0
=
Figure 22-1. A square wave of unit amplitude.
cos2 mθ
(
) θ
d
0
2π
∫
π
=
sin2 mθ
(
) θ
d
0
2π
∫
π
=
−4π
−2π
4π
2π
1
θ
2π t
T---
=
2πf0t
=
ω0t
=
f θ
( )
f
–
θ
–
(
)
=

   
Signal Processing
479
a function is called an odd function and can only be
represented by a collection of odd functions. An
even function would be one for which
(22-14)
These observations save a lot of unnecessary
labor because the terms in the Fourier series are
either sines or cosines. The sine is an odd function
while the cosine is an even function. At this point,
then, only the sine terms in the Fourier series need
be considered for this particular waveform.
The example square wave has a rather simple
mathematical description, namely
(22-15)
(22-16)
At this juncture it is possible to set up a general
expression for the coefficients of the sine terms in
the Fourier series describing the example square
wave.
(22-17)
One is now positioned to write the Fourier series
describing the given square wave, i.e.; specific
numbers can be assigned to the coefficients. As
mentioned earlier, an = 0 for all values of n. b0 = 0
because the integrands in the general expression
vanish as sin(0) is zero. For even values of n other
than zero
(22-18)
where,
n is an even integer.
For odd values of n
(22-19)
where,
n is an odd integer.
Therefore the unit amplitude square wave under
consideration is represented by the infinite series
(22-20)
Recalling that θ = ω0t = 2πf0t, this result can also
be expressed as
(22-21)
The spectrum of the square wave, then, consists
of a fundamental frequency equal to the reciprocal
of the period of the square wave along with dimin-
ishing amplitude odd harmonics of the fundamental
frequency. Furthermore, as the phase angles of the
fundamental as well as the harmonics are zero at
t = 0, all of the frequency components are in phase.
It is instructive to examine how the Fourier
description of the square wave is affected by the
choice of origin of coordinates. Fig. 22-2 displays
the unit amplitude square wave where the origin of
coordinates has been shifted to the right by  π ⁄ 2
radians. This new square wave is now an even
function.
Mathematically, this shift amounts to a change of
independent variable such that 2πf0t is replaced by
2πf0t′+π ⁄ 2. Upon making this substitution, f(t)
becomes f (t′) with
(22-22)
This can be greatly simplified by making use of a
common trigonometric identity involving the sum of
two angles.
f θ
( )
f
θ
–
(
)
=
f θ
( )
+1 when 0 < θ < π
=
f θ
( )
1 when π
θ < 2π
<
–
=
bn
1
π---
+1
(
)
nθ
(
)
sin
θ
d
0
π
∫
1
π---
1
–
(
)
nθ
(
)
sin
θ
d
π
2π
∫
+
=
1
nπ
------
nπ
(
)
cos
–
1
2nπ
(
)
nπ
(
)
cos
–
cos
+
+
[
]
=
1
nπ
------ 1 2
nπ
(
)
cos
–
2nπ
(
)
cos
+
[
]
=
bn
1
nπ
------ 1
2
–
1
+
[
]
=
0
=
bn
1
nπ
------ 1
2
1
+
+
[
]
=
4
nπ
------
=
Figure 22-2. Unit amplitude square wave as an even
function.
f θ
( )
4
π---
θ
( )
sin
1
3---
3θ
(
)
sin
1
5---
5θ
(
)
sin
1
7---
7θ
(
)
…
+
sin
+
+
+
=
f t( )
4
π---
2πf0t
(
)
sin
1
3---
2π3f0t
(
)
sin
1
5---
2π5f0t
(
)
sin
1
7---
2π7f0t
(
)
…
+
sin
+
+
+
=
−4π
−2π
4π
2π
f t′
( )
4
π---
2πf0t′
π
2---
+
⎝
⎠
⎛
⎞
sin
1
3---
2π3f0t′
3π
2
------
+
⎝
⎠
⎛
⎞
sin
1
5---
2π5f0t′
5π
2
------
+
⎝
⎠
⎛
⎞
sin
…
+
+
+
=

480
Chapter 22
(22-23)
This identity leads to the statements
(22-24)
(22-25)
(22-26)
Therefore the expression for this time shifted square
wave that is now an even function is
(22-27)
It is important to observe that the time shift alters
only the phases of the frequency components. The
frequency components present and their amplitudes
are unchanged.
There are some limitations on the types of mathe-
matical functions which can be represented by the
Fourier series. For example, the function to be
represented in a given interval must be continuous
and finite or, if discontinuous, must have a finite
number of finite discontinuities. The mathematical
square wave used as the first example has a discon-
tinuous jump between +1 and −1 at θ = π and
another discontinuous jump between −1 and +1 at
θ = 2π. At such points, the sum of the infinite series
converges to the mid point of the jump. In this
instance, the mid point is zero. Any physically
generated square wave would make this transition in
a finite though short interval and thus would not
display discontinuous behavior. The Fourier series
can represent such a physical square wave exactly at
all points in the interval 0 ≤ θ ≤ 2π.
Before leaving the square wave expressed as an
even function, one final change is of interest. In this
change, a constant of 1 is added to the wave
producing the waveform depicted in Fig. 22-3.
The square wave depicted in Fig. 22-3 has an
average value of one. This follows from the fact that
it was constructed by adding a constant value of one
to a function which originally had an average value
of zero. The formal calculation proceeds through the
following steps.
(22-28)
Upon equating θ with 2πf0t, the Fourier series
describing the square wave of Fig. 22-3 becomes
(22-29)
An analysis of a half wave rectified cosine wave-
form of unit amplitude leads to the result
(22-30)
If, instead, one has a full wave rectified cosine
wave of unit amplitude, the Fourier analysis yields
(22-31)
It should be noted that the average value of the
full wave signal is twice that of the half wave as one
might guess. Additionally, the lowest frequency
component in the full wave signal is the second
harmonic rather than the fundamental frequency.
Thus the full wave signal is more readily filtered
than is the half wave.
A
B
+
(
)
sin
A
( )
B
( )
cos
sin
A
( )
B
( )
sin
cos
+
=
2πf0t′
π
2---
+
⎝
⎠
⎛
⎞
sin
+
2πf0t′
(
)
cos
=
2π3f0t′
3π
2
------
+
⎝
⎠
⎛
⎞
sin
2π3f0t′
(
)
cos
–
=
2π5f0t′
5π
2
------
+
⎝
⎠
⎛
⎞
sin
+
2π5f0t′
(
)
cos
=
f t′
( )
4
π---
2πf0t′
(
)
cos
  1
3---
–
2π3f0t′
(
)
cos
1
5---
2π5f0t′
(
)
cos
  1
7---
–
2π7f0t′
(
)
…
+
cos
+
=
Figure 22-3. Square wave whose average value is one.
−4π
−2π
4π
2π
1
a0
1
2π
------
f θ
( ) θ
d
0
2π
∫
=
1
2π
------
2 θ
d
0
π
2---
∫
0
θ
d
⋅
(
)
π
2---
3π
2
------
∫
2 θ
d
3π
2
------
2π
∫
+
+
=
1
2π
------ π
0
π
+
+
[
]
1
=
=
f t( )
1
4
π---
+
2πf0t
(
)
cos
  1
3---
–
2π3f0t
(
)
cos
1
5---
2π5f0t
(
)
cos
  1
7---
–
2π7f0t
(
)
…
+
cos
+
=
y t( )
1
π--- 1
π
2---
2πf0t
(
) 
cos
+
+ 2
3---
2π2f0t
(
)
cos
 2
15
------
2π4f0t
(
)
cos
–
 + 2
35
------
2π6f0t
(
)  …
–
cos
⎝
⎠
⎛
⎞
=
y t( )
2
π--- 1
2
3---
2π2f0t
(
) 
cos
+
 2
15
------
2π4f0t
(
)
cos
–
+ 2
35
------
2π6f0t
(
)  …
–
cos
⎝
⎠
⎛
⎞
=

   
Signal Processing
481
Two other often-encountered waveforms are the
triangle and the sawtooth. A plot of each of these
waveforms is displayed in Fig. 22-4.
For the triangle waveform of unit amplitude
(22-32)
Whereas for the sawtooth of unit amplitude
(22-33)
22.1.2 Fourier Exponential Series
Upon identifying 
, the general
Fourier trigonometric series can be written as
(22-34)
If one writes Euler’s theorem in the form
 and solves individu-
ally for the sine and cosine terms, one obtains
(22-35)
(22-36)
When these are substituted into the general expres-
sion for the trigonometric series, the result can be
written as
(22-37)
This compact expression is called the Fourier
exponential series. The coefficients, cn, are related
to the former coefficients in the following manner.
(22-38)
(22-39)
(22-40)
…
It should be noted that the coefficients for the
exponential series, with the exception of c0, are
complex and that they occur in complex conjugate
pairs such that
(22-41)
The coefficients for the exponential series can be
calculated directly by employing the integral
expression
(22-42)
The Fourier exponential series is introduced here
for two reasons. Firstly, the general expression for
the exponential series is more compact than that for
the trigonometric series and, secondly, the exponen-
tial series for periodic waveforms provides a step-
ping stone to the Fourier integral transform. The
Fourier integral transform can be employed to calcu-
late the spectra of more general time dependent
Figure 22-4. Triangle and sawtooth waveforms.
y
y
T
T
t
t
Triangle
Sawtooth
y t( )
8
π2
-----
2πf0t
(
)
cos
 + 1
9---
2π3f0t
(
)
cos
+ 1
25
------
2π5f0t
(
) + …
cos
⎝
⎠
⎛
⎞
=
f t( )
2
π---
2πf0t
(
)
sin
  1
2---
2π2f0t
(
)
sin
–
1
3---
2π3f0t
(
)
sin
  1
4---
–
2π4f0t
(
)
…
+
sin
+
=
ω0
2π 1 T
⁄
(
)
2πf0
=
=
f t( )
a0
an
nω0t
(
)
cos
bn
nω0t
(
)
sin
+
n
1
=
∞
∑
+
=
ejnω0t
nω0t
(
)
cos
j
nω0t
(
)
sin
+
=
nω0t
(
)
cos
1
2--- e
jnω0t
e
jnω
–
0t
+
(
)
=
nω0t
(
)
sin
j
–
2---- e
jnω0t
e
jnω
–
0t
–
(
)
=
f t( )
cne
jnω0t
n
∞
–
=
n
+∞
=
∑
=
c0
a0
=
c1
1
2--- a1
jb1
–
(
)
=
c 1
–
1
2--- a1
jb1
+
(
)
=
c n
–
cn
*
=
cn
1
2π
------
f t( )e
j
– nω0t
ω0t
(
)
d
0
2π
∫
=

482
Chapter 22
functions independent of whether the time function
is periodic or not.
The Fourier exponential series will now be
employed to determine the spectrum associated with
a recurrent train of pulses. This periodic waveform
is depicted in Fig. 22-5.
The recurrent pulse train of Fig. 22-5 has an
amplitude of 1, a fundamental frequency or pulse
repetition frequency f0 corresponding to the period
T, and the ratio of the pulse repetition period to the
duration of each pulse is denoted by a constant
termed k. The figure was constructed assuming that
k was equal to 4. The constant, k, however, can take
on any value greater than one. If k is allowed to take
on larger and larger values, the width of an indi-
vidual pulse becomes narrower and narrower and
the interval between pulses becomes relatively
larger and larger.
The analysis of this recurrent pulse train consists
of calculating the coefficients of the Fourier expo-
nential series. In performing this analysis, the 2π
interval over which the integrations are performed
may be taken anywhere on the θ axis. For ease of
calculation, this interval is chosen as −π to +π. The
function, however, is zero except between −π ⁄ k and
+π ⁄ k in which range it has the value of one. There-
fore when it is remembered that ω0t = θ, then
(22-43)
If n = 0,
(22-44)
If n ≠ 0,
(22-45)
The coefficients, cn, represent the amplitude and
phase of the constituent frequency components
which contribute to the recurrent pulse train. The
recurrent pulse train is recovered or synthesized
through the addition of these frequency components
employing the respective amplitudes and phases
determined in the analysis. Therefore,
(22-46)
The fact that n takes on both positive and nega-
tive values suggests the mathematical necessity for
considering both positive and negative frequencies,
i.e., ±nω0. Fig. 22-6 is a plot of cn versus nω0 in the
instance where k has the value two. This assignment
forces the recurrent pulse train into being a square
wave with an average value of one-half. Such a plot
is termed a Fourier line spectrum as the frequencies
are discrete.
The line spectrum of the square wave recurrent
pulse displayed in Fig. 22-6 exhibits the average
value or dc term at zero frequency, the fundamental
components at ±ω0, and the characteristic odd
harmonics with alternating signs and diminishing
amplitudes according to the harmonic order.
Nothing is displayed beyond the fifth harmonic
because of diminishing scale even though all odd
harmonics are present in the actual spectrum.
Figure 22-5. Recurrent pulse train.
2π
2π
−π
π
ω0T
0
+1
ω0t
k
cn
1
2π
------
e jnθ
–
π
k---
–
π
k---
∫
dθ
=
c0
1
2π
------ π
k---
π
k---
+
⎝
⎠
⎛
⎞
1
k---
=
=
Figure 22-6. Fourier line spectrum of recurrent pulse as
a square wave.
cn
1
jn2π
–--------------- e
jn
–
π
k---
e
jnπ
k---
–
⎝
⎠
⎜
⎟
⎛
⎞
=
1
nπ
------
e
jnπ
k---
e
jn
–
π
k---
–
2j
---------------------------
×
=
1
k---
nπ
k---
⎝
⎠
⎛
⎞
sin
nπ
k---
--------------------
×
=
f t( )
1
k---
nπ
k---
⎝
⎠
⎛
⎞
sin
nπ
k---
--------------------e
jnω0t
×
n
∞
–
=
n
∞
=
∑
=
1
2
1
1
5π
−1
3π
π
−ω0
0
ω0

   
Signal Processing
483
22.1.3 Fourier Integral
Most of the signals of interest in acoustics and elec-
tronics are dynamic signals which do not repeat
themselves over and over. In other words, such
signals are not periodic yet it is still necessary, in
fact essential, to know the spectral content of such
signals. One way to approach the analysis of signals
that do not repeat themselves anywhere on the time
axis is to consider that the period of such signals is
infinite. To that end, the expressions for the anal-
ysis and synthesis employing the Fourier exponen-
tial series are recast in a form where time is taken as
the independent variable and the period appears
explicitly. These new expressions appear as Eq.
22-47 and Eq. 22-48.
(22-47)
(22-48)
where,
,
(22-49)
.
(22-50)
At first glance, we might conclude that if T is
allowed to approach infinity in Eq.22-47, that cn
approaches zero and all is lost. A way out is provided
if we also observe in Eq. 22-50 that as T approaches
infinity, ω0 must be shrinking and approaching zero.
In the integral expression of Eq. 22-47, if we now
substitute for T from Eq. 22-50 and then divide both
sides of the expression by ω0 ⁄ 2π, we obtain
(22-51)
As long as f (t) is reasonably well behaved such
that the integral does not diverge, the quantity Fn
will contain the information which is sought. The
corresponding synthesis expression can now be
written as
(22-52)
At this juncture, it is possible to determine what
happens when the period grows indefinitely large
such that in the limit it becomes infinite. As T grows
larger and larger, ω0 grows smaller and smaller and
it becomes an infinitesimal called dω. As ω0 grows
small, the harmonic frequencies designated by ωn
become so numerous and closely packed that they
become a continuum represented by the continuous
variable called ω. Additionally, instead of having a
discrete set of values Fn for each harmonic, one now
has a continuous function of frequency designated
by F(ω). Finally, in the limit of infinite T, the
infinite sum of discrete terms of Eq. 22-52 becomes
a continuous sum or integral. Finally then,
Eqs. 22-51 and 22-52 become
(22-53)
and
(22-54)
Eqs. 22-53 and 22-54 constitute the Fourier
transform and inverse Fourier transform, respec-
tively, applicable to time functions whether they are
periodic or not.
Not every conceivable f(t) has a Fourier trans-
form, i.e., the integral indicated in Eq. 22-53 may
not be calculable. Fortunately, for most of the
signals encountered in acoustics and communica-
tions, this is not the case and F(ω) can be calculated.
One of the many useful properties possessed by a
Fourier transform is that of uniqueness. This means
that if we can calculate the Fourier transform of a
given f (t) there is one and only one F(ω) associated
with this f  (t). In fact the F(ω) so calculated
embodies all of the information contained in f (t)
expressed in a different way. In the case of f (t), the
independent variable is time which is the variable
closest to the nature of human experience. In the
case of F(ω), the independent variable is angular
frequency and the domain of description is called
the frequency or spectral domain. Time and
frequency constitute two different descriptors of the
same physical phenomena. They are both useful in
acquiring a deeper understanding of the nature of
physical systems. In fact, the keys to the
cn
1
T---
f t( )e
jωnt
–
td
T
–
2
------
T
2---
∫
=
f t( )
cne
jωnt
n
∞
–
=
n
∞
=
∑
=
ωn
nω0
=
T
2π
ω0
------
=
cn
ω0
2π
------
------
Fn
≡
f t( )e
jωnt
–
td
T
–
2
------
T
2---
∫
=
f t( )
1
2π
------
Fne
jωnt
ω0
n
∞
–
=
n
+∞
=
∑
=
F ω
(
)
f t( )e jωt
–
td
∞
–
∞
∫
=
f t( )
1
2π
------
F ω
(
)e jωt ω
d
∞
–
∞
∫
=

484
Chapter 22
understanding of the nature of atomic structure were
extracted almost solely by studying the spectra of
the radiation emitted by excited atoms.
22.1.4 General Properties of Fourier Transforms
There are some properties common to all Fourier
transforms, knowledge of which can save much
labor in transform calculations. Physical signals are
generally real functions of time but the Fourier
transforms of such signals may be real or complex
depending on the mathematical structure of the time
signal. For example, if the time signal is real and an
even mathematical function of t, the Fourier trans-
form is also real and an even mathematical function
of ω. If f (t) is real and odd, then F(ω) is imaginary
and odd. If f (t) is real and neither even nor odd, then
F(ω) is complex.
A second useful property is that of time shift.
Suppose it is desired to shift the position of a given
time function f (t) on the time axis for a fixed amount
of time t0 such that f (t) is replaced by f(t – t0) indi-
cating the time function is shifted to the right by an
amount of time equal to t0 while the shape of the
function remains unchanged. Then if F(ω) is the
transform of f  (t), the transform of f  (t – t0) is
. A corollary to this property is that of
frequency shift. Suppose that the transform of f (t ) is
again F(ω). If one shifts the transform to the right
along the frequency axis by a fixed amount ω0 then
F(ω) becomes F(ω − ω0) and the time function of
which this is the transform becomes 
. A shift
to the left would be accomplished by a change in the
algebraic sign of the fixed quantity in both instances.
Additionally, the process of taking the Fourier
transform is a linear operation which allows one to
apply the principle of superposition. Suppose there
are two different time functions denoted as f (t ) and
g(t) which have transforms denoted as F(ω) and
G(ω) respectively. From f (t ) and g (t ) form a new
time function given by af (t ) + bg (t ) where a and b
are constants. As a result of the linearity property,
the transform of this new time function will be
aF(ω) + bG (ω).
Another useful property is associated with a
mathematical process known as convolution. This
process is a little trickier to describe as well as to
actually perform. The convolution process can be
performed in either the frequency or time domains.
In order to gain an understanding of the nature of the
process an example will be drawn from the field of
spectrum measurement. Suppose it is desired to
determine the shape of the spectrum produced by
some stationary signal source. Determining the
shape of the spectrum amounts to continuously iden-
tifying the values of the frequencies which are
present as well as the strength of the signal at each
value of the frequency. A stationary signal source
would be one whose spectrum does not change with
time and hence the measurement may be carried out
in a leisurely fashion.
One way of performing the measurement would
be to apply the signal to a tunable bandpass filter
and to plot the root mean square value of the output
of the filter as it is slowly tuned over the complete
range of all frequencies of interest. The shape of the
plotted results will depend not only on the actual
shape of the spectrum to be measured but also on the
shape of the tunable filter’s frequency response. For
example, at each frequency of tuning, the amount of
signal passed by the filter obviously depends on
whether the filter’s response curve is narrow or
broad, i.e., whether the filter Q is large or small. The
shape of the measured curve will be that of the
convolution of the actual spectrum with that of the
filter’s response function.
Convolution can be applied in either the time or
frequency domain. A detailed calculation will now
be presented in the time domain where time signals
of simple though reasonable geometric shapes can
be chosen so as to visualize easily what is being
done at each step of the process. Initially a mathe-
matical statement of the convolution process must
be made. Suppose one has two time functions
denoted as f (t ) and g(t ). The convolution of f (t )
with g(t ) is denoted and defined as
(22-55)
In Eq. 22-55, τ is a dummy variable having the
dimensions of time, which is integrated out
producing a result that is a function of t only. The
corresponding statement in the frequency domain
might appear as
(22-56)
In Eq. 22-56 k is the dummy variable that is inte-
grated out in the convolution process.
Fig. 22-7 depicts the shape of the two time func-
tions to be convolved in a geometrical illustration of
the convolution process.
The first step in describing the convolution
process geometrically is to flip the figure describing
g(t ) about the vertical axis. This figure will now
describe g (t – τ). It is the negative τ that dictates the
e
jω
–
(
)t0F ω
(
)
e jω0tf t( )
f t( ) ∗ g t( )
f τ
( )g t
τ
–
(
) τ
d
∞
–
∞
∫
≡
F ω
(
) ∗ G ω
(
)
F k
( )G ω
k
–
(
) k
d
∞
–
∞
∫
≡

   
Signal Processing
485
reversal. Next one positions the figure describing the
g function sequentially for all values of t. At each
value of t, the area where the two figures overlap is
calculated. This area of overlap is the result of the
integration over the dummy variable τ in the mathe-
matical definition of convolution. Values of t that do
not produce an overlap can be ignored. This is illus-
trated for several values of t in Fig. 22-8.
For t ranging between 0 and 1, the triangle will be
completely within the rectangle and the overlap area
will remain at a constant value of 0.5. The remaining
steps of the process are illustrated in Fig. 22-9.
The result of the convolution calculation is a new
function of time denoted by h(t). Mathematically,
(22-57)
For each value of t, the function h(t) has as its
value, the value of the area of overlap of the two
functions which are being convolved. The function
h(t) for the present example is drawn in Fig. 22-10.
The property of the Fourier transform which
makes the convolution of interest is that convolution
in the time domain is equivalent to multiplication in
the frequency domain. The meaning of this is as
follows. Let F(ω) be the transform of f (t) and G(ω)
be the transform of g(t). This being the case, then
the Fourier transform of the convolution of f (t) with
g(t) is simply F(ω) multiplied by G(ω). The
converse is also true. If we were to convolve F(ω)
with G(ω) in the frequency domain and then take the
inverse Fourier transform of the result, the resulting
calculation would be equal to the product of f (t)
with g(t) in the time domain.
There is an important theorem associated with
the Fourier transform which further illustrates the
equality between the time domain and frequency
domain descriptions. This is called Parseval’s
Theorem even though it was first expressed and
used by Lord Rayleigh. This is called an energy
theorem because it involves the integral with respect
to time of the square of a signal property such as
acoustic pressure. The acoustic power is propor-
tional to the square of the acoustic pressure and the
time integral of power leads to an expression of the
signal energy. The formal statement of the theorem
appears as Eq. 22-58.
(22-58)
In Eq. 22-58, the square of the absolute magni-
tude appears rather than simply just the square
because even though f (t) is real for physical signals
and the square of the absolute magnitude and the
simple square are equal for this function, F(ω) is
often complex and its simple square would be
complex whereas the square of its absolute
Figure 22-7. Functions to be convolved.
t
1
1
g(t)
−1
1
t
1
f(t)
h t( )
f t( ) ∗ g t( )
=
f τ
( )g t
τ
–
(
) τ
d
∞
–
∞
∫
=
Figure 22-8. Early steps in the convolution process.
t = −1
Area = 0
t = −0.8
Area = 0.02
Area = 0.08
Area = 0.18
Area = 0.32
t = −0.6
t = −0.4
t = −0.2
f t( ) 2 td
∞
–
∞
∫
1
2π
------
F ω
(
) 2 ω
d
∞
–
∞
∫
=

486
Chapter 22
magnitude is real and the result of this calculation
must always be real. It is often much easier to
perform the integral on the right rather than that on
the left and hence the utility of the theorem for finite
energy signals. The term |F(ω)|2 in Eq. 22-58 is
called the spectral density function in that it repre-
sents the energy per unit angular frequency.
Another significant property of the time and
frequency domain descriptions of a given signal
becomes apparent when one compares the duration
of a signal in the time domain with the frequency
interval occupied by the same signal expressed in
the frequency domain. In exploring this feature, an
example will be drawn from the examination of a
tone burst, which is a significant test signal
employed in both acoustics and electroacoustics. A
tone burst is formed by gating on a continuously
operating sinusoidal oscillator at a fixed frequency
for a time interval equal to an integral number of
periods of the oscillator signal. Fig. 22-11 displays
for an interval of one period the function | f (t)|2 from
Eq. 22-58 appropriate for a 1  kHz tone burst.
Fig. 22-12 displays the corresponding frequency
domain spectral density function for this tone burst.
It should be apparent from the figures that even
though the burst’s duration in the time domain is
well defined and limited to an interval of 1 ms, the
same cannot be said of the spectral density function.
The spectral density function is broadly spread out
over a range of frequencies. In fact, the positive and
negative frequency peaks of the spectral density do
not even occur at 1 kHz but rather at lower values.
Note the positions of the markers at ±1  kHz.
Contrast Fig. 22-12 with Fig. 22-13 which corre-
sponds to a tone burst of not one period but rather of
ten periods, that is, a duration in time larger by a
factor of ten.
Now the spectral density function is much better
defined and the peaks occur almost precisely at
±1kHz as evidenced by the markers. In addition to
being much narrower, the peaks are now much taller
Figure 22-9. Final steps in the geometrical calculation
of the convolution.
Figure 22-10. Convolution of f (t) with g(t).
t = 1.2
Area = 0.48
t = 1.4
Area = 0.42
Area = 0.32
Area = 0.18
Area = 0
t = 1.6
t = 1.8
t = 2.0
t
Result of Convolution
−1       −0.5        0         0.5         1         1.5        2
0.5
0.45
0.4
0.35
0.3
0.25
0.2
0.15
0.1
0.05
0
h(t)
Figure 22-11. 1 kHz tone burst for one period.
Tone Burst Power
0    0.1   0.2   0.3   0.4   0.5   0.6   0.7   0.8   0.9   1
Time ×10−3
1.0
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
Instantaneous Power

   
Signal Processing
487
as now the burst has delivered ten times the energy
of the former case and the area under the total curve
must also be ten times larger. This behavior results
from another general property of the time and
frequency domain descriptions of signals. This
property is sometimes referred to as the classical
uncertainty principle. Mathematically this can be
expressed as
(22-59)
The conclusion to be reached which is expressed in
this relationship is that if the frequency content of a
signal is to appear with precision, then the existence
of the signal and our observation of it must endure
for a long period of time. The converse is also true
in that if a signal exists for only a brief time, a
precise statement or measurement cannot be made
about its frequency content.
22.1.5 Unit Impulse
Ironically, oftentimes in physics and mathematics
progress in thinking about things that actually exist
in nature can be facilitated by thinking about things
that do not. A case in point is that of the unit
impulse. The physical thinking that led to the
concept of the unit impulse will be discussed in the
section on system theory. For the present purposes,
we will be satisfied initially in describing the unit
impulse by listing its mathematical properties.
Firstly, the unit impulse is denoted as δ(t ) where
(22-60)
Additionally, δ(t ) is such that
(22-61)
A corollary to Eq. 22-61 issues from the fact that
δ(t  ) vanishes everywhere except at the origin
therefore
(22-62)
Eq. 22-62 is true if and only if a is taken to be
any real number less than zero and b is taken to be
any real number greater than zero. One becomes
more comfortable with the above statements when
one considers the following. Imagine a rectangle
centered on the origin. This rectangle has a duration
along the time axis of W and a height along the
vertical or ordinate axis of H. Now, further imagine
that H always equals to 1 ⁄ W. Clearly, the area under
the rectangle being the product of H with W is unity.
Note also that this area is dimensionless. Now,
consider that the duration along the time axis, W,
becomes progressively smaller. When this occurs,
the height, H, becomes progressively larger in such
a way that the product of H with W remains
constantly at unity. In the limit as W goes to zero, H
goes to infinity with the product of H with W
remaining at unity. This limiting situation describes
the unit impulse δ(t ). A quantity that is zero every-
where except when the number in the parentheses,
in this instance t, is zero. At the point where the
number in the parentheses is zero, the impulse has
an infinite value while retaining a total area of one.
The area, of course, being given by the integral
expression of Eq. 22-61 or Eq. 22-62.
Figure 22-12. Spectral density function for a one period
burst of 1 kHz.
Figure 22-13. Spectral density function for a ten period
burst at 1 kHz.
Frequency in kHz
−3       −2                       0          1          2          3
0.35
0.3
0.25
0.2
0.15
0.1
0.05
0
−1
Spectral Energy Density
Tone Burst Energy Distribution
ΔtΔf 
1
≥
Frequency in kHz
−3       −2                       0          1          2          3
30
25
20
15
10
5
0
−1
Spectral Energy Density
Tone Burst Energy Distribution
δ t( )
0, when t
0
≠
(
)
=
δ t( )
∞, when t
0
=
(
)
=
δ t( ) td
∞
–
+∞
∫
1
=
δ t( ) td
a
0
<
b
0
>
∫
1
=

488
Chapter 22
Unit impulses may occur at points other than at
the origin. For example, suppose one needs to
describe a unit impulse that occurs at t = t0. This is
stated as δ(t – t0). The impulse is located at the posi-
tion where the number in the parentheses becomes
zero. In this instance, this occurs where t = t0. Also,
for this impulse location, Eq.22-62 becomes
(22-63)
One could in fact conceive of a function of time
denoted as s(t) that represents an infinite repetitive
pulse train of unit impulses. Let the repetition period
of this train be denoted as Ts. The expression for s(t )
is actually fairly simple.
(22-64)
where,
n is any integer.
For obvious reasons, unit impulses cannot be
represented on drawings made to scale. For graph-
ical purposes, bold arrows positioned appropriately
on the abscissa axis represent unit impulses. The
three cases just discussed might appear then as
displayed in Fig. 22-14.
Now that the mathematical formalism is in place,
it is time to see if something of interest can be done
with it. Consider some function of time f(t) that
might very well be the voltage signal at the output of
a microphone preamplifier. What does one obtain by
finding the area under the curve that represents the
product of f (t) with δ(t – t0)? In answering this ques-
tion, we first make a mathematical statement of the
problem with y representing the answer that is
sought.
(22-65)
Now f (t) is a physically generated signal. As
such, f (t) is always real, finite, and does not have
any exotic mathematical behavior. The chosen unit
impulse, however, is zero everywhere except at
t = t0. When t = t0, f (t ) has the value f (t0) with f (t0)
being the output voltage of the microphone pream-
plifier at the instant in time equal to t0. Mathemati-
cally, the voltage at the instant t0 is just a constant so
Eq. 22-65 can be written in the form
(22-66)
In words, the area under the product curve of f (t)
with a unit impulse located at the instant of time t0 is
just the value of the given function of time at the
particular instant t0. The application of the unit
impulse in this manner to the continuously time
varying signal at the preamplifier output has sifted
out or sampled the particular value that exists at the
instant in time when t is equal to t0. Suppose now
one desires to sample the microphone preamplifier’s
output periodically with a sampling period Ts or a
sampling frequency fs = 1/Ts. Analytically, this can
be stated as
(22-67)
where,
n is any integer.
Figure 22-14. Various unit impulse depictions.
δ t
t0
–
(
) td
t
t0
<
t
t0
>
∫
1
=
s t( )
δ t
nTs
–
(
)
n
∞
–
=
n
+∞
=
∑
=
Ts
t0
Impulse at origin
Impulse at t0
Train of impulses
y
f t( )δ t
t0
–
(
) td
∞
–
+∞
∫
=
y
f t( )δ t
t0
–
(
) td
∞
–
+∞
∫
=
f t0
(
)δ t
t0
–
(
) td
∞
–
+∞
∫
=
f t0
(
)
δ t
t0
–
(
) td
∞
–
+∞
∫
=
f t0
(
)
=
y nTs
(
)
f t( )δ t
nTs
–
(
) td
−∞
+∞
∫
n
−∞
=
n
+∞
=
∑
=
f nTs
(
)
n
−∞
=
n
+∞
=
∑
=

   
Signal Processing
489
This process is called periodic impulse sampling.
The results of Eq. 22-67 can also be presented
graphically at least for a finite number of samples.
This is done in Fig. 22-15 wherein are displayed
three graphs representing the signal to be sampled,
the sampling impulse train, and the sampled results,
respectively. The sampled points are exaggerated for
ease in viewing.
In viewing Fig. 22-15 it should be noted that the
time coordinate of each sample matches that of the
corresponding sampling impulse while the ordinate
or value of the sample is that of the continuous
signal at the instant of sampling.
22.1.6 Spectrum of a Periodic Impulse Sampled 
Signal
What we refer to as the spectrum of a time depen-
dent signal is the description of that signal in terms
of frequency rather than in terms of time. One
obtains the spectrum of a time dependent signal by
calculating its Fourier transform through the appli-
cation of Eq. 22-53.
On the other hand, if one has on hand a detailed
knowledge of a signal’s spectrum then it is possible
to calculate the time dependence of the signal by
calculating the inverse Fourier transform as
prescribed in Eq. 22-54. The time signal f (t ) and its
spectrum F(ω) constitute a Fourier trans-
form-inverse Fourier transform pair and are
compactly denoted as
(22-68)
In order to determine the spectrum of a periodic
impulse sampled signal we will require just a few
more tools. Firstly, let us calculate the Fourier trans-
form or spectrum of a unit impulse. An application of
Eq. 22-53 to a unit impulse in the time domain yields
(22-69)
In Eq. 22-69, Δ(ω) represents the Fourier trans-
form of δ(t) and the second line is justified because
the integrand is zero everywhere except at the origin
where the exponential term is a constant equal to
one. The result is that the spectrum of the unit
impulse is a constant independent of ω. This means
that all frequencies appear in this spectrum to
exactly the same degree. The spectrum is flat.
Furthermore, as Δ(ω) is purely real, all frequency
components have zero phase. This is an example of
a limiting case expressed in the uncertainty principle
of Eq. 22-59 where the duration in time has tended
to zero forcing the bandwidth to become infinite. In
conclusion then,
(22-70)
Suppose, however, that the unit impulse is
located at t0 rather than at the origin. The result in
this case can be obtained by direct calculation of
course but it is not necessary to do so. One can make
use of the general time shift property of Fourier
transforms. A time shift to the right of an amount t0
Figure 22-15. An example of impulse sampling.
Ts
Train of impulses
Signal to be sampled
Sampled signal
f t( )
F ω
(
)
⇔
Δ ω
(
)
δ t( )e jωt
–
td
∞
–
∞
∫
=
e jω0
–
δ t( ) td
∞
–
∞
∫
=
1
δ t( ) td
∞
–
∞
∫
=
1
=
δ t( )
1
⇔

490
Chapter 22
in the time domain simply multiplies the original
transform by 
 This being the case,
(22-71)
This spectrum is still flat as the magnitude is still
unity but now there is a frequency dependent phase
ϕ = −ωt0. Thus the spectrum is now complex. This
is an example of another general property of Fourier
transforms in that the impulse being located only on
the positive time axis means that the time function is
neither even nor odd leading to a transform that is
complex.
Unit impulses may be multiplied by constants
having both numerical value as well as dimensions.
In such an instance the impulse is said to have a
strength equal to the numerical value of the constant
and the product acquires the dimensions of the
constant as well. For example, if the constant is k,
then Eq. 22-70 and Eq. 22-71 would become
(22-72)
The concept of impulse can be carried over to the
frequency domain as well. In this application, the
independent variable is angular frequency rather
than time while the mathematical properties of the
unit impulse are unchanged. An impulse located at
the origin of coordinates is symbolized as δ(ω). An
impulse located at a fixed angular frequency ω0
would be written as δ(ω − ω0). An infinite sequence
of impulses with a constant separation could be
denoted as
where,
n is any integer.
These impulses are described graphically in
Fig. 22-16.
We are now in position to calculate the expres-
sions in the time domain that correspond to the
above spectra in the frequency domain. This is done
by applying in turn Eq. 22-54 to each of the above
spectra.
For the impulse at the origin
(22-73)
For the displaced impulse at ω0
(22-74)
Finally, for the infinite train of impulses
(22-75)
In summary, the Fourier transform-inverse
Fourier transform pairs are respectively
(22-76)
(22-77)
(22-78)
e jωt
–
0.
δ t
t0
–
(
)
1e
jωt0
–
⇔
kδ t( )
k
⇔
kδ t
t0
–
(
)
ke
jωt0
–
⇔
δ ω
nω0
–
(
)
n
∞
–
=
n
+∞
=
∑
Figure 22-16. Impulses in the frequency domain.
ω0
Impulse at Origin
Impulse at ω0
Train of Impulses
ω0
f t( )
1
2π
------
δ ω
(
)e j0t ω
d
∞
–
+∞
∫
=
1
2π
------e j0t
=
1
2π
------
=
f t( )
1
2π
------
δ ω
ω0
–
(
)e jωt ω
d
∞
–
+∞
∫
=
1
2π
------e
jω0t
=
f t( )
1
2π
------
δ
n
∞
–
=
n = +∞
∑
ω
nω0
–
(
)e jωt ω
d
∞
–
+∞
∫
=
1
2π
------
e
jnω0t
n
∞
–
=
n
+∞
=
∑
=
1
2π
------
δ ω
(
)
⇔
1
2π
------e
jω0t
δ ω
ω0
–
(
)
⇔
1
2π
------
e
jnω0t
n
∞
–
=
n
+∞
=
∑
δ
n
∞
–
=
n
+∞
=
∑
ω
nω0
–
(
)
⇔

   
Signal Processing
491
The sampling signal s(t) of Eq. 22-64 is a peri-
odic pulse train of period Ts with a fundamental
frequency fs = 1⁄  Ts and an attendant angular
frequency ωs = 2πfs. This being the case, s(t ) can
also be written in the form of the Fourier exponen-
tial series of Eq. 22-37 with ωs replacing ω0.
(22-79)
where,
(22-80)
In writing Eq. 22-80 we have made use of the fact
that the integration need be carried out only over one
period of the periodic signal. Our periodic sampling
signal s(t ) is an even function of time so we have
chosen the interval of integration to straddle the
origin. This choice makes the coefficient calculation
quite simple. The sampling signal in this time
interval need be represented by only the unit impulse
at the origin hence, for all n Eq. 22-80 becomes
(22-81)
As a consequence, we now have two equivalent
forms for representing s(t ) as expressed in
(22-82)
We are now in position to determine the spec-
trum or Fourier transform of the sampling signal.
We will do so by first noting that because of
linearity the transform pair in Eq. 22-78 can be
scaled by any constant factor. Furthermore ω0 can
be identified as ωs as they are simply constants. A
rescaling of the pair in Eq. 22-78 by a multiplying
factor 2π ⁄ Ts and replacing ω0 by ωs results in
(22-83)
Now note that on the left side of the arrow in
Eq. 22-83 is just the sampling signal itself while the
expression on the right side is its Fourier transform
or spectrum. Stated in formal terms
(22-84)
Finally, Eq. 22-83 could equally as well be written as
(22-85)
In words, the spectrum of an infinite sequence of
uniformly spaced unit impulses in the time domain
is an infinite sequence of uniformly spaced impulses
of strength 2π ⁄ Ts in the frequency domain. The
spacing in the two domains is related through Ts
being equal to 2π ⁄ ωs. Fig. 22-17 illustrates the spec-
trum of the sampling signal.
We require just one more tool in order to accom-
plish the goal of this section. Reference was made to
this tool earlier while discussing the process of
s t( )
δ
n
∞
–
=
n
+∞
=
∑
t
nTs
–
(
)
=
cne
jnωst
n
∞
–
=
n
+∞
=
∑
=
cn
1
Ts
-----
s t( )e
jnωs
–
t
−Ts
2
----------
+Ts
2
---------
∫
dt
=
cn
1
Ts
-----
δ t( )e
jnωs
–
t
−Ts
2
----------
+Ts
2
---------
∫
dt
=
1
Ts
-----
δ t( )e
jnωs0
–
−Ts
2
----------
+Ts
2
---------
∫
dt
=
1
Ts
-----
=
s t( )
δ
n
∞
–
=
n
+∞
=
∑
t
nTs
–
(
)
=
1
Ts
-----
e
jnωst
n
∞
–
=
n
+∞
=
∑
=
Figure 22-17. The spectrum S(ω) of the sampling signal
s(t).
1
Ts
-----
e
jnωst
n
∞
–
=
n
+∞
=
∑
2π
Ts
------
δ
n
∞
–
=
n
+∞
=
∑
ω
nωs
–
(
)
⇔
S ω
(
)
s t( )
∞
–
+∞
∫
e jωt
–
dt
=
2π
Ts
------
δ
n
∞
–
=
n
+∞
=
∑
ω
nωs
–
(
)
=
δ t
nTs
–
(
)
n
∞
–
=
n
+∞
=
∑
2π
Ts
------
δ
n
∞
–
=
n
+∞
=
∑
ω
nωs
–
(
)
⇔
S(ω)
2π
Ts
−3ωs
3ωs
2ωs
1ωs
−1ωs
ωs
−2
0
ω

492
Chapter 22
convolution. This tool is known as the Frequency
Convolution Theorem of Fourier transforms. This
theorem states that given two functions of time, say
f(t ) and g(t ), with the Fourier transform of f (t )
being F(ω) and that of g(t ) being G(ω), then the
Fourier transform of the product of f (t ) with g(t ) is
given by the convolution of F(ω) with G(ω) divided
by 2π. Expressed in the concise language of mathe-
matics,
(22-86)
For the present case of interest, which involves
sampling the signal at the output of the microphone
preamplifier, the product at the left of Eq. 22-86 is
f(t ) with s(t ). In this instance we are taking f (t ) to
be the continuous time description of the micro-
phone signal of interest and s(t ) to be the periodic
impulse train of Eq. 22-82. Following the pattern of
Eq. 22-86 then, the Fourier transform or spectrum of
this product, which we denote as Fs(ω), will be
given by
(22-87)
F(ω) is of course the Fourier transform of f (t )
and is unknown unless one specifies what particular
sounds the microphone is being exposed to. Rather
than look at the results for a specific case, it is much
more meaningful to consider a generic microphone
signal spectrum that might serve as a bounding one
for audio signals. Audible audio signals can and do
extend to quite low frequencies so to be on the safe
side one might consider the lower limit of the spec-
trum to be zero. Furthermore, the most energetic
signals occur in the range of 500 Hz and below
while the strength above 500 Hz usually diminishes
as the frequency increases and is practically zero
beyond 20 kHz. The audible audio spectrum is thus
naturally band limited even when artificial limits are
not imposed. This being the case, a generic F(ω)
might appear as in Fig. 22-18 where ωm represents
the maximum angular frequency at the upper limit.
With F(ω) now at hand, it is at last possible to
determine the spectrum of the sampled microphone
signal by invoking Eq. 22-87. Remember that in the
convolution process one basically sweeps one func-
tion over the other while at each step in the process
one calculates the area under the product curve in
the region of overlap of the two functions. Graphi-
cally then we are sliding the train of impulse func-
tions of Fig. 22-17 across the spectrum of
Fig. 22-18. At each of the points of overlap, the
impulses simply replicate and scale F(ω), producing
the final result displayed in Fig. 22-19.
The spectrum of the impulse sampled signal,
Fs(ω), is probably a surprising result in that it
contains not only a scaled version of the spectrum of
the continuous microphone signal but also an infi-
nite number of replications uniformly spaced at inte-
gral multiples of the sampling angular frequency. At
this point it would be reasonable to consider what
step or steps must be taken to extract from Fs(ω) just
the spectrum of the original microphone signal
itself, that is, F(ω). The answer is supplied in
Fig. 22-20 where an ideal low pass filter with a
cutoff angular frequency slightly greater than ωm
and a scaling factor of Ts is applied to the spectrum
Fs(ω). The spectrum so filtered is just F(ω).
f t( )g t( )
1
2π
------F ω
(
)* G ω
(
)
⇔
Fs ω
(
)
1
2π
------F ω
(
)* S ω
(
)
=
1
2π
------F ω
(
)* 2π
Ts
------
δ
n
∞
–
=
n
+∞
=
∑
ω
nωs
–
(
)
=
Figure 22-18. Spectrum of a generic audible audio
signal.
Figure 22-19. Spectra involved in the convolution as
well as the result.
F(ω)
−ωm
ωm
ω
0
S(ω)
2π
Ts
−3ωs
3ωs
2ωs
1ωs
−1ωs
ωs
−2
0
ω
F(ω)
−ωm
ωm
ω
0
Fs(ω)
Ts
−3ωs
3ωs
2ωs
1ωs
−1ωs
ωs
−2
0
ω
1

   
Signal Processing
493
Fig. 22-20A depicts the response of the required
low pass filter. Remember that the Fourier descrip-
tion of a low pass filter involves both positive and
negative frequencies and hence the filter is symmet-
rical about the origin. Fig. 22-20B is the spectrum of
the impulse sampled signal while Fig. 22-20C is the
result of the filtering process and is the same as the
spectrum of the original microphone signal. This
spectrum contains all of the information of the orig-
inal continuous time dependent signal f(t) and
nothing has been lost as a result of the sampling
process when carried out as prescribed above.
22.1.7 Sampling Theorem
A visual inspection of Fig. 22-20 should indicate
that the sampling angular frequency ωs is consider-
ably more than twice the maximum angular
frequency in the program material ωm. The spacing
is sufficiently large, in fact, that an ideal filter is not
required to perform the recovery. This fact is illus-
trated in Fig. 22-21.
Fig. 22-21A depicts the sampled spectrum with
the response of a physically realizable or real filter
superimposed about the portion of the spectrum to
be recovered while Fig. 22-21B illustrates the
results of the recovery. The cogent property of a real
filter illustrated here is that such a filter possesses a
finite attenuation rate or slope at the pass band edge.
An ideal filter, of course, would have an infinite
slope at the pass band edge.
One might very well reason after viewing
Fig. 22-20 and Fig. 22-21 that with the aid of an
ideal filter, operation would be possible with
ωs = 2ωm. This situation is presented in Fig. 22-22.
Upon reviewing Fig. 22-22 the first guess might
be that the ideal filter would allow recovery of just
the central spectrum alone and successful operation
would be possible when the sampling frequency is
just twice the maximum frequency in the original
time dependent signal of interest. This, however, is
not the case as is evident from the following illustra-
tion taken from the time domain.
Figure 22-20. Recovery of original spectrum.
S(ω)
Ts
ω
F(ω)
−ωm
ωm
ω
0
Fs(ω)
Ts
−3ωs
3ωs
2ωs
1ωs
−1ωs
ωs
−2
0
ω
1
A. Low Pass Filter Response.
B. Spectrum to be Filtered.
C. Filtered Result.
Figure 22-21. Recovery with a real filter is possible
when ωs is sufficiently large.
Figure 22-22. Spectra appearance when ωs = 2ωm .
F(ω)
−ωm
ωm
ω
0
Fs(ω)
Ts
−3ωs
3ωs
2ωs
1ωs
−1ωs
ωs
−2
0
ω
A. Spectrum to be Filtered.
B. Filtered Result.
Real Recovery Filter
F(ω)
−ωm
ωm
ω
0
Fs(ω)
Ts
−3ωs
3ωs
2ωs
1ωs
−1ωs
ωs
−2
0
ω
B. Sampled Spectrum.
Ideal Recovery Filter
A. Original Spectrum.
Ts
1

494
Chapter 22
In Fig. 22-23 the signal is a sinusoid with a
frequency of 20 kHz. The sampling frequency itself
is set at precisely 40 kHz so that two samples are
taken during each period of the signal. In the situa-
tion depicted in the figure, the sampling signal is in
phase with the signal to be sampled so that the
samples are taken at the zero crossings of the signal
of interest. In this instance, then, all of the samples
are zero and nothing of value is learned about the
signal. Clearly, such a sampling process could never
lead to the recovery of the original signal from the
sampled values.
After examination of the foregoing examples we
are now in position to state the Sampling Theorem.
In simple terms the Sampling Theorem states that if
a continuous time signal is band limited to a
maximum frequency fm, then the continuous time
signal can be uniquely determined from a uniformly
spaced sequence of samples taken at a rate greater
than twice fm. In short, fs > 2fm. The corresponding
angular frequencies are of course just 2π times these
values.
22.1.8 Aliasing
Aliasing is a phenomenon that occurs whenever the
sampling frequency is less than twice the maximum
frequency in the sampled spectrum. That is, fs < 2fm.
Here we are using the actual frequencies rather than
the angular frequencies for the sake of clarity. Most
of us first experience this phenomenon when
viewing western movies that feature stagecoaches or
wagons in motion. Conventional 35  mm sound
movies are made up of sampled data sequences
consisting of individual pictures or frames made at
the rate of 24 frames per second (fps). As long as the
spoked wheels are rotating slowly so that the spokes
pass a reference point at a rate that is less than one-
half of the frame rate, the spoke motion appears to
be consistent with the linear translation of the
vehicle. Once the spoke rate exceeds one-half of the
frame rate, the spoke motion appears to be too slow
as compared with the linear translation. In this
instance, then, the spokes appear to be advancing at
a lower rate or frequency than required to account
for the vehicle motion.
In fact, when the spoke rate is first equal to the
frame rate, the spokes appear to be standing still
while the vehicle is moving at a good clip. As if this
is not bad enough, when the spoke rate first exceeds
the frame rate, the rotation of the spokes appears to
be in the opposite direction than that required to be
consistent with the vehicle motion! As a small child
and a big western movie fan, this bothered me no
end as I saw moving spoked vehicles every day in
real life and this phenomenon did not occur. This
same phenomenon occurs while observing rotating
machinery with the aid of a strobe light. In this
instance, however, the strobe frequency is usually
adjusted to make the rotational motion to appear to
stand still or move at a slow rate.
Aliases are frequency components not present in
the original signal that are generated whenever the
sampling frequency is less than twice the maximum
frequency that appears in the original signal.
Fig. 22-24 displays a portion of a sampled spectrum
where this is the case.
The situation depicted in Fig. 22-24 results when
the sampling frequency is too low. In this instance
the replica spectra overlap their nearest neighbors as
indicated by the shaded regions in the figure. The
regions in which aliasing occur are given by
(22-88)
where,
n is ±1, ±2, ±3, etc.
The portion of the spectrum that spans between
±fm is the region occupied by the original signal.
Aliases occurring anywhere in this region prevent
the recovery of an undistorted version of the original
signal through simple filtering techniques. Aliasing
details are best presented through a numerical
example.
Figure 22-23. Time domain when ωs = 2ωm.
2.0
1.5
1.0
0.5
0
−0.5
−1.0
−1.5
−2.0
−1 −0.8 −0.6 −0.4 −0.2 0 
0.2 0.4 0.6 0.8 1
t–s
*
*
*
*
*
*
*
*
*
Figure 22-24. Aliasing occurs in the shaded regions.
Sampled Spectrum
−3fs
−2fs
−fs
3fs
2fs
fs
0
f
f
nfs  fm
±
=

   
Signal Processing
495
Fig. 22-25 displays only the positive frequency
axis because of space considerations. The situation
on the negative frequency axis is just the mirror
image of what is displayed in the figure. Addition-
ally, there is room in the figure for only one replica
spectrum centered about the sampling frequency of
25  kHz. The original spectrum which is often
referred to as the baseband spectrum in communica-
tion work is centered on the origin and extends from
−20 kHz to +20 kHz with only the positive portion
appearing in the figure. Aliasing occurs in the region
between 5  kHz and 20  kHz. The sloping line
indicated by the lone arrow represents information
associated with the high frequency region of the
replica spectrum, in fact that region between
12.5kHz and 20 kHz. Note, however, that it falls
between 12.5 kHz and 5 kHz in the baseband spec-
trum. Specifically, 20 kHz in the replica appears as
5kHz in the baseband. In other words 20 kHz is
aliased or masquerades as 5 kHz and would appear
as 5 kHz in the recovery process. Similarly, 19 kHz
would appear as 6 kHz, 18 kHz would appear as
7kHz, etc. until the foldover frequency of fs ⁄ 2 or
12.5 kHz is reached.
Beyond the foldover frequency, the progression
just reverses until 20 kHz is reached. Any attempt to
recapture the entire baseband spectrum will involve
a filter that extends to 20kHz or slightly beyond and
hence will include the alias region. If one compares
such a recovered spectrum with the original, it will
be found that the shape of the spectrum will be
highly distorted from 5 kHz and beyond. All of this
is avoided by satisfying the conditions set forth in
the Sampling Theorem. If one is at liberty to select
the sampling frequency, one simply samples at a rate
greater than twice the value of the maximum
frequency in the program material.
The answer to the question of how much greater
hinges on the sharpness of the available recovery
filter with low order recovery filters requiring higher
sampling frequencies. The situation might be,
however, that the sampling frequency is beyond
one’s control. In this instance the program material
to be sampled must be band limited by what is
called an anti-alias filter to a frequency maximum
less than one-half of the available sampling
frequency. Here the answer to the question of how
much less depends on the sharpness of the available
anti-alias filter. Anti-alias filters are almost univer-
sally employed whether needed in principle or not to
guard against possible high frequency noise pollu-
tion of the program material to be sampled.
22.1.9 Realistic Sampling
Man-made sampling pulses and techniques fall short
of the theoretical ideal of the unit impulse. Fortu-
nately, this does not invalidate the Sampling
Theorem or the general conclusions that stem from
the Sampling Theorem. When one employs an accu-
rate mathematical description of the actual
man-made periodic sampling pulses employed the
results and conclusions follow the general outline of
the ideal case presented in the foregoing develop-
ment of sampling. There are some differences of
course in the mathematical details, none of which
are debilitating. As an example of a realistic
sampling technique we will examine the details
associated with a process known as sample and
hold. This is an often employed technique particu-
larly where it is desired to convert the analog
samples into a quantized format that is subse-
quently encoded into a digital word through a
process known as pulse code modulation or PCM.
Fig. 22-26 is an example of a typical sample and
hold circuit.
The switch S in the circuit of Fig. 22-26 is actu-
ally a logic operated electronic switch that is briefly
closed and then opened at the beginning of the
sampling period. While the switch is closed the
capacitor is charged to a voltage equal to the signal
voltage. The capacitor holds this voltage after the
switch opens for the remainder of the sampling
period while the buffer amplifier supplies this same
voltage to subsequent circuitry and isolates the hold
capacitor. The waveform at the output is of the form
of a staircase with the elevations of the steps corre-
sponding to the values of the signal voltage at the
Figure 22-25. Aliasing details.
Figure 22-26. Sample and hold circuit.
5      10    15     20    25    30     35    40    45
f –kHz
fs
C
S
In
Out
+
−
+
−

496
Chapter 22
respective instants of sampling. The time domain
behavior of this process is displayed in Fig. 22-27.
From a mathematical standpoint, the staircase
time domain signal of Fig. 22-27 is given by the
convolution of a unit amplitude rectangular pulse of
width Ts with the periodic impulse sampled signal of
Eq. 22-67. If we denote the pulse waveform as p(t ),
then p(t ) is described by
(22-89)
Formally, the staircase time domain behavior
denoted as fh(t ) is given by
(22-90)
The quantity of interest however is not fh(t ) but
rather its Fourier transform Fh(ω). Fh(ω) is the spec-
trum of the sample and hold signal. Knowledge of
this spectrum is needed in detail in order to formu-
late techniques for recovering the spectrum of the
original unsampled signal. From Eq. 22-90, fh(t ) is
given by the convolution of two functions of time.
Recall that the Fourier transform of the convolution
of two time functions is simply the product of the
transforms of the individual time functions. Fh(ω)
can be calculated by taking the product of the
Fourier transform of p(t ) with the Fourier transform
of the infinite sum of Eq. 22-90. This latter trans-
form is just the spectrum Fs(ω) as displayed in
Fig. 22-19 and expressed in Eq. 22-87.
(22-91)
The calculation of the Fourier transform of p(t ) is
quite straightforward.
(22-92)
Now, if one factors the term 
 from the
last expression of Eq. 22-92 and employs the expo-
nential identity for the sine function, then Eq. 22-92
becomes
(22-93)
It should be apparent from Eq. 22-93 that the
spectrum of the unit amplitude pulse is complex.
This pulse is a real function existing only on the posi-
tive time axis and hence is not an even or an odd
function. For such functions, the Fourier transform is
complex having both a magnitude as well as a phase.
The phase behavior is linear and describes a pure
time shift along the positive t axis of an amount Ts ⁄ 2.
This in effect accounts for the fact that the pulse does
not symmetrically straddle the origin but rather
begins immediately to the right of the origin. The
magnitude of the spectrum is the pulse duration
multiplied by the absolute value of a sinc function,
that is a function of the form sin(x) ⁄ x. With both
P(ω) and Fs(ω) at hand we can at last write an
Figure 22-27. Time domain behavior of sample and
hold.
Signal to be Sampled.
Sampling Instants
Ts
Held Signal.
p t( )
1  when 0
t
Ts
< <
,
=
p t( )
0  when t
Ts
>
,
=
fh t( )
p t( )*
f nTs
(
)
n
∞
–
=
n
+∞
=
∑
=
Fs ω
(
)
1
Ts
-----
F ω
nωs
–
(
)
n
∞
–
=
n
+∞
=
∑
=
P ω
(
)
p t( )e jωt
–
td
∞
–
+∞
∫
=
1e jωt
–
td
0
Ts
∫
=
1
e
jωTs
–
–
jω
-----------------------
=
e jω
–
Ts 2
⁄
(
)
P ω
(
)
Ts
ωTs
2-----
⎝
⎠
⎛
⎞
sin
ωTs
2-----
----------------------- e
jω
–
Ts
2-----
=

   
Signal Processing
497
expression for the spectrum of the sample and hold
signal.
(22-94)
Fig. 22-28 displays Fs(ω) as overlaid by the
magnitude of P(ω). The product of these two curves
describes Fh(ω).
The two components displayed in Fig. 22-28
consist of the spectrum that would be produced by a
pure unit impulse sampling of our original audio
signal and the spectrum associated with the unit
amplitude hold pulse. The spectrum of our original
audio signal resulting from sampling by means of the
sample and hold process is given by the point-
by-point product of the two component curves. The
magnitude of the sinc function beneficially attenu-
ates the repeated replicas but at the same time also
alters the shape of the baseband spectrum.
A viable low pass filter intended for baseband
spectrum recovery must accomplish two things. It
must remove or seriously attenuate the replica
spectra that appear at multiples of the sampling
frequency and it must compensate for the attenua-
tion introduced by the sinc function throughout the
baseband region. This means that the recovery filter
must have just the inverse response of the sinc func-
tion in the frequency region between minus and plus
the maximum frequency of the original audio signal.
Beyond the frequency range of the baseband spec-
trum the recovery filter must further remove the
remaining remnants of the replica spectra.
Fig. 22-29 displays the distorted shape of the
baseband spectrum resulting from the hold opera-
tion. The recovery filter corrects this distortion. The
response of the recovery filter is tailored to match
the inverse of the sinc function spectrum over the
range between ±fm. Beyond the baseband frequency
range the recovery filter furnishes simple attenua-
tion. In the example at hand, fm is one-third of the
sampling frequency fs. It should be noted that in this
case as well as in the previous examples the draw-
ings have been made with linear rather than with
logarithmic axes. In all instances some license has
been taken in making the drawings in that the
spectra do not attenuate to zero but rather to some
negligibly small value.
22.2 Analog to Digital Conversion
In the foregoing discussion the emphasis has been
on the spectral characteristics of the sampling
process and the steps that must be taken in order to
recover the original continuous time dependent
signal from the sampled sequence. There is no prac-
tical reason to perform sampling followed by imme-
diate recovery other than perhaps as an exercise.
The collection of a sampled data sequence is a
precursor to encoding the information so gathered
into a form that can be recognized and processed by
computer circuitry. From a mathematical point of
view computer circuitry is based upon the two
valued logic system and algebra of George Boole
(1815-1864). The number system that lends itself
naturally to computer operations is the binary or
modulus two system. Analog audio signals vary
continuously between a negative minimum and
positive maximum with the difference between
these two values constituting a peak to peak value or
range. One of the first considerations that must be
made in the encoding process is the designation of
the least change in the sampled value that is to be
recognized by the encoding scheme. This least
change sets the numerical precision or quantization
of the encoded signal. Precision in a quantity
expressed with any modulus hinges on the range, the
modulus, and the number of bits involved. Denoting
the precision or quantization by Δ, the range by Vpp,
the modulus by M, and the number of bits by n, the
relationship is
Figure 22-28. The sample and hold spectrum is the
product of the two curves.
Fh ω
(
)
Ts
ωTs
2-----
⎝
⎠
⎛
⎞
sin
ωTs
2-----
----------------------- e
jω
–
Ts
2----- 1
Ts
-----
F ω
nωs
–
(
)
n
∞
–
=
n
+∞
=
∑
=
−2fs
−fs
2fs
fs
0
Figure 22-29. Recovery filter response and baseband
spectrum after sample and hold.
−1.0  −0.8  −0.6  −0.4  −0.2     0     0.2   0.4    0.6    0.8    1.0
f ⁄ fs
1.2
1
0.8
0.6
0.4
0.2
0
Magnitude

498
Chapter 22
(22-95)
An explanation of Eq. 22-95 and a brief review
of the formalism of expressing quantities in any
number base are perhaps worthwhile. The concept
of positional notation is presented in Table 22-1.
The table is divided into two parts by the radix
point. The region to the left of the radix point repre-
sents whole numbers while that to the right repre-
sents fractional numbers. In the most familiar
decimal system M = 10 and the positions to the left
of what is now the decimal point have weighting
factors that are progressively 100 = 1, 101 = 10,
102 = 100, and 103 = 1000. To the right the
weighting factors are progressively 1/10, 1/100,
1/1000, and 1/10,000. If then the entries in the
second row of the table were 1234.4321, the quan-
tity so represented actually means 1 × 1000 plus
2 × 100 plus 3 × 10 plus 4 × 1 plus 4/10 plus 3/100
plus 2/1000 plus 1/10,000. In the decimal system the
column positions are called digit positions with the
most significant digit being on the extreme left. In
general, the numeric entry in any column can take
on any value from zero through M − 1. Now in the
binary or base two system, M = 2 and the entries in
any column can only be 0 or 1. The column posi-
tions are now called the bit positions with the most
significant bit again being on the extreme left. If the
entries in the second row of the table were
1010.0101, the quantity represented would be 1 × 8
plus 0 × 4 plus 1 × 2 plus 0 × 1 plus 0 ⁄ 2 plus 1 ⁄ 4
plus 0 ⁄ 8 plus 1 ⁄ 16. The rule governing the structure
of the position table is that for any given position the
weighting factor is M times as great as that of the
position to the immediate right of the given position.
Eq. 22-95 is structured so that the position rule is
always satisfied when employing a limited numeric
code to cover a given range of values. In such an
instance the quantization or Δ is the value of the
smallest increment associated with the code. In the
case of binary codes Δ is the value represented by
the least significant bit. Let us examine a simple
example. Suppose that we encode a voltage range
from 0 to 1.6 V by employing a four bit binary code.
In this instance Δ will be 1.6 V divided by 24 or
1.6/16 = 0.1 V. The coded values might reasonably
be those of Table 22-2.
Several observations may be made from exam-
ining the table. The step size is indeed 0.1 V and the
positional rule is indeed satisfied in that the code
1000 represents eight increments, 0100 represents
four increments, 0010 represents two increments,
and 0001 represents one increment. A four bit
binary code possesses 16 unique combinations of 1s
and 0s and hence has 16 levels including the zero
level. In general, however, there are only 2n − 1
steps, in this case 15, so that the largest value repre-
sented by such a code is always the top of the range
less one least significant bit. The step size here is
coarse because of the small number of bits. A
sixteen bit code would have produced a step size of
about 24 microvolts (μV) for the same voltage range.
Audio signals of an electrical nature are electric
analogs of acoustic pressure and as such are intrinsi-
cally bipolar. The coding scheme selected for
portraying such signals must retain both algebraic
sign and magnitude behavior. At first glance one
might consider dedicating one bit to indicate the
algebraic sign with the remaining bits being devoted
to magnitude. When this is done the most significant
bit is usually employed as the sign bit. Such a
scheme is viable but does have a serious short-
coming as we shall see.
The most popular signed code employed by
microprocessors in performing arithmetic operations
is called two’s complement binary. The two’s
complement of a given binary number is obtained
by first taking the one’s complement of the given
binary number and then adding one to it. The one’s
complement of a binary number is obtained by
complementing each bit of the binary number.
Table 22-1. Positional Notation Table
M3
M2
M1
M0
•
M-1
M-2
M-3
M-4
_
_
_
_
_
_
_
_
Δ
Vpp
M n
--------
=
Table 22-2. Binary Codes Versus Volts
Binary Code
Volts
0000
0
0001
0.1
0010
0.2
0011
0.3
0100
0.4
0101
0.5
0110
0.6
0111
0.7
1000
0.8
1001
0.9
1010
1.0
1011
1.1
1100
1.2
1101
1.3
1110
1.4
1111
1.5

   
Signal Processing
499
Suppose the original decimal number is +7. The
normal binary statement with a four bit code would
be 0111. The one’s complement is obtained by
changing each zero to a one and each one to a zero
to obtain 1000. The two’s complement is obtained
from this intermediate step simply by adding one to
it so that 1000 becomes 1001.
In two’s complement coding positive numbers
are described by straight binary while negative
numbers are described by the twos complement of
the corresponding positive number. As a conse-
quence the most significant bit is again the sign bit
with a zero representing positive numbers while a
one represents negative numbers. Finally another
scheme called offset binary is similar to two’s
complement except that the most significant bit is
complemented with a one representing positive
numbers and a zero representing negative numbers.
The following table displays each of these schemes
for four binary bits covering a voltage range from
−0.8 to +0.8 V or 1.6 Vpeak to peak.
An inspection of the sign and magnitude column
of Table 22-3 reveals immediately the shortcoming
of this particular coding scheme in that there are two
codes representing the value of zero depending upon
whether zero is approached from values less than
zero or from values greater than zero. This ambi-
guity is removed by employing either the twos
complement code or the offset binary code. It is also
of note that one can readily change from the twos
complement code to the offset binary code by
simply complementing the most significant bit.
 Many different techniques for performing
analog to digital conversion have been developed
over the years. In audio applications there are two
markedly different techniques that have proven their
worth. The first of these is the method of successive
approximations that held the stage almost exclu-
sively for many years. The second of these is the
delta-sigma technique that promises to eventually
dominate in audio applications. Both of these
converter techniques employ a special circuit known
as a digital to amplitude converter or DAC as a
component in the overall analog to digital converter
structure. Analog to digital converters, regardless of
the technique of conversion, are referred to collec-
tively as ADCs. A DAC will be discussed initially
as it is a crucial element regardless of the selected
ADC technique. Fig. 22-30 is a simple circuit for a
four bit DAC.
The DAC displayed in Fig. 22-30 is configured
to operate with an offset binary bipolar code. It will
operate equally as well with a twos complement
code if the MSB data line includes an inverter. The
switches employed are electronic switches activated
by the logic levels on the data lines though they
have been drawn as conventional SPDT for
simplicity. The ground position on each switch
means that the respective data bit is a zero while the
connection to the opamp summing bus means that
the respective data bit is a one. The switches as
shown are in response to the code 0100.
The heart of the circuit is the R−2R ladder
network. The resistance to ground as measured at
the negative voltage reference terminal is R indepen-
dent of the settings of the switches because the
summing bus of the opamp is itself a virtual ground.
The total current directed into the negative voltage
reference source is the value of the negative refer-
ence voltage divided by R. The current in the MSB
switch is ½ of the total. The current for the next bit
Table 22-3. Binary Codes for Bipolar Signals
Decimal 
Value
Sign and 
Magnitude
Two’s
Complement
Offset 
Binary
Voltage 
(Volt)
+7
0111
0111
1111
+0.7
+6
0110
0110
1110
+0.6
+5
0101
0101
1101
+0.5
+4
0100
0100
1100
+0.4
+3
0011
0011
1011
+0.3
+2
0010
0010
1010
+0.2
+1
0001
0001
1001
+0.1
+0
0000
0000
1000
0
−0
1000
0000
1000
0
−1
1001
1111
0111
−0.1
−2
1010
1110
0110
−0.2
−3
1011
1101
0101
−0.3
−4
1100
1100
0100
−0.4
−5
1101
1011
0011
−0.5
−6
1110
1010
0010
−0.6
−7
1111
1001
0001
−0.7
−8
None
1000
0000
−0.8
Figure 22-30. Four bit DAC. 
R
R
R
2R
2R
2R
2R
2R
2R
2R
MSB
LSB
−VREF
Out
+VREF
−
+

500
Chapter 22
switch is ¼ of the total, the next 1⁄8, and finally the
LSB switch has 1⁄16 of the total current. The
remaining 1⁄16 of the total current directed into the
negative voltage reference source always exists in
the 2R resistance that terminates the ladder network.
The offset binary code for the value of zero is 1000.
The connection of the summing bus to a positive
voltage reference equal in magnitude to the negative
voltage reference through a resistance forces the
opamp output to zero volts. With bipolar reference
voltages of +0.8 V and −0.8 V, the DAC output
tracks the last column of Table 22-3.
The DAC circuit was drawn for a four bit device
as this is sufficient for an understanding of the
circuit operation. A simple extension of the R−2R
ladder network allows for more bits to be handled in
the same manner. Increasing the number of bits
employed increases the dynamic range of signals
that may be processed by either a DAC or ADC.
The dynamic range mentioned here refers to the
ratio of the peak signal value to the least signal
value that may be handled by the encoding process.
This is optimistically stated as being 2n to 1 where n
is the number of bits. For bipolar signals, however,
the most significant bit is devoted solely to repre-
senting the algebraic sign of the signal and hence
only n − 1 bits are available for magnitude assign-
ments. This being the case, a more conservative
statement of the dynamic range is 2n – 1 to one. Upon
letting D represent the dynamic range in decibels
then
(22-96)
Sixteen bit encoding is an often encountered
standard for high quality audio program material.
When this is the case Eq. 22-96 yields a dynamic
range of 90 dB. As a caution, this dynamic range
limitation is strictly associated with the linear
encoding process and is a separate issue from the
overall dynamic range of a complete system. A
linear encoding process has an uncertainty of
±½ LSB that contributes to what is termed quantiza-
tion noise. This quantization noise acts to worsen a
system’s signal to noise ratio. This fact alone would
place a premium on a large number of bits.
Fig. 22-31 is a block diagram of a complete ADC
that employs the technique of successive approxi-
mation conversion.
In addition to the elements previously discussed,
the successive approximation converter contains a
comparator, a special successive approximation
register, an output data register, a master clock, and
a control unit. The control unit in collaboration with
the master clock establishes the sample rate and
generates the timing and logic signals necessary for
the overall system operation. The comparator
compares the voltage value of the hold signal with
the output voltage of the DAC and generates a
signal only when the DAC voltage exceeds the hold
voltage. At the start of a conversion as soon as the
sample and hold circuit adopts the hold mode the
SAR sets the most significant bit in the DAC via
means of the data bus. The most significant bit
forces the DAC output to assume a value equal to
one-half of the total voltage range. If the hold signal
exceeds this value, the comparator does not trip and
the SAR continues asserting the most significant bit
and then sets the next most significant bit.
The action continues in this fashion until the
comparator trips. When this occurs, the last bit set is
returned to zero and the next bit down the line is set.
The operation continues in this manner until all bits
D
20dB
2n 
1
–
1
-------------
⎝
⎠
⎛
⎞
log
=
Figure 22-31. Successive approximation analog to digital converter.
SAR
Comparator
Data Bus
Data
Register
DAC
+Ref  −Ref
Sample
&
Hold
Anti
Alias
Filter
Signal
In
Clock
Control

   
Signal Processing
501
have been tested. At the conclusion of all bit tests,
the code in the DAC as well as the data register is
within one LSB of the value equal to that repre-
senting the hold signal. The control circuit then
issues an end of conversion signal that validates and
maintains the status of the data register while
clearing the DAC in preparation for the next conver-
sion. The clocking rate for bit tests is necessarily
greater than n times the audio signal sample rate.
In summary, an n-bit digital word is issued for
each sample immediately following the end of the
conversion period. The data in this form can be
communicated directly to computer memory or to
digital signal processing circuitry. The successive
approximation technique does have at least two
stringent requirements. An expensive high pole
order analog antialiasing filter is required unless the
sampling frequency is considerably greater than
twice the maximum frequency to be passed in the
signal spectrum. The resistors in the R−2R ladder
network of the DAC must be very precise in order to
insure linearity in the conversion process.
The delta-sigma analog to digital conversion
technique is replacing the successive approximation
technique in practically all audio applications. This
has been made possible as a result of technological
developments in the area of very large scale inte-
grated circuits. Such circuits can now be made to
successfully handle a mix of both digital and analog
circuits. Delta-sigma analog to digital converters
contain various combinations of elements depending
upon the exact manner of employment. The basic
element in all instances is a delta-sigma modulator.
A simplified version of such a modulator is
displayed in Fig. 22-32.
The delta-sigma technique tracks the difference
between the value of the audio signal at any given
moment and a reconstructed audio signal that is
derived through the summation of previous differ-
ences. If the audio signal at the moment of sampling
exceeds the present value of the reconstructed
signal, the output of the comparator is positive and
the rising edge of the clock pulse generates a logic 1
at the output of the D flip flop. This in turn connects
the RC integrator via an electronic switch to a posi-
tive voltage reference thus tending to increase the
value of the reconstructed audio signal.
Had the reconstructed signal been greater than
the audio signal at the moment of sampling, the
comparator output would be negative forcing a logic
zero at the output of the flip flop and a connection to
a negative voltage reference. This would lead to a
decrease in the value of the reconstructed audio
signal. There will thus occur a serial bit stream at
the output with 1s indicating level increases and 0s
indicating level decreases. In order for the recon-
structed signal to closely approximate the input
audio signal the sampling rate must be much larger
than that required to simply satisfy the Sampling
Theorem. The delta-sigma technique thus employs
oversampling with the oversampling rate often
being 64×, 128×, or 192× the minimum required by
the Sampling Theorem. The very high sampling rate
greatly simplifies the design of the antialias filter
with a simple RC lowpass often being sufficient. If
the application is that of just signal delay, the serial
data stream can be directly stored in memory and
extracted after the required delay. The delayed serial
data stream can be converted back to audio through
the employment of a delta-sigma demodulator. A
simplified circuit of such a demodulator is depicted
in Fig. 22-33.
Figure 22-32. Simplified delta-sigma modulator.
Clock
Comparator
Audio
In
Serial
Data
Out
+VRef
−VRef
Ck
D
Q
D Flop
+
−
Figure 22-33. Simplified delta-sigma demodulator.
Serial
Data
In
Clock
CLK
D
Q
D Flop
+VRef
−VRef
Audio
Out
+
−

502
Chapter 22
The operation of both the delta-sigma modulator
and demodulator can be enhanced through the
employment of multiple feedback loops of integra-
tion. In addition the voltage references can be
dynamically adjusted through the employment of
adaptive techniques with decisions being guided by
the historical behavior of the serial bit chain. Alter-
natively, the application might require the conver-
sion of the continuous serial bit stream into a
succession of n-bit words at the normal sample rate.
In this instance, a special form of finite impulse
response or FIR digital filter is required in addition
to the modulator. This filter is termed a decimation
filter. Decimation filters are usually constructed in
stages so that a given filter might well consist of a
cascade of several FIRs with downsampling by
various factors of two occurring in each of the sepa-
rate stages.
As an example suppose the objective is to
produce a sequence of 16-bit samples at a sample
rate of 48k samples per second. If the delta-sigma
modulator oversamples at 64× then the required
clock frequency would be 64 × 48k or 3.072 MHz.
The serial bit stream emanating from the modulator
at the clock rate is then fed into a suitably designed
three stage FIR digital filter with decimation factors
of 8, 4, and 2, respectively, the output from the
filters being serial samples each consisting of 16 bits
at a rate of 48k samples per second. Additionally the
digital filter defines the passband of the system
while offering a flat response from dc to beyond
20kHz attended by an attenuation in the stop band
of 90 dB or more.
Digital signal processing engines or DSPs gener-
ally require samples in parallel form. The final
component then in the delta-sigma ADC might well
be a 16-bit shift register for performing serial to
parallel data conversion. In summary, the
delta-sigma technique does not require any precision
components as does the successive approximation
technique. The high sampling rate makes possible
the employment of a very simple analog antialias
filter. In most instances there is no requirement for a
sample and hold circuit and the decimation FIR
filters precisely define the passband while offering
large stopband rejection. The major shortcoming of
the technique exists in the processing time required
by the FIR filters. This processing time is usually of
a few milliseconds.
At this juncture we will temporarily suspend our
study of sampled data systems in order to return to a
further pursuit of continuous time signals. The
initial focus will be on system theory and a mathe-
matical technique that treats both the transient and
steady state response of physical systems under a
single umbrella. This mathematical technique is the
basis of description of analog filters and will serve
as a guideline for developing a similar technique
applicable to digital filters.
22.3 System Theory
The goal of system theory is to evolve a method of
analysis such that certain classes of physical systems
will conform to a signal flow of the form:
A slight rearrangement of which suggests the mathe-
matical statement:
If this is truly an equality then it can be written:
If the system function is to have a unique identity,
related only to the system from which it stems, it
cannot depend on either the response or the excita-
tion functions just as a resistor which obeys Ohm’s
law does not depend on either the voltage or the
current. The independence of the system function on
the excitation function implies that neither the size
of the excitation nor the time of its application is of
importance. This requires that the system from
which the system function is derived must be both
linear and time invariant. In order to achieve the goal
of system theory, it is necessary to transform the
time domain equations governing the system into the
corresponding equations in the complex frequency
domain. Before exploring any of the details associ-
ated with these concepts mention should be made of
the genius to whom we chiefly owe a great debt of
gratitude for making it all possible.
Oliver Heaviside (1850-1925) was born in
London and received only a secondary education.
He was the nephew of Sir Charles Wheatstone but
apparently was from the poor side of the family. He
was employed as a youth by the Great Northern
Telegraph Company but had to leave the company
at age 24 because of encroaching deafness. There-
after he set for himself the formidable task of
studying and understanding Maxwell’s treatise. Not
only did he succeed in this endeavor he also
proceeded to solve many of the outstanding elec-
trical and communications problems of the time
through the employment of analysis techniques
which he had to evolve to compensate for his lack of
Input or Excitation
System
[
]
Output or Response
⇒
⇒
Response function
Excitation function
(
) System function
(
)
=
System function
Response function
Excitation function
----------------------------------------------
=

   
Signal Processing
503
formal mathematical training. He was a physicist in
the highest sense of the word as he felt that physical
ideas should be the master and mathematics the
servant. In his view the servant must accede to the
whims of the master. As a result, the highly placed
academic mathematicians of his time railed against
Heaviside’s mathematical techniques and it was not
until 1916 that they were finally proven to rest on
firm mathematical foundations and were begrudg-
ingly accepted by mathematicians.
Fortunately physicists and engineers had been
using them in the meantime with great success. In
1887, barely 13 years after he began his serious
studies, Heaviside solved the problem of distortion-
less transmission on telegraph and telephone cables
and thus made long distance and wide bandwidth
communication on these media a possibility. William
Thomson had introduced serious study of this
problem in 1855 but had not pursued it to its ultimate
conclusion. Heaviside’s solution to the cable
problem is the first instance of electrical equaliza-
tion. Heaviside’s equalization technique was adopted
by Professor Pupin at Columbia University in the
United States and subsequently introduced to the
American telephone industry. Heaviside published
all of his work often at his own expense.
Heaviside, along with Professor Kennelly of
Harvard University, was also the first to explain the
ionosphere’s role in long distance radio communica-
tion. Heaviside’s contributions were well recognized
and he received many honors toward the end of his
life but his name is hardly ever referenced in
modern textbooks. His mathematical techniques
have been largely supplanted by the transform of
Laplace, which is more general, or that of Fourier
which is actually a special case of the two sided
version of the Laplace transform. The systems
approach employing principally physical reasoning
was his alone and this uniquely warrants his
continued memory.
In determining system or transfer functions the
tool of choice is the Laplace transform. The Laplace
transform is an integral transform that converts a
function of the independent variable of time symbol-
ized by t into some other function of the complex
frequency variable symbolized by S where S has
both real and imaginary parts
(22-97)
The two sided Laplace transform of a function of t is
given by
(22-98)
The Fourier transform is a special case of the
Laplace transform wherein the frequency variable is
purely imaginary.
(22-99)
In analyzing systems, the transform tool to be
employed is the one sided Laplace transform given by
.
(22-100)
This is employed for two reasons. Firstly, the
consideration of time signals defined only for t ≥ 0
automatically satisfies the principle of causality.
Secondly, the Laplace transform with complex
frequency variable inherently takes into account any
initial conditions which exist in the system at t = 0.
One can employ Eq. 22-100 in order to directly
calculate the Laplace transform of a given f (t). This
is often not necessary, as tables are available
containing the transforms of commonly encoun-
tered time functions. Such tables are called tables of
function and transform pairs and can be found in
most mathematical handbooks. Table 22-4 is an
abbreviated table presented here for ready reference.
S
σ
jω
+
=
F S
( )
f t( )e St
–
td
∞
–
∞
∫
=
Table 22-4. A Short Table of Function Tranform 
Pairs
Function of Time
Transform
F ω
(
)
f t( )e jωt
–
td
∞
–
∞
∫
=
F S
( )
f t( )e St
–
td
0
∞
∫
=
1
1
S---
ωt
(
)
sin
ω
S2
ω2
+
------------------
ωt
(
)
cos
S
S2
ω2
+
------------------
γt
(
)
sinh
γ
S2
γ2
–
----------------
γt
(
)
cosh
S
S2
γ2
–
----------------
t
1
S2
-----
tn
1
–
n
1
–
(
)!
------------------
1
Sn
-----
eγt
1
S
γ
–
-----------
e γ
– t
1
S
γ
+
-----------

504
Chapter 22
The laws of physics governing the behavior of
physical systems mathematically appear usually in
the form of time dependent differential or
integro-differential equations. In the course of
attaining the goal of system theory it is necessary to
take the Laplace transform of each term in such
equations. The mathematical operations involved
are successive differentiation and or integration.
Tables relating the time dependent mathematical
operations and their respective transforms are also
available. A brief such table will also be presented
here for ready reference.
A few words of explanation of the entries in
Table 22-5 are needed for clarification. In the first
entry if f (t ) is the time domain function, its Laplace
transform is represented by F(S). In the second entry
the time domain function is the first derivative of
f(t) with respect to t. The corresponding Laplace
transform of this is S times the Laplace transform of
f (t ) less the value of f (t ) at the instant of zero time.
The third entry is the time domain function which
represents the second derivative with respect to time
of the function f (t ). The Laplace transform of this
time dependent function is S squared times the
transform of f (t ) less S times the initial value of
f(t)and further less the value of the first time deriva-
tive of f (t ) evaluated at the initial instant. Finally, in
the fourth entry, the time dependent function is the
integral with respect to time of f (t ).
The transform of this time dependent function is
the transform of f (t ) divided by S plus the time inte-
gral of f (t ) with respect to t evaluated at the initial
instant. This last term probably requires even further
explanation. For example, imagine that f (t ) repre-
sents an electrical current in a capacitor, then the
integral of the current would be the electric charge
on the capacitor and the value of the integral at the
initial instant would be the charge on the capacitor
when t is equal to zero.
At this point it would be instructive to apply this
method of analysis to a physical system commencing
from first principles. So as not to be overly ambitious
a relatively simple system will be chosen. This
system will consist of a time dependent signal gener-
ator which has an open circuit emf denoted by ei(t )
and an internal resistance of Ri. This generator is
supplying a signal to the input circuit of a voltage
amplifier whose input circuit can accurately be
modeled as a resistance Ra in parallel with a capaci-
tance Ca. The object is to determine the transfer func-
tion for this system where the excitation is ei(t ), the
exact form of which is arbitrary, and the response is
to be va(t ) where va(t ) is the time dependent voltage
appearing at the input terminals of the amplifier. The
circuit thus appears as displayed in Fig. 22-34.
The next step is to apply the laws of physics by
writing the differential equation which governs the
system taking the time dependent voltage va as the
dependent variable. The current in the resistor Ra is
the voltage va divided by the resistance Ra. The
current in the capacitor Ca is the time rate of change
of the charge on this capacitor which in turn is the
value of the capacitance multiplied by the time rate
Table 22-4.  (cont.) A Short Table of Function 
Tranform Pairs
Function of Time
Transform
e αt
–
βt
(
)
sin
β
S
α
+
(
)2
β2
+
--------------------------------
e αt
–
βt
(
)
cos
S
α
+
S
α
+
(
)2
β2
+
--------------------------------
te αt
–
1
S
α
+
(
)2
--------------------
tn
1
– e αt
–
n
1
–
(
)!
---------------------
1
S
α
+
(
)n
--------------------
e αt
–
e γt
–
–
γ
α
–
------------------------
1
S
α
+
(
) S
γ
+
(
)
-----------------------------------
1
αt
(
)
cos
–
α2
----------------------------
1
S S2
α2
+
(
)
--------------------------
Table 22-5. A Short Table of Operations Transform Pairs
Function of Real Variable
LaPlace Transform
Figure 22-34. Amplifier input circuit model.
f t( )
F S
( )
df t( )
dt
------------
SF S
( )
f 0
( )
–
d2f t( )
dt2
--------------
S2F S
( )
Sf 0
( )
–
df t( )
dt
------------
t
0
=
–
 f t( ) td
∫
F S
( )
S
-----------
1
S---  f t( ) td
0
∫
+
Ri
Ra
Ca
ei(t)
va(t)

   
Signal Processing
505
of change of the voltage across the terminals of the
capacitor. The current in the resistor Ri is the sum of
these currents. The emf of the generator is equal to
the voltage across Ri plus the voltage va. The equa-
tion governing the circuit behavior is thus
(22-101)
In this example, the initial charge on the capac-
itor at t = 0 will be taken to be zero although other
choices are possible as determined by the prior
history of the circuit before the generator is
connected. The procedure continues by taking the
Laplace transform of each term in this equation. As
neither ei(t ) nor certainly va(t ) are known explicitly
as functions of time their Laplace transforms are
implied by Ei(S) and Va(S), respectively. The trans-
formed equation becomes
(22-102)
Notice that the derivative with respect to time of
a time dependent function has been replaced by
multiplication of the transformed time function by
the complex frequency variable S as indicated by the
second entry in Table 22-5. There is also no contri-
bution from initial conditions here because va(t ) is
zero prior to t = 0. The transformed equation can be
solved algebraically to obtain
(22-103)
The result states that the response as a function
of the complex frequency S is equal to the excitation
expressed as a function of the complex frequency
multiplied by some other function of the complex
frequency S. This other function is the transfer func-
tion which will be denoted H(S). It should be clear
that
(22-104)
The transfer function is really a powerful code
that allows one to determine how the system will
behave regardless of the nature of the excitation. In
fact, as will now be shown, the transfer function is
the description in the complex frequency plane of
the system’s response to an impulse applied as an
excitation in the time domain and the inverse
Laplace transform of the transfer function is the
time domain description of such response.
What is a unit impulse and what is its Laplace
transform? The concept of impulse originated in
classical mechanics wherein Newton’s second law
of motion states the force applied to a particle
equates to the time rate of change of the particle’s
linear momentum or
(22-105)
In Eq. 22-105, m is the particle mass, v is the
particle’s instantaneous velocity, and the product of
the two is the particle linear momentum. Now, given
a force which itself may be time dependent what
change in the particle’s momentum occurs in some
definite time, say t0? The answer is
(22-106)
This integral is called the impulse of the force or
more simply just the impulse. The result of the
impulse is a definite change in momentum of the
particle. However a given change in momentum can
be brought about in a variety of ways. The force may
be weak but last for a long period of time or it may
be strong but last for just a short time. As long as the
integrals are equal in the two cases the result will be
the same. Now consider a time function which has a
time dependence as displayed in Fig. 22-35.
First of all note that the area under the curve is
unity. Now imagine that t0 is allowed to become
increasingly smaller while the height of the plot
which is inversely proportional to t0 becomes
increasingly larger with the total area remaining at
unity. In the limit as t0 approaches 0 the height of the
plot approaches ∞ while the area remains at unity.
The impulse of this function, that is the area under
ei t( )
va t( )
Ra
-----------
Ca
dva t( )
dt
---------------
+
Ri
va t( )
+
=
Ei S
( )
Va S
( )
Ra
--------------
CaSVa S
( )
+
Ri
Va S
( )
+
=
Va S
( )
Ei S
( )
1
RiCa
-----------
S
Ra
Ri
+
RaRiCa
------------------
+
----------------------------
⎝
⎠
⎜
⎟
⎜
⎟
⎜
⎟
⎛
⎞
=
H S
( )
1
RiCa
-----------
S
Ra
Ri
+
RaRiCa
------------------
+
----------------------------
=
Figure 22-35. Time dependent function.
F
d
dt
----- mv
(
)
=
F t( ) td
0
t0
∫
1
t0
t0                     t

506
Chapter 22
the curve, is always unity and hence it is called a
unit impulse but the function being plotted versus
time has grown infinitely large while its existence
has become infinitesimally short. This peculiar
function is called the impulse function or δ(t ). The
Laplace transform of this function can be found
through the steps of the limiting process used in
arriving at the function itself as follows.
(22-107)
In evaluating this limit the term 
 is replaced
by the infinite series expansion for this quantity and
only the leading terms of the series are retained
because all of the higher order terms are negligibly
small compared with the leading terms. Therefore,
(22-108)
The conclusion is that the Laplace transform of
δ(t ) is 1! Note that the dimension of the ordinate in
Fig. 22-35 is reciprocal time and that the area is
dimensionless. Now if a physical quantity such as
voltage has an impulsive behavior this is represented
by kδ(t ) where the size of k represents the value of
the voltage and the dimensions of k are volt seconds.
The product kδ(t ) is termed an impulse of strength k.
Recall that for the simple system under study in
Eq. 22-109
(22-109)
If the generator exciting the system has a time
behavior of an impulse function of strength k, this
equation will become
(22-110)
Alternatively, Eq. 22-109 may be written
(22-111)
It is possible to explore also what the system’s
behavior is in the time domain for such an excita-
tion. This requires taking the inverse Laplace trans-
form of the frequency domain behavior that is
(22-112)
In Eq. 22-112, the operation of taking the inverse
Laplace transform is indicated on the left with the
corresponding time domain function on the right.
The mathematical operations of taking the Laplace
transform and its inverse are linear and hence
(22-113)
The function h(t ) is the system’s time domain
response to a unit impulse. Eq. 22-113 tells one that
h(t) and H(S) constitute a function transform pair.
This implies that the system transfer function is the
system’s response expressed in the complex
frequency domain to a unit impulse applied in the
time domain. There is a formal way for taking the
inverse Laplace transform but it is difficult as it
involves a contour integration in the complex plane.
The procedure which is usually employed is to
consult a table of function, transform pairs, and
hopefully find an appropriate f (t ) ⇔ F(S) combina-
tion. Pair number nine in Table 22-4 is appropriate
in this instance when one identifies
(22-114)
and recognizes that 1 ⁄ RiCa is just a constant.
The impulse response of this simple system as a
function of time is then
(22-115)
Graphically this has the form of a decaying
exponential.
In words, what has happened is this. The gener-
ator at t = 0 produces an impulse of strength k
implying an infinitely large voltage for an infinitesi-
mally short period of time. Subsequently, the
voltage at the amplifier terminals goes from 0 to a
finite value in an infinitesimally short period of
time. This voltage then decays exponentially with
time from this finite value and approaches zero
asymptotically as t grows infinitely large. This is the
time domain description but in order to learn all of
this it was necessary to transform the problem to the
complex frequency domain. What then does it look
like in this domain? For simplicity let Ri and Ra each
Δ S
( )
limt0
0
→
1
t0
----e St
–
td
0
t0
∫
=
limt0
0
→
1
e
St0
–
–
St0
--------------------
=
e St
–
0
Δ S
( )
limt0
0
→
1
1
–
St0
+
St0
-------------------------
=
1
=
Va S
( )
Ei S
( )
1
RiCa
-----------
S
Ra
Ri
+
RaRiCa
------------------
+
----------------------------
⎝
⎠
⎜
⎟
⎜
⎟
⎜
⎟
⎛
⎞
=
Va S
( )
k
1
RiCa
-----------
S
Ra
Ri
+
RaRiCa
------------------
+
----------------------------
⎝
⎠
⎜
⎟
⎜
⎟
⎜
⎟
⎛
⎞
=
Va S
( )
kH S
( )
=
kH S
( )
[
] 1
–
kh t( )
=
H S
( )
[
] 1
–
h t( )
=
γ
Ra
Ri
+
RaRiCa
------------------
=
kh t( )
k
RiCa
-----------e
Ra
Ri
+
(
)t
RaRiCa
-------------------------
–
=

   
Signal Processing
507
equal 1 Ω and let Ca = 1 F. An unlikely set of values
but nevertheless convenient. With this assignment,
(22-116)
Recall that in general 
 that is, H(S) is
complex.
(22-117)
This can be written in the form
(22-118)
where,
|H(S)| is the absolute magnitude of H(S),
ϕ is the phase of H(S).
(22-119)
(22-120)
|H| is a two dimensional surface which has the
appearance in Fig. 22-36.
In Fig. 22-36 the plane below the surface is the
complex frequency or S plane. The transfer function
surface exists in three dimensions so that each point
on the surface has in general x, y, and z coordinates.
The x axis corresponds to σ, the y axis corresponds
to jω, and the z axis represents the magnitude of
H(S). At the point σ = −2, ω = 0, the surface rises to
infinity as the magnitude of the transfer function is
infinite at that point. This singular point is called a
pole of the transfer function. The location of the
pole in the left half of the complex plane, brought
about by σ being negative, is very significant as this
is what led to the impulse response being a decaying
exponential. If the pole were located in the right half
of the complex plane, the impulse response would
be a growing exponential and the system would not
be a physically realizable stable system. This
surface is sufficient to describe the complete
behavior of this system for all types of excitations in
both the steady state as well as the transient state.
For example, if one takes a slice through this surface
by assigning σ the value of zero what appears is the
steady state amplitude response of the system for
sinusoidal excitation. This is depicted in Fig. 22-37.
Finally a slice taken through the point σ = −2 and
an arbitrary value of ω makes an angle with the real
axis which is ϕ = atan(−ω ⁄ 2). This is the phase
response of the system for steady state sinusoidal
excitation.
One other possible feature of transfer functions
requires examination. In order to see this, the orig-
inal circuit needs to be modified by the insertion of a
capacitor between the generator and the amplifier of
the original example. Let this capacitor also for
simplicity have a value of 1 F. The new transfer
function will become
(22-121)
and the new transfer function surface is depicted in
Fig. 22-38.
The transfer function surface now exhibits two
poles rather than the single one of the former case.
This is because the denominator of the transfer
function is now a quadratic having two distinct roots
or values of S for which the denominator becomes
zero and the magnitude of the transfer function
becomes infinite. The really new feature, however, is
Figure 22-36. Transfer function surface.
H S
( )
1
S
2
+
------------
=
S
σ
jω
+
=
H S
( )
1
σ
jω
2
+
+
-------------------------
=
H S
( )
H e jϕ
=
H
1
σ
2
+
(
)2
ω2
+
-------------------------------------
=
ϕ
ω
–
σ
2 
+
--------------
⎝
⎠
⎛
⎞
atan
=
3.0
2.5
2.0
1.5
1.0
0.5
0
−3
−2
−1
0  0
1
2
3
Omega Value
Sigma Value
Transfer Function Magnitude
Figure 22-37. Amplitude response for sinusoidal
excitation.
0.5
0.45
0.4
0.35
0.3
0.25
0.2
0.15
0.1
0.05
0
0     1     2     3      4     5     6      7     8     9    10
Omega Value
Magnitude of Transfer Function
H S
( )
S
S2
3S
1
+
+
---------------------------
=

508
Chapter 22
the point at which the surface contacts the S plane.
This point denotes a value for S at which the transfer
function has a value of zero. In this instance, this
occurs when both σ and ω are equal to zero. This
point is called a zero of the transfer function. The
shape of a general transfer function surface is deter-
mined by the location of the poles and zeros. The
fact that the zero in this instance occurs at the origin
in the S plane means that the system has no response
to direct current in the steady state. Dc of course
means that the exciting frequency is zero. The steady
state amplitude response with sinusoidal excitation
for this modified system is displayed in Fig. 22-39.
The addition of the series capacitor to the circuit
has produced a system which now constitutes a
bandpass filter which should be evident from the
shape of the amplitude response curve. The close
linkage between the shape of the transfer function
surface and the locations of the poles and zeros of
the transfer function have led to a rapid analysis of
transfer functions termed pole-zero analysis. This
technique should be explored in detail as it is not
computationally intensive and it yields most of the
important answers with regards to system behavior.
22.3.1 Pole and Zero Analysis
The circuit diagram for the modified amplifier input
circuit is displayed in Fig. 22-40.
If one were analyzing this circuit by employing the
techniques presented in Chapter 8 Interfacing Elec-
trical and Acoustic Systems, the ratio of the output
voltage to the input voltage would be written as
(22-122)
If the capacitors are uncharged and there are no
currents prior to the connection of the generator at
t = 0, Eq. 22-121 can be put easily into the language
of the Laplace transform simply by replacing jω,
wherever it appears, by S. In doing so, it is impor-
tant to remember that S still represents σ + jω. After
this substitution and some algebraic simplification,
the recasted equation becomes
(22-123)
At this point one may substitute typical values
for each of the circuit components and deal with the
Figure 22-38. Modified transfer function surface.
Figure 22-39. Amplitude response of modified system.
3.0
2.5
2.0
1.5
1.0
0.5
0
−3
−2
−1
0  0
1
2
3
Omega Value
Sigma Value
Transfer Function Magnitude
0.35
0.3
0.25
0.2
0.15
0.1
0.05
0
0     1     2     3      4     5     6      7     8     9    10
Omega Value
Magnitude of Transfer Function
Figure 22-40. Modified amplifier input circuit.
Ri
Ra
Ca
ei(t)
va(t)
Ci
Va
Ei
------
Ra
1
jωCa
------------
Ra
1
jωCa
------------
+
-------------------------
Ri
1
jωCi
-----------
Ra
1
jωCa
------------
Ra
1
jωCa
------------
+
-------------------------
+
+
--------------------------------------------------------
=
Va S
( )
Ei S
( )
--------------
1
RiCa
-----------S
S2
RaCa
RiCi
RaCi
+
+
(
)
RaCaRiCi
-----------------------------------------------------S
1
RaCaRiCi
------------------------
+
+
---------------------------------------------------------------------------------------------------
=

   
Signal Processing
509
collection of numbers that results or pick some
values that will illustrate the procedure to be
followed without requiring tedious numerical calcu-
lation. We will pursue the latter course by taking
unit values for each of the components in which
case Eq. 22-122 becomes simply
(22-124)
The objective at this point is to locate the poles
and zeros of the transfer function in the complex S
plane. By inspection, if S is set equal to zero, the
value of the transfer function also becomes zero.
Therefore, there is a single zero located at the origin.
The poles of the transfer function correspond to
values of S which when substituted in the denomi-
nator force the denominator to have a value of zero
and thus forcing the transfer function to become
infinite. The denominator here is a quadratic in S
and hence there are two values of S which make the
denominator zero therefore this transfer function has
two poles. The pole locations are identified by
factoring the denominator. A straightforward appli-
cation of the quadratic formula leads to
(22-125)
The poles, then, are located at S = −0.382 and
S = −2.618. The pole and zero diagram depicts these
locations and is presented in Fig. 22-41.
The location of the zero in the diagram of
Fig. 22-8 is indicated by the circle at the origin. A
line drawn from this location to an arbitrary value of
ω is indicated in the figure. This line makes a right
angle with the positive real or σ axis. The locations
of the two poles are indicated by xs. In this instance,
both of the poles have real values and each of them
is located on the negative real axis. Lines are drawn
from each of the poles to the selected arbitrary value
of ω and these lines make the angles α and β,
respectively, with the positive real axis. The phase
response function can be readily calculated by
observing the angles in this diagram. In the case of
steady state sinusoidal excitation, the phase
response function is simply the phase difference
between the output signal and the input signal
expressed as a function of ω. This phase difference
can be extracted directly from the figure. This phase
difference is the sum of all angles contributed by
zeros less the sum of all angles contributed by poles.
In this instance there is only a single zero and its
angle is π ⁄ 2. There are two poles providing collec-
tively the angles α and β. Upon denoting the phase
difference by ϕ, the phase response function
becomes
(22-126)
The amplitude response for sinusoidal excitation
is the magnitude of the output signal divided by the
magnitude of the input signal expressed as a function
of ω. This may be calculated directly from either
Eqs. 22-123 or 22-124. One simply substitutes jω for
S wherever S appears and then determines the magni-
tude of the resulting complex quantity. This substitu-
tion yields
(22-127)
The magnitude of the numerator is just ω. Recall
that the magnitude of the denominator is the square
root of the sum of the squares of the real and imagi-
nary part hence, the amplitude response function is
written as
(22-128)
Judging from the examples presented so far, one
might have the false impression that transfer func-
tion poles are always real quantities. In fact, the
poles are more often complex. As an illustration of
complex poles, an example will be drawn from a
real problem dealing with a magnetic phonograph
cartridge. The passive circuit elements associated
with the cartridge’s construction and the input
circuit of the preamplifier to which it may be
connected appear in Fig. 22-42.
The internal structure of the cartridge is modeled
as an ideal voltage source in series with the
Figure 22-41. Pole-zero diagram.
Va S
( )
Ei S
( )
--------------
S
S2
3S
1
+
+
---------------------------
=
Va S
( )
Ei S
( )
--------------
S
S
0.382
+
(
) S
2.618
+
(
)
-------------------------------------------------------
=
α
σ
jω
β
ϕ ω
(
)
π
2---
α ω
(
)
–
β ω
(
)
–
=
π
2---
ω
2.618
-------------
⎝
⎠
⎛
⎞
atan
–
ω
0.382
-------------
⎝
⎠
⎛
⎞
atan
–
=
jω
ω
–
2
3jω
1
+
+
-----------------------------------
Va
Ei
------
ω
ω4
7ω2
1
+
+
------------------------------------
=

510
Chapter 22
inductance of the cartridge’s coil represented by L
and the winding resistance of the coil represented by
r. The resistive load presented by the preamplifier to
the cartridge is R and the shunt capacitance of the
preamplifier and the associated connecting cable is
represented by a total capacitance C. The exact
expression for the transfer function is
(22-129)
In practice, the load resistance R is set to be
about fifty times as large as the cartridge resistance,
r. Furthermore, L/R >> rC for typical systems, so
little error is made in using the following simpler
form 
(22-130)
The analysis here is not concerned with
recording characteristics, pre-emphasis, or
de-emphasis but rather with the faithful transmission
of the signal produced by the generator regardless of
its form. There are no zeros in the transfer function
of Eq. 22-129. This implies that there is response
extending to dc or zero frequency. There are two
poles as evidenced by the denominator being a
quadratic in the complex frequency variable. These
facts taken together define the response to be that of
a second order low pass filter where the shape of the
response depends solely on the locations of the
poles. The pole order is dictated by the highest
power of the complex frequency variable that
appears in the polynomial that constitutes the
denominator of the transfer function. Regardless of
the placement of the poles in the left half of the
complex plane, each pole contributes an asymptotic
attenuation rate of 6 dB/octave and an asymptotic
phase shift of −π ⁄ 2 radians. The attenuation rate of
this filter at high frequencies is thus 12 dB/octave
with an attendant phase shift at high frequencies of
π radians. The question becomes where should the
poles be placed in order to obtain ideal response and
what constitutes “ideal” response. In studying this
placement, it is useful to cast the transfer function in
a standard form which is
(22-131)
The behavior of the polynomial in the denomi-
nator of Eq. 22-131 now hinges on the significance
assigned to the value of ω0 and the value of the coef-
ficient α. There are a multitude of possibilities from
which three distinct classes of polynomials have been
found to possess useful characteristics. These are the
Bessel, Butterworth, and Chebyshev polynomials.
The Bessel polynomials offer the most linear
phase behavior with the reciprocal of ω0 being equal
to the signal group delay at zero frequency.
The Butterworth polynomials offer maximally
flat amplitude response with ω0 being the angular
frequency at cut-off, i.e., the angular frequency at
which the amplitude response is −3 dB for a low or
high pass filter. Note, however, it corresponds to the
center angular frequency for a bandpass filter.
The Chebyshev polynomials feature controlled
ripples in the amplitude response while affording a
rapid attenuation rate in the vicinity of the filter
cut-off point. The value of ω0 for the Chebyshev
corresponds to the angular frequency at which the
attenuation at the cut-off edge of the pass band is
equal to the ripple minimum in the pass band.
If the “ideal” to be achieved is that of flattest
amplitude response, the polynomial of choice will
be a Butterworth. An interesting property of the
Butterworth polynomials is that regardless of the
polynomial order, the poles are located on a
semi-circle of radius ω0 in the left half of the S
plane. Furthermore, for the second order Butter-
worth polynomial, which is the case here, α has a
value of 
. These pole locations are depicted in
Fig. 22-43.
In Fig. 22-43 the radius of the semi-circle is ω0,
the poles are complex conjugates, and they are sepa-
rated by an angular interval of π ⁄ 2. If the denomi-
nator had been third order, there would have been
three poles. One would be on the negative real axis
at −ω0. The other two would form a conjugate pair
placed such that the angle between a given pole and
its nearest neighbor would be π ⁄ 3. The pattern
Figure 22-42. Magnetic phonograph cartridge circuit.
r
C
ei
Vo
L
R
V0 S
( )
Ei S
( )
--------------
1
LC
-------
S2
L
R---
rC
+
⎝
⎠
⎛
⎞
LC
----------------------S
r
R
+
R
------------
⎝
⎠
⎛
⎞1
LC
-------
+
+
----------------------------------------------------------------------
=
V0 S
( )
Ei S
( )
--------------
1
LC
-------
S2
1
RC
--------
⎝
⎠
⎛
⎞S
1
LC
-------
+
+
-------------------------------------------
≈
V0 S
( )
Ei S
( )
--------------
ω0
2
S2
αω0S
ω0
2
+
+
-----------------------------------------
=
2

   
Signal Processing
511
continues in this fashion for all higher orders with
odd orders giving a single pole on the negative real
axis with attendant conjugate pairs. The even orders
contribute only conjugate pairs and for all order n,
the angle between any pole and its neighbor is π ⁄ n.
The analysis of the phonograph cartridge can
now be completed by comparing Eqs. 22-130 and
22-131 while requiring α to be 
. This compar-
ison leads to the identifications
(22-132)
The next step is to solve Eq. 22-131 for C to obtain
(22-133)
A typical high quality cartridge has an induc-
tance internal to its structure of 0.5 H. Additionally
the load resistance R is usually set at 47 k Ω . When
these values are substituted into Eq. 22-133, it is
found that the total allowable shunt capacitance in
order to obtain a maximally flat response is 
To find the cutoff frequency, use
(22-134)
Using Eq. 22-134, and the value of shunt capaci-
tance in the example, the cut-off frequency for the
cartridge circuit becomes
This value of the cut-off frequency is acceptable
but the low value of C forces careful treatment of
the preamplifier circuit and the phonograph
cartridge connecting cable. Fig. 22-44 displays the
amplitude response employing the values found in
the above example. The plot is in the form of
.
In the event the shunt capacitance is larger than
that required for the Butterworth, the response will
exhibit a peak as illustrated in Fig. 22-45.
Finally, Fig. 22-46 shows the result of working
with the exact form of the transfer function as
expressed in Eq. 22-129. In this instance, the L and r
values are those supplied by the manufacturer of a
well-esteemed cartridge, the R value is taken as
47kΩ , and C is calculated as before for optimum
loading.
A comparison of Figs. 22-44 and 22-46 indicates
that the error made in neglecting the internal resis-
tance of the cartridge is only a fraction of a decibel
and hence is insignificant.
Figure 22-43. Complex poles of second order Butter-
worth polynomial.
ω0(−0.707 + j0.7071)
ω0(−0.707 − j0.7071)
jω
σ
2
ω0
2
1
LC
-------
=
1
RC
--------
2ω0
=
C
L
2R2
---------
=
C
0.5
2 47,000
(
)2
---------------------------
=
113 pF
=
Figure 22-44. Amplitude response of optimally loaded
phonograph cartridge.
f0
ω0
2π
------
=
1
2π LC
------------------
=
f0
1
2π LC
------------------
=
21  kHz
=
20 dB
V0 S
( ) Ei S
( )
⁄
 vs. 
f
log
log
6
4
2
0
−2
−4
−6
−8
−10
100           101           102           103           104
Frequency
Cartridge with Optimum Loading
Amplitude Response (dB)

512
Chapter 22
In order to completely describe a system’s steady
state frequency response with sinusoidal excitation
one must describe the amplitude response as a
function of frequency or angular frequency and,
additionally, must describe the phase response as a
function of frequency or angular frequency. This
information is all contained in the complex transfer
function and can be separated out by examining
separately the magnitude of the transfer function
versus the chosen frequency variable and the angle
of the transfer function versus the chosen frequency
variable. Bode plots are a standard way of displaying
these results. The amplitude response as displayed in
a Bode plot is in the form of 20 dB times the log to
the base ten of the magnitude of the transfer function
versus log to the base ten of the chosen frequency
variable. The phase response as displayed in a Bode
plot is in the form of the phase difference between
the output and input, which is the phase of the
transfer function, plotted versus the log to the base
ten of the chosen frequency variable. Figs. 22-47 and
22-48 are the Bode plots for the phonograph
cartridge with optimum shunt capacitance.
22.3.2 Further Considerations
From the work thus far one might draw the
mistaken conclusion that transfer functions are
always dimensionless. This has been the case in the
cited examples as both the excitation and the
response have been voltages. This is certainly not
always the case. In electrical systems the excitation
may be a voltage or a current while the response
may be a current or a voltage. For those instances
where the excitation and response are similar quanti-
ties, the transfer function will be dimensionless. In
the other instances the dimensions will be those of
Figure 22-45. Amplitude response with excessive shunt
capacitance.
Figure 22-46. Response employing exact form of
transfer function.
6
4
2
0
−2
−4
−6
−8
−10
100           101           102           103           104
Frequency
Cartridge with Excessive Capacitance
Amplitude Response (dB)
6
4
2
0
−2
−4
−6
−8
−10
100           101           102           103           104
Frequency
Cartridge with Internal Resistance and Optimum Load
Amplitude Response (dB)
Figure 22-47. Bode plot of cartridge amplitude
response.
Figure 22-48. Bode plot of cartridge phase response.
6
4
2
0
−2
−4
−6
−8
−10
100           101            102           103            104
Frequency
Bode Plot of Amplitude Response with Optimum Load
Amplitude Response (dB)
3
2
1
0
−1S
−2
−3
100           101            102            103           104
Frequency
Bode Plot of Phase Response with Optimum Load
Phase Response (Radians)

   
Signal Processing
513
an admittance or an impedance. More particularly,
however, would be those instances where the system
under study is a transducer such as a microphone or
a loudspeaker. The excitation for a microphone is an
acoustic pressure and the response is a voltage. For a
loudspeaker just the converse is true, the excitation
is a voltage and the response is an acoustic pressure.
Thus the transfer function would have the dimen-
sions of volt per pascal (V/Pa) or pascal per volt
(Pa/V), respectively. In any event, the transfer func-
tion can be written in the form of a scaling factor,
which includes numerical sensitivity as well as the
appropriate dimensions, multiplied by a frequency
dependent term that is itself dimensionless.
(22-135)
In the foregoing, much has been said with regard
to allowable pole locations whether real or complex.
A physically realizable stable system is one whose
impulse response decays with time. In order for this
to be true each pole in the transfer function must
have a negative real part. Geometrically, this means
that all poles must be located in the left half of the S
plane. Given that this is the case, are there similar
restrictions with regard to the locations of the zeros
of transfer functions? The answer to this question is
in the negative. Zeros whether real, imaginary, or
complex can be located anywhere without any influ-
ence on stable system realizability. However, zero
locations do play a significant role with regard to a
system’s phase response.
System phase responses can be divided into the
two categories of minimum phase systems and
non-minimum phase systems. Physically stated, a
minimum phase system is one that can release its
stored energy in a minimum time. When viewed in
the frequency domain, however, minimum time
translates to minimum phase shift. This may be
explored by studying the impulse transient response
in the time domain or, alternatively, by comparing
the phase response in the frequency domain.
Consider two non-identical systems which possess
the same amplitude response but differ in their phase
responses. Can one construct such systems and, if
so, how do their pole-zero diagrams differ? To show
that such systems can be constructed, examine the
following two transfer functions.
(22-136)
(22-137)
In Eqs. 22-136 and 22-137, k is the same constant.
The amplitude response from Eq. 22-136 is
The amplitude response of Eq. 22-137 is
Even just a cursory examination of the ampli-
tude response expressions reveals their equality. The
difference between Eq. 22-136 and Eq. 22-137,
then, must be revealed in the phase responses. The
pole-zero diagrams for these transfer functions are
depicted in Fig. 22-49.
Eq. 22-136 describes a minimum phase system
and from Fig. 22-49 its phase response is
H S
( )
Scale factor with dimensions
(
)
=
Dimensionless frequency dependent function
(
)
Hm S
( )
k
S
3
+
S
1
+
(
) S
2
+
(
)
----------------------------------
=
Figure 22-49. Pole-zero diagram comparison.
Hn S
( )
k
S
3
–
S
1
+
(
) S
2
+
(
)
----------------------------------
=
Hm S
( )
k
ω2
32
+
ω2
12
+
ω2
22
+
---------------------------------------------
=
Hn S
( )
k
ω2
3
–
(
)2
+
ω2
12
+
ω2
22
+
---------------------------------------------
=
−3          −2         −1 
Real
Imaginary
ω
γ
β
α
γ
β
α
ω
Imaginary
Real
Minimum Phase
Non Minimum Phase

514
Chapter 22
(22-138)
Eq. 22-137 describes a non-minimum phase
system and, again from Fig. 22-49, its phase
response is
(22-139)
In writing Eq. 22-139 it must be noted that angles
are always drawn relative to the sense of the positive
real axis and hence the angle γ is 180° or π less the
angle included at the base of the triangle on the right
which is 
 These two phase responses
are displayed in Fig. 22-50.
In Fig. 22-50 ϕn is greater than ϕm at all finite
frequencies and only approaches equality with ϕm as
the frequency becomes infinite. The conclusion to
be drawn is that minimum phase systems are charac-
terized by having their transfer function zeros
located in the left half of the S plane or, in worst
case, on the imaginary axis. The importance of a
system being of the minimum phase type lies in the
fact that only minimum phase systems can be equal-
ized. The validity of this statement, although not
immediately obvious, will become apparent in the
next section.
22.3.3 Equalization
Equalization as applied to sound reinforcement
systems refers to the process of electrically modi-
fying the signal being fed to the system so as to
correct for some anomaly or anomalies exhibited by
the system’s natural behavior. Most systems are
built up of several subsystems, each of which have
individual transfer functions when considered as
stand alone devices. Fig. 22-51 is suggestive of such
a case.
The overall transfer function of the system will
be the product of the individual transfer functions
considered as stand alone devices under two circum-
stances. Each device is insensitive to source imped-
ance and load impedance or the individual transfer
functions have been determined subject to the
appropriate source and load impedances. Assuming
this to be the case,
This will be of the general form
(22-140)
In Eq. 22-140, a, b, c, etc. and α, β, γ, δ, etc. are
constants which define the locations of the zeros and
poles, respectively. If Hoverall displays anomalies in
regards to either its amplitude or phase character-
istic, a procedure exists for improving the overall
results under a restricted set of circumstances. This
procedure amounts to canceling a troublesome zero
by a superimposed pole and canceling a troublesome
pole by a superimposed zero. This procedure is
called pole-zero compensation or otherwise known
as equalization. The picture now becomes as in
Fig. 22-52.
The equalizer’s transfer function must have zeros
for the troublesome poles and poles for the trouble-
some zeros. Recall that for physically realizable
systems, however, the poles must be in the left half of
the S plane. Therefore if the original system
happened to have a troublesome zero in the right half
of the S plane, which it could have if the anomaly
Figure 22-50. Non-minimum and minimum phase
comparison.
ϕm
γ
α
–
β
–
=
ω
3----
⎝⎠
⎛⎞
atan
ω
1----
⎝⎠
⎛⎞
atan
–
ω
2----
⎝⎠
⎛⎞
atan
–
=
ϕn
γ
α
–
β
–
=
π
ω
3----
⎝⎠
⎛⎞
atan
ω
1----
⎝⎠
⎛⎞
atan
–
ω
2----
⎝⎠
⎛⎞
atan
–
–
=
ω 3
⁄
(
).
atan
Phase Comparison
Phase in Radians
Frequency
0     1      2      3      4      5     6      7     8      9    10
4
3
2
1
0
−1
−2
Figure 22-51. Simple reinforcement system.
Preamp
Amp
Hoverall
HmicHpreampHampHloudspeaker
=
Hoverall
k
S
a
+
(
) S
b
+
(
) S
c
+
(
)…
S
α
+
(
) S
β
+
(
) S
γ
+
(
) S
δ
+
(
)…
----------------------------------------------------------------------------
=

   
Signal Processing
515
were non-minimum phase, it would be impossible to
cancel this zero by a superimposed pole. Therefore
such a system could not be truly equalized. If one
were to attempt to experimentally equalize a
non-minimum phase system by, say, flattening its
amplitude response, this process would introduce
violent behavior in the phase response and vice versa.
The process of equalization is restricted to minimum
phase shift systems. When equalization is applied to
correct anomalies in minimum phase systems, the
correction in amplitude and phase behavior go hand
in hand and will occur simultaneously. Equalization
should only be applied to minimum phase systems
and even when it can be employed, it must be
employed with care so as not to force any subsystem
beyond its range of linear operation.
As an instance of a properly applied equalization
consider the following example. Fig. 22-53 displays
the amplitude response curve of a wide band loud-
speaker which has a single resonance centered on
1kHz.
The transfer function describing this system can
be written as the product of a transfer function
describing a loudspeaker without a resonance, Hl,
with a transfer function which describes the anoma-
lous resonance behavior, Hr , as given in Eq. 22-141.
(22-141)
In this particular case, the resonance produces a
6 dB peak in the amplitude response at the resonant
frequency. A transfer function which matches the
peak and overall shape of the resonance is given by
(22-142)
Writing Eq. 22-142 in the factored form as
presented in Eq. 22-140 more readily identifies the
pole and zero locations.
(22-143)
In both Eqs. 22-142 and 22-143, ω0 has the value
2000π. The two zeros in the numerator of
Eq. 22-143 are complex conjugates of each other
having negative real parts and thus are in the left
half of the S plane which denotes minimum phase.
Remember a zero is the value of S which makes the
expression zero. Similarly, the two poles in the
denominator are also complex conjugates of each
other having negative real parts and thus are also
located in the left half of the S plane. In order to
equalize this anomaly, the equalizer must have a
transfer function, He such that
(22-144)
The transfer function of the required equalizer
clearly must be just the reciprocal of the transfer
function of the anomaly. Therefore,
(22-145)
The transfer function required of the equalizer is
physically realizable as its poles are also in the left
half of the S plane. Furthermore this transfer func-
tion is also minimum phase as its zeros are also in
the left half of the S plane.
Figs. 22-54 and 22-55 display the Bode plots for
the resonant anomaly while Figs. 22-56 and 22-57
present those of the equalizer.
If one adds the two amplitude response curves,
Figs. 22-54 and 22-56, together point by point the
result is a flat line at 0 dB. Similarly, if one adds the
Figure 22-52. Simple reinforcement system with
equalizer.
Figure 22-53. Loudspeaker with resonance anomaly.
Preamp
Amp
Equalizer
101             102              103             104           105
Frequency−Hz
Loudspeaker With Resonance
110
105
100
95
90
85
80
SPL−dB
H
HlHr
=
Hr
S2
ω0S
ω0
2
+
+
S2
0.5ω0S
ω0
2
+
+
---------------------------------------------
=
Hr
S
0.5ω0
j0.866ω0
–
+
(
) S
0.5ω0
j0.866ω0
+
+
(
)
S
0.25ω0
j0.968ω0
–
+
(
) S
0.25ω0
j0.968ω0
+
+
(
)
------------------------------------------------------------------------------------------------------------------------
=
Hr He
1
=
He
S
0.25ω0
j0.968ω0
–
+
(
) S
0.25ω0
j0.968ω0
+
+
(
)
S
0.5ω0
j0.866ω0
–
+
(
) S
0.5ω0
j0.866ω0
+
+
(
)
------------------------------------------------------------------------------------------------------------------------
=

516
Chapter 22
phase response curves, Figs. 22-55 and 22-57,
together point by point the result is a flat curve at
0 radian. In other words the effect of the resonance
is exactly compensated for by the action of the
equalizer. The resulting overall response with the
equalizer in the signal chain will be that of a wide
band loudspeaker which is devoid of any resonance
as displayed in Fig. 22-58.
It should be remembered that the equalizer does
not remove the resonance from the loudspeaker. The
equalizer only reduces the amplitude and adjusts the
phase of the drive signal in the vicinity of the reso-
nance so as to negate the resonance’s effects in the
overall result.
The final curve displayed in Fig. 22-58 would
also be that of an idealized loudspeaker with 3 dB
down points at 20 Hz and 20 kHz and without any
anomalies resonant or otherwise. Needless to say
such a device, if available, would find a large
market. The qualitative behavior at the high and low
frequency ends of the response curve, however,
reasonably matches many real loudspeakers except
for the positions of the 3 dB down points. At the
high frequency end, the behavior is that of a low
pass filter while at the low frequency end, the
behavior is that of a high pass filter. In those
instances where this filter behavior is minimum
phase, many practitioners employ equalizers to
widen the bandwidth of narrow band loudspeakers.
This process increases the amplitude and modifies
the phase of the electrical drive signal at the
frequency extremes that, indeed, will extend the
range of response at the expense of requiring signifi-
cantly larger displacements and power dissipation in
the transducer. The larger displacements can easily
lead to non-linear behavior and attendant distortion
while the higher power can well produce thermal
failure. Such practices, therefore, should be
approached with extreme caution.
Figure 22-54. Amplitude response of resonance
anomaly.
Figure 22-55. Phase response of resonance.
101            102               103              104           105
Frequency−Hz
Anomaly Magnitude
7
6
5
4
3
2
1
0
Amplitude Response−dB
101             102              103             104           105
Frequency−Hz
Anomaly Phase
0.4
0.3
0.2
0.1
0
−0.1
−0.2
−0.3
−0.4
Phase Response−Radians
Figure 22-56. Amplitude response of corrective
equalizer.
Figure 22-57. Required equalizer phase response.
101             102              103              104           105
Frequency−Hz
Equalizer Magnitude
0
−1
−2
−3
−4
−5
−6
−7
Amplitude Response−dB
101             102              103              104          105
Frequency−Hz
Equalizer Phase
0.4
0.3
0.2
0.1
0
−0.1
−0.2
−0.3
−0.4
Phase Response−Radians

   
Signal Processing
517
Equalization is a powerful tool when intelligently
applied. When so employed, it can make a system
which is inherently good into an even better one. It
cannot, however, convert a poor system into a good
one. To quote an old southern expression, “You
can’t make a silk purse from a sow’s ear!”
22.3.4 Equalization—Global or Local
Equalization is both the most often used as well as
the most often abused signal processing function.
The foregoing example in which a loudspeaker’s
minimum phase type of anomaly was corrected is an
example of global equalization. The correction that
is invoked improves the quality of sound for all
listeners regardless of where they might be located
in the direct field of the loudspeaker. Global equal-
ization of a loudspeaker is both a legitimate and
desirable signal processing function. An accurate
accomplishment of such an equalization often
requires the services of a multi-band parametric
equalizer. Such equalizers allow adjustments for
filter frequency assignment as well as filter width
and depth.
Local equalization, when it can be legitimately
applied, improves sound quality at only one point
while adversely affecting sound quality at all other
points. In order to appreciate this we will explore a
simple example where local equalization is
employed to negate the effects of a single boundary
reflection. Fig. 22-59 depicts the physical situation
to be considered.
The listener in the figure only has the use of his
left ear. He foolishly may have spent too many hours
on the firing range without the benefit of hearing
protection. Consider that the depicted coaxial loud-
speaker is actually mounted in a properly sealed
enclosure and that its crossover is seamless. The
distances are such that the attenuated reflected
sound arrives two milliseconds after the direct sound
having undergone a broadband attenuation of 3 dB.
We will be very generous in describing the loud-
speaker response by giving it a second order Butter-
worth high pass and low pass characteristic with
–3 dB points at 20 Hz and 20 kHz. This is much
easier said than done! Upon letting t = 0 coincide
with the arrival of the direct sound, the transfer
function describing the direct sound aside from a
scale factor can be written as
(22-146)
where,
f0 is 20 Hz,
ω0 is 2πf0.
The amplitude and phase responses associated
with the direct sound appear in Fig. 22-60 and
Fig. 22-61.
The reflection has an amplitude that is 3 dB down
at all frequencies and is delayed in time by 2ms
relative to the direct sound and thus is described by
the transfer function
Figure 22-58. Overall response with equalizer in place.
101             102              103             104           105
Frequency−Hz
Loudspeaker
110
105
100
95
90
85
80
SPL−dB
Figure 22-59. Direct sound accompanied by a single
boundary reflection.
Figure 22-60. Direct sound amplitude response.
H
106S2ω0
2
S2
2Sω0
ω0
2
+
+
(
) S2
103 2Sω0
106ω0
2
+
+
(
)
---------------------------------------------------------------------------------------------------------------------
=
101                102                103                104
Frequency−Hz
3
2
1
0
−1
−2
−3
−4
−5
−6
Magnitude−dB

518
Chapter 22
(22-147)
The transfer function describing the combination
of the direct and reflected sound is then
(22-148)
Aside from a scale factor, Eq. 22-148 describes
the linear combination of the direct sound plus an
attenuated delayed reflection at the listener’s ear. One
would expect that the spectrum of this signal would
exhibit comb filter effects. This is indeed the case as
exhibited in both the amplitude and phase behavior of
this composite signal displayed in Figs. 22-62 and
22-63. Note that the displayed frequency range has
been restricted to 4000 Hz because of the narrow
spacing between interference notches.
The question at this point amounts to deter-
mining if it is possible to negate the effects of the
reflection through some equalization technique.
Mathematically, this amounts to inquiring what
steps must be taken to reduce Eq. 22-148 to
Eq. 22-146. From a mathematical point of view this
can be done through the multiplication of
Eq. 22-148 by the factor
The transfer function of the equalizer required to
perform this function thus must be
(22-149)
The question now becomes one of whether it is
physically possible to construct such an equalizer.
Remember, that in order to have a physically realiz-
able stable system, the poles for the transfer function
must have negative real parts. In examining
Eq. 22-149 it is found that the numerator is a
constant and hence there are no zeros associated
with the transfer function. The poles of the transfer
function are located at values of S for which the
denominator becomes zero. These values of S are
those for which
(22-150)
where,
n = 1, 3, 5, 7, ... all odd integers.
Figure 22-61. Direct sound phase response.
101             102              103             104           105
Frequency−Hz
Phase−Radians
2.5
2.0
1.5
1.0
0.5
0
−0.5
−1.0
−1.5
−2.0
HR
1
2
-------e
0.002s
(
)
–
S
=
HC =
106S2ω0
2
S2
2Sω0
ω0
2
+
+
(
) S2
103 2Sω0
106ω0
2
+
+
(
)
---------------------------------------------------------------------------------------------------------------------
⎝
⎠
⎜
⎟
⎛
⎞
1
1
2
-------
+
e
0.002s
(
)
–
S
⎝
⎠
⎛
⎞
×
1
1
1
2
-------e
0.002s
(
)S
–
+
----------------------------------------
Figure 22-62. Amplitude response of direct plus
reflected sound.
Figure 22-63. Phase response of both direct and
reflected sound.
101                        102                        103
Frequency−Hz
Magnitude−dB
5
0
−5
−10
−15
−20
101                        102                        103
Frequency−Hz
3
2.5
2.0
1.5
1.0
0.5
0
−0.5
−1.0
Phase−Radians
HE
1
1
1
2
-------e
0.002s
(
)S
–
+
----------------------------------------
=
S
500
2
(
)
 jn500π
±
ln
–
[
]
=

   
Signal Processing
519
In principle this equalizer is physically realiz-
able as all of the poles have negative real parts and
thus lie in the left half of the complex plane. The
poles are complex and considering all possible
frequencies, are infinite in number. In practice one
need consider only those that fall in the pass band of
the loudspeaker. Even with this restriction there are
at least 80 poles that must be considered. The ampli-
tude and phase responses of the required equalizer
are presented in Figs. 22-64 and 22-65.
The good news is that if an equalizer having a
transfer function described by HE is inserted in the
electronic chain then the one-eared observer will
experience only what would have been just the
direct sound from the loudspeaker. This is accom-
plished by distorting the drive signal to the loud-
speaker in such a way as to completely negate the
effects of the reflection. Notice that this requires a
drive signal boost greater than 10 dB at certain
frequencies accompanied by a cut greater than 4 db
at other frequencies. The boost of over 10 dB could
easily lead to headroom difficulties. Now for the bad
news. Even though the one-eared observer will be
well pleased, what about those observers exposed to
only the direct sound? The other observers will be
exposed to a sound field characterized only by the
product of the loudspeaker transfer function with the
transfer function of the equalizer. These observers
will experience a frequency response described in
Figs. 22-66 and 22-67.
In summary, global equalization should always
be applied to the direct field of the loudspeaker as
this improves sound for all observers. Local equal-
ization may indeed be possible but its application
may improve the sound at a selected point while
worsening the sound experienced at other points. As
a general rule, equalization should be applied with
care as one may well experience headroom difficul-
ties leading to distortion and perhaps loudspeaker
thermal failure.
Figure 22-64. Equalizer amplitude response.
Figure 22-65. Equalizer phase response.
101                        102                        103
Frequency−Hz
12
10
8
6
4
2
0
−2
−4
−6
Magnitude−dB
101                        102                        103
Frequency−Hz
0.8
0.6
0.4
0.2
0
−0.2
−0.4
−0.6
−0.8
Phase−Radians
Figure 22-66. Equalized amplitude response for
observers not exposed to the reflection.
Figure 22-67. Equalized phase response for observers
not exposed to the reflection.
101                        102                        103
Frequency−Hz
12
10
8
6
4
2
0
−2
−4
−6
Magnitude−dB
101                        102                        103
Frequency−Hz
3.0
2.5
2.0
1.5
1.0
0.5
0.0
−0.5
−1.0
Phase−Radians

520
Chapter 22
All of the foregoing analysis has dealt with
analog systems in which time is a continuous vari-
able and the signals involved were analog variables
such as continuous time dependent voltages,
currents, acoustic pressures, etc. We turn next to
digital systems where time is measured in discrete
intervals and the dependent variables are a sequence
of binary encoded values such as those issuing from
an ADC. System theory in this instance is based not
on the Laplace transform but rather on a related
discrete variable transform known as the Z trans-
form. It is important not to confuse the employment
of the Z symbol in connection with discrete systems
with the employment of the same symbol Z in
describing electrical impedance.
22.4 Digital Systems and the Z Transform
We will begin our study of digital system theory by
first examining an analog system that also can be
modeled digitally in an almost intuitive manner. In
connection with an analysis of the ensuing analog
and digital models Table 22-6 will prove to be of
great value.
The analog system consists simply of a two-input
summer and a length of transmission line such as a
section of co-axial cable (assumed to be lossless and
properly terminated). The signal transit time along
the cable from input to termination is taken to be a
fixed time denoted by T. This same time interval T
will also be taken as the sampling interval in the
corresponding digital system. A single line drawing
of the analog system appears in Fig. 22-68.
In performing system analysis of the analog
system of Fig. 22-68 we consider how the system
behaves under impulsive excitation so that the input
signal is taken to be δ(t ). The output signal is then
simply the sum of the input with a version of the
input that has been delayed by a time T. Upon
denoting the input signal by f(t ) and the output
signal by g(t ) we can write
(22-151)
The next step is to take the Laplace transform of
the input and the Laplace transform of the output.
The Laplace transform of the unit impulse is just 1
and the Laplace transform of the time shifted unit
impulse is just e–ST times the Laplace transform of
the unit impulse itself so that
(22-152)
The transfer function of the system is the
quotient of the output Laplace transform by the
input Laplace transform and is thus
(22-153)
The corresponding digital system single line
drawing is represented by Fig. 22-69.
The digital system of Fig. 22-69 has its input
provided by the data register at the output of the
ADC. The input is described by the numerical
sequence {f (nT )} where n can range over all integer
values from zero to infinity. Similarly the output is
described by the numerical sequence {g(nT )}. If no
signals have been applied prior to n = 0, the contents
of the shift register will be 0 as will be the contents
of the ADC’s data register. For n = 0, the data
register at the output of the ADC assumes a value of
1 while the contents of the shift register remain at 0.
When n takes on the value of 1 the contents of the
data register become zero and remain there as no
other signals are considered to be applied to the
Table 22-6. System Analysis Functions in Both Analog 
and Digital Domains
Items
Analog Domain
Digital Domain
Time
t
nT
Dependent 
function
f (t), g (t), etc.
f (nT), g (nT), etc.
Unit 
impulse
δ(t)
1
Complex 
plane
variable
S
Z = eST
Transform
F S
( )
f t( )e St
–
td
0
∞
∫
=
F Z
( )
f nT
(
)Z n
–
n
0
=
n
∞
=
∑
=
Figure 22-68. This is a simple analog system that is to
serve as a model for a corresponding digital system.
Figure 22-69. The corresponding digital system.
Co-ax Delay = T
In
Out
Σ
f t( )
δ t( )
=
g t( )
δ t( )
δ t
T
–
(
)
+
=
F S
( )
1
=
G S
( )
1
e ST
–
+
=
H S
( )
G S
( )
F S
( )
------------
=
1
e ST
–
+
(
)
=
Shift Register Delay = T
In
Out
Σ

   
Signal Processing
521
system. On the other hand, when n takes on the
value of 1, the shift register acquires the value 1 that
was formerly contained in the ADC’s register. The
shift register always lags the data register by one
sample thus introducing a delay of T just as did the
co-axial cable in the analog system. The summer
presents at its output the combined contents of both
the data register and the shift register. This behavior
is summarized in Table 22-7.
For the digital system under consideration the
exciting signal is considered to be a single unit
impulse applied at n = 0 hence all entries in the table
beyond n = 1 will be 0. The transfer function of the
system is now calculated by taking the Z transform
of the output and then dividing this transform by the
Z transform of the input. By following the descrip-
tion of the Z transform listed in Table 22-6 these
transforms are found to be
(22-154)
In writing the results of Eq. 22-154 it was recog-
nized that Z–0 = 1. The transfer function describing
the operation of this digital system is thus
(22-155)
When one substitutes the value of Z as listed in
Table 22-6 into Eq. 22-155 it is found that the
transfer function of the digital system has a mathe-
matical form identical to that of the analog system
from which it was modeled. This is an exceptional
case in that regard as will be learned when other
digital systems are examined. Many readers will
recognize that both the analog as well as the digital
system considered thus far constitute a comb filter
as they both simply add a given signal to a delayed
version of itself. There is a significant difference,
however, because in the analog world the delay
interval can take on any value whereas in the digital
world it is restricted to integral multiples of the
sampling interval. This will turn out to have far
reaching consequences. The digital system of this
example is a special case of a digital filter type that
is referred to generically as a finite impulse response
filter or FIR. It is called a finite impulse response
filter because its response to a unit impulse exists
for a finite interval of time. This is in contrast to
another type of digital filter known as the infinite
impulse response filter or IIR. The impulse response
of a stable IIR in principle endures for all time
though all the while diminishing as time increases.
The structures of IIRs differ from those of FIRs in
that the IIRs employ feedback from output to input
whereas the FIRs employ only feed-forward
techniques.
We return now to further analysis of our simple
analog and digital filters of the present example. In
the analog case, the complex frequency variable is S
and in the steady state S takes on the value jω = j2πf
where the signal frequency variable in principle can
range up to an infinite value. In the digital case, the
complex frequency variable is Z where Z = eST and T
is the reciprocal of the sampling frequency. In the
steady state S is again j2πf but the operating
frequency can range only up to one-half of the
sampling frequency. Beyond this limit aliasing rears
its ugly head. The maximum operating frequency in
a practical case is always held to less than this limit
prior to the digital sampling process. If we let fm
represent the operating frequency maximum at the
aliasing limit and f represent the signal frequency
variable then it is possible to write
(22-156)
The absolute magnitude of the exponential func-
tion representing Z is unity independent of the oper-
ating frequency and hence the imaginary frequency
Table 22-7. Digital Example Data Table
n
f (nT )
g (nT )
0
1
1
1
0
1
2
0
0
G Z
( )
g nT
(
)Z n
–
n
0
=
n
∞
=
∑
=
g nT
(
)Z n
–
n
0
=
n
1
=
∑
=
1
Z 1
–
+
(
)
=
F Z
( )
f nT
(
)Z n
–
n
0
=
n
∞
=
∑
=
f nT
(
)Z n
–
n
0
=
n
1
=
∑
=
1
=
H Z
( )
G Z
( )
F Z
( )
------------
=
1
Z 1
–
+
(
)
=
T
1
2fm
--------
=
Z
e
jπ f
fm
-----
=

522
Chapter 22
axis of the S plane between –jfm and +jfm is bent into
a circle of unit radius when displayed or mapped
into the Z plane. The interior of this circle contains
the entire contents of the left half of the S plane
between these frequency limits. This mapping is
displayed in Fig. 22-70.
In the steady state description of frequency all of
the points of interest lie on the unit circle as S = j2πf.
In doing pole-zero analysis, S = σ + j2πf and such
points are described in the Z plane in terms of polar
coordinates r, θ. These coordinates relate to those in
the S plane as expressed in
(22-157)
A typical point is indicated as a black dot in the S
plane. The coordinates of this particular point are
S = −(π ⁄ 2T ) + j(π ⁄ 2T ). The frequency value of this
point in the S plane corresponds to fm ⁄ 2 so it will
appear in the Z plane with θ = π ⁄ 2. The radial
distance from the origin will be r = e–π ⁄ 2. This corre-
sponds to a radial distance of about 0.2. Therefore
the Z plane point corresponding to the given S plane
point appears at a position immediately above the
origin of the circle at a distance of 0.2. The angle of
this location is the angle between the radial line
drawn to the point and the horizontal or real axis and
is the required π ⁄ 2. The given S plane point is thus
mapped into the Z plane.
The comb filter of our analog and digital
example is a crude form of low pass filter. The
frequency response in the digital case is obtained by
substituting S = j2πf into Eq. 22-155. The amplitude
response is given by the magnitude of the resulting
complex expression while the phase response is
given by the angle of the complex expression. After
the substitution for S has been made and Euler’s
Theorem is applied to the result, the expression for
the transfer function becomes
Upon calculating the magnitude of this complex
expression followed by some simplification, the
amplitude response appears as
(22-158)
The arctangent of the ratio of the imaginary to
the real part of the transfer function yields the phase
response. This expression can also be simplified to
yield
(22-159)
This last result is very significant as it indicates
that FIR filters are capable of producing exactly
linear phase responses.
A general FIR is constructed from a chain of
shift registers or a dedicated read-write memory
space along with a collection of multipliers and a
summer or accumulator as depicted in Fig. 22-71.
The transfer function for this filter is given by
(22-160)
In Eq. 22-160 N is the number of taps possessed
by the filter, the number of independent multiplier
coefficients available for shaping the filter’s
behavior, and the number of samples over which the
filter’s impulse response endures. If N were equal to
three then the transfer function would be
H(Z) = c0 + c1Z–1 + c2Z–2 and the impulse response
of this filter would endure over only 3 samples. FIR
digital filters are often called upon to have ampli-
tude responses that mimic those of standard analog
filters such as Butterworth, Chebyshev, etc.
One technique for accomplishing this is to adjust
the filter’s multiplier coefficients in such a manner
that the filter’s impulse response is a discrete time
version of the model analog filter’s continuous time
impulse response. Any reasonable degree of accu-
racy in fashioning the impulse response in this
manner can require a structure having a large
number of taps.
As an example we will take an analog first order
low pass filter as a structure whose amplitude
Figure 22-70. S plane to Z plane mapping.
S Plane
Z Plane
f = fm  ⁄ 2, Z = j
f = −fm  ⁄ 2, Z = −j
f = 0, Z = ej0 = 1
j2πfm
−j2πfm
f = ±fm , Z = ejπ = −1
r
eσT
=
θ
π f
fm
-----
=
H
1
π f
fm
-----
⎝
⎠
⎛
⎞
cos
j
π f
fm
-----
⎝
⎠
⎛
⎞
sin
–
+
=
H
2
πf
2fm
--------
⎝
⎠
⎛
⎞
cos
=
ϕ
πf
2fm
--------
–
=
H Z
( )
ci Z 1
–
(
)
i
i
0
=
i
N
1
–
=
∑
=

   
Signal Processing
523
response is to be mimicked by an FIR filter. It was
learned in continuous time system theory that the
impulse response of such a filter has a time behavior
of the form 
 where τ is the time constant of
the analog low pass filter. The impulse response is
matched between the continuous and discrete time
domains by requiring 
 where n
begins with zero and takes on the sequence of posi-
tive integers. The tap multiplier coefficients for the
FIR filter are then given by
(22-161)
In Eq. 22-161 i begins with zero and takes on the
sequence of positive integers up to the limit set by
the number of taps employed by the filter.
Eq. 22-161 is now substituted into Eq. 22-160 to
obtain an expression for calculating the desired
transfer function.
(22-162)
What is desired at this point is a closed form
expression for the transfer function in which the
number of taps, N, appears explicitly as a variable.
This will allow a trial and error method for choosing
the least number of taps required to obtain the
desired degree of accuracy of performance.
Denoting the total expression within the paren-
theses of Eq. 22-162 by the symbol x we will make
use of a well-known property of power series. When
the absolute magnitude of x is equal to or less than
one then
(22-163)
Upon applying this, Eq. 22-162 can be written as
(22-164)
Further exploration of Eq. 22-164 yields
(22-165)
At this point we replace x by the expression in
the parentheses of Eq. 22-162 for which it stands to
obtain
(22-166)
Finally, we recall that Z–1 = e–ST and in obtaining
the frequency response we must make the substitu-
tion S = j2πf. The amplitude response of the filter is
obtained by taking the absolute magnitude of
Eq. 22-166 after these substitutions are made. The
procedure at this point is then to take a trial value
for N, calculate the frequency response, and
compare its plot with that of the model analog filter.
The procedure is then to find the least value of N
that yields satisfactory results. The processing time
in the FIR, and hence its latency, is directly propor-
tional to N, so a premium is placed on small N.
Figure 22-71. Structure of an N tap FIR.
f(nT)
c0
c1
c2
cN−1
g(nT)
T
T
T
e
t τ
⁄
(
)
–
e
t τ
⁄
(
)
–
e
nT τ
⁄
(
)
–
=
ci
e
iT
τ-----
–
=
H Z
( )
e
T
τ---
–
Z 1
–
⎝
⎠
⎜
⎟
⎛
⎞
i
i
0
=
i
N
1
–
=
∑
=
xi
i
0
=
i
∞
=
∑
1
1
x
–
-----------
=
H Z
( )
xi
i
0
=
i
N
1
–
=
∑
=
xi
i
0
=
i
∞
=
∑
xi
i
N
=
i
∞
=
∑
–
⎝
⎠
⎜
⎟
⎜
⎟
⎛
⎞
=
H Z
( )
1
1
x
–
-----------
xN
1
x
–
-----------
–
=
1
xN
–
1
x
–
--------------
=
H Z
( )
1
e
T
τ---
–
Z 1
–
⎝
⎠
⎜
⎟
⎛
⎞
N
–
1
e
T
τ---
–
Z 1
–
–
----------------------------------
=

524
Chapter 22
When the above procedure is applied in generating
an FIR that mimics a first order analog low pass
whose cut off is at 500 Hz, it is found that good
results are obtained for N = 100 as displayed in
Fig. 22-72.
In constructing Fig. 22-72 the transfer function
of the FIR has been normalized to match that of the
analog filter at zero frequency. A departure between
the analog and digital frequency responses occurs
only in the vicinity of the Nyquist limit that in this
instance is at 20 kHz as the sampling frequency was
taken to be 40 kHz. The design technique employed
in the foregoing is not unique. It has been pursued
here as it is perhaps the most intuitive. There are
even more refined design techniques available for
designing both FIR and IIR filters. The author has
found those available in Matlab to be most valuable.
22.4.1 Recursive or IIR Filters
In the continuous time domain the laws governing
system operations are stated in the form of linear
ordinary differential equations. The corresponding
structure in the discrete time domain is called a
difference equation. In becoming familiar with this
we will again take an analog first order low pass
filter as our model and implement it now by means
of an IIR structure. The analog filter is governed by
a first order differential equation suggesting that the
starting point for the corresponding IIR filter will be
a first order difference equation. If {f (nT)} is the
input signal sequence and {g (nT)} is the output
signal sequence, then the governing equation is
written as follows with a and b playing the roles of
numerical constants.
(22-167)
This equation is implemented by the structure of
Fig. 22-73.
The transfer function of the circuit of Fig. 22-73
is found by taking the Z transform of each term in
Eq. 22-167 and solving for the ratio of the transform
of the output divided by that of the input. In doing
so it should be recalled that the Z transform of a unit
delay term is the transform of the undelayed term
multiplied by Z–1 therefore
(22-168)
The transfer function of Eq. 22-168 can be made
to conform to that of a first order low pass filter
through a suitable choice for the constants a and b.
Instead of matching impulse responses as was done
in the FIR example (although that could well be
done here) a different technique will be introduced.
In this technique the pole location of the model
analog filter will be mapped into the corresponding
location in the Z plane. The transfer function for the
model analog filter can be written as 1 ⁄ (τS + 1). The
pole for this transfer function is located at S = −(1 ⁄ τ)
where τ is the time constant of the filter either RC or
L ⁄ R as the case may be. In the analog case this pole
is located on the negative real axis at the point
σ = −(1 ⁄ τ). One now substitutes Z = eσT into H(Z)
and locates the pole by requiring the denominator to
be zero. One then solves the resulting equation for
the constant b.
Figure 22-72. Analog to FIR digital amplitude response
comparison.
100            101               102              103             104
Frequency−Hz
5
0
−5
−10
−15
−20
−25
−30
Magnitude−dB
Figure 22-73. Circuit implementation of first order
difference equation.
g nT
(
)
af nT
(
)
bg
n
1
–
[
]T
(
)
–
=
a
f(nΤ)
−b
g(nΤ)
Σ
Τ
G Z
( )
aF Z
( )
bZ 1
– G Z
( )
–
=
H Z
( )
G Z
( )
F Z
( )
------------
=
a
1
bZ 1
–
+
--------------------
=

   
Signal Processing
525
(22-169)
The transfer function can now be written as
(22-170)
Finally, in the analog case the amplitude
response is unity at zero frequency. When this is
also required of the digital filter, the final form of
the transfer function becomes
(22-171)
A comparison between the amplitude behavior of
this digital filter and its analog counterpart is
presented in Fig. 22-74. The sampling frequency in
this instance is again 40 kHz. As a result the ampli-
tude performance of the digital filter does not match
that of the analog as the frequency approaches the
aliasing limit of 20 kHz. The performance can be
improved in this region through the employment of
a considerably higher sampling frequency.
Fig. 22-74 contains only part of the story. One
needs to also compare the phase responses of the
two filters. This comparison is presented in
Fig. 22-75.
The well-known minimum phase behavior of the
analog filter is displayed in the lower curve of
Fig. 22-75. The digital filter tracks this at low
frequencies but diverges markedly above about
2kHz. A higher sampling frequency will bring about
some improvement but nevertheless non-minimum
phase behavior will still remain. The aberrant phase
behavior could be corrected through the employ-
ment of suitable all pass digital filters. This,
however, would require considerably more hard-
ware as well as design effort. There exist design
algorithms that evolve IIR filters that simultane-
ously match the corresponding analog versions in
both amplitude as well as phase responses. These
algorithms are based on the employment of second
order filter sections.
A second order section can produce a first order
section through the appropriate choice of constants
and filters of any order may be obtained by
cascading suitable numbers of second order
sections. The second order difference equation that
governs the structure of a second order section can
be written as
(22-172)
Upon taking the Z transform of Eq. 22-172 one
can solve for the transfer function to obtain
(22-173)
This general transfer function for the second
order section is called a biquad as it is quadratic in Z
in both the numerator and the denominator. The
Figure 22-74. IIR and analog amplitude response
comparison.
1
be
T
τ---
+
0
=
b
e
T
τ---
–
–
=
a
1
e
T
τ---
–
e
jπ
f
fmax
-----------
–
–
-----------------------------------
H Z
( )
1
e
T
τ---
–
–
1
e
T
τ---
–
e
jπ
f
fmax
-----------
–
–
-----------------------------------
=
101            102             103             104           105
Frequency−Hz
5
0
−5
−10
−15
−20
−25
−30
Amplitude Response−dB
Figure 22-75. IIR and analog phase response
comparison.
101        102          103         104           105
Frequency−Hz
0
−0.2
−0.4
−0.6
−0.8
−1.0
−1.2
−1.4
−1.6
Phase Response−Radians
g nT
(
)
a0 f nT
(
)
a1f
n
1
–
[
]T
(
)
a2 f
n
2
–
[
]T
(
)  b1g
n
1
–
[
]T
(
)
–
b2
n
2
–
[
]T
(
)
–
+
+
=
H Z
( )
G Z
( )
F Z
( )
------------
=
a0
a1Z 1
–
a2Z 2
–
+
+
1
b1Z 1
–
b2Z 2
–
+
+
----------------------------------------------
=

526
Chapter 22
general biquad is implemented by the arrangement
shown in Fig. 22-76.
We are now in position to correct the aberrant
phase behavior encountered earlier with regard to
the first order low pass filter. The procedure is to
map the pole or poles of the analog prototype
exactly in the Z plane. As the low pass was first
order with just a single pole then the coefficients a2
and b2 in Eq. 22-173 are set equal to zero. The phase
behavior is corrected by placing a zero in the numer-
ator that is not present in the analog prototype. This
zero is located at the aliasing limit so as to have a
minimum effect on the amplitude response. Recall
that the amplitude response was correct in the orig-
inal simple design. This step will require that a0 and
a1 be equal. Finally the common value of these coef-
ficients is adjusted to normalize the amplitude
response of the digital filter to equal that of the
analog prototype in the filter pass band. Finally in
order to make the filter more in accord with actual
practice we will now employ a sampling rate of
48 kHz. The transfer function for this digital filter
now becomes
(22-174)
The comparative performance of this improved
digital filter is presented in Figs. 22-77 and 22-78.
The phase behavior of this improved design is
almost an exact replica of the analog prototype
while the amplitude error is at most about 1 dB at the
frequency extreme of 20  kHz. This filter then
furnishes the required minimum phase behavior
while having only a minor amplitude error at the
frequency extreme. One final example that employs
the quadratic structure of the biquad is that of a
bandpass filter. We will consider a unity gain band-
pass filter having a bandwidth of one octave that is
centered on 500 Hz. The transfer function of such a
filter with a 48 kHz sampling rate is given by
(22-175)
The complex Z plane poles of this filter have
locations corresponding to those of the analog proto-
type. There are two zeros however. One of these is
located at ω equal to zero as in the analog case while
the second one that corrects the phase response is
located at the aliasing limit. The comparative perfor-
mance of the IIR and its analog prototype is
displayed in Figs. 22-79 and 22-80.
An examination of the figures reveals that the
amplitude error is at most about 1 dB at 20 kHz while
the phase curves overlay each other nearly exactly.
Figure 22-76. Hardware implementation of the general
biquad.
Σ
Σ
Τ
Τ
a0
f(nΤ)
−b1
−b2
a1
a2
g(nΤ)
H Z
( )
0.031699 1
Z 1
–
+
(
)
1
0.93660Z 1
–
–
---------------------------------------------
=
Figure 22-77. Analog and digital amplitude comparison
for an improved IIR filter.
Figure 22-78. Analog and digital phase comparison for
an improved IIR filter.
Magnitude−dB
Frequency−Hz
+5
0
−5
−10
−15
−20
−25
−30
 10 
100 
1000 
10,000
Frequency−Hz
Phase−Radians
0
−0.2
−0.4
−0.6
−0.8
−1.0
−1.2
−1.4
−1.6 1 
10 
100 
1000 
10,000 100k
H Z
( )
0.02262 1
Z 2
–
–
(
)
1
1.9506Z 1
–
–
0.95476Z 2
–
+
--------------------------------------------------------------------
=

   
Signal Processing
527
All of the time honored analog filters have accu-
rate IIR digital versions that can be implemented
through the employment of the appropriate number
of second order sections. The Linkwitz-Riley fourth
order filter, for example, would require a cascade of
two such sections with each being designed to
conform to a second order Butterworth. The IIR
filters employ feedback and hence can be unstable if
not properly designed. Stable filter structures in the
analog world require that all poles lie in the left half
of the S plane. The corresponding criterion in the Z
plane is that all poles are contained within the unit
circle. This is not a concern with FIR filters as these
filters do not employ feedback.
22.4.2 Linear Phase Filters
Certain FIR filters can be easily designed to possess
a linear phase shift characteristic. This is a property
that can only be obtained with difficulty through the
employment of analog filters. Linear phase shift
filters have no phase distortion in that they feature a
constant group delay and are highly desirable in
many applications. Linear phase shift requires that
ϕ  = −αω ± β. The group delay is the negative of the
derivative of this expression with respect to ω and
thus is equal to α independent of the constant β.
When β is equal to zero, the impulse response of the
filter in the Fourier sense is symmetric. When β is
π⁄2, the impulse response is anti-symmetric.
Most filter designs start with a requirement for a
particular amplitude response versus frequency. In
the case of digital filters, if one has a mathematical
description of the desired amplitude response
ranging over both positive and negative frequencies
it is possible to take the inverse discrete Fourier
transform of the amplitude response and obtain the
discrete time impulse response of the filter. When
considering both positive and negative frequencies,
the description of the amplitude response will be a
real and even mathematical function.
The impulse response sample sequence will then
be both real and even and thus symmetric about the
origin. Recall from the classical uncertainty prin-
ciple that when the amplitude response exists only
over a relatively small range of the frequency axis as
is true in the case of the audio spectrum, then the
impulse response must exist over quite a large range
of the discrete time axis. This means that the
impulse response sample sequence {h(nTS)} is
symmetric about n = 0 and has significant values out
to large values of n in both the positive and negative
directions. In our earlier simple introduction to the
FIR filter we learned that the various values of the
impulse response sequence determined the tap
weights of the FIR filter. In order to match exactly
the prescribed amplitude response function, the
filter would have to accommodate the entire impulse
response sequence and would be too long to be prac-
tical. It is necessary to truncate the impulse response
sequence. This truncation introduces differences or
errors between the desired response and that which
is actually achieved. These errors will be larger for
short FIRs and vice versa. We will now illustrate the
manner in which a causal FIR accommodates a trun-
cated impulse response. In order to keep the
numbers involved simple the example will deal with
an FIR that is too short for use in practice but will
clearly illustrate what is involved. The FIR of the
example has ten delay sections and eleven tap
weights and thus N = 11. The tap weights or multi-
plier values are ci with i ranging from 0 to 10. In
Table 22-8 the tap weights are positioned above
their respective values in terms of the impulse
response sequence values.
Figure 22-79. Analog and digital filter amplitude
comparison for an octave bandpass.
Figure 22-80. Analog and digital filter phase compar-
ison for an octave bandpass.
101            102               103              104  
Frequency−Hz
Analog IIR Band Pass Amplitude Comparison
5
0
−5
−10
−15
−20
−25
−30
Magnitude−dB
 100          101            102             103            104       105
Frequency−Hz
2.0
1.5
1.0
0.5
0
−0.5
−1.0
−1.5
−2.0
Analog, IIR Band Pass Phase Comparison
Phase−Radians

528
Chapter 22
The filter must accommodate the entire truncated
impulse response in order to approach the desired
amplitude response. In doing so it is necessary to
time shift the impulse response by 5 samples. It is
this shift in the time domain that brings about the
linear phase response in the frequency domain. The
final point to be dealt with is the question of the
errors that were introduced because the impulse
response was truncated. There exists a technique
from approximation theory called the Remez
exchange algorithm that can minimize and distribute
the errors in a meaningful and useful manner. This is
accomplished through small modifications to the tap
weights.
All of the above steps in FIR design have been
incorporated in computer based mathematics
programs. A notable such program is available in
Matlab© where it is described as being the Remez,
Parks-McClellan optimal equiripple FIR filter
design process. As an example, this process was
applied toward the design of a high pass filter with a
pass band edge or cut off at 2 kHz. The sampling
rate employed was 48 kHz. With this sampling rate,
the Nyquist frequency or fmax is 24 kHz. Excellent
performance was desired in the filter. The design
process was run through several iterations with the
number of taps being the variable. The final design
employed 151 taps. As a consequence, the impulse
response undergoes a shift of (N − 1)  ⁄  2 or
75 samples. The delay time through the filter is thus
75 times the sampling period of 1/48,000  s or
1.5625ms. The filter’s performance is depicted in
Fig. 22-81.
Actually there are ripples in the amplitude
response in both the pass band and stop bands of the
filter. These ripples are so small that they do not
appear with the amplitude scale employed. The
ripple amplitude is small as a result of the large
number of taps employed. As a comparison, the
filter was also designed while specifying just 21
taps. The performance in this case is displayed in
Fig. 22-82.
In Fig. 22-82 the ripples are more apparent for
two reasons. The ripples have larger amplitude as a
result of the reduced number of taps and the vertical
scale has been adjusted to more clearly display the
ripple effect. Notice also the overall phase change is
now much less as the signal is now delayed by only
ten samples.
The hardware types are the same for both FIR
and IIR filters. The differences appear only in the
hardware configurations and in the amounts of hard-
ware required to accomplish a given filter’s task.
Digital signal processing engines or DSPs contain
collections of the necessary multipliers, summers,
shift registers, memories, and controllers that may
be configured to accomplish the various signal
processing tasks in the discrete time domain.
22.5 Dynamics Processing
A dynamics signal processor sets the relationship
that exists between the changes in the voltage levels
at its output as compared with the changes in the
voltage levels at its input. This relationship may in
fact in some instances be a linear one. Even so, this
does not mean that the voltage level at the output is
the same as the voltage level at the input. Fig. 22-83
Table 22-8. Time Shift of Truncated Impulse Response
c0
c1
c2
c3
c4
c5
h(–5)
h(–4)
h(–3)
h(–2)
h(–1)
h(0)
c6
c7
c8
c9
c10
h(1)
h(2)
h(3)
h(4)
h(5)
Figure 22-81. High pass FIR filter with 151 taps.
Figure 22-82. High pass FIR filter with 21 taps.
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
Normalized frequency (Nyquist =1)
Normalized frequency (Nyquist =1)
Magnitude−dB
20
0
−20
−40
−60
−80
−100
0
−5000
−10,000
−15,000
Phase−Degrees
0 
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
0 
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
Normalized frequency (Nyquist =1)
Normalized frequency (Nyquist =1)
Magnitude−dB
5
0
−5
−10
−15
−20
−25
0
−500
−1000
−1500
−2000
Phase−Degrees

   
Signal Processing
529
graphically displays three instances of linear
processing.
In each of the three plots in Fig. 22-83 the
processing is said to be linear as a change of 10 dB
in input level causes a corresponding change of
10 dB in output level. Notice, however, that the
output level in the upper curve is always 20 dB
greater than that of the input indicating amplifica-
tion by a factor of 10. In the middle curve the input
level and output level are equal, indicative of unit
amplification. In the lower curve, the output level is
uniformly less than the input level by 20 dB thus
indicating that the output is attenuated by a factor of
10 relative to the input. This behavior is expressed
mathematically in the following fashion. Let Vo be
the output voltage either amplitude or root mean
square value. Similarly, let Vi be the corresponding
input voltage value and let a be a dimensionless
constant. In linear processing these quantities are
related through
.
(22-176)
The display in Fig. 22-83 deals with voltage
levels rather than just input and output voltages per
se. It is necessary then to divide both sides of
Eq. 22-176 by a voltage reference value, take the
logarithm to the base ten on both sides and multiply
both sides by 20dB to obtain
(22-177)
In writing Eq. 22-177 use has been made of the
fact that the logarithm of a product is the sum of the
logs of the multiplier and the multiplicand. When
one assigns a the values of 10, 1, and 0.1, respec-
tively, Eq. 22-177 generates the upper, middle, and
lower plots of Fig. 22-83.
Non-linear dynamics processing is more inter-
esting and is represented by the two distinctly
different categories termed expansion and compres-
sion. Expansion occurs when a small change in
input level produces a larger change in output level
such as a 1 dB change in input level producing a
2dB change in output level.
This is described as being 1 into 2 or 1:2. Simi-
larly compression occurs when a large change in
input level produces a smaller change in output level
such as a 2 dB change in input level producing a
1dB change in output level. This is described as
being 2 into 1 or 2:1. Fig. 22-84 graphically displays
both of these expansion and compression curves
along with a unity amplification linear reference.
The equation for the expansion curve can be
written by inspection of the upper curve in
Fig. 22-84.
(22-178)
If one solves Eq. 22-178 for Vo in terms of Vi it
will be found that Vo is proportional to Vi2. A similar
analysis applied to the compression curve shows
that for compression Vo is proportional to Vi1 ⁄ 2. In
general then, if n is the exponent applied to Vi,
expansion occurs for n > 1 while compression
Figure 22-83. Three examples of linear processing.
Unchanged
Linear Processing
−60 −50 −40 −30 −20 −10 
0 
+10 +20
Input−dB
Output−dB
+40
+20
0
−20
−40
−60
−80
Amplified
Attenuated
Vo
aVi
=
20 dB
Vo
Vr
------
log
20 dB
a
[ ]
log
20 dB
Vi
Vr
-----
log
+
=
Figure 22-84. Expansion 1 into 2 and compression 2
into 1 as compared with linear.
 −60 −50 −40 −30 −20 −10 
0 
+10 +20
Input−dB
Compression and Expansion Compared with Linear
Output −dB
+20
+10
0
−10
−20
−30
−40
−50
−60
Linear
Compression
Expansion
20 dB
Vo
Vi
------
log
2 20 dB
(
)
Vi
Vr
-----
log
=
20 dB
Vi
2
Vr
2
--------
log
=

530
Chapter 22
occurs for n < 1. If one desires an expansion of 1 dB
into 4 dB then n must have the value 4. If one desires
a compression of 4 dB into 1dB then n must have
the value 1⁄4. Both expansion and compression are
non-linear as a power law relates output to input. If
one applies expansion with a quite large value for n
such as n = 10 or more the process is termed gating.
Similarly if one applies compression with n = 1⁄10
or 1⁄20 the process is called limiting. Many
dynamics processing systems offer combinations of
the above mentioned possibilities. Such a system
might have a level in-level out behavior as depicted
in Fig. 22-85.
The processor of Fig. 22-85 features 1:2 expan-
sion for very low level signals, linear behavior for
low level signals, compression of 2:1 for interme-
diate level signals, and limiting of 20:1 as the input
approaches high levels. The transition points or
thresholds for the different processes as well as the
ratios employed in such an instrument might well be
under operator control. Additionally, such a device
might well feature a linear variable output gain stage
that could shift the entire plot either upward or
downward. For example an additional gain of 4 dB
would place the maximum limited output at 0 dB.
Recording studios might well employ all combi-
nations of dynamics processing, particularly when
recording to media of limited dynamic range and or
high noise floors. The reproduction of such record-
ings might well involve complementary dynamics
processing. The overall dynamics processing in such
instances is referred to as companding. The
processing involved in powerful sound reinforce-
ment systems usually consists of linear followed by
optional compression and limiting. In venues
possessing high ambient noise such as sports arenas
or for paging in industrial settings or transportation
centers compression is required to insure that the
average level of an announcer’s voice remains well
above the competing noise levels. Limiting is also
required in such systems to prevent excessive loud-
speaker diaphragm displacement and/or clipping in
power amplifiers.
Once the input level exceeds or falls below the
threshold for a given processing type, the applica-
tion or removal of the designated processing is not
instantaneous as such behavior would be not only
audible but also irritating to the listener. The onset
of such processing must be rapid enough to usefully
accomplish the goal while at the same time keeping
the audible distortion at an acceptable level. Simi-
larly the release of a given processing type must be
slow enough not to be noticeable but fast enough to
again accomplish the desired objective. The onset
and removal behavior is described in terms of attack
or release time constants for those analog control
systems that employ passive resistive charge or
discharge of storage capacitors in the level sensing
circuits. More sophisticated systems employ active
or constant current charging or discharging
techniques. Such systems can be characterized by
actual attack and release times. In both instances,
the time constants or outright times are usually
under operator control. In digital dynamics
processing the functions of level sensing as well as
the application or removal of a given processing
type are accomplished through calculations
involving actual sample values and the time histo-
ries as presented by sample value sequences. Algo-
rithms are employed that result in operations that
mimic or improve upon the behavior of the most
successful of analog systems.
As an example of attack behavior of a dynamics
processing system consider one in which the opera-
tion is linear as long as the input signal has an
amplitude less than 1.5 V and goes into hard limiting
when the amplitude exceeds 1.5 V. Consider also
that this processor is excited by a 1 V amplitude
1kHz sinusoid from t = 0 until t = 5 ms at which
time the input amplitude becomes 2 V and remains
there. The output of such a processor might well
appear as depicted in Fig. 22-86.
An examination of Fig. 22-86 reveals that the
output of the limiter overshoots the limit value of
1.5V and then approaches the limit value by means
of an exponential decay. The time constant, τ, asso-
ciated with this decay represents the attack time
constant of the limiting action. The envelope of the
output is described by
Figure 22-85. Combination dynamics processing.
Expansion 1 into 2
Compression 2 into 1
Linear 1 into 1
Limiting 20 into 1
Combination Dynamics Processing
−60 −50 −40 −30 −20 −10 
0 
+10 +20
Input−dB
Output−dB
+20
+10
0
−10
−20
−30
−40
−50
−60
Vo
1.5
0.5e
t
0.005
–
(
) τ
⁄
–
+
(
)
±
=

   
Signal Processing
531
Similarly, consider now that this same processor
has been excited for some time prior to a new t = 0
by a 2 V amplitude 1 kHz sinusoid and at the new
time of t = 5 ms the excitation amplitude drops to an
amplitude of 1 V and remains there. The recovery
behavior from the limiting action of this processor
under these conditions appears in Fig. 22-87.
Fig. 22-87 indicates that commencing at t = 5ms
the output of the processor undershoots the new
required value of 1 V and asymptotically approaches
the required value as t grows beyond 5 ms. The
envelope of the limiter output is now described by a
new equation with τ now being the release time
constant.
Many studies have been directed toward the
selection of viable values of attack and release times
for various types of program material. These studies
have involved principally subjective listening tests
as the final arbiter is often, “How does it sound?”
Many commercial dynamics processors have default
values for these parameters based on such studies.
Bibliography
G. M. Ballou. Handbook for Sound Engineers, 3rd edition. Boston: Focal Press, 2002.
R. J. Higgins. Digital Signal Processing in VLSI. Englewoods-Cliffs: Prentice-Hall, 1990.
M. S. Roden. Introduction to Communication Theory. New York: Pergamon Press, 1972.
Bernard Sklar. Digital Communications. Englewoods Cliffs: Prentice-Hall, 1988.
A. B. Williams and F. J. Taylor. Electronic Filter Design Handbook, 2nd edition. New York: McGraw-Hill,
1988.
Figure 22-86. Attack behavior of a limiter.
Dynamics Attack
0 
.002 .004 .006 .008 
.01 .012 .014 .016 .018 .02
Time−seconds
+2
+1.5
+1.0
+0.5
0
−0.5
−1.0
−1.5
−2.0
Volts
Figure 22-87. Release behavior of a limiter.
Dynamics Release
0 
.002 .004 .006 .008 
.01 .012 .014 .016 .018 .02 
Time−seconds
+1.5
+1.0
+0.5
0
−0.5
−1.0
−1.5
Volts
Vo
1
0.5e
t
0.005
–
(
) τ
⁄
–
–
(
)
±
=


Chapter 23
Digital Audio Formats and
Transports
by Pat Brown
533
23.1 The Analog Waveform . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 535
23.2 Quantization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 535
Reconstruction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 536
It’s Not Audio, It’s Data  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 536
Data Transport . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 537
The Infinite Conveyor . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 537
How Fast Must It Be?  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 538
Synchronization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 539
Jitter . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 540
Latency  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 540
Standard Data Formats  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 540
The Inner Workings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 542
23.3 Digital Signal Processing—DSP  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 542
23.4 Two Data Camps  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 543
Packet-Switched Networks  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 543
Network Bandwidth . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 543
23.5 How Does Ethernet Work? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 545
Who Are You in the Neighborhood? . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 546
23.6 Ethernet Protocols  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 546
The OSI Model  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 547
Quality of Service—QoS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 549
23.7 An Open Standard  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 549
23.8 AES3 vs. AoE  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 549
23.9 Hybrid and Proprietary Systems  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 549
23.10 Analog vs. Digital Audio . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 550
Which Digital Audio “Flavor?” . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 550
Learning Digital Audio  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 551


Digital Audio Formats and Transports
535
The intent of this chapter is to present the broad
concepts of digital audio sound reinforcement. The
inner workings of these systems are amazingly
complex, and each process is a field of study within
itself. If one invested the time and study to fully
understand each part of the digital signal chain,
there would be no time left to be an audio practi-
tioner. This bird’s eye view is intended to enable one
to be conversant in digital audio, and to make
informed decisions in selecting and deploying
digital audio products. There are a great many excel-
lent resources in-print and on-line for investigating
specific parts of the process in more detail.
Much of the information contained in this
chapter is the result of a collaboration with Steve
Macatee and Brad Benn in producing a digital audio
training course. Countless hours spanning several
years have gone into wading through the sea of
digital theory and identifying the fundamental
concepts required to grasp digital audio.
23.1 The Analog Waveform
Air pressure fluctuations can be converted to an
analog electrical voltage by use of a pressure-sensi-
tive microphone, Fig. 23-1. This audio waveform
can be converted to discrete values for transport or
storage. This is the very nature of digital audio,
Fig. 23-2.
Analog waveforms are digitized by voltage
sampling at a fixed time interval by an
analog-to-digital converter (ADC). The number of
available voltage values that may be assigned to
each sample is approximately 2N, where N is the
number of bits (ones and zeros) that represent each
sample. The more bits, the more available values,
and the greater the dynamic range. So, with regard
to fidelity “the more bits the better,” at least to a
practical limit.
According to Nyquist, the sampling rate must be
slightly higher than twice the highest frequency
present in the waveform to capture all of the audio
information that it contains. An anti-aliasing filter
may be used to force this condition, as it rejects
frequencies for which the selected sample rate is
insufficient. This is crucial. For example, if the
sampling rate is 48 kHz, the highest audio frequency
that can be resolved is approximately one-half, or
24kHz. An anti-aliasing filter at 24 kHz would assure
that no higher frequencies are fed to the ADC.
23.2 Quantization
The process of assigning a digital word to each
audio sample is known as quantization. A sample of
the analog waveform must be rounded to the nearest
discrete value as determined by the bit depth. An
error is produced from this rounding. The more bits,
the lower the quantization error. The accumulated
errors form the noise floor of the signal’s dynamic
range (DR).
The two-axis plot in Fig. 23-2 reveals the need
for sufficiently small amplitude steps on the Y-axis
(bit depth) and a sufficiently short time interval on
the X-axis (sample rate) to allow accurate recon-
struction of the original analog waveform. “CD
quality” of 16 bits and 44.1 kHz sampling rate is
well established as the minimum resolution for high
fidelity audio reproduction. It is exceeded by the
current analog-to-digital converters provided on
both consumer and professional audio products.
Both sample rate and bit depth can be increased or
decreased depending on the desired quality of repro-
duction. Lower resolution can be acceptable for
communication devices, such as telephones and
musical greeting cards. Most professional audio
devices are CD quality or better.
The string of bits can be divided into 8-bit words.
A 16-bit sample is two words. A 24-bit sample is
three words. The professional sample rate of 48 kHz
is slightly higher than that used for CD quality.
Doubling the sample rate adds one musical octave to
the audio bandwidth. This is the major reason for
96 kHz and192  kHz sample rates, the latter
producing an audio bandwidth approaching
100kHz. Increasing the sample rate also reduces the
minimum delay step (1 sample) available in digital
signal processors, which is an additional motivation
for increasing the sample rate beyond what is
needed to reproduce the audible spectrum.
A bit depth of 24 bits and a 48 kHz sample rate is
commonly presented as 24/48k. This is the default
Figure 23-1. Examples of analog waveforms.
Time–seconds
Amplitude–voltage
Music
Waveform
Sine
Wave

536
Chapter 23
resolution for most professional ADCs. This yields a
theoretical dynamic range of approximately 224, or
144dB. This is a mathematical resolution. In prac-
tice the actual resolution will be far less. A respect-
able system dynamic range, resulting from stringing
together a chain of digital audio devices, is about
100 dB—roughly CD quality.
23.2.1 Reconstruction
It is non-intuitive that a smooth analog waveform
can be recovered from a sampled waveform, espe-
cially at high frequencies where there may be only a
few samples collected. Digital-to-Analog converters
employ a reconstruction filter, usually in the form of
a low pass analog filter. The stair steps in the
sampled waveform consist of high frequency
content outside of the audio band. When it is
removed, a smooth analog waveform is the result,
Fig. 23-3.
23.2.2 It’s Not Audio, It’s Data
Once the analog waveform has been converted to a
binary code, we leave the continuous, intuitive
analog world and enter the deterministic, discrete
digital world. While a discontinuity, such as a
scratch on a phonograph record, is the worst thing
that can befall the analog signal, the digital signal is
discontinuous by nature. This is both good and bad.
The ability to slice and dice the analog signal into
small chunks offers some huge benefits with regard
to moving and storing the information. The power of
mathematics can be harnessed to process the data in
useful ways, including error correction algorithms
that can actually replace missing samples. But,
unless the data is properly reassembled, the subtle
distortions of the analog world give way to devasta-
tion in the digital world. The “snow” on an analog
TV screen, resulting from low signal strength, is
much preferred to the bedlam that results from
insufficient digital signal level. This reveals the
discrete nature of the digital signal.
A fundamental change in mindset is required to
understand what is important and what isn’t with
regard to digital audio. The interface must be able to
distinguish between two states, zero and one. If the
signal-to-noise ratio is sufficient for this distinction,
there is probably no benefit realized from improving
it, if the system passes the signal. While an analog
audio system may need 100 dB of dynamic range for
pristine reproduction, the digital system need only
be able to distinguish between two states to recog-
nize the binary code. In short, high dynamic range
analog can be transported over a comparatively low
dynamic range medium.
Fig. 23-4 shows the eye pattern test used to check
the integrity of the pulses. Note that the AES3
minimum allows significant deterioration of the
pulse from the ideal. Unlike analog interfaces,
digital interfaces typically either work or they don’t.
An impaired interface will yield silence, audio with
obvious artifacts, or something completely unrecog-
nizable and possibly devastating to a loudspeaker.
The “shades of grey” performance improvements in
the analog world, possibly realized by the use of
Figure 23-2. The analog waveform must be sampled at a frequency interval. Each sample is assigned a discrete 
value. The number of available values is determined by the number of bits (word length).
Approximating Amplitude/Frequency
Sample Rate
Bit Depth 
0
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
0
-6
-12
-18
-24
-30
-36
-42
-48
-54
-60
-66
-72
-78
-84
-90
-96
-102
-108
-114
-120
-126
-132
-138
-144
1
2
4
8
16
32
64
128
256
512
1024
2048
4096
8192
16384
32768
65536
131072
262144
524288
1048576
2097152
4194304
8388608
16777216
Practical device limit
Practical system limit
8
16
24 “Standard” word length
Bits(N)
DR
AD Values
More bits add
FOOTROOM!
DR = 6.0206 x N dB
Residuals
Samples
000010101001010101010001011010100101010111101010101000
8 bits
16 bits
24 bits
The data stream

Digital Audio Formats and Transports
537
esoteric methods, such boutique cables generally
don’t apply in the digital world. It’s data, not audio.
23.2.3 Data Transport
As with any type of cargo, the transport of digital
data involves moving it from point A to point B.
This broad term encompasses the many factors that
affect data movement. There exist numerous issues
and complexities regarding the transport of digital
data. As with all engineering practices, compromise
is required. The issues at the forefront are:
Data Rate. The rate at which the data flows in
bits-per-second.
Channel Count. The number of audio channels
interleaved into the digital stream.
Latency. Unintentional and unavoidable delay in
transporting the data.
Synchronization. Keeping all audio devices in the
system in step.
Formatting. Organization of the data stream so that
it can be recognized by the receiver.
As with analog audio theory, the principles of
digital audio are not unique to digital audio. I will
use a mechanically analogous system to aid in
describing the issues that affect data transport.
23.2.4 The Infinite Conveyor
The transport of digital audio data can be visualized
as a conveyor belt with one slot or placeholder for
each bit. This allows visualization of the serial data
stream as it flows through the signal chain. Rather
than moving continuously, the conveyor advances
one step at a time. The conveyor speed equates to
the data rate (or bit rate) of the transport system. The
blinding speed of the conveyor (measured in
millions of bits-per-second or Mb/s) makes the
movement appear to be continuous, even though it
moves in discrete steps. The audio words (the
payload) must be loaded onto the conveyor at the
source and removed at the receiver. The data rate
must be high enough to allow additional information
beyond the audio words to be interleaved into the
data stream. This “metadata” can be used to orga-
nize the audio samples into chunks that include
information important for recognition, decoding and
routing. Metadata may contain information about
the data, the data structure, or both. It is data about
Figure 23-3. A low pass filter smooths the waveform.

538
Chapter 23
data. The process of sampling the data and creating
the data stream is called coding.
The data must be decoded at the receiving device
to recover the audio information, which may then be
reconstructed into an analog waveform which is
theoretically identical to the original. The coding
and decoding processes are handled by a codec,
used here in a general sense. There are many types
of codes, the functions and details of which are
application-specific. The ADC is complemented by
a digital-to-analog converter, or DAC, which is the
final step of moving the analog waveform from
point A to point B in digital form. The DAC
contains a reconstruction filter, which low passes the
waveform to remove any residual out-of-band arti-
facts of the digitization process. This allows a
smooth, continuous analog waveform to be recov-
ered from the “stair stepped” analog waveform
created from the discrete samples, Fig. 23-5.
With the distinction made between coding, trans-
port, and decoding, one can see why the increases in
bandwidth accomplished over the last several
decades have vastly increased the capabilities of
digital systems of all types. There exist some
amazing possibilities if there is sufficient bandwidth.
23.2.5 How Fast Must It Be?
The minimum required bit rate for the audio
samples can be estimated by multiplying the word
length in bits times the sample rate, times the
number of audio channels. For example, for profes-
sional audio quality 16/48k stereo this works out to:
16 (48)(103)(2) = 1.54 Mb/s
For 24/96k data this increases to
24 (96)(103)(2) = 4.61 Mb/s
Figure 23-4. The eye pattern test used to check the
integrity of the pulses. Shown is the result of the test for
300 ft. of digital audio cable (passed) vs. 300 ft. of
foil-shield microphone cable (failed).
3
2
1
500m
1.5
2.5
0
500m
1.5
2.5
3
2
1
3
2
1
500m
1.5
2.5
0
500m
1.5
2.5
3
2
1
50n
100n
150n
Sec
V
 
Reduced by noise
or signal level
 
 
 r
c
 
 
Eye Pattern
4
2
0
4
2
100n
Sec
V
Digital Bit Stream
751n
1.077u
1.402u
1.728u
2.053u
2.379u
2.704u
3.355u
An overlay of ~120k data cells
-3
3
-2
-1
0
1
2
V
-3
3
-2
-1
0
1
2
V
0
150n
50n
100n
s
Slope due to reduced bandwidth
Reduced by jitter
AES3 Minimum
u
v
Figure 23-5. The codec codes and decodes the analog
waveform.
CODEC   (Coder-Decoder)
May be hardware or software

Digital Audio Formats and Transports
539
This simple example in Fig. 23-6 clearly illus-
trates the trade off involved in increasing the digital
resolution. If the data rate is fixed at 100 Mb/s, the
number of channels that can be transported is deter-
mined by the chosen resolution.
In consumer audio systems, relatively few chan-
nels are required. This means that high bandwidth
can be used to yield very high resolution digital
audio that (arguably) far exceeds the perception abil-
ities of the human auditory system. In professional-
audio systems, an unnecessarily high sample rate or
bit depth carries the premium of reducing the number
of audio channels. Fig. 23-7 shows how human
perception relates to sample rate and bit depth.
Note that while digital data is by nature discrete,
as the resolution is increased it eventually becomes
indistinguishable from analog audio. Although all
physical signals are intrinsically quantized, the
error introduced by modeling them as continuous is
vanishingly small. The error is overshadowed by
signal noise and instrument inaccuracy. This impor-
tant statement is obscure in its origins but none the
less true.
The data rate must be in excess of what is needed
to transport the audio samples alone in order to
accommodate the inclusion of metadata, without
which the binary code would be unrecognizable to
the receiving device. The details requiring standard-
ization include the data stream format (including
metadata), the medium (wire type or fiber) and the
interface topology, including connectorization.
23.2.6 Synchronization
A major concern in the development of the digital
audio interface was how to address the crucial timing
that must exist to keep multiple devices and audio
channels synchronized. A timing signal, usually at
the sampling frequency, is required and is known as
word clock. Word clock is the digital equivalent to
the timing belt used to synchronize the components
in an internal combustion engine, the failure of
which can be catastrophic. The timing signal origi-
nates at the master clock. This may be a stand-alone
device or one of the system components, usually the
mixer. The clock signal may be distributed to each
digital component (slave) in the signal chain by a
dedicated cable. Word clock transport is typically
over an unbalanced interface using coaxial cable and
connectors. It may be either impedance matched or
bridged, since the operating frequency is not
extremely high (i.e., 48 kHz). Bridging simplifies
word clock distribution in low cost digital audio
systems, such as a home recording studio, Fig. 23-8.
Some digital audio signal formats (AES3 and
S/PDIF) are self-clocking, meaning that the clock is
recovered from the data stream. This allows
multiple devices to be synchronized over the same
cabling that carries the data stream between them.
This simplifies the interconnection of components
because only one cable is needed.
Figure 23-6. Required data rate for digital audio transport.
1 0 0 1 1 1 0 0 1 1 1 0 0 1 0 1 1 0 1 0 0 1 0 0 1 1 1 0 0 1 1 1 0 0 1
* 
24 bits    x    48k    =    1.1 Mbits/sec* 
Needed
Dynamic Range
Needed
FrequencyRange
Required Data Rate for Payload
10Mb
20Mb
30Mb
40Mb
50Mb
60Mb
70Mb
80Mb
90Mb
100Mb
Data Rate for 1 Channel: ~1.5 Mb
Example Data Rate: 100 Mb
Approx. # of Serial Channels: 100/1.5 = 60
Multi-channel Digital Audio Requirements
Single-channel Digital Audio Requirements
plus some additional bandwidth required
for control signals, subcode, etc.
Data rate = bits/sec
Direction

540
Chapter 23
23.2.7 Jitter
Just as a mechanical conveyor may have some
“play” in the gears that skew the timing, the digital
audio interface is plagued by jitter, Fig. 23-9. If the
jitter becomes high enough, synchronization may be
lost. Jitter correction can be included in a digital
audio interface. Very high bandwidth transports
require very low jitter. It is incumbent to the audio
equipment manufacturer to achieve low jitter, and
the audio practitioner to preserve it by observing
good interfacing practices.
23.2.8 Latency
No matter how fast the bit rate, there is some unin-
tentional and unavoidable delay in the processing
and transport of digital audio, referred to as latency.
Each device in the signal chain contributes a latency
delay. It is cumulative and can eventually become
large enough to cause timing problems for a sound
system, such as sync between audio and video.
How much is too much? It depends. Even delays
of a few milliseconds can cause tonal coloration for a
musician playing a saxophone and listening through
an in-ear monitor. Audible delay can be perceived
when the latency between a live talker and the sound
system is 10 ms or so. The latency for a home hi-fi
system, can be hundreds of milliseconds with no ill
effects. So, the amount of latency that is tolerable
depends on whether there is an absolute reference for
the listener, such as a talker, singer, stage monitor or
video display. Many live sound system designers use
a “latency budget” of 10–15ms.
In contrast, analog systems do not exhibit
latency.
23.2.9 Standard Data Formats
There exists many possibilities for organizing the
binary data stream. Several standards were devised
early in the digital audio development process to
avoid having proprietary formats from each manu-
facturer. A century of analog audio development
paved the way for the digital formats. There are
some striking similarities between analog and digital
formats with regard to implementation and limita-
tions. At the forefront are the need for both
consumer and professional versions. The consumer
format and interface must be of high fidelity, low
cost and simple implementation. Short cable length
(a few meters at most) facilitates accomplishment of
these objectives. The professional data format and
interface adds complexity (and cost) in order to
drive longer cables and achieve higher data rates,
two goals that tend to be mutually exclusive. The
higher data rates can be used to transport large
numbers of audio channels, as might be found in
venues such as airports and performing arts centers.
The consumer format objectives are currently
met by the Sony/Philips Digital Interface, or S/PDIF.
The format standardizes the metadata and interface
topologies into an essentially “plug and play” inter-
face for transporting high resolution data with low
channel counts over short distances. Both wired and
optical mediums are available, as are low cost
methods for converting between the two. Like its
analog counterpart, the wired interface is unbalanced
Figure 23-7. Sample rate, bit depth and human
perception.
Figure 23-8. Word clock distribution methods.
Bits per Sample
Sampling Frequency
Higher
Sample
Rates
dB #bits
Residual Noise in 1 k7 resistor
Realizable Product Throughput
Equal
Loudness
Contours
Device One (slave)
Device Three (slave)
Star Distribution
Master Clock
WC Distro
Or
Mixer
(Set as 
WC Master)
Daisy-Chain Distribution
WC IN
WC IN
WC IN
WC OUT
WC OUT
WC OUT
AES3 Out
Signal Distribution
AES3 In
AES3 Out
AES3 In
Master Clock
Device Two (slave)
Device One (slave)
Device Two (slave)
Device Three (slave)
WC IN
WC IN
WC IN
WC OUT
Device One 
Device Two
Device Three 
Word Clock Distribution Methods

Digital Audio Formats and Transports
541
and utilizes coaxial cable and 2-conductor connec-
tors. The interface is impedance-matched at 75Ω
and the signal voltage is about 1 Vp-p.
The professional format objectives are met by
AES3 and its nearly identical European sibling,
AES-EBU. The data format is nearly identical to
S/PDIF, the difference being in some details
regarding the metadata. Like its professional analog
counterpart, the wired interface is balanced electron-
ically and requires a twisted-pair cable for trans-
port. Connectors are 3-conductor to accommodate
an optional cable shield. The interface is imped-
ance-matched at 110 Ω and the signal voltage is
3–7Vp-p. Conversion between AES3 and S/PDIF
can be accomplished with a passive network.
Other professional and consumer formats exist,
some of which support higher channel counts. While
the details may be different, in concept they are
similar to AES3 and S/PDIF, Fig. 23-10.
Both S/PDIF and AES3 can be carried over
cables designed for analog interfaces, which was
one of the requisites that influenced the standardiza-
tion of each interface. Since the interface must only
recognize two states—zero and one—the wiring
characteristics are actually more forgiving than for
analog signals until the data rate becomes very high
or the cable very long. “Digital audio cable” is
designed for lower capacitance per unit length than
wire designed primarily for analog use. This can
become a factor as the 100 meter limit for the basic
AES3 interface are approached or exceeded. Yes, a
“mic cable” can carry digital audio without degrada-
tion, ultimately limited by cable length. The high
twist ratio of Category cable (i.e., CAT 5 or CAT 6)
makes it suitable for carrying AES3 data. As with
balanced analog interfaces, the cable shield is not
Figure 23-9. Jitter can upset the delicate timing required for data transport.
1 0 0 1 1 1 0 0 1 1 1 0 0 1 0 1 1 0 1 0 0
1 0 0 1 1 1 0 0 1 1 1 0
Analog
Digital
ADC
Analog
Digital
DAC
r
0
1
0
Jitter
Payload
Data rate = bits/sec
Jitter Source
Clock
Additional Info
(Metadata)
Volts
Time
Jitter significance increases with data rate.
(measured in picoseconds)
Figure 23-10. Digital audio interface characteristics.
AES3
XL
Shielded Twisted-Pair
AES3id
BNC
Coax
Phono
Coax
S/ PDIF
TOSLINK
Fiber
S/PDIF
or
ADAT
Balanced
3-7 Vpp
110 Ω
100m
Unbalanced
1 Vpp 
75 Ω
1000m
Unbalanced
0.5 - 1 Vpp
75 Ω 
10m
SCMS Copy 
Protection
Pulsed Light
10m
1
2
3
4
5
6
7
8
9
10
11
12
13
14 
15
16 
17
18 
19
20 
21
22
23
24 
25
+
-
1/2 
3/4
5/6 
7/8
Inputs 
Outputs
1
2
3
4
5
6
7
8
9
10 
11
12 
13
14 
15
16 
17
18 
19
20 
21
22 
23
24 
25
/8 
6 
7
/ 
5
/4 
3
2 
/
1
Inputs 
Outputs
Tascam
+
- 
+
-
-
+
+
-
-
+
+
-
+
-
-
+
AES3
on
DB25
Reverse pairs on DB25-DB25!
(not TDIF)
Digital Audio Interface Characteristics

542
Chapter 23
required for signal flow for AES3, but serves the
purpose of:
1.
Containing the digital audio signal field.
2.
Rejecting extraneous fields.
3.
Reducing the chassis voltage difference between
source and load devices.
The electrical properties of video signal distribu-
tion were found to work well for AES3 audio. These
include an unbalanced 75Ω interface, coaxial cable
and active or passive splitters. The AES3id Standard
provides the details for transport over coaxial cable.
23.2.10 The Inner Workings
Both AES3 and S/PDIF are highly complex,
consisting of two interleaved audio channels orga-
nized into blocks, frames and subframes, Fig. 23-11.
There are always two channels present, even if both
contain the same information (mono).This conven-
tion was no doubt influenced by the stereo playback
system popular in consumer playback systems and
recording studios.
Returning to the conveyor belt analogy, the data
stream is flowing, even with no audio present. A
clock signal is recovered from the stream and is
sensed by the interface and used to indicate a
successful connection, known as achieving “lock.”
When lock is achieved, data is flowing. Some audio
devices provide visual indication that lock has been
achieved, as well as metering to observe the audio
being transported.
Sophisticated instrumentation is required for
detailed observation and analysis of the data stream.
In most cases, the audio technician needs only to
know if the clock signal and audio data are present,
which greatly simplifies the required instrumenta-
tion. Some products actually test the cable when a
connection is made, and visually indicate any faults.
A hand-held instrument can detect the clock (lock),
determine the sample rate and strip off the audio for
listening or measurement. It is the digital techni-
cian’s equivalent to the telephone butt set.
AES formats have expanded to accommodate
microphones (AES42) and high channel counts
(AES50).
23.3 Digital Signal Processing—DSP
One of the greatest strengths of digital audio is with
regard to signal processing. DSP has revolutionized
the sound reinforcement industry. It would be diffi-
cult today to find a sound system that does not
include a DSP. Once the analog waveform is repre-
sented numerically, the power of mathematics can
be used to process it in many ways.
Some digital signal processes merely emulate
their analog counterparts. The effect of the DSP on
the signal is indistinguishable from the analog
process, except for latency. This type of digital filter
is called an Infinite Impulse Response, or IIR filter.
Fig. 23-12 shows how an analog low pass filter could
be implemented digitally using mathematics. Note
that both filters are recursive, meaning that some of
the output is fed back to the input, making future
sample values depend on past sample values. In
theory, if fed an impulse such a filter never decays to
zero, hence the name. Most crossover and filter
blocks in a DSP use IIR filters. An IIR filter emulates
an analog filter in both magnitude and phase
response. This is important for loudspeaker equaliza-
tion applications where it is desirable to correct
minimum phase anomalies in the loudspeaker’s
response. In this application, the phase shift produced
by an analog filter, or an IIR digital filter is desirable,
since it is the conjugate of the phase shift in the
response bump or dip being corrected.
Figure 23-11. Details of the AES3 and S/PDIF formats.
192 frames, 12288 bits total
AES3, S/PDIF “Frame”
AES3, S/PDIF “Block”
AES3, S/PDIF “Subframe”
Audio Blocks
Misc
Audio Word
Aux
Info
Channel 1
Channel 2
Output
Input
AES3 S/PDIF Characteristics
Figure 23-12. Implementation of an IIR digital filter.
(Courtesy Steve Macatee.)
Digital Signal Processing (DSP)
x(t)
y(t)
1000 Ω
0.159 MF
1st-order low-pass
−3 dB
1 kHz
dB
F
Analog Filter
s

s
x(n)
y(n)
y(n−1)
1 sample
delay
scaling = 0.123
A = 0.877
coefficient
y(n) = x(n)*(0.123) + y(n−1)*(0.877)
1st-order low-pass
−3 dB
1 kHz
dB
F
based on 48 kHz sample rate
Digital Filter
Theory

Digital Audio Formats and Transports
543
A second type of digital filter is the FIR, or
Finite Impulse Response filter. An FIR filter is a
fixed length impulse response that is convolved with
the digital audio waveform, imparting its character-
istics upon it. Convolution can be used to encode
anechoic program material with the measured or
simulated impulse response of a room, allowing
evaluation of the room’s acoustical characteristics.
It could also be used to convolve a high pass
response onto the digital audio data, such as might
be used in a crossover network. FIR filters have the
interesting characteristic of being non-minimum
phase, meaning that there is no predictable relation-
ship between the magnitude and phase response of
the filter. This can allow the magnitude response to
be modified without changing the phase response. A
practical application is the formation of a very steep
high pass filter for protecting a high frequency
driver. A steep slope produced with an analog or IIR
filter would exhibit significant phase shift which
could be perceived as time smear by a listener. An
FIR filter could create the steep slope without
causing phase shift. The “Linear Phase Brickwall”
filter has become a favorite of loudspeaker
designers. But, there is no free lunch, as FIRs tend
to have longer latency than IIR filters, Fig. 23-13.
23.4 Two Data Camps
Of course the need to transport digital information
efficiently between sources and receivers extends
well beyond audio. Bits are bits, so there is the
potential to utilize other existing data delivery
schemes for the transport of audio. The massive R &
D and investment that has produced the wide band-
width local area computer network (LAN) for
offices can serve as a digital audio transport system.
There are two dominant means for the transport of
digital audio in professional systems. The first is the
use of audio industry-specific formats and interfaces.
These include AES3 and its variants. The second is
the use of Ethernet technology, as borrowed from the
computer networking industry. Several versions of
Audio-over-Ethernet (AoE) provide viable alterna-
tives to the dedicated audio formats.
23.4.1 Packet-Switched Networks
“Packet-switched network” is a general term for a
digital communications network that groups all
transmitted data, irrespective of content, type, or
structure into suitably sized blocks, called packets,
or datagrams. It is analogous to a shipping company
that uses the same carton or container to achieve
standardization, without regard for the content.
While in some ways similar to the frames used to
transport AES3 data, a packet can contain non-audio
data, allowing audio packets to be interspersed with
other, non-audio packets.
Conceptually, if we have an extremely fast, accu-
rate conveyor, and a means of accurately on-loading
and off-loading the ones and zeros, analog informa-
tion of all types can be transported to one or more
destinations. It is not unlike a train made up of a
multitude of cars carrying various types of cargo
from one destination to another. There are sources
and destinations, as well as terminals and rail yards
along the way that connect them. There is a label on
each package to indicate its origin and destination.
The key is to find a route from point A to point B,
Fig. 23-14.
Ethernet has emerged to become the dominant
type of packet-switched network used for the local
area network (LAN). An Ethernet network is
comprised of nodes interconnected through switches.
The nodes may be computers, printers or other office
appliances. A switch (or bridge) is a highly intelli-
gent multi-port device that routes the data between
the nodes. Nodes and switches are connected in a
star topology. Each node has a unique identifier to
distinguish it from other nodes on the network. This
may be a physical Media Access Control (MAC)
address, which all networkable devices are given at
the time of manufacture. If the device resides on the
Internet, there will be an additional Internet Protocol
(IP) address, that can be user-configured for a
specific system or application. An Ethernet switch
compiles a list of nodes connected to its ports. This
allows it to route incoming packets to their intended
destination, Fig. 23-15.
23.4.2 Network Bandwidth
We are now transitioning from the discussion of
dedicated digital audio formats to the discussion of
digital data transport in general. We have covered
many of the principles already, and will now expand
the discussion from point-to-point interfacing to
networks. The bandwidth of a network describes the
data rate or bit rate. A 10Base-T Ethernet network
runs at 10 Mb/s and uses twisted-pair (CAT 5 or
Figure 23-13. Convolving an impulse response of finite
length (.wav file) with dry program material.
Dry 
Wet 
IR 
Convolution 

544
Chapter 23
higher) cabling. Since a full-bandwidth audio channel
requires a data rate of about 1.5 Mb/s, several chan-
nels could be transported over a 10Base-T network.
Technological advancements produce increased
bandwidth, with typical bandwidth leaps of an
order-of-magnitude (ten-fold) occurring every few
years. With 100Base-T Ethernet (known as Fast
Ethernet), AoE becomes quite interesting to system
designers, as the channel count for full bandwidth
audio approaches 60. 1000Base-T (Gigabit) networks
promise to take this to nearly 600, making the
construction of very large, complex audio systems
with sophisticated routing a possibility, Fig. 23-16.
High bandwidth is a two-edged sword. As the
data rate increases, so do the details regarding the
cabling and connectors. Category cable (i.e.
CAT 5,CAT 5e, CAT 6) is a twisted-pair cable rated
based on crosstalk and system noise. 10Base-T and
100Base-T networks can be somewhat forgiving
IF
Figure 23-14. Using Ethernet as a means of audio transport.
1
 
0
 
0
 
1
 
1
 
0
 
1
 
1 1 0 1 1 0
Packetizing Data
Ethernet is the 
United Parcel Service
of Data Delivery
1. Standardized
2. Widely available
3. Strong infrastructure
Packaging
(packet or
datagram)
Routing Info
Prioritization
Error Checking
Unpacking
Delivery
Shipment
Interspersion
Sorting/Routing
Conversion
Video
Email
Web Page
Conversion
Go!
Stop!
Latency
Buffer
Audio Packet
TM
Figure 23-15. An Ethernet network. Any node can
communicate with the other nodes. The network traffic
is routed by a switch (bridge).
8P8C 
Connector
CAT5 Cable
Switch
Node
“Star of stars”
Ethernet Network

Digital Audio Formats and Transports
545
regarding cable installation and routing details.
Their needs are satisfied by Category 5 (CAT 5)
cables. A CAT 5 cable consists of four 24 AWG
twisted pairs sharing a common jacket. It is termi-
nated by the 8P8C connector, often referred to by a
telephone company wiring topology for which it is
used–RJ45. The “CAT 5 cable” has become ubiqui-
tous, sometimes being used to carry proprietary
digital data formats and even analog audio.
As the data rate (bandwidth) increases, the cable
requirements become more stringent. CAT 6 cabling
utilizes a larger wire gauge (22 AWG) to increase its
usable bandwidth. The impedance change caused by
a sharp bend or a tight cable tie can produce reflec-
tions and reduce the data integrity, requiring that
packets be resent by error correction algorithms if
the protocol supports it, thereby reducing the useful
bandwidth. In severe cases, drop-outs may occur.
1000Base-T networks require CAT 6 cabling.
The highest potential bandwidth is afforded by
fiber optic cabling, which uses pulsed light to
convey the bits rather than electrical potential. The
light can travel a long distance before it becomes
dispersed within the medium. Multi-mode fiber has
a large diameter relative to the signal wavelength.
The light reflects geometrically down the fiber and
is recovered at the receiving device. Single-mode
fiber has a small diameter relative to the signal
wavelength. It is analogous to the acoustical plane
wave tube. Single-mode fiber delivers the highest
possible bandwidth (or longer distance) at an
increased cost over multi-mode fiber.
Because the effect of dispersion increases with the
length of the fiber, a fiber transmission system is
often characterized by its bandwidth–distance
product, usually expressed in units of MHz×km. This
value is a product of bandwidth and distance because
there is a trade off between the bandwidth of the
signal and the distance it can be carried. For example,
a common multi-mode fiber with bandwidth–distance
product of 500 MHz×km could carry a 500 MHz
signal for 1 km or a 1000 MHz signal for 0.5km.*
Fiber optic terminations can be especially prob-
lematic. While analog cables can be checked by a
continuity test, high speed data networks require
specialized (and expensive) instrumentation for
testing. A third party may be contracted to certify
the cabling due to the expense of the instrumenta-
tion and the required expertise.
23.5 How Does Ethernet Work?
We have now transitioned away from audio, in a
textbook devoted to audio. There exist a vast
number of resources regarding data transport over
Ethernet networks. It is a field of study and expertise
Figure 23-16. Data rates and digital audio formats.
10 kb
20 kb
30 kb
40 kb
50 kb
60 kb
70 kb
80 kb
90 kb
100 kb
100 kb
200 kb
300 kb
400 kb
500 kb
600 kb
700 kb
800 kb
900 kb
1 Mb
1 Mb
2 Mb
3 Mb
4 Mb
5 Mb
6 Mb
7 Mb
8 Mb
9 Mb
10 Mb
10 Mb
20 Mb
30 Mb
40 Mb
50 Mb
60 Mb
70 Mb
80 Mb
90 Mb
100 Mb
100 Mb
200 Mb
300 Mb
400 Mb
500 Mb
600 Mb
700 Mb
800 Mb
900 Mb
1 Gb
1 Gb
2 Gb
3 Gb
4 Gb
5 Gb
6 Gb
7 Gb
8 Gb
9 Gb
10 Gb
Compressed Speech
Compressed Low Quality Music
Compressed  Avg. Quality Music
Stereo MP3  Typical
Highe
USB 3.0
r
Very High
PCM 16-bit Mono
PCM 16-bit Stere o
PCM 24-bit 48k Stereo
PCM 24-bit 96k Stereo
ISA  Bus
PCI Bus
RS-232
USB 1.x
Fire Wire 10 0
Fire Wire 200
Fire Wire 400
Fire Wire 800
USB 2.x
Bluetooth
802.11
802.11b
802.11a
802.11n
Ethernet 10Base-x
Ethernet 100Base-x
Ethernet 1000Base-x
AES3 - S/PDIF
MIDI
Data Rates in bits-per-second
*
Wikipedia—Fiber Optic Communication.

546
Chapter 23
in and of itself, in which the experts may need to
understand little or nothing about the actual data
flowing around the network. Their job is to ensure
that data that is streamed onto the network is deliv-
ered to its destination intact, and to minimize the
down time of the network. The vast majority of
audio practitioners only need a birds-eye view of
how Ethernet networks work, which I will attempt
to establish in the following sections.
23.5.1 Who Are You in the Neighborhood?
The MAC address is unique for every Ethernet
device in existence (node). It is assigned at the time
of manufacture, and cannot be changed. This is
called the physical address of the node. Depending
on the network type, devices may be given an addi-
tional virtual address, called the Internet Protocol
(IP) address.
An Ethernet network can be envisioned as a
neighborhood comprised of X streets with Y houses
on each street. Each street needs a unique identifier
(the Network ID), as does each house (the Host ID).
Only then can datagrams be properly routed from
house to house (node to node). The IP address is a
32-bit string that is divided into four octets,
Fig. 23-17. Part of this string designates the street
name (or subnet). This is the Network ID. The
remaining part designates the house number. This is
the Host ID. A subnet mask determines which bits
are the street name and which bits are the house
number. The subnet mask is a 32-bit string. The left
most bits will be “1” and the right most bits will be
“0.” It tells the network how to interpret the IP
address of a node. For example, if the first 24 bits are
ones and the final 8 bits are zeroes, this tells the
network to interpret the IP address as the first three
octets signifying the network ID and the final octet
signifying the Host ID. The subnet mask is usually
represented by decimal rather than binary values for
simplicity.
The Network ID must be the same for every node
on the network. The Host ID must be unique for
every node on the network.
For example, how I subdivide the 32-bit IP
address could allow a network with lots of streets
with a few houses on each, or just a few streets with
many houses on each. The IP address can be assigned
manually. While this can work for small networks, a
more sophisticated approach is needed for large
networks. A Dynamic Host Configuration Protocol
(DHCP) server can reside on a network and dole out
unique IP addresses for each device that is connected.
23.6 Ethernet Protocols
In computing, a protocol is a set of rules governing
the exchange or transmission of data between
devices. Many possibilities exist. An Audio-
over-Ethernet (AoE) transport system breaks the
digital audio stream up and transports it in packets.
Figure 23-17. Network node identifiers.
IP Address (Layer 3)
11111111.11111111.11111111.00000000
Binary
255        255         255           0
Decimal
1st Octet
2nd Octet
3rd Octet
4th Octet
1 Byte
1 Byte
1 Byte
1 Byte
192.168.1.100
255.255.255.0
The IP Address
is unique for every
host on the network
The Subnet Mask
Identical
Unique
Host/
Node
Network ID
divides the IP
 
address
into Network ID and
Host ID
Network Class
Class
Class A
Class B
Class C
Class D
Class E
Network T ype
Large 
Medium-sized 
Small (<256 nodes)
Multicasting
240 through 255
Identifiers
1 through 126
128 through 191
192 through 223
224 through 239
Reserved
Network  Address
1st byte
1st two bytes
1st three bytes
Host Address
last 3 bytes
last 2 bytes
last 1 byte
01:23:45:67:89:ab
MAC  Address (Layer 2)
Media Access Control  address
- or physical address
- unique identifier for Ethernet hardware
- typically assigned by manufacturer
- allows frames to be marked for
    specific hosts
- 48 bits in six groups of two HEX digits
 arp -a  at DOS prompt to see MAC addresses!
Who Are You (on the network)?
Network ID
Host ID
Subnet Mask Example
Ranges from 224.0.0.0 - 239.255.255.255

Digital Audio Formats and Transports
547
The data rates are high enough to allow non-audio
packets such as DSP control or even video to be
interleaved with the audio packets. AoE protocols
follow the Open Systems Interconnection (OSI)
layer model for data transport. The OSI model
provides a worldwide, abstract, theoretical frame-
work for understanding and discussing data trans-
port. A general understanding of the OSI reference
model provides the framework for understanding the
differences between the AoE protocols, as well as
problem solving.
23.6.1 The OSI Model
The workings of a computer network can be broken
down into layers, with each layer describing some
aspect of how the network works. Fig. 23-18 shows
the Open Systems Interconnection (OSI) 5-layer
model, which simplifies the original 7-layer model
by combining some of the upper layers. I’ll provide
an overview of the layers used for audio transport.
The layers are usually presented and visualized from
the bottom up, the variable between protocols being
how many layers (if any) above Layer 1 (the phys-
ical cabling) are used.
All of the data on an Ethernet network is in the
form of packets. A “packet sniffer” is a software
application that allows the packet activity to be
viewed and analyzed. All packets that flow over the
network contain routing information. The layers can
be thought of as the address label on a physical ship-
ment. The higher the layer, the more information
included on the label.
Layer 5 - Application.
Layer 4 - Transport.
Layer 3 - Network.
Layer 2 - Data Link.
Layer 1 - Physical.
Layer 1, the physical layer, describes the medium
over which the data travels. This could be copper
wire, fiber or even radio frequency transmission.
AoE that uses only Layer 1 is not technically
Ethernet. It just uses the media designed for
Ethernet. The user is shielded from the complexities
of the inner workings of the network, and is able to
realize many of the strengths of AoE in an essen-
tially “plug and play” implementation. AviomTM is a
commercial example.
Layer 2 protocols transmit Ethernet packets
containing audio samples from node to node based
on each device’s Media Access Control (MAC)
address. This is a unique identifier assigned to the
audio product by the manufacturer, and is some-
times called its physical address. It is like the street
address of a house, except that if the house is moved
the address goes with it. CobranetTM and Ether-
soundTM are commercial examples.
Layer 3 protocols can route audio data to a
device’s Internet Protocol (IP) address, a virtual
address that can be assigned by the user. The IP
address must be unique on a given network, so audio
devices that have the same IP address must reside on
different networks. If connected to the same
network, a conflict occurs that must be resolved for
data to flow. Routing audio data via the IP address
adds another level of sophistication and complexity
to the transport.
Audinate’s DanteTM is a commercial example.
Ethernet AVB is an open standard example.
These Standards are either licensed or proprie-
tary, where networking technology is a product unto
itself and forms a revenue stream for the company
who developed it. They cannot be intermixed nor
can a device using one AoE format directly commu-
nicate with one using another without a protocol
converter. It is very important to research the
strengths and weakness of each to decide which is
most appropriate for a given application.
An Example
Let’s use the OSI model to discuss the creation of a
digital audio network. The first decision is Layer 1.
What media do we wish to use to interconnect the
components? Our choices may include fiber, CAT-5
or coaxial cable. It is decided that CAT-5 will be
used, due to its widespread availability and low cost.
It is decided that CobranetTM, a Layer 2 protocol
will be used for transporting the digital data. We
Figure 23-18. The OSI Reference Model, and the layers
used by AoE protocols.
Audio-over-Ethernet
Copper
Ethernet
Copper/
Fiber
Ethernet
Copper/
Fiber
Ethernet
Copper/
Fiber
UDP
IP
Aviom
EtherSound
CobraNet
Dante
Ethernet
Copper/
Fiber
Ethernet
 
AVB
AoE
 
Technology
Application
Transport
Network
Data Link
Physical
OSI Model
1
2
3
4
5
Each  AoE technology has strengths 
and weaknesses!
Given the same sample rate and bit depth,
audio quality is the same.

548
Chapter 23
select some products that support Cobranet and
connect them to the network, and follow the manu-
facturer’s instructions for routing the data. The
MAC address of each device identifies it on the
network. Some of the audio devices require control
from a PC. The control data will be on Layer 3,
which means that each device will be given a unique
IP address, either manually or by a DHCP server.
The controlling PC is given IP address
192.168.0.100 with a subnet mask of 255.255.255.0.
This means that the devices that it controls will be
given an IP address with the same subnet mask
(255.255.255.0), the same network ID
(192.168.0.nnn) and a unique Host ID (.nnn). This
enables them to communicate on the network. This
will allow 254 devices to reside on the network,
which is the number of unique Host IDs allowed by
this subnet mask.
It’s now time to assess the bandwidth require-
ments of our audio system to determine if it can
reside on the customer’s existing network. It is deter-
mined that it can, so we request that a Virtual Local
Area Network (VLAN) be established by the
customer’s IT department to keep our audio traffic
off of the main network, and to keep the main
network traffic out of our audio. Their network
switches reside on Layer 3,which is required for the
establishment of a VLAN, Fig. 23-19.
The OSI Reference Model has allowed us to
discuss the establishment of the digital audio
network. We had several options for each layer, and
made our choices based on the specific application.
A future system design may use fiber on Layer 1,
and route both the audio and control data on
Layer 3, using an IP address to identify each device
in lieu of the MAC address. A Layer 3 protocol
Figure 23-19. A digital audio network. The nodes that use CAT-5 can be separate by up to 100 m. The 
fiber links allow much greater distances.
DSP
Cobranet
Interface
Other Audio
Formats
Biamp EXPI
HP ProCurve
Whirlwind CO2a
Rane NM 1
Rane Mongoose
Crown I-Tech HD
Renkus-Heinz
Rhaon
Soundweb London
AtteroTech
Matchbox
Mic Station
Network Switch
Interface
Box
Digital Mixer
Aes3-to-CobraNet
Interface
Card
CobraNet
Amplifier
CobraNet
Loudspeaker
CobraNetTM Audio-Over-Ethernet AoE

Digital Audio Formats and Transports
549
must be used, such as Audinate’s DanteTM. We
could then create separate subnets for each building
on a campus, allowing many audio networks to
function independently over the same Layer 1
media. A router could be used to allow the subnets
to pass data between them. Many possibilities exist.
23.6.2 Quality of Service—QoS
A major challenge regarding the use of Ethernet as
an audio transport is to ensure that the continuous
audio waveform can be reconstructed without
discontinuities, and with minimal latency. The audio
packets are flowing over the network interspersed
with non-audio packets. Small delays that occur
when downloading files or receiving emails are
generally acceptable. We give no thought to waiting
a few extra seconds for the information if the
network is busy. This is completely unacceptable for
real-time audio streaming, where delayed packets
could produce a discontinuity or drop-out in the
signal. The umbrella term for the discussion of data
packet priority and other delivery factors is Quality
of Service (QoS).
AoE can be given a high QoS through the use of
a dedicated network for the audio system. Ethernet
switches (bridges) are relatively inexpensive these
days, but unfortunately the installation of separate
cabling for the audio network may not be. It is
extremely attractive to the venue owner to utilize
their existing LAN for audio, which means that it
may also be carrying data for cash registers, credit
card transactions, emails, web surfing, etc. A Virtual
Local Area Network (VLAN) can segment part of
an existing LAN, allowing it to function as a stand-
alone network. It is common for audio system
designers to request (from the IT staff of a facility)
the establishment of a VLAN for AoE. The sound
system designer will be queried regarding the band-
width requirements of their design by the IT depart-
ment of the facility.
23.7 An Open Standard
An open standard is one that is developed and
agreed upon by a standards organization, such as the
IEEE or AES. Ethernet AVB is an IEEE Standard
that bridges audio and video into the same data
stream. It is a Layer 3 technology that addresses
some important issues for audio and video transport,
such as the need for high QoS, to give these packets
higher priority for delivery over the network. In
effect, Ethernet AVB establishes its own “protected
cloud,” giving high QoS to audio and video data.
Ethernet AVB is still in development but is expected
to emerge as a dominant AoE protocol.
It is highly non-intuitive for audio to be sliced up
at one end and pieced back together at the other end
to reconstruct a continuous analog waveform, yet
this is precisely how AoE works. There exists no
intuitive connection between transporting audio data
over Ethernet and the use of point-to-point transport
schemes like AES3 or analog. The need to acquire
IT skills is a major downside of AoE for the audio
technician, who is already tasked with mastering
many disciplines. This preserves the attractiveness
of audio industry-specific formats, such as AES3 for
many applications.
Given the same sample rate and bit depth, all
AoE technologies sound the same. As such, there is
no reason to migrate from one AoE protocol to
another to achieve better sound quality. There are
differences in latency that could be a factor for some
applications. The designer of a digital audio sound
system must know their “latency budget” and stay
within it to avoid timing problems.
23.8 AES3 vs. AoE
Which will win? Hopefully neither. There’s a strong
upside for having industry-specific protocols for
digital audio transport. Advantages include simpler
implementation, analog-like cabling and connec-
tors, and a similar point to-point mentality as analog
interfaces. AoE, on the other hand, rides on the huge
investment made by non-audio industries. Audio
can ride on the existing network backbone in large
facilities, sectioned off as a dedicated VLAN.
Low-cost switches and cabling allow the econom-
ical construction of dedicated audio networks,
where audio can be routed to any address on the
network. While implementation may require signifi-
cant networking knowledge and skills, this requisite
can be expected to diminish with time. Perhaps the
greatest benefit offered by AoE is its flexible routing
capabilities. One need no longer to think of signal
flow being confined to serially connected devices. A
signal processor can be connected anywhere on the
network to process a loudspeaker located anywhere
else on the network.
23.9 Hybrid and Proprietary Systems
Many engineering and medical solutions use the
strengths of multiple approaches to achieve a result
unattainable with any single method. This is also
true of digital audio systems. A modern audio
product may provide analog inputs to accommodate

550
Chapter 23
the sundry program sources that must interface to
the system. Add-on modules may provide addi-
tional analog or digital audio inputs that connect
back to the main unit using a digital interface. This
allows a system to be highly customized, yet retain
the simplicity of point-to-point connections using
network cabling. Many of the strengths of digital
audio can be realized while shielding the user from
the technical details, Fig. 23-20.
23.10 Analog vs. Digital Audio
If analog audio is from Mars, digital audio is from
Venus. Many variables, some subtle and some not,
affect the analog waveform. This has produced a
touchy, feely “shades of grey” medium in which
artistic preference may have as much influence as
“technical correctness.” Analog audio can “sort of”
work, and systems that are far from optimal may still
fulfill their intended purpose. Technical rules are
commonly bent and broken, a practice which may be
considered acceptable if the result sounds good.
Today’s analog standards and practices are the result
of over a century of technical evolution, and the
origins of many of them have faded into obscurity.
Digital audio is about quantization and data
transport, period. It is a deterministic process with
rights, wrongs and unforgiving rules that must be
followed. Errors in transmission can be checked for,
and in some cases corrected by the interface. If there
are sonic differences between digital audio formats,
they can typically be traced to the analog stages that
precede or follow the digital stages. The career path
that prepares one for digital audio is university or
vocational IT training, or perhaps serious self-study.
But ironically, having a computer science degree in
no way qualifies one to be an audio practitioner.
It must be remembered that analog is the stan-
dard by which digital is judged. Many applications
do not require the complexity and sophistication of
digital audio. Analog audio isn’t going away.
23.10.1 Which Digital Audio “Flavor?”
Many see the future of audio as being digital. But,
we know from experience that tried-and-true tech-
nologies may move to the background but they
never go away. Analog audio is high fidelity, robust,
reliable and intuitive. Even “all digital” systems
have analog links, such as the connection between a
power amplifier and a loudspeaker, or the loud-
speaker to the listener. While analog audio is a
mature technology that has enjoyed a long develop-
ment cycle, digital audio is a relatively new devel-
opment, still in its early evolutionary stages.
The major decision on the part of the system
designer regarding digital audio is whether to use a
dedicated audio format such as AES3, or an AoE
technology. As of this writing the dedicated formats
enjoy greater use in traditional sound reinforcement
applications that require point-to-point connectivity
such as portable systems and auditoriums. AoE
offers benefits attractive to very large, multi-purpose
buildings and campuses, such as convention centers,
airports and casinos. There is no doubt that these
distinctions will continue to fade.
Figure 23-20. Hybrid and proprietary approaches can simplify configuration and installation, while retaining sophisti-
cated capabilities. (Courtesy Rane Corp.)
Analog I/O
Remote Analog/Digital
I/O Modules via CAT 5
Ethernet from
Windows PC

Digital Audio Formats and Transports
551
23.10.2 Learning Digital Audio
Once the basic theory has been digested, the digital
audio learner must get their hands on some equip-
ment. This is where the nuances, quirks, exceptions
and requisites are experienced. Most manufacturers
of digital audio products provide tutorials, white
papers and demo software that cover the specifics of
their product line. The time spent reviewing these
materials and playing with control software will pay
big dividends and help you “connect the dots”
regarding how digital audio systems work.


Chapter 24
Sound System Equalization
by Don Davis and Eugene Patronis, Jr.
553
24.1 System Criteria . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 555
24.2 Early Research on Equalization . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 555
Feedback Defined  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 556
24.3 The Transient Nature of Acoustic Feedback  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 556
Growth . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 556
Decay . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 557
Early Practitioners . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 559
24.4 Introduction of Real-Time Analyzers  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 559
One-Third of an Octave Analyzers and Equalizers . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 560
Forty Years Later . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 561
RTA Applications  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 561
24.5 Band-Rejection, Bandpass, and Band-Boost Filters  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 562
Criteria for Band-Rejection Filters  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 562
Filter Parameters  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 562
Characteristics of Successful Filters  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 562
Filter Transfer Characteristics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 565
Minimum-Phase Filters . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 567
24.6 TEF Analysis in Equalization  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 567
24.7 How to Approach Equalization  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 568
When to Use an Equalizer . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 568
Sources of Feedback That Should Not Be Equalized  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 569
Feedback Is a Single Frequency  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 570
Which Sound Field Is the Microphone In?  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 570
24.8 What Can an Equalizer Equalize?  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 570
Mother Nature’s Way . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 572
24.9 A Real-Time Regenerative-Response Method of Equalizing a Sound System . . . . . . . . . . . . . . . . . . . 572
Where to Put the Microphone for Regenerative Response?  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 572
Degree of Correction Necessary  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 573
Using Sweep Oscillators  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 573
24.10 Equalizing for Playback . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 573
24.11 An Improper Use of Real Time Analysis in Monitoring Music and Speech . . . . . . . . . . . . . . . . . . . . 574
24.12 Diaphragmatic Absorbers  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 574
Room Absorption at Specular Frequencies . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 574
House Curves . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 574
24.13 Don’t Equalize for Hearing Loss . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 575
24.14 Proximity Modes  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 575
24.15 Checking Microphone Polarity  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 575
24.16 Loudspeaker Polarity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 576
24.17 Summary  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 576
Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 576


Sound System Equalization
555
The original one-third octave band rejection filter
set utilizing summing circuitry was first used by one
of the authors in 1967 and the patent 3,624,298 was
filed in March 1969 and issued in November 1971.
Since its inception the basic problems in its correct
use have been two fold: first, the ability to design a
sound system capable of benefiting from the use of
an equalizer, and second, the attempt to equalize the
unequalizable. These problems are with us more
than forty years later.
24.1 System Criteria
Equalization can’t solve loudspeaker coverage prob-
lems. Equalization can’t signal align loudspeakers.
Equalizers can’t raise acoustic gain unless the
system has adequate power available to support the
gain increase. Equalizers are of no use in controlling
reverberation, discrete echoes, etc.
Careful practice can minimize aggravating these
problems via regeneration through the sound
system. An equalizer can adjust the direct sound
pressure level of the loudspeaker’s minimum phase
output frequencies. This is accomplished by
providing the conjugate amplitude and phase
response to any minimum phase aberrations in the
loudspeaker’s direct sound level, LD.
Proper equalization adjusts both amplitude and
phase to a more uniform response. A delay in micro-
seconds is introduced by the insertion of the filters.
The measurement of both amplitude and relative
phase is essential in the process of equalization.
Group delay for a phono record can be years. The
delay through some adaptive digital filters can be
appreciable, +30 ms.
The triumvirate of proper equalization, signal
synchronization, and seamless coverage is a very
powerful tool used to create extraordinary sound
quality.
If the system is designed capable of benefiting
from equalization, constructed and installed so that
coverage is of the proper density, the electrical
power is adequate and matched to sufficiently effi-
cient transducers able to absorb it, and the entire
system is free from hum, noise, oscillations, and RF
interference, you are ready to equalize this system in
its acoustic environment to ensure the specified
tonal response and acoustic gain at each listener’s
ears. To do this requires insertion of the necessary
filters into the sound system and the taking of mean-
ingful acoustic measurements.
24.2 Early Research on Equalization
Insofar as the authors can discover, the earliest
researcher to correctly perform meaningful sound
system equalization was Dr. Wayne Rudmose, who
at the time of the work to be described was at the
Southern Methodist University, Dallas, Texas. Dr.
Rudmose published a truly remarkable paper in the
journal, Noise Control (a supplementary journal of
the Acoustical Society of America) in July 1958.
We feel the two most authoritative papers ever
published on this subject that have retained their
fundamental integrity many years later are
Dr. Rudmose’s and that of one of his students and
later an employee of Tracor, Inc. of Austin, Texas,
William K. Conner.
Conner’s paper “Theoretical and Practical
Considerations in the Equalization of Sound
Systems” first given at the 1965 AES Convention,
appeared in the April 1967, Vol. 15, No. 2 issue of
the Journal of the Audio Engineering Society. Amid
all the nonsense written on this subject, these two
papers stand as bedrock for the serious investigator.
In the fall of 1967, one of the authors gave the
first paper on a 1⁄3 octave contiguous equalizer.
Wayne Rudmose was the chairman of the session
and when the author referred to 1⁄3 octave as “broad
band” Rudmose raised his eyebrow and said “broad
band??” In 1969, a thorough discussion of acoustic
feedback that possessed absolute relevance to “real
life” equalization appeared in the Australian
Proceedings of the IREE. “A Feedback-Mode
Analyzer/Suppressor Unit for Auditorium Sound
System Stabilization” by J. E. Benson and D. F.
Craig, illustrated clearly the step function behavior
of the onset and decay of regeneration in sound
systems. The aforementioned papers relate the most
directly to modern practice and the application of
current devices to the adjustment of sound system
response. These four sources constitute the genesis
of modern sound system equalization.
Rudmose went on to not only introduce 1⁄3 octave
band analyzers, but to describe correctly the cause
of “howlback,” room resonance effects, cancella-
tions, and the “ringing” encountered in sound
systems. In this same paper Rudmose described the
devastating effects of transducer misalignments—
large holes in the amplitude response and the basic
importance of obtaining uniformity of distribution
prior to trying to equalize a sound system.
William K. Conner’s paper, originally given in
1965, clearly delineated the role of Q and distance
on the LD and 
 and LW on LR. The first thor-
oughly correct statements regarding useful ratios of
LD/LR and how to achieve them are presented here.
Conner’s paper identified the effect of humidity on
Sa

556
Chapter 24
the sound system’s response. Also he pointed out
that directional microphones have little to no effect
on the power loop gain of the system.
24.2.1 Feedback Defined
Feedback: “The return to the input of a part of the
output of a machine, system, or process.”
Feedback can be positive or negative in sound
systems. Positive feedback, carefully employed, can
raise gain. Negative feedback in amplifiers can lower
distortion. Hearing yourself speak over a sound
system is one form of feedback. It can be beneficial
over a monitor loudspeaker or detrimental when the
delay causes the talker to stutter. This is a psychoa-
coustic effect. Some talkers instinctively lower their
level upon hearing the monitor; others raise their
level, usually a matter of previous exposure.
Oscillatory feedback occurs when the signal
from the loudspeaker returns in phase to the open
microphone at a level equal to the normal input level
resulting in a single frequency “howling” tone.
Shock excitation of a sound system on the threshold
of sustained feedback may excite many simulta-
neous tones. The decay of these tones following
excitation may be observed on a fast real time
analyzer. These tones can then be compensated for
one at a time by sequentially introducing equaliza-
tion at the appropriate frequencies beginning with
the tone exhibiting the slowest decay.
The mathematical description given here is a
carefully specified single frequency example to
illustrate the complexity of the circuitous path. The
advent over the past generation of more controlled
frequency and polar responses has led to less need
of equalizers for the control of feedback. Engi-
neering trade offs, such as controlling directional
response at the expense of smooth frequency
response, can lead to the legitimate use of an
equalizer.
Benson and Craig’s detailed explanation of the
fundamental mechanism behind acoustic feedback
was first published in the March 1969 issue of the
Proceedings of the IRE of Australia. The paper was
entitled “A Feedback-Mode Analyzer/Suppressor
Unit for Auditorium Sound System Stabilization.”
Their analysis made use of the results from an
earlier paper by H. S. Antman entitled “Extension to
the Theory of Howlback in Reverberant Rooms”
that was published in J. Acoust. Soc. Am., Vol. 39,
No. 2, February 1966, p. 399 (Letters). A careful
study of both of these papers is highly recom-
mended. An abbreviated discussion of the more
salient points of these papers related to the transient
nature of the acoustic feedback process is presented
in the next section.
24.3 The Transient Nature of Acoustic Feed-
back
Acoustic feedback occurs whenever an open system
microphone is exposed to the sound field of the
system’s loudspeaker array. This means that except
for very unusual microphone locations, acoustic
feedback is always occurring. What is important,
apparently, is not whether acoustic feedback is
occurring but rather of the type and degree of the
feedback. It is well known that negative or degener-
ative feedback when judiciously applied in an
amplifier can have a desirable stabilizing influence
on the amplifier’s performance at the expense of
reducing the amplifier’s overall gain. On the other
hand, positive or regenerative feedback applied to
an amplifier destabilizes the amplifier’s perfor-
mance, increases its gain, and, if present to a suffi-
cient degree, leads to sustained oscillation. Acoustic
feedback in a sound system behaves in a very
similar way. The major distinctions between the
amplifier case and the sound system case have to do
with the feedback path. In the amplifier case the
feedback path is usually well defined and the transit
time through the feedback path is usually negligibly
small. In the sound system case the feedback paths
are numerous with appreciable transit times that are
dependent upon physical path length.
Consider the simplified situation depicted in
Fig. 24-1.
24.3.1 Growth
In Fig. 24-1, μ represents the feed forward transfer
function of the system. It is made up of the product
of the transfer functions of the microphone, ampli-
fier, and loudspeaker. In the absence of any feed-
back, if p1 is the acoustic pressure at some reference
distance from the microphone, then the acoustic
pressure at a similar reference distance from the
Figure 24-1. Schematic diagram of an elementary
sound system with an acoustic feedback path.
p1
p2
βp2
β
μ

Sound System Equalization
557
loudspeaker would be p2 = μ p1. In the general case μ
would be a complex function of frequency. Similarly,
in Fig. 24-1, β represents the feedback transfer func-
tion. It, too, is a complex function of the frequency in
the general case. As mentioned earlier there are
normally many parallel feedback paths, each with
their own particular value of β. In our simplified
example we will consider only a single feedback
path along which there exists a transit time of
amount Δt = d ⁄ c where d is the path length and c is
the sound speed. When p1 is first applied to the
microphone, the loudspeaker almost instantaneously
produces an acoustic pressure p2 = μp1. After the
elapse of an interval of time Δt, a feedback signal of
amount βp2 = μβp1 arrives at the microphone.
Assuming that the original acoustic pressure is
still present, the signal at the microphone now
becomes p1 + μβp1 = p1(1 + μβ) and the output now
instantaneously jumps to p2 = μp1(1 + μβ). After the
elapse of a second time interval Δt, the input
becomes p1 + μβp1 + (μβ)2p1 = p1[1 + μβ + (μβ)2]
and the output instantaneously becomes
μp1[1 + μβ + (μβ)2]. At this point it is safe to gener-
alize the result for an arbitrary number of delay
intervals N. After N delay intervals or a total time
NΔt, the output pressure will be given by
μp1[1 + μβ + (μβ)2 + (μβ)3 + … + (μβ)N]. The anal-
ysis so far has placed no restrictions on either μ, β,
or on the product μβ.
They can each be either real or complex. The
remainder of the discussion is greatly eased by
requiring only that |μβ| < 1, that is, the absolute
magnitude of the product of μ with β be less than 1.
When this is true the series describing the output
converges to the value μp1[(1 − (μβ)N + 1) ⁄(1 − μβ)].
Remember that this output pressure was originally
the result of an input pressure signal of p1. Now if N
becomes very large, the term (μβ)N + 1 becomes
vanishingly small and the output divided by the
original signal input, system transfer function or
gain, becomes μ ⁄ (1 − μβ). This last expression is
exactly of the same mathematical form as that for a
feedback amplifier. We can simplify the analysis
from here on and still obtain meaningful results by
letting p1 be the acoustic pressure associated with a
single frequency tone such as 1000 Hz and require
that the feedback path is of such length that the
return signal is in phase with p1. This would consti-
tute a case of pure positive feedback. With such a
restriction, both μ and β can be taken as real quanti-
ties. Let μ = 20 and β = 0.03. The steady state gain
with feedback becomes 20 ⁄ [1 − (20 × 0.03)] = 50.
The gain in the absence of feedback is of course μ or
in this case 20. The gain ratio is the gain with feed-
back divided by the gain without or 50 ⁄ 20 = 2.5.
The gain increase brought about by this positive or
regenerative acoustic feedback expressed in decibels
is 20log 2.5 = 8 dB. The effect of this regenerative
feedback has been two-fold. Not only has the steady
state gain been increased by a really significant
amount but also the output arrives at its ultimate
value through a series of steps.
24.3.2 Decay
The decay is initiated by the removal of the input p1.
When p1 is removed, the output drops suddenly by
an amount μp1 while the input continues to be
supplied by the feedback component βp2 that had
left the loudspeaker before p1 had been removed.
This continues for a time Δt during which the output
remains at the value μβp0 where now p0 is the value
of the output at the time p1 was removed. At the end
of the interval Δt, the input suddenly drops to μβ2p0
thus producing a new output (μβ)2p0. This new
output persists again for a time Δt. In this fashion
the output falls in a series of steps such that after the
elapse of N intervals it has become (μβ)Np0 and the
gain ratio has become (μβ)Np0 ⁄ μp0.
Fig. 24-2 displays the growth and decay of
regenerative acoustic feedback for μ = 20 and
β = 0.03. These values produce a steady state gain
ratio of 2.5.
In Fig. 24-2 the exciting signal is removed at
N = 20. Note the slow growth and prolonged ringing
brought about by the large amount of positive feed-
back. The system will become completely unstable
if μβ becomes 1. In the complete absence of feed-
back, the gain ratio would step up to 1 at 0 and
Figure 24-2. Gain ratio versus, N, the number of
traversals around the feedback loop.
Growth and Decay with Positive Acoustic Feedback
0            5            10           15          20           25           30
Loop traversals, N
3
2.5
2
1.5
1
0.5
0
Gain ratio

558
Chapter 24
immediately step down when the exciting signal is
removed. Fig. 24-3 shows the situation that exists
when the positive feedback is less. In this instance,
μ = 20 and β = 0.01. These values produce a steady
state gain ratio of 1.25.
In comparing Figs. 24-2 and 24-3 one can
conclude that a larger amount of positive feedback
increases the gain ratio and brings about a slower
stepwise approach to steady state conditions
followed by a longer decay after the removal of the
exciting signal. Please see Chapter 14 Designing for
Acoustic Gain, Section 14.6, The Feedback Stability
Margin where the early experimental results of
William B. Snow point out the dangers inherent in
large amounts of positive acoustic feedback.
Negative acoustic feedback also has some undesir-
able acoustic consequences. This is brought about by
the relatively long transit time, Δt, around the feed-
back loop. In a practical case Δt can easily be several
milliseconds. Fig. 24-4 illustrates the case where a
large amount of negative acoustic feedback is present.
In this instance the feedback signal is always of the
opposite polarity to that of the exciting signal.
The steady state gain ratio for the conditions of
Fig. 24-4 is given by 1 ⁄ (1− μβ) = 0.625. When the
initiating signal is turned on at N = 0, the gain ratio
first overshoots its steady state value of 0.625 and
then approaches the steady state value by means of a
set of oscillatory steps. At N = 20, the exciting
signal is removed and the gain ratio now approaches
zero through a sequence of constantly diminishing
steps. If no feedback had been present, the gain ratio
would have stepped immediately up to one at N = 0
and would have stepped down immediately to 0 at
N = 20 when the exciting signal was removed. This
situation should be compared with a case of a
smaller amount of negative acoustic feedback as
illustrated in Fig. 24-5.
In Fig. 24-5, the steady state value of the gain ratio
is 0.8333. It should be evident that even negative
acoustic feedback distorts the time behavior of the
original acoustic signal. Negative acoustic feedback,
however, can never produce sustained system oscilla-
tion as is true in the positive acoustic feedback case.
In the numerical examples we have taken both μ and
β to be real numbers just for the sake of simplicity.
The general equations are equally valid when they are
complex quantities. In such an instance, positive
feedback occurs when |1 – μβ| < 1 and negative
acoustic feedback when |1 – μβ| > 1. The case where
|1 – μβ| = 0 is to be avoided at all costs.
Figure 24-3. Growth and decay with a reduced amount
of positive acoustic feedback.
Growth and Decay with Positive Acoustic Feedback
0            5            10           15          20           25           30
Loop traversals, N
3
2.5
2
1.5
1
0.5
0
Gain ratio
Figure 24-4. Behavior with a large amount of negative
acoustic feedback.
Figure 24-5. The behavior with a small amount of nega-
tive acoustic feedback.
Growth and Decay with Negative Acoustic Feedback
0            5            10           15          20           25           30
Loop traversals, N
Gain ratio
2.0
1.8
1.6
1.4
1.2
1.0
0.8
0.6
0.4
0.2
0
μ = 20
β = −0.03
Growth and Decay with Negative Acoustic Feedback
0            5            10           15          20           25           30
Loop traversals, N
Gain ratio
2.0
1.8
1.6
1.4
1.2
1.0
0.8
0.6
0.4
0.2
0
μ = 20
β = −0.01

Sound System Equalization
559
24.3.3 Early Practitioners
Equalization was employed by many early experi-
menters including Kellogg and Rice in the early
1920s, Volkmann of RCA in the 1930s and most
significantly by E. H. Bedell and Iden Kerney’s
equalizers employed in the 1933–1934 Bell Tele-
phone Laboratories, “Symposium on Wire Trans-
mission of Symphonic Music and its Reproduction
in Auditory Perspective.”
This remarkable project which transmitted the
Philadelphia Orchestra over wired circuits to Consti-
tution Hall in Washington DC with full fidelity and
full dynamic range from 35 Hz to 15,000 Hz. Among
others it was witnessed by one of my early
customers in the 1950s at The Golden Ear hi fi shop.
He purchased a full stereophonic Klipschorn system
using Ampex 350 tape recorders which he felt came
close to the Bell Labs system but did not duplicate
the impact he had felt in 1934. William “Cap”
Robinson who had served with distinction in World
War I and then traveled the world for Chicago
Bridge and Iron had had the opportunity to hear all
the world’s great halls and the majority of the great
artists of the first half of the twentieth century.
The sixth paper in this series by Bell telephone
laboratories entitled “System Adaptation” had
utilized a motor driven oscillator coupled to a level
recorder to measure the loudspeakers, the micro-
phone, and their combined effect, as well as learning
to account for the temperature and humidity affects
on air absorption as well as the influence on the
measured curves both nearby the sources and at
various points in the reverberant field compromising
on a measurement point we’d now call critical
distance. They had clearly recognized that the most
useful equalization was close to the source, but that
due to variability in the distribution of the sound
some assessment of the high-frequency rolloff needed
to be accounted for out in the reverberant field.
Working with Paul Klipsch in Hope, Arkansas in
the 1950s, we had duplicated the work by J. C.
Steinberg and W. B. Snow on “Physical Factors,”
the second paper of the symposium. We traveled to
Bell Telephone Laboratories in New Jersey and
presented our demonstration to them using two
Klipschorns and a middle channel “Heresy” (so
named by Mr. Klipsch because it wasn’t horn
loaded) of two channel and derived third channel
geometry allowing the audience to plot their percep-
tion of the physical location of the talkers. Unfortu-
nately at that time I was unaware of the additional
papers from that symposium.
Dr. C. P. Boner provided a valuable example of
repeated application of the principles of equalization
by adjusting sound systems that were considered
unsatisfactory before equalization into sound
systems that satisfied their owners and operators.
Often Dr. Boner’s work had as much to do with
correcting wiring faults, coverage patterns, imped-
ance mismatches, etc., as with equalizing, but in
common with all who did such work at that early
period, all improvements were attributed to the
magic “equalizer.”
Until real-time analyzers were available for
under $5000 (1970), early equalization work was
predominately done by repeatedly raising the gain of
the sound system until feedback occurred and
adjusting the appropriate filter to reduce the system
amplitude at that frequency. One or 2 dB at the very
most are necessary to bring the system back to
stability. By repeating this for 20–30 feedbacks, it is
possible to raise the acoustic gain of a sound-rein-
forcement system to within a few decibels of unity
gain at all frequencies. While this method is an
excellent way to increase gain with a nominal
amount of test equipment, it leaves the overall tonal
balance to the ear of the practitioner. Those with
perfect pitch often exhibit a nonuniversal taste, and
those with a taste that agrees with the majority of
listeners are not often gifted with perfect pitch.
24.4 Introduction of Real-Time Analyzers
Equalization of sound reinforcement systems with
the end purpose of increased acoustic gain and
enhanced acoustic quality became universal with the
introduction of the 1⁄3 octave equalizer by one of the
authors in 1967.
Fig. 24-6 shows one of the authors training a class
of sound contractors in January of 1968 in the use of
a step-by-step 1⁄3 octave analyzer for making
frequency response measurements for equalization
work. The analyzer being used was the GenRad
1564A. In May of 1968 Hewlett Packard delivered to
one of the authors the first 8054A 1⁄3 octave real time
analyzer for $10,000 (that’s 1960 dollars). The
8054A quickly led to a special stripped down version
called the H23-8054A, which came without the nixie
tube read out and the frequency selective push
buttons, Fig. 24-7. The success of each of the early
instruments with the sound contractors who received
them led to collaboration with HP which reduced the
size and price. Approximately 500 instruments went
to the audio industry for use in early equalization
work. Other analyzers followed in the 1970s but
these were the only ones for several years.
The ability to see, in real time, the result of the
equalizer adjustment, in addition to hearing the result,
changed the nature of the activity dramatically. The

560
Chapter 24
change from 45 minutes per house curve to 1 second
had to be lived through to be truly appreciated.
Today the 1⁄3 octave analyzer is still one of our
most usable audio tools. Heyser-based analysis is
more detailed, but there are many cases where the
resolution and accuracy of a 1⁄3, 1⁄6, and 1⁄12 octave
real time analyzers are ideally suited to the job, such
as checking coverage.
The authors feel fortunate indeed to have been
the first users in audio to employ and apply 1⁄3octave
real-time analysis to the study of sound system
performance. (See Chapter 11 Audio and Acoustic
Measurements.)
24.4.1 One-Third of an Octave Analyzers and 
Equalizers
A common error in the labeling of fractional band-
width analyzers and equalizers is the term one-third
octave. This would imply every third octave rather
than one-third of an octave. In actuality they are 1/10
of a decade devices. These devices are widely used in
sound systems to analyze the amplitude response of
loudspeakers and to smooth that response to allow
higher acoustic gain. The best of today’s analyzers
offer bandwidth equivalents of one-third of an
octave, 1⁄6 of an octave, and 1⁄12 of an octave. One
octave analysis is usually reserved for noise measure-
ments called Noise Criteria curves (NC) plots.
As applied initially in sound system reinforce-
ment work, the goal was the control of acoustic feed-
back in order to raise the acoustic gain of the system.
System resonances, due either to the loudspeaker or
aggravated by predominant “room modes”, were
easily detected by using a sweep frequency oscillator
and watching the decay rates of each of the bands on
the analyzers screen using the fast scale. The
offending frequencies drop at a slower rate than the
surrounding frequencies, and by using the sweep
oscillator, it was often possible to “narrow in” on the
exact frequency causing the problem.
It is theoretically possible to utilize a very narrow
band parametric equalizer on such a specific
frequency, but the variability of the velocity of
sound with temperature can easily cause such a
narrow filter to be missed by the frequency being
changed by the environment in the room. Because of
this problem modern parametric filters offer variable
bandwidth as well as amplitude variation.
Quite often the optimum loudspeaker for either
efficiency reasons or directivity control reasons is
not always the smoothest amplitude response. Labo-
ratory sources usually lacked both sensitivity and
directivity, requiring up to 100 times the power
needed by the devices actually used. Even in play-
back system for home use, efficiency and direc-
tivity control, while expensive and large, as
exemplified by the Klipschorn, easily won out over
rigorously engineered “heatsinks.”
Another interesting connection between
well-engineered loudspeakers and all others is the
inexperience of designers to properly understand the
role of acoustic radiation resistance. This can
provide little to no additional damping in an ineffi-
cient acoustic suspension speaker, to a possibly
Figure 24-6. An early equalization training class.
Figure 24-7. Early RTA equipment.
A. H23-8054A
B. 8056
C. 8050A

Sound System Equalization
561
dominant effect in high-efficiency horn systems.
The horn system is likely to be very tolerant of low
damping ratios, as the cone is coupled to a greater
mass of air, so that its own mass becomes less
important by comparison. The effect is similar to
suppressing the “ringing” of an LC filter by properly
terminating the output. All of this comes into sharp
focus when reproducing transients and hearing the
difference between well-engineered horn systems
and consumer products.
In real life balancing economics, smooth ampli-
tude and phase response, directivity control, sensi-
tivity, and physical size, all play a role in a final
choice. Pursuing one to the detriment of the others
leads to the wide diversity we witness in the
marketplace.
24.4.2 Forty Years Later
The authors have each spent over forty years
making precision acoustic measurements on sound
systems and nearly that long in the practice of equal-
izing them. The opinions we put forth here are not
intended to be final judgments on the matter but
rather it is hoped that our suggestions learned from
this experience will save you repeating some of the
same errors we committed.
Today, the knowledge gained is available and
useful in contemplating the next steps. New
analyzers are daily revealing the possibilities of
manipulating the phase characteristics of a system
more directly than in the past, and current digital
technology promises full control over the time
domain, as well as the frequency domain. As in the
past, we expect the future to be shaped by those with
the analysis capability coupled to everyday “real
life” exposure to sound system design, installation,
and operation.
Simple filter networks and their interaction with
real life electroacoustic transducers are a complex
technical study. To quote Richard C. Heyser,
As many technically trained people
are prone to do, I naively presumed
when I first began analyzing loud-
speakers… that I could bring contempo-
rary communication theory to bear and
simply overwhelm the poor loudspeaker
with technology… I soon found the error
in my thinking. The evaluation of the
acoustics of loudspeakers and the room
containing them proved to represent a
microcosm of all the difficult problems
in wave propagation. A wavelength
range of over 1,000 to 1 is bad enough
but the physical extent of the important
dimensions in a single experiment range
from one thirtieth wavelength to greater
than thirty wavelengths for many prac-
tical loudspeaker systems.
The wonder is that the simple tools we employ
work as well as they do. It’s very fascinating to find
that techniques we had to work out intuitively can
now be measured accurately and justified as engi-
neering facts.
Equalizers are now omnipresent on the sound
system scene. Unfortunately, many are designed as
“program equalizers” rather than specifically for the
adjustment of systems to maximum acoustic gain.
The electronic circuit designer designs to his termi-
nation resistor free of all self-doubts or mathemat-
ical uneasiness. Then they wonder why some of us
are less than enamored of their latest electronic
nonsolution to our very real acoustic problems.
24.4.3 RTA Applications
The real-time analyzer has been used by audio engi-
neers for almost 40 years and has proved invaluable
in the following areas:
1.
House curves made with a measuring micro-
phone.
2.
House curves made with a sound system micro-
phone.
3.
Examining distribution of all frequencies at
differing locations at the same time.
4.
Examining house curve at the performer’s
location.
5.
Response curves of the filter settings.
6.
Detecting feedback frequencies.
7.
Frequency response of microphones to be used
in the sound system.
8.
Examining crosstalk between lines.
9.
Setting levels throughout sound system areas
both electrically and acoustically.
10. Detecting resonating surface areas by observing
the effect of manual damping of the vibrating
surface.
Pink noise (equal energy per octave) is used rather
than white noise (equal energy per hertz) because the
bandpass filters used in the typical RTA are constant
percentage bandwidth rather than constant band-
width. This means that a white-noise signal put into a
constant-percentage bandwidth analyzer would have
a +3 dB/octave rise with increasing frequency. The
filters grow wider with increasing frequency, thereby
summing more energy at the same level. Pink noise

562
Chapter 24
on a per hertz basis decreases 3  dB⁄octave
(10 dB ⁄decade); therefore, pink noise matches
constant-percentage bandwidth response, allowing a
flat response across the screen of an RTA. See
Section 24.11, An Improper Use of Real-Time Anal-
ysis in Monitoring Music and Speech.
Fig. 24-8 shows an example of how unavailable
acoustic gain, due to feedback caused by highest
amplitude present, can be made available by equal-
izing all frequencies, making them equal in ampli-
tude response.
24.5 Band-Rejection, Bandpass, and 
Band-Boost Filters
All types have been used to equalize sound systems.
The author’s preference is for band-rejection filters.
Boosting a narrow band of frequencies is not a
natural acoustic phenomenon. Any two frequencies
can come together in a room to a maximum (in the
practical case) of +3  dB but may combine to
complete cancellation. The only thing “narrow
band” going on in an acoustic environment is rejec-
tion, never summing, though acoustic focusing may
be mistaken for summing. Those who think there are
narrow acoustic “peaks” in the environment are the
same ones who advocate equalizing low frequency
room modes, i.e., usually by trying to boost the null
frequency. Very narrow peaked responses can and
do lurk in the transducers used in sound systems.
Such devices should be replaced, not “equalized.”
Again, we have often witnessed skilled electronic
circuit designers trying to correct a deep notch in the
frequency response with a very sophisticated elec-
tronic filter when the cause of the notch is one driver
out of alignment with another.
Interesting to end users, but a matter of disgust to
creative circuit designers, the simpler, almost
sloppy, filters seem to work the best.
24.5.1 Criteria for Band-Rejection Filters
So far as the authors are concerned, if the following
criteria are met, it should be a satisfactory filter:
1.
Minimum phase response.
2.
Combining, sometimes called summing.
3.
Minimum excess delay.
4.
Not narrower than 1⁄6 octave bandwidth with
1⁄3 octave preferred.
5.
Band rejection-type with maximum depth of
14dB, preferably in 1 dB steps.
This is not to say that there are not interesting
differences in designers’ choice of circuits. Fig. 24-9
shows two exceptional fine passive equalizers
wherein the only observable difference is in the
unterminated state. Though largely not manufac-
tured today, these passive units never wear out. It
would be a pity to discard them when newer elec-
tronic equipment is installed, but one needs to be
aware of the need of the “buildout” and “termina-
tion” requirements.
24.5.2 Filter Parameters
Figs. 24-10A and 24-10B show the parameters of a
very narrow-band filter for both amplitude and
phase. The meaning of the bandwidth of a filter is
shown in Fig. 24-11.
One of the earliest methods of sound-
system-room equalization employed individual
broadband networks to shape a rough inverse of the
house curve, Fig. 24-12A. This was followed by the
insertion—one at a time—of very narrow notch
filters at the predominant feedback frequencies,
Fig. 24-12B. When the two sets of filters were elec-
trically combined, the response was like
Fig. 24-12C. Fig. 24-12D is the replacement tuning
finally put in the job after the advent of
1⁄3 octave-spaced bridged-T filter sets. Note how the
same overall gain restoration is provided by either
type of filter, but that the 1⁄3 octave-spaced filter set
removed feedback at many frequencies by changing
the slope rate instead of depressing the amplitude. It
is important to remember that the sound system
deviations from uniformity in a system worth equal-
ization are quite correctable by the slope-rate
changes available in the 1⁄3 octave-spaced filter sets.
24.5.3 Characteristics of Successful Filters
Let us compare an ISO 1⁄3 octave bandpass filter with
a 1⁄3 octave spaced band-rejection filter, Fig. 24-13.
By further comparing the two basic bandpass filter
shapes, both 1⁄3 octave and 1⁄10 octave, we can see that
the inverse of the 1⁄10 octave response most closely
approximates the response of the band-rejection
filter, Fig. 24-14. Looking at a single filter section
and recording each of its 1 dB steps, we get a series
of curves as shown in Fig. 24-15.
If we were to record each filter section in a set of
24 such filters, by setting each filter for a maximum
rejection and then restoring it to zero before
recording the next filter section set at its maximum
rejection, we would obtain the set of curves shown
in Fig. 24-16. If we were to turn all 24 filter sections

Sound System Equalization
563
Figure 24-8. How equalization raises acoustic gain.
80
 100
125
160
200
250
315
400
500
630
800
1000
1250
1600
2000
2500
3150
4000
5000
6300
8000
10,000
12,500
Frequency−Hz
80
 100
125
160
200
250
315
400
500
630
800
1000
1250
1600
2000
2500
3150
4000
5000
6300
8000
10,000
12,500
Frequency−Hz
80
 100
125
160
200
250
315
400
500
630
800
1000
1250
1600
2000
2500
3150
4000
5000
6300
8000
10,000
12,500
Frequency−Hz
80
 100
125
160
200
250
315
400
500
630
800
1000
1250
1600
2000
2500
3150
4000
5000
6300
8000
10,000
12,500
Frequency−Hz
Any frequency above shaded area
will feedback
Any frequency above shaded area
will feedback
Any frequency above shaded area
will feedback
Band number
1     3    5    7    9   11  13   15  17  19  21  23 25  
100
90
80
70
60
50
40
30
dB−SPL
Band number
1     3    5    7    9   11  13   15  17  19  21  23 25  
100
90
80
70
60
50
40
30
dB−SPL
Band number
1     3    5    7    9   11  13   15  17  19  21  23 25  
100
90
80
70
60
50
40
30
dB−SPL
Band number
1     3    5    7    9   11  13   15  17  19  21  23 25  
100
90
80
70
60
50
40
30
dB−SPL
Curve 2
Unavailable acoustic
gain due to feedback
Unavailable acoustic
gain due to feedback
Unavailable acoustic
gain due to feedback
Original level of curve 1
after first stage of equalization
Curve 1
Increased acoustic gain achieved
by first stage of equalization
Increased acoustic gain achieved
by second and final stage of
equalization
Original level of curve 2
after second stage of equalization
Curve 3
Response curve of
band-rejection filters
taken electrically
Final response curve of sound
system taken acoustically
Initial response curve of sound
system taken acoustically
A. Typical situation that can occur in an 
auditorium. Curve 1 shows the sound pressure 
output of the loudspeaker if a signal equal in level 
at all frequencies is connected to the input of the 
sound system. The irregularity of the output is 
partly due to the inability of the loudspeaker to 
respond perfectly uniformly to a uniform input 
signal, and mostly due to the effect of the room 
itself on the acoustic output of the loudspeaker. 
Feedback will occur first at 2000 Hz, since any 
attempts to raise the gain will find this peak to be 
the first frequency to push above the limit line. To 
follow this example, assume the acoustic gain is 
10 dB.
B. Curve 1, after the peaked area between 
2000 Hz and 3150 Hz, has been equalized to 
the majority of the other frequencies. The 
arrows indicate how all these frequencies may 
now be raised simultaneously in gain before 
the new peak of 400 Hz pushes above the 
hatch lines and causes feedback. The number 
of decibels at each frequency between curve 1 
and curve 2 respresents the increased acoustic 
gain made possible by the first stage of sound 
system equalization.
C. Additional smoothing of the curve can allow 
greater acoustic gain at the majority of frequen- 
cies. However, further smoothing, even if per- 
fectly done, would yield either 1 dB or 2 dB at the 
very most throughout the frequency region of 
critical importance for speech. By comparing 
curve 2 with curve 3 we can see that through the 
vital frequency response area for speech, for 
example, the acoustic gain at all frequencies is 
increased from 300 to 3000 by, typically, 10 dB 
or more. Originally, only 2000 Hz could be 
brought to 90 dB Lp before feedback occurred; 
now all frequencies can be brought to 90 dB Lp 
before feedback.
D. The electrical response curve of the critical 
band rejection filters (bottom curve) join together 
to form the inverse of the loudspeaker room 
response curve (top curve). Because this inverse 
filter response curve is included in the total sound 
response, the smoothed over-all acoustic response 
shown by the middle curve results.
−

564
Chapter 24
to maximum rejection at the same time, we would
discover their most important property—they
combine, Fig. 24-17. Note that when they combine
they are essentially additive (their combined depth
exceeds 20 dB at the bottom of the ripple).
Fig. 24-18 shows in detail how they combine.
The narrower curve is 1000 Hz set at −6 dB. The
wider curve is 800 Hz at −2 dB, 1000 Hz at −2 dB,
and 1250 Hz at −2 dB. Here they have combined to
become 6 dB deep, and the center of the curve is at
the middle of the three. It is not difficult to imagine
the complexity of combining from 14 to 24 of these
sections all at different levels to appreciate that
some form of real-time observation is required to
Figure 24-9. Frequency response curves for a passive
equalizer (1000 Hz filter set at −14 dB with high pass
frequency at 80 Hz and low pass frequency at 10 kHz.)
Figure 24-10. A very narrow-band filter.
10
0
–10
–20
–30
–40
dB
20        50   100    200      500   1k      2k        5k    10k 20k
Frequency–Hz
Unterminated
Terminated
A.  Well behaved passive in both terminated and
      unterminated states.
B.  Well behaved passive in both terminated and
     unterminated states—note difference between
     high frequency behavior of this equalizer
     compared to that in Fig. 24-9A.
10
0
–10
–20
–30
–40
dB
20        50   100    200      500   1k      2k        5k    10k 20k
Frequency–Hz
Unterminated
Terminated
Δf = 64 Hz
Δf = 13 Hz
A. Amplitude
B. Phase
3 dB
3 dB
Figure 24-11. The bandwidth of an active bandpass
filter.
Figure 24-12. Very narrow band equalization (A, B, and
C) and typical combining type filter equalization of the
same system (D).
100     200         500       1k       2k            5k    10k
Frequency−Hz
Response−dB
10
0
−10
1. The bandwidth of an active bandpass filter is  
 
measured 3 dB below its center-frequency level (A).
2. The bandwidth of a band-rejection filter is measured  
 
3 dB below the normal level before the filter is  
 
inserted (B).
3. On occasion individuals have chosen to define  
 
the bandwidth of a band-rejection filter as "up 3 dB  
 
from the center notch."
−3 dB (A)
−3 dB (B)
+3 dB (C)
Response−dB
20        50   100    200      500   1k      2k        5k    10k 20k
Frequency−Hz
A.
Response−dB
20        50   100    200      500   1k      2k        5k    10k 20k
Frequency−Hz
 B.
Response−dB
20        50   100    200      500   1k      2k        5k    10k 20k
Frequency−Hz
C.
Response−dB
20        50   100    200      500   1k      2k        5k    10k 20k
Frequency−Hz
D.

Sound System Equalization
565
comprehend thoroughly what is going on. Through
such combining, the smoothest conjugate phase
response is achieved. Fig. 24-19 shows the electrical
response of a set of filters on an actual job. Fourteen
sections were employed at the frequencies and
levels indicated. Note that at 160 Hz the filter is at
−10dB but the curve is at −18.5 dB due to combina-
tion effects. The real test is to compare the inverse
of the filter response before equalization. This is
done on a 1⁄3 octave basis in Fig. 24-20. Filters
producing the type of response we have just looked
at can be either passive or active.
Fig. 24-21 compares the electrical amplitude
response of a set of very narrow-band filters and a
set of critical-bandwidth combining filters after
adjustment on the same job.
24.5.4 Filter Transfer Characteristics
The transfer characteristics of band-rejection,
minimum-phase filters are shown in Fig. 24-22. In
the previous example of the combining power of
these filters, in terms of amplitude, we see an
example of their combining power in terms of
Figure 24-13. Broad-band combining-type band-rejec-
tion filter section compared to 1⁄3 octave active band-
pass filter section.
Figure 24-14. Comparison of a 1⁄3 octave bandpass filter
with a 1⁄10 octave bandpass filter.
Figure 24-15. Response of a band rejection filter at
each of its 14 steps.
200           500         1k         2k               k          10k
Frequency−Hz
Response−dB
Altec 9014A Analyzer
GR1564A
1/3 Octave Analyzer
5 dB
200           500         1k         2k               k          10k
Frequency−Hz
Response−dB
1/3 octave
1/10 octave
Response−dB
20        50   100    200      500   1k      2k        5k    10k 20k
Frequency−Hz
5 dB
Altec 9014A equalizer
1000 Hz filter recorded
at each 1 dB increment
Figure 24-16. A series of band-rejection sections
recorded sequentially one at a time.
Figure 24-17. Series of band rejection sections all
simultaneously turned to maximum attenuation.
Figure 24-18. Response of a 1000 Hz section with 6dB
attenuation compared with the response of a combina-
tion of 800 Hz, 1000 Hz, and 1250 Hz sections with
2dB attenuation each.
Figure 24-19. Example of band filter section in combi-
nation to form inverse of raw house curve.
Response−dB
20        50   100    200      500   1k      2k        5k    10k 20k
Frequency−Hz
5 dB
63
80
 100
125
160
200
250
315
400
500
630
800
1k
1.2k
1.6k
2k
2.5k
3.15k
4k
5k
6.3k
8k
10k
12.5k
Altec  9014A equalizer, each notch filter
recorded individually and sequentially
Response−dB
20        50   100    200      500   1k      2k        5k    10k  20k
Frequency−Hz
5 dB
Altec 9014A Equalizer – All Controls Set At Maximum
Response−dB
20        50   100    200      500    1k      2k         5k    10k  20k
Frequency−Hz
5 dB
Altec 9014A Equalizer
800 Hz, 1000 Hz and 1250 Hz
all set at their 2 dB position
1000 Hz set at its 6 db position
Response–dB
20        50   100    200      500   1k      2k        5k    10k 20k
Frequency–Hz
Reference line
5 dB

566
Chapter 24
phase, Fig. 24-23. The steeper the amplitude slope
rate, the steeper the rate of phase change.
Fig. 24-24 shows all the filters at −1 dB ampli-
tude and the resultant phase characteristic.
Fig. 24-25 shows the same information for −4 dB.
Taking a practical example, Fig. 24-26A shows
the equalized and unequalized response of the left
channel of a monitor system. Fig. 24-26B shows the
Figure 24-20. Example of correlation between raw
house curve and inverse of filter electrical response
curve.
Figure 24-21. Comparison of response of a set of very
narrow-band filters and a set of critical-bandwidth
combining filters.
Figure 24-22. Bridged-T configuration for tandem filter
sections.
dB−SPL
100
95
90
85
80
75
70
1     3     5     7     9    11   13   15   17   19   21   23   25
63
80
100
125
160
200
250
315
400
500
630
800
1k
1.25k
1.6k
2k
2.5k
3.15k
4k
5k
6.3k
8k
10k
12.5k
Band Number
Frequency−Hz
Inverse of filter electrical response
Raw house curve
Final house curve
Frequency−Hz
Response−dB
20        50     100  200     500    1k      2k        5k    10k  20k
20        50     100  200     500    1k      2k        5k    10k  20k
Narrow filter equalization – 63 sections
Shaping filter equalization – 16 sections
5 dB
100       200           500        1k         2k              5k      10k
Frequency−Hz
Amplitude−dB
Phase−degrees
5
0
−5
−10
−15
60
40
20
0
−20
−40
−60
Amplitude and Phase Characteristics of One Section
100       200           500        1k         2k              5k      10k
Frequency−Hz
Figure 24-23. Active configuration for tandem filter
sections.
Figure 24-24. Combined phase and amplitude
response, all sections set for −1 dB.
Figure 24-25. Combined phase and amplitude
response, all sections set for −4 dB.
100       200           500        1k         2k              5k       10k
Frequency−Hz
Amplitude−dB
Phase−degrees
5
0
−5
−10
−15
40
20
0
−20
−40
100       200           500        1k         2k              5k       10k
Frequency−Hz
1 kHz section: −6 dB
800 Hz, 1 kHz, 1.25 kHz: −2 dB each
Amplitude−dB
Phase−degrees
5
0
−5
−10
−15
40
20
0
−20
−40
−60
Frequency−Hz
20       50    100   200      500    1k     2k        5k    10k 20k
20       50    100   200      500    1k     2k        5k    10k 20k
Frequency−Hz
Frequency−Hz
Amplitude−dB
Phase−degrees
5
0
−5
−10
−15
−20
80
60
40
20
0
−20
−40
−60
−80
20       50    100   200      500    1k     2k        5k    10k 20k
Frequency−Hz
20       50    100   200      500    1k     2k        5k    10k 20k

Sound System Equalization
567
same information for the right channel. Fig. 24-27A
shows the electrical amplitude response of the
corrective filters, and Fig. 24-27B shows the phase
response of each channel.
24.5.5 Minimum-Phase Filters
A minimum-phase filter introduces the minimum
possible phase shift but still retains the corrective
amplitude change. It is also obvious that the relative
phase between channels is virtually identical. It is
this careful band-by-band resolution of phase that so
many listeners have dubbed as the “sharp focus”
that equalization seems to produce in sound systems
already relatively smooth in an amplitude sense.
Richard C. Heyser has pointed out that:
Highly important to a loudspeaker’s
ability to produce accurate sound, when
it has been properly equalized, is that of
minimum phase change. A minimum-
phase-change loudspeaker is one in
which, when all amplitude response
variations are removed by conventional
resistance, capacitance, and inductance
networks, it has the minimum possible
phase shift over the frequency spec-
trum. Properly designed equalizers for
balancing the amplitude response will
also automatically balance the phase
response for a minimum phase loud-
speaker. (Bold added.)
Also:
A nonminimum-phase loudspeaker
will usually exhibit frequency-response
difficulties which can be associated with
signal delay effects which, in turn
cannot be corrected with conventional
passive or active equalization. (Bold
added.)
Fig. 24-28A shows an active 1⁄3 octave band-boost
filter (BBF) raised 9  dB, a passive 1⁄3 octave
band-rejection filter (BRF) lowered 9 dB, and the
resultant smooth amplitude response. Fig. 24-28B
shows the phase response of the BBF and the BRF as
well as the resultant smooth phase response.
The distinction between a bandpass filter (BPF)
and a band-boost filter (BBF) is that the “skirts” of a
BPF continue on to minus infinity (−∞). The skirts
on a BBF return to zero reference after passing
through the peak. Such filters are found in active
parametric filter sets and extreme caution is advised
in their use in live system stability adjustment. One
must exercise caution when it comes to program
effects’ adjustment.
24.6 TEF Analysis in Equalization
With TEF analysis in use for almost all serious
equalization work today, the engineer can view LD,
LR, and LRE (early reflection levels), separately or
together as desired. The level, direction, and time of
travel for each reflective interference can be
observed. An aberration in LT can be segregated and
if it is caused by LD equalized, if caused by LRE
blocked, and if due to LR, it can be treated in the
if
Figure 24-26. Equalized and unequalized response of a
monitor system.
Figure 24-27. Response of equalizers.
Frequency−Hz
Response−dB
Response−dB
5 dB
Frequency - Hz
5 dB
A. Left channel.
B. Right channel.
40
50
63
80
100
125
160
200
250
315
400
500
630
800
1k
1.2k
1.6k
2k
2.5k
3.15k
4k
5k
6.3k
8k
10k
12.5k
16k
40
50
63
80
100
125
160
200
250
315
400
500
630
800
1k
1.2k
1.6k
2k
2.5k
3.15k
4k
5k
6.3k
8k
10k
12.5k
16k
Response−dB
Phase−degrees
15
10
5
0
−5
−10
−15
−20
−25
60
40
20
0
−20
−40
−60
−80
−10020       50    100   200      500    1k     2k        5k    10k 20k
Frequency−Hz
20       50    100   200      500    1k     2k        5k    10k 20k
Left channel
Right channel
A. Amplitude
B. Phase
−

568
Chapter 24
statistical manner. Formerly well hidden transducer
aberrations, particularly in phase and in time
behavior, are now strikingly evident and conse-
quently easily prevented.
As a consequence of this enhanced ability to
actually “see” what’s going in the total system, both
rapidly and accurately, the design procedures are
modified to incorporate this new knowledge and we
are finding that less and less equalization is required
in the newer systems. Where and when equalization
is needed, it is invaluable. Misapplied, it can create
harsh sounding high frequency distortion, insta-
bility in the system, and worst of all, a belief that
equalization has solved a problem that in actual fact
is still unaddressed.
Fig. 24-29A is the Envelope Time Curve, ETC,
of a packaged system with a separation between the
low frequency unit and the high frequency of 0.17ft,
0.15 ms. (See Chapter 11 Audio and Acoustic
Measurements for a full explanation of the Envelope
Time Curve.) Fig. 24-29B is the magnitude and
phase of the same loudspeaker with the phase
response made as smooth as possible. Fig. 24-29C is
the Nyquist display of the same loudspeaker with
the cursor set at a high frequency that has encircled
the origin of the display indicating a non-minimum
phase system. Failure of a cursor in a Nyquist plot
to rotate clockwise as frequency increases indicates
a mis-selected signal arrival time at the measure-
ment microphone. Harry Nyquist of the Bell Tele-
phone Labs in the old days was truly a genius.
24.7 How to Approach Equalization
Gently! Slowly! These are key words for key atti-
tudes when utilizing equalizers. After every adjust-
ment, listen carefully to the remaining sounds. The
goal is to improve sound quality in sound reproduc-
tion systems as well as increase acoustic gain in the
case of reinforcement systems. In any type of
system, stop tuning and examine the system with
care when the equalizer causes a detrimental change
in the sound quality.
In using equalizers, we can borrow from the
medical fraternity and say, “First, do no harm.”
Anything within a system that requires steep
slope rates (over 18 dB/octave) or excessive ampli-
tude change (in excess of 3 dB) in order to control a
given frequency increment (on the order of 1⁄3 of an
octave) should be subject to serious consideration as
to its replacement. In today’s marketplace there is a
sufficient number of very well-behaved electronics,
microphones, loudspeakers, and interconnection
networks available to allow avoiding the use of infe-
rior products. Increasing understanding of the
Heyser Transform and its ability to allow us to
understand the transformations in time at given
frequencies coupled to the newer analyzers to
measure such parameters should quickly lead to
both better components and more skillful applica-
tion and adjustment of them.
24.7.1 When to Use an Equalizer
Equalization, in common with most sound system
components, can be misapplied. Therefore, a discus-
sion of when and where it is appropriate to use an
equalizer and when and where it should not be
employed is useful.
Figure 24-28. Notch filter in opposition to boost filter.
Vertical: 6 dB/division
Horizontal: Auto 0.00–2000.24 Hz
Resolution: 1.0010E + 01 Hz
Vertical: 45°/division
Horizontal: Auto 0.00–2000.24 Hz
Resolution: 1.0010E + 01 Hz
Active 1/3 octave
band - boost
Passive 1/3 octave
band - rejection
BRF
BBF
Zero degrees
A. EFC
B. Phase frequency curve, PFC

Sound System Equalization
569
Let’s first imagine a very special case wherein
we have a loudspeaker that already has the acoustic
response we desire and its coverage pattern exactly
covers our audience area so that each listener is
receiving the identical level and %ALCONS. Let’s
further assume that no sound reflects off this audi-
ence into the reverberant space. In such an ideal
case, we would require no equalization unless for
some reason we desired program equalization or the
deliberate distortion of program material for some
departure from this ideal case. This clearly identifies
the fact that only some departure from this ideal
case might require correction. A deviation in LD
might then require an equalizer. Other deviations
would require different remedies.
24.7.2 Sources of Feedback That Should Not Be 
Equalized
Equalizers are most misused by end users in the
following areas:
1.
Used to correct instabilities caused by comb
filters designed into the system rather than
removing the cause of the comb filter.
Figure 24-29. Envelope Time Curve, magnitude, and phase with the phase response made as smooth as possible 
and the Nyquist display of a loudspeaker.
A. Envelope time curve of a packaged two way loudspeaker system arrival times and relative distances plus levels.
B. Magnitude and phase of a packaged two way  loudspeaker system.
C. Magnitude is length of the cursor at any frequency. The angle of the cursor is the phase.
Encirclement of the origin reveals non minimum phase behavior.

570
Chapter 24
2.
A microphone on a desk stand near a hard
surface.
3.
Excessive insertion loss per filter.
4.
Use of the filter to control a problem caused by
mechanical feedback.
5.
Use of the filter to control feedback caused by
crosstalk between circuits.
6.
Use of the equalizer to adjust the steady-state
response of devices whose transient response is
an undamped resonance.
There are many very critical areas where the
distinction between acoustic gain equalizers and
program equalizers becomes quite hazy. Our
increasing appreciation of right brain-left brain influ-
ences in the perception of the received signal by the
listener causes us to proceed with caution in inter-
preting the technical data inundating users of
analyzers. Perhaps we should separate electroacoustic
transducer magnitude and phase adjustment from
other forms of signal processing that are quickly
coming on the scene (e.g., signal synchronization).
If we were to reserve the word “equalizer” for
those devices that made system gain equal at all
frequencies and used the words “signal processor”
or “adjuster” for those devices intended to shape
specifically the transfer function of the system for
any purpose other than optimum acoustic gain, we
might forestall at least a little of the confusion.
24.7.3 Feedback Is a Single Frequency
Acoustic feedback is indeed single frequency. The
fallacy that is usually being defended by that state-
ment is the implication that since feedback is single
frequency, so should the compensating filter be
single frequency.
Nyquist, Waterfall, and Antman have clearly
shown the amplitude, phase, and signal delay path
causes of feedback. A single frequency feedback is
often less than 0.1 dB greater amplitude at that
frequency than the surrounding frequencies.
The only extremely narrow band effects the
authors have ever observed in real life sound
systems is band rejection such as phase cancellation
or diaphragmatic absorption. Recall that the acoustic
environment is passive, not active.
24.7.4 Which Sound Field Is the Microphone In?
Fig. 24-30 hints at the multiplicity of sound fields
that might be encountered in a single acoustic envi-
ronment in connection with the operation of a sound
reinforcement system. Being alert to each of these
acoustic fields can solve many problems that seem
mysterious when considered in the context of a
single field. Often, you will equalize in more than
one of the fields at the same time. For example, you
will equalize the main system for the audience, the
foldback system for the entertainer, a delayed
under-balcony system for a distributed system, and
separate equalization for a signal-delayed portion of
the main system. Some of these are in the direct
field and some in the reverberant field. No one, as
yet, has all the answers to applying equalization to
the fantastic variety of sound systems being
designed today.
Fig. 24-31A illustrates the time dependency of
each of the sound fields. Fig. 24-31B depicts the
frequency dependency of the characteristics of a
sound field. Finally, Fig. 24-31C shows the level
dependency of sound fields relative to their distance
from the sound source.
In almost all sound system measurements, we
avoid the “near field” of an acoustic source. Most
measuring microphones used with equalization
measurements are placed in the far reverberant
sound field. Equalization of monitor loudspeakers in
recording control rooms almost always are in the far
free field.
When using modern analysis capable of sepa-
rating LD from LR, the operator is able to choose
between direct sound levels, LD, early reflected
sound levels, LRE, reverberant sound levels, LR, and
total sound levels, LT (LT is comprised of LD, LRE, LR,
and LN, where LN is the ambient noise sound field).
One of the most frequent errors made in using
1⁄3 octave analyzers, or FFTs which measure LT , is
the failure to note the level of LN separately
followed by observation of its effect on LT .
In complex multi-loudspeaker arrays the best
practice is to turn on one loudspeaker at a time for
equalization. If two loudspeakers share a common
coverage area they are first looked at individually
and then adjusted combined.
24.8 What Can an Equalizer Equalize?
The question, “What can an equalizer equalize?”
needs to be asked. Some claim to equalize the room.
Is this possible? We think not. When an electronic
or passive equalizer is installed in between a mixer
and a power amplifier we need to know that all we
can equalize is the electrical signal being sent to the
loudspeaker.
What can an audience do to affect LD from a
sound source? The answer, of course, is absolutely
nothing. Therefore, it is clear that the audience can

Sound System Equalization
571
only alter LRE, LR, and LN. Now, ask yourself the
question, “how can an equalizer adjust LRE, LR, and
LN?” The answer is that it cannot. I would hesitate to
mention such obvious facts except for the remark-
able number of times in the popular press that claim
the contrary.
If one has only an RTA, one needs to equalize the
loudspeaker’s LD. Often, due to the location of the
loudspeaker; the microphone is in the reverberant
sound field. Knowledge of the free field response of
the loudspeaker allows for intelligent “guesses” as
to what aberrations in the reverberant sound field
should not be responded to with the equalizer, i.e.,
focused reflections.
If the facility is already built and functions are
taking place, be sure to attend a “performance”
Figure 24-30. Example of the multiplicity of sound fields that can affect how you choose to equalize.
Figure 24-31. Acoustic level versus distance and time.
Sound
field
Talker
Sound
field
Sound
field
Sound
field
Sound
field
Microphone
Sound
producing
system
Sound
reinforcement
system
Loudspeaker
Audience
Program transmission path through
the sound reinforcement system
Feedback loop 1—
reflected from
the sound field
Feedback loop 3—reflected from
the sound reinforcement system
Feedback loop 2—acoustic
feedback from the sound system
Feedback loop 4—atmosphere
in the auditorium
Program transmission path through the sound field
Direct sound
LD
Early reflections
LRE
Reverberation LR
Ambient
noise
level
LAMB
TREF
T0
T1
TN
T2
Time
Decibels
Normal
modes
Diffusion
Frequency
Absorption
(specular reflections)
Sound pressure level
Pressure zone
fc
4fc
f1/0/0
B. Controllers of steady state room acoustic response.
A. Large room acoustic response.
T0 − TREF = Signal travel time to observer (D0)
T0 − TREF = Initial signal delay (ISD) gap
TN − TREF = Natural room delay (DN)
T2 − T1 = 3D measurement limits 
(variable from TREF to T2)
10                                      100                                   1000
100
98
96
94
92
90
88
86
84
82
80
78
76
74
72
70
68
66
64
62
60
58
56
54
52
50
Level–dB
D, Dx –ft or m
C. Acoustic level versus distance.
Hopkins-Stryker equation
fc = 11,500* 
T
V
T = 0.049**V
SaSAB
* SI = 1893
**SI = 0.161 

572
Chapter 24
before installing the equalization and follow up with
a visit at a performance after equalization. It is
important to test the equalization with speech. Often
only music will be played which gives little idea of
speech clarity and often a separate equalization is
required for speech and music.
In one case, whenever the equalization was made
uniform to the desired house curve, there was not
enough acoustic gain in the audience area. When the
acoustic gain was raised by the feedback method,
the shape of the house curve in the audience area
was unacceptable. Analysis with an RTA revealed
that the loudspeaker array mounted in the prosce-
nium area was not properly shock mounted and was
causing the arch structure to reradiate a signal
downward to the microphones, causing premature
feedback. When this large array was properly shock
mounted and properly isolated in the proscenium
arch area, then the house curve could be shaped as
desired, and the acoustic gain could be brought to its
potential at the same time.
Another cause of the same effect is when the rear
of the proscenium is open to the stage house and the
rear of the array has substantial radiation of its own
into the microphone. The house curve in the audi-
ence may be a good response, yet the microphone on
stage has severe feedback problems because it is
receiving a strong radiation from the loudspeaker,
usually in the bass region.
24.8.1 Mother Nature’s Way
There are in audio and acoustics both natural and
unnatural distortions. An example of a natural
distortion is harmonic distortion because we hear
harmonics in nature. An example of an unnatural
distortion is print through on tape recordings where
we hear the echo first followed by the desired sound.
This never occurs in nature, thus our brain is
extremely sensitive to its occurrence. So it is with
“boost filters.”
In nature any two signals can combine and go to
various depths depending upon the relative phase
angle between them. Under ideal conditions, they
can only add to 3 dB greater levels and psychologi-
cally we notice the presence of something far more
than its absence. Subjectively, over more than forty
years of system equalization in the field, qualified
investigators report slope rates in excess of
18 dB/octave as audible. Therefore, filter sets
(equalizers) should be designed to avoid steep slope
rates, be combining, and not introduce unnatural
distortions (boosting).
24.9 A Real-Time Regenerative-Response 
Method of Equalizing a Sound System
One of the earliest demonstrations of the effect of
operation near regeneration on the measured
frequency response of a sound reinforcement system
was by William B. Snow before the February 1954
meeting of the Audio Engineering Society in Los
Angeles. Snow recorded on a high-speed graphic
level recorder the dramatic amplitude changes that
occurred in the overall amplitude-versus-frequency
response as the reinforcement system was brought
nearer and nearer regeneration. (See Chapter 14
Designing for Acoustic Gain.)
This same method is still used with a manually
operated oscillator to identify those frequencies
whose amplitude responded unduly to the approach
of the regeneration point of the sound system. Shock
excitation was employed to observe the increased
decay periods of frequencies that otherwise would
not feed back upon being increased in gain but were
unduly affected by the approach of the system
regeneration point. Snow’s paper had also demon-
strated this point, proving that such frequencies,
when shock excited near regeneration, could take as
much as 4 to 6 times as long to decay as the same
frequencies required when they were excited well
below the regeneration point (−12 dB).
Over 40 years of active participation in equaliza-
tion of sound systems has shown us that making
regenerative response curves is one of the most
useful techniques applicable to equalizer adjust-
ment. More often than not, the frequencies that ring
as they are swept do not come up into
steady-state-feedback yet they interfere with speech
intelligibility and the overall acoustic gain of the
system. The regenerative response curve technique
allows careful analysis of both the electrical and the
acoustic responses while allowing both the regener-
ative and degenerative frequencies to be identified.
24.9.1 Where to Put the Microphone for Regen-
erative Response?
Where to place the microphone for viewing the
equalization with an analyzer is one question. The
second question is where do I place the microphone
that is to cause the regeneration of the signal in the
sound system?
One good practice is to place a measuring micro-
phone out in the main coverage pattern looking at
the array. Then place the regenerative microphone
(the microphone that is to be used to cause the
system to go into acoustic feedback during the test)

Sound System Equalization
573
in the location where it is to be employed for normal
system usage.
24.9.2 Degree of Correction Necessary
Interconnect the instruments and the sound system
as illustrated in Fig. 24-32. The instrument labeled
“analyzer receive” can be a 1⁄3 octave of 1⁄1 octave
real-time analyzer, a TEF analyzer, a high-quality
wave analyzer, or a suitable FFT. The instrument
labeled “analyzer send” can be a logarithmic sweep
oscillator (for use with the constant percentage
bandwidth analyzers), a linear sweep oscillator (for
use with the TEF or FFT), or a random noise gener-
ator. In fact, it can be just about any controlled
source that is capable of exciting the sound system’s
entire bandpass.
Clearly evident in this process is the fact that
below regeneration the amplitudes of the frequen-
cies involved are of the order of 1 or 2 dB higher
than other nearby frequencies. As these frequencies
approach regeneration, their amplitudes can “swell”
to +20 dB or more. (See Chapter 14 Designing for
Acoustic Gain, Figs. 9-7 and 9-8.) Naturally the
sound system must supply the power for this
regeneration, as the room cannot—it is passive. The
room can provide nulls and peaks, but not amplifica-
tion. If, before regeneration is approached, one of
these frequencies has its amplitude brought to
uniformity with the remainder, then upon
approaching regeneration again, this frequency will
not “swell” in amplitude.
By using sweeps from an oscillator, it is then
possible to watch what happens to the sound
system’s electrical and acoustic responses as well as
to listen to the transient response. (Measure the tran-
sient response effects if a TEF analyzer is available.)
The ability to make the needed controlling
corrections at a magnitude associated with the
nonregenerative state of the system was first
observed by the authors in 1966 and was presented
as a paper.*
24.9.3 Using Sweep Oscillators
Rapid sweep oscillators allow very effective regen-
erative response tuning. By rapid rate we mean a full
sweep from 20 Hz to 20,000 Hz at about one-half the
time it takes mid-range sound to decay 60 dB in the
environment where the tuning takes place. Typi-
cally, sweep rates of 10  kHz/s are useful. If
searching for a low frequency anomaly, use a loga-
rithmic sweep. If searching for a high frequency
anomaly, use a linear sweep.
This rapid sweep will cause all the bands on a
1⁄3 octave equalizer to jump up on the screen and then
drop at the integration rate of the analyzer (usually
0.1 s at the “fast” rate). A “ringing” band will drop
slower than the rest of the bands being shock excited
by the sweep. The sound created by the sweep
passing through the system and shock exciting the
nonlinear frequencies has a “gong-like” tone not
unlike that heard in older department stores to
summon or alert personnel. As the equalizer’s ampli-
tude is adjusted slowly while listening to the
“gonging,” it turns into a gong-in-a-pillow sound,
indicating sufficient attenuation is present at that
frequency.
Pink noise for regenerative excitation is more
useful at lower frequencies. Bringing the system to
within a few dB of regeneration using pink noise
allows the room and sound system to “display”
which frequencies are unduly sensitive to
approaching regeneration including those due to
phase as well as amplitude.
24.10 Equalizing for Playback
The real time regenerative response method can be
startlingly effective in the equalization of sound
reproduction systems or sound synthesizing
systems. In this case, instead of using a performer’s
microphone to achieve regeneration, the calibrated
Figure 24-32. Regenerative response tuning.
Sound system
microphone
Measuring
microphone
Loudspeaker
Analyzer
receive
Analyzer
send
Equalizer
Mixer
Power
amp
*.
D. Davis. “Adjustable 1⁄3 Octave Band
Notch Equalizer for Minimizing Detrimental
Interaction Between a Sound System and Its
Acoustic Environment,” presented at SMPTE
Meeting in Chicago (Sept. 1967) and AES
Meeting in New York (Oct. 1967).

574
Chapter 24
measuring microphone is simultaneously used for
both room-response measurement and regeneration.
Multichannel systems tuned using this technique are
characterized by superior spatial geometry as well as
improved tonal response. The improved reproduc-
tion of geometry is believed to be due to the better
acoustic phase response between channels at the
listener’s position, and while only a small area so
benefits, it is usually only the mixer’s general area
that has to be covered in the typical studio moni-
toring room situation. Some unusually extended-
range systems may now feed back at frequencies
well above audibility (in one case above 30 kHz),
and care must be taken to use a low-pass filter in
conjunction with either the sound system or the
measuring system. Of course, attention must be paid
to avoid tuning in the null of a standing-wave
pattern. A short walk with the microphone of the
analyzer, especially in a small control room, is fasci-
nating, instructive, and necessary.
24.11 An Improper Use of Real Time Anal-
ysis in Monitoring Music and Speech
Constant percentage bandwidth filters have abso-
lute widths that increase in direct proportion to the
center frequency of the filter. When performing
spectrum analysis with instruments based on such
filters it is necessary to employ a random noise
source whose spectrum has constant energy per
octave, i.e., pink noise as opposed to a noise source
that has constant energy per unit bandwidth, i.e.,
white noise.
 A system possessing a uniform or flat response
on a per unit bandwidth basis that is excited with
pink noise will produce a flat display on a constant
percentage bandwidth analyzer. Such a system
excited with white noise would produce a response
that rises at 3 dB/octave on a constant percentage
bandwidth analyzer. Therefore, when constant
percentage bandwidth analyzers are employed to
study the spectra of program material where it is
desired to determine the response displayed on a per
unit bandwidth basis, it is necessary to precede such
an analyzer by a filter that has a response that falls at
the rate of 3 dB/octave. Any evaluation of program
material without such a device is invalid.
It is the authors’ belief that this uncorrected error
is why so many professional mixing engineers still
use meters and indicators in place of the much more
useful real time analyzer. Trained ears didn’t agree
with the uncorrected visual display. The noise
control people made their criteria constant
percentage bandwidth based, thereby judging rela-
tive results. The recording engineers, home hi-fi
enthusiasts, and other researchers did not realize the
need and therefore failed to compensate for it.
24.12 Diaphragmatic Absorbers
Care should be observed in the handling of dips in
the response of a loudspeaker and a room caused by
diaphragmatic action of some boundary surface. This
is identifiable when, after all the bands around the
dips are brought down, they still fall the same
number of dB below the surrounding bands. Do not
chase it on down, because that will only increase the
insertion loss of the total equalization with but negli-
gible improvement in the response. The correct
method is to drive the loudspeaker room combina-
tion with a tunable bandpass filter and observe the
effect on the real-time analyzer to find the frequency
where the absorption of the signal is greatest; then
use your fingertips and feel all the surfaces of the
space, including walls, doors, windows, etc. You
will feel the offending surface vibrating in sympathy
with the test signal, in one case a walled-up window
area.
At a famous recording studio during a demon-
stration of equalizing monitor loudspeakers, a
diaphragmatic absorption was traced to a loose
“sound-lock” door. Upon holding the door tightly
shut, an 80 Hz notch in the house curve disappeared.
24.12.1 Room Absorption at Specular 
Frequencies
It has been common practice for the past fifty years
to adjust the high frequency response of sound
systems to compensate for high frequency absorption
in the room. Analysis suggests that the loss of high
frequencies being compensated for does not occur as
a result of the absorption present, but as a result of
LW lowering rapidly at about the same frequency Q
increases, with the resultant illusion that the response
is uniform, but duller. The most common cause of
radical high frequency loss in sound systems is either
device misalignment or a high level, very early
reflection (i.e., within 2 ms or less).
24.12.2 House Curves
A famous acoustician once was heard to say that the
“house curve” (i.e., the response as viewed on a
1⁄3 octave real time analyzer) should be down 10 dB at
10 kHz referenced to 1 kHz. What his listeners forgot

Sound System Equalization
575
to consider was where he was standing. It was 70 ft to
80 ft out in front of a horn type loudspeaker system.
At that distance, when you take into account air
absorption, microphone diffraction characteristics,
and high-frequency distortion components, 10dB
down seems quite sensible. When you are in a control
room 10 ft from a loudspeaker the 2 to 3dB typical of
microphone diffraction at 10kHz is more logical and
air absorption is not a factor. When necessary to err,
then err on the side of a little extra rolloff.
24.13 Don’t Equalize for Hearing Loss
Many times there is a tendency to attempt to adjust
the amplitude response of a sound system to make it
the inverse of the hearing-loss curve. This is not a
good idea for several reasons:
1.
Young people with normal hearing will be
annoyed.
2.
Older people have made mental compensation
for the gradual onset of the loss and would also
be annoyed. They usually desire the overall
level higher.
3.
Available high-frequency drivers would have
their distortion increased noticeably with such a
boost.
24.14 Proximity Modes
The microphone proximity effect, traditionally
referred to in the technical literature, is the effect of
increased bass response in the microphone as the
talker gets closer to the unit. This remains true of
most unidirectional microphones today and is often
effectively used by trained performers to enhance
their otherwise weak bass tones. Since the advent of
sound system equalization, however, we have
become aware of still another effect of the proximity
of large bodies (performers) on a typical cardioid
microphone. That is the increased tendency to feed-
back at some key midrange frequency where the
system is otherwise stable until the microphone is
approached. You can use your hands cupped around
the microphone to bring the system into feedback
and can adjust the level of feedback by “playing”
the microphone. In adjusting the appropriate filter,
care should be taken not to carry the adjustment too
far. The idea is to correct the tendency of the micro-
phone to cause instability when it is approached by
the performer and not to remove all tendency toward
feedback even when the microphone is completely
encircled by a closed hand. TEF analysis has shown
that this instability is caused by “comb filters”
produced by reflected sound from the performer.
One classic example was Dan Seals who is a
left-handed guitar player and was having trouble
with acoustic feedback whenever he turned to his
left at the microphone. He allowed us to make a
measurement with the same setup as when he was
performing. Fig. 24-33 shows our measurement.
The guitar reflection and the hat brim reflection
combined acoustically at the microphone to cause a
genuine excess gain problem. When he turned to the
left, the body of his guitar reflected the left monitor
towards the microphone and his hat brim reflected
the right monitor to the same place. When Dan Seals
saw the measurement, he said, “We have met the
enemy and they is us!”
24.15 Checking Microphone Polarity
Surprisingly, one minor checkout prior to equaliza-
tion time that often is overlooked is the poling of the
microphones in a multimicrophone system. The old
way was to arbitrarily assume that the first micro-
phone you picked up was correctly poled. Holding it
in one hand and the second microphone in the other
hand, and bringing them closer and closer together
while talking into them (such as “one-one-one”).
They were in polarity if the apparent bass response
increased as they were brought closer together in
front of your mouth. They were out of polarity if the
bass weakened as they were brought together. In one
memorable case the “first” microphone was
reversed and this simple process reversed all the
others. The arrival on the scene of a polarity checker
revealed the error. In any case, be sure to check this
important factor before equalizing. A polarity
reverser is invaluable in this work. Today we know
Figure 24-33. Effects of surfaces on feedback.
Upper trace is Dan Seals with cowboy hat and guitar
Lower trace is open microphone

576
Chapter 24
to check for absolute polarity as it has been repeat-
edly demonstrated that it is audible on speech. TEF
analyzer phase measurements instantly indicate the
correct polarity (as well as, in the TEF case, the
difference between polarity and phase). Be careful
before you rewire microphones; the patch cords
could be miswired.
24.16 Loudspeaker Polarity
In examining the “raw” response of a loudspeaker
array, pick the poling that gives the most usable
response through the crossover region. True phasing
can enter in here, as well as polarity, and great care
should be exercised in the relative positioning of horns
to each other, especially the spacing and positioning of
the high-frequency elements in relation to the
low-frequency elements. Remember, out in the audi-
ence area there will be phase relationships between
direct and reflected sound as well as those between
two direct sound sources. The real-time analyzer is
invaluable for examining the potential variations and
their effects on the audience area. Today, through TEF
analysis we have identified signal misalignments of
from fractions of an inch to about one foot as particu-
larly hazardous to speech quality.
24.17 Summary
The advent of practical sound system equalization in
situ in the late 1960s coincided with the develop-
ment of portable 1⁄3 octave constant percentage
bandwidth real-time analyzers which led to a revolu-
tion in the design, installation, and operation of
sound reinforcement systems.
The availability of equalizers and analyzers
quickly led to the training of large numbers of alert
sound contractors, consultants, and operators in
sound system measurements. Proper design led to
much more powerful loudspeaker arrays constructed
by those knowledgeable about directivity factor,
comb filter interference, and signal delay and
synchronization. Manufacturers responded with
vastly improved data.
Today we have unimagined design aids, loud-
speaker data, and a cadre of knowledgeable users.
Today equalization is a small component in the
cornucopia of tools available, but it does have the
satisfaction of having been the catalyst to dramatic
improvement in the design and installation of
outstanding sound systems.
Bibliography
J. E. Benson and D. F, Craig. “A Feedback-Mode Analyser/Suppresser Unit for Auditorium Sound-System
Stabilisation,” Proc. IREE, Australia (Mar. 1969).
W. K. Connor. “Theoretical and Practical Considerations in the Equalization of Sound Systems,” Audio Eng.
Soc., Vol. 15 (Apr. 1967).
D. Davis. “Facts and Fallacies on Detailed Sound System Equalization,” Audio (1969).
_______. “A Real Time Regenerative Response Method of Equalizing a Sound System.” AES Paper (May
1973).
Gene Patronis. “Elementary System Theory,” Syn-Aud-Con Tech Topic, Vol. 21 No. 3 (Spring 1994).
W. Rudmose. “Equalization of Sound Systems,” Noise Contr., Vol. 24 (July 1958).
M. R. Schroeder. “Improvement of Acoustic-Feedback Stability by Frequency Shifting,” J. Acoust. Soc. Am.,
Vol. 36 (Sept. 1964).
B. Snow. “Frequency Characteristics of a Sound-Reinforcing System,” J. Audio Eng. Soc., Vol. 3 (Apr. 1955).
G. Stanley. “Minimum Phase: Defined and Illustrated,” Syn-Aud-Con Tech Topic, Vol. 5, No. 10 (1
978).

Chapter 25
Putting It All Together
by Eugene Patronis, Jr.
577
25.1 Acoustical Analysis  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 579
25.2 Alternative Solutions for a Given Space  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 579
More Modern Treatment . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 580
Virtual Sound Processor  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 581
25.3 Device Interconnections . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 582
25.4 Analog Interconnection Circuitry Types  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 583
Balanced Circuits . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 583
Balanced Circuits and Susceptibility to EMI  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 584
Brief Description of Electromagnetic Waves  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 584
Shielding  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 586
Unbalanced Circuits  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 587
Cables, Connectors, and the Pin 1 Problem  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 588
The Pin 1 Problem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 588
Removal of SCIN from Unbalanced Circuits  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 589
Consumer Output to Balanced Input . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 589
25.5 Signal Cables—Analog Audio, Digital Audio, and Video  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 590
Video and Digital Audio Signal Cables . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 590
The Cable Problem  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 591
Characteristic Impedance  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 592
Attenuation  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 592
Phase Velocity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 592
Skin Effect . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 593
Measurement of Cable Signal Propagation Properties  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 595
Sample Calculation  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 596
To Terminate or Not to Terminate . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 596
25.6 AES3  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 597
Encoding Format . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 597
General Transmission Characteristics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 598
Electrical Characteristics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 599
AES Information Documents and Unbalanced Transmission of AES3  . . . . . . . . . . . . . . . . . . . . . . . . 600
Sony/Phillips Digital Interface Format  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 600
Microphones with Digital Outputs  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 601
Connectors for Digitally Interfaced Microphones . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 602
25.7 Computer Control and Communication of Digital Audio . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 602
A Little History  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 602
Networking of Digital Audio Data  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 603
CobraNet®  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 604
Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 604


Putting It All Together
579
The diverse nature and broad range of configura-
tions of devices that constitute sound and sound
reinforcement systems is impressive indeed. A
sound system designer may be called upon to design
a system as simple as a paging-background music
system for a retail venue. Alternatively, the require-
ment could equally as well be the design of a system
accommodating the needs of a multi-purpose arena
having a seating capacity greater than the population
of a small city. A competent designer would treat
both of these with the same degree of profession-
alism. The responsible designer, in addition to
formulating a design that accomplishes the neces-
sary acoustical goals, must also tailor the design to
match the capabilities and training level of the
personnel who will be called upon to operate and
maintain the system. The writer was taught as a
youngster that a good hunter must always adjust the
caliber of the weapon to match the game being
sought. One does not pursue Cape buffalo with an
air rifle nor does one hunt squirrels with 155 mm
howitzers. Overly complicated systems can and do
fall in disarray if the operating personnel lack suffi-
cient expertise. Under-designed systems often fail to
meet the required acoustical and operational goals.
The design of a system for a given venue and
purpose, unlike the solution to certain math equa-
tions, is not unique. There are more ways than one
to skin a cat and some cat skinners are more artful
than are others.
25.1 Acoustical Analysis
System design always begins with an acoustical
analysis of the space involved. Many of the
preceding chapters have been devoted to the various
aspects of acoustics that ultimately bear on the
determination of loudspeaker properties and loud-
speaker arrangements necessary to provide sound
having adequate coverage, intelligibility, and level.
Once the required loudspeaker properties are at hand
a search of manufacturers’ specification sheets can
be initiated to identify the particular loudspeakers
that may be employed in the system. Acoustical
analysis also determines the type or types of loud-
speaker arrangements required, in particular whether
the requirement is for a single source array, such an
array supplemented by satellite arrays, or a distrib-
uted set of loudspeakers, etc. Once the loudspeaker
arrangement is decided upon it becomes possible to
determine the power amplifier requirements. It is
obvious at this point that we are working backwards
from the loudspeakers toward the input of the
system in building up the design. Rather than
proceeding further with a general discussion it may
be more informative to work through some alterna-
tive designs for a particular acoustical space while
making use of the full range of audio technology
that is presently available.
25.2 Alternative Solutions for a Given Space
The space to be considered is that of a large rever-
berant house of worship having a fan shaped seating
plan. In order to achieve speech intelligibility in this
space while simultaneously maintaining source
identity it is necessary to employ a central source
supported by step delayed satellite sources. A plan
view of the space appears in Fig. 25-1.
The loudspeakers are each elevated in a similar
manner above the seating areas and tilted downward.
The area covered by each loudspeaker is approxi-
mately the same. This is accomplished by posi-
tioning the satellite loudspeakers on two circular arcs
centered on the central source and increasing the
loudspeaker density proportional to the square of the
arc radius. In this instance only two arcs are required
necessitating two steps of signal delay. The loud-
speakers themselves are full range, three way units,
and in the initial treatment are considered to have
appropriate passive crossover networks. Each loud-
speaker is allotted 200 W. The single line diagram for
the initial treatment is presented in Fig. 25-2.
Figure 25-1. Plan view of seating space illustrating loud-
speaker placement.
Figure 25-2. Single line diagram for basic treatment.
MX
EQ
DL
A
A
A

580
Chapter 25
The basic treatment is essentially all analog with
the single exception being the two step signal delay.
Even the signal delay has an analog input and two
analog outputs. For the sake of simplicity attenua-
tion or voltage sensitivity settings are not shown. A
single equalizer is sufficient, as all loudspeakers are
the same and mounted similarly. The equalizer can
be all active or passive with a gain makeup stage.
All circuitry is balanced in and out with the excep-
tion of the power amplifiers. The power amplifiers
have balanced inputs and unbalanced outputs. From
left to right, the power amplifiers are progressively
200 W, 400 W, and 800 W. One variation on this
basic treatment worth consideration is that of having
individual power amplifiers for each loudspeaker.
This variation appears in Fig. 25-3.
In the variation of Fig. 25-3 all of the power
amplifiers are the same and some redundancy has
been introduced. If a spare amplifier is provided for
the source loudspeaker, the system can limp along
when a power amplifier fails. In both the basic
treatment as well as in the variant, the system can
survive failure of the equalizer. Dedicated equalizers
are provided with bypass switches and should be
operated as unity gain devices. Bypassing a failed
equalizer will produce a change in sound quality but
not in sound level.
The basic treatment as well as its variant
employing a digital signal delay would have first
been a possibility in the early 1970s as digital signal
delays were not available prior to that time. Prior to
that time signal delay had to be accomplished by
analog only techniques that are crude as compared
with present day techniques. Short delays were
accomplished by having a loudspeaker drive a plane
wave tube that was provided with pickup micro-
phones spaced at appropriate distances along the
tube. Longer delays could be achieved with modi-
fied tape recorders provided with a single recording
head and several physically spaced reproduce heads.
The plane wave tubes had to be physically longer
than the maximum delay distance interval in order
to allow for a non-reflective termination and had to
be isolated in long attics or other such spaces. The
tape recorders had to employ continuous running
high-speed tape loops that were prone to breakage
without warning. The “good old days” were not
always that good in certain respects.
25.2.1 More Modern Treatment
A more modern treatment of the acoustical space
discussed above relies more heavily on digital signal
processing circuitry. Following along with this
change the three way loudspeakers will be crossed
over actively rather than passively with the cross-
over function preceding power amplification. The
single line diagram for this approach appears in Fig.
25-4.
In the treatment of Fig. 25-4 the mixer can be all
analog or a digital mixer with either analog outputs
or digital outputs featuring AES/EBU connectivity.
This treatment introduces loudspeaker management
systems or LMS. These units when first introduced
featured only balanced analog inputs and outputs.
They have subsequently evolved to the point where
both analog and digital inputs and outputs are avail-
able. The digital inputs and outputs conform to the
AES/EBU standard. All internal processing is
performed by DSPs. An LMS can incorporate all of
the following functions:
1.
One-third octave equalizer.
2.
Parametric equalizer.
3.
Signal delay.
4.
Choice of crossover type and order.
5.
Compressor/limiter.
Figure 25-3. A variation on the basic treatment.
MX
EQ
DL
A
A
A
A
A
A
Figure 25-4. Treatment employing increased digital
signal processing.
A
A
A
High
Mid
Low
To single
zero delay
three way
loudspeaker
To two
first delay
three way
loudspeakers
To four
second delay
three way
loudspeakers
A
A
A
High
Mid
Low
A
A
A
High
Mid
Low
MX
L
M
S
L
M
S
L
M
S

Putting It All Together
581
The units are usually configured to offer four
analog/digital inputs with either four or eight
analog/digital outputs. Setup may be accomplished
with front panel controls aided by a display screen
or through a serial interface such as RS/EIA 232 to a
computer provided with the appropriate software.
The computer in turn may be part of a larger
network. The employment of these units with a
digital mixer is particularly desirable for a number
of reasons other than the option of direct digital
connectivity. Even though emphasis has been placed
on the main house system in the stated example,
houses of worship also feature many auxiliary
systems. Typically there are separate listening
systems for the choir and for the hard of hearing.
Additionally, the mixer must provide separate audio
feeds for radio broadcast, television broadcast, and
recording. Digital mixers have the capability to store
several different preset scenes that may be called up
according to the dictates of the particular program
being presented. Digital mixers in addition to the
ordinary analog inputs also accept direct digital
inputs such as AES/EBU, SPDIF, and MIDI.
A variant on the treatment described immediately
above replaces the conventional analog in, analog
out power amplifiers with amplifiers that accept a
digital input. These amplifiers are based on conven-
tional class D or similar amplifiers that have been
modified to convert pulse code modulated signals
into the pulse width modulated signals required by
amplifiers that feature switching in the output stage.
With such amplifiers, the required digital to analog
conversion occurs in the low pass filter following
the switching output stage. At this point, analog
signals exist only at the system input and output
transducers with all required signal processing
having been accomplished in the digital domain. 
25.2.2 Virtual Sound Processor
LMS is well adapted for many installations but does
have limitations. Many hardware boxes are required
for large installations and the list of functions
performed by an individual unit falls short of what
may be required in many systems.
Peavey Electronics Corporation addressed these
shortcomings in 1993 through the introduction of
the MediaMatrix® system. This system is designed
around a software based, integrated sound system
design, control, and hardware platform. The hard-
ware platform utilizes a modular computer main-
frame with a variety of supporting disk drives, a
system controller board, and several digital signal
processing boards. The system features a graphical
user interface supplied with a library of several
hundred software audio devices. The scope of this
library is such that the user may fashion practically
any conceivable audio system. The user simply
selects the required devices from the library and
“wires” them up on the computer generated display
and control surface.
Analog signals are received from or communi-
cated to the outside world via supporting hardware
analog break out boxes. Similarly, digital signals are
received from or communicated to the outside world
via supporting hardware CobraNet® break out
boxes. Real time network communication and
control of digital audio signals is by means of
10/100Base T Ethernet accompanied by CobraNet®
hardware interface. In order to produce a complete
system, the user need only supply the original audio
signal source or sources in either analog or digital
form and the necessary power amplifiers and
speakers.
The MediaMatrix® system constituted the first
viable virtual sound system processor. This system
also featured internal diagnostics and the capability
to expand to almost any size required. It can be
employed in our simple example system as illus-
trated in Fig. 25-5 but more importantly, it equally
as well can be employed to serve all of the audio
needs of a giant international airport system as well
as any system in between.
Following the trail blazed by Peavey, other
manufacturers are now offering their versions of
virtual sound processors.
Although not commonplace at the moment, in
the not too distant future analog to digital conver-
sion will occur at the system microphones with
Figure 25-5. Virtual sound system processor treatment.
A
A
A
High
Mid
Low
To single
zero delay
3 way
loudspeaker
To two
first delay
3 way
loudspeakers
To four
second delay
3 way
loudspeakers
A
A
A
High
Mid
Low
A
A
A
High
Mid
Low
MX
V
i
r
t
u
a
l
 
S
o
u
n
d
 
P
r
o
c
e
s
s
o
r

582
Chapter 25
these signals being communicated directly to the
system mixer or virtual system processor by optical
cables making the system immune to both hum and
radio frequency interference.
25.3 Device Interconnections
We will now explore the device interconnections
required in the various treatments of the house of
worship system discussed above. In the course of
doing so we will identify the wiring techniques,
connection techniques, and communication stan-
dards that will be the subject of detailed later discus-
sion. Microphones typically require shielded twisted
pair circuitry. In fixed installations this usually takes
the form of a short flexible cable attached to the
microphone by means of a female XLR-3 connector.
This cable in turn is terminated by a male XLR-3
connector that is inserted into a wall or floor
mounted receptacle fitted with a female XLR-3
connector. The microphone cable itself must be
highly flexible and free of triboelectric effects. This
is usually accomplished by employing a braided
shield over an insulated twisted pair with the combi-
nation being covered by a woven fabric. This struc-
ture is in turn covered by a rubber or neoprene-
insulating jacket. From the first receptacle, the
microphone circuit continues within a conduit to a
second receptacle mounted in the vicinity of the
mixer location. The wiring within this conduit is
usually in the form of an insulated twisted pair
covered by aluminum foil and a drain wire. This
foil-covered pair is in turn encased by an insulating
jacket. The second receptacle is fitted with a male
XLR-3 connector. A short cable similar to that
attached to the microphone completes the circuit to
the mixer input. Close attention must be directed to
the grounding techniques employed in this wiring
arrangement.
In the initial treatment of Fig. 25-2 and its variant
of Fig. 25-3 all of the signals in connecting links are
analog. All of the circuitry is balanced with the
exception of that associated with the loudspeaker
wiring. The loudspeaker wiring may or may not be
balanced depending on the details of the amplifier
output design. The output connector of the analog
mixer is a male XLR-3 while the input connector to
the equalizer unit may be a female XLR-3, screw
terminals on a barrier strip, or “Euro” style terminal
block inputs. The output of the equalizer can feature
the same diversity of connectors with the XLR-3
being male rather than female. This array of connec-
tion possibilities is likely repeated on the signal
delay unit. The power amplifiers will feature a
similar choice of input connections while the output
connection possibilities are binding posts, screw
terminals on a barrier strip, or Neutrik loudspeaker
connectors. The balanced circuit linking connections
more than likely would employ a foil sheathed
twisted pair of the same type employed in the micro-
phone conduit. The primary consideration in loud-
speaker wiring is the total wire resistance as
compared with the impedance presented by the
loudspeaker load. This is true for two reasons.
Firstly, when the amplifier drives the loudspeaker
directly, the circuit current, I, is common to both the
wiring resistance, Rw , and the loudspeaker imped-
ance, Zl. This being the case, at any particular
frequency it is possible to write the following
average power relationships:
(25-1)
where,
Pt is the total average power,
ϕ is the loudspeaker impedance angle.
The real part of the loudspeaker impedance is given
by
(25-2)
The fraction of the total average power that is deliv-
ered to the loudspeaker is then
(25-3)
Eq. 25-3 clearly indicates that in order to deliver
most of the power to the loudspeaker, the wiring
resistance must be small as compared with the real
part of the loudspeaker impedance. Long wire runs
will thus require wire of large diameter in order to
maintain the wiring resistance at a sufficiently small
value. In many instances, particularly when dealing
with large powers, rather than employing large
diameter wire, it is more economical to employ a
step-up transformer at the amplifier output and a
step-down transformer at the loudspeaker location.
In such instances, the wiring resistance is compared
with a transformed real part of the loudspeaker
Pw
I2Rw
=
Pl
I2 Zl
ϕ
cos
=
Pt
Pw
Pl
+
=
Rl
Zl
ϕ
cos
=
Pl
Pt
-----
I2Rl
I2Rw
I2Rl
+
---------------------------
=
Rl
Rw
Rl
+
------------------
=
1
Rw
Rl
------
1
+
----------------
=

Putting It All Together
583
impedance that is now n2 times as large as before, n
being the step down transformer’s primary to
secondary turns ratio. Common voltage values
employed in such an application are 70.7 V, 100 V,
and 200 V. Shielded cable is not required for loud-
speaker wiring and is in fact undesirable. High
voltage loudspeaker wiring, however, must be
contained in conduit in order to meet electric code
requirements. Secondly, loudspeakers are designed
with the assumption that the driving source resis-
tance is negligible as compared with the nominal
loudspeaker impedance. Modern power amplifier
source resistances certainly meet this requirement
but the source resistance seen by the loudspeaker is
that of the amplifier plus that of the loudspeaker
wiring. A large value of source resistance as viewed
by the loudspeaker will be detrimental to both the
steady state response of the loudspeaker and more
particularly to its transient response. For this reason
also, direct connection between power amplifier and
loudspeaker requires low resistance wiring. Higher
resistance wiring can be tolerated in the high voltage
system as the loudspeaker views a resistance equal
to the wiring resistance divided by n2.
The system treatments of Figs. 25-4 and 25-5
require digital signal interconnections. These
connections require special cabling and communica-
tion protocols. The digital signals being communi-
cated require a considerably larger bandwidth than
that required by analog audio signals. One conse-
quence of this increased bandwidth requirement is
that lengthy interconnections must be treated as
transmission lines. A transmission line, in order to
operate properly, must have a well-defined charac-
teristic or surge impedance and must be properly
terminated in order to prevent reflections. The
following pages are devoted to the grounding and
shielding requirements of analog audio signal inter-
connections and detailed discussions of the commu-
nication standards, protocols, and cable structures
required for digital audio signal communication.
25.4 Analog Interconnection Circuitry Types
There are basically two types of analog interconnec-
tion or link circuitry. Link circuitry is designated as
either being balanced or unbalanced. Link circuitry
in professional audio systems should in general be
balanced with very few exceptions. One such excep-
tion is that of loudspeaker power circuitry which can
be either balanced or unbalanced. Another exception
occurs when provisions must be made to accept
signals from unbalanced musical instrument sources
as well as consumer or non-pro audio gear such as
CD players, etc.
25.4.1 Balanced Circuits
A balanced circuit in its simplest form consists of
two conductors that are symmetrical with respect to
ground. Symmetry with respect to ground requires
that the measured impedance between each
conductor and ground must result in the same value
of impedance. One of the consequences of this
requirement is that the signal voltage measured
between either conductor and ground will have an
amplitude equal to one-half of the amplitude of the
total signal voltage as measured between the
conductors. Furthermore, the polarities of the two
line to ground voltages are opposite. This situation
is depicted in Fig. 25-6.
In Fig. 25-6, vs is a time dependent signal voltage
generator having its own internal or source imped-
ance and Zl is the terminating load impedance for
the balanced circuit. The virtual impedances Zg
represent the individual line to ground impedances
measured with the signal voltage equal to zero and
with the source impedance and terminating load
impedance in place. The ground connection at the
mid-point of the two Zgs forces this point to be
always at ground potential. The voltage between the
upper conductor and ground will be 
 while the
voltage between the lower conductor and ground
will be 
 That is, the two voltages are equal in
magnitude but opposite in polarity.
One of the major attributes of a balanced circuit
is its ability to reject common mode voltages. The
word rejection as used here means that common
mode voltages will not produce current in the load
impedance Zl. A common mode voltage is one
where in the absence of the signal voltage vs, both
the upper conductor and the lower conductor will
display identical voltages measured with respect to
ground. Such voltages add to zero when summing
around the entire circuit loop and thus do not
produce current in the terminating impedance. There
are occasions when a common mode voltage is
purposely introduced into the circuit. One such
occasion is that of supplying polarization voltage for
capacitor microphones. The reader is referred to
Figure 25-6. Basic balanced circuit.
ZS ⁄ 2
ZS ⁄ 2
vS
V
Zg
Zg
Z1
v 2
⁄
v
–
2.
⁄

584
Chapter 25
Figs. 17-27 and 17-28 of Chapter 17 Microphones,
Section 17.8 for circuit examples and discussion of
this application.
25.4.2 Balanced Circuits and Susceptibility to 
EMI
Even when loudspeaker power linking circuits are
excluded, analog audio linking circuits are called
upon to handle a tremendous range of voltage levels.
Microphone signals alone have normal operating
voltage levels which vary from as low as −80 dBV
up to about −20 dBV. So-called line level sources
might exhibit normal values between −20 dbV to
+4dBV while mixer output levels can range up to
+20  dBv or more. Electrical noise of any type
appearing in microphone circuits is particularly
troublesome because of the large degree of voltage
amplification applied to such circuits.
Linking circuits that normally operate at higher
levels must also be protected from electrical noise.
There are quiet times and pauses in all program
material. One can well be amazed how loud 100 mV
of 60 Hz hum measured at a bass amplifier output
can sound as played through an efficient loud-
speaker system in a quiet auditorium. Even though
balanced circuits inherently reject common mode
signals whether purposely introduced or, under
certain conditions, introduced as a result of electro-
magnetic interference (EMI), such circuits are not
immune to EMI in general.
As an example, suppose the physical geometry of
a linking circuit is similar to that of the drawing in
Fig. 25-6. In this instance there are two long parallel
conductors insulated from each other such that there
exists a small but finite distance between the
conductors, with the entire circuit forming an
extended skinny closed loop. Further suppose that
nearby there is an ac power raceway containing
loosely separated power conductors with the
raceway roughly running in the same direction as
the link circuit. There will then be a predominantly
60Hz alternating magnetic field in the vicinity of
the link circuit. Any alternating magnetic flux that
penetrates the area defined by the interior of the link
circuit will induce an emf in the link circuit that
obeys Lenz’s law. This induced emf will produce a
circulating current in the link circuit that attempts to
oppose the externally applied flux change that
brought it about. The unfortunate result is this
induced voltage is not a common mode voltage but
rather is of the same nature as is the desired signal
voltage. The induced voltage will combine with the
signal voltage with the combination of the two
appearing across the load Zl. The power line is also a
nearby source of other noise components. The 60Hz
waveform is not a pure sinusoid and hence there will
always be higher frequency harmonics present such
as 120, 180, 240 Hz, etc. Silicon controlled rectifiers
or similar devices as employed in lighting controls
and dimmers introduce periodic damped radio
frequency oscillations on the power line that can
also induce noise signals in our example link circuit.
In modern times our audio equipment is
constantly awash in a sea of electromagnetic radia-
tion. In addition to the ordinary commercial AM,
FM, and TV transmissions we now have cell
phones, communication radios, wireless micro-
phones, and a host of other electronic devices all of
which are sources of electromagnetic waves that can
lead to electromagnetic interference. This being the
case, a few words about the nature of electromag-
netic waves should be of value.
25.4.3 Brief Description of Electromagnetic 
Waves
A wave of any type is a physical disturbance that
propagates with a characteristic velocity such that
the disturbance is a function of both position and
time. In the case of sound waves in air the distur-
bance is a variation in acoustic pressure and particle
velocity occurring along the direction of propaga-
tion and hence is called a longitudinal wave. The
acoustic pressure is called a scalar quantity as it has
no direction. The particle velocity is a vector quan-
tity having both magnitude and direction. The
particle velocity oscillates back and forth along the
direction of propagation of the wave.
Sound waves of course transport acoustic energy.
Unlike sound waves in air, electromagnetic waves
are transverse. The disturbance involves two vector
quantities that are at right angles to each other in
space with the pair in turn being at right angles to
the direction of propagation of the disturbance. One
of these vector quantities is called the electric field
strength or E while the other is called the magnetic
field strength or B. If the wave existed in air or in a
vacuum and were to consist of a single frequency
component, then both E and B would be undergoing
sinusoidal oscillation in phase along their respective
directions. A third vector quantity called the
Poynting vector or S can be calculated from E and
B. S always points in the direction of propagation
and hence is always perpendicular to both E and B.
The physical significance of S is that of the wave
intensity or energy per unit area per unit time that is
being transported by the wave. Electromagnetic
waves can propagate freely in space and in air where
the only loss is the normal spherical spreading with

Putting It All Together
585
distance. The magnitude of the wave velocity in air
is nearly the same as that in a vacuum for which the
value is very close to 3 × 108 m/s.
Electromagnetic waves can also be guided by
conductors such as on a transmission line or inside
of hollow conducting pipes which are in fact called
waveguides. The propagation velocities for guided
waves are typically 60% to 70% of the free space
value. In guided conditions there is no spherical
spreading but attenuation does exist because of heat
losses in the conductors. Electromagnetic waves can
also propagate through other material media both
insulating and conducting. The propagation velocity
in insulators is typically 80% of the free space value
and the waves are usually only weakly attenuated.
The propagation velocity in the interior of good
conductors such as copper is dramatically reduced
as compared with free space conditions.
For example, at a frequency of 106 Hz an electro-
magnetic wave propagating through the interior of a
slab of copper would have a propagation velocity of
approximately 400 m/s. This is just a little more than
the speed of sound in air! Furthermore, an electro-
magnetic wave propagating in the interior of a good
conductor is rapidly attenuated as we will soon
discover. The usual wave relationship between
frequency, wavelength, and propagation velocity,
(λf = c), also applies to electromagnetic waves
provided one employs the appropriate velocity for
the guide conditions or medium in question.
Unlike sound waves in air, electromagnetic
waves can be linearly polarized. The axis of polar-
ization is that of the electric field. Fig. 25-7 illus-
trates the relationship between the field vectors for
four different circumstances.
In each instance in Fig. 25-7 the field vectors
form a mutually perpendicular set. In A and B the
polarization is vertical with E oscillating along the
vertical axis while B does so in the horizontal plane.
In A the wave progresses to the right along the hori-
zontal while in B it advances to the left along the
horizontal. In C and D the polarization is horizontal
with E oscillating along a horizontal axis while B
does so along a vertical axis. In C the wave
progresses to the left along the horizontal while in D
the wave progresses to the right along the horizontal.
When an electromagnetic wave encounters a
boundary surface or a change in medium a portion
of the wave is reflected and a different portion is
transmitted into the surface or into the new medium.
The details of this process depend upon a number of
factors. These factors are the angle of incidence on
the surface, the polarization of the wave, the thick-
ness of the second medium, and the electric and
magnetic properties of the reflecting surface or
medium. Of particular importance is whether the
reflecting material is an electrical conductor or an
electrical insulator. Highly conducting materials that
are sufficiently thick reflect most of the incident
electromagnetic energy particularly when the direc-
tion of propagation of the incident wave is perpen-
dicular to the surface. The small portion of the wave
not reflected by the conductor, the transmitted
portion, is attenuated as it progresses deeper and
deeper into the interior of the conductor. The attenu-
ation of the field strengths, both electric and
magnetic, as the transmitted wave penetrates the
conducting material is given by
(25-4)
where,
A is the dimensionless attenuation factor,
x is the penetration depth in m,
e is the base of the natural logarithm,
δ is the skin depth.
The skin depth, δ, is the penetration into the
conducting material at which the attenuation factor
becomes e−1 or 0.368. For all practical purposes the
fields are completely attenuated after having trav-
eled a distance of ten skin depths into the interior of
the conductor. For a good conductor such as copper,
the skin depth is given by
(25-5)
where,
f is the frequency in Hz,
Figure 25-7. Cases illustrating the relationship between
the field vectors for different polarizations and direc-
tions of propagation.
E
B
S
B
S
E
S
E
B
B
E
A.
B.
C.
D.
S
A
e
x
δ--
–
=
δ
1
πfμσ
-------------
=

586
Chapter 25
μ is the magnetic permeability in H/m,
σ is the electrical conductivity in siemen/m.
The frequency dependence of the skin depth
when the conducting material is copper is exhibited
in Fig. 25-8.
Table 25-1 presents a tabulation of skin depth
values for copper at a few selected frequencies.
25.4.4 Shielding
Consider the task of completely shielding the circuit
of Fig. 25-6 from the harmful influence of electro-
magnetic waves. This might be accomplished by
encasing the entire circuit in a box made of copper
or other good metallic conductor. If the walls of the
box are as thick as 10 skin depths for the conducting
material in question at all frequencies that are likely
to be encountered, then two things will occur.
Firstly, most of the electromagnetic energy incident
from the exterior will be reflected at the outer
surfaces of the box. Secondly, the weak transmitted
residual wave energy will be completely absorbed as
heat in the walls of the box before penetration of the
total wall thickness occurs. The only wave energy in
the interior of the box will be that of the signal that
is being guided by the conductors constituting the
balanced circuit. A perusal of Eq. 25-5, Fig. 25-8,
and Table 25-1 indicates that at 60 Hz for a copper
shield the wall thickness must exceed about ten
times 8 mm, 80 mm, or about 3 inches. This would
indeed be an expensive and impractical solution.
The objective, of course, is to make the balanced
circuit insensitive to the influence of external fields
that can generate loop as opposed to common mode
voltages in the balanced circuit. Instead of forming
the circuit from a pair of parallel conductors having
a small but finite distance between them, the circuit
should be formed of a tightly twisted pair of conduc-
tors as illustrated in Fig. 25-9.
This figure, as well as the following discussion,
is first presented in Chapter 17 Microphones and is
repeated here for convenience. In Fig. 25-9 imagine
that the twisted pair of conductors is replicated both
to the right and to the left to form an extended
circuit containing many twists with a small but
uniform spacing between twists. Imagine also that in
the vicinity a magnetic field is instantaneously
directed into the figure as indicated by the Xs and
that the field strength is increasing with time.
Examine the two closed paths as indicated by the
circles. According to Lenz’s law, the induced
voltage acting in the loops has the sense indicated
by the arrows. Now look at the white conductor in
the upper left, the induced voltage in this portion of
the conductor acts in the direction of the arrow adja-
cent to it. Compare that with the induced voltage in
the white conductor in the lower right in which the
induced voltage acts in the opposite direction.
The same analysis applied to the two similar
segments of black conductor yields identical results.
There is no voltage induced in the transposition
region as the arrows in adjacent circles are oppo-
sitely directed. In practice, the magnetic field alter-
nates but as it changes its direction of growth, the
induction in the loops reverses direction also while
the net voltage induced in the transposed conductors
Figure 25-8. Skin depth as a function of frequency for
copper.
Table 25-1. Skin Depth Values
f in Hz
δ in mm
102
6.56
105
0.208
106
0.0656
107
0.0208
108
0.00656
109
0.00208
105             106             107              108                109
Frequency−Hz
0.25
0.20
0.15
0.10
0.05
0
Skin depth−mm
Figure 25-9. Twisted pair exposed to a time changing
magnetic field.
X
X
Twisted Pair

Putting It All Together
587
remains at zero. Complete cancellation of loop
voltage will occur as long as there are many uniform
twists in a distance equal to the wavelength of the
offending field. Twisted pair audio cable of the type
employed for microphones, etc., has about ten twists
per foot. The frequency corresponding to a
freespace wavelength of one foot is approximately
109 Hz. A twisted pair alone provides induced loop
noise immunity from the very lowest frequencies up
to about at least 108 Hz.
Twisted pair microphone cable is also supplied
with a tightly braided copper shield. Even though
such a shield does not provide total coverage, there
are very tiny open spaces in the weave, the openings
have dimensions that are small as compared with the
wavelength of radiation up to about 1012 Hz. Radia-
tion at lower frequencies than 1012 would view such
a shield as being continuous. This braid is usually
thick enough to provide total shielding above
107Hz. Finally, if the braided shield is connected
solidly to ground through the metal chassis housing
the driving circuitry, the balanced conductors are
shielded from capacitive coupling to external nearby
power line or loudspeaker circuits. The shield in this
instance provides a return path to the source for
capacitively coupled noise currents.
25.4.5 Unbalanced Circuits
An unbalanced link circuit consists of an unbalanced
line driving circuit and an unbalanced receiving
circuit with the communication between the two
circuits occurring over two conductors. The two
conductors preferably are in the form of a coaxial
cable that consists of an insulated central conductor
and an outer braided shield. According to Maxwell’s
equations, coaxial cables themselves do not produce
either electric or magnetic fields outside of the outer
shield when the current in the inner conductor is
equal in magnitude but oppositely directed to that in
the outer conductor. Furthermore, when the shield
supports an additional current there is no magnetic
field in the region between the shield and the inner
conductor attributable to the additional current.
Unfortunately an unbalanced circuit is highly
susceptible to electromagnetic interference at practi-
cally all frequencies and is particularly susceptible
to power line induced interference. Consider the
arrangement depicted in Fig. 25-10.
In Fig. 25-10 an unbalanced line driver is
connected to an unbalanced line receiver by means
of a coaxial cable. Good grounding practice is
employed in the line driver in that the signal
circuitry ground connects to the power supply
ground and the ac power circuit safety ground wire
at only one point where all three are bonded to the
metal shield or chassis enclosing the driver circuitry.
The same is true for the unbalanced line receiver.
The driver output connects directly to the center
conductor of the coax as does the receiver input. The
driver-receiver signal circuit is completed through
the outer shield of the coax that connects directly to
the respective metal enclosures at each end. All of
this is good practice and causes no problem in and
of itself. This entire arrangement, however, is
usually immersed in external alternating fields asso-
ciated with both commercial ac power circuitry and
radio frequency sources.
Consider the possible conducting path defined by
the sequence of points a, b, c, d, e, f, g, h, and back
to a. Any alternating field that produces a changing
magnetic flux through the area defined by this path
will induce an alternating current that will circulate
around this conducting path. This induced current
will exist in the shield of the coax. The shield of the
coax may have just a small dc resistance but it also
has an inductive reactance that increases linearly
with frequency such that the total impedance associ-
ated with the shield itself can be appreciable. There
then may be an appreciable induced noise voltage
difference between the two ends of the shield equal
to the product of the induced shield current with the
shield impedance.
As a result the genuine signal voltage as
measured between the center conductor and the
shield at the driver end will differ from the received
voltage measured between the center conductor and
the shield at the receiver end. The received voltage
will have been polluted by an amount equal to the
noise voltage existing between the two ends of the
shield. This phenomenon is called shield current
induced noise or SCIN. The susceptibility to SCIN
is an inherent shortcoming of unbalanced circuits.
Figure 25-10. Unbalanced driver and receiver circuit.
Driver
Coax shield
Receiver
Safety ground
wire
Safety ground
wire
Electric service ground
a
b
c
d
e
f
g
h

588
Chapter 25
25.4.6 Cables, Connectors, and the Pin 1 
Problem
Fig. 25-11 displays two popular types of connector
that are employed in analog audio linking circuits.
A major attribute of the XLR type of cable
mounted connector is the positive locking feature
that is activated when the male and female are
coupled together. Two conductor with shield cables
are made with a male connector at one end and a
female at the other so that standard length cables
may be readily joined to produce any desired length.
This is particularly helpful in non-permanent instal-
lations. In permanent installations cables are usually
made up on site having the lengths required. Chassis
mount versions of the XLR connector in both male
and female also feature positive locking when mated
with the appropriate cable connector.
The convention is that the connector associated
with a signal source is male while that associated
with a signal receiver is female. The figure also
displays a male TRS connector for cable mounting.
Cable mounted female TRS connectors are also
available but are seldom used, as this type of
connector does not have a positive locking feature.
Short cables having TRS plugs at each end are often
used with patch panels or jack fields. Cables having
a female XLR at one end and a TRS plug at the
other are often employed with devices that only
have TRS chassis mounted input jacks. Cables and
connectors intended for balanced linking circuits
can be employed with unbalanced systems also
whereas the converse is not true.
The standard pin assignment now in use has pin
1 connected to the cable shield, pin 2 connected to
positive polarity signal, and pin three connected to
negative polarity signal. When employed in unbal-
anced circuits, pin 1 is signal low or ground while
pin 2 is signal high. The TRS or tip-ring-sleeve
connector in the balanced application has the tip
corresponding to pin 2, the ring corresponding to pin
3, and the sleeve corresponding to pin 1. When
balanced XLR cables are used with microphones
that require phantom power, the positive side of the
dc phantom power circuit is fed to both pin 2 and
pin 3 as a common mode voltage while the negative
side of the phantom supply is connected to pin 1 as
described in Chapter 17 Microphones, Section 17.5,
and illustrated in Figs. 17-27 and 17-28.
25.4.7 The Pin 1 Problem
The pin 1 problem is of fairly recent origin and is
principally the result of two factors. The first factor
has to do with changes in manufacturing procedure.
The second has to do with a loss of memory with
regard to certain well-honed circuit engineering
practices. In former times chassis mount XLR input
and output connectors had metal housings and were
mounted directly through mating holes of a heavy
metal chassis that housed and shielded the associ-
ated electronic circuitry. All pin 1 terminals were
either bussed through heavy gauge wire and then
connected to the chassis or connected individually
directly to the chassis. The reference ground for the
active circuitry as well as the ground for the power
supply had their own connections to the chassis. In
permanent installations where custom cables were
made up on site, pin 1 was connected to the cable
shield only at the driving end for all subsequent
balanced linking circuits. For non-permanent instal-
lations employing pre-made cables, pin 1 was
connected at both sending and receiving ends of
balanced linking circuits. Both types of installation
were free of SCIN.
After the advent of printed circuit boards having
automated parts insertion and soldering some, not
all, manufacturers began to mount pcb XLR connec-
tors on printed circuit board subassemblies and also
began to connect pin 1 to the signal ground trace on
the printed circuit board. Thus birth was given to the
pin 1 problem as illustrated in Fig. 25-12.
The closed conducting loop in Fig. 25-12
described by the point sequence a, b, c, d, e, f, g, and
back to a can have noise current induced in it by the
same processes described with regard to Fig. 25-10.
This same current exists in a portion of the printed
circuit board signal ground trace or bus of both the
Figure 25-11.  XLR-3 and TRS connectors.
3
2
1
Male
Female
3
1
2
XLR3 connectors
Male TRS plug
Sleeve
Ring Tip
Figure 25-12. The origin of the pin 1 problem in
balanced linking circuits.
Active
Circuitry
Power
Active
Circuitry
Power
Braided shielded cable
Gnd bus
Gnd bus
2
3
1
2
3
1
b
a
g
d
c
e
f

Putting It All Together
589
send and receive circuits. The impedances of these
traces are small but nevertheless significant and
noise voltages will thus appear between various
stages of the associated active circuitry. Good elec-
tronic engineering practice would not have allowed
this to happen. The cure for this problem is illus-
trated in Fig. 25-13 that employs the time honored
star grounding scheme.
The SCIN loop of Fig. 25-13 now only involves
the point sequence a, b, c, d, e, and back to a and
there is no induced noise current on the active
circuit ground bus.
Comments on Pin-1 Problems
Neil Muncy, a consultant in Canada, is a pioneer in
the detection of Pin-1 problems, and has led the way
to their correction in faulty designs. He wrote
recently:
Regarding employing Pin-1 testing in
the evaluation of new equipment, my
long-standing policy is to categorically
reject a device if it fails a Pin-1 test.
Period. Send it back to the manufacturer
along with a letter explaining why.
Neil further comments:
It is up to the manufacturer to do
whatever objective research is required
to render their product subjectively free
of Pin-1 issues. This is not a burden that
should be dumped on the shoulders of
innocent customers. Any manufacturer
who cannot comprehend that when shield
current applied to a Pin-1 produces an
audible increase in output noise, should
not be in the audio business!
In today’s marketplace many consumer-oriented
devices end up being inserted into professional
systems where everything from their connectors,
impedances, and levels are not compatible with the
other equipment.
25.4.8 Removal of SCIN from Unbalanced 
Circuits
Before the development of electronically balanced
input and output circuits input and output trans-
formers were universally used to accomplish the
balancing tasks. Even today, such transformers are
still employed to perform this task in certain very
sensitive areas and particularly where ground isola-
tion is required. A case in point is the removal of
shield induced current noise in unbalanced circuits
as depicted in Fig. 25-14.
Fig. 25-14 shows an unbalanced line driver
connected to a coaxial cable at the sending end. The
receiver end of the cable is connected to the primary
winding of an input transformer that has a Faraday
shield as a part of its structure. The secondary of the
transformer is connected to the unbalanced receiver’s
input terminals and the Faraday shield is connected
to the receivers signal ground reference terminal.
Note that the cable shield is connected to ground at
the sending end only so that there is no ground loop
formed along which induced noise current might
exist. The connectors at each end are usually RCA
pin plugs and jacks. The employment of BNC male
and female coaxial connectors would be preferred as
they provide a positive locking feature.
25.4.9 Consumer Output to Balanced Input
On occasion it becomes necessary to connect a
signal source having an unbalanced output to a
mixer having balanced inputs. The signal source
may be a CD player, radio tuner, non-pro tape
player, or other similar devices whose output
connector is usually an RCA pin jack. In such
circumstances it is best to make up a braided shield
twisted pair cable with an RCA pin plug on the
sending end and an XLR on the receiving end with
the wiring connections being done as given in
Fig. 25-15.
Figure 25-13. SCIN removed from signal ground refer-
ence by star grounding technique.
Active
Circuitry
Power
Active
Circuitry
Power
Braided shielded cable
Gnd bus
Gnd bus
2
3
1
2
3
1
b
a
d
c
e
Figure 25-14. Transformer provided ground isolation.
Coax cable

590
Chapter 25
25.5 Signal Cables—Analog Audio, Digital 
Audio, and Video
All electric signal transmission by means of a pair of
conductors involves electromagnetic wave propaga-
tion with the conductors serving as boundaries for
both the electric and magnetic fields involved.
Knowledge of the electric field existing in the space
between the conductors at some particular location
along the conducting path and at some instant in
time allows one to determine the potential difference
between the conductors at that location and that
instant in time. Similarly, knowledge of the
magnetic fields at the surfaces of the conductors for
a particular location and time allows one to deter-
mine the currents existing in the conductors at that
location and instant of time. Maxwell’s equations
govern all electric, magnetic, and electromagnetic
phenomena regardless of frequency and circuit
dimensions.
In spite of, or perhaps because of, this univer-
sality, a great deal of mathematical expertise is
required in applying Maxwell’s equations to prob-
lems of a general nature. On the other hand, when
the dimensions of the circuit are small as compared
with the wavelength, Maxwell’s equations reduce to
the usual equations of lumped circuit element anal-
ysis involving Kirchhoff’s laws I and II along with
the usual definitions of capacitance, inductance, and
resistance. Let the circuit in question be the
connecting cable linking a single channel analog
audio driver and receiver. For a high frequency limit
of 20 kHz and assuming for the moment that the
wave speed is the free space value of 3 × 108 m/s,
the shortest wavelength would be 1.5 × 104 m or
approximately 10 miles. Most such linking circuits
in sound systems are orders of magnitude less than
this so simple lumped circuit element analysis is
valid and the cable can be modeled as displayed in
Fig. 25-16.
In Fig. 25-16, R is the total series resistance
considering both conductors, L is the total series
self-inductance considering both conductors, and C
is the total capacitance between the conductors
including the effect of a shield if present. This
model neglects the effect of shunt conductance in
parallel with the capacitance because with short
cables this conductance is so small as to have a
negligible effect. This model along with the source
impedance of the driving circuit and the impedance
presented by the load is sufficient for the calculation
of attenuation as a function of frequency employing
conventional circuit analysis techniques. One conse-
quence of this model is that, aside from direction,
the current in the upper conductor at a given instant
is everywhere the same as that in the lower
conductor. If the linking circuit dimensions were
comparable to the wavelength, this would not be
true and the model would be invalid.
25.5.1 Video and Digital Audio Signal Cables
The bandwidth for video signals extends from dc to
at least 6 MHz. The upper frequency limit corre-
sponds to a wavelength of approximately
 or 50 m. This low value
for wavelength is barely an order of magnitude
greater than the length of many video linking
circuits and in fact is comparable to or less than the
lengths of many such circuits. Video linking circuits
almost universally employ coaxial cables. A simple
lumped circuit model cannot describe the behavior
of the high frequency signals on such cables.
The problem is even more pronounced when
dealing with digital audio linking circuits. Such
circuits are recommended to meet standards as set
forth in AES3. AES3 is a standard recommended by
the Audio Engineering Society. The bandwidth
specified by this standard for a single digital audio
circuit communicating two channels of analog audio
is a function of the individual channel sampling rate.
The bandwidth specified by the standard for a
sampling rate of 192 × 103 samples per second is
24.576 MHz. A maximum frequency of 24.576 MHz
corresponds to a wavelength of approximately 12 m
and thus all such linking circuits are comparable to
or exceed the wavelength.
It is apparent that the description of the behavior
of video and digital audio signals when propagating
along connecting cables must be handled differently
from that of analog audio signals in the typical
sound system installation.
Figure 25-15. Adapter cable wiring for unbalanced to
balanced.
Hi
Lo
Hi
Lo
Shielded twisted pair
Shield
Shield
Figure 25-16. Lumped circuit model of analog audio
connecting cable.
R
L
C
3
108
 m/s
×
(
) 6
106
×
⁄
 Hz

Putting It All Together
591
25.5.2 The Cable Problem
The description of the behavior of voltages and
currents on extended cable structures is called the
cable problem. An extended cable is one whose
physical length is comparable to or larger than what
we now know as the wavelength. The cable problem
was first systematically studied and solved by Prof.
William Thomson, later Lord Kelvin, in the middle
of the nineteenth century. The problem was brought
to Thomson’s attention through the failure by others
to establish telegraphic communication over subma-
rine cables. The laying of successful telegraph
cables on the ocean floor between Europe and the
United States was the outstanding communication
problem of that era. At the time, Thomson had an
outstanding reputation in mathematical physics and
occupied the chair in natural philosophy at Glasgow
University in Scotland. Thomson’s solution to the
cable problem predated Maxwell’s Treatise and
probably contributed to Maxwell’s thought in the
ultimate formulation of his famous equations.
In formulating his model of the cable Thomson
simply required that the structure of the cable be
reasonably uniform. It mattered not whether the
physical arrangement was that of just a pair of insu-
lated wires uniformly spaced, a twisted pair in a
shield, a coaxial cable, etc. The only constraint was
that the series resistance, series self-inductance,
shunt capacitance, and shunt conductance, all per
unit of length, be uniform throughout the length of
the structure. Thomson considered the series resis-
tance and inductance as well as the shunt capaci-
tance and conductance to be continuously
distributed throughout the length of the system. He
furthermore allowed for the possibility that the
voltage between the conductors as well as the
current in or between the conductors could vary
significantly over small distances. Upon taking the
axis of the system as the x-axis he was able to write
equations relating the voltage, current, and the
circuit parameters in the form
(25-6)
where,
v is the voltage between the conductors at any point
x and time t,
i is the current in the conductors at any point x and
time t,
R is the series resistance per unit length,
L is the series self-inductance per unit length,
C is the shunt capacitance per unit length,
G is the shunt conductance per unit length.
Eq. 25-6 is a pair of coupled equations in that
both dependent variables or their partial derivatives
appear in each equation. Uncoupling these equations
leads to
(25-7)
and
(25-8)
Both the voltage as a function of position and
time as well as the current as a function of position
and time obey the same partial differential equation.
If the circuit is excited at the sending end by a sinu-
soidal voltage source then the solution to the voltage
equation will be of the form
(25-9)
The solution for the voltage between the conduc-
tors is a function of both position and time and
consists of two damped or attenuated waves. The
term with the A coefficient describes a wave propa-
gating from the source towards the receiver all the
while being diminished in amplitude as x increases.
Similarly the term with the B coefficient describes a
wave propagating from the receiver back towards the
source being attenuated as x decreases. This latter
wave is a reflected wave. The coefficients A and B
are in general complex and their values depend upon
the conditions that exist at the input and the output
ends of the cable. α and β are determined by the
cable parameters and the operating frequency. Their
structures in the general case are quite complicated.
In the general case they are given by
(25-10)
(25-11)
(25-12)
∂v
∂x
-----
Ri
L∂i
∂t
----
+
⎝
⎠
⎛
⎞
–
=
∂i
∂x
-----
Gv
C∂v
∂t
-----
+
⎝
⎠
⎛
⎞
–
=
LC∂2v
∂t2
--------
RC
LG
+
(
)∂v
∂t
-----
RGv
∂2v
∂x2
--------
–
+
+
0
=
LC∂2i
∂t2
-------
RC
LG
+
(
)∂i
∂t
----
RGi
∂2i
∂x2
--------
–
+
+
0
=
v x t,
(
)
Ae αx
–
e j ωt
βx
–
(
)
Be+αxe j ωt
βx
+
(
)
+
=
α
RG
LCω2
–
R2
ω2L2
+
(
) G2
ω2C2
+
(
)
+
2
-----------------------------------------------------------------------------------------------------
=
β
RG
LCω2
–
(
)
–
R2
ω2L2
+
(
) G2
ω2C2
+
(
)
+
2
--------------------------------------------------------------------------------------------------------------
=
α
jβ
+
R
jωL
+
(
) G
jωC
+
(
)
=

592
Chapter 25
25.5.3 Characteristic Impedance
If the cable were infinitely long there would only be
a forward propagating wave. This would require the
coefficient B to have the value of zero. In this
circumstance, 
. When
this is substituted in the first of Eq. 25-6 and evalu-
ated at the input end of the cable, it is learned that
(25-13)
This leads directly to
(25-14)
Zk is called the characteristic impedance of the
cable and represents the input impedance of a cable
of infinite length. If a cable of finite length is termi-
nated in an impedance equal to Zk the transmitted
signal will be completely absorbed and there will be
no reflection. Zk is also called the surge impedance
because even a cable of finite length that is improp-
erly terminated will present this impedance to the
driving source when the source is first connected to
the cable. The source will continue to see an imped-
ance equal to Zk for a time interval T where T is the
transit time required for a signal to propagate from
the source to the receiver, be reflected, and then
return back to the source. It is important to note that
if the operating frequency is sufficiently high, ωL
will be much larger than R and ωC will be much
larger than G. In this circumstance, Zk becomes
purely resistive as given by
(25-15)
The series self-inductance per unit length and the
shunt capacitance per unit length depend principally
upon geometrical factors. A larger spacing between
conductors increases L and reduces C thus leading
to higher values for the characteristic resistance.
25.5.4 Attenuation
α is known as the attenuation constant and in the
general case is frequency dependent. The attenua-
tion constant has the dimensions of reciprocal
length. After traveling a distance equal to the recip-
rocal of α, a forward traveling wave will have its
amplitude diminished by a factor of e−1 or 0.368.
The voltage amplitude change in dB as a function of
distance traveled can be written as
(25-16)
25.5.5 Phase Velocity
The phase angle of the forward traveling wave in the
case of sinusoidal excitation at the source is
(ωt −βx). The phase velocity of the signal on the
cable is the velocity that an observer must have in
order to observe a constant value for the phase
angle. As time increases uniformly, the observer’s x
coordinate must also increase uniformly such that
the phase angle retains a constant value. Therefore,
(25-17)
The observer’s velocity parallel to the cable axis
is dx ⁄ dt and is called c. In order for all frequencies
to propagate at the same velocity it is necessary that
c be a constant independent of the frequency. Only
under this condition will the transmission maintain a
complex waveform’s shape. This requires that β be
directly proportional to ω. Only a cursory glance at
Eq. 25-11 will indicate that this is not true in the
general case. It can be made so, however. If the
cable is constructed such that GL = RC then
Eqs. 25-10 and 25-11 simplify to
(25-18)
(25-19)
Eq. 25-19 then leads to a phase velocity that is
independent of operating frequency as given by
(25-20)
v x t,
(
)
Ae αx
–
e j ωt
βx
–
(
)
=
i t( )
α
jβ
+
(
)
R
jωL
+
(
)
------------------------v t( )
=
v t( )
i t( )
---------
R
jωL
+
R
jωL
+
(
) G
jωC
+
(
)
-------------------------------------------------------
=
R
jωL
+
G
jωC
+
---------------------
=
Zk
=
Rk
L
C----
=
20 dB
e αx
–
(
)
log
8.686αx  dB
–
=
or
8.686α dB/m
–
ωt
βx
–
(
)
constant
=
d
dt
----- ωt
βx
–
(
)
0
=
dx
dt
------
ω
β----
=
c
=
α
RG
=
β
LCω
=
c
ω
β----
=
ω
LCω
----------------
=
1
LC
-----------
=

Putting It All Together
593
The operation of the cable under these conditions
would be without distortion. Unfortunately, the
requirement that GL = RC is difficult to achieve in
practice and an alternative approach is followed.
Inherently, the shunt conductance is a small quantity
and if R ⁄ ωL can be made small also except of course
at very low frequencies, then Eqs. 25-10 and 25-11
become
(25-21)
(25-22)
In this case also the phase velocity is frequency
independent except of course at the lowest frequen-
cies. Typical phase velocities on cable structures
range between about 50% to 80% of 3 × 108 m/s
depending on conductor spacing and physical
arrangement.
The conclusions above with regard to distortion-
less operation assume that the cable parameters are
frequency independent. This can be approximately
true over only a restricted bandwidth. When a cable
is required to operate over a wide frequency range,
account must be taken of the fact that the cable
parameters are themselves frequency dependent.
The basic Eqs. 25-6 through 25-17 still hold true but
the attenuation constant, phase velocity, and charac-
teristic impedance will all have values that vary with
frequency. Of the four basic parameters, only the
capacitance per unit length is essentially indepen-
dent of frequency. The shunt conductance per unit
length accounts also for the dielectric losses that are
frequency dependent. The series resistance and
self-inductance per unit length are frequency depen-
dent because of a phenomenon known as the skin
effect that will be discussed subsequently. As a
result, wide-band signals transmitted over cables
require equalization to compensate for frequency
dependent attenuation and phase distortion. This
equalization is usually applied at the receiving end
for digital audio signals.
25.5.6 Skin Effect
Consider a long, straight homogeneous conductor of
cylindrical cross-section that is far removed from
other current carrying conductors. When such a
conductor supports a direct current, the current is
uniformly distributed over the entire cross-section of
the conductor. A uniform direct current distribution,
however, does not produce a constant static
magnetic field within the interior of the conductor.
Ampere’s law requires that the magnetic field at the
center of the conductor be zero.
Starting from the center where the magnetic field
is zero, the magnetic field strength grows linearly
with increasing radial distance from the center until
it reaches its maximum value at the surface of the
conductor where the radial distance equals the actual
radius of the conductor. Outside of the conductor,
the magnetic field strength begins to decrease being
proportional to the inverse of the total radial
distance measured from the conductor center.
Fig. 25-17A illustrates the magnetic flux distribu-
tion in the interior of the conductor. 
In Fig. 25-17A, the direct current is directed
toward the observer. The concentric circles repre-
sent lines of magnetic flux. The spacing or density of
the flux lines represents the magnetic field strength.
Note that the lines are closer together as one nears
the conductor surface indicating a stronger field in
this region. In Fig. 25-17B, a slice has been taken
through the center of the conductor. The slice
extends for a small distance along the cylinder axis
and the observer is looking down on this sectional
α
R
2---
C
L----
G
2----
L
C----
+
=
β
LCω
=
Figure 25-17. Magnetic field for direct current in a
cylindrical conductor.
A.
X X    X              X
X X    X              X
X X    X              X
X X    X              X
X X    X              X
X X    X              X
X X    X              X
X X    X              X
B.

594
Chapter 25
view. The uniformly spaced arrows at the bottom of
the figure represent the uniform distribution of direct
current over the cross-section of the conductor. The
arrows point in the direction of the current. The xs in
the left half of the figure indicate that the magnetic
flux is directed inward in this region whereas the
dots in the right half represent magnetic flux directed
outward in this region. Now imagine that the current
is alternating at a low frequency and that instanta-
neously the current is increasing in the direction of
the former direct current. This means that the
magnetic flux is also increasing in the respective
indicated directions. Consider now the lightly drawn
rectangle in the interior of the left half of the figure.
The magnetic flux through this rectangle is
increasing inward. Lenz’s law requires that the
induced emf acting in this rectangle must oppose this
increase in magnetic flux. It does so by driving a
circulating current in the counter-clockwise direc-
tion as indicated by the arrows on the rectangle. In
the right half of the figure the situation is just
reversed because the magnetic flux is increasing
outward. The induced current in the interior rect-
angle of the right half of the figure will be in the
clockwise direction. Note that in each instance, the
induced currents are oppositely directed to the orig-
inal current in the inner regions of the conductor
while being in the same direction as the original
current in the outer regions of the conductor that are
near to the conductor’s surface. The result being that
the net current is no longer uniformly distributed
over the conductor cross-section. There is a higher
current concentration near the conductor’s surface at
the expense of the inner regions. This phenomenon is
known as the skin effect. The effect is more
pronounced for conductors of large radius having a
large electrical conductivity and a large magnetic
permeability. For example, it is more pronounced in
steel wire than in copper. The effect is more
pronounced at high frequencies than low frequen-
cies and becomes even more pronounced as the
frequency continues to increase. Fig. 25-18 illus-
trates the current distribution in a 20 gauge copper
wire with no other nearby conductors.
The relative current density for direct current has
a value of unity at all points in the interior of the
conductor as indicated by the horizontal line. This
represents a uniform current distribution. Notice that
at 105  Hz, the distribution has become slightly
non-uniform with a higher current density near the
conductor surface. The effect is even more
pronounced at 106 Hz with practically no current
near the center of the conductor. At even higher
frequencies, the central region will become current
free with all current concentrated in a shallow
region or skin at the conductor’s outer surface.
Fig. 25-19 illustrates what happens to the
conductor’s resistance per unit length as the
frequency is varied over a large range.
Fig. 25-19 indicates that for an isolated 20 gauge
copper wire the ac resistance is essentially the same
as the dc value throughout the audio band with a
significant departure beginning above 105 Hz. For
larger gauge wires the departure will begin at lower
frequencies.
When two conductors are close to each other and
supporting equal but oppositely directed currents as
in a cable, the proximity of one conductor to the
other influences the current distribution in each
conductor. In this situation, although the skin effect
will be qualitatively the same in each conductor, the
details will be modified dependent on the conductor
spacing and other geometrical factors. The magnetic
field between the conductors and at the conductor
surfaces will also display frequency dependence
such that the inductance per unit length of the
Figure 25-18. Skin effect in a 20 gauge copper wire.
Figure 25-19. Ac resistance per unit length compared
with dc value for 20 gauge copper wire.
5.0
4.5
4.0
3.5
3.0
2.5
2.0
1.5
1.0
0.5
0
−5 
−4 −3 
−2 
−1 
0 
1 
2 
3 
4 
5
× 10−4
Relative current density
dc
105 Hz
106 Hz
Frequency−Hz
Normalized resistance per unit length
10
9
8
7
6
5
4
3
2
1
0
100 
101 
102 
103 
104 
105 
106 
107

Putting It All Together
595
conductors will depend upon both frequency and
geometry. This behavior can be calculated from
theory in closed mathematical form for certain
circuit geometrical arrangements such as coaxial
cables, balanced parallel conductors with or without
shield, and others. For a difficult geometry such as a
twisted pair in a braided shield, the frequency
dependence of cable parameters is usually deter-
mined through direct measurement. For communica-
tion over a large bandwidth, the measurements must
be carried out at numerous spaced frequency values
in the communication band of interest.
25.5.7 Measurement of Cable Signal Propaga-
tion Properties
In calculating what changes a signal undergoes as it
propagates along a length of cable, one needs to
know the characteristic impedance of the cable, the
source and termination impedances, the attenuation
constant, and the phase constant. The inherent cable
properties can be extracted from data provided by
two relatively simple impedance measurements
made at each frequency of interest. In this applica-
tion, it is usual practice to take the origin of coordi-
nates at the receiver end of a convenient length of
cable. The source is then located at an x coordinate
equal to −l where l is the physical length of the cable
measured in meters. Employing Eqs. 25-6 and 25-9
it is relatively simple to determine the voltage and
current at the source end of a length of cable under
two different termination conditions. The chosen
conditions are that of an open circuit condition at the
receiver and a short circuit condition at the receiver.
Upon taking the ratio of the voltage to the current at
the source end one finds the impedance presented by
the cable to the source under the given termination
condition. For an open circuit cable this impedance
is
(25-23)
where,
, 
l = cable length.
On the other hand, for a cable that is
short-circuited at the receiver the impedance
measured at the source end becomes
(25-24)
Multiplication of these two impedance values
directly yields the square of the characteristic
impedance so that
(25-25)
The square root of the quotient of these two
impedances after simplification yields
(25-26)
Eq. 25-26 can be manipulated to obtain
(25-27)
The expression on the right side of Eq. 25-27 is in
general complex so it may be written in exponential
form. The left hand side can also be rewritten to
produce
(25-28)
where,
,
M is the magnitude of Eq. 25-27,
θ is the angle of Eq. 25-27.
From Eq. 25-28 then
(25-29)
The attenuation constant can be determined
directly from the first of Eqs. 25-29 by taking the
natural logarithm of both sides. Care must be exer-
cised in solving for the phase constant in the second
of Eqs. 25-29. Dependent on the length of the cable
sample used in the measurement relative to the
wavelength of the signal on the cable, the angle of
Eqs. 25-29 can have a value less than 2π plus or
minus some integral multiple of 2π. For example, if
it is known that the test cable sample is less than a
wavelength long, then 0 < β < 2π. Finally, having
the value for the phase constant in hand, the last of
Eqs. 25-17 can be solved for the phase velocity on
the cable.
Zopen
Zk
e+Γl
e Γl
–
+
e+Γl
e Γl
–
–
-------------------------
=
Γ
α
jβ
+
=
Zshort
Zk
e+Γl
e Γl
–
–
e+Γl
e Γl
–
+
-------------------------
=
Zk
Zopen
(
) Zshort
(
)
=
Zshort
Zopen
--------------
1
e 2Γl
–
–
1
e 2Γl
–
+
---------------------
=
e 2Γl
–
1
Zshort
Zopen
--------------
–
1
Zshort
Zopen
--------------
+
---------------------------
=
e 2
–
α
jβ
+
(
)l
e 2αl
–
e j2βl
–
=
Me jθ
=
α
jβ
+
Γ
=
e 2αl
–
M
=
2βl
–
θ
=

596
Chapter 25
25.5.8 Sample Calculation
A one-meter sample of digital audio cable is oper-
ated at a frequency of 24.576 MHz in performing
both an open circuit and a short circuit impedance
measurement. The impedance observed at the
source terminals when the receiver terminals are
open is found to be (7.5184 − j136.61) Ω. The
impedance observed at the source terminals when
the receiver terminals are shorted is found to be
(4.8597 + j88.303) Ω . When these values are substi-
tuted into Eq. 25-25 the characteristic impedance of
the cable is found to be 110 Ω . Next one takes the
ratio of the short circuit impedance to the open
circuit impedance and substitutes the result into
Eq. 25-27. The ratio is found to be
(−0.64248 + j0.070933). Evaluation of the right side
of Eq. 25-27 produces (0.20384 – j0.92551). The
magnitude of this complex quantity is 0.94770 while
its angle is –1.3540 radians. These values are then
substituted into Eqs. 25-29. Upon taking the natural
logarithm on both sides of the first of Eqs. 25-29
and solving for α one obtains the value 0.02686 m-1.
This value can be used in connection with Eq. 25-16
to learn the attenuation rate on the cable is
–0.2333 dB m–1.
The second of Eqs. 25-29 can be solved directly
for β to obtain 0.67701 m–1. This value can be used
in turn with Eqs. 25-17 to determine that the phase
velocity on the cable at the operating frequency is
2.281 × 108 ms–1. This is 76% of the free space
value. It is of interest to note that when measure-
ments are made at one and two octaves below
24.576  MHz that the attenuation rate is
–0.1568dB m–1 and –0.1007 dB m–1, respectively
illustrating the increasing attenuation rate with
frequency brought about by the skin effect. These
results are summarized in Table 25-2.
25.5.9 To Terminate or Not to Terminate
The title of this section when posed as a question is
a reasonable one. The current Audio Engineering
Society standard that governs the electrical trans-
mission of digital audio signals over connecting
cables recommends a balanced system with both the
source impedance and the receiver impedance being
equal to the high frequency characteristic impedance
of the connecting cable. This means that the cable
“sees” its characteristic impedance at both ends.
This is a good recommendation for the general case,
particularly where the cable may not be a single
continuous run but rather may be spliced.
Alternatively, the cable might be made up of two
links joined by XLR connectors. Under either condi-
tion a reflection will occur at the discontinuity
sending a return signal back towards the source.
Such a reflection will be completely absorbed at the
matched source and no subsequent reflections will
occur. It should be mentioned, however, that a
circumstance may arise where it might be desirable
to terminate the cable in an impedance much higher
than the characteristic impedance at the receiver end
while maintaining a match at the source end. This
circumstance is one where the cable is a long single
continuous run. Such a long cable can introduce
enough attenuation that the receiver will be voltage
“starved.” In this regard, it is worthwhile to compare
the voltage at the receiver end under both matched
and nearly open circuit conditions. Fig. 25-20 illus-
trates the situation as viewed by the source emf
under the matched at both ends condition as well as
the condition where the source is matched but the
receiver has very high impedance.
The equivalent circuits of Fig. 25-20 allow the
rapid calculation of the voltage impressed across the
input terminals of the connecting cable at the source
location. In viewing Fig. 25-20A, remember that the
input impedance of any length cable that is termi-
nated in its characteristic impedance is the same as
its characteristic impedance. As we are working
Table 25-2. Sample Calculation Summary
Quantity
Measured
Calculated
Frequency
24.576 MHz
Zopen
7.5184 − j136.61 Ω
Zshort
4.8597 + j88.303 Ω
Zk
110 Ω
α
0.02686 m-1
β
0.67701 m-1
Attenuation rate
−0.2333 dB m-1
c
2.281 × 108 ms-1
Figure 25-20. Equivalent circuit at source when the
connecting cable is properly terminated, A, and termi-
nated in an open circuit, B.
vs
ZK ⁄ 2
ZK ⁄ 2
ZK ⁄ 2
ZK ⁄ 2
vs
ZK
Z0
A.
B.

Putting It All Together
597
with a balanced source, the source’s internal imped-
ance that is also equal to the characteristic imped-
ance of the cable has been indicated in two parts
with half in each leg of the generator. It should be
clear from the figure that half of the open circuit
voltage of the source appears across the input termi-
nals of the cable. The general expression for the
voltage anywhere on the cable is given by Eq. 25-9.
In this instance, there is no reflection because we
have a matched condition and B is thus zero. The
sinusoidal open circuit voltage of the generator is
given by
(25-30)
Upon taking the origin of coordinates at the
receiver, which places the source at x = −l where l is
the physical length of the cable, the voltage at the
input end of the cable becomes
(25-31)
from which is learned that
(25-32)
With the value of A in hand it is now possible to
write an expression for the voltage at the receiver
end where x = 0. Again employing Eq. 25-9,
(25-33)
When 
 is substituted into Eq. 25-33 the
final result becomes
(25-34)
The conclusion is that the voltage at the output is
an attenuated and phase shifted version of the
voltage at the input. Even in the absence of attenua-
tion, the maximum voltage at the receiver is only
one-half the voltage of the source. This result is to
be compared with the one derived from the situa-
tion depicted in Fig. 25-20B. Here the receiver has
high input impedance so the cable in effect is termi-
nated in an open circuit at the receiver end. When
there is an open circuit at the end of a cable, the
current at this location will be zero and the incoming
voltage signal is reflected in phase. This boundary
condition makes the coefficients A and B equal. An
inspection of Fig. 25-20B indicates that the voltage
at the cable input terminals is given by
(25-35)
where,
After simplification Eq. 25-35 yields
(25-36)
The voltage anywhere on the cable becomes
(25-37)
At the receiver end of the cable x = 0, so the voltage
there becomes
(25-38)
Comparing Eq. 25-38 with Eq. 25-34 indicates
that there is a factor of 2 or a 6 dB advantage in
having a high impedance termination at the receiver.
The conclusion is that for a very long continuous
run of cable it may be advantageous to employ a
receiver having an input impedance much higher
than the characteristic impedance of the cable.
25.6 AES3
AES3 is an Audio Engineering Society recom-
mended practice for digital audio engineering that
covers the serial transmission format for
two-channel linearly represented digital audio data.
Linearly represented digital audio data can be inter-
preted as being pulse code modulation or PCM.
Reference is made here to AES3-2003 as this is the
latest revision as of this writing. Readers are urged
to visit the AES web site in order to determine avail-
ability of later revisions.
25.6.1 Encoding Format
The encoding format is based on a block of 192
frames. Each frame consists of one sub-frame for
vs
Vme jωt
=
v
l t,
–
(
)
AeΓle jωt
=
Vm
2
-------e jωt
·
=
A
Vm
2
-------e Γl
–
=
v 0 t,
(
)
Vm
2
-------e Γl
– e jωt
=
Γ
α
jβ
+
=
v 0 t,
(
)
Vm
2
-------e αl
–
e j ωt
βl
–
(
)
=
v
l t,
–
(
)
Vme jωt
Zo
Zk
Zo
+
-----------------
=
A eΓl
e Γl
–
+
(
)e jωt
=
Zo
Zopen
=
Zk
eΓl
e Γl
–
+
eΓl
e Γl
–
–
-----------------------
=
A
Vm
2
-------e Γl
–
=
v x t,
(
)
Vm
2
-------e Γl
–
e Γx
–
eΓx
+
(
)e jωt
=
v 0 t,
(
)
Vme αl
–
e j ωt
βl
–
(
)
=

598
Chapter 25
audio channel one and one for audio channel two.
The sub-frame encoding structure is based on
32 bits of which a maximum of 24 bits is devoted to
audio sample data. The sub-frame can appear in two
different forms, that for audio data of 20 bits or less
and that for audio data above 20 bits but not greater
than 24 bits. In either case, if the audio at hand has
less bits than allowed then the least significant bits
are padded with extra zeros to complete the record.
For example a 16 bit audio sample would require an
additional 4 zeros in the least significant bits posi-
tions. Fig. 25-21 illustrates this arrangement.
The preamble codes exist in three forms denoted
as X, Y, and Z. The X preamble denotes audio
channel one while Y denotes audio channel two.
The appearance of preamble Z denotes the start of a
new block consisting of 192 frames.
Channel status data is obtained by collecting the
sequence of values contained in position 30, bit 31,
of the respective sub-frames in each block of 192
frames. The appearance of preamble Z initiates this
process. Thus for each channel one has a sequence of
192 bits that are formed into twenty-four bytes of
8-bits each. A great deal of information with regard
to individual channel status can be conveyed by
these twenty-four bytes and AES3 spells out in detail
the significance of the various codes involved. Such
information as channel identification, audio sample
word length, audio sampling frequency, channel
origin data, channel destination data, local sample
address code, time of day sample address code,
cyclic redundancy check character, and other similar
information is all contained here. All data is trans-
mitted serially from low order bits to high order bits.
25.6.2 General Transmission Characteristics
The bandwidth required for transmission is 128
times the frame rate and the frame rate is equal to the
audio sample rate. At a maximum sample rate of
192 × 103 samples s–1 the required electrical band-
width would then be 24.576 MHz. At a relaxed
popular sampling rate of 48 × 103 samples s–1 the
bandwidth requirement drops to 6.144 MHz. This has
practical importance as quality video distribution
amplifiers can handle this reduced bandwidth. AES3
does not require the use of transformers in electrical
transmission but it does not preclude their use.
On the other hand the European Broadcast Union
does require the use of transformers. AES3 allows
for this by requiring that the data encoding technique
employed has no direct current requirement when
translated into an electrical signal. Furthermore it
must be possible to recover the source clock at the
receiver for synchronization purposes, and finally,
the recovered data stream must be insensitive to the
polarity of connections. This is facilitated by having
all data beyond the preamble be encoded using the
biphase mark technique. In this technique, each logic
bit is represented by a symbol consisting of two
consecutive binary states. The first state of the
symbol must differ from the second state of the
previous symbol and the second state of the symbol
is the same as the first if the bit to be transmitted is
logic 0. The second state of the symbol is different
from the first if the bit is logic 1. This can be accom-
plished by employing a clock rate that is twice the
bit rate. For example, suppose the logic code to be
transmitted is the bit sequence 100110. The biphase
mark encoding and the electrical signal representa-
tion of the encoding is illustrated in Fig. 25-22.
Preambles must have unique characteristics as
they signal the start of a new sub-frame in the case
of X or Y, or a new block of 192 frames in the case
of Z. As such, the encoding for preambles must be
structured so as to be readily distinguishable from
the biphase mark technique employed for channel
encoding. The preamble codes must also allow for
clock recovery and electrically must be free of direct
current. The first state of a preamble is always
preceded by the second state of the parity symbol of
the preceding sub-frame and the last state of a
preamble is always succeeded by the first state of
Figure 25-21. Sub-frame formats.
0
3 4
27 28 29 30 31
V = validity
U = user data bit
C = channel status bit
P = parity bit
Preamble
MSB  V  U   C   P
LSB  24 bit audio data word
Bit
function
0
3 4
27 28 29 30 31
Preamble
MSB  V  U   C   P
         20 bit audio
           data word
Bit
function
Aux
7 8
LSB
Figure 25-22. Channel coding scheme.
Clock = 2 × bit rate
Source logic level
Biphase mark level
Unshaped
electrical
Vpp

Putting It All Together
599
the LSB of the sub-frame with which it is associ-
ated. An example of preamble encoding as well as
its associated unshaped electrical signal appears in
Fig. 25-23.
In viewing Fig. 25-23 it should be remembered
that the preamble occupies the first four of a
sub-frame’s allotted thirty-two bits and as such
occupies eight clock intervals. The dotted line
preceding the preamble represents the logic level of
the second state of the preceding parity bit while the
trailing dotted lines represent the transition to the
first state of the successive LSB associated with the
remainder of the sub-frame. The difference between
the encoding of the preamble and the biphase mark
technique is indicated by the two arrows on the
middle drawing. The biphase mark encoding tech-
nique would require that transitions occur at the
indicated positions. If one were to assign logic
values to the individual clock intervals associated
with the symbol in the middle drawing, the sequence
would be 11100010. This coding would correspond
to preamble X when the preceding parity-state
happened to be a 0. If the preceding state had been
1, the preamble symbol would be different and
correspond to the sequence 00011101.
25.6.3 Electrical Characteristics
The electrical characteristics as set forth in AES3
have been tailored to allow transmission of two
channel digital audio over a balanced twisted pair
shielded cable for a distance of 100 m without equal-
ization for sampling rates up to 50 × 103 samples
s−1. Transmission over the same distance at higher
sampling rates can be accomplished with appro-
priate equalization. The cable employed has a
nominal characteristic impedance of 110 Ω for
frequencies between 100 kHz and 128 times the
maximum frame rate. The cable used in the previous
cable sample calculation is a commercially manu-
factured cable specifically tailored for use under
AES3. The cable driver is required to have a
balanced source impedance of 110 Ω ±20% in the
same frequency range. The cable receiver must also
provide a balanced termination of 110 Ω ±20% in
the same frequency range. The recommended
connectors are XLR-3. The transmitted electrical
pulses are bipolar but their rise and fall times
between the 10% and 90% full amplitude points are
to be limited to the range 5 ns to 30 ns. The peak to
peak pulse voltage must fall in the range 2 V to 7 V.
The measurement of these values is to occur across
a 110 Ω resistor connected to the output terminals of
the driver with no intervening cable. Rise and fall
times and peak to peak voltage are illustrated in
Fig. 25-24.
The process of generating, transmitting, and
receiving serial digital audio is a synchronous
process. Synchronization can be accomplished by
having all elements of the system hardwired to a
common master clock through separate clock refer-
ence circuitry. Alternatively, the clock may be
located in the originating source with the signals so
designed as to allow clock recovery at the receiver.
This latter process is that covered by the AES3 stan-
dard. Accurate clock recovery is crucial to an error
free processing of the received signals. Clock
recovery hinges on the stability of the zero crossing
positions of the received electrical waveform. Varia-
tion in the zero crossing timing is called jitter. The
total jitter has two components, that associated with
the internal clock and that associated with the
intrinsic processing in the device. The standard sets
forth limits for both intrinsic and clock jitter and
details the methods to be employed in jitter
measurements performed at the transmitter.
Minimum requirements with regard to signal ampli-
tude and timing necessary for successful recovery at
the receiver are also set forth. The reader is referred
to the latest version of AES3 for details as exact
values are subject to revision as technology evolves.
Figure 25-23. Preamble coding scheme.
Clock
Preamble encode
Unshaped electrical
Vpp
1
0
Preamble interval
Figure 25-24. Rise time, fall time, and voltage peak to
peak.
90%
10%
Vpp
tf
tr
Fall time
Rise time

600
Chapter 25
25.6.4 AES Information Documents and Unbal-
anced Transmission of AES3
AES information documents are publications of the
Audio Engineering Society in support of the AES
standard documents. For example AES-2id is an
information document for audio engineering that
provides guidelines for the use of the AES3 inter-
face. AES-3id-2001 is an AES information docu-
ment for digital audio engineering covering the
transmission of AES3 formatted data by means of
unbalanced coaxial cables. Detailed information is
provided with regard to cables, equalizers, adapters,
and receiver circuits that allow the transmission of
AES3 formatted data over distances up to 1000 m or
in video installations that employ analog video
distribution equipment. In the instance of a video
installation employing analog video distribution
equipment the frame rate is limited to 48,000 frames
s–1 by the limited bandwidth of the analog video
equipment. The coaxial cables employed have char-
acteristic impedance of 75 Ω ±3 Ω above 100 kHz.
The transmitter output signal requirements for trans-
mission over unbalanced 75 Ω coaxial cable are
summarized in Table 25-3.
An AES3 transmitter with a balanced output can
be converted to unbalanced operation through the
use of an output transformer with one leg of the
transformer secondary connected to the shield of the
coaxial cable. In order for the transformer to provide
the appropriate 75 Ω to 110 Ω impedance match it
must have a primary to secondary turns ratio of
1.211 to 1. The AES3 voltage range at the primary of
the transformer will be reduced by a factor of 1.211
as viewed at the transformer’s secondary. This would
exceed the maximum listed in Table 25-3, so further
attenuation will be required. An attenuator that main-
tains a constant 75 Ω in both directions such as a T
pad can furnish the required attenuation. An example
of this conversion is shown in Fig. 25-25.
Suppose a balanced source conforming to AES3
has a peak to peak output of 5 V. Such a source can
be comfortably converted for employment as an
unbalanced 75 Ω source conforming to AES3-id by
the circuit of Fig. 25-25. The voltage across the
secondary of the depicted transformer when the
circuit is terminated by 75 Ω will be the primary
voltage divided by the turns ratio or
5 V⁄1.211 = 4.13V. The T pad of the circuit when
loaded by 75 Ω across the output terminals attenu-
ates the 4.13 V by a factor of 4 thus producing an
output voltage of 4.13V ⁄ 4 = 1.03V. The operation
of the original source will be completely normal as
it will see a load of 110 Ω .
The connectors employed in electrical unbal-
anced coaxial cable operation are BNC connectors
optimized for 75 Ω. The purpose of conversion to
coaxial cable transmission other than to be compat-
ible with analog video standards is to be able to
transmit over large distances up to a kilometer. As
such, cable loss becomes a significant factor. Cable
losses expressed in units of dB/km are described by
a relatively simple equation expressed as
(25-39)
where,
 A is the loss in dB/km,
 f is the frequency in MHz,
a, b, g are constants.
The loss characteristics for cables that are suit-
able for this application as extracted from
AES3-id-2001 are listed in Table 25-4.
25.6.5 Sony/Phillips Digital Interface Format
The Sony/Phillips digital interface format or S/PDIF
conforms to AES3 with regard to data formatting
and is employed in direct digital transfer from
Table 25-3. Unbalanced Output Signal Characteristics
Parameter
Minimum Typical Maximum
Unit
Output peak to peak
0.8
1.0
1.2
V
dc offset
—
—
< 50
mV
Rise time
30
37
44
ns
Fall time
30
37
44
ns
Figure 25-25. Balanced to unbalanced 110 Ω to 75 Ω
with attenuation.
Table 25-4. Coaxial Cable Loss Characteristics
Cable
A
1 
MHz
A
30 
MHz
A
200 
MHz
a
b
g
5C2V
8
47
126
8.5
0.031
–0.541
RG6A/U
7.9
48
135
8.4
0.082
–0.605
RG59B/
U
14
62
175
9.6
0.177
4.24
AES3
balanced
input
1.211:1
45 Ω
45 Ω
40 Ω
75 Ω
unbalanced
output
A
a  f 
(
)1 2
⁄
bf
g
+
+
=

Putting It All Together
601
compact disc players and RDAT digital tape players.
The electrical digital outputs of such devices are
usually unbalanced and not intended for transmis-
sion over large distances. Small coaxial cables fitted
with RCA pin plugs are employed in the link circuit.
These devices also often feature optical interfaces
with the same data formatting.
25.6.6 Microphones with Digital Outputs
Microphones having digital outputs are sometimes
misleadingly referred to as being digital micro-
phones. At the present writing at least such micro-
phones have conventional analog microphone
elements and analog preamplifiers combined with
an ADC, an internal clock, and the associated
circuitry necessary to present an electric serial
digital output that conforms with AES3. Optical
outputs as well will probably soon be in common
use. This discussion will be restricted to micro-
phones having electric serial digital outputs as a
standard presently exists for microphones of this
type. The current latest version of this standard as of
the present writing is AES42-2001. One of the
prime requirements for such microphones is the
availability of a robust phantom supply capable of
supplying currents much greater than those encoun-
tered when using analog output microphones.
AES42 requires that the microphone receiver supply
digital phantom power or DPP with a nominal dc
voltage of +(10 + 0.5 − 0.1) V. Additional modula-
tion of this voltage for other purposes to be
discussed later involving +2 V ±0.2 V is allowed.
The nominal available current required is 250 mA. A
peak current of 300 mA is allowed when modulation
is present. A circuit that allows the receiver to
furnish phantom power to the microphone appears
in Fig. 25-26A.
The cable involved in the circuit of Fig. 25-26A is
twisted pair with shield as required by AES3 with
the shield also acting as the phantom power return
path. The transformer at the receiver location is
center tapped to allow connection to the DP supply
located in the receiver. The receiver might well be
associated with an AES3 conforming input on a
digital mixer. The transformer at the microphone
location is center tapped on its secondary to provide
the phantom power to the receiver. The phantom
power appears as a common mode signal on the
normal signal conductors and does not interfere with
transmission or reception of the microphone signal
data as long as the superimposed modulation on the
phantom supply has a sufficiently small bit rate. This
modulation is of the pulse width variety with a bit
rate that is limited to the values listed in Table 25-5.
The modulation on the phantom power supply
serves a variety of purposes depending on the mode
of operation of the microphone. There are two
possible modes of operation of the microphone as
set forth in the standard. These modes are simply
denoted as Mode-1 and Mode-2. In Mode-1 opera-
tion the clock internal to the microphone sets the
timing and the receiver must recover the clock from
the AES3 formatted data. In this mode the micro-
phone may transmit information with regard to
microphone ID and status of the operational parame-
ters of the microphone through the employment of
the user bits in the channel data stream.
The microphone control data is transmitted to the
microphone from the receiver by means of the
modulation that is imposed on the DPP. The instruc-
tions contained in this data can enable control of
such factors as directivity pattern, low cut filter,
microphone gain, signal limiter, and signal mute
among others. In Mode-2 operation, the clock in the
microphone is synchronized to the clock contained
in the receiver. This synchronization is made
possible through the issuance of frequent error
correction commands contained in the modulation
imposed on the DPP. In Mode-2 operation all of the
features of Mode-1 with regard to microphone status
Figure 25-26. Phantom power circuit and modulated
phantom power voltage.
Table 25-5. Modulation Bit Rate for Standard Sampling 
Rates
Sampling Rate—kHz
Bit Rate—bits s-1
44.1
689.06
48
750
88.2
689.06
96
750
176.4
689.06
192
750
Receiver
Microphone
Shield
Phantom supply
2
3
1
12 V
10 V
Time
A.
B.

602
Chapter 25
and ID as well as control of microphone operational
parameters are maintained. The use of Mode-2 oper-
ation is very important when employing several
microphones in a given acoustical space along with
a digital mixer. The digital mixer can furnish a
master clock signal to all microphone inputs. In the
absence of a common clock signal, the phases of the
recovered audio signals from several microphones
would be random and stereo imaging would be
impossible. Mono operation could be seriously
impacted as well when two performers using sepa-
rate microphones are in close proximity. Mode-2
operation is absolutely necessary in order to main-
tain phase coherency between the recovered audio
from several microphones.
25.6.7 Connectors for Digitally Interfaced 
Microphones
There are two schools of thought with regards to the
connectors to be employed with digitally interfaced
microphones. One school of thought would require
complete compatibility with the XLR-3 connectors
that are employed for analog interfacing. The other
school would require complete incompatibility
between the two applications. This latter position is
based upon the differences between the phantom
power supply standards for digital and analog.
These differences could well allow the possi-
bility of damage to an analog interface if it is
mistakenly connected to a digital interface receiver.
At the present time there is no standard but
AES42-2001 does make a recommendation that is a
compromise position that can potentially satisfy
both camps. The recommendation proposes an XLD
connector that is based on an XLR-3 connector. The
following is a quotation from informative Annex E
of AES42-2001.
The XLD connector is based on the 3-contact
XLR connector described in AES14 with the addi-
tion of grooves and user-insertable coding keys.
The chassis-mounting female connector includes
a groove added to the inner contact insulator
between contacts 2 and 3. In addition, a coding key
may be added through the outer housing such that
the end of the key protrudes into the space between
the outer metal housing and the inner contact insu-
lator. The key shall be positioned between contacts 1
and 2, close to contact 2, Fig. 25-27.
The male cable connector includes a groove that
aligns with the optional coding key in the female
connector. In addition, a coding key may be added
through the outer shell of the male connector that
aligns with the groove in the female connector.
To be fully coded, a connector shall have both a
groove and a coding key. A half-coded connector
has a groove only.
When XLD connectors are to mate only with
other XLD connectors but never XLR connectors,
then all XLD connectors shall be fully coded.
When complete interoperability of XLD connec-
tors with XLR connectors is required, the coding
keys shall not be inserted in either the male or the
female XLD connectors.
25.7 Computer Control and Communication 
of Digital Audio
Computers now permeate practically every field of
human activity and audio systems are no exception.
Penetration to the depth of individual sound system
components is now a reality and, in the case of
virtual sound processors, many former hardware
elements are replaced by computer controlled DSP.
25.7.1 A Little History
In the late 1970s during the course of planning the
sound systems for the new, sprawling Atlanta Inter-
national Airport, F. B. Mewborn II, president of
Baker Audio Associates, took a daring step. He real-
ized that great economies could be achieved in
system cost if all announcements could be made to
flow through a switching central as is done in
central telephone systems. In order for such a
system to be successful it would be required that the
switching be automatic and transparent to the user. It
was realized that a computer could be made to
perform the switching function provided that the
originating address, the destination address, as well
as the message were all in a form that the computer
could understand. This would require analog to
digital conversion of the audio source material prior
to switching and digital to analog conversion after
the switching had been accomplished with switching
directional information being given by having the
origin and destination addresses in digital form.
Figure 25-27. Fully coded XLD female chassis
connector and male cable connector.

Putting It All Together
603
Prior to A-D conversion and after D-A conversion
the audio source material could be handled in the
conventional fashion employing microphones,
amplifiers, equalizers, and loudspeakers then avail-
able. The author was privileged to serve as technical
consultant for the development of this system.
While Baker Audio Associates was engineering
this system it became apparent that the computer
could also be made to perform a system diagnostic
function through the insertion and observation of
special audio test signals. The system went on line
in 1980 with the diagnostic package being added
shortly thereafter. At about this same time Innova-
tive Electronic Designs began producing a similar
system for application in airport sound systems and
subsequently enlarged the scope of employment to
any large-scale sound system. Up to this point all of
the audio components other than the computer-
operated switch were conventional.
In the ensuing few years Crown International
Electronics, building on the digital electronics and
programming experience it had acquired in the
development of the TEF analyzer, began designing a
new line of power amplifiers which would be
amenable to both digital control and digital moni-
toring with the incorporation of a plug-in digital
module. Parallel to the development of these ampli-
fiers Crown also developed the computer interface
and communication system necessary for interaction
with these amplifiers. This work culminated in the
Crown IQ System.
The Crown IQ System was structured on three
levels. At the upper most level was the host
computer and the IQ software. The host computer
could be any IBM, IBM clone, or Macintosh
computer that had a serial RS232, RS422, or RS4230
port. The computer acted as a monitoring and control
station for the system. At the intermediate level was
the Crown IQ interface that served as a communica-
tion device between the individual power amplifiers
and the host computer. At the lowest level were the
individual power amplifier plug-in microprocessor
cards that were connected in a daisy chain by means
of a single twisted pair to form a serial loop to the IQ
interface. Communication between the interface and
the individual amplifiers occurred at a baud rate of
38,400 s–1 so that the system operation appeared to
occur almost in real time.
All of the normal manually controlled functions
of each amplifier could be computer controlled by
this system up to a total of 2000 two channel ampli-
fiers. The outstanding feature of this approach,
however, was that the actual operational status of
each amplifier including on-off, input level, output
level, distortion, and safe operating area was
constantly monitored almost in real time.
The advent of the compact disc or CD player and
RDAT tape recorders and similar devices led the
Audio Engineering Society to establish standards for
the transmission of two channel serial digital audio
data. The first such standard appeared as AES3
published in 1985.
Finally, the modern era of computer control of
sound systems began with the giant step taken by
Hartley Peavey and Peavey Electronics Corporation
in the introduction of the MediaMatrix® System
that featured real time network communication and
control of digital audio signals by Ethernet
supported by CobraNet® hardware interface.
25.7.2 Networking of Digital Audio Data
The transmission and reception of serial audio data
discussed thus far has been made by means of a
synchronous process. In a synchronous process the
frames of data are of constant size and data is trans-
mitted and received at the same rate as governed by
a single clock. The transit time over a particular
connecting link is small and constant. This is in
direct contrast to an asynchronous process. In an
asynchronous process the size of a data block is not
constant and a given data block is not sent at any
particular time. The time of travel of a particular
data block over a connecting link is not fixed and a
single clock governing the overall process does not
exist. Serial communication between a computer
and a printer is an example of an asynchronous
process.
Fortunately there exists a third type of process
designated as being an isochronous process that will
allow the transmission and reception of synchronous
serial audio data over an interconnecting link where
the link itself is operated asynchronously. In an
isochronous process data is not transmitted at a
fixed rate but there exists a fixed maximum transit
time. Synchronous serial digital audio data can be
successfully communicated via an isochronous
connecting link through the inclusion of large data
buffers at both the sending and receiving ends. The
buffer at the sending end allows the retention of the
proper sequence of serial audio data and the buffer
at the receive end allows the re-synchronization of
serial data at the appropriate rate.
The most commonly employed digital
networking system for all purposes had its origin as
far back as 1972 and is called the Ethernet. Ethernet
has had continuous use and has undergone contin-
uous improvements since its inception. This is an
asynchronous system and as such can only be
employed for the communication of synchronous
serial digital audio data when further supported by

604
Chapter 25
isochronous adjuncts such as CobraNet®. For
detailed information with regard to the history, oper-
ational characteristics, and terminology of Ethernet
the reader is referred to the excellent article by Ray
Rayburn referenced in the bibliography at the
conclusion of this chapter.
25.7.3 CobraNet®
CobraNet® was invented by Kevin Gross and Rich
Zweibel of Peak Audio. It has been licensed to so
many major professional audio equipment manufac-
turers that it has become almost a de facto standard.
CobraNet® is a combination of hardware (the actual
physical interface), network protocol, and firm-
ware. CobraNet® operates on switched Ethernet and
in addition to the normal Ethernet services offers
additional communication services. The additional
services are isochronous audio data transport,
sample clock distribution, and control and moni-
toring data transport. The interface performs all of
the required isochronous to synchronous and
synchronous to isochronous conversions along with
all data formatting required for transporting real
time digital audio data over an Ethernet network. In
this regard, the Ethernet can be thought of as being a
large conduit through which CobraNet® inserts and
manages a group of sub-conduits as depicted in
Fig. 25-28.
A typical CobraNet® interface offers the
following features:
1.
100 Mbps full-duplex Ethernet interface.
2.
Provides a backup Ethernet interface that can be
connected to a redundant network for fault
tolerance.
3.
Quad synchronous output ports capable of
supplying up to 32 total audio channels at 48 or
96 kHz sample rate with 24 bit resolution.
4.
Quad serial input ports capable of receiving up
to 32 audio channels at a 48 or 96 kHz sample
rate with 24 bit resolution.
5.
Clock source with jitter less than 1 ns.
6.
High speed parallel host port interfacing to an
optional external control processor.
7.
Ethernet-based control, monitoring, and manage-
ment.
8.
Selectable low latency of 1.33, 2.66, or 5.33 ms
across the network.
9.
Asynchronous serial I/O port for bridge serial
control data over Ethernet.
10. Status indicators for link, activity, fault, and
CobraNet® conductor status for each Ethernet
jack.
When two or more CobraΝet® interfaces must
communicate over the Ethernet only one interface
supplies the common clock to be employed by all
others. Electrical connection to Ethernet is via RJ-45
jack with integrated transformer isolation. Such a
connection employs 2 of the 4 pairs in a Cat-5 cable.
The serial audio I/O ports also feature RJ-45 jacks to
accommodate RJ-45 plugs and Cat-5 cable. Cat-5
cable consists of 4 unshielded twisted pairs and is
produced in two forms employing either stranded or
solid wire. The nominal characteristic impedance of
this cable is 100 Ω ±15%. The RJ-45 jack and plug
are connectors that originated in the telephone
industry as the terminology might suggest. They are
compact modular connectors featuring eight
contacts that in quality versions are gold-plated.
Bibliography
Audio Engineering Society Publications, Audio Engineering Society, Inc., 60 East 42nd Street, New York,
New York 10165
AES3-2003
AES-3id-2001
AES42-2001
David J. Griffiths. Introduction to Electrodynamics, 2nd edition. Englewood Cliffs: Prentice Hall, 1989.
Ray Rayburn. “Digital Audio Interfacing and Networking,” Handbook for Sound Engineers, 3rd edition.
Boston: Focal Press, 2002.
Figure 25-28. Ethernet with CobraNet®.
A
A
A
A
A
A
A
A
CD
CK
Ur
   A = Audio
CD = Control data
 Ck = clock
 Ur = Unregulated data
   E = Ethernet
E

605
Appendix: Symbols and Abbreviations
a
absorption coefficient:
aS = Sabine
aN = Norris-Eyring
aR = room constant
average absorption coefficient
A
ampere
ac 
alternating current
AES
Audio Engineering Society
AIP
available input power
%ALCONS
percentage of articulation loss for 
consonants
AM
automatic mixer
amplitude modulation
ANCA
ambient noise controlled amplifier
ANL
ambient noise level
ANSI
American National Standards Institute
APF
all-pass filter
ASA
Acoustical Society of America
BBF
band-boost filter
BPF
bandpass filter
BPST
bandpass sweep time
BRF
band-rejection filter
BW
bandwidth
c
velocity in many acoustic equations
CL
coverage angle
CBF
constant bandwidth filter
CPB
constant percentage bandwidth
CPBF
constant percentage bandwidth filter
cps
cycles per second
dB
decibel(s)—a power ratio expressed 
on a logarithmic scale
dBA
A weighted sound-pressure level in 
decibels
dBm
decibels with a reference of 1 milli-
watt (mW)
dc
direct current
dBV
decibels with a reference of 1 V
Dc
critical distance
DCD
directional control device
DFT
Discrete Fourier transform
DI
directivity Index
Dm
measured distance
Do
distance from talker to farthest listener
DR
reflected sound distance
Dr
reference distance
D/R
direct-to-reverberant ratio
Ds
distance from talker to microphone
DVM
digital voltmeter
DX
any given distance
D1
distance between microphone and 
loudspeaker
D2
distance from loudspeaker to farthest 
listener
D2SS
D2 distance for a single source
deg
degrees
DUT
device under test
ΔdB
level change in dB
ΔDX
arbitrary level change associated with 
the distance DX in the Hopkins- 
Stryker equation
E
voltage
EIN
input voltage
EAD
equivalent acoustic distance
ECAN
electronically controlled ambient 
noise system
EFC
energy frequency curve
%Eff
percentage of loudspeaker efficiency
EIA
Electronics Industries Association
EIN
equivalent input noise
emf
electromotive force
Eo
open-circuit voltage
EOUT
output voltage
EPR
electrical power required
ETC
Envelope Time Curve
ΔEAD
arbitrary level change associated with 
the distance EAD in the Hopkins- 
Stryker equation
F
distance from front of room to first lis-
tener
f
frequency
fC
center frequency
FFT
Fast Fourier transform
FM
frequency meter
frequency modulation
FO
frequency offset
FSM
feedback stability margin
FTC
frequency time curve
GLIT
ground loop impedance tester
GLR
graphic level recorder
GMT
Greenwich Mean Time
GM
EIA microphone sensitivity rating
h
height of the loudspeaker
H
barometric pressure
HD
Haas distance
HPF
high-pass filter
h
hour
HR
ceiling height at rear of room
HVAC
heat ventilating air conditioning
Hz
Hertz; cycles per second
I
current, intensity
Ia
acoustic intensity
IEEE
Institute of Electrical & Electronics 
Engineering
IR
Impulse Response
ITD
initial time delay
ISD
initial signal delay
j,i,
an instruction to go to the 90o 
coordinate
a
1
–

606
Appendix 
k
kilo (1000)
K
Kelvin (temperature)
kg
kilogram
LT
total sound level
L
level, length
LAMB
ambient noise level
lb
pound
LD
direct sound level
LEDE
Live End-Dead End
LF
low frequency
LFL
lower frequency limit
Lin
linear
log
logarithmic, base 10
ln
logarithmic, base e
LP(EIA)
EIA loudspeaker sensitivity
LPF
low pass filter
LX
loudspeaker sensi—not EIA
(X may be 4 ft, 1 W
10 ft, 1 W
1 m, 1 W)
LR
reverberant sound level
LRE
level of early reflection
LSENSI
loudspeaker sensitivity
LSI
large-scale integration
Ma
architectural DC modifier
MAX
maximum
MDM
mix down monitors
Me
electroacoustic DC modifier
MFP
mean free path
M
mega (1,000,000)
mic
microphone
min
minimum
MRT
modified rhyme test
MSC
miles of standard cable
ms
milliseconds
μs
microseconds
MTF
modulation transfer function
N
Newton
N
critical distance divisor
(the ratio of acoustic power in the 
reverberant sound field to the acous-
tic power providing the direct sound 
field at the listener) 
NAG
needed acoustic gain
ns
nanosecond
NBS
National Bureau of Standards
NBSA
narrow band spectrum analyzer
NC
noise criteria
NFI
null frequency interval
NFM
near field monitors
Np
Neper
NG
noise generator
NLA
noise level analysis
N/m2
Newtons per square meter
NOALA
noise-operated automatic level 
adjuster
NOM
number of open microphones
NOMA
number of open microphone attenua-
tors (an automatic mixer)
NPP
Nyquist phase plot
NQmin
N times Qmin
NSCA
National Systems Contractor 
Association
OBA
octave-band analyzer
p
sound pressure
Pa
Pascal
PA
power amplifier
PAG
potential acoustic gain
PET
polar envelope time
Phon
loudness measure
PD
phase delay
PF
power factor
PFC
phase frequency curve
Pink noise
equal noise energy per octave
PRD
primitive root diffusor
Program
talker’s level at the microphone
level
without addition of meter lag
PRP
Pressure Recording Process
PZM
Pressure Zone Microphone
Q
directivity factor or electrical quality 
factor (used with resonance equa-
tion); see also Rθ
QSS
Q single source
QREL
Q Relative
Qavail
available Q
Qmin
minimum Q for desired %ALCONS
QRD
quadratic residue diffusor
R
resistance or room constant (usually 
replaced today by 
)
Rb
buildout resistor
RIN
input resistance
RM
match resistance
RS
source resistance
RL
load resistance
ROUT
output resistance
RASTI
Rapid Speech Transmission Index
rad
radians
RC
resistor-capacitor
RFZ
reflection-free zone
RMR
center value of impedance range
rms
root mean square
RNG
random-noise generator
RPN
Reverse Polish notation (Lukasiewicz)
RPS
reflections per second
RTA
real-time analyzer
RT60
reverberation time
Rθ
directivity ratio (also designated Q)
S
total boundary surface area
Sabins; usually supplied by material 
manufacturers in 
SA
signal alignment
Sabin
unit of absorption
Sa
Sa
Sas

Symbols and Abbreviations
607
SAG
sufficient acoustic gain
Saobj
Sabins per object
SBA
signal-biased amplification
SD
signal delay
s
seconds
sensi
sensitivity
SF
shelving filter
Sig Sync
Signal Synchronication 
SLM
sound level meter
SNR, S/N
signal-to-noise ratio
Sp
microphone power sensitivity (with a 
reference of 10 dyn/cm2/1 mW)
SP
sound pressure
SR
sweep rate
sr 
steradians, solid angle
STI
Speech Transmission Index
STP
standard temperature and pressure
SV
microphone sensitivity with a 
reference of 1 dyn/cm2/1 V
T
time
TDS
time delay spectrometry
TEF
time energy frequency
TF
tracking filter
THD
total harmonic distortion
TIM
transient intermodulation distortion
TL
transmission loss
TN
thermal noise
TNL
thermal noise limit
TO
tracking oscillator
TP
time period
TU
transmission unit
U
units
UX
X number of units
UFL
upper frequency limit
μs
microseconds
V, v
volts
V
volume of a room
v
velocity
VA
volt amperes
VI
volume indicator
VOM
volt ohm meter
VU
meter calibrating unit
W
watt
Wa
acoustic watts
Wact
actual watts
Wapp
apparent watts
We
electrical watts
White noise equal noise energy per hertz
WT
total power
X
unknown, Total reactance
XC
capacitive reactance
XL
inductive reactance
Z
impedance
|Z|
impedance (magnitude)
θ
phase angle
γ
Gamma 
ρ
density of air
λ
wavelength, lambda
θ
horizonal coverage angle, theta 
φ
vertial coverage angle, phi
Δ
Delta
Ω
ohms
π
pi
<
less than
>
greater than
≅
approximately equal to
≡
identical
≤
equal to or less than
≥
equal to or greater than
′
feet
″
inches
DIGITAL NOMENCLATURE
AAC
advanced audio coding
ADC
analog to digital converter
ASCII
American Standard Code for Informa-
tion Interchanges
BAUD
a rate defined as Xbaud ´ Y bits ⁄ baud 
= Z bits/s. (Baud is changes of 
state/s) Named after French engineer 
Jean Maurice Emile Baudot
Binary
base 2, log2
Bit rate
bits ´ sampling frequency ´ channels
Bit
binary digit
BWF
broadcast wave format
Byte
8 bits
CBR
constant bit rate
CD
compact disc
Codec
compressor/decompressor
CPU
central processing unit
DAC
digital to analog converter
Denary
base 10, log10
Double word 32 bits
DSP
digital signal processor
DVD
digital versatile disc
ERB
equivalent rectangular bandwidth
FLOP
floating point operations per second
Fs
sampling frequency
GPU
graphics processing unit
HDTV
high-definition television
Hexadecimal base 16, log16
HTML
 hypertext markup language
IO
input – output
ISO
International Organization for 
Standardization
LSB
least significant bit
MDCT
modified discrete cosine transform
MIPS
million instructions per second
MIPW
million instructions per watt
MPEG
motion picture experts group

608
Appendix 
MSB
most significant bit
Nibble
4 bits
Octal
base 8, log8
PCM
pulse code modulation
PDF
portable document format
Quad word
64 bits
RISC
reduced instruction set computer
SNR
signal-to-noise ratio,
10log10 (6 × (2(b - 2))
TNS
temporal noise shaping
V ⁄ 2bits
Quantization level
VBR
variable bit rate
WAV
wave format
Word
16 bits
ROOM MEASUREMENTS
cm
centimeter
D
dimension
Ft
feet or foot
In
inches
Kg
kilogram
Km
kilometer
L
length
L2
area
L3
volume
lb
pound
lbf
pound force
m
mile, meter, metric
mm
millimeter
yd
yard

Index
609
Symbols
% efficiency 262
%ALCONS 153, 254, 268, 269, 276, 
277, 394
choosing the correct equation 
277
effect of SNR 271
factors affecting 272
relationship to acoustic gain 278
role of 277
Numerics
100Base-T Ethernet (Fast Ether-
net) 544
10Base-T Ethernet network 543
20 log x chart 100
30/30 Guideline 437
3D surface model 459
A
Abbreviations 605
Abel, Niels Henrik 47
ABS 453
Absorption 177, 453
Absorption coefficient (ABS) 453
Absorptive materials 453
Ac voltage 114
Acoustic
astigmatism 153, 470
center 153, 470
environment 171
indoor environment 181
origin 153, 470
outdoor 179
power 93
Acoustic astigmatism 153
Acoustic center 153
Acoustic dipole 310, 349
Acoustic distortion 311
Acoustic environment 267
absorption 177
ambient noise field 179
atmospheric absorption 172
diffraction 171
diffuse (reverberant) fields 179
Doppler Effect 175
effect of space heater on flutter 
echo 177
excess attenuation 171
far free field 186
far reverberant field 186
flutter echo 177
free fields 178
indoors 181
interfacing
electrical output power 143
inverse square law 172
inverse-square-law level change 
171
Jesus addressed the multitudes 
180
mean free path (MFP) 184
near field 186
outdoor acoustics 179
pressure fields 179
reflection 171, 176
refraction 171, 176
reverberant sound field 184
semireverberant fields 179
sound absorption coefficients 
182
sound energy density 178
sound fields 178
sound velocity 173
temperature dependant velocity 
174
typical wavelengths 175
Acoustic feedback
analysis 556–558
decay 557
negative
growth and decay 558
Acoustic gain 258
Acoustic gain parameters 258
Acoustic intensity 295, 308, 365
Acoustic kinetic energy 294
Acoustic measurements
acoustic delay 197
analytic signal 195
comparison of an ear and a mi-
crophone 193
constant percentage bandwidth 
analysis 203
critical bandwidth 206
decade exponents 208
envelope time curve 195, 196
equalization 192
ETC plot 195
fractional bandwidth filter ana-
lyzer 206
frequency labels for audio com-
ponents 208
frequency resolution 198
Hells Bells 201
Heyser Integral Transform 193
Heyser Spiral 196
Hilbert Transform 196
HVAC 203
improper use of real time 
analysis 203
impulse response 195
impulse sources 192
initial parameters 191
label frequencies 208
magnitude response 196
measurement analyzers 193
minimum phase response 196
modulation domain analysis 193
music 192
NLA 203
noise criteria 204
noise criteria curves 203
noise level analysis measure-
ments 203
non-minimum phase 196
Nyquist
plot 200
trace of the complex signal 196
phase and polarity 192
phase response 196
pinnea responses 207
polar envelope time (PET) plots 
201
polarity 192
processing TEF signals 194
random noise 192
signal synchronization 192
site surveys 203
speech 192
steady-state sine wave 192
swept sine wave 192
TEF displays 196
TEF instrument 193
test sources 192
three parameter measurement 
198, 200
time offset tracking filter 196
time resolution 198
trained human listener 191
transducers 192
undesired spurious energy 192
Acoustic origin 153
Acoustic potential energy 294
Acoustic power 485
Acoustic pressure 283, 286, 287, 
290, 292, 294, 295, 297, 299, 304, 
305, 307, 308, 310, 347, 351, 365, 
371, 395, 408, 485, 498, 513
far field 354
near field 354
Acoustic pressure amplitude 293, 

610
Index
305, 310, 397, 405
Acoustic sound-pressure-level 
(Lp) 261
Acoustic Tests and Measurements 
15
Acoustical analysis 579
Acoustics
room 451
Active loudspeaker systems 428
Acustica 28
ADC 500, 538
Adiabatic constant 349
Adiabatic process 284, 286, 296
Admittance 124
AES3 541
cable 599
connector 599
encoding 597
transmission characteristics 598
AES3 vs. AoE 549
AES42 542
AES50 542
AES-EBU 541
AIP 316
Air
atmospheric absorption 172
density 173
effect of altitude on the velocity 
of sound 175
Air density 347
Air particle 287, 292, 299, 309
Air particle displacement 291
Aliasing 39, 494
Alkmaion of Kroton 19
All Technical Services (Altec) 13
Altec 12
Alternating currents 113
Amoroso, Richard 19
Ampere, Andre Marie 9
Amplification
voltage 88
Amplifier
30/30 guidline 437
apparent power 431
as a voltage source 429
burst testing results 435
continuous sine wave power rat-
ing 434
criteria for setting sensitivity 
437
digital signal pocessors 436
equivalent amplifier size (EAS) 
429, 430
gain trading 439
input sensitivity 436
input sensitivity control 436
load impedance 433
low crest factor signals
2 ohm loads 435
mixer 142
non-linear operation 428
power from a voltage source 431
power rating 428
real world power generation 434
setting sensitivity 436
setting the amplifier’s sensitivity 
437
voltage rating 429
Amplifier/loudspeaker interface 
425
Amplitude 79
Amplitude response 382
Analog audio 550
Analog interconnections 583
Analog to digital conversion 497
Analog vs. digital audio 550
Analog waveform 535
Analog-to-digital converter 
(ADC) 535, 536
Analog-to-digital converters 
(ADCs) 35
Analysis
constant percentage bandwidth 
203
feedback
analysis 556–558
pole and zero 508
Analyzer
detecting reflections without an-
alyzers 278
fractional bandwidth filter 206
real-time analyzer 559, 573
Angles 75
coverage 153, 160
epoch 75
impedance 116
improper coverage 275
phasors 79
pi 75
polar lunes 156
radians 67
solid 67
steradians 67, 156
Angular frequency 293, 300, 307, 
311, 483, 486, 490, 492, 510
AoE 544
Apparent power 431
Arnold, H. D. 12
Articulation 270
Articulation index 271
Articulation losses of consonants 
in speech 268
ASCII
code 46
printable characters 46
Astrolabes 165
Asynchronous process 603
Atmospheric absorption 172
Atmospheric pressure 283, 287, 
296
ATRAC (Adaptive TRansform 
Acoustic Coding) 38
Attack time 530
Attenuation
excess 171
Audinate’s DanteTM 547
Audio components
frequency labels 208
Audio Engineering Society 35
Audio Perspective 12
Audio power 430
Audio-over-Ethernet (AoE) 543, 
546
AutoCADTM 460
Average loudspeaker sensitivity 
438
Average power 118
Avogadro’s number 283, 284, 287
Axial mode 241
Axial modes 240
Axon chips 19, 22
B
Baars, Bernard J. 20, 21
Babbage, Charles 12
Bais, F. Alexander 41
Balanced circuits 583
Ballou, Glen vii, 9
Bands 28
Bandwidth
critical 206
number of octaves 67
Bans 45, 48
Barks 28
Bartlett, Bruce 333
Bass, H. E. 171
Bauch, H. 28
Bauer, Ben 161
Bayes, Reverand Thomas 47
Bayesian probability theory 47
Bayesian theory 47

Index
611
Beaty, H. Wayne 5
Beavers, Bob 161
Becker, Farrel 201, 274
Beethoven, Ludwig van 28
Bell Labs 12
Bell System Technical Journal 87
Bell Telephone Laboratories 87, 
268
Bell, John (of Cern fame) 19
Benade, L. 374
Benson, J. E. 576
Beranek, Leo J. 240
Berger, Russ 248
Berkeley, Bishop 47
Berkeley, George 19
Bertram, Dr. Sidney 201
Bessel array 398
Bessel polynomials 510
Bickenstein-Hawking 35
Bilello, Charles 243
Binary 45
Binary choices 44
Binary codes 498
Binary numbers 45
Binaural recording 27
Biological memory 37
Biquad 526
Bissell, Chris 42
Bit rate reduction 39
Bits 45, 48
Black noise 40
Blind/deaf question 26
Bode plot 512, 513
Bodie, Hendrik 12
Bolt, Beranek & Newman 215
Bolt, Richard 217
Boner, Dr. C. P. 559
Bose-Einstein 22
Boundaries 309
Boyle, Robert 9
Bozak, Rudy 15
Brooks, Rollins 278
Brüel and Kjaer 14, 341
Burger, J. F. 268
Burst testing 435
Burst testing amplifiers 433
Bush, Vannevar 11
Butterworth polynomials 510
Byron, Lord 12
C
C 155
C– 158, 159
Cable
AES3 599
analysis 591–597
attenuation 592
Cat-5 604
miles of standard cable 87
phase velocity 592
propagation properties 595
sample calculation 596
Callis, Maria 28
Campbell, George A. 11
Capacitive reactance 116
Capacitors 113, 125
Cat-5 cable 604
Category cable 541, 544
CATT-AcousticTM 443
CÐ 155
CEMI field theory 21
Characteristic impedance 592
Charles, Ray 26
Chart
20 log x 100
log 99
polar response 154
Chebyshev polynomials 510
Circle
sector 75
Circuits
balanced 583
dual 124
matched 140
open 140
telephone 87
unbalanced 587
Clarity-C 457
Clarity-C50 460
Clarke, Rick 469
Clausius, Rudolf 35
CLF Viewer 440
CobraNetTM 603
interface features 604
CobranetTM 547
Cochlear implant 26
Codec codes 538
Coding high quality digital audio 
41
Cognitive computing 37
Comb filter 330
Comb filters 226
Components
capacitors 113, 125
inductors 113, 125
resistors 113, 125
Compression 529
Computer aided system design
3D surface model 459
absorption 453
absorption coefficient (ABS) 453
absorptive materials 453
AutoCADTM 460
CATT-AcousticTM 443
Clarity-C 457
Clarity-C50 460
counting balloon 450
critical frequency char 454
Dynamic Link Library (DLL) 
447
Early-Decay Time (EDT) 457
early-reflected sound field 451, 
455
Echogram 460
far field 444
Finite Element Analysis (FEA) 
460
initial time gap (ITG) 455
inverse square law 444
late reflections or echoes 455
late-reflected sound field 451
line array of discrete sources 445
log-squared RIR 452
loudspeaker
sensitivity 446
loudspeaker arrays 447
loudspeaker point source 444
LP 446
modeling with absorption coeffi-
cients 453
near field 444
near field vs. far field 444
objective of room modeling 451
post-processing the RIR 452
predicting room reflections 450
radiation properties of a loud-
speaker 445
ray behavior 454
ray tracing 449, 460
realistic room models 457
reverberant energy 456
reverberant sound field 451
RIR 456
room impulse response (RIR) 
451
room model detail 449
room modeling tips 460
RoomCaptureTM 457
SketchupTM 460
sound behavior 454
specular reflections 460

612
Index
spherical loudspeaker data 443
T30 456
wave behavior 454
wire-frame model 458
Condensation 287, 289, 301
Conductance 124
Connectors
AES3 599
TRS 588
XLD 602
XLR 588
Conner, William K. 555
Conscious electromagnetic infor-
mation field (CEMI) 21
Continuous sine wave power rat-
ing 434
Control code mnemonics 46
Controlling Dc 229
Conversion of Bits, Nats, and 
Bans 48
Cooper, Col. Jeff 20
Coulomb, Charles 10
Coverage angle 153
Craig, D. F, 576
Crick, Francis (of DNA fame) 19
Critical band 28
Critical bandwidth 30
Critical bandwidths 30
Critical distance (Dc) 157, 164, 
228
Critical frequency (fc) 215
Critical frequency chart 454
Crossover
phase response 384
Crossover Network
synthesized 390
Crossover network 378
Curves
envelope time curve 568–569
magnitude and phase 569
house 561
house curves 574
D
d’Alembert, Jean le Rond 11
D’Antonio, Peter 244, 248
D/R 253
D0 254
D1 158, 258
D2 258
DAC 499, 538
Data rate 537, 539, 545
Data transport 537, 550
Davis, Art 15
Davis, Don 573, 576
Davis, Don and Carolyn 186, 279
dB 12
dBm 12, 91
dBV 88
Dc 258
Dc multipliers and dividers 229
Decade
number in a frequency span 104
Decibel 71, 95
20 log x chart 100
acoustic intensity level (LI) 93
acoustic power 93
adding decibel levels 97
amplification 88
apparent VU levels 104
as a power quantity 90
audio level 90
bel 87
calibrating a VI instrument 104
combining 97
combining levels of uncorrelated 
noise signals 98
combining voltage 99
dBm 91
dBV 88
deflection of the eardrum 105
directivity factor 94
distortion 106
electrical power 90
equivalent level (LEQ) 96
harmonic distortion 106
inverse square law 93
LI 92
log charts 99
logarithm of a number to any 
base 100
LP 92
LW 92
neper 87
number of decades in a frequen-
cy span 104
Ohm’s Law 94
older references 96
percentages 109
phon 105
playback systems 108
power 88
power ratio 88, 89
semitone intervals 101
sensation unit SU 87
subtracting decibels 98
tempered scale 106
the name for the transmission 
unit 87
typical A-weighted sound levels 
97
VI meter 101
voltage 88
voltage amplification 88
voltage amplitude 88
voltage ratio 88
VU impedance correction 102
VU meter 101
zero level 87
Decimal 45
Delay 467
Delta-sigma modulation 501
Designing for acoustic gain
% efficiency 262
%ALCONS 254
acoustic gain 258
acoustic sound-pressure-level 
(Lp) 261
D0 254
D1 258
D2 258
Dc 258
direct-to-reverberant ratio (D/R) 
253
distance from the microphone 
(Ds) 254
distance from the talker (D0) 254
EIA sensitivity 261
equivalent acoustic distance 
(EAD) 253
feedback stability margin (FSM) 
255
limiting parameters in sound re-
inforcement system design 260
listener’s maximum level 
(Lp(MAX)) 261
loudspeaker efficiency 262
loudspeaker sensitivity conver-
sions 262
measuring acoustic gain 259
needed acoustic gain (NAG) 254
nonlinear behavior 256
nonlinear response 256
number of open microphones 
(NOM) 255
potential acoustic gain (PAG) 
256, 259
ratio 253
regeneration 255
required electrical power (REP) 
261

Index
613
signal-to-noise ratio (SNR) 253
sound radiation patterns 259
Device interconnections 582
DI 222
Diagram
pole-zero 509
Diamond, John 40
Difference equations 524–525
Differentiation 82
Diffraction 171
Diffusion 244, 245
Digital audio 536, 550
Digital audio cable 541
Digital audio formats
100Base-T Ethernet (Fast Ether-
net) 544
10Base-T Ethernet network 543
ADC 538
AES3 541
AES3 vs. AoE 549
AES42 542
AES50 542
AES-EBU 541
analog audio 550
analog vs. digital audio 550
analog waveform 535
analog-to-digital converter 
(ADC) 535, 536
Audinate’s DanteTM 547
Audio-over-Ethernet (AoE) 543, 
546
catagory cable 541, 544
channel count 537
CobranetTM 547
codec codes 538
DAC 538
data rate 537, 539, 545
data transport 537, 550
decodes 538
digital audio 536, 550
digital audio cable 541
digital audio interface character-
istics 541
digital audio signal formats 539
digital signal processing (DSP) 
542
dynamic range (DR) 535
Ethernet 543
Ethernet AVB 547
Ethernet network 546
Ethernet protocols 546
eye pattern 536
Finite Impulse Response filter 
(FIR) 543
formatting 537
Host ID 546
Infinite Impulse Response (IIR) 
542
Internet Protocol (IP) 543, 547
jitter 540
jitter correction 540
latency 537, 540
local area computer network 
(LAN) 543
MAC address 546
Media Access Control (MAC) 
543
Metadata 537
multi-mode fiber 545
network bandwidth 543
Network ID 546
network node identifiers 546
open standard 549
Open Systems Interconnection 
(OSI) 547
OSI Reference Model 548
packet-switched network 543
Quality of Service (QoS) 549
quantization 535, 550
reconstruction 536
single-mode fiber 545
Sony/Philips Digital Interface 
(S/PDIF) 540
standard data formats 540
synchronization 537, 539
transport of digital audio data 
537
Virtual Local Area Network 
(VLAN) 548, 549
word clock 539
Digital audio interface character-
istics 541
Digital audio signal formats 539
Digital file size 38
Digital nomenclature 42, 607
Digital recording techniques 37
Digital signal processing (DSP) 
542
Digital signal processors (DSP) 
436
Digital systems 520–528
Digital theory
aliasing 39
analog-to-digital converters 
(ADCs) 35
Bans 45, 48
Bayesian theory 47
binary numbers 45
bit rate reduction 39
Bits 45, 48
black noise 40
cognitive computing 37
control code mnemonics 46
digital file size 38
digital nomenclature 42
digital recording techniques 37
digital versatile disc (DVD) 38
dither 39
dynamic range 36
holographic universe 35
latency 38
Markov process 40
Nat 37, 42
Nats 45, 48
over-sampling 39
PCM (pulse code modulation) 
35
pink noise 40
Planck constant 48
Planck frequency 48
Planck length 42, 48
Planck mass 47
Planck scales 47
Planck system 47
Planck time 48
Planck units 47
quantizing 35
sampling 35
Shannon entropy 41
Shannon Space 36
Shannon’s theory 35
Stochastic process 40
text into binary, octal, hexadeci-
mal 46
thermodynamic entropy 41
white noise 40
Digital versatile disc (DVD) 38
Digital voice recognition 22
Direct field (LP) 449
Direct radiators 347
Direct sound field 451, 454
Direct sound level (LD) 555
Direct sound pressure level (LD) 
222, 224
Directional control device (DCD) 
470
Directivity
far field 354
function 355
Directivity factor 94
Directivity factor (Q) 153, 221
Directivity index DI 157, 160

614
Index
Directivity plots 155
3-D plot 155
frequency charts 155
polar charts 155
Direct-to-reverberant ratio (D/R) 
253
Disney 13
Displacement 80
Distance from the microphone 
(Ds) 254
Distance from the talker (D0) 254
Distortion
harmonic 106
unnatural 572
Dither 39
Doak and Bolt delay 469
Dolby AC-3 38
Doolittle, Thomas B. 12
Doppler Effect 175
Ds 254
DSP 542
Dynamic Link Library (DLL) 447
Dynamic microphone equivalent 
circuit 323
Dynamic range 36
Dynamic range (DR) 535
Dynamics processing 528
E
Ear
comparison to microphone 193
deflection of the eardrum 105
Early-Decay Time (EDT) 457
Early-reflected sound field 451, 
455
Echogram 460
Edelman, Gerald M. 20
Edison, Thomas 11
EIA noise spectra 426
EIA sensitivity 261
EIA sensitivity ratings 261
Eickemeyer, Rudolph 11
Eigen 239
Eigen mode 239
EIN 321
Einstein, Albert 19
Electric power 117
Electrical power required 260
Electrical Research Products, Inc. 
(ERPI) 13
Electromagnetic spectrum chart 5
Electromagnetic waves 584–586
absorption 585
polarization 585
reflection 585
skin depth 585
Embleton, T. F. W. 245
EMI 25
EMI susceptibility 584
Enigma code 47
Envelope time curve 269, 274
Envelope Time Curve (ETC) 14, 
218
Environment
acoustic 267
Equal loudness contours 30
Equalization 514
global 517
local 517
system criteria 555
Equalizer
passive 564
Equation
dBm 91
delay 467
distance 467
Sabine 215
signal delay 466
time 467
velocity 467
Equation of state 283
Equivalent acoustic distance 
(EAD) 253
Equivalent amplifier size (EAS) 
430
Equivalent rectangular bandwidth 
29
Equivalent Rectangular Band-
widths (ERBs) 28
Ergodic processes 40
ETC 195, 269, 274, 568
Ethernet 543, 545, 604
Ethernet AVB 547
Ethernet network 546
Ethernet protocols 546
Euler, Leonhard 11
Euler’s identity 405
Euler’s theorem 77, 481
European International Advisory 
Committee 87
Evans, L. 171
Expansion 529
Eye pattern test 536
Eytomotic Research 27
F
Factors to watch for in rooms 231
Far field 444
Faraday, Michael 4, 9
Farmer, J. Doyne 41
Fay-Hall effect 468
Feedback
acoustic
analysis 556–558
growth 556
decay 557
defined 556
effects of surfaces 575
feedback is a single frequency 
570
feedback stability margin 558
negative acoustic 558
oscillatory 556
path 556
positive 556, 558
sources 569
steady-state 572
transient nature of acoustic feed-
back 556
Feedback stability margin (FSM) 
255
Feynman, Richard 41
FFT 573
Field
ambient noise 179
diffuse 179
far free 186
far reverberant 186
free 178
multiplicity of 570–571
near 186
pressure 179
reverberant 184
semireverberant 179
sound 178, 570
Field measurements 458
Fields 4
Filter
active band-pass 564
band-boost 562, 567
bandpass 562, 567
band-rejection 562, 567
Bessel 386
bridged-T 566
broad-band
combining-type band-rejection 
filter 565
Butterworth 386

Index
615
Chebyshev 386
criteria for band-rejection 562
electric 379
FIR 522
high-pass 123
Linkwitz-Riley 386
low-pass 122
minimum phase response 562
minimum-phase 567
narrow-band 564
octave bandpass 121
parameters 562
recursive 524
time offset tracking 196
transfer characteristics 565
Filters
IIR 524–526
linear phase 527–528
Finite Element Analysis (FEA) 
460
Finite Impulse Response filter 
(FIR) 543
Fink, Donald G 5
FIR 543
Fisher, Avery 15
Fleming, John Ambrose 4
Fletcher, Harvey 12, 27, 28, 87, 
268, 279
Flutter echo
effect of a space heater 177
Fogg Art Museum 216
Formatting 537
Fourier
exponential series 477–482
integral 483
transform 484–485
trigonometric series 477–481
Fourier transform 19
Fourier trigonometric series 478
Fourier, Jean Baptiste Joseph 477
Frequency 75, 175, 283, 292, 297, 
302, 305, 307
angular 75
label 208
resolution 198
Frequency dependent case 39
FSM 255
Fuller, Buckminster 19, 27
G
Gabor wavelets 19
Gabor, Dennis 13, 20, 40, 43
Gain structure 439
Galilei, Galileo 9
Gamma rays 5
Geddes, Earl 374
General Electric 11
General Radio 14
GenRad 341, 559
Geometric Q transformed to stera-
dians (sr) 156
Geometrical acoustics 216
Gold Line TEF analyzer 468
Golden Ear 15
Goya, Francisco de 26
Green, Al 13
Gross Jr., Ervin E. 156
Gross, Kevin 604
Group delay 555
Guillmin, Ernst 5
H
Haas effect 243, 468
Hameroff, Stuart 20
Handbook for Sound Engineers 9
Harris, Cyril M. 171
Harrison, Ercel 13
Hartley, Ralph 40
Head related transfer functions 
(HRTFs) 27
Hearing versus listening 3
Heaviside, Oliver 4, 5, 11, 110, 
502
Helmholtz, Hermann von 15
Henry effect 468
Henry, Joseph 10
Hertz, Heinrich 10
Hewlett Packard 559
Hewlett-Packard 14
Hexadecimal 45
Heyser spiral 13
Heyser, Richard 193
Heyser Integral Transform 193
Heyser Spiral 196
Heyser, Richard C. 9, 13, 25, 35, 
39, 53, 561, 567
TDS class 244
Hilbert Transform 196
Hilliard, John 15
Hippocratic School 19
Holograms 19
Holographic universe 35
Holography 49
Hooke, Robert 9
Hopkins-Stryker 157, 277
Hopkins-Stryker equation 259
Hopkins-Stryker—US and SI 222
Horn
acoustic center 375
acoustic origin 375
astigmatism 374
catenoidal 372
compression drivers 376
conical 370
constant directivity 374
cylindrical 371
exponential 373
polar measurements 375
practical considerations 374
Horowitz, Vladimir 28
Host ID 546
How to Build Loudspeaker Enclo-
sures 15
HP 35 14
Human brain 19, 36
Hunt, Frederick Vinton 9
HVAC 203
I
IBM 37
IEC noise spectra 426
Imaginary numbers 77
Imhotep 165
Impedance 115
characteristic 592
complex 137
defined 135
loudspeaker 129, 192
electrical 364
mechanical 350
notation 136
radiation 349
Z 141
impedance angle 116
impedance bridge 126
Impedance diagram 116
Impedance of a real-world loud-
speaker 433
Impedance tube 303
Improved reverberation time cal-
culations 219
Impulse sampling 489
Indiana University 267
Inductive reactance 116
Inductors 113, 125
Infinite Impulse Response (IIR) 
542
Information Theory 12
Information Theory Inference and 

616
Index
Learning Algorithms 36
Ingard 246
Initial signal delay gap (ISD) 240, 
241
Initial time gap (ITG) 455
Input
unbalanced to balanced 589
Instrument
finding the velocity of sound 
with an analyzer 467
high-quality wave analyzer 573
improper use of real-time analy-
sis 574
measurement analyzers 193
microphone calibrator 342
real-time analyzer 576
RTA application 561
sweep oscillators 573
TEF 193, 240
TEF analysis 567, 576
TEF analyzer 576
TEF measurements 278
Integration 82
Intensity level 178
Interfacing
available input power (AIP) 140
complex impedance 137
EIA microphone rating 139
electrical gain of a system 142
equalizer loss 144
gain and loss blocks 141
impedance
defined 135
impedance notation 136
interfacing the electrical output 
power to the acoustic environ-
ment 143
making reactance visible 136
matched circuits 140
mixer amplifier 142
mixer output 140
Nyquist
plot 137
open circuits 140
technicians viewpoint 135
Z (impedance) 141
Z measurements 141
Interfacing systems
ac current 113
ac voltage 114
admittance 124
capacitors 113, 125
circuits
dual 124
conductance 124
filter
high-pass 123
low-pass 122
impedance 115
loudspeaker 129
impedance angle 116
impedance bridge 126
impedance diagram 116
inductors 113, 125
Kirchhoff’s Law 114
network
theorems 132
networks
constant resistance 128
Zoebel 131
octave bandpass filter 121
phase angle 114
power
average 118
electric 117
power factor 119
reactance
capacitive 116
inductive 116
resistors 113, 125
resonance
parallel 124
series 120
root mean square 118
susceptance 124
two port devices 146
International Organization for 
Standardization (ISO) 38
Internet Protocol (IP) 543, 547
Intervals
semitone 101
Inverse square law 172, 444
ISD 240, 241
Isochronous process 603
Isothermal process 284, 285, 296
It’s from bits 38, 42
ITE (in-the-ear—at the eardrum) 
27
ITE recordings 27
ITG 455
J
James B. Lansing 13
Jaynes, Edwin T. 47
Jeffreys, Sir Harold 47
Jet Propulsion Laboratory 13
Jewett, Frank 11
Jitter 540
Jitter correction 540
John, E. Roy 19
Jones, Doug 244
Joule, James Prescott 10
Journal of the Audio Engineering 
Society 14
Joyce, William 217
K
Kant, Immanuel 19
Keele, Don B. Jr. 354, 429
Keller, Helen 26
Kellogg, Edward W. 347
Kelvin temperature scale 322
Kelvin, Lord 9
Kendall, Gary 244, 245
Kennelly, Arthur Edwin 11
Kennelly-Heaviside layer 11
Killion, Dr. Mead 27, 193
Kircher, Athanasius 9
Kirchhoff, Gustav 5
Kirchhoff’s Law 114
Klein, W. 279
Klepper, David 278
Klipsch and Associates 12
Klipsch, Paul 559
Kneser, Adolph 171
Knudsen, Martin 171
Koch, Christop 20
Kupfmuller, Karl 12, 40, 42
L
L Rad systems 40
Lagrange, Joseph Louis 11
Landauer, Thomas K. 41
Landauer’s Principal 35
Lansing Manufacturing Company 
13
Laplace transform 503, 520
Laplace, Pierre-Simon 11, 47
Large room acoustics
comb filters 226
controlling Dc 229
critical distance (Dc) 228
critical frequency (fc) 215
Dc multipliers and dividers 229
DI 222
direct sound pressure level (LD) 
222, 224
directivity factor (Q) 221
Envelope Time Curve (ETC) 
218

Index
617
ergodic specular enclosures 216
factors to watch for in rooms 231
geometrical acoustics 216
improved reverberation time cal-
culations 219
large room frequency (FL) 215
levels in enclosed spaces 221
Ma 230
mean free path (MFP) 217
N factor 230
number of reflections (N) 217
rate of decay of reverberant 
sound energy 218
reflective path distance (rp) 226
reverberant sound level (LR) 224
reverberation time (LT) 224
room absorption 230
RT60 226
signal-to-noise ratio (SNR) 225
sound intensity level (LI) 220
sound power level (LW) 220
sound pressure level (LP) 220
total power (LW) 221
what is a large room? 215
Large room frequency (FL) 215
Late reflections or echoes 455
Latency 38, 537, 540
Late-reflected sound field 451
LEDE 240
concepts 242
design 248
Leibniz, Gottfried Wilhelm 22
Level
acoustic intensity (LI) 93
adding 97
apparent VU 104
audio 90
A-weighted sound level 97
bel 87
dBV 88
decibel, the name for the trans-
mission unit 87
equivalent 96
intensity 178
inverse-square-law level change 
171
neper 87
older references 96
phon 105
sensation unit SU 87
sound pressure 178
SU 87
voltage amplitude 88
zero 87
Levels in enclosed spaces 221
Limiting 530
Limiting parameters in sound re-
inforcement system design 260
Line array 400, 405
near field 408
processed 408
Line array of discrete sources 445
Linear phase 522
Listener
trained 191
Listener’s maximum level 
(Lp(MAX)) 261
Live End Dead End 240
Load impedance seen by amplifier 
433
loading coils 11
Local area computer network 
(LAN) 543
Lochner, J.P.A. 268
Logarithm 60
base e 76
natural 76
number to any base 100
Log-squared RIR 452
Lord Kelvin 191
Loss
equalizer 144
Loudspeaker
%ALCONS 153
acoustic dipole 349
acoustic intensity 365
acoustic pressure 347, 351, 365, 
371, 395, 408
far field 354
near field 354
acoustic pressure amplitude 397, 
405
adiabatic constant 349
air density 347
amplitude response 382
array 392
arraying techniques 395
Bessel 398
design process 393
distributed 411
average sensitivity 438
bass vented enclosure 412
Bessel array 398
catenoidal horn 372
circuit models 359–363
compression driver 368, 376
cone behavior 356
conical horn 370
constant directivity horn 374
continuous line source 401
coverage 153
critical distance Dc 164
crossover network 378
cylindrical horn 371
direct radiator spatial response 
353
direct radiators 347
directivity
far field 354
function 355
directivity factor 365
directivity index DI 157, 160
distributed system 409
dome radiators 358
effect of combining unaligned 
loudspeakers in an array 472
efficiency 363
electrical impedance 364
equal slope bandpass subwoofer 
416
equal-angle, weighted-area 161
exponential horn 373
frequency response of unaligned 
and synchronized horns 473
half space radiation 353
high density overhead 276
horn 368
acoustic origin 375
horn acoustic center 375
horn astigmatism 374
horn polar measurements 375
horn practical considerations 
374
hybrid arrays 411
idealized geometry 160
impedance 192
large signal behavior 420
length of conductor in gap 348
line array 400, 405
near field 408
processed 408
loudspeaker arrays 447
magnetic induction in gap 348
management systems 580
maximun input voltage 426
mechanical impedance 350
mechanical limit testing 429
minimum geometric Q 158
minimum-phase 567
misalignment 274
missynchronization 470
moving coil 348

618
Index
moving mass 348
multi-loudspeaker arrays 570
multi-way 438
non-linear operation 428
Nyquist diagram 380, 385
overhead 409
parameters 348
pew back 276
piston impedance function 349
piston velocity 350
point source 444
polar response 471
polarity 576
power compression 427
power response 384
powered 439
processed line arrays 405
properly isolated 572
properly shock mounted 572
quality factor (Q) 351
radiated power 358
radiating surface area 347
radiation impedance 349
radiation properties 445
radiation resistance 359
radiator area 348
resonance
free air 352
resonant modes 358
sensitivity 365, 446
single source 393
sound pressure level
axial 363
split source 411
static air pressure 349
steerable line arrays 405
surface acceleration 347
surface displacement 347
surface velocity 347
suspension resistance 348
suspension stiffness 348
synchronization and alignment 
469
system 267
transducers 192
transfer function 379
two misaligned 471
under-balcony loudspeaker de-
lay 469
unequal slope bandpass sub-
woofer 418
vented enclosure 420
voice coil inductance 348
voice coil resistance 348
voltage rating 429
volume velocity 347
wire loss 582
Loudspeaker directivity
%ALCONS 153
critical distance Dc 157
directivity ratio 160
equal-angle, weighted-area 161
idealized loudspeaker geometry 
160
loudspeaker directivity factor 
(Q) 155
minimum geometric Q by loud-
speaker placement 158
signal alignment 153
Loudspeaker efficiency 262
Loudspeaker management sys-
tems 580
Loudspeaker power ratings 425
Loudspeaker sensitivity conver-
sions 262
Loudspeaker–room interactions 
14
Lovelace, Lady 12
LP 425, 430, 446
LSB 45
M
Ma 230, 277
MAC 546
MAC address 546
Mach, Ernst 19
MacKay, David J. C. 36
Maclaurin, Colin 47
Magiae Universalis 9
Magnetic phonograph cartridge 
509
Magnitude vs. phase data 448
Marantz, Saul 15
Markov process 40
Martens, William 245
Martin, Bill 13
Martin, W. H. 87
Materials
absorptive 453
diaphragmatic absorbers 574
quadratic residue diffusors 248
Sonex 246, 278
sound absorption coefficients 
182
Mathcad 14
Mathematica 14
Mathematical operations
addition 60
antilogs 61
division 60
log multipliers 61
logarithm 60
multiplication 60
powers 60
roots 60
subtraction 60
Mathematics
accuracy 54
addition 60
amplitude 79
anechoic chamber 71
angles 75
antilogs 61
bandwidth 67
base units 59
complex numbers 64, 77
addition 78
products 78
quotients 78
complex plane 77
conversion factor 55
decade 65
decade calibration 65
decibel 71
differentiation 82
displacement 80
division 60
energy 58
epoch angle 75
Euler’s theorem 77
exponential notation 61
factor label system 55
force 58
frequency 75
angular 75
gains and losses 54
imaginary number 77
integration 82
linear scales 66
log multipliers 61
logarithm 60
base e 76
logarithmic scales 66
math tables 72
mathematical operations 60
multiplication 60
natural logarithm 76
number of octaves 67
numbers
complex 78
exponents 54

Index
619
negative 54
ratios 54
reciprocals 54
roots 54
simple 54
octave spacing 66
percentages 70
phasor
addition 80
diagram 80
phasors 79
pi 75
power 58
powers 60
precision 54
pressure 58
Q 69
radian 75
radians 67
rate of change 80
ratios 70
real number 77
Renard Series 66
resolution 54
roots 60
sector 75
SI to US conversion 57
solid angles 67
spherical surface area 69
steradians 67
subtraction 60
trigonometry 75
US to SI conversion 57
velocity 80
work 58
Matlab 14
Maxfield’s equation 270
Maximum input voltage-MIV 
425, 430, 437
Maximum physical distance 253
Maxwell, James Clerk 5, 9
McFadden, Johnjoe 19, 21
McIntosh, Frank 15
Mean free path (MFP) 217
Measurements
evaluating speech intelligibility 
273
noise level analysis measure-
ments 203
three parameter 198, 200
Z 141
Measuring acoustic gain 259
Mechanical impedance 300, 302, 
305, 350
Media Access Control (MAC) 543
MediaMatrix® 581
Mercedes Benz, Acoustics Lab 27
Metadata 537
Meter
apparent VU levels 104
calibrating 104
VI 101
VU 101
VU impedance correction 102
Mewborn II, F. B. 602
MFP 184
MGM 13
Microphone
AIP 316
axis 330
boundary 330
cables 339
calibrator 342
capacitor 324
carbon 324
cardioid 330
comb filter 330
comparison to ear 193
compression and expansion 338
connector
digital 602
connectors 339
digital output 601
directional characteristics 328
dynamic 322
EIA rating 139
EIN 321
measurement 341
moving coil 324
noise
thermal 317
noise figure 320
noise sources 319
Nyquist noise 317
passive filter set 316
phantom power 339, 340
piezoelectric 325
polar patterns 328
polarity 575
power
noise 318
pre-emphasis and de-emphasis 
curves 337
pressure 325
pressure gradiant 325
pressure gradient 325, 326
pressure zone 333
proximity effect 327
PZM 333
ribbon 325, 330
sensitivity 315
SNR 320
source impedance 323
speech intelligibility 267
wireless 335
Millikan, Robert 11
Milton, John 26
Minimum phase 513
MIV and EAS
combining 439
MIV test setup for internally pow-
ered loudspeaker 428
MIV-burst voltage 429
MIVpeak 429
MIVrms 429
MIV-thermal 429
Mixer
output 140
Modal decay rates 239
Mode
axial 240, 241
damped and undamped 239
Eigen 239
oblique 240, 241
small room modes 239
tangential 240, 241
Modeling with absorption coeffi-
cients 453
Modes
proximity 575
Modular transfer function 268
Modulation
delta sigma 501
Moir, James 246
Moravec’s warning 41
Morrison, Ralph 5
Morse 246
Morse, Philip 217
Motion Picture Expert Group 
(MPEG) 38
Motivations 25
Mozart, Wolfgang Amadeus 28
MSB 45
MTF 268
Multi-mode fiber 545
Multi-way loudspeaker 438
N
N factor 230
NAG 254
NASA 13

620
Index
Nat 37, 42
Nats 45, 48
Near field 444
Near field vs. far field 444
Needed acoustic gain (NAG) 254
Neper 87
Network bandwidth 543
Network ID 546
Network node identifiers 546
Networks
constant resistance 128
crossover 378
theorems 132
Zoebel 131
Neumann, John von 41
Neuron chips 19, 22
Newton, Isaac 10
Newton, Sir Isaac 47
NLA 203
Noble, Jim 15
Noise
criteria 204
pink 561
random 192
white 561
Noise control 555
Noise Criteria curves (NC) 560
Noise figure 320
Noise Measurement Handbook 
160
Noise power 318
Noise signals
combining levels 98
Noise sources 319
NOM 255
Nonlinear behavior 256
Non-linear dynamics processing 
529
Nonlinear response 256
Non-minimum phase 513
Non-planar wave motion 297
Non-statistical spaces 237
Null frequency interval (NFI) 470
Number base 498
Number of open microphones 
(NOM) 255
Number of reflections (N) 217
Numbers
complex 64, 77, 78
addition 78
products 78
quotient 78
imaginary 77
real 77
Nyquist
plot 137
Nyquist diagram 380, 385
Nyquist display 13
Nyquist noise 317
Nyquist, Harry 12, 37, 40, 568
O
Objective of room modeling 451
Oblique mode 240, 241
Octal 45
Octave
number of 67
spacing 66
Octave bandpass filter 121
Ohm’s Law 94
Olson, Harry 14
One Kelvin 35
Open standard 549
Open Systems Interconnection 
(OSI) 547
Origins in Acoustics 9
Orrery 165
Orwell, George 22
Osborne, Tom 14
OSI Reference Model 548
Over-sampling 39
P
Packet-switched network 543
PAG 256, 259
Parseval’s theorem 485
Particle acceleration 290
Particle displacement 287, 288, 
290, 292, 299, 302
Particle velocity 287, 288, 290, 
292, 297, 306, 308
PASC (Precision Adaptive Sub-
band Coding) 38
Passive filter set 316
PCM (pulse code modulation) 35
Peavey, Hartley 603
Peerless Manufacturing 13
Penrose, Roger 20
Percentages 109
Performer 267
PET 201
Peterson, Arnold P. G. 156
Peutz, V.M.A. 268, 269, 278, 279
Peutz, Victor 26
Pharaoh Zoser 165
Phase 192
linear 522
minimum 513
non-minimum 196, 513
velocity 592
Phase angle 114
Phase response 384
Phase velocity 297, 302, 311
Phasor
addition 80
diagram 80
Phon 105
Phon level 29
Phons 28
Phonurgia Nova 9
Physical terms
energy 58
force 58
power 58
pressure 58
work 58
Piercy, J. E. 171
Pin 1 problem 588
solution 589
Pink noise 40, 426
Pink noise spectra 426
Pinna acoustic response 27
Pinnae response 267, 268
Pinnae responses 30
Piston impedance function 301, 
349
Piston velocity 350
Planck area 49
Planck constant 48
Planck frequency 48
Planck length 42, 48
Planck mass 47
Planck scales 47
Planck system 47
Planck time 48
Planck units 47
Planck, Max 19, 35, 47
Planck’s constant 19
Plane
complex 77
Plane wave 334
Plane Wave Tube 298
Plane wave tube 291, 294, 296, 
297, 299, 304, 371
Plane waves 288, 291, 296, 299, 
305, 307
Plot
ETC 195
Nyquist 200
polar envelope time (PET) 201
Plots

Index
621
directivity 155
Plug
RJ-45 604
Polar lunes 156
Polarity
absolute 576
loudspeaker 576
polarity 192
Pole 507
Pole and zero analysis 508
Pole-zero diagram 509
Potential acoustic gain (PAG) 
256, 259
Power
acoustic 93
available input 140
average 118
compression 427
electric 117
electrical 90
from a voltage source 431
phantom 340
radiated 358
relative speech 270
response 384
Power factor 119
Power rating 428
Power ratings for amplifiers and 
loudspeakers
pink noise 426
Power response 384
Powered loudspeakers 439
Predicting room reflections 450
Pre-emphasis 39
Pressure
acoustic 347, 351
far field 354
near field 354
sound 178
static 349
Pressure gradiant 325
Pressure gradient 326
Pressure microphones 325
Pressure Zone Microphone (PZM) 
226
Pribram, Karl H. 19, 20
Probability theory 47
Process
asynchronous 603
isochronous 603
synchronous 603
Processing
dynamics 528
Processor
virtual sound 581
Psychoacoustic effect 556
Psychoacoustics
bands 28
barks 28
binaural recording 27
critical band 28
critical bandwidth 30
equal loudness contours 30
equivalent rectagular bandwidth 
29
equivalent rectangular band-
widths (ERBs) 28
head related transfer functions 
(HRTFs) 27
ITE (in the ear—at the eardrum) 
27
motivations 25
phon level 29
phons 28
pinna acoustic response 27
sones 28, 29
sound reproduction 25
Pulsating sphere 305
Pupin, Dr. Michael I. 11
Purdue University 15
Putting it all together
acoustical analysis 579
analog interconnections 583
balanced circuits 583
circuits
AES3
connector 599
encoding 597
transmission characteristics 
598
cable
AES3 599
attenuation 592
Cat-5 604
phase velocity 592
propagation properties 595
CobraNetTM 603
interface features 604
connector
XLD 602
connectors
TSR 588
XLR 588
Ethernet 604
impedance
characteristic 592
microphone
connector
digital 602
digital output 601
pin 1 problem 588
solution 589
plug
RJ-45 604
process
asynchronous 603
isochronous 603
synchronous 603
S/PDIF 600
SCIN removal 589
skin effect 593
unbalanced 587
unbalanced to balanced input 
589
device interconnections 582
electomagnetic waves
absorption 585
electromagnetic waves
polarization 585
reflection 585
skin depth 585
EMI susceptibility 584
loudspeaker
wire loss 582
loudspeaker management sys-
tems 580
MediaMatrix 581
virtual sound processor 581
Q
Q 69, 155, 156, 157, 158, 271, 277
calculating minimum 271
geometric 156
by placement 159
definition 156
improper 275
loudspeaker directivity factor 
155
minimum 271
role in %ALCONS 277
transform to steradians (sr) 156
Q in %ALCONS 277
Quadratic residue diffusors 248
Quality factor (Q) 351
Quality of Service (QoS) 549
Quantization 535, 550
Quantizing 35
R
Radian 75
Radiating surface area 347

622
Index
Radiation
half space 353
impedance 349
Radiation impedance 349
Radiation properties of a loud-
speaker 445
Radiation resistance 359
RASTI 278
Rate of decay of reverberant 
sound energy 218
Ratios 70
acceptable room ratios 242
directivity 160
numbers 54
power 88, 89
room 240
voltage 88
Ray behavior 454
Ray tracing 449, 460
Rayleigh, Lord 15, 35, 369
Reactance
capacitive 116
inductive 116
making visible 136
Real world power generation 434
Realistic room models 457
Reeves, Alex Harley 35
Reflection 176
focused 273
specific 274
specific long, delayed, high level 
274
Reflection free zone 244
Reflections per second (RPS) 218
Refraction 171, 176
Regeneration 255
Regenerative swelling 256
Release time 531
Renard Series 66
Required electrical power (REP) 
261
Resistance
radiation 359
Resistors 113, 125
Resolution
frequency 198
time 198
Resonance
free air 352
parallel 124
series 120
Response
impulse 195
magnitude 196
minimum phase 196
phase 196
pinnea 207
Reverberant energy 456
Reverberant sound field 451
Reverberant sound level (LR) 224
Reverberation 456
excessive 274
Reverberation time
small room 238
Reverberation time (LT) 224
Rice, Chester W. 347
Rice, Edwin W. 11
Rigging 4
RIR 456
RJ-45 604
Rodgers, Carolyn “Puddie” 244, 
465
Room
absorption 574
Room absorption 230
Room acoustics 451
Room impulse response (RIR) 451
Room measurement nomenclature 
608
Room model detail 449
RoomCaptureTM 457
Root
numbers 54
Root mean square 118
RT60 217, 226
calculating maximum 271
excessive 274
Rudmose, Dr. Wayne 555
Rudmose, Wayne 13
S
S plane 507
S plane to Z plane mapping 522
S/PDIF 600
Sabine equation 215, 217
Sabine, Wallace Clement 15, 216, 
219, 453
Sacks, Oliver 26
Sample and hold 495, 497
Sampling 35
Sampling and recovery 489–495
Sampling angular frequency 493
Sampling Theorem 493–501
Santa Fe Opera 38
Scales
linear 66
logarithmic 66
Schotto, Gaspare P. 9
Schroeder, Manfred 215, 248
Schultz, Ted 238
SCIN removal 589
Scott, Herman Hosmer 15
Seals, Dan 575
Seeing Voices 26
Series resonance 120
Setup for measuring the MIV 427
Seven Arts 13
Shannon entropy 41
Shannon Information Theory 35
Shannon Space 36
Shannon, Claude 12, 25, 37, 40, 
43, 47
Shannon’s theory 35
SI to US conversion 57
Siemens, Ernst Werner von 10
Signal
analytic 195
Nyquist
trace 196
Signal alignment 153
Signal delay 465
acoustic astigmatism 470
acoustic center 470
acoustic origins 470
alignment 469
convergence 469
delay 467
directional control device 
(DCD) 470
distance 467
Doak and Bolt delay 469
effect of combining unaligned 
loudspeakers in an array 472
equations 466
Fay-Hall effect 468
finding the velocity of sound 
with an analyzer 467
frequency response of unaligned 
and synchronized horns 473
Gold Line TEF analyzer 468
Haas effect 468
Henry effect 468
loudspeaker missynchroniza-
tion 470
natural signal delay 469
null frequency interval (NFI) 
470
polar response 471
setting signal delay 469
signal alignment 469
signal synchronization 469

Index
623
synchronization & alignment of 
arrays 469
time 467
two loudspeakers misaligned 
471
under-balcony loudspeaker de-
lay 469
useful 466
velocity 467
velocity equation 467
why delay 465
Signal processing
 510
ADC 500
aliasing 494
analog to digital conversion 497
attack time 530
Bessel polynomials 510
binary codes 498
biquad 526
Butterworth polynomials 510
compression 529
DAC 499
delta sigma modulation 501
dynamics processing 528
equalization 514
global 517
local 517
Euler’s theorem 481
expansion 529
filter
FIR 522
recursive 524
Fourier trigonometric series 478
impulse sampling 489
Laplace transform 503, 520
limiting 530
minimum phase 513
non-linear dynamics processing 
529
non-minimum phase 513
number base 498
Parseval’s theorem 485
phase
linear 522
pole 507
pole and zero analysis 508
pole-zero diagram 509
release time 531
S plane 507
S plane to Z plane mapping 522
sample and hold 495, 497
Sampling Theorem 493–501
spectra 477
spectral density 486
spectrum of a periodic impulse 
sampled signal 489
staircase time domain behavior 
496
system theory 502
table of function transform pairs 
503
table of operations transform 
pairs 504
transfer function 506
transfer function surface 507
uncertainly principle, classical 
487
unit impulse 487
Signal-to-noise ratio (SNR) 225, 
253, 271
Sine wave
steady state 192
swept 192
Single-mode fiber 545
Singularity problem 42
SketchupTM 460
Skin effect 593
Small room acoustics
acceptable ratios 242
Acorn Studios 248
acoustical parameters 238
axial modes 240, 241
damped and undamped modes 
239
dead end 243
diffusion 244, 245
geometry 240
Haas effect 243
initial signal delay gap (ISD) 
240, 241
ISD 240, 241
LEDE 240
concepts 242
design 248
live end 243
Live End Dead End 240
Master Sound Astoria Recording 
Studio 243
modal decay rates 239
modes 239
Non-statistical spaces 237
oblique mode 241
quadratic residue diffusors 248
ratios 240
reflection free zone 244
resonances 239
reverberation time 238
tangential mode 241
Smolin, Lee 22
Snow, William B. 12, 226, 558, 
559, 572
SNR 253, 268, 274, 320
Sones 28, 29
Sonex 246
Sony/Philips Digital Interface 
(S/PDIF) 540
Sound
effect of altitude on the velocity 
of sound in air 175
intensity 178
pressure 178
temperature effect on speed 466
velocity 173
Sound and our brain
axon chips 19, 22
conscious electromagnetic infor-
mation field (CEMI) 21
digital voice recognition 22
Fourier transform 19
human brain 19
neuron chips 19, 22
synapse chips 19, 22
transcranial magnetic stimula-
tion 21
Sound behavior 454
Sound energy density 178
Sound intensity 178
Sound intensity level (LI) 220
Sound level meter (SLM) 315
Sound power level (LW) 220
Sound pressure 178
Sound pressure level 178
axial 363
Sound pressure level (LP) 220
Sound radiation patterns 259
Sound reproduction 25
Sound System Engineering 15, 
443
Sound system equalization
absolute polarity 576
acoustic feedback
analysis 556–558
decay 557
growth 556
negative growth and decay 558
active band-pass filter 564
band-boost filter 562, 567
bandpass filter 562, 567
band-rejection filter 562, 567
bridged-T filter 566
broad-band combining-type 

624
Index
band-rejection filter 565
criteria for band-rejection filters 
562
diaphragmatic absorbers 574
direct sound level (LD) 555
don’t equalize for hearing loss 
575
early practitioners 559
effects of surfaces on feedback 
575
envelope time curve 568–569
magnitude and phase 569
equalizing for playback 573
ETC 568
feedback
defined 556
feedback is a single frequency 
570
feedback path 556
feedback stability margin 558
FFT 573
filter parameters 562
filter transfer characteristics 565
forward transfer function 556
gain ratio 557
GenRad 559
group delay 555
Hewlett Packard 559
high-quality wave analyzer 573
house curves 561, 574
improper use of real time analy-
sis 574
loudspeaker polarity 576
microphone polarity 575
minimum phase loudspeaker 
567
minimum phase response 562
minimum-phase filters 567
Mother Natures way 572
multi-loudspeaker arrays 570
multiplicity of sound fields 
570–571
narrow-band filter 564
negative acoustic feedback 558
noise control 555
Noise Criteria curves 560
Nyquist display 569
oscillatory feedback 556
passive equalizer 564
pink noise 561
positive feedback 556, 558
properly isolated 572
properly shock mounted 572
proximity modes 575
psychoacoustic effect 556
real time regenerative response 
method 573
real-time analyzer 559, 573, 576
real-time regenerative-response 
572
regenerative response 572
tuning 573
room absorption 574
RTA application 561
sound field 570
sources of feedback 569
steady state gain ratio 558
steady-state-feedback 572
sweep oscillators 573
TEF analysis 567, 576
TEF analyzer 573, 576
time dependency 570
transient nature of acoustic feed-
back 556
unnatural distortions 572
white noise 561
Source
impulse 192
Source impedance 323
Space
non-statistical 237
Specific acoustic impedance 293, 
296, 300, 305, 306
Spectra 477
Spectral density 486
Specular reflections 460
Speech intelligibility 269
%ALCONS 268, 269, 272, 276, 
277
%ALCONS variables 277
acoustic environment 267
articulation 270
articulation index 271
articulation losses of consonants 
in speech 268
calculating %ALCONS 269
calculating the minimum 271
calculation of the maximum 
RT60 271
calculations 271
causes of reduced intelligibility 
274
changing STI measurements to 
%ALCONS 274
choosing the correct %ALCONS 
equation 277
comb filter 276
converting STI measurements to 
%ALCONS 274
detecting reflections without an-
alyzers 278
distance from the source 274, 
275
effect of SNR on %ALCONS 271
electronic systems 267
envelope time curve 269, 274
ETC 269, 274
evaluating speech intelligibility 
measurements 273
excessive reverberation 274
excessive RT60 274
factors affecting %ALCONS 272
focused reflections 273
high density overhead distribu-
tion 276
Hopkins-Stryker equation 277
improper coverage angles 275
improper Q 275
Indiana University 267
Intelligibility Workshop 267
Intelligibility Workshop 1986 
278
key parameters affecting speech 
intelligibility 268
lack of synchronization 274
loudspeaker misalignment 274
loudspeaker system 267
Ma 277
Maxfield’s equation 270
maximum RT60 271
microphone 267
minimum Q 271
misalignment 275
misequalization 274, 275
modified rhyme tests 278
modular transfer function 268
MRT tapes by Dynastat 278
MTF 268
non-acoustic articulation prob-
lems 275
pew back loudspeaker systems 
276
pinnae response 267, 268
polar responses before and after 
alignment 276
poor quality devices 274
poor SNR 274
RASTI 278
receiver-listener 267
relationship between acoustic 
gain and %ALCONS 278
relationship between QMIN and 

Index
625
D2 (MAX) 276
relative speech power 270
role of 277
SNR 268, 271, 274
Sonex 278
specific long, delayed, high-lev-
el reflections 274
specific reflections 274
speech power 270
Speech Transmission Index 273
STI 273
subjective word tests 278
synchronization 274
talker 267
TEF analyzers 269
TEF measurements 278
usable percentages 269
Speech Transmission Index 273
Sphere 158
divided into polar lunes 163
divided into zones 163
hemisphere 158
one-eighth sphere 158
one-quarter 158
spherical segments 158
Spherical loudspeaker data 443
Spherical wave 444
Spherical waves 306
Staircase time domain behavior 
496
Standard data formats 540
Standard Handbook for Electrical 
Engineers 5
Standing wave 299, 303
Static air pressure 349
Steinberg 12
Steinberg, J. C. 559
Steinmetz, Charles Proteus 11, 78
Steradians, sr 156
STI 273
Stochastic process 40
Stockham, Thomas 38
Strutt, M. J. O. 216
Stuart, J. Robert 41
Studer 38
SU 87
Sullivan, Anne 26
Surface acceleration 347
Surface displacement 347
Surface velocity 347
Susceptance 124
Sutherland, L. C. 171
Symbols 605
Symbols and abbreviations 605
Synapse chips 19, 22
Syn-Aud-Con Newsletters 15
Synchronization 537, 539
lack of 274
Synchronous process 603
Synergetic Audio Concepts 13
System
criteria 555
electrical gain 142
electronic 267
loudspeaker 267
System gain structure 439
System theory 502
Systems
digital 520–528
playback 108
T
T30 456
Table of function transform pairs 
503
Table of operations transform 
pairs 504
Tables
math 72
Tangential modes 240, 241
Taylor, Herb 13
TEF 193, 240
analysis 567
analyzer 269, 573, 576
displays 196
processing signals 194
Tektronics 14
Telephone circuits 87
Temperature
effect on the speed of sound 466
Tesla, Nikola 10
Test
eye pattern 536
Text into binary, octal, hexadeci-
mal 46
The Mathematical Theory of 
Communication 43
The Physics of Information 41
The Theory of Probability 47
Thermal noise 317
Thermodynamic entropy 41
Things amplifiers hate
2 ohm loads 435
low crest factor signals 435
Thomson, William 113
Thuras, Albert L 12
Time 465, 467
clock time 465
dependency 570
resolution 198
Time Delay Spectrometry (TDS) 
13
Todrank, Robert 248
Tone meister 28
Tononi, Giulio 20
Total power (LW) 221
Transcranial magnetic stimulation 
(TMS) 21
Transfer function 379, 506
Transfer function surface 507
Transport of digital audio data 537
Tronchin, Lamberto 9
Tube
plane wave 371
Tukey, John W. 35, 44
Tuller, Betty 40
Turing, Alan 47
Two port devices 146
U
Unbalanced circuits 587
Unbalanced to balanced input 589
Uncertainty principle, classical 
487
Unit impulse 487
Universal gas constant 284
US to SI conversion 57
V
Velocity 80, 467
phase 592
temperature dependant 174
VI 12
Ville, J. 43
Virtual Local Area Network 
(VLAN) 548, 549
Virtual sound processor 581
Volta, Alessandro 9
Voltage 88
amplitude 88
combining 99
ratio 88
Volume velocity 347
Von Guericke, Otto 9
W
Wahrenbrock, Kenneth 333
Warner Bros. 13
Watt, James 10
Wave behavior 454

626
Index
Waveform
analog 535
Wavelength 175, 287, 292, 295, 
303, 310, 350
frequency 175
typical 175
Waves
electromagnetic
absorption 585
polarization 585
reflection 585
skin depth 585
Weber, Wilhelm Eduard 10
Webster, A. G. 369
Wente, Edward C. 12
Western Electric 13
Wheeler, John Archibald 38, 47
White noise 40
Wilczek, Frank 42
Wilson, Fred 13
Wire
loss 582
Wire-frame model 458
Word clock 539
X
XLD 602
Z
Z transform 520
Zone
reflection free 244


