Articles
https://doi.org/10.1038/s41928-020-00523-3
1CEA, LETI, Université Grenoble Alpes, Grenoble, France. 2Université Paris-Saclay, CNRS, Centre de Nanosciences et de Nanotechnologies, Palaiseau, 
France. ✉e-mail: thomas.dalgaty@cea.fr; damien.querlioz@c2n.upsaclay.fr; elisa.vianello@cea.fr
A
n exciting target for the future of computing is the develop-
ment of a standalone system capable of learning, adapting 
and acting locally at the edge1—and thus independent of the 
cloud—while simultaneously working within constraints in terms of 
energy consumption, data availability and memory size. Currently, 
there is no commercial system that can meet these requirements, 
but edge learning is an application domain that is expected to grow 
over the coming decade2. However, the development of edge learn-
ing faces particular challenges given the noisy and limited raw sen-
sory information encountered in the complex environments where 
such systems could be deployed. This could be, for example, an 
implanted medical system required to locally update its operation 
based on the evolving state of a patient.
Machine learning provides the enabling models and algorithms 
for these systems, but, until recently, little attention has been given 
to the hardware that underpins their computation. Machine learn-
ing models are trained using general-purpose hardware based on 
the von Neumann architecture3. This architecture has spatially sepa-
rated processing and memory, which is not ideal for energy-efficient 
learning. For example, state-of-the-art performance in machine 
learning is currently being obtained with neural network models 
that feature a very high number of parameters4, which are deter-
mined using a backpropagation algorithm5 and a large volume of 
data. The energy required to train these models can be considerable 
due to the transfer of large quantities of information between the 
memory and processing centres of the hardware6,7. Although cloud 
computing platforms offer a centralized solution for such energy- 
and data-intensive training, these demands are not consistent with 
the requirements of edge learning1,2. For edge applications, it is 
likely that the von Neumann approach will need to be abandoned 
in favour of an alternative in which memory and processing coexist 
in the same location.
Resistive random access memory (RRAM) technologies, often 
referred to as memristors8, are a promising approach for the devel-
opment of in-memory computing systems due to their efficient 
implementation—relying simply on Kirchoff’s current law—of 
the dot-product (or multiply-and-accumulate) operation used 
in machine learning9 (Fig. 1a). RRAM comes in many forms10–13, 
and intense effort is currently directed towards it use as synaptic 
elements in hardware-based artificial neural networks for edge 
computing systems9,14–21. Approaches for in situ training of these 
systems revolve around in-memory implementations of backpropa-
gation algorithms15,17–19. Implementing these algorithms remains 
challenging because of multiple non-ideal device properties, such 
as nonlinear conductance modulation22, a lack of stable multi-level 
conductance states14,23 and device variability24.
Although several non-ideality mitigation techniques15–18,20,21 
have been developed that enhance the accuracy of in situ training, 
these device properties lead to a performance that is lower than 
that obtained on conventional computing systems25,26. Approaches 
based on neuroscience-inspired learning algorithms, such as 
spike-timing-dependent plasticity, instead feature resilience and 
can sometimes benefit from device non-idealities27–29. However, 
these models cannot yet match state-of-the-art machine learning 
models when applied to practical tasks. Alternatively, it is possible 
to actively embrace resistive memory non-idealities. For example, 
the cycle-to-cycle conductance state variability, sometimes used 
as a source of entropy in random number generation30, can also 
be exploited in stochastic artificial intelligence algorithms such as 
Bayesian reasoning31,32, population coding neural networks33 and 
in-memory optimization34,35. These approaches, however, sacrifice 
conductance non-volatility, which is the basis of resistive memory’s 
potential for efficient in-memory computing.
In this Article, we report an approach that simultaneously 
exploits conductance variability and conductance non-volatility 
without requiring mitigation of other device non-idealities. We 
show that cycle-to-cycle conductance variability in resistive 
memories can be viewed as physical random variables that can be 
exploited to implement in-memory Markov chain Monte Carlo 
(MCMC) sampling algorithms36. In particular, we demonstrate how 
a resistive-memory-based Metropolis–Hastings MCMC sampling 
approach can be used to train, in situ, a Bayesian machine learning 
In situ learning using intrinsic memristor 
variability via Markov chain Monte Carlo sampling
Thomas Dalgaty   1 ✉, Niccolo Castellani1, Clément Turck2, Kamel-Eddine Harabi2, 
Damien Querlioz   2 ✉ and Elisa Vianello1 ✉
Resistive memory technologies could be used to create intelligent systems that learn locally at the edge. However, current 
approaches typically use learning algorithms that cannot be reconciled with the intrinsic non-idealities of resistive memory, 
particularly cycle-to-cycle variability. Here, we report a machine learning scheme that exploits memristor variability to imple-
ment Markov chain Monte Carlo sampling in a fabricated array of 16,384 devices configured as a Bayesian machine learning 
model. We apply the approach experimentally to carry out malignant tissue recognition and heart arrhythmia detection tasks, 
and, using a calibrated simulator, address the cartpole reinforcement learning task. Our approach demonstrates robustness 
to device degradation at ten million endurance cycles, and, based on circuit and system-level simulations, the total energy 
required to train the models is estimated to be on the order of microjoules, which is notably lower than in complementary metal–
oxide–semiconductor (CMOS)-based approaches.
Nature Electronics | VOL 4 | February 2021 | 151–161 | www.nature.com/natureelectronics
151

Articles
NatuRe EleCtROniCS
model realized in an array of resistive memories. The devices that 
perform the critical sampling operations are also those that store 
the parameters of the Bayesian model in their non-volatile con-
ductance states. This eliminates the need to transport information 
between processing and memory, and instead relies on the physical 
responses of nanoscale devices under application of voltage pulses 
inside the memory circuit itself.
To illustrate the practicality of RRAM-based MCMC sam-
pling, we implement an experimental system that consists of a 
computer-in-the-loop with a fabricated array of 16,384 resistive 
memory devices in a one-transistor–one-resistor (1T1R) configu-
ration, which are organized by the computer to realize a Bayesian 
machine learning model. We train the system to solve classification 
tasks including the detection of malignant breast tissue samples and 
the detection of arrhythmic heartbeats. We also apply the approach, 
using behavioural simulations calibrated on array-level variability 
characterization data, to the cartpole reinforcement learning task. 
Benchmarked against deterministic software-based neural network 
models, we find that the resulting Bayesian models perform bet-
ter, and that RRAM-based MCMC trains a full model with orders 
of magnitude fewer programming operations compared to existing 
RRAM-based backpropagation approaches. Finally, through the 
design and simulation of a fully integrated implementation of our 
approach, we compare the training energy of our approach with that 
required using conventional complementary metal–oxide–semi-
conductor (CMOS) approaches, and observe an energy reduction 
of several orders of magnitude.
Resistive-memory-based MCMC sampling
Arrays of resistive memory devices are capable of efficient 
in-memory implementations of ex situ trained machine learning 
models9,14. Considering an RRAM-based logistic regression clas-
sifier, one of the most canonical models in machine learning, the 
circuit of M parallel devices shown in Fig. 1a defines a hyper-plane 
that can separate two classes of data. Each parameter of the logis-
tic regression model is defined by the conductance of one of the M 
devices. The response of this conductance-based model, g, can be 
inferred by presenting a voltage vector V, encoding a data point, to 
the top terminals of the devices and sensing the current that flows 
out of the common, bottom node. This current is equivalent to the 
dot product between the two vectors, V ⋅ g.
The dominant approaches for training such RRAM-based mod-
els in situ are gradient-based learning algorithms, whereby a loss 
metric is differentiated with respect to the current parameters of 
Update number
Posterior distribution
Initial model
Localized random jumps
Update number
g
g
g
g
g
g
V[0]
V(1)
V
V.g
V.g =
V[0]g[0]
V [1]g[1]
V [0]g[0]
V [2]g[2]
V[3]g[3]
g [0]
g [1]
g [2]
g[3]
V [0]
a
b
∂Loss
∂g
c
V [1]
V [2]
V [3]
V
g
+V [1]g[1]
+V [2]g[2]
+V [3]g[3]
g
Initial model
Gradient-based updates
Optimal model
Posterior approximation
Δg = α
p(gn+1∣gn)
Conductance, g
Conductance, g
Probability density
Probability density
Probability density
Loss
Loss
Loss
Fig. 1 | Strategies for training RRAM-based models. a, Left: a conductance model g, composed of four resistive memory elements, defines a linear 
boundary that (right) separates two classes of data (red circles from blue squares). Through application of a voltage vector V to the top electrode of the 
parallel resistive memories, the summed current flowing out of the common node at the bottom electrode is equivalent to the dot product V ⋅ g, which 
can then be used to determine to what class the data point V belongs. b, Left: gradient-based learning algorithms iteratively compute the derivative of 
an error metric with respect to a conductance model g, multiplied by a learning rate α, to determine updates to be applied to the g parameters. The ideal 
RRAM device should be capable of high precision and linear conductance updates. Right: the three panels show the gradient-descent algorithm for an 
increasing number of model updates (green crosses). From an initial model, the algorithm performs gradient-based updates until it converges to a local 
minimum in error. c, Left: sampling algorithms use a proposal distribution p(gn + 1∣gn) to propose random updates to model conductance parameters, 
which are then either accepted or rejected. The ideal RRAM device for sampling algorithms should offer random conductance updates deriving from a 
known probability distribution. Right: the three panels illustrate how a sampling algorithm performs local random jumps on the posterior distribution 
for an increasing number of sampling operations. From an initial model, the proposal distribution is used to generate a series of localized random jumps 
(dashed green lines), which are then either accepted (green crosses) or rejected. The algorithm tends to accept models of a higher probability density 
on the posterior distribution. After a sufficient number of iterations the accepted models can be used together as an approximation of the posterior 
distribution (blue shading).
Nature Electronics | VOL 4 | February 2021 | 151–161 | www.nature.com/natureelectronics
152

Articles
NatuRe EleCtROniCS
the model. The resulting derivative provides the conductance 
updates required to guide the model down the slope of a gradi-
ent until it settles into a minimum (Fig. 1b). However, perform-
ing this type of training in-memory is extremely challenging due 
to the nonlinear and random characteristics of resistive memory 
technologies, which do not naturally offer an adequate precision 
in these updates14,22–24. Furthermore, in such a deterministic mod-
elling approach (Fig. 1a), each parameter is described by a single 
value, and it is not possible to account for parameter uncertainty. 
Capturing uncertainty in parameters is important when faced with 
the limited, possibly incomplete, data and noisy sensory readings 
encountered at the edge. To account for uncertainty, it is prefer-
able to construct a Bayesian model37,38. In this case, parameters are 
represented, not by single values, but by probability distributions. 
The distribution of all of the parameters of a Bayesian model, given 
observed data, is called the posterior distribution. As an analogue 
to deriving an optimal deterministic model through gradient-based 
updates, the objective in Bayesian machine learning is to learn an 
approximation of the posterior distribution. For this purpose, sam-
pling algorithms, most often MCMC sampling36, can be employed. 
Instead of descending an error gradient, MCMC sampling makes 
localized random jumps on the posterior distribution (Fig. 1c). The 
algorithm jumps from a current location in the model space g to a 
proposed location gp, according to a proposal distribution p(gp∣g), 
usually a normal random variable. By comparing the proposed and 
current models, a decision is made on whether to accept or reject 
the proposed model. If accepted, the next random jump is made 
from this newly accepted model. After a sufficiently large number of 
iterations, the accepted samples describe, together, an approxima-
tion of the posterior distribution.
In this Article we realize that, in stark contrast to the case 
of gradient-based learning algorithms, the properties of resis-
tive memories are incredibly well suited to the requirements of 
MCMC sampling algorithms. This is because the cycle-to-cycle 
conductance variability, inherent to device programming, is not a 
nuisance to be mitigated, but is instead a computational resource 
that can be leveraged by viewing resistive memory devices as physi-
cal random variables. More specifically, we exploit the variability 
of hafnium-dioxide-based random access memory13 (OxRAM), 
co-integrated into a 130-nm CMOS process39 (Methods). The  
conductivity of an OxRAM device can be modified through appli-
cation of voltage waveforms, which, through reduction–oxidation 
reactions at an interfacial oxygen reservoir between the oxide and 
top electrode, create or rupture a conductive oxygen-vacancy fila-
ment between the electrodes. The device can be SET into a high 
conductive state (HCS) by applying a positive voltage to the top 
terminal of the device, while grounding the bottom, and thereafter 
RESET into a low conductive state (LCS) by applying a positive volt-
age to the bottom electrode while grounding the top.
Each time the device is SET, a unique HCS conductance is 
achieved, resulting from the random redistribution of oxygen 
vacancies within the oxide24 on consecutive programming cycles. If 
the HCS conductance is measured over successive cycles, a normally 
distributed cycle-to-cycle conductance probability density emerges 
(Fig. 2a). The SET operation is therefore analogous to drawing a 
random sample from a normal distribution. In addition, the median 
conductance of this probability distribution can be controlled by 
limiting the SET programming current (ISET) via the gate-source 
voltage of a series transistor. The relationship between the con-
ductance median and SET programming current follows a power 
law40, and the standard deviation of the distribution also depends 
on the SET programming current (Fig. 2b)—these quantities are 
also subject to device-to-device variations (Fig. 2c). Therefore, 
manifested in the physical response of these nanoscale devices, we 
find the essential computational ingredient required to implement 
in-memory MCMC sampling algorithms—a physical normal ran-
dom variable that can be harnessed to propose new models based 
on the current one.
We propose that the N × M resistive memory array depicted in 
Fig. 3a can be trained through MCMC sampling and then store, in 
the distribution of its non-volatile conductance states, the result-
ing posterior distribution of a Bayesian model. A single determin-
istic model, gn, is stored in each of the rows, where its parameters 
are encoded by the conductance difference between positive g+n 
and negative g−n sets of devices—allowing for each parameter to 
be either positive or negative (Fig. 3b). The principle of our in situ 
learning approach is to generate at each row a proposed model, 
based on the model in the previous row, in line with the Metropolis–
Hastings MCMC sampling algorithm36 (see Methods for a detailed 
description). Each parameter of the proposed model can be  
0.03
a
b
c
101
102
102
101
40
30
20
10
50
100
Conductance median (µS)
100
102
HCS probability density
Conductance median (µS)
Cycle-to-cycle s.d. (%)
Cycle-to-cycle s.d. (%)
0.02
0.01
0
40
60
80
Conductance (µS)
Current (µA)
Conductance
s.d.
100
120
140
Fig. 2 | Electrical characterization of OxRAM cycle-to-cycle and device-to-device variability. a, Probability density of the HCS cycle-to-cycle variability 
for a single OxRAM device, measured over 100 RESET/SET cycles (Methods) and fitted with a normal distribution (dashed line). b, Cycle-to-cycle 
conductance median and standard deviation for a population of 4,096 devices, for a range of SET programming current (Methods). Both relationships 
are fit with a power law. The device-to-device variability in the quantities over the 4,096 devices, extending to the 95th and 5th percentiles (two standard 
deviations), is shown with error bars at each point. c, Joint distribution of the conductance median and standard deviation of each device in the population, 
where 4,096 devices have been RESET/SET-cycled 100 times under the same programming conditions (Methods), and the resulting median conductance 
and standard deviation of each device have been plotted as a single green point, illustrating the device-to-device variability within a population. Two 
histograms on opposing axes show the probability densities for the conductance median and standard deviation independently.
Nature Electronics | VOL 4 | February 2021 | 151–161 | www.nature.com/natureelectronics
153

Articles
NatuRe EleCtROniCS
generated naturally using the OxRAM physical random variable. 
This is achieved by performing a SET operation on each device in the 
row with a programming current that samples a new conductance 
value from a normal distribution, provided by its cycle-to-cycle 
variability, centred on that of the corresponding device in the pre-
vious row, as depicted in Fig. 3c. By computing a quantity called 
the acceptance ratio (Methods), a decision is made on whether this 
proposed model should be accepted or rejected. If rejected, the row 
is reprogrammed under the same conditions, thereby generating a 
new proposed model. Additionally, the value of a digital counter, Cn, 
which is associated with the previous row, is incremented by one. 
By tracking the number of rejections in this manner, the contribu-
tion of the model in each row to the overall probability density of 
the posterior approximation (Fig. 1c) is taken into account. If the 
proposed model is instead accepted, the process is repeated at the 
next row, and so on until the algorithm arrives at the final row of 
the array.
At this point, the distribution of programmed differential con-
ductances in each of the array columns corresponds to the learned 
distributions of each of the Bayesian model parameters—the poste-
rior distribution. After training, the learned posterior distribution 
in the array can be applied to a task through inference (Methods).
Supervised learning
We now apply in situ RRAM-based Metropolis–Hastings MCMC 
sampling to supervised learning tasks. This is achieved experi-
mentally using a computer-in-the-loop with a fabricated array of 
16,384 OxRAM 1T1R structures, as shown in Fig. 3d. In this 1T1R  
V
–V[0]
V[0]
–V[1]
VSET
VSET
V[1]
–V[M–1]
V [M–1]
–V[0]
V [0]
–V[1]
V [1]
–V[M–1]
V [M–1]
p (g [0])
g0
C0
g[0]
VREAD
g1
C1
VREAD
gN–1
CN–1
Proposal density
Proposal density
VREAD
g+[0]
g–[0]
gp+[0]
g
d
c
b
a
g+
g–
V.g+
VGATE+
g = (g+ – g–)
V.g
V.g+
f (V.g)
VGATE–
gp
Row n
Row n+1
g+[0]
g–[0]
gp+[0]
gp–[0]
gp–[0]
VGATE–(g–[0])
VGATE+(g+[0])
f(V.g0)C0
f(V.g1)C1
f(V.gN–1)CN–1
1R
1T
HfO2
TiN
Fig. 3 | Implementation of Metropolis–Hastings MCMC sampling on a fabricated RRAM array. a, Memory array architecture where RRAM conductances 
store the posterior approximation. Each of the N rows stores a single conductance model gn, contains a digital counter element Cn and applies the 
function f()Cn to the current flowing out of the row. b, A single array row is the differential conductance between conductance vectors g+ and g−. A 
positive voltage vector, V, is applied to the top electrodes of g+, and an equivalent negative voltage vector, −V, is applied over the top electrodes of g−. 
If the common, bottom node is pinned at a virtual ground (dashed ground symbol), the current flowing out of the row is equal to the dot product V ⋅ g. 
c, Model proposal step between two array rows. Using the known relationship between SET programming current and the conductances read in row n 
(Methods), devices (pointed to by the dashed arrows) gp+[0] and gp−[0] in the (n + 1)th array row are SET. The SET programming currents are proportional 
to the conductances of the corresponding devices in the nth row (g+[0] and g−[0]). This thereby samples new conductance values for gp+[0] and gp−[0], 
in the (n + 1)th row, from normal random variables with medians equal to the conductances of the devices g+[0] and g−[0] in the nth row (left, green 
distributions). The SET programming currents are determined by applying appropriate voltages VGATE+ and VGATE− to the transistor gates of row n + 1. d, The 
OxRAM array used in the experiments (Methods). An optical microscopy image of the fabricated array is shown in the background. Scanning electron 
microscopy images are superimposed on top. Left: a focused ion beam etch reveals the cross-section of a 1T1R structure (centre). In the front-end-of-line, 
a transistor (1T) acts as a selector for the OxRAM device (1R) integrated in the back-end-of-line. Right: imaged before deposition of the top electrode 
titanium layer, a 10-nm-thick, 300-nm-wide mesa of HfO2 rests on a TiN bottom electrode.
Nature Electronics | VOL 4 | February 2021 | 151–161 | www.nature.com/natureelectronics
154

Articles
NatuRe EleCtROniCS
configuration, the source and bit lines, contacting the top and bot-
tom device terminals, respectively, run parallel to each other instead 
of orthogonally as in the proposed memory circuit of Fig. 3a. In our 
experiment, the dot product realized at each row (Fig. 3) is there-
fore evaluated on the computer. As a function of the acceptance 
ratio calculation, the computer then configures voltage waveforms, 
which iteratively read and program the devices in the array, thus 
implementing the MCMC sampling algorithm in-memory (see 
Methods and Supplementary Fig. 1).
First, as an illustrative example, we train a Bayesian logis-
tic regression model, realized in a 2,048 × 2 array, to separate 
two classes of artificially generated data—the red circles and blue 
squares in Fig. 4b (Methods). After the algorithm terminates, the 
non-volatile conductance states of the devices in the array give rise 
to the multi-modal posterior approximation plotted in Fig. 4a. Two 
distinct peaks emerge, denoting regions of high probability density 
where many of the accepted models are tightly packed. A randomly 
selected subset of these accepted models are plotted as hyper-planes 
in the space of the data in Fig. 4b, each defining a unique linear 
boundary separating the two clouds of data points belonging to 
each class. Through combination of all the accepted models, therein 
using the posterior approximation that now exists in the array, the 
probabilistic boundary between the two classes in Fig. 4c emerges. 
Any previously unseen data point can hereafter be assigned a prob-
ability of belonging to the class of red circles as a function of where 
it falls on this probability contour.
We next apply the experimental system to the classification of 
histologically stained breast tissue as malignant or benign41, using a 
Bayesian logistic model based on a 256 × 16 array. Following model 
training, the differential conductance parameters programmed 
into the resistive memory array are plotted in a heatmap in Fig. 5a  
(raw conductance and SET current distributions are shown in 
Supplementary Figs. 2 and 3). Probability distributions of two 
parameters from the resulting posterior are shown alongside. To 
visualize this learning process, the classification accuracy of the 
accepted model in each array row, in addition to its correspond-
ing counter value, are plotted in Fig. 5b. From an initial con-
ductance model, which achieves a poor accuracy, the algorithm 
quickly converges onto the posterior after ~32 rows (Methods and 
Supplementary Fig. 4). Strikingly, the accuracy does not saturate 
but rather increases sharply during the first 32 rows (the ‘burn-in’), 
then oscillates between high and medium accuracy conduc-
tance models. This is an important property of MCMC sampling  
algorithms: sub-optimal models are also accepted, although less 
frequently, ensuring that the true form of posterior probability den-
sity is uncovered.
After the algorithm terminates, the accuracy achieved on the 
testing set was 97%. Notably, the combined accuracy of all of the 
models in the posterior approximation is greater than the accuracy 
of any of the single accepted deterministic models alone. This train-
ing process was repeated in 100 further experiments and the result-
ing accuracy distribution is reported in Fig. 5c, achieving a median 
accuracy of 96.3% and, on some iterations, classifying over 98% of 
test points correctly. This median accuracy could be sustained for 
array sizes down to 96 × 16 (Supplementary Fig. 5). To benchmark 
this result, deterministic software-based perceptron and single 
hidden-layer neural networks, using a number of synapses equal to 
the number of devices in our experiment, were trained using back-
propagation on the same task. The resulting accuracy distributions 
of these benchmarks over the 100 training iterations are largely 
similar, obtaining a median accuracy of 95.8%, as plotted in Fig. 5c  
(see Supplementary Fig. 6 for deeper networks). Additionally, 
RRAM-based MCMC was found to require between one and four 
orders of magnitude fewer device programming operations than 
RRAM-based backpropagation implementations17,21 of the bench-
mark models (Supplementary Figs. 7 and 8).
Alongside conductance variability, another drawback of resis-
tive memory technologies is their rapid degradation when sub-
jected to repeated programming operations. We therefore RESET/
SET-cycled an RRAM array one million times and, after each decade 
of cycling, performed RRAM-based MCMC training. After only 
100,000 cycles, the array is already unusable in a standard memory 
application (Supplementary Fig. 9). In spite of this, the accuracy 
of the models trained after each decade, plotted in Fig. 5d, remain 
comfortably within the bounds observed using the fresh memory 
array (Fig. 5c). In a further experiment, the error probabilities mea-
sured on the same technology for 10,000,000 cycles are artificially 
imposed during the experiment (Methods); again, the accuracy of 
the resulting model remains within this boundary.
To address a task more representative of learning at the edge, we 
also applied RRAM-based MCMC to train a multi-layer Bayesian 
neural network experimentally to detect heart arrhythmias from 
electrocardiogram recordings42 (Methods and Fig. 5e). Bayesian 
neural networks are the probabilistic counterparts of deterministic 
ones, where probability distributions are used to represent the synap-
tic weights, allowing them to incorporate uncertainty and therefore  
0.2
a
b
c
0.2
0
–0.2
–0.2
0
0.2
0.2
Feature 1, V 1 (V)
Feature 1, V 1 (V)
Feature 0, V0 (V )
Feature 0, V 0 (V )
0
0
–0.2
–0.2
50
0
–50
–100
–50
–25
0
25
50
75
Parameter 1, g1 (µS)
Parameter 0, g0 (µS)
0.900
0.750
0.600
0.450
0.300
0.150
Fig. 4 | Experimental results on the illustrative two-dimensional dataset. a, Posterior distribution stored within the memory array after the training 
experiment. The two differential conductance parameters of each accepted model are plotted as points in the conductance plane (or model space). The 
initial model stored in the zeroth row is shown as a larger red dot. The models accepted into the subsequent array rows are plotted as green points with 
an opacity proportional to the associated row counter value. The transparent lines connecting green points show the jumps on the posterior between 
successive array rows. The resulting posterior distribution is superimposed in a contour plot whereby blue and green contours denote low and high 
probability densities, respectively. b, The two classes of data (red circles and blue squares) and the hyper-planes defined by a subset of 15 stored models 
from randomly selected rows of the memory array. c, The probabilistic boundary that is described by the posterior distribution stored within the resistive 
memory array. Each of the contour lines is annotated with the probability that any point lying on it belongs to the class of the red data. The bounded 
regions between contours are coloured from red to blue, where red denotes high probability that a point within that shaded region belongs to the red class, 
and blue the contrary.
Nature Electronics | VOL 4 | February 2021 | 151–161 | www.nature.com/natureelectronics
155

Articles
NatuRe EleCtROniCS
be robust to overfitting38. The trained model was tasked with the 
detection of arrhythmic beats in a previously unseen subject. The 
accuracy distribution over 100 training iterations is plotted in  
Fig. 5f, and the model obtains a median test accuracy of 91%, higher 
than that obtained by two software benchmark models. This high-
lights that, beyond being RRAM-compatible, Bayesian machine 
learning offers an alternative modelling method that appears well 
suited to the characteristics of edge learning tasks. The comparison 
between the total number of programming operations observed in 
our experiment and that required by RRAM-based backpropaga-
tion approaches applied to the benchmarks was repeated and, once 
again, our experimental approach achieved a very favourable pro-
gramming efficiency (Supplementary Figs. 7 and 8).
Calibrated on an array-level variability characterization, a behav-
ioural simulation of the experiment was developed (Methods) that 
accurately reproduces the experimental results (Supplementary Fig. 
10). Using this simulator, we show in Supplementary Fig. 11 that 
our scheme is robust to device variability levels with a large devia-
tion from measured values, suggesting its applicability to a broad 
range of technologies. The simulator was also used to demonstrate 
the extension of the approach to multi-class tasks using a Bayesian 
perceptron (Supplementary Fig. 12).
Reinforcement learning
We now demonstrate that the approach can be extended to rein-
forcement learning using the behavioural simulator. In contrast 
0.02
a
b
c
d
e
f
1.0
0
50
100
150
Row number
200
250
90
1.00
0.98
0.96
0.94
0.92
0.90
1.00
0.95
Test accuracy
0.90
0.85
0.80
Experimental Perceptron
DNN
Experimental
Perceptron
DNN
70
50
30
10
Combined accuracy
Accuracy
Count
0.8
0.6
Row model accuracy
Test accuracy
Row counter value
0.4
0.2
Probability density
0.01
0
1.00
10–1
2
Healthy
Arrhythm
1
0
0
0.5
Time (s)
FFT
10–2
10–3
0.04
Probability density
Probability density
0.02
0
0.04
0.02
0
–50
0
Parameter, g10,9 (µS)
Parameter, g9 (µS)
50
–50
0
50
0.95
Accuracy
LCS stuck
HCS stuck
0.90
Accuracy
Magnitude
Error probability
0.85
0.80
104
105
Number of cycles
106
107
–50
Parameter, g5 (µS)
Parameter, g8 (µS)
0
50
–50
0
50
0.02
Probability density
0.01
0
–60 –30
Differential conductance (µS)
0
30
60
g5
g8
Fig. 5 | Experimental results on the supervised classification tasks. a, Left: heatmap of the differential conductance pairs in the 256 × 16 array after a 
training experiment. Cells within the heatmap are coloured from blue to red, indicating the sign and magnitude of each conductance parameter. The row 
counter weighted distributions within columns five and eight, corresponding to two learned model parameters, are plotted in green and blue histograms, 
respectively, and fitted with kernel density estimations. b, Accuracy, evaluated on the dataset, of the conductance model (green) and the row counter 
value (blue) for each of the 256 rows. The first 32 rows, contained within a red-shaded rectangle, have been accepted during the burn-in period. Discarding 
these rows, the combined accuracy of the remaining rows on the test dataset is 97%, indicated by the horizontal dashed line. c, Boxplots showing the test 
accuracy distributions over 100 separate train/test iterations for the malignant tissue recognition task using the same train/test split for the experimental 
set-up (left, green) and software-based neural network benchmark models (centre and right, blue; labelled perceptron and DNN). The coloured boxes 
span the upper and lower quartiles of accuracy, while the upper and lower whiskers extend to the maximum and minimum accuracies obtained over the 
100 iterations. The median accuracy is indicated with a solid horizontal line. d, The experimental accuracy of the trained model after an increasing number 
of decades of endurance cycles. The permanent write error probabilities of devices stuck in the LCS and stuck in the HCS are also plotted on a secondary 
axis. Arrows have been annotated to indicate which curves correspond to which axes and grey horizontal dashed lines denote the lower and upper 
accuracies obtained over 100 training iterations using a fresh array. e, Depiction of the arrhythmic heartbeat detection experiment. Electrocardiograms 
(top left) recorded from the heart, potentially using an implanted cardioverter defibrillator42 (bottom left), are used to extract 10 features through a fast 
Fourier transform (labelled as FFT), which are then used as the input for a multi-layer Bayesian neural network (top right). The Bayesian neural network 
is trained to detect arrhythmic beats. Two of the resulting synaptic weight distributions after training are also plotted (bottom right). f, Boxplots showing 
the test accuracy distributions over 100 separate train/test iterations of the arrhythmic heartbeat detection task using the same train/test split for the 
experimental set-up (left, green) and software-based neural network benchmark models (centre and right, blue; labelled perceptron and DNN). The 
coloured boxes span the upper and lower quartiles of accuracy, while the upper and lower whiskers extend to the maximum and minimum accuracies 
obtained over the 100 iterations. The median accuracy is indicated with a solid horizontal line. Body and heart in e adapted from InjuryMap. Distributed 
under a Creative Commons licence CC BY 4.0.
Nature Electronics | VOL 4 | February 2021 | 151–161 | www.nature.com/natureelectronics
156

Articles
NatuRe EleCtROniCS
to supervised learning, reinforcement learning does not require a 
labelled dataset—an appealing prospect for edge learning systems. 
Instead, a model is tasked with determining the actions of an agent 
based on interaction with its environment43. The agent observes, 
at each time step, information from the environment (V) and also 
takes an action (a). Resulting from the actions taken by the agent, a 
scalar reward (r) is received. The objective in reinforcement learn-
ing is to realize a model that allows an agent to take actions that 
maximize future reward. Here, we apply RRAM-based MCMC to 
learn a posterior distribution in terms or reward44.
We address the cartpole control task45 (Supplementary Videos 1 
and 2), an important validation task in RRAM-based reinforcement 
learning20,46, in which an agent learns how to control a pole balanced 
on top of a cart by accelerating to the left or right, as a function of 
four observed environmental variables (Fig. 6a). To achieve this, we 
employ a two-neuron Bayesian perceptron, effectively two 512 × 4 
memory arrays. The output neuron with the largest response, as a 
function of the input features, dictates the action taken by the agent 
at each time step.
The training process is visualized by plotting the reward received 
when each row was accepted in Fig. 6b (see Supplementary Fig. 
13 for row counts). After training, the agent then uses the learned 
posterior approximation to select actions over 100 testing epi-
sodes, achieving a mean test reward of 484 out of 500 (Methods). 
This procedure was repeated 100 times and the distribution of 
mean test reward is plotted in Fig. 6c. To benchmark this result, a 
software-based Deep-Q network47 (DQN) was applied to the same 
task (Methods), with a number of synapses equal to the number 
of devices in our simulation. The median mean test reward of the 
DQN was only 420 and exhibited greater variability between train-
ing iterations than our model (Fig. 6c). Supplementary Fig. 6 shows 
a comparison with deeper models.
To assess the impact of device-to-device variability (Fig. 2c) on 
this task, the simulation was repeated without its consideration 
(Methods). The resulting test reward distribution (Fig. 6c) is seen to 
be largely unaffected, consistent with the supervised learning results 
(Supplementary Fig. 11). This result challenges the long-standing 
conception that device-to-device variability (Fig. 2c) is a disadvan-
tage in RRAM-based machine learning that requires mitigation. 
However, this should not come as a surprise—unlike gradient-based 
optimization, where device-to-device variations impede the descent 
down a gradient, MCMC sampling actively leverages such random-
ness as a means of exploring the posterior.
Finally, to evaluate the energy efficiency of a fully integrated 
RRAM-based MCMC sampling system, we performed the design 
and simulation of the different CMOS elements that compose it, 
using standard analogue and digital integrated circuit design tools. 
The methodology and results are detailed in Supplementary Note 
1, Supplementary Fig. 14 and Supplementary Table 1. To fully train 
the cartpole model, only 6.9 μJ would be required in the 130-nm 
technology used to design the test chip used throughout this Article 
(Fig. 3d). In a scaled 28-nm technology, this reduces to 3.6 μJ. By 
comparison, an optimized implementation of the MCMC sam-
pling algorithm on a modern workstation processor consumes on 
the order of 600 mJ when applied to the same task. Projecting these 
results to the supervised learning experiments, it is estimated that 
1.3 μJ and 4.7 μJ of energy, respectively, would be required to train 
the presented Bayesian logistic regression and neural network mod-
els in the 28-nm node.
Conclusion
We have demonstrated the potential of simultaneously harnessing 
resistive memories as physical random variables and as efficient 
dot-product engines via the development of in situ MCMC sampling 
algorithms. Our approach, which actively exploits cycle-to-cycle 
conductance variability, is resilient to device-to-device variability 
and extensive device aging (beyond the point where devices could 
be used as traditional memories). We have illustrated the potential 
of this approach in both supervised and reinforcement learning 
situations.
The appeal of RRAM-based MCMC is highlighted by two sets of 
our results. First, a reduced number of programming operations are 
required to train a full model with respect to RRAM-based back-
propagation approaches, and there is a reduction in the energy of 
a full RRAM-based MCMC system relative to conventional CMOS 
solutions (Supplementary Note 1). Second, when faced with data 
representative of the edge (noisy and multi-modal electrocardio-
grams in the arrhythmia detection task), the robustness of Bayesian 
500
All
variability
Cycling
variability
DQN
500
X
X
ω
ω
θ
θ
v
v
Combined test reward
Reward
400
300
Row reward (/500)
200
100
0
500
400
300
Test reward (/500)
200
100
0
400
300
200
Row number
100
0
a
b
c
Fig. 6 | Behavioural simulation results on the cartpole reinforcement learning task. a, Diagram of the cartpole task, in which an agent learns how to 
accelerate left or right to maintain a pole balanced on top of a cart within 15° of normal (the vertical dashed line). The environment is described by four 
features: X, the x-position of the cart; θ, the angle of the pole to vertical; ω, the angular velocity at the tip of the pole; ν, the velocity of the cart. These four 
features serve as input to the perceptron model (upper right), where the two output neurons determine whether the agent accelerates to the left or  
right. b, Reward obtained during a training episode when each of the conductance models was accepted into one of the 512 array rows (the maximum 
reward is 500). A burn-in period of 64 rows is denoted with the red-shaded rectangle. The mean reward obtained over 100 test episodes using the 
combination of the models accepted after the burn-in, equal to 484 out of a maximum score of 500, is denoted with a horizontal dashed black line.  
c, Boxplots showing the distribution of the mean test reward obtained during 100 testing episodes achieved in the cartpole task over 100 separate 
train/test iterations. Behavioural simulation considering both device-to-device and cycle-to-cycle variability (left, light green), behavioural simulation 
considering only cycle-to-cycle variability (centre, dark green) and a DQN benchmark model (right, blue). The coloured boxes span the upper and lower 
quartiles of mean reward, the upper and lower whiskers extend to the maximum and minimum mean rewards obtained, and the median mean reward is 
indicated with a solid horizontal line.
Nature Electronics | VOL 4 | February 2021 | 151–161 | www.nature.com/natureelectronics
157

Articles
NatuRe EleCtROniCS
machine learning to overfitting by incorporating uncertainty into 
learned parameters37,38 was found to be crucial in outperform-
ing the software-based deterministic benchmark neural networks 
trained through backpropagation; this illustrates that, beyond being 
compatible with the fundamental properties of resistive memory 
devices, RRAM-based Bayesian models are also particularly well 
suited to edge applications.
Our system could be used as the foundation (Supplementary 
Fig. 14 and Supplementary Note 1) for the design and fabrication 
of a standalone and fully integrated RRAM-based MCMC sampling 
chip, for applications outside the laboratory. One notable use case of 
RRAM-based MCMC, which builds on the promise of our arrhyth-
mia detection results, is its application to energy-constrained learn-
ing and adaptation in implantable medical systems—a potentially 
revolutionary domain that is currently out of reach with existing 
commercial approaches2. This prospect is also supported by the fact 
that Bayesian network topologies are already employed in some bio-
medical machine learning applications48.
Finally, the emerging class of ‘scalable’ MCMC algorithms49–51, 
which offer a means of extending RRAM-based MCMC to larger 
models and datasets, should be explored in future systems.
Methods
HfO2-based resistive-memory arrays and experimental set-up. Two versions of 
fabricated OxRAM memory arrays are used in the presentation of this Article. The 
first is a 4,096 (4k) device array (16 × 256 devices) of 1T1R structures. The second 
chip is a 16,384 (16k) device array (128 × 128 devices) of 1T1R structures. In each 
array, the OxRAM cell consists of a HfO2 thin film sandwiched in a TiN/HfO2/Ti/
TiN stack. The HfO2 and Ti layers are 5 nm thick and have a mesa structure that is 
300 nm in diameter. The OxRAM stack is integrated into the back-end-of-line of 
a commercial 130-nm CMOS process. In the 4k device array, the n-type selector 
transistors are 6.7 μm wide. In the 16k array, the n-type selector transistors are 
650 nm wide. Voltage pulses, generated off chip, can be applied across specific 
source (SL), bit (BL) and word lines (WL) which contact the OxRAM top 
electrodes, transistor sources and transistor gates, respectively. External control 
signals determine to what complement of SL, BL and WL the voltage pulses are 
applied by interfacing with CMOS circuits integrated with the arrays. Signals for 
the 4k device array are generated using the Keysight B1530 module and those for 
the 16k device array are generated by the RIFLE NplusT engineering test system. 
The RIFLE NplusT system can also run C++ programs that allow the system to act 
as a computer-in-the-loop with the 16k device array.
Before either chip can be used, it is necessary to form all the devices in the 
array. In the forming process, oxygen vacancies are introduced into the HfO2 
thin film through a voltage-induced dielectric breakdown. This is achieved by 
selecting devices in the array one at a time, in raster-scan fashion, and applying a 
voltage between the source and bit lines. At the same time, the current is limited 
to the order of microamperes by simultaneously applying an appropriate VWL 
(transistor gate) voltage. A forming operation consists of the following conditions: 
4k device array, VSL = 4 V, VBL = 0 V, VWL = 0.85 V; 16k device array, VSL = 4 V, 
VBL = 0 V, VWL = 1.3 V. After the devices have been formed, they are conditioned by 
cycling each device in the array between the LCS and the HCS 100 times. Unless 
otherwise specified, the standard RESET conditions used in the paper were as 
follows: 4k device array, VSL = 0 V, VBL = 2.5 V, VWL = 3 V; 16k device array, VSL = 0 V, 
VBL = 2.6 V, VWL = 4.0 V. Unless otherwise specified, the standard SET conditions 
used were as follows: 4k device array, VSL = 2 V, VBL = 0 V, VWL = 1.2 V; 16k device 
array, VSL = 2.0 V, VBL = 0 V, VWL = 1.6 V. The device conductances are determined 
by measuring the voltage drop over a known low-side shunt resistance connected 
in series with the selected SL in a read operation. Devices are read according to the 
following conditions: 4k device array, VSL = 0.1 V, VBL = 0 V, VWL = 4.8 V; 16k device 
array, VSL = 0.4 V, VBL = 0 V, VWL = 4.0 V. All off-chip generated voltage pulses for 
programming and reading have a pulse width of 1 μs.
Measurement of OxRAM HCS random variable properties. To characterize the 
properties of the HfO2 physical random variable, as plotted in Fig. 2a–c, the 4k 
device array chip was used. This allows use of a larger selector transistor, which 
offers a greater range of SET programming currents. To measure the data plotted 
in Fig. 2b, a 4k device array was formed, conditioned and then RESET/SET-cycled 
100 times over a range of nine word-line voltages (VWL), corresponding to the 
range of SET programming currents in Fig. 2b. Each device was read after each 
SET operation. Between each step in VWL, the devices were additionally RESET/
SET-cycled 100 times under standard programming conditions ensuring that, for 
each of the 100 cycles at different VWL, the initial conditions were the same. For the 
data plotted in Fig. 2a,c, a single device and all 4k devices in the 4k device array 
were respectively RESET/SET-cycled 500 times. The conductance was read after 
each SET operation. This conductance data were then processed and plotted using 
the Python libraries NumPy, SciPy, Seaborn and Matplotlib.
MCMC sampling experiments on the 16k device array. The 
computer-in-the-loop experiments (used to obtain the results in Figs. 4a–c and 
5a–c) made use of the 16k device array interfaced to the C++ programmable 
RIFLE NplusT system (Supplementary Fig. 1). The devices in the array, which 
physically exist as a 128 × 128 array of 1T1R structures, were remapped into a 
virtual address space that realizes the structure presented in Fig. 3a. This was 
achieved by allocating pairs of sequential banks of M devices (for an M-parameter 
model) corresponding to the g+ and g− conductance vectors to each of the N 
rows in Fig. 3a. A dot product was performed by reading the conductances of the 
devices composing g+ and g− and subtracting them in the computer-in-the-loop to 
arrive at g and then performing the dot product between V and g. Note that, in a 
future version of the system, by integrating appropriate circuits within the device 
array the dot product could be performed by simply applying the data points as 
read voltages and reading the output current as described in this Article.
Resistive-memory-based MCMC sampling begins by performing a RESET 
operation on each device in the array, rendering all devices in the LCS. Using the 
variable n to point to the row containing the current model, the algorithm begins 
with n = 0. The devices in row n are SET. Because we do not have strong a priori 
belief on the initial model parameters, each device is SET using the lowest available 
VWL (in this case 1.4 V), which corresponds to the lowest SET programming 
current (40 μA) (for a comparison of initialization strategies see Supplementary 
Fig. 15). As a result the standard deviation of the initial samples will be high 
(Fig. 2b), thereby capturing this uncertainty. The devices in the following row, 
n + 1, are then programmed with SET programming currents proportional to 
the conductances read from the corresponding devices in row n. This results in 
a proposed model, gp, being generated in row n + 1, in line with the proposal 
distribution offered by the cycle-to-cycle HCS conductance variability:
p gpjg


¼ N ISETðgÞ; σðgÞ
ð
Þ
ð1Þ
In doing this, a new conductance value is sampled for each device in row n + 
1 from a normal random variable with a median value corresponding to the same 
device in row n, offset by device-to-device variability (Fig. 2c) that is introduced 
when moving between successive rows.
The SET programming current in the proposal step is determined by the value 
of VWL used to program each device in row n + 1. To achieve this, a single look-up 
table is determined in an initial sweep step whereby the entire 16k device array 
is RESET/SET-cycled once per VWL value that will be used in the experiment. For 
each of these values of VWL, the median conductance read across the 16k device 
array is calculated and inserted in the corresponding entry in the table. Therefore, 
when programming, a device in the row containing the proposed model is required 
to read the conductance of the corresponding device in row n, and use the value 
of VWL with the closest corresponding conductance as the VWL used in the SET 
operation. In the experiments, the look-up table extended from 1.4 V to 1.8 V in 
discrete 20 mV steps, corresponding to SET programming currents in the range 
of 40–100 μA, and permitted median conductances in the range of 40–80 μS to be 
used (Supplementary Fig. 16). Programming the devices in row n + 1 implements 
the model proposal step depicted in Fig. 3c.
In Metropolis–Hastings MCMC sampling, after proposing a new model, it is 
necessary to make a decision on whether to accept and record the proposed model 
gp or reject and record, once again, the current model g. This decision is made 
based on the calculation of a quantity named the acceptance ratio a. Because the 
proposal density is normally distributed (equation (1)), and therefore symmetrical, 
it can be written as
a ¼
pðgpÞ
pðgÞ
pðtjgp; VÞ
pðtjg; VÞ
ð2Þ
This acceptance ratio is a number proportional to the product of the likelihood of 
a proposed model (p(t∣gp, V)) and a prior on the proposed model (p(gp)), divided 
by the product of the likelihood and prior of the current model. Given a dataset 
of D data points where A data points belong to the class the model is required to 
recognize (t = 1) and B other data points to the class that the model should not 
recognize (t = 0), the Bernoulli likelihood of a model is given by
p tjg; V
ð
Þ ¼
YA
a¼0 f Va;t¼1 g


´
YB
b¼0 1  f Vb;t¼0 g




ð3Þ
The function f(V ⋅ g) depends on the specific formulation of the model. The prior 
of a model is given by
p g
ð Þ ¼
1
σ
ﬃﬃﬃﬃﬃ
2π
p
exp  g  μ
ð
Þ2
2σ2


ð4Þ
where the constant σ corresponds to the prior belief that the posterior distribution 
is a multi-dimensional normal distribution with a standard deviation of σ in 
each dimension. In all examples in this Article, the value of μ was set to zero. 
Nature Electronics | VOL 4 | February 2021 | 151–161 | www.nature.com/natureelectronics
158

Articles
NatuRe EleCtROniCS
These quantities are calculated on the computer-in-the-loop in logarithmic 
scale, constituting a summation over D points. Because MCMC sampling 
methods work with small datasets, where overfitting can be avoided through the 
incorporation of uncertainty into parameter estimations, it would be possible to 
subsample the original D data points if the dataset were unreasonably large. To 
decide if the proposed model should be accepted or rejected, a is compared to a 
uniform random number between 0 and 1 (u), generated on the computer using 
the C++ standard random math package. If a is less than u, then gp is rejected. 
This is achieved by programming the devices in row n + 1 back into the LCS and 
incrementing the counter at row n (that is, Cn) by one. The counter is a variable 
in C++ on the computer, although, as is the case for all functionality of the 
computer-in-the-loop, this will be integrated as a circuit on future implementations 
of the system. The devices in row n + 1 are then SET once more under the same 
programming conditions, generating a new proposed model gp at row n + 1. 
This process repeats until a is found to be greater than u. When this is the case, 
gp is accepted, whereby the counter at row n + 1 is incremented by one and the 
model at row n + 1 becomes the new current model (n = n + 1). This new current 
model g is then used to propose a model, gp, at the next row in the array. The 
model stored at row n − 1 is then left preserved in the non-volatile conductance 
states of the resistive memory devices, weighted by the counter value Cn − 1. As 
this process repeats, and progresses down the rows of the memory array, the 
algorithm randomly walks around the posterior distribution, leaving information 
on its probability density imprinted into the non-volatile conductance states of 
the OxRAM devices and the row counter values. On arriving at the final row of 
the array, n = N − 1, the training process terminates, resulting in a physical array 
of resistive memory devices that contains an approximation of the posterior 
distribution that can then be used in inference.
Performing inference consists of computing the dot product between a new, 
previously unseen data point (Vnew) and the model recorded in each array row. 
The response of each row is then multiplied by the value in each row counter. The 
summed response of each row in the array is then divided by the sum of all row 
counter values. This results in a scalar value that has been inferred from the N 
weighted samples from the posterior distribution approximation:
P Tnew ¼ 1jV; t
ð
Þ ¼ 1
Tot
XN1
n¼β Cnf Vnew gn


ð5Þ
The summation considers only rows of an index greater than β, which determines 
the number of rows discarded to account for the burn-in period. The variable Tot is 
the sum of all row counter values recorded after the burn-in period.
Supervised learning experiments. The memory array used in the supervised 
learning experiments is configured as a Bayesian logistic regression model by using 
the row function block:
f ðV gÞ ¼
1
1 þ eSðVgÞ
ð6Þ
where S is a scaling parameter. This logistic function limits the response of the 
row dot product into a probability between 0 and 1. When configured as such, the 
likelihood of a conductance model is calculated as
p tjg; V
ð
Þ ¼
YA
a¼0
1
1 þ eSðVa;t¼1gÞ


´
YB
b¼0
1 
1
1 þ eSðVb;t¼0gÞ


ð7Þ
After training, inference can performed on a new data point Vnew, whereby it is 
assigned a probability of belonging to the class t = 1 by computing
PðTnew ¼ 1jV; tÞ ¼ 1
Tot
XN1
n¼β
Cn
1 þ eSðVnewgnÞ
ð8Þ
In the first supervised learning task, the random sampling library from NumPy 
was used to generate 50 samples from a two-dimensional normal distribution 
centred at the origin. Half of the points were assigned a class label of t = 1 and 
shifted up and to the left, while the other half were shifted down and to the right 
(by the same value) and labelled t = 0, thus providing an artificial linearly separable 
dataset of two classes for an illustrative demonstration of the system. For the 
second supervised learning task, the Wisconsin breast cancer dataset was used, 
which consists of 569 data points with class labels ‘malignant’ (t = 1) or ‘benign’  
(t = 0)41. The dataset was accessed through the Scikit-learn library and the random 
shuffle function from NumPy was used to sort the dataset into 369 training points 
and 200 test points, which were used in each of the 100 train/test iterations. 
By implementation of the Chi2 feature selection algorithm52, available through 
Scikit-learn, the number of features was reduced to 16, as this corresponded to the 
number of array columns used in the experiment. A further data pre-processing 
step was performed using the scale function from Scikit-learn to centre the dataset 
around the origin such that the model did not require an additional bias parameter. 
If this step was not performed, an extra column could be added to the array, which 
would then learn the distribution of the bias parameter. During training, the 
algorithm was configured to recognize data points corresponding to malignant 
tissue samples (t = 1). During the inference time, the 200 previously unseen data 
points from the test split were assigned a probability of being malignant using 
equation (8). Output probabilities greater than or equal to 0.5 corresponded to a 
prediction of the sample being malignant (t = 1), and probabilities of less than 0.5 
corresponded to a prediction of the sample being benign (t = 0). The reported test 
accuracy corresponds to the fraction of the 200 test data points that were correctly 
classified.
To force permanent write failures for the study impact of endurance cycling 
on RRAM-based MCMC sampling, C++ code was written whereby, after reading 
a new set of conductances from the memory array, the read bits were set with 
a probability to be either a stuck-in-LCS or a stuck-in-HCS value, according to 
the literature39. When determining what voltage to apply to the gates of the 1T1R 
structures in the subsequent row, the lowest available gate voltage was applied 
to a stuck-in-LCS bit and the maximum available gate voltage was applied for a 
stuck-in-HCS bit.
When performing training iterations after the successive decades of endurance 
cycling as plotted in Fig. 5d, the iteration of RRAM-based MCMC sampling 
was performed as described, without recalibration of the look-up table linking 
the read conductance value to the gate voltage applied to the 1T1R structure 
of the corresponding device in the subsequent row. In addition, because it was 
determined that arrays sizes in the range of 96 × 16 to 256 × 16 were able to 
obtain the same performance (Supplementary Fig. 5), a 4,096-device subset of the 
16,384-device array was subject to endurance cycling, allowing a fourfold reduction 
in the time required to perform the endurance experiment to the order of days. As 
such, the results obtained in Fig. 5d were obtained with a 128 × 16 array.
For the arrhythmic heartbeat detection task, we downloaded data from the 
MIT-BIH heart arrhythmia database42, which comprised half-hour dual-channel 
electrocardiogram recordings from 48 subjects. Single heartbeats were isolated 
from each recording into a 700-ms time series and centred on the R-wave peak of 
the beat. The FFT function from NumPy was then used to generate a frequency 
spectrum of each time series and the lowest five frequency components from each 
channel were used as the 10 features used to describe each heartbeat as a static 
data point. Each heartbeat was labelled as either a normal, healthy heartbeat or as 
a heartbeat exhibiting signs of arrhythmia. A subset of 250 data points were taken 
randomly from 47 of the subjects and then used to train the models. Then, to test 
the models, all of the data points from one, previously unseen, subject were used. 
The RRAM-based Bayesian neural network model, with a hidden-layer of nine 
sigmoid neurons, was trained in the same fashion as the RRAM-based logistic 
regression model. Because each sample requires 198 devices, and given the size 
of the experimental array, there was capacity for storing only 82 models in our 
experiment. To account for the burn-in period, the first 32 sampled models were 
discarded.
MCMC sampling behavioural simulator. A custom behavioural simulation of our 
experiment was developed in Python, implementing the presented Metropolis–
Hastings MCMC sampling algorithm. The proposal distributions were calibrated 
on data measured on the 4k device array. A normal distribution, using the random 
function suite from the NumPy library, was used to sample proposed models 
(gp) from current models (g). The standard deviation (s.d.) of the sample was 
determined based on the data plotted in Fig. 2b, where the median relationship was 
seen to follow the power law
s:d: ¼ a ´ ISET
b
ð9Þ
with constants a = 0.093A1 − b and b = 0.48. The current ISET is determined based on 
the conductances from the current model using the data in Fig. 2b, where
ISET ¼
g
d
 1=c
ð10Þ
with constants c = 0.78 and d = 0.19S/Ac (plotted in Fig. 2b). To incorporate 
device-to-device variability, the s.d. in c, fitted for individual devices in the 4k 
device array (Supplementary Fig. 17), was found to be equal to e = 0.096S/Ac. The 
likelihood and acceptance ratio calculations were performed in the log domain.
Reinforcement learning simulation. The Python library gym was used to simulate 
the cartpole environment. The cartpole environment provides four features to 
the behavioural simulator at each time step of the simulation. The behavioural 
simulator then specifies the actions to be taken by the agent in the environment 
at the next simulation time step. Two simulated 512 × 4 arrays were used. One 
array encoded the accelerate left action, while the other encoded the accelerate 
right action. The two arrays compete in a winner-take-all fashion to determine the 
actions taken by the agent. During training, the output of the array rows containing 
the two proposed models is used to determine the actions of the agent at each 
time step. Under application of a new observation from the environment V, the 
response
f ðV gÞ ¼ S V g
ð11Þ
is calculated, where S is a scalar constant. The two arrays are treated as if they 
are a single model. Rows of equivalent index in both arrays share a common row 
counter and are programmed and evaluated at the same time. The devices within 
Nature Electronics | VOL 4 | February 2021 | 151–161 | www.nature.com/natureelectronics
159

Articles
NatuRe EleCtROniCS
the zeroth row of both arrays are initially SET by sampling from a normal random 
variable with the lowest available conductance median (in this simulation, the 
conductance range extended from 50 μS to 200 μS). The initial model is evaluated 
during a training episode where the cumulative reward received during the 
episode is recorded. For each time step that the agent does not allow the pole to 
rotate 15° away from the perpendicular or does not move outside the bounds of 
the environment (both resulting in early termination of the episode), the agent 
receives a +1 reward. If the agent maintains the pole balanced for 500 time steps, 
the episode terminates, resulting in an episode in which the agent has received the 
maximum possible score of 500. Respective models are then generated at the first 
row of each array by sampling new models from normal random variables with 
medians equal to the conductances of the corresponding devices in the zeroth row, 
offset by device-to-device variability. The two proposed models determine the 
actions of the agent during the following training episode, and the agent accelerates 
to either the left or the right at each time step of the episode as a function of 
which array exhibited the greater response (equation (11)). As a function of the 
cumulative reward achieved during this training episode, a decision is made on 
whether to accept or reject the proposed model using the acceptance ratio
a ¼
pðgpÞ
pðgÞ
pðrjgp; V; aÞ
pðrjg; V; aÞ κ1
ð12Þ
Instead of using the ratio of likelihoods of the proposed and current models 
as in the supervised case, the ratio of episodic rewards for a model g, episodic 
observations V and episodic actions a is used: this is simply the scalar reward 
value obtained after an episode acting according to a proposed model gp, divided 
by the reward received when the current model g is accepted. This demonstrates 
a particular strength of applying MCMC sampling in a reinforcement learning 
setting, relative to supervised learning, because the calculation of the acceptance 
ratio can be achieved in a single calculation instead of an operation involving a 
sum over all data points in the log domain. The prior calculation is the same as 
in equation (4). The acceptance ratio is then multiplied by a constant κ−1, which 
acts as a hyper-parameter that determines the extent of exploration from higher to 
lower reward regions on the posterior. If the acceptance ratio is less than a uniform 
random number generated between 0 and 1, then the proposed model at the first 
row is rejected and the row counter, C0, is incremented by one. A new model is 
then proposed at the first row. If this new model achieves a cumulative reward 
during the next training episode, (p(r∣gp, V, a)), such that the acceptance ratio is 
now greater than a uniform random number, the two models within the first rows 
of both arrays are accepted and then become the current models. The reward that 
was obtained when these current models were accepted is recorded and thereafter 
used as p(r∣g, V, a) in the calculation of the acceptance ratio. After training has 
been completed upon the algorithm reaching the final array row, actions are 
determined during 100 testing episodes by calculating
Pðanew ¼ 1jV; rÞ ¼ 1
Tot
XN1
n¼β CnðVnew gnÞ
ð13Þ
for each array at each simulation time step. The summation considers only 
rows greater than index β, which determines the number of rows discarded to 
account for the burn-in period. The variable Tot is the sum of all row counter 
values recorded after the burn-in period. The array with the largest response at 
each time step determines the action taken during inference in a winner-take-all 
fashion. It should be noted that, although we have used the notation p(r∣g, V, a) for 
consistency with the rest of this Article, this quantity is not a probability, but is in 
fact a reward.
Neural network benchmark models. To benchmark the performance of 
RRAM-based MCMC sampling against a state-of-the-art machine learning 
approach, two neural network models were implemented using the TensorFlow 
Python library and applied to the same tasks. Both of these models were composed 
of a total number of synapses equal to the number of differential conductance 
pairs in the memory arrays (4,096 in both cases). Both models were three-layer 
feed-forward neural networks using 32-bit floating-point precision synaptic weights. 
The hidden layer of each model was sized such that the number of synaptic weights 
in the network was equal to 4,096. The size of the first layer is consistent with the 
number of input features. In the supervised neural network, the hidden and output 
units were logistic functions, as this is the function used in our logistic regression 
model. The model was optimized by minimizing the categorical cross-entropy in 
the training dataset over 100 training epochs with the adaptive moment estimation 
(Adam) optimization algorithm. In the reinforcement learning model, the hidden 
and output units were non-rectifying linear units, because this corresponded to 
the row function block used in our reinforcement learning model. The parameters 
of the models were optimized by minimizing the mean-squared loss using the 
experience replay technique47, also using the Adam optimization algorithm.
Data availability
The Wisconsin breast cancer dataset41, the MIT-BIH ECG dataset42 and the 
reinforcement learning simulation environment are publicly available. All other 
measured data are freely available upon request.
Code availability
All software programs used in the presentation of the Article are freely available 
upon request.
Received: 24 April 2020; Accepted: 30 November 2020;  
Published online: 18 January 2021
References
	1.	 Shi, W., Cao, J., Zhang, Q., Li, Y. & Xu, L. Edge computing: vision and 
challenges. IEEE Internet Things J. 3, 637–646 (2016).
	2.	 Edge AI Chipsets: Technology Outlook and Use Cases. Technical Report (ABI 
Research, 2019).
	3.	 von Neumann, J. First draft of a report on the EDVAC. IEEE Ann. Hist. 
Comput. 15, 27–75 (1993).
	4.	 LeCun, Y., Bengio, Y. & Hinton, G. Deep learning. Nature 521, 436–444 (2015).
	5.	 Rumelhart, D. E., Hinton, G. E. & Williams, R. J. Learning representations by 
back-propagating errors. Nature 323, 533–536 (1986).
	6.	 Strubell, E., Ganesh, A. & Mccallum, A. Energy and policy considerations for 
deep learning in NLP. In Proc. 57th Annual Meeting of the Association for 
Computational Linguistics (ACL) 3645–3650 (ACL, 2019).
	7.	 Li, D., Chen, X., Becchi, M. & Zong, Z. Evaluating the energy efficiency of 
deep convolutional neural networks on CPUs and GPUs. In 2016 IEEE 
International Conferences on Big Data and Cloud Computing (BDCloud), 
Social Computing and Networking (SocialCom), Sustainable Computing and 
Communications (SustainCom) (BDCloud-SocialCom-SustainCom) 477–484 
(IEEE, 2016).
	8.	 Chua, L. Memristor—the missing circuit element. IEEE Trans. Circuit Theory 
18, 507–519 (1971).
	9.	 Prezioso, M. et al. Training and operation of an integrated neuromorphic 
network based on metal-oxide memristors. Nature 521, 61–64 (2014).
	10.	Wong, H. P. et al. Phase change memory. Proc. IEEE 98, 2201–2227 (2010).
	11.	Chappert, C., Fert, A. & Dau, F. The emergence of spin electronics in data 
storage. Nat. Mater. 6, 813–823 (2007).
	12.	Liu, Q. et al. Resistive switching: real-time observation on dynamic growth/
dissolution of conductive filaments in oxide-electrolyte-based ReRAM. Adv. 
Mater. 24, 1774–1774 (2012).
	13.	Beck, A., Bednorz, J. G., Gerber, C., Rossel, C. & Widmer, D. Reproducible 
switching effect in thin oxide films for memory applications. Appl. Phys. Lett. 
77, 139–141 (2000).
	14.	Garbin, D. et al. HfO2-based OxRAM devices as synapses for convolutional 
neural networks. IEEE Trans. Electron Dev. 62, 2494–2501 (2015).
	15.	Gokmen, T., Onen, M. & Haensch, W. Training deep convolutional neural 
networks with resistive cross-point devices. Front. Neurosci. 11, 538 (2017).
	16.	Boybat, I. et al. Neuromorphic computing with multi-memristive synapses. 
Nat. Commun. 9, 2514 (2017).
	17.	Ambrogio, S. et al. Equivalent-accuracy accelerated neural-network training 
using analogue memory. Nature 558, 60–67 (2018).
	18.	Nandakumar, S. R. et al. Mixed-precision architecture based on 
computational memory for training deep neural networks. In Proc. 2018 IEEE 
International Symposium on Circuits and Systems (ISCAS) 1–5 (IEEE, 2018).
	19.	Li, C. et al. Efficient and self-adaptive in-situ learning in multilayer 
memristor neural networks. Nat. Commun. 9, 2385 (2018).
	20.	Wang, Z. et al. Reinforcement learning with analogue memristor arrays. Nat. 
Electron. 2, 115–124 (2019).
	21.	Yao, P. et al. Fully hardware-implemented memristor convolutional neural 
network. Nature 577, 641–646 (2020).
	22.	Burr, G. W. et al. Experimental demonstration and tolerancing of a large-scale 
neural network (165,000 synapses) using phase-change memory as the 
synaptic weight element. IEEE Trans. Electron Dev. 62, 3498–3507 (2015).
	23.	Sebastian, A., Krebs, D., Gallo, M. L., Pozidis, H. & Eleftheriou, E. A 
collective relaxation model for resistance drift in phase change memory cells. 
In Proc. 2015 IEEE International Reliability Physics Symposium MY.5.1–MY.5.6 
(IEEE, 2015).
	24.	Ambrogio, S. et al. Statistical fluctuations in HfOx resistive-switching 
memory: Part 1—set/reset variability. IEEE Trans. Electron Dev. 61, 
2912–2919 (2014).
	25.	Sidler, S. et al. Large-scale neural networks implemented with non-volatile 
memory as the synaptic weight element: impact of conductance response. In 
Proc. 2016 46th European Solid-State Device Research Conference (ESSDERC) 
440–443 (IEEE, 2016).
	26.	Agarwal, S. et al. Resistive memory device requirements for a neural 
algorithm accelerator. In Proc. 2016 International Joint Conference on Neural 
Networks (IJCNN) 929–938 (IEEE, 2016).
	27.	Querlioz, D., Bichler, O., Dollfus, P. & Gamrat, C. Immunity to device 
variations in a spiking neural network with memristive nanodevices. IEEE 
Trans. Nanotechnol. 12, 288–295 (2013).
	28.	Serb, A. et al. Unsupervised learning in probabilistic neural networks with 
multi-state metal–oxide memristive synapses. Nat. Commun. 7, 12611 (2016).
Nature Electronics | VOL 4 | February 2021 | 151–161 | www.nature.com/natureelectronics
160

Articles
NatuRe EleCtROniCS
	29.	Dalgaty, T. et al. Hybrid neuromorphic circuits exploiting non-conventional 
properties of RRAM for massively parallel local plasticity mechanisms. APL 
Mater. 7, 081125 (2019).
	30.	Balatti, S., Ambrogio, S., Wang, Z. & Ielmini, D. True random number 
generation by variability of resistive switching in oxide-based devices. IEEE J. 
Emerg. Select. Top. Circuits Syst. 5, 214–221 (2015).
	31.	Vodenicarevic, D. et al. Low-energy truly random number generation with 
superparamagnetic tunnel junctions for unconventional computing. Phys. Rev. 
Appl. 8, 054045 (2017).
	32.	Faria, R., Camsari, K. Y. & Datta, S. Implementing Bayesian networks with 
embedded stochastic MRAM. AIP Adv. 8, 045101 (2018).
	33.	Mizrahi, A. et al. Neural-like computing with populations of 
superparamagnetic basis functions. Nat. Commun. 9, 1533 (2018).
	34.	Camsari, K. Y., Faria, R., Sutton, B. M. & Datta, S. Stochastic p-bits for 
invertible logic. Phys. Rev. X 7, 031014 (2017).
	35.	Borders, W. A. et al. Integer factorization using stochastic magnetic tunnel 
junctions. Nature 573, 390–393 (2019).
	36.	Hastings, W. K. Monte Carlo sampling methods using Markov chains and 
their applications. Biometrika 57, 97–109 (1970).
	37.	Ghahramani, Z. Probabilistic machine learning and artificial intelligence. 
Nature 521, 452–459 (2015).
	38.	Neal, R. M. Bayesian Learning for Neural Networks Vol. 118 (Springer Science 
& Business Media, 2012).
	39.	Grossi, A. et al. Resistive RAM endurance: array-level characterization and 
correction techniques targeting deep learning applications. IEEE Trans. 
Electron Dev. 66, 1281–1288 (2019).
	40.	Ielmini, D. Modeling the universal set/reset characteristics of bipolar RRAM 
by field- and temperature-driven filament growth. IEEE Trans. Electron Dev. 
58, 4309–4317 (2011).
	41.	Wolberg, W. H. & Mangasarian, O. L. Multisurface method of pattern 
separation for medical diagnosis applied to breast cytology. Proc. Natl Acad. 
Sci. USA 87, 9193–9196 (1990).
	42.	Moody, G. B. & Mark, R. G. The impact of the MIT-BIH arrhythmia 
database. IEEE Eng. Med. Biol. Mag. 20, 45–50 (2001).
	43.	Sutton, R. S. & Barto, A. G. Introduction to Reinforcement Learning (MIT 
Press, 1998).
	44.	Hoffman, M., Doucet, A., Freitas, N. D. & Jasra, A. Trans-dimensional 
MCMC for Bayesian policy learning. In Proc. 20th International Conference 
on Neural Information Processing Systems, NIPS’07 665–672 (Curran 
Associates, 2007).
	45.	Barto, A. G., Sutton, R. S. & Anderson, C. W. Neuronlike adaptive elements 
that can solve difficult learning control problems. IEEE Trans. Syst. Man 
Cybern. SMC-13, 834–846 (1983).
	46.	Berdan, R. et al. In-memory reinforcement learning with 
moderately-stochastic conductance switching of ferroelectric tunnel junctions. 
In Proc. 2019 Symposium on VLSI Technology T22–T23 (IEEE, 2019).
	47.	Mnih, V. et al. Human-level control through deep reinforcement learning. 
Nature 518, 529–533 (2015).
	48.	Pourret, O., Naïm, P. & Marcot, B. Bayesian Networks: A Practical Guide to 
Applications (Wiley, 2008).
	49.	Maclaurin, D. & Adams, R. P. Firefly Monte Carlo: exact MCMC with subsets 
of data. In Proc. Thirtieth Conference on Uncertainty in Artificial Intelligence, 
UAI’14 543–552 (AUAI Press, 2014).
	50.	Korattikara, A., Chen, Y. & Welling, M. Austerity in MCMC land: cutting the 
Metropolis–Hastings budget. In Proc. 31st International Conference on 
Machine Learning 181–189 (PMLR, 2014).
	51.	Hoffman, M. D. & Gelman, A. The no-U-turn sampler: adaptively setting path 
lengths in Hamiltonian Monte Carlo. J. Mach. Learn. Res. 15, 1593–1623 (2014).
	52.	Liu, H. & Setiono, R. Chi2: feature selection and discretization of numeric 
attributes. In Proc. 7th IEEE International Conference on Tools with Artificial 
Intelligence 388–391 (IEEE, 1995).
Acknowledgements
We acknowledge funding support from the French ANR via Carnot funding as well as 
the H2020 MeM-Scales project (871371) and the European Research Council (grant 
NANOINFER, no. 715872). In addition, we thank E. Esmanhotto, J. Sandrini and  
C. Cagli (CEA-Leti) for help with the measurement set-up, J. F. Nodin (CEA-Leti) 
for providing the images in Fig. 3d and to S. Mitra (Stanford University), M. Payvand 
(ETH Zurich), A. Valentian, M. Solinas-Angel, E. Nowak (CEA-Leti), J. Diard (CNRS, 
Université Grenoble Alpes), P. Bessiére and J. Droulez (CNRS, Sorbonne Université), 
J. Grollier (CNRS, Thales) and J.-M. Portal (Aix-Marseille Université) for discussing 
various aspects of the Article.
Author contributions
T.D. developed the concept of RRAM-based MCMC sampling. N.C. built the 
computer-in-the-loop test set-up with the resistive memory array. T.D. and N.C. 
performed the computer-in-the-loop experiments with the resistive memory array. T.D. 
implemented the behavioural simulator, performed measurements on the array, which 
were used to calibrate the simulation and performed the benchmarking. K.-E.H., C.T. 
and D.Q. performed the design and energy analysis of the full system implementation. 
T.D., D.Q. and E.V. developed ideas and wrote the Article together.
Competing interests
The authors declare no competing interests.
Additional information
Supplementary information is available for this paper at https://doi.org/10.1038/
s41928-020-00523-3.
Correspondence and requests for materials should be addressed to T.D., D.Q. or E.V.
Reprints and permissions information is available at www.nature.com/reprints.
Publisher’s note Springer Nature remains neutral with regard to jurisdictional claims in 
published maps and institutional affiliations.
© The Author(s), under exclusive licence to Springer Nature Limited 2021
Nature Electronics | VOL 4 | February 2021 | 151–161 | www.nature.com/natureelectronics
161

