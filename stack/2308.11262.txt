Superdeterminism Without Conspiracy
Tim Palmer
Department of Physics, University of Oxford, UK
August 23, 2023
Abstract
Superdeterminism - where the Measurement-Independence assumption in Bell’s Theorem
is violated - is typically treated with derision as it appears to imply contrived conspiratorial
correlations between properties λ of particles being measured, and nominally accurate mea-
surement settings x and y. Based on an analysis of Pearlean interventions needed to determine
whether x and y are free variables, we show that whilst conspiracy implies superdetermin-
ism, superdeterminism does not imply conspiracy. In conspiratorial superdeterminism these
interventions are consistent with physical theory; in non-conspiratorial superdeterminism they
are inconsistent.
A non-conspiratorial locally-causal superdeterministic model is developed,
based in part on the generic properties of chaotic attractors and in part on an arbitrarily fine
discretisation of complex Hilbert Space. Here the required interventions are inconsistent with
rational-number constraints on exact measurement settings X and Y . In this model, hidden
variables λ are defined as the information, over and above the freely chosen determinants of x
and y, which determine X and Y . These rationality constraints limit the freedom to vary x
and y keeping λ fixed. These constraints disappear with any coarse-graining of λ and hence X.
We show how quantum mechanics might be ‘gloriously explained and derived’ as the singular
continuum limit of a superdeterministic discretisation of Hilbert Space. We argue that the real
message behind Bell’s Theorem is the need to develop more holistic theories of fundamental
physics - notably gravitational physics - some ideas for moving in this direction are discussed.
1
Introduction
A deterministic hidden-variable model of physical theory is said to be superdeterministic if the
so-called Measurement Independence assumption (sometimes referred to as the Statistical Indepen-
dence assumption or the λ-independence assumption),
ρ(λ|xy) = ρ(λ)
(1)
is violated [16] [36] [12] [19] [39]. Here ρ is a probability density on a set of hidden variables λ,
and x and y ∈{0, 1} denote experimentally chosen measurement settings - for concreteness, we
suppose these are nominally accurate polariser orientations. Without (1), it is impossible to show
that model satisfies the CHSH version of Bell’s inequality
|C(x = 0, y = 0) −C(x = 0, y = 1) + C(x = 1, y = 0) + C(x = 1, y = 1)| ≤2
(2)
where C denotes a correlation on Bell-experiment measurement outcomes over an ensemble of
particle pairs prepared in the singlet state.
1
arXiv:2308.11262v1  [quant-ph]  22 Aug 2023

The argument that models that violate (1) are scientifically unacceptable, originates in a paper
by Shimony, Horne and Clauser, written in response to Bell’s paper on local beables [6]. Shimony
et al write:
In any scientific experiment in which two or more variables are supposed to be randomly
selected, one can always conjecture that some factor in the overlap of the backwards
light cones has controlled the presumably random choices. But, we maintain, skepticism
of this sort will essentially dismiss all results of scientific experimentation. Unless we
proceed under the assumption that hidden conspiracies of this sort do not occur, we
have abandoned in advance the whole enterprise of discovering the laws of nature by
experimentation.
The drug trial is often used to illustrate the contrived nature of such a conspiracy. For example
[15]:
. . . if you are performing a drug versus placebo clinical trial, then you have to select
some group of patients to get the drug and some group of patients to get the placebo.
The conclusions drawn from the study will necessarily depend on the assumption that
the method of selection is independent of whatever characteristics those patients might
have that might influence how they react to the drug.
Related to this, superdeterminism is often described as requiring exquisitely (and hence unrealis-
tically) finely tuned initial conditions [3], or as negating experimenter freedom [42]. A number of
quantum foundations experts (e.g. [25] [41] [2] [1]) use one or more of these arguments to dismiss
superdeterminism in derisive terms.
A new twist was added by Aaronson [1] who concluded his excoriating critique of superdeter-
minism with a challenge:
Here’s my challenge to the superdeterminists: when, in 400 years from Galileo to the
present, has such a gambit ever worked? Maxwell’s equations were a clue to special rel-
ativity. The Hamiltonian and Lagrangian formulations of classical mechanics were clues
to quantum mechanics. When has a great theory in physics ever been grudgingly ac-
commodated by its successor theory in a horrifyingly ad-hoc way, rather than gloriously
explained and derived?
It would seem that developing superdetermistic models is a hopeless cause. However, the pur-
pose of this paper is to rebuff all these criticisms and indeed suggest that violating (1) is in fact the
only sensible way to understand the experimental violation of Bell inequalities. Importantly, we
show that whilst conspiracy would imply a violation of (1), the converse is not true. In Section 2,
we define the difference between a conspiratorial and a non-conspiratorial violation of (1) in terms
of the concept of interventions, used in causal inference modelling [33]. Motivated by this, and
the unshieldable chaotic effects of gravity as described in Section 3, two related non-conspiratorial
superdeterministic models are described in Section 4, one based on the invariant set postulate [28]
one based on a discretisation of complex Hilbert Space [30]. The two are in fact related (and are
therefore aspects of the same model) through the homeomorphism between fractals and the p-adic
integers.
In Section 5 it is shown how this model violates (1) non-conspiratorially, and indeed
violates (2) in exactly the same way as does quantum mechanics. In Section 6 we show that the
superdeterministic model is locally causal. Addressing Aaronson’s challenge in Section 7, we show
2

how quantum mechanics can be considered the singular continuum limit of the discretised superde-
terministic model. Fine tuning and free will are discussed in Section 8. A possible experimental
test of the supderdeterministic model is discussed in Section 9.
Before embarking on this venture, one may ask answer the question: why bother? After all,
quantum mechanics is an extremely well tested theory, and has never been found wanting. Why
not just accept that quantum theory violates the concept of local realism - whatever that means -
and get on with it? The author’s principal motivation for pursuing theories of physics which violate
(1) lies in the possibility of finding a theory of quantum physics that is not inconsistent with the
locally causal nonlinear geometric determinism of general relativity theory. As discussed in Section
10, results from this paper suggest that instead of seeking a quantum theory of gravity (‘quantum
gravity’) we should be seeking a holistic superdeterministic gravitational theory of the quantum,
from which the Euclidean geometry of space-time is emergent as a coarse-grained approximation
to the p-adic geometry of state space. This, the author believes, is the real message behind the
experimental violation of Bell inequalities.
2
Conspiratorial and Non-conspiratorial Interventions
There is no doubt that conspiratorial violations of Bell inequalities, of the type mentioned in the
Introduction, imply a violation of (1). Here we are concerned with the converse question: does
a violation of (1) imply the existence of a conspiratorial hidden variable theory? In preparing to
answer this question, we quote from Bell’s response ‘Free Variables and Local Causality’ [6] (FVLC)
to Shimony et al [6]. In FVLC, Bell writes:
I would insist here on the distinction between analyzing various physical theories, on
the one hand, and philosophising about the unique real world on the other hand. In
this matter of causality it is a great inconvenience that the real world is given to us once
only. We cannot know what would have happened if something had been different. We
cannot repeat an experiment changing just one variable; the hands of the clock will have
moved and the moons of Jupiter. Physical theories are more amenable in this respect.
We can calculate the consequences of changing free elements in a theory, be they only
initial conditions, and so can explore the causal structure of the theory. I insist that B
[Bell’s paper on the theory of local beables [6]] is primarily an analysis of certain kinds
of physical theory.
Why is Bell writing about ‘changing free elements in a theory’, i.e. considering hypothetical worlds
where these elements have been changed? To understand the significance of this quote, consider the
thought experiment devised by Bell in FVLC, where, by design, human free will plays no explicit
role. We base the analysis in this paper around this thought experiment. Bell supposes x and y
are determined by the outputs of two pseudo-random number generators (PRNGs). These outputs
are sensitive to the parity Px and Py of the millionth digits of the PRNG inputs. Bell now makes
what he calls a ‘reasonable’ assumption:
But this peculiar piece of information [whether the parity of the millionth digit is odd
or even] is unlikely to be the vital piece for any distinctively different purpose, i.e., it is
otherwise rather useless . . . In this sense the output of such a [PRNG] device is indeed
a sufficiently free variable for the purpose at hand.
3

If the output was not a free variable then it would not be possible to change Px or Py keeping
distinctively different systems unaffected. In the language of Pearl’s causal inference theory, of the
output was not a free variable, there would exist small so-called interventions to the world which by
design changed Px or Py, and by consequence had a vital impact on a distinctly different system.
The single most important part of this paper is to draw attention to two possible ways this might
happen. The first is the conventional way where the effect of the intervention propagates causally
in space-time, systematically and significantly influencing these distinct systems. This is the type
of causal effect that, were it to occur, would lead to an unacceptable conspiratorial violation of (1).
However, there is a second possibility. It could be that the hypothetical state of the universe
where Px or Py was perturbed but other distinctly different elements of the universe were kept fixed,
was inconsistent with the laws of physics. In that case, the intervention would be inconsistent with
the laws of physics: if such an intervention was hypothetically applied to a localised region of
the universe, the vital ontological status of the whole universe, including distant galaxies, would
instantaneously change. Of course, we cannot perform an actual experiment to test directly this
potential inconsistency: in changing the millionth digit, the hands of the clock and the moons of
Jupiter will have moved. Hence addressing the question of whether the PRNG output is a free
variable requires studying the mathematical properties of physical theory. This is Bell’s point in
the first quote.
Based on this discussion, we can define the difference between a conspiratorial and a non-
conspiratorial violation of (1). Suppose for the sake of argument that
ρ(λ|xy) ̸= ρ(λ|x′y);
x′ = 1 −x
(3)
A conspiratorial interpretation of (3) would posit some bizarre physical process whereby the parti-
cles’ hidden variables systematically influenced the measurement settings or vice versa. That is to
say, we imagine an intervention in x leading causally to a change in λ or vice versa. By contrast,
a non-conspiratorial interpretation of (3) would posit that an intervention in x, keeping λ and y
fixed, leads to a state of the world which is inconsistent with physical theory. Clearly, this is not an
intervention in space-time at all. It is merely a hypothetical state-space perturbation which takes
a point in the state space of the world (labelled by the triple (λ, x, y)), consistent with physical
theory and hence with ρ(λ|xy) ̸= 0, to a state (λ, x,′ y) which is inconsistent with physical theory
and hence has ρ(λ|x′y) = 0. In this sense, a non-conspiratorial violation of (3) implies that physical
theory does not have the property of counterfactual definiteness.
However, one needs to be careful to not throw the baby out with the bathwater. Counterfactual
reasoning is pervasive in physics.
Indeed, it is central to the scientific method [24].
The fact
that we can express laws of physics mathematically give us the power to estimate what would
have happened had something been different. Such estimates can lead to predictions. If we have
accurate representations of the laws of physics, then the predictions will be verified by experiment.
We do not want to give up counterfactual reasoning in our search for new theories of physics.
We address this concern by noting that output from experiment and physical theory (particularly
when the complexities of the real world are accounted for) involves some inherent coarse-graining.
Experiments have some nominal accuracy and output from a computational model is typically
truncated to a fixed number of significant digits. We can represent this notion of nominal accuracy
by integrating exact output of physical theory over small volumes Vϵ > 0 in state space, where
Vϵ →0 smoothly as ϵ →0. We then insist that counterfactual definiteness holds generically in
our non-conspiratorial superdeterministic physical theory when all variables are coarse grained over
volumes Vϵ, for any ϵ > 0. The model based on discretised Hilbert Space, described in Section 4
4

has this property. This is why we do not expect to see non-conspiratorial superdeterminism either
in classical theory, or directly from experimentation (we comment on possible indirect experimental
tests of non-conspiratorial superdeterminism in Section 9).
In Section 3 we argue that a gravitational theory could have the property that a perturbation,
small enough to consistently change only the parity of the millionth digit here on Earth, will have a
chaotic (and hence unsystematic) impact on distinctly different systems, say in the distant universe.
In Section 4 we discuss the type of model that could have the property that such a gravitational
perturbation, if it did not chaotically influence such distant parts of the universe, would lead to a
perturbed state of the universe that was inconsistent with physical theory.
These matters are subtle, and it seems Bell appreciated this. Instead of derisively rejecting
theories where (1) is violated he concludes FVLC with the words:
Of course it might be that these reasonable ideas about physical randomisers are just
wrong - for the purposes at hand.
Indeed, in his last paper ‘La Nouvelle Cuisine’, Bell writes:
An essential element in the reasoning here is that [polariser settings] are free vari-
ables....
Perhaps such a theory could be both locally causal and in agreement with
quantum mechanical predictions. However, I do not expect to see a serious theory of
this kind. I would expect a serious theory to permit ‘deterministic chaos’ or ‘pseudo-
randomness.....But I do not have a theorem about that.
The last sentence is insightful, because, as we discuss, there is no such theorem. Indeed the reverse:
here we develop a serious non-classical theory based on the premise that the universe is a chaotic
dynamical system evolving on a fractal invariant set, where measurement settings are not free
variables. As we will show, such a theory can be in agreement with quantum mechanical predictions
and locally causal. Importantly, the theory is not conspiratorial.
3
The Andromedan Butterfly Effect
Can the flap of a butterfly’s wings in the Brazilian jungle (or a change to the millionth digit of the
input to a PRNG) influence the states of distant distinct systems (e.g. the weather on a planet in
Andromeda) or vice versa?
Here we repeat a calculation first reported by Michael Berry [7] and further analysed in [37].
Consider molecules in the Andromedan atmosphere as hard spheres of radius R with mean free
distance l between collisions. We wish to estimate the uncertainty ∆θM in the angle of the Mth
collision of one of the spheres with other spheres, due to some very small uncertain external force.
It is easily shown that ∆θM grows as
∆θM ≈( l
R)M∆θ1
(4)
With l ≈10−7m and R ≈10−10 m, say, l/R ≈103. With l/R > 1, we have the potential for chaotic
exponential growth of uncertainty in the direction of the sphere.
After how many collisions is the position of a molecule in the Andromedan atmosphere sensitive
to the gravitational effect of the uncertain flap of a butterfly’s wing in Brazil? Let r denote the
distance between Earth and Andromeda. The flap of a butterfly’s wing through a distance ∆r
5

will change the gravitational force on our target molecule by an amount ∆F = ∂F/∂r ∆r =
(Gmmolmwing/r3) ∆r. Uncertainty in the flap of a terrestrial butterfly’s wing will therefore induce
an uncertainty in the acceleration of an Andromedan molecule by an amount
∆a = 2Gmwing
r3
∆r
(5)
If τ denotes the mean time between molecular collisions, there is an uncertainty in the direction
of the molecule ∆θ1 ≈τ 2∆a/R. Plugging in mwing = 10−5 kg, ∆r = 10−2m, τ = 10−9s and
r = 1022m, gives ∆θ1 = 10−90. How large is M before ∆θM ≈1? From the above, 103M ≈1090.
Hence after about 30 collisions the direction the direction of travel of the Andromedan molecule
has been rendered completely uncertain by the Brazilian butterfly. Indeed one can go further: the
direction of the Andromedan molecule is rendered completely uncertain by the position of a single
electron at the edge of the observable universe after about only 40 collisions!
Of course uncertainties in flaps of butterflies wings’ (or their equivalents) in Andromeda will
have a similar impact on processes here on Earth. Nowhere above did the mass of the molecule
enter the calculation. The same calculation could just as well apply to the measurement process in
quantum physics - where a particle (a small sphere) interacts with atoms in some measuring device.
This is the first step in our argument that (??) could be violated because the universe should
be considered a rather holistic chaotic system. However, by itself, this argument doesn’t imply
that the parity of the millionth digit, or the flap of a butterfly’s wings in Brazil, is a vital piece
of information for determining distinctly different systems like Andromedan weather. For that we
need more.
4
A Superdeterministic Model
4.1
Nominal vs Exact Measurement Settings and Hidden Variables
We build on Bell’s thought experiment whereby polariser orientations are determined by the parities
Px and Py in Alice and Bob’s PRNGs (supposing there is no particular reason why these would be
odd or even). Manifestly, Px and Py only determines the polariser orientations to some nominal
accuracy. That is, x, y ∈{0, 1} determine small neighbourhoods of the 2-sphere of orientations,
referred to as ϵ disks. None of the results below depend on the magnitude of ϵ as long as ϵ > 0 (as
discussed in Section 7, the limit ϵ = 0 is singular). We will assume - consistent with our search for
an underlying deterministic theory - that when measurements are made on particular particles, the
measurement outcomes ±1 are associated with some exact, albeit unknown, polariser orientations X
and Y. Here, X and Y denote unit vectors in physical 3-space from the centre of a unit ball, to the
surface of the 2-sphere of orientations. The corresponding precise points on the 2-sphere to which
the vectors point, are written as X and Y . The nominal directions x and y refer to unit vectors
pointing to the centroids of the ϵ disks. In the discussion below, we assume that the probabilistic
nature of the quantum measurement problem arises because the measurement outcome is typically
sensitive to the exact measurement settings within an ϵ disk (c.f. fractally intertwined basins of
attraction [27]). Hence, any given nominal setting is consistent with an ensemble of possible exact
settings. The ultimate origin of quantum uncertainty is plausibly the gravitational Andromedan
Butterfly Effect as described above.
With this in mind, in the model described below, λ describes all of the variables which, over
and above Px and Py, determine the exact measurement settings X and Y. These variables include
6

Andromedan weather and indeed electrons at the end of the observable universe. When measuring
a single qubit we can frame it like this: consider a spacelike hypersurface S in the past of the
measurement event M, and through the event where the PRNG determined x, then λ must include
all data on S in the interior of M’s past light cone, with the exception of Px.
In this way we
can write X = E(λ, x), Y = E(λ, y). The extension of this causal picture to entangled qubits is
discussed in Section 6.
4.2
The Invariant Set Postulate
Consider the chaotic model
dxL
dt
= σ(yL −xL)
dyL
dt = xL(ρ −zL) −yL
dzL
dt = xLyL −βzL
(6)
that Lorenz [23] discovered in his quest to understand the deterministic non-periodicity of weather.
This model (based on Newton’s Laws) is a classical dynamical system and can be integrated from
any triple of initial states (xL, yL, zL) at t = 0. However, at t = ∞this model has an emergent non-
classical property: all states lie on a measure-zero, fractionally dimensioned, dynamically invariant
subset IL of state space, known as the Lorenz attractor. That IL is fractionally dimensioned implies
that IL has a non-Euclidean, fractal geometry. That IL is an invariant set implies that if a point lies
on IL, its future evolution will continue to lie on IL for all time, and its past evolution has lain on
IL for all time. That IL has measure zero implies that the probability that a randomly chosen point
belongs to IL is equal to zero (random with respect to the uniform measure on the Euclidean state
space R3 spanned by (xL, yL, zL)). Conversely, associated with IL is a fractal invariant measure ρL
(a Haar-type measure). Points which do not lie on IL have ρL = 0. Such points are inconsistent
with a non-classical dynamical system where all states lie on IL by definition. Such a system is
non-classical because IL is a non-computable subset of state space [9] [14] - non-computability being
a post-quantum discovery of 20th Century mathematics .
Now suppose we are given some timeseries from the output of the Lorenz equations in this
non-classical limit where the system is evolving on IL. No matter how long is the timeseries, we
cannot estimate statistical quantities like correlations or conditional frequencies more accurately
than the accuracy to which the timeseries has been outputted (e.g. the number of significant figures
of output variables). That is to say, we must treat all estimates of frequency (and correlation) as
functions of coarse-grained variables
¯xL =
Z
Vϵ
xLρL(xL)dxL;
¯yL =
Z
Vϵ
yLρL(yL)dyL;
¯zL =
Z
Vϵ
zLρL(zL)dzL
(7)
defined from non-zero ϵ balls of volume Vϵ in state space. A key property of IL is that no matter
how small is Vϵ, as long as it is non-zero, it will be impossible to use statistical output from the
Lorenz system to infer the existence of points inside the ϵ balls where ρL = 0. However, by the
fractal nature of IL, we know such points exist.
The results from Section 3 suggests the universe itself be considered a chaotic system. Following
Lorenz, it is well known that a broad class of chaotic models have measure-zero fractal attractors
7

[38]. The geometry of these attractors provide a holistic description of the states of such chaotic
systems. It is worth noting that defining chaos from geometric properties of the system’s invariant
set (e.g.
its non-integer dimension) provides a relativistically invariant description of chaos, in
contrast with positivity of Lyapunov exponents [13].
Consistent with the discussion above, we
assume the universe is a deterministic chaotic dynamical system evolving precisely on its fractal
invariant set IU, with invariant measure ρU. This is referred to as the invariant set postulate [28].
States which do not lie on IU must be assigned a measure and hence a probability ρ = ρU = 0.
4.3
Rational Quantum Mechanics: RaQM
Although the invariant set postulate provides a geometric approach to non-conspiratorial superde-
terminism, it does not directly address two specific questions.
Firstly, is it possible for a non-
conspiratorial locally-causal superdeterministic model to violate Bell inequalities exactly as does
quantum mechanics, and secondly is it possible in such a theory for (1) to be satisfied if λ is coarse-
grained over any given ϵ-ball Vϵ in state space - and hence to be satisfied in corresponding classical
theories.
Motivated by Planck’s original proposal to discretise energy levels (and John Wheeler’s plea
to excise the continuum from physical theory [40]), a related way to introduce non-conspiratorial
superdeterminism into quantum physics is to discretise Hilbert space [10] [11] [30]. At the experi-
mental level this is surely unexceptionable: all experiments which confirm quantum mechanics will
necessarily confirm a model of quantum physics based on discretised Hilbert Space, providing the
discretisation is fine enough.
4.3.1
Single Qubits
Consider a qubit prepared in a state |1⟩, and written as
|1⟩= cos θ
2|1′⟩+ sin θ
2eiϕ| −1′⟩
(8)
with respect to some measurement basis {|1′⟩, | −1′⟩}. In RaQM we assume
cos2 θ
2 = m1
2p ;
ϕ
2π = n1
4p
(9)
where p is some large prime number and 0 ≤m1, n1 ≤p. Here θ and ϕ can be considered nominal
representatives of exact measurement settings which satisfy the rationality constraints
cos2 θe
2 = 0.m1m2 . . . mI ∈Q =⇒cos θe ∈Q;
ϕe
2π = 0.n1n2 . . . nJ ∈Q
(10)
written in base-p. In this way, it can be shown [32] that |ψ⟩represents a bit-string of p deterministic
elements (= ±1) with fixed m1, n1 but varying m2, n2 (and where ϕ denotes a cyclical permutation
of elements of the bit string). In this representation, |ψ⟩automatically satisfies Born’s Rule (i.e. it
is not a separate axiom in RaQM).
If the exact preparation setting is represented by X, and exact measurement setting Y, then the
first of (10) can be written X · Y ∈Q, where · denotes the scalar product of two vectors. Because
of Niven’s theorem
Theorem. If ϕe/2π ∈Q, then cos ϕe /∈Q except when cos ϕe = 0, ± 1
2, ±1 [26] [20]
8

the discretisation renders incommensurate angles that determine probabilities, and angles that
determine phases, except at the precise values ϕe = 0, π/2, π, 3π/2. One can assume that such
precise values never occur in practice, though they may be relevant for theoretical reasons (e.g.
when one considers a measurement performed with a precisely opposite measurement direction).
An important corollary to Niven’s Theorem - central to this paper - is the Impossible Triangle
Corollary:
Corollary. Let △XY Z be a triangle on the unit sphere with rational internal angles, not precisely
equal to multiples of 45◦, such that X·Y and Y·Z are rational numbers. Then X·Z is an irrational
number.
Proof. Assume otherwise and look for contradiction. Use the cosine rule for △XY Z,
cos θXZ = cos θXY cos θY Z + sin θXY sin θY Z cos ϕY
(11)
where θXZ denotes the exact angular distance between X and Z on the unit sphere, etc and ϕY
is the exact internal angle of the triangle at the vertex Y . Since cos θXY and cos θY Z are both
rational, then from (11), sin θXY sin θY Z cos ϕY must be rational. Squaring, (1 −cos2 θXY )(1 −
cos2 θY Z) cos2 ϕY must be rational. Again, since cos θXY and cos θY Z are both rational, cos2 ϕY
and hence cos 2ϕY must be rational. But this is impossible since ϕY is itself rational and phiY is
not a multiple of 45◦. Hence cos θXZ must be irrational.
The Impossible Triangle Corollary is vital for explaining the notion of non-commutativity in
RaQM [32]. Consider a particle with spin prepared (with Stern-Gerlach device SG0) relative to
some exact orientation X. It is passed through Stern-Gerlach device SG1 with exact orientation Y .
The spin-up output beam of SG1 is passed through Stern-Gerlach device SG2 with exact orientation
Z. By RaQM, X · Y and Y · Z are rational. Suppose the detector in the spin-down output channel
of SG2 registers a particle and consider the hypothetical experiment on the same particle (same λ)
where SG1 and SG2 are swapped (commuted). The measurement outcome from this hypothetical
experiment is undefined: by the Impossible Triangle Corollary, if X · Y and Y · Z are rational, then
X · Z is not.
We note in passing that it is straightforwardly shown [30] that the ensemble representation of
the single qubit state in RaQM satisfies a uncertainty principle relationship, i.e.
∆Sx∆Sy ≥ℏ
2⟨Sz⟩
(12)
Here ∆Sx and ∆Sy are associated with standard deviations of bit-strings, and ⟨Sz⟩denotes a
bit-string ensemble mean.
4.3.2
Multiple Qubits
Bell’s inequality is based on measurements of pairs of entangled particles prepared in the quantum
mechanical singlet state
|ψ >=
1
√
2[|x+⟩|y−⟩−|x−⟩|y+⟩]
(13)
with correlations
C(x, y) = ⟨ψ|(σ · x) (σ · y)|ψ⟩= −x · y
(14)
9

where σ denote Pauli matrices.
In RaQM, an n-qubit system is represented by a set of n bit strings. Hence in RaQM (13) is
represented by two correlated bit strings (with equal numbers of +1s and −1s). The bits represent
measurement outputs from members of an ensemble. These members are governed by deterministic
laws. Corresponding to any one ensemble member (which can be labelled by λ) we require the
exact measurement settings corresponding to x, y to satisfy
X · Y ∈Q
(15)
If XY denotes the great circle between X and Y , then (15) requires that the cosine cos θXY of the
angular length of XY is rational. Now keeping X fixed and perturbing Y 7→Y ′, then, if X and Y ′
are also permissible exact settings, X · Y′ must also be rational, and the angle ϕ subtended at X
between the two great circles XY and XY ′ must satisfy
ϕ
2π ∈Q
(16)
Similar rational constraints apply, fixing Y and perturbing X 7→X′.
Consider a run of a Bell experiment for a pair of particles prepared in the singlet state with
hidden-variable λ, where Alice and Bob’s exact measurement are X and Y, and suppose Bob’s
measurement outcome was +1. In this case, had Alice measured using Bob’s exact setting Y , she
would have got the opposite to what Bob got, i.e she would have got −1.
4.4
Relating the Invariant Set Postulate with RaQM
In number theory, Ostrowsky’s theorem states that there are only two inequivalent norm-induced
metrics on the rational numbers Q: the Euclidean metric and the p-adic metric [22]. It is well
known that the set of p-adic integers is homeomorphic to a Cantor Set with p iterated pieces [35].
In this way, we can relate the two models above by supposing that states in discretised Hilbert
Space represent ensembles of trajectories on a fractal invariant set at some level of fractal iteration,
where each trajectory at one level of iteration is associated with an ensemble of p trajectories at the
next level of fractal iteration. In this way, a deterministic state which does not satisfy the rationality
constraints of RaQM corresponds to a state of the world which does not lie on the invariant set IU.
In this picture, the measurement process corresponds to a jump from one fractal iteration of IU to
the next. This suggests a picture of the evolution of time in terms of a series of jumps in iteration
level - similar to a fractal zoom.
As discussed above, although deterministic, such models are not classical.
Classical models
are associated with deterministic initial conditions and dynamical evolution equations expressed
in terms of differential (or finite difference) equations on the reals or complex numbers. Typically
one can vary initial conditions as one likes, and perturbed initial conditions can be integrated from
the evolution equations without issue. In classical models, the ontology of states does not depend
on them lying on invariant sets, nor on them having rational-number characteristics. In this way,
classical models typically do have the property of indefiniteness. Notice that the results discussed
here do not depend on how large is p, as long as it is not infinite. Moreover, by writing ϵ˜1/p, it
can be seen that violations to the rationality constraints in RaQM can be completely eliminated
by coarse graining over ϵ disks, no matter how small is ϵ.
10

Figure 1: a) The three circles correspond to ϵ disks on the unit sphere associated with the three
nominal measurement settings x1, x2 and x3 in Bell’s 1964 inequality. The straight lines represent
great circles on the unit sphere whose cosine of angular distance is rational. By the Impossible
Triangle Corollary, it is impossible for the cosine of all three angular distances (i.e.
X1 · X2,
X1 · X3 and X2 · X3) to be rational. Because of this, (1) is violated. b) In a more conventional
model, there is no requirement for the exact settings to be held fixed when comparing real and
hypothetical worlds with the same hidden variables and same nominal settings. In this model it is
always possible to satisfy (1) and hence the violation of Bell inequalities must imply violation of
local realism or possibly some grotesque conspiracy.
5
Bell’s Theorem
5.1
The Bell (1964) Inequality
In this subsection, we focus on the original Bell inequality [4]
|C(x1, x2) −C(x1, x3)| ≤1 + C(x2, x3)
(17)
For some specific run in an experiment to test (17), suppose Alice chooses the nominal orientation
x1 and Bob chooses the nominal orientation x2. In keeping with the discussion above, λ, x1 and
x2 fix a pair of exact measurement settings X1 = E(λ, x1) and X2 = E(λ, x2). To satisfy (15),
X1 · X2 ∈Q. Note that Alice and Bob have no choice as to whether this rationality constraint is
satisfied - unlike their nominal settings, they have no control over exact settings. There are many
points in the two ϵ disks for x1 and x2 which satisfy this constraint (see Fig 1).
In order that a putative hidden-variable theory satisfies (17), it is necessary that, in addition
to the real-world run where the particles were measured with nominal settings (x1, x2), the same
particles (same λ) could have been measured with nominal settings (x1, x3) and (x2, x3) with
definite outcomes ±1. We will consider these hypothetical worlds in turn.
For the first, keeping λ fixed, Alice continues to choose the nominal setting x1, whilst Bob
hypothetically chooses the nominal setting x3. Since X1 = E(λ, x1), then keeping λ and x1 fixed
requires fixing X1. By contrast, keeping λ fixed but transforming x2 to x3 implies a hypothetical
change in Bob’s exact setting from X2 to some (unknown) X3. This transformation is consistent
with RaQM as long as the rationality conditions (15) and (16) hold. It is therefore necessary that
X1 · X3 ∈Q and that ϕ/2π ∈Q where ϕ denotes the angle between the great circles X1X2 and
11

X1X3 at the point X1 of intersection. There are plenty of exact settings X3 in the ϵ neighbourhood
for x3 for which these rationality constraints are satisfied.
But now, c.f.
the third term in (17), we consider the hypothetical world where, keeping λ
fixed, Alice chooses the nominal direction x2 and Bob x3. With X3 = E(λ, x3), X3 is fixed by
its value for the first hypothetical world. We now invoke the key property of the singlet state: if
the measurement outcome was +1 (say) when Bob’s exact setting was X2, then the measurement
outcome will be −1 in a hypothetical world where Alice’s exact setting was X2. Hence, both X2 and
X3 must be held fixed at their previously determined values. However, appealing to the Impossible
Triangle Corollary, if X1 · X2 and X1 · X3 are rational and if ϕ is rational and not precisely a
multiple of 45◦(gravitational waves from Andromedan weather will help ensure that), then X2 ·X3
cannot be rational. See Fig 1.
In essence, for each run in a Bell experiment, one of the two hypothetical runs is inconsistent
with the rationality constraints of the hidden variable model and therefore must be assigned a
probability ρ = 0. Put another way
ρ(λ|x1, x2) × ρ(λ|x1, x3) × ρ(λ|x2, x3) = 0
(18)
where, to emphasise, all orientations are nominal. If one configuration occurs in reality (so that its
probability is not identically zero) then (18) implies that (1) is violated.
5.2
The CHSH Inequality
This is a straightforward extension of the argument above. Here x = 0, x = 1, y = 0 and y = 1
denote four ϵ disks (i.e. nominal settings) on the 2-sphere of orientations. Suppose, in a given run
with fixed λ, Alice measures with respect to x = 0 and Bob with respect to y = 0. This is achieved
with exact settings X0, Y0 such that
X0 · Y0 ∈Q
(19)
In order that a putative hidden-variable theory satisfies (2), it is necessary that, in addition to
the real-world run where the particles were measured with nominal settings (x = 0, y = 0), the
same particles could have been measured with nominal settings (x = 0, y = 1), (x = 1, y = 0) and
(x = 1, y = 1), with definite outcomes ±1.
As before, with X0 = E(λ, x = 0), X1 = E(λ, x = 1), Y0 = E(λ, y = 0), Y1 = E(λ, y = 1), and
keeping λ fixed, seek two exact settings X1, Y1 such that:
X0 · Y1 ∈Q;
X1 · Y0 ∈Q;
X1 · Y1 ∈Q
(20)
and
α
2π ∈Q;
β
2π ∈Q;
γ
2π ∈Q;
δ
2π ∈Q
(21)
See Fig 2.
By repeated application of the Impossible Triangle Corollary, we now show it is impossible to
satisfy (20) and (21).
We do this by contradiction. Suppose instead that (20) and (21) are satisfied. Consider the two
triangles △X0X1Y1 and △X0X1Y0. By the cosine rule for spherical triangles for each of the two
triangles
cos θX0X1 = cos θX0Y0 cos θX1Y0 + sin θX0Y0 sin θX1Y0 cos γ
cos θX0X1 = cos θX1Y1 cos θX0Y1 + sin θX1Y1 sin θX0Y1 cos δ
(22)
12

Figure 2: Illustrating the CHSH experiment where x = 0, x = 1, y = 0 and y = 1 denote ϵ-
disks associated with nominal measurement settings, under the control of the experimenters. X0,
X1, Y0 and Y1 are points on the unit 2-sphere corresponding to exact measurement settings, and
straight lines correspond to great circles joining these points. As discussed in the text, if Alice and
Bob chose the nominal settings x = 0 and y = 0, then, by the Impossible Triangle Corollary and
keeping λ fixed, they could not have chosen x = 0 and y = 1, or x = 1 and y = 0. Here, by the
relationship X = E(λ, x) and Y = E(λ, y), fixing λ and a nominal measurement setting fixes an
exact measurement setting.
Subtracting these equations then
A = sin θX0Y0 sin θX1Y0 cos γ −sin θX1Y1 sin θX0Y1 cos δ
(23)
must be rational. Writing A1 = sin θX0Y0 sin θX1Y0 cos γ, A2 = sin θX1Y1 sin θX0Y1 cos δ, then we can
write
A2
1 = r1 + r2 cos 2γ; A2
2 = r3 + r4 cos 2δ
(24)
where r1, r2, r3, r4 are rational. However, by Niven’s Theorem, providing γ and δ are not precise
multiples of 45◦, A2
1 and A2
2 must be irrational. Moreover they must be independently irrational
since γ and δ can be varied independently of one another. Hence generically A1 −A2 = A must be
irrational which is the contradiction we are looking for.
This contradiction implies that cos θX0Y0 and cos θX1Y0 cannot both be rational. Suppose that
in reality Alice’s measurement setting is X0 and Bob’s is Y0, so that cos θX0Y0 = X0Y0 ∈Q.
Then necessarily cos θX1Y0 = X1 · Y0 must be irrational. A similar argument applied to triangles
△Y0Y1X0 and △Y0Y1X1 leads to the conclusion that X0 · Y1 must be irrational.
This in turn leads to the following general conclusion. In the situation where Alice chose x and
Bob y, then, keeping the particles’ hidden variables fixed, Alice and Bob could not have chosen x
and y′, or x′ and y, where x′ = 1 −x, y′ = 1 −y (though there is nothing in the theory to prevent
them from having chosen x′ and y′). Similar to (18)
ρ(λ|x = 0, y = 0) × ρ(λ|x = 0, y = 1) × ρ(λ|x = 1, y = 0) × ρ(λ, x = 1, y = 1) = 0
(25)
If one configuration occurs in reality (so that its probability is not identically zero) then (25) implies
that (1) is violated. As with Bell’s 1964 inequality, the Impossible Triangle Corollary implies that
(1) is violated without conspiracy.
13

It can be noted that since RaQM is based on an arbitrarily fine discretisation of complex Hilbert
Space, by letting p be sufficiently large, RaQM must violate Bell’s inequality as closely we like to
the quantum mechanical violation of Bell’s inequality.
6
Local Causality
In this Section, we show that the proposed superdeterministic model is locally causal. First we
have to define what is meant by local causality. We first note the comment by Bell [5]:
Very often . . . factorizability is taken as the starting point of the analysis. Here we
have preferred to see it not as the formulation of ‘local causality’, but as a consequence
thereof.
In this, his last paper, Bell was still struggling to find a satisfactory definition of local causality.
Fig 3 illustrates a space-time diagram where a photonic source emits two entangled photons.
These are measured by Alice and Bob’s detectors with nominal settings x = 0 and y = 0 and exact
settings X0 and Y0. The nominal settings are determined by two PRNGs shown in the figure. By the
discussion above, the particle’s hidden variables λ, together with the parities Px and Py, determine
these exact settings. In Fig 3, we divide λ into two components, λA corresponding to information
in the past light cone of Alice’s measurement event, and λB corresponding to information in the
past light cone of Bob’s measurement event.
Let us start by writing Alice and Bob’s measurement outcomes (= ±1) in the most general
form:
SA = S(λA, λB, x, y);
SB = S(λA, λB, x, y)
(26)
Here the notion of local causality expresses the relativistic notion that SA should not depend on y
or λB (since these are outside the light cone of Alice’s measurement event), and similarly SB should
not depend on x or λA.
However, in the context of the proposed superdeterministic model, we have to be careful what
we mean by ‘does not depend on’. To understand the subtlety, we define the notion of causality in
terms of Pearlean interventions as above. If we intervene on the world in some small part of space-
time, we expect that intervention to propagate causally, i.e. consistent with the light-cone structure
of space-time. However, as discussed above, we need to distinguish between interventions that keep
the state of the world on IU and interventions that take the state of the world off IU. The former
describe space-time mappings: from a space-time in which the intervention does not occur, to a
space-time in which the intervention does occur. A space-time intervention must be consistent with
the Lorentzian metric of space time, i.e. cannot propagate superluminally. By contrast, an ‘acausal’
intervention which takes the state of the world off IU does not define a space-time mapping. There
is no requirement for such an intervention to be consistent with the Lorentzian metric - there is no
Lorentzian metric on state space.
We define local causality as follows: whatever the values of SA and SB in (26), it is never the
case that
S(λA, λB, x, y′) = −SA;
S(λA, λB, x′, y) = −SB
S(λA, λ′
B, x, y) = −SA;
S(λ′
A, λB, x, y) = −SB
(27)
where x′ = 1 −x, y′ = 1 −y and λ′
A, λ′
B define perturbations in the past light cones of the two
measurement events A and B respectively, which change the exact measurement settings (see Fig
14

Figure 3: A space-time diagram illustrating the locally causal nature of the proposed superdetermin-
istic model. Suppose Alice’s measurement outcome is +1. This measurement outcome could have
been −1 if Px (the parity of the millionth digit) were different or if λA were different. However, local
causality demands that Alice’s measurement outcome could not have been −1 if Py were different or
λB was different, keeping Px and λA fixed. However, importantly, local causality does not exclude
the possibility that Alice’s measurement outcome would have been undefined if Py had been different
or λB had been different, keeping Px and λA fixed. According to RaQM and the invariant set pos-
tulate, this undefinedness arises because the corresponding Pearlean interventions are inconsistent
with rationality constraints and take the universe off its invariant set.
3). If a theory is consistent with this definition, then it is impossible to define a hypothetical space-
time intervention which has the effect of making Alice’s measurement outcome SA depend either
on Bob’s nominal setting y, i.e. on Bob’s PRNG output, or on the hidden variable λB in the past
light cone of Bob’s measurement event.
Importantly, however, this definition is not inconsistent with acausal interventions where
S(λA, λB, x, y′) is undefined;
S(λA, λB, x′, y) is undefined
S(λA, λ′
B, x, y) is undefined;
S(λ′
A, λB, x, y) is undefined
(28)
These quantities are undefined because of the Impossible Triangle Corollary applied to spherical
triangles △XY Y ′ and △XX′Y . Our superdeterministic model is therefore locally causal.
7
Singular Limits and the Aaronson Challenge
Aaronson’s challenge (see the Introduction) raises a more general question: what is the relationship
between a successor theory of physics and its predecessor theory? There is a subtle but important
relationship brought out explicitly by Michael Berry [8] that is of relevance here.
Typically an old theory is a singular limit of a new theory, and not a smooth limit, as a parameter
of the new theory is set equal to infinity or zero. A singular limit is one where some characteristic
of the theory changes discontinuously at the limit, and not continuously as the limit is approached.
Berry cites as examples the old theory of ray optics is explained from Maxwell theory, or the old
15

theory of thermodynamics is explained from statistical mechanics. His claim is that old theories of
physics are typically singular limits of new theories.
If quantum theory is a forerunner of some successor superdeterministic theory, and Berry’s
observation is correct, quantum mechanics is likely to be a singular limit of that superdeterministic
theory. Here the state space of quantum theory arises at the limit p = ∞of RaQM, but not before.
For any finite p, no matter how big, the incompleteness property that led to the violation of (1)
holds. However, it does not hold at p = ∞. From this point of view, quantum mechanics is indeed
a singular limit of RaQM at p = ∞.
It is interesting to note that pure mathematicians often
append the real numbers to sets (‘adeles’) of p-adic numbers, at p = ∞. However, the properties
of p-adic numbers are quite different to those of the reals for any finite p no matter how big. Here
the real-number continuum is the singular limit of the p-adics at p = ∞. The relationship between
QM and RaQM is very similar.
In physics, it is commonplace to solve differential equations numerically, i.e. to treat discreti-
sations as approximations of some continuum exact equations, such that when the discretisation is
fine enough, the numerical results are as close as we require to the exact continuum solution. This
is not a good analogy here. A better analogy is analytic number theory, considered as an approx-
imation to say the exact theory of prime numbers. If one is interested in properties of primes for
large primes, treating p as if it were a continuum variable can provide excellent results. However,
here the continuum limit is the approximation and not the exact theory.
Contrary to Aaronson’s statements, the singular relationship between a superdeterministic the-
ory and quantum mechanics is exactly as one would expect from the history of science.
8
Other Objections to Superdeterminism
Below we address two other objections that have been raised against superdeterminism.
8.1
Fine Tuning
The fine-tuned objection (e.g. [3]) rests on the notion that superdeterminism appears to require
some special, atypical, initial conditions. Perhaps one might view an initial state lying on a fractal
attractor as special and atypical - after all a seemingly tiny perturbation (changing Px keeping λ
fixed) can take the state of the universe off its invariant set IU. Although the Euclidean metric
accurately describes distances in space-time, the p-adic metric is more natural in describing distances
in state space when the inherent geometry of state space is fractal [22]. From the perspective of
the p-adic metric, a fractal invariant set is not fine-tuned: a perturbation which takes a point off
IU is a large perturbation (of magnitude at least p), even though it may appear very small from a
Euclidean perspective.
Similarly, we must ask with respect to what measure are states on IU deemed atypical. Although
states on IU are atypical with respect to a uniform measure on the Euclidean space in which IU is
embedded, they are manifestly typical with respect to the invariant measure of IU [17].
In claiming that a theory is fine tuned, one should first ask with respect to which metric/measure
is the tuning deemed fine - and then ask whether this the natural metric/measure to assess fineness?
8.2
Free Will
Nobel Laureate Anton Zeilinger wrote [42]:
16

We always implicitly assume the freedom of the experimentalist... This fundamental
assumption is essential to doing science. If this were not true, then, I suggest, it would
make no sense at all to ask nature questions in an experiment, since then nature could
determine what our questions are, and that could guide our questions such that we
arrive at a false picture of nature.
To deliberately avoid discussing the poorly understood notion of free will in this paper, following
Bell the nominal settings for the polarisers were fixed by the parity Px of the millionth digit fed
into a PRNG. (This can be contrasted with the determinants of exact settings which comprise
a vast amount of delocalised data completely outside the control of the experimenter.) For any
run of a Bell experiment, we have supposed it is just as likely that Px is odd or even - there are
certainly no knowable constraints that prevent Px from being odd or even. However, we could let Px
represent the state of the ‘millionth’ neuron in an experimenter’s brain. If the neuron has fired, their
measurement apparatus is set to x = 0, otherwise it is set to x = 1. Just as there are no knowable
constraints to prevent the millionth digit being odd or even, we can suppose there are no knowable
constraints to prevent the neuron from firing or not firing. The experimental might interpret this
in terms of an ability to set apparatuses whimsically, surely the very embodiment of freedom. As
such, there is nothing in the proposed model to deny the freedom of the experimentalist, at least
from the perspective of a traditional compatibilist understanding of freedom [21].
9
Experimental Tests
A key result from this paper is that we will not be able to detect non-conspiratorial superdetermin-
istic violations of (1) by studying frequencies of measurement outcomes in a Bell experiment. We
must look for other ways of testing such theories.
Of course, QM is exceptionally well tested and if a superdeterministic theory is to replace QM, it
must clearly be consistent with results from all the experiments which support QM. Here RaQM has
a free parameter p, which, if large enough, can replicate all existing experiments. This is because
with large enough p, discretised Hilbert space is fine enough that it replicates to experimental
accurace the probabilistic predictions of a theory based on continuum Hilbert space (and Born’s Rule
to interpret the squared modulus of a state as a probability - something automatically satisfied in
RaQM). Conversely, however, if p is some finite albeit large number, then in principle an experiment
with free parameter pexp can study situations where pexp > p where there might be some departure
between reality and QM [18].
One conceivable test of RaQM vs QM probes the finite amount of information that can be
contained in the quantum state vector |ψ⟩(in RaQM n qubits are represented by n bit strings of
length p). In RaQM, the finite information encoded in the quantum state vector will limit the
power of a general purpose quantum computer, in the sense that RaQM predicts the exponential
increase in quantum compute speed with qubit number for a range of quantum algorithms may
generally max out at a finite number m of qubits.
The key question is what this value m is. We will explore this issue elsewhere.
10
Conclusions
Here we claim that violation of (1) does not imply any of the derisive things claimed by numerous
researchers in the quantum foundations community over the years.
A superdeterministic (and
17

hence deterministic) model has been proposed which is not conspiratorial, is locally causal, does
not deny experimenter free choice in any meaningful sense and is not fine tuned with respect to
natural metrics and measures. Importantly, the model is not a classical hidden-variable model,
i.e. it derives its properties from post-quantum-theory mathematical science. By considering the
continuum of complex Hilbert Space as a singular limit of a superdeterministic discretisation of
complex Hilbert Space, Aaronson’s challenge to superdeterminists can be met.
Perhaps the most important conclusion of this paper is that we need to be extremely cautious
when invoking the notion of an ‘intervention’ in space time, at least in the context of fundamental
physics.
Such interventions form the bedrock of Pearl’s causal inference modelling, and causal
inference has been used widely in the quantum foundations community to try to analyse the causal
structure of quantum physics. Here we distinguish between two types of intervention: one that is
consistent with the laws of physics and one that is not. The effect of the former type of intervention,
if it is initially contained within a localised region of space-time, must propagate causally in space-
time, constrained by the Lorentzian metric of space time. By contrast, the latter type of intervention
simply perturbs a state of the universe from a part of state space where the laws of physics hold,
to a part of state space where the laws of physics do not hold. The metric of state space is not
Lorentzian and so if the hypothetical intervention is non-zero in a localised region of space-time,
there are no constraints which prevent its effect on the whole of space time being instantaneous
- you cannot violate the laws of physics locally and expect the rest of the universe to carry on
regardless! If this superdeterministic model is correct, theories of quantum physics based on causal
inference models which adopt an uncritical acceptance of interventions, regardless of whether they
are consistent with the laws of physics or not, will give misleading results.
We conclude turn the table on the critics: what alternative interpretation of the experimental
violation of Bell’s inequality makes any sense? If we abandon local causality then we have to explain
- no-signalling notwithstanding - how Bob’s measurement choice could affect Alice’s measurement
outcome.
If we abandon realism, we have to explain what it means to say that states of the
seemingly real world are ‘unreal’. If we appeal to retrocausality, then we admit a conspiratorial
space-time intervention which propagates backwards in time, arguably twice the worse for that.
The results of this paper suggest that gravity may central to understanding the reasons why the
universe can be considered a dynamical system evolving on an invariant set, and hence why Hilbert
space itself should be ‘quantised’. This suggests that instead of looking for a quantum theory of
gravity, we should instead be looking for a gravitational theory of the quantum [29] [34]. However,
importantly, the results here suggest such a theory will not be found by probing smaller and smaller
regions of space-time, ultimately the Planck scale. It will instead be found by incorporating into the
fundamental laws of physics, the state-space geometry of the universe at its very largest scales [31].
Planck-scale discontinuities in space-time may instead be an emergent property of such (top-down)
geometric laws of physics.
In the author’s opinion, this is the real message - not non-locality or indeterminism - behind
the violation of Bell’s inequality.
Acknowledgements
My thanks to Jean Bricmont, Harvey Brown, Michael Hall, Jonte Hance, Inge Svein Helland, Sabine
Hossenfelder, Tim Maudlin and Chris Timpson for helpful discussions and/or useful comments on
an early draft of this paper. The author gratefully acknowledges the support of a Royal Society
Research Professorship.
18

References
[1] S.
Aaronson.
On
tardigrades,
superdeterminism
and
the
struggle
for
sanity.
https://scottaaronson.blog/?p=6215, 2022.
[2] M. Araujo. Superdeterminism is unscientific. https://mateusaraujo.info/2019/12/17/superdeterminism-
is-unscientific/, 2019.
[3] M. Baas and B. Le Bihan. What does the world look like according to superdeterminism.
https://philarchive.org/archive/BAAWDT, 2020.
[4] J.S. Bell. On the Einstein-Podolsky-Rosen paradox. Physics, 1:195–200, 1964.
[5] J.S. Bell.
Speakable and unspeakable in quantum mechanics, chapter La Nouvelle Cuisine.
Cambridge University Press, 2004.
[6] J.S. Bell, A.Simony, M.A.Horne, and J.F.Clauser. An exchange on local beables. Dialectica,
39:85–110, 1985.
[7] M. Berry. Regular and irregular motion. American Institute of Physics Conference Proceedings
Number 46, 1985.
[8] M Berry. Singular limits. Physics Today, 55:10–11, 2002.
[9] L. Blum, F.Cucker, M.Shub, and S.Smale. Complexity and Real Computation. Springer, 1997.
[10] R. Buniy, S. Hsu, and A. Zee. Is Hilbert space discrete. Phys.Lett., B630:68–72, 2005.
[11] R. Buniy, S. Hsu, and A. Zee. Discreteness and the origin of probability in quantum mechanics.
arXiv:hep-th/0606062, 2006.
[12] Eddy
K.
Chen.
Bell’s
theorem,
quantum
probabilities
and
superdeterminism.
arXiv:2006.08609, 2020.
[13] N.J. Cornish.
Fractals and symbolic dynamics as invariant descriptors of chaos in general
relativity. arXiv.org/gr-qc/9709036, 1997.
[14] S. Dube. Undecidable problems in fractal geometry. Complex Systems, 7:423–444, 1993.
[15] S.
Goldstein,
T.
Norsen,
D.V.Tausk,
and
N.Zanghi.
Bell’s
theorem.
http://dx.doi.org/10.4249/scholarpedia.8378, 2011.
[16] M.J.W. Hall. Local deterministic model of singlet state correlations based on relaxing mea-
surement independence. Phys. Rev. Lett., 105:250404, 2011.
[17] Jonte R. Hance, Sabine Hossenfelder, and Tim N. Palmer. Supermeasured: Violating bell-
statistical independence without violating physical statistical independence. Foundations of
Physics, 52(4):81, Jul 2022.
[18] J.R. Hance and S. Hossenfelder.
What does it take to solve the measurement problem?
arXiv:2206.10445, 2022.
19

[19] Sabine Hossenfelder and Tim Palmer. Rethinking superdeterminism. Frontiers in Physics,
8:139, 2020.
[20] J. Jahnel. When does the (co)-sine of a rational angle give a rational number? arXiv:1006.2938,
2010.
[21] R. Kane. Free Will. Blackwell, 2002.
[22] S. Katok. p-adic Analysis compared with Real. American Mathematical Society, 2007.
[23] E.N. Lorenz. Deterministic nonperiodic flow. J.Atmos.Sci., 20:130–141, 1963.
[24] T. Maudlin. Quantum non-locality and relativity. Wiley-Blackwell, 2011.
[25] T.
Maudlin.
Tim
maudlin
and
palmer:
Fractal
geometry,
non-locality,
bell.
https://www.youtube.com/watch?v=883R3JlZHXE, 2023.
[26] I. Niven. Irrational Numbers. The Mathematical Association of America, 1956.
[27] T.N. Palmer. A local deterministic model of quantum spin measurement. Proc. Roy. Soc.,
A451:585–608, 1995.
[28] T.N. Palmer. The invariant set postulate: a new geometric framework for the foundations of
quantum theory and the role played by gravity. Proc. Roy. Soc., A465:3165–3185, 2009.
[29] T.N. Palmer. Quantum theory and the symbolic dynamics of invariant sets: Towards a gravi-
tational theory of the quantum. arXiv:1210.3940, 2012.
[30] T.N. Palmer. Discretization of the Bloch sphere, fractal invariant sets and Bell’s theorem.
Proc. Roy. Soc., https://doi.org/10.1098/rspa.2019.0350, arXiv:1804.01734, 2020.
[31] T.N. Palmer. The Primacy of Doubt. Oxford University Press, 2022.
[32] T.N. Palmer. Quantum physics from number theory. arXiv:2209.05549, 2022.
[33] J. Pearl. Causal and counterfactual inference. The Handbook of Rationality. The MIT Press,
pages 427–438, 2021.
[34] R. Penrose. On the gravitization of quantum mechanics 1: Quantum state reduction. Foun-
dations of Physics, 44:557–575, 2014.
[35] A. M. Robert. A Course in p-adic Analysis. Springer ISBN 0-387-98660-3, 2000.
[36] S. Scanrani. Bell Nonlocality. Oxford Graduate Texts, 2019.
[37] M. Schwartz. Statistical mechanics lecture 3. https://scholar.harvard.edu/files/schwartz/files,
2019.
[38] S.H. Strogatz. Nonlinear dynamics and chaos. Westview Press, 2000.
[39] G. ’tHooft. The Cellular Automaton Interpretation of Quantum Mechanics. Springer, 2016.
[40] J. A. Wheeler. Information, Physics, Quantum: The Search for Links. The Santa Fe Institute
Press, 2023.
20

[41] H.M. Wiseman and E.G.Cavalcanti. Causarum investigatio and the two Bell’s theorems of
John Bell. arXiv:1503.06413, 2015.
[42] A. Zeilinger. Zeilinger on superdeterminism. https://www.physicsforums.com/threads/zeilinger-
on-superdeterminism.742415, 2014.
21

