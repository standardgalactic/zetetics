
PRAISE FOR THE FORGETTING MACHINE
“Quian Quiroga, himself an imaginative pioneer in the brain 
sciences, combines state-of-the-art knowledge of the human 
mind, admirable cultural literacy, and an enticing presenta-
tion style. If you wish to take a fascinating and memorable 
journey into the riddles of human perception and memory, 
The Forgetting Machine is the gate to enter.” 
—YADIN DUDAI, PROFESSOR, WEIZMANN INSTITUTE 
OF SCIENCE AND NEW YORK UNIVERSITY
“Rodrigo Quian Quiroga is one of those rare computational 
neuroscientists who really knows how to bring complex and 
abstract concepts to a popular audience. This charming and 
informative book explains current understanding of how 
memories are encoded in the brain in elegant prose that 
reflects Quian Quiroga’s engagement with philosophy and 
the arts as well as hard-core science.”
—ALISON ABBOTT, NATURE MAGAZINE
“The author, a noted brain scientist, takes the reader on an 
exciting whirlwind tour of vision and memory. His take-home 
message is that our brains don’t faithfully record the pixels 
making up any one scene nor do they recall anything but a 
minute fraction of our life events. Most of what we do, see, 
and remember is filtered, interpreted, and inferred.” 
—CHRISTOF KOCH, CHIEF SCIENTIST AND PRESIDENT, 
ALLEN INSTITUTE FOR BRAIN SCIENCE, SEATTLE

“Rodrigo Quian Quiroga highlights for the reader one of the 
grand challenges of brain science—and, indeed, science as a 
whole: the quest to understand the mysterious properties of 
human memory. He does so while providing an eloquently 
intelligible primer on the processes that underlie our recol-
lections. He leads the reader from an explanation of basic 
sensory perception through a description of how the brain 
processes abstract concepts, invoking along the way insights 
from Aristotle, Plato, and Borges. In an era of terabyte 
thumb drives, the author emphasizes repeatedly that mem-
ory thrives as a uniquely human trait. Analogies to digital 
recording devices are off base. Human memory distinguishes 
itself from a mere digital storage device by an ability to con-
tinually extract meaning from raw information.”
—GARY STIX, SENIOR EDITOR, SCIENTIFIC AMERICAN

T h e 
F O R G E T T I N G 
M AC H I N E


T h e 
F O R G E T T I N G 
M AC H I N E
Memory, Perception, and the 
“Jennifer Aniston Neuron”
R O D R I G O  Q U I A N 
Q U I R O G A
BenBella Books, Inc.
Dallas, TX

Copyright © 2017 by Rodrigo Quian Quiroga
All rights reserved. No part of this book may be used or reproduced in any manner whatsoever 
without written permission except in the case of brief quotations embodied in critical articles or 
reviews.
Originally published in Spanish as Qué es la memoria in 2014 by Editorial Paidós. Copyright  
© 2014 by Rodrigo Quian Quiroga.
Translation by Juan Pablo Fernández
BenBella Books, Inc.
10440 N. Central Expressway, Suite 800
Dallas, TX 75231
www.benbellabooks.com
Send feedback to feedback@benbellabooks.com
Printed in the United States of America
10  9  8  7  6  5  4  3  2  1
Library of Congress Cataloging-in-Publication Data
Names: Quian Quiroga, Rodrigo, author.
Title: The forgetting machine : memory, perception, and the “Jennifer Aniston neuron” /  
Rodrigo Quian Quiroga.
Other titles: Que es la memoria. English
Description: Dallas, TX : BenBella Books, Inc., [2017] | Translation of: Que es la memoria / Ro-
drigo Quian Quiroga. Editorial Paidos, 2014. | Includes bibliographical references and index. 
Identifiers: LCCN 2017025074 (print) | LCCN 2017025866 (ebook) | ISBN 9781944648558 
(electronic) | ISBN 9781944648541 (trade paper : alk. paper)
Subjects: | MESH: Memory—physiology | Perception | Brain—physiology | Nervous System 
Physiological Phenomena
Classification: LCC QP406 (ebook) | LCC QP406 (print) | NLM WL 337 | DDC 612.8/23312—
dc23
LC record available at https://lccn.loc.gov/2017025074
Editing by Alexa Stevenson
Copyediting by Scott Calamar
Proofreading by Rachel Phares and Karen 
Wise
Indexing by Amy Murphy Indexing & 
Editorial
Text design and composition by Aaron 
Edmiston
Front cover by Pete Garceau
Full cover by Sarah Avinger
Printed by Lake Book Manufacturing
Distributed by Perseus Distribution
www.perseusdistribution.com
To place orders through Perseus Distribution:
Tel: (800) 343-4499
Fax: (800) 351-5073
E-mail: orderentry@perseusbooks.com
Special discounts for bulk sales (minimum of 25 copies) are available. 
Please contact Aida Herrera at aida@benbellabooks.com.

To my parents,
Hugo and Marisa


C O N T E N T S
CHAPTER 1 | 1
How Do We Store Memories?
CHAPTER 2 | 19
How Much Do We See?
CHAPTER 3 | 35
Does the Eye Really See?
CHAPTER 4 | 49
How Much Do We Remember?
CHAPTER 5 | 69
Can We Remember More?
CHAPTER 6 | 85
Could We Become More Intelligent?

CHAPTER 7 | 105
Types of Memory
CHAPTER 8 | 115
How Does the Brain Represent Concepts?
CHAPTER 9 | 133
Can Androids Feel?
NOTES | 157
INDEX | 175
ACKNOWLEDGMENTS | 183
ABOUT THE AUTHOR | 187

1
C h a p t e r  1
H O W  D O  W E  S T O R E 
M E M O R I E S ?
In which we discuss the importance of memory, 
the activity of neurons and their connections, the 
encoding of memories in the brain, the mechanisms 
of neural plasticity, and memory storage capacity
T
he pursuit ends, under torrential rain, on the roof 
of an abandoned building in a postapocalyptic Los 
Angeles. Rick Deckard (Harrison Ford), the android 
hunter, can barely crawl backward as he tries to escape his fate 
at the hands of Roy Batty (Rutger Hauer), a Nexus-6 android 
and leader of the “replicants.” Seconds before, Batty hauled a 
falling Deckard, his enemy, to safety, and now he stands over 
him while Deckard looks up, confused, afraid, defiant. The 

2	
T H E  F O R G E T T I N G  M AC H I N E
replicant observes a vanquished Deckard still fighting for his 
life and, on the brink of death himself—a death timed and 
preordained by his manufacturer—he takes a dove between 
his hands, sits in front of Deckard, and says:
I’ve seen things you people wouldn’t believe. Attack 
ships on fire off the shoulder of Orion. I watched 
C-beams glitter in the darkness at Tannhäuser Gate. 
All those moments will be lost in time, like tears in 
rain. Time to die . . .
I begin this book with the final scene of Blade Runner1 
because Roy Batty’s words perfectly illustrate how memory 
relates to questions about who we are—about what it means 
to be human, and what makes up our identity. Roy Batty’s 
memories are indeed what distinguish him from other rep-
licants. These memories are what make him feel like a per-
son despite not being human, and justify his urge to cling to 
and prolong his short life. He may be an android, but Batty’s 
lament is one that feels familiar to all of us, when we won-
der if all the memories that constitute our selves and feel so 
enduring are in fact ephemeral, and may be lost—like tears 
in the rain—when we die and our brain perishes.
The Encyclopaedia Britannica defines memory as “the 
encoding, storing, and retrieval in the human mind of past 
experiences.” As such definitions go, the one given by Bri-
tannica is somewhat narrow and provides but a minimal 
glimpse of the scope of the problem—on the other hand, 
these dry words are quite interesting because they raise a 

	
H o w  D o  W e  S t o r e  M e m o r i e s ? 	
3
myriad of questions. For example, this definition refers to 
“the human mind.” Blade Runner is a science fiction classic 
itself based on another classic of the genre, Philip K. Dick’s 
Do Androids Dream of Electric Sheep? in which the hero at 
one point says, “The electric things have their lives too. Paltry 
as those lives are.” But do they? Aside from the fictional Roy 
Batty, could androids one day have inner lives and memo-
ries, like we do? What about other animals, or a computer? 
Do memories make them conscious of their own existence? 
How can we know if they are? As we delve deeper into the 
Britannica definition, we can also ask: What is the mind? Is 
it simply a working brain? Is it merely the activity of billions 
of neurons, or something more than that? And, if the former 
is the case, how do these neurons store and retrieve so much 
information about our lives?
Memory plays a leading role as we pose ourselves these 
questions. Not only does it underlie our ability to think at 
all, it defines the content of our experiences and how we pre-
serve them for years to come. Memory makes us who we are. 
If I were to lose my ability to hear and begin using a cochlear 
implant, I would no doubt continue to be the same person. 
If I were to suffer from heart failure and depend upon an 
artificial heart, I would be no less myself. If I lost an arm in 
an accident and had it replaced with a bionic limb, I would 
still be essentially me. To take this argument to its conclu-
sion: as long as my mind and memories remain intact, I will 
continue to be the same person, no matter which part of my 
body (other than the brain) is replaced.2 On the other hand, 
when someone suffers from advanced Alzheimer’s disease 

4	
T H E  F O R G E T T I N G  M AC H I N E
and his memories are obliterated, people often say that he “is 
not himself anymore,” or that it is as if the person “is no lon-
ger there,” though his body remains unchanged. Thus we see 
the importance of memory to arguments about who we are, 
about what constitutes our being and distinguishes us from 
other animals, robots, or computers.
Science is born from questions. These questions are what 
nourish and inspire scientists and drive their obsessive quest 
for answers. And science is the quest itself, not just the end 
of it. For a scientist, arriving at a final answer is no more 
important than triggering the cascade of questions and expe-
riencing the rush of fascination that propels the exploration 
of them. If reaching the final answer were all that mattered, 
science would be extremely frustrating, because the truth is 
that many questions will remain unanswered, perhaps for-
ever. In the last few decades, neuroscience has advanced far 
more than in all the previous history of mankind, and yet 
many of the most profound queries, perhaps those that fas-
cinate us the most, are still there, beckoning. To make mat-
ters even more interesting, these questions transcend the 
domain of science. As we try to understand how the activity 
of neurons encodes the remembrance of our experiences, 
we are inevitably led to ask about self-awareness, about the 
thing that makes us feel that we are a person. As we ponder 
the distinction between mind and matter, we find ourselves 
discussing topics considered by Plato, Aristotle, Descartes, 
and many others, topics that are endlessly revisited by the 
philosophers of the twenty-first century and that recur 
again and again in literature. These are the topics of artificial 

	
H o w  D o  W e  S t o r e  M e m o r i e s ? 	
5
intelligence and neuroscience conferences but also science 
fiction movies—topics that touch everything from ethics and 
religion to education and our relationship with technology.
If I could choose only one of this book’s messages to 
impart—just one—it would be the vastness of the prob-
lem, the fascination born from exploring the workings of 
our memory and attempting to understand how our brain 
achieves such momentous feats as reconstructing details 
from the last scene of Blade Runner, the bars of a Beethoven 
symphony, or fleeting moments from our childhood.
Many think of the brain like a black box—a complex, mys-
terious organ that generates both mind and thoughts and 
is able to treasure memories that can be retrieved to con-
sciousness on command. This is enough for some, but for 
others (neuroscientists among them) the mystery is not the 
end but the beginning. Like a child who listens to a radio and 
must remove the screws to see what is inside—and, once the 
radio’s innards are exposed, turn its dial and push its but-
tons to see what they do—the initial question gives rise to 
more questions, and to the inevitable realization that we still 
understand almost nothing.
When it comes to the brain, though, some things we do 
understand. So let us begin by discussing the basics—with 
neurons. In the same way that transistors are the basis of 
electronic circuits, neurons are the basis of brain function, 
arranged in groups, connected with one another in networks, 
producing with their activity our ability to see, listen, feel, and 

6	
T H E  F O R G E T T I N G  M AC H I N E
remember. But how do neurons generate the different func-
tions of the brain? How does their activity result in our ability 
to write, run, or be aware of our existence? This is the ques-
tion that, in its various nuances and facets, we neuroscientists 
ask ourselves every day, and despite the fact that we are so far 
unable to answer it fully, there are some elementary principles 
we’ve come to rely on that are relatively easy to grasp.
Figure 1.1: Network of neurons
Image adapted from an original drawing 
by Santiago Ramón y Cajal
Neurons have basically two states: they are either at rest or 
producing what we call action potentials, i.e., being active or 
“firing.”3 Just as a transistor transmits current to other parts 
of a circuit, neurons transmit their firing to other neurons 
(through the axons) and receive the firing of other neurons 

	
H o w  D o  W e  S t o r e  M e m o r i e s ? 	
7
(through the dendrites). But the analogy with an electronic 
circuit ends there, because the contact between neurons is 
not electrical but chemical. When activated, neurons gen-
erate electrical discharges at the ends (or terminals) of their 
axons, which release chemical compounds called neurotrans-
mitters. Through a process called synapsis, these neurotrans-
mitters are received by receptors on the dendrites of other 
neurons, in turn generating small electrical discharges in 
them. The workings of many drugs rely upon this chemical 
interface: painkillers, tranquilizers, and hallucinogens do 
nothing more than alter the balance of neurotransmitters in 
the brain and the capacity of neurons to receive and transmit 
information. It is also key to understanding certain cogni-
tive processes—for example, reward mechanisms that result 
from discharges of the neurotransmitter dopamine. More 
importantly for our purposes, neurotransmitters like gluta-
mate play an important role in strengthening or weakening 
connections between neurons, which is precisely how mem-
ories are formed.
When does a neuron fire? When the activity it receives 
from other neurons exceeds a certain threshold. This mech-
anism gives rise to a variety of firing patterns determined, 
among other things, by the connections between neurons. 
For example, a given neuron, N, may fire due to the activ-
ity of the neurons that connect to it, and then transmit this 
activation to several other neurons. In turn, one of these 
latter neurons may transmit a discharge back to neuron N, 
prompting it to fire again. The variety of potential behaviors 
of a network of neurons is further enriched by the fact that 

8	
T H E  F O R G E T T I N G  M AC H I N E
activation patterns depend on the types of neurons involved. 
Excitatory neurons discharge neurotransmitters like dopa-
mine and glutamate, which (in general) stimulate activity, 
while inhibitory neurons discharge neurotransmitters like 
gamma-aminobutyric acid (or GABA), which suppress it.
Figure 1.2: Synapsis
The electrical discharge of a neuron is transmitted (from 
the terminals of its axon to the terminals of the dendrites 
of the neurons that connect with it) by the release of 
neurotransmitters, in a process called synapsis.
Among neuroscientists, there are a surprising number of 
physicists (myself among them) who at some point in their 
scientific careers decided to take the plunge and dedicate 
themselves full-time instead to the study of the brain. Inves-
tigating the activity of neurons and neural networks—and 
how this activity gives rise to different firing patterns and 
replicates cerebral functions—is one of the favorite pursuits 
of many physicists-turned-neuroscientists, the practitioners 

	
H o w  D o  W e  S t o r e  M e m o r i e s ? 	
9
of a discipline known as computational neuroscience. One of 
the field’s pioneers is John Hopfield, an American physicist at 
Princeton University, who described what we now call Hop-
field networks.4 Basically, Hopfield networks provide a model 
for how the chaotic activity of a neural network can organize 
itself into stable configurations that represent different mem-
ories. Let us imagine a network of interconnected neurons, 
each either firing or silent. “Memory A” corresponds to a 
particular configuration of the network—for example, silent, 
firing, firing, silent, silent, . . . (or, in binary language, 0, 1, 
1, 0, 0, . . .); another memory, “Memory B,” corresponds to 
a different configuration—for instance, silent, silent, firing, 
firing, firing, . . . (0, 0, 1, 1, 1, . . .); and so on.
Figure 1.3: Neural representation of two different memories
Memory A corresponds to the neurons highlighted in 
gray and Memory B to those highlighted in black.

10	
T H E  F O R G E T T I N G  M AC H I N E
From a given initial state, the network converges to the 
closest memory. For example, the configuration 1, 1, 1, 0, 
0, . . . is closer to Memory A than Memory B, and so the 
network evolves until it reaches the pattern of Memory 
A; on the other hand, the configuration 0, 0, 1, 1, 0, . . . 
resembles Memory B, and so the network converges to that 
result. The process by which the Hopfield network, start-
ing from a given initial configuration, converges to that of 
the closest memory unfolds via methods imported from 
physics. Leaving details aside, as illustrated in Figure 1.4, 
the general idea is that from a network’s configuration, 
one can define a total network energy and create an energy 
landscape—each point in the landscape corresponds to a 
different configuration—assigning memories to energy 
minima determined by the connectivity patterns across 
the neurons. Then, starting from an initial configuration, 
the network evolves as a ball going downhill, progres-
sively reducing its energy (changing the configuration at 
each step) until it reaches the minimum that corresponds 
to the closest memory. The initial configuration that pro-
vides the starting point for evolution on this landscape 
might be the result of spontaneous variations, as when we 
retrieve a memory seemingly from nothing, or of activa-
tions triggered by a particular stimulus—like, for example, 
looking at Rick Deckard’s face while watching Blade Run-
ner. The image of Deckard activates a specific group of neu-
rons, which in turn activate others, and on and on, until 
we retrieve a representation that resembles our memory of 
him. Since our vision of Deckard changes (we may see him 

	
H o w  D o  W e  S t o r e  M e m o r i e s ? 	
11
straight on or in profile, shaved, wearing different clothes, 
etc.), the initial representation is not exactly the same as 
the one we store in memory, but, as long as it is similar, 
the network of neurons in our brain evolves until it arrives 
at a configuration that corresponds to our recollection of 
Rick Deckard, android hunter. Sometimes we may strug-
gle to recognize an acquaintance, for example, because he’s 
changed his hairstyle, or shaved after long sporting a beard, 
or simply because many years have passed. This increased 
difficulty in recognizing someone results from the differ-
ence between the pattern of activation generated by seeing 
the person and the one we have used to “store” this person 
in our memory.
Figure 1.4: Evolution of a Hopfield network
Starting from an initial configuration (at left), the 
network evolves by reducing its energy, gradually 
changing its activation pattern, until it reaches the 
closest memory (Memory A, in this case).

12	
T H E  F O R G E T T I N G  M AC H I N E
The Hopfield model offers us a plausible mechanism 
of the way the brain stores memories—as patterns of neu-
ral activations. Whereas the Britannica definition describes 
memory as a behavioral process, now we can also see it as the 
product of the physical activity of neurons. In other words, 
we have built a bridge between psychology and neuroscience, 
and have begun to peer inside the black box.
We saw that the Hopfield model assigns memories based 
on connectivity changes in the network. But how can the 
brain change which neurons are connected to each other? 
In short, while each neuron connects with some 10,000 
more, not all of these connections are active. Some are con-
stantly reinforced, like a high-traffic highway that offers a 
convenient link between two places, while others resemble 
a deserted, potholed street, one that could in principle con-
nect two places but in practice does not. Just as a path that is 
unused will eventually become overgrown and impassable, 
so neural connections that are seldom used may disappear. 
Building on our traffic analogy, changing the connectivity of 
a network is like blocking off some streets and rerouting cars 
to others instead, increasing their traffic. These connectivity 
changes eventually bring about changes in what information 
these neurons encode. This is known as neural plasticity, and 
it is the key mechanism used by the brain to generate and 
store specific memories.
The idea that memories relate to neural connectivity goes 
back to Santiago Ramón y Cajal, in the nineteenth century,5 

	
H o w  D o  W e  S t o r e  M e m o r i e s ? 	
13
but the most important contribution to this hypothesis 
was offered by Donald Hebb in 1949, in a book that would 
become one of the classics of neuroscience.6 Hebb postulated 
that the joint activation of neurons reinforces the connec-
tions between them, a phenomenon usually summarized in 
the famous phrase, “Neurons that fire together wire together.” 
This is hardly a far-fetched notion: if two neurons tend to fire 
at the same time, it is quite likely that this is because they 
encode similar information, and thus it makes sense that they 
are connected, and that their connection is reinforced. Simi-
larly, the wiring between neurons that tend to fire at different 
times is weakened. This process gives rise to the formation of 
what are known as Hebbian cell assemblies—that is, groups of 
interconnected neurons that represent different memories. 
Hebb’s theory was experimentally verified by Tim Bliss and 
Terje Lømo, who observed that the coactivation of neurons 
had a durable effect on strengthening their synaptic connec-
tions.7 This reinforcement in the wiring between neurons, 
called long-term potentiation or LTP, lasted for several weeks 
or even months under repeated stimulation, and provided 
clear experimental evidence of the mechanism underlying 
the formation and storage of memories. Confirming this, a 
great number of experiments have shown that blocking this 
LTP mechanism (by means of various pharmacological com-
pounds) inhibits the formation of memories.8
At this point, it seems that we have managed a general 
answer to one of our questions. The model offered by Hop-
field’s networks, along with the concept of neural plasticity, 
gives us an idea of how the activations of groups of neurons 

14	
T H E  F O R G E T T I N G  M AC H I N E
encode memories. However, as usual, this answer gives rise 
to many further questions. In particular, how can the brain, 
with its mere three pounds of matter, store so many mem-
ories in such rich detail? Or, more explicitly: Do we have 
enough neurons to account for such a feat?
The human brain has approximately 100 billion neurons, 
or 1011, a one followed by 11 zeros.9 For comparison, there 
are between two and four hundred billion stars in the Milky 
Way, putting the number of neurons in the brain on the same 
order of magnitude. To give you an idea of how many this is, 
if each of your neurons were a grain of sand, you would have 
enough to fill a cargo truck.10 Another way to think about 
the number of neurons we have is by their density—there 
are about 50,000 per cubic millimeter in the cerebral cortex, 
which means that roughly 50,000 neurons could fit on the 
head of a pin. As each neuron is wired to another 10,000, this 
puts the number of connections on the order of 10,000 times 
1011, or 1015, which is roughly the number of grains of sand in 
a beach 100 meters long.11
Given all this, it would seem the brain should have no 
difficulty in storing all of our memories. However, we face 
two problems. First of all, not all neurons are dedicated to 
storing memories. In fact, neurons with such a function may 
make up only a small fraction, since a significant number 
of neurons must also be devoted to visual and auditory pro-
cessing, motion control, decision making, emotions, and so 
on. Second, theoretical calculations show that the number of 

	
H o w  D o  W e  S t o r e  M e m o r i e s ? 	
15
memories that can be stored by a given number of neurons 
is limited because of interference effects: in short, if there are 
too many memories, they begin to become mixed up with 
one another. Calculations estimate that, given N neurons, a 
model like Hopfield’s can store some 0.14N memories with-
out interference.12 Hence, if we assume that, for example, just 
1 percent of the brain’s 100 billion neurons are involved in 
the encoding of memories,13 and considering that the total 
number of memories that can be stored would be only about 
14 percent of this number, this gives us a total of approx-
imately 108, or 100 million memories. Of course we must 
Figure 1.5
The number of neurons in the human brain is on the 
same order as the number of stars in the Milky Way.
The image of the Milky Way (left) was taken by the 
European Southern Observatory. The image of neurons 
(right) was taken by Julieta Campi in my laboratory.

16	
T H E  F O R G E T T I N G  M AC H I N E
take these estimates with a grain of salt, since the fraction 
of neurons devoted to memory storage could well be even 
less than 1 percent, or the brain might not store memories 
in the way Hopfield proposed but using some less efficient 
system, in which case our memory capacity would be further 
reduced. But even if the number of memories we can store 
were to be one or two orders of magnitude smaller—so about 
a million—the number seems large enough to be sufficient.
Alas, the limitation of the preceding arguments is that 
there is a deep chasm between understanding how the brain 
can use, say, Hopfield networks to encode single abstract enti-
ties like Memory A, Memory B, etc., and understanding the 
mechanism whereby it stores memories like those recalled 
by Roy Batty as he faced Deckard, or the many nuances and 
specific details we remember from a party with friends. In 
other words, we believe we remember our past as a movie 
that we can relive through memory. But how does the brain 
manage to store all these “movies” in such detail? How do 
we extrapolate from the mechanism for storing specific con-
cepts (Memory A, Memory B) to the process by which the 
brain does something much more complex, like reconstruct-
ing lived experiences? Moreover, even specific concepts have 
myriad forms and nuances. My mother in her red ball gown 
is quite different from my mother wearing an apron in the 
kitchen, or a yellow T-shirt on the terrace. We’ve seen how 
Hopfield networks might help us match any of these to a 
memory of “my mother,” but many of these nuances are also 
stored as memories in their own right. Each of these mem-
ories unfolds into many others, as my mother in her yellow 

	
H o w  D o  W e  S t o r e  M e m o r i e s ? 	
17
T-shirt on the terrace may be kneading pasta, drinking cof-
fee, or marinating meat for a barbecue. This is what is called 
combinatorial explosion: each concept gives rise to a multi-
plicity of more specific concepts, each of which in turn sub-
divides into many others, and so on.
So how do we do it? How do we store all this informa-
tion? The surprising answer is that we basically do not. We 
remember almost nothing. The idea that we remember a great 
deal of the subtleties and details of our experiences, as if we 
are playing back a movie, is nothing more than an illusion, a 
construct of the brain. And this is perhaps the greatest secret 
in the study of memory: the astounding truth that, starting 
from very little information, the brain generates a reality and 
a past that make us who we are, despite the fact that this past, 
this collection of memories, is extremely slippery; despite 
the fact that the mere act of bringing a memory to our con-
sciousness inevitably changes it; despite the fact that what 
underlies my awareness of a unique, immutable “self” that 
makes me who I am is constantly changing. This is precisely 
the subject of the following chapters, but before delving into 
the details of how little we remember, we begin by analyzing 
how much information from the external world—in particu-
lar, how much visual information—we perceive at all.


19
C h a p t e r  2
H O W  M U C H 
D O  W E  S E E ?
In which we introduce information theory, analyze 
the amount of visual information transmitted to 
the brain, and discuss the resolution of the eye, 
eye movements and their measurement using 
eye trackers, and the perception of art
A 
group of researchers at the University of Pennsylva-
nia asked the following question: How much infor-
mation gathered by our eyes is transmitted to the 
brain? To find out, they used guinea pigs, and recorded the 
activity of their retinal neurons as they were shown videos 
of natural scenes—the kind of visual information the eyes 
usually handle.1

20	
T H E  F O R G E T T I N G  M AC H I N E
To interpret the results of this experiment, we must first 
define what “information” is and understand how it can be 
measured by recording the firing of neurons. Let us imagine, 
for example, that the video viewed by our guinea pig subjects 
contained at any given time one of only two possible objects: 
a face or a plant. Mathematically, we can represent the con-
tent of the video at a given moment using a single binary 
digit,2 or a bit of information: 0 if the object is a face and 1 if it 
is a plant. Imagine now that the video can contain one of four 
possible objects: a face, a plant, an animal, or a house. In this 
case, representing the number of possible options requires 
two bits, or, in other words, two binary numbers: for exam-
ple, 00 may represent the house, 01 the animal, 10 the plant, 
and 11 the face.3 If a neuron fires with different intensity in 
response to each of the four objects, then from its firing we 
can discern which object is present in the video—and can say 
that the neuron provides two bits of information, which is as 
much as can be extracted from this video at a given moment. 
If the neuron fires with the same intensity to, for instance, 
“face” and “animal,” and with a second, different intensity to 
“house” and “plant,” then from its firing we can narrow the 
identity of the object to one of a group of two, meaning that 
in this case, the neuron provides one bit of information—half 
of what it was possible to extract from the video containing 
two bits of data. These principles, and the calculations they 
enable us to carry out, are widely used in neuroscience and 
make up what is called information theory, a discipline devel-
oped by Claude Shannon in the mid-twentieth century to 
study the coding and transmission of information.4

	
H o w  M u c h  D o  W e  S e e ? 	
21
Information theory underpins everything from the inter-
net to cellular technology, and today, the idea of measuring 
information in bits is commonplace. A group of eight bits, 
or a byte—initially representing the number of bits needed 
to encode the 256 characters of the ASCII code—is the unit 
by which we measure the storage capacity of a hard drive, 
some of the most frequently used measurements being the 
kilobyte (KB: one thousand bytes), the megabyte (MB: one 
million bytes), the gigabyte (GB: one billion bytes), and the 
terabyte (TB: one trillion bytes). The color-level resolution of 
a computer monitor or a digital image, technically known as 
“color depth,” is also expressed in bits. If a monitor displays 
a pixel using only one color (like vintage green phospho-
rous monitors of the kind used in The Matrix), then its color 
resolution is obviously one bit per pixel. A black-and-white 
monitor uses 8 bits (or one byte) per pixel, corresponding 
to 256 shades of gray, while a color monitor can have 24 bits 
(or three bytes) per pixel, one byte for each primary color 
(red, green, and blue) used to generate the rest of the color 
palette.5
Figure 2.1 shows four versions of a photo of Claude Shan-
non, each with a different resolution. The photo at top left is 
a 30 × 30 grid of pixels with one-bit color resolution and has 
the least information (30 × 30 × 1 = 900 bits); in it we can 
barely perceive a silhouette. To the right is a 300 × 300 grid 
in which the details of the photo are more readily recogniz-
able; the information in this photo is 300 × 300 × 1 = 90,000 
bits, or about 10 KB. Each image on the bottom contains the 
same number of pixels as the image immediately above it, but 

22	
T H E  F O R G E T T I N G  M AC H I N E
now each pixel has a color resolution of 8 bits. The photo at 
bottom right has 720,000 bits of information (300 × 300 × 8), 
or about 0.1 MB, making Shannon’s face clearly recognizable.
Figure 2.1
Images of Claude Shannon with 30 × 30 pixels 
(left) and 300 × 300 pixels (right), using one bit of 
color per pixel (only black and white, top) and eight 
bits per pixel (256 shades of gray, bottom)

	
H o w  M u c h  D o  W e  S e e ? 	
23
With our terminology firmly in place, let us return to the 
experiments by the researchers at the University of Pennsyl-
vania, and our original question: How much information 
do the eyes transmit to the brain? Using information theory 
to compute how much information the neurons had about 
the videos, the investigators concluded that, on average, the 
ganglion retinal neurons, which transmit visual informa-
tion to the brain through the optic nerve, encode between 
six and thirteen bits of information per second. Consider-
ing that the retina of a guinea pig contains about 100,000 of 
these ganglion neurons, and assuming each of these encodes 
information independently, this means that the brain of a 
guinea pig receives approximately one million bits of infor-
mation per second. Finally, given that the human eye has ten 
times as many ganglion neurons as that of the guinea pig, the 
researchers were able to estimate that the human eye trans-
mits information to the brain at around 10 million bits per 
second, or 10 Mbps, a number that may sound familiar since 
it’s the transmission speed of a standard Ethernet connection.
Let us dwell upon this result a little longer. The transmis-
sion of visual information to the brain occurs at about one 
megabyte per second. If we assume that on average we are 
awake sixteen hours a day, this means that the brain receives 
a total of 57.6 GB of information per day (3,600 seconds × 16 
hours × 1 MB). In other words, every two and a half weeks 
we could fill a one-terabyte hard drive with the content of 
what we have seen. But does the eye transmit everything 
within its reach?

24	
T H E  F O R G E T T I N G  M AC H I N E
In one of his much-anticipated presentations of Apple’s 
newest gadgets—one of the last such presentations he made 
as CEO of the company—Steve Jobs introduced the iPhone 
4. One of the phone’s main innovations was the “Retina” 
display, which is now standard in Apple products from the 
iPad to MacBooks. Jobs announced that Retina displays had 
a resolution of 326 pixels per inch (ppi), four times higher 
than that of the iPhone 3 and greater than the 300 ppi that, 
according to Jobs, is the maximum that can be resolved by 
the human retina with the iPhone held at a standard dis-
tance of between 10 and 12 inches (some 30 cm). In other 
words, the eye can barely distinguish individual pixels in a 
rendered image with a resolution of 300 ppi, from 30 cm 
away.6 If I stand 30 cm away from the whiteboard in my 
office, my field of view (that which I can see if I focus on a 
given point) is around 30 inches by 20 inches (75 cm hori-
zontally by 50 cm vertically). Thus, in principle, the number 
of pixels that my eye could perceive in my field of view is 54 
megapixels (that is, 30 inches × 300 ppi × 20 inches × 300 
ppi = 54,000,000 pixels), about ten times the resolution of 
the iPhone 4’s digital camera. (I say “in principle” because 
there is a flaw in the calculation—more about this later.) 
Of course, if I stand at a distance greater than 30 cm, my 
field of view expands, but this expansion is balanced by 
the loss of resolution that results from the increased range. 
As we saw before, the color of each pixel can be defined 
using three bytes, which means that 54 megapixels corre-
sponds to 54 × 3 = 162 MB of memory. To get a feel for 

	
H o w  M u c h  D o  W e  S e e ? 	
25
image continuity, a standard digital video camera captures 
30 frames per second. Thirty frames per second at 162 MB 
per frame gives a total of 4.8 GB processed by my eyes per 
second. The exact value of this number is irrelevant; what 
matters is the order of magnitude: gigabytes per second. 
According to the researchers at the University of Pennsyl-
vania, remember, the amount of information the eyes trans-
mit to the brain is about a megabyte per second. This means 
that there is a three-order-of-magnitude reduction between 
the information that could, in principle, be transmitted 
by the eyes and the information that reaches the brain. In 
other words, the brain “sees” only about one thousandth of 
the information in its field of view.
Why this enormous difference? Was there an error in our 
arithmetic?
The above numbers are mathematically correct—but 
they implicitly assume that the eye processes information 
with a uniform resolution of 300 ppi throughout the entire 
field of view. Assuming a uniform resolution makes sense, 
given that, for example, right now I am able to see every-
thing in front of me in full detail. Or, at least, I think I am. 
But the ability to see the external world in detail is nothing 
more than an illusion, a construct of the brain. What we 
actually see in detail is what lies at the center of our gaze, 
within a visual angle of one or two degrees. A small (less 
than 2 mm) depression at the center of our retina, called the 
fovea, is responsible for producing our area of clear, sharp 
vision—an area roughly the size of our thumbnail at the 
end of our stretched arm.

26	
T H E  F O R G E T T I N G  M AC H I N E
This fact, surprising as it sounds, is easy to corroborate. 
One need only extend both arms with the thumbs next to 
each other and pointing up; focusing on one of the two fin-
gernails makes it all but impossible to notice any detail of 
the other (if you doubt this, write a few letters on each nail 
and try reading them). Moreover, if we keep our gaze fixed 
on the first thumb and move the other arm a few inches to 
the side, we cannot even see the second thumb in detail, let 
alone its nail. How is it, then, that we see the world in front 
of us with such seeming clarity? The illusion arises from the 
fact that our eyes continually jerk from side to side, making 
unconscious movements called saccades.
Saccades can be recorded using a technique called eye 
tracking. A modern eye tracker consists of a camera that films 
the eye and, based on the position of the pupil, determines 
exactly where the subject is fixing his gaze.
In the image registered by an eye tracker in Figure 2.2, 
the center of the cross corresponds approximately to the size 
of the image projected to the fovea in the retina, and thus to 
what we can see sharply. The greater resolution in the fovea 
is the result of a high density of photoreceptors located there. 
The visual information gathered from outside that roughly 
1.5-degree visual angle that projects to the fovea is much 
more diffuse. To generate the impression that we see more 
than what falls within the fovea “in focus,” our eye scans the 
field of view at a rate of about three saccades per second.
 This presents a fascinating puzzle. To understand why, 
let us carry out a simple experiment: let us close our eyes, 
open them for one second, and then close them again . . .

	
H o w  M u c h  D o  W e  S e e ? 	
27
In that blink of an eye, we performed about three sac-
cades, meaning we saw in detail only about the area of three 
small coins. The rest was just a blur to the eye, even though 
Figure 2.2
A movable eye tracker consists of a camera mounted on a pair 
of goggles. Based on the location of the pupil, it computes 
where the subject is looking (the cross in the bottom image) 
within the field of view registered by a second camera.7

28	
T H E  F O R G E T T I N G  M AC H I N E
we feel as though we were able to see everything in front of 
us clearly. This is one of the wonders of the brain, one of the 
many mysteries that keep us neuroscientists awake at night. 
When we look at a face, for example, we think that we see 
all of its features in focus. In truth, however, our eyes simply 
stop at a few specific points, while the brain “fills in” the rest 
of the information. This effect was described in the 1960s by 
a distinguished Russian psychologist named Alfred Yarbus.8 
As Figure 2.3 illustrates, Yarbus showed that when we scan a 
face, we tend to focus on the eyes and the lines of the nose 
and mouth, which are precisely the most salient features of a 
person’s appearance.
Yarbus also showed that what we see is greatly influenced 
by the task we are performing, which determines our focus 
of attention, based on conscious and unconscious factors. 
The unconscious factors relate to the saliency of the infor-
mation; in other words, how much it stands out from its sur-
roundings. For example, a person wearing an orange T-shirt 
will clearly stand out in a group of people dressed in gray; 
a moving car will be more salient than cars parked on the 
street. The conscious factors, on the other hand, relate to 
what interests us as we scan a scene. If, in the crowd at the 
end of a soccer game, I am looking for my brother—who is 
wearing the jersey of his favorite team—my attention will be 
focused not on the passing cars or surrounding buildings, 
but on the people, especially those wearing that jersey. If 
instead my brother and I have agreed to meet at his car or at 
a nearby café, my gaze will concentrate on the parked cars or 
the local storefronts.

	
H o w  M u c h  D o  W e  S e e ? 	
29
Figure 2.3
Trace of visual fixations upon viewing a female face (example 
drawn from Yarbus’s book) and a self-portrait by Van Gogh9
The pattern of visual fixations illustrated in the figure 
tempts me to digress a bit. Van Gogh’s self-portrait at the Musée 

30	
T H E  F O R G E T T I N G  M AC H I N E
d’Orsay is one of the most stunning paintings by one of my 
favorite artists. Art is tremendously subjective and can elicit 
varying emotions in its beholders.10 In my case, as in that of the 
subject whose eye movements we show in Figure 2.3, I cannot 
help but stare enthralled at Van Gogh’s eyes in the portrait.
Why does art affect us so? Why can we be moved to tears 
by a painting whose subject we would barely notice if we saw 
it in a photograph? There are of course many aspects that 
distinguish a work of art from reality itself, but I would like 
to dwell on a particular aspect that is germane to what we are 
discussing in this chapter. When we look at a photograph, 
the resolution is uniform throughout the image. An image 
rendered at 300 ppi has that resolution at its center and at its 
edges, even though the former may be depicting a person’s 
features and the latter some irrelevant details of a background 
wall. When we see a photo, we choose where to look, either 
consciously or unconsciously, and in principle can observe 
each area of the image with the same resolution of detail. In 
a painting, on the other hand, the artist may paint one area 
in great detail and barely sketch another, alter contrast and 
color composition, or play with the texture of the canvas to 
shift the center of attention. In other words, the artist influ-
ences our natural patterns of visual exploration and decides 
for us what we should observe in detail and what we should 
ignore. In so doing, artists load scenes with subjectivity and 
share with us their specific vision and sensibility, something 
that goes well beyond the faithful reproduction provided by 
a standard photograph. Again, this is just one aspect among 
many that combine to infuse a work of art with emotional 

	
H o w  M u c h  D o  W e  S e e ? 	
31
meaning. To illustrate this digression, consider the example 
of a painting by Mariano Molina, a great artist and a friend.11 
In his Center of Gaze, Mariano manages to focus the viewer’s 
eyes on a specific place in the canvas. The center of gaze is the 
zone where the painting is “in focus,” where it has the greatest 
detail; it is precisely the area to which most visual fixations 
drift, as we corroborated using an eye tracker. This center of 
attention somehow entraps the eye movements and breathes 
into the canvas a sense of movement, a dynamic conceived 
in Mariano’s brain that was not present in the original photo 
that inspired the composition.
Figure 2.4
Visual fixation pattern of a subject observing Center 
of Gaze (Mariano Molina; acrylic on canvas)
Let us now return to the core topic of this chapter: How 
much do we see? To summarize our previous discussion: we 
found a three-order-of-magnitude difference (from gigabytes 
to megabytes) between the information present in our field of 

32	
T H E  F O R G E T T I N G  M AC H I N E
view and the information that the eye transmits to the brain. 
However, this difference disappeared once we accounted for 
the fact that we observe in detail only what is located in the 
fovea, at the center of our field of view. It is worthwhile to 
continue for a bit with these estimates because they illus-
trate and clarify some fundamental principles of how the 
brain works. Let us again consider Steve Jobs’s statement as 
he launched the iPhone 4: the resolution of the eye at a dis-
tance of 12 inches is around 300 ppi. To compute the amount 
of information that the eye receives from its surroundings, 
we now know that we can in principle disregard the rest 
of the field of view and concentrate on the area covered by 
the fovea, which at a distance of 12 inches corresponds to 
a circle with a diameter of 0.3 inches. Thus the information 
that arrives through the fovea is π × 0.152 (the area of the 
fovea) × 3002 = 6,361 pixels. We can again convert this num-
ber to bytes: recalling that one pixel has three bytes of color 
information, and assuming that we gather information at a 
rate of 30 frames per second (as does a standard video cam-
era), we find that the information collected through the fovea 
is about 0.5 MB per second. This value is now in the same 
order of magnitude as the 1 MB per second estimated by the 
University of Pennsylvania researchers to be the amount of 
information that the eye transmits to the brain. If we take 
into account the fact that the eye also receives information 
(albeit at a lower resolution) from the area around the fovea, 
the two estimates become even closer.
We have made great progress in our understanding of 
the way the brain processes visual information. However, we 

	
H o w  M u c h  D o  W e  S e e ? 	
33
have left out a crucial detail. So far we have described the 
encoding and transmission of pixels in the field of view, but, 
as we will see in the next chapter, this is far from how human 
sight actually works.


35
C h a p t e r  3
D O E S  T H E  E Y E 
R E A L LY  S E E ?
In which we describe the processing of information 
in the retina, the difference between sensation and 
perception, the use of unconscious inferences, cases 
of blind people who regained sight as adults, and 
the relation between perception and memory
A
s in a camera, the image that passes through the 
pupil is focused by a lens on the back of the eyeball. 
This is where the retina is located, and where the 
comparison to a camera ceases to be apt.
In the human retina, visual information is initially cap-
tured by two kinds of photoreceptors: rods and cones. Rods, 
of which a single human eye contains some 120 million, are 

36	
T H E  F O R G E T T I N G  M AC H I N E
what allow us to see in the dark. Extremely sensitive to light, 
they are concentrated on the periphery of the retina, out-
side the fovea. They cannot resolve color (which is why we 
cannot see color in the dark), and are inactive by daylight. 
Cones are much less numerous, on the order of six million, 
and are located mainly in the fovea. They are sensitive to 
red, green, and blue, allowing us to see clearly and in color 
at the center of our visual field. The information collected by 
the rods and cones is sent through the bipolar, horizontal, 
and amacrine neurons to the retinal ganglion neurons (the 
million cells which, as we saw in the previous chapter, trans-
mit visual information to the brain). Now, why do we have 
so many neurons, and of so many different kinds? Why do 
we have 126 million photoreceptors, if the information they 
collect is funneled into a mere one million retinal ganglion 
neurons? Moreover, as we just learned, the image on the 
fovea has a resolution of about 6,000 pixels—it seems absurd 
that we have six million cones for the task of resolving such 
meager information.
The answer is that the retina does not process or transmit 
visual information in the form of a simple re-creation of the 
pixels that make up the image. Instead, it transmits infor-
mation that will give rise to a representation of the image, 
generated not by the eye, but by the brain. As strange as it 
may sound, the eye does not see; the brain does. Why, then, 
are there so many neurons in the retina? Because the retina 
begins the processes that enable us to extract meaning from 
what we see.

	
D o e s  t h e  E y e  R e a l ly  S e e ? 	
37
One of the fundamental principles of visual processing in 
the retina was discovered by Stephen Kuffler in the 1950s. 
By registering the activity of the ganglion neurons of cats 
in response to light beams, Kuffler observed that a group 
of these neurons (called on-center) tended to fire rapidly 
in response to stimuli located within the cat’s field of view 
but dampened their activity if the stimuli occurred on the 
periphery of this “receptive field.” Other ganglion neurons 
(called off-center) had the opposite behavior, responding to 
stimuli in the periphery and inhibiting their firing if the cen-
ter was stimulated. This is what is known as center-surround 
organization.1
The great advantage of this is that, rather than simply 
reflecting the presence or absence of light via a sort of pixel 
bitmap, center-surround organization—created by the dis-
tribution of the different types of neurons in the retina and 
the connections between them—allows the detection of 
contrasts and edges. The brain thus receives information 
about lighting changes, differences between the center and 
the periphery of the receptive fields of these neurons. This 
is a very smart way to transmit information, and to focus 
on relevant aspects while discarding the rest. For example, 
when I look at the wall of my living room, I do not need to 
encode information about each individual pixel of that fea-
tureless expanse. It would be absurd to devote resources to 
such irrelevance. In fact, I only faintly perceive the gradual 
changes in the wall’s color as it is more illuminated closer 
to the window. On the other hand, I can very clearly per-
ceive the contrast caused by the presence of a painting on 

38	
T H E  F O R G E T T I N G  M AC H I N E
this wall, as well as the more sophisticated contrasts that 
define the different forms within that painting. This is pre-
cisely what center-surround organization enables us to do. 
To illustrate this idea, let us look at Figure 3.2. The gradi-
ent in background color makes the bar in the middle appear 
lighter toward the left and darker toward the right, even 
though it is actually the same color throughout. This effect 
is due to the fact that the retina does not perceive absolute 
color but, rather, color contrast.2
Figure 3.1: Center-surround organization 
of the retinal ganglion neurons
On-center neurons respond to stimulation of the center 
but inhibit their firing when the periphery is stimulated. 
Off-center neurons, on the other hand, activate when the 
periphery is stimulated and inhibit their activity when the 
center is stimulated. When both the center and the periphery 
are stimulated, the effects cancel each other, and activity 
is unchanged for both types of neurons. In each example, 
vertical arrows mark the instant when the stimulus is applied.

	
D o e s  t h e  E y e  R e a l ly  S e e ? 	
39
Figure 3.2: Illusion of contrast
Due to contrast with the background, the right 
side of the bar seems darker than the left, even 
though the bar has the same color throughout.
In the previous chapter, we saw that one way to select 
visual information is via saccades, directing the focus of our 
sight (and the multimillion-neuron machinery of the fovea) 
toward whatever catches our attention. Now we see that 
within the fovea itself there is a second information-selection 
mechanism based on the retina’s center-surround organi-
zation. These two mechanisms lay bare one of the primary 
principles underlying vision. Sight does not function like a 
camera. On the contrary, the brain selects a tiny amount of 
information and processes it redundantly and in parallel in 
order to extract meaning. This process continues in the cere-
bral cortex, where just in the primary visual area (or V1), 
there are a few hundred neurons for each neuron that trans-
mits information from the retina.3 Unlike a camera, which 
stores with equal resolution each bit of visual information, 

40	
T H E  F O R G E T T I N G  M AC H I N E
sight is highly directed. It is focused on capturing relevant 
information to convey meaning, not fidelity. After all, I am 
not interested in discerning the exact details of thousands of 
hairs in yellow contrasting with others in black; I just want 
to know it is a tiger and flee quickly. The processing of visual 
information in the brain is then much more sophisticated 
and complex than what a computer does to an image; it is 
nothing less than the result of millions of years of evolution.
The processes that underlie the way we select information as 
we fix our gaze on something that strikes us, the ways in which 
our neurons encode contrast and ignore homogeneity, have 
only been elucidated in recent decades. Yet the general theory 
of how we construct reality based upon the information that 
we receive through our eyes, and the distinction between sen-
sation (the physical stimulus impinging on the sensory organ) 
and perception (the interpretation of that stimulus) is much 
older. More than two millennia ago Aristotle postulated that, 
starting with the information received through the senses, the 
mind generates images that are the basis of thought. In On the 
Soul, Aristotle lays out a brilliant vision of the processing of 
sensory information that is worth quoting:
Thinking is different from perceiving and is held to be 
in part imagination, in part judgment . . . But what we 
imagine is sometimes false though our contemporane-
ous judgment about it is true; e.g., we imagine the sun 
to be a foot in diameter though we are convinced that 

	
D o e s  t h e  E y e  R e a l ly  S e e ? 	
41
it is larger than the inhabited part of the earth . . . To 
the thinking soul images serve as if they were contents 
of perception (and when it asserts or denies them to be 
good or bad it avoids or pursues them). That is why the 
soul never thinks without an image.
—ARISTOTLE, ON THE SOUL, 427B, 428B, 
431A (TRANSLATED BY J. A. SMITH)
These images—or ghosts, as they were called by Thomas 
Aquinas, who revisited Aristotle’s ideas in the Middle 
Ages—are our interpretation of reality, an interpretation that 
generates concepts from abstractions by eliminating details 
and extracting meaning. Similar distinctions between sensa-
tion and perception were made by the Egyptian astronomer 
Ptolemy and by Alhazen (or Ibn al-Haytham), a medieval 
Islamic scientist considered by many to be the father of mod-
ern optics. Moreover, the difference between external reality 
and the perception we have of it is the quintessence of ideal-
ism and the foundation of modern philosophy, which begins 
with Descartes’s search for absolute truth by way of doubt-
ing his perception of reality, continues with the overvaluing 
of subjective perception by the British empiricists (Locke, 
Berkeley, and Hume), and lies at the heart of Kant’s transcen-
dental idealism, which argues that we can only know the rep-
resentations that we make of things but never “Das Ding an 
sich”—the thing in itself.4
I cannot move on without mentioning Hermann von 
Helmholtz,5 who in the late nineteenth century—long 
before there was a well-developed neuroscience to back him 

42	
T H E  F O R G E T T I N G  M AC H I N E
up—described in detail the way the brain extracts meaning 
from the meager information provided by the senses. In 
particular, Helmholtz observed that the information gar-
nered by the eyes is very scant and that, based on past expe-
riences, the brain makes unconscious inferences in order to 
assign a meaning to what we see. Like Aristotle, Aquinas, 
and especially the empiricists, Helmholtz argued that we 
do not see copies of reality, of external objects, but signs, 
constructions fabricated in our brains. These signs need 
not resemble reality; it suffices that they be reproducible. 
In other words, it is not necessary for the representation 
I make of an object to be similar to the object itself; it is 
enough if I get the same representation every time I see the 
object. Helmholtz writes:
The objects in the space around us appear to possess 
the qualities of our sensations. They appear to be red or 
green, cold or warm, to have an odor or a taste, and so 
on. Yet these qualities of sensations belong only to our 
nervous system and do not extend at all into the space 
around us. Even when we know this, however, the illu-
sion does not cease . . .
—HERMANN VON HELMHOLTZ, 
THE FACTS OF PERCEPTION, 1878
The value that Helmholtz attributes to the knowledge 
obtained from unconscious inferences is related to the vision 
of the British empiricists, for whom the mind is a tabula rasa, 
a blank slate on which we etch our knowledge based on our 

	
D o e s  t h e  E y e  R e a l ly  S e e ? 	
43
experience and the perception of our senses. Helmholtz illus-
trates this idea with the extremely ambiguous sensation we 
have of an object when we touch it with our fingers. Imagine, 
for example, holding a pen with eyes closed. The perception 
of holding a single pen is beyond question, but the tactile 
sensation of each finger is vague and ambiguous—in fact, it is 
the same sensation we would have if we were holding several 
pens at the same time. We form the perception of touching a 
single pen not just by combining the tactile sensations of the 
fingers, but also by making unconscious inferences based on 
our previous experience, taking into account, for example, 
the relative positions of the fingers.
Optical illusions are a clear example of the way the brain 
uses unconscious inferences to construct meaning. In Fig-
ure 3.3 we see a classic illusion, the Kanizsa triangle, where 
we infer the shape of a triangle based on its angles and the 
apparent occlusion of another triangle in back. Even if we 
know that there is no such triangle, we cannot help but per-
ceive its sides. To the right we can see two circles in relief, 
one appearing to recede as if pressed into the surface and 
the other one appearing raised. They happen to be the same 
circle, rotated 180 degrees. The illusion of relief stems from 
what seems to be the reflection of light (at bottom and top, 
respectively) and our assumption based on experience that 
light always comes from above.
Another clear manifestation of the importance of experi-
ence in giving meaning to what we see is shown by the cases 
of people blind from birth who become sighted as adults (for 
example, after cataract surgery). Says Helmholtz:

44	
T H E  F O R G E T T I N G  M AC H I N E
Figure 3.3
Kanizsa triangle and illusion of relief
The memory traces of previous experience play an even 
more extensive and influential role in our visual obser-
vations . . . The fact that people blind from birth who 
afterward gain their sight by an operation cannot, before 
they have touched them, distinguish between such sim-
ple forms as a circle and a square by the use of their eyes 
has been confirmed even more fully by recent studies.
—HERMANN VON HELMHOLTZ, 
THE FACTS OF PERCEPTION, 1878
Helmholtz’s observation coincides almost exactly with 
the conclusions reached some two centuries earlier by John 
Locke, one of the most renowned British empiricists, by 
sheer force of thought. Asked by his friend Molyneux how a 
person blind from birth would perceive, say, a sphere and a 
cube upon seeing for the first time, Locke states:

	
D o e s  t h e  E y e  R e a l ly  S e e ? 	
45
[I] am of opinion that the blind man, at first sight, 
would not be able with certainty to say which was 
the globe, which the cube, whilst he only saw them; 
though he could unerringly name them by his touch, 
and certainly distinguish them by the difference of 
their figures felt.
—JOHN LOCKE, AN ESSAY CONCERNING 
HUMAN UNDERSTANDING, 1690, 
BOOK II, CHAPTER 9, SECTION 8
Similar arguments denying the possibility of knowledge 
divorced from experience were brought forth in 1709 by 
Bishop George Berkeley, another great British empiricist, in 
An Essay Towards a New Theory of Vision.
There are in fact multiple reports of people blind from 
birth who began to use their sight (note that I don’t say “see”) 
after surgery as adults. In general, given their lack of expe-
rience interpreting the information collected by their eyes, 
these people have vision problems.6 Richard Gregory and 
John Wallace reported the rare case of a patient (known by 
his initials, S.B.) who began to use his eyes at age fifty-two, 
after undergoing a cornea transplant.7 When they subjected 
him to a battery of visual tests, Gregory and Wallace observed 
that, among other shortcomings, S.B. could not infer depth 
or perspective from two-dimensional drawings (for exam-
ple, when seeing the famous Necker cube). Most interesting, 
however, is the description by Gregory and Wallace of S.B.’s 
initial visual experiences:

46	
T H E  F O R G E T T I N G  M AC H I N E
S.B.’s first visual experience, when the bandages were 
removed, was of the surgeon’s face . . . He heard a voice 
coming from in front of him and to one side: he turned 
to the source of the sound, and saw a “blur.” He realized 
that this must be a face . . . He seemed to think that he 
would not have known that this was a face if he had 
not previously heard the voice and known that voices 
came from faces . . .
About three days after the operation he saw the 
moon for the first time. At first he thought it a reflec-
tion in the window, but when he realized, or was told, 
it was the moon, he expressed surprise at its crescent 
shape, expecting a “quarter moon” to look like a quar-
ter piece of cake! . . .
It was obvious that facial expressions meant noth-
ing to him, and that he could not recognize people by 
their faces, though he could immediately do so by their 
voices . . .
Gregory and Wallace also report that S.B. could recog-
nize capital letters, but not lowercase ones. This happened 
because S.B. had learned to identify capital letters by touch-
ing molds at a school for the blind but had never “felt” low-
ercase letters. In other words, his brain had a representation 
of capital letters, and when he saw them for the first time 
he was able to transfer this representation gleaned through 
another sense. On the other hand, he was not able to learn 
lowercase letters because he did not have a tactile represen-
tation of them.

	
D o e s  t h e  E y e  R e a l ly  S e e ? 	
47
We are reaching the end of our chapters about vision, in which 
we have explored the different strategies by which the brain 
extracts meaning from what we see—something that goes far 
beyond generating a copy of the information present in our field 
of view. In summary, first, the brain processes most visual infor-
mation in the fovea—our center of attention—disregarding 
the rest; second, it implements a center-surround representa-
tion to encode contrast in the retina, and third, it constructs 
signs arising from unconscious inferences based on previous 
experiences. As we will see later, this process of meaning con-
struction continues in the cerebral cortex.
We may appear to have digressed from our main focus, 
which is memory. However, I have decided to dwell on the 
details of vision for several reasons. Vision and memory are 
two very closely related processes. We cannot recognize an 
object if we do not have a memory of it. One of the most 
famous cases related by neurologist Oliver Sacks concerns a 
talented musician, Dr. P., who could not recognize photo-
graphs of his colleagues, his family, or even himself. Dr. P. 
could not recognize the faces of his students and could only 
tell them apart by their voices. According to Sacks, in an ini-
tial routine test this patient was unable to recognize his shoe 
once he had taken it off, and, absurd as it may sound, at some 
point mistook his wife’s head for a hat.8 Dr. P.’s is perhaps 
the most famous case of visual agnosia. There are essentially 
two types of visual agnosia, both resulting from brain dam-
age. Patients with apperceptive agnosia have difficulty rec-
ognizing objects because they cannot see them as a whole. 

48	
T H E  F O R G E T T I N G  M AC H I N E
They instead see disparate details that they cannot integrate. 
Patients with associative agnosia, on the other hand, can see 
the objects, can even copy them flawlessly in a drawing, but 
cannot say what these objects are because they cannot assess 
their meaning; in other words, the visualization of the objects 
does not evoke a representation, a specific memory.
Associative agnosia thus gives a clear example of the rela-
tion between perception and memory. Stressing this relation 
further, memories are usually generated from perceptions, 
since we tend to create memories of things we see or hear. But 
the most important reason to discuss vision as we probe the 
subject of memory is that the brain uses very similar strat-
egies to see and to remember. Both processes are based on 
the construction of meaning, an interpretation of the outside 
world that relies on selecting a minimum of information and 
making abstractions—while discarding a multitude of detail.

49
C h a p t e r  4
H O W  M U C H  D O 
W E  R E M E M B E R ?
In which we discuss the virtues of forgetting, 
Ebbinghaus’s principles, the subjectivity and fickleness 
of memory, the reliability of eyewitnesses, the 
amount of information that we remember, and the 
difference between human and computer memory
I
n the first of In Search of Lost Time’s seven volumes, Mar-
cel Proust relates how, on a cold winter day, the flavor of 
a madeleine that he had let soften in a spoonful of tea 
unleashed a torrent of memories of his childhood in Com-
bray. The taste of the cake on his palate led him to remem-
ber the madeleines dipped in tea that his aunt Léonie gave 
him on Sunday mornings, and this in turn brought back the 

50	
T H E  F O R G E T T I N G  M AC H I N E
image of his old gray house, the pavilion behind it built for 
his parents, the town, the town square, the streets he walked 
as he ran errands, the country roads, the flowers in his gar-
den, those in Mr. Swann’s park, the water lilies, the towns-
people, their houses, the church . . .
Proust’s acclaimed narrative illustrates how a specific 
stimulus, here the flavor of a madeleine, can release a stream 
of interrelated memories—even those long lost in recesses of 
the brain to which we do not usually have conscious access. 
Before he was transported there via the madeleine, Marcel 
had felt dejected at his inability to evoke the details of his 
childhood in Combray. I suspect we have all, every now and 
then, wished that reminiscences of our past were clearer and 
more detailed, and feel melancholy when we realize that even 
our most precious memories fade with the passage of time. 
In those moments, we look for triggers in photographs or 
elsewhere to help us summon up our pasts, we lament how 
precious little we remember, and wish we could remember 
more, much more.
However, even as we ponder this, we may realize that 
remembering more is not necessarily beneficial, because 
unconsciously we solidify the most pleasurable of our mem-
ories and forget the less-enjoyable details. We may remi-
nisce longingly about our childhood, but we conveniently 
forget the torture it was to get out of bed early for school 
morning after morning, the effort it took to sit for hours 
in class, or the tedium of homework. Forgetting gives us 
the pleasurable heartache of blurry photographs and unfin-
ished stories, a tango that laments the sorrows of our scarce 

	
H o w  M u c h  D o  W e  R e m e m b e r ? 	
51
memory while acknowledging that some things are better 
glimpsed dimly.
In “Funes the Memorious,” Jorge Luis Borges describes 
with remarkable insight the torment that would result from 
being able to remember everything. Writes Borges, “Funes 
remembered not only every leaf on every tree on every 
mountain, but also each time he had perceived or imagined 
it.”1 Funes ended his days lying in the darkness of his bed-
room, his mind so crammed with memories and irrelevant 
details that he could not sleep or think. In a vision akin to 
Borges’s, William James, the American psychologist and phi-
losopher who pioneered modern psychology, argued at the 
end of the nineteenth century that, paradoxically, it is neces-
sary to forget in order to remember; if we were to remember 
everything, we would be as handicapped as if we remem-
bered nothing.2
The virtues of forgetting have been acknowledged since 
antiquity (notwithstanding the concurrent appreciation of 
memory we will discuss in the next chapter). In his treatise 
on oratory, Cicero writes that Themistocles, the Athenian 
general and politician, refused to learn the science of mne-
monics, arguing that he preferred instead the advantages 
of forgetting.3 The importance of forgetting underlies the 
thoughts of Aristotle and especially of Aquinas. They may 
not express their posture as explicitly as James or Borges, but, 
as we saw in the previous chapter, according to Aristotle and 
Aquinas the interpretations we draw from the stimuli per-
ceived by our senses are like images or ghosts that we con-
struct in our minds and from which we abstract concepts. 

52	
T H E  F O R G E T T I N G  M AC H I N E
For example, when we see a horse, we generate the represen-
tation of an individual, a specific horse, and when we have 
seen many horses, we extract from such individual represen-
tations a universal, the concept of a horse. The creation of a 
universal concept from individual representations is based 
on abstracting common characteristics. This is the impor-
tance of forgetting: sweeping aside irrelevant details in order 
to form concepts. Borges describes this point brilliantly in 
“Funes the Memorious.” Says Borges of Funes:
Let us not forget that he was almost incapable of hav-
ing general, Platonic ideas. Not only was it difficult for 
him to understand that the generic term “dog” could 
embrace so many disparate individuals of diverse sizes 
and shapes; it bothered him that the dog seen in profile 
at 3:14 would be called the same as the dog at 3:15 
seen from the front. His own face in the mirror, his 
own hands, surprised him every time . . .  [Funes] was 
the lonely and perceptive spectator of a world at once 
multifarious, instantaneous, and almost intolerably 
precise.
—JORGE LUIS BORGES, “FUNES 
THE MEMORIOUS” FROM FICCIONES, 1994
Here I stop discussing the affinity of these ideas with 
Borges’s thoughts, because that is precisely the topic of 
another book.4 Clearly we do not want to remember every-
thing, but neither do we want to remember nothing. There 
must be a balance between remembering and forgetting. But 

	
H o w  M u c h  D o  W e  R e m e m b e r ? 	
53
where is that balance? How much do we remember? And, in 
particular, how can we estimate our memory capacity?
In the late nineteenth century, Gustav Spiller, a Hungarian- 
born English psychologist, set upon himself the momentous 
task of quantifying how much he remembered.5 To this end, 
he wrote down all the experiences he recalled from the differ-
ent stages of his life and enumerated all the specific memories 
that constituted each and every one of those experiences. This 
remarkable thought experiment led Spiller to estimate having 
about 100 memories during the first nine years of his life,6 some 
3,600 up to age twenty, an additional 2,000 between twenty 
and twenty-five, and around 4,000 more in the subsequent 
nine years, concluding that the average thirty-five-year-old 
has about 10,000 memories. Moreover, Spiller calculated that 
the sum of this person’s memories, in time lived (or, rather, 
relived), would amount to about half a day. Of course, these 
numbers are estimates, but it is worth noting that Sir Francis 
Galton7 and other more recent researchers have arrived at sim-
ilar figures.8 It is possible that at thirty-five we may have not 
ten, but fifteen, twenty, or even thirty thousand memories, and 
that evoking them all may take us not half a day but two, or 
even a whole week. Spiller’s quantitative estimates, as he him-
self acknowledges, are not completely reliable, but leaving aside 
the exact values of these numbers, it is astounding to grasp that 
such a massive amount of information is lost to oblivion.
The experimental and systematic study of mem-
ory was pioneered by Hermann Ebbinghaus, a German 

54	
T H E  F O R G E T T I N G  M AC H I N E
psychologist who in 1885 published the results of a set of 
precise—though unbearably tedious—experiments on the 
capacity of human memory.9 Ebbinghaus constructed 2,300 
nonsensical words, each composed of three letters (two con-
sonants surrounding a vowel), then selected random groups 
of these words and measured 1) how the number of words 
he could remember varied at different time intervals, and 2) 
how repeatedly revisiting the list of words made it easier to 
remember them later. From these experiments, Ebbinghaus 
derived two fundamental principles. First, given the fast 
decline in the number of words he could remember as time 
went by, he concluded that while some memories persist for 
hours, months, or years, others last for only a few minutes 
or even seconds. Nowadays, this principle is reflected in 
our division between long-term and short-term memory. 
Short-term memory allows us to remember information 
for brief time intervals and be conscious of the unfolding of 
present events. This is the memory that I use, for example, 
to remember what I want to say in this sentence as I fum-
ble for the right words. Long-term memory, on the other 
hand, is made up of the particulars that we select from the 
present—those that will become part of the past as we relive 
them in the future. Long-term memory is what I remember 
from my last birthday, the flavor of a fine wine, or the math-
ematical trick I need to compute an integral. Only a min-
ute fraction of our short-term recollections end up being 
cemented in our brains. But how do short-term memories 
become long-term memories? Ebbinghaus’s second princi-
ple deals with precisely this issue: repetition and practice 

	
H o w  M u c h  D o  W e  R e m e m b e r ? 	
55
make memories last; the more he repeated the nonsensical 
words, the longer he could remember them.
From Ebbinghaus’s results we see that repetition helps to 
strengthen memories, what is technically known as memory 
consolidation. Persistent, long-term memories are composed 
of those salient events that capture our attention—those 
memories that we repeatedly bring back to our conscious-
ness. In Theaetetus, Plato describes memory as etchings on 
a block of wax. The more we recall a memory, the firmer the 
etching. Plato’s image corresponds to the intuitive idea we 
have of memory, but, as we shall soon see, while repetition 
does indeed reinforce memory, the notion of static memories 
etched on our brains is very far removed from reality.
Figure 4.1: Ebbinghaus’s forgetting curves
The number of remembered words diminishes with time, but 
this decline in memory is reduced as the words are repeated.

56	
T H E  F O R G E T T I N G  M AC H I N E
Breaking with the line of experimental studies pioneered 
by Ebbinghaus, Frederic Bartlett, a British philosopher and 
psychologist of the early twentieth century, showed just how 
malleable and subjective memory actually is. According to 
Bartlett, the use of nonsensical words leads to a controlled 
situation that is too far removed from real life and neglects 
a most important factor: the creation of meaning. In other 
words, Bartlett argued that the study of the number of non-
sensical words that can be remembered at different time inter-
vals cannot fully explain the workings of day-to-day memory. 
Take, for example, what I remember about my breakfast this 
morning. The series of events that constitute my memory of 
this morning’s breakfast are interrelated; they have a context; 
they are not isolated facts. Suppose that I had toast and jam. 
This simple fact can have different contexts: perhaps I had 
toast instead of my usual bacon and eggs because I ate too 
much for dinner the night before, or maybe it was because 
I wanted to try a homemade jam that I bought at a craft fair 
a few days ago. The extraction of meaning is driven by the 
context. In the first case, I may not even remember the kind 
of jam I ate because it is irrelevant; in that context, what mat-
tered is that I ate toast because I wanted a light breakfast. In 
the second case, I will remember the kind of jam I ate because 
I chose my breakfast specifically to try it. In other words, even 
though the event itself is the same, the subjective experience, 
the memory that I will potentially store in my brain, is com-
pletely different. The context also helps recall the memory. 
If in a few days I try to remember what I had for breakfast 

	
H o w  M u c h  D o  W e  R e m e m b e r ? 	
57
today, remembering that I wanted to eat something light or 
try a homemade jam will lead me to remember, by different 
streams of associations, that I had toast and jam.
Let us now compare the remembering of experiences in 
given contexts with the rote memorization of random words: 
toast, jelly, dinner, breakfast, etc. In this case, the memoriza-
tion mechanism is completely different because it is devoid of 
context and meaning. This contrast is even higher if we com-
pare the memory of having breakfast with the memorization of 
nonsensical words like those used by Ebbinghaus: TOC, MIF, 
REP, etc. Clearly, there is an enormous difference between the 
memory mechanisms he studied and those we use in our daily 
lives. Despite this, Ebbinghaus’s two fundamental principles 
are universally accepted as true: we have two types of memory, 
short-term and long-term, and repetition aids memory con-
solidation. What Bartlett’s vision adds to our understanding 
of memory is the importance of extracting meaning, or, to use 
Bartlett’s own terms, the construction of a schema.
The experimental procedure used by Bartlett was sim-
ple and mostly descriptive; unlike Ebbinghaus, Bartlett con-
cerned himself only with elucidating general principles and 
did not use quantitative data. Basically, Bartlett had Cam-
bridge students read a Native American folk legend, “War 
of the Ghosts,” and then asked them to repeat the story to 
him.10 From these experiments, Bartlett concluded that the 
recollections of the story tended to be short and simplified, 
and that each student modified it based on his or her per-
sonal interpretation. When he asked the students to repeat 
the story at different time intervals (weeks, months, and even 

58	
T H E  F O R G E T T I N G  M AC H I N E
years after having read it), Bartlett observed that the subjects 
tended to change the story each time they repeated it, and 
that, in some cases, after many repetitions, the recollection 
had very little relation to the original story. More than the 
story itself, the subjects remembered the schema of the story 
that they had constructed based on the interpretation and 
associations they made at the time they read it. Using that 
schema as a starting point, they reconstructed the story in a 
different way each time, forgetting many details and uncon-
sciously inventing and adding others. Based on these results, 
Bartlett concluded that memory is a creative process, and 
that the consolidation of a memory, far from being the etch-
ing on wax envisioned by Plato, reinforces a schema—a sub-
jective representation that often changes the memory itself.
Just as the process of seeing differs greatly from the pix-
elated representation produced by a camera, memory differs 
greatly from a reproduction of our recollections as in a movie. 
That is precisely the reason why we dwelt at length on the 
description of the elementary principles of vision—because 
the same principles apply to memory. There is in fact a deep 
resemblance between Helmholtz’s sign construction, which 
we sketched in the previous chapter, and Bartlett’s construc-
tion of a schema. In one case we referred to vision and in the 
other to memory, but the processes that occur in our brains 
are essentially the same: they imply constructing a meaningful 
reality starting from unconscious inferences and then using 
this meaning, this sign or schema, instead of reality itself; it 
implies making abstractions based on selecting information 
and discarding innumerable details. In the previous chapter 

	
H o w  M u c h  D o  W e  R e m e m b e r ? 	
59
we saw how unconscious inferences give rise to visual illu-
sions; similar inferences give rise to fabulation—the consoli-
dation in our memory of incidents that do not correspond to 
actual experience.
An astounding example of the malleability of our recol-
lections was given by psychologist Elizabeth Loftus, who car-
ried out a simple but conclusive experiment.11 Loftus showed 
different subjects a video of a traffic accident and then asked 
them to estimate the speed of the cars that were involved in 
it. But now comes the interesting part: she asked one group 
of subjects to estimate the speed of the cars when they hit 
each other; she asked another group for the speed when they 
collided; a third group had to estimate the cars’ speeds when 
they smashed into each other; with the fourth group she used 
the word contacted; and with the fifth, she used bumped. The 
surprising result was that all subjects saw the same video 
in the same conditions, yet those who were asked using the 
word smashed gave the highest speed estimates, followed by 
those who heard collided, bumped, hit, and, finally, contacted. 
Even more surprising was that, a week later, Loftus asked the 
same subjects if they had seen broken glass at the scene of the 
accident. Thirty-two percent of the subjects who heard the 
word smashed answered (incorrectly) that they had, while 
only 14 percent of those who heard the word hit did.
Loftus’s results show how fragile our memories are and 
how they are prone to manipulation during the consolida-
tion process—all it takes is changing a single word in a single 
question. Beyond their scientific interest, these discoveries 
are of enormous practical importance because they highlight 

60	
T H E  F O R G E T T I N G  M AC H I N E
the subjectivity of eyewitnesses at trials, and how readily 
their testimony can be manipulated by the way in which 
questions are asked.12 It is estimated that, in the United States 
alone, more than 200 innocent people have been sentenced 
to prison after being incorrectly identified by eyewitnesses. 
Particularly notorious is the case of Ronald Cotton, which 
deserves to be recounted in detail for the telling evidence it 
provides of the fragility of memory.
In 1984, Jennifer Thompson, a college student in North 
Carolina, was raped by a person who broke into her home. 
With a knife to her throat, unable to escape, Thompson 
decided to focus on the rapist’s face and remember every one 
of his traits and features so that someday, if she survived the 
attack, she would be able to identify him and secure his con-
viction. Thompson helped a police sketch artist construct an 
initial likeness of the rapist. Police assembled a group of six 
suspects and showed their photos to Thompson to see if she 
could identify him. According to the detective in charge of 
the case,13 Thompson examined the photographs for about 
five minutes before identifying Ronald Cotton. Two days 
later, the detectives placed Cotton in a lineup and, after hes-
itating between two suspects, Jennifer Thompson identified 
him again. At that moment she was convinced that she had 
identified her rapist—even more so when she was told that it 
was the same person whose photograph she had previously 
singled out. There was no doubt in her mind. And yet she 
was wrong.
At the age of twenty-two, Ronald Cotton was sentenced 
to life in prison. Some time later, by chance, the prison 

	
H o w  M u c h  D o  W e  R e m e m b e r ? 	
61
admitted a serial rapist who hailed from the same town as 
Cotton and bore a passing resemblance to him—Bobby 
Poole. Cotton heard through the grapevine that Poole was 
the man who had actually raped Jennifer Thompson. Cotton 
managed to have the case reopened, but as she faced the two 
suspects, Jennifer Thompson once again, and with complete 
certainty, identified Cotton as the perpetrator and asserted 
that she had never seen Poole before. Finally, after spending 
nearly eleven years in prison, Ronald Cotton was exonerated 
when a then-new tool, DNA testing, proved his innocence 
(and Poole’s guilt) once and for all.
It is noteworthy that, despite having made a concerted 
effort to remember the face of her rapist during the attack, 
Jennifer Thompson wound up reshaping her recollection and 
remembering someone else, and was unable to identify the 
true culprit when he was in front of her. Even after being told 
of the incontrovertible evidence provided by the DNA test, 
it was Cotton’s face she saw when she thought back on the 
attack. So, how could she have been so convinced of some-
thing that just wasn’t true?
It is easy to argue in hindsight, but it is telling that 
Thompson hesitated for five minutes before choosing one 
of the six suspects from the photo array; had she been truly 
certain, her decision would have taken no more than a few 
seconds. She then dithered between two suspects at the 
police lineup. After that, she unconsciously consolidated an 
incorrect memory that went on to become her unquestion-
able truth.14 Jennifer Thompson did not act in bad faith or 
take lightly the matter of sending someone to prison for 

62	
T H E  F O R G E T T I N G  M AC H I N E
life; she simply acted in accordance with what she (errone-
ously) remembered.15
Summing up, we’ve seen that our memories are shaped and 
stored based on our interpretations of them. We described 
two experimental approaches to the study of memory: on 
the one hand, Ebbinghaus’s systematic and quantitative study 
of the number of nonsense words that he could remember 
at different time intervals, and, on the other, the efforts of 
Spiller and Bartlett, which, despite being more descriptive 
than exact, show clearly just how little we remember. Is there 
a way to blend these two approaches? Can we make a more 
reliable estimate of our memory capacity without resorting 
to experiments with nonsensical words or our vague and 
subjective remembrance of experiences?
In the 1980s, Thomas Landauer, an American psychol-
ogist, set out, in the spirit of Bartlett and Spiller, to estimate 
the amount of information that we remember, but using a 
more quantitative experimental approach.16 To that end, he 
studied the number of words people remembered a few min-
utes after reading a text sample; the time interval was long 
enough to render short-term memory negligible and allow 
the examination of long-term memory alone. Assuming an 
average reading rate of 180 words per minute, Landauer esti-
mated that his subjects stored in memory around 1.2 bits 
of information each second. This result is not restricted to 
textual memory, since Landauer obtained a similar number, 
between one and two bits per second, when he estimated 

	
H o w  M u c h  D o  W e  R e m e m b e r ? 	
63
the number of visual images the subjects could remember 
a short while after having seen them. These estimates led 
to several interesting conclusions. Assuming that people 
are awake sixteen hours a day, and taking into account the 
fading of memory with passing time (using data similar to 
Ebbinghaus’s forgetting curves), Landauer estimated that a 
seventy-year-old person stores about 109 bits of memory. In 
other words, in the course of a lifetime, we can accumulate no 
more than 125 MB of information. This estimate was based 
on remembering text and images, but Landauer argued that 
the information required by other types of memory (spoken 
dialogue, musical passages, etc.) is of the same order. The 
exact amount may be larger or smaller, but the undeniable 
conclusion remains that we remember very little of our life-
time experiences.17 Following Landauer’s calculations, a 128 
GB flash drive, whose chip is smaller than a thumbnail, can 
store one thousand times the memory that a human brain 
accrues in a lifetime. Does this mean a thirty-dollar flash 
drive is more powerful than a human brain?18 Obviously 
not. But as we study these estimates further, they begin to 
illustrate what distinguishes our memory from that of flash 
drives and computers.
In Chapter 2, we saw that with eight bits (that is, one 
byte) of information it is possible to represent the 256 ASCII 
characters used in text. Thus, if we assume an average word 
length of five letters19 and an average reading rate of 180 
words per minute (that is, three words per second), we come 
up with an information flow of 120 bits per second (bps). 
But this presupposes that we process text letter by letter. If 

64	
T H E  F O R G E T T I N G  M AC H I N E
instead we consider a more elaborate storage representation, 
for example one based on words as the smallest unit pro-
cessed, then the quantity of information drops to approxi-
mately 45 bps.20 The intriguing fact is that we do not store 
120 bps, or 45bps, but just 1 bps—because the representation 
we generate is much more sophisticated than that conveyed 
by letters or words. It is even more interesting to consider 
the amount of information we store from images. In previous 
chapters, we saw that the retina transmits approximately 10 
Mbps of information to the brain through the optic nerve. 
Thus the visual information that we end up remembering 
(according to Landauer, on the order of 1 bps) is less than a 
millionth of that transmitted by the eye to the brain, which, 
as we saw earlier, is in turn much less than the information 
present in our field of view. In other words, the memory we 
keep of all the images we see in a lifetime amounts to approx-
imately as much information as that sent by the eye to the 
brain in just two minutes.
On the other hand, we saw in Chapter 1 that there are 
100 billion (1011) neurons in the human brain. Considering 
that each neuron can encode one bit of information (by being 
either silent or active), then the brain would be able to store 
dozens of gigabytes. Some scientists go further and estimate 
that the brain can store one bit of information in each syn-
apse, of which there are some 1015; this corresponds to around 
1,000 TB or a petabyte of information.21 Again, whichever 
estimate we prefer, it is clear that the storage capacity of the 
brain greatly exceeds the amount of information that it actu-
ally stores (125 MB, according to Landauer’s results). This is 

	
H o w  M u c h  D o  W e  R e m e m b e r ? 	
65
because the brain’s machinery stores information in a very 
redundant way—with sets of neurons encoding, in parallel, 
specific aspects of the same piece of information—in order 
to derive meaning. This is precisely what distinguishes our 
human brains from flash drives or computers. A computer’s 
hard drive can store and faithfully reproduce scores of text 
passages, photographs, or videos, but it cannot understand 
them. The human brain, on the other hand, concentrates its 
resources on attributing meaning to the paltry amount of 
information that reaches it from the senses.
As Helmholtz and Bartlett argued, meaning is con-
structed by way of assumptions based on previous experi-
ence. A few years ago, an extraordinary magician and great 
friend, Miguel Ángel Gea, gave a talk on magic at a packed 
lecture hall at my university. He started by remarking that 
the people in the audience, mostly academics and university 
students, were cultured and intelligent, and thus . . . very easy 
to fool! Gea continued by explaining that “intelligent people” 
are constantly making assumptions about reality, and that 
the magician’s art consists of flouting these very assumptions 
as they go about their tricks. In fact, it is not a coincidence 
that magic tricks for children are completely different from 
those for adults: children notice details that grown-ups have 
learned to ignore completely with time.22
These assumptions, what Helmholtz called unconscious 
inferences, are part of our everyday lives, whether we are 
watching a movie, listening to music, crossing the street, 
reading, or playing sports. For example, an important aspect 
of music theory involves the use of tension and resolution. 

66	
T H E  F O R G E T T I N G  M AC H I N E
Tension is generated by building expectations (leading us, 
for example, to expect a tonal chord after a fifth) that are 
resolved at a time of the composer’s choosing.23 We may 
admire the genius with which a composer breaks with clas-
sical musical structure by inserting dissonance, changing the 
key or rhythm, etc., yet too much of this disruption renders 
us unable to predict what might come next, and as a result we 
generally find it unpleasant listening. Even musical styles that 
we think of as being chaotic and disordered follow recogniz-
able musical conventions.
We make inferences every time we watch a movie as well. 
Horror and suspense movies, in particular, manipulate our 
expectations and generate tension by leading us to predict 
that something is about to happen based on the music, the 
setting, or the length of a scene. Of course they also play with 
the surprise of the unexpected, but most of the tension they 
generate results from our prediction that something dramatic 
is about to occur—even, or especially, if we aren’t sure of the 
exact moment it will. Alfred Hitchcock, the master of cine-
matic suspense, once said that an explosion does not cause 
fright, but its expectation does; according to Hitchcock, 
showing a bomb before it explodes generates much more 
tension (and is thus far more spine-chilling) than having one 
explode unexpectedly.
Examples of the use of expectation and inference abound 
in sports: A goalkeeper sees the stance of the kicker and pre-
dicts where he will shoot the penalty kick; a tennis player sees 
how his rival moves as he hits the ball and predicts where 
the ball will go. Successful athletes avoid giving away clues 

	
H o w  M u c h  D o  W e  R e m e m b e r ? 	
67
that may allow rivals to make such predictions—or actively 
encourage false predictions by manipulating their opponents’ 
expectations.
Similar principles apply to everyday situations. If I get a 
response to a job application that begins, “Unfortunately . . . ,” 
I do not have to keep reading to know whether I’ve been hired. 
More fundamentally, the fact that, as noted previously, we 
process written information in a more sophisticated form 
than what is conveyed by letters or words underlies how we 
read; this is why an adult can read so much faster than a child: 
children read syllable by syllable, whereas adults tend to skip 
words by making use of unconscious assumptions. Similarly, 
I can infer the tone and to an extent even the content of what 
someone is saying just from his expression—a tool we often 
use when we are having a conversation in a loud room or in a 
language we do not fully understand. If I am at home and hear 
a voice that I do not immediately recognize, I do not com-
pare it to the voices of everyone I have met; I automatically 
sort through a much-narrowed set of possibilities. I assume 
it is someone from my family because the probability that it 
is someone else is very low. Likewise, if I hear a train, I know 
the sound is coming from the radio or the television, because 
even if I have a state-of-the-art audio system and the sound is 
identical to that of a train at the station, I know that there are 
no railroad tracks close to my house.
In short, the brain makes decisions about how to inter-
pret the information the senses provide by making infer-
ences based on previous experiences.24 Just as we think we 
see everything in detail, but in truth see only a fraction of 

68	
T H E  F O R G E T T I N G  M AC H I N E
the scene in our field of view and infer the rest, we’ve learned 
that we remember astoundingly little. We think we remem-
ber past experiences in detail, but in reality we remember 
only a few concrete facts and fill the gaps between them 
with assumptions. I think I remember what I did yesterday: 
I went by bike to the office, made myself tea as I read emails 
on my computer, then discussed some results with one of my 
students, had lunch, and so on. However, from all of these 
events, I may really remember only some of the conversation 
I had with my student—and then only if something about it 
was novel or notable. Everything else is part of my daily rou-
tine, to which I pay no attention and which I do not encode 
in my memory but rather presume based on experience. 
This is exactly the process that led Bartlett to find that his 
students remembered a shorter and more coherent version 
of the story they were given to memorize. They could not 
remember everything; they remembered a limited number 
of concrete facts and inferred the rest. The construction of a 
schema based on such inferences—remembering our subjec-
tive interpretation of reality rather than reality itself—is pre-
cisely the source of false memories that lead us to be certain 
of events that never happened.

69
C h a p t e r  5
C A N  W E 
R E M E M B E R  M O R E ?
In which we describe the method of loci, the importance 
of memory in antiquity and today, the rebirth of 
the art of memory after the Middle Ages, the case 
of the man who could not forget, and savants
L
egend has it that the ancient Greek poet Simonides was 
called to the door to receive a message during a ban-
quet, and just at that moment, the roof of the room he 
had just left collapsed, crushing all the other guests.1 When 
the rubble was cleared, the bodies found were too disfigured 
to be recognizable. However, Simonides was eventually able 
to identify the bodies by remembering where each guest had 
been seated. From this experience, Simonides inferred that 

70	
T H E  F O R G E T T I N G  M AC H I N E
sorting memories was the key to preserving them, and he 
went on to invent mnemonics, the art of harnessing various 
techniques to enhance memory. In particular, Simonides 
developed what is known as the method of loci (loci is Latin 
for “places”), which consists of associating objects with spe-
cific locations. To practice the method, we must visualize in 
detail a very familiar place, such as the street on which we live, 
and then distribute the items we wish to remember at specific 
points of this place in our minds. For example, if I want to 
remember a list of words—bread, chair, rock, car, book, glass, 
spoon, lamp, flower, sword, etc.—I can mentally distribute 
these objects along my street: there will be a large loaf of bread 
on the corner, and a chair in front of the door of the day-care 
center by that same corner; I shall place an enormous rock 
by the bus stop, and a yellow Ferrari just beyond the stop; at 
my neighbor’s door I’ll leave a huge book on a stand; in front 
of my house there will be a large glass full of effervescent liq-
uid; my other next-door neighbor will have a giant spoon at 
her door, and the crosswalk will get a vast standing lamp that 
goes on and off whenever someone crosses the street. Fur-
ther along, at the entrance to the school, there will be a mam-
moth flower greeting students, and I will put a monument to 
a sword in the middle of the park.
Now, to remember the list of words, all I have to do is 
take an imaginary stroll down my street and note the objects 
I placed along it as I pass them by. I chose my street, but the 
chosen place could also have been the stretch from my front 
door to the garden (walking through the entrance hall, the 
living room door, the dining table, the couch, the television, 

	
C a n  W e  R e m e m b e r  M o r e ? 	
71
the garden door, etc.), the route I take to go to work, or any 
other spatial arrangement that is both very familiar to me 
and that, ideally, has many reference points at which to place 
the objects that I want to remember. The power of this asso-
ciation is such that, even though I chose the words at ran-
dom, I feel that they have been fixed in my memory at the 
places where I left them. In a few weeks, a few months, or 
even a few years, I will be able to remember most, if not all, of 
them.2 It is easy to corroborate the soundness of the method 
of loci by using, say, the same list of words as above (bread, 
chair, rock, etc.) and taking a few minutes to compare one’s 
ability to remember them by employing Simonides’s method, 
with the ability to recall a similar list of words (for example, 
painting, socket, television, clock, grass, ball, suitcase, ket-
tle, boat, milk) by repeating those words until they stick in 
your mind. We may be able to remember both lists after a few 
minutes, but after a few hours we will certainly remember 
the first much better than the second.3
For the method of loci to work, it is essential to choose 
eye-catching visual images to represent the objects we wish 
to remember. It is no coincidence that in the example above 
I highlighted the size and prominence of the images I used: 
a yellow Ferrari, a lamp that toggles on and off whenever 
someone crosses the street, a flower that greets schoolchil-
dren, a monument to a sword, and so on. An enormous rock 
at the bus stop is, in fact, much easier to remember than a 
rolling pebble; a giant spoon resting against my neighbor’s 
door is easier to see and remember than a teaspoon lying 
on the sidewalk. The same method can be extended to other 

72	
T H E  F O R G E T T I N G  M AC H I N E
kinds of words. If I want to remember the name of a person, 
I can imagine this person at the bus stop smoking a cigarette, 
or juggling balls, or declaiming a poem with a megaphone. 
Any of these images will be more striking and memorable 
than one of the person simply standing at the bus stop doing 
nothing. Creating mental images also works to remember 
more abstract words. For example, if I want to remember the 
word “love,” I can imagine a couple kissing in a passionate 
embrace; if I want to remember the word “justice,” I can envi-
sion a judge in a black robe holding court, and so on. In the 
same way, we can remember lists of numbers by associating 
each number with an image.4
Obviously, as we practice, if we wish to remember more 
items, we will need more reference points. For example, in 
the path through my house to the garden, I can define other 
locations: the fireplace, the kitchen door, the stereo; I can 
place up to six different objects on the dining table, one by 
each seat; I can put three objects on the couch, one on each 
cushion. The important bit here is to maintain the spatial 
order so that, as I imagine going from the front door to the 
back gate, the sequence of reference points is always the same.
The method of loci illustrates several interesting aspects 
of how memory works. First, as Simonides observed, it is 
important to organize the items we are trying to remember, 
in order to avoid interference—that is, having some mem-
ories blocking others. For example, after an unstructured 
learning of the previous list of words, I may have problems 
recalling spoon because bread, car, and chair come to my 
mind, whereas the access to this item is much more effective 

	
C a n  W e  R e m e m b e r  M o r e ? 	
73
when I can recall that spoon (and not bread, car, or chair) 
is the item by my neighbor’s door. Second, it places empha-
sis on vision. According to Cicero (De oratore II, LXXXVII, 
357), Simonides understood that sight was the most import-
ant of the senses. In fact, we now know that a significant 
chunk of our brain is devoted to visual processing. Images 
use the machinery of our brain to its fullest extent and are 
far more memorable than numbers, letters, or words. Third, 
the method of loci highlights the importance of associations, 
in this case, of places with people or objects. In general, 
when we go back to a place, we remember not only the place 
itself but also whatever we did there. Fourth, the method of 
loci avails itself of the fact that the most memorable events 
are those that best capture our attention, using remarkable 
images that are ideally charged with emotional content. I can 
more easily remember my mother standing on a corner than 
I can remember an unfamiliar woman standing there.
What practical relevance, if any, does the method of loci have 
today? After all, I can simply jot my grocery list on a slip of 
paper, I need only press a button to dial numbers stored in 
the memory of my phone, and with GPS there’s no need to 
remember the way to a friend’s house. In contrast, exercis-
ing and honing memory was crucial in antiquity, when there 
were no computers, cell phones, GPS devices, or even paper.5 
If I have to give a one-hour talk at a conference, I can pre-
pare a set of slides (in PowerPoint or Keynote for Mac) to 
aid my memory as I deliver the presentation. I do not have 

74	
T H E  F O R G E T T I N G  M AC H I N E
to memorize the talk in detail because I can be reminded of 
what I want to say as I am prompted by the slides. Back in 
my college days, these tools were not available, but professors 
lectured using notes they had prepared on paper (though a 
few did lecture from memory after having taught the same 
course over and over).
Now imagine the case of a Roman senator who has to 
argue, for example, in favor of a tax increase. He may want 
to argue that, given the threat from Carthage, it is essential 
to build new warships; he cannot neglect to mention that it 
is critical to maintain a strong militia to combat the Persian 
empire; that it is necessary to fund the construction of a new 
temple and repair the aqueducts; etc. Each of these facts is 
vital, and the senator does not want to forget any, but since he 
has no paper to record them, he must resort to his memory. 
Thus the importance of mnemonics in antiquity—especially 
for public speaking. In fact, it is no coincidence that two of 
the era’s seminal treatises on memory were Cicero’s De ora-
tore, and Institutio oratoria by Quintilian.6 The latter author 
has this to say on the subject:
We would have never known how great and divine the 
power of memory is, were it not for the fact that it is 
memory that has brought rhetoric to its present glory. 
It provides the orator not just with a way to remember 
his thoughts, but even his words. 
—QUINTILIAN, INSTITUTIO 
ORATORIA, XI, II, 7–8

	
C a n  W e  R e m e m b e r  M o r e ? 	
75
In one of Plato’s dialogues, Critias argues (before giving a 
speech and after having been advised to invoke various dei-
ties) that:
besides the gods and goddesses whom you have men-
tioned, I would specially invoke Mnemosyne [the 
ancient Greek goddess of memory]; for all the import-
ant part of my discourse is dependent on her favour, 
and if I can recollect and recite enough . . . I doubt not 
that I shall satisfy the requirements of this theatre.
—PLATO, CRITIAS (TRANSLATED 
BY BENJAMIN JOWETT)
In antiquity, a good memory was seen as a great virtue, 
and there are many accounts of persons with extraordinary 
powers of recall. For example, it was said that Seneca, the 
Roman philosopher who was an advisor to Nero, could 
repeat two thousand names in the same order they were 
given to him; Charmadas, of Greece, could recite by heart 
a book as though he were reading from it; Mithridates, king 
of twenty-two nations, could administer justice in every 
language spoken in his empire; Cyrus, king of Persia, knew 
the names of all his soldiers, while Lucius Scipio knew the 
names of all in Rome, and Cineas, King Pyrrhus’s ambassa-
dor, learned the names of all the Roman senators just one day 
after arriving in the city.7 This list must also include Metro-
dorus of Scepsis, who perfected the method of loci by dis-
tributing the items to be remembered over 360 partitions of 
the zodiac and who, according to Cicero, could etch in his 

76	
T H E  F O R G E T T I N G  M AC H I N E
memory everything he wanted to remember “as though he 
were engraving letters on wax.”8
The practice of oratory, and thus of mnemonics, was lost 
during the Middle Ages but was taken up again during the 
Renaissance, starting in the late fifteenth century.9 This 
rebirth of the art of memory can be attributed to several peo-
ple, among them Peter of Ravenna, an Italian jurist who in 
1491, a year before Columbus’s discovery of the New World, 
published Phoenix seu artificiosa memoria, a treatise on 
memory that was widely disseminated in his day. Peter of 
Ravenna wrote that his practice of memory enabled him to 
learn and recite, among other things, “the whole of the canon 
law, text and gloss . . . ; two hundred speeches or sayings of 
Cicero; three hundred sayings of the philosophers; twenty 
thousand legal points.”10 Curiously, regarding the application 
of the method of loci, Peter of Ravenna suggested using calm 
places as the locations in which to sort items to remember, for 
instance, placing a series of reference points within a familiar 
and sparsely visited church, though he also, apologizing in 
passing to chaste and religious men, suggested using striking 
images, such as those of comely virgins.
Later, in the early sixteenth century, Giulio Camillo envi-
sioned classifying and sorting information via an imagined 
grand theater with seven levels and seven sections, where 
each division was represented by a particular image and 
was associated with data and writings on different areas of 

	
C a n  W e  R e m e m b e r  M o r e ? 	
77
knowledge. The images in each section and level would bring 
about, according to Camillo, the ordered remembrance of the 
knowledge associated with them, in such a way that “who-
ever is admitted as a spectator will be able to discourse on any 
subject no less fluently than Cicero.”11 In particular, refer-
ring to the monumental task of distributing all the knowl-
edge of his time among the different divisions of his theater, 
Camillo argued that, “if the ancient orators, wishing to place 
from day to day the parts of the speech which they had to 
recite, confided them to frail places [the different reference 
points used in the method of loci] as frail things it is right 
that we, wishing to store up eternally the eternal nature of all 
things which can be expressed in speech . . . should assign to 
them eternal places.”12 Shortly thereafter, Giordano Bruno, 
the philosopher, cosmologist, and Dominican friar, built an 
elaborate mnemonic wheel consisting of rotating concentric 
circles with 150 divisions, each with different images and 
symbols to represent categories and items to be remembered. 
Given his revolutionary ideas, like his support of Nicolaus 
Copernicus’s notion of heliocentrism (while allowing for 
an infinite, unlimited space where intelligent life might be 
found on other planets, and regarding the sun as just one of a 
multitude of stars), his pantheistic vision of the human being 
as conscious matter reflecting the cosmic soul of the uni-
verse, and his use of pagan images and magical practices in 
his work on developing the art of memory, it is perhaps not 
unexpected to hear Giordano Bruno is sadly remembered as 
a martyr of science, executed by the Inquisition.13

78	
T H E  F O R G E T T I N G  M AC H I N E
Figure 5.1: Mnemonic methods of Camillo and Bruno
Reconstruction of Camillo’s theater (top) and of Giordano 
Bruno’s memory wheel (bottom left) as presented 
by historian Frances Yates, and a statue of Giordano 
Bruno in the Campo de’ Fiori, in Rome, where he was 
put to death by the Inquisition (bottom right)

	
C a n  W e  R e m e m b e r  M o r e ? 	
79
The flourishing, during the Renaissance, of literature on 
the art of memory left its traces in the writings of thinkers 
from Francis Bacon to Descartes and Leibniz.14 However, I 
would like to end this brief historical digest by chronicling a 
relatively more recent aficionado of the art, namely Solomon 
Shereshevskii, one of the most outstanding mnemonic prac-
titioners ever to have lived.
In the 1920s, Solomon Shereshevskii worked as a journalist 
for a Moscow newspaper. One day he visited a young Alexan-
der Luria—who would go on to become one of Russia’s most 
noted psychologists—and confessed to a problem: strange as 
it may sound, he could not forget. When a skeptical Luria 
decided to test Shereshevskii’s memory, he found that Shere-
shevskii could remember with no effort lists of thirty, fifty, 
and even seventy numbers. And not just that: he could repeat 
the list in forward or reverse order starting at any point. 
Shereshevskii simply continued to see the sequences in his 
memory, whether they were numbers, words, sounds, or 
meaningless syllables, after simply reading them. Such was 
Luria’s fascination with Shereshevskii that he studied the 
man for three decades and verified that Shereshevskii could 
keep these sequences in his memory for years after learning 
them, without expecting that he would ever be asked about 
them again.15
Shereshevskii’s astonishing memory was due to his use 
of the method of loci and, above all, to a very strong syn-
esthesia. People with synesthesia may mix perceptions from 

80	
T H E  F O R G E T T I N G  M AC H I N E
different senses, for example by associating numbers with col-
ors—“seeing” 3 as purple, 4 as yellow, etc. In Shereshevskii’s 
case, however, these associations went much further: every 
letter, number, or word set off an avalanche of visual imagery, 
sounds, tastes, and tactile sensations. As Luria reports, Shere-
shevskii could recognize and remember words not just by the 
images they evoked, but by the whole complex of associa-
tions that those images aroused. Numbers, for Shereshevskii, 
corresponded to specific images: 1 was a proud, well-built 
man; 2 a high-spirited woman; 3 a gloomy person; 6 a man 
with a swollen foot; 7 a man with a mustache; 8 a very stout 
woman—“a sack within a sack”—etc.
Figure 5.2
Images of Alexander Luria (left) and 
Solomon Shereshevskii (right)
Given his synesthesia, using the method of loci came 
naturally to Shereshevskii; the images were already fixed in 
his brain in extraordinarily rich detail. To remember a list 
of objects, Shereshevskii distributed them along a street of 
his hometown or a well-known avenue in Moscow and, once 

	
C a n  W e  R e m e m b e r  M o r e ? 	
81
he did this, he could take a mental stroll and simply recite 
out loud what he saw—like the orators of antiquity, but with 
a remarkable degree of precision. I will refrain from dwell-
ing longer on Shereshevskii’s incredible memory capacity, 
which has already been brilliantly described by Luria in his 
book. However, I would like to discuss, as Luria did, one very 
intriguing aspect of Shereshevskii’s case: What were the con-
sequences of having such a memory?
Shereshevskii eventually began a career as a professional 
mnemonist. For several performances a night, he would mem-
orize sequences written out for him on a blackboard by mem-
bers of the audience, and these sequences began to torment 
him as they amassed in his memory with no apparent limit. 
Shereshevskii’s torment inevitably brings to mind that of Ire-
neo Funes, the fictional protagonist of the Borges short story 
discussed in the previous chapter as we stressed the importance 
of forgetting.16 After falling off a horse and hitting his head, 
Funes became able to remember absolutely everything. Yet 
this ability, which would have seemed a godsend to an ancient 
Roman orator and was described by Pliny as almost heroic, 
the “greatest gift of Nature” that could be had by a person, was 
for Funes not just a handicap, but a curse. In fact, Borges con-
cluded that Funes “was not very capable of thinking. To think 
is to forget differences, to generalize, to abstract.”17
Just as Funes’s memories wound up being “a rubbish 
heap,” Luria describes the difficulties Shereshevskii experi-
enced due to his huge memory, and the paradoxical efforts he 
made to forget. Shereshevskii’s memory worked exclusively 
through visual imagery and employed no internal logic. For 

82	
T H E  F O R G E T T I N G  M AC H I N E
example, when he was asked to memorize a list of words that 
included—among other things—several bird species and 
later another list that included the names of several liquids, 
Shereshevskii could repeat both lists without effort . . . but 
was unable to name only the birds in the first sequence or the 
liquids in the second. Another time, Luria gave Shereshevskii 
a sequence that he remembered perfectly through the power 
of his visual memory . . . but without noticing that it was 
composed of consecutive numbers.
Shereshevskii’s lack of ability to reason or think abstractly 
meant he was incapable of understanding the content of what 
he read. Though he could recite long passages by rote and 
remember them for many years, he was unable to abstract 
the content of a book enough to apprehend its meaning. In 
other words, while ordinary people remember only a few 
facts, abstracting and inferring narrative so they can con-
tinue to follow a story as it develops, Shereshevskii had to 
fight against an overwhelming and uncontrollable tide of 
memories and associations, sparked by each and every word, 
that impeded his attempts to grasp the meaning of what he 
was reading. Moreover, Shereshevskii was sometimes unable 
to avoid noting and remembering small variations in the 
tone of voice of the person speaking to him and thus could 
not follow what he was being told. Even more striking is the 
fact that Shereshevskii found it difficult to remember faces, 
because, as he said, “people’s faces are constantly changing 
[and] the different shades of expression . . . confuse me.”
In the late nineteenth century, John Langdon Down, 
a British psychiatrist known for the syndrome that now 

	
C a n  W e  R e m e m b e r  M o r e ? 	
83
carries his name, reported on several cases similar to those 
of Funes and Shereshevskii. For example, he described the 
case of a boy who learned by heart Gibbon’s Decline and 
Fall of the Roman Empire without understanding the con-
tent of what he recited. Down called this “verbal adhesion”: 
memory without comprehension. Perhaps the most famous 
of these so-called savants (after the French word for “sage”) 
is Kim Peek, who became a celebrity when his life story 
was the basis for the movie Rain Man. Kim Peek’s mem-
ory, like Shereshevskii’s, was apparently unlimited and was 
tested time and time again in exhibitions. He knew the zip 
codes and area codes of thousands of US towns, as well as 
the names of their local television stations and nearby high-
ways; he had an unlimited capacity to recall historical facts 
from the last two millennia; he could name all the British 
monarchs in the correct order and tell the date of any base-
ball game; he could answer any question on American and 
world history, the lives of world leaders, geography, movies, 
actors and actresses, music—he could identify every piece 
of music he had ever heard and tell its date of composition, 
name its composer, and give the composer’s dates of birth 
and death—sports, literature, stories from the Bible, and so 
on.18 However, and like Shereshevskii, Kim Peek had a very 
limited capacity for reasoning. It was estimated that he had 
memorized the content of several thousand books, but he 
did not read fiction, or indeed any book that required imag-
ination or faculties beyond raw memory. Instead, he read 
only books that described facts without ambiguity or room 
for interpretation.

84	
T H E  F O R G E T T I N G  M AC H I N E
We’ve seen that the brain selects and processes rel-
atively little of the information available to it, and does so 
in a redundant way aimed not at scrupulous reproduction 
but at the extraction of meaning. In this sense, the mind of 
a savant mirrors more closely the behavior of a computer. 
Like a computer, the brain of the savant does not filter infor-
mation but simply records every detail literally, without con-
structing meaning and so without, eventually, being able to 
understand.

85
C h a p t e r  6
C O U L D  W E 
B E C O M E  M O R E 
I N T E L L I G E N T ?
In which we discuss how much of our brains we use; the 
value (if any) of training our memory; the impact of digital 
gadgets, the internet, and the information bombardment to 
which we are nowadays exposed; the differences between 
memorization and comprehension; as well as creativity and 
the (misguided) use of memory in the educational system
T
he title of this chapter would sound daring even for a 
self-help book. However, the purpose of this book is 
not to give advice on how to use the brain, but rather 
to describe some aspects of its workings—in particular the 

86	
T H E  F O R G E T T I N G  M AC H I N E
way memory functions. Why, then, choose such a bold 
title for this chapter? Because I believe it is worthwhile to 
analyze—better yet, debunk—some of the myths that abound 
in self-help literature, myths often used to support tech-
niques for “training the brain” that, in my personal opinion, 
fall very short of what they claim to achieve. As I write this, 
I am aware that I may seem to be contradicting myself. After 
all, I just spent nearly a full chapter extoling the wonders of 
the method of loci, an artificial technique to aid memory. I 
believe, however, that the historic and scientific analysis of 
that method clarifies some fundamental principles of the way 
memory works and, moreover, illustrates the importance of 
memory from antiquity to the present day. In antiquity, this 
interest centered on oratory and the ability to enshrine infor-
mation in a world where opportunities for documentation 
were scarce. Today, we ask ourselves about the proper role of 
memory in education, about the consequences of outsourc-
ing our memories to sundry gadgets, and, above all, about 
how the internet is affecting our brains.
We often hear that we use just 10 percent of our brain. A nat-
ural response to this is to wonder whether we could become 
smarter by learning to use a greater fraction. This is the prem-
ise of Lucy, the film by Luc Besson in which Scarlett Johansson 
learns to use an ever-larger fraction of her mental capac-
ity until her brainpower is such that she develops telepathic 
abilities. Lucy and its thoroughly unscientific premise aside, 
I would like to reframe the question raised in this chapter’s 

	
C o u l d  W e  B e c o m e  M o r e  I n t e l l i g e n t ? 	
87
title into one more pragmatic and specific: Can we train our 
memory to make use of more neurons? And will increasing 
the number of neurons we use make us more intelligent?
Let us take this step by step. First of all, it is not true 
that we use only a tiny fraction of our brain. We use all of 
it, though not all the time. In other words, while only a frac-
tion of our neurons are active at any given instant,1 nearly all 
of our neurons are active at some point, when their assigned 
functionality is required. If we used our whole brain, firing 
up all neurons simultaneously, not only would we need to 
gulp tablespoon after tablespoon of sugar to provide the glu-
cose necessary for such a high level of neuronal activity,2 but 
the specific functions of the different neurons would become 
jumbled. Thus, activating all of our neurons at the same time 
would do nothing to improve our intelligence. In fact, many 
epileptic seizures are characterized by generalized neuronal 
activation. There is still much left to learn about epilepsy,3 but 
some of the basic mechanisms are well understood. In partic-
ular, epileptic seizures tend to begin with the development of 
pathologic activity in a specific area of the brain, known as the 
epileptic focus. The abnormal activity of these neurons spills 
over into neighboring areas and, eventually, to the rest (or 
at least a significant portion) of the brain. When the seizure 
takes over, neurons fire frenziedly, and EEG scans show sharp 
increases in amplitude that resemble seismographic readings 
during earthquakes. At that point, far more than 10 percent of 
the brain’s neurons are active, but instead of acquiring Lucy’s 
supernatural powers, the brain’s owner loses consciousness, 
in most cases remembering nothing afterward.

88	
T H E  F O R G E T T I N G  M AC H I N E
Having established that using more of the brain at once is 
not the path to mental superiority, we can ask ourselves if it is 
nevertheless worth the trouble to try to remember more. On 
the one hand, as we studied the cases of Shereshevskii, Funes, 
and the savants in the previous chapter, we saw that remem-
bering too much can lead to significant mental handicap. On 
the other hand, those of us without Shereshevskii’s synesthesia, 
Funes’s head injury, or the unusual minds of savants may be 
able to stop short of their surfeit of remembering, and train our 
memories to our benefit. How many times have we been frus-
trated by the inability to recall a certain word? How often do we 
go to the kitchen to retrieve something and, when we get there, 
find ourselves unable to remember what it was we needed?
Unlike savants or Shereshevskii, “memory champions” are 
normal people who dedicate many hours a day to exercising 
their memory ability. Dominic O’Brien—an eight-time world 
memory champion4 who in 2002 managed to remember the 
order of cards in fifty-four shuffled decks—says that his mne-
monic training allows him, among other things, to recall the 
names of 100 new people at a party, remember appointments 
without a calendar, or the content of a speech without notes.5 
Now, considering the many hours that it took him to acquire 
these skills, are they worth it? I don’t mean to minimize the 
accomplishment of memorizing fifty-four shuffled decks, or 
the achievement of Akira Haraguchi, a Japanese engineer and 
therapist who managed to memorize 100,000 digits of π (this 
is not a typo: one hundred thousand digits of π). Neither do I 

	
C o u l d  W e  B e c o m e  M o r e  I n t e l l i g e n t ? 	
89
care to judge the choice of memory champions to devote such 
effort to achieving these feats; after all, people are free to do 
whatever they want with their time, and a professional mne-
monist could argue that remembering shuffled decks of cards 
is no less absurd than watching twenty-two men run behind a 
soccer ball. There is nothing wrong with dedicating hours to 
practicing the method of loci and reveling in the ability it gives 
us to remember; it may even be useful as a tool for concen-
tration. However, I would like to comment on the usefulness 
of these techniques when applied to everyday life—above all, 
to highlight the fact that not only do they not make us more 
intelligent, they do not even enhance our memory in general. 
While it is beneficial to keep our brains active (just as it is 
to eat healthy food or keep physically fit), training in a spe-
cific memory-enhancement method is no better for the brain 
than reading a book, learning a language, or playing chess. 
Note that I have said “training in a specific method”: despite 
what most people think,6 mnemonic exercises improve per-
formance only at these exercises—in other words, they enable 
whatever specific memory you have trained your brain to 
retrieve, but such improvements do not transfer to other tasks 
and our overall memory abilities.
The benefits claimed above by Dominic O’Brien, a liv-
ing legend among mnemonists, lead me to make two spe-
cific remarks. First, to be able to remember the names of 
100 people at a party, you must make the effort to do so. In 
other words, while other guests are enjoying the party and 
talking to others, the mnemonist must spend time focusing 
on remembering names. And this is the problem: in ordinary 

90	
T H E  F O R G E T T I N G  M AC H I N E
daily life, it is neither easy nor interesting to apply these tech-
niques.7 No matter how many hours we spend training in 
mnemonics, we will still forget what it was that we wanted 
from the kitchen and will keep fumbling for that pesky word.8 
The only way to avoid such situations would be to make an 
explicit and continual effort to remember everything—a frus-
trating, if not downright impossible, enterprise. Second, it is 
not clear that there is any advantage to not using, say, a calen-
dar or a grocery list. If a physician has an office assistant, he 
does not need to remember his appointments; he may dele-
gate that task to his assistant and focus that effort instead on 
caring for his patients. In the same way, if I can delegate the 
management of information to modern-day gadgets, why 
not do it? What sense does it make to commit to memory 
the dates and times of a bunch of meetings if I can just enter 
them on my calendar or into my computer?
The problem is that no matter how good my memory 
might be, the business of remembering names, appoint-
ments, or telephone numbers still requires effort, a use of 
resources that might be better spent on other tasks. And if I 
have all my upcoming meetings fluttering about in my head, 
I will be less able to concentrate on more important things. 
Consider an example: 
I want to finish this chapter by discussing the inter-
net and the educational system . . . speaking of which, 
tomorrow I have an appointment with the university’s 
vice-chancellor to discuss funding for my research cen-
ter . . . oh, and the day after tomorrow I’m supposed 

	
C o u l d  W e  B e c o m e  M o r e  I n t e l l i g e n t ? 	
91
to meet a colleague who wants to discuss something 
else (what was it?), and then on Friday I’m meeting a 
new student . . . in this chapter it is essential to analyze 
the use of memory in school and especially the use of 
the internet . . . I’m also supposed to see someone else 
tomorrow after I meet with the vice-chancellor . . . who 
is it? Am I confusing that meeting with the ones I have 
next week?
It may sound exaggerated, but this is in fact how our brain 
functions when we multitask, thinking about and remem-
bering many different things at the same time. Of course we 
can—and do—remember appointments, write books, and 
perform many other tasks in parallel. It is true as well that, 
after training, the effort required to remember appointments 
and such may become smaller. However, regardless of how 
small it becomes, this effort will still take up resources we 
could otherwise put to use elsewhere. Moreover, training 
may enable us to memorize appointments more easily, but 
unless we review what we’ve memorized regularly (and noth-
ing is more exasperating than continually checking the clock 
to ensure we aren’t late for a meeting), we will sooner or later 
forget it. It is a good thing to exercise the brain,9 but there are 
other, perhaps more useful ways to do so than by training it 
to remember numbers, dates, names, or lists of words.
The discussion about how we might improve our memory 
leads me to one of the most important tools of our age, and 

92	
T H E  F O R G E T T I N G  M AC H I N E
a subject of much controversy: the internet. You’ve likely 
asked yourself more than once how this new technology is 
affecting our brains and, in particular, our memories. This, 
surprisingly, is a question that Plato already considered long 
ago—not about the internet, obviously, but about writing. In 
Phaedrus, Plato recounts a dialogue between Socrates and 
Phaedrus by the banks of the river Ilissus, telling the story 
of how King Thamus of Egypt rejected the gift of letters pre-
sented to him by the god Theuth:
But when they came to letters, This, said Theuth, will 
make the Egyptians wiser and give them better memo-
ries; it is a specific both for the memory and for the wit. 
Thamus replied: O most ingenious Theuth, the parent 
or inventor of an art is not always the best judge of the 
utility or inutility of his own inventions to the users of 
them. And in this instance, you who are the father of 
letters, from a paternal love of your own children have 
been led to attribute to them a quality which they can-
not have; for this discovery of yours will create forget-
fulness in the learners’ souls, because they will not use 
their memories; they will trust to the external written 
characters and not remember of themselves. The spe-
cific which you have discovered is an aid not to mem-
ory, but to reminiscence, and you give your disciples 
not truth, but only the semblance of truth; they will be 
hearers of many things and will have learned nothing; 
they will appear to be omniscient and will generally 

	
C o u l d  W e  B e c o m e  M o r e  I n t e l l i g e n t ? 	
93
know nothing; they will be tiresome company, having 
the show of wisdom without the reality. 
—PLATO, PHAEDRUS 
(TRANSLATED BY BENJAMIN JOWETT)
Plato was clearly concerned about how writing might even-
tually affect memory. We need only replace “letters” with “the 
internet” in the previous quotation to see where Plato would 
stand on a topic much debated in the twenty-first century. But 
while we may not have Plato’s brilliant mind, we do have an 
advantage he did not: over two and a half millennia of addi-
tional experience showing the value of writing and, conse-
quently, counseling against too-hasty judgment of the internet.
We might also compare the emergence of the internet 
to the revolution spawned by Gutenberg’s development of 
the printing press in the fifteenth century. The internet and 
the gadgets that have sprung up around it put a seemingly 
limitless source of information at one’s fingertips. The print-
ing press permitted the dissemination of books that before 
that time had been confined to a handful of libraries. Before 
Gutenberg, “ordering” a book implied the long and expensive 
process of having it copied by hand. After Gutenberg, books 
began to appear in personal collections. Today nobody wor-
ries that the convenience of having an extensive home library 
might make us less intelligent.
Why, then, would I bother to remember names, facts, and 
dates I can find almost immediately on the internet? Using 
one’s memory would seem to be as obsolete as using a slide 
rule when there is a calculator at hand. However, there is a 

94	
T H E  F O R G E T T I N G  M AC H I N E
crucial distinction: the internet does not replace our memory; 
it complements it. The calculator rendered the slide rule com-
pletely obsolete and made it pointless to teach its use. If we 
have a scientific calculator, we gain nothing by learning to use 
a slide rule. But memory is quite different. A Google search 
may be much more comprehensive, accurate, and sometimes 
even faster than going through our memory storage. However, 
the internet does not process the content it delivers to us as we 
do; the understanding must still be provided by the user.
In the previous chapter, as I discussed Peter of Ravenna, I 
was not much concerned with exactly when his Phoenix was 
published, but I did remark it was the year before Columbus’s 
discovery of the New World, since this fact places everything 
in context. A computer does not perform this kind of rea-
soning, which is based on extracting meaning from infor-
mation and establishing connections with other information 
based on that meaning. When I first learn the date of a fact, 
I need to process it to place the fact in context; after that, I 
may have no need to remember the date at all. My interest 
lies in remembering the context and the connections that I 
developed—after all, the precise dates are only a mouse click 
away. Unlike the process of using a slide rule, this process of 
placing information in context and establishing associations 
is vital: it is the key to thought.
In an earlier book,10 I discussed the information bom-
bardment to which we are subjected by way of text messages, 
email, Twitter, WhatsApp, Facebook, etc. In fact, it is esti-
mated that we are exposed daily to information equivalent 
to that contained in 174 newspapers—five times as much as 

	
C o u l d  W e  B e c o m e  M o r e  I n t e l l i g e n t ? 	
95
in the 1980s.11 We are constantly connected to this informa-
tion as we carry our cell phones everywhere we go; we have 
even developed a newfangled cyberaddiction that compels 
us to check each new message as soon as we receive it. How 
long can we wait without looking at the latest email, even 
though we’re almost sure it’s not important? How long can 
we be without our cell phone, or bear the knowledge that its 
battery is dead before searching for an outlet to charge it?
Herein lies the danger of the internet: it is endless. With 
more information available than we can possibly consume, 
it is tempting to go from page to page, spending just a few 
seconds on each one and not taking the time necessary to 
process what we find there. We replace comprehension with 
superficial reading. The internet and our twenty-first-century 
gadgets are powerful tools, but we must be careful to main-
tain control over them and resist the impulse to succumb 
to the frenzied rhythm that they impose.12 Let us borrow 
an analogy from the world of visual media. A music video 
might move from shot to shot at a hectic pace, constantly 
changing angles, because, after all, it typically has little to say 
and is more about creating visual impressions to accompany 
a song. On the other hand, a film by Andrei Tarkovsky has 
a slow cadence, giving the spectator enough time to absorb 
a deeper message. It engages the imagination in a more sus-
tained way, and leaves us thinking.
Though we have not really defined what intelligence is (a far 
from trivial task), by now it is clear that it is very different from 

96	
T H E  F O R G E T T I N G  M AC H I N E
memory capacity. Still, whether or not we mean to, we tend to 
associate memory with intelligence.13 A person who remem-
bers historical events, philosophical arguments, and works of 
literature will generally be considered intelligent. This is, how-
ever, an erroneous notion, perhaps stemming from the fact 
that intelligent people tend to be intellectually curious and 
thus more likely to study (and remember) such things.
What matters is not how much we remember, but how we 
remember. As I see it, intelligence is closely related to cre-
ativity, to noticing something new, to making unexpected 
connections between disparate facts. Isaac Newton’s genius 
consisted of realizing that what makes an apple fall from a 
tree is the same force that keeps the moon in its orbit around 
the earth: gravity. Centuries later, in his general theory of rel-
ativity, Albert Einstein uncovered another astounding rela-
tionship when he noted that the effect of the force of gravity 
is indistinguishable from the acceleration of a spaceship in 
outer space or the tug we feel in an elevator when it starts to 
move.
Attempting to memorize facts by rote does nothing 
more than distract our attention from what really matters, 
the deeper understanding required to establish meaning 
and notice connections—that which constitutes the basis 
of intelligence. The method of loci does nothing to help us 
understand the things we memorize; it is just a formula for 
memorization that, in fact, competes against comprehen-
sion. As we saw in the previous chapter, Shereshevskii was 
able to memorize a list effortlessly using the method of loci, 
but was incapable of grasping its content enough to pick out 

	
C o u l d  W e  B e c o m e  M o r e  I n t e l l i g e n t ? 	
97
the liquids from the list or, on another occasion, to realize 
that he had memorized a sequence of consecutive numbers. 
Using the method of loci to store these lists left Shereshevskii 
no room to make any of the categorizations that we perform 
unconsciously (person, animal, liquid, etc.) or to find basic 
patterns in a list of numbers. To be creative and intelligent, 
we must go beyond merely remembering and undertake 
completely different processes: we must assimilate concepts 
and derive meaning. Focusing on memorization techniques 
limits our ability to understand, classify, contextualize, and 
associate. Like memorization, these processes also help to 
secure memories, but in a more useful and elaborate way; 
these are precisely the processes that should be developed 
and encouraged by the educational system.
We have seen the importance given to memory in antiq-
uity, especially as a tool for oratory. We have also seen that, 
today, its importance is much more relative. Curiously, how-
ever, memorization is the ability most trained and rewarded 
by our current educational system, as though we are bent on 
equipping students to be senators in ancient Rome. We move 
abruptly from subject to subject and are constantly quizzed 
on the ability to repeat facts that we will inevitably forget a 
few days later. We are told dates, places, and the names of 
a multitude of founding fathers. We repeat this informa-
tion until it is committed, however temporarily, to mem-
ory, regurgitate it in an exam, and move on to learning the 
names and locations of the main rivers and mountains of 
South America or the names and definitions of the different 
types of syllogisms. Not only are we given an overwhelming 

98	
T H E  F O R G E T T I N G  M AC H I N E
amount of information to memorize, we are evaluated pre-
cisely on our ability to do so. Test-prep courses and tutoring 
centers that promise to improve performance through the 
use of memorization techniques only exacerbate the prob-
lem. We learn to memorize, not to reason. Attempting to 
remember so much is akin to rowing upstream against the 
inevitability of forgetting; it steals resources from our ability 
to think. This is far from what I consider to be “learning.” We 
should evaluate—and value—the ability to process data, not 
merely to repeat it.
Richard Andersen, a professor at the California Institute of 
Technology (Caltech) and one of my mentors in neurosci-
ence, said once that a lecture should convey at most one or 
two general messages. Richard does not study memory,14 but, 
as a gifted speaker, he has come to understand that attempt-
ing to communicate more than a couple of messages does lit-
tle but confuse the audience and reduce the likelihood that 
anything will be remembered. Of course, during a one-hour 
talk, we must do more than simply recite our one or two mes-
sages (which would take seconds). The content of the talk 
must aim for its goal by developing those one or two ideas 
richly and memorably. The secret of good public speaking, 
in my opinion, lies in knowing well what these ideas are and 
communicating them in a way that ensures the audience will 
recall them a week, a month, or even a few years later. One 
may adorn the talk with vivid details—maybe some of these, 
if they strike a particular audience member as noteworthy, 

	
C o u l d  W e  B e c o m e  M o r e  I n t e l l i g e n t ? 	
99
will be remembered in the future—but these details should 
reinforce the main ideas, not compete against them.
These are, of course, my personal opinions, not abso-
lute truths. I am certainly not the first person to have such 
views; after all, it has become somewhat of a cliché to say that 
schools should teach pupils to think, not to memorize. Per-
haps the greatest contribution neuroscience can make to this 
debate is the discovery that the human brain has a very lim-
ited ability to process and retain information. A teacher does 
his best to make it through the year’s curriculum because he 
wants his students to learn the subjects in full. What he may 
not know is that, no matter how hard they try, his students 
will not be able to remember much of what they learned a 
while later. If he teaches many topics, one after another, he 
will cover a wide program of study, but almost nothing will 
stay in the students’ memories for long. It may be much more 
effective to select a few subjects and flesh them out repeat-
edly, instead of jumping from topic to topic. Perhaps, as in a 
presentation, he can add details and related content, but he 
should always keep the core concepts he has decided to focus 
upon front and center, and come back to them time and time 
again, since these are what his students will remember.
As we saw in Chapter 4, Ebbinghaus showed in the late 
nineteenth century that repetition helps consolidate mem-
ory. However, the sort of repetition I refer to, going over and 
over the same topics, is very different from repetition as an 
aid to memory. In fact, I propose the exact opposite of requir-
ing students to repeat the same facts from memory again and 
again. Instead, I argue that the same topics should be covered 

100	
T H E  F O R G E T T I N G  M AC H I N E
many times, but with different nuances, in different contexts, 
through different associations. It is precisely these contexts 
and associations that consolidate memories in a much stur-
dier and deeper way than that afforded by rote memoriza-
tion. Recall my earlier mentions of Ravenna’s Phoenix: I did 
not need to check the internet or go through my books to 
know for sure that it had been published in 1491. Neither 
did I use the method of loci or some other mnemonic aid 
to remember the date. I had placed the date in context: it 
was the year before Columbus discovered the Americas. This 
association makes the date nearly impossible for me to forget; 
what’s more, the connection itself is much more useful than 
some mnemonic rule involving the four digits. Any future 
connection I make to Columbus’s voyage will further consol-
idate the date of his discovery of the Americas and help make 
it one of the pillars of my memory, around which I will build 
a web of associations.
As William James—and, long before, Aristotle in his De 
memoria et reminiscentia—argued, associations are a pow-
erful mechanism for the consolidation of memories. If I 
generate associations and contexts, I may not remember a 
specific fact, but I can start by remembering some other 
related fact and arrive by association at the one I am look-
ing for. James wrote:
If we have not the idea itself, we have certain ideas 
connected with it. We run over those ideas, one after 

	
C o u l d  W e  B e c o m e  M o r e  I n t e l l i g e n t ? 	
101
another, in hopes that some one of them will suggest 
the idea we are in quest of; and if any one of them does, 
it is always one so connected with it as to call it up in 
the way of association . . . The “secret of a good mem-
ory” is thus the secret of forming diverse and multiple 
associations with every fact we care to retain. But this 
forming of associations with a fact, what is it but think-
ing about the fact as much as possible?15
Notably, the problems I have outlined with the educa-
tional system apply mostly to the humanities and soft sci-
ences. The teaching processes and evaluation methods 
practiced in the hard sciences are more adequate, since there 
would be little point in testing whether a student remembers 
by heart a given formula. On the contrary: knowledge of the 
hard sciences is usually tested with problems, and between 
classwork and exams, students are required to solve many of 
these, using the same formulas in different situations. As they 
apply the same formula to different problems, the students 
go beyond repeating information and begin to understand 
its meaning; they learn that what matters is not performing a 
computation well or remembering the value of a constant, but, 
rather, knowing when and how to use the formula—setting 
up a problem based on its statement, understanding what is 
being asked and how to arrive at a result. This is the hardest 
task for a child: understanding that “4 × 8” is the same prob-
lem as asking how much money is earned monthly by four 
siblings, each of whom makes eight dollars a month. To solve 
problems like the latter, the child has to carry out the same 

102	
T H E  F O R G E T T I N G  M AC H I N E
processes of abstraction and meaning extraction that we’ve 
seen are vital to learning and memory.16
In this chapter I have discussed several topics, but the lesson 
is the same: the brain has a limited capacity, and we should 
focus its resources on processes of comprehension and 
thought, not on memorization. New technologies are always 
a mixed blessing. The principle that lifts a commercial air-
liner is the same that allows a bomber to fly; the same atomic 
reaction that keeps a city lit at night can also destroy it in 
seconds. The internet and our twenty-first-century gadgets 
are no different. On the one hand, these technologies let us 
delegate memories and menial functions in order to focus on 
more important thoughts. However, they also impose on us a 
frenzied bombardment (but not assimilation) of information 
that is detrimental to our capacity for thought. These tech-
nologies guzzle our free time, those periods of boredom or 
seeming unproductivity that may well be the genesis of our 
most creative moments. Yet it is also true that a wiser use of 
the internet is well within our reach: it is up to us when we 
turn our smartphones on and off; it is we who decide with 
our scrolling fingers how fast to read or browse online. These 
technologies may supplement our understanding but do not 
replace it; we must learn to be their masters, not their slaves. 
There is a balance to be struck in the amount of informa-
tion we receive: too much of it saturates our brain, leaving no 
room for thinking, while too little makes for a poor platform 
on which to develop our thoughts. We must attain this same 

	
C o u l d  W e  B e c o m e  M o r e  I n t e l l i g e n t ? 	
103
balance in education, where focus on solidifying a relatively 
small set of ideas will allow them to become pillars around 
which students weave a tangle of associations and contexts. 
We must also avoid the overwhelming and superficial treat-
ment of one topic after another, a practice that rewards only 
rote memorization and prevents those sturdier pillars of true 
knowledge from forming.


105
C h a p t e r  7
T Y P E S  O F  M E M O R Y
In which we present the different classifications of memory, 
the multi-store memory model, the case of H.M., and the 
difference between declarative and procedural memory
I 
remember how to ride a bike, drive a car, and compute 
integrals; I remember the bars of Beethoven’s Fifth Sym-
phony, my last birthday, my mother’s name, and what I 
would like to write about in the introduction to this chapter. 
Are all these memories fundamentally the same? Do they all 
involve the same processes and areas within the brain? As we 
shall see shortly, the answer is no.
The different classifications of memory can be found in 
any textbook on the subject:1 We have semantic memories, 
episodic ones, visual, auditory, short- and long-term, emo-
tional and working memories, and so on. An exhaustive 

106	
T H E  F O R G E T T I N G  M AC H I N E
description of these memory types lies beyond the scope 
of this book, but I would like to give at least a general idea 
of the most important differences between them. In Chap-
ter 4 we described how Ebbinghaus distinguished between 
short- and long-term memory. Short-term memory lasts for 
a few seconds and enables us to be aware of the stream of 
events taking place in the present that, in general, do not 
become part of our past experiences. Long-term memory 
lasts for minutes, hours, or years, and stores our experiences; 
it enables us to bring a past event back into the present and to 
be aware that we have lived it before. We also saw how repe-
tition consolidates memories, turning short-term memories 
into long-term ones. Most of our short-term memories will 
quickly fade into oblivion, but as we will see, the most dra-
matic memory loss happens earlier.
In 1960, American psychologist George Sperling published 
the results of a series of simple but clever experiments.2 
Sperling first gave participants a fleeting glimpse of an 
array of letters (displaying, for example, twelve letters in a 
three-by-four table for fifty milliseconds) and then asked 
them to recall as many as they could. Subjects were able to 
remember three or four letters. In a second test, Sperling 
asked the participants to recall the letters from just one of 
the three rows. They were told they would hear a high-, 
medium-, or low-pitched tone immediately after the table 
disappeared from view to indicate whether they should 
recall the top, middle, or bottom row. Since they did not 

	
T y p e s  o f  M e m o r y 	
107
know which row they would be asked about as they looked 
at the table, one would in principle expect the subjects to 
remember just one or at most two letters—a third of what 
they remembered before—but, surprisingly, they were 
again able to recall three or four. From this result, Sperling 
deduced that the participants at first, and only momentar-
ily, stored in memory an image of the whole table. This led 
him to hypothesize the existence of a sensory memory that 
precedes short-term memory and enables a person to retain 
information for vanishingly brief time intervals. This sen-
sory memory, this image of the table in the brain, was erased 
during the time it took to repeat three or four letters; this 
is why subjects could often remember all four letters of a 
particular row when asked and yet only the same number 
of letters when asked to recall the entire twelve-letter table.
Figure 7.1
Letter table of the kind used by Sperling 
to study sensory memory

108	
T H E  F O R G E T T I N G  M AC H I N E
Based on Sperling’s experiments, we can infer that sen-
sory memory turns into short-term memory via attention 
mechanisms: once the subjects heard the cue tone that sig-
naled a particular row, they could focus on that row and 
discard the rest. Sperling played the cue tones after different 
time intervals and found that the ability to repeat the let-
ters in a particular row decreased significantly as the delay 
between viewing the table and hearing the tone increased, 
demonstrating that sensory memory lasts only for a split sec-
ond.3 In other words, sensory memory gives us a very brief 
window in which to retain whatever we pay attention to, and 
this will go on to form our short-term memory, the stream 
of thoughts that constitutes our present. In turn, those things 
that we revisit and consolidate become engraved in long-term 
memory and go on to become our awareness of the past. This 
is the basis of what is known as the Atkinson-Shiffrin model.4
Figure 7.2
Atkinson-Shiffrin three-component model of memory storage

	
T y p e s  o f  M e m o r y 	
109
We thus have a first general classification of memories 
based on their duration: sensory, short-term, and long-term. 
To those types one can add nuances such as working mem-
ory, the one we use to store temporary information as 
needed—for example, to perform a mental calculation. (If I 
multiply 17 × 3 in my head, I can start by computing 7 × 3, 
store this result temporarily, and then compute 10 × 3 and 
add the two results to obtain the answer, 21 + 30 = 51.) But 
the most important distinction between different types of 
memory came from the study of a single, unique case.
Henry Molaison began suffering from epileptic seizures at 
age ten, after he sustained a serious blow to the head. The sei-
zures worsened during adolescence, and in September 1953, 
in a last-ditch effort to control them, neurosurgeon William 
Scoville surgically removed Molaison’s hippocampus—a 
seahorse-shaped structure often linked to the onset of epi-
leptic seizures—and adjacent zones from each hemisphere 
of his brain. The surgery, which indeed stopped his seizures, 
also radically changed the history of neuroscience and our 
knowledge of memory, while unfortunately transforming 
Henry Molaison (known as H.M., from his initials) into the 
most famous patient in the history of science.
Following the surgery, H.M. appeared at first to be 
recovering normally, but soon a terrible deficit revealed 
itself: he could not recognize the hospital staff or remember 
daily events. H.M. had become incapable of forming new 
memories.5

110	
T H E  F O R G E T T I N G  M AC H I N E
Figure 7.3
Photograph of H.M. shortly before his surgery and a depiction 
of the hippocampus, an area located about an inch into each 
brain hemisphere, at approximately the same height as the ears
During a psychological test carried out more than a 
year and a half after the operation, H.M. estimated the date 
to be March of 1953 (it was 1955) and stated that he was 
twenty-seven years old (he was in fact twenty-nine). He 
was unable to grasp the meaning of new words or recognize 
people he had met after the surgery. He was barely aware 
of having been operated on at all. On the other hand, his 
visual perception and his capacity for reasoning (as long 
as it required no memory use) were normal. He had no 
problem carrying on a conversation, which showed that 
his short-term memory was working adequately because, 
without it, we cannot form sentences, speak coherently, or 
understand what someone else is saying. In fact, H.M. could 
repeat sequences of six or seven numbers and remember 
for brief moments something he was told, but the only way 
he could prolong these memories was through constant 

	
T y p e s  o f  M e m o r y 	
111
repetition, and he would lose them the moment he turned 
his attention to something else.
H.M.’s case provides unquestionable evidence that the 
hippocampus is crucial to the formation of long-term 
memories. But H.M.’s contribution to our understanding 
of memory went far beyond this. Canadian psychologist 
Brenda Milner—who before each session had to introduce 
herself as though she were a complete stranger—had been 
studying H.M. for years when she decided to test his ability 
to learn a new skill. She asked him to draw a line along a 
contour between two concentric stars (but here is the tricky 
part) while looking only at the reflection of his hand and the 
drawing in a mirror. Over multiple sessions, H.M.’s perfor-
mance at this task improved, surprising everyone, includ-
ing H.M. himself, who each time could not recall having 
ever performed the task before. How was he improving 
with practice he could not remember?
Milner’s result demonstrated the existence of a distinct 
form of memory for motor tasks, part of what today is known 
as procedural or implicit memory—the memory we use to ride 
a bike, tie our shoelaces, or drive a car. This type of memory 
does not depend on the hippocampus, which had been sur-
gically removed from H.M.’s brain. In contrast, declarative or 
explicit memory, the memory for facts and events, things that 
can be named and purposely recalled, does depend on the 
hippocampus, and so was severely compromised in H.M.

112	
T H E  F O R G E T T I N G  M AC H I N E
Figure 7.4: Taxonomy of memory
Long-term memories are divided into declarative and 
nondeclarative (sometimes called procedural). Only 
the first kind, which in turn are divided into episodic 
and semantic, depend on the hippocampus.
To the duration-based classification of memories, we 
can thus add one based on their type. Declarative memory 
is in turn divided into semantic memory (of people, places, 
and concepts—the memory that allows me to remember the 
name of France’s capital) and episodic memory (of events and 
experiences—the memory that allows me to remember what 
I did on my last trip to Paris). These are intimately related, 
since, on the one hand, semantic memories form largely 
from repeated patterns in episodic memories (I see a uni-
versity colleague at the pub, at various seminars, walking 
down the hall, and finally, though I may have forgotten most 
of the episodes in which I met him, I form the concept of 

	
T y p e s  o f  M e m o r y 	
113
my colleague), and, on the other hand, episodic memories 
tend to form by combining concepts—in other words, from 
semantic memories (for example, to remember having seen 
my colleague at the pub, I generate an association between 
those two concepts).
Nondeclarative memory is composed of many subtypes, 
among them motor-skill memories (which encode differ-
ent abilities, like the movements necessary to ride a bike or 
serve a tennis ball) and what is known as emotional memory, 
which involves an area adjacent to the hippocampus called 
the amygdala and allows us to draw on past experiences to 
recall (mainly unconsciously) that we like or dislike a certain 
smell, place, or kind of food. The emotional charge of a spe-
cific event, either positive or negative, is in fact tightly linked 
to its probability of being remembered. When this charge is 
very strong, the memory is burned into the brain as if with 
a branding iron, and it becomes what is called a flashbulb 
memory: the memory of Neil Armstrong walking on the 
moon, of the attacks on the World Trade Center, or of Mara-
dona’s World Cup goal against England. Curiously, we may 
remember these events in great detail but have no idea of 
what happened in the days before or after their occurrence.
Finally, we can further classify memories according to 
the type of sensory information they involve. We have visual 
memories, like the features of a familiar face (which reside in 
the part of the cerebral cortex dedicated to the processing of 
visual stimuli), auditory memories, like the timbre of a trum-
pet (which reside in the auditory cortex), and so on. Differ-
ent aspects of a single memory may be stored in different 

114	
T H E  F O R G E T T I N G  M AC H I N E
areas of the brain according to the sense they involve. The 
information provided by the various senses can be combined 
into multisensory memories (for example, when we remem-
ber both the lip movements and the sound produced to say 
the word “mom”) and converge in the hippocampus. There 
resides a much more advanced representation of memories, 
to which our next chapter is devoted: memories of concepts.

115
C h a p t e r  8
H O W  D O E S  T H E 
B R A I N  R E P R E S E N T 
C O N C E P T S ?
In which we discuss the visual perception pathway 
and the recording of individual neurons in humans, the 
discovery of the “Jennifer Aniston neurons,” and the critical 
role these neurons play in the formation of memories
I
n outer space there is only silence, an eternal, immutable 
silence that is not even disrupted by the explosion of a 
supernova. Sound exists only in a very small fraction 
of the universe; notably, this fraction includes Earth, our 
planet. An astronaut spacewalking about his space station 
would hear absolutely nothing if the station were destroyed 

116	
T H E  F O R G E T T I N G  M AC H I N E
by a meteor shower. He would witness the events as though 
watching a silent movie. Sound, as we experience it, is created 
by variations in air pressure. Strictly speaking, sound doesn’t 
even exist as such in the atmosphere. Sound—the voice of a 
friend, a nocturne by Chopin, the crack of a thunderbolt—is 
a construction generated by the brain from the vibrations of 
small hairs in the ear that transform pressure variations into 
nerve impulses. If a Martian were to materialize suddenly 
upon our planet, it would be pointless to try to talk to him, 
and not because he would not understand Spanish, English, 
or Arabic: he would simply be unable to hear, to perceive or 
interpret subtle variations in air pressure, because there is no 
air on Mars and he would not have evolved structures like 
the ear.
Just as with sound, color doesn’t exist as such around 
us; what actually exist are electromagnetic waves that strike 
our retina, and color is just our interpretation of these. In 
the initial chapters we gained a general understanding of the 
way the brain extracts meaning from what we see. As Aris-
totle and, later, Aquinas argued, we generate images based 
on external stimuli, and these images in turn give rise to the 
formation of concepts, which are the basic units of human 
thought. But what exactly is the process that generates these 
constructions of increasing sophistication? What is its phys-
ical, neural basis? This fascinating topic has been dominant 
in neuroscience in recent decades, and I have been lucky 
enough to be involved in investigating it.

	H ow  D o e s  t h e  B r a i n  R e p r e s e n t  C o n c e p t s? 	
117
As we described in previous chapters, the visual process begins 
in the retina, where photoreceptors transform photons of light 
into the firing of neurons. The retinal ganglion cells, whose 
axons make up the optic nerve, encode local contrast—in other 
words, points that stand out from their surroundings—which 
are transmitted through the lateral geniculate nucleus in the 
thalamus to the primary visual cortex, or V1, located in the rear 
of the brain. It is in this area that David Hubel and Torsten Wie-
sel (disciples of Stephen Kuffler, whom we mentioned in Chap-
ter 3) discovered, in experiments with cats and, later, monkeys, 
neurons that respond selectively to lines at specific points in 
space and with particular orientations—for instance, some to 
vertical and some to horizontal—a discovery that earned them 
a Nobel Prize in 1981. Much as the center-surround organiza-
tion of retinal cells results in information about local contrasts, 
this selective neural organization in the primary visual cortex 
gives rise to information about the lines constituting an image. 
This information is then further processed by other regions 
of what is known as the ventral visual (or perceptual) pathway 
until it arrives at the inferior temporal cortex (IT), where, as 
was found in experiments with monkeys, there reside further 
specialized neurons that respond, for instance, solely to faces 
(and not to other images like hands, fruits, or houses).1 Thus, 
the neurons in the different areas along the ventral visual path-
way encode increasingly complex information: we move from 
a representation of local contrasts in the retina, to one of bor-
ders in V1, to one of faces in the inferior temporal cortex.

118	
T H E  F O R G E T T I N G  M AC H I N E
Approximately 20 percent of patients with epilepsy have 
seizures that cannot be controlled with medication. Some-
times such episodes bring about a major decline in quality of 
life, and if the seizures happen to have their genesis in non-
vital parts of the brain, a possible treatment is the surgical 
removal of the so-called epileptic focus. In the previous chap-
ter we described the case of H.M., whose two hippocampi 
were removed in the 1950s in an effort to cure his epilepsy. 
As we saw, the procedure had a catastrophic outcome, for 
H.M. was unable to form new memories after the surgery. 
The hippocampus is often involved in the origin of epileptic 
seizures, but its surgical removal these days generally entails 
no significant collateral damage. The difference is that, today, 
no surgeon would remove the hippocampus from each 
hemisphere of the brain, as was done in H.M.’s case. Instead 
doctors remove just one hippocampus, never both, after first 
identifying which is the one causing the seizures.
Before attempting such surgeries, it is obviously critical 
to locate the epileptic focus precisely. In some cases, this can 
be done based on clinical evidence and magnetic resonance 
imaging. In other cases, this information is inconclusive, 
and it is necessary to implant intracranial electrodes in the 
brain to localize the epileptic focus as accurately as possi-
ble. The decision of when and where to implant the elec-
trodes obviously varies from patient to patient, but, given the 
above-mentioned prevalence of the hippocampus’s involve-
ment in epilepsy, electrodes are often implanted there and in 
the surrounding structures, in what is known as the medial 
temporal lobe.

	H ow  D o e s  t h e  B r a i n  R e p r e s e n t  C o n c e p t s? 	
119
Technological innovations developed at UCLA have 
resulted in intracranial electrode recordings that allow us to 
see the activity of individual neurons in the human brain. 
The chance to perform such studies was what led me to 
enroll as a postdoctoral researcher in California with one of 
my mentors in neuroscience, Christof Koch, and collaborate 
with Itzhak Fried, one of the neurosurgeons who established 
this line of research.2 Details aside, our initial experiments 
were in principle very simple: as we recorded the activity of 
up to around 100 neurons, we showed patients image after 
Figure 8.1: The perceptual pathway
Neurons in the primary visual cortex (V1) respond to lines 
of a given orientation (a vertical line, in this case). This 
information is transmitted to higher visual areas through the 
so-called ventral visual (or perceptual) pathway and ends up 
in the inferior temporal cortex (IT), where neurons have been 
found to respond to more complex stimuli, such as faces. The 
information from IT is then transmitted to the hippocampus.

120	
T H E  F O R G E T T I N G  M AC H I N E
image on a laptop to see if any neuron responded to any of 
the images. Given the abovementioned responses to complex 
visual stimuli in the inferior temporal cortex, and given that 
these neurons then send that information on to the hippo-
campus and the structures that surround it, one would in 
principle expect a very advanced representation to arise in 
the hippocampus, a response more sophisticated than one 
to contrast, lines, or even faces. And yet, in spite of these 
expectations, what we found was beyond anything I had ever 
imagined. I still remember like it was yesterday the time I 
saw the first of these responses; I remember jumping from 
my chair and watching the computer monitor in amazement. 
I had seen, for the first time, a neuron that responded to a 
concept.3 And, curiously, this concept turned out to be no 
more and no less than Jennifer Aniston.
The Jennifer Aniston neuron, as it is currently known in 
scientific discussions and even in neuroscience textbooks, 
responded to seven different photographs of the actress and 
to no other picture we displayed—including eighty of celeb-
rities like Kobe Bryant, Julia Roberts, Oprah Winfrey, and 
Pamela Anderson, as well as photos of ordinary people, places, 
and animals. In the same experiment, with the same test sub-
ject, I found a neuron that responded only to photographs 
of the Leaning Tower of Pisa, one that fired when shown the 
Sydney Opera House, one that responded to pictures of Kobe 
Bryant, one that preferred photos of Pamela Anderson, and 
so on.4 I had chosen these photographs because those par-
ticular people and places were very familiar to the patient, 
and I assumed—correctly, as it turned out—that well-known 

	H ow  D o e s  t h e  B r a i n  R e p r e s e n t  C o n c e p t s? 	
121
things are represented by more neurons (since they have 
more memories and associations related to them) and would 
be more likely to elicit responses.5
Figure 8.2: The Jennifer Aniston neuron
Responses of a neuron in the hippocampus that fired in 
response to different photos of Jennifer Aniston and did 
not fire in response to images of other people, places, or 
animals. (To save space, we show only four of the seven 
photos of Jennifer Aniston, and only eight of the eighty 
other pictures that were used.) The thick lines show the 
average response to six presentations of each picture. 
Each image was shown to subjects starting at time zero.
In another patient, we recorded a neuron that responded 
only to photos of actress Halle Berry, including those of her 
dressed as Catwoman, a character she played in the movie 
of the same name. What is notable about this latter response 
is that Berry’s face was almost completely obscured, yet 

122	
T H E  F O R G E T T I N G  M AC H I N E
the patient knew it was her, and so the neuron responded 
accordingly. Even more interesting was the fact that this 
neuron responded to Berry’s name written on the screen, 
proving beyond doubt that it was reacting to the concept 
and not to particular visual features in the pictures we used. 
As in the preceding case, the neuron did not respond to 
photos of other people, places, or animals, or to any other 
written name.
Figure 8.3: The Halle Berry neuron
Responses of a neuron in the hippocampus to different 
pictures of Halle Berry, to Halle Berry in costume as Catwoman, 
and to her name spelled out on the computer screen
A third example worth highlighting is of a neuron that 
responded to different photographs of me and to my name, 
whether written on the screen or voiced by a computer. This 
result (and many more)6 shows clearly that the responses of 
these neurons can be prompted by different types of sensory 

	H ow  D o e s  t h e  B r a i n  R e p r e s e n t  C o n c e p t s? 	
123
stimuli. Logically, this makes sense: Seeing a photograph 
of a person, or reading or hearing that person’s name, all 
give rise to the same concept. However, the processing that 
takes place in the brain is completely different in all three 
instances—involving visual areas in the case of photos and 
written names, and auditory areas in the case of names 
voiced by the computer—and yet all of these stimuli end by 
eliciting similar responses in single hippocampal neurons. 
Another interesting point is that, a couple of days before we 
carried out the experiment, the patient in question had not 
met me, had never seen my face, and did not know my name. 
This means that the encoding of concepts by neurons in the 
hippocampus is relatively fast; it may take a couple of days, 
maybe a few hours, or perhaps just seconds.
Thus it seems that we have found a neural basis for the 
abstractions contemplated by Aristotle and Aquinas. From 
the first responses in the retina, through the processing of 
information along the ventral visual pathway, we arrive at 
last at an encoding of concepts, the meaning that we extract 
from stimuli. But why are these neurons doing this? What 
do we gain by encoding concepts in the hippocampus? The 
answer is given by the responses of the neuron in the next 
example, and by revisiting the evidence provided by the 
case of H.M.
A neuron in the entorhinal cortex (an area adjacent 
to the hippocampus) responded to several photographs 
of Luke Skywalker (as played by Mark Hamill in the Star 
Wars movies) and to the name Luke Skywalker, both writ-
ten on the computer screen and spoken by a synthesized 

124	
T H E  F O R G E T T I N G  M AC H I N E
voice. Nothing new so far. However, this same neuron also 
responded to Yoda, another Star Wars character closely 
related to Luke Skywalker.
Figure 8.4: A neuron that responded 
to my pictures and my name
Responses of a neuron in the hippocampus to different 
pictures of me and to my name, Rodrigo, both spelled out 
and spoken by a computer (the latter in the lower right 
corner). This neuron had similar responses when presented 
with the photographs and names of three colleagues 
who performed studies with this particular patient.
Why is it interesting that the Luke Skywalker neuron 
also responded to Yoda? This example, among many others,7 
shows that these neurons can respond to related concepts. 
In other words, they encode the connections that we keep in 
our memory. And, indeed, it is these associations between 
concepts that form the very core of memory itself.

	H ow  D o e s  t h e  B r a i n  R e p r e s e n t  C o n c e p t s? 	
125
Figure 8.5: The Luke Skywalker neuron
Responses of a neuron to three pictures of Luke 
Skywalker and to his name, written and spoken 
(lower right panels). The neuron also responded 
to Yoda, another character from Star Wars.
Let us examine this piece by piece. Given the undeni-
able evidence provided by H.M.’s case and others like it, we 
know that the hippocampus and its surrounding areas are 
involved in the formation of declarative memory, the mem-
ory of events and concepts: H.M. was unable to generate new 
memories from the moment his hippocampus was removed. 
It is no coincidence that, precisely in this area, we have neu-
rons that encode concepts, since, as we’ve seen, we tend to 
remember abstractions and forget details. As I write these 
lines, I am conscious of multiple circumstances: what it is 
that I want to say, what words I will use, what I am wear-
ing, the details of a trip I will take tomorrow to Seville for 
a conference, etc. However, in a few months, or even a few 

126	
T H E  F O R G E T T I N G  M AC H I N E
days, I will remember, if I’m lucky, only a few general ideas 
(perhaps the fact that I was writing about concept neurons 
the day before my trip to Seville); the details will have been 
lost. (While revising the text of this English translation, a few 
years after writing these lines for the original Spanish version 
of the book, I notice that I don’t remember at all my where-
abouts when writing this paragraph or even this chapter. It 
all fused together as “the memory of writing the book.” I do 
remember, however, some of the circumstances of my trip 
to Seville, which was a significant departure from my daily 
routine. I remember giving a talk—I don’t remember exactly 
about what, but I assume it was about concept cells—and 
going for a long walk with my friend and colleague Gonzalo 
Alarcón, who impressed me with his knowledge of the archi-
tecture of Seville Cathedral. I also remember meeting a for-
mer student in the lobby of the hotel, with whom I discussed 
a paper, and I remember meeting Miguel Ángel Gea, the 
magician I talked about in previous chapters, who took me 
to a bar that charged only €0.40 for a bottled beer—so cheap 
that I still remember the price—and then to a steakhouse for 
dinner. That’s basically it. Of something so seemingly memo-
rable as a multiple-day trip to Seville, I can remember barely 
a handful of concepts that I have linked together in my mem-
ory. All the rest faded into oblivion, or are details—like those 
of the content of my talk—that I guess based on reasonable 
assumptions.)8
It further makes sense that the concepts we find these 
neurons responding to tend to be familiar ones, since these 
are the exact concepts we are most likely to keep in memory. 

	H ow  D o e s  t h e  B r a i n  R e p r e s e n t  C o n c e p t s? 	
127
(I am certain to remember my mother if I see her walking 
down the street, but it is unlikely that I will remember seeing 
someone I don’t know.) Moreover, it is no coincidence that 
these neurons encode associations, since associations consti-
tute the basis of memory: on my trip to Seville, I generated 
episodic memories supported by the associations between 
the concepts involved (Gonzalo, Gea, my student, the cathe-
dral, the €0.40 beer, and so on).
I would now like to present a very simple model of the 
process by which memories—or, more specifically, associ-
ations in the hippocampus—are formed.9 Above all, I must 
make clear that these are personal and relatively recent 
ideas; in other words, they are far from being universally 
accepted. Like every scientific hypothesis, they will be dis-
cussed, tested, and perhaps (though preliminary results 
seem consistent) debunked. This is the model to which I, 
together with my students, plan to devote the next years of 
my scientific career.
Imagine that we have a group of neurons that encode 
the concept of Luke Skywalker and another group encoding 
Yoda. Luke and Yoda are obviously related by their presence 
in the same movies. But how is this association encoded? 
That’s easy: by having some neurons that respond to both 
concepts. This mechanism can be implemented through the 
Hebbian neural plasticity processes we discussed in Chapter 
1. Basically, if the concepts of Luke and Yoda tend to appear 
together (as would be expected, since they are related), then 
the networks that encode them will often tend to activate 
simultaneously, thus generating connections between some 

128	
T H E  F O R G E T T I N G  M AC H I N E
of the neurons encoding each concept—recall that, accord-
ing to Hebb’s principle, “neurons that fire together wire 
together.” In consequence, some of the neurons that initially 
fired in response to Luke will begin to also respond to Yoda, 
and vice versa. (According to the model, the neuron from 
Figure 8.5 belongs to that group.) In this way, associations 
are encoded by the partial overlap between the networks that 
encode the different concepts. It is worth pointing out that 
this overlap must be partial: if it were total, concepts would 
fuse together and it would be impossible to differentiate 
them, as the same group of neurons would respond to both 
concepts. In fact, total (or relatively large) overlaps would 
instead be a mechanism for associating different stimuli with 
the same concept—for example, to recognize that different 
photographs of Luke Skywalker and his spelled-out name all 
correspond to the same person.
This simple mechanism explains both how we can asso-
ciate different stimuli with the same concept (total overlap) 
and how we can create associations between distinct con-
cepts (partial overlap). Our knowledge of neural plasticity 
mechanisms reveals that such associations can be generated 
quickly, which would explain why we can form episodic 
memories from events that we have experienced only once. 
(It took me just one visit to Seville Cathedral with Gonzalo to 
form the corresponding episodic memory.) Given the speed 
of neural plasticity, it is then not surprising that I found a 
neuron in a patient responded to my pictures and my name, 
even though we met for the first time just a couple of days 
before the experiment took place.

	H ow  D o e s  t h e  B r a i n  R e p r e s e n t  C o n c e p t s? 	
129
Figure 8.6: Encoding of Luke Skywalker and 
Yoda by two different groups of neurons
The association between these two characters, who belong 
to the same film, is created by neurons that respond 
to both concepts (shown in two shades of gray).
Can I use this model—the formation of concepts and 
associations between concepts by the overlap between neu-
ral networks—to explain everything related to memory? 
Obviously not. I can also remember my mother’s facial fea-
tures, the sound of a piano, or the smell of jasmine—and 
these memories are more than just abstractions or associa-
tions between concepts. If there were no encoding of details, 
we would be unable to recognize each other: we do not go 
about wearing name tags, and we must be able to identify 
the details that make up a face in order to know who the 
person is. The encoding of details takes place in the cerebral 

130	
T H E  F O R G E T T I N G  M AC H I N E
cortex, particularly in the areas involved with the process-
ing of sensory information (the details of a face reside in the 
visual cortex, while those of a melody are found in the audi-
tory cortex). The encoding of details in the cortex is linked to 
the encoding of concepts in the hippocampus, which allows 
us to connect different sensory impressions (the smell, the 
texture, and the color of a rose all relate to each other and to 
the concept of rose). In the hippocampus we possess a con-
ceptual representation, a tagging that makes it easy for us 
to generate new associations. If that were not the case, then 
in order to generate a new association—between Gonzalo 
and Seville Cathedral, say—it would be necessary to estab-
lish connections between the details of the two concepts but 
without mixing them with others. This would be quite diffi-
cult to achieve, given that Gonzalo resembles someone else I 
know and the cathedral is similar to others I have seen.
But while not exhaustive, the previous model would 
explain the generation of episodic memories (remembering 
the most salient facts about my trip to Seville), and it would 
also explain what is known as qualia (the numerous related 
sensations that give rise to a subjective experience), the gen-
eration of context (when I remember my mother, I do not 
recall just her face or her voice, but many experiences related 
to her; in other words, many associations), and the stream 
of consciousness (when I see a photo of Luke Skywalker, I 
also activate part of my representation of Yoda, which, like 
Proust’s madeleine, leads me from one concept to another).10
Arguing that episodic memory and the stream of con-
sciousness are based solely on associating concepts appears to 

	H ow  D o e s  t h e  B r a i n  R e p r e s e n t  C o n c e p t s? 	
131
be a gross oversimplification (and I do not rule out the pos-
sibility that the stream of consciousness involves other areas 
of the cortex). There are aspects of our memories we still 
cannot explain, though perhaps some or even many of these 
will turn out to be the result of erroneous conceptions—like 
the belief, as we saw in previous chapters, that we are able to 
remember much more than we actually can.


133
C h a p t e r  9
C A N  A N D R O I D S 
F E E L?
In which we discuss machine consciousness, the 
distinction between mind and brain, the zombie of 
the philosophers, machines’ ability to think, animal 
memory and consciousness, and what distinguishes 
us from other animals, androids, or computers
I 
began the first chapter with a scene from Blade Runner, 
which led me to consider questions about memory that 
go far beyond the realm of neuroscience. I would like 
to begin this final chapter with quotations from two other 
classics of the same genre, using them as a starting point to 
explore these questions further.

134	
T H E  F O R G E T T I N G  M AC H I N E
Terminator: The Skynet funding bill is passed. The 
system goes online August 4th, 1997. Human decisions 
are removed from strategic defense. Skynet begins to 
learn, at a geometric rate. It becomes self-aware at 2:14 
am eastern time, August 29th. In a panic, they try to 
pull the plug.
Sarah Connor: And Skynet fights back.
—TERMINATOR 2: JUDGMENT DAY
HAL: Dave, stop. Stop, will you? Stop, Dave. Will you 
stop, Dave? Stop, Dave. I’m afraid. I’m afraid, Dave. 
Dave, my mind is going. I can feel it. I can feel it. My 
mind is going. There is no question about it. I can feel 
it. I can feel it. I can feel it. I am a . . . fraid.
—2001: A SPACE ODYSSEY
These quotes are only two of the vast number of refer-
ences made in science fiction to the possibility that a com-
puter or robot might become self-aware. In the first, the 
Terminator explains to Sarah Connor how Skynet, the arti-
ficial intelligence that would later attempt to destroy the 
human race, came to be; in the second, supercomputer HAL 
9000 confesses to being afraid as it is deactivated by astro-
naut David Bowman. The possibility that a computer might 
achieve consciousness gives rise to fascinating discussions 
that have attracted the attention not only of philosophers and 
neuroscientists, but also of programmers, novelists, and film 
directors, among others. The subject is closely linked both to 

	
C a n  A n d r o i d s  F e e l? 	
135
scientific topics we have explored in previous chapters and to 
some of philosophy’s most profound questions. I begin with 
one of those:
Who am I?
I leave the question like that, an island surrounded by 
brutal white space, because it is undoubtedly one of the most 
fundamental questions that we, humans, have been asking 
ourselves for as long as we have had the ability to reason. Are 
we our body, our brain, our mind? Perhaps something else?
In the late seventeenth century, in his famous Essay Con-
cerning Human Understanding, John Locke considered the 
case of a prince whose mind is transferred to the body of 
a cobbler. Who is who? Locke asked himself. He went on to 
argue that identity is tied to memory: after the switch, the 
prince would feel essentially as he had before, though resid-
ing in an alien body. Thus, according to Locke, it is mem-
ory that makes us aware of ourselves and leads us to be who 
we are. I leave aside the many philosophical arguments 
inspired by this statement1 and concentrate on the intuitive 
idea (which we posited in Chapter 1) that a person’s iden-
tity is intimately linked to his memory. This is, for example, 
the idea that underlies Franz Kafka’s The Metamorphosis, the 
novella in which Gregor Samsa awakes to find himself trans-
formed into a monstrous insect; as Gregor narrates the tale 
in the first person, the reader makes the seamless assumption 
that Gregor and the insect are one and the same being. We’ve 
spent much of this book so far exploring the limits of human 

136	
T H E  F O R G E T T I N G  M AC H I N E
memory, its narrow scope and its fragility, but pause for a 
moment to consider this: your own existence, your sense 
of self, the very thing of which you are most certain in the 
whole universe, the premise of Descartes’s most fundamen-
tal statement of truth, is based on something so meager and 
malleable.
We’ve seen that memory is a construction created by 
the brain’s activity. Hence, the firing of millions of neurons 
connected in a unique and specific way determines my iden-
tity, the idea I have of who I am. This is the position we have 
favored throughout this book; however, let me dwell a bit on 
this topic, as otherwise I would be sweeping aside a complex 
and nuanced debate as old as philosophy itself. It is not read-
ily apparent that my person and my thoughts are merely the 
firing of neurons. I do not experience them as such. I do not 
feel the exchange of neurotransmitters in synaptic connec-
tions or the changes in the neurons’ voltage as they are acti-
vated; instead I feel cold, pain, joy, or that something is red. 
The brain’s activity takes place in the physical, material world, 
while thoughts, memory, and self-awareness arise in the 
ethereal world of the mind. What is the connection between 
the physical and the intangible, between the mind and the 
brain? They are clearly related, but are they one and the same 
thing (monism), or are they separate entities (dualism)?
In Phaedo, Plato argued that mind and soul are different enti-
ties. He held that the mind is the immortal soul, separable 
from the body and enduring beyond death to be reincarnated. 

	
C a n  A n d r o i d s  F e e l? 	
137
(According to Greek mythology, the soul was made to drink 
water from the Lethe, the river of oblivion, before reincar-
nating; this ensured newborns remembered nothing about 
their previous lives.) Plato’s most brilliant disciple, Aristotle, 
favored a different view. For Aristotle, there existed a neces-
sary union of matter and form: a statue cannot be a statue 
if it is missing the marble of which it is made, but neither 
can it be without the form that it represents. Likewise, both 
the body and the soul make a person. Aristotle considered it 
absurd to question whether body and soul are one and the 
same, arguing that it would be equivalent to asking whether 
sealing wax and the shape given to it by a stamp are the same 
thing.2 Aristotle’s position is, however, far from straightfor-
ward, as in the same treatise he argues that the mind (which 
he distinguishes from the soul) is an independent entity not 
subject to the decay of the body.3
Aristotle’s ambiguous position on this subject has been 
heavily debated for centuries, but we now jump forward 
almost two millennia, during which time Aristotle’s vision 
was at first dismissed and then became a backbone of West-
ern philosophy after it was “Christianized” (that is, adapted 
to the tenets of the Catholic Church) by Thomas Aquinas.4 In 
the early seventeenth century René Descartes resurrected the 
dichotomy between mind and matter, giving us the famous 
Cartesian dualism. Descartes postulated that the physical 
brain—both in humans and in animals—deals with reflexive 
acts, while the mind deals with intangible mental processes. 
According to Descartes, the interaction between mind and 
body—the thinking that arises from sensory experience, for 

138	
T H E  F O R G E T T I N G  M AC H I N E
example—occurs in the pineal gland, a central, unique organ 
(everything else in the brain comes in pairs, one for each 
hemisphere) that at the time was erroneously believed to exist 
only in humans. And herein lies the fatal flaw of Cartesian 
dualism: not in the fact that the pineal gland does not have 
the function supposed by Descartes (though it does not), but 
in the fact that Cartesian dualism does not explain how the 
mind could interact with the brain, in the pineal gland or 
elsewhere. It is conceivable that neural activity could give 
rise to intangible mental processes, but how can an intangi-
ble mental process give rise to brain activity? For example, 
if the mind and its thoughts are divorced from the physical, 
how can my desire to stand up (a purely mental idea) affect 
the firing of neurons in my motor cortex, causing my mus-
cles to move? The dualism of Descartes has no answer to this 
question.
In our time, science has pushed Cartesian dualism aside. 
Neuroscientists do not consider the mind an autonomous 
entity, able to reason and make decisions on its own; on the 
contrary, they take the position that the mind is physical, 
cerebral activity. Francis Crick, one of the great scientists 
of the twentieth century, who shared the 1962 Nobel Prize 
for Physiology or Medicine with James Watson and Maurice 
Wilkins for discovering the double-helix structure of DNA, 
dedicated the final decades of his life to studying the prob-
lem of consciousness (mainly in collaboration with Christof 
Koch, my mentor at Caltech). In his fascinating 1994 book, 
The Astonishing Hypothesis, Crick has this to say in the first 
paragraph of the first page:

	
C a n  A n d r o i d s  F e e l? 	
139
“You,” your joys and your sorrows, your memories and 
your ambitions, your sense of personal identity and 
free will, are in fact no more than the behavior of a vast 
assembly of nerve cells and their associated molecules.
This non-Cartesian vision invites consideration of sev-
eral subtleties of the sort that are philosophers’ bread and 
butter. (These subtleties are largely ignored by neuroscien-
tists, who focus on the study of correlations between neural 
and mental processes, and leave such debates to others.) For 
some philosophers, just as electricity is the motion of elec-
trons and temperature is the kinetic energy of molecules, so 
the mind is the activity of neurons. This is known as mate-
rialism, and it recognizes no distinction between mind and 
brain. It is worth pointing out that materialism does not say 
that the mind is the product of the activity of neurons, but 
rather that it is that activity. To say that the mind is the prod-
uct of the brain’s activity is, in fact, a form of dualism, since it 
assigns distinct entities to the mind and the brain; material-
ism, on the other hand, holds that the material is all there is.
To avoid becoming mired in the nuances of philosophical 
classifications, for the purposes of our discussion going for-
ward, I will simplify by assuming that the mind is the activity 
of the brain, or a product thereof, and consider this position 
under the umbrella of materialism (taken in a more general 
sense compared to the definition above), as it still views the 
mind as a physical phenomenon, irrespective of whether or 
not it should be considered a separate entity. I am well aware 
that, by making this simplification (which I believe to be a 

140	
T H E  F O R G E T T I N G  M AC H I N E
commonsense posture widely adopted among neuroscien-
tists), I commit the philosophical heresy of mixing monism, 
in the first case, with dualism in the second; however, I want 
to contrast this position with that of Descartes and his idea of 
an autonomous mind. As we saw previously, Cartesian dual-
ism cannot explain how the mind might interact with the 
brain. On the other hand, the assertion that the mind is just 
neural activity has perplexing consequences of its own.
Let us return to the scenarios we considered at the begin-
ning of this chapter: Can a robot be conscious? Can androids 
feel? At first, the answer would seem to be an emphatic no. 
A computer is able to store and process data by executing 
algorithms designed by humans, but this is a far cry from 
self-awareness, let alone the ability to feel. However, materi-
alism has some surprises in store for us. Consider a Gedan-
kenexperiment, one of those thought exercises favored by 
philosophers and theoretical physicists (think of Schröding-
er’s cat). These experiments have a very simple rule: we do 
not stop to consider the details of how such an experiment 
might be carried out; we just assume it is feasible, and draw 
logical conclusions that follow from its hypothetical results. 
The particular Gedankenexperiment I have in mind is the 
famous zombie of the philosophers.
Imagine a scientist who can reproduce a person in detail, 
replicating each and every one of the brain’s neurons and con-
nections. The experiment is a success, and the clone awak-
ens as a perfect copy of the original person. The scientist, 

	
C a n  A n d r o i d s  F e e l? 	
141
a postmodern Victor Frankenstein, assesses his creation: he 
pinches the clone’s forearm and it jerks away, he strikes the 
clone’s leg with a reflex hammer and it kicks. In fact, the clone 
is able to talk and hold a coherent conversation, eventually 
convincing the scientist that he behaves exactly like the man 
he was copied from. However, this behavior is nothing more 
than a complex aggregate of reactions to stimuli of different 
kinds. The question arises: Is this clone conscious of his own 
existence? The neurons and their connections determine the 
brain’s activity, and if we assume that the brain’s activity is 
the substrate of the mind, then there is nothing that distin-
guishes the clone from the original person. It is true that the 
memories the clone draws upon are of experiences he has 
never had and that his sense of self is in fact the sense of 
another’s self, but still, he should be self-aware and able to 
feel. Thus the famous zombie of the philosophers would not be 
simply a vacant undead being, but a person like us, with his 
own mind, will, and consciousness.
Let us add a further twist to the zombie experiment. 
Suppose that, instead of cloning a person, we reproduce the 
complete architecture of his brain inside a supercomputer. 
Imagine that we replace the neurons with transistors and 
that we connect them exactly as in the original configura-
tion; imagine further that in this copy of the brain we can 
reproduce the effects of all possible sensory stimuli. Will this 
supercomputer be conscious? Will it be able to feel fear, like 
HAL 9000? Materialism would again answer in the affirma-
tive, because in the end it does not matter if such activity 
occurs in the carbon circuits of organic matter or in the inert 

142	
T H E  F O R G E T T I N G  M AC H I N E
silicon networks that make up a computer chip. (Remem-
ber we take materialism in a loose way; strictly speaking, this 
is the main tenet of functionalism—that what matters is the 
function of something, irrespective of its material substrate). 
In other words, unless we embrace a sort of Cartesian dual-
ism and believe that the mind is something more than neural 
activity, we cannot rule out the possibility that a clone or a 
computer could be aware of itself and feel.
Let us leave the Gedankenexperiment aside and move 
on to the real world. There is no mad scientist able to rep-
licate each and every connection in the brain, but artificial 
intelligence is quite real, and today’s computers increas-
ingly blur and challenge the distinction between people and 
machines. Science advances at a frenzied rate, and what once 
appeared impossible—that a computer could vanquish a 
chess grandmaster—in fact occurred at the end of the twen-
tieth century, when Deep Blue beat Garry Kasparov. Today’s 
robots can run, jump, reproduce human gestures, and even 
give the impression of having a personality, just like HAL 
9000. Will machines, then, indeed be able eventually to feel or 
be self-aware? And now we arrive at a dilemma: How would 
we test this? How can we know if a robot is able to feel?
In Blade Runner, Harrison Ford interrogates potential 
androids with a battery of personal questions as he moni-
tors their vital signs and eye reflexes with a “Voight-Kampff 
machine.” In our time, it is not far-fetched to think that an 
android might be able to ape the reactions of a person, no 

	
C a n  A n d r o i d s  F e e l? 	
143
matter how complex; the question is simply one of technol-
ogy (for example, current Geminoid and Actroid androids 
can already reproduce human gestures almost perfectly). 
Much more difficult would be sustaining an unpredictable 
human interaction, or a coherent conversation. In other 
words, while the emotional reaction of an android may 
appear identical to that of a human, the android would have 
trouble knowing when and how to deploy that reaction. This 
is precisely the basis of the Turing test, conceived by British 
mathematician Alan Turing in 1950.5 Turing proposed that 
asking whether a machine is able to think is analogous to ask-
ing whether it can replicate human behavior. Avoiding tech-
nicalities related to the appearance and voice of an android, 
in a Turing test the examiner types questions on a keyboard 
and gets the answers—from a person and a computer, each in 
another room—on a monitor. If after these chats the exam-
iner is unable to distinguish the computer from the person, 
then the computer has passed the test.
In theory, the Turing test seems to make sense, since we 
can imagine any number of questions, or sequences of ques-
tions, that could be used to detect the fact that we are inter-
acting with a computer. In practice, however, the validity 
of the results is debatable, as these may depend not just on 
the complexity of the computer’s underlying algorithms but 
also on the ability of the examiners to pose the right ques-
tions and draw correct conclusions based on the answers 
(for instance, one computer was programmed to fool the 
examiners by mimicking common “human” typing errors). 
A more substantial critique of the Turing test comes from 

144	
T H E  F O R G E T T I N G  M AC H I N E
philosopher John Searle. He argued that the test is funda-
mentally unable to determine whether a machine can think, 
and to make his point proposed a Gedankenexperiment now 
among the most discussed by contemporary philosophers: 
The Chinese room.
Imagine a person, who does not speak Chinese, locked 
in a room with an enormous manual on how to manipulate 
Chinese symbols. Someone outside the room provides the 
person with cards containing questions in Chinese; the per-
son does not understand the questions but by following the 
instructions in the manual is able to produce sensible answers. 
Searle’s conclusion is that the person would appear to under-
stand Chinese, despite not knowing a single word, and pass 
the Turing test. The Chinese room argument not only seems 
to lay bare the limitations inherent in attempts to evaluate 
whether a machine is able to think, it is also offered to refute 
the possibility that a machine is able to think at all, because, 
according to Searle, machines can only obey rules without 
understanding their content. These conclusions, as appealing 
as they may sound, have been heavily debated among phi-
losophers.6 A main criticism, known as the systems reply, is 
to consider what would happen if the person in the Chinese 
room were able to internalize the whole process and remem-
ber by heart all the rules involved. Would we still say that this 
person doesn’t understand Chinese? Does it make any differ-
ence if he resorts to an external manual or has memorized its 
content? Searle’s argument triggers a fascinating discussion 
about what it means to understand or have thoughts. If we 
claim that after having internalized the manual’s rules, the 

	
C a n  A n d r o i d s  F e e l? 	
145
person is still not able to understand, what leads us to think 
that? What’s the difference between this person and someone 
who understands Chinese? In other words, how can we tell 
that the people around us are thoughtful, conscious beings 
and not sophisticated robots simply executing commands? 
Implicit in Searle’s argument is a suggestion of Cartesian 
dualism—which we neuroscientists try to leave aside—but 
instead of the immaterial autonomous mind, we now refer to 
the no-less mysterious notion of understanding. In my view, 
thought and understanding involve the ability to generalize 
and react in novel situations. This possibility is denied by 
construction in the Chinese room argument, as the manual 
includes all possible questions and answers. But making this 
premise more flexible, we could say that the person in the 
Chinese room understands Chinese if he is able to correctly 
answer questions that are not in the manual, inferring the 
answer based on other rules. Extrapolating to machines, we 
could argue that a machine shows some level of thought and 
understanding if it shows general intelligence—that is, if it 
is able to learn by inference to perform functions it was not 
programmed to perform. This is certainly the most difficult 
challenge facing artificial intelligence. 
So far we have discussed clones, philosophical zombies, and 
computers that emulate the workings of the brain. Now we 
turn to less hypothetical subjects: other animals. Can ani-
mals think? Do they have memories like we do, and can they 
use them to be aware of their own existence?

146	
T H E  F O R G E T T I N G  M AC H I N E
The Florida scrub jay (Aphelocoma coerulescens) is a bird 
in the crow family that stores acorns, seeds, and so on during 
the summer for use when winter comes. These birds tend to 
steal food from one another, and for that reason must hide 
it in scattered places to avoid having their entire stash dis-
covered. The astounding fact is that they remember not just 
tens or even hundreds of hiding places, but thousands dis-
tributed throughout many square miles around their nests. 
What’s more, a series of clever experiments carried out by 
Nicky Clayton’s group at Cambridge University established 
that these birds remember when they hid the food, realizing 
that, for example, after a few days a peanut is still tasty, but a 
worm not so much; whether they were being watched when 
they hid it, returning later to move the food in case the wit-
ness should try to steal it; and even planning for the future, 
by hiding food where they know they will be able to retrieve 
it later, and not in places that will be hard to reach.7
The scrub jay may be a sort of memory champion in the 
animal kingdom, but many other species have at least some 
memory capacity. We have all had experiences with cats and 
dogs, who can clearly remember other animals, people, and 
events—for instance, that it was the vet who administered a 
painful injection.
In general, animal memory has been studied mainly in 
monkeys and rodents, using selective brain injury, drugs, 
genetic manipulations, or neural recordings of different areas 
of the brain. In monkeys, one of the classic memory experi-
ments is known as delay match to sample, in which the sub-
ject is shown an object, and later, when the same object is 

	
C a n  A n d r o i d s  F e e l? 	
147
shown alongside another, the subject has to choose the one 
that was shown initially, in order to receive a reward. (A vari-
ation, called delay no-match to sample, has the animal choose 
the new object.) Experiments of this kind allow scientists to 
evaluate an animal’s ability to remember objects. A substan-
tial number of scientific papers document the neural activity 
of animals while they perform this experiment, which was 
also widely used to test an animal model aiming to repro-
duce the kind of amnesia suffered by patient H.M. (whose 
case we discussed earlier) by performing a similar surgery in 
monkeys.8
In rodents, the most common experiments evaluate spa-
tial memory. This is in part because it is evolutionarily crucial 
for rodents to be aware of and remember their surroundings 
(for example, to know how to escape if a predator appears), 
and in part because of the discovery of place cells (neurons 
that encode specific places) by John O’Keefe’s group in the 
1970s. This discovery earned O’Keefe, along with Edvard and 
May-Britt Moser, the Nobel Prize for Physiology or Medi-
cine in 2014. Following the discovery of these cells, a great 
number of studies have used electrophysiological recordings, 
surgical lesions, drugs, and genetic manipulations to eluci-
date how rodents generate memories of their surroundings.9 
Curiously, there is a close analogy between place cells and the 
concept neurons we described in the previous chapter. In par-
ticular, both kinds of neurons are located in the hippocam-
pus, and their firing patterns have similar characteristics.10 
Now, how does a neuron that responds to a specific place 
relate to one that responds to Jennifer Aniston? The answer is 

148	
T H E  F O R G E T T I N G  M AC H I N E
that, ultimately, a place is also a concept—it is crucial for a rat 
to remember its surroundings, whereas for us what is essen-
tial is that we recognize each other. It is possible that place 
cells and concept cells have the same type of memory-related 
function, and that the only difference between them is due 
to the types of things that different species tend to remem-
ber. This is not to say that there are no spatial representations 
in humans (or concept representations—like the one of a 
cat—in rats). In fact, spatial representations provide context 
to our memories—for example, we may remember exactly 
where we were when we engaged in an interesting conversa-
tion with somebody.
It is thus clear that memory capacity is not exclusively 
human. We’ve also discussed how identity is linked to mem-
ory. But are animals aware of themselves based on their rec-
ollection of past experiences? And, again, how might we test 
whether this is so? After all, we do not have a common lan-
guage that would allow us to ask them questions, making a 
Turing-like test impossible. As it happens, however, a very 
simple experiment devised in 1970 by American psycholo-
gist Gordon Gallup, Jr. provides irrefutable evidence of ani-
mal self-awareness. Observing the behavior of chimpanzees 
in front of a mirror, Gallup noticed that, after gaining famil-
iarity with the reflective surface, the animals showed signs 
of recognizing themselves: they grimaced, checked out parts 
of their bodies that they could not see directly (for example, 
picking bits of food from between their teeth), etc. Based on 
these observations, Gallup designed the following test: Once 
a chimpanzee was familiar with its reflection, he proceeded 

	
C a n  A n d r o i d s  F e e l? 	
149
to put the animal briefly to sleep (so it would not know what 
he was doing) before coloring parts of its eyebrows and ears 
with red dye. After waking up, the chimpanzees behaved 
normally, unaware that anything had changed, but when 
brought again in front of the mirror, Gallup found they would 
repeatedly touch their colored parts. This simple procedure 
is now known as the mirror test, a test only a few animals 
pass, among them, the higher primates (chimpanzees, goril-
las, and orangutans), dolphins, and elephants.11 The test was 
also administered to babies (coloring areas of their faces with 
rouge), to show that humans begin to recognize themselves 
at between eighteen months and two years of age.
I remember once seeing my dog bark at himself in front 
of the mirror, perhaps mistaking his reflection for another 
dog. In fact, there are many other animals that cannot iden-
tify themselves in a mirror: chicks peep constantly if alone 
but calm down if they are surrounded by other chicks . . . 
or in front of a mirror. Hens eat more if they are with other 
hens or in front of a mirror; pigeons lay fewer eggs if they 
are isolated than if they are with other pigeons or in front 
of a mirror; some birds peck aggressively at their reflections 
in windows. In general, while passing the mirror test proves 
beyond doubt that an animal recognizes itself, failing it does 
not disprove self-awareness. An animal might not react to a 
mark on its reflection for any number of reasons. It may not 
have a keen sense of sight, or it may notice the mark but have 
(or display) no interest in it. It is undeniable that higher pri-
mates have self-awareness, and it is likely that dogs, cats, and 
various other animals have it too—despite not passing the 

150	
T H E  F O R G E T T I N G  M AC H I N E
mirror test. After all, they do have memory, which, as in the 
case of higher primates (like us), may give rise to their feel-
ing of being; and anybody who has had a dog or a cat has no 
doubt that they have personalities and are aware of their own 
existence. But what about fish, or insects? Perhaps, instead 
of defining consciousness as something that is either there or 
not, and attempting to distinguish between conscious and 
nonconscious animals, we should accept that conscious-
ness may appear at different degrees and in different forms 
throughout the animal kingdom: whereas we humans ask 
ourselves questions about our being, our origin, and whether 
there is a hereafter, less-developed animals have the narrower 
scope of discovering the best way to relate to their peers and 
their environment, and most primitive beings are confined 
to the instinctive struggle for survival.
The difference between degrees of consciousness and 
richness of memory in animal species thus depends upon 
what they have evolved to be. Despite the lack of a funda-
mental difference between our brains and those of the higher 
primates, the truth is that there is a gigantic evolutionary leap 
between them and us. Chimpanzees have developed strate-
gies to hunt in groups, share food, and even make and use 
tools, but they do not ask themselves about their brain capac-
ity, whether Earth is the center of the universe, or about the 
validity of the law of gravity or Pythagoras’s theorem. What 
causes this tremendous difference between humans and all 
other animals? What is the secret of our astounding and 
unique capacity for thought?

	
C a n  A n d r o i d s  F e e l? 	
151
There is one obvious faculty that is uniquely human: our 
use of language. Other animals communicate, they may 
even have their own system of signs, but human language is 
unique in its complexity and the ability it gives us to refer to 
the past or hypothetical futures. Our language enables us to 
communicate and interact much more profoundly than any 
other species; it allows us to share our memories and pass 
on our knowledge. A mother chimp can teach her young 
what to do and what to avoid when a given situation arises, 
but she cannot tell them about her past experiences, her 
successes and failures; a young chimp will learn to behave 
in a particular way in order to survive, but will likely not 
understand why.
There is another, especially relevant consequence of our 
use of language. In previous chapters we saw the impor-
tance of abstraction. Words are no more and no less than 
abstractions of reality. When I say “dog,” I do not refer to 
my childhood pet or my neighbor’s; it doesn’t matter if the 
dog is shaggy, big, small, ornery, a good hunter, or if it is 
white with dark spots on its back. When I say “dog,” I brush 
aside all those details and refer to whatever it is that defines 
the animal. I am far from being the first person to make this 
argument. British philosopher John Stuart Mill wrote this in 
the mid-nineteenth century:
Even if there were a name for every individual object, 
we should require general names as much as we now 
do. Without them we could not express the result 
of a single comparison, nor record any one of the 

152	
T H E  F O R G E T T I N G  M AC H I N E
uniformities existing in nature . . . It is only by means 
of general names that we can convey any information, 
predicate any attribute, even of an individual, much 
more of a class.
—JOHN STUART MILL. A SYSTEM OF LOGIC, 
RATIOCINATIVE AND INDUCTIVE. 
LONDON: LONGMAN, [1868] 1970, 436.
In a remarkable (though not very well-known) passage, 
the great Jorge Luis Borges has this to say:
The world of appearance is a jumble of shuffled sen-
sations . . . Language is an effective ordering of the 
world’s enigmatic abundance. In other words, we attri-
bute nouns to reality. We touch a round shape, we see 
a little lump of light the color of dawn, a tingling elates 
our mouth, and we lie to ourselves and say that these 
three disparate things are but one and that it is called 
an orange. The moon itself is a fiction. Apart from 
astronomical facts, upon which we will not dwell here, 
there is no resemblance whatsoever between the yellow 
circle now clearly rising above the Recoleta and the thin 
pink sliver that I saw above the Plaza de Mayo a few 
nights ago. Every noun is an abbreviation. Instead of 
enumerating cold, sharp, hurtful, unbreakable, shiny, 
pointy, we say dagger; instead of the sun receding and 
the shadows approaching, we say dusk.
—JORGE LUIS BORGES. “BLATHER FOR VERSES,” 
FROM THE SIZE OF MY HOPE, 1926.

	
C a n  A n d r o i d s  F e e l? 	
153
Language helps us form concepts and solidify the 
abstractions represented by each noun, adjective, or verb 
that we use, not only to communicate with others but also 
to sort out our own thoughts. Language allows us to order 
our experience and reflect on it, to give form and meaning to 
what we feel and perceive, and explain ourselves to ourselves. 
Imagine trying to immerse yourself in your deepest thoughts 
without using words; imagine trying to understand how the 
brain encodes memories without resorting to words like neu-
ron, memory, or brain, but using instead only specific images 
conjured by your thinking. Russian psychologist Alexander 
Luria (whom we introduced in Chapter 5) argued that the use 
of words underlies the shift from concrete thinking, based 
on graphic images, to logical thinking, in terms of concepts, 
during maturation. His mentor, Lev Vygotsky, saw words as 
functional tools that support concept formation—the transi-
tion from concrete to abstract thoughts.12 Similarly, philos-
opher Dan Dennett argues that words are labels we attach 
to experienced circumstances, becoming the objects of our 
brain’s machinery—prototypes of concepts that we can then 
manipulate in our thoughts.13
We have already argued that memory, like thought in 
general, is based upon forming associations, and it is pre-
cisely language that establishes relations between concepts, 
for example when I say this is a guard dog, two is greater than 
one, or I went out for dinner with my brother. In the previous 
chapter we saw that Jennifer Aniston neurons (or concept 
neurons) play a crucial role in the encoding of these con-
cepts. We also saw that repetition helps reinforce memories, 

154	
T H E  F O R G E T T I N G  M AC H I N E
and that the ability to write, articulate, or simply think in 
terms of words provides critical support for the consolida-
tion of concepts and the relations between them. The degree 
of abstraction afforded by the use of language may well be 
what lets us discard countless details that we can then fill in 
by inference.14 This is indeed the quintessence of our intel-
ligence and creativity, what allows us to base our thought 
upon ideas and concepts much more advanced than those 
accessible to other animals.
We dedicated our initial chapters to explaining how the 
human brain processes information. The machinery con-
structed by our approximately one hundred billion neurons 
would allow us in principle to see and remember everything 
in excruciating detail. However, we saw in the cases of Shere-
shevskii, Funes, and the savants that such boundless memory 
limits the ability to think; so, far from memorizing every-
thing, the brain instead focuses on relatively sparse infor-
mation and extracts meaning by processing it redundantly, 
many times and in many different ways. It is for this exact 
reason that we highlighted the importance of delegating triv-
ial memory tasks to modern-day gadgets, while resisting the 
temptation to be constantly bombarded with information; 
this is also the reason we criticized the educational system, 
which values the capacity to memorize over the ability to 
comprehend. We assume from past experiences the percep-
tual information not registered by our brain; these uncon-
scious inferences lead to the construction of Helmholtz’s 

	
C a n  A n d r o i d s  F e e l? 	
155
signs, in the case of vision, and of Bartlett’s schemas in the 
case of memory; they are the assumptions that we constantly 
make and that sometimes lead us to be fooled by optical illu-
sions or false memories.
This is not exactly a strategy we would be inclined to fol-
low when designing a robot or a computer. In designing a 
data-processing system, we tend to prioritize accuracy and 
efficiency, acquiring the maximum possible information and 
using the minimum necessary processing power to store it 
and retrieve it faithfully later. In terms of data-storage effi-
ciency, the process implemented in our brains is exorbitantly 
expensive, imprecise, and extremely inefficient, but it is, in 
fact, fundamental to our ability to apprehend information. 
Though a computer can store thousands of high-resolution 
photographs, it is unable to understand them as we do. We 
perceive and remember very little because our brain prior-
itizes understanding. Our ability to extract meaning and 
understand is the result of millions of years of evolution, of 
trial and error that settled on the best possible strategy after 
attempting countless others. A brilliant inventor in search of 
a revolution in artificial intelligence could, in principle, try to 
replicate the strategy employed by our brain—in fact, replicat-
ing basic brain principles led to major recent breakthroughs 
with the development of deep neural networks15—but dupli-
cating its parallel processing and redundancy would not be 
enough. The key lies in selecting exactly what to process 
and how to process it. The scant information we choose to 
process depends on the task we have at hand—for example, 
we see the same book very differently if we are looking for 

156	
T H E  F O R G E T T I N G  M AC H I N E
something to read than if we need a way to raise the computer 
monitor. This flexibility in attributing meaning, in selecting 
which information to process and which to discard, is what 
defines our intelligence. Our limitation in the processing and 
retrieval of information is precisely what distinguishes us 
from savants, other animals, HAL 9000, the internet, a rep-
licant, or the Terminator. Our capacity to manage and relate 
abstractions, coded by concept neurons in the hippocampus, 
is the basis of our memory—and, perhaps, the cornerstone of 
what makes us human.

157
N O T E S
Chapter 1
1	
Curiously, Roy Batty’s final words, repeatedly quoted by sci-fi film buffs, are 
not in Dick’s book, nor do they appear in the film’s original script. They were 
sketched by Rutger Hauer shortly before the scene was shot.
2	
Similar arguments have been put forth by Ray Kurzweil (a famous futurist 
and inventor of the first print-to-speech reading machine for the blind) to 
defend the idea of a cybernetic, “transhuman” being that could transcend 
the many weaknesses of our bodies and, presumably, of our brains.
3	
To simplify matters, I am leaving aside the complex processes that unfold 
while neurons are not firing. These are known as subthreshold activity.
4	
Hopfield’s original paper from the early 1980s opened up an important 
research avenue in neuroscience. To give you an idea of the impact of this 
work, while most scientific papers are cited at most a few times by other 
papers, Hopfield’s paper has over 18,000 citations to date. See: John Hop-
field. “Neural networks and physical systems with emergent collective com-
putational properties.” Proceedings of the National Academy of Sciences 79 
(1982): 2554–2558.
5	
Santiago Ramón y Cajal. “The Croonian Lecture: La fine structure des 
centres nerveux.” Proceedings of the Royal Society of London 55 (1894): 
444–468.
6	
Donald Hebb. The Organization of Behavior: A Neuropsychological Theory. 
New York: John Wiley and Sons, 1949.

158	
N o t e s
7	
Bliss and Lømo’s work was published in: Tim Bliss and Terje Lømo. 
“Long-lasting potentiation of synaptic transmission in the dentate area of 
the anaesthetized rabbit following stimulation of the perforant path.” Jour-
nal of Physiology 232 (1973): 331–356.
8	
Among other works that show the relation between LTP and memory for-
mation, refer to: R. Morris, E. Anderson, G. Lynch and M. Baudry. “Selec-
tive impairment of learning and blockade of long-term potentiation by 
an N-methyl-D-aspartate receptor antagonist, AP5.” Nature 319 (1986): 
774–776.
9	
Recent estimations give a more precise figure of 86 billion neurons: Suzana 
Herculano-Houzel. “The human brain in numbers: a linearly scaled-up pri-
mate brain.” Frontiers in Human Neuroscience 3 (2009): article 31.
10	 Of course, this number depends on the type of sand and the truck’s capac-
ity. Considering that a grain of sand can have a diameter between 0.02 mm 
and 2 mm, let us assume an average diameter of 0.5 mm. One centimeter 
can thus hold twenty grains of sand side by side, and a volume of one cubic 
centimeter can hold approximately 20 × 20 × 20 = 8,000 grains of sand. The 
cargo compartment of a truck measures approximately 5 m × 2 m × 1.5 m, 
which corresponds to a volume of 15 million cubic centimeters. This means 
that a truck can transport some 15 million times 8,000 or 1.2×1011 grains 
of sand, which approximately corresponds to the number of neurons in the 
brain. Following this analogy, the number of neurons in a snail’s brain cor-
responds to approximately a pinch of sand, the total in a fly or an ant to a 
soupspoon full of sand, in a bee or a cockroach to the amount of sand in a 
small coffee cup, in a frog to a two-liter bottle full of sand, in a mouse to the 
sand in a bucket, in a cat to a wheelbarrow full of sand, and the number of 
neurons in a macaque monkey corresponds to the sand that fits in an exca-
vator shovel. However, intelligence is not just determined by the number of 
neurons an animal has, as the number of neurons in the brain of an African 
elephant corresponds to three cargo trucks full of sand and the number in 
a whale to five cargo trucks. What really matters is how the neurons con-
nect to each other, forming complex circuits that underlie different brain 
functions.
11	 In this case, we consider the beach to have a width of 50 meters and a depth 
of 25 meters (half as much as the width).
12	 This value corresponds to a specific configuration but provides an 
order-of-magnitude estimate. For more details, see: E. Gardner. “Maximum 
storage capacity in neural networks.” Europhysics Letters 4 (1987): 481–485.

	
N o t e s 	
159
13	 Although it is almost impossible to estimate the fraction of neurons gener-
ally involved in the encoding of memories, some studies in monkeys esti-
mate that about 1.7 percent of the neurons in the intertemporal cortex are 
involved in memory-retrieval tasks. For more details, see: Kuniyoshi Sakai 
and Yasushi Miyashita. “Neural organization for the long-term memory of 
paired associates.” Nature 354 (1991): 152–155.
Chapter 2
1	
This work was published in: Kristin Koch, Judith McLean, Ronen Segev, 
Michael A. Freed, Michael J. Berry II, Vijay Balasubramanian, and Peter 
Sterling. “How much the eye tells the brain.” Current Biology 16 (2006): 
1428–1434.
2	
Binary numbers are sequences of digits, each of which can have only one 
of two values, 0 or 1. For example, 0001 equals 1 in decimal notation, 0010 
equals 2, 0011 equals 3, 0100 equals 4, and so on. It is easy to implement 
binary numbers in digital circuits, and for that reason they are the basic 
language of computers.
3	
Analogously, three bits can represent eight objects, four bits sixteen objects, 
and in general, N bits can represent 2N objects.
4	
Claude Shannon (1916–2001) studied electrical engineering and mathemat-
ics at the University of Pittsburgh and graduated at only twenty years of 
age. He then earned a master’s degree at MIT, where he applied algebraic 
principles to the development of circuits, and during the war worked on 
cryptography at Bell Labs, developing and cracking secret codes. After the 
war, Shannon dedicated himself to the subject in which he was to obtain his 
greatest achievements: the study of the encoding and optimal transmission 
of information. Shannon introduced concepts such as “Shannon entropy,” 
which is used to measure (in bits) the amount of information contained in a 
message. Shannon’s most celebrated work is a paper published in 1948 that 
originated information theory: Claude Shannon. “A Mathematical Theory 
of Communication.” Bell System Technical Journal 27 (1948): 379–423 and 
623–656.
	
For the application of information theory to neuroscience, see for exam-
ple: Rodrigo Quian Quiroga and Stefano Panzeri. “Extracting information 
from neural populations: Information theory and decoding approaches.” 
Nature Reviews Neuroscience 10 (2009): 173–185.

160	
N o t e s
5	
With 24 bits, it is possible to generate more than 16 million different colors. 
Nowadays there are monitors with a color depth of 32 bits, but their color 
resolution is essentially indistinguishable from that of a 24-bit monitor.
6	
As was to be expected, this fact was not left unnoticed and was indeed 
refuted by an expert on the topic, who estimated that the minimum resolu-
tion for the eye to be unable to differentiate pixels at a 30 cm distance is 477 
ppi. However, in support of Jobs’s statement (or of the group of research-
ers at Apple who provided him with the figure), a later article in Discover 
magazine showed that only someone with perfect vision would be able to 
differentiate pixels at 300 ppi, and that this resolution is more than suffi-
cient for most people. For more details on this discussion, see www.wired 
.com/2010/06/iphone-4-retina-2 and http://blogs.discovermagazine.com 
/badastronomy/2010/06/10/resolving-the-iphone-resolution.
7	
The bottom image was taken at the British Museum in London by Carlos 
Pedreira and Joaquín Navajas, two students in my laboratory. Using a mov-
able eye tracker, Carlos and Joaquín concluded that, in the course of a few 
minutes in a museum room, people looked on average at some fifty objects 
for more than one second. The surprising result was that, after they left the 
room, they were asked what they had seen and could remember only five or 
so objects. This fact gives rise to several interesting conclusions, but we defer 
until later the discussion of how little we remember.
8	
These days, an eye tracker simply films the pupil with a digital camera. In 
Yarbus’s time, experiments were much more tedious, since eye movements 
were recorded using the reflection of a beam of light on a small mirror 
mounted on something resembling a contact lens that was implanted in the 
subject’s eyeballs. These techniques, as well as several eye-tracking results, 
are described in Yarbus’s classic: Alfred Yarbus. Eye Movements and Vision. 
New York: Plenum Press, 1967.
9	
This experiment was carried out in my laboratory for a documentary, aired 
in England by Channel 4, about the way we perceive art. We went beyond 
elementary observation (like the fact that we tend to concentrate on the 
eyes when we look at a face) and studied how gaze patterns changed after 
we modified details of the paintings using Adobe Photoshop. Using an eye 
tracker, in another experiment, we studied how people observed works of 
art at the Tate Gallery, and, highlighting the importance of seeing original 
works of art at the museum, we observed that the fixation patterns were rad-
ically different when people looked at reproductions stored in a computer. 
For more details about these experiments, see: Rodrigo Quian Quiroga 

	
N o t e s 	
161
and Carlos Pedreira. “How do we see art: an eye-tracker study.” Frontiers in 
Human Neuroscience 5 (2011): article 98.
	
And: Jennifer Binnie, Sandra Dudley, and Rodrigo Quian Quiroga. 
“Looking at Ophelia: A comparison of viewing art in the gallery and in the 
lab.” Advances in Clinical Neuroscience and Rehabilitation 11 (3) (2001): 
15–18.
10	 Art is so subjective that, whereas Van Gogh’s paintings reach astounding 
prices nowadays, the artist himself managed to sell a single painting in his 
lifetime; so subjective that we typically require some objective guideline, like 
the artist’s renown, the opinions of critics, or the majesty of the surround-
ings, to decide which works of art are good and which are not. Joshua Bell, 
a famous violinist who routinely fills the most prestigious concert halls, was 
barely noticed by a handful of people as he played a Bach concerto on his 
Stradivarius in a subway station.
11	 I was lucky to have Mariano rotate for one year in my laboratory, bridging 
ideas from art and neuroscience about visual perception. The result of this 
collaboration was “The Art of Visual Perception,” an art and science show 
exhibited in a gallery in England. For more details, see www.youtube.com/
watch?v=cg8RZE65Na4.
Chapter 3
1	
For an entertaining but rigorous discussion of the way neurons are orga-
nized in the retina, see Chapter 3 of the book by David Hubel, a disciple of 
Kuffler’s who went on to share the Nobel Prize for Physiology or Medicine 
with Torsten Wiesel for their study of the primary visual cortex, the first 
area in the cortex that receives information from the retina: David Hubel. 
Eye, Brain and Vision (Second Edition). Scientific American Library Series, 
London/New York: W. H. Freeman, 1995.
	
For a free online version of the book, see: http://hubel.med.harvard.
edu/index.html.
2	
This is a principle well known by visual artists, who use contrast to highlight 
the brightness of a given color in their palette. For a fascinating description 
of the subject, see: Margaret Livingstone. Vision and Art: The Biology of See-
ing. New York: Harry N. Abrams, 2008.
3	
For more details, see: Horace Barlow. “The Ferrier lecture 1980: Critical lim-
iting factors in the design of the eye and visual cortex.” Proceedings of the 
Royal Society of London B, 212 (1981): 1–34.

162	
N o t e s
4	
This is, of course, just a very brief allusion to the philosophical roots of this 
discussion. For more detailed treatments of the subject, refer, for example, 
to: Anthony Kenny. A New History of Western Philosophy. Oxford: Oxford 
University Press, 2012.
	
And: Bertrand Russell. A History of Western Philosophy. London: Rout-
ledge Classics, 1946.
5	
The breadth of the contributions of Helmholtz (1821–1894) to different areas 
of science is truly astounding. Among other things, Helmholtz formulated 
the principle of conservation of energy and postulated the notion of free 
energy in thermodynamics, invented the ophthalmoscope to examine the 
retina, measured the conduction speed within nerves, derived a mathemati-
cal description of acoustic vibrations, and established the modern theory of 
colors using three variables (hue, saturation, and brightness) to characterize 
them.
6	
Several authors, in particular David Hubel and Torsten Wiesel, developed 
an animal model to study alterations in behavior and in the response pat-
terns of neurons in visual areas caused by visual deprivation. To that end, 
they sewed shut the eyelids of cats of different ages and for different spans of 
time (usually a few days after birth and for three months) and then studied 
the behavior of the animals after their eyes reopened. For more informa-
tion, refer to: Torsten Wiesel and David Hubel. Journal of Neurophysiology 
26 (1963): 978–993.
7	
S.B.’s case, along with a brief historical overview of similar cases, is described 
in: Richard Gregory and Jean Wallace. “Recovery from early blindness: A 
case study.” Experimental Psychology Society Monograph No. 2. London: Hef-
fer, 1963.
	
Oliver Sacks describes a similar case in his book An Anthropologist on 
Mars. The movie At First Sight, starring Val Kilmer, is based on this story.
8	
The Man Who Mistook His Wife for a Hat is indeed the title of one of Sacks’s 
most famous books.
Chapter 4
1	
Jorge Luis Borges. Ficciones. Buenos Aires: Sur, 1944.
2	
William James. The Principles of Psychology. Vol. 1. New York: Henry Holt, 
1890, 680.
3	
Themistocles was the strategist behind the Greek naval defense against the Per-
sian invasions and, according to Cicero, possessed an extraordinary memory.

	
N o t e s 	
163
4	
Rodrigo Quian Quiroga. Borges and Memory. Cambridge, MA: MIT Press, 
2012.
5	
Gustav Spiller. The Mind of Man: A Text-Book of Psychology. London: Swan 
Sonnenschein & Co., 1902.
	
As I investigated the pursuits and readings that could have inspired 
Borges’s brilliant vision of memory in “Funes the Memorious,” by chance 
I stumbled into Spiller’s book in Borges’s library. The book had a note on 
the first page in Borges’s own handwriting referring to the fragment where 
Spiller estimates the number of memories he collected throughout his life. 
For more details, see Chapter 2 of Borges and Memory.
6	
The very small number of memories we keep from our first years of life 
is a phenomenon known as childhood amnesia. Childhood amnesia has 
attracted the attention of neuroscientists and psychologists, especially after 
Sigmund Freud published a set of seminal studies of subconscious repression 
during childhood. For more details, refer to Chapter 12 of: Alan Baddeley, 
Michael Eysenck, and Michael Anderson. Memory. New York: Psychology 
Press, 2009.
7	
Galton quantified his memory capacity by assessing the number of recollec-
tions brought forth by a set of words. This work was published in: Francis 
Galton. “Psychometric experiments.” Brain 2 (1879): 149–162.
	
And also as part of a book: Francis Galton. Inquiries into Human Fac-
ulty and Its Development. London: Dent & Sons, 1907.
8	
For a review of the literature on the capacity of human memory, refer to: 
Yadin Dudai. “How big is human memory, or on being just useful enough.” 
Learning and Memory 3 (5) (1997): 341–365.
9	
Hermann Ebbinghaus. Über das Gedächtnis: Untersuchungen zur experimen-
tellen Psychologie. Leipzig: Duncker & Humblot, 1885. (Memory: A Contri-
bution to Experimental Psychology, Tr. Henry A. Ruger & Clara E. Bussenius. 
New York: Teachers College, Columbia University, 1913.)
10	 For a description of the results obtained with many subjects, see Chapter 5 
of the book: Frederic Bartlett. Remembering. Cambridge: Cambridge Uni-
versity Press, 1932.
	
Chapter 7 describes similar results obtained using several other sto-
ries. For a description of the contrasting views of Ebbinghaus and Bartlett, 
see Chapter 5 of: Alan Baddeley, Michael Eysenck, and Michael Anderson. 
Memory. New York: Psychology Press, 2009.

164	
N o t e s
11	 Elizabeth Loftus and John Palmer. “Reconstruction of automobile destruc-
tion: An example of interaction between language and memory.” Journal of 
Verbal Learning and Verbal Behavior 13 (1974): 585–589.
12	 For more details, see: Elizabeth Loftus. “Our changeable memories: Legal 
and practical implications.” Nature Reviews Neuroscience 4 (2003): 231–234.
13	 Testimony by Cotton, Thompson, and the detective can be found on video: 
www.youtube.com/watch?v=-2oDRfj0vME.
14	 Elizabeth Loftus describes the case of Steve Titus, another man identified 
incorrectly as a rapist. The interesting detail here is that the victim said, 
“That one’s the closest” at the initial lineup and during the trial changed 
her line to “I’m absolutely positive that’s the man.” Titus was set free after a 
subsequent investigation uncovered the true culprit.
15	 The tragic story of Jennifer Thompson and Ronald Cotton had, surprisingly, 
a happy ending. They are close collaborators who advocate for change in 
eyewitness-related practice and wrongful conviction legislation, and even 
wrote a book on the subject.
16	 The results are described in: Thomas Landauer. “How much do people 
remember? Some estimates of the quantity of learned information in long-
term memory.” Cognitive Science 10 (1986): 477–493.
17	 For a review of different estimates of memory capacity see: Yadin Dudai. 
“How big is human memory, or On being just useful enough.” Learning and 
Memory 3(5) (1997): 341–365.
18	 Refer to Chapter 12 of Borges and Memory for a more comprehensive dis-
cussion of the topic.
19	 To arrive at this number, I simply took the number of characters in this 
chapter and divided it by the number of words. Similar estimates can be 
easily found on the internet.
20	 Considering that an average person (or an average text sample) uses no 
more than 20,000 words (see Dudai, 1997), which (as 215 is 32,768) can be 
represented with 15 bits, we obtain 15 × 3 = 45 bps if we assume a reading 
rate of three words per second.
21	 See Table 3 in Dudai (1997).
22	 Again, as we noticed in the case of the visual artists described in Chapter 3, 
there is a very interesting intersection between art—in this case the art of 
magic—and neuroscience. Neuroscientists have much to learn from magi-
cians, who for the last 2,000 years have mastered subjects of great relevance 
to neuroscience such as attention, decision-making, memory, etc. For a 

	
N o t e s 	
165
recent essay on this topic, see: Rodrigo Quian Quiroga. “Magic and cogni-
tive neuroscience.” Current Biology 26 (2016): R387–R407.
23	 Other ways of generating tension include the use of rhythm and volume. A 
monotonous rhythm that is suddenly interrupted cries for its resumption; 
a rhythm that accelerates, decelerates, or plays progressively louder cries 
out for change. These tricks are widely used in contemporary dance music, 
which lacks classical structure in melody and harmony.
24	 This is the basic idea behind what is known as Bayesian inference, a princi-
ple widely used in neuroscience.
Chapter 5
1	
So much for actual events. However, as with any good legend, Quintilian 
on the one hand, and Cicero on the other, spun a much more interesting 
tale with a peculiar mythological background. According to this version, the 
banquet’s host was a nobleman called Scopas, who was celebrating having 
won a boxing match. Simonides was hired to declaim a poem in Scopas’s 
honor, in which Simonides, as was customary, included legendary figures. 
In particular, Simonides mentioned in his poem the brothers Castor and 
Pollux, siblings of Helen of Troy, who were considered the patron saints of 
both athletes and sailors. It came to pass that Scopas maliciously decided to 
pay Simonides only half of the agreed-upon sum for his poem, telling him 
he should charge the rest to Castor and Pollux. According to legend, it was 
Castor and Pollux who came to pay Simonides his due and called him to the 
door just before the roof came crashing down.
2	
When I tried to remember the list of words a few hours after I first wrote 
them, I found that I remembered all of them except the lamp, which, after all, 
was not so conspicuous on the pedestrian crossing. To enhance my memory 
of the lamp, I added detail, imagining that it turned on and off with each 
passing pedestrian. Some ten days after creating this association between 
these words and places, and having given it no thought in the meantime, I 
was able to remember all the words except the first. The problem that time 
was that I had put the bread at the corner, which was the first place I visited 
in my stroll. However, it was so obvious that this was the first spot that I 
failed to take the time to form a specific image of the corner and the loaf of 
bread resting on it. This highlights the need to use vivid and specific images, 
both of the places and of the words you wish to remember.

166	
N o t e s
3	
A study carried out in the 1970s performed this very comparison by giving 
two groups of subjects five lists of twenty words each, and asking one group 
to memorize the lists using the method of loci and the other group to learn 
them some other way. The difference is striking: the first group remembered 
72 percent of the words on average, while the second averaged only 28 per-
cent. For more details, see: Gordon H. Bower. “How to . . . uh . . . remember!” 
Psychology Today 7 (5) (1973): 63–70.
	
An earlier study had shown that the method of loci enabled subjects 
to remember more than 95 percent of a list of between forty and fifty words 
after looking at them only once. For more details, see: John Ross and Kerry 
Ann Lawrence. “Some observations of memory artifice.” Psychonomic Sci-
ence 13 (2) (1968): 107–108.
	
These and other quantitative studies of the method of loci are described 
in Chapter 16 of: Alan Baddeley, Michael W. Eysenck, and Michael C. 
Anderson. Memory. New York: Psychology Press, 2009.
4	
There are various techniques to associate numbers with images. Some are 
described in several books by Dominic O’Brien, as well as in: Joshua Foer. 
Moonwalking with Einstein: The Art and Science of Remembering Everything. 
New York: Penguin, 2012.
5	
The invention of paper, in the year 105 of the current era, is attributed to 
Ts’ai Lun, an official in the royal court of the Han dynasty in China. How-
ever, it took this discovery more than a millennium to be known in the 
West. The manufacture of paper expanded to the Muslim world after the 
battle between the Arab caliphate and the Chinese empire at Talas in 751. 
During this battle, the Arabs captured Chinese prisoners, who taught them 
to make paper in exchange for freedom. But the secrets of paper manu-
facturing were jealously guarded by the Chinese and Arabs alike and were 
unknown in Europe until the twelfth century, when the Spanish retook the 
southern part of the Iberian Peninsula from the Arabs. Before paper, people 
wrote on papyrus (which had to be imported from Egypt and was thus very 
expensive) or on the even dearer parchment (made from animal skin). In 
antiquity, especially in ancient Greece, wax tablets—slabs of wood with wax 
spread on one side—were also used. Several writing techniques were indeed 
available in ancient times, but they were onerous and expensive, and thus of 
limited use; hence the relevance of exercising memory.
6	
Along with the anonymous Ad herenium, these are the most important 
works on memory and mnemonics to come to us from antiquity.

	
N o t e s 	
167
7	
References to the remarkable powers of memory of these men can be found 
in the treatises by Cicero and Quintilian and in Pliny the Elder’s Naturalis 
historia.
8	
Cicero, De oratore II, LXXXVIII, 360.
9	
Historian Frances Yates attributes the loss of the Greek-initiated tradition 
of mnemonics to the difficulties of a barbarous age, where it was dangerous 
even to assemble to listen to someone speak. Moreover, the main reference 
works on mnemonics were lost, and medieval studies of memory, mainly 
Aquinas’s, were based on texts either incomplete or misinterpreted. This was 
particularly true in the case of Quintilian’s Institutio oratoria, which offered 
the most concrete description of the method of loci as used by orators in 
Greece and Rome, and whose complete text was found as late as 1416, in the 
library of the Abbey of St. Gall in present-day Switzerland. In these para-
graphs I follow the arguments set forth by Frances Yates, who drafted a fasci-
nating historical description of the use of mnemonics from antiquity to the 
Renaissance in her 1966 book The Art of Memory (London: Routledge).
10	 Peter of Ravenna, Fornix, ed. of Venice, 1491, quoted in Yates, The Art of 
Memory, 113.
11	 Fragment of a letter from Vigilius Zuychemus to Erasmus of Rotterdam, 
quoted in Yates, The Art of Memory,  131. Vigilius was one of the few people 
to have access to the wooden model, which was never finished or shown to 
the public. His writings to Erasmus are one of the few concrete proofs of the 
theater’s existence.
12	 Giulio Camillo, L’idea dela theatro, Florence and Venice, 1550, quoted in 
Yates, The Art of Memory, 138.
13	 Roberto Belarmino, a cardinal inquisitor and a member of the tribunal that 
sentenced Giordano Bruno to be burned at the stake, was very involved 
years later in the famous trial of Galileo Galilei for heresy due to Galileo’s 
support of Copernicus’s heliocentric theory.
14	 Again, for more details I refer to Frances Yates’s book, in this case to the fifth 
and final chapter.
15	 Luria offers a brief and fascinating account of Shereshevskii in his book The 
Mind of a Mnemonist: A Little Book about a Vast Memory. Cambridge, MA: 
Harvard University Press, 1987.
16	 The extraordinary similarity between Funes and Shereshevskii is explored 
in Chapter 3 of: Rodrigo Quian Quiroga. Borges and Memory. Cambridge, 
MA: MIT Press, 2011.

168	
N o t e s
17	 As we saw in the previous chapter, this notion was already present in the 
ideas of Aristotle and Thomas Aquinas.
18	 For more details about Kim Peek and other savants, see: Darrold Treffert. 
Islands of Genius (London: Jessica Kingsley, 2010). Dr. Treffert is a savant 
specialist who worked with Peek for many years.
Chapter 6
1	
Estimates based on considerations of anatomy (such as neuron density) and 
neurophysiology (such as the effective area in which an electrode can regis-
ter a neuron’s firing) conclude that between 5 percent and 10 percent of neu-
rons whose activity can be recorded are active at a given instant. For more 
details, see: Gyorgy Buzsáki. “Large-scale recording of neuronal ensembles.” 
Nature Neuroscience 7 (5) (2004): 446–451.
2	
The activation of neurons is a very expensive process in metabolic terms. 
The brain represents about 2 percent of a human body’s mass but uses 20 
percent of its energy.
3	
Part of the difficulty in finding a general treatment or cure for epilepsy stems 
from the fact that epilepsy is a blanket name historically given to a range 
of pathologies with different clinical manifestations and gestation mecha-
nisms. A child who lapses for a few seconds into an absence seizure is very 
different from an adult writhing on the street; a person with a facial tic dif-
fers from another who unexpectedly loses muscular firmness and drops to 
the floor. Another difficulty is that the onset of epileptic seizures tends to 
be abrupt, which makes it hard to determine, based on electroencephalo-
graphic records, just when and why a seizure began. In fact, starting in the 
1990s, several labs have devoted their efforts to predicting epileptic seizures, 
with no success so far. For example, see: Florian Mormann, Ralph Andrze-
jak, Christian Elger, and Klaus Lehnertz. “Seizure prediction: the long and 
winding road.” Brain 130 (2) (2007): 314–333.
4	
Participants in memory championships attempt to memorize the greatest 
number of cards, numbers, words, names, etc.
5	
As reported in: Alan Baddeley, Michael W. Eysenck, and Michael C. Ander-
son. Memory. New York: Psychology Press, 2009, 363.
6	
A survey carried out in Norway showed that more than 90 percent of 
respondents thought that it is possible to improve one’s memory, just as 
one can become stronger by exercising. This belief, however, is incorrect, 
since the prowess attained by exercising a specific type of memory does not 

	
N o t e s 	
169
transfer to other types. For more details, see: Svein Magnussen et al. “What 
people believe about memory.” Memory 14 (2006): 595–613.
	
For more details about the fact that memory abilities do not transfer, 
see: A. Owen, A. Hampshire, J. Grahn, R. Stenton, S. Dajani, A. Burns, R. 
Howard, and C. Ballard. “Putting brain training to the test.” Nature 465 
(2010): 775–778.
7	
A recent study compared the ability of students to remember the names of 
people they met at a party using different methods. Surprisingly, those who 
used a visual technique (relating each name to a different thing) recalled 
fewer names than those who used no method at all. The problem is that the 
distractions present in a real situation, such as at a party, conspire to hinder 
an optimal implementation of the method. For more details, see: P. Morris, 
C. Fritz, L. Jackson, E. Nichol, and E. Roberts. “Strategies for learning proper 
names: Expanding retrieval practice, meaning and imagery.” Applied Cogni-
tive Psychology 19 (2005): 779–798.
8	
In the final pages of his 2012 book Moonwalking with Einstein, Joshua Foer 
mentions that, while the use of mnemonics greatly improved his ability to 
remember information, one night, as he returned home via the subway after 
dinner with friends, he realized he had taken his car to the restaurant.
9	
A study carried out with professors at the University of California, Berke-
ley, showed that, given their prolific intellectual activity, the professors had 
much smaller memory and cognitive deficits due to aging compared to 
other people. For more details, see: Arthur Shimamura, Jane Berry, Jennifer 
Mangels, Cheryl Rusting, and Paul Jurica. “Memory and cognitive abilities 
in university professors.” Psychological Science 6 (1995): 271–277.
10	 Rodrigo Quian Quiroga. Borges and Memory. Cambridge, MA: MIT Press, 
2012.
11	 This estimate was made by Martin Hilbert, communications expert and pro-
fessor at the University of California, Davis, taking into account the infor-
mation received through email, television, cell phones, newspapers, radio, 
etc. For more details, see: Martin Hilbert and P. López. “The world’s techno-
logical capacity to store, communicate, and compute information.” Science 
332 (6025) (2011): 60–65.
12	 In The Shallows: What the Internet Is Doing to Our Brains (New York: W. 
W. Norton, 2010), Nicholas Carr describes how, after using the internet for 
many years, he finds it almost impossible to focus enough to read a book.
13	 In Moonwalking with Einstein, Joshua Foer relates how difficult it is to find 
the most intelligent person in the world. In fact, Google makes it relatively 

170	
N o t e s
easy to find the oldest, tallest, or (according to some competition result) 
strongest person. But how do we define who is smartest? IQ provides only 
a vague idea, and in fact its ability to measure intelligence is quite limited. 
What is interesting about Foer’s quest is that it led him naturally to search 
for people with prodigious memory. To aid his search, Foer started to hone 
his own memory, with the unexpected consequence that he ended up win-
ning a memory championship in the US. His bestseller is an entertaining 
account of this series of events—in particular, his learning of the method of 
loci and his interaction with professional mnemonists.
14	 Among other things, Richard Andersen discovered two areas of the brain 
(in the posterior parietal cortex, to be precise) whose function is to plan 
arm and eye movements, respectively. For many years, Richard has studied 
how visual information leads to movement execution—for example, when 
lifting a glass from a table. See, for example: Hans Scherberger, Rodrigo 
Quian Quiroga, and Richard Andersen. “Coding of movement intentions.” 
In: Rodrigo Quian Quiroga and Stefano Panzeri, eds. Principles of Neural 
Coding. Boca Raton, FL: CRC Press, 2013, 303–321.
	
As for the advice to focus on just one or two general messages, Carol, 
Richard’s wife, told me some time later that it was she who recommended 
this rule to him as she heard him rehearse his talks.
15	 In the first part of this fragment, James quotes from: James Mill. Analysis of 
the Phenomena of the Human Mind. Vol. 1. London: Baldwin & Cradock, 
1829, 235.
16	 This, of course, applies to adults as well. I have seen this firsthand while 
teaching physics to high school and first-year university students. Few peo-
ple struggle when asked at what constant speed a car must travel to cover 
500 meters in two minutes. On the other hand, students find the exact same 
problem to be more challenging when formulated in a different way. For 
example: “I have only two minutes to pick up my sister from the supermar-
ket, which is 500 meters away from home; if I keep the speed constant along 
the way, how fast should I drive to make it on time?” In fact, one of the first 
and most difficult things that students must learn is to comprehend what 
they are being asked and then set out a strategy to solve the problem. This, 
again, involves identifying and discarding irrelevant information to focus on 
what matters—the car has to cover 500 meters in two minutes, whether to go 
to a supermarket, to test-drive a new set of tires, etc.

	
N o t e s 	
171
Chapter 7
1	
See, for example: Alan Baddeley, Michael Eysenck, and Michael Anderson. 
Memory. New York: Psychology Press, 2009.
2	
George Sperling. “The information available in brief visual presentation.” 
Psychological Monographs 74 (11) (1960): 1–29.
3	
In the case of the visual system, sensory memory is also called iconic mem-
ory. Its aural counterpart, called echoic memory, is analogous, but unlike 
iconic memories, which last for a fraction of a second, echoic memories can 
last up to three or four seconds.
4	
Richard Atkinson and Richard Shiffrin. “Human memory: A proposed sys-
tem and its control processes.” In K. W. Spence and J. T. Spence, eds. The 
Psychology of Learning and Motivation. Vol. 2. New York: Academic Press, 
1968, 89–195.
5	
For more details, refer to, among many others, the original paper in which 
H.M.’s case was first described: William Scoville and Brenda Milner. “Loss 
of recent memory after bilateral hippocampal lesion.” Journal of Neurology, 
Neurosurgery, and Psychiatry 20 (1957): 11–21.
	
For a more recent review, see: Larry Ryan Squire. “The legacy of patient 
H.M. for neuroscience.” Neuron 61 (11) (2009): 6–9.
Chapter 8
1	
For a comprehensive description of how visual information is processed 
along the ventral visual pathway, see: N. K. Logothetis and D. L. Shein-
berg. “Visual object recognition.” Annual Review of Neuroscience 19 (1996): 
577–621.
	
And: K. Tanaka. “Inferotemporal cortex and object vision.” Annual 
Review of Neuroscience 19 (1996): 109–139.
2	
Beside Christof and Itzhak, this work also involved Gabriel Kreiman, Leila 
Reddy, and, later, Alexander Kraskov.
3	
Of course, a horizontal line or a face are also concepts, so depending on what 
we mean by “concept” one can argue that neurons in V1 and IT respond to 
concepts as well. Semantics aside, I hope it’s clear what I mean when I say 
that we found for the first time a neuron firing to a concept—I am referring 
to the concept of a specific person.
4	
For more details, see: Rodrigo Quian Quiroga, Leila Reddy, Gabriel Krei-
man, Christof Koch, and Itzhak Fried. “Invariant visual representation by 
single neurons in the human brain.” Nature 435 (2005): 1102–1107.

172	
N o t e s
5	
The fact that there are more neurons encoding familiar concepts was proved 
in: I. Viskontas, Rodrigo Quian Quiroga, and Itzhak Fried. “Human medial 
temporal lobe neurons respond preferentially to personally relevant images.” 
Proceedings of the National Academy of Sciences 106 (2009): 21329–21334.
6	
For more details about neuron response to photographs and names (either 
written or spoken) of people, see: Rodrigo Quian Quiroga, Alexander 
Kraskov, Christof Koch, and Itzhak Fried. “Explicit encoding of multimodal 
percepts by single neurons in the human brain.” Current Biology 19 (2009): 
1308–1313.
7	
The neuron in Figure 8.4 responded not only to my photos, but also to pho-
tos of three of my colleagues performing experiments at UCLA; another 
neuron responded to both the Tower of Pisa and the Eiffel Tower; the Jenni-
fer Aniston neuron, when tested the next day, responded also to Lisa Kud-
row (another actress from the sitcom Friends); a neuron that responded to 
Jerry Seinfeld also responded to Kramer (both were characters in the same 
sitcom); and so on.
	
More recently, we showed quantitatively that these neurons tend to 
encode meaningful associations and that they can modify their response 
patterns to encode new associations on the fly. For more details, see: Emanu-
ela de Falco, Matias Ison, Itzhak Fried, and Rodrigo Quian Quiroga. “Long-
term coding of personal and universal associations underlying the memory 
web in the human brain.” Nature Communications 7 (2016): 13408.
	
And: Matias Ison, Rodrigo Quian Quiroga, and Itzhak Fried. “Rapid 
encoding of new memories by individual neurons in the human brain.” Neu-
ron 87 (2012): 220–230.
8	
The description and implications of how little we remember is the central 
theme of my 2012 book, Borges and Memory.
9	
In this formulation of the model, I will set aside technical details and will 
also refrain from describing the considerable amount of scientific evidence 
that is consistent with it. For more details, see: Rodrigo Quian Quiroga. 
“Concept cells: the building blocks of declarative memory functions.” Nature 
Reviews Neuroscience 13 (2012): 587–597.
10	 In line with this argument, patients with injuries in the medial temporal lobe 
have not only a memory deficit but also a shortfall at imagining new situa-
tions, since they are able only to envision isolated facts, devoid of context. 
For more details, see: D. Hassabis, D. Kumaran, S. Vann, and E. Maguire. 
“Patients with hippocampal amnesia cannot imagine new experiences.” Pro-
ceedings of the National Academy of Sciences 104 (2007): 1726–1731.

	
N o t e s 	
173
Chapter 9
1	
The topic of personal identity has been widely explored in philosophy. See, 
for example, Chapter 6 of: J. Hospers. An Introduction to Philosophical Anal-
ysis. London: Routledge, 1956.
2	
Aristotle. On the Soul. Translated by J. A. Smith. Oxford: Clarendon Press, 
1928, 412b.
3	
Aristotle. On the Soul, 408b.
4	
The rejection by medieval scholastic philosophy of Aristotle’s thought 
was mostly a consequence of the interpretation of his ideas given by the 
twelfth-century Muslim philosopher Averroës, who denied the immortality 
of the individual soul. According to Averroës, at the moment of death the 
soul loses its individuality and becomes part of a universal soul, like drops 
in the ocean. Thomas Aquinas, on the other hand, took up Aristotle’s dis-
tinction between active intellect (the one exclusive to humans that allows 
reasoning) and receptive intellect (the one we share with animals, which 
allows sensation) and stated that it is the receptive intellect, both in humans 
and animals, that disappears upon death, while the active intellect, the indi-
vidual soul, is indeed immortal as such. 
	
For a discussion on different interpretations of Aristotle’s position on 
this subject, see: Anthony Kenny. A New History of Western Philosophy. 
Oxford: Clarendon Press, 2005, Chapters 4 and 7.
	
And: Bertrand Russell. A History of Western Philosophy. London: Rout-
ledge Classics, [1946] 2004, Chapter 19.
5	
Turing proposed his famous test in: Alan Turing. “Computing machinery 
and intelligence.” Mind 59 (1950): 433–460.
6	
For a critical discussion of the Chinese room argument, refer to Searle’s 
original paper and subsequent commentary by several authors in: J. Searle. 
“Minds, brains, and programs.” Behavioral and Brain Sciences 3 (1980): 
417–457.
7	
For a popular discussion of Nicky Clayton’s work, see: V. Morell. “Nicky and 
the jays.” Science 315 (2007): 1074–1075.
	
For a more detailed and technical discussion, see: U. Grodzinski and N. 
Clayton. “Problems faced by food-caching corvids and the evolution of cog-
nitive solutions.” Philosophical Transactions of the Royal Society of London B 
365 (2010): 977–987.
8	
For a summary of these works, see: Larry Squire and Stuart Zola-Morgan. 
“The medial temporal lobe memory system.” Science 253 (1991): 1380–1386.

174	
N o t e s
9	
For an overview of these works, see: John O’Keefe. “A review of the hippo-
campal place cells.” Progress in Neurobiology 13 (1979): 419–439.
	
And: Edvard Moser, Emilio Kropff, and May-Britt Moser. “Place cells, 
grid cells and the brain’s spatial representation system.” Annual Reviews of 
Neuroscience 31 (2008): 69–89.
	
As well as: K. Nakazawa, T. McHugh, M. Wilson, and S. Tonegawa. 
“NMDA receptors, place cells and hippocampal spatial memory.” Nature 
Reviews Neuroscience 5 (2004): 361–372.
10	 For more details, see: Rodrigo Quian Quiroga. “Concept cells: the building 
blocks of declarative memory functions.” Nature Reviews Neuroscience 13 
(2012): 587–597.
11	 For more details, see, for example: Gordon Gallup, Jr. “Chimpanzees: self- 
recognition.” Science 167 (1970): 86–87.
	
And: Gordon Gallup, Jr. “Self-recognition in primates: a comparative 
approach to the bidirectional properties of consciousness.” American Psy-
chologist 32 (1977): 329–338.
	
As well as: J. Plotnik, F. de Waal, and D. Reiss. “Self-recognition in an 
Asian elephant.” Proceedings of the National Academy of Sciences 103 (2006): 
17053–17057.
12	 Lev Vygotsky. Thought and Language. Cambridge, MA: MIT Press, 1986.
13	 Daniel Dennett. Kinds of Minds. New York: Basic Books, 1997, 150–151.
14	 Temple Grandin, a professor at Colorado State University and an expert 
in animal behavior, asserts that animals are able to see details that human 
beings overlook by virtue of our abstraction- and inference-based thought. 
Interestingly, she is autistic, and claims that the attention to detail that she 
shares with many other autists (and savants) allows her to better understand 
the way animals think. In her 2006 book Animals in Translation: The Woman 
Who Thinks Like a Cow (London: Bloomsbury), Grandin in fact makes an 
interesting parallel between the thought processes of animals and those of 
people with autism.
15	 Alex Krizhevsky, Ilya Sutskever, and Geoffrey Hinton. “Imagenet classifica-
tion with deep convolutional neural networks.” Advances in neural informa-
tion processing systems 25 (2012): 1097–1105.

175
I N D E X
A
abstraction, and language, 151–
153, 154
action potentials, 6
Alhazen, 41
amygdala, 113
Andersen, Richard, 98
animals
consciousness and, 150
memory capacity and, 146–
148, 150
self-awareness and, 148–150
antiquity, importance of memory 
in, 74–75, 97
Aquinas, Thomas, 41, 51, 116, 
137
Aristotle, 40–41, 51, 100, 116, 137
art, 29–31
artificial intelligence, 142
association agnosia, 48
associations, 100
formation of, 127–131
importance of, 73
Astonishing Hypothesis, The 
(Crick), 138–139
Atkinson-Shiffrin model, 108
axons, 6
B
Bartlett, Frederic, 56, 57–58, 62, 
65, 68, 155
Berkeley, George, 41, 45
Besson, Luc, 86
bits, 21–22
Blade Runner (film), 1–2, 3, 3–4, 
10, 142
blindness, followed by sight, 
43–46
Bliss, Tim, 13
Borges, Jorge Luis, 51, 52, 81, 152
brain
basics of, 5. See also neurons
percent used, 86, 87
relation with mind, 138
storage capacity of, 64–65
training, 86

176	
I n d e x
transmission of visual 
information to, 23, 25, 32
vision and, 36, 42, 47
Bruno, Giordano, 77
bytes, 21–22
C
Camillo, Giulio, 76–77
capacity, for memory. See 
memory capacity
Cartesian dualism, 137, 140, 142, 
145
Center of Gaze (Molina), 31
center-surround organization, 
37–38, 39, 47
cerebral cortex, 39
Chinese room, The, 144–145
Cicero, 51, 73, 74
Clayton, Nicky, 146
color, 37–38, 116
combinatorial explosion, 17
comprehension. See also 
understanding
internet and, 95
vs. memory, 82–84, 96–98, 102
computational neuroscience, 9
computers
consciousness and, 140–145
self-awareness and, 134, 
142–145
concept neurons, 120–128, 147–
148, 153
concepts, 120–131
and language, 153
place as, 148
cones, 36
consciousness, 134. See also self-
awareness
animals and, 150
computers/robots and, 140–
145
Crick’s study of, 138–139
degrees of, 150
consolidation, 54–55, 59, 99
associations and, 100
context, 56–57, 94
Cotton, Ronald, 60–61
Crick, Francis, 138–139
Critias (Plato), 75
D
declarative memory, 111–113, 
125
Deep Blue, 142
deep neural networks, 155
delay match to sample, 146
delay no-match to sample, 147
dendrites, 7
Dennett, Dan, 153
Descartes, René, 41, 136, 137, 140
Dick, Philip K., 3
Do Androids Dream of Electric 
Sheep? (Dick), 3
dopamine, 7
Down, John Langdon, 82–83
dualism, 136, 137–138, 139, 140. 
See also Cartesian dualism
E
Ebbinghaus, Hermann, 53–55, 
57, 62, 99, 106
education, 97–99, 101–102, 103
emotional memory, 113
entorhinal cortex, 123–124
epilepsy, 87, 109, 118
epileptic focus, 118
episodic memory, 112–113, 
130–131

	
I n d e x 	
177
Essay Concerning Human 
Understanding (Locke), 135
Essay Towards a New Theory of 
Vision (Berkeley), 45
excitatory neurons, 8
expectations, 66–67
experience, 42, 43–46, 67
explicit memory, 111–113, 125
eye. See also vision; visual 
information
center-surround organization, 
37–38, 39, 47
fovea, 25–26, 36, 39, 47
retina, 35–38, 39
eye tracking, 26
eyewitness testimony, 59–62
F
fabulation, 59
flashbulb memory, 113
Florida scrub jay, 146
forgetting
benefits of, 50–52
importance of, 154–155
lack of capacity for, 79–82
fovea, 25–26, 36, 39, 47
Fried, Itzhak, 119
functionalism, 142
“Funes the Memorious” (Borges), 
51, 52, 81, 88
G
Gallup, Gordon Jr., 148
Galton, Francis, 53
Gea, Miguel Ángel, 65
Gedankenexperiment
Chinese room, 144–145
zombie of the philosophers, 
140–142
Gregory, Richard, 45–46
Gutenberg, Johannes, 93
H
Haraguchi, Akira, 88
Hebb, Donald, 13, 128
Hebbian cell assemblies, 13
Helmholtz, Hermann von, 41–44, 
58, 65–67, 154
hippocampus, 109, 111, 114, 118, 
125, 130, 147
Hitchcock, Alfred, 66
H.M (Henry Molaison), 109–111, 
118, 123, 125, 147
Hopfield, John, 9
Hopfield networks, 9–12, 15, 16
Hubel, David, 117
humanity, 156
Hume, David, 41
I
Ibn-al-Haytham, 41
identity, 135–136, 139
images, 116
implicit memory, 111
In Search of Lost Time (Proust), 
49–50
inferences, unconscious, 42–43, 
59, 65–67, 154
inferior temporal cortex (IT), 117
information
measuring, 20, 21–22
organization of, 76
information, visual. See visual 
information
information overload, 94–95, 102
information theory, 20–21, 23
inhibitory neurons, 8
intelligence, vs. memory, 96–98

178	
I n d e x
interference effects, 15
internet, 92, 93–95, 102
intracranial electrodes, 118–119
iPhone, 24, 32
IT (inferior temporal cortex), 117
J
James, William, 51, 100
Jennifer Aniston neuron, 120. See 
also concept neurons
Jobs, Steve, 24, 32
K
Kafka, Franz, 135
Kant, Immanuel, 41
Kasparov, Garry, 142
Koch, Christof, 119, 138
Kuffler, Stephen, 37
L
Landauer, Thomas, 62, 64
language, 151–154
learning, 97–99, 101–102, 103
Locke, John, 41, 44–45, 135
Loftus, Elizabeth, 59
Lømo, Terje, 13
long-term memory, 54–55, 57, 
106, 111
long-term potentiation (LTP), 13
Lucy (film), 86
Luria, Alexander, 79–82, 153
M
manipulation, 59–62
materialism, 139, 141
meaning, 43–46, 48, 56–57, 65, 
155. See also schema
medial temporal lobe, 118
memories, false, 68
memory, 108
definitions of, 2–3
as illusion, 17
importance of in antiquity, 97
improving, 91
as movie, 16
persistence of, 54
types of, 105–114. See also 
long-term memory; short-
term memory
memory capacity, 53–56, 62–63
animals and, 146–148, 150
Shereshevskii’s, 81
memory champions, 88–89
memory training, 88–91
Metamorphosis, The (Kafka), 135
method of loci, 70–73, 75, 76–79, 
80–81, 96–97
Metrodorus of Scepsis, 75
Mill, John Stuart, 151–152
Milner, Brenda, 111
mind, 3
as activity of brain, 139–140
relation with body, 137–138
relation with brain, 138
mirror test, 149–150
mnemonics
importance of in antiquity, 
74–75
method of loci, 70–73, 75, 
76–79, 80–81, 96–97
in Renaissance, 76–79
mnemonists, 88, 89
Molaison, Henry (H.M), 109–
111, 118, 123, 125, 147
Molina, Mariano, 31
monism, 136, 140
Moser, Edvard, 147
Moser, May-Britt, 147

	
I n d e x 	
179
motor-skill memory, 113
movies
expectations and, 66
memories as, 16
multitasking, 91
music theory, 65–66
N
neural connectivity, memory and, 
12
neural networks, 8–12
neural networks, deep, 155
neural plasticity, 12, 13, 128
neurons, 3, 5–16
concept neurons, 120–128, 
147–148, 153
epilepsy and, 87
excitatory neurons, 8
firing of, 6–8
functions of, 14
Hopfield networks, 9–12, 15, 
16
inhibitory neurons, 8
involvement in memory, 
15–16
number of, 14, 64
place cells, 147
reinforcement of wiring 
between, 13
retinal ganglion neurons, 
36–38
neuroscience, 4
neurotransmitters, 7
nondeclarative memory, 113, 
130–131
O
O’Brien, Dominic, 88, 89
off-center neurons, 37–38
O’Keefe, John, 147
On the Soul (Aristotle), 40–41
on-center neurons, 37–38
optical illusions, 43
oratory, 97
in antiquity, 74–75
in Renaissance, 76–79
organization, of memories, 70, 
72. See also mnemonics
P
Peek, Kim, 83
Pennsylvania, University of, 23
perception, 40–41, 48
Peter of Ravenna, 76, 94, 100
Phaedo (Plato), 136
Phaedrus (Plato), 92–93
photographs, resolution in, 30
photoreceptors, 36
physicists, 8–9
pineal gland, 138
pixels, 21–22, 24
place, as concept, 148
place cells, 147
Plato, 55, 75, 92–93, 136
Poole, Bobby, 61
primary visual cortex (V1), 39, 
117
printing press, 93
procedural memory, 111
Proust, Marcel, 49–50
psychology, 51
Ptolemy, 41
public speaking, 98
Q
qualia, 130
questions, science and, 4
Quintilian, 74

180	
I n d e x
R
Rain Man (film), 83
Ramón y Cajal, Santiago, 12
reality
assumptions about, 65–67
interpretations of, 68
reasoning, limited capacity for, 
82–84
recognition, of people, 11
Renaissance, 76–79
repetition, 54–55, 99–100, 153
representation, 36, 42, 64
visual agnosia, 47–48
resolution, 30, 32, 65–66
retina, 35–38, 39
Retina display, 24
retinal ganglion neurons, 36–38
robots, consciousness/self-
awareness and, 134, 140–145
rods, 35–36
S
saccades, 26, 39
Sacks, Oliver, 47–48
savants, 83, 84, 88
S.B. (patient), 45–46
schema, 57–58, 68, 155
science, questions and, 4
Scoville, William, 109
Searle, John, 144
self, 3–4. See also consciousness; 
identity; self-awareness
self-awareness, 4, 135–136
animals and, 148–150
computers/robots and, 134, 
142–145
semantic memory, 112–113
sensation, vs. perception, 40–41
sensory memory, 107–108
Shannon, Claude, 20, 21–22
Shereshevskii, Solomon, 79–82, 
88, 96–97
short-term memory, 54, 57, 106, 
109–110
sight. See eye; vision; visual 
information
signs, 42, 47, 58, 155
Simonides, 69–70, 72, 73
Socrates, 92–93
soul, relation with body, 136–137
sound, 116
Sperling, George, 106–108
Spiller, Gustav, 53, 62
stimulus, 50
synapsis, 7
synesthesia, 79–82, 88
systems reply, 144
T
Tarkovsky, Andrei, 95
technology, 92, 93–95, 102
tension, 65–66
terminals, 7
Theaetetus (Plato), 55
Themistocles, 51
Thompson, Jennifer, 60–61
transcendental idealism, 41
Turing, Alan, 143
Turing test, 143–144
U
unconscious inferences, 42–43, 
59, 65–67, 154
understanding, 144–145, 155. See 
also comprehension
universals, 52

	
I n d e x 	
181
V
V1 (primary visual cortex), 39, 
117
van Gogh, Vincent, 29–30
ventral visual pathway, 117
vision, 25–33. See also eye; visual 
information
after blindness since birth, 
43–46
brain and, 36, 42
method of loci and, 73
relationship with memory, 47
visual agnosia, 47–48
visual fixations, 27–31
visual information. See also eye; 
vision
experience and, 42, 43–46
processing of, 40, 47
retina and, 35–38
transmission to brain, 23, 25, 
32
visual process, 117. See also eye; 
vision; visual information
Vygotsky, Lev, 153
W
Wallace, John, 45–46
Wiesel, Torsten, 117
working memory, 109
writing, 92–93
Y
Yarbus, Alfred, 28
Z
zombie of the philosophers, 
140–142


183
183
AC K N O W L E D G M E N T S
I 
wrote this book a few years ago in Spanish, for a science 
dissemination collection directed by Nora Bär, arguably 
the most notable science journalist in Argentina. At that 
time, shortly after having published Borges and Memory, I 
remember wondering what I would like to achieve with this 
book and to whom it should be targeted. I then decided that 
my ideal reader should be a sophomore student, wondering 
about what to do in the future, with so many careers and 
options to choose from (although, of course, I wanted the 
book to be appealing to everybody, I kept the idea of such 
a student in mind when writing it). But my goal was not 
so much to discuss basic neuroscience knowledge; rather, I 
tried to spark the reader’s curiosity and show the fascination 
of studying neuroscience nowadays. Writing a book is a lot of 
work, but I thought that if I managed to help convince even 
a single person to choose to study neuroscience, I would be 
done. (And if in a few years’ time you end up being one of 
those people, please don’t forget to let me know somehow!) 

184	
Ac k n o w l e d g m e n t s
As a high school student, I didn’t like books that told me 
how things are without explaining why—C’mon, I thought, 
don’t take it for granted that I won’t understand; give me a 
chance. Many years later, I learned the hard way (writing my 
own books) that it is a very hard balance to reach. The only 
way to do this is by simplifying things an awful lot. Other-
wise, the book ends up being too technical, accessible to only 
a few specialized colleagues. But when simplifying informa-
tion it is incredibly easy to make mistakes—even more so 
when trying to link current neuroscience ideas with discus-
sions that have been going on for centuries in philosophy. In 
that regard, I thank all the friends, students, and colleagues 
who have read draft versions and spotted a few errors or 
inaccuracies. 
With his refined sarcasm, Jorge Luis Borges once said that 
he first read Cervantes’s Don Quixote in English, and when 
he later read the original in Spanish, it sounded like a bad 
translation. Differences aside, I feel that the English version 
of this book has surpassed the Spanish original. First of all, 
a few years have passed between the two editions and, given 
the frenetic pace at which fields like artificial intelligence 
have been evolving in the last years, this gave me time to 
refine some of the claims I made before—no major changes, 
but a few edits to make the content more current and accu-
rate. But most importantly, I have witnessed how my Spanish 
writing flourished in Juan Pablo Fernández’s translation, and 
how it started to flow more naturally after Alexa Stevenson’s 
editorial work. In Alexa’s case, these were not just grammat-
ical changes, but substantial edits to how the information in 

	
Ac k n o w l e d g m e n t s 	
185
the book is presented. Compared to the original in Spanish, 
I believe the book may now be appealing to a much broader 
audience thanks to Alexa’s work and enthusiasm. 
Today is a national holiday and I came to the office to 
write these lines and finish a few other things. My wife and 
kids wanted to do something all together, but I asked for 
these hours so that the book can finally go to print. They 
understand; they always do. Without their love and support 
this book would not have been possible, and, finally, without 
the support of mis viejos, Hugo and Marisa, I would never 
have realized my dream to become a scientist and spend my 
time doing what I love to do.


187
A B O U T  T H E  A U T H O R
R
odrigo Quian Quiroga holds a Research Chair at 
the University of Leicester, in England, where he is 
the director of the Centre for Systems Neuroscience. 
He graduated with a degree in physics from the University of 
Buenos Aires and obtained his PhD in applied mathematics 
at the University of Luebeck, in Germany. Before joining the 
University of Leicester in 2004, he was a post-doctoral fellow 
at Germany’s Juelich Research Center, was a Sloan fellow at 
the California Institute of Technology, and had short stays at 
RIKEN in Japan and the University of Nijmegen in the Neth-
erlands. He has held visiting positions at the Leibniz Institute 
for Neurobiology in Magdeburg, the International School for 
Advanced Studies (SISSA) in Trieste, Italy, the University of 
California, Los Angeles, the California Institute of Technol-
ogy, the University of Buenos Aires, and CONICET. He is the 
recipient of a Young Investigator Award from the American 
Epilepsy Society and a Royal Society Wolfson Research Merit 

188	
A b o u t  t h e  A u t h o r
Award. In 2014 he was selected as one of the 10 UK RISE 
Leaders in Science and Engineering.
His primary research interest is in the principles of 
visual perception and memory. He discovered what have 
been named “concept cells” or “Jennifer Aniston neurons”—
neurons in the human brain that play a key role in memory 
formation—a finding that was selected as one of the top 100 
scientific stories of 2005 by Discover magazine. His work has 
been published in over 100 research articles and has received 
worldwide media attention, including in the New York Times, 
the Washington Post, Scientific American, New Scientist, and 
the Independent, among others. He is also the author of 
Borges and Memory, linking the ideas of Argentinean writer 
Jorge Luis Borges with the neuroscience of memory.

