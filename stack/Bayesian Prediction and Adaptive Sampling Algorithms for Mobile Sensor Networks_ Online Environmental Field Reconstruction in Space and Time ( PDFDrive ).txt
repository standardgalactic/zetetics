123
SPRINGER BRIEFS IN ELECTRICAL AND COMPUTER
ENGINEERING  CONTROL, AUTOMATION AND ROBOTICS
Yunfei Xu
Jongeun Choi
Sarat Dass
Tapabrata Maiti
Bayesian Prediction 
and Adaptive Sampling 
Algorithms for Mobile 
Sensor Networks
Online Environmental 
Field Reconstruction in 
Space and Time

SpringerBriefs in Electrical and Computer
Engineering
Control, Automation and Robotics
Series editors
Tamer Başar
Antonio Bicchi
Miroslav Krstic

More information about this series at http://www.springer.com/series/10198

Yunfei Xu
• Jongeun Choi
• Sarat Dass
Tapabrata Maiti
Bayesian Prediction
and Adaptive Sampling
Algorithms for Mobile
Sensor Networks
Online Environmental Field Reconstruction
in Space and Time
123

Yunfei Xu
Michigan State University
East Lansing, MI
USA
Jongeun Choi
Michigan State University
East Lansing, MI
USA
Sarat Dass
Department of Statistics
Michigan State University
East Lansing, MI
USA
Tapabrata Maiti
Department of Statistics
Michigan State University
East Lansing, MI
USA
ISSN 2191-8112
ISSN 2191-8120
(electronic)
SpringerBriefs in Electrical and Computer Engineering
ISSN 2192-6786
ISSN 2192-6794
(electronic)
SpringerBriefs in Control, Automation and Robotics
ISBN 978-3-319-21920-2
ISBN 978-3-319-21921-9
(eBook)
DOI 10.1007/978-3-319-21921-9
Library of Congress Control Number: 2015950872
Springer Cham Heidelberg New York Dordrecht London
© The Author(s) 2016
This work is subject to copyright. All rights are reserved by the Publisher, whether the whole or part
of the material is concerned, speciﬁcally the rights of translation, reprinting, reuse of illustrations,
recitation, broadcasting, reproduction on microﬁlms or in any other physical way, and transmission
or information storage and retrieval, electronic adaptation, computer software, or by similar or dissimilar
methodology now known or hereafter developed.
The use of general descriptive names, registered names, trademarks, service marks, etc. in this
publication does not imply, even in the absence of a speciﬁc statement, that such names are exempt from
the relevant protective laws and regulations and therefore free for general use.
The publisher, the authors and the editors are safe to assume that the advice and information in this
book are believed to be true and accurate at the date of publication. Neither the publisher nor the
authors or the editors give a warranty, express or implied, with respect to the material contained herein or
for any errors or omissions that may have been made.
Printed on acid-free paper
Springer International Publishing AG Switzerland is part of Springer Science+Business Media
(www.springer.com)

To our loving parents and beautiful families

Preface
We have witnessed a surge of applications using static or mobile sensor networks
interacting with uncertain environments. To treat a variety of useful tasks such as
environmental monitoring, adaptive sampling, surveillance, and exploration, this
book introduces a class of problems and efﬁcient spatio-temporal models when
scalar ﬁelds need to be predicted from noisy observations collected by mobile
sensor networks. The book discusses how to make inference from the observations
based on the proposed models and also explores adaptive sampling algorithms for
robotic sensors to maximize the prediction quality subject to constraints on mem-
ory, communication, and mobility.
The objective of the book is to provide step-by-step progress in chapters for
readers to gain better understanding of the interplay between all the essential
constituents such as resource-limited mobile sensor networks, spatio-temporal
models, data-driven prediction, prediction uncertainty, and adaptive sampling for
making better predictions. The book builds on previous collective works by the
authors and is not meant to provide a comprehensive review of the topics of
interest. Speciﬁcally, materials from the previous publications by the authors [1–5]
make up a large portion of the book.
In this book, a spatio-temporal scalar ﬁeld is used to represent the collection of
scalar quantities of interest, such as chemical concentration or biomass of algal
blooms (e.g., see Fig. 1.3), transported via physical processes. To deal with com-
plexity and practicality, phenomenological and statistical modeling techniques are
used to make inference from noisy observations collected, taking into account a
large scope of uncertainties. To this end, nonparametric models such as Gaussian
processes and Gaussian Markov random ﬁelds (GMRFs), along with their predic-
tion and adaptive sampling algorithms, will be explored and tailored to our needs.
The importance of selecting a Gaussian process prior via hyperparameters for given
experimental observations is illustrated (Chap. 3). Adaptive sampling to improve
the quality of hyperparameters is proposed (Chap. 3). Memory efﬁcient prediction
based on truncated observations in space and time as well as the collective mobility
based on distributed navigation are discussed (Chap. 4). While the book starts with
vii

a rather simple empirical Bayes approach (Chap. 3), as we move through further
chapters, we discuss recent efforts with a fully Bayesian perspective to maximize
the ﬂexibility of the models under various uncertainties while minimizing the
computational complexity (Chaps. 5 and 7). A fully Bayesian framework is adopted
here as it offers several advantages when inferring parameters and processes from
highly complex models (Chaps. 5 and 7). The Bayesian approach requires prior
distributions to be elicited for model parameters that are of interest. Once the priors
are elicited, the Bayesian framework is ﬂexible and effective in incorporating all
uncertainties as well as information (limited or otherwise from data) into a single
entity, namely, the posterior. The fully Bayesian approach thus allows additional
sources and extent of uncertainties to be integrated into the inferential framework,
with the posterior distribution effectively capturing all aspects of uncertainties
involved. Subsequently, the practitioner needs only to focus on different compo-
nents of the posterior to obtain inference separately for the parameters of interest,
nuisance parameters, and hyperparameters. The fully Bayesian approach also
allows data to select the most appropriate values for nuisance parameters and
hyperparameters automatically and achieve optimal inference and prediction for the
scalar ﬁeld. In this book, a fully Bayesian approach for spatio-temporal Gaussian
process regression will be formulated for resource-constrained robotic sensors to
fuse multifactorial effects of observations, measurement noise, and prior distribu-
tions for obtaining the predictive distribution of a scalar environmental ﬁeld of
interest. Traditional Markov Chain Monte Carlo (MCMC) methods cannot be
implemented on resource-constrained mobile sensor networks due to high com-
putational complexity. To deal with complexity, the Bayesian spatio-temporal
models will be carefully tailored (Chap. 5). For example, we will approximate a
Gaussian process with a GMRF for computational efﬁciency (Chaps. 6 and 7).
A new spatial model is proposed via a GMRF (Chap. 6). In addition, ways to
improve computational efﬁciency will be proposed in form of empirical Bayes and
approximate Bayes instead of MCMC-based computation. For some special cases,
the developed centralized algorithms will be further reﬁned in a distributed manner
such that mobile robots can implement distributed algorithms only using local
information available from neighboring robots over a proximity communication
graph (Chaps. 4–6).
We note that although regression problems for sensor networks under location
uncertainty have practical importance, they are not considered in this book. The
interested reader is referred to [6, 7] (centralized scheme) and [8] (distributed
scheme) for further information on this topic.
Organization
This book is organized as follows: Chapter 1 gives some background information
and a summary for each chapter. In Chap. 2, we introduce the basic mathematical
notation that will be used throughout the book. We then describe the general
viii
Preface

Gaussian process and its usage in nonparametric regression problems. The notations
for mobile sensor networks are also introduced in Chap. 2. In Chap. 3, we deal with
the case where hyperparameters in the covariance function is deterministic but
unknown. We design an optimal sampling strategy to improve the maximum
likelihood estimation of these hyperparameters. In Chap. 4, we assume the
hyperparameters in the covariance function are given; they can be obtained using
the approach proposed in Chap. 3. We then analyze the error bounds of prediction
error using Gaussian process regression with truncated observations. Inspired by the
error analysis, we propose both centralized and distributed navigation strategies for
mobile sensor networks to move in order to reduce prediction error variances at
points of interest. In Chap. 5, we consider a fully Bayesian approach for Gaussian
process regression in which the hyperparameters are treated as random variables.
Using discrete prior probabilities and compactly supported kernels, we provide a
way to design sequential Bayesian prediction algorithms that can be computed in
constant time as the number of observations increases. To cope with the compu-
tational complexity brought by using standard Gaussian processes with covariance
functions, in Chap. 6, we exploit the sparsity of the precision matrix by using
Gaussian Markov random ﬁelds (GMRFs). We ﬁrst introduce a new class of
Gaussian processes with built-in GMRF and show its capability of representing a
wide range of nonstationary physical processes. We then derive the formulas for
Chapter 2: Preliminaries: Gaussian process (GP)
and Gaussian Markov random ﬁeld (GMRF)
Chapter 1: Background: Mobile sen-
sor network (MSN) and robotic sensors
Chapter 3: GP, prediction, adaptive
sampling, & empirical Bayes appr.
Chapter 5: GP, prediction, adaptive sam-
pling, MCMC appr., & fully Bayesian appr.
Chapter 6: new spatial model, GMRF, predic-
tion, distributed strategy, & empirical Bayes appr.
Chapter 7: approximated GP, GMRF, predic-
tion, adaptive sampling, & fully Bayesian appr.
Chapter 4: GP, prediction, & distributed strategy
Fig. 1 Organization of chapters along with keywords
Preface
ix

predictive statistics and design sequential prediction algorithms with ﬁxed com-
plexity. In Chap. 7, we consider a discretized spatial ﬁeld that is modeled by a
GMRF with unknown hyperparameters. From a Bayesian perspective, we design a
sequential prediction algorithm to exactly compute the predictive inference of the
random ﬁeld. An adaptive sampling strategy is also designed for mobile sensing
agents to ﬁnd the most informative locations in taking future measurements in order
to minimize the prediction error and the uncertainty in the estimated hyperpara-
meters simultaneously.
Keywords for chapters are summarized in Fig. 1. While each chapter is
self-contained and so can be read independently, arrows in Fig. 1 recommend
possible reading sequences for readers.
Acknowledgments
We would like to thank Songhwai Oh at Seoul National University for his
suggestions and contribution to Chap. 4. We also thank the National Science
Foundation RET teacher, Alexander Robinson, undergraduate student David York,
and Ph.D. student Huan N. Do at Michigan State University for collecting the
experimental data using a robotic boat in Chap. 3. We thank Jeffrey W. Laut,
Maurizio Porﬁri (NYU Polytechnic School of Engineering), Xiaobo Tan (Michigan
State University), and Derek A. Paley (University of Maryland) for providing
pictures of their robots used in the introduction of Chap. 1.
The authors Yunfei Xu and Jongeun Choi have been supported in part by the
National Science Foundation through CAREER Award CMMI-0846547. This
support is gratefully acknowledged. Any opinions, ﬁndings, and conclusions, or
recommendations expressed in this book are those of the authors and do not
necessarily reﬂect the views of the National Science Foundation.
Santa Clara, California
Yunfei Xu
East Lansing, Michigan
Jongeun Choi
Seri Iskandar, Malaysia
Sarat Dass
East Lansing, Michigan
Tapabrata Maiti
May 2015
x
Preface

Contents
1
Introduction. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1
1.1
Background. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1
1.2
Contents in Chapters . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
8
2
Preliminaries . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
11
2.1
Mathematical Notation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
11
2.2
Physical Process Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
12
2.2.1
Gaussian Process . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
12
2.2.2
Spatiotemporal Gaussian Process . . . . . . . . . . . . . . . . . .
13
2.2.3
Gaussian Markov Random Field . . . . . . . . . . . . . . . . . .
14
2.3
Mobile Sensor Network . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
16
2.4
Gaussian Processes for Regression . . . . . . . . . . . . . . . . . . . . . .
17
3
Learning Covariance Functions . . . . . . . . . . . . . . . . . . . . . . . . . .
19
3.1
Selection of Gaussian Process Prior . . . . . . . . . . . . . . . . . . . . .
19
3.2
Learning the Hyperparameters . . . . . . . . . . . . . . . . . . . . . . . . .
21
3.3
Optimal Sampling Strategy . . . . . . . . . . . . . . . . . . . . . . . . . . .
23
3.4
Simulation. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
25
4
Memory Efficient Prediction With Truncated Observations . . . . . .
27
4.1
GPR with Truncated Observations . . . . . . . . . . . . . . . . . . . . . .
28
4.1.1
Error Bounds Using Truncated Observations . . . . . . . . . .
28
4.1.2
Selecting Temporal Truncation Size . . . . . . . . . . . . . . . .
34
4.2
Optimal Sampling Strategies . . . . . . . . . . . . . . . . . . . . . . . . . .
37
4.2.1
Centralized Navigation Strategy. . . . . . . . . . . . . . . . . . .
37
4.2.2
Distributed Navigation Strategy . . . . . . . . . . . . . . . . . . .
39
4.3
Simulation. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
45
4.3.1
Centralized Sampling Scheme . . . . . . . . . . . . . . . . . . . .
46
4.3.2
Distributed Sampling Scheme . . . . . . . . . . . . . . . . . . . .
48
xi

5
Fully Bayesian Approach . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
53
5.1
Fully Bayesian Prediction Approach . . . . . . . . . . . . . . . . . . . . .
54
5.1.1
Prior Selection. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
56
5.1.2
MCMC-Based Approach. . . . . . . . . . . . . . . . . . . . . . . .
56
5.1.3
Importance Sampling Approach . . . . . . . . . . . . . . . . . . .
61
5.1.4
Discrete Prior Distribution. . . . . . . . . . . . . . . . . . . . . . .
64
5.2
Sequential Bayesian Prediction . . . . . . . . . . . . . . . . . . . . . . . .
64
5.2.1
Scalable Bayesian Prediction Algorithm . . . . . . . . . . . . .
65
5.2.2
Distributed Implementation for a Special Case. . . . . . . . .
66
5.2.3
Adaptive Sampling. . . . . . . . . . . . . . . . . . . . . . . . . . . .
69
5.3
Simulation. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
70
5.3.1
MCMC-Based Approach on a 1-D Scenario . . . . . . . . . .
70
5.3.2
Centralized Scheme on 1-D Scenario . . . . . . . . . . . . . . .
71
5.3.3
Distributed Scheme on 2-D Scenario . . . . . . . . . . . . . . .
74
6
New Efficient Spatial Model with Built-In Gaussian Markov
Random Fields. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
77
6.1
Spatial Prediction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
78
6.1.1
Spatial Model Based on GMRF. . . . . . . . . . . . . . . . . . .
78
6.1.2
Gaussian Process Regression . . . . . . . . . . . . . . . . . . . . .
79
6.1.3
Sequential Prediction Algorithm. . . . . . . . . . . . . . . . . . .
82
6.2
Distributed Spatial Prediction. . . . . . . . . . . . . . . . . . . . . . . . . .
83
6.2.1
Distributed Computation . . . . . . . . . . . . . . . . . . . . . . . .
84
6.2.2
Distributed Prediction Algorithm . . . . . . . . . . . . . . . . . .
84
6.3
Simulation and Experiment . . . . . . . . . . . . . . . . . . . . . . . . . . .
87
6.3.1
Simulation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
87
6.3.2
Centralized Scheme . . . . . . . . . . . . . . . . . . . . . . . . . . .
87
6.3.3
Distributed Scheme . . . . . . . . . . . . . . . . . . . . . . . . . . .
88
6.3.4
Experiment . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
89
7
Fully Bayesian Spatial Prediction Using Gaussian Markov
Random Fields. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
91
7.1
Spatial Field Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
92
7.2
Bayesian Predictive Inference . . . . . . . . . . . . . . . . . . . . . . . . .
94
7.3
Sequential Bayesian Inference . . . . . . . . . . . . . . . . . . . . . . . . .
96
7.3.1
Update Full Conditional Distribution . . . . . . . . . . . . . . .
97
7.3.2
Update Likelihood . . . . . . . . . . . . . . . . . . . . . . . . . . . .
98
7.3.3
Update Predictive Distribution . . . . . . . . . . . . . . . . . . . .
99
7.4
Adaptive Sampling. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
101
7.5
Simulation. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
102
Appendix A: Mathematical Background. . . . . . . . . . . . . . . . . . . . . . .
107
References. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
111
xii
Contents

Chapter 1
Introduction
1.1 Background
Sensor networks are ubiquitous due to the recent technological breakthroughs in
micro-electro-mechanical systems (MEMS), wireless communications, and embed-
ded systems [9, 10]. A sensor network consists of a collection of low-cost, low-power,
and multifunctional sensing devices that communicate over ﬁnite distances. A ﬂexi-
ble and application-speciﬁc operating system, TinyOS, was developed at UC Berke-
ley for sensor networks with severe memory and power constraints [11]. TinyOS
runs on small and cheap wireless sensor nodes (e.g., MICA2DOT from Crossbow
Technology, Inc., CA, USA) as shown in Fig.1.1a. Such sensor nodes have been
equipped with various environmental and ambient sensors such as temperature sen-
sors, lighting sensors, chemical sensors, accelerometers, and RFID readers along
with the communication capability with neighbors via low-power wireless commu-
nication to form a wireless ad hoc sensor network with up to 100,000 nodes [10].
Endowing the nodes in a sensor network with mobility signiﬁcantly increases the
sensor network’s sampling capabilities [12, 13]. The sensor networks which consist
of mobile sensing agents are more ﬂexible than the ones with only static nodes. A
conceptual picture of a distributed mobile sensor network with a (R-disk) proximity
communication graph model is shown in Fig.1.1b, which assumes that a robotic
sensor can communicate with its neighboring robots within distance R. Devised in
the Laboratory of Intelligent Systems at the Swiss Federal Institute of Technology,
the Swarming Micro Air Vehicle Network (SmavNet) depicted in Fig.1.1c allows
a single operator to control an entire swarm of cheap unmanned aerial vehicles
(UAVs) for search and rescue operation [14]. 3D Robotics, Inc., Berkeley, USA
produces “personal drones” such as DIY drone kits as well as ready-to-ﬂy quadrotors,
multirotors, and ﬁxed wing UAVs based on open source UAV autopilot platforms. A
quadrotor with a camera from 3D Robotics is shown in Fig.1.2.
Biologists and other scientists are interested in leveraging recent technological
advances [10, 15, 16] by deploying mobile sensor networks for environmental and
© The Author(s) 2016
Y. Xu et al., Bayesian Prediction and Adaptive Sampling Algorithms
for Mobile Sensor Networks, SpringerBriefs in Control,
Automation and Robotics, DOI 10.1007/978-3-319-21921-9_1
1

2
1
Introduction
(a)
(b)
(c)
Fig. 1.1 a Wireless microsensor mote (MICA2DOT) from Crossbow Technology, Inc., CA, USA,
(www.xbow.com). b Distributed mobile sensor network with a (R-disk) proximity communication
graph for environmental monitoring (credit: Justin Mrkva). c Swarming Micro Air Vehicle Network
(SmavNet) developed in the Laboratory of Intelligent Systems at the Swiss Federal Institute of
Technology for search and rescue operation (Photo courtesy of Laboratory of Intelligent Systems
at EPFL, http://lis.epﬂ.ch)
wildlife monitoring. For example, one of the pressing societal concerns about water
quality is the proliferation of harmful algal blooms in ponds, lakes, rivers, and coastal
ocean worldwide. A satellite image of a 2011 signiﬁcant harmful algal bloom in
western Lake Erie is shown in Fig.1.3. The excessive growth of cyanobacteria leads
to a decaying biomass and oxygen depletion, which are detrimental to ﬁsh and other
aquatic life as well as to land animals and humans consequently (due to the produced

1.1 Background
3
Fig. 1.2 Personal drone (IRIS+) manufactured by 3D Robotics Inc., Berkeley, USA (credit: 3D
Robotics, http://3drobotics.com)
Fig. 1.3 Satellite image of 2011 signiﬁcant harmful algal bloom in western Lake Erie in
Michigan, which impacted over half of the lake shore (credit: MERIS/ESA, processed by
NOAA/NOS/NCCOS, http://www.noaanews.noaa.gov)
toxins that deteriorate water quality) [17–19]. Deploying mobile sensor networks
can be a viable way to reconstruct and monitor such harmful algal blooms [20, 21].
Indeed, we have seen the increasing exploration of robotic technologies in aquatic
sensing [20, 22–25]. A robotic boat was used in concert with stationary buoys to form
an aquatic microbial system [20]; spatiotemporal aquatic ﬁeld reconstruction was
implemented using inexpensive, low-power, robotic ﬁsh in [21] (see also Fig.1.5a
for gliding robotic ﬁsh [26]); and low-cost, self-sustained mobile surface vehicles
have been designed for environmental monitoring as part of the citizen science project
Brooklyn Atlantis [23] (see Fig.1.4). A robotic boat equipped with a depth sensor, as

4
1
Introduction
(a)
(b)
Fig. 1.4 Robots developed by NYU Polytechnic School of Engineering for image and water quality
data collection as part of the citizen science project Brooklyn Atlantis (http://www.brooklynatlantis.
poly.edu) [23] (credit: Jeffrey W Laut)
shown in Fig.1.5b, can sample the depth of a lake for its estimation [27]. Autonomous
underwater vehicles (AUVs) are being developed as an important tool in oceanog-
raphy, marine biology, and other maritime applications [28–30]. Autonomous sea
gliders are another noteworthy example. These battery-powered, buoyancy-driven
vehicles can travel thousands of miles horizontally, for many months, without chang-
ing or recharging batteries [31–34]. With the networks of gliders as shown in Fig.1.6,
adaptive sampling has been demonstrated in Monterey Bay, California [35–37].

1.1 Background
5
(a)
(b)
Fig. 1.5 a Gliding robotic ﬁsh “Grace” sampling harmful algae in the Wintergreen Lake, Michigan
[26] (credit: Xiaobo Tan). b Robotic boat sampling depth near Hawk Island, Lansing, Michigan
(credit: Jongeun Choi)
The robotic sensor technologies have then brought an increasing exploitation of
navigation of mobile sensor networks and robotic sensors interacting with uncertain
environments [2, 35–42]. A necessity in such scenarios is to design algorithms to
process collected observations from environments (e.g., distributed estimators) for
robots such that either the local information about the environment can be used for
local control actions or the global information can be estimated asymptotically.
The approach of designing such algorithms takes two different paths depend-
ing on whether it uses an environmental model in space and time or not. Without

6
1
Introduction
Fig. 1.6 Gliders used for adaptive sampling [35–37] (credit: Derek A. Paley)
environmentalmodels,extremumseekingcontrolhasbeenproventobeveryeffective
for ﬁnding a source of a signal (chemical, electromagnetic, etc.) [38, 39]. Distributed
algorithms for stochastic source seeking with mobile robot networks have been devel-
oped for both cases with and without the mutual information model between their
expected measurements and the expected source location [43]. A unifying frame-
work of distributed stochastic gradient algorithms that can deal with coverage control,
spatial partitioning, and dynamic vehicle routing problems in the absence of a priori
knowledge of the event location distribution has been presented in [40].
A drawback of the spatial model free approach is that it limits its task to ﬁnding
the maximum (or minimum) point of the environmental ﬁeld. To tackle a variety
of useful tasks such as the exploration, estimation, prediction, and maximum seek-
ing of a scalar ﬁeld, it is essential for robots to have a spatial (and temporal) ﬁeld
model [2–4, 36, 41, 42, 44–50]. Although control algorithms for mobile robots have
been developed based on computationally demanding, physics-based ﬁeld models
[51], for resource-constrained mobile robots, recently, phenomenological and statis-
tical modeling techniques such as kriging, Gaussian process regression, and kernel
regression have gained much attention. Among phenomenological spatial models,
adaptive control of multiple robotic sensors based on a parametric approach needs
a persistent excitation (PE) condition for convergence of parameters [42, 50], while
control strategies based on Bayesian spatial models do not require such conditions
(e.g., by utilizing priori distributions as in Kalman ﬁltering [41] or Gaussian process
regression [2]). Hence, control engineers have become more aware of the useful-
ness of nonparametric Bayesian approaches such as Gaussian processes (deﬁned by

1.1 Background
7
mean and covariance functions) [52, 53] to statistically model physical phenomena
for the navigation of mobile sensor networks, e.g., [2–4, 36, 44–47]. Other more
data-driven approaches have also developed (without statistical structure used in
Gaussian processes) such as using kernel regression [48] and in reproducing kernel
Hilbert spaces [49]. However, without a statistical structure in a random ﬁeld, such
an approach (as in [48, 49]) usually requires a great number of observations than the
one with a statistical structure for a decent prediction quality.
In a mobile sensor network, the resource-limited sensing agents are required to
collaborate in order to achieve a speciﬁc objective. The cooperative control becomes
essential. The most popular applications are in networks of autonomous ground
vehicles [54, 55], underwater and surface vehicles [23, 36, 56–58], or aerial vehicles
[59–61]. Emerging technologies have been reported on the coordination of mobile
sensing agents [41, 62–70].
The mobility of mobile agents can be designed in order to perform the optimal
sampling of the ﬁeld of interest. Optimal sampling design is the process of choosing
where to take samples in order to maximize the information gained. Recently, in
[36], Leonard et al. developed mobile sensor networks that optimize ocean sampling
performance deﬁned in terms of uncertainty in a model estimate of a sampled ﬁeld.
A typical sensor placement technique [71] that puts sensors at the locations where
the entropy is high tends to place sensors along the borders of the area of interest
[44]. In [44], Krause et al. showed that seeking sensor placements that are most
informative about unsensed locations is NP-hard, and they presented a polynomial
time approximation algorithm by exploiting the submodularity of mutual information
[72]. In a similar approach, in [73], Singh et al. presented an efﬁcient planning of
informative paths for multiple robots that maximize the mutual information.
To ﬁnd these locations that predict the phenomenon best, one needs a model
of the spatiotemporal phenomenon. To this end, we use Gaussian processes (and
Gaussian random ﬁelds) to model ﬁelds undergoing transport phenomena. Nonpara-
metric Gaussian process regression (or Kriging in geostatistics) has been widely used
as a nonlinear regression technique to estimate and predict geostatistical data [52, 53,
74, 75]. A Gaussian process is a natural generalization of the Gaussian probability
distribution. It generalizes a Gaussian distribution with a ﬁnite number of random
variables to a Gaussian process with an inﬁnite number of random variables in the
surveillance region [53]. Gaussian process modeling enables us to efﬁciently pre-
dict physical values, such as temperature, salinity, pH, or biomass of harmful algal
blooms, at any point with a predicted uncertainty level. For instance, near-optimal
static sensor placements with a mutual information criterion in Gaussian processes
were proposed in [44, 76]. A distributed Kriged Kalman ﬁlter for spatial estimation
based on mobile sensor networks was developed in [45]. Multiagent systems that are
versatile for various tasks by exploiting predictive posterior statistics of Gaussian
processes were developed in [77, 78].
Gaussian process regression, based on the standard mean and covariance func-
tions, requires an inversion of a covariance matrix whose size grows as the number
of observations increases. The signiﬁcant computational complexity in Gaussian

8
1
Introduction
process regression due to the growing number of observations (and hence the size of
covariance matrix) has been tackled in different ways [2, 79–83].
Unknown hyperparameters in the covariance function can be estimated by a max-
imum likelihood (ML) estimator or a maximum a posteriori (MAP) estimator and
then be used in the prediction as the true hyperparameters [1]. However, the point
estimate (ML or MAP estimate) itself needs to be identiﬁed using a sufﬁcient amount
of measurements and it fails to incorporate the uncertainty in the estimated hyper-
parameters into the prediction in a Bayesian perspective. The advantage of a fully
Bayesian approach is that the uncertainty in the model parameters is incorporated in
the prediction [84]. In [85], Gaudard et al. presented a Bayesian method that uses
importance sampling for analyzing spatial data sampled from a Gaussian random
ﬁeld whose covariance function was unknown. However, the solution often requires
Markov Chain Monte Carlo (MCMC) methods, which greatly increases the com-
putational complexity. In [46], an iterative prediction algorithm without resorting
to MCMC methods has been developed based on analytical closed-form solutions
from results in [85], by assuming that the covariance function of the spatiotemporal
Gaussian random ﬁeld is known up to a constant.
There have been growing efforts to ﬁt a computationally efﬁcient Gaussian
Markov random ﬁeld (GMRF) on a discrete lattice to a Gaussian random ﬁeld on a
continuum space [4, 86–88]. It has been demonstrated that GMRFs with small neigh-
borhoods can approximate Gaussian ﬁelds surprisingly well [86]. This approximated
GMRF and its regression are very attractive for the resource-constrained mobile sen-
sor networks due to its computational efﬁciency and scalability [89] as compared to
the standard Gaussian process and its regression. Fast kriging of large datasets using
a GMRF as an approximation of a Gaussian ﬁeld has been proposed in [88].
1.2 Contents in Chapters
A brief summary for each subsequent chapter is as follows. Chapter2 gives an
introduction to Gaussian processes and Gaussian Markov random ﬁelds for general
domains as well as the space-time domain.
In Chap.3, we develop covariance function learning algorithms for the sensing
agents to perform nonparametric prediction based on a properly adapted Gaussian
process for a given spatiotemporal phenomenon. By introducing a generalized covari-
ance function, we expand the class of Gaussian processes to include the anisotropic
spatiotemporal phenomena. Maximum likelihood (ML) optimization is used to esti-
mate hyperparameters for the associated covariance function as an empirical Bayes
method.Theproposedoptimalnavigationstrategyforautonomousvehicleswillmax-
imize the Fisher information [90], improving the quality of the estimated covariance
function.
In Chap.4, we ﬁrst present a theoretical foundation of Gaussian process regres-
sion with truncated observations. In particular, we show that the quality of prediction
based on truncated observations does not deteriorate much as compared to that of

1.2 Contents in Chapters
9
prediction based on all cumulative data under certain conditions. The error bounds to
use truncated observations are analyzed for prediction at a single point of interest. A
way to select the temporal truncation size for spatiotemporal Gaussian processes is
also introduced. Inspired by the analysis, we then propose both centralized and dis-
tributed navigation strategies for mobile sensor networks to move in order to reduce
prediction error variances at points of interest. In particular, we demonstrate that
the distributed navigation strategy produces an emergent, swarming-like, collective
behavior to maintain communication connectivity among mobile sensing agents.
In Chap.5, we formulate a fully Bayesian approach for spatiotemporal Gaussian
process regression under practical conditions such as measurement noise and
unknown hyperparameters (particularly, the bandwidths). Thus, multifactorial effects
of observations, measurement noise, and prior distributions of hyperparameters are
all correctly incorporated in the computed posterior predictive distribution. Using
discrete prior probabilities and compactly supported kernels, we provide a way to
design sequential Bayesian prediction algorithms that can be computed (without
using the Gibbs sampler) in constant time (i.e., O(1)) as the number of observations
increases. An adaptive sampling strategy for mobile sensors, using the maximum
a posteriori (MAP) estimation, has been proposed to minimize the prediction error
variances.
In Chap.6, we propose a new class of Gaussian processes for resource-constrained
mobile sensor networks that build on a Gaussian Markov random ﬁeld (GMRF) with
respect to a proximity graph over the surveillance region. The main advantages of
using this class of Gaussian processes over standard Gaussian processes deﬁned by
mean and covariance functions are its numerical efﬁciency and scalability due to
its built-in GMRF and its capability of representing a wide range of nonstationary
physical processes. The formulas for predictive statistics are derived and a sequential
ﬁeld prediction algorithm is provided for sequentially sampled observations. For a
special case using compactly supported weighting functions, we propose a distributed
algorithm to implement ﬁeld prediction by correctly fusing all observations.
In Chap.7, we consider a discretized spatial ﬁeld that is modeled by a GMRF with
unknown hyperparameters. From a Bayesian perspective, we design a sequential pre-
diction algorithm to exactly compute the predictive inference of the random ﬁeld.
The main advantages of the proposed algorithm are (1) the computational efﬁciency
due to the sparse structure of the precision matrix, and (2) the scalability as the num-
ber of measurements increases. Thus, the prediction algorithm correctly takes into
account the uncertainty in hyperparameters in a Bayesian way and also is scalable to
be usable for the mobile sensor networks with limited resources. An adaptive sam-
pling strategy is also designed for mobile sensing agents to ﬁnd the most informative
locations in taking future measurements in order to minimize the prediction error
and the uncertainty in the estimated hyperparameters simultaneously.

Chapter 2
Preliminaries
2.1 Mathematical Notation
Standard notation is used throughout this book. Let R, R≥0, R>0, Z, Z≥0, Z>0 denote
the sets of real numbers, nonnegative real numbers, positive real numbers, integers,
nonnegative integers, and positive integers, respectively.
Let E, Var, Corr, Cov denote the expectation, variance, correlation, and the covari-
ance operators, respectively.
Let AT ∈RM×N be the transpose of a matrix A ∈RN×M. Let tr(A) and det(A)
denote the trace and the determinant of a matrix A ∈RN×N, respectively. Let
rowi(A) ∈RM and col j(A) ∈RN denote the ith row and the jth column of a matrix
A ∈RN×M, respectively.
The positive deﬁniteness and the positive semi-deﬁniteness of a square matrix A
are denoted by A ≻0 and A ⪰0, respectively.
Let |x| denote the absolute value of a scalar x. Let ∥x∥denote the standard
Euclidean norm (2-norm) of a vector x. The induced 2-norm of a matrix A is denoted
by ∥A∥. Let ∥x∥∞denote the inﬁnity norm of a vector x.
Let 1 denote the vector with all elements equal to one and I denote the identity
matrix with an appropriate size. Let ei be the standard basis vector of appropriate
size with 1 as its ith element and 0 on all other elements.
The symbol ⊗denotes the Kronecker product. The symbol ◦denotes the
Hadamard product (also known as the entry-wise product and the Schur product).
A random vector x, which is distributed by a normal distribution of mean μ and
covariance matrix C, is denoted by x ∼N(μ, C). The corresponding probability
density function is denoted by N(x; μ, C).
The relative complement of a set A in a set B is denoted by B \ A := B ∩Ac,
where Ac is the complement of A. For a set A ∈I, we deﬁne zA = {zi | i ∈A}.
Let −A denote the set I \ A.
© The Author(s) 2016
Y. Xu et al., Bayesian Prediction and Adaptive Sampling Algorithms
for Mobile Sensor Networks, SpringerBriefs in Control,
Automation and Robotics, DOI 10.1007/978-3-319-21921-9_2
11

12
2
Preliminaries
An undirected graph G = (V, E) is a tuple consisting of a set of vertices V :=
{1, · · · , n} and a set of edges E ⊂V × V. The neighbors of i ∈V in G are denoted
by Ni := { j ∈V | {i, j} ∈E}.
Other notations will be explained in due course.
2.2 Physical Process Model
In this section, we review important notions for the Gaussian process which will be
used to model the physical phenomenon. In particular, we introduce a class of spa-
tiotemporalGaussianprocessmodelwithanisotropiccovariancefunctions.Theprop-
erties of Gaussian Markov random ﬁelds (GMRF) are also brieﬂy reviewed.
2.2.1 Gaussian Process
A Gaussian process can be thought of a generalization of a Gaussian distribution over
a ﬁnite vector space to function space of inﬁnite dimension. It is formally deﬁned as
follows [53, 91]:
Deﬁnition 2.1 A Gaussian process (GP) is a collection of random variables, any
ﬁnite number of which have a consistent1 joint Gaussian distribution.
A Gaussian process, denoted by
z(x) ∼GP

μ(x), C(x, x′; θ)

(2.1)
is completelyspeciﬁedbyits meanfunction μ(x) andcovariancefunctionC(x, x′; θ)
which are deﬁned as
μ(x) = E [z(x)] ,
C(x, x′; θ) = E

(z(x) −μ(x)) (z(x′) −μ(x′))|θ

.
Although not needed to be done, we take the mean function to be zero for notational
simplicity,2 i.e., μ(x) = 0. If the covariance function C(x, x′; θ) is invariant with
respect to translations in the input space, i.e., C(x, x′; θ) = C(x −x′; θ), we call it
stationary. Furthermore, if the covariance function is a function of only the distance
between the inputs, i.e., C(x, x′; θ) = C(
x −x′ ; θ), then it is called isotropic.
1It is also known as the marginalization property. It means simply that the random variables obey
the usual rules of marginalization, etc.
2This is not a drastic limitation since the mean of the posterior process is not conﬁned to zero [53].

2.2 Physical Process Model
13
Fig. 2.1 Realization of a
two-dimensional (D = 2)
Gaussian process with
σ 2
f = 5, σ1 = 2.5, and
σ2 = 1.5.
Inpractice, aparametricfamilyof functions is usedinsteadof ﬁxingthecovariance
function [84]. One common choice of a stationary covariance function is
C(x, x′; θ) = σ 2
f exp

−
D

ℓ=1

xℓ−x′
ℓ
2
2σ 2
ℓ
	
,
(2.2)
where xℓis the ℓth element of x ∈RD. From (2.2), it can be easily seen that the
correlation between two inputs decreases as the distance between them increases.
This decreasing rate depends on the choice of the length scales {σℓ}. A very large
length scale means that the predictions would have little bearing on the correspond-
ing input which is then said to be insigniﬁcant. σ 2
f gives the overall vertical scale
relative to the mean of the Gaussian process in the output space. These parame-
ters play the role of hyperparameters since they correspond to the hyperparame-
ters in neural networks and in the standard parametric model. Therefore, we deﬁne
θ = (σ 2
f , σ1, · · · , σD)T ∈RD+1 as the hyperparameter vector. A realization of a
Gaussian process that is numerically generated is shown in Fig.2.1.
2.2.2 Spatiotemporal Gaussian Process
In this section, spatiotemporal Gaussian processes are of particular interest. Spa-
tiotemporal Gaussian processes are obtained as a special case of (2.1) by setting
x ⊂RD × R≥0, where RD is for spatial locations and R≥0 is the temporal domain.
A spatiotemporal Gaussian process can be written as
z(s, t) ∼GP(μ(s, t), C(s, t, s′, t′; θ)),

14
2
Preliminaries
(a)
(b)
(c)
Fig. 2.2 Realization of a spatiotemporal (D = 2) Gaussian process with σ 2
f = 5, σ1 = 2.5,
σ2 = 1.5, and σt = 8 at a t = 1, b t = 5, and c t = 10.
where x = (sT , t)T
∈RD × R≥0. We consider the following generalized
anisotropic covariance function C(x, x′; θ) with a hyperparameter vector θ :=
(σ 2
f , σ1, · · · , σD, σt)T ∈RD+2:
C(x, x′; θ) = σ 2
f exp

−
D

ℓ=1
(sℓ−s′
ℓ)2
2σ 2
ℓ

exp

−(t −t′)2
2σ 2t

,
(2.3)
where s, s′ ∈Q ⊂RD, t, t′ ∈R≥0. {σ1, · · · , σD} and σt are kernel bandwidths
for space and time, respectively. (2.3) shows that points close in the measurement
space and time indices are strongly correlated and produce similar values. In reality,
the larger temporal distance two measurements are taken with, the less correlated
they become, which strongly supports our generalized covariance function in (2.3).
This may also justify the truncation (or windowing) of the observed time series data
to limit the size of the covariance matrix for reducing the computational cost. A
spatially isotropic version of the covariance function in (2.3) has been used in [36].
A realization of a spatiotemporal Gaussian process that is numerically generated is
shown in Fig.2.2.
2.2.3 Gaussian Markov Random Field
The Gaussian Markov random ﬁeld is formally deﬁned as follows [92]:
Deﬁnition 2.2 (GMRF, [92, Deﬁnition 2.1]) A random vector z = (z1, · · · , zN)T ∈
RN is called a GMRF with respect to a graph G = (V, E) with mean μ and precision
matrix Q ≻0, if and only if its density has the form
π(z) =
|Q|1/2
(2π)N/2 exp

−1
2(z −μ)T Q(z −μ)

,

2.2 Physical Process Model
15
and(Q)i j ̸= 0 ⇔{i, j} ∈E foralli ̸= j,wheretheprecisionmatrix(orinformation
matrix) Q = C−1 is the inverse of the covariance matrix C, and |Q| denotes the
determinant of Q.
The Markov property of a GMRF can be shown by the following theorem.
Theorem 2.1 ([92, Theorem 2.4]) Let z be a GMRF with respect to G = (V, E).
Then the followings are equivalent.
1. The pairwise Markov property:
zi⊥z j | z−i j
if {i, j} /∈E and i ̸= j,
where ⊥denotes conditional independence and z−i j := z−{i, j} = zI\{i, j}. This
implies that zi and z j are conditionally independent given observations at all
other vertices except {i, j} if i and j are not neighbors.
2. The local Markov property:
zi⊥z−{i,Ni} | zNi
for every i ∈I.
3. The global Markov property:
zA⊥zB | zC
for disjoint sets A, B, and C where C separates A and B, and A and B are
nonempty.
If a graph G has small cardinalities of the neighbor sets, its precision matrix Q
becomes sparse with many zeros in its entries. This plays a key role in computation
efﬁciency of a GMRF which can be greatly exploited by the resource-constrained
mobile sensor network. For instance, some of the statistical inference can be obtained
directly from the precision matrix Q with conditional interpretations.
Theorem 2.2 ([92, Theorem 2.3]) Let z be a GMRF with respect to G = (V, E)
with mean μ and precision matrix Q ≻0, then we have
E(zi | z−i) = μi −
1
(Q)ii

j∈Ni
(Q)i j(z j −μ j),
Var(zi | z−i) =
1
(Q)ii
,
Corr(zi, z j | z−i j) = −
(Q)i j

(Q)ii(Q) j j
,
∀i ̸= j.

16
2
Preliminaries
2.3 Mobile Sensor Network
In this section, we explain the sensor network formed by multiple mobile sensing
agents and present the measurement model used throughout the thesis.
Let N be the number of sensing agents distributed over the surveillance region
Q ∈RD. The identity of each agent is indexed by I := {1, 2, · · · , N}. Assume that
all agents are equipped with identical sensors and take noisy observations at time
t ∈Z>0. At time t, the sensing agent i takes a noise-corrupted measurement yi(t)
at its current location qi(t) ∈Q, i.e.,
yi(t) = z(qi(t), t) + ϵi,
ϵi
i.i.d.
∼N(0, σ 2
w),
where the sensor noise ϵi is considered to be an independent and identically dis-
tributed Gaussian random variable. σ 2
w > 0 is the noise level and we deﬁne the
signal-to-noise ratio as
γ =
σ 2
f
σ 2w
.
Notice that when a static ﬁeld is considered, we have z(s, t) = z(s).
For notational simplicity, we denote the collection of positions of all N agents at
time t as q(t), i.e.,
q(t) :=

q1(t)T , · · · , qN(t)T T
∈QN.
The collective measurements from all N mobile sensors at time t are denoted by
yt := (y1(t), · · · , yN(t))T ∈RN.
The cumulative measurements from time t ∈Z>0 to time t′ ∈Z>0 are denoted by
yt:t′ :=

yT
t , · · · , yT
t′
T
∈RN(t′−t+1).
The communication network of mobile agents can be represented by an undirected
graph. Let G(t) := (I, E(t)) be an undirected communication graph such that an edge
(i, j) ∈E(t) if and only if agent i can communicate with agent j ̸= i at time t. We
deﬁne the neighborhood of agent i at time t by Ni(t) := { j ∈I | (i, j) ∈E(t)}.
Similarly, let q[i](t) denote the vector form of the collection of positions in

q j(t) | j ∈{i} ∪Ni(t)

. Let y[i]
t
denote vector form of the collection of obser-
vations in

y(q j(t), t) | j ∈{i} ∪Ni(t)

. The cumulative measurements of agent i
from time t to time t′ are denoted as y[i]
t:t′.

2.4 Gaussian Processes for Regression
17
2.4 Gaussian Processes for Regression
Suppose we have a dataset D =

(x(i), y(i)) | i = 1, · · · , n

collected by mobile
sensing agents where x(i) denotes an input vector of dimension D and y(i) denotes a
scalar value of the noise-corrupted output. The objective of probabilistic regression
is to compute the predictive distribution of the function values z∗:= z(x∗) at some
test input x∗.
For notational simplicity, we deﬁne the design matrix X of dimension n × D as
the aggregation of n input vectors (i.e., rowi(X) := (x(i))T ), and the outputs are
collected in a vector y := (y(1), · · · , y(n))T . The corresponding vector of noise-free
outputs is deﬁned as z := (z(x(1)), · · · , z(x(n)))T .
The advantage of the Gaussian process formulation is that the combination of the
prior and noise models can be carried out exactly via matrix operations [93]. The
idea of Gaussian process regression is to place a GP prior directly on the space of
functions without parameterizing the function z(·), i.e.,
π(z|θ) = N(z; μ, K),
where μ ∈Rn is the mean vector obtained by (μ)i
= μ(x(i)), and K :=
Cov(z, z|θ) ∈Rn×n is the covariance matrix obtained by (K)i j = C(x(i), x( j); θ).
Notice that the GP model and all expressions are always conditional on the corre-
sponding inputs. In the following, we will always neglect the explicit conditioning
on the input matrix X.
The inference in the Gaussian process model is as follows. First, we assume a
joint GP prior π(z, z∗|θ) over functions, i.e.,
π(z, z∗|θ) = N

μ
μ(x∗)

,
 K
k
kT C(x∗, x∗; θ)

,
(2.4)
where k := Cov(z, z∗|θ) ∈Rn is the covariance between z and z∗obtained by
(k)i = C(x(i), x∗; θ). Then, the joint posterior is obtained using Bayes rule, i.e.,
π(z, z∗|θ, y) = π(y|z)π(z, z∗|θ)
π(y|θ)
,
where we have used π(y|z, z∗) = π(y|z). Finally, the desired predictive distribution
π(z∗|θ, y) is obtained by marginalizing out the latent variables in z, i.e.,
π(z∗|θ, y) =

π(z, z∗|θ, y)dz
=
1
π(y|θ)

π(y|z)π(z, z∗|θ, y)dz.
(2.5)

18
2
Preliminaries
Since we have the joint Gaussian prior given in (2.4) and
y|z ∼N

z, σ 2
wI

,
the integral in (2.5) can be evaluated in closed-form and the predictive distribution
turns out to be Gaussian, i.e.,
z∗|θ, y ∼N

μz∗|θ,y, σ 2
z∗|θ,y

,
(2.6)
where
μz∗|θ,y = μ(x∗) + kT (K + σ 2
wI)−1(y −μ),
(2.7)
and
σ 2
z∗|θ,y = C(x∗, x∗; θ) −kT (K + σ 2
wI)−1k.
(2.8)
For notational simplicity, we deﬁne the covariance matrix of the noisy observations
as C := Cov(y, y|θ) = K + σ 2
wI.

Chapter 3
Learning Covariance Functions
We often assume that Gaussian processes are isotropic implying that the covariance
function only depends on the distance between locations. Many studies also assume
that the corresponding covariance functions are known a priori for simplicity. How-
ever, this is not the case in general as pointed out in the literature [44, 76, 94], in
which they treat the nonstationary process by fusing a collection of isotropic spatial
Gaussian processes associated with a set of local regions. Our objective in this chapter
is to develop theoretically sound algorithms for mobile sensor networks to learn the
anisotropic covariance function of a spatiotemporal Gaussian process. Mobile sens-
ing agents can then predict the Gaussian process based on the estimated covariance
function in a nonparametric manner.
First, in Sect.3.1, we illustrate the importance of the choice of the covariance
function. In Sect.3.2, we introduce a covariance function learning algorithm for an
anisotropic, spatiotemporal Gaussian process. The covariance function is assumed to
be deterministic but unknown a priori and it is estimated by the maximum likelihood
(ML) estimator. In Sect.3.3, an optimal sampling strategy is proposed to minimize
the Cramér–Rao lower bound (CRLB) of the estimation error covariance matrix. In
Sect.3.4, simulation results illustrate the usefulness of our proposed approach.
3.1 Selection of Gaussian Process Prior
In this subsection, we illustrate the importance of selecting a Gaussian process prior
via hyperparameters when we make inferences from the experimental data. To have
illustrative cases, we consider the experimental data collected by the robotic boat
(see Fig.3.1a) that was deployed in a pond in Central Park, Okemos, Michigan. A set
of water depth values and sampling locations was collected from onboard sensors in
the robotic boat. Figure3.1b shows the location site with boat trajectories in red lines.
Without loss of generality, the GPS data, in particular the longitude and latitude, are
normalized to [0, 1]. Let us assume that the process has a known constant mean so
© The Author(s) 2016
Y. Xu et al., Bayesian Prediction and Adaptive Sampling Algorithms
for Mobile Sensor Networks, SpringerBriefs in Control,
Automation and Robotics, DOI 10.1007/978-3-319-21921-9_3
19

20
3
Learning Covariance Functions
(a)
(b)
Fig. 3.1 a Remotely controlled boat equipped with depth sensor and GPS (credit: Jongeun Choi),
b experiment site with robotic boat’s trajectories (shown as red lines)
that we only care to select the covariance function. With the squared exponential
covariance function in (2.2), i.e.,
C(x, x′; θ) = σ2
f exp

−
2

ℓ=1
(xℓ−x′
ℓ)2
2σ2
ℓ

,
the estimated depth ﬁeld and the prediction error variance using the estimated hyper-
parameters by maximizing the likelihood function are shown in Fig.3.2. Another set
of corresponding ﬁgures are provided with the scaled σ1 and σ2 values by 0.2 from
the estimates as shown in Fig.3.3. With different bandwidths (or length scales) σ1
and σ2 while keeping other parameters ﬁxed on the same values, the prediction and
its prediction error variance on the same experimental data are signiﬁcantly different.
(a)
(b)
Fig. 3.2 Prediction with estimated hyperparameters σ f = 2.19, σ1 = 0.40, σ2 = 0.29, σw = 0.24.
a Estimated depth, and b prediction error variance, with sampling positions shown as white crosses

3.1 Selection of Gaussian Process Prior
21
(a)
(b)
Fig. 3.3 Prediction with scaled σ1 and σ2 by 0.2, i.e., σ f = 2.19, σ1 = 0.08, σ2 = 0.058,
σw = 0.24. a Estimated depth, and b prediction error variance, with sampling positions shown as
white crosses
With smaller bandwidths, the predicted depth ﬁeld is much more wiggly and wavy
than its counterpart (Figs.3.2a and 3.3a), which is an artifact due to the wrong choice
of bandwidths in this case.
For the sake of illustration, let us assume that hyperparmeters are known to be
different as reported in Figs.3.2 and 3.3. As shown in Figs.3.2 and 3.3, in general,
the Gaussian process with larger bandwidths (and stronger spatial correlations) tends
to be smooth and does not need dense sampling for a decent level of prediction error
variance quality (Fig.3.2b). On the other hand, the Gaussian process with smaller
bandwidths (and weaker spatial correlations) allows much more complicated spatial
details and needs to be densely sampled. From these ﬁndings, we recognize the
importance of the choice of the covariance function to make precise prediction as
well as schedule the sampling in an optimal way. More discussions on the selection
of covariance functions from a Bayesian perspective can be found in [95].
3.2 Learning the Hyperparameters
Without loss of generality, we consider a zero-mean spatiotemporal Gaussian process
z(s, t) ∼GP

0, C(s, t, s′, t′; θ)

,
with the covariance function
C(s, t, s′, t′; θ) = σ2
f exp
⎛
⎝−

ℓ=1,2
(sℓ−s′
ℓ)2
2σ2
ℓ
⎞
⎠exp

−(t −t′)2
2σ2t

,

22
3
Learning Covariance Functions
where s, s′ ∈Q ⊂R2, t, t′ ∈R≥0, for modeling the ﬁeld undergoing a physical
transport phenomenon. θ = (σ2
f , σ1, σ2, σt)T ∈RM is the hyperparameter vector,
where M = 4. The assumption of zero-mean is not a strong limitation since the mean
of the posterior process is not conﬁned to zero [53].
If the covariance function C(s, t, s′, t′; θ) of a Gaussian process is not known a
priori, mobile agents need to estimate parameters of the covariance function (i.e.,
the hyperparameter vector θ ∈RM) based on the observed samples. In the case
where measurement noise level σw is also unknown, it can be incorporated in the
hyperparameter vector and be estimated. Thus, we have θ = (σ2
f , σ1, σ2, σt, σw)T ∈
RM where M = 5.
Existing techniques for learning the hyperparameters are based on the likelihood
function. Given the observations y = (y(1), . . . , y(n))T ∈Rn collected by mobile
sensing agents over time, the likelihood function is deﬁned as
L(θ|y) = π(y|θ).
(3.1)
Notice that in this chapter, the hyperparameter vector θ is considered to be deter-
ministic, and hence π(y|θ) should not be considered as conditional distribution.
A point estimate of the hyperparameter vector θ can be made by maximizing the
log likelihood function. The maximum likelihood (ML) estimate ˆθ ∈RM of the
hyperparameter vector is obtained by
ˆθ = arg max
θ∈ log L(θ|y),
(3.2)
where  is the set of all possible choices of θ. The log likelihood function is given
by
log L(θ|y) = −1
2yT C−1y −1
2 log det(C) −n
2 log 2π,
where C := Cov(y, y|θ) ∈Rn×n is the covariance matrix, and n is the total number
of observations. Maximization of the log likelihood function can be done efﬁciently
using gradient-based optimization techniques such as the conjugate gradient method
[96, 97]. The partial derivative of the log likelihood function with respect to a hyper-
parameter θi ∈R, i.e., the ith entry of the hyperparameter vector θ, is given by
∂log L(θ|y)
∂θi
= 1
2yT C−1 ∂C
∂θi
C−1y −1
2 tr

C−1 ∂C
∂θi

= 1
2 tr

(ααT −C−1) ∂C
∂θi

,
where α = C−1y ∈Rn. In general, the log likelihood function is a nonconvex
function and hence it can have multiple maxima.
As an alternative, when certain prior knowledge is available on the hyperparame-
ters, a prior distribution π(θ) can be imposed on the hyperparameter vector. Using

3.2 Learning the Hyperparameters
23
Bayes’ rule, the posterior distribution π(θ|y) is proportional to the likelihood L(θ|y)
times the prior distribution π(θ), i.e.,
π(θ|y) ∝L(θ|y)π(θ)
= π(y|θ)π(θ),
in light of (3.1) deﬁned earlier. Then the maximum a posteriori (MAP) estimate
ˆθ ∈RM of the hyperparameter vector can be obtained similarly by
ˆθ = arg max
θ∈ (log L(θ|y) + log π(θ)) .
(3.3)
Notice that when no prior information is available, the MAP estimate is equivalent
to the ML estimate.
Once the estimate of the hyperparameter vector θ is obtained with conﬁdence, it
can be used as the true value for the mobile sensor network to predict the ﬁeld of
interest using Gaussian process regression in (2.6).
3.3 Optimal Sampling Strategy
We assume now that the estimate of hyperparameters has been obtained using the
procedure outlined in Sect.3.2 based on all observations collected up to and including
time t. At time t + 1, agents should ﬁnd new sampling positions to improve the
quality of the estimated covariance function. For instance, to precisely estimate the
anisotropic phenomenon, i.e., processes with different covariances along x and y
directions, sensing agents need to explore and sample measurements along different
directions.
To this end, we consider a centralized scheme. Suppose that a central station (or a
leader agent) has access to all measurements collected by agents. Assume that at time
t + 1, agent i moves to a new sampling position ˜qi ∈Q and makes an observation
yi(t + 1) ∈R. The collection of the new sampling positions and new observations
from all agents are denoted by ˜q ∈QN and ˜y ∈RN, respectively. The objective of
the optimal sampling strategy is to ﬁnd the best sampling positions ˜q such that the
maximum likelihood (ML) estimate ˆθt+1 ∈RM at time t + 1 is as close to the true
hyperparameter vector θ∗∈RM as possible. Notice that θ∗is unknown in practice,
but this issue will be addressed slightly later.
Consider the Fisher information matrix (FIM) that measures the information pro-
duced by y1:t ∈RNt and ˜y ∈RN for estimating the true hyperparameter vector
θ∗∈RM at time t + 1. The Cramér–Rao lower bound (CRLB) theorem states that
the inverse of the FIM (denoted by M ∈RM×M) is a lower bound of the estimation
error covariance matrix [90, 98]:
E

(ˆθt+1 −θ∗)(ˆθt+1 −θ∗)T 
⪰M−1,

24
3
Learning Covariance Functions
where ˆθt+1 ∈Rm represents the ML estimate of θ∗at time t + 1. The FIM [90] is
given by
(M)i j = −E
∂2 ln L(θ|˜y, y1:t)
∂θi∂θ j

,
where L(θ|˜y, y1:t) is the likelihood function at time t + 1, and the expectation is
taken with respect to π(y1:t, ˜y|θ). Notice that the likelihood is now a function of θ
and ˜y. The analytical form of the FIM is given by
(M)i j = 1
2 tr

˜C
−1 ∂˜C
∂θi
˜C
−1 ∂˜C
∂θ j

,
where ˜C ∈RN(t+1)×N(t+1) is deﬁned as
˜C := Cov
y1:t
˜y

,
y1:t
˜y
 θ∗

.
Since the true value θ∗is not available, we will evaluate the FIM at the currently
best estimate ˆθt.
We can expect that minimizing the Cramér–Rao lower bound results in a decrease
of uncertainty in estimating θ [99]. The most common optimality criterion is
D-optimality [100, 101]. It corresponds to minimizing the volume of the ellipsoid
which represents the maximum conﬁdence region for the maximum likelihood esti-
mate of the unknown hyperparameters [101]. Using the D-optimality criterion [100,
101], the objective function J(·) is given by
J(˜q) := det(M−1).
However, if one hyperparameter has a very large variance compared to the others, the
ellipsoid will be skinny and thus minimizing the volume may be misleading [101].
As an alternative, A-optimality which minimizes the sum of the variances is often
used. The objective function J(·) based on A-optimality criterion is
J(˜q) := tr(M−1).
Hence, a control law for the mobile sensor network can be formulated as follows:
q(t + 1) = arg min
˜q∈QN J(˜q).
(3.4)
In (3.4), we only consider the constraint that robots should move within the region
Q. However, the mobility constraints, such as the maximum distance that a robot

3.3 Optimal Sampling Strategy
25
Table 3.1 Centralized optimal sampling strategy at time t
For i ∈I, agent i performs:
1: make an observation at current position qi(t), i.e., yi(t)
2: transmit the observation yi(t) to the central station
The central station performs:
1: collect the observations from all N agents, i.e., yt
2: obtain the cumulative measurements, i.e., y1:t
3: compute the maximum likelihood estimate ˆθt based on
ˆθt = arg maxθ∈Θ ln L(θ|y1:t),
starting with the initial point ˆθt−1
4: compute the control in order to minimize the cost function J(˜q)
via
q(t + 1) = arg min˜q∈QN J(˜q)
5: send the next sampling positions {qi(t + 1) | i ∈I} to all N
agents
For i ∈I, agent i performs:
1: receive the next sampling position qi(t + 1) from the central
station
2: move to qi(t + 1) before time t + 1
can move between two time indices, or the maximum speed with which a robot can
travel, can be incorporated as additional constraints in the optimization problem [45].
The overall protocol for the sensor network is summarized as in Table3.1.
3.4 Simulation
We apply our approach to a spatial Gaussian process. The Gaussian process was
numerically generated for the simulation [53]. The hyperparameters used in the sim-
ulation were chosen such that θ = (σ2
f , σ1, σ2, σw)T = (5, 4, 2, 0.5)T . In this case,
N = 9 mobile sensing agents were initialized at random positions in a surveillance
region Q = [0, 10] × [0, 10]. The initial values for the algorithm were given to be
θ0 = (1, 1, 1, 0.1)T . The gradient method was used to ﬁnd the MAP estimate of the
hyperparameter vector.
For simplicity, we assumed that the global basis is the same as the model basis. We
considered a situation where at each time, measurements of agents are transmitted
to a leader (or a central station) that uses our Gaussian learning algorithm and sends
optimal control back to individual agents for next iteration to improve the quality of
the estimated covariance function. The maximum distance for agents to move in one
time step was chosen to be 1 for both x and y directions. The A-optimality criterion
was used for optimal sampling.

26
3
Learning Covariance Functions
0
2
4
6
8
10
0
2
4
6
8
σ
σ
σ
σ
σ
σ
σ
σ
f
0
2
4
6
8
10
0
5
10
1
0
2
4
6
8
10
0
2
4
6
2
0
2
4
6
8
10
−0.5
0
0.5
1
w
t
(a)
0
2
4
6
8
10
0
2
4
6
8
f
0
2
4
6
8
10
0
5
10
1
0
2
4
6
8
10
0
2
4
6
2
0
2
4
6
8
10
−0.5
0
0.5
1
w
t
(b)
Fig. 3.4 Monte Carlo simulation results (100 runs) for a spatiotemporal Gaussian process using a
the random sampling strategy, and b the adaptive sampling strategy. The estimated hyperparameters
are shown in blue circles with error bars. The true hyperparameters that used for generating the
process are shown in red dashed lines
For both proposed and random strategies, Monte Carlo simulations were run
for 100 times and the statistical results are shown in Fig.3.4. The estimates of the
hyperparameters (shown in circles and error bars) tend to converge to the true values
(shown in dotted lines) for both strategies. As can be seen, the proposed scheme
(Fig.3.4a) outperforms the random strategy (Fig.3.4b) in terms of the A-optimality
criterion.
After converging to a good estimate of θ, agents can switch to a decentralized
conﬁguration and collect samples for other goals such as peak tracking and prediction
of the process [42, 77, 78].

Chapter 4
Memory Efﬁcient Prediction
With Truncated Observations
The main reason why the nonparametric prediction using Gaussian processes has not
been popular for resource-constrained multi-agent systems is the fact that the optimal
prediction must use all cumulatively measured values in a non-trivial way [74, 75].
In this case, a robot needs to compute the inverse of the covariance matrix whose
size grows as it collects more measurements. With this operation, the robot will run
out of memory quickly. Therefore, it is necessary to develop a class of prediction
algorithms using spatio-temporal Gaussian processes under a ﬁxed memory size.
A simple way to cope with this dilemma is to design a robot so that it predicts a
spatio-temporal Gaussian process at the current (or future) time based on truncated
observations, e.g., the last m observations from a total of n of observations as shown
in Fig.4.1. This seems intuitive in the sense that the last m observations are more
correlated with the point of interest than the other r = n −m observations (Fig.4.1)
in order to predict values at current or future time. Therefore, it is very important
to analyze the performance degradation and trade-off effects of prediction based on
truncated observations compared to the one based on all cumulative observations.
The second motivation is to design and analyze distributed sampling strategies
for resource-constrained mobile sensor networks. Developing distributed estimation
and coordination algorithms for multi-agent systems using only local information
from local neighboring agents has been one of the most fundamental problems in
mobile sensor networks [42, 45, 62–66]. Emphasizing practicality and usefulness, it
is critical to synthesize and analyze distributed sampling strategies under practical
constraints such as measurement noise and a limited communication range.
In Sect.4.1, we propose to use only truncated observations to bound the computa-
tional complexity. The error bounds in using truncated observations are analyzed for
prediction at a single point in Sect.4.1.1. A way of selecting a temporal truncation
size is also discussed in Sect.4.1.2. To improve the prediction quality, centralized and
distributed navigation strategies for mobile sensor networks are proposed in Sect.4.2.
In Sect.4.3, simulation results illustrate the usefulness of our schemes under different
conditions and parameters.
© The Author(s) 2016
Y. Xu et al., Bayesian Prediction and Adaptive Sampling Algorithms
for Mobile Sensor Networks, SpringerBriefs in Control,
Automation and Robotics, DOI 10.1007/978-3-319-21921-9_4
27

28
4
Memory Efﬁcient Prediction With Truncated Observations
sy
sx
1
2
3
t
t −η
time
r = n −m observations
m observations
x∗
. . .
. . .
Fig. 4.1 Robot predicts a scalar value at x∗(denoted by a red star) based on cumulative n spatio-
temporal observations (denoted by blue crosses). Near-optimal prediction can be obtained using
truncated observations, e.g., the last m observations. In this case, x = (sx, sy, t)T
4.1 GPR with Truncated Observations
As mentioned in above, one drawback of Gaussian process regression is that its
computational complexity and memory space increase as more measurements are
collected, making the method prohibitive for robots with limited memory and com-
puting power. To overcome this increase in complexity, a number of approximation
methods for Gaussian process regression have been proposed. In particular, the sparse
greedy approximation method [79], the Nystrom method [80], the informative vec-
tor machine [81], the likelihood approximation [82], and the Bayesian committee
machine [83] have been shown to be effective for many problems. However, these
approximation methods have been proposed without theoretical justiﬁcations.
In general, if measurements are taken from nearby locations (or space-time loca-
tions), correlation between measurements is strong and correlation exponentially
decays as the distance between locations increases. If the correlation function of a
Gaussian process has this property, intuitively, we can make a good prediction at a
point of interest using only measurements nearby. In the next subsection, we for-
malize this idea and provide a theoretical foundation for justifying Gaussian process
regression with truncated observations proposed in this chapter.
4.1.1 Error Bounds Using Truncated Observations
Consider a zero-mean Gaussian process
z(x) ∼GP(0, σ2
f C(x, x′)).
(4.1)

4.1 GPR with Truncated Observations
29
Notice that we denote the covariance function as σ2
f C(x, x′) in which C(x, x′) :=
Corr(z(x), z(x′)) is the correlation function. Recall that the predictive distribution
of z∗:= z(x∗) at a point of interest x∗given observations y = (y(1), . . . , y(n))T is
Gaussian, i.e.,
z∗|y ∼N

μz∗|y, σ2
z∗|y

,
(4.2)
where
μz∗|y = kT C−1k,
(4.3a)
and
σ2
z∗|y = σ2
f (1 −kT C−1k).
(4.3b)
In (4.3a) and (4.3b), we have deﬁned C := Corr(y, y) ∈Rn×n, and k :=
Corr(y, z∗) ∈Rn. Notice that in this chapter, we assume the hyperparameter vector
θ ∈RM is given, and hence we neglect the explicit conditioning on θ.
Without loss of generality, we assume that the ﬁrst m out of n observations are used
to predict z∗. Let r = n −m, ym = (y(1), . . . , y(m))T , yr = (y(m+1), . . . , y(n))T .
Then the covariance matrix K ∈Rn×n and k ∈Rn can be represented as
K =
 Km Kmr
KT
mr Kr

,
k =
km
kr

.
Using truncated observations, we can predict the value z∗as
μz∗|ym = kT
mC−1
m km,
(4.4)
with a prediction error variance given by
σ2
z∗|ym = σ2
f (1 −kT
mC−1
m km),
(4.5)
where Cm = Km + σ2
wI ∈Rm×m.
The following result shows the gap between predicted values using truncated
measurements and all measurements.
Theorem 4.1 Consider a Gaussian process z(x) ∼GP(0, σ2
f C(x, x′)), we have
μz∗|y −μz∗|ym = (kr −KT
mrC−1
m km)T (Cr −KT
mrC−1
m Kmr)−1(yr −KT
mrC−1
m ym),
(4.6a)
and
σ2
z∗|yy −σ2
z∗|ym = −σ2
f (kr −KT
mrC−1
m km)T (Cr −KT
mrC−1
m Kmr)−1(kr −KT
mrC−1
m km) < 0.
(4.6b)

30
4
Memory Efﬁcient Prediction With Truncated Observations
Proof We can rewrite (4.3a) as
μz∗|y =
km
kr
T  Cm Kmr
KT
mr Cr
−1 ym
yr

,
(4.7a)
and (4.3b) as
σ2
z∗|y = σ2
f

1 −
km
kr
T  Cm Kmr
KT
mr Cr
−1 km
kr

.
(4.7b)
Using the identity based on matrix inversion lemma (see AppendixA.2), (4.7a) and
(4.7b) become
μz∗|y = kT
mC−1
m ym
+ (kr −KT
mrC−1
m km)T (Cr −KT
mrC−1
m Kmr)−1(yr −KT
mrC−1
m ym),
and
σ2
z∗|y = σ2
f

1 −kT
mC−1
m km

−σ2
f (kr −KT
mrC−1
m km)T (Cr −KT
mrC−1
m Kmr)−1(kr −KT
mrC−1
m km).
Hence, by the use of (4.4) and (4.5), we obtain (4.6a) and 4.6b.
□
Corollary 4.1 The prediction error variance σ2
z∗|ym is a non-increasing function
of m.
Proof The proof is straightforward from Theorem4.1 by letting n = m + 1.
□
Considering an ideal case in which the measurements ym are not correlated with
the remaining measurements yr, we have the following result.
Proposition 4.1 Under the assumptions used in Theorem4.1 and for given yr ∼
N(0, Cr), if Kmr = 0, then μz∗|y −μz∗|ym = kT
r C−1
r yr and σ2
z∗|y −σ2
z∗|ym =
−σ2
f kT
r C−1
r kr. In addition, we also have
μz∗|y −μz∗|ym
 ≤
			kT
r C−1
r
			
√r ¯y(p1)
with a non-zero probability p1. For a desired p1, we can ﬁnd ¯y(p1) by solving
p1 =

1≤i≤r

1 −2Φ

−¯y(p1)
λ1/2
i

,
(4.8)

4.1 GPR with Truncated Observations
31
where Φ is the cumulative normal distribution and {λi | i = 1, . . . ,r} are the eigen-
values of Cr = UUT with a unitary matrix U, and  = diag(λ1, . . . , λr).
Proof The ﬁrst statement is straightforward from Theorem4.1.
For the second statement, we can represent yr as yr = C1/2
r
u = U1/2u = U˜y,
where u is a vector of independent standard normals and Cr = UUT and C1/2
r
=
U1/2. By using the Cauchy-Schwarz inequality and norm inequalities, we have
μz∗|y −μz∗|ym
 =
kT
r C−1
r yr
 =
kT
r C−1
r U˜y

≤
			kT
r C−1
r
			
		U˜y
		 =
			kT
r C−1
r
			
		˜y
		
≤
			kT
r C−1
r
			
√r
		˜y
		
∞≤
			kT
r C−1
r
			
√r ¯y.
Recall that we have u ∼N(0, I) and ˜y ∼N(0, ), where  = diag(λ1, . . . , λr).
Then we can compute the probability p1 = Pr(
		˜y
		
∞≤¯y) as follows.
p1 = Pr

max
1≤i≤r
 ˜y(i) ≤¯y

= Pr

max
1≤i≤r
λ1/2
i
ui
 ≤¯y

=

1≤i≤r
Pr

λ1/2
i
|ui| ≤¯y

=

1≤i≤r
Pr

|ui| ≤
¯y
λ1/2
i

=

1≤i≤r

1 −2Φ

−
¯y
λ1/2
i

,
where Φ(·) is the cumulative standard normal distribution.
□
Hence, if the magnitude of Kmr is small, then the truncation error from using trun-
cated measurements will be close to kT
r C−1
r kr. Furthermore, if we want to reduce this
error, we want kr to be small, i.e., when the covariance between z∗and the remaining
measurements yr is small. In summary, if the following two conditions are satisﬁed:
(1) the correlation between measurements ym and the remaining measurements yr
is small and (2) the correlation between z∗and the remaining measurements yr is
small, then the truncation error is small and μz∗|ym can be a good approximation to
μz∗|y. This idea is formalized in a more general setting in the following theorem.
Theorem 4.2 Consider a zero-mean Gaussian process z(x) ∼N(0, σ2
f C(x, x′))
with the correlation function
C(x, x′) = exp

−
		x −x′		2
2σ2
ℓ

,
(4.9)

32
4
Memory Efﬁcient Prediction With Truncated Observations
andassumethatwehavecollectedn observations, y(1), . . . , y(n).SupposethatKmr is
smallenoughsuchthat
			KT
mrC−1
m km
			 ≤∥kr∥,and
			KT
mrC−1
m ym
			 ≤δ2
		yr
		andfor
some δ2 > 0. Given 0 < p2 < 1, choose ¯y(p2) such that maxn
i=m+1
y(i) < ¯y(p2)
with probability p2 and ϵ > 0 such that ϵ < 2γr(1 + δ2) ¯y(p2) where γ is the
signal-to-noise ratio. For x∗, if the last r = n −m data points satisfy
			x(i) −x∗
			
2
> 2σ2
ℓlog

2γ 1
ϵr(1 + δ2) ¯y(p2)

,
then, with probability p2, we have
μz∗|y −μz∗|ym
 < ϵ.
Proof Let A = C−1
m Kmr and B = KT
mrC−1
m Kmr for notational convenience. Then
μz∗|y −μz∗|ym
 =
			(kT
r −kT
mA)(Cr −B)−1(kr −AT ym)
			
≤
			kT
r −kT
mA
			
			(Cr −B)−1(yr −AT ym)
			
≤
			kT
r −kT
mA
			 × (
			(Cr −B)−1yr
			 +
			(Cr −B)−1AT ym
			)
≤2 ∥kr∥
			(Cr −B)−1yr
			 +
			(Cr −B)−1AT ym
			

Since Kr is positive semi-deﬁnite, and Cm is positive deﬁnite, we have Kr −B is
positive semi-deﬁnite. Then we have
(Cr −B)−1 = (Kr + 1/γI −B)−1 ⪯γI.
Combining this result, we get
μz∗|y −μz∗|ym
 ≤2γ ∥kr∥(
		yr
		 +
			AT ym
			)
≤2γ(1 + δ2) ∥kr∥
		yr
		
≤2γ(1 + δ2)√rCmax
		yr
		 ,
where C(x(i), x∗) ≤Cmax for i
∈{m + 1, . . . , n}. Deﬁne ¯y(p2) such that
maxn
i=m+1
y(i) ≤¯y(p2) with probability p2. Then, with probability p2, we have
μz∗|y −μz∗|ym
 ≤2γr(1 + δ2)Cmax ¯y(p2).
Hence, for ϵ > 0, if
Cmax <
ϵ
2γr(1 + δ2) ¯y(p2)
(4.10)

4.1 GPR with Truncated Observations
33
with probability p2, we have
μz∗|y −μz∗|ym
 < ϵ.
Let l2 = min
		x(i) −x∗
		2 for any i ∈{m + 1, . . . , n}. Then (4.10) becomes, with
probability p2,
exp

−l2
2σ2
ℓ

≤Cmax <
ϵ
2γr(1 + δ2) ¯y(p2)
l2 > −2σ2
ℓlog

ϵ
2γr(1 + δ2) ¯y(p2)

For ϵ < 2γr(1 + δ2) ¯y(p2), we have
l2 > 2σ2
ℓlog

2γ 1
ϵr(1 + δ2) ¯y(p2)

,
and this completes the proof.
□
Remark 4.1 The last part of Proposition4.1 and Theorem4.2 seek a bound for the
difference between predicted values using all and truncated observations with a given
probability since the difference is a random variable.
Example 4.1 We provide an illustrative example to show how to use the result of
Theorem4.2 as follows. Consider a Gaussian process deﬁned in (4.1) and (4.9) with
σ2
f = 1, σℓ= 0.2, and γ = 100. If we have any randomly chosen 10 samples
(m = 10) within (0, 1)2 and we want to make prediction at x∗= (1, 1)T . We choose
¯y(p2) = 2σ f = 2 such that maxn
i=m+1
y(i) < ¯y(p2) with probability p2 = 0.95.
According to Theorem4.2, if we have an extra sample x(11) (r = 1) at (2.5, 2.5)T ,
which satisﬁes the condition
		x(11) −x∗
		 > 0.92, then the difference in prediction
using with and without the extra sample is less than ϵ = 0.01 with probability
p2 = 0.95.
Example 4.2 Motivated by the results presented, we take a closer look at the use-
fulness of using a subset of observations from a sensor network for a particular
realization of the Gaussian process. We consider a particular realization shown in
Fig.4.2, where crosses represent the sampling points of a Gaussian process deﬁned
in (4.1) and (4.9) with σ2
f = 1, σℓ= 0.2, and γ = 100 over (0, 1)2. We have selected
ym as the collection of observations (blue crosses) within the red circle of a radius
R = 2σℓ= 0.4 centered at a point (a red star) located at x∗= (0.6, 0.4)T . If a mea-
surement is taken outside the red circle, the correlation between this measurement
and the value at x∗decreases to 0.135. The rest of observations (blue crosses outside

34
4
Memory Efﬁcient Prediction With Truncated Observations
Fig. 4.2 Example of the
selection of truncated
observations. The parameters
used in the example are:
σ2
f = 1, σℓ= 0.2, σw = 0.1
0
0.2
0.4
0.6
0.8
1
0
0.2
0.4
0.6
0.8
1
of the red circle) are selected as yr. The prediction results are shown in Table4.1. In
this particular realization, we have z∗= 1.0298. It can be seen that the prediction
means and variances using only ym are close to the one using all observations. We
also compute the prediction at x∗with yr which is far from the true value with a
large variance.
The result of Theorem4.2 and Examples4.1 and 4.2 all suggest the usage of
observations that are highly correlated with the point of interest.
4.1.2 Selecting Temporal Truncation Size
Inprevioussubsection,wehaveobtainedtheerrorboundsforthepredictionatasingle
point. In general, the observations made close to that point are more informative than
the others.
Table 4.1 Prediction means and variances using y, ym, and yr
n = 20
m = 12
r = 8
μz∗|y
1.0515
1.0633
0.3491
σ2
z∗|y
0.0079
0.0080
0.9364

4.1 GPR with Truncated Observations
35
Consider a zero-mean spatio-temporal Gaussian process
z(s, t) ∼GP(0, σ2
f C(s, t, s′, t′)),
(4.11)
with covariance function
C(x, x′) = Cs(s, s′)Ct(t, t′)
= exp
⎛
⎝−

ℓ=1,2
(sℓ−s′
ℓ)2
2σ2
ℓ
⎞
⎠exp

−(t −t′)2
2σ2t

.
(4.12)
We deﬁne η as the truncation size, and our objective is to use only the observations
made during the last η time steps, i.e., from time t −η+1 to time t, to make prediction
at time t. In general, a small η yields faster computation but lower accuracy and a large
η yields slower computation but higher accuracy. Thus, the truncation size η should
be selected according to a trade-off relationship between accuracy and efﬁciency.
Next, we show an approach to select the truncation size η in an averaged perfor-
mance sense. Given the observations and associated sampling locations and times
(denoted by D which depends on η), the generalization error ϵx∗,D at a point
x∗= (sT
∗, t∗)T is deﬁned as the prediction error variance σ2
z∗|D [102, 103]. For
a given t∗not knowing user speciﬁc s∗a priori, we seek to ﬁnd η that guarantees
a low prediction error variance uniformly over the entire space Q, i.e., we want
ϵD = Es∗[σ2
z∗|D] to be small [102, 103]. Here Es∗denotes the expectation with
respect to the uniform distribution of s∗.
According to Mercer’s Theorem, we know that the kernel function Cs can be
decomposed into
Cs(s, s′) =
∞

i=1
λiφi(s)φi(s′),
where {λi} and {φi(·)} are the eigenvalues and corresponding eigenfunctions, respec-
tively [103]. In a similar way shown in [103], the input dependent generalization error
ϵD for our spatio-temporal Gaussian process can be obtained as
ϵD = Es∗

σ2
f

1 −tr

kkT (K + 1/γI)−1
(4.13)
= σ2
f

1 −tr

Es∗[kkT ](K + 1/γI)−1
.
We have
Es∗[kkT ] = 2T ◦ktkT
t ,
(4.14)
and
K = T ◦KtKT
t ,
(4.15)

36
4
Memory Efﬁcient Prediction With Truncated Observations
where ()i j = φ j(si), (kt) j = Ct(t( j), t∗), (Kt)i j = Ct(t(i), t( j)), and ()i j =
λiδi j. δi j denotes the Dirac delta function. ◦denotes the Hadamard (element-wise)
product [103]. Hence, the input-dependent generalization error ϵD can be computed
analytically by plugging (4.14) and (4.15) into (4.13). Notice that ϵD is a function of
inputs (i.e., the sampling locations and times). To obtain an averaged performance
level without the knowledge of the algorithmic sampling strategy a priori, we use
an appropriate sampling distribution which models the stochastic behavior of the
sampling strategy. Thus, further averaging over the observation set D with the samp-
ing distribution yields ϵ(η) = ED[ϵD] which is a function of the truncation size
η only. This averaging process can be done using Monte Carlo methods. Then η
can be chosen based on the averaged performance measure ϵ(η) under the sampling
distribution.
An alternative way, without using the eigenvalues and eigenfunctions, is to directly
and numerically compute ϵD = Es∗[σ2
z∗|D] uniformly over the entire space Q with
random sampling positions at each time step. An averaged generalization error with
respect to the temporal truncation size can be plotted by using such Monte Carlo
methods. Then the temporal truncation size η can be chosen such that a given level
of the averaged generalization error is achieved.
Example 4.3 Consider a problem of selecting a temporal truncation size η for
spatio- temporal Gaussian process regression using observations from 9 agents.
The spatio-temporal Gaussian process is deﬁned in (4.1) and (4.9) with σ2
f = 1,
σ1 = σ2 = 0.2, σt = 5, and γ = 100 over (0, 1)2. The Monte Carlo simulation
result is shown in Fig.4.3. The achieved generalization error ϵD are plotted in blue
circles with error-bars with respect to the temporal truncation size η. As can be seen,
an averaged generalization error (in blue circles) under 0.1 can be achieved by using
observations taken from last 10 time steps.
Fig. 4.3 Example of
selecting a temporal
truncation size η. The
parameters used in the
example are: σ2
f = 1,
σ1 = σ2 = 0.2, σt = 5,
γ = 100
0
5
10
15
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
0.45
0.5
0.55
η
ϵD

4.1 GPR with Truncated Observations
37
Notice that the prediction error variances can be signiﬁcantly minimized by opti-
mally selecting the sampling positions. Hence, the selected η guarantees at least
the averaged performance level of the sensor network when the optimal sampling
strategy is used.
By using a ﬁxed truncation size η, the computational complexity and memory
space required for making prediction (i.e., evaluating (4.3a) and (4.3b)) do not
increase as more measurements are collected. Our next objective is to improve the
quality of the prediction by carefully selecting the future sampling positions for the
mobile sensor network.
4.2 Optimal Sampling Strategies
At time t, the goal of the mobile sensor network is to make prediction at pre-speciﬁed
points of interest

p j = (v j, τ j) | j ∈J

indexed by J := {1, . . . , M}. From here
on, points of interest will be referred to as target points. The introduction of target
points is motivated by the fact that the potential environmental concerns should be
frequently monitored. For instance, the target points can be assigned at the interface
of a factory and a lake, sewage systems, or polluted beaches. Thus, the introduction
of target points, which can be arbitrarily speciﬁed by a user, provides a ﬂexible way
to deﬁne a geometrical shape of a subregion of interest in a surveillance region.
Notice that the target points can be changed by a user at any time. In particular, we
allow that the number of target points M can be larger than that of agents N, which
is often the case in practice. The prediction of z j := z(p j) of the Gaussian process
at a target point p j can be obtained as in (4.3a) and (4.3b).
4.2.1 Centralized Navigation Strategy
Consider the case in which a central station receives collective measurements from
all N mobile sensors and performs the prediction. Let the central station discard the
oldest set of measurements yt−η+1 after making the prediction at time t. At the next
time index t + 1, using the remained observations yt−η+2:t in the memory along
with new measurements yt+1 from all N agents at time t + 1, the central station will
predict z(s∗, t∗) evaluated at target points

p j | j ∈J

. Hence, agents should move
to the most informative locations for taking measurements at time t + 1 [44].
For notational simplicity, let ¯y ∈RN(η−1) be the remaining observations, i.e.,
¯y := yt−η+2:t, and ˜y ∈RN be the measurements that will be taken at positions
˜q = (˜qT
1 , . . . , ˜qT
N)T ∈QN and time t + 1. In contrast to the information-theoretic
control strategies using the conditional entropy or the mutual information criterion
[44, 72], in this chapter, the mobility of the robotic sensors will be designed such

38
4
Memory Efﬁcient Prediction With Truncated Observations
that they directly minimize the average of the prediction error variances over target
points, i.e.,
Jc(˜q) =
1
|J |

j∈J
σ2
z j|¯y,˜y(˜q),
(4.16)
where |J | = M is the cardinality of J . The prediction error variance at each of M
target points is given by
σ2
z j|¯y,˜y(˜q) = σ2
f

1 −k j(˜q)T C(˜q)−1k j(˜q)

,
∀j ∈J ,
where k j(˜q) and C(˜q) are deﬁned as
k j(˜q) =
Corr(¯y, z j)
Corr(˜y, z j)

,
C(˜q) =
Corr(¯y, ¯y) Corr(¯y, ˜y)
Corr(˜y, ¯y) Corr(˜y, ˜y)

.
In order to reduce the average of prediction error variances over target points

p j | j ∈J

, the central station solves the following optimization problem
q(t + 1) = arg min
˜q∈QN Jc(˜q).
(4.17)
Notice that in this problem set-up, we only consider the constraint that robots should
move within the region Q. However, the mobility constraints such as the maximum
distance a robot can move between two time indices or the maximum speed a robot
can travel, can be incorporated as additional constraints in the optimization problem
[45].
The sensor network conﬁguration q(t) can be controlled by a gradient descent
algorithm such that q(t) can move to a local minimum of Jc for the prediction at
time t + 1. The gradient descent control algorithm is given by
dq(τ)
dτ
= −∇qJc(q(τ)),
(4.18)
where ∇x Jc(x) denotes the gradient of Jc(x) at x. A critical point of Jc(q) obtained
in (4.18) will be q(t +1). The analytical form of ∂σ2
z j|¯y,˜y(˜q)/∂˜qi,ℓ, where ˜qi,ℓis the
ℓth element in ˜qi ∈Q, can be obtained by
∂σ2
z j|¯y,˜y(˜q)
∂˜qi,ℓ
= kT
j C−1
 ∂C
∂˜qi,ℓ
C−1k j −2 ∂k j
∂˜qi,ℓ

,
∀i ∈I, ℓ∈{1, 2} .
Other more advanced non-linear optimization techniques may be applied to solve
the optimization problem in (4.17) [104].

4.2 Optimal Sampling Strategies
39
The centralized sampling strategy for the mobile sensor network with the cost
function Jc in (4.16) is summarized in Table4.2. Notice that the prediction in the
centralized sampling strategy uses temporally truncated observations. A decentral-
ized version of the centralized sampling strategy in Table4.2 may be developed using
the approach proposed in [105] in which each robot incrementally reﬁnes its decision
while intermittently communicating with the rest of the robots.
4.2.2 Distributed Navigation Strategy
Now, we consider a case in which each agent in the sensor network can only com-
municate with other agents within a limited communication range R. In addition,
no central station exists. In this section, we present a distributed navigation strategy
for mobile agents that uses only local information in order to minimize a collective
network performance cost function.
The communication network of mobile agents can be represented by an undirected
graph. Let G(t) := (I, E(t)) be an undirected communication graph such that an
edge (i, j) ∈E(t) if and only if agent i can communicate with agent j at time t. We
deﬁne the neighborhood of agent i at time t by Ni(t) := { j ∈I | (i, j) ∈E(t)}. In
particular, we have
Ni(t) =

j ∈I |
		qi(t) −q j(t)
		 < R, j ̸= i

.
Note that in our deﬁnition above, “<” is used instead of “≤” in deciding the com-
munication range.
At time t ∈Z>0, agent i collects measurements

y j(t) | j ∈{i} ∪Ni(t)

sampled
at

q j(t) | j ∈{i} ∪Ni(t)

from its neighbors and itself. The collection of these
observations and the associated sampling positions in vector forms are denoted by
y[i]
t
and q[i]
t , respectively. Similarly, for notational simplicity, we also deﬁne the
cumulative measurements that have been collected by agent i from time t −η + 1
to t as
y[i]
t−η+1:t =

(y[i]
t−η+1)T , . . . , (y[i]
t )T T
.
In contrast to the centralized scheme, in the distributed scheme, each agent deter-
mines the sampling points based on the local information from neighbors. After
making the prediction at time t, agent i discards the oldest set of measurements
y[i]
t−η+1. At time t + 1, using the remained observations y[i]
t−η+2:t in the memory
along with new measurements y[i]
t+1 from its neighbors in Ni(t + 1), agent i will
predict z(s∗, t∗) evaluated at target points

p j | j ∈J

.

40
4
Memory Efﬁcient Prediction With Truncated Observations
Table 4.2 Centralized sampling strategy at time t
Input:
(1) Number of agents N
(2) Positions of agents {qi(t) | i ∈I}
(3) Hyperparameters of the Gaussian process θ = (σ2
f, σ1, σ2, σt)T
(4) Target points

pj | j ∈J

(5) Truncation size η
Output:
(1) Prediction at target points

μzj|yt−η+1:t | j ∈J

(2) Prediction error variance at target points

σ2
zj|yt−η+1:t | j ∈J

For i ∈I, agent i performs:
1: make an observation at current position qi(t), i.e., yi(t)
2: transmit the observation yi(t) to the central station
The central station performs:
1: collect the observations from all N agents, i.e., yt = (y1(t), · · · , yN(t))T
2: obtain
the
cumulative
measurements,
i.e.,
yt−η+1:t
=
(yT
t−η+1, · · · , yT
t )T
3: for j ∈J do
4:
make prediction at a target point pj
μzj|yt−η+1:t = kT C−1y,
with a prediction error variance given by
σ2
zj|yt−η+1:t = σ2
f(1 −kT C−1k),
where y = yt−η+1:t, k = Corr(y, zj), and C = Corr(y, y)
5: end for
6: if t ≥η then
7:
discard the oldest set of measurements taken at time t −η + 1, i.e.,
yt−η+1
8: end if
9: compute the control with the remained data yt−η+2:t
q(t + 1) = arg min˜q∈QN Jc(˜q),
via
dq(τ)
dτ
= −∇qJc(q(τ))
10: send the next sampling positions {qi(t + 1)}N
i=1 (a critical point of Jc(˜q))
to all N agents
For i ∈I, agent i performs:
1: receive the next sampling position qi(t + 1) from the central station
2: move to qi(t + 1) before time t + 1

4.2 Optimal Sampling Strategies
41
For notational simplicity, let ¯y[i] be the remaining observations of agent i, i.e.,
¯y[i] := y[i]
t−η+2:t. Let ˜y[i] be the new measurements that will be taken at positions of
agent i and its neighbors ˜q[i] ∈Q|Ni(t+1)|+1, and at time t + 1, where |Ni(t + 1)|
is the number of neighbors of agent i at time t + 1. The prediction error variance
obtained by agent i at each of M target points (indexed by J ) is given by
σ2
z j|¯y[i],˜y[i](˜q[i]) = σ2
f

1 −k[i]
j (˜q[i])T C[i](˜q[i])−1k[i]
j (˜q[i])

,
∀j ∈J ,
where k[i]
j (˜q[i]) and C[i](˜q[i]) are deﬁned as
k[i]
j (˜q[i]) =

Corr(¯y[i], z j)
Corr(˜y[i], z j)

,
C[i](˜q[i]) =

Corr(¯y[i], ¯y[i]) Corr(¯y[i], ˜y[i])
Corr(˜y[i], ¯y[i]) Corr(˜y[i], ˜y[i])

.
(4.19)
The performance of agent i can be evaluated by the average of the prediction error
variances over target points, i.e.,
J [i](˜q[i]) =
1
|J |

j∈J
σ2
z j|¯y[i],˜y[i](˜q[i]),
∀i ∈I.
One criterion to evaluate the network performance is the average of individual per-
formance, i.e.,
J(˜q) = 1
|I|

i∈I
J [i](˜q[i]).
(4.20)
However, the discontinuity of the function J occurs at the moment of gaining or
losing neighbors, e.g., at the set
˜q |
		˜qi −˜q j
		 = R

.
A gradient decent algorithm for mobile robots that minimizes such J may produce
hybrid system dynamics and/or chattering behaviors when robots lose or gain neigh-
bors.
Therefore, we seek to minimize an upper-bound of J that is continuously differ-
entiable. Consider the following function
¯σ2
z j|¯y[i],˜y[i](˜q[i]) = σ2
f

1 −k[i]
j (˜q[i])T ¯C
[i](˜q[i])−1k[i]
j (˜q[i])

,
∀j ∈J ,
(4.21)

42
4
Memory Efﬁcient Prediction With Truncated Observations
Fig. 4.4 Function Φ(d) in
(4.22) with γ = 100,
R = 0.4, and d0 = 0.1 is
shown in a red dotted line.
The function Φ(d) = γ is
shown in a blue solid line
0
0.1
0.2
0.3
0.4
0.5
0
20
40
60
80
100
d
Φ(d)
where ¯C
[i](˜q[i]) is deﬁned as
¯C
[i](˜q[i]) =

Corr(¯y[i], ¯y[i])
Corr(¯y[i], ˜y[i])
Corr(˜y[i], ¯y[i]) Corr(˜y[i], ˜y[i]) + ˜C
[i](˜q[i])

.
Notice that ¯C
[i](˜q[i]) is obtained by adding a positive semi-deﬁnite matrix ˜C
[i](˜q[i])
to the lower right block of C[i](˜q[i]) in (4.19), where
˜C
[i](˜q[i]) = diag

Φ(di1)−1, . . . , Φ(di(|Ni(t+1)|+1))−1
−1
γ I,
where di j :=
		˜qi −˜q j
		 is the distance between agent i and agent j, ∀j ∈{i} ∪
Ni(t + 1). Φ : [0, R) →(0, γ] is a continuously differentiable function deﬁned as
Φ(d) = γφ
d + d0 −R
d0

,
(4.22)
where
φ(h) =
 1,
h ≤0,
exp

−h2
1−h2

, 0 < h < 1.
An example of Φ(d) where γ = 100, R = 0.4, and d0 = 0.1 is shown in the red
dotted line in Fig.4.4. Notice that if Φ(d) = γ is used (the blue solid line in Fig.4.4),
we have ¯C
[i](˜q[i]) = C[i](˜q[i]). We then have the following result.
Proposition 4.2 ¯σ2
z j|¯y[i],˜y[i](˜q[i]) is an upper-bound of σ2
z j|¯y[i],˜y[i](˜q[i]), ∀i ∈I.

4.2 Optimal Sampling Strategies
43
Proof Let A := C[i](˜q[i]) and B := diag(0, ˜C
[i](˜q[i])). The result follows immedi-
ately from the fact that (A + B)−1 ⪯A−1 for any A ≻0 and B ⪰0.
□
Hence, we construct a new cost function as
Jd(˜q) = 1
|I|

i∈I
1
|J |

j∈J
¯σ2
z j|¯y[i],˜y[i](˜q[i]).
(4.23)
By Proposition4.2, Jd in (4.23) is an upper-bound of J in (4.20).
Next, we show that Jd is continuously differentiable when agents gain or lose
neighbors. In doing so, we compute the partial derivative of Jd with respect to ˜qi,ℓ,
where ˜qi,ℓis the ℓth element in ˜qi ∈Q, as follows.
∂Jd(˜q)
∂˜qi,ℓ
= 1
|I|

k∈I
1
|J |

j∈J
∂¯σ2
z j|¯y[k],˜y[k](˜q[k])
∂˜qi,ℓ
= 1
|I|

k∈{i}∪Ni
1
|J |

j∈J
∂¯σ2
z j|¯y[k],˜y[k](˜q[k])
∂˜qi,ℓ
,
∀i ∈I, ℓ∈{1, 2} .
(4.24)
We then have the following.
Proposition 4.3 The cost function Jd in (4.23) is of class C1, i.e., it is continuously
differentiable.
Proof We need to show that the partial derivatives of Jd with respect to ˜qi,ℓ, ∀i ∈
I, ℓ∈{1, 2} exist and are continuous. Without loss of generality, we show that
∂Jd/∂˜qi,ℓ, ∀ℓ∈{1, 2} is continuous at any point ˜q∗in the following boundary set
deﬁned by
Sik :=
˜q | dik =
		˜qi −˜qk
		 = R

.
First, we consider a case in which ˜q /∈Sik and dik < R, i.e., k ∈Ni and i ∈Nk. By
the construction of ¯σ2
z j|¯y[i],˜y[i] in (4.21) using (4.22), when we take the limit of the
partial derivative, as dik approaches R from below (as ˜q approaches ˜q∗), we have
that
lim
dik→R−
∂¯σ2
z j|¯y[i],˜y[i](˜q[i])
∂˜qi,ℓ
=
∂¯σ2
z j|¯y[i],˜y[i](˜q[i]\˜qk)
∂˜qi,ℓ
,
lim
dik→R−
∂¯σ2
z j|¯y[k],˜y[k](˜q[k])
∂˜qi,ℓ
=
∂¯σ2
z j|¯y[k],˜y[k](˜q[k]\˜qi)
∂˜qi,ℓ
= 0,

44
4
Memory Efﬁcient Prediction With Truncated Observations
Table 4.3 Distributed sampling strategy at time t
Input:
(1) Number of agents N
(2) Positions of agents {qi(t) | i ∈I}
(3) Hyperparameters of the Gaussian process θ = (σ2
f, σ1, σ2, σt)T
(4) Target points

pj | j ∈J

(5) Truncation size η
Output:
(1) Prediction at target points

μzj|y[i]
t−η+1:t | i ∈I, j ∈J

(2) Prediction error variances at target points

σ2
zj|y[i]
t−η+1:t | i ∈I, j ∈J

For i ∈I, agent i performs:
1: make an observation at qi(t), i.e., yi(t)
2: transmit the observation to the neighbors in Ni(t)
3: collect the observations from neighbors in Ni(t), i.e., y[i](t)
4: obtain
the
cumulative
measurements,
i.e.,
y[i]
t−η+1:t
=

(y[i]
t−η+1)T , · · · , (y[i]
t )T 	T
5: for j ∈J do
6:
make prediction at a target point pj
μzj|y[i]
t−η+1:t = kT C−1y,
with a prediction error variance given by
σ2
zj|y[i]
t−η+1:t = σ2
f(1 −kT C−1k),
where y = y[i]
t−η+1:t, k = Corr(y, zj), and C = Corr(y, y)
7: end for
8: if t ≥η then
9:
discard the oldest set of measurements taken at time t −η + 1, i.e.,
y[i]
t−η+1
10: end if
11: while t ≤τ ≤t + 1 do
12:
compute ∇qℓJ[i] with the remained data y[i]
t−η+2
13:
send ∇qℓJ[i] to agent ℓin Ni(τ)
14:
receive ∇qiJ[ℓ] from all neighbors in Ni(τ)
15:
compute the gradient ∇qiJd = 
ℓ∈Ni(τ) ∇qiJ[ℓ]/|I|
16:
update position according to qi(τ + δt) = qi(τ) −α∇qiJd for a small
step size α
17: end while

4.2 Optimal Sampling Strategies
45
where ˜q[a]\˜qb denotes the collection of locations of agent a and its neighbors exclud-
ing ˜qb. Hence we have
lim
dik→R−
∂Jd(˜q)
∂˜qi,ℓ
= ∂Jd(˜q∗)
∂˜qi,ℓ
.
(4.25)
Consider the other case in which ˜q /∈Sik and dik > R, i.e., k /∈Ni and i /∈Nk.
When dik approaches R from above (as ˜q approaches ˜q∗), we have
lim
dik→R+
∂¯σ2
z j|¯y[i],˜y[i](˜q[i])
∂˜qi,ℓ
=
∂¯σ2
z j|¯y[i],˜y[i](˜q[i])
∂˜qi,ℓ
,
and hence
lim
dik→R+
∂Jd(˜q)
∂˜qi,ℓ
= ∂Jd(˜q∗)
∂˜qi,ℓ
.
(4.26)
Therefore, from (4.25) and (4.26), we have
lim
dik→R−
∂Jd(˜q)
∂˜qi,ℓ
=
lim
dik→R+
∂Jd(˜q)
∂˜qi,ℓ
= ∂Jd(˜q∗)
∂˜qi,ℓ
.
This completes the proof due to Theorem4.6 in [106].
□
By using Jd in (4.23), a gradient descent algorithm can be used to minimize the
network performance cost function Jd in (4.23) for the prediction at t + 1.
dq(τ)
dτ
= −∇qJd(q(τ)).
(4.27)
Note that the partial derivative in (4.24), which builds the gradient ﬂow in (4.27), is a
function of positions in ∪j∈Ni(t)N j(t) only. This makes the algorithm distributed. A
distributed sampling strategy for agent i with the network cost function Jd in (4.23)
is summarized in Table4.3. In this way, each agent with the distributed sampling
strategy uses spatially and temporally truncated observations.
4.3 Simulation
In this section, we apply our approach to a spatio-temporal Gaussian process with
a covariance function in (4.12). The Gaussian process was numerically generated
through circulant embedding of the covariance matrix for the simulation [107]. The
hyperparameters used in the simulation were chosen to be θ = (σ2
f , σ1, σ2, σt)T =
(1, 0.2, 0.2, 5)T . The surveillance region Q is given by Q
=
(0, 1)2. The

46
4
Memory Efﬁcient Prediction With Truncated Observations
signal-to-noise ratio γ = 100 is used throughout the simulation which is equiva-
lent to a noise level of σw = 0.1. In our simulation, N = 9 agents sample at time
t ∈Z>0. The initial positions of the agents are randomly selected. The truncation
size η = 10 is chosen using the approach introduced in Sect.4.1.2 that guarantees the
averaged performance level ϵ(η = 10) < 0.1 under a uniform sampling distribution
(see Example4.3).
In the ﬁgures of simulation results, the target positions, the initial positions of
agents, the past sampling positions of agents, and the current positions of agents are
represented by white stars, yellow crosses, pink dots, and white circles with agent
indices, respectively.
4.3.1 Centralized Sampling Scheme
Consider a situation where a central station has access to all measurements collected
by agents. At each time, measurements sampled by agents are transmitted to the cen-
tral station that uses the centralized navigation strategy and sends control commands
back to individual agents.
Case 1: First, we consider a set of ﬁxed target points, e.g., 6 × 6 grid points on
Q at a ﬁxed time t = 10. At each time step, the cost function Jc in (4.16), which
is the average of prediction error variances at target points, is minimized due to the
proposed centralized navigation strategy in Sect.4.2.1. As a benchmark strategy, we
consider a random sampling scheme in which a group of 9 agents takes observations
at randomly selected positions within the surveillance region Q.
In Fig.4.5a, the blue circles represent the average of prediction error variances
over target points achieved by the centralized scheme, and the red squares indicate the
2
4
6
8
10
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
t
Prediction error variance
2
4
6
8 10 12 14 16 18 20
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
t
Prediction error variance
2
4
6
8 10 12 14 16 18 20
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
0.4
0.45
t
Prediction error variance
(a)
(b)
(c)
Fig. 4.5 Average of prediction error variances over target points (in blue circles) achieved by the
centralized sampling scheme using all collective observations for a Case 1, b Case 2, and c Case
3. In (a), the target points are ﬁxed at time t = 10, and the counterpart achieved by the benchmark
random sampling strategy is shown in red squares with error-bars. In (b) and (c), the target points
are at t + 1 and change over time. The counterpart achieved by using truncated observations are
shown in red squares

4.3 Simulation
47
(a)
(b)
(c)
(d)
(d)
(f)
Fig. 4.6 Simulation results at t = 1 and t = 5 obtained by the centralized sampling scheme for
Case 2. a True ﬁeld at t = 1. b True ﬁeld at t = 5. c Predicted ﬁeld at t = 1. d Predicted ﬁeld at
t = 5. e Prediction error variance at t = 1. f Prediction error variance at t = 5.

48
4
Memory Efﬁcient Prediction With Truncated Observations
average of prediction error variances over target points achieved by the benchmark
strategy. Clearly, the proposed scheme produces lower averaged prediction error
variances at target points as time increases, which demonstrates the usefulness of
our scheme.
Case 2: Next, we consider the same 6×6 grid points on Q as in Case 1. However,
at time t, we are now interested in the prediction at the next sampling time t + 1. At
each time step, the cost function Jc is minimized. Figure4.5b shows the average of
prediction error variances over target points achieved by the centralized scheme with
truncation (in red squares) and without truncation (in blue circles). With truncated
observations, i.e., with only observations obtained from latest η = 10 time steps, we
are able to maintain the same level of the averaged prediction error variances (around
0.05 in Fig.4.5b).
Figure4.6a, c and e show the true ﬁeld, the predicted ﬁeld, and the prediction error
variance at time t = 1, respectively. To see the improvement, the counterpart of the
simulation results at time t = 5 are shown in Fig.4.6b, d and f. At time t = 1, agents
have little information about the ﬁeld and hence the prediction is far away from
the true ﬁeld, which produces a large prediction error variance. As time increases,
the prediction becomes close to the true ﬁeld and the prediction error variances are
reduced due to the proposed navigation strategy.
Case 3: Now, we consider another case in which 36 target points (plotted in
Fig.4.7 as white stars) are evenly distributed on three concentric circles to form a
ring shaped subregion of interest. As in Case 2, we are interested in the prediction
at the next time iteration t + 1. The average of prediction error variances over these
target points at each time step achieved by the centralized scheme with truncation
(in red squares) and without truncation (in blue circles) are shown in Fig.4.5c. The
prediction error variances at time t = 1 and t = 5 are shown in Fig.4.7a and b,
respectively. It is shown that agents are dynamically covering the ring shaped region
to minimize the average of prediction error variances over the target points.
4.3.2 Distributed Sampling Scheme
Consider a situation in which the sensor network has a limited communication range
R, i.e., Ni(t) :=

j ∈I |
		qi(t) −q j(t)
		 < R, j ̸= i

. At each time t ∈Z>0,
agent i collects measurements from itself and its neighbors Ni(t) and makes pre-
diction in a distributed fashion. The distributed strategy is used to navigate itself to
move to the next sampling position. To be comparable with the centralized scheme,
the same target points as in Case 2 of Sect.4.3.1 are considered.

4.3 Simulation
49
(a)
(b)
Fig. 4.7 Simulation results obtained by the centralized sampling scheme for Case 3. The trajectories
of agents are shown in solid lines a Prediction error variance at t = 1. b Prediction error variance
at t = 5
Figure4.8 shows that the cost function, which is an upper-bound of the averaged
prediction error variance over target points and agents, deceases smoothly from time
t = 1 to t = 2 by the gradient descent algorithm with a communication range
R = 0.4. Signiﬁcant decreases occur whenever one of the agent gains a neighbor.
Notice that the discontinuity of minimizing J in (4.20) caused by gaining or losing
neighbors is eliminated due to the construction of Jd in (4.23). Hence, the proposed
distributed algorithm is robust to gaining or losing neighbors.
200
400
600
800
1000
1200
0.65
0.7
0.75
0.8
0.85
Number of iterations
Cost function
Fig. 4.8 Cost function Jd(˜q) from t = 1 to t = 2 with a communication range R = 0.4

50
4
Memory Efﬁcient Prediction With Truncated Observations
2
4
6
8 10 12 14 16 18 20
0
0.2
0.4
0.6
0.8
1
t
Prediction error variance
(a)
2
4
6
8 10 12 14 16 18 20
0
0.2
0.4
0.6
0.8
1
t
Prediction error variance
(b)
Fig. 4.9 Average of prediction error variances over all target points and agents achieved by
the distributed sampling scheme with a communication range a R = 0.3, and b R = 0.4. The
average of prediction error variances over all target points and agents are shown in blue circles.
The average of prediction error variance over local target points and agents are shown in red squares.
The error-bars indicate the standard deviation among agents
The following study shows the effect of different communication range. Intu-
itively, the larger the communication range is, the more information can be obtained
by the agent and hence the better prediction can be made. Figures4.9a and b show
the average of prediction error variances over all target points and agents in blue
circles with error-bars indicating the standard deviation among agents for the case
R = 0.3 and R = 0.4, respectively. In both cases, d0 = 0.1 in (4.22) was used. The
average of prediction error variances is minimized quickly to a certain level. It can
be seen that the level of achieved averaged prediction error variance with R = 0.4
is lower than the counterpart with R = 0.3.
Now, assume that each agent only predict the ﬁeld at target points within radius
R (local target points). The average of prediction error variances, over only local
target points and agents, are also plotted in Fig.4.9 in red squares with the standard
deviation among agents. As can be seen, the prediction error variances at local target
points (the red squares) are signiﬁcantly lower than those for all target points (the
blue circles).
Figure4.10 shows the prediction error variances obtained by agent 1 along with
the edges of the communication network for different communication range R and
different time step t. In Fig.4.10, the target positions, the initial positions, and the
current positions are represented by white stars, yellow crosses, and white circles,
respectively. Surprisingly, the agents under the distributed navigation algorithm pro-
duce an emergent, swarm-like behavior to maintain communication connectivity

4.3 Simulation
51
(a)
(b)
(c)
(d)
Fig. 4.10 Simulation results obtained by the distributed sampling scheme with different commu-
nication ranges. The edges of the graph are shown in solid lines. a R = 0 : 3, t = 1. b R = 0 : 3,
t = 2. c R = 0 : 3, t = 5. d R = 0 : 3, t = 20. e R = 0 : 4, t = 1. f R = 0 : 4, t = 2. g R = 0 : 4,
t = 5. h R = 0 : 4, t = 20
among local neighbors. Notice that this collective behavior emerged naturally and
was not generated by the ﬂocking or swarming algorithm as in [42].
This interesting simulation study (Fig.4.10) shows that agents won’t get too close
each other since the average of prediction error variances at target points can be
reduced by spreading over and covering the target points that need to be sampled.
However, agents won’t move too far away each other since the average of prediction
error variances can be reduced by collecting measurements from a larger population
of neighbors. This trade-off is controlled by the communication range. With the

52
4
Memory Efﬁcient Prediction With Truncated Observations
(e)
(f)
(g)
(h)
Fig. 4.10 (continued)
intertwined dynamics of agents over the proximity graph, as shown in Fig.4.10,
mobile sensing agents are coordinated in each time iteration in order to dynamically
cover the target positions for better collective prediction capability.

Chapter 5
Fully Bayesian Approach
In Chap.4, we analyzed the conditions under which near-optimal prediction can
be achieved using only truncated observations. This motivates the usage of sparse
Gaussian process proposed in [108]. However, they both assumed the covariance
function is known a priori. In this chapter, we relax this stringent assumption.
Unknown parameters in the covariance function can be estimated by a point esti-
mator based on maximum likelihood (ML) or maximum a posterior (MAP). Such
ML or MAP estimates may be regarded as the true parameters and then used in the
prediction as in Chap.3. However, the point estimate itself needs to be identiﬁed
using sufﬁcient amount of measurements and most importantly, the whole procedure
fails to incorporate the uncertainty in the point estimate into the prediction.
Motivated by the aforementioned issues, a fully Bayesian framework is adopted in
this chapter as it offers several advantages when inferring parameters and processes
from highly complex models. The Bayesian approach requires prior distributions to
be elicited for model parameters that are of interest. Although difﬁcult initially, this
forces the practitioner to reﬂect on all sources and extent of uncertainties from sci-
entiﬁc knowledge and past experience. In highly complex models, this pre-analysis
of uncertainties eventually yields better inference for the parameters of interest, and
even more so when data contains limited information. Once the priors are elicited,
the Bayesian framework is ﬂexible and effective in incorporating all uncertainties
as well as information (limited or otherwise from data) into a single entity, namely,
the posterior. There is, thus, no need to pre-process or account for each source of
uncertainty separately. The Bayesian framework seamlessly describes their joint
inﬂuence and contributions through the posterior distribution—which is also, con-
veniently, the only entity to focus on for inference. The fully Bayesian approach
further advocates priors for all unknown entities in the model; these entities can
either be nuisance parameters (such as the scale of measurement error from each
mobile sensor) or (hyper) parameters that govern the prior distributions (such as the
© The Author(s) 2016
Y. Xu et al., Bayesian Prediction and Adaptive Sampling Algorithms
for Mobile Sensor Networks, SpringerBriefs in Control,
Automation and Robotics, DOI 10.1007/978-3-319-21921-9_5
53

54
5
Fully Bayesian Approach
extent of spatial variability of the scalar ﬁeld). The fully Bayesian approach thus
allows additional sources and extent of uncertainties to be integrated into the infer-
ential framework, with the posterior distribution effectively capturing all aspects of
uncertainties involved. Subsequently, the practitioner needs only to focus on differ-
ent components of the posterior to obtain inference separately for the parameters
of interest, nuisance parameters and hyperparameters. The fully Bayesian approach
also allows data to select the most appropriate values for nuisance parameters and
hyperparameters automatically, and achieve optimal inference and prediction for the
scalar ﬁeld.
The advantage of a fully Bayesian approach, which will be adopted in this chapter,
is that the uncertainty in the model parameters are incorporated in the prediction [84].
In [85], Gaudard et al. presented a Bayesian method that uses importance sampling
for analyzing spatial data sampled from a Gaussian random ﬁeld whose covariance
function was unknown. However, the assumptions made in [85], such as noiseless
observations and time-invariance of the ﬁeld, limit the applicability of the approach
on mobile sensors in practice. The computational complexity of a fully Bayesian pre-
diction algorithm has been the main hurdle for applications in resource-constrained
robots. In [46], an iterative prediction algorithm without resorting to Markov Chain
Monte Carlo (MCMC) methods has been developed based on analytical closed form
solutions from results in [85], by assuming that the covariance function of the spa-
tiotemporal Gaussian random ﬁeld is known up to a constant. Our work builds on
such Bayesian approaches used in [46, 85] and explores new ways to synthesize
practical algorithms for mobile sensor networks under more relaxed conditions.
In Sect.5.1, we provide fully Bayesian approaches for spatiotemporal Gaussian
process regression under more practical conditions such as measurement noise and
the unknown covariance function. In Sect.5.2, using discrete prior probabilities and
compactly supported kernels, we provide a way to design sequential Bayesian pre-
diction algorithms in which the exact predictive distributions can be computed in
constant time (i.e., O(1)) as the number of observations increases. In particular, a
centralized sequential Bayesian prediction algorithm is developed in Sect.5.2.1, and
its distributed implementation among sensor groups is provided for a special case in
Sect.5.2.2. An adaptive sampling strategy for mobile sensors, utilizing the maximum
a posteriori (MAP) estimation of the parameters, is proposed to minimize the pre-
diction error variances in Sect.5.2.3. In Sect.5.3, the proposed sequential Bayesian
prediction algorithms and the adaptive sampling strategy are tested under practical
conditions for spatiotemporal Gaussian processes.
5.1 Fully Bayesian Prediction Approach
In this chapter, we consider a spatiotemporal Gaussian process denoted by
z(x) ∼GP

μ(x), σ2
f C(x, x′; θ)

,

5.1 Fully Bayesian Prediction Approach
55
where z(x) ∈R and x := (sT , t)T ∈Q × Z>0 contains the sampling location
s ∈Q ⊂R2 and the sampling time t ∈Z>0. The mean function is assumed to be
μ(x) = f (x)T β,
where f (x) := ( f1(x), . . . , f p(x))T ∈Rp is a known regression function, and
β ∈Rp is an unknown vector of regression coefﬁcients. The correlation between
z(x) and z(x′) is taken as
C(x, x′; θ) = Cs
s −s′
σs

Ct
t −t′
σt

,
(5.1)
which is governed by spatial and temporal distance functions Cs(·) and Ct(·). We
assume that Cs(·) and Ct(·) are decreasing kernel functions over space and time,
respectively, so that the correlation between two inputs decreases as the distance
between spatial locations (respectively, time indices) increases. The decreasing rate
depends on the spatial bandwidth σs (respectively, the time bandwidth σt) for given
ﬁxed time indices (respectively, spatial locations). The signal variance σ2
f gives the
overall vertical scale relative to the mean of the Gaussian process in the output space.
We deﬁne θ := (σs, σt)T ∈R2 for notational simplicity.
Given the collection of noise-corrupted observations from mobile sensing agents
up to time t, we want to predict z(s∗, t∗) at a prespeciﬁed location s∗∈S ⊂Q and
current (or future) time t∗. To do this, suppose we have a collection of n observations
D =

(x(i), y(i)) | i = 1, . . . , n
	
from N mobile sensing agents up to time t. Here
x(i) denotes the ith input vector of dimension 3 (i.e., the sampling position and time
of the ith observation) and y(i) denotes the ith noise-corrupted measurement. If all
observations are considered, we have n = Nt. Notice that the number of observations
n grows with the time t. For notational simplicity, let y := (y(1), . . . , y(n))T ∈Rn
denote the collection of noise-corrupted observations. Based on the spatiotemporal
Gaussian process, the distribution of the observations given the parameters β, σ2
f ,
and θ is Gaussian, i.e.,
y|β, σ2
f , θ ∼N(Fβ, σ2
f C)
with F and C deﬁned as
F :=

f (x(1)), . . . , f (x(n))
T
∈Rn×p,
C := Corr(y, y|θ) =

C(x(i), x( j); θ) + 1
γ δi j

∈Rn×n,
(5.2)
where δi j is the Kronecker delta which equals to one when i = j, and zero otherwise.

56
5
Fully Bayesian Approach
5.1.1 Prior Selection
Toinfertheunknownparametersβ,σ2
f ,andθ inaBayesianframework,thecollection
of them is considered to be a random vector with a prior distribution reﬂecting the
a priori belief of uncertainty for them. In this chapter, we use the prior distribution
given by
π(β, σ2
f , θ) = π(β|σ2
f )π(σ2
f )π(θ),
(5.3)
where
β|σ2
f ∼N(β0, σ2
f T).
The prior for π(σ2
f ) is taken to be the inverse gamma distribution, chosen to guarantee
positiveness of σ2
f and a closed-form expression for the posterior distribution of σ2
f
for computational ease of the proposed algorithms. To cope with the case where no
prior knowledge on β is available, which is often the case in practice, we propose to
use a noninformative prior. In particular, we take β0 = 0, T = αI, and subsequently,
let α →∞. Any proper prior π(θ) that correctly reﬂects the priori knowledge of θ
can be used.
5.1.2 MCMC-Based Approach
According to the Bayes rule, the posterior distribution of β, σ2
f , and θ is given by
π(β, σ2
f , θ|y) =
π(y|β, σ2
f , θ)π(β, σ2
f , θ)

π(y|β, σ2
f , θ)π(β, σ2
f , θ)dβdσ2
f dθ .
(5.4)
When a proper prior is used, the posterior distribution can be written as
π(β, σ2
f , θ|y) ∝π(y|β, σ2
f , θ)π(β, σ2
f , θ).
The inference on β, σ2
f , and θ can be carried out by sampling from the posterior
distribution in (5.4) via the Gibbs sampler. Table5.1 gives the steps based on the
following proposition.
Proposition 5.1 For a prior distribution given in (5.3) with the noninformative prior
on β, the conditional posteriors are given by
1. β|σ2
f , θ, y ∼N

ˆβ, σ2
f  ˆβ

, where
 ˆβ = (FT C−1F)−1,
ˆβ =  ˆβ(FT C−1y).

5.1 Fully Bayesian Prediction Approach
57
Table 5.1 Gibbs sampler
Input: initial samples β(1), σ2
f
(1), and θ(1)
Output: samples

β(i), σ2
f
(i), θ(i)m
i=1 from joint distribution π(β, σ2
f, θ|y)
1: initialize β(1), σ2
f
(1), θ(1)
2: for i = 1 to m do
3:
sample β(i+1) from π(β|σ2
f
(i), θ(i), y)
4:
sample σ2
f
(i+1) from π(σ2
f|β(i+1), θ(i), y)
5:
sample θ(i+1) from π(θ|β(i+1), σ2
f
(i+1), y)
6: end for
2. σ2
f |β, θ, y ∼IG

¯a, ¯b

, where
¯a = a + n + p
2
,
¯b = b + 1
2(y −Fβ)T C−1(y −Fβ).
3.
π(θ|β, σ2
f , y) ∝det(C)−1/2 exp

−(y −Fβ)T C−1(y −Fβ)
2σ2
f

π(θ).
Proof Since the noninformative prior is chosen, the posterior distribution shall be
computed with T = αI and then let α →∞.
(i) For given σ2
f , θ, and y, we have
π(β|σ2
f , θ, y) = lim
α→∞
π(y|β, σ2
f , θ)π(β|σ2
f )

π(y|β, σ2
f , θ)π(β|σ2
f )dβ .
Let
num1 = π(y|β, σ2
f , θ)π(β|σ2
f )
=
exp

−1
2σ2
f (y −Fβ)T C−1(y −Fβ)

(2πσ2
f )n/2 det(C)1/2
exp

−1
2σ2
f βT T−1β

(2πσ2
f )p/2 det(T)1/2
=
exp

−1
2σ2
f RSS

(2πσ2
f )(n+p)/2 det(C)1/2 det(T)1/2
× exp

−1
2σ2
f
(β −ˆβ)T (FT C−1F + T−1)(β −ˆβ)

,

58
5
Fully Bayesian Approach
and
den1 =
exp

−1
2σ2
f RSS

(2πσ2
f )(n+p)/2 det(C)1/2 det(T)1/2
×

exp

−1
2σ2
f
(β −ˆβ)T (FT C−1F + T−1)(β −ˆβ)

dβ
=
exp

−1
2σ2
f RSS

(2πσ2
f )(n+p)/2 det(C)1/2 det(T)1/2 (2πσ2
f )p/2 det(FT C−1F + T−1)−1/2
where
RSS = yT 
C−1 −C−1F(FT C−1F + T−1)−1FT C−1
y
= yT (C + FTFT )−1y.
Then we have
π(β|σ2
f , θ, y) = lim
α→∞
num1
den1
= lim
α→∞
exp

−1
2σ2
f (β −ˆβ)T (FT C−1F + T−1)(β −ˆβ)

(2πσ2
f )p/2 det(FT C−1F + T−1)−1/2
=
exp

−1
2σ2
f (β −ˆβ)T −1
ˆβ (β −ˆβ)

(2πσ2
f )p/2 det( ˆβ)1/2
.
Therefore, we have β|σ2
f , θ, y ∼N( ˆβ, σ2
f  ˆβ).
(ii) For given β, θ, and y, we have
π(σ2
f |β, θ, y) = lim
α→∞
π(y|β, σ2
f , θ)π(σ2
f |β)

π(y|β, σ2
f , θ)π(σ2
f |β)dσ2
f
= lim
α→∞
π(y|β, σ2
f , θ)π(β|σ2
f )π(σ2
f )

π(y|β, σ2
f , θ)π(β|σ2
f )π(σ2
f )dσ2
f
.

5.1 Fully Bayesian Prediction Approach
59
Let
num2 = π(y|β, σ2
f , θ)π(β|σ2
f )π(σ2
f )
=
exp

−1
2σ2
f (y −Fβ)T C−1(y −Fβ)

(2πσ2
f )n/2 det(C)1/2
×
exp

−1
2σ2
f βT T−1β

(2πσ2
f )p/2 det(T)1/2
ba exp

−b
σ2
f

Γ (a)(σ2
f )a+1
=
ba
Γ (a)(2π)¯a+1 det(C)1/2 det(T)1/2
1
(σ2
f )¯a+1 exp

−
¯b + 1
2βT T−1β
σ2
f

,
and
den2 =
ba
Γ (a)(2π)¯a+1 det(C)1/2 det(T)1/2
×

1
(σ2
f )¯a+1 exp

−
¯b + 1
2βT T−1β
σ2
f

dσ2
f
=
ba
Γ (a)(2π)¯a+1 det(C)1/2 det(T)1/2 Γ (¯a)¯b−¯a.
Then we have
π(σ2
f |β, θ, y) = lim
α→∞
num2
den2
= lim
α→∞
¯b¯a
Γ (¯a)(σ2
f )¯a+1 exp

−
¯b + 1
2βT T−1β
2σ2
f

=
¯b¯a
Γ (¯a)(σ2
f )¯a+1 exp

−
¯b
2σ2
f

.
Therefore, we have σ2
f |β, θ, y ∼IG

¯a, ¯b

.
(iii) For given β, σ2
f , and y, we have
π(θ|β, σ2
f , y) = lim
α→∞
π(y|β, σ2
f , θ)π(θ)

π(y|β, σ2
f , θ)π(θ)dθ
∝det(C)−1/2 exp

−(y −Fβ)T C−1(y −Fβ)
2σ2
f

π(θ).

60
5
Fully Bayesian Approach
The posterior predictive distribution of z∗:= z(s∗, t∗) at location s∗and time t∗
can be obtained by
π(z∗|y) =

π(z∗|y, β, σ2
f , θ)π(β, σ2
f , θ|y)dβdσ2
f dθ,
(5.5)
where in (5.5), the conditional distribution π(z∗|β, σ2
f , θ, y), is integrated with
respect to the posterior of β, σ2
f , and θ given observations y. The conditional distri-
bution of z∗is Gaussian, i.e.,
z∗|β, σ2
f , θ, y ∼N(μz∗|β,σ2
f ,θ,y, σ2
z∗|β,σ2
f ,θ,y),
with
μz∗|β,σ2
f ,θ,y = E(z∗|β, σ2
f , θ, y) = f (x∗)T β + kT C−1(y −Fβ),
σ2
z∗|β,σ2
f ,θ,y = Var(z∗|β, σ2
f , θ, y) = σ2
f (1 −kT C−1k),
where k := Corr(y, z∗|θ) = [C(x(i), x∗; θ)] ∈Rn. To obtain numerical values of
π(z∗|y), we draw m samples

β(i), σ2
f
(i), θ(i)m
i=1 from the posterior distribution
π(β, σ2
f , θ|y) using the Gibbs sampler presented in Table5.1, and then obtain the
predictive distribution in (5.5) by
π(z∗|y) ≈1
m
m

i=1
π(z∗|y, β(i), σ2
f
(i), θ(i)).
It follows that the predictive mean and variance can be obtained numerically by
μz∗|y = E(z∗|y) ≈1
m
m

i=1
μz∗|β(i),σ2
f
(i),θ(i),y,
σ2
z∗|y = Var(z∗|y) ≈1
m
m

i=1
σ2
z∗|β(i),σ2
f
(i),θ(i),y
+ 1
m
m

i=1

μz∗|β(i),σ2
f
(i),θ(i),y −μz∗|y
2
.
Remark 5.1 The Gibbs sampler presented in Table5.1 may take long time to con-
verge,whichimpliesthatthenumberofsamplesrequiredcouldbequitelargedepend-
ing on the initial values. This convergence rate can be monitored from a trace plot
(a plot of sampled values versus iterations for each variable in the chain). More-
over, since C is a complicated function of σs and σt, sampling from π(θ|β, σ2
f , y) in
Proposition5.1isdifﬁcult.Aninversecumulativedistributionfunction(CDF)method

5.1 Fully Bayesian Prediction Approach
61
[109] needs to be used to generate samples, which requires griding on a continuous
parameter space. Therefore, high computational power is needed to implement the
MCMC-based approach.
In the next subsection, we present an alternative Bayesian approach which only
requires drawing samples from the prior distribution π(θ) using a similar approach
to one used in [85].
5.1.3 Importance Sampling Approach
The posterior predictive distribution of z∗:= z(s∗, t∗) can be written as
π(z∗|y) =

π(z∗|θ, y)π(θ|y)dθ,
(5.6)
where
π(θ|y) =
π(y|θ)π(θ)

π(y|θ)π(θ)dθ ,
is the posterior distribution of θ, by integrating out analytically the parameters β and
σ2
f . We have the following proposition.
Proposition 5.2 For a prior distribution given in (5.3) with the noninformative prior
on β, we have
1. π(θ|y) ∝w(θ|y)π(θ) with
log w(θ|y) = −1
2 log det(C) −1
2 log det(FT C−1F) −˜a log ˜b,
(5.7)
where
˜a = a + n
2,
˜b = b + 1
2yT C−1y −1
2(FT C−1y)T (FT C−1F)−1(FT C−1y).
2. π(z∗|θ, y) is a shifted student’s t-distribution with location parameter μ, scale
parameter λ, and ν degrees of freedom, i.e.,
π(z∗|θ, y) = Γ
 ν+1
2

Γ
 ν
2

 λ
πν
 1
2 
1 + λ(z∗−μ)2
ν
−ν+1
2
,
(5.8)
where ν = 2˜a, and

62
5
Fully Bayesian Approach
μ = kT C−1y + ( f (x∗) −FT C−1k)T (FT C−1F)−1(FT C−1y),
λ =
˜b
˜a

(1 −kT C−1k) + ( f (x∗) −FT C−1k)T (FT C−1F)−1( f (x∗)
−FT C−1k)

.
Proof (i) For given θ, we have
π(y|θ) =

π(y|β, σ2
f , θ)π(β, σ2
f )dβdσ2
f
=

π(y|β, σ2
f , θ)π(β|σ2
f )π(σ2
f )dβdσ2
f
=
ba
Γ (a)(2π)n/2 det(C)1/2 det(T)1/2 det(FT C−1F + T−1)1/2
×
 exp

−b+ RSS
2
σ2
f

(σ2
f )n/2+a+1 dσ2
f
=
Γ ( n+2a
2
)ba
Γ (a)(2π)n/2 det(C)1/2 det(T)1/2 det(FT C−1F + T−1)1/2
×

b + RSS
2
−n+2a
2
where
RSS = yT 
C−1 −C−1F(FT C−1F + T−1)−1FT C−1
y.
As α →∞, we have
π(θ|y) = lim
α→∞
π(y|θ)π(θ)

π(y|θ)π(θ)dθ
∝det(C)−1/2 det(FT C−1F)−1/2

b + 1
2yT y
−n+2a
2
,
where  = C−1 −C−1F(FT C−1F)−1FT C−1.
(ii) For given θ and y, we have
π(z∗|θ, y) =

π(z∗|y, β, σ2
f , θ)π(β, σ2
f |θ, y)dβdσ2
f
=

π(z∗|y, β, σ2
f , θ)π(β|σ2
f , θ, y)π(σ2
f |θ, y)dβdσ2
f ,

5.1 Fully Bayesian Prediction Approach
63
where
z∗|y, β, σ2
f , θ ∼N

f (x∗)T β + kT C−1(y −Fβ), σ2
f (1 −kT C−1k)

,
β|σ2
f , θ, y ∼N( ˆβ, σ2
f  ˆβ),
σ2
f |θ, y ∼IG

a + n
2, b + RSS
2

.
Then, it can be shown that
π(z∗|θ, y) = Γ
 ν+1
2

Γ
 ν
2

 λ
πν
 1
2 
1 + λ(z∗−μ)2
ν
−ν+1
2
,
when α →∞.
The results in Proposition5.2 are different from those obtained in [85] by using
a noninformative prior on β. For a special case where β and σ2
f are known a pri-
ori, we have the following corollary which will be exploited to derive a distributed
implementation among sensor groups in Sect.5.2.2.
Corollary 5.1 In the case where β and σ2
f are known a priori, (5.7) and (5.8) can
be simpliﬁed as
log w(θ|y) = −1
2 log det(C) −1
2(y −Fβ)T C−1(y −Fβ),
z∗|θ, y ∼N

f (x∗)T β + kT C−1(y −Fβ), σ2
f (1 −kT C−1k)

.
If we draw m samples

θ(i)m
i=1 from the prior distribution π(θ), the posterior
predictive distribution in (5.6) can then be approximated by
π(z∗|y) ≈
 w(θ(i)|y)π(z∗|θ(i), y)
 w(θ(i)|y)
.
It follows that the predictive mean and variance can be obtained by
μz∗|y = E(z∗|y) ≈
 w(θ(i)|y)μz∗|θ(i),y
 w(θ(i)|y)
,
σ2
z∗|y = Var(z∗|y) ≈
 w(θ(i)|y)σ2
z∗|θ(i),y
 w(θ(i)|y)
+
 w(θ(i)|y)

μz∗|θ(i),y −μz∗|y
2
 w(θ(i)|y)
,

64
5
Fully Bayesian Approach
where the mean and variance of the student’s t-distribution π(z∗|θ, y) are given by
μz∗|θ,y = E(z∗|θ, y) = μ,
σ2
z∗|θ,y = Var(z∗|θ, y) =
˜a
˜a −1λ.
5.1.4 Discrete Prior Distribution
To further reduce the computational demands from the Monte Carlo approach, we
assign discrete uniform probability distributions to σs and σt as priors instead of
continuous probability distributions. Assume that we know the range of parameters
in θ, i.e.,
σs ∈

σs, σs

and σt ∈

σt, σt

,
where σ and σ denote the known lower-bound and upper-bound of the random
variable σ, respectively. We constrain the possible choices of θ on a ﬁnite set of grid
points denoted by . (Note here  is deﬁned as a ﬁnite set of discrete points, not to
be confused with the continuous space deﬁnition used in previous chapters.) Hence,
π(θ) is now a probability mass function (i.e., 
θ∈ π(θ) = 1) as opposed to a
probability density. The integration in (5.6) is reduced to the following summation
π(z∗|y) =

θ∈
π(z∗|θ, y)π(θ|y),
(5.9)
where the posterior distribution of θ is evaluated on the grid points in θ by
π(θ|y) =
w(θ|y)π(θ)

θ∈θ w(θ|y)π(θ).
(5.10)
In order to obtain the posterior predictive distribution in (5.9), the computation of
π(z∗|θ, y) and w(θ|y) for all θ ∈ using the results from Proposition5.2 (or
Corollary5.1 for a special case) are necessary. Note that these quantities are available
in closed-form which reduces the computational burden signiﬁcantly.
5.2 Sequential Bayesian Prediction
Although the aforementioned efforts in Sects.5.1.3 and 5.1.4 reduce the compu-
tational cost signiﬁcantly, the number of observations (that mobile sensing agents
collect) n increases with the time t. For each θ ∈, an n × n positive deﬁnite
matrix C needs to be inverted which requires time O(n3) using standard methods.

5.2 Sequential Bayesian Prediction
65
This motivates us to design scalable sequential Bayesian prediction algorithms by
using subsets of observations.
5.2.1 Scalable Bayesian Prediction Algorithm
The computation of π(z∗|y1:t) soon becomes infeasible as t increases. To overcome
this drawback while maintaining the Bayesian framework, we propose to use subsets
of all observations y1:t ∈Rn. However, instead of using truncated local observations
only as in [2], Bayesian inference will be drawn based on two sets of observations:
• First, a set of local observations near target points ˜y which will improve the quality
of the prediction, and
• second, a cumulative set of observations ¯y which will minimize the uncertainty in
the estimated parameters.
Taken together, they improve the quality of prediction as the number of observations
increases. We formulate this idea in detail in the following paragraph. For notational
simplicity, we deﬁne y ∈Rn as a subset of all observations y1:t which will be used for
Bayesian prediction. We partition y into two subsets, namely ¯y and ˜y. Let ¯F and ˜F be
the counterparts of F deﬁned in (5.2) for ¯y and ˜y, respectively. The following lemma
provides the conditions under which any required function of y in Proposition5.2
can be decoupled.
Lemma 5.1 For a given θ ∈θ, let C = Corr(y, y|θ), ¯C = Corr(¯y, ¯y|θ), ˜C =
Corr(˜y, ˜y|θ), k = Corr(y, z∗|θ), ¯k = Corr(¯y, z∗|θ), and ˜k = Corr(˜y, z∗|θ). If the
following conditions are satisﬁed
C1: Corr(˜y, ¯y|θ) = 0, i.e., ˜y and ¯y are uncorrelated, and
C2: Corr(¯y, z∗|θ) = 0, i.e., ¯y and z∗are uncorrelated,
then we have the following results:
FT C−1F = ¯F
T ¯C
−1 ¯F + ˜F
T ˜C
−1 ˜F ∈Rp×p,
FT C−1y = ¯F
T ¯C
−1 ¯y + ˜F
T ˜C
−1 ˜y ∈Rp,
yT C−1y = ¯yT ¯C
−1 ¯y + ˜yT ˜C
−1 ˜y ∈R,
log det C = log det ¯C + log det ˜C ∈R,
FT C−1k = ˜F
T ˜C
−1 ˜k ∈Rp,
kT C−1k = ˜k
T ˜C
−1 ˜k ∈R.
Proof The results follow by noting the correlation matrix C can be decoupled such
that C = diag( ¯C, ˜C) and ¯k = 0.

66
5
Fully Bayesian Approach
Remark 5.2 In order to compute the posterior predictive distribution π(z∗|y) (or the
predictive mean and variance) in (5.9), π(z∗|θ, y) and π(θ|y) for all θ ∈ need to be
calculated. Notice that the posterior distribution of θ can be obtained by computing
w(θ|y) in (5.7). Suppose ¯F
T ¯C
−1 ¯F ∈Rp×p, ¯F
T ¯C
−1 ¯y ∈Rp, ¯yT ¯C
−1 ¯y ∈R, and
log det ¯C ∈R are known for all θ ∈. If ˜F
T ˜C
−1 ˜F ∈Rp×p, ˜F
T ˜C
−1 ˜y ∈Rp,
˜yT ˜C
−1 ˜y ∈R, and log det ˜C ∈R for all θ ∈ have ﬁxed computation times,
then (5.7) and (5.8) can be computed in constant time due to decoupling results of
Lemma5.1.
The following theorem provides a way to design scalable sequential Bayesian
prediction algorithms.
Theorem 5.1 Consider the discrete prior probability π(θ) and the compactly sup-
ported kernel function φt(·). If we select η ≥⌊σt⌋∈Z>0, Δ ∈Z>0 and deﬁne
ct := max
 t −Δ
Δ + η

, 0

∈R,
ξ j := y( j−1)(Δ+η)+1:( j−1)(Δ+η)+Δ ∈RΔN,
¯y := (ξT
1 , . . . , ξT
ct )T ∈RΔNct ,
˜y := yt−Δ+1:t ∈RΔN,
(5.11)
where ⌊·⌋is the ﬂoor function deﬁned by ⌊x⌋:= max {m ∈Z | m ≤x}, then the
posterior predictive distribution in (5.9) can be computed in constant time (i.e., does
not grow with the time t).
Proof Byconstruction,conditionsC1–2 inLemma5.1aresatisﬁed.Hence,itfollows
fromRemark5.2thattheposteriorpredictivedistributioncanbecomputedinconstant
time.
Remark 5.3 In Theorem5.1, η ≥⌊σt⌋guarantees the time distance between ξ j and
ξ j+1 is large enough such that the conditions in Lemma5.1 are satisﬁed. Notice that
Δ is a tuning parameter for users to control the trade-off between the prediction
quality and the computation efﬁciency. A large value for Δ yields a small predictive
variance but long computation time, and vice versa. An illustrative example with
three agents sampling the spatiotemporal Gaussian process in 1-D space is shown in
Fig.5.1.
Based on Theorem5.1, we provide the centralized sequential Bayesian prediction
algorithm as shown in Table5.2.
5.2.2 Distributed Implementation for a Special Case
In this subsection, we will show a distributed way (among agent groups) to implement
the proposed algorithm for a special case in which β and σ2
f are assumed to be known

5.2 Sequential Bayesian Prediction
67
10
(s∗, t∗)
t = 15
σt
1
2
· · ·
· · ·
time
space
13
Fig. 5.1 Example with three agents sampling the spatiotemporal Gaussian process in 1-D space
and performing Bayesian inference. In this example, σt = 2.5, η = 2, Δ = 3, t = 15, ct = 2,
¯y = (yT
1:3, yT
6:8)T and ˜y = y13:15
a priori. The assumption for this special case is the exact opposite of the one made
in [46] where β and σ2
f are unknown and θ is known a priori.
To develop a distributed scheme among agent groups for data fusion in Bayesian
statistics, we exploit the compactly supported kernel for space. Let Cs(h) in (5.1) also
be a compactly supported kernel function as Ct(h) so that the correlation vanishes
whenthespatialdistancebetweentwoinputsislargerthanσs,i.e.,Cs(h) = 0, ∀h >1.
Consider a case in which M groups of spatially distributed agents sample a spa-
tiotemporal Gaussian process over a large region Q. Each group is in charge of its
sub-region of Q. The identity of each group is indexed by V := {1, . . . , M}. Each
agent in group i is indexed by I[i] := {1, . . . , N}. The leader of group i is referred
to as leader i, which implements the centralized scheme to make prediction on its
sub-region using local observations and the globally updated posterior distribution
of θ. Therefore, the posterior distribution of θ shall be updated correctly using all
observations from all groups (or agents) in a distributed fashion.
Let G(t) := (V, E(t)) be an undirected communication graph such that an edge
(i, j) ∈E(t) if and only if leader i can communicate with leader j at time t. We deﬁne
the neighborhood of leader i at time t by Ni(t) := { j ∈V | (i, j) ∈E(t), j ̸= i}. Let
a[i] denote the quantity as a in the centralized scheme for group i. We then have the
following theorem.
Theorem 5.2 Assume that ¯y[i] and ˜y[i] for leader i are selected accordingly to
Theorem5.1 in time-wise. Let ˜y deﬁned by ˜y := ((˜y[1])T , . . . , (˜y[M])T )T . If the
following condition is satisﬁed
C3: ∥q[i]
ℓ(t) −q[ j]
ν (t′)∥≥σs, ∀i ̸= j, ∀ℓ∈I[i], ∀ν ∈I[ j],
in the spatial domain, then the weights w(θ|y), based on all observations from all
agents, can be obtained from
log w(θ|y) = log w(θ|¯y) +
M

i=1
log w(θ|˜y[i]).
(5.12)

68
5
Fully Bayesian Approach
Table 5.2 Centralized Bayesian prediction algorithm
Input:
(1) prior distribution on σ2
f, i.e., π(σ2
f) = IG(a, b)
(2) prior distribution on θ ∈Θ, i.e., π(θ)
(3) tuning variables Δ and η
(4) number of agents N
(5) M(θ).A = 0 ∈Rp×p, M(θ).B = 0 ∈R, M(θ).c = 0 ∈Rp, M(θ).D = 0 ∈R,
M0(θ) = M(θ), ∀θ ∈Θ
Output:
(1) The predictive mean at location s∗∈S and time t∗= t, i.e., μz∗|y
(2) The predictive variance at location s∗∈S and time t∗= t, i.e., σ2
z∗|y
At time t, the central station does:
1: receive observations yt from agents, set ˜y = yt−Δ+1:t and n = NΔ
2: compute ˜F = (f(˜x(1)), · · · , f(˜x(n)))T where ˜x(i) is the input of the i-th element
in ˜y
3: for each θ ∈θ do
4:
compute ˜C = Cor(˜y, ˜y) ∈Rn×n
5:
compute the key values
FT C−1F = M(θ).A + ˜F
T ˜C
−1˜F ∈Rp×p, yT C−1y = M(θ).B + ˜yT ˜C
−1˜y ∈R,
FT C−1y = M(θ).c + ˜F
T ˜C
−1˜y ∈Rp, log det C = M(θ).D + log det ˜C ∈R
6:
compute ˜a = a + n
2 and
˜b = b + 1
2yT C−1y −1
2(FT C−1y)T (FT C−1F)−1(FT C−1y)
7:
update weights via
log w(θ|y) = −1
2 log det C −1
2 log det(FT C−1F) −˜a log ˜b
8:
for each s∗∈S do
9:
compute f(x∗) ∈Rp, ˜k = Corr(˜y, z∗) ∈Rn
10:
compute predictive mean and variance for given θ
μz∗|θ,y = ˜k˜C
−1˜y + (f(x∗) −˜F
T ˜C
−1˜k)T (FT C−1F)−1(FT C−1y),
σ2
z∗|θ,y =
˜b
˜a−1

(1 −˜k
T ˜C
−1˜k) + (f(x∗) −˜F
T ˜C
−1˜k)T (FT C−1F)−1(f(x∗) −˜F
T ˜C
−1˜k)

11:
end for
12:
if mod(t, Δ + η) = Δ then
13:
set M(θ) = M0(θ), then M0(θ).A = FT C−1F, M0(θ).B = yT C−1y,
M0(θ).c = FT C−1y, and M0(θ).D = log det C
14:
end if
15: end for
16: compute the posterior distribution
π(θ|y) =
w(θ|y)π(θ)

θ w(θ|y)π(θ)
17: compute the predictive mean and variance
μz∗|y = 
θ μz∗|θ,yπ(θ|y),
σ2
z∗|y = 
θ σ2
z∗|θ,yπ(θ|y) + 
θ μz∗|θ,y −μz∗|y
2 π(θ|y).

5.2 Sequential Bayesian Prediction
69
σs
σs
σs
Fig. 5.2 Example with three group of agents sampling the spatiotemporal Gaussian process in 2-D
space and performing Bayesian prediction. The symbol ‘o’ denotes the position of a leader for a
group and the symbol ‘x’ denotes the position of an agent. Distance between any two sub-regions
is enforced to be greater than σs which enables the distributed Bayesian prediction
Proof The result follows by noting Corr(˜y[i], ˜y[ j]|θ) = 0, ∀i ̸= j, when the condi-
tion C3 is satisﬁed.
An exemplary conﬁguration of agents which satisﬁes C3 is shown in Fig.5.2.
Suppose that the communication graph G(t) is connected for all time t. Then
the average 1
M
M
i=1 log w(θ|˜y[i]) can be achieved asymptotically via discrete-time
average-consensus algorithm [110]:
log w(θ|˜y[i]) ←log w(θ|˜y[i]) + ϵ

j∈Ni

log w(θ|˜y[ j]) −log w(θ|˜y[i])

,
with 0 < ϵ < 1/Δ(G) that depends on the maximum node degree of the network
Δ(G) = maxi |Ni|.
5.2.3 Adaptive Sampling
At time t, the goal of the navigation of agents is to improve the quality of prediction of
the ﬁeld Q at the next sampling time t + 1. Therefore, mobile agents should move to
the most informative sampling locations q(t +1) = (q1(t +1)T , . . . , qN(t +1)T )T
at time t + 1 in order to reduce the prediction error [44].
Suppose at time t +1, agents move to a new set of positions ˜q = (˜qT
1 , . . . , ˜qT
N)T .
The mean squared prediction error is deﬁned as
J(˜q) =

s∈S
E

(z(s, t + 1) −ˆz(s, t + 1))2
ds,
(5.13)

70
5
Fully Bayesian Approach
where ˆz(s, t + 1) is obtained as in (5.9). Due to the fact that θ has a distribution, the
evaluation of (5.13) becomes computationally prohibitive. To simplify the optimiza-
tion, we propose to utilize a maximum a posteriori (MAP) estimate of θ at time t,
denoted by ˆθt, i.e.,
ˆθt = arg max
θ∈θ π(θ|y),
where y is the subset of all observations used up to time t. The next sampling positions
can be obtained by solving the following optimization problem
q(t + 1) = arg min
˜qi⊂Q

s∈S
Var(z(s, t + 1)|y, ˆθt)ds.
(5.14)
This problem can be solved using standard constrained nonlinear optimization tech-
niques (e.g., the conjugate gradient algorithm), possibly taking into account mobility
constraints of mobile sensors.
Remark 5.4 The proposed control algorithm in (5.14) is truly adaptive in the sense
that the new sampling positions are functions of all collected observations. On the
other hand, if all parameters are known, the optimization in (5.14) can be performed
ofﬂine without taking any measurements.
5.3 Simulation
In this section, we apply the proposed sequential Bayesian prediction algorithms
to spatiotemporal Gaussian processes with a correlation function in Sect.5.1. The
Gaussian process was numerically generated through circulant embedding of the
covariance matrix for the simulation study [107]. This technique allows us to numer-
ically generate a large number of realizations of the Gaussian process.
5.3.1 MCMC-Based Approach on a 1-D Scenario
We consider a scenario in which N = 5 agents sample the spatiotemporal Gaussian
process in 1-D space and the central station performs Bayesian prediction. The sur-
veillance region Q is given by Q = [0, 10]. We consider the squared exponential
function
Cs(h) = exp

−1
2h2

,
for space correlation and a compactly supported correlation function [111] for time
as

5.3 Simulation
71
5
0
5
0
200
400
0
2
4
6
0
200
400
600
1.6 1.8
2
2.2
0
50
100
150
4
6
8
10
12
0
50
100
150
β
σ2
f
σs
σt
2
0
2
0
200
400
0
1
2
3
0
100
200
300
1.6 1.8
2
2.2
0
100
200
300
4
6
8
10
12
0
200
400
β
σ2
f
σs
σt
(a)
(b)
Fig. 5.3 Posterior distribution of β, σ2
f , σs, and σt at a t = 1, and b t = 20
Ct(h) =
 (1−h) sin(2πh)
2πh
+ 1−cos(2πh)
π×2πh
, 0 ≤h ≤1,
0,
otherwise,
(5.15)
The signal-to-noise ratio γ is set to be 26dB which corresponds to σw = 0.158.
The true values for the parameters used in simulating the Gaussian process are given
by (β, σ2
f , σs, σt) = (0, 1, 2, 8). Notice that the mean function is assumed to be an
unknown random variable, i.e., the dimension of the regression coefﬁcient β is 1.
We assume that β|σ2
f has the noninformative prior and σ2
f ∼IG(3, 20). The Gibbs
sampler in Table5.1 was used to generate samples from the posterior distribution
of the parameters. A random sampling strategy was used in which agents make
observations at random locations at each time t ∈Z>0. The prediction was evaluated
at each time step for 51 uniform grid points within Q.
The histograms of the samples at time t = 1 and t = 10 are shown in Fig.5.3a and
Fig.5.3b, respectively. It is clear that the distributions of the parameters are centered
around the true values with 100 observations at time t = 20. The prediction results
at time t = 1 and t = 20 are shown in Fig.5.4a and Fig.5.4b, respectively. However,
with only 100 observations, the running time using the full Bayesian approach is
about several minutes which will soon become intractable.
5.3.2 Centralized Scheme on 1-D Scenario
We consider the same scenario in which N = 5 agents sample the spatiotemporal
Gaussian process in 1-D space and the central station performs Bayesian prediction.
The true values for the parameters used in simulating the Gaussian process are given
by (β, σ2
f , σs, σt) = (20, 10, 2, 8). Notice that the mean function is assumed to
be an unknown random variable, i.e., the dimension of the regression coefﬁcient
β is 1. We assume that β|σ2
f has the noninformative prior and σ2
f ∼IG(3, 20).

72
5
Fully Bayesian Approach
0
2
4
6
8
10
-2
-1
0
1
2
s
0
2
4
6
8
10
s
-1
0
1
2
(a)
(b)
Fig. 5.4 Prediction at a t = 1, and b t = 20 using the MCMC-based approach. The true ﬁelds
are plotted in blue solid lines. The predicted ﬁelds are plotted in red dash-dotted lines. The area
between red dotted lines indicates the 95 % conﬁdence interval
We also assume the bounds of θ, viz. σs ∈[1.6, 2.4] and σt ∈[4, 12] are known.
Δ = 12 is used and η = 11 is selected satisfying the condition in Theorem5.1. We
use a discrete uniform probability distribution for π(θ) as shown in Fig.5.6a. The
adaptive sampling strategy was used in which agents make observations at each time
t ∈Z>0. The prediction was evaluated at each time step for 51 uniform grid points
within Q.
Figure5.5 shows the comparison between predictions at time t = 1 using
(a) the maximum likelihood (ML) based approach, and (b) the proposed fully
Bayesian approach. The ML based approach ﬁrst generates a point estimate of the
hyperparameters and then uses them as true ones for computing the prediction and
the prediction error variance. In this simulation, a poor point estimate on θ was
achieved by maximizing the likelihood function. As a result, the prediction and the
associated prediction error variance are incorrect and are far from being accurate
for a small number of observations. On the other hand, the fully Bayesian approach
which incorporates the prior knowledge of θ and uncertainties in θ provides a more
accurate prediction and an exact conﬁdence interval.
Using the proposed sequential Bayesian prediction algorithm along with the adap-
tive sampling strategy, the prior distribution was updated in a sequential manner. At
time t = 100, the posterior distribution of θ is shown in Fig.5.6b. With a larger num-
ber of observations, the support for the posterior distribution of θ becomes smaller
and the peak gets closer to the true value. As shown in Fig.5.7a, the quality of the
prediction at time t = 100 is signiﬁcantly improved. At time t = 300, the prior dis-
tribution was further updated which is shown in Fig.5.6c. At this time, θ = (2, 8)T ,
which is the true value, has the highest probability. The prediction is also shown in
Fig.5.7b. This demonstrates the usefulness and correctness of our algorithm. The
running time at each time step is ﬁxed, which is around 12s using Matlab, R2008a
(MathWorks) in a PC (2.4GHz Dual-Core Processor).

5.3 Simulation
73
0
2
4
6
8
10
14
16
18
20
22
24
26
28
s
0
2
4
6
8
10
14
16
18
20
22
24
26
28
s
(a)
(b)
Fig. 5.5 Prediction at t = 1 using (a) the maximum likelihood based approach, and (b) the
proposed fully Bayesian approach. The true ﬁelds are plotted in blue solid lines. The predicted
ﬁelds are plotted in red dash-dotted lines. The area between red dotted lines indicates the 95 %
conﬁdence interval
1.6 1.8 2 2.2 2.4
4
6
8
10
12
0
0.005
0.01
0.015
σs
σt
1.6 1.8 2 2.2 2.4
4
6
8
10
12
0
0.05
0.1
0.15
0.2
σs
σt
1.6 1.8 2 2.22.4
4
6
8
10
12
0
0.2
0.4
0.6
0.8
σs
σt
(a)
(b)
(c)
Fig. 5.6 a Prior distribution θ, b posterior distribution of θ at time t = 100, c posterior distribution
of θ at time t = 300
0
2
4
6
8
10
16
17
18
19
20
21
22
23
24
s
0
2
4
6
8
10
16
17
18
19
20
21
22
23
24
s
(a)
(b)
Fig. 5.7 Prediction at a t = 100, and b t = 300 using the centralized sequential Bayesian approach.
The true ﬁelds are plotted in blue solid lines. The predicted ﬁelds are plotted in red dash-dotted
lines. The area between red dotted lines indicates the 95 % conﬁdence interval

74
5
Fully Bayesian Approach
1.6
1.8
2
2.2
2.4
4
6
8
10
12
0
0.1
0.2
0.3
0.4
σs
σt
Fig. 5.8 Posterior distribution of θ at time t = 100 using the distributed algorithm
(a)
(b)
Fig. 5.9 Comparison of (a) the true ﬁeld at t = 100 and (b) the predicted ﬁeld at t = 100 using
the distributed algorithm
5.3.3 Distributed Scheme on 2-D Scenario
Finally, we consider a scenario in which there are 4 groups, each of which contain 10
agents sampling the spatiotemporal Gaussian process in 2-D space. The surveillance
region Q is given by Q = [0, 10]×[0, 10]. The parameter values used in simulating
the Gaussian process are given by θ = (σs, σt)T = (2, 8)T , β = 0, and σ2
f = 1,
last two values of which are assumed to be known a priori. To use the distributed
scheme, we only consider compactly supported kernel functions for both space and
time. In particular, we consider Cs(h) = Ct(h) as in (5.15). We also assume the fact
that σs ∈[1.6, 2.4] and σt ∈[4, 12] are known a priori. Δ = 12 is used and η = 11
is selected satisfying the condition in Theorem5.1. The region Q is divided into 4
square sub-regions with equal size areas as shown in Fig.5.9a. Distance between any
two sub-regions is enforced to be greater than ¯σs = 2.4, satisfying the condition in

5.3 Simulation
75
Theorem5.2, which enables the distributed Bayesian prediction. The same uniform
prior distribution for θ as in the centralized version (see Fig.5.6a) is used.
The globally updated posterior distribution of θ at time t100 is shown in Fig.5.8. It
has a peak near the true θ, which shows the correctness of the distributed algorithm.
The predicted ﬁeld compared with the true ﬁeld at time t100 is shown in Fig.5.9. Due
to the construction of sub-regions, the interface areas between any of two sub-regions
are not predicted. Notice that the prediction is not as good as in the 1-D scenario due
to the effect of curse of dimensionality when we move from 1-D to 2-D spaces. The
prediction quality can be improved by using more number of sensors at the cost of
computational time. The running time of the distributed algorithm in this scenario
is about several minutes due to the complexity of the 2-D problem under the same
computational environment as the one used for the 1-D scenario. However, thanks
to our proposed sequential sampling schemes, the running time does not grow with
the number of measurements.

Chapter 6
New Efﬁcient Spatial Model with Built-In
Gaussian Markov Random Fields
Recently, there have been efforts to ﬁnd a way to ﬁt a computationally efﬁcient
Gaussian Markov Random Field (GMRF) on a discrete lattice to a Gaussian random
ﬁeldonacontinuumspace[86–88]. Suchmethods havebeendevelopedusingaﬁtting
with a weighted L2-type distance [86], using a conditional-mean least-squares ﬁtting
[87], and for dealing with large data by fast Kriging [88]. It has been demonstrated
that GMRFs with small neighborhoods can approximate Gaussian ﬁelds surprisingly
well [86]. This approximated GMRF and its regression are very attractive for the
resource-constrained mobile sensor networks due to its computational efﬁciency
and scalability [89] as compared to the standard Gaussian process and its regression,
which is not scalable as the number of observations increases.
Mobile sensing agents form an ad hoc wireless communication network in which
each agent usually operates under a short communication range, with limited mem-
ory and computational power. For resource-constrained mobile sensor networks,
developing distributed prediction algorithms for robotic sensors using only local
information from local neighboring agents has been one of the most fundamental
problems [42, 45, 46, 68, 112, 113].
In Sect.6.1.1, a new class of Gaussian processes is proposed for resource-
constrained mobile sensor networks. Such a Gaussian process builds on a GMRF [92]
with respect to a proximity graph, e.g., the Delaunay graph of a set of vertices over a
surveillance region. The formulas for predictive statistics are derived in Sect.6.1.2.
We propose a sequential prediction algorithm which is scalable to deal with sequen-
tially sampled observations in Sect.6.1.3. In Sect.6.2, we develop a distributed and
scalable statistical inference algorithm for a simple sampling scheme by applying
the Jacobi over-relaxation and discrete-time average consensus algorithms. Simula-
tion and experimental study demonstrate the usefulness of the proposed model and
algorithms in Sect.6.3.
© The Author(s) 2016
Y. Xu et al., Bayesian Prediction and Adaptive Sampling Algorithms
for Mobile Sensor Networks, SpringerBriefs in Control,
Automation and Robotics, DOI 10.1007/978-3-319-21921-9_6
77

78
6
New Efﬁcient Spatial Model with Built-In Gaussian Markov Random Fields
6.1 Spatial Prediction
In this section, we ﬁrst propose a new class of Gaussian random ﬁelds with built-in
Gaussian Markov Random Fields (GMRF) [92]. Then we show how to compute the
prediction at any point of interest based on Gaussian process regression, and provide
a sequential ﬁeld prediction algorithm for mobile sensor networks.
6.1.1 Spatial Model Based on GMRF
Let γ := (γ(p1), · · · , γ(pm))T ∼N(0, Q−1) be a zero-mean GMRF [92] with
respect to an undirected graph G = (V, E), where the location of vertex i is denoted
by pi in the surveillance region Q. Such locations of vertices will be referred to
as generating points. The inverse covariance matrix (precision matrix) Q ≻0 has
the property (Q)i j ̸= 0 ⇔{i, j} ∈E. If the graph G has small cardinalities of the
neighbor sets, its precision matrix Q becomes sparse with many zeros in its entries.
This plays a key role in computation efﬁciency of a GMRF which can be greatly
exploited by the resource-constrained mobile sensor network.
The spatial ﬁeld is modeled by a Gaussian process with a built-in GMRF
deﬁned as
z(s) = μ(s) +
m

j=1
λ(s, p j)γ(p j),
(6.1)
where λ(·, ·) is a weighting function. The new class of Gaussian processes is capable
of representing a wide range of nonstationary Gaussian ﬁelds, by selecting
1. different number of generating points m,
2. different locations of generating points

p j | j = 1, · · · , m

over Q,
3. a different structure of the precision matrix Q, and
4. different weighting functions

λ(·, p j) | j = 1, · · · , m

.
Remark 6.1 The number of generating points could be determined by a model selec-
tion criterion such as the Akaike information criterion [114]. Similar to hyperpara-
meter estimation in the standard Gaussian process regression, one can estimate all
other parameters using maximum likelihood (ML) optimization [1, 53]. This is non-
convex optimization and so the initial conditions need to be chosen carefully to avoid
local minima. In our approach, we use basic structures for weighting functions and
the precision matrix; however, we make them as functions of the locations of gen-
erating points. Different spatial resolutions can be obtained by a suitable choice of
locations of generating points. As an example shown in Fig.6.1, higher resolution
can be obtained by higher density of generating points (see lower left corner). In this
way, we only need to determine the locations of generating points. This approach
will be demonstrated with real-world data in Sect.6.3.4.

6.1 Spatial Prediction
79
0
0.2
0.4
0.6
0.8
1
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
(a)
(b)
Fig. 6.1 a Generating points in blue dots and the associated Delaunay graph with edges in red
dotted lines. The Voronoi partition is also shown in blue solid lines. b Gaussian random ﬁeld with
a built-in GMRF with respect to the Delaunay graph in (a)
6.1.2 Gaussian Process Regression
Suppose we have a collection of observations y := (y1, · · · , yn)T whose entries are
sampled at the corresponding points s1, · · · , sn. The noise corrupted measurement
yi ∈R is given by
yi = z(si) + ϵi,
where ϵi
i.i.d.
∼N(0, σ2
w) is an independent and identically distributed (i.i.d.) Gaussian
white noise. We then have the following results.
Proposition 6.1 Let  ∈Rn×m be a matrix obtained by ()i j = λ(si, p j) and
let λ ∈Rm be a vector obtained by (λ)i = λ(s0, pi), where s0 is a point of
interest. Then the covariance matrix of y and the covariance between y and z(s0) are
given by
C := E[(y −Ey)(y −Ey)T ] = Q−1T + σ2
wI,
k := E[(y −Ey)z(s0)] = Q−1λ,
where Q ∈Rm×m is the precision matrix of the GMRF γ ∈Rm.
Proof The (i, j)th element of the covariance matrix C, i.e., the covariance between
yi and y j, can be obtained by

80
6
New Efﬁcient Spatial Model with Built-In Gaussian Markov Random Fields
(C)i j = Cov(z(si), z(s j)) + σ2
wδi j
= E(z(si) −μ(si))(z(s j) −μ(s j)) + σ2
wδi j
= E

k
λ(si, pk)γ(pk)
 
l
λ(s j, pl)γ(pl)

+ σ2
wδi j
= E
⎛
⎝
k,l
λ(si, pk)γ(pk)γ(pl)λ(s j, pl)
⎞
⎠+ σ2
wδi j
=

k,l
λ(si, pk)E(γ(pk)γ(pl))λ(s j, pl) + σ2
wδi j
=

k,l
λ(si, pk)(Q−1)klλ(s j, pl) + σ2
wδi j.
The ith element of the covariance vector k, i.e., the covariance between yi and
z(s0), can be obtained by
(k)i = Cov(z(si), z(s0))
= E(z(si) −μ(si))(z(s0) −μ(s0))
= E

k
λ(si, pk)γ(pk)
 
l
λ(s0, pl)γ(p j)

= E
⎛
⎝
k,l
λ(si, pk)γ(pk)γ(pl)λ(s0, pl)
⎞
⎠
=

k,l
λ(si, pk)E(γ(pk)γ(pl))λ(s0, pl)
=

k,l
λ(si, pk)(Q−1)klλ(s0, pl),
whose matrix form completes the proof.
□
By Proposition 6.1, we can make prediction at the point of interest s0 using
Gaussian process regression [53]. This is summarized by the following theorem.
Theorem 6.1 For given y, the prediction of z0 := z(s0) at any location s0 ∈Q is
given by the conditional distribution
z0|y ∼N

μz0|y, σ2
z0|y

,

6.1 Spatial Prediction
81
where the predictive mean and variance are obtained by
μz0|y = μ(s0) + λT ˆQ
−1 ˆy,
(6.2)
σ2
z0|y = λT ˆQ
−1λ,
with
ˆQ = Q + σ−2
w T  ∈Rm×m,
ˆy = σ−2
w T (y −μ) ∈Rm.
Proof By using the Woodbury matrix identity (see Appendix A.2.1), the prediction
mean can be obtained by
μz0|y = μ(s0) + kT C−1(y −μ)
= μ(s0) + (Q−1λ)T (Q−1T + σ2
wI)−1(y −μ)
= μ(s0) + λT Q−1T (Q−1T + σ2
wI)−1(y −μ)
= μ(s0) + λT Q−1T (σ−2
w I−
σ−2
w (Q + σ−2
w T )−1T σ−2
w )(y −μ)
= μ(s0) + λT (σ−2
w Q−1−
σ−4
w Q−1T (Q + σ−2
w T )−1)T (y −μ)
= μ(s0) + λT T (y −μ),
where
 = σ−2
w Q−1 −σ−4
w Q−1T (Q + σ−2
w T )−1
= σ−2
w Q−1(Q + σ−2
w T )(Q + σ−2
w T )−1
−σ−4
w Q−1T (Q + σ−2
w T )−1
= (σ−2
w I + σ−4
w Q−1T )(Q + σ−2
w T )−1
−σ−4
w Q−1T (Q + σ−2
w T )−1
= σ−2
w (Q + σ−2
w T )−1.
Similarly, the prediction error variance can be obtained by
σ2
z0|y = λT Q−1λ −kT C−1k
= λT Q−1λ −(Q−1λ)T (Q−1T + σ2
wI)−1(Q−1λ)
= λT 
Q−1 −Q−1T (Q−1T + σ2
wI)−1Q−1
λ
= λT (Q + σ−2
w T )−1λ,

82
6
New Efﬁcient Spatial Model with Built-In Gaussian Markov Random Fields
where Cov(z(s0), z(s0)) = λT Q−1λ is obtained similarly as in Proposition 6.1. □
Remark 6.2 When the generating points

p1, p2, · · · , pm

are not known a priori,
they can be estimated by maximizing the likelihood function. Given n observations
y = (y1, y2, · · · , yn)T sampled at {s1, s2, · · · , sn}, the log likelihood of y is given
by
log π(y) = −1
2(y −μ)T C−1(y −μ) −1
2 log det C −n
2 log 2π,
where C = Q−1T + σ2
wI is the covariance matrix of y. the maximum likeli-
hood estimate of the generating points can be obtained via solving the following
optimization problem.
ˆpML = arg max
p log π(y).
(6.3)
Remark 6.3 Note that the number of generating points m is ﬁxed and the num-
ber of observations n may grow in time, and so in general we consider m ≪n.
Theorem 6.1 shows that only the inversion of an m × m matrix ˆQ = Q + σ−2
w T 
is required in order to compute the predictive distribution of the ﬁeld at any point.
The computational complexity grows linearly with the number of observations, i.e.,
O(nm2), compare to the standard Gaussian process regression which requires O(n3).
Moreover, it enables a scalable prediction algorithm for sequential measurements.
In what follows, we present a sequential ﬁeld prediction algorithm for sequential
observations by exploiting the results of Theorem 6.1.
6.1.3 Sequential Prediction Algorithm
Consider a sensor network consisting of N mobile sensing agents distributed in
the surveillance region Q. The index of the robotic sensors is denoted by I :=
{1, · · · , N}. The sensing agents sample the environmental ﬁeld at time t ∈Z>0 and
send the observations to a central station which is in charge of the data fusion.
At time t, agent i makes an observation yi(t) at location si(t). Denote the collec-
tion of observations at time t by yt := (y1(t), · · · , yN(t))T . We have the following
proposition.
Proposition 6.2 At time t ∈Z>0, the predictive mean and variance at any point of
interest can be obtained via (6.2) with
ˆQt = ˆQt−1 + σ−2
w T
t t,
ˆQ0 = Q
ˆyt = ˆyt−1 + σ−2
w T
t (yt −μt),
ˆy0 = 0,
where (t)i j = λ(si(t), s j(t)), and (μt)i = μ(si(t)).

6.1 Spatial Prediction
83
Table 6.1 Sequential algorithm for ﬁeld prediction
Input:
a set of target points S
Output:
(1) prediction mean {ˆz(s0) | s0 ∈S}
(2) prediction error variance {σ2(s0) | s0 ∈S}
Assumption:
(1) the central station knows p, Q, and λ(·, ·)
(2) the central station initially has ˆQ ←Q, ˆy ←0
At time t, agent i ∈I in the network does:
1: take measurement yi from its current location si
2: send the measurement (si, yi) to the central station
At time t, the central station does:
1: obtain measurements {(sℓ, yℓ) | ∀ℓ∈I} from mobile sensors
2: compute Λ via (Λ)ij = λ(si, pj)
3: update ˆQ ←ˆQ + σ−2
w ΛT Λ
4: update ˆy ←ˆy + σ−2
w ΛT (y −μ), where (μ)i = μ(si)
5: for s0 ∈S do
6:
compute (λ)i via λ(s0, pi)
7:
compute ˆz(s0) = μ(s0) + λT ˆQ
−1ˆy
8:
compute σ2(s0) = λT ˆQ
−1λ
9: end for
Proof The result can be obtained easily by noting that AT A = AT
1 A1 + AT
2 A2,
where A = (AT
1 , AT
2 )T .
□
Based on Proposition 6.2, we present a sequential ﬁeld prediction algorithm using
mobile sensor networks in Table6.1.
6.2 Distributed Spatial Prediction
In this section, we propose a distributed approach, in which robotic sensors exchange
only local information between neighbors, to implement the ﬁeld prediction effec-
tively fusing all observations collected by all sensors correctly. This distributed
approach can be implemented for a class of weighting functions λ(·, ·) in (6.1) that
have compact supports. In particular, we consider the weighting function deﬁned by
λ(s, p j) = λ(
s −p j
 /r),
(6.4)
where
λ(h) :=

(1 −h) cos(πh) + 1
π sin(πh), h ≤1,
0,
otherwise.

84
6
New Efﬁcient Spatial Model with Built-In Gaussian Markov Random Fields
Notice that the weighting function λ(·, ·) in (6.4) has a compact support, i.e., λ(s, p j)
is nonzero if and only if the distance
s −p j
 is less than the support r ∈R>0.
6.2.1 Distributed Computation
We ﬁrst brieﬂy introduce distributed algorithms for solving linear systems and com-
puting the averages. They will be used as major tools for distributed implementation
of ﬁeld prediction.
• Jacobi over-relaxation method: The Jacobi over-relaxation (JOR) [112] method
provides an iterative solution of a linear system Ax = b, where A ∈Rn×n is a
nonsingular matrix and x, b ∈Rn. If agent i knows the rowi(A) ∈Rn and bi, and
ai j = (A)i j = 0 if agent i and agent j are not neighbors, then the recursion is
given by
x(k+1)
i
= (1 −h)x(k)
i
+ h
aii
⎛
⎝bi −

j∈Ni
ai j x(k)
j
⎞
⎠.
(6.5)
This JOR algorithm converges to the solution of Ax = b from any initial condition
if h < 2/n [45]. At the end of the algorithm, agent i knows the ith element of
x = A−1b.
• Discrete-time average consensus: The Discrete-time average consensus (DAC)
provides a way to compute the arithmetic mean of elements in the a vector c ∈Rn.
Assume the graph is connected. If agent i knows the ith element of c, the network
can compute the arithmetic mean via the following recursion [113]
x(k+1)
i
= x(k)
i
+ ϵ

j∈Ni
ai j(x(k)
j
−x(k)
i
),
(6.6)
with initial condition x(0) = c, where ai j = 1 if j ∈Ni and 0 otherwise,
0 < ϵ < 1/Δ, and Δ = maxi(
j̸=i ai j) is the maximum degree of the network.
After the algorithm converges, all node in the network know the average of c, i.e.,
n
i=1 ci/n.
6.2.2 Distributed Prediction Algorithm
Consider a GMRF with respect to a proximity graph G = (V, E) that generates a
Gaussian random ﬁeld in (6.1). The index of the generating points is denoted by
V := {1, · · · , n}. The location of the ith generating point is pi. The edges of the
graph are considered to be E :=
{i, j} |
pi −p j
 ≤R

, where R is a constant
that ensures the graph is connected.

6.2 Distributed Spatial Prediction
85
Consider a mobile sensor network consisting of N mobile sensing agents dis-
tributed in the surveillance region Q. For simplicity, we assume that the number of
agents is equal to the number of generating points, i.e., N = m. The index of the
robotic sensors is denoted by I := {1, · · · , m}. The location of agent i is denoted
by si.
The assumptions made for the resource-constrained mobile sensor networks are
listed as follows.
A.1 Agent i is in charge of sampling at point si within a r-disk centered at pi, i.e.,
∥si −pi∥< r.
A.2 r is the radius of the support of the weighting function in (6.4) and also satisﬁes
that 0 < r < R
2 .
A.3 Agenti canonlylocallycommunicatewithneighborsin Ni := { j ∈I | {i, j} ∈E}
deﬁned by the connected proximity graph G = (V, E).
A.4 Agent i knows rowi(Q), i.e., the ith row of Q, where (Q)i j ̸= 0 if and only if
j ∈{i} ∪Ni.
Remark 6.4 As in A.1, it is reasonable to have at least one agent collect measure-
ments that are correlated with a random variable from a single generating point. This
sampling rule may be modiﬁed such that a single agent dynamically samples for
multiple generating points or more number of agents samples for a generating point
depending on available resources. Since there is at least one agent in charge of a
generating point by A.1, it is natural to have A.3 and A.4 taking advantage of the
proximity graph for the GMRF. Notice that each agent only knows local information
of Q as described in A.4.
An illustration of agent ℓsampling a measurement at point sℓin the intersection
of the supports of the weighting functions of pi and p j is shown in Fig.6.2.
From A.1 and A.2, since R > 2r, we have λ(sℓ, pi) = 0 if ℓ/∈Ni. Thus the
matrix ˆQ = Q + σ−2
w T  ∈Rm×m and the vector ˆy = σ−2
w T (y −μ) ∈Rm can
be obtained in the following form.
Fig. 6.2 Example of
computing (T )i j =
λ(sℓ, pi)λ(sℓ, p j)
pi
pj
pk
r
sℓ

86
6
New Efﬁcient Spatial Model with Built-In Gaussian Markov Random Fields
( ˆQ)i j = (Q)i j + σ−2
w

ℓ∈{{i}∪Ni}∩{{ j}∪N j}
λ(sℓ, pi)λ(sℓ, p j),
(ˆy)i
= σ−2
w

ℓ∈{i}∪Ni
λ(sℓ, pi)(yℓ−μℓ).
(6.7)
Noticethat ˆQhasthesamesparsityasQ.From (6.7),A.3andA.4,agenti cancompute
rowi( ˆQ) and (ˆy)i by using only local information from neighbors. Using rowi( ˆQ) and
(λ)i, agent i can obtain the ith element in the vector ˆQ
−1λ = (Q + σ−2
w T )−1λ
via JOR by using only local information. Finally, using (ˆy)i and (λ)i the prediction
meanandvariancecanbeobtainedviathediscrete-timeaverageconsensusalgorithm.
Notice that the sequential update of ˆQ and ˆy for sequential observations proposed in
Sect.6.1.3 can be also applied to the distributed algorithm. The distributed algorithm
for sequential ﬁeld prediction under assumptions A.1–4 is summarized in Table6.2.
Table 6.2 Distributed algorithm for sequential ﬁeld prediction
Input:
(1) a set of target points S
(2) the topology of sensor network G = (I, E) in which E :=

{i, j} |
pi −pj
 ≤R

Output:
(1) prediction mean

μz0|y | s0 ∈S

(2) prediction error variance

σ2
z0|y | s0 ∈S

Assumption:
(A1) agent i ∈I is in charge of sampling at point si within a r-disk centered at pi,
i.e., ∥si −pi∥< r
(A2) the radius of the support of the weighting function satisﬁes 0 < r < R
2
(A3)
agent
i
∈
I
can
only
locally
communicate
with
neighbors
Ni
:=
{j ∈I | {i, j} ∈E} deﬁned by the connected graph G = (V, E)
(A4) agent i ∈I initially has rowi(ˆQ) ←rowi(Q), (ˆy)i ←0
At
time
t,
agent
i
∈
I
in
the
network
does
the
following
concur-
rently:
1: take measurement yi from its current location si
2: update rowi(ˆQ) ←rowi(ˆQ) + rowi(σ−2
w ΛT Λ) by exchanging information from
neighbors Ni
3: update (ˆy)i ←(ˆy)i +(σ−2
w ΛT (y−μ))i by exchanging information from neighbors
Ni
4: for s0 ∈S do
5:
compute (λ)i = λ(s0, pi)
6:
compute (ˆQ
−1λ)i via JOR
7:
compute μz0|y = μ(s0) + λT ˆQ
−1ˆy via DAC
8:
compute σ2
z0|y = λT ˆQ
−1λ via DAC
9: end for

6.2 Distributed Spatial Prediction
87
The number of robotic sensors and the sampling rule can be modiﬁed or optimized
to maintain a better quality of the prediction and the corresponding distributed algo-
rithm may be derived in a same way accordingly.
6.3 Simulation and Experiment
In this section, we apply the proposed schemes to both simulation and experimental
study.
6.3.1 Simulation
We ﬁrst apply our proposed prediction algorithms to a numerically generated
Gaussian random ﬁeld z(·) based on a GMRF with respect to a graph G = (V, E)
deﬁned in (6.1). The mean function μ(·) is assumed to be constant and μ = 5 is
used in the simulation. We assume the generating points of the GMRF, indexed by
V = {1, · · · , n} where n = 30, are located at

p1, · · · , pn

in a 2-D unit area Q.
The edges of the graph are assumed to be E :=
{i, j} |
pi −p j
 ≤R

, where
R = 0.4.
The GMRF γ = (γ(p1), · · · , γ(pn))T has a zero-mean and the precision matrix
Q is given by
(Q)i j =
⎧
⎨
⎩
|N(i)| + c0, if j = i,
−1,
if j ∈N(i),
0,
otherwise,
where |N(i)| denotes the degree of node i, i.e., the number of connections it has
to other nodes, c0 = 0.1 is used to ensure Q is positive deﬁnite since a Hermitian
diagonally dominant matrix with real non-negative diagonal entries is positive semi-
deﬁnite [92]. We use compactly supported weighting functions deﬁned in (6.4) for
both centralized and distributed schemes with different support r. The sensor noise
level is given by σw = 0.5. Since the optimal sampling is beyond the scope of
this chapter, in the simulation, we use a random sampling strategy in which robotic
sensors sample at random locations at each time instance.
6.3.2 Centralized Scheme
We ﬁrst consider a scenario in which N = 5 agents take samples in the surveillance
region D at certain time instance t ∈Z>0 and send the observations to a central
station in which the prediction of the ﬁeld is made.

88
6
New Efﬁcient Spatial Model with Built-In Gaussian Markov Random Fields
0
0.5
1
0
0.5
1
5.5
6
6.5
7
7.5
8
8.5
0
0.5
1
0
0.5
1
5.5
6
6.5
7
7.5
8
8.5
0
0.5
1
0
0.5
1
5.5
6
6.5
7
7.5
8
8.5
0
0.5
1
0
0.5
1
5.5
6
6.5
7
7.5
8
8.5
(a)
(b)
(c)
(d)
Fig. 6.3
Simulation results for the centralized scheme. a The true ﬁeld, b the predicted ﬁeld at
time t = 1, c the predicted ﬁeld at time t = 5, d the predicted ﬁeld at time t = 20. The generating
points are shown in black circles, and the sampling locations are shown in black crosses
The Gaussian random ﬁeld z(·) is shown in Fig.6.3a with the n = 30 generating
points of the built-in GMRF shown in black circles. The predicted ﬁeld at times
t = 1, t = 5, and t = 20 are shown in Figs.6.3b, c and d, respectively. The sampling
locations are shown in black crosses. Clearly, the predicted ﬁeld gets closer to the
true ﬁeld as the number of observations increases. The computational time for ﬁeld
prediction at each time instance remains ﬁxed due to the nice structure of the proposed
Gaussian ﬁeld in (6.1) and its consequent results from Theorem 6.1.
6.3.3 Distributed Scheme
Next, we consider a scenario in which prediction is implemented in a distributed
fashion (Table6.2) under assumptions A.1–4 for the resource-constrained mobile
sensor network in Sect.6.2.2. In particular, N = 30 robotic sensors are distributed

6.3 Simulation and Experiment
89
0
0.2
0.4
0.6
0.8
1
0
0.2
0.4
0.6
0.8
1
0
5
10
15
20
25
30
0
5
10
15
20
25
30
(a)
(b)
Fig. 6.4
a Graph G = (V, E). b Sparsity structure of the precision matrix Q
according to the graph G = (V, E), which is connected. Agent i is in charge of the
sampling with in a r-disk centered at pi, where the support r = 0.2 is used. Agent i
has a ﬁxed neighborhood, i.e., N(i) = { j | {i, j} ∈E}. In the simulation, h = 0.02
in (6.5) and ϵ = 0.02 in (6.6) are chosen to ensure the convergence of the JOR
algorithm and the DAC algorithm.
Figure6.4a shows the underlying graph G = (V, E) for the GMRF with the
generating points denoted by black circles and the edges in red lines. The sparsity
of the precision matrix Q is shown in Fig.6.4b. Notice that only 316 out of 900
elements in Q are nonzero which enables the efﬁcient distributed computation. The
true and the predicted ﬁelds at time t = 5 are shown in Figs.6.5a, b, respectively. The
normalized RMS error computed over about 10000 grid points at time t = 5 is 7.8 %.
The computational time at each time instance remains ﬁxed due to the nice structure
of the proposed Gaussian ﬁeld in (6.1) and its consequent results from Theorem 6.1.
6.3.4 Experiment
In order to show the practical usefulness of the proposed approach, we apply the
centralized scheme in Theorem 6.1 on an experimentally obtained observations.
We ﬁrst measured depth values of a terrain on grid points by using a Microsoft
Kinect sensor [115] as shown in Fig.6.6a. As pointed out in Remark 6.1, we make
the structures of weighting functions and the precision matrix as functions of the
locations of generating points. In particular, two generating points are neighbors if
and only if their corresponding Voronoi cells intersect. The individual weighting
function takes the same form as in (6.4) and its support size ri is selected to be the
largest distance between the generating point i and it’s neighbors. We then predict the

90
6
New Efﬁcient Spatial Model with Built-In Gaussian Markov Random Fields
0
0.5
1
0
0.5
1
5.8
6
4.8
5
5.2
5.4
5.6
0
0.5
1
0
0.5
1
5.8
6
4.8
5
5.2
5.4
5.6
(a)
(b)
Fig. 6.5
Simulation results for the distributed scheme. a The true ﬁeld, b the predicted ﬁeld at
time t = 5. The generating points are shown in circles, and the sampling locations are shown in
crosses
10
20
30
40
50
60
5
10
15
20
25
30
35
40
45
780
790
800
810
820
830
840
10
20
30
40
50
60
5
10
15
20
25
30
35
40
45
780
790
800
810
820
830
840
(a)
(b)
Fig. 6.6
a True ﬁeld on grid positions obtained by the Kinect sensor and randomly sampled
positions indicated in black crosses. b The ﬁtted Gaussian random ﬁeld with a build-in GMRF with
respect to the Delaunay graph
ﬁeld by our model with 20 estimated generating points given by the ML estimator
in (6.3) using a subset of experimental observations, i.e., 200 randomly sampled
observations denoted by crosses in Fig.6.6a. The estimated positions of generating
points along with the predicted ﬁeld are shown in Fig.6.6b. In this experiment, it is
clear to see that our approach effectively produces the predicted ﬁeld, which is very
close to the true ﬁeld for the case of unknown generating points.

Chapter 7
Fully Bayesian Spatial Prediction
Using Gaussian Markov Random Fields
In this chapter, we consider the problem of predicting a large scale spatial ﬁeld using
successive noisy measurements obtained by mobile sensing agents. The physical
spatial ﬁeld of interest is discretized and modeled by a Gaussian Markov random
ﬁeld (GMRF) with unknown hyperparameters. From a Bayesian perspective, we
design a sequential prediction algorithm to exactly compute the predictive inference
of the random ﬁeld. The main advantages of the proposed algorithm are: (1) the
computational efﬁciency due to the sparse structure of the precision matrix, and
(2) the scalability as the number of measurements increases. Thus, the predic-
tion algorithm correctly takes into account the uncertainty in hyperparameters in
a Bayesian way and also is scalable to be usable for the mobile sensor networks
with limited resources. An adaptive sampling strategy is also designed for mobile
sensing agents to ﬁnd the most informative locations in taking future measurements
in order to minimize the prediction error and the uncertainty in hyperparameters. The
effectiveness of the proposed algorithms is illustrated by a numerical experiment.
In Chap.5, we designed a sequential Bayesian prediction algorithm to deal with
unknown bandwidths by using a compactly supported kernel and selecting a subset
of collected measurements. In this chapter, we instead seek a fully Bayesian approach
overadiscretizedsurveillanceregionsuchthattheBayesianspatialpredictionutilizes
all collected measurements in a scalable fashion. In contrast to this chapter, Chap.6
focuses on efﬁcient spatial modeling using a GMRF with known hyperparameters.
A distributed version of the prediction algorithm in this chapter for a special case
can be found in [5].
In Sect.7.1, we model the physical spatial ﬁeld as a GMRF with unknown hyper-
parameters and formulate the estimation problem from a Bayesian point of view. In
Sect.7.2, we design a sequential Bayesian estimation algorithm to effectively and
efﬁciently compute the exact predictive inference of the spatial ﬁeld. The proposed
© The Author(s) 2016
Y. Xu et al., Bayesian Prediction and Adaptive Sampling Algorithms
for Mobile Sensor Networks, SpringerBriefs in Control,
Automation and Robotics, DOI 10.1007/978-3-319-21921-9_7
91

92
7
Fully Bayesian Spatial Prediction Using Gaussian Markov Random Fields
algorithm often takes only seconds to run even for a very large spatial ﬁeld, as will be
demonstrated in this chapter. Moreover, the algorithm is scalable in the sense that the
running time does not grow as the number of observations increases. In particular,
the scalable prediction algorithm does not rely on the subset of samples to obtain
scalability (as was done in Chap.5), correctly fusing all collected measurements. In
Sect.7.4, an adaptive sampling strategy for mobile sensor networks is designed to
largely improve the quality of prediction and to reduce the uncertainty in the hyper-
parameter estimation simultaneously. We demonstrate the effectiveness through a
simulation study in Sect.7.5.
7.1 Spatial Field Model
In what follows, we specify the models for the spatial ﬁeld and the mobile sen-
sor network. Notice that in this chapter, we slightly change notation for notational
simplicity.
Let Q∗⊂RD denote the spatial ﬁeld of interest. We discretize the ﬁeld into n∗
spatial sites S∗:=

s1, . . . , sn∗

and let z∗= (z1, . . . , zn∗)T ∈Rn∗be the value of
the ﬁeld (e.g., the temperature). Due to the irregular shape a spatial ﬁeld may have,
we extend the ﬁeld such that n ≥n∗sites denoted by S := {s1, . . . , sn} are on a
regular grid. The latent variable zi := z(si) ∈R is modeled by
zi = μ(si) + ηi,
∀1 ≤i ≤n,
(7.1)
where si ∈S ⊂RD is the ith site location. The mean function μ : RD →R is
deﬁned as
μ(si) = f (si)T β,
where f (si) = ( f1(si), . . . , f p(si))T ∈Rp is a known regression function, and
β = (β1, . . . , βp)T ∈Rp is an unknown vector of regression coefﬁcients. We deﬁne
η = (η1, . . . , ηn)T ∈Rn as a zero-mean Gaussian Markov random ﬁeld (GMRF)
[92] denoted by
η ∼N

0, Q−1
η|θ

,
where the inverse covariance matrix (or precision matrix) Qη|θ ∈Rn×n is a function
of a hyperparameter vector θ ∈RM.
There exists many different choices of the GMRF (i.e., the precision matrix Qη|θ)
[92]. For instance, we can choose one with the full conditionals in (7.2) (with obvious
notation as shown in [92]).

7.1 Spatial Field Model
93
E(ηi|η−i, θ) =
1
4 + a2
⎛
⎜⎜⎜⎜⎝
2a
◦◦◦◦◦
◦◦• ◦◦
◦• ◦• ◦
◦◦• ◦◦
◦◦◦◦◦
−2
◦◦◦◦◦
◦• ◦• ◦
◦◦◦◦◦
◦• ◦• ◦
◦◦◦◦◦
−1
◦◦• ◦◦
◦◦◦◦◦
• ◦◦◦•
◦◦◦◦◦
◦◦• ◦◦
⎞
⎟⎟⎟⎟⎠
,
Var(ηi|η−i, θ) = (4 + a2)κ.
(7.2)
Figure7.1 displays the elements of the precision matrix related to a single location
that explains (7.2). The hyperparameter vector is deﬁned as θ = (κ, α)T ∈R2
>0,
where α = a −4. The resulting GMRF accurately represents a Gaussian random
ﬁeld with the Matérn covariance function [116]
C(r) = σ2
f
21−ν
Γ (ν)
√
2νr
ℓ
ν
Kν
√
2νr
ℓ

,
where Kν(·) is a modiﬁed Bessel function [53], with order ν = 1, a bandwidth
ℓ= 1/√α, and vertical scale σ2
f = 1/4πακ. The hyperparameter α > 0 guarantees
the positive deﬁniteness of the precision matrix Qη|θ. In the case where α = 0, the
resulting GMRF is a second-order polynomial intrinsic GMRF [92, 117]. Notice that
the precision matrix is sparse which contains only small number of non-zero ele-
ments. This property will be exploited for fast computation in the following sections.
Example 7.1 Consider a spatial ﬁeld of interest Q∗∈[0, 100] × [0, 50]. We ﬁrst
divide the spatial ﬁeld into a 100 × 50 regular grid with equal areas 1, which makes
n∗= 5000. We then extend the the ﬁeld such that 120 × 70 grids (i.e., n = 8400)
are constructed on the extended ﬁeld Q = [−10, 110] × [−10, 60]. The precision
matrix Qη|θ introduced above is chosen with the regular lattices wrapped on a torus
[92]. In this case, only 0.15 % elements in the sparse matrix Qη|θ are non-zero.
The numerically generated ﬁelds with the mean function μ(si) = β = 20, and the
hyperparameter vector θ = (κ, α)T being different values are shown in Fig.7.2.
Fig. 7.1 Elements of the
precision matrix Q related to
a single location

94
7
Fully Bayesian Spatial Prediction Using Gaussian Markov Random Fields
0
20
40
60
80
100
0
10
20
30
40
50
20
22
24
26
28
0
20
40
60
80
100
0
10
20
30
40
50
16
18
20
22
24
26
28
0
20
40
60
80
100
0
10
20
30
40
50
15
20
25
30
(a)
(b)
(c)
Fig. 7.2 Numerically generated spatial ﬁelds deﬁned in (7.1) with μ(si) = β = 20, and Qη|θ
constructed using (7.2) with hyperparameters being a θ = (4, 0.0025)T , b θ = (1, 0.01)T , and
c θ = (0.25, 0.04)T
7.2 Bayesian Predictive Inference
In this section, we propose a Bayesian inference approach to make predictive infer-
ences of a spatial ﬁeld z∗∈Rn∗.
First, we assign the vector of regression coefﬁcients β ∈Rp with a Gaussian prior,
namely β ∼N

0, T−1
, where the precision matrix T ∈Rp×p is often chosen as a
diagonal matrix with small diagonal elements when no prior information is available.
Hence, the distribution of latent variables z given β and the hyperparameter vector
θ is Gaussian, i.e.,

7.2 Bayesian Predictive Inference
95
z|β, θ ∼N

Fβ, Q−1
η|θ

,
where F = ( f (s1), . . . , f (sn))T ∈Rn×p. For notational simplicity, we denote the
full latent ﬁeld of dimension n + p by x = (zT , βT )T . Then, for a given hyperpa-
rameter vector θ, the distribution π(x|θ) is Gaussian obtained by
π(x|θ) = π(z|β, θ)π(β)
∝exp

−1
2(z −Fβ)T Qη|θ(z −Fβ) −1
2βT Tβ

= exp

−1
2xT Qx|θx

,
where the precision matrix Qx|θ ∈R(n+p)×(n+p) is deﬁned by
Qx|θ =

Qη|θ
−Qη|θF
−FT Qη|θ FT Qη|θF + T

.
By the matrix inversion lemma, the covariance matrix x|θ ∈R(n+p)×(n+p) can be
obtained by
x|θ = Q−1
x|θ =

Q−1
η|θ + FT−1FT FT−1
(FT−1)T
T−1

.
At time t ∈Z>0, we have a collection of observational data y1:t ∈RNt obtained
by the mobile sensing agents over time. Let A1:t = (A1, . . . , At) ∈R(n+p)×Nt,
where Aτ ∈R(n+p)×N is deﬁned by
(Aτ)i j =
1, if si = qτ, j,
0, otherwise.
Then the covariance matrix of y1:t can be obtained by
R1:t = AT
1:tx|θA1:t + P1:t,
where P1:t = σ2
wI ∈RNt×Nt. By Gaussian process regression [53], the full condi-
tional distribution of x is also Gaussian, i.e.,
x|θ, y1:t ∼N(μx|θ,y1:t , x|θ,y1:t ),
where
x|θ,y1:t = x|θ −x|θA1:tR−1
1:t AT
1:tx|θ,
μx|θ,y1:t = x|θA1:tR−1
1:t y1:t.
(7.3)

96
7
Fully Bayesian Spatial Prediction Using Gaussian Markov Random Fields
The posterior distribution of the hyperparameter vector θ can be obtained via
π(θ|y1:t) ∝π(y1:t|θ)π(θ),
where the log likelihood function is deﬁned by
log π(y1:t|θ) = −1
2yT
1:tR−1
1:t y1:t −1
2 log det R1:t −Nt
2 log 2π.
(7.4)
If a discrete prior on the hyperparameter vector θ is chosen with a support  =
{θ1, . . . , θL}, the posterior predictive distribution π(x|y1:t) can be obtained by
π(x|y1:t) =

ℓ
π(x|θℓ, y1:t)π(θℓ|y1:t).
(7.5)
The predictive mean and variance then follow as
μxi|y1:t =

ℓ
μxi|θℓ,y1:t π(θℓ|y1:t),
σ2
xi|y1:t =

ℓ
σ2
xi|θℓ,y1:t π(θℓ|y1:t) +

ℓ
(μxi|θℓ,y1:t −μxi|y1:t )2π(θℓ|y1:t),
(7.6)
where μxi|θℓ,y1:t is the ith element in μx|θℓ,y1:t , and σ2
xi|θℓ,y1:t is the ith diagonal
element in x|θℓ,y1:t .
Remark 7.1 The discrete prior π(θ) greatly reduced the computational complexity
in that it enables summation in (7.5) instead of numerical integration which has to be
performed with a choice of continuous prior distribution. However, the computation
of the full conditional distribution π(x|θ, y1:t) in (7.3) and the likelihood π(y1:t|θ)
(7.4) requires the inversion of the covariance matrix R1:t, whose size grows as the
time t increases. Thus, the running time grows fast as new observations are collected
and it will soon become intractable.
7.3 Sequential Bayesian Inference
Inthissection,weexploitthesparsityoftheprecisionmatrix,andproposeasequential
Bayesian prediction algorithm which can be performed in constant time and fast
enough even for a very large spatial ﬁeld.

7.3 Sequential Bayesian Inference
97
7.3.1 Update Full Conditional Distribution
First, we rewrite the full conditional distribution π(x|θ, y1:t) in terms of the sparse
precision matrix Qx|θ as follows
x|θ, y1:t ∼N(μx|θ,y1:t , Q−1
x|θ,y1:t ),
where
Qx|θ,y1:t = Qx|θ + A1:tP−1
1:t AT
1:t
μx|θ,y1:t = Q−1
x|θ,y1:t A1:tP−1
1:t y1:t.
(7.7)
From here on, we will use Qt|θ = Qx|θ,y1:t and μt|θ = μx|θ,y1:t , for notational
simplicity. Notice that (7.7) can be represented by the following recursion
Qt|θ = Qt−1|θ + 1
σ2w
N

i=1
ut,iuT
t,i,
bt = bt−1 + 1
σ2w
N

i=1
ut,i yt,i,
(7.8)
where bt = Qt|θμt|θ with initial conditions
Q0|θ = Qx|θ,y1:0 = Qx|θ, and b0 = 0.
In (7.8), we have deﬁned ut,i ∈Rn+p as
(ut,i) j =
1, if s j = qt,i,
0, otherwise.
Lemma 7.1 For a given θ ∈θ, the full conditional mean and variance, i.e., μt|θ
and Qt|θ, can be updated in short constant time given Qt−1|θ and bt−1.
Proof The update of Qt|θ and bt can be obviously computed in constant time. Hence
μt|θ can be obtained by solving a linear equation Qt|θμt|θ = bt. Due to the sparse
structure of Qt|θ, this operation can be done in a very short time. Moreover, notice
that Qt|θ and Qt−1|θ have the same sparsity structure and hence the computational
complexity remains ﬁxed.
□
From Lemma7.1, we can compute μxi|θ,y1:t in (7.6) in constant time. In order to
ﬁnd σ2
xi|θ,y1:t in (7.6), we need to compute x|θ,y1:t which requires the inversion of
Qt|θ. The inversion of a big matrix (even a sparse matrix) is undesirable. However,
notice that only the diagonal elements in Q−1
t|θ are needed. Following the Sherman-
Morrison formula (see AppendixA.2.2) and using (7.8), σ2
xi|θ,y1:t can be obtained

98
7
Fully Bayesian Spatial Prediction Using Gaussian Markov Random Fields
exactly via
diag(Q−1
t|θ) = diag
⎛
⎝

Qt−1|θ +
N

i=1
ut,iuT
t,i
−1⎞
⎠
= diag(Q−1
t−1|θ) −
N

i=1
ht,i|θ ◦ht,i|θ
σ2w + uT
t,iht,i|θ
,
ht,i|θ = B−1
t,i|θut,i,
Bt,i|θ = Qt−1|θ + 1
σ2w
i
j=1
ut, juT
t, j,
(7.9)
where ◦denotes the element-wise produce. By this way, the computation can be done
efﬁciently in constant time.
7.3.2 Update Likelihood
Next, we derive the update rule for the log likelihood function. We have the following
proposition.
Proposition 7.1 The log likelihood function log π(y1:t|θ) in (7.4) can be obtained by
log π(y1:t|θ) = ct + gt,θ + 1
2bT
t μt|θ −Nt
2 log(2πσ2
w)
(7.10)
where
ct = ct−1 −
1
2σ2w
N

i=1
y2
t,i,
c0 = 0,
gt|θ = gt−1|θ −1
2
N

i=1
log

1 + 1
σ2w
uT
t,iht,i|θ

,
g0|θ = 0,
with ht,i|θ deﬁned in (7.9).
Proof The inverse of the covariance matrix R1:t can be obtained by
R−1
1:t = (AT
1:tQ−1
0|θA1:t + P1:t)−1
= P−1
1:t −P−1
1:t AT
1:t(Q0|θ + A1:tP−1
1:t AT
1:t)−1A1:tP−1
1:t
= P−1
1:t −P−1
1:t AT
1:tQ−1
t|θA1:tP−1
1:t .

7.3 Sequential Bayesian Inference
99
Similarly, the log determinant of the covariance matrix 1:t can be obtained by
log det R1:t = log det(AT
1:tQ−1
0|θA1:t + P1:t)
= log det(I + 1
σ2w
AT
1:tQ−1
0|θA1:t) + Nt log σ2
w
= log det(Q0|θ + 1
σ2w
t
τ=1
N

i=1
uτ,iuT
τ,i) −log det(Q0|θ) + Nt log σ2
w
=
t
τ=1
log(1 + uT
τ Q−1
τ−1|θuτ) + Nt log σ2
w.
Hence, we have
log π(y1:t|θ)
= −1
2yT
1:tR−1
1:t y1:t −1
2 log det R1:t −Nt
2 log 2π
= −1
2yT
1:tP−1
1:t y1:t + 1
2bT
t μt|θ −1
2
t
τ=1
N
i=1
log(1 + uT
τ,iB−1
τ,i|θuτ,i) −Nt
2 log(2πσ2
w).
□
Lemma 7.2 For a given θ ∈θ, the log likelihood function, i.e., log π(y1:t|θ) can
be computed in short constant time.
Proof The result follows directly from Proposition7.1.
□
7.3.3 Update Predictive Distribution
Combining the results in Lemmas7.1, 7.2, and (7.5), (7.6), we summarize our results
in the following theorem.
Theorem 7.1 The predictive distribution in (7.5) (or the predictive mean and vari-
ance in (7.6)) can be obtained in constant time as time t increases.
WesummarizetheproposedsequentialBayesianpredictionalgorithminTable7.1.

100
7
Fully Bayesian Spatial Prediction Using Gaussian Markov Random Fields
Table 7.1 Sequential Bayesian predictive inference
Input:
(1) prior distribution of θ ∈Θ, i.e., π(θ)
Output:
(1) predictive mean

μxi|y1:t
n∗
i=1
(2) predictive variance

σ2
xi|y1:t
n∗
i=1
Initialization:
1: initialize b = 0, c = 0
2: for θ ∈Θ do
3:
initialize Qθ, gθ = 0
4:
compute diag(Q−1
θ )
5: end for
At time t ∈Z>0, do:
1: for 1 ≤i ≤N do
2:
obtain new observations yt,i collected at current locations qt,i
3:
ﬁnd the index k corresponding to qt,i, and set u = ek
4:
update b = b + yt,i
σ2
w u
5:
update c = c −
1
2σ2
w y2
t,i
6:
for θ ∈Θ do
7:
compute hθ = Q−1
θ u
8:
update diag(Q−1
θ ) = diag(Q−1
θ ) −
hθ◦hθ
σ2
w+uT hθ
9:
update Qθ via Qθ = Qθ +
1
σ2
w uuT
10:
update gθ = gθ −1
2 log(1 +
1
σ2
w uT h)
11:
end for
12: end for
13: for θ ∈Θ do
14:
compute μθ = Q−1
θ b
15:
compute the likelihood via
log π(θ|y1:t) = c + gθ + 1
2bT μθ
16: end for
17: compute the posterior distribution via
π(θ|y1:t) ∝π(y1:t|θ)π(θ)
18: compute the predictive mean via
μxi|y1:t = 
ℓ(μθℓ)iπ(θℓ|y1:t)
19: compute the predictive variance via
σ2
xi|y1:t = 
ℓ(diag(Qθℓ))i + ((μθℓ)i −μxi|y1:t)2
π(θℓ|y1:t)

7.4 Adaptive Sampling
101
7.4 Adaptive Sampling
In the previous section, we have designed a sequential Bayesian prediction algorithm
for estimating the scalar ﬁeld at time t. In this section, we propose an adaptive
sampling strategy for ﬁnding most informative sampling locations at time t + 1 for
mobile sensing agents in order to improve the quality of prediction and reduce the
uncertainty in hyper parameters simultaneously.
In our previous work [118], we have proposed to use the conditional entropy
H(z∗|θ = ˆθt, y1:t+1) as an optimality criterion, where
ˆθt = arg max
θ
π(θ|y1:t),
is the maximum a posterior (MAP) estimate based on the cumulative observations
up to current time t. Although this approach greatly simpliﬁes the computation, it
does not count for the uncertainty in estimating the hyperparameter vector θ.
In this chapter, we propose to use the conditional entropy H(z∗, θ|yt+1, y1:t)
which represents the uncertainty remained in both random vectors z∗and θ by know-
ing future measurements in the random vector yt+1. Notice that the measurements
y1:t have been observed and treated as constants. It can be obtained by
H(z∗, θ|yt+1, y1:t) = H(z∗|θ, yt+1, y1:t) + H(θ|yt+1, y1:t)
= H(z∗|θ, yt+1, y1:t) + H(yt+1|θ, y1:t)
+ H(θ|y1:t) −H(yt+1|y1:t).
Notice that we have the following Gaussian distributions (the means will not be
exploited and hence not shown here):
z∗|θ, yt+1, y1:t ∼N(·, x∗|θ,y1:t+1),
yt+1|θ, y1:t ∼N(·, yt+1|θ,y1:t + σ2
wI),
yt+1|y1:t
approx
∼
N(·, yt+1|y1:t + σ2
wI),
in which the last one is approximated using (7.6). Notice that the approximation is
used here to avoid numerical integration over the random vector yt+1 which needs to
be done using Monte Carlo methods. Moreover, the entropy H(θ|y1:t) = c is a con-
stant since y1:t is known. Since the entropy for a multivariate Gaussian distribution
has a closed-from expression [72], we have

102
7
Fully Bayesian Spatial Prediction Using Gaussian Markov Random Fields
H(z∗, θ|yt+1, y1:t) =

ℓ
1
2 log

(2πe)n∗det(x∗|θℓ,y1:t+1)

π(θℓ|y1:t)
+

ℓ
1
2 log

(2πe)N det(qt+1|θℓ,y1:t )

π(θℓ|y1:t)
−1
2 log

(2πe)N det(qt+1|y1:t )

+ c.
It can also be shown that
log det(x∗|θℓ,y1:t+1) = log det(Q−1
t+1|θℓ)(S∗)
= log det(Qt+1|θℓ)(−S∗) −log det(Qt+1|θℓ),
where A(S∗) denotes the submatrix of A formed by the ﬁrst 1 to n∗rows and columns
(recall that S∗=

s1, . . . , sn∗

). Notice that the term log det(Qt+1|θℓ)(−S∗) is a
constant since agents only sample at S∗. Hence, the optimal sampling locations at
time t + 1 can be determined by solving the following optimization problem
q∗
t+1 = arg
min
{qt+1,i∈Rt,i}
H(z∗, θ|yt+1, y1:t)
= arg
min
{qt+1,i∈Rt,i}

ℓ
−log det(Qt+1|θℓ)π(θℓ|y1:t)
+

ℓ
log det(yt+1|θℓ,y1:t )π(θℓ|y1:t) −log det(yt+1|y1:t ),
where Rt,i =

s |
s −qt,i
 ≤r, s ∈S∗

(in which r ∈R>0 is the maximum
distance an agent can move between time instances) is the reachable set at time t.
This combinatorial optimization problem can be solved using a greedy algorithm,
i.e., ﬁnding the sub-optimal sampling locations for agents in sequence.
7.5 Simulation
In this section, we demonstrate the effectiveness of the proposed sequential Bayesian
inference algorithm and the adaptive sampling strategy through a numerical experi-
ment.
Consider a spatial ﬁeld introduced in Example7.1. The mean function is a constant
β = 20. We choose the precision matrix Qx|θ with hyperparameters α = 0.01
equivalent to a bandwidth ℓ= 1/√α = 10, and κ = 1 equivalent to a vertical
scale σ2
f = 1/4πακ ≈8. The numerically generated ﬁeld is shown in Fig.7.2b. The
precision matrix T ∈R of β is chosen to be 10−4. The measurement noise level
σw = 0.2 is assumed to be known. A discrete uniform distribution is selected with a
support shown in Fig.7.3. N = 5 mobile sensing agents take measurements at time

7.5 Simulation
103
0.25
1
4
0.0025
0.01
0.04
0
0.1
0.2
0.3
0.4
κ
α
0.25
1
4
0.0025
0.01
0.04
0
0.2
0.4
0.6
0.8
1
κ
α
0.25
1
4
0.0025
0.01
0.04
0
0.2
0.4
0.6
0.8
1
κ
α
0.25
1
4
0.0025
0.01
0.04
0
0.2
0.4
0.6
0.8
1
κ
α
(a)
(b)
(c)
(d)
Fig. 7.3 Posterior distributions of θ, i.e., π(θ|y1:t), at a t = 1, b t = 5, c t = 10, and d t = 20
t ∈Z>0, starting from locations shown in Fig.7.4b (in white dots). The maximum
distance each agent can travel between time instances is chosen to be r = 5.
Figure7.4 shows the predicted ﬁelds and the prediction error variances at times
t = 1, 5, 10, 20. The trajectories of agents are shown in white circles with the cur-
rent locations shown in white dots. It can be seen that agents try to cover the ﬁeld
of interest as time evolves. The predicted ﬁeld (the predictive mean) gets closer to
the true ﬁeld (see Fig.7.2b) and the prediction error variances become smaller as
more observations are collected. Figure7.3 shows the posterior distribution of the
hyperparameters in θ. Clearly, as more measurements are obtained, this posterior
distribution becomes peaked at the true value (1,0.01). Figure7.5a shows the pre-
dicted distribution of the estimated mean β as time evolves. In Fig.7.5b, we can see
that the RMS error computed via
rms(t) =



 1
n∗
n∗

i=1
(μzi|y1:t −zi)2,

104
7
Fully Bayesian Spatial Prediction Using Gaussian Markov Random Fields
0
20
40
60
80
100
0
10
20
30
40
50
16
18
20
22
24
26
28
0
20
40
60
80
100
0
10
20
30
40
50
1
2
3
4
5
6
0
20
40
60
80
100
0
10
20
30
40
50
16
18
20
22
24
26
28
0
20
40
60
80
100
0
10
20
30
40
50
1
2
3
4
5
6
7
8
(a)
(b)
(c)
(d)
Fig. 7.4 Predicted ﬁelds at a t = 1, c t = 5, e t = 10, and g t = 20. Prediction error variances at
b t = 1, d t = 5, f t = 10, and h t = 20

7.5 Simulation
105
0
20
40
60
80
100
0
10
20
30
40
50
16
18
20
22
24
26
28
0
20
40
60
80
100
0
10
20
30
40
50
1
2
3
4
5
6
0
20
40
60
80
100
0
10
20
30
40
50
16
18
20
22
24
26
28
0
20
40
60
80
100
0
10
20
30
40
50
1
2
3
4
5
6
(e)
(f)
(g)
(h)
Fig. 7.4 (continued)

106
7
Fully Bayesian Spatial Prediction Using Gaussian Markov Random Fields
Fig. 7.5 a Estimated β, and
b root mean square error
10
15
20
25
30
0
0.05
0.1
0.15
0.2
0.25
0.3
0.35
β
t=1
t=5
t=10
t=20
0
5
10
15
20
0.8
1
1.2
1.4
1.6
1.8
2
2.2
2.4
2.6
2.8
t
(a)
(b)
decreases as time increases, which shows the effectiveness of the proposed scheme.
The most important contribution is that the computation time at each time step
does not grow as the number of measurements increases.

Appendix A
Mathematical Background
A.1 Gaussian Identities
ThemultivariateGaussiandistributionofarandomvectorx ∈Rn (i.e.,x ∼N(μ, ))
has a joint probability density function (pdf) given by
p(x; μ, ) =
1
(2π)−n/2||−1/2 exp

−1
2(x −μ)T −1(x −μ)

,
where μ ∈Rn is the mean vector, and  ∈Rn×n is the covariance matrix.
Now, suppose x consists of two disjoint subsets xa and xb, i.e.,
x =
xa
xb

.
The corresponding mean vector μ and covariance matrix Σ can be written as
μ =
μa
μb

,
Σ =
aa ab
ba bb

,
where ab = T
ba due to the symmetry of . Then, the marginal distribution of xa
is given by
xa ∼N(μa, aa),
and the conditional distribution of xa given xb is given by
xa|xb ∼N(μa|b, a|b),
where
μa|b = μa + ab−1
bb (xb −μb)
a|b = aa −ab−1
bb ba.
© The Author(s) 2016
Y. Xu et al., Bayesian Prediction and Adaptive Sampling Algorithms
for Mobile Sensor Networks, SpringerBriefs in Control,
Automation and Robotics, DOI 10.1007/978-3-319-21921-9
107

108
Appendix A: mathematical background
A.2 Matrix Inversion Lemma
Matrices canbeinvertedblockwisebyusingthefollowinganalyticinversionformula:
 A B
BT C
−1
=
A−1 + A−1B(C −BT A−1B)−1BT A−1 −A−1B(C −BT A−1B)−1
−(C −BT A−1B)−1BT A−1
(C −BT A−1B)−1

,
where A, B, and C are matrix subblocks of arbitrary size. Matrices A and C −
BT A−1B must be nonsingular.
A.2.1 Woodbury Identity
The Woodbury matrix identity is
(A + UCV)−1 = A−1 −A−1U

C−1 + VA−1U
−1
VA−1,
where A, U, C, and V denote matrices with appropriate size.
A.2.2 Sherman–Morrison Formula
Suppose A ∈Rn×n is invertible and u ∈Rn and v ∈Rn are vectors. Assume that
1 + vT A−1u ̸= 0, the Sherman–Morrison formula states that
(A + uvT )−1 = A−1 −A−1uvT A−1
1 + vT A−1u
.
A.3 Generating Gaussian Processes
In order to implement algorithms in simulation studies, we need to generate multi-
variate Gaussian samples from N(μ, ) with arbitrary mean μ and covariance matrix
. In what follows, we introduce two approaches.

Appendix A: mathematical background
109
A.3.1 Cholesky Decomposition
Given an arbitrary mean μ and a positive deﬁnite covariance matrix , the algorithm
generates multivariate Gaussian samples is shown in TableA.1.
A.3.2 Circulant Embedding
Consider a 1D zero-mean stationary Gaussian process z(x) with a covariance func-
tion C(x, x′). The covariance matrix  of z(x) sampled on the equispaced grids
Ω =

x(1), . . . , x(n)	
has entries ()pq = C(|x(p) −x(q)|). Notice that the covari-
ance matrix  is a positive semi-deﬁnite symmetric Toeplitz matrix which can be
characterized by its ﬁrst row r = row1().
The key idea behind circulant embedding method is to construct a circulant matrix
S that contains  as its upper-left submatrix. The reason for seeking a circulant
embedding is the fact that, being a m × m circulant matrix, S has an eigendecompo-
sition S = (1/m)FFH, where F is the standard FFT matrix of size m with entries
(F)pq = exp(2πipq/m), FH is the conjugate transpose of F, and  is a diagonal
matrix whose diagonal entries form the vector ˜s = Fs (s is the ﬁrst row of S).
Given a positive semi-deﬁnite circulant extension S of , the algorithm generates
the realization of z(x) sampled on Ω is shown in TableA.2. Extension to multidi-
mensional cases can be found in [107].
Table A.1 Generating multivariate Gaussian samples by Cholesky decomposition
1: compute the Cholesky decomposition of the positive deﬁnite symmetric covariance
matrix Σ = LLT , where L is a lower triangular matrix
2: generate u ∼N(0, I) by multiple separate calls to the scalar Gaussian generator
3: compute x = μ + Lu which has desired normal distributed with mean μ and
covariance matrix LE[uuT ]LT = LLT = Σ
Table A.2 Generating multivariate Gaussian samples by circulant embedding
1: compute via the FFT the discrete Fourier transform of ˜s = Fs and form the vector
(˜s/m)1/2
2: generate a vector ϵ = ϵ1 + iϵ2 of dimension m with ϵ1 ∼N(0, I) and ϵ2 ∼N(0, I)
being independent and real random variables
3: compute a vector ˜e = ϵ ◦(˜s/m)1/2
4: compute via FFT the discrete Fourier transform e = F˜e. The real and imaginary
parts of the ﬁrst n entries in e yield two independent realizations of z(x) on Ω

References
1. Y. Xu, J. Choi, Adaptive sampling for learning Gaussian processes using mobile sensor net-
works. Sensors 11(3), 3051–3066 (2011)
2. Y. Xu, J. Choi, S. Oh, Mobile sensor network navigation using Gaussian processes with
truncated observations. IEEE Transactions on Robotics 27(6), 1118–1131 (2011)
3. Y. Xu, J. Choi, S. Dass, T. Maiti, Sequential Bayesian prediction and adaptive sampling
algorithms for mobile sensor networks. IEEE Trans. Autom. Control 57(8), 2078–2084 (2012)
4. Y. Xu, J. Choi, Spatial prediction with mobile sensor networks using Gaussian processes with
built-in Gaussian markov random ﬁelds. Automatica 48(8), 1735–1740 (2012)
5. Y. Xu, J. Choi, S. Dass, T. Maiti, Efﬁcient Bayesian spatial prediction with mobile sensor
networks using Gaussian Markov random ﬁelds. Automatica 49(12), 3520–3530 (2013)
6. M. Jadaliha, Y. Xu, J. Choi, N.S. Johnson, W. Li, Gaussian process regression for sensor
networks under localization uncertainty. IEEE Trans. Signal Process. 61(2), 223–237 (2013)
7. L.S. Muppirisetty, T. Svensson, H. Wymeersch, Spatial wireless channel prediction under
location uncertainty, 4 (2015). arXiv:1501.0365
8. S.Choi,M.Jadaliha,J.Choi,S.Oh,DistributedGaussianprocessregressionunderlocalization
uncertainty. J. Dyn. Syst., Meas. Control 137(3) (2015)
9. I.F. Akyildiz, W. Su, Y. Sankarasubramaniam, E. Cayirci, Wireless sensor networks: a survey.
Comput. Netw. 38(4), 393–422 (2002)
10. D. Culler, D. Estrin, M. Srivastava, Guest editors’ introduction: overview of sensor networks.
Computer 37(8), 41–49 (2004)
11. P. Levis, S. Madden, J. Polastre, R. Szewczyk, K. Whitehouse, A. Woo, D. Gay, J. Hill,
M. Welsh, E. Brewer et al., TinyOS: an operating system for sensor networks, in Ambient
Intelligence (Springer, Berlin, 2005), pp. 115–148
12. C.G. Cassandras, W. Li, Sensor networks and cooperative control. Eur. J. Control 11(4–5),
436–463 (2005)
13. S. Oh, L. Schenato, P. Chen, S. Sastry, Tracking and coordination of multiple agents using
sensor networks: system design, algorithms and experiments. Proc.-IEEE 95(1), 234–254
(2007)
14. S. Hauert, S. Leven, J. Zufferey, D. Floreano, The swarming micro air vehicle network
(smavnet) project (2012)
15. P. Juang, H. Oki, Y. Wang, M. Martonosi, L.S. Peh, D. Rubenstein, Energy-efﬁcient computing
for wildlife tracking: design tradeoffs and early experiences with zebranet, in ACM Sigplan
Notices, vol. 37, no. 10 (ACM, 2002), pp. 96–107
© The Author(s) 2016
Y. Xu et al., Bayesian Prediction and Adaptive Sampling Algorithms
for Mobile Sensor Networks, SpringerBriefs in Control,
Automation and Robotics, DOI 10.1007/978-3-319-21921-9
111

112
References
16. V. Dyo, S. A. Ellwood, D. W. Macdonald, A. Markham, C. Mascolo, B. Pásztor, S. Scellato,
N. Trigoni, R. Wohlers, K. Yousef, Evolution and sustainability of a wildlife monitoring
sensor network, in Proceedings of the 8th ACM Conference on Embedded Networked Sensor
Systems (ACM, 2010), pp. 127–140
17. J. Huisman, H.C.P. Matthijs, P.M. Visser, Harmful Cyanobacteria (Springer, New York, 2005)
18. K. Johnk, J. Huisman, J. Sharples, B. Sommeijer, P. Visser, J. Stroom, Summer heatwaves
promote blooms of harmful cyanobacteria. Glob. Change Biol. 14(3), 495–512 (2008)
19. I. Chorus, J. Bartram, Toxic Cyanobacteria in Water: A Guide to Their Public Health Conse-
quences, Monitoring, and Management (Sponpress, London, 1999)
20. G.S. Sukhatme, A. Dhariwal, B. Zhang, C. Oberg, B. Stauffer, D.A. Caron, Design and
development of a wireless robotic networked aquatic microbial observing system. Environ.
Eng. Sci. 24(2), 205–215 (2007)
21. Y. Wang, R. Tan, G. Xing, X. Tan, J. Wang, R. Zhou, Spatiotemporal aquatic ﬁeld reconstruc-
tion using cyber-physical robotic sensor systems. ACM Trans. Sensor Netw. (TOSN) 10(4),
57 (2014)
22. J. Lee, M. Roh, K. Kim, D. Lee, Design of autonomous.underwater vehicles for cage aqua-
farms, in Proceedings of the 2007 IEEE Intelligent Vehicles Symposium, Istanbul, Turkey,
2007, pp. 938–943
23. J. Laut, E. Henry, O. Nov, M. Porﬁri, Development of a mechatronics-based citizen science
platform for aquatic environmental monitoring. IEEE Trans. mechatron. 19(5), 1541–1551
(2014)
24. I. Vasilescu, K. Kotay, D. Rus, M. Dunbabin, P. Corke, Data collection, storage, and retrieval
with an underwater sensor network, in Proceedings of the 3rd International Conference on
Embedded Networked Sensor Systems (ACM, 2005), pp. 154–165
25. A. Marino, G. Antonelli, A.P. Aguiar, A. Pascoal, S. Chiaverini, A decentralized strategy
for multirobot sampling/patrolling: theory and experiments. IEEE Transactions on Control
Systems Technology (2014)
26. F. Zhang, O. En-Nasr, E. Litchman, X. Tan, Autonomous sampling of water columns using
gliding robotic ﬁsh: control algorithms and ﬁeld experiments, in Proceedings of 2015 IEEE
Conference on Robotics and Automation (ICRA), Seattle. IEE, May (2015)
27. J. Choi, D. Milutinovi´c, Tips on stochastic optimal feedback control and Bayesian spatiotem-
poral models: applications to robotics, J. Dyn. Syst., Meas. Control 137(3) (2015)
28. S.S. Mupparapu, S.G. Chappell, R.J. Komerska, D.R. Blidberg, R. Nitzel, C. Benton, D.O.
Popa, A.C. Sanderson, Autonomous systems monitoring and control (ASMAC)—an AUV
ﬂeet controller, in IEEE/OES Autonomous Underwater Vehicles, 2004, pp. 119–126 (2004)
29. C.L. Nickell, C.A. Woolsey, D.J. Stilwell, A low-speed control module for a streamlined AUV,
in Proceedings of MTS/IEEE OCEANS, Boston, 2005, pp. 1680–1685
30. P.R. Bandyopadhyay, Trends in biorobotic autonomous undersea vehicles. IEEE J. Ocean.
Eng. 30, 109–139 (2005)
31. C.C. Ericksen, T.J. Osse, R.D. Light, T. Wen, T.W. Lehman, P.L. Sabin, J.W. Ballard, A.M.
Chiodi, Seaglider: a long-range autonomous underwater vehicle for oceanographic research.
IEEE J. Ocean. Eng. 26, 424–436 (2001)
32. J. Sherman, R.E. Davis, W.B. Owens, J. Valdes, The autonomous underwater glider “spray”.
IEEE J. Ocean. Eng. 26, 437–446 (2001)
33. D.C. Webb, P.J. Simonetti, C.P. Jones, “SLOCUM”: an underwater glider propelled by envi-
ronmental energy. IEEE J. Ocean. Eng. 26, 447–452 (2001)
34. D.L. Rudnick, C.C. Eriksen, D.M. Fratantoni, M.J. Perry, Underwater gliders for ocean
research. Mar. Technol. Soc. J. 38, 48–59 (2004)
35. E. Fiorelli, N.E. Leonard, P. Bhatta, D.A. Paley, R. Bachmayer, D.M. Fratantoni, Multi-AUV
control and adaptive sampling in Monterey Bay. IEEE J. Ocean. Eng. 31(4), 935–948 (2006)
36. N.E. Leonard, D.A. Paley, F. Lekien, R. Sepulchre, D.M. Fratantoni, R. Davis, Collective
motion, sensor networks, and ocean sampling. Proc. IEEE 95(1), 48–74 (2007)
37. N.E. Leonard, D.A. Paley, R.E. Davis, D.M. Fratantoni, F. Lekien, F. Zhang, Coordinated con-
trol of an underwater glider ﬂeet in an adaptive ocean sampling ﬁeld experiment in Monterey
Bay. J. Field Robot. 27(6), 718–740 (2010)

References
113
38. C. Zhang, A. Siranosian, M. Krstic, Extremum seeking for moderately unstable systems and
for autonomous vehicle target tracking witwith position measurements. Automatica 43(10),
1832–1839 (2007)
39. M.S. Stankovic, D.M. Stipanovic, Extremum seeking under stochastic noise and applications
to mobile sensors. Automatica 46(8), 1243–1251 (2010)
40. J. Le Ny, G.J. Pappas, Adaptive deployment of mobile robotic networks. IEEE Trans. Autom.
Control 58(3), 654–666 (2013)
41. K.M. Lynch, I.B. Schwartz, P. Yang, R.A. Freeman, Decentralized environmental modeling
by mobile sensor networks. IEEE Trans. Robot. 24(3), 710–724 (2008)
42. J. Choi, S. Oh, R. Horowitz, Distributed learning and cooperative control for multi-agent
systems. Automatica 45, 2802–2814 (2009)
43. N.A. Atanasov, J. Le Ny, G.J. Pappas, Distributed algorithms for stochastic source seeking
with mobile robot networks, J. Dyn. Syst. Meas. Control 137(3) (2015)
44. A. Krause, A. Singh, C. Guestrin, Near-optimal sensor placements in Gaussian processes:
theory, efﬁcient algorithms and empirical studies. J. Mach. Learn. Res. 9, 235–284 (2008)
45. J. Cortés, Distributed kriged Kalman ﬁlter for spatial estimation. IEEE Trans. Autom. Control
54(12), 2816–2827 (2009)
46. R. Graham, J. Cortés, Cooperative adaptive sampling of random ﬁelds with partially known
covariance. Int. J. Robust Nonlinear Control 1, 1–2 (2009)
47. R. Graham, J. Cortés, Adaptive information collection by robotic sensor networks for spatial
estimation. IEEE Trans. Autom. Control 57(6), 1404–1419 (2012)
48. Y. Xu, J. Choi, Stochastic adaptive sampling for mobile sensor networks using kernel regres-
sion. Int. J. Control, Autom. Syst. 10(4), 778–786 (2012)
49. D. Varagnolo, G. Pillonetto, L. Schenato, Distributed parametric and nonparametric regression
with on-line performance bounds computation. Automatica 48(10), 2468–2481 (2012)
50. M. Jadaliha, J. Lee, J. Choi, Adaptive control of multiagent systems for ﬁnding peaks of
uncertain static ﬁelds. J. Dyn. Syst. Meas. Control 134(5) (2012)
51. C.-H. Moeng, A large-eddy-simulation model for the study of planetary boundary-layer tur-
bulence. J. Atmos. Sci. 41(13), 2052–2062 (1984)
52. N. Cressie, Kriging nonstationary data. J. Am. Stat. Assoc. 81(395), 625–634 (1986)
53. C.E. Rasmussen, C.K.I. Williams, Gaussian Processes for Machine Learning (The MIT Press,
Cambridge, 2006)
54. California partners for advanced transit and highways. http://www.path.berkeley.edu. (2015)
55. P. Seiler, A. Pant, K. Hedrick, Disturbance propagation in vehicle strings. IEEE Trans. Autom.
Control 49(10), 1835–1842 (2004)
56. B. Zhang, G. Sukhatme, Adaptive sampling for estimating a scalar ﬁeld using a robotic boat
and a sensor network, in 2007 IEEE International Conference on Robotics and Automation
(IEEE, 2007), pp. 3673–3680
57. M. Jadaliha, J. Choi, Environmental monitoring using autonomous aquatic robots: sampling
algorithms and experiments. IEEE Trans. Control Syst. Technol. 21(3), 899–905 (2013)
58. Y. Wang, R. Tan, G. Xing, X. Tan, J. Wang, R. Zhou, Spatiotemporal aquatic ﬁeld reconstruc-
tion using robotic sensor swarm, in 2012 IEEE 33rd Real-Time Systems Symposium (2012)
59. B. Grocholsky, J. Keller, V. Kumar, G. Pappas, Cooperative air and ground surveillance. IEEE
Robot. Autom. Mag. 13(3), 16–25 (2006)
60. C. Tomlin, G.J. Pappas, S. Sastry, Conﬂict resolution for air trafﬁc management: a study in
multiagent hybrid systems. Autom. Control, IEEE Trans. 43(4), 509–521 (1998)
61. R.P. Anderson, E. Bakolas, D. Milutinovi´c, P. Tsiotras, Optimal feedback guidance of a small
aerial vehicle in a stochastic wind. J. Guid. Control Dyn. 36(4), 975–985 (2013)
62. M.M. Zavlanos, G.J. Pappas, Dynamic assignment in distributed motion planning with local
coordination. IEEE Trans. Robot. 24(1), 232–242 (2008)
63. M.M. Zavlanos, G.J. Pappas, Distributed connectivity control of mobile networks. IEEE
Trans. Rob. 24(6), 1416–1428 (2008)
64. A. Jadbabaie, J. Lin, A.S. Morse, Coordination of groups of mobile autonomous agents using
nearest neighbor rules. IEEE Trans. Autom. Control 48(6), 988–1001 (2003)

114
References
65. R. Olfati-Saber, Flocking for multi-agent dynamic systems: algorithms and theory. IEEE
Trans. Autom. Control 51(3), 401–420 (2006)
66. W. Ren, R.W. Beard, Consensus seeking in multiagent systems under dynamically changing
interaction topologies. IEEE Trans. Autom. Control 50(5), 655–661 (2005)
67. M. Mesbahi, M. Egerstedt, Graph theoretic methods in multiagent networks (Princeton Uni-
versity Press, Princeton, 2010)
68. F. Bullo, J. Cortés, S. Martínez, Distributed Control of Robotic Networks, Applied Mathe-
matics Series (Princeton University Press, Princeton, 2009)
69. R.M. Murray, Recent research in cooperative control of multivehicle systems. J. Dyn. Syst.
Meas. Control 129(5), 571–583 (2007)
70. Y. Cao, W. Yu, W. Ren, G. Chen, An overview of recent progress in the study of distributed
multi-agent coordination. IEEE Trans. Ind. Inf. 9(1), 427–438 (2013)
71. N. Cressie, Statistics for Spatial Data (A Wiley-Interscience Publication, John Wiley and
Sons Inc, New York, 1991)
72. T.M. Cover, J.A. Thomas, Elements of Information Theory, 2nd edn. (Wiley, Hoboken, 2006)
73. A. Singh, A. Krause, C. Guestrin, W. Kaiser, Efﬁcient informative sensing using multiple
robots. J. Artif. Intell. Res. 34(1), 707–755 (2009)
74. M. Gibbs, D.J.C. MacKay, Efﬁcient implementation of Gaussian processes (1997) http://
www.cs.toronto.edu/mackay/gpros.ps.gz
75. D.J.C. MacKay, Introduction to Gaussian processes. NATO ASI Ser. F Comput. Syst. Sci.
168, 133–165 (1998)
76. A. Krause, C. Guestrin, A. Gupta, J. Kleinberg, Near-optimal sensor placements: maximizing
information while minimizing communication cost, in Proceedings of the 5th International
Conference on Information Processing in Sensor Networks (2006), pp. 2–10
77. J. Choi, J. Lee, S. Oh, Biologically-inspired navigation strategies for swarm intelligence using
spatial Gaussian processes, in Proceedings of the 17th International Federation of Automatic
Control (IFAC) World Congress (2008)
78. J. Choi, J. Lee, S. Oh, Swarm intelligence for achieving the global maximum using spatio-
temporal Gaussian processes, in Proceedings of the 27th American Control Conference (ACC)
(2008)
79. A.J. Smola, P. Bartlett, Sparse greedy Gaussian process regression, in Advances in Neural
Information Processing Systems, 13 (2001)
80. C.K.I. Williams, M. Seeger, Using the Nyström method to speed up kernel machines, in
Advances in Neural Information Processing Systems, 13 (2001)
81. N. Lawrence, M. Seeger, R. Herbrich, Fast sparse Gaussian process methods: the informative
vector machine, in Advances in Neural Information (2003)
82. M. Seeger, Bayesian Gaussian process models: PAC-Bayesian generalisation error bounds
and sparse approximations. Ph.D. dissertation, School of Informatics, University of Edinburgh
(2003)
83. V. Tresp, A Bayesian committee machine. Neural Comput. 12(11), 2719–2741 (2000)
84. C.M. Bishop, Pattern Recognition and Machine Learning (Springer, New York, 2006)
85. M. Gaudard, M. Karson, E. Linder, D. Sinha, Bayesian spatial prediction. Environmental and
Ecological Statistics 6(2), 147–171 (1999)
86. H. Rue, H. Tjelmeland, Fitting Gaussian Markov random ﬁelds to Gaussian ﬁelds. Scand. J.
Stat. 29(1), 31–49 (2002)
87. N. Cressie, N. Verzelen, Conditional-mean least-squares ﬁtting of Gaussian Markov random
ﬁelds to Gaussian ﬁelds. Comput. Stat. Data Anal. 52(5), 2794–2807 (2008)
88. L. Hartman, O. Hössjer, Fast kriging of large data sets with Gaussian Markov random ﬁelds.
Comput. Stat. Data Anal. 52(5), 2331–2349 (2008)
89. J. Le Ny, G. Pappas, On trajectory optimization for active sensing in Gaussian process models,
in Decision and Control, 2009 Held Jointly with the 2009 28th Chinese Control Conference.
CDC/CCC 2009. Proceedings of the 48th IEEE Conference on, 2010, pp. 6286–6292
90. S.M. Kay, Fundamentals of Statistical Signal Processing: Estimation Theory. (Prentice Hall,
Inc., Upper Saddle River, 1993)

References
115
91. J. Quiñonero-Candela, C.E. Rasmussen, A unifying view of sparse approximate Gaussian
process regression. J. Mach. Learn. Res. 6, 1939–1959 (2005)
92. H. Rue, L. Held, Gaussian Markov Random Fields: Theory and Applications. (Chapman &
Hall, Upper Saddle River, 2005)
93. C.K.I.Williams,C.E.Rasmussen,Gaussianprocessesforregression.Adv.NeuralInf.Process.
Syst. 8, 514–520 (1996)
94. D.J. Nott, W.T.M. Dunsmuir, Estimation of nonstationary spatial covariance structure. Bio-
metrika 89(4), 819–829 (2002)
95. J.Q. Shi, T. Choi, Gaussian Process Regression Analysis for Functional Data (CRC Press,
New York, 2011)
96. J. Nocedal, S.J. Wright, Numerical Optimization (Springer, Berlin, 1999)
97. W.W. Hager, H. Zhang, A survey of nonlinear conjugate gradient methods. Pac. J. Optim.
2(1), 35–58 (2006)
98. M. Mandic, E. Franzzoli, Efﬁcient sensor coverage for acoustic localization, in Proceedings
of the 46th IEEE Conference on Decision and Control (2007), pp. 3597–3602
99. S. Martínez, F. Bullo, Optimal sensor placement and motion coordination for target tracking.
Automatica 42(4), 661–668 (2006)
100. F. Pukelsheimi, Optimal Design of Experiments (Wiley, New York, 1993)
101. A.F. Emery, A.V. Nenarokomov, Optimal experiment design. Meas. Sci. Technol. 9(6), 864–
876 (1998)
102. C.K.I. Williams, F. Vivarelli, Upper and lower bounds on the learning curve for Gaussian
processes. Mach. Learn. 40(1), 77–102 (2000)
103. P. Sollich, A. Halees, Learning curves for Gaussian process regression: approximations and
bounds. Neural Comput. 14(6), 1393–1428 (2002)
104. D.P. Bertsekas, W.W. Hager, O.L. Mangasarian, Nonlinear Programming (Athena Scientiﬁc,
Belmont, 1999)
105. G.M. Mathews, H. Durrant-Whyte, M. Prokopenko, Decentralised decision making in het-
erogeneous teams using anonymous optimisation. Robot. Auton. Syst. 57(3), 310–320 (2009)
106. W. Rudin, Principles of Mathematical Analysis (McGraw-Hill, New York, 1976)
107. C.R. Dietrich, G.N. Newsam, Fast and exact simulation of stationary Gaussian processes
through circulant embedding of the covariance matrix. SIAM J. Sci. Comput. 18(4), 1088–
1107 (1997)
108. S. Oh, Y. Xu, J. Choi, Explorative navigation of mobile sensor networks using sparse Gaussian
processes, in Proceedings of the 49th IEEE Conference on Decision and Control (CDC) (2010)
109. L. Devroye, Non-uniform Random Variate Generation (Springer, New York, 1986)
110. R. Olfati-Saber, R. Franco, E. Frazzoli, J.S. Shamma, Belief consensus and distributed hypoth-
esis testing in sensor networks, Networked Embedded Sensing and Control, pp. 169–182
(2006)
111. T. Gneiting, Compactly supported correlation functions. J. Multivar. Anal. 83(2), 493–508
(2002)
112. D.P. Bertsekas, J.N. Tsitsiklis, Parallel and Distributed Computation: Numerical Methods
(Prentice Hall, Englewood Cliffs, 1999)
113. R. Olfati-Saber, J.A. Fax, R.M. Murray, Consensus and cooperation in networked multi-agent
systems. Proceedings of the IEEE 95(1), 215–233 (2007)
114. H. Akaike, A new look at the statistical model identiﬁcation. IEEE Trans. Autom. Control
19(6), 716–723 (1974)
115. M. Corporation, Ofﬁcial website of Kinect for Xbox 360. http://www.xbox.com/en-US/kinect
116. F. Lindgren, H. Rue, J. Lindström, An explicit link between Gaussian ﬁelds and Gaussian
Markov random ﬁelds: the stochastic partial differential equation approach. J. R. Stat. Soc.:
Ser. B 73(4), 423–498 (2011)
117. H. Rue, S. Martino, N. Chopin, Approximate Bayesian inference for latent Gaussian models
by using integrated nested Laplace approximations. J. R. Stat. Soc.: Ser. B (Stat. Methodol.)
71(2), 319–392 (2009)
118. Y. Xu, J. Choi, S. Dass, T. Maiti, Bayesian prediction and adaptive sampling algorithms for
mobile sensor networks, in Proceedings of the 2011 American Control Conference (ACC)
(2011), pp. 4095–4200

