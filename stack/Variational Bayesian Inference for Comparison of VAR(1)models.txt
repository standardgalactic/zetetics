Variational Bayesian Inference for
Comparison of VAR(1) models
Adrian James Houghton
Thesis submitted for the degree of
Doctor of Philosophy
School of Mathematics and Statistics
University of Newcastle upon Tyne
Newcastle upon Tyne
United Kingdom
January 2009

Abstract
Suppose that we wish to determine which models in a candidate set are most likely to
have given rise to a set of observed data. Then, it is well-established that, from a Bayesian
viewpoint, evaluation of the marginal likelihood for each candidate is a crucial step to
this end. For the purposes of model comparison, this will enable subsequent computation
of both Bayesâ€™ factors and posterior model probabilities. Given its evident signiï¬cance
in this area, it is thus regrettable that analytic calculation of the marginal likelihood is
often not possible. To tackle this problem, one recent addition to the literature is the
variational Bayesian approach.
In this thesis, it is seen that variational Bayes provides eï¬ƒcient, accurate approximations
to both the marginal likelihood and the parameter posterior distribution, conditioned on
each model. In particular, the theory is applied to ranking sparse, vector autoregressive
graphical models of order 1 in both the zero and non-zero mean case. That is, our primary
aim is to estimate the unknown sparsity structure of the autoregressive matrix in the
process. Moreover, approximate, marginal posterior information about the coeï¬ƒcients of
this matrix is also of interest. To enable rapid exploration of higher-dimensional graphical
spaces, a Metropolis-Hastings algorithm is presented so that a random walk can be made
between neighbouring graphs. The scheme is then tested on both simulated and real
datasets of varying dimension.

Acknowledgements
Initially, I would like to express my gratitude to my supervisor, Darren Wilkinson, for his
exceptional guidance, expertise and endless patience in the midst of some rather repetitive
questioning during my time at Newcastle. Without his inï¬‚uence, this thesis would look
somewhat diï¬€erent. Thanks must also go to my advisor, Richard Boys, for providing
additional, insightful input.
Without the immense love, support and encouragement of my mum and dad, I would
never have got to where I am today. For that, I will always be greatly appreciative. I also
extend these words to the rest of my family.
High praise is reserved for all my friends, in particular those within the Department of
Statistics, who have always helped me in times of crisis, provided great encouragement
and cheered me up with humour of ï¬ne quality.
Finally, I would like to acknowledge the ï¬nancial support of the Engineering and Physical
Sciences Research Council.

Contents
1
Introduction
1
1.1
A Bayesian perspective . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
2
1.1.1
Bayesâ€™ Factors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
6
1.2
Approximation of the marginal likelihood . . . . . . . . . . . . . . . . . . .
14
1.2.1
Laplaceâ€™s approximation . . . . . . . . . . . . . . . . . . . . . . . .
15
1.2.2
Bayesian Information Criterion (BIC) . . . . . . . . . . . . . . . . .
16
1.3
Further criteria . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
18
1.3.1
Akaikeâ€™s Information Criterion (AIC) . . . . . . . . . . . . . . . . .
19
1.3.2
Deviance Information Criterion (DIC)
. . . . . . . . . . . . . . . .
20
1.4
Outline of thesis and literature review . . . . . . . . . . . . . . . . . . . . .
22
2
Variational Bayes
25
2.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
25
2.2
Markov chain Monte Carlo . . . . . . . . . . . . . . . . . . . . . . . . . . .
26

CONTENTS
2.2.1
The Gibbs sampler . . . . . . . . . . . . . . . . . . . . . . . . . . .
26
2.2.2
Metropolis-Hastings algorithm . . . . . . . . . . . . . . . . . . . . .
27
2.3
Expectation-Maximisation (EM) algorithm . . . . . . . . . . . . . . . . . .
30
2.4
Variational Bayesian methods . . . . . . . . . . . . . . . . . . . . . . . . .
31
2.4.1
Kullback-Leibler divergence
. . . . . . . . . . . . . . . . . . . . . .
32
2.4.2
Deï¬nition of L(q) . . . . . . . . . . . . . . . . . . . . . . . . . . . .
33
2.4.3
Approximating the marginal likelihood . . . . . . . . . . . . . . . .
34
2.4.4
Computation of L(q) . . . . . . . . . . . . . . . . . . . . . . . . . .
35
2.5
A univariate example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
37
2.5.1
Free form variational method
. . . . . . . . . . . . . . . . . . . . .
39
2.5.2
Fixed form variational method . . . . . . . . . . . . . . . . . . . . .
44
2.5.3
The Gibbs sampler . . . . . . . . . . . . . . . . . . . . . . . . . . .
49
2.5.4
EM algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
50
2.5.5
A numerical example . . . . . . . . . . . . . . . . . . . . . . . . . .
52
2.6
A multivariate example . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
54
2.7
Summary
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
61
3
Model comparison of VAR(1) models
62
3.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
62
3.2
VAR(1) graphical models . . . . . . . . . . . . . . . . . . . . . . . . . . . .
63

CONTENTS
3.2.1
Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
66
3.3
Scoring zero mean VAR(1) graphical models . . . . . . . . . . . . . . . . .
68
3.3.1
Priors
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
71
3.3.2
Free form method . . . . . . . . . . . . . . . . . . . . . . . . . . . .
73
3.3.3
Fixed form method . . . . . . . . . . . . . . . . . . . . . . . . . . .
79
3.4
Other issues . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
90
3.4.1
Problems with computation . . . . . . . . . . . . . . . . . . . . . .
90
3.4.2
Speciï¬cation of priors . . . . . . . . . . . . . . . . . . . . . . . . . .
92
3.5
Toy example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
95
4
Searching the graphical space
99
4.1
Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
99
4.2
Hill-climbing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 100
4.2.1
Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 102
4.3
Random walks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 104
4.3.1
Implementation and analysis . . . . . . . . . . . . . . . . . . . . . . 114
4.3.2
Examples
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 120
4.3.3
Prior sensitivity . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 130
4.3.4
Small sample size . . . . . . . . . . . . . . . . . . . . . . . . . . . . 135
4.3.5
A further example
. . . . . . . . . . . . . . . . . . . . . . . . . . . 137
i

CONTENTS
4.3.6
Application to ERP data . . . . . . . . . . . . . . . . . . . . . . . . 140
4.3.7
Application to microarray data
. . . . . . . . . . . . . . . . . . . . 152
4.4
Summary
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 155
5
Generalisation to non-zero mean VAR(1) models
157
5.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 157
5.2
Scoring non-zero mean VAR(1) models . . . . . . . . . . . . . . . . . . . . 158
5.2.1
Priors
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 160
5.2.2
Free form method . . . . . . . . . . . . . . . . . . . . . . . . . . . . 160
5.2.3
Fixed form method . . . . . . . . . . . . . . . . . . . . . . . . . . . 174
5.3
Toy example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 181
5.4
Taking a random walk . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 184
5.4.1
Examples
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 185
5.4.2
Application to ERP data . . . . . . . . . . . . . . . . . . . . . . . . 196
5.4.3
Application to microarray data
. . . . . . . . . . . . . . . . . . . . 202
6
Conclusions and further work
209
6.1
Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 209
6.2
Further work
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 211
A Probability distributions
213
ii

CONTENTS
A.1 Gaussian distribution . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 213
A.2 Inverse gamma distribution
. . . . . . . . . . . . . . . . . . . . . . . . . . 214
A.3 Multivariate Gaussian distribution
. . . . . . . . . . . . . . . . . . . . . . 214
A.4 Inverse Wishart distribution . . . . . . . . . . . . . . . . . . . . . . . . . . 215
B Graphical Models
216
B.1 Conditional Independence
. . . . . . . . . . . . . . . . . . . . . . . . . . . 216
B.2 Graph theory . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 217
B.3 Undirected graphical models . . . . . . . . . . . . . . . . . . . . . . . . . . 218
B.3.1
Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 220
B.4 Bayesian networks
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 221
B.4.1
Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 222
C Generalised inverses
224
iii

List of Tables
3.1
Lower bounds and posterior means for each zero mean VAR(1) model . . .
98
4.1
Comparing the accuracy of Ë†Î  for each choice of c
. . . . . . . . . . . . . . 132
4.2
Comparing the accuracy of Ë†Î  for each choice of p
. . . . . . . . . . . . . . 134
4.3
Comparing the accuracy of Ë†Î  for each choice of N . . . . . . . . . . . . . . 136
4.4
Genes examined in the microarray experiment . . . . . . . . . . . . . . . . 153
5.1
Lower bounds and posterior means for each non-zero mean VAR(1) model
183
iv

List of Figures
2.1
(a) and (b): Approximate marginal posterior distributions for m and v
respectively, using variational Bayes, the EM algorithm and the Gibbs
sampler; (c) and (d): Corresponding trace plots for m and v produced
by the Gibbs sampler . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
54
2.2
Contour plots for: (a) Variational posterior, (b) True posterior . . . . . . .
55
3.1
Time series graph for a VAR(1) model
. . . . . . . . . . . . . . . . . . . .
67
3.2
Causality graph for the VAR(1) process . . . . . . . . . . . . . . . . . . . .
67
3.3
A-graph for the true zero mean VAR(1) model . . . . . . . . . . . . . . . .
95
4.1
Convergence of hill-climbing algorithm for diï¬€erent, initial graphs . . . . . 103
4.2
A simple graph on which to make a random walk
. . . . . . . . . . . . . . 105
4.3
Plots for the analysis of the MCMC output in Example 1 . . . . . . . . . . 121
4.4
Plots showing estimated, marginal posterior distributions for aij, i, j =
1, 2, 3, in Example 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 124
4.5
Plots for the analysis of the MCMC output in Example 2 . . . . . . . . . . 125
v

LIST OF FIGURES
4.6
Plots showing estimated, marginal posterior distributions for aij, i, j =
1, 2, 3, in Example 2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 127
4.7
Plots for the analysis of the MCMC output in Example 3 . . . . . . . . . . 128
4.8
Plots showing estimated, marginal posterior distributions for aij, i, j =
1, 2, 3, in Example 3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 129
4.9
Plots of Ë†Î  for diï¬€erent speciï¬cations of c: (a) c = 10, 000, (b) c = 10, (c)
c = 0.5, (d) c = 0.1, (e) c = 0.01, (f) c = 0.001 . . . . . . . . . . . . . . . . 132
4.10 Plots of Ë†Î  for diï¬€erent speciï¬cations of p: (a) p = 0.95, (b) p = 0.855, (c)
p = 0.5, (d) p = 0.3, (e) p = 0.1 . . . . . . . . . . . . . . . . . . . . . . . . 134
4.11 Plots of Ë†Î  for diï¬€erent speciï¬cations of N: (a) N = 100, (b) N = 80, (c)
N = 50, (d) N = 20, (e) N = 10 . . . . . . . . . . . . . . . . . . . . . . . . 136
4.12 Plots for the analysis of the MCMC output in Example 4.3.5 . . . . . . . . 138
4.13 Plots showing estimated, marginal posterior distributions for aij, i, j =
1, 2, 3 in Example 4.3.5
. . . . . . . . . . . . . . . . . . . . . . . . . . . . 141
4.14 Animal ERP data for one subject . . . . . . . . . . . . . . . . . . . . . . . 144
4.15 Distractor ERP data for one subject
. . . . . . . . . . . . . . . . . . . . . 145
4.16 Plots for the analysis of the MCMC output for the animal ERP data
. . . 147
4.17 Plots for the analysis of the MCMC output for the distractor ERP data . . 148
4.18 Plots showing estimated, marginal posterior distributions for aij, i, j =
1, 2, 3, for the animal ERP data . . . . . . . . . . . . . . . . . . . . . . . . 151
4.19 Plots showing estimated, marginal posterior distributions for aij, i, j =
1, 2, 3, for the distractor ERP data . . . . . . . . . . . . . . . . . . . . . . 152
vi

LIST OF FIGURES
4.20 Plots for the analysis of the MCMC output for the microarray data . . . . 153
4.21 Plots showing estimated, marginal posterior distributions for aij, i, j =
1, 2, 3, for the microarray data
. . . . . . . . . . . . . . . . . . . . . . . . 155
5.1
Plots for the analysis of the MCMC output in Example 1 (non-zero mean) 186
5.2
Plots showing estimated, marginal posterior distributions for aij, i, j =
1, 2, 3, in Example 1 (non-zero mean) . . . . . . . . . . . . . . . . . . . . . 188
5.3
Plots showing estimated, marginal posterior distributions for Î¼j, j = 1, . . . , 6,
in Example 1
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 189
5.4
Plots for the analysis of the MCMC output in Example 2 (non-zero mean) 190
5.5
Plots showing estimated, marginal posterior distributions for aij, i, j =
1, 2, 3, in Example 2 (non-zero mean) . . . . . . . . . . . . . . . . . . . . . 192
5.6
Plots showing estimated, marginal posterior distributions for Î¼j, j = 1, . . . , 6,
in Example 2
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 193
5.7
Plots for the analysis of the MCMC output in Example 3 (non-zero mean) 194
5.8
Plots showing estimated, marginal posterior distributions for aij, i, j =
1, 2, 3, in Example 3 (non-zero mean) . . . . . . . . . . . . . . . . . . . . . 195
5.9
Plots showing estimated, marginal posterior distributions for Î¼j, j = 1, . . . , 6,
in Example 3
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 196
5.10 Plots for the analysis of the MCMC output for the animal ERP data (non-
zero mean) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 197
5.11 Plots for the analysis of the MCMC output for the distractor ERP data
(non-zero mean) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 198
vii

LIST OF FIGURES
5.12 Plots showing estimated, marginal posterior distributions for aij, i, j =
1, 2, 3, for the animal ERP data (non-zero mean) . . . . . . . . . . . . . . 200
5.13 Plots showing estimated, marginal posterior distributions for aij, i, j =
1, 2, 3, for the distractor ERP data (non-zero mean)
. . . . . . . . . . . . 201
5.14 Plots showing estimated, marginal posterior distributions for Î¼j, j = 1, . . . , 6,
for the animal ERP data . . . . . . . . . . . . . . . . . . . . . . . . . . . . 203
5.15 Plots showing estimated, marginal posterior distributions for Î¼j, j = 1, . . . , 6,
for the distractor ERP data
. . . . . . . . . . . . . . . . . . . . . . . . . . 204
5.16 Plots for the analysis of the MCMC output for the microarray data (non-
zero mean) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 205
5.17 Plots showing estimated, marginal posterior distributions for aij, i, j =
1, 2, 3, for the microarray data (non-zero mean) . . . . . . . . . . . . . . . 207
5.18 Plots showing estimated, marginal posterior distributions for Î¼j, j = 1, . . . , 6,
for the microarray data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 208
B.1 4-node graph, corresponding to the choice of K
. . . . . . . . . . . . . . . 220
B.2 6-node DAG . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 222
viii

Chapter 1
Introduction
Suppose that we possess an observed dataset, which has been generated by an incom-
pletely understood underlying process. Then, an important statistical problem is to ï¬nd
a model that explains the inherent trends in the data well. In this case, such a model
can subsequently be utilised to make reasonably accurate, future predictions. In real life
situations, it is customarily the case that there will be a huge number of complicated
factors that will aï¬€ect the generation of the data. Thus, a standard philosophy to follow
is that a model is merely an approximation to the mechanism giving rise to the data.
Assume we now have a collection of possible models in competition, referred to as a
candidate set. Then, the model selection task is to choose the â€˜bestâ€™ model in the set, given
the data. That is, we ideally require the model that forms the most suitable representation
of the reality. Unfortunately, the procedure is non-trivial. It is valid to ask at this stage
what constitutes such a selection. For instance, a suï¬ƒciently complex model (with many
parameters) will be able to provide a good ï¬t, i.e. the underlying trends will be well
reï¬‚ected. Else, the model is said to underï¬t the data. So, the ï¬t in a simple model can
be improved by adding extra parameters and will be equivalent to before if these new
parameters are set to zero.
1

1.1. A Bayesian perspective
However, as Beal (2003) indicates, model ï¬t alone is an unsatisfactory criterion for choos-
ing between models. In any model, by its deï¬nition of being an approximation, it will be
practically infeasible to capture exactly each factor that has given rise to the data. Hence,
we refer to these factors as noise. A suï¬ƒciently complex model, with its exceptional ï¬‚ex-
ibility, can be made to produce an exact ï¬t. However, this is not because the trends are
being accurately approximated, but instead the noise is being absorbed into the model.
That is, an excessive number of parameters will resultantly ï¬t the noise in the data. So,
although such a model may be the best ï¬tting in a candidate set given a dataset, it will
provide inadequate predictions of future observations, generated by the same truth, as
the noise will vary in these new observations. In this case, the model is said to overï¬t the
data.
To summarise, by choosing the most complex model in a candidate set, we are not precisely
approximating the intangible reality. Instead, there is a necessary trade-oï¬€to be made
between the ï¬t of a model to a particular dataset and its complexity, in terms of how well
it predicts new observations. These issues are at the forefront for any technique used to
select a model given observed data. In this chapter, some of these established methods
are presented. In particular, we focus primarily on how a Bayesian tackles the model
comparison dilemma.
1.1
A Bayesian perspective
Let M = {M1, . . . , MR} be a set of R candidate models, where each model is a probability
distribution. Given the observation of data D, we want to compare the credibility of
these candidates. To eï¬€ect this, the fundamentals of the Bayesian approach to model
comparison are now examined, illustrated by, inter alia, Kass and Raftery (1995) and
Chipman et al. (2001). We ï¬rst require some initial deï¬nitions. If Î¸i = (Î¸i1, . . . , Î¸id)T is
a set of unknown parameters speciï¬c to model Mi, then let p(D | Î¸i, Mi) be the probability
2

1.1. A Bayesian perspective
density function of D given the value of Î¸i (also referred to as the likelihood function for
Î¸i).
A Bayesian framework dictates the introduction of priors on all unknowns. Thus, in this
case, let p(Î¸i | Mi) be the prior distribution over the parameters of each model. Moreover,
we suppose that p(Mi) is the prior probability assigned to each model itself. Upon the
observation of data D, we are able to update our prior beliefs about the probability of
each model. Thus, by Bayesâ€™ Theorem, the posterior probability of model Mi is given by
p(Mi | D) = p(D | Mi) p(Mi)
p(D)
,
(1.1)
where the probability of the data, a normalising constant, is equivalent to
p(D) =

i
p(D | Mi) p(Mi).
Moreover, the term p(D | Mi) is referred to as the marginal likelihood of data D given
model Mi, such that
p(D | Mi) =

p(D | Î¸i, Mi) p(Î¸i | Mi) dÎ¸i.
(1.2)
It is so named since we marginalise, or integrate, over the model parameter space.
We realise that the model posterior, p(Mi | D), is a valuable tool to possess when choosing
between models. If our task were to pick the most plausible model, we can easily choose
that which maximises the value of the posterior probability. So, we can interpret p(Mi | D)
as the probability that the model Mi is the mechanism that generated the data initially.
In other words, this posterior expresses our beliefs, hence quantiï¬es our uncertainty,
about each model after the observation of data. Furthermore, we can derive a posterior
3

1.1. A Bayesian perspective
distribution for the parameters, speciï¬c to each model. This is expressed as
p(Î¸i | D, Mi) = p(D | Î¸i, Mi) p(Î¸i | Mi)
p(D | Mi)
.
(1.3)
Upon examination of (1.1) and (1.3), it is noted that computation of the marginal like-
lihood enables calculation of not only the posterior over models, but also the posterior
over parameters. We shall make a further comment on this relationship in due course.
We now turn to the question of specifying a prior over the set of models, namely p(Mi);
the same procedure for p(Î¸i | Mi) is examined in Section 1.1.1. In both cases however,
as noted by Chipman et al. (2001), there are two approaches to consider. On the one
hand, we could adopt subjective priors, representing our own personal knowledge or beliefs
about the unknowns before data is observed. Although a nice proposal, this framework is
most idealistic, especially if there are many candidate models in our set, each with high-
dimensional parameters Î¸i, and we must somehow quantify our information as probability
distributions.
Therefore, a pragmatic Bayesian approach is adopted here. In this case, priors are con-
structed whereby little or even no prior knowledge is available, hence not aï¬€ecting the
construction of the posterior. Such priors are described as being broad, ï¬‚at, diï¬€use or
vague (Gelman et al., 1995). So, as regards speciï¬cation of a model prior, a straightfor-
ward procedure is to make all models equally plausible, hence representing prior ignorance.
Thus, if there are R candidates in our model set M, our prior could be
p(Mi) = 1
R.
(1.4)
The above prior follows a (discrete) uniform distribution, whereby each model has been
awarded the same prior probability. An interesting point to notice is that, upon using
this prior, (1.1) will simplify such that p(Mi | D) âˆp(D | Mi) as the model prior cancels.
4

1.1. A Bayesian perspective
Hence, on this basis, the model posterior is computed up to a multiplicative constant, and
thus the marginal likelihood can be viewed as the evidence for each model. By deï¬nition,
it is the average probability of the data for a given model, with respect to the prior
distribution.
As discussed previously in this chapter, it is critical to ï¬nd a technique to compare models
fairly so that more complex models are penalised suï¬ƒciently. The marginal likelihood is
able to eï¬€ect this since, by its deï¬nition, it naturally integrates out parameters. Thus, it
embodies the principle of Occamâ€™s razor, which states, in general, that a simpler model
for the data is preferred over a more complex alternative.
MacKay (1995b) and Beal (2003) discuss this aspect of Bayesian model comparison. Sup-
pose that we have two competing models, Mk and Ml, the former being a simple model
and the latter a more complex oï¬€ering. Consider the space of all datasets of size N. As
Ml will possess additional parameters due to its relative, extra complexity, it will be able
to model a wider range of datasets than its simpler counterpart, Mk.
For every dataset, the corresponding marginal likelihood for each model can be computed
to assess which is the most plausible. Yet, the marginal likelihood over datasets must
integrate to 1. Consequently, Ml, although capable of modelling a plethora of datasets,
can assign only small marginal likelihoods to each. On the contrary, Mk can award a
higher marginal likelihood value to the limited number of datasets that it can model.
Thus, if it is possible for a particular dataset D to be modelled by both Mk and Ml,
then p(D | Mk) > p(D | Ml) and the simpler structure is hence favoured. Initially, this
phenomenon was displayed diagrammatically in Section 1.3 of MacKay (1995b).
Unfortunately, despite its importance in model comparison, calculation of the marginal
likelihood via (1.2) is diï¬ƒcult since the integral could be intractable (e.g. if Î¸i is high-
dimensional as we integrate over the model parameters). Analytic computation of this
quantity is rare. Therefore, a good approximation to this quantity is desirable and tech-
5

1.1. A Bayesian perspective
niques that enable this will be presented later in this chapter. At the present time however,
we now illustrate its signiï¬cance in model comparison.
1.1.1
Bayesâ€™ Factors
Kass and Raftery (1995) elucidated a simple, but elegant criterion for comparing models
in the Bayesian framework, called a Bayesâ€™ factor. Assume that we have two models, say
Mk and Ml, and we want to discover which is the most plausible, given data D. As above,
we specify prior probabilities over the models, namely p(Mk) and p(Ml). For subsequent
interpretation purposes, we choose to work on the odds scale.
In general, recall that, if the probability of an event occurring is p, then the odds, o, in
favour of such an event is given by
o =
p
1 âˆ’p.
(1.5)
This is customarily written as 1 : o. Hence currently, the prior odds in favour of Mk are
p(Mk)
1 âˆ’p(Mk),
where, moreover, the denominator is equal to p(Ml). Then, by use of (1.1), it is evident
that the ratio of posteriors, or posterior odds of Mk, is equivalent to
p(Mk | D)
p(Ml | D) = p(D | Mk)
p(D | Ml)
p(Mk)
p(Ml) ,
(1.6)
where, of course, p(Ml | D) = 1âˆ’p(Mk | D). Then, the Bayesâ€™ factor for model Mk against
model Ml is deï¬ned as
Bkl = p(D | Mk)
p(D | Ml) .
(1.7)
6

1.1. A Bayesian perspective
As hinted at previously, calculation of Bkl is dependent on the two marginal likelihoods.
Moreover, the Bayesâ€™ factor is seen to be the ratio of the posterior odds of Mk to its prior
odds, and can be interpreted as the evidence provided by the data in favour of Mk com-
pared to Ml. Thus, for instance, if Bkl = 1, we are indiï¬€erent between the two models. If
Bkl > 1, then model Mk is preferred, otherwise model Ml. A more deï¬nitive interpreta-
tion is provided by Kass and Raftery. Here, the authors oï¬€er a guideline whereby values
of Bkl > 100 indicate decisive evidence in favour of Mk. Conversely, if approximately
1 < Bkl < 3, then the preference for Mk over Ml is small.
There is no doubt that Bayesâ€™ factors are straightforward and easy to interpret, by quanti-
fying our preference for one model over another. However, they are certainly not infallible.
Initially, we mention two general criticisms. Kass and Raftery adopt the stance that eval-
uation of the Bayesâ€™ factor is made to determine which of the two models is correct. As the
authors themselves identity, many would dispute this claim from a couple of viewpoints.
Firstly, as discussed above, a model is only an approximation to the truth. Moreover, by
examining only two models, we may ultimately choose a poor model, only since it repre-
sents the data better than an even worse model. A second criticism is that computation
of the Bayesâ€™ factor can be arduous due to its reliance on the marginal likelihood, a point
already illuminated. This is exacerbated if the size of the candidate set is large.
The ï¬nal problem that is raised is the most speciï¬c and perhaps that which has caused
most debate in the literature. It is concerned with prior speciï¬cation of the parameters.
This is elucidated, for instance, by Oâ€™Hagan (1995) and we now follow this authorâ€™s
explanation. Of course, to calculate a Bayesâ€™ factor, p(Î¸i | Mi) must be speciï¬ed (c.f.
(1.2)). Suppose we want to represent prior ignorance (also referred to as vague prior
knowledge) for our parameters. For instance, to express each value of Î¸i as equally likely
a priori, we could employ a (continuous) uniform distribution (c.f. (1.4)). Yet, if the
parameter space is inï¬nite, this distribution is no longer deï¬ned since it possesses only
7

1.1. A Bayesian perspective
ï¬nite support. Hence, we could use an improper uniform prior given as
p(Î¸i | Mi) âˆ1.
(1.8)
Clearly, no particular value of Î¸i is favoured since the prior mass is spread equally across
all values. However, the distribution is now improper since

p(Î¸i | Mi)dÎ¸i (representing
the total probability mass) diverges and is not equal to one. Thus, any improper prior will
contain no normalising constant. A further example of an improper, vague prior is the
Jeï¬€reysâ€™ prior. Such a choice is characterised by its invariance under reparameterisation,
i.e. the vagueness of a prior on Î¸i is maintained upon transformation of this parameter
vector. So, in this case, prior ignorance is represented by the distribution p(Î¸i | Mi) âˆ
|I(Î¸i | Mi)|
1
2, where I(Î¸i | Mi) is Fisherâ€™s information matrix. For more details, see, for
instance, Gelman et al. (1995). We note that the use of improper priors to represent
prior ignorance is common and often provide an easy Bayesian update from prior to
posterior distribution. They are particularly useful when there is diï¬ƒculty in attempting
to quantify oneâ€™s prior uncertainty in a distribution. Yet, their use is the only way that
an improper posterior may be produced.
Now, generalise (1.8) such that
p(Î¸i | Mi) âˆfi(Î¸i | Mi),
(1.9)
where fi is any known function whose integral does not converge. For instance, this could
be the Jeï¬€reysâ€™ prior. Thus, it follows that p(Î¸i | Mi) = cifi(Î¸i | Mi) for some unspeciï¬ed
constant ci. Of course, this normalising constant does not exist due to the divergence of
the integral. Then, the parameter posterior is
p(Î¸i | D, Mi) =
p(D | Î¸i, Mi) fi(Î¸i | Mi)

p(D | Î¸i, Mi) fi(Î¸i | Mi) dÎ¸i
.
(1.10)
8

1.1. A Bayesian perspective
This distribution is well-deï¬ned, assuming the integral for the marginal likelihood is con-
vergent, since the constants ci have cancelled. Yet, if the models Mk and Ml are given
improper priors similar to (1.9), then the corresponding Bayesâ€™ factor is, by deï¬nition,
equivalent to
Bkl = ck
cl

p(D | Î¸k, Mk) fk(Î¸k | Mk) dÎ¸k

p(D | Î¸l, Ml) fl(Î¸l | Ml) dÎ¸l
.
(1.11)
Unfortunately, the constants now do not cancel and so the Bayesâ€™ factor contains a ratio of
two unknown constants. This dilemma has caused much consternation amongst Bayesian
statisticians.
If improper priors are to be persisted with to represent ignorance, then
solutions have been sought in the literature. Two of the most common are now presented.
Fractional Bayesâ€™ factors
To remove the dependence on ck
cl from the usual Bayesâ€™ factor in the case of improper
priors, Oâ€™Hagan (1991, 1995) suggested a new variant. Suppose again we wish to compare
the models Mk and Ml. Initially, partition the data such that D = (D1, D2). The portions,
D1 and D2, are now employed for two separate purposes: D1, known as a training sample,
is used to learn the parameters Î¸k and Î¸l, and D2 to compare Mk and Ml in a Bayesâ€™
factor.
Thus, it is simple to form parameter posterior distributions through D1, p(Î¸i | D1, Mi) for
i = k, l, using (1.3). Then, the Bayesian paradigm is implemented in a sequential way so
that these parameter posteriors become prior distributions in the wake of the new data
D2, hence resulting in a Bayesâ€™ factor calculation. So, Oâ€™Hagan (1995) deï¬nes the partial
Bayesâ€™ factor for model Mk against model Ml using data D2, conditional on D1, as
Bkl(D2 | D1) = p(D2 | D1, Mk)
p(D2 | D1, Ml)
(1.12)
9

1.1. A Bayesian perspective
=

p(D2 | Î¸k, D1, Mk) p(Î¸k | D1, Mk) dÎ¸k

p(D2 | Î¸l, D1, Ml) p(Î¸l | D1, Ml) dÎ¸l
.
(1.13)
Here, the probability density for D2, namely p(D2 | Î¸i, D1, Mi) for i = k, l, is dependent
on the parameters and the dataset D1, itself previously utilised to learn the parame-
ters.
Even if the initial priors, p(Î¸k | Mk) and p(Î¸l | Ml), are chosen as improper, the
sequential updating of posterior to prior implies that the new â€˜priorsâ€™, p(Î¸k | D1, Mk) and
p(Î¸l | D1, Ml), are proper and any unspeciï¬ed constants have cancelled using (1.10). The
partial Bayesâ€™ factor is so-called as comparison of the models requires only a portion of
the data, hence diï¬€ering from the full Bayesâ€™ factor, and is well-deï¬ned.
This partial Bayesâ€™ factor can now subsequently be used to construct a full Bayesâ€™ factor,
incorporating all data D. In this case, the marginal likelihood of D2 under Mi, conditioned
on D1, is simply
p(D2 | D1, Mi) = p(D1, D2 | Mi)
p(D1 | Mi)
=

p(D | Î¸i, Mi) p(Î¸i | Mi) dÎ¸i

p(D1 | Î¸i, Mi) p(Î¸i | Mi) dÎ¸i
.
(1.14)
Then, it is evident that
p(D | Mk)
p(D | Ml) = p(D1 | Mk)
p(D1 | Ml)
p(D2 | D1, Mk)
p(D2 | D1, Ml)
and so, by deï¬nition of Bayesâ€™ factors,
Bkl(D) = Bkl(D1)Bkl(D2 | D1).
(1.15)
10

1.1. A Bayesian perspective
By assigning the prior distribution (1.9) for the parameters speciï¬c to each model, it
follows from (1.11) that the term
ck
cl is common in the deï¬nition of both the Bayesâ€™
factors, Bkl(D) and Bkl(D1). Hence, this ratio of unspeciï¬ed constants cancels from both
sides of (1.15). Thus, Bkl(D) is now well-deï¬ned, as intended. Theoretically, the partial
Bayesâ€™ factor would appear to possess a solid foundation. Yet, in practice, although no-
longer dependent on any unspeciï¬ed constants, it remains reliant on choosing a training
sample of size m from a total of N observations, so that the parameters may be learnt
(there are
N
m

ways to do this). To avert the selection of such a dataset D1, Oâ€™Hagan
makes an asymptotic approximation to the partial Bayesâ€™ factor.
If we deï¬ne b = m
N and then let both m and N become large, then an approximation is
obtained such that
p(D1 | Î¸i, Mi) â‰ˆ[p(D | Î¸i, Mi)]b ,
where D1 and D are datasets with m and N observations respectively. Thus, by con-
sideration of (1.14), an alternative marginal likelihood for D under model Mi is given
as
pb(D | Mi) =

p(D | Î¸i, Mi) p(Î¸i | Mi) dÎ¸i

[p(D | Î¸i, Mi)]b p(Î¸i | Mi) dÎ¸i
.
(1.16)
Hence ï¬nally, motivated by (1.12), the fractional Bayesâ€™ factor, denoted as Bb
kl(D), is
equivalent to
Bb
kl(D) = pb(D | Mk)
pb(D | Ml) .
(1.17)
It is apparent that, if we choose a prior over the parameters that is improper, any un-
speciï¬ed constants will now cancel in (1.16), and hence the fractional Bayesâ€™ factor will
be well-deï¬ned. Yet, one outstanding issue still remains. Although there is no need to
speciï¬cally choose a training dataset D1, we must however specify the proportion, b, of
D1. This is the main problem with fractional Bayesâ€™ factors and is discussed further in
11

1.1. A Bayesian perspective
Oâ€™Hagan (1995). On face value, it appears that the method has replaced one problem
(the unspeciï¬ed ratio ck
cl ) with another (how to select a value for b).
Posterior Bayesâ€™ Factors
An alternative framework in the context of using Bayesâ€™ factors with improper priors is
developed by Aitkin (1991). Again, the author is able to construct a methodology, which
removes the dependence of any unspeciï¬ed constants in the comparison of the models
Mk and Ml. Firstly, reconsider (1.2), representing the marginal likelihood of the data D,
given model Mi. As noted previously, an alternative perspective shows that this equation
can also be viewed as the prior mean of the density function.
Consequently, Aitkin suggests that when comparing models, to avert the dilemma caused
by arbitrary constants, we can average the density, p(D | Î¸i, Mi), with respect to the
parameter posterior distribution, p(Î¸i | D, Mi), instead of the corresponding prior. This
seems reasonable since, via (1.10), this posterior is well-deï¬ned. Thus, the posterior mean
of the likelihood is deï¬ned as
ppost(D | Mi) =

p(D | Î¸i, Mi) p(Î¸i | D, Mi) dÎ¸i.
(1.18)
So, a posterior Bayesâ€™ factor for model Mk against model Ml is then deï¬ned as
Bpost
kl
= ppost(D | Mk)
ppost(D | Ml) .
(1.19)
Notably, the posterior Bayesâ€™ factor is extremely similar in form to the partial Bayesâ€™
factor in (1.13), the diï¬€erence being the latter is dependent on the partition of the data
for the purposes of both parameter learning and model comparison. The derivation of
both has required a sequential use of Bayesâ€™ theorem whereby the parameter posterior
12

1.1. A Bayesian perspective
has subsequently been applied as a well-deï¬ned prior distribution for model comparison.
In fact, by substituting in for the parameter posterior, (1.18) can be rewritten as
ppost(D | Mi) =

[p(D | Î¸i, Mi)]2 p(Î¸i | Mi) dÎ¸i

p(D | Î¸i, Mi) p(Î¸i | Mi) dÎ¸i
.
(1.20)
When studying (1.16) and (1.20), now notice the similarity between the fractional and
posterior Bayesâ€™ factors. Thus, akin to before, any outstanding, unspeciï¬ed constants
will cancel from (1.20) and so leave a well-deï¬ned Bayesâ€™ factor. A consistent criticism of
posterior Bayesâ€™ factors is the use of the data â€˜twiceâ€™ for learning parameters and model
comparison, which, as illustrated above, is the signiï¬cant diï¬€erence between partial and
posterior Bayesâ€™ factor methodology. Such a practice lacks any logical foundation. More-
over, it has been shown by Lindley (1991) that the method can be viewed as incoherent
via a counter-example.
To summarise this section, the use of Bayesâ€™ factors for the purpose of model comparison
can become problematic when improper priors are used to illustrate prior ignorance. In
response, Oâ€™Hagan (1995) and Aitkin (1991) have independently constructed solutions
to remove the ratio of unspeciï¬ed constants, as seen in (1.11). A further technique is
developed in Berger and Pericchi (1996), producing a so-called intrinsic Bayesâ€™ factor.
Using a similar, initial foundation to Oâ€™Hagan, the authors reason that, to avoid specifying
a training sample D1, partial Bayesâ€™ factors should be computed for all training samples
and the result then averaged.
A sensible question to ask at this stage is whether it is even necessary to use improper
priors to represent prior ignorance. A clear, simple alternative is to specify a proper prior
distribution (so integrates to 1), which is not concentrated around any one particular
value. In other words, we require a prior with a reasonable variance. If both p(Î¸k | Mk)
and p(Î¸l | Ml) are speciï¬ed as proper, then calculation of the Bayesâ€™ factor is theoretically
13

1.2. Approximation of the marginal likelihood
possible and no dependence on arbitrary constants, seen in (1.11), exists.
Unfortunately, the use of proper, diï¬€use priors in these circumstances is dangerous since
the Bayesâ€™ factor may be highly dependent on the arbitrary choice of such a prior vari-
ance, and hence inappropriate conclusions may be reached. This is referred to as Lindleyâ€™s
paradox and is discussed in more detail in Chapter 3. The fractional and posterior Bayesâ€™
factors do not suï¬€er from this paradox in quite the same way as, even if proper priors
were speciï¬ed in each case, both methods have their foundations in using the parameter
posterior as a prior for marginal likelihood computation. Thus, speciï¬cation of a reason-
able prior variance will not inï¬‚uence the conclusion of the Bayesâ€™ factor in these cases.
Yet, each procedure will be inï¬‚uenced by the choice of b and the repetitive use of the data
respectively.
The work of Oâ€™Hagan and Aitkin is motivated due to the diï¬ƒculties created with improper
priors. Yet, we must question whether much can be gained by the use of the comparison
techniques that the authors advocate. In solving one problem, it appears that further
issues have been created. Therefore, has much been learnt as regards how to practice
Bayesian model comparison?
It is evident however that the speciï¬cation of either a
proper or improper prior is a thorny issue when assessing the value of a set of competing
models, and a solution is hence required. As mentioned by Aitkin (1991), one possibility
would be to carefully apply an informative, proper prior and analyse the sensitivity of
results to such a choice. This technique is performed later in this thesis.
1.2
Approximation of the marginal likelihood
The importance of the marginal likelihood in Bayesian model comparison is clear. How-
ever, as commented previously, the integral (1.2) is often intractable and so an approxi-
mation is necessary. In this section, two of the more popular, analytic techniques for this
14

1.2. Approximation of the marginal likelihood
are considered. Of course, we must stress that such an approximation is also vital in the
computation of the normalised parameter posterior distribution, as seen by (1.3).
1.2.1
Laplaceâ€™s approximation
For the derivation of this method, we follow that given by Beal (2003). Initially, consider
the integrand in the deï¬nition of the marginal likelihood. By taking logarithms of this
expression, we can deï¬ne
h(Î¸i) = log [p(D | Î¸i, Mi) p(Î¸i | Mi)] .
(1.21)
This expression is now expanded using a second-order multivariate Taylor series about its
maximum a posteriori (MAP) estimate, denoted by ËœÎ¸i. Clearly, this is the point where
the posterior density is maximised, i.e. the mode of the posterior distribution. Hence, we
achieve
h(Î¸i) = h(ËœÎ¸i) + (Î¸i âˆ’ËœÎ¸i)T hâ€²(ËœÎ¸i) + 1
2!

Î¸i âˆ’ËœÎ¸i
T
hâ€²â€²(ËœÎ¸i)

Î¸i âˆ’ËœÎ¸i

+ . . .
â‰ˆh(ËœÎ¸i) + 1
2

Î¸i âˆ’ËœÎ¸i
T
Hh(ËœÎ¸i)

Î¸i âˆ’ËœÎ¸i

,
(1.22)
where â€² represents diï¬€erentiation with respect to Î¸i. Moreover, Hh(ËœÎ¸i) is the Hessian
matrix of second partial derivatives for the function h, evaluated at ËœÎ¸i. Now, notice that
log p(Î¸i | D, Mi) âˆh(Î¸i) and, consequently by (1.3), [log p(Î¸i | D, Mi)]â€² = hâ€²(Î¸i). Thus,
hâ€²(ËœÎ¸i) = 0 as ËœÎ¸i is a maximum of h(Î¸i), that is, the MAP estimate. Via (1.21) and (1.22),
it follows that the log marginal likelihood is given by
log p(D | Mi) = log

exp {h(Î¸i)} dÎ¸i
= log
	
exp

h(ËœÎ¸i)
 
exp
1
2

Î¸i âˆ’ËœÎ¸i
T
Hh(ËœÎ¸i)

Î¸i âˆ’ËœÎ¸i

dÎ¸i

15

1.2. Approximation of the marginal likelihood
â‰ˆh(ËœÎ¸i) + log

(2Ï€)di/2 
|W âˆ’1|
1/2
,
(1.23)
where di is the dimension of Î¸i and W = âˆ’Hh(ËœÎ¸i). In other words, we have approxi-
mated exp {h(Î¸i)} = p(D | Î¸i, Mi) p(Î¸i | Mi) via a multivariate normal distribution (see
Appendix A) with mean vector ËœÎ¸i, the MAP estimate, and covariance matrix W âˆ’1, and
then subsequently integrated. Finally, by substituting (1.21) into (1.23) and taking ex-
ponentials, the Laplace approximation is given by
p(D | Mi)Lap = p(D | ËœÎ¸i, Mi) p(ËœÎ¸i | Mi) (2Ï€)di/2|W|âˆ’1/2.
(1.24)
This approximation is based on the fact that, for a large dataset, the parameter posterior
distribution can be approximately normally distributed (Gelman et al., 1995). Hence,
using Laplace seems reasonable if the posterior is unimodal and almost symmetric. Fur-
ther, it is an enticing option due to the ease of computing the MAP estimate. Yet, on
the contrary, we may expect an inaccurate approximation to the marginal likelihood, and
hence posterior, if the sample size is small. Moreover, notice that the Hessian matrix is of
dimension di Ã— di. So, such a method may suï¬€er from a computational perspective if Î¸i
is high-dimensional. Finally, as Beal (2003) also mentions, this method may not capture
the position of the posterior probability mass well since the MAP estimate maximises the
posterior density. So, we will obtain a more eï¬€ective approximation if p(Î¸i | D, Mi) is
tightly peaked about its mode, where all the mass is situated.
1.2.2
Bayesian Information Criterion (BIC)
A further procedure applied to approximate the marginal likelihood is the Bayesian Infor-
mation Criterion (Schwarz, 1978), also termed Schwarzâ€™s Information Criterion (SIC).
This criterion is viewed purely as a means to compare candidate models, and not to
16

1.2. Approximation of the marginal likelihood
construct an approximate, parameter posterior distribution. As we shall see, it contains
terms to evaluate both the ï¬t and complexity of any particular model, as discussed in the
introduction to this chapter.
The criterion can be derived directly from the Laplace approximation as Ghahramani
(2004) demonstrates. Note initially that the Hessian matrix of h, evaluated at the MAP
estimate, is equivalent to
Hh(ËœÎ¸i) =

log p(D | Î¸i, Mi) + log p(Î¸i | Mi)
â€²â€²
Î¸i=ËœÎ¸i
=

N

t=1
log p(xt | Î¸i, Mi) + log p(Î¸i | Mi)
â€²â€²
Î¸i=ËœÎ¸i
(1.25)
where we possess a dataset D = {x1, . . ., xN}. So, it is evident that the Hessian matrix
is dependent on N. Consequently, by taking logarithms of (1.24), and then rejecting all
terms that are independent of the sample size N, we obtain
log p(D | Mi)Lap = log p(D | ËœÎ¸i, Mi) âˆ’1
2 log |W|.
(1.26)
Here, log p(D | ËœÎ¸i, Mi) will be a sum of N terms. Consequently, it is realised that the
Hessian matrix is of order O(N) since, for each entry of Hh(ËœÎ¸i), N summations must again
be made. Then, by deï¬nition of O notation, we can specify W â‰ˆNW0 for suï¬ƒciently
large N, where W0 is a ï¬xed constant matrix. Thus, it follows immediately that, as W is
of dimension di Ã— di,
1
2 log |W| â‰ˆdi
2 log N + 1
2 log |W0|,
(1.27)
where |NW0| = Ndi|W0| (Harville, 1997). Now, the term
1
2 log |W0| is also ï¬xed with
respect to N. By dropping this and substituting (1.27) into (1.26), the BIC, as presented
17

1.3. Further criteria
by Schwarz (1978), is deï¬ned to be
log p(D | Mi)BIC = log p(D | ËœÎ¸i, Mi) âˆ’di
2 log N.
(1.28)
In (1.28), it is customary that the log-likelihood, log p(D | Î¸i, Mi), is evaluated not at the
MAP estimate ËœÎ¸i, but instead at Ë†Î¸i, the maximum likelihood estimate (MLE). This is the
value of Î¸i for which the likelihood is maximised.
Due to its reliance on calculation of the MLE, this criterion is easy to handle. Moreover,
notice that, although working in a Bayesian context, the BIC is deï¬ned such that no
speciï¬cation of the prior p(Î¸i | D, Mi) is required, assuming that the log-likelihood is
evaluated at the MLE. Depending on oneâ€™s perspective, this may be a positive attribute
if it is awkward to elicit oneâ€™s parameter prior knowledge. However, the converse may be
true if an informative prior is required. In addition, as the derivation of the BIC given
here is reliant on the Laplace approximation, the criterion may suï¬€er if the sample size
is insuï¬ƒciently large.
We realise that the two terms in the BIC expression each serve a purpose. If we interpret
the MLE as the value of the parameters for model Mi that makes the data most plausible,
log p(D | Ë†Î¸i, Mi) illustrates how well Mi ï¬ts the data, a term that is ideally maximised.
On the other hand, di
2 log N acts to penalise more complex models, determined by the
number of parameters, di, that each possesses. So, for a candidate set of models, the
optimum model choice is that which has the highest value of (1.28).
1.3
Further criteria
The BIC is a classical technique to evaluate the evidence for a set of models. In fact,
other such criteria exist and, in this section, we consider brieï¬‚y two of the more signiï¬cant
18

1.3. Further criteria
options. We shall see that, as previously, each is dependent on assessing model ï¬t and
model complexity.
1.3.1
Akaikeâ€™s Information Criterion (AIC)
Akaike (1974) realised that we need a way to measure the misï¬t between a model and a
truth to judge whether the former is a decent approximation to the latter on the basis of
a dataset. From an alternative perspective, we determine the information lost in making
such an approximation whereby a good model will minimise this quantity. To quantify
this, the Kullback-Leibler (KL) divergence (Kullback and Leibler, 1951) from the truth
to the model is employed, deï¬ned as
KL(f | p) =

f(D) log

f(D)
p(D | Î¸i, Mi)

dD
= Ef(D){log f(D)} âˆ’Ef(D){log p(D | Î¸i, Mi)},
(1.29)
where log is the natural logarithm. In addition, the expectations above are taken with
respect to f(D), the true density of D, speciï¬ed without parameters. Clearly, in (1.29),
the term Ef(D){log f(D)} is a constant across models. Hence, minimising KL(f | p) is
equivalent to ï¬nding the model that maximises J = Ef(D){log p(D | Î¸i, Mi)}, referred to
as the relative KL divergence.
Unfortunately, calculation of J is not possible per se as it is dependent upon knowledge
of the truth f. Paradoxically, an understanding of this reality would render the deriva-
tion of such a criterion unnecessary. Thus, Akaike introduced a fabricated dataset X,
independent of D, but arising from the same distribution. It was then shown that the
expected value of J with respect to f(X) could be estimated, where Î¸i is replaced by the
corresponding MLE Ë†Î¸i(X), dependent on model Mi and constructed using the dataset X
(if it were available). In fact, a biased estimator of Ef(X){J} is given by the maximised
19

1.3. Further criteria
log-likelihood function, namely log p(D | Ë†Î¸i(D), Mi). Moreover, it was further established
that the bias of this estimate is asymptotically (for a large dataset) equivalent to di, the
dimension of the parameter vector. For additional details on this, see, for instance, Burn-
ham and Anderson (2004) or Stoica and SelÂ´en (2004). Upon removing the dependence of
the MLE upon D, we see that maximising the unbiased estimator, log p(D | Ë†Î¸i, Mi) âˆ’di,
for the expectation of J, is equivalent to minimising the following, known as Akaikeâ€™s
information criterion:
AIC = âˆ’2 log p(D | Ë†Î¸i, Mi) + 2di.
(1.30)
The â€˜bestâ€™ model is deemed to be that which has the smallest AIC value and is interpreted
as the model â€˜closestâ€™ to the actual truth. According to Burnham and Anderson (2004),
the multiplication here by âˆ’2 is for â€˜historical reasonsâ€™. In fact, the BIC, given by (1.28), is
also presented similarly, implying that the resulting expression should now be minimised.
Clearly, the AIC and BIC have the same goodness of ï¬t term. Yet, the model complexity
term is more stringent in the BIC case (if N â‰¥8, then di log N > 2di), hence providing an
obvious preference for simpler models. However, this could be detrimental when a simpler
model is chosen over a more complex one, even if the former is a poor speciï¬cation. On
the other hand, AIC could be susceptible to overï¬tting the data by showing an aï¬ƒnity
for too complex models. Finally, as it is based on asymptotic maximum likelihood theory,
the performance of the AIC in datasets of small size may be questionable.
1.3.2
Deviance Information Criterion (DIC)
The ï¬nal model comparison criterion that is examined was pioneered by Spiegelhalter
et al. (2002). The initial foundation for this technique is provided by the classical de-
viance, which is equivalent to the diï¬€erence in the log-likelihoods between a model and
20

1.3. Further criteria
the unknown truth that generated the data. In fact, the deviance Dâˆ—is deï¬ned as
Dâˆ—(Î¸i | Mi) = âˆ’2 log p(D | Î¸i, Mi) + 2 log f(D)
(1.31)
where, again, f(D) is the true density of the data. However, this term is independent of
the model Mi. Correspondingly, it is constant, and hence irrelevant, for the purposes of
model comparison. Spiegelhalter et al. examine a Bayesian treatment for the problem at
hand and thus focus their attention on the posterior distribution of the deviance.
Thus, the posterior mean of Dâˆ—(Î¸i | Mi) could be utilised as a Bayesian measure of model
ï¬t, denoted as
Â¯Dâˆ—=

Dâˆ—(Î¸i | Mi) p(Î¸i | D, Mi) dÎ¸i
= EÎ¸i | D, Mi{Dâˆ—}.
(1.32)
Due to the deï¬nition of the deviance, those models that provide a good ï¬t will possess a
small value of Â¯Dâˆ—. This will occur when the number of parameters is increased so we now
require a measure of model complexity to counterbalance this. So, Spiegelhalter et al.
denote such a quantity as pD, taking the form
pD = EÎ¸i | D, Mi{Dâˆ—} âˆ’Dâˆ—
EÎ¸i | D, Mi{Î¸i} | Mi

= Â¯Dâˆ—âˆ’Dâˆ—(Â¯Î¸i | Mi).
Thus, pD is equivalent to the diï¬€erence between the posterior mean of the deviance
and the deviance evaluated at the posterior mean of the parameters.
Recalling that
Dâˆ—(Î¸i | Mi) = âˆ’2 log p(D | Î¸i, Mi), our terms for both measure of ï¬t and the penalty for
model complexity can now be summed (akin to the AIC and BIC) to form the Deviance
21

1.4. Outline of thesis and literature review
Information Criterion:
DIC = Â¯Dâˆ—+ pD
= Dâˆ—(Â¯Î¸i | Mi) + 2pD,
(1.33)
the latter by rearranging the expression for pD. In the way of both the AIC and BIC, the
high-ranking models are those that minimise the DIC and, hence, an optimal model can
be chosen. By writing the AIC in terms of the deviance such that AIC = Dâˆ—(Ë†Î¸i | Mi)+2di,
Spiegelhalter et al. show that the DIC is a Bayesian generalisation of the AIC.
In the discussion to this paper, some salient points were raised. For instance, Robert
and Titterington (2002) noticed that the authorsâ€™ had used the data once, to construct
a posterior distribution for Î¸i, and then a second time, to take the posterior mean of
the deviance.
This is the same criticism as seen for Aitkinâ€™s posterior Bayesâ€™ factor
whereby the dataset is applied to both learning the parameters and for model comparison.
Moreover, Brooks (2002) questioned why it was possible that pD could in fact be negative,
leaving it open to interpretation in such a case.
1.4
Outline of thesis and literature review
In this chapter, a variety of procedures have been analysed so that the evidence for each
model in a candidate set can be evaluated. Moreover, the potential hazards associated
with each method have also been discussed. In Chapter 2, a relatively recent addition to
the Bayesian model comparison literature is introduced, referred to as variational Bayes.
This method is advantageous since we inherently derive separate approximations to both
the posterior distribution and the marginal likelihood, suitable for future inference and
ranking models respectively.
Its theoretical foundation is reliant upon the Kullback-
Leibler divergence, previously seen in this chapter to derive the AIC. To conclude this
22

1.4. Outline of thesis and literature review
chapter, its performance in posterior approximation is compared to two other, standard
techniques.
For the remainder of the thesis, variational Bayes is applied speciï¬cally to comparing
sparse vector autoregressive (VAR) models of order 1. In Chapter 3, by modelling using
sparsity, a candidate set of zero mean VAR(1) graphical models (speciï¬cally dynamic
Bayesian networks) is established, each of which relates to the autoregressive matrix in
the VAR process.
We proceed to form a lower bound on the marginal likelihood to
compare the evidence for such models. A valid question to inquire at this stage would
be how to handle the problem if the candidate set of graphical models is large. This is
the focus of Chapter 4 and it is answered by constructing a Metropolis-Hastings type
algorithm to search quickly and eï¬ƒciently for high-scoring models in the graphical space.
The ideas of Chapter 3 are then mimicked in Chapter 5 by the study of non-zero mean
VAR(1) models. Examples involving both simulated and real data are then utilised to
elucidate the theory of these two chapters. A summary, illustrating the main points of
the thesis, is presented in Chapter 6.
The most comprehensive review of the variational approximation is provided by Beal
(2003). In this thesis, by considering any model with both parameters and hidden vari-
ables, the author develops a variational Bayesian EM algorithm, allowing alternate up-
dating of approximate posteriors for these two sets of unknowns. The algorithm is applied
to a variety of statistical models, in particular, hidden Markov models, mixtures of factor
analysers and linear dynamical systems, using both simulated and real datasets in each
case. The current work extends that of Beal by providing the variational treatment to
both zero and non-zero mean VAR models (of course, deï¬ned without hidden variables).
However, as opposed to determining an optimum model order for a VAR(p) process, we
wish to evaluate the evidence for a set of sparse graphical models of order 1, given a
dataset. This is aided by the use of MCMC methods in high-dimensional spaces.
We realise that it is essential to use an approximation technique such as variational Bayes
23

1.4. Outline of thesis and literature review
in the context of VAR(1) model comparison since, even for the model that is saturated, it
is not possible to derive the marginal likelihood analytically. This fact is shown explicitly
in Chapter 3. Furthermore, this approach is able to enforce naturally the speciï¬c spar-
sity constraints placed upon the approximate posterior distribution of the autoregressive
matrix for each candidate. It is also important to note that learning a dynamic Bayesian
network from data is a problem that has received much coverage in the statistical lit-
erature. To rank candidate structures, Friedman et al. (1998) suggested application of
the BIC or the so-called Bayesian Dirichlet equivalence (BDe) score, originally developed
in the static case by Heckerman et al. (1995). Alternatively, Husmeier (2003) used a
MCMC search algorithm to locate the most plausible models in the space, similar to that
which is presented in Chapter 4. However, to enable analytic computation of the marginal
likelihood, the author was required to discretise the data, leading to a considerable loss
of information.
As opposed to the structural search algorithm considered in this thesis, an alternative
method would be to put sparsity priors on the coeï¬ƒcients of the autoregressive matrix.
This idea is used by, for instance, Lucas et al. (2006) in the circumstance of regression
modelling for microarray data. The aim here is for many entries of this matrix to be
estimated close to (or even equal to) zero following a variational Bayesian analysis. Thus,
if the value of such elements lies below a speciï¬ed threshold point, no edge is placed on
the graph between the corresponding nodes. Although this approach is more eï¬ƒcient,
ascertaining possible inï¬‚uences between nodes in this way can be inaccurate and so is not
pursued here.
24

Chapter 2
Variational Bayes
2.1
Introduction
The focus in the previous chapter was to explore techniques in which the marginal like-
lihood could be approximated, for the primary purpose of model comparison. Our em-
phasis now turns to the approximation of the posterior distribution over parameters. In
this chapter, the dependence of our distributions on each model Mi will be predominantly
removed. So, for completeness, our beliefs about the parameter vector Î¸ = (Î¸1, . . . , Î¸d)T
upon observing data D are quantiï¬ed by the distribution
p(Î¸ | D) =
p(D | Î¸) p(Î¸)

p(D | Î¸) p(Î¸) dÎ¸
.
(2.1)
Of course, the integral in the denominator of this expression could be intractable. So, a
straightforward, direct solution to this would be to apply the analytic Laplace approxi-
mation. In this chapter, some alternative approaches are examined. For instance, the use
of Markov chain Monte Carlo methods enables samples to be drawn from p(Î¸ | D), with
which, inter alia, understanding can be garnered about the marginal posterior of each
25

2.2. Markov chain Monte Carlo
component of Î¸. Furthermore, an expectation-maximisation type algorithm can allow
approximation of the afore-mentioned marginal posteriors via MAP estimation. Finally,
special detail is devoted to a relatively, recent technique, known as variational Bayes.
Each method will be treated theoretically and then compared via example.
2.2
Markov chain Monte Carlo
The use of Markov chain Monte Carlo (MCMC) methodology to understand a posterior
distribution has become highly popular in the Bayesian community. Instead of using an
analytic technique such as Laplace to approximate (2.1), a Markov chain is simulated
whose samples will be draws from the posterior, upon convergence of the chain. When a
chain converges to its stationary distribution, it will possess this distribution for all time
henceforth. Thus, to simulate from the posterior, we construct a Markov chain whose
stationary distribution is the posterior distribution.
The summary statistics and the
distribution of these posterior samples will approximate the corresponding characteristics
of the true posterior.
Here, we present two of the most fundamental MCMC methods: the Gibbs sampler and
the Metropolis-Hastings algorithm. In each case, we consider the general case and hence
suppose that Ï€(Î¸) is the density of interest, where we allow the possibility that each Î¸j
(the j-th component of Î¸ for j = 1, . . .d) could be multi-dimensional. When simulating
from a posterior, we let Ï€(Î¸) = p(Î¸ | D).
2.2.1
The Gibbs sampler
First documented by Geman and Geman (1984), this method relies on sampling from the
full conditional distributions for each component of Î¸, such that a sample from Ï€(Î¸) may
26

2.2. Markov chain Monte Carlo
be obtained. The full conditionals are denoted as
Ï€(Î¸j | Î¸1, . . . , Î¸jâˆ’1, Î¸j+1, . . ., Î¸d) = Ï€(Î¸j | Î¸âˆ’j),
(2.2)
for j = 1, . . ., d, and are assumed to be in closed form so that we may sample from them.
The algorithm for the Gibbs sampler is as given below.
Algorithm 1
1. Initialise the iteration counter to k = 1. The chain itself is initialised
at a starting value Î¸(0) = (Î¸(0)
1 , . . . , Î¸(0)
d )T.
2. By successive simulation from the full conditionals, a new value Î¸(k) is obtained from
the previous Î¸(kâˆ’1):
Î¸(k)
1
âˆ¼Ï€(Î¸1 | Î¸(kâˆ’1)
2
, . . ., Î¸(kâˆ’1)
d
)
Î¸(k)
2
âˆ¼Ï€(Î¸2 | Î¸(k)
1 , Î¸(kâˆ’1)
3
, . . ., Î¸(kâˆ’1)
d
)
...
Î¸(k)
d
âˆ¼Ï€(Î¸d | Î¸(k)
1 , . . . , Î¸(k)
dâˆ’1).
3. Change the counter from k to k + 1 and return to step 2.
Upon convergence of the Markov chain, the simulated iterates will be draws from Ï€(Î¸).
Moreover, at this stage, the values of a particular component will be draws from the
corresponding marginal posterior distribution for that component.
2.2.2
Metropolis-Hastings algorithm
A complementary methodology is the Metropolis-Hastings algorithm (Hastings, 1970),
which allows simulation from the density of interest when this is known only up to a
constant of proportionality. We now introduce an arbitrary proposal distribution, q(Î¸, Ï†),
27

2.2. Markov chain Monte Carlo
the notation of which here speciï¬es the probability of a move from Î¸ to Ï†. The reverse
move is implied by q(Ï†, Î¸).
This distribution should be easy to simulate from.
The
algorithm is as follows:
Algorithm 2
1. Initialise both the iteration counter to k = 1 and the chain itself to
starting value Î¸(0).
2. Generate a proposed value Ï† from the distribution q(Î¸(kâˆ’1), Ï†).
3. Compute the acceptance probability Î±(Î¸(kâˆ’1), Ï†) of the proposed move, where
Î±(Î¸, Ï†) = min

1, Ï€(Ï†)q(Ï†, Î¸)
Ï€(Î¸)q(Î¸, Ï†)

.
(2.3)
4. Put Î¸(k) = Ï† with probability Î±(Î¸(kâˆ’1), Ï†), otherwise put Î¸(k) = Î¸(kâˆ’1).
5. Change the counter from k to k + 1 and return to step 2.
In essence, at each iteration, a new value is generated from the proposal distribution, which
may be accepted (indicating that the chain moves) or rejected (hence the chain stays put).
The movement of the chain is dependent on the acceptance probability Î±. By drawing
u âˆ¼U(0, 1), the proposal Ï† is accepted if u < Î±(Î¸(kâˆ’1), Ï†) at iteration k. Once the
chain reaches convergence, all simulated values will be draws from Ï€(Î¸), irrespective of the
choice of proposal distribution. The method is of particular use in the Bayesian paradigm,
as since Ï€(Â·) is only involved in Î±(Î¸, Ï†) via a ratio, the proportionality constant p(D),
required to compute the posterior distribution and itself computationally problematic,
will cancel out. Although not utilised in this chapter, the Metropolis-Hastings algorithm
will be a crucial tool at our disposal later in this thesis.
When running an MCMC scheme, the period that elapses prior to convergence of the
chain, i.e. before the stationary distribution has been reached, is referred to as the burn-
in period. Therefore, if we want to generate samples from Ï€(Î¸), we discard those values
28

2.2. Markov chain Monte Carlo
simulated during burn-in. In fact, a good method to establish the length of the burn-in
period required is to plot all values using a trace plot, a time series plot displaying the
values of a component of Î¸ against the number of iterations. Moreover, without burn-in,
such a plot can be used as a crude test for convergence by revealing how well a chain
is said to mix. A well mixing chain will move freely about a constant mean level with
constant variance, exploring the parameter space. Conversely, a poorly mixing chain will
not traverse quickly through the space, indicated on the plot by long, â€˜ï¬‚atâ€™ regions, as a
consequence of numerous, proposed moves being rejected.
The use of MCMC methods in Bayesian statistical inference enables posterior approxima-
tion in large multivariate problems or where the posterior itself is of non-standard form.
Highly accurate results can be obtained if we draw a large number of samples. However,
a huge amount of computational time may be required to achieve this. As Lappalainen
and Miskin (2000) indicate, this is in contrast, for instance, to the Laplace approximation,
which will produce less accurate results, but in shorter time. Moreover, uncertainty will
remain as to whether the chain has reached its stationary distribution. An additional
discussion is provided to this latter issue in Chapter 4.
It is brieï¬‚y worth mentioning that, although this chapter is primarily concerned with ap-
proximating the parameter posterior, sampling from this distribution by MCMC methods
enables a further approximation to the marginal likelihood. A simple estimate was given
by Newton and Raftery (1994) as
p(D | Mi) â‰ˆ

1
B
B

k=1
p(D | Î¸(k)
i , Mi)âˆ’1
âˆ’1
,
where Î¸(k)
i
= (Î¸(k)
i1 , . . ., Î¸(k)
id )T, the parameters speciï¬c to Mi, and we obtain B draws from
the posterior. For further details, the reader is referred to the afore-mentioned paper.
29

2.3. Expectation-Maximisation (EM) algorithm
2.3
Expectation-Maximisation (EM) algorithm
We now turn our attention to a method that will approximate analytically each marginal
posterior distribution. As above, let Î¸ = (Î¸1, . . . , Î¸d)T be a parameter vector of length
d. Consider the density p(Î¸1 | D) for a dataset D. Then, Gelman et al. (1995) have
illustrated that the EM algorithm (developed by Dempster et al. (1977)) can be applied
as an iterative procedure to ï¬nd a mode (MAP estimate) of this marginal posterior density.
This is of particular use in circumstances where knowledge of this marginal is limited, and
hence cannot be maximised directly to ï¬nd such an estimate. We denote the resulting
estimate by ËœÎ¸1. Further suppose that we ï¬nd corresponding marginal posterior modes,
ËœÎ¸2, . . . , ËœÎ¸jâˆ’1, ËœÎ¸j+1, . . . , ËœÎ¸d. Then, by deriving the full conditional posteriors, p(Î¸j | Î¸âˆ’j, D)
for each j = 1, . . .d, the marginal posterior for Î¸j can be approximated via p(Î¸j | Î¸1 =
ËœÎ¸1, . . . , Î¸jâˆ’1 = ËœÎ¸jâˆ’1, Î¸j+1 = ËœÎ¸j+1, . . . , Î¸d = ËœÎ¸d, D). Hence, the algorithm has increased
value, as opposed to just providing a parameter point estimate of the marginal posterior
where the density is highest.
The algorithm itself is a two-stage iterative process, consisting of an E-step (expectation)
and M-step (maximisation).
To ï¬nd a marginal posterior mode for p(Î¸1 | D), we can
follow the procedure below, as presented by Gelman et al..
Algorithm 3
1. Initialise the iteration counter to k = 1. Make an initial MAP esti-
mate of p(Î¸1 | D), say Î¸(0)
1 .
2. At iteration k, perform the following two stages:
(a) E-step: Determine the log joint posterior density, log p(Î¸1, . . . , Î¸d | D). Then,
take its expectation with respect to the conditional posterior distribution of
Î¸2, . . . , Î¸d given the previous estimate Î¸(kâˆ’1)
1
, with density denoted by
p(Î¸2, . . . , Î¸d | Î¸(kâˆ’1)
1
, D). In other words, derive the expectation
30

2.4. Variational Bayesian methods
Ekâˆ’1 {log p(Î¸1, . . . , Î¸d | D)}
=

Â· Â· Â·

log p(Î¸1, . . . , Î¸d | D) p(Î¸2, . . . , Î¸d | Î¸(kâˆ’1)
1
, D) dÎ¸2 . . . dÎ¸d.
(b) M-step: Determine Î¸(k)
1 , the new value of Î¸1 that maximises
Ekâˆ’1 {log p(Î¸1, . . . , Î¸d | D)}.
3. Change the counter from k to k + 1 and return to step 2.
The algorithm alternates between the E-step and M-step until the estimate has converged
after, say, K iterations. At this point, we deï¬ne ËœÎ¸1 := Î¸(K)
1
. As Gelman et al. note,
the algorithm works since, at each iteration, Ekâˆ’1 {log p(Î¸1, . . . , Î¸d | D)} is maximised,
producing an estimate Î¸(k)
1
that monotonically increases the log marginal posterior density,
i.e. log p(Î¸(k)
1 | D) > log p(Î¸(kâˆ’1)
1
| D). By running until convergence such that Î¸(K)
1
=
Î¸(Kâˆ’1)
1
, a mode of the marginal posterior is hence found.
It was indicated earlier that, to approximate a marginal posterior for Î¸j, the algorithm
must be repeated to ï¬nd the additional modes ËœÎ¸2, . . ., ËœÎ¸jâˆ’1, ËœÎ¸j+1, . . . , ËœÎ¸d, although this
task could become somewhat laborious.
A ï¬nal point to make is that, if p(Î¸1 | D) is
multimodal, we may not automatically arrive at the global maximum of p(Î¸1 | D). To
negotiate this problem, the algorithm should be initialised at a variety of points in the
parameter space, and then let ËœÎ¸1 be the mode such that log p(ËœÎ¸1 | D) is maximal.
2.4
Variational Bayesian methods
We now present a ï¬nal, alternative technique for approximating a posterior distribution,
known as variational Bayes (also referred to by MacKay (1995a) as ensemble learning).
In recent years, the literature has become quite rich in this area - see, for instance,
31

2.4. Variational Bayesian methods
Lappalainen and Miskin (2000), Winn (2003), Beal (2003) or Penny et al. (2006). The
outline of the method is as follows. For a set of observed data D and a parameter vector
Î¸, this approach forms a parametric approximation of the true posterior, p(Î¸ | D). The
approximating distribution is known as a variational distribution (or an ensemble), and
is denoted subsequently by q(Î¸ | D). We must ensure that this distribution is as â€˜closeâ€™ as
possible to the true posterior. To eï¬€ect this, a dissimilarity measure can be employed to
gauge the misï¬t between the two distributions. As mentioned in Section 1.3.1 to derive
the AIC, one standard choice of measure is the Kullback-Leibler divergence.
2.4.1
Kullback-Leibler divergence
Given the true and approximating posterior densities p(Î¸ | D) and q(Î¸ | D), recall from
Chapter 1 that the KL divergence from q to p is deï¬ned as
KL(q | p) =

q(Î¸ | D) log q(Î¸ | D)
p(Î¸ | D) dÎ¸.
(2.4)
It merely measures the extent to which the two densities agree. Of course, as previously
discussed, to provide a good approximation, we choose the distribution q such that the KL
divergence between q and p is minimised. An important property of the KL divergence is
that it is always non-negative, a result known as the Gibbsâ€™ inequality (Penny et al., 2006),
i.e. KL(q | p) â‰¥0 with equality if and only if q = p. We also note that, although the KL
divergence is gauging the distance between q and p, it is not per se a true â€˜distanceâ€™ metric
since it is not symmetric, i.e. KL(q | p) Ì¸= KL(p | q). Therefore, it is relevant whether we
minimise the misï¬t between q and p or vice versa. A further mention of this is made
below.
32

2.4. Variational Bayesian methods
2.4.2
Deï¬nition of L(q)
As it currently stands, evaluation of (2.4) is not possible since it requires knowledge of
p(Î¸ | D), which we have assumed to be intractable. However, the true posterior can be
simply rewritten as p(Î¸ | D) = p(Î¸, D)
p(D) . By substituting in, we hence obtain
KL(q | p) =

q(Î¸ | D) log q(Î¸ | D)p(D)
p(Î¸, D)
dÎ¸
=

q(Î¸ | D) log q(Î¸ | D)
p(Î¸, D) dÎ¸ +

q(Î¸ | D) log p(D) dÎ¸
=

q(Î¸ | D) log q(Î¸ | D)
p(Î¸, D) dÎ¸ + log p(D).
(2.5)
Yet, alternatively, if the same substitution is used to simplify the reverse KL-divergence
KL(p | q), the following is reached:
KL(p | q) =

p(Î¸ | D) log
p(Î¸, D)
q(Î¸ | D)p(D) dÎ¸
=

p(Î¸ | D) log p(Î¸, D)
q(Î¸ | D) dÎ¸ âˆ’log p(D).
Hence, calculating KL(p | q) instead of KL(q | p) provides no beneï¬t since we would now
be required to evaluate the expectation of log p(Î¸, D)
q(Î¸ | D) under the true posterior p(Î¸ | D),
which is only known up to a constant. Consequently, as mentioned previously, there is
crucial signiï¬cance attached to how we measure the misï¬t between the two distributions.
Therefore, we now return to (2.5). Clearly here, the term log p(D) is a constant, indepen-
dent of q(Î¸ | D). Thus, to minimise the KL divergence, we need only minimise the ï¬rst
term in (2.5). A quantity, referred to only as L(q) for the present time, is deï¬ned to be
the negative of this ï¬rst term such that
L(q) =

q(Î¸ | D) log p(Î¸, D)
q(Î¸ | D) dÎ¸.
(2.6)
33

2.4. Variational Bayesian methods
In general, the integral in (2.6) is able to be evaluated, as will be discussed shortly. Hence,
by taking the negative, we wish to maximise the value of L(q), which, correspondingly,
minimises the KL divergence between the true and approximating posterior. In performing
this, an optimal variational distribution will then have been derived.
2.4.3
Approximating the marginal likelihood
In this chapter hitherto, the variational approach has been examined from the perspec-
tive of approximating a posterior distribution. However, such methods are yet further
attractive since they can play a signiï¬cant role in the area of model comparison. Suppose
we have an available set of candidate models, M = {M1, . . . , MR}. By conditioning our
distributions upon the model Mi, (2.5) can now be speciï¬ed as
KL(qi | p) = log p(D | Mi) âˆ’LMi(qi),
(2.7)
where each LMi(qi) is speciï¬c to every Mi, qi = q(Î¸i | D, Mi) and Î¸i = (Î¸i1, . . . , Î¸id)T.
Moreover, by the Gibbsâ€™ inequality of the KL divergence, we also have that
LMi(qi) â‰¤log p(D | Mi).
(2.8)
Equations (2.7) and (2.8) are of critical importance in the variational Bayesian approach.
For each model Mi, (2.8) reveals that LMi(qi) provides a lower bound on the logarithm of
the marginal likelihood, with the diï¬€erence between the two being the KL divergence, as
indicated by (2.7). Henceforth, L(q), whether dependent on a model or not, is referred
to as the lower bound (or variational score). Moreover, to form (2.8), we now see the
rationale behind deï¬ning the lower bound to be the negative of the ï¬rst term in (2.5).
The crux of the method is that, by maximising LMi(qi), we hence minimise the KL
34

2.4. Variational Bayesian methods
divergence by (2.7), and so ensure that the variational distribution is a good approximation
to the true posterior. Furthermore, this implies correspondingly that the bound (2.8) will
be made as tight as possible, and thus LMi(qi) will be a good approximation to the log
marginal likelihood over models. The process of enforcing the accuracy of the bound to
the true value is referred to as bound optimisation. Now, reconsider (1.1) as in Winn
(2003). If we again suppose a uniform prior across models such that p(Mi) = 1
R, then the
afore-mentioned variational theory implies that, approximately, the posterior density for
Mi is such that
p(Mi | D) âˆexp {LMi(qi)} ,
upon optimising qi. So, we can utilise the lower bound to compare and rank a set of
models. Notice that, if the KL divergence is zero, the lower bound will equal the log
marginal likelihood, and the approximate posterior will hence be equivalent to the true
posterior. Henceforth in this chapter, the dependence of our distributions on Mi is no
longer assumed.
2.4.4
Computation of L(q)
Thus far, we have seen that the variational Bayesian framework is often employed to
ï¬nd an optimal approximation to the true posterior distribution, but moreover, the lower
bound L(q) can be utilised as a variational model selection criterion. However, we have
not discussed how to calculate L(q), deï¬ned by (2.6). Thus, to ensure this integral is
tractable, the variational approximation is required to be of a simpler form than the true
posterior, else nothing has been gained. One way to ensure this is to assume q(Î¸ | D)
factorises over parameters such that, if again Î¸ = (Î¸1, . . . , Î¸d)T, then
q(Î¸ | D) =
d

j=1
q(Î¸j | D).
(2.9)
35

2.4. Variational Bayesian methods
This implies that the set of parameters, {Î¸j}, have now been constrained to be inde-
pendent approximately a posteriori. In other words, the approximating distribution now
possesses a simpler dependency structure than the true posterior. Hence, approximation
(2.9) can be substituted into (2.6). Moreover, we suppose that the joint density of data
and parameters can also be split into a product of likelihood and prior terms such that,
if D = (x1, . . ., xN), then
p(Î¸, D) = p(D | Î¸)p(Î¸) =
N

t=1
p(xt | Î¸)
d

j=1
p(Î¸j).
The prior distributions are thus forced to be independent. Consequently, by taking loga-
rithms as stated in (2.6), the lower bound L(q) can be written as
L(q) =

q(Î¸ | D)
 N

t=1
log p(xt | Î¸) +
d

j=1
log
p(Î¸j)
q(Î¸j | D)

dÎ¸.
(2.10)
At this stage, we can proceed using two separate procedures, known as the free form and
ï¬xed form variational methods (Lappalainen and Miskin, 2000). Both techniques rely
on the independence of the variational distributions, as seen in (2.9). Yet, in the free
form approach, no distributional form for the variational posteriors is assumed. Here, by
writing L(q) as a functional of q(Î¸j | D) for all j, the lower bound is maximised by taking
a functional derivative with respect to each variational distribution. Thus, we can derive
the required distributional forms. For instance, by expressing (2.10) as a functional of
q(Î¸j | D) and optimising, it is shown by Miskin (2000) and Winn (2003) that, in general,
q(Î¸j | D) âˆexp

Eq(Î¸\j | D) (log p(Î¸, D))

(2.11)
= p(Î¸j) exp

Eq(Î¸\j | D)
 N

t=1
log p(xt | Î¸)

,
where the notation Î¸\j refers to all components of Î¸ except Î¸j.
The above formula
36

2.5. A univariate example
can be used to simplify calculations in this thesis. Moreover, in this method, equations
for the parameters of the variationals (referred to as variational parameters) are found
simultaneously. Then ultimately, the explicit expression for L(q) is derived by use of (2.6).
On the other hand, by contemplating the situation from a ï¬xed form perspective, a ï¬xed
and speciï¬ed parametric form is assumed for each variational distribution. Such a selection
is made to ensure that the joint variational distribution is similar to the true posterior,
albeit an approximation as seen by (2.9). Thus, the lower bound L(q) is calculated initially
by evaluation of the necessary integrals. Then, this bound is maximised with respect to the
variational parameter set, hence minimising the KL-divergence and deriving expressions
for the parameters.
It is customarily the case that, independent of which method is used, the algebraic ex-
pressions for the variational parameters will be dependent on each other. Hence, to ï¬nd
the optimal values of the parameters that maximise L(q), each equation must be iterated
to convergence. Moreover, we realise that the value of L(q), due to its maximisation, will
monotonically increase (or remain unchanged) at each iteration. As this quantity is also
bounded above, the algorithm is guaranteed to converge. In fact, as Beal (2003) com-
ments, a local maximum of the lower bound will eventually be reached. In the following
example, both methods described here will be elucidated.
2.5
A univariate example
Suppose that we have a set of observed, one-dimensional data D = (x1, . . ., xN) such that
we model xt âˆ¼N (m, v) for all t = 1, . . . , N. Assuming the xt to be independent, we
write p(D | m, v) = N
t=1 p(xt | m, v). We wish to infer m and v. Moreover, deï¬ne prior
distributions over m and v so that
p(m) = N (m | Î¼m, Ïƒm)
(2.12)
37

2.5. A univariate example
p(v) = IG(v | a, b),
(2.13)
where an inverse gamma prior is deï¬ned over v. The choice of priors stems from the
fact that these are the typical semi-conjugate choices for a Gaussian distribution with
unknown mean and variance. That is the case when, although the usual Bayesian update
is non-conjugate using independent priors, the two full conditional posterior distributions
for both mean and variance are of standard form and follow the same distributional form
as the respective priors. This will become clear when constructing a Gibbs sampler for
this example later in the chapter. Allowing our prior beliefs about m and v to separate
into independent speciï¬cations implies that knowledge of one of the parameters does not
inform us about the distribution of the other.
It is evident that, for this model, analytic analysis of the posterior distribution is in-
tractable. This follows since
p(m, v | D) âˆ
 N

t=1
p(xt | m, v)

p(m) p(v)
= vâˆ’N
2 exp

âˆ’vâˆ’1
2
N

t=1
(xt âˆ’m)2

Ã— exp

âˆ’Ïƒâˆ’1
m
2 (m âˆ’Î¼m)2

Ã— vâˆ’(a+1) exp

âˆ’bvâˆ’1
= vâˆ’(a+ N
2 +1) exp

âˆ’vâˆ’1
2
N

t=1
(xt âˆ’m)2 âˆ’Ïƒâˆ’1
m
2 (m âˆ’Î¼m)2 âˆ’bvâˆ’1

.
(2.14)
Clearly, this density will not factorise for m and v and hence these parameters are not
independent a posteriori. To combat this problem, three techniques are now employed to
learn an approximate, marginal posterior for both m and v, given the data: variational
Bayesian methods, Gibbs sampling and the EM algorithm. Initially, both the free form
and ï¬xed form variational procedures are applied to elucidate the theory and reveal how
the methods can coincide. Throughout this example, the results of Appendix A are of
38

2.5. A univariate example
particular importance.
2.5.1
Free form variational method
In this instance, optimal variationals, initially for m and later for v, are found without
assuming any distributional form. These are denoted by q(m | D) and q(v | D) respectively.
In fact, we only allow independence between these distributions such that q(m, v | D) =
q(m | D) q(v | D). This assumption will crucially simplify the following computation. Of
course, it is also an approximation to the truth, which, as recognised above, does not
factorise.
To commence, we write L(q) as a functional of both q(m | D) and q(v | D). Therefore, in
this example, the lower bound is deï¬ned as
L(q) =

q(m, v | D) log
	p(D, m, v)
q(m, v | D)

dm dv.
(2.15)
This expression is straightforward to manipulate since the prior and variational distribu-
tions are independent. Hence, the lower bound is also equivalent to
L(q) =

q(m | D)q(v | D)
 N

t=1
log p(xt | m, v)

dm dv +

q(m | D) log p(m) dm
+

q(v | D) log p(v) dv âˆ’

q(m | D) log q(m | D) dm
âˆ’

q(v | D) log q(v | D) dv.
(2.16)
Here, parameters have been integrated out when necessary, a process aided by the fac-
torisation of q(m, v | D). Resultantly, by recombining integrals, the lower bound can now
be expressed as a functional of both variational distributions. As a functional of q(m | D),
39

2.5. A univariate example
we obtain
L(q) =

q(m | D)
 
q(v | D)
 N

t=1
log p(xt | m, v)

dv
+ log p(m) âˆ’log q(m | D)

dm + const.
(2.17)
Moreover, expressing in terms of q(v | D) provides
L(q) =

q(v | D)
 
q(m | D)
 N

t=1
log p(xt | m, v)

dm
+ log p(v) âˆ’log q(v | D)

dv + const.
(2.18)
Each functional contains a constant term that is independent of q(m | D) and q(v | D)
correspondingly. Recall that, in this method, we take a functional derivative of L(q) with
respect to both variational distributions. Consequently, at that stage, these constants will
disappear.
By examining both equations, we can derive the distributional forms for both q(m | D)
and q(v | D) respectively. The integrals are tackled in order. So, we can substitute in for
both log p(xt | m, v) and log p(m) in (2.17) such that
L(q) =

q(m | D)

N

t=1

q(v | D)

âˆ’1
2 log 2Ï€v âˆ’vâˆ’1
2 (xt âˆ’m)2

dv
âˆ’1
2 log 2Ï€Ïƒm âˆ’Ïƒâˆ’1
m
2 (m âˆ’Î¼m)2 âˆ’log q(m | D)

dm + const.
Again here, there are terms, independent of m. After taking a functional derivative of
the lower bound, such terms will clearly play no part in determining the form of q(m | D).
40

2.5. A univariate example
Henceforth, they are dropped and included in a new constant term. Thus, we acquire
L(q) =

q(m | D)

âˆ’1
2
N

t=1
(xt âˆ’m)2

q(v | D)vâˆ’1 dv
âˆ’Ïƒâˆ’1
m
2 (m âˆ’Î¼m)2 âˆ’log q(m | D)

dm + const.â€²
(2.19)
Of course here,

q(v | D)vâˆ’1 dv = Eq(v | D) {vâˆ’1}. This expectation can be deï¬ned when
the variational distribution for v has been derived. Subsequently, L(q), written as a func-
tional of q(m | D), will no longer depend on v as this parameter will have been integrated
out. This is important since we assumed independence between the variational distribu-
tions. At this time, notice that since q(m | D) is a density function, it must integrate to 1.
That is, we look for the variational distribution that optimises the lower bound, subject
to the constraint that it is normalised. To enforce this, Lappalainen and Miskin (2000)
use a Lagrange multiplier. Thus, correspondingly, a new functional, ËœL(q), is formed such
that
ËœL(q) = L(q) + Î½m

q(m | D) dm âˆ’1

,
(2.20)
and Î½m is the required Lagrangian. Via (2.19), we diï¬€erentiate ËœL(q) with respect to the
distribution q(m | D). Taking the functional derivative and equating to zero results in
âˆ‚ËœL(q)
âˆ‚q(m | D) = âˆ’Eq(v | D) {vâˆ’1}
2
N

t=1
(xt âˆ’m)2 âˆ’Ïƒâˆ’1
m
2 (m âˆ’Î¼m)2 âˆ’log q(m | D) âˆ’1 + Î½m = 0.
Rearranging in terms of q(m | D) and dropping constant terms, we arrive at
q(m | D) âˆexp

âˆ’1
2

m2 
NEq(v | D)

vâˆ’1
+ Ïƒâˆ’1
m

âˆ’2m

Eq(v | D)

vâˆ’1
N

t=1
xt + Ïƒâˆ’1
m Î¼m
 
41

2.5. A univariate example
âˆexp
âŽ§
âŽ¨
âŽ©âˆ’1
2

NEq(v | D)

vâˆ’1
+ Ïƒâˆ’1
m


m âˆ’Eq(v | D) {vâˆ’1}  N
t=1 xt + Ïƒâˆ’1
m Î¼m
NEq(v | D) {vâˆ’1} + Ïƒâˆ’1
m
2âŽ«
âŽ¬
âŽ­
via completing the square. It is thus apparent that the variational distribution for m is a
Gaussian distribution such that
q(m | D) = N (m | Î¼m
â€², Ïƒm
â€²).
(2.21)
Moreover, the variational parameters, Î¼mâ€² and Ïƒmâ€², are deï¬ned as
Î¼m
â€² = Eq(v | D) {vâˆ’1}  N
t=1 xt + Ïƒâˆ’1
m Î¼m
NEq(v | D) {vâˆ’1} + Ïƒâˆ’1
m
(2.22)
Ïƒm
â€² =
1
NEq(v | D) {vâˆ’1} + Ïƒâˆ’1
m
.
(2.23)
This process is now repeated to ï¬nd the optimum form for q(v | D). Hence, reconsider
(2.18). On this occasion, by substituting in for log p(xt | m, v) and log p(v), the lower
bound is expressed as
L(q) =

q(v | D)

N

t=1

q(m | D)

âˆ’1
2 log 2Ï€v âˆ’vâˆ’1
2 (xt âˆ’m)2

dm
+ a log b âˆ’log Î“(a) âˆ’(a + 1) log v âˆ’bvâˆ’1 âˆ’log q(v | D)

dv + const.
As we strive to ï¬nd the variational distribution for v, those terms that are independent
of this parameter can again be dropped as before. Consequently, we obtain
L(q) =

q(v | D)

âˆ’N
2 log v âˆ’vâˆ’1
2
N

t=1

q(m | D)(xt âˆ’m)2 dm
âˆ’(a + 1) log v âˆ’bvâˆ’1 âˆ’log q(v | D)

dv + const.â€²
(2.24)
42

2.5. A univariate example
with the new constant term speciï¬ed. In addition, with q(m | D) now known, this expres-
sion can be simpliï¬ed yet further. Therefore, by (A.2),
N

t=1

q(m | D)(xt âˆ’m)2 dm =
N

t=1
Eq(m | D)

(xt âˆ’m)2
=
N

t=1

Eq(m | D) {xt âˆ’m}
2 +
N

t=1
Varq(m | D) {xt âˆ’m}
=
N

t=1
(xt âˆ’Î¼m
â€²)2 + NÏƒm
â€².
(2.25)
So, we have an expression for L(q) that is now independent of m. We seek the variational
q(v | D) that maximises the lower bound, with respect to the density function integrating
to 1. Hence again, the Lagrangian Î½v is applied to construct ËœL(q) such that
ËœL(q) = L(q) + Î½v

q(v | D) dv âˆ’1

.
It is now possible to optimise ËœL(q) with respect to q(v | D). Thus, by diï¬€erentiating and
setting to zero, we achieve
âˆ‚ËœL(q)
âˆ‚q(v | D) = âˆ’

a + N
2 + 1

log v âˆ’vâˆ’1

b + 1
2
N

t=1
(xt âˆ’Î¼m
â€²)2 + N
2 Ïƒm
â€²

âˆ’log q(v | D) âˆ’1 + Î½v = 0.
A simple rearrangement here provides
q(v | D) âˆvâˆ’(a+ N
2 +1) exp

âˆ’vâˆ’1

b + 1
2
N

t=1
(xt âˆ’Î¼m
â€²)2 + N
2 Ïƒm
â€²

.
Hence, we have ï¬nally that the approximate posterior q(v | D) is an inverse gamma dis-
43

2.5. A univariate example
tribution given by
q(v | D) = IG(v | a â€² , b â€²),
(2.26)
where a â€² and b â€² have been found to be equivalent to
a â€² = a + N
2
(2.27)
b â€² = b + 1
2
N

t=1
(xt âˆ’Î¼m
â€²)2 + N
2 Ïƒm
â€².
(2.28)
Consequently, we can now compute Eq(v | D){vâˆ’1}, upon which the equations for Î¼mâ€² and
Ïƒmâ€² depend. It is evident that Eq(v | D){vâˆ’1} = a â€²
b â€² via (A.5). To summarise, we have a set
of variational parameters, {Î¼mâ€², Ïƒmâ€², a â€², b â€²}. When inspecting the corresponding alge-
braic expressions, it follows that these equations, and hence the variational distributions
for m and v, are dependent upon each other, as commented upon in Section 2.4.4. There-
fore, we solve these equations iteratively. That is, we update the parameter values by
continuous use of (2.22), (2.23), (2.27) and (2.28) until convergence. The resulting distri-
butions are then optimal in terms of minimising KL divergence, given the approximation
(2.9). In the free form method, this procedure of updating each variational distribution
with respect to all others in the approximation will be seen in further examples in this
thesis.
2.5.2
Fixed form variational method
The second variational procedure is now applied to learn an approximate posterior for
both m and v, given a dataset. Consequently, ï¬xed distributional forms for both varia-
tional distributions must be chosen. On this occasion, it is straightforward to make such
selections since we can use the distributions derived by the free form approach. Hence,
44

2.5. A univariate example
we have
q(m | D) = N (m | Î¼m
â€², Ïƒm
â€²)
q(v | D) = IG(v | a â€² , b â€²),
and these distributions are required to be independent as before, thus simplifying com-
putation.
We can return to (2.16) and compute L(q) initially, using the now known
variationals. At this point, we realise an overlap between the free and ï¬xed variational
approaches. The free form method concludes by deriving L(q) to obtain an estimate of
the log evidence, provided this calculation is deemed necessary. However initially, in this
ï¬xed form case, the procedure is carried out in identical fashion since q(m | D) and q(v | D)
have been ï¬xed to follow the same distributions as previously suggested by the free form
approach.
The sum of integrals in (2.16) are now tackled in order. Thus ï¬rstly, we acquire

q(m | D)q(v | D)
 N

t=1
log p(xt | m, v)

dm dv
=
N

t=1
	
q(m | D)q(v | D)

âˆ’1
2 log 2Ï€v âˆ’vâˆ’1
2 (xt âˆ’m)2

dm dv

= âˆ’N
2 log 2Ï€ âˆ’N
2

q(v | D) log v dv
âˆ’1
2
N

t=1

q(v | D)vâˆ’1 dv

q(m | D)(xt âˆ’m)2 dm
= âˆ’N
2 log 2Ï€ âˆ’N
2 [log b â€² âˆ’Ïˆ(a â€²)] âˆ’a â€²
2b â€²
N

t=1
(xt âˆ’Î¼m
â€²)2 âˆ’Na â€²
2b â€² Ïƒm
â€².
In the last line, (2.25), (A.5) and (A.6) have been applied. Further, by the deï¬nition of
the prior and variational distribution for m,
45

2.5. A univariate example

q(m | D) log p(m) dm
=

q(m | D)

âˆ’1
2 log 2Ï€Ïƒm âˆ’Ïƒâˆ’1
m
2 (m âˆ’Î¼m)2

dm
= âˆ’1
2 log 2Ï€Ïƒm âˆ’Ïƒâˆ’1
m
2

Eq(m | D) {m âˆ’Î¼m}
2 + Varq(m | D) {m âˆ’Î¼m}

= âˆ’1
2 log 2Ï€Ïƒm âˆ’Ïƒâˆ’1
m
2

(Î¼m
â€² âˆ’Î¼m)2 + Ïƒm
â€²
.
In a similar fashion for v, we obtain

q(v | D) log p(v) dv
=

q(v | D)

a log b âˆ’log Î“(a) âˆ’(a + 1) log v âˆ’bvâˆ’1
dv
= a log b âˆ’log Î“(a) âˆ’(a + 1) [log b â€² âˆ’Ïˆ(a â€²)] âˆ’ba â€²
b â€² .
Moreover, it is apparent that

q(m | D) log q(m | D) dm
=

q(m | D)

âˆ’1
2 log 2Ï€Ïƒm
â€² âˆ’(Ïƒmâ€²)âˆ’1
2
(m âˆ’Î¼m
â€²)2

dm
= âˆ’1
2 log 2Ï€Ïƒm
â€² âˆ’(Ïƒmâ€²)âˆ’1
2

Eq(m | D) {m âˆ’Î¼m
â€²}
2 + Varq(m | D) {m âˆ’Î¼m
â€²}

= âˆ’1
2 log 2Ï€Ïƒm
â€² âˆ’1
2.
Finally, in a comparable way to

q(v | D) log p(v) dv, it follows that

q(v | D) log q(v | D) dv
=

q(v | D)

a â€² log b â€² âˆ’log Î“(a â€²) âˆ’(a â€² + 1) log v âˆ’b â€²vâˆ’1
dv
46

2.5. A univariate example
= âˆ’log Î“(a â€²) âˆ’log b â€² + (a â€² + 1)Ïˆ(a â€²) âˆ’a â€².
By collecting all these integrals together, we can substitute into (2.16), and hence obtain
an expression for L(q). This gives the lower bound to be
L(q) = âˆ’N
2 log 2Ï€ âˆ’N
2 [log b â€² âˆ’Ïˆ(a â€²)] âˆ’a â€²
2b â€²
N

t=1
(xt âˆ’Î¼m
â€²)2 âˆ’Na â€²
2b â€² Ïƒm
â€²
âˆ’1
2 log 2Ï€Ïƒm âˆ’Ïƒâˆ’1
m
2

(Î¼m
â€² âˆ’Î¼m)2 + Ïƒm
â€²
+ a log b âˆ’log Î“(a)
âˆ’(a + 1) [log b â€² âˆ’Ïˆ(a â€²)] âˆ’ba â€²
b â€² + 1
2 log 2Ï€Ïƒm
â€² + 1
2 + log Î“(a â€²)
+ log b â€² âˆ’(a â€² + 1)Ïˆ(a â€²) + a â€².
(2.29)
Consequently, we can ï¬nd the maximum of the lower bound by setting its gradient to zero.
That is, we eï¬€ect partial diï¬€erentiation of L(q) with respect to the variational parameter
set {Î¼mâ€², Ïƒmâ€², a â€², b â€²}. Thus, we examine initially maximisation with respect to Î¼mâ€². This
then yields
âˆ‚L(q)
âˆ‚Î¼mâ€² =
âˆ‚
âˆ‚Î¼mâ€²

âˆ’Ïƒâˆ’1
m
2 (Î¼m
â€² âˆ’Î¼m)2 âˆ’a â€²
2b â€²
N

t=1
(xt âˆ’Î¼m
â€²)2

= âˆ’Ïƒâˆ’1
m (Î¼m
â€² âˆ’Î¼m) + a â€²
b â€²
 N

t=1
xt âˆ’NÎ¼m
â€²

.
By setting to zero and then rearranging, we ï¬nd that the update equation for Î¼mâ€² is
identical to (2.22) as required, recalling the deï¬nition of Eq(v | D){vâˆ’1}. Diï¬€erentiating
with respect to Ïƒmâ€² leads to
âˆ‚L(q)
âˆ‚Ïƒmâ€² =
âˆ‚
âˆ‚Ïƒmâ€²

âˆ’Na â€²
2b â€² Ïƒm
â€² âˆ’Ïƒâˆ’1
m
2 Ïƒm
â€² + 1
2 log 2Ï€Ïƒm
â€²

= âˆ’Na â€²
2b â€² âˆ’Ïƒâˆ’1
m
2
+ (Ïƒmâ€²)âˆ’1
2
.
47

2.5. A univariate example
On this occasion, equating to zero and solving for Ïƒmâ€² provides (2.23). Eï¬€ecting the same
procedure in terms of a â€² implies
âˆ‚L(q)
âˆ‚a â€²
=
âˆ‚
âˆ‚a â€²

N
2 Ïˆ(a â€²) âˆ’a â€²
2b â€²
N

t=1
(xt âˆ’Î¼m
â€²)2 âˆ’Na â€²
2b â€² Ïƒm
â€² + (a + 1)Ïˆ(a â€²)
âˆ’ba â€²
b â€² + log Î“(a â€²) âˆ’(a â€² + 1)Ïˆ(a â€²) + a â€²

= Ïˆ1(a â€²)
	
a + N
2 âˆ’a â€²

âˆ’1
b â€²

b + 1
2
N

t=1
(xt âˆ’Î¼m
â€²)2 + N
2 Ïƒm
â€²

+ 1,
(2.30)
where the trigamma function (Johnson et al., 1992), denoted by Ïˆ1(z) for some z âˆˆR, is
deï¬ned to be
Ïˆ1(z) = d2
dz2 log Î“(z) = d
dzÏˆ(z).
Finally, the partial diï¬€erentiation of L(q) with respect to b â€² oï¬€ers
âˆ‚L(q)
âˆ‚b â€²
=
âˆ‚
âˆ‚b â€²

âˆ’N
2 log b â€² âˆ’a â€²
2b â€²
N

t=1
(xt âˆ’Î¼m
â€²)2 âˆ’Na â€²
2b â€² Ïƒm
â€²
âˆ’(a + 1) log b â€² âˆ’ba â€²
b â€² + log b â€²

=
a â€²
(b â€²)2

b + 1
2
N

t=1
(xt âˆ’Î¼m
â€²)2 + N
2 Ïƒm
â€²

âˆ’1
b â€²
	
a + N
2

.
(2.31)
By inspecting (2.30) and (2.31), it is apparent that these expressions are zeroed by speci-
ï¬cations (2.27) and (2.28) for a â€² and b â€². Therefore, when choosing the variational distri-
butional forms in the ï¬xed form method to be those suggested by the free form method,
the two variational approaches, as expected, have coincided. However, as Miskin (2000)
indicates, one can make incorrect choices for the approximating posteriors in the ï¬xed
form algorithm, hence aï¬€ecting subsequent results.
48

2.5. A univariate example
2.5.3
The Gibbs sampler
Here, we are only required to ï¬nd the two full conditional posterior distributions for m
and v, namely p(m | v, D) and p(v | m, D). From (2.14), it is evident that
p(m | v, D) âˆexp

âˆ’1
2

vâˆ’1
N

t=1
(xt âˆ’m)2 + Ïƒâˆ’1
m (m âˆ’Î¼m)2

âˆexp
âŽ§
âŽ¨
âŽ©âˆ’1
2

Nvâˆ’1 + Ïƒâˆ’1
m


m âˆ’vâˆ’1  N
t=1 xt + Ïƒâˆ’1
m Î¼m
Nvâˆ’1 + Ïƒâˆ’1
m
2âŽ«
âŽ¬
âŽ­,
and hence
p(m | v, D) = N

vâˆ’1  N
t=1 xt + Ïƒâˆ’1
m Î¼m
Nvâˆ’1 + Ïƒâˆ’1
m
,
1
Nvâˆ’1 + Ïƒâˆ’1
m

.
(2.32)
Furthermore,
p(v | m, D) âˆvâˆ’(a+ N
2 +1) exp

âˆ’vâˆ’1

b + 1
2
N

t=1
(xt âˆ’m)2

,
whereby
p(v | m, D) = IG

a + N
2 , b + 1
2
N

t=1
(xt âˆ’m)2

.
(2.33)
The semi-conjugacy of the problem is now realised, i.e. the full conditionals for m and
v are of standard form, and follow the same distributions as the corresponding priors.
Once initialised anywhere such that the posterior has support, the sampler then produces
alternate simulations from the full conditionals and a bivariate Markov chain is hence
deï¬ned. Upon convergence, the corresponding samples will be draws from the density of
interest, p(m, v | D). Moreover, the values for each component are simulations from the
corresponding marginal posterior distribution.
49

2.5. A univariate example
2.5.4
EM algorithm
Two separate EM algorithms are now constructed to ï¬nd the modes Ëœm and Ëœv of the respec-
tive marginal posterior densities, p(m | D) and p(v | D). Hence, via the full conditionals
(2.32) and (2.33), the unknown marginals can be approximated by p(m | v = Ëœv, D) and
p(v | m = Ëœm, D).
From (2.14), it is clear that the logarithm of the joint posterior density is
log p(m, v | D) = âˆ’

a + N
2 + 1

log vâˆ’vâˆ’1
2
N

t=1
(xtâˆ’m)2âˆ’Ïƒâˆ’1
m
2 (mâˆ’Î¼m)2âˆ’bvâˆ’1. (2.34)
Suppose that we are currently at iteration k. Initially, we use Algorithm 3 to derive an
expression for m(k). So, in the E-step, we take the expectation of (2.34) with respect to
p(v | m(kâˆ’1), D), where m(kâˆ’1) is the marginal posterior mode at the previous iteration.
Denoting Em(kâˆ’1){Â·} to be the expectation with respect to p(v | m(kâˆ’1), D), the following
is yielded:
Em(kâˆ’1) {log p(m, v | D)} = âˆ’

a + N
2 + 1

Em(kâˆ’1) {log v} âˆ’1
2 Em(kâˆ’1)

vâˆ’1
N

t=1
(xt âˆ’m)2
âˆ’Ïƒâˆ’1
m
2 (m âˆ’Î¼m)2 âˆ’b Em(kâˆ’1)

vâˆ’1
.
(2.35)
Here, evaluation of Em(kâˆ’1) {log v} is not required since, being independent of m, the cor-
responding term in (2.35) will disappear under diï¬€erentiation in the M-step. Resultantly,
we need only compute Em(kâˆ’1) {vâˆ’1}, which, by (A.5) and our previous derivation of the
full conditional for v, is equivalent to
Em(kâˆ’1)

vâˆ’1
=
a + N
2
b + 1
2
 N
t=1 [xt âˆ’m(kâˆ’1)]2.
(2.36)
We can now proceed to the M-step. By diï¬€erentiating (2.35) with respect to m, we hence
50

2.5. A univariate example
achieve
âˆ‚
âˆ‚mEm(kâˆ’1) {log p(m, v | D)} = Em(kâˆ’1)

vâˆ’1
N

t=1
(xt âˆ’m) âˆ’Ïƒâˆ’1
m (m âˆ’Î¼m).
By equating to zero and solving for m, the current marginal posterior mode estimate for
p(m | D) is
m(k) = Em(kâˆ’1) {vâˆ’1}  N
t=1 xt + Ïƒâˆ’1
m Î¼m
NEm(kâˆ’1) {vâˆ’1} + Ïƒâˆ’1
m
,
(2.37)
substituting in (2.36). The same procedure is performed to determine v(k). As a conse-
quence, we now calculate the expectation of (2.34) with respect to p(m | v(kâˆ’1), D) in the
E-step. Hence, we obtain
Ev(kâˆ’1) {log p(m, v | D)} = âˆ’

a + N
2 + 1

log v âˆ’vâˆ’1
2
N

t=1
Ev(kâˆ’1)

(xt âˆ’m)2
âˆ’Ïƒâˆ’1
m
2 Ev(kâˆ’1)

(m âˆ’Î¼m)2
âˆ’bvâˆ’1.
(2.38)
We realise that, similar to before, computation of Ev(kâˆ’1) {(m âˆ’Î¼m)2} is not necessary.
Therefore, we have
Ev(kâˆ’1)

(xt âˆ’m)2
= (Ev(kâˆ’1) {xt âˆ’m})2 + Varv(kâˆ’1) {m}
=

xt âˆ’
$
v(kâˆ’1)%âˆ’1  N
t=1 xt + Ïƒâˆ’1
m Î¼m
N [v(kâˆ’1)]âˆ’1 + Ïƒâˆ’1
m
2
+
1
N [v(kâˆ’1)]âˆ’1 + Ïƒâˆ’1
m
,
(2.39)
due to (2.32). In the M-step, maximising (2.38) with respect to v implies
âˆ‚
âˆ‚vEv(kâˆ’1) {log p(m, v | D)} = âˆ’

a + N
2 + 1

vâˆ’1
+ vâˆ’2
2
N

t=1
Ev(kâˆ’1)

(xt âˆ’m)2
+ bvâˆ’2.
51

2.5. A univariate example
So, this equation is zeroed when
v(k) = b + 1
2
 N
t=1 Ev(kâˆ’1) {(xt âˆ’m)2}
a + N
2 + 1
,
(2.40)
substituting in (2.39). By iterating equations (2.37) and (2.40) separately K times un-
til convergence, we will obtain Ëœm = m(K) and Ëœv = v(K), the modes for p(m | D) and
p(v | D) respectively. Thus, an approximation to these two marginal posteriors is given
by p(m | v = Ëœv, D) and p(v | m = Ëœm, D).
It is worth brieï¬‚y mentioning that the above derivation can also be used to obtain the
expressions for the variational parameters seen in Section 2.5.1. By application of (2.11),
it is apparent that both (2.22) and (2.23) can be read oï¬€from equation (2.35) without
any additional work, similarly (2.27) and (2.28) from (2.38).
2.5.5
A numerical example
We illustrate the theory above with a simple, numerical example.
Suppose that our
dataset consists of N = 20 samples, simulated from a univariate Gaussian distribution
with mean m = 2 and variance v = 1. In addition, the priors for m and v were given the
following speciï¬cations:
p(m) = N (m | 0, 10, 000)
p(v) = IG(v | 1, 0.001).
Thus, both priors are deemed to be diï¬€use as each has been assigned a huge variance.
In fact, as the variance of an IG(a, b) distribution is deï¬ned only for a > 2, the above
distribution for v has inï¬nite variance. So importantly, we do not favour any particular
value of the parameters a priori. A more thorough discussion of vague, inverse gamma
52

2.5. A univariate example
prior speciï¬cation, in particular, is oï¬€ered in Chapter 3.
The variational Bayes approach, EM algorithm and Gibbs sampler were then run for this
example. In the variational case, equations (2.22) and (2.23), for Î¼mâ€² and Ïƒmâ€² respectively,
are both dependent upon a â€² and b â€². So, an arbitrary, initial choice of a â€² = b â€² = 1 was
made for the algorithm to commence. Similarly, the EM algorithm and Gibbs sampler
were both initialised such that m(0) and v(0) were points simulated from the respective
prior distributions. The sampler was run for 10, 000 iterations, the ï¬rst 1000 of which
were discarded as burn-in. Convergence of the variational Bayes algorithm was extremely
rapid, taking no more than 4 iterations.
Figure 2.1 shows the plots of the approximate marginal posteriors for the two parameters,
illustrating the three methods. To recap, the variational posteriors are the distributions
(2.21) and (2.26) with variational parameters whose update equations have been run until
convergence. The marginals via the EM algorithm are the full conditionals (2.32) and
(2.33), dependent upon the posterior modes Ëœv and Ëœm respectively. Finally, kernel density
estimates are plotted for the draws obtained via the Gibbs sampler. Inspection of plots
(a) and (b) in Figure 2.1 clearly illustrate the similarity of the distributions produced by
the three approaches. Moreover, each marginal is centred at values very close to the true
values of the parameters. This is impressive since a dataset of only small size was used
to infer m and v. Hence in this case, the variational Bayes method appears to produce
results, considered equally as good as two other rival approximations.
Further evidence for the worth of the variational approach is oï¬€ered in Figure 2.2. Here,
contour lines are plotted for both the joint variational distribution, q(m, v | D), and the
true posterior (2.14), known up to a multiplicative constant. The ï¬gure clearly shows
that the contours for these distributions are centred in almost the equivalent position
and, moreover, are similar in shape. However, due to the independence assumption that
q(m, v | D) = q(m | D)q(v | D), the variational approximation is not quite able to fully
capture correlations between m and v, seen in the truth. Yet, it does correctly show that
53

2.6. A multivariate example
0
1
2
3
4
0.0
0.5
1.0
1.5
2.0
m
Density
Var
EM
Gibbs
0
1
2
3
4
0.0
0.5
1.0
1.5
v
Density
Var
EM
Gibbs
Iteration
m
0
2000
4000
6000
8000
1.5
2.0
2.5
3.0
Iteration
v
0
2000
4000
6000
8000
0.5
1.0
1.5
2.0
2.5
3.0
3.5
(a)
(b)
(c)
(d)
Figure 2.1: (a) and (b): Approximate marginal posterior distributions for m and v re-
spectively, using variational Bayes, the EM algorithm and the Gibbs sampler; (c) and (d):
Corresponding trace plots for m and v produced by the Gibbs sampler
the posterior density is not symmetric about the mode value of v.
2.6
A multivariate example
In the previous section, inter alia, a variational Bayesian approach was used to infer
approximate distributions for the unknown mean and variance of a univariate, Gaussian
sample. In fact, the above numerical example has shown the method to produce fast and
accurate results. These ideas are now extended to the corresponding multivariate case.
This will motivate subsequent chapters in this thesis, whereby variational Bayes is applied
to vector autoregressive models of order 1.
54

2.6. A multivariate example
m
v
1
2
3
0.5
1
1.5
m
v
1
2
3
0.5
1
1.5
(a)
(b)
Figure 2.2: Contour plots for: (a) Variational posterior, (b) True posterior
Consequently, we now possess a dataset D = (x1, . . . , xN), where each xt is an indepen-
dent, d-dimensional random vector such that xt âˆ¼N (m, V ) for all t = 1, . . . , N. Here,
m is a mean vector and V a d Ã— d covariance matrix. The speciï¬cation of priors for m
and V is now
p(m) = N (m | Î¼m, Î£m)
(2.41)
p(V ) = IW(V | A, r),
(2.42)
where the prior for V follows an inverse Wishart distribution with parameters A, a d Ã— d
matrix, and a scalar r. Further details of this distribution are provided in Appendix A.
These independent prior distributions merely generalise the univariate, semi-conjugate
choices, seen in Section 2.5, to higher dimensions.
To emphasise the need to approximate the joint posterior in this case, it follows that
p(m, V | D) âˆ
 N

t=1
p(xt | m, V )

p(m) p(V )
55

2.6. A multivariate example
= |V |âˆ’(r+d+N+1)/2 exp

âˆ’1
2

N

t=1
(xt âˆ’m)TV âˆ’1(xt âˆ’m)
+ (m âˆ’Î¼m)TÎ£âˆ’1
m (m âˆ’Î¼m) + Tr
$
V âˆ’1A
%

.
Of course, this is akin to (2.14) and shows that the above density will not factorise, hence
no distributional form can be found for the marginal posteriors of m and V . Thus, we can
use variational Bayesian techniques to infer respective variational distributions, q(m | D)
and q(V | D). Again, we form an approximation such that the joint variational posterior
factorises into the corresponding variational marginals.
We proceed by mimicking the free form method of Section 2.5.1, hence assuming no
variational distributional form. Consequently, the lower bound is now given by
L(q) =

q(m, V | D) log p(D, m, V )
q(m, V | D) dm dV.
(2.43)
Writing L(q) as a functional of both q(m | D) and q(V | D) is elementary via studying the
analogous univariate expressions, (2.17) and (2.18). We again notice the importance here
of independence between each prior and variational distribution. Hence, as a functional
of q(m | D), the following is acquired:
L(q) =

q(m | D)
 
q(V | D)
 N

t=1
log p(xt | m, V )

dV
+ log p(m) âˆ’log q(m | D)

dm + const.
(2.44)
The corresponding expression in terms of q(V | D) is
56

2.6. A multivariate example
L(q) =

q(V | D)
 
q(m | D)
 N

t=1
log p(xt | m, V )

dm
+ log p(V ) âˆ’log q(V | D)

dV + const.
(2.45)
The distributional form for q(m | D) is derived initially. By substituting in the appropriate
terms, (2.44) can be rewritten as
L(q) =

q(m | D)

N

t=1

q(V | D)

âˆ’d
2 log 2Ï€ âˆ’1
2 log |V |
âˆ’1
2(xt âˆ’m)TV âˆ’1(xt âˆ’m)

dV âˆ’d
2 log 2Ï€ âˆ’1
2 log |Î£m|
âˆ’1
2(m âˆ’Î¼m)TÎ£âˆ’1
m (m âˆ’Î¼m) âˆ’log q(m | D)

dm + const.
By dropping all terms independent of m, we then obtain
L(q) =

q(m | D)

âˆ’1
2
N

t=1
(xt âˆ’m)T Eq(V | D)

V âˆ’1
(xt âˆ’m) dV
âˆ’1
2(m âˆ’Î¼m)TÎ£âˆ’1
m (m âˆ’Î¼m) âˆ’log q(m | D)

dm + const.â€²
The term Eq(V | D) {V âˆ’1} can be computed upon determining the variational posterior
for V . The functional ËœL(q) is now formed using the Lagrangian Î½m in the way akin to
(2.20), hence ensuring that q(m | D) is normalised. We now seek the optimal q(m | D)
that maximises ËœL(q). Hence, by diï¬€erentiating, we obtain
âˆ‚ËœL(q)
âˆ‚q(m | D) = âˆ’1
2
N

t=1
(xt âˆ’m)T Eq(V | D)

V âˆ’1
(xt âˆ’m)
âˆ’1
2(m âˆ’Î¼m)TÎ£âˆ’1
m (m âˆ’Î¼m) âˆ’log q(m | D) âˆ’1 + Î½m = 0.
57

2.6. A multivariate example
Rearranging this expression then implies
q(m | D) âˆexp

âˆ’1
2

mT 
NEq(V | D)

V âˆ’1
+ Î£âˆ’1
m

m
âˆ’mT

Eq(V | D)

V âˆ’1
N

t=1
xt + Î£âˆ’1
m Î¼m

âˆ’
 N

t=1
xT
t Eq(V | D)

V âˆ’1
+ Î¼T
mÎ£âˆ’1
m

m

âˆexp

âˆ’1
2

m âˆ’

NEq(V | D)

V âˆ’1
+ Î£âˆ’1
m
âˆ’1

Eq(V | D)

V âˆ’1
N

t=1
xt + Î£âˆ’1
m Î¼m
T
Ã—
$
NEq(V | D)

V âˆ’1
+ Î£âˆ’1
m
%
Ã—

m âˆ’

NEq(V | D)

V âˆ’1
+ Î£âˆ’1
m
âˆ’1

Eq(V | D)

V âˆ’1
N

t=1
xt + Î£âˆ’1
m Î¼m
 
.
Hence, it follows that the variational posterior for m is a multivariate Gaussian distribu-
tion such that
q(m | D) = N (m | Î¼m
â€², Î£m
â€²),
(2.46)
with update equations for the variational parameters speciï¬ed as
Î¼m
â€² =

NEq(V | D)

V âˆ’1
+ Î£âˆ’1
m
âˆ’1

Eq(V | D)

V âˆ’1
N

t=1
xt + Î£âˆ’1
m Î¼m

(2.47)
Î£m
â€² =

NEq(V | D)

V âˆ’1
+ Î£âˆ’1
m
âˆ’1 .
(2.48)
The identical course is now taken for q(V | D). By substituting in for the prior on V and
likelihood, (2.45) is now given by
L(q) =

q(V | D)

N

t=1

q(m | D)

âˆ’d
2 log 2Ï€ âˆ’1
2 log |V |
âˆ’1
2(xt âˆ’m)TV âˆ’1(xt âˆ’m)

dm âˆ’log k + r
2 log |A|
âˆ’r + d + 1
2
log |V | âˆ’1
2Tr
$
V âˆ’1A
%
âˆ’log q(V | D)

dV + const.
58

2.6. A multivariate example
where k is deï¬ned by (A.10). Dropping all terms independent of V provides
L(q) =

q(V | D)

âˆ’N
2 log |V | âˆ’1
2
N

t=1
Eq(m | D)

(xt âˆ’m)TV âˆ’1(xt âˆ’m)

âˆ’r + d + 1
2
log |V | âˆ’1
2Tr
$
V âˆ’1A
%
âˆ’log q(V | D)

dV + const.â€²
(2.49)
By knowledge of q(m | D), we can also compute
Eq(m | D)

(xt âˆ’m)TV âˆ’1(xt âˆ’m)

= Eq(m | D) {xt âˆ’m}T V âˆ’1Eq(m | D) {xt âˆ’m}
+ Tr
$
V âˆ’1Varq(m | D) {xt âˆ’m}
%
= (xt âˆ’Î¼m
â€²)TV âˆ’1(xt âˆ’Î¼m
â€²) + Tr
$
V âˆ’1Î£m
â€²%
. (2.50)
Here, we have utilised the identity to ï¬nd the expectation of a quadratic form, i.e.
E

wTPw

= E {w}T P E {w} + Tr [P Var {w}] ,
(2.51)
where w is a random vector and P is a compatible, ï¬xed matrix (Rice, 1995).
By forming ËœL(q) with the Lagrangian Î½V , we diï¬€erentiate with respect to q(V | D):
âˆ‚ËœL(q)
âˆ‚q(V | D) = âˆ’N
2 log |V | âˆ’1
2
N

t=1
(xt âˆ’Î¼m
â€²)TV âˆ’1(xt âˆ’Î¼m
â€²) âˆ’N
2 Tr
$
V âˆ’1Î£m
â€²%
âˆ’r + d + 1
2
log |V | âˆ’1
2Tr
$
V âˆ’1A
%
âˆ’log q(V | D) âˆ’1 + Î½V = 0.
Notice that (xt âˆ’Î¼m
â€²)TV âˆ’1(xt âˆ’Î¼m
â€²) = Tr
$
V âˆ’1(xt âˆ’Î¼m
â€²)(xt âˆ’Î¼m
â€²)T%
since
Tr [PQR] = Tr [RPQ] = Tr [QRP]
59

2.6. A multivariate example
for compatible matrices P, Q, R (Harville, 1997).
Thus, deï¬ning S â€² = 1
N
 N
t=1(xt âˆ’Î¼m
â€²)(xt âˆ’Î¼m
â€²)T, it hence follows that
q(V | D) âˆ|V |âˆ’(r+N+d+1)/2 exp

âˆ’1
2Tr
$
V âˆ’1 (A + NÎ£m
â€² + NS â€²)
%
.
Therefore, the variational for V is distributed as
q(V | D) = IW(V | A â€², r â€²),
(2.52)
with A â€² and r â€² expressed as
A â€² = A + NÎ£m
â€² + NS â€²
(2.53)
r â€² = r + N.
(2.54)
Hence, we can now express Eq(V | D) {V âˆ’1} = r â€²(A â€²)âˆ’1 via (A.11) and this result is sub-
stituted into both (2.47) and (2.48). Finally, update equations (2.47), (2.48), (2.53) and
(2.54) are iterated until converged values of Î¼m
â€², Î£m
â€², A â€² and r â€² are found, hence deï¬ning
the variational distributions for m and V .
In the task of deriving variational posteriors for the unknown mean and variance of a
Gaussian sample, it is evident that the univariate case in Section 2.5 has been naturally
extended in this section to higher dimensions. Clearly, the choice of multivariate normal
and inverse Wishart priors for m and V respectively simply generalises the semi-conjugate
speciï¬cations seen previously. This is further true in terms of the variational distributions
ultimately derived in both circumstances. In the following chapter, similar variational
multivariate theory will be required to score sparse vector autoregressive models.
60

2.7. Summary
2.7
Summary
The purpose of this chapter was to introduce the theory behind variational Bayes, founded
upon minimising the KL divergence between the approximating, variational distribution
and the true posterior.
Hence, as Kullback-Leibler is a global measure, an analytic,
global approximation to this distribution will be provided that is optimal over the whole
parameter space. This is in contrast to Laplaceâ€™s approximation that only makes a local
(Gaussian) approximation to the posterior at the MAP estimate. Furthermore, we noted
that L(q), a bound on the log marginal likelihood for each model, can be utilised as a
variational model comparison criterion. This feature is exploited in the remainder of this
thesis.
The main problem with the variational Bayesian approach is that, for computational
reasons, the true posterior is assumed to factorise. This implies that we cannot determine
any a posteriori dependencies between parameters. However, in contrast, we have seen
that variational Bayes is a fast and computationally eï¬ƒcient procedure. In addition, the
example of Section 2.5.5 has moreover revealed its accuracy, relative to two competing
alternatives: the Gibbs sampler and the EM algorithm.
The option of using either a free form or ï¬xed form variational method would also appear
attractive. As has been mentioned, care must be employed when choosing a distributional
form for the variationals in the latter case to ensure a reliable approximation. Yet, by
not making such an assumption, the free form procedure will always ensure the best,
possible variationals are selected. On the other hand, the ï¬xed form method is often
straightforward to apply for more complicated models where the free form approach is
intractable, i.e. in situations where integration over the model parameters cannot be
performed. Although that is not the case in this thesis, both of these procedures will have
an important role to play in Chapters 3 and 5.
61

Chapter 3
Model comparison of VAR(1) models
3.1
Introduction
By deï¬nition, a time series is a set of data values that are measured at equally spaced,
successive time points. For instance, a simple example would be to monitor the average
price of houses in a particular region each month. By modelling such data accurately, we
hope to be able to predict future events in the series. A popular way to eï¬€ect this would be
to use an autoregressive (AR) model, deï¬ned so that there exists a linear dependence on
previous data values. Moreover, if the data is of dimension d, then the time series is now
multivariate (i.e. there are d time series), and can be modelled via a vector autoregressive
(VAR) process, possessing either a zero or non-zero mean.
The Bayesian treatment of VAR models has traditionally focussed on learning the opti-
mum model order and the model parameters, given a set of time series data. Such analysis
is analytically intractable. To tackle this, the variational Bayesian algorithm has been
often applied as an approximation. For instance, in the context of choosing the model
order p, its use has been seen when modelling via a zero mean, univariate autoregressive
model, with noise given by both a Gaussian distribution (Penny and Roberts, 2000) and
62

3.2. VAR(1) graphical models
a mixture of Gaussians (Roberts and Penny, 2002) and, moreover, a zero mean VAR(p)
model (Penny and Roberts, 2002). In addition, the method has allowed approximation
of the parameter posterior distributions found in dynamic linear models, leading to iden-
tiï¬cation and subsequent graphical display of potential interactions between genes (Beal
et al., 2005).
In contrast, in the rest of this thesis, an analogous treatment is provided to the particular
situation of VAR models with ï¬xed model order 1, but sparse matrix of VAR coeï¬ƒcients,
denoted as A. Hence, it can be shown that the VAR process can be represented graphically.
Moreover, the use of sparsity as a modelling tool implies that we are able to develop
a model comparison problem.
This is due to the construction of a candidate set of
potential â€˜A-graphsâ€™, corresponding to sparse â€˜A-matricesâ€™. Our task therefore is, given
data modelled using a VAR(1) process, to ï¬nd the models that appear the most likely
from the set. That is, we want to estimate the unknown sparsity structure of A, the
autoregressive matrix. In this chapter, the zero mean case is considered, in Chapter 5,
non-zero mean models. Of course, we already know that the variational framework is
particularly attractive for this purpose as we can use LMi(qi), a tractable lower bound on
the logarithm of the marginal likelihood, inherent within the algorithm, to rank candidate
models.
3.2
VAR(1) graphical models
We commence by studying the family of VAR(p) models, in particular the VAR(1) process,
and showing how to model using sparsity. The zero mean VAR(p) process of dimension
d is expressed as
yt =
p

i=1
ytâˆ’iA(i) + et.
(3.1)
So, as Penny and Roberts (2002) indicate, the new, t-th value of the multivariate time
63

3.2. VAR(1) graphical models
series, yt, is explained via a linear combination of the p previous data values of the series.
Here, yt = (yt1, yt2, . . . , ytd), a (1 Ã— d) vector, each A(i) is a d Ã— d matrix of coeï¬ƒcients
and et = (et1, et2, . . . , etd) is a (1 Ã— d) noise-vector, distributed as
et âˆ¼N (0, Î“).
Moreover, with et independent to eu for t Ì¸= u (i.e. Cov(et, eu) = 0) and with zero mean,
such vectors are deï¬ned to be Gaussian white noise. We now focus in particular on the
following zero mean VAR(1) model:
yt = ytâˆ’1A + et,
(3.2)
where et is distributed as above.
The covariance matrix is now deï¬ned as Î“ = Ïƒ2Id
for unknown parameter Ïƒ2 and d Ã— d identity matrix Id. This speciï¬cation implies that
all oï¬€-diagonal covariances are zero, i.e. Cov(eij, ekl) Ì¸= 0 if and only if (i, j) = (k, l)
for i, k = 1, . . .N and j, l = 1, . . . d, assuming N samples are collected.
Moreover,
Var(eij) = Ïƒ2. We deï¬ne Î“ in this way since, in a Bayesian analysis, it allows a simple,
univariate prior speciï¬cation on Ïƒ2 as opposed to needing a more complicated speciï¬cation
on a matrix, such as an inverse Wishart prior (c.f. Appendix A).
For a detailed analysis of VAR(p) models, refer to LÂ¨utkepohl (2005). We now draw special
attention to the matrix A of VAR(1) coeï¬ƒcients. For the purposes of what follows, it
is assumed that A is a sparse matrix. Hence, by deï¬nition, it will consist of many, in
particular oï¬€-diagonal, elements constrained to be zero, with only a few, unspeciï¬ed non-
zero entries. A matrix of this ilk allows us to take advantage of the substantial number
of zeroes that it possesses. For instance, it can be related to a graphical structure. We
realise that, in a diï¬€erent context, the pattern of zeroes in the concentration matrix of
an arbitrary multivariate Gaussian distribution provides the conditional independence
64

3.2. VAR(1) graphical models
structure, which subsequently characterises an existent graphical (Gaussian) model. This
is detailed in Appendix B.
Similarly, the sparse matrix A in a VAR(1) process, containing a clear zero structure,
can be represented graphically also. To do this, we must model (3.2) using a dynamic
graphical structure (Ghahramani, 1997; Friedman, Murphy, and Russell, 1998; Mihajlovic
and Petkovic, 2001). Of course, the same procedure can be applied in the non-zero mean
case. We realise that a Bayesian network (a graphical model with directed edges) is used
to describe the conditional dependencies between a ï¬xed set of random variables in a
static situation (see Appendix B).
Conversely, a dynamic Bayesian network is a special case of the afore-mentioned static
graphical model, speciï¬cally orientated towards modelling time series. Each time point,
at which the values of a set of random variables are observed, is often referred to as a time
slice. Within a network, directed edges connect nodes from one slice to the next, denoting
the dependencies of the corresponding variables. Such edges are sometimes called inter-
edges. A convention is adopted whereby inter-edges point in the direction of time, hence
illustrating that one variable can cause another, only if the latter is in the future.
Moreover, dynamic Bayesian networks can also contain edges within each slice, known as
intra-edges. In this case, the conditional dependencies between variables in a single time
slice are represented by a static Bayesian network. In other words, a dynamic Bayesian
network can be viewed as merely a collection of static Bayesian networks, linked by inter-
edges. Each dynamic network would contain not only the identical graphical structure for
every time slice, but, moreover, the identical dependencies between slices. Thus, notice
that the term â€˜dynamicâ€™ does not refer to the network changing over time slices, but
instead to the dynamic process being modelled.
VAR models can be represented as continuous-state dynamic Bayesian networks since
each node is a continuous random variable. In what follows, we consider no intra-edges
65

3.2. VAR(1) graphical models
in the graphical model. However, such edges, given as undirected connections, can be
used to specify the zero structure in the corresponding concentration matrix of the noise
vector et (Eichler, 2001).
In our case, the VAR model has order equal to 1.
Thus,
consider a dynamic Bayesian network between times t âˆ’1 and t, where each component
of ytâˆ’1 = (ytâˆ’1,1, ytâˆ’1,2, . . . , ytâˆ’1,d) and yt is a node. We use inter-edges to connect nodes
in these two successive time slices together and this pattern is repeated over all slices.
The network is correspondingly said to have order 1. By aggregating the nodes yti for
each i = 1, . . . , d across all time points t (in particular, from t âˆ’1 to t) into a single
node, say yi, in the time series graph, we can hence form a causality graph (Dahlhaus and
Eichler, 2003). Thus, each node represents one component of the whole time series. If a
component is dependent upon its own past, we allow this to be expressed by a directed
self-loop.
It has previously been documented that in such a time series graph with p = 1, for
a, b = 1, . . ., d, an edge exists between nodes ytâˆ’1,a and ytb if and only if the element
aba of the autoregressive matrix is non-zero (Eichler, 2001; Murphy, 2002; Dahlhaus and
Eichler, 2003). We note that such a result generalises to a VAR(p) model. Hence, there
is a clear link between the causality graph and A in this circumstance as the former is
deï¬ned through the sparsity structure of the latter. Due to this relationship, the causality
graph is resultantly referred to as an A-graph throughout the remainder of this thesis.
The subsequent example elucidates the situation.
3.2.1
Example
Suppose d = 2. Consider Figure 3.1, showing a time series graph for a VAR(1) pro-
cess. As mentioned erstwhile for such a model, inter-edges are used to deï¬ne a structure
between successive time slices, here shown repeated.
By letting yi = (yi1, yi2) where
i = t âˆ’2, t âˆ’1, t, the nodes on the graph are clearly speciï¬ed by representing these ran-
66

3.2. VAR(1) graphical models
dom variables.
t âˆ’2
t âˆ’1
t
1
2
Figure 3.1: Time series graph for a VAR(1) model
By concentrating only on one pair of successive slices, we can hence produce a causality
graph across all time slices for this process, with nodes y1 and y2, as given below.
y1
y2
Figure 3.2: Causality graph for the VAR(1) process
Notice the use of self-loops for both nodes here. Using the above result of correspondence
between the dynamic Bayesian network, hence causality graph, and sparse A-matrix, we
have the speciï¬cation in this circumstance that A =
âŽ›
âŽâˆ—
0
âˆ—
âˆ—
âŽž
âŽ , whereby âˆ—represents a
free, non-zero element. Thus, the graph of Figure 3.2 is termed an A-graph.
67

3.3. Scoring zero mean VAR(1) graphical models
3.3
Scoring zero mean VAR(1) graphical models
It is clear that the variational Bayesian method is of high relevance in terms of scoring
models. We now apply this to the particular case of zero mean VAR(1) models. Hence,
using the theory of Section 3.2, we construct a candidate set of graphical models, say
M = {M1, M2, . . .}. Each graphical model Mi relates to an A-graph, Gi, which, in turn,
corresponds to a sparse A-matrix, denoted by A(i). Recall that there exists an edge be-
tween two nodes of a given Gi if and only if the correct corresponding element of A(i) is
non-zero. We can quantify the evidence for each prospective graphical model with the
corresponding marginal likelihood, denoted as p({yt} | Mi). However, as previously dis-
cussed, we can approximate this quantity using a variational Bayesian framework and, in
particular, the tractable lower bound LMi(qi). Henceforth, we assume not only depen-
dence of the lower bound, but also conditioning in our distributions upon the graphical
model Mi, although not stated explicitly.
The subsequent set-up follows that of Penny and Roberts (2002). Assume there exists
t = 1, . . . , N independent samples of the time series. Therefore, to take account of and
store these samples, we rewrite (3.2) using matrix notation, and hence form a multivariate
linear model. Firstly, deï¬ne xt = [ytâˆ’1] for all t = 1, . . . , N. Then, we form matrices Y ,
X and E, all of which have dimension N Ã— d, such that the t-th row of each matrix is
respectively given by yt, xt and et. Consequently, using the deï¬nitions of these vectors,
we obtain a matrix equation such that
âŽ›
âŽœ
âŽœ
âŽœ
âŽœ
âŽœ
âŽœ
âŽœ
âŽœ
âŽœ
âŽœ
âŽ
y11
. . .
y1d
...
...
...
yt1
. . .
ytd
...
...
...
yN1
. . .
yNd
âŽž
âŽŸ
âŽŸ
âŽŸ
âŽŸ
âŽŸ
âŽŸ
âŽŸ
âŽŸ
âŽŸ
âŽŸ
âŽ 
=
âŽ›
âŽœ
âŽœ
âŽœ
âŽœ
âŽœ
âŽœ
âŽœ
âŽœ
âŽœ
âŽœ
âŽ
x11
. . .
x1d
...
...
...
xt1
. . .
xtd
...
...
...
xN1
. . .
xNd
âŽž
âŽŸ
âŽŸ
âŽŸ
âŽŸ
âŽŸ
âŽŸ
âŽŸ
âŽŸ
âŽŸ
âŽŸ
âŽ 
âŽ›
âŽœ
âŽœ
âŽœ
âŽ
a11
. . .
a1d
...
...
...
ad1
. . .
add
âŽž
âŽŸ
âŽŸ
âŽŸ
âŽ +
âŽ›
âŽœ
âŽœ
âŽœ
âŽœ
âŽœ
âŽœ
âŽœ
âŽœ
âŽœ
âŽœ
âŽ
e11
. . .
e1d
...
...
...
et1
. . .
etd
...
...
...
eN1
. . .
eNd
âŽž
âŽŸ
âŽŸ
âŽŸ
âŽŸ
âŽŸ
âŽŸ
âŽŸ
âŽŸ
âŽŸ
âŽŸ
âŽ 
.
68

3.3. Scoring zero mean VAR(1) graphical models
So, we can succinctly denote this as
Y = XA + E.
(3.3)
At the end-points, we take x1 = (0, 0, . . ., 0) and xN = yNâˆ’1. xN is speciï¬ed directly
through the deï¬nition of xt. Correspondingly, we set x1 = y0 to equal the mean of the
stationary distribution. Of course, (3.2) is such that E(yt) = 0 for all t, i.e. all yt possess
this mean, regardless of t.
Next, by using the afore-mentioned matrix notation, we can now resultantly compute
the probability of the data, using ideas from LÂ¨utkepohl (2005) and Box and Tiao (1992).
Assume a given data set D = {X, Y }. By using the vec operator, we now rewrite (3.3)
according to
vec(Y ) = vec(XA + E)
= vec(XA) + vec(E)
= (Id âŠ—X)vec(A) + vec(E)
=â‡’y = (Id âŠ—X)a + e,
(3.4)
where y, e are both dN Ã— 1 vectors and a is a d2 Ã— 1 vector. That is, for example, y is
formed by stacking the columns of Y one under the other, similarly for e and a.
Here, we have used a core property of the vec operator: vec(P +Q) = vec(P)+vec(Q), for
compatible matrices P and Q (Petersen and Pedersen, 2007). In addition, we deï¬ne âŠ—to
be a Kronecker product (Henderson and Searle, 1981). Furthermore, suppose speciï¬cally
that P and Q are matrices of dimensions m Ã— p and p Ã— r respectively. Then, notice the
result from Henderson and Searle (1979) that
vec(PQ) = (Ir âŠ—P)vec(Q) = (QT âŠ—P)vec(Ip) = (QT âŠ—Im)vec(P).
(3.5)
69

3.3. Scoring zero mean VAR(1) graphical models
Recall that et âˆ¼N (0, Ïƒ2Id). We now determine the mean vector and covariance ma-
trix of e.
Clearly, E(e) = 0.
Moreover, to derive the covariance, we deï¬ne e(s) =
(e1s, e2s, . . . , eNs)T, the error vector of the component s = 1, . . . , d for each of the N data
samples, i.e. the s-th column of E. Thus,
Var(e) = Var
âŽ›
âŽœ
âŽœ
âŽœ
âŽœ
âŽ
e(1)
...
e(d)
âŽž
âŽŸ
âŽŸ
âŽŸ
âŽŸ
âŽ 
=
âŽ›
âŽœ
âŽœ
âŽœ
âŽ
Var

e(1)

. . .
Cov

e(1), e(d)

...
...
...
Cov

e(d), e(1)

. . .
Var

e(d)

âŽž
âŽŸ
âŽŸ
âŽŸ
âŽ .
Assume henceforth that i, k = 1, . . . N and j, l, r, s = 1, . . .d. We know that Var(eij) =
Ïƒ2, for all i, j.
Thus, for each s, it follows that Var(e(s)) = Ïƒ2IN, an N Ã— N ma-
trix. Moreover, from before, Cov(eij, ekl) = 0 if and only if (i, j) Ì¸= (k, l). Therefore,
Cov

e(r), e(s)

= 0 for all r Ì¸= s.
As E possesses d columns, consequently Var(e) = Id âŠ—Ïƒ2IN by deï¬nition of the Kronecker
product. Therefore, e âˆ¼N (0, IdâŠ—Ïƒ2IN). In other words, the probability density function
for e is denoted by
p(e | Ïƒ2) = (2Ï€)âˆ’dN
2 ,,Id âŠ—Ïƒ2IN
,,âˆ’1
2 exp

âˆ’1
2eT(Id âŠ—Ïƒ2IN)âˆ’1e

.
(3.6)
Ultimately, to ï¬nd the likelihood of the data, we rearrange (3.4) in terms of e and sub-
stitute into the exponent of the above. By concentrating solely on this exponent for the
time being, this provides
exp

âˆ’1
2eT(Id âŠ—Ïƒâˆ’2IN)e

= exp

âˆ’1
2 [y âˆ’(Id âŠ—X)a]T (Id âŠ—Ïƒâˆ’2IN) [y âˆ’(Id âŠ—X)a]

= exp

âˆ’1
2 [vec(Y ) âˆ’vec(XA)]T (Id âŠ—Ïƒâˆ’2IN) [vec(Y ) âˆ’vec(XA)]

70

3.3. Scoring zero mean VAR(1) graphical models
= exp

âˆ’1
2 [vec(Y âˆ’XA)]T (Id âŠ—Ïƒâˆ’2IN) [vec(Y âˆ’XA)]

= exp

âˆ’1
2Tr
$
(Y âˆ’XA)TÏƒâˆ’2IN(Y âˆ’XA)Id
%
= exp

âˆ’1
2Tr
$
Ïƒâˆ’2g(A)
%
,
(3.7)
where, to ease notation, we let g(A) = (Y âˆ’XA)T(Y âˆ’XA), a d Ã— d matrix. In addition,
notice, for compatible matrices P, Q and R, the use of the identity Tr(P TQPR) =
[vec(P)]T(RT âŠ—Q)vec(P) (Henderson and Searle, 1979). Furthermore, when surveying
(3.6), we realise that
,,Id âŠ—Ïƒ2IN
,,âˆ’1
2 =
,,Ïƒ2(Id âŠ—IN)
,,âˆ’1
2 =
$
(Ïƒ2)dN|Id|N|IN|d %âˆ’1
2 = (Ïƒ2)âˆ’dN
2 .
Here, we use the identity that if P is m Ã— m and Q is r Ã— r, then |P âŠ—Q| = |P|r |Q|m
(Muirhead, 1982). Finally then, the probability of the data is given by the expression
p(D |A, Ïƒ2) = (2Ï€Ïƒ2)âˆ’dN
2 exp

âˆ’1
2Tr
$
Ïƒâˆ’2g(A)
%
.
(3.8)
3.3.1
Priors
To perform in a Bayesian framework, we specify prior distributions over the parameter
set Î¸ = {A, Ïƒ2}. In fact here, a prior is assigned over a = vec(A) where a is a d2-vector.
Note that the use of the vec operator to convert a matrix to a vector is a simple way to
deï¬ne any distribution over a matrix. Thus, we have
p(a) = N (a | 0, Câˆ—)
(3.9)
p(Ïƒ2) = IG(Ïƒ2 | Î±, Î²).
(3.10)
71

3.3. Scoring zero mean VAR(1) graphical models
As was noted in Chapter 2, the above, independent priors seem reasonable as they are the
semi-conjugate speciï¬cations for a normally distributed random sample with both mean
and variance unknown.
At this stage, attention is drawn to Câˆ—. We wish to evaluate L(q) for diï¬€erent choices
of sparsity of A, corresponding to diï¬€erent graphical structures. Furthermore, we must
carry such a sparsity choice through the whole problem, implied by the A-matrices. As
a result, a prior distribution is chosen on vec A that imposes the sparsity structure, and
which appropriately distinguishes diï¬€erent priors. So, we construct a matrix C = (cij)
such that, for each choice of A = (aij) and âˆ€i, j,
cij =
âŽ§
âŽ¨
âŽ©
c
if aij Ì¸= 0
0
if aij = 0
,
(3.11)
for some ï¬xed constant c. Accordingly, deï¬ne Câˆ—= diag {vec(C)}, a natural choice for
the covariance matrix of size d2 Ã— d2. Hence, the sparsity structure is maintained by
constraining C to be of the same form as A, and thus the prior distribution will vary,
dependent upon the sparsity structure for each A-matrix. So, we have eï¬€ectively speciï¬ed
a prior only on the non-zero components of a. Whenever an element of sparse matrix A
is equal to zero (i.e. not present in the problem), the corresponding variance element of
Câˆ—is thus constrained to zero. Moreover, the constant c represents the prior variance of
those elements of a that are present. Each non-zero element is given the equivalent prior
variance since we have no extra prior knowledge about the value of one these elements
over another.
This construction, for constraining certain prior variance elements to zero, is simple and el-
egant to apply. In addition, realise that Câˆ—is usually not of full rank, i.e. its columns/rows
do not form a linearly independent set. This is unless A is a dense matrix, i.e. strictly
no zero elements, in which case the diagonal elements of Câˆ—are all non-zero. When Câˆ—
72

3.3. Scoring zero mean VAR(1) graphical models
is rank deï¬cient, this complicates subsequent analysis in terms of matrix inversion and
computing the logarithms of determinants. We shall make further mention of this, and
of maintaining sparsity structure, later.
3.3.2
Free form method
Recall that, in the variational approach, we intend to approximate each true posterior
by a variational distribution. In this case, two approximate posteriors are considered,
namely q(a | D) and q(Ïƒ2 | D). We continue initially by using the free form method to ï¬nd
the variational posteriors for Ïƒ2 and then a. However, we shall also make use of the ï¬xed
form method, as will be seen in due course.
So, by a free form perspective, recollect from Chapter 2 that one and only one assumption
is made, which aids the subsequent calculation: that these variational distributions are
independent, i.e. q(a, Ïƒ2 | D) = q(a | D) q(Ïƒ2 | D). However, the true posterior p(a, Ïƒ2 | D)
does not factorise in this way, and hence this assumption is an approximation. This is
clear as follows:
p(a, Ïƒ2 | D) âˆp(D | A, Ïƒ2) p(a) p(Ïƒ2)
= (Ïƒ2)âˆ’dN
2 exp

âˆ’1
2Tr
$
Ïƒâˆ’2g(A)
%
Ã— exp

âˆ’1
2aTCâˆ—âˆ’1a

Ã— (Ïƒ2)âˆ’(Î±+1) exp

âˆ’Î²(Ïƒ2)âˆ’1
= (Ïƒ2)âˆ’(Î±+ dN
2 +1) exp

âˆ’(Ïƒ2)âˆ’1
2
Tr [g(A)] âˆ’1
2aTCâˆ—âˆ’1a âˆ’Î²(Ïƒ2)âˆ’1

.
Notice that g(Â·) is deï¬ned only in terms of matrix A, not vector a, hence also the likelihood,
(3.8). However, Tr [g(A)] can be written in terms of a, as will be seen later. Nevertheless,
the term (Ïƒ2)âˆ’1
2
Tr [g(A)] implies that this posterior density will not factorise, and hence a
and Ïƒ2 are not a posteriori independent.
73

3.3. Scoring zero mean VAR(1) graphical models
Consequently, the lower bound in this context is given as
L(q) =

q(a, Ïƒ2 | D) log
	p(D | A, Ïƒ2) p(a, Ïƒ2)
q(a, Ïƒ2 | D)

da dÏƒ2.
(3.12)
Due to the independence of both prior and approximating posterior distributions, this
can now be rewritten as a sum of integrals:
L(q) =

q(a | D)q(Ïƒ2 | D) log p(D | A, Ïƒ2) da dÏƒ2 +

q(a | D) log p(a) da
+

q(Ïƒ2 | D) log p(Ïƒ2) dÏƒ2 âˆ’

q(a | D) log q(a | D) da
âˆ’

q(Ïƒ2 | D) log q(Ïƒ2 | D) dÏƒ2,
(3.13)
integrating out parameters where appropriate. Thus, by writing L(q) as a functional of
q(a | D), we derive
L(q) =

q(a | D)
	
q(Ïƒ2 | D) log p(D | A, Ïƒ2) dÏƒ2 + log p(a) âˆ’log q(a | D)

da + const.
(3.14)
As a functional of q(Ïƒ2 | D), the lower bound is:
L(q) =

q(Ïƒ2 | D)
	
q(a | D) log p(D | A, Ïƒ2) da + log p(Ïƒ2) âˆ’log q(Ïƒ2 | D)

dÏƒ2+const.
(3.15)
We inspect both of these equations in turn. Firstly, derive the variational distribution,
q(Ïƒ2 | D). By substituting in for both log p(D | A, Ïƒ2) and log p(Ïƒ2) in (3.15), we acquire
L(q) =

q(Ïƒ2 | D)
	 
q(a | D)

âˆ’dN
2 log 2Ï€Ïƒ2 âˆ’1
2Tr
$
(Ïƒ2)âˆ’1g(A)
%
da
+ Î± log Î² âˆ’log Î“(Î±) âˆ’(Î± + 1) log Ïƒ2 âˆ’Î²(Ïƒ2)âˆ’1 âˆ’log q(Ïƒ2 | D)

dÏƒ2 + const.
74

3.3. Scoring zero mean VAR(1) graphical models
By dropping terms independent of Ïƒ2, a new constant term is formed, and resultantly, we
obtain
L(q) =

q(Ïƒ2 | D)
	
âˆ’dN
2 log Ïƒ2 âˆ’(Ïƒ2)âˆ’1
2
Eq(a | D) {Tr [g(A)]}
âˆ’(Î± + 1) log Ïƒ2 âˆ’Î²(Ïƒ2)âˆ’1 âˆ’log q(Ïƒ2 | D)

dÏƒ2 + const.â€²
(3.16)
Our attention is now focussed on the term Eq(a | D) {Tr [g(A)]}. As was commented upon
previously, Tr [g(A)] can be denoted in terms of a and, since here we take the expectation
with respect to the variational distribution of vec(A), this would be beneï¬cial. Therefore,
Tr [g(A)] = Tr
$
(Y âˆ’XA)T(Y âˆ’XA)
%
= [vec(Y âˆ’XA)]T [vec(Y âˆ’XA)]
= [vec(Y ) âˆ’vec(XA)]T [vec(Y ) âˆ’vec(XA)]
= [y âˆ’(Id âŠ—X) a]T [y âˆ’(Id âŠ—X) a]
(3.17)
=: h(a),
where y, a are as given previously, and the function h is deï¬ned to ease notation. More-
over, we have used the following identity:
Tr(P TQ) = [vec(P)]Tvec(Q)
(3.18)
for compatible matrices P, Q (Henderson and Searle, 1979). We now take the expectation
of (3.17). Multiplying out the brackets and use of (2.51) consequently provides
Eq(a | D) {Tr [g(A)]} = Eq(a | D)

yTy âˆ’aT(Id âŠ—XT)y âˆ’yT(Id âŠ—X)a + aT(Id âŠ—XTX)a

= yTy âˆ’Eq(a | D)

aT
(Id âŠ—XT)y âˆ’yT(Id âŠ—X)Eq(a | D) {a}
+ Eq(a | D)

aT(Id âŠ—XTX)a

75

3.3. Scoring zero mean VAR(1) graphical models
= yTy âˆ’ÏT(Id âŠ—XT)y âˆ’yT(Id âŠ—X)Ï + ÏT(Id âŠ—XTX)Ï
+ Tr
$
(Id âŠ—XTX)Ï„
%
= h(Ï) + Tr
$
(Id âŠ—XTX)Ï„
%
,
(3.19)
where we deï¬ne Ï = Eq(a | D) {a} and Ï„ = Varq(a | D) {a}. When deriving the variational
posterior for a, algebraic forms for Ï and Ï„ will be found. Notice that
(P âŠ—Q)(R âŠ—S) = PR âŠ—QS
(3.20)
for matrices P compatible with R, Q with S (Harville, 1997).
We can hence substitute (3.19) back into (3.16) to give an expression for L(q), a functional
of q(Ïƒ2 | D), which no longer depends upon a = vec(A). Now, in accordance with the
technique of Chapter 2, a Lagrangian Î½Ïƒ2 can be used to ensure that the distribution
q(Ïƒ2 | D) is normalised. Hence, the new functional ËœL(q) is formed, given by
ËœL(q) = L(q) + Î½Ïƒ2

q(Ïƒ2 | D) dÏƒ2 âˆ’1

.
(3.21)
Thus, we determine the maximum of ËœL(q) by computing the functional derivative with
respect to q(Ïƒ2 | D) and setting to zero. This gives
âˆ‚ËœL(q)
âˆ‚q(Ïƒ2 | D) = âˆ’dN
2 log Ïƒ2 âˆ’(Ïƒ2)âˆ’1
2

h(Ï) + Tr
$
(Id âŠ—XTX)Ï„
%
âˆ’(Î± + 1) log Ïƒ2 âˆ’Î²(Ïƒ2)âˆ’1 âˆ’log q(Ïƒ2 | D) âˆ’1 + Î½Ïƒ2 = 0.
By dropping constant terms and manipulating, we obtain
q(Ïƒ2 | D) âˆ(Ïƒ2)âˆ’(Î±+ dN
2 +1) exp

âˆ’(Ïƒ2)âˆ’1

Î² + 1
2

h(Ï) + Tr
$
(Id âŠ—XTX)Ï„
%
.
76

3.3. Scoring zero mean VAR(1) graphical models
Hence, it is immediately apparent that
q(Ïƒ2 | D) = IG(Ïƒ2 | Î³, Î´),
(3.22)
with variational parameters expressed as
Î³ = Î± + dN
2
(3.23)
Î´ = Î² + 1
2

h(Ï) + Tr
$
(Id âŠ—XTX)Ï„
%
,
(3.24)
where the function h(Â·) is deï¬ned in (3.17) and Ï„ = Varq(a | D) {a}.
Notice that it is
also possible for (3.23) and (3.24) to be derived from the equations (2.53) and (2.54) in
Chapter 2.
Now, return to (3.14) and follow the identical procedure to ï¬nd q(a | D). Substituting in
for log p(D | A, Ïƒ2) and log p(a) implies that
L(q) =

q(a | D)
	 
q(Ïƒ2 | D)

âˆ’dN
2 log 2Ï€Ïƒ2 âˆ’1
2Tr
$
(Ïƒ2)âˆ’1g(A)
%
dÏƒ2
âˆ’d2
2 log 2Ï€ âˆ’1
2 log |Câˆ—| âˆ’1
2aTCâˆ—âˆ’1a âˆ’log q(a | D)

da + const.
This time, those terms that are independent of a will disappear under a functional deriva-
tive with respect to q(a | D). Therefore, we arrive at
L(q) =

q(a | D)
	
âˆ’1
2Tr [g(A)] Eq(Ïƒ2 | D)

(Ïƒ2)âˆ’1
âˆ’1
2aTCâˆ—âˆ’1a âˆ’log q(a | D)

da + const.â€²
(3.25)
Furthermore, we already know that Eq(Ïƒ2 | D) {(Ïƒ2)âˆ’1} =
Î³
Î´ . By forming ËœL(q) with the
Lagrange multiplier Î½a to enforce normality, we maximise this functional, now with respect
77

3.3. Scoring zero mean VAR(1) graphical models
to q(a | D). So, we acquire
âˆ‚ËœL(q)
âˆ‚q(a | D) = âˆ’Î³
2Î´Tr [g(A)] âˆ’1
2aTCâˆ—âˆ’1a âˆ’log q(a | D) âˆ’1 + Î½a = 0.
In a similar fashion to before, this can be rewritten as
q(a | D) âˆexp

âˆ’Î³
2Î´Tr [g(A)] âˆ’1
2aTCâˆ—âˆ’1a

.
(3.26)
At this stage, we can express Tr [g(A)] more usefully in terms of a by using (3.17), as this
is the parameter for which we require the variational distribution. This hence removes
the dependence of (3.26) on A. In other words, we have
q(a | D) âˆexp

âˆ’1
2
	Î³
Î´ yTy âˆ’Î³
Î´ aT(Id âŠ—XT) y âˆ’Î³
Î´ yT(Id âŠ—X)a
+ Î³
Î´ aT(Id âŠ—XTX)a âˆ’aTCâˆ—âˆ’1a

âˆexp

âˆ’1
2
	 
a âˆ’Î³
Î´
Î³
Î´ (Id âŠ—XTX) + Câˆ—âˆ’1âˆ’1
(Id âŠ—XT)y
T
Ã—
Î³
Î´ (Id âŠ—XTX) + Câˆ—âˆ’1
Ã—

a âˆ’Î³
Î´
Î³
Î´ (Id âŠ—XTX) + Câˆ—âˆ’1âˆ’1
(Id âŠ—XT)y
 
,
via completing the square. Consequently, the variational posterior of a is distributed such
that
q(a | D) = N (a | Ï, Ï„),
(3.27)
and algebraic equations for Ï and Ï„ have been derived such that
Ï = Î³
Î´
Î³
Î´ (Id âŠ—XTX) + Câˆ—âˆ’1âˆ’1
(Id âŠ—XT)y
(3.28)
Ï„ =
Î³
Î´ (Id âŠ—XTX) + Câˆ—âˆ’1âˆ’1
.
(3.29)
78

3.3. Scoring zero mean VAR(1) graphical models
In a way akin to the variational distribution on Ïƒ2, we realise that (3.28) and (3.29) are
applications of equations (2.47) and (2.48). At this time, the expression for Î´ is now fully
deï¬ned. Optimal solutions for {Î³, Î´, Ï, Ï„} can be found by iteratively updating these
parameter values until convergence, using equations (3.23), (3.24), (3.28) and (3.29).
However, here we realise a problem. The above variational posterior for a is ï¬ne when
the matrix A is dense. Yet, we also need to examine the circumstance when A is sparse.
Therefore, we must maximise the functional ËœL(q) with respect to some of the elements
of a being zero, dependent on the sparsity structure of each A-matrix. Recall that, when
specifying the prior p(a), a matrix C was created to have the identical zero structure
of a given A. Consequently, some of the prior variance elements of Câˆ—were necessarily
constrained to zero.
Now similarly, for these same entries of A, we are to enforce the corresponding variational
posterior mean and variance elements of Ï and Ï„ respectively to be zero. Thus, for each
graphical structure, Ï will be of the same form in terms of its dimension and sparsity
structure as a, likewise Ï„ with the diagonal matrix Câˆ—. To apply this constraint, a clean
and direct solution is now oï¬€ered.
3.3.3
Fixed form method
In the previous section, we have derived the variational distribution for a, and hence the
variational parameters, Ï and Ï„, in the dense case. However, dealing with a prescribed
sparsity structure using a free form approach is diï¬ƒcult.
Fortunately, to handle this
problem, it turns out to be relatively straightforward to adopt the ï¬xed form variational
procedure.
Thus, now suppose that we assume ï¬xed parametric forms for the variational distributions
of both a and Ïƒ2.
To eï¬€ect this, as suggested in Chapter 2, we can simply use the
79

3.3. Scoring zero mean VAR(1) graphical models
parametric families suggested by the free form method, i.e.
q(a | D) = N (a | Ï, Ï„)
q(Ïƒ2 | D) = IG(Ïƒ2 | Î³, Î´).
Then, as mentioned previously, the lower bound is derived initially using the known
variational distributions. Ordinarily thereafter, we would optimise L(q) with respect to
the variational parameter set. However, update equations for Î³ and Î´, namely (3.23) and
(3.24), have erstwhile been computed via the free form approach, and q(Ïƒ2 | D) does not
depend upon the sparsity of A. Thus, we need only to consider maximising with respect
to Ï and Ï„. At this point, the sparsity constraint can be enforced.
Consider once again (3.13). With assumed knowledge of the variational posteriors, these
integrals can now be computed in turn. Therefore ï¬rstly, by (3.8), we obtain

q(a | D)q(Ïƒ2 | D) log p(D | A, Ïƒ2) da dÏƒ2
=

q(a | D)q(Ïƒ2 | D)
	
âˆ’dN
2 log 2Ï€Ïƒ2 âˆ’1
2Tr
$
(Ïƒ2)âˆ’1g(A)
%
da dÏƒ2
= âˆ’dN
2 log 2Ï€ âˆ’dN
2

q(Ïƒ2 | D) log Ïƒ2 dÏƒ2
âˆ’1
2

q(a | D)Tr [g(A)] da

q(Ïƒ2 | D)(Ïƒ2)âˆ’1 dÏƒ2
= âˆ’dN
2 log 2Ï€ âˆ’dN
2 [log Î´ âˆ’Ïˆ(Î³)] âˆ’Î³
2Î´

h(Ï) + Tr
$
(Id âŠ—XTX)Ï„
%
.
Furthermore, it is realised that the ï¬nal line requires the use of (3.19) and (A.6). Moreover,
by (2.51),

q(a | D) log p(a) da
=

q(a | D)
	
âˆ’d2
2 log 2Ï€ âˆ’1
2 log |Câˆ—| âˆ’1
2aTCâˆ—âˆ’1a

da
80

3.3. Scoring zero mean VAR(1) graphical models
= âˆ’d2
2 log 2Ï€ âˆ’1
2 log |Câˆ—| âˆ’1
2Eq(a | D) {a}T Câˆ—âˆ’1Eq(a | D) {a}
âˆ’1
2Tr

Câˆ—âˆ’1Varq(a | D) {a}

= âˆ’d2
2 log 2Ï€ âˆ’1
2 log |Câˆ—| âˆ’1
2ÏTCâˆ—âˆ’1Ï âˆ’1
2Tr

Câˆ—âˆ’1Ï„

.
Similarly, using previous results,

q(Ïƒ2 | D) log p(Ïƒ2) dÏƒ2
=

q(Ïƒ2 | D)
$
Î± log Î² âˆ’log Î“(Î±) âˆ’(Î± + 1) log Ïƒ2 âˆ’Î²(Ïƒ2)âˆ’1%
dÏƒ2
= Î± log Î² âˆ’log Î“(Î±) âˆ’(Î± + 1)[log Î´ âˆ’Ïˆ(Î³)] âˆ’Î²Î³
Î´ .
In addition, by knowledge of the variational for a, we have that

q(a | D) log q(a | D) da
=

q(a | D)
	
âˆ’d2
2 log 2Ï€ âˆ’1
2 log |Ï„| âˆ’1
2(a âˆ’Ï)TÏ„ âˆ’1(a âˆ’Ï)

da
= âˆ’d2
2 log 2Ï€ âˆ’1
2 log |Ï„| âˆ’1
2 Eq(a | D)

[a âˆ’Ï]T
Ï„ âˆ’1Eq(a | D) {a âˆ’Ï}
âˆ’1
2Tr
$
Ï„ âˆ’1Varq(a | D) {a âˆ’Ï}
%
= âˆ’d2
2 log 2Ï€ âˆ’1
2 log |Ï„| âˆ’d2
2 .
Finally, again by (A.6), it is clear that

q(Ïƒ2 | D) log q(Ïƒ2 | D) dÏƒ2
=

q(Ïƒ2 | D)
$
Î³ log Î´ âˆ’log Î“(Î³) âˆ’(Î³ + 1) log Ïƒ2 âˆ’Î´(Ïƒ2)âˆ’1%
dÏƒ2
= âˆ’log Î“(Î³) âˆ’log Î´ + (Î³ + 1)Ïˆ(Î³) âˆ’Î³.
81

3.3. Scoring zero mean VAR(1) graphical models
Therefore, by simplifying all integral computations from (3.13), the lower bound is found
to be
L(q) = âˆ’dN
2 log 2Ï€ âˆ’dN
2 log Î´ + dN
2 Ïˆ(Î³) âˆ’Î³
2Î´

h(Ï) + Tr
$
(Id âŠ—XTX)Ï„
%
âˆ’1
2 log |Câˆ—| âˆ’1
2ÏTCâˆ—âˆ’1Ï âˆ’1
2Tr

Câˆ—âˆ’1Ï„

+ Î± log Î² âˆ’log Î“(Î±) âˆ’Î± log Î´
+ Î±Ïˆ(Î³) âˆ’Î²Î³
Î´ + 1
2 log |Ï„| + d2
2 + log Î“(Î³) âˆ’Î³Ïˆ(Î³) + Î³.
(3.30)
Resultantly, we have calculated L(q), the quantity required to approximate the log marginal
likelihood for each graphical model Mi, using the ï¬xed form method.
Having derived the lower bound, to optimise, the partial diï¬€erentiation of L(q) with
respect to Ï and Ï„ is now examined. Of course, if L(q) is maximised with respect to Î³
and Î´, then, by setting to zero and manipulating, we acquire the same iterative equations
for these variational parameters, namely (3.23) and (3.24), as in the free form method.
However, recall that the sparsity structure only needs to be enforced for the variational
distribution q(a | D). Thus, ï¬rst by maximising with respect to Ï, it is established that
âˆ‚L(q)
âˆ‚Ï
= âˆ‚
âˆ‚Ï

âˆ’Î³
2Î´h(Ï) âˆ’1
2ÏTCâˆ—âˆ’1Ï

= âˆ‚
âˆ‚Ï

âˆ’Î³
2Î´
$
yTy âˆ’ÏT(Id âŠ—XT)y âˆ’yT(Id âŠ—X)Ï + ÏT(Id âŠ—XTX)Ï
%
âˆ’1
2ÏTCâˆ—âˆ’1Ï

= âˆ‚
âˆ‚Ï

ÏT
	
âˆ’Î³
2Î´ (Id âŠ—XTX) âˆ’1
2Câˆ—âˆ’1
Ï + Î³
Î´ yT(Id âŠ—X)Ï

,
where ÏT(Id âŠ—XT)y =
$
yT(Id âŠ—X)Ï
%T = yT(Id âŠ—X)Ï, as we transpose a scalar quantity.
Maximising this expression per se is fairly straightforward, requiring some standard matrix
calculus. However, this is a logical point at which we can introduce the constraint of some
of the elements of Ï being zero, dependent on the sparsity of each A-matrix, as explained
82

3.3. Scoring zero mean VAR(1) graphical models
earlier. Thus, we observe the beneï¬t of using the ï¬xed form method in this context.
Accordingly, the problem reduces to a quadratic programming (QP) problem. Classically,
this features the minimisation of a quadratic function, subject to a set of linear constraints.
For more details on this topic, see Fletcher (2000). In this case, the constraint is able to
be handled more easily and, in fact, the problem is speciï¬ed as:
max
Ï
ÏTHÏ + cTÏ
(3.31)
subject to:
some elements of Ï constrained to be zero,
where
H = âˆ’Î³
2Î´ (Id âŠ—XTX) âˆ’1
2Câˆ—âˆ’1
cT = Î³
Î´ yT(Id âŠ—X).
Suppose that a given A-matrix contains Î· free, non-zero elements with a prescribed spar-
sity structure. This structure is moreover inherent within Ï and thus, to solve the QP
problem, we subsequently maximise with respect to the non-zero elements of Ï. To eï¬€ect
this, we initially must permute rows and columns of (3.31) so that the ï¬rst Î· elements of
Ï are now these non-zeroes. The corresponding Î·-vector is deï¬ned to be Ï1. Henceforth,
we practise in terms of block matrices.
Thus, after permuting rows and columns, deï¬ne Ïperm =
âŽ¡
âŽ£Ï1
0
âŽ¤
âŽ¦. Moreover, let Hperm =
âŽ¡
âŽ£H11
H12
H21
H22
âŽ¤
âŽ¦, whereby H11 is of dimension Î· Ã— Î·, H12 is Î· Ã— (d2 âˆ’Î·), H21 (d2 âˆ’Î·) Ã— Î·
and H22 is a (d2 âˆ’Î·) Ã— (d2 âˆ’Î·) matrix. In other words, H11 is the submatrix obtained
by deleting the i-th row and column of H, corresponding to a zero element in the i-th
83

3.3. Scoring zero mean VAR(1) graphical models
position of Ï for all i. Likewise, c T
perm =
âŽ¡
âŽ£c1
c2
âŽ¤
âŽ¦
T
, where c1, a vector of dimension Î·, is the
analogous subvector of c, and c2 is of size d2 âˆ’Î·.
Hence, by substituting into (3.31), the problem reduces to
max
Ï1
âŽ¡
âŽ£Ï1
0
âŽ¤
âŽ¦
T âŽ¡
âŽ£H11
H12
H21
H22
âŽ¤
âŽ¦
âŽ¡
âŽ£Ï1
0
âŽ¤
âŽ¦+
âŽ¡
âŽ£c1
c2
âŽ¤
âŽ¦
T âŽ¡
âŽ£Ï1
0
âŽ¤
âŽ¦
= max
Ï1
ÏT
1 H11Ï1 + cT
1 Ï1.
Optimising this expression with respect to the non-zero vector, Ï1, is now elementary
since
âˆ‚
âˆ‚Ï1

ÏT
1 H11Ï1 + cT
1 Ï1

= (H11 + H
T
11 )Ï1 + c1
= 2H11Ï1 + c1
=

âˆ’Î³
Î´ (Id âŠ—XTX) âˆ’Câˆ—âˆ’1
11 Ï1 +
Î³
Î´ (Id âŠ—XT) y

1 ,
using the deï¬nitions of H and cT, in addition to the continuing subscript notation. We
apply standard results for the matrix calculus required here (Petersen and Pedersen,
2007). Observe that as H is symmetric, then by only removing rows and corresponding
columns, H11 is also a symmetric matrix. Ultimately, setting to zero and solving for Ï1
provides
Ï1 = Î³
Î´
Î³
Î´ (Id âŠ—XTX) + Câˆ—âˆ’1
11
âˆ’1 $
(Id âŠ—XT) y
%
1 .
(3.32)
Finally, it is recognised that once Ï1 has been found, then Ï is reformed by re-introducing
the sparsity structure, in accordance with the speciï¬c A-matrix. We realise that this
reconstruction is needed as, for instance, (3.24) is strictly reliant upon the full vector Ï.
84

3.3. Scoring zero mean VAR(1) graphical models
In summary, when A is dense, we need only utilise (3.28) to ï¬nd Ï. However, when A
is sparse, Ï1 must be computed initially using (3.32), before re-constructing Ï. This is
easily performed by choosing the correct block of H (i.e. H11) and c (i.e. c1) every time.
Thus, notice the obvious analogy between the dense and the sparse case from (3.28) and
(3.32).
So, we have constrained, according to the speciï¬c sparsity structure of each A-matrix,
some elements of the variational posterior mean vector, Ï, to be zero. The same operation
can now be performed to constrain to zero the corresponding elements of Ï„. Customarily,
when diï¬€erentiating (3.30) with respect to Ï„, we would need to ï¬nd
âˆ‚L(q)
âˆ‚Ï„
= âˆ‚
âˆ‚Ï„

âˆ’Î³
2Î´Tr
$
(Id âŠ—XTX)Ï„
%
âˆ’1
2Tr

Câˆ—âˆ’1Ï„

+ 1
2 log |Ï„|

.
Clearly, in this case, we cannot enforce the sparsity constraint by using simple quadratic
programming as was seen with Ï. Consequently, an alternative approach is to attempt
the problem again in component form, and ï¬nd an expression for the elements of Ï„ that
correspond to those elements of Câˆ—, which have non-zero, prior variance. Obviously, by
the sparsity structure, if an element of Câˆ—is constrained to have zero prior variance, then
the corresponding element of Ï„ will have zero variational posterior variance.
The prior over Ïƒ2 is maintained to be of the same form as before since Ïƒ2 is unaï¬€ected
by sparsity. Yet, as Câˆ—is a diagonal matrix, we can use a well-known property of the
multivariate Gaussian distribution to denote the prior over a as a product of independent,
univariate Gaussians, i.e.
p(a) =

(p,q)âˆˆI
N (apq | 0, Câˆ—
(p,q)),
(3.33)
where I is the set of those elements of a (corresponding to A) for which apq Ì¸= 0. We then
can use a ï¬xed form method to proceed. Previously, we assumed that the joint variational
85

3.3. Scoring zero mean VAR(1) graphical models
posterior, q(a, Ïƒ2 | D) could be factorised, an approximation to the true posterior. Now,
a further approximation is made at the component level to p(a, Ïƒ2 | D), namely that,
moreover, the variational distribution for a can be factorised into a product of univariate
Gaussian distributions, i.e. we let
q(a | D) =

(p,q)âˆˆI
N (apq | Ï(p,q), Ï„(p,q)),
(3.34)
where Ï(p,q) is the variational posterior mean that corresponds to element apq of a, similarly
Ï„(p,q). We now continue in parallel with the ï¬xed form method in the multivariate case
by evaluating (3.13) at the component level.
Initially, the likelihood (3.8) is rewritten in component form. Realising, for an m Ã— r
matrix P, that by Harville (1997),
Tr
$
P TP
%
=
m

j=1
r

k=1
p2
jk,
(3.35)
consequently we acquire, by deï¬nition of g(A) and matrix multiplication,
p(D | {aij}, Ïƒ2) = (2Ï€Ïƒ2)âˆ’dN
2 exp

âˆ’(Ïƒ2)âˆ’1
2
Tr
$
(Y âˆ’XA)T(Y âˆ’XA)
%
= (2Ï€Ïƒ2)âˆ’dN
2 exp

âˆ’(Ïƒ2)âˆ’1
2
N

j=1
d

k=1

[Y âˆ’XA]jk
2

= (2Ï€Ïƒ2)âˆ’dN
2 exp
âŽ§
âŽ¨
âŽ©âˆ’(Ïƒ2)âˆ’1
2
N

j=1
d

k=1

yjk âˆ’
d

i=1
xjiaik
2âŽ«
âŽ¬
âŽ­.
Now, examine the ï¬rst integral of (3.13):

q(a | D)q(Ïƒ2 | D) log p(D | {aij}, Ïƒ2) da dÏƒ2
86

3.3. Scoring zero mean VAR(1) graphical models
=

q(a | D)q(Ïƒ2 | D)
âŽ¡
âŽ£âˆ’dN
2 log 2Ï€Ïƒ2 âˆ’(Ïƒ2)âˆ’1
2
N

j=1
d

k=1

yjk âˆ’
d

i=1
xjiaik
2âŽ¤
âŽ¦da dÏƒ2
= âˆ’dN
2 log 2Ï€ âˆ’dN
2 [log Î´ âˆ’Ïˆ(Î³)] âˆ’Î³
2Î´
N

j=1
d

k=1

q(a | D)

yjk âˆ’
d

i=1
xjiaik
2
da,
(3.36)
using (A.5) and (A.6). The ï¬nal integral in (3.36) is equivalent to
Eq(a | D)
âŽ§
âŽ¨
âŽ©

yjk âˆ’
d

i=1
xjiaik
2âŽ«
âŽ¬
âŽ­
= y2
jk âˆ’2yjkEq(a | D)

d

i=1
xjiaik

+ Eq(a | D)
âŽ§
âŽ¨
âŽ©

d

i=1
xjiaik
2âŽ«
âŽ¬
âŽ­
= y2
jk âˆ’2yjk
d

i=1
xjiEq(a | D){aik} +
d

i=1
Varq(a | D){xjiaik} +

d

i=1
xjiEq(a | D){aik}
2
= y2
jk âˆ’2yjk
d

i=1
xjiÏ(i,k) +
d

i=1
x2
jiÏ„(i,k) +

d

i=1
xjiÏ(i,k)
2
,
noting that, as Ï„ is diagonal, the covariance between elements of a with respect to q(a | D)
is always zero. Furthermore, we obtain, by (3.33), that

q(a | D) log p(a) da
=

(p,q)âˆˆI

q(a | D)

âˆ’1
2 log 2Ï€ âˆ’1
2 log Câˆ—
(p,q) âˆ’1
2
a2
pq
Câˆ—
(p,q)

da
= âˆ’

(p,q)âˆˆI

1
2 log 2Ï€ + 1
2 log Câˆ—
(p,q) +
1
2Câˆ—
(p,q)

Varq(a | D){apq} +
$
Eq(a | D){apq}
%2
= âˆ’

(p,q)âˆˆI

1
2 log 2Ï€ + 1
2 log Câˆ—
(p,q) + 1
2
Ï„(p,q)
Câˆ—
(p,q)
+ 1
2
Ï2
(p,q)
Câˆ—
(p,q)

.
87

3.3. Scoring zero mean VAR(1) graphical models
Moreover, by (3.34),

q(a | D) log q(a | D) da
=

(p,q)âˆˆI

q(a | D)
	
âˆ’1
2 log 2Ï€ âˆ’1
2 log Ï„(p,q) âˆ’1
2
(apq âˆ’Ï(p,q))2
Ï„(p,q)

da
= âˆ’

(p,q)âˆˆI
	1
2 log 2Ï€ + 1
2 log Ï„(p,q)
+
1
2Ï„(p,q)
$
Eq(a | D){apq âˆ’Ï(p,q)}
%2 + Varq(a | D){apq âˆ’Ï(p,q)}
 
= âˆ’

(p,q)âˆˆI
	1
2 log 2Ï€ + 1
2 log Ï„(p,q) + 1
2

.
The two other integrals of (3.13) are independent of a, and so are calculated as previous.
Therefore, in component form, the lower bound is equivalent to
L(q) = âˆ’dN
2 log 2Ï€ âˆ’dN
2 [log Î´ âˆ’Ïˆ(Î³)] âˆ’Î³
2Î´
N

j=1
d

k=1
y2
jk + Î³
Î´
d

i=1
N

j=1
d

k=1
yjkxjiÏ(i,k)
âˆ’Î³
2Î´
d

i=1
N

j=1
d

k=1
x2
jiÏ„(i,k) âˆ’Î³
2Î´
N

j=1
d

k=1

d

i=1
xjiÏ(i,k)
2
âˆ’1
2

(p,q)âˆˆI
log Câˆ—
(p,q)
âˆ’1
2

(p,q)âˆˆI
Ï„(p,q)
Câˆ—
(p,q)
âˆ’1
2

(p,q)âˆˆI
Ï2
(p,q)
Câˆ—
(p,q)
+ Î± log Î² âˆ’log Î“(Î±) âˆ’Î± log Î´ + Î±Ïˆ(Î³)
âˆ’Î²Î³
Î´ + 1
2

(p,q)âˆˆI
log Ï„(p,q) +

(p,q)âˆˆI
1
2 + log Î“(Î³) âˆ’Î³Ïˆ(Î³) + Î³.
(3.37)
Finally, we optimise L(q) by diï¬€erentiating with respect to the component Ï„(p,q) to obtain
âˆ‚L(q)
âˆ‚Ï„(p,q)
=
âˆ‚
âˆ‚Ï„(p,q)
âŽ§
âŽ¨
âŽ©âˆ’Î³
2Î´
d

i=1
N

j=1
d

k=1
x2
jiÏ„(i,k) âˆ’1
2

(p,q)âˆˆI
Ï„(p,q)
Câˆ—
(p,q)
+ 1
2

(p,q)âˆˆI
log Ï„(p,q)
âŽ«
âŽ¬
âŽ­
= âˆ’Î³
2Î´
N

j=1
x2
jp âˆ’
1
2Câˆ—
(p,q)
+
1
2Ï„(p,q)
.
88

3.3. Scoring zero mean VAR(1) graphical models
By equating to zero and solving for Ï„(p,q), we have that each non-zero diagonal element of
Ï„ is given by
Ï„(p,q) =

1
Câˆ—
(p,q)
+ Î³
Î´
N

j=1
x2
jp
âˆ’1
.
(3.38)
Consequently, we can express the diagonal elements of Ï„ such that
Ï„(p,q) =
âŽ§
âŽª
âŽª
âŽª
âŽ¨
âŽª
âŽª
âŽª
âŽ©

1
Câˆ—
(p,q)
+ Î³
Î´
N

j=1
x2
jp
âˆ’1
if apq Ì¸= 0
0
if apq = 0
.
Clearly, by diï¬€erentiating (3.37) with respect to Î³ and Î´, we reach the same update
equations as before, but in component form. A genuine question to ask at this stage
would be why not use this method to ï¬nd an expression for any Ï(p,q), corresponding to
a non-zero element apq, rather than the quadratic programming method, as examined
earlier. In this case, maximising with respect to Ï(p,q), we acquire
âˆ‚L(q)
âˆ‚Ï(p,q)
=
âˆ‚
âˆ‚Ï(p,q)
Î³
Î´
d

i=1
N

j=1
d

k=1
yjkxjiÏ(i,k) âˆ’Î³
2Î´
N

j=1
d

k=1

d

i=1
xjiÏ(i,k)
2
âˆ’1
2

(p,q)âˆˆI
Ï2
(p,q)
Câˆ—
(p,q)

= Î³
Î´
N

j=1
yjqxjp âˆ’Î³
2Î´
N

j=1
d

t=1
xjpxjtÏ(t,q) âˆ’Ï(p,q)
Câˆ—
(p,q)
,
where we note that  N
j=1
 d
k=1
 d
i=1 xjiÏ(i,k)
2
=  N
j=1
 d
k=1
 d
t=1
 d
i=1 xjixjtÏ(i,k)Ï(t,k).
However, by equating to zero and solving for Ï(p,q), we realise that the expression is not
independent of  d
t=1 Ï(t,q). Hence, the quadratic programming method to constrain Ï
according to sparsity is preferred.
To summarise, we have derived the distributional form for both variational posteriors,
namely q(a | D) and q(Ïƒ2 | D), together with update equations for the set of variational
89

3.4. Other issues
parameters, initially Î³ and Î´, then Ï (also Ï1) and Ï„ (using Ï„(p,q)). These update equa-
tions are run until convergence, hence ï¬nding the parameter values for our variational
distributions. At each iteration for every graph, we can evaluate the lower bound (3.30)
until convergence, thereupon giving a good approximation of the log marginal likelihood.
This provides the evidence needed to rank the graphical structures available from the
candidate set of models.
3.4
Other issues
3.4.1
Problems with computation
We comment brieï¬‚y upon the computational issues of the matrices Câˆ—and Ï„. Notice that
in (3.30), the expression for L(q), we must compute log |Câˆ—|, log |Ï„| and Câˆ—âˆ’1. Yet, these
afore-mentioned matrices by construction have all oï¬€-diagonal entries equal to zero and,
unless A is dense, contain some zero elements on the leading diagonal. Thus, when A is
sparse, the determinant of Câˆ—and Ï„ will typically be zero and, hence, the logarithm of
the determinant is undeï¬ned. Moreover by deï¬nition, both matrices will be consequently
singular, implying a problem in calculating the inverse of Câˆ—.
However, these dilemmas can be overcome.
To understand this, suppose that X is a
random vector that follows a Nr(m, V ) distribution, where the subscript r is used to
emphasise the dimension of X. If V is singular (with rank k < r), then the standard
multivariate normal density function does not exist on Rr. However, it does exist on a
k-dimensional subspace of Rr where the distribution has support. In addition, the density
of X on this subspace is deï¬ned by Rao and Mitra (1972) as
p(x | m, V ) =
(2Ï€)âˆ’k/2
(Î»1 Â· Â· Â·Î»k)1/2 exp

âˆ’1
2(x âˆ’m)TV âˆ’(x âˆ’m)

,
(3.39)
90

3.4. Other issues
where Î»1, . . . , Î»k are the non-zero eigenvalues of V , and V âˆ’is any generalised inverse
of V (see Appendix C). Thus, we refer to (3.39) as the density of a singular Nr(m, V )
distribution of rank k.
Of course, there is a clear correspondence between (3.39) and its non-singular counterpart,
(A.7). That is, the singular density may be computed on the subspace by alternative
calculation of the determinant and inverse of V in the density of full rank. We use this
relationship to justify the following analysis. If a given A-matrix has Î· non-zero elements
as before, then by construction, Câˆ—, and consequently Ï„, will have rank Î· < d2 (recall
that the rank of any diagonal matrix is equivalent to the number of non-zero diagonal
elements that it possesses). So, analogous to (3.39) where V was again a singular, positive
semideï¬nite matrix, the determinant of Câˆ—(and hence Ï„) can also be calculated as the
product of its non-zero eigenvalues (Neudecker, 1995), namely its Î·, non-zero diagonal
entries. If câˆ—
11, . . ., câˆ—
Î·Î· are these elements, then resultantly, by taking logarithms, we easily
have
log |Câˆ—| =
Î·

i=1
log câˆ—
ii.
(3.40)
The case is similar for Ï„.
Additionally, if it were non-singular, the inverse of Câˆ—would trivially be the matrix
with the diagonal elements of Câˆ—replaced by their reciprocals. Yet, when A is sparse,
a generalised inverse can be utilised for this procedure, as seen in (3.39). Moreover, a
generalised inverse of a diagonal matrix is formed by reciprocating only the non-zero,
diagonal entries (Harville, 1997). In fact, this is the Moore-Penrose inverse of the matrix,
denoted in this case by Câˆ—+ â€” additional details are again provided in Appendix C.
Consequently, in (3.30), the lower bound expression is altered so that Câˆ—âˆ’1 is replaced by
Câˆ—+.
Finally, the lower bound contains terms that remain constant across diï¬€erent models.
91

3.4. Other issues
Thus, we can rewrite (3.30) as
L(q) âˆâˆ’dN
2 log Î´ âˆ’Î³
2Î´

h(Ï) + Tr
$
(Id âŠ—XTX)Ï„
%
âˆ’1
2 log |Câˆ—|
âˆ’1
2ÏTCâˆ—+Ï âˆ’1
2Tr

Câˆ—+Ï„

âˆ’Î± log Î´ âˆ’Î²Î³
Î´ + 1
2 log |Ï„|,
(3.41)
and hence use the above expression to provide evidence for the competing, candidate
models.
3.4.2
Speciï¬cation of priors
We discuss speciï¬cation of the parameter values for both prior distributions included in
the model. Such issues were succinctly touched upon in Section 2.5.5. In the case of p(Ïƒ2),
it is customary to want the prior to have little inï¬‚uence over the resulting approximate
posterior distribution. Thus, we aim to use a vague prior. A popular choice is to apply the
relatively ï¬‚at, proper prior IG(Ïµ, Ïµ) for low values of Ïµ and, in particular, when Ïµ = 0.001
(Spiegelhalter et al., 1995). By Appendix A, any IG(a, b) distribution is deï¬ned only
when a, b > 0, and so this speciï¬cation is thus considered to be a â€˜justâ€™ proper prior. As
mentioned previously, the IG(0.001, 0.001) distribution is described as vague since it has
very large (in this case, inï¬nite) variance.
However, it has been seen, in the context of hierarchical models, that the resultant pos-
terior distribution can be highly sensitive to the choice of Ïµ, when the variance parameter
in question is estimated to be small a posteriori (Gelman, 2006). In this case, the author
showed that, in particular for one dataset, the prior was perversely not at all vague. We
realise that this prior is highly peaked for small Ïƒ2, and so may show a preference for
lower values of Ïƒ2 in the Bayesian update. Perhaps a more attractive choice would be to
use a IG(1, Ïµ) density for Ïµ â†’0. When Ïµ = 0.001 say, this prior has a maximum around
Ïƒ2 = 0 as before. Yet, this peak is now extremely sharp. As such, the density reaches
92

3.4. Other issues
negligible values quicker than before, implying that the prior is then ï¬‚atter.
Customarily, for the choice of a Gaussian prior, we again represent prior ignorance by
choosing the distribution to have large variance. However, when choosing between models,
this policy may be susceptible to Lindleyâ€™s paradox. Introduced initially in Chapter 1, we
now explain the paradox, following that of Shafer (1982). Suppose a random quantity X
follows a Gaussian distribution with unknown mean Î¼ and known variance Ï‰2. On the
basis of observing a dataset D of size n with sample mean Â¯x, we want to evaluate the
evidence for two models, which may have given rise to the data. These are:
Mk : X âˆ¼N (Î¼0, Ï‰2)
Ml : X âˆ¼N (Î¼, Ï‰2).
According to Ml, we place a diï¬€use prior over Î¼, centred at Î¼0, e.g. Î¼ âˆ¼N (Î¼0, d2) for
large d. We then can compute the Bayesâ€™ factor for model Mk against Ml, as illustrated
in Chapter 1:
Bkl = p(D | Mk)
p(D | Ml) .
Yet, as Shafer illustrates, by allowing the prior variance d2 to become suï¬ƒciently large,
the Bayesâ€™ factor, in turn, will become signiï¬cantly greater than 1, and hence, Mk will
be favoured always ahead of Ml.
Here, we realise that model Ml can be written as
X âˆ¼N (Î¼0, d2 + Ï‰2). Thus, with increasing d, Ml becomes more complex and Bkl works
in favour of the simpler Mk. The paradox arises since a standard, hypothesis test, in par-
ticular Z = Â¯x âˆ’Î¼0
Ï‰/âˆšn , may show strong evidence against model Mk, whilst simultaneously,
the Bayesian assessment can display exactly the reverse conclusion. In other words, even
if the sample mean of the data is signiï¬cantly diï¬€erent from Î¼0, then, by making the
prior as ï¬‚at as necessary, this will override the evidence, provided by the data, and hence
suggest that Î¼ = Î¼0. This conï¬‚icts with the interpretation of the Bayesâ€™ factor as being
93

3.4. Other issues
the odds of the two models, implied solely by the data. For further discussion, see, for
instance, Robert (1993), Berger and Sellke (1987) and Aitkin (1991).
The converse of the paradox is the scenario when the prior variance is allowed to ap-
proach zero. Then, the prior, now highly informative for Î¼, will be tightly-peaked around
Î¼0, implying that those values of Î¼, in the vicinity of Î¼0, will be given very high prior
probability. If the sample mean Â¯x is reasonably close to the value of Î¼0, then these same
values will also possess high likelihood. Deï¬ne L(Î¼ | D, Ml) = p(D | Î¼, Ml) as the like-
lihood function, speciï¬c to Ml. Hence, the marginal likelihood for this model, namely
p(D | Ml) =

L(Î¼ | D, Ml) p(Î¼ | Ml) dÎ¼, denoting the average of the likelihood with re-
spect to the prior, will increase, hence reducing the Bayesâ€™ factor to below 1, and thus
favouring Ml.
In the above example of Lindleyâ€™s paradox, we can consider Mk to be the simpler model
and Ml the more complex model. In eï¬€ect, we choose a model either with mean equal
to Î¼0 or with unknown mean Î¼. This situation corresponds to the current, zero mean
VAR(1) case if we take Î¼0 = 0. Then, we choose each element of the d Ã— d matrix A to
be either a zero or a free entry, whereby the latter follows a prior distribution of the form
given by (3.33). That is, in each case, we again examine a simpler or more complex model
respectively. When specifying the prior, it seems reasonable to take the mean as zero,
hence the prior distribution is centred around the simpler model for each component.
By carefully specifying a value not too small for the prior variance on each non-zero
element of a, we will be able to penalise more complex A-matrices in the candidate set,
i.e.
those with more unspeciï¬ed, non-zero entries.
Although such models with more
parameters will be better at ï¬tting the data, by penalising, it will enable us to choose the
model with optimum structure. On the other hand, the use of a diï¬€use prior on a may
lead to favouring an A-matrix of simpler structure. Hence, there is a justiï¬cation to use
a deliberately chosen informative prior so that the problem is not susceptible to Lindleyâ€™s
paradox. Moreover, the speciï¬cation of c from (3.11) must be a compromise between
94

3.5. Toy example
always favouring a simpler A-matrix (large c) and a more complex matrix (small c). A
full prior sensitivity analysis, examining these issues, is provided in the next chapter.
3.5
Toy example
To illustrate the above procedure, we consider a simple toy example, based upon an
arbitrary, zero mean VAR(1) model. In previous work, we have speciï¬ed distributions
over a = vec A and found that Eq(a | D)(a) = Ï. In the following example, we unstack
the d2-vector Ï to form a d Ã— d matrix called Ë†A. This procedure is illustrated further in
Section 5.2.2.
An easy case is supposed whereby d = 2. A dataset of size N = 250 was simulated from
the zero mean VAR(1) model (3.2) with speciï¬cations such that A =
âŽ›
âŽ0
0.7
0.3
0
âŽž
âŽ and
Ïƒ2 = 0.1. We choose A with care to ensure that all its eigenvalues have modulus less
than 1. In this case, the VAR process is said to be stable and, hence, the dataset does
not explode for increasing N (LÂ¨utkepohl, 2005). As mentioned previously, we again let
x1 = (0, 0) and x250 = y249. This choice of A thus deï¬nes the A-graph below.
y1
y2
Figure 3.3: A-graph for the true zero mean VAR(1) model
When d = 2, there are 24 = 16 directed A-graphs on two vertices. However, the null
model, represented by a completely sparse graph, is ignored. In such a case, Câˆ—and
Ï„ would both be zero matrices, implying that taking the logarithm of their determi-
nants, as required in the computation of LMi(qi), would be undeï¬ned (c.f. (3.40)). As a
consequence, we construct a candidate set of 15 graphs, referred to in terms of their cor-
95

3.5. Toy example
responding A-matrices. Thus, a zero element in a given matrix implies no edge between
the corresponding vertices on the graph, as explained earlier. So, given the data, we aim
to select the optimum model from the set. The prior distributions over a = vec(A) and
Ïƒ2 were speciï¬ed to be
p(a) = N (a | 0, Câˆ—) where cij âˆˆ{0, 0.5}
p(Ïƒ2) = IG(Ïƒ2 | 1, 0.001).
Clearly, the prior on Ïƒ2 remains the same throughout whereas, for that on a, the covariance
matrix Câˆ—changes according to the sparsity structure of each A-matrix.
Recall that we wish to ï¬nd parameter values for variational distributions given by
q(a | D) = N (a | Ï, Ï„)
q(Ïƒ2 | D) = IG(Ïƒ2 | Î³, Î´).
Consequently, for each candidate model, the lower bound, LMi(qi), was evaluated at each
iteration, and update equations for the variational parameters were run until convergence.
For this medium-sized dataset, this took merely 4 iterations in each case, identical to what
was seen in the example of Section 2.5.5. As the update equations for Ï1 and Ï„(p,q) (hence
deï¬ning Ï and Ï„) depend upon Î³ and Î´, the algorithm was initialised arbitrarily with
Î³ = Î´ = 1.
The results of the example are shown in Table 3.1.
Initially, we report back the log
marginal likelihood estimation by LMi(qi). As we would hoped, the model which relates
to the true choice of A, in terms of sparsity structure, was chosen. The more complex
models with A-matrices that contained at least the two, true free elements were also well-
favoured. Recall that the prior parameters for a were chosen to avoid Lindleyâ€™s paradox.
The speciï¬cation made appears to be a valid one since neither the simpler, nor more
96

3.5. Toy example
complex models are favoured, ahead of the truth.
Now, we examine the estimates of the true A and Ïƒ2, namely Ë†A and Eq(Ïƒ2 | D){Ïƒ2} respec-
tively. Notice that all the non-zero elements of each Ë†A are very similar to each other, but
not mathematically exact. This stems from the variational algorithm and, in particular,
the deï¬nition of Ï1. For each candidate model, H11 and c1 will vary in dimension and
value of elements, dependent on the sparsity structure, hence creating such a diï¬€erence.
Moreover, Câˆ—will also change from model to model. With a reasonably-sized dataset
chosen, each Ë†A-matrix is similar to the original choice of A. This is since, with N = 250,
the likelihood term dominates the prior distribution. That is, with a prior chosen so that
no favouritism exists for either simpler or more complex models, most of the information
about a was passed through to the variational distribution q(a | D), in this approximate
Bayesian update, via the data.
The corresponding estimates for Ïƒ2, found using (A.4), are all reasonably accurate to the
true value. However, there is less concordance between these values than the Ë†A-matrices.
It is apparent that any candidate that possessed a sparsity structure similar to the truth
produced better estimates of Ïƒ2 than the remaining models. We are already aware that
Î³ is constant across models (c.f. (3.23)). Thus, if the wrong model is chosen, the value
of Î´ has become more inaccurate when compared with that for the true model, hence
Eq(Ïƒ2 | D) {Ïƒ2} also. Suppose we attempt to ï¬t a model with the wrong sparsity pattern to
the given set of data. Then, the noise variance, which determines the extent to which the
data ï¬‚uctuates about the mean of the process (in this case, zero), must be readjusted to
cope with this model misspeciï¬cation. That is, the model error, created by attempting
to model the data incorrectly, is â€˜pushedâ€™ exclusively into the estimate of Ïƒ2.
97

3.5. Toy example
Speciï¬cation
Posterior means
LMi(qi)
A-matrix
Ë†A-matrix
Eq(Ïƒ2 | D){Ïƒ2}
âˆ—
0
0
0

âˆ’0.066
0
0
0

0.135
âˆ’1136.791
0
0
0
âˆ—

0
0
0
âˆ’0.041

0.135
âˆ’1137.165
0
âˆ—
0
0

0
0.674
0
0

0.109
âˆ’1084.561

0
0
âˆ—
0


0
0
0.341
0

0.126
âˆ’1119.862
âˆ—
âˆ—
0
0

âˆ’0.066
0.674
0
0

0.109
âˆ’1086.926
âˆ—
0
âˆ—
0

âˆ’0.074
0
0.342
0

0.126
âˆ’1122.113
0
âˆ—
0
âˆ—

0
0.676
0
âˆ’0.052

0.110
âˆ’1087.169

0
0
âˆ—
âˆ—


0
0
0.341
âˆ’0.041

0.126
âˆ’1122.622

âˆ—
0
0
âˆ—


âˆ’0.066
0
0
âˆ’0.041

0.135
âˆ’1139.534
0
âˆ—
âˆ—
0


0
0.675
0.341
0

0.100
âˆ’1065.786
âˆ—
âˆ—
0
âˆ—

âˆ’0.066
0.676
0
âˆ’0.052

0.109
âˆ’1089.534

âˆ—
0
âˆ—
âˆ—


âˆ’0.074
0
0.342
âˆ’0.041

0.126
âˆ’1124.873

âˆ—
âˆ—
âˆ—
0


âˆ’0.074
0.675
0.343
0

0.100
âˆ’1067.992
0
âˆ—
âˆ—
âˆ—


0
0.676
0.341
âˆ’0.052

0.100
âˆ’1068.393
âˆ—
âˆ—
âˆ—
âˆ—

âˆ’0.074
0.676
0.343
âˆ’0.052

0.100
âˆ’1070.599
Table 3.1: Lower bounds and posterior means for each zero mean VAR(1) model
98

Chapter 4
Searching the graphical space
4.1
Motivation
In the previous chapter, we constructed a candidate set of individual VAR(1) models, each
dependent on the sparsity structure of an A-matrix and represented by an A-graph. Given
a set of observed data, these sparse models were able to be scored by evaluating, in each
case, LMi(qi), a lower bound approximation to the logarithm of the marginal likelihood,
derived using the variational Bayesian method. Thus, we were able to select the most
plausible models from the set. At present, this approach is applicable, but, conversely,
rather limited.
This is because we can only compute the lower bound, or variational score, for a set
of predetermined graphs individually.
As a consequence, it becomes a computational
impossibility to consider all the candidate models within the graphical space in this way,
when the dimension of the VAR(1) models, d, increases. In fact, explicitly, the number of
possible candidate models, each represented by a graph on d nodes, is 2d2 âˆ’1, excluding
the null model. Obviously, for large d, the task of computing a lower bound for each
candidate individually is somewhat arduous! It would hence be more beneï¬cial if the
99

4.2. Hill-climbing
whole process was fully automated, and thus we possessed an eï¬ƒcient way to traverse
through the graphical space quickly to ï¬nd high scoring graphs.
In this chapter, we consider such an automated system. In particular, two such methods
are developed. Initially, a customary hill-climbing algorithm is contemplated. In this
circumstance, we are able to manoeuvre through the graphical space by comparing the
values of two lower bounds, and accepting the A-graph that eï¬€ects the higher L(q), with
probability 1. The alternative is to make a random walk across the space so that moves to
neighbouring graphs are reliant upon Markov chain Monte Carlo (MCMC) techniques and,
in particular, the Metropolis-Hastings algorithm (previously documented in Chapter 2).
Thus, we accept a move to a new graph on the basis of an acceptance probability, Î±.
However, due to exclusion of the null graph from our candidate set, care must be shown
when specifying Î±. We shall consider each approach in turn.
4.2
Hill-climbing
As the above introduction suggests, the hill-climbing algorithm (Russell and Norvig, 2003)
is the simpler of the two approaches. In general, this a straightforward search method
used in a large state space that, at each iteration, will move to a neighbour of a given
current state, whenever the new state is of increased value. In this case, the algorithm is
said to â€˜climbâ€™ in an uphill direction until it reaches a local maximum, i.e. a point where
no neighbour has higher value. The algorithm is known as greedy as it always chooses the
best available state at each iteration without thinking any further ahead.
Consider the algorithm from the perspective of scoring sparse VAR(1) models. Thus, at
some iteration, say that we have accepted a model from the graphical space, represented
by an A-graph, together with an associated lower bound value. Then, at the next iteration,
we propose a new model, by randomly choosing a graph within the neighbourhood of the
100

4.2. Hill-climbing
current, accepted graph, i.e. by the addition or deletion of a single edge. We then evaluate
the lower bound for the proposal, and compare the value to that of the accepted graph. If
the variational score between the two models improves (i.e. increases), then the proposed
graph, with its corresponding lower bound, is accepted categorically, otherwise we reject
and return to the graph at the previous iteration. We continue until all neighbouring
graphs have lower scores, at which point the lower bound of the accepted graph is a local
maximum. This procedure can be represented by a formal hill-climbing algorithm as given
below.
Algorithm 4
1. Initialise the iteration counter to k = 1. For an initial graphical
model M0, relating to a directed A-graph on d vertices, G0 (itself corresponding to
matrix A(0)), run update equations for the variational parameters until convergence,
and hence evaluate the converged lower bound, LM0(q0).
2. At iteration k, propose a modiï¬ed graphical model, MÏ†, to the current model, Mkâˆ’1,
such that we have exactly one of the following:
(a) a new edge is randomly added to the current graph, Gkâˆ’1.
(b) a randomly selected edge is deleted from this graph.
That is, randomly and independently, simulate two integers from the sequence 1, . . . , d,
namely i, j. Examine the corresponding entry of the matrix A(kâˆ’1). If a(kâˆ’1)
ji
= 0
(the value of aji at iteration k âˆ’1), add the corresponding directed edge from i to
j to the existing Gkâˆ’1, and let a(Ï†)
ji
= âˆ—(an unspeciï¬ed, non-zero). Otherwise, if
non-zero, delete this edge and let a(Ï†)
ji = 0.
3. Evaluate the variational score, LMÏ†(qÏ†), for the proposed model MÏ†.
4. Set LMk(qk) = LMÏ†(qÏ†), hence Mk = MÏ†, i.e. accept the new variational score and
model MÏ†, if LMÏ†(qÏ†) > LMkâˆ’1(qkâˆ’1). Otherwise, set LMk(qk) = LMkâˆ’1(qkâˆ’1) and
thus Mk = Mkâˆ’1.
101

4.2. Hill-climbing
5. Change the counter from k to k + 1 and return to step 2.
So, this algorithm attempts to locate a locally optimum graph by searching throughout
the graphical space, accepting and rejecting moves as appropriate.
This procedure is
illustrated by a simple example.
4.2.1
Example
Suppose d = 10. A dataset of size N = 250 was simulated from the VAR(1) model (3.2)
with speciï¬cations A = diag(0.6), a 10 Ã— 10 diagonal matrix of coeï¬ƒcients, and Ïƒ2 = 0.1.
This implies that the true choice of A can be represented by an A-graph such that each
of the 10 nodes has a directed self-loop, and no other edges exist. We realise now that
the dimension of the graphical space is 2102 âˆ’1 â‰ˆ1.268 Ã— 1030.
The prior distributions over a and Ïƒ2 were again given by
p(a) = N (a | 0, Câˆ—) where cij âˆˆ{0, 0.5}
p(Ïƒ2) = IG(Ïƒ2 | 1, 0.001).
Algorithm 4 was then implemented for this example by choosing three distinct, ini-
tial models, denoted as M0, 1, M0, 2, M0, 3, each represented by a corresponding A-graph,
namely G0, 1, G0, 2, G0, 3. Then, G0, 1 was speciï¬ed to be a graph with only one edge, a
self-loop on node y1, whereas G0, 2 was given as the complete graph. Finally, G0, 3 had
directed edges in both directions between nodes yi and yi+1 for all i = 1, . . ., 9. This lat-
ter graph corresponds to an A-matrix with non-zero elements down the ï¬rst sub-diagonal
and ï¬rst super-diagonal (the diagonals immediately below and above the main diagonal
respectively) and zeroes elsewhere.
Then, in each case, the algorithm was run for 10, 000 iterations. For the three starting
102

4.2. Hill-climbing
graphs, G0, 1, G0, 2 and G0, 3, a local maximum of LMi(qi) was located after 1041, 540 and
1041 iterations, requiring 39, 98 and 58 accepted moves respectively to reach this value.
The local maximum found by each model was, in fact, the variational score associated with
the graph from which the data was simulated. Given the dimension of the graphical space,
we cannot be certain that we have reached a global maximum as there may be other graphs
that are erroneously preferred to the truth. However, since the same optimum has been
reached from three diï¬€erent starting points, there is a good chance that this maximum
cannot be improved upon, and is indeed global. The convergence patterns of the three
models is shown in Figure 4.1 below.
Time
L(q)
0
200
400
600
800
1000
1200
âˆ’8400
âˆ’8200
âˆ’8000
âˆ’7800
âˆ’7600
âˆ’7400
G0, 1
G0, 2
G0, 3
Figure 4.1: Convergence of hill-climbing algorithm for diï¬€erent, initial graphs
The plot shows that the climb taken by G0, 2 to reach the maximum was much smoother
and quicker than that of G0, 1 and G0, 3, whose paths were actually quite akin to each
other. Clearly, the complete graph was already well-favoured by the data. For G0, 2, it
is no surprise however that the number of accepted moves needed to reach convergence
was greater than for both G0, 1 and G0, 3 as it was the most distinct initial graph from the
truth. We notice that both G0, 1 and G0, 3, due to the similarity of their routes, became
103

4.3. Random walks
stuck at the same local maximum, after around 400 iterations, before reaching the ï¬nal
lower bound value. This is indicated by the ï¬‚atness of their convergence at this stage.
The hill-climbing algorithm is an eï¬ƒcient search tool that can be used in large state spaces
and, as the above example illustrates, can perform well in reasonable time. It is clear that
as the state space decreases in size, the number of iterations required to reach a local
maximum will also lessen. However, hill-climbing does possess some intrinsic problems.
For instance, we can never be certain of ï¬nding a global maximum. We can easily get
stuck at a local maximum, where all neighbouring states are of lesser value. However, this
point could be signiï¬cantly worse than the global maximum, and even other local maxima
in the space. Moreover, the algorithm can reach a ï¬‚at part of the state space known as
a plateau. In this case, all neighbours will be of the same quality, no uphill moves can
be made, and hence the algorithm is again trapped. So, the success of the algorithm is
dependent upon the shape of the state space. To tackle these issues, several diï¬€erent
forms of hill-climbing have been constructed. For details, see, for example, Russell and
Norvig (2003).
4.3
Random walks
As we have seen in the previous section, application of the hill-climbing algorithm consists
of comparing the variational scores for a current and proposed model at each iteration.
However, unfortunately, no information is provided about the model posterior distribu-
tion. Of course, this is a key concept because it encapsulates our post-data beliefs about
each model. So, an alternative method, which will allow exploration of this distribu-
tion, would be to make a random walk across the graphical space.
As mentioned in
Section 4.1, the acceptance of a proposed move to a new graph is determined by the
Metropolis-Hastings algorithm. It is already evident that the greediness of hill-climbing
is, in fact, its downfall, i.e. we can never see beyond exactly any one move. So, a further
104

4.3. Random walks
advantage of random walks is now that we may be willing to accept â€˜downhillâ€™ moves
which, although result in a decrease of variational score, may lead to a greater increase
at a subsequent iteration, and hence escape local maxima. Other such authors to search
the graphical space in this way include Giudici and Green (1999) and Jones et al. (2005).
A random walk on a single graph involves randomly selecting, and hence moving to, an
adjacent node to the current node on the graph, with equal probability for each of these
neighbours, hence forming a sequence of selected nodes. That is, the next node is chosen
from the (discrete) uniform distribution. We can illustrate this by considering Figure 4.2.
Here, we let each undirected edge represent a two-way directed edge between a pair of
nodes. Suppose we are at node 1. Then, as this node possesses two neighbours (nodes 2
and 4), the probability of moving to either neighbour is 1
2. However, if we are at node 2,
the corresponding probability would be 1
3 and so on.
1
2
3
4
Figure 4.2: A simple graph on which to make a random walk
In general, notice that the probability of moving to a new node at time t+1 is dependent
only upon the node at which we reside at time t, and none of the previous history of the
random walk. Thus, the sequence of visited nodes forms a Markov chain with transition
105

4.3. Random walks
matrix probabilities, pij, indicating a move from node i to node j, such that
pij =
âŽ§
âŽ¨
âŽ©
1
di
if (i, j) âˆˆE
0
otherwise
,
as noted by HÂ¨aggstrÂ¨om (2002). Here, di is the number of neighbours of node i and E is
the set of edges. For a comprehensive review of random walks, see, for instance, LovÂ´asz
(1993).
Here however, we examine not movement between adjacent nodes on one graph, but
instead between adjacent graphs in the space.
So, in terms of models, for a current
model, say Mj, represented by an A-graph, Gj, a proposed, neighbouring model, Ml,
is considered, whose graph Gl diï¬€ers from that corresponding to Mj by the addition or
deletion of a uniformly selected edge. We allow acceptance of the proposed graphical
model by using the Metropolis-Hastings algorithm.
For further details, the reader is
referred back to Chapter 2.
By considering a move from a current to a proposed model, an acceptance probability
(c.f. (2.3)) can be speciï¬ed such that
Î±(Mj, Ml) = min

1, p(Ml | D) q(Ml, Mj)
p(Mj | D) q(Mj, Ml)

.
(4.1)
Our distribution of interest is now given as the posterior over models, and q(Â· , Â·) is again
the proposal distribution, entering Î±(Â· , Â·) via a ratio, namely
q(Ml, Mj)
q(Mj, Ml).
The denominator speciï¬es the probability of the move from current model Mj to proposed
model Ml whereas, on the numerator, that of the reverse move. However, as was seen in
106

4.3. Random walks
Chapter 1, we have no knowledge of the model posterior as, by Bayesâ€™ Theorem, this is
dependent upon the marginal likelihood, p(D | Mi), for each model Mi. Despite this, we
have already used the variational algorithm to bound, and hence approximate, p(D | Mi)
whereby LMi(qi) â‰¤log p(D | Mi). Thus, the ratio of model posteriors in the acceptance
probability (4.1) can be rewritten as
p(Ml | D)
p(Mj | D) = p(D | Ml) p(Ml)
p(D | Mj) p(Mj) â‰ˆexp{LMl(ql)} p(Ml)
exp{LMj(qj)} p(Mj).
(4.2)
As was mentioned previously in Chapter 2, the constant of proportionality, p(D), is
eliminated in the acceptance probability by the ratio of posteriors. An important point
to raise here is that we can only be sure of sampling from an approximation to the true
model posterior. Of course, by minimising the KL divergence between the variational and
true posterior, we suppose that the lower bound is close to the log marginal likelihood
(and hence the samples are of suï¬ƒcient quality). However, this is only an assumption and
does not illustrate formally the accuracy of the bound.
To combat this problem, Miskin (2000) and Beal (2003) discuss the use of importance
sampling from the varaiational approximation to estimate log p(D | Mi). That is, the loga-
rithm of integral (1.2) is approximated by taking importance samples from the variational
distribution q(Î¸i | D, Mi). This idea seems sensible since the variational should be repre-
sentative of the true posterior by free form optimisation. However, Beal (2003) indicates
several drawbacks with this approach, most notably that importance sampling performs
poorly in high dimensions and can even fail in one dimension. In any case, we would
expect the diï¬€erence between the log marginal likelihood and lower bound to be similar
for any model Mi. As a consequence, any inaccuracy in the approximation will cancel
from the ratio of bounds in (4.2), and so such a comparison simulation is not employed
here.
In returning to (4.2), a form for the model priors must also be speciï¬ed. However, further
107

4.3. Random walks
discussion is required before making such a choice. We reconsider (3.9) and (3.10). Al-
though not stated explicitly, these prior distributions are conditioned on each model Mi in
the candidate set, similarly the variational distributions (3.22) and (3.27). Yet moreover,
it is recalled that, in the previous chapter, sparsity modelling was used to induce many
zeroes in the parameter matrix A. That is, across Metropolis-Hastings iterations, we ex-
pect models to be chosen with few existent edges, implying that the number of causations
between nodes will be sparse. By modelling in this manner, a prior over the coeï¬ƒcients aij
of the autoregressive matrix A, where i, j = 1, . . ., d, across models is induced automat-
ically, which dictates that each aij may either be zero or non-zero. Such a speciï¬cation
is termed a sparsity prior (also termed by Lucas et al. (2006) as a â€˜point-mass mixtureâ€™
prior), taking the form
p(aij) = pÎ´0(aij) + (1 âˆ’p)N (aij | 0, c).
(4.3)
Here, c is deï¬ned from (3.11), and p = P(aij = 0) = 1 âˆ’P(aij Ì¸= 0) is the â€˜in-outâ€™, prior
probability that a coeï¬ƒcient is zero. Moreover, Î´0(Â·) is the Dirac delta function, which,
for any z âˆˆR, possesses the properties
 +âˆž
âˆ’âˆž
Î´0(z) dz = 1
Î´0(z) =
âŽ§
âŽ¨
âŽ©
0
if z Ì¸= 0
âˆž
if z = 0
.
That is, Î´0(z) has a peak of inï¬nite height at z = 0, and vanishes elsewhere on the real
line such that it integrates to unity. Thus, (4.3) dictates that aij is a point mass at zero
a priori with probability p, whereas a Gaussian distribution is followed with probability
1 âˆ’p. So, this prior, not conditional on each model, mixes a probability mass at aij = 0
with a distribution over non-zero values of aij. By updating (4.3), approximate marginal
posterior information can be provided about each aij, and this is discussed in the next
108

4.3. Random walks
section.
Presently however, we examine how this sparsity prior aï¬€ects the speciï¬cation of the
model prior distributions. Since p is the common, prior probability that no edge exists
between any pair of nodes, a form for p(Mi) is determined, assuming that all edges are
a priori independent. If a model Mi has Î· non-zero elements in its associated A-matrix
(i.e. there are Î· edges on the graph), then, as A contains d2 elements, a prior distribution
can be speciï¬ed such that
p(Mi) = pd2âˆ’Î·(1 âˆ’p)Î·.
(4.4)
For example, suppose that a model is represented by the matrix A =
âŽ›
âŽ0
0
âˆ—
0
âŽž
âŽ . Then, the
prior for this model is equivalent to P(a11, a12, a22 = 0) Ã— P(a21 Ì¸= 0) = p3(1 âˆ’p).
From (4.4), we notice that all models will be equally likely a priori if p = 0.5. In such a
case, no preference is given to any particular model. However, if we choose p > 0.5, this is
no-longer true since more complex models will be penalised, and sparse models favoured.
Correspondingly, in the sparsity prior (4.3), this would then imply that all nodes have
lower prior probability of association with another node. For the subsequent examples in
this chapter, varying choices of p will be made to gauge the eï¬€ect produced on the models
accepted across iterations.
Ultimately, we return to (4.2), and specify the ratio of model priors in this expression by
inspecting two distinct circumstances. Suppose that there are Î· edges on the graph Gj,
corresponding to the current model Mj. Then ï¬rstly, assume that the proposed model
Ml is deï¬ned such that a uniformly chosen edge is added to the graph. Thus, the model
prior ratio provides
p(Ml)
p(Mj) = pd2âˆ’Î·âˆ’1(1 âˆ’p)Î·+1
pd2âˆ’Î·(1 âˆ’p)Î·
= 1 âˆ’p
p
.
109

4.3. Random walks
So, in this case, the acceptance probability is given by
Î±(Mj, Ml) = min

1,
	1 âˆ’p
p
Ã— exp{LMl(ql)} q(Ml, Mj)
exp{LMj(qj)} q(Mj, Ml)

.
(4.5)
Secondly, let Ml now be speciï¬ed whereby an edge is randomly deleted from the current
graph. Hence, on this occasion, the afore-mentioned ratio yields
p(Ml)
p(Mj) = pd2âˆ’Î·+1(1 âˆ’p)Î·âˆ’1
pd2âˆ’Î·(1 âˆ’p)Î·
=
p
1 âˆ’p.
Of course, the proposed model is subsequently accepted on the basis of
Î±(Mj, Ml) = min

1,
	
p
1 âˆ’p Ã— exp{LMl(ql)} q(Ml, Mj)
exp{LMj(qj)} q(Mj, Ml)

.
(4.6)
Notice that (4.5) and (4.6) are equivalent, only when p = 0.5, as mentioned previously.
We also need to deï¬ne a form for the proposal distribution, q(Â· , Â·). In general, care must
be shown when making such a choice. If the proposal results in candidates being regularly
rejected, the chain will move infrequently, and so mixing will be poor. Similarly, if too
many candidates are accepted, achieved by proposing only small moves, exploration of
the graphical space will again take a long time. A good proposal will avert both these
extremes.
If we examine the random walk on a single graph again, such proposal probabilities are
easily speciï¬ed. For instance, reconsider Figure 4.2. If we were proposing the move from
node 1 to node 2, then using the same notation for proposal densities as above, the ratio
of proposals in the Metropolis-Hastings acceptance probability would be
q(2, 1)
q(1, 2) =
1
3
1
2
= 2
3,
110

4.3. Random walks
as node 1 and node 2 have two and three neighbours respectively. The case of random
walks amongst graphs is analogous to this, where we now use a (discrete) uniform proposal
distribution to choose a new graph from the set of neighbouring graphs. For a graph on
d nodes, there are typically d2 neighbours. This is clear since each graph corresponds to
a d Ã— d sparse matrix A, and hence there are d2 possible ways to change exactly one of
the elements in the matrix to form a new graph. However, we must proceed cautiously
here since we ignore the null graph, represented by the zero matrix, as pointed out in
Section 3.5. Thus, for graphs with just 1 existent edge, there are only d2 âˆ’1 neighbouring
graphs.
Consequently, we look at three scenarios for the ratio of proposal densities, each to be
considered in turn. Recall that we modify the existent model in two ways: either adding or
deleting an edge from the current graph. A â€˜delete moveâ€™ from a model Mj, corresponding
to a graph Gj with two edges, to a speciï¬ed model Ml, whose graph Gl possesses a single
edge, has ratio of proposals such that
q(Ml, Mj)
q(Mj, Ml) =
1
d2âˆ’1
1
d2
=
d2
d2 âˆ’1.
(4.7)
Here, the probability of a move from model Mj to Ml, given by the denominator, follows
since Gj has d2 neighbouring graphs.
Moreover, the probability of the reverse move,
provided by the numerator, is clear as Gl has only d2 âˆ’1 neighbours. In contrast, an
â€˜add moveâ€™ from Mj, whose associated graph has one edge, to a given Ml, represented
graphically with two edges, has ratio of proposals given by
q(Ml, Mj)
q(Mj, Ml) =
1
d2
1
d2âˆ’1
= d2 âˆ’1
d2
.
(4.8)
Any other move has the ratio
q(Ml, Mj)
q(Mj, Ml) =
1
d2
1
d2
= 1,
(4.9)
111

4.3. Random walks
as now we can traverse to any of the d2 neighbouring graphs. A minor issue here is how
to proceed if the ï¬nal edge is selected for deletion, and this is explained in Algorithm 5
below.
Finally, we realise that, in practice, the exponential of the variational lower bound is
customarily very small in size. Hence, it makes computationally better sense to work
on the log scale.
In total, four separate versions are obtained for the log acceptance
probability log Î±(Â·, Â·). If an edge is added to the current graph, the ratio of proposal
densities, (4.8) and (4.9), are substituted directly into (4.5), representing respectively
the cases when the current graph has one edge, and otherwise. In an analogous way,
(4.7) and (4.9) are inserted accordingly into (4.6), when an edge is deleted. In all cases,
logarithms are taken of both parts of the acceptance probability. So, the Metropolis-
Hastings algorithm can be provided thus. In what follows, we suppose that each current
graph has Î» edges, whereas every proposed graph has Î¶ edges, i.e. Î» and Î¶ represent the
number of non-zeroes in the corresponding A-matrix.
Algorithm 5
1. Initialise the iteration counter to k = 1. For an initial graphical
model M0, relating to a directed A-graph on d vertices, G0 (itself corresponding to
matrix A(0)), run update equations for the variational parameters until convergence,
and hence evaluate the converged lower bound, LM0(q0).
2. At iteration k, propose a modiï¬ed graphical model, MÏ†, to the current model, Mkâˆ’1,
such that we have exactly one of the following:
(a) a new edge is randomly added to the current graph, Gkâˆ’1.
(b) a randomly selected edge is deleted from this graph.
That is, randomly and independently, simulate two integers from the sequence 1, . . . , d,
namely i, j. Examine the corresponding entry of the matrix A(kâˆ’1). If a(kâˆ’1)
ji
= 0,
add the corresponding directed edge from i to j to the existing Gkâˆ’1, and let a(Ï†)
ji = âˆ—
112

4.3. Random walks
(an unspeciï¬ed, non-zero). Otherwise, if non-zero, delete this edge and let a(Ï†)
ji = 0.
If the last edge is chosen for deletion, additional pairs of integers are simulated until
an edge is found that can be added. During this time, the algorithm remains at
iteration k.
3. Evaluate the variational score, LMÏ†(qÏ†), for the proposed model MÏ†.
4. Calculate the log acceptance probability log Î±(Mkâˆ’1, MÏ†) of the proposed move, where:
(a) an edge is added to the graph Gkâˆ’1.
â€¢ if Î» = 1,
log Î±(Mkâˆ’1, MÏ†) = min{0, log(1 âˆ’p) âˆ’log p + LMÏ†(qÏ†) âˆ’LMkâˆ’1(qkâˆ’1)
+ log(d2 âˆ’1) âˆ’log d2}.
â€¢ otherwise,
log Î±(Mkâˆ’1, MÏ†) = min{0, log(1 âˆ’p) âˆ’log p + LMÏ†(qÏ†) âˆ’LMkâˆ’1(qkâˆ’1)}.
(b) an edge is deleted from the graph Gkâˆ’1.
â€¢ if Î¶ = 1,
log Î±(Mkâˆ’1, MÏ†) = min{0, log p âˆ’log(1 âˆ’p) + LMÏ†(qÏ†) âˆ’LMkâˆ’1(qkâˆ’1)
+ log d2 âˆ’log(d2 âˆ’1)}.
â€¢ otherwise,
log Î±(Mkâˆ’1, MÏ†) = min{0, log p âˆ’log(1 âˆ’p) + LMÏ†(qÏ†) âˆ’LMkâˆ’1(qkâˆ’1)}.
5. Put LMk(qk) = LMÏ†(qÏ†), hence Mk = MÏ†, i.e. accept the new variational score and
graphical model MÏ†, with log probability log Î±(Mkâˆ’1, MÏ†). Otherwise, put LMk(qk) =
113

4.3. Random walks
LMkâˆ’1(qkâˆ’1) and thus Mk = Mkâˆ’1.
6. Change the counter from k to k + 1 and return to step 2.
To clarify, at each iteration, a new model is simulated from the proposal distribution,
represented in the algorithm by a corresponding variational score. The score (and hence
model) can be either accepted or rejected upon comparison to the lower bound of the
current model, determined by the acceptance probability.
Notice that, from a com-
putational perspective, a proposed move is accepted if log u < log Î±(Mkâˆ’1, MÏ†) where
u âˆ¼U(0, 1). It is also realised that, from the deï¬nitions of the log acceptance probability,
log

1âˆ’p
p

= log

p
1âˆ’p

= 0 when p = 0.5. Thus, the acceptance of models in the scheme
will be independent of p in this circumstance.
We hence construct a Markov chain of accepted variational scores, whose values, upon
convergence and exponentiating, will be draws from the distribution proportional to
exp{LMi(qi)} p(Mi), an approximation to the model posterior. Here, LMi(qi) is the dis-
tribution of lower bounds across all models, where i = 1, . . ., R. By comparing both
Algorithms 4 and 5, it is clear that this version of the Metropolis-Hastings algorithm is
merely an extension of the simpler hill-climbing algorithm of earlier. Presently however,
a proposed move is dependent upon an acceptance probability, which, as discussed previ-
ously, enables the graphical space to be explored with greater eï¬€ect than would be seen
with hill-climbing.
4.3.1
Implementation and analysis
In due course, we will use Algorithm 5 to make a random walk across the graphical space
in several examples. Before this, we examine the MCMC theory required to produce and
analyse the subsequent results. Initially, recall from Chapter 2 that trace plots can be
used to assess not only the duration of the burn-in period, but also the mixing properties
114

4.3. Random walks
of a Markov chain as a way to analyse possible convergence. Note that, in this case prior
to convergence, both the accepted lower bound values and associated candidate models
are eliminated.
A further plot to utilise when examining for convergence of a chain is that of the autocor-
relation function (ACF). We realise that the values generated by using the Metropolis-
Hastings sampler, upon convergence, are not independent since, by deï¬nition of a Markov
chain, each simulated value is dependent on the previous value. For instance here, the
current model, which may have been accepted at many iterations previous, is used to
generate a proposed model, by the addition or deletion of a uniformly selected edge from
the representative graph. Hence, this dependence implies that there will be correlation
between the corresponding variational scores for these models.
To quantify this correlation, the ACF at lag h measures the correlation between the whole
chain of lower bound values and the same chain, time-shifted by h iterations. Suppose
that, after burn-in and upon convergence, the chain is of length n. Then, for example, at
lag 10, we study the correlation between the lower bounds of the chain at the iteration
sets {1, 2, . . . , n âˆ’10} and {11, 12, . . . , n}. If LMk(qk) is the lower bound at the k-th
iteration, then the lag h ACF is estimated by
Ë†rh =
 nâˆ’h
k=1(LMk(qk) âˆ’Â¯L(q))(LMk+h(qk+h) âˆ’Â¯L(q))
 n
k=1(LMk(qk) âˆ’Â¯L(q))2
,
(4.10)
where Â¯L(q) = 1
n
 n
k=1 LMk(qk).
A high value of the ACF indicates poor mixing as indicated by no rapid movements on
the trace plot, and hence a lack of convergence. On the contrary, lower autocorrelations
correspond to little dependence between chain values. Therefore, new values of the chain
will not remain in the same area of the graphical space as those before, leading to good
coverage of the space, and hence a well mixing chain. Thus, the values are seen to be
â€˜independentâ€™ when there is approximately zero autocorrelation at each lag. The number
115

4.3. Random walks
of independent values represented is called the eï¬€ective sample size of the chain.
A
standard way to reduce autocorrelation is by only retaining every t-th value of the chain
after burn-in, a method referred to as thinning. It is important that t is chosen not to be
too large, since, although this would further reduce autocorrelation, we require a chain of
suï¬ƒcient length to conduct analysis.
In our discussion of testing for the convergence of a Markov chain, we have hitherto
inspected graphical methods, which are reliable, but lack formality. To this end, several
such convergence diagnostics have been developed, two of which are now examined and
a third illustrated in Section 4.3.5. Such diagnostics can be located within the R package
called CODA (Plummer et al., 2006).
The Raftery-Lewis test (Raftery and Lewis, 1992) is formulated around estimating a
quantile Q of the distribution of interest to within an accuracy of Â±r with probability s.
Recall, in general, that the value xp of a distribution F whereby F(xp) = p, for 0 < p < 1,
is the p-th quantile of this distribution.
Having speciï¬ed Q, r, s, the test breaks the
Markov chain into a new sequence such that we obtain a â€˜1â€™ if LMk(qk) â‰¤LQ(q) (the
Q-th quantile of the sample distribution of lower bounds) and a â€˜0â€™ otherwise, for all k.
This binary sequence generates a two-state Markov chain. Transition probabilities can be
estimated from the sample by counting the number of times that state a moves to state
b where a, b = 0, 1, and normalising so that the row sums in the transition matrix equal
one.
Thus, the test subsequently estimates the length of the burn-in period, M, the thinning
interval t and the number of additional iterations, N, required to achieve the level of
speciï¬ed accuracy. Moreover, also determined is Nmin, the number of iterations required
had the chain been fully independent. From this, the convergence diagnostic, I, known
as the dependence factor is derived such that I =
N
Nmin. This measures the increase in the
number of iterations needed to achieve convergence as a result of the correlation within
the chain. As a rule of thumb, if I > 5, then the chain suï¬€ers from strong autocorrelation,
116

4.3. Random walks
indicating convergence problems.
An alternative diagnostic for convergence of a Markov chain is given by Heidelberger and
Welch (1983). Initially, we test the null hypothesis that the values of the chain come from
a stationary distribution. If the null is accepted, then no burn-in is needed; if rejected,
the ï¬rst 10% of the chain is removed and we repeat the test. If the test fails again, we
remove the next 10% from the sequence, and continue on until either the null hypothesis
is accepted, whereby the burn-in is considered to be the discarded part of the chain, or
less than 50% of the chain is left. In the latter case, the â€˜stationarity testâ€™ is deemed to
have failed, and hence the requirement for a longer MCMC run.
If the stationarity test is passed, then we conduct a half-width test on the remaining
part of the chain by constructing a conï¬dence interval for the mean of the distribution of
interest. Subsequently, we ï¬nd the ratio between half the width of the interval and the
sample mean. If the ratio is less than a speciï¬ed value, Ïµ, then this test is also passed.
A failure implies that a larger sample is required from which the mean can be estimated
with the necessary accuracy.
Thus far, the MCMC output has been pivotal to our analysis. However, we have additional
interest in the graphical structures of the models accepted across iterations, information
not provided by the variational scores on their own. To proceed, we simply measure the
cumulative eï¬€ect of such models. Thus, we create a d Ã—d â€˜countingâ€™ matrix, Ë†Î , initialised
as the zero matrix, which records each edge between any pair of nodes for the accepted
graph at every iteration of the thinned chain with burn-in discarded. For example, at
iteration k, suppose that there exists an edge between nodes i and j, and this same edge
had already been counted a times in the previous k âˆ’1 iterations. Then, we say that
Ë†Î (k)
ij = a + 1. This process is repeated for other edges between nodes before progressing
to iteration k + 1, and so on.
At the end of the MCMC run, the matrix can be inspected to establish which edges have
117

4.3. Random walks
been accepted most often. It would be beneï¬cial if this task were able to be performed
visually. Fortunately, we can utilise the standard R function, image. This function creates
a grid, representing each element of the matrix Ë†Î , and each rectangle on the grid is
assigned a colour. In the examples forthcoming, a spectrum of colours is applied, ranging
from red to white. The lighter the colour, the more often that edge has been accepted
between two particular nodes.
In other words, if any rectangle is red, that edge has
occurred infrequently.
When simulating data ourselves, we can introduce a true adjacency matrix, Î , deï¬ned
such that Î ij = 1 if aij Ì¸= 0, otherwise zero. Having normalised Ë†Î  by the length of the
chain n, we wish to employ a formal technique so that we may compare the empirical
proportions that any edge exists on the graph to the (0, 1)â€“matrix of true probabilities.
That is, to measure the discrepancy between the truth and the normalised estimate, we
can compute the residual sum of squares, denoted by S. Hence, in this instance, we have
S =
d

i=1
d

j=1
1
n
Ë†Î ij âˆ’Î ij
2
.
(4.11)
As mentioned in Section 4.3, the coeï¬ƒcients aij of the sparse matrix A across models
are a further quantity of interest. Formerly, given a dataset, our principle objective has
been to estimate the unknown sparsity structure of A, and discover which nodes on the
A-graph have an inï¬‚uence over others. That is, we aspired to determine the pattern of
zeroes in the truth. However, the focus now switches to learning the likely values of each
aij on the basis of an MCMC sampler. Thus, upon specifying the sparsity prior (4.3) over
these coeï¬ƒcients, we would like to revise our beliefs by inferring both P(aij = 0 | D) and
p(aij | aij Ì¸= 0, D). The former is the posterior probability over models that a particular
aij = 0, whereas the latter is the marginal posterior density of aij, given that it is non-zero
in value.
For each coeï¬ƒcient, it is possible to estimate P(aij = 0 | D) by counting the number of
118

4.3. Random walks
times that aij = 0 for the models accepted across Metropolis-Hastings iterations of the
thinned, converged chain, and dividing by the length of the run n. It is critical to realise
that this estimate is dependent, not only upon the simulation of a new model via the
proposal distribution, but also the use of the variational algorithm to determine which
model is accepted at each iteration. At this stage, we recollect that the two lower bounds
for the proposed and current model are entered into the acceptance probability. Hence,
our approximation is denoted by Pvar(aij = 0 | D).
We now proceed to infer the marginal p(aij | aij Ì¸= 0, D). It is clear that the variational
posterior for aij, which corresponds to the model, Mk, accepted at iteration k of the
sampler, is conditioned upon it. So, to estimate this true posterior density of aij without
conditioning, we average these variational densities across iterations whenever aij Ì¸= 0.
This technique is known as Bayesian model averaging â€” for a brief overview, see Kass
and Raftery (1995). Now, deï¬ne naijÌ¸=0 to be the length of the chain when aij Ì¸= 0. Thus,
using (3.34) and previous notation, we calculate
pvar(aij | aij Ì¸= 0, D) =
1
naijÌ¸=0

a(k)
ij Ì¸=0
q(aij | D, Mk)
=
1
naijÌ¸=0

a(k)
ij Ì¸=0
N

aij | Ï(k)
(i,j), Ï„ (k)
(i,j)

.
(4.12)
Here, recall that a(k)
ij is the value of aij at iteration k, similarly Ï(k)
(i,j), Ï„ (k)
(i,j). Computation-
ally, we can evaluate the densities at the same set of points, and then average the values
obtained. Of course, the error associated with this estimate, achieved by simulation, is
again a consequence of the use of the variational approximation.
We now require a way to summarise the above, approximate marginal posterior informa-
tion for a set of coeï¬ƒcients of the matrix A. This can be performed graphically, as seen
in Scott and Berger (2006). For each aij, Pvar(aij = 0 | D) is denoted by the height of a
black, vertical bar with a circle atop, placed at zero and corresponding to the probability
119

4.3. Random walks
scale on the right-hand side of every graph. Moreover, the density pvar(aij | aij Ì¸= 0, D) is
also plotted, measured by the scale on the opposite side, and indicating the value of aij,
given that it is non-zero.
4.3.2
Examples
Algorithm 5 was coded in C, and then applied to three simulated data-sets from the
VAR(1) model (3.2), each of size N = 250 with dimension d = 10 and Ïƒ2 = 0.1. Only
the speciï¬cations of A and p = P(aij = 0) were considered for alteration in each example.
Here, the true A-graphs were chosen to be highly symmetric. Of course, the simulation
could be extended to test the algorithm on randomly generated, less structured graphs.
The prior distributions were again chosen to be
p(a) = N (a | 0, Câˆ—) where cij âˆˆ{0, 0.5}
p(Ïƒ2) = IG(Ïƒ2 | 1, 0.001).
The Metropolis-Hastings scheme was run for 10, 000, 000 iterations in each case, and
the output transferred to R for subsequent analysis. It was initialised from graph G0,
containing one self-loop on the node y1. Of course, this corresponds to the matrix A(0)
where a(0)
11 = âˆ—, otherwise zero. Using trace plots, the burn-in period was taken to be
the ï¬rst 100, 000 iterations. The remainder was thinned by maintaining every 1000-th
iteration, leaving a total of 9900 iterations for each example on which to conduct analysis.
A histogram of 30 bins was employed throughout.
Moreover, the Raftery-Lewis test was initialised with Q = 0.025, r = 0.005, s = 0.95, i.e.
estimate the 2.5% quantile of the cumulative distribution function to within an accuracy
of Â±0.005 with probability 0.95. These are the default speciï¬cations for the function,
as quoted in Raftery and Lewis (1992).
On the other hand, the Heidelberger-Welch
120

4.3. Random walks
diagnostic was speciï¬ed to ï¬nd a 95% conï¬dence interval for the mean, and the half-
width ratio to be less than Ïµ = 0.1. Moreover, the stationarity test was passed if the
p-value calculated was greater than 0.05.
Example 1
Initially, A and p were speciï¬ed such that A = diag(0.8) and p = 0.5, i.e. all models were
favoured equally a priori. Figure 4.3 shows the trace plot, ACF plot and histogram of
the lower bound values, and the image plot of Ë†Î .
0
2000
4000
6000
8000
10000
âˆ’7340
âˆ’7330
âˆ’7320
âˆ’7310
Trace plot of L(q)
Iteration
L(q)
0
20
40
60
80
100
0.0
0.2
0.4
0.6
0.8
1.0
Lag
ACF
ACF plot for L(q)
Histogram of L(q)
L(q)
Frequency
âˆ’7340
âˆ’7330
âˆ’7320
âˆ’7310
âˆ’7300
0
200
400
600
0
1
2
3
4
5
6
7
8
9
10
0
1
2
3
4
5
6
7
8
9
10
Image plot for Pihat
Row
Col
Figure 4.3: Plots for the analysis of the MCMC output in Example 1
The trace plot shows rapid movement throughout the graphical space, and hence that
it is mixing well.
Moreover, the ACF plot drops immediately to approximately zero
autocorrelation, thus indicating the independence of the values of the chain.
This is
121

4.3. Random walks
illustrated further by utilising the effectiveSize function in the CODA library. In this
case, the eï¬€ective sample size, i.e. the equivalent independent sample size, is calculated
to be 9900, which is the length of the entire chain. Therefore, we can view the output
as an independent chain. Given the length of the MCMC run, the stringent thinning has
evidently worked. It is stressed that the correlation at lag 0 is always equal to 1, as this
is the chain cross-correlated with itself without any time shift. This is clear from (4.10)
by setting h = 0.
The above analysis provides good evidence of convergence of the chain to the station-
ary distribution. For the purposes of formality, we now apply the two afore-mentioned
convergence diagnostics to the set of lower bounds. So, using CODA, the output from the
Raftery-Lewis test was as follows.
Iterations = 1:9900
Thinning interval = 1
Number of chains = 1
Sample size per chain = 9900
Quantile (q) = 0.025
Accuracy (r) = +/- 0.005
Probability (s) = 0.95
Burn-in
Total Lower bound
Dependence
(M)
(N)
(Nmin)
factor (I)
Lq
2
3780
3746
1.01
The results suggest that only the ï¬rst 2 iterations should be taken as additional burn-in,
and a further 3780 iterations are necessary to attain the desired level of accuracy. To this
end, resultantly, the 9900 iterations actually applied are more than suï¬ƒcient. Finally, the
value of the dependence factor is close to 1, indicating the independence inherent within
the chain and evidence for convergence.
The Heidelberger-Welch diagnostic produced
122

4.3. Random walks
Stationarity start
p-value
test
iteration
Lq
passed
1
0.119
Halfwidth Mean
Halfwidth
test
Lq
passed
-7315 0.117
On the output for the stationarity test, we see that the test was passed without the
need to discard any of the chain, hence the start iteration is given as 1.
Thus, the
null hypothesis that the chain has converged is accepted with a p-value greater than the
threshold value of 0.05. Moreover, the half-width test above yields the sample mean of the
lower bounds, and the size of half of the constructed conï¬dence interval. With both tests
passed, once again, the chain of variational scores seems to have converged. It is noted
that diagnostics were also considered for several components of Ï and Ï„, recorded at each
iteration and corresponding to the accepted model. In each case, these were consistent
with the convergence results for LMk(qk), and so are not shown here. We suggest that
studying LMk(qk) is deemed suï¬ƒcient to test for convergence.
In addition, we realise that the image plot of Ë†Î  in Figure 4.3 is as expected, with self-loops
regularly recognised for all nodes (white rectangles along the main diagonal). With the
true adjacency matrix speciï¬ed as Î  = diag(1), this accuracy is ampliï¬ed by calculating
the residual sum of squares to be S = 0.684. So, when choosing p = 0.5, the true sparsity
structure has been identiï¬ed to a highly acceptable level. Finally, graphical summaries
for both Pvar(aij = 0 | D) and pvar(aij | aij Ì¸= 0, D) are presented in Figure 4.4 for several
coeï¬ƒcients of A.
As the true A had non-zero entries only along the diagonal, we would expect the value of
Pvar(aij = 0 | D), the approximate posterior probability of a point mass at zero, to be high
for those oï¬€-diagonal coeï¬ƒcients. This is certainly apparent from the above plots. More-
over, each diagonal coeï¬ƒcient possesses the corresponding probability to be approximately
zero. It is also noticeable that these same entries possess a density pvar(aij | aij Ì¸= 0, D)
123

4.3. Random walks
0.0
0.5
1.0
Value
0
2
4
6
8
10
Density
0
0.2
0.4
0.6
0.8
1
Probability
0.0
0.5
1.0
Value
0
2
4
6
8
10
Density
0
0.2
0.4
0.6
0.8
1
Probability
0.0
0.5
1.0
Value
0
2
4
6
8
10
Density
0
0.2
0.4
0.6
0.8
1
Probability
0.0
0.5
1.0
Value
0
2
4
6
8
10
Density
0
0.2
0.6
1
Probability
0.0
0.5
1.0
Value
0
2
4
6
8
10
Density
0
0.2
0.4
0.6
0.8
1
Probability
0.0
0.5
1.0
Value
0
2.2
4.4
6.6
8.8
11
Density
0
0.2
0.4
0.6
0.8
1
Probability
0.0
0.5
1.0
Value
0
2
4
6
8
10
Density
0
0.2
0.4
0.6
0.8
1
Probability
0.0
0.5
1.0
Value
0
2
4
6
8
10
Density
0
0.2
0.4
0.6
0.8
1
Probability
0.0
0.5
1.0
Value
0
2
4
6
8
10
Density
0
0.2
0.4
0.6
0.8
1
Probability
a11
a12
a13
a21
a22
a23
a31
a32
a33
Figure 4.4: Plots showing estimated, marginal posterior distributions for aij, i, j = 1, 2, 3,
in Example 1
with mode approximately equal to 0.8. Similarly, the related density for the oï¬€-diagonal
components is peaked around zero. So, in each case, the truth is being well represented.
Thus, the dataset of size N = 250 has overridden the prior on a at each iteration in the
variational Bayesian update, hence providing accurate, akin estimates of aij, when not
constrained to zero (c.f. Table 3.1 in Section 3.5). At the same time, the variance from
prior to variational distribution has decreased, and so there is greater certainty about
these values.
Therefore, as this will be the case for each component, these marginal
density plots possess a similar shape.
124

4.3. Random walks
Example 2
On this occasion, we again chose p = 0.5, but now A as the tridiagonal matrix such that
A = tridiag(0.2, 0.4, 0.2), using the notation of Saad (2003). That is, A has 0.4s down the
main diagonal and 0.2s down the ï¬rst sub-diagonal and ï¬rst super-diagonal, with zeroes
elsewhere. The graphical analysis of the MCMC output for this data-set is displayed in
Figure 4.5.
0
2000
4000
6000
8000
10000
âˆ’7380
âˆ’7370
âˆ’7360
âˆ’7350
âˆ’7340
Trace plot of L(q)
Iteration
L(q)
0
20
40
60
80
100
0.0
0.2
0.4
0.6
0.8
1.0
Lag
ACF
ACF plot for L(q)
Histogram of L(q)
L(q)
Frequency
âˆ’7380
âˆ’7370
âˆ’7360
âˆ’7350
âˆ’7340
0
200
400
600
0
1
2
3
4
5
6
7
8
9
10
0
1
2
3
4
5
6
7
8
9
10
Image plot for Pihat
Row
Col
Figure 4.5: Plots for the analysis of the MCMC output in Example 2
The trace and ACF plots reveal quick mixing and an independent chain respectively,
implying convergence. This is emphasised by effectiveSize being calculated as 9900,
similar to above. For completeness, we apply the two convergence diagnostics for the
lower bounds. The Raftery-Lewis output shows
125

4.3. Random walks
Iterations = 1:9900
Thinning interval = 1
Number of chains = 1
Sample size per chain = 9900
Quantile (q) = 0.025
Accuracy (r) = +/- 0.005
Probability (s) = 0.95
Burn-in
Total Lower bound
Dependence
(M)
(N)
(Nmin)
factor (I)
Lq
2
3812
3746
1.02
whereas the Heidelberger-Welch diagnostic provides
Stationarity start
p-value
test
iteration
Lq
passed
1
0.270
Halfwidth Mean
Halfwidth
test
Lq
passed
-7355 0.116
Both tests supply good evidence that the stationary distribution of the chain has been
acquired. As before, a similar conclusion is reached when applying the diagnostics to
components of Ï and Ï„. With the true value of Î  taken as Î  = tridiag(1, 1, 1), it was
found that S = 1.746. Thus, Ë†Î  remains highly accurate, as is displayed by the image
plot whereby the non-zero elements of A have been identiï¬ed, despite the A-graph that
simulated the data containing more edges than previous.
Upon examination of Figure 4.6, we see that the output is encouraging. For instance,
both Pvar(a13 = 0 | D) and Pvar(a31 = 0 | D) are very high in value. The same probability
for all other coeï¬ƒcients is negligible, whereas the plots pvar(aij | aij Ì¸= 0, D) for these
elements are peaked, close to the true value in each case. When compared with Example
1, the algorithm here had to determine more non-zero signals in the truth at each iteration,
indicating a reason as to why the density estimates were slightly less accurate than before.
126

4.3. Random walks
0.0
0.5
1.0
Value
0
1.5
3
4.5
6
Density
0
0.2
0.4
0.6
0.8
Probability
0.0
0.5
1.0
Value
0
1.5
3
4.5
6
Density
0
0.2
0.4
0.6
0.8
Probability
0.0
0.5
1.0
Value
0
1.4
2.8
4.2
5.6
7
Density
0
0.2
0.4
0.6
0.8
1
Probability
0.0
0.5
1.0
Value
0
1.6
3.2
4.8
6.4
8
Density
0
0.2
0.4
0.6
0.8
1
Probability
0.0
0.5
1.0
Value
0
1.6
3.2
4.8
6.4
8
Density
0
0.2
0.4
0.6
0.8
1
Probability
0.0
0.5
1.0
Value
0
1.6
3.2
4.8
6.4
8
Density
0
0.2
0.4
0.6
0.8
1
Probability
0.0
0.5
1.0
Value
0
1.5
3
4.5
6
7.5
Density
0
0.2
0.4
0.6
0.8
1
Probability
0.0
0.5
1.0
Value
0
1.5
3
4.5
6
7.5
Density
0
0.2
0.4
0.6
0.8
1
Probability
0.0
0.5
1.0
Value
0
1.5
3
4.5
6
7.5
Density
0
0.2
0.4
0.6
0.8
1
Probability
a11
a12
a13
a21
a22
a23
a31
a32
a33
Figure 4.6: Plots showing estimated, marginal posterior distributions for aij, i, j = 1, 2, 3,
in Example 2
Example 3
For the ï¬nal example, A was the sparse matrix given as A = tridiag(0.4, 0, 0.4). However,
we let p = 0.9, a larger speciï¬cation than used before and one which should favour
the acceptance of sparse models across iterations. The results are shown graphically in
Figure 4.7.
As with the two previous examples, the effectiveSize was computed in CODA as 9900
and, together with the trace and ACF plots, reveals probable convergence. This is further
emphasised by the Raftery-Lewis test on the variational scores, the results of which are
given below.
127

4.3. Random walks
0
2000
4000
6000
8000
10000
âˆ’7330
âˆ’7325
âˆ’7320
âˆ’7315
Trace plot of L(q)
Iteration
L(q)
0
20
40
60
80
100
0.0
0.2
0.4
0.6
0.8
1.0
Lag
ACF
ACF plot for L(q)
Histogram of L(q)
L(q)
Frequency
âˆ’7330
âˆ’7325
âˆ’7320
âˆ’7315
0
1000
2000
3000
4000
5000
0
1
2
3
4
5
6
7
8
9
10
0
1
2
3
4
5
6
7
8
9
10
Image plot for Pihat
Row
Col
Figure 4.7: Plots for the analysis of the MCMC output in Example 3
Iterations = 1:9900
Thinning interval = 1
Number of chains = 1
Sample size per chain = 9900
Quantile (q) = 0.025
Accuracy (r) = +/- 0.005
Probability (s) = 0.95
Burn-in
Total Lower bound
Dependence
(M)
(N)
(Nmin)
factor (I)
Lq
2
3843
3746
1.03
Moreover, the Heidelberger-Welch diagnostic exhibits additional conï¬rmation:
Stationarity start
p-value
test
iteration
Lq
passed
1
0.303
128

4.3. Random walks
Halfwidth Mean
Halfwidth
test
Lq
passed
-7317 0.0393
The histogram in Figure 4.7 is most intriguing. Here, very few moves are being accepted
(illustrated by an acceptance rate of just 1.4%), and any movement that is made is to
high-ranking models in the neighbourhood of the truth. By specifying p = 0.9, the plot of
Ë†Î  shows only the true edges being selected consistently, and no â€˜wrongâ€™ links identiï¬ed.
This contrasts slightly to the previous examples. After normalising, the proximity of Ë†Î 
to the true adjacency matrix is evident since now S = 0.014.
0.0
0.5
1.0
Value
0
1.4
4.2
7
Density
0
0.2
0.6
1
Probability
0.0
0.5
1.0
Value
0
1.5
3
4.5
6
7.5
Density
0
0.2
0.4
0.6
0.8
1
Probability
0.0
0.5
1.0
Value
0
1.4
4.2
7
Density
0
0.2
0.6
1
Probability
0.0
0.5
1.0
Value
0
1.7
3.4
5.1
6.8
8.5
Density
0
0.2
0.4
0.6
0.8
1
Probability
0.0
0.5
1.0
Value
0
1.7
3.4
5.1
6.8
8.5
Density
0
0.2
0.4
0.6
0.8
1
Probability
0.0
0.5
1.0
Value
0
1.7
3.4
5.1
6.8
8.5
Density
0
0.2
0.4
0.6
0.8
1
Probability
0.0
0.5
1.0
Value
0
1.7
3.4
5.1
6.8
8.5
Density
0
0.2
0.4
0.6
0.8
1
Probability
0.0
0.5
1.0
Value
0
1.7
3.4
5.1
6.8
8.5
Density
0
0.2
0.4
0.6
0.8
1
Probability
0.0
0.5
1.0
Value
0
1.7
3.4
5.1
6.8
8.5
Density
0
0.2
0.4
0.6
0.8
1
Probability
a11
a12
a13
a21
a22
a23
a31
a32
a33
Figure 4.8: Plots showing estimated, marginal posterior distributions for aij, i, j = 1, 2, 3,
in Example 3
Ultimately, the trends in the variational marginal posteriors for a set of coeï¬ƒcients of
A, given above in Figure 4.8, mimic what has been seen in the previous examples. In
129

4.3. Random walks
other words, those entries in the truth, speciï¬ed as zero, are again predicted to have a
point mass at zero with very high probability. Moreover, for all true non-zero elements,
pvar(aij | aij Ì¸= 0, D) is centred around the original speciï¬cation in each case.
4.3.3
Prior sensitivity
The above examples show initially that the Markov chain is reaching its stationary dis-
tribution.
We have tested this by using a combination of trace and ACF plots, the
effectiveSize function in CODA and two diï¬€erent convergence diagnostics. Moreover,
we have emphasised that the true sparsity structure is being recognised across iterations,
as seen by the image plot and statistic S, although this is aï¬€ected by the prior speciï¬ca-
tion of p. Finally, approximate marginal posteriors for sets of coeï¬ƒcients aij have been
seen to be accurate, compared to the true speciï¬cation of A.
Henceforth, a prior sensitivity analysis is conducted. Initially, we alter the prior parame-
ters for both a and Ïƒ2, whilst using a ï¬xed data-set. This is important, in particular for
the informative prior on a, to gauge if such a choice averts Lindleyâ€™s paradox (see Sec-
tion 3.4.2). Subsequently, sensitivity to the choice of p is also analysed. On this occasion,
the dimension is increased such that d = 20. A data-set was simulated with respect to
N = 250, A = tridiag(0.2, 0.4, 0.2) and Ïƒ2 = 0.1. Six diï¬€erent speciï¬cations of non-zero
cij = c and ï¬ve varying choices of Î±, Î² were examined (cf. (3.9) and (3.10)). The in-
verse gamma speciï¬cations were amended between Î± = 1, Î² = 0.001; Î± = 1, Î² = 0.01;
Î± = 1, Î² = 0.1; Î± = 1, Î² = 1 and Î± = 10, Î² = 10. Currently, p was ï¬xed at the true
proportion of zeroes in the A-matrix, namely p = 0.855. Hence, the results obtained will
not be aï¬€ected by this choice.
Algorithm 5 was initialised as in the previous section, and run for 10,000,000 iterations,
separately for each of the 30 combinations of c and Î±, Î². Again, in each case, the ï¬rst
100,000 were treated as burn-in and the remainder thinned by 1000. Image plots were then
130

4.3. Random walks
produced for all possibilities. It was found that, for every choice of c, the varying speciï¬ca-
tions of Î±, Î² made often no diï¬€erence to each image plot. So, at each Metropolis-Hastings
iteration, a suï¬ƒcient quantity of data was available to estimate the noise parameter, Ïƒ2,
extremely well, regardless of the prior speciï¬cation. Therefore, with the noise in the data
identiï¬ed, we will be able to establish the correct signals in the truth throughout the
scheme, leading to image plots that are similar to the truth, and to each other.
Consequently, Figure 4.9 contains the plots for altering c where Î± = 1, Î² = 0.001 are
now ï¬xed, a ï¬‚at prior, as mentioned previously. Moreover, Table 4.1 displays the values
of S, computed for each speciï¬cation of c. Here, the impact of Lindleyâ€™s paradox can be
ascertained. To produce frame (a), the most diï¬€use prior distribution was used, i.e. the
variance for each non-zero component, aij, was large. In addition, by recalling that every
aij is speciï¬ed as either a zero or a free entry, this prior was not concentrated around the
simpler of these two models in each case. So, an intuitive rationale may be that the signal
in the data will be recognised, and hence models, similar and at least as complex as the
truth, would be accepted during the MCMC run.
However, although the sparsity structure is being predicted here to some extent, the para-
dox is visible. That is, models, even simpler than the truth, are being accepted, and hence
favoured (shown in frame (a) by the white rectangles darkening or even disappearing) since
the non-zero elements of A are not being detected in the data. This is illustrated further
by the inaccuracy of S for this image plot. In the Metropolis-Hastings sampler, very few
proposed models are being accepted, hence leading to the lack of complexity shown here.
Indeed, across iterations, the overall acceptance rate of proposals was merely 2%. We
realise that a comparable, but less severe scenario is displayed in frame (b).
In contrast, consider frame (f), which resulted from specifying a highly informative prior.
Correct edges are now only selected infrequently, and more uncertainty has arisen about
the truth. When examining the matrix Ë†Î  itself, all incorrect edges are chosen more often
than in the other cases, although to an insuï¬ƒcient level so as to register on the image
131

4.3. Random walks
0
2
4
6
8
10
12
14
16
18
20
0
4
8
12
16
20
Row
Col
0
2
4
6
8
10
12
14
16
18
20
0
4
8
12
16
20
Row
Col
0
2
4
6
8
10
12
14
16
18
20
0
4
8
12
16
20
Row
Col
0
2
4
6
8
10
12
14
16
18
20
0
4
8
12
16
20
Row
Col
0
2
4
6
8
10
12
14
16
18
20
0
4
8
12
16
20
Row
Col
0
2
4
6
8
10
12
14
16
18
20
0
4
8
12
16
20
Row
Col
(a)
(b)
(c)
(d)
(e)
(f)
Figure 4.9: Plots of Ë†Î  for diï¬€erent speciï¬cations of c: (a) c = 10, 000, (b) c = 10, (c)
c = 0.5, (d) c = 0.1, (e) c = 0.01, (f) c = 0.001
Speciï¬cation of c
S
10, 000
21.244
10
10.018
0.5
6.439
0.1
6.513
0.01
7.078
0.001
11.731
Table 4.1: Comparing the accuracy of Ë†Î  for each choice of c
132

4.3. Random walks
plot. Resultantly, the S-value dictates that accuracy has been lost. So, we intimate a
slight tendency to approve denser models, the converse of the paradox, noted by the more
routine acceptance of proposals (23% acceptance rate).
The three foremost speciï¬cations of c appear to be c = 0.5, 0.1, 0.01. When studying
frame (e), â€˜non-existentâ€™ edges are occasionally identiï¬ed, and hence there is a preference
for models with more complexity. Yet, there is little diï¬€erence between frames (c) and
(d), whilst the values of S, when c = 0.5 and c = 0.1, are almost identical. Thus, it is
evident that, in each case, the truth is well represented. We notice that elements a16, 2
and a19, 12 are incorrectly recognised as non-zeroes in both of these plots, although more
recurrently when c = 0.1. Therefore, it is suggested that c = 0.5 is a sensible choice for
this example to compromise between continuous acceptance of simpler or more complex
models.
As a consequence of this sensitivity analysis, the prior parameter speciï¬cations of Î± =
1, Î² = 0.001 and c = 0.5 are henceforth maintained for further studies. We now wish
to establish the extent to which results are aï¬€ected by varying the choice of p.
For
this purpose, we retained d = 20, and utilised the same dataset as simulated above.
Moreover, for each choice of p, the MCMC sampler was also run in an identical fashion.
The speciï¬cations given for p were namely p = 0.95, 0.855, 0.5, 0.3, 0.1. Image plots and
their accuracy to the truth are displayed in Figure 4.10 and Table 4.2 respectively.
When A = tridiag(0.2, 0.4, 0.2), recall that specifying p = 0.855 will induce the correct
level of sparsity for models accepted during the scheme. Thus, it follows that frame (b)
is the best portrayal of the truth. If p is assigned above this level, we would then expect
those models considered too sparse to be in favour. A slight indication of this is revealed
in frame (a), and explains why the value of S has now become more discrepant.
In
addition, the acceptance rate of proposals here is only 3%. Similarly, when p < 0.855,
more dense models are preferred. As p approaches zero, this bias is more conspicuous,
and the acceptance rate rises dramatically; for instance, when p = 0.1, the rate is 58%.
133

4.3. Random walks
0
2
4
6
8
10
12
14
16
18
20
0
4
8
12
16
20
Row
Col
0
2
4
6
8
10
12
14
16
18
20
0
4
8
12
16
20
Row
Col
0
2
4
6
8
10
12
14
16
18
20
0
4
8
12
16
20
Row
Col
0
2
4
6
8
10
12
14
16
18
20
0
4
8
12
16
20
Row
Col
0
2
4
6
8
10
12
14
16
18
20
0
4
8
12
16
20
Row
Col
(a)
(b)
(c)
(d)
(e)
Figure 4.10: Plots of Ë†Î  for diï¬€erent speciï¬cations of p: (a) p = 0.95, (b) p = 0.855, (c)
p = 0.5, (d) p = 0.3, (e) p = 0.1
Speciï¬cation of p
S
0.95
9.164
0.855
6.439
0.5
8.312
0.3
16.123
0.1
61.563
Table 4.2: Comparing the accuracy of Ë†Î  for each choice of p
134

4.3. Random walks
Hence, in frame (e), although most true links are routinely discovered, it is unsurprising
that a plethora of false edges are now common, implying an inï¬‚ated S value. We conclude
that altering the speciï¬cation of p can have an extreme inï¬‚uence upon subsequent results.
4.3.4
Small sample size
We explore another study, namely to establish how well the true A is represented over
a Metropolis-Hastings run as the sample size N is changed. The choices for d, A and
Ïƒ2 are retained from the above section, whereas the prior speciï¬cations are set with
Î± = 1, Î² = 0.001, c = 0.5 and p = 0.855. Five separate datasets were simulated for
diï¬€ering values of N, in particular, N = 100, 80, 50, 20, 10. This was performed in such
a way that the matrix Y , of dimension N Ã— d, would form the ï¬rst N rows of the new
Y for the next highest selection of N. This ensured consistency between the data-sets.
Algorithm 5 was run for each N, whereby initialising graph, length of MCMC run, burn-in
period and thinning ratio were maintained as above.
The outcome of the investigation is summarised in Figure 4.11 and Table 4.3. Thus, it is
apparent that, as N decreases, the algorithm struggles to locate the truth and, as such,
the accuracy of Ë†Î  deteriorates. This is to be expected since, in this case, the signal in the
data will be weak. In the ï¬gure, for the higher choices of N, frames (a), (b) and (c) do
show that some correct edges are being continually recognised. However, once N = 20,
the signal disappears completely, and no obvious pattern emerges on the image plots. As
a consequence, values of S increase signiï¬cantly.
One ï¬nal analysis was administered by altering the value of the noise variance, Ïƒ2. For
this purpose, we let N = 250, and all other speciï¬cations stated above remained the
same.
The choices of Ïƒ2 considered were Ïƒ2 = 0.1, 0.5, 1, 5, 10.
Upon running the
MCMC algorithm and constructing image plots in each case, negligible diï¬€erence was
seen between Figure 4.9(c) (when Ïƒ2 = 0.1) and all other plots. Hence, all S-values were
135

4.3. Random walks
0
2
4
6
8
10
12
14
16
18
20
0
4
8
12
16
20
Row
Col
0
2
4
6
8
10
12
14
16
18
20
0
4
8
12
16
20
Row
Col
0
2
4
6
8
10
12
14
16
18
20
0
4
8
12
16
20
Row
Col
0
2
4
6
8
10
12
14
16
18
20
0
4
8
12
16
20
Row
Col
0
2
4
6
8
10
12
14
16
18
20
0
4
8
12
16
20
Row
Col
(a)
(b)
(c)
(d)
(e)
Figure 4.11: Plots of Ë†Î  for diï¬€erent speciï¬cations of N: (a) N = 100, (b) N = 80, (c)
N = 50, (d) N = 20, (e) N = 10
Speciï¬cation of N
S
100
19.437
80
23.477
50
35.035
20
47.113
10
51.729
Table 4.3: Comparing the accuracy of Ë†Î  for each choice of N
136

4.3. Random walks
akin. So, analogous to varying the prior speciï¬cation on Ïƒ2, it follows that adequate
observations are present here to estimate the noise in the data. Thus, whilst the true
noise is changed, the correct sparsity structure can be predicted accurately.
4.3.5
A further example
Hitherto, the Metropolis-Hastings algorithm has been applied to ï¬nd high scoring models
in graphical spaces of small to moderate dimension. Here, a more challenging example is
inspected whereby a dataset is simulated of size N = 250, with noise variance speciï¬ed
as Ïƒ2 = 0.1 and A = tridiag(0.2, 0.4, 0.2) as erstwhile, but now dimension d = 100. The
parameters for the prior distributions are maintained as Î± = 1, Î² = 0.001 and c = 0.5,
but we now let p = 0.9702, the proportion of zeroes in the true A.
It has been customary thus far to run the MCMC sampler for 10, 000, 000 iterations.
However, on this occasion, a problem may be encountered since the amount of compu-
tational time to complete the run can become too great. A simple solution to this is to
make several, shorter, parallel runs of the scheme, each independent and initialised from
a varying starting value (known as a seed). An advantage of this technique is that, by
comparing MCMC output, it is simple to identify any salient diï¬€erences between several
seemingly converged chains, if stationarity has yet to be reached.
Thus, ï¬ve Markov chains were simulated from diï¬€erent, user-speciï¬ed seeds in C, each of
length 2, 000, 000 iterations, and initialised from the same choice of G0 as before. Each
chain had the ï¬rst 100, 000 iterations dropped as burn-in, and was then thinned by 1000.
Hence, in total, 9500 iterations remained for analysis purposes. Figure 4.12 reveals the
plots of the output from the algorithm. Notice that the histogram displays the pooled
lower bound values for all ï¬ve chains. Here, CODA has been applied to produce an overall
trace plot, whereby the traces of the ï¬ve, individual chains are overlaid on top of each
other. Convergence can be realised when all chains possess similar behaviour, and hence
137

4.3. Random walks
are independent of each initial choice of seed.
By examining the plot, the mean and
variance of each chain are similar since the chains all overlap. Thus, there is reasonable
evidence for convergence.
0
500
1000
1500
âˆ’102500
âˆ’102450
âˆ’102400
Trace plot of L(q)
Iterations
L(q)
0
20
40
60
80
100
0.0
0.2
0.4
0.6
0.8
ACF plot for L(q)
Lag
ACF
Histogram of L(q)
L(q)
Frequency
âˆ’102500
âˆ’102450
âˆ’102400
0
200
400
600
800
0
10
20
30
40
50
60
70
80
90
100
0
10
30
50
70
90
Image plot for Pihat
Row
Col
Figure 4.12: Plots for the analysis of the MCMC output in Example 4.3.5
The ACF plot shows the average autocorrelation across all ï¬ve chains for a set of lags,
calculated simply by application of the function autocorr.diag. Here, the ACF declines
steadily, reaching zero at around lag 35, whereby the values in the chain are recognised
as being approximately independent.
In hindsight, the chain could be thinned by a
higher factor than 1000 to reduce this initial dependence between consecutive values.
Nevertheless, the trace and ACF plots still show acceptably quick mixing, and thus good
graphical space coverage.
At this stage, it would be beneï¬cial to amplify this view formally by the use of a conver-
138

4.3. Random walks
gence diagnostic. However, both tests discussed previously can be utilised when only one
chain is simulated. Fortunately, in the case of parallel chains, Gelman and Rubin (1992)
formulated such a diagnostic. For a set of m > 1 multiple chains, each containing n iter-
ations with the ï¬rst n
2 then discarded as burn-in, the statistic is based upon comparing
the variance within each chain, and the variance between chains. Thus, to estimate the
variance, Îº2, of the stationary distribution, we can compute both W, the mean of the m
within-chain variances, and Ë†Îº2, the variance of the mn values from all chains combined.
A variance ratio (often referred to as the potential scale reduction factor), denoted as Ë†R, is
then computed, dependent upon these two estimates. Consequently, if Ë†R is approximately
equal to 1, the variances within and between chains are coinciding, and so there is evidence
that all chains have converged to the stationary distribution, indicated on a trace plot by
overlapping. That is, each run is viewed as being independent of its initial seed choice.
In practice, Gelman et al. (1995) suggest a value of Ë†R â‰ˆ1.2 should be suï¬ƒcient for this
purpose, otherwise further iterations will be required to improve the estimates, W and
Ë†Îº2.
As with previous diagnostics, CODA can be used to apply the Gelman and Rubin test. So,
in the current example, the corresponding output was
Iterations = 1:1900
Thinning interval = 1
Number of chains = 5
Sample size per chain = 1900
Potential scale reduction factor:
Point est. 97.5% quantile
[1,]
1.02
1.04
Reported here are the estimated value and 97.5% quantile of Ë†R, the latter, an upper
limit, derived from its approximate sampling distribution â€” see Gelman and Rubin for
additional details. We realise that the ï¬rst n = 950 iterations of each chain are dropped
as burn-in automatically, and so the above values are computed using the lower bounds
139

4.3. Random walks
in the second half of the chains. As Ë†R and its upper limit are both close to 1, we can
conclude that 950 iterations were enough to enable convergence, and samples 950 âˆ’1900
from all chains are assumed to be draws from the stationary distribution.
We now return to Figure 4.12, and examine the plot of Ë†Î . This was produced by summing
the counting matrices from each of the ï¬ve chains, where recall that the total number of
iterations was n = 9500. Upon visual inspection, most true edges are recognised regularly,
whilst, due to the speciï¬cation of p, false links are seldom in favour. In this case, S is
computed as 82.611, a higher value than has been noted for previous examples. Yet, this
is hardly surprising when we realise that the size of the graphical space is now 210,000 âˆ’1.
If the size of the dataset were increased, we would expect S to be reduced, since the
algorithm should be able to locate the true sparsity structure with a much stronger signal
now in the data.
Finally, consider Figure 4.13, providing approximate, marginal posterior summaries for a
set of aij. In accordance with the initial speciï¬cation, the estimated posterior probabilities
that a13 and a31 are zero are very high.
Moreover, the plots of pvar(aij | aij Ì¸= 0, D)
have predicted the true coeï¬ƒcient values with impressive accuracy.
Here, we realise
that it is important to specify both parts of the approximate posterior distribution, as
noted by Scott and Berger (2006).
When studying both a21 and a32, it is seen that
Pvar(aij = 0 | D) â‰ˆ0.4 in each case. Yet, the density portion is concentrated around non-
zero values, as we would expect. Again, our uncertainty about these coeï¬ƒcients would
have been reduced if a larger dataset had been simulated.
4.3.6
Application to ERP data
A fresh example of our Metropolis-Hastings algorithm is now presented, where it is now
applied to real time series data, as opposed to the simulated datasets used previously.
This data has been analysed formerly by Delorme et al. (2004), and is freely available at
140

4.3. Random walks
Value
0
1.4
2.8
4.2
5.6
0
0.5
1
Density
0
0.2
0.4
0.6
0.8
Probability
Value
0
1.4
4.2
7
0
0.5
1
Density
0
0.2
0.6
1
Probability
Value
0
1.4
2.8
4.2
5.6
7
0
0.5
1
Density
0
0.2
0.4
0.6
0.8
1
Probability
Value
0
1.6
3.2
4.8
6.4
0
0.5
1
Density
0
0.2
0.4
0.6
0.8
Probability
Value
0
1.4
4.2
7
0
0.5
1
Density
0
0.2
0.6
1
Probability
Value
0
1.6
3.2
4.8
6.4
0
0.5
1
Density
0
0.2
0.4
0.6
0.8
Probability
Value
0
1.4
4.2
7
0
0.5
1
Density
0
0.2
0.6
1
Probability
Value
0
1.5
3
4.5
6
7.5
0
0.5
1
Density
0
0.2
0.4
0.6
0.8
1
Probability
Value
0
1.4
2.8
4.2
5.6
7
0
0.5
1
Density
0
0.2
0.4
0.6
0.8
1
Probability
a11
a12
a13
a21
a22
a23
a31
a32
a33
Figure 4.13: Plots showing estimated, marginal posterior distributions for aij, i, j =
1, 2, 3 in Example 4.3.5
141

4.3. Random walks
http://sccn.ucsd.edu/âˆ¼arno/fam2data/publicly available EEG data.html.
The authors
of the paper also provide details about the experiment that gave rise to the data, and this
is now summarised.
Several human subjects participated in an animal categorisation task, involving 100 diï¬€er-
ent photographs being shown at random to each volunteer for 20ms, with a small, random
time between each display. Of the images exhibited, half were target photographs, featur-
ing an animal, and the remaining 50 were non-targets, each known as a distractor. The
subjects had to respond within 1s, by releasing a button whenever the picture was an
animal, or keep the button depressed if a distractor was identiï¬ed.
During the experiment, for each participant, the electrical activity produced by the brain
(measured in microvolts, denoted Î¼V ) was recorded via d = 32 electrodes placed on the
scalp, hence giving rise to a set of electro-encephalographic (EEG) data. In every case,
this was split into two diï¬€erent datasets, representing the display and correct identiï¬cation
of either a target or non-target image. Moreover, the animal and distractor datasets were
further separated into a series of time periods or epochs, each lasting for approximately
3s, in which time one image was displayed. In what follows, N = 250 corresponding,
independent time points were examined in each epoch, a number suï¬ƒcient for decent
analysis. To reduce the amount of data further to a more, manageable level, the EEG
measurements were averaged at each time point across epochs, thus forming a set of event-
related potential (ERP) data. This procedure is also performed in practice, as it makes
the brain response to a particular stimulus more visible graphically.
For our analysis, we want to compare the fast, cerebral processing involved, by taking
ERP measurements, when correctly identifying either a target or non-target image. By
modelling the two sets of 32-electrode data by a zero mean VAR(1) process with unknown
A and Ïƒ2, our primary focus is to infer the sparsity structure of A. Moreover, an A-graph
can be constructed, with each node an electrode, determining the neural dynamics of
the information processing.
That is, our interest is to discover which electrodes were
142

4.3. Random walks
signiï¬cant by activating further responses elsewhere, and whether this was consistent
between viewing an animal or a distractor photograph.
We consider the animal and distractor ERP data for one particular subject in the study,
shown respectively in Figures 4.14 and 4.15.
Here, ERP value (in Î¼V ) is shown on
the vertical axis, time (in ms) the horizontal axis. Each ï¬gure displays the position of
every electrode on the scalp and, moreover, ERP measurements at each electrode. In all
cases, the stimulus was administered at time 0ms, hence the scale on the time axis. It
is noticeable that these two ï¬gures reveal similar ERPs at corresponding electrodes. It
will be seen in due course whether the same processing pathways are also involved upon
observation of the two distinct stimuli.
In each case, a data matrix Y of dimension 250 Ã— 32 was formed such that each row
was the measurement for a single time point across all electrodes. Moreover, as we have
assumed that the mean of the process is zero, the data can be centred by subtracting the
sample mean vector of the ERP values at each electrode from every time point. This is a
standard practice to estimate the mean, and is performed to ensure that results will not
be aï¬€ected if the true mean is signiï¬cantly diï¬€erent from zero. Prior speciï¬cations for a
and Ïƒ2 were maintained from the previous section.
A valid question to ask at this stage is what might be a sensible choice for p. In general,
we know that each A-matrix in a candidate set has dimension d Ã— d, and so contains d2
elements. Typically, by deï¬nition, the number of non-zeroes in any sparse matrix of such
size will be of order O(d). Suppose that we set p = 1 âˆ’1
d. Then, using (4.4), the number
of non-zeroes present will follow a binomial distribution with parameters d2, the number
of trials, and 1 âˆ’p = 1
d, the success probability. Moreover, it follows from Johnson et al.
(1992) that this distribution has expected value equal to d, which is clearly of the required
order. Hence, p = 1 âˆ’1
d is a general speciï¬cation that induces the correct level of sparsity
for every A-matrix a priori.
143

4.3. Random walks
Figure 4.14: Animal ERP data for one subject
1 
2 
3  
4  
5  
6  
7  
8  
9  
10  
11  
12  
13  
14  
15  
16  
17  
18  
19 
20 
21 
22 
23 
24 
25 
26  
27   
28
29
30 
31 
32  
âˆ’52.2
+52.2
âˆ’1000
1996
144

4.3. Random walks
Figure 4.15: Distractor ERP data for one subject
1 
2 
3  
4  
5  
6  
7  
8  
9  
10  
11  
12  
13  
14  
15  
16  
17  
18  
19 
20 
21 
22 
23 
24 
25 
26  
27   
28
29
30 
31 
32  
âˆ’85
+85
âˆ’1000
1996
145

4.3. Random walks
So, in the current scenario, we let p = 31
32. Then, the MCMC scheme was run for both
datasets for 10, 000, 000 iterations, with the same burn-in period, thinning interval and
choice of G0 as used previously. The output for the animal and distractor data is shown
in Figures 4.16 and 4.17 respectively. In each case, the trace plot indicates that the chain
is mixing reasonably well, although slower than has been seen in previous examples. This
is a consequence of fewer proposed moves being accepted. Moreover, the ACF plots reveal
that the autocorrelation only reduces to approximately zero by lag 100. Of course, it is
now beneï¬cial to apply our convergence diagnostics. For the animal data, using CODA, the
test of Raftery-Lewis yielded
Iterations = 1:9900
Thinning interval = 1
Number of chains = 1
Sample size per chain = 9900
Quantile (q) = 0.025
Accuracy (r) = +/- 0.005
Probability (s) = 0.95
Burn-in
Total Lower bound
Dependence
(M)
(N)
(Nmin)
factor (I)
Lq
6
7800
3746
2.08
Moreover, Heidelberger-Welch produced the output
Stationarity start
p-value
test
iteration
Lq
passed
1
0.558
Halfwidth Mean
Halfwidth
test
Lq
passed
-31934 0.798
Likewise, the Raftery-Lewis diagnostic for the chain that arose from the distractor data
supplied the following:
Iterations = 1:9900
Thinning interval = 1
Number of chains = 1
146

4.3. Random walks
0
2000
4000
6000
8000
10000
âˆ’31960
âˆ’31940
âˆ’31920
Trace plot of L(q)
Iteration
L(q)
0
20
40
60
80
100
0.2
0.4
0.6
0.8
1.0
Lag
ACF
ACF plot for L(q)
Histogram of L(q)
L(q)
Frequency
âˆ’31970
âˆ’31960
âˆ’31950
âˆ’31940
âˆ’31930
âˆ’31920
âˆ’31910
0
200
400
600
800
1000
0
5
10
15
20
25
30
0
5
10
15
20
25
30
Image plot for Pihat
Row
Col
Figure 4.16: Plots for the analysis of the MCMC output for the animal ERP data
147

4.3. Random walks
0
2000
4000
6000
8000
10000
âˆ’31720
âˆ’31700
âˆ’31680
Trace plot of L(q)
Iteration
L(q)
0
20
40
60
80
100
0.2
0.4
0.6
0.8
1.0
Lag
ACF
ACF plot for L(q)
Histogram of L(q)
L(q)
Frequency
âˆ’31730
âˆ’31720
âˆ’31710
âˆ’31700
âˆ’31690
âˆ’31680
âˆ’31670
0
200
400
600
800
0
5
10
15
20
25
30
0
5
10
15
20
25
30
Image plot for Pihat
Row
Col
Figure 4.17: Plots for the analysis of the MCMC output for the distractor ERP data
148

4.3. Random walks
Sample size per chain = 9900
Quantile (q) = 0.025
Accuracy (r) = +/- 0.005
Probability (s) = 0.95
Burn-in
Total Lower bound
Dependence
(M)
(N)
(Nmin)
factor (I)
Lq
10
10996
3746
2.94
Meanwhile, the results of Heidelberger-Welch in this case were
Stationarity start
p-value
test
iteration
Lq
passed
1
0.143
Halfwidth Mean
Halfwidth
test
Lq
passed
-31692 1.23
So, these diagnostics still oï¬€er good evidence of convergence to the respective stationary
distributions in each case. We note however that, due to the slower movement of these
chains than before, a longer MCMC run must be used to produce better coverage of
the graphical space, and hence more independent chain values. Along with additional
thinning, this would improve the trace and ACF plots in Figures 4.16 and 4.17.
We now compare the two image plots for the datasets. Here, the axes on these plots
correspond to the respective, numbered electrodes, as pictured on Figures 4.14 and 4.15.
It is clear that these graphs are quite similar. For instance, when examining the main
diagonals, it follows that many nodes have analogous self-loops, and moreover, several
common links are discovered elsewhere. An intriguing feature seen in both cases is however
that not all nodes possess a self-loop. From Chapter 3, this implies that, on the time series
graph, an electrode i at time t âˆ’1 will not cause a reaction in the same electrode at the
next time point t, but instead, stimulate other electrodes on the scalp.
In both cases, it is interesting that many electrodes regularly activate a response in elec-
149

4.3. Random walks
trodes 24 and 29 that are, independently, in reasonable proximity to these nodes. In fact,
the converse is true of electrodes 2 and 14 that act as inï¬‚uencing nodes. Unsurprisingly,
diï¬€erences can be spotted. For the distractor data, numerous edges are widespread be-
tween medium and high-numbered electrodes in both directions (as displayed above and
below the main diagonal). Additionally, in the animal case, electrode 4 is stimulated
less frequently whereas electrode 20 has reduced aï¬€ect over other electrodes. However,
in general, we conclude that, upon display of either a target or non-target image, the
cerebral processing of the stimulus is reasonably consistent.
Finally, we can contrast the approximate posterior distributions for aij, where again i, j =
1, 2, 3, for the animal data (Figure 4.18) and distractor data (Figure 4.19). In both cases,
we can suggest conï¬dently that a13, a21, a23 and a31 are all zero in the true speciï¬cation
of A, since Pvar(aij = 0 | D) is extremely high for these coeï¬ƒcients. The most captivating
plot is that for a32. At ï¬rst glance, we realise that Pvar(a32 = 0 | D) â‰ˆ1 for the two
datasets. Yet, despite this, pvar(a32 | a32 Ì¸= 0, D) takes values that are somewhat distinct
from zero. A simple explanation for this is that very few non-zero values of a32 were
discovered during the MCMC run (as we are extremely certain that this coeï¬ƒcient is
zero). Hence, little weight is given to this density, and so a slight perturbation in the
variational approximation will produce this imprecision.
All other coeï¬ƒcients plotted
would appear to be non-zero signals, and the mode values of the corresponding non-zero
densities between datasets are most alike.
It is also noticeable that, upon close inspection, some of these densities for each dataset
consist of a mixture of components, and thus are multimodal. We have established pre-
viously that any node yj causes a ï¬xed yi on an A-graph at each MCMC iteration if the
element aij, for j = 1, . . ., d, is non-zero. That is, our attention is on the i-th row of A.
Then, the models accepted throughout the sampler will reveal that each yi can be aï¬€ected
by several nodes to varying degrees; the cumulative eï¬€ect of this is shown in each image
plot.
150

4.3. Random walks
In fact, during the scheme, many diï¬€erent combinations of edges from nodes yj can
inï¬‚uence yi for numerous j, hence aï¬€ecting the non-zero value of a particular aik. So,
an intuitive explanation for these multimodal plots is that each peak is a consequence
of one such combination.
Moreover, the highest peak corresponds to the most likely
combination, i.e. that which occurs most regularly in the MCMC run. Similarly, the
next highest peak will arise from the second most plausible combination, and so on.
This feature is intriguing since it was not observed in any previous examples that used
simulated data. To understand this, we realise that the ERP datasets possess a more
complicated structure whereby, judging from each image plot in Figures 4.16 and 4.17,
many edges exist between diï¬€erent nodes.
Value
0
9
18
27
36
45
0
0.4
0.8
1.2
Density
0
0.2
0.4
0.6
0.8
1
Probability
Value
0
4
8
12
16
20
âˆ’0.2
0.2
0.6
1
Density
0
0.2
0.4
0.6
0.8
1
Probability
Value
0
9
18
27
36
45
âˆ’0.4
0
0.4
0.8
Density
0
0.2
0.6
1
Probability
Value
0
9
18
27
36
45
âˆ’0.4
0
0.4
0.8
Density
0
0.2
0.4
0.6
0.8
1
Probability
Value
0
5
10
15
20
25
0
0.4
0.8
1.2
Density
0
0.2
0.6
1
Probability
Value
0
11
22
33
44
55
âˆ’0.4
0
0.4
0.8
Density
0
0.2
0.4
0.6
0.8
1
Probability
Value
0
4
8
12
16
20
âˆ’0.4
0
0.4
0.8
Density
0
0.2
0.6
1
Probability
Value
0
2.8
5.6
8.4
14
âˆ’0.6
âˆ’0.2
0.2
0.6
Density
0
0.2
0.4
0.6
0.8
1
Probability
Value
0
4
8
12
16
20
0
0.4
0.8
1.2
Density
0
0.2
0.6
1
Probability
a11
a12
a13
a21
a22
a23
a31
a32
a33
Figure 4.18: Plots showing estimated, marginal posterior distributions for aij, i, j =
1, 2, 3, for the animal ERP data
151

4.3. Random walks
Value
0
8
16
24
32
0
0.4
0.8
1.2
Density
0
0.2
0.4
0.6
0.8
Probability
Value
0
4
8
12
16
20
âˆ’0.2
0.2
0.6
1
Density
0
0.2
0.6
1
Probability
Value
0
8
16
24
32
40
âˆ’0.4
0
0.4
0.8
Density
0
0.2
0.4
0.6
0.8
1
Probability
Value
0
8
16
24
32
40
âˆ’0.4
0
0.4
0.8
Density
0
0.2
0.6
1
Probability
Value
0
6
12
18
24
30
0
0.4
0.8
1.2
Density
0
0.2
0.4
0.6
0.8
1
Probability
Value
0
9
18
27
36
45
âˆ’0.4
0
0.4
0.8
Density
0
0.2
0.6
1
Probability
Value
0
4
8
12
16
20
âˆ’0.4
0
0.4
0.8
Density
0
0.2
0.6
1
Probability
Value
0
1.7
3.4
5.1
6.8
8.5
âˆ’0.6
âˆ’0.2
0.2
0.6
Density
0
0.2
0.4
0.6
0.8
1
Probability
Value
0
4
8
12
16
20
0
0.4
0.8
1.2
Density
0
0.2
0.6
1
Probability
a11
a12
a13
a21
a22
a23
a31
a32
a33
Figure 4.19: Plots showing estimated, marginal posterior distributions for aij, i, j =
1, 2, 3, for the distractor ERP data
4.3.7
Application to microarray data
Finally, we wish to determine a graphical structure for a set of microarray time series
data. A study of gene expression was conducted in the gram-positive bacterium Bacillus
subtilis whereby d = 9 genes are believed to aï¬€ect the organismâ€™s decision on whether to
sporulate. Hence, the levels of mRNA are measured for each gene at N = 40 time points.
For the purposes of understanding the subsequent image plot, a number is assigned to
every gene, as shown in Table 4.4. As before, the data was centred by subtracting the
sample mean at every time point, and modelled with a zero mean VAR(1) process with
unknown A and Ïƒ2. The optimum sparsity level is now given as p = 8
9, whilst all other
speciï¬cations are preserved.
152

4.3. Random walks
Number
1
2
3
4
5
6
7
8
9
Gene
spo0A
sda
kinA
lexA
dnaA
spoIIAA
clpP
spo0F
spo0B
Table 4.4: Genes examined in the microarray experiment
Figure 4.20 reveals the results of the MCMC run for this dataset.
0
2000
4000
6000
8000
10000
âˆ’890
âˆ’885
âˆ’880
âˆ’875
Trace plot of L(q)
Iteration
L(q)
0
20
40
60
80
100
0.0
0.2
0.4
0.6
0.8
1.0
Lag
ACF
ACF plot for L(q)
Histogram of L(q)
L(q)
Frequency
âˆ’895
âˆ’890
âˆ’885
âˆ’880
âˆ’875
0
500
1000
1500
0
1
2
3
4
5
6
7
8
9
0
1
2
3
4
5
6
7
8
9
Image plot for Pihat
Row
Col
Figure 4.20: Plots for the analysis of the MCMC output for the microarray data
On this occasion, excellent evidence for convergence is displayed by both the trace and
ACF plots. This is ampliï¬ed by the output of the usual diagnostics. For completeness,
Raftery-Lewis returned
Iterations = 1:9900
Thinning interval = 1
Number of chains = 1
Sample size per chain = 9900
153

4.3. Random walks
Quantile (q) = 0.025
Accuracy (r) = +/- 0.005
Probability (s) = 0.95
Burn-in
Total Lower bound
Dependence
(M)
(N)
(Nmin)
factor (I)
Lq
1
3748
3746
1
whereas Heidelberger-Welch issued
Stationarity start
p-value
test
iteration
Lq
passed
1
0.215
Halfwidth Mean
Halfwidth
test
Lq
passed
-878
0.05
To interpret the image plot, we refer back to Table 4.4.
It follows that many genes
stimulate a response in the same gene at consecutive time points, although this is not
the case for gene kinA. Moreover, lexA seems to be rather insigniï¬cant in the decision
making process. Two clear links are spotted between diï¬€erent genes in the study, namely
the inï¬‚uence of spoIIAA over spo0B and the reaction caused by kinA in spo0F.
Variational posterior summaries for a set of aij are provided in Figure 4.21. It appears
that only a11 and a22 are true signals since the estimate of P(aij = 0 | D) for all other
coeï¬ƒcients is approximately equal to 1. Yet, despite this, these latter entries often possess
a plot of pvar(aij | aij Ì¸= 0, D) that is peaked away from zero. This is merely a consequence
of the size of the dataset â€” if N was increased, we would anticipate, from previous
experience, greater precision in these densities. It is also observed that the likely values
of a11 and a22 are in close proximity.
154

4.4. Summary
Value
0
0.6
1.2
1.8
2.4
3
0
0.4
0.8
1.2
Density
0
0.2
0.4
0.6
0.8
1
Probability
Value
0
0.55
1.65
2.75
âˆ’0.4
0
0.4
0.8
Density
0
0.2
0.4
0.6
0.8
1
Probability
Value
0
0.24
0.72
1.2
âˆ’0.4
0
0.4
0.8
1.2
Density
0
0.2
0.4
0.6
0.8
1
Probability
Value
0
0.65
1.95
3.25
âˆ’0.5
âˆ’0.1
0.3
0.7
Density
0
0.2
0.6
1
Probability
Value
0
0.7
1.4
2.1
2.8
3.5
0
0.4
0.8
1.2
Density
0
0.2
0.4
0.6
0.8
1
Probability
Value
0
0.55
1.65
2.75
âˆ’0.8
âˆ’0.4
0
0.4
Density
0
0.2
0.4
0.6
0.8
1
Probability
Value
0
0.95
2.85
4.75
âˆ’0.6
âˆ’0.2
0.2
0.6
Density
0
0.2
0.4
0.6
0.8
1
Probability
Value
0
0.9
1.8
2.7
3.6
4.5
âˆ’0.4
0
0.4
0.8
Density
0
0.2
0.4
0.6
0.8
1
Probability
Value
0
0.55
1.65
2.75
âˆ’0.5
âˆ’0.1
0.3
0.7
Density
0
0.2
0.6
1
Probability
a11
a12
a13
a21
a22
a23
a31
a32
a33
Figure 4.21: Plots showing estimated, marginal posterior distributions for aij, i, j =
1, 2, 3, for the microarray data
4.4
Summary
In this chapter, our main focus was to develop a procedure by which graphical spaces
of increasing dimension could be searched, rapidly and eï¬€ectively, to locate high ranking
models. Moreover, we wished to explore the posterior distribution on model space. A
Metropolis-Hastings algorithm was constructed whereby, at each iteration, a new model
was proposed uniformly, and then accepted on the basis of an acceptance probability.
This probability, Î±(Â·, Â·), was itself dependent on the lower bound approximation to the
logarithm of the marginal likelihood for each model, derived by variational Bayes.
A
matrix Ë†Î  was constructed to count the number of occasions that an edge between any pair
of nodes was included in the accepted model at each iteration. The algorithm was applied
155

4.4. Summary
to a variety of simulated examples where, inter alia, the prior probability p = P(aij = 0)
was altered. Throughout, the true sparsity structure of A was identiï¬ed with impressive
accuracy.
It was also possible to determine an approximate, marginal posterior distribution for each
aij across models. That is, we were able to display graphically the probability that a
particular aij was zero, and the probable magnitude of aij, given that it was non-zero.
For the simulated data, it was feasible to ascertain which aij were actually signals, and,
in that case, estimate their true values precisely. Finally, the MCMC scheme was applied
to two real cases, namely a set of ERP and microarray data. For the former, we con-
cluded that there are many similarities in processing the visual information when correctly
recognising either an animal or distractor photograph, a decision made in equivalent brain
areas. Moreover, in the latter, a gene network was identiï¬ed, regarding the decision of a
bacterium to sporulate. In the next chapter, the ideas presented here, and in Chapter 3,
are extended, so that the variational Bayesian treatment is provided to VAR(1) models
that are no-longer assumed to have zero mean.
156

Chapter 5
Generalisation to non-zero mean
VAR(1) models
5.1
Introduction
In Chapter 3, a candidate set of VAR(1) graphical models was constructed, each reliant
upon the diï¬€ering sparsity structure of the autoregressive matrix A. The evidence for
each model, given by the corresponding marginal likelihood, was approximated using the
variational Bayesian algorithm. Hence, it was possible to determine the more plausible
models in the set.
Recall that, in general, a VAR(1) model of dimension d is speciï¬ed as
yt = ytâˆ’1A + et,
with the noise vector et âˆ¼N (0, Î“). However, alternatively, the model can be rewritten
157

5.2. Scoring non-zero mean VAR(1) models
in mean-adjusted form (LÂ¨utkepohl, 2005) such that
yt âˆ’Î¼ = (ytâˆ’1 âˆ’Î¼)A + et,
(5.1)
whereby Î¼ = (Î¼1, Î¼2, . . . , Î¼d) = E(yt) for all t, a (1Ã—d) vector, and the noise is distributed
as before. All other dimensions are as previous. (5.1) is now classiï¬ed as the non-zero
mean VAR(1) model.
Of course, as LÂ¨utkepohl informs us, this generalisation can be
extended further to the VAR(p) process.
Therefore, using again the graphical representation of the sparse matrix A, we can conduct
a similar procedure to that of Chapter 3 by applying the variational algorithm to derive
a lower bound, LMi(qi), for each graphical model Mi, an approximation to the logarithm
of the corresponding marginal likelihood for each model, p({yt} | Mi).
Consequently,
by ranking models, we seek primarily to learn the sparsity structure of A.
However,
analysis is now complicated since, by model (5.1), the parameter set is now deï¬ned as
Î¸ = {A, Ïƒ2, Î¼}. Here, as erstwhile, we let the covariance matrix of the noise vector be
Î“ = Ïƒ2Id for ease of prior speciï¬cation. Thus, by the deï¬nition of the lower bound (2.6),
we extend previous work by now placing a further prior on Î¼, and subsequently deducing
an additional variational distribution for this parameter. Henceforth, conditioning and
dependence on Mi is assumed throughout, although not expressed explicitly.
5.2
Scoring non-zero mean VAR(1) models
Suppose that t = 1, . . ., N independent samples of the time series have been collected.
Initially, by rewriting (5.1) as a matrix equation, we derive an expression for the data
likelihood. Deï¬ne Y , X and E, with the same dimension, as in Section 3.3, whereby
xt = [ytâˆ’1] for all t. Moreover, let M be a N Ã— d matrix, with each row of M given by
158

5.2. Scoring non-zero mean VAR(1) models
the vector Î¼. Thus, we designate (5.1) in matrix form as
Y âˆ’M = [X âˆ’M]A + E.
(5.2)
At the end-points, we again allow xN = yNâˆ’1.
Moreover, we assume the process is
initialised such that x1 = y0 = Î¼. As E(yt) = Î¼ for all t, this is, by deï¬nition, the
stationary mean. Recall that this value exists if all eigenvalues of A have modulus less
than 1, hence the VAR(1) process is referred to as stable.
Now, decompose (5.2) into vector form such that
vec(Y âˆ’M) = vec([X âˆ’M]A + E)
=â‡’vec(Y ) âˆ’vec(M) = vec(XA) âˆ’vec(MA) + vec(E)
=â‡’y âˆ’m = (Id âŠ—X)a âˆ’(Id âŠ—M)a + e,
(5.3)
using the same results as in Section 3.3. Moreover, let vec(M) = m, a dN Ã—1 vector, and
allow all other deï¬nitions as before. Determination of the probability density function for
e is exactly as before since, again, et âˆ¼N (0, Ïƒ2Id). Consequently, e âˆ¼N (0, Id âŠ—Ïƒ2IN).
Hence, we can rearrange (5.3) in terms of e, and substitute into the probability density
function of e, (3.6). The exponent of this expression is then
exp

âˆ’1
2eT(Id âŠ—Ïƒâˆ’2IN)e

= exp

âˆ’1
2 [y âˆ’m âˆ’(Id âŠ—X)a + (Id âŠ—M)a]T (Id âŠ—Ïƒâˆ’2IN)
Ã— [y âˆ’m âˆ’(Id âŠ—X)a + (Id âŠ—M)a]

= exp

âˆ’1
2 [vec(Y âˆ’M âˆ’[X âˆ’M]A)]T (Id âŠ—Ïƒâˆ’2IN) [vec(Y âˆ’M âˆ’[X âˆ’M]A)]

= exp

âˆ’1
2Tr
$
Ïƒâˆ’2g(A, M)
%
,
(5.4)
159

5.2. Scoring non-zero mean VAR(1) models
where g(A, M) = (Y âˆ’M âˆ’[X âˆ’M]A)T(Y âˆ’M âˆ’[X âˆ’M]A), a d Ã— d matrix and using
corresponding results. Resultantly, given a data-set D = {X, Y }, the probability of the
data is such that
p(D |A, Ïƒ2, Î¼) = (2Ï€Ïƒ2)âˆ’dN
2 exp

âˆ’1
2Tr
$
Ïƒâˆ’2g(A, M)
%
.
(5.5)
5.2.1
Priors
As mentioned in Section 5.1, we must denote priors over, not only a = vec(A) and Ïƒ2 as
before, but also Î¼. Therefore, the speciï¬cations are
p(a) = N (a | 0, Câˆ—)
(5.6)
p(Ïƒ2) = IG(Ïƒ2 | Î±, Î²)
(5.7)
p(Î¼) = N (Î¼ | b, Î”).
(5.8)
There is no motivation to change the priors on both a and Ïƒ2, and so these are maintained
from Section 3.3.1. Again, we deï¬ne Câˆ—= diag {vec(C)}, where C is indicated by equation
(3.11). We realise that Câˆ—can be rank deï¬cient, hence creating problems in later analysis.
Thus, the sparsity structure on A is retained in the prior by constraining C. The prior
on Î¼ was chosen since the multivariate normal distribution is the typical conjugate choice
for the unknown mean vector of a normal random sample. Of course, these speciï¬cations
are assumed to be independent such that p(a, Ïƒ2, Î¼) = p(a)p(Ïƒ2)p(Î¼).
5.2.2
Free form method
When considering non-zero mean VAR(1) models, the variational distributions, which
approximate each true posterior, are here deï¬ned to be q(a | D), q(Ïƒ2 | D) and q(Î¼ | D).
160

5.2. Scoring non-zero mean VAR(1) models
We continue by applying the same procedure as in Chapter 3.
That is, a free form
variational method is implemented initially to derive the variationals for Ïƒ2, Î¼ and a
respectively in the dense case. Furthermore, a ï¬xed form technique is then employed
to calculate the lower bound and, more importantly, to constrain as a result of a given
sparsity structure.
From a free form approach, we only assume independence between the variational distri-
butions, i.e. q(a, Ïƒ2, Î¼ | D) = q(a | D) q(Ïƒ2 | D) q(Î¼| D). This is an approximation since
a, Ïƒ2 and Î¼ are not a posteriori independent. This was seen previously for zero mean
VAR(1) models, and hence still holds in the more advanced situation here.
By deï¬nition, the lower bound is speciï¬ed as
LÎ¼(q) =

q(a, Ïƒ2, Î¼ | D) log
	p(D | A, Ïƒ2, Î¼) p(a, Ïƒ2, Î¼)
q(a, Ïƒ2, Î¼ | D)

da dÏƒ2 dÎ¼,
(5.9)
where the subscript Î¼ on L(q) represents the non-zero mean model. As seen formerly, this
equation can be rewritten as a sum of integrals using the independence of the distributions
involved, and simpliï¬ed further by integrating out parameters when necessary. Hence, by
recombining integrals, we can denote LÎ¼(q) as a functional of q(a | D), q(Ïƒ2 | D) and
q(Î¼ | D). These are given respectively by equations (5.10), (5.11) and (5.12) below.
LÎ¼(q) =

q(a | D)
	 
q(Ïƒ2 | D) q(Î¼ | D) log p(D | A, Ïƒ2, Î¼) dÏƒ2 dÎ¼
+ log p(a) âˆ’log q(a | D)

da + const.
(5.10)
LÎ¼(q) =

q(Ïƒ2 | D)
	 
q(a | D) q(Î¼ | D) log p(D | A, Ïƒ2, Î¼) da dÎ¼
+ log p(Ïƒ2) âˆ’log q(Ïƒ2 | D)

dÏƒ2 + const.
(5.11)
LÎ¼(q) =

q(Î¼ | D)
	 
q(a | D) q(Ïƒ2 | D) log p(D | A, Ïƒ2, Î¼) da dÏƒ2
+ log p(Î¼) âˆ’log q(Î¼ | D)

dÎ¼ + const.
(5.12)
161

5.2. Scoring non-zero mean VAR(1) models
We shall tackle each of these integrals. Examine ï¬rst (5.11). In this equation, we can
substitute for both log p(D | A, Ïƒ2, Î¼) and log p(Ïƒ2). Upon comparison, we notice the
similarity between (3.15) and (5.11), the functionals of q(Ïƒ2 | D) in both the zero and
non-zero mean cases. Moreover, as the prior on Ïƒ2 is identical and the data likelihood of
similar form to the zero mean circumstance, by dropping terms independent of Ïƒ2 which
disappear upon diï¬€erentiation with respect to q(Ïƒ2 | D), we will arrive at an expression
that is akin to (3.16). Thus, we acquire
LÎ¼(q) =

q(Ïƒ2 | D)
	
âˆ’dN
2 log Ïƒ2 âˆ’(Ïƒ2)âˆ’1
2

q(a | D) q(Î¼| D) {Tr [g(A, M)]} da dÎ¼
âˆ’(Î± + 1) log Ïƒ2 âˆ’Î²(Ïƒ2)âˆ’1 âˆ’log q(Ïƒ2 | D)

dÏƒ2 + const.â€²
(5.13)
Now notice, by the deï¬nition of g(A, M) and the derivation of (5.3), that,
Tr [g(A, M)] = [vec(Y âˆ’M âˆ’[X âˆ’M]A)]T [vec(Y âˆ’M âˆ’[X âˆ’M]A)]
= [y âˆ’m âˆ’(Id âŠ—X)a + (Id âŠ—M)a]T [y âˆ’m âˆ’(Id âŠ—X)a + (Id âŠ—M)a]
(5.14)
=: h(a, M),
again using identity (3.18), and deï¬ning the function h to ease the algebra. Hence, we
take the expectation of this expression with respect to the variational distributions for
both a and Î¼. Thus, we compute
Eq(a | D)

Eq(Î¼ | D) {Tr [g(A, M)]}

= yTy âˆ’[vec(Î©)]T y âˆ’ÏT(Id âŠ—XT)y + ÏT(Id âŠ—Î©T)y âˆ’yTvec(Î©)
+ Eq(Î¼| D){mT}Eq(Î¼| D){m} + Tr[Varq(Î¼| D){m}] + ÏT(Id âŠ—XT)vec(Î©)
âˆ’ÏTEq(Î¼ | D)

vec(MTM)

âˆ’yT(Id âŠ—X)Ï + [vec(Î©)]T (Id âŠ—X)Ï
+ Eq(a | D){aT}(Id âŠ—XTX)Eq(a | D){a} + Tr[(Id âŠ—XTX)Varq(a | D){a}]
162

5.2. Scoring non-zero mean VAR(1) models
âˆ’Eq(a | D){aT}(Id âŠ—Î©TX)Eq(a | D){a} âˆ’Tr[(Id âŠ—Î©TX)Varq(a | D){a}] + yT(Id âŠ—Î©)Ï
âˆ’Eq(Î¼ | D)

$
vec(MTM)
%T
Ï âˆ’Eq(a | D){aT}(Id âŠ—XTÎ©)Eq(a | D){a}
âˆ’Tr[(Id âŠ—XTÎ©)Varq(a | D){a}] + Eq(a | D)

aT 
Id âŠ—Eq(Î¼| D){MTM}

a

.
(5.15)
Here, we deï¬ne Ï = Eq(a | D) {a} as before. In addition, let Eq(Î¼| D){Î¼} = Ï‰ and, moreover,
Eq(Î¼| D){M} = Î©. That is, by construction of M, Î© is the NÃ—d matrix with each row equal
to the d-vector Ï‰. Furthermore, Eq(Î¼| D){m} = vec(Eq(Î¼| D){M}) = vec(Î©). To derive
(5.15), the identities (3.20) and (2.51), used at the corresponding stage in Chapter 3, have
been applied, and moreover (3.5) (by setting P = MT, Q = M). We also realise that
Eq(Î¼| D){IdâŠ—M} = IdâŠ—Eq(Î¼| D){M} since IdâŠ—M is merely the block diagonal matrix where
each block is equivalent to M. Taking expectations here is simpliï¬ed by the variational a
posteriori independence between a and Î¼.
We now account for the other terms in (5.15).
As erstwhile, let Ï„ = Varq(a | D) {a}.
Moreover, deï¬ne Varq(Î¼| D){Î¼} = Î› and Varq(Î¼| D){m} = Îž. In the above expression,
we must ï¬nd Tr[Îž]. However, as m = (Î¼1, Î¼1, . . . , Î¼1, Î¼2, Î¼2, . . . , Î¼2, . . . , Î¼d, Î¼d, . . . Î¼d)T,
with each component repeated N times by deï¬nition, it follows that
Tr[Îž] = N(Varq(Î¼| D){Î¼1} + Varq(Î¼| D){Î¼2} + Â· Â· Â· + Varq(Î¼| D){Î¼d})
= N Tr[Varq(Î¼| D){Î¼}]
= N Tr[Î›].
(5.16)
We now endeavour to ï¬nd Eq(Î¼| D)

vec(MTM)

= vec

Eq(Î¼ | D)

MTM

. It helps to
inspect this problem in component form. So, let M = (mij) such that MT = (mji).
Then, by deï¬nition of matrix multiplication,
[MTM]ij =
N

k=1
mkimkj =
N

k=1
Î¼iÎ¼j = NÎ¼iÎ¼j,
163

5.2. Scoring non-zero mean VAR(1) models
since each element of the j-th column of M is Î¼j. The expectation of this expression with
respect to q(Î¼ | D) is now taken. Thus,
Eq(Î¼| D){[MTM]ij} = N Eq(Î¼ | D){Î¼iÎ¼j}
= N Eq(Î¼ | D){Î¼i}Eq(Î¼| D){Î¼j} + NCovq(Î¼| D){Î¼i, Î¼j}
=
N

k=1
Eq(Î¼| D){mki}Eq(Î¼| D){mkj} + N
$
Varq(Î¼| D){Î¼}
%
ij
=
$
Eq(Î¼| D){MT}Eq(Î¼ | D){M}
%
ij + N
$
Varq(Î¼| D){Î¼}
%
ij ,
using the deï¬nition of covariance. Consequently, by removing subscripts and returning to
matrix form, we obtain the identity
Eq(Î¼| D){MTM} = Î©TÎ© + NÎ›,
(5.17)
and hence Eq(Î¼ | D)

vec(MTM)

= vec(Î©TÎ©) + Nvec(Î›). As a result, the ï¬nal term of
(5.15) is now equal to
Eq(a | D)

aT 
Id âŠ—Eq(Î¼ | D){MTM}

a

= Eq(a | D)

aT 
Id âŠ—[Î©TÎ© + NÎ›]

Eq(a | D) {a} + Tr[

Id âŠ—[Î©TÎ© + NÎ›]

Varq(a | D){a}]
= ÏT 
Id âŠ—[Î©TÎ© + NÎ›]

Ï + Tr[

Id âŠ—[Î©TÎ© + NÎ›]

Ï„].
By (5.14), the expression (5.15) can be simpliï¬ed somewhat. In fact, we reach
Eq(a | D)

Eq(Î¼| D) {Tr [g(A, M)]}

= h(Ï, Î©) + N Tr[Î›] âˆ’NÏTvec(Î›) + Tr[(Id âŠ—XTX)Ï„] âˆ’Tr[(Id âŠ—Î©TX)Ï„]
âˆ’N[vec(Î›)]TÏ âˆ’Tr[(Id âŠ—XTÎ©)Ï„] + NÏT(Id âŠ—Î›)Ï
+ Tr[(Id âŠ—Î©TÎ©)Ï„] + N Tr[(Id âŠ—Î›)Ï„]
164

5.2. Scoring non-zero mean VAR(1) models
= h(Ï, Î©) + N Tr[Î›] + NÏT [(Id âŠ—Î›)Ï âˆ’2vec(Î›)]
+ Tr
$
Id âŠ—
$
(X âˆ’Î©)T(X âˆ’Î©) + NÎ›
%
Ï„
%
=: h(Ï, Î©) + j(Ï, Ï„, Î©, Î›),
(5.18)
introducing a further function j to simplify notation. Now, substitute (5.18) into (5.13)
so that the latter is now independent of a and Î¼. As in Section 3.3.2, we use the Lagrange
multiplier Î½Ïƒ2 to construct the functional ËœLÎ¼(q) (c.f. (3.21)). Maximising this functional
with respect to q(Ïƒ2 | D) then provides
âˆ‚ËœLÎ¼(q)
âˆ‚q(Ïƒ2 | D) = âˆ’dN
2 log Ïƒ2 âˆ’(Ïƒ2)âˆ’1
2
[h(Ï, Î©) + j(Ï, Ï„, Î©, Î›)]
âˆ’(Î± + 1) log Ïƒ2 âˆ’Î²(Ïƒ2)âˆ’1 âˆ’log q(Ïƒ2 | D) âˆ’1 + Î½Ïƒ2 = 0.
When comparing this expression with the zero mean case, it is clear that
q(Ïƒ2 | D) âˆ(Ïƒ2)âˆ’(Î±+ dN
2 +1) exp

âˆ’(Ïƒ2)âˆ’1

Î² + 1
2 [h(Ï, Î©) + j(Ï, Ï„, Î©, Î›)]

.
Therefore, using the same notation as before, we can easily see that, as in Chapter 3,
q(Ïƒ2 | D) = IG(Ïƒ2 | Î³, Î´),
(5.19)
but now with variational parameters speciï¬ed as
Î³ = Î± + dN
2
(5.20)
Î´ = Î² + 1
2 [h(Ï, Î©) + j(Ï, Ï„, Î©, Î›)] ,
(5.21)
165

5.2. Scoring non-zero mean VAR(1) models
whereby
h(Ï, Î©) = [y âˆ’vec(Î©) âˆ’(Id âŠ—X)Ï + (Id âŠ—Î©)Ï]T
Ã— [y âˆ’vec(Î©) âˆ’(Id âŠ—X)Ï + (Id âŠ—Î©)Ï]
(5.22)
j(Ï, Ï„, Î©, Î›) = N Tr[Î›] + NÏT [(Id âŠ—Î›)Ï âˆ’2vec(Î›)]
+ Tr
$
Id âŠ—
$
(X âˆ’Î©)T(X âˆ’Î©) + NÎ›
%
Ï„
%
.
(5.23)
It is worth mentioning that the expression for Î³ is the same as that in the zero mean case.
That for Î´, however, is more complicated; yet, if the mean is equated to zero, then (5.21)
is equivalent to (3.24). We now reconsider (5.12), and ï¬nd the variational distribution for
Î¼. By substituting the likelihood and prior for Î¼, given by (5.8), this functional becomes
LÎ¼(q) =

q(Î¼ | D)
	 
q(a | D) q(Ïƒ2 | D)

âˆ’dN
2 log 2Ï€Ïƒ2
âˆ’1
2Tr
$
(Ïƒ2)âˆ’1g(A, M)
% 
da dÏƒ2 âˆ’d
2 log 2Ï€ âˆ’1
2 log |Î”|
âˆ’1
2(Î¼ âˆ’b)Î”âˆ’1(Î¼ âˆ’b)T âˆ’log q(Î¼ | D)

dÎ¼ + const.
Here, we show care when specifying the prior density since Î¼ is a row vector. By dropping
terms independent of Î¼, we then arrive at
LÎ¼(q) =

q(Î¼ | D)
	
âˆ’1
2

q(Ïƒ2 | D)(Ïƒ2)âˆ’1 dÏƒ2

q(a | D)Tr [g(A, M)] da
âˆ’1
2(Î¼ âˆ’b)Î”âˆ’1(Î¼ âˆ’b)T âˆ’log q(Î¼ | D)

dÎ¼ + const.â€²
(5.24)
This expression can be simpliï¬ed by the substitution of result (A.5). We now concentrate
on computing the expectation of Tr [g(A, M)] with respect to the variational distribution
q(a | D). To this end, Tr [g(A, M)] is expanded in a slightly diï¬€erent way to that seen
166

5.2. Scoring non-zero mean VAR(1) models
previously. That is, we can rewrite (5.14) as
Tr [g(A, M)] =
$
y âˆ’m âˆ’(Id âŠ—X)a + (AT âŠ—IN)m
%T
Ã—
$
y âˆ’m âˆ’(Id âŠ—X)a + (AT âŠ—IN)m
%
,
using the necessary identities of (3.5). This will aid greatly in later algebra simpliï¬cation.
Taking the afore-mentioned expectation of the above provides
Eq(a | D){Tr [g(A, M)]}
= yTy âˆ’mTy âˆ’ÏT(Id âŠ—XT)y + mT( Ë†A âŠ—IN)y âˆ’yTm + mTm + ÏT(Id âŠ—XT)m
âˆ’mT( Ë†A âŠ—IN)m âˆ’yT(Id âŠ—X)Ï + mT(Id âŠ—X)Ï
+ Eq(a | D){aT}(Id âŠ—XTX)Eq(a | D){a} + Tr[(Id âŠ—XTX)Varq(a | D){a}]
âˆ’Eq(a | D){mTvec(XAAT)} + yT( Ë†AT âŠ—IN)m âˆ’mT( Ë†AT âŠ—IN)m
âˆ’Eq(a | D)

$
vec(XAAT)
%T m

+ mT 
Eq(a | D){AAT} âŠ—IN

m.
(5.25)
In the above, we have made use of (3.20) and (2.51). Further, it is realised that
vec(PQR) = (RT âŠ—P)vec(Q)
(5.26)
for compatible matrices P, Q, R (Henderson and Searle, 1979). Moreover, we have deï¬ned
Eq(a | D){A} = Ë†A. As mentioned in Section 3.5, the dÃ—d matrix Ë†A is created by unstacking
the d2-vector Ï. So, if Ï = (Ï1, Ï2, . . . , Ïd2)T, then
Ë†A =
âŽ›
âŽœ
âŽœ
âŽœ
âŽœ
âŽœ
âŽœ
âŽœ
âŽ
Ï1
Ïd+1
Â· Â· Â·
Ïd(dâˆ’1)+1
Ï2
Ïd+2
Â· Â· Â·
Ïd(dâˆ’1)+2
...
...
...
...
Ïd
Ï2d
Â· Â· Â·
Ïd2
âŽž
âŽŸ
âŽŸ
âŽŸ
âŽŸ
âŽŸ
âŽŸ
âŽŸ
âŽ 
.
167

5.2. Scoring non-zero mean VAR(1) models
To enable this, we introduce the notation vecâˆ’1 to be the inverse vec operator, and hence
write Ë†A = vecâˆ’1
d (Ï), where the subscript d represents the number of rows in the new
matrix. Thus, the operator is deï¬ned such that this subscript must be a divisor of the
length of the vector, and can produce non-square matrices. Notice that, if P is any matrix
with r rows, it follows that vecâˆ’1
r [vec(P)] = P.
In (5.25), we now must ï¬nd Eq(a | D){AAT}. In particular, it is apparent that
Eq(a | D){mTvec(XAAT)} = mTvec(XEq(a | D){AAT}).
Again via component form, the
expectation of the (i, j)-th element of AAT, using the deï¬nition of matrix multiplication
and covariance, is seen to be
Eq(a | D){[AAT]ij} = Eq(a | D)

d

k=1
aikajk

=
d

k=1
Eq(a | D){aikajk}
=
d

k=1

Eq(a | D){aik}Eq(a | D){ajk} + Covq(a | D){aik, ajk}

=
$
Eq(a | D){A}Eq(a | D){AT}
%
ij +
d

k=1
$
Varq(a | D){Ak}
%
ij ,
(5.27)
where we deï¬ne Ak to be the k-th column vector of A. We can simplify this expres-
sion yet further by examining Varq(a | D){Ak}.
Suppose that the k-th column of Id is
denoted by ik, i.e. Id = (i1 | i2 | . . .| id). Then, it follows that Ak = Aik. We realise that
Varq(a | D) {vec(A)} = Ï„ by the deï¬nition of a. Consequently,
Varq(a | D){Ak} = Varq(a | D){Aik}
= Varq(a | D){vec(Aik)}
= Varq(a | D){(iT
k âŠ—Id)vec(A)}
= (iT
k âŠ—Id)Varq(a | D){vec(A)}(iT
k âŠ—Id)T
= (iT
k âŠ—Id)Ï„(ik âŠ—Id)
168

5.2. Scoring non-zero mean VAR(1) models
by (3.5), and since Var{Pw} = P Var{w}P T for any random vector w and ï¬xed matrix
P of suitable dimension. Moreover, for any vector r, it is clear that vec(r) = r. Hence,
substituting back into (5.27) and returning to matrix form provides
Eq(a | D){AAT} = Ë†A Ë†AT +
d

k=1
(iT
k âŠ—Id)Ï„(ik âŠ—Id)
= Ë†A Ë†AT + (1T
d âŠ—Id)Ï„(1d âŠ—Id),
(5.28)
where 1d is deï¬ned to be the vector of 1s of length d. Here, we notice the result
d

i=1
d

j=1
(iT
i âŠ—Id)Ï„(ij âŠ—Id) = (1T
d âŠ—Id)Ï„(1d âŠ—Id).
However, as Ï„ is diagonal, then (5.28) holds. All outstanding terms in (5.25) have now
been accounted for, and this expression in turn can be substituted into (5.24). Again, we
establish ËœLÎ¼(q) = LÎ¼(q) + Î½Î¼(

q(Î¼ | D) dÎ¼ âˆ’1), and diï¬€erentiate now with respect to
q(Î¼ | D). Accordingly, this leads to
âˆ‚ËœLÎ¼(q)
âˆ‚q(Î¼ | D) = âˆ’Î³
2Î´Eq(a | D){Tr [g(A, M)]} âˆ’1
2(Î¼ âˆ’b)Î”âˆ’1(Î¼ âˆ’b)T
âˆ’log q(Î¼ | D) âˆ’1 + Î½Î¼ = 0.
Upon rearranging and dropping all terms that are independent of Î¼, in particular those
within Eq(a | D){Tr [g(A, M)]}, we arrive at
q(Î¼ | D) âˆexp

âˆ’Î³
2Î´
	
mT

IdN âˆ’( Ë†A âŠ—IN) âˆ’( Ë†AT âŠ—IN) + ( Ë†A Ë†AT âŠ—IN)
+

(1T
d âŠ—Id)Ï„(1d âŠ—Id)

âŠ—IN
 
m
âˆ’mT

y âˆ’vec(Y Ë†AT) âˆ’vec(X Ë†A) + vec(X Ë†A Ë†AT) + vec

X(1T
d âŠ—Id)Ï„(1d âŠ—Id)

169

5.2. Scoring non-zero mean VAR(1) models
âˆ’

yT âˆ’

vec(Y Ë†AT)
T
âˆ’

vec(X Ë†A)
T
+

vec(X Ë†A Ë†AT)
T
+

vec

X(1T
d âŠ—Id)Ï„(1d âŠ—Id)
T 
m

âˆ’1
2(Î¼ âˆ’b)Î”âˆ’1(Î¼ âˆ’b)T

,
using (3.5) and that (P + Q) âŠ—R = (P âŠ—R) + (Q âŠ—R). This expression can be further
simpliï¬ed:
q(Î¼ | D) âˆexp

âˆ’Î³
2Î´
	
mT
 
Id âˆ’Ë†A
 
Id âˆ’Ë†A
T
+ (1T
d âŠ—Id)Ï„(1d âŠ—Id)

âŠ—IN

m
âˆ’mT

vec

Y âˆ’X Ë†A
 
Id âˆ’Ë†A
T
+ X(1T
d âŠ—Id)Ï„(1d âŠ—Id)
 
âˆ’
	
vec

Y âˆ’X Ë†A
 
Id âˆ’Ë†A
T
+ X(1T
d âŠ—Id)Ï„(1d âŠ—Id)
 T
m

âˆ’1
2(Î¼ âˆ’b)Î”âˆ’1(Î¼ âˆ’b)T

,
(5.29)
whereby y = vec(Y ) and Id âŠ—IN = IdN (Harville, 1997).
Here, there is an evident
problem.
We require a variational distribution for Î¼ whereas the expression above is
given predominantly in terms of m = vec(M). Recall that M is a matrix with each row
equivalent to Î¼. So, we need to manipulate such terms, in particular, those of the form
mTr and mTCm for a given dN-vector r and dN Ã— dN matrix C.
With regards to the former, notice that, by deï¬nition, m = Î¼T âŠ—1N, remembering that
Î¼ is a row vector. Thus, by introducing a N Ã— d matrix R such that R = vecâˆ’1
N (r), it
follows that
mTr = rTm = mTvec(R)
= (Î¼T âŠ—1N)Tvec(R)
= (Î¼ âŠ—1N
T)vec(R)
= vec(1N
TR Î¼T)
= 1N
TR Î¼T,
(5.30)
170

5.2. Scoring non-zero mean VAR(1) models
where (5.26) has been applied. On the other hand, we also realise that
mTCm = (Î¼T âŠ—1N)T C (Î¼T âŠ—1N)
= (Î¼ âŠ—1N
T) C (Î¼T âŠ—1N)
= (Î¼ âŠ—1)(Id âŠ—1N
T) C (Id âŠ—1N)(Î¼T âŠ—1)
= Î¼(Id âŠ—1N
T) C (Id âŠ—1N)Î¼T,
(5.31)
noting (3.20) and that P âŠ—z = zP for any matrix P and scalar z. Hence, we can utilise
(5.30) and (5.31) to ensure that each term of (5.29) is written in terms of Î¼. To eï¬€ect
this, we must be aware that 1N T1N = N. As a result, (5.29) can be expressed in the form
q(Î¼ | D) âˆexp

âˆ’1
2
$
Î¼Î¥Î¼T âˆ’Î˜Î¼T âˆ’Î¼Î˜T%
(5.32)
âˆexp

âˆ’1
2
$
(Î¼ âˆ’Î˜Î¥âˆ’1)Î¥(Î¼ âˆ’Î˜Î¥âˆ’1)T%
,
where we have
Î¥ = NÎ³
Î´

Id âˆ’Ë†A
 
Id âˆ’Ë†A
T
+ (1T
d âŠ—Id)Ï„(1d âŠ—Id)

+ Î”âˆ’1
(5.33)
Î˜ = Î³
Î´ 1N
T

Y âˆ’X Ë†A
 
Id âˆ’Ë†A
T
+ X(1T
d âŠ—Id)Ï„(1d âŠ—Id)

+ bÎ”âˆ’1.
(5.34)
So ultimately, the variational distribution for Î¼ is such that
q(Î¼ | D) = N (Î¼ | Ï‰, Î›)
(5.35)
whereby
Ï‰ = Î˜Î¥âˆ’1
(5.36)
Î› = Î¥âˆ’1.
(5.37)
171

5.2. Scoring non-zero mean VAR(1) models
Application of the free form method is concluded by seeking a form for q(a | D). By sub-
stitution of terms into (5.10) and dropping those independent of a, hence, in accordance
with (3.25), we acquire
LÎ¼(q) =

q(a | D)
	
âˆ’Î³
2Î´

q(Î¼ | D)Tr [g(A, M)] dÎ¼
âˆ’1
2aTCâˆ—âˆ’1a âˆ’log q(a | D)

da + const.â€²,
(5.38)
moreover via (A.5). If Tr [g(A, M)] is expanded with respect to (5.14), then, in comparison
with (5.15), taking expectations implies
Eq(Î¼| D){Tr [g(A, M)]}
= yTy âˆ’[vec(Î©)]T y âˆ’aT(Id âŠ—XT)y + aT(Id âŠ—Î©T)y âˆ’yTvec(Î©) + [vec(Î©)]T [vec(Î©)]
+ N Tr[Î›] + aT(Id âŠ—XT)vec(Î©) âˆ’aTvec(Î©TÎ©) âˆ’NaTvec(Î›) âˆ’yT(Id âŠ—X)a
+ [vec(Î©)]T (Id âŠ—X)a + aT(Id âŠ—XTX)a âˆ’aT(Id âŠ—Î©TX)a + yT(Id âŠ—Î©)a
âˆ’
$
vec(Î©TÎ©)
%T a âˆ’N [vec(Î›)]T a âˆ’aT(Id âŠ—XTÎ©)a + aT 
Id âŠ—{Î©TÎ© + NÎ›}

a,
in particular, as a consequence of (5.16) and (5.17). We now feed this expression into
(5.38), and subsequently form ËœLÎ¼(q) as before, using the Lagrange multiplier Î½a. Opti-
mising this functional with respect to q(a | D) provides
âˆ‚ËœLÎ¼(q)
âˆ‚q(a | D) = âˆ’Î³
2Î´Eq(Î¼| D){Tr [g(A, M)]} âˆ’1
2aTCâˆ—âˆ’1a âˆ’log q(a | D) âˆ’1 + Î½a = 0.
By rearranging and dropping all terms that do not depend on a, we obtain
q(a | D) âˆexp

âˆ’1
2
	
aTÎ³
Î´

(Id âŠ—XTX) âˆ’(Id âŠ—Î©TX) âˆ’(Id âŠ—XTÎ©) + (Id âŠ—Î©TÎ©)
+ N(Id âŠ—Î›)

+ Câˆ—âˆ’1
a
172

5.2. Scoring non-zero mean VAR(1) models
âˆ’Î³
Î´ aT
(Id âŠ—XT)y âˆ’(Id âŠ—Î©T)y âˆ’(Id âŠ—XT)vec(Î©) + vec(Î©TÎ©) + Nvec(Î›)

âˆ’Î³
Î´

yT(Id âŠ—X) âˆ’yT(Id âŠ—Î©) âˆ’[vec(Î©)]T (Id âŠ—X) +
$
vec(Î©TÎ©)
%T + N [vec(Î›)]T 
a

.
Since vec(Î©TÎ©) = (Id âŠ—Î©T)vec(Î©), this equation can be easily rewritten as
q(a | D) âˆexp

âˆ’1
2
	
aT
Î³
Î´

Id âŠ—
$
(X âˆ’Î©)T(X âˆ’Î©) + NÎ›
% 
+ Câˆ—âˆ’1
a
âˆ’aT
Î³
Î´

 
Id âŠ—[X âˆ’Î©]T
(y âˆ’vec(Î©)) + Nvec(Î›)

âˆ’
Î³
Î´

[y âˆ’vec(Î©)]T (Id âŠ—[X âˆ’Î©]) + N [vec(Î›)]T 
a

.
It is apparent that this is now in the form as given by (5.32), and consequently
q(a | D) = N (a | Ï, Ï„)
(5.39)
as in the zero-mean case, but now with Ï and Ï„ equivalent to
Ï =
	Î³
Î´

Id âŠ—
$
(X âˆ’Î©)T(X âˆ’Î©) + NÎ›
% 
+ Câˆ—âˆ’1âˆ’1
Ã—
	Î³
Î´

 
Id âŠ—[X âˆ’Î©]T
(y âˆ’vec(Î©)) + Nvec(Î›)

(5.40)
Ï„ =
	Î³
Î´

Id âŠ—
$
(X âˆ’Î©)T(X âˆ’Î©) + NÎ›
% 
+ Câˆ—âˆ’1âˆ’1
.
(5.41)
Thus, the expressions for the variational parameters {Î³, Î´, Ï‰, Î›, Ï, Ï„} are (5.20), (5.21),
(5.36), (5.37), (5.40) and (5.41) respectively. Once again, these are update equations,
which must be solved iteratively.
173

5.2. Scoring non-zero mean VAR(1) models
5.2.3
Fixed form method
The variational distributions for both Ïƒ2, Î¼ and a, when this vector is dense, have now
been accounted for. However, as in Chapter 3, we must now derive the approximation
for a in the sparse case, i.e. we constrain elements of Ï and Ï„ to zero relative to the
sparsity structure of a given A-matrix. Consequently, the ï¬xed form procedure is again
most beneï¬cial.
Therefore, we assume ï¬xed forms for each variational, as given by (5.19), (5.35) and (5.39)
in the free form approach. Recall that an inherent component of this method is to derive
the lower bound initially. So, using again the independence of both prior and variational
distributions, (5.9) can be split up into a sum of integrals:
LÎ¼(q) =

q(a | D)q(Ïƒ2 | D)q(Î¼| D) log p(D | A, Ïƒ2, Î¼) da dÏƒ2 dÎ¼ +

q(a | D) log p(a) da
+

q(Ïƒ2 | D) log p(Ïƒ2) dÏƒ2 +

q(Î¼ | D) log p(Î¼) dÎ¼ âˆ’

q(a | D) log q(a | D) da
âˆ’

q(Ïƒ2 | D) log q(Ïƒ2 | D) dÏƒ2 âˆ’

q(Î¼ | D) log q(Î¼ | D) dÎ¼.
(5.42)
Each integral is subsequently tackled in turn. Thus, initially, it follows that

q(a | D)q(Ïƒ2 | D)q(Î¼ | D) log p(D | A, Ïƒ2, Î¼) da dÏƒ2 dÎ¼
=

q(a | D)q(Ïƒ2 | D)q(Î¼ | D)
	
âˆ’dN
2 log 2Ï€Ïƒ2 âˆ’1
2Tr
$
(Ïƒ2)âˆ’1g(A, M)
%
da dÏƒ2 dÎ¼
= âˆ’dN
2 log 2Ï€ âˆ’dN
2

q(Ïƒ2 | D) log Ïƒ2 dÏƒ2
âˆ’1
2

q(a | D)q(Î¼| D)Tr [g(A, M)] da dÎ¼

q(Ïƒ2 | D)(Ïƒ2)âˆ’1 dÏƒ2
= âˆ’dN
2 log 2Ï€ âˆ’dN
2 [log Î´ âˆ’Ïˆ(Î³)] âˆ’Î³
2Î´ [h(Ï, Î©) + j(Ï, Ï„, Î©, Î›)] ,
(5.43)
via equations (A.5), (A.6) and (5.18). In addition, using (2.51) and the variational distri-
174

5.2. Scoring non-zero mean VAR(1) models
bution for Î¼,

q(Î¼ | D) log p(Î¼) dÎ¼
=

q(Î¼ | D)
	
âˆ’d
2 log 2Ï€ âˆ’1
2 log |Î”| âˆ’1
2 (Î¼ âˆ’b) Î”âˆ’1 (Î¼ âˆ’b)T

dÎ¼
= âˆ’d
2 log 2Ï€ âˆ’1
2 log |Î”| âˆ’1
2Eq(Î¼| D) {Î¼ âˆ’b} Î”âˆ’1Eq(Î¼| D)

[Î¼ âˆ’b]T
âˆ’1
2Tr

Î”âˆ’1Varq(Î¼| D)

[Î¼ âˆ’b]T
= âˆ’d
2 log 2Ï€ âˆ’1
2 log |Î”| âˆ’1
2 (Ï‰ âˆ’b) Î”âˆ’1 (Ï‰ âˆ’b)T âˆ’1
2Tr
$
Î”âˆ’1Î›
%
.
Furthermore, using the above computation,

q(Î¼ | D) log q(Î¼ | D) dÎ¼
= âˆ’d
2 log 2Ï€ âˆ’1
2 log |Î›| âˆ’1
2Eq(Î¼| D) {Î¼ âˆ’Ï‰} Î›âˆ’1Eq(Î¼ | D)

[Î¼ âˆ’Ï‰]T
âˆ’1
2Tr

Î›âˆ’1Varq(Î¼| D)

[Î¼ âˆ’Ï‰]T
= âˆ’d
2 log 2Ï€ âˆ’1
2 log |Î›| âˆ’d
2,
as Tr [Î›âˆ’1Î›] = Tr [Id] = d. At this moment, we notice that, as the prior and variational
distributions for both a and Ïƒ2 are identical for both the zero and non-zero mean cases
(albeit with diï¬€ering update equations for the variational parameters), all other integrals
in (5.42) have been previously evaluated in Section 3.3.3. Thus, to recap, we have

q(a | D) log p(a) da = âˆ’d2
2 log 2Ï€ âˆ’1
2 log |Câˆ—| âˆ’1
2ÏTCâˆ—âˆ’1Ï âˆ’1
2Tr

Câˆ—âˆ’1Ï„

.

q(Ïƒ2 | D) log p(Ïƒ2) dÏƒ2 = Î± log Î² âˆ’log Î“(Î±) âˆ’(Î± + 1)[log Î´ âˆ’Ïˆ(Î³)] âˆ’Î²Î³
Î´ .

q(a | D) log q(a | D) da = âˆ’d2
2 log 2Ï€ âˆ’1
2 log |Ï„| âˆ’d2
2 .

q(Ïƒ2 | D) log q(Ïƒ2 | D) dÏƒ2 = âˆ’log Î“(Î³) âˆ’log Î´ + (Î³ + 1)Ïˆ(Î³) âˆ’Î³.
175

5.2. Scoring non-zero mean VAR(1) models
Ultimately, by substituting back into (5.42), the lower bound is given by
LÎ¼(q) = âˆ’dN
2 log 2Ï€ âˆ’dN
2 log Î´ + dN
2 Ïˆ(Î³) âˆ’Î³
2Î´ [h(Ï, Î©) + j(Ï, Ï„, Î©, Î›)] âˆ’1
2 log |Câˆ—|
âˆ’1
2ÏTCâˆ—âˆ’1Ï âˆ’1
2Tr

Câˆ—âˆ’1Ï„

+ Î± log Î² âˆ’log Î“(Î±) âˆ’Î± log Î´ + Î±Ïˆ(Î³)
âˆ’Î²Î³
Î´ âˆ’1
2 log |Î”| âˆ’1
2 (Ï‰ âˆ’b) Î”âˆ’1 (Ï‰ âˆ’b)T âˆ’1
2Tr
$
Î”âˆ’1Î›
%
+ 1
2 log |Ï„| + d2
2 + log Î“(Î³) âˆ’Î³Ïˆ(Î³) + Î³ + 1
2 log |Î›| + d
2.
(5.44)
As before, we realise that (3.40) can be applied to compute the logarithm of the deter-
minant for any singular matrix in (5.44), in particular, for Câˆ—and Ï„. If we knew Î¼ = 0,
then, of course, this expression would simplify down to the lower bound in the zero mean
case, given by (3.30). We now consider the maximisation of LÎ¼(q) with respect to Ï and
Ï„, and hence subsequently, enforce the sparsity constraint. By diï¬€erentiating with respect
to Ï, we have
âˆ‚LÎ¼(q)
âˆ‚Ï
= âˆ‚
âˆ‚Ï

âˆ’Î³
2Î´ [h(Ï, Î©) + j(Ï, Ï„, Î©, Î›)] âˆ’1
2ÏTCâˆ—âˆ’1Ï

= âˆ‚
âˆ‚Ï

âˆ’Î³
2Î´ [y âˆ’vec(Î©) âˆ’(Id âŠ—[X âˆ’Î©]) Ï]T [y âˆ’vec(Î©) âˆ’(Id âŠ—[X âˆ’Î©]) Ï]
âˆ’Î³
2Î´

NÏT [(Id âŠ—Î›)Ï âˆ’2vec(Î›)]

âˆ’1
2ÏTCâˆ—âˆ’1Ï

= âˆ‚
âˆ‚Ï

ÏTHÏ + cTÏ

,
whereby
H = âˆ’Î³
2Î´

Id âŠ—
$
(X âˆ’Î©)T(X âˆ’Î©) + NÎ›
% 
âˆ’1
2Câˆ—âˆ’1
(5.45)
cT = Î³
Î´

(y âˆ’vec(Î©))T (Id âŠ—[X âˆ’Î©]) + N [vec(Î›)]T 
,
(5.46)
and [(Id âŠ—[X âˆ’Î©]) Ï]T [y âˆ’vec(Î©)] = [y âˆ’vec(Î©)]T [(Id âŠ—[X âˆ’Î©]) Ï].
Therefore, we
have the quadratic programming problem (3.31) that was faced in Section 3.3.3, with
176

5.2. Scoring non-zero mean VAR(1) models
diï¬€erent speciï¬cations of H and cT. By again deï¬ning Ï1 as the non-zero elements of a
given A, we must thus maximise ÏT
1 H11Ï1 + cT
1 Ï1 with respect to Ï1 where H11 and c1
are deï¬ned as previous. Resultantly, upon optimisation and solving for Ï1, it is evident
that
Ï1 =
 Î³
Î´

Id âŠ—
$
(X âˆ’Î©)T(X âˆ’Î©) + NÎ›
% 
+ Câˆ—âˆ’1
11
âˆ’1
Ã—
Î³
Î´

 
Id âŠ—[X âˆ’Î©]T
(y âˆ’vec(Î©)) + Nvec(Î›)

1.
(5.47)
This deï¬nition of Ï1 is again used to reconstruct Ï, according to the prescribed sparsity
structure. Recall that the subscript notation refers to choosing the correct submatrix H11
and subvector c1, following row and column permutation.
When maximising LÎ¼(q) with respect to Ï„, as in the zero mean case, it is apparent
that the sparsity constraint cannot be enforced using quadratic programming. Thus, we
derive an expression for those elements of Ï„ with non-zero variational posterior variance
in component form as before. The prior distributions for Ïƒ2 and Î¼, parameters unaï¬€ected
by sparsity, remain speciï¬ed by equations (5.7) and (5.8), whereas that for a is denoted
by (3.33), a product of univariate Gaussians. Using a ï¬xed form variational procedure,
the variational distribution for a is again given, in component form, by (3.34).
We thus strive to re-calculate (5.42) at the component level. By using the identity (3.35),
the probability of the data can be rewritten as
p(D | {aij}, Ïƒ2, Î¼)
= (2Ï€Ïƒ2)âˆ’dN
2 exp

âˆ’(Ïƒ2)âˆ’1
2
Tr
$
(Y âˆ’M âˆ’[X âˆ’M]A)T(Y âˆ’M âˆ’[X âˆ’M]A)
%
= (2Ï€Ïƒ2)âˆ’dN
2 exp

âˆ’(Ïƒ2)âˆ’1
2
N

j=1
d

k=1

[Y âˆ’M âˆ’[X âˆ’M]A]jk
2

= (2Ï€Ïƒ2)âˆ’dN
2 exp
âŽ§
âŽ¨
âŽ©âˆ’(Ïƒ2)âˆ’1
2
N

j=1
d

k=1

yjk âˆ’mjk âˆ’
d

i=1
xjiaik +
d

i=1
mjiaik
2âŽ«
âŽ¬
âŽ­.
177

5.2. Scoring non-zero mean VAR(1) models
The deï¬nition of matrix multiplication is again noted. Hence, the ï¬rst integral of (5.42)
is computed as

q(a | D)q(Ïƒ2 | D)q(Î¼ | D) log p(D | {aij}, Ïƒ2, Î¼) da dÏƒ2 dÎ¼
=

q(a | D)q(Ïƒ2 | D)q(Î¼ | D)

âˆ’dN
2 log 2Ï€Ïƒ2
âˆ’(Ïƒ2)âˆ’1
2
N

j=1
d

k=1

yjk âˆ’mjk âˆ’
d

i=1
xjiaik +
d

i=1
mjiaik
2 
da dÏƒ2 dÎ¼
= âˆ’dN
2 log 2Ï€ âˆ’dN
2 [log Î´ âˆ’Ïˆ(Î³)]
âˆ’Î³
2Î´
N

j=1
d

k=1

q(a | D)q(Î¼| D)

yjk âˆ’mjk âˆ’
d

i=1
xjiaik +
d

i=1
mjiaik
2
da dÎ¼,
via (5.43). Moreover, the double integral in the above expression can be calculated as
Eq(a | D)
âŽ§
âŽ¨
âŽ©Eq(Î¼| D)
âŽ§
âŽ¨
âŽ©

yjk âˆ’mjk âˆ’
d

i=1
xjiaik +
d

i=1
mjiaik
2âŽ«
âŽ¬
âŽ­
âŽ«
âŽ¬
âŽ­
= y2
jk +
$
Eq(Î¼ | D){mjk}
%2 + Varq(Î¼| D){mjk} +

d

i=1
xjiEq(a | D){aik}
2
+
d

i=1
x2
jiVarq(a | D){aik} + Eq(Î¼ | D)
âŽ§
âŽ¨
âŽ©

d

i=1
mjiEq(a | D){aik}
2âŽ«
âŽ¬
âŽ­
+ Eq(Î¼| D)

d

i=1
m2
jiVarq(a | D){aik}

âˆ’2yjkÎ©jk âˆ’2yjk
d

i=1
xjiÏ(i,k)
+ 2yjk
d

i=1
Î©ji Ï(i,k) + 2Î©jk
d

i=1
xji Ï(i,k) âˆ’2Eq(Î¼| D)

mjk
d

i=1
mji Ï(i,k)

âˆ’2Eq(a | D)

d

i=1
xjiaik
d

u=1
Î©juauk

,
(5.48)
using (2.51) and previous deï¬nitions of variational parameters. Recall that Ï(i,k) and Ï„(i,k)
are the variational posterior mean and variance corresponding to element aik respectively.
178

5.2. Scoring non-zero mean VAR(1) models
Notice that, in the ï¬nal line, the indices i and u are used, merely to distinguish the two
summations. Since we only require to maximise LÎ¼(q) with respect to Ï„, a little extra
work can be saved by computing only those outstanding terms in (5.48) that will depend
upon Ï„. Clearly,  d
i=1 x2
jiVarq(a | D){aik} =  d
i=1 x2
jiÏ„(i,k). Moreover,
Eq(Î¼| D)

d

i=1
m2
jiVarq(a | D){aik}

=
d

i=1
Ï„(i,k)
$
Eq(Î¼ | D){mji}
%2 + Varq(Î¼| D){mji}

=
d

i=1
Ï„(i,k)

Î©2
ji + Î›ii

.
Here, we realise that Varq(Î¼| D){mji} = Varq(Î¼| D){Î¼i} = Î›ii, by construction of
M = (mij). Furthermore,
Eq(a | D)

d

i=1
xjiaik
d

u=1
Î©juauk

= Eq(a | D)

d

i=1
xjiaik

Eq(a | D)

d

u=1
Î©juauk

+
d

i=1
d

u=1
xjiÎ©juCovq(a | D){aik, auk}
=
d

i=1
xjiÏ(i,k)
d

u=1
Î©juÏ(u,k) +
d

i=1
xjiÎ©jiÏ„(i,k).
Notice that Covq(a | D){aik, auk} Ì¸= 0 only if i = u as Ï„ is diagonal. The above computations
can then be substituted back into (5.48). Consequently, by dropping all terms independent
of Ï„, we obtain

q(a | D)q(Ïƒ2 | D)q(Î¼ | D) log p(D | {aij}, Ïƒ2, Î¼) da dÏƒ2 dÎ¼
âˆâˆ’Î³
2Î´
N

j=1
d

k=1
d

i=1
Ï„(i,k)
$
(xji âˆ’Î©ji)2 + Î›ii
%
.
Calculating the additional integrals in (5.42) is straightforward since the prior and vari-
179

5.2. Scoring non-zero mean VAR(1) models
ational posterior for a are, in eï¬€ect, identical to those in the zero mean case. Hence, to
recap the results from Section 3.3.3,

q(a | D) log p(a) da = âˆ’

(p,q)âˆˆI

1
2 log 2Ï€ + 1
2 log Câˆ—
(p,q) + 1
2
Ï„(p,q)
Câˆ—
(p,q)
+ 1
2
Ï2
(p,q)
Câˆ—
(p,q)


q(a | D) log q(a | D) da = âˆ’

(p,q)âˆˆI
	1
2 log 2Ï€ + 1
2 log Ï„(p,q) + 1
2

,
where (p, q) âˆˆI if and only if element apq Ì¸= 0. All other terms in (5.42) are independent
of Ï„. Thus, in component form and as a function of Ï„, the lower bound is now such that
LÎ¼(q) âˆâˆ’Î³
2Î´
N

j=1
d

k=1
d

i=1
Ï„(i,k)
$
(xji âˆ’Î©ji)2 + Î›ii
%
âˆ’1
2

(p,q)âˆˆI

Ï„(p,q)
Câˆ—
(p,q)
âˆ’log Ï„(p,q)

. (5.49)
Maximising (5.49) with respect to the element Ï„(p,q) thus provides
âˆ‚LÎ¼(q)
âˆ‚Ï„(p,q)
= âˆ’Î³
2Î´
 N

j=1
$
(xjp âˆ’Î©jp)2%
+ NÎ›pp

âˆ’1
2

1
Câˆ—
(p,q)
âˆ’
1
Ï„(p,q)

.
Upon equating to zero, this equation can be quickly solved for the non-zero Ï„(p,q). Hence,
the diagonal elements of Ï„ are declared as
Ï„(p,q) =
âŽ§
âŽª
âŽª
âŽª
âŽ¨
âŽª
âŽª
âŽª
âŽ©

1
Câˆ—
(p,q)
+ Î³
Î´
N

j=1
(xjp âˆ’Î©jp)2 + NÎ³
Î´ Î›pp
âˆ’1
if apq Ì¸= 0
0
if apq = 0
.
To conclude, update equations have been derived for the variational parameters of Ïƒ2,
namely Î³ and Î´, and, moreover, for those of Î¼, that is Ï‰ and Î›. Furthermore, we can use
Ï1 and Ï„(p,q) to construct Ï and Ï„, the parameters of a. By running until convergence,
parameter values for q(Ïƒ2 | D), q(Î¼ | D) and q(a | D) are acquired. Of course, the converged
value of LÎ¼(q) will provide evidence for each model. As before, we can rewrite the lower
180

5.3. Toy example
bound (5.44) so that constant terms across models are disregarded:
LÎ¼(q) âˆâˆ’dN
2 log Î´ âˆ’Î³
2Î´ [h(Ï, Î©) + j(Ï, Ï„, Î©, Î›)] âˆ’1
2 log |Câˆ—| âˆ’1
2ÏTCâˆ—+Ï
âˆ’1
2Tr

Câˆ—+Ï„

âˆ’Î± log Î´ âˆ’Î²Î³
Î´ âˆ’1
2 (Ï‰ âˆ’b) Î”âˆ’1 (Ï‰ âˆ’b)T
âˆ’1
2Tr
$
Î”âˆ’1Î›
%
+ 1
2 log |Ï„| + 1
2 log |Î›|.
(5.50)
Here, Câˆ—is now inverted using the Moore-Penrose inverse, Câˆ—+, as explained in Sec-
tion 3.4.1.
5.3
Toy example
The methodology discussed thus far in this chapter is elucidated via a straightforward
example. Here, we examine an arbitrary non-zero mean VAR(1) model. In fact, the true
model is chosen with speciï¬cations identical to those given in the corresponding example
for the zero mean case in Section 3.5. Moreover here, the mean is speciï¬ed as Î¼ = (1, 1),
a row vector. Consequently, a dataset was generated from the model (5.1), where A is
represented graphically by Figure 3.3. We let x1 = Î¼ and x250 = y249. Again, a candidate
set of 15 A-graphs, ignoring the null graph, is constructed, each of which is scored using
LÎ¼(q).
The choice of prior parameter values is made as before for both a and Ïƒ2. That is, we
avoid Lindleyâ€™s paradox, namely that a simpler model will be favoured as the prior is
made to be more diï¬€use, by choosing an informative prior of the form N (0, Câˆ—) on a,
where cij âˆˆ{0, 0.5}. Moreover, a vague IG(1, 0.001) prior is speciï¬ed on Ïƒ2. For further
details, refer back to Section 3.4.2. Furthermore, a new prior is required for Î¼. This is
denoted as
p(Î¼) = N (Î¼ | 0, 10, 000Id).
181

5.3. Toy example
In this speciï¬cation, it seems sensible to centre the distribution at the zero mean case.
Each element of the vector Î¼ is then assigned prior variance equal to 10, 000. Hence,
prior ignorance is represented since the prior is not concentrated around any particular
value. By running all update equations until convergence, we sought to ï¬nd values for
the variational parameters for each variational distribution, given by (5.19), (5.35) and
(5.39). As erstwhile, convergence of update equations and lower bound values took 4
iterations. The expressions for Ï‰ and Î› were run ï¬rst so that, to start the algorithm,
initial, arbitrary choices were made such that Î³ = Î´ = 1 and Ï(i,j) = Ï„(i,j) = 1, whenever
aij Ì¸= 0.
The results obtained in this case are revealed in Table 5.1. Consider ï¬rstly the values of
the lower bound, LÎ¼, Mi(qi). As in the zero mean case, the true A was deemed to be the
most plausible model in the candidate set. Moreover, those models, containing at least
the two, correct free elements, were again ranked highly. Hence, the more complex models
were penalised suï¬ƒciently by the choice of informative prior variance on a. Candidates
with neither of the true non-zero elements of A unsurprisingly fared poorly, thus indicating
a very weak signal in the data for the two, true zero elements being non-zero.
In addition, the posterior means of A, Ïƒ2 and Î¼ are now inspected and compared to the
truth. With a dataset of size N = 250, Ë†A and Eq(Î¼ | D){Î¼} are reasonably close to the
truth for each candidate A-matrix. In fact, in both cases, the estimates are extremely
akin to each other. In particular, if we misspecify the model, the estimates for Î¼, the
point about which the data ï¬‚uctuates, are unaï¬€ected. However, those for Ïƒ2 tend to show
more discrepancy, a scenario also seen in the zero mean case. If a candidate model was
speciï¬ed with at least the correct free elements seen in the truth, the afore-mentioned
estimates were extremely accurate. Yet, if the wrong model was chosen, i.e. an incorrect
sparsity structure of A, the resulting error provided inaccuracy in Eq(Ïƒ2 | D)(Ïƒ2).
Finally, we compare Tables 3.1 and 5.1, the zero and non-zero mean models respectively.
It is seen in these tables that the estimates of Ïƒ2 for each candidate are almost identical.
182

5.3. Toy example
Speciï¬cation
Posterior means
LÎ¼, Mi(qi)
A-matrix
Ë†A-matrix
Eq(Ïƒ2 | D){Ïƒ2}
Eq(Î¼ | D){Î¼}
âˆ—
0
0
0

âˆ’0.069
0
0
0

0.134
(0.973, 0.951)
âˆ’1142.389
0
0
0
âˆ—

0
0
0
âˆ’0.055

0.134
(0.973, 0.951)
âˆ’1142.610
0
âˆ—
0
0

0
0.667
0
0

0.109
(0.973, 0.951)
âˆ’1091.392

0
0
âˆ—
0


0
0
0.338
0

0.125
(0.974, 0.951)
âˆ’1126.006
âˆ—
âˆ—
0
0

âˆ’0.070
0.662
0
0

0.109
(0.973, 0.951)
âˆ’1093.702
âˆ—
0
âˆ—
0

âˆ’0.072
0
0.338
0

0.125
(0.973, 0.951)
âˆ’1128.282
0
âˆ—
0
âˆ—

0
0.668
0
âˆ’0.060

0.109
(0.973, 0.951)
âˆ’1093.840

0
0
âˆ—
âˆ—


0
0
0.338
âˆ’0.055

0.125
(0.973, 0.951)
âˆ’1128.561

âˆ—
0
0
âˆ—


âˆ’0.069
0
0
âˆ’0.055

0.134
(0.973, 0.951)
âˆ’1144.945
0
âˆ—
âˆ—
0


0
0.669
0.340
0

0.100
(0.974, 0.952)
âˆ’1073.091
âˆ—
âˆ—
0
âˆ—

âˆ’0.070
0.663
0
âˆ’0.060

0.109
(0.973, 0.951)
âˆ’1096.150

âˆ—
0
âˆ—
âˆ—


âˆ’0.072
0
0.338
âˆ’0.055

0.125
(0.973, 0.951)
âˆ’1130.837

âˆ—
âˆ—
âˆ—
0


âˆ’0.073
0.664
0.341
0

0.100
(0.974, 0.952)
âˆ’1075.335
0
âˆ—
âˆ—
âˆ—


0
0.670
0.340
âˆ’0.060

0.100
(0.974, 0.952)
âˆ’1075.536
âˆ—
âˆ—
âˆ—
âˆ—

âˆ’0.073
0.665
0.340
âˆ’0.060

0.100
(0.974, 0.952)
âˆ’1077.778
Table 5.1: Lower bounds and posterior means for each non-zero mean VAR(1) model
183

5.4. Taking a random walk
Here, there is a correspondence between the two cases whereby, if we select an A-matrix
with an erroneous sparsity pattern, the variational posterior mean of the noise variance
suï¬€ers, regardless of our beliefs about Î¼. The most notable diï¬€erence stems from the
values of LMi(qi) and LÎ¼, Mi(qi). Although the correct model is selected in each case, the
lower bound values are higher when Î¼ = 0. When the mean is unknown, the resulting
uncertainty in the problem implies that the approximate evidence for each model, denoted
by LÎ¼, Mi(qi), is reduced. This may also account for the slight discrepancy between the
corresponding Ë†A-matrices. These estimates are very similar, although marginally more
inaccurate to the truth in the non-zero mean case.
5.4
Taking a random walk
Hitherto in this chapter, variational Bayesian methods have been utilised to derive an ap-
proximation, LÎ¼, Mi(qi), to the logarithm of the marginal likelihood, p(D | Mi). Hence, we
were able to score non-zero mean VAR(1) models, in particular for graphs with a small
number of nodes. However, we can apply the methods of Chapter 4 to ï¬nd the most
plausible models in graphical spaces of higher dimension. In particular, the variational al-
gorithm, presented in this chapter, can again be embedded within the Metropolis-Hastings
scheme, given by Algorithm 5, so that a random walk can be made across the space. The
principles behind the MCMC algorithm remain the same â€” a new model is proposed
by the addition or deletion of a randomly selected edge from the current model, and is
accepted on the basis of a log acceptance probability.
For analysis, trace and ACF plots can be used to test for the convergence of the chain, as
well as the more formal diagnostics previously described. Furthermore, image plots of the
counting matrix Ë†Î  are produced, which will be dependent on the choice of p = P(aij = 0).
When using simulated data, Ë†Î  can then be normalised, and hence compared to the true
adjacency matrix Î  by computing the residual sum of squares, S (c.f. (4.11)).
184

5.4. Taking a random walk
Moreover, approximate posterior summaries can be produced for the coeï¬ƒcients aij of
the matrix A. We realise that of additional inferential interest here are the components
of the mean vector Î¼ across models. As the prior speciï¬cation for Î¼, given by (5.8), is an
equivalent choice for every model, its conditioning on Mi (although not stated explicitly)
can be dropped. Thus, we wish to update the prior
p(Î¼j) = N (Î¼j | bj, Î”jj),
and subsequently infer the marginal posterior p(Î¼j | D), where j = 1, . . . , d. As before,
Bayesian model averaging can be applied to estimate this true density, i.e. for a con-
verged chain of length n, we average all variational densities for Î¼j (c.f. (5.35)) that are
associated with the models accepted across the scheme. So, akin to (4.12) and using the
corresponding notation, we aim to compute
pvar(Î¼j | D) = 1
n
n

k=1
N

Î¼j | Ï‰(k)
j , Î›(k)
jj

.
(5.51)
5.4.1
Examples
In the following, the same speciï¬cations were maintained from Section 4.3.2, i.e. d = 10,
N = 250 and Ïƒ2 = 0.1. The prior on a was such that cij âˆˆ{0, 0.5} and for that on Ïƒ2,
Î± = 1, Î² = 0.001. Moreover, a N (0, 10, 000Id) prior was allowed for Î¼ as in Section 5.3.
By now simulating data from the non-zero mean VAR(1) model (5.1), only A, p and also
now Î¼ were changed between examples. The MCMC algorithm was initialised from the
graph with only one self-loop on node y1, and run in C for 10, 000, 000 iterations, of which
the ï¬rst 100, 000 were discarded as burn-in and the remainder thinned by 1000.
185

5.4. Taking a random walk
Example 1
We allow direct comparison between this and the corresponding ï¬rst example in Sec-
tion 4.3.2 by specifying A = diag(0.8) and p = 0.5, but, furthermore, Î¼ = (1, . . . , 1), a
10-vector. The output of the scheme is displayed graphically in Figure 5.1.
0
2000
4000
6000
8000
10000
âˆ’7360
âˆ’7350
âˆ’7340
âˆ’7330
Trace plot of L(q)
Iteration
L(q)
0
20
40
60
80
100
0.0
0.2
0.4
0.6
0.8
1.0
Lag
ACF
ACF plot for L(q)
Histogram of L(q)
L(q)
Frequency
âˆ’7360
âˆ’7350
âˆ’7340
âˆ’7330
0
100
300
500
700
0
1
2
3
4
5
6
7
8
9
10
0
1
2
3
4
5
6
7
8
9
10
Image plot for Pihat
Row
Col
Figure 5.1: Plots for the analysis of the MCMC output in Example 1 (non-zero mean)
The trace and ACF plots are extremely similar to those in the corresponding zero mean
example, indicating a well-mixing and independent chain. The only signiï¬cant diï¬€erent
is that the mean value of the lower bound, about which the values of the chain ï¬‚uctu-
ate, is greater in this case due to the additional uncertainty about Î¼. Moreover, the
effectiveSize of the chain is equal to 9900, indicating that the chain is fully indepen-
dent. When applied to the variational scores, the Raftery-Lewis test yielded the following:
186

5.4. Taking a random walk
Iterations = 1:9900
Thinning interval = 1
Number of chains = 1
Sample size per chain = 9900
Quantile (q) = 0.025
Accuracy (r) = +/- 0.005
Probability (s) = 0.95
Burn-in
Total Lower bound
Dependence
(M)
(N)
(Nmin)
factor (I)
Lq
2
3794
3746
1.01
The Heidelberger-Welch diagnostic reached a similar conclusion:
Stationarity start
p-value
test
iteration
Lq
passed
1
0.0708
Halfwidth Mean
Halfwidth
test
Lq
passed
-7339 0.114
Each diagnostic has produced overwhelming evidence in favour of the chain having con-
verged. In addition, when employing these tests for components of Ï, Ï„, Ï‰ and Î›, stored
at each iteration, the results produced were concurrent with those above.
Moreover, it is evident from Figures 4.3 and 5.1 that the image plots of Ë†Î  in both the
zero and non-zero mean cases are well-matched and, after normalising, will be close to
the truth Î .
In this case, the residual sum of squares is computed as S = 0.757, a
value only marginally bigger than that in the zero mean case. This implies that there is
suï¬ƒcient data available here to learn the unknown mean, and hence the zero and non-zero
mean cases subsequently become most alike. So, the new variational algorithm, derived
in this chapter, is able to accurately predict the sparsity structure of the true A from the
simulated data.
Finally, Figures 5.2 and 5.3 display approximate posterior information for numerous co-
eï¬ƒcients of both A and Î¼.
187

5.4. Taking a random walk
0.0
0.5
1.0
Value
0
2
4
6
8
10
Density
0
0.2
0.4
0.6
0.8
1
Probability
0.0
0.5
1.0
Value
0
2
4
6
8
10
Density
0
0.2
0.4
0.6
0.8
1
Probability
0.0
0.5
1.0
Value
0
2
4
6
8
10
Density
0
0.2
0.6
1
Probability
0.0
0.5
1.0
Value
0
2.2
4.4
6.6
8.8
11
Density
0
0.2
0.4
0.6
0.8
1
Probability
0.0
0.5
1.0
Value
0
2
4
6
8
10
Density
0
0.2
0.4
0.6
0.8
1
Probability
0.0
0.5
1.0
Value
0
2.2
4.4
6.6
8.8
11
Density
0
0.2
0.4
0.6
0.8
1
Probability
0.0
0.5
1.0
Value
0
2
4
6
8
10
Density
0
0.2
0.4
0.6
0.8
1
Probability
0.0
0.5
1.0
Value
0
2
4
6
8
10
Density
0
0.2
0.4
0.6
0.8
1
Probability
0.0
0.5
1.0
Value
0
2
4
6
8
10
Density
0
0.2
0.4
0.6
0.8
1
Probability
a11
a12
a13
a21
a22
a23
a31
a32
a33
Figure 5.2: Plots showing estimated, marginal posterior distributions for aij, i, j = 1, 2, 3,
in Example 1 (non-zero mean)
188

5.4. Taking a random walk
Value
Density
0
0.8
1.6
2.4
3.2
4
0.4
0.8
1.2
1.6
Value
Density
0
0.8
1.6
2.4
3.2
4
0.4
0.8
1.2
1.6
Value
Density
0
0.9
1.8
2.7
3.6
0.4
0.8
1.2
1.6
Value
Density
0
1
2
3
4
0.4
0.8
1.2
1.6
Value
Density
0
0.7
1.4
2.1
2.8
0.4
0.8
1.2
1.6
Value
Density
0
0.8
1.6
2.4
3.2
4
0.4
0.8
1.2
1.6
Î¼1
Î¼2
Î¼3
Î¼4
Î¼5
Î¼6
Figure 5.3: Plots showing estimated, marginal posterior distributions for Î¼j, j = 1, . . . , 6,
in Example 1
As in the zero mean case, the approximate posterior probability that aij = 0 is large for
all oï¬€-diagonal elements. Moreover, the density plots, given that aij Ì¸= 0, are peaked at
around the true speciï¬cation for the diagonal entries. We realise that Figures 4.4 and
5.2 are almost identical. As mentioned above, this is a consequence of the mean being
estimated accurately, a fact borne out by Figure 5.3. Here, as expected, we see that the
approximate posterior mode of each Î¼j is close to 1.
Example 2
We now choose A = tridiag(0.2, 0.4, 0.2), as in the corresponding zero mean case. How-
ever, on this occasion, the prior probability p is assigned such that p = 0.9. In addition,
189

5.4. Taking a random walk
the mean is speciï¬ed as Î¼ = (2, . . ., 2). Figure 5.4 reveals the results of the algorithm.
0
2000
4000
6000
8000
10000
âˆ’7405
âˆ’7395
âˆ’7385
âˆ’7375
Trace plot of L(q)
Iteration
L(q)
0
20
40
60
80
100
0.0
0.2
0.4
0.6
0.8
1.0
Lag
ACF
ACF plot for L(q)
Histogram of L(q)
L(q)
Frequency
âˆ’7405
âˆ’7400
âˆ’7395
âˆ’7390
âˆ’7385
âˆ’7380
âˆ’7375
0
200
400
600
800
0
1
2
3
4
5
6
7
8
9
10
0
1
2
3
4
5
6
7
8
9
10
Image plot for Pihat
Row
Col
Figure 5.4: Plots for the analysis of the MCMC output in Example 2 (non-zero mean)
From the plots, it is seen that the chain is moving freely and quickly in the graphi-
cal space, as well as the autocorrelation dropping to zero immediately. Moreover, the
effectiveSize of the chain, once again computed as 9900, intimates full independence
of the values.
Both convergence diagnostics produce favourable results, whereby the
Raftery-Lewis output is
Iterations = 1:9900
Thinning interval = 1
Number of chains = 1
Sample size per chain = 9900
Quantile (q) = 0.025
Accuracy (r) = +/- 0.005
Probability (s) = 0.95
190

5.4. Taking a random walk
Burn-in
Total Lower bound
Dependence
(M)
(N)
(Nmin)
factor (I)
Lq
2
3768
3746
1.01
and the Heidelberger-Welch test gives the results
Stationarity start
p-value
test
iteration
Lq
passed
1
0.657
Halfwidth Mean
Halfwidth
test
Lq
passed
-7383 0.0875
Again, upon application of these diagnostics to components of Ï, Ï„, Ï‰ and Î›, the same
outcome was provided. Henceforth, only the chain of lower bound is thus analysed.
Noticeable diï¬€erences are apparent upon comparison of the image plots in the two cases
due to the change in speciï¬cation of p. In this case, p = 0.9 was chosen to be higher
than the â€˜trueâ€™ value (computed as p = 0.72).
Consequently, a slight preference has
been given to the acceptance of models considered too sparse, as displayed in Figure 5.4.
That is, many true edges are identiï¬ed from the data with less regularity than seen in
Figure 4.5, whilst the link from y5 to y4 is no-longer recognised. This trait is reï¬‚ected
by the calculation of S = 2.619, a value relatively less accurate than in the zero mean
circumstance, where p = 0.5.
By studying Figure 5.5, it follows that the true speciï¬cations of aij are being well repre-
sented in these graphical summaries. Moreover, it is clear that there is much similarity
between these plots and those in the zero mean case, shown in Figure 4.6. This is despite
the choice of p = P(aij = 0) being increased here. Although this implies a bias for the
selection of more sparse models, the variational algorithm is still able to predict accu-
rately those values of aij that are not constrained to zero in all models accepted across
the scheme. In addition, it is obvious from Figure 5.6 that all plots of pvar(Î¼j | D) are
peaked near to the true value. At each iteration, accurate estimates of all Î¼j have been
191

5.4. Taking a random walk
0.0
0.5
1.0
Value
0
1.4
2.8
4.2
5.6
7
Density
0
0.2
0.4
0.6
0.8
1
Probability
0.0
0.5
1.0
Value
0
1.4
2.8
4.2
5.6
7
Density
0
0.2
0.4
0.6
0.8
1
Probability
0.0
0.5
1.0
Value
0
1.4
2.8
4.2
5.6
7
Density
0
0.2
0.4
0.6
0.8
1
Probability
0.0
0.5
1.0
Value
0
1.6
3.2
4.8
6.4
8
Density
0
0.2
0.4
0.6
0.8
1
Probability
0.0
0.5
1.0
Value
0
1.5
3
4.5
6
7.5
Density
0
0.2
0.4
0.6
0.8
1
Probability
0.0
0.5
1.0
Value
0
1.6
3.2
4.8
6.4
8
Density
0
0.2
0.4
0.6
0.8
1
Probability
0.0
0.5
1.0
Value
0
1.4
2.8
4.2
5.6
7
Density
0
0.2
0.4
0.6
0.8
1
Probability
0.0
0.5
1.0
Value
0
1.5
3
4.5
6
7.5
Density
0
0.2
0.4
0.6
0.8
1
Probability
0.0
0.5
1.0
Value
0
1.4
2.8
4.2
5.6
Density
0
0.2
0.4
0.6
0.8
Probability
a11
a12
a13
a21
a22
a23
a31
a32
a33
Figure 5.5: Plots showing estimated, marginal posterior distributions for aij, i, j = 1, 2, 3,
in Example 2 (non-zero mean)
192

5.4. Taking a random walk
Value
Density
0
2
4
6
8
10
1.4
1.8
2.2
2.6
Value
Density
0
1.8
3.6
5.4
7.2
9
1.4
1.8
2.2
2.6
Value
Density
0
2
4
6
8
1.4
1.8
2.2
2.6
Value
Density
0
2
4
6
8
10
1.4
1.8
2.2
2.6
Value
Density
0
2
4
6
8
10
1.4
1.8
2.2
2.6
Value
Density
0
2
4
6
8
1.4
1.8
2.2
2.6
Î¼1
Î¼2
Î¼3
Î¼4
Î¼5
Î¼6
Figure 5.6: Plots showing estimated, marginal posterior distributions for Î¼j, j = 1, . . . , 6,
in Example 2
provided, and uncertainty about every component reduced. Hence, as in the previous
example, the density plots are alike in shape.
Example 3
The third example in Section 4.3.2 was also repeated with A = tridiag(0.4, 0, 0.4) and
p = 0.9 as before, but now Î¼ = (3, . . ., 3). The output was analysed and is displayed
graphically below.
When calculating convergence diagnostics, the Raftery-Lewis test yielded
193

5.4. Taking a random walk
0
2000
4000
6000
8000
10000
âˆ’7365
âˆ’7360
âˆ’7355
Trace plot of L(q)
Iteration
L(q)
0
20
40
60
80
100
0.0
0.2
0.4
0.6
0.8
1.0
Lag
ACF
ACF plot for L(q)
Histogram of L(q)
L(q)
Frequency
âˆ’7365
âˆ’7360
âˆ’7355
0
1000
2000
3000
4000
5000
0
1
2
3
4
5
6
7
8
9
10
0
1
2
3
4
5
6
7
8
9
10
Image plot for Pihat
Row
Col
Figure 5.7: Plots for the analysis of the MCMC output in Example 3 (non-zero mean)
Iterations = 1:9900
Thinning interval = 1
Number of chains = 1
Sample size per chain = 9900
Quantile (q) = 0.025
Accuracy (r) = +/- 0.005
Probability (s) = 0.95
Burn-in
Total Lower bound
Dependence
(M)
(N)
(Nmin)
factor (I)
Lq
2
3856
3746
1.03
Moreover, application of Heidelberger and Welch resulted in
Stationarity start
p-value
test
iteration
Lq
passed
1
0.113
194

5.4. Taking a random walk
Halfwidth Mean
Halfwidth
test
Lq
passed
-7355 0.0386
Therefore, the plots and diagnostics are all concurrent with chain convergence and in-
dependence of values (effectiveSize = 9900). Notice that the histograms produced
in Figures 4.7 and 5.7 are almost identical due to the larger speciï¬cation of p in each
case. Similarly, the image plots also overlap signiï¬cantly, revealing an obvious tendency
to select models that are not dense. For completeness, we note that S = 0.015 here. To
conclude, we again realise that the approximate marginal posterior summaries for both
aij (Figure 5.8) and Î¼j (Figure 5.9) are a strong reï¬‚ection of the truth.
0.0
0.5
1.0
Value
0
1.4
4.2
7
Density
0
0.2
0.6
1
Probability
0.0
0.5
1.0
Value
0
1.4
4.2
7
Density
0
0.2
0.6
1
Probability
0.0
0.5
1.0
Value
0
1.4
4.2
7
Density
0
0.2
0.6
1
Probability
0.0
0.5
1.0
Value
0
1.7
3.4
5.1
6.8
8.5
Density
0
0.2
0.4
0.6
0.8
1
Probability
0.0
0.5
1.0
Value
0
1.7
3.4
5.1
6.8
8.5
Density
0
0.2
0.4
0.6
0.8
1
Probability
0.0
0.5
1.0
Value
0
1.7
3.4
5.1
6.8
8.5
Density
0
0.2
0.4
0.6
0.8
1
Probability
0.0
0.5
1.0
Value
0
1.7
3.4
5.1
6.8
8.5
Density
0
0.2
0.4
0.6
0.8
1
Probability
0.0
0.5
1.0
Value
0
1.7
3.4
5.1
6.8
8.5
Density
0
0.2
0.4
0.6
0.8
1
Probability
0.0
0.5
1.0
Value
0
1.7
3.4
5.1
6.8
8.5
Density
0
0.2
0.4
0.6
0.8
1
Probability
a11
a12
a13
a21
a22
a23
a31
a32
a33
Figure 5.8: Plots showing estimated, marginal posterior distributions for aij, i, j = 1, 2, 3,
in Example 3 (non-zero mean)
195

5.4. Taking a random walk
Value
Density
0
2.6
5.2
7.8
10.4
13
2.4
2.8
3.2
3.6
Value
Density
0
2
4
6
8
10
2.4
2.8
3.2
3.6
Value
Density
0
2
4
6
8
2.4
2.8
3.2
3.6
Value
Density
0
2
4
6
8
10
2.4
2.8
3.2
3.6
Value
Density
0
2.2
4.4
6.6
8.8
11
2.4
2.8
3.2
3.6
Value
Density
0
2
4
6
8
10
2.4
2.8
3.2
3.6
Î¼1
Î¼2
Î¼3
Î¼4
Î¼5
Î¼6
Figure 5.9: Plots showing estimated, marginal posterior distributions for Î¼j, j = 1, . . . , 6,
in Example 3
5.4.2
Application to ERP data
We now reconsider the ERP data, introduced previously in Section 4.3.6. It is recalled
that an animal and distractor dataset, each of size N = 250, were obtained by monitoring
the cerebral activity produced at d = 32 electrodes for a particular volunteer in the study
(shown in Figures 4.14 and 4.15). On this occasion, each dataset was ï¬tted to a non-zero
mean VAR(1) model. The sparsity structure of A and the likely values of the coeï¬ƒcients
aij, Î¼j are of inferential interest.
Here, the sample mean of ERP values was not subtracted from the data since the true
mean is itself estimated during the algorithm. Thus, the Metropolis-Hastings scheme was
run twice in an identical fashion to that described in Section 5.4.1. The prior distributions
196

5.4. Taking a random walk
for a, Ïƒ2 and Î¼ were also chosen as here, whereas we ï¬xed p = 31
32 in accordance with the
zero mean case. Figures 5.10 and 5.11 display the graphical summaries of the sampler for
the animal and distractor datasets respectively.
Trace plot of L(q)
Iteration
L(q)
0
2000
4000
6000
8000
10000
âˆ’32950
âˆ’32930
âˆ’32910
0
20
40
60
80
100
0.0
0.2
0.4
0.6
0.8
1.0
Lag
ACF
ACF plot for L(q)
Histogram of L(q)
L(q)
Frequency
âˆ’32960
âˆ’32950
âˆ’32940
âˆ’32930
âˆ’32920
âˆ’32910
0
200
400
600
800
1200
0
5
10
15
20
25
30
0
5
10
15
20
25
30
Image plot for Pihat
Row
Col
Figure 5.10: Plots for the analysis of the MCMC output for the animal ERP data (non-
zero mean)
Formal diagnostics can now be administered to test for convergence of the chains. For
the animal dataset, Raftery-Lewis oï¬€ered the results
Iterations = 1:9900
Thinning interval = 1
Number of chains = 1
Sample size per chain = 9900
Quantile (q) = 0.025
Accuracy (r) = +/- 0.005
Probability (s) = 0.95
197

5.4. Taking a random walk
Trace plot of L(q)
Iteration
L(q)
0
2000
4000
6000
8000
10000
âˆ’32510
âˆ’32490
âˆ’32470
0
20
40
60
80
100
0.2
0.4
0.6
0.8
1.0
Lag
ACF
ACF plot for L(q)
Histogram of L(q)
L(q)
Frequency
âˆ’32510
âˆ’32500
âˆ’32490
âˆ’32480
âˆ’32470
âˆ’32460
0
200
400
600
800
1000
0
5
10
15
20
25
30
0
5
10
15
20
25
30
Image plot for Pihat
Row
Col
Figure 5.11: Plots for the analysis of the MCMC output for the distractor ERP data
(non-zero mean)
Burn-in
Total Lower bound
Dependence
(M)
(N)
(Nmin)
factor (I)
Lq
7
8315
3746
2.22
whereas the Heidelberger-Welch diagnostic revealed
Stationarity start
p-value
test
iteration
Lq
passed
1
0.484
Halfwidth Mean
Halfwidth
test
Lq
passed
-32926 0.757
Moreover, in the distractor case, the output of the Raftery-Lewis test was
198

5.4. Taking a random walk
Iterations = 1:9900
Thinning interval = 1
Number of chains = 1
Sample size per chain = 9900
Quantile (q) = 0.025
Accuracy (r) = +/- 0.005
Probability (s) = 0.95
Burn-in
Total Lower bound
Dependence
(M)
(N)
(Nmin)
factor (I)
Lq
8
10428
3746
2.78
Additionally, Heidelberger-Welch returned
Stationarity start
p-value
test
iteration
Lq
passed
1
0.246
Halfwidth Mean
Halfwidth
test
Lq
passed
-32482 1.04
So, as was noted in the zero mean case due to the length of the run, the graphical output
and diagnostics suggest that these chains have converged, but without rapid exploration
of the space, and thus with fewer independent values.
Upon comparison of the two image plots for each dataset, all of the conclusions seen when
Î¼ = 0 can again be reached. For further discussion, the reader is referred back to the
corresponding stage in Section 4.3.6. So, when the mean is non-zero, we can again surmise
that the decision needed to categorise both animal and distractor images is made along
similar neural pathways. Moreover, the analogous animal and distractor image plots are
closely related, independent of the value of Î¼. This is particularly true along the main
diagonals, but many edges between diï¬€erent electrodes are also regularly recognised.
Figures 5.12 and 5.13 provide variational posterior summaries for a set of aij in the animal
and distractor cases respectively.
199

5.4. Taking a random walk
Value
0
8
16
24
32
0
0.4
0.8
1.2
Density
0
0.2
0.4
0.6
0.8
Probability
Value
0
6
12
18
24
âˆ’0.2
0.2
0.6
1
Density
0
0.2
0.4
0.6
0.8
Probability
Value
0
8
16
24
32
40
âˆ’0.4
0
0.4
0.8
Density
0
0.2
0.6
1
Probability
Value
0
4
8
12
16
20
âˆ’0.4
0
0.4
0.8
Density
0
0.2
0.6
1
Probability
Value
0
6
12
18
24
0
0.4
0.8
1.2
Density
0
0.2
0.4
0.6
0.8
Probability
Value
0
10
20
30
40
50
âˆ’0.4
0
0.4
0.8
Density
0
0.2
0.4
0.6
0.8
1
Probability
Value
0
4
8
12
16
20
âˆ’0.4
0
0.4
0.8
Density
0
0.2
0.4
0.6
0.8
1
Probability
Value
0
4
8
12
16
20
âˆ’0.6
âˆ’0.2
0.2
0.6
Density
0
0.2
0.6
1
Probability
Value
0
5
10
15
20
0
0.4
0.8
1.2
Density
0
0.2
0.4
0.6
0.8
Probability
a11
a12
a13
a21
a22
a23
a31
a32
a33
Figure 5.12: Plots showing estimated, marginal posterior distributions for aij, i, j =
1, 2, 3, for the animal ERP data (non-zero mean)
200

5.4. Taking a random walk
Value
0
4
8
12
16
20
0
0.4
0.8
1.2
Density
0
0.2
0.4
0.6
0.8
1
Probability
Value
0
4
8
12
16
âˆ’0.2
0.2
0.6
1
Density
0
0.2
0.4
0.6
0.8
Probability
Value
0
8
16
24
32
40
âˆ’0.4
0
0.4
0.8
Density
0
0.2
0.4
0.6
0.8
1
Probability
Value
0
9
18
27
36
45
âˆ’0.4
0
0.4
0.8
Density
0
0.2
0.4
0.6
0.8
1
Probability
Value
0
6
12
18
24
30
0
0.4
0.8
1.2
Density
0
0.2
0.4
0.6
0.8
1
Probability
Value
0
9
18
27
36
45
âˆ’0.4
0
0.4
0.8
Density
0
0.2
0.4
0.6
0.8
1
Probability
Value
0
3
6
9
12
15
âˆ’0.4
0
0.4
0.8
Density
0
0.2
0.6
1
Probability
Value
0
4.5
9
13.5
22.5
âˆ’0.6
âˆ’0.2
0.2
0.6
Density
0
0.2
0.4
0.6
0.8
1
Probability
Value
0
5
10
15
20
25
0
0.4
0.8
1.2
Density
0
0.2
0.6
1
Probability
a11
a12
a13
a21
a22
a23
a31
a32
a33
Figure 5.13: Plots showing estimated, marginal posterior distributions for aij, i, j =
1, 2, 3, for the distractor ERP data (non-zero mean)
201

5.4. Taking a random walk
It follows that a13, a21, a23 and a31 appear all to be zero in these ï¬gures as before. In
fact, the respective densities for these coeï¬ƒcients are similar both to each other and the
corresponding plots in the zero mean case, with the possible exception of pvar(a21 | a21 Ì¸=
0, D). It is additionally evident that a32 = 0; here, we note that, unlike in Figures 4.18 and
4.19, the densities for this coeï¬ƒcient are tightly peaked around zero. All of the remaining
elements considered are suggested to be non-zero, with the likely values of each akin for
the two datasets. Moreover, it is realised that some of the densities are multimodal, as
discussed erstwhile.
For completeness, plots of pvar(Î¼j | D) are provided for the two datasets in Figures 5.14
and 5.15. Upon comparison to each other, the densities are peaked around quite distinct
values for all coeï¬ƒcients, apart from that for Î¼5 and especially Î¼6. Thus, we can suggest
that the mean level of electrical activity varies regularly at corresponding electrodes for
the two datasets. In such cases, the response is greater upon recognition of an animal
despite the use of comparable circuits in each case to process the information.
A valid question to ask at this stage is whether there is much gain in applying the more
complex non-zero mean approach as opposed to comparing zero mean VAR(1) models with
centralised input data (i.e. by subtracting the sample mean). For instance, in the current
scenario, results are similar between the two approaches. We have learnt additionally
about the likely values of components of Î¼ here, but this required a large quantity of
theoretical and computational work. Yet, in poor datasets, diï¬€erences may exist if we
assume either zero or non-zero mean models. In fact, evidence of this is provided in the
ï¬nal example below.
5.4.3
Application to microarray data
To conclude, our Metropolis-Hastings algorithm is run again for the microarray data,
introduced in the previous chapter, and now modelled via a non-zero mean VAR(1) process
202

5.4. Taking a random walk
Value
Density
0
0.35
0.7
1.05
1.4
1.75
1.1
1.8
2.5
3.2
3.9
Value
Density
0
0.55
1.1
1.65
2.2
2.75
1.9
2.6
3.3
4
4.7
Value
Density
0
0.25
0.5
0.75
1
1.25
0.6
1.3
2
2.7
3.4
Value
Density
0
0.2
0.4
0.6
0.8
1
3.8
4.5
5.2
5.9
6.6
Value
Density
0
0.19
0.38
0.57
0.76
0.95
1.2
1.9
2.6
3.3
4
Value
Density
0
0.2
0.4
0.6
0.8
1
4.3
5
5.7
6.4
7.1
Î¼1
Î¼2
Î¼3
Î¼4
Î¼5
Î¼6
Figure 5.14: Plots showing estimated, marginal posterior distributions for Î¼j, j = 1, . . . , 6,
for the animal ERP data
203

5.4. Taking a random walk
Value
Density
0
0.45
0.9
1.35
1.8
2.25
âˆ’0.2
0.5
1.2
1.9
2.6
Value
Density
0
0.35
0.7
1.05
1.4
1.75
0.4
1.1
1.8
2.5
3.2
Value
Density
0
0.25
0.5
0.75
1
1.25
âˆ’0.1
0.6
1.3
2
2.7
Value
Density
0
0.55
1.1
1.65
2.2
2.75
2.6
3.3
4
4.7
5.4
Value
Density
0
0.22
0.44
0.66
0.88
1.1
1.4
2.1
2.8
3.5
4.2
Value
Density
0
0.25
0.5
0.75
1
1.25
4.3
5
5.7
6.4
7.1
Î¼1
Î¼2
Î¼3
Î¼4
Î¼5
Î¼6
Figure 5.15: Plots showing estimated, marginal posterior distributions for Î¼j, j = 1, . . . , 6,
for the distractor ERP data
204

5.4. Taking a random walk
with unknown A, Ïƒ2 and Î¼. Recall that, for this dataset, we have d = 9 and N = 40.
Moreover, we let p = 8
9 and retain the remaining speciï¬cations from before. The genes
considered in the study are displayed in Table 4.4.
0
2000
4000
6000
8000
10000
âˆ’920
âˆ’910
âˆ’900
Trace plot of L(q)
Iteration
L(q)
0
20
40
60
80
100
0.0
0.2
0.4
0.6
0.8
1.0
Lag
ACF
ACF plot for L(q)
Histogram of L(q)
L(q)
Frequency
âˆ’920
âˆ’915
âˆ’910
âˆ’905
âˆ’900
âˆ’895
0
500
1000
1500
0
1
2
3
4
5
6
7
8
9
0
1
2
3
4
5
6
7
8
9
Image plot for Pihat
Row
Col
Figure 5.16: Plots for the analysis of the MCMC output for the microarray data (non-zero
mean)
The output of the scheme, displayed in Figure 5.16, is now analysed. It is clear from the
trace and ACF plots that the chain is moving rapidly through the space and contains
many independent values. Furthermore, the Raftery-Lewis test yielded
Iterations = 1:9900
Thinning interval = 1
Number of chains = 1
Sample size per chain = 9900
Quantile (q) = 0.025
Accuracy (r) = +/- 0.005
Probability (s) = 0.95
205

5.4. Taking a random walk
Burn-in
Total Lower bound
Dependence
(M)
(N)
(Nmin)
factor (I)
Lq
2
3812
3746
1.02
whilst Heidelberger-Welch produced
Stationarity start
p-value
test
iteration
Lq
passed
1
0.528
Halfwidth Mean
Halfwidth
test
Lq
passed
-905
0.0525
Thus, it can be suggested conï¬dently that the stationary distribution of the chain has
been reached. When examining the image plot, we see that there are similarities with
that in the zero mean case (c.f. Figure 4.20). For instance, kinA causes a reaction in
a distinct gene, namely spo0F, as opposed to inï¬‚uencing itself at the next time point.
However, on this occasion, a new link is determined from spoOF to clpP whereas the
aï¬€ect of spoIIAA over spo0B is scarcely recognised. In fact, there may exist other such
edges between diï¬€erent genes, although these associations seem rather weak.
Finally, the approximate posterior information for the coeï¬ƒcients aij and Î¼j is revealed in
Figures 5.17 and 5.18 respectively. As in the zero mean case, the only non-zero coeï¬ƒcients
of A shown are a11 and a22, although the possible value of a22 appears to be marginally
smaller than before. On the other hand, most of the densities pvar(Î¼j | D) have negative
modal values. Again, for a larger dataset, we would expect these densities to be more
tightly peaked, and hence the same links would be suggested in the image plots for when
the mean was both zero or otherwise.
206

5.4. Taking a random walk
Value
0
0.6
1.2
1.8
2.4
3
0
0.4
0.8
1.2
Density
0
0.2
0.4
0.6
0.8
1
Probability
Value
0
0.55
1.65
2.75
âˆ’0.4
0
0.4
0.8
Density
0
0.2
0.6
1
Probability
Value
0
0.35
1.05
1.75
âˆ’0.4
0
0.4
0.8
1.2
Density
0
0.2
0.4
0.6
0.8
1
Probability
Value
0
0.8
1.6
2.4
3.2
4
âˆ’0.7
âˆ’0.3
0.1
0.5
Density
0
0.2
0.4
0.6
0.8
1
Probability
Value
0
0.7
1.4
2.1
2.8
3.5
0
0.4
0.8
1.2
Density
0
0.2
0.4
0.6
0.8
1
Probability
Value
0
0.45
1.35
2.25
âˆ’0.8
âˆ’0.4
0
0.4
Density
0
0.2
0.4
0.6
0.8
1
Probability
Value
0
0.95
2.85
4.75
âˆ’0.6
âˆ’0.2
0.2
0.6
Density
0
0.2
0.4
0.6
0.8
1
Probability
Value
0
0.6
1.8
3
âˆ’0.4
0
0.4
0.8
Density
0
0.2
0.6
1
Probability
Value
0
0.85
2.55
4.25
âˆ’0.4
0
0.4
0.8
Density
0
0.2
0.4
0.6
0.8
1
Probability
a11
a12
a13
a21
a22
a23
a31
a32
a33
Figure 5.17: Plots showing estimated, marginal posterior distributions for aij, i, j =
1, 2, 3, for the microarray data (non-zero mean)
207

5.4. Taking a random walk
Value
Density
0
0.3
0.6
0.9
1.2
1.5
âˆ’1.4
âˆ’0.9
âˆ’0.4
0.1
0.6
Value
Density
0
0.4
0.8
1.2
1.6
âˆ’2.6
âˆ’2.1
âˆ’1.6
âˆ’1.1
âˆ’0.6
Value
Density
0
0.4
0.8
1.2
1.6
2
âˆ’3.2
âˆ’2.7
âˆ’2.2
âˆ’1.7
âˆ’1.2
Value
Density
0
0.8
1.6
2.4
3.2
4
âˆ’1
âˆ’0.5
0
0.5
1
Value
Density
0
0.24
0.48
0.72
0.96
1.2
âˆ’0.7
âˆ’0.2
0.3
0.8
1.3
Value
Density
0
0.3
0.6
0.9
1.2
1.5
âˆ’2.1
âˆ’1.6
âˆ’1.1
âˆ’0.6
âˆ’0.1
Î¼1
Î¼2
Î¼3
Î¼4
Î¼5
Î¼6
Figure 5.18: Plots showing estimated, marginal posterior distributions for Î¼j, j = 1, . . . , 6,
for the microarray data
208

Chapter 6
Conclusions and further work
6.1
Conclusions
In this thesis, the predominant focus has been to illustrate how variational Bayesian
methods can be applied so that sparse VAR(1) graphical models may be scored. As noted,
this approximation has been utilised previously by Penny and Roberts (2002) in zero mean
VAR(p) models for the purpose of model-order selection, itself a signiï¬cant, inferential
problem. Here however, our wish was to estimate the unknown sparsity structure of the
autoregressive matrix A in both zero and non-zero mean processes, as seen respectively
in Chapters 3 and 5.
To rank models, we realise that an inherent feature of variational Bayes methodology is
that a lower bound is formed on the logarithm of the marginal likelihood, an essential
statistic for Bayesian model comparison. At the same time, an attractive beneï¬t of the
approach is that a global approximation can also be made to each parameter posterior
by minimising the KL divergence between the true and variational distribution.
The
optimality of every estimate is ensured by iterating update equations that are derived
for the corresponding set of variational parameters until convergence. It was shown via
209

6.1. Conclusions
example in Chapter 2 that such an approximation competes favourably with that of the
EM algorithm and Gibbsâ€™ sampling.
An additional advantage here is that variational distributions may be determined by either
a free form or ï¬xed form approach. Of course, this proved to be of importance in both
Chapters 3 and 5. If A was dense, application of the free form method was possible to
ï¬nd q(a | D). However, in the sparse case, the most natural and straightforward way to
proceed was to assume ï¬xed forms for the variational posteriors, namely those suggested
by the free form approach. A toy example based upon simulated data was considered in
both the zero and non-zero mean cases, and positive results were produced. In particular,
the model possessing the true sparsity structure was ranked highest in each case and,
when unknown, the mean of the process was accurately estimated.
In Chapter 4, an MCMC algorithm was constructed to traverse quickly graphical spaces
of higher dimensions. Any move to a neighbouring graph was proposed by the addition
or deletion of a single edge from the current graph, and accepted in accordance with
a Metropolis-Hastings acceptance probability. Throughout the scheme, a Markov chain
of accepted lower bounds was formed, enabling exploration of an approximation to the
model posterior distribution. For analysis purposes, image plots could be produced to
display which edges were accepted most frequently during the run. Moreover, the probable
values of the coeï¬ƒcients aij could be determined by estimating both P(aij = 0 | D) and
the marginal density p(aij | aij Ì¸= 0, D). Similarly, in Chapter 5, an approximate posterior
summary could also be provided for each coeï¬ƒcient of the mean vector.
The algorithm was tested on several datasets of varying dimension, simulated from both
zero and non-zero mean VAR(1) models. In this case, the results produced throughout
accurately predicted the true speciï¬cations. Moreover, two sets of real time series data
were also considered. Initially, for the 32-electrode ERP datasets, we concluded that the
networks required to process the information of target and non-target photographs were
similar, independently of whether the mean was equal to zero or otherwise. Then, for the
210

6.2. Further work
microarray data, it was possible to discover which genes were inï¬‚uential in determining
whether an organism should sporulate. So, in summary, upon modelling a real dataset by
a zero or non-zero mean VAR(1) process, we can use our algorithm to locate high scoring
models with computational eï¬ƒciency in graphical spaces of potentially huge dimension.
6.2
Further work
We consider brieï¬‚y how the methodology that is comprised within this thesis could be
extended. Recall that, in Chapter 3, the VAR(1) model was speciï¬ed such that the noise
vector et was distributed with covariance matrix Î“ = Ïƒ2Id. Thus, a simple direction to
take would be to implement the variational Bayesian approach for ranking sparse VAR(1)
models when Î“ was no-longer constrained. In this case, the most natural way to proceed
would be to place an inverse Wishart prior on Î“. Alternatively, we could examine the
scenario when the noise is modelled as a mixture of Gaussian distributions, as opposed
to the standard single Gaussian. This has been tackled previously to identify the optimal
model order by Roberts and Penny (2002).
However, an additional area of research that is perhaps most clearly motivated here is
to compare sparse VAR(p) models. Now, our task would be to determine the sparsity
structure of all p autoregressive matrices in the process, where each A(i) is of dimension
d Ã— d. By deï¬ning xt = [ytâˆ’1, ytâˆ’2, . . . , ytâˆ’p] where t = 1 . . . , N, we could follow Penny
and Roberts (2002) and rewrite (3.1) as
yt = xtW + et.
Here, W is a pd Ã— d matrix, formed by stacking the A(i)-matrices. Thus, by specifying
a prior on vec(W) that imposes the correct sparsity structure for each model, the vari-
ational algorithm could proceed as before. In particular, it would be interesting to see
211

6.2. Further work
how eï¬€ectively our Metropolis-Hastings algorithm could handle moving through graphical
spaces of such extreme dimension.
Of course, we are not restricted to model time series data using just VAR processes. Hence
ï¬nally, it is noted that the variational Bayes treatment could be given to such alternatives.
For instance, one possibility is the VARMA(p, q) (vector autoregressive moving average)
process, deï¬ned as
yt =
p

i=1
ytâˆ’iA(i) + et +
q

j=1
etâˆ’jÏ†(j),
where again et âˆ¼N (0, Î“). Thus, for i = 1, . . ., p and j = 1, . . . , q, our parameter set
would be {A(i), Ï†(j), Î“}, where each Ï†(j) has dimension d Ã— d. For further information
on this and other related models, the reader is referred to LÂ¨utkepohl (2005).
212

Appendix A
Probability distributions
In this appendix, some standard, continuous probability distributions are documented.
In each case, the probability density function is deï¬ned, together with any salient expec-
tations, taken with respect to this density.
A.1
Gaussian distribution
The Gaussian (normal) distribution with mean m and variance v > 0 is denoted as
p(x | m, v) = N (x | m, v)
=
1
âˆš
2Ï€v exp

âˆ’(x âˆ’m)2
2v

.
(A.1)
An important result is that
E

X2
= m2 + v.
(A.2)
213

A.2. Inverse gamma distribution
A.2
Inverse gamma distribution
With support wherever x > 0, the density of the inverse gamma distribution is
p(x | a, b) = IG(x | a, b)
=
ba
Î“(a)xâˆ’(a+1) exp

âˆ’bxâˆ’1
,
(A.3)
with parameters a, b > 0. We realise three pertinent identities for this distribution.
E {X} =
b
a âˆ’1
for a > 1
(A.4)
E

Xâˆ’1
= a
b
(A.5)
E {log X} = log b âˆ’Ïˆ(a),
(A.6)
by both Beal (2003) and Nicolas (2002).
Here, for z âˆˆR, we deï¬ne Ïˆ(z) to be the
digamma function (Johnson et al., 1992), i.e. the logarithmic derivative of the gamma
function, given by
Ïˆ(z) = d
dz log Î“(z) = Î“
â€²(z)
Î“(z) .
A.3
Multivariate Gaussian distribution
The univariate Gaussian can be generalised to d dimensions with density
p(x | m, V ) = N (x | m, V )
= (2Ï€)âˆ’d/2 |V |âˆ’1/2 exp

âˆ’1
2(x âˆ’m)TV âˆ’1(x âˆ’m)

,
(A.7)
where m = (m1, . . ., md) is the mean vector and V is the symmetric, positive-deï¬nite,
214

A.4. Inverse Wishart distribution
d Ã— d covariance matrix. Akin to the univariate case, we have
E

XXT
= mmT + V.
(A.8)
A.4
Inverse Wishart distribution
A multivariate generalisation of the inverse gamma distribution is the inverse Wishart,
with density function for d Ã— d matrix X given by Oâ€™Hagan et al. (1994) as
p(X | B, r) = IW(X | B, r)
= kâˆ’1|B|r/2|X|âˆ’(r+d+1)/2 exp

âˆ’Tr
$
Xâˆ’1B
%
/2

,
(A.9)
where the normalising constant is
k = 2rd/2Ï€d(dâˆ’1)/4
d

i=1
Î“ {(r + 1 âˆ’i)/2} .
(A.10)
The parameters of this distribution are B, a symmetric, positive deï¬nite, d Ã— d matrix
and a scalar r > d. The afore-mentioned authors also indicate that
E {X} =
B
r âˆ’d âˆ’1
for r > d + 1
E

Xâˆ’1
= rBâˆ’1.
(A.11)
215

Appendix B
Graphical Models
The main focus of this appendix is to introduce the concept of a graphical model. This
will lead us to examine brieï¬‚y both graphical Gaussian models and Bayesian networks.
Initially, we deï¬ne conditional independence, the key notion that characterises a graphical
model.
B.1
Conditional Independence
Suppose we have two random variables, X1 and X2, possessing a joint probability density
function pX1, X2. Then, these random variables are independent, written X1 âŠ¥âŠ¥X2, if
pX1, X2(x1, x2) = pX1(x1)pX2(x2). An equivalent formulation is pX1 | X2(x1 | x2) = pX1(x1),
i.e.
the conditional density of X1, given X2 = x2, is not a function of x2, and that
pX2 | X1(x2 | x1) = pX2(x2).
Now, introduce a third variable, X3. We say X1 and X2 are conditionally independent
given X3, written X1 âŠ¥âŠ¥X2 | X3, if X1 and X2 are independent in their conditional
distribution given X3 = x3, for any value of x3.
In other words, given knowledge of
X3, subsequent understanding of X2 will not provide any new information about X1.
216

B.2. Graph theory
Conditional independence can be characterised in terms of density functions as follows:
X1 âŠ¥âŠ¥X2 | X3 â‡â‡’pX1, X2 | X3(x1, x2 | x3) = pX1 | X3(x1 | x3)pX2 | X3(x2 | x3)
(B.1)
â‡â‡’pX1 | X2, X3(x1 | x2, x3) = pX1 | X3(x1 | x3)
(B.2)
â‡â‡’pX2 | X1, X3(x2 | x1, x3) = pX2 | X3(x2 | x3).
(B.3)
B.2
Graph theory
Some standard notation and terminology for graphs is recalled. For further discussion,
the reader is referred to Cowell et al. (1999).
By deï¬nition, a graph is a pair G = (V, E), whereby V is a ï¬nite set of nodes (or vertices)
and E a set of edges of ordered pairs of nodes. If, for two nodes a and b, (a, b) âˆˆE and
(b, a) âˆˆE, the edge between them is described as undirected, written a âˆ¼b (represented
on a graph by a line between the two nodes). Thus, a and b are described as neighbours.
On the contrary, if (a, b) âˆˆE, but (b, a) /âˆˆE, the edge is called directed, written a â†’b
(represented on a graph by an arrow from a to b). In this case, a is termed as a parent
of b, and b one of the children of a. We denote pa(b) to be the set of parents of the node
b, similarly ch(a) the set of children of a. The boundary, bd(a), of a âˆˆV is the set of
parents and neighbours of this node. Moreover, the closure, cl(a), is the set a âˆªbd(a).
If a graph possesses only directed edges, it is referred to as a directed graph, similarly an
undirected graph. If an edge exists between every pair of nodes, the graph is complete.
A sequence of distinct nodes a = a0, . . . , an = b, such that ajâˆ’1 âˆ¼aj for all j = 1, . . ., n,
forms a path from a to b of length n. If the path is such that a = b, i.e. the end-points
coincide, it is referred to as an n-cycle. A path from a to b, given by the same set of nodes
as above, is described as directed if it contains at least one directed edge ajâˆ’1 â†’aj for
any j. In this case, a is an ancestor of b and b one of the descendants of a. Denote an(b)
217

B.3. Undirected graphical models
to be the set of ancestors of b, similarly de(a) the set of descendants of a. The deï¬nition
of a directed n-cycle follows immediately. A graph without any cycles is called acyclic.
Finally, suppose that A, B and C are subsets of V. If all paths from A to B intersect C,
then C is deemed to separate A and B. The theory presented here is important for what
ensues in this appendix.
B.3
Undirected graphical models
Let G = (V, E) be an undirected graph and X = (X1, . . . , Xp)T a p-dimensional random
vector. If the graph has p nodes, then a random variable Xa is associated to each node for
all a âˆˆV where, of course, V = {1, . . ., p}. In general, note that, on any graph, a circle
is used to represent a continuous random variable, a dot for a discrete variable. Here,
we are concerned with the former case. Now, suppose a subset A âŠ†V . We thus denote
XA = (Xa : a âˆˆA) to be a collection of random variables.
Furthermore, introduce P, a probability distribution for X. If A âŠ†V , then let PA denote
the marginal distribution for XA. Thus, an important deï¬nition is realised.
Deï¬nition 1 Assume that A, B, C are disjoint subsets of V . If XA âŠ¥âŠ¥XB | XC whenever
C separates A and B in the graph G, the distribution P is said to be Markov with respect
to G.
This is known as the global Markov property. We stress that, on the graph, if two nodes
are conditionally independent, no edge exists between them. It is worth mentioning that
other such Markov properties exist over graphs.
Deï¬nition 2 If Xa âŠ¥âŠ¥XV \cl(a) | Xbd(a) for any a âˆˆV , a distribution P obeys the local
Markov property with respect to a graph G.
218

B.3. Undirected graphical models
Moreover, if Xa âŠ¥âŠ¥Xb | XV \{a, b} for any pair (a, b) /âˆˆE, then, relative to a graph, the
pairwise Markov property is satisï¬ed. These properties are important since they show
that any conditional independencies that can be determined from the graph also hold in
the corresponding probability distribution. Further analysis of these Markov properties
is provided by Lauritzen (1996). Finally, an undirected graphical model (also termed a
Markov network) for X is a joint probability distribution for X, that is Markov (obeys
the global Markov property) with respect to an undirected graph G.
If the distribution is multivariate Gaussian, say N (x | Î¼, Î£), then a graphical Gaussian
model is so deï¬ned. We now examine the conditional independencies between random
variables, inherent in such a model. Thus, let K = Î£âˆ’1 be the concentration (preci-
sion) matrix for such a multivariate Gaussian. Speed and Kiiveri (1986) illustrate that
K determines the conditional independence structure of a graphical Gaussian model as
follows.
Proposition 1 Let a, b âˆˆ{1, . . ., p} be distinct nodes on an undirected graph G, giv-
ing rise to a graphical Gaussian model, parameterised by mean vector Î¼ and covari-
ance matrix Î£.
Deï¬ning the corresponding concentration matrix as K = (kab), then
Xa âŠ¥âŠ¥Xb | XV \{a, b} (pairwise Markov property) if and only if kab = 0.
So, for a given K, a graph can be associated and its independencies identiï¬ed. Moreover,
a given graph determines a sparse matrix K. Of course, as the graph is undirected and
with K symmetric, if kab = 0, then kba = 0, implying Xb âŠ¥âŠ¥Xa | XV \{a, b}. Thus, in this
case, no edge would exist between nodes a and b. To clarify, consider this simple example.
219

B.3. Undirected graphical models
B.3.1
Example
Suppose that the random vector X = (X1, X2, X3, X4)T is modelled via a multivariate
Gaussian distribution, with concentration matrix K speciï¬ed as
K =
âŽ›
âŽœ
âŽœ
âŽœ
âŽœ
âŽœ
âŽœ
âŽœ
âŽ
âˆ—
âˆ—
âˆ—
âˆ—
âˆ—
âˆ—
0
0
âˆ—
0
âˆ—
0
âˆ—
0
0
âˆ—
âŽž
âŽŸ
âŽŸ
âŽŸ
âŽŸ
âŽŸ
âŽŸ
âŽŸ
âŽ 
,
where âˆ—refers to an unspeciï¬ed, non-zero element. Then, a graphical Gaussian model is
deï¬ned, with respect to the graph below.
X1
X2
X3
X4
Figure B.1: 4-node graph, corresponding to the choice of K
Using Proposition 1, the subsequent conditional independencies are apparent: X2 âŠ¥âŠ¥
X3 | {X1, X4}, X2 âŠ¥âŠ¥X4 | {X1, X3} and X3 âŠ¥âŠ¥X4 | {X1, X2}.
Similarly, the reverse
independencies, such as X3 âŠ¥âŠ¥X2 | {X1, X4}, also hold.
220

B.4. Bayesian networks
B.4
Bayesian networks
Let G = (V, E) now be a directed graph and suppose that we have again the random
vector X = (X1, . . . , Xp)T. Here, a directed edge implies a causal dependence between
a pair of nodes. So if Xa â†’Xb for a, b âˆˆ{1, . . . , p}, then we say that Xa causes (or
inï¬‚uences) Xb. Moreover, whenever G contains no directed cycles, then it is referred to
as a directed acyclic graph (DAG). On any DAG, a (non-unique) ordering of the nodes
can be found such that Xa â†’Xb only when a < b, i.e. every node follows its parents in
the ordering.
Introducing a distribution P for X, we now present an analogue to Deï¬nition 2 for the
directed case.
Deï¬nition 3 Let nd(Xa) represent the set of non-descendants of Xa for a âˆˆV . Then, if
Xa âŠ¥âŠ¥nd(Xa) | pa(Xa), the distribution P obeys the directed local Markov property with
respect to a directed acyclic graph G.
Although not treated here, there are also directed counterparts to the (undirected) global
and pairwise Markov properties. In contrast to the undirected case, the directed local and
global Markov properties are equivalent over a DAG (Lauritzen 1996, pg. 33, 51). Thus,
if either of these two properties is satisï¬ed, P is termed a directed Markov distribution
(c.f. Deï¬nition 1). Finally, a Bayesian network (also termed a belief network) for X is
a joint probability distribution for X, that is directed Markov (obeys the directed global
Markov property) with respect to G, a DAG.
Essentially, a Bayesian network is merely a directed, acyclic graphical model, containing
an ordering of the nodes. We note that this ordering is consistent with the DAG, but
is otherwise arbitrary. Of course, any conditional independencies between variables can
be simply read oï¬€the graph. Moreover, the probability distribution for X can be fac-
torised according to the DAG (Cowell, 1998). The condition Xa âŠ¥âŠ¥nd(Xa) | pa(Xa),
221

B.4. Bayesian networks
determining the directed local Markov property, can be re-expressed, in general, as
Xa âŠ¥âŠ¥X1, . . . , Xaâˆ’1 | pa(Xa). This is because Xb /âˆˆde(Xa) if b < a. So, in terms of
densities and dropping subscripts on p, we have
p(xa | x1, . . . , xaâˆ’1) = p(xa | pa(xa)),
by (B.2). Hence, the full distribution can be factorised with density
p(x1, . . . , xp) = p(x1)p(x2 | x1)p(x3 | x1, x2) Ã— Â· Â· Â· Ã— p(xp | x1, . . ., xpâˆ’1)
=
p

a=1
p(xa | x1, . . . , xaâˆ’1)
=
p

a=1
p(xa | pa(xa)).
(B.4)
In other words, the joint density, represented by the graph, consists of a product of
marginal densities for each node, conditioned on the parents of that node. It is evident
that this ï¬nal factorisation is independent of the (arbitrary) choice of ordering.
B.4.1
Example
As a straightforward illustration, Figure B.2 shows a simple, directed acyclic graph, which
deï¬nes a Bayesian network for X = (X1, . . . , X6)T, possessing a joint density p(x1, . . . , x6).
X1
X3
X5
X2
X4
X6
Figure B.2: 6-node DAG
222

B.4. Bayesian networks
Then, by (B.4), it is evident from the graph that
p(x1, . . . , x6) = p(x1)p(x2 | x1)p(x3 | x2, x1)p(x4)p(x5 | x3)p(x6 | x3, x4).
Hence, for instance, it follows that X6 âŠ¥âŠ¥X1 | {X3, X4}, X5 âŠ¥âŠ¥X1 | X3, etc.
223

Appendix C
Generalised inverses
Every non-singular, square matrix P possesses a unique inverse, denoted by P âˆ’1, whereby
PP âˆ’1 = P âˆ’1P = I.
(C.1)
The inverse matrix itself has many properties, for instance, (P âˆ’1)âˆ’1 = P, (P T)âˆ’1 =
(P âˆ’1)T and (aP)âˆ’1 = aâˆ’1P âˆ’1 for all non-zero a âˆˆR etc. However, as we have seen in
both Chapters 3 and 5, it can be the case that we want to ï¬nd an inverse matrix when P
is singular or even not square. To eï¬€ect this, we search for a generalised inverse (termed
by some authors as a pseudoinverse), with similar properties to the standard inverse of a
square, non-singular matrix.
Initially, we have the following deï¬nition.
Deï¬nition 4 A generalised inverse of a mÃ—p matrix P is any pÃ—m matrix G such that
PGP = P.
(C.2)
224

Appendix C. Generalised inverses
Let P âˆ’denote an arbitrary generalised inverse of such a matrix P. Hence, PP âˆ’P =
P.
In the speciï¬c case of P being square and non-singular, then this matrix has a
unique generalised inverse, the standard inverse P âˆ’1. Clearly, when G = P âˆ’1, the above
generalised inverse condition is satisï¬ed. Moreover, if G is a generalised inverse of P,
then, by deï¬nition, G = P âˆ’1PGPP âˆ’1 = P âˆ’1PP âˆ’1 = P âˆ’1 (Harville, 1997).
Some of the properties of the standard inverse can correspond to an arbitrary generalised
inverse, proven by direct substitution into (C.2). For instance, if P is m Ã— p, then one
choice of (P T)âˆ’is (P âˆ’)T. In this case, P T(P âˆ’)TP T = (PP âˆ’P)T = P T, hence (C.2) is
satisï¬ed. In addition, aâˆ’1P âˆ’is a generalised inverse of aP where a âˆˆR and is non-zero.
However, it is not necessarily true that one choice of (P âˆ’)âˆ’is P.
The generalised inverse as deï¬ned above exists for any matrix, but is not unique. In fact,
for a mÃ—p matrix P of rank r, there are an inï¬nite number of generalised inverses (Harville,
1997). So, an alternative, unique generalised inverse has been considered, initially by
Moore (1920) and then independently by Penrose (1955), which now must hold for several
constraints.
Deï¬nition 5 The Moore-Penrose inverse of any m Ã— p matrix P is the unique p Ã— m
matrix G that holds for the following conditions:
PGP
=
P
(C.3)
GPG
=
G
(C.4)
(PG)T
=
PG
(C.5)
(GP)T
=
GP.
(C.6)
Let P + denote the Moore-Penrose inverse (often referred to as the generalised inverse) of
such a matrix P. We realise that other generalised inverses exist that meet (C.3) and a
combination of the properties (C.4)â€“(C.6). See Ben-Israel and Greville (1974) or Harville
225

Appendix C. Generalised inverses
(1997) for more details.
When P is square and non-singular, then, similar to the case as that of any generalised
inverse, P + = P âˆ’1. We realise this since P has a unique generalised inverse, as mentioned
earlier, and that G = P âˆ’1 holds for conditions (C.3)â€“(C.6).
The Moore-Penrose inverse possesses some properties that are in common with both an
arbitrary generalised inverse, P âˆ’, and the standard inverse, P âˆ’1. For instance, analogous
to previous, (P T)+ = (P +)T and (aP)+ = aâˆ’1P + for all non-zero a âˆˆR. However, unlike
P âˆ’, we now have (P +)+ = P. Such results are proven by direct substitution into (C.3)â€“
(C.6) (Harville, 1997). Other such properties of the Moore-Penrose inverse do not hold
for any generalised inverse. For a complete list, see Rao (1966).
A simple way to compute P + is to use matrix decomposition. Here, we examine one of
the more popular methods, used in this context by Rao (1962).
Deï¬nition 6 The singular value decomposition of any mÃ—p matrix P of rank r is deï¬ned
to be
P = U
âŽ¡
âŽ£S
0
0
0
âŽ¤
âŽ¦V T,
(C.7)
where U and V are mÃ—m and pÃ—p orthogonal matrices respectively (i.e. UTU = UUT =
Im, similarly for V ) and S = diag(Ïƒ1, Ïƒ2, . . . , Ïƒr), an r Ã— r matrix with strictly positive
diagonal elements.
In this deï¬nition, the Ïƒi, i = 1, . . . , r are the singular values of P and are unique. Note
that P is of rank r since it has r non-zero singular values.
Harville (1997) shows that the Moore-Penrose inverse of P with this singular value de-
composition is given by
P + = V
âŽ¡
âŽ£S
0
0
0
âŽ¤
âŽ¦
+
UT,
(C.8)
226

Appendix C. Generalised inverses
where
âŽ¡
âŽ£S
0
0
0
âŽ¤
âŽ¦
+
=
âŽ¡
âŽ£S+
0
0
0
âŽ¤
âŽ¦.
At this stage, it can be realised that for any D = diag(d1, d2, . . . , dr), an r Ã— r diagonal
matrix, then D+ = diag(d+
1 , d+
2 , . . . , d+
r ), whereby, for all i,
d+
i =
âŽ§
âŽ¨
âŽ©
dâˆ’1
i
if di Ì¸= 0
0
if di = 0
.
(C.9)
Thus, S+ = diag(Ïƒâˆ’1
1 , Ïƒâˆ’1
2 , . . . , Ïƒâˆ’1
r ).
The proof is quite straightforward. We note that, as S is diagonal and the product of two
diagonal matrices is merely the product of each pair of diagonal entries, S+, as deï¬ned
above, holds for the conditions (C.3)â€“(C.6), and hence is the Moore-Penrose inverse of
S. Moreover, by substituting (C.7) and (C.8) directly into conditions (C.3)â€“(C.6), then
it is easy to see that (C.8) is the Moore-Penrose inverse of (C.7), as U and V are both
orthogonal.
227

Bibliography
Aitkin, M. (1991). Posterior Bayes factors (with discussion). Journal of the Royal Statis-
tical Society, Series B 53, 111â€“142.
Akaike, H. (1974). A new look at statistical model identiï¬cation. IEEE Transactions on
Automatic Control 19, 716â€“723.
Beal, M. (2003). Variational algorithms for approximate Bayesian inference. Ph. D. thesis,
Gatsby Computational Neuroscience Unit, University College London.
Beal, M., F. Falciani, Z. Ghahramani, C. Rangel, and D. Wild (2005).
A Bayesian
approach to reconstructing genetic regulatory networks with hidden factors. Bioin-
formatics 21(3), 349â€“356.
Ben-Israel, A. and T. Greville (1974). Generalized Inverses: Theory and Applications.
New York, Wiley.
Berger, J. and L. Pericchi (1996). The Intrinsic Bayes factor for model selection and
prediction. Journal of the American Statistical Association 91(433), 109â€“122.
Berger, J. and T. Sellke (1987). Testing a point null hypothesis: the irreconcilability
of p-values and evidence. Journal of the American Statistical Association 82(397),
112â€“122.
Box, G. and G. Tiao (1992). Bayesian Inference in Statistical Analysis. New York, Wiley.
228

BIBLIOGRAPHY
Brooks, S. (2002). Discussion on Bayesian measures of model complexity and ï¬t (by D.J.
Spiegelhalter et al). Journal of the Royal Statistical Society, Series B 64(4), 616â€“618.
Burnham, K. and D. Anderson (2004). Multimodel inference: Understanding AIC and
BIC in model selection. Sociological Methods and Research 33(2), 261â€“304.
Chipman, H., E. George, and R. McCulloch (2001). The practical implementation of
Bayesian model selection. In P. Lahiri (Ed.), Model Selection, Volume 38, pp. 67â€“
116. IMS, Beachwood, OH.
Cowell, R. (1998). Introduction to inference in Bayesian networks. In M. Jordan (Ed.),
Learning in Graphical Models, pp. 9â€“26. Kluwer.
Cowell, R., A. Dawid, S. Lauritzen, and D. Spiegelhalter (1999). Probabilistic Networks
and Expert Systems. Springer-Verlag, New York.
Dahlhaus, R. and M. Eichler (2003). Causality and graphical models in time series anal-
ysis. In P. Green, N. Hjort, and S. Richardson (Eds.), Highly Structured Stochastic
Systems, pp. 115â€“137. Oxford University Press.
Delorme, A., G. Rousselet, M.-M. MacÂ´e, and M. Fabre-Thorpe (2004). Interaction of
top-down and bottom-up processing in the fast visual analysis of natural scenes.
Cognitive Brain Research 19(2), 103â€“113.
Dempster, A., N. Laird, and D. Rubin (1977). Maximum likelihood from incomplete data
via the EM algorithm. Journal of the Royal Statistical Society, Series B 39(1), 1â€“38.
Eichler, M. (2001). Markov properties for graphical time series models. Technical report,
Department of Statistics, University of Heidelberg.
Fletcher, R. (2000). Practical Methods of Optimization (2nd ed.). Wiley.
Friedman, N., K. Murphy, and S. Russell (1998). Learning the structure of dynamic prob-
abilistic networks. In Fourteenth Conference on Uncertainty in Artiï¬cial Intelligence,
pp. 139â€“147.
229

BIBLIOGRAPHY
Gelman, A. (2006). Prior distributions for variance parameters in hierarchical models.
Bayesian Analysis 1(3), 515â€“533.
Gelman, A., J. Carlin, H. Stern, and D. Rubin (1995). Bayesian Data Analysis. Chapman
and Hall.
Gelman, A. and D. Rubin (1992).
Inference from iterative simulation using multiple
sequences. Statistical Science 7(4), 457â€“511.
Geman, S. and D. Geman (1984).
Stochastic relaxation, Gibbs distributions and the
Bayesian restoration of images. IEEE Transactions on Pattern Analysis and Machine
Intelligence 6, 721â€“741.
Ghahramani, Z. (1997). Learning Dynamic Bayesian Networks. In C. Giles and M. Gori
(Eds.), Adaptive Processing of Temporal Information, Lecture Notes in Artiï¬cial In-
telligence, pp. 168â€“197. Berlin, Springer-Verlag.
Ghahramani, Z. (2004).
Unsupervised Learning.
In O. Bousquet, U. von Luxburg,
and G. Raetsch (Eds.), Advanced Lectures in Machine Learning, pp. 72â€“112. Berlin,
Springer-Verlag.
Giudici, P. and P. Green (1999). Decomposable graphical Gaussian model determination.
Biometrika 86(4), 785â€“801.
HÂ¨aggstrÂ¨om, O. (2002). Finite Markov Chains and Algorithmic Applications. Cambridge
University Press.
Harville, D. (1997). Matrix Algebra from a Statisticianâ€™s Perspective. New York, Springer.
Hastings, W. (1970).
Monte Carlo sampling methods using Markov chains and their
applications. Biometrika 57(1), 97â€“109.
Heckerman, D., D. Geiger, and D. Chickering (1995). Learning Bayesian networks: The
combination of knowledge and statistical data. Machine Learning 20, 197â€“243.
230

BIBLIOGRAPHY
Heidelberger, P. and P. Welch (1983). Simulation run length control in the presence of
an initial transient. Operations Research 31, 1109â€“1144.
Henderson, H. and S. Searle (1979). Vec and vech operators for matrices, with some uses
in Jacobian and multivariate statistics. The Canadian Journal of Statistics 7(1),
65â€“81.
Henderson, H. and S. Searle (1981). The vec-permutation matrix, the vec operator and
Kronecker products: a review. Linear and multilinear algebra 9, 271â€“288.
Husmeier, D. (2003). Sensitivity and speciï¬city of inferring genetic regulatory interac-
tions from microarray experiments with dynamic Bayesian networks. Bioinformat-
ics 19(17), 2271â€“2282.
Johnson, N., S. Kotz, and A. Kemp (1992). Univariate Discrete Distributions (2nd ed.).
New York, Wiley.
Jones, B., C. Carvalho, A. Dobra, C. Hans, C. Carter, and M. West (2005). Experi-
ments in stochastic computation for high-dimensional graphical models. Statistical
Science 20(4), 388â€“400.
Kass, R. and A. Raftery (1995).
Bayes factors.
Journal of the American Statistical
Association 90(430), 773â€“795.
Kullback, S. and R. Leibler (1951).
On information and suï¬ƒciency.
The Annals of
Mathematical Statistics 22(1), 79â€“86.
Lappalainen, H. and J. Miskin (2000). Ensemble learning. In M. Girolami (Ed.), Advances
in Independent Component Analysis, pp. 76â€“92. Springer-Verlag.
Lauritzen, S. (1996). Graphical Models. Oxford University Press.
Lindley, D. (1991). Discussion on Posterior Bayes factors (by M. Aitkin). Journal of the
Royal Statistical Society, Series B 53, 130â€“131.
231

BIBLIOGRAPHY
LovÂ´asz, L. (1993). Random walks on graphs: A survey. Combinatorics, Paul ErdÂ¨os is
Eighty 2, 353â€“397.
Lucas, J., C. Carvalho, Q. Wang, A. Bild, J. Nevins, and M. West (2006). Sparse statistical
modelling in gene expression genomics. In K. Do, P. Mueller, and M. Vannucci (Eds.),
Bayesian Inference for Gene Expression and Proteomics, pp. 155â€“176. Cambridge
University Press.
LÂ¨utkepohl, H. (2005). New Introduction to Multiple Time Series. Springer-Verlag.
MacKay, D. (1995a). Developments in probabilistic modelling with neural networks â€“
ensemble learning. In Neural Networks: Artiï¬cial Intelligence and Industrial Appli-
cations. Proceedings of the 3rd Annual Symposium on Neural Networks, Nijmegen,
Netherlands, pp. 191â€“198. Springer.
MacKay, D. (1995b). Probable networks and plausible predictions - a review of practical
Bayesian methods for supervised neural networks. Network: Computation in Neural
Systems 6, 469â€“505.
Mihajlovic, V. and M. Petkovic (2001). Dynamic Bayesian Networks: A State of the Art.
Technical report, Computer Science Department, University of Twente.
Miskin, J. (2000). Ensemble learning for independent component analysis. Ph. D. thesis,
University of Cambridge.
Moore, E. (1920). On the reciprocal of the general algebraic matrix. Bulletin of the
American Mathematical Society 26, 394â€“395.
Muirhead, R. (1982). Aspects of Multivariate Statistical Theory. New York, Wiley.
Murphy, K. (2002). Dynamic Bayesian Networks: Representation, Inference and Learn-
ing. Ph. D. thesis, UC Berkeley.
Neudecker, H. (1995). Mathematical properties of the variance of the multinomial distri-
bution. Journal of Mathematical Analysis and Applications 189, 757â€“762.
232

BIBLIOGRAPHY
Newton, M. and A. Raftery (1994). Approximate Bayesian inference with the weighted
likelihood bootstrap (with discussion). Journal of the Royal Statistical Society, Series
B 56(1), 3â€“48.
Nicolas, J. (2002). Introduction to second kind statistics: application of log-moments and
log-cumulants to SAR image law analysis. Traitement du signal 19(3), 139â€“167.
Oâ€™Hagan, A. (1991). Discussion on Posterior Bayes factors (by M. Aitkin). Journal of the
Royal Statistical Society, Series B 53, 136.
Oâ€™Hagan, A. (1995). Fractional Bayes factors for model comparison. Journal of the Royal
Statistical Society, Series B 57(1), 99â€“138.
Oâ€™Hagan, A., A. Stuart, J. Ord, and M. Kendall (1994). Kendallâ€™s Advanced Theory of
Statistics: Bayesian Inference, Volume 2B. Edward Arnold.
Penny, W., S. Kiebel, and K. Friston (2006). Variational Bayes. In K. Friston, J. Ash-
burner, S. Kiebel, T. Nichols, and W. Penny (Eds.), Statistical Parametric Mapping:
The analysis of functional brain images. Elsevier, London.
Penny, W. and S. Roberts (2000). Bayesian methods for autoregressive models. In IEEE
Workshop on Neural Networks for Signal Processing, Sydney, Australia.
Penny, W. and S. Roberts (2002, February). Bayesian multivariate autoregressive models
with structured priors. In IEE Proceedings - Vision, Image, and Signal Processing,
Volume 149, pp. 33â€“41.
Penrose, R. (1955). A generalised inverse for matrices. Proceedings of the Cambridge
Philosophical Society 51, 406â€“413.
Petersen,
K.
and
M.
Pedersen
(2007,
September).
The
Matrix
Cookbook.
http://matrixcookbook.com.
Plummer, M., N. Best, K. Cowles, and K. Vines (2006, March). CODA: Convergence
diagnosis and output analysis for MCMC. R News 6(1), 7â€“11.
233

BIBLIOGRAPHY
Raftery, A. and S. Lewis (1992). How many iterations in the Gibbs sampler? In Bayesian
Statistics 4, pp. 763â€“773. Oxford University Press.
Rao, C. (1962). A note on a generalized inverse of a matrix with applications to problems
in mathematical statistics. Journal of the Royal Statistical Society, Series B 24(1),
152â€“158.
Rao, C. (1966). Generalized inverse for matrices and its applications in mathematical
statistics. In F. David (Ed.), Festschrift for J. Neyman: Research Papers in Statistics,
pp. 263â€“279. London, Wiley.
Rao, C. and S. Mitra (1972). Generalized inverse of a matrix and its applications. In
Proceedings of the Berkeley Symposium on Mathematical Statistics and Probability,
Volume 1, pp. 601â€“620. University of California Press.
Rice, J. (1995). Mathematical Statistics and Data Analysis. Duxbury Press.
Robert, C. (1993). A note on Jeï¬€reys-Lindley paradox. Statistica Sinica 3, 601â€“608.
Robert, C. and D. Titterington (2002). Discussion on Bayesian measures of model com-
plexity and ï¬t (by D.J. Spiegelhalter et al). Journal of the Royal Statistical Society,
Series B 64(4), 621â€“622.
Roberts, S. and W. Penny (2002). Variational Bayes for generalized autoregressive models.
IEEE Transactions on Signal Processing 50(9), 2245â€“2257.
Russell, S. and P. Norvig (2003). Artiï¬cial Intelligence: A Modern Approach (2nd ed.).
Prentice Hall.
Saad, Y. (2003). Iterative Methods for Sparse Linear Systems (2nd ed.). SIAM.
Schwarz, G. (1978). Estimating the dimension of a model. The Annals of Statistics 6(2),
461â€“464.
234

BIBLIOGRAPHY
Scott, J. and J. Berger (2006). An exploration of aspects of Bayesian multiple testing.
Journal of Statistical Planning and Inference 136, 2144â€“2162.
Shafer, G. (1982).
Lindleyâ€™s paradox.
Journal of the American Statistical Associa-
tion 77(378), 325â€“334.
Speed, T. and H. Kiiveri (1986). Gaussian Markov distributions over ï¬nite graphs. The
Annals of Statistics 14(1), 138â€“150.
Spiegelhalter, D., N. Best, B. Carlin, and A. van der Linde (2002). Bayesian measures of
model complexity and ï¬t. Journal of the Royal Statistical Society, Series B 64(4),
583â€“639.
Spiegelhalter, D., A. Thomas, N. Best, and W. Gilks (1995). BUGS: Bayesian inference
using Gibbs sampling, Version 0.50.
Technical report, Medical Research Council
Biostatistics Unit, Institute of Public Health, Cambridge University.
Stoica, P. and Y. SelÂ´en (2004). Model-order selection: A review of information criterion
rules. IEEE Signal Processing Magazine 21(4), 36â€“47.
Winn, J. (2003). Variational message passing and its applications. Ph. D. thesis, Depart-
ment of Physics, University of Cambridge.
235

