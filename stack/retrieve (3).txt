Philosophical Psychology, 2018
VOL. 31, NO. 3, 403–418
https://doi.org/10.1080/09515089.2017.1381679
Marr, Mayr, and MR: What functionalism should now be 
about
M. Chirimuuta
Department of History & Philosophy of Science, University of Pittsburgh, Pittsburgh, PA, USA
ABSTRACT
In this review essay on The Multiple Realization Book by 
Polger and Shapiro, I consider the prospects for a biologically 
grounded notion of multiple realization (MR) which has been 
given too little consideration in the philosophy of mind 
and cognitive science. Thinking about MR in the context 
of biological notions of function and robustness leads to a 
rethink of what would count as a viable functionalist theory 
of mind. I also discuss points of tension between Polger and 
Shapiro’s definition of MR and current explanatory practice in 
neuroscience.
1.  MR 1.0
The thesis that mental states are multiply realized by neural states, and the func-
tionalist theory of the mind given credence by it, are two of the rarest of beasts 
in philosophy: ideas that a near majority of philosophers have subscribed to, and 
for more than one generation. The presumption that the existence of multiple 
realization (MR) is an empirically established fact is part of the explanation of 
the surprising longevity of a non-reductive physicalist consensus. In The Multiple 
Realization Book, Thomas Polger and Lawrence Shapiro challenge that presump-
tion head on with an impressive deployment of arguments and extensive review 
of scientific facts. Without doubt, the MR debate will not be the same again.
Polger and Shapiro’s wide-ranging critical project is intended to undermine the 
entrenched anti-reductive consensus in order to clear the ground for reductive 
theories to thrive (p. 12). The purpose of my essay is to complicate their vision of 
the post-functionalist future. I, for one, have been convinced by Polger and Shapiro 
that the original conception of multiple realization (“MR 1.0”) needs to go—they 
have done a service to philosophy by showing the weaknesses of the received view, 
and written a sophisticated and rewarding book in the process. However, as I 
will argue below, we still need MR. This is because of the centrality of functional 
© 2018 Informa UK Limited, trading as Taylor & Francis Group
KEYWORDS
Functionalism; philosophy 
of neuroscience; multiple 
realization; philosophy of 
biology
ARTICLE HISTORY
Received 13 July 2017 
Accepted 13 July 2017
CONTACT  M. Chirimuuta 
  mac289@pitt.edu

404 
  ﻿M. CHIRIMUUTA
thinking within biology and neuroscience—a topic that Polger and Shapiro do not 
delve into. It is time to imagine a new conception of MR, “MR 2.0,” which I will 
sketch below. First, we must discuss MR 1.0 and the reasons why its time is up.
1.1.  Conditions for multiple realization
In this brief characterization of the original MR thesis, I draw on Putnam (1967, 
1973) and Fodor (1974) rather than the many later publications on the subject. 
On this way of framing things, the question “is mind reducible to brain?” becomes 
“is psychology reducible to neuroscience?”. Psychology deals with functions, neu-
roscience with their realizers. The Fodor–Putnam account comes with the prob-
lematic implication that neuroscience is not relevant to understanding the mind. 
A functionalist metaphysics of mind also leads Fodor and Putnam to bet on there 
being widespread and dramatic instances of multiple realization in nature—if 
a mind, fundamentally, is the a kind of thing that could have been made out of 
anything (Swiss cheese included), then we should expect millions of years of 
evolutionary experiment to have explored this possibility space and thrown up 
at least a few surprisingly different realizations.
Much of Polger and Shapiro’s careful survey of the neuroscientific literature 
(chapters 5 and 6) serves to make a compelling case that this prediction has not 
been borne out by the facts. They utilize their own characterization of MR, devel-
oped, and defended in chapters 3 and 4 (the “official recipe”). Here are the condi-
tions that a comparison of kinds from two different sciences must satisfy in order 
to qualify as a case of multiple realization. This list of requirements is the beating 
heart (or pulsating brain) of the book:
i.	
As and Bs are of the same kind in model or taxonomic system S1.
ii.	 As and Bs are of different kinds in model or taxonomic system S2.
iii.	 The factors that lead the As and Bs to be differently classified by S2 must 
be among those that lead them to be commonly classified by S1.
iv.	 The relevant S2-variation between As and Bs must be distinct from the 
intra-kind variation between As and Bs. (p. 67)
Condition iii ensures that the candidates for different realizations differ in ways 
which are relevant to the function that they are both said to perform. For illus-
trative purposes, Polger and Shapiro return to their old example of the waiter’s 
and two handled corkscrews. The difference in basic design plan (e.g., one vs. two 
pivots) leads to the different S2 classification, while the fact that the properties 
referred to in S2 classification bring about the shared S1 functional classification 
of removing corks means that these are genuinely different realizations of the same 
function. One may worry about reliance on these simple artifacts as the template 
for MR in formidably complex and only partially understood biological systems. 
I will return to this concern below.

PHILOSOPHICAL PSYCHOLOGY﻿ 
  405
Variants of different material constitution do not automatically count as mul-
tiple realizations because of condition iv. Plastic and wooden handled corkscrews 
will differ in strength and weight just as octopus and human eyes differ in their 
focusing ability (p. 42), and human retinas show variation in light capturing pho-
to-pigments which they contain (pp. 104–111). None of these kinds of variations 
multiply realize the function of the eye because they all come within the scope 
of normal within-kind variation. And on the assertion that human and octopus 
eyes are mere variants of the same camera eye design, it turns out Putnam (1967) 
would agree.
In Section 3.3, I will consider whether these conditions for MR are too demand-
ing. Here I will raise a broader point about framing. Polger and Shapiro follow 
Fodor (1974) closely in taking the issue at stake to be about the cross-classification 
of the kinds of different branches of science, restricting their attention narrowly 
on the functionalist’s conception of MR in philosophy of mind. This is all well 
and good if the only aim is to score the dialectical point against functionalism. 
However, there are some problematic features of MR 1.0 which themselves infect 
Polger and Shapiro’s treatment, and limit the usefulness of their analysis to broader 
projects within the philosophy of the mind-brain (e.g., developing accounts of 
explanation in psychology and neuroscience). A major failing of the MR 1.0 frame-
work is that it does not recognize the importance of functional thinking within 
biology (and hence neuroscience), and moreover it pits those who think biology 
and neuroscience are relevant to understanding the mind against those with a 
non-reductionist bent. As will become clear in the course of this essay, this is a 
troubling dichotomy.
2.  Marr—and others—on functional explanation in neuro- and 
cognitive science
Discussions of MR and functionalism within cognitive science itself often bring us 
to David Marr’s three levels. Although he refers to them as levels of “description” 
or “understanding” (Marr, 1982, pp. 24–25), they are often treated by philosophers 
as levels of being, perhaps under the influence of Fodor’s (1974) discussion of 
“kinds” and “properties” of the physical and special sciences, and laws governing 
them. On this Fodorian picture, computational theory describes psychological 
kinds, the “mental”, and its functions; implementation theory describes neural 
kinds, the “physical”—whatever realizes psychological functions. This picture is 
consistent with Polger and Shapiro’s definition of MR as a relationship between 
kinds of different sciences.1
Marr is often erroneously bracketed with Fodor as an advocate of the full 
autonomy of psychology from neuroscience.2 Thus, advocates of computational 
theory and functional description are pitted against those who see the relevance of 
brain science to understanding the mind. However, this invidious choice between 
acknowledging the value either of computational approaches or neural ones is 

406 
  ﻿M. CHIRIMUUTA
eliminated as long as we take Marr at his word as outlining different types of 
explanation of one thing—the visual system. Computational explanation occurs 
within neuroscience, not just psychology3; neuroscience happens also to be in the 
business of discovering mechanisms which implement the proposed functions.
As the vision scientists Frisby and Stone write:
Some take the view that finding a link between a given visual phenomenon and a neu-
rophysiological process counts as a sufficient explanation of that phenomenon. We dis-
agree, as did Marr … A theory of vision should do more than identify a mechanism 
that could implement a given computation: it should also provide a functional (e.g., 
computational) reason why the computation was desirable in the first place. To some 
extent, Marr’s call for a computational account of vision has been taken up in the nas-
cent field of computational neuroscience, where fine-grained analysis of physiological 
data is commonly interpreted in terms of its functional significance. (2012, p. 104)
These authors point out the insufficiency of purely mechanistic explanations—ones 
that do no more than identify the neural processes underlying visual phenomena. 
Their appeal is just to what they find to be a satisfying explanation. However, 
there are in-principle reasons why explanatory pluralism is to be expected in 
neuroscience. As Marr (1982) noted, and philosophers of biology like Mitchell 
(2009) have also argued, highly complex biological systems require description 
and explanation with multiple kinds of models and theoretical approaches. Each 
of these perspectives guides researchers to certain phenomena, and suggests which 
details of the system might be safely ignored.
Note that on this perspectival and pluralist account, the computational descrip-
tion is no more and no less realistic and fundamental than the mechanistic/imple-
mentational one.4 Yet, computational theory does have a preeminent role to play in 
cutting through the daunting complexity of neural structures and activity patterns. 
This was recognized early in the history of visual neurophysiology. The following 
passage comes from an article in which Horace Barlow presents the redundancy 
reduction explanation for the existence of lateral inhibition in the retina, deriving 
the result from information theory5:
A wing would be a most mystifying structure if one did not know that birds flew … 
Without understanding something of the principles of flight, a more detailed exam-
ination of the wing itself would probably be unrewarding. I think that we may be at 
an analogous point in our understanding of the sensory side of the central nervous 
system. We have got our first batch of facts from the anatomical, neurophysiological, 
and psychophysical study of sensation and perception, and now we need ideas about 
what operations are performed by the various structures we have examined … It seems 
to me vitally important to have in mind possible answers to this question when investi-
gating these structures, for if one does not one will get lost in a mass of irrelevant detail 
and fail to make the crucial observations. (Barlow, 1961, p. 217)
The idea here is that knowledge of the function of a structure or process leads to 
knowledge of the relevant theoretical principles that apply to it—aerodynamics for 
flight, information theory for the nervous system. With the appropriate theoretical 
framework in place, the scientist can better see what the relevant details are for 

PHILOSOPHICAL PSYCHOLOGY﻿ 
  407
explaining the behavior of the system, and this is crucial for scientific progress, 
given the over-production of data. The point is not about the intuitive insufficiency 
of purely mechanistic explanation (as with Frisby and Stone, quoted above); rather, 
it is about how to make scientific progress, given the complexity of the brain.6
3.  Mayr—and other biologists—on functions and MR
The task of this section is to examine functional thinking within biology more 
generally. This serves to reinforce the point of the section following it, that multiple 
realizability (the idea that functions can in principle be realized in different ways) 
is an important concept within the life sciences, understood as non-reductive 
enterprises. Functional thinking has many guises in biology. Some (i) are centered 
in evolutionary approaches, others (ii) in reverse engineering methodologies, 
where bio systems are compared with mechanical and artificial ones which do 
similar jobs, and others (iii) in robustness analysis, where functions are discov-
ered/hypothesized and scientists investigate how the behavior is kept stable across 
perturbing conditions.
3.1.  Evolution and non-reductive causal explanation
A famous assertion of explanatory pluralism in biology is Ernst Mayr’s (1961) 
distinction between proximate and ultimate causal explanation. The former refers 
to mechanisms operating within a living organism, while the latter refers to the 
evolutionary function or “purpose” of a behavior, such as migration. Mayr’s larger 
agenda was to demonstrate that evolutionary biology was a non-replaceable com-
plement to reductive molecular biology, which was advancing rapidly at that time. 
As Beatty (1994, p. 339) writes, “Mayr allowed that the study of proximate causa-
tion in biology approaches ‘the ideal of a purely physical or chemical experiment’ 
(Mayr, 1961, p. 1502). That leaves the evolutionary perspective most responsible 
for the special character and autonomy of biology.”
Another pay-off of a pluralism which accommodates explanations referring 
to evolutionary or ecological causes is that it demystifies teleology. Apparently 
goal-directed processes have been selected for because of their adaptive value 
and so Darwinian evolution offers an account of “purposefulness” being so wide-
spread in the living world.7 It is convenient to describe subsystems of an organism 
with recognizable purposes as having “functions.” Important goals of biological 
research are to construct hypotheses about the functions of structures or processes 
when they are not immediately obvious, and to develop mechanistic explanations 
of how systems achieve their functions.

408 
  ﻿M. CHIRIMUUTA
3.2.  Reverse engineering biological functions
Because biological systems have evolved to perform functions that are often com-
parable to the actions of man-made devices, one research strategy involves taking 
a design stance to biology and seeing if a system can be understood in terms of 
general engineering principles. In the following passage, neurologist Sir Francis 
Walshe contrasts reductive strategies with a reverse engineering approach—one 
that posits functions in the nervous system and then works back to see how 
the physical constituents realize them. This approach is advocated at length by 
neuroscientists Sterling and Laughlin (2015), but I refer to this text from 1961 
to reinforce the point that these ideas in neuroscience and biology predate func-
tionalism in the philosophy of mind:
The modern student finds it difficult to see the wood for the trees … He does not always 
have a synoptic concept of the nervous system in his mind … If we subject a clock to 
minute analysis by the methods of physics and chemistry, we shall learn a great deal 
about its constituents, but we shall not discover its operational principles, that is, what 
makes these constituents function as a clock. Physics and chemistry are not competent 
to answer questions of this order, which are an engineer’s task … Both modes have 
their place and limitations; and they complement one another. (Walshe, 1961, p. 131)
Section 2 noted the explanatory pluralism and functional thinking within neu-
roscience; here the point is more general, that functional thinking is prevalent in 
biological research more generally, and reference to computational functions in 
neuroscience is just one instance of this. In their advocacy of explanatory plural-
ism, both Mayr and Walshe display their anti-reductive commitments. Pluralism 
is recommended because of the limitations of micro-explanations, which refer 
only to physical and chemical causes and therefore miss the larger scale patterns 
of organization that the biologist needs to understand.
3.3.  Biological robustness
Biological robustness has been defined as “the ability of a system to sustain its func-
tionality in the face of perturbation” (Kitano, 2004). It is often achieved by multiple 
different mechanisms capable of performing equivalent functions (degeneracy). 
This raises the question of whether multiple realization is therefore a pervasive 
feature of biological systems. Boone (in press) argues that, because of robustness, 
MR is common in neural systems. But I suspect that such examples of neurons 
with varying ratios of ion channel density would not satisfy condition iv of Polger 
and Shapiro’s “official recipe” and would be considered instead as normal, with-
in-kind variants. However, the fact that their definition excludes these interesting 
cases of robustness suggests to me that it misses something interesting about the 
organization of living systems. In the living world, stasis is death: the working 
parts of organisms are constantly rearranging themselves, and yet in the midst of 
this flux they must maintain (approximate) functional stability. The maintenance 
of functional coherence even though the working parts of the system are in a state 

PHILOSOPHICAL PSYCHOLOGY﻿ 
  409
of constant upheaval is a problem that biology has had to solve many times, hence 
the prevalence of many kinds of mechanisms for robustness.8
Here is a quotation from a recent discussion of motor learning by neurosci-
entists taking issue with the “reductionist bias” in neuroscience. They explicitly 
connect robustness with multiple realizability in order to make the point that 
fine-grained descriptions of single circuits are of limited explanatory value.
It is now known from careful psychophysical work that many distinct learning algo-
rithms operate together to counter the effects of a perturbation during adaptation, 
even though phenotypically their summed behavior can look like pure error-based 
cerebellar learning … This is a further example of multiple realizability … If there are 
many ways to neurally generate the same behavior, then the properties of a single cir-
cuit at best are a particular instantiation and do not reveal a general design principle. 
(Krakauer et al., 2017, p. 487)
These authors are stating a case quite recognizable to readers of Fodor (1974)—
that multiple realization of a behavioral phenomenon implies that fine-grained 
neuroscientific description of one instantiation will not take the place of psycho-
logical description. However, if we consider the other material discussed above, 
we can see how it suggests ways to go further than the Fodor–Putnam charac-
terization of MR.
Firstly, it is reasonable to predict that biological functions will be multiply 
realized (in a non-stringent sense, not satisfying Polger and Shapiro’s condition 
iv) because natural selection targets the adaptive “goals” of these functions, and 
because there will be multiple ways to materially achieve those goals. Furthermore, 
given the flux of biological hardware, multiple pathways toward the same goal will 
be a design requirement in order to maintain robust functioning.9 Because the 
springboard for this argument is the quasi-teleological character of living systems, 
rather than the abstract nature of computation, it diverges from the traditional 
functionalist idea that multiple realizations of psychological functions are to be 
expected because psychological states are computational ones, and computation 
is inherently indifferent to material realization.
Now an obvious reply here is that these cases of MR in the non-stringent sense 
are beside the point. The aim of The Multiple Realization Book was to convince 
us of the need for a more stringent definition, and of the fact that the empirical 
findings do not deliver cases of MR understood stringently. However, it is here 
that worries rise to the surface about the “ecological validity” of a set of condi-
tions on MR whose primary example is the corkscrew. We hear from the actual 
science (not the imaginary science of corkscrews) that functional classifications 
capture regularities not apparent when description is restricted to a more fine-
grained vocabulary (be it physical, chemical, or neuroanatomical). Such findings 
avert us to the limitations of purely reductive research agendas in biology and 
neuroscience. Such cases have enough philosophical interest that they deserve to 
be the starting point of an account of MR, not ruled out by fiat because they do 

410 
  ﻿M. CHIRIMUUTA
not meet the requirements of a definition of MR tried and tested on the science 
of corkscrews.
4.  MR 2.0: Nonreductive physicalism made biological
In this section, I sketch some salient features of a new version of MR which is 
grounded in biology and scientific practice.
4.1.  Multiple realizability, for science
While Polger & Shapiro’s main target is the empirical claims for multiple realiza-
tion, they are also dismissive about the idea that certain functions are in principle 
multiply realizable:
Radical Multiple Realization comes into play, in our experience, when advocates of 
multiple realization try to take seriously the empirical viability of their positions and 
then start to worry about whether the evidence is on their side. Facing challenges about 
the empirical evidence for actual multiple realization, they retreat to the possibility of 
multiple realization—i.e. to multiple realizibility. (p. 52)
The point I would like to make here is that the in-principle case for multiple real-
izability is not only a dialectical retreat for functionalist philosophers—it also has 
a home in non-reductionist scientific methodology.
I like to think of the functional perspective in science as a handbook for culti-
vating beneficial ignorance. In the quotation above from Barlow (1961), we saw 
the connection between (1) the positing of a function, (2) the selection of theory 
or principles relevant to explaining that function, (3) the design of experiments 
for collection of data most relevant to the chosen theoretical framework, leading 
finally to (4) an explanation or description which illuminates how the system 
works. If you assume that the function initially posited is in principle multiply 
realizable, you get a useful guide to research. It indicates, for instance, what kinds 
of data you do not need to collect, and what details can be left out of your models. 
In Barlow’s example of wings and aerodynamics, many of the material properties 
of feathers would be irrelevant to the investigation because they just give rise to 
functionally equivalent variants. (In contrast, such factors would be highly relevant 
to theories of sexual selection in birds.)
The idea of “canonical neural computations” promoted by Carandini and 
Heeger (2012) is an example of this methodology being employed in recent neu-
roscience. Here the assumption that primary sensory cortex neurons are linear 
filters (the functional posit), and the attendant uptake of signal engineering the-
ory permits scientists to ignore physiological data except for stimulus-response 
relations for purposes of modeling these neurons because there are numerous 
functionally equivalent ways to build a linear filter from neural tissue. In short, 
positing the multiple realizability of functions allows scientists to black-box details 
that are irrelevant to their research programs. Functionalist philosophers of mind 

PHILOSOPHICAL PSYCHOLOGY﻿ 
  411
overstated case for multiple realizability by claiming that the brain could be made 
of any old stuff, but neglected this important methodological point.
4.2.  Life gets in the way
However, it can be hard to disentangle the commitments of this neural computa-
tional approach from philosophical functionalism, with its indifference to whether 
the computation is occurring in artificial or living systems.10 And if the task of 
disentangling is neglected, then much of the evidence marshalled by Polger and 
Shapiro can be presented against neural computationalism of the sort defended 
by Carandini and Heeger. For in chapters 5 and 6 of The Multiple Realization 
Book, we learn that operations performed by the nervous system are not in fact 
indifferent to the details of their realization in the way that functionalist dogma 
had supposed.
So how is it possible to assert that MR is an important concept for the science 
of the mind-brain, thus holding on to the non-reductive insights that the concept 
facilitates, but dropping the empirically untenable commitments of philosophical 
functionalism? The key move here is to dispense with the indifference to biologi-
cal hardware which characterizes philosophical functionalism, and also much of 
cognitive science. It can both be true that the material from which the nervous 
system is built (i.e. living, metabolizing cells) is crucial to their function and that 
those functions are multiply realized. My argument here will recapitulate points 
made above in the previous section.
First, living material is inherently Heraclitean—it maintains its integrity in the 
face of thermodynamic forces working against it, through the continual turnover 
of matter and energy. Unlike the hardware of a computer which is engineered 
to resist material change when used, neural tissue—like all living tissue—keeps 
changing as it is working. As Godfrey-Smith (2016) argues, it is plausible that this 
and other material properties of biological brains are key to understanding how 
cognition and awareness occur in animals, and so radical functionalism is false. At 
the same time, the Heraclitean nature of the nervous system is a roadblock to the 
success of purely reductive methodologies. Biological systems robustly maintain 
their functional profiles in spite of constant internally and externally generated 
perturbations. Therefore, the functionally relevant patterns—which stay the same 
across lower level changes, like the spiral shape of a raging tornado—will not be 
readily apparent at the finest grain descriptions of individual cells, or even small 
circuits. Hence the need for “meso-level” descriptions which make salient the 
shape of the storm against the swirling flux of background changes.11
4.3.  Toward identity theory 2.0
While Polger and Shapiro come out in favor of a traditional identity theory,12 
they appear to be bothered by the prospect of a reductionist race to the bottom. 

412 
  ﻿M. CHIRIMUUTA
Chapters 9 and 10 are intended to head off this threat. Since Polger and Shapiro 
resist eliminativism regarding mental states and assert the “actual autonomy” of 
psychology (p. 210), it would seem that they need to entertain anti-reductionism of 
some sort. Obviously, they have rejected MR 1.0 as an anti-reductionist ingredient, 
but I wonder if they would be tempted by MR 2.0. The view I sketched combines 
the anti-reductionism of functionalism with the neuro-centrism of identity theory, 
but it emphasizes biology in a way that is atypical of most identity theories.13 As 
Godfrey-Smith (2016, note 32) points out, it is moot whether one considers such 
a view as a rejection of or a modification of functionalism; and it is equally open 
to classification as a variety of identity theory.
5.  Three challenges to Polger and Shapiro
In this last section, I put larger issues aside and focus on three specific points of 
tension between Polger and Shapiro’s account and explanatory practice in current 
neuro- and cognitive science.
5.1.  Computational explanation without multiple realizability?
In chapter 8, Polger and Shapiro account for the prevalence of computational 
explanations in the cognitive sciences. Their claim is that such models are not 
ontologically committing (p. 162), and they insist that any inference from the use 
of computational models to claims about the putative computational nature of 
mental states would be to mistake the abstractness of the model for an inherent 
property of the model’s target (p. 156).
However, there are reasons to think that Polger and Shapiro do have trouble 
accounting for computational explanations. Let us take as an example vision sci-
entists Frisby and Stone’s discussion of lateral inhibition in the eyes of humans 
and horseshoe crabs. They write that,
Only a computational theory provides a plausible explanation of why the eyes of both 
organisms … should exaggerate luminance edges, and therefore why both organisms 
should “suffer” the Chevreul illusion. In essence, we no longer have to accept a mere 
physiological mechanism as an adequate explanation for a given visual phenomenon, 
we can now demand that there should also be an underlying computational reason 
for the nature of the information processing provided by that particular mechanism. 
(Frisby & Stone, 2012, p. 1050)
On the face of it, this does not sound very non-committal. The suspicion is con-
firmed if we consider that such explanations work by showing that both of these 
biological eyes fall into a similarity class which also contains man-made devices 
performing lateral inhibition, and a completely abstract coding scheme describing 
this computation.14 It is important that we be persuaded that there is a genuine 
similarity between these eyes and between the models—that is, that the similarity 
is not just an artifact of the abstractions we’ve introduced via our models.15 To 

PHILOSOPHICAL PSYCHOLOGY﻿ 
  413
the extent that computational explanation assumes genuine similarities, then it 
is ontologically committing. This is not in strong sense of declaring, “the human 
retina is fundamentally a computing circuit of type L.” Rather, it is in the sense that 
the abstract, computational description captures (even if in a caricatured or dis-
torted way) something “real” about the inherent structure or nature of the system.
5.2.  Not so beneficial ignorance
One of Polger and Shapiro’s central cases against MR is Karten’s neuroanatomical 
findings of surprising similarity in the circuits specialized for audition in bird and 
mammal brains. Karten reports that “the avian brain contains cells and circuitry 
which are nearly identical to those in the mammalian cortex, but disposed as 
nuclei rather than layers with interlaminar reciprocal connections” (Karten, 2013, 
p. R15, quoted in Polger & Shapiro, 2016, pp. 115–116). According to Polger and 
Shapiro, the avian and mammalian brain areas do not count as multiple realiza-
tions of the circuit for sensory processing because “the differences in the spatial 
organization of avian and mammalian brains … are not relevant differences” 
(Polger & Shapiro, 2016, p. 117).
However, this is a risky inference because it might well be that the spatial organ-
ization is relevant to sensory processing. One reason to think spatial organization 
is relevant stems from the fact that spatial organization affects axonal wiring 
length, and this in turn influences the speed and cost of neural information pro-
cessing (Sterling & Laughlin, 2015). So different arrangements might privilege 
different “solutions” to the problem of auditory processing. Karten’s text does not 
rule out this possibility, though his anatomical drawing (reproduced in Polger 
& Shapiro, 2016, p. 116) does imply that the difference in spatial organization is 
irrelevant, because both the mammalian and avian arrangements can be repre-
sented by roughly the same circuit diagram.
Polger and Shapiro can of course reply that it is an obvious point that all infer-
ences are risky, given the limitations of current knowledge of the brain; we all have 
to live with risk. Yet the deeper concern is that Polger and Shapiro’s “official recipe” 
exploits the gaps in our knowledge in order to make quick work of potential cases 
of MR. The condition relevant to Karten’s case is (iii), that “factors that lead the 
As and Bs to be differently classified by S2 [here, neuroanatomy] must be among 
those that lead them to be commonly classified by S1 [here, computational neuro-
science]” (p. 67). It is not only neuro-computational models and representations 
that are abstract. Neuro-anatomical schematic drawings such as Karten’s abstract 
from the complexity of actual brain tissue by making assumptions about what 
structures are the functionally relevant ones.16 There are plenty of biophysical 
differences between birds’ and mammals’ brains that an advocate of MR might 
point to as potentially relevant to function, but Polger and Shapiro are presuming 
them to be irrelevant, and hence not the ones leading the two kinds of circuits to 
be commonly classified with respect to sensory processing functions.

414 
  ﻿M. CHIRIMUUTA
It is worth returning to the problem of Polger and Shapiro’s reliance on toy 
examples, and why it is significant that brains are not like corkscrews. Even with 
elaborate Alessi corkscrews it is obvious after a bit of tinkering what the func-
tional parts are, and what is mere aesthetic flourish. With the brain, the separation 
between information processing structures and metabolic supports systems is 
probably more blurred than has commonly been assumed (Cao, 2014). This means 
that even the way that we draw the line between information processing kinds 
and realizing structures depicted in neuroanatomy is contestable and theory-de-
pendent. The denier of MR (as defined by the “official recipe”) will have latitude 
to contest claims of MR because there may never be a neutral way to characterize 
information processing kinds as opposed to structural and metabolic support, no 
matter how much data comes in the future.
5.3.  Deep networks
Finally, I would like to consider one case that seems to be an obvious instance of 
multiple realization, but for which I have doubts about the applicability of Polger 
and Shapiro’s conditions for MR. Polger and Shapiro write that:
Connectionist networks are almost always simulated or emulated using traditional 
symbolic computing machines—thereby illustrating the fact that their operation is 
suitably independent of the details of their realization. (p. 159)
The idea here is that an artificial connectionist network is the kind of thing that 
shows independence from its material realization. It would seem to follow straight-
forwardly that an artificial network for visual object recognition, running on a 
desktop PC, and the biological networks in the primate ventral stream are multiple 
realizations of the same functions.
However, visual neuroscientists Yamins and DiCarlo, who use many layered 
connectionist networks (“deep networks”) to model the responses of the visual 
cortex, emphasize the “structural” similarities between the artificial and biological 
structures:
Do such top-down goals [e.g., visual object recognition] strongly constrain biological 
structure? Will performance optimization imposed at the outputs of a network be suffi-
cient to cause hidden layers in the network to behave like real neurons in, for example, 
V1, V4 or IT? A series of recent results has shown that this might indeed be the case. 
(Yamins & DiCarlo, 2016, p. 359)
In particular, both the artificial and biological networks are hierarchical, many-lay-
ered, and have feedforward connections; the individual artificial neurons also 
develop receptive field properties like their biological counterparts. Yamins and 
DiCarlo’s point is that the task of visual object recognition may be such that any 
computational network will have to employ these same structural features in 
order to solve it.
This raises the question of whether the biological and artificial visual networks 
are multiple realizations after all. Polger and Shapiro (2016, p. 159) imply that 

PHILOSOPHICAL PSYCHOLOGY﻿ 
  415
difference in material hardware is enough to show MR here—and this fits the tra-
ditional functionalist intuition that MR just occurs when the same computational 
function is run on electronic, mechanical, or neural hardware. However, when 
discussing their official recipe, Polger and Shapiro mention as a “litmus test” for 
MR the question of “whether the same mechanical explanation can explain the 
operation of the two devices” (p. 64). (Answer: in the case of waiter’s and dou-
ble-level corkscrews it cannot, hence there is MR.) It would seem to follow that in 
the connectionist network case, the analogues of “mechanical explanation” are the 
biophysical and electronic engineering explanations of the hardware of the brain 
and PC, respectively. But, as should be clear from my discussion above,17 those 
low-level descriptions don’t go very far in explaining how the systems work (and 
this is another problematic point of disanalogy with the corkscrew case). In order 
to explain object recognition, neuroscientists like Yamins and DiCarlo refer to 
the more abstract structural features of the system, such as its being hierarchical 
and many layered. And it turns out that the “structural explanation” of both the 
artificial and biological networks are the same. So perhaps, by Polger and Shapiro’s 
lights, this turns out not to be a case of MR after all.
6.  Conclusion
The Multiple Realization Book rewards careful consideration and promises to 
change the landscape of philosophy of mind and cognitive science. While its aim 
is destructive—to overturn the received wisdom of the discipline—the project is 
carried out with real creative energy. This energy is infectious and has certainly 
prompted me to look with excitement at future possibilities for theorizing about 
the mind-brain sciences, some prospects for which I hope to have conveyed in 
this brief essay.
Notes
1.  See Boone (in press) for criticism of this approach, and an alternative causal 
framework.
2.  For further discussion, see Kaplan (2011, pp. 342–343) and Chirimuuta (in press).
3.  This is an obvious point, and it has been true since the 1950s; but it is neglected 
by functionalists in the Fodor–Putnam tradition. Putnam (1973) himself recognizes 
the importance of levels of explanation, giving the square peg/round hole example. 
Putnam says that the higher level explanation is better because it is “far more general” 
and at one point the autonomy of the mental amounts just to the credible claim that, 
“whatever our mental functioning may be, there seems to be no serious reason to 
believe that it is explainable by our physics and chemistry.” Yet this sensible discussion 
of explanation is part of the larger argument that brain material is irrelevant to 
explaining mental life.
4.  The way to argue otherwise would be via a blanket argument for reductive physicalism 
which prioritizes the “lower level” description. But then why stop at neural description, 
rather than chemical, then physical?

416 
  ﻿M. CHIRIMUUTA
5.  See Chirimuuta (2017a) for an extended discussion.
6.  Marr (1982, p. 27) uses a similar analogy: “trying to understand perception by 
studying only neurons is like trying to understand bird flight by studying only feathers: 
It just cannot be done. In order to understand bird flight, we have to understand 
aerodynamics; only then do the structure of feathers and the different shapes of 
birds’ wings make sense.” This passage often read as an assertion of the autonomy of 
perceptual psychology from neuroscience. I think we should take him to be making 
same point as Barlow (1961).
7.  I’m being simplistic for purposes of illustration. See Jablonka and Lamb (2014) on the 
complex developments of evolutionary theory post-Darwin.
8.  In another paper, I discuss this at length (Chirimuuta, 2017b).
9.  Canalization in developmental biology is another important example of this. See, for 
example, Noman et al. (2015), Siegal and Bergman (2002), and Jablonka and Lamb 
(2014, pp. 258–259)
10.  Here it is tempting to read Carandini through the filter of philosophical functionalism: 
“research in neural computation does not need to rest on an understanding of the 
underlying biophysics. Some computations, such as thresholding, are closely related to 
underlying biophysical mechanisms. Others, however, such as divisive normalization, 
are less likely to map one-to-one onto a biophysical circuit. These computations 
depend on multiple circuits and mechanisms acting in combination, which may vary 
from region to region and species to species. In this respect, they resemble a set of 
instructions in a computer language, which does not map uniquely onto a specific 
set of transistors or serve uniquely the needs of a specific software application” 
(Carandini, 2012, p. 508). However, I think we should focus on the methodological 
point that is being made by means of the computer analogy: that neuroscience will be 
advanced by application of meso-level descriptions, intermediate between very fine-
grained biophysical ones and very coarse-grained behavioral ones (p. 507).
11.  Some important criticisms of Sebastian Seung’s connectome project to generate 
synapse-by-synapse reconstructions of retinal circuits centers on this point (Morgan 
& Lichtman, 2013).
12.  “Explanatorily important mental process kinds can be identified with brain process 
kinds, that is, brain process kinds that can be fully characterized using the resources 
of the neurosciences.” (Polger & Shapiro, 2016, p. 26). This brief characterization of 
identity theory leaves open questions about what kinds of brain processes, and at what 
grain of description, psychological kinds are to be identified with—questions which 
naturally arise from my discussion above. Note also that in the decades since the first 
identity theory was formulated, neuroscience and psychology have grown toward 
one another and merged in places. Some neuroscience is a lot like psychology; some 
psychology is very neuro-sciency. Merely referring to what can be “characterized 
using the resources of the neurosciences” says very little about how far down the 
reduction is intended to go.
13.  Feigl (1958) is an exception.
14.  See Chirimuuta (2017a). Cf. Batterman and Rice (2014) on “minimal model 
explanation”.
15.  To make this clear, consider a case in which a similarity or sameness judgment is 
due to an artifact of abstraction. If I take black and white photographs of oranges 
and limes, and based on these representations say that the fruits are the same color, 
my judgment would be grounded on an artifact of abstraction. My photographic 
representations reduced the dimensionality of pixel variation from trichromatic to 
monochromatic, and hence the resulting sameness is artefactual.

PHILOSOPHICAL PSYCHOLOGY﻿ 
  417
16.  It is an obvious point, but still worth stating, that Karten’s diagram assumes the 
neuron doctrine—that single neurons are the basic units for information processing 
in the brain of mammals and avians. For this reason, no glial cells are depicted. This 
is a standard assumption, but see Cao (2014) for concerns about it.
17.  And see also Carandini (2012); Jonas & Kording, 2017.
Acknowledgments
I would like to thank Ken Aizawa for organizing the book symposium at the Southern Society 
for Philosophy and Psychology 2017 where this work was first presented. Credit is also due to 
my fellow speakers, Trey Boone and Dan Weiskopf, for their many perceptive comments and 
of course the authors themselves—Tom Polger and Larry Shapiro – who wrote an inspiring 
book.
Disclosure statement
No potential conflict of interest was reported by the author.
References
Barlow, H. B. (1961). Possible principles underlying the transformation of sensory messages. In 
W. A. Rosenblith (Ed.), Sensory communication (pp. 217–234). Cambridge, MA: MIT Press.
Batterman, R., & Rice, C. (2014). Minimal model explanations. Philosophy of Science, 81(3), 
349–376.
Beatty, J. (1994). The proximate/ultimate distinction in the multiple careers of Ernst Mayr. 
Biology and Philosophy, 9, 333–356.
Boone, W. (in press). Multiple realization and robustness. In M. Bertolaso, S. Caianiello, & E. 
Serrelli (Eds.), Biological robustness. Berlin: Springer.
Cao, R. (2014). Signaling in the brain: In search of functional units. Philosophy of Science, 
81(5), 891–901.
Carandini, M. (2012). From circuits to behavior: A bridge too far? Nature, 15(4), 507–509.
Carandini, M., & Heeger, D. J. (2012). Normalization as a canonical neural computation. Nature 
Reviews Neuroscience, 13, 51–62.
Chirimuuta, M. (2017a). The development and application of efficient coding explanation in 
neuroscience. In J. Saatsi, & A. Reutlinger (Eds.), Explanation beyond causation. Oxford: 
Oxford University Press.
Chirimuuta, M. (2017b). Crash testing an engineering framework in neuroscience: Does the 
idea of robustness break down?. Philosophy of Science, Advance online publication.
Chirimuuta, M. (in press). Vision. In M. Sprevak, & M. Colombo (Eds.), The Routledge 
handbook of the computational mind.
Feigl, H. (1958). The ‘mental’ and the ‘physical’. In H. Feigl, M. Scriven, & G. Maxwell (Eds.), 
Minnesota studies in the philosophy of science, volume 2: Concepts, theories, and the mind-
body problem (pp. 370–409). Minneapolis: University of Minnesota Press.
Fodor, J. (1974). Special sciences, or the disunity of science as a working hypothesis. Synthese, 
28, 97–115.
Frisby, J., & Stone, J. (2012). Marr: An appreciation. Perception, 41, 1040–1052.
Godfrey-Smith, P. (2016). Mind, matter, and metabolism. Journal of Philosophy, 113(10), 
481–506.

418 
  ﻿M. CHIRIMUUTA
Jablonka, E., & Lamb, M. (2014). Evolution in four dimensions (Revised ed.). Cambridge, MA: 
MIT Press.
Jonas, E., & Kording, K. (2017). Could a neuroscientist understand a micro- processor? PLoS 
Computational Biology, 13, e1005268.
Kaplan, D. M. (2011). Explanation and description in computational neuroscience. Synthese, 
183, 339–373.
Karten, H. (2013). Neocortical evolution: Neuronal circuits arise independently of lamination. 
Current Biology, 23(1), R12–R15.
Kitano, H. (2004). Biological robustness. Nature Reviews Genetics, 5(11), 826–837.
Krakauer, J. W., Ghazanfar, A. A., Gomez-Marin, A., MacIver, M. A., & Poeppel, D. (2017). 
Neuroscience needs behavior: Correcting a reductionist bias. Neuron, 93, 480–490.
Marr, D. (1982). Vision: A computational investigation into the human representation and 
processing of visual information. San Francisco, CA: Freeman.
Mayr, E. (1961). Cause and effect in biology. Science, 134, 1501–1506.
Mitchell, S. D. (2009). Unsimple truths: Science, complexity, and policy. Chicago, IL: University 
of Chicago Press.
Morgan, J. L., & Lichtman, J. W. (2013). Why not connectomics? Nature Methods, 10(6), 494.
Noman, N., Monjo, T., Moscato, P., & Iba, H. (2015). Evolving robust gene regulatory networks. 
PLoS One, 10(1), e0116258.
Polger, T. W., & Shapiro, L. A. (2016). The multiple realization book. Oxford: Oxford University 
Press.
Putnam, H. (1967). Psychological predicates. In W. H. Capitan & D. D. Merrill (Eds.), Art, 
mind, and religion. Pittsburgh, PA: University of Pittsburgh Press. Reprinted as “The Nature 
of Mental States” in H. Putnam (Ed.), 1975.
Putnam, H. (1973). Philosophy and our mental life. Berkeley, CA: Symposium. Reprinted in 
H. Putnam (Ed.), 1975.
Putnam, H. (1975). Mind, language, and reality: Philosophical papers, Vol. 2. Cambridge: 
Cambridge University Press.
Siegal, M. L., & Bergman, A. (2002). Waddington’s canalization revisited: Developmental stability 
and evolution. Proceedings of the National Academy of Sciences USA, 99, 10528–10532.
Sterling, P., & Laughlin, S. B. (2015). Principles of neural design. Cambridge, MA: MIT Press.
Walshe, F. (1961). Contributions of John Hughlings Jackson to neurology: A brief introduction 
to his teachings. Archives of Neurology, 5, 119–131.
Yamins, D. L. K., & DiCarlo, J. J. (2016). Using goal-driven deep learning models to understand 
sensory cortex. Nature Neuroscience, 19, 356–365.

Copyright of Philosophical Psychology is the property of Routledge and its content may not
be copied or emailed to multiple sites or posted to a listserv without the copyright holder's
express written permission. However, users may print, download, or email articles for
individual use.

