
Springer Series in Statistics
Advisors:
P. Bickel, P. Diggle, S. Fienberg, U. Gather,
I. Olkin, S. Zeger

Springer Series in Statistics
Alho/Spencer: Statistical Demography and Forecasting
Andersen/Borgan/Gill/Keiding: Statistical Models Based on Counting Processes
Atkinson/Riani: Robust Diagnostic Regression Analysis
Atkinson/Riani/Ceriloi: Exploring Multivariate Data with the Forward Search
Berger: Statistical Decision Theory and Bayesian Analysis, 2nd edition
Borg/Groenen: Modern Multidimensional Scaling: Theory and Applications, 2nd edition
Brockwell/Davis: Time Series: Theory and Methods, 2nd edition
Bucklew: Introduction to Rare Event Simulation
Capp´e/Moulines/Ryd´en: Inference in Hidden Markov Models
Chan/Tong: Chaos: A Statistical Perspective
Chen/Shao/Ibrahim: Monte Carlo Methods in Bayesian Computation
Coles: An Introduction to Statistical Modeling of Extreme Values
Devroye/Lugosi: Combinatorial Methods in Density Estimation
Diggle/Ribeiro: Model-based Geostatistics
Dudoit/Van der Laan: Multiple Testing Procedures with Applications to Genomics
Efromovich: Nonparametric Curve Estimation: Methods, Theory, and Applications
Eggermont/LaRiccia: Maximum Penalized Likelihood Estimation, Volume I:
Density Estimation
Fahrmeir/Tutz: Multivariate Statistical Modeling Based on Generalized Linear Models,
2nd edition
Fan/Yao: Nonlinear Time Series: Nonparametric and Parametric Methods
Ferraty/Vieu: Nonparametric Functional Data Analysis: Theory and Practice
Ferreira/Lee: Multiscale Modeling: A Bayesian Perspective
Fienberg/Hoaglin: Selected Papers of Frederick Mosteller
Fr¨uhwirth-Schnatter: Finite Mixture and Markov Switching Models
Ghosh/Ramamoorthi: Bayesian Nonparametrics
Glaz/Naus/Wallenstein: Scan Statistics
Good: Permutation Tests: Parametric and Bootstrap Tests of Hypotheses, 3rd edition
Gouri´eroux: ARCH Models and Financial Applications
Gu: Smoothing Spline ANOVA Models
Gy¨oﬁ/Kohler/Krzy´zak/Walk: A Distribution-Free Theory of Nonparametric Regression
Haberman: Advanced Statistics, Volume I: Description of Populations
Hall: The Bootstrap and Edgeworth Expansion
H¨ardle: Smoothing Techniques: With Implementation in S
Harrell: Regression Modeling Strategies: With Applications to Linear Models, Logistic
Regression, and Survival Analysis
Hart: Nonparametric Smoothing and Lack-of-Fit Tests
Hastie/Tibshirani/Friedman: The Elements of Statistical Learning: Data Mining, Inference,
and Prediction
Hedayat/Sloane/Stufken: Orthogonal Arrays: Theory and Applications
Heyde: Quasi-Likelihood and its Application: A General Approach to Optimal Parameter
Estimation
Huet/Bouvier/Poursat/Jolivet: Statistical Tools for Nonlinear Regression: A Practical Guide
with S-PLUS and R Examples, 2nd edition
Ibrahim/Chen/Sinha: Bayesian Survival Analysis
Jiang: Linear and Generalized Linear Mixed Models and Their Applications
Jolliﬀe: Principal Component Analysis, 2nd edition
Knottnerus: Sample Survey Theory: Some Pythagorean Perspectives
Konishi: Information Criteria and Statistical Modeling
K¨uchler/Sørensen: Exponential Families of Stochastic Processes
Kutoyants: Statistical Inference for Ergodic Diﬀusion Processes
Lahiri: Resampling Methods for Dependent Data
Lavall´ee: Indirect Sampling
Le Cam: Asymptotic Methods in Statistical Decision Theory
Le Cam/Yang: Asymptotics in Statistics: Some Basic Concepts, 2nd edition
Le/Zidek: Statistical Analysis of Environmental Space-Time Processes
Liu: Monte Carlo Strategies in Scientiﬁc Computing
Manski: Partial Identiﬁcation of Probability Distributions
Marshall/Olkin: Life Distributions: Structure of Nonparametric, Semiparametric
and Parametric Families
(continued after index)

Marco A.R. Ferreira
Herbert K.H. Lee
Multiscale Modeling
A Bayesian Perspective
123

Marco A.R Ferreira
Department of Statistics
146 Middlebush Hall
University of Missouri
Columbia, MO 65211
USA
ferreiram@missouri.edu
Herbert K.H. Lee
School of Engineering
Department of Applied Mathematics
and Statistics
University of California
Santa Cruz, CA 95064
USA
herbie@ams.ucsc.edu
Library of Congress Control Number: 2007929183
ISBN 978-0-387-70897-3
e-ISBN 978-0-387-70898-0
Printed on acid-free paper.
c⃝2007 Springer Science+Business Media, LLC
All rights reserved. This work may not be translated or copied in whole or in part without
the written permission of the publisher (Springer Science+Business Media, LLC, 233 Spring
Street, New York, NY 10013, USA), except for brief excerpts in connection with reviews or
scholarly analysis. Use in connection with any form of information storage and retrieval, elec-
tronic adaptation, computer software, or by similar or dissimilar methodology now known
or hereafter developed is forbidden.
The use in this publication of trade names, trademarks, service marks, and similar terms,
even if they are not identiﬁed as such, is not to be taken as an expression of opinion as to
whether or not they are subject to proprietary rights.
9 8 7 6 5 4 3 2 1
springer.com

To Alejandra

Preface
A wide variety of natural processes occur on multiple scales, either naturally
or as a consequence of measurement. This book contains methodology for
the analysis of data that arise from such multiscale processes. This topic is
relatively young in statistics, and our goal in writing this book is to bring
together a number of recent developments and make them accessible to a
wider audience. Here we focus on three main classes of methods: multiscale
random ﬁeld models, approximate basis representations, and implicit meth-
ods. Multiscale random ﬁeld models attempt to directly model the process
at each scale as well as provide a model for the link between scales; they
build upon standard autocorrelated time series and intrinsic spatial processes
to explicitly model multiscale correlated processes. Approximate basis repre-
sentations include wavelets and convolution methods, both of which involve
a ﬁnite approximation to an inﬁnite basis set for the space of continuous
functions, where ﬁner scales use successively more basis elements. Implicit
methods induce a multiscale structure via computation, having the various
scales share information as the model is being ﬁt but not directly modeling
the relationship between scales.
We take a Bayesian approach, which allows for full accounting of uncer-
tainty. The methodology presented herein allows one to deal with the delicate
issue of uncertainty at multiple scales. The Bayesian approach also facilitates
the use of knowledge from prior experience or data, and these methods can
handle diﬀerent amounts of prior knowledge at diﬀerent scales, as often occurs
in practice.
We provide a number of real-world examples that are thoroughly analyzed
in order to demonstrate our methods and to assist readers in applying
these methods to their own work. While this is a high-level book, our
primary objective is to make the material accessible so that the reader
can implement the methods and hopefully ﬁnd them helpful in practice.
To further assist readers, we are making source code (for R) available for
many of the basic methods discussed in this book. Code can be found at
http://www.ams.ucsc.edu/~herbie/multiscale.

viii
Preface
The book is aimed at statisticians, applied mathematicians, and engineers
working on problems dealing with multiscale processes in time and/or space,
such as in petroleum engineering, materials engineering, signal processing,
ﬁnance, environmetrics, and geology. This book will also be of interest to
researchers in academia working on multiscale computational problems, and
can be used as the basis for an upper-level graduate seminar.
The main prerequisite for this book is a knowledge of Bayesian statistics
at the level of Gelman et al. (1995) or a similar book. Such a background
should necessarily include familiarity with basic Markov chain Monte Carlo
methods. Knowledge of time series at the level of Pe˜na et al. (2000) is helpful
to understand Chapters 3 and 12.
A signiﬁcant portion of the methodology highlighted in this book orig-
inated from work done as part of the National Science Foundation funded
(DMS 9873275) multidisciplinary project “Multiscale Modeling and Simula-
tion in Scientiﬁc Inference: Hierarchical Methods for Parameter Estimation
in Porous Flow”, which brought together statisticians, applied mathemati-
cians, engineers, and geologists from several universities to study multiscale
processes in geology and hydrology. Both authors were members of the Center
for Multiscale Modeling and Distributed Computing at Duke University dur-
ing that time, where they developed several of the methods included in this
book. Marco Ferreira also received partial support from CNPq Brazil grants
302717/2003-0 and 402010/2003-5. Herbert Lee also received partial support
from National Science Foundation grants DMS 0233710 and DMS 0504851.
There are many people who have contributed in one way or another to
the writing of this book. We would like to thank the editor, John Kimmel,
for his incentive, and the former editor, Stephanie Harding, for convincing
us to write this book. We have beneﬁtted from discussions about Bayesian
statistics and/or multiscale modeling with several colleagues, among them
Mike West, David Higdon, Chris Holloman, Peter M¨uller, Brani Vidakovic,
Dani Gamerman, Alexandra Schmidt, Hedibert Lopes, and Helio Migon. A
signiﬁcant portion of the book was written while Marco Ferreira was a faculty
member at the Institute of Mathematics, Federal University of Rio de Janeiro.
The authors would like to thank Robert Gramacy for his extensive help with
the R source code; Adelmo Bertolde, Geraldo Cunha, Luzia Tonon, and Vini-
cius Israel for the implementation of the examples presented in Sections 8.5,
9.2.4, and 9.3.4; and Albert Ko for giving permission to use the leptospirosis
data in the application presented in Section 9.3.4.
Columbia, Missouri, USA
Marco A.R. Ferreira
Santa Cruz, California, USA
Herbert K.H. Lee
April 2007

Contents
Preface . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . vii
Part I Introduction
1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
3
2
Models for Spatial Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
7
2.1
Markov Random Fields . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
7
2.2
Gaussian Processes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 10
3
Illustrative Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17
Part II Convolutions and Wavelets
4
Convolution Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25
4.1
Convolutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 25
4.2
Multiscale Convolutions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33
4.2.1
Synthetic Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 34
4.2.2
Fraser River Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 36
5
Wavelet Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39
5.1
Background . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40
5.2
Continuous Wavelet Transform . . . . . . . . . . . . . . . . . . . . . . . . . . . 41
5.3
Scaling Function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 42
5.4
Discrete Wavelets and the Discrete
Wavelet Transform . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 43
5.4.1
Application: Image Compression . . . . . . . . . . . . . . . . . . . . 45
5.5
Bayesian Nonparametric Regression with Wavelets . . . . . . . . . . 46
5.5.1
Statistical Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 47
5.5.2
Estimation of Hyperparameters . . . . . . . . . . . . . . . . . . . . . 48

x
Contents
5.5.3
Empirical Bayes Estimation of Wavelet Coeﬃcients . . . . 49
5.5.4
Application . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 50
5.6
Other Statistical Applications of Bayesian Wavelet Analysis. . . 52
Part III Explicit Multiscale Models
6
Overview of Explicit Multiscale Models . . . . . . . . . . . . . . . . . . . . 57
6.1
Tree Deﬁnition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59
6.2
Classiﬁcation and Regression Trees . . . . . . . . . . . . . . . . . . . . . . . . 59
7
Gaussian Multiscale Models on Trees
. . . . . . . . . . . . . . . . . . . . . 63
7.1
The Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 65
7.2
Covariance Structure. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 66
7.3
Estimation When θ Is Known . . . . . . . . . . . . . . . . . . . . . . . . . . . . 69
7.3.1
Fine to Coarse Filter . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 70
7.3.2
Coarse to Fine Smoother
. . . . . . . . . . . . . . . . . . . . . . . . . . 73
7.4
Estimation When θ Is Unknown . . . . . . . . . . . . . . . . . . . . . . . . . . 76
8
Hidden Markov Models on Trees . . . . . . . . . . . . . . . . . . . . . . . . . . 79
8.1
HMMs in 1-D . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 80
8.2
HMMs on Trees
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 81
8.3
Estimation When θ Is Known . . . . . . . . . . . . . . . . . . . . . . . . . . . . 82
8.3.1
Fine to Coarse Filter . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 82
8.3.2
Coarse to Fine Smoother
. . . . . . . . . . . . . . . . . . . . . . . . . . 83
8.4
Estimation When θ Is Unknown . . . . . . . . . . . . . . . . . . . . . . . . . . 84
8.5
Application: Image Classiﬁcation
. . . . . . . . . . . . . . . . . . . . . . . . . 84
9
Mass-Balanced Multiscale Models on Trees . . . . . . . . . . . . . . . . 87
9.1
Introduction
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 88
9.2
Gaussian Case . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 89
9.2.1
Likelihood . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 89
9.2.2
Prior Distributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 90
9.2.3
Estimation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 91
9.2.4
Application: Per Capita Income in Espirito Santo State
92
9.3
Poisson Case . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 93
9.3.1
Likelihood . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 93
9.3.2
Prior Distributions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 93
9.3.3
Estimation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 94
9.3.4
Application: Smoothing of Leptospirosis Time Series . . 95
10
Multiscale Random Fields . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 97
10.1 Two-Level Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 99
10.2 Model with Several Levels
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 102

Contents
xi
10.3 The Multiscale Model as an Application
of Jeﬀrey’s Rule . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 106
10.4 Didactic Example: Three-Level Model . . . . . . . . . . . . . . . . . . . . . 107
10.5 Posterior Simulation
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 109
10.5.1 Simulation of Multiscale Random Fields . . . . . . . . . . . . . 109
10.5.2 Parameter Updates
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 110
10.6 A Simulated Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 111
11
Multiscale Time Series. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 113
11.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 113
11.2 Model Construction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 114
11.2.1 General Framework . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 114
11.2.2 Example – AR(1) Building Blocks . . . . . . . . . . . . . . . . . . . 116
11.2.3 General Case – Implied Fine-Level Distribution . . . . . . . 117
11.2.4 Example – MA(1) Building Blocks . . . . . . . . . . . . . . . . . . . 118
11.2.5 HRMs with ARMA Building Blocks . . . . . . . . . . . . . . . . . 119
11.3 Properties of Hidden Resolution Models
. . . . . . . . . . . . . . . . . . . 119
11.3.1 Limiting Behavior
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 120
11.3.2 Autocorrelation Functions
. . . . . . . . . . . . . . . . . . . . . . . . . 122
11.4 Incorporating Periodicities . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 130
11.5 Inference and Prediction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 132
11.5.1 Posterior Simulation
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 132
11.5.2 Forecasting . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 133
11.5.3 Estimation and Forecasting in the Presence
of Periodicities
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 135
11.5.4 Eﬃcient Computation Using the Kalman Filter . . . . . . . 135
11.6 Examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 136
11.6.1 Analysis of the Flow of the Fraser River . . . . . . . . . . . . . 136
11.6.2 Northern Hemisphere Temperature . . . . . . . . . . . . . . . . . . 140
11.6.3 Potential Hydroelectric Energy . . . . . . . . . . . . . . . . . . . . . 142
12
Change of Support Models . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 145
12.1 Point-Level Spatial Processes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 146
12.2 Inferring Intermediate-Level Processes . . . . . . . . . . . . . . . . . . . . . 149
12.3 Block-Level Spatial Processes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 151
Part IV Implicit Multiscale Models
13
Implicit Computationally Linked
Model Overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 155
13.1 Simulated Annealing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 157
13.2 Simulated Tempering . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 158
13.3 Simulated Sintering . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 161
13.4 Multigrid Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 163

xii
Contents
14
Metropolis-Coupled Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 165
14.1 Metropolis Coupling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 165
14.2 Multiscale Metropolis Coupling . . . . . . . . . . . . . . . . . . . . . . . . . . . 167
14.2.1 Swapping with Convolutions . . . . . . . . . . . . . . . . . . . . . . . . 168
14.2.2 Swapping with Autoregressive Processes . . . . . . . . . . . . . . 173
14.3 Sequential Parallel Tempering . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 175
14.4 Extensions. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 176
15
Genetic Algorithms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 179
15.1 The Basics of Genetic Algorithms . . . . . . . . . . . . . . . . . . . . . . . . . 179
15.2 Multiscale Genetic Algorithms . . . . . . . . . . . . . . . . . . . . . . . . . . . . 182
15.3 Multiscale Genetic Algorithm-Style MCMC . . . . . . . . . . . . . . . . . 185
15.3.1 Genetic Algorithms and MCMC . . . . . . . . . . . . . . . . . . . . . 185
15.3.2 Multiresolution Versions. . . . . . . . . . . . . . . . . . . . . . . . . . . . 186
15.3.3 Implementational Concerns . . . . . . . . . . . . . . . . . . . . . . . . . 189
15.4 Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 191
Part V Case Studies
16
Soil Permeability Estimation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 195
16.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 195
16.2 Multiscale Modeling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 198
16.2.1 Static Information Propagation . . . . . . . . . . . . . . . . . . . . . 199
16.2.2 Dynamic Data Incorporation . . . . . . . . . . . . . . . . . . . . . . . 200
16.2.3 One-Dimensional Permeability Estimation
. . . . . . . . . . . 200
16.2.4 Two-Dimensional Permeability Estimation . . . . . . . . . . . 204
16.3 Implicit Multiscale Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 209
17
Single Photon Emission Computed Tomography Example. . 213
17.1 Metropolis Coupling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 217
17.2 Genetic Algorithms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 219
18
Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 223
References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 225
Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 243

Part I
Introduction


1
Introduction
In this book, we are concerned with multiscale methods and models. The
term multiscale broadly refers to processes, algorithms, and data that can be
structured by scale. A well-known example of a multiscale stochastic process
is a fractal (e.g., Mandelbrot, 1999). An example of a multiscale algorithm is
the fast wavelet transform (e.g., Vidakovic, 1999; Mallat, 1999). An example
of multiscale data is a time series dataset that happens to be observable at
diﬀerent sampling frequencies. One could check the price of a stock once a
year, daily, hourly, or every minute. The ﬂuctuations in the annual prices will
generally have rather diﬀerent behavior than the hourly ﬂuctuations, and one
may want to model both sorts of behavior simultaneously.
The goal of this book is to present methodology for dealing with multiscale
situations. These methods represent a number of rather diﬀerent perspectives
on the multiscale problem. What they have in common is their value in mul-
tiscale modeling. In all cases, these methods are based on probability models.
Furthermore, we take a fully Bayesian perspective, and the methods contained
herein are all amenable to a Bayesian approach. There are many more mul-
tiscale methods in the literature, and we are not able to discuss all of them
in a single book. We focus on those that are the most suitable for Bayesian
models. The Bayesian paradigm allows full accounting for uncertainty, some-
thing that can be quite diﬃcult in complex models, such as multiscale models.
The problem of propagating uncertainty between scales makes the Bayesian
approach particularly attractive.
We note that the terms multiscale and multiresolution are being used in-
creasingly in the literature in a growing variety of disciplines and applications.
We will not attempt to distinguish between these two terms but will essentially
use them interchangeably.
When does it pay to use multiscale ideas? Throughout this book, we focus
on three main cases where the multiscale approach is particularly helpful:
for processes that are naturally multiscale, when information is available at
diﬀerent levels of resolution, and when embedding a standard problem in a

4
1 Introduction
multiscale framework leads to signiﬁcant computational advantages. Let us
brieﬂy consider each of these cases.
Processes may naturally occur in a multiscale fashion. In some cases, rel-
evant features of the data can be seen only at particular scales, with diﬀerent
aspects requiring diﬀerent scales. Eﬀective modeling of such a process clearly
requires a fully multiscale model. Another important case is when the process
has a simpler representation at coarser scales. In that case, a multiscale model
can be used to represent the process in a cascade manner from coarser to ﬁner
levels. But we also include in this categorization more general processes that
have underlying multiscale mechanisms. An example is that of the concen-
tration of a ground-level pollutant such as ozone. A station making hourly
measurements over the course of a year or more will notice both a daily cycle
(higher in midday) and an annual cycle (higher in the summer) in addition to
the possible ﬁne-level deviations at the level of measurement. Thus a model
would need to incorporate both annual and daily components. The multiscale
approach provides a natural mechanism for dealing with this situation. Note
that data may only be available at a single level of resolution. Typically the
data will be at the ﬁnest level of resolution being considered, but some meth-
ods such as those in Chapter 10 can also deal with the case where the data
occur on a coarser scale than the ﬁnest scale of interest.
The other obvious application for multiscale methods is when data are
collected at multiple levels of resolution. The time series example given at the
beginning of this chapter is an example of this, where the time series may
be observed at diﬀerent levels of resolution, possibly by diﬀerent observers,
and the two sets of data need to be combined. Another example is in geology,
where soil characteristics may be measured using several diﬀerent techniques,
each resulting in data at a diﬀerent physical scale of interpretation. Core sam-
ples provide information at a point but no direct information away from the
sampling location. Flow experiments can provide information on an intermedi-
ate scale, covering more area but not providing precise information at speciﬁc
locations. Seismic experiments are at a yet larger scale, providing information
about larger areas. To fully model the ground, it may be necessary to incorpo-
rate all three sources of information in a statistically coherent manner. This
example will be revisited in more detail in Chapter 16. In these multiscale
data cases, we often consider the true process to occur at a particular scale,
and it is just the data that are collected at multiple scales that drive the need
for a multiscale approach. Of course, it is possible to have both the data and
the underlying process be multiscale, which would be a combination of both
this case and that of the previous paragraph.
A third set of problems amenable to multiscale approaches are ones where
multiple levels of resolution are artiﬁcially imposed in order to improve the
tractability of the problem by helping with computational aspects. Modern
Bayesian computation is often done with Markov chain Monte Carlo (MCMC)
methods, and in complex problems the chain may mix slowly, requiring unrea-
sonable amounts of time to converge. In addition, there may be a large number

1 Introduction
5
of posterior local modes, and the chance of the chain becoming trapped around
one of these modes is very high. By creating an artiﬁcial coarser scale, the
parameter space can be reduced, resulting in many fewer local modes and
allowing the model to be ﬁt more easily on the coarser scale, thus signiﬁcantly
improving mixing. The coarser scale is then related back to the original ﬁner
scale. One example of this occurs in medical imaging, such as with single
photon emission computed tomography (SPECT). The problem of interest is
to reconstruct properties of the object being scanned from the collected pho-
tons. This information is desired on a particular scale, and a physical model
relates these parameters to the observed counts. Running this model can be
computationally expensive, and the correlations in the parameters (the object
properties on a grid) can cause poor mixing of MCMC methods. Fitting the
model at a coarser resolution (i.e., a coarser grid for the unknown object prop-
erties) reduces both the physical model run time and the number of unknown
parameters, thus helping reduce the amount of time needed to use MCMC
methods eﬀectively. Note that the process is only of interest at a single reso-
lution, the data are only collected at one resolution, and the multiscale model
is used solely as a computational tool. The SPECT example is explored more
fully in Chapter 17.
This book is divided into ﬁve parts. This introductory chapter plus chap-
ters on basic spatial models and our primary illustrative example comprise
Part I. Part II concerns multiscale decomposition methods, in particular con-
volutions and wavelets. Part III presents explicit multiscale models, including
multiscale models on trees, multiscale random ﬁelds, multiscale time series,
and change of support models. Part IV presents multiscale models that are
implicitly deﬁned by a computational linkage of the diﬀerent levels of reso-
lution; such linkages include Metropolis-coupled methods and genetic algo-
rithms. Part V closes the book with some case studies. Each of the three
main parts starts out with an overview chapter introducing the methods and
putting them into broader context.
Finally, we note that basic computer code (in R) is available for many of
the methods discussed in this book, and can be found at
http://www.ams.ucsc.edu/~herbie/multiscale
This code is not meant to be a complete ready-to-use package but rather a
starting point from which the user may make modiﬁcations for their particular
situation. The routines illustrate the key aspects of the methods for basic cases
and can easily be adapted to more complex problems.


2
Models for Spatial Data
Before launching into the main topics of the book, we ﬁrst want to introduce
two standard models used for spatial data, as they will reappear throughout
the book. The ﬁrst is the Markov random ﬁeld (MRF), which is most useful
for grids and irregular areal data. The second is the Gaussian process, which is
more useful when a continuous surface is desired or a wider variety of spatial
smoothness needs to be speciﬁed or ﬁt.
2.1 Markov Random Fields
Markov random ﬁelds are typically deﬁned over a regular lattice but can
also be used for irregular grids or regular or irregular areal units. Here we
focus on implementation on a regular grid, as that is the most relevant for
the multiscale methods in the rest of the book. But we do want to stress
that these models are ﬂexible and useful well beyond the regular grid setting.
Similarly, we consider only Gaussian MRFs but acknowledge that alternative
forms of MRFs may be more applicable in other situations. Many more details
of MRFs can be found in references such as Rue and Held (2005), Hjort and
Omre (1994), and Besag (1974).
The key idea of a Markov random ﬁeld is that the distribution of the
process at a particular location depends only on the values of the process at
neighboring locations. It is in this sense that it is Markovian—points outside
the neighborhood are conditionally independent given the neighborhood. One
of the degrees of ﬂexibility in the model is the speciﬁcation of the neighbor-
hood. Often, only the immediately adjacent points will constitute the deﬁni-
tion of the neighborhood. However, more extended neighborhoods are easily
incorporated into the structure if desired. Here we typically focus on simple
ﬁrst-order neighborhoods (i.e., only the immediate neighbors). On a regular
grid in two dimensions, this would be the four lattice points (or grid cells)
that are horizontally or vertically adjacent. In three dimensions, there would
be six such neighbors. In one dimension, there are only two neighbors. Of

8
2 Models for Spatial Data
course, locations on the edges or corners of the lattice will have fewer neigh-
bors. MRF models are closely related to conditional autoregressive (CAR)
models (Banerjee et al., 2003).
Write the process values on the grid of spatial locations in vector form as
x = (x1, . . . , xn). A proper Gaussian Markov random ﬁeld model, for example
as considered by Ferreira and de Oliveira (2007), can be written as
x ∼N(µ1n, Σ),
(2.1)
where µ ∈R is a location parameter, 1n is an n-dimensional vector of ones,
and Σ−1 = τ(αIn + H), with τ > 0 a scale parameter, In the n × n identity
matrix, and H is comprised of elements
Hjk =
⎧
⎨
⎩
hk,
j = k,
−gjk,
j ∈Nk,
0,
otherwise,
(2.2)
where gjk = gkj > 0 is a “measure of similarity” between sites j and k, Nk is
the set of locations j such that j is a neighbor of k, and hk = 
j∈Nk gjk. In
many cases, rotational symmetry of the spatial similarity will mean that gjk
will be the same for all (j, k) in the lattice. The parameter α > 0 is a “spatial”
parameter that controls the strength of association between the components
of x and determines the main properties of model (2.1).
When α →0, model (2.1) approaches the intrinsic autoregressive model
(Besag et al., 1991; Besag and Kooperberg, 1995), which is an improper dis-
tribution that has been used extensively in spatial statistics as a prior dis-
tribution for latent processes or random eﬀects (Sun et al., 1999; Carlin and
Banerjee, 2003). As an example of the eﬀects of the key parameters, Figure 2.1
shows perspective plots of random realizations of 2-D MRFs with mean zero
and gjk = 1 for all j and k. The left column shows intrinsic ﬁelds with α = 0,
and the right column shows proper (mean-reverting) ﬁelds with α = 1. All
plots are on the same scale. The rows show MRF scale parameters of τ = 1,
4, and 16, and so they are successively smoother. Note that the proper ﬁelds
are generally smoother than the intrinsic ﬁelds with the same scale parame-
ter. The range of the intrinsic ﬁelds is typically larger because they are not
mean-reverting, as the smoothness constraint is entirely locally deﬁned.
In the intrinsic case, and assuming a zero-mean process, the conditional
distribution for a point given its neighbors is
xk|x−k ∼N
−
j̸=k Hjkxj
Hkk
,
1
τHkk

,
(2.3)
where x−k denotes all elements of x except xk. For a ﬁrst-order zero-mean
process, this simpliﬁcation is considerable. It also allows for eﬃciency in
updating because the lattice can be partitioned into two checkerboards, as the
neighborhood of each point is only the directly adjacent points, so picturing a

2.1 Markov Random Fields
9
alpha=0, tau=1
alpha=0, tau=4
alpha=0, tau=16
alpha=1, tau=1
alpha=1, tau=4
alpha=1, tau=16
Fig. 2.1. Random realizations of Markov random ﬁelds by parameter values.

10
2 Models for Spatial Data
checkerboard, all of the black squares are conditionally independent given the
values on the other half of the squares. Within a Bayesian context, ﬁtting of
the MRF is done via Gibbs sampling, such as with the complete conditional
for each point given by Equation (2.3). Since the two colors of the checker-
board denote conditionally independent segments, the entire lattice can be
updated in just two multivariate Gibbs steps. In practice, the MRF model
x is combined with data y, such as with a conditionally independent normal
likelihood
yi|xi∼N(xi, σ2) ,
assuming that there is one observation for each cell (such as with image analy-
sis) or using a suitable mapping of the MRF cells xj to the data points yi. This
formulation also allows full updating with just two multivariate Gibbs steps.
Conditionally conjugate priors of an inverse-gamma for σ2 and a gamma for τ
complete the speciﬁcation, allowing Gibbs updates for those two parameters
as well. By using all Gibbs steps, posterior inference is usually fairly eﬃcient,
with good mixing. In some more complex situations, such as the SPECT
example of Chapter 17 with the computer model involved in the likelihood
function, the MCMC updates require more care and achieving good mixing
is more diﬃcult (hence the value of a multiscale approach). Some ideas for
other update proposals can be found in Lee et al. (2002). Alternative choices
of priors, such as reference priors (Ferreira and de Oliveira, 2007), may also
require Metropolis-Hastings updates.
From this development, it is clear how having a regular lattice makes the
implementation of an MRF much simpler. For the irregular case, deﬁning a
neighborhood structure is possible, although it is a more complex process.
In contrast, the Gaussian process models discussed in the next section have
no additional complications for irregular grids because they are deﬁned as a
continuous process and can then be evaluated at any arbitrary set of locations.
2.2 Gaussian Processes
Gaussian processes have a long history of use for spatially distributed data.
Much of the early work appeared in the geostatistical literature under the
name of kriging (Matheron, 1963). Related ideas were explored initially as
a method for interpolation, and later full probability models were developed
(Journel and Huijbregts, 1978; Ripley, 1981; Cressie, 1993; Wackernagel, 1998;
Stein, 1999). Applications can now be found in a wide variety of areas, includ-
ing meteorological ﬁelds (Royle et al., 1999), unknown functions (O’Hagan,
1991), complex computer model responses (Sacks et al., 1989; Kennedy and
O’Hagan, 2001; Santner et al., 2003; Fang et al., 2006), agricultural fertil-
ity gradients (Brownie et al., 1994), and pollutant ﬁelds (Host et al., 1995).
Introductory descriptions of Gaussian processes can be found in Cressie (1993)
and Hjort and Omre (1994). Gaussian processes are also used as a method

2.2 Gaussian Processes
11
of nonparametric regression to ﬁt arbitrary surfaces in the presence of inde-
pendent errors (Williams and Rasmussen, 1996; Neal, 1999). Lee (2004) gives
more context for how Gaussian processes ﬁt into the families of nonpara-
metric regression methods. Detailed theoretical treatments are available in
Abrahamsen (1997) and Stein (1999).
The key identifying feature of a Gaussian process is that it is a continu-
ously deﬁned process such that its values at any ﬁnite collection of locations
have a multivariate Gaussian distribution. Two common simplifying assump-
tions are stationarity and isotropy. In its basic form, stationarity says that if
you take any ﬁnite collection of points and a translation of that collection,
they will both have the same distribution. Thus the process does not depend
directly on location in the sense that the distributions of the points are the
same everywhere. In particular, this implies that all points have the same
mean and marginal variance. Considering for the moment a two-dimensional
space, stationarity also implies that if you examine the joint distribution of a
point and another point one unit away to the northwest, that bivariate nor-
mal distribution will be the same bivariate normal distribution for the joint
distribution if you shift both points one unit to the east. This distributional
invariance extends to any number of dimensions and to any ﬁnite number of
points in the collection. Often the marginal mean of the ﬁeld is not constant,
so the mean is ﬁrst modeled separately (such as with a linear model or a
low-order polynomial) and then the detrended ﬁeld can be ﬁt with a station-
ary Gaussian process. Although the trend and the zero-mean spatial process
are modeled separately, they can be ﬁt simultaneously to allow a trade-oﬀ
between complexity in the trend and a larger-magnitude spatial process.
Isotropy further simpliﬁes the structure of a stationary ﬁeld by requiring
that the covariance between any two points depend only on the distance bet-
ween them. Thus the covariance between one point and another point one
unit to the northwest is the same as the covariance between the ﬁrst point
and another one unit to the northeast, and in fact with any point exactly one
unit away from it. And by the assumption of stationarity, the same covariance
applies to all pairs of points exactly one unit apart.
Thus, for a Gaussian process x(s) observed at a set of locations s1, . . . , sn ∈
S, we can write its distribution in terms of its mean function µ(s) and its
covariance function C(si, sj) as
x ∼MV N (µ, Σ) ,
where x = (x(s1), . . . , x(sn)), µ = (µ(s1), . . . , µ(sn)), and Σ is the variance-
covariance matrix with elements C(si, sj). With the typical assumptions of
stationarity and isotropy, we can simplify this by letting µ(si) = µ for all i,
and deﬁning the covariance matrix such that
C(si, sj) = 1
λρ(d) ,

12
2 Models for Spatial Data
where λ is the precision (the inverse of the variance, which is easier to work
with in a Bayesian context) and ρ(d) is the correlation function that gives
the correlation between any two points that are a distance of d units apart.
Here we will simplify things by assuming a zero-mean process, so µ = 0, but
this is easily generalized to other mean functions, and lower-order polynomial
functions of location are often used.
In most problems, S = Rp and Euclidean distance is used as the distance
metric. Other distance metrics are possible, and most are based on Euclidean
distance on a transformation of S. Such transformations are typically rota-
tions and dilations (Isaaks and Srivastava, 1989, Chapter 16). More generally,
spatial deformations can be used (Sampson and Guttorp, 1992; Schmidt and
O’Hagan, 2003).
Since every covariance matrix must be nonnegative deﬁnite, the covariance
function C(·, ·) must also be nonnegative deﬁnite. Typically one of several
parametric forms is chosen for the correlation function, ρ(d). Popular examples
include the
spherical correlogram,
ρ(d) =

1 −3
2d + 1
2d3
I{0≤d≤1}(d);
exponential correlogram, ρ(d) = e−d;
Gaussian correlogram,
ρ(d) = e−d2; and
Mat´ern class,
ρ(d) = [(d/2)ν2Kν(d)] /Γ(ν),
where I{0≤d≤1}(d) is the indicator function, which is one when 0 ≤d ≤1 and
zero otherwise, Kν is a modiﬁed Bessel function of the second kind, and ν
is a smoothness parameter (see Abramowitz and Stegun, 1964). The spheri-
cal correlogram is sometimes preferred because of its compact support. Stein
(1999) presents a case for why the Mat´ern class (Mat´ern, 1986) should be
preferred, particularly from a theoretical standpoint. However, from a more
practical viewpoint, the smoothness parameter ν can be diﬃcult to ﬁt, partic-
ularly in the context of inverse problems (e.g., Chapter 16). The exponential
and Gaussian correlograms are special cases of the Mat´ern class, with ν = 1/2
and the limit as ν →∞, respectively. We will typically use one of these simpler
forms, such as the Gaussian correlogram, in this book.
Additional parameters can be used to specify the marginal variance and
the range of spatial dependence so that C(si, sj) = θ1ρ(d/θ2); e.g., the two-
parameter Gaussian covariogram would be
C(d) = θ1 exp
	
−
 d
θ2
2
.
(2.4)
Figure 2.2 shows the correlogram (left column) and a random realization (right
column) for the spherical, exponential, and Gaussian correlation functions.

2.2 Gaussian Processes
13
0
5
10
15
20
25
0.0
0.2
0.4
0.6
0.8
1.0
distance
correlation
spherical correlogram
x
Y
Z
0
5
10
15
20
25
0.2
0.4
0.6
0.8
1.0
distance
correlation
exponential correlogram
x
Y
Z
0
5
10
15
20
25
0.2
0.4
0.6
0.8
1.0
distance
correlation
Gaussian correlogram
x
Y
Z
Fig. 2.2. Correlograms (left column) and surface realizations (right column) for
spherical, exponential, and Gaussian correlation functions.

14
2 Models for Spatial Data
For this ﬁgure, θ2 has been set to 15 for each plot. Note that the Gaussian
function produces much smoother realizations than the other two functions.
The smoothness of the realizations is related to the behavior of the correlation
function near zero (Stein, 1999). Further details on choosing or modeling a
covariance or correlation function can be found in Cressie (1993), Stein (1999),
or Banerjee et al. (2003).
In the correlation structures above, the processes interpolate the data,
passing through all data points and predicting continuously in between
observations. In many cases, one wants to allow more ﬂexibility in ﬁtting,
not requiring the predictions to match the data points exactly. Such a ﬁt can
then be a smoother function. Such a model can arise philosophically in one of
two ways. First, one could consider a standard additive random noise model
for the observations. Alternatively, one could consider additional variability
as coming from a diﬀerent small-scale process. This latter interpretation was
the original motivation for the introduction of the nugget term (Matheron,
1963; Cressie, 1993). These two approaches can be shown to be mathemati-
cally equivalent under the right formulation. It is also worth noting that the
inclusion of some additional variability can improve the numerical stability of
the problem, particularly for the Gaussian correlation function (Neal, 1997).
In most spatial problems, the covariance parameters can be estimated from
the data (although improper priors can cause problems in the Bayesian setting;
see Berger, De Oliveira, and Sans´o, 2001, for more discussion of noninforma-
tive priors). However, in some problems where no direct measurements of the
spatial ﬁeld are available, such as the permeability example in Chapter 16,
most of these parameters will need to be chosen a priori, as the data do not
contain suﬃcient information for the estimation of these parameters (see, for
example, Oliver et al., 1997).
In the Bayesian setting, some simple cases can be dealt with in closed
form. For example, if a covariance function is taken as known, the mean func-
tion is parameterized as a linear expansion, and a conjugate (normal) prior is
used for the coeﬃcients, then the posterior is available in closed form. With
the right prior speciﬁcation, the case of unknown marginal variance (the θ1
parameter in Equation (2.4)) can be handled by using an inverse-gamma prior
for the variance, also leading to a closed-form posterior and analytic forms for
predictions and predictive variance. More details are available in Hjort and
Omre (1994). We omit those details here because our focus tends to be on
more complex situations, in particular either the case where additional aspects
of the covariance structure need to be estimated (e.g., θ2 in Equation (2.4)) or
where the likelihood is signiﬁcantly more complex (such as with the computer
model for water ﬂow in Chapter 16), and thus no fully conjugate speciﬁca-
tion is available. In such cases, posterior estimation needs to be done with
Markov chain Monte Carlo methods. Some parameters (such as the coeﬃ-
cients for the mean and the marginal variance) can typically be treated with
conditionally conjugate priors, allowing for Gibbs updates during MCMC.
Other parameters (such as the range parameter θ2) can only be updated

2.2 Gaussian Processes
15
via Metropolis-Hastings steps. When covariance parameters other than the
marginal variance (θ1) are unknown, the full covariance matrix must be
inverted at each MCMC iteration, which can be computationally expensive
as well as numerically unstable. The instability is a result of the matrix being
close to singular, and the problem is exacerbated by smoother covariance func-
tions, particularly the Gaussian covariogram. An important computational
device is the Cholesky decomposition, which not only helps with numerical
stability itself but can also be used with pivoting, allowing the rearrangement
of the covariance matrix so that the focus of the ﬁtting can be on the more
important elements (see, for example, Lee et al., 2002).
This framework can be extended to settings with a spatially correlated
multivariate response by employing methods such as cokriging (Ver Hoef and
Barry, 1998; Wackernagel, 1998) or coregionalization (Schmidt and Gelfand,
2003; Gelfand et al., 2004).
An alternative speciﬁcation for Gaussian processes uses a convolution
approach, which is discussed in detail in Chapter 4. Using convolutions has
certain computational beneﬁts, and it also allows for a natural mechanism for
modeling at diﬀerent resolutions.
While not the focus of this book, it should be noted that a number of
methods are available for modeling nonstationary processes, although these
are typically limited to use on relatively smaller datasets. Examples include
Haas (1990), Sampson and Guttorp (1992), Damian et al. (2001), and Schmidt
and O’Hagan (2003). The convolution approach has also proved useful in
modeling nonstationarity (Barry and Ver Hoef, 1996; Higdon et al., 1999;
Fuentes and Smith, 2001), and Paciorek (2003) found an elegant extension that
allows a number of expressions to be obtained in closed form. Kim et al. (2005)
and Gramacy and Lee (2006) handle nonstationarity through partitioning
approaches.


3
Illustrative Example
We present here a preliminary analysis of a dataset that is used in many
parts of the book as an illustrative example for diﬀerent multiscale modeling
approaches. The dataset is the monthly ﬂow of the Fraser River in Canada
from January 1913 to December 1990. This dataset was previously analyzed
by McLeod (1994) and is available from StatLib at
http://lib.stat.cmu.edu/datasets/fraser-river
Figure 3.1(a) presents the plot of the log of the mean monthly ﬂows of the
Fraser River from January 1913 to December 1990, as well as the series of
its annual averages. The presence of seasonality in the monthly series is quite
obvious. Also, it is evident from Figure 3.1(a) that there is strong temporal
dependence between the annual averages.
During an exploratory analysis, we veriﬁed that the seasonality can be
well explained by the ﬁrst, fourth, and ﬁfth harmonics. Figure 3.1(b) shows
the plot of the monthly residuals after extracting the overall mean and the
seasonality. Figure 3.2 shows the autocorrelation and partial autocorrelation
functions of the monthly residuals. The autocorrelation function decays fairly
slowly and thus suggests a long memory type process at the monthly level.
In contrast, Figure 3.3 shows the autocorrelation and partial autocorrela-
tion functions of the annual series, strongly suggesting an AR(1) process for
the annual level of aggregation. Thus, it seems that there are strong annual
level dynamics that are reasonably well explained by an AR(1) process. More-
over, it seems that this annual level dynamics induces the long memory type of
behavior at the monthly level. The annual level behavior is probably the result
of large-timescale climate dynamics that impact water and snow precipitation
and thus the ﬂow of the river.
This example points to the necessity of having approaches for the analysis
of processes with relevant dynamics at diﬀerent levels of resolution. Chapter 11
presents the construction of explicit multiscale time series models from
coarser to ﬁner resolution levels. These models have the ability to describe

18
3 Illustrative Example
processes that have dynamics at several time-resolution levels. In particular,
Section 11.6.1 presents an analysis of the Fraser River with a multiscale time
series model. Chapter 14 presents the computational construction of implicit
multiscale models through the use of Metropolis coupling. This approach is
illustrated on the Fraser River dataset in Section 14.2.1.
year
1920
1940
1960
1980
6.5
7.0
7.5
8.0
8.5
9.0
Time in months
1920
1940
1960
1980
−0.5
0.0
0.5
(a)
(b)
Fig. 3.1. Fraser River. (a) Log of the mean monthly ﬂows (dotted) and annual
averages (solid). (b) Monthly residuals after extracting the seasonality and the mean.
0
5
10
15
20
25
30
0.0
0.2
0.4
0.6
0.8
1.0
lag
ACF
0
5
10
15
20
25
30
−0.1
0.0
0.1
0.2
0.3
0.4
0.5
0.6
lag
Partial ACF
(a)
(b)
Fig. 3.2. Fraser River. (a) Autocorrelation and (b) partial autocorrelation functions
of monthly residuals.

3 Illustrative Example
19
0
5
10
15
−0.2
0.0
0.2
0.4
0.6
0.8
1.0
lag
ACF
5
10
15
−0.2
0.0
0.2
0.4
lag
Partial ACF
(a)
(b)
Fig. 3.3. Fraser River. (a) Autocorrelation and (b) partial autocorrelation functions
of the annual series.


Part II
Convolutions and Wavelets


Convolution and Wavelet Overview
The two methods in this section, convolutions and wavelets, are grouped to-
gether because they are both multiscale decomposition methods. They are
quite diﬀerent in ﬂavor from the explicit multiscale models of Part III (which
make up the bulk of this book), as well as from the implicit multiscale models
in Part IV. Hence they have received their own section. We include their part
ﬁrst, as some of the other methods in this book build upon their ideas. The
two methods in this part are rather diﬀerent from each other as well, both in
mechanics and applicability. Yet they share an underlying basic conceptual
approach.
The key idea is to build a model using multiple levels of components.
This is essentially a hierarchical basis decomposition. Many nonparametric
regression techniques rely on using an inﬁnite basis set that spans the space
of continuous functions. For example, the set of all polynomials spans the space
of continuous functions, as do particular sets of orthogonal polynomials (e.g.,
Legendre, Laguerre, Hermite). Similarly, Fourier series regression relies on
using a theoretically inﬁnite set of sine and cosine functions to span the space
of interest. For any of these basis function approaches, in practice only a ﬁnite
number of basis terms are used, and using enough terms gives a close enough
approximation. Additional discussion on families of nonparametric regression
methods can be found in Lee (2004, Chapter 2). Similarly, both convolutions
and wavelets can be thought of as using a basis expansion. However, the basis
functions are instead ordered hierarchically (as opposed to by the order of
the polynomial, for example), with larger-scale components being considered
ﬁrst and successively smaller-scale components added sequentially. Models can
thus be built using multiple levels of resolution. At some point, the hierarchy
is truncated when it is deemed that a suﬃcient number of kernels or wavelets
have been included.
This type of approach gives a way to model diﬀerent aspects of a dataset,
with larger-scale components modeling overall trends and smaller-scale com-
ponents modeling ﬁner details. In some cases, this additional interpretability
of the models may be beneﬁcial. Done correctly, it may be possible to match
the modeling scales to physically meaningful scales, particularly with the con-
volution approach, where the scales can be chosen more arbitrarily. In other
cases, the scales should be seen more as mathematical constructions chosen for
computational convenience, and attempting to ascribe physical interpretabil-
ity may not make sense. As always, such ideas will be highly dependent on
the particular application.
We do want to note that, for both convolutions and wavelets, most uses of
these methods in the literature are not explicitly multiscale. Most frequently,
these methods are used as nonparametric regression techniques, and they just
happen to organize their basis components hierarchically. Both approaches
have seen great successes in a large variety of applications. Wavelets in par-
ticular have found widespread popularity. However, we will skip over large

24
sections of the literature in the following chapters so that we can focus on the
aspects that are most relevant for explicit multiscale uses.

4
Convolution Methods
Standard Gaussian process models were introduced in Section 2.2. Such mod-
els gained popularity originally in geostatistical applications but have become
widely used throughout spatial statistics. In this chapter, we will see how
one can represent a Gaussian process via convolutions, which can have great
computational advantages as well as providing a rather natural mechanism
for moving to a multiscale model. Thus the latter section of this chapter will
fully explore how to use the convolution representation to build a multiscale
model.
4.1 Convolutions
A convenient way of obtaining a Gaussian process is given by convolving
white noise with a smoothing kernel (Thi´ebaux and Pedder, 1987; Barry and
Ver Hoef, 1996). Following Higdon (2002), let w(s) be a white noise process
(or Wiener process “derivative”; see, e.g., Priesley, 1981), s ∈S, and let k(·; φ)
be a kernel, possibly depending on a low-dimensional parameter φ. Then a
Gaussian process is obtained by
x(s) =

S
k(u −s; φ)w(u)du =

S
k(u −s; φ)dW(u),
(4.1)
where W is a Wiener process. The resulting process x(s) has a covariance
function that depends only on the displacement vector ds,s′ = s −s′ for
s, s′ ∈S; i.e.,
C(ds,s′) = cov(x(s), x(s′)) =

S
k(u −s; φ)k(u −s′; φ)du
=

S
k(u −ds,s′; φ)k(u; φ)du.
As noted in Kern (2000), C(ds,s′) is the convolution of the kernel with itself.
If S is Rp and k(s) is isotropic, then x(s) is also isotropic, with covariance

26
4 Convolution Methods
function C(ds,s′), which depends only on the magnitude d of ds,s′. In this
case, there is a one-to-one relationship between the smoothing kernel k(d) and
the covariogram C(d), provided either

Rp k(s)ds < ∞and

Rp k2(s)ds < ∞
or C(s) is integrable and positive deﬁnite (Thi´ebaux and Pedder, 1987). In
particular, for a given C(·), k(·; φ) can be obtained as the inverse Fourier
transform of the square root of the spectral density of C. This relationship
is based on the convolution theorem for Fourier transforms; more details can
be found in Barry and Ver Hoef (1996). An example of a ﬂexible family of
isotropic kernels is obtained from the Mat`ern class of isotropic correlations
(see, for example, Stein, 1999), which is known to correspond to processes with
widely diﬀerent degrees of smoothness. The spectral density of the correlation
function in the R2 Mat`ern class, with range λ > 0 and smoothness ν > 0, is
given by f(Υ) ∝1/(λ2 + Υ 2)ν/2+1. The corresponding kernel is the inverse
Fourier transform of 1/(λ2 + Υ 2)ν/4+1/2, which is proportional to
(λs)νKν(λs),
λ > 0, ν > 1,
(4.2)
where Kν is the modiﬁed Bessel function of the second kind of order ν
(Abramowitz and Stegun, 1964).
In the rest of this chapter, we focus the discussion and examples on
processes in one dimension. However, the results are readily applied to higher
dimensions as well. In practice, the need to model the background process
tends to limit the application of the convolution approach to three or fewer
dimensions as, with more dimensions than that, the curse of dimensionality
starts to kick in and it is typically more eﬃcient to model the Gaussian process
directly.
A discrete approximation of Equation (4.1) can be obtained by ﬁxing a
ﬁnite number of evenly spaced points, say s1, . . . , sM, and giving
x(s) ≈
M

i=1
k(si −s; φ)w(si),
(4.3)
where w(·) is white noise (Higdon, 2002). (Note that the kernel may need
to be rescaled to be comparable with Equation (4.1)). Figure 4.1 shows this
approximation in action. Each of the three plots shows a process produced
by smoothing a background process of nine points (at s = (1, . . . , 9)) drawn
independently from Gaussian distributions, w(si)
iid
∼N(0, 1), and smoothed
with a standard Gaussian kernel. The solid dark line shows the approximate
Gaussian process, and the light curves show the individual kernels, with the
smaller vertical black lines denoting the background process. The three plots
diﬀer only in that the background process has been regenerated each time.
Note that a smooth curve results from the convolution of a discrete process
and that the smoothness is a function of the choice of kernel, so all three
curves have similar smoothness and covariance structure because they were
generated using the same kernel. (The initial downward trend in all three is
a coincidence of the particular set of random numbers drawn.)

4.1 Convolutions
27
10
8
6
4
2
0
10
8
6
4
2
0
10
8
6
4
2
0
−0.4
−0.2
−0.2
0.0
0.2
0.4
s
z
−0.4
0.0
0.2
0.4
0.6
s
z
−0.5
0.0
0.5
1.0
s
z
Fig. 4.1. Examples of Gaussian processes built from discrete convolutions. The grey
lines show the individual kernels, and the dark lines are the resulting processes.
As mentioned earlier, the choice of kernel is the primary determinant of
the properties of the resulting process. Figure 4.2 demonstrates the eﬀect of
changing the kernel width on the resulting curve. The background process is
the same as in the middle plot of Figure 4.1, but the standard deviation of the
Gaussian kernels has been changed. (Note that even though the background
process is the same, the kernel heights shown in the ﬁgure vary because the
kernels are normalized to have unit area.) Whereas it was 1.0 in Figure 4.1,
in Figure 4.2 it is (from top to bottom) 0.4, 0.6, and 2.0. Notice that smaller
kernels produce more wiggly curves, while larger kernels give rise to extremely

28
4 Convolution Methods
10
8
6
4
2
0
10
8
6
4
2
0
10
8
6
4
2
0
−1.0
−0.5
−0.5
0.0
0.5
1.0
s
z
0.0
0.5
s
z
−0.2 −0.1 0.0 0.1 0.2 0.3 0.4 0.5
s
z
Fig. 4.2. Eﬀect of kernel width on the resulting Gaussian process approximation.
The kernel shape and discrete process values are the same as in the middle graph of
Figure 4.1, but the kernel width is smaller in the top two graphs and larger in the
bottom one.
smooth curves. Just as with standard approaches to Gaussian processes (see
the last paragraph of Section 2.2), if the data allow, the width of the kernel
can be treated as a parameter and ﬁt from the data along with the values of
the background process. In other cases, the kernel parameters may need to be
chosen a priori.
The choice of kernel is not restricted to the Gaussian kernels used in
Figures 4.1 and 4.2. Although they are frequently a convenient choice for

4.1 Convolutions
29
0
2
4
6
8
10
−0.4 −0.2 0.0 0.2 0.4 0.6
s
z
0
2
4
6
8
10
−0.4 −0.2
0.0
0.2
0.4
0.6
s
z
0
2
4
6
8
10
−0.4 0.2
0.0
0.2
0.4
0.6
s
z
Fig. 4.3. Eﬀect of kernel shape on the resulting Gaussian process approximation.
The discrete process values are the same as in the middle graph of Figure 4.1. The
kernels are for an exponential variogram, for a Mat´ern process with shape parameter
1.5, and the tricube kernel.
relatively smooth functions, they can be too smooth for other applications.
Examples of other choices of kernels on the same background process are
shown in Figure 4.3. The top plot shows the kernels that would lead to the
exponential variogram, suitably standardized. Note that, in a real applica-
tion, more background points would be needed for nonsmooth kernels such
as these in order to produce a good realization; here we keep the number of
background points ﬁxed for comparison with the other plots. The middle plot

30
4 Convolution Methods
shows the kernels that result in a process in the Mat´ern class with shape pa-
rameter 1.5, a curve of intermediate smoothness between the exponential and
Gaussian variograms. The bottom plot uses the tricube kernel, a local kernel
that produces a diﬀerent sort of smoothness. This kernel is given by
k(s) =

1 −|s|3
λ3
3
I[|s| < λ],
where λ is a range parameter aﬀecting the width of the kernel. Additional
discussion of the relationship between the kernel and the process is given in
Kern (2000).
A lesser issue is the choice of spacing for the background process. If the
points are too far apart, then the kernels will not be able to smooth the
process eﬀectively. But once a reasonable saturation has been reached, there
are strongly diminishing returns from adding additional background locations.
A rule of thumb given by Higdon is that a good compromise is to have the
background process locations on a grid with a distance between the nearest
points equal to the standard deviation of the kernels (although more localized
kernels such as that leading to exponential variograms will require a more
dense grid). Figures 4.4 and 4.5 show the results of ﬁtting the log of the ﬁrst
three years of the Fraser River data (from Chapter 3) with Gaussian kernels.
Here the values of the background process are ﬁt using Markov chain Monte
Carlo methods (see the next paragraph for a discussion of model ﬁtting). In
each case, Gaussian kernels with a standard deviation of four months are
used, while the spacing of the background process changes. In Figure 4.4,
the plots from top to bottom use background grid points placed every two,
three, and four months, respectively. Note that there is almost no diﬀerence
in the ﬁtted curves for the three plots. Figure 4.5 shows spacings of ﬁve, six,
and seven months, respectively, from top to bottom, and one can see that
the curves start to diﬀer from those in Figure 4.4, with a spacing of seven
months basically destroying the model. In this last case, the kernels are too
far apart. While in many cases using too few kernels results in an overly lumpy
ﬁt (overﬁtting certain regions and ignoring others), here the periodic nature
of the data results in the best kernel ﬁt being close to constant. In summary,
spacing the background points equal to the standard deviation of the kernel
is usually suﬃcient, in that little additional gain is to be had by using more
background points. One can sometimes get away with using even fewer, but
using too few leads to degradation in the ﬁt. Also note that it is helpful for
the background grid to be slightly larger than the space of the observed data,
so that there is a buﬀer of at least one point in each direction outside of the
convex hull of observed points.
Fitting a convolution-based process to data is a matter of ﬁnding the val-
ues of the background process points, and often also ﬁtting some or all of
the other parameters in the model (parameters deﬁning the kernel, the vari-
ance of the error terms, the variance of the background process, and any
parameters in the mean function of the process). Higdon (2002) provides a

4.1 Convolutions
31
*
*
*
*
*
*
* *
*
*
*
*
*
* *
*
*
* *
*
* * *
*
* * *
*
* * *
*
*
* *
*
0
5
10
15
20
25
30
35
6.5
7.0
7.5
8.0
8.5
9.0
s
z
*
*
*
*
*
*
* *
*
*
*
*
*
* *
*
*
* *
*
* * *
*
* * *
*
* * *
*
*
* *
*
0
5
10
15
20
25
30
35
6.5
7.0
7.5
8.0
8.5
9.0
s
z
*
*
*
*
*
*
* *
*
*
*
*
*
* *
*
*
* *
*
* * *
*
* * *
*
* * *
*
*
* *
*
0
5
10
15
20
25
30
35
6.5
7.0
7.5
8.0
8.5
9.0
s
z
Fig. 4.4. Eﬀect of kernel spacing on the resulting Gaussian process approximation.
The background points are spaced 2, 3, and 4 units apart in the plots.
worked-out example with code in R or S (which can also be found in the
technical report version, Duke Institute of Statistics and Decision Sciences
working paper 01-03). We also provide basic code at the Web site for this
book (http://www.ams.ucsc.edu/~herbie/multiscale). If all of the other
parameters are taken as known, then the problem is equivalent to ﬁtting a
mixed-eﬀects model and can be done via restricted maximum likelihood esti-
mation (REML), such as with the E-M algorithm (Dempster et al., 1984). In
a fully Bayesian setting, the posterior is not generally available in closed form,
and Markov chain Monte Carlo methods are necessary. MCMC theoretically

32
4 Convolution Methods
*
*
*
*
*
*
* *
*
*
*
*
*
* *
*
*
* *
*
* * *
*
* * *
*
* * *
*
*
* *
*
0
5
10
15
20
25
30
35
6.5
7.0
7.5
8.0
8.5
9.0
s
z
*
*
*
*
*
*
* *
*
*
*
*
*
* *
*
*
* *
*
* * *
*
* * *
*
* * *
*
*
* *
*
0
5
10
15
20
25
30
35
6.5
7.0
7.5
8.0
8.5
9.0
s
z
*
*
*
*
*
*
* *
*
*
*
*
*
* *
*
*
* *
*
* * *
*
* * *
*
* * *
*
*
* *
*
0
5
10
15
20
25
30
35
6.5
7.0
7.5
8.0
8.5
9.0
s
z
Fig. 4.5. Eﬀect of kernel spacing on the resulting Gaussian process approximation.
The background points are spaced 5, 6, and 7 units apart in the plots.
also allows ﬁtting any number of other parameters in the model. In practice,
the data may be limited in the amount of information that they provide, and
some of the parameters may need to be ﬁxed a priori. Note also that some care
must be taken with the priors for the kernel parameters, in that improper pri-
ors may lead to improper posteriors (Berger et al., 2001). Using proper priors
for the kernel parameters avoids this problem.
This ﬁnite representation has many computational advantages, as only a
relatively small number of sites si are necessary for a close approximation,
saving much computing time. This reduction in dimension is also useful for a

4.2 Multiscale Convolutions
33
variety of theoretical reasons; for example, many inverse problems are dras-
tically ill-conditioned, and the dimension reduction of the parameter space
greatly aids in the ability to conduct inference. Note that this approach still
produces a continuous process, even though the underlying process is discrete.
The class of resulting spatial processes can be enlarged by either allow-
ing the kernel to vary spatially (Higdon et al., 1999) or by changing the
background process. Examples of the latter include background processes of
Gaussian processes (Fuentes and Smith, 2001), Markov random ﬁelds (Lee
et al., 2005), and non-Gaussian processes (Ickstadt and Wolpert, 1999). Some
similar ideas have also appeared in the spatio-temporal literature (Wikle et al.,
1998; Calder et al., 2002; Stroud et al., 2001).
4.2 Multiscale Convolutions
The convolution approach to generating Gaussian processes is easily adapted
to model a process at multiple resolutions (Higdon, 2002). The process is
taken to be a sum of separate component processes at diﬀerent resolutions,
accumulating from coarse to ﬁne. Finer levels use kernels of smaller width on
a larger number of background grid points. To be explicit, the multiresolution
process with L levels is given by
x(s) =
L−1

l=0
xl(s) =
L−1

l=0
ml

i=1
kl(si −s; φ)wl(si),
(4.4)
where xl(s) is the lth resolution process, and each of these processes is gener-
ated from a convolution of kernels kl on an appropriate resolution background
process wl. As before, a mean term or mean function can be added in as well.
If the process is observed on multiple scales, then the terms accumulate
only to the scale being modeled. For example, if observations occur at three
scales, then the coarsest is modeled as just x0(s), while the intermediate
process is modeled with x0(s)+x1(s) and the ﬁnest with x0(s)+x1(s)+x2(s),
i.e.,
yl(tj) = µl(tj) +
l

q=0
mq

i=1
kq(si −tj; φ)wq(si) + εl(tj),
(4.5)
where yl(tj) is an observation of the process at the lth scale, j ∈{1, . . . , nl},
tj ∈Sl (the same space as the si, which often does not depend on scale), µl(s)
is the mean process at scale l (taken here as a constant at each scale, but
this could be easily generalized), and εl(tj) is iid mean zero Gaussian error
whose variance could depend on the scale. Additional scales can be added
for computational or modeling reasons at any point, and they accumulate
appropriately.
If the process is only observed at a single scale, this formulation can still
be useful for explicitly modeling large-scale trends separately from small-scale
activity, as with the examples below.

34
4 Convolution Methods
A typical structure would be for xl+1 (the next ﬁner resolution than xl) to
have kernels kl+1 with eﬀective width (e.g., standard deviation for a normal)
one half that of kl and to use twice as many grid cells in each dimension for
wl+1 as compared to wl. Clearly this is most practical for only a small number
of scales in a relatively small number of dimensions, as the computational
requirements can quickly grow out of hand. Computational restrictions or
information about the problem of interest may suggest other designs.
Choosing appropriate priors becomes more diﬃcult than in the single-
resolution setting, where one may have a good idea about what the process
should look like. It may be harder to have good intuition about a multiresolu-
tion process (although sometimes the problem will have useful information to
incorporate). Thus it can be helpful to have default priors that work reason-
ably well in a variety of situations. Following Higdon (2002), we have found
that vaguely informative priors on a small hierarchy work well in practice.
Both the background processes and the observational error are taken to be
Gaussian with unknown precision (the reciprocal of the variance, which helps
simplify the structure). The gamma distribution is conditionally conjugate for
the precision of a normal, and a reasonable vague speciﬁcation for a gamma
is with shape parameter 1 and mean 200 (which is an exponential with rate
0.005). With more information, other gamma parameters or other distribu-
tions can be used. These parameters can also vary by resolution. In the absence
of such information, these values provide a good starting point. Thus the full
hierarchical model is
εl(tj) ∼N(0, λ−1
y )
l = 0, . . . , L −1; j = 1, . . . , nl
wl(si) ∼N(0, λ−1
w )
l = 0, . . . , L −1; i = 1, . . . , ml
λw ∼Γ(1, 0.005)
λy ∼Γ(1, 0.005).
This setup is easily expanded to allow diﬀerent hyperparameters on the λ
parameters at diﬀerent scales if desired. If a mean parameter is included, it
can either be given a ﬂat prior or the same prior as the background process
(which helps to simplify the computations).
As with the single-resolution convolution model, the background process
can be ﬁt via either REML or MCMC, and the full posterior including un-
known parameters can be found with MCMC methods (Higdon, 2002). We
provide basic code for multiresolution modeling with convolutions at our Web
site (http://www.ams.ucsc.edu/~herbie/multiscale). This code can serve
as a template and is easily modiﬁed for a variety of more complex situations.
4.2.1 Synthetic Example
The example in this section is inspired by one from Higdon (2002) and is of a
known process that is composed of two subprocesses that are harmonic with

4.2 Multiscale Convolutions
35
****
*
*
*
**
***
***
**
*
*
*
*
***
*
**
*
****
*****
*
*
**
****
*
****
**
****
*
*
*
**
*
**
*
**
*
***
****
*
*
*
*
*
0
10
20
30
40
−1.5 −1.0 −0.5
0.0
0.5
1.0
s
z
****
*
*
*
**
***
***
**
*
*
*
*
***
*
**
*
****
*****
*
*
**
****
*
****
**
****
*
*
*
**
*
**
*
**
*
***
****
*
*
*
*
*
0
10
20
30
40
−1.5 −1.0 −0.5
0.0
0.5
1.0
s
z
****
*
*
*
**
***
***
**
*
*
*
*
***
*
**
*
****
*****
*
*
**
****
*
****
**
****
*
*
*
**
*
**
*
**
*
***
****
*
*
*
*
*
10
10
20
30
40
−1.5 −1.0 −0.5
0.0
0.5
1.0
s
z
Fig. 4.6. Standard convolutions ﬁt to synthetic data. The Gaussian kernels have
standard deviation 5, 2, and 1. Dark lines show the ﬁtted functions, light lines the
true function.
diﬀerent periods. Thus this example is of a process observed on a single scale
but that can be modeled in a multiscale manner. In particular, the data are
generated from the true function plus Gaussian noise
y(ti) = sin
2πti
20

+ cos
2πti
4

+ ε(ti)
for ti ∈(1, 40) and ε(ti) ∼N(0, (0.1)2). The truth is shown in Figures 4.6
and 4.7 as the solid grey line, with the generated data shown as the points

36
4 Convolution Methods
scattered about the line. This truth is a combination of a lower-frequency
smooth sine curve and a higher-frequency cosine curve, and the convolution
approach provides a mechanism for capturing both of these pieces simultane-
ously. For comparison, ﬁrst standard single-scale convolutions are ﬁt to the
data, with Figure 4.6 showing the results of ﬁtting convolutions using Gaussian
kernels with standard deviations 5, 2, and 1 (from top to bottom). The ﬁtted
curves are shown with dark solid lines. Note that there is little diﬀerence be-
tween the ﬁrst two, even though only ten background points are used in the
ﬁrst while 22 are used in the second. The last plot uses 43 background points
(on the unit locations from 0 to 42) and achieves a much ﬁner resolution of
ﬁt, as the smaller kernels allow a closer ﬁt. The ﬁrst two choices of kernels are
too smooth to fully model this particular dataset with only a single scale.
Figure 4.7 demonstrates the results of using multiscale convolution models.
First, for comparison, the top plot again shows the ﬁt with a single convolution
with standard deviation one Gaussian kernels and also plots all of the indi-
vidual kernels. The second plot shows a multiresolution model with Gaussian
kernels of standard deviations 5 and 1 and also shows the individual kernels,
with dashed lines for the larger kernels and dotted lines for the smaller ones.
The third plot shows a multiresolution model with Gaussian kernels of stan-
dard deviations 3 and 1, and leaves out the individual kernels to reduce the
clutter in the plot. First, note that all three ﬁtted curves are very similar, so,
as before, the larger-scale process can be modeled by a range of possible larger
kernels. Now compare the individual kernels in the top two plots. Notice that
in the second plot the larger kernels capture the larger motion of the sine
curve, while the smaller kernels capture the ﬁner motion of the cosine curve.
The smaller kernels can be viewed as modeling the local deviations from the
larger process. In contrast, in the top plot, the smaller kernels have to do
double duty, modeling both the ﬁner and coarser processes at the same time.
If one really only cares about the ﬁnest scale, such as with interpolation or
prediction, then the single-scale model will work just ﬁne. But if one is trying
to understand the underlying process at multiple scales (e.g., a process such
as pollution that has both weekly and daily cycles), then the multiresolution
convolution is more appropriate, as it can produce separate ﬁts for the two
separate cycles.
4.2.2 Fraser River Example
We now return to the ongoing Fraser River example (introduced in Chap-
ter 3). While Figure 4.4 shows the results of a convolution process using only
a single set of kernels, Figure 4.8 shows a multiresolution example. The top
plot shows the ﬁt from a multiresolution convolution using Gaussian kernels
of standard deviations 4 and 1, with the kernels spaced on a grid of match-
ing size (i.e., one background point every four units for the larger kernels,
one every unit for the smaller kernels), with the inclusion of one additional
background point on either end (to help eliminate edge eﬀects). Notice that

4.2 Multiscale Convolutions
37
****
*
*
*
**
***
***
**
*
*
*
*
***
*
**
*
****
*****
*
*
**
****
*
****
**
****
*
*
*
**
*
**
*
**
*
***
****
*
*
*
*
*
0
10
20
30
40
−1.5 −1.0 −0.5
0.0
0.5
1.0
s
z
****
*
*
*
**
***
***
**
*
*
*
*
***
*
**
*
****
*****
*
*
**
****
*
****
**
****
*
*
*
**
*
**
*
**
*
***
****
*
*
*
*
*
0
10
20
30
40
−1.5 −1.0 −0.5
0.0
0.5
1.0
s
z
****
*
*
*
**
***
***
**
*
*
*
*
***
*
**
*
****
*****
*
*
**
****
*
****
**
****
*
*
*
**
*
**
*
**
*
***
****
*
*
*
*
*
0
10
20
30
40
−1.5 −1.0 −0.5
0.0
0.5
1.0
s
z
Fig. 4.7. Standard and multiresolution convolutions ﬁt to synthetic data. The top
plot shows a standard convolution with its Gaussian kernels of standard deviation
1. The middle plot shows a multiresolution ﬁt with its kernels of sizes 5 and 1. The
bottom plot shows just the ﬁt for kernels of sizes 3 and 1. Dark lines show the ﬁtted
functions, light solid lines the true function.
the ﬁt is slightly better than in Figure 4.4. For comparison, the bottom plot
of Figure 4.8 shows a single-resolution ﬁt using smaller kernels of standard
deviation 2. Note that the ﬁtted curves in the top and bottom plots are quite
similar. The middle plot shows the decomposition of the multiresolution ﬁt,
with the ﬁts due to the larger and smaller kernels graphed separately (with
the smaller kernel eﬀects being shown as deviations from the mean level). The

38
4 Convolution Methods
*
*
*
*
*
*
* *
*
*
*
*
*
* *
*
*
* *
*
* * *
*
* * *
*
* * *
*
*
* *
*
0
5
10
15
20
25
30
35
6.5
7.0
7.5
8.0
8.5
9.0
s
z
*
*
*
*
*
*
* *
*
*
*
*
*
* *
*
*
* *
*
* * *
*
* * *
*
* * *
*
*
* *
*
0
5
10
15
20
25
30
35
6.5
7.0
7.5
8.0
8.5
9.0
s
z
*
*
*
*
*
*
* *
*
*
*
*
*
* *
*
*
* *
*
* * *
*
* * *
*
* * *
*
*
* *
*
0
5
10
15
20
25
30
35
6.5
7.0
7.5
8.0
8.5
9.0
s
z
Fig. 4.8. Multiresolution and standard convolutions ﬁt to the Fraser River data.
The top plot shows a multiresolution ﬁt with Gaussian kernels of sizes 4 and 1. The
middle plot shows the separate ﬁt components for the larger and smaller kernels.
The bottom plot shows a standard convolution with Gaussian kernels of standard
deviation 2.
annual trend is neatly captured by the larger (standard deviation 4) kernels,
while a shorter-term, presumably seasonal, trend is captured by the smaller
kernels. Thus, when interpretability at multiple scales is required, multireso-
lution convolutions provide a convenient representation.

5
Wavelet Methods
Wavelets are one of the most well-known multiscale techniques and have been
extensively explored in statistical applications in the 1990s and the 2000s.
Wavelets are powerful mathematical tools that have been used with success
in the compression of images and in the analysis of signals. They decompose
signals and images in components spatially localized at diﬀerent levels of res-
olution known as wavelet coeﬃcients.
Bayesian wavelet analysis is useful when the signal is subject to random
error. In that case, the wavelet transform of the observations will provide noisy
empirical wavelet coeﬃcients. In Bayesian analysis, the use of a joint prior dis-
tribution for the wavelet coeﬃcients and an appropriate loss function will lead
to a Bayesian estimate that will shrink or threshold the empirical wavelet co-
eﬃcients toward zero. The inverse wavelet transform of the estimated wavelet
coeﬃcients will provide a noise-free estimate of the signal.
In this book, we focus not only on multiscale decomposition methods such
as wavelets but also on other multiscale statistical models. These other models
are more suitable for time series prediction, for problems where data are avail-
able at diﬀerent resolution levels, or when dealing with a natural multiscale
stochastic process.
While Fourier analysis decomposes a signal into its frequency components,
a wavelet analysis decomposes a signal into its time-scale (or time-frequency)
components. Wavelet functions are obtained by translations and scalings of
the so-called mother wavelet. The mother wavelet is a function that has some
properties related to the very name wavelet. The ﬁrst property, known as the
admissibility condition, implies that the mother wavelet integrates to zero,
and thus it is a wave. The second property, known as the regularity condition,
implies that the mother wavelet has vanishing moments, and, as a conse-
quence, it is well localized. A function with these properties is then a small
wave – a wavelet. This chapter is intended to give an overview on wavelets.
For more detailed information on wavelets, the reader is referred to the ex-
cellent books by Daubechies (1992), Mallat (1999), and Vidakovic (1999). A

40
5 Wavelet Methods
comprehensive overview of Bayesian wavelet methods is given in M¨uller and
Vidakovic (1999a).
This chapter is organized as follows. Section 5.1 provides some notation
and background information. Section 5.2 presents the continuous wavelet
transformation. Section 5.3 introduces the scaling function. Section 5.4 pres-
ents discrete wavelets and the discrete wavelet transform. Bayesian nonpara-
metric regression using wavelets is discussed in Section 5.5.
5.1 Background
Wavelets can be used to analyze functions f(t) that belong to the set of ﬁnite
energy functions L2(R); that is,
 +∞
−∞|f(t)|2dt < +∞.
In the deﬁnition of the wavelet transform, we will use inner products be-
tween functions, deﬁned as ⟨f, g⟩=
 +∞
−∞f(t)g(t)dt, where g(t) is the complex
conjugate of g(t). Moreover, we will consider here the L2 norm: ||f|| = ⟨f, f⟩.
A wavelet is a function ψ ∈L2(R) such that
•
 +∞
−∞ψ(t)dt = 0;
•
||ψ|| = 1.
The function ψ may be used to generate by translation and scaling op-
erations a whole family of wavelets. For this reason, ψ is called the mother
wavelet. More precisely, translating ψ by u and scaling it by s leads to
ψsu(t) = 1
√sψ
t −u
s

,
(5.1)
where u ∈R and s ∈R+. Depending on whether s < 1 or s > 1, then ψs0 will
be a contracted or an expanded version of ψ, respectively.
The simplest and maybe most well-known wavelet is the Haar wavelet
(Haar, 1910). The mother Haar wavelet is
ψ(t) =
⎧
⎨
⎩
1,
0 ≤t < 0.5,
−1,
0.5 ≤t < 1,
0,
otherwise.
Due to its blockiness, the Haar wavelet is not appropriate to approximate
smooth functions. Fortunately, there are many other families of wavelets. In
particular, the Daubechies wavelet family (Daubechies, 1992) has been ex-
tensively used in statistical applications because its members have compact
support and can be chosen according to the smoothness of the function of
interest.

5.2 Continuous Wavelet Transform
41
5.2 Continuous Wavelet Transform
A continuous wavelet transform (CWT) can be used to decompose any ﬁ-
nite energy function in its time-scale components, and an inverse continuous
wavelet transform can be used to perfectly reconstruct that function. This
ability mirrors that of the Fourier transform for the analysis of stationary
signals.
The CWT of f based on ψ computed for translation u and scale s is deﬁned
as
W ψ
f (s, u) = ⟨f, ψsu⟩=
 +∞
−∞
f(t)ψsu(t)dt.
(5.2)
When applied to a one-dimensional function, the CWT is a two-dimensional
function and thus is a highly redundant transform. We will go back to this
redundancy later.
Let us consider the admissibility condition (Calder´on, 1964; Grossmann
and Morlet, 1984)
Cψ =
 ∞
−∞
| ˆψ(w)|2
|w|
dw < ∞,
where ˆψ(w) =
 ∞
−∞ψ(t)e−iwtdt, the Fourier transform of ψ, measures the
amount of oscillation of ψ at the frequency w. The admissibility condition
implies that ˆψ(0) = 0. But ˆψ(0) =
 ∞
−∞ψ(t)dt and thus the mother wavelet
integrates to zero.
If the mother wavelet ψ(t) satisﬁes the admissibility condition, then any
function f ∈L2(R) satisﬁes (Calder´on, 1964; Grossmann and Morlet, 1984)
f(t) =
1
Cψ
 +∞
0
 ∞
−∞
1
s2 W ψ
f (s, u)ψsu(t)duds;
that is, the CWT based on ψ(t) is invertible. Moreover, under the admissibility
condition, a continuous wavelet transform conserves energy:
 ∞
−∞
|f(t)|2dt =
1
Cψ
 +∞
0
 ∞
−∞
1
s2 |W ψ
f (s, u)|2duds.
As mentioned before, the continuous wavelet transform is highly redun-
dant. That is because two diﬀerent wavelets ψsu and ψs0u0 are in general
nonorthogonal. The correlation between ψsu and ψs0u0 is measured by the
so-called reproducing kernel K(s, u, s0, u0) = ⟨ψsu, ψs0u0⟩. It is easy to show
that
W ψ
f (s0, u0) =
1
Cψ
 +∞
0
 ∞
−∞
1
s2 K(s, u, s0, u0)W ψ
f (s, u)duds.
The preceding equation is known as the reproducing kernel equation.

42
5 Wavelet Methods
As the CWT is redundant, one can reduce the computational eﬀort by
using discrete values of u and s and still have an invertible transformation.
The most used discretization is deﬁned by
u = 2−lk, s = 2−l, k, l ∈Z.
As discretizations coarser than this discretization do not lead to an invert-
ible transformation, the discretization above is known as critical sampling.
When using critical sampling, the wavelet at scale l and translation k can be
rewritten as
ψlk(t) = 2l/2ψ

2lt −k

.
(5.3)
For a positive integer l, ψl0 is a contracted version of the mother wavelet
ψ, whereas for negative integer l, ψl0 is an expanded version of the mother
wavelet. Thus, larger l’s will correspond to ψlk being able to capture localized
high-frequency details, whereas smaller l’s will correspond to ψlk being able
to capture global low-frequency behavior.
Under mild conditions, {ψlk(t), l, k ∈Z} will be an orthogonal basis for
L2(R) (see Vidakovic, 1999). In that case, any function f ∈L2(R) can be
expanded as
f(t) =

l,k∈Z
ψlk(t)W ψ
f (2−l, 2−lk).
(5.4)
Henceforth, we consider orthogonal wavelets with critical sampling.
5.3 Scaling Function
Very often in practice the wavelet transform of a function f will be computed
only for scales l larger than a given threshold l0. In order to recover the
function f, it will be necessary to have a coarser version of f at scale l0. This
coarser version will be obtained with the help of the so-called scaling function.
The scaling function φ, also known as the father wavelet, can be seen as
an aggregation of wavelets at scales l coarser than 0. Let us deﬁne
φlk(t) = 2l/2φ(2lt −k).
The scaling function φ is such that {φl0k, ψlk, l > l0, k ∈Z} is an orthogonal
basis for L2(R).
Let us deﬁne
Lφ
f(l, k) = ⟨f, φlk⟩.
The coarser approximation of f at scale l0 is

k∈Z
φl0k(t)Lφ
f(l0, k).
Thus, the wavelet expansion (5.4) becomes

5.4 Discrete Wavelets and the Discrete Wavelet Transform
43
f(t) =

k∈Z
φl0k(t)Lφ
f(l0, k) +

l≥l0

k∈Z
ψlk(t)W ψ
f (2−l, 2−lk).
(5.5)
For the Haar wavelet, the corresponding scaling function is:
φ(t) =
1,
0 ≤t < 1,
0,
otherwise.
When using the Haar wavelet, the coarser version of a function f at res-
olution level l0 will be a step function with step lengths equal to 2−l0 and
with step value equal to the mean of the function in the corresponding in-
terval. We can then consider a succession of coarser versions of f at diﬀer-
ent resolution levels, as illustrated in Figure 5.1 for the function HeaviSine
f(t) = 4 sin(4πt) −sign(t −0.3) −sign(0.72 −t) considered by Donoho and
Johnstone (1994). Figure 5.1 shows the original function and coarser versions
at resolution levels 3 through 7. At resolution level 3, the approximation is
very rough, but as the resolution level increases more details are added, and
at resolution level 7 the approximation is very close to the original function.
The approximations at diﬀerent resolution levels may highlight diﬀerent as-
pects of the function of interest. For example, the approximation at resolution
level 3 highlights the large-scale features of the HeaviSine function, such as
the existence of two major valleys and two major hills. Complementarily, the
approximation at resolution level 7 highlights small-scale features of the func-
tion, such as the discontinuities and one peak that was hidden in the level 3
analysis.
5.4 Discrete Wavelets and the Discrete
Wavelet Transform
In practice, the function f will not be observed continuously but instead will be
sampled within a given interval of the real line with measurement error. In this
section, we consider the case without measurement error, and in Section 5.5
we consider the case with measurement error. As often found in practice,
we assume here that the function is sampled at equally spaced intervals and
there are n = 2L sampled points. The discrete wavelet transform will consider
wavelet and scaling functions sampled at those same points. As in the wavelet
analysis for continuous functions, the discretized function will be expanded in
terms of the discretized wavelet and scaling functions.
Without loss of generality, assume that the observations are taken on the
interval [0, 1]. Denote by ti = (i −1) 2−L and by fi = f(ti), i = 1, . . . , 2L the
sampling points and the sampled values of the function f.
As the sampled interval is ﬁnite, there is a lower limit for the coarsest
possible scale, which we assume to be l = 0. Moreover, as the number of
sampled points is 2L, the ﬁnest possible scale is l = L −1.

44
5 Wavelet Methods
0.0
0.5
1.0
−6
−1
4
0.0
0.5
1.0
−6
−1
4
(a)
(b)
0.0
0.5
1.0
−6
−1
4
0.0
0.5
1.0
−6
−1
4
(c)
(d)
0.0
0.5
1.0
−6
−1
4
0.0
0.5
1.0
−6
−1
4
(e)
(f)
Fig. 5.1. Function HeaviSine (a) and its Haar-wavelet-based coarser versions at
resolution levels 3 (b), 4 (c), 5 (d), 6 (e), and 7 (f).
The values of the discretized scaling and wavelet functions computed at
ti, i = 1, . . . , n, will be denoted by φi and ψlki. Depending on boundary condi-
tions, the discretization may or may not lead to orthogonal vectors. Here we
assume that the necessary boundary corrections are made and (φ1, . . . , φn)
and (ψlk1, . . . , ψlkn), l = 0, . . . , L−1, k = 0, . . . , 2l −1, are orthogonal vectors.
Please refer to Cohen et al. (1993) for information on the boundary correction.
In the case of the Haar wavelet, the discretized scaling and wavelet func-
tions are

5.4 Discrete Wavelets and the Discrete Wavelet Transform
45
φi =
1
√nφ(ti),
ψlki =
1
√nψlk(ti).
The discrete wavelet transform (DWT) computed for scale l and transla-
tion k will be
dlk =
n

i=1
fiψlki,
and the coeﬃcient for the coarse approximation of f at scale 0 will be c0 =
n
j=1 fjφj.
The discrete wavelet expansion of fi, i = 1, . . . , n, will be
fi = c0φi +
L−1

l=0
2l−1

k=0
dlkψlki.
(5.6)
A coarse version of fi at resolution level l0 will be
fi = c0φi +
l0

l=0
2l−1

k=0
dlkψlki.
(5.7)
The higher-resolution wavelet terms can then be included sequentially and
will provide a succession of coarser versions of fi. Analogously to the example
provided by Figure 5.1 for the continuous case, a look at the succession of
approximations may highlight small-, medium-, and large-scale features of
the discretized function.
In practice, the DWT is performed with a fast cascade algorithm (Mallat,
1989) with O(n) operations. For details on the cascade algorithm, please refer
to Mallat (1999) and Vidakovic (1999).
5.4.1 Application: Image Compression
We illustrate here the power of the discrete wavelet transform for image com-
pression. Figure 5.2(a) presents a 512 × 512 image of the sunset in B´uzios,
Rio de Janeiro, Brazil. Using the R package Wavethresh (Nason, 1998), we ap-
plied the wavelet transform to the sunset image using the Daubechies wavelets
with 6 vanishing moments and periodic boundary treatment. After that, we
assigned value zero to the 95% smallest (in absolute value) wavelet coeﬃ-
cients, an operation known in the wavelets literature as thresholding. Finally,
we applied the inverse wavelet transform to the thresholded wavelet coeﬃ-
cients to obtain the image shown in Figure 5.2(b). The compression of the
image is incredible: with only 5% of the wavelet coeﬃcients, Figure 5.2(b) is
indistinguishable from Figure 5.2(a).

46
5 Wavelet Methods
(a)
(b)
Fig. 5.2. Sunset in B´uzios, Rio de Janeiro, Brazil. Example of image compression
with Daubechies wavelets. (a) Original image. (b) Reconstructed image using the
5% largest wavelet coeﬃcients.
5.5 Bayesian Nonparametric Regression with Wavelets
Wavelets have been shown to possess near-minimax optimality when used for
nonparametric regression (Donoho and Johnstone, 1994, 1995). The procedure
is very simple: the discrete wavelet transform is applied to the observed data,
and the resulting empirical wavelet coeﬃcients are shrunk toward zero and
transformed back to the data domain by the inverse discrete wavelet trans-
form. Several approaches based on the Bayesian paradigm have been shown
to provide a smaller mean square error than the procedures of Donoho and
Johnstone (1994, 1995) for diﬀerent test functions (e.g., Chipman et al., 1997;
Clyde et al., 1998). Moreover, these Bayesian approaches may incorporate
prior beliefs about the regularity of the function through the joint prior dis-
tribution of the wavelet coeﬃcients. The several Bayesian approaches diﬀer
with respect to the prior distribution of the coeﬃcients, the prior distribution
of the other model parameters, the loss function, and the estimation method.
Initial Bayesian approaches assumed independent prior distributions for
each wavelet coeﬃcient with diﬀerent hyperparameters at diﬀerent resolutions
(Chipman et al., 1997; Abramovich et al., 1998; Vidakovic, 1998; Clyde et al.,
1998). Chipman et al. (1997) assumed as independent priors for the coeﬃ-
cients a mixture of two normals, whereas Abramovich et al. (1998) and Clyde
et al. (1998) assumed a mixture of a normal and a point mass at zero, and
Vidakovic (1998) assumed Student-t priors. With respect to the loss function,
Chipman et al. (1997), Vidakovic (1998), and Clyde et al. (1998) considered
the quadratic loss, whereas Abramovich et al. (1998) considered the absolute
loss function. An interesting aspect of the use of the absolute loss function is

5.5 Bayesian Nonparametric Regression with Wavelets
47
that the estimator is the posterior median; as a result, some wavelet coeﬃ-
cients may be estimated as equal to zero. As this may lead to signal repre-
sentations based on a few wavelet coeﬃcients diﬀerent from zero, this may be
particularly useful when the objective is to compress the signal. An alterna-
tive that also leads to wavelet coeﬃcients estimated as zero is to use Bayesian
hypothesis tests (e.g., see Vidakovic, 1998). As the speciﬁcation of the priors
for the hyperparameters is not an easy task in wavelet nonparametric regres-
sion, Abramovich et al. (1998) and Clyde and George (2000) have proposed
empirical Bayes estimation for wavelets. Finally, the model can be made more
robust by using Student-t errors (Vidakovic, 1998; Clyde and George, 2000).
Vannucci and Corradi (1999a) have presented a recursive approach to com-
puting the covariances between the empirical wavelet coeﬃcients within and
across scales. Based on the empirical wavelet coeﬃcients’ covariance structure,
Vannucci and Corradi (1999a,b) have proposed a joint prior distribution for
the wavelet coeﬃcients. In a related approach, Vidakovic and M¨uller (1995)
have proposed a joint prior distribution for the wavelet coeﬃcients that as-
sumes independence across scales and dependence within scales. In a fairly
diﬀerent approach, Crouse et al. (1998) and Nowak (1999) model the depen-
dence between wavelet coeﬃcients using hidden Markov models on trees. For
an introduction to hidden Markov models on trees, see Chapter 8.
5.5.1 Statistical Model
In nonparametric regression with wavelets, it is assumed that observations
y1, . . . , yn are taken with measurement error at equally spaced points t1, . . . , tn,
where, as in Section 5.4, ti = (i −1)2−L. Formally
yi = f(ti) + ϵi = fi + ϵi,
(5.8)
where fi can be expanded with the discrete wavelet expansion (5.6). Using
that expansion, Equation (5.8) can be rewritten in matrix notation as
y = Wβ + ϵ,
(5.9)
where y = (y1, . . . , yn)′, ϵ = (ϵ1, . . . , ϵn)′ ∼N(0, σ2I), β = (c0, d00, d10, d11,
. . . , dL−1,2L−1−1)′ is the n-dimensional vector of wavelet coeﬃcients and
W =
⎡
⎢⎢⎢⎣
φ1 ψ001 ψ101 ψ111 . . . ψL−1,2L−1−1,1
φ2 ψ002 ψ102 ψ112 . . . ψL−1,2L−1−1,2
...
...
...
...
...
φn ψ00n ψ10n ψ11n . . . ψL−1,2L−1−1,n
⎤
⎥⎥⎥⎦
(5.10)
is the n×n orthogonal matrix that contains the discretized scaling and wavelet
functions.
The discrete wavelet transform of the observations y1, . . . , yn corresponds
to the multiplication of y by W′. Let d = W′y be the vector of empirical

48
5 Wavelet Methods
wavelet coeﬃcients. In addition, let ε = W ′ϵ ∼N(0, σ2I). Then, regression
(5.9) becomes
d = β + ε.
(5.11)
As wavelet representations of functions will typically have a few large (in
absolute value) wavelet coeﬃcients and many zero or close to zero, it is reason-
able to assume sparsity of the vector β. This knowledge can be incorporated
in the model with independent mixtures of a Gaussian and a point mass at
zero as prior distributions for the elements of β as proposed by Abramovich
et al. (1998) and Clyde et al. (1998),
dlk ∼wlN(0, clσ2) + (1 −wl)δ(0),
where δ(0) represents a point mass at zero, wl is the expected fraction of
nonzero wavelet coeﬃcients at level l, and cl is related to the magnitude of
the coeﬃcients at level l.
A full Bayesian analysis requires the assignment of priors for the hyper-
parameters σ2, w0, . . . , wL−1, c0, . . . , cL−1. Moreover, a full Bayesian analysis
may require MCMC-based methods. This type of analysis takes into account
all sources of uncertainty and can be extended to more complex situations,
such as, for example, nonequally spaced regression and hierarchical functional
analysis. For a nice introduction to MCMC methods for wavelets, see M¨uller
and Vidakovic (1999b).
In practice, very often a lack of prior knowledge about the function f
will prevent the elicitation of priors for the hyperparameters. Moreover, an
MCMC-based full Bayesian analysis may be computationally too expensive.
As an alternative, empirical Bayes approaches are often used (e.g., Clyde and
George, 2000). Typically, an empirical Bayes approach estimates the hyper-
parameters σ2, w0, . . . , wL−1, c0, . . . , cL−1 using method of moments or max-
imum likelihood and then replaces the hyperparameters with their estimates
in the posterior analysis of the wavelet coeﬃcients.
5.5.2 Estimation of Hyperparameters
An approach that works well in practice is to estimate σ2 using the median
absolute deviation estimator (Donoho and Johnstone, 1995; Donoho et al.,
1995)
ˆσ =
1
0.6745mediank(| ˆdL−1,k|).
This estimator uses the fact that most empirical wavelet coeﬃcients at the
ﬁnest resolution level will be just white noise. Moreover, use of the median
provides a robust estimator in case some signal is present at the ﬁnest reso-
lution level through a few large coeﬃcients.
Conditional on σ = ˆσ, the remaining hyperparameters can be estimated
via maximum likelihood. Integrating out β, the empirical wavelet coeﬃcients

5.5 Bayesian Nonparametric Regression with Wavelets
49
will be conditionally independent given w0, . . . , wL−1, c0, . . . , cL−1. In that
case,
ˆdlk ∼wlN(0, (1 + cl)σ2) + (1 −wl)N(0, σ2),
and the likelihood function of wl, cl will be proportional to

k

wl
√1 + cl
exp

−
1
2(1 + cl)σ2

ˆd2
lk

+ (1 −wl) exp

−1
2σ2

ˆd2
lk

.
In order to ﬁnd ˆw0, . . . , ˆwL−1, ˆc0, . . . , ˆcL−1, the maximization of the likelihood
function above has to be performed numerically. Clyde and George (2000)
maximize this function with nonlinear Gauss-Seidel iteration, whereas John-
stone and Silverman (1998) use an EM algorithm (Dempster et al., 1977); in
practice, both methods have similar performance.
The estimation of one pair (wl, cl) for each resolution level may lead to
high frequentist variance of hyperparameter estimates and overly adaptive es-
timated curves. In order to ameliorate the situation, it is advisable to write
(wl, cl) in terms of a few parameters and then maximize the likelihood func-
tion for those parameters. In addition, it is advisable to perform shrinkage or
thresholding of wavelet coeﬃcients only at resolution levels higher than a pre-
speciﬁed level l0. Here we use a parameterization similar to that of Abramovich
et al. (1998):
cl = 2−αlC1,
wl = 2−βlC2,
l = l0, . . . , L −1. Abramovich et al. (1998) discuss the relationship between
(α, β) and Besov space parameters, and thus how prior knowledge about the
function’s regularity can be incorporated in the prior for the wavelet coeﬃ-
cients through (α, β). The hyperparameters C1 and C2 can be easily estimated
via maximum likelihood.
5.5.3 Empirical Bayes Estimation of Wavelet Coeﬃcients
Once the hyperparameters have been estimated, their estimates are used as
true values in the posterior analysis of the wavelet coeﬃcients. Given σ2,
w0, . . . , wL−1, c0, . . . , cL−1, the elements of β will be a posteriori conditionally
independent. Moreover, the posterior distribution of dlk will be a mixture of
a Gaussian and a point mass at zero (e.g., see Clyde and George, 2000),
dlk|y ∼plkN

cl
1 + cl
ˆdlk,
cl
1 + cl
σ2

+ (1 −plk)δ(0),
(5.12)
where plk = Olk/(1 + Olk) is the posterior probability that dlk is diﬀerent
from zero and Olk is the posterior odds that dlk is diﬀerent from zero:

50
5 Wavelet Methods
Olk = (1 + cl)−0.5
wl
1 −wl
exp

0.5
cl
1 + cl
d2
lk
σ2

.
Depending on the loss function used, diﬀerent estimators of dlk can be ob-
tained from the posterior distribution (5.12). Use of square loss leads to the
posterior mean (Clyde et al., 1998)
E(dlk|y) = plk
cl
1 + cl
ˆdlk,
(5.13)
which is a shrinkage estimator.
Use of the absolute loss function leads to the posterior median (Abramovich
et al., 1998; Johnstone and Silverman, 2004, 2005), which is a threshold esti-
mator equal to zero if
plkΦ
	
cl
1 + cl
0.5 | ˆdlk|
σ

≤0.5,
(5.14)
where Φ is the standard Gaussian cumulative distribution function. Thus, if
plk ≤0.5, the posterior median is necessarily equal to 0. If inequality (5.14)
is not satisﬁed, then the posterior median is equal to
cl
1 + cl
ˆdlk −sign( ˆdlk)σ

cl
1 + cl
0.5
Φ−1
0.5
plk

.
Another threshold estimator (Clyde and George, 2000) is obtained by us-
ing the posterior mean conditional on the most probable component of the
mixture in Equation (5.12). Thus, the estimator is equal to zero if plk ≤0.5
and equal to cl(1 + cl)−1 ˆdlk if plk > 0.5. Clyde and George (2000) report that
the performance of this last estimator is worse than the performance of the
square-loss-based estimator given in Equation (5.13).
5.5.4 Application
Here we illustrate the use of wavelets for nonparametric regression with an
application to the Doppler test function (Donoho and Johnstone, 1994):

t(1 −t) ∗sin

2π 1 + 0.05
t + 0.05

.
We rescaled this function and added independent N(0, 1) noise so that the
signal-to-noise ratio was equal to 5. Figure 5.3(a) presents the Doppler func-
tion, and Figure 5.3(b) presents noisy observations.
We applied Daubechies’s least asymmetric wavelet of order 8 (Daubechies,
1992) using Wavethresh (Nason, 1998). Figure 5.4(a) presents the wavelet
coeﬃcients by resolution level. The lower resolution levels, those related to
the large-scale features, are dominated by some large wavelet coeﬃcients.

5.5 Bayesian Nonparametric Regression with Wavelets
51
0.0
0.2
0.4
0.6
0.8
1.0
−6
−4
−2
0
2
4
6
0.0
0.2
0.4
0.6
0.8
1.0
−6
−4
−2
0
2
4
6
(a)
(b)
Fig. 5.3. (a) Doppler function. (b) Doppler function with noise. Signal-to-noise
ratio equal to 5.
On the contrary, the wavelet coeﬃcients at the higher resolution levels are
confounded with noise.
We used the empirical Bayes approach described in this chapter with
l0 = 3, α = 1, β = 1, and C1 and C2 estimated via maximum likelihood
as equal to 1701.38 and 5.90, respectively. These values for α and β assume
that both the prior variance of nonzero wavelet coeﬃcients and the prior prob-
ability of a nonzero wavelet coeﬃcient decrease 50% from a given resolution
level to the next higher resolution level. Figures 5.4(b) and 5.4(c) present the
wavelet coeﬃcients’ posterior mean and median, respectively. When compared
with Figure 5.4(a), these ﬁgures display a much clearer picture of the multires-
olution behavior of the function to be estimated. The main features at each
resolution level are located in the regions where the estimated wavelet coef-
ﬁcients are large. Figures 5.4(b) and 5.4(c) indicate that large-scale features
are located close to t = 1, and as smaller scales are considered, the important
features move closer to t = 0.
As the posterior mean is a shrinkage estimator and the posterior median
is a thresholding estimator, Figure 5.4(c) displays a much more dramatic re-
duction in the wavelet coeﬃcients than Figure 5.4(b). The diﬀerence between
the wavelet coeﬃcients’ posterior mean and median carries on to the estima-
tion of the Doppler function. Figures 5.5(a) and 5.5(b) show the estimated
Doppler function using the wavelet coeﬃcients’ posterior mean and median,
respectively. The Doppler function estimate based on the posterior median is
smoother and visually much more pleasant.

52
5 Wavelet Methods
9
8
7
6
5
4
3
2
1
0
128
256
384
512
9
8
7
6
5
4
3
2
1
0
128
256
384
512
9
8
7
6
5
4
3
2
1
0
128
256
384
512
(a)
(b)
(c)
Fig. 5.4. Wavelet coeﬃcients. Resolution increases from top to bottom. Here, the
posterior mean is a shrinkage estimator, whereas the posterior median is a thresh-
old estimator. (a) Empirical wavelet coeﬃcient. (b) Posterior mean. (c) Posterior
median.
0.0
0.2
0.4
0.6
0.8
1.0
−6
−4
−2
0
2
4
6
0.0
0.2
0.4
0.6
0.8
1.0
−6
−4
−2
0
2
4
6
(a)
(b)
Fig. 5.5. Doppler function estimates based on wavelet coeﬃcients’ (a) posterior
mean and (b) posterior median.
5.6 Other Statistical Applications of Bayesian Wavelet
Analysis
Bayesian wavelet analysis has been successfully applied to a myriad of prob-
lems in several diﬀerent ﬁelds. A full treatment of the subject cannot be
ﬁt within a single chapter; it would rather need a book by itself. Here we
mention just some of the many successful applications of Bayesian wavelet
analysis: in time series, estimation of ARFIMA(p,d,q) parameters (Ko and
Vannucci, 2006a), detection of multiple change points of a long memory

5.6 Other Statistical Applications of Bayesian Wavelet Analysis
53
parameter (Ko and Vannucci, 2006b), and estimation of spectral density (Pen-
sky et al., 2006); in bioinformatics, extraction of structural features from pro-
teins (Li`o and Vannucci, 2000; Vannucci and Li`o, 2001); analysis of turbulence
ﬂows (Katul et al., 2001); analysis of network traﬃc (Kim et al., 2004; Kwon
et al., 2006); analysis of functional magnetic resonance imaging data (Sendur
et al., 2005); estimation of the link function in single-index models (Park
et al., 2005); hierarchical functional analysis (Morris et al., 2003); and spec-
troscopic calibration (Brown et al., 2001; Vannucci et al., 2003). Please refer
to Vannucci (2007) for more details on statistical applications of wavelets.


Part III
Explicit Multiscale Models


6
Overview of Explicit Multiscale Models
Multiscale modeling arises in a wide variety of applications. As discussed in
Chapter 1, there are at least three classes of problems that can be modeled
most eﬀectively within a multiscale framework. In the ﬁrst type, data are
observed at diﬀerent spatial scales and the model is used to integrate the
information from the diﬀerent scales. In the second type, data are observed
only at the ﬁnest scale and the model is used to induce a particular process
at that scale. In the third type, the observed data are related nonlocally and
nonlinearly to an underlying multiscale process, and the model is used as a
prior for that process.
Many multiscale procedures have appeared in the engineering literature
and have focused on the development of coarser representations of the phe-
nomenon of interest in order to obtain fast computational algorithms. In most
of that literature, the statistical structure is isolated from scale to scale, and
thus there is no consistent joint multiresolution statistical model as, for exam-
ple, in the work of Saquib et al. (1996), Comer and Delp (1999), and Pizurica
et al. (2002). An exception is the work developed by Allan S. Willsky and
his coauthors in the past decade or so, which we review in Chapter 7 (see
also Willsky, 2002). In that body of work, Willsky et al. developed multiscale
models in dyadic and quad trees in which sites of a given level are condition-
ally independent given the immediate coarser level. This allows a state-space
representation of those models, and thus a variant of the Kalman ﬁlter can
be used for inference (for references on state-space models and the Kalman
ﬁlter, see Harvey, 1989, and West and Harrison, 1997).
Fully Bayesian approaches generalizing that body of work are reasonably
new and have been applied to a variety of ﬁelds. For example, Kolaczyk (1999)
introduces Bayesian multiscale models based on recursive dyadic partitions for
Poisson processes, Nowak and Kolaczyk (2000) use such a framework to solve
Poisson inverse problems, Nowak (1999) proposes a multiscale hidden Markov
model for Bayesian image analysis, Kolaczyk and Huang (2001) construct a
multiscale model for spatial aggregation, and Huang et al. (2002) use multi-
scale models to perform fast spatial prediction for global processes. Although

58
6 Overview of Explicit Multiscale Models
those models lead to very eﬃcient algorithms, they introduce artifacts in the
analysis such as the blocky behavior pointed out by Irving et al. (1997). A
possible remedy to those artifacts is to deﬁne a multiscale model on a more
general graph as proposed by Huang and Cressie (2001), where each site at a
given resolution level depends on more than one site at the immediate coarser
level, and the knowledge of the immediate coarser level decorrelates the sites
at that given resolution level. The model by Huang and Cressie (2001) leads
to smoother processes than the tree-based models at each resolution level but,
like the tree-based models, does not take into account the dynamics at each
level of resolution. Some of these models are reviewed in Chapter 9.
An alternative approach that does model the dynamics at each level of
resolution is the multiscale random ﬁeld approach of Ferreira et al. (2005).
This class of multiscale random ﬁelds is useful for modeling processes that
live and possibly can be observed at diﬀerent levels of resolution. Each level
of resolution is connected with the immediately ﬁner level through a linear
function plus Gaussian noise. Initially, Markov random ﬁeld processes are
assigned for each level of resolution, and then Jeﬀrey’s rule of conditioning
(see, for example, Jeﬀrey, 1988) is used to revise the implied distributions and
ensure that the probability distributions of the diﬀerent levels are compatible.
As these models assume the existence of dependence between sites of a given
resolution level even conditional on the immediate coarser level, they do not
have the undesirable block eﬀects, and they do incorporate the dynamics at
each level. In fact, they are able to accommodate fairly smooth processes at
the diﬀerent levels of resolution. Moreover, this class of models has the ability
both to combine information across levels of resolution and to emulate long
memory spatial processes. These models are reviewed in Chapter 10.
As time series processes can be seen as random ﬁeld processes in one di-
mension, the same type of multiscale model of Ferreira et al. (2005) can be
specialized to time series modeling, as in the work of Ferreira et al. (2006).
These multiscale time series models are able to consistently model time series
at diﬀerent levels of resolution (e.g., daily or monthly aggregates of ﬁnancial
or meteorological data) and to coherently combine information across time
scales. Several issues particular to time series analysis arise, such as the in-
clusion of seasonality in the model and the capacity to perform predictions.
In particular, when compared with multiscale analyses of time series based
on wavelet decompositions, the ability to perform predictions is a great ad-
vantage of the multiscale models of Ferreira et al. (2006). These models are
reviewed in Chapter 11.
A rather diﬀerent perspective is presented in Chapter 12, where one may
expect that the discrete blocks at diﬀerent scales fail to line up easily across
scales. Whereas the other chapters in this part primarily deal with the case
where the number of cells at a ﬁner scale is an integer multiple of the number
of cells at a coarser scale, so that a coarse cell can be comprised of a ﬁxed
number of ﬁner cells, the change of support methods allow more arbitrary
movement across scales. We include the change of support modeling chapter

6.2 Classiﬁcation and Regression Trees
59
in this section because it also describes an explicit model for moving between
diﬀerent resolutions, although the ﬂavor of the models is noticeably diﬀerent
from those in the rest of this section.
While we have tried to include a wide range of broadly applicable methods,
we regret that this section is not an exhaustive compilation of Bayesian explicit
multiscale methods. For example, a neat approach that has appeared in the
context of the analysis of deterministic computer simulators at multiple levels
of resolution is that of Kennedy and O’Hagan (2000). Each level is modeled
with a Gaussian process, and the levels are linked through an autoregressive
process. The setup thus gives a joint multivariate normal distribution for the
combined data across all scales, simplifying the posterior analysis.
Before moving on to the methodological chapters, the rest of this chapter
presents a brief review of trees and some tree models.
6.1 Tree Deﬁnition
A tree is a graph formed by nodes connected by line segments containing
no closed loops. Here we consider rooted trees. In a rooted tree, one of the
nodes is the root node, and nodes at the same distance from the root node
are said to be in the same level of resolution. Levels closer to the root are said
to be coarser and levels farther away are said to be ﬁner. Two immediately
connected nodes at a coarser and a ﬁner level are said to be the parent and
a child of each other, respectively. Trees with two or four children per node
are called dyadic trees or quadtrees, respectively. Figure 6.1 represents three
levels of a dyadic tree.
In general, a model on a tree with L levels of resolution is considered,
where (l, j) denotes the jth node at the lth level, l = 0, . . . , L −1. It is
assumed that node (l, j), l ≥1, has one parent node at the immediate coarser
level l −1 and dl,j descendant nodes at the immediate ﬁner level l + 1. Let
Dlj denote the set of nodes of the (l +1)th level that are descendants of (l, j),
and let Alj denote the node of the (l −1)th level that is the ancestor of (l, j).
Denote by nl the number of nodes at the lth level; we can recursively compute
nl = nl−1
j=1 dl−1,j and typically n0 = 1.
6.2 Classiﬁcation and Regression Trees
The basic tree model in statistics is CART (classiﬁcation and regression trees),
also known as recursive partitioning regression (Breiman et al., 1984). In a
regression setting, the idea is to use a tree to partition the space of the ex-
planatory variables, ﬁtting the response with a constant value in each par-
tition. Typically, dyadic trees with binary splits are used, but by allowing
recursive splitting, variables may be revisited and thus nonbinary partitions
can be achieved. Also, typical splitting rules are purely recursive, so that splits

60
6 Overview of Explicit Multiscale Models
(2,1)
(0,1)
(1,2)
(2,2)
(2,3)
(2,4)
(1,1)
Fig. 6.1. Three levels of a dyadic tree
at one node are independent of any possible splits at another node at the same
level. For example, in Figure 6.1, the root node (0, 1) may represent a split
on the ﬁrst explanatory variable, with node (1, 1) representing all cases with
x1 ≤r1 and (1, 2) containing all cases with x1 > r1. Then the split between
nodes (2, 1) and (2, 2) could split again on the ﬁrst variable, with (2, 1) con-
taining cases with x1 ≤r2 < r1, and (2, 2) containing cases with r2 < x1 ≤r1.
But node (1, 2) can split diﬀerently, such as by using a second explanatory
variable x2. Thus the splits are independent conditioned on the parents of the
nodes. The ﬁtted value is then the average of the responses of the cases in
the partition. For a classiﬁcation problem, the tree would predict the ﬁtted
probability of class membership to be the empirical probability of the cases
in that partition (the number of cases in the partition in that class divided by
the total number of cases in the partition). More details on tree models can
be found in Hastie et al. (2001) and the references therein.
CART has gained popularity because it is easy to use, produces a model
that can often give a meaningful interpretation, and has been found to work
reasonably well in a wide variety of problems. Tree models can be extended
to allow the ﬁtting of linear regression or other more complex models over
each of the regions (Chipman et al., 2002; Gramacy and Lee, 2006). Bayesian
versions of CART have also been developed (Denison et al., 1998; Chipman
et al., 1998). The key ingredients are the speciﬁcation of the prior over the
space of trees and a mechanism for mixing over this space during MCMC. Care
must be taken, as the posterior over the tree space tends to be multimodal.

6.2 Classiﬁcation and Regression Trees
61
Partition models can also be generalized beyond trees, such as with a Voronoi
tessellation partition (Denison et al., 2002).
In some sense, CART can be viewed as a multiscale model in that each level
of the tree represents a successive reﬁnement. In this way, multiscale models
can be built somewhat analogously to the convolution and wavelet models in
Chapters 4 and 5. However, the basic CART model is somewhat suboptimal
for this purpose, as the diﬀerent branches of the tree are typically unrelated to
each other, and so the successive reﬁning happens in a rather nonsystematic
way with respect to the multiscale nature of the problem. For this reason, we
focus on other varieties of tree models in the following chapters.


7
Gaussian Multiscale Models on Trees
Many multiscale approaches have appeared in the engineering literature, with
a focus on the development of coarser representations of the phenomenon of
interest in order to obtain fast computational algorithms. With this objec-
tive in mind, a particularly eﬀective multiscale framework was developed by
Allan S. Willsky and his coauthors in the 1990s (Basseville et al., 1992a,b;
Luettgen et al., 1993; Chou et al., 1994a,b; Luettgen et al., 1994; Luettgen and
Willsky, 1995a,b; Irving et al., 1997; Frakt and Willsky, 1998; Daoudi et al.,
1999). In that work, Willsky et al. developed multiscale models on trees in
which nodes of a given level are conditionally independent given the immedi-
ate coarser level. Those models admit a state-space representation and, as a
result, a variant of the Kalman ﬁlter can be used for inference (for references
on state-space models and the Kalman ﬁlter, see Harvey, 1989, and West and
Harrison, 1997). For a detailed review of multiscale modeling on trees from
an engineering point of view, the reader is referred to Willsky (2002). In this
chapter, we review from a Bayesian statistical point of view the main points
of Willsky’s multiscale framework (WMF).
In a seminal set of papers, Basseville et al. (1992a,b) introduced the basis
for multiscale autoregressive modeling on dyadic trees. Building on those de-
velopments, Chou et al. (1994a,b) introduced Gaussian multiscale models on
dyadic trees and a corresponding optimal estimation algorithm. In addition,
they presented examples of the use of these multiscale models on dyadic trees
for the denoising of signals, the incorporation of information from multiple
resolutions, and the estimation of motion. Use of the multiscale estimation al-
gorithm of Chou et al. (1994a,b) is not restricted to dyadic trees, and it can be
used for Gaussian multiscale models on quadtrees. Moreover, autoregressive
multiscale models on quadtrees may be used to approximate Gaussian ran-
dom ﬁelds, as pointed out by Luettgen et al. (1993) with the approximation of
Markov random ﬁelds. Luettgen et al. (1994) used multiscale dynamic models
on quadtrees as priors for the computation of optical ﬂow, a computationally
intensive inverse problem. Finally, Luettgen and Willsky (1995a) developed
an algorithm for likelihood computation for multiscale models on trees that

64
7 Gaussian Multiscale Models on Trees
may be used for maximum likelihood estimation or for the computation of
likelihood ratio tests.
One of the problems of models on quadtrees is that the resulting covari-
ance function at the highest resolution level may be very blocky. In order to
reduce that problem, Irving et al. (1997) proposed the use of overlapping trees.
Another possible solution was proposed by Huang and Cressie (1997), who in-
troduced multiscale dynamic models on acyclic directed graphs and developed
a fast optimal estimation algorithm for the state-space process, while Huang
and Cressie (2001) applied these models to command-and-control problems.
There are many parallels between multiscale autoregressive models on trees
and wavelets. Both consider multiple scales of resolution, and multiscale au-
toregressive models on trees can mimic the wavelet reconstruction algorithm
(Daoudi et al., 1999). In its most basic version, wavelet analysis decomposes
a signal in a sequence of details at diﬀerent levels of resolution in a descrip-
tive manner, and statistical modeling is then used in order to decide if each
detail (wavelet coeﬃcient) is signiﬁcant or not (e.g., see Vidakovic, 1999; Mal-
lat, 1999). In turn, Willsky’s multiscale autoregressive models may be seen as
stochastic versions of the wavelet reconstruction algorithm, with independent
Gaussian details being added as the resolution level increases. Finally, in con-
trast to wavelets, the WMF is able to accommodate observations at diﬀerent
levels of resolution.
The ability of WMF to accommodate observations at diﬀerent resolution
levels can be used, for example, to integrate atmospheric data. Let us say that
a given process of interest such as the amount of rain can be measured with
measurement error by diﬀerent equipment, such as terrestrial stations, radar,
and satellites. These measurements provide information about the process of
interest at diﬀerent levels of resolution and may have diﬀerent spatial cover-
ages. In the WMF, the underlying process of interest would be modeled with
a latent process on a tree, where nodes at a given scale would correspond to
diﬀerent aggregation levels of the process. The nodes at the diﬀerent scales
would be connected through a linear model. The measurements at each res-
olution would be connected to the respective nodes through an observation
equation. The algorithms of Section 7.3 would then be used to integrate the
measurement information from the diﬀerent resolution levels and to provide
estimates of the process of interest at the several resolution levels.
Figure 7.1 represents three levels of a latent process on a dyadic tree.
Here, xl denotes the vectorized latent process at the lth level of resolution,
l = 0, . . . , L −1, and xlj denotes the value corresponding to the jth node at
the lth level. The latent process at the root node is x0 = xlj. When dealing
with time series, Willsky uses dyadic trees, and so dl,j = 2, ∀(l, j). When
dealing with 2-D random ﬁelds, Willsky uses quadtrees, and in that case
dl,j = 4, ∀(l, j). In order to simplify notation, deﬁne xDlj = {xl′j′|(l′, j′) ∈
Dlj}. Finally, denote by yl the vectorized (potentially) observed process at
the lth level of resolution and by ylj the ny-dimensional (potentially) observed
value at the jth node at the lth level. Note that while in some applications

7.1 The Model
65
there are observations at all levels of resolution, in other applications there
are observations at only one level of resolution, or only some elements of yl
at each level l = 0, . . . , L −1 are observed. In order to diﬀerentiate observed
nodes from nonobserved nodes, a dummy variable γlj assumes the value 1 if
ylj was actually observed and 0 otherwise.
0
11
12
24
23
22
21
x
x
x
x
x
x
x
Fig. 7.1. Three levels of a dyadic tree.
7.1 The Model
Assuming that the latent process at nodes of a given level are condition-
ally independent given the latent process at the immediate coarser level,
and assuming that the observations at each node and each level are condi-
tionally independent given the latent process, the joint density function of
(y0, . . . , yL−1, x0, . . . , xL−1) of a generalized version of the WMF model can
be written as
f(y0, . . . , yL−1, x0, . . . , xL−1|θ) = f(x0|θ)
⎡
⎣
L−1

l=1
nl

j=1
f(xlj|xAlj, θ)
⎤
⎦
×
⎡
⎣
L−1

l=0
nl

j=1
[f(ylj|xlj, θ)]γlj
⎤
⎦,
(7.1)

66
7 Gaussian Multiscale Models on Trees
where f(xlj|xAlj, θ) is the density of xlj given its ancestral node and
f(ylj|xlj, θ) is the density of ylj given the corresponding latent variable xlj.
Note that this general framework may include nonnormal observations and
nonnormal latent processes. Moreover, θ is the parameter vector associated
with the WMF model of interest and is typically of low dimension. For exam-
ple, θ may include the overall mean and a scale parameter.
More speciﬁcally, Willsky et al. assume that all the densities above are
Gaussian. Under this assumption, the model deﬁned by Equation (7.1) can
be rewritten as a Gaussian state-space model on a tree (Chou et al., 1994a,b),
ylj = Fljxlj + vlj,
vlj ∼N(0, Vlj),
(7.2)
xlj = GljxAlj + wlj,
wlj ∼N(0, Wlj),
(7.3)
x0 ∼N(0, Σ0),
(7.4)
where vlj and wlj, l = 0, . . . , L−1, j = 1, . . . , nl, are all mutually independent.
Moreover, Flj, Glj, Vlj, and Wlj, l = 0, . . . , L −1, are functions of the
parameter vector θ.
Example 7.1. Figure 7.2 presents levels 1, 3, 5, 7, and 9 of a multiscale process
on the interval [0, 1]. At each level, the process is a step function, and each
sub-interval corresponds to a node of an autoregressive process on a dyadic
tree. This process was generated with x0 ∼N(0, 5), Flj = 1, Glj = 1, Vlj =
1/(l + 1), and Wlj = 10/2l+1, l = 0, . . . , L −1, j = 1, . . . , nl. The reduction of
the variance Vlj for ﬁner scales is typical of problems that have information
at diﬀerent levels of resolution, higher-resolution information generally being
more precise. The reduction of the variance Wlj following a power law leads
to a fractal-like process (for a reference on fractal processes, see Mandelbrot,
1999). It is noteworthy that the manner in which the ﬁner levels derive from
the coarser levels leads to a long memory dependence process at the ﬁnest
level of resolution.
7.2 Covariance Structure
The covariance structure of the state-space model on a tree deﬁned by Equa-
tions (7.2), (7.3), and (7.4) was derived by Chou et al. (1994a). Note that
the tree has only one node at the coarsest level 0. Assume that the corre-
sponding latent value, x0, is normally distributed with zero mean and covari-
ance matrix V (x0). Thus E[xlj] = 0, ∀l, j. Moreover, the covariance matrix
V (xlj) = E[xljx′
lj] can be recursively computed through the Lyapunov equa-
tion
V (xlj) = GljV (xAlj)G′
lj + Wlj.
Then the covariance matrix V (ylj) can be computed as
V (ylj) = FljV (xlj)F′
lj + Vlj.

7.2 Covariance Structure
67
0.0
0.2
0.4
0.6
0.8
1.0
−6
−4
−2
0
2
0.0
0.2
0.4
0.6
0.8
1.0
−6
−4
−2
0
2
0.0
0.2
0.4
0.6
0.8
1.0
−6
−4
−2
0
2
0.0
0.2
0.4
0.6
0.8
1.0
−6
−4
−2
0
2
0.0
0.2
0.4
0.6
0.8
1.0
−6
−4
−2
0
2
Fig. 7.2. Levels 1, 3, 5, 7, and 9 of a simulated latent process on a dyadic tree,
with x0 ∼N(0, 5), Flj = 1, Glj = 1, Vlj = 1/(l + 1), and Wlj = 10/2l+1, l =
0, . . . , L −1, j = 1, . . . , nl.
The
cross
covariance
matrix
between
xlj
and
xl∗j∗,
denoted
by
CV (xlj, xl∗j∗) = E[xljx′
l∗j∗], can be computed as
CV (xlj, xl∗j∗) = Φlj,A(lj,l∗j∗)V (xA(lj,l∗j∗))Φ′
l∗j∗,A(lj,l∗j∗),
where A(lj, l∗j∗) is the most recent common ancestral node of nodes (l, j) and
(l∗, j∗), and Φlj,A(lj,l∗j∗) is the transition matrix
Φlj,A(lj,l∗j∗) =

I,
(l, j) = A(lj, l∗j∗),
GljΦAlj,A(lj,l∗j∗),
otherwise.

68
7 Gaussian Multiscale Models on Trees
The cross covariance matrix between ylj and yl∗j∗is equal to
CV (ylj, yl∗j∗) = E(yljy′
l∗j∗)
= E(Fljxljx′
l∗j∗F′
l∗j∗)
= Flj CV (xlj, xl∗j∗) F′
l∗j∗.
If Glj = G, Wlj = W and the eigenvalues of G are all smaller than 1 in
absolute value, then existence is guaranteed for the limit
lim
l→∞V (xlj) = Vx.
In this case, the matrix Vx is the stationary covariance matrix of the latent
process deﬁned by Equation (7.3), and it can be computed as the solution of
the equation
Vx = GVxG′ + W.
In addition, if V (x0) = Vx then V (xlj) = Vx, l = 0, . . . , L −1, j = 1, . . . , nl.
Moreover, deﬁning (lA, jA) = A(lj, l∗j∗), the cross covariance matrix between
xlj and xl∗j∗will be
CV (xlj, xl∗j∗) = Gl−lAVx(Gl∗−lA)′
Note that the cross covariance matrix between two nodes depends only on
their distances from their most recent common ancestral node.
Moreover, if Flj = F and Vlj = V, l = 0, . . . , L −1, then the entire
model deﬁned by Equations (7.2) and (7.3) will be stationary. In this case,
the stationary covariance matrix of the observations will be
Vy = FVxF′ + V
and the cross covariance matrices will be
CV (ylj, yl∗j∗) = F CV (xlj, xl∗j∗) F′.
Example 7.2. Figure 7.3 presents the correlation function between the univari-
ate latent variables at the ﬁnest resolution level for a stationary process on a
dyadic tree with G = 0.9. It is easy to show that in this case the correlation
function between xlj and xl∗j∗is Gl+l∗−2lA, where lA is the resolution level of
the most recent common ancestral node of nodes (l, j) and (l∗, j∗). Thus, the
correlation function is a step function with the ratio between successive steps
equal to G2. Moreover, the length of each step increases by a factor of 2 at
each new step. As a consequence, the correlation function decays very slowly.

7.3 Estimation When θ Is Known
69
0
50
100
150
200
250
0.0
0.2
0.4
0.6
0.8
1.0
Fig. 7.3. Correlation function between the latent variables at the ﬁnest resolution
level for a stationary process on a dyadic tree. G = 0.9.
7.3 Estimation When θ Is Known
If the parameter vector θ is known, the latent process x can be estimated very
quickly through a multiscale estimation algorithm analogous to the Kalman
ﬁlter. This multiscale estimation algorithm was introduced by Chou, Willsky
and Benveniste (1994a) and was explained using Bayesian reasoning by Huang
and Cressie (1997). From now on, we will refer to this algorithm as the CWB
algorithm. The major diﬀerence between the CWB algorithm and the Kalman
ﬁlter for time series is that while the Kalman ﬁlter has a forward in time
ﬁltering sweep followed by a backward smoothing sweep, the CWB algorithm
has a ﬁne to coarse ﬁltering sweep followed by a coarse to ﬁne smoothing
sweep. For information about the Kalman ﬁlter, see West and Harrison (1997)
and Harvey (1989). For simplicity of exposition, in this section we omit the
dependence of the distributions on θ.
The available information set below node (l, j) (that is, the set of obser-
vations at descendant nodes of node (l, j)) is simply
Y +
lj = {yl′j′|(l′, j′) is a descendant of (l, j) and γl′j′ = 1},
while the information set up to node (l, j) is Ylj = Y +
lj
{ylj} if γlj = 1 and
Ylj = Y +
lj if γlj = 0. Note that Y +
lj = 
(l′,j′)∈Dlj Yl′j′ and Y0 is the set of all
observations.
Of particular interest are two distributions of the latent process at node
(l, j), each of them conditional on a diﬀerent set of information: the ﬁltered dis-
tribution is conditional on the information up to (l, j), Ylj, and the smoothed
distribution is conditional on all the information, Y0. First the ﬁltered dis-
tributions for the latent process at all nodes of the tree are computed in the
ﬁne to coarse sweep of the CWB algorithm, and after that the smoothed dis-
tributions are computed in the coarse to ﬁne sweep of the CWB algorithm.

70
7 Gaussian Multiscale Models on Trees
With the smoothed distributions, estimators of the latent process and their
respective measures of uncertainty can be easily computed. In particular, if
the square loss function is used, then the Bayes estimator of xlj is the posterior
mean E[xlj|Y0] and the expected loss is the posterior variance V [xlj|Y0].
Section 7.3.1 describes the ﬁne to coarse ﬁlter of the CWB algorithm and
Section 7.3.2 describes the coarse to ﬁne smoother.
7.3.1 Fine to Coarse Filter
The multiscale construction of the latent process x deﬁnes a marginal prior
for each xlj,
xlj ∼N(0, Σlj),
where Σlj = GljΣAljG′
lj + Wlj. Moreover, the coarse to ﬁne construction
of the multiscale latent process can be reversed using Bayes’ Theorem. More
speciﬁcally,
p(xlj|xl′j′) ∝p(xl′j′|xlj)p(xlj)
∝exp

−1
2(xl′j′ −Gl′j′xlj)′W−1
l′j′(xl′j′ −Gl′j′xlj)

× exp

−1
2x′
ljΣ−1
lj xlj

.
Therefore,
xlj|xl′j′ ∼N(Bl′j′xl′j′, Ul′j′),
(l′, j′) ∈Dlj,
where
Ul′j′ =

Σ−1
lj + G′
l′j′W−1
l′j′Gl′j′
−1
,
Bl′j′ = Ul′j′G′
l′j′W−1
l′j′.
The following theorem provides the ﬁne to coarse ﬁlter.
Theorem 7.1. In the Gaussian multiscale model deﬁned by Equations (7.2),
(7.3), and (7.4), ﬁltered distributions are given as follows:
(a) Posterior at the ﬁnest resolution level:
xL−1,j|YL−1,j ∼N(mL−1,j, CL−1,j),
where
mL−1,j = γL−1,jΣL−1,jF′
L−1,j

FL−1,jΣL−1,jF′
L−1,j + VL−1,j
−1yL−1,j,
CL−1,j = ΣL−1,j −γL−1,jΣL−1,jF′
L−1,j
×

FL−1,jΣL−1,jF′
L−1,j + VL−1,j
−1 FL−1,jΣL−1,j.

7.3 Estimation When θ Is Known
71
(b) Posterior for (l′, j′) ∈Dlj: For some mean ml′j′ and covariance matrix
Cl′j′,
xl′j′|Yl′j′ ∼N(ml′j′, Cl′j′).
(c) Prior at (l, j):
xlj|Y +
lj ∼N(alj, Rlj),
where
Rlj =
⎧
⎨
⎩Σ−1
lj +

(l′,j′)∈Dlj

Ul′j′ + Bl′j′Cl′j′B′
l′j′
−1 −Σ−1
lj

⎫
⎬
⎭
−1
,
alj = Rlj
⎧
⎨
⎩

(l′,j′)∈Dlj

Ul′j′ + Bl′j′Cl′j′B′
l′j′
−1 Bl′j′ml′j′
⎫
⎬
⎭.
(d) Forecast at (l, j):
ylj|Y +
lj ∼N(flj, Qlj),
where
flj = Fljalj,
Qlj = FljRljF′
lj + Vlj.
(e) Posterior at (l, j):
xlj|Ylj ∼N(mlj, Clj),
with
mlj = alj + γljAljelj,
Clj = Rlj −γljAljQljA′
lj,
where Alj = RljF′
ljQ−1
lj
and elj = ylj −flj.
Proof.
The proof is by induction and uses multivariate normal distribution theory
and Bayes’ Theorem.
(a) At the ﬁnest resolution level, Y +
L−1,j = ∅, j = 1, . . . , nL−1, and so
YL−1,j = {yL−1,j} when γL−1,j = 1 and YL−1,j = ∅when γL−1,j = 0.
As a consequence, if γL−1,j = 0 then p(xL−1,j|YL−1,j) = p(xL−1,j), im-
plying mL−1,j = 0 and CL−1,j = ΣL−1,j. Conversely, when γL−1,j = 1
then by Bayes’ Theorem
p(xL−1,j|YL−1,j) = p(xL−1,j|yL−1,j)
∝p(yL−1,j|xL−1,j)p(xL−1,j)
∝exp

−1
2 (yL−1,j −FL−1,jxL−1,j)′ V−1
L−1,j (yL−1,j

72
7 Gaussian Multiscale Models on Trees
−FL−1,jxL−1,j)

exp

−1
2x′
L−1,jΣ−1
L−1,jxL−1,j

∝exp

−1
2 (xL−1,j −mL−1,j)′ C−1
L−1,j
(xL−1,j −mL−1,j)

,
where C−1
L−1,j = F′
L−1,jV−1
L−1,jFL−1,j + Σ−1
L−1,j and mL−1,j = CL−1,j
F′
L−1,j V−1
L−1,jyL−1,j. Simple linear algebra shows that these expressions
are equivalent to
mL−1,j = ΣL−1,jF′
L−1,j

FL−1,jΣL−1,jF′
L−1,j + VL−1,j
−1 yL−1,j,
CL−1,j = ΣL−1,j −ΣL−1,jF′
L−1,j

FL−1,jΣL−1,jF′
L−1,j + VL−1,j
−1
FL−1,jΣL−1,j.
Therefore, xL−1,j|YL−1,j ∼N(mL−1,j, CL−1,j).
(b) It follows directly from the fact that all distributions are Gaussian.
(c) Note that p(xlj|Yl′j′) =

p(xlj|xl′j′)p(xl′j′|Yl′j′)dxl′j′. Thus, xlj|Yl′j′ ∼
N(Bl′j′ml′j′, Ul′j′ + Bl′j′Cl′j′B′
l′j′). Moreover,
p(xlj|Y +
lj ) ∝p(xlj)p(Y +
lj |xlj)
= p(xlj)

(l′,j′)∈Dlj
p(Yl′j′|xlj)
∝p(xlj)

(l′,j′)∈Dlj
p(xlj|Yl′j′)
p(xlj)
.
Therefore, xlj|Y +
lj ∼N(alj, Rlj).
(d) It follows directly from (c) and the fact that ylj|xlj ∼N(Fljxlj, Vlj).
(e) Note that Ylj = Y +
lj
{ylj} when γlj = 1 and Ylj = Y +
lj when γlj = 0. As
a consequence, if γlj = 0 then p(xlj|Ylj) = p(xlj|Y +
lj ), implying mlj = alj
and Clj = Rlj. Conversely, when γlj = 1, then by Bayes’ Theorem
p(xlj|Ylj) ∝p(ylj|xlj)p(xlj|Y +
lj )
∝exp

−1
2 (ylj −Fljxlj)′ V−1
lj (ylj
−Fljxlj)

exp

−1
2(xlj −alj)′R−1
lj (xlj −alj)

∝exp

−1
2

xlj −mlj)′C−1
lj (xlj −mlj

,
where C−1
lj = F′
ljV−1
lj Flj + R−1
lj
and mlj = Clj

F′
ljV−1
lj ylj + R−1
lj alj

.
Simple linear algebra shows that these expressions are equivalent to mlj =

7.3 Estimation When θ Is Known
73
alj + Aljelj and Clj = Rlj −AljQljA′
lj, where Alj = RljF′
ljQ−1
lj
and
elj = ylj −flj. Therefore, xlj|Ylj ∼N(mlj, Clj).
□
7.3.2 Coarse to Fine Smoother
After the ﬁne to coarse ﬁltering sweep, the analyst will have at the root of
the tree the distribution x0|Y0, that is, the distribution of the latent process
at the root node given all the information. In order to obtain the smoothed
distributions xlj|Y0, l = 1, . . . , L −1, j = 1, . . . , nl, it will be necessary to
send the information Y0 down the tree. Deﬁne Y −
lj = Y0 \ Ylj. The following
theorem provides the coarse to ﬁne smoother.
Theorem 7.2. In the Gaussian multiscale model deﬁned by Equations (7.2),
(7.3), and (7.4), smoothed distributions are given as follows:
(a) Posterior for node Alj: For some mean sAlj and covariance matrix SAlj,
xAlj|Y0 ∼N(sAlj, SAlj).
(b) xlj|xAlj, Ylj ∼N(klj, Klj), where
Klj =

C−1
lj + W−1
lj −Σ−1
lj
−1
,
klj = Klj

C−1
lj mlj + W−1
lj GljxAlj

.
(c) Posterior for node (l, j):
xlj|Y0 ∼N(slj, Slj),
where
Slj = Klj + KljW−1
lj GljSAljG′
ljW−1
lj Klj,
slj = Klj

C−1
lj mlj + W−1
lj GljsAlj

.
Proof.
Again, the proof is by induction and uses multivariate normal distribution
theory and Bayes’ Theorem.
(a) It follows directly from the fact that all distributions are Gaussian.
(b) From Bayes’ Theorem

74
7 Gaussian Multiscale Models on Trees
p(xlj|xAlj, Ylj) ∝p(xlj|Ylj)p(xAlj|xlj, Ylj)
= p(xlj|Ylj)p(xAlj|xlj)
= p(xlj|Ylj)p(xlj|xAlj)p(xAlj)
p(xlj)
∝p(xlj|Ylj)p(xlj|xAlj)
p(xlj)
= exp
#
−0.5(xlj −mlj)′C−1
lj (xlj −mlj)
$
×
exp
#
−0.5(xlj −GljxAlj)′W−1
lj (xlj −GljxAlj)
$
exp
#
−0.5x′
ljΣ−1
lj xlj
$
∝exp
#
−0.5

x′
lj(C−1
lj + W−1
lj −Σ−1
lj )xlj
−2x′
lj(C−1
lj mlj + W−1
lj GljxAlj)
$
.
Therefore, xlj|xAlj, Ylj ∼N(klj, Klj), where
Klj =

C−1
lj + W−1
lj −Σ−1
lj
−1
,
klj = Klj

C−1
lj mlj + W−1
lj GljxAlj

.
(c) Using Y0 = Y −
lj
 Ylj and p(xlj|xAlj, Y −
lj , Ylj) = p(xlj|xAlj, Ylj),
p(xlj|Y0) =

p(xlj, xAlj|Y0)dxAlj
=

p(xlj|xAlj, Ylj)p(xAlj|Y0)dxAlj.
As xlj|xAlj, Ylj ∼N(klj, Klj), and xAlj|Y0 ∼N(sAlj, SAlj), the result
follows from the convolution of Gaussian random vectors.
□
Example 7.3. Figure 7.4 presents the latent process and observations at lev-
els 1, 3, 5, 7, and 9 of the simulated multiscale process of Example 7.1. At
each level of resolution, observations are made at the midpoint of some sub-
intervals. Note that not all subintervals have observations, as the probability
of the existence of an observation at a particular subinterval at level l is 0.8l.
Thus, in the simulated example, there is an observation at the root node with
certainty, while at the ﬁnest level the probability of existence of an observa-
tion at a particular node is only about 0.13. This is typical of problems where
data are available at diﬀerent scales of resolution, with higher-resolution data
being more sparse.

7.3 Estimation When θ Is Known
75
0.0
0.2
0.4
0.6
0.8
1.0
−6
−4
−2
0
2
0.0
0.2
0.4
0.6
0.8
1.0
−6
−4
−2
0
2
0.0
0.2
0.4
0.6
0.8
1.0
−6
−4
−2
0
2
0.0
0.2
0.4
0.6
0.8
1.0
−6
−4
−2
0
2
0.0
0.2
0.4
0.6
0.8
1.0
−6
−4
−2
0
2
Fig. 7.4. Levels 1, 3, 5, 7, and 9 of a simulated multiscale process on a tree: latent
process (solid line) and observations (bullets). x0 ∼N(0, 10), Flj = 1, Glj = 1,
Vlj = 1/(l + 1), and Wlj = 10 × 2l+1, l = 0, . . . , L −1, j = 1, . . . , nl.
Figure 7.5, like Figure 7.4, presents the latent process and observations at
levels 1, 3, 5, 7, and 9, but in addition presents the smoothed posterior mean
and 95% credible intervals. It is remarkable how the estimation methodology
recovers most of the features of the latent process at the diﬀerent levels of
resolution. This remarkable performance is the result of the transfer of in-
formation through all the levels of resolution, with observations in one level
helping to estimate the latent process at the other levels.

76
7 Gaussian Multiscale Models on Trees
0.0
0.2
0.4
0.6
0.8
1.0
−6
−4
−2
0
2
0.0
0.2
0.4
0.6
0.8
1.0
−6
−4
−2
0
2
0.0
0.2
0.4
0.6
0.8
1.0
−6
−4
−2
0
2
0.0
0.2
0.4
0.6
0.8
1.0
−6
−4
−2
0
2
0.0
0.2
0.4
0.6
0.8
1.0
−6
−4
−2
0
2
Fig. 7.5. Levels 1, 3, 5, 7, and 9 of a simulated multiscale process on a tree: latent
process (solid line), observations (bullets), smoothed means (dashed line), and 95%
credible intervals (dotted lines).
7.4 Estimation When θ Is Unknown
If the parameter vector θ is unknown, the estimation algorithm of Section 7.3
cannot be used directly. Instead, the ﬁne to coarse ﬁltering sweep and the
coarse to ﬁne smoothing sweep may be integrated within algorithms for the
Bayesian estimation of the parameter vector θ and the latent process x. The
solution can be a full Bayesian approach implemented with a Markov chain
Monte Carlo (MCMC) algorithm (for references on MCMC algorithms, see
Gamerman and Lopes, 2006; Robert and Casella, 2005) or an empirical Bayes
approach.

7.4 Estimation When θ Is Unknown
77
A full Bayesian approach requires the elicitation of a prior distribution for
θ. As θ is related to the smoothness of the multiscale process, prior knowledge
about it can be incorporated in the prior for θ. Moreover, the prior for θ is
speciﬁc for each particular multiscale model. The full Bayesian approach can
be implemented with an MCMC algorithm. The MCMC algorithm simulates
a Markov chain whose limiting distribution is the joint posterior distribution
of (θ, x). In the analysis of Gaussian multiscale models on trees, each itera-
tion of the MCMC algorithm can be divided into two steps. In the ﬁrst step,
the latent process is simulated from its full conditional distribution; that is,
its posterior distribution conditional on θ. This step uses the ﬁne to coarse
ﬁltering sweep of Section 7.3.1 and a coarse to ﬁne sampling sweep that recur-
sively simulates from xlj|xAlj, Ylj. This step can be seen as a generalization
to tree topologies of the forward ﬁltering backward sampling algorithm for
state-space models (Carter and Kohn, 1994; Fr¨uhwirth-Schnatter, 1994). The
second step is constructed according to the multiscale model and the elements
of the parameter vector θ. If the full conditional distribution is available for
sampling, then this step consists of the simulation of θ from that distribution.
Conversely, if the full conditional distribution is not available for sampling,
then θ may be simulated with Metropolis or Metropolis-Hastings steps.
Very often in practice, a full Bayesian approach for a Gaussian multiscale
model on a tree is not feasible because an MCMC implementation would be
too expensive computationally or because a prior for θ would be diﬃcult
to elicit. In those cases, an empirical Bayes approach might provide a good
solution. Typically, an empirical Bayes approach estimates θ using method of
moments or maximum likelihood. Maximum likelihood estimation of θ can be
performed by direct maximization of the marginal likelihood or by the EM
algorithm. When direct maximization is used, the marginal likelihood of θ can
be computed with the ﬁne to coarse ﬁlter of Section 7.3.1. Then, the resulting
estimate of θ substitutes the true value of θ in the estimation procedures of
Sections 7.3.1 and 7.3.2. Alternatively, when the EM algorithm is used, θ and
x are estimated iteratively with two steps at each iteration, the E and the M
steps (for references on the EM algorithm, see Dempster et al., 1977; Tanner,
1993). Conditional on the value of θ from the previous iteration, the E step
uses the multiscale algorithm of Section 7.3 in order to compute the posterior
mean of the latent process x and assigns this value to x. Conditional on this
value of x, the M step consists of ﬁnding ˆθ that maximizes the likelihood
function (7.1). Even though numerical methods will generally be necessary to
perform this maximization step, the computation of the likelihood function
is fairly fast as a result of the tree topology associated with the multiscale
model.
A good example of the use of an empirical Bayes approach in a multi-
scale analysis is given in Section 5.5 in the context of wavelet nonparametric
regression.


8
Hidden Markov Models on Trees
We present in this chapter hidden Markov models on trees. These models
are generalizations of the more traditional one-dimensional hidden Markov
models. Traditional hidden Markov models (HMMs) assume hidden states
that can take discrete values and are connected through a one-dimensional
Markov chain (for a good review on HMMs, see Scott, 2002). In these HMMs,
the observations may be discrete or continuous and are conditionally indepen-
dent given the hidden states. Analogously, hidden Markov models on trees
(HMMTs) assume that the values of the latent label process at nodes of a
given level are conditionally independent given the latent label process at
the immediate coarser level. Moreover, HMMTs assume that the latent la-
bel process evolves on a tree in a construction analogous to that described
in Chapter 7 for Gaussian processes on trees. More speciﬁcally, nodes of a
given level are conditionally independent given the immediate coarser level.
This conditional independence leads to very fast algorithms for the analysis
of HMMTs. HMMTs and variants have been successfully used for image clas-
siﬁcation (Kato et al., 1996a,b; Lafert´e et al., 2000) and image segmentation
(Bouman and Shapiro, 1994; Comer and Delp, 1999). An interesting con-
struction is the use of hidden Markov models on trees coupled with wavelets
in order to induce dependence among the wavelet coeﬃcients (Crouse et al.,
1998; Nowak, 1999).
There are other approaches to the analysis of images using multiscale label
representations. For example, Gidas (1989) and P´erez and Heitz (1996) deﬁne
the label ﬁeld model at the ﬁnest level and, given some coarsening operation,
obtain approximations for the model at the coarser levels. Another approach
based on multigrid methods (for an introduction to multigrid methods, see
Briggs et al., 2000) is to initiate the image analysis at the coarsest level, use
that analysis as a starting point for the analysis at the second-coarsest level,
and proceed analogously until the ﬁnest level of resolution. This multigrid-
based approach requires the deﬁnition of how to coarsen the image and how
to interpolate the image analysis results to the next ﬁner level (Bouman and
Liu, 1991; Krishnamachari and Chellappa, 1997). These constructions do not

80
8 Hidden Markov Models on Trees
lead to coherent joint probability models for the latent label process at the
diﬀerent levels of resolution. We prefer the HMMT framework that provides a
coherent joint probability model at the diﬀerent levels of resolution and, thus,
inherits from the laws of probability a natural ﬂow of information between
the diﬀerent resolution levels.
An approach that is related to HMMTs has been proposed by Kolaczyk
et al. (2005) for image segmentation. In their approach, conditional on a label
ﬁeld the observations are independent with label-dependent mixture distri-
butions. The label ﬁeld is obtained through adaptive pruning of recursive
dyadic partitions and is estimated by penalized maximum likelihood. The pe-
nalization term can be interpreted as the logarithm of a prior that induces
parsimonious estimated label ﬁelds.
This chapter is organized as follows. Section 8.1 discusses hidden Markov
models in one dimension. Section 8.2 presents hidden Markov models on trees.
The recursive algorithms for ﬁne to coarse ﬁltering and coarse to ﬁne smooth-
ing are presented in Section 8.3. Estimation when the hyperparameters are
unknown is discussed in Section 8.4. We illustrate the use of HMMTs with an
application to image classiﬁcation in Section 8.5.
8.1 HMMs in 1-D
A hidden Markov model in one dimension has two parts: a latent label process
that assumes discrete values in a set B = {1, . . . , b} and evolves through time
according to a Markov chain; and observations that are (in most models) con-
ditionally independent given the latent label process. This can be seen as a
mixture model with a ﬁnite state Markov chain as the mixing distribution
(e.g., see Scott, 2002). Hidden Markov models in one dimension have been
applied in a wide range of problems. For example, Hamilton (1989), Albert
and Chib (1993), Chopin and Pelgrin (2004), and Pelletier (2006) have used
HMMs to model regime changes in time series useful for detecting economic
cycles; in that case, the latent label process may assume distinct discrete val-
ues that correspond to diﬀerent economic regimes. Husmeier and McGuire
(2003) have developed an HMM-based model for evolution of species with
molecular sequences arising from mixtures of topologies adequate to the detec-
tion of recombination in 4-taxa DNA sequence alignments. Other ﬁelds where
HMMs have been applied include speech recognition (Juang and Rabiner,
1991; Sirigos et al., 2002), network security (Scott, 1999, 2004), alignment of
molecular sequences (Liu et al., 1999; Neuwald and Liu, 2004), and longitu-
dinal comparisons of treatments (Scott et al., 2005).
Deﬁne y1:t = (y1, . . . , yt)′ and x1:t = (x1, . . . , xt)′. The HMM is deﬁned by
the transition kernel for the latent label process from time t −1 to time t, by
the initial distribution at time 0, and by the distribution of the observation
at time t conditional on the latent label process

8.2 HMMs on Trees
81
p(xt = a|x1:(t−1), θ) = p(xt = a|xt−1, θ),
(8.1)
p(x1 = a),
a ∈B,
(8.2)
p(yt|x1:t, y1:(t−1), θ) = p(yt|xt, θ) = fxt(yt|θ),
(8.3)
where a ∈B, B is the set of labels, t = 1, . . . , T, and fxt(yt|θ) may be a
density function or a probability function.
Bayesian analysis of HMMs in 1-D is typically performed within an MCMC
framework in two steps. The ﬁrst step simulates the latent label vector
(x1, . . . , xT ) from its joint full conditional distribution using a forward ﬁl-
ter backward sampler. The second step, which is problem-speciﬁc, simulates
the parameter vector θ from its full conditional distribution. Let us now de-
scribe the recursive equations for the ﬁrst step. For the sake of simplicity, we
omit the dependence on θ.
The analysis of HMMs starts with the computation of the posterior dis-
tribution of the latent variable at time 1 given the observation at time 1:
p(x1|y1) =
p(y1|x1)p(x1)
b
a=1 p(y1|x1 = a)p(x1 = a)
.
Then, a forward ﬁlter computes
p(xt|y1:(t−1)) =
b

a=1
p(xt|xt−1 = a)p(xt−1 = a|y1:(t−1)),
p(xt|y1:t) =
fxt(yt)p(xt|y1:(t−1))
b
a=1 fa(yt)p(xt = a|y1:(t−1))
.
The forward ﬁlter stops at time T and provides p(xT |y1:t), the posterior dis-
tribution of the latent label process at time T given all the observations. Then,
the following backward smoother computes the posterior distributions of the
latent label process at each time conditional on all the observations:
p(xt|y1:T ) =
b

a=1
p(xt|y1:t, xt+1 = a)p(xt+1 = a|y1:T ),
where
p(xt|y1:t, xt+1 = a) = p(xt+1 = a|xt)p(xt|y1:t)
p(xt+1 = a|y1:t)
.
The equations above for the forward ﬁlter backward smoother may be nu-
merically unstable. Refer to Scott (2002) for modiﬁcations that make the
recursions more stable.
8.2 HMMs on Trees
The construction of a hidden Markov model on a tree is analogous to the
construction of Gaussian multiscale models on trees described in Chapter 7.

82
8 Hidden Markov Models on Trees
More speciﬁcally, a hidden Markov model on a tree assumes that the values of
the latent label process at nodes of a given level are conditionally independent
given the latent label process at the immediate coarser level. The notation here
is analogous to that of Chapter 7; that is, xl and yl denote the vector of labels
and the vector of observations at resolution level l.
For the sake of simplicity of exposition, we assume here that the obser-
vations at each node and each level are conditionally independent given the
latent process. Thus, the joint density function of (y0, . . . , yL−1, x0, . . . , xL−1)
can be written as
p(y0, . . . , yL−1, x0, . . . , xL−1|θ) = p(x0|θ)
⎡
⎣
L−1

l=1
nl

j=1
p(xlj|xAlj, θ)
⎤
⎦
×
⎡
⎣
L−1

l=0
nl

j=1
p(ylj|xlj, θ)
⎤
⎦,
(8.4)
where p(xlj|xAlj, θ) is the discrete probability function of xlj given its ances-
tor, and f(ylj|xlj, θ) is the density function, either discrete or continuous, of
ylj given the corresponding latent variable xlj. Moreover, θ is the parameter
vector associated with the multiscale hidden Markov model of interest and
is typically of low dimension. For example, θ may include transition proba-
bilities. Bayesian estimation of the label process and the parameter vector θ
is easily performed regardless of whether the observations ylj are discrete or
continuous.
8.3 Estimation When θ Is Known
When θ is known, a Viterbi-like algorithm (for information on the Viterbi
algorithm, see Viterbi, 1967; Forney, 1973; Scott, 2002) can be used for infer-
ence on the multiscale latent label process. This algorithm was independently
introduced by Dawid (1992) for the analysis of probabilistic expert systems
and by Lafert´e et al. (1995) for discrete image modeling.
8.3.1 Fine to Coarse Filter
The multiscale construction of the discrete latent process deﬁnes a marginal
prior for each xlj, p(xlj), that can be recursively computed as
p(xlj) =
b

a=1
p(xlj|xAlj = a)p(xAlj = a).
(8.5)
Moreover, the coarse to ﬁne construction of the latent process can be reversed
using Bayes’ Theorem. More speciﬁcally, if (l′, j′) ∈Dlj then

8.3 Estimation When θ Is Known
83
p(xlj|xl′j′) = p(xl′j′|xlj)p(xlj)
p(xl′j′)
.
(8.6)
The following theorem provides the ﬁne to coarse ﬁlter.
Theorem 8.1. In the hidden Markov multiscale model deﬁned by Equation
(8.4), ﬁltered distributions are given as follows:
(a) Posterior at the ﬁnest resolution level:
p(xL−1,j|YL−1,j) =
p(yL−1,j|xL−1,j)p(xL−1,j)
b
a=1 p(yL−1,j|xL−1,j = a)p(xL−1,j = a)
.
(b) Posterior for (l′, j′) ∈Dlj: Discrete probability distribution
p(xl′j′|Yl′j′).
(c) Prior at (l, j):
p(xlj|Y +
lj ) ∝p(xlj)p(Y +
lj |xlj)
= p(xlj)

(l′,j′)∈Dlj
p(Yl′j′|xlj)
∝p(xlj)

(l′,j′)∈Dlj
p(xlj|Yl′j′)
p(xlj)
,
where p(xlj|Yl′j′) can be computed as
p(xlj|Yl′j′) =
b

a=1
p(xlj|xl′j′ = a)p(xl′j′ = a|Yl′j′).
(d) Posterior at (l, j):
If γlj = 0 then p(xlj|Ylj) = p(xlj|Y +
lj ).
If γlj = 1 then p(xlj|Ylj) ∝p(ylj|xlj)p(xlj|Y +
lj ).
Proof. The proof is by induction and uses discrete probability calculus and
Bayes’ Theorem. As the proof is straightforward, we leave it to the reader. □
8.3.2 Coarse to Fine Smoother
After the ﬁne to coarse ﬁltering sweep, we have at the root of the tree the
distribution x0|Y0; that is, the distribution of the latent label process at the
root node given all the information. In order to obtain the smoothed distrib-
utions xlj|Y0, l = 1, . . . , L −1, j = 1, . . . , nl, it will be necessary to send the
information Y0 down the tree. Deﬁne Y −
lj = Y0 \ Ylj. The following theorem
provides the coarse to ﬁne smoother.

84
8 Hidden Markov Models on Trees
Theorem 8.2. In the multiscale hidden Markov model deﬁned by Equation
(8.4), smoothed distributions are given as follows:
(a) Posterior for node Alj: Discrete probability distribution p(xAlj|Y0), xAlj =
1, . . . , b.
(b)
p(xlj|xAlj, Ylj) ∝p(xlj|Ylj)p(xlj|xAlj)
p(xlj)
.
(c) Posterior for node (l, j):
p(xlj|Y0) =
b

a=1
p(xlj|xAlj = a, Ylj)p(xAlj = a|Y0).
Proof. Again, the proof is by induction and uses discrete multivariate prob-
ability calculus and Bayes’ Theorem. As the proof is straightforward, we leave
it to the reader.
□
8.4 Estimation When θ Is Unknown
If the parameter vector θ is unknown, the Viterbi-like algorithm of Section 8.3
cannot be used directly. Nevertheless, the ﬁne to coarse ﬁltering sweep and
the coarse to ﬁne smoothing sweep may be integrated within algorithms for
the joint Bayesian or maximum likelihood estimation of the parameter vector
θ and the latent process x. As discussed in Section 7.4 for the Gaussian
case, maximum likelihood estimation will typically be performed by an EM
algorithm, while Bayesian estimation will use a Markov chain Monte Carlo
algorithm or an empirical Bayes approach.
Moreover, as θ includes the hyperparameters of the conditional distrib-
ution of an observation given the corresponding label, when θ is unknown
there is ambiguity in the deﬁnition of the model because a switch of two la-
bels will yield the same likelihood. The typical solution for this problem is
to impose parameter constraints, such as ordering of the means or variances
corresponding to diﬀerent labels (e.g., see Scott, 2002).
8.5 Application: Image Classiﬁcation
In this section, we illustrate the use of multiscale hidden Markov models with
an application to the classiﬁcation of a synthetic image.
We consider here a ﬁeld of size 128 × 128. Each pixel of this ﬁeld can
be classiﬁed as belonging to one of three groups, A, B, or C, as depicted
in Figure 8.1(a). Associated with each pixel is a Gaussian observation with
parameters that depend on the pixel classiﬁcation:

8.5 Application: Image Classiﬁcation
85
x
y
32
64
96
128
32
64
96
128
x
y
32
64
96
128
32
64
96
128
x
y
32
64
96
128
32
64
96
128
(a)
(b)
(c)
Fig. 8.1. (a) True label ﬁeld: white (group 1), grey (group 2), black (group 3).
(b) Observed noisy ﬁeld (light colors correspond to higher values, darker colors
correspond to lower values). (c) Maximum a posteriori label ﬁeld: white (group 1),
grey (group 2), black (group 3).
•
Group 1: N(µ1, σ2
1).
•
Group 2: N(µ2, σ2
2).
•
Group 3: N(µ3, σ2
3).
Conditional on the label ﬁeld (that is, the ﬁeld that contains the classiﬁcations
of the pixels), the observations are independent. Here we used µ1 = 9, µ2 = 7,
µ3 = 5, σ2
1 = 4, σ2
2 = 2, σ2
3 = 1. In the computations below, it is assumed
that these parameters are known. The simulated observed ﬁeld is depicted in
Figure 8.1(b).
The objective here is to use the observed ﬁeld to classify each pixel of
the image as belonging to group 1, 2, or 3. In order to do that, we assume
a hidden Markov model on a quadtree with log2 128 = 7 resolution levels. In
this particular example, the observations are made only at the ﬁnest resolution
level (128 × 128).
It is assumed that there is no prior information on the label at the root
level; that is, p(x0 = a) = 1/3, a = 1, 2, 3. Moreover, it is assumed that the
transition probability from parent node to children nodes is given by
p(xlj = b|xAlj = a) =

1 −θl,
if b = a,
0.5θl, otherwise.
Thus, as we go from coarser to ﬁner levels, the probability that a descendant
node assumes the same label as its ancestral node increases. That is a good
idea because it induces more similarity between nodes at the ﬁner levels while
allowing larger variability at the coarser levels.
The parameter θ ∈(0, 1) controls the smoothness of the process. Note that
the relationship between labels of a given level is induced by their relationship
with the most recent common ancestor. Thus, if θ is small, then the labels
at the descendant node will tend to be the same as the label at the ancestral

86
8 Hidden Markov Models on Trees
node, and that will induce more smoothness. If θ is large, then the dependence
between the nodes at the ﬁnest resolution level will be weaker. Here we use
θ = 0.7, which in fact induces negative correlations between the label nodes
at level 1 and their ancestor at level 0 but nevertheless induces smoothness
at the ﬁnest level of resolution.
Figure 8.1(c) presents the maximum a posteriori (MAP) estimate of the
label ﬁeld at the ﬁnest resolution. The multiscale hidden Markov model frame-
work was able to classify without error all the pixels corresponding to group 3.
While the framework had some diﬃculty with the classiﬁcation of the pixels
close to the boundary between groups 1 and 2, most of the pixels of those
groups were correctly classiﬁed.

9
Mass-Balanced Multiscale Models on Trees
In many multiscale problems, the relationship between the diﬀerent levels
of the multiscale process is deterministic. For example, the total volume of
petroleum in a given region at a coarser level is the sum of the volumes of
petroleum in the corresponding ﬁner regions. This type of property is known
as balance of mass. In this chapter, we revise the tree modeling approach of
Kolaczyk and Huang (2001) for the analysis of multiscale processes subject to
mass balance. Their approach is strongly based on the approach of Allan S.
Willsky and his coauthors, presented in Chapter 7, but generalized to cases
where the number of descendants is not constant and to include the cases
of Gaussian and Poisson observations. The case of Poisson observations is a
generalization of the work of Kolaczyk (1999) for multiscale Poisson processes
on dyadic trees. As in Willsky’s tree model, the multiscale model of Kolaczyk
and Huang induces rich covariance structures whose analytic expressions were
derived by Louie and Kolaczyk (2004). Building on the work of Kolaczyk
(1999), Bouman et al. (2005) developed a multiscale hazard model for survival
analysis. Other alternative multiscale models for the analysis of mass-balanced
processes have been developed by Huang et al. (2002) and Daoudi et al. (1999)
for Gaussian processes. Here we present the developments of Kolaczyk and
Huang (2001) because they include analysis not only for Gaussian but also
for Poisson processes.
The procedure of Kolaczyk and Huang (2001) may be used as a multiscale
smoothing of the observed values in order to obtain a smoothed estimated
latent mean process. There are other alternatives in the literature, and the
most currently used assume a priori that the latent mean process follows
a Gaussian random ﬁeld (e.g., Besag et al., 1995). This assumption is not
appropriate when some areas have mean levels much higher than their sur-
rounding areas. In those cases, the analysis with Gaussian random ﬁelds will
oversmooth the latent mean process. In contrast, the multiscale analysis of
Kolaczyk and Huang (2001) will tend to indicate that at those areas the la-
tent mean level is in fact much higher than in the surrounding areas. This idea
has been further developed by Louie and Kolaczyk (2006a,b) in the context of

88
9 Mass-Balanced Multiscale Models on Trees
disease mapping in spatial epidemiology and is very eﬀective for the detection
of isolated disease clusters.
9.1 Introduction
Assume that interest lies in some underlying continuous process {µ(s) : s ∈
S} on some domain S ⊂Rk, where k is typically less than or equal to 3.
Moreover, assume that because of measurement restrictions, data are available
only up to a given scale of resolution L −1 on a partition of the domain
S, denoted by {BL−1,1, . . . , BL−1,nL−1}, with BL−1,j ∈S, j = 1, . . . , nL−1,
BL−1,i ∩BL−1,j = ∅, i ̸= j, and ∪n
j=1BL−1,j = S.
Kolaczyk and Huang (2001) assume that for each element BL−1,j there
is a measurement yL−1,j such that E(yL−1,j) = µL−1,j =

BL−1,j µ(s)ds,
j = 1, . . . , nL−1. Moreover, they assume that yL−1,1, . . . , yL−1,nL−1 are condi-
tionally independent given µL−1,1, . . . , µL−1,nL−1. This is a fairly reasonable
assumption equivalent to assuming independent measurement errors. Note
that in general the spatial process µ(s) will be correlated and this spatial de-
pendence will pass over to the measurements yL−1,1, . . . , yL−1,nL−1. Thus, the
marginal distribution of the measurements will exhibit spatial dependence.
Kolaczyk and Huang (2001) are interested not only in the process µ(s) at
the resolution scale L −1 but also in the process at aggregated coarser scales.
At the lth scale of resolution, the domain S is partitioned in nl subregions
Bl,1, . . . , Bl,nl, l = 0, . . . , L −2. It is assumed that the partition at level l
is a reﬁnement of the partition at level l + 1; that is, Blj = ∪(l′,j′)∈DljBl′j′,
l′ = l + 1, where Dlj is the set of descendants of subregion j at level l, and
Dlj ∩Dli = ∅, i ̸= j. Note that the number of descendants does not need to be
constant; denote the number of descendants of subregion (l, j) by mlj. This
construction is very similar to the construction of multiscale models on trees
of Chapter 7, except for the property of balance of mass and the fact that the
tree nodes correspond here to subregions.
The mass-balance assumption corresponds to the recursive deﬁnition at
the lth level of aggregated measurements
ylj =

(l′,j′)∈Dlj
yl′j′ =

(l′,j′)∈Dlj
yl+1,j′
and aggregated mean process
µlj =

(l′,j′)∈Dlj
µl+1,j′.
Let G be a set of subregions and denote by yG and µG the corresponding
vectors of measurements and expected values, respectively. Thus yDlj denotes
the vector of descendants of ylj. Note that as ylj is a deterministic function

9.2 Gaussian Case
89
of its descendants, the distribution of yDlj conditional on ylj is degenerate.
In order to resolve this degeneracy, deﬁne D∗
lj as the set of descendants of ylj
with one deleted descendant; which descendant is deleted is arbitrary. Then,
the likelihood function admits the following multiscale factorization (Kolaczyk
and Huang, 2001):
nL−1

j=1
p(yL−1,j|µ) =
⎡
⎣
n0

j=1
p(y0,j|µ)
⎤
⎦×
L−2

l=0
nl

j=1
p(yD∗
lj|ylj, µ).
(9.1)
This factorization holds fairly generally and, as discussed in the following sec-
tions, can be specialized in a simple way for the cases of Gaussian and Poisson
observations. In the Gaussian case, the conditional distribution of the descen-
dants given the ancestral node is degenerate Gaussian and we use the notation
D∗
lj in Section 9.2. In the Poisson case, the distribution of the descendants
given the ancestral node is multinomial. Even though the multinomial is a
degenerate discrete distribution, there is no ambiguity in its deﬁnition and
thus we use the notation Dlj in Section 9.3.
9.2 Gaussian Case
9.2.1 Likelihood
Denote the expected value and variance of ylj by µlj and σ2
lj, respectively. In
addition, deﬁne yl = (yl,1, . . . , yl,nl)′, µl = (µl,1, . . . , µl,nl)′, σ2
l = (σ2
l,1, . . . ,
σ2
l,nl)′, and Σl = diag(σ2
l ). Under the assumption of conditional independence
of yl given µL−1 and σ2
L−1, the variance at (l, j) can be recursively computed
as
σ2
lj =

(l′,j′)∈Dlj
σ2
l+1,j′.
Let us assume that the joint distribution of the observations at the ﬁnest
level L −1 conditional on the mean process µ is multivariate Gaussian. Thus,
yl|µl, Σl ∼N(µl, Σl). Moreover, the joint distribution of ylj and yD∗
lj is
 ylj
yD∗
lj
%%%% µL−1, σ2
L−1 ∼N
⎡
⎣
 µlj
µD∗
lj

,
⎛
⎝σ2
lj

σ2
D∗
lj
′
σ2
D∗
lj
ΣD∗
lj
⎞
⎠
⎤
⎦,
where µD∗
lj and ΣD∗
lj are the mean vector and covariance matrix of yD∗
lj,
respectively. In addition, σ2
D∗
lj is the cross covariance matrix between yD∗
lj and
ylj; in this case, the cross covariance matrix is equal to the vector of variances
of yD∗
lj. Thus, from standard results for multivariate normal distributions, the
conditional distribution of yD∗
lj given ylj is

90
9 Mass-Balanced Multiscale Models on Trees
yD∗
lj
%%% ylj, µL−1, σ2
L−1 ∼N(vljylj + ωlj, Ωlj),
with
vlj = σ2
D∗
lj/σ2
lj,
ωlj = µD∗
lj −vljµlj,
and
Ωlj = ΣD∗
lj −σ−2
lj σ2
D∗
lj

σ2
D∗
lj
′
.
Therefore, all the distributions in Equation (9.1) are also Gaussian, and
the factorization may be written as
nL−1

j=1
p(yL−1,j|µL−1,j, σ2
L−1,j) = p(y0|µ0, Σ0)
L−2

l=0
nl

j=1
p(yD∗
lj|ylj, ωlj, Ωlj).
(9.2)
9.2.2 Prior Distributions
The factorization (9.2) reparameterizes the Gaussian model initially pa-
rameterized by µL−1, the latent process at the ﬁnest level, in terms of
(µ0, ω0, . . . , ωL−2), where ωl = (ω′
l1, . . . , ω′
l,nl)′. This is a multiscale decom-
position of the mean process analogous to wavelet decompositions, where ωlj
has a role similar to wavelet coeﬃcients. More speciﬁcally, ωlj explains how the
value at node (l, j) is expected to split among its descendants. As is common
practice in wavelet analysis, Kolaczyk and Huang (2001) assign independent
priors to each element of (µ0, ω0, . . . , ωL−2).
A natural choice for the mean level at the coarsest resolution is to assume
a conjugate prior µ0 ∼N(mµ0, Φ0), with Φ0 implying a fairly diﬀuse distrib-
ution. For the ωlj’s there are some possible speciﬁcations that imply diﬀerent
levels of homogeneity for the latent process µ(s).
In one prior speciﬁcation, they assume conjugate priors
ωlj|Φlj ∼N(0, Φlj),
(9.3)
where Φlj, l = 0, . . . , L −1, j = 1, . . . , nl are known covariance matrices.
The use of this conjugate prior allows fast computation of summaries of the
posterior distribution such as posterior means and variances.
They also consider a prior speciﬁcation based on the mixture of distribu-
tions
ωlj|ηlj, Φ(0)
lj , Φ(1)
lj ∼(1 −ηlj)N(0, Φ(0)
lj ) + ηljN(0, Φ(1)
lj ),
(9.4)
where ηlj ∼Bernoulli(plj), and Φ(0)
lj
and Φ(1)
lj
are known covariance matrices
such that Φ(0)
lj
implies a distribution very concentrated around the mean 0,
while Φ(1)
lj
implies a very diﬀuse distribution. This speciﬁcation allows fairly
inhomogeneous latent processes µ(s).

9.2 Gaussian Case
91
9.2.3 Estimation
The estimation of the latent process at the ﬁnest level µL−1 is performed
assuming a square error loss. As a consequence, the Bayesian estimator is the
posterior mean of µL−1.
A very interesting feature of Kolaczyk and Huang’s construction is that
the posterior distribution of the mean level process at the ﬁnest level µL−1
factorizes in terms of the new parameterization:
p(µL−1|yL−1) = p(µ0|y0)
L−2

l=0
nl

j=1
p(ωlj|yD∗
lj, ylj).
(9.5)
Because of the factorization above, the posterior mean of µL−1 can be recur-
sively computed using the formula
ˆµD∗
lj = ˆωlj + vlj ˆµlj,
where ˆωlj = E[ωlj|yD∗
lj, ylj].
The recursion starts with the computation of the posterior mean of the
latent process at the coarsest level:
ˆµ0 = (Σ−1
0
+ Φ−1
0 )−1(Σ−1
0 y0 + Φ−1
0 mµ0).
Note that when the prior for µ0 is diﬀuse (that is, Φ0 is large), the posterior
mean of µ0 will be close to y0.
When the conjugate Gaussian prior (9.3) is used, the posterior distribution
of ωlj is Gaussian with mean
ˆωlj = Φlj(Φlj + Ωlj)−1(yD∗
lj −yljvlj).
(9.6)
When the mixture-of-normals prior (9.4) is used, the posterior distribution
of ωlj is also a mixture of normals. In this case, the posterior mean will be
ˆωlj = qlj ˆω(1)
lj + (1 −qlj)ˆω(0)
lj ,
where ˆω(0)
lj
and ˆω(1)
lj
are computed with Equation (9.6) using Φ(0)
lj
and Φ(1)
lj ,
respectively, instead of Φlj. Moreover,
qlj = P(ηlj = 1|yD∗
lj, ylj)
=
Olj
1 + Olj
,
where Olj is the posterior odds ratio that node (l, j) belongs to component 1
against component 0 of the mixture; that is,
Olj =
plj
1 −plj
×
|Φ(0)
lj + Ωlj|0.5 exp
#
0.5(yD∗
lj −yljvlj)′(Φ(0)
lj + Ωlj)−1(yD∗
lj −yljvlj)
$
|Φ(1)
lj + Ωlj|0.5 exp
#
0.5(yD∗
lj −yljvlj)′(Φ(1)
lj + Ωlj)−1(yD∗
lj −yljvlj)
$.

92
9 Mass-Balanced Multiscale Models on Trees
over 1.8
1.5 – 1.8
1.2 – 1.5
0.9 – 1.2
under 0.9
(a)
(b)
(c)
(d)
Fig. 9.1. (a) Logarithm of observed Espirito Santo State per capita income per
county in 2001. (b) Logarithm of smoothed per capita income. (c) Micro-region map.
(d) Macro-region map. The smoothed map highlights the existence of a cluster of
higher per capita level in the central-east part of the state that corresponds to the
metropolitan area of Vitoria.
9.2.4 Application: Per Capita Income in Espirito Santo State
We illustrate the application of the Gaussian multiscale model to the smooth-
ing of the per capita income per county of Espirito Santo State, Brazil, in
2001 (Figure 9.1). The per capita income is a continuous variable, and for

9.3 Poisson Case
93
easy visualization Figure 9.1(a) shows in ﬁve categories the logarithm of the
observed per capita income per county of Espirito Santo State in 2001. Here
we consider three levels of resolution: county (ﬁne), micro-region (intermedi-
ate), and macro-region (coarse). Here we do not have mass balance as deﬁned
in Section 9.1, but we are interested in using the model for smoothing. In this
application, the observations are made at the ﬁne level of resolution; that is,
at the county level. There is high disparity among counties of Espirito Santo
State with respect to per capita income, with highest and lowest per capita
income diﬀering by a factor of 3. Figures 9.1(c) and 9.1(d) show the political
boundaries of the micro- and macro-regions, respectively.
We applied the Gaussian multiscale model estimating the variances by
empirical Bayes. Figure 9.1(b) shows the smoothed per capita income per
county. The smoothing is highly related to the deﬁnitions of the micro- and
macro-regions. Thus, this type of procedure is adequate when the quantity of
interest is related to the political boundaries at the several resolution levels.
In the case of Espirito Santo State, counties in the same micro- and macro-
regions have similar socio-economic characteristics. From Figure 9.1(b), it is
interesting to note that counties in the east of Espirito Santo State have higher
smoothed per capita incomes. Another important feature is the existence of
a cluster of higher per capita levels in the central-east part of the state that
corresponds to the metropolitan area of the state capital, Vitoria.
9.3 Poisson Case
9.3.1 Likelihood
When the distribution of the observations at the ﬁnest level L −1 conditional
on the latent process µ is Poisson, then all the distributions in Equation (9.1)
will be Poisson and multinomial. More speciﬁcally, in the case of Poisson
observations, the factorization (9.1) may be written as
nL−1

j=1
p(yL−1,j|µL−1,j) = p(y0|µ0)
L−2

l=0
nl

j=1
p(yDlj|ylj, ωlj),
(9.7)
where y0|µ0 ∼Poisson(µ0) and yDlj|ylj, ωlj ∼Multinomial(ylj, ωlj), with
ωlj = µDlj/µlj.
9.3.2 Prior Distributions
As in the Gaussian case, the factorization (9.7) reparameterizes the Poisson
model initially parameterized by the latent process at the ﬁnest level µL−1 in
terms of (µ0, ω0, . . . , ωL−2), where ωl = (ω′
l1, . . . , ω′
l,nl)′.
A natural choice for the mean level at the coarsest resolution, µ0, is to
assume independent conjugate gamma priors for each element; that is, µ0j ∼

94
9 Mass-Balanced Multiscale Models on Trees
Gamma(τ0, τ1), j = 1, . . . , n0, with τ0 > 0 and τ1 > 0. Typically, τ0 and τ1
are chosen close to zero, implying a fairly diﬀuse distribution.
Again, for the ωlj’s there are some possible speciﬁcations that imply diﬀer-
ent levels of homogeneity for the latent process µ(s). One possible speciﬁcation
is to assume conjugate priors
ωlj|γlj ∼Dirichlet(γlj1mlj),
(9.8)
where γlj > 0 and 1mlj is a vector of ones with length equal to the number
of descendants mlj of node (l, j). The use of this conjugate prior allows fast
multiscale analysis.
Another possibility is to assume a priori a mixture of distributions,
ωlj|ηlj, γ(0)
lj , γ(1)
lj
∼(1−ηlj)Dirichlet(γ(0)
lj 1mlj)+ηljDirichlet(γ(1)
lj 1mlj), (9.9)
where ηlj ∼Bernoulli(plj), γ(0)
lj
> 0 is small, and γ(1)
lj
> 0 is large. In the
limiting case γ(1)
lj
→∞, the second component of the mixture becomes a
degenerate multivariate distribution with each element equal to 1/mlj, which
implies an equal split of the value at node (l, j) between its descendants.
9.3.3 Estimation
As in the Gaussian case, in the Poisson case the posterior distribution of the
mean level process at the ﬁnest level, µL−1, factorizes as in Equation (9.5).
As a consequence, the posterior mean of µL−1 can be recursively computed
using the formula
ˆµDlj = ˆωlj ˆµlj,
where ˆωlj = E[ωlj|yDlj, ylj].
The recursion starts with the computation of the posterior mean of the
latent process at the coarsest level. The posterior distribution of µ0j is
Gamma(y0j + τ0, 1 + τ1). Thus, the posterior mean is
ˆµ0j = y0j + τ0
1 + τ1
.
Note that when the prior for µ0 is diﬀuse (that is, τ0 and τ1 are close to zero),
the posterior mean of µ0 will be close to y0.
When the conjugate Dirichlet prior (9.8) is used, the posterior distribution
of ωlj is Dirichlet(γlj1mlj + yDlj). In this case, the posterior mean of ωlj is
ˆωlj = γlj1mlj + yDlj
γljmlj + ylj
.
(9.10)
When the mixture of Dirichlets prior (9.9) is used, the posterior distrib-
ution of ωlj is also a mixture of Dirichlets. In this case, the posterior mean
will be

9.3 Poisson Case
95
ˆωlj = qlj ˆω(1)
lj + (1 −qlj)ˆω(0)
lj ,
where ˆω(0)
lj
and ˆω(1)
lj
are computed with Equation (9.10) using γ(0)
lj
and γ(1)
lj ,
respectively, instead of γlj.
Moreover, qlj is the posterior probability that node (l, j) belongs to com-
ponent 1 of the mixture of Dirichlets,
qlj = P(ηlj = 1|yDlj, ylj)
=
Olj
1 + Olj
,
where Olj is the posterior odds ratio of node (l, j) belonging to component 1
rather than component 0 of the mixture,
Olj =
plj
1 −plj
×p(yDlj|ylj, ηlj = 1)
p(yDlj|ylj, ηlj = 0),
(9.11)
where p(yDlj|ylj, ηlj = c) is the predictive distribution of the descendants
yDlj conditional on the parent ylj and on node (l, j) belonging to compo-
nent c of the mixture. Standard probability results show that this predictive
distribution can be computed as
p(yDlj|ylj, ηlj = c) =
Γ

mljγ(c)
lj

Γ

γ(c)
lj
mlj
*
(l′,j′)∈Dlj Γ

γ(c)
lj + yl′j′

Γ

mljγ(c)
lj + ylj

. (9.12)
9.3.4 Application: Smoothing of Leptospirosis Time Series
We illustrate here the use of the multiscale Poisson model with an application
to the series of leptospirosis patients admitted to the Couto Maia Hospi-
tal from March 15, 1996 to March 15, 2004 in the city of Salvador, Bahia,
Brazil. This dataset has been analyzed in more detail by Bustamante et al.
(2006). The Couto Maia Hospital receives about 95% of all leptospirosis cases
in Salvador. Leptospirosis is a potentially fatal disease that is epidemic in
Salvador and has been associated in that city with ﬂoods and poor sanitation
in slums (Ko et al., 1999; Sarkar et al., 2002). Here we consider the num-
ber of cases reported in periods of 11 days, leading to a time series with 256
observations presented in Figure 9.2(a).
We applied the multiscale Poisson model with dyadic partition of Kolaczyk
(1999) and 1 + log2 256 = 9 scales. This model uses a tree mixing scheme
that implies a stationary multiscale model. We assumed a degenerate mixture
prior (9.9) for ωlj with γ(0)
lj
= 1 and γ(1)
lj
→∞, ∀l, j. Moreover, we used equal

96
9 Mass-Balanced Multiscale Models on Trees
0
50
100
150
200
250
0
10
20
30
40
0
50
100
150
200
250
0
10
20
30
40
(a)
(b)
Fig. 9.2. (a) Series of leptospirosis from March 15, 1996 to March 15, 2004 aggre-
gated in periods of 11 days. (b) Estimated intensity. The estimated intensity draws
attention to the existence of a seasonal pattern and a reduction in the seasonal
ﬂuctuations through time.
mixing probabilities at each level; that is, plj = pl. Additionally, we assumed
that the pl’s follow an a priori independent uniform distribution on [0, 1]. The
mixing probabilities were estimated with marginal posterior modes and the
intensity function was estimated as explained in Section 9.3.3.
Figure 9.2(b) presents the estimated intensity function. From the esti-
mated intensity, we can note a seasonal pattern and a reduction in the seasonal
ﬂuctuations along the considered time period. While surveillance eﬀorts prob-
ably reduced the maximum annual risk over the years, deteriorating urban
conditions seem to have led to an increase in the minimum annual risk.

10
Multiscale Random Fields
This chapter presents multiscale random ﬁeld models with interconnected
resolution levels and smoothness within each level that were introduced by
Ferreira et al. (2005). This is important when interest lies in modeling the
dynamics of the multiscale process within each scale of resolution as well as
across the diﬀerent scales. This is of particular interest when the process is
observed at diﬀerent scales of resolution or when the multiscale model is used
as a prior for an underlying process, and it is desirable to impose smoothness
within each level of resolution and a stochastic constraint that the diﬀerent
levels of resolution have similar behavior.
For example, Figure 10.1 represents a multiscale random ﬁeld with three
levels of resolution. At the coarsest and intermediate levels of resolution, each
site corresponds to four sites of the immediate ﬁner level. It is desirable to
impose some stochastic structure at each level, such as Markov random ﬁelds,
and connect the levels through some coarsening or aggregation operation, such
as averaging or sampling, but in general this leads to incompatible probabil-
ity distributions. Jeﬀrey’s rule of conditioning is used to revise the implied
distributions and ensure that the probability distributions at diﬀerent levels
are strictly compatible.
As with the Gaussian multiscale models on trees presented in Chapter 7,
the multiscale random ﬁeld models presented in this chapter have the ability
to accommodate observations at diﬀerent levels of resolution. An advantage of
the multiscale random ﬁeld models of this chapter over the models presented
in Chapter 7 is that they provide smoother estimates of the process of interest.
An example where multiscale random ﬁeld models have been used with suc-
cess is in the estimation of permeability ﬁelds. In that problem, there are two
types of information: static data and dynamic data. Static data are available
at diﬀerent resolution levels as a result of geological studies, well tests, and
core samples. Dynamic data are obtained from results of tracer experiments
performed in an aquifer or from the history of oil production in a petroleum
ﬁeld. The dynamic data can be incorporated in the estimation of the perme-
ability ﬁeld with the help of ﬂuid ﬂow simulators that can run at diﬀerent

98
10 Multiscale Random Fields
x1
x2
x0
Fig. 10.1. Three levels of a multiscale random ﬁeld. A particular region at a given
resolution level is connected to its neighbors at the same level, to its parent at the
immediate coarser level, and to its descendants at the immediate ﬁner level.
resolution levels. Practical implementations use coarser-scale runs that are
fast and ﬁner-scale runs that are more accurate. The multiscale random ﬁeld
models of this chapter provide a natural framework for the incorporation of
the static data available at diﬀerent levels as well as for the incorporation of
the dynamic data with the use of ﬂuid ﬂow simulators running at diﬀerent
resolution levels. Section 16.2 of Chapter 16 gives a detailed description of the
use of multiscale random ﬁelds for the estimation of permeability ﬁelds.
Let us now introduce some notation. In general, a multiscale random ﬁeld
with L levels of resolution is considered, where xl denotes the vectorized lth
level of resolution with nl elements, l = 0, . . . , L −1; xlj denotes the value of
the jth site (or region) of the lth level and (l, j) its corresponding index. It is
assumed that site (l, j) has blj neighbor sites at the same level of resolution,
one parent site at the immediate coarser level l −1, and ml+1,j descendant
sites at the immediate ﬁner level l + 1. Moreover, Nlj denotes the set of sites
of the lth level that are neighbors of (l, j), and Dlj denotes the set of sites of
the (l + 1)th level that are descendants of (l, j).
The remainder of this chapter is organized as follows. Section 10.1 presents
the basic ideas of the construction of multiscale random ﬁelds through the
construction of a two-level model. This class of models is generalized to an
arbitrary number of levels in Section 10.2. Section 10.5 describes the algorith-
mic implementation of the model by means of a Markov chain Monte Carlo
(MCMC) sampling scheme. Section 10.6 illustrates with a simulated dataset
the procedures of multiscale random ﬁeld simulation and parameter estima-
tion.

10.1 Two-Level Model
99
10.1 Two-Level Model
In order to introduce the main concepts of multiscale random ﬁeld modeling,
this section presents the construction of a two-level multiscale random ﬁeld
model. We refer to the two-levels as the coarse and ﬁne scales.
The deﬁnition of the model is somehow subtle — it is important to care-
fully consider the information on which each equation is conditioned; oth-
erwise the model will be inconsistent. In order to build a consistent model
with smoothness at each resolution level and link between the levels, we use
here the concept of probability kinematics and the associated Jeﬀrey’s rule
of conditioning (for detailed information on probability kinematics and Jef-
frey’s rule, see Jeﬀrey, 1988). This rule explains how to revise an old joint
probability model for unknowns when new information completely revises the
marginal probability distribution for a subset of these unknowns. In our case,
we build an initial joint probability model for the coarse and ﬁne levels by
assuming that the ﬁne level follows a Markov random ﬁeld process and by
assuming that the coarse level is a linear function of the ﬁne level plus noise.
We note that this in general leads to weak spatial correlation at the coarse
level and, thus, the coarse-level process would not be very smooth. But let
us assume that we believe that the coarse level follows a smooth process, and
we incorporate this belief into the model by revising the marginal probability
distribution of the coarse level and assuming that the coarse level follows an
MRF process. This belief is the new information that completely revises the
marginal probability model at the coarse level. But this new information is at
odds with the old information that led us to assume an MRF at the ﬁne level
and a linear link between levels. Jeﬀrey’s rule is then used to revise the old
joint probability distribution at coarse and ﬁne levels. Using Jeﬀrey’s rule, we
assume that the conditional distribution of the process at the ﬁne level given
the coarse level remains the same. Thus the joint density updated by Jeﬀrey’s
rule is the product of the conditional density of the ﬁne level given the coarse
level with the revised density of the coarse level. Finally, the updated marginal
distribution at the ﬁne level is obtained from the updated joint distribution
by marginalization.
To be more concrete, start by assuming that the ﬁne level x1 = (x11, . . . ,
x1n1) can be modeled by a proper Markov random ﬁeld (PMRF) model as in
Equation (2.1),
x1 ∼N(µ1n1, Σ1),
(10.1)
with µ ∈R a location parameter and Σ1 a covariance matrix. As before, we
take Σ−1
1
= τ1(α1In1 + H1), with τ1 > 0 a scale parameter. H1 is a matrix
deﬁning the spatial similarities at the ﬁne level,
(H1)kl =
⎧
⎨
⎩
h1k,
k = l,
−g1kl, (1, k) ∈N1l,
0,
otherwise,
(10.2)

100
10 Multiscale Random Fields
with g1kl > 0 being a “measure of similarity” between sites (1, k) and (1, l)
and h1k = 
l∈N1k g1kl.
As will be made clear, the positive deﬁniteness of Σ−1
1
and thus the exis-
tence of Σ1 are fundamental for this particular multiscale model construction.
In order to guarantee that Σ−1
1
is positive deﬁnite, it is assumed that α1 > 0
since that implies Σ−1
1
is diagonally dominant and therefore positive deﬁnite
(Harville, 1997).
Assume a coarsening or aggregation operation through a linear link equa-
tion that establishes that the value at each site at the coarse level is equal to
a weighted average of the corresponding sites at the ﬁne level plus an error
term. More speciﬁcally, the link equation is deﬁned as
p(x0|x1) = N(x0|A1x1, δ1In0),
(10.3)
where A1 is the matrix that performs the coarsening operation and δ1 is the
variance of the error term. Thus, the sum of the elements of each line of A1
is equal to one. For example, the term A1x1 can represent arithmetic block
averages or sampling of the ﬁne level x1. If arithmetic block averages are
considered, then Equation (10.3) can be rewritten as
p(x0|x1) =
n0

i=1
N
⎛
⎝x0i
%%%%m−1
1

j∈D0i
x1j, δ1
⎞
⎠,
(10.4)
where ml is the number of descendants at the ﬁne level of each site at the
coarse level and D0i is the set of descendants of the ith coarse-level site. The
PMRF model at the ﬁne level x1 and the link Equation (10.3) imply the
particular model p(x0) = N(x0|µ1n0, A1Σ1A′
1 + δ1In0) for the coarse level.
As discussed by Lakshmanan and Derin (1993), in general the Markovianity
is lost in this coarsening operation. Thus, the resulting model at the coarse
level is more complex than desired and does not lead to eﬃcient algorithms
for incorporating information at diﬀerent resolutions. In order to deal with
this problem, Lakshmanan and Derin (1993) suggested approximating the
process at the coarse level by a Markov random ﬁeld. However, in that case
the joint probabilistic model of ﬁne and coarse levels becomes inconsistent.
Ferreira et al. (2005) suggest another route: part of the information contained
in Equations (10.1) and (10.3) is revised in order to impose a simple model
at the coarse level.
Suppose that additional information about the coarse level x0 is received,
information that supersedes the prior information on which p(x0) is based
and directly revises p(x0) to an updated model q(x0). For example, suppose
q(x0) is a PMRF,
q(x0) = N(x0|µ1n0, Q0),
(10.5)
where Q−1
0
= τ0[α0In0 + H0], and

10.1 Two-Level Model
101
{H0}kl =
⎧
⎨
⎩
h0k,
k = l,
−g0kl, (0, k) ∈N0l,
0,
otherwise.
where the interpretation of the parameters here is analogous to the interpre-
tation of the parameters in Equations (10.1) and (10.2).
The revision of the model for the coarse level from p(x0) to q(x0) can be
viewed as Bayesian updating with an implicit likelihood function proportional
to q(x0)/p(x0). It is assumed that in the revision of beliefs the coarse level
x0 is suﬃcient for the ﬁne level x1, where this meaning of suﬃciency is as
deﬁned by Diaconis and Zabell (1982); i.e., that conditional on the values at
the coarse level, the ﬁne level is independent of the additional information that
updated the distribution of the coarse level. As a consequence, the conditional
distribution of the ﬁne level given the coarse level is not updated by the
additional information, and Jeﬀrey’s rule of conditioning can be applied to
revise the marginal distribution of x1 (for details, see Jeﬀrey, 1988; Diaconis
and Zabell, 1982). The following theorem establishes the resulting multiscale
model with two-levels of resolution.
Theorem 10.1. Consider the initial model (10.1) for the ﬁne level x1, the
link equation (10.3) and the revised model (10.5) for the coarse level x0. If in
the revision of beliefs the coarse level x0 is suﬃcient for the ﬁne level x1, then
(i) the joint multiscale model for coarse and ﬁne levels is
q(x0, x1) = N(x1|µ1n1 + B1(x0 −µ1n0), Σ1 −B1W1B′
1)N(x0|µ1n0, Q0);
(10.6)
(ii) the revised marginal model for the ﬁne level is
q(x1) = N(x1|µ1n1, Σ1 −B1(W1 −Q0)B′
1),
(10.7)
where B1 = Σ1A′
1W−1
1
and W1 = A1Σ1A′
1 + δ1In0.
Proof.
The assumption that in the revision of beliefs the coarse level x0 is suf-
ﬁcient for the ﬁne level x1 means that, conditional on x0, x1 is independent
of the new information that led to the revision of beliefs about x0; that is,
q(x1|x0) = p(x1|x0). This last density function can be obtained by Bayes’
Theorem:
p(x1|x0) ∝p(x1)p(x0|x1)
= N(x1|µ1n1, Σ1) N(x0|A1x1, δ1In0).
Therefore
p(x1|x0) = N(x1|µ1n1 + B1(x0 −µ1n0), Σ1 −B1W1B′
1),

102
10 Multiscale Random Fields
where B1 = Σ1A′
1W−1
1
and W1 = A1Σ1A′
1 + δ1In0. Thus, the revised joint
multiscale model for coarse and ﬁne levels is
q(x0, x1) ∝q(x1|x0)q(x0)
N(x1|µ1n1 + B1(x0 −µ1n0), Σ1 −B1W1B′
1)N(x0|µ1n0, Q0).
This concludes part (i).
Moreover, the revised marginal model for the ﬁne level can be obtained by
the integration of the joint density above with respect to the coarse level, and
this is equivalent to the application of Jeﬀrey’s rule of conditioning. Thus
q(x1) =

q(x0, x1)dx0 = N(x1|µ1n1, Q1),
where Q1 = Σ1 −B1(W1 −Q0)B′
1. This concludes part (ii).
□
10.2 Model with Several Levels
The construction of the multiscale model can be generalized to any arbitrary
number of levels through the use of a result by Skyrms (1980), who has shown
that the same eﬀect of Jeﬀrey’s rule can be obtained by using a suﬃciently
richer sample space and by carefully conditioning each equation on diﬀerent
information. In addition, conditioning each equation on diﬀerent information
provides a diﬀerent interpretation and enlightens interesting aspects of the
multiscale model.
Consider a multiscale random ﬁeld model with L levels of resolution. The
lth level is denoted by xl, l = 0, 1, . . . , L −1, with x0 being the coarsest
level, and increases in l meaning progressively ﬁner levels. The movement
from coarser to ﬁner levels can be interpreted as an increase in the resolution
in a similar interpretation as in the wavelet framework, with the distinction
that in this multiscale framework each level can have a meaningful practical
interpretation.
The information on which each equation is conditioned is of extreme im-
portance, as the equations would be incompatible if they were conditioned on
the same information. Here Il denotes the initial knowledge about the behav-
ior on the lth level, and Gl is the accumulated knowledge from the coarsest
level up to the lth level xl. More speciﬁcally, G0 = I0 denotes the knowledge
about the generator mechanism of the coarsest level x0 and the accumulated
knowledge up to level x0 as well. In addition, G1 = I0
+ I1. In general, the ac-
cumulated knowledge from the coarsest level up to the lth level is recursively
deﬁned as Gl = Gl−1
+ Il.
The general multiscale random ﬁeld model is deﬁned in a hierarchical way.
Although it seems that the model is deﬁned from ﬁne to coarse levels, condi-
tional on all the information used to construct the model, the true dependence
direction in the model is from coarser to ﬁner levels. That is, following the

10.2 Model with Several Levels
103
model deﬁnition from ﬁne to coarse levels, the multiscale model is deﬁned as
the result of propagating down from coarse to ﬁne levels the implication of re-
vising distributions at the coarse levels. Figure 10.2 presents a partial graphical
representation of the model with the true dependence direction from coarser
to ﬁner levels.
G
I
I
x
x
x
l −1
l
l +1
l −1
l +1
l
Fig. 10.2. Partial graphical representation of the multiscale random ﬁeld model.
To be concrete, assume that given Il, the initial information about level l,
the level xl follows a proper Markov random ﬁeld process. Thus
xl|Il ∼N(µ1nl, Σl), l = 0, . . . , L −1,
(10.8)
where Σ−1
l
= τl(αlInl + Hl), and the roles and deﬁnitions of τl, αl, and Hl
are analogous to the roles and deﬁnitions of τ1, α1, and H1 in Section 10.1.
In order to develop estimation and simulation methodologies, it is useful
to rewrite Equation (10.8) as (Ferreira and de Oliveira, 2007)
p(xl|Il) ∝τ 0.5n
l
n

k=1
(λlk + αl)0.5 exp
,
−0.5τl
	
µ2nlαl −2µαl
n

k=1
xlk
+αl
n

k=1
x2
lk + x′
lHlxl

-
,
(10.9)
where λl1 ≥λl2 ≥. . . ≥λl,n−1 > λln = 0 are the eigenvalues of Hl. This
expression facilitates the derivation of the full conditional distributions pre-
sented in Section 10.5. Moreover, as Hl, l = 0, . . . , L −1 are assumed known
a priori, their eigenvalues need to be computed only once, in the beginning

104
10 Multiscale Random Fields
of the estimation procedure. Thus, the use of Equation (10.9) leads to fast
computation of the densities of interest in the estimation procedure presented
in Section 10.5.2.
In addition, assume that conditional on Il there exists a known linear
transformation mapping the level xl to the immediate coarser level xl−1 plus
noise. Then, for l = 1, . . . , L −1,
p(xl−1|Il, xl) = N(xl−1|Alxl, Ul),
(10.10)
where Ul = δlInl−1 and the sum of the elements of each line of Al is equal
to one. This representation is useful when the relation between coarser and
ﬁner levels occurs in a nonregular grid and the number of descendants or the
weights are not constant, as in Chapter 9.
In the simplest case, each element of xl−1 is written as an arithmetic
average of its ml descendants at level l plus noise. That is,
xl−1,s = m−1
l

w∈Dl−1,s
xlw + ul−1,s,
(10.11)
where the ul−1,s, (l = 1, . . . , L), (s = 1, . . . , nl), are mutually uncorrelated
zero-mean, normally distributed noise terms with ui−l,s ∼N(ul−1,s|0, δl) for
some between-levels variance δl.
Integrating out the ﬁner level xl, the distribution of the coarser level xl−1
given Il is obtained as p(xl−1|Il) = N(xl−1|µ1nl−1, AlΣlA′
l + Ul). This is
straightforward to show since all the involved distributions are Gaussian.
Now, assume that from coarser levels in the hierarchy updated informa-
tion Gl−1 is received about the generator mechanism of the coarser level.
Following this information, the coarser level xl−1 follows a Gaussian process
with mean µ1nl−1 and covariance matrix Ql−1; that is, p(xl−1|Gl−1) =
N(xl−1|µ1nl−1, Ql−1).
As the new information goes down the hierarchy, it is necessary to revise
the information on the process at the lth resolution level. Analogously to the
construction of the two-level model of Section 10.1, the basic principle is that
the accumulated knowledge Gl supersedes the initial knowledge Il on which
the initial distribution for xl was based, and is then sent down to ﬁner levels
to update the joint distribution throughout the hierarchy.
In order to obtain the joint multiscale model for (x0, . . . , xL−1) given all
the knowledge GL−1, the following two hypotheses are assumed:
(1) p(x0, . . . , xl−1|Gl) = p(x0, . . . , xl−1|Gl−1, Il) = p(x0, . . . , xl−1|Gl−1).
(2) p(xl|Gl, x0, . . . , xl−1) = p(xl|Gl−1, Il, xl−1) = p(xl|Il, xl−1).
Hypothesis (1) states that the coarser levels x0, . . . , xl−1 are independent
of the generator mechanism of the ﬁner level xl given their own generator
mechanism; this hypothesis is equivalent to the subjective update of the dis-
tribution of x0, . . . , xl−1.

10.2 Model with Several Levels
105
Hypothesis (2) states that given the generator mechanism of the ﬁner level,
the revised information Gl−1 on the generator mechanism of the coarser
level passes to the ﬁner level xl only through the realized immediate coarser
level xl−1; this hypothesis is equivalent to a Markovian assumption in addi-
tion to the suﬃciency assumption necessary for the application of Jeﬀrey’s
rule.
The following theorem establishes the resulting multiscale model with L
levels of resolution.
Theorem 10.2. The model deﬁned by Equations (10.8) and (10.10) and by
Hypotheses (1) and (2) has the following properties:
(i) the joint multiscale model for (x0, . . . , xL−1) given all the knowledge GL−1
is
p(x0, . . . , xL−1|GL−1) = N(x0|µ1n0, Q0)
L−1

l=1
N(xl|µ1nl + Bl(xl−1 −µ1nl−1), Σl −BlWlB′
l);
(ii) the marginal model for xl, l = 1, . . . , L −1 given all the knowledge GL−1
is
p(xl|GL−1) = N(xl|µ1nl, Ql);
(iii) and the conditional model of xl given the knowledge from the coarsest
up to the (L−1)th resolution level and the realized process from the coarsest up
to the (l −1)th level is
p(xl|GL−1, x0, . . . , xl−1) = N(xl|µ1nl + Bl(xl−1 −µ1nl−1), Σl −BlWlB′
l),
where Bl = ΣlA′
lW−1
l
, Wl = AlΣlA′
l + δlInl−1, and Ql = Σl −Bl(Wl −
Ql−1)B′
l.
Proof.
Proving part (iii).
Hypothesis (1) implies that p(x0, . . . , xl−1|GL−1) = p(x0, . . . , xl|Gl), and
thus
p(xl|GL−1, x0, . . . , xl−1) = p(xl|Gl, x0, . . . , xl−1)
= p(xl|Il, xl−1)
by Hypothesis (2). Using Bayes’ Theorem and Equations (10.8) and (10.10),
p(xl|Il, xl−1) ∝p(xl|Il)p(xl−1|xl, Il)
= N(xl|µ1nl, Σl)N(xl−1|Alxl, Ul).
Thus, through Bayesian linear regression,
p(xl|GL−1, x0, . . . , xl−1) = N(xl|µ1nl + Bl(xl−1 −µ1nl−1), Σl −BlWlB′
l),

106
10 Multiscale Random Fields
where Bl = ΣlA′
lW−1
l
and Wl = AlΣlA′
l +δlInl−1. This concludes part (iii).
Therefore
p(x0, . . . , xL−1|GL−1) = p(x0|GL−1)
L−1

l=1
p(xl|GL−1, x0, . . . , xl−1)
= p(x0|I0)
L−1

l=1
p(xl|Il, xl−1)
= N(x0|µ1n0, Q0)
L−1

l=1
N(xl|µ1nl + Bl(xl−1 −µ1nl−1), Σl −BlWlB′
l).
This concludes part (i).
The proof of part (ii) is by induction. By Hypothesis (1), p(x0|GL−1) =
p(x0|I0) = N(x0|µ1n0, Q0). Assume that p(xl−1|GL−1) = N(xl−1|µ1nl−1,
Ql−1). Then
p(xl|GL−1) =

p(xl|GL−1, xl−1)p(xl−1|GL−1)dxl−1
=

p(xl|Il, xl−1)p(xl−1|GL−1)dxl−1
=

N(xl|µ1nl + Bl(xl−1 −µ1nl−1), Σl −BlWlB′
l)
N(xl−1|µ1nl−1, Ql−1)dxl−1
= N(xl|µ1nl, Ql),
where Ql = Σl −Bl(Wl −Ql−1)B′
l. This concludes part (ii).
□
In several types of problems, the direct computation of the matrices Bl,
Wl, and Ql, l = 1, . . . , L −1, will not be necessary. Instead, it will be more
useful to consider the following alternative representation of part (iii) of The-
orem 10.2 for l = 1, . . . , L −1:
p(xl|Gl, x0, . . . , xl−1) = N(xl−1|Alxl, Ul)N(xl|µ1nl, Σl)
N(xl−1|µ1nl−1, AlΣlA′
l + Ul) .
(10.12)
This factorization allows eﬃcient generation of realizations from the multiscale
model in a cascade fashion from the coarsest to the ﬁnest levels of resolution.
10.3 The Multiscale Model as an Application
of Jeﬀrey’s Rule
This section presents an interpretation of the multiscale model of Ferreira
et al. (2005) as an application of Jeﬀrey’s rule.

10.4 Didactic Example: Three-Level Model
107
Quoting Diaconis and Zabell (1982): “Jeﬀrey’s rule for revising a prob-
ability P to a new probability P ∗based on new probabilities P ∗(Ei) on a
partition {Ei}i=1,...,n is
P ∗(A) =

P(A|Ei)P ∗(Ei).
Jeﬀrey’s rule is applicable if it is judged that P ∗(A|Ei) = P(A|Ei) for all A
and i.”
The construction of the multiscale model of Ferreira et al. (2005) can be
interpreted as an application of Jeﬀrey’s rule for revising probabilities in the
following way. Initially, one would think that the ﬁner level follows a Markov
random ﬁeld process, say, and the coarser level is derived from the ﬁner level
as a known function plus noise. In this way, the distribution of the coarser
level is already determined, as well as the distribution of the ﬁner level given
the coarser level, denoted by p(xl|Il, xl−1).
The hypothesis p(xl|Gl, x0, . . . , xl−1) = p(xl|Gl−1, Il, xl−1) = p(xl|Il, xl−1)
assumes the condition P ∗(A|Ei) = P(A|Ei), necessary for the application
of Jeﬀrey’s rule, as well as assuming Markovian resolution levels; that is,
(x0, . . . , xl−1) and (xl+1, . . . , xL−1) are conditionally independent given xl.
Thus, in the notation of Jeﬀrey’s rule, p(xl|Gl, x0, . . . , xl−1) corresponds to
P ∗(A|Ei) and p(xl|Il, xl−1) corresponds to P(A|Ei).
It is fundamental to note that the assumption p(x0, . . . , xl−1|Gl) =
p(x0, . . . , xl−1|Gl−1) in Section 10.2 means that the distribution of (x0, . . . ,
xl−1) will be completely revised. In the notation of Jeﬀrey’s rule, p(x0, . . . ,
xl−1| Gl−1) corresponds to P ∗(Ei).
Finally, Jeﬀrey’s rule can be used to recalculate the distribution of the
ﬁner level l, being equivalent to part (ii) of Theorem 10.2.
10.4 Didactic Example: Three-Level Model
This section illustrates the theory developed in Section 10.2 by the didactic
construction of a three-level model. In particular, interest will be in the joint
distribution of the three levels x0, x1, and x2. To make matters simpler, it is
assumed that µ = 0.
The initial information for each level is
p(x0|G0) = p(x0|I0) = N(x0|0, Σ0) = N(x0|0, Q0),
p(x1|I1) = N(x1|0, Σ1),
p(x2|I2) = N(x2|0, Σ2).
The link equation between x0 and x1 is
p(x0|I1, x1) = N(x0|A1x1, U1).

108
10 Multiscale Random Fields
Integrating out x1,
p(x0|I1) = N(x0|0, A1Σ1A′
1 + U1).
Moreover, by Bayes’ Theorem,
p(x1|I1, x0) = p(x1|I1)p(x0|I1, x1)
p(x0|I1)
= N(x1|0, Σ1)N(x0|A1x1, U1)
N(x0|0, A1Σ1A′
1 + U1)
.
Thus, the joint distribution of x0 and x1 conditional on the information G1 =
G0
+ I1 is
p(x0, x1|G1) = p(x1|G1, x0)p(x0|G1)
= p(x1|I1, x0)p(x0|G0)
= N(x1|0, Σ1)N(x0|A1x1, U1)
N(x0|0, A1Σ1A′
1 + U1)
N(x0|0, Q0).
Consider now the resolution level x2. From the link equation (10.11),
p(x1|I2, x2) = N(x1|A2x2, U2).
Thus, by Bayes’ Theorem,
p(x2|I2, x1) = p(x2|I2)p(x1|I2, x2)
p(x1|I2)
= N(x2|0, Σ2)N(x1|A2x2, U2)
N(x1|0, A2Σ2A′
2 + U2)
.
Therefore, the joint distribution of x0, x1, and x2 conditional on the in-
formation G2 = G1
+ I2 is
p(x0, x1, x2|G2) = p(x2|G2, x0, x1)p(x0, x1|G2)
= p(x2|I2, x1)p(x0, x1|G1)
= N(x2|0, Σ2)N(x1|A2x2, U2)
N(x1|0, A2Σ2A′
2 + U2)
× N(x1|0, Σ1)N(x0|A1x1, U1)
N(x0|0, A1Σ1A′
1 + U1)
× N(x0|0, Q0).
(10.13)
This three-level model is used in Chapter 16 for modeling 1-D permeability
ﬁelds.

10.5 Posterior Simulation
109
10.5 Posterior Simulation
The posterior distribution is explored by using a Markov chain Monte Carlo
procedure (Gamerman and Lopes 2006) that generates a sample from the
joint posterior density of the unknown quantities of the model. From this
sample, posterior summaries such as means, medians, variances, and credible
intervals can be computed through Monte Carlo integration. Section 10.5.1
describes the simulation of multiscale random ﬁelds, while Section 10.5.2
describes the simulation of the related parameters.
10.5.1 Simulation of Multiscale Random Fields
Simulation of multiscale random ﬁelds is necessary for the inference process
when part of the ﬁeld is observed and part is not or when these models
are used as priors for hidden processes. When the relationship between the
hidden process and the observations is nonlinear and nonlocal, as in the inverse
problem application presented in Chapter 16, simulation of the multiscale
random ﬁeld is performed using MCMC-based iterative methods. Here the
focus is on iterative simulation methods.
As the coarsest level x0 follows a Markov random ﬁeld a priori, its sim-
ulation is straightforward. In order to explore the joint distribution of the
random ﬁeld sites, single-site Metropolis steps are used. More speciﬁcally, the
proposal for x0k is simulated from
x∗
0k ∼N

x(old)
0k
, C0k/φ0k

,
where C0k = {τ0[α0 + h0k]}−1 and φ0k is adjusted to yield good acceptance
rates. The proposal is accepted with the usual Metropolis step acceptance
probability (Gamerman and Lopes, 2006).
The simulation of the lth level (l = 1, . . . , L −1) is performed by blocks
using a checkerboard pattern, with each block corresponding to one site of
the immediate coarser level. Let Bll−1,j and Rel−1,j be the black and white
sites, respectively, of level l corresponding to site (l −1, j). As simulation of
white and black sites is analogous, here the latter is presented.
The prior full conditional density for black sites at level l corresponding
to site (l −1, k) is
p(xBll−1,k|GL−1, x∼Bll−1,k, xl−1) ∝p(xl|Il, xl−1)
= p(xl−1|Il, xl)p(xl|Il)
p(xl−1|Il)
∝p(xl−1,k|Il, xDl−1,k)

j∈Bll−1,k
p(xlj|Il, xNlj)

110
10 Multiscale Random Fields
∝exp
⎧
⎪
⎨
⎪
⎩
−1
2δl
⎛
⎝xl−1,k −m−1
l

j∈Dl−1,k
xlj
⎞
⎠
2⎫
⎪
⎬
⎪
⎭

j∈Bll−1,k
exp

−
l
2Clj
(xlj −alj)2

,
(10.14)
where
Clj = [τl(αl + hlj)]−1
and
alj = τlClj
⎛
⎝αlµ +

i∈Nlj
glijxli
⎞
⎠.
The joint proposal for xBll−1,k is simulated as follows. The proposal for
each site in Bll−1,k is simulated independently from
x∗
lk ∼N

x(old)
lk
, Clk/φlk

,
where φik is a tuning parameter adjusted to yield good acceptance rates. The
joint proposal for xBll−1,k is accepted with Metropolis acceptance probability.
10.5.2 Parameter Updates
Here the simulation of the parameters and their prior speciﬁcation is con-
sidered. The parameters are assumed independent a priori with joint prior
density
p(µ)
L−1

l=0
p(αl)p(τl)
L−1

l=1
p(δl).
More speciﬁcally,
p(µ) = N(µ|mµ, s2
µ),
p(δl) = Ga(δl|0.5nδl, 0.5nδls2
δl),
p(τl) = Ga(τl|0.5nτl, 0.5nτls2
τl),
p(αl) ∝
⎡
⎣
nl−1

k=1
(λlk + αl)−2 −(nl −1)−1
,nl−1

k=1
(λlk + αl)−1
-2⎤
⎦
0.5
,
where this last expression is the reference prior derived by Ferreira and
de Oliveira (2007) for the spatial parameter of a PMRF.
The mean level µ is simulated with a Metropolis step. The acceptance
probability is computed with the help of Equation (10.12).
The simulation of δl, l = 1, . . . , L −1, is performed with a Metropolis-
Hastings step,

10.6 A Simulated Example
111
δ∗
l ∼U

δ(old)
l
/φδ, δ(old)
l
φδ

,
where φδ > 1 is a tuning parameter adjusted to yield good acceptance rates.
The parameters αl and τl, l = 0, . . . , L −1, are strongly correlated a
posteriori. In order to overcome the associated diﬃculties, αl and τl are jointly
simulated using individual Metropolis-Hastings steps,
α∗
l ∼U

α(old)
l
/φα, α(old)
l
φα

and
τ ∗
l ∼U

τ (old)
l
/φτ, τ (old)
l
φτ

.
The joint proposal (α∗
l , τ ∗
l ) is accepted with the appropriate Metropolis-
Hastings probability.
0.0
0.2
0.4
0.6
0.8
1.0
0.0
0.2
0.4
0.6
0.8
1.0
0.0
0.2
0.4
0.6
0.8
1.0
0.0
0.2
0.4
0.6
0.8
1.0
(a)
(b)
Fig. 10.3. Simulated multiscale random ﬁeld with parameters µ = 15.0, τ0 = 1.0,
α0 = 0.5, τ1 = 8.0, α1 = 1.0, and δ1 = 0.0016. (a) Coarse level; (b) ﬁne level.
10.6 A Simulated Example
Figure 10.3 presents a simulated multiscale random ﬁeld with two-levels of
resolution: a 16 × 16 coarse level and a 32 × 32 ﬁne level. Simulation of this
multiscale random ﬁeld was performed as discussed in Section 10.5.1. The
parameter values used to simulate this multiscale random ﬁeld were µ = 15.0,
τ0 = 1.0, α0 = 0.5, τ1 = 8.0, α1 = 1.0, and δ1 = 0.0016. The values of α0 and
α1 imply a strong spatial dependence at both the coarse level and the ﬁne
level. The value of τ0 leads to a reasonable variability at the coarse level, while
the value of τ1 leads to less diﬀerence between neighbors at the ﬁne level. The

112
10 Multiscale Random Fields
value of δ1 imposes a strong constraint on the ﬁne level, causing it to closely
follow the realized coarse level.
Note that the ﬁne level has a local behavior similar to that of Markov ran-
dom ﬁelds yet retains the coarse-level-induced global behavior. This global
behavior is analogous to the long memory type of behavior observed in mul-
tiscale time series models (Ferreira et al., 2006).
The parameters were estimated using the MCMC-based procedure pre-
sented in Section 10.5. Vague priors were used with mµ = 0, s2
µ = 104, and
nδ1 = nδ1s2
δ1 = nτ0 = nτ0s2
τ0 = nτ1 = nτ1s2
τ1 = 10−3. Table 10.1 presents some
posterior summaries showing that the estimation procedure works very well.
Table 10.1. Simulated multiscale random ﬁeld – Posterior summaries.
True value Mean Standard deviation
µ
15.0
15.024
0.053
τ0
1.0
1.066
0.123
α0
0.5
0.308
0.197
τ1
8.0
7.970
0.446
α1
1.0
0.955
0.123
δ1
0.0016
0.00161
0.00009
Chapter 16 discusses the use of multiscale random ﬁeld models as priors
for permeability ﬁelds.

11
Multiscale Time Series
11.1 Introduction
This chapter presents multiscale time series models that have been introduced
by Ferreira et al. (2006). These models couple standard linear models at diﬀer-
ent time scales with linear link equations between scales. As in the multiscale
random ﬁeld models presented in Chapter 10, Jeﬀrey’s rule of conditioning
is used to ensure that the processes at the diﬀerent levels are compatible.
This allows consistent modeling of time series at diﬀerent levels of resolution
(e.g., daily or monthly aggregates of ﬁnancial or meteorological data) and also
allows coherent combination of information across time scales.
Concerns about the temporal scales of resolution of time series date back
at least to Working (1960), who studied the eﬀect of aggregation of random-
walk processes. Since then, several authors have considered the use of data
sampled at a coarser level of resolution than the original time scale on which
the stochastic model is deﬁned; for example, Telser (1967), Amemiya and
Wu (1972), Palm and Nijman (1984), Drost and Nijman (1993), Schmidt and
Gamerman (1997), Hwang (2000), and Bollerslev and Wright (2000). Rather
than using models deﬁned at a ﬁne resolution and aggregated to coarser res-
olutions, Ferreira et al. (2006) have proposed a new class of multiscale time
series models built from coarse to ﬁne scales of resolution.
The coarse to ﬁne construction results in a class of models for time series
that has the capacity to emulate long memory processes. Formally, a long
memory process has autocorrelation function ρ(k) = ck2d−1, where c ̸= 0
and 0 < d < 0.5. That is, the decay of the autocorrelation function is geo-
metric, instead of exponential as for autoregressive processes. Thus, for a long
memory process, as ∞
k=1 ρ(k) = ∞, the spectral function approaches in-
ﬁnity in the limit when the frequency goes to zero. For references on long
memory processes, see Beran (1994) and Brockwell and Davis (1991). The
multiscale time series models of Ferreira et al. (2006) are built in a cascade
way from coarse to ﬁne levels of resolution. The coarser levels of resolution
will determine the large time scale behavior of the series, and the ﬁner levels

114
11 Multiscale Time Series
will determine the high-frequency behavior. Analogous to the construction of
long memory processes through the use of the inverse discrete wavelet trans-
form (Wornell, 1990), if an inﬁnite number of resolutions are used, then the
resulting process at the ﬁnest level is a long memory process. Usually a small
number of resolution levels, such as two or three, is enough to model the time
series of interest and to induce an approximate long memory process at the
ﬁnest time-resolution level.
Long memory is only one possible behavior of the models proposed by
Ferreira et al. (2006). These models are adequate for naturally multiscale
processes; that is, processes that exist and have diﬀerent dynamics at diﬀerent
resolution levels. Moreover, with a very parsimonious parameterization based
on a few parameters for each resolution, the induced process at the ﬁnest
resolution level exhibits a variety of autocorrelation structures. This is useful
when the process is naturally multiscale but data are observed only at the
ﬁnest scale; in this case, the model is used to induce a particular process at
this ﬁnest scale, resulting in what Ferreira et al. (2006) call Hidden Resolution
Models (HRMs). As there is a progressive correlated stochastic process at each
scale, the resulting multiscale class of models can be used in extrapolation and
forecasting.
Another useful feature of the multiscale time series models of Ferreira et al.
(2006) is the ability to combine information across levels of resolution. These
models are proper joint probability models for the process at the diﬀerent
levels of resolution. Thus, in the case of data observed at diﬀerent scales, the
models can be used to coherently integrate the information from the diﬀerent
scales. This is accomplished with standard probability calculus operations
such as marginalization and conditioning.
The remainder of this chapter is organized as follows. Section 11.2.1
presents the general framework for multiscale time series models (MSTSMs)
and HRMs with one coarse level and one ﬁne level. Section 11.2.2 presents
an example of an MSTSM and the corresponding HRM with autoregressive
processes of order 1 as building blocks. Section 11.2.3 shows the derivation,
for the general case, of the implied distribution at the ﬁne level; that is, the
Hidden Resolution Model. Section 11.3 presents several properties of HRMs.
Section 11.4 describes extensions to incorporate periodicities into the multi-
scale framework relevant for certain applications. Section 11.5 discusses issues
of inference and prediction. Three examples are presented in Section 11.6.
11.2 Model Construction
11.2.1 General Framework
Begin with a univariate time series xt, (t = 1, 2, . . .), following a speciﬁed
model. Generally, write x1:nx = (x1, . . . , xnx) for any integer nx > 0, and
denote by p(x1:nx) the density of the joint distribution of x1:nx. For example,

11.2 Model Construction
115
the xt could follow a standard linear stationary time series model, such as
an AR(1) model, that is completely speciﬁed; in that case, p(x1:nx) is the
implied stationary distribution for the set of nx values. In other examples,
p(x1:nx) could be a posterior predictive distribution arising from a dynamic
model conditioned on past observations (as in West and Harrison, 1997).
For a speciﬁed positive integer m, deﬁne the process ys indexed on
s = 1, 2, . . . by ys = m−1 m
i=1 x(s−1)m+i + us, where the us, (s = 1, 2, . . .),
are mutually uncorrelated zero-mean, normally distributed noise terms with
us ∼N(us|0, τ) for some between-level variance τ. The y values are the av-
erages of nonoverlapping groups of m consecutive x values, such as weekly
averages (m = 7) of daily data or annual averages (m = 12) of monthly
data, subject to the addition of noise or error terms u. Refer to m as the
coarsening window, xt as the ﬁne-level process, and ys as the coarse-level ag-
gregate process. Then, the marginal distribution for y1:ny is computed as
p(y1:ny) =

p(y1:ny|x1:nx)p(x1:nx)dx1:nx. The implied distribution of the
process at the coarse level is usually less tractable and more complex than
at the ﬁne level.
The basic idea underlying the multiscale construction, analogous to that of
Chapter 10, is to impose a simple process at the coarse level. This is interpreted
as a new piece of information G received after p(x1:nx) and p(y1:ny|x1:nx) are
deﬁned and that supersedes the prior information on which p(x1:nx) is based.
To be speciﬁc, suppose that the additional information G relevant to y has
as a consequence the revision of the distribution of y1:ny to q(y1:ny). That is
equivalent to the existence of an implicit likelihood function for y1:ny denoted
by l(y1:ny|G) and computed as l(y1:ny|G) ∝q(y1:ny)/p(y1:ny).
It is extremely important to note that p(x1:nx), q(y1:ny), and p(y1:ny|x1:nx)
may be inconsistent and generally will be. Consistency is restored by the
use of Jeﬀrey’s rule of conditioning to revise the ﬁne-scale model p(x1:nx).
In this way, the models are made consistent across the diﬀerent levels of
resolution. Diaconis and Zabell (1982) discuss the use and roles of Jeﬀrey’s
rule in Bayesian analysis. Loschi et al. (2002) use Jeﬀrey’s rule for inference
in the context of ﬁnancial time series. Good references on Jeﬀrey’s rule of
conditioning are Jeﬀrey (1992), Diaconis and Zabell (1982), and Shafer (1981).
Jeﬀrey’s rule of conditioning updates the ﬁne-level distribution by the formula
q(x1:nx) =

p(x1:nx|y1:ny)q(y1:ny)dy1:ny. If the two levels of resolution x1:nx
and y1:ny are observable, then the Multiscale Time Series Model (MSTSM) is
p(x1:nx|y1:ny)q(y1:ny). Conversely, if the coarse level y1:ny is an unobservable
latent process, then the implied process at the ﬁne level q(x1:nx) is called a
Hidden Resolution Model (HRM).
Section 11.2.2 presents an example using autoregressive processes of order
1 as building blocks for the construction of MSTSMs and HRMs.

116
11 Multiscale Time Series
11.2.2 Example – AR(1) Building Blocks
Suppose that the initial ﬁne-level model is a standard stationary linear AR(1)
model
xt = φxxt−1 + εt,
(11.1)
where εt, (t = 1, 2, . . .), is a sequence of mutually uncorrelated zero-mean, nor-
mally distributed innovations with εt ∼N(0, σ2
x) for some variance σ2
x. Then,
for all nx > 0, p(x1:nx) is the implied nx-dimensional stationary distribution
p(x1:nx) = N(x1:nx|0, Vx),
(11.2)
where 0 is the vector of nx zeros and Vx is the nx-square variance matrix
with i, j element σ2
xφ|i−j|
x
/(1 −φ2
x).
Suppose that the link between levels is described simply via the densities
p(y1:ny|x1:nx) (for all ny) implied by assuming that the ys are conditionally
independent and normally distributed with means m−1 m
i=1 x(s−1)m+i and
constant variance τ.
Fixing nx = nym, deﬁne the ny × nx matrix A such that E[y1:ny] =
Ax1:nx. Thus A is a sparse matrix whose nonzero elements are all 1/m; in
row i, the nonzero elements are those in columns (i −1)m + 1 to im. Then,
the link equation is deﬁned as
p(y1:ny|x1:nx) =
ny

s=1
N
/
ys
%%%%m−1
m

i=1
x(s−1)m+i, τ
0
= N(y1:ny|Ax1:nx, U),
(11.3)
where U = τI, with I as the ny-square identity matrix and between-levels
variance τ. It is useful to parameterize τ as a function of AVxA′, and the
parameterization τ = λ(AVxA′)11 works well. As the parameter λ has a
natural interpretation in terms of the relative increase in uncertainty at the
coarse level due to the lack of agreement with the ﬁne level, it is much easier
to establish a prior for λ than for τ.
Suppose that additional information about the coarse level y1:ny is now
received such that the revised model q(y1:ny) is a simple standard stationary
linear AR(1) model
ys = φyys−1 + ηs,
(11.4)
where ηs, (s = 1, 2, . . . , ), is a sequence of mutually uncorrelated zero-mean,
normally distributed innovations with variance σ2
y. Then, for all ny > 0,
q(y1:ny) is the implied ny-dimensional stationary distribution
q(y1:ny) = N(y1:ny|0, Qy),
(11.5)
where 0 is the vector of ny zeros and Qy is the ny-square variance matrix
with i, j element σ2
yφ|i−j|
y
/(1 −φ2
y).
Obviously, the densities p(y1:ny) and q(y1:ny) are not compatible. However,
viewing the information G as superseding the information on which the model

11.2 Model Construction
117
p(x1:nx) is based, Equation (11.5) must be adopted and p(x1:nx) has to be
updated accordingly. This is done using Jeﬀrey’s rule of conditioning to revise
the distribution of x1:nx. The application of Jeﬀrey’s rule assumes that the re-
vised conditional distribution of x1:nx given y1:ny, denoted by q(x1:nx|y1:ny),
is equal to the conditional distribution of x1:nx given y1:ny implied by Equa-
tions (11.2) and (11.3), denoted by p(x1:nx|y1:ny). As discussed in Chapter 10,
this assumption means that given y1:ny, x1:nx is independent of the new in-
formation that led to the revision of beliefs about y1:ny.
Section 11.2.3 shows that the resulting distribution q(x1:nx), the Hidden
Resolution Model, is also zero-mean normal, q(x1:nx) = N(x1:nx|0, Qx), with
covariance matrix Qx = Vx −B(W −Qy)B′, where W = AVxA′ + U and
B = VxA′W−1.
11.2.3 General Case – Implied Fine-Level Distribution
This section derives the revised distribution at the ﬁne level; that is, the Hid-
den Resolution Model. This development is analogous to that of Section 10.1
for the case µ = 0, and it is presented here for completeness.
Start by using Bayes’ Theorem in order to obtain the conditional distrib-
ution of x1:nx given y1:ny:
p(x1:nx|y1:ny) ∝p(x1:nx)p(y1:ny|x1:nx)
= N(x1:nx|0, Vx) N(y1:ny|Ax1:nx, U).
Therefore, by linear regression, x1:nx|y1:ny ∼N(By1:ny, Vx −BWB′), where
B = VxA′W−1 and W = AVxA′+U. As the distribution p(x1:nx) has mean
zero, the expected value of x1:nx is shrunk from the corresponding value of
y1:ny toward zero.
So, as q > 0 and p > 0, the generalized Jeﬀrey’s rule (Diaconis and Zabell,
1982) can be used to derive the Hidden Resolution Model:
q(x1:nx) =

p(x1:nx|y1:ny)q(y1:ny)dy1:ny
∝

N(x1:nx|By1:ny, Vx −BWB′)
N(y1:ny|0, Qy)dy1:ny.
(11.6)
Therefore, the resulting distribution q(x1:nx), the Hidden Resolution Model,
is also zero-mean normal,
q(x1:nx) = N(x1:nx|0, Qx),
(11.7)
with covariance matrix
Qx = Vx −B(W −Qy)B′,
(11.8)
where W = AVxA′ + U and B = VxA′W−1.

118
11 Multiscale Time Series
11.2.4 Example – MA(1) Building Blocks
Assume that the initial ﬁne-level model is an MA(1) process,
xt = εt + θxεt−1,
where the {εt} are i.i.d. N(0, σ2
ε). Then, x1:nx ∼N(0, Vx), where Vx is a
sparse matrix with all but three diagonals equal to zero. The main diagonal
elements are equal to (1 + θ2
x)σ2
ε, and the elements of the subdiagonals and
superdiagonals are equal to θxσ2
ε.
Consider the link equation
p(y1:ny|x1:nx) =
ny

s=1
N
/
ys
%%%%m−1
m

i=1
x(s−1)m+i, τ
0
= N(y1:ny|Ax1:nx, U),
(11.9)
where U = τI with I as the ny-square identity matrix and between-levels
variance τ.
Then, p(y1:ny) = N(y1:ny|0, AVxA′ + U). Note that as Vx is a sparse
matrix and U is a diagonal matrix, then W = AVxA′ +U is a sparse matrix,
a fact that can be used to accelerate computations when using MA(1) building
blocks.
In order to determine the implied process at the coarse level, rewrite ys as
a function of the ε’s:
ys = m−1
m

i=1
x(s−1)m+i + us
= m−1
m

i=1
(ε(s−1)m+i + θxε(s−1)m+i−1) + us
= m−1
m

i=1
ε(s−1)m+i + m−1θx
m−1

i=0
ε(s−1)m+i + us
= m−1(1 + θx)
m−1

i=1
ε(s−1)m+i + m−1(εsm + θxε(s−1)m) + us.
Deﬁne ˜us = us + m−1(1 + θx) m−1
i=1 ε(s−1)m+i and ˜εs = m−1εsm. Then
V (˜us) = τ + m−2(m −1)(1 + θx)2σ2
ε, Cov(˜us, ˜us−1) = 0, V (˜εs) = m−2σ2
ε,
and Cov(˜εs, ˜εs−1) = 0. Thus, it is possible to rewrite ys as
ys = ˜us + ˜εs + θx˜εs−1.
(11.10)
Then,
V (ys) = τ + (m −1)(1 + θx)2
m2
σ2
ε + m−2(1 + θ2
x)σ2
ε,
(11.11)

11.3 Properties of Hidden Resolution Models
119
Cov(ys, ys−1) = E(ysys−1) = θxE(˜ε2
s−1) = m−2θxσ2
ε,
(11.12)
and Cov(ys, ys−k) = 0, ∀k ≥2. Therefore, ys follows an MA(1) process with
parameters that depend on θx and σ2
ε.
Now, revise the distribution of y1:ny to an MA(1) process with parameters
θy and σ2
y. Using Jeﬀrey’s rule to revise the distribution of x1:nx, one obtains
the Hidden Resolution Model of x1:nx given by the general Equations (11.7)
and (11.8). Section 11.3.2 studies in some detail the behavior of autocorrela-
tion functions of HRMs when the building blocks are MA(1) processes.
11.2.5 HRMs with ARMA Building Blocks
Sections 11.2.2 and 11.2.4 presented in detail the construction of Hidden Res-
olution Models with autoregressive and moving average processes of order
1 as building blocks. This section brieﬂy discusses the implications of using
autoregressive moving average (ARMA) processes as building blocks.
From a general viewpoint, the construction of MSTSMs and HRMs has
three ingredients: the initial process at the ﬁne level, the link equation, and
the revised process at the coarse level. With these three ingredients, Jeﬀrey’s
rule can be used to derive the Hidden Resolution Model. Therefore, the con-
struction put forward in this chapter is quite general and can be used with
any well-behaved types of processes as building blocks. In particular, natural
choices for building blocks are stationary and invertible ARMA processes.
The main implications of the use of ARMA processes as building blocks are
related to the properties of the resulting HRM and to the particular methods
necessary to estimate the parameters of the model and perform forecasts for
future observations. Section 11.3.1 studies the limiting behavior of the covari-
ance structure of HRMs for fairly general building blocks including ARMA
processes. Properties of the updated ﬁne-level process with AR(1) only, MA(1)
only, and combinations of AR(1) and MA(1) building blocks are discussed in
Section 11.3. These building blocks provide a very rich collection of Hidden
Resolution Models, as shown in Figures 11.3 to 11.18. Properties of Hidden
Resolution Models constructed with more general ARMA building blocks can
be studied along the same lines as in Section 11.3 and will not be consid-
ered here. With respect to estimation and forecasting, when using general
ARMA building blocks, the general idea is the same as the idea presented in
Section 11.5 for the two-level model with AR(1) building blocks: the factor-
ization of p(x1:nx|y1:ny) and the simple form of q(y1:ny) are used to speed up
the computations.
11.3 Properties of Hidden Resolution Models
Here we discuss some interesting properties of Hidden Resolution Models by
analyzing their autocorrelation functions. In Section 11.3.1, limiting cases of

120
11 Multiscale Time Series
the Hidden Resolution Model are considered, and in Section 11.3.2 autocor-
relation functions for several Hidden Resolution Models are discussed. As a
by-product of the study of the autocorrelation functions, the parameters of
Hidden Resolution Models are given suitable interpretations.
11.3.1 Limiting Behavior
Some properties of Hidden Resolution Models for limiting cases are consid-
ered here. The focus here is on the behavior of some interesting functions of
the covariance matrix Qx, such as the autocorrelation function and AQxA′.
All the theorems in this section are valid for Hidden Resolution Models con-
structed with the link equation (11.3) and stationary and invertible processes
as building blocks.
Theorem 11.1 states that when τ →0, the covariance structure of a coars-
ened version of an HRM process converges to the covariance structure of the
hidden coarse-level process.
Theorem 11.1. limτ→0 AQxA′ = Qy.
Proof.
lim
τ→0 AQxA′ = A(lim
τ→0 Qx)A′
= A[Vx −VxA′(AVxA′)−1AVx + VxA′(AVxA′)−1
Qy(AVxA′)−1AVx]A′
= AVxA′ −AVxA′(AVxA′)−1AVxA′
+AVxA′(AVxA′)−1Qy(AVxA′)−1AVxA′
= Qy.
□
Theorem 11.2 states that when τ →∞, the covariance structure of the
HRM process converges to the original covariance structure.
Theorem 11.2. limτ→∞Qx = Vx.
Proof. Note that limτ→∞W−1 = limτ→∞(AVxA′ + τI)−1 = 0. Therefore,
lim
τ→∞Qx = lim
τ→∞Vx −VxA′W−1AVx + VxA′W−1QyW−1AVx
= Vx.
□
Theorem 11.3. Let us consider two hidden resolution processes with all pa-
rameters equal except σ2
x and σ2
y. If the ratio between σ2
x and σ2
y is the same
for the two processes, then they have the same autocorrelation function.

11.3 Properties of Hidden Resolution Models
121
Proof. Redeﬁne τ = κσ2
x, σ2
y = γσ2
x, Ψx = Vx/σ2
x and Ψy = Qy/σ2
y. Then
B = VxA′W−1 = σ2
xΨxA′(σ2
xAΨxA′ + κσ2
xI)−1 = ΨxA′(AΨxA′ + κI)−1
Thus, B does not depend on σ2
x. Moreover:
Qx = σ2
xΨx −B[σ2
x(AΨxA′ + κI) −γσ2
xΨy]B′
= σ2
x{Ψx −B[(AΨxA′ + κI) −γΨy]B′}.
Hence, each element of Qx is proportional to σ2
x. Consequently, the correlation
matrix of x1:nx does not depend on σ2
x and σ2
y in the new reparameterization.
Therefore, the correlation matrix depends on σ2
x and σ2
y only through γ =
σ2
y/σ2
x.
□
Theorem 11.4 presents an identiﬁability problem: when γ, the ratio be-
tween σ2
y and σ2
x, goes to inﬁnity at a rate proportional to the square of κ,
the ratio between τ and σ2
x, the covariance matrix Qx converges to a constant
positive deﬁnite matrix.
Theorem 11.4. limκ→∞,γ→∞,γ/κ2=c Qx = C, where det(C) > 0.
Proof. Let us use the same reparameterization used in the proof of Theorem
11.3. In order to simplify notation, in this proof “lim” means the limit as κ
and γ tend to inﬁnity with γ/κ2 held ﬁxed. First, let us consider the behavior
of B(AΨxA′ + κI)B′:
lim B(AΨxA′ + κI)B′ = lim ΨxA′κ−1I(AΨxA′ + κI)κ−1IAΨx
= 0.
Therefore,
lim Qx = σ2
x lim{Ψx −B[(AΨxA′ + κI) −γΨy]B′}
= σ2
xΨx + σ2
x lim ΨxA′κ−1γΨyκ−1AΨx
= σ2
xΨx + cσ2
xΨxA′ΨyAΨx = C.
As Ψx and Ψy are positive deﬁnite, then det(C) > 0.
□
In order to illustrate Theorem 11.4, Figure 11.1 shows as dotted lines the
autocorrelation functions for φx = 0.5, 0.9, 0.99, for λ = 1, 5, 10, 20, 100, 1000,
10000, σ2
y = 5λ2, φy = 0.0, σ2
x = 1.0, and m = 12. As λ and σ2
y increase with
σ2
y/λ2 held constant, the autocorrelation function increases and converges to
the limiting autocorrelation function represented by the solid line and depicted
in Theorem 11.4.
Theorems 11.2 and 11.4 have important consequences that point to the
right speciﬁcation of the priors for the parameters of HRMs. In order to il-
lustrate this point, Figure 11.2 shows diﬀerent representations of the like-
lihood function for λ and σ2
y, the other parameters kept constant at their
posterior means, for the Fraser River application that will be presented in

122
11 Multiscale Time Series
0
20
40
60
80
100
−0.2
0
0.2
0.4
0.6
0.8
1
0
20
40
60
80
100
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
0
10
20
30
40
50
60
70
80
90
100
0
0.2
0.4
0.6
0.8
1
(a)
(b)
(c)
Fig. 11.1. Illustration of Theorem 11.4. Dotted lines are HRM autocorrelation
functions with diﬀerent values of λ (1, 5, 10, 20, 100, 1000, 10000) and σ2
y = 5λ2. As
λ and σ2
y increase with σ2
y/λ held constant, the autocorrelation function converges
to the autocorrelation function represented by the solid line. In all ﬁgures, φy = 0.0,
σ2
x = 1.0, and m = 12. Panels (a), (b), and (c) correspond to diﬀerent values of φx:
(a) 0.5; (b) 0.9; (c) 0.99.
Section 11.6.1. The behavior of the likelihood is very interesting in two as-
pects. First, as can be seen in Figures 11.2 (a) and (b), when λ approaches
inﬁnity and σ2
y is kept constant, the likelihood does not vanish but becomes
constant, equal to the likelihood of the original ARMA model p(x). Second,
as can be seen in Figures 11.2 (a) and (d), when λ and σ2
y approach inﬁnity
such that σ2
y/λ2 is constant, the likelihood function again does not vanish but
approaches a constant value greater than zero. Hence, if the prior distribu-
tion for λ is improper, then its posterior distribution will also be improper.
Nonetheless, as indicated in Figures 11.2(c) and 11.2(d), there is information
in the likelihood function about the value of λ. Therefore, it is necessary to
carefully assign a proper prior distribution for λ. In Section 11.3.2, a graphical
study shows that the autocorrelation function is almost the same for λ = 10
and for λ →∞. Thus, assigning a proper prior is recommended for λ, with
positive mass in the interval (0, 10) and zero mass outside of the interval.
11.3.2 Autocorrelation Functions
This section analyzes plots of several possible autocorrelation functions to
elucidate some interesting properties of Hidden Resolution Models. In addi-
tion, some of these properties are related to the analytical results obtained in
Section 11.3.1 about the limiting behavior of the autocorrelation functions.
As a by-product of the study of the autocorrelation functions, the parameters
of Hidden Resolution Models are given suitable interpretations.
AR(1) Building Blocks
Let us now consider HRMs with an initial AR(1) process at the ﬁne level
and a revised AR(1) process at the coarse level. An interesting feature of

11.3 Properties of Hidden Resolution Models
123
-4
-2
0
2
4
-6
-4
-2
0
2
900
900
925
925
940
940
946
946
948
948
950
954
log(  )
     λ
log(    )
     σ  
            y
            2
-4
-2
 0
2
4
-6
-4
-2
 0
2
750
800
850
900
950
1000
log(  )
     λ
log(    )
     σ  
2
y
(a)
(b)
-4
-2
 0
2
4
-6
-4
-2
 0
2
 0
2e27
4e27
6e27
8e27
log(  )
     λ
log(    )
     σ  
2
y
-4
-2
 0
2
4
-6
-4
-2
 0
2
 0
2e27
4e27
6e27
8e27
log(  )
     λ
log(    )
     σ  
2
y
(c)
(d)
Fig. 11.2. Likelihood function for λ and σ2
y: (a) log-likelihood contour plot; (b) log-
likelihood; (c) likelihood; (d) likelihood from another perspective.
these models is the emulation of long memory processes (for references on
long memory processes, see Beran, 1994, or Brockwell and Davis, 1991). As
can be seen in Figure 11.3, the parameter φy controls the rate of decay of
the autocorrelation function, which shows some persistence when the value of
φy increases. When the number of hidden resolution levels is ﬁnite, HRMs do
not have the long memory property but can emulate long memory processes.
Nonetheless, their advantage over actual long memory models is interpretabil-
ity; that is, the long memory type of behavior is explicitly modeled as a result
of a high autocorrelation in the hidden coarse level of the hierarchy. Moreover,
Figures 11.3 to 11.6 show that, when compared with traditional long memory
models, Hidden Resolution Models provide richer autocorrelation structures.

124
11 Multiscale Time Series
0
20
40
60
80
100
−0.1
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
0
20
40
60
80
100
−0.1
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
0
20
40
60
80
100
−0.1
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
(a)
(b)
(c)
Fig. 11.3. AR(1) building blocks. Autocorrelation functions varying φy (the au-
toregressive coeﬃcient on the coarse scale). Parameters kept constant: φx = 0.9,
σ2
x = 1, σ2
y = 1, λ = 0.1, and m = 12. Multiscale model (solid line); autoregressive
model (dotted line). Particular values of φy: (a) 0.0; (b) 0.5; (c) 0.9.
0
20
40
60
80
100
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
0
20
40
60
80
100
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
0
20
40
60
80
100
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
(a)
(b)
(c)
Fig. 11.4. AR(1) building blocks. Autocorrelation functions varying λ (the lack
of agreement between coarse and ﬁne levels). Parameters kept constant: φx = 0.9,
σ2
x = 1, φy = 0.9, σ2
y = 1, and m = 12. Multiscale model (solid line); autoregressive
model (dotted line). Particular values of λ: (a) 0.01; (b) 1.0; (c) 10.0.
The values of λ control how much the generator mechanism of the coarse
level inﬂuences the behavior of the ﬁne level. Thus, as can be seen in
Figure 11.4, the decay of the autocorrelation function also depends on λ.
As shown in Section 11.3.1, the limit of the autocorrelation function when
λ approaches inﬁnity is the autocorrelation function of the original autore-
gressive process with coeﬃcient φx. Actually, as can be seen in Figure 11.4,
the autocorrelation functions of the HRM and original autoregressive process
are already very close when λ = 10. When λ gets smaller, the model departs
progressively further from the AR(1) model, as can be observed from the
autocorrelation functions for λ = 1 and λ = 0.01.
As shown in Section 11.3.1, the asymptotic behavior of the likelihood func-
tion when λ approaches inﬁnity is a key feature of the model and has to be
considered very carefully. When λ approaches inﬁnity, the likelihood function

11.3 Properties of Hidden Resolution Models
125
0
20
40
60
80
100
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
0
20
40
60
80
100
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
0
20
40
60
80
100
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
(a)
(b)
(c)
Fig. 11.5. AR(1) building blocks. Autocorrelation functions varying φx (the autore-
gressive coeﬃcient on the ﬁne scale). Parameters kept constant: σ2
x = 1, φy = 0.9,
σ2
y = 1, λ = 0.1, and m = 12. Multiscale model (solid line); autoregressive model
(dotted line). Particular values of φx: (a) 0.0; (b) 0.5; (c) 0.9.
0
20
40
60
80
100
−0.2
0
0.2
0.4
0.6
0.8
1
0
20
40
60
80
100
−0.2
0
0.2
0.4
0.6
0.8
1
0
20
40
60
80
100
−0.2
0
0.2
0.4
0.6
0.8
1
(a)
(b)
(c)
Fig. 11.6. AR(1) building blocks. Autocorrelation functions varying σ2
x (the vari-
ance of the error on the ﬁne scale). Parameters kept constant: φx = 0.9, φy = 0.9,
σ2
y = 1, λ = 0.1, and m = 12. Multiscale model (solid line); autoregressive model
(dotted line). Particular values of σ2
x: (a) 0.01; (b) 1; (c) 100.
approaches a constant equal to the likelihood function of an AR(1) process,
implying that the use of an improper prior for λ would lead to an improper
posterior. In addition, as shown in Figure 11.4, λ = 10 and λ →∞provide
almost the same autocorrelation function for the ﬁne level. Therefore, a so-
lution for the impropriety is to deﬁne a prior for λ truncated to the interval
(0, 10).
Another interesting feature of Hidden Resolution Models is the existence of
a blocking eﬀect that depends on m and φx. More speciﬁcally, when φx = 0.0
the autocorrelations are constant by blocks of length m. Additionally, as can
be seen in Figure 11.5, when φx increases the blocking eﬀect is progressively
reduced. Therefore, φx can be interpreted as the parameter that controls the
smoothness of the autocorrelation function.

126
11 Multiscale Time Series
(a)
(b)
(c)
Fig. 11.7. MA(1) building blocks. Autocorrelation functions varying θy. Parameters
kept constant: θx = 0.9, σ2
x = 1, σ2
y = 1, λ = 0.1, and m = 12. Multiscale model
(solid line); moving average model (dotted line). Particular values of θy: (a) 0.0;
(b) 0.5; (c) 0.9.
(a)
(b)
(c)
Fig. 11.8. MA(1) building blocks. Autocorrelation functions varying λ. Parameters
kept constant: θx = 0.9, σ2
x = 1, θy = 0.9, σ2
y = 1, and m = 12. Multiscale model
(solid line); moving average model (dotted line). Particular values of λ: (a) 0.01;
(b) 1.0; (c) 10.0.
The decay of the autocorrelation function is also controlled by the para-
meters σ2
x and σ2
y. As shown in Section 11.3.1, the autocorrelation function
depends on σ2
x and σ2
y only through σ2
x/σ2
y. Therefore, it is necessary to study
only the autocorrelation function for σ2
x or σ2
y. Figure 11.6 depicts the auto-
correlation function for σ2
x assuming values 0.01, 1, and 100. It is interesting
to note that the decay of the autocorrelation function for the HRM can be
faster than the decay for the original AR(1) process.
MA(1) Building Blocks
Let us now consider HRMs with an initial MA(1) process at the ﬁne level and
a revised MA(1) process at the coarse level. Some autocorrelation functions
for these models are presented in Figures 11.7 to 11.10. For these models,

11.3 Properties of Hidden Resolution Models
127
(a)
(b)
(c)
Fig. 11.9. MA(1) building blocks. Autocorrelation functions varying θx. Parameters
kept constant: σ2
x = 1, θy = 0.9, σ2
y = 1, λ = 0.1, and m = 12. Multiscale model
(solid line); moving average model (dotted line). Particular values of θx: (a) 0; (b) 0.5;
(c) 0.9.
(a)
(b)
(c)
Fig. 11.10. MA(1) building blocks. Autocorrelation functions varying σ2
x. Parame-
ters kept constant: θx = 0.9, θy = 0.9, σ2
y = 1, λ = 0.1, and m = 12. Multiscale
model (solid line); moving average model (dotted line). Particular values of σ2
x:
(a) 0.01; (b) 1; (c) 100.
the autocorrelation functions behave as step functions (θx = 0) or variations
of step functions (θx > 0). Qualitatively, the autocorrelation functions for
diﬀerent parameter values are not very diﬀerent from each other. Reﬂecting
the MA(1) behavior at the coarse level, the autocorrelation functions vanish
for lags greater than 3m. From Figure 11.7, it can be seen that θy is related to
the size of the autocorrelation function. As can be seen in Figure 11.8, λ can be
interpreted as how close the HRM process is to the original MA(1) ﬁne process.
From Figure 11.9, θx is related to how fast the change in autocorrelation is
for times closer to the block limits. Figure 11.10 shows that the size of the
autocorrelation function also depends on the value of σ2
x.

128
11 Multiscale Time Series
(a)
(b)
(c)
Fig. 11.11. AR(1) coarse level, MA(1) ﬁne level. Autocorrelation functions varying
φy. Parameters kept constant: θx = 0.9, σ2
x = 1, σ2
y = 1, λ = 0.1, and m = 12.
Multiscale model (solid line); moving average model (dotted line). Particular values
of φy: (a) 0.0; (b) 0.5; (c) 0.9.
(a)
(b)
(c)
Fig. 11.12. AR(1) coarse level, MA(1) ﬁne level. Autocorrelation functions varying
λ. Parameters kept constant: θx = 0.9, σ2
x = 1, φy = 0.9, σ2
y = 1, and m = 12.
Multiscale model (solid line); moving average model (dotted line). Particular values
of λ: (a) 0.01; (b) 1.0; (c) 10.0.
AR(1) at the Coarse Level and MA(1) at the Fine Level
Let us now consider HRMs with an initial MA(1) process at the ﬁne level
and a revised AR(1) process at the coarse level. Some autocorrelation func-
tions for these models are presented in Figures 11.11 to 11.14. As in the case of
MA(1) building blocks, the autocorrelation functions behave as step functions
(θx = 0) or variations of step functions (θx > 0). Moreover, the autocorrela-
tion functions are similar for diﬀerent parameter values. Reﬂecting the AR(1)
process at the coarse level, the decay of the autocorrelation functions is slow
for high values of φy. Interpretations of θx, σ2
x, φy, and λ are the same as for
the models with only AR(1) or only MA(1) building blocks.

11.3 Properties of Hidden Resolution Models
129
(a)
(b)
(c)
Fig. 11.13. AR(1) coarse level, MA(1) ﬁne level. Autocorrelation functions varying
θx. Parameters kept constant: σ2
x = 1, φy = 0.9, σ2
y = 1, λ = 0.1, and m = 12.
Multiscale model (solid line); moving average model (dotted line). Particular values
of θx: (a) 0; (b) 0.5; (c) 0.9.
(a)
(b)
(c)
Fig. 11.14. AR(1) coarse level, MA(1) ﬁne level. Autocorrelation functions varying
σ2
x. Parameters kept constant: θx = 0.9, φy = 0.9, σ2
y = 1, λ = 0.1, and m = 12.
Multiscale model (solid line); moving average model (dotted line). Particular values
of σ2
x: (a) 0.01; (b) 1; (c) 100.
MA(1) at the Coarse Level and AR(1) at the Fine Level
Let us now consider HRMs with an initial AR(1) process at the ﬁne level and a
revised MA(1) process at the coarse level. Figures 11.15 to 11.18 depict auto-
correlation functions for some of these models. This class of models provides
several interesting autocorrelation functions. The autocorrelation functions
are reasonably smooth for typical values of φx and die oﬀfor lags greater
than 4m. Moreover, they can oscillate smoothly between positive and nega-
tive values. For example, in Figure 11.18, we can see that when φx = 0.9,
θy = 0.9, σ2
x = 0.01, σ2
y = 1, and λ = 0.1, the autocorrelation function ini-
tially falls slowly, then falls very quickly, becoming negative, and stabilizes at
zero around lag 4m. This autocorrelation function could represent, for exam-
ple, a process that is being monitored to be kept at a given nominal level:
it takes some time for people to realize the need for intervention; after the

130
11 Multiscale Time Series
intervention, the process converges to the nominal level and slightly passes it;
and ﬁnally (and hopefully) the process stabilizes at the nominal level.
0
20
40
60
80
100
−0.1
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
0
20
40
60
80
100
−0.1
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
0
20
40
60
80
100
−0.1
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
(a)
(b)
(c)
Fig. 11.15. MA(1) coarse level, AR(1) ﬁne level. Autocorrelation functions varying
θy. Parameters kept constant: φx = 0.9, σ2
x = 1, σ2
y = 1, λ = 0.1, and m = 12.
Multiscale model (solid line); autoregressive model (dotted line). Particular values
of θy: (a) 0.0; (b) 0.5; (c) 0.9.
0
20
40
60
80
100
−0.1
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
0
20
40
60
80
100
−0.1
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
0
20
40
60
80
100
−0.1
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
(a)
(b)
(c)
Fig. 11.16. MA(1) coarse level, AR(1) ﬁne level. Autocorrelation functions varying
λ. Parameters kept constant: φx = 0.9, σ2
x = 1, θy = 0.9, σ2
y = 1, and m = 12.
Multiscale model (solid line); autoregressive model (dotted line). Particular values
of λ: (a) 0.01; (b) 1.0; (c) 10.0.
11.4 Incorporating Periodicities
Periodicities are incorporated in MSTSMs and HRMs at the ﬁne level by
including regressors corresponding to harmonics with a cycle length equal to
the coarsening window. As harmonics are sine and cosine functions with mean

11.4 Incorporating Periodicities
131
0
20
40
60
80
100
−0.1
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
0
20
40
60
80
100
−0.1
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
0
20
40
60
80
100
−0.1
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
(a)
(b)
(c)
Fig. 11.17. MA(1) coarse level, AR(1) ﬁne level. Autocorrelation functions varying
φx. Parameters kept constant: σ2
x = 1, θy = 0.9, σ2
y = 1, λ = 0.1, and m = 12.
Multiscale model (solid line); autoregressive model (dotted line). Particular values
of φx: (a) 0; (b) 0.5; (c) 0.9.
0
20
40
60
80
100
−0.2
0
0.2
0.4
0.6
0.8
1
0
20
40
60
80
100
−0.2
0
0.2
0.4
0.6
0.8
1
0
20
40
60
80
100
−0.2
0
0.2
0.4
0.6
0.8
1
(a)
(b)
(c)
Fig. 11.18. MA(1) coarse level, AR(1) ﬁne level. Autocorrelation functions varying
σ2
x. Parameters kept constant: φx = 0.9, θy = 0.9, σ2
y = 1, λ = 0.1, and m = 12.
Multiscale model (solid line); autoregressive model (dotted line). Particular values
of σ2
x: (a) 0.01; (b) 1; (c) 100.
over the cycle length equal to zero, the coarsening operation eliminates the
periodic pattern.
The construction of the model is the same as in Section 11.2.2, except
that Equation (11.2) is substituted by x1:nx ∼N(x1:nx|µx, Vx) where µx =
Zβ is a periodic vector with period equal to the coarsening window m, Vx
is the covariance matrix of the ﬁne-level process, and Z is a design matrix
corresponding to the harmonics. It is easy to show that the updated marginal
distribution of x1:nx is
q(x1:nx) = N(x1:nx|Zβ, Vx −B(W −Qy)B′),
where B = VxA′W−1 and W = AVxA′+U are the same as in Section 11.2.2.
Sections 11.6.1 and 11.6.3 present examples of the application of HRMs
and MSTSMs to time series in the presence of periodicities.

132
11 Multiscale Time Series
11.5 Inference and Prediction
11.5.1 Posterior Simulation
The Bayesian estimation of the parameters of MSTSMs and HRMs cannot be
performed analytically because the posterior distribution of the parameters
is rather complicated due to nonlinearities. In order to explore the posterior
distribution, an algorithm based on Markov chain Monte Carlo (MCMC) tech-
niques is used to generate a sample from the posterior. This sample is then
used to estimate summaries of the posterior distribution such as posterior
means, standard deviations, and credible intervals.
A major aspect of the estimation for MSTSMs and HRMs is that, condi-
tional on the hidden coarse level, the parameters corresponding to coarse and
ﬁne levels are independent. Thus, the inclusion of the generation of the hidden
coarse level dramatically facilitates the implementation of a Gibbs sampler to
explore the posterior distribution.
The following priors are assumed for the parameters: φy ∼N(mφy, Sφy),
σ2
y ∼IG(νσy/2, νσysσy/2), φx ∼TrN(−1.0,1.0)(mφx, Sφx), σ2
x ∼IG(νσx/2,
νσxsσx/2), λ ∼TrIG(0,10)(νλ/2, νλsλ/2), where TrN(a,b) and TrIG(a,b)
denote respectively the normal and gamma distributions truncated to the
interval (a, b). Then, the joint distribution of all involved random quantities
is
p(x1:nx|y1:ny, φx, σ2
x, λ)q(y1:ny|φy, σ2
y)p(φy)p(σ2
y)p(φx)p(σ2
x)p(λ).
(11.13)
From the joint distribution given by Equation (11.13), it is easy to verify that
conditional on the hidden coarse level, the generation of the parameters cor-
responding to diﬀerent levels can be done separately. Thus, as the coarse-level
process is generally simple, techniques already available in the literature can
be used to generate the coarse-level parameters. For example, if the coarse
level follows an ARMA process, then the coarse-level parameters can be gen-
erated with the procedure proposed by Chib and Greenberg (1994).
The generation of the parameters of the ﬁne level and link equation is not
so trivial because, in general, the full conditional distributions are not avail-
able in closed form for sampling. To overcome this problem, these parameters
are simulated with Metropolis-Hastings proposals. The following theorem sim-
pliﬁes and accelerates the computations for the simulation of (φx, σ2
x, λ):
Theorem 11.5.
p(φx, σ2
x, λ|x1:nx, y1:ny) ∝p(φx, σ2
x)p(x1:nx|φx, σ2
x)p(λ)
×p(y1:ny|x1:nx, φx, σ2
x, λ)
p(y1:ny|φx, σ2x, λ)
,
where

11.5 Inference and Prediction
133
p(y1:ny|x1:nx, φx, σ2
x, λ) =
ny

s=1
N
/
ys
%%%%m−1
m

i=1
x(s−1)m+i, λ(A′VxA)11
0
and
p(y1:ny|φx, σ2
x, λ) = N(y1:ny|0, A′VxA + U).
Proof.
Since the conditional distribution of x1:nx given (y1:ny, φx, σ2
x, λ) is not
revised by Jeﬀrey’s rule, then
q(x1:nx|y1:ny, φx, σ2
x, λ) = p(x1:nx|y1:ny, φx, σ2
x, λ)
= p(x1:nx|φx, σ2
x, λ)p(y1:ny|x1:nx, φx, σ2
x, λ)
p(y1:ny|φx, σ2x, λ)
.
The result follows on application of Bayes’ Theorem.
□
Note that p(x1:nx|φx, σ2
x, λ) and p(y1:ny|x1:nx, φx, σ2
x, λ) are easy to com-
pute and that the computation of p(y1:ny|φx, σ2
x, λ) can be done very eﬃ-
ciently by the Kalman ﬁlter (for a reference on the Kalman ﬁlter, see West
and Harrison, 1997).
The generation of proposals for φx, σ2
x, and λ is performed through
Metropolis-Hastings steps. After the generation of each proposal, Theo-
rem 11.5 is used to compute its acceptance probability. More speciﬁcally, the
proposal for σ2
x is generated from U(σ2
x|σ2 (old)
x
/δσx, σ2 (old)
x
δσx), where δσx
has to be tuned to yield a reasonable acceptance rate.
The proposal for φx is simulated from U

φx|max(−1.0, φ(old)
x
−δφx),
min(10.0, φ(old)
x
+ δφx)

, where δφx has to be tuned to yield a reasonable
acceptance rate.
In the case of MSTSMs, the generation of λ is easily performed. Conversely,
in the case of HRMs, the hidden coarse level y1:ny and the parameter λ are
highly correlated a posteriori. Thus, y1:ny and λ are jointly simulated in order
to improve the mixing of the Gibbs sampler. First, a proposal λ(new) for λ is
generated from U(λ| max(0, λ(old) −δλ), min(1, λ(old) + δλ)). Then, a proposal
for y1:ny is simulated from its full conditional on λ(new). The joint proposal
is accepted or rejected with the appropriate Metropolis-Hastings acceptance
probability.
11.5.2 Forecasting
In order to compute forecasts, it is suﬃcient to obtain a sample from the
predictive distribution of the future observations at the diﬀerent levels. Point
and interval forecasts can then be derived from this sample.
A two-stage procedure is used to generate each realization of the sample
from the predictive distribution. First, a future realization of the hidden coarse

134
11 Multiscale Time Series
level is simulated conditional on the past. After that, a realization of the ﬁne
level is simulated conditional on the past and on the realization of the coarse
level. The following two theorems show that it is possible to sample from the
coarse- and ﬁne-level predictive distributions in a very eﬃcient way.
The following theorem is very useful for the generation of predictions of
the coarse level. The theorem states that the one-step-ahead predictive distri-
bution at the coarse level depends on the whole past at the coarse level but
depends only on the last observation at the ﬁne level.
Theorem 11.6. q(yny|y1:(ny−1), x1:(nx−m)) = q(yny|y1:(ny−1), xnx−m).
Proof.
q(ys|y1:s−1, x1:[m(s−1)]) ∝

q(y1:s)p(x1:ms|y1:s)dx(ms−m+1):ms
∝q(ys|ys−1)
 p(x1:ms)p(y1:s|x1:ms)
p(y1:s)
dx(ms−m+1):ms
∝q(ys|ys−1)
p(y1:s)

p(x(ms−m+1):ms|xm(s−1))
× p(ys|x(ms−m+1):ms)dx(ms−m+1):ms
∝
q(ys|ys−1)
p(ys|y1:(s−1))p(ys|xm(s−1)).
□
In practice, the dependence on the past coarse level falls reasonably quickly
with time.
The following theorem is important because it simpliﬁes the task of fore-
casting the ﬁne level when the future coarse level is known:
Theorem 11.7.
p(x(nx−m+1):nx|y1:ny, x1:(nx−m)) = p(x(nx−m+1):nx|yny, xnx−m).
Proof.
Using the fact that q(x1:nx|y1:ny) = p(x1:nx|y1:ny), the conditional dis-
tribution of the ﬁne level given the coarse level is not revised by Jeﬀrey’s
rule:
q(x1:nx|y1:ny) = p(x1:nx|y1:ny) ∝p(x1:nx)p(y1:ny|x1:nx)
∝p(x1)
	 nx

i=2
p(xi|xi−1)

 ⎡
⎣
ny

j=1
p(yj|x(mj−m+1):(mj))
⎤
⎦.
Therefore

11.5 Inference and Prediction
135
p(x(nx−m+1):nx|y1:ny, x1:(nx−m)) ∝p(x1:nx|y1:ny)
∝p(yny|x(nx−m+1):nx)
nx

i=nx−m+1
p(xi|xi−1)
∝p(x(nx−m+1):nx|yny, xnx−m).
□
Then, the following theorem follows from Theorem 11.7 by mathematical
induction.
Theorem 11.8.
p(x(nx+1):(nx+ml)|y1:(ny+l), x1:nx) = p(x(nx+1):(nx+ml)|y(ny+1):(ny+l), xnx).
That is, conditional on the last observation xnx at the ﬁne level and on the
future observations y(ny+1):(ny+l) at the coarse level, the future observations
at the ﬁne level are independent of the observations at the ﬁne level up to
time nx −1 and the observations at the coarse level up to time ny.
11.5.3 Estimation and Forecasting in the Presence of Periodicities
The procedures for estimation and forecasting when there are periodicities in
the ﬁne level of the model are analogous to the case without periodicities.
The full conditional for β is N(m∗
β, C∗
β), where C∗
β = (C−1
β +Z′V−1
x Z)−1
and m∗
β = C∗
β(C−1
β mβ + Z′V−1
x x1:nx).
The full conditionals for φy, σ2
y, and τ are the same as in the case without
periodicities. The full conditionals for φx and σ2
x are analogous to the case
without periodicities but substituting x1:nx by x∗
1:nx = x1:nx −Zβ.
The forecasting procedure in the case with periodicities is analogous to
the case without them. More speciﬁcally, predictions are made for the series
x∗
(nx+1):(nx+l), and the periodicities are added to these predictions.
11.5.4 Eﬃcient Computation Using the Kalman Filter
Although p(y1:ny) is substituted by q(y1:ny) in the construction of the mul-
tiscale model, it is necessary to compute p(y1:ny) in order to perform esti-
mation and forecasting. This section discusses how to compute p(y1:ny) and
p(ys|y1:(s−1)) very eﬃciently through the use of the Kalman ﬁlter.
The main point of this section is that the model p(y1:ny) can be rewrit-
ten as a Dynamic Linear Model (DLM) (West and Harrison, 1997) and the
Kalman ﬁlter can be used in order to compute p(y1:ny) and p(ys|y1:(s−1)). As
our interest is the computation of the marginal p(y1:ny), in this section it is
assumed that the ﬁne level is the unobservable state parameter of a DLM.
First, it is necessary to rewrite Equations (11.1) and (11.3) as a DLM:

136
11 Multiscale Time Series
xs = Gxs−1 + ws,
ws ∼N(0, W),
(11.14)
ys = Fxs + vs,
vs ∼N(0, V ),
(11.15)
where x′
s = (x(s−1)m+1, . . . , xsm), {W}ij = σ2
xφ|i−j|
x
(1 −φ2 min(i,j)
x
)/(1 −φ2
x),
F = m−1(1, . . . , 1), V = τσ2
x, and
G =
⎛
⎜
⎜
⎜
⎝
0 · · · 0 φx
0 · · · 0 φ2
x
...
...
...
0 · · · 0 φm
x
⎞
⎟
⎟
⎟
⎠.
Deﬁne D0 = {x is stationary} and Ds = Ds−1
+{ys}, s = 1, . . . , ny. There-
fore, x1|D0 ∼N(a1, R1) with a1 = 0 and {R1}ij = σ2
xφ|i−j|
x
/(1 −φ2
x).
The Kalman ﬁlter can be used to compute p(ys|Ds−1), p(xs|Ds) and
p(xs+1|Ds), s = 1, . . . , ny:
•
ys|Ds−1 ∼N(fs, Qs), where fs = Fas and Qs = FRsF′ + V ;
•
xs|Ds ∼N(ms, Cs), where ms = as + Ases, Cs = Rs −AsQsA′
s, As =
RsF′Q−1
s , and es = ys −fs;
•
xs+1|Ds ∼N(as+1, Rs+1), where as+1 = Gms and Rs+1 = GCsG′ +W.
Note that p(ys|y1:(s−1)) = p(ys|Ds−1) and p(y1:ny) = *ny
s=1 p(ys|Ds−1).
11.6 Examples
Here several applications illustrate the power and the ﬂexibility of HRMs and
MSTSMs when applied to the analysis of time series from a variety of areas.
The HRM is applied to three diﬀerent time series. In Section 11.6.1, the HRM
with seasonality is used to analyze the Fraser River dataset introduced in
Chapter 3. Section 11.6.2 presents an analysis of temperatures of the Northern
Hemisphere. Additionally, in Section 11.6.3, the MSTSM is used in an analysis
of the potential hydroelectric energy in the southeast region of Brazil.
11.6.1 Analysis of the Flow of the Fraser River
This section presents an analysis of the ﬂow of the Fraser River at Hope,
British Columbia, as an example of the application of the HRM with sea-
sonality. As described in Chapter 3, a standard time series analysis for the
monthly data using harmonics suggests long memory dependence behavior for
the monthly data but a simple AR(1) process for the annual data. That pro-
vides the motivation to perform an analysis using the HRM with seasonality.
Figure 3.1(a) presents the plot of the log of the mean monthly ﬂows of
the Fraser River from January 1913 to December 1990, which shows obvi-
ous seasonality and strong dependence between years. Thus a simple ARMA

11.6 Examples
137
process with seasonality for the monthly series seems to be inappropriate, as
it would probably give poor medium-term forecasts. Instead, we model this
dataset with the HRM introduced in Section 11.2, as was done in Ferreira
et al. (2006). In order to check the performance of the HRM in this particular
application, its predictive performance is compared with the performance of
an AR model.
An exploratory analysis has shown that the seasonality can be well ex-
plained by the ﬁrst, fourth, and ﬁfth harmonics, which will be included in the
model as discussed in Section 11.4.
Figure 3.1(b) shows the plot of the monthly residuals after extracting the
overall mean and the seasonality. Figure 3.2 shows the autocorrelation and
partial autocorrelation functions of the monthly residuals, suggesting a long
memory type process. As discussed in Section 11.3, this long memory behavior
of the series can be captured by the HRM.
Figure 3.3 shows the autocorrelation and partial autocorrelation functions
of the annual series, strongly suggesting an AR(1) process for the annual level
of aggregation. Accordingly, in the application of the multiscale framework
to the ﬂow of the Fraser River, it is natural to assign the annual level of
aggregation as the coarse level.
Posterior summaries for the parameters appear in Table 11.1. The esti-
mation procedure proposed in Section 11.5 was used with a total of 5000
iterations of the Gibbs sampler. The tuning parameters of the Metropolis-
Hastings proposals were set to provide reasonable acceptance probabilities,
equal to 40%, 50%, and 46% for φx, τ, and λ, respectively.
Table 11.1. Fraser River Flow – Posterior summaries for the parameters.
HRM
AR(1) model
Mean
Standard deviation
Mean
Standard deviation
φy
0.6562
0.1331
–
–
σ2
y
0.0193
0.0075
–
–
φx
0.5958
0.0371
0.6093
0.0263
σ2
x
0.0449
0.0023
0.0451
0.0021
τ
0.0106
0.0049
–
–
λ
0.5365
0.2369
–
–
β1 −0.8422
0.0177
−0.8423
0.0179
β2 −0.4612
0.0177
−0.4616
0.0176
β3
0.3391
0.0116
0.3389
0.0116
β4 −0.0565
0.0114
−0.0564
0.0114
β5 −0.1014
0.0085
−0.1012
0.0086
β6
0.0670
0.0086
0.0670
0.0085
A visual check of convergence was performed by running two MCMC
chains with diﬀerent starting values (for a discussion on convergence mon-
itoring, see Gelman, 1996). Figure 11.19 shows the trace of φy, σ2
y, φx, σ2
x,

138
11 Multiscale Time Series
0
1000
3000
5000
0.0
0.2
0.4
0.6
0.8
1.0
0
1000
3000
5000
0.1
0.2
0.3
0.4
0.5
0
1000
3000
5000
0.0
0.2
0.4
0.6
φy
σ2
y
φx
0
1000
3000
5000
0.20
0.22
0.24
0.26
0.28
0.30
0.32
0
1000
3000
5000
0.05
0.10
0.15
0.20
0.25
0
1000
3000
5000
0.5
1.0
1.5
2.0
σ2
x
τ
λ
Fig. 11.19. Fraser River. Traces of φy, σ2
y, φx, σ2
x, τ, and λ.
0
1000
3000
5000
−0.8
−0.6
−0.4
−0.2
0.0
0
1000
3000
5000
−0.5
−0.4
−0.3
−0.2
−0.1
0.0
0
1000
3000
5000
0.0
0.1
0.2
0.3
β1
β2
β3
0
1000
3000
5000
−0.10
−0.08
−0.06
−0.04
−0.02
0.00
0
1000
3000
5000
−0.12
−0.08
−0.04
0.00
0
1000
3000
5000
0.00
0.02
0.04
0.06
0.08
0.10
β4
β5
β6
Fig. 11.20. Fraser River. Traces of the harmonic coeﬃcients.
τ, and λ for a particular set of starting values. Figure 11.20 shows the trace
of the harmonic coeﬃcients. As it seems that the MCMC scheme converged
after 1000 iterations, those ﬁrst 1000 iterations were taken to be the burn-
in period; the remaining 4000 iterations were used to perform the statistical

11.6 Examples
139
0.0
0.2
0.4
0.6
0.8
1.0
0
200
400
600
800
1000
1200
0.05
0.10
0.15
0.20
0.25
0.30
0
200
400
600
800
1000 1200
0.45
0.55
0.65
0.75
0
200
400
600
800
φy

σ2y
φx
0.195
0.205
0.215
0.225
0
100
200
300
400
500
600
0.05
0.10
0.15
0.20
0
200
400
600
0.4
0.6
0.8
1.0
1.2
1.4
0
200
400
600
800
1000
1200
√
σ2x
√τ
λ
Fig. 11.21. Fraser River. Histograms of φy,

σ2y, φx,
√
σ2x, √τ, and λ.
−0.92
−0.88
−0.84
−0.80
0
200
400
600
800
−0.52
−0.48
−0.44
−0.40
0
200
400
600
800
0.28
0.30
0.32
0.34
0.36
0.38
0
200
400
600
800
1000
1200
β1
β2
β3
−0.10
−0.08
−0.06
−0.04
−0.02
0
100
200
300
400
500
600
700
−0.13
−0.11
−0.09
−0.07
0
200
400
600
800
0.04
0.06
0.08
0.10
0
200
400
600
800
β4
β5
β6
Fig. 11.22. Fraser River. Histograms of the harmonic coeﬃcients.
inference presented here. Figures 11.21 and 11.22 show the histograms of the
parameters of the model. As all the parameters are reasonably distant from
zero, it is reasonable to keep all of them in the model.

140
11 Multiscale Time Series
1988.0
1988.5
1989.0
1989.5
1990.0
1990.5
1991.0
6.0
6.5
7.0
7.5
8.0
8.5
9.0
9.5
Fig. 11.23. Fraser River. Observed ﬂow (solid), forecast (dashed), and predictive
interval (dotted).
Figure 11.23 shows the observed monthly ﬂow, the forecasts, and 95% pre-
dictive intervals for the years 1988, 1989, and 1990 using only the observations
until 1987. As can be seen in Figure 11.23, the model performs very well in
terms of predictive capacity. When compared with the AR(1) model, the HRM
reduces the mean squared prediction error from 0.0549 to 0.0469, demonstrat-
ing for this example the superiority of the Hidden Resolution Model.
11.6.2 Northern Hemisphere Temperature
The analysis of the series of annual land-only average temperatures of the
Northern Hemisphere is presented here as an example of an application of the
HRM. Figure 11.24 shows the plot of annual land-only average temperatures
of the Northern Hemisphere from 1851 to 1986 from the report of the Intergov-
ernmental Panel on Climate Change (Houghton et al., 1990). Similar datasets
were analyzed by Smith (1993) and Petris and West (1998) using long memory
dependence models: Smith (1993) analyzed the series of monthly overall av-
erage temperatures of the Northern Hemisphere, and Petris and West (1998)
analyzed the monthly overall average temperatures of the Southern Hemi-
sphere. Here the HRM is used in order to emulate long memory dependence,
assuming that the ﬁne level is the annual time scale, and that there is an
unobservable coarse level with coarsening window m = 4.
The MCMC algorithm described in Section 11.5.1 was used in order to ﬁt
the HRM. Figure 11.25 shows the posterior histograms of the parameters of
the HRM. The posterior distribution of φy is very skewed, mainly because of

11.6 Examples
141
1860
1880
1900
1920
1940
1960
1980
−0.6
−0.4
−0.2
0.0
0.2
0.4
Fig. 11.24. Northern Hemisphere land temperatures. Observed series (solid), fore-
casts (dashed), and predictive intervals (dotted) for the period from 1971 to 1986.
0.4
0.5
0.6
0.7
0.8
0.9
1.0
0
200
400
600
800
0.00
0.04
0.08
0.12
0
500
1000
1500
−0.4
−0.2
0.0
0.2
0.4
0.6
0
200
400
600
800
1000
1200
φy
σ2
y
φx
0.02
0.03
0.04
0.05
0.06
0
200
400
600
800
1000 1200 1400
0.000
0.010
0.020
0.030
0
200
400
600
800
1000 1200
σ2
x
τ
Fig. 11.25. Northern Hemisphere land temperatures. Posterior histograms of φy,
σ2
y, φx, σ2
x, and τ.
the restrictions −1 < φy < 1. The posterior distributions of σ2
y, φx, σ2
x and τ
are well behaved.
Table 11.2 presents posterior means and standard deviations for the para-
meters of both the HRM and the AR(1) models. There is a big diﬀerence

142
11 Multiscale Time Series
between the posterior means for φx in the two models. This is expected when
the HRM is signiﬁcantly diﬀerent from the AR(1) model such that φx has dif-
ferent interpretations in each of the models. The impact of the HRM can also
be noticed by the magnitude of the posterior mean of φy, which is reasonably
close to 1 as a result of the long memory type of behavior of the series. In
addition, the posterior mean for τ is very small, imposing a high degree of
agreement between the coarse and ﬁne levels. Therefore, the introduction of
an underlying coarse level seems to have a large impact on the process at the
ﬁne level.
Table 11.2. Northern Hemisphere temperatures – Posterior summaries for the pa-
rameters.
HRM
AR(1) model
Mean Standard deviation Mean Standard deviation
φy 0.8407
0.0955
–
–
σ2
y 0.0235
0.0164
–
–
φx 0.1014
0.1284
0.4843
0.0816
σ2
x 0.0352
0.0058
0.0465
0.0063
τ
0.0064
0.0042
–
–
In order to check the predictive capacity of the model, its forecasts were
compared with those of autoregressive models. Data from 1851 to 1970 were
used to ﬁt both models, and then the forecasts from 1971 to 1986 were com-
puted. When compared with the original AR(1) model, the HRM reduces the
mean squared prediction error from 0.0936 to 0.0754, a reduction of about
19.4%. When compared with the best autoregressive model in this applica-
tion, the AR(5), the reduction is about 2.8%. In addition, the HRM is more
parsimonious, it has one parameter less than the AR(5) model, and therefore
it is preferable. Finally, Figure 11.24 shows the observed annual average tem-
perature, the predictive mean based on the HRM for the period from 1971 to
1986, and 95% predictive intervals.
11.6.3 Potential Hydroelectric Energy
In this section, the analysis of the series of potential hydroelectric energy of
the rivers of the southeast region of Brazil is presented as an example of the
application of the MSTSM with seasonality.
Figure 11.26(a) presents the plot of the monthly potential hydroelectric
energy of the southeast region of Brazil from January 1937 to December 2000,
as well as the series of annual averages. In the monthly series, the presence of
seasonality and the strong dependence between the years are quite obvious.
Moreover, the annual potential hydroelectric energy is well deﬁned as the sum
of the corresponding monthly series. Thus, the potential hydroelectric energy

11.6 Examples
143
1920
1940
1960
9.0
9.5
10.0
10.5
11.0
1997.0
1998.0
1999.0
2000.0
9.0
9.5
10.0
10.5
11.0
(a)
(b)
Fig. 11.26. Potential hydroelectric energy. (a) Monthly potential (dotted) and an-
nual averages (solid). (b) Observed potential hydroelectric energy (solid), forecast
(dashed), and predictive interval (dotted).
is modeled with the MSTSM with τ = 0 and the annual series being the
observed coarse level.
The model was compared with an AR(1) model with respect to its pre-
dictive capacity. Both models were ﬁtted with the data until 1997 and used
to compute three-years-ahead forecasts. The MSTSM performed much better
than the AR(1) model in terms of mean squared prediction error, with values
of 0.0532 and 0.0621 for the MSTSM and the AR(1) model, respectively, a
decrease of 14.3% for the MSTSM. Furthermore, the mean squared prediction
error is likely to decrease if there exists a model for the annual series with
better predictive capacity. For example, a model for the coarse level can be
built based on the knowledge of the physical process of the ﬂow of the rivers in
the southeast region of Brazil. Just as an indication of the potential increase
in the predictive capacity, the mean squared prediction error would decrease
by around 45.4% to 0.0339 if the future coarse level were known.


12
Change of Support Models
In contrast to the grid-based methods of the previous chapters in this section,
the general class of methods often referred to as “change of support” methods
evolved mostly to deal with problems of data that are observed at a scale
diﬀerent from the scale at which inference is desired, and the mapping between
scales is nonregular. For example, demographic data may be available by
postal code, but information about particular city blocks might be of interest.
Alternatively, one could be trying to relate such demographic data to voting
data, which are reported by voting precinct, and these precincts may not have
any relationship to postal codes (so that precincts may overlap multiple postal
codes, and postal code regions may contain multiple voting precincts). How
is one to use the available data to draw valid conclusions at a diﬀerent scale?
The desire to answer this question is the primary motivation for the change
of support problem.
Additional motivation comes from the desire to combine information at
multiple scales. One typical example is attempting to combine individual
medical record information with pollution data that are measured on a much
larger scale. The methods must also deal with the case where the scales are
nonnested, such as the postal codes and voting precinct example above.
The choice of scale and the method for changing scales can have major
consequences for the results of the analysis. One of the earliest examples of the
importance of the choice of scale was given by Gehlke and Biehl (1934), who
were examining the relationship between male juvenile delinquency and me-
dian monthly rental rates by census tract in Cleveland. They discovered that
the correlation coeﬃcient between these two variables depended on whether
the correlation was computed using the values from individual census tracts or
using aggregated groups of tracts. In particular, if adjacent tracts were com-
bined to form local clusters, the computed correlation coeﬃcient was larger
than when computed on the individual tracts. However, combining tracts in
random groups did not impact the computed correlation. The authors also
found similar results in the correlation between farm product value and the
number of farmers in 1000 rural counties, with increasing correlation when

146
12 Change of Support Models
counties were combined in contiguous blocks. A number of later authors have
thoroughly investigated this phenomenon, and Gotway and Young (2002) pro-
vide a review of this literature.
Another vivid example was provided by Openshaw and Taylor (1979), who
looked at the correlation between the percentages of Republican voters and
elderly voters in Iowa. They started with data at the county level for the
99 counties in Iowa and then considered all possible aggregations into larger
groups of these counties and computed the correlation using each of these
possible datasets. They found that, using 12 groups, they could produce a
correlation coeﬃcient ranging from −0.97 to 0.99. Thus, with creative ag-
gregation, the original data can be ﬁnagled to give just about any possible
answer. Hence it is important to develop a methodology for aggregation (or
for reﬁning the scale) that is consistent with the true underlying process and
that will accurately reﬂect that process at all scales.
A related concept from the epidemiology literature is that of “ecological
inference”, which describes learning about the behavior of individuals from
aggregated data. It is analogous to trying to learn about a point-level process
from regional data. However, as with the examples above, grouped data may
not accurately reﬂect the relationship between variables at the individual level.
Incorrectly drawing such an inference is referred to as the “ecological fallacy”.
Wakeﬁeld (2004) provides a recent discussion of this problem, which has by
now generated extensive literature.
In the rest of this chapter, we present three methods for dealing with the
change of support problem. The ﬁrst assumes that there is an underlying
process that occurs at the point level, and is typically modeled with Gaussian
processes. The second is explicitly aimed at inference and prediction at an
intermediate level, and also employs Gaussian processes. The third assumes
that data occur inherently at the block level, with Markov random ﬁelds
being a natural model for spatial processes. The basics of these spatial models
were introduced in Chapter 2 and additional references can be found there.
Gotway and Young (2002) is an extensive review article that provides a more
general overview of the change of support literature (both Bayesian and non-
Bayesian).
12.1 Point-Level Spatial Processes
A Gaussian process approach makes sense when the process can be viewed as
arising from point data, with coarser-scale observations being block averages
of the point process. For example, Banerjee et al. (2003) give an example on
ground-level ozone pollution, which varies spatially and can be measured at
individual points. One may then want to predict average pollution levels over
an aggregated region, such as a postal code region, in order to relate it to other
available data, such as hospital admittance data, that may only be obtainable
at the postal code level. Thus, in order to study the relationship between

12.1 Point-Level Spatial Processes
147
hospital admittance and pollution, it is necessary to be able to estimate the
average pollution over a region, and to do so from point measurements. The
change of support methodology provides a coherent mechanism for moving
between and among points and regions.
Some authors distinguish between various change of support problems,
depending on the type of data that are observed, and what type of spatial
inference is desired. A common distinction is to split the problem into four sub-
problems: points-to-points, points-to-regions, regions-to-points, and regions-
to-regions. In the ﬁrst case, the process is observed at point locations, and
inference is desired at other point locations. This is typically handled via
ordinary kriging, as in Section 2.2. In the second case, inference on regions
(blocks) is desired from point source data, and this is the primary focus of the
development that follows. The methodology can then be extended similarly
to deal with the other cases. The fourth case, regions-to-regions, is sometimes
referred to as the modiﬁable areal unit problem.
In this section, we follow the approach of Banerjee et al. (2003, Ch. 6),
and further details on these change of support methods can be found in that
book and the references therein. The basic assumption is that there exists an
underlying process w(s) for s ∈S, some region of interest, which will typically
be a subset of Euclidean space. Point data would be observed or inferred over
a set of locations {s1, . . . , sm}. Block (region) data would be over a set of
blocks {b1, . . . , bn}. Because we assume that the basic process exists at the
point level, block data are assumed to be derived as averages of the point-level
process over the regions. Thus the block-level process is deﬁned as
x(bi) =
1
|bi|

bi
w(s)ds,
(12.1)
where bi ⊂D is a region of interest and |bi| is the area (or generalized volume)
of the block bi. This block averaging provides a statistically coherent method
for moving between points and blocks. Possible alternatives would include
taking the block value to be the process value at a central point or setting
the block value to the average of the observed points in the block. However,
such approaches tend to lead to larger variability and/or estimation bias when
compared with Equation (12.1) (Banerjee et al., 2003).
To obtain the posterior predictive distribution for the block averages from
point observations, we employ a Bayesian version of what is sometimes referred
to as block kriging (Cressie, 1993; Chil`es and Delﬁner, 1999). Here we follow
the Bayesian approach of Banerjee et al. (2003). For predicting over a set of
blocks b = {b1, . . . , bn} from data y at a set of points s = {s1, . . . , sm}, the
predictive distribution is
f(x(b)|y(s)) =

f(x(b)|y(s), θ)f(θ|y(s))dθ,
(12.2)
where θ is the vector of parameters (both for the mean of the process and
for the covariance structure). f(θ|y) is the posterior distribution for the

148
12 Change of Support Models
parameters, given the point-level observations, which would typically be ﬁt
using Markov chain Monte Carlo methods.
Denote the mean function of the Gaussian process by µ and the covariance
between points si and sj by σ2ρ(si, sj). The Gaussian process model gives
f
 y(s)
x(b)
%%%% θ

= N
 µy(θ)
µx(θ)

, σ2
 Hy(θ) Hy,x(θ)
Ht
y,x(θ) Hx(θ)

,
(12.3)
where the jth element of the mean function vector for the blocks is
µx(θ)j = E [x(bj)|θ] =
1
|bj|

bj
w(s|θ)ds,
the correlation matrix for the process observed at the vector of points s is
Hy(θ) with elements ρ(si, sj; θ), the cross-correlation matrix between ob-
served points and predicted blocks has elements (i, j) for the correlation be-
tween point si and block bj,
Hy,x(θ)i,j =
1
|bj|

bj
ρ(si, t; θ)dt,
and the correlation matrix for the block predictions has (i, j)th element
Hx(θ)i,j =
1
|bi| |bj|

bi

bj
ρ(s, t; θ)dtds.
Standard properties of the multivariate normal distribution imply that the
conditional posterior predictive distribution is
x(b)|y(s), θ ∼N

µx(θ) + Ht
y,x(θ)H−1
y (θ)

y(s) −µy(θ)

,
(12.4)
σ2 3
Hx(θ) −Ht
y,x(θ)H−1
y (θ)Hy,x(θ)
4
.
Unfortunately, these integrals typically cannot be analytically evaluated.
Banerjee et al. (2003) suggest numerical integration via a Monte Carlo scheme.
For each region bj, they propose drawing a random (independent and uni-
formly distributed) sample of Mj points s∗
j = {s∗
j,1, . . . , s∗
j,Mj} in bj, with Mj
possibly related to |bj| (so that larger regions may use more points for better
accuracy). The numerical estimates necessary are then
µx(θ)j =
1
Mj
Mj

k=1
w(s∗
j,k|θ),
Hy,x(θ)i,j =
1
Mj
Mj

k=1
ρ(si, s∗
j,k; θ),
Hx(θ)i,j =
1
MiMj
Mi

k=1
Mj

l=1
ρ(s∗
ik, s∗
jl; θ).

12.2 Inferring Intermediate-Level Processes
149
Note that the accuracy of this estimation step depends on the size of the
Monte Carlo sample, not the size of the original dataset. A single Monte
Carlo sample can be generated for the entire set of blocks b and used for all
of the estimates above.
Similarly, if one observed block data and wanted to predict at points, a
version analogous to Equation (12.4) could be obtained from Equation (12.3)
by focusing on y(s):
y(s)|x(b), θ ∼N

µy(θ) + Hy,x(θ)H−1
x (θ) (x(b) −µx(θ)) ,
σ2 3
Hy(θ) −Hy,x(θ)H−1
x (θ)Ht
y,x(θ)
4
.
Finally, to convert from one set of blocks to a diﬀerent set of blocks (the
modiﬁable areal unit problem), a point estimate for the value of a new block
b0 is the posterior mean of the process over that block,
E
3
x(b0)|x(b)] = E
3
µ(b0; θ) + Ht
x,b0(θ)H−1
x (θ) (x(b) −µx(θ))
%% x(b)
4
,
where Hx,b0(θ) is the vector of correlations between x(bi) and x(b0) for i ∈
{1, . . . , n}. A ﬁrst-order approximation for the mean is given by
µ(b0; θ) ≈
1
|b0|
n

i=1
|bi ∩b0| x(bi) ,
which is found by approximating the process as being roughly constant within
each of the existing blocks bi.
12.2 Inferring Intermediate-Level Processes
For some problems, speciﬁcation of a complete probabilistic model at all pos-
sible scales may not be feasible, yet it is still necessary to draw a coherent
inference from data at multiple scales. Wikle and Berliner (2005) provide
methodology for such a situation. Suppose that data ya = {y(a1), . . . , y(ana)}
are observed on a ﬁne set of blocks {a1, . . . , ana}, and that coarse-scale data
yc = {y(c1), . . . , y(cnc)} are observed on a set of blocks {c1, . . . , cnc}, with
nc < na. These data points are assumed to arise from noisy observations of
two related underlying true processes, xa and xc, i.e., ya = xa + εa, where
εa is mean zero with covariance matrix Σa, and similarly yc = xc + εc with
associated covariance matrix Σc. Typically, Σa and Σc will be taken to be a
constant times the identity matrix, i.e., errors are assumed to be independent
and identically distributed, but the development here is suﬃciently general
to allow correlated error structures. This setup can be used for a variety of
types of data, including those that arise from aggregation over blocks and
those that are point measurements taken over diﬀerent domains (e.g., pre-
dicted wind speeds from two diﬀerent atmospheric models that give output
on diﬀerent regular lattices).

150
12 Change of Support Models
The goal here is inference or prediction at a potentially diﬀerent scale,
typically somewhere between the two other scales. By assuming that there are
at most three scales of interest, the model can be built in a more restricted
fashion without the need for the ability to model at an arbitrary scale. This
will allow for various simpliﬁcations.
Denote the blocks on the level of interest as {b1, . . . , bnb}, with nc < nb <
na. Thus the goal is to ﬁnd the latent process xb = {x(b1), . . . , x(bnb)}. This
modeling is done in two steps, which separate the modeling of xb itself from
the modeling of the ﬁner-scale residuals conditional on xb. Starting with the
second of those, it is assumed that there exists a continuously deﬁned process
x(s) for s ∈D such that for each bj and each s ∈bj
x(s) = x(bj) + γ(s),
where γ(s) is a zero-mean process with a covariance function (deﬁned over
all of the space of interest, D) that does not depend on xb. Note that this
formulation implies constant means within blocks, i.e., E[x(s)] = E[x(bj)].
The ﬁnal piece of the methodology is the speciﬁcation of the rest of the
hierarchical model. A probability distribution, or at least the ﬁrst two mo-
ments, must be speciﬁed for xa and xc given xb, showing how to relate the
scales. The process xb itself needs a speciﬁcation. And then the parameters for
each of these distributions, as well as for the ya and yc distributions, must be
given appropriate hyperpriors. As full MCMC may be diﬃcult or infeasible in
large problems, Wikle and Berliner propose integrating out xa and xc when
possible, reducing the dimension of the parameter space.
The relation of xa and xc to xb is a key part of the speciﬁcation. Areal
averaging is a natural choice. In the simplest case when ai ⊂bj, this implies
that
x(ai) =
1
|ai|

ai
x(bj)ds +
1
|ai|

ai
γ(s)ds
= x(bj) +
1
|ai|

ai
γ(s)ds .
In the nonnested case, the ﬁrst term is replaced by a weighted average,
x(ai) =
1
|ai|
nb

j=1

ai∩bj
x(bj)ds + 1
|ai|

ai
γ(s)ds
=

gi
a
t xb + 1
|ai|

ai
γ(s)ds ,
where gi
a is the vector of weights with elements |ai ∩bj|/|ai|, most of which
will be zero. Similarly, the coarser process is obtained by
x(ck) =
1
|ck|
nb

j=1

ck∩bj
x(bj)ds +
1
|ck|

ck
γ(s)ds

12.3 Block-Level Spatial Processes
151
=

gk
c
t xb +
1
|ck|

ck
γ(s)ds .
Additional details, as well as a full analysis of their motivating example in
meteorology, can be found in Wikle and Berliner (2005). They also discuss
a number of extensions of this methodology, including data observed at the
intermediate level, spatio-temporal processes, multivariate processes, and non-
additive error structures.
12.3 Block-Level Spatial Processes
In some cases, it does not make sense to think of a point-level process. Ex-
amples include data that are proportions (such as the proportion of voters
favoring a candidate, which would be a binary response at the point level) or
counts over regions. In these cases, it is necessary to operate solely at the block
level, without recourse to an underlying point-level process. This situation is
another example of the modiﬁable areal unit problem. Banerjee et al. (2003)
distinguish between two types of these problems. The ﬁrst case is when the
new blocks (the target blocks) are contained within the set of existing blocks
(the source blocks), and they call this “nested block realignment”. The second
case, nonnested block realignment, covers the more general situation where
neither set of blocks necessarily contains the other set.
A simple approach to the nested realignment problem is to assume that
the process is approximately constant within blocks, and then the new target
block can be computed as a linear interpolation. For example, in the case of
measuring counts (e.g., of people or events) in blocks and then denoting a new
target block by b0 and the source blocks by {b1, . . . , bn}, with |b| denoting the
area or generalized volume of a block, the value for b0 can be approximated
by
x(b0) ≈
n

i=1
|b0 ∩bi|
|bi|
x(bi) .
However, in many cases the assumption of constant rates within blocks is
unrealistic. Furthermore, it is diﬃcult to obtain an estimate of the uncertainty
from this formulation. Flowerdew and Green (1989, 1994) developed models
for incorporating covariates and using these covariates for improved estimation
of the new target block values. Building on these models, Mugglin and Carlin
(1998) developed a fully Bayesian approach that uses hierarchical models for
predicting target block values. The exact form of the model will depend on
the problem at hand. Best et al. (2000) proposed a related approach based on
a marked point process model.
The nonnested block realignment problem is a bit more complicated be-
cause of the possible edge cases. Denote the observed values by {y(b1), . . . ,
y(bn)} on a set of nonoverlapping blocks (which we refer to as a grid of blocks)

152
12 Change of Support Models
{b1, . . . , bn}. Covariate information may be available on an alternate set of
blocks {c1, . . . , cm}. The key is to partition the space into disjoint subblocks
that are entirely within both a single bi and a single cj, so that a ﬁner set
of regions is deﬁned that is as common as possible to both original sets of
blocks (edge cases may prevent a single common grid when n
i=1 bi ̸= m
j=1 cj,
for example, when the boundaries of the grid of zip code blocks covering a
metropolitan area might not match the boundaries of a grid deﬁned by the
counties comprising that metropolitan region). Thus, divide each bi into re-
gions bi = m
j=0 (bi ∩cj), where c0 is the region (if any) outside the grid; i.e.,
c0 = S −m
j=1 cj. Note that many of the bi ∩cj may be empty sets, so that
a more eﬃcient numbering scheme would index over only the nonempty sub-
sets. For notational convenience, denote these intersection sets by Bij, which
Banerjee et al. (2003) call atoms. Note that these atoms may be disconnected.
Similar labeling is done using the covariate blocks as the reference; i.e., Ckl
is the lth (nonempty) intersection of ck with one of the b blocks. Thus, each
nonedge atom will have two equivalent labels (a Bij and a Ckl), whereas edge
atoms will exist with only one label. Because there may be both B and C
edge atoms, no simple single indexing scheme can be used.
With these indices, Banerjee et al., following Mugglin et al. (2000), describe
a fully Bayesian model for inference and prediction, incorporating covariates
measured on either or both grids, as well as a spatial process that is speciﬁed
for the mean levels of the blocks (for both b and c). They suggest a Markov
random ﬁeld speciﬁcation for these latent spatial process, and assume that
these values are inheritable; i.e., the same value can be used for all of the
relevant atoms of a Bij or a Ckl cell. They also assume that the covariates
are either aggregates (which can thus be apportioned) or inheritable measure-
ments. They require that the y(bi)’s be aggregated measurements (such as
counts), so that these values can be apportioned among the Bij atoms. In
the case of counts, a Poisson formulation is used. For continuous responses,
a gamma formulation could be used, leading to latent scaled product Dirich-
let distributions on the atoms. Alternatively, a normal model could be used,
with latent conditional multivariate normals. Banerjee et al. (2003) provide a
detailed example of the Poisson case.

Part IV
Implicit Multiscale Models


13
Implicit Computationally Linked
Model Overview
In contrast to the rest of the multiscale models discussed in this book, the
methods of this section do not attempt to explicitly model the joint distribu-
tion of the data at all of the scales. Instead, a probability model is speciﬁed
for each scale independently, and then the scales are linked during the ﬁtting
algorithms. A fully dependent multiscale ﬁt is then obtained implicitly.
This may seem like a strange approach to multiscale modeling. In fact,
most of the methods of this section were originally developed to aid in the
ﬁtting of highly multimodal single-scale models. One way to attempt to deal
with the multimodality is to move to a coarser resolution, which has an eﬀect
similar to smoothing the function and thus ameliorating the multimodality.
In dealing with a likelihood, maximization is thus aided by improving the
chances of ﬁnding all of the primary modes, including the global maximum.
The speed of ﬁnding these modes can also be greatly increased. For a fully
Bayesian posterior analysis, MCMC is typically employed. Standard Gibbs
and Metropolis-Hastings steps can have great diﬃculty escaping from local
modes, leaving exploration of the space incomplete. Entire modes can easily be
missed, causing sections of the posterior density to be left out. By coarsening,
the mixing of the chain can be greatly improved, allowing more complete
exploration of the space in a smaller amount of computing time.
If multiple scales are used merely as a computational tool, then the ul-
timate object of interest is only the ﬁnest scale. In the case of optimization
routines, it is only the end result that matters, when the algorithm has con-
verged at the ﬁnest scale. For MCMC runs, if the joint multiscale space is
explored, then the marginal distribution at the ﬁnest scale is easily obtained
by discarding all information from the other scales. It was in this sort of
context that most of these methods were created and reﬁned.
On the other hand, as with the rest of this book, one may be truly inter-
ested in a multiscale problem, either with data observed at multiple scales, or
with only unobservable yet physically meaningful processes at more than one
scale. It turns out that most of the methods of this section are also directly
applicable to these multiscale problems. They provide a computationally

156
13 Implicit Computationally Linked Model Overview
eﬃcient approach to dealing with multiple scales in the presence of multi-
modality, which is a frequent concern.
The rest of this chapter will discuss approaches leading up to multigrid
methods and simulated sintering. The latter grew out of simulated annealing,
a stochastic optimization technique, and in between is simulated tempering,
a related optimization technique that uses varying amounts of smoothness to
help deal with multimodality. Simulated sintering varies the scale to allow
better exploration at a coarser scale and then reﬁnes the scale over time to
hopefully eventually settle at the global maximum. Sintering is basically just a
computational tool and is not as useful for a true multiscale problem. However,
it is closely related to some of the other methods presented here, so we include
it for perspective.
The second set of methods are multiscale MCMC algorithms that in-
volve Metropolis-Hastings steps between scales, so that information moves
directly between the scales, inducing posterior dependence. Standard Gibbs
and Metropolis steps are mixed with these multiscale swapping steps to ex-
plore the joint multiscale posterior. These methods are equally applicable to
multimodal single-scale problems and true multiscale problems.
The ﬁnal methods are genetic algorithms and related MCMC algorithms.
Genetic algorithms are a class of optimization techniques inspired by the
action of genes on chromosomes. A population of solution chromosomes is
evolved through the sharing of gene information between the chromosomes.
A selection mechanism favors the better solutions. A series of iterations tends
to converge to the global maximum if the initial population is selected from a
wide enough set. This approach can also be adapted for MCMC by creating
Metropolis proposals based on the mechanics of genetic algorithms. Such al-
gorithms can be used for either optimization or full posterior inference for a
truly multiscale problem.
Before moving on, we note that there are alternative computational ap-
proaches to using coarse-scale samples to help explore the ﬁne-scale poste-
rior. One basic alternative would be importance sampling (Evans and Swartz,
1995). Here, MCMC could be used to sample from the coarse posterior and to
construct ﬁne-scale candidates, which could then be used as the importance
sample. However, on even simple one-dimensional examples, this approach
can have serious problems. In particular, the importance weights tend to be
dominated by one or two huge weights. This is because the importance sam-
ple does a poor job covering the region of highest posterior density on the
ﬁne scale. The few realizations from the importance distribution that do hit
this region yield huge importance weights. Such problems can be expected
since the coarse-to-ﬁne proposal is not designed to use information from the
likelihood.
Another alternative is the reversible jump approach of Green (1995). Here,
MCMC draws are constructed from a mixture of the posteriors at each scale.
Note that this new target distribution is a mixture of densities whose support
may be on diﬀerent spaces, adding to the complexity. We shall not focus on

13.1 Simulated Annealing
157
such methods here but instead refer the reader to additional references (Carlin
and Chib, 1995; Richardson and Green, 1997; Brooks, 1998; Besag, 2000).
13.1 Simulated Annealing
Simulated annealing is a maximization technique developed for multimodal
problems (Kirkpatrick et al., 1983). In such problems, the standard deter-
ministic algorithms (such as gradient descent) are prone to becoming trapped
in a local maximum. While these algorithms are typically optimal for well-
behaved problems, they can fail spectacularly in the more complex problems
often found in real applications. Thus some element of randomness is neces-
sary during the maximization to facilitate escapes from local maxima in order
to ﬁnd the true global maximum.
Simulated annealing is one of the most popular of these approaches. The
method draws analogies to statistical mechanics (equilibrium tends to occur
in the minimum energy state) and the production of crystals and metals. In
materials science, annealing refers to a process whereby a material is heated
until it melts, and then slowly cooled to form a pure crystalline or metal-
lic structure. Cooling must happen suﬃciently slowly, or else the atoms or
molecules will settle too quickly and not in their optimal places. But if done
at the right pace, the random movements of the particles will tend to lead
them to settle down into the optimal structure, forming the desired substance.
Simulated annealing is similar, in that the typically high-dimensional para-
meter is initially allowed to move around quite randomly, like the particles
at high temperature. Then, as the system is cooled, the parameter tends to
make smaller movements and eventually settle into a maximum (or, to be
completely analogous, one would work with the negative of the function to be
maximized, and instead minimize this function, just as annealing minimizes
the energy state of the system).
The algorithm is based on analogy with the Boltzmann probability distrib-
ution, P(E) ∝exp(−E/kt), where E is the energy function, k is Boltzmann’s
constant, and t is the temperature. In simulated annealing, E is the function
to be minimized (and thus −E is maximized). Applied to ﬁnd the maximum
of a posterior (or likelihood), the −E can be taken as the posterior or just
a key piece of the posterior. For example, in the common case of a Gaussian
likelihood (with a ﬂat or conjugate prior),
f(θ|y) ∝exp
,
−1
2σ2
n

i=1
(y −g(θ))2
-
,
one could then choose
E =
n

i=1
(y −g(θ))2 ,

158
13 Implicit Computationally Linked Model Overview
where g(θ) = θ in the simplest case, but could also be a tremendously com-
plicated function (such as in the hydrology example of Chapter 16). In this
way, there is only a single exponentiation, and P(E) is essentially taken to be
the posterior.
The temperature t is started at a relatively large (relative, in a sense, to
E) value and then slowly decreased to “cool” the system. The algorithm is
started with an initial value for the parameters and thus for E. A new value
of parameters and thus a new energy E∗is proposed, typically as a random
perturbation (as with a Metropolis step in Markov chain Monte Carlo). This
new value is accepted with probability min (1, P(E∗)/P(E)). Thus, if the
new value is an improvement, i.e., P(E∗) > P(E), then the new value is
always accepted, but if the new value is worse then it is only accepted with a
probability that depends on just how much worse it is. “Worse” is a relative
term, as it also depends on the temperature t. Thus, when t is large, small
changes in E are relatively unimportant and the algorithm will move easily. As
t decreases, changes in E become more signiﬁcant and the system eventually
stabilizes at a mode, hopefully the global mode. The schedule for decreasing
t may require tuning for good performance of the algorithm.
Because this algorithm is not deterministic, in multimodal situations it
typically outperforms greedy algorithms (those that deterministically optimize
at each step). While it tends to seek maxima and will often initially ﬁnd only a
local maximum, it also has a chance of escaping in order to explore the rest of
the space and ﬁnd the global maximum. The key is that the temperature scale
must be chosen so that local maxima can be escaped when the temperature is
at its highest. If the maxima are well separated, then a high initial temperature
is necessary. Thus the optimal choice of the temperature schedule will depend
on the function being maximized. But, if done correctly, simulated annealing
has been found to work well in practice on highly multimodal problems. For
example, it was one of the ﬁrst algorithms to perform well on the traveling
salesman problem (Kirkpatrick et al., 1983).
The original Metropolis version of MCMC (Metropolis et al., 1953) can
be seen as a version of simulated annealing where the process does not cool.
So while in simulated annealing the goal is to ﬁnd a point estimate for the
maximum and the process cools to reach this stable point, in MCMC the goal
is to estimate a posterior density. A sample of points is used to empirically
estimate the posterior, where this sample is taken at a ﬁxed temperature using
the same sampling procedure as in simulated annealing.
13.2 Simulated Tempering
Simulated tempering, proposed independently by Marinari and Parisi (1992)
and Geyer and Thompson (1995), builds on the ideas of simulated annealing
by changing the cooling analogy from that of the movement of the chain to
that of the equilibrium distribution itself. A rough description of the process

13.2 Simulated Tempering
159
is that MCMC is run but the posterior itself is started as a heated version and
cooled during the process. The idea is that heated versions of the posterior
are smoothed out so that the local maxima are reduced, allowing the chain to
more easily explore the whole space and not become stuck in a local maximum.
The heating is done by taking the posterior to a fractional power, thus keeping
some of the original shape while diminishing the peaks.
In mathematical terms, an auxiliary parameter is introduced which indexes
the “temperature” of the system. The temperature is deﬁned as a power for
the posterior; i.e., let j ∈{1, . . . , m} be the auxiliary parameter, let 1 = β1 <
β2 < . . . < βm, and denote the unnormalized posterior (the product of the
likelihood and the prior) by h(θ). Then hj(θ) is deﬁned as h(θ)1/βj. A prior
π(j) must be speciﬁed for the diﬀerent temperature states. Then MCMC is
performed over the joint space (θ, j) for f(θ, j) = hj(θ)π(j):
1. update f(θ|j) = hj(θ) via standard Gibbs or Metropolis-Hastings steps,
2. update f(j|θ) using Metropolis-Hastings with proposal jnew = jold ± 1
with either equal or unequal move probabilities,
3. repeat steps 1 and 2 until convergence and desired number of samples are
obtained.
In the second step, the acceptance probability is min(1, α), where
α = hjnewπ(jnew)q(jnew, jold)
hjoldπ(jold)q(jold, jnew)
and q(jold, jnew) is the probability of moving from jold to jnew = jold ± 1. If
the probabilities of moving up and down by 1 are equal, then the q terms will
drop from the ratio.
This approach allows the Markov chain to explore not just the original
posterior but also smoothed versions of the posterior, which can lessen the
probability of becoming stuck in local maxima. For ﬁnal inference where one
only cares about the “cool” function, one conditions on j = 1 by simply
discarding all samples with j ̸= 1.
Figure 13.1 shows the process of heating an objective function. The top
graph is the target function to explore (it was built by summing seven normal
densities and one gamma density, and then squaring to produce the sharp
modes). Note that if an MCMC run found itself in either the leftmost or
especially the rightmost mode, it would be quite diﬃcult for it to escape from
that local maximum and ﬁnd the true mode. The second graph is a partially
“heated” version which was created by taking the square root of the original
function. In particular, note how the separation between the two modes on
the left is much diminished so that one can now imagine moving between
those two modes somewhat easily. The third and fourth graphs are again
successively taking square roots, so that the bottom graph is the top graph to
the one-eighth power. In that ﬁnal graph, the locations of the modes are still
clear to the viewer, yet the function is overall becoming close to constant over

160
13 Implicit Computationally Linked Model Overview
the central region of interest, so that an MCMC run would wander across
that whole region, visiting all three modes regularly. This is analogous to
a substance that is raised in temperature until it is melted, so that atoms
or molecules can freely move around. As the substance is cooled, the atoms
gradually fall into place in an orderly fashion, and in Figure 13.1 as the process
is “cooled”, the idea is for an MCMC run to eventually settle into the primary
global mode at 0.3.
0.0
0.2
0.4
0.6
0.8
1.0
0
1
2
3
4
0.0
0.2
0.4
0.6
0.8
1.0
0.0 0.5 1.0 1.5
2.0
0.0
0.2
0.4
0.6
0.8
1.0
0.2
0.6
1.0
1.4
0.0
0.2
0.4
0.6
0.8
1.0
0.4 0.6 0.8 1.0 1.2
Fig. 13.1. The simulated tempering process. The top graph is the target function,
and the lower graphs are successively heated versions which reduce the eﬀect of the
modes and allow better exploration of the function.

13.3 Simulated Sintering
161
Geyer and Thompson (1995) suggest tuning the setup to obtain acceptance
rates of moving between temperatures in the range of 20% to 40%. Such tuning
can be done by adjusting the number of temperatures m, by changing the
temperatures (the inverse powers βj), and by wisely choosing the prior on the
temperatures π(j).
13.3 Simulated Sintering
Simulated tempering uses the concept of temperature to relate the target dis-
tribution to “heated” distributions that are smoother, so that an MCMC run
is more easily able to traverse the space and ﬁnd the global maximum. Sim-
ulated sintering (Liu and Sabatti, 1999) is analogous, except that instead of
deﬁning “hotter” as smoother, hotter is deﬁned as a coarser scale. Thus we
now can see how the whole simulated annealing framework relates to multi-
scale modeling. The target distribution is typically on a relatively ﬁne scale
or grid. Such a high-dimensional process can be diﬃcult to eﬀectively explore
via MCMC, so successively “heated” versions use coarser and coarser grids.
By coarsening, one can often reduce the eﬀects of extrema, thus achieving
a relatively ﬂatter overall distribution (although in this case not necessarily
“smoother”, as the coarser grid tends to lead to sharper peaks and valleys
than the more rounded graphs on ﬁner grids). The term “sintering” is from
metallurgy, where it relates to fractioning material into smaller portions.
A visual demonstration of sintering on the same 1-D function from Fig-
ure 13.1 appears in Figure 13.2, where the top graph is the same target func-
tion and the following graphs show successive coarsening. The coarsening re-
duces the diﬀerences between the modes and the rest of the graph. Thus
increases in “temperature” correspond to coarser grids and thus decreased
dimensionality of the target space.
Simulated sintering drew its inspiration from multigrid methods (see the
next section) and from ideas in Wong (1995), who was one of the ﬁrst in the
statistical literature to propose an auxiliary variable for scale/coarseness as
part of an MCMC run.
Mathematically, sintering is justiﬁed through and serves as just one exam-
ple of group moves for generalized Gibbs sampling and MCMC. In standard
Gibbs sampling, parameters are updated one at a time. The idea of a group
move is to transform a collection of parameters by drawing a joint random
move that leaves the equilibrium distribution invariant. For more details, the
reader is referred to Liu and Sabatti (1999, 2000).
The execution of simulated sintering is analogous to that of simulated
tempering. An auxiliary variable j is created to represent the current scale
of the process, with its space Xj satisfying dim(X1) > dim(X2) > . . . >
dim(Xm). For the space Xj, the unnormalized posterior is given by hj(θj).
Things can be kept simple by choosing a discrete uniform prior over the spaces.
MCMC is then run over the joint space of θ and j. Within a scale, updates

162
13 Implicit Computationally Linked Model Overview
0.0
0.2
0.4
0.6
0.8
1.0
0
1
2
3
4
0.0
0.2
0.4
0.6
0.8
1.0
0
1
2
3
0.0
0.2
0.4
0.6
0.8
1.0
0
1
2
3
0.0
0.2
0.4
0.6
0.8
1.0
0
1
2
3
Fig. 13.2. The simulated sintering process. The top graph is the target function and
lower graphs are successively heated versions which reduce the eﬀect of the modes
and allow better exploration of the function.
for f(θj|j) = hj(θj) are performed with standard moves. For moving between
scales, reversible jump MCMC (Green, 1995) is used, which just includes an
additional Hastings term (Hastings, 1970) that adjusts for the probabilities
of proposals that move between spaces of diﬀerent dimensions. Moves within
and between scales are then alternated until convergence is achieved and the
desired number of posterior samples is drawn.

13.4 Multigrid Methods
163
13.4 Multigrid Methods
Multigrid methods (e.g., Goodman and Sokal, 1989; Briggs et al., 2000) were
originally developed in the physics and applied mathematics literature, pri-
marily for the solution of systems of diﬀerential equations. When such systems
cannot be solved analytically (which is typical of complex systems), they must
be solved numerically. This approach requires setting a grid on the parameter
space over which the solution is found. After that, iterative methods based
on single grid-block updates, such as Jacobi’s algorithm, are used in order
to ﬁnd the solution. Deﬁning the error as the diﬀerence between the correct
solution and the solution at the present iteration, these algorithms are able
to eliminate the high-frequency components of the error. Unfortunately, the
low-frequency components of the error are not eliminated by these single grid-
block update algorithms. Multigrid methods solve this problem by recognizing
that low-frequency components at one resolution level become high-frequency
components at coarser resolution levels. Moreover, coarser grids lead to inac-
curacies in the solution, while ﬁne grids require more computing time than is
available. Thus, multigrid methods cycle between diﬀerent resolution levels,
performing some single-site updates at each level, in order to speed up com-
putations and convergence to an accurate solution. There are several possible
multigrid cycle regimes, the most common of them in applied mathematics
and physics are known as the V and W cycles. The V cycle starts at the ﬁnest
resolution level and progressively moves to coarser resolutions until it reaches
the coarsest resolution level. After that it progressively moves to ﬁner resolu-
tions until it reaches the ﬁnest resolution level. The W cycle corresponds to
the application of two successive V cycles. Other cycle regimes are possible,
such as going only from coarser to ﬁner levels analogously to the estimation
of permeability ﬁelds in Chapter 16, or the grid can be dynamically adjusted,
allowing the solver to move between diﬀerent grids in an attempt to speed the
solution without losing accuracy in the ﬁnal result. This latter approach has
been applied to statistical problems. For example, in the rejoinder to the main
article, Besag et al. (1995, pp. 64–65) use this approach to allow their MCMC
to move between scales when ﬁtting Markov random ﬁeld models to image
data. In that context, multigrid methods become functionally equivalent to
simulated sintering.


14
Metropolis-Coupled Methods
The methods of the previous chapter are useful for employing a multiscale
approach for computational eﬃciency but are not as useful when one is faced
with truly multiscale data. In contrast, the methods in this chapter are equally
useful as a computational tool or for a full analysis of multiscale data. These
methods can be seen as a generalization of simulated sintering, where instead
of having a single chain moving between scales, multiple chains are run so
that there is one (or more) chain at each scale at each point in time. These
chains periodically exchange scales with each other, which allows information
to move across scales but also ensures that we continue to sample at every
scale. This eliminates some of the diﬃculties in posterior inference that can
occur when trying to incorporate samples which are disjoint in time. In par-
ticular, simulated sintering produces a single MCMC run over the joint space
of the parameters and the scale, but for any particular scale, there will only
be MCMC samples at unconnected intervals.
14.1 Metropolis Coupling
The concept of Metropolis coupling was introduced by Geyer (1991) to im-
prove mixing, although in the context of a standard MCMC run at a single
scale (Barone et al., 2002). Coupling was later used in other contexts, such as
diagnosing convergence (e.g., Johnson, 1998). For more context in one of the
original intended uses of Metropolis coupling, see Section 14.3 below. In this
chapter, we will follow the ideas of Higdon et al. (2002) in applying coupling
to multiscale problems.
The basic idea of Metropolis coupling is to have chains running in paral-
lel using standard MCMC updates (Gibbs sampling or Metropolis-Hastings
techniques as appropriate). Periodically, these chains then propose to swap
information in the sense of exchanging some or all of their parameter values.
This step is done via the Metropolis-Hastings algorithm. We illustrate this
here in the case of just two chains. Denote the parameter values of the ﬁrst

166
14 Metropolis-Coupled Methods
chain by θ0 and those of the second chain by θ1, where these could be vector-
valued in multivariate problems. We use an additional subscript in parentheses
to indicate the iteration number; e.g., θ1(1) is the value of θ1 at the ﬁrst iter-
ation, and θ1(4) is its value at the fourth iteration. A schematic illustration of
the process is
θ0(1)
MCMC
−→
θ0(2)
θ1(1)
MCMC
−→
θ1(2)
SWAP
−→θ0(3)
MCMC
−→
θ0(4)
θ1(3)
MCMC
−→
θ1(4)
SWAP
−→θ0(5)
MCMC
−→
· · ·
θ1(5)
MCMC
−→
· · ·
Here the arrows labeled
MCMC
−→are standard within-chain updates (one or
more iterations), and the arrows labeled
SWAP
−→are updates that propose swap-
ping information across chains. Technically, what is going on is that a single
(yet complicated) multivariate chain is being run on the joint space of (θ0, θ1).
The standard updates deal with θ0 and θ1 independently, as if two separate
chains were being run. However, these updates can also be viewed as sequen-
tial updates in a single joint chain, where the two components happen to be
independent. The swap steps then tie the two otherwise independent chains
together.
To make this concrete, we take a simple example. Suppose we have data
{y1, . . . , yn} which are a random sample from a normal distribution with un-
known mean µ and variance σ2. The likelihood is
f(y|µ, σ2) = (2πσ2)−n/2 exp
,
−1
2σ2
n

i=1
(yi −µ)2
-
.
Denote the prior for the parameters as π(µ, σ2), which could be the standard
independent noninformative conjugate prior but could also be any other prior.
One prior that could cause sampling issues would be π(µ, σ2) = (exp{−(µ −
3)2 −(µ + 3)2})/

(2π)σ2, which has µ and σ2 a priori independent, puts
a standard noninformative prior on σ, and puts a mixture prior on µ with
highly separated masses at 3 and −3. This sort of prior could lead to a highly
bimodal posterior (for example, if there aren’t that many data points and
they have a mean near zero). The posterior is f(µ, σ2|y) ∝f(y|µ, σ2)π(µ, σ2),
which could be sampled via Gibbs sampling for certain forms of π or else with
Metropolis-Hastings algorithm in the general case. If one tried to use standard
Metropolis-Hastings techniques with a bimodal posterior (such as the example
above), then the Markov chain would be likely to get stuck in one of the two
modes. One solution is to use a Metropolis-coupled chain. Start by creating
two separate MCMC runs, one with (µ0, σ2
0) and the other with (µ1, σ2
1), and
start them near separate modes of the posterior. Each chain can be updated
independently in the beginning, with both using identical formulas for the
likelihood and prior. Periodically, a swap step is made which proposes setting
the new value for µ0 (denoted µ∗
0) to be the current value of µ1 and the new
value for µ1 (denoted µ∗
1) to be the current value for µ0. This is a simple
Metropolis proposal, which is accepted with probability

14.2 Multiscale Metropolis Coupling
167
f(y|µ∗
0, σ2
0)π(µ∗
0, σ2
0)f(y|µ∗
1, σ2
1)π(µ∗
1, σ2
1)
f(y|µ0, σ2
0)π(µ0, σ2
0)f(y|µ1, σ2
1)π(µ1, σ2
1)
= f(y|µ1, σ2
0)π(µ1, σ2
0)f(y|µ0, σ2
1)π(µ0, σ2
1)
f(y|µ0, σ2
0)π(µ0, σ2
0)f(y|µ1, σ2
1)π(µ1, σ2
1) ,
(14.1)
or with probability 1 if this ratio is larger than 1 (this condition is always
implied if unstated). If the priors for µ and σ2 are independent (i.e., π(µ, σ2) =
π(µ)π(σ2)), then the swap acceptance probability (14.1) reduces to
f(y|µ1, σ2
0)f(y|µ0, σ2
1)
f(y|µ0, σ2
0)f(y|µ1, σ2
1)
because all the terms in the prior cancel. Note that the proposal is deter-
ministic and reversible, so we do not need to include the Hastings term in the
probability. If we now marginalize out µ1 and σ2
1, we get a posterior sample for
µ0 and σ2
0 that has fully explored both modes of the posterior. Marginalizing
is trivial, as we can simply discard all of the µ1 and σ2
1 values.
In this particular example, we swap only the µ values. If we had swapped
both µ and σ, then the swap would always be accepted. But the resulting
chain would be essentially the same as running two chains independently,
as the likelihoods and priors are the same for each chain. Of course, this is
merely an illustrative example. There are more eﬃcient ways of exploring a
multimodal posterior such as this. We have gone over these details to make the
concept clear, and in the next section we apply this approach to the multiscale
setting.
14.2 Multiscale Metropolis Coupling
Following Higdon et al. (2002), we now expand the original idea of Metropolis
coupling to multiscale problems. We consider ﬁrst just two scales, a coarse
scale and a ﬁne scale. Let θ0 be the parameters at the coarse scale, with
likelihood f(y0|θ0), and let θ1 be the parameters at the ﬁne scale, with cor-
responding likelihood f(y1|θ1). In some cases, such as the hydrology example
in Chapter 16, the data will be the same at all scales (i.e., y0 = y1), and it is
the parameters that are of interest at diﬀerent scales. In other cases, we will
actually observe diﬀerent data at diﬀerent scales, and in yet other cases, we
may only observe data at the ﬁnest scale and may compute a coarser dataset
from the ﬁne data. The coarse and ﬁne parameter spaces may also be the
same or diﬀerent, depending on the problem. Denote the respective priors by
π(θ0) and π(θ1).
A pictorial representation of the resulting algorithm is
(θ0)1
MCMC
−→
(θ0)2
(θ1)1
MCMC
−→
(θ1)2
SWAP
−→(θ0)3
MCMC
−→
(θ0)4
(θ1)3
MCMC
−→
(θ1)4
SWAP
−→(θ0)5
MCMC
−→
· · ·
(θ1)5
MCMC
−→
· · ·

168
14 Metropolis-Coupled Methods
Again, we create independent chains at the coarse and ﬁne levels, and start
with standard within-scale MCMC updates. Periodically we now propose to
swap information between the two scales. The exact swapping mechanism will
depend on the particular problem. The general idea is to move the information
about the current ﬁt at the coarse level to the ﬁne level and vice versa. This
may involve directly swapping the values of the parameters at the two scales
if the parameter spaces are the same size and have the same interpretation
(as with the convolution example below). Otherwise, a transformation of the
parameters will be necessary to create a realistic proposal across the scales (as
with the Markov random ﬁeld models below). The probability of accepting
the swap proposal is thus
f(y0|θ∗
0)π(θ∗
0)f(y1|θ∗
1)π(θ∗
1)q(θ0, θ1|θ∗
0, θ∗
1)
f(y0|θ0)π(θ0)f(y1|θ1)π(θ1)q(θ∗
0, θ∗
1|θ0, θ1),
(14.2)
where θ∗is the proposed value for each scale and q(θ∗
0, θ∗
1|θ0, θ1) is the density
function for the generation of the proposed values (θ∗
0, θ∗
1) given the current
values (θ0, θ1). In the simple example of the previous section, this was a
deterministic function, so its value was always 1. We must also take care to
make sure that this proposal distribution q is reversible (as for all MCMC),
so that the term in the denominator is always nonzero.
In many cases, the formula above can be simpliﬁed based on the particular
form of the likelihood, prior, and swap proposal. In the next section, we illus-
trate this algorithm on the Fraser River data introduced in Chapter 3. The
model used here is the Gaussian process convolution approach, described in
more detail in Chapter 4. A single-resolution Gaussian process is ﬁt at each
scale. This approach has several key features that allow for simpler implemen-
tation.
A second class of models that are amenable to this multiscale approach are
Markov random ﬁelds. Section 14.2.2 discusses the implementation of these
models, and additional examples appear in Sections 15.4 and 16.3.
14.2.1 Swapping with Convolutions
One approach is to model the data with a Gaussian process, and to use convo-
lutions to ﬁt this model. The convolution concept was introduced in Chapter 4.
Here we use a simple (single-scale) convolution at each scale. By putting the
two datasets on comparable grids, the same kernel width and same latent
process locations can be used, simplifying the swapping mechanism.
Working with the seasonally detrended log river data, the monthly ﬂow av-
erages are {y11, . . . , y1n1}, and we also use quarterly averages {y01, . . . , y0n0}.
To keep the example simple, we will use only the ﬁrst three years of the data,
and hence n1 = 36 and n0 = 12. We consider y1 to be observed at the loca-
tions s1 = {1, 2, . . . , n1} and y0 to be observed at s0 = {2, 5, 8, . . . , 35}. Latent
processes w0 and w1 are then deﬁned on the grid t = {−1, 2, 5, 8, . . . , 35, 38},

14.2 Multiscale Metropolis Coupling
169
and these processes are convolved with Gaussian kernels k with standard de-
viation 3, k(tj −si) = exp{−(tj −si)2/18}/
√
18π. The same grid of nw = 14
points and the same kernels are used on both scales. The ﬁtted process is thus
ˆyri = ˆyr(sri) =
nw

j=1
k(tj −sri)wrj
(14.3)
for either the coarse scale (r = c) or the ﬁne level (r = f). We take an
iid Gaussian likelihood at each scale, with respective variances σ2
0 and σ2
1.
However, it turns out it will be easier to work with precisions, which are
the reciprocals of the variances, so we will use τ0 = 1/σ2
0 and τ1 = 1/σ2
1.
During MCMC, the precision τ is updated via Gibbs sampling, as its complete
conditional is a gamma distribution, while the variance σ2 has a complete
conditional that is an inverse-gamma and is thus a little more diﬃcult to
work with, and it would be a little bulkier in the already long equations that
follow below. Thus, using precisions, the likelihoods at each scale are
f(y0|w0, τ0) =
 τ0
2π
n0/2
exp
,
−τ0
2
n0

i=1
(y0i −ˆy0i)2
-
,
f(y1|w1, τ1) =
 τ1
2π
n1/2
exp
,
−τ1
2
n1

i=1
(y1i −ˆy1i)2
-
.
Note that the ˆy terms are deterministic transformations of the appropriate w,
as given by Equation (14.3). Next, we put a prior on the latent wi terms, each
being iid Gaussian with mean zero and precision either λ0 or λ1, for the coarse
and ﬁne scales. Finally, we can either set these precisions to ﬁxed values or can
use a hierarchical structure and put priors on them. In a hierarchical setup,
gamma priors will allow Gibbs sampling, so they are the obvious choice. One
possibility is to use common hyperpriors for the scales,
τ0 ∼Γ(ατ, βτ),
τ1 ∼Γ(ατ, βτ),
(14.4)
λ0 ∼Γ(αλ, βλ),
λ1 ∼Γ(αλ, βλ),
and then ατ, αλ, βτ, and βλ are constants that need to be speciﬁed. In this
example, we use fairly weak priors (small α) with ατ = αλ = 1, βτ = 0.005,
and βλ = 1000, i.e., τ0 and τ1 have exponential priors with mean 200. This
speciﬁcation encourages the process to ﬁt the data with only some smoothing
and allows large ﬂexibility in the latent process.
With this setup, the swap maneuver is quite straightforward. We basically
propose exchanging all values of w0 and w1. Both scales use a latent process
on the same grid, so these latent values have a common interpretation.

170
14 Metropolis-Coupled Methods
The diﬀerence in the scales is from diﬀerent discretizations of the convolved
processes, both of which are in reality continuous processes. With such a swap
proposal, the q term in Equation (14.2) is just 1. The τ terms are not part of
the swap. If the same priors are used for the latent processes at both scales
(i.e., λ0 = λ1), those terms also drop out of the equation, and thus the prob-
ability of accepting the swap is
f(y0|w1, τ0)f(y1|w0, τ1)
f(y0|w0, τ0)f(y1|w1, τ1) .
In some cases, these swaps may have a low probability of acceptance be-
cause the resulting ﬁts are a little worse at both scales before they have a
chance to settle down. It can then help to resample both τ terms as part
of the swap proposal. The new proposal for τ is best chosen using the same
Gibbs sampler that is being used for the standard τ updates. For example,
using the hierarchical prior speciﬁed in Equation (14.4), the complete condi-
tional distribution for τ0 is a gamma distribution with parameters ατ + n1/2
and βτ + SSx/2, where SSx is the sum of squared diﬀerences between the
observed data y and the ﬁtted values ˆy. However, this is not a Gibbs step
because it is now just another piece of the multivariate swap, so it needs to be
part of the sampling probability in the Metropolis-Hastings ratio, and it ap-
pears as the q terms below. Denoting the proposed values as τ ∗, the resulting
acceptance probability is now
f(y0|w1, τ ∗
0 )π(τ ∗
0 )f(y1|w0, τ ∗
1 )π(τ ∗
1 )q(τ0|w0)q(τ1|w1)
f(y0|w0, τ0)π(τ0)f(y1|w1, τ1)π(τ1)q(τ ∗
0 |w1)q(τ ∗
1 |w0) .
If a hierarchical prior (such as in Equation (14.4)) is used so that the latent
processes have diﬀerent hyperparameters λ0 and λ1, then these also need to
be taken into account and can be redrawn as well. Again, it can be helpful
to use a Gibbs-style draw to produce the proposal. This setup results in the
acceptance probability
f(y0|w1, τ ∗
0 )π(τ ∗
0 )q(τ0|w0)f(y1|w0, τ ∗
1 )π(τ ∗
1 )q(τ1|w1)
f(y0|w0, τ0)π(τ0)q(τ ∗
0 |w1)f(y1|w1, τ1)π(τ1)q(τ ∗
1 |w0)
×
π(w1|λ∗
0)π(λ∗
0)q(λ0|w0)π(w0|λ∗
1)π(λ∗
1)q(λ1|w1)
π(w0|λ0)π(λ0)q(λ∗
0|w1)π(w1|λ1)π(λ1)q(λ∗
1|w0) .
Note that the term π(w1|λ∗
0) is the result of moving the latent process from
the ﬁne scale to the coarse scale, resampling λ0 from the distribution q(λ∗
0|w1)
to get a proposed value λ∗
0, and then evaluating the prior for the latent process
(on the coarse scale, with the values obtained from the ﬁne scale, and using
this newly proposed λ∗).
For the Fraser River example with the hierarchical prior above, after can-
celling out various normalizing constants, the swap acceptance ratio is

14.2 Multiscale Metropolis Coupling
171
(τ ∗
0 )n0/2 exp
#
−
τ∗
0
2 SS∗
y0
$
(τ ∗
0 )ατ −1exp{−βτ τ ∗
0 }(τ0)(ατ +n0/2)−1exp{−(βτ+SSy0/2)τ0}
(τ0)n0/2 exp{−τ0
2 SSy0}(τ0)ατ −1exp{−βτ τ0}(τ ∗
0 )(ατ +n0/2)−1exp{−(βτ+SS∗
y0/2)τ ∗
0 }
×
(τ ∗
1 )n1/2exp
#
−
τ∗
1
2 SS∗
y1
$
(τ ∗
1 )ατ−1exp{−βτ τ ∗
1 }(τ1)(ατ +n1/2)−1exp{−(βτ+SSy1/2)τ1}
(τ1)n1/2exp{−τ1
2 SSy1}(τ1)ατ−1exp{−βτ τ1}(τ ∗
1 )(ατ +n1/2)−1exp{−(βτ+SS∗
y1/2)τ ∗
1 }
×
(λ∗
0)nw/2exp
#
−
λ∗
0
2 SSw1
$
(λ∗
0)αλ−1exp{−βλλ∗
0}(λ0)(αλ+nw/2)−1exp{−(βλ+SSw0/2)λ0}
(λ0)nw/2exp5
−λ0
2 SSw0
6
(λ0)αλ−1exp{−βλλ0}(λ∗
0)(αλ+nw/2)−1exp{−(βλ+SSw1/2)λ∗
0}
×
(λ∗
1)nw/2exp
#
−
λ∗
1
2 SSw0
$
(λ∗
1)αλ−1exp{−βλλ∗
1}(λ1)(αλ+nw/2)−1exp{−(βλ+SSw1/2)λ1}
(λ1)nw/2exp5
−λ1
2 SSw1
6
(λ1)αλ−1exp{−βλλ1}(λ∗
1)(αλ+nw/2)−1exp{−(βλ+SSw0/2)λ∗
1} ,
where SSy0 = n0
i=1 (y0i −ˆy0i)2 and SS∗
y0 = n0
i=1 (y0i −ˆy∗
0i)2, and ˆy0 is
given by Equation (14.3) and is a function of w0, while ˆy∗
0 is a function of w1.
Similarly, SSw0 = nw
j=1 w2
0j. The corresponding quantities for the ﬁne scale
are deﬁned analogously. Careful inspection shows that this ratio is exactly
equal to 1 (because in each case q ∝fπ), so that these swaps are always
accepted, but it is displayed as above so the reader can easily see where all of
the terms come from, and how one would modify it for a diﬀerent setup where
it may not be so easy to sample from the complete conditional, such as with
the Markov random ﬁelds in the next section. But, in the present case, the
swaps are accepted with probability 1, improving the mixing of the Markov
chain.
Figure 14.1 shows the results of running our R code (available at
http://www.ams.ucsc.edu/~herbie/multiscale) for Metropolis coupling
on the ﬁrst three complete years of the detrended Fraser River data. The
data are shown as the circles, with open circles for the original (ﬁne scale)
data and solid circles for the quarterly averages (coarse scale). Vertical dashed
lines show the locations of the latent process. The solid line is the posterior
mean ﬁtted curve at the ﬁne scale, and the middle dash-dot line is the ﬁtted
curve at the coarse scale. Both curves are quite similar; 95% credible inter-
vals are shown as the dashed (ﬁne scale) and dotted lines (coarse scale). This
problem is not too complex, and the interval estimates are also similar at
both scales. Note that, under the Bayesian approach, uncertainty estimates
are automatically available as a result of having ﬁt the model with MCMC,
and are available at all scales.
One of the key beneﬁts of Metropolis coupling is improved mixing and
posterior exploration. One possible measure of mixing is the autocorrelation of
elements of the Markov chain or derived quantities (Sokal, 1987). This problem
is fairly simple, so we won’t be able to show any drastic improvements. A
more dramatic improvement appears in the hydrology example in Chapter 16.
Here we show a more modest but still noticeable improvement. Figure 14.2
shows the autocorrelation plots for one of the latent process values at the ﬁne
(original) scale, with a single-resolution run (at the ﬁne scale only) on the left
and the Metropolis-coupled run on the right. Notice how the autocorrelations
die out more quickly using Metropolis coupling, in that the correlation at lag

172
14 Metropolis-Coupled Methods
0
5
10
15
20
25
30
35
−0.6
−0.4
−0.2
0.0
0.2
0.4
0.6
1−d Coarse & Fine (Metropolis−coupled Bayes) [with pred]
ll$s
df$y
Fig. 14.1. Fitted values and conﬁdence bands for the Fraser River data. Open
circles are the original data, solid circles are quarterly averages, the solid line is the
posterior mean ﬁtted curve at the ﬁne scale, and the middle dashed line is the ﬁtted
curve at the coarse scale; 95% credible intervals are shown with dashed lines for the
ﬁne scale and dotted lines for the coarse scale.
one is smaller, and the correlation at lag two is nearly zero and well below
the standard error line. We could claim that the correlation range has been
reduced by one-half, although this is really just from two lags to one. While it
is true that autocorrelation is not necessarily the optimal measure of mixing,
it is an easily obtainable and relatively intuitive measure. The point here is
that there is a reduction in autocorrelation, and that this reduction can be
pronounced in more complex situations.

14.2 Multiscale Metropolis Coupling
173
0
2
4
6
8
0.0
0.2
0.4
0.6
0.8
1.0
Lag
Fine scale Only
Metropolis−Coupled
ACF
0
2
4
6
8
0.0
0.2
0.4
0.6
0.8
1.0
Lag
ACF
Fig. 14.2. Autocorrelation plots for a latent value.
14.2.2 Swapping with Autoregressive Processes
For spatial data, an alternative to a Gaussian process model is a Markov
random ﬁeld (MRF), and these were introduced in Section 2.1. While the
Gaussian process models were easy to deal with at diﬀerent scales because the
underlying parameters were the same (specifying a continuous process that
was merely discretized at diﬀerent scales but always had the same parameter
dimension), an MRF speciﬁes the process over a grid and thus must specify
a value for each grid cell. Thus, if a ﬁne scale has twice as many grid cells
in each dimension, then the number of parameters will increase by a factor
of 2 for each dimension. For the sake of illustration, we will discuss a two-
dimensional process here, as the examples that appear in Sections 15.4 and
16.3 are two-dimensional. So if the coarse scale is a 32 × 32 grid and the ﬁne
scale is a 64 × 64 grid, there are four times as many parameters at the ﬁne
scale than at the coarse scale, and thus there is a four-to-one correspondence
that must be dealt with when swapping across scales.
Here the MRF could be either proper as in Section 10.1, or it could be in-
trinsic and thus not strictly stationary (because its mean level is not deﬁned).

174
14 Metropolis-Coupled Methods
Because the examples use intrinsic ﬁelds, as well as the fact that intrinsic
ﬁelds result in simpler notation, we focus on the intrinsic case in the rest of
this section. The basic model for a ﬁrst-order intrinsic Gaussian MRF at a
single scale is deﬁned as values xj over a prespeciﬁed grid,
π(x|β) ∝β
m
2 exp
⎧
⎨
⎩−1
2β

i∼j
(xi −xj)2
⎫
⎬
⎭= β
m
2 exp

−1
2βxT Hx

,
(14.5)
where β is a smoothing parameter, m is the total number of grid cells, and
i ∼j speciﬁes that grid cells i and j are neighbors. In two dimensions, interior
cells will have four neighbors, edge cells three, and corner cells two. In one
dimension, a cell would have only one or two neighbors. In matrix notation,
the precision matrix H contains oﬀ-diagonal entries hij = −1 if pixel i is
adjacent to pixel j and 0 otherwise, and diagonal elements hii equal to the
number of neighbors of pixel i.
In order to create the correspondence between scales, we work with the
means of equivalent blocks. Thus, when moving between scales, we consider
a joint move between four ﬁne cells and the one corresponding coarse cell
(in the two-dimensional case), and we keep the mean of the four ﬁne cells
equal to the mean of the corresponding coarse cell (which is just its value).
This formulation makes the swap proposal from the ﬁne to the coarse levels a
deterministic proposal, x∗
0i = 1
4

j∈Ji x1j, where Ji is the set of indices of the
four ﬁne cells that correspond to the ith coarse cell. The full proposal is then
the collection of the subproposals for each of the individual cells; i.e., for each
cell at the coarse scale, its proposed value is found by averaging the current
values of the four corresponding ﬁne cells.
One possible proposal for going from the coarse to the ﬁne scale would be
to deterministically set all four corresponding ﬁne cells to be the value of the
current coarse cell. While conceptually simple, this tends not to work as well
in practice because the resulting ﬁne scale has a very blocky behavior and is
unlikely to be consistent with the MRF prior at the ﬁne scale (which expects
the variability between adjacent cells to be at a more constant level, rather
than some neighbors taking identical values and some taking very diﬀerent
values). If the proposal is not consistent with the prior, then the prior term
in the Metropolis-Hastings acceptance probability will be very small and the
proposal will be rejected. In order to rectify this situation, a more complex
and more smooth proposal is needed.
The approach of Higdon et al. (2002) is to sequentially draw ﬁne cell
proposals from the prior distribution conditioned on the blocks of four having
a mean matching the current corresponding coarse cell. These draws are done
block-by-block, with the other blocks being held ﬁxed, either at temporary
values before they are updated, or using the updated values after they have
been drawn. For the MRF speciﬁcation, conditioned on the other blocks, the
draw for the four cells in a block is a multivariate normal restricted to have a

14.3 Sequential Parallel Tempering
175
particular mean. In the two-dimensional case, this would be a degenerate four-
dimensional draw, or equivalently a three-dimensional multivariate normal. To
be speciﬁc, the steps for creating the ﬁne proposal are as follows:
1. Set the temporary value of each cell x∗
1j in a ﬁne block of four equal to
the corresponding coarse value x0i.
2. Repeat step 1 for all of the cells at the ﬁne level.
3. For each ﬁne block, draw a random sample from the MRF prior distribu-
tion conditioned on the block having the ﬁxed mean, and conditioned on
the currently proposed values of the neighboring cells from all neighboring
blocks.
4. Repeat step 3 for each of the ﬁne blocks, so that the original temporary
values are sequentially replaced by these multivariate draws.
This process will create an entire ﬁne ﬁeld x∗
1.
As with the Gaussian process speciﬁcation, it is usually also helpful to
include new proposals for the precision parameters β1 and β0, and these can
be drawn from their complete conditional distributions using the proposed
values x∗
1 and x∗
0. This joint proposal of (x∗
1, x∗
0, β∗
1, β∗
0) is then accepted or
rejected according to the standard Metropolis-Hastings probability of
f(y0|x∗
0, β∗
0)π(x∗
0|β∗
0)π(β∗
0)f(y1|x∗
1, β∗
1)π(x∗
1|β∗
1)π(β∗
1)q(x1|x∗
0, β∗
1)q(β0|x0)q(β1|x1)
f(y0|x0, β0)π(x0|β0)π(β0)f(y1|x1, β1)π(x1|β1)π(β1)q(x∗
1|x0, β1)q(β∗
0|x∗
0)q(β∗
1|x∗
1) .
Because the coarse proposal is a deterministic function of the current ﬁne
values, the q terms are equal to 1 and are omitted. If the likelihood or prior are
more complex, further parameters can be included as in the previous section.
More details on this procedure can be found in Higdon et al. (2002). Examples
can be found in Chapter 17 for the SPECT data, in the context of Metropolis-
coupled swaps and genetic-algorithm style swaps, and in Section 16.3 in the
hydrology case study.
14.3 Sequential Parallel Tempering
Similar algorithms have been developed independently under the name of
sequential parallel tempering (Liang, 2003). In the next paragraph, we discuss
parallel tempering, before moving on to the sequential version. As a side note,
in ﬁtting with the discussion of this chapter and the previous one, perhaps
“parallel sintering” would have been a more descriptive name than sequential
parallel tempering.
Parallel tempering (Geyer, 1991) extends the ideas of simulated tempering
(from Section 13.2) to use multiple Markov chains simultaneously. The tem-
pering ladder of functions at m diﬀerent temperatures is set up, and instead
of running a single chain that moves between the temperatures via an aux-
iliary variable, one chain is run at each temperature. Thus again one has a
Markovian system over the joint space of the parameters and the temperature

176
14 Metropolis-Coupled Methods
scale, but in this case there are m nominally independent chains running
in parallel. The system of chains alternates between independent within-
temperature updates and Metropolis-coupled updates across temperatures.
These Metropolis-coupled updates are completely analogous to those de-
scribed earlier in this chapter for moving between scales. Through this cou-
pling, mixing is often greatly improved, allowing escapes from local maxima
and better posterior exploration. As the chains are asymptotically indepen-
dent, if one is only interested in the coolest distribution, one can just take
the corresponding chain, discarding the others, and base posterior inference
on the samples from that chain.
Sequential parallel tempering (Liang, 2003) goes one step further, com-
bining multigrid/sintering methods with parallel tempering. The idea is to
deﬁne a sequence of spaces of reduced dimension {Xi} such that dim(X1) >
dim(X2) > . . . > dim(Xm). Choosing the Xi to be diﬀerent scales is the obvi-
ous application here, although the algorithm is more broadly applicable (for
example, dimension reduction via marginalization). In the context of multi-
scale modeling, by choosing the Xi to be diﬀerent scales, the algorithm is func-
tionally equivalent to the Metropolis-coupled methods previously discussed in
this chapter.
14.4 Extensions
The swapping methods in this chapter are quite ﬂexible, being readily ap-
plicable to a wide variety of situations. While the examples here were one-
dimensional cases, the approach is equally useful in higher dimensions. Higdon
et al. (2002) use Markov random ﬁelds, which is a generalization of the au-
toregressive model. Higdon et al. (2003) look at convolution models in higher
dimensions.
It is also straightforward to extend this approach to more than two scales.
An initially independent chain is set up at each scale, and then swaps are pro-
posed between chains. When dealing with more than two scales, it is usually
best to restrict swap proposals to adjacent scales, as those scales farther apart
will tend to lead to low acceptance probabilities.
While the Metropolis-coupled algorithms were introduced with only a sin-
gle chain at each scale, one could just as easily run multiple chains at each
scale, as with parallel tempering or sequential parallel tempering. Having more
such chains can be particularly beneﬁcial in multiscale multimodal problems,
just as with single-scale multimodal problems. The main restriction here is
computer time.
As a ﬁnal note, these algorithms are ideal for parallel computing environ-
ments. The chains are run mostly independently, with only occasional swap-
ping interactions. The amount of information that has to be passed between
processes is fairly small, usually just the set of relevant parameter values. Most

14.4 Extensions
177
of the computational work can be done by the processors independently, lead-
ing to a highly eﬃcient use of a parallel environment.


15
Genetic Algorithms
This chapter starts by reviewing the key ideas of genetic algorithms and then
demonstrates how to use them in a multiscale setting. The direct extension
to multiscale modeling is useful for maximization. However, these multiscale
ideas can also be extended to the Bayesian framework in combination with
Markov chain Monte Carlo ideas. The resulting approach can then be seen as
a generalization of the Metropolis-coupled methods of the previous chapter.
This combination is a powerful method for fully Bayesian multiscale modeling,
particularly in a parallel computing environment. Compared with the methods
in the previous two chapters, the key extension of this chapter is to allow the
swapping across scales (or “temperatures”) of only part of the information in
the chains instead of requiring the entire current state of the chain to move
between scales. This adaptation can improve the probability of accepting a
swap in complicated problems and thus further improve the mixing of the
chains.
15.1 The Basics of Genetic Algorithms
Genetic algorithms were developed as a general maximization technique that
was inspired by biological evolution. Maximization of a function with a higher-
dimensional input parameter vector can be quite diﬃcult when the function
has many local maxima (i.e., it is multimodal). Genetic algorithms have been
found to be one of the best methods for dealing with such complicated prob-
lems.
The concept in nature is that well-adapted organisms are more likely to
survive and pass their genes on to the next generation. In each generation,
there is the possibility of some random genetic mutations, and in the process of
reproduction there is mixing and redistribution of genetic material. Over time,
the genes which result in traits that are helpful for survival and reproduction
(genes with high “ﬁtness”) will tend to dominate. This concept is then applied
to the numerical maximization setting by thinking of a vector of parameter

180
15 Genetic Algorithms
values as a chromosome of genes and by deﬁning genetic ﬁtness as the result
of evaluating the function at those parameter values. A collection of these
chromosomes is randomly mutated and mixed via transformations analogous
to biological ones, as explained below. The collection is then culled, with those
of higher ﬁtness being more likely to be kept. This process is repeated and will
converge to one or more local maxima, often including the global maximum
even in diﬃcult multimodal settings.
Early versions of the genetic algorithm (Holland, 1975) dealt with discrete
parameter spaces with a relatively small number of possibilities, analogous to
the biological setting where there are only four genetic bases. Later versions
generalized this approach to real-valued parameters, which is also the primary
interest for this book. Here we outline the basics of such algorithms. For more
details, the reader is referred to Chatterjee et al. (1996) and the references
therein, which provide an overview of the concepts as well as descriptions of
applications in the ﬁeld of statistics.
Suppose we wish to maximize some function g(v), where v is a vector
(v1, . . . , vR) and R is the number of parameters. g(v) is thus taken as the
measure of ﬁtness. To initialize the algorithm, we need to create a population
of solutions (analogous to chromosomes) each of which is represented as a vec-
tor of length R. For example, a population of solutions v1
(0), . . . , vM
(0) could be
created by randomly selecting M vectors of length R from some distribution.
Here, the subscript in parentheses denotes the iteration number within the
algorithm. Ordinarily, R is determined by the problem, but M, the number
of solutions, may be chosen by the user. One cycle of the algorithm is com-
prised of three steps based on the biological analogy: selection, crossover, and
mutation.
Selection: Mimicking biological natural selection, in the selection step, the
population of solutions is culled to potentially remove poorer solutions
while generally allowing better solutions to remain. Recall that the goal
of the genetic algorithm is to maximize the ﬁtness g(v). The selection
step proceeds by drawing M vectors with replacement from the current
population of solutions to form a new population. If g(·) is nonnegative,
solution vectors are selected with probabilities proportional to their ﬁt-
nesses, g(v). Thus, for one solution vi
(t), its probability of being selected
is g(vi
(t))/ M
j=1 g(vj
(t)). In this way, solutions with a higher ﬁtness have a
larger probability of being selected and moving through to the next cycle.
If g(·) is not a nonnegative function, then it is typically transformed to
be so, such as through exponentiating, exp(g). This one-to-one monotone
transformation is then used as the ﬁtness function.
Crossover: The crossover step is drawn from the idea of pairs of chro-
mosomes swapping genetic material by having them exchange segments
which are located at the same positions on both chromosomes. To perform
a crossover, several pairs of solutions (up to M/2 pairs) are selected and

15.1 The Basics of Genetic Algorithms
181
some of their values are traded. It has been recommended that for each
pair, the probability of performing a trade should be tuned to be between
0.6 and 0.95 (see B¨ack, 1993, and the references therein). If a pair is se-
lected to perform a trade, then one of several types of crossovers may be
performed. In a one-point crossover, a single element is chosen randomly
from {1, . . . , R−1} and all elements after the chosen element are swapped.
The following diagram depicts a one-point crossover between v1
(t) and v2
(t)
when the element z∗is chosen. The subscript denoting the iteration, (t),
is suppressed within the expanded vectors for clarity.
v1
(t) = {v1
1, ..., v1
z∗, v1
z∗+1, ..., v1
R}
v2
(t) = {v2
1, ..., v2
z∗, v2
z∗+1, ..., v2
R}
Partial
−→
Swap
v1
(t+1) = {v1
1, ..., v1
z∗, v2
z∗+1, ..., v2
R}
v2
(t+1) = {v2
1, ..., v2
z∗, v1
z∗+1, ..., v1
R}
This particular style of crossover is called a single-point crossover. Some
additional types of crossovers are discussed below.
Mutation: Following the random mutations that occur in nature, the muta-
tion step randomly perturbs each element of each vector in the population
of solutions with some small mutation probability. For instance, using a
probability of mutation 0.01, in each cycle on average 0.01 × M × R ele-
ments would be altered. When working with real-valued vectors, mutation
is typically performed by adding independent Gaussian noise to the se-
lected elements.
These three steps are repeated until a prespeciﬁed measure of convergence
is satisﬁed. Typical convergence criteria include: no change in maximum ﬁt-
ness over multiple iterations; the most ﬁt solution obtains a ﬁtness above a
threshold level; or the number of iterations reaches a preestablished limit.
The crossover step as described above is for a single-point crossover, as
directly inspired by genetics, where a single element is chosen and the solutions
“cross over” at that point, swapping their remaining sections. A number of
alternative styles of crossovers have been proposed; for example:
k-point crossover: k elements are chosen and segments between the chosen
elements alternate between swapping and not swapping.
Uniform crossover: A swapping probability is chosen, and then each ele-
ment is swapped individually with this probability.
Snooker crossover: Introduced by Liang and Wong (2001), this crossover
move is intended to improve mixing by moving along directions of two
solutions rather than merely exchanging solutions, and is based on the
snooker algorithm (Roberts and Gilks, 1994). The steps of the crossover
are as follows.
1. Select one solution, vi, chosen with equal probability from the popu-
lation.

182
15 Genetic Algorithms
2. Select another solution, vj, from the remaining population with prob-
abilities proportional to the ﬁtness of the solutions.
3. Deﬁne e = (vj −vi)/||vj −vi|| and then sample u ∈(−∞, ∞) from
the density f(u) ∝|u|R−1π(vj + ue), where π is the prior for the
parameters.
4. Let ˜v = vj + u e and replace vi with ˜v in the population of solutions.
For the rest of this chapter, we will concentrate on single-point crossovers (for
their simplicity) and uniform crossovers (as we have found they most help
improve mixing in complex problems).
Several modiﬁcations to the basic genetic algorithm have been proposed
to speed up convergence. One that we have found helpful is the elitist strategy
(DeJong, 1975), where the solution with the highest ﬁtness value is automati-
cally retained after the mutation step; i.e., if the crossover and mutation steps
cause the previously best solution to be worse, and no better solution arises,
then the element with lowest ﬁtness is immediately discarded and replaced by
the previously best solution (so that it remains as the best solution).
15.2 Multiscale Genetic Algorithms
The form of the algorithm described above is suited only to solving problems
for which all considered solutions have the same dimension, which is true in
most problems but not generally true in multiscale problems. An early at-
tempt to overcome the ﬁxed solution length limitation was by Goldberg et al.
(1989), who introduced a variable string length genetic algorithm. Their algo-
rithm allows for solution representations of varying sizes in order to facilitate
maximization. Although this algorithm only solves problems where the ﬁnal
solution is of a ﬁxed dimension, it does demonstrate the utility of allowing
diﬀerent solution representations within the algorithm. The algorithm we de-
scribe here appeared in Holloman (2002) and Holloman et al. (2006) and was
developed to extend the original genetic algorithm by making use of related
solutions of diﬀering dimensions.
The basic issue is that in order to perform crossover style swaps, it is
necessary that the elements being swapped have a common interpretation.
If that is not the case, then the resulting entity will not make any sense.
For example, consider a time series on a daily scale and the same series on
a weekly scale. A set of ﬁtted values at the daily scale cannot be combined
via a crossover with a set of ﬁtted values at the weekly scale as the resulting
combination would be a mix of daily and weekly values and not have any useful
interpretation. What needs to be done is to establish a subset of elements
of the solutions that share a common interpretation, so that these can be
swapped. In the case of daily and weekly ﬁtted values, the set of daily values
could be reparameterized as the weekly average ﬁtted value and the daily
ﬁtted diﬀerences from the weekly mean. Now both scales have weekly ﬁtted

15.2 Multiscale Genetic Algorithms
183
values, and these can be swapped via any of the crossover moves described
above.
To be more precise, we choose a parameterization such that we can parti-
tion each solution vector into two parts, v = (φ, λ), where φ has a common
interpretation across all scales and λ encodes all of the scale-speciﬁc informa-
tion. An important factor is that φ has the same dimension, C, regardless of
the scale i. So to continue the example of daily and weekly values, φ would be
the weekly values or weekly averages, and λ might be empty for the weekly
series, while for the daily series it would contain the diﬀerences between the
daily values and the weekly averages. Thus one could swap the φ values for
the two scales and the resulting solutions would still make sense.
As with the previous chapter, the likelihood function must be speciﬁed at
each scale, and then the joint likelihood is taken as their product. In some
cases, the likelihoods may have the same dimensions across all scales, but
in many cases, moving between scales changes both the number of available
observations and the number of parameters in the model. When the dimension
changes, it will be necessary to pay more attention to some of the details in
the algorithm, as the normalizing constants can have a large eﬀect.
To initialize the algorithm, we choose M ≥2 × I random solution vec-
tors, v1
(0), . . . , vM
(0), where vm
(0) = (φm
(0), λm
(0), im
(0)) for m = 1, . . . , M. The last
parameter (i) in this solution vector speciﬁes the resolution (and portion of
the full likelihood) to which this solution vector corresponds. We recommend
having at least two solution vectors for each resolution, though this is not
strictly necessary. The algorithm often works better with even more solution
vectors at each resolution, but having two can be a reasonable compromise
between algorithm eﬃciency and computational resources. Once initialized,
the algorithm follows selection, crossover, and mutation steps similar to those
from before but modiﬁed to deal with the possibly diﬀering dimensions of the
parameters across scales.
One important distinction is in the selection step. Traditionally, selection
is across all solution vectors. However, in the multiscale setting, the likelihoods
may not be the same at diﬀerent scales, and so one would not want to blindly
compare ﬁtness via diﬀerent likelihoods. Instead, it is better to apply the
selection step to each scale separately. Within a particular scale, the likelihood
function is the same for all solutions, and so it can be used as a measure
of ﬁtness. Recall that the likelihoods for individual scales are conditionally
independent, so implementation is straightforward.
The key change is in the crossover step, as this step would normally destroy
the solutions when crossing between scales if not properly modiﬁed. Thus the
crossover is modiﬁed so that only the φ parts of the solutions are involved,
and the λ parts are left unchanged by the crossover step. As with the standard
crossover moves, the new solutions are not guaranteed to be good solutions,
but at least they are legitimate solution vectors. Because all of the φ vectors
are the same length and have the same general meaning, this treatment ensures
that meaningful solutions are produced by the crossover moves. Alternative

184
15 Genetic Algorithms
crossovers are possible for strings of varying lengths (Goldberg et al., 1989);
however, the crossover described here takes full advantage of the common
interpretation of φ vectors on diﬀerent scales. The steps of the full multiscale
algorithm are the following.
Selection: Each of the I scales is dealt with separately. For a particular
scale, the scale-speciﬁc likelihood serves as the ﬁtness function for the n(i)
(t)
solution vectors at that scale (identiﬁed by their last element). Now resam-
ple n(i)
(t) of these solutions with replacement with probabilities proportional
to their likelihoods, L(i)(φ(i), λ(i) | y(i)), to form a new population at this
level. This procedure is repeated for each i ∈{1, . . . , I}.
Crossover: The crossover step is modiﬁed from the ordinary genetic algo-
rithm since the lengths of the vectors v1
(t), . . . , vM
(t) may not all be the same.
Instead we perform crossovers (of any type, as described in Section 15.1)
on the portion of the vectors that are of the same length, the φ vectors.
The last part of each vector, (λ, i), is not involved in the crossover. For
example, a hypothetical one point crossover between two vectors is shown
in the following diagram, where the subscript denoting the iteration, (t),
is suppressed within the expanded vectors for clarity.
v1
(t) = {φ1
1, . . . , φ1
z∗, φ1
z∗+1, . . . , φ1
C, λ1, i1}
v2
(t) = {φ2
1, . . . , φ2
z∗, φ2
z∗+1, . . . , φ2
C, λ2, i2}
Swap
−→{φ1
1, . . . , φ1
z∗, φ2
z∗+1, . . . , φ2
C, λ1, i1}
{φ2
1, . . . , φ2
z∗, φ1
z∗+1, . . . , φ1
C, λ2, i2}
Mutation: The mutation step remains basically unchanged from the stan-
dard genetic algorithm. Each element has a small probability of being
perturbed, typically by adding random noise (for the case of real-valued
parameters). It is not necessary to consider mutating the value of the scale
parameter, i, because of the crossover moves, but it can be done and might
speed up convergence in some cases. If i is mutated, one may want to take
care that at least one solution is allowed to remain at each resolution in
the solution space. Changing the value of i would also require adjusting λ
appropriately.
Note that it is through the multiscale crossovers that information is shared
across resolutions. These crossovers can be seen as a generalization of the
Metropolis-coupled swaps of the previous chapter. While the Metropolis-
coupled swaps exchanged complete parameter vectors, the genetic algorithm
crossovers allow swapping of only pieces of the solutions through any of the
crossover moves previously described, such as the single-point, k-point, uni-
form, or snooker crossovers.
As with ordinary genetic algorithms, using an elitist strategy that saves the
best solution of interest from being destroyed through crossover or mutation

15.3 Multiscale Genetic Algorithm-Style MCMC
185
may increase the speed of convergence (DeJong, 1975). In the multiscale case,
one may want to retain the best solution at each scale rather than merely the
best overall solution.
15.3 Multiscale Genetic Algorithm-Style MCMC
In the Bayesian paradigm, one is usually interested in estimating a posterior
distribution for the parameters rather than simply ﬁnding an optimal point
estimate. In particular, if the full parameter distribution is known, then the
estimation of and accounting for uncertainty is straightforward. Here we re-
tain the formulation of the likelihood and decomposition of the parameter
vector ψ = (φ, λ) as in the previous section. To these we must add a prior
distribution for the parameters at each scale ψ(i) = (φ(i), λ(i)), which we de-
note π(i)(ψ(i)) = π(i)(φ(i), λ(i)). The resulting posterior distribution for each
scale (up to a normalizing constant) is
π(i) 
ψ(i) | y(i)
= π(i) 
φ(i), λ(i) | y(i)
∝L

ψ(i) | y(i)
π(i) 
φ(i), λ(i)
.
As before, once the posterior is deﬁned on a single scale, generalizing to mul-
tiple resolutions is simple. The full posterior is simply the product of the
posteriors from each scale. To sample from the posterior in complex prob-
lems, the typical approach is to use Markov chain Monte Carlo (MCMC).
The next section discusses combining genetic algorithms and MCMC. Then
the key multiresolution adaptation is described in the following section. This
algorithm can take advantage of the multiresolution nature of the problem to
eﬃciently explore the parameter space and draw samples from the posterior.
As an aside, we note that this framework extends to more complex sit-
uations where one could have a parameter vector ψ(i) that was a non-
deterministic transformation of (φ(i), λ(i)), in which case we must add an-
other term, π(i)(ψ(i) | φ(i), λ(i)), to the right-hand side for the distribution
induced by the probabilistic transformation, and the posterior will be deﬁned
over ψ(i), φ(i), and λ(i). In addition, the term π(i)(ψ(i) | φ(i), λ(i)) will need
to be included when appropriate in expressions in the following sections. Some
further comments are available in Holloman et al. (2006).
15.3.1 Genetic Algorithms and MCMC
Just as optimization can be diﬃcult in complex multimodal problems, MCMC
can similarly be troubled by complex multimodal posterior distributions. The
chain can easily become stuck in a local mode and fail to explore the whole
space, never visiting other modes and possibly never visiting the most impor-
tant parts of the space. As genetic algorithms are one of the more powerful
optimization methods in the presence of multimodality, it makes sense to try

186
15 Genetic Algorithms
to incorporate some of their features into MCMC to improve mixing and pos-
terior exploration.
Holmes and Mallick (1998) suggest an MCMC algorithm, the Parallel
Adaptive Metropolis Sampler (PAMS), that combines mutation steps with
crossover steps. At each iteration, the algorithm chooses randomly between
mutation and crossover steps. A mutation step is a standard Metropolis-
Hastings update of a solution vector where the proposal is a random per-
turbation of the current solution (i.e., a small amount of typically Gaussian
noise is added). The crossover steps create new proposals, which are then
also accepted or rejected via Metropolis-Hastings. They propose both uni-
form crossovers and a variant of the snooker crossover, moving along the line
connecting two current solutions. The selection and resampling step does not
have an explicit counterpart in MCMC, but there are elements of selection
involved in the MCMC versions of mutation and crossover, leading to similar
net results.
A further step is Evolutionary Monte Carlo (EMC) (Liang and Wong,
2001), which combines MCMC, genetic algorithms, and parallel tempering.
Just as with parallel tempering (from Section 14.3), a ladder of target func-
tions is created,
fi(x) =
1
Z(ti) exp{−Q(x)/ti},
where t serves as the temperature, t1 > . . . > tM, Q is typically the negative of
the unnormalized log-posterior (i.e., the log-likelihood plus the log-prior), and
Z is the normalizing constant (which here is a function of t). The algorithm
is a series of mutation, crossover, and exchange steps. Mutation, as before, is
a standard additive noise Metropolis-Hastings update. Crossovers can be any
of the standard varieties, such as k-point, uniform, or snooker crossovers. The
exchange step proposes swapping solutions at diﬀerent temperature levels.
Typically, a pair of adjacent temperatures, ti and ti+1, are chosen, solutions
xi and xi+1 are swapped, and then this proposal is accepted according to the
usual Metropolis-Hastings probability calculation. Multiple pairs can be at-
tempted to be swapped either simultaneously or stepwise during the exchange
step. The exchange step is the same as the moves between scales in parallel
tempering and is analogous to the Metropolis-coupled swaps of the previous
chapter. By combining parallel tempering and genetic algorithms, EMC is a
method for exploring posteriors that has improved chances of escaping from
local modes.
15.3.2 Multiresolution Versions
Building on the ideas of Evolutionary Monte Carlo and Metropolis coupling,
Holloman et al. (2006) introduced an MCMC algorithm with multiscale ge-
netic algorithm updates. A set of M Markov chains are run in parallel, nomi-
nally independently. M could be chosen to be equal to I, the number of scales,
or as with the multiscale genetic algorithm of Section 15.2, one could ensure

15.3 Multiscale Genetic Algorithm-Style MCMC
187
that at least two chains are started at each of the I scales. As with Metropolis
coupling, information is shared across scales via MCMC updates, in this case
crossover moves inspired by genetic algorithms.
Denote the chains by Γ1, . . . , ΓM, so that for any m ∈{1, . . . , M}, Γm ex-
plores one part of the posterior: π(i)(ψ(i) | y(i)) for some i ∈{1, . . . , I}. The
values of the random variables in any chain at a given time step determine
the current state of that chain. We denote the state of the lth chain at time
k as Γl(φ1
(k), λ1
(k)), where, as before, ψ = (φ, λ). φ represents the vector of
parameters with a common interpretation across all scales, and λ contains all
of the scale-speciﬁc parameters. It is unfortunate that so many superscripts
and subscripts are necessary, separate indices are needed to distinguish (i)
which of the M solutions it is, (ii) which scale the solution is on (with the
accompanying data, likelihood, and prior), (iii) which MCMC iteration (time
step) t it is at, and (iv) elements within the parameter vector (e.g., the ﬁrst
element may be a precision, the next a mean). Hence superscripts without
parentheses specify which of the M solutions is under consideration, super-
scripts in parentheses specify the scale, subscripts in parentheses specify the
iteration, and subscripts without parentheses specify the elements of a solu-
tion. We will try to use only one superscript and one subscript at a time, with
the other values being implied by the context and usually not being modiﬁed.
With this notation deﬁned, a diagram of a portion of the algorithm for M = 3
is given in Figure 15.1.
Γ1(φ1
(1), λ1
(1))
MCMC
−→Γ1(φ1
(2), λ1
(2))
Γ2(φ2
(1), λ2
(1))
MCMC
−→Γ2(φ2
(2), λ2
(2))
Γ3(φ3
(1), λ3
(1))
MCMC
−→Γ3(φ3
(2), λ3
(2))
SWAP
−→
Γ1(φ1′
(3), λ1′
(3))
MCMC
−→Γ1(φ1′
(4), λ1′
(4)) . . .
Γ2(φ2′
(3), λ2′
(3))
MCMC
−→Γ2(φ2′
(4), λ2′
(4)) . . .
Γ3(φ3
(3), λ3
(3))
MCMC
−→Γ3(φ3
(4), λ3
(4)) . . .
Fig. 15.1. Example of a multiscale crossover within MCMC, where chains 1 and 2
attempt a swap in step 2.
As with the other algorithms that combine MCMC and genetic algorithms,
this algorithm is a mix of standard Metropolis-Hastings MCMC updates (mu-
tations) and swapping steps (crossovers). Here each chain advances using or-
dinary within-chain MCMC steps (mutations) for a ﬁxed number of iterations
until a swap step is reached. At that point, one or more pairs of chains at-
tempt to swap values. In the diagram, a prime mark after a variable realization
(e.g., λ1′
(3)) indicates that the realization will take diﬀerent values depending
on whether the swap is successful or not. If the swap is unsuccessful, the
primed variables take the same values as their unprimed counterparts at the
previous time step (e.g., φ1′
(3) = φ1
(2)). If the swap is successful, the values of
the primed variables take on the values proposed in the swap (e.g., φ1′
(3) = φ2
(2)
and φ2′
(3) = φ1
(2)). Note that since there are an odd number of chains in this

188
15 Genetic Algorithms
example, the third chain does not take part in the swap. The next section
describes the crossover step in more detail.
Multiscale Crossover Step
In a crossover step, two chains exchange part or all of the relevant parts of their
solution vectors (the φ part). For now, we assume the chains are chosen with
equal probability. We will later return to the possibility of using additional
selection techniques in choosing the chains.
After pairing, proposals are formed from a crossover of the φ vectors of
the two paired chains. Any of the previously described crossover moves can be
used. One that we have found particularly eﬀective is uniform crossovers with
the probability of each element being swapped at 50%. The proposed values for
a chain are marked with stars (e.g., φ1∗is a proposed φ vector for chain Γ1).
As with the Metropolis-coupled algorithm, acceptance is usually improved by
proposing new values λ∗from some distributions q(i)(λj∗| φj∗, y(i)) which
are based on the proposed φ values for each chain j. The complete condi-
tional distribution is an obvious choice when it is of a form that can be easily
sampled. The proposal distributions q(i) may be diﬀerent at each scale. For
the swap depicted in Figure 15.1 where the ﬁrst two chains attempt a swap,
we accept or reject the swap according to the Metropolis-Hastings rule with
probability
π(1)(φ1∗, λ1∗| y(1))π(2)(φ2∗, λ2∗| y(2))q(1)(λ1 | φ1, y(1))q(2)(λ2 | φ2, y(2))
π(1)(φ1, λ1 | y(1))π(2)(φ2, λ2 | y(2))q(1)(λ1∗| φ1∗, y(1))q(2)(λ2∗| φ2∗, y(2))
(or probability one if this ratio is larger than one). Holloman (2002) shows
that this acceptance probability guarantees detailed balance in the MCMC
chain.
We refer to moves of the form above as crossover swaps. In some cases, it
can be useful to use swap steps that trade all elements. One could think of such
a step as a uniform crossover with element swap probability of 100%. In this
context, we refer to these steps as full swaps. In the context of the previous
chapter, a full swap is equivalent to the Metropolis-coupled swap. These moves
are also analogous to the exchange steps of Evolutionary Monte Carlo (where
entire solutions were traded between temperatures). Full swap proposals can
lead to greater exploration of the parameter space but are also more likely to
be rejected (because more elements are being exchanged), so there is a trade-
oﬀbetween the types of swaps. In some of our implementations, when a swap
step is called for, we randomly select between a full and a crossover swap.
One detail that can be expanded is the selection of the chains to be paired
together. Earlier we assumed that they were picked with equal probability.
One modiﬁcation would be to require that pairs can only swap with adjacent
scales, which typically improves acceptance probabilities but at the expense of
lesser gains in mixing (i.e., allowing nonadjacent swaps can lead to additional

15.3 Multiscale Genetic Algorithm-Style MCMC
189
improvement in mixing, but these swaps are less likely to be accepted). An-
other alternative plan involves appealing to the idea of selection from genetic
algorithms and attempting to encourage the pairing of the most promising
solutions. Instead of uniform probabilities, the two chains are chosen with
probabilities proportional to their ﬁtness measures. One possible ﬁtness crite-
rion would be the unnormalized posterior density of a realization on its portion
of the full posterior. This criterion is valid if priors, likelihoods, and known
values are similar on all scales, since the unknown normalizing constants for
each scale should be about the same. If the likelihoods are not comparable
across scales, then one could select chains in a two-step process: ﬁrst, select
a scale randomly with probabilities proportional to the number of available
(unpaired) chains at that scale; second, select chains from that scale with
probabilities proportional to their unnormalized likelihoods. Caution should
be used when performing the selection with diﬀerent ﬁtness functions for
diﬀerent chains since all portions of the posterior are only known up to a nor-
malizing constant. When in doubt, we recommend weighting chains equally.
Note that if nonuniform probabilities are used to select the pairings of the
chains, then a term for these selection probabilities must also be included in
the Metropolis-Hastings acceptance ratio.
15.3.3 Implementational Concerns
Before moving on to an example, we ﬁrst want to address a couple of im-
plementational items. Depending on the setting, the user of these algorithms
may need to make a choice of possible scales. The user will also need to choose
an appropriate number of chains/solutions. Finally, we give a brief discussion
of parallel computing.
In a truly multiscale problem, the scales will be determined by the data.
In other problems, one could picture additional possible unobserved scales
which could be used for interpretation or for computational purposes. This
setting could also include the case where data are only observed on a single
scale. When the user has the latitude to choose scales, the choice of both how
many and which scales must be made. The simulated tempering literature
provides some guidance for choosing the number of scales by analogy with their
recommendations for choosing heated distributions. In simulated tempering
schemes, it has been recommended that the temperatures be chosen such that
the acceptance probability of moves between adjacent scales is between about
20% and 40% (Geyer and Thompson, 1995). This recommendation can be
used as a guideline for selecting the scales to be used in modeling multiscale
problems. This now leaves the choice of the endpoints, the ﬁnest and coarsest
scales. The ﬁnest scale is the smallest resolution of interest to the practitioner.
Typically, this is the ﬁnest resolution that is actually observed. The coarsest
scale is usually chosen to be one where the Markov chain mixes easily, so that
if MCMC was run only at that scale, it would quickly explore the whole space,
not becoming unduly stuck in local modes.

190
15 Genetic Algorithms
Another consideration in choosing the scales is that of computational re-
sources. Since at least one Markov chain is run at each scale, using more
scales translates into additional computational eﬀort. If the chains are run on
a single machine, using too many scales can take prohibitively long. If the
chains are run in parallel on separate processors, the user will quickly run up
against the limit of the physical number of processors available. So there is a
compromise between eﬃciency of moving between scales and eﬃciency in the
allocation of available computational resources.
A similar trade-oﬀneeds to be made in choosing the number of chains
(or, equivalently, the number of solution vectors). At the least, one chain is
needed for each scale. But eﬃciency can often be improved by using more
than one chain per scale. For a genetic algorithm, if there are too few chains,
the algorithm may not have enough diversity in the population of chains to
allow rapid exploration. At the other end of the spectrum, having too many
chains wastes computational eﬀort. For standard genetic algorithms, the usual
recommendation is to set M = 2 × R, where R is the length of the parameter
vector. For multiscale MCMC implementations, premature convergence as
found in genetic algorithms with too few solution vectors is not a large threat,
so fewer chains can be used. Two chains per scale is a reasonable compromise.
This multiscale MCMC algorithm is easily adapted for parallel comput-
ing environments. Independent execution of mutation steps and ﬁtness func-
tion evaluations is possible for each element of the population. Factorization
of the posterior distribution into conditionally independent components al-
lows simultaneous sampling of each of those components. Synchronization is
only important for the swap steps, and not much data need to be passed at
those steps. In addition, multiple swaps can be performed simultaneously in
the MCMC algorithm. When pairing in parallel implementations, making as
many nonoverlapping pairs as possible can be more eﬃcient, but making sev-
eral swaps simultaneously can make the acceptance probability very small if
chains are chosen with probabilities proportional to some measure of ﬁtness.
In this situation, all proposed swaps must be accepted or rejected together.
In contrast, if chains are chosen with equal probability, individual swap pro-
posals between pairs of chains may be evaluated for acceptance or rejection
independently, so performing several swaps simultaneously usually improves
performance. Further details on performing several swaps simultaneously can
be found in Holloman (2002).
Because there may be diﬀerent amounts of data and diﬀerent likelihoods
for each scale, synchronization disparities can easily arise, leading to idle pro-
cessors. It can pay to try to time the length of the run for each node so that
they all work for approximately the same amount of time before a swap is
considered. For instance, a scale with half the resolution of the next ﬁner one
could do two cycles of within-scale parameter updates (mutation and selec-
tion for the multiscale genetic algorithm or standard MCMC updates in the
multiscale MCMC algorithm) in the time the ﬁner scale does one. Additional

15.4 Example
191
information on issues in parallel MCMC can be found in Rosenthal (2000)
and the references therein.
15.4 Example
Here we continue the example from Section 14.2.1 of ﬁtting the ﬁrst three
years of the Fraser River data using a convolution model. This is not the
best example, but we use it here for the sake of continuity. Since the model
is fairly simple, there isn’t much additional beneﬁt from the crossover swaps
compared with the full swaps of the previous chapter. The ﬁtted values look
quite similar to those in Figure 14.1 in the previous chapter. Also, there is
typically not much additional reduction in autocorrelation, as shown below in
Figure 15.2. In this case, the methods of the previous chapter have already
taken advantage of mixing across scales, and there is little left to be gained
by also using crossover swaps. However, for more complicated problems there
can be signiﬁcant gains.
An additional example is the single photon emission computed tomogra-
phy (SPECT) example in Chapter 17. Of interest is a pixelated map of image
intensities, which must be reconstructed from photon counts collected by a
rotating gamma camera. A Markov random ﬁeld prior is used for the intensity
map, and a physical forward model links the hypothesized intensities to the
observed photon counts. Fitting of the latent intensity map pixels is done with
MCMC, but mixing can be poor because of the high correlation between the
unknown parameters. As with many imaging problems, it is expected that
neighboring pixels will be highly correlated, as otherwise the image would
just be a random collection of numbers, not a coherent image. These cor-
relations make it diﬃcult to create good Metropolis-Hastings proposals, as
the proposal must make enough changes in order to be diﬀerent enough from
the current values that it makes progress in exploring the space, but not too
diﬀerent from the current values so that it is rejected. In this case, too “dif-
ferent” is often achieved because neighboring pixels are not kept suﬃciently
similar in a proposal. The multiscale methods of this chapter and the previ-
ous chapter provide an eﬃcient mechanism for creating good proposals. These
proposals can retain enough of the spatial qualities to allow reasonable accep-
tance probabilities, yet provide enough movement so that the posterior can
be explored with a practical amount of computational eﬀort. The underly-
ing imaging problem here is not inherently multiscale, but by embedding the
problem in a multiscale framework, the inference can be done more eﬃciently
through multiscale MCMC. Chapter 17 provides additional details.

192
15 Genetic Algorithms
0
2
4
6
8
0.0
0.2
0.4
0.6
0.8
1.0
Lag
Fine Scale Only
Metropolis-Coupled
With Crossovers
ACF
0
2
4
6
8
0.0
0.2
0.4
0.6
0.8
1.0
Lag
ACF
0
2
4
6
8
0.0
0.2
0.4
0.6
0.8
1.0
Lag
ACF
Fig. 15.2. Comparison of autocorrelation plots for a latent value.

Part V
Case Studies


16
Soil Permeability Estimation
16.1 Introduction
Many important applications in the cleanup of contaminated soil and in the
production of petroleum from oil ﬁelds require the understanding of soil struc-
ture and prediction of ﬂuid ﬂow patterns. Subsurface ﬂow is dependent on
a number of factors, with one of the primary ones being the permeability
ﬁeld. Permeability is a measure of how easily ﬂuid moves through the porous
medium at a point, and it varies spatially. In this chapter, we treat perme-
ability as a constant at a point, but in more detailed applications it may be
tensor-valued to account for the fact that soil structure can be directional and
so ﬂuid may ﬂow more easily in some directions than in others.
Permeability estimation is important both for its own sake and for helping
to determine ﬂow patterns. In environmental cleanup applications, perme-
ability estimates are critical for two parts: for identifying the likely location
and distribution of the contaminant and for designing the remediation oper-
ation (James et al., 1997; Jin et al., 1995). The contamination can be treated
without having to dig up the ground by pumping water containing a sur-
factant through the aﬀected area. The water can then be treated to remove
the contaminants, a much quicker and less costly operation than excavating
and treating the soil itself. However, eﬀective use of this procedure requires
good knowledge of the permeability ﬁeld. In petroleum production, primary
production occurs when a well is drilled into an underground oil ﬁeld and the
oil rises to the surface under its own pressure. Typically, much less than half
of the oil can be extracted in this manner. Secondary and tertiary recovery
eﬀorts require increasing the pressure within the oil ﬁeld to cause more oil
to rise to the surface. This increase in pressure is achieved by pumping ei-
ther water or natural gas (a frequent by-product of oil production) into the
ﬁeld. Eﬀective recovery procedures rely on good permeability estimates, as
one must be able to identify high-permeability channels and low-permeability
barriers (Xue and Datta-Gupta, 1996).

196
16 Soil Permeability Estimation
There are in general two types of available information for the estimation
of the permeability ﬁeld: static data and dynamic data. The static informa-
tion about the permeability ﬁeld comes from a variety of sources, such as
geological studies, well tests, and core samples. Each of these sources provides
information at diﬀerent levels of aggregation or resolution: geological studies
(for example, seismic studies) provide information at a very coarse level of res-
olution. Well tests provide information at an intermediate level, giving more
information in the local area around a well but also some information farther
from the well. Core logs, either taken to a laboratory for direct permeability
measurements or measuring resistivity in the bore hole, give information at
a very ﬁne level. These core measurements only provide information at the
sampling point, so all spatial information must be inferred from the model. It
is also worth pointing out that while laboratory measurements are the only
direct estimates of permeability, they are also expensive, variable, and de-
structive. Drilling a core sample, returning it to a lab, and analyzing it is a
labor-intensive process. There can be large measurement errors induced be-
cause the soil in a core can act diﬀerently than it did in the ground—drilling
the core is disruptive to the soil one is trying to measure. And the core is de-
structive to the remaining ﬁeld in that now there is a hole in the ground and
often the surrounding material will collapse into the hole. The permeability
and the water ﬂows can be radically altered by the very process of removing
the core. Thus there is a trade-oﬀbetween level of resolution and coverage of
the ﬁeld. Higher-resolution data may be available for restricted parts of the
ﬁeld, while the coarse-resolution data are generally available for the whole
ﬁeld. Here, we assume that the static data are either direct measurements or
known deterministic and invertible transformations of measurements of the
permeability ﬁeld at the corresponding scales of resolution.
The dynamic data are obtained from results of tracer experiments per-
formed in an aquifer or from the history of oil production of a petroleum ﬁeld.
As opposed to the simple relationship with the static data, the permeability
ﬁeld aﬀects the ﬂuid ﬂow and therefore the dynamic data in a highly nonlinear
way. If the permeability ﬁeld and other physical characteristics of the porous
media were known, physical models such as Darcy’s Law, Fick’s Law, and the
law of conservation of mass could be used to solve the forward problem; that is,
to predict the ﬂuid ﬂow and the dynamic data (Gelhar, 1993). These physical
models are described by a system of diﬀerential equations that can be solved
numerically by computer codes called ﬂuid ﬂow simulators (FFS) (King and
Datta-Gupta, 1998; Vasco and Datta-Gupta, 1999). In this chapter, relatively
fast simulators are used to compute approximations for the expected dynamic
data for permeability ﬁelds partitioned into discrete grid-blocks. An extremely
important point for practical implementations is that as the resolution of the
partition increases, the FFS computes more accurate solutions but becomes
slower.
The use of dynamic data for the estimation of the permeability ﬁeld is
known in the subsurface hydrology literature as the inverse problem. This

16.1 Introduction
197
terminology arises in contrast to the forward problem, which is the solution
of the ﬂow equations when the permeability is known, as discussed in the
previous paragraph. The inverse problem is the opposite — having observed
dynamic data, one tries to infer the permeability ﬁeld. To do so requires
iterative use of the solution to the forward problem in that one guesses a
value for the permeability ﬁeld, solves the forward problem to see what ﬂows
would result, and then goes back and adjusts the initial guess at the per-
meability ﬁeld, iterating until the predicted ﬂows match the observed data
closely enough. References on the subsurface hydrology inverse problem in-
clude Neuman and Yakowitz (1979), Yeh (1986), Oliver (1994), Craig et al.
(1996), Hegstad and Omre (1997), Oliver et al. (1997), Vasco and Datta-Gupta
(1999), Floris et al. (2001), and Lee et al. (2002). The inverse problem is ill-
posed; i.e., there are an inﬁnite number of permeability ﬁeld solutions whose
expected dynamic data exactly match the observed dynamic data. Many of
those solutions are too rough to be plausible, and proposed approaches gen-
erally impose some stochastic regularity constraints on the permeability ﬁeld.
For example, Bonet-Cunha et al. (1998) and Oliver et al. (1997) assume that
the permeability ﬁeld follows a Gaussian process model, while Lee et al. (2002)
consider allowing the permeabilities to follow a Markov random ﬁeld process.
While the Gaussian process model can imply permeability ﬁelds that are too
smooth, the Markov random ﬁeld assumption can lead to an undesirably fast
decay of the spatial correlation. Thus we turn to multiscale approaches.
Here we present two diﬀerent approaches. First, the multiscale models of
Chapter 10 are used as priors for permeability ﬁelds. These multiscale models
have the local behavior of Markov random ﬁelds but globally emulate long
memory processes, being well suited to capture global features of the perme-
ability ﬁeld. In combination with this multiscale prior, corresponding likeli-
hood functions for the high-dimensional random ﬁeld parameters representing
the permeability ﬁeld at each level or resolution are computed with the help
of the FFS embedded in an MCMC scheme. This statistical framework uses
the faster solutions at the coarser levels to guide the solutions at the ﬁner
levels. Results in the next section appeared originally in Ferreira et al. (2003)
and Ferreira et al. (2005). Section 16.2 presents the multiscale permeability
model. Section 16.2.1 describes the propagation of static information through
the diﬀerent levels of resolution, and Section 16.2.2 discusses the incorporation
of the dynamic data. A one-dimensional permeability ﬁeld example appears
in Section 16.2.3, and Section 16.2.4 presents the application of the multiscale
framework to several two-dimensional permeability ﬁelds.
The second approach, presented in Section 16.3, is that of the implicit
multiscale models of Chapter 14. The setup of the problem is analogous to that
in Section 16.2.4. Rather than making modeling assumptions about the links
between the scales, we can link them through the model ﬁtting, achieving good
ﬁts and improved computational eﬃciency. Some of these results originally
appeared in Higdon et al. (2002).

198
16 Soil Permeability Estimation
16.2 Multiscale Modeling
In order to estimate a true continuous permeability ﬁeld, the ﬁeld is discretized
in coarse, intermediate, and ﬁne versions denoted respectively by x0, x1, and
x2. The multiscale random ﬁeld of Chapter 10 is used as a prior for the
multiscale permeability ﬁeld. More speciﬁcally, the prior of the multiscale
permeability ﬁeld is of the form
p(x0|µ, τ0, α0)p(x1|x0, µ, τ1, α1, δ1)p(x2|x1, µ, τ2, α2, δ2),
where
p(x0|µ, τ0, α0) = N(x0|µ1n0, Q0),
p(x1|x0, µ, τ1, α1, δ1) = N(x1|µ1n1 + B1(x0 −µ1n0), Σ1 −B1W1B′
1),
and
p(x2|x1, µ, τ2, α2, δ2) = N(x2|µ1n2 + B2(x1 −µ1n1), Σ2 −B2W2B′
2),
where µ is the mean level of the ﬁeld, B1, B2, W1, and W2 are as deﬁned in
Theorem 10.2, and Q0, Σ1, and Σ2 are covariance matrices of proper Markov
random ﬁelds as deﬁned by Equations (10.1) and (10.2).
Denote the available information by
•
pobs = observed dynamic data;
•
d0 = measurement of permeability at the coarse scale;
•
d1 = measurement of permeability at the intermediate scale;
•
d2 = measurement of permeability at the ﬁne scale.
In addition, it is assumed that
•
pobs|x2 ∼N(f(x2), σ2
εI),
•
d0|x0 ∼N(x0, S0),
•
d1|x1 ∼N(x1, S1), and
•
d2|x2 ∼N(x2, S2),
where S0, S1, and S2 are the known covariance matrices of the measurement
errors at the respective levels of resolution and f(x) is the expected dynamic
data for the permeability ﬁeld x. Here it is assumed that the expected dynamic
data can be computed by the FFS with negligible approximation error. Typ-
ically, S0, S1, and S2 are diagonal matrices or covariance matrices obtained
from a geostatistical analysis of the static data.
As a result, the posterior density will be proportional to
p(pobs|x2, σ2
ε)p(d2|x2)p(d1|x1)p(d0|x0)p(x0|µ, τ0, α0)
p(x1|x0, µ, τ1, α1, δ1)p(x2|x1, µ, τ2, α2, δ2)
p(µ)p(τ0, α0)p(τ1, α1, δ1)p(τ2, α2, δ2).

16.2 Multiscale Modeling
199
This posterior density is explored with an MCMC scheme with each iteration
divided in two main steps. In the ﬁrst step, all the information about the sta-
tic data d0, d1, and d2 is propagated from the ﬁner to the coarser levels by
analytically integrating out the ﬁner levels. In the second step, the dynamic
data are incorporated in the analysis in a cascade way from coarser to ﬁner
levels of resolution. First, the dynamic data are used to generate the coarser
levels by using the FFS running at those levels. After that, the ﬁner levels
are generated conditional on the generated coarser levels. The incorporation
of the dynamic data from coarser to ﬁner levels brings two advantages. The
ﬁrst advantage is that the running time of the FFS at the coarser levels is
faster than at the ﬁner levels. The second advantage is that the MCMC for
the coarser levels converges much faster than for the ﬁner levels because the
marginal posterior distribution of coarser levels has fewer local maxima than
those of ﬁner levels. As a result, the results at coarser levels guide the simu-
lation at ﬁner levels, and the main consequence is faster convergence at ﬁner
levels as compared with convergence of traditional MRF schemes.
Thus, the main idea of this MCMC algorithm is the following: the coarse
level x0 is simulated from p(x0|pobs, d0, d1, d2); that is, x1 and x2 are inte-
grated out analytically before the simulation of x0. Then, x1 is simulated from
p(x1|x0, pobs, d0, d1, d2) with x2 integrated out. Finally, x2 is simulated from
its full conditional p(x2|x1, x0, pobs, d0, d1, d2). The next sections present the
expressions of these distributions.
16.2.1 Static Information Propagation
This section describes how to send the measurement information from ﬁner to
coarser levels. As the generalization to more levels is straightforward, here only
two levels are considered. For notational simplicity, we omit the dependence
of the density functions on the hyperparameters. Thus, the objective is to
obtain p(x0|d0, d1). Hence
p(x0|d0, d1) ∝p(d0, d1|x0)p(x0)
= p(d0|x0)p(x0)

p(d1|x1)p(x1|x0)dx1
∝N(d0|x0, S0)N(x0|µ1n0, Q0)
N(x0|µ1n0, A1Σ1A′
1 + δ1In0)N(x0|b0, B0),
where A1 is the matrix that performs the coarsening operation as in Equation
(10.3),
B0 = A1(S−1
1
+ Σ−1
1 )−1A′
1 + δ1In0,
and
b0 = A1(S−1
1
+ Σ−1
1 )−1(S−1
1 d1 + τ1α1µ1n1)
since Σ−1
1 1n1 = τ1α1In1.

200
16 Soil Permeability Estimation
16.2.2 Dynamic Data Incorporation
After propagating the measurement data from ﬁner to coarser levels, the al-
gorithm incorporates the dynamic data from coarser to ﬁner levels. The ﬁrst
step is the simulation of x0, conditional on the pressure and the measurement
data. It is assumed that, conditional on the coarse level, the dynamic data
pobs are independent of the measurements at the ﬁne and intermediate levels.
This assumption allows use of the FFS at diﬀerent levels of resolution for the
simulation of each level. Under this assumption, the conditional distribution
of x0 given pobs, d0, d1, and d2 is
p(x0|pobs, d0, d1, d2) ∝p(pobs, d0, d1, d2|x0)p(x0)
∝p(pobs|x0)p(x0|d0, d1, d2).
Note that p(x0|d0, d1, d2) can be easily obtained using the result outlined
in Section 16.2.1. Moreover, running the FFS at the coarse level provides a
good approximation for p(pobs|x0), that is, p(pobs|x0) ≈N(pobs|f(x0), σ2
ε0I).
This avoids the cumbersome computation of the integral in p(pobs|x0) =
 
p(pobs|x2) p(x2|x1)p(x1|x0)dx1dx2, which is very complicated due to the
nonlinear relationship between pobs and x2.
Moreover, assuming pobs independent of d2 given x1 implies
p(x1|x0, pobs, d0, d1, d2) ∝p(pobs|x1)p(x1|x0, d0, d1, d2)
∝p(pobs|x1)p(x1|x0)p(d1|x1)

p(d2|x2)p(x2|x1)dx2.
Again, the result of Section 16.2.1 is used to compute

p(d2|x2)p(x2|x1)dx2,
bringing the measurement information about the ﬁnest level to the intermedi-
ate level. In addition, p(pobs|x1) can be approximated by running the FFS at
the intermediate level and assuming that p(pobs|x1) ≈N(pobs|f(x1), σ2
ε1I).
Finally, the conditional distribution of x2 given x1, x0, pobs, d0, d1, and
d2 is
p(x2|x1, x0, pobs, d0, d1, d2) ∝p(pobs|x2)p(x2|x1)p(d2|x2).
16.2.3 One-Dimensional Permeability Estimation
This section presents an application of the multiscale framework to the esti-
mation of a synthetic 1-D permeability ﬁeld. Some real-world problems can be
cast in this one-dimensional framework. One such example is the estimation of
the permeability ﬁeld of incised valley oil ﬁelds, that is, petroleum ﬁelds that
developed in buried ancient river beds. See Stephen and Dalrymple (2002) for
an example of an incised valley oil ﬁeld.

16.2 Multiscale Modeling
201
1280 m
Production
well
Porous media
Fig. 16.1. Design of the reservoir.
The design of the synthetic ﬁeld is as follows. The length of the ﬁeld is
equal to 1280 meters, and there is only one production well located in the
right end of the ﬁeld, as depicted in Figure 16.1. There are three discretized
versions of the ﬁeld, x0, x1, and x2, partitioning it into 8, 32, and 128 grid-
blocks, respectively. Moreover, it is assumed that the ﬁne discretized level x2
is equal to the truth, and inference will be done only for the coarser resolutions
x0 and x1.
In order to reduce the dimension of the problem of prior speciﬁcation, we
assume a priori independence of the parameters, allowing us to focus on the
speciﬁcation of the prior for each parameter individually.
Several aspects distinctive to the multiscale approach to the 1-D ﬂuid ﬂow
problem facilitate the speciﬁcation of informative priors for several parameters
of interest. The most important of these characteristics is that the permeabil-
ity ﬁeld is modeled on the logarithm scale. Thus, reasoning on the relative
variability between neighbor grid-blocks within and across diﬀerent levels of
resolution leads to straightforward speciﬁcation of the priors for τ0, τ1, and δ1.
Considerations on the smoothness of the log-permeability ﬁeld at each resolu-
tion level lead to the speciﬁcation of the priors for the spatial dependence para-
meters α0 and α1. Physical considerations assist the speciﬁcation of the prior
for the overall log-permeability mean µ. The variances σε0 and σε1 are assigned
vague priors. More speciﬁcally, the priors used in this particular application
are τ0 ∼Ga(3.0, 1.1), α0 ∼Ga(10, 1), τ1 ∼Ga(57, 0.14) α1 ∼Ga(0.2, 20),
µ ∼N(5.0, 1.21), σε0 ∼IG(5×10−5, 5×10−5), σε1 ∼IG(5×10−5, 5×10−5),
and δ1 ∼IG(57, 0.14).
Figure 16.2 presents the original synthetic permeability ﬁeld with 512 grid-
blocks and coarser versions with 64 and 8 grid-blocks, darker colors corre-
sponding to lower values and lighter colors corresponding to higher values.
The permeability of the ith grid-block of the synthetic ﬁeld has a value of
exp(−3.1710−5i2 + 0.01625i + 3.91), i = 0, . . . , 511, i = 1 and i = 512 corre-
sponding respectively to the left and right ends of the ﬁeld. Other physical
characteristics of the reservoir, such as number of phases, initial pressure,

202
16 Soil Permeability Estimation
(a)
(b)
(c)
Fig. 16.2. Permeability ﬁeld. (a) Original ﬁeld (512 grid-blocks); (b) intermediate
ﬁeld (64 grid-blocks); (c) coarse ﬁeld (8 grid-blocks). Lighter colors correspond to
higher values.
porosity, production rate, cross-sectional area, and compressibility, are as-
sumed constant and known. In addition, there is only one production well
located in the right end of the ﬁeld. The static data at the coarse level are
d0 = (4.4, 5.1, 5.6, 5.9, 6.0, 5.7, 5.2, 4.3) and S0 = 0.12I. There are static data
at the intermediate level only for the grid-blocks 1, 9, 17, 25, 33, 41, 49, 57,
and 64 with variance equal to 0.004, with recorded values equal to 3.97, 4.86,
5.50, 5.88, 5.99, 5.85, 5.45, 4.78, and 3.99.
Depending on the production regime, the dynamic data can be either the
ﬂow rate or the pressure at the production well. In this example, the ﬂow rate
is kept constant and the dynamic data are given by the pressure curve at the
production well. The FFS was used to compute the pressure curve for the ﬁrst
two days of production, and measurement errors with variance σ2
ε = 1.0 were
added to the pressure curve, shown in Figure 16.3.
Figure 16.4 presents the coarse version of the original ﬁeld and the poste-
rior mean of the coarse level of resolution. Analogously, Figure 16.5 presents
the intermediate version of the original ﬁeld and the posterior mean of the
intermediate level of resolution. At both resolution levels, the posterior mean
is very close to the original permeability ﬁeld, the main diﬀerence being that
the estimation at the intermediate level of resolution recovers a higher degree
of detail.
One of the main advantages of the Bayesian framework coupled with
MCMC technology is the uncertainty characterization. The uncertainty present
in the inference about the permeability ﬁeld can be summarized by the pos-
terior variance of each grid-block. Figure 16.6 presents the posterior variance
across the ﬁeld at the coarse and intermediate levels of resolution. At both
levels of resolution, as the production well is located in the right end of the
ﬁeld, the incorporation of the dynamic data results in smaller posterior vari-
ances for grid-blocks closer to that region. In particular, the ratio between the

16.2 Multiscale Modeling
203
0.0
0.5
1.0
1.5
2.0
1250
1300
1350
1400
1450
1500
time
pressure
Fig. 16.3. Dynamic data for permeability estimation. Pressure curve through time.
(a)
(b)
Fig. 16.4. Estimation at the coarse level of resolution. (a) Original coarse ﬁeld;
(b) posterior mean.
(a)
(b)
Fig. 16.5. Estimation at the intermediate level of resolution. (a) Original interme-
diate ﬁeld; (b) posterior mean.

204
16 Soil Permeability Estimation
posterior variances of the coarse grid-blocks 1 (left end) and 8 (right end) is
about 50, demonstrating the reduction in uncertainty due to the proximity
of the production well. At the intermediate level, the existence of static data
for the grid-blocks 1, 9, 17, 25, 33, 41, 49, 57, and 64 implies smaller poste-
rior variances at these grid-blocks than at their neighbors. In addition, as the
measurement information is equally spaced, the transfer of information along
the ﬁeld causes periodic behavior of the posterior variances.
(a)
(b)
Fig. 16.6. Uncertainty in the estimation of the permeability ﬁeld. Posterior variance
across the ﬁeld (a) at the coarse level and (b) at the intermediate level.
16.2.4 Two-Dimensional Permeability Estimation
This section presents an application of the multiscale random ﬁeld models
presented in Chapter 10 to the estimation of 2-D permeability ﬁelds. The
increase in dimensionality poses new problems for the estimation of perme-
abilities because with this increase the ﬂuid has many more possible paths to
ﬂow through. This increase in the number of possible paths means, for exam-
ple, that a limited number of small areas of very low permeability have little
eﬀect on the ﬂuid ﬂow, as the ﬂuid can go around those areas. As a conse-
quence, the problem of permeability ﬁeld estimation is severely ill-posed in the
sense that for given observed dynamic data and a given agreement level, there
are an inﬁnite number of possible permeability ﬁelds. Thus one must make
modeling assumptions that impose smoothness constraints on the permeabil-
ity ﬁeld, such as Gaussian process models (Bonet-Cunha et al., 1998; Oliver
et al., 1997) or Markov random ﬁeld models (Lee et al., 2002). However, the
Gaussian process model can lead to permeability ﬁelds that are too smooth,
while the Markov random ﬁeld assumption can be overly rough. As an al-
ternative, multiscale random ﬁeld models have the local behavior of Markov
random ﬁelds but globally emulate long memory processes. Thus, here we
consider multiscale random ﬁeld models as priors for permeability ﬁelds.
The setup of the examples in this section is the same as in Lee et al. (2002).
In order to estimate the permeability ﬁeld of an aquifer, the following exper-
iment is performed. Water is pumped into the aquifer through one or more

16.2 Multiscale Modeling
205
injection wells at a ﬁxed rate. The water is extracted by producer wells while
keeping constant the pressure at the bottom of each well. After equilibrium
is reached, a tracer is injected at the injection well(s) and the concentration
of the tracer is measured over time at each of the producer wells. Lee et al.
(2002) found that the ﬁrst time of arrival of the tracer at each well, called
the breakthrough time, is practically a suﬃcient statistic for a unimodal con-
centration curve. In the petroleum engineering literature, Vasco et al. (1998)
and Yoon et al. (1999) have also used breakthrough times as summaries of the
concentration curves. Thus, here breakthrough times are used as the dynamic
data.
More speciﬁcally, the setup in the ﬁrst two examples is an inverted 9-spot
pattern, that is, it is a square ﬁeld with a single injection well in the center of
the ﬁeld and eight producer wells, one at each corner and one on the middle
of each edge. Thus there are eight breakthrough times to estimate the whole
permeability ﬁeld. Denote by pobs the dynamic data vector with the eight
breakthrough times. These dynamic data are incorporated in the estimation
of the permeability ﬁeld at the diﬀerent resolution levels using the results
presented in Section 16.2.2. It is assumed that all other important physical
quantities such as initial pressure and porosity are known. Moreover, it is
assumed an incompressible medium and ﬂuid, and an ideal tracer.
The permeability ﬁeld aﬀects the ﬂuid ﬂow and therefore the dynamic data
in a highly nonlinear manner. When the physical characteristics of the porous
media, such as the permeability ﬁeld and porosity, are known, physical models
such as Darcy’s Law and the law of conservation of mass can be used to solve
the forward problem. A ﬂuid ﬂow simulator (FFS) numerically solves these
systems of diﬀerential equations. In the remainder of this chapter, we use the
S3D streamtube code of King and Datta-Gupta (1998), which is fast enough
to make Markov chain Monte Carlo solutions practical. Similar to Lee et al.
(2002), a Gaussian likelihood for the logarithm of the breakthrough times is
used, with each log-breakthrough time conditionally independent with mean
equal to the value obtained from the FFS. The results of Section 16.2.2 lead
to the use of the FFS at diﬀerent levels of resolution in order to accelerate
the procedure for estimation of the permeability ﬁeld. More speciﬁcally, the
algorithm runs ﬁrst at the coarse level, and then at the ﬁne level conditional
on the coarse-level results. As a consequence, the algorithm converges faster
at the ﬁne level when compared with algorithms based on traditional Markov
random ﬁeld models, analogous to results on multigrid methods (see, for ex-
ample, Briggs et al., 2000).
As there is no static data in this set of examples and as the dynamic data
provide very little information about the smoothness of the ﬁeld, the hyper-
parameters of the model have to be speciﬁed a priori on a case-by-case basis.
Thus, in the following examples, the hyperparameters of the multiscale model
are kept constant. As we model the log-breakthrough times, the variances σε0
and σε1 are related to the amount of allowed relative diﬀerences between the
observed and the adjusted breakthrough times. Thus, it is reasonably easy to

206
16 Soil Permeability Estimation
assign informative priors for σε0 and σε1. In general, their simulated values
are large in the beginning of the MCMC and become smaller as the multiscale
random ﬁeld realizations converge to a draw from their posterior distribution.
This behavior of the traces of σε0 and σε1 leads to an eﬀect similar to sim-
ulated annealing for the simulation of the diﬀerent levels of the ﬁeld, with
higher temperatures in the beginning and cooler temperatures at the end of
the chain.
The following sections present three examples of applications of the mul-
tiscale framework for the estimation of 2-D permeability ﬁelds. The ﬁrst two
examples are based on dynamic data simulated from synthetic linear and
Gaussian log-permeability ﬁelds. These cases are informative because the true
underlying ﬁeld is known and so can be compared with the ﬁtted values. The
third example refers to data on breakthrough times obtained from a real ex-
periment at the Hill Air Force Base in Utah.
Linear Field
Figure 16.7 presents a linear log-permeability ﬁeld with lower permeabilities
in the southwest corner of the ﬁeld and higher permeabilities in the northeast
corner, as well as some results of the multiscale analysis. In the plots, darker
colors indicate higher permeability values.
0.0
0.2
0.4
0.6
0.8
1.0
0.0
0.2
0.4
0.6
0.8
1.0
0.0
0.2
0.4
0.6
0.8
1.0
0.0
0.2
0.4
0.6
0.8
1.0
0.0
0.2
0.4
0.6
0.8
1.0
0.0
0.2
0.4
0.6
0.8
1.0
0.0
0.2
0.4
0.6
0.8
1.0
0.0
0.2
0.4
0.6
0.8
1.0
0.0 0.2 0.4 0.6 0.8 1.0
0.0 0.2 0.4 0.6 0.8 1.0
0.0 0.2 0.4 0.6 0.8 1.0
0.0 0.2 0.4 0.6 0.8 1.0
0.0 0.2 0.4 0.6 0.8 1.0
0.0 0.2 0.4 0.6 0.8 1.0
0.0 0.2 0.4 0.6 0.8 1.0
0.0 0.2 0.4 0.6 0.8 1.0
Fig. 16.7. Linear log-permeability ﬁeld: ﬁne level (ﬁrst line), coarse level (second
line), original ﬁeld (ﬁrst column), posterior mean (second column), and realizations
(third and fourth columns).
The original 32 × 32 log-permeability ﬁeld is shown in the upper left of
Figure 16.7. The original ﬁeld was used as input for the ﬂuid ﬂow simulator,

16.2 Multiscale Modeling
207
generating 8 breakthrough times. Using the multiscale framework outline in
this chapter, these 8 breakthrough times were used to check how well we can
estimate the original ﬁeld.
The lower left of Figure 16.7 shows the 8 × 8 coarse version of the original
ﬁeld. The second column shows the posterior means of the ﬁne and coarse
levels of the log-permeability ﬁeld. As can be seen in the ﬁgure, the posterior
mean recovers the original ﬁeld very well.
The last two columns show some realizations of the ﬁne and coarse levels
of the permeability ﬁeld. There is a reasonable amount of variability between
the realizations. It is remarkable how the coarse-level realizations drive the
ﬁne-level realizations and how features in the coarse level are reﬂected in the
ﬁne level.
Gaussian Field
Figure 16.8 presents the logarithm of a Gaussian permeability ﬁeld as well
as some results of the multiscale analysis. In the plots, darker colors indi-
cate higher permeability values. The layout in Figure 16.8 is the same as in
Figure 16.7.
0.0
0.2
0.4
0.6
0.8
1.0
0.0
0.2
0.4
0.6
0.8
1.0
0.0
0.2
0.4
0.6
0.8
1.0
0.0
0.2
0.4
0.6
0.8
1.0
0.0
0.2
0.4
0.6
0.8
1.0
0.0
0.2
0.4
0.6
0.8
1.0
0.0
0.2
0.4
0.6
0.8
1.0
0.0
0.2
0.4
0.6
0.8
1.0
0.0 0.2 0.4 0.6 0.8 1.0
0.0 0.2 0.4 0.6 0.8 1.0
0.0 0.2 0.4 0.6 0.8 1.0
0.0 0.2 0.4 0.6 0.8 1.0
0.0 0.2 0.4 0.6 0.8 1.0
0.0 0.2 0.4 0.6 0.8 1.0
0.0 0.2 0.4 0.6 0.8 1.0
0.0 0.2 0.4 0.6 0.8 1.0
Fig. 16.8. Gaussian log-permeability ﬁeld: ﬁne level (ﬁrst line), coarse level (second
line), original ﬁeld (ﬁrst column), posterior mean (second column), and realizations
(third and fourth columns).
The multiscale framework recovers the original ﬁeld very well. The pos-
terior mean has most of the major features of the original ﬁeld, such as the
regions of lower permeability in the southeast corner and in the center-north,

208
16 Soil Permeability Estimation
and the region of higher permeability in the central region and in the center-
south.
It is really amazing to see how the ﬁne-level realizations derive from the
coarse-level realizations and how the ﬁne-level realizations are much smoother
than their coarse counterparts. There is a lot of variability between the ﬁne-
level realizations, but they still show some of the main features of the original
permeability ﬁeld. Moreover, some artifacts such as very small regions of lower
or higher permeability appear in each of the realizations. The appearance of
these artifacts happens because the ﬂuid can easily go around small regions
of low permeability.
Hill Air Force Base Dataset
In this example, the multiscale framework is used to estimate the permeabil-
ity ﬁeld of a test site where the ground contains several contaminants at Hill
Air Force Base in Utah. Multiple tracer experiments were run to estimate
the physical characteristics in order to support the cleanup of the aquifer
(Annable et al., 1998; Yoon, 2000). The focus here is on the data from an ex-
periment with a conservative tracer whose interaction with the contaminants
is negligible, so that the ﬂow data reﬂects the permeability structure of the
aquifer.
The 14 foot by 11 foot test site is modeled with two levels of resolution: a
coarse resolution on a 14 by 11 grid and a ﬁne resolution on a 28 by 22 grid. The
left plots of Figure 16.9 contain the locations of the wells and the breakthrough
times at each sampling well. There are four injection wells along a short edge
and three production wells along the opposite edge. The concentration of the
tracer is measured only at ﬁve sampling wells in the middle of the site.
Figure 16.9 shows the posterior means and realizations of the permeability
ﬁeld at both the coarse- and ﬁne-level resolutions. The plots in the left column
are the posterior means, and the plots in the other columns are realizations.
The upper and bottom lines correspond respectively to the ﬁne and coarse
levels of resolution. As the lower sampling well has the earliest breakthrough
time, the lower left region has the highest posterior mean permeability. In
addition, as the central sampling well has the latest breakthrough time and
a sampling well slightly to its left has the second earliest breakthrough time,
there is a sudden reduction in the posterior mean permeability close to the
central well. Moreover, the top left region has reasonably high posterior mean
permeability and the right region has intermediate level posterior mean per-
meability. Note that even though the posterior means at both resolution levels
are reasonably smooth, the posterior realizations are quite noisy, indicating
that many diﬀerent pathways are consistent with the observed breakthrough
times. Nevertheless, the posterior realizations clearly indicate that the region
close to the central well has the lowest permeability.

16.3 Implicit Multiscale Methods
209
0
2
4
6
8
10 12 14
0
2
4
6
8
10 12 14
0
2
4
6
8
10 12 14
0
2
4
6
8
10 12 14
0
2
4
6
8
10 12 14
0
2
4
6
8
10 12 14
0
2
4
6
8
10 12 14
0
2
4
6
8
10 12 14
0
2
4
6
8
10
0
2
4
6
8
10
0
2
4
6
8
10
0
2
4
6
8
10
0
2
4
6
8
10
0
2
4
6
8
10
0
2
4
6
8
10
0
2
4
6
8
10
S1
S2 S3
S4
S5
P
P
P
I
I
I
I
S1
S2 S3
S4
S5
P
P
P
I
I
I
I
Fig. 16.9. Hill Air Force Base example. Log-permeability ﬁeld: ﬁne level (ﬁrst line),
coarse level (second line), posterior mean (ﬁrst column), and realizations (second,
third, and fourth columns).
16.3 Implicit Multiscale Methods
An alternative modeling scheme to that in the previous section is to use in-
dependent priors at each level and then to link them implicitly via the com-
putation, as with the Metropolis-coupled methods from Chapter 14. Here we
use the same setup as in Section 16.2.4, considering dynamic data for two-
dimensional ﬁelds. Again, our data are the breakthrough times from a ﬂow
experiment, as the arrival times contain most of the available information.
In this section, we use only two resolutions, a coarse grid of 16×16 cells and
a ﬁne grid of 32 × 32 cells. Denote the observed breakthrough times by pobs,
and note that this same dataset is used for all scales. Denote the unknown ﬁeld
of coarse log-permeabilities by x0 and the ﬁne log-permeability ﬁeld as x1. Let
the function g represent the result of running a ﬂow simulator (here S3D) on an
input permeability ﬁeld, so that g(x0) is the vector of predicted breakthrough
times for the coarse ﬁeld x0 and g(x1) is the vector of predicted breakthrough
times for the ﬁne ﬁeld x1. We use independent Gaussian likelihoods at each
scale:
p(pobs|x0, x1, τ0, τ1) ∝exp

−τ0
2 (pobs −g(x0))′(pobs −g(x0))
−τ1
2 (pobs −g(x1))′(pobs −g(x1))

.
The precisions τ0 and τ1 could be treated separately or could be forced to be
equal.

210
16 Soil Permeability Estimation
We put a ﬁrst-order symmetric intrinsic 2-D Markov random ﬁeld prior
on the coarse and ﬁne scales. For each scale i,
p(xi|βi) ∝exp

−βi
2 x′
iHixi

,
(16.1)
where βi is the smoothness parameter for that scale, and H is the preci-
sion matrix with diagonal elements equal to the number of neighbors of that
grid cell and oﬀ-diagonal elements equal to −1 if the corresponding cells are
adjacent and 0 otherwise. The priors for the diﬀerent scales are treated as
independent of each other. Finally, we specify informative gamma priors on
τ0, τ1, β0, and β1.
Turning to the actual data, here we use the same Hill Air Force Base
data as in Section 16.2.4. There are four injection wells along one short edge
where water is pumped into the ground, and at a particular point in time
a tracer is added so that its concentration can be monitored at other sites.
Three production wells along the opposite edge extract water from the ground,
forcing water to ﬂow across the site. There are ﬁve sampling wells in the
middle, where the concentration of the tracer is measured (see the upper left
plot of Figure 16.10).
Well Data
0.42
0.34 0.93
0.52
0.17
P
P
P
I
I
I
I
Old Fine Values
0 5
15
25
0 5 10
20
30
0 5
15
25
0 5 10
20
30
0 5
15
25
0 5 10
20
30
0
5
15
10
0
5
10
15
0
5
15
10
0
5
10
15
0
5
10
15
0
5
10
15
Proposed Fine Values
Fine Posterior Mean
Old Coarse Values
Proposed Coarse
Coarse Posterior Mean
Fig. 16.10. Layout of wells, a sample swap, and posterior means for the Hill Air
Force Base data. In the upper left plot, the wells are labeled “I” for injectors, “P”
for producers, and the samplers are shown with numbers where the value is the
breakthrough time (in days) for each well. For the permeability plots, all values are
on the log scale, and lighter regions correspond to higher permeability values.
Running the Metropolis-coupling algorithm leads to good ﬁts of the data.
Figure 16.10 shows a representative swap between the coarse and ﬁne scales,

16.3 Implicit Multiscale Methods
211
cpu effort
permeability
0
50
100
150
200
250
300
500
1500
Lag
ACF
0
20
40
60
80
0.0
0.4
0.8
cpu effort
permeability
0
50
100
150
200
250
300
500
1500
Lag
ACF
0
20
40
60
80
0.0
0.4
0.8
fine scale MCMC
coupled MCMC
MCMC realizations
estimated autocorrelations
Fig. 16.11. MCMC trace plots and autocorrelation plots for the permeability at
an interior pixel in the hydrology application under the coupled MCMC approach
(top row) and standard MCMC within the ﬁne scale only (bottom row). The trace
plots are standardized to a comparable CPU time.
and one can see how the features of the ﬁelds are transferred between scales.
Yet the resulting ﬁelds also have a reasonable amount of smoothness for their
respective levels. The rightmost column of Figure 16.10 shows the posterior
mean log-permeability ﬁelds, with the ﬁne grid on top and the coarse grid be-
neath. Note that the lower and central sampling wells have the ﬁrst and last
breakthrough times, respectively. In order to be consistent with these data, the
posterior permeability realizations need to contain a high-permeability path
from the injectors to the lower sampling well, but also contain a rather abrupt
decrease near the central sampling well. Our methods here have captured this
structure. We note that such constraints can create severe diﬃculties in the
mixing of MCMC in that ﬁne-scale-only runs can have diﬃculties escaping
from local modes. Coupling the two scales allows the coarse-scale sampler,
which is far more eﬃcient in exploring its posterior, to pass this improved
performance on to the ﬁner scale. Figure 16.11 shows MCMC trace plots and
their associated autocorrelation functions for an interior pixel under the two
sampling schemes. Notice the order-of-magnitude diﬀerence in the range of
values explored by the coupled chain as compared with the single-scale chain.

212
16 Soil Permeability Estimation
Using Metropolis coupling yields autocorrelation times drastically smaller
than those of the standard ﬁne-scale MCMC algorithm.

17
Single Photon Emission Computed
Tomography Example
Single photon emission computed tomography (SPECT) is a medical imaging
technology. The patient is treated with a radioactive substance that releases
individual gamma rays (in small amounts, so as to be detectable but not
damaging to the patient). Some of these gamma rays are detected by a special
camera, and then a classic inverse problem results from the need to infer
the original image in the patient from the counts of detected gamma rays.
Computer code links hypothesized images to predicted gamma ray counts.
The primary goal is to reconstruct the features of the underlying object, such
as a patient’s brain. This image is typically desired at a particular resolution,
and only one type of data is collected, so there is nothing inherently multiscale
here. However, a fully Bayesian analysis requires the use of Markov chain
Monte Carlo methods, and the chain can take a long time to run because
of poor mixing. The use of multiscale techniques can greatly speed up the
computational aspects of the problem, improving the statistical inference that
can be done in a reasonable amount of time. Thus, we demonstrate the implicit
methods of Part IV with this example.
Poor mixing in this example can result from the fact that the unknown of
interest is an image, and naturally the pixels of the image are highly correlated.
Adjacent pixels are more likely to have the same or close to the same values
than are pixels farther away. In two or more dimensions, the correlations in
images can make it diﬃcult to eﬃciently explore the posterior. Furthermore,
when computer simulators are involved, such as the SPECT simulator (or the
ﬂow simulator from Chapter 16), each likelihood evaluation is considerably
more computationally expensive than in a standard statistical model. Thus,
improving mixing has a serious impact on the overall computational eﬃciency.
The gamma cameras can be set up for either two-dimensional or three-
dimensional imaging. Here we work only with the two-dimensional setup, but
the approaches easily generalize to the three-dimensional case. Some imaging
setups are to create a single static image, while others are designed to capture a
series of images over time, allowing the creation of an imaging movie. We keep
things simple by only dealing with a single static image here, as the need to

214
17 Single Photon Emission Computed Tomography Example
handle both space and time requires a more sophisticated model to deal with
diﬀerent correlations in space and time. Of course, the multiscale methods
directly generalize to the spatio-temporal setting when an appropriate model
is used.
In this chapter, our primary goal is to demonstrate the multiscale method-
ology, and thus we work with a somewhat simpliﬁed version of the problem.
We retain the key features of the real application but use several simplifying
assumptions that could be dealt with in more sophisticated ways. For more
complete treatments, we refer the reader to other references, such as Vardi
et al. (1985) or Higdon et al. (1997).
Thus this chapter focuses on the problem of reconstructing a two-dimen-
sional image. The goal is to build a photon emission intensity map of the
underlying object by using photon counts detected by a gamma camera. Figure
17.1 shows a conceptualized version of the physical setup of the problem and
the information available. The object is represented as a collection of pixels
at a certain resolution. Each pixel emits photons at a certain rate xi, where i
indexes the pixel location, and the intensities are expected to vary by spatial
location (which is what allows us to create the image). The gamma camera is
really an array of detectors that count the number of photons observed. Lead
columnators on the camera separate the detectors and absorb any photon that
fails to hit the camera at nearly a right angle. The camera thus obtains counts
within bins, with the bins indexed by b. The camera is fully rotated around
the object so that photons can be observed from all directions. The angle
of observation is denoted by a. The columnators ensure that the observed
photons are from the correct angle. The observed data are the counts yab
obtained from bin b of the gamma camera while it was positioned at angle a.
Here we use 120 camera positions and 128 camera bins; i.e., a ∈{1, . . . , 120}
and b ∈{1, . . . , 128}.
A photon may be scattered, absorbed, miss the gamma camera, or other-
wise fail to be detected. The columnators, along with the physical characteris-
tics of the object, determine the probability, pabi, that a photon emitted from
pixel i is detected by camera bin b when the camera is positioned at angle
a. Here we take the probabilities pabi as known. In practice, prior calibration
experiments are typically carried out to determine these probabilities, and
they can then be taken as ﬁxed and known.
It is then reasonable to model the counts yab as having a Poisson distrib-
ution with mean
θab =

i
xipabi
or rewriting this in matrix form
θn×1 = Pn×mxm×1,
(17.1)
where n = 128 × 120 is the total number of observations and m = 128 × 128
is the number of pixels. The object pixel intensities, xi, are the unknowns of

17 Single Photon Emission Computed Tomography Example
215
x
bin b
gamma camera
angle a
yab
i
object
pixel intensity
observed counts
Fig. 17.1. An object emits photons with location-dependent intensities xi. The
gamma camera array produces counts of photon emissions detected within bins.
The camera array is rotated around the object and at any given time of detection
the observation angle is denoted by a. The counts from each angle a and each bin b
are denoted yab.
interest, as the intensity map is the image that we wish to reconstruct. Given
these intensities, the likelihood can be written as
L(y|x) ∝

a,b
θyab
ab e−θab.
(17.2)
More details on the derivation of this likelihood can be found in Vardi et al.
(1985).
Primarily we are interested in this likelihood at this scale. However, it
will be computationally helpful to consider an auxiliary coarser scale for the
image intensity map of m0 = 64 × 64, which is half the resolution in each
dimension. Note that the observed data y are the same regardless of the
resolution for the underlying intensity map. Thus the likelihood is of the form
(17.2) for all scales, where only the values of θab may change with the change
in scale. The resulting coarse mean vector θ0 is still of length n, but it is the
product of the n × m0-dimensional probability matrix P0 and the vectorized
set of m0 unknown coarse pixel intensities x0. So calculating the change in

216
17 Single Photon Emission Computed Tomography Example
θ0 after changing an x0j is four times faster as compared with the ﬁne-scale
calculation.
Because the likelihood is Poisson and the ﬁne scale has exactly twice the
resolution in each dimension, it makes sense to move between scales by aggre-
gation. Thus the photon emission intensity of a coarse pixel is equal to the sum
of the emission intensities of the four corresponding ﬁne pixels. Note that this
summation across scales is in contrast to the more common averaging to move
from ﬁner to coarser scales, and is chosen because of the particular physical
details of the problem.
(a)
(c)
(e)
(g)
(b)
(d)
(f)
(h)
coarse
fine
true intensity
accepted swap proposal
posterior mean
Fig. 17.2. Coupled ﬁne- and coarse-scale MCMC for a SPECT example. (a) True
emission intensities; (b) coarsened version of the true intensities; (c) and (d) current
values for intensities x1 and x0 during the coupled MCMC run; (e) and (f) proposed
ﬁne and coarse images x∗and x∗
0 after swapping an interior patch of the images in
(c) and (d); (g) posterior mean for x1; (h) posterior mean for x0.
Here our data are from a computer-generated dataset from Higdon et al.
(2002). The true image source intensity is shown in Figure 17.2(a). The cor-
responding coarsened version is given in Figure 17.2(b). Because there is a
physical diﬀerence between pixels representing brain matter and pixels that
are outside of the brain, we use a mask for moving between scales, so that only
pixels within the brain area are dealt with in fully multiscale fashion. The pix-
els outside of the brain area are of less scientiﬁc interest, and emissions should
be close to zero. Thus inference focuses only on the interior region. Figure 17.3
shows a schematic version, where the active region is shaded.
Following the analysis in Higdon et al. (2002), we use a symmetric ﬁrst-
order intrinsic Gaussian Markov random ﬁeld (MRF) prior, as in Equa-
tion (14.5), for the intensities at each scale, x1 and x0. The precision matrices
H1 and H0 have diagonal elements Hii with values equal to the number of

17.1 Metropolis Coupling
217
@
@
@
@
@
@
R







-
-
current x1
current x0
intermediate value
intermediate value
proposal x∗
1
proposal x∗
0
ﬁne
coarse
Fig. 17.3. A proposal that swaps only a piece of the image between the coarse and
ﬁne scales. Given the current values for x and x0, the shaded regions of the two
images are exchanged, giving the intermediate values. The coarse shaded piece is
reﬁned to give a ﬁne proposal x∗, and the ﬁne shaded piece is coarsened to give a
coarse proposal x∗
0. The stochastic reﬁning of the coarse shaded piece conditions on
its previous coarse value as well as its neighboring ﬁne-scale pixels.
neighboring sites; their oﬀ-diagonal elements Hij are equal to −1 if sites i
and j are adjacent and 0 otherwise. The MRF structure works well for mul-
tiresolution image analysis since it naturally occurs on a grid and because the
methods of Chapters 14 and 15 are suitable for MRF models. Diﬀuse gamma
priors are assigned to the β precision parameter for each scale. At a particular
resolution, we perform standard MCMC, such as in Weir (1997) or Higdon
et al. (1997).
17.1 Metropolis Coupling
Our ﬁrst multiscale analysis uses the Metropolis coupling of Chapter 14, and
in particular Section 14.2.2. For creating the Metropolis-Hastings proposal
for moving from ﬁne to coarse, the intensities in proposed coarse pixels are
just the sum of the intensities of the four corresponding ﬁne pixels. To get
the proposed ﬁne values from the current coarse image map, for each coarse
pixel, the four corresponding ﬁne pixels of the proposal are ﬁrst set at a value
which is one-quarter that of the coarse pixel, which produces the intermediate

218
17 Single Photon Emission Computed Tomography Example
step in Figure 17.3. This is done for all of the proposed ﬁne-scale pixels. After
this step is complete, then the intermediate map is smoothed by taking each
block of four ﬁne pixels and drawing them from their conditional distribution,
conditioning on them having the same mean value as their current value (or,
equivalently, the same total value) and conditioned on the current values of all
neighbors. This smoothing step helps create a more realistic proposal that has
a reasonable probability of being accepted. The conditioning on the proper
mean ensures reversibility. It is necessary to take this smoothing step into
account when computing the Metropolis-Hastings ratio for the probability of
acceptance.
cpu effort
intensity
0
100
200
300
400
500
0
100
200
300
Lag
ACF
0
10
20
30
40
0.0
0.4
0.8
cpu effort
intensity
0
100
200
300
400
500
0
100
200
300
Lag
ACF
0
10
20
30
40
0.0
0.4
0.8
fine scale MCMC
coupled MCMC
MCMC realizations
estimated autocorrelations
Fig. 17.4. Trace plots and autocorrelation plots for the intensity of an interior
pixel under the Metropolis-coupled approach (top row) and standard single-scale
MCMC (bottom row). The coupled MCMC is about three times as eﬃcient when
standardized to CPU eﬀort.
For our SPECT example, this proposal has about a one in eight chance
of acceptance. Figure 17.2 shows the before and after images for an accepted
swap (images (c) to (f)) along with coarse- and ﬁne-scale posterior mean
images (images g and h). MCMC trace plots of the ﬁtted intensity value
of an interior pixel are shown in Figure 17.4 for Metropolis-coupled MCMC
(top) and a single-scale MCMC run at the ﬁner resolution only (bottom). The

17.2 Genetic Algorithms
219
coupled MCMC produces notably better mixing as evidenced both in the trace
plots and in the autocorrelation plots, where the estimated autocorrelation
times (Sokal, 1987) for the coupled MCMC are about a third of those for the
single-scale MCMC algorithm. Note that the trace plots are standardized to
a comparable CPU time to account for the fact that Metropolis coupling is
more computationally intensive. Yet this small additional eﬀort clearly leads
to overall gains in eﬃciency.
17.2 Genetic Algorithms
In this example, we can further improve upon the results from Metropolis
coupling by using the multiscale MCMC methods derived from genetic algo-
rithms in Chapter 15. We now add in the multiscale crossover swap proposals
from Section 15.3.2 using each about half of the time.
For the crossover steps, we need to reparameterize so that the parame-
ter vector is suitable for crossover sampling. In the notation of Chapter 15,
let φ(2) = x(2) and let φ(1) be the sum of each block of four ﬁne pixels
corresponding to a single coarse pixel, so that φ(1) and φ(2) have the same
dimension and interpretation. λ(1) is then deﬁned as the values of the upper
left, upper right, and lower left pixels for each of the blocks of four ﬁne pixels
(since knowing those three and their sum determines the fourth pixel for each
block). λ(1) also contains β(1), and λ(2) = β(2). Finally, π(i) is the product of
the diﬀuse gamma prior on β(i) and the MRF prior induced on (φ(i), λ(i)) by
Equation (14.5).
We then use both full swaps (the Metropolis-coupled swaps from above)
and crossover swaps. While the full swaps exchange all of the φ values (i.e., the
full grid), the crossover swaps exchange only a subset of φ values and sample
only the associated pixels in λ(1), as well as β(1) and β(2). (An alternative
crossover scheme could swap clusters of coarse pixels, such as a 4 × 4 block,
which might preserve more of the local structure of the MRF prior.)
About one in eight full swaps and about one in ﬁve crossover swaps were
accepted. Crossover swaps often have larger acceptance probabilities because
less of the parameter space is being changed at the same time, yet they still
provide a large increase in mixing when compared with most single-scale tech-
niques. However, they do not improve mixing as much as an accepted full swap
typically does since it changes the entire parameter space. Thus the combina-
tion of full and crossover swaps can be quite beneﬁcial. Figure 17.5 shows an
accepted full swap along with coarse- and ﬁne-scale posterior mean images.
Autocorrelation functions are shown in Figure 17.6 for a representative ﬁne
pixel under three posterior sampling schemes: a single-resolution chain, a mul-
tiresolution approach that only uses Metropolis-coupled full swaps, and the
combination of both full and crossover swaps. Comparing the two multiscale
results provides a method for attempting to separate out the eﬀect of using
multiple scales from the additional gains made by the genetic algorithm-style

220
17 Single Photon Emission Computed Tomography Example
(a)
(c)
(e)
(g)
(b)
(d)
(f)
(h)
Coarse
Fine
True Intensity
Accepted Full Swap
Posterior Mean
Fig. 17.5. Modeling using multiscale genetic algorithm-style MCMC. (a) True emis-
sion intensities; (b) coarsened version of the true intensities; (c) and (d) snapshot
of current ﬁne and coarse intensity values right before a swap; (e) and (f) ﬁne and
coarse images after a swap; (g) ﬁne posterior mean intensity map; (h) coarse poste-
rior mean intensity map.
proposals. The combination approach reduces the estimated autocorrelation
times by more than Metropolis coupling alone does, even after adjusting for
comparable CPU time. As such, gains from any multiscale approach are signiﬁ-
cant, and additional gains can be obtained from eﬃcient multiscale algorithms
such as this combination swapping approach.

17.2 Genetic Algorithms
221
No Swapping
Lag
ACF
0
10
20
30
40
0.0
0.2
0.4
0.6
0.8
1.0
Only Full Swapping
Lag
ACF
0
10
20
30
40
0.0
0.2
0.4
0.6
0.8
1.0
All Swapping
Lag
ACF
0
10
30
30
40
0.0
0.2
0.4
0.6
0.8
1.0
Fig. 17.6. Autocorrelation plots for the intensity of an interior pixel in the SPECT
application under the single-chain standard MCMC at the ﬁne scale only (left),
multiscale with full swaps only (middle), and our multiscale MCMC approach with
full and crossover swaps (right).


18
Conclusions
Multiscale modeling presents a number of challenges beyond standard statis-
tical modeling. In particular, there is the need for consistent modeling across
diﬀerent scales. The methods presented in this book represent a wide vari-
ety of such approaches, having been grouped into three general categories:
methods for building a model at the ﬁnest levels that can be simpliﬁed for
coarser scales, methods for explicitly modeling the relationship between scales,
and methods that implicitly link the scales. We expect that additional new
approaches will continue to be developed in the future.
Depending on the particular problem, some approaches may be more rel-
evant or sensible than others. In some cases, the analyst will have a choice of
possible multiscale approaches. As many of these methods have only been de-
veloped quite recently, there has been little analysis comparing the methods,
either analytically or empirically. We want to encourage this investigation, and
hope that such research will produce practical suggestions and guidelines.
The Bayesian approach is powerful, allowing a number of approaches that
would be diﬃcult or impossible without the ability to incorporate prior infor-
mation. It also allows a coherent accounting of uncertainty, something that
can be quite diﬃcult to do across multiple scales. Markov chain Monte Carlo
methods provide a general mechanism for ﬁtting these models.
In many cases, the multiscale problem is diﬃcult because of a lack of direct
information for moving between scales. Care must be taken not to incorporate
incorrect information, which can easily sneak in when specifying priors. It is
common to use priors that are convenient either because they are conjugate (or
conditionally conjugate) or because a particular parametric form makes the
speciﬁcation of hyperparameters easier. Such practices can have inadvertent
eﬀects on the posterior. As multiscale problems are often characterized by not
having as much data as one would like at all of the scales, the prior information
becomes quite important. This setting necessitates serious thinking about the
choice of priors. It would also be a good idea to conduct a sensitivity analysis
to see how much the posterior depends on the choice of the prior. In many
cases, it will be highly dependent, but one can see if a reasonable range of prior

224
18 Conclusions
speciﬁcations leads to similar conclusions, and one can see which parameters
have the most inﬂuence and hence which parts of the prior are the most
important.

References
Abrahamsen, P. (1997). “A review of Gaussian random ﬁelds and correlation
functions.” Technical Report 917, Norwegian Computing Center.
Abramovich, F., Sapatinas, T., and Silverman, B. W. (1998). “Wavelet thresh-
olding via a Bayesian approach.” Journal of the Royal Statistical Society,
Series B, 60, 725–749.
Abramowitz, M. and Stegun, I. A. (1964). Handbook of Mathematical Func-
tions with Formulas, Graphs, and Mathematical Tables. 9th ed. New York:
Dover.
Albert, J. H. and Chib, S. (1993). “Bayes inference via Gibbs sampling of
autoregressive time series subjec to to Markov mean and variance shifts.”
Journal of Business and Economic Statistics, 11, 1–15.
Amemiya, T. and Wu, R. Y. (1972). “The eﬀect of aggregation on prediction in
the autoregressive model.” Journal of the American Statistical Association,
67, 628–632.
Annable, M. D., Rao, P. S. C., Hatﬁeld, K., Graham, W. D., Wood, A. L., and
Enﬁeld, C. G. (1998). “Partitioning tracers for measuring residual NAPL:
Field-scale test results.” Journal of Environmental Engineering, 124, 498–
503.
B¨ack, T. (1993). “Optimal mutation rates in genetic search.” In Proceedings
of the Fifth International Conference on Genetic Algorithms, ed. S. Forrest,
2–8. San Mateo, CA: Morgan Kaufmann.
Banerjee, S., Carlin, B. P., and Gelfand, A. E. (2003). Hierarchical Modeling
and Analysis for Spatial Data. Boca Raton, FL: Chapman and Hall.
Barone, P., Sebastiani, G., and Stander, J. (2002). “Over-relaxation methods
and coupled Markov chains for Monte Carlo simulation.” Statistics and
Computing, 12, 17–26.
Barry, R. P. and Ver Hoef, J. M. (1996). “Blackbox Kriging: Spatial prediction
without specifying variogram models.” Journal of Agricultural, Biological,
and Environmental Statistics, 1, 297–322.

226
References
Basseville, M., Benveniste, A., and Willsky, A. S. (1992a). “Multiscale autore-
gressive processes, part I: Schur-Levinson parametrizations.” IEEE Trans-
actions on Signal Processing, 40, 1915–1934.
— (1992b). “Multiscale autoregressive processes, part II: Lattice structures
for whitening and modeling.” IEEE Transactions on Signal Processing, 40,
1935–1953.
Beran, J. (1994). Statistical Methods for Long Memory Processes. Boca Raton,
FL: Chapman and Hall.
Berger, J. O., de Oliveira, V., and Sans´o, B. (2001). “Objective Bayesian
analysis of spatially correlated data.” Journal of the American Statistical
Association, 96, 1361–1374.
Besag, J. (1974). “Spatial interaction and the statistical analysis of lattice
systems (with discussion).” Journal of the Royal Statistical Society, Series
B, 36, 192–236.
— (2000).
“Markov chain Monte Carlo for statistical inference.”
Techni-
cal Report, University of Washington, Center for Statistics and the Social
Sciences.
Besag, J., Green, P., Higdon, D., and Mengersen, K. (1995). “Bayesian com-
putation and stochastic systems (with discussion).” Statistical Science, 10,
3–66.
Besag, J. and Kooperberg, C. (1995). “On conditional and intrinsic autore-
gressions.” Biometrika, 82, 733–746.
Besag, J., York, J., and Molli´e, A. (1991). “Bayesian image restoration, with
two applications in spatial statistics (with discussion).” Annals of the In-
stitute of Statistical Mathematics, 43, 1–59.
Best, N. G., Ickstadt, K., and Wolpert, R. L. (2000). “Spatial Poisson re-
gression for health and exposure data measured at disparate resolutions.”
Journal of the American Statistical Association, 95, 1076–1088.
Bollerslev, T. and Wright, J. H. (2000). “Semiparametric estimation of long-
memory volatility dependencies: The role of high-frequency data.” Journal
of Econometrics, 98, 81–106.
Bonet-Cunha, L., Oliver, D. S., Redner, R. A., and Reynolds, A. C. (1998).
“A hybrid Markov chain Monte Carlo method for generating permeability
ﬁelds conditioned to multiwell pressure data and prior information.” SPE
Journal, 3, 261–271.
Bouman, C. and Liu, B. (1991). “Multiple resolution segmentation of textured
images.” IEEE Transactions on Pattern Analysis and Machine Intelligence,
13, 99–113.
Bouman, C. A. and Shapiro, M. (1994). “A multiscale random ﬁeld model for
Bayesian image segmentation.” IEEE Transactions on Image Processing,
3, 162–177.
Bouman, P., Dukic, V., and Mengu, X.-L. (2005). “A Bayesian multiresolution
hazard model with application to an AIDS reporting delay study.” Statistica
Sinica, 15, 325–357.

References
227
Breiman, L., Friedman, J. H., Olshen, R., and Stone, C. (1984). Classiﬁcation
and Regression Trees. Belmont, CA: Wadsworth.
Briggs, W. L., Henson, V. E., and McCormick, S. F. (2000).
A Multigrid
Tutorial. 2nd ed. Philadelphia: Society for Industrial and Applied Mathe-
matics.
Brockwell, P. J. and Davis, R. A. (1991). Time Series: Theory and Methods.
2nd ed. New York: Springer.
Brooks, S. P. (1998). “Markov chain Monte Carlo method and its application.”
The Statistician, 47, 69–100.
Brown, P. J., Fearn, T., and Vannucci, M. (2001). “Bayesian wavelet regression
on curves with application to a spectroscopic calibration problem.” Journal
of the American Statistical Association, 96, 398–408.
Brownie, C., Bowman, D. T., and Burton, J. W. (1994). “Estimating spatial
variation in analysis of data from yield trials: A comparison of methods.”
Agronomy Journal, 85, 1244–1253.
Bustamante, C., Boaventura, E. G., Tassinari, W., Reis, M. G., Carvalho, M.,
and Ko, A. I. (2006). “The eﬀect of climate on cyclic epidemic transmission
of urban leptospirosis.” Technical Report, Fiocruz.
Calder, C. A., Holloman, C., and Higdon, D. M. (2002). “Exploring space-
time structure in ozone concentration using a dynamic process convolution
model.” In Case Studies in Bayesian Statistics 6, eds. C. Gatsonis, R. E.
Kass, A. Carriquiry, A. Gelman, D. Higdon, D. K. Pauler, and I. Verdinelli,
165–176. New York: Springer.
Calder´on, A. P. (1964). “Intermediate spaces and interpolation, the complex
method.” Studia Mathematica, 24, 113–190.
Carlin, B. P. and Banerjee, S. (2003). “Hierarchical multivariate CAR mod-
els for spatio-temporally correlated survival data.”
In Bayesian Statis-
tics 7, eds. J. M. Bernardo, M. J. Bayarri, J. O. Berger, A. P. Dawid,
D. Heckerman, A. F. M. Smith, and M. West, 45–63. Oxford: Oxford Uni-
versity Press.
Carlin, B. P. and Chib, S. (1995). “Bayesian model choice via Markov chain
Monte Carlo methods.” Journal of the Royal Statistical Society, Series B,
57, 473–484.
Carter, C. K. and Kohn, R. (1994).
“On Gibbs sampling for state space
models.” Biometrika, 81, 541–553.
Chatterjee, S., Laudato, M., and Lynch, L. A. (1996). “Genetic algorithms and
their statistical applications: An introduction.” Computational Statistics
and Data Analysis, 22, 633–651.
Chib, S. and Greenberg, E. (1994). “Bayes inference in regression models with
ARMA(p,q) errors.” Journal of Econometrics, 64, 183–206.
Chil`es, J.-P. and Delﬁner, P. (1999). Geostatistics: Modeling Spatial Uncer-
tainty. New York: John Wiley and Sons.
Chipman, H., George, E., and McCulloch, R. (1998). “Bayesian CART model
search (with discussion).” Journal of the American Statistical Association,
93, 935–960.

228
References
Chipman, H. A., George, E. I., and McCulloch, R. E. (2002). “Bayesian treed
models.” Machine Learning, 48, 303–324.
Chipman, H. A., Kolaczyk, E. D., and McCulloch, R. E. (1997). “Adaptive
Bayesian wavelet shrinkage.” Journal of the American Statistical Associa-
tion, 92, 1413–1421.
Chopin, N. and Pelgrin, F. (2004).
“Bayesian inference and state number
determination for hidden Markov models: An application to the information
content of the yield curve about inﬂation.” Journal of Econometrics, 123,
327–344.
Chou, K. C., Willsky, A. S., and Benveniste, A. (1994a). “Multiscale recur-
sive estimation, data fusion, and regularization.” IEEE Transactions on
Automatic Control, 39, 464–478.
Chou, K. C., Willsky, A. S., and Nikoukhah, R. (1994b). “Multiscale systems,
Kalman ﬁlters, and Riccati equations.” IEEE Transactions on Automatic
Control, 39, 479–492.
Clyde, M. and George, E. I. (2000). “Flexible empirical Bayes estimation for
wavelets.” Journal of the Royal Statistical Society, Series B, 62, 681–698.
Clyde, M., Parmigiani, G., and Vidakovic, B. (1998). “Multiple shrinkage and
subset selection in wavelets.” Biometrika, 85, 391–402.
Cohen, A., Daubechies, I., Jawerth, B., and Vial, P. (1993). “Multiresolution
analysis, wavelets and fast algorithms on an interval.” Comptes Rendus I ,
316, 417–421.
Comer, M. and Delp, E. (1999).
“Segmentation of textured images using
a multiresolution Gaussian autoregressive model.” IEEE Transactions on
Image Processing, 8, 408–420.
Craig, P. S., Goldstein, M., Seheult, A. H., and Smith, J. A. (1996). “Bayes lin-
ear strategies for history matching of hydrocarbon reservoirs.” In Bayesian
Statistics 5, eds. J. M. Bernardo, J. O. Berger, A. P. Dawid, and A. F. M.
Smith, 69–95. Oxford: Clarendon Press.
Cressie, N. A. C. (1993). Statistics for Spatial Data, revised edition. New
York: John Wiley and Sons.
Crouse, M. S., Nowak, R. D., and Baraniuk, R. G. (1998). “Wavelet-based sta-
tistical signal processing using hidden Markov models.” IEEE Transactions
on Signal Processing, 46, 886–902.
Damian, D., Sampson, P. D., and Guttorp, P. (2001). “Bayesian estimation
of semiparametric nonstationary spatial covariance structure.”
Environ-
metrics, 12, 161–178.
Daoudi, K., Frakt, A. B., and Willsky, A. S. (1999). “Multiscale autoregres-
sive models and wavelets.” IEEE Transactions on Information Theory, 45,
828–845.
Daubechies, I. (1992). Ten Lectures on Wavelets. Philadelphia: Society for
Industrial and Applied Mathematics.
Dawid, A. P. (1992). “Applications of a general propagation algorithm for
probabilistic expert systems.” Statistics and Computing, 2, 25–36.

References
229
DeJong, K. (1975). “An Analysis of the Behavior of a Class of Genetic Adap-
tive Systems.” Ph.D. thesis, University of Michigan, Ann Arbor, MI.
Dempster, A. P., Laird, N., and Rubin, D. B. (1977). “Maximum likelihood
from incomplete data via the EM algorithm.” Journal of the Royal Statis-
tical Society, Series B, 39, 1–38.
Dempster, A. P., Selwyn, M. R., Patel, C. M., and Roth, A. J. (1984). “Sta-
tistical and computational aspects of mixed model analysis.” Applied Sta-
tistics, 33, 203–214.
Denison, D. G. T., Holmes, C. C., Mallick, B. K., and Smith, A. F. M. (2002).
Bayesian Methods for Nonlinear Classiﬁcation and Regression.
London:
John Wiley and Sons.
Denison, D. G. T., Mallick, B. K., and Smith, A. F. M. (1998). “A Bayesian
CART algorithm.” Biometrika, 85, 363–377.
Diaconis, P. and Zabell, S. L. (1982).
“Updating subjective probability.”
Journal of the American Statistical Association, 77, 822–830.
Donoho, D. L. and Johnstone, I. M. (1994). “Ideal spatial adaptation via
wavelet shrinkage.” Biometrika, 81, 425–455.
— (1995). “Adapting to unknown smoothness via wavelet shrinkage.” Journal
of the American Statistical Association, 90, 1200–1224.
Donoho, D. L., Johnstone, I. M., Kerryacharian, G., and Picard, D. (1995).
“Wavelet shrinkage: Asymptopia?” Journal of the Royal Statistical Society,
Series B, 57, 301–369.
Drost, F. C. and Nijman, T. E. (1993). “Temporal aggregation of GARCH
processes.” Econometrica, 61, 909–927.
Evans, M. and Swartz, T. (1995). “Methods for approximating integrals in
statistics with special emphasis on Bayesian integration problems (Disc:
V11 P54-64).” Statistical Science, 10, 254–272.
Fang, K.-T., Li, R., and Sudjianto, A. (2006). Design and Modeling for Com-
puter Experiments. Boca Raton, FL: Chapman and Hall/CRC.
Ferreira, M. A. R., Bi, Z., West, M., Lee, H., and Higdon, D. (2003). “Multi-
scale modelling of 1-D permeability ﬁelds.” In Bayesian Statistics 7, eds.
J. M. Bernardo, M. J. Bayarri, J. O. Berger, A. P. Dawid, D. Heckerman,
A. F. M. Smith, and M. West, 519–527. Oxford: Oxford University Press.
Ferreira, M. A. R. and de Oliveira, V. (2007). “Bayesian reference analysis
for Gaussian Markov random ﬁelds.” Journal of Multivariate Analysis, 98,
789–812.
Ferreira, M. A. R., Higdon, D., Lee, H. K. H., and West, M. (2005). “Multiscale
random ﬁeld models.” Technical Report, UFRJ - DME.
Ferreira, M. A. R., West, M., Lee, H. K. H., and Higdon, D. (2006). “Multi-
scale and hidden resolution time series models.”
Bayesian Analysis, 1,
947–968.
Floris, F. J. T., Bush, M. D., Cuypers, M., Roggero, F., and Syversveen, A.-R.
(2001). “Methods for quantifying the uncertainty of production forecasts:
A comparative study.” Petroleum Geosciences, 7, S87–S96.

230
References
Flowerdew, R. and Green, M. (1989). “Statistical methods for inference be-
tween incompatible zonal systems.” In Accuracy of Spatial Databases, eds.
M. Goodchild and S. Gopal, 239–247. London: Taylor and Francis.
— (1994). “Areal interpolation and types of data.” In Spatial Analysis and
GIS, eds. S. Fotheringham and P. Rogerson, 121–145. London: Taylor and
Francis.
Forney, G. D. (1973). “The Viterbi algorithm.” Proceedings of the IEEE, 61,
268–278.
Frakt, A. B. and Willsky, A. S. (1998). “Multiscale autoregressive models
and the stochastic realization problem.” In 32nd Asilomar Conference on
Signals, Systems and Computers, 747–751. Paciﬁc Grove, CA: IEEE.
Fr¨uhwirth-Schnatter, S. (1994). “Data augmentation and dynamic linear mod-
els.” Journal of Time Series Analysis, 15, 183–202.
Fuentes, M. and Smith, R. L. (2001). “A new class of nonstationary spatial
models.” Technical Report 2534, North Carolina State University, Depart-
ment of Statistics.
Gamerman, D. and Lopes, H. F. (2006). Markov Chain Monte Carlo: Stochas-
tic Simulation for Bayesian Inference. 2nd ed. Boca Raton, FL: Chapman
and Hall/CRC.
Gehlke, C. E. and Biehl, K. (1934). “Certain eﬀects of grouping upon the
size of the correlation coeﬃcient in census tract material.” Journal of the
American Statistical Association, 29, 169–170.
Gelfand, A. E., Schmidt, A. M., Banerjee, S., and Sirmans, C. F. (2004).
“Nonstationary multivariate process modeling through spatially varying
coregionalization (with discussion).” Test, 13, 1–50.
Gelhar, L. W. (1993). Stochastic Subsurface Hydrology. Englewood Cliﬀs, NJ:
Prentice-Hall.
Gelman, A. (1996).
“Inference and monitoring convergence.”
In Markov
Chain Monte Carlo in Practice, eds. W. R. Gilks, S. Richardson, and D. J.
Spiegelhalter, 131–143. London: Chapman and Hall.
Gelman, A., Carlin, J. B., Stern, H. S., and Rubin, D. B. (1995). Bayesian
Data Analysis. London: Chapman and Hall.
Geyer, C. J. (1991). “Markov chain Monte Carlo maximum likelihood.” In
Computing Science and Statistics. Proceedings of the 23rd Symposium on
the Interface, 156–163. Fairfax Station, VA: Interface Foundation of North
America.
Geyer, C. J. and Thompson, E. A. (1995). “Annealing Markov chain Monte
Carlo with applications to ancestral inference.” Journal of the American
Statistical Association, 90, 909–920.
Gidas, B. (1989). “A renormalization group approach to image processing
problems.” IEEE Transactions on Pattern Analysis and Machine Intelli-
gence, 11, 164–180.
Goldberg, D. E., Korb, B., and Deb, K. (1989). “Messy genetic algorithms:
Motivation, analysis, and ﬁrst results.” Complex Systems, 3, 493–530.

References
231
Goodman, J. and Sokal, A. D. (1989).
“Multigrid Monte Carlo method.”
Physical Review Letters D, 40, 2035–2072.
Gotway, C. A. and Young, L. J. (2002). “Combining incompatible spatial
data.” Journal of the American Statistical Association, 97, 632–648.
Gramacy, R. B. and Lee, H. K. H. (2006). “Bayesian treed Gaussian process
models.” Technical Report ams2006-08, Dept. of Applied Math and Statis-
tics, University of California, Santa Cruz.
Green, P. J. (1995). “Reversible jump Markov chain Monte Carlo computation
and Bayesian model determination.” Biometrika, 82, 711–732.
Grossmann, A. and Morlet, J. (1984). “Decomposition of Hardy Functions
into Square Integrable Wavelets of Constant Shape.”
SIAM Journal on
Mathematical Analysis, 15, 723–736.
Haar, A. (1910). “Zur theorie der orthogonalen funktionensysteme.” Mathe-
matische Annalen, 69, 331–371.
Haas, T. C. (1990). “Lognormal and moving window methods of estimat-
ing acid deposition.” Journal of the American Statistical Association, 85,
950–963.
Hamilton, J. D. (1989). “A new approach to the economic analysis of nonsta-
tionary time series and the business cycle.” Econometrica, 57, 357–384.
Harvey, A. C. (1989). Forecasting, Structural Time Series Models and the
Kalman Filter. Cambridge: Cambridge University Press.
Harville, D. A. (1997). Matrix Algebra from a Statistician’s Perspective. New
York: Springer-Verlag.
Hastie, T., Tibshirani, R., and Friedman, J. (2001). The Elements of Statistical
Learning. New York: Springer-Verlag.
Hastings, W. K. (1970). “Monte Carlo sampling methods using Markov chains
and their applications.” Biometrika, 57, 97–109.
Hegstad, B. K. and Omre, H. (1997).
“Uncertainty assessment in history
matching and forecasting.” In Geostatistics Wollongong ’96, Vol. 1., ed.
E. Y. Baaﬁand N. A. Schoﬁeld, 585–596. Dordrecht: Kluwer Academic
Publishers.
Higdon, D. (2002). “Space and space-time modeling using process convolu-
tions.”
In Quantitative Methods for Current Environmental Issues, eds.
C. Anderson, V. Barnett, P. C. Chatwin, and A. H. El-Shaarawi, 37–56.
London: Springer-Verlag.
Higdon, D., Lee, H., and Bi, Z. (2002). “A Bayesian approach to characterizing
uncertainty in inverse problems using coarse and ﬁne scale information.”
IEEE Transactions on Signal Processing, 50, 389–399.
Higdon, D. M., Johnson, V. E., Bowsher, J. E., Turkington, T. G., Gilland,
D. R., and Jaszczack, R. J. (1997). “Fully Bayesian estimation of Gibbs
hyperparameters for emission computed tomography data.” IEEE Trans-
actions on Medical Imaging, 16, 516–526.
Higdon, D. M., Lee, H., and Holloman, C. (2003).
“Markov chain Monte
Carlo-based approaches for inference in computationally intensive inverse
problems.” In Bayesian Statistics 7, Proceedings of the Seventh Valencia

232
References
International Meeting, eds. J. M. Bernardo, M. J. Bayarri, J. O. Berger,
A. P. Dawid, D. Heckerman, A. F. M. Smith, and M. West. Oxford: Oxford
University Press.
Higdon, D. M., Swall, J., and Kern, J. C. (1999). “Non-stationary spatial
modeling.” In Bayesian Statistics 6, eds. J. M. Bernardo, J. O. Berger,
A. P. Dawid, and A. F. M. Smith, 761–768. Oxford: Oxford University
Press.
Hjort, N. L. and Omre, H. (1994). “Topics in spatial statistics.” Scandinavian
Journal of Statistics, 21, 289–357.
Holland, J. H. (1975). Adaptation in Natural and Artiﬁcial Systems. Ann
Arbor: The University of Michigan Press.
Holloman, C. (2002). “Parameter Estimation Algorithms for Computationally
Intensive Spatial Problems.” Ph.D. thesis, Duke University, Durham, NC.
Holloman, C. H., Lee, H. K. H., and Higdon, D. M. (2006). “Multi-resolution
genetic algorithms and Markov chain Monte Carlo.” Journal of Computa-
tional and Graphical Statistics, 15, 861–879.
Holmes, C. C. and Mallick, B. K. (1998). “Parallel Markov chain Monte Carlo
sampling.” Technical Report, Imperial College, London.
Host, G., Omre, H., and Switzer, P. (1995).
“Spatial interpolation errors
for monitoring data.” Journal of the American Statistical Association, 90,
853–861.
Houghton, J. T., Jenkins, G. J., and Ephraums, J. J., eds. (1990). Climate
Change: The IPCC Scientiﬁc Assessment. Intergovernmental Panel on Cli-
mate Change. Cambridge: Cambridge University Press.
Huang, H.-C. and Cressie, N. (1997).
“Multiscale spatial modeling.”
In
ASA Proceedings of the Section on Statistics and the Environment, 49–54.
Alexandria, VA: American Statistical Association.
— (2001). “Multiscale graphical modeling in space: applications to command
and control.” In Spatial Statistics: Methodological Aspects and Applications,
ed. M. Moore, 83–113. New York: Springer.
Huang, H.-C., Cressie, N., and Gabrosek, J. (2002).
“Fast, resolution-
consistent spatial prediction of global processes from satellite data.” Journal
of Computational and Graphical Statistics, 11, 63–88.
Husmeier, D. and McGuire, G. (2003).
“Detecting recombination in 4-
taxa DNA sequence alignments with Bayesian hidden Markov models and
Markov chain Monte Carlo.” Molecular Biology and Evolution, 20, 315–337.
Hwang, S. (2000).
“The eﬀects of systematic sampling and temporal ag-
gregation on discrete time long memory processes and their ﬁnite sample
properties.” Econometric Theory, 16, 347–372.
Ickstadt, K. and Wolpert, R. L. (1999). “Spatial regression for marked point
processes.” In Bayesian Statistics 6, eds. J. M. Bernardo, J. O. Berger, A. P.
Dawid, and A. F. M. Smith, 323–341. Oxford: Oxford University Press.
Irving, W. W., Fieguth, P. W., and Willsky, A. S. (1997). “An overlapping
tree approach to multiscale stochastic modeling and estimation.”
IEEE
Transactions on Image Processing, 6, 1517–1529.

References
233
Isaaks, E. H. and Srivastava, R. M. (1989). Applied Geostatistics. Oxford:
Oxford University Press.
James, A. I., Graham, W. D., Hatﬁeld, K., Rao, P. S. C., and Annable, M. D.
(1997). “Optimal estimation of residual non-aqueous phase liquid saturation
using partitioning tracer concentration data.” Water Resources Research,
33, 2621–2636.
Jeﬀrey, R. C. (1988). “Conditioning, kinematics, and exchangeability.” In
Causation, Chance, and Credence, eds. B. Skyrms and W. L. Harper, vol. 1,
221–255. Dordrecht: Kluwer.
— (1992).
Probability and the Art of Judgement.
New York: Cambridge
University Press.
Jin, M., Delshad, M., Dwarakanath, V., McKinney, D. C., Pope, G. A.,
Sepehrnoori, K., Tilburg, C. E., and Jackson, R. E. (1995). “Partitioning
tracer test for detection, estimation, and remediation performance assess-
ment of subsurface non-aqueous phase liquids.” Water Resources Research,
31, 1201–1211.
Johnson, V. E. (1998). “A coupling-regeneration scheme for diagnosing con-
vergence in Markov chain Monte Carlo algorithms.” Journal of the Ameri-
can Statistical Association, 93, 238–248.
Johnstone, I. M. and Silverman, B. W. (1998). “Empirical Bayes approaches to
mixture problems and wavelet regression.” Technical Report, Department
of Mathematics, University of Bristol.
— (2004). “Needles and straw in haystacks: Empirical Bayes estimates of
possibly sparse sequences.” Annals of Statistics, 32, 1594–1649.
— (2005). “Empirical Bayes selection of wavelet thresholds.” Annals of Sta-
tistics, 33, 1700–1752.
Journel, A. G. and Huijbregts, C. J. (1978). Mining Geostatistics. New York:
Academic Press.
Juang, B. H. and Rabiner, L. R. (1991). “Hidden Markov models for speech
recognition.” Technometrics, 33, 251–272.
Kato, Z., Berthod, M., and Zerubia, J. (1996a). “A hierarchical Markov ran-
dom ﬁeld model and multi-temperature annealing for parallel image classi-
ﬁcation.” Graphical Models and Image Processing, 58, 18–37.
Kato, Z., Zerubia, J., and Berthod, M. (1996b). “Unsupervised parallel im-
age classiﬁcation using Markovian models.” Graphical Models and Image
Processing, 58, 18–37.
Katul, G. G., Vidakovic, B., and Albertson, J. D. (2001). “Estimating global
and local scaling exponents in turbulent ﬂows using wavelet transforma-
tions.” Physics of Fluids, 13, 241–250.
Kennedy, M. C. and O’Hagan, A. (2000). “Predicting the output from a com-
plex computer code when fast approximations are available.” Biometrika,
87, 1–13.
— (2001). “Bayesian calibration of computer models.” Journal of the Royal
Statistical Society, Series B, 63, 425–464.

234
References
Kern, J. C. (2000). “Bayesian Process-Convolution Approaches to Specifying
Spatial Dependence Structure.” Ph.D. thesis, Duke University, Durham,
NC.
Kim, H.-M., Mallick, B. K., and Holmes, C. C. (2005). “Analyzing nonsta-
tionary spatial data using piecewise Gaussian processes.” Journal of the
American Statistical Association, 100, 653–668.
Kim, S. S., Reddy, A. L. N., and Vannucci, M. (2004). “Detecting traﬃc anom-
alies using discrete wavelet transform.” In Proceedings of the International
Conference on Information Networking, eds. H. K. Kahng and S. Goto,
951–961. Berlin: Springer-Verlag.
King, M. J. and Datta-Gupta, A. (1998). “Streamline simulation: A current
perspective.” In Situ, 22, 91–140.
Kirkpatrick, S., Gelatt, C. D., and Vecchi, M. P. (1983). “Optimization by
simulated annealing.” Science, 220, 671–680.
Ko, A. I., Reis, M. G., Dourado, C. R., Johnson, W. D., and Riley, L. W.
(1999). “Urban epidemic of severe Leptospirosis in Brazil. Salvador Lep-
tospirosis Study Group.” Lancet, 354, 820–825.
Ko, K. and Vannucci, M. (2006a). “Bayesian wavelet analysis of autoregressive
fractionally integrated moving-average processes.”
Journal of Statistical
Planning and Inference, 136, 3415–3434.
— (2006b). “Bayesian wavelet-based methods for the detection of multiple
changes of the long memory parameter.”
IEEE Transactions on Signal
Processing, 54, 4461–4470.
Kolaczyk, E. D. (1999). “Bayesian multiscale models for Poisson processes.”
Journal of the American Statistical Association, 94, 920–933.
Kolaczyk, E. D. and Huang, H. (2001).
“Multiscale statistical models for
hierarchical spatial aggregation.” Geographical Analysis, 33, 95–118.
Kolaczyk, E. D., Ju, J., and Gopal, S. (2005).
“Multiscale, multigranular
statistical image segmentation.” Journal of the American Statistical Asso-
ciation, 100, 1358–1369.
Krishnamachari, S. and Chellappa, R. (1997). “Multiresolution Gauss-Markov
random ﬁeld models for texture segmentation.”
IEEE Transactions on
Image Processing, 6, 251–267.
Kwon, D. W., Ko, K., Vannucci, M., Reddy, A. L. N., and Kim, S. (2006).
“Wavelet methods for the detection of anomalies and their application to
network traﬃc analysis.” Quality and Reliability Engineering International,
22, 1–17.
Lafert´e, J.-M., Heitz, F., P´erez, P., and Fabre, E. (1995). “Hierarchical statis-
tical models for the fusion of multiresolution image data.” In Proceedings of
the International Conference on Computer Vision, 908. Washington, DC:
IEEE Computer Society.
Lafert´e, J.-M., P´erez, P., and Heitz, F. (2000). “Discrete Markov image mod-
eling and inference on the quadtree.” IEEE Transactions on Image Process-
ing, 9, 390–404.

References
235
Lakshmanan, S. and Derin, H. (1993). “Gaussian Markov random ﬁelds at
multiple resolutions.” In Markov Random Fields: Theory and Applications,
eds. R. Chellapa and A. Jain, 131–157. New York: Academic Press.
Lee, H. K. H. (2004). Bayesian Nonparametrics via Neural Networks. ASA-
SIAM Series on Statistics and Applied Probability. Philadelphia: Society
for Industrial and Applied Mathematics.
Lee, H. K. H., Higdon, D., Bi, Z., Ferreira, M. A. R., and West, M. (2002).
“Markov random ﬁeld models for high-dimensional parameters in simula-
tions of ﬂuid ﬂow in porous media.” Technometrics, 44, 230–241.
Lee, H. K. H., Higdon, D. M., Calder, C. A., and Holloman, C. H. (2005).
“Eﬃcient models for correlated data via convolutions of intrinsic processes.”
Statistical Modelling, 5, 53–74.
Liang, F. (2003).
“Use of sequential structure in simulation from high-
dimensional systems.” Physical Review E, 67, 056101–1–7.
Liang, F. and Wong, W. H. (2001). “Real parameter evolutionary Monte Carlo
with applications to Bayesian mixture models.” Journal of the American
Statistical Association, 96, 653–666.
Li`o, P. and Vannucci, M. (2000). “Wavelet change-point prediction of trans-
membrane proteins.” Bioinformatics, 16, 376–382.
Liu, J. S., Neuwald, A. F., and Lawrence, C. E. (1999). “Markovian structures
in biological sequence alignments.”
Journal of the American Statistical
Association, 94, 1–15.
Liu, J. S. and Sabatti, C. (1999). “Simulated sintering: Markov chain Monte
Carlo with spaces of varying dimensions (with discussion).” In Bayesian
Statistics 6, eds. J. M. Bernardo, J. O. Berger, A. P. Dawid, and A. F. M.
Smith, 389–413. Oxford: Oxford University Press.
— (2000).
“Generalised Gibbs sampler and multigrid Monte Carlo for
Bayesian computation.” Biometrika, 87, 353–369.
Loschi, R. H., Iglesias, P. L., and Arellano-Valle, R. B. (2002). “Conditioning
on uncertain event: Extensions to Bayesian inference.” Test, 11, 1–29.
Louie, M. M. and Kolaczyk, E. D. (2004). “On the covariance properties of
certain multiscale spatial processes.” Statistics and Probability Letters, 66,
407–416.
— (2006a). “Multiscale detection of localized anomalous structure in aggre-
gate disease incidence data.” Statistics in Medicine, 25, 787–810.
— (2006b). “A multiscale method for disease mapping in spatial epidemiol-
ogy.” Statistics in Medicine, 25, 1287–1308.
Luettgen, M. R., Karl, W. C., and Willsky, A. S. (1994). “Eﬃcient multiscale
regularization with applications to the computation of optical ﬂow.” IEEE
Transactions on Image Processing, 3, 41–63.
Luettgen, M. R., Karl, W. C., Willsky, A. S., and Tenney, R. R. (1993).
“Multiscale Representations of Markov random ﬁelds.” IEEE Transactions
on Signal Processing, 41, 3377–3395.

236
References
Luettgen, M. R. and Willsky, A. S. (1995a). “Likelihood calculation for a class
of multiscale stochastic models, with application to texture discrimination.”
IEEE Transactions on Image Processing, 4, 194–207.
— (1995b).
“Multiscale smoothing error models.”
IEEE Transactions on
Automatic Control, 40, 173–175.
Mallat, S. G. (1989). “Multiresolution approximations and the wavelet or-
thonormal bases of L2(R).” Transactions of the American Mathematical
Society, 315, 69–87.
— (1999). A Wavelet Tour of Signal Processing. 2nd ed. San Diego: Academic
Press.
Mandelbrot, B. B. (1999). Multifractals and 1/F Noise: Wild Self-aﬃnity in
Physics. San Francisco: W. H. Freeman.
Marinari, E. and Parisi, G. (1992). “Simulated tempering: A new Monte Carlo
scheme.” Europhysics Letters, 19, 451–458.
Mat´ern, B. (1986). Spatial Variation. 2nd ed. New York: Springer-Verlag.
Matheron, G. (1963). “Principles of geostatistics.” Economic Geology, 58,
1246–1266.
McLeod, A. I. (1994). “Diagnostic checking periodic autoregression models
with application.” Journal of Time Series Analysis, 15, 221–233.
Metropolis, N., Rosenbluth, A. W., Rosenbluth, M. N., Teller, A. H., and
Teller, E. (1953). “Equation of state calculations by fast computing ma-
chines.” Journal of Chemical Physics, 21, 1087–1092.
Morris, J. S., Vannucci, M., Brown, P. J., and Carroll, R. J. (2003). “Wavelet-
based nonparametric modeling of hierarchical functions in colon carcinogen-
esis.” Journal of the American Statistical Association, 98, 573–583.
Mugglin, A. S. and Carlin, B. P. (1998).
“Hierarchical modeling in geo-
graphic information systems: Population interpolation over incompatible
zones.” Journal of Agricultural, Biological, and Environmental Statistics,
3, 111–130.
Mugglin, A. S., Carlin, B. P., and Gelfand, A. E. (2000).
“Fully model-
based approaches for spatially misaligned data.” Journal of the American
Statistical Association, 95, 877–887.
M¨uller, P. and Vidakovic, B., eds. (1999a). Bayesian Inference in Wavelet
Based Models. Lecture Notes in Statistics. New York: Springer-Verlag.
M¨uller, P. and Vidakovic, B. (1999b). “MCMC methods in wavelet shrink-
age: Non-equally spaced regression, density and spectral density estima-
tion.” In Bayesian Inference in Wavelet Based Models, eds. P. M¨uller and
B. Vidakovic, 187–202. New York: Springer-Verlag.
Nason, G. P. (1998). “WaveThresh3 software.” Technical Report, Department
of Mathematics, University of Bristol.
Neal, R. (1997). “Monte Carlo implementation of Gaussian process models
for Bayesian regression and classiﬁcation.” Technical Report 9702, Dept. of
Computer Science, University of Toronto.

References
237
Neal, R. M. (1999).
“Regression and classiﬁcation using Gaussian process
priors.” In Bayesian Statistics 6, eds. J. M. Bernardo, J. O. Berger, A. P.
Dawid, and A. F. M. Smith, 475–501. Oxford: Clarendon Press.
Neuman, S. P. and Yakowitz, S. (1979). “A statistical approach to the problem
of aquifer hydrology: 1. Theory.” Water Resources Research, 15, 845–860.
Neuwald, A. F. and Liu, J. S. (2004). “Gapped alignment of protein sequence
motifs through Monte Carlo optimization of a hidden Markov model.” BMC
Bioinformatics, 5. Art. No. 157.
Nowak, R. D. (1999). “Multiscale hidden Markov models for Bayesian image
analysis.” In Bayesian Inference in Wavelet Based Models, eds. P. M¨uller
and B. Vidakovic, 243–265. New York: Springer-Verlag.
Nowak, R. D. and Kolaczyk, E. D. (2000). “A statistical multiscale framework
for Poisson inverse problems.” IEEE Transactions on Information Theory,
46, 1811–1825.
O’Hagan, A. (1991). “Bayes-Hermite quadrature.” Journal of Statistical Plan-
ning and Inference, 29, 145–260.
Oliver, D. S. (1994). “Incorporation of transient pressure data into reservoir
characterization.” In Situ, 18, 243–275.
Oliver, D. S., Cunha, L. B., and Reynolds, A. C. (1997). “Markov chain Monte
Carlo methods for conditioning a permeability ﬁeld to pressure data.” Math-
ematical Geology, 29, 61–91.
Openshaw, S. and Taylor, P. (1979). “A million or so correlation coeﬃcents.”
In Statistical Methods in the Spatial Sciences, ed. N. Wrigley, 127–133.
London: Pion.
Paciorek, C. (2003). “Nonstationary Gaussian Processes for Regression and
Spatial Modelling.” Ph.D. thesis, Carnegie Mellon University, Department
of Statistics.
Palm, F. C. and Nijman, T. E. (1984). “Missing observations in the dynamic
regression model.” Econometrica, 52, 1415–1435.
Park, C. G., Vannucci, M., and Hart, H. D. (2005). “Bayesian methods for
wavelet series in single-index models.” Journal of Computation and Graph-
ical Statistics, 14, 1–25.
Pelletier, D. (2006). “Regime switching for dynamic correlations.” Journal of
Econometrics, 131, 445–473.
Pe˜na, D., Tiao, G. C., and Tsay, R. (2000). A Course in Time Series Analysis.
New York: John Wiley and Sons.
Pensky, M., Vidakovic, B., and De Canditiis, D. (2006). “Bayesian decision
theoretic scale-adaptive estimation of spectral density.” Technical Report,
ISyE, Georgia Institute of Technology.
P´erez, P. and Heitz, F. (1996). “Restriction of a Markov random ﬁeld on a
graph and multiresolution statistical image modeling.” IEEE Transactions
on Information Theory, 42, 180–190.
Petris, G. and West, M. (1998). “Bayesian time series modelling with long-
range dependence.” Technical Report 686, Carnegie Mellon University.

238
References
Pizurica, A., Philips, W., Lemahieu, I., and Acheroy, M. (2002). “A joint inter
and intrascale statistical model for Bayesian wavelet based image denois-
ing.” IEEE Transactions on Image Processing, 11, 545–557.
Priestley, M. B. (1981). Spectral Analysis and Time Series. San Diego: Aca-
demic Press.
Richardson, S. and Green, P. J. (1997). “On Bayesian analysis of mixtures
with an unknown number of components (Disc: P758-792) (Corr: 1998V60
P661).” Journal of the Royal Statistical Society, Series B, 59, 731–758.
Ripley, B. D. (1981). Spatial Statistics. New York: John Wiley and Sons.
Robert, C. P. and Casella, G. (2005). Monte Carlo Statistical Methods. 2nd
ed. New York: Springer-Verlag.
Roberts, G. O. and Gilks, W. R. (1994). “Convergence of adaptive direction
sampling.” Journal of Multivariate Analysis, 49, 287–298.
Rosenthal, J. S. (2000). “Parallel computing and Monte Carlo algorithms.”
Far East Journal of Theoretical Statistics, 4, 207–236.
Royle, J. A., Berliner, L. M., Wikle, C. K., and Milliﬀ, R. (1999). “A hierar-
chical spatial model for constructing wind ﬁelds from scatterometer data in
the Labrador Sea.” In Case Studies in Bayesian Statistics, vol. IV, 367–382.
New York: Springer-Verlag.
Rue, H. and Held, L. (2005). Gaussian Markov Random Fields. Boca Raton,
FL: Chapman and Hall.
Sacks, J., Welch, W. J., Mitchell, T. J., and Wynn, H. P. (1989). “Design and
analysis of computer experiments.” Statistical Science, 4, 409–435.
Sampson, P. D. and Guttorp, P. (1992). “Nonparametric estimation of nonsta-
tionary spatial covariance structure.” Journal of the American Statistical
Association, 87, 108–119.
Santner, T. J., Williams, B. J., and Notz, W. I. (2003).
The Design and
Analysis of Computer Experiments. New York: Springer-Verlag.
Saquib, S. S., Bouman, C. A., and Sauer, K. (1996). “A non-homogeneous
MRF model for multiresolution Bayesian estimation.” In IEEE Interna-
tional Conference on Image Processing, vol. 2, 445–448. New York: IEEE.
Sarkar, U., Nascimento, S. F., Barbosa, R., Martins, R., Nuevo, H.,
Kalafanos, I., Grunstein, I., Flannery, B., Dias, J., Riley, L. W., Reis, M. G.,
and Ko, A. I. (2002). “A population-based case-control investigation of risk
factors for leptospirosis during an urban epidemic.” American Journal of
Tropical Medicine and Public Hygiene, 66, 605–610.
Schmidt, A. M. and Gamerman, D. (1997). “Temporal aggregation in dynamic
linear models.” Journal of Forecasting, 16, 293–310.
Schmidt, A. M. and Gelfand, A. E. (2003).
“A Bayesian coregionaliza-
tion approach for multivariate pollutant data.”
Journal of Geophysical
Research–Atmospheres, 108, 8783.
Schmidt, A. M. and O’Hagan, A. (2003). “Bayesian inference for nonstation-
ary spatial covariance structure via spatial deformations.” Journal of the
Royal Statistical Society, Series B, 65, 743–758.

References
239
Scott, S. L. (1999).
“Bayesian analysis of a two-state Markov modulated
Poisson process.” Journal of Computational and Graphical Statistics, 8,
662–670.
— (2002). “Bayesian methods for hidden Markov models: Recursive comput-
ing in the 21st century.” Journal of the American Statistical Association,
97, 337–351.
— (2004). “A Bayesian paradigm for designing network intrusion systems.”
Computational Statistics and Data Analysis, 45, 69–83.
Scott, S. L., James, G. M., and Sugar, C. A. (2005). “Hidden Markov models
for longitudinal comparisons.” Journal of the American Statistical Associ-
ation, 100, 359–369.
Sendur, L., Maxim, V., Whitcher, B., and Bullmore, E. (2005). “Multiple
hypothesis mapping of functional MRI data in complex and orthogonal
wavelet domains.” IEEE Transactions in Signal Processing, 53, 3413–3426.
Shafer, G. (1981). “Jeﬀrey’s rule of conditioning.” Philosophy of Science, 48,
337–362.
Sirigos, J., Fakotakis, N., and Kokkinakis, G. (2002).
“A hybrid syllable
recognition system based on vowel spotting.” Speech Communication, 38,
427–440.
Skyrms, B. (1980). Causal Necessity. New Haven, CT: Yale University Press.
Smith, R. L. (1993). “Long-range dependence and global warming.” In Sta-
tistics for the Environment, eds. V. Barnett and F. Turkman, 141–161.
Chichester: Wiley.
Sokal, A. D. (1987). “Monte Carlo methods in statistical mechanics: founda-
tions and new algorithms.” Cours de Troisi´eme Cycle de la Physique en
Suisse Romande. Lausanne.
Stein, M. L. (1999). Interpolation of Spatial Data: Some Theory for Kriging.
New York: Springer-Verlag.
Stephen, K. D. and Dalrymple, M. (2002). “Reservoir simulations developed
from an outcrop of incised valley ﬁll strata.” AAPG Bulletin, 86, 797–822.
Stroud, J. R., M¨uller, P., and Sans´o, B. (2001). “Dynamic models for spatio-
temporal data.”
Journal of the Royal Statistical Society, Series B, 63,
673–689.
Sun, D., Tsutakawa, R. K., and Speckman, P. L. (1999). “Posterior distrib-
ution of hierarchical models using CAR(1) distributions.” Biometrika, 86,
341–350.
Tanner, M. A. (1993). Tools for Statistical Inference: Methods for the Explo-
ration of Posterior Distributions and Likelihood Functions. 3rd ed. New
York: Springer-Verlag.
Telser, L. G. (1967). “Discrete samples and moving sums in stationary sto-
chastic processes.”
Journal of the American Statistical Association, 62,
484–499.
Thi´ebaux, H. J. and Pedder, M. A. (1987). Spatial Objective Analysis with
Applications in Atmospheric Science. London: Academic Press.

240
References
Vannucci, M. (2007). Wavelets in Statistics with Applications. New York:
Springer-Verlag. In press.
Vannucci, M., Brown, P. J., and Fearn, T. (2003). “A decision theoretical
approach to wavelet regression on curves with a high number of regressors.”
Journal of Statistical Planning and Inference, 112, 195–212.
Vannucci, M. and Corradi, F. (1999a). “Covariance structure of wavelet co-
eﬃcients: Theory and models in a Bayesian perspective.” Journal of the
Royal Statistical Society, Series B, 61, 971–986.
— (1999b). “Modeling dependence in the wavelet domain.” In Bayesian In-
ference in Wavelet Based Models, eds. P. M¨uller and B. Vidakovic, 171–186.
New York: Springer-Verlag.
Vannucci, M. and Li`o, P. (2001). “Non-decimated wavelet analysis of biological
sequences: Applications to protein structure and genomics.” Sankhy˜a, 63,
218–233.
Vardi, Y., Shepp, L., and Kaufman, L. (1985). “A statistical model for positron
emission tomography.” Journal of the American Statistical Association, 80,
8–25.
Vasco, D. W. and Datta-Gupta, A. (1999). “Asymptotic solutions for solute
transport: A formalism for tracer tomography.” Water Resources Research,
35, 1–16.
Vasco, D. W., Yoon, S., and Datta-Gupta, A. (1998). “Integrating dynamic
data into high-resolution reservoir models using streamline-based analytic
sensitivity coeﬃcients.” Society of Petroleum Engineers 1998 Annual Tech-
nical Conference, SPE 49002.
Ver Hoef, J. M. and Barry, R. P. (1998). “Constructing and ﬁtting models
for cokriging and multivariable spatial prediction.” Journal of Statistical
Planning and Inference, 69, 275–294.
Vidakovic, B. (1998).
“Nonlinear wavelet shrinkage with Bayes rules and
Bayes factors.”
Journal of the American Statistical Association, 93,
173–179.
— (1999). Statistical Modeling by Wavelets. New York: Wiley.
Vidakovic, B. and M¨uller, P. (1995). “Wavelet shrinkage with aﬃne Bayes
rules with applications.” Technical Report 95-34, Institute of Statistics and
Decision Sciences, Duke University.
Viterbi, A. J. (1967). “Error bounds for convolutional codes and an asymptot-
ically optimum decoding algorithm.” IEEE Transactions on Information
Theory, 13, 260–269.
Wackernagel, H. (1998). Multivariate Geostatistics. Berlin: Springer.
Wakeﬁeld, J. (2004). “A critique of statistical aspects of ecological studies in
spatial epidemiology.” Environmental and Ecological Statistics, 11, 31–54.
Weir, I. (1997). “Fully Bayesian reconstructions from single photon emission
computed tomography.” Journal of the American Statistical Association,
92, 49–60.
West, M. and Harrison, J. (1997). Bayesian Forecasting and Dynamic Models.
2nd ed. New York: Springer-Verlag.

References
241
Wikle, C. K. and Berliner, L. M. (2005).
“Combining information across
spatial scales.” Technometrics, 47, 80–91.
Wikle, C. K., Berliner, L. M., and Cressie, N. (1998). “Hierarchical Bayesian
space-time models.” Environmental and Ecological Statistics, 5, 117–154.
Williams, C. K. I. and Rasmussen, C. E. (1996).
“Gaussian processes for
regression.” In Advances in Neural Information Precessing Systems 8, eds.
D. S. Tourestzky, M. C. Mozer, and M. E. Haeelmo. Cambridge, MA: MIT
Press.
Willsky, A. S. (2002). “Multiresolution Markov models for signal and image
processing.” Proceedings of the IEEE, 90, 1396–1458.
Wong, W. H. (1995). “Comment (on Bayesian computation and stochastic
systems).” Statistical Science, 10, 52–53.
Working, H. (1960). “Note on the correlation of ﬁrst diﬀerences of averages
in a random chain.” Econometrica, 28, 916–918.
Wornell, G. W. (1990). “A Karhunen-Lo´eve-like expansion for 1/f processes
via wavelets.” IEEE Transactions on Information Theory, 36, 859–861.
Xue, G. and Datta-Gupta, A. (1996). “A new approach to seismic data inte-
gration using optimal non-parametric transformations.” Society of Petro-
leum Engineers 1996 Annual Technical Conference, SPE 36500.
Yeh, W. W. (1986).
“Review of parameter identiﬁcation in groundwater
hydrology: The inverse problem.” Water Resources Research, 22, 95–108.
Yoon, S. (2000).
“Dynamic data integration into high resolution reser-
voir models using streamline-based inversion.” Ph.D. thesis, Texas A&M
University, Department of Petroleum Engineering.
Yoon, S., Malallah, A. H., Datta-Gupta, A., Vasco, D. W., and Behrens, R. A.
(1999). “A multiscale approach to production data integration using stream-
line models.” Technical Report 56653, Society of Petroleum Engineers.


Index
admissibility condition, 41
aggregation, 42, 64, 88, 97, 100, 113,
137, 146, 196, 216
autocorrelation function plot, 17–19,
121–131, 137, 171–172, 191,
210–212, 218–221
autoregressive moving average time
series, 119
autoregressive time series, 115, 116
balance of mass, 87, 88
Besov space, 49
block kriging, 147
Boltzmann distribution, 157
breakthrough time, 205–207
CART, 59–61
change of support, 58, 145–152
Cholesky decomposition, 15
concentration curve, 205
convolution, 5, 15, 23–38, 61, 168–172,
176, 191
critical sampling, 42
CWB algorithm, 69–75
ﬁlter, 70–73
smoother, 73–74
Darcy’s Law, 196
Dirichlet prior, 94, 152
Doppler function, 50, 51
dyadic tree, 57, 59, 60, 63–66, 68, 87
dynamic data, 97, 196, 200, 202
dynamic linear model, 135
ecological fallacy, 146
elitist strategy, 182, 184
empirical wavelet coeﬃcients, 39, 46–48
evolutionary Monte Carlo, 186
father wavelet, see scaling function
FFS, see ﬂuid ﬂow simulator
Fick’s Law, 196
ﬁtness function, 179–180
ﬂuid ﬂow simulator, 196–200
forward problem, 196, 197
Fraser River data, 17–18, 30, 36–38,
121, 136–140, 168–172, 191
Gaussian processes, 10
Gaussian state-space model on a tree,
66
genetic algorithm, 5, 156, 179–191,
219–220
crossover, 180, 184
mutation, 181, 184
selection, 180, 184
Haar wavelet, 40, 43
harmonics, 130, 136
HeaviSine function, 43, 44
hidden Markov model, 80
hidden Markov model on a tree, 82
hidden resolution model, 114, 115,
119–122, 124, 126–133
Hill Air Force Base data, 208–212
HRM, see hidden resolution model
identiﬁability, 121

244
Index
image
classiﬁcation, 79, 84
compression, 45
segmentation, 80
implicit likelihood function, 101
importance sampling, 156
improper prior, 8, 14, 32, 34, 122, 125,
166
incised valley oil ﬁeld, 200
instability, numerical, 14, 15, 81
intrinsic ﬁeld, 8–10, 173–175, 210,
216–220
inverse problem, 33, 57, 63, 109, 196,
197
isotropy, 11–12, 25–26
Jacobi’s algorithm, 163
Jeﬀrey’s rule of conditioning, 58, 97, 99,
101, 102, 105–107, 113, 115, 117,
119
Kalman ﬁlter, 57, 63, 69, 133, 135–136
kernel
Mat´ern, 29, 30
spacing, 30–32, 34
tricube, 29, 30
width, 26–28, 34, 36–38, 168
kriging, 10
law of conservation of mass, 196
long memory, 17, 66, 112–114, 123, 136,
137, 197, 204
Lyapunov equation, 66
marked point process model, 151
Markov random ﬁelds, 7
Mat´ern correlation, 12, 26, 28–30
mixture prior, 46, 48, 90, 91, 94, 166
modiﬁable areal unit problem, 147, 149,
151–152
mother wavelet, 39, 40, 42
moving average time series, 118
MSTSM, 114, 115, 130, 132, 133, 143
multigrid methods, 79, 156, 161, 163,
176, 205
multimodality, 60, 155–162, 165–167,
176, 179–182, 185, 186, 189, 199,
211
multiscale label representation, 79
multiscale likelihood factorization, 89,
90, 93, 167, 183
multiscale Poisson process, 87, 93
multiscale random ﬁeld, 97–112
nested block realignment, 151–152
non-nested block realignment, 151
nonstationarity, 15, 33
nugget, 14
parallel adaptive Metropolis sampler,
186
parallel computing, 165, 175, 177, 179,
186, 189–191
parallel tempering, 175–176, 186
periodicities, see seasonality
permeability, 195
petroleum production, 195
prior sensitivity, 8, 14, 32, 122, 174,
223–224
probability kinematics, 99
quadtree, 57, 59, 63, 64, 85
REML, 31, 34
reproducing kernel, 41
reversibility, 167, 168, 218
reversible jump Markov chain Monte
Carlo, 156
scaling function, 42–44
seasonality, 17–18, 36, 58, 130–131,
135–143
sequential parallel tempering, 175–176
simulated annealing, 156–158, 161, 206
simulated sintering, 156, 161–163, 165,
175, 176
simulated tempering, 156, 158–161,
175–176, 186, 189
soil clean-up, 195
sparsity, 48
spectral density, 26, 53, 113
static data, 97, 196, 199
subsurface ﬂow, 195
tracer experiments, 196
Viterbi algorithm, 82
Voronoi tessellation, 61

Index
245
wavelet, 3, 5, 23–24, 39–53, 58, 61, 64,
77, 79, 90, 102, 114
wavelet nonparametric regression, 46–51
wavelet shrinkage, 49, 50
wavelet threshold, 49, 50
Willsky’s multiscale framework, 63–77
WMF model, 65
correlation function at ﬁnest level, 68
covariance matrix, 66
cross covariance matrix, 68

