o
00o
0
■p
Technical Report 70-111 
Nonr-5144(00)
April, 1^70
ISOTONIC GRAMMARS, PARALLEL
grammars, and picture grammars
Azriel Rosenfeld
UNIVERSITY OF MARYLAND 
COMPUTER SCIENCE CENTER
COLLEGE PARK, MARYLAND
* j •
\Ul „,L 1> «™

Technical Report 70-111 
Nonr-5144(00) 
April, 1970 
ISOTONIC GRAMMARS, PARALLEL 
GRAMMARS, AND PICTURE GRAMMARS 
Azriel Rosenfeld 
The support of the Information 
Naval Research, under Contract 
achnowledged. 
Systems Branch, 
Nonr-5144(00), 
Office of 
is gratefully 

RESEARCH PROGRESS REPORT 
TITLE: "Isotonic grammars, parallel grammars and picture 
grammars", A. Rosenfeld, University of Maryland Computer 
Science Center Technical Report 70-111, April 1970; 
Contract Nonr-5144(00). 
BACKGROUND: The Computer Science Center of the University 
of Maryland is investigating the theory of image proces¬ 
sing by computer. One area under study is the theory 
of "grammars" whose "languages" are arrays rather than 
strings. 
CONDENSED REPORT CONTENTS: When one attempts to generalize 
phrase-structure grammars from strings to arrays, dif¬ 
ficulties arise which can be avoided if the grammars 
are required to be isotonic; in any array rewriting 
rule, the left and right members are congruent subar¬ 
rays. For strings, such grammars are exactly as power¬ 
ful as monotonie grammars, provided that derivations 
can begin with any initial string of the form #3½ 
rather than always with #S#. 
Isotonic context-sensitive array rewriting rules 
are essentially the same as local digital picture proces¬ 
sing operations. Since the latter are often applied to 
pictures in parallel, it is of interest to study (string) 
grammars which operate in parallel: that is, when a rule 
is applied to a string, every instance of the left 
member is replaced by the right member. (Here again, 
there are difficulties which can be avoided if all rules 
are isotonic and context-sensitive.) The sets of sentences 
which such a parallel grammar generates is not the same 
as the set of sentences which it parses, nor is either of 
these the same as the set of sentences generated (or 
parsed) when rules need not be applied in parallel. How¬ 
ever, any parallel language is a sequential language and 
vice versa . 
FOR FURTHER INFORMATION: The complete report is available in 
the major Navy technical libraries and can be obtained 
from the Defense Documentation Center. A few copies are 
available for distribution by the author. 

1. Introduction 
1.1 String grammars and array grammars 
In recent years there has been considerable interest 
in applying the methods of mathematical linguistics to 
picture generation and description [1]. In this approach, 
pictures are regarded as "concatenations" of subpictures, 
which are in turn built up out of still smaller parts, 
in analogy with the way that sentences can be broken down 
into phrases and words. 
In mathematical linguistics, the most widely used 
device for generating and analyzing "sentences" is the 
phrase structure grammar. Formally, such a grammar is 
a 5-tuple G = (V, V ,P, S, #), where 
T 
1) V is a finite set, called the vocabulary of G; 
the elements of V are called symbols. 
?) V is a subset of V, called the terminal 
T —. 
vocabulary of G. 
3) P is a finite set of pairs (<*, (3), where a and 
ß are strings of elements of V, a nonnull; P 
is called the set of productions or rewriting 
rules of G. Elements of P are usually written 
in the form cr -* 0 (read: "a can be rewritten 
as ß"). Symbols in are never destroyed by 
these rules; in other words, if a - ß is a rule 
and a = Çq^I-I**'^n^n' w^ere 5's are strin9s 
of elements of and the ri's are strings on 
V-V , then ß = ...C Ç * where the r's 
t :>Ov,lï,l '’n^n 
are strings on V. 

« 
4) S is a special nonterminal symbol (i.e., symbol 
in V-V ), called the initial symbol of G. 
T 
5) # is a special terminal symbol, called the end- 
marker, which is neither created nor destroyed 
by any rule of G. 
Let y» 6 be strings on V. We say that 6 is directly 
derivable from v in G (notation: v => 6) if Y = and 
j = -y ¡3Y , where a 3 a rule of G. More generally, 
^ • * > 
we say that 6 is derivable from y in G (notation: y =* 6) 
if there exist strings 0,,..., 9n such that y * 01 =>... 
=» 0 ^6. A string on V is called a sentence of G if 
n T 
it is derivable from #S#. The set of sentences of G 
is called the language of G (notation: L(G)). [In apply¬ 
ing this formalism to natural language, one can think of 
the terminal symbols as words, the nonterminal symbols 
as phrases, S as "sentence", and the endmarkers as 
punctuation marks which indicate the beginning and end 
of the sentence.] Readily, the sentences of G are just 
the strings of terminal symbols from which #S# can be de¬ 
rived by applying the rules in reverse (i.e., replacing 
right members by left members); this reverse procedure 
is called parsing. 
Since a picture does not ordinarily have a natural 
description as a string of subpictures, phrase-structure 
grammars as such are not a natural tool for picture gene¬ 
ration or analysis. In general, a (discrete, e.g., digital) 
picture is an array of elements having given colors or gray 
levels? these elements can be regarded as the symbols of a 
terminal vocabulary. A grammar for a language whose "sen¬ 
tences" are such pictures would have to have rules a - 3 

which rewrite arrays as arrays; to use such a rule to 
directly derive the array 6 from the array v* one would 
have to find the subarray a in y and replace it by ß. 
A grammar of this type, whose language consists of digital 
pictures of triangles, has been devised by Kirsch [2] and 
generalized by Dacey [3]; these seem to be the only ex¬ 
amples of array-rewriting grammars in the literature. 

1.2 Isotonie grammars 
A potentially serious defect of array grammars is 
that when one subarray is replaced by another, the ef¬ 
fects of the replacement may extend far beyond the im¬ 
mediate vicinity of the subarray. In the string case, 
when the substring a is replaced by ß in the string y, 
if a and ß have different lengths, we simply regard y 
as pushed apart or pulled together until ß exactly fits 
the space left by removing For arrays, on the other 
hand, if we wish to replace one subarray by another of 
a different size or shape, the rows and columns of the 
host array may have to stretch or shrink by varying a- 
mounts, so that "shearing" effects occur which extend 
all the way out to the edges of the host array, arbi¬ 
trarily far from the replaced subarray. 
Most of the literature on picture grammars deals 
with line drawings rather than arrays. Here the lines 
and curves are regarded as joined only at explicitly 
specified "attaching points", irrespective of whether 
they actually touch or intersect in the picture. Thus 
replacement of one subdrawing by another affects the struc¬ 
ture of the host drawing only locally, and the shearing 
problem never arises. Kirsch's right triangle grammar 
avoided the problem by adding to arrays only at their 
edges. However, it is not clear that this method could 
be used for arbitrary array languages. 
A simple way of preventing shearing would be to re¬ 
quire the left and right members of any array rewriting 
rule to be congruent. In the string case, the analogous 

requirement would be that the left and right members of 
any rule must have the same length. (A grammar whose 
rules have this property will be called isotonic.) How¬ 
ever, this evidently implies that the strings in any 
derivation must all be of the same length, since no ap¬ 
plication of a rule can change the length of a string. 
Since sentences must all be derivable from a single ini¬ 
tial S (surrounded by endmarkers, which are never created 
or destroyed), it follows that sentences can consist only 
of single symbols, which makes the language rather un¬ 
interesting . 
This objection to isotonic grammars can be overcome 
if one is allowed to start not with a single initial S, 
but with any one of a set of initial strings — for ex¬ 
ample, with an arbitrary string of S's (bordered by end- 
markers) . In fact, it can be shown that if this is per¬ 
mitted, isotonic grammars become exactly as powerful as 
monotonie grammars (i.e., grammars in which the right 
member of any rule is at least as long as the left mem¬ 
ber) , which are the most general class of grammars ordi¬ 
narily studied. It can also be shown that monotonie 
grammars which change the length of a string only at its 
ends are as powerful as arbitrary monotonie grammars; 
this generalizes the method used by Kirsch. These re¬ 
sults are presented in Section 2 of this paper. 

1.3 Parallel grammars 
In digital picture processing, a local operation 
is one which replaces a given picture element by a new 
one whose value (if, as is usual, we regard the symbols 
in a picture array as numbers) depends on the value of 
the original element and on the values of a set of neigh¬ 
boring elements. This type of operation is analogous to 
an isotonic, context sensitive string rewriting rule —i.e., 
a rule of the form ÇAri -4 ÇBti, where A and B are single 
symbols (A must be nonterminal, since terminals cannot 
be rewritten). It is well known that context sensitive 
grammars (i.e., grammars in which every rule is context 
sensitive) are exactly as powerful as monotonie string 
grammars; similarly, it is easily shown that isotonic con¬ 
text sensitive grammars are as powerful as arbitrary iso¬ 
tonic grammars (see the end of Section 2). 
Local picture processing operations are often applied 
to every element of a picture "in parallel", i.e., using 
the original values of the element and its neighbors 
throughout, rather than using new values for neighbors 
which have already been processed. It has been shown 
elsewhere [4] that parallel local operations on pictures 
are exactly as powerful as "sequential" operations, in 
which the elements are processed in a fixed order, and in 
processing each element, new values are used for its al¬ 
ready processed neighbors. In view of the analogy between 
local operations and rewriting rules, the analogous ques¬ 
tion for grammars is thus of interest: How is the power 
of an (isotonic, context sensitive) grammar affected if 

its rules are applied in parallel rather than sequentially - 
i.e., when the rule ÇAr) - ÇBri is applied to a string y, 
we simultaneously replace every A which occurs in the con¬ 
text (§, #ri) by B, rather than just replacing one such A 
by B? 
One could attempt to formulate the notion of paral¬ 
lelness for grammars having arbitrary rewriting rules or - 0 : 
when applying such a rule to a string y, replace every 
instance of & in v by 0. However, if a can overlap it¬ 
self, i.e., a = ^...An where \+1-..An = ^-‘^n-k for 
some k < n, undesirable effects arise. For example, let 
& = ABA and suppose that y = ABABA. Since a occurs twice 
in y, applying <* - ß to y "in parallel" should require us 
to rewrite y as 00; but this means that, in effect, one 
of the ß's replaces an ABA and the other replaces only an 
AB or a BA. As another example, let a = xxx, 0 = xx, 
Y = xm. Applying a - 0 to y sequentially shortens y by 
1 at each application; but applying it in parallel yields 
gm-2 = x2(m-2) (where it will be noted that one 0 replaces 
an xxx while all the others replace single x'si), so that 
parallel application of this length-decreasing rule to y 
can actually increase its length. 
These difficulties do not arise if we restrict our¬ 
selves to context-sensitive rules, a = §Ari, and replace 
only the A by the appropriate part of 0; here there can 
be no self-overlap of the substrings which are being re¬ 
placed, since they have length 1. On the ether hand, if 
we allowed arbitrary context-sensitive rules |Ari - çeri, 
where 0 need not be just a single symbol, the same 

undesirable effects could arise when the rules are used 
to parse, since Q's might overlap. Thus parallelness is 
most easily handled if all rules are required to be 
isotonic context-sensitive, as suggested by the parallel 
picture processing analogy. 
It will be shown in Section 3 that when a grammar 
is used "in parallel", the set of sentences which can 
be derived from #S# is not in general the same as the 
set obtained when the rules are used in the ordinary 
"sequential" manner. Moreover, the set of sentences 
which can be derived "in parallel" need not be the same 
as the set which can be parsed in parallel. However, 
we shall show that various classes of "parallel languages" 
are the same as the corresponding classes of "sequential 
languages". 

2. Isotonic string grammars 
In this section we show that isotonic grammars are 
as powerful as monotonie grammars. More precisely, we 
prove that if the language L has a monotonie grammar, 
it also has an isotonic grammar, provided that deriva¬ 
tions are allowed to start with initial scrings con¬ 
sisting of arbitrary numbers of repetitions of the ini¬ 
tial symbol. To this end, we first prove 
Proposition 1. Any (monotonie, isotonic) language has 
a (monotonie, isotonic) grammar in which no rule 
involves the endmarkers. 
Proof: Let the given language have a grammar on the vo 
A = S (where A-,...,A are terminal 
n I c 
cabulary A^ I ••• I n 
and the rest nonterminal), and with rules of the 
A ,...,A , with initial symbol A°, and new rules 
X t» 
constructed as follows: 
Original rule 
Replaced bv rule(s) 
- #€^ 
#B]_# - #CV..CS* (s > U 
- ttCj# (r > 1) 
#B1...Br# - tr,s 
#B1 - #cx 
tBj^ - #Cr..Cs (s > 1) 
#Bl***Br - #C1 (r > 1) 

» 
Original rule 
#B. .. .B -> #C. .. .C (r, s > J 
1 r Is 
Bl# ■* Cl# 
B # - C .. .C # (s > 1) 
1 Is 
Bl**,Br# ci# (r > 
B ...B # - C-...C #(r,s > ]) 
X 3T X S 
bi -ci 
B. - C....Co (s > 1) 
11s 
Bl***Br " C1 > 1) 
Replaced by rule(s) 
L M 
B1B2- 
„L_M 
B1B2 * 
..B 
. .B 
L M M 
C1C2 * * *Cs 
lBR 
r-1 r 
_L_M 
C1C2- 
R 
.C -C 
s—1 s 
Bi -c: 
0 rC 
1 C] 
R 
1 
S 
1 
M 
B 
B 
B, - 
_M _M _R 
1 s—1 s 
L M M R 
ClC2**,Cs-lCs 
B X 
L M 
B1B2 
B M 
M R _R 
.B .B - C. 
r-1 r 1 
M R O 
•••Br-lBr - C1 
.bm iBr-c“...cm ,c 
r-1 r 1 s—1 s 
L M 
B1B2' 
Bï- 
dr 
B, - 
R 
. .B . B 
r-1 r 
C1C2' .C .C 
s—1 s 
B, - 
B 
B 
B 
M 
1 
L 
1 
R 
1 
0 
1 
B, - 
B 
M M 
Cl-*,Cs 
_L M M 
C1C2 * * *Cs 
M M R 
Cl* **CS-lCs 
R 
L M M 
ClC2*,,Cs lCs 
B M 
1’ * .B M 
M 
L M 
B1B2 
. . .B M 
B M 
I“ 
_L_M 
B1B2 
_M R 
.B -B 
r-1 r 
.M 
.R 
R O 
••*Br-lBr ■* C1 

Original rule 
Bl* * ,Br ■* Cl**,Cs 
Replaced by rule(s) 
i qM nM cM cM 
r,s > 1 Ci* * *Cs 
- ClC2 * * *Cs 
Bl* * *Br-lBr - C1-**CM 
.C 
s—1 s 
L M „M _R 
B1B2* * *Br-lBr 
In addition, the new grammar has the rules 
.0 
rLrM c*4 
C1 2*’ * 
,R 
s-l“s 
h. 
AL - A. 
i i 
A« - Ai 
for 1 £ i * t. (Note that the new grammar may block if 
these rules are applied too early.) Readily, the new 
grammar and the original one have the same language; 
and if one is monotonie or isotonic, so is the other. // 
We can now prove 
Theorem 2. Let L be any language having a monotonie grammar; 
then there exists an isotonic grammar on the set of 
initial strings (Tk | * = 1.2,...} whose language is 
exactly L. 
Proof: Let G be a monotonie grammar for L having vocabulary 
V = {S, Ax.Am, bx.bn} and rewriting rules 
-.ß. (1 á i s k), where 0<|ai|^|Pi|»lá;Lik- 
We define an isotonic grammar G' for L using the 
vocabulary V = {T, U, V, A1,...,Am> 
For any string y on V, let y’ be the string on V de¬ 
fined by replacing S by U and the b's by B's in y. 
Then we can take the rules of G’ to be 

#T - #U 
T - V 
UV - VU 
A . V - VA. 
1 1 
(1 á i s m) 
(1 £ i £ n) 
a.V^i^^iJ - ß! ( 1 £ i £ k*) 
B . V 
i 
VB . 
i 
'i' - i 
B. -b. (l£i£n) 
i i 
We first show that every sentence a of L is a 
sentence of L(G'). Let 
S = a0 * G1 
ar = a 
be a derivation of a in G, where the rule used to 
rewrite ^ as is otn 
B ; we shall abbreviate 
n. 
i 
Ib I - I« I by ki, 1 £ i £ r. Note that 
i i 
lGil “ lai l' = 1 ^ ^ r' 30 that ^a' = *ar' = 
Iar_iI + kr = = ,CTo' + kr +--*+ kl' wherG by 
monotonicity the k’s are all nonnegative. To de¬ 
rive o in o' » we begin with the initial string T 
and use the rules #T - #U, T - V to obtain the string 
Uv'0!"1. Since this string has at least k^ Vs, and 
since a’ = U or #U, we can apply the rule 
k nl 
a’ V 1 - ß' to obtain a new string, call it 
nl nl 
Evidently, is just followed by at least k2 Vs; 
in particular, ^ contains a copy of a¿ . If we use 
the rules which shift Vs to the left, we can move 
k2 of them until they just follow this copy, and then 
apply the rule «ñ V 2 " ßn to obtain a new strin9 T2* 
2 2 
This assumes that no rule of G involves the right endmarker, 
which is a legitimate assumption by Proposition 1. 

This arcrument can be repeated, so that eventually 
we obtain a string Tr which evidently is just = a'« 
Applying the rules Bi - bi to a' then gives us the 
desired string o. 
Conversely, let T^ = Pg Ä P]. * ••• a ps " ^ 
be a non-blocking derivation in G'. Without loss of 
generality, we may assume that is first re¬ 
written into Uvlpt Let p i =' pu (1 ^ i á P) 
i" i 
be the steps at which rules of the form <*’ V - 
i i 
are used. We shall show how to construct a deriva¬ 
tion for p in G. Specifically, we shall construct a 
G-derivation S = Vg =* =» ... =* vp ~ p 
^=0 with U‘s replaced by S’s and B's by b's, 
1 Ui 
and ignoring Vs, 1 s i á p (and similarly Vg - Pu 
with the same changes). Note first that Pu^_i can 
contain no A's, B's or b's, so that the rule used to 
W1 
rewrite it as p must be of the form UV - (or 
w. U1 
#UV 1 - #ß ' ); let us take v. = ß i-n our G-deriva- 
V1 1 V1 
tion. Thus \f1 and pu satisfy our requirements. Sup¬ 
pose that ^ end p^ do so. Now p^ must con¬ 
tain a copy of (¾' , and since the other rules of o 
\ 
cannot change the order of U's, A's, B's or b's, it 
follows that (ignoring Vs) pu must also contain 
i — 1 
such a copy. Thus by induction hypothesis, vi_1 
contains a copy of « ; apply the rule av 
i i 
to 

* 
this copy, and call the resulting string vi. Evi¬ 
dently, V. and p satisfy our requirements; thus in 
i u. 
particular, v and p do. But since p^ is the 
p Up P 
last step of the given G'-derivation at which U's, Vs 
or A's can be eliminated, and since this derivation 
is non-blocking, we see that pu must consist entirely 
P 
of B's and b's, and that p = Pu with B's (if any) 
P 
replaced by b's; thus v must be just p. // 
Conversely, let G', as in the proof of Theorem 2, be 
an isotonic grammar which, given the set of initial 
strings {Tk | k = 1, 2,...}, yields the language L. Let 
G be the grammar defined by adding a new initial symbol S 
to the vocabulary of G', and the new rules S - ST, S - T 
to the rules of G'. Evidently G is nonotonic and L(G) = L. 
Note also that G is isotonic except at the left end of a 
string, which is the only place that the rule S -• ST can 
ever apply. We have thus proved 
Theorem 3. The following three classes of grammars have 
the same set of languages; 
a) The monotonie grammars, with initial string #S# 
b) The monotonie grammars which are isotonic except 
at the ends of strings, with initial string #S# 
c) The isotonic grammars, with set of initial strings 
t#Sk# I k = 1, 2,...). 
It is not difficult to verify that the isotonic gram¬ 
mars are also equivalent to the isotonic context sensitive 
grammars, i.e., grammars in which every rule is of the 
form ?An - ÇBti. Indeed, if is the kth 

rule in an isotonic grammar (which we can assume not to 
involve endmarkers) we can replace it by the rules 
Ai • • "* Ai 
1 m i 
(k)A A - A(k)A = A(k)A(k) 1 ^ i ^ m- 
A2*#* m' i i+1 i i+1' 1 * 1 * m' 
Afk)Afk| - B(k)A!k> 1 s i < m; and B A^k) 
i i+l i i+l m-1 m 
B -B . 
m-1 m 
(k) (k) 
Since the special nonterminals A| ,...,A^ are only 
created or rewritten by these rules, the only way that 
they can be eliminated once the A....A has been re- 
written is to finish rewriting it as B.. .. .B . 
1 m 

3. Parallel string granunars 
Even for isotonic context-sensitive grammars, the 
sets of sentences generated and parsed when the grammar 
is used "in parallel" is not the same as the set gene¬ 
rated or parsed when the grammar is used "sequentially". 
In fact, these sets can even be disjoint, as shown by 
the following example. Let the initial string be #XXXX#, 
and let the rules be 
XXX - XYX 
XXY - XaY 
XYY - XbY 
#XX - #cX 
XX# - Xc# 
cXc ccc 
aX -• aa bX -* bb 
Xa - aa Xb - bb 
aY - aa bY - bb 
It is not hard to verify that the "sequential language" 
of this grammar consists of the single sentence #aaaa#, 
while its "parallel languages" consist of the single 
sentences #bbbb# (generated) and #cccc# (parsed), re¬ 
spectively. [If we were not restricted to context-sen¬ 
sitive grammars, a simpler example would be provided by 
the grammar whose sole rule is XX -• aa; readily, from 
the initial string #XXXX# this yields the sequential language 
{#aaaa#}, but its "parallel languages" are (#aaaaaa#} 
(generated) and {#aaa#} (parsed), respectively.] 
In spite of the fact that the sequential and parallel 
languages of a given grammar need not be the same, we can 
show that various classes of such languages are the same. 
Here we shall not restrict ourselves to isotonic context- 

sensitive grammars. We begin by showing that for any 
grammar G, there exists a grammar G1 such that L(G') = L(G), 
and such that in any step of any derivation of a sentence 
using G', no rule can apply in more than one place. It 
follows that the parallel languages of G' — by any defi¬ 
nition — must be the same as its sequential language 
L(G). Moreover, if G is monotonie or isotonic, so is G'. 
Thus any (monotonie, isotonic) sequential language is a 
(monotonie, isotonic) parallel language. 
Theorem 4. For any grammar G, there exists a grammar G' 
such that L(G') = L(G), and where at any step of 
any G'-derivation, no rule applies at more than one 
place. Moreover, if G is monotonie or isotonic, so 
is G'. 
Proof: We may assume that no rule of G involves the end- 
markers. In every rule of G, replace each terminal 
X by a new nonterminal x, and then replace the left¬ 
most symbols A,B in the left and right members of 
the rule by new nonterminals (This assures 
that the right menber of any rule of G is nonnull, 
which is certainly true if G is monotonie or iso¬ 
tonic; the contrary case will be treated later.) 
Also add the new rules 
(1) #S# - #S*# 
(2) A*B -» AB* for all pairs of nonterminals A,B, 
,. one starred and the other not 
AB* - A*B 
(3) x y - xy fQr terminals x,y 
X*# - X# 
Readily, any derivation in G corresponds to a deri¬ 
vation in this new grammar G': initially, the S is 

changed to S*, and the modified rules of G in con¬ 
junction with rules (2) can then be used to yield 
any string in L(G), but with bars on its symbols 
and a star on its first symbol. Rules (3) can then 
be used to erase the bars and star. Note that G' 
may block if this is done too soon. Conversely, a 
derivation in G' can yield a terminal string only 
by eliminating all nonterminals except the barred 
ones, which can only be done using the modified 
rules of G, so that the resulting terminal string 
must be in L(G). Thus L(G') = L(G). 
Clearly, at any step in any nonblocking der¬ 
ivation in G' except the first and last, there is 
exactly one starred symbol. Thus no rule of G' can 
ever apply to a string in such a derivation at more 
than one place. Moreover, since rules (1-3) are all 
isotonic, if G was monotonie or isotonic, so is G'. 
The treatment is analogous if G is isotonic and 
uses the set of initial strings {#T # | k= 1,2,...}, 
except that (1) is replaced by #T - #U*. Note also 
that if G is context-sensitive, (2-3) can be modified 
to insure that G' is context-sensitive (e.g., replace 
A*B - AB* by A*B - A*B' - A'B' - A'B* - AB*). 
If G can have rules with null right members, we 
can use a slightly different trick to insure that no 
rule applies in more than one place. Let Z be a new 
nonterminal, and replace each rule « - ß of G by the 
rule Za -* Zß (where the bars indicate that terminals 
have been replaced by barred nonterminals). Also add 

the new rules 
1) #S# - #ZS# 
2) AZ - ZA 
for all nonterminals A 
ZA - AZ 
3) Zx - xZ 
Z# - #. // 
Note that if L is finite state (or more generally, 
linear), it has a linear grammar G, which implies that 
at any step of any derivation of a sentence in L, only 
one nonterminal is present. In particular, no rule can 
apply except to that nonterminal. Thus the analog of 
Theorem 4 holds with "monotonie" replaced by "finite state" 
or "linear". (On the analogous questions for the context 
free case, see the end of this section.) 
Our final goal is to show that for any grammar G 
there exists a grammar G* which, in effect, applies the 
rules of G in parallel, so that L(G*) is the same as the 
parallel language generated by G; thus any parallel lan¬ 
guage is a sequential language. Here again, we need not 
restrict ourselves to any particular definition of parallel 
language". The proof given below assumes that <* -• ß is 
applied to y by replacing every instance of of in v by ß; 
an analogous proof can be given for the context sinsitive 
version of "parallel" in which çAri - ?9ii is applied to y 
by replacing every A in v by 0. 
Let the vocabulary of G be {S = A^,...,An, #}, and its 
rules be -* ß^ 
ßi \ 1 i i * m), where * Aii*“Air. 
-- ' "ine G* to have vocabulary 
# • • • # m 

or d = 0,M,N,M*,N* or P} and initial symbol 
(5,0,0,0), and to have the following rules: 
1) #(a.,0,0,0)...(a ,0,0,0) - #(a A ,i*,0) 
1 ri L ±l 
(a ,A. ,i,0)...(ar ,Air ,i,0)# 1 ^ i s m 
X2 ri iri 
These rules copy the left member of a rule of 
G into the second terms of the left end of a 
string, and the rule number into the third 
terms; the first element of the rule has its 
rule number starred. In all of the following 
rules, a, b, c are A's: 
2) (a,b,i*,0) - (a,b,i*,M) if a = b 
(a,b,i*,0) - (a,b,i*,N) if a ^ b 
(a,b,i or i*, M) (c,d,i,0) - (a,b,i or i*,M) (c,d,i,M) 
if c - d, or with the last M replaced 
by N if c ^ d 
(a,b,i or i*,N) (c,d,i,0) - (a,b,i or i*,N) (c,d,i,N) 
These rules test to see whether the left member of 
the rule matches the corresponding string of first 
terms, starting from the left end. M's are created 
as long as the match continues, N's otherwise. 
3) (a,b,i*,M) (c,0,0,0) - (a,0,i,P) (c,b,i*,0) 
(a,b,i,M) (c,0,0,0) - (a,0,i,M) (c,b,i,0) 
(a,b,i,M) (c,o,i,M) - (a,0,i,M) (c,b,i,0) 
(a,b,i*,M) (c,0,i,M) - (a,0,i,P) (c,b,i*,0) 
If a match reaches the right end of the string of 
second terms, the string is shifted one step to the 
right, and a P is created at its former left end, 
while the M's and N's are erased. 

4) (a#b,i*,N) (¢,0,0,0) - (a,0,0,0) (c,b,i*,0) 
(a,b,i,N) (C,0,0,0) - (a,0,i,N) (c,b,i,0) 
(a,b,i,N) (c,0,i,N) - (a,0,i,N) (c,b,i,0) 
(a,b,i,M) (c,0,i,N) - (a,0,i,N) (c,b,i,0) 
(a,b,i*,N) (c,0,i,N) - (a,0,0,0) (c,b,i*,0) 
(a,b,i*,M) (c,0,i,N) - (a,0,0,0) (c,b,i*,0) 
Otherwise, the string is shifted and the M's and 
N's erased, but no P is created. In either case, 
once the i* is shifted, (2-4) can now be repeated. 
Note that when it has shifted sufficiently, and 
there are no P's left behind, (1) can be re-initiated 
too. 
5) (a,b, i* ,M)# - (a,0,i,P)# 
(a,b,i,M)# - ( a , 0,0, M* ) # 
(a,b,i,M) (c,0,0,M*) - (a,0,0,M*) (c,0,0,0) 
(a,b,i*,M) (c,0,0,M*) - (a,0,i,P) (c,C,0,0) 
6) (a,b,i*,N)# - (a,0,0,0)# 
(a,b,i,N)# - (a,0,0,N*)# 
(a,b,i,N) (c,0,0,N*) -* (a,0,0,N*) (c,0,0,0) 
(a,b,i,M) (c,0,0,N*) - (a,0,0,N*) (c,0,0,0) 
(a,b,i*,N) (c,0,0,N*) - (a,0,0,0) (c,0,0,0) 
(a,b,i*,M) (c,0,i,N*) - (a,0,0,0) (c,0,0,0) 
When the right endmarker is reached, the string of 
second terms is erased, M's and N's are erased, 
and a P created if what reached the right endmarker 
was an M. Note also that (3-4) turned all the i s 
to the left of the i* into 0's, and left i's only 
where there are P's; now (5-6) have turned all the 
i's to the right of the i* into 0's, and have turned 
.-he i* into i if it has a P, into 0 otherwise. 

,0,0,0)... 
t 
7) (a 0,i,p) <a2,0,0,0)...(3 ,0,0,0) - (air +1 
L * 1 
(A. ,0,0,0), (1 á i £ m); 
is. 
i 
(a^O,!,?) (a2,0,i,0) ...(ak,0,i,0) (b,0,i,P) - 
(A. ,0,i,0)...(A. ,0,i,0) (b,0,i,P), (1 £ i á m, 
ir.+l' lsi 1 £ k < r.) 
These rules replace each run of up to r^ 4-tuples 
which starts with P, contains no other P, and (if 
shorter than r^) is immediately followed by a P, 
by 4-tuples containing the right member of the ith 
rule. Even if a new rule left member has been 
copied in, its processing cannot cross P’s; i.e., 
one rule's P's must be processed before a second 
rule can move into the same part of the string. 
In summary: Rules (1-7¾of G* cause the ith rule of G 
to be applied to the given string "in parallel". 
8) #(a,0,0,0) - #a 
a (b, 0, 0,0) -• ab 
These rules turn the string of 4-tuples into a 
string of symbols of G's vocabulary; unless these 
are all terminals, the derivation blocks. 
Note that if G is monotonie or isotonic, so is G*. To 
modify the proof to handle the context sensitive type of 
parallelness, we would need to mark the symbol to be re¬ 
written (A, in §Ati) rather than the leftmost symbol. 
The analog of these results in the context free case 
is false — a context free parallel language is not neces¬ 
sarily a context free sequential language. For example, 
the context free grammar with rules S - TT, T - aT, T - bT, 
T - a, T - b, if applied in parallel, generates the set 
of sentences uotw, where uj is any string of a's and b's; as 

is well known, this is not a context free sequential lan 
guage. It is an open question whether conversely, any 
context free sequential language is a context free paral 
lei language. 

REFERENCES 
1. W. F. Miller and A. C. Shaw, Linguistic methods in 
picture processing - a survey, Proc. 1968 Fall Joint 
Comp. Conf., 279-290. 
2. R. A. Kirsch, Computer interpretation of English text 
and picture patterns, IEEE Trans. EC-13, August 1964, 
363-376. 
3. M. F. Dacey, The syntax of a triangle and some other 
figures, Pat. Recog. 2, January 1970, 11-31. 
4. A. Rosenfeld and J. L. Pfaltz, Sequential °P®rat^® 
in digital picture processing, JACM 13, October 1966, 
471-494. 


