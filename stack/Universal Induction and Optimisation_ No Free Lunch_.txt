SJÄL
VST
ÄNDIGA
ARBETEN
I
MA
TEMA
TIK
MA
TEMA
TISKA
INSTITUTIONEN,
STOCKHOLMS
UNIVERSITET
Univ
ersal
Indu tion
and
Optimisation:
No
F
ree
Lun 
h?
a
v
T
om
Ev
eritt
2013
-
No
3
MA
TEMA
TISKA
INSTITUTIONEN,
STOCKHOLMS
UNIVERSITET,
106
91
STOCKHOLM
,

,

Univ
ersal
Indu tion
and
Optimisation:
No
F
ree
Lun 
h?
T
om
Ev
eritt
Självständigt
arb
ete
i
matematik
30
högsk
olep
oäng,
A
v
an erad
niv
å
Handledare:
T
or
Lattimore,
P
eter
Sunehag
o
 
h
Mar us
Hutter
2013
,

,

Universal Induction and Optimisation:
No Free Lunch?
Tom Everitt
March 18, 2013

Abstract
Inductive reasoning is the process of making uncertain but justiﬁed infer-
ences; often the goal is to infer a general theory from particular observations.
Despite being a central problem in both science and philosophy, a formal
understanding of induction was long missing. In 1964, substantial progress
was made with Solomonoﬀ’s universal induction.
Solomonoﬀformalized
Occam’s razor by means of algorithmic information theory, and used this
to construct a universal Bayesian prior for sequence prediction. The ﬁrst
part of this thesis gives a comprehensive overview of Solomonoﬀ’s theory of
induction.
The optimisation problem of ﬁnding the arg max of an unknown function
can be approached as an induction problem. However, optimisation diﬀers in
important respects from sequence prediction. We adapt universal induction
to optimisation, and investigate its performance by putting it against the
so-called No Free Lunch (NFL) theorems. The NFL theorems show that
under certain conditions, eﬀective optimisation is impossible. We conclude
that while universal induction avoids the classical NFL theorems, it does
not work nearly as well in optimisation as in sequence prediction.

Acknowledgements
Thanks to my supervisors Tor Lattimore, Peter Sunehag and Marcus Hutter
at ANU. An extra thanks to Tor Lattimore for many enlightening discus-
sions, and to Marcus Hutter and ANU for hosting me for this Master’s
thesis.

Contents
1
Introduction
4
I
Kolmogorov Complexity and Universal Induction
8
2
Information
8
2.1
Strings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
8
2.2
Integers and strings . . . . . . . . . . . . . . . . . . . . . . . .
9
2.3
Preﬁx codes . . . . . . . . . . . . . . . . . . . . . . . . . . . .
9
2.4
Standard codes . . . . . . . . . . . . . . . . . . . . . . . . . .
11
2.4.1
Strings . . . . . . . . . . . . . . . . . . . . . . . . . . .
11
2.4.2
Pairs and tuples
. . . . . . . . . . . . . . . . . . . . .
11
2.4.3
Rational numbers . . . . . . . . . . . . . . . . . . . . .
11
2.5
Kraft’s inequality . . . . . . . . . . . . . . . . . . . . . . . . .
11
2.6
Optimality
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
12
3
Kolmogorov complexity and additively optimal preﬁx codes 13
3.1
Preﬁx-machines . . . . . . . . . . . . . . . . . . . . . . . . . .
13
3.2
Universal preﬁx-machines . . . . . . . . . . . . . . . . . . . .
15
3.3
Existence proofs for preﬁx-machines
. . . . . . . . . . . . . .
15
3.4
Description length
. . . . . . . . . . . . . . . . . . . . . . . .
16
3.5
Additive optimality . . . . . . . . . . . . . . . . . . . . . . . .
16
3.6
Kolmogorov complexity
. . . . . . . . . . . . . . . . . . . . .
17
3.7
Complexity bounds . . . . . . . . . . . . . . . . . . . . . . . .
19
3.8
Structure and randomness . . . . . . . . . . . . . . . . . . . .
20
3.9
Objectiveness . . . . . . . . . . . . . . . . . . . . . . . . . . .
20
4
Computability
21
4.1
Degrees of computability . . . . . . . . . . . . . . . . . . . . .
21
4.2
Semi-computability of K . . . . . . . . . . . . . . . . . . . . .
22
5
Measures and induction
23
5.1
Deﬁnition of measure . . . . . . . . . . . . . . . . . . . . . . .
24
5.2
Measure spaces on B∗and B∞. . . . . . . . . . . . . . . . . .
25
5.3
Measure conventions . . . . . . . . . . . . . . . . . . . . . . .
26
5.4
Measures on B∗. . . . . . . . . . . . . . . . . . . . . . . . . .
26
5.4.1
Dominance of m . . . . . . . . . . . . . . . . . . . . .
26
5.5
Measures on B∞
. . . . . . . . . . . . . . . . . . . . . . . . .
27
5.6
M and sequence prediction: Solomonoﬀinduction
. . . . . .
28
5.6.1
Induction with a uniform prior . . . . . . . . . . . . .
30
5.7
Other induction settings . . . . . . . . . . . . . . . . . . . . .
30
5.8
AIXI and universal intelligence . . . . . . . . . . . . . . . . .
31
1

6
Summary of Part I
31
II
No Free Lunch and Optimisation
32
7
Preliminaries
33
7.1
Search problems
. . . . . . . . . . . . . . . . . . . . . . . . .
33
7.2
Algorithms
. . . . . . . . . . . . . . . . . . . . . . . . . . . .
34
7.2.1
Search traces . . . . . . . . . . . . . . . . . . . . . . .
34
7.2.2
Deterministic search algorithms . . . . . . . . . . . . .
34
7.2.3
Probabilistic algorithms . . . . . . . . . . . . . . . . .
35
7.3
An example . . . . . . . . . . . . . . . . . . . . . . . . . . . .
36
7.4
Permutations, functions and enumerating algorithms . . . . .
37
7.5
A measure on traces . . . . . . . . . . . . . . . . . . . . . . .
38
7.5.1
Types of events . . . . . . . . . . . . . . . . . . . . . .
39
8
Literature review
40
8.1
NFL Theorems . . . . . . . . . . . . . . . . . . . . . . . . . .
40
8.2
Classes of functions . . . . . . . . . . . . . . . . . . . . . . . .
40
8.3
Single functions, searchability . . . . . . . . . . . . . . . . . .
41
8.4
Almost No Free Lunch . . . . . . . . . . . . . . . . . . . . . .
42
8.5
Other investigations
. . . . . . . . . . . . . . . . . . . . . . .
43
9
No free lunch
43
9.1
Two equivalent NFL-deﬁnitions . . . . . . . . . . . . . . . . .
44
9.2
Uniform distributions
. . . . . . . . . . . . . . . . . . . . . .
45
9.3
Non-uniform distributions . . . . . . . . . . . . . . . . . . . .
46
9.4
Continuity of NFL . . . . . . . . . . . . . . . . . . . . . . . .
48
9.4.1
Tightness . . . . . . . . . . . . . . . . . . . . . . . . .
51
10 Performance measures
53
10.1 Theoretical considerations . . . . . . . . . . . . . . . . . . . .
54
11 Universal free lunch
56
11.1 Adapting the optimisation problem . . . . . . . . . . . . . . .
57
11.2 The universal distribution . . . . . . . . . . . . . . . . . . . .
59
11.3 Free lunch under arbitrary measure . . . . . . . . . . . . . . .
59
11.4 Free lunch under Mptm . . . . . . . . . . . . . . . . . . . . . .
60
12 Upper bounds on universal free lunch
63
12.1 Computable algorithms
. . . . . . . . . . . . . . . . . . . . .
63
12.2 Needle-in-a-haystack functions
. . . . . . . . . . . . . . . . .
66
12.3 Incomputable algorithms . . . . . . . . . . . . . . . . . . . . .
67
2

13 Concluding remarks
68
13.1 Summary
. . . . . . . . . . . . . . . . . . . . . . . . . . . . .
68
13.2 Optimisation and sequence prediction
. . . . . . . . . . . . .
69
13.3 Future research . . . . . . . . . . . . . . . . . . . . . . . . . .
69
Appendices
72
A Proofs
72
B Lists of notation
72
B.1
Abbreviations . . . . . . . . . . . . . . . . . . . . . . . . . . .
72
B.2
Generic math notation . . . . . . . . . . . . . . . . . . . . . .
72
B.3
Kolmogorov complexity notation . . . . . . . . . . . . . . . .
72
B.4
Probability theory notation . . . . . . . . . . . . . . . . . . .
73
B.5
No free lunch notation . . . . . . . . . . . . . . . . . . . . . .
73
List of ﬁgures
1
Kolmogorov directions—XKCD web-comic . . . . . . . . . . .
18
2
Example of a search-situation . . . . . . . . . . . . . . . . . .
37
3
Function class with high “information gain”.
. . . . . . . . .
54
4
Illustration of non-block uniformity of m . . . . . . . . . . . .
60
List of tables
1
The 1n0-code for numbers. . . . . . . . . . . . . . . . . . . . .
10
3

1
Introduction
The goal of optimisation is to ﬁnd an input (to some system) that yields a
high output. When an input is tried, you become aware of the associated
output, but trying inputs (probing) is costly. The goal is therefore to only
try a small number of inputs before ﬁnding one that yields a high output.
In other words, the goal is eﬃcient optimisation in the number of probes.
What information is required for eﬃcient optimisation to be possible?
This will be the central question of this thesis. Formally it is natural to
represent an optimisation problem with an unknown function; the goal is
then to quickly ﬁnd the arg max of the function. We also need a representa-
tion of the information/uncertainty we have about the function. Adopting a
Bayesian perspective, the information about the function can be represented
as a prior probability distribution over the class of all functions. For exam-
ple, if one function f has probability 1 and all other functions probability
0 in the prior, then this represents a complete certainty in f being the true
function. In this case the maximum should easily be found in only one probe
(disregarding computational aspects).
More realistically, the problem might be to ﬁnd an ideal input to a system
that is only partially known. For example, the task might be to ﬁnd the
ideal amount of gas to input into the ignition of a car engine, and the only
thing known about the system might be that it is described by a low-degree
polynomial. This situation can be represented by a prior with relatively
high weight on low-degree polynomials, and low or zero weight on other
functions.
As diﬀerent inputs are supplied to the system and the outputs of those
inputs are measured, the knowledge of the system grows. For example, if
an input x is found out to map to some y, then all functions not consistent
with this behaviour may be discarded.
The prior may be updated to a
posterior distribution where inconsistent functions receive probability 0 (it
is now certain they are not the true function), and consistent functions get
a corresponding upweighting (cf. Bayes’ rule). If the prior with high weight
on low-degree polynomials was correct, then only a few probes should be
required to detect which function describes the input-output relation, so a
good input should be found quickly.
But what if nothing is known about the system the function describes,
and the only information one has about the function is its input-output
behaviour in some probed points? Does that make it impossible optimise
the function eﬃciently? or is there a universal principle for how to optimise
a function when nothing else is known? Most humans seem to have the
intuition that from seeing, say, 100 points of a function, they can often
discover the pattern of the function and (somewhat) accurately extrapolate
its behaviour in unseen points. Is there any formal justiﬁcation for such a
claim?
4

Let us begin with a negative observation.
In answer to overly bold
claims about the universal performance of some search algorithms, Wolpert
and Macready [WM97] showed a number of results called No Free Lunch
(NFL) theorems. Essentially they proved that if a search algorithm does well
on some set of functions, then that must be mirrored by bad performance
on another set of functions.
More formally, they showed that all search
algorithms will perform the same in uniform expectation over all functions
(see Part II for more details).
The NFL theorems were generally interpreted to say that a problem-
speciﬁc bias is required for eﬃcient optimisation. The argument roughly
goes like this: The uniform prior is the most unbiased prior, as it gives
equal weight to all functions. The NFL theorems show that it is impossible
to optimise well under the uniform prior. Hence a problem speciﬁc bias is
necessary for eﬃcient optimisation.
This argument is not accepted in this thesis. It can be shown that if a
function is sampled from the uniform distribution, then with high probabil-
ity the function exhibits no particular structure (is algorithmically random).
Obviously, if no pattern exists, no intelligent optimiser (humans included)
can ﬁnd a pattern for extrapolating the function behaviour. Eﬃcient op-
timisation thus becomes hopeless.
In contrast, functions that do behave
according to some pattern should—at least in principle—be possible to op-
timise eﬃciently. Remarkably, the notion of structure and randomness can
be given formal deﬁnitions based on Kolmogorov complexity described in
Section 3.
Along these lines it may be argued that the uniform prior is not bias-free
but biased towards randomness, and that this explains the diﬃculty in opti-
mising under a uniform prior. A principled alternative called the universal
distribution exists. The universal distribution is based on Kolmogorov com-
plexity, and is designed to give high weight to structured problems and low
weight to random ones. It is often advocated as a formalisation of Occam’s
razor [RH11].
Since the universal distribution is only biased towards structure per se,
it does not favour any particular problem over another. It does give lower
probability to random functions than the uniform distribution, but since
random functions are next to hopeless to optimise eﬃciently, this should not
be seen as a major deﬁcit. Rather, this is precisely what gives an intelligent
optimiser a fair chance to ﬁnd a pattern.
In sequence prediction, which is a rather general induction setting, a pre-
dictor based on the universal distribution has been shown to do exceptionally
well on sequences generated by computable distributions. This induction
principle is called universal induction or Solomonoﬀinduction.
The main goal of this thesis is an adaption of universal induction to
optimisation. A similar venture for Supervised Learning was made in [LH11].
Our most important results include a proof that the NFL theorems do not
5

apply to the universal distribution, as well as some upper bounds on the
“amount of free lunch” under the universal distribution (Section 11 and
12). Part II also contains a number of minor contributions, indicated in its
introduction.
Before the new contributions, we will provide background on two areas.
Part I explains Kolmogorov complexity and Solomonoﬀinduction. The ﬁrst
sections of Part II recounts the most important NFL results, including a
literature review on NFL and optimisation in Section 8. Throughout I use
“we” rather than “I”, so that the thesis can be consistent with a recent
paper submission [EL13].
6


Part I
Kolmogorov Complexity and
Universal Induction
In this part we give an account of Kolmogorov complexity and universal
(Solomonoﬀ) induction. The two main sources are [LV08, Hut05]. The ﬁrst
oﬀers an expansive exposition on Kolmogorov complexity, including a wide
range of applications. The second is more concise and primarily directed
towards Artiﬁcial Intelligence.
The aim here is to give a comprehensive
overview of the core results of Kolmogorov complexity and to lay a founda-
tion for applications to optimisation in Part II. Unless otherwise mentioned,
results and deﬁnitions found in this part (Part I) are from the previously
mentioned sources; further discussion and motivation can be found in them.
2
Information
2.1
Strings
Binary strings are natural objects for representing information. Formally,
let B = {0, 1} and deﬁne a binary string s as a sequence s1 . . . sn with si ∈B
for 1 ≤i ≤n. We say that the length of a string s = s1 . . . sn is n, and
denote it by ℓ(s) = n. We use the notation sn and sm:n to extract the nth
and the m-to-nth bits of s respectively.
The letters s, t and q will be used for arbitrary strings, and ϵ for the
empty string (of length 0). The set of all strings of length n is denoted by
Bn; the set of all ﬁnite strings is denoted by B∗= S
n∈N Bn; and the set of
all ﬁnite, non-empty strings is denoted by B+ = B∗−{ϵ}. The letter z will
be used for one-way inﬁnite sequences z1z2, . . . with zi ∈B. The set of all
one-way inﬁnite sequences will be denoted by B∞.
A number of operations on strings and one-way inﬁnite sequences can be
deﬁned. Let s = s1 . . . sn, t = t1 . . . tm and z = z1z2, . . . . The concatenation
of s and t is written st = s1 . . . snt1 . . . tm, and has length ℓ(st) = ℓ(s)+ℓ(t).
The concatenation of s with an inﬁnite sequence z is the inﬁnite sequence
sz = s1 . . . snz1z2 . . . . The empty string ϵ is the identity element for con-
catenation; that is, ϵs = sϵ = s for all strings s, and ϵz = z for all one-way
inﬁnite sequences z.
Exponentiation is deﬁned thus: Let s ∈B and n ∈N. Then
sn = s . . . s
| {z }
n times
For example, 03 = 000.
8

Let s = tq be a string. Then t is said to be a preﬁx of s, and s is said to
be an extension of t. If q ̸= ϵ, then t and s are said to be proper preﬁxes and
extensions respectively. A preﬁx s = z1:n of z is called an initial segment of
z.
2.2
Integers and strings
It will be convenient to identify natural numbers with strings in a somewhat
non-standard manner. Using the lexicographical enumeration of
B∗= {ϵ, 0, 1, 00, 01, 10, 11, 000, 001, . . . }
identify any natural number i with the ith element of this enumeration.
So, for example, 0 is identiﬁed with ϵ and 5 with 01. This diﬀers from the
more standard assignment where for instance 2 corresponds to 10, 010, 0010,
etc. The primary beneﬁt of our identiﬁcation is that the correspondence is
bijective.
Using this identiﬁcation, the length of a number i may be deﬁned as the
length of its corresponding string. It is easily veriﬁed that the length grow
logarithmically with the number; more precisely, log2(i) ≤ℓ(i) ≤log2(i + 1)
for all i ∈N [LV08, p. 14].
2.3
Preﬁx codes
What information does a string contain? This completely depends on the
coding. To have a string represent something, a code has to be deﬁned that
assigns a meaning to each string. Strings with assigned meaning are called
code words or just words. For example, the (Extended) ASCII-code used on
many computers, assigns symbols to binary strings of length 8. In ASCII,
the letter A is encoded by 01000001 and B by 01000010.1 When typing on a
computer, the letters are encoded as binary strings according to the ASCII-
code, and typically stored in some ﬁle. The letters may later be retrieved,
decoded, using the ASCII-code in the “opposite direction”.
Deﬁnition 2.1 (Codes). A code is a partial function C : B∗⇁X, where
X is known as the set of objects. The strings w ∈B∗on which C is deﬁned
are known as the code words of C. If C(w) = s we say that w is a C-code
word for s, and say that s is the meaning or object of w.
Several ASCII-code words can be appended to each other with main-
tained decodability. This is not a property of all codes. Imagine, for in-
stance, that we had chosen the code 0 for A, the code 1 for B, the code 01
for C and so on. Then it would not be clear whether 01 should be decoded
as AB or as C.
1See for instance http://www.ascii-code.com/ (accessed February 12, 2013) for a full
list of the ASCII code words.
9

For the ASCII-code, the property that guarantees unique decodability
is that all codes have the same length. This is an undesirable restriction
in some cases. Sometimes one object is much more frequent than another,
in which case it may be advantageous to assign a shorter code word to
the frequent object. In other cases, we may want to construct a code for
inﬁnitely many objects (such as for the natural numbers). In both these
cases, code words of varying length are required.
The general theory of preﬁx codes can be used to construct codes with
code words of diﬀerent lengths, while retaining the unique decodability of
appended code words.
Deﬁnition 2.2 (Preﬁx codes). A code C is a preﬁx (free) code if no code
word of C is a proper preﬁx of another code word of C.
The preﬁx property makes it possible to tell where one code word stops
and the next starts in a sequence of appended code words. Intuitively, the
sequence can be read bit by bit until a code word is found. Since this code
word is not a preﬁx of any other code word, it must be correct to decode
the code word immediately.
The ASCII-code is preﬁx, since no code word of ASCII is a proper preﬁx
of another (this is obvious since all code words have the same length). And
accordingly, it is always possible to tell where one code word stops and the
next starts in an ASCII-sequence (given the starting point of the ﬁrst code
word). A more interesting example is the 1n0-code for the natural numbers
(Table 1).
The idea is very simple: encode every number n with n 1’s
Number
code word
0
0
1
10
2
110
3
1110
...
...
n
1n0
...
...
Table 1: The 1n0-code for numbers.
followed by a 0. This way no code word can be a preﬁx of another. As an
example, the sequence 11011100 can only be decoded as 2,3,0:
110
|{z}
2
1110
|{z}
3
0
|{z}
0
An important point is that the starting point has to be ﬁxed. In many preﬁx
codes, it is not possible to start in the middle of a sequence and decode it
correctly (the 1n0-code is an exception).
10

2.4
Standard codes
It is now time to introduce a number of standard encodings, which we will
frequently rely on in the subsequent developments.
2.4.1
Strings
A standard preﬁx code for strings which will be of much use is the following.
Encode every string s as s = 1ℓ(s)0s. That is, preﬁx s with the 1n0-code
word for ℓ(s), so that the encoder knows how long s is before starting to
read it.
For example, the string 101 will be encode as 101 = 1110101, because
101 = 111
|{z}
1ℓ(101)
0
|{z}
0
101
|{z}
101
The empty string ϵ has code word ϵ = 1ℓ(ϵ)0ϵ = 0 (so ℓ(ϵ) = 1).
2.4.2
Pairs and tuples
The standard preﬁx code for strings can be used for a standard code of pairs
of strings. Pairs of strings will be encoded as (s, t) = st. This makes it clear
where s stops and t starts. The length of a pair (s, t) is ℓ(s, t) = ℓ(st) =
2ℓ(s) + 1 + ℓ(t). By intention, this does not entail a preﬁx code for both
s and t. The reason for this choice of deﬁnition will become clear in the
deﬁnition of Kolmogorov complexity in Section 3. To obtain a preﬁx code
for both s and t, the construction (s, t) = st may be used.
Triples (s1, s2, s3) are encoded as s1 s2s3 and so on. In situations where
the cardinality of the tuple is not clear from the context, such as when an
arbitrary tuple can be supplied to a program, n-tuples (s1, . . . , sn) can be
encoded as 1n0(s1, . . . , sn) = 1n0s1 . . . sn−1sn.
2.4.3
Rational numbers
The set of rational numbers Q can be identiﬁed with pairs of natural num-
bers, together with a sign. For m, n ∈N encode the rational number m/n as
1(m, n) = 1mn, and the rational number −m/n as 0(m, n) = 0mn (where
we have tacitly used the identiﬁcation between natural numbers and strings
described in Section 2.2).
2.5
Kraft’s inequality
A useful intuition for preﬁx codes is that by including a short code word—
say 10—in our code, we rule out all longer strings starting with 10 as code
words (because 10 is a proper preﬁx of those). In this respect, short code
11

words take up “more space” in the set of of potential code words than long
code words. This intuition has a geometric interpretation.
The set of all one-way inﬁnite binary sequences naturally represent the
interval [0, 1] by interpreting sequences as binary expansions of real num-
bers. In this view, let a (ﬁnite) string s correspond to the half-open interval
Γs = [s000 . . . , s111 . . . ). Observe that the length of this interval is pre-
cisely 2−ℓ(s). Observe also that by using s as a codeword, no string s′ with
overlapping interval can be used as a code word.
This is the intuition behind Kraft’s inequality (see e.g. [LV08, Section
1.11.2] for a full proof).
Theorem 2.3 (Kraft’s inequality). There is a preﬁx code with code words
of length l1, l2, . . . if and only if P
i 2−li ≤1.
2.6
Optimality
The Kraft inequality makes precise the “maximum shortness” of the code
words of a preﬁx code. Consider for example the 1n0-code for the natural
numbers discussed above. This code is optimal in the sense that the lengths
of its code words are maximally short with respect to Kraft’s inequality.
The code for 0 has length 1, the code for 1 has length 2 and so on, so the
total length is P
i∈N 2−i = 1.
However, in another sense it is rather ineﬃcient. Consider the number
99999. This number is shortly describable in the standard (informal) math-
ematical language. To construct a formal code in which 99999 is short, the
ASCII-code discussed above can be used: encode 99999 with the ASCII-
code for 10e+100 as is done on most calculators. This coding only requires
7 · 8 = 56 bits for 99999. On the other hand, in the 1n0-code the code word
for 99999 requires approximately 101989 pages! (assuming we could ﬁt ten
thousand 1’s on every page). In this sense, the 1n0-code is very ineﬃcient.
The ASCII-coding pays the price for the shorter code word of 99999 by
having longer code words for the small natural numbers. While the number
2 requires only 3 bits in the 1n0 code, it requires 8 bits in ASCII.
Which code is better depends on the situation. The 1n0 code is better
if one mainly wants to encode small numbers, and the ASCII-code is better
if one (sometimes) wants to encode larger numbers. There is, however, an
objective sense in which the ASCII-based code is preferable: No number
has a substantially longer ASCII-code word than 1n0-code word, but some
numbers (such as 99999) have much shorter ASCII-code words than 1n0-code
words. This is the idea of additively optimal codes, developed further in the
next section.
12

3
Kolmogorov complexity and additively optimal
preﬁx codes
In this section the aim will be to quantify the information content of a string
s, called the Kolmogorov complexity of s. The intuition is that while some
strings have no shorter description than the string itself, other strings are
signiﬁcantly compressible. For example, the string t of a thousand consecu-
tive 0’s is highly compressible since t has a short description. In this sense,
t has low information content. Conversely, to describe a random string, one
generally needs to describe each single bit by itself. Such incompressible
strings are said to have high information content.
That there is an (essentially) objective measure of information content
is somewhat surprising. The measure is obtained by the construction of an
additively optimal code for strings (in this section, all codes describe strings).
Deﬁnition 3.1 (Additive optimality). A code C is additively optimal for a
class C of codes, if for all C′ ∈C exists a constant c such that for all strings
s, the existence of a C′-code word w′ for s implies the existence of a C-code
word w for s with ℓ(w) ≤ℓ(w′) + c.
As an example, recall the comparison between the 1n0-code for numbers
and the ASCII-code for numbers. In the class of these two codes, only the
ASCII-code was additively optimal (it is possible to construct numbers that
the the ASCII-code has arbitrarily much shorter code words for but not the
other way around). Other code-classes may have several additively optimal
elements.
Unfortunately, there is no additively optimal preﬁx code for the class of
all preﬁx codes. But in the restriction to eﬀective preﬁx codes (deﬁned in a
moment) an additively optimal element exists. The ﬁrst aim of this section
will be to develop such an additively optimal eﬀective code. The existence
will then be used to deﬁne Kolmogorov complexity, which can be interpreted
as an objective measure of the information content of a string.
3.1
Preﬁx-machines
Turing-machines correspond to partial recursive functions (see, for instance,
[Cut80]). It is natural to say that a code is eﬀective if it is a partial recursive
function. Some, but not all, partial recursive functions deﬁne preﬁx codes.
Deﬁne a preﬁx-function f : B∗⇁B∗as a partial function with the property
that if f(w) is deﬁned, then f(wt) is undeﬁned for all t ̸= ϵ; that is, f is
a function deﬁning a preﬁx code. Consequently, eﬀective preﬁx codes are
partial recursive preﬁx-functions.
Just as Turing-machines correspond to partial recursive functions, there
is a type of machine corresponding to the partial recursive preﬁx-functions.
13

It is called a preﬁx-machine, and is essentially a Turing-machine with slightly
limited input-output behavior.
Deﬁnition 3.2 (Preﬁx-machines). A preﬁx-machine V is a Turing-machine
[Cut80] modiﬁed in the following way. V has a one-way inﬁnite input tape
and a one-way inﬁnite output tape, allowing only 0 and 1 as symbols. V also
has a one-way inﬁnite work-tape that allows blank symbols # in addition to
0 and 1. V has a reading head for the input tape that can only be moved to
the right; and V has a writing head for the output tape that always moves
one step to the right after it has written a symbol. The writing head cannot
be moved in any other manner.
If V halts after having read an initial segment w of the input tape (the
input head is on the rightmost symbol of w), and the string to the left of
the writing head is s, then we say that V outputs s on input w, and write
V (w) = s.
Note that by the restriction in input-output behaviour, if a preﬁx-
machine V halts on w, then V does not halt on any proper preﬁx of w, nor
does it halt on any proper extension of w. This shows that preﬁx-machines
deﬁne partial recursive preﬁx-functions.
Conversely, the following proposition shows that every partial recursive
preﬁx-function is computed by a preﬁx-machine (using the fact that every
partial recursive function is computed by a Turing-machine).
Proposition 3.3 (Preﬁx-machines and partial recursive preﬁx-functions).
For every partial recursive preﬁx-function f, there is a preﬁx-machine V
such that V (w) = s whenever f(w) = s.
Proof. For a given partial recursive preﬁx-function f, there is a Turing-
machine V ′ computing it. Using V ′, we can construct a preﬁx-machine V
that also computes f.
Let V have a variable w initialized as the empty string ϵ, and let V
execute the following loop. For growing k ≥0, V simulates V ′ with inputs
wt with t of size at most k for k time steps, until a halting input wt is found
(if not, V runs forever). If t = ϵ, then V outputs the output of V ′(w). If
not, then V reads one more symbol χ from the input tape, sets w = wχ and
restarts the loop.
Since V ′ computes a preﬁx-function, if V ′ halts on an input w then V ′
will not halt on any proper preﬁx or extension of w. So whenever V gets an
input sequence starting with w, then V will halt exactly when it has read w,
and output V ′(w). And if the input sequence given to V does not contain
any initial segment on which V ′ halts, then V will not halt either. So V
computes the same partial function f as V ′.
We have thus established that there is a natural correspondence between
preﬁx-machines and partial recursive preﬁx-functions/eﬀective preﬁx codes.
14

3.2
Universal preﬁx-machines
A pivotal property of the Turing-machines is that they can be described
by strings, and that there is a universal Turing-machine U that simulates
any Turing-machine V given the string-description of V . By a similar argu-
ment as is used for Turing-machines, the preﬁx-machines can be described
by strings.
Henceforth the string-descriptions of preﬁx-machines will be
treated as numbers (according to the string-number identiﬁcation described
in Section 2.2), which yields an eﬀective enumeration V1, V2, . . . of all preﬁx-
machines (where Vi is the machine described by i).2
To enable preﬁx-machines to take more than one argument, we will make
use of the standard encoding of pairs (tuples) described in Section 2.4.2. For
example, Vi(q, w) means Vi(qw).
A preﬁx-machine V0 is a universal preﬁx-machine if there is an exhaustive
enumeration of all preﬁx-machines V1, V2, . . . such that for all i ∈N and all
q, w, s ∈B∗it holds that V0(q, i, w) = s whenever Vi(q, w) = s.3
The
enumeration V1, V2, . . . is called the enumeration associated with V0. The
reason for q will be apparent shortly.
The following shows the existence of a universal preﬁx-machine.
Proposition 3.4 (Universal preﬁx-machines). There is a universal preﬁx-
machine V0.
Proof. V0 can roughly be designed as follows. First V0 reads q and i and
stores them on the work-tape. Then it continues to simulate Vi as described
by i, except that V0 simulates Vi reading symbols from q until Vi has read
past q. When (if) Vi reads past q, then Vi is simulated to read symbols
directly from V0’s input tape.
3.3
Existence proofs for preﬁx-machines
The standard way to show that a certain function is a partial recursive preﬁx-
function is to outline the construction of a preﬁx-machine computing it. This
normally involves devising a preﬁx code for which it is “clearly decidable”
(for a preﬁx-machine) where a code-word stops in an input-sequence. There-
after the argument normally proceeds much like the standard argument
for the existence of certain Turing-machines: The rest of the computation-
procedure is described in a way that makes it clear that it could, in principle,
be implemented on a Turing-/preﬁx-machine.
2The enumeration is eﬀective in the sense that given an index i, it is clear which preﬁx-
machine is denoted by Vi. This is immediate, since the index is a description of how to
simulate Vi on V0.
3Technically, the universal preﬁx-machine we have deﬁned here may be called an addi-
tively optimal preﬁx-machine. There are (degenerate) universal preﬁx-machines that for
example require the input to appear twice on the input tape (so V (qq, ii, ww) = Vi(q, w))
[LV08, Example 2.1.2]. This degenerate kind of universal preﬁx-machine cannot be used
to deﬁne Kolmogorov complexity.
15

3.4
Description length
Let V be a preﬁx-machine. Deﬁne for any string s the (minimum) descrip-
tion length of s with respect to V as:
KV (s) = min
w {ℓ(w) : V (w) = s}
(1)
The minimum description length is the length of the shortest description—or
maximum compression—of s in the code V .
In many situations it is natural to ask what the description length of an
object is relative to a description of another object. For example, the com-
plexity of an image might be high, but if we have a sequence of images (such
as in a movie) it can be natural to ask what the complexity of one image
is given the preceding image. In a movie, the latter quantity is often much
smaller. This motivates the more general notion of conditional description
length.
Deﬁne the conditional (minimum) description length of a string s with
respect to a preﬁx-machine V and given information q as
KV (s|q) = min
w {ℓ(w) : V (q, w) = s}
(2)
That is, the length of the shortest addition w to q such that V (q, w) = s.
In the case of a movie, w could be a description of how the current image s
diﬀers from the preceding image q.
Just as when no q was supplied, all preﬁx-machines V deﬁne a preﬁx
code V (q, ·) for any ﬁxed q.
3.5
Additive optimality
Recall Deﬁnition 3.1 of additive optimality. Universal preﬁx-machines de-
ﬁne additively optimal codes for the class of eﬀective preﬁx codes, by the
following theorem.
Theorem 3.5 (Additive optimality). Let U be a universal preﬁx-machine
and let q be any string. Then U(q, ·) describes an additively optimal preﬁx
code.
Proof. Let C be an eﬀective preﬁx code computed by a preﬁx-machine V .
Then there is a preﬁx-machine V ′ such that V ′(q, ·) computes C (V ′ works
like V , except that it ﬁrst reads past q).
In the enumeration V1, V2, . . .
associated with U, V ′ = Vi for some i. This means that whenever w is
a C-code word for a string s (that is, when V ′(q, w) = V (w) = s), then
U(q, i, w) = s. Therefore the minimal U(q, ·)-code word for any string s is
at most ℓ(i) = 2ℓ(i)+1 longer than the minimal description length of s with
respect to V .
The constant cV = ℓ(i) is sometimes known as the compiler constant for
V .
16

3.6
Kolmogorov complexity
Having obtained an eﬀective additively optimal preﬁx code, it is fairly
straightforward to deﬁne the Kolmogorov complexity of a string s.
The
deﬁnition uses the length of the shortest code word for s in an additively
optimal code.
Deﬁnition 3.6 (Conditional Kolmogorov complexity). Let U to be a par-
ticular conditional universal preﬁx-machine, from now on known as the ref-
erence machine. When enumerating preﬁx-machines subsequently, the enu-
meration will be with respect to U. Let the conditional Kolmogorov com-
plexity be deﬁned as
K(s|q) = KU(s|q)
(3)
Finally, deﬁne K(s) = K(s|ϵ) for the unconditioned Kolmogorov complexity.
The invariance theorem below show that the choice of conditional uni-
versal preﬁx-machine only has limited impact, and thus that Kolmogorov
complexity is an essentially objective notion (see Section 3.9 for further dis-
cussion).
Theorem 3.7 (Invariance theorem). For any preﬁx-machine V there is a
constant cV such that for all strings s and q
K(s|q) ≤KV (s|q) + cV
Proof. By Theorem 3.5, the code U(q, ·) is additively optimal. Thus, for any
preﬁx-machine V , there exists a constant cV such that for all strings s and
q, the shortest U(q, ·)-code word for s is at most cV longer than any V -code
word for s.
Example 1 (Kolmogorov complexity). Consider the following two strings.
Let s be the string of one million 0’s, and let t be a string of one million
random 0’s and 1’s. Then the complexity of s is low, since there is a simple
preﬁx-machine V that on input n outputs 10n (ten to the n) number of 0’s.
V has a simple index i, and outputs s on input 6 = 11010. Therefore the
complexity of s is K(s) ≤2ℓ(i) + 1 + ℓ(6) = 2ℓ(i) + 6.
For t the situation is the opposite. With high probability there is no
simple preﬁx-machine that outputs t on a short code word, intuitively
because there is no structure in t to exploit. Kolmogorov complexity can be
seen as a formal measure of structure, with lower complexity corresponding
to more structure.
♦
Figure 1 gives a more humorous illustration of compression and Kol-
mogorov complexity.
17

Figure 1:
Kolmogorov directions.
An XKCD web-comic (by Randall
Munroe, January 2013), depicting a highly (maximally?) compressed set
of directions. Fetched from http://xkcd.com/1155/ on January 28, 2013.
To help intuition, it is useful to consider the two-part nature of the code
words of U. Indeed, the Kolmogorov complexity may equivalently be deﬁned
as
K(s|q) = min
i,w {ℓ(i, w) : Vi(q, w) = s}
(3′)
There is often a tradeoﬀbetween on the one hand describing a complex
preﬁx-machine (with complex index i) for which a short program suﬃces to
produce s, and on the other describing a simple preﬁx-machine for which a
longer program is required to produce s. In the following example, which
also illustrates conditional Kolmogorov complexity, it is natural to put all
information in the index i, and no information in w.
Example 2 (Preﬁx-complexity). The complexity of a string s given the same
string s is
K(s|s) ≤c
(4)
for some constant c independent of s. The intuitive reason is that there
is a program i for the machine U that copies any input to the output
tape.
In more detail, there is a preﬁx-machine Vi that on any input
string s (in the standard preﬁx-encoding of s) outputs s. This means that
U(s, i, ϵ) = Vi(s, ϵ) = Vi(s) = s, which implies K(s|s) ≤2ℓ(i) + 1 where i is
independent of s.
♦
18

3.7
Complexity bounds
It is possible to establish an upper bound on the complexity of any string.
Proposition 3.8 (Maximum complexity). There exist constants c1, c2 > 0
such that
K(s|q) ≤ℓ(s) + K(ℓ(s)) + c1 ≤ℓ(s) + 2ℓ(ℓ(s)) + c2
(5)
for all s and q.
Proof. Any string s can be (preﬁx-)coded by a preﬁx code for ℓ(s) immedi-
ately followed by s (this was for example used in the s = 1ℓ(s)0s code). By
using the additively optimal code associated with the reference machine U
to code the length of s, we can code ℓ(s) in K(ℓ(s)) bits. This motivates
the ﬁrst inequality.
One particular choice of coding for lengths is to encode ℓ(s) by
ℓ(s) = 1ℓ(ℓ(s))0ℓ(s).
This yields a code where every string s is encoded
as 1ℓ(ℓ(s))0ℓ(s)s.
For example, the string t = 10010 is encoded as t′ =
1100110010, since
t′ =
11
|{z}
1ℓ(ℓ(t))
0 01
|{z}
ℓ(t)=5
10010
| {z }
t
(6)
In this coding, every string has a code word of length 2ℓ(ℓ(s)) + ℓ(s) + 1.
This code is somewhat longer than the K(ℓ(s)), but much more eﬃcient
than 1ℓ(s)0s.
By using Kraft’s inequality, it is possible to also derive a type of lower
bound for Kolmogorov complexity. Although little can be said about the
complexity of an arbitrary (single) string, it is possible to say something
about the minimum complexity of some collections of strings.
First a deﬁnition: We say that a string s is compressible if K(s) <
ℓ(s) and that s is incompressible if K(s) ≥ℓ(s). Analogously, the notions
compressible- and incompressible with respect to q are deﬁned by K(s|q) <
ℓ(s) and K(s|q) ≥ℓ(s) respectively.
Proposition 3.9 (Minimum complexity). For any given length n, at most
half of the strings of length n are compressible.
Proof. For any n, there are 2n strings s of length n. For s to compressible,
there must be a code word w of length less than n. By Kraft’s inequality, in
any preﬁx code there can be at most 2n−1 code words of length strictly less
than n. Thus, at most half of all strings of length n can be compressible.
Note that the bound is not tight for most n, as there are some code
words that are much shorter than n −1 for most n. Also, the proposition
is only true for preﬁx codes. For codes that are not preﬁx, there are can be
up to 2n −1 code words shorter than n.
19

It is straightforward to generalize compressibility to k-compressibility. A
string s is k-compressible if K(s) < ℓ(s) −k and k-incompressible if it is not
k-compressible. The corresponding generalisation of Proposition 3.9 then
reads: At most 2n−k−1 strings of length n are k-compressible.
The bounds of Proposition 3.8 and 3.9 are often essential tools in estab-
lishing properties of Kolmogorov complexity.
3.8
Structure and randomness
Incompressibility may also be used to deﬁne randomness.
Essentially, a
string is (Martin-L¨of) random if it is incompressible. As most strings are
k-incompressible for some small k, this shows that most strings are “essen-
tially” random. This corresponds to our intuition that ﬂipping a coin n times
yields a random sequence with high probability. Martin-L¨of randomness is
sometimes called algorithmic randomness.
The opposite of randomness is structure. The more compressible a string
is, the more structured.
3.9
Objectiveness
Kolmogorov complexity is often interpreted to quantify the maximum com-
pression or information content of individual strings.
For example, assume that a reference machine U has been ﬁxed which
gives complexity K(s) to some string s. Then K(s) can be interpreted as
the maximum compressibility of s, even though there is always some preﬁx-
machine Vs that assigns an arbitrarily short code word to s.
From the
perspective of U it can be argued that Vs then contains the information
s, and thus that K(s) is a better measure of complexity than the measure
KVs(s), which is “tailored” to s.
But what if Vs is also a universal preﬁx-machine?
Given any string
s, there exists a universal preﬁx-machine Us such that KUs(s) = 1.
Of
course, from the perspective of U, the reason is still that Us “contains” the
information s, and that Us is tailored to give s low complexity. But since Us
is a universal preﬁx-machine, there is no formal reason for why Us should
not have been chosen as reference machine instead of U. In which case U
would have seemed to give inexplicably high complexity to s.
One possible solution is to deem some universal preﬁx-machines “natu-
ral” and to require the reference machine to be chosen among those. For
example, it might be argued that a natural reference machine should assign
lower complexity to 00000000000000000 than to seemingly random strings
such as 100100101101110101. In this view, naturalness must be inherited
through simple simulation; that is, if U′ is natural and there is a short U′-
description of U′′, then U′′ should also be natural. Although imprecise, the
20

concept of naturalness provides some means for deciding the complexity of
particular strings.
Mueller [Mue06] tried to use the idea of simple simulation to ﬁnd an
objective reference machine. Unfortunately it turned out that simple simu-
lation did not yield an objective reference machine, and the attempt failed.
So an informal appeal to naturalness remains the only solution for deter-
mining the complexity of single strings.
In this thesis, the objectiveness provided by the invariance theorem (The-
orem 3.7) will suﬃce for all results. That is, any universal preﬁx-machine
U′ must agree with the chosen reference machine U on the complexity of
most strings, in the sense that
∃cU,U′ : ∀s, q : |K(s|q) −KU′(s|q)| ≤cU,U′
(7)
Much eﬀort has gone into the study of complexity of growing initial segments
of inﬁnite sequences, as it pertains to sequence prediction (Section 5.6 be-
low). Asymptotically, any two reference machines agree on the complexity
of such initial segments.
4
Computability
An important question is whether K is computable. In this section, a hier-
archy of computability concepts is presented and the position of K in the
hierarchy is determined.
4.1
Degrees of computability
If the domain and range of a function f have standard string-encodings (that
is, if the domain and are subsets B∗, N or Q) then f is recursive if there is
an algorithm computing it.
Some functions f are not recursive, but are still computable in some
sense. For example, a function f with the real numbers R as range can be
deﬁned as computable by means of a recursive approximation-function.
Deﬁnition 4.1 (Computable functions). A function f : B∗→R is com-
putable if there is a recursive approximation-function g : B∗× N →Q such
that for all s ∈B∗and all k ∈N, |g(s, k) −f(s)| ≤1/k.
The intuition is that f may be approximated arbitrary well by g. Note
that computability and recursiveness are equivalent if the range of f is N.
In general, a function g is a recursive approximation-function for f
if for all s, the function g(s, k) approaches f(s) when k goes to inﬁn-
ity. Approximation-functions with diﬀerent additional requirements are the
main tool for deﬁning computability-types weaker than recursiveness.
21

One such weaker type of computability of interest is semi-computability.
A semi-computable function also have a recursive approximation-function.
The diﬀerence is that there is no guarantee for how close the approximation is
for any given k. Instead, the approximation-function must be monotonically
increasing or decreasing.
Deﬁnition 4.2 (Semi-computable functions). A partial function f : B∗⇁R
is upper semi-computable if there is a decreasing, recursive approximation-
function g : B∗× N →Q for f. That is, g should be recursive and sat-
isfy: For all s ∈B∗, limk→∞g(s, k) = f(s) whenever f(s) is deﬁned, and
g(s, k) ≥g(s, k + 1). Further, f is lower semi-computable if −f is upper
semi-computable, and f is semi-computable if at least one of f and −f are
upper semi-computable.
Semi-computable functions with range N are not necessarily recursive,
but neither are they entirely incomputable. If a function f is upper semi-
computable it is possible to approximate it with a recursive function g(s, k)
that approaches f(s) from above, and is identical to f(s) in the limit. So
g(s, k) forms a lower bound for f(s) for all k, and the bound becomes better
with increasing k.
The problem is that there is generally no guarantee
for how tight the bound is. If g(s, k) has been evaluated to 87 for all k
smaller than, say, 100’000’000, then f(s) may in fact be 87, but can also be
arbitrarily much smaller.
Further weaker notions of computability are also available. For example,
if we remove the restriction of the approximation-function g being always
decreasing, we get the approximable functions. The approximable functions
include the semi-computable functions (both the upper and the lower vari-
ant), and also some non-semi-computable functions.
4.2
Semi-computability of K
The complexity function K(s|q)—here treated as a function of s for any
ﬁxed q—only takes on non-negative integer values. The following two theo-
rems show that K is upper semi-computable, but not computable.
Theorem 4.3 (Semi-computability of K). K is upper semi-computable.
Proof. The proof constructs a recursive, decreasing approximation-function
g(s, k) for K(s|q).
Let g(s, k) simulate all possible inputs of length at most 2ℓ(s) + c to U
for k steps (the constant c as in Proposition 3.8). When done, g outputs the
length of the shortest input that made U produce s in at most k steps. If
no input produced s in k steps (a common situation for small k), g outputs
2ℓ(s) + c This is an upper bound on the complexity by Proposition 3.8.
The function g(s, k) is recursive, since it simulates a preﬁx-machine on
a ﬁnite number of inputs, each for a ﬁnite number of steps. And g(s, k)
22

is clearly decreasing in k, since any output that produces s in at most k
steps will also produce s in at most k + 1 steps. Finally, g(s, k) →K(s|q)
when k →∞. To see why, assume that w is the shortest input on which
U(q, w) = s. Then U(q, w) halts in a ﬁnite number m of time steps, so for
all k ≥m it holds that g(s, k) = K(s|q). (Unfortunately, there is no general
procedure to determine the number m.)
Theorem 4.4 (Incomputability of K). K is not computable.
Proof. Fix some q ∈B∗. Throughout this proof, let s(n) denote the ﬁrst
string of length n (in the lexicographic order) that is incompressible with
respect to q. Recall that s incompressible with respect to q if K(s|q) ≥ℓ(s),
and that there are incompressible strings of all lengths by Proposition 3.9.
Assume that K(s|q) were computable; that is, that there were a program
computing K(s|q) on any input s. Building on this program, it would be
easy to construct a preﬁx-machine Vi such that Vi(q, n) = s(n) for all n.
This leads to a contradiction. For any n, the reference machine U(q, i, n)
would return s(n), so all s(n) would have complexity at most 2ℓ(i)+2ℓ(n)+2.
This would imply
n ≤K(s(n)|q) ≤2ℓ(i) + 2ℓ(n) + 2
(8)
≤2log2(i + 1) + 2log2(n + 1) + 2
(9)
for all n, which is a contradiction for suﬃciently large n (i remains ﬁxed).
In other words, an incompressible string would be compressible.
In conclusion, although the Kolmogorov complexity is not computable,
it can still be approximated in the semi-computability sense.
5
Measures and induction
Inductive reasoning is the process of making uncertain but justiﬁed infer-
ences; often the goal is to infer a general theory from particular observations.
For example, according to the famous anecdote, Newton discovered gravity
when seeing an apple fall from a tree. (Presumably, he also recalled a large
number of other (particular) examples of things falling or “attracting” each
other in space).
Inductive inference is a central tool in science.
One of the most im-
portant induction principles is Occam’s razor, which may be interpreted as
“given several possible explanations for an observed phenomenon, the sim-
plest explanation should be preferred”. The problem is that it is (i) often
unclear which explanation is simpler, and (ii) unclear to what extent a sim-
pler theory should be preferred to a more complicated theory if the more
complicated theory gives a more exact explanation.
23

Given the right setup, Kolmogorov complexity can be used as a for-
malization of the vague term simple. Kolmogorov complexity thus oﬀers a
formal solution to (i). Further, Kolmogorov complexity can be used to con-
struct a prior, which together with Bayes’ rule oﬀers a convincing solution to
(ii). Kolmogorov complexity can thus be used as a basis of a formal theory
of scientiﬁc induction [RH11].
First we will review some general measure theory and construct measure
spaces for B∗and B∞. For these spaces, two measures (priors) m and M are
constructed in accordance with Occam’s razor. We then give an account of
how M can be used for induction (sequence prediction) and recount a strong
result by Solomonoﬀ[Sol78] that shows the strong inductive performance of
M.
5.1
Deﬁnition of measure
Measure theory formalizes probability theory. Here we will only brieﬂy re-
count the most important deﬁnitions, for a more complete overview we refer
to any standard textbook on formal probability theory (for instance [Res98]).
Deﬁnition 5.1 (σ-algebra). A σ-algebra on a sample space Ωis a collection
Σ of subsets of of Ωsatisfying:
• Σ contains Ω.
• Σ is closed under countable union and complementation. That is, if
A ∈Σ, then Ac = Ω−A ∈Σ; and if {Ai}i∈I is a countable collection
of elements of Σ, then S
i∈I Ai ∈Σ.
The elements of Σ are called measurable sets or events.
Note that since Σ contains Ωand is closed under complementation, it
also includes the empty set ∅= Ωc. Σ must also be closed under countable
intersection, since T
i∈I Ai =
 S
i∈I Ac
i
c.
A measure space on a space Ωis a pair (Σ, Ω) where Σ is a σ-algebra on
Ω.
Deﬁnition 5.2 (Measure). Given a measure space (Σ, Ω), a function
λ : Σ →[0, 1] is a measure4 on (Σ, Ω) if it satisﬁes:
• λ(Ω) = 1,
• λ(S
i∈I Ai) = P
i∈I λ(Ai) for any countable collection {Ai}i∈I of pair-
wise disjoint elements of Σ.
4In the measure-theory literature, a more general version of measure that can take on
any non-negative real number and +∞is often considered. In such contexts, our version
of measure with λ(Ω) = 1 is often called a probability measure.
24

An important consequence is that λ(∅) = 0. This follows, since λ(Ω) =
λ(ΩS ∅) = λ(Ω) + λ(∅). By subtracting λ(Ω) from both sides, λ(∅) = 0 is
established.
When Ωis countable, the standard choice of σ-algebra is the power-set
2Ω= {A : A ⊆Ω} of Ω. However, when Ωis inﬁnite, it is often hard (or even
impossible) to obtain a measure on all subsets. Some sets are immeasurable
in the sense that no “natural” measure can assign a value to them.5
We will often use a slightly weaker version of measure, called semi-
measure.
Deﬁnition 5.3 (Semi-measure). A semi-measure on a measure space (Σ, Ω)
is a function λ : Σ →[0, 1] satisfying
• λ(Ω) ≤1,
• λ(S
i∈I Ai) ≥P
i∈I λ(Ai) for any collection {Ai}i∈I of pairwise disjoint
elements of Σ.
The diﬀerence between measures and semi-measures is that the full event
Ωonly needs to have measure at most 1, and that the union of disjoint
events may have a larger measure than the sum of the parts. Note that the
inequalities are set in a way so that semi-measures must assign the empty
set measure 0.
5.2
Measure spaces on B∗and B∞
We will now construct measure spaces on the set of strings B∗and the set
of one-way inﬁnite sequences B∞. These measure spaces will be the only
measure spaces we will use this section.
For the measure space B∗we will simply use the “maximal” σ-algebra
2B∗. So the measure space on B∗becomes (2B∗, B∗).
For the measure space on B∞, some further notation needs to be devel-
oped. Deﬁne for any string s the cylinder Γs = {sz : z ∈B∞}. The cylinders
are subsets of B∞, but do not form a σ-algebra. To obtain a σ-algebra on
B∞, let Ψ be the σ-closure of the set of all cylinders. That is, let Ψ be the
set of all A ⊆B∞that can be obtained from any collection of cylinders by
means of (repeated application of) countable union and complementation.
The σ-algebra Ψ is sometimes called the Borel σ-algebra.
The measure
space we will use for B∞is (Ψ, B∞).
For brevity, we will sometimes write B∗for (2B∗, B∗) and B∞for (Ψ, B∞),
keeping in mind which measure spaces are actually intended.
5Such immeasurable sets include the so-called Vitali sets, see for instance [Fri70].
25

5.3
Measure conventions
First adopt the abbreviations λ(s) = λ({s}) for the singleton events of
(P(B∗), B∗) and ν(s) = ν(Γs) for the cylinder sets of (Ψ, B∞). Further, all
semi-measures are extended with provided information q ∈B∗, in semblance
to conditional Kolmogorov complexity. Every semi-measure λ is thus ex-
tended to a class of measures λq. The provided information q is sometimes
useful when studying induction.
Deﬁnition 5.4 (Computable measure). We say that a (class of) measure(s)
λ on (2B∗, B∗) is computable if there is a computable function gλ that satisﬁes
gλ(s, q) = λq(s), and that λ is lower semi-computable if gλ is lower semi-
computable. Similarly, a measure ν on (Ψ, B∞) is (lower semi-)computable
if there is a (lower semi-)computable function gν such that gν(s, q) = νq(Γs)
for all strings s and q.
5.4
Measures on B∗
The uniform measure on (2B∗, B∗) is the discrete Lebesgue-measure µ, deﬁned
by µ(s) = 2−2ℓ(s)−1 on the singleton events {s} for all s ∈B∗. (The measure
µ simply ignores provided information q, so µ = µq for all q.) Deﬁning a
measure on the singleton events uniquely determines it on all other subsets
of B∗, by the axioms of a probability measure.
A universal semi-measure m for B∗can be deﬁned as follows.
Deﬁnition 5.5 (The discrete universal distribution). Let for every s, q ∈B∗
mq(s) = 2−K(s|q)
(10)
The semi-measure m is called the discrete universal distribution. It agrees
with Occam’s razor in assigning higher probability to strings with low com-
plexity.
That m is a semi-measure (sums to at most 1) follows from Kraft’s
inequality (Theorem 2.3 on page 12).
Kraft’s inequality gives that
P
w∈C 2−ℓ(w) ≤1 for any set C of code words in a preﬁx code.
As the
reference machine deﬁnes a preﬁx code, it follows that P
s∈B∗mq(s) ≤1 for
all strings q. As not all programs are a shortest code words for some string,
the summation will in fact be strictly less than 1. Therefore, m will only be
a semi-measure and not a measure.
5.4.1
Dominance of m
An important property of m is that it dominates all semi-computable semi-
measures on (2B∗, B∗).
26

Deﬁnition 5.6 (Dominance of measures). Let ρ and ν be two semi-measures
on some measure space (Σ, Ω). If there is a constant c > 0 such that ρ(A) ≥
c · ν(A) for all events A ∈Σ, then we say that ρ dominates ν with the
constant c. Similarly, ρ dominates a class M of measures on (Σ, Ω) if ρ
dominates each element of M.
The following discussion explains why m dominates all semi-measures.
There is an eﬀective enumeration λ1, λ2, . . . of all semi-computable semi-
measures on (2B∗, B∗) [LV08, p. 267]. Essentially, the index i in λi represents
a code for a program (semi-)computing λi
q(s). Fixing one such enumera-
tion/reference machine, it is natural to extend the deﬁnition of Kolmogorov
complexity to the lower semi-computable semi-measures on (2B∗, B∗) by
K(λ) = mini{K(i) : λ = λi}.
Semi-measures λi that are “simple” (have short descriptions) will receive
simple indexes i and therefore high weight, whereas complicated, arbitrary
semi-measures will receive complex indexes. Examples of fairly simple mea-
sures include µ and m since they have comparatively simple descriptions.
The dominance of m over all semi-computable measure follows from that
mq(s) =
X
i∈N
2−K(i)λi
q(s)
(11)
holds up to a multiplicative constant [LV08, Theorem 4.3.3]. This immedi-
ately gives that mq(s) ≥2−K(i)λi
q(s) for any semi-computable semi-measure
λi on (2B∗, B∗). We state this as a proposition for future reference.
Proposition 5.7 (Dominance of m). The discrete universal measure m
dominates every lower semi-computable semi-measure λ with a constant
2−K(λ).
Dominance is one reason for using semi-measures rather than measures.
It can be shown that no computable measure dominates all other computable
measures [LV08, Lemma 4.3.1]. Meanwhile, m is a lower semi-computable
semi-measure (since K is upper semi-computable) and m dominates all lower
semi-computable semi-measures.
5.5
Measures on B∞
The uniform distribution on B∞is the continuous Lebesgue-measure L(s) =
2−ℓ(s). The important diﬀerence between the discrete case and the continu-
ous case is that in the continuous case, the event of a short string s contains
all extensions of s. In the discrete case, any extension of s is a separate
event.
There is a continuous universal distribution M for (Ψ, B∞). In analogy
to the preﬁx-machines, there is a type of machine called monotone machines
which may be used to deﬁne M. Rather than deﬁning monotone machines,
27

however, we take a shortcut and deﬁne M via an enumeration ν1, ν2, . . . of
all semi-computable semi-measures [LV08, p. 295]. Let K(ν) = mini{K(i) :
ν = νi}.
Deﬁnition 5.8 (The continuous universal distribution). Let the continuous
universal distribution M be deﬁned as6
M(s) =
X
i∈N
2−K(i)νi(s)
(12)
The properties of M mirrors to a large extent the properties of m.
The semi-measure M trivially dominates all lower semi-computable semi-
measures ν on (Ψ, B∞) with a constant 2−K(ν).
Further, M is lower semi-computable: The value 2−K(i)νi(s) is lower
semi-computable for all lower semi-computable semi-measures ν.
There-
fore, a sum M(s) can be lower semi-computed by lower semi-computing an
increasing number of terms to increasing accuracy.
It can be shown that M assigns higher weight to simple initial segments
s; in fact, M(s) ≈m(s) so M(s) ≈2−K(s) for all strings s (both approx-
imations are up to logarithmic factors in the length of s). Thus M agrees
with Occam’s razor in assigning higher probability to “simple” events.
5.6
M and sequence prediction: Solomonoﬀinduction
Sequence prediction is a rather general induction setting. For example, it can
model a scientist making repeated experiments, or the development of the
weather. Formally, in the setting of sequence prediction an inﬁnite sequence
z has been generated according to some distribution ν on (Ψ, B∞). The task
is to (repeatedly) guess the next bit zn+1 for growing initial segments z1:n.
Assume, for instance, that we are trying to predict the weather based on
previous meteorological observations. Let rain be encoded as 0 and sunshine
as 1, and let the task be to predict the weather (sun or rain) the next day
given a string z1:n representing the weather of previous days.
The weather is presumably described by some computable distribution ν.
This means that the best prediction s of zn+1 (the weather tomorrow) would
be the prediction given by (the Bayesian ν-posterior) ν(zn+1 = s|z1:n1) =
ν(z1:ns)/ν(z1:n). Unfortunately, the true distribution ν of how the weather
develops is unknown. Solomonoﬀ’s idea was that ν could be replaced with
an inductive prior ρ that would converge to the true distribution ν, given
that ν came from some (preferably large) class of distributions.
To be able to quantify how well a certain prior ρ performs on sequence
prediction, we need a formal benchmark for how well ρ manages to predict
sequences generated from a true measure ν. One interesting benchmark is
based on the ν-expected prediction-distance.
6For technical reasons it is standard to include provided information to m but not to
M.
28

Deﬁnition 5.9 (Prediction-distance). Deﬁne the ν-expected prediction-
distance of prediction n between a semi-measure ρ and a measure ν as
Dn(ρ, ν) =
X
s∈B
X
z1:n∈Bn
ν(z1:n)
p
ρ(zn+1 =s|z1:n) −
p
ν(zn+1 =s|z1:n)
2
That
is,
the
ν-expected
value
of
the
distance
p
ρ(zn+1 =s|z1:n) −
p
ν(zn+1 =s|z1:n)
2
, summed over all next possible
bits s.
A few remarks can be made about this benchmark. First, the expectation
is taken with respect to the true measure ν. The eﬀect is that it is more
valuable to do well on likely sequences than unlikely sequences. Second, one
might question why the “complicated” prediction-distance is used rather
than a simple comparison of whether both predicted the same bit (1 or 0)
as the most likely next bit.
Such a comparison could indeed have been
interesting. However, we are often interested in the probability of an event
rather than only the most likely outcome. Say, for instance, that there is a
45% chance of rain tomorrow. Then we are interested in knowing that (so
we can take our umbrella in case), rather than only knowing that the chance
of sun is higher than the chance of rain. Such “decision-theoretic” aspects
are better captured by the prediction-distance.
Solomonoﬀdiscovered that dominance was an important feature for an
inductive prior. The following can be proven about prediction-distance for a
prior semi-measure ρ dominating another measure ν (see [LV08, Section 5.2]
for a proof7).
Theorem 5.10 (Solomonoﬀinduction). Let ρ be a semi-measure and ν be a
measure, and let ρ dominate ν with a constant c. Then the total ν-expected
prediction-distance between ρ and ν is ﬁnite and bounded by ln(1/c):
X
n∈N
Dn(ρ, ν) ≤ln(1/c)
(13)
Since M dominates all computable measures ν with a constant 2−K(ν)
by deﬁnition, we immediately obtain the following corollary.
Theorem 5.11 (Solomonoﬀinduction). For all computable measures ν, the
total ν-expected prediction-distance between M and ν is ﬁnite and bounded
by K(ν):
X
n∈N
Dn(M, ν) ≤K(ν) ln(2)
(14)
7More precisely, the theorem is a special case of what is proven in Example 5.2.5 on
page 356 in [LV08].
29

This shows that M is an excellent prior, given that the true distribution
is computable (which, arguably, is a quite reasonable assumption in most
practical cases). For an in-depth investigation of the philosophical aspects
of universal induction, see [RH11].
Since induction with M works for any (lower semi-)computable
(semi-)measure it is often called universal induction.
Other names in-
clude Solomonoﬀinduction, recognizing its inventor Ray Solomonoﬀ[Sol64a,
Sol64b, Sol78].
5.6.1
Induction with a uniform prior
It is instructive to compare the inductive performance of M and the uniform
measure L.
Under a uniform prior L, the next bit is 0 or 1 with equal probability,
given any initial sequence z1:n.
To illustrate why this is undesirable for
induction we will consider two examples, one where the sequence is random
(uniformly distributed) and one where the sequence is structured.
Consider ﬁrst the case where z is sampled from a deterministic envi-
ronment ν which give probability 1 to 101010 . . . and probability 0 to all
other sequences. Then M will quickly converge to ν, and correctly predict
the next bit with high probability. This follows from Theorem 5.11 since ν
is computable and has low complexity. The uniform prior L, on the other
hand, will after every initial segment predict that 0 is as likely as 1. M thus
clearly outperforms L in this case, as was expected.
But what if z was sampled from the uniform distribution L? Then the
prior L would correctly predict that both 0 and 1 were equally likely next
bits. But since L is a computable distribution (with low complexity), M
would quickly converge to predicting that 0 and 1 were equally likely as well.
These two examples give a sense of how a uniform prior is biased towards
randomness. No matter how long initial segment is highly structured, the
uniform prior insists that 0 and 1 are equally likely next bits. The universal
prior M, on the other hand, adapts. If the initial segment is structured, it
predicts that the structure is likely to remain. If no structure is present in
the initial segment, than the next bit is probably randomly sampled. In this
sense, a universal prior is less biased than a uniform prior.
5.7
Other induction settings
Not all induction problems can be (naturally) cast as sequence-prediction
tasks.
For example, in supervised machine learning (see for instance
[Mar09]), a ﬁnite number of predictions should be made based on a ﬁnite
number of learning examples. A related problem is the optimisation of a
function over a ﬁnite domain, which will be the focus in Part II. In these
ﬁnite cases, it is sometimes more natural to use the discrete universal mea-
30

sure m. (Philosophically it does not make much diﬀerence, as both measures
dominate their respective measure classes, and m and M diﬀer from each
other by at most a logarithmic factor in the string-argument).
Fewer results have been obtained in the ﬁnite settings. One of the major
aims of Part II will be to develop an understanding of the usefulness of m
in function optimisation over a ﬁnite domain.
5.8
AIXI and universal intelligence
Another setting is a generalization of sequence prediction to the active case.
In this setting, the goal is not only to predict the next symbol, but to interact
with an environment. That is, at every time step, the agent makes an action
(0 or 1), and the environment (the perceived input sequence) reacts to it.
Perhaps surprisingly, this makes the problem signiﬁcantly harder. A well-
developed theory called AIXI exists for this setting, see [Hut05].
AIXI arguably constitutes an optimal, universal intelligent agent (disre-
garding computational aspects) [Hut05]. Thanks to the semi-computability
of Solomonoﬀinduction, AIXI can be computably approximated. In a cer-
tain sense, the approximation performs as well as any other computable
agent with the same computation power, save for rather big multiplicative
constants [Hut05, Section 7.2.7].
6
Summary of Part I
In this part we have given an introduction to a formal, essentially objective
complexity measure K for strings, called Kolmogorov complexity. We used
K to construct two “universal” measures m and M with a bias towards
simplicity (in the Kolmogorov-complexity sense).
A result on M’s total
prediction-distance to any computable measure ν was formulated. A natural
interpretation of this result is that M is an excellent prior for sequence
prediction.
31

Part II
No Free Lunch and Optimisation
The problem of optimisation arises in many situations. For example, the
development of a medicine can naturally be understood as an optimisation
problem where the optimal combination of chemicals is sought. The Trav-
elling Salesman Problem can be seen as an optimisation problem where the
goal is to ﬁnd a maximally short route. In nature, one can understand evo-
lution as an optimisation process, striving to ﬁnd as good gene combinations
as possible.
Optimisation can be formalized as: An unknown function f : X →Y
is probed at particular points xi ∈X and the value f(xi) is perceived; the
aim being to quickly ﬁnd high/maximum values of f. As points of f are
probed, the knowledge of f grows, and better guesses can be made. Most
optimisation problems can (more or less naturally) be formalized this way.
In the medicine example, the function f could be the diﬀerence between the
fraction of patients cured minus the number of side eﬀects. For evolution,
f could be deﬁned as the amount of oﬀ-spring a certain gene-combination
yields (in a certain environment).
The aspect we will be interested in is what prior information one needs
about f in order to optimise f eﬃciently. Typically, informed guesses must
be made about f’s global behaviour from a set of particular examples (the
probed points). From this “information-theoretic” perspective, optimisation
includes an induction problem.
The No Free Lunch (NFL) theorems show that under some priors, ef-
ﬁcient optimisation is not possible. Intuitively, if all functions are equally
likely, then no meaningful extrapolation from any acquired knowledge is
possible; therefore all algorithms will perform equally badly [WM97]. When
a prior P makes all algorithms perform equally well, we say that NFL holds
for P. One of the main results so far has been a precise characterization of
priors for which NFL holds, known as the Non-uniform NFL theorem [IT04]
(see Section 8 and 9.3 for further discussion).
Note however that not all optimisation problems are interesting to study
from an information-theoretic perspective. In the Travelling Salesman Prob-
lem, for instance, the challenge is not lack of information—all distances are
known—but the computational complexity of the problem.
The universal distribution provides a universal prior, which in the case
of sequence prediction can be used whenever the true environment is com-
putable (see Section 5.6 above). This thesis will culminate in a characteriza-
tion of whether the universal distribution can be used also for optimisation
(Section 11 and 12), improving on the current knowledge in several direc-
tions.
Other contributions include a precise derivation of the probabilistic
32

framework underlying most NFL-studies (Section 7.5); a direct proof of
a generalization of the Non-uniform NFL theorem (Theorem 9.9); a con-
tinuity theorem for NFL (Theorem 9.11); and a discussion on particular
performance measures (Section 10).
We start by making the problem description precise (Section 7). We
then give an overview of the NFL research done so far, chieﬂy during the
last 15 years (Section 8). The most important results will be given detailed
accounts in Section 9.
Our main results then appear in sections 9.4–12,
together with an outlook and some concluding remarks in Section 13.
7
Preliminaries
In this section we make the setting formally precise, and introduce most of
the required notation.
7.1
Search problems
Let X and Y be two ﬁnite ordered spaces containing at least two elements
each. X will be known as the search space or the domain, and Y as the
range or the co-domain. Together they will be known as the problem con-
text. Lower case x and y, sometimes with sub- or superscripts, will denote
elements of X and Y respectively.
A (black-box optimisation) problem8 is a probability measure P over the
ﬁnite set Y X = {f : X →Y } of functions from X to Y . P(f) = P({f})
should be interpreted as the prior belief in f being the true function. For-
mally, P is a measure on the measure space (Σ, Ω) with Ω= {f : X →Y }
and Σ = 2{f:X→Y } the power-set of Ω. The measure P will sometimes also
be referred to as the prior.
As the function is probed at some point xi, its behaviour yi in the
probed point will become known.
Let {(xi, yi) : xi has been probed} be
the knowledge acquired of f. The associated event A = {f : f(xi) = yi)}
can be used to update the prior belief in f, P(f), to a posterior belief
P(f |A) = P(f, A)/P(A).
From P we can also derive the probability of events such as “f(x) = y”
for a certain point x. Let B = {f : f(x) = y}. Then P(f(x)=y) = P(B). It
is also straightforward to ask for the probability of “f(x) = y” given some
knowledge A. The letters A and B will denote function events. Often (but
not always), function events have an associated set of (x, y)-pairs as was the
case with the acquired knowledge above.
8Sometimes known as a Black-box Search problem, or Optimisation with Randomized
Heuristics [DJW02].
33

7.2
Algorithms
Only knowing the problem context X,Y and the prior P, a search algorithm
a should try diﬀerent values x ∈X, and, depending on the y-values returned,
try new points in X. Often the goal is to ﬁnd a certain type of value (such
as the maximum) as soon as possible, but formal investigations often allow a
wider range of performance measures (see Deﬁnition 9.1 below, and Section
10 for a discussion). Since the algorithm only has access to a distribution P
(and not to the true function), the goal for the algorithm will be to do well
in P-expectation.
7.2.1
Search traces
To deﬁne search algorithms formally, some further notation need to be de-
veloped. A search trace Tn is an ordered n-tuple ⟨(x1, y1), . . . , (xn, yn)⟩∈
(X × Y )n, representing a search history. T and S will be used as names for
traces. The empty trace will be denoted by ⟨⟩.
Let Tn be the set of all search traces of length n, and let T = S|X|
i=0 Ti
be the set of traces of any length. If Tn = ⟨(x1, y1), . . . , (xn, yn)⟩, let T x
n =
⟨x1, . . . , xn⟩be the corresponding probing sequence and T y
n = ⟨y1, . . . , yn⟩the
corresponding result vector. Analogously, let T x
n be the set of all probing
sequences of length n, and T y
n be the set of all result vectors of length n.
Finally, let T x and T y denote the set of probing sequences and result vectors
of any length.
Elements of T|X|, T x
|X| and T y
|X| will be called full-length traces, full-length
probing sequences and full-length result vectors respectively.
7.2.2
Deterministic search algorithms
A deterministic search algorithm a can now be modelled as a function
a : S ∈T 7→x ∈X −Sx
(15)
from search traces to new points to probe.
The no-revisiting condition
a(S) ̸∈Sx ensures that no search algorithm searches the same point twice,
a restriction commonly used in the literature (see [WM97] for a discussion).
Let A be the set of all deterministic algorithms.
A deterministic search procedure a encountering a function f thus gen-
erates traces
Tn(a, f) = ⟨(x1, y1), . . . , (xn, yn)⟩∈(X × Y )n
(16)
where each (xi+1, yi+1) = a⟨(x1, y1), . . . , (xi, yi)⟩. Let T.(x, y) be the trace
T appended with (x, y).
34

Example 3 (Trace-generation). Assume that the true function f is al-
ways 4 on the search space X = {0, 1, 2}, and assume that a always
searches X from left to right.
Then a will start searching at 0; that is,
a(⟨⟩) = 0.
The perceived value will be 4, so the search trace becomes
T1(a, f) = ⟨(0, 4)⟩. Continuing, a(⟨(0, 4)⟩) = 1. That is, a searches at 1
in the second step, and will again perceive value 4. This yields the search
trace T2(a, f) = ⟨(0, 4), (1, 4)⟩. And so on.
♦
7.2.3
Probabilistic algorithms
Many general search algorithms are not deterministic.
Instead the next
search point is (sometimes) chosen stochastically. It is, for example, common
to let hill-climbing algorithms restart at a random point once they reach a
local optima. A probabilistic algorithm b can be modeled by conditional
probability distributions Prb(·|T ) over next search points for all T ∈T . The
expression Prb(x|T ) denotes the probability that b continues the search at
x after the trace T. The no-revisiting condition for probabilistic algorithms
states that for any T and any x ∈T x, Prb(x|T ) = 0; in other words,
Prb(·|T ) should have no support outside X −T x.
Note that deterministic algorithms are special cases probabilistic algo-
rithms. A deterministic algorithm a is a probabilistic algorithm for which
the conditional distributions Pra(·|T ) have range {0, 1} for all traces T.
In fact, probabilistic algorithms may equally well be modeled by algo-
rithms that are only stochastic prior to the search phase. Such algorithms
that probabilistically chooses a deterministic algorithm b before the search
phase and then deterministically searches like b will be called pre-sampling
algorithms.
Lemma 7.1 (Pre-sampling algorithms). For every probabilistic algorithm b
there is an equivalent pre-sampling algorithm b′ in the sense that for every
T ∈T and x ∈X, it holds that Prb(x|T ) = Prb′(x|T ).
Proof. Let b be a probabilistic algorithm. For each T ∈T , independently
sample a search point x ∈X according to the conditional probability
Prb(x|T ). Denote the full sample with a deterministic function (algorithm)
a : T →X.
The probability for a given sample a is then Prb(a) = Q
T∈T Prb(x|T ).
Further, for any T
∈T
and any x ∈X, it holds that Prb(x|T ) =
P
a:a(T)=x Prb(a).
Let b′ sample deterministic algorithms according to Prb(a).
Then
Prb′(x|T ) = P
a:a(T)=x Prb(a) = Prb(x|T ), which completes the proof.
Let [[r1 = r2]] be the truth function that is 1 if r1 = r2 and 0 otherwise.
The following is an immediate corollary of Lemma 7.1.
35

Proposition 7.2. The probability that a probabilistic algorithm b generates
a trace T ∈Tn on a function f is
Prb(T |f ) =
X
a∈A
Prb(a)[[Tn(a, f) = T]]
(17)
Proposition 7.2 will be useful in constructing a measure on traces (Sec-
tion 7.5) and in generalizing results on deterministic algorithms to proba-
bilistic ones.
7.3
An example
We now give a longer example illustrating our setup. Readers who already
feel conﬁdent with the setup may safely skip this example.
Example 4. Assume that X = {−2.0, −1.9, . . . , 0, . . . , 1.9, 2}, and that the
class F of functions is the polynomials f(x) = c0 + c1x + c2x2 + · · · + c5x5 of
degree at most ﬁve with bounded integer coeﬃcients ci ∈{0, ±1, . . . , ±10}.
There are then 21 constant polynomials (degree 0), 212 polynomials of degree
1 and so on. Denote the number of polynomials with the same degree as a
polynomial f with #deg(f). Let the distribution be P(f) = 1/(6#deg(f)).
Then the summed probability of all polynomials of a certain degree is 1/6,
and since there are six diﬀerent degrees (0–5) the probability sums to 1.
The probability of a single “simple” (i.e., low-degree) polynomial is higher
than a “complex”, high-degree polynomial, however, since there are fewer
polynomials of low degrees. Let the range be determined implicitly by Y =
{y : ∃x ∈X, f ∈F : f(x) = y}.
The algorithm should now try values in X in order to ﬁnd a maximum of
the sampled function as quickly as possible. Assume that the true function
is f(x) = −x4+4x2−2x−1 (the algorithm does not receive this information,
of course; the algorithm only has access to the distribution P).
Assume the algorithm starts with trying 0 ∈X. Then it will receive
f(0) = −1 in return; the search trace becomes T1 = ⟨(0, −1)⟩. This pro-
vides a limited amount of information, so the algorithm may (arbitrar-
ily) try 1 at the next probe, which gives f(1) = 0.
The trace becomes
T2 = ⟨(0, −1), (1, 0)⟩. The polynomial with the highest sampling-probability
that is consistent with T2 is p1(x) = x −1. This indicates that 2 should be
the maximum. Trying that, however, it receives f(2) = −5 (which is incon-
sistent with the conjectured polynomial x −1). The algorithm thus needs
to revise its model, and make a new attempt. And so on.
Figure 2 illustrates the situation after the second probe.
Substantial eﬀort has been put into the problem of how to best optimise a
function in diﬀerent settings. In the setting of this example, Lagrange inter-
polation oﬀers a systematic approach. In other settings, Newton’s method,
Hill-climbing and Simulated Annealing are popular alternatives. The prob-
lem distribution P is not always known or explicitly speciﬁed, but it can be
36

−2
−1.5
−1
−0.5
0
0.5
1
1.5
2
−6
−4
−2
0
2
4
6
f(x) = −x4 + 4x2 −2x −1
p1(x) = x −1
T2 = ⟨(0, −1), (1, 0)⟩
Figure 2: The situation for the search algorithm in Example 4 after two
probes. The algorithm has searched at 0 and 1, which has generated the
search trace T2 = ⟨(0, −1), (1, 0)⟩. The algorithm (erroneously) conjectures
that p1(x) = x −1 might be the true function.
argued that even when the problem distribution is not speciﬁed, an implicit
distribution is used. For example, if one uses a hill-climbing algorithm it may
be argued that one is implicitly assuming that the function is somewhat con-
tinuous. This may be expressed as a prior problem-distribution with (much)
higher weight on continuous functions than on “scattered” ones.
As the true function is not known, the goal is typically to do well in
P-expectation (a precise deﬁnition of how to measure performance will be
given in Deﬁnition 9.1 below).
♦
7.4
Permutations, functions and enumerating algorithms
Many of the subsequent results will depend on permutations of diﬀerent
types of objects.
Deﬁnition 7.3 (Permutations). Deﬁne a permutation of size n as a bi-
jective function σ : {1, . . . , n} →{1, . . . , n}. Extend the domain of per-
mutations σ of size n to arbitrary ordered sets of size n, according to
σ(X) = {σ(x1), . . . , σ(xn)} = {xσ(1), . . . , xσ(n)} and to functions f : X →Y
by (σf)(x) = f(σ−1(x)) where X is some ordered set of size n. Subsequently
permutations will always be assumed to be of the size of the search space
|X|, and the set of all such permutations will be denoted by Π.
To illustrate some applications of Deﬁnition 7.3, deﬁne an enumerating
algorithm as an algorithm that searches X in a pre-deﬁned order without
heeding the returned y-values. Let e be the enumerating algorithm that
37

searches X in order, and for any permutation σ ∈Π let eσ be the enumer-
ating algorithm that searches X in the order σ(X). (Recall that X is an
ordered set by assumption.)
It is then easy to see that e generates the full-length result vector
⟨f(x1), . . . , f(x|X|)⟩exactly when f is the true function.
Analogously,
eσ generates the full-length result vector ⟨f(σ(x1)), . . . , f(σ(x|X|))⟩
=
⟨(σ−1f)(x1), . . . , (σ−1f)(x|X|)⟩exactly when f is the true function. It fol-
lows that the full-length result vector of eσ is ⟨f(x1), . . . , f(x|X|)⟩exactly
when σf is the true function.9
Functions are naturally identiﬁed with sets of ordered pairs, by f =
{(x1, f(x1), . . . , (x|X|, f(x|X|)))}. Using the order on X, we will sometimes
also identify functions with tuples f = (f(x1), . . . , f(x|X|)).
The latter representation coincides with the representation of full -length
result vectors (result vectors of length |X|). Incidentally, this allows us to
express our observation about enumerating algorithms rather concisely. The
observations can be expressed as T y
|X|(e, f) = f and T y
|X|(eσ, σf) = f. We
state this as a lemma for future reference.
Lemma 7.4 (Result vectors of enumerating algorithms). The result trace for
the enumerating algorithm e on any function f is the associated tuple for the
function itself, that is T y
|X|(e, f) = f. Further, if σ ∈Π then T y
|X|(eσ, σf) =
f.
On a related note, we also introduce the concept of an informed choice.
Deﬁnition 7.5 (Informed choice). A choice of a next search point is in-
formed if it depends on the perceived y-values, and it is blind if it only
depends on the probing sequence.
An algorithm that only makes blind
choices is called a blind algorithm. Formally, a is blind if for all traces S
and T with T x = Sx, and all x ̸∈T x it holds that Pra(x|T ) = Pra(x|S).
Enumerating algorithms are blind deterministic algorithms.
For this
reason, they are sometimes also known as oblivious algorithms [GO05].
An example of a stochastic blind algorithm is the random algorithm.
It can be deﬁned as the probabilistic algorithm rand, with Prrand(x|T ) =
1/(|X| −|T x|) for any trace T and any x ̸∈T x (and 0 for x ∈T x).
7.5
A measure on traces
In this section the goal will be to derive a measure Pa over the set of full-
length traces T|X|, where Pa(T) will be the probability that a generates T.
Formally, Pa will be a measure on the measure space (2T|X|, T|X|). We will
sometimes refer to Pa as the trace-measure induced by P and a.
9The concept of “permuting” the enumerating algorithm e can be generalized to arbi-
trary algorithms. This leads to a generalized result on how permutations interact when
applied to functions and algorithms respectively [SVW01].
38

Given a function f, a trace T = σ⟨(x1, y1), . . . , (x|X|, y|X|)⟩is possible if
and only if f(xi) = yi for all 1 ≤i ≤|X|. Therefore the measure Pa must be
a reﬁnement of P in the sense that P
σ∈Π Pa(σ⟨(x1, y1), . . . , (x|X|, y|X|)⟩) =
P(f). From the perspective of Pa, the event of a function f will be identiﬁed
with the set of all traces consistent with f.
In a similar manner, the event of a trace Tk of length k < |X| will be
identiﬁed with the set of all full-length extensions of Tk. Introducing the
notation T[i:j] = ⟨ti, . . . , tj⟩and T[i] = ti for extracting components of a
vector T = ⟨t1, . . . , tn⟩, the event of Tk is formally identiﬁed with the set
{T ∈T|X| : T[1:k] = Tk}.
By combing the measure Pra(T |f ) from Proposition 7.2 with P we arrive
at a measure Pa over T|X|,
Pa(T) =
X
f∈F
P(f)Pra(T |f )
(18)
=
X
f∈F
P(f)
X
a∈A
Prb(a)[[Tn(a, f) = T]]
(19)
This deﬁnes the measure Pa for all points (singleton events) T ∈T|X|, which
uniquely determines Pa for all subsets (events) of T|X| by Carath´eodory’s
extension theorem.
Pa is obviously non-negative and additivity follows from the additivity
of Pra. The following veriﬁes that Pa sums to 1.
Pa(T|X|) =
X
S∈T|X|
Pa(S)
(20)
=
X
S∈T|X|
X
f∈F
P(f)Pra(S |f )
(21)
=
X
f∈F
P(f)
X
S∈T|X|
Pra(S |f )
(22)
=
X
f∈F
P(f) = 1
(23)
So Pa is a proper measure (Deﬁnition 5.2 on page 24).
7.5.1
Types of events
To be able to speak about events such as “a searches at x in its kth probe”,
we deﬁne random variables xk and yk for the kth search point and the kth
perceived function value. Formally, for every 1 ≤k ≤|X|, they can be
deﬁned as
xk : T ∈T|X| 7→T x[k]
(24)
yk : T ∈T|X| 7→T y[k]
(25)
39

For example, Pa(y1 =2|x1 =10) denotes the probability that a ﬁnds the
value 2 at its ﬁrst probe, given that a’s ﬁrst probe is at 10.
Note that
Pa(xn+1 =x|⟨x1y1 . . . xnyn⟩=T ) = Pra(x|T ).
The random variables xk and yk enable us to describe any property of
the search trace. Although possible, they will not be used to describe all
types of events. In particular, a trace Tk will still denote the event of all
full-length extensions of Tk; a result vector R (of any length) will denote the
event of all traces consistent with R; and, ﬁnally, the event of a function f is
the event of all traces consistent with f. As all these objects have diﬀerent
formal representations (traces are ordered lists of X,Y -pairs, result vectors
ordered lists of y-values, and functions sets of pairs), there should be no risk
of confusion. For example, Pa(R|f ) = Pra(R|f ) is the probability that a
generates the result vector R on f.
8
Literature review
We now give an overview of the research done on NFL and optimisation,
before we go into a more detailed treatment in subsequent sections.
8.1
NFL Theorems
Wolpert and Macready [WM95, WM97] are generally credited for the ﬁrst
formal proof of the No Free Lunch (NFL) theorem for black-box optimi-
sation, proving that when uniformly averaged over all functions, no search
algorithm will be any better or worse than any other.10 Schumacher et al.
[SVW01] made an important generalization to more general classes of func-
tions. This also sharpened the theorem. They observed that NFL holds
for a uniform prior over a class F of functions if and only if F is closed
under permutation (c.u.p.). This theorem is often known as the sharpened
NFL theorem. A more detailed account of Wolpert and Macready’s and
Schumacher et al.’s theorems are given in Section 9.2.
Igel and Toussaint [IT04] generalized the sharpened NFL theorem to non-
uniform averages, showing that the precise condition for NFL is that every
permutation σf of a function f have the same probability/weight as f—a
so-called block-distribution is required (see Section 9.3).
Streeter [Str03]
reformulated the result in a Bayesian setting, showing that the conditions
for NFL can equivalently be phrased in terms of (zero) information gain for
a Bayesian learner.
8.2
Classes of functions
There are many classes of functions for which NFL does not hold, an imme-
diate consequence of the fact that most function classes that are not c.u.p.
10See also [Sch94, RS95, WB69].
40

(the fraction of c.u.p. function classes vanishes quickly with growing X and
Y [IT04]). In particular, there are free lunches for the subsets of functions
deﬁned by the conditions:
1. A global minimum is not adjacent to a global maximum [IT04],
2. The number of local minima is bounded [IT01, IT04]
3. The maximum steepness is bounded [IT01, IT03b],
4. The Kolmogorov complexity is lower than k, [Str03, McG06].
In all cases, the reason is that the sets are not c.u.p. However, at least
in the case of subsets formed by a bound on the Kolmogorov complexity,
there may still be further subsets for which NFL holds, as demonstrated by
[SVW01].
Streeter [Str03] also found that if the average is taken with respect to the
universal distribution, free lunch exists. In Section 11.3 we prove a related
theorem. In the related area of supervised learning, Lattimore and Hutter
[LH11] showed that there is free lunch under the universal distribution.
Griﬃths and Orponen [GO05] studied the more speciﬁc case of binary
functions with a particular maximization performance measure. Unsurpris-
ingly, using a particular performance measure yields less free lunch. In their
setting, NFL sometimes hold for function classes not c.u.p.
8.3
Single functions, searchability
It is also possible to ask on which functions an algorithm will be able to
outperform a random search. The pioneering work on this interesting ﬁeld
was done by Christensen and Oppacher [CO01], who conjectured that a
function would be searchable if it was ”self-similar”, i.e., points close in the
search space should have close target values (compare Item 3 in the list
above). They developed a simple measure of self-similarity by counting the
number of jumps over the median, and showed that a ”submedian-seeker”
algorithm outperformed random search on functions with few median-jumps.
This work was later extended in [WR06], and, in turn, by Jiang and Chen
[JC11]. The latter study developed a general model of Lipschitz-continuity
for any structured search space. They also gave an algorithm outperforming
random search on many Lipschitz-continuous functions, and being equally
good on some very hard Lipschitz-functions. Hard Lipschitz-functions in-
clude the so-called needle-in-a-haystack (NIAH) functions, deﬁned and dis-
cussed in Section 12.2.
Lipschitz-continuity and self-similarity may be criticized as searchability
criteria, however, since on the one hand they include provably hard of func-
tions such as NIAH functions (proven hard in [DJW04]), and on the other
41

they exclude intuitively searchable functions11 such as
f(x) =
(
x
if x even
0
otherwise.
So Lipschitz-continuity is neither a suﬃcient nor necessary condition for
searchability. (It may still be the correct criteria for many practical opti-
misers such as Genetic Algorithms (GA) and Simulated Annealing (SA),
however, as argued by Christensen and Oppacher in [CO01].)
As predictability (of the maximum, at least) seems to be a key aspect,
it is natural to turn to Kolmogorov complexity K and the universal distri-
bution. Borenstein and Poli [BP06] informally investigate the possibility to
use the universal distribution in optimisation. They argue that since it is
possible to ”hide” a maximum as a hard-coded point in the program with
small (O(log2|X|)) penalty in complexity, there are many functions with
low KC that still are hard to search. As examples, they mention NIAH-
functions and trap-functions (a trap-function is a compressible function with
one hard-coded exception). However, their argument is informal (and they
seem to neglect the fact that it is easier to encode exceptions in compressible
points rather than in incompressible ones, which, for example, makes some
NIAH/trap-functions much simpler than others). In Section 11.2 we deﬁne
compressibility of functions and points, and in Section 12.3 we give a formal
argument for why NIAH-functions make it hard to search under m.
Having discarded KC as unsuitable for a searchability criterion, Boren-
stein and Poli instead propose the following deﬁnition of KC-continuity as
an alternative.
Deﬁnition 8.1. A function f is KC-continuous in a point x if
f(x) = arg min
y
K
 
g(x′) =
(
y
if x′ = x
f(x′)
otherwise.
!
The intention is to disallow the hiding of the maximum in one random
point, and thus better capture the notion of searchability. It is unclear, how-
ever, to what extent the criteria works (beyond discarding NIAH-functions
and trap-functions). They claim that a simple function can only be hard
to search for a KC-based searcher if the function is KC-discontinuous at its
maxima, but no proof is provided.
8.4
Almost No Free Lunch
Even though free lunches are proven for a large number of (classes of) func-
tions, as discussed above, there are also negative results on the amount
11To the Lipschitz-criterion’s defence, a NIAH function can only be Lipschitz if the
needle is very low. So when it is suﬃcient to ﬁnd a value close to the maximum, the
Lipschitz functions may still be intuitively searchable.
42

of free lunch available. Such results are sometimes called Almost No Free
Lunch (ANFL) theorems. The most important one is found in [DJW02],
and shows that given an algorithm a that does well on a function f, there
are many only slightly more complex functions on which a does extremely
badly (this, of course, precedes and pertains to the above arguments by
Borenstein and Poli). As a concrete example, they discuss the ONEMAX
problem (in which the search space is all binary strings of length n, and
f(x) =”number of 1’s in x”) and a slight modiﬁcation of it called TRAP
where f(0n) = n + 1. They show that both Genetic Algorithms (GA) and
Simulated Annealing (SA) will perform poorly on TRAP, despite its fairly
simple description. Further, and without good argument, they conjecture
that for every ”reasonable” (not formally deﬁned) search-algorithm, there is
some ”simple” problem on which it does badly. The claim is weak, as neither
GA nor SA are universally biased towards simple/structured problems.
Whitley and Rowe [WR08] develop an ANFL theorem for classes, proving
that if a class F is not c.u.p. (and thus have free lunch) there is a ”small”
extension of F on which NFL holds.
This has some interest, since the
“permutation closure” of F may be signiﬁcantly larger than F. Even so, it
says little about the actual amount of free lunch on F, which normally is
the quantity of interest.
Our results in Section 12 below can be interpreted as ANFL-theorems
for the universal distribution.
8.5
Other investigations
A ubiquitous assumption so far has been the ﬁniteness of the search space
X and the range Y . Auger and Teytaud [AT07] generalize the NFL problem
to continuous (inﬁnite) search spaces and conclude that free lunches exist
for such domains. Diﬀerent generalizations to the inﬁnite case are possible,
however, and not all provide free lunch [RVW09].
A ﬁnite search space
together with an inﬁnite co-domain Y yields no free lunch [Str03].
One may also question the no-revisiting condition; for large search spaces
it may be infeasible to keep all visited points in memory. Some consequences
of forgetfulness is explored in [MH09] and in a study on multi-objective
optimisation [CK03].
9
No free lunch
This section will give a detailed account of the “classical” NFL theorems by
Wolpert and Macready [WM97], Schumacher et al. [SVW01] and Igel and
Toussaint [IT04] (Theorem 9.5, 9.7 and 9.9 below). The classical NFL theo-
rems are all similar in spirit, they only diﬀer in generality. They essentially
show that under certain conditions no search algorithm can outperform an-
other. For example, this implies that a hill-climbing algorithm will ﬁnd the
43

maximum equally slowly as a hill-descending algorithm! The NFL theorems
thus renders any attempt at intelligent search moot (in the settings they
apply to).
By the end of this section, we investigate how the possible diﬀerence in
search performance—the amount of free lunch, so to speak—is aﬀected by
small deviations from the conditions required for NFL.
9.1
Two equivalent NFL-deﬁnitions
Deﬁnition 9.1 (Performance measure). A performance measure is a func-
tion M : T y →R+ S{0} that measures how diﬀerent result vectors are
valued. Generally, the expected performance of an algorithm a on a problem
P is the interesting quantity; we therefore extend the performance measure
to algorithms a and search lengths n the following way.
MP(a, n) =
X
R∈T y
n
Pa(R)M(R)
(26)
=
X
R∈T y
n
f:X→Y
P(f) · Pra(R|f )M(R)
(27)
For deterministic algorithms, this reduces to
MP(a, n) =
X
f∈F
P(f)M(T y
n(a, f))
(28)
When the search length n is clear from the context, it may be omitted. In
the beginning of Section 10, a full-length performance measure is deﬁned as
a performance measure only deﬁned on full-length result vectors.
For some search problems P it can be shown that all algorithms perform
equally well with respect to some (or all) performance measure(s). This is
often phrased as “there is no free lunch available for P”; hence the term No
Free Lunch (NFL).
Deﬁnition 9.2 (Performance measure-NFL). NFL holds for a search prob-
lem P and a performance measure M if MP(a, n) = MP(b, n) for every pair
of search procedures a and b, and every search length n. If NFL holds for
all performance measures M, then NFL simply holds for the problem P. If
NFL does not hold for a problem P (and performance measure M) we say
that there is free lunch for P (under M).
The stronger version of NFL that holds for all performance measures
may equivalently be deﬁned in terms of result vectors. The equivalence will
be veriﬁed shortly in Lemma 9.4.
44

Deﬁnition 9.3 (Result vector-NFL). NFL holds for a search problem P in
the result-vector sense if every result vector is equally likely to be generated
by all algorithms; that is, Pa(R) = Pb(R) for every pair of search algorithms
a and b and every result vector R ∈T y.12
Despite being slightly less intuitive, the result-vector deﬁnition is often
more convenient to use. Both because theorems about result vectors tend to
be more useful as auxiliary results, and because theorems about result vec-
tors often are (slightly) more direct to prove. The following lemma veriﬁes
the equivalence of the two deﬁnitions.
Lemma 9.4 (Equivalence of NFL deﬁnitions [Str03]). For a given search
problem P, it holds that Pa(R) = Pb(R) for all search procedures a and b
and all result vectors R ∈T y if and only if MP(a, n) = MP(b, n) for all
performance measures M, all procedures a, b and all search lengths n.
Proof. Assume that NFL does not hold in the result-vector sense. Then
there are two procedures a and b and a result vector Rn of length n such
that Pa(Rn) ̸= Pb(Rn). Deﬁne the (degenerate) performance measure M
that is 1 only on the result vector Rn, and 0 otherwise. This means that
MP(a, n) =
X
R∈T y
n
Pa(R)M(R) = Pa(Rn)M(Rn) = Pa(Rn)
The same applies to b, so MP(b, n) = Pb(Rn). By assumption, Pa(Rn) ̸=
Pb(Rn), so a and b perform diﬀerently with respect to M.
Assume conversely that NFL does hold in the result-vector sense. Then
Pa(R) = Pb(R) for all R ∈T y and all procedures a and b, which means that
for any performance measure M and search length n,
MP(a, n) =
X
R∈T y
n
Pa(R)M(R) =
X
R∈T y
n
Pb(R)M(R) = MP(b, n)
So NFL holds for all performance measures M.
Since NFL holds in the result-vector sense if and only if it holds in the
performance-measure sense, we will generally not distinguish between the
two subsequently.
9.2
Uniform distributions
Wolpert and Macready [WM97] famously proved that if the sampling of a
function f : X →Y is uniform, than NFL holds. Formally, let
uF (f) =
(
1/|F|
for f ∈F
0
otherwise
12Observe that T y includes result vectors of all lengths.
45

be the uniform distribution over a class of function F. The formal statement
of Wolpert and Macready’s result is:
Theorem 9.5 (NFL for uniform distribution [WM97]). NFL holds for the
problem uF , when F = Y X.
The theorem is a special case of the more general Theorem 9.7 and
Theorem 9.9 below. See Appendix A for a proof.
Schumacher et al. [SVW01] extended Wolpert and Macready’s theorem
to more general classes of functions. Their result, sometimes known as the
Sharpened NFL Theorem, has become pivotal to much of the subsequent
NFL research. It depends on the notion of a function class closed under
permutation (c.u.p.).
Deﬁnition 9.6 (Closed under permutation). A class F of functions is c.u.p.
if f ∈F =⇒σf ∈F for all permutations σ.
Theorem 9.7 (NFL for c.u.p. classes [SVW01]). NFL holds for a search
problem uF if and only if F is c.u.p.
The theorem is a special case of of Theorem 9.9 below. We defer the
proof until Appendix A.
9.3
Non-uniform distributions
The c.u.p. NFL theorem (Theorem 9.7) gives a precise condition for NFL
for uniform distributions. In this section we present an important result by
Igel and Toussaint [IT04] that generalizes this to arbitrary distributions.
To generalize the c.u.p. property, histograms can be used to describe base
classes, the smallest building blocks for c.u.p. function classes. A histogram
for a function f is a function hf : Y →N indicating how many x’s map
to every y (that is, hf(y) = |f−1(y)|). The set of all functions with the
histogram h is called the base class of h, and is denoted by Bh. Base classes
are the smallest c.u.p. function classes in the sense that all base class are
c.u.p., and any c.u.p. class is the union of some base classes [IT01]. Base
classes entail the following useful generalizations of the c.u.p. property.
Deﬁnition 9.8 (Block uniformity). A problem distribution P is block uni-
form if every pair of functions f, g ∈Y X in the same base class are equally
likely; that is, if f, g ∈Bh =⇒P(f) = P(g). More generally, for ε ≥0 the
distribution P is ε-block uniform if f, g ∈Bh =⇒|P(f) −P(g)| ≤ε.
Using block uniformity, Igel and Toussaint generalized the NFL Theorem
9.7 to non-uniform problems P. Our proof diﬀers from the original proof
in [IT04] by showing the result directly, rather than using Theorem 9.7 as
a middle step. Our result is also more general as it applies to probabilis-
tic algorithms; Igel and Toussaint’s theorem only considered deterministic
algorithms.
46

Theorem 9.9 (Non-uniform NFL [IT04]). NFL holds for a problem P if
and only if P is block uniform.
Proof. (IF) Suppose P is block uniform. Let X = {x1, . . . , x|X|} and let
F be the set of all functions f : X →Y . Deﬁne a base-class-respecting
(function-)mapping to be a mapping ψ : F →F such that ψf is always in
the same base class as f. By the block uniformity of P, for any base-class
respecting mapping ψ holds that P(ψf) = P(f).
It turns out that deterministic algorithms a naturally induces base-class-
respecting mappings by their result vectors. For example, if f = (4, 4, 5) and
a searches X = {x1, x2, x3} in the order x2, x3, x1, then this naturally maps
f to (4, 5, 4) (by the result vector T y
|X|(a, f) = ⟨4, 5, 4⟩).
Formally, deﬁne for every deterministic algorithm a the mapping ψa by
ψaf = T y
|X|(a, f)
(29)
using the identiﬁcation of functions with tuples described in Section 7.4.
That is, ψaf maps every xi to the ith component of the full-length result
vector a creates on f. Since the result vector contains every function value
once, the histogram is preserved, so ψa respects base-classes.
Further, and more surprisingly, ψa is bijective. We will show this by
showing that ψa is surjective; this suﬃces since F is ﬁnite.
Pick an f in F. The following constructs a function g such that ψag = f.
Let
g(a(⟨⟩)) = f(x1)
(30)
In words, g takes value f(x1) on the point a starts searching. The algorithm
a thus obtains the trace T1(a, g) = ⟨(a(⟨⟩), f(1))⟩on g. At the second point
a searches when encountering f(x1) in its ﬁrst probe, g takes on the value
f(x2):
g(a(T1(a, g))) = f(x2)
(31)
And so on. In general, we let
g(a(Tn(a, g))) = f(xn+1)
(32)
for n
<
|X|.
Then a generates the result vector T y
|X|(a, g)
=
⟨f(x1), f(x2), . . . , f(x|X|)⟩on g. Therefore, (ψag)(xi) = T y
|X|(a, g)[i] = f(xi)
for all i, so ψag = f. Hence ψa is surjective, and thereby also bijective.
We will now use the mapping ψa to show that a generates every result
vector R with the same probability as the enumerating algorithm e. Recall
that the enumerating algorithm e searches X in order, and thus creates the
result vector ⟨f(x1), . . . , f(x|X|)⟩exactly when f is the true function (Section
47

7.4; Lemma 7.4). Importantly, this means that T y
n(a, g) = T y
n(e, ψag) for any
n.
Now, for any n and any result vector R of length n,
Pa(R) =
X
g∈F
P(g)[[T y
n(a, g) = R]]
(33)
=
X
g∈F
P(g)[[T y
n(e, ψag) = R]]
(34)
by the just motivated equality. Since ψa respects base-classes and is bijec-
tive, (34) equals
=
X
ψag∈F
P(ψag)[[T y
n(e, ψag) = R]]
(35)
= Pe(R)
(36)
This shows that any deterministic algorithm a generates an arbitrary result
vector R with the same probability as the enumerating algorithm e. By
transitivity, this shows that all deterministic algorithms generate the same
result vectors with the same probability.
To generalize the result to probabilistic algorithms, let cR be the proba-
bility that a deterministic algorithm generates result vector R and let b be
a probabilistic algorithm. By deﬁnition,
Pb(R) =
X
a∈A
Prb(a)Pa(R)
(37)
= cR
X
a∈A
Prb(a) = cR
(38)
That is, probabilistic algorithms also generate result vector R with proba-
bility cR. This shows that NFL holds for any block uniform problem P.
(ONLY IF) Assume that P is not block uniform. Then there are two
functions f and σf in the same base class Bh such that P(f) > P(σf).
Recall the enumerating algorithms e and eσ from Section 7.4. By Lemma
7.4 we had that e generates the result vector Rf = ⟨f(1), . . . , f(|X|)⟩exactly
when f is the true function, and that eσ generates Rf exactly when σf is the
true function. An immediate consequence is that Pe(Rf) = P(f) > P(σf) =
Peσ(Rf). That is, e and eσ generate Rf with diﬀerent probability, which
means that NFL does not hold (Lemma 9.4).
9.4
Continuity of NFL
An interesting generalization of Theorem 9.9 is what happens when the
distribution P is almost block uniform, naturally formalized by ε-block uni-
formity (Deﬁnition 9.8). As we shall see, the amount of free lunch grows at
most linearly with increasing ε-perturbations of the block uniformity.
48

First a lemma is required.
Lemma 9.10 (Equal number of functions). For any base class Bh, any
result vector R ∈T y and any two deterministic algorithms a and b holds
that
|{f ∈Bh : T y
n(a, f) = R}| = |{f ∈Bh : T y
n(b, f) = R}|
(39)
That is, a and b produce the result vector R on equally many functions in
Bh.
Proof. Assume the problem P = uBh is uniform over Bh and 0 otherwise.
Then Pa(R) = Pb(R) for all algorithms a and b and all result vectors R. Let
R be a result vector of length n. Then
Pa(R) =
X
f:X→Y
P(f)[[T y
n(a, f) = R]]
= |{f ∈Bh : T y
n(a, f) = R}| · 1/|Bh|
for all algorithms a. Therefore all algorithms must produce the same result
vector R on equally many functions.
Theorem 9.11 (Continuity of NFL). If the problem P is ε-block uniform
for some (small) ε ≥0, then the amount of free lunch is bounded by
|MP(a, n) −MP(b, n)| ≤ε
X
f∈F
M(T y
n(a, f))
for any performance measure M, any pair of algorithms a, b and any search
length n. In particular, the amount of free lunch goes to 0 as ε goes to 0.
Proof. Since P is ε-block uniform, there is a number ph for every Bh such
that f ∈Bh
=⇒
P(f) ∈[ph −ε/2, ph + ε/2]. Let Ha,R,F = {f ∈F :
T y
n(a, f) = R} be the set of functions in F on which a deterministic algorithm
a generates the result vector R. (Note that it was the size of certain sets
Ha,R,F that was investigated in Lemma 9.10.)
Let a and b be two deterministic algorithms. Then,
MP(a, n) −MP(b, n) =
(40)
=
X
f∈F
P(f)M(T y
n(a, f)) −
X
g∈F
P(g)M(T y
n(b, g))
(41)
=
X
Bh
X
R∈T y
n

X
f∈Ha,R,Bh
P(f)M(T y
n(a, f)) −
X
g∈Hb,R,Bh
P(g)M(T y
n(b, g))

(42)
49

by ﬁrst expanding deﬁnitions, then splitting the sum over base classes and
result vectors. Since T y
n(a, f) = R for all f ∈Ha,R,Bh, (42) equals
=
X
Bh
X
R∈T y
n

X
f∈F
P(f)M(R) −
X
g∈F
P(g)M(R)


(43)
=
X
Bh
X
R∈T y
n
M(R)

X
f∈Ha,R,Bh
P(f) −
X
g∈Hb,R,Bh
P(g)

(44)
which means that we can extract M(R) (44).
We now use the ε-block
uniformness to bound (44) by
≤
X
Bh
X
R∈T y
n
M(R)

X
f∈Ha,R,Bh
(ph + ε/2) −
X
g∈Hb,R,Bh
(ph −ε/2)

(45)
By Lemma 9.10, a and b produce the result vector R on equally many
functions in a base class Bh, which implies that (45) equals
=
X
Bh
X
R∈T y
n
M(R)|Ha,R,Bh|
 ph + ε/2 −(ph −ε/2)

(46)
The ε may now be moved out and the summation rewritten
= ε
X
Bh
X
R∈T y
n
|Ha,R,Bh|M(R) = ε
X
Bh
X
R∈T y
n
X
f∈Bh:T y
n(a,f)=R
M(R)
(47)
= ε
X
Bh
X
f∈Bh
M(T y
n(a, f)) = ε
X
f∈F
M(T y
n(a, f))
(48)
This shows the theorem for deterministic algorithms a and b. Thanks to
Proposition 7.2, we easily obtain a generalization to probabilistic algorithms.
Fix a search length n. Then there are two real numbers r1, r2 such that
for all deterministic algorithm b
r1 ≤MP(b, n) ≤r2
(49)
with r2 −r1 ≤ε P
f∈F M(T y
n(a, f)) for an arbitrary a, by equations (40)–
(48).
Let a′ be a probabilistic algorithm. Then
MP(a′, n) =
X
b∈A
Pra′(b)M(T y
n(b, n)) ≤r2
X
b∈A
Pra′(b) = r2
(50)
By a similar argument, r1 ≤MP(a′, n), so r1 ≤MP(a′, n) ≤r2. The same
holds, of course, for any other probabilistic algorithm b′. Therefore,
|MP(a′, n) −MP(b′, n)| ≤r2 −r1 ≤ε
X
f∈F
M(T y
n(a′, f))
(51)
holds also for probabilistic algorithms.
50

Theorem 9.11 can be interpreted as a continuity result. The amount
of free lunch is continuous in the “block-uniform points” in the space of
problem-distributions (with distance d(P1, P2) = maxf:X→Y |P1(f) −P2(f)|
between two problem distributions P1 and P2).
Although the growth of potential free lunch is bounded by a linear func-
tion in ε, the growth in ε is typically rather fast. For example, if the search
space is of size |X| = 100′000 and the average performance measure is about
1, then the bound is ε100′000 for ε-block uniform problems.
Perhaps a
smaller bound could be proven? This question will be addressed shortly in
Section 9.4.1.
Corollary 9.12. Under the extra condition that there is an k ∈R such that
M(R) ≤k for all performance measures M and all result vectors R, then
|MP(a, n) −MP(b, n)| ≤εk|F| ≤εk|Y ||X| for all performance measures M,
where |F| is the number of functions with probability > 0.
Proof. This is an immediate corollary of Theorem 9.11:
|MP(a, n) −
MP(b, n)| ≤ε P
f∈F M(T y
n(a, f) ≤εk|F| ≤εk|Y ||X|.
9.4.1
Tightness
The following example shows that the bound in Theorem 9.11 is tight for
some problem distributions and some performance measures.
Example 5 (ANFL tightness). Let F = Bh be a base class of bijective func-
tions and assume without loss of generality that X = Y = {1, . . . , |X|}.
Assume n = |X|.
Now construct an ε-block uniform distribution P by
P(f) =
(
ph + ε/2
if f(n −1) < f(n)
ph −ε/2
if f(n −1) > f(n)
where ph = 1/|Bh| so that P
f∈F P(f) = 1 (exactly half of the functions
receive an ε increase and the other half an ε decrease in probability, therefore
they sum to 1). Since f is bijective, either f(n−1) < f(n) or f(n−1) > f(n),
so the cases are exhaustive. Note that if Bh is large, ε must to be small in
order for ph −ε/2 = 1/|Bh| −ε/2 ≥0.
Deﬁne a performance measure M according to
M(R) =
(
1
if R[n −1] < R[n]
0
if R[n −1] > R[n]
(52)
Let R< = {R ∈T y
n : R[n −1] < R[n]} be the set of result vectors yielding
value 1, and let R> = T y
n −R< be the complement of R< (that is, the
vectors yielding 0).
51

Finally, deﬁne two enumerating search procedures a and b that searches
the n ﬁrst points of X in the order 1, . . . , n and 1, . . . , n −2, n, n −1 respec-
tively (both ignoring the output of the function they are searching).
Applying the proof idea of Theorem 9.11 with Ha,R = Ha,R,F , we obtain
MP(a, n) −MP(b, n) =
(53)
=
X
f∈Bh
P(f)M(T y
n(a, f)) −
X
g∈Bh
P(g)M(T y
n(b, g))
(54)
=
X
R∈T y
n

X
f∈Ha,R
p(f)M(T y
n(a, f)) −
X
g∈Hb,R
p(g)M(T y
n(b, g))

(55)
=
X
R∈T y
n
M(R)

X
f∈Ha,R
P(f) −
X
g∈Hb,R
P(g)

(56)
=
X
R∈R<
M(R)

X
f∈Ha,R
P(f) −
X
g∈Hb,R
P(g)

+
+
X
R∈R>
M(R)

X
f∈Ha,R
P(f) −
X
g∈Hb,R
P(g)

(57)
=
X
R∈R<
1 ·

X
f∈Ha,R
P(f) −
X
g∈Hb,R
P(g)

(58)
=
X
R∈R<
(ph + ε/2 −(ph −ε/2))
(59)
=ε|R<| = ε|F|/2 = ε
X
f∈F
M(T y
n(a, f))
(60)
The steps roughly follow the proof of Theorem 9.11. The diﬀerences are:
As the function class F now is a base class Bh itself, there is no need to
split the sum over base classes. In (58) the fact that M(R) = 0 for R ∈R>
is used. In (59) we use that the bijectiveness of the the elements of F makes
the sets Ha,R and Hb,R singletons.
♦
In a similar manner one can create a tightness proof for larger ε-
block uniform classes of bijective functions.
However, given a collection
Bh1, . . . , Bhk for which the bound is tight, it is not necessary that the bound
is tight for their union S Bhi. Intuitively, if Bh has a distribution deﬁned
as in the above example, and another base class Bh′ receives the diametric
weighting of functions f ∈Bh′:
P(f) =
(
ph′ + ε/2
if f(n −1) > f(n)
ph′ −ε/2
if f(n −1) < f(n)
(61)
(the directions of the inequality signs are switched compared to (52)). In this
case, it may not be possible to construct policies that diﬀer to the maximum
extent permitted by the bound.
52

The bijectiveness is also necessary to make the bound tight. For base
classes on which at least two inputs generate the same output, any two
procedures a and b will produce the same result vectors on some pair of
functions, making the performance diﬀerence between a and b smaller than
the bound in Theorem 9.11.
Nonetheless, the fact that the bound is (sometimes) tight shows that
although the growth of free lunch is continuous, just a small perturbation of
the block uniformity may allow one algorithm to widely outperform another.
10
Performance measures
So far we have only considered problems for which either NFL holds for
all performance measures, or for which a free lunch is available for some
performance measures. Often, however, we are interested in performing well
under a ﬁxed, particular performance measure of interest.
One natural such performance measure is the probes-till-max-measure
Mptm, which only depends on the number of probes until the maximum is
found, and ignores other properties of the result vector. Unfortunately, this
performance measure can only be deﬁned on full-length result vectors. We
therefore deﬁne a full-length performance measure as a performance measure
deﬁned only on full-length result vectors. Mptm can then be deﬁned as a
full-length performance measure:
Deﬁnition 10.1 (Probes-till-max-measure). The probes-till-max measure
Mptm is deﬁned by
Mptm(R) = min
i (R[i] = max R)
(62)
Just as with other performance measures, we will be interested in the P-
expected value MP
ptm(a) = P
R Pa(R)Mptm(R). Under Mptm a low score is
normally considered better than a high score.
Other performance measures have been considered in the NFL-literature.
The Mptm-measure is essentially the performance measure used in [BP06]. A
related performance measure based on how many of the ﬁrst k points exceed
a certain threshold (e.g., the median) is used in [CO01, WR06, JC11]. Grif-
ﬁths and Orponen [GO05] use a maximization performance measure Mmax,
deﬁned as:
Mmax(R) = max R
The Mmax-measure is closely related to the Mptm-measure. The main reason
for preferring Mptm to Mmax is that Mmax does not lend itself as nicely to the
asymptotic results we will aim for in Section 11. In [WM97], a minimization
performance measure is discussed; it is also less suitable for asymptotic
studies.
53

0
1
2
0
1
2
3
4
5
X = {0, 1, 2}
Y = {0, . . . , 5}
f1 = (0, 0, 1)
f2 = (2, 3, 2)
f3 = (5, 4, 4)
Figure 3: The three functions f1 = (0, 0, 1), f2 = (2, 3, 2) and f3 = (5, 4, 4)
used in Example 6. After having searched one point, it becomes obvious
which function is the true function. Depending on the performance measure,
it may and may not be advantageous to use this information.
10.1
Theoretical considerations
Particular performance measures (if well-chosen) have the advantage of be-
ing of greater practical interest. In addition, they also add some theoretical
dimensions to the NFL-problem, not visible when arbitrary performance
measures are allowed.
Griﬃths and Orponen [GO05] show that under Mmax, NFL may hold
for classes of functions where NFL does not hold for all performance mea-
sures. This does not contradict Theorem 9.7, which only claims that some
performance measure provides a free lunch for the class considered. Indeed,
it is unsurprising that NFL will apply to wider ranges of function classes
when a ﬁxed performance measure is used. Griﬃths and Orponen’s conclu-
sion is that classes satisfying NFL for Mmax have signiﬁcantly more intricate
descriptions, compared to the standard NFL case.
Another diﬀerence is found in the cleverness required to exploit a free
lunch.
In fact, smarter algorithms may be required for exploiting a free
lunch when using a particular performance measure such as Mptm or Mmax
compared to when arbitrary performance measures are permitted. This is
demonstrated by the following example.
Example 6 (Particular versus freely chosen measures). Assume X = {1, 2, 3}
and that we have the set of functions F = {f1 = (0, 0, 1), f2 = (2, 3, 2), f3 =
(5, 4, 4)} depicted in Figure 3).13
Let P be uniform over F.
Since P is
13Recall that the tuple (y1, y2, y3) denotes the function f(1) = y1, f(2) = y2, f(3) = y3.
54

not block uniform (F is not c.u.p.), a free lunch is available according to
Theorem 9.9. Indeed, choosing the performance measure as M(⟨0, 0, 1⟩) =
M(⟨2, 3, 2⟩) = (⟨5, 4, 4⟩) = 1 and 0 otherwise, makes the enumerating al-
gorithm e that simply searches X in the order 1, 2, 3 outperform any other
algorithm (it will have optimal M-performance).
However, under Mptm, all enumerating algorithms perform equally well,
since any point is as likely to be the maximum. But it is possible to construct
an algorithm b that outperforms other algorithms by letting it make an
informed choice (Deﬁnition 7.5) after its ﬁrst probe (that I assume is at
1 ∈X). Let b choose its second search point according to
b(⟨1, f(1)⟩) =
(
3
if f(1) = 0
2
otherwise; i.e. f(1) = 2 or f(1) = 5
The rationale is: If f(1) = 0, then the function must be (0, 0, 1), so the
maximum must be at 3. If instead f(1) = 2, then the maximum must be
at 2, since the only consistent function is (2, 3, 2). Finally, if f(1) = 5, then
that must be the maximum and it does not matter how the search proceeds.
This way b will ﬁnd the maximum in at most two steps and ﬁnd the
maximum in one step with probability 1
3.
This means that b’s expected
number of probes-till-max MP
ptm(b) = 1
3 ·1+ 2
3 ·2 = 5
3. Thereby b outperforms
all the enumerating algorithms, as they expect to ﬁnd the maximum in
1
3 · 1 + 1
3 · 2 + 1
3 · 3 = 2 probes.
♦
This example illustrates that “more cleverness” may be required to ex-
ploit a free lunch under Mptm than under arbitrary performance measures.
The same example applies with minor modiﬁcations to Mmax as well, since
b will have a higher expected maximum after having searched two points,
compared to the enumerating algorithms. So sometimes informed, “clever”
choices (i.e., choices depending on the seen f(x)-values) are required to ex-
ploit a free lunch under Mptm and Mmax.
In the above example, it was also the case that when arbitrary perfor-
mance measures were considered, no cleverness was required. The following
proposition shows that this is true in general when arbitrary performance
measures are permitted. The proof is essentially a reiteration of the proof
of Theorem 9.9, where the enumerating algorithms e and eσ generate the
result vector ⟨f(x1), . . . , f(x|X|)⟩with diﬀerent probability.
Proposition 10.2. If NFL does not hold for a problem PX,Y on a problem
context X,Y , then there is free lunch for an enumerating algorithm a (under
some performance measure).
Proof. Assume that NFL does not hold for a problem context X,Y . Then
PX,Y is not block uniform by Theorem 9.9, so there are two functions f
55

and σf in the same base class Bh such that P(f) > P(σf), where σ is
a permutation on X. By Lemma 7.4 we had that e generates the result
vector Rf = ⟨f(1), . . . , f(|X|)⟩exactly when f is the true function, and
that eσ generates Rf exactly when σf is the true function. An immediate
consequence is that Pe(Rf) = P(f) > P(σf) = Peσ(Rf).
That is, the
enumerating algorithms e and eσ generate Rf with diﬀerent probability,
which means that there is free lunch for some enumerating algorithm (under
some performance measure).
Indeed, enumerating algorithms can sometimes obtain the “maximum
possible amount” of free lunch, as was the case in Example 5.
In conclusion, speciﬁc performance measures can be considered for both
practical and theoretical reasons. They are more practically relevant in the
sense that they measure aspects that we care about in practice (such as how
long it takes to ﬁnd a maximum). But they also have theoretical interest,
as they illuminate theoretical subtleties invisible from an arbitrary-measure
perspective.
11
Universal free lunch
The black-box optimisation problem is to a large extent an induction prob-
lem: Given data about how a function behaves on the particular points
already probed, an algorithm should infer some idea about the general or
global behavior of the function in order to make a good choice for its next
search point. As the NFL theorems demonstrate, it is necessary to have
some bias rendering some functions more likely than others. Without such
a bias (that is, with a uniform or block uniform prior) all generalizations be-
come equally likely, and it becomes impossible to outperform random search
or enumeration.
In most cases, we have the intuition that from seeing a number of points
we can, in principle, extrapolate the global behavior of the function. Just
as in the case of sequence prediction in Part I, it also seems to be the case
that we consider the “simplest” continuation of the points as the most likely
true function (cf. Occam’s razor).
In sequence prediction, the universal measure M turned out to have
excellent induction performance (Theorem 5.11 on page 29). The optimi-
sation problem diﬀers from the sequence prediction task in some important
respects.
In sequence prediction the next bit is independent of previous
guesses. This is not the case in optimisation, where the selection of prob-
ing points aﬀects the knowledge. This entails an exploration-exploitation
dilemma, as there is sometimes a payoﬀbetween points that are likely to be
the maximum and points that yield more information. Another diﬀerence
stem from optimisation being a ﬁnite setting: Functions f : X →Y are
56

naturally represented by (ﬁnite) strings, and only a ﬁnite number of guesses
(probes) are to be made.
The ﬁniteness makes it natural to use the discrete universal measure m
in place of M. The ﬁniteness also entails certain problems with the reference
machine. For any ﬁnite collection of strings, there is a reference machine
that gives all the strings the same complexity, and thus causes m to give
them the same probability. For this reason, all our results will be of the form:
For a ﬁxed reference machine there are (suﬃciently large) search spaces for
which the result holds.
Another diﬀerence is that in sequence prediction we could do well in any
computable environment. This is not possible in ﬁnite settings. Instead the
goal will be to do well in m-expectation.
One way to understand the diﬀerence between a uniform prior and m
is that m gives high weight to structured, compressible functions whereas
a uniform prior gives high weight to unstructured problems. If a function
is sampled from the uniform distribution, then the probability that this
function is algorithmically random approaches one as the size of the domain
increases.14 Therefore a uniform prior represents a strong belief in that the
true function will be almost entirely without structure, and therefore hard to
optimise (cf. Section 5.6.1). In contrast, m follows Occam’s razor in giving
higher weight to structured functions.
The main goal of the remainder of the thesis will be an understanding
of optimisation under the prior m. The ﬁrst step will be to adapt the opti-
misation setting to m. This involves devising string-encodings for problem
contexts and functions. It also involves generalizing the deﬁnitions for search
problem, performance measure and search algorithm, to enable asymptotic
studies.
11.1
Adapting the optimisation problem
For the remainder of this thesis we will assume that X and Y are ordered,
ﬁnite subsets of B+, containing at least 0 and 1 as elements15 (recall that
B+ is the set of all non-empty, ﬁnite strings). Let X be the set of all such
search spaces, and Y be the set of all ranges.
As the universal distribution requires investigations to be asymptotic,
we generalize problems, performance measures and algorithms to be deﬁned
on all possible X and Y .
Recall that T denotes the set of all traces between (implicit) spaces X
and Y . Let T (X, Y ) be the set of traces between X,Y , making the problem
14For any c ∈(0, 1), the fraction of (n −nc)-compressible strings of length n goes to
zero with growing n—see Section 3.8 on page 20.
15The assumption that both X and Y contain 0 and 1 is only for readability. It is
possible to substitute 0 ∈X for min X and 0 ∈Y with min Y , and to substitute 1 for the
second smallest elements, with maintained validity of proofs and deﬁnitions.
57

context explicit. Subscripts and superscripts retain their meaning, so, for
example Tn(X, Y ) is the set of all search traces of length n on the speciﬁed
problem context.
Let T (X, Y) = S
(X,Y )∈X×Y T (X, Y ) be the set of all
traces on any context.
A generalized (optimisation) problem P is a collection of distributions
such that PXY is a distribution over the set {f : X →Y } for every (X, Y ) ∈
X × Y.
Generalized search algorithms receive the problem context as an extra
argument. Deterministic generalized search algorithm are modelled by func-
tions
a : (X, Y , T) ∈X × Y × T (X, Y) 7→x ∈X −T x
(63)
Similarly, probabilistic generalized search algorithms are modelled by condi-
tional distributions
Prb(x|X, Y, T )
(64)
where T
∈
T (X, Y ).
As before,
we require that no distribution
Prb(·|X, Y, T ) has support outside X −T x (cf. Section 7.2 on page 34).
The full-length trace a deterministic algorithm generates is now deter-
mined by the problem context and the function. We write T(X, Y , a, f) for
the full-length trace a deterministic algorithm a generates on X,Y and f.
The measures PrXY a(T |f ) and PXY a(T) can be constructed as Pra and Pa
for every X,Y (Section 7).
To ease the exposition slightly, and since Mptm is a full-length measure,
in the remainder of this thesis we restrict our attention to full-length result
vectors. Let R(X, Y ) be the set of all full-length result vectors on X, Y ,
and let R = S
(X,Y )∈X×Y R(X, Y ). A generalized performance measure is
deﬁned by a function M : X ×Y×R →R+ S{0}. As usual, we are interested
in the P-expected performance of diﬀerent algorithms.
MP
XY (a) =
X
R∈R(X,Y )
PXY a(R)MXY (R)
(65)
For deterministic algorithms, this reduces to
MP
XY (a) =
X
f:X→Y
PXY (f)MXY (T y(X, Y , a, f))
(66)
As a concrete example, the generalised version of Mptm is deﬁned as
MP
ptm,XY (a) =
X
R∈R(X,Y )
PXY a(R)Mptm,XY (R)
(67)
with
Mptm,XY (R) = min
i (R[i] = max R)
(68)
58

11.2
The universal distribution
Using the assumed order on X = {x1, . . . , x|X|} and Y = {y1, . . . , y|Y |},
it is natural to encode X and Y as |X|- and |Y |-tuples, according to the
code devised in Section 2.4.2 on page 11. Similarly, a function f : X →Y
mapping f(xi) = yi is encoded as an |X|-tuple (y1, . . . y|X|).
The string encodings of functions and functions allow us to deﬁne the
complexity of a function f : X →Y . Let n = |X| and m = |Y |.
K(f |X, Y ) = K(n f(x1) . . . f(xn−1)f(xn)|n x1 . . . xn m y1 . . . ym)
(69)
The complexity of a search point x ∈X with respect to X,Y is deﬁned
as K(x|X, Y ).
A function f : X →Y is compressible if K(f |X, Y ) <
|X|log2|Y | and a point x ∈X is compressible with respect to X, Y if
K(x|X, Y ) < log2|X|.16
Using the complexity of functions, we deﬁne the universal probability of
a function f : X →Y as
mXY (f) = cm · 2−K(f |X, Y ) =
2−K(f |X, Y )
P
g:X→Y 2−K(g|X, Y )
(70)
The normalisation factor cm ensures that mXY is a proper distribution and
deﬁnes an optimisation problem (cf. the deﬁnition of optimisation problem
on page 33). It slightly abuses notation compared to the standard deﬁnition
of m (Deﬁnition 5.5 on page 26). The harm should be minor, as it is still
biased towards simplicity in a similar manner, and the dominance property
from Proposition 5.7 on page 27 still holds. The main reason the unnor-
malised version is sometimes preferred is that the normalised version of m
is not semi-computable.
11.3
Free lunch under arbitrary measure
Streeter shows that there is free lunch for m under certain conditions [Str03].
We prove a similar result, but with more easily interpretable conditions (in
terms of the size of X). We also use a diﬀerent proof than Streeter.
Theorem 11.1 (Universal free lunch). There exists an n ∈N such that
there is free lunch for the problem m for any X,Y satisfying |X| ≥n.
Proof. It will be shown that m is not block uniform for problem contexts
with suﬃciently large X, which by Theorem 9.9 implies that NFL does not
hold.
16Note that a point x ∈X may be incompressible with respect to some X, Y1 while
being compressible while being compressible with respect to X, Y2. To see this, any point
x ∈X is generally compressible with respect to X,Y with Y = {0, 1, x}.
59

0
1
· · ·
k−1
k
k+1
· · ·
1
0
f
g
Figure 4: Functions of type f have complexity bounded by a constant cf
independent of X and Y . In contrast, the complexity of functions of type g
grow logarithmically with |X|. See the proof of Theorem 11.1 for details.
Pick an arbitrary problem context X,Y and let X = {x1, . . . , xn}. Con-
sider two functions f and g in the base class Bh of functions with one value
1 and the rest of the values 0. Let f be 1 at x1 and let g be 1 at some
point xk where k is chosen so that K(g|X, Y ) ≥log2n. To see that such a
g exists, note that there are n diﬀerent functions in Bh. In any preﬁx-code
there are at most n code words of length ≤log2n by Kraft’s inequality, since
n2−log2n = 1 (see e.g. [LV08, p. 76]). Thus at least one of the Bh-functions
must have a shortest code word longer than log2n in the preﬁx-code of the
reference machine. That is, at least one Bh-function g has at least complex-
ity K(g|X, Y ) ≥log2n.
Let for every problem context X,Y the functions fXY and gXY be func-
tions of “type” f and g above. Then K(gXY |X, Y ) ≥log2(|X|). Meanwhile,
K(fXY |X, Y ) ≤cf for some constant cf independent of the problem con-
text, since there is a program computing fXY for any provided problem
context. So for search spaces with log2(|X|) > cf, this means that fXY will
have lower complexity than gXY , and thus that mXY will assign diﬀerent
probabilities to fXY and gXY . But fXY and gXY are elements of the same
base class. Therefore m is not block uniform for suﬃciently large search
spaces |X| > 2cf . By Theorem 9.9, this implies that there is free lunch for
m under some performance measure.
Indeed, m is not even ε-block uniform for any reasonably small ε for
large search spaces. This may lead one to suspect that there is a signiﬁcant
amount of free lunch under m for large search spaces; however, Section 12
below indicates that this is not necessarily the case.
11.4
Free lunch under Mptm
As has been discussed, in practice we often care about a particular perfor-
mance measure. The following deﬁnitions and lemmas build up to Theorem
60

11.5, which investigates whether there is free lunch under the performance
measure Mptm.
Deﬁnition 11.2 (Incompressible search points). For any problem context
X,Y , let DXY = {x ∈X : K(x|X, Y ) ≥log2(|X|)} be the set of all
incompressible search points. Subsets D ⊆DXY of the incompressible search
points will be called incompressibility sets (of X,Y ).
The following lemma ensures the existence of incompressibility sets of a
certain size. It is a simple reformulation of Proposition 3.9 on page 19.
Lemma 11.3. For any X,Y there exists an incompressibility set D of size
|X|/2 (that is, at least |X|/2 points of X are incompressible).
Functions that only have incompressible maxima (except, possibly, for
a maximum at 0) will play an important role since they are guaranteed to
have high complexity. The reason for excluding 0 will be apparent in the
proof of Theorem 11.5.
Lemma 11.4. If g : X →Y is such that {x : g(x) = max g} ⊆DXY ∪{0},
then it holds that K(g|X, Y ) ≥log2(|X|) −c, where c depends only on the
reference machine and not on g, X or Y .
Proof. Let g be a function whose maxima are in DXY ∪{0}, and let xm ∈
X −{0} be the ﬁrst maximum of g not at 0. Then xm can be coded by
means of g with constant length procedure FirstMax(g) that computes
the ﬁrst maximum not at 0 for a given function g. Hence K(xm |X, Y ) ≤
K(g|X, Y )+ℓ(FirstMax)+c. The constant c depends only on the reference
machine, and absorbs the cost of initializing FirstMax with a provided
description of g.
By assumption, xm belongs to DXY , so K(xm |X, Y ) ≥log2|X|. Com-
bined and rearranged, this gives K(g|X, Y ) ≥log2|X| −ℓ(FirstMax) −c.
The lemma now follows by absorbing ℓ(FirstMax) into c.
We are now ready for the main theorem of this section, that there is free
lunch for Mptm on the problem m. The key idea is to show that there is a
trace after which two unexplored points have diﬀerent probability of being
the maximum.
Theorem 11.5. There is free lunch for the problem m under the perfor-
mance measure Mptm for suﬃciently large search spaces.
Proof. The ﬁrst step of the proof is to construct an event G (deﬁned in a
moment) that makes the point 0 likelier to be a maximum than a certain
point xm ̸= 0 (also deﬁned in a moment).
Fix some k ≥2 and some X,Y with |X| ≥2k. Choose some incompress-
ibility set Dk ⊆DXY of size k. Let Q = X −Dk −{0}.
61

The function f = (1, 0, . . . , 0) has complexity bounded by a constant
cf independent of X,Y . Accordingly, f’s universal probability is always at
least 2−cf :
mXY (f) ≥2−cf
(71)
Let G = {g ∈Y X : x ∈Q =⇒g(x) = f(x) = 0} be the set of functions g
consistent with f on Q. Let xm be the ﬁrst point in Dk (in the lexicographic
order) and let G1 = {g ∈G : g(xm) = max g} be the subset of functions in
G with a maximum at xm. Note that while mXY (G) ≥mXY (f) ≥2−cf ,
the functions in G1 all have high complexity by Lemma 11.4. Note also that
the cardinality of G1 is less than |Y |k+1 since the elements of G1 are ﬁxed
on Q and |X −Q| = k + 1.
Now, a maximum at 0 is likely (is O(1) with respect to X) since the
complexity of f is O(1) with respect to X:
mXY (max at 0|G) ≥mXY (f |G) ≥mXY (f) ≥2−cf
A maximum at xm, on the other hand, is less likely since only functions in
G1 can have a maximum there:
mXY (max at xm |G) = mXY (max at xm, G)/mXY (G)
= mXY (G1)/mXY (G)
≤mXY (G1) · 2cf
= cm
X
g∈G1
2−K(g|X, Y ) · 2cf
(72)
Using the lower bound on the complexity from Lemma 11.4, (72) is bounded
by
≤cm
X
g∈G1
2−log2|X|+c · 2cf
= cm|G1| · 2−log2|X|+c · 2cf
(73)
and since the cardinality of G1 is less than |Y |k+1, (73) is bounded by
≤cm|Y |k+12−log2|X|+c · 2cf
= cm|Y |k+12c+cf
|X|
(74)
the last equality by elementary simpliﬁcation.
As (74) goes to 0 with growing search space (and ﬁxed k and Y ), this
shows that for large enough search spaces, 0 is more likely to be the maxi-
mum than xm.
62

Now all that remains is to use this fact to create two algorithms that
perform diﬀerently under Mptm. Let a start by enumerating Q in order.
If the perceived function points are consistent with f, it proceeds at 0 and
then at xm and then enumerates the remaining points X −Dk −0. If the
trace is not consistent with f it simply enumerates the remaining points.
Deﬁne b the same way, with the only exception that after Q it searches xm
before 0 in case the trace is consistent with f.
This way, a and b will perform the same except when encountering a
function in G, in which case a will have a strictly better chance of ﬁnding
the maximum at step |Q| + 1. If neither a nor b ﬁnds a maximum at step
|Q| + 1 they will perform the same, since if neither 0 nor xm is a maximum,
then neither a nor b will ﬁnd a maximum at step |Q| + 2 either. Finally, on
step |Q|+3 and onwards their behavior will again be identical, and therefore
also their Mptm performance.
So a has a strictly better chance at step |Q|+1 and a and b’s performance
is identical on all other steps and in all other situations. This shows that
there is a (possibly small) free lunch for Mptm on m for suﬃciently large
search spaces.
12
Upper bounds on universal free lunch
Theorems 11.1 and 11.5 show that there is free lunch under the universal
distribution. This section will bound the amount of free lunch available,
and show that it is only possible to outperform random search by a constant
factor. First we show that the performance of computable search algorithms
deteriorates linearly with the worst-case scenario and the size of the search
space. This result applies to computable performance measures in general,
and has a concrete interpretation for Mptm, where it implies that as the size
of the domain is increased, a non-zero fraction of the domain must be probed
before a maximum is found in expectation. This result should not be seen
as too negative, since for random search the fraction of probes required is
approximately half, but for other search algorithms it may be substantially
smaller.
We also consider possible ways to circumvent the negative result de-
scribed above result by means of incomputable search procedures. A fur-
ther negative result for Mptm is obtained: It does not appear possible to
ﬁnd the maximum with only o(|X|) probes. That is, the number of probes
required to ﬁnd the maximum in expectation grows linearly with the size
of the search space, but again, the proportion may be substantially smaller
than that required for a random algorithm.
12.1
Computable algorithms
To bound the amount of free lunch available for computable algorithms,
63

we will adapt a proof-technique for showing that average-case complexity is
worst-case complexity under the universal distribution [LV08, Section 4.4].
Deﬁnition 12.1 (Decidable performance measure). A performance measure
M is decidable if there is an algorithm computing whether MXY (R1) <
MXY (R2) or not for every X,Y and every R1, R2 ∈R(X, Y ).17
Fix a decidable performance measure M. Although no formal theorem
relies on it, greater M-values will generally be assumed to mean worse per-
formance.
Deﬁnition 12.2 (Maximally bad function). fbad : X →Y is a maximally
bad function for a deterministic algorithm a on the problem context X,Y
with respect to a performance measure M if
MXY (T y(X, Y , a, fbad)) =
max
R∈R(X,Y ) MXY (R)
Lemma 12.3. Given any performance measure M, any algorithm a and any
problem context X,Y , there exists a maximally bad function fbad : X →Y
for a with respect to M.
Proof. Assume there were a problem context X,Y on which a never performs
maximally badly with respect to some performance measure M. Let Rbad
be a result vector on X,Y such that MXY (Rbad) = maxR∈R(X,Y ) MXY (R),
and let f = Rbad (recall the identiﬁcation of functions with result vectors
from Section 7.4). Then the enumerating algorithm e produces the result
vector Rbad when f is the true function. By Lemma 9.10, all deterministic
algorithms produces Rbad on equally many functions. Hence a must also
produce Rbad on some function.
Deﬁne a procedure FindWorst(a, X, Y ) that given a computable search
algorithm a (speciﬁed by some binary string), a search space X and a range
Y , returns (the tuple for) a maximally bad function fbad,a,X,Y for a and
M. FindWorst is a computable operation since a is computable and M is
decidable: FindWorst need only simulate a on all possible functions in Y X,
and output one that yields a worst result vector. FindWorst is computed
by some program of some length ℓ(FindWorst), where ℓ(FindWorst) is
independent of X and Y .
This means that the conditional complexity of a maximally bad function
for a is O(1) with respect to X and Y , since
K(fbad,a,X,Y |X, Y ) ≤ℓ(FindWorst) + ℓ(a) + c = O(1)
(75)
17Computability of M does not imply decidability.
If the values MXY (R1) and
MXY (R1) were both computable (Deﬁnition 4.1 on page 21) it can still be undecid-
able whether MXY (R1) < MXY (R2) or not. Intuitively, this is because if MXY (R1) =
MXY (R2) we cannot in general be sure that they are actually equal by only approximating
them arbitrarily well. See for instance [Wei00] for more details.
64

where the c term depends only on the reference machine, and absorbs the
cost for initializing FindWorst with a, X and Y .
Since the complexity of a maximally bad function does not grow
with X, this means that a will do badly with at least probability
2−(ℓ(FindWorst)+ℓ(a)+c), no matter how large X grows.
That is, for any
performance measure M, the performance of a computable deterministic
algorithm a grows linearly with the performance measure of the worst pos-
sible result vector. Formally:
Theorem 12.4 (Almost NFL for m). For every decidable performance mea-
sure M and every computable algorithm a there exists a constant ca > 0 such
that for all and problem contexts X,Y
Mm
XY (a) ≥ca
max
R∈R(X,Y ) MXY (R)
(76)
for all X and Y .
Proof. Fix a problem context X,Y . The proof utilizes FindWorst for a
short description of a maximally bad function for a.
Mm
XY (a) =
X
fX→Y
mXY (f)MXY (T y(X, Y, a, f))
= cm
X
f:X→Y
2−K(f|X,Y )MXY (T y(X, Y , a, f))
≥
X
f:X→Y
2−K(f|X,Y )MXY (T y(X, Y , a, f))
≥2−K(fbad,a,X,Y |X,Y )MXY (T y(X, Y , a, fbad,a,X,Y ))
≥ca · MXY (T y(X, Y , a, fbad,a,X,Y ))
= ca
max
R∈R(X,Y ) MXY (R)
where fbad,a,X,Y is the output of FindWorst(a, X, Y ) and therefore is max-
imally bad and has complexity bounded by a constant by inequality (75).
This theorem shows that for every performance measure M, there is only
a constant amount of free lunch available in an asymptotic sense. Since the
result is asymptotic it has no impact on measures whose value does not grow
with X. However, the “semi-assumption” of higher values being worse is not
necessary: If the converse is the case and high values are better, then the
proposition shows that all algorithms will do well. Indeed, this is also an
NFL result, as it implies that random search (and even algorithms designed
to do poorly!) will perform well.
Applied to the performance measure Mptm, Theorem 12.4 has a fairly
concrete interpretation: For any computable deterministic search algorithm
a, the expected number of probes until a maximum is found grows linearly
with |X|.
65

Corollary 12.5. For every computable algorithm a there exists a constant
ca > 0 such that Mm
ptm,XY (a) ≥ca · |X| for all algorithms a and all problem
contexts X,Y .
Proof. Let a be a search algorithm. Then there is a function fbad,a,X,Y such
that a does not ﬁnd the maximum of fbad,a,X,Y until the very last probe.
Hence Mptm,XY (T y(X, Y , a, fbad,a,X,Y )) = |X|.
By Theorem 12.4, there
is a constant ca > 0 such Mm
ptm,XY (a) > caMptm(T y(X, Y , a, fbad,a,X,Y )) =
ca·|X| for all X and Y . That is, the expected number of probes Mm
ptm,XY (a)
grows linearly with |X|.
The importance of this result should not be overstated. The constant ca
may be very small; for example, if the description of the search algorithm
a is 100 bits long, then ca becomes of the order 2−100. The fact that an
algorithm is always required to search such a fraction to ﬁnd a maximum is
mainly of theoretical importance, since in practice search spaces seldom grow
large enough for this fraction to have a meaningful impact. Nonetheless, the
result does illustrate the fundamental hardness of optimization, and shows
that—in this sense—the universal distribution does not provide enough bias
for sublinear maximum ﬁnding.
12.2
Needle-in-a-haystack functions
A problematic class of functions is the class of so-called needle-in-a-haystack
(NIAH) functions. For a given X and Y , a function f : X →Y is a NIAH-
function if f is taking on the value 0 for all x ∈X except one where f(x)
equals 1.
The exception point is called the needle.
The class of NIAH
functions for a given X and Y is denoted NIAHXY .
It should be intuitively clear that it is hard to ﬁnd the maximum of a
NIAH-function. Probing a NIAH-function, the output will generally just
turn out to be 0 and provide no clues to where the needle might be. More
formally, the function class NIAHXY is c.u.p., so NFL holds for the problem
uNIAH,XY = uNIAHXY by Theorem 9.7. The expected performance (of any
algorithm) on the NIAH-problem can be calculated from a general result of
Igel and Toussaint [IT03a]. They show that for any c.u.p. problem uF where
F only contains functions with exactly m maxima, the expected number of
probes to ﬁnd a maximum is (|X| + 1)/(m + 1). The NIAH-functions have
exactly one maximum, which gives the following proposition.
Proposition 12.6. For uNIAH,XY and any algorithm a, the expected number
of probes until the maximum is found is MuNIAH
ptm,XY (a) = (|X| + 1)/2.
One feature that makes the NIAH-class more problematic than other
c.u.p. function classes is that the NIAH-functions all have fairly low com-
plexity (as remarked by [SVW01, BP06]). The NIAH-functions have low
complexity, since to encode a NIAH-function one only needs to encode that
66

it is NIAH (which takes a constant number of bits) and the place of the
needle (which requires at most O(log2|X|) bits).
A NIAH-function thus
has complexity of order O(log2|X|); in comparison, a random function has
complexity above |X|log2|Y |.
The NIAH-measure is also computable. This is intuitively obvious, but
we prove it as a lemma to verify it against the formal deﬁnition of computable
measure given in Deﬁnition 5.4 on page 26.
Lemma 12.7 (Computability of the NIAH-measure). The (uniform) NIAH-
measure uNIAH,XY over the NIAH-functions X →Y is a computable mea-
sure.
Proof. The uNIAH,XY measure can be formally described as
uNIAH,XY (f) =
(
1/|X|
if f is a NIAH-function X →Y
0
otherwise.
for any X and Y
The distribution uNIAH,XY is computable since there is an associated
computable function g(x, y) that outputs 1/|X| if y is a preﬁx-code for two
spaces X and Y , and x is the preﬁx-code of a NIAH-function between X
and Y . If these conditions are not satisﬁed, g just outputs 0.
The following lemma is an immediate consequence of Proposition 5.7 on
page 27, which states that m dominates any computable measure.
Lemma 12.8 (uNIAH is dominated by m). There is a constant cNIAH > 0
such that for all X and Y and all functions f : X →Y ,
mXY (f) ≥cNIAH · uNIAH,XY (f)
12.3
Incomputable algorithms
Theorem 12.4, Corollary 12.5 rely on a being describable as a computer pro-
gram. Intuitively, if a is not computable, then it is not possible to describe
it as a program. This means that it is not possible to use (a description of)
a for a short description of fbad,a,X,Y , which was the trick employed in The-
orem 12.4. Incomputable search procedures may seem like remote objects of
concern, but for example the (Bayes-)optimal procedure for a problem mXY
is incomputable (due to the incomputability of m). Therefore, incomputable
procedures do at least have theoretical interest.
The following theorem generalizes Corollary 12.5 to incomputable search
procedures, showing that also they must search a linearly growing portion
of X to ﬁnd the maximum.
Theorem 12.9 (Almost NFL for m and Mptm). Let the problem be m. For
any search procedure a (not necessarily computable), the expected number of
probes until a maximum is found grows linearly with |X|.
67

Proof. The proof follows from the dominance of m over uNIAH.
Mm
ptm,XY (a) =
X
R∈R(X,Y )
mXY a(R)Mptm(R)
(77)
=
X
R∈R(X,Y )
f:X→Y
mXY (f) · Pra(R|f )Mptm(R)
(78)
≥
cNIAH·
X
R∈R(X,Y )
f:X→Y
uNIAH,XY (f) · Pra(R|f )Mptm(R)
(79)
=
cNIAH · MuNIAH
ptm,XY (a) = cNIAH · (|X| + 1)
2
(80)
(79) uses the multiplicative dominance of m over uNIAH just proved in
Lemma 12.8. (80) uses Proposition 12.6 for the expected number of probes
until the maximum of a NIAH-function is found.
Conversely, no algorithm will need to search less than a constant portion
of the search space to ﬁnd the maximum. Theorem 12.9 can thus be inter-
preted as an asymptotic ANFL theorem for the universal distribution and
Mptm: All algorithms perform essentially the same in expectation under the
universal distribution and Mptm—up to a constant determining the size of
portion. However, the remark from Theorem 12.5 is valid here as well: The
diﬀerence in constants may be so large that the result has small practical
implications.
13
Concluding remarks
13.1
Summary
To summarize the results of Part II, we started out by giving an account
of the classical NFL theorems, which culminated in a precise condition for
NFL (Theorem 9.9). We then investigated the potential growth of free lunch
as the problem distribution moved away from block uniformity, and found
that the growth was continuous but rapid (Section 9.4).
We also argued that in many cases the real quantity of interest is free
lunch under some particular measure. Mptm was deﬁned to be a performance
measure quantifying the expected number of probes until a maximum was
found.
Based on Part I and the characterization of optimisation as an induction
problem, we set out to investigate whether the universal distribution could
be used as a universal optimisation bias. The conclusion was that given the
right formal setup, the universal distribution does feature a free lunch. In
68

particular, there was free lunch under Mptm. However, although the uni-
versal distribution diverged signiﬁcantly from block uniformity, asymptotic
ANFL theorems could still be obtained (Theorem 12.4 and 12.9).
13.2
Optimisation and sequence prediction
The asymmetry between the optimisation problem and the sequence pre-
diction task described in Section 5.6 on page 28 is striking. In sequence
prediction, a predictor based on M widely outperforms a random predic-
tor (a random predictor would have inﬁnite expected prediction-distance);
in contrast, the diﬀerence between an optimal and a random searcher was
limited in optimisation.
One way to understand the diﬀerence is that optimisation is a ﬁnite
setting.
Intuitively, a sequence predictor may spend an unbounded but
ﬁnite initial period on learning the true model, and then exploit this model
indeﬁnitely. This is not possible in optimisation.
The NIAH-functions used in Theorem 12.9 were problematic in optimi-
sation because they had comparatively simple descriptions, but were hard
to predict because they had hard-coded exception points. In sequence pre-
diction this cannot happen. If an environment had hard-coded exception
points, there would be a rule (pattern) to where the exceptions occurred.
And it would only take the predictor a ﬁnite amount of time to ﬁnd this
pattern. Once the pattern had been found, the exception points would be
perfectly predictable.
Adversarial functions of the type fbad,a,X,Y used in Section 12.1 were
another reason the free lunch was limited under the universal distribution.
The incomputability of the M-predictor allows it to perform well on all com-
putable environments, as the incomputability makes it impossible to con-
struct a computable adversarial environment. Computable approximations
of the M-predictor are vulnerable to adversarial environments, however.
13.3
Future research
In conclusion, the universal distribution does not provide suﬃcient bias for
good (theoretical) optimisation performance. This naturally raises the ques-
tion of whether there is some stronger bias, which is still universal in the
sense that it is not biased towards a speciﬁc type of problem.
One possibility is to restrict the class of functions to exclude particu-
larly troubling function classes (such as the NIAH-functions). Applying the
universal distribution to such a restricted class of functions may potentially
yield a principled, signiﬁcant free lunch for optimisation.
The KC-continuity brieﬂy discussed in Section 8.3 oﬀers one such possi-
ble restriction. Quite possibly, however, a stronger criteria may be needed.
Other possibilities include restring the function class to Lipschitz-continuous
69

functions, or to “simple” permutations of clearly searchable function-classes
such as polynomials. Combinations of several criteria is also a possibility.
The adversarial functions might potentially be avoided by punishing run-
ning time in the prior. The complexity of a string s may instead be deﬁned
along the lines of
KtU (s) = min
w {ℓ(w) + log tU (q) : U (w) = s}
where tU(q) is the running time of q.
A universal “speed” prior based
on Kt was suggested by Schmidhuber [Sch02]. Given that maximally bad
functions were suﬃciently time-consuming to compute in comparison with
other functions, this could be one way to avoid the issue with adversarial
functions.
Finally, it would be instructive to investigate generalisations to inﬁnite
search spaces as in [AT07]. This would make the setting more similar to
sequence prediction. One major diﬀerence would remain, however: In se-
quence prediction the outcome of the next bit is independent of previous
guesses. This is not the case in optimisation, where the selection of probing
points aﬀects the knowledge.
70


Appendices
A
Proofs
Proof of Theorem 9.5. The uniform distribution over the class of all func-
tions is block uniform (Deﬁnition 9.8 on page 46). Therefore the theorem is
a special case of Theorem 9.9.
Proof of Theorem 9.7. The uniform distribution over a c.u.p.-class of func-
tions is block uniform (Deﬁnition 9.8 on page 46). Therefore the theorem is
a special case of Theorem 9.9.
B
Lists of notation
B.1
Abbreviations
c.u.p.
closed under permutation
NFL
No Free Lunch
ANFL
Almost No Free Lunch
NIAH
Needle-in-a-haystack
B.2
Generic math notation
c, r
real-valued constants
m, n, k
integer-valued constants
i, j
indices
N, Q, R
the sets of integer, rational and real numbers
R+
the set of positive real numbers
O, Θ, Ω
big- O, Theta and Omega notation
B.3
Kolmogorov complexity notation
B
the set of the binary symbols {0, 1}
B∗
the set of all ﬁnite binary strings
B+
the set of all non-empty ﬁnite binary strings
Bn
the set of all ﬁnite binary strings of length n
B∞
the set of all inﬁnite binary sequences
s, t, q
strings
z
inﬁnite sequence
72

w
code-word
q
provided information
C
code
C
class of codes
V
preﬁx-machine
U
universal preﬁx-machine
ℓ
length of a string
KV
description length w.r.t. V
K
Kolmogorov complexity
B.4
Probability theory notation
Ω
Sample space
Σ
σ-algebra
A, B
events
λ, ν, ρ
measures
µ, L
discrete and continuous Lebesgue-measure
m, M
discrete and continuous universal distribution
Dn
expected prediction-distance of prediction n
B.5
No free lunch notation
X, Y
search space and co-domain, problem context
x, y
members of X and Y respectively
xk, yk
random variables for the kth search point and perceived value
f, g
functions
fbad,a,X,Y
function on which a does maximally badly
F, G, H
sets of functions
h
histogram
Bh
the set of functions with histogram h
σ
permutation
Π
set of permutations
V [i:j], V [i]
extracts the ith to jth elements and the ith element, respectively
T, S
search traces
Tn
search trace of length n
Q, T x
n
probing sequences, the X-components of Tn
R, T y
n
result vectors, the Y -components of Tn
73

Tn, T x
n , T y
n
the sets of all Tn, T x
n and T y
n’s respectively
T (X, Y )
the set of traces for the problem context X,Y
R, R(X, Y )
the set of full-length result vectors (on X,Y )
a, b
search algorithms
A
the set of deterministic search algorithms
e, eσ
enumerating search procedures
Tn(a, f)
the trace of length n that a generates on f
P
search problem (probability distribution over Y X)
Pra
probability for algorithms
Pa
distribution over traces
uF
the uniform distribution over set of functions F
NIAHX,Y
the class of needle-in-a-haystack functions
uNIAH,XY
the (uniform) NIAH-problem
mXY
the universal distribution-search problem
mXY a
the trace-measure induced by mXY and a
M
performance measures of search algorithms
MXY
generalized performance measure
Mptm
the performance measure probes-till-max found
References
[AT07]
Anne Auger and Olivier Teytaud. Continuous lunches are free!
In Proceedings of the 9th annual conference on Genetic and evo-
lutionary computation GECCO’07, 2007.
[BP06]
Yossi Borenstein and Riccardo Poli. Kolmogorov complexity, op-
timization and hardness. In Proceedings of the IEEE Congress on
Evolutionary Computation CEC’06, pages 112–119. IEEE, 2006.
[CK03]
David Corne and Joshua Knowles. Some multiobjective optimizers
are better than others.
Proceedings of the IEEE Congress on
Evolutionary Computation CEC’03, 4:2506–2512, 2003.
[CO01]
Steﬀen Christensen and Franz Oppacher. What can we learn from
no free lunch? a ﬁrst attempt to characterize the concept of a
searchable function.
In Lee Spector, editor, Proceedings of the
Genetic and Evolutionary Computation Conference GECCO’01,
pages 1219–1226, San Fransisco, 2001.
[Cut80]
Nigel Cutland.
Computability:
An Introduction to Recursive
Function Theory. Cambridge University Press, 1980.
74

[DJW02] Stefan Droste, Thomas Jansen, and Ingo Wegener.
Optimiza-
tion with randomized search heuristics – the (A)NFL Theorem,
realistic scenarios, and diﬃcult functions. Theoretical Computer
Science, 287(1):131–144, 2002.
[DJW04] Stefan Droste, Thomas Jansen, and Ingo Wegener. Upper and
lower bounds for randomized search heuristics in black-box opti-
mization. Technical Report CI-162/04, University of Dortmund,
2004.
[EL13]
Tom Everitt and Tor Lattimore. Universal induction and optimi-
sation: No free lunch? Submitted 2013.
[Fri70]
Avner Friedman. Foundations of modern analysis. Courier Dover
Publications, 1970.
[GO05]
Evan J Griﬃths and Pekka Orponen. Optimisation , block de-
signs and no free lunch theorems. Information Processing Letters,
94(2):55–61, 2005.
[Hut05]
Marcus Hutter. Universal Artiﬁcial Intelligence: Sequential Deci-
sions based on Algorithmic Probability. Lecture Notes in Artiﬁcial
Intelligence (LNAI 2167). Springer, 2005.
[IT01]
Christian Igel and Marc Toussaint. On classes of functions for
which no free lunch results hold. Information Processing Letters,
86(6):317–321, 2001.
[IT03a]
Christian Igel and Marc Toussaint. Neutrality and self-adaptation.
Natural Computing, 2(2):117–132, 2003.
[IT03b]
Christian Igel and Marc Toussaint. Recent results on no-free-lunch
theorems for optimization. arXiv preprint cs/0303032, 2003.
[IT04]
Christian Igel and Marc Toussaint. A no-free-lunch theorem for
non-uniform distributions of target functions. Journal of Mathe-
matical Modelling and Algorithms, 3:312–322, March 2004.
[JC11]
Pei Jiang and Ying-ping Chen. Free lunches on the discrete lip-
schitz class.
Theoretical Computer Science, 412(17):1614–1628,
April 2011.
[LH11]
Tor Lattimore and Marcus Hutter. No free lunch versus occam’s
razor in supervised learning.
In Proceedings of the Solomon-
oﬀ85th Memorial Conference, Melbourne, Australia, November
2011. Springer.
[LV08]
Ming Li and Paul Vitanyi. Kolmogorov Complexity and its Appli-
cations. Springer Verlag, third edition, 2008.
75

[Mar09]
Stephen Marsland. Machine Learning: An Algorithmic Perscpec-
tive. Chapman & Hall, 2009.
[McG06] Simon McGregor. No free lunch and algorithmic randomness. In
GECCO’06, pages 2–4. ACM, 2006.
[MH09]
James A R Marshall and Thomas G Hinton.
Beyond no free
lunch: realistic algorithms for arbitrary problem classes. CoRR,
abs/0907.1:1–9, 2009.
[Mue06]
Markus Mueller. Stationary algorithmic probability. Theoretical
Computer Science, 2(1):13, 2006.
[Res98]
Sidney I Resnick. A probability path. Springer, 1998.
[RH11]
Samuel Rathmanner and Marcus Hutter. A philosophical treatise
of universal induction. Entropy, 13(6):1076–1136, 2011.
[RS95]
Nicholas J Radcliﬀe and Patrick D Surry. Fundamental limita-
tions on search algorithms: Evolutionary computing in perspec-
tive. Computer Science Today, pages 275–291, 1995.
[RVW09] Jonathan E Rowe, Michael D Vose, and Alden H Wright. Reinter-
preting no free lunch. Evolutionary computation, 17(1):117–129,
January 2009.
[Sch94]
Cullen Schaﬀer.
A conservation law for generalization perfor-
mance. In Proceedings of the Eleventh International Conference
on Machine Learning, pages 259–265. Morgan Kaufmann, 1994.
[Sch02]
J¨urgen Schmidhuber. The speed prior: A new simplicity measure
yielding near-optimal computable predictions. In Proceedings of
the 15th Annual Conference on Computational Learning Theory
COLT 2002, volume 2375 of Lecture Notes in Artiﬁcial Intelli-
gence, pages 216–228. Springer, 2002.
[Sol64a]
Ray J Solomonoﬀ. A formal theory of inductive inference. Part I.
Information and Control, 7(1):1–22, 1964.
[Sol64b]
Ray J Solomonoﬀ. A formal theory of inductive inference. Part II.
Applications of the systems to various problems in induction. In-
formation and Control, 7(2):224–254, 1964.
[Sol78]
Ray J Solomonoﬀ. Complexity-based induction systems: Com-
parisons and convergence theorems. IEEE Transactions on Infor-
mation Theory, IT-24(4):422–432, 1978.
76

[Str03]
Matthew J Streeter. Two broad classes of functions for which a no
free lunch result does not hold. In Proceedings of the Genetic and
Evolutionary Computation Conference GECCO’03, pages 1418–
1430, 2003.
[SVW01] Christopher W Schumacher, Michael D Vose, and L Darrell Whit-
ley.
The no free lunch and problem description length.
In
Lee Spector, editor, Proceedings of the Genetic and Evolution-
ary Computation Conference GECCO’01, pages 565–570. Morgan
Kaufmann, 2001.
[WB69]
Satosi Watanabe and D Boulton. Knowing and guessing; a quan-
tative study of inference of information. Wiley, New York, 1969.
[Wei00]
Klaus Weihrauch.
Computable Analysis:
An Introduction.
Springer, 2000.
[WM95]
David H Wolpert and William G Macready. No free lunch the-
orems for search. Technical Report SFI-TR-95-02-010, Santa Fe
Institute, 1995.
[WM97]
David H Wolpert and William G Macready. No free lunch theo-
rems for optimization. IEEE Transactions on Evolutionary Com-
putation, 1(1):270–283, 1997.
[WR06]
L Darrell Whitley and Jonathan E Rowe. Subthreshold-seeking
local search. Theoretical Computer Science, 361(1):2–17, August
2006.
[WR08]
L Darrell Whitley and Jonathan E Rowe. Focused no free lunch
theorems. In Proceedings of the 10th annual conference on Genetic
and evolutionary computation GECCO’08, page 811, New York,
New York, USA, 2008. ACM Press.
77

