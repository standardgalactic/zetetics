HAL Id: tel-01165038
https://tel.archives-ouvertes.fr/tel-01165038
Submitted on 18 Jun 2015
HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not.
The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.
L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.
Bayesian inference in plant growth models for prediction
and uncertainty assessment
Yuting Chen
To cite this version:
Yuting Chen. Bayesian inference in plant growth models for prediction and uncertainty assessment.
Engineering Sciences [physics]. Ecole Centrale Paris, 2014. English. ￿NNT : 2014ECAP0040￿. ￿tel-
01165038￿

ECOLE CENTRALE DES ARTS
ET MANUFACTURES
“ECOLE CENTRALE PARIS”
Th`ese
pr´esent´ee par Yuting CHEN
pour l’obtention du GRADE DE DOCTEUR
Sp´ecialit´e: Math´ematiques Appliqu´ees
Laboratoire d’accueil: Math´ematiques Appliqu´ees aux Syst`emes (MAS)
Inf´erence Bay´esienne
dans les Mod`eles de Croissance de Plantes
pour la Pr´evision et la Caract´erisation des Incertitudes
Bayesian Inference in Plant Growth Models
for Prediction and Uncertainty Assessment
Soutenue le 27 juin 2014
N° d’ordre: 2014ECAP0040
Devant un jury compos´e de :
Mme. Florence d’Alch´e-Buc
Universit´e d’´Evry-Val d’Essonne
(Rapportrice)
M. Fabien Campillo
INRIA
(Rapporteur)
M. Paul-Henry Courn`ede
ECP
(Directeur de th`ese)
M. Gilles Fa¨y
ECP
(Pr´esident)
M. Jean-Louis Foulley
Universit´e de Montpellier II
(Examinateur)
Mme. Martine Gu´erif
INRA
(Examinatrice)
M. Samis Trevezas
ECP
(Examinateur)


Simplicity is the ultimate sophistication.
Leonardo da Vinci
It is a capital mistake to theorize before one has data. Insensibly one
begins to twist facts to suit theories, instead of theories to suit facts.
Arthur Conan Doyle
Today’s posterior distribution is tomorrow’s prior.
David Lindley


Acknowledgement
This PhD thesis is the result of a challenging journey. It’s with emotion and cer-
tainly a lot of sincerity that I would like to thank those from whom I have received
tremendous help and those who encouraged and supported me to complete this en-
deavour.
First and foremost, my sincerest gratitude goes to my supervisor, Prof.
Paul-
Henry Courn`ede. The enthusiasm he has for his research has been an example for me,
contagious and motivational even during tough times. Thank you for putting your trust
in me and for giving me all the opportunities, guidance, patience and encouragement.
I greatly appreciate your willingness to listen and I feel truly grateful to your expertise
that allowed me to shape this dissertation. We have studied so many algorithms and
tested so many hypotheses together! It was an honour and privilege to work under
your supervision and surely this PhD would not have been achievable without you.
Furthermore, I’m indebted to Director of Research Fabien Campillo and Prof. Flo-
rence d’Alch´e-Buc for agreeing to be part of the reading committee and providing me
insightful suggestions and advices, which allowed me to improve the manuscript and to
enrich my research ideas. I’d like to extend my thanks and gratitude to the rest of my
dissertation jury, Prof. Gilles Ga¨y, Director of Research Jean-Louis Foulley, Director
of Research Martine Gu´erif and Dr. Samis Trevezas, for your invaluable feedback on
my research, for being supportive of my work and for standing by me through this
process.
This project could not come to fruition without the kindness of all the members
of the group DigiPlante. They have contributed immensely to my personal and pro-
fessional time at Centrale. The group has been a source of friendship as well as useful
advices and collaborations. Undertaking this PhD would not have been easy without
you guys. Particularly, I’m grateful for growing up with the other PhD students and
engineers, C´edric, Chi-Thanh, Claire, Fenni, Gautier, Qiongli, Robert, Xiujuan and
Zhongping who used to share the oﬃce with me, especially Charlotte and Marion who
have acted as families to me and helped me with the last minute preparation. I have
very much enjoyed exchanging ideas and sharing food with all of you and I can’t for-
get those seminars and conferences that we attended together. Thank you, Robert,
for those countless badminton training sessions and for taking the risk of missing your
train and being there with me waiting for the liberation and the defence report. Thank
you Samis, for all those emails that we’ve exchanged and all the fruitful discussions.
You’ve always been so helpful and provided me with your assistance throughout my
dissertation. Thank you, V´eronique, for showing me how to make measurements of
trees in China and for inviting me to supervise so many intriguing projects of fresh-
year students. Moreover, I feel particularly grateful to the senior engineer of our group
Benoˆıt who often answered my emails and requests at late hours. Thank you for being
patient and helping me to debug from time to time. I could not have been able to run
so many tests of CPF without your help.
My deep appreciation also goes out to the other members of the MAS lab. Thank
you Erick, Gilles (as well as Paul-Henry and V´eronique) for according me this job of
teaching assistant which allowed me to gain so much teaching skills and experiences

with constructive feedback. Many thanks to Annie and Sylvie who provided me with
eﬃcient help for all the administrative paperwork. I’m also thankful to the admin-
istrator of mesocenter Laurent who assisted me with parallel computation and the
optimization of the resource of mesocenter.
Finally, none of this would have been possible without the love and understanding
of my family. I’d like to say a heartfelt thank you to my parents who have raised me
up and always believe in me and support me in all my pursuits. And most of all, I
want to thank my husband Lionel, who has faithfully backed me up and encouraged
me all along, especially during the ﬁnal stage of this PhD. Thank you for being there
for me.
This project has been undoubtedly an enormous test of commitment, patience and
perseverance for me. Fortunately, I have not achieved this alone. Along the way, I
have received various help in many ways from so many people whose names are not
mentioned here. As a foreign student, I feel very lucky. I just want you to know that
these contributions have not gone unnoticed but only acknowledged with genuinely
appreciation and sincere gratitude.
Yuting C.

Abstract :
Plant growth models aim to describe plant development and functional processes
in interaction with the environment. They oﬀer promising perspectives for many ap-
plications, such as yield prediction for decision support or virtual experimentation in
the context of breeding. This PhD focuses on the solutions to enhance plant growth
model predictive capacity with an emphasis on advanced statistical methods. Our
contributions can be summarized in four parts.
Firstly, from a model design perspective, the Log-Normal Allocation and Senes-
cence (LNAS) crop model is proposed. It describes only the essential ecophysiological
processes for biomass budget in a probabilistic framework, so as to avoid identiﬁcation
problems and to accentuate uncertainty assessment in model prediction.
Secondly, a thorough research is conducted regarding model parameterization. In a
Bayesian framework, both Sequential Monte Carlo (SMC) methods and Markov chain
Monte Carlo (MCMC) based methods are investigated to address the parameterization
issues in the context of plant growth models, which are frequently characterized by
nonlinear dynamics, scarce data and a large number of parameters. Particularly, when
the prior distribution is non-informative, with the objective to put more emphasis on
the observation data while preserving the robustness of Bayesian methods, an iterative
version of the SMC and MCMC methods is introduced.
It can be regarded as a
stochastic variant of an EM type algorithm.
Thirdly, a three-step data assimilation approach is proposed to address model pre-
diction issues. The most inﬂuential parameters are ﬁrst identiﬁed by global sensitiv-
ity analysis and chosen by model selection. Subsequently, the model calibration is
performed with special attention paid to the uncertainty assessment. The posterior
distribution obtained from this estimation step is consequently considered as prior in-
formation for the prediction step, in which a SMC-based on-line estimation method
such as Convolution Particle Filtering (CPF) is employed to perform data assimilation.
Both state and parameter estimates are updated with the purpose of improving the
prediction accuracy and reducing the associated uncertainty.
Finally, from an application point of view, the proposed methodology is imple-
mented and evaluated with two crop models, the LNAS model for sugar beet and the
STICS model for winter wheat. Some indications are also given on the experimental
design to optimize the quality of predictions. The applications to real case scenarios
show encouraging predictive performances and open the way to potential tools for yield
prediction in agriculture.
Keywords: State space models; parameter estimation; data assimilation; uncertainty
analysis; yield prediction; LNAS; STICS; dynamic crop model; Markov chain Monte
Carlo methods; Sequential Monte Carlo methods; Regularized Particle Filter; Con-
volution Particle Filter; Adaptive Metropolis; Parallel and interacting Markov chain
Monte Carlo; Diﬀerential Evolution Adaptive Metropolis; Ensemble Kalman Filter.

R´esum´e :
La croissance des plantes en interaction avec l’environnement peut ˆetre d´ecrite
par des mod`eles math´ematiques. Ceux-ci pr´esentent des perspectives prometteuses
pour un nombre consid´erable d’applications telles que la pr´evision des rendements
ou l’exp´erimentation virtuelle dans le contexte de la s´election vari´etale. Dans cette
th`ese, nous nous int´eressons aux diﬀ´erentes solutions capables d’am´eliorer les capacit´es
pr´edictives des mod`eles de croissance de plantes, en particulier grˆace `a des m´ethodes
statistiques avanc´ees. Notre contribution se r´esume en quatre parties.
Tout d’abord, nous proposons un nouveau mod`ele de culture (Log-Normal Allo-
cation and Senescence ; LNAS). Enti`erement construit dans un cadre probabiliste, il
d´ecrit seulement les processus ´ecophysiologiques essentiels au bilan de la biomasse v´e-
g´etale aﬁn de contourner les probl`emes d’identiﬁcation et d’accentuer l’´evaluation des
incertitudes.
Ensuite, nous ´etudions en d´etail le param´etrage du mod`ele. Dans le cadre Bay´e-
sien, nous mettons en œuvre des m´ethodes Monte-Carlo S´equentielles (SMC) et des
m´ethodes de Monte-Carlo par Chaˆınes de Markov (MCMC) aﬁn de r´epondre aux diﬃ-
cult´es soulev´ees lors du param´etrage des mod`eles de croissance de plantes, caract´eris´es
par des ´equations dynamiques non-lin´eaires, des donn´ees rares et un nombre impor-
tant de param`etres. Dans les cas o`u la distribution a priori est peu informative, voire
non-informative, nous proposons une version it´erative des m´ethodes SMC et MCMC,
approche ´equivalente `a une variante stochastique d’un algorithme de type Esp´erance-
Maximisation, dans le but de valoriser les donn´ees d’observation tout en pr´eservant la
robustesse des m´ethodes Bay´esiennes.
En troisi`eme lieu, nous soumettons une m´ethode d’assimilation des donn´ees en trois
´etapes pour r´esoudre le probl`eme de pr´evision du mod`ele. Une premi`ere ´etape d’analyse
de sensibilit´e permet d’identiﬁer les param`etres les plus inﬂuents aﬁn d’´elaborer une
version plus robuste de mod`ele par la m´ethode de s´election de mod`eles `a l’aide de
crit`eres appropri´es. Ces param`etres s´electionn´es sont par la suite estim´es en portant
une attention particuli`ere `a l’´evaluation des incertitudes. La distribution a posteriori
ainsi obtenue est consid´er´ee comme information a priori pour l’´etape de pr´evision, dans
laquelle une m´ethode du type SMC telle que le ﬁltrage par noyau de convolution (CPF)
est employ´ee aﬁn d’eﬀectuer l’assimilation de donn´ees. Dans cette ´etape, les estimations
des ´etats cach´es et des param`etres sont mis `a jour dans l’objectif d’am´eliorer la pr´ecision
de la pr´evision et de r´eduire l’incertitude associ´ee.
Finalement, d’un point de vue applicatif, la m´ethodologie propos´ee est mise en
œuvre et ´evalu´ee avec deux mod`eles de croissance de plantes, le mod`ele LNAS pour la
betterave sucri`ere et le mod`ele STICS pour le bl´e d’hiver. Quelques pistes d’utilisation
de la m´ethode pour l’am´elioration du design exp´erimental sont ´egalement ´etudi´ees,
dans le but d’am´eliorer la qualit´e de la pr´evision. Les applications aux donn´ees exp´e-
rimentales r´eelles montrent des performances pr´edictives encourageantes, ce qui ouvre
la voie `a des outils d’aide `a la d´ecision en agriculture.

Mots cl´es : mod`ele de Markov cach´e ; estimation param´etrique ; inf´erence Bay´esienne ;
assimilation de donn´ees ; analyse d’incertitude ; pr´evision de rendement ; LNAS ; STICS ;
mod`ele de culture ; m´ethode de Monte Carlo par chaˆıne de Markov ; m´ethode de Monte-
Carlo s´equentielle ; ﬁltre particulaire r´egularis´e ; ﬁltrage par noyaux de convolution ;
Metropolis adaptatif ; m´ethode de Monte Carlo par chaˆınes de Markov en parall`ele et
en interaction ; ´evolution diﬀ´erentielle adaptative Metropolis ; ﬁltre de Kalman d’en-
semble.


Contents
Acknowledgement
5
1
Introduction
15
1.1
Background and objectives . . . . . . . . . . . . . . . . . . . . . . . . .
16
1.2
Problem formulation and contributions . . . . . . . . . . . . . . . . . .
17
1.2.1
Model design for prediction purpose . . . . . . . . . . . . . . . .
17
1.2.2
Model calibration and uncertainty assessment
. . . . . . . . . .
19
1.2.3
Model prediction with data assimilation
. . . . . . . . . . . . .
22
1.3
Dissertation outline . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
23
2
Plant Growth Models
25
2.1
LNAS model of plant growth . . . . . . . . . . . . . . . . . . . . . . . .
25
2.2
STICS model of plant growth
. . . . . . . . . . . . . . . . . . . . . . .
30
3
Preliminary - Estimation Theory
33
3.1
Estimation paradigms
. . . . . . . . . . . . . . . . . . . . . . . . . . .
33
3.2
General State-Space Models . . . . . . . . . . . . . . . . . . . . . . . .
34
3.2.1
Bayesian statistics
. . . . . . . . . . . . . . . . . . . . . . . . .
36
3.3
Monte Carlo methods . . . . . . . . . . . . . . . . . . . . . . . . . . . .
37
3.3.1
Classical Monte Carlo integration . . . . . . . . . . . . . . . . .
37
3.3.2
Importance Sampling . . . . . . . . . . . . . . . . . . . . . . . .
38
3.4
Estimators and optimization criteria
. . . . . . . . . . . . . . . . . . .
39
3.4.1
Generalized Least Squares Estimator . . . . . . . . . . . . . . .
41
3.5
Markov chain Monte Carlo methods . . . . . . . . . . . . . . . . . . . .
42
3.5.1
Markov chains . . . . . . . . . . . . . . . . . . . . . . . . . . . .
42
4
Numerical Approaches for Bayesian Estimation
47
4.1
MCMC-based algorithms . . . . . . . . . . . . . . . . . . . . . . . . . .
48
4.1.1
Metropolis-Hastings algorithm . . . . . . . . . . . . . . . . . . .
48
4.1.2
Gibbs Sampler
. . . . . . . . . . . . . . . . . . . . . . . . . . .
54
4.1.3
Metropolis-within-Gibbs algorithm
. . . . . . . . . . . . . . . .
55
4.1.4
Adapted Metropolis-within-Gibbs . . . . . . . . . . . . . . . . .
57
4.1.5
Implementation issues
. . . . . . . . . . . . . . . . . . . . . . .
62
11

12
CONTENTS
4.2
Parallel MCMC . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
68
4.2.1
Diﬀerential Evolution Adaptive Metropolis . . . . . . . . . . . .
68
4.2.2
Interacting Metropolis-within-Gibbs . . . . . . . . . . . . . . . .
71
4.2.3
Convergence criteria for multiple chains . . . . . . . . . . . . . .
73
4.3
Sequential Monte Carlo methods
. . . . . . . . . . . . . . . . . . . . .
75
4.3.1
Unscented Kalman Filter . . . . . . . . . . . . . . . . . . . . . .
77
4.3.2
Ensemble Kalman Filter . . . . . . . . . . . . . . . . . . . . . .
81
4.3.3
Particle Filter . . . . . . . . . . . . . . . . . . . . . . . . . . . .
82
4.3.4
Regularized Particle Filter and Convolution Particle Filter . . .
86
5
Iterative Approaches for State-Space Model Calibration
91
5.1
Stochastic variants of an EM-type algorithm . . . . . . . . . . . . . . .
92
5.1.1
Gaussian Randomization . . . . . . . . . . . . . . . . . . . . . .
93
5.2
Iterative SMC and MCMC . . . . . . . . . . . . . . . . . . . . . . . . .
99
5.2.1
Iterative Regularized/Convolution Particle Filtering . . . . . . .
99
5.2.2
Iterative Adapted Metropolis-within-Gibbs . . . . . . . . . . . . 101
5.2.3
Implementation issues
. . . . . . . . . . . . . . . . . . . . . . . 101
6
Uncertainty Assessment in Stochastic State-Space Models
103
6.1
Sensitivity analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 104
6.2
Evaluation of noise parameters by model selection . . . . . . . . . . . . 106
6.3
Conditional SMC and MCMC for noise parameter estimation . . . . . . 107
6.3.1
Bayesian update of noise parameters
. . . . . . . . . . . . . . . 108
6.3.2
Empirical noise parameter estimation . . . . . . . . . . . . . . . 109
6.4
Comparison of uncertainty intervals . . . . . . . . . . . . . . . . . . . . 109
6.4.1
Frequentist conﬁdence interval . . . . . . . . . . . . . . . . . . . 110
6.4.2
Bayesian credibility interval . . . . . . . . . . . . . . . . . . . . 113
6.4.3
Comparisons
. . . . . . . . . . . . . . . . . . . . . . . . . . . . 114
7
Computational implementation with PyGMAlion
115
7.1
Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 115
7.2
State-space model formulation . . . . . . . . . . . . . . . . . . . . . . . 116
7.3
Computation issues and strategy
. . . . . . . . . . . . . . . . . . . . . 117
7.3.1
Random number generation . . . . . . . . . . . . . . . . . . . . 117
7.3.2
Implementation of Inverse-Gamma priors . . . . . . . . . . . . . 117
7.3.3
Parallel simulations . . . . . . . . . . . . . . . . . . . . . . . . . 119
7.4
Ongoing work and perspective . . . . . . . . . . . . . . . . . . . . . . . 122
8
Parameter Estimation in Plant Growth Models
123
8.1
Study case description
. . . . . . . . . . . . . . . . . . . . . . . . . . . 124
8.1.1
State space model representation
. . . . . . . . . . . . . . . . . 124
8.1.2
Selection of priors . . . . . . . . . . . . . . . . . . . . . . . . . . 126
8.2
Implementation of MCMC-based methods
. . . . . . . . . . . . . . . . 127
8.2.1
Implementation descriptions . . . . . . . . . . . . . . . . . . . . 127

CONTENTS
13
8.2.2
Adapted Metropolis-within-Gibbs . . . . . . . . . . . . . . . . . 131
8.2.3
Diﬀerential Evolution Adaptive Metropolis . . . . . . . . . . . . 141
8.2.4
Interacting parallel MCMC
. . . . . . . . . . . . . . . . . . . . 148
8.3
Implementation of SMC methods . . . . . . . . . . . . . . . . . . . . . 154
8.3.1
Implementation descriptions . . . . . . . . . . . . . . . . . . . . 154
8.3.2
Regularized Particle Filter/Convolution Particle Filter
. . . . . 155
8.3.3
EnKF
. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 162
8.4
Implementation of the Generalized Least Squares method . . . . . . . . 163
8.5
Method comparison . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 164
8.5.1
Precision on one dataset . . . . . . . . . . . . . . . . . . . . . . 165
8.5.2
General behaviour and coverage comparison . . . . . . . . . . . 167
8.5.3
Inﬂuence of the modelling noise level on scarce dataset . . . . . 169
8.5.4
Eﬃciency comparison . . . . . . . . . . . . . . . . . . . . . . . . 171
8.6
Implementation of Iterative SMC and MCMC algorithms . . . . . . . . 172
8.6.1
Implementation descriptions . . . . . . . . . . . . . . . . . . . . 173
8.6.2
Iterative AMwG Vs. Iterative RPF . . . . . . . . . . . . . . . . 174
8.6.3
Strategies to increase the number of particles in the Iterative-
RPF algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . 175
8.7
Conditional iterative approach for full parameter estimation
. . . . . . 177
8.7.1
Iterative AMwG with noise updates . . . . . . . . . . . . . . . . 177
8.7.2
Iterative RPF with noise updates . . . . . . . . . . . . . . . . . 182
8.8
Estimation with real experimental data . . . . . . . . . . . . . . . . . . 189
8.8.1
Data description
. . . . . . . . . . . . . . . . . . . . . . . . . . 189
8.8.2
Bayesian approaches . . . . . . . . . . . . . . . . . . . . . . . . 190
8.8.3
Frequentist based iterative approaches
. . . . . . . . . . . . . . 196
8.9
Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 200
9
Prediction and Uncertainty Assessment with Data Assimilation
203
9.1
Three-step approach for prediction
. . . . . . . . . . . . . . . . . . . . 205
9.1.1
Parameter selection . . . . . . . . . . . . . . . . . . . . . . . . . 205
9.1.2
Parameter estimation . . . . . . . . . . . . . . . . . . . . . . . . 207
9.1.3
Data assimilation . . . . . . . . . . . . . . . . . . . . . . . . . . 207
9.2
Application to the LNAS model . . . . . . . . . . . . . . . . . . . . . . 208
9.2.1
Experimental data
. . . . . . . . . . . . . . . . . . . . . . . . . 208
9.2.2
Results and method comparison . . . . . . . . . . . . . . . . . . 209
9.2.3
Inﬂuence of the noise level . . . . . . . . . . . . . . . . . . . . . 221
9.2.4
Impact of the calibration precision
. . . . . . . . . . . . . . . . 223
9.2.5
Data assimilation with UKF and EnKF . . . . . . . . . . . . . . 227
9.2.6
Inﬂuence of the number of assimilated data . . . . . . . . . . . . 228
9.2.7
Inﬂuence of the number of updated parameters
. . . . . . . . . 230
9.2.8
Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 231
9.3
Application to the STICS model . . . . . . . . . . . . . . . . . . . . . . 233
9.3.1
Experimental data
. . . . . . . . . . . . . . . . . . . . . . . . . 233

14
CONTENTS
9.3.2
Results and method comparison . . . . . . . . . . . . . . . . . . 234
9.4
Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 236
10 Discussion and Perspective
241
10.1 Contributions and results . . . . . . . . . . . . . . . . . . . . . . . . . . 241
10.1.1 Model design
. . . . . . . . . . . . . . . . . . . . . . . . . . . . 241
10.1.2 Parameter estimation and uncertainty assessment . . . . . . . . 242
10.1.3 Data assimilation approach
. . . . . . . . . . . . . . . . . . . . 245
10.1.4 Application with real experimental data
. . . . . . . . . . . . . 248
10.2 Perspectives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 248
10.2.1 Modelling Uncertainty . . . . . . . . . . . . . . . . . . . . . . . 248
10.2.2 Estimation Methods
. . . . . . . . . . . . . . . . . . . . . . . . 251
10.2.3 Data assimilation applications . . . . . . . . . . . . . . . . . . . 252
Publications
255
Annexes
257
Notations
259
Bibliography
261

CHAPTER 1
Introduction
P
lant growth modelling has become a key research subject in the ﬁeld of agriculture,
forestry and environmental science. In an interdisciplinary research landscape, the
development of plant growth models has made considerable progress in the past two
decades, thanks to the eﬀorts made by biologists, mathematicians, computer scientists
and the growing computation resources.
The main objective of plant growth modelling is to reproduce the growth of plants
in interaction with the environment. It has a huge potential for many applications,
such as to perform yield prediction in a qualitative and quantitative way for decision
support, or by testing hypotheses and conducting virtual experiments to optimize the
use of limited energy resources, which could otherwise take years in ﬁeld conditions.
All of these applications require plant growth models with accurate descriptions of
the plant growth process as well as eﬃcient mathematical and statistical methods to
perform the parameterization and the prediction.
However, a major challenge for plant growth modelling is to keep up with the
progress made in the related scientiﬁc domains (Fourcaud et al., 2008). This is espe-
cially diﬃcult when it comes to the development of mathematical and statistical tools
which play an essential role in a good practice of modelling, for most of the methods
are developed outside of the plant growth model framework.
Therefore, this thesis encompasses the essential core steps of modelling, including
model design, sensitivity analysis, model calibration (also known as parameterization),
model selection, uncertainty analysis, model prediction and eventually design of exper-
iments. The objective is to enhance the predictive capacity of plant growth models.
In the following, we ﬁrst present the background of the prediction problem in plant
growth modelling. An overview of the development of plant growth models and the
statistical methods used is given. The problems of interest and the focus of this thesis
are subsequently detailed.
15

16
1.1. BACKGROUND AND OBJECTIVES
1.1
Background and objectives
To improve or even to optimize the predictive capacity of plant growth models in
various environmental contexts has been a long-standing challenge. A common idea is
to enrich the mechanistic description of plant ecophysiology (Yin and Struik, 2010).
With this purpose, particular eﬀorts have been made to take into account abiotic
stresses regarding temperature (e.g. Fowler et al. (2003)), water (e.g. Tardieu (2003)),
or Nitrogen (e.g. (Bertheloot et al., 2011)). Some advanced agro-environmental mod-
els even aim at addressing the full diversity of environmental variations, like STICS
(Brisson et al., 2003) or APSIM (Keating et al., 2003). However, the complexity of
the interaction between processes can make the task rather diﬃcult. Particularly in
the case when several stresses are involved, it is delicate to describe the mixed eﬀects
of these combined stresses (Mittler, 2006). Hence, most models simply consider mul-
tiplicative stresses or a general stress value given by the maximal stress eﬀects. As
described by Yin and Struik (2010), the tendency is still to complicate the mechanistic
description of biophysical processes, even by linking ecophysiology to “omics” sciences
as an attempt for the full comprehension of the regulatory networks from which plant
robustness and plasticity is supposed to emerge (Hirai et al., 2004), whilst a robust
description appears diﬃcult to achieve at the cell or tissue level.
This direction is clearly leading the way to great advances in research, especially
in extending our understanding of how genotype leads to phenotype (Buck-Sorlin and
Bachmann, 2000; Hammer et al., 2006; Yin and Struik, 2010). However, the objective
of improving the prediction quality relies not only on providing an accurate prediction,
but also on an appropriate assessment of the uncertainty, and further on reducing the
uncertainty associated to the prediction.
It is obvious that the more complex the models are, the more troublesome their
parameterization and the assessment of the estimate uncertainty become (Chen and
Courn`ede, 2012; Ford and Kennedy, 2011), speciﬁcally due to the costly experimen-
tation and the great number of unknown parameters to consider.
This is thus an
important drawback of this approach of building sophisticated models. Likewise, lo-
cal environmental conditions (in terms of climatic and soil variables, as well as biotic
stresses) and initial conditions in speciﬁc ﬁelds are also very delicate to characterize.
Consequently, it may raise important issues regarding the identiﬁability of the param-
eters, the assessment of the confounding noises and the propagation of uncertainty
and errors related to both parameters and inputs of these dynamic models. Failing
to address these issues may ﬁnally result in poor predictions of plant-environment
interactions in real situations, that is to say the opposite of the pursued objective.
Therefore, considering the lack of suﬃcient data assimilation approaches putting
proper emphasis on the uncertainty assessment for prediction, the objective of this
thesis is to propose a full methodology in a probabilistic framework for plant growth
model prediction. This approach should be robust, eﬃcient, adapted to the speciﬁc
characteristics of plant growth models (nonlinear dynamics, restricted and irregular
observation data) and provide a proper evaluation of the model uncertainties with the
aim of reducing those associated to the prediction.

CHAPTER 1. INTRODUCTION
17
For this purpose, our research mainly focuses on three directions. The ﬁrst concerns
the design of an adequate model for prediction, then we are interested in the methods
to perform a proper parameterization of the model with an emphasis on the reliable
uncertainty assessment. Finally, the implementation of the data assimilation technique
is investigated with the objective to improve the predictive capacity of plant growth
models in general.
1.2
Problem formulation and contributions
1.2.1
Model design for prediction purpose
Pioneer studies carried out on data assimilation approach were aiming at speciﬁc
farming conditions. A combination of a crop model and the data assimilation technique
was used to update the model variables and / or parameters based on the observed data
of early growth stages (Bouman, 1992; Del´ecolle et al., 1992; Maas, 1988; Moulin et al.,
1998). This approach was particularly developed following the progress in deriving
biophysical and biochemical canopy state variables from optical remote sensing (Dorigo
et al., 2007), which could potentially give way to crop production forecast at large scales
(Moran et al., 1997) and thus be considered as a tool for decision support (Gabrielle
et al., 2002; Houl`es et al., 2004).
The conventional strategy for prediction purpose is to employ reference models
like SUCROS (Gu´erif and Duke, 1998, 2000; Launay and Gu´erif, 2005) or CERES
(Dente et al., 2008) as the framework to integrate the remotely sensed observations to
enhance the prediction quality. A few methods were developed under this perspective
(see Dorigo et al. (2007) for a review). The forcing method consists in replacing a state
variable of the model by the observed data, for instance the Leaf Area Index (LAI) in
(Del´ecolle et al. (1992); Dente et al. (2008)). One important drawback is that generally
a considerable part of the model state variables cannot be or are not observed and thus
cannot be updated simultaneously at each time step. Moreover, the method does not
take into account the observation error, which should not be neglected considering the
general lack of accuracy of remote sensing data.
Another possibility is to use the available observation data to recalibrate some
model parameters and / or initial states that may presumably vary with local condi-
tions (Bouman, 1992; Gu´erif and Duke, 2000; Launay and Gu´erif, 2005). The main
limitation of this method is that it requires suﬃcient data to perform the calibration,
which is often costly and diﬃcult to obtain. Besides, the global approach of this cali-
bration step usually fails to capture and to maintain the system dynamics and thus is
unable to improve the prediction accuracy.
On the other hand, it is noteworthy that in other research domains, data assimi-
lation problems have been commonly reformulated and studied with a Bayesian prob-
abilistic perspective, which allows the sequential estimation of model states and pa-
rameters simultaneously (Van Leeuwen and Evensen, 1996; Jazwinski, 1970) in the
framework of generalized state-space models.
In the light of these applications, the ﬁrst attempt to adapt a relatively simple

18
1.2. PROBLEM FORMULATION AND CONTRIBUTIONS
crop model into this perspective was made by Makowski et al. (2004). The method
implementation relies on a probabilistic framework of crop model which is used to
derive prior distributions of the model state variables and parameters at time steps
with available observations while taking into account uncertainty in model prediction.
Conditionally to the experimental observations and the observation error, posterior
distributions are deduced according to Bayes’ rule. An updated prediction of the model
state variables can thus be inferred. The procedure is repeated at all measurement
dates. Classical estimation methods used for this purpose are Ensemble Kalman Filter
(see Evensen (2006) for the general presentation of the method, and Jones and Graham
(2006) for an application in the context of crop models) or Particle Filter (see for
example Kitagawa (1996) for the general concepts, and Naud et al. (2007) for an
application in the context of crop models).
Nonetheless, one of the diﬃculties to implement this approach comes from the fact
that it requires the plant growth model as well as the measurement model described
in a probabilistic framework, as a hidden Markov model (Capp´e et al., 2005). The
classical and complex crop models (like STICS (Brisson et al., 1998), APSIM (Keating
et al., 2003), CERES (Jones and Kiniry, 1986) ...) were not built in this perspective
and their stochastic reformulation is therefore far from straightforward: the large num-
ber of involved processes may potentially lead to a drastic increase in the number of
parameters to model process errors. One simple solution to circumvent this problem
is to only consider observation errors (Gu´erif et al., 2006), but it may hinder a proper
update of hidden state variables.
The above examples demonstrate the importance of having an appropriate model
design to enhance the predicting performance. An adequate level of complexity may
allow us to describe the principal plant development and functional process in in-
teraction with the environment, while retaining the identiﬁability of the underlying
parameters. Moreover, the model is better described in a probabilistic framework, so
that the uncertainty evaluation can be carried out in an easier way.
By keeping these key points in mind, a new plant growth model describing biomass
budget in crops is proposed in this thesis, with the particularity of being fully built in
a probabilistic framework. Based on the analysis of Del´ecolle et al. (1992), we simplify
the model description while retaining the major ecophysiological processes (at least in
terms of Carbon economy): biomass production, biomass allocation, senescence and
leaf surface development. The restriction of the model description to the fundamental
processes allows an easier representation of the model errors without increasing signif-
icantly the number of parameters. The model is named LNAS (Log-normal allocation
and senescence) in reference to the empirical functions of the (cumulative) Log-normal
distribution employed to model allocation and senescence processes.
Although the
parameters of these functions are no longer supposed to be from genetic origin only,
the adopted assumption is that the empirical functions describing the ecophysiological
processes are ﬂexible enough to adapt, and robust enough so that the mean prediction
remains pertinent.
Currently the LNAS model is used to study simple crops such as sugar beet, maize,
sunﬂower and wheat.

CHAPTER 1. INTRODUCTION
19
1.2.2
Model calibration and uncertainty assessment
The parametrization and the predictive capacity of plant growth models are con-
sidered to be complex and critical issues which are highly correlated.
Frequentist approaches
Facing limited and unevenly distributed measurements, important number of unknown
parameters and complex interactions among compartments described in plant growth
models, many studies are dedicated to tackle the parameterization problem in liter-
ature.
Both frequentist and Bayesian approaches are considered.
Yet most of the
work put more emphasis on the model construction and the biological interpretation
of the results, whereas the parameter estimation is usually performed with a simple
frequentist approach with little attention to the uncertainty assessment. For instance,
Zhan et al. (2003) and Guo et al. (2006) performed parameter estimation for the
Greenlab models by minimizing an Ordinary Least-Squares criterion for applications
to unbranched plants, such as cotton and maize, so is the case of de Reﬀye et al. (1999),
who carried out a preliminary calibration for a hydraulic growth model for cotton. We
could say that the objective in these studies is more about data ﬁtting than parameter
estimation.
However, with the increasing complexity of the considered models, nonlinear esti-
mators are in great needs, as in the case of Hillier et al. (2005), who used a Generalized
Nonlinear Least Square estimator with a maximum likelihood criteria and two Boot-
strap methods to ﬁt plant organ growth models. As a transition, Makowski et al.
(2006) gave a general presentation of parameter estimation in crop models, in which
the description of several more advanced estimation methods are presented including
some basic Bayesian methods.
The ﬁrst advantage of Bayesian methods is that they allow to take into account
the prior knowledge. Indeed, although the experimental data are often restricted due
to high costs, there is usually additional information available regarding the param-
eters of plants growth and development processes, speciﬁcally when they have clear
biophysical interpretations. Hence, the estimation problem can be characterized as
using experimental data to update the prior knowledge of the plant growth with the
Bayesian philosophy. In this way, the weight of the observed data is limited and the
estimation obtained is more interpretable.
Moreover, the Bayesian approaches provide a probability distribution as estimation
for the unknown parameter which is opposite to the point estimation of the frequentist’s
philosophy. Therefore, not only the Bayesian approaches are capable of reconstructing
the system by estimating simultaneously model parameters and unobservable state
variables, but also they allow to evaluate the uncertainty related to the estimated
model parameters and to identify the uncertainties stemming from other sources. In
this way, the uncertainties can be handled properly and taken into account for the
prediction process in order to achieve better prediction accuracy and reliable corre-
sponding conﬁdence intervals. These are very desirable features for estimation and
prediction (data assimilation) problems in the context of plant growth models, which
explain why sequential data assimilation techniques, especially the Bayesian ﬁltering

20
1.2. PROBLEM FORMULATION AND CONTRIBUTIONS
methods have received considerable attention to deal with similar applications in other
research areas (Anderson, 2001; Reichle et al., 2002; Mattern et al., 2013).
Yet despite all these desirable features, few eﬀorts have been made to employ
more sophisticated Bayesian approaches to solve plant growth models’ parameteri-
zation problem. For example, Makowski et al. (2002) conducted a comparison be-
tween Generalized Likelihood Uncertainty Estimation method (GLUE) and a MCMC
based method, the Metropolis-Hastings, for parameter estimation and Gaucherel et al.
(2008) compared Particle ﬁltering and a MCMC based method in the application to
a process-based tree-growth model. Loi et al. (2011) introduced the ﬁrst application
of the ﬁltering methods (Unscented Kalman Filter and Particle Filter) to a GreenLab
model for Bayesian estimations. The comparison of these two methods can be found
in (Loi, 2011).
Markov chain Monte Carlo based approaches
The Markov chain Monte Carlo (MCMC) based methods are very popular numerical
approximations for Bayesian inference, which make the estimation of posterior dis-
tributions feasible in practice. However, some complex implementation issues can be
encountered due to the speciﬁcity of plant growth models. First of all, the eﬃciency
of the chain depends a lot on the proposal distribution. To tune the proposal distribu-
tion continuously, an adaptive scheme is proposed by Haario et al. (2001). Moreover,
as pointed out by Geyer (1992), independent Markov chains may result in pseudo-
convergence due to the multimodality of the target distribution. It seems that there
is no satisfactory analytical tool to distinguish the pseudo-convergence from the real
convergence, the only reliable way is to run the chain long enough, the strategy is
thus known as “one long run”. For this reason, the algorithm is very time consuming.
Furthermore, if we aim at the joint estimation of both hidden states and unknown
parameters, a poor mixing due to strong correlations between the two may result in
very poor performance of the estimation (Liu et al., 1994; Roberts and Sahu, 1997).
A possible solution to improve the mixture properties as well as the eﬃciency of the
estimation is to make diﬀerent copies of the same Markov chain and let them inter-
act with each other, the strategy is known as ”many short runs”. Two well known
algorithms developed in this perspective are the Interacting parallel MCMC (Campillo
et al., 2009) and the Diﬀerential Evolution Adaptive Metropolis (DREAM) (Vrugt
et al., 2009a). Therefore in this thesis, both strategies are investigated when applied
to a plant growth model. In addition, a new Adapted Metropolis-within-Gibbs algo-
rithm is proposed to cope with the mixing properties of the plant growth model in
order to estimate both the hidden states and unknown parameters.
Note that given the iterative nature of MCMC-based methods, which means that
they process all the observation data repeatedly, they are often regarded as oﬀ-line
estimation approaches: when a new observation is available, the MCMC based methods
have to run from the start again without being able to conserve the samples obtained
formerly.
Sequential Monte Carlo approaches
Sequential Monte Carlo (SMC) methods are a set of simulation-based methods which

CHAPTER 1. INTRODUCTION
21
provide a convenient approach to compute the posterior distributions. The most repre-
sentative methods of the SMC family are the ﬁltering methods. Unlike MCMC-based
approaches, ﬁltering methods are performed in a sequential way. They are able to take
into account the variation of parameters over time and carry out real-time updating,
which is why they are known as on-line estimation methods.
The most eﬃcient ﬁltering method when dealing with linear systems is the Kalman
ﬁlter (Kalman, 1960). To date, many eﬀorts have been made to develop extensions
of the Kalman ﬁlter for nonlinear systems. The most well known are the Extended
Kalman Filter (EKF) (Evensen, 1994), the Unscented Kalman Filter (UKF) (Julier and
Uhlmann, 1997; Quach et al., 2007) and the Ensemble Kalman Filter (EnKF) (Evensen,
1994). The EKF simply linearizes locally the model so that the traditional Kalman
ﬁlter can be applied.
However, when the nonlinearity is signiﬁcant, it may cause
divergence and the method proves to be no longer reliable. On the other hand, the
UKF adopts deterministic sampling aiming at using a small set of discretely sampled
points, known as sigma-points (Julier et al., 2000; Wan and Van Der Merwe, 2000),
to get hold of the information of higher order for both the mean and the covariance
matrix. But it performs poorly when confronting large scale nonlinear models because
of its dependence on the Gaussian assumption and its limited sample size. The EnKF
relies on normality assumptions in order to improve the accuracy of its estimates with
a more important number of samples compared to the UKF. Both latter methods
generalize to nonlinear systems in an elegant way without relying on the linearization
required by the EKF.
Another important approach is the Particle Filtering (PF). Unlike the Kalman ﬁl-
ter based methods, PF uses a set of randomly drawn samples with each an associated
weight to represent the probability distribution of the hidden states and parameters
conditioned on a series of observations. During decades, the development of PF-based
methods has thrived since the Sequential Importance Sampling (SIS). The main weak-
ness of SIS is the potential weight degeneracy (Arulampalam et al., 2002) and sample
impoverishment (Gordon et al., 1993). Gordon et al. (1993); Kitagawa (1996) pro-
posed a similar method, the Sequential Importance Resampling (SIR), by introducing
the idea of resampling, which allows to overcome the degeneracy problem in most of
the cases. Comparing to the Kalman-based ﬁlters, the PF-based methods have the
advantage of being able to better predict nonlinear growth behaviours, for example,
occasional skewness resulting from sudden or unusual climate changes.
Although the literature on the PF methods is considerably rich, the Convolution
Particle Filter (CPF) (Campillo and Rossi, 2009; Musso and Oudjane, 1998; Rossi
and Vila, 2006) which can be regarded as a generalization of the regularized particle
ﬁlter proposed by Musso and Oudjane (1998), stands out for its attractive features
regarding the challenges raised by parameter estimation and data assimilation of crop
models. Firstly, the method is not only rather easy to adapt (with very few tuning
parameters), but also robust in terms of convergence since it circumvents the classical
problem of potential weight degeneracy in the SIR when the parameter identiﬁcation
issues occur. This property is valuable in classical ﬁeld experimentations for which
irregular or heterogeneous data are available. When these models are formalized as
state-space hidden Markov models, the CPF can achieve a proper evaluation of model

22
1.2. PROBLEM FORMULATION AND CONTRIBUTIONS
uncertainty. Another interesting feature is that it works as well with deterministic
models, which also makes the method straightforwardly adaptable to the classical and
widely used crop models.
In this thesis, the above Bayesian approaches are used for model calibration of the
LNAS model derived for sugar beet growth. Their performances are compared with
both simulated data and real experimental data.
Iterative approaches
When the prior is non-informative and few observation data are available, it is prefer-
able to put more weight on the data. Intuitively, an iterative approach is proposed
in this thesis which can be regarded as a variant of Expectation-Maximization (EM)
algorithm. The EM algorithm Dempster et al. (1977) is generally used to ﬁnd the
maximum-likelihood estimate of the parameters of an underlying distribution based
on a dataset which is incomplete or has missing values, which corresponds to our
case of rare and irregular experimental data. Some recent eﬀorts to obtain appropri-
ate stochastic EM-type algorithms for complex models arising in plant growth model
applications can be found in Trevezas and Courn`ede (2013).
In contrast to classical stochastic variants (Celeux and Diebolt, 1985; Wei and
Tanner, 1990; Delyon et al., 1999), in this thesis we present a simple way of turning a
non-explicit M-step into an explicit one. Both MCMC based methods and SMC based
methods are chosen to perform the E-step. We mention that until now the use of this
type of Particle Filter was restricted to Bayesian type of estimation.
Consequently, the uncertainty related issues are mainly discussed, especially re-
garding the noise parameter calibration. The robustness of this iterative approach is
examined with the application to LNAS model derived for sugar beet growth, based
on both simulated data and real experimental data.
Implementation with PyGMAlion
All the methods and models tested in this thesis are implemented in the modelling
platform PyGMAlion (Plant Growth Model Analysis, Identiﬁcation and Optimization)
(Courn`ede et al., 2013), which can be seen an attempt to promote a modelling frame-
work and model analysis methods with the objectives of enhancing good modelling
practices and increasing model design eﬃciency.
1.2.3
Model prediction with data assimilation
On-line estimation methods for model prediction
As stated previously, unlike the MCMC based methods, the ﬁltering methods have the
advantage of processing sequentially. This is a very attractive feature, for it enables
the real-time updates for model prediction. New observed data can be assimilated
to re-adjust the calibration of the model suﬃciently without the need of eliminating
all the previous estimations as the MCMC based methods do. In addition, both the
model error and observation error can be quantiﬁed in the prediction process, which

CHAPTER 1. INTRODUCTION
23
is why the ﬁltering methods are particularly suited to perform model prediction with
uncertainty assessment.
Three-step approach for model prediction
In this thesis, we intend to provide a clear view about the numerical methods available
to tackle the parameter estimation and yield prediction problem with both determinis-
tic and stochastic plant growth models built with diﬀerent perspectives, while putting
a special emphasis on the uncertainty assessment.
Inspired by the various applications mentioned above, a full methodology to per-
form data assimilation with plant growth model is proposed in this thesis. A three-step
data assimilation approach is proposed to address the model prediction problem :
– Parameter selection : the most inﬂuential parameters are identiﬁed by global
sensitivity analysis and selected by model comparison.
– Model calibration : the unknown parameters are estimated either with a Bayesian
perspective (with Sequential Monte Carlo (SMC) methods or Markov chain
Monte Carlo (MCMC) methods), or with a frequentist perspective (with an iter-
ative version of the previous Bayesian methods) from on a experimental dataset.
The uncertainty analysis is as well conducted to identify various sources of noises
and determine the conﬁdence interval associated to the parameter estimates if the
iterative approaches are employed. Although various estimation methods oﬀer
many options, according to the characteristic of the considered model, estimation
strategies are summarized.
– Prediction with data assimilation : the ﬁltering methods are carried out to ben-
eﬁt from the available data of early growth stages with regular updates of the
state and parameter estimates obtained from the calibration step. The objective
is to improve the prediction accuracy as well as to reduce the associated uncer-
tainty. The prediction conﬁdence interval can thus be derived from the posterior
distribution.
This approach is applied to both the STICS model for winter wheat growth and
the LNAS model for sugar beet growth.
1.3
Dissertation outline
In Chapter 2, we introduce a new model, the LNAS model, which is designed in the
purpose of performing model prediction with an emphasis on uncertainty assessment.
We also provide a brief overview of the main principles of the STICS model, which is
one of the most classical crop models. It represents another modelling philosophy by
enriching the description of growth processes.
As mentioned above, most of the estimation methods employed in the thesis are
considered under a Bayesian framework.
Therefore, basic notions and concepts of
Bayesian inference are recalled in Chapter 3, some classical algorithms of both MCMC
based approaches and SMC approaches are presented in chapter 4.

24
1.3. DISSERTATION OUTLINE
A methodological contribution of this thesis is detailed in Chapter 5, proposing
a variant of the EM-type algorithm using SMC and MCMC based methods to per-
form the E-step. Chapter 6 describes the approaches adopted to perform uncertainty
assessment for stochastic models Subsequently, the numerical implementation of the
algorithms mentioned as well as the PyGMAlion modelling platform are presented in
Chapter 7.
In Chapter 8, the Bayesian methods and the frequentist-based methods are ap-
plied to LNAS to perform parameter estimation with both simulated datasets and
experimental dataset. The objective is to identify their performance with diﬀerent
conﬁgurations and in various modelling conditions. Note that both functional param-
eters and (observation and modelling) noise parameters are taken into account, and
the corresponding implementation is detailed and estimation results are discussed.
Subsequently, a three-step approach is proposed in Chapter 9 to address prediction
problems in plant growth models of diﬀerent types. The approach is applied both to
the stochastic LNAS model for sugar beet and to the deterministic STICS model for
winter wheat. In order to test the predictive capacity of the model in various situations
as well as its pertinence to evaluate the associated uncertainty, real experimental data
are used for validation. An introduction to optimal design of experiments is given
to select the best experimental conﬁgurations with the objective of improving the
prediction quality while taking into account the experimental cost.
Finally, Chapter 10 summarizes all the results, the methods and the proposed
selection strategies are discussed. Some perspective are presented and possible future
research directions are outlined.

CHAPTER 2
Plant Growth Models
In this chapter, we present the two plant growth models studied in this thesis.
Both models belong to the category of crop models. They describe the crop growth at
compartment level, per unit of land surface area.
The LNAS model is developed as a simpliﬁcation of the GreenLab model (de Reﬀye
et al., 2003), but with a probabilistic perspective in the form of hidden Markov models.
We highlight the fact that the LNAS model can also be derived at individual scale. In
our study, it is speciﬁcally derived for the sugar beet growth.
On the contrary of the LNAS model, the second model considered is a classical one,
the STICS model. It is deterministic and is well known for its detailed description of
plant-environment interactions. In this study, it is derived for the winter wheat growth.
2.1
LNAS model of plant growth
For data assimilation purpose, a general scheme for agrosystem models was given
by Del´ecolle et al. (1992) and adapted by Dorigo et al. (2007). They underlined the
main ecophysiologcal processes and key variables to describe the interaction between
plants and their environment. We adapt this scheme to the sugar beet case in Fig.
2.1. The principal processes they suggested to consider are crop development, light
interception, biomass accumulation, biomass partitioning and senescence.
A speciﬁcity of the LNAS model is that the main growth processes underlined in
Fig. 2.1 are considered as stochastic processes when it appears relevant. The version
presented does not detail how nitrogen, temperature and water stress eﬀects are taken
into account in the model, classical functions borrowed from Sunﬂo (Lecoeur et al.,
2011), STICS (Brisson et al., 2008) and Pilote (Mailhol et al., 1997) can be used, when
necessary.
We believe that a realistic plant growth model should include the variability in-
25

26
2.1. LNAS MODEL OF PLANT GROWTH
Figure 2.1: General scheme of an agroecosystem model for sugar beet (adapted from
Del´ecolle et al. (1992) and Dorigo et al. (2007)).
volved in the way that the plant evolves (modelling noise, also known as process noise
or state noise), as well as the variability regarding the estimation of the true value of the
state of interest (observation noise) (de Valpine, 2002; Donnet et al., 2010), for there
are multiple stochastic factors, including environmental noises and inter-individual
variability, that are inherent in the plant functional growth processes. These noises
are generally considered independent of the errors resulted from the sampling meth-
ods or from the observations (Dennis et al., 2006).
Generally speaking, more and
more models tend to take into account the observation noise (Hilborn and Ledbetter,
1979; Polacheck et al., 1993), but not the modelling noise, mostly for computation
convenience. Nonetheless, if process noises are present in reality, then omitting them
while building a model will lead to important bias in the likelihood function. Without
modelling noise, the ﬁt of the model is measured by only one trajectory (evolution
of the state variables) that might have produced the data. This could result in bias
in parameter estimation (Ludwig and Walters, 1981; de Valpine and Hastings, 2002;
Schnute, 1995). By taking into account the modelling noise, an important range of
trajectories that could have produced the data are incorporated in the ﬁtting process.
For the reasons mentioned above, it seems to be a more reasonable conﬁguration for
plant growth, which is why we opt for including both observation noise and modelling
noise in our model.
Note that adaptations of the model are currently derived for maize, wheat and
sunﬂower, and the equations can be adapted to other type of plant without diﬃculty
by adding other types of compartments.
In the following, we present the equations of the Log-Normal Allocation and Senes-

CHAPTER 2. PLANT GROWTH MODELS
27
cence (LNAS) model speciﬁcally derived for the sugar beet, per unit surface area, with
two organ compartments: foliage and root system. The time step is one day and the
environmental variables are daily averages.
Interception and assimilation:
Q(t) is the biomass production on day t per unit
surface area (g.m−2) which can be obtained by an adaptation of the Beer-Lambert law
(Monteith, 1977):
 1 −e−λ·Qg(t)
represents the fraction of intercepted radiation, with
Qg(t) the total mass of green leaves on day t (in g.m−2) and λ a parameter deﬁned in
g−1.m2. The biomass production of the whole plant is then deduced by multiplying
the total amount of absorbed photosynthetically active radiation per unit surface area
(PAR, in MJ.m−2) and an energetic eﬃciency µa (in g · MJ−1·):
Q(t) =
 µa · PAR(t)
 1 −e−λQg(t)
· (1 + ηQ(t))
(2.1)
where we introduce the modelling noise ηQ ∼N(0, σ2
Q). Since the characterization of
the environmental variables and of the light interception is not accurately described by
the Beer-Lambert law, the model noise appears relevant for the production equation.
Despite the fact that Q(t) should always be positive, we still use a normal law. With
the multiplicative form and the levels of noise generally considered (inferior to 10%),
there is no problem of positivity loss.
The parameter λ corresponds to λ = k SLA, where k is the Beer-Lambert extinc-
tion coeﬃcient and SLA is the speciﬁc leaf area, so that the term
 1 −e−λQg(t)
can
classically be rewritten as
 1 −e−k LAI
, with LAI the leaf area index. There is a
slight diﬀerence in the formulation however, because we consider λ as an empirical
constant parameter, whereas linking leaf mass to leaf surface via the SLA variable is
not obvious since the SLA is known to vary during crop growth and within plants
(see for example Jullien et al. (2009)), even though it is often regarded as constant in
models. This simpliﬁcation also allows us to avoid the diﬀerentiation between blades
and petioles (which is not always easy from a botanical point of view in sugar beet),
both constitute the leaf compartment.
Allocation
to the foliage and root system compartments:
The description of the allocation process is a simpliﬁcation of the GreenLab model
(Yan et al., 2004; Guo et al., 2006) with the organ sink dynamics being described at
compartment level: the proportion of biomass allocated to each compartment (foliage
and root) is described by an empirical function γ:
Qf(t + 1) =
Qf(t) + γ(t) · Q(t)
(2.2)
Qr(t + 1) =
Qr(t) + (1 −γ(t)) · Q(t)
(2.3)
where
γ(t) = Γ(t) · (1 + ηγ(t))
= (γ0 + (γf −γ0) · Ga(τ(t))) · (1 + ηγ(t))
(2.4)

28
2.1. LNAS MODEL OF PLANT GROWTH
with τ(t) the thermal time, which corresponds to the accumulated daily temperature
(above a threshold temperature, which is taken as 0 for the sugar beet (Lemaire et al.,
2008)) since emergence day.
Ga denotes the cumulative distribution function of a
log-normal law parameterized by its median µγ and standard deviation σγ (for more
explicit biological meanings of the parameters). γ0 and γf correspond to the initial
and ﬁnal proportion of biomass allocated to the leaf compartment respectively (Figure
2.2).
The modelling noise (process noise) is denoted by ηγ(t) ∼N(0, σ2
γγ).
The
cumulative distribution of the log-normal law is chosen for its ﬂexibility: it allows to
reproduce dynamics similar to the sigmoid-type functions often employed to describe
biological processes, while having the advantage to start with a null value on zero. The
transformation chosen to obtain γ is inspired by the simulation of biomass allocation
to root and leaf compartments of sugar beet described by SUCROS (Spitters et al.,
1989) and GreenLab (Lemaire et al., 2008).
Figure 2.2: The cumulative distribution function Ga and the resulting allocation func-
tion γ, with the initial proportion of biomass allocated to the leaf compartment (γ0)
0.9, and the ﬁnal proportion of allocation (γf) 0.2.
The allocation strategy is very sensitive to environmental conditions, therefore we
introduce a multiplicative perturbation, again following a Gaussian law.
Senescence:
The senescent foliage mass Qs is a proportion of the accumulated fo-
liage mass given by the cumulative distribution of a log-normal law of median µs and
standard deviation ss:
Qs(t) = Gs(τ(t) −τsen)Qf(t)
(2.5)

CHAPTER 2. PLANT GROWTH MODELS
29
with τsen the thermal time at which the senescence process initiates. The green foliage
mass Qg can be hence obtained easily:
Qg(t) = Qf(t) −Qs(t)
(2.6)
We choose a deterministic version of the senescence equation despite the strong varia-
tions that can characterize the process. As a matter of fact, the inﬂuence of senescence
in the biomass budget is due to the decrease of photosynthetic foliage in Equation (2.1),
adding a perturbation in the senescence mass either would be of second order or could
be summarized in the modelling noise ηQ.
Figure 2.3: The evolution of the senescence function with the initial proportion of
senescent biomass 0.0, and the ﬁnal proportion 0.85.
The gray part refers to the
unobserved thermal time.
Note that both allocation and senescence processes are driven by the thermal time.
The phenological stage in Fig. 2.1 is thus simply represented in our model by the
course of the thermal time, from emergence.
Observations:
As described in the next paragraph, the general state space mod-
els considered in this study describe observation equations in addition to the state
equations. In our study, the observation variables potentially available from ﬁeld mea-
surements for data assimilation are:
Y (t) =
 Qg(t) · (1 + ξg(t))
Qr(t) · (1 + ξr(t))

(2.7)
with measurement noises: ξg(t)) ∼N(0, σ2
g), and ξr(t) ∼N(0, σ2
r).
We remark that in the LNAS model, multiplicative Gaussian noise structure is
adopted for both the modelling and observation noises. This choice is justiﬁed since the
scale of measurement varies greatly across time (from 0.01g to 250g for one plant), an
additive noise would have clearly led to some diﬃculties regarding the risk of positivity

30
2.2. STICS MODEL OF PLANT GROWTH
loss or a misrepresentation of the complex measurement process (plants cutting, drying,
weighing, averaging on large samples). With a multiplicative form of the noise and
with the standard deviation of the modelling (respectively observation) noise usually
around 5% (resp. 10% for observation noise) and always below 15% (resp. 20%), the
probability for a random variable following a Gaussian distribution N(0, 0.22) to be
inferior to -1 (in order to cause positive loss) is 2.9 10−7. Therefore, the probability of
obtaining a negative value is extremely small. There are undoubtedly other advantages
of choosing a Gaussian distribution, for instance the symmetry (which is surely shared
by many other distributions), the simpliﬁcations in maximum likelihood inference, the
easy simulation process and its robustness.
However, other distributions could have been possible such as the log-normal dis-
tribution, speciﬁcally to prevent positivity loss. Both log additive or log multiplicative
noise can be considered.
Another important point is that the proposed framework would still be applicable
when satellite image data are used for LAI evaluation. In that case, LAI should be
speciﬁed clearly as a state variable in the system (with an explicit formulation of the
SLA variable), and a corresponding observation function should be deﬁned.
2.2
STICS model of plant growth
The STICS model (Brisson et al., 2003) focuses on the crop-soil system and has
already been applied to various crops. It is divided into several modules with each
representing diﬀerent plant growth mechanisms (Brisson et al., 2008). Among them,
the development module is in charge of the evolution of the LAI and root compartment,
and in the meantime deﬁnes the harvested organ ﬁlling phase. Fig. 2.4 illustrates the
main processes involved in the STICS model adapted to the winter wheat crop.
Contrary to LNAS which is based on a biomass budget, the growth in STICS is
driven by an empirical law for the LAI growth. Three phases are involved, the ﬁrst
phase (from emergence to the maximal LAI point) is approached by a logistic function
with the hypothesis that the ratio of biomass between leaves and stems is constant,
followed by a stabilized phase and a senescent phase of linearly decreasing LAI. Several
stress factors limit the potential daily increase in LAI. The daily biomass production is
then computed as a quadratic function of the intercepted radiation, given by the Beer-
Lambert law. Hence, crop total biomass results from the accumulation of the daily
biomass increase, and the ﬁnal grain biomass is obtained through a harvest index.
In our study, the ﬁeld experimentations were conducted without Nitrogen stress,
but in light water stress conditions. Therefore, the soil characteristics are taken into
account to compute the water balance of the plant-soil-atmosphere system and thus
to estimate several water stress indices impacting plant growth at diﬀerent levels. For
this purpose, the water contents in three soil layers are calculated.
In consequence, the above model can be divided into two sub-models, one concern-
ing the plant system with state variables at time t denoted Xp(t) and the other about
the soil system with state variables denoted Xs(t). Plant growth is described by the

CHAPTER 2. PLANT GROWTH MODELS
31
Figure 2.4: General scheme of the STICS model for winter wheat.
function fp. The root compartment growth is directly aﬀected by the soil temperature
and water content. Likewise, the soil water content determines several water stress
indices impacting LAI development, biomass production and senescence. On the other
hand, water transfers including evaporation and plant transpiration are calculated in
the soil system by the function fs.
 Xp(t + 1) = fp (Xp(t), Xs(t), Ep(t), Θp)
Xs(t + 1) = fs (Xs(t), Xp(t), Es(t), Θs)
(2.8)
The details of the equations can be found in Brisson et al. (2008).
Given the complexity of the STICS model, a large number of parameters are in-
volved, some of which may be species dependent or genotype dependent.

32
2.2. STICS MODEL OF PLANT GROWTH

CHAPTER 3
Preliminary
- Estimation Theory
I
n parallel with theoretical advances, there has been a rise in the development of com-
putationally eﬃcient approximation models to address the increasing complexities
of modern data analysis. With the availability of cheap and ﬂexible computing power,
simulation based Monte Carlo methods have gained great importance in probability
and statistics. Mathematically based on the law of large numbers and conceptually
based on a frequentist notion of probability, a lot of problems can be surmounted
through approximation schemes with important number of simulations.
Before presenting the principles algorithms of the MCMC-based methods and the
SMC methods in a general state-space setting, in this chapter, a number of important
concepts to be used in the other sections are presented. First, we outline the funda-
mental diﬀerence between the frequentist and the Bayesian philosophies. A general
probabilistic model for both frequentist and Bayesian inference objectives is described.
Then, problems associated with the posterior computation which motivate the stan-
dard approximation methods are brieﬂy discussed. Subsequently, the Monte Carlo
methods are introduced. Some commonly used estimators are presented. Finally, we
review some basic elements regarding the Markov chain principals and its behaviour
to prepare for the use of Markov chains Monte Carlo methods on general state-spaces
presented in the next chapter.
3.1
Estimation paradigms
Generally speaking, there are several streams of thought in statistical analysis (such
as parametric or nonparametric, inferential or exploratory, robust or nonrobust), one
of the most salient is frequentist or Bayesian (Robert, 2001). Their common objective
is to explore a phenomenon based on observed data, like in the case of plant growth
33

34
3.2. GENERAL STATE-SPACE MODELS
modelling. The calibration of a given model is carried out based on past observations
with the purpose of improving the understanding of the plant growth mechanisms and
hopefully to be used as predictive tools for future applications.
However, the two
categories of the methods are based on diﬀerent paradigms.
According to the frequentist approach, the studied events are assumed to have
statistical stability, therefore, the parameter is supposed to have a true value which
is ﬁxed. A random conﬁdence interval is usually provided, a 95% conﬁdence inter-
val indicates that if the experiment is repeated a large number of times, 95% of the
conﬁdence intervals calculated would contain the true value of the parameter.
On the other hand, in the Bayesian framework, the understanding of probability
and of inference is conceptually diﬀerent. A probability distribution can be associated
with the parameter to express one’s uncertainty and belief before taking into account
the data 1. The estimation consists in updating the previous (prior) knowledge of the
studied event based on new observations. In some situations, a credible interval may
be provided as a probabilistic region around the parameter. In the contrast of the fre-
quentist conﬁdence interval, it results from a probability distribution (posterior) which
incorporates contextual problem-speciﬁc information given by the prior knowledge.
With that being said, generally for plant growth models, the limited observations
contain frequently important noises, hence the importance of prior information and
the advantage of Bayesian approaches.
Moreover, when it comes to the estimation of unknown parameters of a given model,
frequentist methods rely on estimators whose properties are derived from distributions
of repeated samples whereas Bayesian methods provide distribution of parameters con-
ditional on the actual dataset observed. Given the settings and the objectives of plant
growth modelling, one may come to the conclusion that the Bayesian approaches are
more suitable by nature to address the issues of uncertainty assessment in model cal-
ibration and model prediction. As a result, in this thesis the Bayesian approaches
are mainly investigated. Nevertheless, we also provide some results given by the fre-
quentist approach in comparison, since in some situations, frequentist methods derive
estimators based on the maximum likelihood function which oﬀers similar estimation
results compared to the Bayesian approach.
In the following, Bayesian inference framework is formally formulated and some
frequently used estimators, both Bayesian and frequentist are presented for point es-
timation. First, we introduce the general state-space models.
3.2
General State-Space Models
For parameter estimation and sequential data assimilation in crop models, we rely
on the statistical framework provided by the discrete nonlinear general state-space
model. Here we ﬁrst introduce the general formulation of a dynamic state-space model
(Kalman, 1960; Harrison and West, 1989; Hamilton, 1994; Doucet et al., 2001) which
1. Parameters of prior distributions are known as hyperparameters, so as to distinguish from those
of the model.

CHAPTER 3. PRELIMINARY - ESTIMATION THEORY
35
is usually deﬁned by a state function and an observation function, as follows:



X(t + 1) = ft (X(t), E(t), Θ, η(t)) ,
Y (t) = gt (X(t), Θ, ξ(t)) .
(3.1)
The evolution equation is embodied in the function ft, which is time dependent.
{X(t)}t∈N represents the state variables at time t, X(t) ∈X ⊆R dx.
Θ denotes
the parameter vector, Θ ∈P ⊆R dΘ, and E(t) represents the system input vector
in a controlled environment, E(t) ∈E ⊆R de. The modelling noise is represented
with the random variables η(t) (corresponding to model imperfections or uncertainty
in the model inputs). The observation equation incorporates observations on the state
variables of interest.
Y (t) is the output vector which is related to the state vari-
able vector X(t) through the function gt. {Y (t)}t∈N∗consists of state variables that
can be observed experimentally (outcome) and usually diﬀer from X(t) (for instance,
biomasses of some plant organs can be measured while the daily biomass production
cannot), Y (t) ∈Y ⊆R dy. Measurement noises are denoted by ξ(t). Here, we separate
the noise parameters and the model parameters (also known as functional parame-
ters), for they play diﬀerent roles with respect to likelihood computation. {η(t)}t∈N
and {ξ(t)}t∈N are considered as sequences of independent and identically distributed
random variables.
Note that only in rare occasions (Makowski et al., 2004; Chen and Courn`ede, 2012;
Trevezas and Courn`ede, 2013), plant models were built by really taking into account
modelling and measurement noises.
Models are generally written as deterministic
dynamic systems. Of course, such deterministic models can still be represented with
(3.1), the stochastic variables being zero with probability 1.
Figure 3.1: Generic state-space model.
Furthermore, since experimental data tend to be limited due to high costs, ob-
servations are only available at irregular times. Let (t1, t2, ...tN) be the N measure-
ment time steps. For all n ∈N, we set: xn := X(tn), yn := Y (tn) and we denote
y1:n := (y (t1) , y (t2) , . . . , y (tn)).

36
3.2. GENERAL STATE-SPACE MODELS
If we reformulate the state-space dynamic model in a Bayesian perspective as a
hidden Markov Model, it can be described as:



x0
∼pΘ(x0)
initial density,
xn
∼pΘ(xn|xn−1)
transition density,
yn
∼pΘ(yn|xn)
measurement density.
(3.2)
with Θ ∈P and n ≥0.
More discussions about the state space model and Hidden Markov model can be
found in Jazwinski (1970); Robert and Casella (1999); Robert (2001); Kaipio and
Somersalo (2005). The Bayesian approach for parameter estimation mainly consists of
updating prior knowledge of parameter Θ, π(Θ), based on the observational evidence to
a posterior distribution π(Θ|y1:n). The probability is thus interpreted as a conditional
measure of uncertainty.
Before proceeding to Bayesian inference and Bayesian prediction, we ﬁrst recall
some basics of Bayesian statistics.
3.2.1
Bayesian statistics
To perform parameter estimation for plant growth models in a Bayesian framework,
we intend to compute the posterior distributions for the parameters. However, com-
plex models usually involve high dimensionality as well as nonlinearity, and the lack of
data often occurs. These diﬃculties preclude analytical solutions: the posterior distri-
butions are either impossible to obtain explicitly or diﬃcult to sample from directly.
Therefore, an approximation can be considered. Three types of problems inherently
linked to the Bayesian statistics can be encountered: normalization, marginalization
and expectation.
For the sake of simplicity, let Θ denote the unknown parameters, Θ ∈P ⊆R dΘ,
and y the outcome variable y ∈Y ⊆R dy.
• Normalization
Given the prior π(Θ) and the likelihood function L (Θ|y) = p(y|Θ) which assesses the
probability of obtaining y if Θ is the true value of the parameter, the posterior π(Θ|y)
can be obtained according to Bayes’ rule (Bayes, 1763) :
π(Θ|y) = p(y|Θ)π(Θ)
p(y)
=
p(y|Θ)π(Θ)
R
P p(y|Θ)π(Θ)dΘ
(3.3)
as the product of the prior and the likelihood divided by a normalizing factor, for
which complex integrations are needed over the whole parameter space.
• Marginalization
Given the joint posterior (Θ, x), with x ∈X ⊆R dx, the marginal posterior can be
expressed as:
π(Θ|y) =
Z
X
p(Θ, x|y)dx.
(3.4)

CHAPTER 3. PRELIMINARY - ESTIMATION THEORY
37
We show in the following sections (e.g.
Sections 4.1.3, 4.3.3 and 5.2.1) that the
marginalization plays an important role in Bayesian inference.
• Expectation
Given the conditional pdf, we are often interested in computing some averaged func-
tions of Θ :
Eπ(Θ|y)[f(Θ)] =
Z
P
f(Θ)π(Θ|y)dΘ.
(3.5)
For instance, if f is an identity function, then we obtain E(Θ|y).
Since the explicit computation of these integrals is generally intractable, we are
led to consider approximate solutions based on Monte Carlo methods, which consist
of sampling random variables from probability distributions so as to perform the inte-
gration implicitly.
3.3
Monte Carlo methods
One of the main numerical issues in statistical analysis concerns integration prob-
lems, which generally emerge with the likelihood approach and the Bayesian approach.
Monte Carlo methods oﬀer a way to evaluate integrals.
3.3.1
Classical Monte Carlo integration
Let πu deﬁne the un-normalized density of interest on a measurable state space X ⊂
Rd, with respect to d-dimensional Lebesgue measure, which satisﬁes 0 <
R
X πu < ∞.
Let B denote the Borel σ-algebra associated to X.
We thus have the probability
measure π(·) on X, for A ∈B(X):
π(A) =
R
A πu(x)dx
R
X πu(x)dx.
(3.6)
We wish to estimate the expectation of the function f: X →R with respect to
π(·):
π(f) = Eπ[f(X)] =
R
X f(x)πu(x)dx
R
X πu(x)dx
,
(3.7)
for which direct evaluation of integration could be infeasible.
Thus, by using the
classical Monte Carlo method, if we have {Xi, i = 1, . . . , n} i.i.d. samples generated
from π(·), then the following estimator is available :
ˆπ(f) : = 1
n
n
X
i=1
f(Xi),
(3.8)

38
3.3. MONTE CARLO METHODS
since
lim
n→∞
1
n
n
X
i=1
f(Xi) −→
Eπ[f(Xi)]
a.s.
(3.9)
Particularly, in the case when π(f 2) < ∞, Var(ˆπ(f)) can be estimated according
to the Central Limit Theorem, the speed of the convergence vn can accordingly be
assessed :
Var(ˆπ(f)) = 1
n
R
X(f(x) −Eπ[f(X)])2πu(x)dx
R
X πu(x)dx
,
(3.10)
ˆvn = 1
n
n
X
i=1
(f(Xi) −ˆπ(f))2,
(3.11)
and
lim
n→∞
ˆπ(f) −π(f)
√ˆvn
−→N(0, 1).
(3.12)
It means that the unbiased estimator has a standard deviation of order O(1/√n),
which can lead to the construction of conﬁdence bounds and convergence test.
Note that it is not necessary to draw samples directly from the distribution f to
approximate the integral, especially when it is not easy to do so, some other tech-
niques like importance sampling could also be employed (Ripley, 1988; Robert and
Casella, 1999). It is also one of the most popular techniques to reduce the variance of
the estimate. The idea is to represent the integration by an expectation of weighted
samples.
3.3.2
Importance Sampling
The main idea is to evaluate the equation (5.8) (i.e. approximate the expected mean)
based on i.i.d. samples {Xi, i = 1, . . . , n}, generated from an arbitrary chosen distri-
bution g(·). The expectation of f can be reformulated as follows:
Eπ[f(X)] =
R
X f(x)πu(x)
g(x) g(x)dx
R
X
πu(x)
g(x) g(x)dx
,
(3.13)
which can be approximated and estimated by
ˆEπ[f(X)] =
1
n
Pn
i=1 f(Xi)πu(Xi)
g(Xi)
1
n
Pn
i=1
πu(Xi)
g(Xi)
.
(3.14)
If we deﬁne
w(Xi) =
πu(Xi)
g(Xi)
Pn
j=1
πu(Xj)
g(Xj)
,
(3.15)

CHAPTER 3. PRELIMINARY - ESTIMATION THEORY
39
a possible Monte Carlo estimate of the integration of Eπ[f(X)] can be obtained :
ˆEπ[f(X)] =
n
X
i=1
w(Xi)f(Xi).
(3.16)
The proposal density g(·) is chosen so as to be easy to sample from. g is some-
times referred to as importance function, and w(x) as importance weight.
Thus,
{Xi, w(Xi)}n
i=1 can be regarded as giving an approximation to πu(·).
The advantage of introducing the proposal density is that it permits us to sample
random variables from densities diﬀerent from the original one. A noteworthy point
is that the importance function is supposed to mimic the target distribution, in a way
that it should be positive where the target distribution is positive, and particularly
also be able to capture the peak of the target distribution.
Note that importance sampling is a general Monte Carlo integration method which
brings considerable improvements compared to the classic Monte Carlo method. The
estimate provided is consistent. However, the proposal distribution should have heavy
tail in order to be insensitive to the outliers (Robert and Casella, 1999). Moreover,
the method is computationally expensive for recursive estimation in state space mod-
els, since each time when there is a new data available, one needs to recompute the
importance weights over the entire state space (Doucet et al., 2001). In the literature,
many variations of importance sampling exist to overcome this problem. One of the
most popular methods which generally works well for identiﬁcation problems in dy-
namic systems, is sequential importance sampling. This method is shortly reviewed in
Section 4.3.4.
3.4
Estimators and optimization criteria
The objective of Bayesian inference is to use prior knowledge, quantitatively and
qualitatively, to infer the conditional probability given limited observations.
Once
the posterior distribution is constructed, an estimator is required.
Here are some
estimators and the associated criteria that can be used to measure the optimality.
1. Minimum mean square error (MMSE)
The point estimation of Θ can be found by minimizing the prediction or ﬁl-
tering error. The MMSE estimator thus aims to obtain the conditional mean
E [Θ|y0:n] =
R
P θp(θ|y0:n)λ(dθ), with λ the Lebesgue measure. It can be deﬁned
as :
ˆΘMMSE = argmin
Θ∈P
E(∥Θ −ˆΘ∥2|y0:n)
(3.17)
2. Maximum a posteriori (MAP)
The point estimation of Θ can as well be obtained by choosing the value of Θ

40
3.4. ESTIMATORS AND OPTIMIZATION CRITERIA
at which L(Θ|y0:n) attains its maximum (mode) in the posterior density. The
Maximum a posteriori (MAP) estimator is deﬁned as :
ˆΘMAP = argmax
θ∈P
p(θ|y0:n)
= argmax
θ∈P
p(y0:n|θ)p(θ).
(3.18)
3. Maximum likelihood (ML)
If the prior is non-informative, the MAP estimator can be further simpliﬁed and
as a result, be generalized to the maximum likelihood estimator (MLE):
ˆΘML = argmax
θ∈P
p(y0:n|θ).
(3.19)
Notice that the range of MLE should coincide with the range of the parame-
ter by construction. Under fairly general conditions (see Casella and Lehmann
(1998)), the MLE is converging almost surely to the true value of the parameter.
However, according to Berger and Wolpert (1984), it is situated at the fringe of
the Bayesian paradigm.
N.B.
- We highlight that the above criteria and estimators are valid for state estimations as
well as for parameter estimations.
- Both MMSE and MAP estimators require the computation of the posterior density
distribution. However, MAP has the advantage of not requiring the calculation of the
denominator (integration), which makes it less computational expensive. On the other
hand, one of its drawbacks is that in high-dimensional space, high probability density
could belong to a narrow distribution and thus does not imply high probability mass.
Thus, the width of the mode is also very important to take into account. Moreover, in
the case of a real parameter, it has no justiﬁcation in terms of minimization of a risk
function (Heinrich, 2014). Therefore, the MMSE estimator is selected for the Bayesian
approaches presented in this thesis.
In the meantime, under very simple assumptions on the error model, the compu-
tation of maximum likelihood can also be implemented through the minimization of
sums of square residuals, which introduces the Least Squares (LS) estimator. For
nonlinear functions, it can be formulated as :
ˆΘLS = argmin
Θ∈P
n
X
i=0
∥yi −g(Θ)∥2.
(3.20)
Regarding the estimation of model state variables, the generalized least squares esti-
mator is often employed.

CHAPTER 3. PRELIMINARY - ESTIMATION THEORY
41
3.4.1
Generalized Least Squares Estimator
The classical parameter estimation technique Generalized Least Squares (GLS) is
traditionally used when the measurement errors have unequal variance or are corre-
lated. Generally, modelling errors are not considered, and the dynamics of the model
is not taken into account in the error model. If we denote ˜Y (Θ) the full output vec-
tor of a deterministic model with parameter vector Θ as in the equation (3.1), Y the
corresponding experimental data, ˜Y (Θ), Y ∈Y ⊆R dy and Θ ∈P ⊆R dΘ, we assume:
Y = ˜Y (Θ) + ξ
with ξ an additive measurement error. If Var(Y |Θ) = Σ is known, the GLS estimator
is given by:
ˆΘGLS = argmin
Θ∈P

Y −˜Y (Θ)
T
Σ−1 
Y −˜Y (Θ)

.
(3.21)
If the model is linear, ˜Y (Θ) = AΘ with A a ny × nΘ matrix, we can deduce (see for
example Rao (1973)) that ˆΘGLS has a Gaussian vector of variance:
Var

ˆΘGLS

=
 ATΣ−1A
−1 .
If the model is moderately nonlinear (see for example Wu et al. (2010) which gives
some ways to characterize the nonlinearity of plant growth models), an approximation
is given by:
Var

ˆΘGLS

=
 
∂˜Y
∂θ

ˆΘGLS
T
Σ−1∂˜Y
∂θ

ˆΘGLS
!−1
.
(3.22)
When Σ is unknown, yet can be expressed as a function of Θ, Σ(Θ), then the
strategy is to implement an iterative method with the multi-stage Aitken estimator
(Taylor, 1977). Given Σ0, ˆΘ(1) can be obtained, which in turn can be used to update
the estimation of Σ to obtain ˆΣ(1). The new estimate can be used to compute ˆΘ(2)
according to equation (3.21). This alternating estimation scheme can be iterated until
both estimates stabilize. A very useful example is given by Taylor (1977) considering
the case when Y can be gathered into q groups, q ∈N∗, with Yi the error terms in
group i, (1 ≤i ≤q), supposed to have common unknown variance Θi. Σ is assumed
given by a diagonal matrix:
Σ =







α1IY1
0
0
· · ·
0
0
α2IY2
0
· · ·
0
...
...
...
...
...
0
· · ·
0
αq−1IYq−1
0
0
· · ·
0
0
αqIYq







with Ik, the identity matrix of rank k. Note that this method may induce rearranging
the data in the ˜Y vector by grouping the data of the same type.
The 2-stage estimator proposed by Taylor is described as follows. From an algo-
rithmic point of view, there are two stages in the estimation process:

42
3.5. MARKOV CHAIN MONTE CARLO METHODS
(1) αi is estimated in the ﬁrst place as the variance of all experimental data in group
i to give the ﬁrst estimate ˆΣ(1) of Σ. We then obtain:
ˆΘ(1)
2SA = argmin
Θ∈P

Y −˜Y (Θ)
T 
ˆΣ(1)−1 
Y −˜Y (Θ)

.
(2) We then estimate αi with:
ˆαi =
1
Yi −nΘ

Yi −˜Yi

ˆΘ(1)
2SA
T 
Yi −˜Yi

ˆΘ(1)
2SA

,
to obtain ˆΣ(2) and the ﬁnal estimator which is given by
ˆΘ2SA = argmin
Θ∈P

Y −˜Y (Θ)
T 
ˆΣ(2)−1 
Y −˜Y (Θ)

.
Finally the variance of ˆP2SA is approximated with Equation (3.22) (using ˆΣ(2)).
N.B.
- This strategy is widely used in the application of GreenLab model calibration (Courn`ede
et al., 2011).
- Note that when the underlying model is incorrect, other methods such as the Huber
Sandwich Estimator (Huber, 1967) can be considered to provide a robust estimation
of the variance of the MLE.
3.5
Markov chain Monte Carlo methods
MCMC has become a standard technique commonly used as a tool to generate
large samples in order to estimate unknown characteristics of a target distribution.
It implies building a Markov chain on a state space X, produced by a discrete-time
stochastic process (Xn)n∈N, to represent the posterior distribution. However, before
implementation and interpretation, particular attention should be paid to the condi-
tions and assumptions that need to be veriﬁed to establish the central limit theorem
for Markov chains. In this section, some basic concepts of Markov chains which we
need for the application in this thesis are brieﬂy recalled.
More details regarding stochastic processes and Markov chains’ properties can be
found in (Robert et al., 1999; Robert and Casella, 1999; Jones and Hobert, 2001;
Roberts and Tweedie, 2008).
3.5.1
Markov chains
Suppose (Xn)n∈N is a homogeneous Markov chain with values in a general state
space (X, B(X)). Although X is a general set, in practice, we are most likely consider-
ing d-dimensional Euclidean space, so that X = Rd, or some countable or uncountable

CHAPTER 3. PRELIMINARY - ESTIMATION THEORY
43
subset of Rd. In order to deﬁne probabilities, B(X) is employed to denote a countably
generated σ-algebra on X: when X = Rd, B(X) will be taken as the Borel σ-algebra;
when X is countable, B(X) contains all subsets; otherwise it may remain arbitrary.
Let P(x, dy) be the transition kernel associated to the homogeneous Markov chain
(Xn). For x ∈X, A ∈B(X) and i ∈N :
P(x, A) = Pr(Xi+1 ∈A|Xi = x).
For all n ∈N, we deﬁne P n(x, dy) as the n-step Markov transition kernel, then for
x ∈X, A ∈B(X) and i ∈N :
P n(x, A) = Pr(Xn+i ∈A|Xi = x).
Since in our application context, X ⊂Rd, we assume that for all x ∈X, the probability
measure P(x, ·) has a conditional density k(·|x) with respect to the Lebesgue measure,
P(x, A) =
Z
A
k(u|x)du.
The density k is referred to as the Markov transition density. If there exists a density
π that satisﬁes :
π(x) =
Z
X
k(x|y)π(y)dy,
(3.23)
then π(·) is called a stationary distribution, also known as invariant distribution of the
Markov chain (Xn). It is easy to see that if we can simulate X0 ∼π(·), then (Xn) is a
sequence of dependent samples from π(·).
Deﬁnition 3.5.1 A Markov chain transition kernel P is said to be reversible with
respect to a probability distribution π(·) on X, if:
π(dx)P(x, dy) = π(dy)P(y, dx),
for all x, y ∈X.
(3.24)
Deﬁnition 3.5.2 A Markov chain transition kernel P is said to be π-irreducible if
for any x ∈X and any set A, A ∈B(X) with π(A) > 0, there exists an n that satisﬁes:
P n(x, A) > 0.
If (Xn) is a Markov chain associated with a π-irreducible transition kernel, then
the chain can be qualiﬁed as a π-irreducible Markov chain.
If the chain is π-irreducible, it means for all the points in the considered state
space, there is a positive probability that we may reach any set which has positive
π-probability. This deﬁnition assures that those sets that are π-positive are always
reachable by the chain with positive probability, independently of the initial point, as
a result, the chain cannot be reduced into separated pieces.
Another important property of Markov chains is the periodicity.

44
3.5. MARKOV CHAIN MONTE CARLO METHODS
Deﬁnition 3.5.3 If for a π-irreducible Markov transition kernel P, there exists an
integer d and a collection of disjoint sets A1, . . . , Ad ∈B(X) such that for each x ∈Aj,
P(x, Aj) = 1 for j = 1, . . . , d −1, and for each x ∈Ad, P(x, A1) = 1, then P is said
to be periodic. Otherwise, P is said to be aperiodic.
In other words, if the state space can be partitioned in such ways that the cyclic
behavior is introduced, then P is periodic. Otherwise, if such partition does not exist,
then P is aperiodic. For countable space, being aperiodic indicates that the return to
a visited state may occur at irregular times for the chain. In similar ways, if a Markov
chain (Xn) is associated with a periodic (resp. aperiodic) transition kernel, then the
chain is called periodic (resp. aperiodic).
Deﬁnition 3.5.4 If (Xn) is a π-irreducible Markov chain with π the stationary dis-
tribution, then X is deﬁned to be recurrent if for any set Λ with π(Λ) > 0:
Pr(Xn ∈Ai.o. | X1 = x) > 0
for all x,
Pr(Xn ∈Ai.o. | X1 = x) = 1
for π-almost all x.
The chain is called Harris recurrent if Pr(Xn ∈Ai.o. | X1 = x) = 1 for all x.
For countable space, a π-irreducible Markov chain is deﬁned as recurrent if the
probability of returning to a visited state is 1. Additionally, if π(·) is a probability
distribution, then the chain is positive recurrent.
If a Markov chain is π-irreducible, aperiodic and positive Harris recurrent, then it
is Harris ergodic.
However, in practice, it is often impossible to draw samples directly from π(·)
which motivates the use of MCMC. Consequently, it is important to state same condi-
tions under which the chain can be described as “converged” to the desired stationary
distribution :
∥P n(x, ·) −π(·)∥:= sup
A∈B
|P n(x, A) −π(A)|.
Proposition 3.5.1 Suppose that a Markov chain transition kernel P is π-irreducible,
which has an invariant distribution π(·). Then P is positive recurrent and π is the
unique invariant distribution of P. If P is an aperiodic as well, then for π-almost all
x,
∥P n(x, ·) −π(·)∥→0
as n →∞.
In the case that P is Harris recurrent, the convergence occurs for all x.
The proof of proposition 3.5.1 is provided by Athreya et al. (1996).
Markov Chain Monte Carlo methods aim to construct a Markov chain with random
samples which has a unique stationary distribution as its posterior distribution to
estimate certain characteristics of the parameter’s real distribution. To be assured
that the estimate of the integration converges to the right value as the number of
samples approaches inﬁnity, the Strong Law of Large Numbers is needed. That is
to say, we are under the assumption that the random variables should be sampled

CHAPTER 3. PRELIMINARY - ESTIMATION THEORY
45
independently from the same distribution.
If a Markov chain has converged to a
stationary distribution, we may assure that the samples are produced from the same
distribution, but they are still correlated. The property of ergodicity makes the SLLN
hold also for correlated samples.
Theorem 3.5.2 (Strong Law of Large Numbers)
If (Xn) is a Harris ergodic Markov chain on a state space X ⊂Rd and has an invariant
distribution π(·), then ∀f veriﬁes
R
X |f(x)|π(x)dx < ∞,
lim
n→∞
1
n
n
X
i=1
f(Xi) =
Z
X
f(x)π(x)dx
a.s.
(3.25)
for any initial distribution.
However, to assure that the Central Limit Theorem (CLT) holds for a Markov chain,
some stronger regularity conditions are needed. More precisely, the chain is required
to be geometrically ergodic or uniformly ergodic, which depends on the moment
condition.
Deﬁnition 3.5.5 If (Xn) is a Harris ergodic Markov chain which has an invariant
distribution π(·). The chain is deﬁned as geometrically ergodic if there exists a
constant 0 < t < 1 and a function M : X 7→R+ such that for any x ∈X :
∥P n(x, ·) −π(·)∥≤M(x)tn
for n ∈N. If there is a bounded M which satisﬁes this condition, then (Xn) is uni-
formly ergodic.
Here we state three diﬀerent sets of conditionals for Markov chain CLT.
Theorem 3.5.3 Suppose (Xn) is a Harris ergodic Markov chain on X which has an
invariant distribution π(·). Let f : X 7→R be a Borel function. If one of the following
conditions is assumed:
1. (Doukhan et al. 1994) (Xn) is geometrically ergodic, and Eπ[f 2(X)(log+|f(X)|)] <
∞;
2. (Roberts and Rosenthal 1997) (Xn) is geometrically ergodic and reversible, and
Eπ[f 2(X)] < ∞;
3. (Ibragimov and Linnik, 1971) (Xn) is uniformly ergodic and Eπ[f 2(X)] < ∞.
Then, for any initial distribution, as n →∞, and assuming X1 ∼π(·) :
√n(Eπ[f(X)] −¯fn)
d
−→N(0, σ2
f)
where
σ2
f = Varπ(f(X1)) + 2
∞
X
i=2
Covπ(f(X1), f(Xi)).
(3.26)
Further discussions concerning the convergence issues related to MCMC based
methods can be found in Ibragimov and Linnik (1971); Rosenthal (1995); Robert et al.
(1999); Robert and Casella (1999); Jones and Hobert (2001) and Roberts and Tweedie
(2008).

46
3.5. MARKOV CHAIN MONTE CARLO METHODS

CHAPTER 4
Numerical Approaches for Bayesian
Estimation
B
ayesian inference, formal and informal, has found widespread applications. Al-
though Monte Carlo methods are ﬁnely suited to generate samples from the pos-
terior distribution, they remain generally ineﬃcient when complex models with mul-
timodality problems are presented. This motivates the development of Markov chain
Monte Carlo (MCMC) methods, which aim at visiting solutions with stable frequency
stemming from a stationary distribution. In parallel, inspired from the fact that the
observations arrive sequentially in time, the idea of performing inference online seems
to be very attractive and convenient in real world applications, such as aircraft track-
ing, noisy signal identiﬁcation, or stock market prediction. Based on this idea, the
approaches developed are known as Sequential Monte Carlo (SMC) methods. Instead
of having one simulation creating trajectories repeatedly, like MCMC-based methods
do, one may imagine SMC methods as a large number of simulations evolving simul-
taneously and those who ﬁt best the observations are sequentially selected.
In this chapter, simulation based methods, including both the MCMC-based meth-
ods and the SMC methods are investigated using the sampling and integration tech-
niques presented in Section 3.3. Three MCMC-based algorithms are investigated and
some important issues often raised in implementation are subsequently addressed. The
aim is to provide some options to the parameterization problem of dynamic state-space
system in plant growth modelling. We are particularly convinced that with proper
estimation methods, even for misspeciﬁed models the impact could be limited and
contextual.
Note that in this chapter, we only investigate the Bayesian numerical methods for
functional parameter estimation while considering the noise parameters of the state-
space model known. The issues related to noise parameters estimation and uncertainty
assessment are further addressed in Chapter 6.
The chapter is organized as follows: in the ﬁrst part, MCMC-based methods which
47

48
4.1. MCMC-BASED ALGORITHMS
are known as oﬄine Bayesian estimation methods are introduced. The two most fa-
mous MCMC-based algorithms, Metropolis-Hastings (MH) and Gibbs sampler (GS)
are presented. They can be employed as basic tools to construct ergodic Markov chains.
Then, some latest MH and GS based algorithms, involving techniques like “one long
run” or “many short runs” are detailed. In order to meet the demand of parameter es-
timation purpose in state-space plant growth models, an adaptive scheme is proposed
in this thesis. In the second part, some SMC methods which represent online Bayesian
estimation methods are reviewed. The general ﬁltering recursion framework is revis-
ited, followed by a brief presentation of Kalman based ﬁltering methods. Sequential
Important Sampling and Resampling algorithms are reviewed and two recent particle
ﬁltering based algorithms Regularized Particle Filter and Convolution Particle Filter
are presented. They will be further studied in comparison with the MCMC based
methods when applied to the LNAS plant growth model in Chapter 8.
4.1
MCMC-based algorithms
In a short period of time, the Markov chain Monte Carlo (MCMC) integration
methods, especially the Metropolis-Hastings algorithm Metropolis et al. (1953); Hast-
ings (1970) and the Gibbs sampling algorithm (Geman and Geman, 1984; Gelfand
et al., 1990) have emerged as popular tools in the ﬁeld of Bayesian analysis to perform
analysis for complex statistical models. Appropriately deﬁned and implemented, the
MCMC-based methods allow us to evaluate complex and high-dimensional integrals
with the purpose of obtaining posterior distributions for unknown parameter, missing
data and hidden variables, by sampling values from an ergodic Markov chain.
Excellent tutorial concerning the implementation and the methodology is provided
by Robert and Casella (1999) and Robert and Casella (2010).
4.1.1
Metropolis-Hastings algorithm
Based on the accept-reject methodology, the Metropolis-Hastings algorithm was
ﬁrst introduced by Hastings (1970) as a generalized version of the Metropolis algorithm,
described in Metropolis et al. (1953). It oﬀers a way to obtain a sequence of samples
from a probability distribution for which direct sampling is infeasible. The resulting
sequence can be used to approximate the target distribution or to compute an integral.
For each iteration of the algorithm, a new candidate point is drawn from a proposal
distribution, and the decision is made based on the acceptance probability computed
by taking into account both the actual candidate and the last accepted candidate.
Suppose that πu deﬁnes the un-normalized target density on a state space X ⊂Rd
as in (3.6), with respect to the d-dimensional Lebesgue measure. Suppose also that it is
possible to sample from a Markov chain with transition density q(·|x), namely the pro-
posal distribution or the instrumental distribution, with respect to the d-dimensional
Lebesgue measure. The Metropolis-Hastings algorithm associated with the target dis-
tribution and the proposal distribution produces a Markov chain in the following way:

CHAPTER 4. BAYESIAN ESTIMATION
49
Algorithm : Metropolis-Hastings
• Initialization
- Choose initial values for X0.
• Iteration
- For i = 1, . . . , n :
1. Sample Zi ∼q(·|Xi−1).
2. Set
Xi =
(
Zi
with probability α(Xi−1, Zi),
Xi−1
with probability 1 −α(Xi−1, Zi),
(4.1)
where
α(x, z) = min

1, πu(z)
πu(x)
q(x|z)
q(z|x)

.
(4.2)
In the case that πu(x)q(z|x) = 0, to avoid ambiguity, we set α(x, z) = 0 (Roberts and
Rosenthal, 2004).
Remark that since only the ratio of densities πu(z)/πu(x) is required, the nor-
malizing constant
R
X πu(x)dx does not need to be computed, which alleviates the
normalization problem described in Section 3.2.1.
An important remark is that although q(·|x) does not need to be related to our
target density πu, the choice of this proposal density may inﬂuence crucially the eﬃ-
ciency of the method. There exist many possible ways to choose the proposal density,
for instance:
Independence sampler
When the instrumental density q does not depend on the previous accepted candidate
Xi−1, i.e. q(z|x) = q(z), the acceptance probability can be written as :
α(x, z) = min

1, πu(z)
πu(x)
q(x)
q(z)

,
(4.3)
where πu(z)/q(z) can be regarded as the importance weight function used in impor-
tance sampling. Indeed, the basic ideas of independent sampler and importance sam-
pler (Section 3.3.2) are quite similar, both of them attribute massive probability to
points with large weights, however in diﬀerent ways: the importance sampler selects
those points more often than usual, whereas the independence sampler remains at
those points for a long time.
Symmetric Random walk Metropolis Algorithm (RWM)
Another choice for the instrumental law is random walk with q(z|x) = qRW(z −x)

50
4.1. MCMC-BASED ALGORITHMS
and we assume that qRW(w) = qRW(−w). Therefore the acceptance probability can
be simpliﬁed:
α(x, z) = min

1, πu(z)
πu(x)

.
(4.4)
All candidates that improve πu are accepted. By applying the random walk-type of
proposal distribution, we are supposed to approach the zone containing the mode of
πu more often than to move away from it (see Figure 4.1).
Figure 4.1: The region of acceptance (A(x)) and the region of rejection (R(x)) for the
random walk proposal (qRW) in Metropolis Hastings algorithm.
An advantage of RWM is that the computation of πu is only involved in the accept-
reject mechanism, hence the algorithm is relatively easy to implement, which is prob-
ably why it is considered as one of the most popular MCMC-based methods.
There are many possible choices for qRW, including uniform distributions on the
unit circle, Student’s t-distributions, or multivariate normal distributions, and the
choices of qRW is crucial to determine the performance of the method (the convergence
speed, the precision of the estimator, etc.). A classical choice is the multivariate normal
distribution with zero-mean and covariance matrix Σ. It is well known that either too
small or too large variances for the proposal distribution of the random walk will
cause highly correlated Markov chains and therefore result in imprecise estimates. For
instance, if the variance is too small, then almost all the proposed values are accepted.
As a consequence, the diﬀerence between the two accepted values are often very small
which leads to the slow exploration of the state space. Conversely, if the variance is
too large, the proposals are often rejected and the chain has to stay for a long time at
the same point. Thus, to tune the covariance matrix Σ of the proposal distribution to
a proper scale is absolutely essential for a successful implementation of RWM.
Note that to illustrate the performance of the method, the acceptance rate could
be monitored, as illustrated by Figure 4.2. When the acceptance rate is too large,
it indicates that the chain may move too slowly on the surface of the model space f,
except in the case when f is almost ﬂat, for which a high acceptance rate is acceptable,
otherwise, it is highly possible that some parts of the domain can be missed. On the
other hand, if the acceptance rate is too low, it suggests that the chain may move too
fast and have missed an isolated mode of f.

CHAPTER 4. BAYESIAN ESTIMATION
51
In the meantime, another variable, the autocovariance can as well be used to mon-
itor the convergence and the mixing of the chain. The autocovariance is deﬁned as
the covariance between equidistant states in a chain which reaches its real-valued sta-
tionary distribution. The term Covπ(f(Xi), f(Xi+k)) presented in Equation (3.26) of
Theorem 3.5.3 is known as the lag-k autocovariance of the function f, and accordingly
Covπ(f(Xi),f(Xi+k))
Varπ(f(Xi))
is called the lag-k autocorrelation of the function f.
In the following toy example given in Robert and Casella (2010), three choices of
δ, δ ∈R for the random walk proposal distribution are made to estimate the mean of
a standard normal distribution N(0, 1).
Yi = Xi−1 + ϵi,
ϵi ∼U[−δ, δ]
All the three chains are monitored by both the acceptance rate and the autocorrelation
function.
Figure 4.2: Three diﬀerent proposals and resulting chains. The evolution of the esti-
mates, the histogram representing the distribution of the estimates and the autocorre-
lation function are presented for each choice of δ. Left panel: δ = 0.1. Middle panel:
δ = 1. Right panel: δ = 10.
As demonstrated in Figure 4.2, the ﬁrst choice δ = 0.1 yields in signiﬁcant autocor-
relations, which indicates that the chain has not converged after 5000 iterations. The
acceptance rate is extremely high, which conﬁrms the drawback of too small steps of
the RWM formerly stated. In the case of δ = 10, the autocorrelations are less remark-
able, but the chain still converges more slowly than the second case (δ = 1). Hence,

52
4.1. MCMC-BASED ALGORITHMS
in this particular example, δ = 1 with the median acceptance rate is proved to be the
most eﬃcient among the three. The autocorrelations decay to nearly zero. However,
we also notice that δ = 10 which gives the lowest acceptance rate performs better than
a high acceptance rate provided by δ = 0.1.
It is demonstrated that in the case of Random Walk MH with multivariate normal
proposal, and a large dimensional context (d →∞), the optimum is achieved when
the overall acceptance rate (without the burn-in part) of the chain is close to 0.234
(Roberts et al.; Roberts and Rosenthal; B´edard, 2008), and the variance of the proposal
distribution is (2.382/d)Σπ (Gelman et al., 1996), with d the dimension of X and Σπ
the covariance matrix of the target distribution.
To estimate Σπ, a few adaptive
algorithms have been developed in the last two decades, the most famous one is the
Adaptive Metropolis-Hastings proposed by Haario et al. (1999, 2001).
Adaptive Metropolis
To avoid the time-consuming manual tuning of the proposal distribution, meanwhile
to optimize the choice of Gaussian RWM proposals aiming at a more rapid convergence,
Haario et al. (2001) have proposed the Adaptive Metropolis to update continuously Σπ
(learn on the ﬂy). Inspired by the Robbins-Monro update scheme (Robbins and Monro,
1951), the stochastic approximation framework is proposed as follows :
Algorithm : Adaptive Metropolis
• Initialization
- Choose initial values for X0, µ0 and Σ0.
• Iteration
- For i = 1, . . . , n :
1. Sample Zi ∼N(Xi−1, λΣi−1), with λ = 2.382/d.
2. Set
Xi =
(
Zi
with probability α(Xi−1, Zi),
Xi−1
with probability 1 −α(Xi−1, Zi),
where α(x, z) is given by (4.2).
3. Update
µi = µi−1 + γi(Xi −µi−1),
Σi = Σi−1 + γi((Xi −µi−1)(Xi −µi−1)T −Σi−1).
(4.5)
In this algorithm, γi is a deterministic, non-increasing sequence of stepsizes which
satisﬁes P∞
i=1 γi = ∞and P∞
i=1 γ1+ν
i
< ∞for some ν > 0. The objective is to make
sure that the variations introduced by the adaptive scheme vanish as the iteration

CHAPTER 4. BAYESIAN ESTIMATION
53
i →∞, so that π-ergodicity of the chain is guaranteed. One classical choice is 1/i,
with i denoting the current iteration number.
In literature, many adaptive schemes have been proposed which appear to enhance
signiﬁcantly the acceptance rate of the MCMC based methods. However, prudence
must be taken to make sure that the adaptation does not damage the detailed balance
and the overall ergodicity of the chain, for it is obvious that the adaptive scheme
has modiﬁed the nature of the chain, the process is no longer Markovian because of
the dependence on the history of the chain. Only in some cases, it can be proved
that the algorithm still has appropriate ergodicity properties which ensure the correct
generation of samples from the target distribution. For further ergodicity investigation,
please refer to Haario et al. (2006).
Moreover, there may still remain some diﬃculties during the exploration of the
target distribution. In the particular plant growth models studied in this thesis, we
are facing multi-dimensional vectors with various scales. When the initial values of Σπ
are poorly chosen, in a way that λΣi−1 can be too large in some directions or too small
in all the directions, it results in poor exploration of the target distribution due to the
localised proposals. This motivates the introduction of a non-increasing function for
the scaling parameter λ in a global adaptive scaling framework, which initially takes
the value of 2.382/d (Andrieu and Thoms, 2008).
Algorithm : Adaptive Metropolis with global multivariate adaptive scaling
• Initialization
- Choose initial values for X0, µ0, Σ0 and λ0.
• Iteration
- For i = 1, . . . , n :
1. Sample Zi ∼N(Xi−1, λi−1Σi−1).
2. Set
Xi =
(
Zi
with probability α(Xi−1, Zi)
Xi−1
with probability 1 −α(Xi−1, Zi),
where α(x, z) is given by (4.2).
3. Update µi and Σi as in (4.5).
4. Update λi :
log λi = log λi−1 + γi (α(Xi−1, Zi) −α∗) ,
(4.6)
with α∗the target acceptance rate.
Note that this algorithm is proved to be quite useful in the early stages of the
computation. It improves the performance of Adaptive Metropolis in practice. Never-
theless, it is unlikely to make signiﬁcant diﬀerence in a long run. The interest lies in
the case of poor chosen Σ0 which can be translated into either too small or too large
acceptance probability.

54
4.1. MCMC-BASED ALGORITHMS
It is shown that this algorithm can be further improved in the case when we cus-
tomize λ, λ ∈R for each component (parameter) of the state space X when updating
the chain in an univariate fashion. To achieve this goal, we ﬁrst revisit the Gibbs
Sampler.
4.1.2
Gibbs Sampler
Introduced by Geman and Geman (1984) and developed by Gelfand et al. (1990),
the Gibbs Sampler can be seen as a special case of MH transition (Robert et al.,
1999) which decomposes a multi-dimensional simulation into a collection of single
dimensional ones. For each step of the algorithm, only a single component of the state
of the chain is updated, by keeping the others ﬁxed and drawing form the conditional
distribution of the component given the others. Suppose that the i-th component of x
is to be updated, x−i denotes the complementary components, a proposal distribution
is thus chosen:
q(z|x) =
(
π(z(i)|x(−i))
if x(−i) = z(−i),
0
otherwise.
(4.7)
Theorem 4.1.1 The Gibbs sampling method is equivalent to the composition of p
Metropolis-Hastings algorithms, with acceptance probabilities equal to 1.
Proof
The resulting acceptance probability is:
α(x, z) = π(z)q(x|z)
π(x)q(z|x) = π(z)/π(z(i)|x(−i))
π(x)/π(x(i)|z(−i))
= π(z)/π(z(i)|z(−i))
π(x)/π(x(i)|x(−i))
since x(−i) = z(−i)
= π(z(−i))
π(x(−i)) = 1.
2
To explain this proof, one can easily imagine that the only possible jump is the pro-
posal z that matches x on all components other than the i-th, and it is accepted
automatically.
Now suppose that πu(·) is a d-dimensional un-normalised density on a state space
X which is an open subset of Rd, with X = (X(1), . . . , X(d)), the sampling proceeds by
systematically updating each component in turn based on univariate full conditional
distributions π1, . . . , πd. For j = 1, 2, . . . , d:
X(j) | x(1), . . . , x(j−1), x(j+1), . . . , x(d) ∼πj(x(j) | x(1), . . . , x(j−1), x(j+1), . . . , x(d)).
Therefore, to update from Xi−1 to Xi, the associated Gibbs sampling algorithm can
be described as follows :

CHAPTER 4. BAYESIAN ESTIMATION
55
Algorithm : Gibbs Sampling
- Given Xi−1 = (x(1)
i−1, . . . , x(d)
i−1).
- Sample
1. X(1)
i
∼π1(x(1) | x(1)
i−1, . . . , x(d)
i−1),
2. X(2)
i
∼π2(x(2) | x(1)
i , x(3)
i−1, . . . , x(d)
i−1),
. . . ,
d. X(d)
i
∼πd(x(d) | x(1)
i , . . . , x(d−1)
i
).
Note that although the Gibbs sampler is considered as a special case of MH, it has
some features that can be distinguished from MH and need to be taken care of during
implementation:
– Since all the proposed values are accepted, the acceptance rate is equal to 1, which
indicates that the optimal acceptance rates cannot be applied in this setting. The
convergence criteria are therefore diﬀerent from those of MH.
– The fact that the choice of instrumental distribution is limited implies that the
prior knowledge and some analytical properties of πu(·) are required when im-
plementing the Gibbs sampler.
– If the transition kernel associated with the resulting chain is absolutely con-
tinuous with respect to the dominating measure, then the chain is irreducible,
aperiodic and therefore ergodic. Detailed proof can be found in (Robert et al.,
1999).
Thanks to Gibbs sampler, we are able to have the choice to sample from high
dimensional distribution using lower (one) dimensional conditional distributions. Mo-
tivated by the fact that some of the conditional distributions might be diﬃcult or even
impossible to sample from, it gives rise to an extremely convenient and widely used
algorithm known as Metropolis-within-Gibbs (Carter and Kohn, 1994), or Hastings-
within-Gibbs. The idea is to hybrid the Metropolis Hastings and the Gibbs sampler,
replacing some sampling steps from the conditional distribution πi(· | x(−i)) in Gibbs
sampler by a Metropolis step.
4.1.3
Metropolis-within-Gibbs algorithm
In this thesis, beside improving the performance of adaptive Metropolis, another
motivation to employ the Metropolis-within-Gibbs algorithm comes from the fact that
in state-space plant growth models, we are often interested in some hidden state vari-
ables other than the unknown parameters (also known as latent variables) (see Equa-
tion (3.1)), such as biomass of the root compartment for yield prediction. Even if
the marginal density of the parameter vector Θ is our sole interest, since π(Θ|y1:tmax)
are often analytically intractable or diﬃcult to evaluate, the hidden state variables
are often introduced to provide an analytical expression, and subsequently make the
numerical implementation easier. Hence, a joint estimation of both unknown parame-
ters and hidden states is required. Intuitively, given the target p(Θ, x1:tmax|y1:tmax), we
deﬁne the generic joint updates’ scheme:

56
4.1. MCMC-BASED ALGORITHMS
– Update Θ ∼π(θ|x1:tmax, y1:tmax).
– Update X1:tmax ∼π(x1:tmax|Θ, y1:tmax).
However, to obtain the full set of conditional distributions in order to update such
time dependent variables simultaneously can be a troublesome task. Being able to
break the hidden state vector into unidimensional (or lower dimensional) components
can largely facilitate the update process of these hidden state variables.
Under these circumstances, the Metropolis-within-Gibbs appears to provide an
appropriate framework, since it allows us not only to reduce the dimensionality of the
parameter vector, separate and alternate the estimation of unknown parameters Θ =
{θ(1), . . . , θ(d)}, d ∈N∗and the hidden state variables X = {x(1), . . . , x(tmax)}, tmax ∈
N∗, but also to simplify the update process by replacing the sampling step of Gibbs
Sampling by a Metropolis-Hastings step. In this way, we no longer require to sample
directly from the full set of conditional distributions which can be hard or impossible
to obtain.
In the following, the adaptive Metropolis-within-Gibbs algorithm for state-space
models is presented. It can be used to perform a numerical approximation by simulat-
ing an ergodic Markov chain {θ(1:d)
i
, x(1:tmax)
i
} which admits π(Θ, x1:tmax|y1:tmax) as its
stationary distribution.
Algorithm : Adaptive Metropolis-within-Gibbs
• Initialization
- Choose initial values for X0 = (θ(1)
0 , . . . , θ(d)
0 , x(1)
0 , . . . , x(tmax)
0
).
• Iteration
- For i = 1, . . . , n :
• Parameters
- For j = 1, . . . , d :
1. Sample Z(j)
i
∼qj(θ(j) | θ(1)
i , . . . , θ(j−1)
i
, θ(j+1)
i−1 , . . . , θ(d)
i−1, x(1:tmax)
i−1
).
2. Set
θ(j)
i
=
(
Z(j)
i
with probability αj(θ(j)
i−1, Z(j)
i ),
θ(j)
i−1
with probability 1 −αj(θ(j)
i−1, Z(j)
i ),
where
αj(x, z) = min

1, πj(z)
πj(x)
qj(x | z)
qj(z | x)

.
(4.8)
• Hidden states
- For t = 1, . . . , tmax :
1. Sample Z(d+t)
i
∼qt(x(t) | θ(1:d)
i
, x(1)
i , . . . , x(t−1)
i
, x(t+1)
i−1 , . . . , x(tmax)
i−1
).
2. Set
x(t)
i
=
(
Z(d+t)
i
with probability αd+t(x(t)
i−1, Z(d+t)
i
),
x(t)
i−1
with probability 1 −αd+t(x(t)
i−1, Z(d+t)
i
),
where αd+t(x, z) can be obtained by (4.8).

CHAPTER 4. BAYESIAN ESTIMATION
57
Note that when the posterior distribution (target distribution) can be expressed
in its analytical form, we need to determine if it is better to sample from the target
distribution individually or in groups. The latter is known as block updating, in contrast
to componentwise sampling. It refers to splitting a multivariate vector into groups and
being sampled separately. Parameters which are more correlated should be grouped
into the same block to retain their correlations instead of ignoring them as is the
case in componentwise sampling. Moreover, there exist other advantages of the block
updating, such that diﬀerent sampling strategies can be used for each block, and that
large dimensional covariance matrices can be reduced, which can be helpful for high
dimensional models.
In this algorithm, the block update is adopted for the parameter Θ in which all of its
components are updated simultaneously by using a multivariate proposal distribution.
However, we may also choose to implement Adaptive Metropolis with componentwise
updating. With such an update scheme, one λi := (λ1
i , . . . , λd
i ) for each parameter can
be deﬁned at iteration i, to tune the random walk step so as to speed up convergence.
This approach is known as Adaptive Metropolis with componentwise adaptive scaling
(Andrieu and Thoms, 2008).
As for the hidden states’ estimation, in this algorithm, we opt for a componentwise
update. The advantage of this choice is that it is very easy to implement. A convenient
choice of proposal distribution is the model transition density.
In the next section, further attention is paid to the joint update scheme of the
parameters and the hidden state variables. In the case of plant growth models, some
important issues may arise during the implementation regarding the mixing properties
of the chain which may aﬀect the eﬃciency of the estimates in a signiﬁcant way. An
adapted algorithm is thus proposed based on the previous Adaptive Metropolis-within-
Gibbs algorithm.
4.1.4
Adapted Metropolis-within-Gibbs
Mixing property
The conditional joint updates’ scheme enables joint estimation of both the parame-
ter vector and the hidden state variables. As formerly mentioned, the natural approach
is to update the parameter conditionally on the current value of the estimated hidden
state trajectory. Yet the overall eﬃciency of the algorithm can be sabotaged if there
is a strong correlation between the parameter vector Θ and the hidden state vector X
(Liu et al., 1994; Roberts and Sahu, 1997), which is obviously an undesirable feature.
In the plant growth models that we study, such a problem is frequently encountered.
This model conﬁguration known as centered parameterisation (Fearnhead, 2011), for
which :
p(Θ|x1:tmax, y1:tmax) ≈p(Θ|x1:tmax).

58
4.1. MCMC-BASED ALGORITHMS
It is shown by (Roberts and Sahu, 1997) that for f ∈L2, the Bayesian fraction of
missing information is deﬁned by
γf = 1 −E(Var(f(Θ)|x1:tmax, y1:tmax)|y1:tmax)
Var(f(Θ)|y1:tmax)
.
(4.9)
The convergence rate is thus supfγf. When the value of γ ≈1, it implies a poor
mixing between Θ and X. It is due to the fact that the most of the variation of f(Θ)
is explained by x1:tmax conditioned by the data y1:tmax. Further investigation of this
problem, particularly the convergence rate of such algorithms can be found in Liu
(1994) and Roberts and Sahu (1997).
To understand the impact of strong correlation on the mixing property of the
chain, one may imagine that large moves of Θ are more likely to be rejected since it is
inconsistent with the value of x1:tmax. One way to alleviate this is to consider the joint
update of (Θ, x1:tmax) with a proposal distribution under the form (Fearnhead, 2011) :
q(Θ′, x′
1:tmax|Θ, x1:tmax) = q(Θ′|Θ)q(x′
1:tmax|Θ′),
where (Θ′, x′
1:tmax) denotes the proposal. Note that q(Θ′|Θ) allows to propose moves of
reasonable sizes, and the proposed hidden states being consistent with Θ′. Indeed, the
choice of the proposal for the hidden states is crucial. If the exploration of the state
space X is not guided, the proposed trajectory can result in a very poor likelihood
evaluation (a trajectory unlikely to happen in reality). In order to go through the
state space in a more informative way, ideally, the proposal should take into account
the observations y1:tmax and could be chosen as :
q(x′
1:tmax|Θ′) = p(x′
1:tmax|Θ′, y1:tmax).
Nonetheless, such a proposal for the hidden states would necessitate computing
and simulating from π(x′
1:tmax|Θ′, y1:tmax), which is impossible for most real applica-
tions.
When the density cannot be computed explicitly or if it is complicated to
simulate from, p(x′
1:tmax|Θ′) can be used as a reasonable compromise, which simpliﬁes
the computation in a considerable way and is very easy to simulate from. Thus, the
acceptance probability α can be simpliﬁed and this value does not need to be evaluated:
α({Θ, x1:tmax}, {Θ′, x′
1:tmax})
= min

1, π(Θ′, x′
1:tmax|y1:tmax)q(Θ, x1:tmax|Θ′, x′
1:tmax)
π(Θ, x1:tmax|y1:tmax)q(Θ′, x′
1:tmax|Θ, x1:tmax)

= min

1, p(Θ′, x′
1:tmax|y1:tmax)
p(Θ, x1:tmax|y1:tmax)
q(Θ|Θ′)q(x1:tmax|Θ)
q(Θ′|Θ)q(x′
1:tmax|Θ′)

= min

1, p(y1:tmax|Θ′, x′
1:tmax)p(x′
1:tmax|Θ′)p(Θ′)
p(y1:tmax|Θ, x1:tmax)p(x1:tmax|Θ)p(Θ)
q(Θ|Θ′)p(x1:tmax|Θ)
q(Θ′|Θ)p(x′
1:tmax|Θ′)

= min

1, p(y1:tmax|Θ′, x′
1:tmax)p(Θ′)
p(y1:tmax|Θ, x1:tmax)p(Θ)
q(Θ|Θ′)
q(Θ′|Θ)

.
(4.10)

CHAPTER 4. BAYESIAN ESTIMATION
59
Compared to the algorithms presented in the literature, such as the Monte Carlo
within Metropolis and Grouped Independence MH (Beaumont, 2003), in this thesis,
we propose to simplify the step of simulating a large number of X′ from p(x1:tmax|Θ′)
by simulating only once the hidden state variables. Thus, the eﬃciency of the resulting
algorithm is based on the eﬃciency of the proposal distribution of Θ, as well as the
closeness of q(x′
1:tmax|Θ′) to p(x′
1:tmax|Θ′, y1:tmax). When the modelling noises are rela-
tively small, the proposed algorithm helps to reduce considerably the computational
cost.
Furthermore, with the purpose of improving the estimation of the hidden states,
we propose to perform additional Metropolis-within-Gibbs steps simulating X′ from
p(x′
1:tmax|Θ) repeatedly once the functional parameters have converged. This also al-
lows to improve the estimation of the modelling noise parameters, the implementation
details of which are described in Chapter 6.
We also remark that if Θ has a low dimension (d ≤6 in our test case), a multi-
variate proposal may be preferred since its computational cost is more advantageous.
Therefore, the resulting algorithm can be summarized as follows:
Algorithm : Adapted Metropolis-within-Gibbs
• Initialization
- Choose initial values for Θ0 = {θ(1)
0 , . . . , θ(d)
0 } and x0 = {x(1)
0 , . . . , x(tmax)
0
} with
x0 = f(Θ0), where f is the transition density of the model.
- Choose initial values for µ0, Σ0 and λ0.
• Parameters
Iteration
- For i = 1, . . . , n1 :
1. Sample θ(1:d)
i
′ ∼N(θ(1:d)
i−1 , λi−1Σi−1).
2. Sample x(1:tmax)
i
′ ∼p(x1:tmax|θ(1:d)
i
′).
3. Set
{θ(1:d)
i
, x(1:tmax)
i
} =
(
{θ(1:d)
i
′, x(1:tmax)
i
′}
with probability αθ(θ(1:d)
i−1 , θ(1:d)
i
′),
{θ(1:d)
i−1 , x(1:tmax)
i−1
}
with probability 1 −αθ(θ(1:d)
i−1 , θ(1:d)
i
′),
where αθ(θ, θ′) is given by (4.10).
4. Update µi and Σi as in (4.5).
5. Update λi as in (4.6).
Estimator
– For a burn-in period n0 < n1:
ˆθ(1:d)
n1
=
1
n1 −n0
n1
X
k=n0+1
θ(1:d)
k
,
ˆΣn1 =
1
(n1 −n0) −1
n1
X
k=n0+1
(θ(1:d)
k
−ˆθ(1:d)
n1 )T(θ(1:d)
k
−ˆθ(1:d)
n1 ).

60
4.1. MCMC-BASED ALGORITHMS
• Hidden states
• Iteration
- For j = n1 + 1, . . . , n2; n2 > n1 + 1 :
- For t = 1, . . . , tmax :
1. Sample x(t)
j
′ ∼qt(x(t) | ˆθ(1:d)
n1 , x(1)
j , . . . , x(t−1)
j
, x(t+1)
j−1 , . . . , x(tmax)
j−1
).
2. Set
x(t)
j
=
(
x(t)
j
′
with probability αd+t(x(t)
j−1, x(t)
j
′),
x(t)
j−1
with probability 1 −αd+t(x(t)
j−1, x(t)
j
′),
where
αd+t(x(t)
j−1, x(t)
j
′) = min
 
1, π(x(t)
j
′|x(1:t−1)
j
, x(t+1:tmax)
j−1
, ˆθ(1:d)
n1 , y1:tmax)
π(x(t)
j−1|x(1:t−1)
j
, x(t+1:tmax)
j−1
, ˆθ(1:d)
n1 , y1:tmax)
· qt(x(t)
j−1|ˆθ(1:d)
n1 , x(1:t−1)
j
, x(t+1:tmax)
j−1
)
qt(x(t)
j
′|ˆθ(1:d)
n1 , x(1:t−1)
j
, x(t+1:tmax)
j−1
)
!
.
(4.11)
N.B.
- In the hidden state estimation part, the target distribution for the hidden state x(t)
at time t can be simpliﬁed according to the Markov chain property :
π(x(t)|x(1:t−1), x(t+1:tmax), θ(1:d), y1:tmax)
∝
p(x(t)|x(t−1)) p(x(t+1)|x(t)) p(y(t)|x(t)).
- As for the proposal distribution for the hidden state update of x(t), a convenient choice
is to use the transition density of the model f. Since x(t) only depends on θ(1:d) and
on x(t−1) in the case of a state space model, the proposal distribution for the state
variable x(t) can be simpliﬁed as :
qt(x(t) | θ(1:d), x(1:t−1), x(t+1:tmax)) = p(x(t) | θ(1:d), x(t−1)).
- Based on the previous simpliﬁcations, the acceptance ratio (4.11) can be described
as:
αd+t(x(t)
j−1, x(t)
j
′)
= min
 
1, p(x(t)
j
′|x(t−1)
j
, ˆθ(1:d)
n1 )p(x(t+1)
j−1 |x(t)
j
′, ˆθ(1:d)
n1 )p(yt|x(t)
j
′, ˆθ(1:d)
n1 )
p(x(t)
j−1|x(t−1)
j
, ˆθ(1:d)
n1 )p(x(t+1)
j−1 |x(t)
j−1, ˆθ(1:d)
n1 )p(yt|x(t)
j−1, ˆθ(1:d)
n1 )
qt(x(t)
j−1|x(t−1)
j
, ˆθ(1:d)
n1 )
qt(x(t)
j
′|x(t−1)
j
, ˆθ(1:d)
n1 )
!
= min
 
1, p(x(t+1)
j−1 |x(t)
j
′, ˆθ(1:d)
n1 )p(y(t)|x(t)
j
′, ˜θ(1:d)
j,t )
p(x(t+1)
j−1 |x(t)
j−1, ˆθ(1:d)
n1 )p(y(t)|x(t)
j−1, ˜θ(1:d)
j−1,t)
!
.
(4.12)

CHAPTER 4. BAYESIAN ESTIMATION
61
- Instead of ﬁxing θ(1:d) at ˆθ(1:d)
n1
when estimating the hidden state variables, an ad-
ditional step of sampling ˜θ(1:d)
j,t
∼N(ˆθ(1:d)
n1 , ˆΣn1) can be considered before drawing a
new hidden state candidate. It allows to introduce more variability to the proposal.
According to the Markov chain property :
π(θ(1:d), x(t)|x(1:t−1), x(t+1:tmax), y1:tmax)
∝
p(θ(1:d)) p(x(t)|x(t−1), θ(1:d)) p(x(t+1)|x(t), θ(1:d)) p(y(t)|x(t), θ(1:d)).
In this way, we obtain a dual proposal as in the case for the parameter update, the
acceptance ratio (4.11) however, remains the same :
αd+t({x(t)
j−1, ˜θ(1:d)
j−1,t}, {x(t)
j
′, ˜θ(1:d)
j,t })
= min
 
1, p(x(t)
j
′, ˜θ(1:d)
j,t |x(t−1)
j
, x(t+1)
j−1 , y(t))
p(x(t)
j−1, ˜θ(1:d)
j−1,t|x(t−1)
j
, x(t+1)
j−1 , y(t))
q(˜θ(1:d)
j−1,t)
q(˜θ(1:d)
j,t )
q(x(t)
j−1|x(t−1)
j
, ˜θ(1:d)
j−1,t)
q(x(t)
j
′|x(t−1)
j
, ˜θ(1:d)
j,t )
!
= min
 
1,
p(˜θ(1:d)
j,t )p(x(t)
j
′|x(t−1)
j
, ˜θ(1:d)
j,t )p(x(t+1)
j−1 |x(t)
j
′, ˜θ(1:d)
j,t )p(y(t)|x(t)
j
′, ˜θ(1:d)
j,t )
p(˜θ(1:d)
j−1,t)p(x(t)
j−1|x(t−1)
j
, ˜θ(1:d)
j−1,t)p(x(t+1)
j−1 |x(t)
j−1, ˜θ(1:d)
j,t )p(y(t)|x(t)
j−1, ˜θ(1:d)
j−1,t)
· p(˜θ(1:d)
j−1,t)
p(˜θ(1:d)
j,t )
p(x(t)
j−1|x(t−1)
j
, ˜θ(1:d)
j−1,t)
p(x(t)
j
′|x(t−1)
j
, ˜θ(1:d)
j,t )
!
= min
 
1, p(x(t+1)
j−1 |x(t)
j
′, ˜θ(1:d)
j,t )p(y(t)|x(t)
j
′, ˜θ(1:d)
j,t )
p(x(t+1)
j−1 |x(t)
j−1, ˜θ(1:d)
j,t )p(y(t)|x(t)
j−1, ˜θ(1:d)
j−1,t)
!
.
(4.13)
- Note also that if only the functional parameter estimation is desired, the hidden state
estimation part can be omitted.
More discussion about the mixing property of state-space models can be found in
Andrieu and Roberts (2009) and Andrieu et al. (2010).
Scarce observations
As mentioned previously, one important characteristic of the experimental data for
plant growth models is that they are often limited and unevenly registered. Tanner
and Wong (1987) point out that sometimes the posterior distributions are intractable
because of the lack of some data, however MCMC can still be used in those situations.
Therefore, the observation vector Y can be separated into two parts, Y = (y, y′), where
y are the observed data and y′ are the missing data. The current posterior distribution
π(Θ|y) may appear to be muddled, while the “intended” posterior distribution π(Θ|Y )
could be in a tractable form. According to the requirement of the Gibbs sampler, the
full conditionals are accordingly:
– Update Θ ∼π(Θ|x1:tmax, y′, y).

62
4.1. MCMC-BASED ALGORITHMS
– Update y′ ∼π(y′|Θ, x1:tmax, y).
– Update X ∼π(x1:tmax|Θ, y′, y).
Note that π(y′|Θ, x1:tmax, y) = π(y′|Θ, x1:tmax). Consequently, the missing data y′
can be treated as hidden states, also known as latent variable.
Given the fact that the missing observations y′ are not really the objective of our
estimation, in our implementation, the trajectory is divided into segments according to
the observations y. The missing segment of the trajectory of Y is accepted or rejected
according to the decision regarding the corresponding segment of x. More precisely, if
ti and ti+1 denote the time of two successive observations, then the proposal for the
segments xti+1:ti+1 and y′
ti+1:ti+1−1 are accepted or rejected according to the decision
for the proposal x(ti+1).
Further discussions about the general strategies regarding the missing data can be
found in Smith and Roberts (1993) and Robert and Casella (1999). In the following,
a series of key issues regarding the implementation of MCMC based methods are
presented.
4.1.5
Implementation issues
To sum up, the implementation of an MCMC based method should involve con-
structing an ergodic Markov chain with transition kernel K which has an invariant
distribution π(·).
However in practice, many issues have been raised during the implementation of
MCMC, for instance, the burn-in period can be too long and potentially useful samples
are wasted, or the chain could be stopped too early and miss some modes of the target
distribution, or the estimation provided contains no information of the quality of the
estimates. In this section, these problems are addressed and discussed.
Burn-in period
When applying an MCMC based method, it is highly possible that at the begin-
ning of the chain, there is a period during which the algorithm has not converged
to the stationary distribution and therefore should be discarded when computing the
estimates. This period is known as burn-in period. The length of the burn-in period
however, depends not only on the initial value of the chain X0, but also on the shape
of the target distribution.
To determine the length of the burn-in period, the intuitive way is to run the
algorithm a few times with diﬀerent initial values and to note the number of iterations
needed before the chain converges to some kind of equilibrium.
Thus the burn-in
period is calculated in an empirically way based on these observations. As a matter
of fact, the burn-in period is a method to ﬁnd a good starting point, from which the
chain is considered “converged” and the following iterations can be used for MCMC
calculations.

CHAPTER 4. BAYESIAN ESTIMATION
63
There are other ways to ﬁnd a good starting point, for example, to start the next
run from the point where the last run ended, or to start at a mode of the equilib-
rium distribution obtained by other optimization methods. A Markov chain started
anywhere near the center of the equilibrium distribution does not need burn-in. More
discussion regarding the burn-in period issue can be found in Jones and Hobert (2004).
Up to now, we have reviewed some methods to construct a Markov chain which may
produce an ergodic stationary distribution as its posterior distribution. In this case,
as stated in Section 3.5.1, the average of the estimates converges towards a Gaussian
distribution. However, since the samples are often not independent (i.e. correlation
between consecutive iterations), one possible way to reduce the correlation is to take
into account every k-th estimate of the chain, which is known as the thinning technique.
Although the chain is no longer Markovian if treated this way, the subchains are still
proved to converge to the correct distribution (Roberts and Rosenthal, 2004; Robert
and Casella, 2010).
Furthermore, the precision of the mean estimate can as well be provided. In the
following, the batch mean method is presented.
Precision estimation: Batch means
A batch consists of a subsequence of estimates given by consecutive iterations of
the Markov chain Xk+1, ..., Xk+b, with batch length b. If the Markov chain reaches an
ergodic and stationary distribution, then all batches with the same length should have
the same joint distribution. Under regularity conditions (Theorem 3.5.3), the CLT can
be applied.
Suppose X1, . . . , Xm is a Markov chain of m iterations with the burn-in period
discarded. Let f : X 7→R be a Borel function. We deﬁne ¯fm =
1
m
Pm
i=1 f(Xi). The
batch mean method can be describe as follows :
– Non-overlapping batch mean : the chain is divided into batches of equal
size. m = ambm. am denotes the number of the batches and bm denotes the
batch length. The mean estimates of am batches are deﬁned as :
¯Yj = 1
bm
bm
X
k=1
f(X(j−1)bm+k),
for j = 1, . . . , am.
The batch means estimates of σ2
f are therefore :
ˆσ2
BM =
bm
am −1
am
X
j=1
(¯Yj −¯fm)2
(4.14)
– Overlapping batch mean : with the m −bm + 1 overlapping batches of length
bm, the mean estimates are given by
¯Yj = 1
bm
bm
X
k=1
f(Xj−1+k),
for j = 1, . . . , m −bm + 1.

64
4.1. MCMC-BASED ALGORITHMS
Figure 4.3: Variance estimation performed with batch means.
The batch means estimates of σ2
f are thus :
ˆσ2
OBM =
mbm
(n −bm)(n −bm + 1)
n−bm
X
j=0
(¯Yj −¯fm)2
(4.15)
Batch means is an attractive method for its easy implementation. However, in
literature, some authors warn that it should be used with caution since the estimator
ˆσ2
BM is not consistent (Roberts, 1996).
Flegal and Jones (2010) demonstrate that
the overlapping batch means provide a consist estimator ˆσ2
OBM and are more stable
than the non-overlapping batch means. On the other hand, Jones et al. (2006) argue
that if the number of batches and their sizes are allowed to increase as the overall
length of the chain increases, then by setting bm = ⌊mψ⌋and am = ⌊m/bm⌋, ˆσ2
BM →
σ2 with probability 1 as m →∞. According to the regularity condition, the chain
has to be geometrically ergodic (i.e. Eπ|f|2+δ+ϵ < 0 for some strictly positive δ and
strictly positive ϵ with (1 + δ/2)−1 < ψ < 1). Hence, ψ = 1/2 is a convenient choice
(bm = ⌊√m⌋) in practice. Therefore, in this thesis, we consider the batch means with
increasing batch length rather than the ﬁxed length.
It is noteworthy that this approach allows us to obtain an estimation of the Monte
Carlo Error (MCE) of the estimate ¯fm : ˆσ2
f/m, and from there, to form an asymptot-
ically valid conﬁdence interval:
[ ¯fm + tam−1
ˆσBM
√m ; ¯fm −tam−1
ˆσBM
√m ].
where tam−1 is a quantile of Student’s -t distribution with am −1 degrees of freedom.
Note that the estimated Monte Carlo error can also be considered as a stopping
criteria for the MCMC-based algorithm by putting a constraint on the precision of
the estimate : limiting the conﬁdence interval width. It can also be estimated by

CHAPTER 4. BAYESIAN ESTIMATION
65
performing a large number of the estimation with the same conﬁguration, prior and
initialization. Indeed, the stopping criteria is crucial, the most frequently asked ques-
tion in practice is when the simulation can be ended. The Batch means is a popular
method, yet it does not give any indication regarding the convergence of the chain. In
the following, some convergence diagnostic related problems are discussed.
Convergence diagnostic and stopping rules
Undoubtedly, stopping rules and convergence diagnostic are both crucial and criti-
cal issues in the practice of MCMC-based methods. The objective is to decide whether
the chain has reached its invariant distribution and whether the converged distribution
is the target distribution. Regarding this issue, conﬂicting advices are often given in
literature which makes the output analysis of MCMC a muddled area. The diﬃculty
is that the convergence rate varies according to each algorithm and the speciﬁc tar-
get distribution. A chain may appear to have converged while it is not, as a result
of poorly connected parts of the considered state space. The convergence is in fact
conditioned on the initial value of the chain, which is known as pseudo-convergence or
pseudo-ergodicity. To move from one part to another could take a surprisingly long
time, especially in case of multimodality (Figure 4.4). As stated in Brooks and Roberts
(1998), it seems that it is not possible to get any analytical tool or even stopping rules
that could uniquely determine the necessary length of the run. Likewise, the MCMC
based algorithm cannot be veriﬁed thoroughly whether the samples produced can truly
characterize the target distribution. Hence, the proposed diagnostics are only used for
educated guess regarding the convergence of the algorithm.
Figure 4.4: Multimodality: a contour plot of log-likelihood surface of a two-dimensional
state-space and three independent runs (Robert and Casella, 2010).

66
4.1. MCMC-BASED ALGORITHMS
Figure 4.5: Histograms of runs with diﬀerent numbers of iterations compared to the
theoretical target distribution.
An easy way to verify the convergence is to run a few number of parallel chains
with diﬀerent initial values for each. With the growing iteration number, as illustrated
by Figure 4.5, one may visually identify the period after which the chains start to
converge, and if they converge to the same distribution.
On the other hand, monitoring the acceptance rate is also a very eﬀective way to
diagnostic the convergence. Although some optimal values are suggested in literature
as mentioned above (0.234 for multidimensional problems and 0.44 for unidimensional
problems). However, it is not always the case that 0.44 is the optimal, as demonstrated
by Figure 4.2. The real optimal depends on the shape of the posterior distribution.
Generally speaking, an acceptance rate between 0.1 and 0.5 can be considered as
satisfactory.
As for the stopping rules, in this thesis, we propose a mixed strategy. Two criteria
are considered, one to diagnostic the convergence of the chain and the other to claim
the end of the run. Similar approaches based on the CLT are discussed in Chauveau
and Diebolt (1999).
- Convergence diagnostic based on mean estimates
As we all know, the scaling nature of the Adaptive Metropolis changes the nature of
the Markov chain, in the sense that current state of the chain depends not only on the
one previous state, but on the history of the chain. Therefore, the ﬁrst criterion is used
to determine the end of the adaptive scheme (tuning of the random walk proposal) and
deﬁne the burn-in period. In other words, once this criterion is satisﬁed, the covariance
matrix Σ is ﬁxed and no longer dependent on the evolution of the chain.
The criterion is grounded on a standard stopping rule computing the last an suc-
cessive overlapped batch means with each containing bn iterations (Booth and Hobert,

CHAPTER 4. BAYESIAN ESTIMATION
67
1999) with cn iterations overlapped. ∀i ∈{1, . . . , d}, for r = 1, . . . , an, if the relative
changes in the batch means are suﬃciently small :
max
i
 
| θ(i)
r+1 −θ(i)
r
|
| θ(i)
r
| +δ1
!
< δ2
(4.16)
then the convergence can be claimed. Searle et al. (1992) suggest that δ1 = 0.001 and
δ2 = 0.0005 are generally appropriate choices.
In the light of this basic criterion, a ﬁrst convergence diagnostic can be provided,
however, some parameters may exhibit a very slow ﬁrst order convergence behaviour,
especially when few data are available and the parameters are not sensitive to the
model (see sensitivity analysis in Section 6.1).
Thus, we propose to add another
condition to this: the an successive relative changes should not be monotonic. In our
implementation, an = 4, bn = 3000 and cn = 1000 seem to assure a good convergence
behaviour.
- Stopping rule based on Monte Carlo Errors
If the previous convergence criterion is satisﬁed, the Monte Carlo Error can be used
as the second condition to terminate the simulations. Indeed, asymptotic variance can
also be used for MCMC convergence control Chauveau and Diebolt (2003). Theorem
3.5.3 shows that the precision of the estimates can be provided by assessing the Monte
Carlo Error σ2
f.
It can be obtained by estimating the variance of the asymptotic
distribution of ˆπ(f) with Batch means (Section 4.1.5).
σ2
f := Varπ(f(X1)) + 2
∞
X
i=2
Covπ(f(X1), f(Xi))
as n →0. Therefore, in our implementation, a relative threshold of the estimation
precision is deﬁned for the all the parameters which translates as a constraint on the
width of the conﬁdence interval provided by the chain, so that the simulation continues
if the interval is not narrow enough.
According to the implementation experience, to avoid a premature stop which
would probably result in a poor estimate, a minimum number of the iterations is
assured, which can be determined based on the number of parameters to estimate and
the number of the available observations. Then, the proposing stopping criterion is
checked every mBM iterations (1000 or 5000 in our implementation) until it is satisﬁed
for all the parameters and hidden states. This criterion can be described as follows :
ˆσ(π)
√m + p(m) ≤ϵ,
where p(m) = ϵI(m < mmin) is the penalty term with ﬁxed strictly positive mmin
(10000 in our implementation), I is the indicator function on Z and ϵ is the threshold
predeﬁned according to the application.
More discussion regarding the stopping criteria and convergence diagnostics can
be found in Jones and Hobert (2004), Chauveau and Diebolt (2003) and Roberts and
Rosenthal (2004).

68
4.2. PARALLEL MCMC
It is well known that when using MCMC-based methods, one may adopt either
a suﬃciently long run or many short runs as estimation strategies. In the following
section, some algorithms based on multiple parallel MCMC are presented.
4.2
Parallel MCMC
In the literature, the idea of multiple short runs has been well developed, the mo-
tivation of which comes from the reasoning that a single chain is unable to eﬃciently
cope with potentially complex posterior surface with multiple local optima. such as the
work of Gilks et al. (1994) and Chauveau and Vandekerkhove (2002), who use multiple
chains to explore the space, or some self-regenerative algorithms, such as Mykland et al.
(1995), Gilks et al. (1998) and Sahu and Zhigljavsky (2003), in which mixture com-
ponents are used. However, these approaches involve high computational cost which
makes them rarely feasible to confront multi-dimensional applications. Recognizing
these limits, the DiﬀeRential Evolution Adaptive Metropolis algorithm is proposed.
4.2.1
Diﬀerential Evolution Adaptive Metropolis
The DiﬀeRential Evolution Adaptive Metropolis (DREAM) algorithm is proposed
by Vrugt et al. (2009a) based on the Diﬀerential Evolution-Markov chain (DE-MC)
method (Ter Braak, 2006). The major idea is to run multiple sequences in parallel in
an MCMC setting in order to hasten the convergence and to detect the multimodality
problem in an eﬃcient way if it is present in the target distribution.
In fact, in order to explore multimodal density in eﬃciently, a mode should be
represented by at least a single chain, so that a second chain can be moved to it in
accordance in the DREAM algorithm. This could be due to the quasi-ergodicity, which
refers to isolated modes, or strong correlation between parameters.
−5
0
5
0.0
0.5
1.0
1.5
x
 
Target distribution
p0(.)
(a)
−5
0
5
0.0
0.5
1.0
1.5
x
 
Target distribution
Single quasi−ergodic chain
(b)
−5
0
5
0.0
0.5
1.0
1.5
x
 
Target distribution
Multiple quasi−ergodic chains
(c)
Figure 4.6: Illustrations of quasi-ergodicity (Murray, 2010). (a): The target distribu-
tion and the prior distribution. (b): Estimation results from one quasi-ergodic Markov
chain. (c): The samples result from multiple quasi-ergodic Markov chains.

CHAPTER 4. BAYESIAN ESTIMATION
69
Figure 4.6 gives two examples of quasi-ergodicity when multimodality is present in
the target distribution. Figure 4.6(b) demonstrates the case when only one mode of
the target distribution is detected if only one Markov chain is carried out with a limited
length. It is highly possible that under multimodality target distribution, one Markov
chain with limited length is conditional to its departure point. In the case that multiple
chains are implemented as illustrated by Figure 4.6(c), we are more likely to detect
both modes, however, it is still possible that their weight are not properly deﬁned due
to the small number of the chains which leads to the samples disproportionally being
partitioned in the two modes.
The recommended conﬁguration for the number of chains is M = 2d (Ter Braak
and Vrugt, 2008), with d the dimension of the target distribution initialised from over-
dispersed distributions. Instead of running the chains independently as proposed by
Gelman et al. (2004), jumps are made between chains by generating from a discrete
proposal distribution to encourage the chains to learn from each other. The algorithm
scales the orientation and tunes the proposal distribution by using an adaptive scheme
(Adaptive Metropolis) and is designed to maintain the ergodicity by generating an
exact approximation of the target distribution (posterior pdf) (Vrugt et al., 2009b).
More concretely, the chains are updated sequentially conditional to the other chains.
A ﬁxed multiple of the diﬀerence of the states belonging to randomly chosen pairs of
other chains is taken into account in the proposal. Therefore, the DREAM can be seen
as a single Markov chain on the state space X M (Ter Braak and Vrugt, 2008). The
update of the ith chain uses a mixture of kernels. Vrugt et al. (2009a) demonstrate that
the Markov chain yielded by the DREAM algorithm is ergodic with unique stationary
distribution of pdf π(·)M, with π(·) the original target distribution.
In the following, the DREAM algorithm is detailed and adaptations are made to
ﬁt the algorithm to the state-space model estimations.
Algorithm : DREAM
• Initialization
- For i = 1, . . . , M :
- Choose initial values for Xi,0 = (θ(1)
i,0 , . . . , θ(d)
i,0 , x(1)
i,0 , . . . , x(tmax)
i,0
) from the prior
distributions p0(·).
• Parameters
Iteration
- For j = 1, . . . , n1 :
1. Proposal step: for i = 1, . . . , M :
– Sample e and ϵ:
e ∼Ud(−b, b)
ϵ ∼Nd(0, b∗)
with |b| < 1 and b∗smaller than the width of the target distribution.

70
4.2. PARALLEL MCMC
– Sample θ(1:d)
i,j
′ :
θ(1:d)
i,j
′ = θ(1:d)
i,j−1 + (1d + ed)γ(δ)
 
δ
X
k=1
θ(1:d)
r(k),j−1 −
δ
X
l=1
θ(1:d)
r(l),j−1
!
+ ϵd.
where δ denotes the number of pairs used for the candidate,
r(k), r(l) ∈{1, . . . , M}, r(k) ̸= r(l) ̸= i, and γ = 2.38/
√
2δd.
– Sample x(1:tmax)
i,j
′ ∼p(x1:tmax|θ(1:d)
i,j
′).
2. Transition step: for i = 1, . . . , M :
– Set
{θ(1:d)
i,j
, x(1:tmax)
i,j
} =
(
{θ(1:d)
i,j
′, x(1:tmax)
i,j
′} with probability αθ(θ(1:d)
i,j−1, θ(1:d)
i,j
′),
{θ(1:d)
i,j−1, x(1:tmax)
i,j−1
} with probability 1 −αθ(θ(1:d)
i,j−1, θ(1:d)
i,j
′),
where αθ(θ, θ′) is given by (4.10).
Estimator
– For a burn-in period n0 < n1:
ˆθ(1:d)
n1
=
1
M(n1 −n0)
l=M
X
l=1
n1
X
k=n0
θ(1:d)
l,k ,
ˆΣn1 =
1
M(n1 −n0) −1
l=M
X
l=1
n1
X
k=n0
(θ(1:d)
l,k
−ˆθ(1:d)
n1 )T(θ(1:d)
l,k
−ˆθ(1:d)
n1 )
• Hidden states
– For i = 1, . . . , M :
– Sample ˜θ(1:d)
i
∼N(ˆθ(1:d)
n1 , ˆΣn1).
– Sample xi,n1
(1:tmax) ∼p(x1:tmax|˜θ(1:d)
i
).
Iteration
- For j = n1 + 1, . . . , n2; n2 > n1 + 1 :
- For i = 1, . . . , M :
- For t = 1, . . . , tmax :
1. Sample x(t)
i,j
′ ∼qt(x(t) | ˜θ(1:d)
i
, x(1)
i,j , . . . , x(t−1)
i,j
, x(t+1)
i,j−1, . . . , x(tmax)
i,j−1 ).
2. Set
x(t)
i,j =
(
x(t)
i,j
′
with probability αd+t(x(t)
i,j−1, x(t)
i,j
′),
x(t)
i,j−1
with probability 1 −αd+t(x(t)
i,j−1, x(t)
i,j
′),
where αd+t(x, y) can be obtained according to (4.13).
N.B.

CHAPTER 4. BAYESIAN ESTIMATION
71
- Note that here, we opt to keep independent chains for the estimation of the hidden
state variables while the same between-chain communication can be implemented as
for the estimation of the parameters. However, the comparison result suggests that
it does not signiﬁcantly improve the estimation probably due to the important time
dependency among the hidden states.
- The resampling step for the parameters at the beginning of the hidden state estimation
can be omitted, and therefore reduce the variability of the hidden state proposals.
- Another possible extension for the hidden state variable estimation is to transform
the Gibbs sampling to importance sampling.
- The posterior distribution is built based on the pool of samples from all the chains
except those of the burn-in period.
Unfortunately, in practice, we may run into convergence problems since the chains
may not converge fast enough, therefore the parallel short runs will turn out to be
parallel long runs and the algorithm may end up with computational complexity. In
Geyer (1992) and Robert and Casella (1999) (Section 6.5), the authors argue that
independent parallel chains could be a poor idea, for some of them may not converge.
Therefore, one long chain could be preferred. To avoid this frequently occurred prob-
lem, another technique is developed, taking into account only the last estimates of an
important number of chains. In this way, the parallel computing may reduce eﬃciently
the computational time. The following algorithm, known as Interacting MCMC is one
of the approaches that adopt this strategy.
4.2.2
Interacting Metropolis-within-Gibbs
As stated previously, the idea of multiple MCMC is to accelerate the state space
in a more eﬃcient way compared to single MCMC, and can be parallelised and dis-
tributed to multiple CPU to save computational time. It is a temping idea, despite
the convergence of all the chains which is hard to achieve. Eﬀorts have been made to
encourage the exchange among chains (Chauveau and Vandekerkhove, 2002; Drugan
and Thierens, 2005; Laskey and Myers, 2003) with the purpose of improving the mix-
ing properties of the samples. A Population Monte Carlo framework was proposed by
Capp´e et al. (2004).
In the following Interacting MCMC algorithm introduced by Campillo et al. (2009),
to concentrate the computational eﬀort on the zone of interest, each individual chain
proposes one candidate for all the chains.
It is proved that the set of interacting
chains has a unique stationary distribution with pdf π(·)M, with π(·) the original target
distribution and M the number of parallel chains. Each of the M chains provides a
sample to construct the posterior distribution (Campillo et al., 2009).
Algorithm : Interacting Metropolis-within-Gibbs

72
4.2. PARALLEL MCMC
• Initialization
- For i = 1, . . . , M :
- Choose initial values for Xi,0 = (θ(1)
i,0 , . . . , θ(d)
i,0 , x(1)
i,0 , . . . , x(tmax)
i,0
) from the prior
distributions p0(·).
• Parameters
Iteration
- For j = 1, . . . , n1 :
- Proposal step: for i = 1, . . . , M :
1. Sample θ(1:d)
i,j
′ ∼N(θ(1:d)
i,j−1, Σ0).
2. Sample x(1:tmax)
i,j
′ ∼p(x1:tmax|θ(1:d)
i,j
′).
- Selection step: for i = 1, . . . , M :
1. Compute αθ(θ(1:d)
i,j−1, θ(1:d)
i,j
′) as in (4.10).
2. Set
{θ(1:d)
i,j
, x(1:tmax)
i,j
}











{θ(1:d)
1,j
′, x(1:tmax)
1,j
′} with probability
1
M αθ(θ(1:d)
i,j−1, θ(1:d)
1,j
′),
. . .
{θ(1:d)
M,j
′, x(1:tmax)
M,j
′} with probability
1
M αθ(θ(1:d)
i,j−1, θ(1:d)
M,j
′),
{θ(1:d)
i,j−1, x(1:tmax)
i,j−1
} with probability 1 −1
M
PM
k=1 αθ(θ(1:d)
i,j−1, θ(1:d)
k,j
′).
• Hidden states
Iteration
- For j = n1 + 1, . . . , n2; n2 > n1 + 1 :
- For t = 1, . . . , tmax :
- Proposal step: for i = 1, . . . , M :
1. Sample x(t)
i,j
′ ∼qt(x(t) | θ(1:d)
i,n1 , x(1)
i,j , . . . , x(t−1)
i,j
, x(t+1)
i,j−1, . . . , x(tmax)
i,j−1 )
2. Compute αx(x(t)
i,j−1, x(t)
i,j
′) according to (4.13).
- Selection step: for i = 1, . . . , M :
Set
x(t)
i,j =











x(t)
1,j
′
with probability
1
M αx(x(t)
i,j−1, x(t)
1,j
′),
. . .
x(t)
M,j
′
with probability
1
M αx(x(t)
i,j−1, x(t)
M,j
′),
x(t)
i,j−1
with probability 1 −1
M
PM
k=1 αx(x(t)
i,j−1, x(t)
k,j
′).
Note that the transition kernel and the prior distribution are regarded as proposal
distributions respectively for the joint estimation of the parameter vector and the
hidden state variables.
The posterior distribution is build only based on the samples of the last iteration
from all the chains.
More discussion about population based simulations for static inference can be
found in Jasra et al. (2007) and Mengersen and Robert (2003).

CHAPTER 4. BAYESIAN ESTIMATION
73
4.2.3
Convergence criteria for multiple chains
Gelman-Rubin (Gelman, 1992)
For parallel chains, the Gelman-Rubin criterion is created based on the normal
theory approximation to exact Bayesian posterior inference. The idea involves the
estimation of the target distribution as a conservative Student-t distribution by using
the last n iterations of the considering chains. Both the between-chain variance and
the with-in chain variance are evaluated to compute a scale parameter, with the aim
of monitoring the convergence.
To use this criterion, the assumption that the starting point is sampled from an
appropriately over-dispersed prior distribution is made. More precisely, to carry out
this evaluation of convergence, 7 steps are involved. Firstly, suppose that we simulate
m independent chains of length n after the burn-in period. The Gelman and Rubin
stopping criterion needs to compute the following elements, ∀θ(k), k ∈{1 . . . d}:
– ˆθ(k), which is the estimator of the target mean µθ(k) =
R
θ(k)P(θ(k))dθ(k).
ˆθ(k) = ¯θ(k)
..
– B(k)/n, which denotes the variance between the m chain means, each based on
n estimations of θ(k).
B(k)/n =
1
m −1
m
X
i=1
(¯θ(k)
i. −¯θ(k)
.. )2
– W, which is the average of the m within-chain variances.
W (k) = 1
m
1
(n −1)
m
X
i=1
n
X
j=1
(θ(k)
ij −¯θ(k)
i. )2 = 1
m
m
X
i=1
(s(k)
i )
2
– (ˆσ(k))
2, which is the estimator of the target variance
R
(θ(k) −µθ(k))2P(θ(k))dθ(k).
(ˆσ(k))
2 = n −1
n
W (k) + 1
nB(k)
Note that the variance estimator may overestimate the variance, if we assume
that the prior distribution is over-dispersed. However, it remains unbiased if the
prior distribution is the target distribution (under stationarity). The reason to
explain the two components of (ˆσ(k))
2 is that W alone can under-estimate the
overall variance, since the individual chains may do not have enough time to
explore the whole target distribution, and therefore have less variability. When
n →∞, the expectation of W approaches (σ(k))
2.
–
p
ˆV (k), as the scale of the estimated target distribution. The motivation is to
be more tolerance (allowing more variability) by adopting an approximation of
Student’s t distribution for θ(k).
p
ˆV (k) =
q
(ˆσ(k))2 + B(k)/mn

74
4.2. PARALLEL MCMC
with df = 2(ˆV (k))
2/ ˆ
Var(ˆV (k)) degrees of freedom, where
ˆ
Var(ˆV (k)) =
n −1
n
2 1
m
ˆ
Var((s(k)
i )
2) +
m + 1
mn
2
2
m −1(B(k))2
+ 2(m + 1)(n −1)
mn2
n
m[ ˆ
Cov((s(k)
i )
2, (¯θ(k)
i. )
2) −2¯θ(k)
..
ˆ
Cov((s(k)
i )
2, ¯θ(k)
i. )]
–
p
ˆR(k), served as the convergence monitor, built by estimating the potential scale
reduction.
p
ˆR(k) =
s
ˆ
V (k)
W (k)
df
(df −2)
n→∞
−→1
ˆR(k) is the ratio of the current estimate of variance
ˆ
V (k) to the within-chain
variance W (k) corrected by a factor account for the extra variance considered
from the Student’s t distribution. If
p
ˆR(k) is important, then further simulation
may be needed to improve the inference based on the observations. Therefore,
a threshold can be deﬁned to indicate the convergence and stop the simulation
based on
p
ˆR(k), which is usually close to 1. In our implementation, 1.0001 is
chosen.
200
400
600
800
1000
1.00
1.05
1.10
1.15
1.20
Iteration
Shrink Factor
median
97.5%
Figure 4.7: The evolution of shrink factor from the Gelman-Rubin criterion.
Note that another desirable function of this criterion due to its feature is that it
could help us to detect the problem of multi-modal target distribution by producing a
value of
p
ˆR(k) not decreasing to 1.
In our implementation, this criterion is used for the DREAM algorithm.

CHAPTER 4. BAYESIAN ESTIMATION
75
4.3
Sequential Monte Carlo methods
Within a Bayesian framework, Sequential Monte Carlo (SMC) methods as well as
Monte Carlo Markov Chain (MCMC) based methods oﬀer the opportunity to estimate
the parameter distribution (posterior) based on the predeﬁned knowledge (prior) (Gel-
man et al., 1995; Andrieu et al., 2001). However, unrealistic results might be obtained
by MCMC based methods with a given inappropriate prior.
Moreover, despite all the advantage of MCMC-based methods, in practice, many
problems require online estimation, they hence rely on recursive methods. Therefore,
the ﬁltering methods might be considered as a better choice. Traditional estimation
methods for linear systems subject to normal noises are based on the Kalman Filter
(Kalman, 1960; Kailath et al., 2000). However, to answer the growing complexity of
the considering models often nonlinear, extensions of Kalman Filters, such as Extended
Kalman Filter (Anderson and Moore, 1979; Sorenson, 1985), Unscented Kalman Filter
(Julier and Uhlmann, 1997; Quach et al., 2007) and Ensemble Kalman ﬁlter (Evensen,
1994, 2006) are developed. Only in recent years that the growth in computational
power has made computational intensive statistical methods feasible. More and more
approaches appeared solving directly the estimation problem based on Monte Carlo
techniques (Doucet et al., 2001), instead of using approximation to linearize the system.
The main breakthrough came with the invention of particle ﬁltering method (Gordon
et al., 1993).
In the meantime, new issues arise mainly in regards of uncertainty
assessment.
In this thesis, the particle ﬁlter based methods are mainly analysed and applied,
whereas the Kalman Filter based methods are served as comparison. In the following,
we ﬁrst introduce the context of Bayesian inference and describe the general ﬁltering
recursion. The algorithms of two Kalman based ﬁlters, the Unscented Kalman Filter
and the Ensemble Kalman Filter are reviewed. Subsequently, two particle ﬁlter based
algorithms, the Regularized Particle Filter and the Convolution Particle Filter are
presented.
General Bayesian estimation problems
For n ∈N, the classical estimation problems can be divided into three categories:
– Filtering : it involves the extraction of information of a variable of interest Xn
at time n from the data observed up to time n: Y0:n.
– Prediction : it aims to derive information of a variable of interest Xn+τ at some
time n + τ (τ ∈N∗) in the future based on the observation up to time n.
– Smoothing : it consists using all the observations Y0:n, even those after the time
of interest n′ (n′ ∈N, n′ < n) for the estimation of Xn′.
For ﬁltering methods, the objective is to estimate jointly the unknown parameters
and the hidden states. An augmented state vector Xa
n = (Xn, Θn) is consequently
deﬁned for each time step n ∈{0, . . . , tmax} with the associated state space X a
def=
X × P. It contains Xn the true hidden state at time tn and Θn the vector of unknown

76
4.3. SEQUENTIAL MONTE CARLO METHODS
parameters which can be considered as a random variable deﬁned on the measurable
space (P, B (P)) (see Quach et al. (2007) and d’Alch´e Buc and Brunel (2010) for
examples). In the following, if X represents a random variable with values in X, then
for all x ∈X, p(x) denotes the probability density of X on x.
A nature way to deal with the dynamic parameter vector Θn is to keep it being
constant in time. That is to say: Θn = Θn+1. However, in Section 5.1, a new version of
particle ﬁlter may enable us to modify Θn sequentially in time. Therefore, an artiﬁcial
dynamic evolution is assigned to Θn :
Θn+1 = hn+1(Θn, ζn+1),
n ≥0,
with a Borel function hn and {ζn}n≥0 a sequence of i.i.d. random variables which is
mutually independent of {ξn}n≥0 and {ηn}n≥0. For n ∈N, we assume that Θn admits
a density with respect to the Lebesgue measure, denoted p(Θn).
Therefore, the description of state-space model (3.1) presented in Section 3.2 is
slightly modiﬁed :
 Xa
n+1 = f a
n+1
 Xa
n, En, ηa
n+1,

,
n ≥0,
Yn = gn (Xa
n, Θ, ξn) , n ≥0,
(4.17)
with ηa = (η, ζ) and f : X × P × E × Rdηn +dζn 7→X × P which characterizes the
evolution of Xa
n. We denote X × P by X a.
General ﬁltering recursions
The ﬁltering methods allow us to estimate the augmented hidden state variable
Xa
n based on Y0:n. An MMSE estimator of ˆXa
n conditional to Y0:n is often chosen and
deﬁned as:
ˆXa
n = E[Xa
n|Y0:n] =
Z
X a xa
np(xa
n|y0:n)λ(dxa
n) =
Z
(X a)n+1 f(xa
0:n)p(xa
0:n|y0:n)λ(dxa
0:n).
with λ the Lebesgue measure on X a. p(xa
n|y0:n) is the marginal density of p(xa
0:n|y0:n).
Note that if only a parameterization is desired, it is possible to extract the estimation
of the parameter vector Θn from the estimator ˆXa
n.
The ﬁltering process can be summarized by two steps, the prediction, also known
as time update, and the correction, respectively known as measurement update. The
ﬁrst-order hidden Markov model is characterized by the transition density p(xa
n|xa
n−1)
corresponding to the state equation (Quach et al., 2007), and the observation density
p(yn|xa
n) corresponding to the observation equation and the initial density p(xa
0).
– Determinate the density distribution to predict the hidden state at time n + 1
based on the former observations.
p(xa
n+1|y0:n) =
Z
X a p(xa
n+1|xa
n)p(xa
n|y0:n)λ(dxa
n).
(4.18)

CHAPTER 4. BAYESIAN ESTIMATION
77
– Correct the density distribution by taking into account the new observation yn+1.
p(xa
n+1|y0:n+1) =
p(xa
n+1|y0:n)p(yn+1|xa
n+1)
R
X a p(xa
n+1|y0:n)p(yn+1|xa
n+1)λ(dxa
n+1).
(4.19)
Kalman ﬁlter can be regarded as the most eﬃcient ﬁltering method for linear
system. However, it cannot cope with nonlinear systems. To date, many eﬀorts have
been made to develop extension for Kalman ﬁlter in nonlinear systems, the most well
known extensions remain to be the extended Kalman ﬁlter, the unscented Kalman
ﬁlter and the ensemble Kalman ﬁlter. The Extended Kalman Filter (EKF) (Evensen,
1994) simply linearizes locally the model so that the tradition Kalman ﬁlter can be
applied. However, it exhibits poor performance with highly nonlinear system, while
both latter methods generalize elegantly to nonlinear systems which are free of the
linearization required by the EKF. In the following, the Unscented Kalman Filter and
ensemble Kalman ﬁlter are presented. First, we revisit the algorithm of the famous
Kalman Filter.
4.3.1
Unscented Kalman Filter
Kalman Filter
Generally, there does not exist a ﬁnite dimensional solution to the Bayesian esti-
mation problem. However, for a linear system subject to Gaussian noise, the solution
can be formulated recursively using the Kalman Filter (Kalman, 1960), which can be
regarded as the most eﬃcient ﬁltering method for linear systems.
Let us consider a linear dynamic system (4.17) with both f a
n and gn linear functions.
Suppose the density p(xa
0) associated to Xa
0 is Gaussian. Since a Gaussian distribution
can be characterized by its ﬁrst two moments, mean and covariance matrix, the update
of p(xa
n|y0:n) concerns only the density of the expectation ˆxa
n|n and the covariance matrix
ˆΣxa
n|n :
ˆxa
n|n = E[Xa
n|Y0:n]
ˆΣxa
n|n = E[(Xa
n −ˆxa
n|n)T(Xa
n −ˆxa
n|n)|Y0:n].
(4.20)
In the following, we assume that ηa
n and ξn are white noises drawn from Gaussian
distributions :
ηa
n ∼N(0, Jn)
and
ζn ∼N(0, Rn).
For the sake of simplicity, we denote f a
n+1(Xa
n) = f a
n+1(Xa
n, En, ηa
n+1) and gn+1(Xa
n+1) =
gn+1(Xa
n+1, ξn+1). The ﬁltering process is thus carried out in two steps.
• Prediction (time update) : the aim is to determinate p(xa
n+1|y0:n) using the evolution
equation f a
n+1 of the state-space model.
ˆxa
n+1|n = E[Xa
n+1|Y0:n] = E[f a
n+1(Xa
n, ηa
n+1)|Y0:n].

78
4.3. SEQUENTIAL MONTE CARLO METHODS
Note that ηa
n+1 is independent of {ηa
k}k=1,...,n and {ξk}k=1,...,n+1, and therefore is inde-
pendent of Y0:n+1. Its expected value is determined by N(0, Jn+1) and p(xa
n|y0:n).
ˆΣxa
n+1|n = E[(Xa
n+1 −ˆxa
n+1|n)T(Xa
n+1 −ˆxa
n+1|n)|Y0:n].
In the same way, we can deduce the associate expectation of p(yn+1|y0:n):
ˆyn+1|n = E[Yn+1|Y0:n] = E[gn+1(Xa
n+1)|Y0:n],
(4.21)
since ξn+1 and Y0:n are independent, the corresponding covariance matrix is therefore:
ˆΣy
n+1|n = E[(Yn+1 −ˆyn+1|n)T(Yn+1 −ˆyn+1|n)|Y0:n]
= E[(gn+1(Xa
n+1) −ξn+1 −ˆyn+1|n)T(gn+1(Xa
n+1) −ξn+1 −ˆyn+1|n)|Y0:n] + Rn+1.
(4.22)
The correlation matrix between Xa
n+1 and Yn+1 conditional by Y0:n can be calculated :
ˆΣxay
n+1|n = E[(Xa
n+1 −ˆxa
n+1|n)T(Yn+1 −ξn+1 −ˆyn+1|n)|Y0:n].
• Correction (measurement update) : the expectation and the covariance matrix
associated to p(xa
n+1|y0:n+1) can be estimated by :
ˆxa
n+1|n+1 = ˆxa
n+1|n + Kn+1(yn+1 −ˆyn+1|n)T
ˆΣxa
n+1|n+1 = ˆΣxa
n+1|n −Kn+1 ˆΣy
n+1|nKT
n+1.
(4.23)
Kn+1 is known as the Kalman gain, which can be expressed as :
Kn+1 = ˆΣxay
n+1|n

ˆΣy
n+1|n
−1
.
Unscented transform
As one of the nonlinear extensions of classical Kalman Filter, the Unscented Kalman
Filter (UKF) (Julier and Uhlmann (1997) and Quach et al. (2007)) adopts determin-
istic sampling aiming at using a small set of discretely sampled points, known as
sigma-points (Unscented Transform, see Arulampalam et al. (2002)) to get hold of
the information of higher order for both mean and covariance matrix based on nor-
mal assumptions. Before proceeding to the UKF, we ﬁrst introduce the Unscented
transform.
Consider X, Y two random variables and a nonlinear Borel function f:
Y = f(X).
The objective is to provide an approximation of E[Y ] = E[f(X)] in the case when X
follows a normal distribution N(¯x, Σx). We denote d as the dimension of X. First, we
simulate 2d + 1 samples to represent the distribution of X, namely sigma-points :







χ0
= x
χi
= x +
p
(d + κ)Σx

i
i ∈{1, . . . , d}
χd+i
= x −
p
(d + κ)Σx

i
i ∈{1, . . . , d}

CHAPTER 4. BAYESIAN ESTIMATION
79
with κ > −d.
p
(d + κ)Σx

i represents the ith line or column of
p
(d + κ)Σx. Each
sigma point χi is associated with a weight ωi which is deﬁned as :



ω0
= κ/(d + κ)
ωi
= 1/2(d + κ)
i ∈{1, . . . , d}
ωi+d
= 1/2(d + κ)
i ∈{1, . . . , d}
Thus, the following approximation can be made :
E[Y ] = E[f(X)] ≈
2d
X
i=0
ωif(χ(i)).
N.B.
A good choice of κ is d −3 (see Julier and Uhlmann (1997))
If f is linear, then the approximation of E[Y ] is exact which allows a third-order
approximation of the expectation.
The Choleski decomposition can be used to compute the square root of (d + κ)Σx.
Unscented Kalman Filter
The Unscented Kalman Filter (UKF) (Julier and Uhlmann (1997) and Quach et al.
(2007)) is known as one of the nonlinear extensions of classical Kalman Filter. When
f a
n and gn are no longer linear, the density p(xa
n|y0:n) does not follow the normal
distribution any more. Thanks to the Unscented Transform, the approximation of
both mean and covariance matrix can be made via the sigma-points. Therefore, it
does not require a tangent linear model as EKF does and claims a better precision and
robustness for nonlinear models.
We denote dη = dim(ηn+1), dX = dim(ˆxa
n|n) and dη,X = dη + dX. We recall that Jn
and Rn are the covariance matrices for ηa
n and ξn respectively. The two steps of the
ﬁltering process can be described as follows :
Algorithm : Unscented Kalman Filter
• Initialization
- Choose initial values for xa
0 and Σxa
0 , set accordingly ˆxa
0|0 = xa
0 and ˆΣxa
0|0 = Σxa
0 .
• Iteration
- For n = 1, . . . , tmax :
Prediction:
- Construct the 2dη,X + 1 sigma-points χi
n|n and their associated weights ωi
according to N

ˆxb
n|n, ˆΣxb
n|n

, with :
ˆxb
n|n = (ˆxa
n|n, 0dη)
and
ˆΣxb
n|n =

ˆΣxa
n|n
0dX,dη
0dη,dX
Jn+1

.

80
4.3. SEQUENTIAL MONTE CARLO METHODS
- Propagate the sigma-points with χi
n+1|n = f a
n+1(χi
n|n) to obtain the expecta-
tions at time n + 1 :
ˆxa
n+1|n =
2dη,X+1
X
i=1
ωiχi
n+1|n
and
ˆyn+1|n =
2dη,X+1
X
i=1
ωign+1(χi
n+1|n),
as well as the associated covariance matrices :
ˆΣxa
n+1|n =
2dη,X+1
X
i=1
ωi(χi
n+1|n −ˆxa
n+1|n)T(χi
n+1|n −ˆxa
n+1|n),
(4.24)
ˆΣy
n+1|n =
2dη,X+1
X
i=1
ωi(gn+1(χi
n+1|n) −ˆyn+1|n)T(gn+1(χi
n+1|n) −ˆyn+1|n),
(4.25)
and
ˆΣxay
n+1|n =
2dη,X+1
X
i=1
ωi(χi
n+1|n −ˆxa
n+1|n)T(gn+1(χi
n+1|n) −ˆyn+1|n).
(4.26)
Correction :
- Compute the Kalman gain:
Kn+1 = ˆΣxay
n+1|n

ˆΣy
n+1|n
−1
.
- The corrected estimator and the corresponding covariance matrix at time n+1
are :
ˆxa
n+1|n+1 = ˆxa
n+1|n + Kn+1(yn+1 −ˆyn+1|n)T
(4.27)
ˆΣxa
n+1|n+1 = ˆΣxa
n+1|n −Kn+1 ˆΣy
n+1|nKT
n+1.
(4.28)
N.B.
Given the fact that f a
n+1 is not necessarily linear with ηa
n+1, we prefer to perform the
transformation with the vector (Xa
n, W a
n+1) instead of Xa
n described originally in the
UKF algorithm.

CHAPTER 4. BAYESIAN ESTIMATION
81
4.3.2
Ensemble Kalman Filter
The Ensemble Kalman Filter (EnKF) (Evensen, 1994) is another extension of
Kalman ﬁlter designed for nonlinear system. Established on the Monte-Carlo method
coupled with the Kalman formulation, it relies on normality assumptions in order to
improve the accuracy of its estimates with a more important number of samples com-
pared to the UKF. In the EnKF, an ensemble of possible augmented hidden state
vectors are randomly generated using a Monte-Carlo method to characterize the sta-
tistical properties of the vector.
Algorithm : Ensemble Kalman Filter
• Initialization
- Choose initial values for xa
0 and Σxa
0 , set accordingly ˆxa
0|0 = xa
0 and ˆΣxa
0|0 = Σxa
0 .
- For i = 1, . . . , m, sample xa(i)
0
∼N

ˆxb
0|0, ˆΣxb
0|0

, with :
ˆxb
0|0 = (ˆxa
n|n, 0dη)
and
ˆΣxb
0|0 =

ˆΣxa
0|0
0dX,dη
0dη,dX
Jn+1

.
• Iteration
- For n = 1, . . . , tmax :
Prediction:
- Propagate the ensemble to obtain the expectation of Xa
n+1 given Y0:n :
ˆxa
n+1|n = 1
m
m
X
i=1
xa(i)
n+1|n
and
ˆyn+1|n = 1
m
m
X
i=1
gn+1(xa(i)
n+1|n),
as well as the associated covariance matrices :
ˆΣxa
n+1|n =
1
m −1
m
X
i=1
(xa(i)
n+1|n −ˆxa
n+1|n)T(xa(i)
n+1|n −ˆxa
n+1|n),
(4.29)
ˆΣy
n+1|n =
1
m −1
m
X
i=1
(gn+1(xa(i)
n+1|n) −ˆyn+1|n)T(gn+1(xa(i)
n+1|n) −ˆyn+1|n),
(4.30)
and
ˆΣxay
n+1|n =
1
m −1
m
X
i=1
(xa(i)
n+1|n −ˆxa
n+1|n)T(gn+1(xa(i)
n+1|n) −ˆyn+1|n).
(4.31)

82
4.3. SEQUENTIAL MONTE CARLO METHODS
Correction :
- Compute the Kalman gain:
Kn+1 = ˆΣxay
n+1|n

ˆΣy
n+1|n
−1
.
- The corrected samples of the ensemble at time n + 1 are :
xa(i)
n+1|n+1 = xa(i)
n+1|n + Kn+1(yn+1 −gn+1(xa(i)
n+1|n))T
for i = 1, . . . , m,
- The corrected estimator and the corresponding covariance matrix are :
ˆxa
n+1|n+1 = 1
m
m
X
i=1
xa(i)
n+1|n+1,
(4.32)
ˆΣxa
n+1|n+1 =
1
m −1
m
X
i=1
(xa(i)
n+1|n+1 −ˆxa
n+1|n+1)T(xa(i)
n+1|n+1 −ˆxa
n+1|n+1).
(4.33)
4.3.3
Particle Filter
Despite the Kalman ﬁlter-based approaches, another important category of ﬁltering
methods is Particle Filter based approach.
It is a recursive Bayesian ﬁlter based
on Monte Carlo simulations (Arulampalam et al., 2002). Unlike Kalman ﬁlter-based
approaches, Particle Filter (PF) intends to provide better approximation of the exact
posterior distributions by creating a set of randomly drawn samples with each an
associated time evolving weight. The main idea is that since the marginal density
of p(xa
0:n|y0:n), p(xa
n|y0:n) is either unknown or impossible to simulate in most of the
applications, as mentioned in Section 3.3, the importance sampling can be introduced
to address the issue.
The importance function associated to p(xa
0:n|y0:n) is denoted πn(xa
0:n|y0:n). The
importance weight wn can be deﬁned as:
∀xa
0:n ∈(X a)n+1 ,
wn(xa
0:n) = p(xa
0:n|y0:n)
πn(xa
0:n|y0:n).
The MMSE estimator of the augmented hidden state vector conditioned on a series of
observations is thus:
ˆXa
n =
M
X
i=1
˜w(˜xa
0:n
(i))˜xa
n
(i),
(4.34)
with ˜wn the normalized importance weights and {˜xa
0:n
(i)}i=1,...,M the M samples (also
known as trajectories) of Xa
0:n conditional to Y0:n, simulated from πn(xa
0:n|y0:n).
One may interpret a particles as a moving point in X a, with ˜xa
0:n
(i) describing the
trajectory of its movement from time 0 to n. The associated weight wn(˜xa
0:n
(i)) is an

CHAPTER 4. BAYESIAN ESTIMATION
83
indicator of the likelihood of the trajectory produced compared to the real trajectory
of the hidden states of the system.
For this reason, the PF algorithm is also named Sequential Importance Sampling.
The PF based ﬁltering methods have been studied intensively in the literature (Gordon
et al., 1993; Kitagawa, 1996; Doucet et al., 2001). Among them, the most adapted to
our application context can be cast into the framework of the generic Sequential Im-
portance Sampling (SIS) algorithm, or SIR, when a resampling step is introduced (see
Arulampalam et al. (2002) and Doucet et al. (2001)). The ﬁrst eﬃcient implementation
of Monte-Carlo particle ﬁlters of this type dates back to Gordon et al. (1993). The
authors give a generic formulation of the bootstrap PF, using importance sampling
ideas in the correction step and systematic use of resampling in order to avoid the
sample degeneracy problem. The term Interacting Particle Filter (IPF) is also used
by Del Moral (1996) (see also Deleuze (1996); Crisan et al. (1998)) for the same PF
algorithm. For other names of the same algorithm see Arulampalam et al. (2002) (page
178) and the references therein. In the following, the general algorithm of Sequential
Importance Sampling is presented.
Sequential Importance Sampling
Motivated by the fact that the computation of {wn(˜x(i)
0:n)}i=1,...,M can be tedious,
the idea is to beneﬁt from the Markovian feature of the state space dynamic system
in order to establish a recursive relation between wn(˜xa
0:n
(i)) and wn+1(˜xa
0:n+1
(i))). To
do this, an importance transition density denoted qn+1(xa
n+1|xa
n) is introduced which
allows the particle to propagate from time n to n + 1. This density is chosen in the
way that it should be easy to sample from, which also veriﬁes the following condition :
∀xa
n+1 ∈X a,
p(xa
n+1|xa
n) > 0
⇒
qn(xa
n+1|xa
n) > 0.
Therefore, the importance density can be obtained by recursion:
πn+1(xa
0:n+1|y0:n+1)
def= πn(xa
0:n|y0:n)qn+1(xa
n+1|xa
n) = q0(xa
0)
n
Y
k=0
qk+1(xa
k+1|xa
k)
(4.35)
with q0(xa
0) the importance density from which Xa
0 can be simulated.
Thanks to the Bayes’ rule,
p(xa
0:n+1|y0:n+1) = p(xa
0:n|y0:n)p(yn+1|xa
n+1)p(xa
n+1|xa
n)
p(yn+1|y0:n)
.
(4.36)
By combining the two previous equations (4.35) and (4.36), we may obtain the impor-
tance weight in a recursive way :
wn+1(˜xa
0:n+1
(i)) =
p(˜xa
0:n+1
(i)|y0:n+1)
πn+1(˜xa
0:n+1
(i)|y0:n+1)
= wn(˜xa
0:n
(i))p(yn+1|˜xa
n+1
(i))p(˜xa
n+1
(i)|˜xa
n
(i))
p(yn+1|y0:n)qn+1(˜xa
n+1
(i)|˜xa
n
(i)).
(4.37)

84
4.3. SEQUENTIAL MONTE CARLO METHODS
The computation of p(yn+1|y0:n) is diﬃcult, yet not indispensable, for the weight vec-
tor needs to be normalized before proceeding to the construction of the estimator.
Therefore, the normalized weight ˜wn+1(˜xa
0:n+1
(i)) can be obtained by :
˜wn+1(˜xa
0:n+1
(i)) =
wn+1(˜xa
0:n+1
(i))
PM
j=1 wn+1(˜xa
0:n+1
(j))
pour i = 1, . . . , M.
(4.38)
Resampling
Figure 4.8: Sample degeneracy and impoverishment.
The drawback of the Particle Filter based method is that it could appear to be
unstable due to the discrepancy between the particle weights. This phenomenon is
known as weight degeneracy (Arulampalam et al., 2002)) and sample impoverishment
(Gordon et al., 1993) (Figure 4.8). One possible solution to improve the algorithm
and hopefully to avoid this problem is to introduce a resampling procedure with a
suﬃcient frequency (Kong et al., 1994; Kitagawa, 1996). A threshold η is often chosen
(η = 0.8M, see Caron (2006)) to launch the resampling procedure, which is related to
the empirical variance of the particle weights.
Algorithm : Resampling
$ Resampling :
- Compute Neﬀ=
hPM
i=1( ˜wn+1(˜xa
0:n+1
(i)))2i−1

CHAPTER 4. BAYESIAN ESTIMATION
85
- If Neﬀ≤η :
- For i = 1, . . . , M :
- Draw with replacement a new particle ˜xa
0:n+1
(i) from {˜xa
0:n+1
(j), j ∈{1, . . . , M}}
according to a multinomial distribution
M (1, ˜wn+1(˜xa
0:n+1
(1)), . . . , ˜wn+1(˜xa
0:n+1
(M))).
- Update ˜wn+1(˜xa
0:n+1
(i)) = 1/M.
- Else, proceed to the next iteration.
Note that other resampling techniques also exist, for example Pham (2001); West
(1993). More discussions regarding the choice of the resampling scheme for particle
ﬁltering can be found in Douc et al. (2005).
With the purpose of alleviating the undesirable side eﬀect of resampling to improve
the parametrization performance when facing restricted dataset, we opted for the Con-
volution Particle Filter (CPF) proposed by (Campillo and Rossi, 2009) based on the
post-Regularized Particle Filter (post-RPF) (Musso and Oudjane, 1998; Oudjane and
Musso, 1999; Le Gland and Oudjane, 2004).
These two ﬁltering methods share in common a kernel smoothing method to change
the discrete approximation of the ﬁltering density.
Here, we ﬁrst present brieﬂy the kernel density estimator.
Kernel density estimator
Kernel density estimation, also known as the Parzen-Rosenblatt window method,
is an approach grounded in the methodology of histogram, which aims to estimate the
density function at a point x based on neighbour observations (Parzen, 1962; Silverman,
1986).
Deﬁnition 4.3.1 (Kernel) A kernel K is deﬁned as an application of Rd 7→R which
satisﬁes the following conditions:
– K(x) ≥0,
∀x ∈Rd ;
– K is bounded and symmetric : ∀x ∈Rd,
K(x) = K(−x) ;
– K is integrable, such that
R
Rd K(x)dx = 1.
These properties ensure that the kernel density estimation results in a probability
density function. We deﬁne :
Kh(x)
def= 1
hdK(x
h),
x ∈Rd,
with h > 0 a smoothing factor, which is known as the bandwidth parameter. Therefore,
Kh is still a kernel.
Deﬁnition 4.3.2 (Parzen-Rosenblatt Kernel) A kernel K is deﬁned as a Parzen-
Rosenblatt kernel if :
|x|dK(x) →0
as |x| →∞.

86
4.3. SEQUENTIAL MONTE CARLO METHODS
Suppose X1, . . . , Xn are i.i.d random variables drawn from a density distribution
f(·) which is absolutely continuous with respect to a Lesbegue measure on R.
Deﬁnition 4.3.3 (Kernel estimator) (Parzen, 1962) The kernel estimator of fN(x)
is deﬁned as:
ˆfN(x) =
1
Nhd
N
N
X
i=1
K
x −Xi
hN

,
x ∈Rd.
4.3.4
Regularized Particle Filter and Convolution Particle Fil-
ter
Regularized Particle ﬁlter
The regularization refers to the use of a kernel smoothing method to change the
discrete approximation of the ﬁltering density (induced by the weighted particles in the
classical IPF) into an absolutely continuous approximation. In a way, the regulariza-
tion with convolution kernels can be regarded as artiﬁcial noise. The term post-RPF
is used to indicate that the regularization step takes place after the correction step. A
comprehensive exposition of RPFs and improvements can be found in Musso et al. and
some theoretical results in Le Gland et al. (1998) and Le Gland and Oudjane (2004).
In Musso and Oudjane (1998) and Oudjane and Musso (1999), the authors compare
the performance of the RPFs with the IPFs in some classical tracking problems. Let
us now describe the adaptation of this method in our context.
In the initialization step of our implementation, the parameters are initialized from
either informative distributions p(xa
0) or non-informative distributions for all the par-
ticles. Particle weights are assigned uniformly.
We denote by KX the regularization kernel (usually Epanechnikov or Gaussian)
associated to Xa
n and by KK
h the rescaled kernel given by:
KX
h (xa) = h−dKX(h−1xa),
where h > 0 is the bandwidth parameter and d is the dimension of the state vector.
In our application, we used the Gaussian kernel and with M particles the optimal
bandwidth parameter (when the underlying density is Gaussian) is given by (see, eg.,
Musso et al.):
hX
M =

4
d + 2

1
d+4
M −
1
d+4.
(4.39)
Let us assume that at the end of the n-th step, the estimate of p(xa
n|y0:n) is given by:
ˆp(xa
n|y0:n) =
M
X
i=1
˜w(i)
n KX
hX
M(xa
n −˜xa (i)
n
),
where {( ˜w(i)
n , ˜xa (i)
n
)} is the normalised weighted sample before the regularization step.
The basic ﬁltering step can be described as follows:

CHAPTER 4. BAYESIAN ESTIMATION
87
• Sampling
For i = 1, . . . , M:
– Generate I(i) ∈{1, . . . , M}, with P(I(i) = j) = ˜w(j)
n .
– Generate ϵ(i) ∼KX(xa).
– Compute ˜xa (i)
n
= ˜xa (I(i))
n−
+ hX
M ˆΣ1/2
n ϵ(i), where ˆΣ1/2
n
is the square root of the em-
pirical covariance matrix (whitening can be used).
• Prediction
For i = 1, . . . , M:
– Generate ˜x(i)
n+1 ∼p(xn+1|˜xa (i)
n
).
– Set ˜θ(i)
n+1 = ˜θ(i)
n .
• Correction and regularization
For i = 1, . . . , M:
– Set ˜w(i)
n+1 = p(yn+1|˜xa (i)
n+1).
– Regularize the weighted sample {( ˜w(i)
n+1, ˜xa (i)
n+1)} by taking
ˆp(xa
n+1|y0:n+1) =
M
X
i=1
˜w(i)
n+1KX
hX
M(xa
n+1 −˜xa (i)
n+1).
As far as the regularization is concerned, it is noteworthy to mention the recent
approach presented in Rossi and Vila (2006) and Campillo and Rossi (2009). The
authors proposed a particle ﬁlter where a convolution kernel is used to regularize the
likelihood of the observations as well. The new ﬁlter, called convolution particle ﬁlter,
seems to be more appropriate to use when the likelihood cannot be computed explicitly
or when signal-to-noise ratio is very low or very high (Rossi and Vila, 2006).
Convolution Particle Filter
Inspired by the post-Regularized Particle Filter (Oudjane and Musso, 1998), the
objective of the Convolution Particle Filter (CPF) (Rossi, 2004; Campillo and Rossi,
2009) is also to estimate jointly the parameters and the hidden states of the dynamic
system by processing the data on-line, but with both deterministic models and stochas-
tic models. Similar to the RPF approach, the construction and the theoretical analysis
of the CPF diﬀer from the standard particle approach, as they are based on the non-
parametric estimate of the conditional densities by convolution kernels.
Concerning the choice of the kernel, in our implementation, Gaussian kernels
(Parzen-Rosenblatt kernel) are used, for they are more tolerant and generous with
regards to the variance compared to the Epanechnikov kernel, as demonstrated by
Figure 4.9.
Each ﬁltering step is performed recurrently in two stages and occurs only at time
steps when the observation is available (Campillo and Rossi, 2009):
Prediction:
The objective is to provide a kernel estimator of p(xa
n+1, yn+1|y0:n) denoted by
ˆp(xa
n+1, yn+1|y0:n). M particles {˜xa
n
(i), i = 1, . . . , M} are sampled from the distribution

88
4.3. SEQUENTIAL MONTE CARLO METHODS
Figure 4.9: Comparison of Gaussian kernel (Parzen-Rosenblatt kernel) and Epanech-
nikov kernel.
with conditional density ˆp(xa
n|y0:n).
The M particles are propagated through the
evolution model until the next available measurement to obtain the predicted states
{˜xa
n+1−(i), i = 1, . . . , M}. The updating scheme relies directly on Bayes’ law. The
particle weights are calculated based on the experimental measurements and the
predictions, and then normalized. The empirical kernel approximation of the prob-
ability density of (Xa
n+1, Yn+1) conditional to Y0:n can accordingly be deduced using
the Parzen-Rosenblatt kernel KX
hX
M, with bandwidth parameter hX
M:
ˆp(xa
n+1, yn+1|y0:n) = 1
M
M
X
i=1
KX
hX
M
 xa
n+1 −˜xa
n+1−(i)
· p
 yn+1|˜xa
n+1−(i)
.
(4.40)
Correction:
The a posteriori form of the estimation is deduced from Bayes’ law and the kernel
approximation for p(xa
n+1|y0:n+1) is given by:
ˆp(xa
n+1|y0:n+1) =
M
X
i=1
p(yn+1|˜xa
n+1−(i)) · KX
hX
M(xa
n+1 −˜xa
n+1−(i))
M
X
i=1
p(yn+1|˜xa
n+1−(i))
.
(4.41)
The part p(yn+1|˜xa
n+1−(i))/PM
i=1p(yn+1|˜xa
n+1−(i)) can be considered as the normal-
ized weight ˜w(i)
n+1 associated to the particle ˜xa
n+1−(i). When the analytic form of the
observation density p(yn+1|˜xa
n+1−) is unknown, or in the case of a deterministic model,
an observation kernel can similarly be introduced (Campillo and Rossi, 2009) with
another Parzen-Rosenblatt kernel KY
hY
M, associated with bandwidth parameter hY
M:

CHAPTER 4. BAYESIAN ESTIMATION
89
ˆp(xa
n+1|y0:n+1) =
M
X
i=1
KX
hX
M(xa
n+1 −˜xa
n+1−(i))KY
hY
M(yn+1 −˜y(i)
n+1−)
M
X
i=1
KY
hY
M(yn+1 −˜y(i)
n+1−)
.
(4.42)
Suﬃcient conditions for the L1-convergence of ˆp(xa
n+1|y0:n+1) can be found in
Storvik (2002). The new set of particles

˜xa
n+1
(i), 1 ≤i ≤M
	
are then sampled from
ˆp(xa
n+1|y0:n+1).
Algorithm : Convolution Particle Filter
• Initialization
- For i = 1, . . . , M :
- Choose initial values for xa
0 from the prior distributions p0(·).
• Iteration
$ Prediction step :
- For i = 1, . . . , M :
- Sample ˜xa
n+1−(i) ∼p(xa
n+1|˜xa
n
(i))
- Sample ˜y(i)
n+1−∼p(yn+1|˜xa
n+1−(i))
- Compute the associated weight :
w(i)
n+1 = KY
hM(yn+1 −˜y(i)
n+1−)
$ Normalize the weight vector :
- For i = 1, . . . , M :
- Set
˜w(i)
n+1 = w(i)
n+1/
M
X
j=1
w(j)
n+1
$ Correction step :
- Set
ˆp(xa
n+1|y0:n+1) =
M
X
i=1
˜w(i)
n+1KX
hM(xa
n+1 −˜xa
n+1−(i))
- For i = 1, . . . , M :
- Sample ˜xa
n+1
(i) ∼ˆp(xa
n+1|y0:n+1)
N.B.
- The observation Y0 is usually not taken into account.
However, it is possible to
integrate it into the algorithm. To do so, for Kalman ﬁlter based methods, the initial
samples (sigma-points for UKF) can be generated from time 0 according to N(xa
0, Σxa
0 ).
For Particle ﬁlter based methods, we can begin with time -1 and set p(xa
0|˜xa
−1
(i)) = p(xa
0)
for i ∈{1, . . . , M}.

90
4.3. SEQUENTIAL MONTE CARLO METHODS
Despite the methods presented in this chapter, other methods can also be employed
to address the parameter estimation problem in a state space model, such as the Ap-
proximate Bayesian Computation (Rubin, 1984; Rau et al., 2011) and the Expectation-
Maximization algorithm (Dempster et al., 1977; Andrieu and Doucet, 2003; Rau et al.,
2010).

CHAPTER 5
Iterative Approaches for
State-Space Model Calibration
F
or stochastic plant growth models and more generally stochastic biological models,
model parameterization is generally a diﬃcult process. Such type of models are
not only characterized by a large number of interacting processes with a large number
of parameters, nonlinear dynamics and scarce data for parameter estimation, resulting
from costly experimental data acquisition, but also uncertainties that arise at diﬀerent
scales. Bayesian inference methods oﬀer interesting perspectives to cope with such
characteristics, mostly due to their robustness when confronted to scarce data, and
have been used for this purpose in plant growth modeling (Wyckoﬀand Clark (2000),
Gaucherel et al. (2008)). However, in such situations the inﬂuence of a priori distribu-
tions is prevalent (Chen and Courn`ede (2012)) while it is generally not easy to assess
precisely.
As we all know, in the Bayesian formulation, it is assumed that the considered
model is adequate to describe the phenomenon of interest. A prior distribution is then
formulated over the unknown parameters, which is meant to capture our beliefs re-
garding the studying subject before the reception of the new information. Therefore,
after updating our knowledge based on the new information, the resulting posterior
distribution takes both the prior and the new data into account, from which future
observations can be predicted. Thus, the selection of a prior is very important, es-
pecially when the quantity of the new information is limited. Yet many people are
uncomfortable with this theoretically simple approach, simply because their view of
the prior selection is arbitrary and subjective, which could possibly inﬂuence a lot the
resulting distribution. Although the choice is subjective, we argue that it is however
not arbitrary. It should be the one who captures the prior beliefs, which is subjective
in most cases. Hence the prior should be placed modestly, with cautious. Unfortu-
nately, many pseudo-Bayesian applications can be found in the literature, in which
models, especially priors are chosen without justiﬁcation and serious reﬂection, and
91

92
5.1. STOCHASTIC VARIANTS OF AN EM-TYPE ALGORITHM
therefore, cannot represent appropriately the prior belief. For example, choosing pri-
ors for convenience or for a precise objective, varying prior according to the number
of new observations, or even conducting model comparison with models that cannot
be considered appropriate to describe the reality. On the other hand, undoubtedly
in some situations, it can be diﬃcult to perform properly a Bayesian method, for we
may not be able to translate our prior beliefs into a adequately formulated model with
suﬃcient prior distributions.
In the case when the prior is non-informative, and few data are available, we intend
to put more weight on the data. Intuitively, one may imagine that the experiment is
carried out over and over again and the same observations are obtained. Pursuing in
this direction, we show in Chen et al. (2013b) that the resulting iterative approach can
be regarded as an Expectation-Maximization (EM) type algorithm, at least when the
prior distribution for the parameters is Gaussian. The proposed algorithm combines
the robustness of Bayesian methods while preserving the prevalence of observation data
and the interest of point estimation for plant growth models, in which the biophysical
meaning and value of parameters are crucial. Furthermore, the term Gaussian random-
ization is introduced to designate that the initial model could be seen as a special case
of an extended model, which includes all the Gaussian distributions with the param-
eters of the model as the means. In the resulting algorithm, at the beginning of each
iteration, the posterior means and variances are used to initialize the updated normal
distributions. By doing so, the eﬀect of prior fades out and the estimated variances
of the parameters tend to zero, we demonstrate that it converges to the Maximum
Likelihood Estimator.
The chapter is organized as follows. First, we introduce the notion of Gaussian
randomization and present a theoretical framework for transforming the parameter es-
timation problem in the initial model into a problem that can be solved with the help
of an appropriate EM-type algorithm in the resulting incomplete data model. Then we
detail a regularized particle ﬁlter approximation of the E-step and a MCMC approx-
imation of the E-step of the iterative algorithm, in order to make feasible parameter
estimation. Finally, we describe the averaged estimator employed and the parametric
bootstrap used to provide the associated conﬁdence interval.
5.1
Stochastic variants of an EM-type algorithm
The estimation the proposing approach is performed in the classical framework
of incomplete data models via an appropriate stochastic variant of an EM-type algo-
rithm (Dempster et al., 1977). In contrast to classical stochastic variants (Celeux and
Diebolt (1985), Wei and Tanner (1990), Delyon et al. (1999), Foulley et al. (2000)) the
proposed variant of EM-type algorithm is particularly adapted to the extended model
resulting from the Gaussian randomization, since the last iterations of the algorithm
are performed under very low variance scenarios. Some recent eﬀorts to obtain ap-
propriate stochastic EM-type algorithms for complex models arising in plant growth
model applications can be found in Trevezas and Courn`ede (2013), Trevezas et al.
(2013) and Baey et al. (2014). These algorithms are designed for a non-explicit M-step

CHAPTER 5. ITERATIVE APPROACHES
93
and a numerical maximization algorithm is involved as well in one of the conditional
maximization steps.
In this thesis, we present a simple way of turning a non-explicit M-step into an
explicit one and opt for both the MCMC based methods and the SMC methods pre-
sented in Chapter 4 to perform the E-step. We mention that the use of Regularized
Particle Filter was restricted until now to Bayesian type estimation.
The resulting data and parameter augmentation method enable us to estimate
more easily the parameters of the initial model with the help of an iterative state
estimation technique for the extended model. The term Gaussian randomization is
introduced for such type of modiﬁcations.
Note that the proposed method should
not be confused with the Bayesian approach. The variance parameters involved in
the Gaussian randomization are assumed to be unknown in contrast to the Bayesian
approach in which normal priors are selected for the parameters of the model.
In the following the Gaussian Randomization and the theoretical framework of the
iterative scheme is presented.
5.1.1
Gaussian Randomization
Let us consider an arbitrary parametric statistical model m ≜{(Ω, A, PΘ); Θ ∈M},
where M is a Euclidean subset, and a random vector Y (representing the data vector)
deﬁned on this probability space and taking values in a measured space {(Y, B, ν)},
where ν is a reference measure. Suppose that the vector Y admits a density p(y; Θ)
w.r.t. ν for each Θ ∈M and for a given observation Y = y, the likelihood function is
L(Θ|y) denoted by L(Θ). The following assumption will be used in the sequel:
Assumption 1 i) The likelihood function L(Θ) is continuous on M,
ii) The model has a unique MLE Θ∗, i.e., for all Θ ∈M,
0 ≤L(Θ) ≤L(Θ∗),
and the second inequality is strict for Θ ̸= Θ∗.
Let us suppose that maximization of L(Θ) or log L(Θ) w.r.t. some of the parameters of
Θ is very diﬃcult to perform. In particular, let us decompose the unknown parameter
Θ = (Θ1, Θ2), where Θ1 could represent a part of the parameter vector that could
not be updated explicitly in an iterative conditional maximization procedure by ﬁxing
Θ2. The general idea consists in considering an enlarged model, by adding parameters
and hidden variables to the existing model, in such a way that maximization w.r.t.
to the augmented parameter vector in the enlarged model is equivalent to the initial
maximization problem. In this direction, we give a ﬁrst deﬁnition. Let dx denote the
dimension of a vector x. We treat the case where Θ1 ∈RdΘ1.
Deﬁnition 5.1.1 Let m be a statistical model which satisﬁes Assumption 1 and Θ =
(Θ1, Θ2), where Θ1 ∈RdΘ1. The statistical model em(Θ1) will be called Gaussian ran-
domization of m w.r.t. Θ1 if em(Θ1) is an incomplete data model, which consists in:

94
5.1. STOCHASTIC VARIANTS OF AN EM-TYPE ALGORITHM
i) a Gaussian hidden vector Ψ, where
Ψ ∼NdΘ1(Θ1, Σ),
and Σ = diag{σ2
i }1≤i≤dΘ1, where σ2
i > 0,
ii) an observed vector Y , where the conditional distribution of Y given Ψ = ψ
depends only on the parameter Θ2 and satisﬁes:
p(y|ψ; Θ2) = L(ψ, Θ2).
Let us take σ2 = (σ2
i )1≤i≤dΘ1 ∈(R∗
+)dΘ1 to be a minimal vector representation of the
corresponding covariance matrix Σ. The parameterization corresponding to em(Θ1) is
given by:
φ = (Θ, σ2) = (Θ1, Θ2, σ2) ∈Φ = M × (R∗
+)dΘ1 ⊂Rdφ.
(5.1)
Let us now assume that we allow some variance parameters of Ψ to be null. This
is equivalent to say that the corresponding parameters are not randomized. Denote
by Θ11 the subvector of Θ1 with associated strictly positive variances. According to
Deﬁnition 5.1.1-i) this model is no longer a Gaussian randomization of m w.r.t. Θ1
but rather a Gaussian randomization of m w.r.t. Θ11. In order to treat in a common
framework the class of all Gaussian randomizations of m w.r.t. to subvectors of Θ1 we
allow null variances in the parameterization. Most importantly, if σ2 is assigned to the
null vector 0dΘ1, then the parameter φ = (Θ1, Θ2, 0dΘ1) could be identiﬁed with the
parameter Θ = (Θ1, Θ2) of the initial model m. In this way m could be understood as
a submodel of em(Θ1). In the sequel we justify theoretically this intuition. Let us ﬁrst
state the following lemma.
Lemma 5.1.1 The likelihood function ˜L(φ) of the extended model em(Θ1) as given in
Deﬁnition 5.1.1 is upper bounded by L(Θ∗).
Proof: First, we compute the likelihood function ˜L(φ) of the extended model em(Θ1).
We have:
˜L(φ)
=
p(y; φ) =
Z
ψ∈M1
p(ψ, y; φ)dψ
=
Z
ψ∈M1
p(ψ; Θ1, σ2) p(y|ψ; Θ2)dψ
=
EΘ1,σ2 p(y|Ψ; Θ2)

,
(5.2)
where Ψ ∼NdΘ1(Θ1, Σ) according to Deﬁnition 5.1.1-i). By using Deﬁnition 5.1.1-ii)
and Assumption 1-ii) we get successively that for any φ ∈Φ,
˜L(φ) = EΘ1,σ2 L(Ψ, Θ2)

≤L(Θ∗),
(5.3)
and this completes the proof.
2
In order to justify the existence of the MLE in this extended model, we need to
extend the likelihood function of em(Θ1) to parameter values which include null vari-
ances as explained at the beginning of this section and give the correct interpretation
in this type of boundary values. We will need the following lemma.

CHAPTER 5. ITERATIVE APPROACHES
95
Lemma 5.1.2 Let x ∈Rdx, I ⊂{1, . . . , dx} and J = {1, . . . , dx} \ I. Let also σ2
I and
σ2
J be the subvectors of σ2 ∈Rdx with components indexed by I and J respectively. If
we consider the family of non-singular random vectors {Xσ2; Xσ2 ∼Ndx(x, Σ)}, where
Σ = diag{σ2
i }1≤i≤dx, then we have
Xσ2
weakly
−−−−−→
||σ2
J||→0 Xσ2
I ∼Ndx(x, ΣI),
where ΣI is a singular covariance matrix which results from Σ by putting σ2
J = 0J. In
particular, if I = ∅, then
Xσ2
weakly
−−−−→
||σ2||→0 x.
Proof: We denote by φσ2, φσ2
I and φ0 the characteristic functions of Xσ2, Xσ2
I and
the constant vector x respectively. It suﬃces to show that as σ2
J →0J, φσ2 converges
pointwise to φσ2
I. Indeed, let t = (t1, . . . , tdx)⊤∈Rdx. We have
φσ2(t) = eit⊤x−1
2 t⊤Σt −−−−−→
||σ2
J||→0 eit⊤x−1
2 t⊤ΣIt = φσ2
I(t).
(5.4)
In particular, if I = ∅, then ΣI is the null matrix and by (5.4), φσ2 converges pointwise
to φ0.
2
Proposition 5.1.3 Let I ⊂{1, . . . , dΘ1} and J = {1, . . . , dΘ1} \ I. Let also ΘI be the
subvector of Θ1 with components indexed by I, and σ2
I, σ2
J and ΣI as given in Lemma
5.1.2. We have
˜L(φ) = ˜L(Θ, σ2
I, σ2
J) −−−−−→
||σ2
J||→0
˜L(Θ, σ2
I),
where ˜L(Θ, σ2
I) is the likelihood function associated with the em(ΘI) Gaussian random-
ization of m. In particular, if I = ∅, then
˜L(φ) = ˜L(Θ, σ2) −−−−→
||σ2||→0 L(Θ),
where L(Θ) is the likelihood function associated with the initial model m.
Proof: By (5.3) the likelihood ˜L(φ) is expressed as the expectation of the random
variable L(Ψ, Θ2), where Ψ ∼NdΘ1(Θ1, Σ). For clarity, let us denote {Ψσ2} the family
of random vectors Ψ indexed by σ2. Then, we can rewrite (5.3) as
˜L(φ) = EΘ1,σ2 L(Ψσ2, Θ2)

.
(5.5)
If we apply Lemma 5.1.2 for the family {Ψσ2}, we have that for any (Θ1, σ2
I),
Ψσ2
weakly
−−−−−→
||σ2
J||→0 Ψσ2
I ∼NdΘ1(Θ1, ΣI),
or equivalently, for any continuous and bounded function f : RdΘ1 →R,
EΘ1,σ2 f(Ψσ2)

−−−−−→
||σ2
J||→0 EΘ1,σ2
I,0J
 f(Ψσ2
I)

,
(5.6)

96
5.1. STOCHASTIC VARIANTS OF AN EM-TYPE ALGORITHM
where we have used the characterization of weak convergence of a family of random
vectors (indexed by a continuous parameter) to a random vector in a speciﬁc limit
point. By Assumption 1, the likelihood function L(Θ) is continuous on M and bounded
by L(Θ∗). Consequently, for any Θ2, the function g : RdΘ1 →R, where Θ1 7→L(Θ1, Θ2)
is continuous on M1 and bounded. Using this and (5.6), we have
EΘ1,σ2 L(Ψσ2, Θ2)

= EΘ1,σ2 g(Ψσ2)

−−−−−→
||σ2
J||→0 EΘ1,σ2
I,0J
 g(Ψσ2
I)

= EΘI,σ2
I
 L(ΨI,σ2
I, ΘJ, Θ2)

,
(5.7)
where ΨI,σ2
I is the subvector of Ψσ2 indexed by I. In the last expectation σ2
i > 0 only
for i ∈I and consequently the last term corresponds to the analogue of (5.5) for an
equivalent representation of the likelihood function associated to the em(ΘI) Gaussian
randomization of m. If I = ∅, then obviously the last term coincides with L(Θ) and
the proof is complete.
2
By Proposition 5.1.3 we can consider in a uniﬁed framework the class { em(ΘI)}I of
2dΘ1 −1 Gaussian randomizations of m w.r.t. to subvectors of Θ1 together with the
initial model m, which corresponds to the choice I = ∅. For this reason we extend the
domain of ˜L(φ), from Φ given by (5.1) to ˜Φ = M × (R+)dΘ1 by allowing null variances
as follows:
˜L(Θ, σ2
I, 0J)
=
˜L(Θ, σ2
I),
(5.8)
˜L(Θ, 0dΘ1)
=
L(Θ).
(5.9)
With similar arguments as in the proof of Proposition 5.1.3 we can deduce from the
continuity of L(Θ) on M that ˜L(φ) is continuous on Φ (as (Θ, σ2) →(Θ0, σ2
0) ∈
Φ show that (ΨΘ1,σ2, Θ2) converges weakly to (ΨΘ1,0,σ2
0, Θ2,0)).
Consequently, both
equations (5.8) and (5.9) determine the continuous extension of ˜L from Φ to ˜Φ by
using Proposition 5.1.3.
Theorem 5.1.4 Let us consider the class
emΘ1 of all Gaussian randomizations
{ em(ΘI)}I of the initial model m, where I ⊂{1, . . . , dΘ1} (for I = ∅, em(Θ∅) = m) and
ΘI is deﬁned in Proposition 5.1.3. If Assumption 1 holds, then the unique MLE Θ∗
associated with the model m determines a unique MLE φ∗associated with the model
emΘ1. In particular, we have
φ∗
=
(Θ∗, 0dΘ1),
(5.10)
˜L(φ∗)
=
L(Θ∗).
(5.11)
Conversely, if Assumption 1-i) holds and the MLE φ∗associated with the model emΘ1
exists and is unique, then it determines a unique MLE Θ∗associated with the model
m and satisﬁes (5.10) and (5.11).
Proof: ⇒) The restriction of ˜L(φ) on Φ = M ×(R∗
+)dΘ1 is upper bounded by L(Θ∗) by
Lemma 5.1.1. Now, if φ ∈˜Φ\Φ, take the nonempty set J = {j ∈{1, . . . , dΘ1} : σ2
j = 0}
and I the complement of J. Then, ˜L(φ) can be expressed as the left-hand member
of equations (5.8) or (5.9). By the same equations we obtain that ˜L(φ) equals the

CHAPTER 5. ITERATIVE APPROACHES
97
likelihood function of the extended model ˜m(ΘI) or of the initial model m respectively.
Therefore, by applying Lemma 5.1.1 for ΘI or by Assumption 1 respectively, we infer
that ˜L(φ) is upper bounded by L(Θ∗) also on ˜Φ \ Φ, and consequently on ˜Φ. By
(5.9) we have that ˜L(Θ∗, 0dΘ1) = L(Θ∗) and consequently the MLE exists and if it is
unique it satisﬁes (5.10) and (5.11). We have that (Θ∗, 0dΘ1) ∈M × {0}dΘ1 and by
Assumption 1 and (5.9), it is unique on this set. Let us now assume that there exists
φ = (Θ, σ2) ∈M ×

R
dΘ1
+
\ {0}dΘ1

such that ˜L(Θ, σ2) = L(Θ∗). Take the nonempty
set I = {i ∈{1, . . . , dΘ1} : σ2
i > 0} and J the complement of I. By (5.8), (5.3), the
remark following (5.7) and our assumption, we have
˜L(Θ, σ2) = EΘI,σ2
I
 L(ΨI, Θ
′
2)

= L(Θ∗),
(5.12)
where Θ
′
2 concatenates the components of Θ1 indexed by J and Θ2. Since by Assump-
tion 1, the function L(Θ) is upper bounded by L(Θ∗), we obtain that the random
variable L(ΨI, Θ
′
2) has the same upper bound, that is, L(Θ∗) −L(ΨI, Θ
′
2) is a positive
random variable. But, by (5.12)
EΘI,σ2
I
 L(Θ∗) −L(ΨI, Θ
′
2)

= 0,
so we get L(ΨI, Θ
′
2) = L(Θ∗), PΘI,σ2
I−a.s. , or
1 = PΘI,σ2
I
 L(ΨI, Θ
′
2) = L(Θ∗)

= 1{Θ′
2=Θ′∗
2 }PΘI,σ2
I(ΨI = Θ∗
I) = 0,
where the second equality follows by Assumption 1 and the last equality follows from
the fact that ΨI follows a non-singular multivariate normal distribution, so it induces on
(RdΘI , B(RdΘI )) a measure which is absolutely continuous w.r.t. the Lebesgue measure
which assigns measure 0 to the singleton {Θ∗
I}. We conclude that for any φ ∈M ×

R
dΘ1
+
\ {0}dΘ1

, we have ˜L(Θ, σ2) < L(Θ∗) and consequently the MLE φ∗is unique.
⇐) If an MLE exists on ˜Φ, then ˜L is upper bounded on ˜Φ by ˜L(φ∗), and consequently
is upper bounded on M × {0}dΘ1 by the same value. By (5.9) this implies that L is
upper bounded on M by ˜L(φ∗). If φ∗∈M ×{0}dΘ1, then (5.10) and (5.11) are satisﬁed
for some Θ∗∈M. Since the upper bound of L is attained on Θ∗the MLE exists. It is
also unique, since if Θ∗
1 and Θ∗
2 are two distinct MLE, then (Θ∗
1, 0dΘ1) and (Θ∗
2, 0dΘ1)
are two distinct MLE associated with emΘ1, and this contradicts the initial assumption.
Now we will show that φ∗∈M × {0}dΘ1 is a necessary condition. Let us assume that
φ∗∈M ×

R
dΘ1
+
\ {0}dΘ1

. Take the nonempty set I = {i ∈{1, . . . , dΘ1} : (σ2
i )∗> 0}
and J the complement of I. By applying (5.12) for φ∗we have
˜L(φ∗) = EΘ∗
I,(σ2
I)∗
 L(ΨI, (Θ
′
2)∗)

.
(5.13)
If L(ΘI, (Θ
′
2)∗) <
˜L(φ∗) for all ΘI
∈RdΘI then this would contradict (5.13).
So, we conclude that there exists Θ∗∗
I
such that L(Θ∗∗
I , (Θ
′
2)∗)
=
˜L(φ∗), or
φ∗∗= (Θ∗∗
I , (Θ
′
2)∗, 0dΘ1) ̸= φ∗is an MLE, which contradicts the assumption of
uniqueness. Therefore, φ∗∈M × {0}dΘ1 and the proof is complete.
2

98
5.1. STOCHASTIC VARIANTS OF AN EM-TYPE ALGORITHM
A consequence of Theorem 5.1.4 is that we can transfer the maximization problem
corresponding to the initial model m to a maximization problem corresponding to the
model emΘ1. But since the latter is formulated as an incomplete data problem, we could
design an appropriate version of the EM-algorithm to solve the maximization problem
or more often a stochastic variant of the EM-algorithm (Expectation-Maximization,
see Dempster et al. (1977)) to handle the usually non-explicit state estimation problem.
It is noteworthy that if all parameters belonging to Θ are randomized then the M-step
becomes explicit. Otherwise, a GEM (G:Generalized) or stochastic GEM could be
used to ﬁnd the MLE. An example of this kind could be an ECM (C:Conditional),
see Meng and Rubin (1993), where parameters are updated in a cyclic fashion. In the
following Proposition we give the form of the Q-function, and the update formulas for
the randomized parameter Θ1.
Proposition 5.1.5 Let φ′ = (Θ1, Θ2, σ2)′ ∈M × (R∗
+)dΘ1 be the current parameter
update associated with the model emΘ1. The update equations for the parameter (Θ1, σ2)
are given by:
c
Θ1
=
Eφ′ Ψ | Y = y

(5.14)
bσ2
=
( bσ2
i )1≤i≤dΘ1 =
 Varφ′(Ψi | Y = y)

1≤i≤dΘ1
(5.15)
and Θ2 can be updated independently by maximizing
Q2(Θ2; φ
′) = Eφ′
log p(y|Ψ; Θ2) | Y = y
	
.
(5.16)
Proof: Since φ′ ∈M × (R∗
+)dΘ1, this parameter corresponds to the Gaussian ran-
domization em(Θ1) and by the deﬁnition of the Q-function and Deﬁnition 5.1.1 we
have
Q(φ; φ′)
=
Eφ′
log p(Ψ, y; Θ1, Θ2, σ2) | Y = y
	
(5.17)
=
Eφ′
log p(Ψ; Θ1, σ2) | Y = y
	
+ Eφ′
log p(y|Ψ; Θ2) | Y = y
	
.(5.18)
The last term in the right-hand member of equation (5.18) depends only on Θ2 and
coincides with (5.16), while the ﬁrst term denoted by Q1(Θ1, σ2; φ
′) does not depend
on Θ2. Consequently, the last statement of this theorem is true. By using the inde-
pendence of the components of Ψ and the density of the normal distribution we have
that Q1 can be maximized equivalently as follows:
Q1(Θ1, σ2; φ
′)
max
∼−1
2
dΘ1
X
i=1
log σ2
i −1
2
dΘ1
X
i=1
Eφ′{(Ψi −Θ1,i)2 | Y = y}
σ2
i
.
(5.19)
Consequently, it is elementary to show by relation (5.19) that (5.14) and (5.15) hold. 2
Remark A question which arises naturally concerns the adaptation of this method
in the case that some of the components of the parameter ψ have range diﬀerent
than R. Then a Gaussian randomization as explained in Deﬁnition 5.1.1 cannot be
applied directly and a modiﬁcation is needed by suitable reparameterizations whenever
possible.

CHAPTER 5. ITERATIVE APPROACHES
99
At each iteration of the EM-algorithm, given the current parameter update φ′, our
objective is to approximate Eφ′ Θ | Y0:n = y0:n

and
 Varφ′(Θi | Y0:n = y0:n)

1≤i≤dΘ1
where n corresponds to the observation length, since the update equations for the
parameters of the model given in Proposition 5.1.5 generally lead to non-explicit so-
lutions. Several alternative algorithms can be employed to make this approximation,
such as particle ﬁlters, Markov chain Monte Carlo based algorithms or Kalman-based
ﬁlters.
5.2
Iterative SMC and MCMC
5.2.1
Iterative Regularized/Convolution Particle Filtering
A particular feature of the Gaussian randomization is that the optimal variance
parameters equal zero (see Theorem 5.1.4). When the variances are close to zero, and
this will indeed happen after some iterations of the EM-algorithm, classical particle
ﬁlters cannot perform well, neither do the MCMC based methods. This is due to
the fact that the particles make a discrete approximation of the ﬁltering distribution
and consequently degenerate easier under a low variance scenario due to the resam-
pling mechanism (this is known as sample impoverishment). A successful strategy to
overcome this problem was devised in Musso and Oudjane (1998) by using Regular-
ized Particle Filters (RPF). In the light of this work, we presented in Section 4.3.4
the post-Regularized Particle Filter (Post-RPF) and the Convolution Particle Filter
(CPF). First, let us explain how the ﬁltering approach is feasible in the plant growth
model calibration context.
In our application context the initial model m is a state space model and the
randomized Θ can be considered as a part of the hidden state vector.
The most
natural way of dealing with Θ dynamically in time is to construct copies of Θ, denoted
Θn which remain constant in time, that is, for all n, we have Θn = Θn+1. Despite these
constant dynamics, the version of the particle ﬁlter that we describe in Section 4.3.4
enables us to modify sequentially in time the distribution of Θ given the increasingly
data vector.
The corresponding augmented state vector will be denoted by Xa
n =
(Xn, Θn). In this context, all we need to approximate is Eφ′ Θn | Y0:n = y0:n

and
 Varφ′(Θn,i | Y0:n = y0:n)

1≤i≤dΘ1. If we have a way to approximate the intractable
ﬁltering density p(xa
n|y0:n) by a suitable ˆp(xa
n|y0:n), then since xa
n = (xn, θn), we can
obtain an approximation of the ﬁrst two conditional moments of Θn given the complete
data vector with the help of the marginal ˆp(θn|y0:n).
Strategies to increase simulation numbers
An appealing feature of an EM-type algorithm is that it guarantees an improve-
ment of the likelihood function in every iteration of the algorithm. Suppose φ(k) =
(Θ1, Θ2, σ2)(k) ∈M × (R∗
+)dΘ1 be the parameter update at iteration k and Ψ(k) ∼

100
5.2. ITERATIVE SMC AND MCMC
NdΘ1(Θ(k)
1 , σ(k)2). The likelihood ascent property can be described as :
∆Qk = Q(φ(k); φ(k−1)) −Q(φ(k−1); φ(k−1)) > 0,
(5.20)
where Q(φ(k); φ(k−1)) is deﬁned as in (5.18). If Θ2 remains invariant between the two
iterations, then,
∆Qk =E

log p(Ψ(k); Θ(k−1)
1
, σ(k−1)2) | Y = y
	
−E

log p(Ψ(k−1); Θ(k−1)
1
, σ(k−1)2) | Y = y
	
.
(5.21)
However, the Q-function cannot be computed explicitly, but only approximated
by a ﬁnite sample size n which entails an algorithmic error disproportional to the
sample size, known as Monte Carlo error. For the sake of computational tractability,
the sample size is usually limited in practice. By doing so, we sacriﬁce accuracy for
acceptable computational complexity. Yet if the ﬁxed sample size is too small, we risk
of never converging to the MLE because of considerable sampling errors (Booth et al.,
2001) and in similar ways, losing the likelihood ascent property. This motivates an
increase in the sample size. Some eﬀorts have been made in the literature to increase
the sample size progressively. McCulloch (1994, 1997) proposed to increase the sample
size in a deterministic fashion with a ﬁxed number of iterations, while Polyak and
Juditsky (1992) used an averaging technique to optimize convergence speed. Fort and
Moulines (2003) tried to accelerate the convergence by coupling both techniques. In
addition, Capp´e et al. (2005) ﬁxed the ﬁnal sample size which can be found useful
under some situations. There are also some attempts made aiming at more ﬂexible
solutions, such as Booth and Hobert (1999); Levine and Casella (2001), who intended
to increase the sample size based on the estimated Monte Carlo error.
In this context, to assure the EM’s likelihood ascent property, we compare the two
strategies to increases the sample size (number of simulations) automatically. One
is based on a geometric increase, the other concerns a quadratic increase. The two
strategies can be described as follows :
– Geometric increase: n ←n + ⌊n/κ⌋,
κ = 4, 5 or 6.
– Quadratic increase: n ←n + 100 · i2,
i ←i + 1.
Since parameter estimates tend to make large moves in the ﬁrst iterations, for the
sake of computational eﬃciency, we propose to start with a relatively small sample
size. We deﬁne a evaluation criterion Zigzagk similar to ∆Qk in order to measure the
improvements made in the two last iterations :
Zigzagk = ˆQ(φ(k−1); φ(k−1)) −ˆQ(φ(k−2); φ(k−1)) > 0,
k ≥2.
For iteration k, if it appears that no further improvement is possible based on the
current sample size by verifying ZigZagk < 0 and ∆ˆQk < 0, which suggests that not
only no sign of improvement is detected for the past two iterations, the sample size is
consequently increased.
Another way to proceed is to deﬁne an interval for the ∆Qk function based on a
normal approximation (Booth and Hobert, 1999; Caﬀo et al., 2005):
√n

∆ˆQk −∆Qk

n→∞
−→N(0, σ2
Q),
(5.22)

CHAPTER 5. ITERATIVE APPROACHES
101
with ∆Qk deﬁned as in (5.21).
An approximate asymmetric conﬁdence interval can thus be constructed (Caﬀo
et al., 2005) :
[∆ˆQk −z1−α
ˆσQ
√n; ∆ˆQk + z1−α′ ˆσQ
√n]
where z1−α and z1−α′ the α-percentile and respectively α′-percentile of the standard
normal distribution. A Student’s t distribution can also be chosen. The σQ can be
estimated with ˆσQ by the method of Batch means presented in Section 4.1.5.
When ∆ˆQk −z1−α
ˆσQ
√n < 0, the sample size is to be increased, while if ∆ˆQk +
z1−α′ ˆσQ
√n < δ, where δ is a pre-deﬁned threshold, then the algorithm can be stopped.
Note that α′ is usually diﬀerent from α.
5.2.2
Iterative Adapted Metropolis-within-Gibbs
In the same way, the Adapted Metropolis-within-Gibbs proposed in the Section
4.1.3 can as well be employed to perform the E-step, although unlike the particle
ﬁlter based methods with resampling process engaged, the MCMC based methods
may potentially suﬀer from the sample degeneracy and impoverishment problem due
to the diminishing variance. Discussion of the related issues can be found in Bordes
et al. (2007).
Note that the noise parameters could be estimated in the same fashion as the
functional parameter, but the estimation performance depends crucially on the mixing
properties of the chain, and is often not satisfactory. More discussions regarding the
uncertainty assessment can be found in Chapter 6.
As for the convergence criterion, in the case of MCMC based methods, the Monte
Carlo error computed by the Batch means can be used to claim the convergence ac-
cording to the precision required. Since the sample size increases naturally with the
length of the Marov chain during the computation, the sample size does not need to
be pre-deﬁned by the Q-function as in the case of RPF/CPF, which can be considered
as one advantage of the MCMC based methods for such an iterative scale. However,
we can still use the Q-function to provide a minimum sample size which can be used
as a penalty term in the deﬁnition of the stopping criterion as presented in Section
4.1.5.
5.2.3
Implementation issues
Averaged estimator
Due to the stochastic nature of this method, the averaging technique (Capp´e et al.,
2005) (Chap.4) is carried out to smooth and to decrease the ﬂuctuations of the esti-
mates after a burn-in period of K iterations. If we denote ˆΘ(l) and ˆx(l)
n the estimates of

102
5.2. ITERATIVE SMC AND MCMC
the parameters and the hidden state variables at the l-th iteration respectively, then
for l > K :
¯ˆΘ(l) =
1
l −K
l
X
j=K+1
wj ˆΘ(j) and ¯ˆx(l)
n =
1
l −K
l
X
j=K+1
wjˆx(j)
n
,
(5.23)
where wj ∝the sample size (number of the particles or length of the chain) used for
each E-step.
Parametric Bootstrap
As mentioned in Section 5.1.1, since the posterior distributions of the parame-
ters are no longer representative of the estimates’ uncertainty because of the itera-
tive scheme, parametric bootstrap (Efron and Tibshirani, 1994; Bradley and Tibshi-
rani, 1994) is implemented to provide an approximated distribution of the estimates.
Therefore, we can easily deduce approximated conﬁdence intervals for each parameter
separately. The parametric bootstrap can be carried out as follows :
1. Collect a dataset y0:tmax (simulated or experimental).
2. Estimate xa
n with some method, including the proposed iterative approaches,
Bayesian approaches or frequentist approaches.
3. If the noise parameters are unknown, then update them. (For the related esti-
mation methods, please refer to Section 6.3).
4. Generate new datasets {y(i)
0:tmax} for i ∈{1, . . . , M} with the estimated parame-
ters (ˆxa
n and noise parameters if not ﬁxed).
5. Perform the estimation based on each of them {y(i)
0:tmax}, with i ∈{1, . . . , M}.
The obtained estimates denote ˆΘ(i).
6. Deduce the approximated 95% conﬁdence interval for each parameter based on
{ˆΘ(i)}, with i ∈{1, . . . , M}.
N.B.
The number of simulated datasets aﬀects the precision of the estimated conﬁdence
interval. Commonly, at least 500 datasets are required for a 95% conﬁdence interval.
A sample of 200 could also be acceptable, when the precision requirements are not so
strict.
Regarding the type of the conﬁdence interval, in our implementation, both the boot-
strap percentile interval and the bootstrap-t interval are considered. We note that
other bootstrap intervals also exist, their deﬁnitions are detailed in Section 6.4.1.
Moreover, we highlight that the algorithmic uncertainty, also known as Monte Carlo
error, which is associated with the stochastic algorithm and the underlying assumption
made for the approximation, can also be assessed by applying the conditional ICPF
approach to the same experimental data set a large number of times, as presented by
Chen and Courn`ede (2012).

CHAPTER 6
Uncertainty Assessment in
Stochastic State-Space Models
U
ncertainty assessment plays a crucial role when addressing parameter estimation
problems and model prediction issues. When a model contains a large number
of parameters, as it is often the case for plant growth models, parameter estimation
based on limited experimental data is a challenging task, for parameter identiﬁability
problems often occur. To avoid such situations, sensitivity analysis is classically applied
in advance to select the most inﬂuential parameters to be estimated.
On the other hand, as mentioned in Section 2.1, any realistic model should in-
corporate both modelling noises and observation noises. They allow us to avoid an
excessive forcing of the model towards the observations. Consequently, a complete
parametrization should involve the evaluation of these noises as well as the estimation
of the functional parameters. However, these two sources of uncertainty complicate
greatly the statistical analysis of the model, hence, the estimation of noise parameters
is a computational and statistical challenge for state-space models. In this thesis, we
elaborate diﬀerent strategies for the evaluation of noise parameters. Considering that
in our applications, we assume only Gaussian zero-centered noises, the parameters to
estimate are those that assess the variances. Note that other forms of noises could
also be used, such as Poisson, negative Binomial, log-normal or Gamma, without any
diﬃculty.
In this chapter, we ﬁrst give a general presentation of sensitivity analysis and detail
the method that is used in our application. Then, some noise parameter estimation
methods which can be combined with the functional parameter estimation methods
presented in Chapter 4 and Chapter 5 are detailed. Finally, the Bayesian credibility
interval and the frequentist’s conﬁdence interval, which can be regarded as common
tools to characterize the uncertainty related to the estimations are compared.
103

104
6.1. SENSITIVITY ANALYSIS
6.1
Sensitivity analysis
Biological models usually contain a large number of interacting components. Fre-
quently, both spatial and temporal processes across multiple scales are involved. A
good comprehension of the model is fundamental to ensure a correct use and an ap-
propriate interpretation of the obtained results. For a proper model assessment, we
need to quantify the model adequacy given the observation, to identify interactions
between factors, to evaluate the model relevance and eventually to simplify the model
structure if possible.
In all these tasks, parameter sensitivity analysis can provide
useful insights. Indeed, sensitivity analysis can help characterize the uncertainty un-
derlying a model. A possible deﬁnition of sensitivity analysis is proposed by Saltelli
et al. (2004):
“the study of how uncertainty in the output of a model (numerical or oth-
erwise) can be apportioned to diﬀerent sources of uncertainty in the model
input.”
When a model contains a large number of parameters, parameter estimation based
on limited experimental data may aﬀect strongly the quality of model prediction with
important estimates uncertainty. Therefore, sensitivity analysis is classically applied
in advance to select the most inﬂuential parameters to be estimated, whereas those
screened as the least inﬂuential ones can be ﬁxed to any values in their domains. In
the context of sensitivity analysis, this method is called “screening” or “factor ﬁxing”
(Campolongo et al., 2007).
With this purpose, we implement the algorithm proposed by Wu et al. (2012)
to compute Sobol’s indices (ﬁrst order and total order) of all the parameters of the
studied model based on its deterministic version. The generalized least-square criterion
is chosen, as the output for which sensitivity analysis is performed, in the process of
parameter selection.
Here, we brieﬂy present the general principles of sensitivity analysis based on Saltelli
et al. (2000) and Saltelli et al. (2004). For the simplicity of notations, let the model
of interest be presented under the following form :
Y = f(X1, . . . , Xd)
where {X1, . . . , Xd} are the input factors considered as random variables with known
probability distributions, the objective is therefore to study their inﬂuence on the
model outcome Y . Note that in our application, the input factors of interest are the
functional model parameters.
The basic idea of Sobol’s method (Sobol, 1993) is to decompose the variance of the
model output Y , denoted V (Y ) into terms of increasing dimensionality as follows:
V (Y ) =
d
X
i=1
Vi +
X
1≤i,j≤d
Vij + . . . + V1...d

CHAPTER 6. UNCERTAINTY ASSESSMENT
105
where
Vi = Var(E(Y | Xi))
Vij = Var(E(y | Xi, Xj)) −Vi −Vj
. . .
V1...d = V −
d
X
i=1
Vi −
X
1≤i,j≤d
Vij −. . . −
X
1≤i1<···<id−1≤d
Vi1...id−1
The corresponding sensitivity indices are deﬁned : the ﬁrst order index Si = Vi
V ,
the second order index Sij = Vij
V , and in the same fashion for higher order indices.
The total order indices associated to factor Xi, denoted STi, can be deﬁned as the
sum of all the indices accounting for the factor i. The ﬁrst order indices allow us to
quantify the proportion of V (Y ) that can be explained by each factor individually,
whereas the second order indices aim to quantify the interaction between two factors.
In other words, the diﬀerence between the total order index and the ﬁrst order index
for a given factor can be seen as an indication of the importance of the interactions
that concern this factor. Small diﬀerence implies that the associated interactions have
no signiﬁcant inﬂuence on the variance V (Y ).
Note that if the outcome variable Y is multidimensional and time-evolving, which
is often the case for plant growth models, the index Sj
i (t) should be computed which
represents the sensitivity to the factor (parameter) i at time t for each component of
the observation vector Y , denoted Yj, for j = 1, . . . , nY (Wu et al., 2012). The general
sensitivity index Sj
i (t) can be obtained as follows :
Sj
i =
Ptmax
t=1 Sj
i (t)Var(Yj(t))
Ptmax
t=1 Var(Yj(t))
,
which can be understood as weighting the indices Sj
i (t) with the associated variance
Var(Yj(t)). For parameter estimation, we choose as output the GLS criterion. If we
denote ˜Y = f(X1, . . . , Xd), then the GLS criterion can be expressed as :

Y exp −˜Y
T
Σ−1 
Y exp −˜Y

,
where Σ is the covariance matrix of the observation errors and Y exp is the observation
vector which contains the experimental data used for parameter estimation (see Section
3.4.1 for details). The parameter ranking is deduced from their total order indices.
Note that once the inﬂuence of the parameters are determined by parameter sensi-
tivity analysis, the parameter selection problem is transformed into a model selection
problem in which candidate models have diﬀerent numbers of parameters: we increase
the complexity of the model by introducing parameters according to their ranking. In
the simplest model, only the most inﬂuential parameter is estimated while all the oth-
ers are ﬁxed to the mean values of their distributions; in the second simplest mode, the
two most inﬂuential parameters are estimated; ...; in the full model, all the parameters
ranked by the sensitivity analysis are estimated. Model selection criteria can be used
to select the model that is best supported by the data from all the candidate models.
In the same way, model selection criteria can also be used for noise parameter
selection. In the following, some methods for the noise parameter estimation problem

106
6.2. EVALUATION OF NOISE PARAMETERS BY MODEL SELECTION
are presented. First, we introduce the noise parameter estimation with model selection.
6.2
Evaluation of noise parameters by model selec-
tion
The ﬁrst approach consists of using a grid of modelling noise parameters ﬁxed
at diﬀerent levels for selection. SMC methods as well as MCMC based methods, or
frequentist methods can be performed to estimate the functional parameters of the
model with diﬀerent levels of noise parameters, with the aim of obtaining the best
combination with respect to a given model selection criterion.
Here, we ﬁrst introduce some model selection criteria frequently employed in various
applications.
Let L(ˆθ) denote the likelihood function evaluated at ˆθ. The most famous model
selection criterion is the Akaike Information Criterion (AIC). Founded on information
entropy, AIC evaluates the trade-oﬀbetween the goodness of ﬁt of the model and the
complexity of the model (Akaike, 1974). It is widely used as model selection criterion
to avoid over-ﬁtting problems. The AIC has two components: negative log-likelihood,
which measures lack of model ﬁt to the observed data, and a bias correction factor,
which increases as a function of the number of model parameters. It is deﬁned as
follows :
AIC = −2 (ln L(ˆθ) −d),
where d denotes the number of parameters that are estimated. A corrected version
of the AIC, known as AICc is also frequently used to account for limited sample size
(Hurvich and Tsai, 1989) :
AICc = −2 (ln L(ˆθ) −d) + 2 d (p + 1)
(n −d −1),
in which, n denotes the sample size of the observation vector.
When the number of observations is not many times larger than d2, AIC increases
the probability of choosing models with more parameters, which can result in over-
ﬁtting problems. Therefore, Cavanaugh (1997) and Burnham and Anderson (2002)
recommend strongly the use of AICc instead of AIC.
Another similar criterion based on the likelihood evaluation is the Bayesian infor-
mation criterion (BIC), also known as Schwarz criterion (Schwarz, 1978). It is deﬁned
as follows :
BIC = −2 ln L(ˆθ) + d ln n,
These two criteria are commonly used for model selection objectives with point
estimations (e.g. obtained by the MAP estimator). According to this criterion, the
best model is deﬁned as the one that is best supported by the data and obtains the
smallest value compared to the other candidate models. The BIC generally penalizes
more strongly the number of parameters than AIC.
A popular model selection criterion often employed in the Bayesian model com-
parison framework is the Deviance Information Criterion (DIC) (Spiegelhalter et al.,

CHAPTER 6. UNCERTAINTY ASSESSMENT
107
1998). It can be regarded as a natural generalisation of AIC (Claeskens and Hjort,
2008). While AIC and BIC require calculating the likelihood at its maximum over θ,
DIC is easily calculated from the samples generated by a Markov chain Monte Carlo
simulation in the case of Bayesian model selection.
First, we introduce the Bayesian deviance. The investigation of the posterior dis-
tribution of the log-likelihood under each model is conducted to derive measures of ﬁt
and hence, choose the most eﬀective number of parameters to estimate. It is deﬁned
as follows :
D(θ) = −2 ln p(y|θ) + 2 ln f(y),
D(θ) is the posterior distribution of the log-likelihood of the data (Dempster, 1974),
where f(y) is a function of the data alone and does not have impact on model com-
parison. Therefore, the ﬁt of the model can be assessed by the conditional expectation
of the deviance given y :
¯D(θ) = Eθ|y(D(θ)),
(6.1)
while the complexity of the model can be measured by the eﬀective number of param-
eters:
pD = Eθ|y(D(θ)) −D(E(θ|y)) := ¯D(θ) −D(¯θ),
(6.2)
where ¯θ = E(θ|y) is the mean estimates of θ obtained from independent runs. Finally,
the Deviance Information Criterion can be deﬁned as :
DIC = ¯D(θ) + pD = D(¯θ) + 2pD.
(6.3)
Like AIC and BIC, smaller values of DIC indicate a better ﬁtting. Although de-
signed for model selection regarding the complexity of the model (number of parame-
ters), these criteria are used in our context to deﬁne the level of noise which ﬁts better
the data. Based on a common dataset, the same estimation method is carried out, to
ﬁt the model. Ideally, independent runs could be made to give an idea of the Monte
Carlo error. The estimation is subsequently evaluated by the criteria mentioned above.
Note that for AIC, AICc and BIC, it simply amounts to evaluating the likelihood of
ˆθ. In the following comparison, DIC is used to resolve the Bayesian model selection
problem, whereas AIC, AICc and BIC are used to address model selection issues of fre-
quentist based iterative approaches. Note that if multiple noise parameters are present
in the model, the computational intensity is increased drastically, since there will be
more possible combinations of parameter values. Therefore, this approach should be
restricted to the parameters that have an identiﬁability problem.
In the case when no identiﬁcation problem is detected, the noise parameters can be
estimated jointly with the functional parameters by SMC and MCMC based methods.
6.3
Conditional SMC and MCMC for noise param-
eter estimation
First, we partition the full parameter vector Θ: Θ = (Θ1, Θ2), in which Θ1 denotes
the parameters corresponding to the deterministic part of the model (state equation

108
6.3. CONDITIONAL SMC AND MCMC
and measurement equation) and Θ2 denotes those of the noise model, including the
variance parameters of the modelling noises and of the observation noises (η and ξ in
(3.1)).
Ideally, functional and noise parameters should be jointly estimated. However, even
if theoretically this could be feasible, in practice it could be diﬃcult to carry out. Many
factors could be responsible for this inconvenience. First, adding additional variance
parameters in the estimation process could result in identiﬁability problems, since
the number of unknown parameters could be signiﬁcantly increased. Second, the true
purpose of introducing noise parameters is to acknowledge that variability exists in the
evolution and in the observation of the system, and thus can be used to explain some
residual variability that cannot be explained by the deterministic equations involved
in an assumed ideal model. However, this cannot be entirely reﬂected in the target
function if the functional and noise parameters are estimated at the same time. Thus,
to estimate Θ1 and Θ2 in turns seems to be a more reasonable scheme to carry out
the model calibration for stochastic state-space models. Note that this scheme is very
classical which is also used in the GLS estimation (see for example the 2-stage Aitken
estimator proposed by Taylor (1977)). We proceed the estimation as follows :
– Update Θ1 ∼π(Θ1|Θ2, y1:tmax).
– Update Θ2 ∼π(Θ2|Θ1, y1:tmax).
In the ﬁrst place, the estimation of the hidden states and of Θ1 is performed by
considering that Θ2 is known. Note that the estimation of the functional parameters
can be conducted either with Bayesian inference, such as SMC methods or MCMC-
based methods, or with frequentist-based methods, such as the stochastic EM variant
that we proposed in Chapter 5 with the E-step performed with either MCMC-based
methods or particle ﬁltering based methods. From the ﬁrst estimation of Θ1 and of
the hidden states, we can estimate the parameters of the distributions of the modelling
and measurement noises Θ2 from the results. Conditionally to the new estimated Θ2,
the approach is then carried out again to estimate Θ1 together with the hidden states.
In this way, the algorithm can be iterated in turns between the model parameters Θ1
and the noise parameters Θ2 until the convergence of both.
In practice, however, the convergence of this method is not always assured. In
our implementation, small initial variances for the noises seem to be helpful to the
convergence of the algorithm towards satisfactory estimation for both the hidden states
variables and the functional parameters Θ1.
Regarding the second step for noise parameter estimation, several approaches are
possible and the choice remains debatable. In this thesis, we detail and examine two
of them.
6.3.1
Bayesian update of noise parameters
In the Bayesian framework, instead of updating the parameter vector at once, here
we propose to divide the parameter vector into two parts, Θ1 and Θ2 and update
them in turns. For MCMC based methods, this scheme is known as Gibbs in blocks.
Since the functional parameters Θ1 have the priority, and we wish that they could

CHAPTER 6. UNCERTAINTY ASSESSMENT
109
explain as much variability of the model as possible, given the data, we choose to start
the joint updates by Θ1. In order to keep the stability of the estimation, the update
of noise parameters Θ2 is carried out only when the estimations of Θ1 is claimed
converged conditionally to Θ2. Moreover, conjugate prior distributions are chosen for
Θ2, so that they can be updated by simulating directly from the target distribution
instead of being updated by a MH algorithm. For instance, for variance parameters
corresponding to Gaussian density distributions, prior assumption of Inverse Gamma
distributions can be made in order to guarantee the positivity of the sampled noises,
and most importantly, they can lead to explicit updates of the posterior distributions.
The detailed implementation of this method for our test case can be found in Section
8.7.
6.3.2
Empirical noise parameter estimation
If the noise parameters are deﬁned without a conjugate prior, or a ﬁltering method
is applied to estimate the functional parameters, then an empirical noise parameter
estimation is needed at the end of the ﬁltering update. In our implementation, under
the assumption that both the modelling noises {ηn}0≤n≤tmax and the observation noises
{ξn}0≤n≤tmax are mutually independent Gaussian distributions (eventually multivariate
Gaussian distributions), their estimators can be derived based on the estimates of the
hidden states variables and the functional parameters (denoted ˆxa
n as the augmented
hidden state vector), as well as the observation vectors Y0:n.
For modelling noise parameters, their estimators can be deﬁned as the averaged
diﬀerence between the estimates of the hidden state variables in ˆxa
n and ˜xa
n obtained by
propagating through the evolution equation in its deterministic form f a
n(ˆxa
n−1, En−1, 0).
Respectively, for the observation noise parameters, their estimator can be deﬁned as
the averaged diﬀerence between the estimation of the outcome variables ˆyn = gn(ˆxa
n, 0)
(deterministic observation equation) and the experimental observation Yn.
We note that for particle ﬁltering approaches, the estimation of the noise param-
eters can be carried out for each of the M particles. Therefore, the posterior distri-
butions of the noise parameters ση and σξ can be obtained by the samples with their
associated weights w: {ˆσ(i)
η , w(i)}1≤i≤M and {ˆσ(i)
ξ , w(i)}1≤i≤M .
Undoubtedly, other noise estimation methods also exist in literature, which are
often based on the maximum likelihood functions.
More discussions regarding the
noise parameter estimation can be found in de Valpine (2002) and Dennis et al. (2006).
6.4
Comparison of uncertainty intervals
The proper interpretation and distinction of the Bayesian credibility intervals, boot-
strap intervals and frequentist conﬁdence intervals appears often diﬃcult or confusing.
In this section, we attempt to present their deﬁnitions, to compare their use in prac-
tice, and to sort out the interpretation problem. The problem can be formulated as
follows:

110
6.4. COMPARISON OF UNCERTAINTY INTERVALS
Suppose that the objective is to estimate θ conditional on the observed data y and
the data generation process is known F(y|θ). The inference problem is to infer the
optimal value ˆθ of θ with respect to a given criterion and under speciﬁc assumptions for
the nature of θ. We assume for the rest of this section that the unknown parameters
is unidimensional. Similar interpretations can yet be given in the multi-dimensional
case as well.
6.4.1
Frequentist conﬁdence interval
In the frequentist interpretation, a 100(1-α)% conﬁdence interval deﬁnes a charac-
teristic of a process to generate intervals. If we denote a 100(1-α)% conﬁdence interval
I ≡[lb(Y ); ub(Y )], where lb(Y ) and ub(Y ) represent the upper bound and the lower
bound respectively, and generated by the random process, then ideally I should satisfy
Pθ∗(θ∗∈I) = 1 −α,
where α is known as the conﬁdence level and θ∗stands for the true value of the
parameter. If we generate independently data under the same conditions (and under
θ∗), then with a large sample size, 100(1-α)% of the estimated conﬁdence intervals
contain the true value of the parameter.
As illustrated by Figure 6.2, among 40 simulated 90% conﬁdence intervals, 4 do
not contain the true value θ∗. This is an example of the frequentist interpretation in
the case that the samples are generated from a true underlying distribution.
Figure 6.1: Simulated conﬁdence intervals. The true value is represented by the vertical
line.
A similar notion widely employed is the frequentist coverage.

CHAPTER 6. UNCERTAINTY ASSESSMENT
111
Frequentist coverage
The frequentist coverage is calculated before the observations are gathered, there-
fore, it is known as pre-experimental coverage.
Deﬁnition 6.4.1
A random interval [lb(Y ); ub(Y )] has 100(1-α)% frequentist coverage for θ before the
new observations are made if:
Pθ(lb(Y ) < θ < ub(Y )) = 1 −α.
Note that once the observations are gathered Y = y, θ∗is either contained in the
interval or not, it is no longer a matter of chance.
To explain this notion, it is important to understand that for frequentist methods,
a point estimate is a numerical estimate with no indication of its quality (precision,
bias and variance of the estimator). If there is not a direct method to extract a 100(1-
α)% conﬁdence interval while we intend to assess the estimation quality, then we need
to verify all possible random samples of the same size (n) as the experimental data
{Y exp
i
}i=1,...,n that are used to obtain our point estimate in the ﬁrst place. Indeed,
the reasoning used in frequentist inference depends on thinking about all possible
appropriate samples of the same size. Which samples are “appropriate” depend on the
particular statistical procedure (model assumptions) used.
Suppose Y denotes the new random sample vector of size n, then we can deﬁne
a random variable ˜θ resulting from Y as an estimate of θ∗, the distribution of which
is known as sampling distribution. The idea of frequentist coverage and conﬁdence
intervals is that we can ﬁnd an appropriate k that
– The probability that ˜θ lies between θ∗−k and θ∗+ k is 100(1-α)%. Therefore,
˜θ is random while θ∗and k are ﬁxed.
– The previous conﬁdence interval can be easily reformulated as the probability
that θ∗lies between ˜θ −k and ˜θ + k is 100(1-α)%.
The resulting problem is that there are two possibilities regarding the data
{Y exp
i
}i=1,...,n:
it can provide either a conﬁdence interval [˜θ −k; ˜θ + k] that con-
tains θ∗(with 100(1-α)% of the chance), or a conﬁdence interval that does not contain
θ∗(with α% of the chance). Unfortunately, it is impossible to know which possibility
is true. We can only state that the procedure that we used to obtain the conﬁdence
interval works 100(1-α)% of the time.
Therefore, if one aims to achieve a post-experimental coverage, a large number of
independent experiments can be carried out, and we can build one conﬁdence interval
for each of them. By the Strong Law of Large Numbers, ideally if all the intervals
have 100(1-α)% coverage probability, then with a large sample size, approximately
100(1-α)% of these intervals should contain the true value of the parameter. However,
the conﬁdence intervals are many times approximate, moreover, it is not always the
case that all assumptions used in deriving a conﬁdence interval are met, therefore
the actual coverage probability could be less or greater than the nominal coverage
probability which corresponds to the conﬁdence level pre-deﬁned.

112
6.4. COMPARISON OF UNCERTAINTY INTERVALS
Bootstrap conﬁdence interval
In most applications, it is extremely diﬃcult or not possible to sample directly from
the original distribution F from which {Y exp
i
}i=1,...,n were drawn from, another option
is to sample from the best approximation to this distribution, based on the observed
data. Let ˆF denotes the empirical distribution function as an approximation of F. The
bootstrap idea is to generate new samples from the empirical distribution function.
The construction of a bootstrap interval involves two steps with necessary assump-
tions for the approximations: in the Plug-In step, we consider the distribution of the
sampling statistics under ˆF instead of the distribution F to result in the bootstrap dis-
tribution, and in the Monte-Carlo step, an empirical approximation is obtained instead
of the exact bootstrap distribution. There are situations that allow to compute the
exact bootstrap distribution and in this case the Monte Carlo step is not needed. In
the vast majority of situations the bootstrap distribution is not tractable analytically.
Then simulation from the empirical distribution ˆF yields an empirical approximation
to the bootstrap distribution. This approximation can be made arbitrarily close by in-
creasing the bootstrap sample size, given the availability of suﬃcient computing power.
In contrast, the asymptotic equivalence of the bootstrap distribution and original dis-
tribution of the sampling statistic is far from being trivial and is based on convergence
results for empirical processes.
In order to construct a conﬁdence interval for θ we need to know how an estimator
of ˆθ varies in repeated sampling from the population. Since all the information we
have about the population is contained in the sample, bootstrap methods treat the
sample as if it were the population.
In the following, we present three types of
bootstrap conﬁdence intervals that are commonly used, the details of which can be
found in Efron and Tibshirani (1994) and Davison and Hinkley (1997) (Chapter 5.18):
- Bootstrap percentile interval: I = [q∗
α/2; q∗
1−α/2],
where q∗
α/2 is the α/2 percentile of the bootstrap distribution (respectively 1 −α/2
percentile for q∗
1−α/2.
- Basic bootstrap interval: I = [2ˆθ −q∗
1−α/2; 2ˆθ −q∗
α/2],
where ˆθ is the estimate of θ in the original model.
- Bootstrap-t interval: I = [ˆθ −ˆt∗
1−α ˆ
SEbootstrap; ˆθ −ˆt∗
α ˆ
SEbootstrap],
where
ˆ
SE denotes the estimate of the standard error in the original model, and ˆtα
denotes the α percentile of the bootstrapped Student’s t-test : ˆt∗= (ˆθ∗−ˆθ)/ ˆ
SEbootstrap,
in which
ˆ
SEbootstrap denotes the standard error of the bootstrap distribution and ˆθ∗
denotes the bootstrap mean.
N.B.
- The diﬀerence between the bootstrap mean ˆθ∗and the original estimate ˆθ can be
regarded as an estimate of the bias of ˆθ.
Indeed, standard parametric conﬁdence intervals can provide a measure of un-
certainty related to the model parameters. Yet they require acceptance of Gaussian

CHAPTER 6. UNCERTAINTY ASSESSMENT
113
assumptions for their validity. However, given the limited observation data to esti-
mate the variability resulted from various of sources, the Gaussian assumptions may
not always hold. Alternatives to the standard parametric conﬁdence intervals are the
semiparametric or nonparametric methods.
Wang et al. (1994) compared several bootstrap conﬁdence intervals to Bayesian
conﬁdence intervals for smoothing splines. Both bootstrap and Bayesian conﬁdence
intervals are not necessarily symmetric as classical frequentist conﬁdence intervals.
They concluded that bootstrap conﬁdence intervals work as well as Bayesian intervals
concerning average coverage probability. Additionally, bootstrap conﬁdence intervals
appear to be better for small sample sizes. Based on their simulations, the “percentile-
interval”bootstrap interval performs better than the other types of bootstrap intervals.
Bootstrap conﬁdence intervals are easy to interpret and can be used with any
distribution. However, because they require a large number of repetitions of the whole
estimation process, their construction is computationally intensive.
6.4.2
Bayesian credibility interval
In contrast to the classical frequentist methods, a Bayesian method considers that
the true θ∗is a random variable drawn from some probability distribution. The un-
certainty is captured by imposing a prior knowledge and updated based on the new
observations. The obtained conclusion stands only under the assumption that the prior
is pertinent. The point estimate is more often obtained using the mean of the posterior
distribution. Note that other estimators also exist, such as the posterior mode and the
posterior median. The extent of the uncertainty is expressed by a credibility interval:
P(ˆqθ
α/2 ≤θ ≤ˆqθ
1−α/2|Y = y) = 1 −α.
Figure 6.2: Bayesian interpretation of a 90% credibility interval.

114
6.4. COMPARISON OF UNCERTAINTY INTERVALS
Bayesian coverage
The Bayesian interval describes the possible location of the true parameter θ∗after
the observation of y. The Bayesian coverage probability is therefore known as post-
experimental.
Deﬁnition 6.4.2
An interval [lb(y); ub(y)], based on the observed data Y = y has 100(1-α)% Bayesian
coverage for θ if
P(lb(y) < θ < ub(y)|Y = y) = 1 −α.
6.4.3
Comparisons
The comparison between the Bayesian credibility interval and frequentist conﬁdence
interval has always been a thought-provoking subject. Almost four decades ago, Jaynes
(1976) examined the Bayesian and frequentist solutions to six common statistical prob-
lems to investigate the reliability of the conﬁdence intervals provided. According to
this paper, in every case without exception, the Bayesian method appeared to yield
the same or better results yet easier to apply compared to the frequentist methods.
Furthermore, they found that the frequentist solutions were satisfactory only when
they agreed closely with those provided by the Bayesian methods.
But is it true that the Bayesian’s choice is absolutely better?
It actually depends on our objective. In fact, a frequentist conﬁdence interval is
not deﬁned with the aim of obtaining the highest probability to contain the real value
of the parameter given what we can infer from the observations. Unfortunately, in
practice this is often the way that the conﬁdence interval is interpreted, which can be
misleading. Therefore, if the comparison is about ﬁnding an interval where the real
value of the statistics lies with probability 100(1−α)%, then the frequentist conﬁdence
interval may not answer that question directly (which entails the problems stated in
Jaynes’ paper), while the Bayesian solution can. Hence the conclusion is that the
Bayesian credibility interval is superior to the frequentist one in that aspect. If the
former objective can be regarded as the “wrong” one for the frequentist methods, then
the right objective would be to obtain an interval in which if the experiment is repeated
a large number of times, then the true value of the statistic lies with 100(1−α)% of all
the intervals obtained. In such cases, the Bayesian’s solution may also be able to give
an answer, although it may not be directly the credibility interval (Hartigan, 1966).

CHAPTER 7
Computational implementation
with PyGMAlion
I
n plant growth modelling, a large variety of models coexist in the literature with
generally an absence of benchmarking between the diﬀerent approaches and in-
suﬃcient model evaluation. In this context, the PyGMAlion (Plant Growth Model
Analysis, Identiﬁcation and Optimization) platform (Courn`ede et al., 2013) can be
regarded as an attempt to promote a modelling framework and model analysis meth-
ods with the objectives of enhancing good modelling practices and increasing model
design eﬃciency. In this chapter, this simulation platform on which all the methods
presented in this thesis are implemented is presented. Some implementation issues are
subsequently discussed.
Note that all the simulations and numerical tests presented in this thesis were
carried out on the mesocenter of Ecole Centrale Paris, which has a total capacity
of over 10 TFLOPS and comprises nearly 1000 calculation units 1. All the parallel
computations were realized with up to 10 cores.
7.1
Motivation
Undoubtedly, classical numerical and statistical software such as MATLAB®, R
or WinBugs, generally provide eﬃcient and sophisticated methods for model analysis,
especially for parameter estimation. However, the platform proposed is not always
adequate and convenient for the development and analysis of complex models featured
by speciﬁc data structures (diﬀerent from vectors or matrices), which generally need
to be developed by the user, as well as speciﬁc encapsulation methods in order to
make the generic analysis and estimation methods applicable. The proposed packages
1. http://www.mesocentre.ecp.fr/
115

116
7.2. STATE-SPACE MODEL FORMULATION
provide algorithms that are operated like a black box, which often appear to be hard
to be reconﬁgured. Moreover, various limitations are imposed by the software cited
previously, especially regarding the computational resources. Indeed, computationally
intensive statistical models and methods need corresponding computation facility to
scale. To improve the computational performances, the use of distributed computation
is an opportunity (parallel and multi-threading computation) which can be diﬃcult to
carry out with the above limitations.
Under these circumstances, the PyGMAlion C++ platform oﬀers a framework in
which the implementation of stochastic or deterministic discrete dynamic models and
statistical methods can be carried out easily. All the algorithms presented in this thesis
including the sensitivity analysis, uncertainty analysis, parameter estimation, model
selection or data assimilation are thus implemented on this platform, so that model
comparisons and method comparisons can be conducted to provide benchmarks for
the diﬀerent approaches, among other utilities.
7.2
State-space model formulation
To perform Monte Carlo based methods based on state-space models, ﬁrst, we need
to translate them into exploitable code for simulation, the following reformulations are
made (Bayol et al., 2013).
• The dynamical evolution system of a meta model M is deﬁned as a 6-tuple (for
which the general formulation is detailed in Section 3.2):
{Xn, En, Θ1, Θ2, INIT, NEXT}
where :
– {Xn, En, Θ1} denote respectively the state variables, the control variables and
the functional parameters involved in both the evolution step and the obser-
vation step.
– The noise parameter vector Θ2 is used to generate the modelling noises (ηn)n
and the observation noises (ξn)n of the dynamical system, for each random
sequence a pseudo-random number generator is associated.
– INIT and NEXT describe respectively the initialization function for the state
variables X0 and the evolution function of the dynamical system model fn of
a meta model M.
• An observation model is deﬁned as a 4-tuple OMi = {Xn, Θ1, Θ2, Y i
n}, with Y i
n
the ith outcome variable.
• An observer is deﬁned as a 2-tuple Oi = {OMi, TMLi} where TML is a timeline
associated to OMi which control the trigger of global observation of dynamical
system during the evolution.
Thus the global system is denoted by a 8-tuple
S = {Xn, En, Θ1, Θ2, INIT, NEXT, Yn, TML}.
N.B.
Instead of deﬁning a common observer for all the outcome variable Yn, we choose to
personalize one observer for each component of Yn in order to account for their irreg-

CHAPTER 7. IMPLEMENTATION WITH PYGMALION
117
ularity and diversity, such as diﬀerent types of observation noise, diﬀerent timelines
and various output forms.
7.3
Computation issues and strategy
A crucial justiﬁcation of one simple Monte Carlo estimation is the assumption that
we are capable of generating a set of independent random values with distribution π.
7.3.1
Random number generation
The assumption that one can create a set of values with independent π distribu-
tions has become more viable with the advent of computing power and is crucial in
the justiﬁcation of simple Monte Carlo estimation. The task of generating a set of
independent values with distribution π is usually divided into two parts :
1. Generate a set of values {U(i)}i=1,...,n considered i.i.d. from U[0, 1).
2. Transform U(i) to yield {X(i)}i=1,...,n which follow distribution π.
Much attention has been given to this ﬁrst step which is the goal of a random
number generator. With the growing needs of working with increasing size of samples,
sophisticated algorithms have been designed and studied to produce a sequence that
approximates the properties of random numbers and is practically indistinguishable
from independent uniform samples. These algorithms are known as Pseudo-Random
Number Generators (PRNG), the advantages of which are their reproducibility and
eﬃciency in number generation.
Generally, they operate in a recursive way such that the next number generated is
determined by the last several numbers. The sequence is not truly random for it is
determined by a relatively small set of initial values, in which a random seed needs to
be required.
Another key point is that the recursive generator must be periodic, as each number
is identiﬁed to ﬁnite precision. In the case when the sample size is larger than the
period of the generator, the illusion of independence is impossible to maintain. Hence,
the sample size should not exceed the square root of the period.
In this work, the PRNG used is called Mersenne Twister (Matsumoto and
Nishimura, 1998). It has a period of 219937 −1 and optimal equidistribution property
in 623-dimensional output blocks to 32-bit accuracy.
For the simulations studied in this thesis, the assumption of i.i.d random variables
taken from this generator appears reliable. However, more other generators can be used
for comparison’s sake, so as to evaluate the performance and to ensure the functionality
of each generator. Further tests can therefore be carried out following this direction.
7.3.2
Implementation of Inverse-Gamma priors
Since the prior distribution types are limited by the basic distributions proposed by
the library, to use an Inverse-Gamma prior, a transformation is required to compute the

118
7.3. COMPUTATION ISSUES AND STRATEGY
corresponding expectation and standard deviation of the Gamma distribution provided
by the boost C++ library. Similar problem has been encountered in other software
development, more discussion of which can be found in Adjemian (2010).
Deﬁnition 7.3.1 Let X be a Gamma distributed random variable with shape param-
eter α > 0 and scale parameter β > 0. Then Z = X−1 can be seen as Inverse-Gamma
distributed, Z ∼IG(α, β).
Proposition 7.3.1 The density of the continuous random variable Z ∼IG(α, β) is:
f(z) = C(α, β)−1 × z−α−1 exp−1
βz
where C(α, β) = Γ(α)βα is the constant of integration.
Proof
Let fx denote the density of the Gamma distribution. If we deﬁne g(x) =
1
x, the
density of the Inverse-Gamma distribution can be written as follows:
fZ(z) = fX(g−1(z)) × | d
dzg−1(z)|
= C(α, β)−1 × z−α+1 exp−1
βz ×| d
dz
1
z|
= C(α, β)−1 × z−α−1 exp−1
βz .
2
Proposition 7.3.2 The expectation and variance of Z ∼IG(α, β) are:
µ =
1
(α −1)β
σ2 =
1
(α −1)2(α −2)β2
for any
α ≥2.
(7.1)
Proof
According to the pdf of the Inverse-Gamma, the ﬁrst moment is
µ = C(α, β)−1
Z ∞
0
z−α exp−1
βz dz
= C(α, β)−1
Z ∞
0
uα−2 exp−u
β du
= C(α −1, β)
C(α, β)
= Γ(α −1)βα−1
Γ(α)βα
=
Γ(α −1)βα−1
(α −1)Γ(α −1)βα
=
1
(α −1)β ,

CHAPTER 7. IMPLEMENTATION WITH PYGMALION
119
and the second moment is deﬁned by
E[Z2] = C(α, β)−1
Z ∞
0
z−α+1 exp−1
βz dz
= C(α, β)−1
Z ∞
0
uα−3 exp−u
β du
= C(α −2, β)
C(α, β)
= Γ(α −2)βα−2
Γ(α)βα
=
Γ(α −2)βα−2
(α −1)(α −2)Γ(α −2)βα
=
1
(α −1)(α −2)β2,
so that the variance
σ2 =
1
(α −1)(α −2)β −
1
(α −1)2β2
=
α −1
(α −1)2(α −2)β2 −
α −2
(α −1)2(α −2)β2
=
1
(α −1)2(α −2)β2.
2
Therefore, according to the desired the mean µ and the variance σ2 of the param-
eter, the shape α and scale β parameters can be deﬁned as follows:
α = 2 + (µ
σ)2,
β =
1
µ[1 + ( µ
σ)2].
Note that for the implementation of Gibbs sampler, this calculation is useful when
an Inverse-Gamma conjugate prior is required for the noise parameter σ2
obs update (for
details, see Section 8.7.1).
7.3.3
Parallel simulations
To achieve the parallel computation of Monte Carlo simulations, a vector of simula-
tions (S) is required. It can be regarded as a basic tool for statistical analysis methods,
such as ﬁltering methods, parallel MCMC, sensitivity analysis and uncertainty analy-
sis. Figure 7.2 illustrates the ﬂow of the Convolution Particle Filter, with each particle
representing an individual simulation S.
For each simulation, a PRNG is associated to each of its noises (modelling noises or
observation noises). For the ﬁltering algorithms which contain a resampling process,
some simulations are duplicated during the exploration of the state-space, therefore, a

120
7.3. COMPUTATION ISSUES AND STRATEGY
new random seed needs to be initiated to avoid the duplication of the same sequence
of random variables shared by two simulations.
A multi-threaded or distributed implementation is carried out for the ﬁltering meth-
ods, the parallel MCMC based algorithms and sensitivity analysis algorithms.
Figure 7.1: System evolution of the Unscented Kalman Filter 2.
2. http://www.cslu.ogi.edu/nsel/ukf/node6.html

CHAPTER 7. IMPLEMENTATION WITH PYGMALION
121
Figure 7.2: System evolution of the Convolution Particle Filter.
Figure 7.3: System evolution of the Ensemble Kalman Filter.

122
7.4. ONGOING WORK AND PERSPECTIVE
7.4
Ongoing work and perspective
From a computational point of view, the objective is to provide a stronger parallel
implementation for distributed computing. So far, the parameter estimation methods
like the Convolution particle ﬁlter, the Diﬀerential Evolution Adaptive Metropolis, the
Interacting Metropolis-within-Gibbs as well as the algorithms to perform sensitivity
analysis, such as the Sobol algorithm beneﬁt from the distributed computing via MPI
(Message Passing Interface) or OpenMP (Open Multiprocessing) approaches.
The
objective is to enable the possibility of distributed computation at more elementary
levels (each time step for example) which should elevate the computational performance
to a new level.
More generally, the platform should evolve towards an EDSL (embedded domain-
speciﬁc languages), with the objective to ease for the users the development of models,
the calls of analysis methods and the use of parallel architecture for computation.

CHAPTER 8
Parameter Estimation in Plant
Growth Models
P
lant growth models or crop models are generally deterministic and can be de-
scribed in a state-space form. One can easily get their stochastic counterparts by
introducing modelling and measurement noises. Such a statistical framework allows a
joint estimation of parameters and hidden states. However, some diﬃculties arise in
the implementation, not only from the uneven and irregular measurement data, but
also from sudden or unusual climate changes that occasionally induce skewness, which
is diﬃcult to account for in models.
To compare the performances of diﬀerent estimation methods in terms of accuracy
for point estimation and appropriateness for uncertainty assessment, the LNAS model
presented in Chapter 2 is used. In this chapter, the tests are organized in two parts.
For the ﬁrst part, only simulated datasets are tested. The performance of the Bayesian
methods presented in Chapter 4 are investigated based on their estimation of the model
functional parameters. Subsequently, the iterative approaches proposed in Chapter
5 are implemented and compared, followed by the implementation of a conditional
version of the iterative approach which allows noise parameter estimation.
In the
second part, all the methods aforementioned are applied to real experimental datasets
for an evaluation of their estimation quality of both the functional and the noise
parameters. The results are ﬁnally discussed together with some method selection
strategies. Note that all the parallel computation and simulations presented in this
chapter were carried out with the mesocenter of Ecole Centrale Paris with up to 10
cores.
123

124
8.1. STUDY CASE DESCRIPTION
8.1
Study case description
With the purpose of testing the performances of the proposed algorithms, we ﬁrst
consider the virtual experimental datasets obtained by performing simulations based on
the true experimental conditions of one experiment conducted by the French institute
for sugar beet research (ITB, Paris) in 2010 (see Baey et al. (2012) for a detailed
description of the experimental protocol). Here, we present the results of simulations
in two diﬀerent scenarios :
(i) the full dataset is observed, that is, at each day from day 1 to day 160, both the
green leaf biomass Qg and the root compartment biomass Qr are measured, which
result in a full observation vector of size 2 × 160,
(ii) only a restricted dataset is available, for which Qg and Qr are measured at 14 dates
which correspond exactly to the following 14 dates of measurement O2010 in the 2010
experiment (in days after sowing)
O2010 = {54, 68, 76, 83, 90, 98, 104, 110, 118, 125, 132, 139, 145, 160} .
The restricted observation vector is thus of size 2 × 14. In this way, we can assess the
consequences of missing information in parameter estimation.
8.1.1
State space model representation
The LNAS model is therefore reformulated in the form of a state-space model, also
known as Hidden Markov Model (Rabiner, 1989):



X(t + 1) = Φt(X(t), η(t); Θ)
Y (t) = Rt(X(t), ξ(t); Θ),
(8.1)
where X(t) = (X1(t), X2(t), X3(t)) = (Qf(t), γ(t), Qr(t)), {η(t)}t≥1 and {ξ(t)}n≥1 are
appropriately chosen sequences of random vectors.
Note that X(0) is determined
by a ﬁrst allocation of the seed biomass between the root and leaf compartments
(corresponding to germination). The parameter vector of our model is denoted by Θ
and includes six functional parameters {µa, λ, µγ, σ2
γ, γ0, γf} chosen according to the
sensitivity analysis (details of which can be found in Section 6.1), and eventually some
noise parameters (error variances) {σ2
γγ, σ2
q, σ2
g, σ2
r}. However, according to the DIC
for model selection (details of which can be found in Section 6.2), when the noise
parameters are ﬁxed, the best model is obtained by estimating only three functional
parameters {µa, µγ, γ0}. This conﬁguration is therefore adopted for the simulation case
study.
In the following lemma we explicit the state equation and the observation equation
corresponding to our model.
Lemma 8.1.1 The model given by Equations (2.1)-(2.7) can be described as a state
space model (also known as hidden Markov model). The state equation is given by the

CHAPTER 8. PARAMETER ESTIMATION APPLICATIONS
125
following system of equations :















X1(t + 1) = X1(t) + X2(t) · F t
Q(X1(t); Θ)(1 + ηQ(t))
X2(t + 1) = Γt(Θ)(1 + ηγ(t))
X3(t + 1) = X3(t) + 1 −X2(t)
X2(t)
· F t
Q(X1(t); Θ)(1 + ηQ(t)),
(8.2)
where {ηQ(t)}t≥1 and {ηγ(t)}t≥1 are mutually independent sequences of independent
zero-centered Gaussian random vectors with variance σ2
Q and σ2
γγ respectively.
The observation equation is given by :
Y (t) = Rt(X(t), ξ(t)) =
 F t
g(X1(t); Θ)
X3(t)

·
 (1 + ξg(t))
(1 + ξr(t))

,
(8.3)
where {ξg(t)}t≥1 and {ξr(t)}t≥1 are i.i.d. sequences of centered Gaussian random vari-
ables with variances σ2
g for ξg(t) and σ2
r for ξr(t), and assumed to be independent from
{ηQ(t)}t≥1 and {ηγ(t)}t≥1.
Proof
X(t) is a Markov process.
First, we prove that the observation vector can be de-
termined by (X1(t), X2(t), X3(t)) = (Qf(t), γ(t), Qr(t)), Θ and the noise vector ξ(t).
According to the LNAS model,
Qr(t + 1) = F t
r(Qr(t), Qf(t + 1), γ(t); Θ)
= Qr(t) + (1 −γ(t)) · Q(t)
= Qr(t) + 1 −γ(t)
γ(t)
(Qf(t + 1) −Qf(t)),
(8.4)
and
Qg(t) = F t
g(Qf(t); Θ) = Qf(t) −Qs(t),
where
Qs(t) = Gs(τ(t) −τsen)Qf(t),
in which Gs(τ(t)−τsen) is determined by the functional parameters µs and σs, which are
related to the senescence process and can be estimated only based on the senescent leaf
mass. These two parameters are thus ﬁxed in our study. Consequently, the observation
vector Y (t) = (Qg(t), Qr(t)) depends only on X(t), Θ and the noise vector ξ(t).
Then, we prove that in the evolution equation, X(t + 1) depends only on X(t), Θ and
the noise vector η(t). Since
Qf(t + 1) = Qf(t) + γ(t) · Q(t),
Q(t) = F t
Q(Qf(t); Θ) · (1 + ηQ(t))
=
 µa · PAR(t)
 1 −e−λQg(t)
· (1 + ηQ(t)),

126
8.1. STUDY CASE DESCRIPTION
and
γ(t) = Γ(t) · (1 + ηγ(t))
= (γ0 + (γf −γ0) · Ga(τ(t))) · (1 + ηγ(t)),
if we denote X(t) = (γ(t), Qf(t), Qr(t)), we can obtain the transition function :
p (X(t + 1)|X(t)) = p ((γ(t + 1), Qf(t + 1), Qr(t + 1))|(γ(t), Qf(t), Qr(t)))
= p(γ(t + 1))p(Qf(t + 1)|γ(t), Qf(t))δQr(t+1),φ(Qf(t+1),γ(t),Qf(t),Qr(t)),
(8.5)
where the ﬁrst two components have a density (w.r.t. the 2-dimensional Lebesque
measure) and the third component, a Dirac delta function, results from a deterministic
move from the current state X(t) and Qf(t+1) according to Equation (8.4). p(γ(t+1))
and p(Qf(t+1)|γ(t), Qf(t)) are densities of normal distributions which can be described
as follows:
Qf(t + 1) ∼N

Qf(t) + γ(t)F t
Q(Qf(t); Θ),
γ2(t)F t
Q
2(Qf(t); Θ)σ2
Q

,
(8.6)
γ(t) ∼N

Γt(Θ),
Γt(Θ)
2σ2
γγ

.
(8.7)
Hence, X(t + 1) depends only on X(t), Θ and the noise vector η(t).
2
N.B.
- It is important to note that since Qr(t+1) is obtained from a deterministic function of
Qf(t + 1), γ(t), Qf(t) and Qr(t), the support of the transition density is in R2 instead
of R3.
- We point out that for the state variables representing biomasses, we are under the
positivity assumptions which could theoretically be violated by the normal distribu-
tions. Although in practice, the probability of obtaining γ(t) > 1 or a negative value
for the biomasses is very small, Equation (8.5) remains an approximation. Note that
the adaptation of the formulation of the state space model with truncated normal dis-
tributions or log-normal distributions would be straightforward, and so would be the
adaptation in the implementation section.
8.1.2
Selection of priors
In this thesis, from an application point of view, priors of the considered plant
growth models are often chosen according to recommended values from literature. Even
in the tests with simulated datasets, we opt for truncated Gaussian priors centered
on the recommended values with relatively large variances.
However, in the case
that no recommended values are available, either a more dispersed prior or a uniform
one is used. In the case when an important number of data are available, the prior
eﬀect is supposed to fade out. To accelerate the convergence, the starting point(s)
of the chain(s) for MCMC-based methods can be determined with the help of a ﬁrst
calibration of the model performed with a frequentist method, such as the Generalized

CHAPTER 8. PARAMETER ESTIMATION APPLICATIONS
127
Least Squares Estimator (Courn`ede et al., 2011), for this method is computationally
low cost and provides an estimate close to the MLE.
8.2
Implementation of MCMC-based methods
In this section, we apply three MCMC-based methods: Adapted Metropolis-within-
Gibbs, Diﬀerential Evolution Adaptive Metropolis and Interacting parallel MCMC to
the LNAS model. They represent respectively the three strategies of MCMC-based
methods: “one long run”, “some median runs” and “many short runs”.
In the ﬁrst place, we detail the implementation process of these methods, including
the formulation of the full conditionals, the initialization and the convergence criterion.
Then, their estimation results based on simulated datasets are given and discussed
according to their conﬁguration features. Accordingly, some implementation issues are
discussed.
8.2.1
Implementation descriptions
Formulation
Let π(Θ) = π(µa, µγ, γ0) be the joint prior distribution of the LNAS model param-
eters. First, we consider the case that the noise parameters of the model are known.
Given the fact that π(Θ|y1:tmax) is analytically intractable, the hidden state vari-
ables are introduced to provide an analytical expression, and consequently make the
numerical implementation easier. A joint estimation of both unknown parameters and
hidden states is thus required. Given the target p(Θ, x1:tmax|y1:tmax), the joint updates’
scheme derived from the Gibbs sampling can be described as follows (Capp´e et al.,
2005):
– Update Θ ∼π(θ|x1:tmax, y1:tmax).
– Update X1:tmax ∼π(x1:tmax|Θ, y1:tmax).
However, because of the poor mixing between Θ and X1:tmax (as described in Section
4.1.4), we opt for a joint update for Θ and x1:tmax :
– Update {Θ, X1:tmax} ∼π(θ, x1:tmax|y1:tmax).
In our application, since the observation vector Y (t) = (Qg(t), Qr(t)) can be expressed
as a function of X(t) = (Qf(t), γ(t), Qr(t)), the latter are chosen as the hidden state
variables in the implementation of the three MCMC-based methods. We recall that
among the three hidden state variables, the value of Qr(t) is obtained in a deterministic
fashion based on Qr(t −1), Qf(t −1), Qf(t) and γ(t −1) (see Lemma 8.1.1 for details).
Therefore, based on Equations (8.7) and (8.6), the full likelihood of the parameter
vector Θ and the hidden state variable x1:n given the observation y1:n can be described
as :

128
8.2. IMPLEMENTATION OF MCMC-BASED METHODS
L(Θ, x1:n|y1:n) ∝p(x1:n|Θ)p(y1:n|Θ, x1:n)
∝
n−1
Y
t=0
p(X(t + 1)|X(t), Θ) ·
n−1
Y
t=0
p(Y (t + 1)|X(t + 1), Θ)
∝
n−1
Y
t=0
1
σQγ(t)F t
Q(Qf(t); Θ) · exp{−
 Qf(t + 1) −Qf(t) −γ(t)F t
Q(Qf(t); Θ)
2
2
 σQγ(t)F t
Q(Qf(t); Θ)
2
}
n
Y
t=1
1
σγγΓt(Θ) · exp{−(γ(t) −Γt(Θ))2
2(σγγΓt(Θ))2 } ·
n−1
Y
t=0
δQr(t+1),φ(Qf(t+1),γ(t),Qf(t),Qr(t))
n−1
Y
t=0
1
σgF t+1
g
(Qf(t + 1); Θ) · exp{−(F t+1
g
(Qf(t + 1); Θ) −Y exp
g
(t + 1))2
2(σgF t+1
Q (Qf(t + 1); Θ))2
}
n−1
Y
t=0
1
σrF t
r(Qr(t), Qf(t + 1), γ(t); Θ)
· exp{−(F t
r(Qr(t), Qf(t + 1), γ(t); Θ) −Y exp
r
(t + 1))2
2(σgF t
r(Qr(t), Qf(t + 1), γ(t); Θ))2
}.
Note that the term Qn−1
t=0 δQr(t+1),φ(Qf(t+1),γ(t),Qf(t),Qr(t)) represents the fact that Qr(t)
is deduced in a deterministic fashion.
The posterior density of the parameter vector Θ can thus be expressed as :
π(Θ, x1:n|y1:n) ∝L(Θ, x1:n|y1:n) · πΘ(Θ)
∝L(Θ, x1:n|y1:n) · πµa(µa)πµγ(µγ)πγ0(γ0),
where πΘ(Θ) denotes the density of the prior distribution for Θ.
Truncated normal prior distributions are assumed for the parameters (µa, µγ, γ0) :
µa ∼N(mµa, σ2
µa)IR+,
µγ ∼N(mµγ, σ2
µγ)IR+,
γ0 ∼N(mγ0, σ2
γ0)I(0,1).
If we denote Φ(·) the cumulative distribution function of the standard normal distri-
bution :
Φ(x) =
Z x
−∞
1
√
2π exp{−t2
2 }dt,
then 1 −Φ(a) represents the normalizing factor in the probability density function of
a truncated normal distribution, with support in [a, +∞).
As a result, the posterior distribution in the general implementation of a MCMC-based

CHAPTER 8. PARAMETER ESTIMATION APPLICATIONS
129
method should have the following form :
π(Θ, x1:n|y1:n) ∝
n−1
Y
t=0
1
σQγ(t)F t
Q(Qf(t); Θ)
· exp{−
 Qf(t + 1) −Qf(t) −γ(t)F t
Q(Qf(t); Θ)
2
2
 σQγ(t)F t
Q(Qf(t); Θ)
2
}
n
Y
t=1
1
σγγΓt(Θ) · exp{−(γ(t) −Γt(Θ))2
2(σγγΓt(Θ))2 } ·
n−1
Y
t=0
δQr(t+1),φ(Qf(t+1),γ(t),Qf(t),Qr(t))
n−1
Y
t=0
1
σgF t+1
g
(Qf(t + 1); Θ) · exp{−(F t+1
g
(Qf(t + 1); Θ) −Y exp
g
(t + 1))2
2(σgF t+1
Q (Qf(t + 1); Θ))2
}
n−1
Y
t=0
1
σrF t
r(Qr(t), Qf(t + 1), γ(t); Θ)
· exp{−(F t
r(Qr(t), Qf(t + 1), γ(t); Θ) −Y exp
r
(t + 1))2
2(σgF t
r(Qr(t), Qf(t + 1), γ(t); Θ))2
}
·
1
σµaσµγσγ0
· exp{−(µa −mµa)2
2σ2
µa
−(µγ −mµγ)2
2σ2
µγ
−(γ0 −mγ0)2
2σ2
γ0
}
·

1 −Φ(−mµa
σµa
)
−1 
1 −Φ(−mµγ
σµγ
)
−1
·

Φ(1 −mγ0
σγ0
) −Φ(−mγ0
σγ0
)
−1
·I(µa > 0) · I(µγ > 0) · I(γ0 ∈(0, 1)).
(8.8)
One important issue is that due to the complicated structure, it is almost impossible
to sample directly from the posterior distribution.
Thus, the Metropolis-Hastings
algorithm is implemented.
In the computation of the acceptance ratio, the three
normalizing factors 1−Φ(·) remain constant and as a result can be cancelled. According
to the algorithm given in Section 4.1.4, we regard {Θ′, x′
1:n} as a joint proposal, thus
the acceptance ratio can be expressed as (details can be found in Equation (4.10)):
α({Θ, x1:n}, {Θ′, x′
1:n})
= min

1, p(y1:n|Θ′, x′
1:n)p(x′
1:n|Θ′)π(Θ′)
p(y1:n|Θ, x1:n)p(x1:n|Θ)π(Θ)
q(Θ|Θ′)q(x1:n|Θ)
q(Θ′|Θ)q(x′
1:n|Θ′)

.
(8.9)
Considering the strong correlation between Θ and x1:n, if we choose q(x′
1:n|Θ′) =
p(x′
1:n|Θ′), then Equation (8.9) can be simpliﬁed :
α({Θ, x1:n}, {Θ′, x′
1:n})
= min

1, p(y1:n|Θ′, x′
1:n)π(Θ′)
p(y1:n|Θ, x1:n)π(Θ)
q(Θ|Θ′)
q(Θ′|Θ)

.
(8.10)

130
8.2. IMPLEMENTATION OF MCMC-BASED METHODS
Ideally, the random walk proposal distribution for Θ should be truncated, therefore to
obtain the acceptance ratio it requires to calculate:
q(Θ|Θ′)
q(Θ′|Θ) =
1
σRW
√
2π exp

−(Θ−Θ′)2
2σ2
RW

1 −Φ

−Θ′
σRW

·


1
σRW
√
2π exp

−(Θ′−Θ)2
2σ2
RW

1 −Φ

−Θ
σRW



−1
=
1 −Φ

−Θ
σRW

1 −Φ

−Θ′
σRW
,
(8.11)
where σ2
RW denotes the variance for the proposal distribution of the random walk. How-
ever, for the sake of computational eﬃciency, we may also consider the non-truncated
symmetric normal random walk distribution, thus q(Θ|Θ′)
q(Θ′|Θ) =1. In this case, the posi-
tivity of Θ is still ensured thanks to the prior distribution, for negative candidate will
obtain 0 as acceptance probability.
Let ˜Qg(t) denote the estimate of Qg(t) which can be obtained by a deterministic
function of the estimates of Qf(t), and let ˜Qr(t) denote the estimate of Qr(t), to
compute the acceptance ratio, we need to calculate :
p(y1:n|Θ, x1:n) · π(Θ)
∝
n−1
Y
t=0
p(Y (t + 1)|X(t + 1), Θ) · πµa(µa)πµγ(µγ)πγ0(γ0)
∝
n
Y
t=1
1
σg ˜Qg(t)
· exp
(
−( ˜Qg(t) −Y exp
g
(t))2
2(σg ˜Qg(t))2
)
n
Y
t=1
1
σr ˜Qr(t)
· exp
(
−( ˜Qr(t) −Y exp
r
(t))2
2(σr ˜Qg(t))2
)
·
1
σµaσµγσγ0
· exp{−(µa −mµa)2
2σ2
µa
−(µγ −mµγ)2
2σ2
µγ
−(γ0 −mγ0)2
2σ2
γ0
}
· I(µa > 0) · I(µγ > 0) · I(γ0 ∈(0, 1)),
(8.12)
with Y exp
r
(t) and Y exp
g
(t) the observation data for Qg and Qr respectively at time t.
In the following, we detail in the ﬁrst place the implementation of the one chain
Adapted Metropolis-within-Gibbs algorithm.
Initialization of the algorithms
The initialization of the MCMC based algorithms can be carried out as follows :
– Deﬁne prior distributions for each parameter of Θ: p0(·) with the expectation
µp0 (normal distributions).
– Set Θ(1:d)
0
. Simulate one value for each parameter from the prior distribution

CHAPTER 8. PARAMETER ESTIMATION APPLICATIONS
131
while verifying that they are all positive: Θ ∼p0(·). The noise parameters are
ﬁxed, and the hidden state variables x(0)
0
are initialized to 0.
– Choose initial values for µ0, Σ0 and λ0 for the adaptive scheme. In our applica-
tion, we set µ0 = Θ(1:d)
0
, Σ0 = (2.382/d)(µ0 −µp0)(µ0 −µp0)T and λ0 = 1 if the
global scaling is used.
Convergence criteria
The convergence criteria for the one chain Adapted Metropolis-within-Gibbs
algorithm are detailed in Section 4.1.5, putting thresholds on both the relative diﬀer-
ence between the overlapping batch means and the precision (i.e. the width of the
conﬁdence intervals) of the mean estimates determined by the estimated Monte Carlo
errors. In our implementation, 4 batches of length 3000 with overlapped length 1000
are used for the convergence diagnostic and unﬁxed (increasing) batch length is used
to compute the precision of the estimates.
As for the parallel chains algorithm DREAM, the Gelman-Rubin criterion is used.
A threshold is deﬁned for the scale parameter
p
ˆR, in which ˆR is the estimated ratio
of the current estimate of variance to the within-chain variance corrected by a factor
accounting for the extra variance considered from the Student’s t distribution. In our
implementation, 1.0001 is chosen. More details about the Gelman-Rubin criterion can
be found in Section 4.2.3.
Finally, for the Interacting parallel MCMC, a similar stopping criterion as the
convergence diagnostic based on mean estimates for one chain Metropolis-within-Gibbs
algorithm is employed, except the mean estimates are computed from the posterior
distribution which consists of the samples from the last iteration of all the chains.
8.2.2
Adapted Metropolis-within-Gibbs
The one chain Adapted Metropolis-within-Gibbs (AMwG) algorithm represents
the “one long run” strategy in our implementation. In this section, some tests are
conducted to explore various conﬁgurations and to investigate the robustness of this
method.
List of the tests for the AMwG algorithm :
I
Decomposition of variance
II
Latent variable estimation
III
Multivariate Vs. componentwise proposals
IV
Number of iterations and estimation precision
V
Proposal scaling eﬀect on the convergence
VI
Impact of priors and initial values
VII
Normal proposal Vs. Student proposals

132
8.2. IMPLEMENTATION OF MCMC-BASED METHODS
General settings :
Here we provide the standard conﬁguration for all the tests if no contradictory
details are given in the setting descriptions.
The modelling noise parameters and
the observation noise parameters are ﬁxed to 0.02 and 0.1 respectively. Multivariate
proposals are used with global scaling. Chains with the length of 350 000 are considered
(if the length is ﬁxed), for this length usually ensures the convergence in our context.
I
Decomposition of variance
The aim of this test is to evaluate the stability of the proposed AMwG algorithm, both
in terms of the mean estimates and the variance estimates. If the algorithm is well
implemented, then it should respect the law of total variance :
V(Θ) = V(E(Θ|Y )) + E(V(Θ|Y )).
Settings :
To achieve this purpose, 600 parameter sets are generated from a given distribu-
tion p0(·), the corresponding observation datasets are as well simulated. The prior
distribution used for these tests is the same as the one used to generate the datasets :
∀i ∈1, . . . , 600, Θ∗
i ∼p0(·) ⇒{Yi}i=1,...,600
p0(·)
−→{˜Θi}i=1,...,600
where ˜Θi = ˆE(Θ|Yi) and the approximation ˆE of the expectation E(Θ|Yi) is performed
with the ergodic mean of the samples generated by the AMwG algorithm for each
dataset Yi.
Observations and remarks :
Noise 0.02
Prior
Estimation
Variance decomposition
µ∗
0
σ2
0
∗
µ0
σ2
0
E(E(Θ|Y ))
V(E(Θ|Y ))
E(V(Θ|Y ))
V(E(Θ|Y ))+E(V(Θ|Y ))
µa
3.595
0.0104
3.600
0.0100
3.597
0.0069
0.0035
0.0104
γ0
0.7519
0.0060
0.7500
0.0064
0.7513
0.0058
0.0003
0.0061
µγ
599.92
401.78
600.00
400.00
599.92
99.42
303.87
403.29
Noise 0.05
Prior
Estimation
Variance decomposition
µ∗
0
σ2
0
∗
µ0
σ2
0
E(E(Θ|Y ))
V(E(Θ|Y ))
E(V(Θ|Y ))
V(E(Θ|Y ))+E(V(Θ|Y ))
µa
3.596
0.0102
3.600
0.0100
3.599
0.0067
0.0038
0.0105
γ0
0.7520
0.0062
0.7500
0.0064
0.7518
0.0058
0.0004
0.0062
µγ
599.81
400.32
600.00
400.00
599.96
69.31
333.92
403.23
Table 8.1: Estimation and uncertainty assessment provided by one chain MCMC based
on 600 simulated datasets (14 dates) generated with the parameter vectors simulated
from the same prior distribution. Each test contains 350 000 simulations. Two mod-
elling noise levels are tested. µ∗
0 and σ2
0
∗denote the sample mean and variance.
– The conditional expectation formula and the variance decomposition are veriﬁed
which is a good indicator of the proper assessment of the uncertainty related to
the estimations (bias and variance of the target distribution).

CHAPTER 8. PARAMETER ESTIMATION APPLICATIONS
133
– With diﬀerent modelling noise levels, we may infer from the results given by
Table 8.1 that the noise inﬂuences diﬀerently the within chain (intra-chain) vari-
ation E(V(Θ|Y )) and between chain variation V(E(Θ|Y )) as estimated by the
algorithm. The more the modelling noise is important, the more the intra-chain
variance increases, and the more the between chain variance decreases.
– Based on the sensitivity analysis (see Section 9.2.2), the estimates of the most
sensitive parameter γ0 appear to be less inﬂuenced by the increase of the mod-
elling noises than µa and µγ.
II
Latent variable estimation
The objective is to study the impact of the lack of available data on the estimation of
the hidden state variables (also known as latent variables).
Settings :
The same simulated dataset is used for the estimation of the hidden state variables
Qr and Qg (which can be inferred from the estimation of Qf with a deterministic
function) with the setting of 14 dates (restricted dataset) and 160 dates (full dataset).
Observations and remarks :
– According to Figure 8.1, the mean estimates remain quite accurate in both
cases, which proves the robustness of the proposed algorithm.
– The lack of data brings not only larger estimation errors, but most importantly
more uncertainty associated with the estimation of the hidden states. The esti-
mated 95% conﬁdence intervals are signiﬁcantly larger in the case of the scarce
dataset compared to the full dataset.
GGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGG
GG
GGGGGG
GGG
G
G
G
G
G
G
G
G
GG
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
GGG
G
G
G
G
G
G
G
GG
G
GGG
G
G
G
G
G
G
G
G
G
GG
G
G
GG
G
G
G
G
G
GG
G
G
G
G
G
G
GGG
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
0
50
100
150
0
100
200
300
400
500
Time (day)
Biomass Qg (g)
GGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGG
GG
GGGGGG
GGG
G
G
G
G
G
G
G
G
GG
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
GGG
G
G
G
G
G
G
G
GG
G
GGG
G
G
G
G
G
G
G
G
G
GG
G
G
GG
G
G
G
G
G
GG
G
G
G
G
G
G
GGG
G
G
G
GG
G
G
G
G
G
G
G
G
G
G
G
G
Noised observations
Real hidden state values
Averaged estimations
Confidence interval 95%
(a) Qg (full dataset)
GGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGG
GGGG
GGGG
GGG
G
G
G
GGGGG
G
GG
G
G
GG
G
GG
G
G
G
G
GG
GGG
G
G
G
G
G
G
G
GGGG
G
GG
G
G
G
G
G
GG
G
G
G
GG
G
G
G
G
GG
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
0
50
100
150
0
500
1000
1500
2000
2500
Time (day)
Biomass Qr (g)
GGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGG
GGGG
GGGG
GGG
G
G
G
GGGGG
G
GG
G
G
GG
G
GG
G
G
G
G
GG
GGG
G
G
G
G
G
G
G
GGGG
G
GG
G
G
G
G
G
GG
G
G
G
GG
G
G
G
G
GG
G
G
G
G
G
G
G
GG
G
G
G
G
G
G
G
Noised observations
Real hidden state values
Averaged estimations
Confidence interval 95%
(b) Qr (full dataset)

134
8.2. IMPLEMENTATION OF MCMC-BASED METHODS
GGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGG
GG
GGGG
G
G
G
G
G
G
GG
GGGG
GGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGG
0
50
100
150
0
100
200
300
400
500
Time (day)
Biomass Qg (g)
G
G
G
G
G
G G
G
G
G
G
G
G
G
G
Noised observations
Real hidden state values
Averaged estimations
Confidence interval 95%
(c) Qg (restricted dataset)
GGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGG
0
50
100
150
0
500
1000
1500
2000
2500
Time (day)
Biomass Qr (g)
G
G
G
G
G
G G
G
G
G
G
G
G
G
G
Noised observations
Real hidden state values
Averaged estimations
Confidence interval 95%
(d) Qr (restricted dataset)
Figure 8.1: Hidden states estimation given by one chain MCMC Adapted Metropolis-
within-Gibbs algorithm based on a full dataset (160 dates) and on its restricted form
(14 dates) with 350 000 iterations. Both averaged estimations and the associated 95%
conﬁdence intervals are provided. Left panel: green leaf biomass Qg evolution. Right
panel: root biomass Qr evolution.
III
Multivariate Vs. componentwise proposals
The goal of this test is to compare the Monte Carlo error associated with each one of the
proposed updating strategies: to update all the parameters together as a block (Multi-
variate, denoted M) or to update them separately (Univariate, denoted N) introduces
bias in the estimation under both restricted dataset and full dataset scenarios.
Settings :
The tests are carried out with the same dataset, in both its complete form (160
dates) and its restricted form (14 dates). 200 repetitions of the same test are performed
in each case to evaluate the Monte Carlo error. Two priors are considered.
p1(·)+N
−→
{˜ΘN 1
i
}i=1,...,200
p1(·)+M
−→
{˜ΘM1
j
}j=1,...,200
Θ∗⇒Y
p2(·)+N
−→
{˜ΘN 2
k }k=1,...,200
p2(·)+M
−→
{˜ΘM2
l
}l=1,...,200

CHAPTER 8. PARAMETER ESTIMATION APPLICATIONS
135
Observations and remarks :
Full dataset
Prior 1
Componentwise proposals
Multivariate proposals
Real value
µ0
σ2
0
E(E(Θ|Y ))
V(E(Θ|Y ))
E(V(Θ|Y ))
V(V(Θ|Y ))
E(E(Θ|Y ))
V(E(Θ|Y ))
E(V(Θ|Y ))
V(V(Θ|Y ))
µa
3.560
3.40
0.20
3.606
6.45e-5
0.0114
1.40e-6
3.602
2.69e-5
0.0199
7.64e-7
γ0
0.625
0.90
0.10
0.630
8.07e-6
0.00076
1.18e-8
0.626
1.02e-6
0.00094
1.70e-9
µγ
550.00
650.00
40.00
531.51
22.234
2551.90
7.92e4
542.37
3.313
2708.11
5.67e4
Prior 2
µ0
σ2
0
E(E(Θ|Y ))
V(E(Θ|Y ))
E(V(Θ|Y ))
V(V(Θ|Y ))
E(E(Θ|Y ))
V(E(Θ|Y ))
E(V(Θ|Y ))
V(V(Θ|Y ))
µa
3.560
3.80
0.40
3.619
6.42e-5
0.0118
1.60e-6
3.611
1.78e-5
0.0207
1.35e-6
γ0
0.625
0.40
0.20
0.633
9.18e-6
0.00084
1.14e-8
0.628
5.80e-7
0.00096
1.84e-9
µγ
550.00
350.00
60.00
521.72
10.58
2674.84
6.51e4
534.04
2.58
2870.53
1.19e4
Restricted dataset
Prior 1
Componentwise proposals
Multivariate proposals
Real value
µ0
σ2
0
E(E(Θ|Y ))
V(E(Θ|Y ))
E(V(Θ|Y ))
V(V(Θ|Y ))
E(E(Θ|Y ))
V(E(Θ|Y ))
E(V(Θ|Y ))
V(V(Θ|Y ))
µa
3.560
3.40
0.20
3.449
1.39e-4
0.0150
4.45e-6
3.456
8.23e-6
0.0199
2.47e-7
γ0
0.625
0.90
0.10
0.659
1.30e-5
0.00117
2.60e-8
0.657
3.89e-7
0.00153
1.42e-9
µγ
550.00
650.0
40.00
555.43
12.68
1909.57
2.22e4
558.83
0.99
2486.97
3.74e3
Prior 2
µ0
σ2
0
E(E(Θ|Y ))
V(E(Θ|Y ))
E(V(Θ|Y ))
V(V(Θ|Y ))
E(E(Θ|Y ))
V(E(Θ|Y ))
E(V(Θ|Y ))
V(V(Θ|Y ))
µa
3.560
3.80
0.40
3.474
7.10e-5
0.0190
2.42e-6
3.480
8.23e-6
0.0257
5.29e-7
γ0
0.625
0.40
0.20
0.698
1.44e-5
0.00208
6.35e-8
0.691
7.78e-7
0.00257
8.85e-9
µγ
550.00
350.0
60.00
468.73
11.50
2454.50
4.19e4
473.58
1.13
3016.41
6.60e3
Table 8.2: Estimation and uncertainty assessment provided by one chain MCMC based
on one simulated dataset with two settings (14 dates and 160 dates). 200 repetitions
are performed, with ﬁxed noise parameters. The given estimations are based on a
total of 200 tests, with a maximum number of 240 000 iterations for each, taking into
account a burn-in period of 40 000 iterations for the restricted dataset and 10 000 for
the full dataset. Two prior distributions are used.
– In Table 8.2, notice that the componentwise proposal works almost as well as the
multivariate proposal in the case of three parameters for both the full dataset
and the scarce dataset. However, the use of the multivariate proposal results
in generally ﬂatter distributions (estimations of variance E(V(Θ|Y )) tend to be
larger compared to the componentwise approach) which suggests the existence of
an eﬀect when the covariance among the three parameters are taken into account.
– Both proposals provided similar averaged mean estimates E(E(Θ|Y )), except
perhaps for the parameter µγ which has slightly diﬀerent estimates from time to
time given by the two approaches. Note that µγ is the least inﬂuential parameter
among the three that we estimate.
– Larger prior variances generally lead to larger variance estimations for the target
distribution, since the number of data is limited.
– Regarding the Monte Carlo error, componentwise proposals result in larger
variability between the individual tests, for both the mean estimates and the

136
8.2. IMPLEMENTATION OF MCMC-BASED METHODS
variance estimates (V(E(Θ|Y )) and V(V(Θ|Y ))).
This is observed for the
diﬀerent priors that we tested.
– Since the multivariate proposal is much less time consuming (the computational
time was reduced by ≈62%), and it allows us to take into account the covariance
among parameters, it is preferred for the following tests.
IV
Number of iterations and estimation precision
The objective of this test is to identify the inﬂuence of the number of iterations on the
performance of the algorithm, especially on the precision of the estimates.
Settings :
Batch means and the variance of expected values of 100 independent runs are used
to estimate the Monte Carlo Error (MCE) based on the same restricted dataset. Six
conﬁgurations for the number of iterations are investigated.
The evolution of the
estimated MCE is studied with a long chain of 5 000 000 iterations.
Θ∗⇒Y ⇒{˜Θi}i=1,...,100
Observations and remarks :
– Figure 8.2 illustrates the decrease of the estimated Monte Carlo errors when the
number of iterations increases for a long run, which is in agreement with the CLT.
– Figure 8.3 manifests the evolution of the random walk standard deviation tuned
by the adaptive scheme.
The covariance matrix of the normal instrumental
distribution tends to stabilize with the iterations.
– The posterior distributions of the three parameters are given by Figure 8.4.
0e+00
2e+05
4e+05
6e+05
0.00
0.01
0.02
0.03
0.04
Iteration
Monte Carlo Error
(a) µa
0e+00
2e+05
4e+05
6e+05
0.000
0.005
0.010
0.015
Iteration
Monte Carlo Error
(b) γ0
0e+00
2e+05
4e+05
6e+05
0
2
4
6
8
10
12
14
Iteration
Monte Carlo Error
(c) µγ
Figure 8.2: Evolutions of the Monte Carlo errors computed by batch means based on
a simulated dataset (14 dates) with a long run of 5 000 000 iterations.

CHAPTER 8. PARAMETER ESTIMATION APPLICATIONS
137
(a) µa
(b) γ0
(c) µγ
Figure 8.3: Evolutions of the standard deviations of random walk steps for one test
based on a restricted dataset (14 dates).
(a) µa
(b) γ0
(c) µγ
Figure 8.4: Posterior distribution estimated by a long run of 10 000 000 iterations
based on the same simulated dataset (14 dates) and the same prior distribution.
350 000 (iter.)
200 000
100 000
Real value
E(E(Θ|Y ))
E(V(Θ|Y ))
V(E(Θ|Y ))
E(E(Θ|Y ))
E(V(Θ|Y ))
V(E(Θ|Y ))
E(E(Θ|Y ))
E(V(Θ|Y ))
V(E(Θ|Y ))
µa
3.746
3.7485
3.54e-3
2.48e-7
3.7487
3.47e-3
5.65e-7
3.7486
3.45e-3
9.90e-7
γ0
0.7525
0.7527
3.1e-4
2.44e-8
0.7527
3.1e-4
4.72e-8
0.7527
3.0e-4
8.19e-8
µγ
579.00
573.241
307.71
2.65e-2
573.25
305.58
4.24e-2
573.21
305.31
7.90e-2
Prior
50 000 (iter.)
30 000
10 000
µ0
σ2
0
E(E(Θ|Y ))
E(V(Θ|Y ))
V(E(Θ|Y ))
E(E(Θ|Y ))
E(V(Θ|Y ))
V(E(Θ|Y ))
E(E(Θ|Y ))
E(V(Θ|Y ))
V(E(Θ|Y ))
µa
3.6
0.01
3.7485
3.45e-3
1.91e-6
3.7485
3.44e-3
3.41e-6
3.7483
3.39e-3
9.79e-6
γ0
0.75
0.0064
0.7527
3.0e-4
1.68e-7
0.7538
3.0e-4
3.18e-7
0.7527
3.0e-4
9.13e-7
µγ
600.0
400.00
573.23
307.89
1.67e-1
573.27
305.03
2.98e-1
573.33
302.49
9.46e-1
Table 8.3: Evolution of estimations and uncertainty assessments provided by one chain
AMwG, with the increase of the number of iterations, based on the same simulated
dataset (14 dates).
For each conﬁguration, the mean estimates are based on 100
independent runs.
– According to Table 8.3, the averaged estimates (E(E(Θ|Y ))) are always
accurate when comparing the six conﬁgurations.
However, the estimated

138
8.2. IMPLEMENTATION OF MCMC-BASED METHODS
V(E(Θ|Y )) for the three parameters, which indicate the precision of the mean
estimates and can also be regarded as a way to evaluate the MCE, increase
quickly when the number of iterations decreases.
Therefore, a lower bound
of the number of iterations should be deﬁned if a certain precision level is desired.
– The variance estimates E(V(Θ|Y )) also begin to be less precise with the conﬁgu-
ration of 10 000 iterations. This test can be regarded as a preliminary test when
implementing a MCMC-based method, as it gives a vague idea of the behaviour
of the chains, especially to decide the threshold for the stopping criteria.
V
Proposal scaling eﬀect on the convergence
As mentioned in Section 4.1.1, it is possible to apply the global multivariate adaptive
scaling to improve the convergence of the algorithm. Here, we attempt to verify the
scaling eﬀect compared to the simple Adaptive Metropolis.
Settings:
This test is conducted with the same simulated restricted dataset by the two algo-
rithms, with global scaling and without global scaling.
Observations and remarks :
0
10000
20000
30000
40000
3.4
3.5
3.6
3.7
Iteration
Estimation
With scaling
Without scaling
Figure 8.5: Estimation with and without global scaling of the adaptive scale based on
the same simulated restricted dataset.
Figure 8.5 demonstrates that the scaled proposal has an impact at the beginning
of the chain, but for a long run, there is no signiﬁcant diﬀerence between the chains
run with and without scaling.

CHAPTER 8. PARAMETER ESTIMATION APPLICATIONS
139
VI
Impact of priors and initial values
As we know, the prior distribution plays an important role in Bayesian inference.
However, the prior eﬀect fades out with an increasing number of observations. In this
test, we try to identify the importance of the prior in the scenario with restricted
dataset.
Settings :
Three priors are used for the estimation based on a restricted dataset. No global
scaling is used.
The estimates are based on 100 repetitive long runs with a ﬁxed
number of iterations (350 000).
p1(·)
−→{˜Θ1
i }i=1,...,100
Θ∗⇒Y
p2(·)
−→{˜Θ2
j}j=1,...,100
p3(·)
−→{˜Θ3
k}k=1,...,100
Observations and remarks :
– Table 8.4 illustrates that the estimates resulting from diﬀerent priors are quite
diﬀerent, which indicates the lack of data to erase the prior information. This
result suggests that in the scenario with restrict dataset, the prior should be
chosen cautiously, for it has important inﬂuence on the posterior distribution.
Prior 1
Estimation
Monte Carlo error
Real value
µ0
σ2
0
E(E(Θ|Y ))
E(V(Θ|Y ))
p
V(E(Θ|Y ))
σBM
µa
3.746
3.60
0.01
3.748
0.0035
0.000498
0.000888
γ0
0.7525
0.750
0.0064
0.7527
0.00031
0.000156
0.000265
µγ
579.00
600
400
573.24
307.71
0.1627
0.2648
Prior 2
µ0
σ2
0
E(E(Θ|Y ))
E(V(Θ|Y ))
p
V(E(Θ|Y ))
σBM
µa
3.746
3.70
0.01
3.818
0.0036
0.000572
0.000954
γ0
0.7525
0.720
0.0064
0.7231
0.00026
0.000155
0.000260
µγ
579.00
650
400
614.91
315.91
0.1817
0.2890
Prior 3
µ0
σ2
0
E(E(Θ|Y ))
E(V(Θ|Y ))
p
V(E(Θ|Y ))
σBM
µa
3.746
3.752
0.0225
3.804
0.0050
0.000646
0.001013
γ0
0.7525
0.744
0.0100
0.7453
0.00042
0.000191
0.000296
µγ
579.00
590.695
625
562.94
430.93
0.1925
0.3023
Table 8.4: Estimation and uncertainty assessment provided by one chain MCMC based
on one simulated dataset (14 dates) with 100 repetitions. For each test, the length of
the chain is 350 000. Three prior distributions are used.
– It is likely that the batch means method over-estimates the Monte Carlo er-
rors, since they are more important than the estimations obtained with the 100
repetitions of the same test.

140
8.2. IMPLEMENTATION OF MCMC-BASED METHODS
0e+00
2e+05
4e+05
6e+05
3.66
3.68
3.70
3.72
3.74
3.76
3.78
Iteration
Estimation
(a) µa
0e+00
2e+05
4e+05
6e+05
0.71
0.72
0.73
0.74
0.75
0.76
0.77
0.78
Iteration
Estimation
(b) γ0
0e+00
2e+05
4e+05
6e+05
540
560
580
600
620
Iteration
Estimation
(c) µγ
Figure 8.6: Evolutions of the averaged estimations computed by batch means based
on the same simulated dataset (14 dates) and the same prior distribution, performed
for 5 independent chains departing from diﬀerent initial points.
– The estimated Monte Carlo errors are relatively small, which imply small algo-
rithmic errors when long chains are employed. Since the initial point of each
chain is drawn from the prior distribution, this result also indicates that the pos-
terior distribution obtained is independent of the departure point (Figure 8.6).
A long run could ensure a good performance of convergence to the invariant dis-
tribution independently of the departure point as long as they are drawn from
the same prior distribution.
VII
Normal proposal Vs. Student proposal
This test aims to investigate the impact of normal and Student proposals, since they
are both symmetric proposals but with diﬀerent types of distribution tails.
Settings :
Based on the same simulated full dataset, the AMwG algorithm is carried out with
both normal proposals for random walk and Student proposals for random walk, each
with 200 repetitions.
N(·)
−→{˜ΘN
i }i=1,...,200
Θ∗⇒Y
T (·)
−→{˜ΘT
j }j=1,...,200
Observations and remarks :
– As suggested by Table 8.5, both methods result in similar estimations. Nonethe-
less, Student distribution has heavier tails than the normal one, which implies
more tolerance. The posterior distribution given by the Student proposal results
in slightly larger variances, however the estimation of the target distribution
should not be inﬂuenced by the proposal distribution. Thus, it is possible that
some of the tests performed with the Student proposal have not converged, some
outlier samples may be consequently included.

CHAPTER 8. PARAMETER ESTIMATION APPLICATIONS
141
Prior
Student proposals
Real value
µ0
σ2
0
E(E(Θ|Y ))
V(E(Θ|Y ))
E(V(Θ|Y ))
V(V(Θ|Y ))
µa
3.560
3.80
0.40
3.613
1.01e-5
0.0216
1.64e-6
γ0
0.625
0.40
0.20
0.629
4.61e-7
0.00098
7.24e-9
µγ
550.00
350.00
60.00
534.39
2.41
3004.42
2.47e4
Prior
Normal proposals
Real value
µ0
σ2
0
E(E(Θ|Y ))
V(E(Θ|Y ))
E(V(Θ|Y ))
V(V(Θ|Y ))
µa
3.560
3.80
0.40
3.611
1.78e-5
0.0207
1.35e-6
γ0
0.625
0.40
0.20
0.628
5.80e-7
0.00096
1.84e-9
µγ
550.00
350.00
60.00
534.04
2.58
2870.53
1.19e4
Table 8.5: Estimation and uncertainty assessment provided by normal and Student
proposals based on one simulated dataset (160 dates) with 200 repetitions, with ﬁxed
noise parameters. The given estimations are based on a total of 200 tests, with a
maximum of 120 000 iterations for each, taking into account a burn-in period of 10
000 iterations.
– Note that the Student distribution is widely used to correct the estimation of
the variance for MCMC based methods. Although the risk of over-estimation of
the variance is not desirable with the objective of reducing uncertainties related
to the parameter estimates for future prediction use, the eﬀect of correcting the
variance estimator could be attractive for multiple chains algorithms, such as the
Interacting parallel MCMC, when the shrinkage (sample degeneracy) is present.
It is also used in the Gelman-Rubin criterion (Gelman, 1992).
8.2.3
Diﬀerential Evolution Adaptive Metropolis
The Diﬀerential Evolution Adaptive Metropolis (DREAM) approach uses the strat-
egy of“some median runs”. Therefore, the assumption has been made for this approach
that the target distribution of the M parallel chains is the product of the original target
distributions πM(·) (Vrugt et al., 2009a). Thanks to the MCMC’s scheme, a population
of estimates resulting from M chains move from one iteration to another conditionally
on the estimates of the previous iteration. As a result, the empirical moments can
be derived. In the case that parallel chains are engaged without communication, the
overall speed of convergence is limited by the convergence of each chain and the num-
ber of iterations to be discarded for each of them. The DREAM algorithm proposes
to hasten the convergence of individual chains by creating communications between
the chains. In the following, the performance and the features of this algorithm are
studied.
List of the tests for the DREAM algorithm :
I
Comparison of convergence property with one chain MCMC
II
Impact of the number of parallel chains
III
Comparison of the computational costs of diﬀerent conﬁgurations
IV
Discussion: Comparison of computational strategies

142
8.2. IMPLEMENTATION OF MCMC-BASED METHODS
General settings :
As for the previous tests with one chain AMwG, the modelling noise parameters and
the observation noise parameters are ﬁxed at 0.02 and 0.1 respectively. Multivariate
proposals are used without global scaling.
I
Comparison of convergence property with one chain MCMC
The objective is to investigate the convergence behaviour of this parallel chain
algorithm compared to the one chain AMwG algorithm.
Settings :
Given a restricted dataset, we monitor the evolution of the Gelman-Rubin scale
parameters as well as the corresponding evolution of the estimates. Then, 100 runs
are conducted based on the same dataset with the same total number of iterations to
compare the estimation quality of DREAM and one chain AMwG.
Θ∗⇒Y ⇒{˜Θi}i=1,...,100
Observations and remarks :
0
10000
20000
30000
40000
50000
1.00
1.05
1.10
1.15
Iteration
Gelman−Rubin
(a) µa
0
10000
20000
30000
40000
50000
1.00
1.05
1.10
1.15
Iteration
Gelman−Rubin
(b) γ0
0
10000
20000
30000
40000
50000
1.00
1.05
1.10
1.15
Iteration
Gelman−Rubin
(c) µγ
Figure 8.7: Evolutions of the Gelman-Rubin criterion of the DREAM algorithm based
on a restricted dataset (14 dates).
Prior
AMwG
DREAM
Theoretical value∗
Real value
µ0
σ2
0
E(E(Θ|Y ))
E(V(Θ|Y ))
E(E(Θ|Y ))
E(V(Θ|Y ))
˜µ∗
˜σ2
µa
3.746
3.6
0.01
3.748
0.0035
3.749
0.0024
3.7487
0.0035
γ0
0.7525
0.75
0.0064
0.7527
0.00031
0.7531
0.00021
0.7526
0.00031
µγ
579.00
600.0
400.00
573.24
307.71
572.79
211.07
573.21
307.89
Table 8.6: Estimation and uncertainty assessment provided by one chain MCMC and
DREAM based on the same simulated dataset (14 dates) with 100 repetitions. Each
test contains 360 000 simulations for both DREAM and one chain MCMC. ∗: The
theoretical values are provided by taking the average of three long runs of AMwG with
10 000 000 iterations.

CHAPTER 8. PARAMETER ESTIMATION APPLICATIONS
143
0e+00
2e+04
4e+04
6e+04
8e+04
1e+05
3.72
3.73
3.74
3.75
3.76
3.77
3.78
Iteration
Estimation
(a) µa
0e+00
2e+04
4e+04
6e+04
8e+04
1e+05
0.745
0.750
0.755
0.760
0.765
0.770
Iteration
Estimation
(b) γ0
0e+00
2e+04
4e+04
6e+04
8e+04
1e+05
565
570
575
580
Iteration
Estimation
(c) µγ
Figure 8.8: Evolutions of the estimates provided by the DREAM algorithm based on
a restricted dataset (14 dates).
Based on the evolution of the Gelman-Rubin diagnostic illustrated by Figure 8.7,
we notice that the scaling parameters converge very quickly, while it is not the case
for the evolution of the estimates as demonstrated by Figure 8.8. This result suggests
that the Gelman and Rubin criterion is probably too tolerant for small numbers of
chains.
Table 8.6 implies that the mean posterior variances are very likely to be underes-
timated when the recommended conﬁguration is used (Ter Braak and Vrugt, 2008),
in which the number of chains is 2d, with d the dimension of the target distribution.
Ter Braak (2006) showed that M = 2d or 3d worked well for unimodal posteriors,
but M = 10d to 20d were needed when multimodality or high correlation was present
in the target distribution. Therefore, more chains might improve the inference of the
posterior distribution.
II
Impact of the number of parallel chains
Following this idea, tests with more parallel chains are conducted to see their impacts
on the variance estimation. The performance of the Gelman-Rubin criterion is also
evaluated.
Settings :
With the same restricted dataset, 12 conﬁgurations with diﬀerent numbers of par-
allel chains are tested with each 50 independent runs.
1d
−→{˜Θ1d}i=1,...,50
Θ∗⇒Y
. . .
12d
−→{˜Θ12d}i=1,...,50
Observations and remarks :
In this test, conﬁgurations with more pooled parallel chains are adopted to estimate
the target distribution. According to Figure 8.9, the mean estimates appear to be quite
accurate when M ≥2d. However, the variance estimations are not stable for diﬀerent

144
8.2. IMPLEMENTATION OF MCMC-BASED METHODS
conﬁgurations. The variance estimations increase when more chains are involved, as
demonstrated by Table 8.8. This is probably due to the fact that the burn-in period is
diﬃcult to handle for all the chains in an independent way (Geyer, 1991). Therefore,
when the number of chains increases, more and more outliers could be included in the
ﬁnal pooled estimates which are used to construct the posterior distribution. In other
words, some individual chains may not have converged.
µa
γ0
µγ
˜µ∗
˜σ2∗
˜µ∗
˜σ2∗
˜µ∗
˜σ2∗
Theoretical∗
3.7487
3.47e-3
0.7526
3.06e-4
573.21
307.89
Nbr of chains
E(E(Θ|Y ))
E(V(Θ|Y ))
E(E(Θ|Y ))
E(V(Θ|Y ))
E(E(Θ|Y ))
E(V(Θ|Y ))
3 (1d)
3.757
8.02e-4
0.7401
7.77e-5
605.98
130.14
6 (2d)
3.748
2.47e-3
0.7543
2.24e-4
572.02
230.75
9 (3d)
3.750
3.50e-3
0.7533
3.07e-4
572.62
314.95
12 (4d)
3.750
3.84e-3
0.7536
3.38e-4
572.59
347.49
15 (5d)
3.750
4.10e-3
0.7534
3.57e-4
572.78
364.60
18 (6d)
3.749
4.23e-3
0.7536
3.64e-4
572.87
377.89
21 (7d)
3.750
4.42e-3
0.7535
3.83e-4
572.64
392.98
24 (8d)
3.750
4.47e-3
0.7534
3.88e-4
572.74
396.70
27 (9d)
3.750
4.54e-3
0.7536
3.95e-4
572.71
396.59
30 (10d)
3.750
4.54e-3
0.7536
3.97e-4
572.43
398.97
33 (11d)
3.749
4.53e-3
0.7536
3.96e-4
572.80
397.60
36 (12d)
3.750
4.55e-3
0.7535
3.98e-4
572.75
399.41
Table 8.7: Comparison of the estimations and uncertainty assessments resulting from
diﬀerent conﬁgurations of the DREAM algorithm based on the same simulated dataset
(14 dates) with 50 independent runs. ∗: The theoretical values are provided by taking
the average of three long runs of MCMC with 5 000 000 iterations.
(a) µa
(b) γ0

CHAPTER 8. PARAMETER ESTIMATION APPLICATIONS
145
(c) µγ
Figure 8.9: Evolution of the estimations with diﬀerent conﬁgurations of the DREAM
algorithm based on the same simulated dataset (14 dates) with 50 repetitions.
It is conﬁrmed by checking the intra-chain variances of each chain (Figure 8.10)
which are quite variable. It is possible that the jumps introduced between chains to
improve the convergence speed, could be too frequent and result in bias. The compo-
nents of the chains exhibit important dependencies which may damage the adaptive
scheme and dissimulate the fact of non-convergence. If a few chains have converged,
the overall behaviour of the within chain variance and between chain variance could
easily appear to be stable and thus claim the convergence too fast, especially when a
large number of chains are involved. Many parallel chains could artiﬁcially exhibit a
robust behaviour, for instance the mean estimates may appear to be stable while the
target distribution is not properly characterized.
Frequency
0.0030
0.0035
0.0040
0.0045
0.0050
0.0055
0.0060
0.0
0.1
0.2
0.3
0.4
(a) µa
Frequency
0.00030
0.00035
0.00040
0.00045
0.00050
0.00055
0.00
0.05
0.10
0.15
0.20
0.25
0.30
(b) γ0
Frequency
300
350
400
450
500
550
0.00
0.05
0.10
0.15
0.20
0.25
0.30
(c) µγ
Figure 8.10: Histograms of the intra-chain variance provided by the DREAM algorithm
conﬁgured with 24 parallel chains (8d) based on a restricted dataset (14 dates).

146
8.2. IMPLEMENTATION OF MCMC-BASED METHODS
Indeed, facing multimodality or high dimensional problems, one strategy that is
widely used concerns building a pool of samples resulting from multiple chains per-
formed in parallel. However, the quasi-ergodicity problem may frustrate this simple
idea. Our result suggests that when the lengths of the chains are limited, multiple
chains may not necessarily provide a better estimation of the target distribution than
the single chain, especially for nonlinear models and limited data. Most importantly,
it seems more diﬃcult to deﬁne a proper way to diagnose the convergence for multiple
parallel chains. As stated previously, our results imply that there is a strong possibil-
ity that the Gelman and Rubin criterion is too tolerant for small numbers of chains,
for example, in the case when M = 1d, both the mean estimates and the variance
estimates are inaccurate (Figure 8.9).
The Gelman and Rubin criterion puts emphasis on reducing bias in estimation by
using a shrink factor, which can be interpreted as follows : when the between-chain
variance is dominated by the pooled within-chain variance, it approaches to one, and
thus all the chains should have escaped the inﬂuence of their departure points (initial
values of the chains) and have visited the entire target distribution.
However, an
important feature of its implementation is that it strongly relies on the user ability to
ﬁnd an appropriate starting distribution which is over-dispersed. If a small number
of chains are involved, not only the dispersion of the departure points might not be
important enough, but it is also possible that the communications between chains
which are meant to accelerate the convergence speed, may result in an underestimation
of the variance between chains. As a result, the convergence is claimed much earlier
than it should be. In Ter Braak (2006), similar results were obtained, they showed
that the Gelman and Rubin criterion is too optimistic about the convergence. This
result suggests a reassessment of this diagnostic criterion.
0
1000
2000
3000
4000
5000
6000
3.72
3.73
3.74
3.75
3.76
3.77
3.78
Iteration
Estimation
6 chains (2d)
30 chains (10d)
(a) µa
0
1000
2000
3000
4000
5000
6000
0.740
0.745
0.750
0.755
0.760
0.765
Iteration
Estimation
6 chains (2d)
30 chains (10d)
(b) γ0
0
1000
2000
3000
4000
5000
6000
555
560
565
570
575
580
585
590
Iteration
Estimation
6 chains (2d)
30 chains (10d)
(c) µγ
Figure 8.11: Evolution of the mean estimates given by the conﬁgurations of 6 chains
and 30 chains of the DREAM algorithm based on the same simulated dataset (14
dates) after the burn-in period of 4000 iterations already discarded.
The mean estimates are more variable with smaller numbers of chains than larger
numbers of chains, as illustrated by Figure 8.11 with a burn-in period of 4000 iterations
already discarded. Although the ﬁnal mean estimates given by the two conﬁgurations

CHAPTER 8. PARAMETER ESTIMATION APPLICATIONS
147
are quite close, it seems that the conﬁguration of 30 chains provide much more sta-
ble estimates. Thus, the computational cost is crucial to determine the appropriate
number of chains.
III
Comparison of the computational costs of diﬀerent conﬁgurations
The objective is to identify the computational cost when diﬀerent number of chains
are used in the DREAM algorithm.
Settings :
Twelve conﬁgurations regarding the number of chains are considered. A minimum
number of 4000 iterations are required and regarded as a penalty term to avoid an over-
early convergence claim. Once the convergence criterion is satisﬁed (
p
ˆR < 1.001),
another 10 000 iterations are conducted to build the posterior distributions.
Computational cost
Number of iterations
Memory (Gb)
CPU time
Real computational time
3 (1d)
12000
1.06
26m
4m
6 (2d)
69500
8.00
1h44m
17m
9 (3d)
45800
10.02
2h17m
24m
12 (4d)
62300
14.47
5h35m
59m
15 (5d)
78500
20.60
5h59m
1h6m
18 (6d)
51200
20.01
5h35m
1h5m
21 (7d)
48900
19.23
6h34m
1h15m
24 (8d)
53000
22.01
7h42m
1h23m
27 (9d)
51900
25.15
7h38m
1h25m
30 (10d)
46000
25.93
9h16m
1h32m
33 (11d)
41100
25.59
8h30m
1h28m
36 (12d)
40300
25.41
8h35m
1h29m
Table 8.8: Comparison of the computational cost for the diﬀerent conﬁgurations of the
DREAM algorithm based on the same simulated dataset (14 dates).
Observations and remarks :
Table 8.8 compares the computational time and memory requirement of the 12
conﬁgurations. Despite the adaptive scheme, when the target distribution increases
in dimension, it may result in an undesirable slow convergence compared to a single
chain. For all the M chains to converge, there is an extra computational cost which is
very important as illustrated by Table 8.8. Note that it could be worse if slow mixing
occurs.
IV
Discussion: Comparison of computational strategies
Indeed, it could be considered as ineﬃcient to run multiple chains while a substan-
tial number of the ﬁrst estimates are discarded, in the sense that if one runs a single
chain of 20 000 iterations in comparison of 20 independent chains with each 1 000 itera-
tions, then the last 19 000 iterations of the long chain are more likely to be drawn from

148
8.2. IMPLEMENTATION OF MCMC-BASED METHODS
the real target distribution than those reached by any of the other chains. Figures of
8.12 give an eﬃcient example to compare the performance of the two strategies: “one
long run” and “many short runs” in the case of a bimodal target distribution when two
parameters are involved. When the number of the chains is limited, as well as their
lengths, eﬀectively, there is no guarantee that the weight of each mode is assigned pro-
portionally to its relative likelihood evaluation, therefore, the variance estimations are
less accurate. In Geyer (1991), a debate is carried out regarding these two strategies,
their advantages and disadvantages are accordingly discussed.
In order to determine the number of samples of the chains that should be discarded
pertinently, an eﬃcient way is to take only the last sample of each chain, as showed
by 8.12(b)(IV). This leads to the idea of using a large number of even “shorter” runs
to estimate the target distribution. This is exactly the technique employed by the
Interacting parallel MCMC algorithm.
(a) True density.
(b) Estimation trajectories.
Figure 8.12: One long run compared to many short runs for a bimodal target distri-
bution. The evolution of the estimation given by one long run (II), three short runs
(III) and 100 short runs (IV) compared to the target distribution (I). The red points
in (IV) correspond to the estimations resulting from the last iteration of each chain.
8.2.4
Interacting parallel MCMC
The Interacting parallel MCMC algorithm adopts the strategy of“many short runs”.
Introduced by Campillo et al. (2009), the idea of Interacting MCMC is to concentrate
the computational eﬀort on the zone of interest. To achieve this purpose, each indi-
vidual chain proposes one candidate for all the chains. Only the last estimate of each
chain is taken into account to build the posterior distribution.

CHAPTER 8. PARAMETER ESTIMATION APPLICATIONS
149
List of the tests for the Interacting MCMC algorithm :
I
Convergence monitoring
II
Impact of the prior distribution
III
Impact of the number of chains
IV
Improvement tests
General settings :
As for the previous tests, the modelling noise parameters and the observation noise
parameters are ﬁxed at 0.02 and 0.1 respectively.
Multivariate proposals are used
without global scaling. No adaptive scale is used to tune the proposals. The ﬁrst
convergence criterion for one chain AMwG described in Section 4.1.5 is used for the
Interacting parallel MCMC algorithm.
I
Convergence monitoring
The objective is to monitor the evolution of the estimates given by the Interacting
MCMC in order to observe their convergence behaviour.
Settings :
For a given restricted dataset, 1000 parallel chains are used, the overall estimates
are built from only the last samples of all the chains.
Observations and remarks :
The monitoring of both the mean and the variance estimates of the posterior dis-
tributions (Figure 8.13) shows that they converge after about 120 iterations. Further
investigations are presented in the following tests.
0
20
40
60
80
100
3.62
3.64
3.66
3.68
3.70
3.72
3.74
Iteration
Mean Estimation
(a) E(˜µa|Y )
0
20
40
60
80
100
0.755
0.760
0.765
0.770
0.775
Iteration
Mean Estimation
(b) E(˜γ0|Y )
0
20
40
60
80
100
575
580
585
590
595
600
Iteration
Mean Estimation
(c) E(˜µγ|Y )

150
8.2. IMPLEMENTATION OF MCMC-BASED METHODS
0
20
40
60
80
100
0.002
0.004
0.006
0.008
0.010
0.012
0.014
Iteration
Variance Estimation
(d) V(˜µa|Y )
(e) V(˜γ0|Y )
0
20
40
60
80
100
200
300
400
500
600
700
Iteration
Variance Estimation
(f) V(˜µγ|Y )
Figure 8.13: Evolutions of the mean estimates and the variance estimates based on
the same simulated dataset (14 dates) and the same prior distribution, performed by
Interacting MCMC with 1000 chains. The horizontal lines represent the converged
values.
II
Impact of the prior distribution
The objective is to observe the behaviour of the Interacting MCMC when performed
with diﬀerent priors compared to the one chain AMwG.
Settings :
100 independent runs are conducted with the same restricted dataset and two
diﬀerent priors.
p1(·)
−→{˜Θ1
i }i=1,...,100
Θ∗⇒Y
(8.13)
p2(·)
−→{˜Θ2
j}j=1,...,100
Theoretical value∗
Prior 1
Estimation
Monte Carlo error
˜µ
˜σ2
µ0
σ2
0
E(E(Θ|Y ))
E(V(Θ|Y ))
V(E(Θ|Y ))
E(MSE)
µa
3.749
0.0035
3.60
0.01
3.748
0.0019
1.23e-5
1.24e-5
γ0
0.7526
0.00031
0.750
0.0064
0.7524
0.00016
1.26e-6
1.33e-6
µγ
573.21
307.89
600
400
573.26
165.27
1.26
1.25
Theoretical value∗
Prior 2
˜µ
˜σ2
µ0
σ2
0
E(E(Θ|Y ))
E(V(Θ|Y ))
V(E(Θ|Y ))
E(MSE)
µa
3.818
0.0036
3.70
0.01
3.817
0.0020
1.26e-5
1.27e-5
γ0
0.7230
0.00026
0.720
0.0064
0.7229
0.00014
9.06e-7
9.17e-7
µγ
614.97
315.71
650
400
615.02
170.32
1.05
1.06
Table 8.9: Estimation and uncertainty assessment provided by Interacting MCMC
based on one simulated dataset (14 dates) with 100 independent runs.
Each test
contains a maximum of 350 000 simulations (1000 chains), and two prior distributions
are used.
The theoretical values are obtained by three long runs of AMwG with
5000000 iterations.

CHAPTER 8. PARAMETER ESTIMATION APPLICATIONS
151
Observations and remarks :
Based on the results given in Table 8.9, despite the mean estimates which appear to
be in agreement with the results of one long run, it seems that the Interacting MCMC
underestimates the variance of the posterior compared to the result of one long run.
It is possibly due to the limitation regarding the number of samples. In the following
test, conﬁgurations with diﬀerent numbers of chains are compared.
III
Impact of the number of chains
We seek to optimize the performance of this algorithm by adjusting the number of
chains. Given the fact that the posterior distribution is solely built based on the last
samples, the number of chains is crucial to assure a proper interpretation of the results.
Settings :
Based on the same restricted dataset, we maintain the same total numbers of
performed simulations (350 000) and compare the estimation results given by 5000
chains of 70 iterations, 3500 chains of 100 iterations and 1000 chains of 350 iterations.
100 independent runs are processed to compare the estimation of Monte Carlo errors.
Θ∗⇒Y ⇒{˜Θi}i=1,...,100
Observations and remarks :
Table 8.10 illustrates a comparison test between three diﬀerent conﬁgurations of
the Interacting MCMC algorithm with the same number of simulations in total. The
same conﬁgurations with independent chains are carried out as well. Obviously, the
Interacting MCMC’s scheme allows to accelerate signiﬁcantly the estimations, since
none of the multiple independent chains appear to have converged.
An interesting remark is about the Mean Squared Error (MSE) estimations. Since
MSE(Θ) = bias2(Θ) + V ar(Θ),
the estimated MSEs are obtained based on the assumption that the theoretical values
are given by one very long run of AMwG. In all the three cases, they are more important
than V(E(Θ|Y )). Among the three conﬁgurations tested with the same total number
of simulations, V(E(Θ|Y )), which can be regarded as an estimation of Monte Carlo
error, increases when the number of chains decreases, and so is MSE.
However, since one iteration of Interacting MCMC generally takes more time than
one iteration of parallel independent MCMC, for the independent chains are updated
only with their own proposed candidate, the computational cost for one iteration in-
creases exponentially with the number of chains. Hence, the CPU time is taken into
account and the DIC is used to judge the goodness of ﬁt, as presented by Figure 8.14.
The interacting scheme clearly improves the convergence behaviour. The consid-
ered selection technique can be regarded as a variant of importance sampling, with
each candidate assigned an importance weight in order to compute their acceptance
probability. In this way, the computational eﬀorts are mostly concentrated in the zone
of interest.

152
8.2. IMPLEMENTATION OF MCMC-BASED METHODS
Real value
Prior
Theoretical value∗
µ0
σ2
0
˜µ
˜σ2
µa
3.746
3.60
0.01
3.7487
3.47e-3
γ0
0.7525
0.750
0.0064
0.7526
3.10e-4
µγ
579.00
600
400
573.21
307.89
5000(chains) * 70(iter.)
Indep.
E(E(Θ|Y ))
V(E(Θ|Y ))
E(V(Θ|Y ))
V(V(Θ|Y ))
MSE∗∗
E(Θ|Y )
V(Θ|Y )
µa
3.7479
1.17e-6
2.15e-3
5.88e-9
1.70e-6
3.7108
7.16e-3
γ0
0.7527
9.49e-9
1.80e-4
5.45e-11
1.04e-8
0.7591
5.94e-4
µγ
573.54
1.21e-1
189.63
34.75
2.20e-1
581.45
514.09
3500(chains) * 100(iter.)
Indep.
E(E(Θ|Y ))
V(E(Θ|Y ))
E(V(Θ|Y ))
V(V(Θ|Y ))
MSE∗∗
E(Θ|Y )
V(Θ|Y )
µa
3.7479
2.52e-6
1.99e-3
6.99e-9
3.49e-6
3.7222
6.36e-3
γ0
0.7526
2.33e-8
1.70e-4
4.30e-11
4.49e-8
0.7563
5.14e-4
µγ
573.35
1.91e-1
172.54
23.67
2.05e-1
580.51
461.05
1000(chains) * 350(iter.)
Indep.
E(E(Θ|Y ))
V(E(Θ|Y ))
E(V(Θ|Y ))
V(V(Θ|Y ))
MSE∗∗
E(Θ|Y )
V(Θ|Y )
µa
3.7479
4.82e-6
1.87e-3
1.87e-8
5.04e-6
3.7384
5.21e-3
γ0
0.7524
4.65e-7
1.62e-4
1.41e-10
5.34e-7
0.7534
4.06e-4
µγ
573.46
5.11e-1
166.05
144.79
5.67e-1
578.03
335.43
Table 8.10: Evolution of estimations and uncertainty assessments provided by one
chain AMwG, with 350 000 simulations of diﬀerent conﬁgurations, based on the same
simulated dataset (14 dates). For each conﬁguration, the mean estimates are based on
100 independent runs.
∗: The theoretical values are obtained by taking the average
of three long runs of MCMC with 5000 000 iterations.
∗∗: Mean Square Error com-
puted based on the theoretical mean values. Indep.: the same conﬁguration but with
independent chains.
0
20
40
60
80
100
120
300
310
320
330
340
CPU time (min.)
DIC
Independent multiple chains
Interacting multiple chains
Figure 8.14: Comparison of the evolution of the DIC for the parallel independent
MCMC and the interacting MCMC with both 500 chains and the same simulated
dataset (14 dates).

CHAPTER 8. PARAMETER ESTIMATION APPLICATIONS
153
Nevertheless, this algorithm does suﬀer from variability, for the estimated variances
are much smaller than the results given by one chain AMwG. Indeed, as a variant of
importance sampling, the considered selection process could result in sample impover-
ishment problem, for the regions with small acceptance probability are rarely visited.
This can be seen as a counterpart of concentrating the computational eﬀorts on the
zone of interest. Moreover, compared to DREAM, here we pursue a much more impor-
tant number of parallel chains, considering that each chain provides a candidate for all
the chains, the computational cost is much more important, while a sampling bias is
introduced. Thus, if only the mean estimation is desired, this method is very eﬃcient,
however it cannot provide an appropriate estimation of the entire target distribution.
One possible improvement of this method is to loosen the convergence criterion and
to run the Interacting parallel MCMC algorithm until its convergence is claimed, and
then continue to run the parallel chains in an independent way in order to characterize
correctly the target distribution.
IV
Improvement tests
Motivated by the attractive eﬃciency of the original algorithm and its drawback of
underestimation of the variance to characterize the target distribution, we aim to
improve this algorithm by adding a step of independent parallel runs. The objective
of this test is to study the performance of this new algorithm.
Settings :
Based on the same conﬁguration as test II conducted to examine the impact of
the prior distribution, we perform the improved Interacting parallel MCMC with 1000
chains. The total number of 350 000 iterations is maintained. For the ﬁrst 100 it-
erations, the interactions are introduced while for the last 250 iterations, the chains
remain independent without interactions. The Adaptive Metropolis with scaling is
used to tune the proposals of the 1000 chains for the last 250 iterations. 100 indepen-
dent runs are conducted.
Θ∗⇒Y ⇒{˜Θi}i=1,...,100
Observations and remarks :
Theoretical value∗
Prior 1
Interacting
Improv. Int.
˜µ
˜σ2
µ0
σ2
0
E(E(Θ|Y ))
E(V(Θ|Y ))
E(E(Θ|Y ))
E(V(Θ|Y ))
µa
3.749
0.0035
3.60
0.01
3.748
0.0019
3.740
0.0032
γ0
0.7526
0.00031
0.750
0.0064
0.7524
0.00016
0.7521
0.00029
µγ
573.21
307.89
600
400
573.26
165.27
575.62
330.74
Table 8.11: Estimation and uncertainty assessment provided by Interacting MCMC
and Improved Interacting algorithms based on one simulated dataset (14 dates) with
100 independent runs. The theoretical values are obtained by three long runs of AMwG
with 5000 000 iterations. Improv. Int.: Improved Interacting parallel MCMC.
Table 8.11 suggests that the new algorithm improves the variance estimation in a
considerable way compared to the original Interacting MCMC. The counterpart is that

154
8.3. IMPLEMENTATION OF SMC METHODS
the mean estimates become less accurate, especially for µγ. The fact of introducing
the adaptive scheme with global scaling helps to accelerate the process of ﬁnding the
appropriate random walk step, which is very useful to this implementation context with
important number of parallel chains. However, further studies are required to optimize
the performance of this new algorithm, such as to reduce the number of parallel chains
in the ﬁrst phase of the estimation when interactions are introduced, and to increase
the number of parallel chains in the second phase of the estimation.
8.3
Implementation of SMC methods
In this section, we present the implementation of three SMC ﬁltering methods: Reg-
ularized/Convolution Particle Filter, Ensemble Kalman Filter and Unscented Kalman
Filter to the LNAS model based on the simulated datasets.
In the ﬁrst place, we detail the implementation process of these methods with
an emphasis on the initialization. Then, some tests based on the simulated datasets
are conducted according to the features of the RPF/CPF and the EnKF algorithms.
The test results and some implementation issues are discussed. Note that the UKF
algorithm is only considered as a reference method, thus its estimation performance is
only evaluated in the comparison tests presented in Section 8.5.
8.3.1
Implementation descriptions
As stated previously, a possible choice of hidden state vector for the LNAS model
is X(t) = (Qf(t), γ(t), Qr(t)). The functional parameter vector of our model is Θ =
{µa, µγ, γ0} and the error variances {σ2
γγ, σ2
q, σ2
g, σ2
r} are considered known.
Initialization
The initialization of the SMC based algorithms consists of the following steps :
– Deﬁne truncated normal prior distributions for each parameter of Θ: p0(·) with
the expectation µp0 and variance σ2
p0. Note that uniform or other form of priors
can also be considered.
– For EnKF and RPF/CPF, the number of samples (particles) M is required to
be deﬁned in advance, while for UKF, the number of the sigma points is deﬁned
by 2(dxa + dη) + 1, with dxa the dimension of the augmented hidden state vector
dim(xa
n|n) and dη the dimension of the modelling noise parameter vector dim(ηn).
– Initialize xa
0 = {Θ0, x0}. For EnKF and RPF/CPF, set {Θ0
(i)}1≤i≤M by sim-
ulating one value for each parameter from the prior distribution Θ ∼p0(·) for
each i. The hidden state variables x(0)
0
are determined by a ﬁrst allocation of the
seed biomass between the root and leaf compartments (corresponding to germi-
nation). The weight associated to each sample (particle) is assigned uniformly

CHAPTER 8. PARAMETER ESTIMATION APPLICATIONS
155
( 1
M for each). For UKF, initialize the sigma points and their associated weights
according to the unscented transform (details can be found in Section 4.3.1).
8.3.2
Regularized Particle Filter/Convolution Particle Filter
List of the tests for the RPF/CPF algorithm :
I
Choice of the kernel
II
Decomposition of variance
III
Inﬂuence of the number of particles
IV
Impact of priors
General settings :
The modelling noise parameters and the observation noise parameters are ﬁxed at
0.02 and 0.1 respectively. Without speciﬁc test settings, the conﬁguration of 250 000
particles is used for the restricted dataset and 100 000 for the full dataset.
I
Choice of the kernel
For the RPF/CPF approach, one or two kernel functions KX (or KX and KY for
CPF) associated respectively to Xa and Y are deﬁned. Campillo and Rossi (2009)
mentioned that in practice, the choice of the kernel did not aﬀect appreciably the
results. In our implementation, a Gaussian kernel is chosen for KXa. If dXa denotes
the dimension of the augmented hidden state vector Xa, KX(x) can thus be regarded
as a Parzen-Rozenblatt kernel for |x|dXa KX(x) →∞as |x| →∞. Hence :
KX
hX
M(x) =
1
hX
M
dXa KX( x
hX
M
) =

1
√
2πhX
M
dXa
e−|x|2/hX
M
2.
where the positive bandwidth parameter hX
M is deﬁned as:
hX
M = CXM −1/(4+dXa),
which is optimal for the Mean Squared Error criteria. Likewise, when the density of the
modelling noise is unknown, a similar kernel KY
hY
M(y) can be deﬁned for Y , replacing
hX
M by hY
M = CY M −1/(4+dY ). It is proved that this choice of hX
M and hY
M allows the
L1-convergence of ˆp(xa
n|y0:n) towards p(xa
n|y0:n) when M →∞(see Campillo and Rossi
(2009) and Rossi (2004)).
Another noteworthy point is that the choice of CX is crucial for density estimation,
since it is related to the dispersion of the particle population. Some sophisticated
methods have been proposed, like in Devroye and Lugosi (2001), yet cannot be applied
in the on-line estimation context. Generally, CX is deﬁned as:

156
8.3. IMPLEMENTATION OF SMC METHODS
CX = cx[Cov(˜xa
n+1
(1), . . . , ˜xa
n+1
(M))]1/2.
In Campillo and Rossi (2009), authors mention that a cx ≈1 gives good results.
Compared to the Gaussian kernel of the RPF (4.39), the value of cx corresponds to
((4/(d + 2))(1/(d+4)), with d the dimension of xa
n. In our application to LNAS model, if
d = 5 (3 parameters and 2 hidden states), then cx ≈0.940, if d = 8 (6 parameters and
2 hidden states), then cx ≈0.926.
Indeed, small values of cx (for example < 0.001) imply that the particle ˜xa
n+1
(i) will
remain close to ˜xa
n
(i), which may constrain the movement of the particles in a limited
zone, while a large value of cx (≈0.8) allows the particles to explore more thoroughly
the state space. Therefore, the value of cx should be chosen with care to optimize the
perturbation rate of the particles after the selection step.
In this study, we notice that Cov(˜xa
n+1
(1), . . . , ˜xa
n+1
(M)) is very important at the
beginning of the iteration, especially when a dispersed prior is given. Therefore, when
the number of data is limited as in our study case, an important cx may result in a large
population of the particles with small importance weights, which in turn causes sample
degeneracy and instability of the algorithm. The obtained estimates may appear to
be very unstable (large V(E(Θ|Y )) when the same estimation process is repeated). In
the worst scenario, either all the importance weights are close to 0 (≈0 numerically)
and cause numerical problems, or the least worst particles are chosen, which leads to
unsatisfactory estimations.
By keeping these constraints in mind, the adopted technique is to assign a large
value to CX from the start and decrease the value when moving forward with the
ﬁltering process in order to avoid the over-estimation of the variance as well as to
improve the estimation accuracy.
Settings :
For the same simulated dataset, in restricted or complete form, ﬁve conﬁgurations
of cx are tested, including a time-evolving ˜c∗
x chosen as follows :
- For the full dataset,
˜c∗
x = 0.8 ∗0.95i,
where i denotes the number of the dates at which the ﬁltering has already been per-
formed;
- For the restricted dataset,
˜c∗
x = 0.5 ∗0.7i.
In this test, 100 independent runs are processed to evaluate the MCE of the algo-
rithm. The estimation provided by the one chain AMwG is also listed for comparison
purpose.

CHAPTER 8. PARAMETER ESTIMATION APPLICATIONS
157
cx=0.9
−→{˜Θ1
i }i=1,...,100
cx=0.5
−→{˜Θ2
i }i=1,...,100
Θ∗⇒Y
cx=0.3
−→{˜Θ3
i }i=1,...,100
cx=10−4
−→{˜Θ4
i }i=1,...,100
cx=˜c∗
x
−→{˜Θ5
i }i=1,...,100
(8.14)
Observations and remarks :
Multiple conﬁgurations of cx are tested for both a full dataset and a restricted
dataset, the results of which are given in Table 8.12. With an important value of cx, the
variability among the estimates is very important. Although it allows the particles to
explore the state space with more liberty, the mean estimates remain quite inaccurate
compared to the results given by smaller value of cx, so is the estimated Monte Carlo
errors V(E(Θ|Y )) (which can also be interpreted as the algorithmic errors).
Restricted data
µa
γ0
µγ
Real value
3.592
0.7411
612.27
Prior
N(3.60, 0.102)
N(0.75, 0.082)
N(600.00, 20.002)
cx
E(E(Θ|Y ))
V(E(Θ|Y ))
E(V(Θ|Y ))
E(E(Θ|Y ))
V(E(Θ|Y ))
E(V(Θ|Y ))
E(E(Θ|Y ))
V(E(Θ|Y ))
E(V(Θ|Y ))
0.9
3.536
9.00e-06
7.35e-03
0.7609
1.00e-06
7.98e-04
596.25
1.000
586.221
0.5
3.538
4.00e-06
4.81e-03
0.7614
4.90e-07
4.57e-04
595.96
0.706
390.734
0.3
3.538
1.00e-06
3.86e-03
0.7618
2.50e-07
3.59e-04
595.74
0.410
335.769
0.0001
3.533
1.02e-06
3.27e-03
0.7632
1.96e-07
3.05e-04
595.07
0.403
304.769
˜c∗
x
3.533
1.00e-06
3.29e-03
0.7624
1.60e-07
3.07e-04
594.48
0.303
306.610
AMwG♦
3.533
1.00e-06
3.37e-03
0.7622
2.50e-07
3.05e-04
594.77
0.372
306.190
Complete data
µa
γ0
µγ
Real value
3.746
0.7525
579.00
Prior
N(3.60, 0.102)
N(0.75, 0.082)
N(600.00, 20.002)
cx
E(E(Θ|Y ))
V(E(Θ|Y ))
E(V(Θ|Y ))
E(E(Θ|Y ))
V(E(Θ|Y ))
E(V(Θ|Y ))
E(E(Θ|Y ))
V(E(Θ|Y ))
E(V(Θ|Y ))
0.9
3.890
1.07e-03
9.80e-03
0.5381
0.2314
8.29e-03
702.34
257.250
182.352
0.0001
3.702
1.10e-03
4.67e-04
0.7623
1.20e-04
3.56e-05
579.77
140.353
40.870
˜c∗∗
x
3.730
3.09e-04
3.26e-04
0.7552
1.39e-05
4.38e-05
582.82
35.353
47.068
AMwG♦
3.730
1.61e-05
3.60e-04
0.7561
4.68e-06
4.26e-05
582.29
4.542
45.019
Table 8.12: Parameter estimation and uncertainty assessment provided by RPF based
on the same target dataset (14 dates or 160 dates), with diﬀerent values of cx. The
given estimations are based on 100 independent runs. ˜c∗
x: cx variable, start with 0.5
and decreases gradually (0.5 ∗0.7i) with i the number of dates at which the ﬁltering
has already been performed. ˜c∗∗
x : cx variable, start with 0.8 and decreases gradually
(0.8 ∗0.95i). AMwG♦: Estimates obtained based on 100 independent runs of AMwG,
conﬁgured with the same number of iterations as of particles for the RPF/CPF ap-
proach.
One thought-provoking point is that in the case of a restricted dataset, a very
small cx provides satisfactory estimations while it is not the case with a full dataset.

158
8.3. IMPLEMENTATION OF SMC METHODS
To understand this behaviour, it is important to understand the role of the correction
step (by cx) of CPF/RPF. The objective is to provide more dynamics to the parti-
cle population and to avoid degeneracy problems. However, when few observations
are available with an important number of missing observations, the values of the co-
variance matrix usually keep inﬂating, therefore, there is no need to introduce more
variability among the particles with the CX, especially when a large number of parti-
cles are simulated. On the other hand, if abundance observations are available, since
the resampling is performed at each time step when an observation is available, it is
highly possible that the degeneracy problem could occur. Thus, the correction with
CX appears to be necessary to maintain the variability within the particle population.
Based on these arguments, a conﬁguration strategy is proposed in this thesis to
handle the two situations diﬀerently. In a general way, the cx can be deﬁned as :
cn
x = c0
x ∗αn−1,
with α ∈[0; 1].
with n the number of time steps at which the ﬁltering has been performed.
When there is a suﬃcient number of dates at which the observations data can be
used for ﬁltering, then the initial value assigned to cx, denoted c0
x, should be smaller
than 1, but remain as close to 1 as possible, to assure a controlled exploration of
the state-space without numerical issues occurred (too large covariances can result in
a population of particles with associated weights close to 0). For the last ﬁltering
steps, the perturbations provided by CX should be insigniﬁcant in order to assure that
the algorithm converges to the real target distribution and no artiﬁcial variance is
introduced. Thus, the value of cx should be decreasing gently with the ﬁltering steps
and getting close to 0 at the end. An α being slightly smaller than 1 seems to be a
good choice to maintain the dynamics of the population so as to avoid the degeneracy
problems at the same time.
On the contrary, if there is an important lack of data, and an important number of
particles are involved, then the objective is to prevent introducing too much variability
to the particles, and to assure the convergence of them. Therefore, a smaller α is
preferred.
In our implementation, we opt for c0
x = 0.5, α = 0.7 for the restricted data,
and c0
x = 0.8, α = 0.95 for the full dataset. According to Table 8.12, the proposed
strategy regarding the conﬁguration of cx appears to give satisfactory results for both
the complete dataset and the restricted dataset.
II
Decomposition of variance
In the previous test, the proposed strategy appears to work. In order to identify the sta-
bility of the method in terms of both mean and variance estimations, the following tests
are carried out to verify the law of total variance V(Θ) = V(E(Θ|Y )) + E(V(Θ|Y )).
Settings :
300 parameter sets are generated from a given distribution p0(·), and the corre-
sponding observation datasets are simulated. The prior distribution used for this test
is the same as the one used to generate the datasets :

CHAPTER 8. PARAMETER ESTIMATION APPLICATIONS
159
cx=0.9
−→{˜Θ1
i }i=1,...,300
cx=0.5
−→{˜Θ2
i }i=1,...,300
∀i ∈1, . . . , 300, Θ∗
i ∼p0(·) ⇒{Yi}i=1,...,300
cx=0.3
−→{˜Θ3
i }i=1,...,300
cx=10−4
−→
{˜Θ4
i }i=1,...,300
cx=˜c∗
x
−→{˜Θ5
i }i=1,...,300
(8.15)
Prior
µ∗
0
σ2
0
∗
µ0
σ2
0
µa
3.598
0.010
3.60
0.01
γ0
0.7544
0.0070
0.750
0.0064
µγ
600.28
398.98
600
400.00
Estimation
Variance decomposition
cx=0.9
E(E(Θ|Y ))
V(E(Θ|Y ))
E(V(Θ|Y ))
V(E(Θ|Y ))+E(V(Θ|Y ))
µa
3.597
0.007
0.007
0.014
γ0
0.7537
0.0070
0.0008
0.0078
µγ
598.41
54.64
573.36
628.00
cx=0.5
µa
3.599
0.007
0.005
0.012
γ0
0.7545
0.0068
0.0005
0.0073
µγ
598.68
66.11
406.11
472.22
cx=0.3
µa
3.600
0.007
0.004
0.011
γ0
0.7547
0.0068
0.0004
0.0071
µγ
598.47
76.17
340.58
416.75
cx=0.0001
µa
3.591
0.009
0.003
0.012
γ0
0.7573
0.0098
0.0003
0.0102
µγ
599.10
102.71
306.18
408.89
cx=˜c∗
x
µa
3.594
0.007
0.003
0.010
γ0
0.7568
0.0074
0.0003
0.0077
µγ
599.08
92.71
307.91
400.62
AMwG♦
µa
3.599
0.007
0.003
0.010
γ0
0.7543
0.0069
0.0003
0.0072
µγ
598.36
88.93
308.92
397.85
Table 8.13: Estimation and uncertainty assessment provided by RPF based on 300
simulated datasets (14 dates) generated with the parameter vectors simulated from the
same prior distribution. Each test contains 250 000 simulations. AMwG♦: Estimates
obtained based on 100 independent runs of AMwG, conﬁgured with the same number
of iterations as of particles for the RPF/CPF approach. µ∗
0 and σ2
0
∗denote the sample
mean and variance.

160
8.3. IMPLEMENTATION OF SMC METHODS
Observations and remarks :
Table 8.13 illustrates the decomposition of the variance based on a population
of datasets.
The adaptive strategy proposed for the choice of cx showed the best
performance compared to the other conﬁgurations. Both the mean estimates and the
variance estimates are quite accurate, which suggests a satisfactory performance of this
particle ﬁltering method. The resulting variances are the closest to the target ones,
and remain comparable with the MCMC estimates.
N.B.
- In the same way, if KY is required, the associated constant CY can be deﬁned as:
CY = cy[Cov(˜yn+1
(1), . . . , ˜yn+1
(M))]1/2,
where the constant cy can be assigned in a way that the particle weights remain in a
reasonable range so as to avoid the numerical instability.
- In our implementation, the likelihood of the observations is considered known. Hence,
the RPF algorithm is chosen to perform the parameter estimation rather than the CPF
algorithm.
- The CPF algorithm allows to introduce more dynamics to the model than the RPF
algorithm for it approximates the likelihood function by deﬁning another kernel for
Y . Therefore, it can also perform with deterministic models, which is a very desirable
feature of this method, as will be illustrated in Section 9.3.
III
Inﬂuence of the number of particles
One important conﬁguration required in the initialization is the number of particles.
In this test, we seek to ﬁnd a good compromise between the computational cost and
the precision of the estimations.
Settings :
Six conﬁgurations of M (which denotes the number of particles) are tested based
on the same restricted dataset. Algorithmic error is evaluated by 100 repetitions of
independent runs.
Θ∗⇒Y ⇒{˜Θi}i=1,...,100
Observations and remarks :
The estimation results illustrated by Table 8.14 suggest that the increase of the
number of particles to a certain level can improve the precision, but then it is less
helpful in terms of the averaged estimation accuracy. However, it does help to reduce
the estimated Monte Carlo errors V(E(Θ|Y )), which is understandable since MCE
decreases when the number of samples increases.

CHAPTER 8. PARAMETER ESTIMATION APPLICATIONS
161
Theoretical value∗
M =350 000
200 000
100 000
˜µ∗
˜σ2∗
E(E(Θ|Y ))
E(V(Θ|Y ))
V(E(Θ|Y ))
E(E(Θ|Y ))
E(V(Θ|Y ))
V(E(Θ|Y ))
E(E(Θ|Y ))
E(V(Θ|Y ))
V(E(Θ|Y ))
µa
3.749
3.47e-3
3.7439
3.42e-3
1.95e-6
3.7440
3.42e-3
4.11e-6
3.7448
3.44e-3
5.27e-6
γ0
0.7526
3.1e-4
0.7538
3.0e-4
2.20e-7
0.7538
3.0e-4
4.10e-7
0.7536
3.0e-4
5.69e-7
µγ
573.21
307.89
571.06
298.79
0.416
571.07
298.05
0.553
571.32
298.29
0.987
Prior
M =50 000
30 000
10 000
µ0
σ2
0
E(E(Θ|Y ))
E(V(Θ|Y ))
V(E(Θ|Y ))
E(E(Θ|Y ))
E(V(Θ|Y ))
V(E(Θ|Y ))
E(E(Θ|Y ))
E(V(Θ|Y ))
V(E(Θ|Y ))
µa
3.6
0.01
3.7452
3.46e-3
1.35e-5
3.7451
3.40e-3
2.15e-5
3.7462
3.47e-3
6.98e-5
γ0
0.75
0.0064
0.7535
3.0e-4
1.21e-6
0.7535
3.0e-4
2.28e-6
0.7536
3.0e-4
7.13e-6
µγ
600.0
400.00
571.60
294.50
2.062
571.73
292.66
4.294
571.79
293.29
10.320
Table 8.14: Evolution of estimations and uncertainty assessments provided by RPF,
with the increase of the number of particles (M), based on the same simulated dataset
(14 dates). For each conﬁguration, the mean and variance estimates are computed
based on 100 repetitions. ∗: The theoretical values are provided by taking the average
of three long runs of AMwG with 5000 000 iterations.
IV
Impact of priors
The prior distribution has established its importance, especially when a restricted
dataset is presented. In this test, we look to identify the impact of priors on the RPF
estimates.
Settings :
Like in the study case of the one chain AMwG algorithm, 350 000 particles are
simulated based on the same restricted dataset to estimate the augmented hidden
state vector. Three priors are used, the averaged variance and expectation are obtained
based on 100 independent runs.
p1(·)
−→{˜Θ1
i }i=1,...,100
Θ∗⇒Y
p2(·)
−→{˜Θ2
j}j=1,...,100
p3(·)
−→{˜Θ3
k}k=1,...,100
Observations and remarks :
– The estimation results obtained based on diﬀerent priors are very diﬀerent
according to Table 8.15, which conﬁrms the important impact of the prior for
the restricted dataset. The variance estimations are obviously correlated to the
prior distribution, which conﬁrms that an appropriate uncertainty assessment
relies on an appropriate prior.
– Little diﬀerence between the MCMC estimates and the RPF estimates is noticed.
Further comparison is needed in this regard to compare the estimation quality
of these two types of methods.
– The estimated MCE is more important with the Prior 2 probably because of the
important distance between the expectation of the prior distribution and the real

162
8.3. IMPLEMENTATION OF SMC METHODS
value used to generate the data.
Real
Theoretical
AMwG
Prior 1
Estimation
MCE
value
value∗
µ∗
σ∗2
µ0
σ2
0
E(E(Θ|Y ))
E(V(Θ|Y ))
p
V(E(Θ|Y ))
MSE
µa
3.746
3.749
3.748
0.0035
3.60
0.01
3.744
0.0034
0.0014
2.53e-5
γ0
0.7525
0.7526
0.7527
0.00031
0.750
0.0064
0.7538
0.00047
4.69e-4
1.52e-6
µγ
579.00
573.21
573.24
307.71
600
400
571.06
298.79
0.6448
5.0650
Real
Theoretical
AMwG
Prior 2
Estimation
MCE
value
value∗
µ∗
σ∗2
µ0
σ2
0
E(E(Θ|Y ))
E(V(Θ|Y ))
p
V(E(Θ|Y ))
MSE
µa
3.746
3.818
3.818
0.0036
3.70
0.01
3.813
0.0035
0.0026
3.10e-5
γ0
0.7525
0.7230
0.7231
0.00026
0.720
0.0064
0.7244
0.00025
7.13e-4
2.26e-6
µγ
579.00
614.97
614.91
315.91
650
400
612.10
299.93
1.08
9.35
Real
Theoretical
AMwG
Prior 3
Estimation
MCE
value
value∗
µ∗
σ∗2
µ0
σ2
0
E(E(Θ|Y ))
E(V(Θ|Y ))
p
V(E(Θ|Y ))
MSE
µa
3.746
3.803
3.804
0.0050
3.752
0.0225
3.794
0.0048
0.0011
8.58e-5
γ0
0.7525
0.7453
0.7453
0.00042
0.744
0.0100
0.7477
0.00041
3.82e-4
6.01e-6
µγ
579.00
563.06
562.94
430.93
590.695
625
559.92
418.70
0.42
10.05
Table 8.15: Estimation and uncertainty assessment provided by RPF based on one
simulated dataset (14 dates) with 100 repetitions. Each test contains 350 000 sim-
ulations, and three prior distributions are used. MCE: the estimated Monte Carlo
error. The AMwG estimates are obtained based on 100 independent runs with each
350 000 iterations.
∗: The theoretical values are provided by taking the average of
three long runs of AMwG with 5000 000 iterations. The Mean Squared Errors (MSE)
are evaluated based on the theoretical values.
8.3.3
EnKF
The diﬀerence between the EnKF and the UKF is that EnKF is less dependent of the
normal assumption and has larger sample size, so that in applications with important
scales, EnKF usually performs better. Since EnKF is regarded as a reference method
in our application, here, only the optimal conﬁguration of the sample size is studied.
Settings :
Six conﬁgurations of ensemble sample size are considered.
Based on the same
restricted dataset, 100 independent runs are processed to evaluate the algorithmic
errors of this method.
Θ∗⇒Y ⇒{˜Θi}i=1,...,100
Observations and remarks :
According to Table 8.16, we notice very slight changes among the estimates
when the ensemble size increases.
As expected, the estimated MCE (provided by
V(E(Θ|Y ))) decreases with the increase of the ensemble size. Yet, the estimations
remain quite diﬀerent from those given by RPF and AMwG.
Further investigations are needed for a proper comparison of this Kalman ﬁlter
based method with the MCMC based methods and particle ﬁltering based methods.

CHAPTER 8. PARAMETER ESTIMATION APPLICATIONS
163
Real
Theoretical
350 000
200 000
100 000
value
value
E(E(Θ|Y ))
E(V(Θ|Y ))
V(E(Θ|Y ))
E(E(Θ|Y ))
E(V(Θ|Y ))
V(E(Θ|Y ))
E(E(Θ|Y ))
E(V(Θ|Y ))
V(E(Θ|Y ))
µa
3.746
3.749
3.7333
3.73e-3
4.76e-8
3.7332
3.73e-3
9.26e-8
3.7329
3.73e-3
1.60e-7
γ0
0.7525
0.7526
0.7131
1.08e-3
1.46e-8
0.7131
1.08e-3
2.23e-8
0.7132
1.08e-3
6.83e-8
µγ
579.00
573.21
590.25
366.70
6.86e-3
590.28
366.48
1.11e-2
590.30
366.39
2.37e-2
Prior
50 000
30 000
10 000
µ0
σ2
0
E(E(Θ|Y ))
E(V(Θ|Y ))
V(E(Θ|Y ))
E(E(Θ|Y ))
E(V(Θ|Y ))
V(E(Θ|Y ))
E(E(Θ|Y ))
E(V(Θ|Y ))
V(E(Θ|Y ))
µa
3.6
0.01
3.7321
3.73e-3
3.84e-7
3.7313
3.70e-3
6.81e-7
3.7272
3.80e-3
2.89e-6
γ0
0.75
0.0064
0.7134
1.08e-3
9.99e-8
0.7136
1.08e-3
1.97e-7
0.7146
1.08e-3
4.97e-7
µγ
600.0
400.00
590.28
366.45
4.06e-2
590.30
366.84
1.10e-1
590.50
366.94
2.19e-1
Table 8.16: Evolution of estimations and uncertainty assessments provided by EnKF,
with the increasing ensemble sizes, based on the same simulated dataset (14 dates).
For each conﬁguration, the mean estimates are based on 100 independent runs. ∗: The
theoretical values are provided by taking the average of three long runs of AMwG with
5000 000 iterations.
8.4
Implementation
of
the
Generalized
Least
Squares method
As a classical frequentist approach widely used in plant growth modelling
(Courn`ede et al., 2011; Guo et al., 2006), the Generalized Least Squares Estimator
is applied to the LNAS model with the objective of providing a comparison between
the estimation results of this frequentist approach and the Bayesian approach in the
following sections.
The version of the GLS estimator applied is described in Section 3.4.1, with a
diagonal error covariance matrix initially chosen, consisting of equal error variances for
all Qg and all Qr respectively. The multiplicative error assumption is made. Note that
the estimator does not support modelling noises, thus the modelling noise parameters
σq and σγγ are set to 0 during the estimation. Moreover, to apply the GLS estimator,
an initialization of the departure point of each parameter is required. The algorithm is
stopped when the diﬀerence between the estimates given by two successive iterations
is small enough. A threshold is accordingly deﬁned.
As a reference method like EnKF and UKF, here we only investigate the inﬂuence
of initialization on the GLS estimates.
Inﬂuence of initialization
In the following tests, the mean values of the prior distribution deﬁned for the
Bayesian methods are used as the initial points.
The objective is to compare the
results provided by two diﬀerent sets of departure points.
Settings :
Based on the restrict dataset generated with small modelling noises (σγγ and σQ
set to 0.02) and observation noises (σg and σr set to 0.1), two diﬀerent initializations

164
8.5. METHOD COMPARISON
regarding the departure parameter sets are considered.
The estimates of the last
iteration and the estimated variance are provided.
Observations and remarks :
We test the inﬂuence of the initial departure points in the following test with a
simulated restricted dataset (14 dates).
Table 8.17 suggests that the estimation of GLS does not depend on the initial
points. Both the mean estimates and the variances estimates remain the same when
the algorithm is initialized with two sets of very diﬀerent points. The log-likelihood
evaluation of the estimates is better than the evaluation of the real parameter set used
to generate the data, probably due to the fact that in the case of restricted dataset,
there are more possible trajectories than in the scenario of full dataset, therefore the
MLE is not necessarily obtained with the real parameters set (and often not the case in
practice). In the meantime, it is noteworthy that since GLS cannot cope with modelling
noises, for those stochastic models built with modelling noise(s), GLS estimates are
not necessarily the MLE.
Initialization 1
Estimates
Real value
µ0
Est.
Var
µa
3.746
3.40
3.732
0.0044
γ0
0.7525
0.90
0.7940
0.00083
µγ
579.00
650.00
494.47
935.55
Initialization 2
Estimates
Real value
µ0
Est.
Var
µa
3.746
3.80
3.732
0.0044
γ0
0.7525
0.40
0.7940
0.00083
µγ
579.00
350.00
494.47
935.55
−2L
311.06
-
300.53
-
Table 8.17: Estimation and uncertainty assessment provided by one chain GLS based
on one simulated dataset (14 dates), without noises. Two initial sets are used.
8.5
Method comparison
With the purpose of identifying the estimation performance of the previous algo-
rithms, some tests of comparisons are conducted in this thesis to evaluate the param-
eter estimation performance of the methods investigated, including AMwG, DREAM,
Interacting parallel MCMC, RPF/CPF, EnKF, UKF and GLS.
List of the comparison tests :
8.5.1
Precision on one dataset
8.5.2
General behaviour and coverage comparison
8.5.3
Inﬂuence of the modelling noise level on scarce dataset
8.5.4
Eﬃciency comparison

CHAPTER 8. PARAMETER ESTIMATION APPLICATIONS
165
General settings :
As for the previous tests, if without speciﬁc notice, the modelling noise parameters
and the observation noise parameters are ﬁxed at 0.02 and 0.1 respectively. Multi-
variate proposals are used without global scaling for MCMC-based methods. For the
Interacting MCMC algorithm, the original version is used, which means that no adap-
tive scale is used to tune the proposals. A variable tuning parameter c∗
x is deﬁned
for the RPF algorithm using the strategy proposed in Section 8.3.2. The DREAM
algorithm is performed with 9 chains, while the Interacting parallel MCMC uses 1000
chains. In order to provide a reference value for the sake of comparison, three indepen-
dent long chains of AMwG (5000 000) are carried out to deﬁne the theoretical values
of the estimation, on which the Mean Squared errors are evaluated for all the Bayesian
methods.
8.5.1
Precision on one dataset
In this test, we aim to investigate the precision of the estimation given by the
seven methods that we implemented in this thesis, both in terms of the averaged mean
estimation and the variance estimation based on a single restricted dataset. Since from
a Bayesian point of view, the objective is to update the knowledge based on the new
observations, the prior distribution plays an important role.
Settings :
With a ﬁxed total number of simulations, the MCMC-based methods (one chain
AMwG, DREAM, Interacting MCMC) and the ﬁltering based methods (UKF, EnKF,
RPF) are subsequently performed with each 100 independent runs based on the same
simulated restricted dataset. The DIC is used to evaluate their estimates. The GLS es-
timates are also given as a reference result which is obtained based on the deterministic
form of the LNAS model.
Θ∗⇒Y ⇒{˜Θi}i=1,...,100
Observations and remarks :
According to Table 8.18, all the seven methods appear to be able to perform the
estimation with satisfactory estimation quality. Judging from the averaged estimates,
all the MCMC-based methods provide similar estimations and small MSE, while the
ﬁltering methods disagree with each other.
Furthermore, if we are under the assumption that the estimates of one very long
chain MCMC are the theoretical values, then we consider the diﬀerence between the
MSE and V(E(Θ|Y )) as the bias. MCMC-based methods appear to have smaller bias
than the ﬁltering methods.

166
8.5. METHOD COMPARISON
Prior
AMwG
DREAM
Interacting
Real value
µ0
σ2
0
E(E(Θ|Y ))
E(V(Θ|Y ))
E(E(Θ|Y ))
E(V(Θ|Y ))
E(E(Θ|Y ))
E(V(Θ|Y ))
µa
3.746
3.6
0.01
3.748
0.0035
3.749
0.0035
3.748
0.0020
γ0
0.7525
0.75
0.0064
0.7527
0.00031
0.7531
0.00031
0.7526
0.00017
µγ
579.00
600.0
400.00
573.24
307.71
572.79
314.95
573.35
172.54
−2L(¯Θ)
311.06
346.40
308.11
308.22
308.19
DIC
-
340.06
296.21
297.67
298.74
Theoretical value∗
GLS
RPF
EnKF
UKF
˜µ∗
˜σ2∗
E(E(Θ|Y ))
E(V(Θ|Y ))
E(E(Θ|Y ))
E(V(Θ|Y ))
E(E(Θ|Y ))
E(V(Θ|Y ))
E(E(Θ|Y ))
E(V(Θ|Y ))
µa
3.7487
0.0035
3.732
0.0044
3.744
0.0034
3.733
0.0037
3.634
0.0065
γ0
0.7526
0.00031
0.7940
0.00083
0.7538
0.00030
0.7131
0.00108
0.7373
0.00148
µγ
573.21
307.89
494.47
935.56
571.06
298.80
590.25
366.70
598.62
348.60
−2L(¯Θ)
308.10
300.53
307.73
325.30
326.96
DIC
296.19
-
296.32
296.52
312.94
Table 8.18: Estimation and uncertainty assessment provided by one chain AMwG,
DREAM, Interacting AMWG, RPF, UKF, EnKF and GLS based on the same sim-
ulated dataset (14 dates) with 100 independent runs. All the test contains 350 000
simulations, except for GLS and UKF (number of sigma points predeﬁned). The same
prior is shared for all the methods. ∗:
Prior
AMwG
DREAM
Interacting
Real value
µ0
σ2
0
V(E(Θ|Y ))
MSE
V(E(Θ|Y ))
MSE
V(E(Θ|Y ))
MSE
µa
3.746
3.6
0.01
2.48e-7
2.77e-7
4.95e-6
5.39e-6
1.23e-5
1.24e-5
γ0
0.7525
0.75
0.0064
2.44e-8
2.58e-8
4.29e-7
6.77e-7
1.26e-6
1.26e-6
µγ
579.00
600.0
400.00
2.65e-2
2.70e-2
4.72e-1
6.50e-1
1.91e-1
2.05e-1
Theoretical value♠
GLS
RPF
EnKF
UKF
˜µ∗
˜σ2∗
V(E(Θ|Y ))
MSE∗
V(E(Θ|Y ))
MSE
V(E(Θ|Y ))
MSE
V(E(Θ|Y ))
MSE
µa
3.7487
0.0035
-
-
1.95e-6
2.53e-5
4.76e-8
2.39e-4
8.98e-5
1.32e-2
γ0
0.7526
0.00031
-
-
2.20e-7
1.52e-6
1.46e-8
1.56e-3
3.45e-5
2.69e-4
µγ
573.21
307.89
-
-
4.16e-1
5.06
6.86e-3
290.23
3.91
649.04
Table 8.19: Comparison of the estimated Monte Carlo errors of one chain AMwG,
DREAM, Interacting AMWG, RPF, UKF and EnKF. The Mean Squared Error (MSE)
of the proposing estimates is evaluated based on the same simulated dataset (14 dates)
with 100 independent runs. The same prior is shared for all the Bayesian methods.
Each test contains 350 000 simulations except for DREAM and UKF, for which the
recommended number of simulations are used. MSE∗: the MSE of the frequentist
GLS method cannot be evaluated with the theoretical values provided by the Bayesian
based AMwG.
Based on the evaluation of the posterior distribution given by the DIC, the one
chain AMwG, RPF and EnKF show similar performances. The one long run AMwG
scores the best DIC among all the methods, which conﬁrms that its result could be
considered as the theoretical target distribution.
DREAM is performed with 3d = 9 chains based on the tests of Section 8.2.3.
Therefore, the variance estimation of one chain AMwG, RPF and DREAM are rela-
tively close. RPF has smaller E(V(Θ|Y )) than one chain AMwG, but more important

CHAPTER 8. PARAMETER ESTIMATION APPLICATIONS
167
variation of its estimates V(E(Θ|Y )) which implies larger MCE (algorithmic error),
hence it is less stable than one chain AMwG in this test case.
Table 8.19 illustrates the MSE for each of the methods regarding the mean esti-
mates. The variability of the estimates V(E(Θ|Y )) provided by RPF and Interacting
MCMC is similar, which could be understood by the fact that the Interacting MCMC
is based on the importance sampling technique as the RPF. We also notice that both
multiple chain MCMC methods, DREAM and Interacting MCMC fail to estimate the
variance of the posterior distribution in an accurate way. For DREAM, it is highly
possible that outlier samples are included in the pooled samples used to build the
posterior distributions, while for Interacting MCMC, either a sample size of 1000 is
not suﬃcient to capture and to characterize the variability of the target distribution,
or the posterior distribution is biased, for the states with small likelihood evaluations
are seldomly reached.
Finally, the log-likelihood evaluation of the mean estimates suggests that the GLS
estimator provides the best point estimation. However, when we have reliable prior
information and we desire an estimate with interpretable biological explanations, the
Bayesian approaches are preferred.
8.5.2
General behaviour and coverage comparison
After studying the performance of the methods performed on one single dataset,
we are also interested in their more global performance, including the assessment of
their post-experimental coverage probability.
Settings :
For this test, we study the estimation precision of those methods when dealing with
the 1000 simulated datasets generated with the same parameter set. The conﬁdence
intervals are bootstrap percentile intervals, constructed based on the 2.5% percentile
(lower bound, denoted lb) and the 97.5% percentile (upper bound, denoted ub) of the
1000 bootstrap mean estimates (E(Θ|Y )). The post-experimental coverage is com-
puted based on the Bayesian credibility intervals provided by each test.
Θ∗⇒{Yi}i=1,...,1000 ⇒{˜Θi}i=1,...,1000
Observations and remarks :
Regarding the averaged estimated values based on a large number of simulated
datasets (1000) generated with one parameter set (Table 8.20), the three MCMC-based
methods and RPF provide similar results. The fact of performing 1000 repetitions of
the tests with the same parameter set allows us to average the observation noises eﬀect
and the modelling noise eﬀect.

168
8.5. METHOD COMPARISON
Prior
GLS
Real value
µ0
σ2
0
E(E(Θ|Y ))
E(V(Θ|Y ))
lbB
ubB
Coverage∗
µa
3.7458
3.6
0.01
3.7394
0.0072
3.5373
3.9216
100%
γ0
0.7525
0.75
0.0064
0.7587
0.00104
0.6923
0.8393
98.2%
µγ
579.00
600.0
400.00
576.71
1426.34
469.63
657.79
94.7%
AMwG
Interacting MCMC
E(E(Θ|Y ))
E(V(Θ|Y ))
lbB
ubB
Coverage
E(E(Θ|Y ))
E(V(Θ|Y ))
lbB
ubB
Coverage
µa
3.7070
0.0034
3.6193
3.7916
95.9%
3.7060
0.0019
3.6222
3.7888
83.2%
γ0
0.7564
0.00030
0.7317
0.7804
98.8%
0.7563
0.00021
0.7314
0.7789
94.4%
µγ
591.16
306.06
575.018
607.14
99.8%
591.29
189.77
574.25
606.36
94.6%
DREAM
RPF
E(E(Θ|Y ))
E(V(Θ|Y ))
lbB
ubB
Coverage
E(E(Θ|Y ))
E(V(Θ|Y ))
lbB
ubB
Coverage
µa
3.7071
0.0035
3.6218
3.8020
92.3%
3.7086
0.0033
3.6235
3.8039
94.9%
γ0
0.7563
0.00031
0.7295
0.7821
94.0%
0.7560
0.00030
0.7333
0.7843
98.6%
µγ
591.65
315.73
573.91
608.76
95.1%
591.05
303.70
575.65
608.50
99.7%
EnKF
UKF
E(E(Θ|Y ))
E(V(Θ|Y ))
lbB
upB
Coverage
E(E(Θ|Y ))
E(V(Θ|Y ))
lbB
upB
Coverage
µa
3.7003
0.0122
3.6148
3.7748
99.9%
3.7224
0.0068
3.6125
3.8534
98.4%
γ0
0.7680
0.0038
0.7042
0.8418
100%
0.7531
0.0016
0.7019
0.7923
99.3%
µγ
594.77
366.21
587.33
601.66
99.8%
596.94
349.47
582.13
610.43
91.2%
Table 8.20: Estimation and uncertainty assessment provided by one chain MCMC,
DREAM, Interacting AMWG, RPF, UKF, EnKF and GLS based on 1000 simulated
datasets (14 dates) generated with the same parameter set. Each test contains 350000
simulations except for DREAM and UKF, with which the recommended number of
simulations are used, and the same prior is shared for all the methods.
Among the Bayesian based methods, and the rest of the results also show great
coherence, since they all consider the same prior knowledge. The EnKF’s estimation
of variance is much more important than those given by the other methods and UKF
appears to suﬀer from the insuﬃcient sigma point sample size.
The one chain AMwG and RPF propose globally very similar results for both
the averaged estimates and the variance estimates. Their coverage probabilities also
indicate that in terms of risk management, they are more reliable and better optimize
the posterior credibility interval than the other methods do. It is important to note
that although some methods have better coverage probability than these two methods,
they also provide much larger variance estimates, which does not correspond to the
objective of optimizing the coverage probability while keeping the CI as narrow as
possible.
Remarks have also been made that the variance estimates are still greatly biased
in the case of Interacting MCMC, illustrating again that the algorithm suﬀers from
the underestimation of variability.
Comparison of the computational cost
The computational cost plays an important role in numerical applications. Based on
the test 8.5.1 conducted based on one dataset (which result is given in Table 8.18), the
mean computational time and memory consummation are listed as follows :

CHAPTER 8. PARAMETER ESTIMATION APPLICATIONS
169
GLS
UKF
EnKF
AMwG
Interacting MCMC
DREAM
RPF/CPF
Number of simulations
20
15
350 000
350 000
350 000a
349 998b
350 000
CPU time
2s
2s
22m36s
22m20s
8h31m
1h34m
30m34s
Real computational time
2s
2s
12m17s
22m20s
1h49m
17m24s
14m30s
Memory (Gb)
5e-3
4e-3
5.02
4.80
5.74
8.75
22.76
Table 8.21: The averaged computational cost of one test with simulated dataset (14
dates) performed by one chain AMwG, DREAM, Interacting AMWG, RPF, UKF,
EnKF and GLS based on the 1000 tests conducted with diﬀerent datasets. For GLS,
the estimation is performed based on the deterministic form of the LNAS model.
a:
Interacting MCMC is performed with 1000 chains and 350 iterations.
b: DREAM is
performed with 9 chains and 38889 iterations.
Observations and remarks :
Among the seven methods, only the one chain AMwG algorithm cannot be paral-
lelized. However, the parallel computing does not appear to optimize the eﬃciency of
all the algorithms, especially for the multiple-chain algorithms.
Considering both the real computational time and the estimation precision, EnKF,
one chain AMwG and RPF provide the best compromise and thus are considered to
have outperformed the other methods in this study case.
8.5.3
Inﬂuence of the modelling noise level on scarce dataset
In this test, we intend to identify the impact of the modelling noise level on the
seven studied methods, both in terms of stability and accuracy.
Settings :
Three levels are deﬁned for modelling noise parameters η : 0, 0.02 and 0.05. 600
parameter sets generated from the same distribution are used to generate observa-
tion datasets with diﬀerent levels of modelling noises. The observation noise level is
ﬁxed to 0.1. According to the previous tests, the one chain AMwG, the Interacting
MCMC, EnKF and RPF, representing each an estimation technique, are applied to the
1800 datasets. Considering that in practice, no exact priors are known, ﬂatter prior
distribution is deﬁned compared to the real distribution used to generate {Θi}i=1,...,600.
η1
−→Y 1
i
⇒{˜Θη1
i }i=1,...,600
∀i ∈1, . . . , 600, Θ∗
i ∼p∗
0(·)
, ∀Θi
η2
−→Y 2
i
⇒{˜Θη2
i }i=1,...,600
η3
−→Y 3
i
⇒{˜Θη3
i }i=1,...,600
Distribution of Θ∗
Prior
E(Θ∗
i )
V(Θ∗
i )
µ0
σ2
0
µa
3.5954
0.0104
3.60
0.04
γ0
0.7519
0.0058
0.750
0.01
µγ
599.92
400.784
650
900.00

170
8.5. METHOD COMPARISON
Observations and remarks :
Generally speaking, according to Table 8.22, the four selected methods provide
comparable results. Yet the mean estimates are still far from the distribution of Θ∗,
which implies a general lack of information. Considering the scarce dataset that we
have provided for this test, it is completely understandable.
Regarding the averaged mean estimation and the averaged variance estimation,
the results given by the one chain AMwG and RPF share much similarity. The esti-
mations of RPF have more important variability than those of the one chain AMwG
(V(E(Θ|Y ))), however, the variance estimations E(V(Θ|Y )) of RPF are slightly less
important. It refers to the between-particle variation for RPF and to the intra-chain
variation for AMwG. This result indicates that there is a small bias regarding the
variance estimation of RPF.
Modelling noise 0
Modelling noise 0.02
Modelling noise 0.05
Adapted Metropolis-within-Gibbs
E(E(Θ|Y ))
V(E(Θ|Y ))
E(V(Θ|Y ))
V(V(Θ|Y ))
E(E(Θ|Y ))
V(E(Θ|Y ))
E(V(Θ|Y ))
V(V(Θ|Y ))
E(E(Θ|Y ))
V(E(Θ|Y ))
E(V(Θ|Y ))
V(V(Θ|Y ))
µa
3.6218
0.0117
0.0048
4.61e-07
3.6265
0.0117
0.0049
4.57e-07
3.6260
0.0119
0.0053
4.30e-07
γ0
0.7402
0.00541
4.19e-4
6.41e-09
0.7339
0.00538
4.23e-4
6.49e-09
0.7269
0.00541
4.76e-4
6.66e-09
µγ
629.80
223.53
558.82
645.37
630.48
226.99
560.32
649.21
632.36
234.86
599.79
897.25
Interacting MCMC
E(E(Θ|Y ))
V(E(Θ|Y ))
E(V(Θ|Y ))
V(V(Θ|Y ))
E(E(Θ|Y ))
V(E(Θ|Y ))
E(V(Θ|Y ))
V(V(Θ|Y ))
E(E(Θ|Y ))
V(E(Θ|Y ))
E(V(Θ|Y ))
V(V(Θ|Y ))
µa
3.6215
0.0138
0.0030
3.36e-7
3.6254
0.0136
0.0029
2.68e-7
3.6255
0.0132
0.0034
3.34e-7
γ0
0.7399
0.00580
2.19e-4
2.33e-9
0.7380
0.00579
2.33e-4
2.33e-9
0.7215
0.00526
2.73e-4
2.07e-9
µγ
630.32
286.34
306.99
1119.75
631.84
288.62
309.97
1031.06
631.30
257.98
335.27
1272.48
RPF
E(E(Θ|Y ))
V(E(Θ|Y ))
E(V(Θ|Y ))
V(V(Θ|Y ))
E(E(Θ|Y ))
V(E(Θ|Y ))
E(V(Θ|Y ))
V(V(Θ|Y ))
E(E(Θ|Y ))
V(E(Θ|Y ))
E(V(Θ|Y ))
V(V(Θ|Y ))
µa
3.6214
0.0119
0.0047
7.61e-07
3.6263
0.0130
0.0048
7.18e-07
3.6252
0.0122
0.0053
7.28e-07
γ0
0.7410
0.00546
4.10e-4
6.07e-09
0.7357
0.00545
4.17e-4
6.04e-09
0.7273
0.00583
4.68e-4
6.17e-09
µγ
629.69
229.53
553.77
786.46
630.98
229.40
561.76
766.90
632.23
230.94
598.36
777.42
EnKF
E(E(Θ|Y ))
V(E(Θ|Y ))
E(V(Θ|Y ))
V(V(Θ|Y ))
E(E(Θ|Y ))
V(E(Θ|Y ))
E(V(Θ|Y ))
V(V(Θ|Y ))
E(E(Θ|Y ))
V(E(Θ|Y ))
E(V(Θ|Y ))
V(V(Θ|Y ))
µa
3.6029
0.0137
0.0014
4.42e-8
3.5978
0.0117
0.0014
5.50e-8
3.6071
0.0117
0.0014
4.85e-8
γ0
0.7107
0.00670
0.00632
2.63e-6
0.7173
0.00606
0.00622
2.46e-6
0.7131
0.00642
0.00663
2.60e-6
µγ
646.55
34.87
825.89
841.76
647.14
33.36
823.23
970.77
646.43
36.87
826.82
992.02
Table 8.22: Estimation and uncertainty assessment provided by one chain AMwG,
Interacting MCMC, RPF and EnKF based on 600 simulated datasets (14 dates) gen-
erated with the same parameter set, but with diﬀerent level of modelling noises. The
given estimations are tests with a maximum of 350 000 iterations for each, taking into
account a burn-in period of 10 000 iterations.
Furthermore, by considering at the amplitude of the ﬂuctuation of the variance
estimation V(V(Θ|Y )), we highlight the fact that RPF appears to be the most sta-
ble method, for the variance estimation of the parameter µγ.
In fact, the drastic
increase of the variance among the variance estimations given by the one chain AMwG
(V(V(Θ|Y ))) in the case of µγ suggests that the method does not cope well with the
increase of the noise level. Yet, in a general way, the estimations of noise level 0 and
0.02 are closer compared to those of the noise level 0.05, which implies a common lack

CHAPTER 8. PARAMETER ESTIMATION APPLICATIONS
171
of precision when the model is too noisy.
The modelling noise level does not appear to inﬂuence the estimation in a remark-
able way, still, we notice that the mean estimates get closer to Θ∗when the noise level
decreases for the parameter γ0, from the results of the three ﬁrst methods (except
EnKF). The variability between the estimates (cf E(V(Θ|Y )) ) tends to be slightly
more important in the case of heavier modelling noises for all the parameters, par-
ticularly the less sensitive ones, µa and µγ. The EnKF estimations again make an
exception. In fact, EnKF seems to be the method least inﬂuenced by the noise level.
Nevertheless, its estimations are very close to the prior distributions and the associated
variance between the estimates are very small as well, which suggest that it has not
fully assimilated the information in the observations.
Based on the result, the Interacting MCMC still suﬀers from the variability esti-
mation. Not only its mean estimations are smaller than those of other methods, but
the huge variability of the variance estimations conﬁrms this assumption. Therefore,
the two most robust methods regarding this test are the one chain MCMC and CPF.
In the following, we will concentrate on investigating these two methods. The prior
inﬂuence is studied in the ﬁrst place.
8.5.4
Eﬃciency comparison
Based on the former results, the RPF with time-evolving tuning parameter cx and
the one chain AMwG illustrate the most convincing estimation performance. In this
test, the impact of the number of simulations are reviewed for both methods. The aim
is to identify the more eﬃcient method.
Settings :
The estimation is performed based on the same restricted dataset with 100 inde-
pendent runs. The boxplot of estimations provided by the one chain AMwG and the
RPF under various conﬁgurations are displayed in Table 8.15.
Observations and remarks :
G
G
GG
G
G
G
G
GG
GG
10000
30000
50000
100000
200000
350000
3.72
3.73
3.74
3.75
3.76
3.77
Iteration
Estimation
(a) µa (AMwG)
G
G
G
10000
30000
50000
100000
200000
350000
3.72
3.73
3.74
3.75
3.76
3.77
Iteration
Estimation
(b) µa (RPF)

172
8.6. IMPLEMENTATION OF ITERATIVE APPROACHES
G
G
G
G
G
G
G
10000
30000
50000
100000
200000
350000
560
565
570
575
580
Iteration
Estimation
(c) µγ (AMwG)
G
10000
30000
50000
100000
200000
350000
560
565
570
575
580
Iteration
Estimation
(d) µγ (RPF)
G
G
G
GG
GG
G
10000
30000
50000
100000
200000
350000
0.748
0.750
0.752
0.754
0.756
0.758
0.760
Iteration
Estimation
(e) γ0 (AMwG)
G
G
GGG
G
GG
10000
30000
50000
100000
200000
350000
0.748
0.750
0.752
0.754
0.756
0.758
0.760
Iteration
Estimation
(f) γ0 (RPF)
Figure 8.15: Boxplot of 100 mean estimates based on 100 independent runs of the same
test performed with diﬀerent numbers of iterations for the three parameters µa, µγ,
γ0 respectively. Left panel: estimations given by Adapted Metropolis-within-Gibbs.
Right panel: estimations given by RPF.
There is obviously less variation among the mean estimates of the one chain AMwG
compared to those of the RPF, which indicates that the one chain AMwG is much more
stable while the RPF estimates could be biased.
8.6
Implementation of Iterative SMC and MCMC
algorithms
To put more emphasis on the observation data, in the following, the frequentist
based iterative algorithms are applied to the LNAS model with the simulated data.
As for Bayesian based methods and for GLS, three functional parameters are estimated.
In this section, we ﬁrst detail the implementation description of the iterative ap-
proach to the LNAS model. Then, two tests are conducted to study the performance

CHAPTER 8. PARAMETER ESTIMATION APPLICATIONS
173
of this EM based approaches in the case when only the three functional parameters are
estimated. Subsequently, the results are presented with the objective of giving some
directions when confronting real experimental data.
List of the tests for the iterative approaches :
8.6.2
Iterative AMwG Vs. Iterative RPF
8.6.3
Strategies to increase the number of particles in the Iterative-RPF algorithm
8.6.1
Implementation descriptions
Gaussian randomization
In this part we apply the ideas developed in Section 5.1.1 for the state space model
described in Lemma 8.1.1. In the ﬁrst place, we assume for simplicity of presentation
that all error variances {σ2
γγ, σ2
q, σ2
g, σ2
r} are known or a priori ﬁxed to some values.
The interest will be focused on the estimation of the structural parameters and let
Θ = (µa, λ, µγ, σγ, γ0, γf). Note also that this state space model can equivalently be
described as a non-homogeneous hidden Markov model Capp´e et al. (2005), and usual
estimation techniques are based on some variant of the EM algorithm, by combining an
approximation of the E-step and a usually explicit M-step. Nevertheless, we can easily
see that there is no explicit solution for Θ even in the complete log-likelihood of this
model, therefore leading to a non-explicit M-step. Otherwise, conditional maximization
approaches should be invoked and this often leads to complicated generalized EM-type
algorithms (see, eg., Trevezas and Courn`ede (2013)), where a numerical maximization
procedure should be implemented as well.
It is also well known (see, eg., McLachlan and Krishnan (2008)) that the EM-type
sequences do not necessarily converge to the true MLE (if it exists). In typical plant
growth models with a large number of parameters, it is very diﬃcult to ensure the
existence of the MLE and the subsequent convergence of the EM iterates to the true
MLE. The best that we can hope is to have a robust algorithm and the solutions to
the initial maximization problem to be biologically relevant. For this reason, we take
Assumption 1 presented in Section 5.1.1 for granted.
When the noise parameters are ﬁxed, let Θ = (µa, λ, µγ, σγ, γ0, γf) when six func-
tional parameters are estimated, or Θ = (µa, µγ, γ0) when only three of them are
estimated.
The results of Section 5.1.1 are directly applicable to Θ. In particular, let em(Θ)
the Gaussian randomization of m w.r.t. Θ. By Deﬁnition 5.1.1 we have that em(Θ) is
an incomplete data model which consists in:
i) a Gaussian hidden vector Ψ, where
Ψ ∼NdΘ(η, Σ),
and Σ = diag{σ2
i }1≤i≤dΘ, where σ2
i > 0,
ii) an observed vector Y , where conditioned on Ψ = ψ is a state space model
detailed in lemma 8.1.1 with the parameter Θ replaced by ψ.

174
8.6. IMPLEMENTATION OF ITERATIVE APPROACHES
The parameter of the extended model is given by φ = (Θ, σ2) ∈RdΘ × (R∗
+)dΘ.
By Proposition 5.1.5, the problem of parameter estimation of φ is transformed in an
iterative state estimation problem. Starting with a ﬁxed value φ(0), the EM-update
equations given by (5.14) and (5.15) produce a sequence φ(n) which converges to a
stationary point of the initial likelihood.
Unfortunately, the conditional moments
involved in these equations cannot be computed explicitly for nonlinear models of this
type and for this reason we need to implement a stochastic variant of the EM-algorithm
to approximate them. In order to tackle this problem, we describe next a MCMC-based
method, such as a one chain Adapted Metropolis-within-Gibbs algorithm or a SMC-
based method, such as CPF to perform the E-step. Parametric bootstrap is used to
provide the uncertainty assessment (conﬁdence interval for the parameter vector Θ).
Convergence criterion
As a stopping rule we use either the one proposed in Booth and Hobert (1999), which
claims convergence when the relative change in the estimates from three successive
iterations is reasonably small, as for the Interacting MCMC, or the one using Monte
Carlo error evaluation (Q-function) to build a tolerant interval detailed in Section
5.2.1.
8.6.2
Iterative AMwG Vs. Iterative RPF
At each iteration of the EM-algorithm, given the current parameter update φ′, our
objective is to approximate
Eφ′ Θ | Y0:n = y0:n

and
 Varφ′(Θi | Y0:n = y0:n)

1≤i≤dΘ1,
where n corresponds to the observation length, since the update equations for the pa-
rameters of the model given in Proposition 5.1.5 generally lead to non-explicit solutions.
Several alternative algorithms can be employed to make this approximation for this
E-step, according to our former tests, the one chain AMwG and the CPF algorithms
have demonstrated the best performance and as a result have been selected.
Settings :
In the following, 20 updates of the prior distribution are carried out (20 iterations
of the proposed variant of EM-type algorithm) with the E-step performed by the one
chain AMwG and RPF based on the same simulated restrict dataset.
Observations and remarks :
Figure 8.16 displays the evolutions of the mean estimates and the associated cred-
ibility intervals given by the two iterative algorithms. The variance estimates shrink
drastically with the EM iterations in all cases. We recall that they are no longer vari-
ances of the Bayesian posterior distribution p(θ|y) inferred from the limited data y,
but are supposed to converge to zero with the iteration of the EM algorithm. For a
proper uncertainty assessment, it is thus necessary to perform parametric bootstrap.
In a general way, the estimations resulting from the iterative RPF and the iterative

CHAPTER 8. PARAMETER ESTIMATION APPLICATIONS
175
one chain AMwG are quite close. Further evaluation is conducted for a more precise
comparison.
Figure 8.16: Comparison of estimations (of 3 functional parameters) based on the pro-
posed variant of EM-type algorithm with the E-step performed by CPF and Adapted
Metropolis-within-Gibbs.
8.6.3
Strategies to increase the number of particles in the
Iterative-RPF algorithm
To improve the precision of our estimation, considering the fact that for the particle
ﬁltering based methods, the number of simulations (particles) should be deﬁned before
one complete iteration, diﬀerent strategies are compared for the augmentation of the
Monte Carlo sample size (geometric and quadratic), after each iteration of the EM
algorithm.
Settings :
Based on the same restricted dataset, two strategies, the geometric and the
quadratic increases of the number of particles are used with the iterative RPF. 100
independent runs are conducted. A large constant sample size is also used to have a
more ideal (but more expensive) EM algorithm (100 000 particles for the restricted
dataset).

176
8.6. IMPLEMENTATION OF ITERATIVE APPROACHES
Observations and remarks :
Real value
Quadratic Increase
Geometric Increase
Constant (Max)
E(E(Θ|Y ))
V(E(Θ|Y ))
E(E(Θ|Y ))
V(E(Θ|Y ))
E(E(Θ|Y ))
V(E(Θ|Y ))
µa
3.56
3.562
2.40e-5
3.560
9.18e-6
3.560
1.63e-6
γ0
0.625
0.626
3.3e-5
0.625
7.21e-6
0.625
2.69e-6
µγ
553.9
550.85
5.33
551.64
2.18
552.04
0.34
Stop iteration∗(Time)
51
(61min)
41
(38min)
24
(102min)
Table 8.23:
Comparison of strategies to increase the number of particles.
Both
quadratic and geometric increases have a maximum of 100 000 particles, while the
constant conﬁguration has 100 000 particles for each iteration. The results are based
on 100 independent runs, based on a full dataset (160 dates). The same stopping rule
is used for all the tests. ∗: EM iterations.
Figure 8.17 illustrates the two strategies based on the same observation dataset. In
Table 8.23, we compare the results of the two strategies with those that we obtained
with the constant number of particles. The geometric increase provided better results
compared to the quadratic increase. The increase of the number of particles takes
place every time that the Monte Carlo error in the evaluation of the Q-function is
considered to be signiﬁcant, either by detecting a zig-zagging in parameter estimates,
or by a tolerant interval (See Section 5.2.1). Our preliminary tests have showed that
both criteria work with similar performance.
0
50
100
150
200
250
300
2e+04
4e+04
6e+04
8e+04
1e+05
Iteration
Nb of particles
Quadratic increase
Geometric increase
Figure 8.17: Comparison of geometric and quadratic increases of the number of parti-
cles for the IRPF algorithm.
Without a strong eﬀort to optimize the increasing strategy, the computational time
is reduced signiﬁcantly. The results show that both increase techniques induce slightly
higher variability in the estimates among diﬀerent runs of the algorithm than in the

CHAPTER 8. PARAMETER ESTIMATION APPLICATIONS
177
case with a constant number of particles. Consequently, the gain in computational
time from the decrease of the total number of simulations is counterbalanced by this
eﬀect.
8.7
Conditional iterative approach for full param-
eter estimation
Until now, we are always under the assumption that the noise parameters of the
model are known, although in practice, this is generally not the case. To meet the
requirement of providing reasonable estimates for the noise parameters, some possible
conditional approaches are presented in Section 6.3 with SMC approaches or with
MCMC based methods. In the study case with simulated dataset, we illustrate the
two approaches when the noise estimation is combined with the Iterative RPF and
the Iterative AMwG algorithms. We highlight the fact that the noise estimation can
naturally carried out with all the Bayesian methods presented in this thesis as well.
This section is organized as follows, we ﬁrst detail the implementation of the noise
parameter estimation combined with a MCMC base-method for functional parameter
estimation, then another noise parameter estimation method is presented when it is
combined with a SMC method which is used to estimate the functional parameters
and the hidden state variables. Finally, the corresponding results are compared with
a simulated dataset in both its complete and restricted form in order to evaluate the
impact of the lost of information.
8.7.1
Iterative AMwG with noise updates
Implementation description
We recall that the noise parameters {σ2
γγ, σ2
q, σ2
g, σ2
r} are unknown and to be estimated,
as the six functional parameters of the LNAS model: {µa, λ, µγ, σγ, γ0, γf}. Regarding
the priors, Inverse Gamma prior distributions are assumed for the noise parameters,
and normal priors are assumed for the functional parameters:
σ2
γγ ∼IG(ασγγ, βσγγ),
σ2
q ∼IG(ασq, βσq),
σ2
g ∼IG(ασg, βσg),
σ2
r ∼IG(ασr, βσr),
µa ∼N(mµa, σ2
µa)IR+,
λ ∼N(mλ, σ2
λ)IR+,
µγ ∼N(mµγ, σ2
µγ)IR+,
σγ ∼N(mσγ, σ2
σγ)IR+,
γ0 ∼N(mγ0, σ2
γ0)I(0,1),
γf ∼N(mγf, σ2
γf)I(0,1).

178
8.7. CONDITIONAL ITERATIVE APPROACH
The target distribution (8.8) is accordingly updated:
π(Θ|x1:n, y1:n) ∝
n−1
Y
t=0
1
σQγ(t)F t
Q(Qf(t); Θ)
· exp{−
 Qf(t + 1) −Qf(t) −γ(t)F t
Q(Qf(t); Θ)
2
2
 σQγ(t)F t
Q(Qf(t); Θ)
2
}
n
Y
t=1
1
σγγΓt(Θ) · exp{−(γ(t) −Γt(Θ))2
2(σγγΓt(Θ))2 }
n−1
Y
t=0
δQr(t+1),φ(Qf(t+1),γ(t),Qf(t),Qr(t))
n−1
Y
t=0
1
σgF t+1
g
(Qf(t + 1); Θ)
· exp{−(F t+1
g
(Qf(t + 1); Θ) −Y exp
g
(t + 1))2
2(σgF t+1
Q (Qf(t + 1); Θ))2
}
n−1
Y
t=0
1
σrF t
r(Qr(t), Qf(t + 1), γ(t); Θ)
· exp{−(F t
r(Qr(t), Qf(t + 1), γ(t); Θ) −Y exp
r
(t + 1))2
2(σgF t
r(Qr(t), Qf(t + 1), γ(t); Θ))2
}
·
1
σµaσλσσγσγfσµγσγ0
·

1 −Φ(−mµa
σµa
)
−1 
1 −Φ(−mλ
σλ
)
−1
·

1 −Φ(−mσγ
σσγ
)
−1 
1 −Φ(−mµγ
σµγ
)
−1
·

Φ(1 −mγf
σγf
) −Φ(−mγf
σγf
)
−1 
Φ(1 −mγ0
σγ0
) −Φ(0 −mγ0
σγ0
)
−1
· exp{−(µa −mµa)2
2σ2
µa
−(λ −mλ)2
2σ2
λ
−(σγ −mσγ)2
2σ2
σγ
−(γf −mγf)2
2σ2
γf
−(µγ −mµγ)2
2σ2
µγ
−(γ0 −mγ0)2
2σ2
γ0
}
·
1
(σ2
γγ)ασγγ +1(σ2
q)ασq +1(σ2
g)ασg +1(σ2
r)ασr+1
· exp{−βσγγ
σ2
γγ
−βσq
σ2
q
−βσg
σ2
g
−βσr
σ2
r
}
· I(µa > 0) · I(λ > 0) · I(σγ > 0)
· I(γf ∈(0, 1)) · I(µγ > 0) · I(γ0 ∈(0, 1)).
(8.16)
Since in practice, direct simulation is diﬃcult to achieve, here we propose an iterative
approach to update the functional parameters Θ1, the hidden state variables x1:n and
the noise parameters Θ2 in turns with three steps :

CHAPTER 8. PARAMETER ESTIMATION APPLICATIONS
179
• Initialization
– Choose initial values for Θ1, Θ2 and x1:n.
• Iteration
For i = 1, . . . , m :
-Step 1 Estimate Θ1 by MH with a joint proposal {Θ1, x1:n} conditional to Θ2
until convergence is claimed.
-Step 2 Fix Θ1 to the estimated expectation and estimate x1:n conditional to
Θ1 and Θ2 by MH until convergence is claimed,
or, estimate x1:n by MH with a joint proposal {Θ1, x1:n} (the proposal distri-
bution for Θ1 is ﬁxed to the posterior distribution obtained in Step 1) until
convergence is claimed.
-Step 3 Update Θ2 directly from the target distribution.
In the following, we detail each of the three steps.
• Step 1: sample {Θ1, X1:n} ∼π(θ1, x1:n|y1:n, Θ2) (carried out by MH).
The objective of this step is to estimate the functional parameter vector Θ1 given
y1:n. The hidden state variables x1:n are introduced only in order to make the compu-
tation of the acceptance probability possible.
According to (8.12), the target distribution for the parameters can be simpliﬁed
in the case of six functional parameters, conditional to the four noise parameters. To
compute the acceptance ratio, we need to calculate :
p(y1:n|Θ, x1:n) · π(Θ) ∝
n
Y
t=1
1
σg ˜Qg(t)
· exp
(
−( ˜Qg(t) −Y exp
g
(t))2
2(σg ˜Qg(t))2
)
n
Y
t=1
1
σr ˜Qr(t)
· exp
(
−( ˜Qr(t) −Y exp
r
(t))2
2(σr ˜Qg(t))2
)
·
1
σµaσλσσγσγfσµγσγ0
· exp{−(µa −mµa)2
2σ2
µa
−(λ −mµλ)2
2σλ2
−(σγ −mσγ)2
2σ2
σγ
−(γf −mγf)2
2σ2
γf
−(µγ −mµγ)2
2σµγ2
−(γ0 −mγ0)2
2σ2
γ0
}
· I(µa > 0) · I(λ > 0) · I(σγ > 0)
· I(γf ∈(0, 1)) · I(µγ > 0) · I(γ0 ∈(0, 1)).
• Step 2: sample X1:n ∼π(x1:n|y1:n, Θ1, Θ2) (carried out by MH).

180
8.7. CONDITIONAL ITERATIVE APPROACH
In the previous step, the candidate of the hidden state variables x1:n is simulated
based on the candidate of Θ1 only in the objective to compute the acceptance ratio.
For the sake of computational eﬃciency, it is simulated only once which clearly does
not optimize the trajectory given y1:n. Given the fact that the hidden state estimates
are required to update the noise parameters, in this step, we aim to improve the hidden
states estimates given the posterior distribution of Θ1 provided by step 1 when it has
converged. Thus a nested new Markov chain is built for this purpose.
- If Θ1 is ﬁxed to the mean estimate, then according to Equation (4.12), the compu-
tation of acceptance ratio requires :
For t = 1, . . . , n :
p(X(t + 1)|X(t), Θ)p(Y (t)|X(t), Θ)
∝
1
σQγ(t)F t
Q(Qf(t); Θ) · exp{−
 Qf(t + 1) −Qf(t) −γ(t)F t
Q(Qf(t); Θ)
2
2
 σQγ(t)F t
Q(Qf(t); Θ)
2
}
·
1
σγγΓt+1(Θ) · exp{−(γ(t + 1) −Γt+1(Θ))2
2(σγγΓt+1(Θ))2
}
· δQr(t+1),φ(Qf(t+1),γ(t),Qf(t),Qr(t))
·
1
σgF t
g(Qf(t); Θ) · exp{−(F t
g(Qf(t); Θ) −Y exp
g
(t))2
2(σgF t
Q(Qf(t); Θ))2
}
·
1
σrF t−1
r
(Qr(t −1), Qf(t), γ(t −1); Θ)
· exp{−(F t−1
r
(Qr(t −1), Qf(t), γ(t −1); Θ) −Y exp
r
(t))2
2(σgF t−1
r
(Qr(t −1), Qf(t), γ(t −1); Θ))2
}.
(8.17)
- If Θ1 is drawn from the posterior distribution obtained in step 1, then according
to (4.13), the same result as (8.17) can be obtained to compute the acceptance ratio.
Note that in this case, an independence sampler is used for Θ1 instead of a random
walk proposal as the case in Step 1.
N.B.
This step can be regarded as building another Markov chain dedicated only to the
estimation of x1:n, in which the noise parameters are considered ﬁxed, as a result, the
samples are not used to construct the posterior distribution of Θ1.
• Step 3: update Θ2 ∼π(θ2|x1:n, y1:n, Θ1).
Once the estimations of the hidden states have converged, the noise parameters
are updated. Conjugate priors are chosen for the noise parameters Θ2 with the aim
of realizing an explicit update by simulating from the corresponding full conditional
distributions (8.16):

CHAPTER 8. PARAMETER ESTIMATION APPLICATIONS
181
σ2
q
∼IG

ασq + n
2,
βσq + 1
2
n−1
X
t=0
 Qf(t + 1) −Qf(t) −γ(t)F t
Q(Qf(t); Θ)
2
 γ(t)F t
Q(Qf(t); Θ)
2

,
σ2
γγ
∼IG

ασγγ + n
2,
βσγγ + 1
2
n−1
X
t=0

γ(t) −Γt(Θ)
2
Γt(Θ)2

,
σ2
g
∼IG

ασg + n
2,
βσg + 1
2
n−1
X
t=0

F t+1
g
(Qf(t + 1); Θ) −Y exp
g
(t + 1)
2

F t+1
g
(Qf(t + 1); Θ)
2

,
σ2
r
∼IG

ασr + n
2,
βσr + 1
2
n−1
X
t=0

F t
r(Qr(t), Qf(t + 1), γ(t); Θ) −Y exp
r
(t + 1)
2

F t
r(Qr(t), Qf(t + 1), γ(t); Θ)
2

.
Note that this three steps should be iterated, until the convergence of both Θ1 and Θ2.
Similar stopping rules used in the implementation of MCMC without noise parameter
update can be used, the details of which can be found in Section 4.1.5.
Synthetic study case
The estimation framework presented is applied to a simulated dataset in both its
complete and restricted forms.
The objective is to evaluate the robustness of this
approach when applied to the LNAS model.
Settings :
In this tests, two diﬀerent initializations are carried out in each case and the averag-
ing technique (Capp´e et al. (2005)) is used to smooth parameter estimates after a small
burn-in period. One simulated dataset is used in both its complete form and restricted
form. A maximum of 350000 iterations are deﬁned for each iteration (E-step) with the
restrict dataset and 150 000 iterations respectively for complete dataset. The standard
errors of the variability of parameter estimates from independent runs of the algorithm
(20 repetitions based on the same dataset) are also given, which corresponds to the al-
gorithmic uncertainty. The log-likelihood values of the estimates are estimated by the
means of 10 independent evaluations (the standard errors were small, approximately
0.005).
Observations and remarks :
The parameters’ real values and the estimation results are presented in Table 8.24.
As expected, the one chain AMwG based EM variant does not cope well with the
complete dataset due to the variance degeneracy, as illustrated by Table 8.24 for both
initializations.
The log-likelihood evaluations indicate that the estimates are quite
poor. The important variance between the estimates implies that the method may
suﬀer from the updated prior distribution during the initialization of each EM iter-
ation, which becomes narrower and narrower and can exhibit important inﬂuence in
the computation for the acceptance ratio and constrain the evolution of the chain.
However, when confronting the restricted dataset, the method does provide generally
better results. Regarding the diﬀerence between the estimates resulted from the two

182
8.7. CONDITIONAL ITERATIVE APPROACH
diﬀerent priors, in the case of restricted dataset it is more remarkable.
This result suggests that the one chain AMwG may not be suitable to perform
the E-step of the EM variant algorithm with complete datasets. In the following, the
iterative RPF/CPF algorithm is performed with the same conﬁguration of the test.
Initialization 1
Initial distribution
Restricted dataset ♠
Full dataset ♣
Parameter
Real value
µ0
σ0
E(E(Θ|Y ))
p
V(E(Θ|Y ))
E(E(Θ|Y ))
p
V(E(Θ|Y ))
µa
3.56
3.40
0.15
3.650
0.052
3.567
0.072
λ
56.6
60.0
5.0
59.71
0.86
55.83
2.34
γ0
0.625
0.58
0.10
0.676
0.042
0.623
0.011
γf
0.1035
0.12
0.025
0.081
0.028
0.050
0.027
µγ
550.0
500.0
50.00
495.41
8.36
628.24
23.73
σγ
950.0
880.0
50.00
1373.29
35.71
1682.52
47.53
σg
0.1
σ2
g ∼IG(25, 2)
0.109
0.007
0.090
0.002
σr
0.1
σ2
r ∼IG(25, 2)
0.112
0.008
0.104
0.003
σq
0.05
σ2
q ∼IG(55, 2)
0.039
0.003
0.048
0.002
σγγ
0.05
σ2
γγ ∼IG(55, 2)
0.048
0.003
0.052
0.002
273.75 ♠
853.74 ♠
272.76
0.70
1907.50
7.20
−2L(¯Θ)
1870.70 ♣
34624.20 ♣
Initialization 2
Initial distribution
Restricted dataset ♠
Full dataset ♣
Parameter
Real value
µ0
σ0
E(E(Θ|Y ))
p
V(E(Θ|Y ))
E(E(Θ|Y ))
p
V(E(Θ|Y ))
µa
3.56
3.60
0.15
3.670
0.067
3.568
0.065
λ
56.6
52.0
5.0
59.87
0.98
55.70
1.78
γ0
0.625
0.7
0.10
0.684
0.045
0.624
0.009
γf
0.1035
0.09
0.025
0.072
0.031
0.053
0.028
µγ
550.0
580.0
50.00
511.12
12.53
627.47
19.66
σγ
950.0
1000.0
50.00
1589.75
46.91
1790.25
46.91
σg
0.1
σ2
g ∼IG(25, 2)
0.097
0.007
0.092
0.002
σr
0.1
σ2
r ∼IG(25, 2)
0.103
0.008
0.102
0.003
σq
0.05
σ2
q ∼IG(55, 2)
0.047
0.003
0.048
0.002
σγγ
0.05
σ2
γγ ∼IG(55, 2)
0.050
0.002
0.051
0.003
273.75 ♠
776.93 ♠
272.826
0.79
1916.42
8.59
−2L(¯Θ)
1870.70 ♣
8212.03 ♣
Table 8.24: Comparison of the estimations resulting from two diﬀerent initializations
with one chain AMwG based EM variant, both for the restricted (maximum of 350 000
iterations for each E-step) and the complete dataset (maximum of 150 000 iterations
for each E-step). ♠: estimated log-likelihood based on the restricted dataset (14 dates);
♣: estimated log-likelihood based on the complete dataset (160 dates).
8.7.2
Iterative RPF with noise updates
For the ﬁltering approaches, the noise estimation can be carried out only at the end
of the algorithm. Hence, we have to update the noise parameters Θ2 and the functional

CHAPTER 8. PARAMETER ESTIMATION APPLICATIONS
183
parameters Θ1 in turns with the proposed estimators. Nevertheless, we highlight that
this noise estimation approach can also be combined with other Bayesian methods,
such as the MCMC-based methods.
In the following, we propose four estimators for both modelling noise parameters
and observation noise parameters which are built based on the estimation of the aug-
mented hidden states vector.
Implementation descriptions
In the application of LNAS model, we recall that the modelling noises ηQ appear in
the biomass production process (2.1):
Q(t) = F t
Q(Qf(t); Θ) · (1 + ηQ(t)),
and ηγ in the biomass allocation process (2.4):
γ(t) = Γt(Θ) · (1 + ηγ(t))
= (γ0 + (γf −γ0) · Ga(τ(t))) · (1 + ηγ(t)).
Since
Qr(t + 1) = F t
r(Qr(t), Qf(t + 1), γ(t); Θ),
= Qr(t) + (1 −γ(t)) · Q(t)
= Qr(t) + 1 −γ(t)
γ(t)
(Qf(t + 1) −Qf(t)),
Qf(t + 1) = Qf(t) + γ(t) · Q(t).
and
Qg(t) = F t
g(Qf(t); Θ) = Qf(t) −Qs(t),
the observation vector depends only on Qf(t) and Qr(t), which is why they are chosen
as hidden state variables to estimate.
We emphasize again that the hidden state
variables and the functional parameters Θ1 can be estimated by either the Bayesian
approaches presented in Chapter 4 or the iterative approaches presented in Chapter
5, based on the observations y0:n. In our ﬁrst application, this approach is combined
with the iterative ﬁltering approach IRPF.
The obtained estimates ˆQ0:n
r
and ˆQ0:n
f
can be used to deduce ˆγ0:n and ˆQ0:n:
ˆγ(t) =
ˆQf(t + 1) −ˆQf(t)
ˆQr(t + 1) −ˆQr(t) + ˆQf(t + 1) −ˆQf(t)
,
ˆQ(t) = ˆQr(t + 1) −ˆQr(t) + ˆQf(t + 1) −ˆQf(t).

184
8.7. CONDITIONAL ITERATIVE APPROACH
Thus, by using the estimated functional parameter vector ˆΘ1, the estimators of the
standard error of the modelling noise ηQ denoted σq, and the standard error of the
modelling noise ηγ denoted σγγ, can be deﬁned as follows :
Deﬁnition 8.7.1 (Estimator of modelling noise parameter)
ˆσq =
v
u
u
t
1
n −1
n
X
t=1
 ˆQ(t) −F t
Q( ˆQf(t); ˆΘ1)
F t
Q( ˆQf(t); ˆΘ1)
!2
,
ˆσγγ =
v
u
u
t
1
n −1
n
X
t=1
 
ˆγ(t) −Γt(ˆΘ1)
Γt(ˆΘ1)
!2
.
In the same way, the estimator of the standard errors for the observation noises ϵg
and ϵr can be derived:
Deﬁnition 8.7.2 (Estimator of observation noise parameter)
ˆσg =
v
u
u
t
1
Nobs −1
Nobs
X
n=1
 
Y g
tn −F tn
g ( ˆQf(tn); Θ1)
F tn
g ( ˆQf(tn); Θ1)
!2
,
ˆσr =
v
u
u
t
1
Nobs −1
Nobs
X
n=1
 
Y r
tn −ˆQr(tn)
ˆQr(tn)
!2
.
with Nobs the number of available observation data.
The conditional estimation process begins with the estimation of Θ1 given Θ2,
then Θ2 is estimated empirically based on the estimates of the hidden states. The
estimation then proceeds with the new value of Θ2 and iterates. The convergence of
both Θ1 and Θ2 are claimed by a standard stopping rule based on the relative changes
in the estimations during three successive estimations (See Section 8.6.1).
Synthetic study case
For the conditional IRPF approach, the following tests are carried out to evaluate and
to improve its eﬃciency when applied to the LNAS model with simulated dataset.
List of the tests for the conditional IRPF approaches :
I
Inﬂuence of priors and of missing data
II
Uncertainty assessment with parametric bootstrap
III
Strategy to increase the number of particles

CHAPTER 8. PARAMETER ESTIMATION APPLICATIONS
185
I
Inﬂuence of priors and of missing data
Settings :
In the following tests, two diﬀerent initializations are tested with both the full
dataset and the restricted dataset derived from the full dataset. The averaging tech-
nique (Capp´e et al. (2005)) is used to smooth parameter estimates after a small burn-in
period. One simulated dataset is used in both its complete form and restricted form. A
maximum of 350000 iterations are deﬁned for each iteration (E-step) with the restrict
dataset and 150 000 iterations respectively for complete dataset. The standard errors
of the variability of parameter estimates from independent runs of the algorithm (20
repetitions based on the same dataset) are also given, which corresponds to the algo-
rithmic uncertainty. The log-likelihood values of the estimates are estimated by the
means of 10 independent evaluations (the standard errors were small, approximately
0.005).
Note that usually, ﬁve estimations in turns of the functional and noise parameters
are performed.
Observations and remarks :
The iterative RPF/CPF provides better estimates in terms of Log-likelihood eval-
uation compared to the former results given by the MCMC based approach, as demon-
strated by Table 8.25, for both the restricted dataset and the complete dataset. It is
thus more suitable to perform the E-step for this EM variant algorithm.
As in the previous test case, estimations are carried out based on two initial dis-
tributions. We remark again that for the complete dataset the estimates based on
these two diﬀerent initializations are very close, which suggests a negligible eﬀect of
the initial distributions. However, for the restricted dataset, there is a diﬀerence in the
estimates of the last three parameters (γf, µγ, σγ) and the eﬀect of the initialization
seems to be non negligible, especially in the case of σγ. This can be explained by the
sensitivity of model outputs Qg and Qr to parameters. A sensitivity analysis of the
LNAS model based on Sobol’s method is presented in chapter 9 and the results show
that the last three parameters are the least inﬂuential ones among the six which are
estimated. The increased variability of these parameters (see the corresponding stan-
dard deviations) from independent runs of the algorithm (20 repetitions) based on the
same dataset is also an argument in this direction, since the great loss of information
for the restricted dataset seems to aﬀect their estimation quality.
The results of log-likelihood evaluations also seem to suggest that despite that
the estimated MLE could slightly diﬀer from two diﬀerent initializations, the most
sensitive functional parameters can be estimated without diﬃculty even in the case of
the restricted dataset, together with the observation and model noise parameters. It
may as well be conﬁrmed by the results given by the AMwG based algorithm 8.24.
By comparing the estimation results (with the same initialization) between the
restricted and the complete dataset, we also conclude that the estimates of the most
inﬂuential parameters are closer to the real values with the complete dataset than the
restricted one, as expected, due to the great amount of missing information.

186
8.7. CONDITIONAL ITERATIVE APPROACH
Initialization 1
Initial distribution
Restricted dataset ♠
Full dataset ♣
Parameter
Real value
µ0
σ2
0
E(E(Θ|Y ))
p
V(E(Θ|Y ))
E(E(Θ|Y ))
p
V(E(Θ|Y ))
µa
3.56
3.40
0.15
3.664
0.049
3.564
0.005
λ
56.6
60.0
5.0
59.73
0.22
55.68
0.12
γ0
0.625
0.58
0.10
0.679
0.026
0.628
0.002
γf
0.1035
0.12
0.025
0.088
0.013
0.047
0.006
µγ
550.0
500.0
50.00
492.91
2.44
624.55
9.07
σγ
950.0
880.0
50.00
1338.75
20.25
1633.29
98.66
σg
0.1
0.08
-
0.083
0.001
0.091
0.001
σr
0.1
0.08
-
0.106
0.001
0.108
0.001
σq
0.05
0.035
-
0.047
0.006
0.037
0.005
σγγ
0.05
0.035
-
0.059
0.010
0.061
0.005
273.75 ♠
853.74 ♠
-
271.12
0.36
1858.81
3.25
−2L(¯Θ)
1870.70 ♣
34624.20 ♣
Initialization 2
Initial distribution
Restricted dataset ♠
Full dataset ♣
Parameter
Real value
µ0
σ2
0
E(E(Θ|Y ))
p
V(E(Θ|Y ))
E(E(Θ|Y ))
p
V(E(Θ|Y ))
µa
3.56
3.60
0.15
3.668
0.058
3.566
0.003
λ
56.6
52.0
5.0
59.94
0.50
55.73
0.07
γ0
0.625
0.7
0.10
0.686
0.036
0.628
0.002
γf
0.1035
0.09
0.025
0.070
0.024
0.048
0.005
µγ
550.0
580.0
50.00
510.24
4.60
623.14
6.69
σγ
950.0
1000.0
50.00
1610.93
46.88
1609.01
82.70
σg
0.1
0.08
-
0.106
0.002
0.091
0.001
σr
0.1
0.08
-
0.083
0.001
0.108
0.001
σq
0.05
0.035
-
0.048
0.008
0.040
0.004
σγγ
0.05
0.035
-
0.055
0.012
0.060
0.004
273.75 ♠
776.93 ♠
-
271.07
0.654
1858.52
2.54
−2L(¯Θ)
1870.70 ♣
82812.03 ♣
Table 8.25: Comparison of the estimations from two diﬀerent initializations with iter-
ative RPF/CPF (EM variant), both for the restricted (maximum of 350 000 iterations
for each E-step) and the complete dataset (maximum of 150 000 iterations for each
E-step).
♠: estimated log-likelihood based on the restricted dataset (14 dates); ♣:
estimated log-likelihood based on the complete dataset (160 dates).
II
Uncertainty assessment with parametric bootstrap
The uncertainty related to parameter estimation is evaluated by parametric boot-
strap.
As a better approximation of the MLE, we considered the means from the
estimates of both initializations. In Table 8.26 we present the results that we obtained
with a bootstrap sample of size 100. Except for the least inﬂuential parameters, the
bootstrap means are very close to the MLE in the case of the complete dataset, but
when a great amount of data is missing a small bias is introduced. By comparing the

CHAPTER 8. PARAMETER ESTIMATION APPLICATIONS
187
standard deviations of the estimates for the complete and the restricted dataset, it
is clear that the additional amount of information reduces considerably the standard
deviations of all the estimated parameters, except for the 3 least inﬂuential functional
parameters. Moreover, the standard deviations of γf and σγ are prohibitively high to
allow for reliable estimations. However, for all the other parameters, despite the in-
creased standard deviations in the case of the restricted dataset, we ﬁnally get reliable
estimates of the true values within the range of one standard deviation.
Restricted dataset ♠
Full dataset ♣
Parameter
Real value
MLE
Mean
Std.
MLE
Mean
Std.
µa
3.560
3.666
3.615
0.137
3.565
3.567
0.058
λ
56.6
59.8
57.7
4.6
55.7
55.7
1.2
γ0
0.625
0.680
0.660
0.057
0.628
0.626
0.017
γf
0.1035
0.079
0.097
0.033
0.048
0.040
0.030
µγ
550.00
501.58
503.60
77.95
623.85
633.29
53.62
σγ
950.00
1474.84
1292.37
314.81
1621.15
1852.70
308.58
σg
0.1
0.106
0.101
0.016
0.108
0.106
0.005
σr
0.1
0.083
0.079
0.021
0.091
0.092
0.006
σq
0.05
0.047
0.049
0.012
0.038
0.038
0.004
σγγ
0.05
0.057
0.054
0.016
0.061
0.052
0.006
Table 8.26: Uncertainty assessment in the case of both restricted and complete simu-
lated datasets by parametric bootstrap. The means and the standard deviations are
given on the basis of a 100-bootstrap sample for the restricted (14 dates) and the
complete (160 dates) datasets.
III
Strategy to increase the number of particles
Settings :
Like in the previous test case without the noise parameter (Θ2) estimation, we
compare the results of the geometric increase (from 60 000 to 150 000 particles) with
those that we obtained with the constant number of particles (150 000 particles) under
the same settings as in the previous test case.
Observations and remarks :
In Table 8.27, the results conﬁrm that the geometric increase induces higher vari-
ability in the estimates among diﬀerent runs than in the case with a constant particle
number, we also remark that the computational time was reduced by 23%, thus the
gain in computational time from the decrease of the total number of simulations is
counterbalanced by this eﬀect. Further investigations can be conducted in this direc-
tion to seek for the most eﬃcient use of Monte Carlo resources.
In Figure 8.18 and Figure 8.19, we illustrate the convergence of the estimations of
the six functional parameters and four noise parameters respectively for the restricted
dataset based on a single run of the algorithm. The modelling noise parameters appear
to converge to a ﬂatter distribution than the observation noise parameters, especially
for σγγ.

188
8.7. CONDITIONAL ITERATIVE APPROACH
Initial distribution
Constant →
Geometric increase ↑
Parameter
Real value
Mean
Std.
Mean estimate
Std.
Mean estimate
Std.
µa
3.56
3.40
0.15
3.664
0.049
3.662
0.082
λ
56.6
60.0
5.0
59.73
0.22
59.67
0.54
γ0
0.625
0.58
0.10
0.679
0.026
0.677
0.063
γf
0.1035
0.12
0.025
0.088
0.001
0.089
0.001
µγ
550.0
500.0
50.00
492.91
2.44
495.27
7.71
σγ
950.0
880.0
50.00
1338.75
20.25
1372.40
32.92
σg
0.1
0.08
-
0.106
0.001
0.107
0.002
σr
0.1
0.08
-
0.083
0.001
0.085
0.001
σq
0.05
0.035
-
0.047
0.006
0.051
0.008
σγγ
0.05
0.035
-
0.059
0.010
0.061
0.013
−2L(¯Θ)
273.75
853.74
-
271.02
0.36
271.29
0.34
Table 8.27: Comparison of parameter estimates with two diﬀerent conﬁgurations of
particle numbers based on 200 independent runs. →: a constant number of 150 000
particles. ↑: starting from 60 000, the number of particles increases geometrically until
a maximum number of 150 000.
Figure 8.18: Evolution of the averaged estimates of the six functional parameters:
µa, λ, γ0, γf, µγ and σγ with the iterative RPF algorithm (35 0000 particles) for the
restricted dataset.

CHAPTER 8. PARAMETER ESTIMATION APPLICATIONS
189
0
10
20
30
40
50
0.06
0.08
0.10
0.12
0.14
Iteration
Estimation
(a) σg
0
10
20
30
40
50
0.06
0.08
0.10
0.12
0.14
Iteration
Estimation
(b) σr
0
10
20
30
40
50
0.00
0.02
0.04
0.06
0.08
Iteration
Estimation
(c) σq
0
10
20
30
40
50
0.00
0.02
0.04
0.06
0.08
Iteration
Estimation
(d) σγγ
Figure 8.19: Evolution of the estimated values of the four noise parameters: µa, λ,
γ0, γf, µγ and σγ with the RPF-EM algorithm (35 0000 particles) for the restricted
dataset.
8.8
Estimation with real experimental data
In this section, we present the identiﬁcation results from a real dataset with the
LNAS model, where parameter estimation is performed either in the Bayesian frame-
work with MCMC and SMC based methods, or in the frequentist framework with
the iterative version of the ﬁltering methods and parametric bootstrap for uncertainty
assessment.
8.8.1
Data description
This dataset concerns limited experimental observations realized by the French
institute for Sugar Beet research in 2010 (details of the experimental protocols are

190
8.8. ESTIMATION WITH REAL EXPERIMENTAL DATA
presented in Baey and Courn`ede (2011)). Dry matter of root (denoted by Qr) and
leaves (denoted by Qg) were collected on 50 plants at 14 diﬀerent dates. The observa-
tion vector, which records at each available date the average mass per square meter,
is given by Table 8.28.
n
54
68
76
83
90
98
104
110
118
125
132
139
145
160
Yn,1
85.2
372.9
447.6
440.8
620.4
523.8
541.4
620.2
627.5
757.6
760.5
598.3
670.7
628.4
Yn,2
23.1
199.8
302.4
409.2
709.2
768.1
863.9
1232.5
1498.8
1770.2
1878.2
1913.7
2118.4
2274.7
Table 8.28: Experimental dataset provided by the French institute for Sugar beet
research (ITB) based on an experiment in 2010. 14 dates of measurement are available
(denoted by n). The observation vector contains the averaged mass (from 50 plants)
per square meter of green leaf compartment (denoted by Yn,1) and root compartment
(denoted by Yn,2) in g.
8.8.2
Bayesian approaches
Based on the 2010 experimental dataset, we ﬁrst aim to carry out the Bayesian
based methods for functional parameter estimation. All the Bayesian methods studied
previously are applied. The objective is to evaluate and to compare their performance
with real experimental data.
List of the tests for the conditional IRPF approaches :
I
Preliminary test (with six parameters)
II
Model selection
III
Method comparison
I
Preliminary test
Settings :
According to sensitivity analysis (results of which can be found in Section 9.2.2),
those functional parameters {µa, λ, γ0, γf, µγ, σγ} which has a total order index over
0.02 are chosen to be estimated. Since the noise parameters are not included in the sen-
sitivity analysis, all the four of them are estimated. Three Bayesian based approaches,
AMwG, RPF and EnKF are ﬁrst applied.
Observations and remarks :
According to the results given by Table 8.29, for the functional parameters, RPF
and AMwG provided similar estimates while for noise parameters, especially σγγ, the
three methods gave diﬀerent opinions. Moreover, we observe the slow mixing behaviour
for AMwG, since the acceptance rate is very low (≈0.08). This is probably due to
a strong correlation among the parameters, thus, they evolve very slowly and showed
an important dependence on the prior distribution.
Similar problem occurred for
the ﬁltering methods as well, the noise parameter update of σγγ also appears to be

CHAPTER 8. PARAMETER ESTIMATION APPLICATIONS
191
unstable with important estimated variance, which implies identiﬁability problem. The
estimations given by the three methods are quite diﬀerent, especially regarding the
variance estimates.
Prior
AMwG
RPF
EnKF
µ0
σ2
0
E(Θ|Y )
V(Θ|Y )
E(Θ|Y )
V(Θ|Y )
E(Θ|Y )
V(Θ|Y )
µa
3.40
0.04
3.556
0.006
3.551
0.005
3.507
0.013
λ
58.0
9.0
59.29
4.51
58.95
4.90
56.99
6.94
γ0
0.90
0.01
0.8496
0.00116
0.8452
0.00108
0.8106
0.00161
γf
0.18
0.0025
0.178
0.00042
0.177
0.00038
0.211
0.00054
µγ
650.0
1600.0
647.42
921.23
650.1
946.91
644.99
1184.28
σγ
350.0
900.0
350.30
843.22
351.68
898.55
317.07
889.90
σg
σ2
g ∼IG(25, 2)
0.139
9.2e-6
0.140
1.3e-5
0.157
1.4e-5
σr
σ2
r ∼IG(25, 2)
0.163
9.5e-6
0.165
2.4e-5
0.166
3.1e-5
σq
σ2
q ∼IG(55, 2)
0.040
2.2e-7
0.046
2.5e-5
0.053
2.4e-5
σγγ
σ2
γγ ∼IG(55, 2)
0.038
2.4e-7
0.061
1.6e-4
0.071
2.5e-4
DIC
336.21
331.32
331.39
332.04
Table 8.29: Comparison of the estimations resulted from the one chain AMwG and
RPF in the case of the 2010 experimental dataset.
(a) µa
(b) λ
(c) γ0
(d) γf
(e) µγ
(f) σγ
Figure 8.20: Histogram of the posterior distributions of the six functional parameters:
µa, λ, γ0, γf, µγ and σγ in the LNAS model estimated by one chain AMwG (5000 000
iterations) with noise estimation based on the 2010 experimental dataset.

192
8.8. ESTIMATION WITH REAL EXPERIMENTAL DATA
(a) µa
(b) λ
(c) γ0
(d) γf
(e) µγ
(f) σγ
Figure 8.21: Normality test of the posterior distributions of the six functional parame-
ters: µa, λ, γ0, γf, µγ and σγ with QQplot in the LNAS model estimated by one chain
AMwG (5000 000 iterations) with noise estimation based on the 2010 experimental
dataset.
Figure 8.21 provides the normality test result of all the six posterior distributions,
which are illustrated in Figure 8.20. All the posteriors appear to be Gaussian, except
γ0. Considering that a large number of samples (5000 000 iterations) are included, this
result is not surprising. However, it also suggests that no multimodality was detected
and aﬃrms that standard error is representative and capable of characterizing the
variability within the normal-like posterior distribution.
Given the fact that these methods do not cope well with this parameter, a Bayesian
model selection is carried out aiming at the most appropriate conﬁguration with the
noise level which provides the best ﬁtting.
II
Model selection
In a general way, the estimation of the modelling noise parameters seem to be less
stable than those of the observation noise parameters, and therefore may be evaluated
via model selection methods and ﬁxed in the following analysis.

CHAPTER 8. PARAMETER ESTIMATION APPLICATIONS
193
Settings :
As presented in Chapter 6, a grid of 10 modelling noise levels is formed for the
parameter σγγ to determine its optimum choice according to the Deviance Information
Criterion.
Diﬀerent conﬁgurations of the number of functional parameters are also evaluated.
The order of the reduction of the parameter vector is give by the sensitivity analysis,
detailed in Section 6.1. The values of those parameters that are not estimated are ﬁxed
according to their recommended values.
Considering the Bayesian model selection
framework, the most suitable selection criterion is DIC. The RPF approach is used
to calibrate the model under diﬀerent conﬁguration, since it is more eﬃcient than
one chain AMwG (as shown in the computational comparison in Section 8.5.4), and
provides similar result according to the previous tests.
d
1
2
3
4
5
6
σγγ
DIC
0.00
329.92
326.01
322.10
324.03
326.01
332.40
0.01
329.10
325.88
322.15
323.89
325.92
331.98
0.02
329.05
325.49
321.98
323.92
325.93
332.09
0.03
328.85
325.53
322.02
324.11
325.71
331.94
0.04
327.97
325.48
321.95
323.86
325.66
331.81
0.05
327.95
325.77
321.80
324.08
325.41
331.42
0.06
328.14
325.61
321.93
323.79
325.44
331.39
0.07
328.08
326.01
321.89
323.82
325.60
331.54
0.08
328.17
325.82
322.27
323.94
325.69
332.01
0.09
329.52
326.21
323.41
323.93
325.82
332.12
0.10
329.29
327.58
324.69
324.06
326.07
332.04
Table 8.30: Evaluation of DIC with increasing number of functional parameters to
estimate in the LNAS model based on the 2010 experimental dataset.
d
1
2
3
4
5
6
E(Θ|Y )
p
V(Θ|Y )
E(Θ|Y )
p
V(Θ|Y )
E(Θ|Y )
p
V(Θ|Y )
E(Θ|Y )
p
V(Θ|Y )
E(Θ|Y )
p
V(Θ|Y )
E(Θ|Y )
p
V(Θ|Y )
γ0
0.9699
0.0130
0.9716
0.0146
0.8607
0.0340
0.8420
0.0316
0.8346
0.0304
0.8486
0.0329
µa
3.500
-
3.393
0.035
3.554
0.078
3.565
0.076
3.559
0.070
3.558
0.073
µγ
550.00
-
550.00
-
659.41
28.17
655.56
29.27
643.62
30.23
649.20
31.77
λ
60.00
-
60.00
-
60.00
-
59.13
2.12
59.03
2.02
59.54
2.08
γf
0.150
-
0.150
-
0.150
-
0.150
-
0.196
0.018
0.177
0.020
σγ
300.00
-
300.00
-
300.00
-
300.00
-
300.00
-
350.52
29.69
σg
0.161
-
0.158
-
0.152
-
0.148
-
0.150
-
0.145
-
σr
0.202
-
0.197
-
0.171
-
0.166
-
0.165
-
0.160
-
σq
0.081
-
0.076
-
0.060
-
0.062
-
0.058
-
0.048
-
σγγ
0.050
-
0.050
-
0.050
-
0.050
-
0.05
-
0.050
-
¯D
343.90
335.51
332.82
333.82
333.54
332.46
D(¯Θ)
359.84
345.24
343.82
343.56
341.66
330.50
DIC
327.96
325.76
321.80
324.08
325.41
331.42
Table 8.31: Evaluation of DIC with increasing number of functional parameters to
estimate in the LNAS model based on the 2010 experimental dataset.
The noise
parameter σγγ is ﬁxed at 0.05. d: Number of functional parameters.

194
8.8. ESTIMATION WITH REAL EXPERIMENTAL DATA
Observations and remarks :
The results showed in Table 8.30 suggest that the modelling noise parameter σγγ is
better ﬁxed at 0.05 based on the DIC. As for the number of functional parameters to
estimate, the best ﬁtting is obtained in the case of three functional parameters which
are the most inﬂuential ones to the model based on the parameter screening method
of sensitivity analysis.
Therefore, the model calibration is carried out again with this obtained conﬁgura-
tion.
III
Method comparison
In the following test, all the Bayesian estimation methods and GLS are applied to
the 2010 experimental dataset. The objective is to evaluate their performance facing
real experimental scenario.
Settings :
The conﬁguration of three functional parameters and three noise parameters ob-
tained in the previous test is adopted. The noise parameter σγγ is ﬁxed to 0.05. The
stopping criteria are used for each method to evaluate their estimation eﬃciency and
computational cost. Noted that for GLS, although the estimation is performed with
the deterministic version of the model, the observation noise parameters σg and σr can
still be estimated with the estimators given in Section 6.3. However, the modelling
noise parameters cannot be estimated, since no hidden state estimations are provided
by the method.
Prior
MCMC
DREAM
Interacting
µ0
σ0
E(Θ|Y )
p
V(Θ|Y )
E(Θ|Y )
p
V(Θ|Y )
E(Θ|Y )
p
V(Θ|Y )
µa
3.40
0.20
3.553
0.079
3.554
0.071
3.554
0.059
γ0
0.90
0.10
0.8612
0.0341
0.8599
0.0302
0.8594
0.0236
µγ
650.0
40.0
658.08
28.18
658.98
25.22
659.31
19.90
σg
σ2
g ∼IG(21, 2)
0.148
0.002
0.151
0.002
0.149
0.002
σr
σ2
r ∼IG(21, 2)
0.165
0.002
0.168
0.003
0.164
0.002
σq
σ2
q ∼IG(56, 2)
0.039
0.001
0.040
0.002
0.038
0.001
−2L(¯Θ)
348.52
344.63
344.89
344.72
DIC
343.72
321.77
322.25
321.85
GLS∗
RPF
EnKF
UKF
E(Θ|Y )
p
V(Θ|Y )
E(Θ|Y )
p
V(Θ|Y )
E(Θ|Y )
p
V(Θ|Y )
E(Θ|Y )
p
V(Θ|Y )
µa
3.653
0.102
3.554
0.078
3.557
0.062
3.410
0.090
γ0
0.8120
0.0354
0.8607
0.0340
0.8995
0.0876
0.8717
0.0299
µγ
707.47
36.44
659.41
28.17
652.00
33.48
666.20
28.33
σg
0.138
-
0.152
0.002
0.148
0.003
0.167
0.005
σr
0.155
-
0.171
0.002
0.165
0.003
0.191
0.008
σq
-
-
0.060
0.003
0.045
0.004
0.065
0.007
−2L(¯Θ)
338.186
343.82
357.34
360.20
DIC
-
321.80
324.51
332.17
Table 8.32:
Comparison of the estimations resulting from the one chain AMwG,
DREAM, Interacting MCMC, GLS, RPF, EnKF and UKF in the case of the 2010
experimental dataset with noise parameter σγγ ﬁxed to 0.05. GLS∗: the estimation is
performed based on the deterministic version of the LNAS model.

CHAPTER 8. PARAMETER ESTIMATION APPLICATIONS
195
Observations and remarks :
Like in the case of simulated data presented previously, the three MCMC-based
methods provided very close estimations. According to Table 8.32, similar results are
also given by RPF. The DIC conﬁrms their comparable estimation qualities, with the
estimates of AMwG and RPF slightly better than those of the others. EnKF and UKF
depend on normal assumptions, and UKF suﬀers from limited samples, their estimates
are thus less accurate. The part of variability explained by the noises is thus more
important.
0
10
20
30
40
0.0
0.2
0.4
0.6
0.8
1.0
Lag
ACF
(a) µa
0
10
20
30
40
0.0
0.2
0.4
0.6
0.8
1.0
Lag
ACF
(b) γ0
0
10
20
30
40
0.0
0.2
0.4
0.6
0.8
1.0
Lag
ACF
(c) µγ
Figure 8.22: Autocorrelation of estimations given by the one chain AMwG based on
the 2010 experimental dataset with noise parameter σγγ ﬁxed to 0.05.
The corresponding computational cost is given for all the above methods.
UKF
EnKF
AMwG
Interacting MCMC
DREAM
RPF/CPF
Number of simulations
15
200 000
186 500
62 000a
153 700b
200 000
CPU time
2s
12m46s
11m18s
1h27m
58m
16m13s
Real computational time
2s
6m11s
11m18s
15m22s
9m17s
7m58s
Memory (Gb)
4e-3
2.85
2.48
3.34
6.41
14.27
Table 8.33: The averaged computational cost of three functional parameter estimation
based on the 2010 experimental dataset, performed by one chain AMwG, DREAM,
Interacting AMWG, RPF, UKF, EnKF and GLS. a: Interacting MCMC is performed
with 1000 chains. b: DREAM is performed with 9 chains.
GLS provided the best point estimation based on the likelihood evaluation, how-
ever, since for the Bayesian methods, only the MMSE estimator is used instead of the
MAP estimator, the likelihood evaluation based on the mean estimates is not really
comparable.
For AMwG, the autocorrelation function is evaluated (Figure 8.22). In the case
that only three functional parameters are estimated, the acceptance rate obtained is
close to 22%, which also conﬁrms an appropriate behaviour of convergence.
In Table 8.33, the computational cost of all the methods considered are given. This
result illustrates the advantage of the parallel computation. Although RPF requires

196
8.8. ESTIMATION WITH REAL EXPERIMENTAL DATA
more memory than the other methods, considering its estimation results, the real
computational time is very reasonable. In the meantime, among the MCMC-based
methods, the parallel chains did not help to reduce the computational time.
For
DREAM, the convergence of all the chains are diﬃcult to obtain, and for Interacting
MCMC, the 1000 parallel chains appear to be computational expensive.
8.8.3
Frequentist based iterative approaches
For the following tests, attempts are made to put more emphasis on the data
despite the lack of information. The iterative scheme is considered. Since the iterative
approaches aim to an point estimation that maximize the likelihood evaluation, to
perform the model comparison, MAP based criterion such as AIC and BIC are more
suitable, and are thus chosen.
We note that the model selection can also be carried out under this context to
identify the best combination of noise parameters to estimate and the complexity of
the model, as what we have performed for the Bayesian based approaches. However,
this test is extremely computationally expensive with iterative based ﬁltering methods
with noise parameter assessment. Therefore, in this study, all the noise parameters
are estimated by the conditional approaches.
Model selection
Settings :
Based on the sensitivity analysis (results detailed in Section 9.2.2), the model se-
lection for the functional parameters is carried out with IRPF performing the ﬁtting.
d
1
2
3
4
5
6
2L
345.65
341.97
338.52
335.77
332.76
329.47
AIC
347.65
345.97
344.52
343.77
342.76
341.47
AICc
347.80
346.45
345.52
345.50
345.49
345.49
BIC
348.98
348.63
348.52
349.10
349.42
349.46
Table 8.34: Evaluation of AIC, AICc and BIC with increasing number of functional
parameters to estimate in the LNAS model based on the 2010 experimental dataset.
All the four noise parameters are estimated.
Observations and remarks :
Unfortunately, according to Table 8.34, the opinion is not shared by diﬀerent cri-
teria which put us in a dilemma.
The AIC favours the model with six functional
parameters estimated, while the BIC prefers the model with three functional parame-
ters. AICc gives similar evaluation among the model with 3-6 parameters. To illustrate
the performance of the iterative approaches, we decided to estimate the six functional
parameters and the four noise parameters with the iterative approaches.

CHAPTER 8. PARAMETER ESTIMATION APPLICATIONS
197
Parameter estimation
Settings :
The uncertainty related to parameter estimation was assessed by parametric boot-
strap, by averaging the estimates obtained from both initializations for IRPF, and
the estimation yields the best log-likelihood evaluation for IAMwG. The estimation
results are presented in Table 8.36 together with estimated standard errors from 100
independent runs. The Monte Carlo sample size was increased geometrically and other
implementation details are similar to those that have been used for the simulated data,
which can be found in Section 8.6.
We ﬁnally compare the diﬀerent ﬁltering methods in the iterative framework. For
the conditional IRPF approach, 60 000 particles were initialized with the same prior
distributions as for the conditional IEnKF and IUKF approach. The maximum number
of particles is 350 000. For the conditional IEnKF approach, an ensemble size of 350 000
is adopted for the comparison purpose. A parametric bootstrap is also implemented
to evaluate the estimates’ uncertainty. Standard deviations and conﬁdence intervals
are hence obtained from 300 bootstrap samples. The corresponding results are given
in Table 8.39.
Observations and remarks :
In Table 8.37, we present the means and the standard deviations of a 300-bootstrap
sample. Notice that the estimates of the three most important parameters (high sen-
sitivity indices) are very satisfactory, with low standard deviations relatively to their
mean values. Nevertheless, the estimations from the least inﬂuential parameters are
less satisfactory with higher standard deviations as expected from the simulated case.
A small bias in the mean estimated values from the bootstrap sample also conﬁrms
the diﬃculty in estimating these parameters. Note also that the estimates of the noise
parameters are satisfactory.
Initialization I
Initialization II
Parameter
Initial distribution
Estimation
Initial distribution
Estimation
µ0
σ0
E(E(Θ|Y ))
p
V(E(Θ|Y ))
µ0
σ0
E(E(Θ|Y ))
p
V(E(Θ|Y ))
µa
3.40
0.2
3.563
0.078
3.45
0.4
3.599
0.092
λ
58.0
3.0
59.40
2.14
57.0
5.0
59.36
3.36
γ0
0.90
0.10
0.849
0.034
0.78
0.15
0.834
0.040
γf
0.18
0.05
0.188
0.021
0.20
0.05
0.198
0.023
µγ
650.0
40.0
642.01
32.12
630.00
50.0
640.81
36.21
σγ
350.0
30.00
319.96
28.84
300.0
40.0
306.13
36.58
σg
0.10
-
0.138
0.003
0.12
-
0.139
0.001
σr
0.10
-
0.152
0.003
0.12
-
0.155
0.001
σq
0.02
-
0.040
0.009
0.03
-
0.041
0.010
σγγ
0.05
-
0.058
0.011
0.03
-
0.062
0.012
−2L
347.82
-
333.44
0.36
338.71
-
335.96
0.43
Table 8.35: Comparison of the functional and noise parameter estimations resulting
from two diﬀerent initializations based on the one chain AMwG performed E-step of
the iterative approach, in the case of the 2010 experimental dataset.
Note that in Table 8.36, the inﬂuence of the initialization is negligible for all the
parameters but σγ, which is the least inﬂuential parameter. This is also suggested

198
8.8. ESTIMATION WITH REAL EXPERIMENTAL DATA
by the small diﬀerence of the log-likelihood evaluations at the corresponding solutions.
The variability from independent runs of the algorithm was relatively high for the mod-
elling noise parameters (σq, σγγ), but by averaging a moderate number of independent
runs a better precision can be obtained.
Initialization I
Initialization II
Parameter
Initial distribution
Estimation
Initial distribution
Estimation
µ0
σ0
E(E(Θ|Y ))
p
V(E(Θ|Y ))
µ0
σ0
E(E(Θ|Y ))
p
V(E(Θ|Y ))
µa
3.40
0.2
3.565
0.062
3.45
0.4
3.563
0.059
λ
58.0
3.0
59.78
0.37
57.0
5.0
59.33
0.46
γ0
0.90
0.10
0.844
0.017
0.78
0.15
0.836
0.021
γf
0.18
0.05
0.190
0.002
0.20
0.05
0.198
0.001
µγ
650.0
40.0
642.64
5.96
630.00
50.0
641.02
6.46
σγ
350.0
30.00
319.59
13.62
300.0
40.0
297.78
14.80
σg
0.10
-
0.142
0.004
0.12
-
0.143
0.001
σr
0.10
-
0.164
0.004
0.12
-
0.167
0.001
σq
0.02
-
0.042
0.012
0.03
-
0.043
0.012
σγγ
0.05
-
0.064
0.012
0.03
-
0.064
0.012
−2L
347.82
-
331.17
0.23
338.71
-
331.18
0.26
Table 8.36: Comparison of the estimations resulting from two diﬀerent initializations
based on the iterative RPF/CPF approach (EM variant), in the case of the 2010
experimental dataset.
RPF
MLE
Mean
Std.
µa
3.564
3.562
0.123
λ
59.55
59.70
3.13
γ0
0.840
0.843
0.044
γf
0.194
0.182
0.053
µγ
642.33
654.89
62.40
σγ
308.69
336.62
109.95
σg
0.142
0.143
0.032
σr
0.165
0.158
0.024
σq
0.042
0.039
0.008
σγγ
0.064
0.073
0.015
MCMC
MLE
Mean
Std.
µa
3.563
3.565
0.169
λ
59.40
59.15
3.57
γ0
0.849
0.850
0.062
γf
0.188
0.182
0.077
µγ
642.01
651.05
73.64
σγ
319.96
346.56
181.97
σg
0.138
0.139
0.006
σr
0.152
0.151
0.005
σq
0.040
0.039
0.002
σγγ
0.058
0.060
0.003
Table 8.37:
Uncertainty assessment of estimates based on the 2010 experimental
dataset performed by parametric bootstrap and Iterative RPF and Iterative MCMC
(EM variant with the E-step performed by RPF or MCMC).
IUKF
IEnKF
IAMwG
IRPF
CPU time
1m11s
4h13s
5h37s
6h13s
Real computational time
1m11s
1h42m
5h37s
2h21s
Memory (Gb)
0.15
6.51
6.19
25.47
Table 8.38: The averaged computational cost for the point estimation of 100 tests,
performed by the four iterative methods IEnKF, IRPF, IUKF and IAMwG, based on
the 2010 experimental dataset.

CHAPTER 8. PARAMETER ESTIMATION APPLICATIONS
199
IEnKF
IRPF
IUKF
IAMwG
GLS∗
E(E(P|Y ))
p
V(E(P|Y ))
E(E(P|Y ))
p
V(E(P|Y ))
E(E(P|Y ))
p
V(E(P|Y ))
E(E(P|Y ))
p
V(E(P|Y ))
E(P|Y )
p
V(P|Y )
µa
3.600
0.154
3.564
0.123
3.900
0.270
3.563
0.169
3.591
0.142
λ
60.16
6.51
59.55
3.13
60.18
6.49
59.40
3.57
59.49
7.96
γ0
0.830
0.087
0.840
0.044
0.800
0.064
0.849
0.062
0.824
0.112
γf
0.206
0.058
0.194
0.053
0.216
0.048
0.188
0.077
0.202
0.078
µγ
639.39
83.28
642.33
62.40
579.98
73.75
642.01
73.64
651.87
77.20
sa
276.18
149.83
308.69
109.95
338.31
44.89
319.96
181.97
277.72
228.59
σg
0.137
0.028
0.142
0.032
0.156
0.070
0.138
0.006
0.132
-
σr
0.166
0.027
0.165
0.024
0.193
0.092
0.152
0.005
0.149
-
σq
0.040
0.004
0.042
0.008
0.052
0.048
0.040
0.002
-
-
σγγ
0.061
0.002
0.064
0.015
0.072
0.031
0.058
0.003
-
-
−2L
334.75
-
329.46
-
353.37
-
333.44
-
329.97
-
Table 8.39: Estimated values and standard deviations for all the parameters of the
LNAS model provided by the iterative approaches as an EM variant with IEnKF,
IRPF, IUKF and IAMwG to perform the E-step. GLS∗: GLS is performed with the
deterministic version of the model.
Prior
AMwG
RPF
EnKF
µ0
σ2
0
E(Θ|Y )
V(Θ|Y )
E(Θ|Y )
V(Θ|Y )
E(Θ|Y )
V(Θ|Y )
µa
3.40
0.04
3.556
0.006
3.551
0.005
3.507
0.013
λ
58.0
9.0
59.29
4.51
58.95
4.90
56.99
6.94
γ0
0.90
0.01
0.8496
0.00116
0.8452
0.00108
0.8106
0.00161
γf
0.18
0.0025
0.178
0.00042
0.177
0.00038
0.211
0.00054
µγ
650.0
1600.0
647.42
921.23
650.1
946.91
644.99
1184.28
σγ
350.0
900.0
350.30
843.22
351.68
898.55
317.07
889.90
σg
σ2
g ∼IG(25, 2)
0.139
9.2e-6
0.140
1.3e-5
0.157
1.4e-5
σr
σ2
r ∼IG(25, 2)
0.163
9.5e-6
0.165
2.4e-5
0.166
3.1e-5
σq
σ2
q ∼IG(55, 2)
0.040
2.2e-7
0.046
2.5e-5
0.053
2.4e-5
σγγ
σ2
γγ ∼IG(55, 2)
0.038
2.4e-7
0.061
1.6e-4
0.071
2.5e-4
DIC
336.21
331.32
331.39
332.04
Table 8.40: Comparison of the estimations resulted from the one chain AMwG, RPF
and EnKF in the case of the 2010 experimental dataset.
Compared to the iterative RPF, Table 8.35 suggests that the iterative AMwG
based algorithm provides estimates that are more dependent of the initial distribution.
Unlike the RPF approach, the shrinkage of the variance results in a more important
variability between the estimates given by independent runs for the iterative AMwG.
Since the IAMwG cannot be performed in a parallelized way as for the other SMC
based iterative approaches, according to Table 8.39, it is the most time consuming.
Judging from the estimation performance and the computational cost, despite the
important memory requirement, IRPF appears to be the most eﬃcient method.

200
8.9. DISCUSSION
We recall the estimation results (Table 8.29) given by the same Bayesian approaches
(without the iterative scheme). In comparison, the iterative approaches provide results
with better likelihood evaluations. In counterpart, the iterative approaches are much
more computational expensive.
8.9
Discussion
Despite built on diﬀerent inference bases, globally, all the three types of methods,
the generalized nonlinear least squares method, the MCMC-based methods and the
ﬁltering methods illustrate their robustness in model calibration facing the dynamic
state-space plant growth model LNAS. Only UKF based methods showed less good ﬁts
compared to the other methods (Table 8.39 and Table 8.32) due to its small sample size
and the dependence of the normal assumption. GLS often gives unrealistic conﬁdence
intervals (CI for sa with the 2010 experimental data), while other methods perform
better in this respect yet with a much longer computational time. If only judging on
the mean estimates, the estimations of iterative approaches yield better log-likelihood
evaluation than the Bayesian approaches, which can be understood since they put more
emphasis on the data and the prior distributions weight less in the ﬁnal estimations.
Although GLS mean estimates seem to score the best the log-likelihood evaluation
in various occasions, the fact that it considers only the best ﬁt estimate instead of
probability distribution makes the error term less meaningful. In the meantime, GLS
aims to ﬁnd the MLE by avoiding the local maximums, while in the plant growth
context, sometimes the local maximums are preferred for they are biologically more
interpretable. On the other hand, the GLS estimator retains only the parameter set
that illustrates the best ﬁt, while the mean estimates of the Bayesian based methods
provide the most frequently visited value, therefore, their estimates are not comparable.
If we compare the MCMC-based methods and the ﬁltering methods, both of them
are Monte Carlo methods. However, in the Bayesian framework, the MCMC-based
methods are iterative while the ﬁltering methods are not, for the former aim at
p(X0:n|Y0:n) while the latter compute only p(Xn|Y0:n).
The ﬁltering methods have
the advantage of being sequential, and therefore being able to process on-line, while
the MCMC-based methods cannot. Yet to achieve the oﬀ-line parameter estimation
objective, the MCMC-based methods appear to be more stable with less important
algorithmic error (Monte Carlo error). The inconvenient part is the need of full con-
ditional distributions or the tuning of the instrumental proposal distribution in the
MCMC-based algorithms, although the latter can be solved by applying an adaptive
scheme. Conventionally, a successful implementation of the MCMC-based methods
(achieve interpretable convergence) requires a pertinent prior knowledge of the studied
subject and a good practice of the MCMC algorithms, whereas the ﬁltering methods
have usually less tuning parameters, there is no need of burn-in period, the concept is
easier to understand and thus the implementation is simpler. The small drawback is
that for an eﬃcient exploration of the state-space, an important number of simulations
are necessary.
Furthermore, regarding the computational cost, both the parallel-chain methods

CHAPTER 8. PARAMETER ESTIMATION APPLICATIONS
201
and the SMC methods can be parallelized when a large sample size is required, while
the one chain AMwG cannot. The counterpart for the parallel MCMC is that the
convergence is diﬃcult to achieve when an important number of chains are imple-
mented. The burn-in period is diﬃcult to deﬁne for each of the chains and therefore
the posterior composed of pooled samples from all the chains are less accurate than
one chain AMwG. In the case of Interacting MCMC, by taking only the last sample of
each chain, although the mean estimation is very accurate for the computational power
is concentrated on the zone of interest by the importance sampling scheme, unfortu-
nately, a sampling bias is accordingly introduced, for the samples with less important
acceptance probability are rarely visited. Therefore, despite its eﬃciency of ﬁnding
the mean estimates, the resulting posterior is often less ﬂat than it ought to be. This
could be potentially an issue for an appropriate uncertainty assessment, and inﬂuence
the future prediction results.
As a result, the following selection technique is suggested. If a rapid estimation is
required to get a rough idea of the parameters, then the GLS is recommended when no
prior information is available, and the Interacting MCMC is recommended when the
user has a prior knowledge on the studied subject with a good understanding of the
MCMC-based methods. On the other hand, if there is no time constraint, with a good
knowledge of the MCMC based methods, a one chain AMwG is advised, so that the
target distribution can be inferred appropriately. Finally, a compromise between the
estimation quality and the computational time are CPF/RPF and EnKF, which are
simple to develop and to implement and can be parallelized to be even more eﬃcient.
N.B.
The model selection step is performed with RPF while other estimation methods can
also be considered, which could potentially results in diﬀerent conclusions.
In this study, only normal priors are used while non-informative uniform priors can
also be used.

202
8.9. DISCUSSION

CHAPTER 9
Prediction and
Uncertainty Assessment
with Data Assimilation
S
equential data assimilation techniques are considered as invaluable tools due to
their capability to improve prediction performances. The conventional strategy
is to use reference models like SUCROS (Gu´erif and Duke, 1998, 2000; Launay and
Gu´erif, 2005) or CERES (Dente et al., 2008) and to integrate the information obtained
by remote sensing to enhance the prediction quality. A few methods were developed
under this perspective (see Dorigo et al. (2007) for a review). The forcing method
consists in replacing a state variable of the model by the observed data (Del´ecolle
et al. (1992); Dente et al. (2008)). However, a considerable part of the model state
variables cannot be or are not observed and thus cannot be updated simultaneously
at each time step. Moreover, the method does not take into account the observation
error, which should not be neglected considering the general lack of accuracy of remote
sensing data.
Another approach is to use the available observation data to recalibrate some model
parameters and / or initial states that may presumably vary with local conditions
(Bouman, 1992; Gu´erif and Duke, 2000; Launay and Gu´erif, 2005). The drawback of
this method is that it requires a suﬃcient number of data to perform the calibration,
which is often costly and diﬃcult to obtain.
Besides, the global approach of this
calibration step usually fails to capture and to maintain the system dynamics and thus
is unable to improve the prediction accuracy.
In other research domains, the data assimilation problem have been commonly
reformulated and studied with a Bayesian probabilistic perspective, which allows the
sequential estimation of model states and parameters simultaneously (Jazwinski, 1970;
Van Leeuwen and Evensen, 1996) in the framework of generalized state-space models.
The most important applications concern weather forecasting (e.g. Anderson (2001))
203

204
and hydrology (e.g. Reichle et al. (2002)).
In plant growth modelling, the ﬁrst attempt to adapt a relatively simple crop model
into this perspective was made by Makowski et al. (2004). The method implementa-
tion relies on a probabilistic framework of crop model which is used to derive prior
distributions of the model state variables and parameters at time steps with available
observations while taking into account uncertainty in model prediction. Conditionally
to the experimental observations and the observation error, posterior distributions are
deduced according to Bayes’ law. An updated prediction of the model state variables
can thus be inferred. The procedure is repeated at all measurement dates. Classical
ﬁltering methods used for this purpose are Ensemble Kalman Filter (see Jones and
Graham (2006) for an application in the context of crop models). However, among
many competing data assimilation approaches, the Particle Filters, have gained their
popularity because they are adaptive to nonlinearity and non-Gaussianity (see Naud
et al. (2007) for an application in the context of crop models).
However, one important constraint of this approach lies on the fact that it requires
the plant growth model described in a probabilistic framework, as a hidden Markov
model (Capp´e et al., 2005). The classical and complex crop models (like STICS (Bris-
son et al., 1998), APSIM (Keating et al., 2003), CERES (Jones and Kiniry, 1986),
etc.) are not built in this perspective and their stochastic reformulation is therefore
far from straightforward: the large number of involved processes may potentially lead
to a drastic increase in the number of parameters to model process errors. One simple
solution to circumvent this problem is to only consider observation errors (Gu´erif et al.,
2006), but it may hinder a proper update of hidden state variables.
In this context, aiming at integrating limited information from diﬀerent levels in
order to comprehend and to predict reasonable outcome, we propose in this chap-
ter a generic approach for data assimilation and prediction purpose in plant growth
modelling, which consists of 3 steps: sensitivity analysis, model calibration and data
assimilation. The performance of the data assimilation techniques with both Kalman
ﬁlter based methods and particle ﬁlter based methods are tested in the prediction of
biomass production and allocation in a dynamically evolving plant-growth model that
can be formalized as a nonlinear stochastic state-space model. We demonstrate that
this approach can also cope with classical complex crop models like STICS, originally
built in a deterministic framework.
The chapter is organized as follows. We ﬁrst outline the full methodology proposed
for plant growth model prediction which consists of three principal steps. For each step,
the concerning methods and algorithms are presented, followed by the application to
the LNAS and STICS models with real experimental scenarios. Experimental data
collected in a diﬀerent year, location or with a new cultivar are used for prediction.
The performances of the diﬀerent algorithms are compared and the prediction related
issues are discussed.

CHAPTER 9. DATA ASSIMILATION
205
9.1
Three-step approach for prediction
With the purpose of achieving proper predictions with plant growth models given
some experimental datasets, which can be considered as a way to provide prior knowl-
edge, in this thesis, we propose a three step approach which consists of parameter
selection, parameter estimation and data assimilation. In the ﬁrst place, the least
inﬂuential model parameters are screened using sensitivity analysis methods (Campo-
longo et al.Campolongo et al. (2007)) and are thus ﬁxed to either their recommended
values, or the center value of their prior conﬁdence intervals. Here, we consider cases
in which no satisfying problem speciﬁc prior distributions are available for the consid-
ered parameters, so that a ﬁrst calibration step is performed on a previously obtained
dataset in a similar context to provide appropriate prior distributions. Afterwards, the
obtained prior distributions are used for data assimilation applications during which
experimental data of early growth stages are assimilated to improve model prediction
at later stages. Of course, the preliminary calibration step can be skipped if satisfying
prior distributions are available.
9.1.1
Parameter selection
The estimation of the unknown parameters from the available experimental data is
an important step. The prediction performance of the model depends on the accuracy
of the model calibration (Makowski et al., 2006). However, it is unrealistic to estimate
all the model parameters based on a limited dataset, for identiﬁability problem may
occur, especially when a complex model with an important number of parameters is
considered. Moreover, it is suggested that by ﬁxing some parameters, the uncertainty
related to the estimated parameters could be reduced (Guo et al., 2006; Lamboni et al.,
2011). Therefore, a common strategy can be described as follows :
1. Select a subset of the model parameters and rank them according to sensitivity
analysis. Fix the least inﬂuential parameters to some nominal values (Wallach
et al., 2002; Monod et al., 2006).
2. Based on the ranking provided by sensitivity analysis, decide the number of
parameters to estimate based on the selection criteria (AIC / AICc / BIC /
DIC) according to the estimation method employed.
Sensitivity analysis
When a model contains a large number of parameters, as it is often the case for plant
growth models, parameter estimation based on limited experimental data is usually
considered to be a key issue which may aﬀect strongly the quality of model prediction
with important estimates uncertainty.
Therefore, sensitivity analysis (Campolongo
et al., 2007; Monod et al., 2006) can be applied in advance to select the most inﬂuential
parameters to be estimated, whereas those screened as the least inﬂuential ones can
be ﬁxed to any values in their domains, conventionally the mean values are chosen. In

206
9.1. THREE-STEP APPROACH
the context of sensitivity analysis, this method is called “screening” or “factor ﬁxing”
(Campolongo et al., 2007).
With this purpose, we implement the algorithm proposed by Wu et al. (2012)
to compute Sobol’s indices (ﬁrst order and total order) of all the parameters of the
studied model based on its deterministic version. The generalized least-square criteria
is chosen as the output for the variance decomposition and the parameters are ranked
according to their total-order indices. More details of this method can be found in
Section 6.1.
We remark that a potentially important issue in sensitivity analysis can be the
determination of the distributions representing the uncertainty in the inputs, partic-
ularly when the parameters are empirical with no explicit biological meaning, and
speciﬁc methods have to be devised for this purpose (Wernsd¨orfer et al., 2008). Gen-
erally speaking, in crop models, all the functions represent well-known processes, as
for sugar beet with the LNAS model or for winter wheat with the STICS model, with
an important literature, so that it is relatively easy to assess proper variation intervals
for the parameters. The question for us is the following: for each parameter, what is
the reasonable range of possible values, or when calibrating our system what would
be acceptable values for the parameters? In regards to such criteria, it also seems
appropriate to select the uniform distribution after assessing the appropriate variation
intervals. Moreover some tests were performed by increasing the range of the least im-
portant parameters while decreasing the range of the most important ones to check the
possible bias induced by the choice of the ranges, but it did not aﬀect the importance
ranking of the parameters, which is the result of interest for parameter screening.
Model selection criteria
Once the inﬂuence and the ranks of the parameters are determined, the parameter
selection problem is equivalent to a model selection problem in which candidate models
have diﬀerent numbers of parameters. From a model with only one parameter (the
most inﬂuential one) to the model with all the parameters, the number of parameters
is increased one by one with respect to the ranking of the parameters. In other words,
the most inﬂuential parameters have the priority to be included in the model. The
objective is to ﬁnd a balance between the complexity of the model and the quantity
of the data available based on an appropriate selection criterion. Indeed, by adding
more parameters to estimate, the likelihood can be increased. Unfortunately, this may
also entails overﬁtting. To avoid this problem, model selection criteria conventionally
take into account a penalty term for the number of parameters to estimate, such
as the Akaike Information Criterion (AIC), the corrected AIC (known as AICc which
contains an additional correction term for ﬁnite sample size), the Bayesian Information
Criterion (BIC) and the Deviance Information Criterion (DIC) usually considered for
Bayesian inference.
For the detailed description of these criteria, please refer to Section 6.2.

CHAPTER 9. DATA ASSIMILATION
207
9.1.2
Parameter estimation
In this step, numerous parameter estimation methods can be carried out based on
the calibration dataset. In this thesis, both Bayesian and frequentist perspectives are
considered. First, we distinguish the selected functional model parameters Θ1 from
the noise model parameters Θ2. A joint update scheme is adopted to estimate Θ1 and
Θ2 as follows (detailed in Section 6.3) :
the estimation of the selected functional parameters Θ1 are conducted with diﬀerent
methods, mainly with both MCMC based methods (Adaptive MCMC, Interacting
MCMC, DREAM) and ﬁltering-based SMC methods (UKF, EnKF, RPF). In addition,
we also employ one frequentist approach, the Generalized Least Squares estimator,
which is commonly used in plant growth model calibration.
Moreover, in order to put more emphasis on the calibration dataset and to reduce
the inﬂuence of the prior distribution, an iterative scheme is considered and formulated
as a variant of an EM type of algorithm. More precisely, the posterior distribution of
iteration k is regarded as the prior distribution for iteration k+1 as if the same dataset
is repeatedly obtained. In this way, the lack of available data can be mended. However,
since this iterative framework results in diminishing variances that approach 0, the
uncertainty related to the unknown parameters is assessed by parametric bootstrap.
(For a theoretical justiﬁcation of this approach when normal priors are used for the
selected parameters, please refer to Section 5.1).
Note that except with GLS, all the other methods allow an estimation of hidden
state variables combined with the estimation of Θ1. Once the estimation of Θ1 and
the hidden states variables of interest are converged, the modelling and measurement
noises Θ2 can thereafter be evaluated. Three methods are proposed in this thesis to
evaluate the noise parameters : noise parameter selection, noise parameter update with
conjugate priors for MCMC based methods and empirical estimation (see Chapter 6
for detailed descriptions).
Based on our tests presented in Chapter 8, we propose in Table 10.1 a strategy with
the objective to select the most appropriate method according to the type of situation,
the speciﬁc need / emphasis in this step.
9.1.3
Data assimilation
In this prediction step, a new experimental dataset, comparable to the calibration
dataset (for instance same type of crop but observed in a diﬀerent year, or at a diﬀerent
location, or of diﬀerent genotype...) with few early measurements is introduced. With
the purpose of performing predictions of yield or other state variables of interest, an
on-line ﬁltering approach (such as EnKF, CPF/RPF and UKF) can again be carried
out by regarding the results of the calibration step as prior information (Chen and
Courn`ede, 2014). In this step, the probability density is represented by a large number
of samples (particles) which evolve with time. Hence, after a short readjustment period
while model parameters and state variables are updated based on the available mea-
surements, the particles continue to propagate so as to forecast the system evolution
and to evaluate the uncertainty related to these state variables of interest.

208
9.2. APPLICATION TO THE LNAS MODEL
Conditions
Recommended method(s)
•
Time constraint, no reliable prior,
only point estimation is needed
⇒
GLS
•
Time constraint, slightly non linear model
⇒
UKF
•
Unknown parameter vector with important dimension
⇒
DREAM
•
Precision of the mean value
⇒
Interacting MCMC
•
Reliable prior, need precise CI%, no time constraint,
implementation expertise in MCMC
⇒
One long run AMwG
•
Reliable prior, time constraint
⇒
CPF, EnKF
•
Less reliable priors
⇒
Iterative SMC, especially ICPF/IRPF
Table 9.1: Selection strategy for estimation method.
Note that as a stochastic approach, the prediction and the data assimilation results
entail Monte Carlo errors. To reduce the uncertainty related to both the mean esti-
mates and the variance estimates, in our implementation, a large number of particles
are chosen (350 000) which generally ensure an appropriate precision.
Comparison criteria
For method comparison purpose, the Root Mean Squared Error for Prediction (RM-
SEP) and Relative Error (RE) are chosen as the criteria to evaluate the quality of
prediction in our application, for they seem to be the most suitable considering the
structure of our data.
If n denotes the total number of prediction dates, ˆYi and Y exp
i
denote the mean
predicted value and the experimental observation for the ith prediction date respec-
tively, then for each type of observation (Qg and Qr in our application), the RMSEP
is deﬁned as :
RMSEP =
q
E[(Y exp −ˆY )2].
The unbiased estimator of RMSEP can be deﬁned as follows (Wallach et al., 2006) :
ˆ
RMSEP =
v
u
u
t1
n
n
X
i=1
(ˆYi −Y exp
i
)2.
The RE can be obtained by :
RE =
1
Y exp
i
|ˆYi −Y exp
i
|.
9.2
Application to the LNAS model
9.2.1
Experimental data
The data used for this study were obtained by the French institute for sugar beet
research (ITB, Paris, France) in 2006, 2008 and 2010 with slightly diﬀerent cultivars

CHAPTER 9. DATA ASSIMILATION
209
and in diﬀerent locations with diﬀerent observed densities (details of the experimental
protocols can be found respectively in Lemaire et al. (2008), Lemaire et al. (2009) and
Baey et al. (2013a)). For the test case, the 2010 dataset is chosen for estimation since
more observation points are available compared to the other ﬁve datasets (of course, in
real applications, the older datasets are supposed to be used for parameter estimation).
Dry matter of root and leaves were collected on 50 plants at 14 dates (in days after
sowing):
O2010 = {54, 68, 76, 83, 90, 98, 104, 110, 118, 125, 132, 139, 145, 160} .
whereas for assimilation and prediction, other datasets (2006 and 2008) are used. The
same type of observations were made at 7 diﬀerent dates given by
O2006 = {54, 59, 66, 88, 114, 142, 198} ,
and
O2008 = {39, 60, 67, 75, 88, 122, 158} ,
respectively. For each plant, the green foliage mass denoted by Qg and the root com-
partment mass denoted by Qr were measured. The observation vector Yn is obtained
by averaging each data on all the samples and extrapolated at m2 level by multiplying
by the observed density.
We note that among the four 2008 datasets used for assimilation in diﬀerent
density conditions, three of them are of the same genotype as in the 2010 dataset
(11.9 plants/m2) Radar, but with diﬀerent density conditions (5.4 plants/m2, 10.9
plants/m2, 16.4 plants/m2). The other 2008 dataset is of a diﬀerent genotype Harmo-
nia with a density of 10.7 plants/m2. As for the 2006 dataset, the density condition is
9.6 plants/m2.
9.2.2
Results and method comparison
Step 1.1: Parameter ranking by Sensitivity Analysis
Sobol’s indices (ﬁrst order and total order) of all the functional parameters of the
LNAS model (without counting the noises parameters) were computed using a gen-
eralized least-squares criterion as output (see Courn`ede et al. (2013)). According to
the sensitivity analysis result, we screened the parameters µsen and ssen, as their total
order indices are all below 0.02. We note that for these two senescence related param-
eters, some complementary experimental data can be used to determine appropriate
values. For the six other functional parameters, we choose to use the model selection
approach to determine which of them will be estimated from the experimental data.

210
9.2. APPLICATION TO THE LNAS MODEL
Figure 9.1: Comparison of the ﬁrst and total order indices for parameters of the LNAS
model: µa, λ, γ0, γf, µγ, sa, µsen, ssen.
Step 1.2: Model selection
1
2
3
4
5
6
320
325
330
335
Number of functional parameters
DIC
(a) Bayesian approaches
1
2
3
4
5
6
342
344
346
348
350
Number of functional parameters
BIC
AICc
AIC
(b) Iterative approaches
Figure 9.2: (a): Model selection based on the DIC with σγγ ﬁxed at 0.05 for the
Bayesian approaches. (b): Model selection based on the AIC, the AICc and the BIC
for the iterative approaches with all the noise parameters estimated.
Settings :
Based on the sensitivity analysis results, the full unknown parameter vector for the
deterministic part of the model is assumed to be Θ1 = (µγ, λ, µa, γ0, γf, sa) and the
unknown noise parameter vector is Θ2 = (σQ, σγ, σg, σr). To determine the number
of parameters to estimate, a model selection is conducted. RPF is performed with
diﬀerent conﬁgurations of the LNAS model to determine the best ﬁtting. Due to the

CHAPTER 9. DATA ASSIMILATION
211
identiﬁability issue of the modelling noise parameter σγγ, its value is ﬁxed for the
Bayesian approaches, while for the frequentist iterative approaches, all the four noise
parameters are estimated. The implementation details and detailed test results can
be found in Section 8.8.2 for Bayesian inference and Section 8.8.3 respectively for the
iterative approaches.
Observations and remarks :
Figure 9.2 sums up the model selection results. For the Bayesian approaches, the
Deviance Information Criterion suggests that the model of three functional param-
eters outperforms the others. On the other hand, for the iterative approaches, the
three model selection criteria give diﬀerent conclusions. For the purpose of illustrat-
ing the robustness of the proposed iterative approach, the model with six functional
parameters is selected and considered as the most robust one. Moreover, the AIC are
generally preferred in a prediction context.
Step 2: Parameter Estimation
For this second step, we can perform the parameter estimation with any of the
methods presented in Chapters 4 and 5 based on the 2010 experimental dataset. Below,
we recall the results obtained in Chapter 8 for the two types of approaches :
– the Bayesian approaches with three functional parameters estimated {µa, µγ, γ0}
as suggested by the DIC,
– the iterative approaches with six functional parameters estimated {µa, λ, µγ, σ2
γ, γ0, γf}
as suggested by the AIC and AICc.
Note that the estimates given by the frequentist method GLS are also listed as a
reference.
Step 2a: Parameter Estimation with Bayesian approaches
The Bayesian inference is carried out based on the 2010 experimental dataset. The
Bayesian approaches presented in Chapter 4 are implemented, the conﬁguration and
the implementation details of which are detailed in Section 8.8.2. Here we simply recall
the obtained results (Table 8.32).
Step 2b: Parameter Estimation with iterative approaches
In the same fashion, the iterative approaches presented in Chapter 5 are applied
to the 2010 dataset. The obtained results are summarized in Table 8.39. For more
details regarding the implementation, please refer to Section 8.8.3.

212
9.2. APPLICATION TO THE LNAS MODEL
Prior
AMwG
DREAM
Interacting
µ0
σ0
E(P|Y )
p
V(P|Y )
E(P|Y )
p
V(P|Y )
E(P|Y )
p
V(P|Y )
µa
3.40
0.20
3.553
0.079
3.554
0.071
3.554
0.059
γ0
0.90
0.10
0.8612
0.0341
0.8599
0.0302
0.8594
0.0236
µγ
650.0
40.0
658.08
28.18
658.98
25.22
659.31
19.90
σg
σ2
g ∼IG(21, 2)
0.148
0.002
0.151
0.002
0.149
0.002
σr
σ2
r ∼IG(21, 2)
0.165
0.002
0.168
0.003
0.164
0.002
σq
σ2
q ∼IG(56, 2)
0.039
0.001
0.040
0.002
0.038
0.001
−2L(¯θ)
348.52
344.63
344.89
344.72
DIC
343.72
321.77
322.25
322.94
GLS∗
RPF
EnKF
UKF
E(P|Y )
p
V(P|Y )
E(P|Y )
p
V(P|Y )
E(P|Y )
p
V(P|Y )
E(P|Y )
p
V(P|Y )
µa
3.653
0.102
3.554
0.078
3.557
0.062
3.410
0.090
γ0
0.8120
0.0354
0.8607
0.0340
0.8995
0.0876
0.8717
0.0299
µγ
707.47
36.44
659.41
28.17
652.00
33.48
666.20
28.33
σg
0.138
-
0.152
0.002
0.148
0.003
0.167
0.005
σr
0.155
-
0.171
0.002
0.165
0.003
0.191
0.008
σq
-
-
0.060
0.003
0.045
0.004
0.065
0.007
−2L(¯θ)
338.186
343.82
357.34
360.20
DIC
-
321.80
322.51
332.17
Table 9.2:
Comparison of the estimations resulting from the one chain AMwG,
DREAM, Interacting MCMC, GLS, RPF, EnKF and UKF in the case of the 2010
experimental dataset with noise parameter σγγ ﬁxed to 0.05. GLS∗: reference results.

CHAPTER 9. DATA ASSIMILATION
213
IEnKF
IRPF
IUKF
IAMwG
GLS∗
E(E(P|Y ))
p
V(E(P|Y ))
E(E(P|Y ))
p
V(E(P|Y ))
E(E(P|Y ))
p
V(E(P|Y ))
E(E(P|Y ))
p
V(E(P|Y ))
E(P|Y )
p
V(P|Y )
µa
3.600
0.154
3.564
0.123
3.900
0.270
3.563
0.169
3.591
0.142
λ
60.16
6.51
59.55
3.13
60.18
6.49
59.40
3.57
59.49
7.96
γ0
0.830
0.087
0.840
0.044
0.800
0.064
0.849
0.062
0.824
0.112
γf
0.206
0.058
0.194
0.053
0.216
0.048
0.188
0.077
0.202
0.078
µγ
639.39
83.28
642.33
62.40
579.98
73.75
642.01
73.64
651.87
77.20
sa
276.18
149.83
308.69
109.95
338.31
44.89
319.96
181.97
277.72
228.59
σg
0.137
0.028
0.142
0.032
0.156
0.070
0.138
0.006
0.132
-
σr
0.166
0.027
0.165
0.024
0.193
0.092
0.152
0.005
0.149
-
σq
0.040
0.004
0.042
0.008
0.052
0.048
0.040
0.002
-
-
σγγ
0.061
0.002
0.064
0.015
0.072
0.031
0.058
0.003
-
-
−2L
334.75
-
329.46
-
353.37
-
333.44
-
329.97
-
Table 9.3: Estimated values and standard deviations for all the parameters of the
LNAS model provided by the iterative approaches as an EM variant with IEnKF,
IRPF, IUKF and IAMwG to perform the E-step. GLS∗: reference results.
Step 3: Data Assimilation and model prediction
In this step, a SMC ﬁltering method is used to perform data assimilation and model
prediction based on a new dataset. The model calibrations carried out by both the
Bayesian inference and the iterative approaches are considered.
Step 3a: Data Assimilation with the calibrations performed by Bayesian
inference
We ﬁrst investigate the predictive capacity of the Bayesian estimates. The posterior
distribution resulting from the Bayesian inference was used as prior information in the
assimilation step, in which the (classical) CPF algorithm is applied.
Data assimilation and model prediction with three functional parameters
In this ﬁrst attempt, the optimized conﬁguration obtained in the previous model se-
lection step (estimation with three functional parameters) is adopted. The objective
is to compare the prediction results with and without data assimilation of data from
the early growth stages.
Settings :
For both the 2006 and 2008 datasets, 500000 particles are simulated, all but the
last two measurements (corresponding to data until day 114 for the 2006 dataset, and
until day 88 for the 2008 dataset) are used to update and correct the parameter and the
state estimates. The propagation of particles through the stochastic dynamic model is
carried on without any further correction until day 198 for the 2006 dataset and day 158

214
9.2. APPLICATION TO THE LNAS MODEL
for the 2008 dataset. At last, the simulated values of the state variables Qg and Qr on
day 142 and day 198 (resp. day 122 and day 158 for the 2008 dataset) given by all the
particles as well as their associated weights are used to build the posterior predictive
distributions, from which both the mean prediction and the credibility interval are
obtained.
In order to provide reference values of the prediction without assimilation, an Un-
certainty Analysis (UA) is performed. 500000 particles are initialized in the same way
as in the CPF approach, from the prior distribution given by the parameter estima-
tion step, and the distribution of the model outputs of interest is approximated by
propagating independently through the stochastic dynamic system all the particles.
No parameter or state update is performed from the experimental data of the early
stages.
Observations and remarks :
The prediction results based on the Bayesian estimations seem to be unsatisfac-
tory after being performed with both the 2006 and 2008 datasets (Tables 9.4 and 9.5
respectively). Almost all the predictions relative errors are above 10% for the 2006
dataset, which is quite disappointing. The relative errors for the Qg prediction of the
2008 dataset appear also to be quite signiﬁcant. The estimation of EnKF which is
associated with larger variance in the calibration step seems to show slightly better
performance in the prediction step. Considering that the estimations given by AMwG,
DREAM and RPF in the previous step are very close, the similarity of their prediction
results is understandable.
Real value
AMwG
DREAM
RPF
RE (%)
Std.
RE (%)
Std.
RE (%)
Std.
Qg (t142)
355.2
21.9%
85.2
22.2%
84.4
21.8%
85.4
Qg (t198)
320.6
25.1%
76.3
25.0%
74.8
25.2%
76.0
Qr (t142)
1459.2
24.8%
302.2
24.7%
300.0
24.9%
301.9
Qr (t198)
2400.0
14.6%
454.1
14.6%
453.2
14.7%
453.8
GLS∗
Interacting
EnKF
UKF
RE (%)
Std.
RE (%)
Std.
RE (%)
Std.
RE (%)
Std.
20.0%
79.1
30.3%
92.2
11.8%
78.4
19.9%
95.4
24.1%
71.5
32.2%
86.3
17.9%
72.8
22.3%
88.0
24.3%
284.9
26.9%
301.2
24.9%
302.0
17.8%
329.0
14.5%
430.6
16.2%
454.4
15.4%
454.2
9.8%
494.1
Table 9.4: Comparison of the prediction capacity of the estimations resulting from the
one chain AMwG, DREAM, Interacting MCMC, GLS, RPF, EnKF and UKF in the
case of the 2006 experimental dataset with data assimilation. RE: relative error in %.
GLS∗: the GLS estimates are given as a reference.

CHAPTER 9. DATA ASSIMILATION
215
Figure 9.3: Comparison of the predictions for Qr of the LNAS model given by the
CPF approach with the RPF’s estimates and predictions given by the uncertainty
analysis (UA) based on the 2006 dataset. The red squares correspond to the assimilated
experimental data while the pink squares represent the data used for validation.
Real value
AMwG
DREAM
RPF
RE (%)
Std.
RE (%)
Std.
RE (%)
Std.
Qg (t122)
373.5
22.1%
68.2
22.3%
68.0
22.2%
68.5
Qg (t158)
380.6
24.0%
71.3
24.1%
70.2
24.2%
71.1
Qr (t122)
1559.1
6.9%
242.5
6.6%
241.8
6.8%
242.6
Qr (t158)
2327.7
8.3%
357.7
8.4%
357.3
8.4%
357.6
GLS∗
Interacting
EnKF
UKF
RE (%)
Std.
RE (%)
Std.
RE (%)
Std.
RE (%)
Std.
20.5%
61.7
31.1%
69.4
19.9%
63.3
24.8%
79.3
23.8%
69.3
32.8%
73.2
25.3%
23.7
25.3%
89.5
7.3%
233.2
8.7%
243.5
6.8%
244.6
11.7%
329.0
9.5%
349.1
10.3%
357.7
10.4%
357.9
5.8%
494.1
Table 9.5: Comparison of the prediction capacity of the estimations resulting from the
one chain AMwG, DREAM, Interacting MCMC, GLS, RPF, EnKF and UKF in the
case of the 2008 experimental dataset with data assimilation. RE: relative error in %.
GLS∗: the GLS estimates are given as a reference.
Figure 9.3 displays the prediction results with and without data assimilation when
the calibration was performed with the RPF method. We remark the small reduction
of the uncertainties associated to the prediction with DA compared to the results of
UA. In this concrete example, DA did not apparently improve much the prediction
performance. Indeed, most methods showed the same poor prediction performance.
The prediction results performed based on diﬀerent calibrations are comparable for
both Qr and Qg in both the 2006 and 2008 datasets. It could be resulted from either

216
9.2. APPLICATION TO THE LNAS MODEL
the lack of data, or the misspeciﬁcation of the model, or the lack of liberty to re-
adjust the model with only three functional parameters. The ﬁrst two possibilities are
diﬃcult to verify, while the last possibility can be veriﬁed by taking into account all
the possible candidate models selected in the ﬁrst step.
Data assimilation and model prediction with model comparison
The following test is conducted to identify the best candidate model (with diﬀerent
numbers of parameters calibrated in step 2 and updated in step 3) based on the
perspective of data assimilation in the prediction step.
Settings :
Six conﬁgurations of the LNAS model with diﬀerent numbers of functional param-
eters being calibrated in step 2 and updated in step 3 are evaluated with regards to
their prediction performance. RPF is selected to perform the calibration based on the
2010 dataset, and CPF is used to perform the data assimilation and prediction for
all the six candidate models. For both situations, 350 000 particles are used. In the
following, we present the prediction results performed based on the 2006 experimental
dataset (density 9.6) and on the 2008 experimental dataset (density 10.9). The average
estimates are given with their corresponding 95% credibility intervals obtained with
the posterior distributions.
The Root Mean Squared Error for Prediction (RMSEP) and Relative Error (RE)
are used as the criterion to evaluate the quality of prediction for model comparison
purpose.
Nb of
1
2
3
parameters d
RE (%)
Std.
RE (%)
Std.
RE (%)
Std.
Qg (t142)
67.9%
96.6
44.6%
88.4
21.8%
85.4
Qg (t198)
64.5%
84.6
44.1%
79.4
25.2%
76.0
Qr (t142)
31.2%
377.8
28.3%
349.9
24.9%
301.9
Qr (t198)
19.1%
564.8
17.5%
516.6
14.7%
453.8
4
5
6
RE (%)
Std.
RE (%)
Std.
RE (%)
Std.
Qg (t122)
7.2%
64.5
11.1%
68.6
15.6%
73.3
Qg (t158)
9.5%
56.1
14.2%
70.1
11.4%
67.1
Qr (t122)
8.7%
261.0
6.2%
312.3
12.7%
302.3
Qr (t158)
7.6%
426.9
4.5%
468.9
8.7%
456.4
Table 9.6: Comparison of the prediction capacity with diﬀerent numbers of parameters
estimated by RPF in the calibration step and updated in the data assimilation step
by CPF based on the 2006 experimental dataset. RE: relative error in %.

CHAPTER 9. DATA ASSIMILATION
217
Figure 9.4: Comparison of model prediction capacity of diﬀerent numbers of parame-
ters estimated and updated by RPF, evaluated by Root Mean Squared Error of Pre-
diction (RMSEP) based on the 2006 datasets with assimilation of data at the early
growth stages.
Observations and remarks :
According to Table 9.6 and Table 9.7, we notice that the selected conﬁguration in
the ﬁrst step (model selection for the calibration) did not result in the best performance
in the data assimilation and prediction step. For the 2006 dataset, the best prediction
result is obtained with the models with 4 and 5 parameters. For the 2008 dataset,
again the model with 4 parameters appears to provide the most accurate prediction.
Nb of
1
2
3
parameters d
RE (%)
Std.
RE (%)
Std.
RE (%)
Std.
Qg (t122)
60.4%
69.1
26.4%
68.8
22.2%
68.5
Qg (t158)
54.0%
72.0
42.0%
71.0
24.0%
71.1
Qr (t122)
11.0%
288.3
8.2%
270.5
6.8%
242.6
Qr (t158)
12.6%
422.0
9.3%
395.3
8.4%
357.6
4
5
6
RE (%)
Std.
RE (%)
Std.
RE (%)
Std.
Qg (t122)
6.3%
58.1
15.9%
66.2
13.9%
65.5
Qg (t158)
4.8%
58.9
18.3%
70.9
14.2%
69.2
Qr (t122)
2.6%
250.5
5.4%
241.1
4.8%
236.7
Qr (t158)
3.4%
370.2
7.0%
355.7
6.0%
350.2
Table 9.7: Comparison of the prediction capacity with diﬀerent numbers of parameters
estimated by RPF in the calibration step and updated in the data assimilation step
by CPF based on the 2008 experimental dataset (density 10.9). RE: relative error in
%.

218
9.2. APPLICATION TO THE LNAS MODEL
Figure 9.5: Comparison of model prediction capacity of diﬀerent numbers of parame-
ters estimated and updated by RPF, evaluated by Root Mean Squared Error of Pre-
diction (RMSEP) based on the 2008 datasets with assimilation of data at the early
growth stages.
Figure 9.4 and Figure 9.5 indicate that the model selection results with the per-
spectives of calibration and of prediction may not share the same conclusion, especially
when models with fewer parameters are preferred in the calibration step since the
penalty term for the number of parameters to be estimated is important in the selec-
tion criteria. While in the prediction step, it seems that models with more functional
parameters calibrated tend to outperform those with less parameters. One potential
issue is that with limited data available to perform the calibration, models with more
parameters could entail identiﬁability and over-ﬁtting problems. Undoubtedly, it is
also important to note that this model comparison conducted based on the evaluation
of prediction capacity is only a posterior comparison, in real applications, the choice
regarding the model conﬁguration should be made before the assimilation step. This
issue is further discussed in Section 9.2.8.
Step 3b:
Data Assimilation with the calibration performed by iterative
approaches
Regarding the estimates of the iterative approaches, the model with six functional
parameters was selected in the calibration step. Given the fact that generally, the
IRPF estimates obtain often better likelihood evaluation than those of the other it-
erative approaches, the prediction performance based solely on the IRPF estimates is
thoroughly investigated in the ﬁrst place.
Settings :
Similar to the settings used with the Bayesian estimates for prediction purpose,
based on the parameter estimation results of the 2010 dataset, we compare the predic-
tive capacity of the model for the 2006 and the 2008 experiments, with and without
data assimilation (denoted DA and UA respectively), regarding the last two observa-
tions (t142 and t198 for 2006 and t122 and t158 for 2008). The RPF approach is used

CHAPTER 9. DATA ASSIMILATION
219
with 350 000 particles to perform DA. The average estimates are given with their
corresponding 95% credibility intervals obtained with the posterior distributions.
Figure 9.6: Comparison of the predictions for Qg with and without data assimilation
regarding the 2006 dataset. Based on the calibration performed by IRPF, the data
assimilation is performed by the RPF approach and the predictions without data
assimilation is performed by the uncertainty analysis. The red squares correspond to
the assimilated experimental data while the pink squares represent the data used for
validation.
Observations and remarks :
Although the six experiments are quite diﬀerent (diﬀerent locations, in diﬀerent
years, and diﬀerent cultivars), the proposed RPF-based data assimilation approach
was proved to provide fair predictions in most cases and managed to reduce the pre-
diction errors compared to the results obtained with UA (without data assimilation),
as demonstrated by Figure 9.6. These results conﬁrm the assumption that by esti-
mating only the three most inﬂuential functional parameters while ﬁxing the others
to recommended values like in the previous test case, the data assimilation cannot be
performed eﬃciently. It is particularly spectacular for the leaf biomass (Qg) prediction
(Table 9.8, Table 9.15).
Real Data 2006
DA estimates
95% CI
UA estimates
95% CI
(relative error in %)
(relative error in %)
Qg (t142)
355.2
357.5 (0.7%)
[202.5; 518.6]
513.3 (44.5%)
[256.0; 770.3]
Qg (t198)
320.6
339.4 (5.9%)
[174.5; 516.2]
459.9 (43.4%)
[226.3; 693.7]
Qr (t142)
1459.2
1583.8 (8.5%)
[1238.8; 1979.3]
1928.7 (32.2%)
[1222.0; 2639.4]
Qr (t198)
2400.0
2469.5 (2.9%)
[1933.5; 3080.4]
2893.8 (20.6%)
[1849.0; 3938.3]
Table 9.8: Comparison of the prediction results of the LNAS model with and without
data assimilation based on the 2006 dataset (density 9.6).

220
9.2. APPLICATION TO THE LNAS MODEL
Real Data 2008
DA estimates
95% CI
UA estimates
95% CI
(relative error in %)
(relative error in %)
Qg (t122)
373.5
403.6 (8.1%)
[294.4; 526.0]
521.7 (39.7%)
[253.7; 789.7]
Qg (t158)
380.6
408.7 (7.4%)
[288.0; 570.3]
510.6 (34.2%)
[247.1; 774.1]
Qr (t122)
1559.1
1466.7 (5.9%)
[1094.4; 1920.6]
1673.0 (7.3%)
[1053.6; 2292.3]
Qr (t158)
2327.7
2187.6 ( 6.0%)
[1610.1; 2889.2]
2349.5 (0.9%)
[1494.1; 3205.0]
Table 9.9: Comparison of the prediction results of the LNAS model with and without
data assimilation based on the 2008 dataset (density 10.9).
Real Data 2008
ICPF estimates
95% CI
UA estimates
95% CI
(relative error in %)
(relative error in %)
Qg (t122)
385.8
407.2 (5.6%)
[324.4; 510.1]
525.9 (36.3%)
[379.6; 672.3]
Qg (t158)
345.1
416.9 (20.8%)
[315.9; 552.7]
502.0 (45.5%)
[358.9; 645.0]⋆
Qr (t122)
1326.8
1410.6 (6.3%)
[1200.4; 1641.2]
1654.5 (24.7%)
[1372.5; 1936.6]⋆
Qr (t158)
1778.9
2051.1 (15.3%)
[1725.5; 2417.3]
2350.6 (32.1%)
[1924.6; 2776.7]⋆
Table 9.10: Comparison of model prediction with and without data assimilation based
on the 2008 dataset variety Harmonia (density 10.7).
⋆: the predicted credibility
interval does not contain the real observed data.
Real Data 2008
DA estimates
95% CI
UA estimates
95% CI
(relative error in %)
(relative error in %)
Qg (t122)
318.6
407.5 (27.9%)
[279.7; 555.1]
552.8 (73.5%)
[403.1; 702.5]⋆
Qg (t158)
385.5
399.5 (3.6%)
[269.9; 548.2]
523.6 (35.2%)
[378.2; 669.0]
Qr (t122)
1319.5
1482.5 (12.35%)
[1158.0; 1659.2]
1689.2 (28.0%)
[1401.5; 1977.0]⋆
Qr (t158)
2368.5
2260.9 (4.5%)
[1906.5; 2560.7]
2416.0 (2.0%)
[1983.4; 2848.7]
Table 9.11: Comparison of the prediction results of the LNAS model with and without
data assimilation based on the 2008 dataset (density 16.4). ⋆: the predicted credibility
interval does not contain the real observed data.
Real Data 2008
DA estimates
95% CI
UA estimates
95% CI
(relative error in %)
(relative error in %)
Qg (t122)
297.6
351.1 (18.0%)
[276.0; 486.6]
483.0 (62.3%)
[342.1; 624.0]⋆
Qg (t158)
408.1
387.4 (5.1%)
[268.9; 493.8]
467.5 (14.6%)
[328.5; 606.6]
Qr (t122)
1551.4
1462.7 (5.7%)
[1288.8; 1632.0]
1590.7 (2.5%)
[1316.9; 1864.5]
Qr (t158)
2535.0
2266.5 (10.6%)
[1946.6; 2585.3]
2285.6 (9.8%)
[1886.3; 2684.8]
Table 9.12: Comparison of the prediction results of the LNAS model with and without
data assimilation based on the 2008 dataset (density 5.4). ⋆: the predicted credibility
interval does not contain the real observed data.
Tables 9.8 to 9.12 illustrate the prediction results of the two methods (with or
without data assimilation) for diﬀerent experiments. According to the results based on
the 2006 dataset (Table 9.8) and on the 2008 dataset with observed density 10.9 (Table
9.9), the prediction results are clearly improved both in terms of the mean prediction

CHAPTER 9. DATA ASSIMILATION
221
and the associated uncertainty assessment for nearly all the predictions given by the
CPF-based approach compared to those provided by UA. All the predictions have a
relative error close or inferior to 10%, which indicates that the ICPF calibration results
combined with CPF-based data assimilation method result in an excellent predictive
performance. Although in Table 9.9, the mean predictions of UA are already quite
accurate, the standard deviations of the DA predictions are much smaller than those
given by the UA. Considering the important level of observation error (≈15%), the
uncertainty associated to the mean estimates is indeed crucial in yield prediction. The
proposed credibility intervals all include the real value of the last two measurements
and are generally narrower than those given by the UA.
On the other hand, as suggested by Figure 9.6, the 95% credibility interval provided
by the UA can be considered non-reliable since it does not always contain the real mea-
surement values in several cases (cf. Table 9.11, Table 9.12 and Table 9.10). These
cases correspond to very diﬀerent crop densities compared to the 2010 dataset used
for the calibration (16.4 and 5.4 plants/m2 respectively compared to 11.9 plants/m2)
or a diﬀerent cultivar (Harmonia compared to Rada). The limitation of the simple
prediction approach (performed by UA) can thus be recognized, since the prediction
conditions are out of the strict range of validity of the domain. Therefore, it is im-
portant to learn that the data assimilation approach broadens the range of applicable
cases and enhances the model predictive capacity.
9.2.3
Inﬂuence of the noise level
Figure 9.7: Decomposition of the uncertainties related to the prediction of Qr in 2006
(density 9.6) performed with data assimilation based on the ICPF estimates.
We highlight that when the step 3 is performed with the RPF approach, the likeli-
hood of the observations is considered known explicitly, thus we are able to decompose
the uncertainty associated to the prediction into two parts, one related to the parame-

222
9.2. APPLICATION TO THE LNAS MODEL
ter and modelling errors, and the other due to the observation errors, as demonstrated
by Figure 9.7.
Undeniably, the noise related to parameters play a crucial role in the uncertainty
assessment of the predictions, however, we are not certain neither if the Gaussian
assumption holds for the observation likelihood function, nor if the noise level remains
the same for observations made in diﬀerent locations or in diﬀerent years. Bearing this
thought in mind, the RPF and CPF approaches for data assimilation and uncertainty
propagation are compared, three observation noise levels are taken into account.
Settings :
Three assumptions for observation noise level, 0.01, 0.08 and 0.15, are tested for
the data assimilation step, performed with CPF (kernel estimator, considering the
likelihood function unknown) and RPF (considering the likelihood function known)
with 350 000 particles.
Small noise (1%)
Medium noise (8%)
Large noise (15%)
DA(RPF)
relative error in %
Std.
relative error in %
Std.
relative error in %
Std.
Qg (t142)
0.9%
15.8
1.2%
36.1
0.8%
80.5
Qg (t198)
8.1%
15.1
6.9%
34.3
5.9%
72.1
Qr (t142)
4.0%
51.4
6.6%
142.2
8.9%
205.3
Qr (t198)
3.8%
58.3
4.1%
189.4
5.2%
317.9
DA(CPF)
relative error in %
Std.
relative error in %
Std.
relative error in %
Std.
Qg (t142)
0.8%
15.9
2.2%
38.4
2.1%
82.4
Qg (t198)
10.2%
15.3
7.0%
36.1
7.2%
75.5
Qr (t142)
4.8%
52.9
12.9%
146.7
7.9%
238.2
Qr (t198)
4.2%
59.8
7.3%
187.3
4.9%
344.4
UA
relative error in %
Std.
relative error in %
Std.
relative error in %
Std.
Qg (t142)
44.7%
53.6
44.7%
89.8
44.3%
138.3
Qg (t198)
43.5%
48.1
43.6%
74.3
43.1%
116.8
Qr (t142)
32.3%
102.5
32.3%
193.8
32.0%
354.2
Qr (t198)
20.1%
136.2
20.2%
282.1
20.2%
522.3
Table 9.13: Comparison of model prediction errors and predicted standard deviation
(Std.) with and without data assimilation for the LNAS model based on the 2006
dataset (density 9.6) according to diﬀerent assumptions of noise levels.
Observations and remarks :
According to our tests (Table 9.13), the uncertainty associated to the prediction
results is quite sensitive to the level of observation noises compared to the mean pre-
dicted values. The prediction results obtained with Gaussian assumptions appear to
be closer to the real measurements and more stable when the noise level assumption
changes, which suggests a small advantage of the RPF approach.
Another meaningful thought is that since the level of noise parameter evaluated
on one year may not represent properly the corresponding level in another year or in

CHAPTER 9. DATA ASSIMILATION
223
a diﬀerent location, applying the same level of noises in the assimilation step with a
diﬀerent dataset is debatable. Further studies are hence needed to address the inﬂuence
of the observation noise level to the prediction quality.
We remark that in the LNAS model, we opt for a multiplicative noise model while
additive models and log normal models are also widely used and could also be tested.
Preliminary tests have suggested better performances of the multiplicative noise model
compared to the additive one in the calibration step. However, further investigation
is still required.
9.2.4
Impact of the calibration precision
Prediction performance of calibrations performed by IEnKF, IRPF, IUKF
and IAMwG
Regarding the prediction based on the iterative approaches, as illustrated by Table
9.14, the best performance in the evaluation of the log-likelihood was achieved by the
IRPF estimates. The same conclusion holds for the AICc and the BIC evaluations as
well. In the following test, the goal is to identify the diﬀerence of the predictive perfor-
mance only due to the estimation precision in the calibration step (prior information
of the assimilation step).
In this ﬁrst study case, we choose the RPF as the only algorithm to perform the
assimilation step. The prediction performed by EnKF and UKF are further compared
in Section 9.2.5. Another thought-provoking comparison between the prior information
given by the RPF and the IRPF algorithm with the same conﬁguration in the context
of data assimilation problems can be found in Chen et al. (2013a).
Settings :
Based on the 2006 experimental dataset (density 9.6) and the 2008 experimental
dataset (density 10.9), the calibration carried out by the iterative approaches are com-
pared with regards to their prediction capacity. RPF with 350 000 particles is used
to perform the data assimilation and the prediction. The uncertainty analysis is also
conducted to illustrate the predictive performance of the raw estimates without the
assimilation of data obtained at early growth stages. The Root Mean Squared Error
for Prediction (RMSEP) is used as the criterion to evaluate the quality of prediction.
Observations and remarks :
Generally speaking the assimilation step has well established its value as demon-
strated by Table 9.14 compared to the prediction without assimilation (UA). The es-
timation relative error was greatly reduced when data assimilation was performed. In
the meantime, the uncertainties (standard errors) associated to the prediction were also
signiﬁcantly decreased in all cases with the assimilation of data from the early growth
stages. IAMwG and IRPF estimates resulted in similar estimations, with IAMwG a
slightly better prediction for Qr and IRPF a small advantage in Qg prediction.

224
9.2. APPLICATION TO THE LNAS MODEL
Estimation methods
IRPF
IEnKF
IUKF
IAMwG
DA
UA
DA
UA
DA
UA
DA
UA
Qg (t142)
Relative error
0.7%
44.5%
3.2%
45.8%
5.7%
55.6%
0.8%
45.1%
Std.
80.5
128.7
80.8
163.7
89.7
165.0
82.7
162.8
Qg (t198)
Relative error
5.9%
43.4%
9.8%
46.5%
12.1%
58.5%
6.1%
43.2%
Std.
72.1
116.8
75.1
141.2
94.3
144.2
77.4
149.7
Qr (t142)
Relative error
8.5%
32.2%
7.8%
29.8%
9.3%
43.1%
8.0%
31.7%
Std.
205.3
354.3
208.0
384.3
259.4
479.2
192.8
367.1
Qr (t198)
Relative error
2.9%
20.6%
2.0%
18.6%
4.0%
29.8%
2.6%
20.3%
Std.
317.9
522.3
321.4
553.4
402.7
693.6
296.9
539.1
Table 9.14: Comparison of model prediction capacity based on the estimates provided
by four iterative methods (IEnKF, IRPF, IUKF and IAMwG) performed with the
2006 dataset (density 9.6). DA: with assimilation of data at the early growth stages,
UA: uncertainty analysis without data assimilation.
Real Data 2008
IEnKF estimates
Std.
IRPF estimates
Std.
(relative error in %)
(relative error in %)
Qg (t122)
373.5
419.5 (12.3%)
68.9
403.6 (8.1%)
59.2
Qg (t158)
380.6
433.1 (13.8%)
73.4
408.7 (7.4%)
71.8
Qr (t122)
1559.1
1460.5 (6.3%)
197.5
1466.7 (5.9% )
210.7
Qr (t158)
2327.7
2125.6 (8.7%)
324.1
2187.6 (6.0%)
326.2
Real Data 2008
IUKF estimates
Std.
IAMwG estimates
Std.
(relative error in %)
(relative error in %)
Qg (t122)
373.5
440.9 (18.1%)
80.4
423.8 (13.5%)
79.5
Qg (t158)
380.6
461.1 (21.2%)
91.2
444.1 (16.7%)
90.0
Qr (t122)
1559.1
1508.8 (3.2%)
235.2
1391.2 (10.8%)
220.5
Qr (t158)
2327.7
2213.7 (4.9%)
361.4
2028.4 (12.9%)
344.2
Table 9.15: Comparison of model prediction capacity of estimates provided by four
iterative methods (IEnKF, IRPF, IUKF and IAMwG) based on the 2008 dataset with
assimilation of data at the early growth stages.
For the green leaf biomass allocation Qg, it has always been the IRPF estimates
that led to the best predictions for both years, as indicated by Table 9.15 and Table
9.14. This may be related to the important nonlinearity of its evolution.
IUKF provided the best 2008 root prediction as indicated by Figure 9.8. A possible
explanation lies on the fact that the root biomass allocation is more linear than the
green leaf biomass allocation according to Figure 9.9, Figure 9.10 and Figure 9.11.
This may also explain the fact that the prediction based on the IUKF estimates for
the green leaf biomass are less accurate compared to the results given by the other three
methods for the two years. The limited sample size of sigma-points could still have
some diﬃculty when facing relatively important nonlinearity with multidimensional
estimations required.

CHAPTER 9. DATA ASSIMILATION
225
(a) 2006 dataset (density 9.6)
(b) 2008 dataset (density 10.9)
Figure 9.8: Comparison of model prediction capacity of estimates provided by four it-
erative methods (IEnKF, IRPF, IUKF and IAMwG) evaluated by Root Mean Squared
Error of Prediction (RMSEP) based on the 2006 and 2008 datasets with assimilation
of data at the early growth stages.
Figure 9.9: Comparison of the predictions of Qr in 2008 (density 10.9) performed with
or without data assimilation (Uncertainty Analysis) based on IUKF estimates.
However, it is not always the case for the 2006 root biomass prediction. Although
the IEnKF estimates displayed the best performance, we notice that the performance
of the four sets of predictions were relatively close, as suggested by Table 9.14.
Therefore in general, the most accurate predictions are those obtained based on the
IRPF estimates (in the calibration step), if we disregard the computation time and
the memory requirements.

226
9.2. APPLICATION TO THE LNAS MODEL
Figure 9.10: Comparison of the predictions of Qr in 2006 (density 9.6) performed with
or without data assimilation (Uncertainty Analysis) based on IEnKF estimates.
Figure 9.11: Comparison of the predictions of Qg in 2008 (density 10.9) performed
with or without data assimilation (Uncertainty Analysis) based on IAMwG estimates.

CHAPTER 9. DATA ASSIMILATION
227
Figure 9.12: Comparison of the predictions of Qg in 2008 performed with data assim-
ilation based on IEnKF, IUKF, ICPF and IAMwG estimates.
Note that the UKF and the EnKF algorithms can also be adapted to perform the
data assimilation step. Therefore, the data assimilation step is also carried out with
these Kalman ﬁlter based methods in the following study case.
9.2.5
Data assimilation with UKF and EnKF
As mentioned previously, other SMC ﬁltering methods than CPF/RPF can also be
used to perform the model prediction by propagating the uncertainty and re-adjusting
the system on-line. In this test, we aim to compare the predictive capacity of UKF,
EnKF and RPF with the calibration performed based on their iterative version with
the 2010 dataset.
Settings :
EnKF is performed in the data assimilation step with an ensemble size of 350
000 based on the IEnKF calibration. The prediction with UKF is conducted with the
unscented transform (21 sigma-points) based on the IUKF calibration. Their predictive
performances are evaluated by both the relative error and the associated prediction
uncertainty, and are compared to the RPF approach using 350 000 particles with the
IRPF calibration. The experimental dataset of 2006 is used for the prediction test.

228
9.2. APPLICATION TO THE LNAS MODEL
Real Data 2006
EnKF
Std.
RPF
Std.
UKF
Std.
(RE in %)
(RE in %)
(RE in %)
Qg (t142)
355.2
396.4 (11.6%)
83.4
357.2 (0.7%)
80.5
363.5 (2.3%)
99.7
Qg (t198)
320.6
370.6 (16.6%)
78.4
339.4 (5.9%)
72.1
328.4 (2.4%)
98.3
Qr (t142)
1459.2
1459.2 (2.9%)
203.2
1583.8 (8.5%)
205.3
2002.1 (37.2%)
270.0
Qr (t198)
2400.0
2312.5 (3.6%)
321.4
2469.5 (2.9%)
317.9
2499.7 (4.2%)
438.9
Table 9.16:
Comparison of model prediction capacity of three ﬁltering methods
(IEnKF, IRPF and IUKF) using the estimates obtained with their respective iter-
ative approaches based on the 2006 dataset with data assimilation. Relative error
(RE) and standard deviations (Std.) for the prediction are given.
Observations and remarks :
According to Table 9.16, all the three SMC methods, EnKF, RPF and UKF were
used to perform the prediction (data assimilation) step based on the estimation results
of their respective iterative approaches. We remark that the conﬁdence intervals given
by UKF are the widest, so are the prediction error for the root compartment Qr. The
EnKF and the RPF estimates are comparable, especially for Qr prediction. However,
the IUKF estimates seem to be improved for Qg prediction compared to Table 9.14
while the IEnKF estimates appear to be worse. In all cases, their uncertainty associated
to the predictions are increased compared to the DA step performed by RPF. The result
thus suggests that RPF is more appropriate to perform the assimilation step, since it is
not constrained by the Gaussian assumption as the Kalman-based the ﬁltering methods
are.
9.2.6
Inﬂuence of the number of assimilated data
As argued previously, the experimental data are obtained with heavy protocols
which are extremely costly. Therefore, in applications, we should seek for the best
compromise between the cost of the data and the prediction quality. The tests pre-
sented in this section can be regarded as a ﬁrst step towards the optimization of
experimental design to improve the predictive capacities of a model.
Settings :
In the following test, based on the 2006 experimental data, we attempt to eliminate
some of the observation dates, and evaluate the impact on the prediction accuracy. The
last two dates t122 and t158 are used for prediction. The impact of the remaining ﬁve
dates on the prediction results is investigated. In Table 9.17, the observation dates
that are available for data assimilation among the total ﬁve are marked as “o”, while
those that are eliminated are marked as “−”.
For all prediction tests, the DA step is carried out with RPF (350 000 particles)
based on the 2010 IRPF estimates obtained in the calibration step.

CHAPTER 9. DATA ASSIMILATION
229
DA
5
4
4
4
4
4
dates
(t54−114)
(t54−88)
(t59−114)
(t54, t59, t88, t114)
(t54−66, t114)
(t54, t66, t88, t114)
ooooo
oooo-
-oooo
oo-oo
ooo-o
o-ooo
RE
Std
RE
Std
RE
Std
RE
Std
RE
Std
RE
Std
Qg (t122)
0.7%
80.5
2.6%
119.6
4.4%
82.4
2.5%
82.3
0.3%
85.3
2.9%
82.4
Qg (t158)
5.9%
72.1
2.9%
108.3
12.2%
75.2
8.6%
75.3
4.0%
79.7
9.1%
75.6
Qr (t122)
8.5%
205.3
11.0%
258.8
7.8%
206.5
8.7%
207.3
8.9%
208.3
8.7%
211.2
Qr (t158)
2.9%
317.9
4.2%
376.1
3.6%
320.1
2.0%
322.2
2.6%
322.2
2.5%
330.6
3
3
3
2
2
2
(t54−66)
(t66−114)
(t54, t66, t114)
(t54, t59)
(t88, t114)
(t59, t88)
ooo- -
- -ooo
o-o-o
oo- - -
- - -oo
-o-o-
RE
Std
RE
Std
RE
Std
RE
Std
RE
Std
RE
Std
Qg (t122)
24.9%
142.4
0.8%
83.3
0.2%
85.5
29.4%
149.2
4.0%
83.0
1.6%
107.8
Qg (t158)
27.6%
118.8
5.8%
76.7
4.1%
80.1
32.0%
124.9
10.1%
76.5
3.3%
94.9
Qr (t122)
19.2%
294.2
8.7%
211.2
8.8%
211.8
20.9%
288.6
8.8%
214.9
9.7%
254.1
Qr (t158)
10.1%
414.2
3.2%
331.2
2.5%
330.9
11.1%
406.0
1.9%
340.5
2.4%
375.8
1
1
(t114)
(t88)
- - - -o
- - -o-
Error
Std
Error
Std
Qg (t122)
3.6%
84.0
17.6%
110.6
Qg (t158)
9.3%
77.9
24.9%
99.6
Qr (t122)
9.2%
216.9
9.1%
254.3
Qr (t158)
2.9%
343.7
3.0%
378.4
Table 9.17: Comparison of the relative errors (RE) and standard deviations corre-
sponding to the prediction uncertainty resulting from the data assimilation step per-
formed with diﬀerent numbers of data used for assimilation by RPF, based on the
IRPF estimates with the 2006 experimental dataset. On each observation date, two
measurements Qg and Qr are obtained.
Observations and remarks :
Table 9.17 illustrates the point prediction quality resulting from diﬀerent combina-
tions of observation dates. As expected, the result suggests that the most important
data to enhance the prediction accuracy is the one closest to the prediction. When
observation dates are close, the data appear to be less useful: we can see that elimi-
nating one observation date between t54 or t59 did not inﬂuence much the prediction
results. The root compartment Qr prediction does not vary much among the various
conﬁgurations, while the green leaf compartment Qg prediction is more sensitive to
the lack of certain data. This is probably due to the nonlinearity of the Qg evolution.
If only the observations of the ﬁrst two dates are available (t54 and t59), which are
very close, we are at risk of over-correcting the evolution curve. Taking the last two
observations dates (t88 and t114) seems to be the optimal choice.
Likewise, the impact of diﬀerent observation dates on the uncertainty assessment
varies. When the observation date is close to the prediction date, the uncertainty
associated to the prediction is reduced in a more signiﬁcant way. However, this result
may be contextual. Further tests should be conducted.
Another key issue is the type of data to observe. Here we only considered the green
leaf biomass Qg and root compartment biomass Qr, however, one can imagine using
data obtained by drone or satellite images (Baret et al., 2007). The observations such
as the LAI can be derived with image processing methods. Indeed, remote sensing

230
9.2. APPLICATION TO THE LNAS MODEL
images tend to be less costly than the experimental measurements, which could be
considered as a very attractive source of information despite the important observation
error. Therefore, this research subject is worth further investigations.
9.2.7
Inﬂuence of the number of updated parameters
In this test, we try to decrease the number of parameters to update in the prediction
step to see its inﬂuence on the prediction performance. Note that the prediction tests
are conducted based on the six functional parameters estimated in step 2 by IRPF.
Settings :
The functional parameters are eliminated according to the order given by the pa-
rameter ranking of the sensitivity analysis. Those parameters that are calibrated but
not selected for the re-calibration are propagated as in the case of UA (distributions
characterized by the mean value and the standard deviation). The data assimilation
is performed by RPF with the IRPF estimations given in step 2. 350 000 particles are
used by RPF for prediction purpose.
Figure 9.13: Comparison of model prediction capacity of IRPF estimates with diﬀerent
numbers of parameters updated by RPF, evaluated by Root Mean Squared Error of
Prediction (RMSEP) based on the 2006 datasets with and without (d = 0) assimilation
of data at the early growth stages.
d
6
5
4
3
2
1
0 (UA)
RE
Std
RE
Std
RE
Std
RE
Std
RE
Std
RE
Std
RE
Std
Qg (t122)
0.7%
80.5
0.4 %
96.9
5.7%
100.2
6.8%
101.5
7.7%
102.8
9.3%
103.1
44.5%
128.7
Qg (t158)
5.9%
72.1
4.8 %
105.2
12.8%
98.4
12.9%
97.6
13.5%
98.9
15.4%
99.6
43.4%
116.8
Qr (t122)
8.5%
205.3
12.2 %
241.5
12.5%
251.3
12.7%
252.5
12.9%
252.1
14.6%
253.4
32.2%
354.3
Qr (t158)
2.9%
317.9
9.2 %
350.2
7.6%
367.8
7.7%
368.0
8.3%
370.4
10.7%
371.1
20.6%
522.3
Table 9.18: 2006 experimental dataset: comparison of the relative errors (RE) and
standard deviations resulting from the data assimilation step performed with diﬀer-
ent numbers of parameters updated by RPF, based on the IRPF estimates of the
calibration step.

CHAPTER 9. DATA ASSIMILATION
231
Observations and remarks :
Table 9.18 and Figure 9.13 indicate that it is important to recalibrate all the six
functional parameters, for right from the conﬁguration with ﬁve parameters (with only
σγ eliminated), the prediction of Qr became signiﬁcantly less accurate (even though
the prediction of some variables may be improved). Between the conﬁgurations with
3 and 4 parameters recalibrated, the prediction relative errors are very close, while in
the following when more parameters are eliminated, the prediction quality is largely
deteriorated. This result somehow coincides with the result of the sensitivity analysis
(Figure 9.1) for the parameter 4 and 3 (λ and µγ resp.) have similar impacts. The
same remark is made for the parameter 6 and 5 (σγ and γf resp.) as well.
Note that unlike the results given by the Bayesian approach (cf Table 9.6 and
Table 9.7), the uncertainty related to the prediction was not greatly inﬂuenced by the
number of updated parameters, for the uncertainty associated with those parameters
are still taken into account and propagated in the prediction while in the Bayesian
case, the non-selected parameters are ﬁxed at their recommended values.
Likewise, this result could be contextual.
9.2.8
Discussion
The three-step data assimilation approach proposed in this thesis generally appears
to be robust, which allows us to improve the prediction accuracy and to reduce the
associated uncertainty.
However, when the Bayesian methods were used in the parameter estimation step
(step 2), the model conﬁguration (in terms of the number of parameters to estimate)
selected by the DIC based on the learning dataset proved not to be the best one
regarding the predictive capacities in the assimilation step (step 3). Therefore, the
model selection result can be contextual or the DIC may not be the most adapted
selection criterion for prediction perspective. It is a risk to take when applying such an
approach, since in real application, the prediction results are unknown. It seems that
by increasing slightly the number of parameters suggested by the DIC in the estimation
step, or rather by using a more tolerant criteria, the quality of the prediction results
obtained with data assimilation could be improved.
As for the prediction results based on the iterative calibration, the predicted cred-
ibility intervals provided by the RPF-based approach are nearly in all cases narrower
than those of the UA. It is of course an expected result for data assimilation: to reduce
the prediction uncertainty based on the available information. However, regarding the
point estimations, the results of the CPF-based method were not always more accurate
than those provided by UA, especially for the root mass, as shown in Table 9.15 for
Qr(t158) or in Table 9.12 for Qr(t122) or Qr(t158). However, when it happened, the
corresponding predictions of leaf biomass given by the UA were nonetheless far from
the real observed values and can be considered as unreliable. This may reveal some
particular plasticity in root biomass production that was not well captured by the
model, which can be regarded as a drawback of our simpliﬁed model LNAS. However,
even in the few cases when the proposed method failed to improve the point prediction

232
9.2. APPLICATION TO THE LNAS MODEL
of some variables, it always managed to provide reasonable credibility intervals which
contained the real values of the observations.
Concerning the prediction results based on the 2008 dataset with the cultivar Har-
monia (cf Table 9.10), there is an important improvement of the predictive performance
with data assimilation compared to the case without assimilation (UA), for which the
predicted credibility intervals for 3 variables out of 4 do not even contain the real
values of the measurements. However, the relative errors with data assimilation are
all around 15% to 20% for the last measurement date, which is not satisfactory for
practical applications. This may be linked to the fact that the prior information result-
ing from the calibration step is not appropriate, it represents the level of uncertainty
of the parameters of a speciﬁc cultivar, in a given environment. If the adaptation to
other environmental conditions via data assimilation seems to work rather well, the
adaptation to a diﬀerent cultivar appears more diﬃcult, at least in the case when
the environmental conditions are also diﬀerent. However, it is still reassuring to note
that the real values of the last two observations are still in the computed credibility
intervals.
Regarding the uncertainty assessment, when the estimated modelling noises are
quite small (around 2%), it usually implies a good adaptation of the model, whereas
when it is above 5%, the prediction gain with data assimilation could be limited.
When the observation noises are important, it indicates that the observations may not
be reliable enough to update parameters and state variables. Thus in the assimilation
step they may also prevent the algorithm to retrieve the most useful information out
of the few available data, especially when we consider the likelihood function cannot
be computed explicitly (CPF).
By keeping in mind the importance of the uncertainty assessment for the predictive
capacity of the data assimilation method, some numerical tests were performed using
artiﬁcially diﬀerent levels of observation noise in place of the ones estimated from the
2010 dataset. A comparison of prediction capacity linked to three diﬀerent levels of
observation noises (1%, 8% and 15%) was carried out. UA provided close point esti-
mations in all the three cases while the width of the 95% credibility interval increased
with the observation noises. However, the level of the noises inﬂuenced signiﬁcantly
the point estimations given by the CPF-based method. For the last two measure-
ments regarding the biomass of root compartment, the prediction quality was greatly
improved with the decrease of the observation noises, while for the prediction of leaf
biomass, it is the reverse, the prediction may even be slightly deteriorated on account
of the small noises.
Hence, given the sensitivity of the ﬁltering-based data assimilation methods with
regards to the observation noises, their proper evaluation is crucial to improve the
accuracy and reliability of the method, especially regarding the uncertainty associated
to the prediction. It is clearly a bottleneck for real applications since the observation
noises in practice tend to vary a lot according to the experimental conﬁgurations (for
example in two diﬀerent years or in two diﬀerent ﬁelds), so that their proper evaluation
may remain quite diﬃcult.
In this study case, the three SMC methods were used to carry out the prediction
and data assimilation step. RPF showed a small advantage compared to EnKF. The

CHAPTER 9. DATA ASSIMILATION
233
estimates achieved by IRPF, IEnKf, IUKF and IAMwG in the calibration step were
also compared. Overall, the IRPF estimation provided the most accurate predictions
with narrowest conﬁdence intervals. Nonetheless, the IEnKF approach despite the nor-
mality assumption which led to slightly worse prediction results, sometimes provides
similar or even more accurate predictions. By taking into account the computational
cost, the use of IEnKF in the calibration step could be preferable, unless the nonlinear-
ity is remarkable, the Gaussian assumption does not hold or more precise calibration
results are required. In these cases, the ICPF approach is more suitable.
Regarding the time-consuming problem related to an iterative use of the particle
ﬁltering methods, it might also be interesting to be less strict on the model parameter
estimation and loosen the convergence criterion so as to reduce the iteration numbers.
Given the fact that the parameters will be further adjusted in the assimilation step,
the importance of the ﬁrst calibration step might be over-evaluated.
Finally, towards an optimized design of experiments, a few tests have been con-
ducted to study the eﬀect of the number of observation data and of the selection of the
observation dates on the prediction accuracy. The results in Table 9.17 suggest that it
is not evident that more observations lead to more precise predictions. Irregular and
non-dispersed observation dates usually result in poor predictions except when the
observation dates are close enough to the prediction dates. Consequently, the collec-
tion of new data should be guided by targeting the optimal conditions. Similar results
have been obtained by Varella et al. (2010). The strategy proposed is that ideally, the
observation dates should be evenly placed, with the preference of being close to the
prediction dates. It is obvious that the latest observation weighs more and is thus more
valuable, however the objective remains to provide accurate yield predictions with less
new data and as early as possible. Satellite images (remote sensing) although often
imprecise may help to follow closely the evolution of LAI, and this could be a useful
and eﬃcient way to update the prediction so as to improve its accuracy and reduce
the associated uncertainties (Bouman, 1992; Del´ecolle et al., 1992; Gu´erif and Duke,
1998, 2000; Dorigo et al., 2007; Baret et al., 2007; Dente et al., 2008).
9.3
Application to the STICS model
9.3.1
Experimental data
The data used for this study were obtained by INRA (Institut National de
Recherche Agronomique) in the context of the Aquateam project (http://www.projet-
aquateam.org/) whose objective is to develop decision aid tools for crop irrigation.
The experiments were carried out at Villamblain (France).
The growth of two
commercial varieties of winter wheat were monitored:
Raﬀy in two experimental
campaigns, 2011-2012 (sowing date: 25 October 2011; harvesting date: 25 July 2012)
and 2012-2013 (sowing date: 29 October 2012; harvesting date: 30 July 2013) and
Numeric in one experimental campaign, 2012-2013 (sowing date: 29 October 2012;
harvesting date: 30 July 2013).
In our study, the 2012 dataset of variety Raﬀy
was used for parameter estimation. For the sake of clarity for the readers already

234
9.3. APPLICATION TO THE STICS MODEL
familiar with the STICS model, we use the classical notations for state variables
and parameters recalled extensively in Brisson et al. (2008).
Dry matter of green
leaves (denoted mafv, g·m−2), above-ground dry matter (denoted masec, g·m−2), soil
averaged water content (denoted hur, mm/unit area) and dry matter of grain yield
(denoted magrain, g·m−2) were measured and collected at diﬀerent dates in 2012 (in
days after sowing):
Omafv
2012 = {155, 185} ,
Omagrain
2012
= {269} ,
Omasec
2012
= {155, 185, 213, 239, 269} ,
Ohur
2012 = {155, 171, 178, 192, 203, 219, 234, 247, 260} .
For data assimilation and prediction, the two 2013 datasets corresponding to both
varieties were used.
Additional measurements of LAI (denoted LAI, m2 leaf ·m−2
soil) were available for the 2013 dataset (obtained with the SunScan Canopy Analysis
System of Delta-T Devices), while the dry matter of green leaves was not measured.
The observation dates are given as follows:
Ohur
2013 = {21, 79, 114, 155, 170, 182, 198, 210, 226, 240, 255, 275} ,
Omagrain
2013
= {266} ,
OLAI
2013 = {162, 175, 191, 203, 212, 219, 233} .
Daily mean values of air temperature, solar radiation, potential evapotranspiration,
and total daily rainfall were obtained from French meteorological advisory services
(M´et´eo France) 3 km away from the experimental site.
9.3.2
Results and method comparison
Parameter Screening by Sensitivity Analysis
Since STICS has a large number of parameters, and regarding the reduced exper-
imental data sets that are available for its parameterization, a preliminary parameter
selection was conducted in the ﬁrst place. 16 variety-dependent parameters that are
relevant to the concerned model state equations were selected to perform the sensitiv-
ity analysis, for the output chosen as a generalized least-square criterion based on the
2012 dataset.
According to Sobol total order indices, the four most inﬂuential parameters,
VLAIMAXP, EFFICIENCE, STAMFLAXV and UDLAIMAXP were selected for the
next calibration step. Their deﬁnitions are given by Table 9.19. The other parameters
(with total order indices below 0.02) were hence ﬁxed to the mean values of their
variation intervals (deduced from literature (Brisson et al., 2008)).
As illustrated by Figure 9.14, the diﬀerence between the ﬁrst order and the total
order indices is little, which indicates a high linearity of the system (Campolongo et al.,
2007).

CHAPTER 9. DATA ASSIMILATION
235
Figure 9.14: First and total order indices for parameters of STICS wheat crop model.
EFFICIENCE: maximum radiation use eﬃciency (g·MJ−1)
STAMFLAXV: duration between the end of the juvenile phase and the maximal of leaf area index
(deg C.days)
UDLAIMAXP: maximal daily relative development of LAI (no unit)
VLAIMAXP: daily relative development of LAI at the inﬂexion point (no unit)
Table 9.19: Deﬁnition of the selected parameters for the calibration of STICS.
Parameter Estimation
In the deterministic case, the conditional ICPF approach coupled with the para-
metric bootstrap used for the LNAS model is not possible. We thus estimated the
unknown parameter vector
Θ = (EFFICIENCE, STAMFLAXV, UDLAIMAXP, V LAIMAXP)
with the classical CPF. 100000 particles were drawn from the distributions used for
sensitivity analysis and obtained from the literature (Brisson et al., 2008). Means and
standard deviations of all the four parameters are thus obtained based on the posterior
distribution provided by the population of the particles and their associated weights.
The results are presented in Table 9.20.
Data Assimilation with CPF
Data assimilation was subsequently performed using as prior distributions the pos-
terior distributions of the parameters provided by the estimation step. 100000 particles
were simulated for the two 2013 datasets. The recalibration was carried out based on
the ﬁrst seven observations of soil water content hur and the ﬁrst three observations
of LAI, corresponding for both cases to data obtained before Day 199 after sowing.
The values of these state variables along with the grain yield were then simulated for

236
9.4. DISCUSSION
Parameter
Prior
CPF
Distribution
Estimates
Std.
EFFICIENCE
N (4.00, 0.202)
3.62
0.19
STAMFLAXV
U (250, 350)
277.05
35.88
UDLAIMAXP
N (3.00, 0.52)
2.89
0.67
VLAIMAXP
N (2.20, 0.22)
1.91
0.14
Table 9.20: Estimated values and approximated standard deviations obtained by CPF
for the 4 selected parameters of the STICS winter wheat model, based on the 2012
experimental data.
all particles until the end of the growing season (Day 275 after sowing), which allows
us to build the posterior distribution of the prediction.
Uncertainty Analysis (UA) was also performed in this study to provide reference
values for the prediction with 100000 particles as well initialized in the same way as
for the prediction with assimilation.
Figure 9.15 and Figure 9.16 illustrate the model prediction for the LAI variable,
with and without data assimilation. The assimilation step has clearly enhanced the
predictive capacity of the model. The results are detailed in Table 9.21 for the variety
Raﬀy and Table 9.22 for the variety Numeric: the predictions and relative prediction
errors as well as the prediction uncertainty (given by the credibility intervals) are
given for the soil water content hur, LAI, and grain yield magrain, with and without
data assimilation. The relative error of prediction was greatly reduced when taking
advantage of the early data by assimilation, and the prediction uncertainty was also
signiﬁcantly decreased in almost all the cases.
Real Data
DA estimates
95% CI
UA estimates
95% CI
2013
(RE in %)
(RE in %)
hur (t210)
0.296
0.311 (5.2%)
[0.298; 0.324]
0.308 (4.0%)
[0.304; 0.312]
hur (t226)
0.296
0.305 (3.2%)
[0.292; 0.318]
0.303 (2.3%)
[0.296; 0.310]
hur (t240)
0.293
0.304 (3.7%)
[0.291; 0.317]
0.301 (2.8%)
[0.294; 0.308]
hur (t255)
0.247
0.266 (7.8%)
[0.253; 0.279]
0.273 (10.6%)
[0.255; 0.292]
hur (t275)
0.252
0.253 (0.4%)
[0.238; 0.268]
0.268 (6.5%)
[0.233; 0.304]
LAI (t203)
3.51
2.91 (17.2%)
[2.16; 3.65]
2.04 (41.9%)
[0.27; 3.81]
LAI (t212)
4.39
3.87 (11.9%)
[3.10; 4.69]
2.25 (49.8%)
[0.00; 4.51]
LAI (t219)
4.37
4.06 (7.2%)
[3.24; 4.87]
2.33 (46.7%)
[0.00; 5.06]
LAI (t233)
5.21
5.00 (4.0%)
[3.65; 6.35]
2.48 (52.4%)
[0.00; 6.56]
magrain (t266)
829.93
769.70 (7.3%)
[613.18; 926.22]
449.11 (45.9%)
[41.08; 857.14]
Table 9.21: Comparison of the prediction results of the STICS model with and without
data assimilation performed with CPF calibration for the 2013 dataset variety Raﬀy.
RE: relative error.
9.4
Discussion
Similar to the application of the LNAS model for sugar beet, the mean prediction
and prediction credibility intervals are generally greatly improved with data assimila-

CHAPTER 9. DATA ASSIMILATION
237
Figure 9.15: Comparison of the predictions of LAI obtained with CPF-based assimila-
tion and by the uncertainty analysis (without assimilation) based on the 2013 dataset
for variety Raﬀy. The red squares correspond to the assimilated experimental data
while the pink squares represent the data used for validation.
Figure 9.16: Comparison of the predictions of LAI obtained with CPF-based assimila-
tion and by the uncertainty analysis (without assimilation) based on the 2013 dataset
for variety Numeric. The red squares correspond to the assimilated experimental data
while the pink squares represent the data used for validation.
tion compared to simple prediction by uncertainty analysis.
A noteworthy point concerns the special climatic conditions of year 2013 for the

238
9.4. DISCUSSION
Real Data
DA estimates
95% CI
UA estimates
95% CI
2013
(RE in %)
(RE in %)
hur (t198)
0.276
0.272 (1.7%)
[0.260; 0.283]
0.290 (5.0%)
[0.286; 0.295]
hur (t210)
0.274
0.303 (10.3%)
[0.284; 0.322]
0.308 (12.2%)
[0.303; 0.313]
hur (t226)
0.289
0.297 (2.6%)
[0.278; 0.316]
0.303 (4.7%)
[0.295; 0.310]
hur (t255)
0.239
0.262 (9.7%)
[0.240; 0.283]
0.272 (14.0%)
[0.253; 0.291]
hur (t275)
0.257
0.260 (1.2%)
[0.229; 0.291]
0.267 (4.0%)
[0.233; 0.302]
LAI (t203)
4.24
4.51 (6.6%)
[3.10; 5.92]
3.5 (17.8%)
[0.47; 6.49]
LAI (t212)
4.74
4.63 (2.3%)
[2.75; 6.40]
3.84 (18.9%)
[0.00; 7.69]
LAI (t219)
4.23
4.87 (15.2%)
[2.39; 7.34]
3.99 (5.5%)
[0.00; 8.64]
LAI (t233)
4.91
5.22 (6.2%)
[1.57; 8.86]
4.27 (13.0%)
[0.00; 11.21]
magrain (t266)
819.38
804.33 (1.8%)
[611.68; 996.98]
550.58 (32.8%)
[128.97; 972.20]
Table 9.22: Comparison of the prediction results of the STICS model with and without
data assimilation performed with CPF calibration for the 2013 dataset for variety
Numeric.
winter wheat data, since severe stresses due to heavy rain and frost in winter were
observed which resulted in a far lower plant density compared to 2012. However, since
there was more space available for each plant, a compensation phenomenon was ob-
served. The LAI curve got delayed but ﬁnally nearly caught up with what would have
been observed with the regular climate conditions, and therefore grain yield was not
seriously inﬂuenced. However, the prediction performed without assimilation was not
able to capture this compensation phenomena and thus failed to provide a reasonable
prediction for the LAI and for the ﬁnal yield (cf.
variable magrain in Table 9.22
and Table 9.21), while the proposed approach has remarkably tackled this issue by
updating properly the parameters and hidden variables based on the available data.
As a result, the satisfactory predictions demonstrated its robustness in case of extreme
weather scenarios.
On the other hand, the prediction improvement is less impressive with the soil
water content variable, probably due to the fact that the prediction results obtained
without data assimilation were already satisfactory, and there was no soil parameter
selected by sensitivity analysis, and only light water stress conditions: the inﬂuence of
the crop parameters updated in the data assimilation is limited, so that the diﬀerence
with the case without assimilation is not so apparent (while still to the advantage of the
assimilation method). In the light of this example, we may also consider a more subtle
selection of parameters in the ﬁrst step of our approach to improve the prediction of a
speciﬁc output variable of interest when needed.
Finally, it is important to underline that when the proposed approach is applied to
a deterministic model, the resulting uncertainty assessment is less rigorous in both the
estimation and assimilation steps. As presented in Section 8.3.2, CPF can bring arti-
ﬁcial dynamics to the deterministic STICS model by introducing two kernel functions
associated to Xa
n and Yn, so that more variations are tolerated and the estimation
can be considered as a distribution. In practice, a value of cx ≈1 assured a good
exploration of the state-space. Nevertheless, in this case, the posterior distributions
obtained with the CPF approach are extensively inﬂuenced by the tuning parameters
of the algorithm, especially the choice of the kernel functions and their bandwidth pa-
rameters, so that the credibility intervals computed should be regarded as contextual

CHAPTER 9. DATA ASSIMILATION
239
approximations. This directly results from the fact that the model does not have a
probabilistic framework, which of course restricts the validity of the statistical analysis.

240
9.4. DISCUSSION

CHAPTER 10
Discussion and Perspective
T
o improve the predictive performance of plant growth models, various eﬀorts are
made from diﬀerent perspectives in literature. However, based on the existing
approaches and strategies, the plant growth prediction application appears to be very
case-speciﬁc, the methods and the data analysis settings employed are often either too
superﬁcial regarding the prediction objective or simply chosen based on their availabil-
ity, without a profound analysis. A full methodology dedicated to guide a good practice
of the data assimilation technique could beneﬁt the development of applications.
In this context, this thesis encompasses the essential core steps of modelling, in-
cluding model design, sensitivity analysis, model calibration (also known as param-
eterization), model selection, uncertainty analysis, model prediction and eventually
design of experiments. Aiming to enhance the predictive performance in terms of both
point estimation and the associated uncertainty assessment, we attempted to provide
such an approach described in a probabilistic Bayesian framework to perform data
assimilation. In this last chapter, we overview and discuss the principal results and
contributions of this thesis, some possible future research directions are accordingly
proposed.
10.1
Contributions and results
The objective of this thesis is to develop a full methodology to address the data
assimilation and prediction issues in plant growth models from diﬀerent perspectives.
Our main contributions can be summarized in four categories, described below.
10.1.1
Model design
Firstly, from a model design perspective, a simple crop model, the Log-Normal
Allocation and Senescence (LNAS) model was elaborated and adapted to the imple-
241

242
10.1. CONTRIBUTIONS AND RESULTS
mentation of a Bayesian approach to perform model prediction with a special focus on
the characterization of the inevitable uncertainty present in plant growth models. To
facilitate the application of Bayesian based methods, the plant growth model used for
prediction purpose should be described in a general state-space model form. The cur-
rent trend in plant growth modelling is to develop sophisticated models with detailed
description of plant-environment interactions Yin and Struik (2010), which leads to
an important number of parameters in the model. With insuﬃcient number of avail-
able observation data, estimation diﬃculties can frequently occur, while the generally
deterministic model form does not allow a proper assessment of uncertainty.
In this context, we aim to ﬁnd a balance between the complexity of the model
and the quantity of available data in order to avoid identiﬁability problems. In this
regard, being built from a probabilistic perspective, the LNAS model describes only
the essential ecophysiological processes involved in biomass budget based on the anal-
ysis of Del´ecolle et al. (1992), for instance, biomass production, biomass allocation,
senescence and leaf surface development. Although the parameters of these functions
are no longer supposed to be from genetic origin only, our assumption is that the em-
pirical functions describing the ecophysiological processes are ﬂexible enough to adapt
to a large range of situations, and robust enough so that the mean prediction remains
pertinent. Moreover, such simpliﬁcation allows an easier representation of the model
errors without increasing signiﬁcantly the number of parameters. Indeed, an extra
attention is paid in the construction of the LNAS model to describe the uncertainty
in crop growth.
The introduction of both modelling noises and observation noises
helps to avoid an excessive forcing of the model towards the observations and allows
to take into account multiple stochastic factors, including environmental noises and
various stress and compensation factors not included in the model. As a counterpart,
the combination of these two types of noises alters the dependence structure and pro-
duces signiﬁcant computational diﬃculties. Therefore, extensive numerical simulation
integration methods are required for conducting statistical inference. The parameter
estimation of such a state space model becomes a major challenging research subject.
In the following, we present the contributions of this thesis in these regards.
10.1.2
Parameter estimation and uncertainty assessment
Dynamic crop models are generally characterized by complex interacting processes
and a large number of model parameters. As a speciﬁcity of agricultural systems,
experimental data acquisition tends to be costly (when direct ﬁeld data collections are
involved) or inaccurate (for indirect measurements such as satellite images), and gen-
erally irregular. Therefore, due to the nonlinear dynamics of the system equations, the
restricted experimental data and the considerable uncertainty of the inputs, the pa-
rameterization of these models is generally regarded as a key issue which may strongly
aﬀect the quality of model prediction. Eﬃcient and precise parameter estimation with
proper assessment of the parameter uncertainty is thus crucial to ensure reliable and
satisfactory prediction performance.
In this thesis, a thorough research is conducted regarding model parameterization
methods, with a special focus on Bayesian estimation, involving both MCMC-based

CHAPTER 10. DISCUSSION AND PERSPECTIVE
243
methods and SMC methods.
Bayesian inference
Regarding MCMC based methods, we investigated the three strategies that are of-
ten opposed in applications, namely “one long run”, “some median runs” and “many
short runs”. For this purpose, we respectively implemented and studied the Adapted
Metropolis-within-Gibbs algorithm (Haario et al., 2001; Andrieu and Thoms, 2008),
the DREAM algorithm (Vrugt et al., 2009a) and interacting parallel MCMC (Campillo
et al., 2009). For the three strategies, a new scheme was proposed to deal with the
issue of poor mixing between hidden states and parameters in state-space plant growth
models. The convergence properties and behaviours of each method were studied and
compared based on both the simulated datasets and a real experimental dataset.
Globally, the three algorithms provided accurate mean estimates. Although the
one long run has the advantage to provide accurate mean and variance estimates, the
algorithm cannot be parallelized and suﬀers from the long computational time. For
the sake of computational eﬃciency, parallel chains are also widely studied.
When parallel chains are engaged without communication, the overall speed of
convergence is limited by the convergence of each chain.
The DREAM algorithm
proposes to hasten the convergence of individual chains by creating communications
between the chains. However, according to our results, it still appears to have slow
convergence issues and the burn-in period for each of its chains is diﬃcult to deﬁne.
Moreover, it requires an appropriate starting distribution which is over-dispersed. The
performance of the classical Gelman-Rubin criterion for multiple chains convergence
diagnostic is also proved to be ineﬃcient.
Therefore, when the number of chains
increases, more and more outliers could be included in the ﬁnal pooled estimates which
are used to construct the posterior distribution, while a small number of chains are
very likely to underestimate the mean posterior variance. In order to determine the
number of samples of the chains that should be discarded pertinently, an eﬃcient way
is to take only the last sample of each chain, as in the case of the interacting parallel
MCMC algorithm.
By gathering the candidates of all the individual chains together and being selected
by all the chains, the idea is to concentrate the computational eﬀort on the zone of
interest. Although one iteration of Interacting MCMC generally takes more time than
one iteration of parallel independent MCMC, our tests demonstrated that the interact-
ing scheme, which can be regarded as a sort of importance sampling, clearly improved
the convergence eﬃciency. Nevertheless, manifestly the algorithm suﬀered from the
sample impoverishment issue and failed to provide appropriate variance estimates to
characterize precisely the target distributions, for the regions with small acceptance
probability are rarely visited. Although some eﬀorts of improvement were made to
extend the interacting parallel runs without the interacting scheme, the variance esti-
mates still remained less accurate than those of a long run.
Our results suggest that multiple chains perform less eﬃciently than a single chain
(at least for the type of situations considered in this thesis). They may save some
computational time, but their estimation of posterior distribution is less accurate than

244
10.1. CONTRIBUTIONS AND RESULTS
one long run methods, especially for nonlinear models and limited data. Most impor-
tantly, it seems more diﬃcult to deﬁne a proper way to diagnose the convergence for
multiple parallel chains.
Another important category of Bayesian estimation methods are the SMC ﬁlters.
The Unscented Kalman Filter (Julier and Uhlmann, 1997; Quach et al., 2007), the
Ensemble Kalman Filter (Evensen, 1994) and the Regularized/Convolution Particle
Filter (Musso and Oudjane, 1998; Oudjane and Musso, 1998; Campillo and Rossi,
2009) were also implemented and studied. The three methods are designed to confront
nonlinear systems. Contrary to the MCMC-based approaches, the ﬁltering methods
are performed in a sequential way. They are able to take into account the variation of
parameters over time and carry out on-line updating. Based on the Kalman prediction-
correction ﬁlter equations, UKF uses a small set of sigma-points to approximate both
the mean and the covariance matrix in the prediction step. EnKF relies on normality
assumptions in order to improve the accuracy of its estimates with a more important
number of samples. Finally, CPF and RPF are particle ﬁlter-based methods, they
intend to provide better approximation of the exact posterior distributions by creating
a set of randomly drawn samples that are propagated in the dynamic system. Each
trajectory has an associated weight, evolving at each ﬁltering step. A kernel smoothing
method is used to change the discrete approximation of the ﬁltering density into an
absolutely continuous approximation. The diﬀerence between CPF and RPF is that
for CPF, a convolution kernel is used to regularize the likelihood of the observations
as well. Since in our application to the LNAS model, the likelihood of the observation
is considered known, RPF was used to perform the model calibration.
According to our tests, unlike the MCMC-based methods that generally provided
similar estimations and remain stable, UKF, EnKF and RPF usually disagreed on the
estimation results. The estimations given by RPF were often similar to those of the
MCMC based methods, which suggests a reliable performance, even though the Monte
Carlo error was generally larger. On the other hand, UKF is limited by its sample
size which often led to poor estimations, especially when the system is characterized
by a strong nonlinearity. In comparison, the other Kalman based ﬁlter EnKF behaved
better. Its larger sample size makes it more adapted to nonlinear systems than UKF,
but it is still aﬀected by the underlying Gaussian approximation, and ﬁnally yielded
less accurate estimations than those of RPF.
Iterative approaches
We highlight that when the number of data is limited, one crucial point to deﬁne
the performance of Bayesian inference is the choice of prior. In the context of plant
growth modelling, when a new model is developed (as for LNAS), there might be
a lack of accuracy in the prior knowledge that could be gathered, since few speciﬁc
studies on the parameterization of the model exist. The desirable strategy is hence to
put more emphasis on the data, while still preserving an interpretable context and to
beneﬁt from the robustness of Bayesian based methods. Motivated by this thought, in
this thesis, an iterative scheme was proposed based on the SMC or MCMC Bayesian
estimation methods to improve the estimation accuracy. It can be regarded as a variant
of the Expectation-Maximization algorithm under the normal assumption of the prior

CHAPTER 10. DISCUSSION AND PERSPECTIVE
245
distributions. A theoretical framework was elaborated in this regard to describe this
variant of EM type algorithm. The term Gaussian randomization was introduced to
designate that the initial model could be seen as the special case of an extended model
which includes all the Gaussian distributions with the parameters of the original model
as the means.
The estimation results showed that the iterative RPF performed better than the
MCMC-based iterative approach. It can be explained by the fact that since the vari-
ance of the posterior tends to 0 with the EM iterations, the resampling scheme allows
RPF to introduce and to maintain the dynamics among the population or particles,
which cannot be achieved by the MCMC-based iterative approach. Accordingly, para-
metric bootstrap was used to evaluate the uncertainties associated with the mean
estimates of the parameters.
For both Bayesian and iterative methods, when the parameters of the noise model
are unknown, a conditional approach was described for their estimation. The noise
parameters were jointly estimated with the functional parameters and the hidden state
variables to characterize the uncertainty present in plant growth models. The noise
parameters were either updated with conjugate priors, or estimated with empirical
estimators, or ﬁxed by model selection. The simulation results indicate that such a
framework usually allows for the quantiﬁcation of uncertainty both at parameter level
and error model level.
Finally, a decision aid table for the choice of estimation strategies is proposed as
follows with regards to diﬀerent situations and needs:
Conditions
Recommended method(s)
•
Time constraint, no reliable prior,
only point estimation is needed
⇒
GLS
•
Time constraint, slightly non linear model
⇒
UKF
•
High-dimensional parameter vector
⇒
DREAM
•
Precision of the mean estimate
⇒
Interacting MCMC
•
Reliable prior, need precise CI%, no time constraint,
implementation expertise in MCMC
⇒
One long run AMwG
•
Reliable prior, time constraint
⇒
CPF, EnKF
•
Less reliable priors
⇒
Iterative SMC, especially ICPF/IRPF
Table 10.1: Selection strategy for estimation methods.
10.1.3
Data assimilation approach
Thirdly, a three step data assimilation methodology was proposed as a guide to
tackle model prediction problems. The most inﬂuential parameters are ﬁrst selected
by global sensitivity analysis and accordingly estimated in a Bayesian framework by
either Sequential Monte Carlo (SMC) methods or Markov chain Monte Carlo (MCMC)
methods in the calibration step. The posterior distribution obtained from this step

246
10.1. CONTRIBUTIONS AND RESULTS
can be subsequently considered as prior information for the prediction performed with
data assimilation. In this last step, a SMC-based on-line estimation method is applied
to update state and parameter estimates based on the data obtained at early growth
stages, with the purpose of improving model predictions and assessing or even reducing
the associated prediction uncertainty.
Sensitivity analysis and model selection
For the ﬁrst step, a sensitivity analysis method is carried out ﬁrst to rank the functional
model parameters according to their inﬂuences on model outcome variables of interest.
Then, by selecting an increasing number of parameters to estimate (following the
importance ranking and starting with the most inﬂuential one), a family of models is
built. The parameters that are not selected are ﬁxed to their recommended values.
To reduce the number of candidate models, a threshold can also be deﬁned to even
exclude a priori of the selection process the least inﬂuential parameters.
A selection method is then applied to determine the best model, and subsequently,
the number of parameters to estimate. Generally the selection process is based on
model calibration and standard criteria, like AIC, AICc or DIC.
In the applications to the LNAS and STICS models, this step allowed us to reduce
the number of parameters from 6 to 3 and from 16 to 4 respectively. The other param-
eters are thus ﬁxed to their recommended values given by literature and considered as
constants.
However, it is important to note that the best model selected from the calibration
step is not proved to be the best model in a predictive context, with data assimilation.
If the DIC criterion is used with bayesian estimation methods in the calibration step,
it seems that it penalizes too much the number of parameters, ﬁnally allowing too
little ﬂexibility in the data assimilation step, to the detriment of model adaptation
and predictive capacity. This results suggest that a model selection criterion with less
penalty on the number of the model parameters could be preferred for the prediction
objective.
Parameter estimation for stochastic state space models
In this second step, when a calibration data set is available, the estimation methods
investigated in Chapter 4 and Chapter 5 can be applied.
For the type of models
considered in this thesis and the type of classically available data, Bayesian methods
(principally one long run AMwG and RPF/CPF) were able to provide fair posterior
distributions, that could be used in the data assimilation step.
The iterative approaches were also able to provide estimates that approach MLE,
which is a desirable feature when the prior information is not pertinent. The con-
ﬁdence intervals obtained by parametric bootstrap were however far larger than the
credibility intervals given by the Bayesian approaches. Although these intervals can-
not be compared for they bear diﬀerent meanings, the predictive performances of the
two approaches (Bayesian versus Iterative) were evaluated in our data assimilation
application for the LNAS model.

CHAPTER 10. DISCUSSION AND PERSPECTIVE
247
Prediction with assimilation
In the last step, the model prediction with assimilation of data from early growth
stages was carried out with the four SMC ﬁltering methods (CPF, RPF, UKF, EnKF).
Unlike RPF, CPF applies when the likelihood cannot be computed explicitly, another
convolution kernel being introduced for the likelihood computation of the observation
function. It is useful when the form of the observation error is not known. In our tests,
data assimilation with CPF showed similar prediction performances as RPF.
Regarding the comparison with the prediction by UKF and EnKF, generally,
CPF/RPF yielded more accurate mean estimates and reduced more the prediction
uncertainty than the other two Kalman based ﬁltering methods, and therefore CPF
and RPF appears to be more robust and suitable in our application context.
The inﬂuence of the calibration precision was also studied. Generally, the preci-
sion has a direct impact on the prediction accuracy. However, some exceptions were
detected, speciﬁcally when the environmental conditions were very diﬀerent in the pre-
diction phase compared to the calibration phase, and when the model was not able to
handle this diﬀerence. In that case, the accuracy of the prior induced some bias in the
prediction step, by restraining the model adaptability.
Likewise, multiple observation noise levels were considered. The impact on the
mean predictions was small, but it was important on the evaluation of prediction
uncertainty. This result suggests that the evaluation of the observation noise level is
crucial and should be determined with care, since it could vary from one experiment
to another and can be inﬂuenced by many factors that are diﬃcult to assess.
Moreover, we also demonstrated that in our study case, the number of parameters
recalibrated in the data assimilation step was also of great importance.
Generally
speaking, the issue is to determine the proper number of parameters to be re-calibrated
allowing a suﬃcient liberty for the calibrated system to re-adjust itself to the new
context, while preserving the model robustness and avoiding the identiﬁability issues.
As mentioned above, the optimal choice in terms of prediction is diﬃcult to determine
a priori. It seems that by increasing slightly the number of parameters suggested by
the DIC in the estimation step, or rather by using a more tolerant criteria, the quality
of the prediction results obtained with data assimilation could be improved.
Finally, the impact of the number of data based on which data assimilation can be
performed and the impact of their acquisition dates were evaluated. As expected, the
latest observed data (that is to say those that are close to the prediction dates) tend
to be the most informative, and consequently, they improve greatly prediction results
compared to cases when the same data is not available for assimilation. More dispersed
observation dates also appeared to yield better prediction precision.
Furthermore,
the number of repetitions of observations did not appear to be as important as their
acquisition dates for the prediction quality. This part opens some perspectives towards
the optimal design of experiments, regarding the choice of the observation dates and
of the type of data to collect, with the objective to improve the predictive capacity.

248
10.2. PERSPECTIVES
10.1.4
Application with real experimental data
Finally, from an application point of view, the proposed methods are implemented
and evaluated with two crop models, the STICS model for winter wheat and the LNAS
model for sugar beet, to illustrate the robustness of the proposed data assimilation ap-
proach. Five datasets obtained in various experimental conditions were used for the
sugar beet LNAS model, and three datasets for the winter wheat STICS model. In both
studies, one dataset was used for a priori parameter estimation and the others were
used to test the model predictive capacity, both with and without data assimilation.
The RPF-based data assimilation approach showed promising predictive capacity and
provided robust and reduced credibility intervals in various test conﬁgurations (diﬀer-
ent years for calibration and prediction by assimilation, diﬀerent experimental sites,
diﬀerent cultivars, diﬀerent crop densities, diﬀerent levels of water stresses), which sug-
gests that the combination of such an approach with both types of crop models (simple
probabilistic model or complex deterministic model) is quite reliable and can therefore
be regarded as a potential tool for yield prediction applications in agriculture. The
fact that the method can be applied straightforwardly to deterministic model is very
interesting. There is however a limitation since the conﬁdence intervals produced by
this method are not statistically relevant (since there is no statistical model for this
purpose).
10.2
Perspectives
While answering a few of the initial questions addressed in this thesis, a lot of issues
remain unsolved or were raised during this work. In the following, some perspective
and research directions are discussed.
10.2.1
Modelling Uncertainty
Assumption for noise models
The proper assessment of uncertainty appears as a crucial point for the usefulness
of plant models (Ford and Kennedy, 2011). In the construction of the LNAS model
introduced in Section 2.1, a multiplicative Gaussian noise structure is adopted for both
the modelling noises and the observation noises.
However, other distributions could have been tested in a model selection perspec-
tive. The log-normal distribution is a classical choice, speciﬁcally to prevent positivity
loss. Both log additive or log multiplicative noise can be considered. In this case, our
evolution model can be transformed to:
Q(t) = F t
Q(Qf(t); Θ) eηQ(t),
γ(t) = Γt(Θ) eηγ(t),
t ≥1,
where {ηQ(t)}t≥1 and {ηγ(t)}t≥1 are independent from X0 sequence of mutually inde-
pendent centered Gaussian random variables with variances σQ and σγγ respectively.

CHAPTER 10. DISCUSSION AND PERSPECTIVE
249
So as the observation equations:
Y (t) =
 log Qg(t) + ξg(t)
log Qr(t) + ξr(t)

,
(10.1)
where {ξg(t)}t≥1 and {ξr(t)}t≥1 are i.i.d. mutually independent sequences of centered
Gaussian random variables with variances σ2
g for ξg(t) and σ2
r for ξr(t), and assumed
to be independent from {ηQ(t)}t≥1 and {ηγ(t)}t≥1.
Regarding the deterministic STICS model presented in this thesis, it could also be
interesting to consider its adaptation in a state-space form described in a probabilistic
framework in order to characterize and identify diﬀerent sources of uncertainty. Similar
log-normal noise models can be introduced for biomass production, allocation and the
stress functions. Of course, some more experimental data would be available to avoid
identiﬁability problems, since potentially many diﬀerent modelling noises could be
introduced.
Finally, the evaluation of the appropriateness of a noise model could be contextual,
the assessment of uncertainty still remains a critical and crucial point to determine
the performance of the prediction.
An excessive forcing of the model towards the
observations is not desired, yet too much noise could conceal the useful information.
How to extract most information from the available data while still addressing the
uncertainty in an appropriate way in order to provide reliable credibility intervals?
Further investigations are still required.
Climatic uncertainty
A very strong assumption was used in all our prediction tests: we assumed that the
climatic data were known, even after the last data acquisition that was used for assimi-
lation. Of course, this is not the case in real situations. For real prediction applications,
it would be useful to also consider the uncertainty in the climatic variables. The most
classical way in this objective is to use historical climate data, for example in the last
50 years, and use these data to run simulations for each of these 50 climatic scenarios.
Ideally, these 50 simulations should be run for each particle describing the posterior
distribution obtained in the ﬁltering process. However, since after the last ﬁltering
step, we are in a pure uncertainty analysis situation (propagation of uncertainty in the
plant dynamic system), the number of particles can be reduced.
A problem of this classical approach based on historical scenarios is that the sim-
ulations run after the last ﬁltering step at date tf are based on climatic scenarios
that are independent of the observed climatic variables until tf while these are avail-
able, and there exist long dependence chains in the climatic time series.
For this
purpose, it would be interesting to couple our approach with stochastic weather gener-
ators that simulate weather scenarios conditionally on the observed climatic variables
(Yiou, 2014).
Towards population-based models
In this thesis, both the LNAS and the STICS models consider only mean population
values to assess the impact of covariates and to perform the model prediction. How-
ever, if there is a strong variability among individuals, the conclusion can be severely

250
10.2. PERSPECTIVES
biased. Indeed, describing plant populations only in terms of mean growth is often not
adequate. Although the modelling noises allow to take into account some variations
resulting from the population eﬀect, it is still diﬀerent from studying speciﬁcally the
inter-individual variability, which could help us to understand population behaviour
and thus enhance the predictive capacity of plant growth models at ﬁeld scale.
For this purpose, individual centered models like the LNAS or GreenLab mod-
els can be extended to a population level using mixed eﬀect models, as proposed by
Baey et al. (2013b); Baey (2014); Baey et al. (2014). They also proposed an estima-
tion method combining multiple chains Monte Carlo with Expectation-Maximization
algorithm (Stochastic Approximation of EM algorithm, see Delyon et al. (1999)) to
mimic the population dynamics. In order to study the covariates’ eﬀect, the maximum
likelihood function used in the MCMC algorithm should therefore be based on the
joint density of the observation given the covariates, and the Wald test can be used
for model selection. Diﬀerent types of covariance structures as well as diﬀerent noise
models can be considered and compared, so as the signiﬁcance of the random eﬀect
introduced. Given the fact that the variance estimates of the random eﬀects provided
by the Maximum Likelihood method can be biased (Meza et al., 2007), it can be as-
sessed with the Restricted Maximum Likelihood (REML) (see Foulley et al. (2000)
and Foulley and Van Dyk (2012)).
Finding population data adapted to the GreenLab population model iss diﬃcult
since data at organ scales are heavy to collect, and it is of course multiplied when we
are interested in a population of individuals ... Moreover, the population formulation
was based on a deterministic version of the GreenLab model, without modelling noise.
Therefore, further study can be conducted by combining this population approach
with other simpliﬁed plant growth models described in a probabilistic framework to
avoid identiﬁability problems and to take into account growth process variations via
modelling noises.
The LNAS model is a good candidate for this purpose since it
requires far less data than the GreenLab model for its parameterization and would
thus open the way to wider applications, with more individual plant samples.
Moreover, if an important number of sample plants are available, we could assume
that some modelling noises (random eﬀects) are generated from a non-parametric
distribution (e.g. a mixture of mass points with each corresponding to a cluster of
plants) in order to admit more variability among the plant population while avoiding
over-ﬁtting problem by introducing more parameters (see for example Debashis et al.
(2011)).
It would also be interesting to adapt the Bayesian methods investigated in our
thesis, to take advantage of the prior knowledge on model parameters, and also to avoid
the iterative process of the EM algorithm which repeats a large number of MCMC
computations and is thus very expensive in the context of mixed models when the
population size becomes important.
One chain should be enough in the Bayesian
frame, even if of course the convergence could be very slow according to the number
of parameters and of mixed eﬀects to consider.
Finally, methods like cross validation can be used to identify the bias of model
selection. Population based models and average individual based models can therefore
be compared with regards to their predictive capacity.

CHAPTER 10. DISCUSSION AND PERSPECTIVE
251
10.2.2
Estimation Methods
In terms of estimation, the results obtained by AMwG with our proposed scheme to
handle the parameter - hidden states mixing issue, the RPF / CPF approach, and the
iterative versions of RPF / CPF are very satisfactory regarding our parameterization
and uncertainty assessment objectives. However a few interesting perspectives could
still be considered. The ﬁrst one concerns the interacting paralell MCMC (Campillo
et al., 2009), for which a few things could be tested to improve the under-evaluation
of the posterior variances. Another promising approach is the hybrid Particle MCMC
method introduced by Andrieu et al. (2010).
A hybrid Particle MCMC method
The objective of MCMC based methods for parameter estimation in state-spaces mod-
els can be reformulated as follows: given a batch of observation y1:tmax, we seek the
posterior distribution π(Θ|y1:tmax) ∝p(y1:tmax|Θ)π(Θ) with π(Θ) the prior distribution.
This posterior distribution is typically not available in closed form. A possible remedy
is to include the hidden state variables x1:tmax as auxiliary variables. Therefore, a joint
update scheme is proposed.
– Update Θ′ ∼π(Θ|x1:tmax, y1:tmax).
– Update x′
1:tmax ∼π(x1:tmax|Θ, y1:tmax).
By sampling Θ conditionally on both the observed data and the hidden state vari-
ables, it generally simpliﬁes the update. For non-conjugate models as in our case, a
MH step is used to replace the exact update. However, the second step is much less
straightforward.
In practice, slow mixing occurs frequently when strong temporal dependencies are
present in the model. Many eﬀorts are made in the literature to improve the sampling
process of the hidden states estimation, including dividing the trajectory in blocks
and updating them subsequently (see Carter and Kohn (1994) for block independence
sampler), or updating the whole trajectory from its full conditional (see Rabiner and
Juang (1986) for the Kalman ﬁlter algorithm and Scott (2002); Fearnhead (2006) for
the forward-backward algorithms). However, the block updating may result in slow
mixing at the boundaries of the blocks, Shephard and Pitt (1997) suggest that the
blocks to be updated can be chosen randomly.
Another alternative consists in simulating directly from the full conditional of the
hidden state variables, but there is the important constraint that the full conditional
can be expressed analytically, which cannot be applied to many models. Likewise,
independent proposals are built under the Gaussian assumption and thus can only be
used for limited models. It is possible to obtain good proposals for state-space models
in a more general way, but this can be a challenging task, especially for models with
high-dimensional states and important nonlinearity.
Note that this can be regarded as another argument for simpliﬁed model design,
since the more sophisticated a model is, the more diﬃcult its parameterization will be,
and very limited methods can be applied considering the computational constraint.

252
10.2. PERSPECTIVES
A promising approach for block updates of hidden state variables has been recently
proposed by Andrieu et al. (2010), which is based on employing SMC methods within
a Markov chain. The idea is to beneﬁt from the eﬃciency of the SMC methods by
generating a proposal distribution for the trajectory of the hidden state variables inside
an MCMC algorithm. This framework is described as Particle Markov chain Monte
Carlo (PMCMC).
As we stated in Section 4.1.4, ideally the proposal q(x′
1:tmax|Θ′) should be taken as
p(x′
1:tmax|Θ′, y1:tmax), but since it is diﬃcult to achieve, anther way to approximating
the intractable π(Θ|y1:tmax) required for the computation of the acceptance probability
of the MH update is to use importance sampling estimates :
˜π(Θ|y1:tmax) = 1
N
N
X
k=1
π(Θ, x1:tmax(k)|y1:tmax)
q(x1:tmax(k)|Θ)
with
x1:tmax(k)
i.i.d.
∼q(x1:tmax|Θ).
So that the acceptance probability can be simpliﬁed as :
min

1, ˜π(Θ′|y1:tmax)q(Θ|Θ′)
˜π(Θ|y1:tmax)q(Θ′|Θ)

.
However, in a general way, the success of this approach relies greatly on using
a large number of particles M in the underlying particle ﬁltering method, to obtain
accurate kernel approximations. Although it seems to be a natural requirement, it also
implies that a lot of computational resources are wasted. This can be explained by the
fact that at each iteration of the Gibbs sampler, a large number of particles are used
to extract a single state trajectory.
Based on the actual version of AMwG described in Section 4.1.4 and its demon-
strated performance, a more simple way to improve the PMCMC performance could
be to introduce a particle ﬁlter inside the parameter update every k iterations for the
updates of hidden states, or to consider a smaller sample size for a more often hidden
state update. The performance of diﬀerent proposal distributions can also be explored.
We believe this idea is worth further investigation for our applications of interest in
plant growth model calibration.
10.2.3
Data assimilation applications
Of course, a deeper investigation on real test cases is necessary to show the robust-
ness of the proposed approach. For example, a potentially interesting performance
comparison for future study can be using both a sophisticated model like STICS and
a probabilistic model like LNAS to perform model prediction with the same crop and
same observation datasets.
With real applications in mind, a crucial aspect is the assimilation of data obtained
via remote sensing techniques, either from satellite images or aerial (drone for example)
images. It has been a long-standing challenge and there were already several pioneer
applications carried out Gu´erif and Duke (2000); Launay and Gu´erif (2005). It will be
interesting to see how this kind of information can be integrated into our probabilistic

CHAPTER 10. DISCUSSION AND PERSPECTIVE
253
model and how it helps for its predictive capacity. The information provided by these
techniques are potentially cheap and quite frequently available during the crop cycle.
However, few biophysical variables can be estimated, and the level of uncertainty re-
mains pretty high. Observations of some agronomic variables in the ﬁeld (phenological
stages for example, or direct LAI measurements with LAI analyzers, some biomass
sampling ...) could greatly complement the remote sensing data.
More generally, since the acquisition of ﬁeld measurements is expensive, the study
of experimental design can be useful to reduce the number of measurements and to
ﬁnd a compromise between the prediction accuracy and the measurement cost. Not
only the number of data, their precision and the date of observations can be studied,
but of course also the type of measured variables, and the combination of diﬀerent
acquisition sources (e.g LAI analyzer versus satellite / drone image analysis). The
answer would diﬀer with the type of models considered.
The ’Information Theory’ is the scientiﬁc ﬁeld that can help tackle the issue of
Design of Experiments (DOE). A design space has to be chosen, and the question is
mainly about how to identify the aggregation of the data points among all the candidate
points in order to best reﬂect the information in the considered design space. In the
meantime, it is also important to identify some validation points in order to test the
accuracy of the model. Various methods are proposed in the literature, among which
two main statistical approaches (Koehler and Owen (1996), chapter 9), one based
on frequentist sampling technique, like Latin Hypercube Sampling, Scrambled net and
Grids. The other concerns the Bayesian experimental design techniques which takes
into account prior knowledge, such as Minimas Designs, Mean Squared-Error designs
or Maximum Entropy Sampling. For both approaches an optimal design is one that
maximizes a given optimality criterion. The two most suitable DOE techniques for
sequential design problems as for plant growth modelling are D-optimal design and
Bayesian Entropy Sampling.
To sum up, plant growth modelling oﬀers promising perspectives, for example for
virtual experimentation in the context of breeding, or to provide yield potential predic-
tion for decision support. However, there still remain a considerable amount of issues
to be addressed to ensure the quality of model predictions. How to ﬁnd a balance
between the complexity of the model (a good indicator of this complexity being the
number of functional model parameters) and the necessary data for its parameteriza-
tion in order to avoid over-ﬁtting and under-ﬁtting? How do parameters vary across
years, diﬀerent locations or genotypes? How to distinguish and to identify the diﬀerent
sources of variations and uncertainty? How to take into account in the yield prediction
the uncertainty related to the climate (and climate change!)? How to optimize the de-
sign of experiments? These issues should be considered crucial and properly addressed
by the new generation of plant models.

254
10.2. PERSPECTIVES

Publications
• Publications in peer-reviewed journals :
Y.-T. Chen and P.-H. Courn`ede.
Data assimilation to reduce uncertainty of crop
yield prediction based on the Log-normal allocation and senescence crop model and
convolution particle ﬁltering. Ecological Modelling. Accepted, 2014.
Y.-T. Chen, S. Trevezas, P.-H. Courn`ede. A regularized particle ﬁlter EM algorithm
based on Gaussian randomization with an application to plant growth modeling. Sub-
mitted, 2013.
P.-H. Courn`ede, Y.-T. Chen, Q.-L. Wu, C. Baey, B. Bayol. Development and eval-
uation of plant growth models: Methodology and implementation in the Pygmalion
platform. Mathematical Modelling of Natural Phenomena, 2013, 8(4), pages 112-130.
• Publications in peer-reviewed conferences/proceedings :
Y.-T. Chen, S. Trevezas, A. Gupta, P.-H. Courn`ede. Some sequential Monte Carlo
techniques for Data Assimilation in a plant growth model. 15th Conference of Ap-
plied Stochastic Models and Data Analysis (ASMDA, Barcelona, Spain), Proceedings
of ASMDA, 2013.
Y.-T. Chen, S. Trevezas, P.-H. Courn`ede. Iterative convolution particle ﬁltering for
nonlinear parameter estimation and data assimilation with application to crop yield
prediction.
SIAM Conference on Control and its Applications (CT13, San Diego,
USA), pages 67-74, 2013.
B. Bayol, Y.-T. Chen and P.-H. Courn`ede.
Towards an EDSL to Enhance Good
Modeling Practice for Non-linear Stochastic Discrete Dynamical Models - Application
to Plant Growth Models. Third International Conference on Simulation and Mod-
eling Methodologies, Technologies and Applications (SIMULTECH 2013, Reykjavik,
Iceland), SciTePress, pages 132-138, 2013.
Y.-T. Chen and P.-H. Courn`ede. Assessment of parameter uncertainty in plant growth
model identiﬁcation.
Fourth International Symposium on Plant Growth Modeling,
Simulation, Visualization and Applications (PMA’12, Shanghai, China), IEEE press,
pages 85-92, 2012.
Y.-T. Chen, B. Bayol, C. Loi, S. Trevezas, P.-H. Courn`ede.
Filtrage par noyaux
de convolution it´eratif. 44e Journ´ees de Statistique (JdS’2012, Brussels, Belgium),
Proceedings of JdS’2012, 2012.


Annexes


Notations
• Plant Growth State-Space Model
−M : Metamodel.
−Qn : Biomass produced at time n.
−tmax : Last date of observations.
−Θ1 : Functional parameter vector.
−Θ2 : Noise parameter vector.
−Θ : Parameter vector, Θ = (Θ1, Θ2).
−Xn : Hidden state vector.
−Xa
n : Augmented hidden state vector, Xa
n = (Xn, Θn) .
−Yn : Observation vector.
−E : Environmental control vector.
• Probability
−P : Probability.
−E : Expectation.
−∼: Sampled from or distributed according to.
−V : Variance.
−Var, Cov : Variance, covariance.
−diag(V ) : Diagonal matrix with elements of V on the diagonal.
−p(·) : Probability distribution function.

• Abbreviations
−ACF : Autocorrelation function.
−AIC : Akaike information criterion.
−AICc : Akaike information criterion with correction.
−AM : Adaptive Metropolis.
−AMwG : Adaptive Metropolis-within-Gibbs.
−a.s. : almost surely.
−BIC : Bayesian information criterion.
−CLT : Central limit theorem.
−CPF : Convolution particle ﬁlter.
−DA : Data assimilation.
−DIC : Deviance information criterion.
−DREAM : Diﬀerential evolution adaptive Metropolis.
−EM : Expectation-Maximization.
−EnKF : Ensemble Kalman ﬁlter.
−GLS : Generalized least squares.
−i.i.d. : independent and identically distributed.
−KF : Kalman ﬁlter.
−MCMC : Markov chain Monte Carlo.
−MH : Metropolis-Hastings.
−ML : Maximum likelihood.
−MLE : Maximum likelihood estimator.
−RPF : Regularized particle ﬁlter.
−SA : Sensitivity analysis.
−SMC : Sequential Monte Carlo.
−UA : Uncertainty analysis.
−UKF : Unscented Kalman ﬁlter.

Bibliography
S. Adjemian. Prior distributions in Dynare. 2010. URL http://www.dynare.org/
stepan/dynare/text/DynareDistributions.pdf.
H. Akaike. A new look at the statistical model identiﬁcation. IEEE Transactions on
Automatic Control, (6):716–723, 1974.
B. Anderson and J. Moore. Optimal Filtering. Prentice Hall, Englewood Cliﬀs, NJ,
1979.
J. L. Anderson. An ensemble adjustment Kalman ﬁlter for data assimilation. Mon.
Wea. Rev., 129:2884–2903, 2001.
C. Andrieu and A. Doucet.
Online expectation-maximization type algorithms for
parameter estimation in general state space models. In Proc. IEEE Conf. ICASSP,
pages 69–72, 2003.
C. Andrieu and G. O. Roberts. The pseudo-marginal approach for eﬃcient computa-
tions. Annals of Statistics, 37(2):697–725, 2009.
C. Andrieu and J. Thoms. A tutorial on adaptive MCMC. Statistics and Computing,
18:343–373, 2008.
C. Andrieu, N. de Freitas, and A. Doucet. Robust full Bayesian learning for radial
basis networks, 2001.
C. Andrieu, A. Doucet, and R. Holenstein. Particle Markov chain Monte Carlo meth-
ods. Journal of the Royal Statistical Society, (72):269–342, 2010.
M. Arulampalam, S. Maskell, N. Gordon, and T. Clapp. A tutorial on particle ﬁlters
for online nonlinear/non-Gaussian Bayesian tracking. In Connection between forest
resources and wood quality: modelling approaches and simulation software, number
50(2), pages 174–188. IEEE Trans. Signal Proces., 2002.
K. B. Athreya, H. Doss, and J. Sethuraman. On the convergence of the Markov chain
simulation method. The Annals of Statistics, 24(1):1–448, 1996.
C. Baey. Mod´elisation de la variabilit´e inter-individuelle dans les mod`eles de croissance
de plantes et s´election de mod`eles pour la pr´evision. PhD thesis, Ecole Centrale Paris,
2014.
261

C. Baey and P.-H. Courn`ede.
Using a hierarchical segmented model to assess the
dynamics of leaf appearance in plant populations. In Proceedings of ASMDA 2011,
2011.
C. Baey, A. Didier, S. Li, S. Lemaire, F. Maupas, and P.-H. Courn`ede. Evaluation of the
predictive capacity of ﬁve plant growth models for sugar beet. In 4th international
symposium on Plant Growth and Applications (PMA12), Shanghai, China. IEEE,
2012.
C. Baey, A. Didier, S. Lemaire, F. Maupas, and P.-H. Courn`ede. Parametrization of
ﬁve classical plant growth models applied to sugar beet and comparison of their
predictive capacity on root yield and total biomass. Ecological Modelling, 2013a.
C. Baey, A. Didier, S. Lemaire, F. Maupas, and P.-H. Courn`ede. Modelling the in-
terindividual variability of organogenesis in sugar beet populations using a hierar-
chical segmented model. Ecological Modelling, 263:56–63, 2013b.
C. Baey, S. Trevezas, and P.-H. Courn`ede. A nonlinear mixed eﬀects model of plant
growth and estimation via stochastic variants of the EM algorithm.
Submitted,
2014.
F. Baret, V. Houles, and M. Gu´erif. Quantiﬁcation of plant stress using remote sens-
ing observations and crop models: the case of nitrogen management. Journal of
Experimental Botany, 58(4):869–880, 2007.
T. Bayes. An essay towards solving a problem in the doctrine of chances. Philosophical
Transactions of the Royal Society of London, 53(370), 1763.
B. Bayol, Y. Chen, and P.-H. Courn`ede. Towards an EDSL to enhance good modeling
practice for non-linear stochastic discrete dynamical models - application to plant
growth models. In International Conference on Simulation and Modeling Method-
ologies, Technologies and Applications (SIMULTECH), 2013, Reykjavik, Iceland,
2013.
M. A. Beaumont. Estimation of population growth or decline in genetically monitored
populations. Genetics, 164:1139–1160, 2003.
M. B´edard. Optimal acceptance rates for Metropolis algorithms: Moving beyond 0.234.
Stochastic Processes and their Applications, 118(12):2198–2222, 2008.
J. Berger and R. Wolpert.
The Likelihood Principle.
Hayward, CA: Institute of
Mathematical Statistics, 1984.
J. Bertheloot, P.-H. Courn`ede, and B. Andrieu. NEMA, a functional-structural model
of nitrogen economy within wheat culms after ﬂowering: I. Model description. Annals
of Botany, 108(6), 2011.
J. G. Booth, J. P. Hobert, and W. Jank. A survey of Monte Carlo algorithms for
maximizing the likelihood of a two-stage hierarchical model. Statistical Modelling,
1(4):333–349, 2001.

J. G. J. Booth and J. P. J. Hobert. Maximizing generalized linear mixed model likeli-
hoods with an automated Monte Carlo EM algorithm. 61(1):265–285, 1999.
L. Bordes, D. Chauveau, and P. Vandekerkhove. A stochastic EM algorithm for a
semiparametric mixture model. Comp. Stat. and Data Analysis, 51:5429–5443, 2007.
B. Bouman.
Linking physical remote sensing models with crop growth simulation
models, applied for sugar beet. International Journal of Remote Sensing, 13(14):
2565–2581, 1992. doi: 10.1080/01431169208904064.
E. Bradley and R. Tibshirani. An Introduction to the Bootstrap. Chapman & Hal-
l/CRC, 1994.
N. Brisson, B. Mary, M. H. Ripoche, D.and Jeuﬀroy, F. Ruget, B. Nicoullaud, P. Gate,
F. Devienne-Barret, R. Antonioletti, C. Durr, G. Richard, N. Beaudoin, S. Recous,
X. Tayot, D. Plenet, P. Cellier, J. Machet, J. M. Meynard, and R. Delecolle. Stics :
a generic model for the simulation of crops and their water and nitrogen balances.
i. theory, and parameterization applied to wheat and corn. Agronomie, 18:311–346,
1998.
N. Brisson, C. Gary, E. Justes, R. Roche, B. Mary, D. Ripoche, D. Zimmer, J. Sierra,
P. Bertuzzi, P. Burger, F. Bussi`ere, Y. Cabidoche, P. Cellier, P. Debaeke, J. Gaudil-
l`ere, C. H´enault, F. Maraux, B. Seguin, and H. Sinoquet. An overview of the crop
model STICS. European Journal of Agronomy, 18:309–332, 2003.
N. Brisson, M. Launay, B. Mary, and N. Beaudoin, editors. Conceptual Basis, Formal-
isations and Parameterization of the Stics Crop Model. ´Editions QUAE, Versailles,
France, 2008.
S. Brooks and G. Roberts. Assessing convergence of Markov chain Monte Carlo algo-
rithms. Statistics and Computing, 8:319–335, 1998.
G. Buck-Sorlin and K. Bachmann. Simulating the morphology of barley spike pheno-
types using genotype information. Agronomie, 20:691–702, 2000.
K. Burnham and D. Anderson. Model selection and multimodel inference: a practical
information-theoretic approach. Springer Verlag, 2nd editio edition, 2002.
B. S. Caﬀo, W. Jank, and G. L. Jones. Ascent-based Monte Carlo expectation- maxi-
mization. 67(2):235–251, 2005.
F. Campillo and V. Rossi.
Convolution particle ﬁlter for parameter estimation in
general state-space models. IEEE Transactions in Aerospace and Electronics., 45
(3):1063–1072, 2009.
F. Campillo, R. Rakotozafy, and V. Rossi.
Parallel and interacting Markov chain
Monte Carlo algorithm. Mathematics and Computers in Simulation, 79:3424–3433,
2009.

F. Campolongo, J. Cariboni, and A. Saltelli. An eﬀective screening design for sensitiv-
ity analysis of large models. Environmental Modelling and Software, 22:1509–1518,
2007.
O. Capp´e, A. Guillin, J.-M. Marin, and C. P. Robert. Population Monte Carlo. Journal
of Computational and Graphical Statistics, 13:907–929, 2004.
O. Capp´e, E. Moulines, and T. Ryd´en. Inference in Hidden Markov Models. Springer,
New York, 2005.
F. Caron.
Inf´erence Bay´esienne pour la D´etermination et la S´election de Mod`eles
Stochastiques. PhD thesis, Ecole Centrale de Lille, 2006.
C. Carter and R. Kohn. On Gibbs sampling for state space models. Biometrika, 83
(3):541–553, 1994.
G. Casella and E. Lehmann. Theory of point estimation. Springer, Berlin, 1998.
J. E. Cavanaugh. Unifying the derivations for the Akaike and Corrected Akaike Infor-
mation Criteria, 1997.
G. Celeux and J. Diebolt.
The SEM algorithm: a probabilistic teacher algorithm
derived from the EM algorithm for the mixture problem. Computational Statistics
Quarterly, 2:73–82, 1985.
D. Chauveau and J. Diebolt. An automated stopping rule for MCMC convergence
assessment. Computational Statistics, 14(3):419–442, 1999.
D. Chauveau and J. Diebolt. Estimation of the asymptotic variance in the CLT for
Markov chains. Stochastic Models, 19(4):449–465, 2003.
D. Chauveau and P. Vandekerkhove. Improving convergence of the Hastings-Metropolis
algorithm with a learning proposal. Scan J Stat, 29:13–29, 2002.
Y. Chen and P.-H. Courn`ede. Assessment of parameter uncertainty in plant growth
model identiﬁcation. In M. Kang, Y. Dumont, and Y. Guo, editors, Plant growth
Modeling, simulation, visualization and their Applications (PMA12), 2012.
Y. Chen and P.-H. Courn`ede. Data assimilation to reduce uncertainty of crop yield
prediction based on the log-normal allocation and senescence crop model and con-
volution particle ﬁltering. Ecological Modelling, Accepted, 2014.
Y. Chen, S. Trevezas, and P.-H. Courn`ede. Iterative convolution particle ﬁltering for
nonlinear parameter estimation and data assimilation with application to crop yield
prediction. In Society for Industrial and Applied Mathematics (SIAM): Control &
its Applications, San Diego, USA, 2013a.
Y. Chen, S. Trevezas, and P.-H. Courn`ede. A regularized particle ﬁlter EM algorithm
based on Gaussian randomization with an application to plant growth modeling.
Submitted, 2013b.

G. Claeskens and N. L. Hjort. Model Selection And Model Averaging. Cambridge
Series In Statistical And Probabilistic Mathematics. Cambridge University Press,
New York, 2008.
P.-H. Courn`ede, V. Letort, A. Mathieu, M.-Z. Kang, S. Lemaire, S. Trevezas, F. Houl-
lier, and P. de Reﬀye. Some parameter estimation issues in functional-structural
plant modelling. Mathematical Modelling of Natural Phenomena, 6(2):133–159, 2011.
P.-H. Courn`ede, Y. Chen, Q. Wu, C. Baey, and B. Bayol. Development and evaluation
of plant growth models: Methodology and implementation in the PYGMALION
platform. Mathematical Modelling of Natural Phenomena, 8:112–130, 2013.
D. Crisan, P. Del Moral, and T. Lyons. Discrete Filtering Using Branching and Inter-
acting Particle Systems. Markov Processes and Related Fields, 5(3):293–318, 1998.
F. d’Alch´e Buc and N. Brunel. Estimation of Parametric Nonlinear ODEs for Biolog-
ical Networks Identiﬁcation, pages 61–96. 2010. MIT Press.
A. Davison and D. Hinkley. Bootstrap Methods and their Application. Cambridge
University Press, Cambridge, UK, 1997.
P. de Reﬀye, F. Blaise, S. Chemouny, T. Fourcaud, and F. Houllier. Calibration of
hydraulic growth model on the architecture of cotton plants. Agronomie, 19:265–280,
1999.
P. de Reﬀye, M. Goursat, J. Quadrat, and B. Hu. The Dynamic Equations of the Tree
Morphogenesis Greenlab Model. Technical Report 4877, INRIA, 2003.
P. de Valpine.
Review of methods for ﬁtting time-series models with process and
observation error and likelihood calculations for nonlinear, non-Gaussian state-space
models. Bulletin of Marine Science, 70(2):455–471, 2002.
P. de Valpine and A. Hastings. Fitting population models incorporating process noise
and observation error. Ecological Monographs, 72(1):57–76, 2002.
P. Debashis, P. Jie, and B. Prabir. Semiparametric modeling of autonomous nonlin-
ear dynamical systems with application to plant growth. The Annals of Applied
Statistics, 5(3):2078–2108, 2011.
P. Del Moral. Nonlinear Filtering: Interacting Particle Resolution. Markov Processes
and Related Fields, 2(4):555–580, 1996.
R. Del´ecolle, S. Maas, M. Gu´erif, and F. Baret. Remote sensing and crop production
models: present trends. ISPRS Journal of Photogrammetry and Remote Sensing, 47
(23):145 – 161, 1992.
C. Deleuze. Pour une dendrom´etrie fonctionnelle: essai sur l’int´egration de connais-
sances ´ecophysiologiques dans les mod`eles de production ligneuse. PhD thesis, Uni-
verist´e Claude Bernard - Lyon I, 1996.

B. Delyon, M. Lavielle, and E. Moulines. Convergence of a stochastic approximation
version of the EM algorithm. Annals of Statistics, 27:94–128, 1999.
A. Dempster. The direct use of likelihood for signiﬁcance testing. In In Proceedings
of Conference on Foundational Questions in Statistical Inference, pages 335–352.
Department of Theoretical Statistics, University of Aarhus, 1974.
A. Dempster, N. Laird, and D. Rubin. Maximum Likelihood from incomplete data
via the EM algorithm. Journal of the Royal Statistical Society. Series B (Statistical
Methodology), 39:1–38, 1977.
B. Dennis, J. M. Ponciano, S. R. Lele, M. L. Taper, and D. F. Staples. Estimating
density dependence, process noise, and observation error. Ecological Monographs, 76
(3):323–341, 2006.
L. Dente, G. Satalino, F. Mattia, and M. Rinaldi. Assimilation of leaf area index
derived from ASAR and MERIS data into CERES-wheat model to map wheat yield.
Remote Sensing of Environment, 112(4):1395 – 1407, 2008.
L. Devroye and G. Lugosi. Combinatorial Methods in Density Estimation. Springer
Verlag New York, 2001.
S. Donnet, J.-L. Foulley, and A. Samson. Bayesian analysis of growth curves using
mixed models deﬁned by stochastic diﬀerential equations. Biometrics, 66(3):733–
741, 2010.
W. Dorigo, R. Zurita-Milla, A. de Wit, J. Brazile, R. Singh, and M. Schaepman. A
review on reﬂective remote sensing and data assimilation techniques for enhanced
agroecosystem modeling. International Journal of Applied Earth Observation and
Geoinformation, 9(2):165 – 193, 2007.
R. Douc, O. Capp´e, and E. Moulines. Comparison of resampling schemes for particle
ﬁltering. CoRR, 2005.
A. Doucet, N. De Freitas, and N. Gordon. Sequential Monte Carlo methods in practice.
Springer-Verlag, New-York, 2001.
M. M. Drugan and D. Thierens. Recombinative emcmc algorithms. In Congress on
Evolutionary Computation, pages 2024–2031. IEEE, 2005.
B. Efron and R. Tibshirani. An Introduction to the Bootstrap. Chapman & Hall/CRC
Monographs on Statistics and Applied Probability, 1994.
G. Evensen. Sequential data assimilation with a nonlinear quasi-geostrophic model
using Monte Carlo methods to forecast error statistics. J. Geophys. Res., (99(C5)):
10143–10162, 1994.
G. Evensen. Data assimilation: The ensemble Kalman Filter. Springer, 2006.
P. Fearnhead. Exact and eﬃcient inference for multiple changepoint problems. Statis-
tics and Computing, 16:203–213, 2006.

P. Fearnhead. MCMC for State-Space Models. In Brooks, Steve (ed.) et al., editor,
Handbook of Markov chain Monte Carlo. Boca Raton, FL: CRC Press. Chapman,
2011.
J. M. Flegal and G. L. Jones. Batch means and spectral variance estimators in Markov
chain Monte Carlo. The Annals of Statistics, 38(2):1034–1070, Apr. 2010.
E. D. Ford and M. C. Kennedy. Assessment of uncertainty in functional-structural
plant models. Annals of Botany, 108(6):1043–1053, 2011. doi: 10.1093/aob/mcr110.
G. Fort and E. Moulines. Convergence of the monte carlo expectation maximization
for curved exponential families. The Annals of Statistics, 31(4):1220–1259, 2003.
J.-L. Foulley and D. A. Van Dyk. The PX-EM algorithm for fast stable ﬁtting of
Henderson’s mixed model. Genetics Selection Evolution, 32(2):1–21, 2012.
J.-L. Foulley, F. Jaﬀr´ezic, and C. Robert-Grani´e. EM-REML estimation of covari-
ance parameters in Gaussian mixed models for longitudinal data analysis. Genetics
Selection Evolution, 32(2):129–141, 2000.
T. Fourcaud, X. Zhang, A. Stokes, H. Lambers, and C. K¨orner. Plant growth modelling
and applications: The increasing importance of plant architecture in growth models.
Annals of Botany, 101(8), 2008.
D. B. Fowler, A. E. Limin, and J. T. Ritchie. Low-temperature tolerance in cereals:
Model and genetic interpretation. Crop Science, 39(3):626–633, 2003.
B. Gabrielle, R. Roche, P. Angas, C. Cantero-Martinez, L. Cosentino, M. Mantineo,
M. Langen-Siepen, C. H´enault, P. Laville, B. Nicoullaud, and G. Gosse. A priori
parameterisation of the ceres soil-crop models and tests against several European
data sets. Agronomie, 22-2:119–132, 2002.
C. Gaucherel, F. Campillo, L. Misson, J. Guiot, and J. Boreux. Parameterization of a
process-based tree growth model: Comparison of optimization, mcmc and particle
ﬁltering algorithms. Environmental Modelling and Software, 23(10-11):1280–1288,
2008.
A. E. Gelfand, S. E. Hills, A. Racine-Poon, and A. F. M. Smith.
Illustration of
Bayesian inference in normal data models using Gibbs sampling. Journal of the
American Statistical Association, 85(412):972–985, 1990.
A. Gelman, C. Robert, N. Chopin, and J. Rousseau. Bayesian data analysis, 1995.
A. Gelman, G. Roberts, and W. Gilks. Eﬃcient Metropolis jumping rules. Bayesian
Statistics, V:599–608, 1996.
A. Gelman, J. B. Carlin, H. Stern, and D. Rubin. Bayesian data analysis, 2nd edition.
London, Chapman & Hall, 2004.
D. Gelman, A.and Rubin. Inference from iterative simulation using multiple sequences.
Statistical Science, 7:457–511, 1992.

S. Geman and D. Geman. Stochastic relaxation, Gibbs distributions, and the Bayesian
restoration of images. IEEE Transactions on Pattern Analysis and Machine Intel-
ligence, 6:721–741, 1984.
C. Geyer. Markov chain Monte Carlo maximum likelihood. Computing science and
Statistics: proceedings of the 23rd Symposium on the interface, pages 156–163, 1991.
C. Geyer. Practical Markov chain Monte Carlo (with discussion). Statistical Science,
7(4):473–482, 1992.
W. Gilks, G. Roberts, and E. George. Adaptive direction sampling. Statistician, (43):
179–189, 1994.
W. Gilks, G. Roberts, and S. Sahu. Adaptive Markov chain Monte Carlo through
regeneration. J Amer Stat Assoc, (93):1045–1054, 1998.
N. Gordon, D. Salmond, and A. Smith. A novel approach to nonlinear/non-Gaussian
Bayesian state estimation. Proc. Inst. Electr. Eng., Part F 140:107–113, 1993.
M. Gu´erif and C. Duke. Calibration of the SUCROS emergence and early growth
module for sugar beet using optical remote sensing data assimilation.
European
Journal of Agronomy, 9:127–136, 1998.
M. Gu´erif and C. Duke. Adjustment procedures of a crop model to the site speciﬁc
characteristics of soil and crop using remote sensing data assimilation. Agriculture,
ecosystems & environment, 81(1):57–69, 2000.
M. Gu´erif, V. Houl`es, D. Makowski, and C. Lauvernet. Data assimilation and param-
eter estimation for precision agriculture using the crop model stics. In D. Wallach,
D. Makowski, and J. Jones, editors, Working with Dynamic Crop Models, pages
391–398. Elsevier, 2006.
Y. Guo, Y. Ma, Z. Zhan, B. Li, M. Dingkuhn, D. Luquet, and P. de Reﬀye. Parameter
optimization and ﬁeld validation of the functional-structural model Greenlab for
maize. Annals of Botany, 97:217–230, 2006.
H. Haario, S. J., and J. Tamminen. Adaptive proposal distribution for random walk
Metropolis algorithm. Comput. Statist., 14:375–395, 1999.
H. Haario, S. J., and J. Tamminen. An adaptive Metropolis algorithm. Bernoulli, 7:
223–242, 2001.
H. Haario, M. Laine, A. Mira, and E. Saksman. DRAM: Eﬃcient adaptive MCMC.
Statistics and Computing, 16(4):339–354, 2006.
J. Hamilton. Time Series Analysis. Princeton University Press, 1994.
G. Hammer, M. Cooper, F. Tardieu, S. Welch, B. Walsh, F. Van Eeuwijk, S. Chapman,
and D. Podlich. Models for navigating biological complexity in breeding improved
crop plants. Trends in Plant Science, 11(12):587–593, 2006.

J. Harrison and M. West. Bayesian Forecasting and Dynamic Models. Springer-Verlag,
1989.
J. Hartigan. Note on the conﬁdence prior of Welch and Peers. J. Roy. Statist. Soc. B,
28:55–56, 1966.
W. Hastings. Monte Carlo sampling methods using Markov chains and their applica-
tions. Biometrika, 57(1):97–109, 1970.
C. Heinrich. The mode functional is not elicitable. Biometrika, 101(1):245–251, 2014.
R. Hilborn and M. Ledbetter. Analysis of the British Columbia salmon purse-seine
ﬂeet: Dynamics of movement. J. Fish. Res, 36(4):384–391, 1979.
J. Hillier, D. Makowski, and B. Andrieu. Maximum likelihood inference and bootstrap
methods for plant organ growth via multi-phase kinetic models and their application
to maize. Annals of Botany, (96):137–148, 2005.
M. Y. Hirai, M. Yano, D. B. Goodenowe, S. Kanaya, T. Kimura, M. Awazuhara,
M. Arita,
T. Fujiwara,
and K. Saito.
Integration of transcriptomics and
metabolomics for understanding of global responses to nutritional stresses in ara-
bidopsis thaliana. Proceedings of the National Academy of Sciences of the United
States of America, 101(27):10205–10210, 2004. doi: 10.1073/pnas.0403218101.
V. Houl`es, B. Mary, M. Gu´erif, D. Makowski, and E. Justes. Evaluation of the ability
of the crop model STICS to recommend nitrogen fertilisation rates according to
agro-environmental criteria. Agronomie, 24:339–349, 2004.
P. J. Huber.
The behavior of maximum likelihood estimation under nonstandard
conditions.
In L. M. L. Cam and J. Neyman, editors, Proceedings of the Fifth
Berkeley Symposium on Mathematical Statistics and Probability, Berkeley, CA, 1967.
University of California Press.
C. M. Hurvich and C. Tsai. Regression and time series model selection in small samples.
Biometrika, 76:297–307, 1989.
I. A. Ibragimov and Y. V. Linnik. Independent and Stationary Sequences of Random
Variables. Wolters-Noordhoﬀ, Groningen, 1971.
A. Jasra, D. A. Stephens, and C. C. Holmes. On population-based simulation for static
inference. Statistics and Computing, (3):263–279, 2007.
E. T. Jaynes. Conﬁdence intervals vs Bayesian intervals. Foundations of Probability
Theory, Statistical Inference, and Statistical Theories of Science, pages 175–258,
1976.
A. Jazwinski. Stochastic Processes and Filtering Theory. Academic Press, New York,
1970.
C. Jones and J. Kiniry. CERES-Maize : A simulation model of maize growth and
development. Texas A&M University Press, 1986.

G. Jones and J. Hobert. Honest exploration of intractable probability distributions via
Markov chain Monte Carlo. Statistical Science, 16:312–334, 2001.
G. Jones and J. Hobert. Suﬃcient burn-in for Gibbs samplers for a hierarchical random
eﬀects model. The Annals of Statistics, 32:784–817, 2004.
G. L. Jones, M. Haran, B. S. Caﬀo, and R. Neath. Fixed-width output analysis for
Markov chain Monte Carlo. Journal of the American Statistical Association, 101:
1537–1547, 2006.
J. Jones and W. Graham. Application of extended and ensemble Kalman ﬁlters to
soil carbon estimation. In D. Wallach, D. Makowski, and J. Jones, editors, Working
with Dynamic Crop Models, pages 55–100. Elsevier, 2006.
S. Julier and J. Uhlmann. A new extension of the Kalman ﬁlter to nonlinear systems.
International Symposium of Aerospace/Defense Sensing, Simulation and Controls,
1997. Orlando. Fl.
S. Julier, J. Uhlmann, and H. Durrant-Whyte. A new method for the nonlinear trans-
formation of means and covariances in ﬁlters and estimators. IEEE Transaction on
Automatic Control, 45(3):477–482, 2000.
A. Jullien, J.-M. Allirand, A. Mathieu, B. Andrieu, and B. Ney. Variations in leaf
mass per area according to nitrogen nutrition, plant age, and leaf position reﬂect
ontogenetic plasticity in winter oilseed rape (brassica napus l.). Field Crops Research,
114(2):188 – 197, 2009.
T. Kailath, A. Sayed, and B. Hassibi. Linear Estimation. Information and System
Sciences. Prentice Hall, Upper Saddle River, New Jersey, 2000.
J. Kaipio and E. Somersalo. Statistical and Computational Inverse problems. Applied
Mathematical Science. Springer Science, 2005.
R. Kalman. A new approach to linear ﬁltering and prediction problem. Journal of the
basic engineering, 82:35–45, 1960.
B. Keating, P. Carberry, G. Hammer, M. Probert, M. Robertson, D. Holzworth,
N. Huth, J. Hargreaves, H. Meinke, Z. Hochman, G. McLean, K. Verburg, V. Snow,
J. Dimes, M. Silburn, E. Wang, S. Brown, K. Bristow, S. Asseng, S. Chapman,
R. McCown, D. Freebairn, and C. Smith. An overview of APSIM, a model designed
for farming systems simulation. European Journal of Agronomy, 18(3-4):267–288,
2003.
G. Kitagawa. Monte Carlo ﬁlter and smoother for non-Gaussian nonlinear state space
models. Journal of Computational and Graphical Statistics, 5(1):1–25, 1996.
J. R. Koehler and A. Owen. Computer experiments. In Handbook of statistics 13.
1996.
A. Kong, J. Liu, and W. Wong. Sequential imputations and Bayesian missing data
problems. Journal of the American Statistical Association, 89(425):278–288, 1994.

M. Lamboni, H. Monod, and D. Makowski. Multivariate sensitivity analysis to measure
global contribution of input factors in dynamic models. Reliability Engineering &
System Safety, 96(4):450–459, 2011.
K. B. Laskey and J. Myers.
Population Markov chain Monte Carlo.
In Machine
Learning, pages 175–196. University Press, 2003.
M. Launay and M. Gu´erif. Assimilating remote sensing data into a crop model to
improve predictive performance for spatial applications. Agriculture, Ecosystems &
Environment, 111:321–339, 2005.
F. Le Gland and N. Oudjane. Stability and uniform approximation of nonlinear ﬁlters
using the Hilbert metric and application to particle ﬁlters. Ann. Appl. Probab., 14
(1):144–187, 2004. doi: 10.1214/aoap/1075828050.
F. Le Gland, C. Musso, and N. Oudjane.
An Analysis of Regularized Interacting
Particle Methods for Nonlinear Filtering. In Proceedings of the 3rd IEEE European
Workshop on Computer-Intensive Methods in Control and Signal Processing, pages
167–174, 1998.
J. Lecoeur, R. Poir´e-Lassus, A. Christophe, B. Pallas, P. Casadebaig, P. Debaeke,
F. Vear, and L. Guilioni. Quantifying physiological determinants of genetic variation
for yield potential in sunﬂower. sunﬂo: a model-based analysis. Functional Plant
Biology, 38:246–259, 2011.
S. Lemaire, F. Maupas, P.-H. Courn`ede, and P. de Reﬀye. A morphogenetic crop model
for sugar-beet (beta vulgaris l.). In International Symposium on Crop Modeling and
Decision Support: ISCMDS 2008, April 19-22, 2008, Nanjing, China, 2008.
S. Lemaire, F. Maupas, P.-H. Courn`ede, J.-M. Allirand, P. de Reﬀye, and B. Ney.
Analysis of the density eﬀects on the source-sink dynamics in sugar-beet growth.
In B.-G. Li, M. Jaeger, and Y. Guo, editors, 3rd international symposium on Plant
Growth and Applications(PMA09), Beijing, China. IEEE Computer Society (Los
Alamitos, California), November 9-12 2009.
R. A. Levine and G. Casella. Implementations of the Monte Carlo EM algorithm.
Journal of Computational and Graphical Statistics, 10(3):422–439, 2001.
J. Liu. Fraction of missing information and convergence rate of data augmentation.
Interface Foundation of North America, Fairfax Station, VA, 1994.
J. Liu, W. Wong, and A. Kong. Covariance structure and convergence rate of the
Gibbs sampler with applications to the comparisons of estimators and augmentation
schemes. Biometrika, 81:27–40, 1994.
C. Loi. Analyse probabiliste, ´etude combinatoire et estimation param´etrique pour une
classe de mod`eles de croissance de plantes avec organogen`ese stochastique.
PhD
thesis, Ecole Centrale Paris, 2011.

C. Loi, P.-H. Courn`ede, and S. Trevezas. Bayesian estimation in Functional-Structural
Plant Models with stochastic organogenesis. In Proceedings of ASMDA, 2011.
D. Ludwig and C. Walters. Measurement errors and uncertainty in parameter estimates
for stock and recruitment. Canadian Journal of Fisheries and Aquatic Sciences, 38
(6):711–720, 1981.
S. J. Maas. Using satellite data to improve model estimates of crop yield. Agronomy
Journal, 80(4):655–662, 1988.
J. Mailhol, A. Olufayo, and P. Ruelle. Sorghum and sunﬂower evapotranspiration and
yield from simulated leaf area index. Agri. Water Manag., 35:167–182, 1997.
D. Makowski, D. Wallach, and M. Tremblay. Using a Bayesian approach to parameter
estimation; comparison of the GLUE and MCMC methods. Agronomie, 22(2):191–
203, 2002.
D. Makowski, J. Jeuﬀroy, and M. Gu´erif. Bayesian methods for updating crop-model
predictions, applications for predicting biomass and grain protein content. Wagenin-
gen UR Frontis Series, 2004.
D. Makowski, J. Hillier, D. Wallach, B. Andrieu, and M.-H. Jeuﬀroy.
Parameter
estimation for crop models. In D. Wallach, D. Makowski, and J. Jones, editors,
Working with Dynamic Crop Models, pages 55–100. Elsevier, 2006.
M. Matsumoto and T. Nishimura. Mersenne twister: A 623-dimensionally equidis-
tributed uniform pseudo-random number generator. ACM Trans. Model. Comput.
Simul., 8(1):3–30, 1998.
J. P. Mattern, M. Dowd, and K. Fennel. Particle ﬁlter-based data assimilation for
a three-dimensional biological ocean model and satellite observations. J. Geophys.
Res. Oceans, 118(5):2746–2760, 2013.
C. E. McCulloch.
Maximum likelihood variance components estimation for binary
data. Journal of the American Statistical Association, 89(425):330–335, 1994.
C. E. McCulloch. Maximum likelihood algorithms for generalized linear mixed models.
Journal of the American statistical Association, 92(437):162–170, 1997.
G. McLachlan and T. Krishnan. The EM Algorithm and Extensions. John Wiley &
Sons Inc., 2008.
X.-L. Meng and D. B. Rubin. Maximum likelihood estimation via the ECM algorithm:
A general framework. Biometrika,, 80:267–278, 1993.
K. L. Mengersen and C. P. Robert. Population Markov chain Monte Carlo: the pinball
sampler. in Bayesian Statistics, Oxford University Press, 2003.
N. Metropolis, A. Rosenbluth, M. Rosenbluth, A. Teller, and E. Teller. Equations
of state calculations by fast computing machines. J. Chem. Phys., 21(1087-1091),
1953.

C. Meza, F. Jaﬀr´ezic, and J.-L. Foulley. REML estimation of variance parameters
in nonlinear mixed eﬀects models using the SAEM algorithm. Biometrical journal.
Biometrische Zeitschrift, 49(6):876–88, 2007.
R. Mittler. Abiotic stress, the ﬁeld environment and stress combination. Trends in
Plant Science, 11(1):15 – 19, 2006.
H. Monod, C. Naud, and D. Makowski. Uncertainty and sensitivity analysis for crop
models. In D. Wallach, D. Makowski, and J. Jones, editors, Working with Dynamic
Crop Models, pages 55–100. Elsevier, 2006.
J. Monteith. Climate and the eﬃciency of crop production in Britain. Proceedings of
the Royal Society of London B, 281:277–294, 1977.
M. Moran, Y. Inoue, and E. Barnes. Opportunities and limitations for image-based
remote sensing in precision crop management. Remote Sensing of Environment, 61
(3):319 – 346, 1997.
S. Moulin, A. Bondeau, and R. Delecolle. Combining agricultural crop models and
satellite observations: From ﬁeld to regional scales. International Journal of Remote
Sensing, 19(6):1021–1036, 1998. doi: 10.1080/014311698215586.
L. M. Murray. Distributed Markov chain Monte Carlo. In NIPS Workshop: Learning
on Cores, Clusters and Clouds, 2010.
C. Musso and N. Oudjane. Regularization schemes for branching particle systems as
a numerical solving method of the nonlinear ﬁltering problem. In Proceedings of the
Irish Signals and Systems Conference, 1998.
C. Musso, N. Oudjane, and F. Le Gland. In A. Doucet, N. de Freitas, and N. Gordon,
editors, Sequential Monte Carlo Methods in Practice. New York.
P. Mykland, L. Tierney, and B. Yu. Regeneration in Markov chain samplers. Journal
of the American Statistical Association, 90:233–241, 1995.
C. Naud, D. Makowski, and M.-H. Jeuﬀroy. Application of an interacting particle
ﬁlter to improve nitrogen nutrition index predictions for winter wheat. Ecological
Modelling, 207(24):251 – 263, 2007.
N. Oudjane and C. Musso. Regularized particle schemes applied to the tracking prob-
lem. In International Radar Symposium, Munich, Proceedings, 1998.
N. Oudjane and C. Musso. Multiple model particle ﬁlter. In 17`eme Colloque GRETSI,
Vannes 1999, pages 681–684, 1999.
E. Parzen. On Estimation of a Probability Density Function and Mode. Annals of
Mathematical Statistics, 33:1065–1076, 1962.
D. Pham. Stochastic Methods for Sequential Data Assimilation in Strongly Nonlinear
Systems. Monthly Weather Review, 129(5):217–244, 2001.

T. Polacheck, R. Hilborn, and A. Punt. Fitting surplus production models: Comparing
methods and measuring uncertainty. Can. J. Fish. Aquat. Sci., 50:2597–2607, 1993.
B. T. Polyak and A. B. Juditsky. Acceleration of stochastic approximation by averag-
ing. SIAM Journal on Control and Optimization, 30(4):838–855, 1992.
M. Quach, N. Brunel, and F. d’Alch´e Buc. Estimating parameters and hidden variables
in non-linear state-space models based on odes for biological networks inference.
Bioinformatics, 23(23):3209–3216, 2007.
L. Rabiner. A tutorial on hidden Markov models and selected applications in speech
recognition. Proc. IEEE, 77:257–284, 1989.
L. R. Rabiner and B. H. Juang. An introduction to hidden Markov models. IEEE
ASSP Magazine, pages 4–15, 1986.
C. Rao. Linear Statistical Inference and Its Applications. Wiley, New York, 1973.
A. Rau, F. Jaﬀr´ezic, J.-L. Foulley, and R. Doerge. An empirical Bayesian method for
estimating biological networks from temporal microarray data. Statistical Applica-
tions in Genetics and Molecular Biology, 9(1):1–28, 2010.
A. Rau, F. Jaﬀr´ezic, J.-L. Foulley, and R. Doerge. Reverse Engineering Gene Regula-
tory Networks Using Approximate Bayesian Computation. Statistics and Comput-
ing, 22:1257–1271, 2011.
R. H. Reichle, P. W. Jeﬀrey, D. K. Randal, and R. H. Paul. Extended versus ensemble
Kalman ﬁltering for land data assimilation. J. Hydrometeorol., 3(6):728–740, 2002.
B. Ripley. Stochastic Simulation. John Wiley, 1988.
H. Robbins and S. Monro. A stochastic approximation method. The Annals of Math-
ematical Statistics, pages 400–407, 1951.
C. Robert. The Bayesian Choice. Springer Texts in Statistics Series. Springer-Verlag,
2001.
C. Robert and G. Casella. Monte Carlo Statistical Methods. Springer Texts in Statistics
Series. Springer-Verlag GmbH, 1999.
C. Robert, T. Ryd´en, and D. Titterington. Convergence controls for MCMC algo-
rithms, with applications to hidden Markov chains. Journal of Statistical Computa-
tion and Simulation, 64:327–355, 1999.
C. P. Robert and G. Casella. Introducing Monte Carlo methods with R. Springer, New
York, 1 edition, 2010.
G. Roberts. Markov chain concepts related to sampling algorithms. Markov Chain
Monte Carlo in Practice, 7:45–57, 1996.
G. Roberts and J. Rosenthal. Statistical Science.

G. Roberts and J. Rosenthal. General state space Markov chains and MCMC algo-
rithms. Probability Surveys, 1:20–71, 2004.
G. Roberts and S. K. Sahu. Updating schemes, correlation structure, blocking and
parameterization for the Gibbs sampler. Journal of the Royal Statistical Society,
Series B, 59:291–317, 1997.
G. Roberts and R. Tweedie. Understanding MCMC. Springer, 2008.
G. Roberts, A. Gelman, and W. Gilks. The annals of applied probability.
J. S. Rosenthal. Minorization conditions and convergence rates for Markov chain Monte
Carlo. Journal of the American Statistical Association, 90:558–566, 1995.
V. Rossi. Filtrage non lin´eaire par noyaux de convolution: Application `a un proc´ed´e
de d´epollution biologique. PhD thesis, Ecole National Sup´erieure Agronomique de
Montpellier, 2004.
V. Rossi and J.-P. Vila. Nonlinear ﬁltering in discrete time: A particle convolution
approach. Ann. Inst. Stat. Univ. Paris, 3:71–102, 2006.
D. Rubin. Bayesianly justiﬁable and relevant frequency calculations for the applied
statistician. Annals of Statistics, 12(4):1151–1172, 1984.
S. Sahu and A. A. Zhigljavsky.
Self regenerative Markov chain Monte Carlo with
adaptation. Bernoulli, 9:395–422, 2003.
A. Saltelli, K. Chan, and E. M. Scott. Sensitivity Analysis. Wiley, 2000.
A. Saltelli, S. Tarantola, F. Campolongo, and M. Ratto. Sensitivity Analysis in Prac-
tice: A Guide to Assessing Scientiﬁc Models. John Wiley & Sons, 2004.
R. L. J. Schnute, Jon T. The inﬂuence of error on population estimates from catch-
age models. Canadian Journal of Fisheries and Aquatic Sciences, 52(10):2063–2077,
1995.
G. Schwarz. Estimating the Dimension of a Model. Annals of Statistics, 6(2):461–464,
1978.
S. L. Scott. Bayesian methods for hidden Markov models: Recursive computing in the
21st century. Journal of the American Statistical Association, 97:337–351, 2002.
S. R. Searle, G. Casella, and C. E. McCulloch. Variance components. Wiley & Sons,
N. Y., 1992.
N. Shephard and M. K. Pitt. Likelihood analysis of non-Gaussian measurement time
series. Biometrika, 84:653–667, 1997.
B. Silverman. Density Estimation. Chapman and Hall, London, 1986.
A. Smith and G. Roberts. Bayesian computation via the Gibbs sampler and related
Markov chain Monte Carlo methods. J. Roy. Statist. Soc. Ser., B(55):3–24, 1993.

I. Sobol. Sensitivity analysis for non-linear mathematical models. Mathematical Mod-
eling and Computational Experiment, 1:407–414, 1993.
H. Sorenson. Kalman Filtering: Theory and Applications. IEEE Press, 1985.
D. J. Spiegelhalter, N. G. Best, and B. P. Carlin. Bayesian deviance, the eﬀective
number of parameters, and the comparison of arbitrarily complex models. Technical
report, 1998.
C. Spitters, H. Van Keulen, and D. Van Kraalingen. A simple and universal crop
growth simulator: SUCROS87. PUDOC, Wageningen, 1989.
G. Storvik. Particle ﬁlters in state space models with the presence of unknown static
parameters. IEEE Transactions on Signal Processing, 50(2):281–289, 2002.
M. A. Tanner and W. H. Wong. The calculation of posterior distributions by data
augmentation. with discussion and with a reply by the authors.
Journal of the
American Statistical Association, 82(398):528–550, 1987.
F. Tardieu. Virtual plants: modelling as a tool for the genomics of tolerance to water
deﬁcit. Trends in Plant Science, 8(1):9–14, 2003.
W. Taylor. Small sample properties of a class of two-stage Aitken estimator. Econo-
metrica, 45(2):497–508, 1977.
C. J. Ter Braak. A Markov chain Monte Carlo version of the genetic algorithm dif-
ferential evolution: easy Bayesian computing for real parameter spaces. Stat Comp,
16:239–249, 2006.
C. J. Ter Braak and J. A. Vrugt. Diﬀerential evolution Markov chain with snooker
updater and fewer chains. Stat Comp, 18:435–446, 2008.
S. Trevezas and P.-H. Courn`ede. A sequential Monte Carlo approach for MLE in a plant
growth model. Journal of Agricultural, Biological, and Environmental Statistics, 18
(2):250–270, 2013.
S. Trevezas, S. Malefaki, and P.-H. Courn`ede. Simulation techniques for parameter es-
timation via a stochastic ECM algorithm with application to plant growth modeling.
Preprint, http://hal.archives-ouvertes.fr/hal-00798695, 2013.
P. Van Leeuwen and G. Evensen. Data assimilation and inverse methods in terms of
a probabilistic formulation. Monthly Weather Review, 124:2898–2913, 1996.
H.-V. Varella, M. Guerif, S. Buis, and N. Beaudoin. Soil properties estimation by
inversion of a crop model and observations on crops improves the prediction of agro-
environmental variables. European Journal of Agronomy, 33(2):139–147, 2010.
J. A. Vrugt, C. J. ter Braak, C. G. Diks, B. A. Robinson, J. M. Hyman, and D. Higdon.
Accelerating Markov chain Monte Carlo simulation by diﬀerential evolution with
self-adaptive randomized subspace sampling.
International Journal of Nonlinear
Sciences and Numerical Simulation, 10(3):273–290, 2009a.

J. A. Vrugt, C. J. ter Braak, H. V. Gupta, and B. A. Robinson. Equiﬁnality of for-
mal (DREAM) and informal (GLUE) Bayesian approaches in hydrologic modeling?
Stochastic Environmental Research and Risk Assessment, 23(7):1011–1026, 2009b.
D. Wallach, B. Goﬃnet, J. Bergez, P. Debaeke, D. Leenhardt, and J. Aubertot. The
eﬀect of parameter uncertainty on a model with adjusted parameters. Agronomie,
22:159–170, 2002.
D. Wallach, D. Makowski, and J. Jones. Working with Dynamic Crop Models: Evalua-
tion, Analysis, Parameterization, and Applications, chapter Evaluating crop models,
pages 11–53. Elsevier Science Ltd, 2006.
E. Wan and R. Van Der Merwe. The unscented Kalman ﬁlter for nonlinear estimation.
IEEE Symposium 2000, Lake Louise, Alberta, Canada, 2000.
Y. Wang, Y. Wang, G. Wahba, and G. Wahba. Bootstrap conﬁdence intervals for
smoothing splines and their comparison to Bayesian ‘conﬁdence intervals’. J. Statist.
Comput. Simulation, 51:263–279, 1994.
G. Wei and M. Tanner. A Monte Carlo implementation of the EM algorithm and
the poor man’s data augmentation algorithms. Journal of the American Statistical
Association, 85:699–704, 1990.
H. Wernsd¨orfer, V. Rossi, G. Cornu, S. Oddou-Muratorio, and S. Gourlet-Fleury. Im-
pact of uncertainty in tree mortality on the predictions of a tropical forest dynamics
model. Ecological Modelling, 218(3):290–306, 2008.
M. West. Approximating posterior distribution by mixtures. Journal of Royal Statis-
tical Society, B(55):409–442, 1993.
Q. Wu, J. Bertheloot, A. Mathieu, B. Andrieu, and P.-H. Courn`ede.
Assessment
of non-linearity in functional-structural plant models. In T. De Jong, J. Vos, and
A. Escobar, editors, 6th international workshop on Functional-Structural Plant Mod-
els (FSPM10), Davis, USA, November 9-12 2010.
Q. Wu, P.-H. Courn`ede, and A. Mathieu.
An eﬃcient computational method for
global sensitivity analysis and its application to tree growth modelling. Reliability
Engineering & System Safety, 107:35–43, 2012.
P. Wyckoﬀand J. Clark. Predicting tree mortality from diameter growth: a compar-
ison of maximum likelihood and Bayesian approaches. Canadian Journal of Forest
Research, 30(1):156–167, 2000.
H. Yan, M. Kang, P. De Reﬀye, and M. Dingkuhn. A dynamic, architectural plant
model simulating resource-dependent growth. Annals of Botany, 93:591–602, 2004.
X. Yin and P. C. Struik. Modelling the crop: from system dynamics to systems biology.
Journal of Experimental Botany, 61(8):2171–2183, 2010. doi: 10.1093/jxb/erp375.
P. Yiou. Anawege: a weather generator based on analogues of atmospheric circulation.
Geoscientiﬁc Model Development, 7(2):531–543, 2014.

Z. Zhan, P. de Reﬀye, F. Houllier, and B. Hu. Fitting a structural-functional model
with plant architectural data. In B. Hu and M. Jaeger, editors, Plant Growth Models
and Applications, pages 236–249. Tsinghua University Press and Springer (Beijing,
China), 2003.

