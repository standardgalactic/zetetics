Inferring stochastic low-rank recurrent neural
networks from neural data
Matthijs Pals1,2
A Erdem Sa˘gtekin1,2,3
Felix Pei1,2
Manuel Gloeckler1,2
Jakob H Macke1,2,4
1Machine Learning in Science, Excellence Cluster Machine Learning, University of Tübingen, Germany
2Tübingen AI Center, Tübingen, Germany
3Graduate Training Centre of Neuroscience, University of Tübingen, Germany
4Department Empirical Inference, Max Planck Institute for Intelligent Systems, Tübingen, Germany
Abstract
A central aim in computational neuroscience is to relate the activity of large
populations of neurons to an underlying dynamical system. Models of these neural
dynamics should ideally be both interpretable and fit the observed data well. Low-
rank recurrent neural networks (RNNs) exhibit such interpretability by having
tractable dynamics. However, it is unclear how to best fit low-rank RNNs to
data consisting of noisy observations of an underlying stochastic system. Here,
we propose to fit stochastic low-rank RNNs with variational sequential Monte
Carlo methods. We validate our method on several datasets consisting of both
continuous and spiking neural data, where we obtain lower dimensional latent
dynamics than current state of the art methods. Additionally, for low-rank models
with piecewise linear nonlinearities, we show how to efficiently identify all fixed
points in polynomial rather than exponential cost in the number of units, making
analysis of the inferred dynamics tractable for large RNNs. Our method both
elucidates the dynamical systems underlying experimental recordings and provides
a generative model whose trajectories match observed trial-to-trial variability.
1
Introduction
A common goal of many scientific fields is to extract the dynamical systems underlying noisy
experimental observations. In particular, in neuroscience, much work is devoted to understanding the
coordinated firing of neurons as being implemented through underlying dynamical systems [1–5].
Recurrent neural networks (RNNs) constitute a common model-class of neural dynamics [6–13]
which can be reverse-engineered to form hypotheses about neural computations [14, 15].
As a result, several recent research directions have centered on interpretable or analytically tractable
RNN architectures. In particular, RNNs with low-rank structure [16–22] admit a direct mapping
between high-dimensional population activity and an underlying low-dimensional dynamical system.
RNNs with piecewise-linear activations [8, 9, 23–26] have fixed points and cycles that can be accessed
analytically.
{firstname.secondname}@uni-tuebingen.de
arXiv:2406.16749v1  [cs.LG]  24 Jun 2024

Figure 1: Our goal is to obtain generative models from which we can sample realistic neural data
while having a tractable underlying dynamical system. We achieve this by fitting stochastic low-rank
RNNs with variational sequential Monte Carlo.
To serve as useful models of brain activity, it is important that models also capture the observed brain
activity, including trial-to-trial variability. Many methods that fit RNNs to data are restricted to RNNs
with deterministic transitions [6–8, 10–12]. It is unlikely that, in general, all variability in the data
can be explained by variability in the RNNs initial state. Thus, adopting stochastic transitions is
imperative. While probabilistic sequence models are used effectively in neuroscience [27], they have
so far largely consisted of state space models without an obvious mechanistic interpretation [28–32].
Here, we demonstrate that we can fit large stochastic RNNs to noisy high-dimensional data. First, we
show that, by combining variational sequential Monte Carlo methods [33–35] with low-rank RNNs,
we can efficiently fit stochastic RNNs with many units by learning the underlying low-dimensional
dynamical system. Second, we show that, for low-rank networks with piecewise-linear activation
functions, the resulting dynamics can be efficiently analyzed: In particular, we show how all fix
points can be found with a polynomial cost in the number of units – dramatically more efficient than
the exponential cost in the general case.
We first validate our method using several teacher-student setups and show that we recover both
the ground truth dynamics and stochasticity. We then fit our model to several real-world datasets,
spanning both spiking and continuous data, where we obtain a generative model which needs lower
dimensional latent dynamics than current state of the art methods. We also demonstrate how in our
low-rank RNNs fixed points can be efficiently inferred — potentially at a lower cost than approximate
methods [25], while additionally coming with the guarantee that all fixed points are found.
2
Theory and methods
2.1
Low-rank RNNs
2.1.1
Access to the low-dimensional dynamics underlying large networks
Our goal is to infer recurrent neural network models of the form
τ dx
dt = −x(t) + Jϕ(x(t)) + Γxξ(t),
(1)
with neuron activity x(t) ∈RN, time-constant τ ∈R>0, recurrent weights J ∈RN×N, element-wise
nonlinearity ϕ, an R dimensional white noise process ξ(t) and Γx ∈RN×R. In particular, we are
interested in the case where the weight matrix J has rank R ≤N, i.e. it can be written as J = MNT,
with M, N ∈RN×R ([18–21]). Assuming that x(0) lies in the subspace spanned by the columns of
M and Γx = MΓz, with Γz ∈RR×R , we can rewrite Eq. 1 as an equivalent R dimensional system,
τ dz
dt = −z(t) + NTϕ(Mz(t)) + Γzξ(t),
(2)
where we can switch between Eq. 1 and Eq. 2 by means of linear projection, z(t)
=
(MTM)−1MTx(t) and x(t) = Mz(t). Note that we can directly extend these equations to in-
clude input, representing, e.g., experimental stimuli or context (see Supplement C.2).
2

2.1.2
Low-rank RNNs as state space models
We consider nonlinear latent dynamical systems with observations yt:
p(z1:T , y1:T ) = p(z1)
T
Y
t=2
p(zt|zt−1)
T
Y
t=1
p(yt|zt),
p(zt|zt−1) = N(F(zt−1), Σz), p(z1) = N(µz1, Σz1),
p(yt|zt−1) = G(zt),
where the transition distribution is parameterised by discretising a low-rank RNN with timestep ∆t
(see Supplement C.1), we have mean F(zt) = azt + ˜NTϕ(Mzt), with a = 1 −∆t
τ and ˜N = ∆t
τ N,
and covariance Σz. The specific form of the observation function G, depends on the data-modality,
e.g., here we use a Poisson distribution for count observations. This formulation allows one to keep
the one-to-one correspondence between RNN units (or a subset of those) and recorded data neurons,
(as was desired in e.g., [10–12, 36]). For example, assuming Gaussian observation noise, we can
simply use that xt = Mzt and define G = N(Mzt, Σy).
Once we learn p(z1:T , y1:T ), we can use the obtained RNN as generative model to sample trajectories,
and reverse engineer the underlying dynamics to gain insight in the data generation process. Given
the sequential structure of the RNN, we can do model learning by using variational sequential Monte
Carlo (also called Particle Filtering) methods [33–35].
2.2
Model learning with variational sequential Monte Carlo
2.2.1
Sequential Monte Carlo
Sequential Monte Carlo (SMC) can be used to approximate sequences of distributions, such as those
generated by our RNN, with a set of K trajectories of latents z1:T (commonly called particles) [37].
A crucial choice when doing SMC is picking the right proposal distribution r, from which we can
sample latents at a given timestep, conditioned on the previous latent zt−1 and observed data y1:t, or
a subset of those. Given initial samples z1:K
1
∼r and corresponding importance weights w1:K
1
(as
defined below) SMC progresses by repeatedly executing the following steps:
resample
ak
t−1 ∼Discrete(ak
t−1|wk
t−1),
propose
zk
t ∼r(zk
t |yt, z
ak
t−1
t−1 ),
reweight
wk
t = p(yt, zk
t |z
ak
t−1
t−1 )
r(zk
t |yt, z
ak
t−1
t−1 )
,
with wk
t =
wk
t
PK
j=1 wj
t . We obtain, at time t, a filtering approximation to the posterior,
qfilt(z1:t|y1:t) =
K
X
k=1
wk
t δ(zk
1:t).
(3)
The unnormalised weights give an unbiased estimate to the marginal likelihood,
ˆp(y1:T ) =
T
Y
t=1
1
K
K
X
k=1
wk
t .
(4)
We now detail how we pick the proposal distribution r. For linear Gaussian observations G =
N(Bzt, Σy), we set r(zt|yt, zt−1) = p(zt|yt, zt−1), as this is available in closed form and is
optimal (in the sense that it minimises the variance of the importance weights [37])
r(zt|yt, zt−1) = N((I −KB)F(zt−1) + Kyt, (I −KB)Σz),
(5)
with K the Kalman Gain: K = ΣzBT(BΣzBT + Σy)−1. For non-linear observations, we can
not invert the observation process in closed form, so we instead jointly optimize a parameterized
3

‘encoding’ distribution e(zt|yt−t′:t) (as in a variational autoencoder [38]). In particular, we assume e
to be a multivariate normal with diagonal covariance, which we parameterize by a causal convolutional
neural network, such that each latent is conditioned on the t′ latest observations. We then use the
following proposal:
r(zt|zt−1, yt−t′:t) ∝e(zt|yt−t′:t)p(zt|zt−1),
(6)
where we now also assume p(zt|zt−1) has a diagonal covariance matrix.
2.2.2
Relationship to Generalised Teacher Forcing
In our approach, the mean of the proposal distribution at time t is a linear interpolation between
the RNN predicted state F(zt−1) and a data-inferred state ˆzt. A recent study obtained state-of-
the art results for reconstructing dynamical systems by fitting deterministic RNNs with a method
called Generalised Teacher Forcing (GTF), which also linearly interpolates between a data-inferred
and an RNN predicted state at every time-step [8]; the model propagates forward in time as zt =
(1 −α)F(zt−1) + αˆzt. [8] showed that by choosing the appropriate α, one can completely avoid
exploding gradients, while still allowing backpropagation through time, and thus obtaining long-term
stable solutions [39]. The optimal α can be picked based on the maximum Lyaponuv exponent of the
system (a measure of how fast trajectories diverge in a chaotic system) [8].
By including the RNN in the proposal distribution, we similarly to GTF allow backpropagation
through time through the sampled trajectories. The interpolation is given by α = ΣzBT(BΣzBT +
Σy)−1B in Eq. 5, and in Eq. 6 by α = Σz(Σz + Σˆzt)−1, where Σˆzt is the predicted variance of the
encoding network. Thus, instead of interpolating based on an estimate of how chaotic the system is,
our approach interpolates adaptively (every time step, if Eq. 6 is used) based on how relatively noisy
the transition distribution is with respect to the data-inferred states at time t, analogous to, e.g., the
gain of a Kalman filter.
2.2.3
Variational objective
We can fit our RNNs to data by using SMC to specify a variational objective [33–35]. In variational
inference, we specify a family of parameterized distributions Q, and optimize those parameters such
that a divergence (usually the KL divergence) between the variational distribution q(z1:T ) ∈Q and
the true posterior p(z1:T |y1:T ) is minimized. We do this by maximising a lower bound (ELBO) to
the log likelihood p(y1:T ). In particular, we can use Eq. 4 to specify the ELBO objective[33–35]
L = Eqsmc(z1:K
1:T ,a1:K
1:T −1|y1:T )[log ˆp(y1:T )],
(7)
with qsmc the sampling distribution:
qsmc(z1:K
1:T , a1:K
1:T −1|y1:T ) = QK
k=1 r(zk
1|y1) QK
k=1
QT
t=2 r(zk
t |z
ak
t−1
t−1 yt)Discrete(ak
t−1|wk
t−1). We
approximate this objective with Monte Carlo samples during training. As suggested in [33–35, 40],
we use biased gradients during optimization by dropping high-variance terms arising from the
resampling.
2.3
Finding fixed points in piecewise-linear low-rank RNNs
After having learned our model, we can gain insight into the mechanisms underlying the data
generation process by reverse engineering the learned dynamics [15], e.g. by calculating their
fixed points. Here, we show that the fixed points can be found analytically and efficiently for
low-rank networks with piecewise-linear activation functions. This class of activation functions
ϕ(xi) = PD
d b(i,d)max(xi −h(d)
i
, 0) includes, e.g., the standard ReLU (ϕ(xi) = max(xi −hi, 0))
or the ‘clipped’ variant (ϕ(xi) = max(xi +hi, 0)−max(xi, 0)) [8] which we used in all experiments
with real-world data here.
Naively, the cost of finding all fixed points piecewise-linear networks scales exponentially with the
number of units in the networks: we would have to solve (D +1)N systems of N equations [9, 24]. If
networks are low rank, it is straightforward to show that we can reduce this cost to solving (D + 1)N
systems of R equations (See Supplement A.1). In addition, however, we show that the computational
cost can be greatly reduced further: One can find all fixed points in a cost that is polynomial instead
of exponential in the number of units:
4

Proposition 1. Assume Eq. 1, with J of rank R and piecewise-linear activations ϕ. For fixed
rank R and fixed number of basis functions D, we can find all fixed points in the absence of
noise, that is all x for which dx
dt = 0, by solving at most O(N R) linear systems of R equations.
Figure 2: Proof
sketch.
Proof. See Supplement A.1.
Sketch. Assuming D = 1, activations ϕ = max(0, xi −hi); N units will partition
the full phase space into 2N regions in which the dynamics are linear (2 units, 4
regions in Fig. 2). We can thus, in principle, solve for all fixed points by solving
all corresponding linear systems of equations [9, 24]. If dynamics are confined to
the R-dimensional subspace spanned by the columns of M, only a subset of the
linear regions (3 in Fig. 2) can be reached. Each unit partitions the space spanned
by the columns of M with a hyperplane (pink points in Fig. 2). The amount of
linear regions in M, becomes equivalent to ‘how many regions can we create in
R-dimensional space with N hyperplanes?’ Using Zaslavsky’s theorem [41], we
can show that this at most PR
r=0
 N
r

∈O(N R).
3
Empirical Results
3.1
RNNs recover ground truth dynamics in student-teacher setups
Figure 3: RNNs recover dynamics in teacher-student setups. a) Example ground truth latent trajectory
and phase plane of low-rank RNN trained to oscillate (top left) and noisy observations of neuron
activity (top right; 6/20 shown). A second low-rank RNN trained on the activity of the first recovers
ground truth dynamics. b) Same set-up, but with Poisson observations. c) The teacher network was
trained on a task where it has to provide an output corresponding to 8 different angles depending on
an input cue. The student network, when given the same input during fitting, recovers the approximate
ring attractor with 8 stable fixed points. d) Mean (±1SD) autocorrelation of the latents of the models
from panel a, show the oscillation frequency is captured, as well as the decorrelation due to recurrent
noise. The scale of the observed rates also agrees between student and teacher. e) Mean rates and ISI
between student and teacher units of panel b match. f) Example rate distribution of one unit of the
teacher and student RNN (of panel c), after onset of the 8 different stimuli.
5

We validated our method using several student-teacher setups (Fig. 3; additional statistics in Fig. S4).
We first trained a ‘teacher’ RNN, with the weight matrix constrained to rank 2, to oscillate. We then
simulated multiple trajectories with a high level of stochasticity in the latent dynamics (Fig. 3a, top
left) and additional additive Gaussian observation noise (Fig. 3b, top left) on the observed neuron
activity (yi ∼N(xi, σy), with x = Mz). A second ‘student’ RNN was then fit to the data drawn
from the teacher, and both recovered the true latent dynamical system, as well as the right level of
stochasticity (Fig. 3a, bottom).
Given that neurons emit action potentials, which are commonly approximated as discrete events, we
repeated the experiment with Poisson observations generated according to yi ∼Pois(softplus(wixi−
bi)). The student RNN again recovers the oscillatory latent dynamics. Note that because of the
affine transformation in the observation model, the inferred dynamics can be scaled and translated
with respect to the teacher model. To verify that samples from our inferred model follow the same
distribution as samples from the teacher model, we computed several statistics, which all show a
close match (Fig. 3e; Fig. S4).
In our final teacher-student setup, we verified the ability to recover dynamics when there are known
stimuli or contexts. In particular, we trained a rank-2 RNN on a task where, at each trial, it receives
a transient pulse input corresponding to a particular angle θ (given as sin(θ), cos(θ)), and is asked
to provide output matching the input after stimulus offset. The teacher RNN learns to perform the
task by using an approximate ring attractor, with a stable fixed point for each of the 8 angles - which
the student RNN accurately infers (Fig. 3c). Here, we inferred all fixed points by making use of
Preposition 1.
3.2
Stochasticity allows recovering low-dimensional latents underlying EEG data
Figure 4: Example ground truth EEG [42, 43] and
(unconditionally) generated traces by our model.
Shown are 5/64 EEG channels.
After validating our model on a toy example,
we went on to several challenging real-world
datasets. We first used an EEG dataset [42, 43]
with 64 channels containing one minute of con-
tinuous data sampled at 160 Hz (Fig. 4). This
dataset was recently used in a study where gen-
eralized teacher forcing (GTF) was used to fit
deterministic RNNs with low-rank structure [8].
The GTF method obtains state-of-the-art results
on several dynamical systems reconstruction
tasks. It outperformed SINDy [44], neural differ-
ential equations [45], Long-Expressive-Memory
[46], and other methods, while using a smaller
latent dynamical system.
Here we show that using a stochastic RNN with
SMC instead of a deterministic RNN with GTF,
we can decrease the latent dimensionality even further, from 16 to just 3 latents, while matching
the original reconstruction accuracy (Table 1). We hypothesize this is because the data can be
well explained by stochastic transitions with simple underlying dynamics as opposed to complex
deterministic chaos.
Table 1: Lower dimensional latent dynamics than SOTA at same sample quality. We report median ±
median absolute deviation over 20 independent training runs, ‘dim’ refers to the dimensionality of
the model’s underlying dynamics and |θ| denotes the total number of trainable parameters. Values
for GTF taken from [8].
Dataset
Method
Dstsp ↓
DH ↓
dim
|θ|
EEG
(64d)
GTF [8]
2.1 ± 0.2
0.11 ± 0.01
16
17952
adaptive GTF [8]
2.4 ± 0.2
0.13 ± 0.01
16
17952
SMC (ours)
2.2 ± 0.2
0.11 ± 0.01
3
3920
We evaluated samples from our RNN with two measures which were used in [8], one KL divergence-
based measure between the states (Dstsp), and one measure over time, based on the power spectra of
6

generated and inferred dynamics (DH; see Supplement D.3.3). Unlike [8], who applied smoothing,
we optimized our models directly on the raw EEG data.
3.3
Interpretable latent dynamics underlying spikes recorded from rat hippocampus
Figure 5: RNNs reproduce the stationary distribution of spiking data. a) We fit a rank-3 RNN to
spike data recorded from rat hippocampus [47, 48] (left), and generate new samples from the RNN
(right). b) Single neuron statistics. Mean rates and means of interspike interval (ISI) distributions of
a long trajectory of data generated by the RNN (gen) match those of a held-out set of data (test). As a
reference we additionally computed the same statistics between the train and test set. c) Population
level statistics. We plot the pairwise correlations between all neurons for generated data against the
pairwise correlations in the test data. d) The corresponding latents generated by running the RNN
look visually similar to the local field potential (LFP). e) The peak in the power spectrum matches
between latents and LFP. f) The posterior latents show coherence with the LFP. As a reference, we
compute the coherence between the LFP and the latents generated by the RNN.
We next investigated how well our model can capture the distribution of non-continuous time
series. In particular, we used publicly available electrophysiological recordings from the hip-
pocampus of rats running to drops of water or pieces of food [47, 48]. We binned the spik-
ing data into 10ms bins and fit a rank-3 RNN to ∼850 s of data. Samples generated by run-
ning the fit RNN autonomously closely matched the statistics of the recordings (Fig. 5a-c).
Figure 6:
Posterior la-
tents of our model (fit
solely spikes) can be
used to predict rat posi-
tion.
Previous investigations into this dataset have examined the relationship
between spikes and theta (5-10 Hz) oscillations in the local field potential
([47]), and found that units were locked to the LFP rhythm, with the
relative phase depending on the subregions from which the units were
recorded. The latents generated by the RNN are visually similar to the
average local field potential (Fig. 5d) and match its power spectrum
(Fig. 5e). While the model was solely trained on the spikes, the posterior
latents (Eq. 3) have a clear phase relationship with the LFP, as evidenced
by a high coherence between the posterior latents and LFP. In contrast,
and as expected, latents from running the RNN are not correlated with
the LFP (Fig. 5f).
Units in rat hippocampus have been shown to code for position, i.e.
through place cells [49], which tend to fire if the animal is at a specific
location. To further investigate how well we can model recordings from
the hippocampus, we fit a rank-4 RNN to an additional set of recordings
of rats running on a linear track [50–52]. As in [53], we focus only on the spikes recorded while
the rat is moving, which we bin into 25 ms bins. The RNN again accurately reconstructs the
distribution of spikes and again has latent oscillations with frequency matching the LFP (Fig. S5).
While solely trained on spikes, the posterior latents also allowed us to predict the position of the rats
with reasonable accuracy (R2 = 0.62 ± 0.073 mean ± SD, N=4 RNNs; Fig. 6).
7

Figure 7: Inferred and generated dynamics from the model fit to macaque spiking activity during
reaching task. a) Latent states inferred from the macaque spiking data prior to movement initiation
(‘pre-movement’) and during movement execution (‘movement’), colored by the intended reach
target. b) Reach trajectories decoded from model-inferred neural activity. c) Dissimilarity matrices
computed across the seven conditions (i.e., the seven colors in a-b) for per-neuron mean firing rate
and ISI. We generate neural activity from the model by providing the same conditioning stimuli as
in the real data. Then, for each statistic, we compute and show the correlation distance between
conditions in the real data (left) and model-generated data (right). d,e) Same as a-b, but with latent
activity and behavioral predictions generated from the model with conditioning inputs including
directions not seen in the real data (e.g., lime green). For clarity, we show only a subset of conditions
in the decoded reaches.
3.4
Extracting stimulus-conditioned dynamics in monkey reaching task
We further investigated how well we can recover stimulus-conditioned dynamics. We applied our
method to spiking activity recorded from the motor and premotor cortices of a macaque performing
a delayed reaching task. This type of data has been popular for investigating neural dynamics
underlying the control of movement [2, 3] and evaluating neuroscientific latent variable models
[7, 54, 55]. We first validated the ability of our method to obtain a sensible posterior by evaluating it
on the Neural Latents Benchmark [55] (Supplement B.3, Table S 2).
We then went on to a set-up where we explicitly conditioned our model on external context. For
simplicity, we constrained our experiment to trials with straight reach trajectories in the data. We
fit a rank-5 model to these data while conditioning its dynamics on the target position by providing
the target position as input to the RNN. Our model was able to infer single-trial latent dynamics and
neuron firing rates that predict reach velocity with high accuracy at lower latent dimensionalities than
models without inputs (Fig. 7b, R2 = 0.90 for this model, see Table S3 for additional statistics).
We examined the posterior latents inferred by the model and found that our model recovers structured
and interpretable latent dynamics. Before movement onset, latent states corresponded to the intended
reach targets, which were near the edges of a rectangular screen (Fig. 7a, left), in line with [54].
During the movement period, the latents followed parallel curved trajectories that preserve target
information (Fig. 7a, right) and can be decoded to predict monkey reach behavior (Fig. 7b).
We then generated neural data from the RNN conditioned on stimulus input. Again, the distribution
of spikes is well-captured (Fig. S6). We additionally evaluated whether the model faithfully captures
differences in spiking statistics across the seven reach directions, finding reasonable correspondence
in dissimilarities between conditions in the generated and the real data (Fig. 7c). Finally, we simulated
our trained RNN with conditioning inputs, including reach directions not present in the data, and
found that the structured latent space recovered by the model enables realistic generalization to
unseen reach conditions (Fig. 7d,e, lime green condition).
8

3.5
Searching for fixed points
Figure 8:
Comparison of our ana-
lytic method (star) and the approximate
method proposed in [25] (blue) for find-
ing the fixed points of the teacher RNN
in Fig. 3c. We can also use Proposition
1 to constrain the search space of the
approximate method (orange). We here
show the number of fixed points found
as a function of the number of matrix
inverses computed, with errorbars denot-
ing the minimum and maximum amount
of fixed points found over 20 indepen-
dent runs of the algorithm.
In Proposition 1, we derived a bound on the number of
systems of equations one has to solve in order to find
all fixed points in piece-wise linear low-rank RNNs. Re-
cently, an approximate algorithm for finding fixed points
in piece-wise linear networks was proposed [25]. Here, we
perform an exploration into how this compares to our an-
alytic method by searching for fixed points of the RNN in
Fig. 3c (top). For the same number of matrix inverses com-
puted by our analytic method, the approximate method
generally does not find all 17 fixed points (Fig. 8). We
note, however, that (unlike ours) the convergence of the
approximate method depends on the dynamics of the RNN,
and as a result, there are theoretical scenarios where the
approximate method can be shown to be faster. Yet we
empirically also found scenarios where the approximate
methods failed to converge within the time-frame of our
experiments (Fig. S7).
Our analytic method relies on the insight that only a subset
of all linear subregions formed by the piece-wise linear
activations can be reached in low-rank networks.For net-
works with moderate rank, the cost of searching through all
of the subregions might still be too high. We can, however,
hugely reduce the search space of the approximate method
[25] (from (D + 1)N to PR
r=0 Dr N
r

), at an upfront cost
(Supplement B.5; orange line in Fig. 8).
4
Discussion
Here we proposed to fit low-rank RNNs to neural data using variational sequential Monte Carlo.
The resulting RNNs are generative models with tractable underlying dynamics, from which we can
sample long, stable trajectories of realistic data. We validated our method on several teacher-student
setups and demonstrated the effectiveness of our method on multiple challenging real-world examples,
where we generally needed a latent dynamical system with very few dimensions to accurately model
the data. Besides our empirical results, we obtained a theoretical bound on the cost of finding fixed
points for RNNs with piecewise-linear activation functions when they are also low-rank.
Adding stochastic transitions to low-rank RNNs can potentially hugely reduce the rank required
to accurately model observed data, as demonstrated here with a network fit to EEG data where we
could reduce the dimensionality from 16 to just 3. While many methods that fit RNNs to neural
data (e.g, [6–8, 10–12]) assume deterministic transitions, there is a rich literature concentrating
on probabilistic sequence models in neuroscience (e.g., [28–32]). In particular, a recent work
termed FINDR [31] uses variational inference (but not SMC), to similarly find very low-dimensional
dynamical systems underlying neural data. These stochastic dynamical systems were parameterized
using neural differential equations [45]. While Eq. 2 can be seen as a neural differential equation with
one hidden layer [8], our particular formulation allows us to find its fixed-points effectively and map
back to a regular, mechanistically interpretable RNN (Eq. 1) after fitting, which enables additional
investigations into neural population dynamics [18, 20–22].
The reason we can do the mapping between a low-rank RNN (Eq. 1) and a latent dynamical system
(Eq. 2) crucially relies on our assumption that samples from the recurrent noise process are correlated,
such that they lie within the column-space of M. [56] showed that for linear low-rank RNNs arbitrary
covariances in the full N dimensional space can be used, when increasing the dimensionality of the
latent dynamics to twice the rank R (to the column space of both M and N), this however does not
generalise to our non-linear setting. We do expect correlated recurrent noise to be appropriate for
modeling stochasticity arising from unobserved inputs or from partial observations [56] —additionally,
correlated noise constituted a pragmatic choice that allows building an stochastic model that can
allow for trial-by-trial variability while maintaining the tractability of low-rank deterministic RNNs.
9

Still, future work can investigate training networks with more relaxed assumptions on the recurrent
noise models, including extensions to non-Gaussian noise-processes. The latter could be of particular
interest if more biologically plausible (i.e., spiking) neurons were used in the recurrence [36, 57].
Our results also open up further avenues to explore questions in neuroscience. The relation between
LFP and spike (phase) in the hippocampus has been of great interest [47, 58–60]. While we
performed some preliminary investigation into the relation between the inferred latents and the
local field potential, further studies could perform a systematic investigation into their relation, for
instance, by using a multi-modal setup [13], or to investigate multi-region temporal relationships and
interactions [10].
Taken together, by inferring low-rank RNNs with variational SMC, we obtained generative models of
neural data whose trajectories match observed trial-to-trial variability, and whose underlying latent
dynamics are tractable.
Acknowledgments
This work was supported by the German Research Foundation (DFG) through Germany’s Excellence
Strategy (EXC-Number 2064/1, PN 390727645) and SFB1233 (PN 276693517), SFB 1089 (PN
227953431) and SPP2041 (PN 34721065), the German Federal Ministry of Education and Research
(Tübingen AI Center, FKZ: 01IS18039; DeepHumanVision, FKZ: 031L0197B), the Else Kröner Fre-
senius Stiftung (Project ClinbrAIn), and the European Union (ERC, DeepCoMechTome, 101089288).
MP and MG are members of the International Max Planck Research School for Intelligent Systems
(IMPRS-IS). We thank Cornelius Schröder for feedback on the manuscript, and all members of
Mackelab for discussions throughout the project.
Code availability
Code to reproduce our results is available at https://github.com/mackelab/smc_rnns.
References
[1] M. M Churchland, B. M Yu, M Sahani, and K. V Shenoy. Techniques for extracting single-trial activity
patterns from large-scale neural recordings. Current Opinion in Neurobiology, 17(5):609–618, 2007.
[2] K. V Shenoy, M Sahani, and M. M Churchland. Cortical control of arm movements: A dynamical systems
perspective. Annual Review of Neuroscience, 36(1):337–359, 2013.
[3] J Gallego, M Perich, L Miller, and S Solla. Neural manifolds for the control of movement. Neuron, 94:
978–984, 2017.
[4] S Vyas, M. D Golub, D Sussillo, and K. V Shenoy. Computation through neural population dynamics.
Annual Review of Neuroscience, 43(1):249–275, 2020.
[5] D. L Barack and J. W Krakauer. Two views on the cognitive brain. Nature Reviews Neuroscience, 22(6):
359–371, 2021.
[6] D Sussillo and L. F Abbott. Generating coherent patterns of activity from chaotic neural networks. Neuron,
63:544–557, 2009.
[7] C Pandarinath, D. J O’Shea, J Collins, R Jozefowicz, S. D Stavisky, J. C Kao, E. M Trautmann, M. T
Kaufman, S. I Ryu, L. R Hochberg, J. M Henderson, K. V Shenoy, L. F Abbott, and D Sussillo. Inferring
single-trial neural population dynamics using sequential auto-encoders. Nature Methods, 15(10):805–815,
2018.
[8] F Hess, Z Monfared, M Brenner, and D Durstewitz. Generalized teacher forcing for learning chaotic
dynamics. In Proceedings of the 40th International Conference on Machine Learning, ICML’23, 2023.
[9] D Durstewitz. A state space approach for piecewise-linear recurrent neural networks for identifying
computational dynamics from neural measurements. PLOS Computational Biology, 13(6):1–33, 2017.
[10] M. G Perich, C Arlt, S Soares, M. E Young, C. P Mosher, J Minxha, E Carter, U Rutishauser, P. H
Rudebeck, C. D Harvey, and K Rajan. Inferring brain-wide interactions using data-constrained recurrent
neural network models. bioRxiv:2020.12.18.423348, 2021.
10

[11] A Valente, J. W Pillow, and S Ostojic. Extracting computational mechanisms from neural data using
low-rank rnns. In Advances in Neural Information Processing Systems, volume 35, 2022.
[12] F Dinc, A Shai, M Schnitzer, and H Tanaka. CORNN: Convex optimization of recurrent neural networks
for rapid inference of neural dynamics. In Thirty-seventh Conference on Neural Information Processing
Systems, 2023.
[13] M Brenner, F Hess, G Koppe, and D Durstewitz. Integrating multimodal data for joint generative modeling
of complex dynamics. In Forty-first International Conference on Machine Learning, 2024.
[14] O Barak. Recurrent neural networks as versatile tools of neuroscience research. Current Opinion in
Neurobiology, 46:1–6, 2017. Computational Neuroscience.
[15] D Sussillo and O Barak. Opening the Black Box: Low-Dimensional Dynamics in High-Dimensional
Recurrent Neural Networks. Neural Computation, 25(3):626–649, 2013.
[16] H. S Seung. How the brain keeps the eyes still. Proceedings of the National Academy of Sciences, 93(23):
13339–13344, 1996.
[17] C Eliasmith and C. H Anderson. Neural Engineering (Computational Neuroscience Series): Computational,
Representation, and Dynamics in Neurobiological Systems. MIT Press, Cambridge, MA, USA, 2002.
[18] F Mastrogiuseppe and S Ostojic. Linking connectivity, dynamics, and computations in low-rank recurrent
neural networks. Neuron, 99(3):609–623.e29, 2018.
[19] F Schuessler, A Dubreuil, F Mastrogiuseppe, S Ostojic, and O Barak. Dynamics of random recurrent
networks with correlated low-rank structure. Physical Review Research, 2(1):013111, 2020.
[20] M Beiran, A Dubreuil, A Valente, F Mastrogiuseppe, and S Ostojic. Shaping Dynamics With Multiple
Populations in Low-Rank Recurrent Networks. Neural Computation, 33(6):1572–1615, 2021.
[21] A Dubreuil, A Valente, M Beiran, F Mastrogiuseppe, and S Ostojic. The role of population structure in
computations through neural dynamics. Nature Neuroscience, 25(6):783–794, 2022.
[22] M Pals, J. H Macke, and O Barak. Trained recurrent neural networks develop phase-locked limit cycles in
a working memory task. PLOS Computational Biology, 20(2):1–23, 2024.
[23] C Curto, J Geneson, and K Morrison. Fixed Points of Competitive Threshold-Linear Networks. Neural
Computation, 31(1):94–155, 2019.
[24] M Brenner, F Hess, J. M Mikhaeil, L. F Bereska, Z Monfared, P.-C Kuo, and D Durstewitz. Tractable
dendritic RNNs for reconstructing nonlinear dynamical systems. In Proceedings of the 39th International
Conference on Machine Learning, volume 162 of Proceedings of Machine Learning Research, 2022.
[25] L Eisenmann, Z Monfared, N Göring, and D Durstewitz. Bifurcations and loss jumps in rnn training. In
Advances in Neural Information Processing Systems, volume 36, 2023.
[26] K Morrison, A Degeratu, V Itskov, and C Curto. Diversity of emergent dynamics in competitive threshold-
linear networks. SIAM Journal on Applied Dynamical Systems, 23(1):855–884, 2024.
[27] J. P Cunningham and B. M Yu. Dimensionality reduction for large-scale neural recordings. Nature
Neuroscience, 17(11):1500–1509, 2014.
[28] B Petreska, B. M Yu, J. P Cunningham, G Santhanam, S Ryu, K. V Shenoy, and M Sahani. Dynamical
segmentation of single trials from population neural data. In Advances in Neural Information Processing
Systems, volume 24, 2011.
[29] J. H Macke, L Buesing, J. P Cunningham, B. M Yu, K. V Shenoy, and M Sahani. Empirical models of
spiking in neural populations. In Advances in Neural Information Processing Systems, volume 24, 2011.
[30] S Linderman, M Johnson, A Miller, R Adams, D Blei, and L Paninski. Bayesian learning and inference
in recurrent switching linear dynamical systems. In Proceedings of the 20th International Conference
on Artificial Intelligence and Statistics, volume 54 of Proceedings of Machine Learning Research, pages
914–922, 2017.
[31] T. D Kim, T. Z Luo, T Can, K Krishnamurthy, J. W Pillow, and C. D Brody. Flow-field inference from
neural data using deep recurrent networks. bioRxiv:2023.11.14.567136, 2023.
[32] Y Zhao, J Nassar, I Jordan, M Bugallo, and I Park. Streaming variational monte carlo. IEEE Transactions
on Pattern Analysis & Machine Intelligence, 45(01):1150–1161, 2023.
11

[33] T. A Le, M Igl, T Rainforth, T Jin, and F Wood. Auto-encoding sequential monte carlo. In International
Conference on Learning Representations, 2018.
[34] C. J Maddison, J Lawson, G Tucker, N Heess, M Norouzi, A Mnih, A Doucet, and Y Teh. Filtering
variational objectives. In Advances in Neural Information Processing Systems, volume 30, 2017.
[35] C Naesseth, S Linderman, R Ranganath, and D Blei. Variational sequential monte carlo. In Proceed-
ings of the Twenty-First International Conference on Artificial Intelligence and Statistics, volume 84 of
Proceedings of Machine Learning Research, 2018.
[36] C Sourmpis, C Petersen, W Gerstner, and G Bellec. Trial matching: capturing variability with data-
constrained spiking neural networks. In Advances in Neural Information Processing Systems, volume 36,
2023.
[37] A Doucet and A. M Johansen. A tutorial on particle filtering and smoothing: Fifteen years later. The
Oxford Handbook of Nonlinear Filtering, pages 656–704, 2011.
[38] D. P Kingma and M Welling. Auto-Encoding Variational Bayes. In 2nd International Conference on
Learning Representations, ICLR, Conference Track Proceedings, 2014.
[39] K Doya. Bifurcations of recurrent neural networks in gradient descent learning. IEEE Transactions on
Neural Networks, 1993.
[40] J Zenn and R Bamler. Resampling gradients vanish in differentiable sequential monte carlo samplers. In
The First Tiny Papers Track at ICLR 2023, Tiny Papers @ ICLR 2023, 2023.
[41] T Zaslavsky. Facing up to arrangements: face-count formulas for partitions of space by hyperplanes.
Memoirs of American Mathematical Society, 154:1–95, 1975.
[42] G Schalk, D McFarland, T Hinterberger, N Birbaumer, and J Wolpaw. Bci2000: a general-purpose
brain-computer interface (bci) system. IEEE Transactions on Biomedical Engineering, 51(6):1034–1043,
2004.
[43] G Moody, R Mark, and A Goldberger. Physionet: a research resource for studies of complex physiologic
and biomedical signals. Computers in cardiology, 27:179–82, 2000.
[44] S. L Brunton, J. L Proctor, and J. N Kutz. Discovering governing equations from data by sparse iden-
tification of nonlinear dynamical systems. Proceedings of the National Academy of Science, 113(15):
3932–3937, 2016.
[45] R. T. Q Chen, Y Rubanova, J Bettencourt, and D. K Duvenaud. Neural ordinary differential equations. In
Advances in Neural Information Processing Systems, volume 31, 2018.
[46] T. K Rusch, S Mishra, N. B Erichson, and M. W Mahoney. Long expressive memory for sequence
modeling. In International Conference on Learning Representations, 2022.
[47] K Mizuseki, A Sirota, E Pastalkova, and G Buzsáki. Theta oscillations provide temporal windows for local
circuit computation in the entorhinal-hippocampal loop. Neuron, 64(2):267–280, 2009.
[48] K Mizuseki, A Sirota, E Pastalkova, and G Buzsáki. Multi-unit recordings from the rat hippocampus made
during open field foraging. Database: CRCNS, 2009.
[49] J O’Keefe. Place units in the hippocampus of the freely moving rat. Experimental Neurology, 51(1):
78–109, 1976.
[50] A. D Grosmark and G Buzsáki. Diversity in neural firing dynamics supports both rigid and learned
hippocampal sequences. Science, 351(6280):1440–1443, 2016.
[51] Z Chen, A. D Grosmark, H Penagos, and M. A Wilson. Uncovering representations of sleep-associated
hippocampal ensemble spike activity. Scientific Reports, 6, 2016.
[52] L. J Grosmark, A.D. and G Buzsáki. Recordings from hippocampal area ca1, pre, during and post novel
spatial learning. Database: CRCNS, 2016.
[53] D Zhou and X.-X Wei. Learning identifiable and interpretable latent models of high-dimensional neural
activity using pi-vae. In H Larochelle, M Ranzato, R Hadsell, M Balcan, and H Lin, editors, Advances in
Neural Information Processing Systems, volume 33, pages 7234–7247. Curran Associates, Inc., 2020.
[54] G Santhanam, B. M Yu, V Gilja, S. I Ryu, A Afshar, M Sahani, and K. V Shenoy. Factor-analysis methods
for higher-performance neural prostheses. Journal of Neurophysiology, 102(2):1315–1330, 2009.
12

[55] F Pei, J Ye, D. M Zoltowski, A Wu, R. H Chowdhury, H Sohn, J. E O’Doherty, K. V Shenoy, M. T
Kaufman, M Churchland, M Jazayeri, L. E Miller, J Pillow, I. M Park, E. L Dyer, and C Pandarinath.
Neural latents benchmark ’21: Evaluating latent variable models of neural population activity. In Advances
in Neural Information Processing Systems (NeurIPS), Track on Datasets and Benchmarks, 2021.
[56] A Valente, S Ostojic, and J. W Pillow. Probing the Relationship Between Latent Linear Dynamical Systems
and Low-Rank Recurrent Neural Network Models. Neural Computation, 34(9):1871–1892, 2022.
[57] L Cimeša, L Ciric, and S Ostojic. Geometry of population activity in spiking networks with low-rank
structure. PLOS Computational Biology, 19(8):1–34, 2023.
[58] J O’Keefe and M. L Recce. Phase relationship between hippocampal place units and the eeg theta rhythm.
Hippocampus, 3(3):317–330, 1993.
[59] G Buzsáki. Rhythms of the Brain. Oxford University Press, 1 edition, 2006.
[60] S Liebe, J Niediek, M Pals, T. P Reber, J Faber, J Bostroem, C. E Elger, J. H Macke, and F Mormann. Phase
of firing does not reflect temporal order in sequence memory of humans and recurrent neural networks.
bioRxiv:2022.09.25.509370, 2022.
[61] L Schläfli. Theorie der vielfachen Kontinuität. Birkhäuser Basel, Basel, 1901.
[62] R. C Buck. Partition of space. The American Mathematical Monthly, 50(9):541–544, 1943.
[63] R Stanley. An introduction to hyperplane arrangements. Geometric Combinatorics, 13:389–496, 2007.
[64] B. M Yu, J. P Cunningham, G Santhanam, S Ryu, K. V Shenoy, and M Sahani. Gaussian-process factor
analysis for low-dimensional single-trial analysis of neural population activity. In D Koller, D Schuurmans,
Y Bengio, and L Bottou, editors, Advances in Neural Information Processing Systems, volume 21, 2008.
[65] J Ye and C Pandarinath. Representation learning for neural population activity with neural data transformers.
Neurons, Behavior, Data analysis, and Theory, 5(3), 2021.
[66] A Paszke, S Gross, F Massa, A Lerer, J Bradbury, G Chanan, T Killeen, Z Lin, N Gimelshein, L Antiga,
A Desmaison, A Kopf, E Yang, Z DeVito, M Raison, A Tejani, S Chilamkurthy, B Steiner, L Fang, J Bai,
and S Chintala. Pytorch: An imperative style, high-performance deep learning library. In Advances in
Neural Information Processing Systems, volume 32, 2019.
[67] A Orvieto, S. L Smith, A Gu, A Fernando, C Gulcehre, R Pascanu, and S De. Resurrecting recurrent neural
networks for long sequences. In Proceedings of the 40th International Conference on Machine Learning,
ICML’23, 2023.
[68] L Liu, H Jiang, P He, W Chen, X Liu, J Gao, and J Han. On the variance of the adaptive learning rate and
beyond. In International Conference on Learning Representations, 2020.
A
Supplemental material
A.1
Proof of preposition 1
A.1.1
Problem definition
We are interested in finding all fixed points of the following equation:
τ dx
dt = −x(t) + Jϕ(x(t)),
(8)
with x(t) ∈RN, element-wise nonlinearity ϕ(xi) = PD
d b(d)
i
max(xi −h(d)
i
) and low-rank matrix
J = MNT, with M, N ∈RN×R and R ≤N. Since τ only scales the speed of the dynamics, we
will, for convenience and without loss of generality, assume τ = 1.
13

A.1.2
Preliminaries: Fixed points in Piecewise-linear RNNs
First, we briefly repeat results from [9]. Assume D = 1, ϕ(xi) = max(xi −hi). To find all fixed
points of Eq. 8, start by redefining ϕ by introducing a diagonal indicator matrix:
DΩ=


d1
d2
...
dN

,
(9)
with di =
1,
if xi > hi
0,
otherwise .
Then our RNN equation, for a given x and corresponding DΩreads:
dx
dt = −x(t) + JDΩx(t) −JDΩh.
Each of the 2N configuration of DΩcorresponds to a region in which the dynamics are linear. Thus,
for each configuration, we can solve:
0 = −x + JDΩx −JDΩh,
x∗= (JDΩ−I)−1JDΩh.
Next, we check whether the obtained x∗is consistent with the assumed DΩ(Eq. 9). If so, we found
a fixed point of the RNN. We have to check, as the solution to the system of linear equations can
lie outside of the linear regions specified by DΩ. Note that if for some DΩthe matrix JDΩ−I is
not invertible, then there is no single fixed point, but we still can find a structure of interest (e.g., a
direction with eigenvalue 0 corresponds to marginal stability, i.e., a line attractor).
A.2
Preliminaries: Fixed points in Piecewise-linear low-rank RNNs
First, assume x(0) is in the subspace spanned by the columns of M. With the low-rank assumption,
we can rewrite Eq. 8 for all t ∈[0, ∞), by projecting it on M [18, 20, 21]:
dz
dt = −z(t) + NTϕ(Mz(t) −h)
(10)
with x(t) = Mz(t).
Now assume x(0) contains some part x⊥(0) not in the subspace spanned by M, i.e., we have
x(0) = Mz(0) + x⊥(0). The dynamics of x⊥(t) are simply given by x⊥
dt = −x⊥(t) which will
decay to its stable point at 0 irrespective of z(t), and can thus not contribute additional fixed points.
Naively, using the same strategy as before to obtain all fixed points z, we would need to solve 2N
linear systems of R equations (again for all configurations of DΩ):
z∗= (NTDΩM −I)−1NTDΩh,
(11)
A.3
Preliminaries: Hyperplane arrangements
In the subsequent section, we will turn to the question of how many equations we need to solve to find
all possible fixed points. Recall that it is possible to calculate the fixed points analytically because
piecewise linear nonlinearities partition space into subregions in which dynamics are linear. Each of
the linear regions corresponds to a configuration of DΩ. For networks with low-rank connectivity,
we have to consider only a small subset of those, as only a small subset of all configurations of DΩ
correspond to x’s within the column space of M (See Fig. S1). To find out exactly how many regions
lie within the column space, we will need to answer the question: in how many regions can we
divide R-dimensional space, with N hyperplanes? To answer this question in general, we will need a
theorem from the field of hyperplane arrangements [41, 61–63]. Here we give a brief introduction.
14

Supplementary Figure 1: Proof sketch including DΩ’s. The phase-space of an RNN with N (here 2)
units with activation max(0, xi−hi) is partitioned into 2N (here 4) regions in which the dynamics are
linear, each corresponding to a configuration of DΩ. If dynamics are confined to the R-dimensional
subspace spanned by the columns of M, only a subset (here 3) can be reached. Each unit intersects
the space spanned by the columns of M with a hyperplane (the pink points in the Figure). The
amount of linear regions in M, thus becomes equivalent to "how many regions can we create in
R-dimensional space with N hyperplanes?"
Introduction to hyperplane arrangements:
A finite arrangements of hyperplanes is a set of
N affine subspaces A = {a1, . . . , aN} in some vector space V = RR. Recall a hyperplane
is a R −1 dimensional subspace defined by a linear equation ai := {v ∈V |mTv = h} for
some m ∈V, h ∈R. Note that any linear system of equations Mv = h with M ∈RN×R
equivalents defines an arrangement of N hyperplanes in R dimensional space. In Fig. S2a,c, we show
arrangements of 3 hyperplanes in R2. In this case, a hyperplane is a line, but there are infinitely many
possibilities on how we can arrange these lines in two-dimensional space. We are interested in
N(A) := number of regions A partitions RR,
where regions correspond to the connected components of RR \ A. In this simple case, we can
visually verify that the arrangements in Fig. S 2a partitions the space into 7 regions, whereas the
arrangement in Fig. S2c partitions the space into only 6 regions. Clearly, the number of regions
A partitions space in is strongly related to the number of unique intersections of lines. We have
fewer regions in Fig. S2c, simply because all lines intersect at the same point. If we can wiggle the
hyperplanes a little, and not change the number of regions (as we can do in Fig. S2a, but not Fig. S2c),
we call the hyperplanes in general position (see Theorem 1 for a formal definition).
To count the amount of regions for any arrangement of hyperplanes, we can leverage an algebraic
construction called the intersections poset L(A). This is the set of all nonempty intersections of
hyperplanes in A and includes V . Elements of this set are generally referred to as flats. The flats
are ordered by reverse inclusion x ≤y
⇐⇒
x ⊇y in the intersection poset. We visualized
example intersection posets of the previous examples (Fig. S2b,d). Here we organized the flats by
dimensionality (such a visualization is called a Hesse Diagram). Importantly for any real arrangement
A, N(A) solely depends on L(A) (Corollary 2.1, [63]).
To calculate N(A) from L(A), we need one last construction, namely the Möbius function, recur-
sively defined by
µ(X, s) =
1
if s = X
−P
X⊇s′⊃sµ(X, s′),
if s ⊂X.
(12)
The numerical values for the example are shown in Fig. S2.
Theorem 1 (Zaslavsky’s Theorem; [41, 63]). Given a vector space V = RR and a arrangement of
N hyperplanes A = {a1, . . . , aN} on V , then the number of regions A partitions V (denoted N(A),
can be expressed as follows
N(A) =
X
s∈L(A)
µ(RR, s)(−1)dim(s)
15

a
a1
a2
a3
b
a1
−1
a2
−1
a3
−1
a1 ∩a2
1
a2 ∩a3
1
a1 ∩a3 1
R2
1
c
a1
a2
a3
d
a1
−1
a2
−1
a3
−1
a1 ∩a2 ∩a3
2
R2
1
Supplementary Figure 2: a) An arrangement of 3 hyperplanes a1, a2 and a3 in general position. b)
the associated intersection poset of the arrangement in a. c) An alternative arrangement with its
associated intersection poset. d). Blue numbers indicate the value of the Möbius function.
furthermore, it holds that
N(A) ≤
R
X
r=0
N
r

(13)
with equality if and only if A is in general position i.e. A must satisfy
(i) {a1, . . . , ap} ⊂A and p ≤N ⇒dim(Tp
i=1 ai) = N −p
(ii) {a1, . . . , ap} ⊂A and p > N ⇒Tp
i=1 ai = ∅
One can verify this fact for the given example shown in Fig. S2. We refer to Stanley [63] for an
in-depth formal introduction to this topic. Fundamentally, it is based on the following recursion that
the number of regions for any arrangement satisfies
N(A ∪{aN+1}) = N(A) + N(AaN+1)
where AaN+1 := {aN+1 ∩ai : ai ∈A, aN+1 ∩ai ̸= ∅, aN+1 ⊈ai} (Lemma 2.1, Stanley [63]).
Note that aN+1 is itself an R −1 dimensional vector space, and each intersection aN+1 ∩ai is an
R −2 dimensional hyperplane within aN+1 (e.g., the intersection of two planes is a line within
the planes). Hence AaN+1 is itself an arrangement of N hyperplanes, but in an R −1 dimensional
subspace. In fact, the intersection poset exhaustively enumerates the elements of all possible Aai,
and the Möbius function can be shown to satisfy the above recursion.
If we choose ϕ(xi) = max(xi −hi, 0) i.e D = 1, each neuron would partition space by a single
hyperplane xi = hi or equivalently the R dimensional subspace by the hyperplane MT
i z = hi.
Hence, the hyperplane arrangement is determined by the matrix M and offset h. As these quantities
are learned during training of the RNN, this arrangement is often in a general position because it is
simply numerically unlikely that two hyperplanes are exactly parallel or intersect in exactly the same
"point".This does, however, change in the general case D > 1, for which we derive a tighter bound in
the section below.
Arrangements of parallel families
For the general case ϕ(xi) = PD
d=1 bd
i max(xi −hd
i , 0) each
neurons will partition space with D hyperplanes bd
i xi = bd
i h(d)
i
⇐⇒
xi = h(d)
i
as before;
16

equivalently each neuron partitions the R dimensional subspace with hyperplanes mT
i z = hd
i .
Notably, all the D hyperplanes here will share the same row of M, and thus they are parallel. Clearly,
any such arrangement cannot be in general arrangement by definition.
The resulting arrangement will have a very specific structure. Let’s define
Ai := {ai1, . . . , aiD}
as a family of D parallel hyperplanes. Any pair of hyperplanes ail, aim ∈Ai is parallel. A low-rank
RNN with N neurons and a general activation function will thus lead to an arrangement consisting of
N families of D parallel hyperplanes.
We can use this specific structure to obtain a tighter bound.
Lemma 1. Let A = A1 ∪· · · ∪AN−1 be an arrangement of N −1 families of D parallel lines then
it satisfies the following recursion
N(A ∪AN) = N(A) +
D
X
d=1
N (AaNd)
Furthermore, denote by N(N, R, D) the maximum number of regions attainable by any arrangement
of N families of D parallel hyperplanes in R dimensional space then
N(N, R, D) ≤N(N −1, R, D) + D · N(N −1, R −1, D)
Proof. To add a An to A, we have to add D new parallel hyperplanes. We can do so by iteratively
applying Lemma 2.1 [63]. We obtain
N(A ∪{aN1, . . . , aND}) = N(A ∪{aN1, . . . , aN(D−1)}) + N(
 A ∪{aN1, . . . , aN(D−1)}
aND)
= N(A) +
D
X
d=1
N
 "
A ∪
d−1
[
i=1
{aNi}
#aNd!
Now note that AaNj := {aNj ∩alm : alm ∈A, aNj ∩alm ̸= ∅, aNj ⊈alm}, hence by definition
only hyperplanes that do intersect with aNj are included in this set. As aNj is parallel to any other
aNi for all i ̸= j, all aNj ∩aNi cannot be in the set. Hence for any d, we have that
N
 "
A ∪
d−1
[
i=1
{aNi}
#aNd!
= N(AaNd)
which proves the first equation.
Recall that we define N(N, R, D) as the maximum number of regions attainable by any arrangement.
Notice that A by construction is an arrangement of N −1 families of D parallel hyperplanes in R
dimension. Thus by definition N(A) ≤N(N −1, R, D).
Furthermore, the intersection set of two hyperplanes in dimension R is itself hyperplanes of dimension
R −1. Furthermore, the intersection sets of D parallel hyperplanes with aNd, remain parallel and
hence AaNd is an arrangement of at most N −1 families of D parallel hyperplanes in R −1
dimensions. Thus N(AaNd) ≤N(N −1, R −1, D) leaving us with
N(A ∪{aN1, . . . , aND}) ≤N(N −1, R, D) + D · N(N −1, R −1, D)
As this holds for any arrangement, it also holds for the arrangement that has N(N, R, D) regions
(i.e., which maximizes the number of regions) and, therefore, proves the second equation.
Lemma 2. Let A be an arrangement of N families of D parallel hyperplanes. Then, it holds that
N(A) ≤
R
X
r=0
Dr
N
r

with equality if each family is in a general position, i.e. that every subarrangement {a1j1, . . . , aNjN }
for all 1 ≤ji ≤D is in general position.
17

A1 | {a1i|i <= D}
. . .
AN | {aNi|i <= D}
A1 ∩A2 | {a1i ∩a2j|i, j ≤D}
. . .
A1 ∩AN | {a1i ∩aNj|i, j ≤D}
RR
...
...
...
TR
k=1 Ak | {T
k akdk|d1, . . . , dk ≤D}
. . .
. . .
Supplementary Figure 3: Construction of the intersection poset L(A) for a arrangement of N families
Ai of D parallel hyperplanes in "general position".
Proof. We will first construct an intersection poset L(A) on the level of families Ai in general
position. After all, the intersection properties between these families is the same as between their
elements, e.g. if ai1 intersects aj1 then also all lines in Ai intersect all lines in Aj.
The resulting intersection poset L(A) can be clustered into the corresponding families. We visualize
the construction in Fig. S3.
At each rank r (level from bottom to top), we can choose exactly
 N
r

families of hyperplanes that
intersect (exactly the case if we just have N hyperplanes in general position). To obtain a flat of
dimension N −r we have to choose r out of the N hyperplane families without replacement.
If, e.g., two families of parallel hyperplanes Ai, Aj intersect, then any element aik will intersect with
any element ajl for all 1 ≤k, l ≤D leading to at most D2 flats within each family (there can be less
as other families might intersect in the same "point"). In general, each cluster of intersections of r
families will contain at most Dr flats.
By construction of L(A) and Theorem 1, the lemma follows directly.
To show that this construction indeed is an upper bound for all arrangements, we can use Lemma
1. There, we established a recursion, which any such upper bound must satisfy. Hence, assume
N(N, R, D) = PR
r=0 Dr N
r

. Notice that using Pascal’s identity, we can rewrite
N(N, R, D) =
R
X
r=0
Dr
N
r

=
R
X
r=0
Dr
N −1
r

+
N −1
r −1

=
R
X
r=0
Dr
N −1
r

+
R
X
r=0
Dr
N −1
r −1

=
R
X
r=0
Dr
N −1
r

+ D0
N −1
−1

|
{z
}
:=0
+
R
X
r=1
Dr
N −1
r −1

= N(N −1, R, D) +
R−1
X
r=0
Dr+1
N −1
r

= N(N −1, R, D) + D · N(N −1, R −1, D)
18

A.4
Proof of proposition
Using the previously derived techniques, we will prove here the main proposition. Furthermore, in
Algorithm 1, pseudo-code is given to compute all fixed points in practice.
Proposition 1. Assume the RNN of Eq. 8 , with J of rank R and piecewise-linear activations:
ϕ(xi) = PD
d b(d)
i
max(xi −h(d)
i
, 0). For fixed rank R and fixed number of basis functions D, we
can find all fixed points in the absence of noise, that is all x for which dx
dt = 0, by solving at most
O(N R) linear systems of R equations.
Proof. By definition, each neuron partitions RN in D linear regions with hyperplanes described
by x(d)
i
= h(d)
i
, for the i’th neuron. Using that in the columnspace of M, we have x = Mz., it
follows that each neuron partitions the R dimensional subspace spanned by columns of M, with D
hyperplanes described by PR
r Mi,rzr = h(d)
i
. Notice that these hyperplanes are parallel, as they all
share the same coefficients Mr but have a different offset h(d)
i
. Using Lemma 2 we know that there
can only be PR
r=0 Dr N
r

such regions.
How do we find those regions? Let’s first consider the case of D = 1, and assume that the hyperplanes
are in general position. We can find the corresponding configurations of DΩas follows. We first obtain
the set of all intersections of R hyperplanes. For this we try to solve
 N
R

systems of R equations.
Let MR ∈RR×R be the matrix obtained by choosing R different rows 1, . . . , R of M ∈RN×R (i.e.
picking R neurons), then we may find the corresponding intersection of R hyperplanes by solving
the following linear system of R equations
z∩= M−1
R hR
and
x∩= Mz∩.
which will always have a unique solution if all hyperplanes are in general position, as then all MR
have rank R. Each x∩has 2R possible bordering linear regions. We can find the corresponding
DΩ= diag([d1, . . . , dN)’s matrices of each of those subsections as follows. First di = I(x∩< 0)
for all i <= N. By construction 1, . . . , R at x∩will be exactly at the threshold, by moving away
from it dR can become either zero or one, depending on in which region we and up. Hence, the
2R regions correspond to one in which either combination of neurons 1, . . . R is active (meaning
that it is above the threshold). We thus just have to check all combinations d1, . . . , dR ∈{0, 1}R.
Using this, we will find at most PR
r=0
 N
r

unique configurations (as this is the maximal number
of regions possible for D = 1). To find all the fixed points we hence have to solve Eq. 11 for each
configuration. We thus end up with solving
 N
R

systems of R linear equations to find all regions, and
another PR
r=0
 N
r

∈O(N R) systems of R linear equations to find all fixed points.
Let us now consider the case for D > 1. Note that an RNN with N units and D basis functions per
unit, can be expanded to an RNN with ND units with activation ϕ(xi) = max(xi −hi, 0) ([24],
Theorem 1). Any fixed point can then still be analytically computed using Eq. 11. We expand
the network but keep track of all PR
r Dr N
R

possible intersections. It still holds that from each
intersection, we can reach 2R regions. In total, we will now find at most PR
r=0 Dr N
r

regions
(Lemma 2). To find all the fixed points, we hence have to solve
 N
R

Dr + PR
r=0
 N
r

Dr systems of
R linear equations, which for constant D and R has a cost of O(N R)
Finally, let’s consider the case when hyperplanes are not in general position (which is unlikely to
happen when doing numerical optimization). If there are intersections of more than R hyperplanes,
we proceed as before, but in case the intersection of R hyperplanes we are currently considering
intersects additional hyperplanes, set the diagonal elements of DΩcorresponding to these additional
hyperplanes arbitrarily to 1 (as intersections including the additional hyperplanes are considered
separately). On the other hand, in case some hyperplanes are only part of intersections of less than
R hyperplanes (because they became parallel), we proceed as follows. Instead of considering only
intersections of R hyperplanes, we now also consider all possible intersections of r hyperplanes, with
1 ≤r ≤R. For this, we solve no more than PR
r
 N
r

systems of r equations. Let Mr ∈Rr×R be
the matrix obtained by choosing r different linearly independent rows 1, . . . , r of M ∈RN×R; then
we may find a point on the corresponding intersection of r hyperplanes (note that the intersection
19

itself can now also be a hyperplane) by to solving the following linear system of r equations
z∩= M†
rhr
and
x∩= Mz∩.
with † being the pseudoinverse. We here now end up with solving no more than PR
r
 N
r

systems of
r linear equations to find all regions, which has an equal cost in N as the previous cases.
We here provide pseudocode. For simplicity, we restrict ourselved to the case of D = 1 and assume
that the arrangement specified by M and h is in general position. This can be generalized to the
general setting as presented in the proof.
Algorithm 1: Improved exhaustive search for all fixedpoints
Data: N ∈RN×R, M ∈RN×R, h ∈RN
Result: z_set set of all fixpoints, D_set the set of all relevant DΩconfigurations.
D_set := {};
z_set := {};
idx = [1, . . . , N];
// Find feasible configurations
idx_comb = all
 N
R

combinations of indices idx;
for (i1, . . . , iR) in idx_comb do
MR = M[(i1, . . . , iR), :];
hR = h[(i1, . . . , iR)];
// MR is invertible as the arrangement is in general position
z∩= solve(MR, hR);
x∩= Mz∩;
d_init = x∩> h;
for (v1, . . . , vR) in {0, 1}R do
d = d_init[(i1, . . . , iR)].set(v1, . . . , vR) ;
DΩ= diag(d) ;
D_set = D_set ∪{DΩ};
end
end
// Find fixed points, for the at most PR
r=0
 N
r

configurations
for DΩin D_set do
z∗= solve(NTDΩM −I, NTDΩh) ;
z_set = z_set ∪{z∗}
end
20

B
Additional figures & tables
B.1
Additional statistics for Teacher-Student setups
Supplementary Figure 4: a-c) Pairwise correlations between units of the modes for panel a-c) of
Fig. 3, respectively. Note that c is computed over all conditions.
B.2
Statistics for HPC-11
Supplementary Figure 5: a) We fit a rank-4 RNN to spikes recorded from rat hippocampus [50–52],
and generate new samples from the RNN (right). b) Single neuron statistics. The mean rates and
coefficient of variations of interspike interval (ISI) distributions of a long trajectory of data generated
by the RNN (gen) match those of a held-out set of data (test). As a reference we additionally
computed the same statistics between the train and test set. c) Population level statistics. The pairwise
correlations between neurons for generated data and the test data. d) The corresponding latents
generated by the RNN consists of 10Hz (fast theta) oscillations on top of slower oscillations. e)
Latents with further zooming in (on time), shown together with the LFP signal. f) The power spectrum
latents sampled from the RNN next to that of the LFP.
B.3
Neural Latents Benchmark evaluation
We applied our method to the MC_Maze dataset of the Neural Latents Benchmark (NLB) [55] at 20
millisecond bin size (Table 2). The benchmark evaluates methods on a number of metrics: ‘co-bps’
(co-smoothing bits-per-spike) assesses the quality of firing rate predictions for a set of held-out
neurons that are unobserved in the test data, evaluated with the Poisson likelihood of the true spiking
activity given the rate predictions. ‘vel R2’ evaluates how well the model’s inferred firing rates can
predict the subject’s hand velocity. ‘PSTH R2’ evaluates how well peri-stimulus time histograms
(PSTHs) computed from model-inferred rates match empirical PSTHs from the data. We found that
our method outperforms classical methods (GPFA [64] and SLDS[30]) while certain state-of-the-art
21

deep learning (LFADS [7], Neural Data Transformer [65]) are slightly better than our method on this
particular benchmark. We do note that NLB metrics center around evaluating the quality of smooth
rates inferred from spikes, which is not the central focus of our method. Rather, we aim to fit an
RNN, from which — by design — we can sample noisy latent trajectories that reproduce variability
in the data.
While our method also has comparatively lower dimensionality than the other deep learning ap-
proaches, a latent dimensionality of 36 is still considerably higher than all networks considered in the
Main text. We reason that we need a high number of latents, because the full MC_Maze dataset has a
large number of conditions (108), spanning multiple maze-configurations, which may be difficult to
fully model with autonomous low-dimensional latent dynamics.
Table 2: Performance of our method on the MC_Maze dataset of the Neural Latents Benchmark, ‘dim’
refers to the dimensionality of the model’s underlying dynamics (where possible).
method
dim
co-bps ↑
vel R2 ↑
PSTH R2 ↑
Spike smoothing
137
0.2076
0.6111
−0.0005
GPFA
52
0.2463
0.6613
0.5574
SLDS
38
0.2117
0.7944
0.4709
LFADS
100
0.3554
0.8906
0.6002
NDT
274
0.3597
0.8897
0.6172
Ours
36
0.3210
0.8571
0.5902
B.4
Stimulus-conditioning in monkey reaching task
For the experiment with stimulus-conditioned dynamics in the monkey reaching task, we tested the
performance of models with and without the conditioning inputs. We found that the conditioning
inputs allow the networks to perform better on velocity decoding at lower dimensionalities.
Table 3: Performance benefits of conditioning for monkey reaching task.
conditioning
dim
vel R2 ↑
w/o
conditioning
5
0.7897 ± 0.0687
6
0.8944 ± 0.0039
8
0.9085 ± 0.0048
16
0.9196 ± 0.0041
with
conditioning
5
0.8589 ± 0.0493
6
0.9018 ± 0.0114
Following the analysis in Fig. 7, we also further visualized the model’s match to the spiking statistics,
including mean and standard deviation (SD) of spiking rate, and mean, SD, and coefficient of variation
(CV) of inter-spike intervals. We observed a good match to the mean and SD of the spiking rate
across all conditions. Match to ISI statistics is also quite reasonable given the noise observed between
estimates of the statistics from train and test.
22

Supplementary Figure 6: Spiking statistics of model-generated (teal) and train data (brick red)
compared against test data.
23

B.5
Comparison to approximate method for finding fixed points
Supplementary Figure 7: Repetition of the experiment of Fig. 8, but now with a rank-2 RNN with
128 units. Again, we show the number of fixed points found as a function of the number of matrix
inverses computed, with errorbars denoting the minimum and maximum amount of fixed points found
over 20 independent runs of the algorithm.
Recently an approximate method for finding fixed points in piece-wise linear RNNs was proposed
[25]. The method proceeds by randomly selecting a linear region (a configuration of DΩ, see
Supplement A.1.2) and calculating the corresponding fixed-point. If it is indeed a ’true’ fixed point
of the RNN (it is consistent with the assumed DΩ), we store it. If the fixed point was inconsistent
with the assumed DΩ, we iteratively initialize DΩaccording to the ’virtual’ fixed point found and
calculate the new fixed point corresponding to this DΩ, until we either reach a ’true’ fixed point or
reach a certain amount of iterations. Then, we reinitialize at a randomly selected new configuration
of DΩand repeat the procedure.
Under some conditions, the approximate method can be shown to converge in linear time (∥M ˜NT∥+
∥aI∥≤1) [8], where it will be faster than our exact method — however in general the convergence
of the approximate method strongly depends on the dynamics of the networks. In particular, there are
reasonable settings where the approximate method fails to find all fixed points, such as of a rank-2,
128 unit RNN with 17 fixed points (trained similarly to the teacher RNN of Fig. 3c; Fig. S7). While an
in-depth study of the approximate method is out of scope, we hypothesize that the failure to converge
is because when initializing with randomly selected DΩs out of (D + 1)N possible configurations,
the approximate method tends to converges to the same set of DΩ.
Our method is completely independent of the dynamics of the system and has a fixed cost, after which
one is guaranteed that all fixed points are found. However, we do note that there can be scenarios
where our exact method is still too costly. In this scenario, we propose to use the approximate method,
with one adjustment - we first pre-compute the subset of PR
r Dr N
r

configurations that can contain
fixed points, and then initialize the approximate method using randomly selected DΩfrom this subset.
Empirically, this leads to better convergence in at least some scenarios (Fig. 8, Fig. S7)
For the approximate method, we used code from https://github.com/DurstewitzLab/CNS-2023, which
was released with the GNU General Public License.
C
Additional details of low-rank RNNs
C.1
Discretisation
Given
τ dz
dt = −z(t) + NTϕ(Mz(t)) + Γzξ(t),
Using the Euler–Maruyama method with timestep ∆t:
zt+1 = (1 −∆t
τ )zt + ∆t
τ NTϕ(Mzt) +
√∆t
τ
Γzϵt,
and with ϵt ∼N(0, I), define a = 1 −∆t
τ , ˜N = ∆t
τ N, and Σz = ∆t
τ
2ΓzΓT
z , we obtain the transition
distribution used in our experiments.
24

C.2
Conditional generation
Given input weights H ∈RN×Ns and stimulus s ∈RNs, we define our model as
τ dx
dt = −x(t) + Jϕ(x(t)) + Hs(t) + ξx.
Using the same assumptions as before, x can be described by R + Ns variables
τ dz
dt = −z(t) + NTϕ(Mz(t) + H˜s(t)) + ξz,
τ d˜s
dt = −˜s(t) + s(t),
with x = Mz + H˜s, and

z
˜s

= ([M, H]T[M, H])−1[M, H]Tx.
For constant input s, ˜s will converge to s, and we can ignore the additional Ns variables, assuming
x(0) = Mz(0)+s. Similarly if s varies on a time scale slower than τ, s ≈˜s is a good approximation
[21]. Here, for all experiments, the input is either a constant context signal or a rectangular pulse, so
we always substitute s for ˜s and consider the R dimensional system described by z (which now has
additional conditioning on s).
We can write the conditional sequential distribution generated by discretizing our model as
p(z1:T , y1:T |s1:T −1) = p(z1)
T
Y
t=2
p(zt|st−1, zt−1)
T
Y
t=1
p(yt|zt),
p(zt|st−1, zt−1) = N(F(st−1, zt−1), Σz), p(z1) = N(µz1, Σz1),
where the transition distribution is F(st, zt) = azt + ˜NTϕ(Mzt + Hst).
C.3
Linear transformations of the latent space and orthogonalisation
Given
xt+1 = axt + M ˜NTϕ(xt) + ϵx
zt+1 = azt + ˜NTϕ(Mzt) + ϵz
with ϵz ∼N(0, Σz), ϵx ∼N(0, MΣzMT). We can do any linear transformation of the latent
dynamics z: ˆz = Az, as long as A has rank R, without changing the neuron activity x. To see this,
define ˆM = MA−1, ˆN = A ˜N, and ϵˆz ∼N(0, AΣzAT ), giving us:
xt+1 = axt + ˆM ˆNTϕ(xt) + ϵx
ˆzt+1 = aˆzt + ˆNTϕ( ˆMˆzt) + ϵˆz,
which will leave x unchanged, while our latents z are expressed in a new basis. We typically got
a more interpretable visualization of the latents by orthonormalising the columns of M. Thus we
applied for all visualisations after training A = UTM, with ˆM = U, where U are the first R left
singular vectors of J = MNT.
D
Details of empirical experiments
D.1
Training details
D.1.1
Initialisation
Our models are (unless noted otherwise) initialized as follows:
25

˜Nij ∼U[−
1
√
N ,
1
√
N ],
Mij ∼U[−
1
√
R ,
1
√
R ],
Wij ∼N(0, 2
R),
Hij ∼U[−
1
√Ninp ,
1
√Ninp ],
hi ∼U[−
1
√
N ,
1
√
N ],
b ←0,
a ←.9,
Σz ←.01I,
Σz1 ←I,
µz1 ←0,
where W and b are the output weights and biases respectively. For Gaussian observations we
initialise Σy ←.01I.
For experiments with Poisson observations, we jointly optimized a causal CNN encoder as part of the
proposal distribution. The CNN was conditioned on observations and predicted the mean and log
variance of a normal distribution. It consisted of common initial layers consisting of 1D convolutions,
with a GeLU activation function, and a separate output convolution for the predicted mean and (log)
variance. The CNN was initialized to the Pytorch [66] defaults, except for the bias of the log variance
output layer, to which we added a log(.01) term, such that the output matches the initially predicted
variance of the RNN. The exact number of layers and channels are reported in the sections for each
experiment.
For the teacher-student setups, we used as non-linearity ϕ(xi) = max(xi −hi, 0) for both the
students and the teachers, and for all experiments with real-world data, we used the ‘clipped’
ϕ(xi) = max(xi + hi, 0) −max(xi, 0) [8].
D.1.2
Parameterisation
We constrain a to be between 0 and 1 by instead optimising ˜a with the following (sigmoidal)
parameterisation a = exp(−exp(˜a)) [67]. In experiments with the optimal proposal, we estimate
the full Σz, which we constrain to be symmetric positive definite, by optimizing a lower triangular
matrix C such that Σz = CCT , where we additionally constrain the diagonal of C to be positive
using Cii = exp( ˜Cii/2). For all diagonal covariances, we parameterize the diagonal elements using
Σii = exp(˜Σii). For Poisson observations, we apply a Softplus function to rectify the predicted rate.
D.1.3
Optimisation
During training we minimise the variational SMC ELBO [33–35] (Eq.7) with stochastic gradient
descent, using the RAdam [68] optimiser in Pytorch [66]. We generally use an exponentially decaying
learning rate (details under each experiment).
D.2
Teacher student experiments
D.2.1
Dataset description
We created datasets by first training ‘teacher’ RNNs to perform a task and then generating observations
by simulating the trained teacher RNNs.
For Fig. 3a,b we used code from [22]to train rank-2 RNNs to produce oscillations, using a sine-wave
with a periodicity of 50 time-steps as a target and an additional L2 regularisation on the rates. After
training, we extracted the recurrent weights M, N and biases h, orthonormalized the columns of M,
and created a dataset by simulating the model for 75 timesteps, with Σz = .04I. For Fig. 3a we used
N = 20 units and generated observations according to G = N(Mzt, Σy), with Σy = .01I. Fig. 3b
26

we used N = 40 units and generated observations according to G = Pois(Softplus(wMzt −b), with
w = 4 and b = 3.
For Fig. 3c, we followed a similar procedure but now trained the teacher RNN on a task where it
has to use input. After an initial period of 25 time steps, a stimulus was presented for 25 timesteps
consisting of [sin(θ),cos(θ)]T, where θ was randomly selected every trial out of 8 fixed angles. The
RNN was tasked to produce output that equals the transient stimulus for the next 100 time-steps. Here
we used N = 60 units, Σz = .025I and generated observations according to G = N(Mzt, Σy),
with Σy = .01I. The training data for the student RNN was included for each trial the corresponding
stimulus.
D.2.2
Training details
The ‘student’ RNNs had 20, 40, 60 units, respectively and rank R = 2, matching that of the teacher
RNNs. For Fig. 3a, c. The observation model was a linear Gaussian according to G = N(Mzt, Σy),
and we used the optimal proposal distribution. For Fig. 3b we used G = Pois(Softplus(WMzt−B)),
withW a diagonal matrix (scaling the output of each unit individually). For Fig. 3b, we used a
causal CNN encoder as part of the proposal distribution. It consisted of 3 layers, with kernel sizes
(21, 11, 1), and channels (64, 64, 2). We used (causal) circular padding.
For all three experiments, we used k = 64 particles, batch-sizes of 10, and decreased the learning
rate exponentially from 10−3 to 10−5. For Fig. 3a,b, we used epochs of 400 trials and trained for
1000 and 1500 epochs, respectively. For Fig. 3c we trained for 3000 epochs of 96 trials each. We
used a workstation with a NVIDIA GeForce RTX 3090 GPU for these runs. One model took about 3
to 4 hours to finish training.
D.2.3
Evaluation setup
For Fig. 3 we generated long trajectories of T = 10000 time-steps of data for both the student and
teacher RNNs. To facilitate visual comparisons between student and teacher dynamics, we also
orthonormalized the columns of the students weights M after training, and for Fig. 3a,c picked signs
of the columns of M such that the student and teacher match (note that after orthormalizing, the
columns of M are equal to the non-zero singular vectors of the full weight matrix J, which are
only unique up to a sign flip). As noted before, this leaves the output of the model unchanged. The
autocorrelation in Fig. 3a was computed by convolving a sequence of lag= 120 steps of data with
itself (with duration 2×lag), and normalising such that lag=0 corresponds to a correlation of 1. We
repeated this for 80 sequences starting at different time-points of the whole trajectory.
D.3
EEG data
D.3.1
Dataset description
We
used
openly
accessible
electroencephalogram
(EEG)
data
from
[42,
43]
(
https://www.physionet.org/content/eegmmidb/1.0.0/, ODC-BY licence). The data was recorded from
a human subject sitting still with eyes open (session S001R01), and was sampled at 160 Hz. Like
[8], we used the full 1 minute of recording, but unlike [8], we did not smooth the data (but just
standardized the data). Thus, to compare our performance to [8], who ran their evaluation using the
smoothed data, we smoothed our generated samples equivalently, using a Hann filter with a window
length of 15-time bins, so that we can also compare our samples to the smoothed data.
D.3.2
Training details
We used N = 512 units, and rank R = 3. The observation model was a linear Gaussian conditioned
on the hidden state and we used the optimal proposal distribution. We trained for 1000 epochs
consisting of 50 batches of size of 10, and k = 10 particles. The learning rate was decreased
exponentially from 10−3 to 10−6. Models were trained using NVIDIA RTX 2080 TI GPUs on a
compute cluster. A single model took between 4 and 5 hours to finish training.
27

D.3.3
Evaluation setup
We used our RNN to generate one long trajectory of T = 9760 steps of data, yt (after discarding the
first 2440 steps), which we compare to the EEG data, ˆyt, using two evaluation measures from [8, 24]
(using code from https://github.com/DurstewitzLab/GTF-shPLRNN, GNU General Public License):
Dstsp: This is an estimate of the KL divergence between the ground truth and generated states.
To compute this, we obtained kernel density estimates of the probability density functions (over
states, not time), using a Gaussian kernel with standard deviation σ = 1. We get for the EEG data:
ˆp(y) = 1
T
PT
t=1 N(ˆyt, I), and for the generated data ˆq(y) = 1
T
PT
t=1 N(yt, I). We then used the
following Monte Carlo estimate of the KL divergence: Dstsp ≈
1
n
P log ˆp(ˆyi)
ˆq(ˆyi), using n = 1000
samples ˆyi drawn randomly from the EEG data.
DH: This is an estimate of the difference in power spectra between the ground truth and generated
states. We first computed for each data dimension the spectra ˆyi
ω, yi
ω for the EEG and generated data,
respectively. We used a Fast Fourier Transform, smoothed the estimates with a Gaussian kernel with
standard deviation σ = 20, and normalized the spectra so they sum to 1. We computed the mean of
the Hellinger distances between the spectra: DH =
1
64
P64
i
1
√
2∥
p
ˆyiω −
p
yiω∥.
D.4
Hippocampus HC-2
D.4.1
Dataset description
We used openly accessible neurophysiological data recorded from layer CA1 of the right dorsal
hippocampus [47, 48] (https://crcns.org/data-sets/hc/hc-2/about-hc-2. Signals were recorded as the
rats engaged in an open field task, chasing drops of water or pieces of food that were randomly placed.
We used the session ec013.527 from rat ID ec13, which is approximately 1062 seconds long. From
37 units (neurons) we used 21 neurons that have maximal spike counts, discarding the rest of the
comparatively silent neurons. We binned the spike data to 10ms. We used the first 80 percent of the
data for training, and the rest was saved for testing purposes.
D.4.2
Training details
We used N = 512 units, and rank R = 3 for the run that was used in our Fig. 5. We used a causal
CNN encoder as part of the proposal distribution, which consisted of 3 layers with kernel sizes (150,
11, 1), with (64, 64, 3) channels. During our study, we swept over multiple ranks and found that
theta oscillations consistently emerged from rank 3 onwards, after which reconstruction accuracy
was relatively stable. For each rank, we used three different seeds and two different first layer sizes
for the encoder, 25 or 150. The duration of a randomly sampled trial (sequence length) from the
whole data was 94 time steps when the first layer size was 25, and 219 when the first layer size was
150. We, however, also found that the choice of the duration did not affect the results much. We
trained the model using 3000 epochs, each epoch consisting of 3000 trials with 64 batches and k = 64
particles. The learning rate was decreased exponentially from 10−3 to 10−6. A single model took
approximately 21 hours to finish training on a NVIDIA RTX 2080 TI GPU on a compute cluster.
D.4.3
Evaluation setup
We used our RNN to generate data that matches the duration of the test data, which is 20810 time steps
(∼208 s) (after discarding the first 1000 steps). We compare different spike statistics of generated
data with test data, and for comparison purposes, we also compared the same statistics measurements
between train and test data as well. We calculated the mean firing rate of each neuron, mean of ISI
distributions, and pairwise correlations. We used a band-pass filter 1-40 Hz for the latents and the
LFP signal before calculating the powerspectrogram (Fig.5e).
D.5
Hippocampus HC-11
D.5.1
Dataset description
We used openly accessible neurophysiological data recorded from hippocampal CA1 region [50–52]
(https://crcns.org/data-sets/hc/hc-11/about-hc-11). We used the subset of the dataset called the maze
28

epoch, where a rat was running on a 1.6-meter linear track, with rewards located at each end (left
and right). Throughout this task, neural activity was recorded from 120 identified pyramidal neurons.
As in [13], we only used 60 neurons that had sufficient activity and discarded rest of the units. We
used code from [53] (https://github.com/zhd96/pi-vae) to preprocess the spike data, and only use data
corresponding to the rat running and the location data being available. We used 25ms bins.
D.5.2
Training details
We used N = 512 units, and rank R = 4. We used the causal CNN encoder with zero padding, 3 layers
(24, 11, 1), and (64, 64, 4) channels. The model is trained for 3000 epochs, each epoch having 3000
trials with a sequence length of 94 time bins (2.35 s), using batch size 64 and k = 64 particles. The
learning rate was decreased exponentially from 10−3 to 10−6. A single model took approximately 21
hours to finish training on a NVIDIA RTX 2080 TI GPU on a compute cluster.
D.5.3
Evaluation setup
We used our RNN to generate data that matches the duration of the test data, which is 4289 time steps
(∼107 s) (after discarding the first 1000 steps). We calculated the mean firing rate of each neuron,
coefficient of variations of ISI distributions, and pairwise correlations. We fit a simple linear regressor
to posterior latents to predict the location data, and used this regression model to predict the test data
for the location.
D.6
Monkey Reach
D.6.1
Dataset description
We used the publicly available MC_Maze dataset from the Neural Latents Benchmark (NLB) [55]
(https://dandiarchive.org/dandiset/000128, CC-BY-4.0 licence). The data were recorded from a
macaque performing a delayed center-out reaching task with barriers, resulting in a variety of straight
and curved reaches. For simplicity, we took only the trials with no barriers and thus straight reach
trajectories, resulting in 592 training trials and 197 test trials. We binned the data at 20 ms and aligned
each trial from 250 ms before to 450 ms after movement onset.
To create conditioning inputs for the model, we took the x and y coordinates of the target position for
each trial and scaled them to be between −1 and 1. We then provide this scaled target position as
constant context input to the RNN for the duration of the trial.
D.6.2
Training details
We ran a random search of 30 different models with rank r ∈3, 4, 5, 6 and particle number k ∈
16, 32, 64. All models had 512 units and used a causal CNN encoder with kernel sizes (14, 4, 2)
and channels (128, 64, r). We used (causal) reflect padding. We trained each model for up to 2000
epochs, terminating training early if no improvement was seen for 50 epochs. Each model took
around 3 to 4 hours to train on an NVIDIA RTX 2080 TI GPU on a compute cluster. Seeing that a
rank of 5 was sufficient for velocity decoding R2 ≈0.9, we took the best-performing rank-5 model
for subsequent analyses.
D.6.3
Evaluation setup
For qualitative evaluation of replication of cross-condition differences, we grouped the reach targets
in the data into 7 conditions, one at each corner and the midpoint of each edge of the rectangular
reach plane, excluding the midpoint directly at the bottom. We then generated data from the model
RNN using conditioning inputs from the test trials of the real data. Then, for the test data and the
model-generated data, we computed mean firing rate and inter-spike interval for each neuron for
each condition. We then computed correlation distance (1 −r, where r is the Pearson correlation
coefficient) on the neuron statistics between conditions in the test data and model-generated data.
For generation of data for Fig. 7d,e, we selected target locations by choosing angles from 0 to 360◦,
evenly spaced by 22.5◦, and determined the corresponding reach endpoint on a square spanning from
(−1, −1) to (1, 1). We then constructed conditioning inputs similar to the real data using these target
29

locations and simulated the RNN with them. To decode the reaches, we used a linear decoder trained
from inferred firing rates to reach velocity from the real data.
D.7
Neural Latents Benchmark
D.7.1
Dataset description
We again used the publicly available MC_Maze dataset from NLB (see Supplement D.6.1). We
resampled the data to 20 ms bin size and followed the standard data preprocessing procedures for the
benchmark, as described in [55].
D.7.2
Training details
We ran a random search of 30 different models with varying rank from 12 to 40 and particle number
k ∈16, 32, 64. All models had 512 units and used a causal CNN encoder with kernel sizes (14, 4, 2)
and channels (128, 64, 36), and reflect padding. We trained each model for up to 2000 epochs,
terminating training early if no improvement was seen for 50 epochs. Each model took around 10 to
12 hours to train on an NVIDIA RTX 2080 TI GPU on a compute cluster.
Because the primary task of the benchmark is co-smoothing, i.e., prediction of held-out neuron
firing rates from held-in neurons, we provide the encoder with only the activity of held-in neurons.
However, the observation likelihood component of the ELBO is computed on all neurons, held-in
and held-out.
After training, we selected the model with the best co-smoothing score on the validation split and
submitted its predictions to the benchmark for the final evaluation.
D.7.3
Evaluation setup
Automated evaluation was performed on the benchmark platform, as described in [55].
We used for the prediction at timestep t, the expected Poisson rate of held-out neurons, conditioned
on the activity of held-in neurons at the current and previous timesteps, by making use of the filtering
Posterior (Eq. 3). We averaged over 32 sets of trajectories with 192 particles each.
30

