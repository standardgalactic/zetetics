See discussions, stats, and author profiles for this publication at: https://www.researchgate.net/publication/366956734
Modeling Team Interaction and Decision-Making in Agile Human-Machine
Teams: Quantum and Dynamical Systems Perspective
Article Â· May 2023
DOI: 10.1109/THMS.2023.3276744
CITATIONS
0
READS
129
3 authors:
Some of the authors of this publication are also working on these related projects:
Examining Human-Autonomy Team Interaction and Explicable Behavior View project
Dynamic Modeling of Trust in Automation in Human-Autonomy Teaming View project
Mustafa Demir
Arizona State University
90 PUBLICATIONSÂ Â Â 1,093 CITATIONSÂ Â Â 
SEE PROFILE
Mustafa Canan
Naval Postgraduate School
80 PUBLICATIONSÂ Â Â 1,702 CITATIONSÂ Â Â 
SEE PROFILE
Myke C. Cohen
Arizona State University
20 PUBLICATIONSÂ Â Â 14 CITATIONSÂ Â Â 
SEE PROFILE
All content following this page was uploaded by Mustafa Demir on 14 May 2023.
The user has requested enhancement of the downloaded file.

1 
 
*
Modeling Team Interaction and Decision-Making in 
Agile Human-Machine Teams:  
Quantum and Dynamical Systems Perspective 
 
Mustafa Demir, Member, IEEE, Mustafa Canan, and Myke C. Cohen 
Abstractâ€” In this study, we define team agility as a function of 
exploration and exploitation of team coordination. Based on these 
two coordination concepts, we examined interactive decision-
making in a dynamic task environment by applying: (1) the 
principles of quantum cognition for the decision-making processes 
at the confluence of teamwork and taskwork (to discern the effects 
of ontic uncertainty for each human team member in the case of 
having incomplete teamwork) and (2) nonlinear dynamical systems 
modeling for the teamwork (to capture epistemic uncertainty). In 
this study, there were three conditions based on manipulation of 
the pilot role: (1) synthetic condition - the pilot role was played by 
a synthetic agent, (2) control condition - it was a randomly 
assigned participant, and (3) experimenter condition - it was an 
expert who used a role-specific coordination script. Overall 
findings indicate that when teams in the experimenter condition 
come across the targets, they tend to explore alternatives by 
coordinating as a team rather than exploiting existing team 
strategies which may not work best for the situation at hand. In 
contrast, teams in control and synthetic conditions tended more 
towards exploitation than exploration in coordination. We consider 
this a sign of agility in teamwork. 
 
Index 
Termsâ€” 
Artificial 
Intelligence, 
Human-Machine 
Teaming, Decision Making, Nonlinear Dynamical Systems, 
Quantum Cognition, Team agility 
I. INTRODUCTION 
VER since the Industrial Revolution, advancements in 
machines have been a driving force in the achievement 
of scientific milestones, from conventional automation 
to autonomous machine teammates. As Isaac Asimov indicated, 
technological evolution is faster than biological evolution, but 
it has been slow until this century [1]. With recent 
advancements in machine learning and artificial intelligence 
(AI; [2]), highly autonomous machines now function more as a 
teammate instead of optimization tools in various dynamic task 
environments, such as in human-synthetic teams in remotely 
piloted aircraft systems [3], in human-robot teams in urban 
search and rescue [4], or Marine operations [5]. Human-
Machine Teams (HMTs) are characterized by human and 
autonomous members with distinct roles working together for a 
common goal or task. To be considered part of a team, the 
machine must participate either by serving as an interactive 
external repository of information or as an executor and 
mediator between members [6]. But even if autonomous 
 
*This work was supported in part by the U.S. Office of Naval Research 
(ONR) under Grant N000141712382, and ONR - CRUSER under N00244-18-
S-NPS-F001. Corresponding author: M. Demir.  
Mustafa Demir is with the Center for Human, AI, and Robot Teaming, 
Arizona State University, Tempe, AZ 85281 USA (e-mail: mdemir@asu.edu).  
machines can now be considered teammates, HMTs may still 
not be agile enough to adapt to dynamic task environments 
because of the machinesâ€™ lack of cognitive processes, such as 
interaction. 
Agility is an emergent phenomenon in which lower-level 
system elements (e.g., team members) interact to adapt to a 
dynamic environment [7]. Earlier studies framed the 
phenomenon as adaptability, which was the word of choice in 
psychological studies of individual and group behavior at the 
time. The second of the two replicated the results of the first and 
expanded the interpretation in the direction of group self-
efficacy, with less emphasis on adaptability (see the studies [8], 
[9], respectively). Therefore, understanding complex adaptive 
team behavior is critical to the design of agile HMTs. For 
instance, 
interactions 
among 
team 
members 
(i.e., 
communication and coordination) are activities through which 
team agility can be observed in a dynamic task environment 
[10]. The relationship of complex team interactive behaviors 
with team performance has been studied in different dynamic 
task 
environments, 
including 
communication 
[11], 
coordination [12], and trust [13]. Another activity in which 
team agility manifests is interactive decision-making, which is 
defined as â€œa process where team members consult one another 
and make their final decision [regarding their task] aloneâ€ [14, 
p. 306]. In other words, this process involves team members 
explaining their choices and thinking as a group about those 
they have not considered before, maintaining teamwork by 
making decisions.   
This paper conceptually and analytically outlines the team 
interaction dynamics and interactive decision-making to 
understand HMT agility. Therefore, the main goal of this paper 
is to explicate team agility by considering team coordination 
stability using quantum cognition and dynamical systems 
approaches. We discuss an experiment that used a machine as a 
team member who interacted with human counterparts to make 
team-level decisions. Our results identify empirical findings 
that we believe can advance the design of HMTs, especially 
real-time 
stability 
measurement 
techniques 
and 
team 
interactions therein. We follow this with a framework that can 
aid in identifying and empirically studying what interactive 
decision-making means in the context of agility in HMTs. 
Mustafa Canan is with the Department of Information Sciences, Naval 
Postgraduate 
School, 
Monterey, 
CA 
93943 
USA 
(e-mail: 
mustafa.canan@nps.edu). 
Myke C. Cohen is with the program of Human Systems Engineering, Mesa, 
AZ 85212 USA (e-mail: myke.cohen@asu.edu). 
E

2 
THMS-21-12-0464 
 
II. LITERATURE 
A. Team Agility: Exploration and Exploitation 
In complex task environments in which team behaviors 
emerge, team agility is one of the primary determinants of a 
teamâ€™s success. Based on the findings of a previous study [12], 
we define team agility as a teamâ€™s capability to remain flexible 
and maintain stability in facing a taskâ€™s inherent dynamism. 
This involves adjusting team behavior continuously and 
developing new ones (e.g., coordination) to adapt to 
unpredictable changes in the task environment. This capability 
is not only a response to major disruptions; it also implies that 
a team is able to proactively change its course of action to 
sustain its performance over time [12]. Team agility has three 
dimensions. Firstly, team agility involves a set of actions taken 
by a team that operates in an environment characterized by 
rapid and unpredictable change, i.e., agile teams can 
successfully adapt to this disruptive environment. Secondly, 
team agility requires changes that are different from routine 
changes, i.e., the changes that result from team agility are 
specified as continuous, systematic variations in a teamâ€™s 
perception, comprehension, and projection. The intensity and 
variety of these changes are high; thus, agile teams demonstrate 
complex adaptive behavior. Finally, rapid information 
gathering is critical to gleaning the environmental changes that 
might require agile-adaptive behavior, i.e., team agility requires 
team-level situation awareness to maintain adaptiveness. 
A salient indicator of team agility is when exploration and 
exploitation of various ways that a team can interact is 
observable in a team. Exploration involves the pursuit of new 
information, while exploitation involves using resources that 
are already known [15, p. 105]. Exploration is associated with 
the teamâ€™s knowledge base. Together, these processes form a 
loop that departs from established modes of coordination 
between team members. For example, agile teams coordinate in 
established ways (exploitation) and then shift to a new mode of 
coordination (exploration) to respond to unexpected events 
promptly. Agile exploration, in other words, involves seeking a 
solution to a novel situation by increasing the flexibility of 
established team coordination. Exploratory team interactions 
have previously been defined as any unique interaction in light 
of a teamâ€™s collective history [16]. In part, they are 
characterized by how feedback is explored in a novel situation 
in an exploitation-exploration process, consistent with a teamâ€™s 
tendency to transition from exploitation to exploration, and vice 
versa, over time. 
B. Team Coordination Dynamics 
The importance of team interactions is underlined in the 
Interactive Team Cognition (ITC) theory [17]. Accordingly, 
team cognition is team interaction; thus, team cognition can be 
measured with the team as a unit of analysis instead of 
individuals. ITC considers team cognition with the perspective 
that tasks are dynamic in nature. In this case, team interactions 
are emergent properties of teams that are irreducible to the 
heterogeneous characteristics of individual team members. This 
characterization places team cognition within the realm of 
nonlinear dynamical systems (NDS). 
The NDS approach has shown much about how teams 
interact in various dynamic task domains [8], [18]â€“[23]. 
Gorman, Amazeen, and Cooke (2010) [24] applied NDS 
methods in a remotely piloted aircraft systems (RPAS) task 
environment, in which team membership either changed (i.e., 
Mixed teams) or stayed the same (i.e., Intact teams) over 
successive experimental sessions. Their findings show that 
mixed teams were better able to adjust to unexpected 
perturbations, and this ability was linked to team-level 
dynamics: Mixed teams adopted a globally stable pattern of 
communication while exhibiting strong temporal dependence. 
Another study shows that teams (in their case, mixed teams, i.e., 
human-machine teams)  should be â€œflexibleâ€ to adapt to 
dynamic task uncertainty and also be â€œstableâ€ to maintain 
performance (for more elaboration regarding stability and 
flexibility, see [10]). Their study found an â€œinverted U-shapeâ€ 
relationship between interaction flexibility and performance. 
They predicted that the interaction dynamics of novice all-
human teams might exhibit greater flexibility (at the cost of 
performance) compared to Wizard of Oz (WoZ [25]) HMTs, 
which may exhibit a state of interaction metastability [10], [12]. 
Similar findings have supported this by observing calibrated 
interactions (i.e., teams adjusting interaction based on the task 
situation), which was considered as the metastable coordination 
level for better team performance [4], [10], [26] and 
effectiveness (such as team situation awareness, team trust; 
[13], [27]â€“[29]). These findings support the ITC viewpoint by 
emphasizing the importance of contextualized team-level 
process measures in the study of team cognition [17]. In this 
study, we investigate the potential of NDS and team agility to 
capture the differential dynamics of all-human and HMTs. 
C. Interactive Decision Making  
Team communication and coordination are dynamic 
interaction constructs in HMTs and are both factors and 
manifestations of another cognitive construct: interactive 
decision-making, which is a process of identifying and 
choosing alternatives in interactive tasks. This activity also 
involves other cognitive aspects, such as the theory of mind, 
social cognition, and goal-directed behaviors [30]. Team 
interactions allow team members to develop coherent rationales 
and opinions from other team members regarding a team task, 
but because they make their final decisions individually, they 
can either use or ignore the information they collect during team 
interaction. In other words, interacting team members can make 
choices that favor either their individual task or overall 
teamwork in light of their common goal. Related to team 
agility, 
interactive 
decision-making 
also 
depends 
on 
exploitation and exploration in team coordination. From the 
definitions of exploration and exploitation, interactive decision-
making as a process is thus affected by contextual changes, i.e., 
cost and benefit in the context of routine and novel conditions. 
Team members need to choose either established or new forms 
of coordination with other team members to be agile and, in 
turn, maintain a desirable level of performance. Thus, team 
agility is a quality or a measure of interactive decision-making.  
In this study, we analyze team membersâ€™ interactive 
decision-making process for taskwork by considering quantum 
cognition principles along with NDS. In doing so, we scrutinize 
a teamâ€™s instability by considering how much the choices of one 
member depend on antecedent decisions and the behavior of 
other team members. This also helps us understand how agile 

3 
THMS-21-12-0464 
 
HMT members synchronize with each other during decision-
making. 
D. Quantum Cognition 
Human judgment and decision-making are probabilistic and 
dynamic; typically, these models thereof have been built and 
tested with the axioms of the classical probability theory (CPT) 
[31]. Newer findings in cognitive science demonstrate that 
quantum probability theory (QPT) [32]â€“[35] can also be used 
to build and test the models of human decision-making. CPT-
based models are robust but may fail to explain and predict the 
decision outcome when an event (e.g., a perturbation in a 
situation) produces a context for a possible subsequent event. A 
decision-maker perceives and evaluates events in a situation 
using perspectives which are considered compatible [32]â€“[35]. 
However, when a perturbation occurs in the same situation, the 
same person may lack the knowledge and experience to 
evaluate the events with compatible perspectives; hence, in this 
novel situation, perspectives can be incompatible for the same 
individual [36], [32]. In these types of situations, compatible 
event representation may only become available after the 
human gains experience by observing the events and 
establishing a coherent understanding of the situation, which 
may cause a delay in decisions and hinder agility. Both 
compatible and incompatible perspectives may be available to 
evaluate the situation; however, the dynamics of a complex 
situation, which is context and time-sensitive, may give rise to 
the use of one or the other [32]. 
The use of compatible perspectives gives rise to decision 
outcomes that are coherent with the axioms of CPT. In contrast, 
the use of incompatible perspectives gives rise to violations of 
the CPT axioms [32],  such as order effects, sure thing principle 
violation, and conjunction and disjunction fallacies, all of 
which can be explained in terms of interference effect that is 
supported by QPT [32], [35]. To discuss the interference effect, 
suppose three events, A, B, and C, are probable in a situation; a 
decision model is built to calculate the probability of event C 
happening in two different conditions. In the first condition, 
events are observed in the following order:  ğ´â†’ğµâ†’ğ¶. In the 
second condition, event B is not observed; hence the event order 
becomes ğ´â†’ğ¶. The interference effect is the difference 
between the probability values of event C occurring in these 
two conditions [32], [35].  
With respect to team agility and interactive decision-
making, during exploitation or exploration, team members may 
need to skip a decision or communication in response to a 
perturbation, which can produce a different sequence of events 
compared to routine situations. Due to the nature of the process, 
interference effects may emerge and dominate the decision 
process. Consequently, CPT-based models can become 
inadequate to explicate team stability in the face of changing 
communication and coordination behaviors. Team stability in 
these types of situations must be monitored by considering the 
interference effects, which cause the decision probabilities to 
oscillate. The emerging oscillatory behavior is unique to QPT 
dynamics and can account for an ontic (implicit) type of 
uncertainty [33], [37], [38] that represents the vacillation of the 
decision-maker. These oscillations can be strong immediately 
after the perturbation; as a result, Lyapunov exponents can 
transiently become positive, indicative of system instability. In 
quantum decision theory (QDT) [39], [40] Lyapunov exponents 
are calculated via Kullback-Leibler [39], [40] relative 
information gain approach; in doing so, local Lyapunov 
exponents are dynamically calculated where multiplier matrix, 
ğ‘šğ‘–ğ‘—, elements are expressed in terms of decision outcome 
probabilities of the interacting decision-makers: ğ‘šğ‘–ğ‘—(ğ‘¡) =
ğ›¿ğ‘ğ‘–(ğ‘¡)/ğ›¿ğ‘ğ‘—(ğ‘¡), where ğ›¿ğ‘ğ‘–(ğ‘¡) represents the interference effect 
contribution, and Lyapunov exponents then become ğœ†ğ‘–,ğ‘—â‰¡
1/ğ‘¡  ln [0.5 âˆ—(ğ‘‡ğ‘Ÿ ğ‘šÌ‚ Â± âˆšğ‘‡ğ‘Ÿ ğ‘šÌ‚ âˆ’4 det ğ‘šÌ‚ )] [39], [41]; for two 
interacting 
agents, 
ğ‘‡ğ‘Ÿ ğ‘šÌ‚ â‰¡ğ‘š11 + ğ‘š22 and 
det ğ‘šÌ‚ â‰¡
ğ‘š11ğ‘š22 âˆ’ğ‘š12ğ‘š21.  
E. Quantum Cognition and Situation Awareness 
To further explicate the cognitive enabler of team agility 
while sustaining team stability, a conceptual analysis of  
Endsleyâ€™s three-level situation awareness framework [42] is 
done with the quantum cognition principles. Level 1 situation 
awareness is a mixture of implicit and explicit elements. The 
perception of cues and other environmental factors in the 
situation transpires at this level. Level 2 situation awareness is 
the cognitive systemsâ€™ comprehension of the current situation 
based on the Level 1 elements; this is the level at which the 
context and causal relations are processed with the Level 1 
elements. Level 3 situation awareness involves the projection 
of the decision outcomes in the situation. These three levels are 
concomitant processes, and the interplay between the elements 
of each level can be different in complex situations. For 
example, when a perturbation occurs, team members may not 
form a coherent understanding of the situation due to the 
dominance of incompatible perspectives. Until a cognitive 
adaptation to the novel situation occurs, reconstructed and 
newly formed perspectives would continue to be incompatible. 
Since incompatible perspectives give rise to interference effects 
(higher ontic uncertainty), which influence the information-
seeking (perception) at Level 1 and the comprehension process 
at Level 2. Due to the oscillating probabilities, the projection of 
actions/decisions, Level 3, can become prone to interference 
effects, which give rise to conjunction or disjunction fallacies, 
order effects, or violation of transitivity. 
New methods are necessary to minimize and monitor the 
presence of interference effects. To achieve this, in the  RPAS 
decision processes, we used the Bell inequality test for the first 
time in team studies to monitor the presence of interference 
effects [32], [44]. Since interference effects are one of the 
sources of uncertainty, Bell's temporal inequality test can 
provide additional system-level insight to monitor the implicit 
(ontic) uncertainty and its impacts on team stability. 
III. METHODS 
A. Simulated RPAS Task Environment 
The experiment took place in the RPAS Synthetic Task 
Environment (STE) testbed, which emulates the individual and 
team cognitive activities that occur in an RPAS ground station. 
The 
RPAS-STE 
comprises 
three 
heterogeneous 
and 
interdependent task roles ([39]). The goal of this task was to take 
good photos of target waypoints while navigating the RPA along 
a safe route. Timing and content of communication were 
important for the teams to succeed. In this study, the pilot role 

4 
THMS-21-12-0464 
 
was either an Adaptive Control of Thought-Rational (ACT-R; 
[46]) based cognitive model or a randomly selected participant 
or an â€œAIâ€ teammate that was simulated by a trained confederate 
using a â€œWizard of Ozâ€ methodology (WoZ) [25]. The AIâ€™s 
capabilities were limited in verbal comprehension, production, 
and piloting behaviors for this experiment. The confederate 
followed a script that indicated when and what to communicate 
throughout the task and described behaviors for controlling the 
flight of the RPA. Pilot behaviors were limited to the script.  
In the RPAS team task, team coordination comprises three 
key communication events at each target waypoint, which 
happen in the following optimal coordination sequence [18]: (1) 
information (I) is given by the navigator to the pilot about the 
target waypoint of the mission (i.e., altitude, speed restrictions, 
and effective radius), (2) negotiation (N) occurs between the 
pilot and photographer regarding camera settings, airspeed, and 
altitude at the target, and (3) feedback (F) is given by the 
photographer to the pilot and navigator about whether the 
photograph taken at the target is acceptable. 
B. Design 
The study involved three conditions/configurations based on 
the identity of the pilot teammate. Accordingly, if the pilot was: 
(1) a synthetic teammate (i.e., an ACT-R-based computational 
model [46]), or simply the synthetic condition, (2) a randomly 
assigned human participant, control condition, or (3) an expert 
confederate who used a role-specific coordination script, 
experimenter condition.  
For all three conditions, team members communicated with 
each other using a text-based interface, and each member had 
access to a communication cheat sheet for effective 
communication with the pilot and another team member. 
Participants in the synthetic condition had to ensure that 
messages to the synthetic teammate were neither ambiguous 
nor cryptic [47] due to the latterâ€™s limited language capabilities. 
In the experimenter condition, the confederate pilot used a 
coordination script and asked the participants scripted questions 
to promote the adaptive passing of information about the critical 
waypoints [48], [49]. 
C. Interactive Decision-Making In RPAS Roles 
Interactive decision-making across the RPAS roles varies in 
terms of the level of complexity of the decision-making 
structure. We divided each roleâ€™s interactive decision-making 
process into the three-level situation awareness model [42]. 
Across all three roles, the teamwork-related indicators (i.e., 
altitude, airspeed, and current and next waypoint-related 
information) played an important role in facilitating 
transparency in team tasks, primarily for the pilotâ€™s task role. 
Controlling the teamwork-related indicators is the pilotâ€™s task 
based on interacting with the other roles. At the individual level, 
we model situation awareness based on taskwork. Due to the 
page limit, we only discuss the navigatorâ€™s taskwork with a 
quantum cognition perspective; by doing so, the effects of 
incomplete teamwork can give rise to interference effects that 
can influence taskwork. In Fig. 1, taskwork and teamwork-
related indicators are illustrated for each task role. Accordingly, 
each role focuses on their taskwork: the navigator to the 
waypoint map, the pilot to the route and fuel, and the 
photographer to the camera settings and photo log. All three 
team members monitor the teamwork-related indicators 
regarding the current and next waypoint.  
 
Fig. 1. Teamwork and taskwork indicators across the three roles. Teamwork: 
altitude, airspeed, and current and next waypointsâ€™ information). Taskwork: 
navigator (map and waypoint list), pilot (course deviation, fuel, air flaps, and 
gears), and photographer (camera and camera settings). 
Fig. 2 categorizes each task roleâ€™s situation awareness 
regarding perception, comprehension, and projection. In terms 
of INF coordination sequence, comprehension plays an 
important role in relating to the perception and projection stages 
of the navigatorâ€™s task because sending information about the 
target waypoint happens during the task comprehension (Level 
2 SA). However, considering only comprehension and ignoring 
perception and projection is insufficient for understanding the 
individual level of the task. Since agility is the capability of 
having and developing multiple ways of coordination to adapt 
to dynamic task environments while maintaining team stability, 
the sources of instability of the team structure must be 
monitored when a perturbation occurs. Perturbations entail 
changes in team membersâ€™ situation awareness because they 
increase the uncertainty of a system. Due to the 
interdependence between team members, any change in the 
situation can engender incongruences in shared understanding 
(i.e., situation awareness). For instance, when the navigator 
looks at the map and finds the relevant waypoints based on the 
colors and notices a message expressing disagreement from the 
pilot, the ensuing disagreement at the perception level 
permeates situation awareness and gives rise to uncertainty at 
the comprehension level. In this study, we specifically focus on 
the perception and comprehension stage of the decision-making 
process by considering the message-sent time (i.e., perception) 
and message-read time (i.e., comprehension). We do this 
through the following variables: message sent time is 
perception because it is at a team member recognizes a task in 

5 
THMS-21-12-0464 
 
need of coordination and signals it to other team members; 
message read time is the comprehension stage because the team 
member(s) begins comprehending the task coordination 
requirements at that point. We hypothesize that the coordination 
dynamics differ between each level of SA.  
 
Fig. 2. Situation awareness across three task roles. 
D. Participants 
A total of 70 participants (60 males and 10 females, 
Mage=23.7, SDage= 3.3) split into 30 teams (10 per condition) 
were recruited from Arizona State University and surrounding 
areas for this experiment. All participants had normal or 
corrected vision and were fluent in English. They were 
compensated $10 per hour. Each team completed an 
approximately eight-hour experiment. Participants were 
assigned their task roles randomly.  
E. Synthetic Teammate and Materials 
Teams in the synthetic condition featured an AI teammate 
with an ACT-R cognitive modeling architecture [46]. This 
architecture comprises the following components [50]: (1) 
English language analysis to accommodate teammate 
communications, (2) language generation for communications 
originating from the AI, (3) dialog modeling to recognize when 
communication is needed, (4) situation modeling for situation 
awareness, and (5) agent-environment interaction to fly the 
Remotely Piloted Aircraft (RPA) plausibly.  
Participants had access to a communication â€œcheat sheetâ€ that 
showed examples of communicating with the synthetic 
teammate. Other print materials containing supplemental 
information, such as role-specific rule summaries, were 
displayed at the corresponding workstations. Confederates in 
the experimenter condition had a coordination script to aid 
information pushes and pulls with participants.  
F. Procedure 
Participants were asked to sign an informed consent form 
upon arrival and were randomly assigned to one of the roles 
afterward. The pilot was isolated in one room in all three 
conditions, with the navigator and the photographer together in 
another location. In the synthetic and experimenter conditions, 
participants were limited to navigator and photographer roles 
only, and were informed that the pilot was a synthetic 
teammate. Teams in the control condition knew that all roles 
were occupied by a human participant. After roles were 
assigned, participants individually received a briefing and a 30-
minute role-specific skills training using an interactive 
PowerPoint audiovisual presentation. A 30-minute team hands-
on training took place afterward.  
Each team completed five 40-minute missions. After 
completing the first mission, a knowledge check was conducted 
individually and as a team to test participants regarding team 
and task-related knowledge relevant to the RPAS-STE. Teams 
had to photograph 11 target waypoints for Mission 1 and 
Mission 3, 12 for Mission 2, 13 for Mission 4, and 20 for 
Mission 5.  
Throughout the missions, team communication was observed 
by two experimenters who checked appropriate boxes on 
situation awareness and coordination logs in real-time. After 
teams reached each target, both experimenters independently 
rated the teamâ€™s process behaviors (i.e., adequacy of team 
member behaviors such as communication) on a scale of one to 
five, five being the best. After the last mission, teams were 
administered a second round of knowledge tests and NASA 
TLX surveys, and had demographic data (e.g., age, education) 
collected. Lastly, participants were debriefed about the 
experiment. This entire procedure is summarized in Table 1. 
TABLE 1 EXPERIMENTAL SESSION 
Session Order and Task Duration 
1) Consent forms (15 min) 
6) Mission 3 (40 min) 
2) PowerPoint (30 min) and 
hands-on training (30 min) 
7) Mission 4 (40 min)  
3) Mission1 (40 min) 
8) Mission5 (40 min) 
4) NASA TLX-I / Knowledge 
Session-I (30 min) 
9) NASA TLX-II / Knowledge 
Session-II (30 min) 
5) Missions 2 (40 min) 
10) Post-Check Procedure (15 min) 
Note. From the hands-on training onwards, a 15-minute break occurred after 
each task. The total approximate time for each session was eight hours. 
G. Measures 
Only two measures were considered for this study: (1) a 
target performance score was collected for each of the targets. 
These scores were calculated based on 1000 points possible for 
each target, less the number of seconds spent in the target radius 
and minus 200 penalty points per missed photo [52]; (2) Kappa 
scores (Ğº) were calculated according to the message sent, and 
the message read of the components of the INF coordination 
sequence. The Kappa score is an order parameter for the 
subsequent analysis; for a detailed discussion of the measure, 
we refer the reader to [18].  
IV. MODELING AND RESULTS 
To improve the understanding of interactive decision-
making in the experimental context, we propose two techniques: 
(1) quantum cognition for taskwork decision-making processes 
to discern the impact of interference effects to monitor the ontic 
uncertainty for each individual taskwork; and (2) nonlinear 
dynamical systems modeling teamwork and capture epistemic 
uncertainty.  
A. Quantum Cognition and Bellâ€™s Temporal Inequality Test 
 In complex situations [36], quantum models of cognition 
can ameliorate the understanding of the sources of instability. 

6 
THMS-21-12-0464 
 
To start, consider the case where the navigator finds the relevant 
waypoints based on colors on the map and notices a disagreeing 
message from the pilot. Subsequently, without explicitly 
interacting with the teammates, the navigator needs to make a 
binary decision about whether what they see is a target 
waypoint; the two probable answers are yes (1) or no (0). Fig. 
3 shows (a) and (b) scenarios that can take place during the 
comprehension and projection levels of SA for the navigator. 
First, the navigator could think about the pilotâ€™s possible 
decision, yes (1) or no (0), and then the photographerâ€™s. Second, 
the navigator could think about the photographerâ€™s possible 
decision, then the pilotâ€™s. Consequently, the navigator has eight 
mental paths to follow (Fig. 3a and b). 
 
Fig. 3. Situation awareness for the navigator. Figures show the comprehension 
and projection levels after perception elements occur. Comprehension and 
projection depict possible thought processes while the navigator thinks about A 
(pilot) and B (photographer) possible decisions. The difference between (a) and 
(b) is in the order of thought processes in comprehension and projection. Each 
consists of four possible paths to deciding yes (1). 
For example, the navigator could comprehend and project a 
yes (1) decision by assuming that the pilotâ€™s possible decision 
would be yes (1), and the photographerâ€™s possible decision 
would be no (0) (the navigator thinks in the following order: 
pilot (navigator assumes pilot would say yes) â†’ photographer 
(navigator assumes photographer would say no) â†’ navigator 
(decides yes)); this is the path shown with solid lines (1 â†’0 â†’
1) in Fig. 3a. In the case of having no explicit interaction, the 
followed mental path could be any of the eight possible mental 
paths; hence, interference effects [32] can emerge. Since 
interference effects allude to the fluctuation of the navigator's 
mental state, depending on the magnitude of the vacillation, the 
navigator may experience a higher intrinsic (ontic [33], [37], 
[38]) type of uncertainty. This mental path dependency alludes 
to a salient contribution of interactive team cognition theory 
[53]. Well-coordinated optimal interactions among teammates 
can divulge the mental decision path in the task environment. 
In doing so, any interference effect is circumvented. However, 
delaying or skipping an interaction could engender uncertainty; 
in return, emerging uncertainty would negatively influence the 
team's stability. Therefore, interference effects need to be 
checked/ monitored in the RPAS study.   
This paper used the framework developed by the studies of 
[32], [44] to apply Bellâ€™s temporal inequality test in the 
quantum cognition model to check the existence of interference 
effects. This framework identifies three measurement points: 
information (I), negotiation (N), and feedback (F) from the 
RPAS study. A â€œ1â€ at time t1 means a positive perception of the 
target, so the navigator tells the photographer to take a picture 
of the target. A â€œ-1â€ at time t1 means a negative perception (no 
target) of the target in the shared information. Three conditions 
were described and were coded as â€œ1â€ or â€œ0â€, as shown in 
TABLE 2. Condition 1, C1, compares the two interaction points, 
t1, and t2; if both are 1, then C1 gets a 0 value because a 0 value 
demonstrates that there is no perceptual change between the 
two-time points. Condition 2, C2, compares the time points t2 
and t3; condition 3, C3, compares the points t1 and t3. After 
coding all of the three conditions, we built a joint probability 
table for the 8 possible events; these are p(1,1,1), p(1,1,-1), p(1,-
1,1), p(1,-1,-1), p(-1,1,1), p(-1,1,-1), p(-1,-1,1) and p(-1,-1,-1).  
TABLE 2. CODING SCHEMA, PROBABILITY DECISION TRAJECTORIES 
 
t1 
t2 
t3  
Condition(C) 
No 
I 
N 
F 
Joint Prob 
C1 
C2 
C3 
1 
1 
1 
1 
0.22333685 
0 
0 
0 
2 
1 
1 
-1 
0.13463569 
0 
1 
1 
3 
1 
-1 
1 
0.08183738 
1 
1 
0 
4 
1 
-1 
-1 
0.16156283 
1 
0 
1 
5 
-1 
1 
1 
0.16578669 
1 
0 
1 
6 
-1 
1 
-1 
0.08553326 
1 
1 
0 
7 
-1 
-1 
1 
0.08078141 
0 
1 
1 
8 
-1 
-1 
-1 
0.06652587 
0 
0 
0 
To use the temporal Bellâ€™s inequality test, the total 
probabilities are summed for each row in TABLE 2 for each 
condition. After that, by multiplying the column score (0 or 1, 
as shown in TABLE 2) by the corresponding joint probability 
and summing the rows in each column, the total probability of 
a difference for each column condition is obtained, p(D|C1), 
p(D|C2), and p(D|C3) in TABLE 3.    
TABLE 3. BELLâ€™S TEMPORAL INEQUALITY TEST 
Difference Probability 
Bell inequality test 
p(D|C1) 
p(D|C2) 
p(D|C3) 
p(D|C1)+p(D|C2)>=p(C3) 
0.4947 
0.3828 
0.54277 
0.4947+0.3828 > 0.54277 
P(D|C1) = p(1,-1,1) + p(1,-1,-1) + p(-1,1,1) + p(-1,1,-1) 
P(D|C2) = p(1,1,-1) + p(1,-1,1) + p(-1,1,-1) + p(-1,-1,1) 
P(D|C3) = p(1,1,-1) + p(1,-1,-1) + p(-1,1,1) + p(-1,-1,1) 
The Bellâ€™s inequality test shown in TABLE 3 indicates that if 
the sum of the probability of a change from time t1 to t2 and 
from time t2 to t3 is greater than or equal to the probability of a 
change from time t1 to t3 (p(D|C1)+p(D|C2) >= p(C3)). Classical 
dynamics are sufficient to explain the decision process; 
otherwise, interference effects should be used to explain the 
same decision processes.   
The proposed use of Bellâ€™s temporal inequality test provides 
a measurement/monitoring technique to distinguish the 
dominating dynamics. In this data set, Bellâ€™s inequality is not 
violated. This means that a single decision path was followed 
among the eight possible ones; interference effects were either 
circumvented or were negligible to influencing the teamâ€™s 
stability. Therefore, based on Bellâ€™s temporal inequality test 

7 
THMS-21-12-0464 
 
results, among two possible classes of models, using nonlinear 
dynamical systems modeling will be sufficient to monitor and 
track team dynamics. 
B. Nonlinear Dynamical Systems Modeling and Results 
Since the interference effects were not observed, the classical 
dynamic contribution to the Lyapunov exponent (Î») is 
comprehensive enough to model the dynamics of the RPAS 
study. First, we calculated Kappa (ğœ…) scores for each message 
sent and read times, and then we reconstructed attractors and 
calculated Î» exponents based on two types of ğœ… scores.  
1. Kappa Score. As team members interact, the variability in 
their repeated use of the Information (I) â€“ Negotiation (N) -
Feedback (F) sequence (specifically, the relationship between 
the timing of each of the three parts of the sequence) was used 
to compute a coordination score for each team at each target 
waypoint. Assuming that I, N, and F are the principal axes of 
the procedural model, a geometry-based measure of 
coordination was created (Fig. 4; [18]).  
 
 
Fig. 4. The intrinsic geometry coordination score, Kappa (ğœ…ğ‘–) [20]. 
These axes are related by a variable ğœ…, resulting from the 
normalization of the area around feedback per target. This was 
done to develop a distribution over the intrinsic procedural 
model geometry (Fig. 4). Because all three components are 
expressed in terms of time, their units cancel in the computation 
of ğœ…, making it a unitless quantity. ğœ… also describes two 
qualitatively different states: uncoordinated (ğœ… < 1) and 
coordinated (ğœ… > 1). In uncoordinated teams, either N precedes 
I, or F precedes either I, N, or both. When N occurs before I, it 
indicates that there is a backlog of information. In contrast, 
well-coordinated teams follow the I, N, and F procedural model 
sequentially. Larger values of ğœ… indicate that the I component 
is established well in advance of the target approach [12]. ğœ… 
score was calculated for each target message sent time (ğœ…-sent; 
i.e., teammate perception) and the message read time (ğœ…-read; 
i.e., teammate comprehension). 
Fig. 5 depicts examples of ğœ… scores for each condition across 
the five missions. Team interaction dynamics change based on 
the roadblock target waypoints (shown by red vertical arrows) 
and routine target waypoints and across the conditions. For 
instance, though teams in the synthetic and control conditions 
rarely changed their coordination, those in the experimenter 
condition demonstrated more coordination changes (K) 
between roadblock and routine target waypoints. This indicates 
that the experimenter condition teams demonstrated relatively 
more exploration in their coordination, especially during 
roadblocks. This can be seen in the figure where changes in K 
coincide with where the red arrows are on the target's axis. 
Notably, the experimenter team completed more targets than 
the other two conditions. This is an interesting overlap with the 
findings in [43], which argues that a controlled sequence of 
interactions by machine teammates can reduce interference 
effects, demonstrating stability in HMTs. 
 
Fig. 5. Kappa (ğœ…) scores for (a) synthetic, (b) control, and (3) experimenter 
conditions. Red vertical arrows indicate roadblock target waypoints.  
To examine how kappa scores differ across conditions and 
types (ğœ…-sent and ğœ…-read), we performed a one-way 
Multivariate Analysis of Variance (MANOVA) with the 
condition as a between-subjects variable. Accordingly, a Boxâ€™s 
M value of 874.52 was associated with a p-value of .0001. Thus, 
the covariance matrices between the groups were not assumed 
to be equal for the MANOVA, and we used Pillaiâ€™s Trace (V). 
Results showed a significant difference in ğœ… scores, F (4, 2156) 
= 3.52, p = .007; Pillai's V = 0.013, ğœ‚ğ‘
2 = 0.006. A subsequent 
test of between-subject effects indicates that while there was a 
significant condition main effect on kappa score based on the 
t(I) = Information sent/ read time 
t(N) = Negotiation sent/ read time 
t(F) = Feedback sent/ read time 

8 
THMS-21-12-0464 
 
message sent time, F (2, 1078) = 5.95, p = .003, ğœ‚ğ‘
2 = 0.011, 
there was no significant difference between the conditions in ğœ… 
score based on message read time, F (2, 1078) = 2.16, p = .116, 
ğœ‚ğ‘
2 = 0.004. Further analysis of the significant condition main 
effect of ğœ…-sent showed that synthetic and experimenter 
conditions had a significantly higher ğœ… score than the control 
conditions (p = 0.010, p = 0.001, respectively; Fig. 6). On the 
other hand, ğœ…-read findings indicate that only the experimenter 
condition was significantly higher than the control condition (p 
= 0.038). We interpret these findings as indicating that teams in 
the experimenter condition demonstrated greater agility than 
teams in the other two conditions. In contrast, the example team 
in the synthetic condition (Fig. 6) demonstrated a similar 
pattern of interaction dynamics as the experimenter condition 
in perception level (i.e., ğœ…-sent). The synthetic team did not 
catch the same level as the experimenter teams in 
comprehension level (i.e., ğœ…-read). The discussion section 
discusses these findings more from the exploration and 
exploitation perspective based on the statistical perspective.  
 
Fig. 6. Mean Kappa (ğœ…) scores across conditions and Kappa type (+/- Error bars 
refer to 95% Confidence Intervals-CIs).  
2. Attractor Reconstruction and Stability Analysis. We 
characterized teamsâ€™ coordination dynamics by applying 
attractor reconstruction on Ğº score time series at the team level 
[18], [54]. This is followed by stability analysis (Î» exponents) 
for each coordination order parameter Ğº at the team level. In 
attractor reconstruction visualization, based on Takenâ€™s 
theorem [55], one can recover a systemâ€™s dynamical structure 
(i.e., reconstruct the attractor) from a one-dimensional signal (in 
this study, this signal is the Îº time series) and a set of 
independent, time-delayed versions of itself. The reconstructed 
attractor exposes the dynamical structure that produced the 
patterns observed in the original one-dimensional signal. The 
attractor was reconstructed for each teamâ€™s Îº series by first 
estimating two embedding parameters: the optimal time delay 
(ğœ) and the embedding dimension (m) [54], [56]. Ï„ identifies the 
lag for which the original signal is maximally different from 
itself. These lagged versions are then used as the dimensions 
(m) in the phase space to unfold the signal. Following standard 
practice, ğœ was estimated as the first minimum of the Average 
Mutual Information function [54], [56]. The selection of m 
followed the False Nearest Neighbors (FNN) method outlined 
in [56]. This process surveys data points and neighbors in 
dimensions ranging within spaces of increasing dimensions. 
The goal is to find â€œfalse neighbors,â€ points that separate when 
examined in a higher dimension. Per convention, m was 
determined as the lowest dimension where the percentage of 
false neighbors â‰¤ 10 [10].  
We also examined team coordination stability from the 
reconstructed attractors by estimating the largest Lyapunov 
exponent (Î») for each ğœ…-sent and ğœ…-read time. The Î» measures 
the exponential rate of divergence of two nearby trajectories on 
the attractor [56], [57]: stable (Î»1 < 0), unstable (Î»1 > 0), and 
metastable or parallel trajectories (Î»1 â‰ˆ 0) of team coordination 
[58]. The magnitude of Î» relates to the speed with which a 
dynamic system reaches an equilibrium point, stable or 
unstable. A system with large negative Î» reaches an equilibrium 
state quickly and will have difficulty moving away from it (i.e., 
the system becomes rigid), while a system with large positive Î» 
will quickly become unstable, leading to a breakdown in 
communication coordination and, perhaps, a jeopardized 
mission. Systems with Î» close to zero will begin to meander, 
stabilize (if Î» is negative), or meander and destabilize (if Î» is 
positive). Systems that exhibit either of these metastable 
situations can be said to be agile and, thus, are likely to perform 
well [59].  
To examine how the Î» exponents differ across conditions 
and Î» exponent types (i.e., Î» exponent based on ğœ…-sent and Î» 
exponent based on ğœ…-read), a one-way MANOVA was 
conducted with the condition as a between-subject variable. 
Accordingly, the Boxâ€™s M value of 12.00 was associated with 
a p-value of .100, which was interpreted as non-significant 
based on Huberty and Petoskeyâ€™s (2000) guideline [60]. Thus, 
the covariance matrices between the groups were assumed to be 
equal for the MANOVA. Results showed a statistically 
significant difference in ğœ… scores based on condition, F (4, 50) 
= 0.42, p < .0001; Wilk's Î› = 0.42, ğœ‚ğ‘
2 = 0.35. Test of between-
subject effects indicates that there were significant condition 
main effects on both of the Lyapunov exponents based on ğœ…-
sent F (2, 26) = 6.10, p = .007, ğœ‚ğ‘
2 = 0.319, and based on ğœ…-
read, F (2, 26) = 15.82, p < .0001, ğœ‚ğ‘
2 = 0.549.  
According to the significant condition main effect of the Î» 
exponent based on ğœ…-sent, teams in the synthetic condition had 
a significantly lower Î» exponent than the control (p = 0.049) and 
experimenter conditions (p = 0.002; Fig. 7). On the other hand, 
Î» exponents based on ğœ…-read findings indicate that the synthetic 
condition was significantly lower than the control (p = 0.001) 
and experimenter conditions (p < 0.0001). We also report a non-
significant result indicating that teams in the experimenter 
condition had marginally higher ğœ…-read Î» exponents than those 
in the control condition (p = 0.054). Altogether, these findings 
show that teams in the experimenter condition demonstrated 
higher instability than those in the synthetic and control 
conditions. Furthermore, these show that synthetic condition 
teams demonstrated more rigid dynamics than other conditions 
in the perception (Î»-based on ğœ…-sent) and comprehension levels 
(Î»-based on ğœ…-read).  
The question is how coordination stability is associated with 
the target performance score. To answer this question, we 
applied multiple regression analysis with which the model 
accounted for 13.6% of the variance, F(2, 26) = 3.20, p = 0.057. 
According to the regression findings, while Î» exponent based 
on the Kappa-read significantly predicted the target 
performance, ï¢ = 0.49, t(28) = 2.26, p = 0.033, Î» exponent 
based on ğœ…-sent time did not have any significant relationship 

9 
THMS-21-12-0464 
 
with the target performance score, ï¢ = -0.08, t(28) = -0.37, p = 
0.713. Overall, these findings show that during the Level 2 SA, 
comprehension, team coordination instability positively 
impacted team performance in taking target photos, while the 
Level 1 SA, perception of coordination, did not have any 
impact.       
 
 
Fig. 7. Mean Lyapunov exponent across condition and Lyapunov type (+/- 
Error bars refer to 95% CIs). 
V. DISCUSSION AND CONCLUSION 
In this study, we defined team agility as a function of 
exploration and exploitation of team coordination. Based on 
these two coordination concepts, we examined interactive 
decision-making in an RPAS task environment by applying: (1) 
the principles of quantum cognition to distinguish the 
dominating dynamics to choose the most appropriate model; (2) 
NDS modeling for teamwork (to capture epistemic uncertainty).  
A. Quantum Dynamics of Team Agility 
 
Quantum cognition does not ascribe any quantum-ness to a 
team or the mind. Quantum models can capture the contextual 
dynamics of sequential decision-making in complex situations. 
For example, order effects are critical for team agility because 
exploration and exploitation may require a different 
combination of sequential team communication; for instance, 
as in uncoordinated teams, either N precedes I or F precedes 
either I, N, or both. These can give rise to order effects due to 
interference effects; by using quantum cognition principles, the 
RPAS data was tested for interference effects. This was the first 
application of the Bell inequality test to a team study data, and 
the interpretation of the results is as follows. First, having no 
interference effects implies that teamsâ€™ communication and 
coordination were effective. Second, robust and resilient team 
cognition was obtained due to the training, and team stability 
was sustained even during the perturbation period. Third, the 
Bell inequality test can be used to test/monitor/determine 
effective communication and coordination strategies to avoid 
human cognitive biases while expediting human adaptation to a 
complex situation. This systemic analysis is critical to team 
cognition because interaction among team members is the only 
way to reduce the ontic type uncertainty to a negligible level in 
time-constraint situations [61]. Higher ontic uncertainty (as a 
result of interference effects) due to incomplete teamwork can 
impede agility because it can give rise to taskwork uncertainty. 
Team agility is an emergent quality from all these interactive 
processes in response to the task environment (i.e., task-
dependent). This is promising because facing complexity as an 
agile team requires using heuristics [62], and using quantum 
cognition can provide agility strategies that do not give rise to 
instability [38][43].   
B. Nonlinear Dynamical Systems Modeling on Team Agility 
When the primary source of uncertainty is epistemic 
uncertainty, teamsâ€™ coordination dynamics fluctuate during 
teamwork on specific targets based on the ğœ… score. This 
fluctuation is especially prominent for teams in the experimenter 
condition than those in the other two conditions, particularly 
during roadblock targets. This indicates that when teams in the 
experimenter condition come across the targets, they tend to 
explore alternatives by coordinating as a team rather than 
exploiting existing team strategies that may not work best for the 
situation at hand. In contrast, teams in control and synthetic 
conditions tended more towards exploitation than exploration in 
coordination. We consider this a sign of agility in teamwork. The 
differences in the level of exploitation for synthetic teams with 
respect to those in other conditions between stages of the INF 
process indicate that teams demonstrated different dynamics in 
different levels of team situation awareness (at least for the 
perception and comprehension level). As argued earlier, a 
controlled sequence of interactions by synthetic teammates can 
ensure convergence to available options (exploitations) with a 
very high probability, and HMTs demonstrate stability  [43].  
We also demonstrated that measuring Î» exponents at both the 
perception (Î»-sent) and comprehension levels (Î»-read) allows for 
a more in-depth analysis of team agility as a construct. Overall 
findings of this approach show that teams in the experimenter 
condition demonstrated more instability than those in the other 
two conditions, especially during the comprehension level, and 
this helped experimenter teams to perform better in teamwork. 
This finding supports that the ability to transition into 
explorative coordination is related to relative instability in 
coordination dynamics.  
In conclusion, team agility requires more exploration in 
coordination dynamics and exploitation to adapt to the dynamic 
task and teamwork requirements. The level of exploration and 
exploitation changes in the perception and comprehension level 
of the team situation awareness. Future studies are suggested 
using the same methods for the projection level of SA. 
ACKNOWLEDGMENT 
This research is partially supported by ONR Award N000141712382 and 
ONR - CRUSER Award N00244-18-S-NPS-F001. 
REFERENCES 
[1] 
I. Asimov and J. M. Cote, Futuredays: A Nineteenth Century Vision of 
the Year 2000, 1st American ed edition. New York, NY: Henry Holt & 
Co, 1986. 
[2] 
S. P. Franklin, Artificial Minds, New edition. Cambridge, Mass.: A 
Bradford Book, 1997. 
[3] 
M. Demir, N. J. McNeese, and N. J. Cooke, â€œTeam situation awareness 
within the context of human-autonomy teaming,â€ Cognitive Systems 
Research, 
vol. 
46, 
pp. 
3â€“12, 
Dec. 
2017, 
doi: 
10.1016/j.cogsys.2016.11.003. 
[4] 
M. Demir, N. J. McNeese, and N. J. Cooke, â€œUnderstanding human-
robot teams in light of all-human teams: Aspects of team interaction 
and shared cognition,â€ International Journal of Human-Computer 
Studies, vol. 140, Aug. 2020, doi: 10.1016/j.ijhcs.2020.102436. 
[5] 
M. Novitzky, H. R. R. Dougherty, and M. R. Benjamin, â€œA Human-
Robot Speech Interface for an Autonomous Marine Teammate,â€ in 

10 
THMS-21-12-0464 
 
Social Robotics, Cham, 2016, pp. 513â€“520. doi: 10.1007/978-3-319-
47437-3_50. 
[6] 
S. M. Fiore and T. J. Wiltshire, â€œTechnology as Teammate: Examining 
the Role of External Cognition in Support of Team Cognitive 
Processes,â€ 
Front 
Psychol, 
vol. 
7, 
Oct. 
2016, 
doi: 
10.3389/fpsyg.2016.01531. 
[7] 
S. W. J. Kozlowski and G. T. Chao, â€œThe Dynamics of Emergence: 
Cognition and Cohesion in Work Teams,â€ Manage. Decis. Econ., vol. 
33, no. 5â€“6, pp. 335â€“354, Jul. 2012, doi: 10.1002/mde.2552. 
[8] 
S. J. Guastello, â€œNonlinear Dynamics of Team Performance and 
Adaptability in Emergency Response,â€ Hum Factors, vol. 52, no. 2, pp. 
162â€“172, Apr. 2010, doi: 10.1177/0018720809359003. 
[9] 
S. J. Guastello, D. E. Marra, J. Castro, M. Gomez, and C. Perna, 
â€œPerformance and Participation Dynamics in an Emergency Response 
Simulation,â€ Nonlinear Dynamics Psychol Life Sci, vol. 21, no. 2, pp. 
217â€“250, Apr. 2017. 
[10] 
M. Demir, N. J. Cooke, and P. G. Amazeen, â€œA conceptual model of 
team dynamical behaviors and performance in human-autonomy 
teaming,â€ Cognitive Systems Research, vol. 52, pp. 497â€“507, Dec. 
2018, doi: 10.1016/j.cogsys.2018.07.029. 
[11] 
M. Demir, N. J. McNeese, and N. J. Cooke, â€œTeam communication 
behaviors of the human-automation teaming,â€ in 2016 IEEE 
International Multi-Disciplinary Conference on Cognitive Methods in 
Situation Awareness and Decision Support (CogSIMA), Mar. 2016, pp. 
28â€“34. doi: 10.1109/COGSIMA.2016.7497782. 
[12] 
M. Demir, A. D. Likens, N. J. Cooke, P. G. Amazeen, and N. J. 
McNeese, â€œTeam Coordination and Effectiveness in Human-Autonomy 
Teaming,â€ IEEE Transactions on Human-Machine Systems, pp. 1â€“10, 
2019, doi: 10.1109/THMS.2018.2877482. 
[13] 
M. Demir, N. J. McNeese, J. C. Gorman, N. J. Cooke, C. W. Myers, 
and D. A. Grimm, â€œExploration of Team Trust and Interaction 
Dynamics in Human-Autonomy Teaming,â€ IEEE Transactions on 
Human-Machine Systems, 2021. 
[14] 
C. Heath and R. Gonzalez, â€œInteraction with Others Increases Decision 
Confidence but Not Decision Quality: Evidence against Information 
Collection Views of Interactive Decision Making,â€ Organizational 
Behavior and Human Decision Processes, vol. 61, no. 3, pp. 305â€“326, 
Mar. 1995, doi: 10.1006/obhd.1995.1024. 
[15] 
J. G. March and Z. Shapira, â€œVariable risk preferences and the focus of 
attention,â€ Psychological Review, vol. 99, no. 1, pp. 172â€“183, 1992, 
doi: 10.1037/0033-295X.99.1.172. 
[16] 
G. Lematta, â€œExploratory Team Cognition and Resilience in Human 
Agent Teaming,â€ M.S., Arizona State University, United States -- 
Arizona, 2019. Accessed: May 09, 2021.  
[17] 
N. J. Cooke, J. C. Gorman, C. W. Myers, and J. L. Duran, â€œInteractive 
Team Cognition,â€ Cogn. Sci., vol. 37, no. 2, pp. 255â€“285, Mar. 2013, 
doi: 10.1111/cogs.12009. 
[18] 
J. C. Gorman, P. G. Amazeen, and N. J. Cooke, â€œTeam coordination 
dynamics.,â€ Nonlinear Dynamics Psychol Life Sci, vol. 14, no. 3, pp. 
265â€“289, Jul. 2010. 
[19] 
A. D. Likens, P. G. Amazeen, R. Stevens, T. Galloway, and J. C. 
Gorman, â€œNeural signatures of team coordination are revealed by 
multifractal analysis,â€ Social Neuroscience, vol. 9, no. 3, pp. 219â€“234, 
May 2014, doi: 10.1080/17470919.2014.882861. 
[20] 
J. C. Gorman, N. J. Cooke, P. G. Amazeen, and S. Fouse, â€œMeasuring 
Patterns in Team Interaction Sequences Using a Discrete Recurrence 
Approach,â€ Human Factors: The Journal of the Human Factors and 
Ergonomics Society, vol. 54, no. 4, pp. 503â€“517, Aug. 2012, doi: 
10.1177/0018720811426140. 
[21] 
P. J. Ramos-Villagrasa, P. Marques-Quinteiro, J. Navarro, and R. Rico, 
â€œTeams as Complex Adaptive Systems: Reviewing 17 Years of 
Research,â€ Small Group Research, vol. 49, no. 2, pp. 135â€“176, Apr. 
2018, doi: 10.1177/1046496417713849. 
[22] 
S. J. Guastello, â€œNonlinear dynamical systems for theory and research 
in ergonomics,â€ Ergonomics, vol. 60, no. 2, pp. 167â€“193, Feb. 2017, 
doi: 10.1080/00140139.2016.1162851. 
[23] 
T. J. Wiltshire, J. E. Butner, and S. M. Fiore, â€œProblem-Solving Phase 
Transitions During Team Collaboration,â€ Cogn Sci, p. n/a-n/a, Feb. 
2017, doi: 10.1111/cogs.12482. 
[24] 
J. Gorman, P. Amazeen, and N. Cooke, â€œTeam Coordination 
Dynamics,â€ Nonlinear dynamics, psychology, and life sciences, vol. 14, 
pp. 265â€“89, Jul. 2010. 
[25] 
L. D. Riek, â€œWizard of Oz Studies in HRI: A Systematic Review and 
New Reporting Guidelines,â€ J. Hum.-Robot Interact., vol. 1, no. 1, pp. 
119â€“136, Jul. 2012, doi: 10.5898/JHRI.1.1.Riek. 
[26] 
M. Demir, N. J. McNeese, and N. J. Cooke, â€œThe Evolution of Human-
Autonomy Teams in Remotely Piloted Aircraft Systems Operations,â€ 
Front. Commun., vol. 4, 2019, doi: 10.3389/fcomm.2019.00050. 
[27] 
L. Huang et al., â€œChapter 13 - Distributed dynamic team trust in human, 
artificial intelligence, and robot teaming,â€ in Trust in Human-Robot 
Interaction, C. S. Nam and J. B. Lyons, Eds. Academic Press, 2021, pp. 
301â€“319. doi: 10.1016/B978-0-12-819472-0.00013-7. 
[28] 
N. J. McNeese, M. Demir, E. K. Chiou, and N. J. Cooke, â€œTrust and 
Team Performance in Humanâ€“Autonomy Teaming,â€ International 
Journal of Electronic Commerce, vol. 25, no. 1, pp. 51â€“72, Jan. 2021, 
doi: 10.1080/10864415.2021.1846854. 
[29] 
N. Tenhundfeld, M. Demir, and E. J. de Visser, â€œAn Argument for Trust 
Assessment in Human-Machine Interaction: Overview and Call for 
Integration.â€ OSF Preprints, Jan. 11, 2021. doi: 10.31219/osf.io/j47df. 
[30] 
Y. Hu, Y. Pan, X. Shi, Q. Cai, X. Li, and X. Cheng, â€œInter-brain 
synchrony and cooperation context in interactive decision making,â€ 
Biological Psychology, vol. 133, pp. 54â€“62, Mar. 2018, doi: 
10.1016/j.biopsycho.2017.12.005. 
[31] 
A. N. Kolmogorov, A. T. Bharucha-Reid, and N. Morrison, 
Foundations of the theory of probability, Second English edition, Dover 
edition. Muneola, New York: Dover Publications, Inc, 2018. 
[32] 
J. R. Busemeyer and P. D. Bruza, Quantum models of cognition and 
decision. Cambridge: Cambridge university press, 2012. 
[33] 
J. Busemeyer, Q. Zhang, S. N. Balakrishnan, and Z. Wang, 
â€œApplication of Quantumâ€”Markov Open System Models to Human 
Cognition and Decision,â€ Entropy, vol. 22, no. 9, p. 990, Sep. 2020, 
doi: 10.3390/e22090990. 
[34] 
J. M. Yearsley, â€œAdvanced tools and concepts for quantum cognition: 
A tutorial,â€ Journal of Mathematical Psychology, vol. 78, pp. 24â€“39, 
Jun. 2017, doi: 10.1016/j.jmp.2016.07.005. 
[35] 
D. Aerts, â€œQuantum structure in cognition,â€ Journal of Mathematical 
Psychology, vol. 53, no. 5, pp. 314â€“348, Oct. 2009, doi: 
10.1016/j.jmp.2009.04.005. 
[36] 
M. Canan and A. Sousa-Poza, â€œPragmatic Idealism: Towards a 
Probabilistic Framework of Shared Awareness in Complex Situations,â€ 
in 2019 IEEE Conference on Cognitive and Computational Aspects of 
Situation Management (CogSIMA), 2019, pp. 114â€“121. 
[37] 
P. D. Kvam, J. R. Busemeyer, and T. J. Pleskac, â€œTemporal oscillations 
in preference strength provide evidence for an open system model of 
constructed preference,â€ Sci Rep, vol. 11, no. 1, p. 8169, Dec. 2021, 
doi: 10.1038/s41598-021-87659-0. 
[38] 
P. D. Kvam and T. J. Pleskac, â€œA quantum information architecture for 
cue-based heuristics.,â€ Decision, vol. 4, no. 4, pp. 197â€“233, Oct. 2017, 
doi: 10.1037/dec0000070. 
[39] 
V. I. Yukalov, E. P. Yukalova, and D. Sornette, â€œInformation 
processing by networks of quantum decision makers,â€ Physica A: 
Statistical Mechanics and its Applications, vol. 492, pp. 747â€“766, Feb. 
2018, doi: 10.1016/j.physa.2017.11.004. 
[40] 
V. I. Yukalov, â€œEvolutionary Processes in Quantum Decision Theory,â€ 
Entropy, vol. 22, no. 6, p. 681, Jun. 2020, doi: 10.3390/e22060681. 
[41] 
V. I. Yukalov and E. P. Yukalova, â€œTemporal dynamics in perturbation 
theory,â€ Physica A: Statistical Mechanics and its Applications, vol. 
225, no. 3â€“4, pp. 336â€“362, 1996, doi: 10.1016/0378-4371(95)00471-8. 
[42] 
M. R. Endsley, â€œToward a theory of situation awareness in dynamic 
systems,â€ Human factors, vol. 37, no. 1, pp. 32â€“64, 1995, doi: 
10.1518/001872095779049499. 
[43] 
L. Snow, S. Jain, and V. Krishnamurthy, â€œLyapunov based Stochastic 
Stability of Human-Machine Interaction: A Quantum Decision System 
Approach,â€ arXiv:2204.00059 [cs, econ, eess, q-fin], Mar. 2022, 
Accessed: Apr. 12, 2022.  
[44] 
H. Atmanspacher and T. Filk, â€œA proposed test of temporal nonlocality 
in bistable perception,â€ Journal of Mathematical Psychology, vol. 54, 
no. 3, pp. 314â€“321, Jun. 2010, doi: 10.1016/j.jmp.2009.12.001. 
[45] 
N. J. Cooke and S. M. Shope, â€œDesigning a Synthetic Task 
Environment,â€ in Scaled Worlds: Development, Validation, and 
Application, L. R. E. Schiflett, E. Salas, and M. D. Coovert, Eds. 
Surrey, England: Ashgate Publishing, 2004, pp. 263â€“278.  
[46] 
J. R. Anderson, How can the human mind occur in the physical 
universe? Oxford; New York: Oxford University Press, 2007. 
[47] 
M. Demir, N. J. McNeese, N. J. Cooke, J. T. Ball, C. Myers, and M. 
Freiman, â€œSynthetic Teammate Communication and Coordination with 
Humans,â€ in Proceedings of the Human Factors and Ergonomics 
Society Annual Meeting, Sep. 2015, vol. 59, pp. 951â€“955. doi: 
10.1177/1541931215591275. 

11 
THMS-21-12-0464 
 
[48] 
M. Demir, N. J. McNeese, N. J. Cooke, and C. Myers, â€œThe Synthetic 
Teammate as a Team Player in Command-and-Control Teams,â€ in 
Proceedings of the Human Factors and Ergonomics Society Annual 
Meeting, 
Sep. 
2016, 
vol. 
60, 
pp. 
116â€“116. 
doi: 
10.1177/1541931213601026. 
[49] 
N. J. McNeese, M. Demir, N. J. Cooke, and C. Myers, â€œTeaming With 
a Synthetic Teammate: Insights into Human-Autonomy Teaming,â€ 
Hum 
Factors, 
vol. 
60, 
no. 
2, 
pp. 
262â€“273, 2018, 
doi: 
10.1177/0018720817743223. 
[50] 
J. Ball et al., â€œThe synthetic teammate project,â€ Comput Math Organ 
Theory, vol. 16, no. 3, pp. 271â€“299, Sep. 2010, doi: 10.1007/s10588-
010-9065-3. 
[51] 
S. G. Hart and L. E. Staveland, â€œDevelopment of NASA-TLX (Task 
Load Index): Results of empirical and theoretical research,â€ in Human 
Mental Workload, P. A. Hancock and N. Mashkati, Eds. Amsterdam: 
North Holland Press, 1988, pp. 139â€“183. 
[52] 
N. J. Cooke et al., â€œAcquisition and Retention of Team Coordination in 
Command-and-Control,â€ Jul. 2007. Accessed: Jan. 22, 2015. [Online]. 
Available: http://www.dtic.mil/docs/citations/ADA475567 
[53] 
N. J. Cooke, J. C. Gorman, C. W. Myers, and J. L. Duran, â€œInteractive 
Team Cognition,â€ Cognitive Science, vol. 37, no. 2, pp. 255â€“285, Mar. 
2013, doi: 10.1111/cogs.12009. 
[54] 
H. Abarbanel, Analysis of Observed Chaotic Data, 1st edition. Berlin; 
Heidelberg u.a.: Springer, 1996. 
[55] 
F. Takens, â€œDetecting strange attractors in turbulence,â€ in Dynamical 
Systems and Turbulence, Lecture Notes in Mathematics, vol. 898, D. A. 
Rand and L. S. Young, Eds. Springer-Verlag, 1981, pp. 230â€“242. 
Accessed: Mar. 17, 2017.  
[56] 
M. T. Rosenstein, J. J. Collins, and C. J. De Luca, â€œA practical method 
for calculating largest Lyapunov exponents from small data sets,â€ 
Physica D: Nonlinear Phenomena, vol. 65, no. 1, pp. 117â€“134, May 
1993, doi: 10.1016/0167-2789(93)90009-P. 
[57] 
A. Wolf, J. B. Swift, H. L. Swinney, and J. A. Vastano, â€œDetermining 
Lyapunov exponents from a time series,â€ Physica D: Nonlinear 
Phenomena, vol. 16, no. 3, pp. 285â€“317, Jul. 1985, doi: 10.1016/0167-
2789(85)90011-9. 
[58] 
H. Kantz and T. Schreiber, Nonlinear Time Series Analysis, 2 edition. 
Cambridge, UKâ€¯; New York: Cambridge University Press, 2004. 
[59] 
J. A. S. Kelso, â€œThe Complementary Nature of Coordination Dynamics: 
Self-organization and Agency,â€ Nonlinear Phenomena in Complex 
Systems, vol. 5, no. 4, pp. 364â€“371, 2002. 
[60] 
C. J. Huberty and M. D. Petoskey, â€œMultivariate analysis of variance 
and covariance,â€ in Handbook of applied multivariate statistics and 
mathematical modeling, San Diego, CA, US: Academic Press, 2000, 
pp. 183â€“208. doi: 10.1016/B978-012691360-6/50008-2. 
[61] 
M. Canan and M. Demir, â€œAddressing Two Central Issues of Team 
Interaction Dynamics: the Whole is Greater than the Sum of Its Parts,â€ 
presented at the 12th International Conference on Applied Human 
Factors and Ergonomics (AHFE 2021), NY, NY, USA, Jul. 2021. 
[62] 
L. Biggiero, â€œSources of Complexity in Human Systems,â€ Nonlinear 
Dynamics, Psychology, and Life Sciences, vol. 5, no. 1, pp. 3â€“19, 2001, 
doi: 10.1023/A:1009515211632. 
 
 
 
 
View publication stats

