
Springer Texts in Statistics 
Advisors: 
Stephen Fienberg Ingram Olkin 

Springer Texts in Statistics 
Alfred 
Berger 
Blom 
Chow and Teicher 
Christensen 
Christensen 
Christensen 
Creighton 
Elements of Statistics for the Life and Social 
Sciences 
An Introduction to Probability and Stochastic 
Processes 
Probability and Statistics: Theory and 
Applications 
Probability Theory: Independence, 
Interchangeability, Martingales, Second Edition 
Plane Answers to Complex Questions: The 
Theory of Linear Models 
Linear Models for Multivariate, Time Series, 
and Spatial Data 
Log-Linear Models 
A First Course in Probability Models and 
Statistical Inference 
du Toit, Steyn and Stump! 
Graphical Exploratory Data Analysis 
Finkelstein and Levin 
Statistics for Lawyers 
Jobson 
Applied Multivariate Data Analysis, Volume I: 
Regression and Experimental Design 
Jobson 
Applied Multivariate Data Analysis, Volume II: 
Categorical and Multivariate Methods 
Kalbfleisch 
Probability and Statistical Inference, Volume I: 
Probability, Second Edition 
Kalbfleisch 
Probability and Statistical Inference, Volume II: 
Statistical Inference, Second Edition 
Karr 
Probability 
Continued at end of book 

Christian P. Robert 
The Bayesian Choice 
A Decision-Theoretic Motivation 
Springer Science+ Business Media, LLC 

Christian P. Robert 
URA CNRS 1378 - Dept. de Math. 
Universite de Rouen 
76821 Mont Saint Aignan Cedex 
France 
Editorial Board 
Stephen Fienberg 
Department of Statistics 
Carnegie-Mellon University 
Pittsburgh, PA 15213 
USA 
Ingram Olkin 
Department of Statistics 
Stanford University 
Stanford, CA 94305 
USA 
On the cover: Three prior distributions on a binomial probability. 
With 10 Figures 
Library of Congress Cataloging-in-Publication Data 
Robert, Christian P., 1961-
[Analyse statistique bayesienne. English] 
The Bayesian choice: a decision-theoretic motivation/Christian 
P. Robert 
p. cm. - (Springer texts in statistics) 
Includes bibliographical references and index. 
ISBN 978-1-4757-4316-6 
ISBN 978-1-4757-4314-2 (eBook) 
DOl 10.1007/978-1-4757-4314-2 
1. Bayesian statistical decision theory. 
I. Title. 
II. Series. 
QA279.5.R6313 
1994 
519.5' 42-dc20 
94-10781 
Printed on acid-free paper. 
© 1994 Springer Science+ Business Media N ew York 
Originally published by Springer-Verlag New York, Inc. in 1994 
Softcover reprint of the hardcover 1st edition 1994 
All rights reserved. This work may not be translated or copied in whole or in part without the 
written permission of the publisher Springer Science+ Business Media, ILC , 
except for brief excerpts in connection with reviews or scholarly 
analysis. Use in connection with any form of information storage and retrieval, electronic 
adaptation, computer software, or by similar or dissimilar methodology now known or hereaf-
ter developed is forbidden. 
The use of general descriptive names, trade names, trademarks, etc., in this publication, even 
if the former are not especially identified, is not to be taken as a sign that such names, as 
understood by the Trade Marks and Merchandise Marks Act, may accordingly be used freely 
by anyone. 
Production managed by Francine McNeill; manufacturing supervised by Gail Simon. 
Photocomposed pages prepared using Springer-Verlag's "svpJain" TeX macro. 
987654321 
ISBN 978-1-4757-4316-6 

To my reference prior, 
Brigitte 

Preface 
From where we stand, the rain seems random. 
If we could stand somewhere else, we would see the order in it. 
-
T. Hillerman (1990) Coyote Waits. Harper-Collins, New York. 
This book stemmed from a translation of a French version that was written 
to supplement the gap in the French statistical literature about Bayesian 
Analysis and Decision Theory. As a result, its scope is wide enough to 
cover the two years of the French graduate Statistics curriculum and, more 
generally, most graduate programs. This book builds on very little pre-
requisites in Statistics and only requires basic skills in calculus, measure 
theory, and probability. Intended as a preparation of Ph.D. students, this 
book goes far enough to cover advanced topics and modern developments of 
Bayesian Statistics (complete class theorems, the Stein effect, hierarchical 
and empirical modelings, Gibbs sampling, etc.). As usual, what started as 
a translation eventually ended up as a deeper revision, because of the com-
ments of French readers, of adjustments to the different needs of American 
programs, and also because my perception of things has slightly changed in 
the meantime. As a result, this new version is quite adequate for a general 
graduate audience of an American university. 
In terms of level and existing literature, this book starts at a level 
similar to those of the introductory books of Lee (1989) and Press (1989), 

Vlll 
Preface 
but it also goes further and keeps up with most of the recent advances in 
Bayesian Statistics, while motivating the theoretical appeal of the Bayesian 
approach on decision-theoretic justifications. Nonetheless, this book differs 
from the reference book of Berger (1985a) by including the more recent de-
velopments of the Bayesian field (the Stein effect for spherically symmetric 
distributions, multiple shrinkage, loss estimation, decision theory for testing 
and confidence regions, hierarchical developments, Bayesian computation, 
mixture estimation, etc.). Moreover, the style is closer to a textbook in the 
sense that the progression is intended to be linear. In fact, the exposition 
of the advantages of a Bayesian approach and of the existing links with 
other axiomatic systems (fiducial theory, maximum likelihood, frequentist 
theory, invariance, etc.) does not prevent an overall unity in the discourse. 
This should make the book easier to read by student audiences; through the 
years and on both sides ofthe blackboard(!), I found most Statistics courses 
disturbing, because a wide scope of methods was presented simultaneously 
with very little emphasis on ways of discriminating between competing ap-
proaches. In particular, students with a strong mathematical background 
are quite puzzled by this multiplicity of theories since they have not been 
exposed previously to conflicting systems of axioms. A unitarian presenta-
tion that includes other approaches as limiting cases is thus more likely to 
reassure the students while giving a broad enough view of Decision Theory 
and even of parametric Statistics. 
The plan of the book is as follows: Chapter 1 is an introduction to sta-
tistical models, including the Bayesian model and some connections with 
the Likelihood Principle. The book then proceeds with Chapter 2 on Deci-
sion Theory, considered from a classical point of view, this approach being 
justified through the axioms of rationality and the need to compare decision 
rules in a coherent way. It also includes a presentation of usual losses and 
a discussion of the Stein effect. Chapter 3 gives the corresponding analysis 
for prior distributions and deals in detail with conjugate priors, mixtures of 
conjugate priors, and noninformative priors, including a concluding section 
on prior robustness. Classical statistical models are studied in Chapter 4, 
paying particular attention to normal models and their relations with linear 
regression. This chapter also contains a section on sampling models that 
allows us to include the pedagogical example of capture-recapture models. 
Tests and confidence regions are considered separately in Chapter 5, since 
we present the usual construction through "0 - I" losses, but also include 
recent advances in the alternative decision-theoretic evaluations of testing 
problems. The second part of the book dwells on more advanced topics 
and can be considered as providing a basis for a more advanced graduate 
course. Chapter 6 covers complete class results and sufficient/necessary ad-
missibility conditions. Chapter 7 introduces the notion of invariance and 
its relations with Bayesian Statistics, including a heuristic section on the 
Hunt-Stein theorem. Hierarchical and empirical extensions of the Bayesian 
approach, including some developments on the Stein effect, are treated in 

Preface 
IX 
Chapter 8. Chapter 9 is rather appealing, considering the available litera-
ture, as it incorporates in a graduate textbook an introduction to state-of-
the-art computational methods (Laplace, Monte Carlo and, mainly, Gibbs 
sampling). In connection with this chapter, a short appendix provides the 
usual pseudorandom generators. Chapter 10 is a more personal conclusion 
on the advantages of Bayesian theory, also mentioning the most common 
criticisms of the Bayesian approach. French readers may appreciate that 
a lot of effort has been put into the exercises of each chapter in terms of 
volume and difficulty: They now range from very easy to difficult instead 
of being uniformly difficult! The most difficult exercises are indexed by 
asterisks and are usually derived from research papers (covering subjects 
such as spherically symmetric distributions (1.1), the Pitman nearness crit-
icism (2.55), marginalization paradoxes (3.48), multiple shrinkage (8.32), 
etc.). They should benefit most readers by pointing out new directions of 
Bayesian research and providing additional perspectives. 
A standard single-semester course should cover the first five chapters 
(with the possible omission of §2.4.5, §2.5.4, §2.6, §3.3, §4.3.4, §4.4.3, and 
§5.3). More advanced (or longer) courses can explore the material presented 
in Chapters 6, 7, and 8, bearing in mind that a detailed and rigorous treat-
ment of these topics requires additional reading of the literature mentioned 
in those chapters. In any case, I would advise against a complete bypass 
of Chapter 9. Even a simple reading of this chapter could be beneficial to 
most students, by illustrating the practical difficulties related to the com-
putation of Bayesian procedures and the corresponding answers brought by 
simulation methods. 
This book took many "excruciating" small steps and extorted a heavy 
toll on evenings, weekends, and vacations .... It is thus only a small indi-
cation of my gratitude that this book is dedicated to Brigitte (although 
she might take this as a propitiatory attempt for future books!!!). Many 
persons are to be thanked for the present version of this book. First and 
foremost, Jim Berger's "responsibility" can be traced back to 1987 when 
he invited me to Purdue University for a year and, as a result, consider-
ably broadened my vision of Statistics; he emphasized his case by insisting 
very vigorously that I translate the French version and urging me along 
the whole time. My gratitude to Jim goes very deep when I consider his 
strong influence in my "coming-of-age" as a statistician. Mary-Ellen Bock, 
Anirban Das Gupta, Edward George, Gene (formerly Jiunn) Hwang, and 
Marty Wells were also very "instrumental" in my progression towards the 
Bayesian choice, although they do not necessarily support this choice. In 
this regard, George Casella must be singled out for his strong influence 
through these years of intense collaboration and friendship, even during 
his most severe (and "unbearable") criticisms of the Bayesian paradigm! I 
am also quite grateful to Jean-Fran<;ois Angers, Dean Foster, and Giovanni 
Parmigiani for taking the risk of using a preliminary version of these notes 
in their courses, as well as for the resulting comments. Thanks to Teena 

x 
Preface 
Seele for guiding my first steps in TEX, as well as some delicate points in this 
book-never use \def as an abbreviation of definition! I am also grate-
ful to Elsevier North-Holland for granting me permission to use Diaconis 
and Ylvisaker's (1985) figures in §3.3. Last, and definitely not least, Kerrie 
Mengersen and Costas Goutis put a lot of time and effort going through a 
preliminary version and provided numerous and very helpful comments on 
content, style, and clarity, while adding a touch of Ausso-Greek accent to 
the tone. (In addition, Costas Goutis saved the subject index from utter 
destruction!) They are thus partially responsible for the improvements over 
previous versions (but obviously not for the remaining defects!), and I am 
most thankful to them for their essential help. 
Paris. France 
Christian P. Robert 

Contents 
Preface 
vii 
1. 
Introduction 
1 
1.1. Statistical Problems and Statistical Models 
1 
1.2. The Bayesian Paradigm as a Duality Principle 
7 
1.3. Likelihood Principle and Sufficiency Principle 
13 
1.4. Prior and Posterior Distributions 
21 
1.5. Improper Prior Distributions 
25 
1.6. The Bayesian Choice 
28 
Exercises 
29 
2. 
Decision-Theoretic Foundations of Statistical Inference 
2.1. Evaluating Estimators 
39 
39 
2.2. Existence of a Utility Function 
2.3. Utility and Loss 
41 
48 
2.4. Two Optimalities: Minimaxity and Admissibility 
53 
2.4.1. Randomized Estimators 
53 
2.4.2. Minimaxity 
54 
2.4.3. Existence of Minimax Rules and Maximin Strategy 57 
2.4.4. Admissibility 
62 
2.4.5. The Stein Effect 
65 
2.5. Usual Loss Functions 
69 
70 
2.5.1. The Quadratic Loss 

Xll 
Contents 
2.5.2. The Absolute Error Loss 
2.5.3. The "0 - I" Loss 
2.5.4. Intrinsic Losses 
2.6. Criticisms and Alternatives 
Exercises 
3. 
From Prior Information to Prior Distributions 
3.1. Subjective Determination and Approximations 
72 
73 
74 
75 
79 
89 
90 
3.2. Conjugate Priors 
97 
3.2.1. Introduction 
97 
3.2.2. Exponential Families 
99 
3.2.3. Conjugate Distributions for Exponential Families 
103 
3.3. Criticisms and Extensions 
3.4. Noninformative Prior Distributions 
3.5. Posterior Validation and Robustness 
Exercises 
4. 
Bayesian Point Estimation 
4.1. Bayesian Inference 
4.2. Bayesian Decision Theory 
4.3. The Particular Case of the Normal Model 
4.3.1. Introduction 
4.3.2. Estimation of Variance 
4.3.3. Linear Models and g-Priors 
4.3.4. Ranking and Selection 
4.4. Sampling Models 
4.4.1. Laplace Succession Rule 
4.4.2. The Tramcar Problem 
4.4.3. Capture-Recapture Models 
Exercises 
5. 
Tests and Confidence Regions 
5.1. A First Approach to Testing Theory 
5.2. Comparisons with the Classical Approach 
5.2.1. UMP and UMPU Tests 
5.2.2. Least Favorable Prior Distributions 
5.2.3. Criticisms 
5.2.4. The rr Values 
5.2.5. Least Favorable Bayesian Answers 
5.3. A Second Decision-Theoretic Approach 
5.4. Confidence Regions 
Exercises 
106 
112 
120 
124 
137 
137 
144 
151 
151 
152 
155 
158 
160 
160 
161 
162 
166 
179 
180 
189 
189 
193 
194 
196 
198 
205 
209 
217 

Contents 
xiii 
6. 
Admissibility and Complete Classes 
229 
6.1. Admissibility of Bayes Estimators 
229 
6.2. Necessary and Sufficient Admissibility Conditions 
6.2.1. Continuous Risks 
6.2.2. Blyth Sufficient Condition 
6.2.3. Stein Necessary and Sufficient Condition 
6.2.4. Another Limit Theorem 
6.3. Complete Classes 
6.4. Necessary Admissibility Conditions 
Exercises 
238 
239 
240 
245 
246 
247 
251 
254 
7. 
Invariance, Haar Measures, and Equivariant Estimators 
263 
7.1. Invariance Principles 
7.2. The Particular Case of Location Parameters 
7.3. Invariant Decision Problems 
263 
265 
268 
7.4. Best Equivariant Estimators and Noninformative Distributions 272 
7.5. The Hunt-Stein Theorem 
278 
7.6. The Role of Invariance in Bayesian Statistics 
Exercises 
8. 
Hierarchical and Empirical Bayes Extensions 
282 
283 
291 
8.1. Introduction 
291 
8.2. Hierarchical Bayes Analysis 
293 
8.3. Optimality of Hierarchical Bayes Estimators 
303 
8.4. The Empirical Bayes Alternative 
307 
8.5. Empirical Bayes Motivations of the Stein Effect 
313 
Exercises 
319 
9. 
Bayesian Calculations 
329 
9.1. Implementation Difficulties 
329 
9.2. Classical Approximation Methods 
337 
9.2.1. Numerical Integration 
337 
9.2.2. Monte Carlo Methods 
338 
9.2.3. Laplace Analytic Approximation 
341 
9.3. Bayesian Sampling and Markov Chain Monte Carlo Methods 
344 
9.4. An Application to Mixture Estimation 
355 
Exercises 
358 
10. A Defense of the Bayesian Choice 
369 
Appendix A: Usual Probability Distributions 
381 
Appendix B: Usual Pseudorandom Generators 
387 

XIV 
Contents 
Notation 
References 
Author Index 
Subject Index 
391 
395 
417 
425 

1 
Introduction 
1.1. Statistical Problems and Statistical Models 
The main purpose of statistical theory is to derive from observations of a 
random phenomenon an inference about the probability distribution under-
lying this phenomenon. That is, it provides either an analysis (description) 
of a past phenomenon or some predictions about a future event of a similar 
nature. In this book, we insist on the decision-oriented aspects of statistical 
inference, because, first, these analyses and predictions are usually moti-
vated by an objective purpose (whether a company should launch a new 
product, a racing boat should modify its route, an individual should sell 
shares, etc.) which have measurable consequences (monetary results, posi-
tion at the end of the race, benefits, etc.). Second, to propose inferential 
procedures implies that one should stand by them, i.e., that the statistician 
thinks they are preferable to alternative procedures. Therefore, there is a 
need for an evaluation tool which allows for the comparison of different 
procedures; this is the purpose of Decision Theory. As with most formal 
definitions, this view of Statistics blatantly ignores some additional aspects 
of statistical practice like those related to data collection (surveys, design 
of experiments, etc.), but so does this book, although we do not want to 
diminish the importance of these omitted topics. We also insist on the fact 
that Statistics should be considered an interpretation of natural phenom-
ena, rather than an explanation. In fact, statistical inference is based on a 
probabilistic modeling of the observed phenomenon and implies a necessar-
ily reductive formalization step since without this probabilistic support, it 
cannot provide any useful conclusion (or decision). 

2 
1. Introduction 
Example 1.1 Consider the problem of forest fires. They usually appear 
at random but some ecological and meteorological factors are influential 
in their eruption. To determine the probability p of fire as a function of 
these factors should help in the prevention of forest fires, even though this 
modeling is obviously unable to lead to the eradication of forest fires nor 
even to encompass all the factors involved. A more reductive approach 
would be to assume a parametrized shape for the function p, including 
physical constraints on the influential factors. For instance, denoting by h 
the humidity rate, t the average temperature, x the degree of management 
of the forest, a logistic model 
could be proposed, the statistical step dealing with the evaluation of the 
parameters aI, a2, a3. 
/':-,. 
To impose a probability modeling on unexplained phenomena seems 
to be overly reductive in some cases, since a given phenomenon can be 
entirely deterministic although the regulating function of the process is un-
known and cannot be recovered from the observations. This is, for instance, 
the case with chaotic phenomena, where a sequence of observations cannot 
be distinguished from a sequence of random variables, in the sense of a 
statistical test (see Berge, Pommeau, and Vidal (1984) and Gleick (1987) 
for general introductions to chaos theory and Berliner (1991, 1992) for a 
statistical approach). Pseudo-random generators are actually based on this 
indeterminacy since, while they use iterative deterministic algorithms like 
they imitate (or simulate) rather well the behavior of a sequence of random 
variables (see Devroye (1985), Ripley (1987), and Appendix B for a list of 
the most common generators). 
Although valid on a philosophical ground, this criticism does not hold 
if we consider the probabilistic modeling from the interpretation perspective 
mentioned above. This modeling simultaneously incorporates the available 
information about the phenomenon (influential factors, frequency, ampli-
tude, etc.) and the uncertainty pertaining to this information. It thus autho-
rizes a quantitative discourse on the problem by providing via probability 
theory a genuine calculus of uncertainty going beyond the mere descrip-
tion of deterministic modelings. This is why a probabilistic interpretation 
is definitely necessary for statistical inference; it provides a framework re-
placing a singular phenomenon in the globality of a model and thus allows 
for analyses and generalizations. Far from being a misappropriation of the 
inferential purposes, the imposition of a probabilistic structure which is 
only an approximation of reality is essential for the subsequent statisti-
cal modeling to induce a deeper and more adequate understanding of the 
considered phenomenon. 

1.1. Statistical Problems and Statistical Models 
3 
Obviously, the probabilistic modeling can only be defended if it pro-
vides an adequate representation of the observed phenomenon. A more 
down-to-earth criticism of probabilistic modeling is therefore that, even 
when a modeling is appropriate, it is difficult to know exactly the probabil-
ity distribution underlying the generation of the observations, e.g., to know 
that it is normal, exponential, binomial, etc., except in special cases. 
Example 1.2 Consider a radioactive material with unknown half-life H. For 
a given atom of this material, the time before disintegration follows exactly 
an exponential distributionl with parameter log(2)j H. The observation of 
several of these particles can then lead to an inference about H. 
~ 
Example 1.3 In order to determine the number N of buses in a town, a 
possible inferential strategy goes as follows: observe buses during a whole 
day and keep track of their identifying number. Then repeat the experiment 
the next day by paying attention to the number of buses which have been 
already observed the previous day, n. If 20 buses have been observed the 
first day and 30 the second day, n is distributed as an hypergeometricl ran-
dom variable, 1t(30, N, 20jN), and the knowledge of this distribution leads, 
for instance, to the approximation of N by 20(30jn). This method, called 
capture-recapture, has induced numerous and less anecdotal developments 
in ecology and population dynamics (see Chapter 4). 
~ 
We could produce many other examples where the distribution of the 
observations is exactly known, its derivation based upon physical, econom-
ical, etc., considerations. In the vast majority of cases, however, statistical 
modeling is reductive, in the sense that it only approximates the reality, 
losing part of its richness but gaining in efficiency. 
Example 1.4 Price and salary variations are closely related. One way to 
represent this dependence is to assume the linear relation 
L).P = a + bL).S + E, 
where L).p and L).S are the price and salary variations, a and b are unknown 
coefficients and E is the error factor. A further but drastic reduction can be 
obtained by assuming that E is normally distributed since, while E is indeed 
a random variable, there are many factors playing a role in the determi-
nation of prices and salaries and it is usually impossible to determine the 
distribution of E. Nonetheless, besides a justification through the Central 
Limit Theorem (Le., the additional influence of many small factors of sim-
ilar magnitude), this advanced modeling also allows for a more thorough 
statistical analysis which remains valid even if the distribution of E is not 
exactly normal. (See also Exercise 1.3.) 
~ 
Last, in some cases, the reductive effect is deliberately sought as a posi-
tive smoothing effect which partially removes unimportant perturbations of 
1 See Appendix A for a survey of the most common distributions. 

4 
1. Introduction 
the phenomenon and often improves its analysis by highlighting the major 
factors. 
Example 1.5 Radiological images can be represented as a 1000 x 1200 grid of 
elementary points, called pixels, which are grey levels represented by num-
bers between 0 and 256. For instance, Figure 1.1 provides the histogram of 
the grey levels for a usual chest radiograph. If we consider a pixel to be a dis-
crete random variable taking values in {O, 1, ... ,256}, the histogram gives 
an approximation of the distribution of this random variable. As shown by 
the figure, this distribution is rather complex but approximately bimodal. 
This particularity is observed on most radiographs and suggests a modeling 
of the distribution through a continuous approximation by a mixture of two 
normal distributions, with density 
0.02 r--------------, 
0.01 
0.00 "-----'---...1....-----'----'--.>--.... 
o 
50 
100 
150 
200 
250 
Gray levels 
FIGURE 1.1. Histogram of the grey levels of a chest radiograph. (Source: Plessis, 
1989.) 
Obviously, this modeling considerably smoothens the histogram (see Figure 
1.2) but also allows a description of the image through five parameters, with 
no substantial loss of information. The two important modes of the true 
distribution have actually been shown to correspond to two regions of the 
chest, the lungs and the mediastinum. This smoothing technique is used in 
an image-processing algorithm called Parametric Histogram Specification 
(see Plessis, 1989). We will consider the Bayesian estimation of mixture 
distributions in detail in §9.4. 
/::, 
Given this imperative of reduction of the complexity of the observed 
phenomenon, two statistical approaches compete. A first approach assumes 

1.1. Statistical Problems and Statistical Models 
5 
0.02 r---------------, 
-- Original 
-- Parameterized 
250 
Gray levels 
FIGURE 1.2. Modeling of the chest radiograph histogram. (Source: Plessis, 1989.) 
that statistical inference must incorporate as much as possible of this com-
plexity and thus aims at estimating the distribution underlying the phe-
nomenon under minimal assumptions, generally using functional estimation 
(density, regression function, etc.). This approach is called nonparametric. 
Conversely, the parametric approach represents the distribution of the ob-
servations through a density function f(xIB), where only the parameter B 
(of finite dimension) is unknown. We consider that this second approach is 
more pragmatic, since it takes into account the fact that a finite number 
of observations can efficiently estimate only a finite number of parameters. 
Moreover, a parametric modeling authorizes an evaluation of the inferential 
tools for finite sample sizes, contrary to the more involved nonparametric 
methods which are usually justified only asymptotically, therefore strictly 
only apply when the sample size becomes infinite (see, however, Field and 
Ronchetti (1990) who study the applicability of asymptotic results for fi-
nite sample sizes). Of course, some nonparametric approaches, like rank 
tests (Hajek and Sidak, 1967), completely evacuate the estimation aspect 
by devising distribution-free statistics, but their applicability is limited to 
testing settings. Both approaches have obviously their interest and we will 
not try to justify any further the parametric choice. Quite naturally, there 
is also an extensive literature on model construction. See Cox (1990) and 
Lehmann (1990) for references as well as reflections on the very notion of 
a statistical model. 
In this book, we only consider parametric modelings. We assume that 
the observations supporting the statistical analysis, Xl, ... , X n , have been 
generated from a parametrized probability distribution, i.e., Xi (1 ::; i ::; n) 
has a distribution with density fi(XiIB;) on IRP, such that the parameter Bi 

6 
1. Introduction 
is unknown and the function fi is known (see Exercise 1.2 about the formal 
ambiguity of this definition). This model can then be represented more 
simply by x rv f(xIO), where x is the vector of the observations and 0 is the 
set of the parameters, 01 , ... , On, which may all be equal. This approach is 
unifying, in the sense that it represents similarly isolated observations and 
repeated observations Xl, ... ,xn from a common distribution, f (xlIO). In 
the second case, x = (Xl. ... ,xn ) and 
n 
f(xIO) = IT f(XiI O). 
i=l 
Note also that densities of discrete and continuous random variables will 
be denoted identically in this book, the reference measure being generally 
provided by the setup. Moreover, we use the notation "x is distributed 
according to f" or "x rv f" instead of "x is an observation from the dis-
tribution with density f" for the sake of conciseness. Most of the time, the 
sample is reduced to a single observation, for simplification reasons, but 
also because we are usually dealing with distributions where the sample 
size does not matter, since they allow for sufficient statistics of constant 
dimension (see §1.3 and Chapter 3). 
Definition 1.1 A parametric statistical model consists of the ob-
servation of a random variable x, distributed according to f(xIO), 
where only the parameter 0 is unknown and belongs to a vector 
space e of finite dimension. 
Once the statistical model is defined, the main purpose of the statistical 
analysis is to lead to an inference on the parameter O. This means that we 
use the observation x to improve our knowledge on the parameter 0, so that 
one can take a decision related with this parameter, i.e., either estimate a 
function of 0 or a future event which distribution depends on O. The infer-
ence can deal with some components of 0, precisely ("What is the value of 
01 ?") or not ("Is O2 larger than 03 ?"). A distinction is often made between 
estimation and testing problems, depending whether the exact value of the 
parameters (or of some functions of the parameters) or just an hypothe-
sis about these parameters is of interest. For instance, the two reference 
books of classical Statistics, Lehmann (1983) and Lehmann (1986), deal, 
respectively, with each of these themes. Other authors have proposed a 
more subtle distinction between estimation and evaluation of estimation 
procedures (see, for instance, Casella and Berger, 1990). As shown later, 
these divisions are somehow artificial, since all inferential problems can be 
expressed as estimation problems when considered in a decision-theoretic 
perspective. 
The choice of the parametric approach made in this book can be crit-
icized, since we cannot always assume that the distribution of the obser-
vations is known up to a parameter, but we maintain that this reduction 

1.2. The Bayesian Paradigm as a Duality Principle 
7 
allows for deeper developments in the inferential process, even though this 
may seem a paradoxical statement. Criticisms on the reductive aspects of 
the statistical approach and, a fortiori, on the parametric choice are actually 
seconded by other criticisms about the choice of the evaluation criteria and 
the whole purpose of Decision Theory, as we will see in Chapter 2. However, 
we stand by these choices on the ground that these increasingly reductive 
steps are nonetheless minimal requirements for a statistical approach to be 
coherent. Indeed, the ultimate goal of statistical analysis is, in the over-
whelming majority of cases, to support a decision as being optimal. It is 
thus necessary to be able to compare the different inferential procedures 
at hand. The next section presents the foundations of Bayesian statistical 
analysis, which seems to us to be the most appropriate approach for this 
determination of optimal procedures, while being also the most coherent, 
since it builds up these procedures by starting from required properties, 
instead of the reverse, namely, verifying the good behavior of procedures 
selected in an ad hoc manner. The Bayesian choice, as presented in this 
book, may appear as a superfluous diminution of the inferential scope, and 
it has indeed been criticized by many as being so. But we will see in the 
following chapters that this reduction is necessary and above all profitable. 
Chapter 10 summarizes various points of a defense of the Bayesian choice 
and can be read in connection with the previous arguments. 2 
Note that there also exists a Bayesian approach to nonparametric 
Statistics. It usually involves prior distributions on functional spaces, like 
Dirichlet processes. See Ferguson (1973, 1974) and Escobar (1989), Esco-
bar and West (1994) for references in this area. Example 1.16 provides an 
illustration of the interest of the Bayesian approach in this setup. 
1.2. The Bayesian Paradigm as a Duality Principle 
Compared with probabilistic modeling, the purpose of a statistical analy-
sis is fundamentally an inversion purpose, since it aims at retrieving the 
"causes" - parameters of the probabilistic generating mechanism - from the 
"effects" - observations.3 In other words, when observing a random phe-
nomenon directed by a parameter B, statistical methods allow to deduce 
from these observations an inference about B, while probabilistic modeling 
characterizes the behavior of the future observations conditional on B. This 
inverting aspect of Statistics is obvious in the notion of the likelihood func-
tion, since, formally, it is just the sample density rewritten in the "proper 
2 Like this Introduction, Chapter 10 is worth re-reading once the more techni-
cal points of the inferential process and the issues at hand have been fully 
understood. 
3 At the time of Bayes and Laplace, i.e., at the end of the eighteenth century, 
Statistics was often called Inverse Probability because of this perspective. See 
Stigler (1986, Chap. 3). 

8 
1. Introduction 
order" , 
£(Blx) = f(xIB), 
(1.1) 
i.e., as a function of B, which is unknown, depending on the observed value 
x. 
The fiducial approach of Fisher (1956) also relies on this inversion. For 
instance, considering the relation 0 = P + E where E is an error term, it is 
argued that, if P (the cause) is known, 0 (the effect) is distributed according 
to the above relation. Conversely, if 0 is known, P = 0 -
E is distributed 
according to the symmetric distribution. In this perspective, observations 
and parameters play a symmetric role, depending on the way the model 
is analyzed, i.e., depending on what is known and what is unknown. More 
generally, the fiducial approach consists in renormalizing the likelihood (1.1) 
so that it becomes a density in B when 
Ie £(Blx) dB < +00, 
thus truly inverting the roles of x and B. As can be seen in the above ex-
ample, the argument underlying the causal inversion is totally conditional: 
conditionally on P, 0 = P + E while, conditionally on 0, P = 0 -
E. 
Obviously, this argument does not hold from a probabilistic point of view 
since, if 0 is a random variable and P is a (constant) parameter, to write 
P = O-E does not imply that P becomes a random variable. Moreover, the 
transformation of £(Blx) into a density is not always possible. The fiducial 
approach was progressively abandoned after the exposure of fundamental 
paradoxes (see Stein (1959), Wilkinson (1977) and the references in Zabell 
(1989)). Nonetheless, it appears as a precursor of the noninformative ap-
proaches of Jeffreys (1961) and Bernardo (1979) which would pursue the 
derivations of distributions on B from the likelihood function on a Bayesian 
basis (see §3.4). 
A general description of the inversion of probabilities is given by 
Bayes's Theorem: If A and E are events such that P(E) =I- 0, P(AIE) 
and P(EIA) are related by 
In particular, 
P(AIE) _ 
P(EIA)P(A) 
- P(EIA)P(A) + P(EIAc)P(Ac) 
P(AIE) 
P(BIE) 
P(EIA) 
P(EIB) , 
when P(B) = P(A). To derive this result through the machinery of modern 
axiomatized probability theory is trivial. However, it appears as a major 
conceptual step in the history of Statistics, being the first inversion of 
probabilities. It expresses the fundamental fact that, for two equiprobable 
causes, the ratio of their probabilities given a particular effect is the same 
as the ratio of the probabilities of this effect given the two causes. This 

1.2. The Bayesian Paradigm as a Duality Principle 
9 
theorem can also be seen as an actualization principle since it describes 
the updating of the likelihood of A from P(A) to P(AIE) once E has been 
observed. Thomas Bayes (1763) actually proved a continuous version of 
this result, namely that, given two random variables x and y, with condi-
tional distribution f(xly) and marginal distribution g(y), the conditional 
distribution of y given x is 
f(xly)g(y) 
g(ylx) = J f(xly)g(y) dy . 
Published posthumously by R. Price in Bayes (1763), this theorem was later 
proved independently by Pierre-Simon Laplace in a more general setting 
(see Stigler (1986) for a more detailed accounting). 
While this inversion theorem is quite natural from a probabilistic point 
of view, Bayes and Laplace went further and considered that the uncertainty 
on the parameters 0 of a model could be modeled through a probability 
distribution 7r on e, called prior distribution. The inference is then based 
on the distribution of 0 conditional on x, 7r(Olx), called posterior distribution 
and defined by 
f(xIO)7r(O) 
7r(Olx) = J f(xIO)7r(O) dO . 
(1.2) 
Note that 7r(Olx) is actually proportional to the distribution of x condition-
ally on 0, i.e., the likelihood, multiplied by the prior distribution of O. (It 
seems that the full generality of (1.2) was not perceived by Bayes, but by 
Laplace who developed it to a greater extent.) The main addition brought 
by a Bayesian statistical model is thus to consider a probability distribution 
on the parameters. 
Definition 1.2 
A Bayesian statistical model is made of a para-
metric statistical model, f(xIO), and a prior distribution on the 
parameters,7r(O). 
In more statistical terms, Bayes's Theorem actualizes the information 
on 0 due to the information contained in the observation x. Its impact 
is based on the daring move which puts causes (observations) and effects 
(parameters) on the same conceptual level, since both of them have prob-
ability distributions. From a statistical modeling viewpoint, there is thus 
little difference between observations and parameters, since conditional ma-
nipulations allow for an interplay of their respective roles. Note that, in-
cidentally, this perspective that parameters directing random phenomena 
can also be perceived as random variables goes against the atheist deter-
minism of Laplace4 as well as the clerical position of Bayes, who was a 
nonconformist minister. By imposing this fundamental modification to 
4 "We must envision the present state of the Universe as the effect of its anterior 
state and as the cause of the following state" - Laplace (1795). 

10 
1. Introduction 
the perception of random phenomena, these two mathematicians have given 
birth to modern statistical analysis and, in particular, to Bayesian analysis. 
Indeed, the recourse to the prior distribution 7f On the parameters of 
a model is truly revolutionary (or "shocking", depending On the point of 
view). There is indeed a major step from the notion of an unknown pa-
rameter to the notion of a random parameter and many statisticians place 
an absolute boundary between the two concepts, although they accept the 
probabilistic modeling on the observation. They defend this point of view 
On the ground that, even though in some particular settings, the parameter 
is produced under the simultaneous action of many factors and can thus 
appear as (partially) random, as for instance, in the quantum interpretation 
of Physics, the parameter to be estimated cannot be perceived as resulting 
from a random experiment in most cases. A typical setting occurs when 
estimating physical quantities like the speed of light, c. An anSwer in this 
particular setup is that the limited accuracy of the measurement instru-
ments implies that the true value of c will never be known and thus that it 
is justified to consider c as being uniformly distributed On [co -
E, Co + E], 
if E is the maximal precision of the measuring instruments and Co the ob-
tained value. We will consider in Chapter 3 some approaches to the delicate 
problem of prior distribution determination. However, more fundamentally, 
we want to stress here that the importance of the prior distribution in a 
Bayesian statistical analysis is not at all that the parameter of interest e can 
(or cannot) be perceived as generated from 7f or even as a random variable, 
but rather that the use of a prior distribution is the best way to summarize 
the available information (or even the lack of information) about this pa-
rameter, as well as the residual uncertainty, thus allowing for incorporation 
of this imperfect information in the decision process. (A similar reasoning 
led Laplace to develop statistical models, despite his determinism.) A more 
technical point is that the only way to construct a mathematically justified 
approach which operates conditionally On the observations is to introduce 
a corresponding distribution On the parameters. 
Let us conclude this section with the "historical" examples of Bayes 
and Laplace. The experiment described in Bayes (1763) is as follows: a 
billiard ball W is rolled On a line of length one, with a uniform probability 
of stopping anywhere. It stops at p. A second ball 0 is then rolled n times 
under the same assumptions and X denotes the number of times the ball 0 
stopped On the left of W. Given X, what inference can we make on p? In 
modern terminology, the problem is then to derive the posterior distribution 
of p given X, when the prior distribution On p is uniform On [0, 1] and 
X", B(n,p), the binomial distribution (see Appendix A). Since 

1.2. The Bayesian Paradigm as a Duality Principle 
11 
P(X = xlp) = (:)pX(1- p)n-x, 
P(a < p < b and X = x) = lb (:)px(1- pt-xdp 
and 
we derive that 
fb (n) X(l 
)n-x d 
P(a<p<bIX=x)= Ja x p 
-p 
p 
I; (~)pX(l - p)n-x dp 
I: pX(1- p)n-x dp 
B(x+1,n-x+1) , 
i.e., that the distribution of p conditionally on X = x is a beta distribution, 
Be(x + 1, n - x + 1) (see Appendix A). 
Laplace also proposed a probabilistic modeling of the parameter space. 
But his examples are more advanced in the sense that the prior distributions 
he considers are based on abstract reasoning, instead of the physical basis 
of Bayes's prior distribution.5 
Example 1.6 (Laplace, 1773) An urn is supposed to contain a number n 
of black and white cards. If the first card drawn out of the urn is white, 
what is the probability that the proportion p of white cards is Po? In his 
resolution of the problem, Laplace assumes that all numbers from 2 to 
n - 1 are equally likely values for pn, i.e., that p is uniformly distributed 
on {2/n, ... ,n - l/n}. The posterior distribution of p can then be derived 
using Bayes's Theorem and 
P(p = Po I data) = n(n - ~)/2 - 1 
The above choice of the prior distribution can obviously be attacked 
as being partially arbitrary. However, in Laplace's view of probability the-
ory, most events can be decomposed in elementary equiprobable events and, 
therefore, in this particular case, it seems reasonable to consider the events 
{p = i/n} (2 :::; i :::; n-1) as elementary events. A similar reasoning justifies 
the following example. 
Example 1.7 (Laplace, 1786) Considering the proportion of male births in 
Paris, Laplace wants to test whether the probability x of a male birth is 
5 It is also possible to picture a more Machiavellian Bayes who picked up this 
particular example in order to circumvent potential criticisms against the choice 
of the prior. But it seems that this was not the case, i.e., that Bayes was actually 
studying this example for its own sake. See Stigler (1986) for more details. 

12 
1. Introduction 
above 1/2. For 251,527 male and 241,945 female births, assuming that x 
has a uniform prior distribution on [0, 1], Laplace obtains 
P(x::; 1/21(251,527;241,945)) = 1.15 x 10-42 . 
(see Stigler, 1986, p. 134 and Exercise 1.4). He then deduces that this 
probability x is more than likely to be above 50%. Still assuming a uniform 
prior distribution on this probability, he also compares the male births in 
London and Paris and deduces that the probability of a male birth is higher 
in England. 
~ 
The following example worked out by Laplace is even more interesting 
because, from a practical point of view, it provides a method of deriving 
optimal procedures and, from a theoretical point of view, it is the first 
formal derivation of a Bayes estimator. 
Example 1.8 In astronomy, one frequently gets several observations of a 
quantity ~. These measurements are independently distributed according 
to a distribution which is supposed to be unimodal and symmetric around 
~. If we put a uniform distribution on the parameter ~, it should be a 
"uniform distribution on (-00, +00)" which is not defined as a probability 
distribution. However, if we agree on this formal extension (see §1.5 for 
a justification), we can work with the Lebesgue measure on (-00, +00) 
instead. Using this generalized distribution, Laplace (1773) establishes that 
the posterior median of ~, i.e., for the distribution of ~ conditional on the 
observations, is an optimal estimator in the sense that it minimizes the 
average absolute error 
This result justifies the use of the posterior median as an estimator of ~, 
whatever the distribution of the observation. Although established more 
than two centuries ago, it is strikingly modern (generality of the distri-
bution, choice of a loss function to evaluate the estimators) and Laplace 
extended it in 1810 by establishing a similar result for squared error. Sur-
prisingly, though, Laplace was rather unsatisfied with this result, because he 
still needed the distribution of the observation error to be able to compute 
the resulting estimator. He considered first, in 1774, the double exponential 
distribution 
x E JR, 
also called the Laplace distribution, which supposedly involved the resolu-
tion of a fifteenth degree equation for three observations. (Actually, Laplace 
made a mistake and the correct equation is cubic, as shown by Stigler, 1986.) 
Then, in 1777, he looked at the even less tractable alternative 
1 
'P(x) = -log (a/Ix!) lllxl<a, 
2a 
-

1.3. Likelihood Principle and Sufficiency Principle 13 
where I denotes the indicator function. It was only in 1810 when Legendre 
and Gauss independently exposed the importance of the normal distribu-
tion, that Laplace was able to compute his (Bayes) estimators explicitly, 
since he then thought this was the 'ideal' error distribution. 
l::, 
We will consider again this example along with other optimality results 
in Chapter 2, when we study different loss functions to evaluate estimation 
procedures and the associated Bayes estimators. Let us stress here that the 
main consequence of the Bayes and Laplace works has been to introduce the 
conditional perspective in Statistics, Le., to realize that parameters and ob-
servations are fundamentally identical objects although they are perceived 
differently.6 To construct in parallel a probability distribution on the param-
eter space completes this equivalence and, through Bayes's Theorem, allows 
a quantitative discourse on the "causes", Le., in our parametric framework 
an inference on the parameters. As mentioned above, the choice of the prior 
distribution is delicate, but its determination should be incorporated in the 
statistical process in parallel with the determination of the distribution of 
the observation. Indeed, a prior distribution is, in fact, the optimal way to 
include residual information into the model. In addition, Bayesian statisti-
cal analysis provides natural tools to incorporate the uncertainty associated 
with this information, as it is also part of the prior distribution (possibly 
through a hierarchical modeling, see Chapter 8). Lastly, as pointed out 
in Lindley (1971), the Bayesian paradigm is intrinsically logical: given a 
set of required properties represented by the loss function and the prior 
distribution, the Bayesian approach provides estimators satisfying these re-
quirements, while other approaches evaluate the properties of estimators 
derived for reasons external to the inferential framework. 
1.3. Likelihood Principle and Sufficiency Principle 
Classical Statistics can be envisaged as directed by principles which are 
often justified by "common sense" or additional axioms. On the contrary, 
the Bayesian approach naturally incorporates most of these principles with 
no restraint on the procedures to be considered and also definitely rejects 
other principles, like the notion of unbiasedness. This notion was once a 
cornerstone of Classical Statistics and restricted the choice of estimators to 
those who are on average correct (see Lehmann, 1983). While intuitively ac-
ceptable, it imposes too stringent conditions on the choice of the procedures 
and often leads to subefficiency in their performances. (See, e.g., the Stein 
effect in §2.4.5.) Two fundamental principles are followed by the Bayesian 
paradigm, namely the Likelihood Principle and the Sufficiency Principle. 
6 This is why this book indistinctly writes random variables, observations and 
parameters in lower case, contrary to most Statistics books where random 
variables are usually denoted with capital letters. 

14 
1. Introduction 
Definition 1.3 When x '" f(xI8), a function T of x (also called a 
statistic) is said to be sufficient if the distribution of x condition-
ally on T(x) does not depend on 8. 
A sufficient statistic T(x) contains the whole information brought by 
x about 8. According to the factorization theorem, under some regularity 
conditions (see Lehmann, 1983), the density of x can then be written as 
f(xI8) = g(T(x)18)h(xIT(x)), 
if g is the density of T( x). We will see in Chapter 2 that, when an estimator 
is evaluated under a convex loss, the optimal procedures only depend on 
sufficient statistics (the Rao--Blackwell Theorem). In particular, when the 
model allows for a minimal sufficient statistic, i.e., for a sufficient statis-
tic which is a function of all the other sufficient statistics, we only have 
to consider the procedures depending on this statistic or equivalently the 
restricted statistical model associated with this statistic. The concept of 
sufficiency has been developed by Fisher (see Huzurbazar (1976) for an 
exhaustive survey) and is associated with the following principle: 
Sufficiency Principle Two observations x and y factorizing through 
the same value of a sufficient statistic T, i.e., such that T(x) = 
T(y), must lead to the same inference on 8. 
Example 1.9 Consider Xl, ... ,Xn independent observations from a normal 
distribution N(p" (72) (see Appendix A). The factorization theorem then 
implies that the pair T(x) = (x, S2), where 
1 n 
X = - LXi 
n i=l 
n 
and 
s2 = L(xi - X)2, 
i=l 
is a sufficient statistic for the parameter (p" (7), with density 
f;f, -
2 
2 (s2)(n-3)/2e- s2/2<72 
(T( )18) -
-- -(x-OJ n/2<7 
g 
x 
-
21m2 e 
(7n r( n _ 1/2)2n-I/2 . 
Therefore, according to the Sufficiency Principle, inference on p, should only 
depend on this two-dimensional vector, whatever the sample size n is. We 
will see in Chapter 3 that the existence of a sufficient statistic of constant 
dimension is in a sense characteristic of exponential families. 
L. 
Example 1.10 Consider Xl '" B(nl,p), X2 '" B(n2'p), and X3 '" B(n3,p), 
three binomial independent observations when the sample sizes nl, n2, and 
n3 are known. The likelihood function is then 
f(xI,x2,x3Ip) = (:~) (::) (::)pxl+X2+X3(1_ ptl+n2+n3-xl-x2-X3 
and the statistics 

1.3. Likelihood Principle and Sufficiency Principle 15 
or 
are sufficient, on the contrary of xdnl + X2/n2 + X3/n3' 
The Sufficiency Principle is generally accepted by most statisticians, 
in particular, because of the Rao-Blackwell Theorem, which rules out es-
timators which do not depend only on sufficient statistics. In model choice 
settings, it is sometimes criticized as being too drastically reductive, but 
note that the Sufficiency Principle is only legitimate when the statistical 
model is actually the one underlying the generation of the observations. 
Any uncertainty about the distribution of the observations should be in-
corporated into the model, a modification which almost certainly leads to 
a change of sufficient statistics. A similar cautionary remark applies to the 
Likelihood Principle (see below). 
This second principle is partially a consequence of the Sufficiency Prin-
ciple. It can be attributed to Fisher (1959) or even to Barnard (1949) but 
was formalized by Birnbaum (1962). It is strongly defended by Berger and 
Wolpert (1988) who provide an extended study of the topic. In the following 
definition, the notion of information is to be considered in the general sense 
of the collection of all possible inferences on (), and not in the mathematical 
sense of Fisher information defined in Chapter 3. 
Likelihood Principle The information brought by an observation 
x about () is entirely contained in the likelihood function f( ()Ix). 
Moreover, if Xl and X2 are two observations depending on the 
same parameter (), such that there exists a constant c satisfying 
for every (), they bring the same information about () and must 
lead to identical inferences. 
Note that the Likelihood Principle is only valid when (i) inference is 
about the same parameter () and (ii) () includes every unknown factor of 
the model. The following example provides a (now 'classical') illustration 
of this principle: 
Example 1.11 While working on the audience share of a TV series, 0 :::; 
() :::; 1 representing the part of the TV audience, an investigator found nine 
viewers and three nonviewers. If no additional information is available on 
the experiment, two probability models at least can be proposed: 
(1) the investigator questioned 12 persons, thus observed x rv 8(12, ()) with 
x = 9; 
(2) the investigator questioned N persons until he obtained 3 nonviewers, 
with N rv N eg(3, 1 - ()) and N = 12. 
In other words, the random quantity in the experiment can be either 9 or 
12. (Note that it could also be both.) The important point is that, for the 
two models, the likelihood is proportional to 

16 
1. Introduction 
Therefore, the Likelihood Principle implies that the inference on B should 
be identical for both models. On the contrary, a classical treatment of the 
two models can lead to different answers, for instance, when testing an 
hypothesis about B (see Exercise 1.17). 
I:::, 
Since the Bayesian approach is entirely based on the posterior distri-
bution 
£( Blx )n( B) 
n( Blx) = J £( Blx )n( B)dB 
(see (1.2) and §1.4), which depends on x only through £(Blx), the Likelihood 
Principle is automatically satisfied in a Bayesian setting. 
On the contrary, the Jrequentist approach7 focuses on the average be-
havior properties of procedures and thus justifies the use of an estimator 
for reasons which can contradict the Likelihood Principle. This perspective 
is particularly striking in testing theory. For instance, if x rv N (B, 1) and if 
the hypothesis to be tested is Ho : B = 0, the classical Neyman-Pearson test 
procedure at level 5% is to reject the hypothesis if x = 1.96, on the basis 
that P(lx - BI 2: 1.96) = 0.05, i.e., because an unlikely event (Ixl > 1.96) 
did not occur. Such arguments come to contradict the Likelihood Princi-
ple (see also Exercise 1.12). The opposition between the frequentist and 
Bayesian paradigms is stronger in testing theory than in point estimation, 
where the frequentist approach usually appears as a limiting case of the 
Bayesian approach (see Chapter 5). 
Example 1.12 Consider Xl, X2 i.i.d. N(B, 1). The likelihood function is then 
£(Blxl' X2) ex exp{ -(x - B?} with x = (Xl + x2)/2. Now, consider the 
alternative distribution 
( 
IB) _ 
-3/2 e-(Xl +X2-20)2 /4 
g XI,x2 
-n 
1+(XI-X2)2. 
This distribution gives a likelihood function which is proportional to 
£(Blxl,X2) and therefore should lead to the same inference about B. How-
ever, the distribution g is quite different from J(XI, x2IB); for instance, the 
expectation of (Xl - X2) is not defined. Therefore, the estimators of B will 
have different frequentist properties if they do not depend only on x. In 
particular, the confidence regions on B may differ significantly because of 
the heavier tails of g. 
I:::, 
Example 1.13 Another implication of the Likelihood Principle is the Stop-
ping Rule Principle in sequential analysis. A stopping rule T can be de-
fined as follows. If the experiments [i lead to observations Xi E Xi, with 
7 The theory built up by Wald, Neyman, and Pearson in the 1950s is called 
frequentist, because it evaluates statistical procedures according to their long-
run performances, i.e., on the average (or in frequency) rather than to focus on 
the performance of a procedure for the obtained observation, as a conditional 
approach would do. It will be considered in detail in Chapters 2 and 5. 

1.3. Likelihood Principle and Sufficiency Principle 17 
Xi rv f(xiIO), consider a corresponding sequence Ai C Xl X ... X Xi such 
that the criterion T takes the value n if (Xl, ... ,Xn) E An, i.e., the experi-
ment stops after the nth observation only if the first n observations are in 
An. The likelihood of (Xl, ... ,xn) is then 
f(Olxl, ... ,xn) = f(xlIO)f(x2IXl, 0) 
... f(xnlxl, ... , Xn-l, O)IAn (Xl, ... , xn), 
thus depends only on T through the sample Xl, ... , X n . This implies the 
following principle: 
Stopping Rule Principle If a sequence of experiments, £1, £2, ... , 
is directed by a stopping rule, T, which indicates when the ex-
periments should stop, inference about 0 must depend on T only 
through the resulting sample. 
Example 1.11 illustrates the case where two different stopping rules 
lead to the same sample: either the sample size is fixed to be 12 or the ex-
periment is stopped when 9 viewers have been interviewed. Another striking 
(although artificial) example of a stopping rule is to observe Xi rv N(O, 1) 
and to take T as the first integer n such that 
n 
IXnl = Lxdn > 1.96/vn. 
i=l 
In this case, the stopping rule is obviously incompatible with the frequentist 
modeling since the resulting sample always leads to the rejection of the null 
hypothesis Ho: 0 = 0 at the level 5% (see Chapter 5). On the contrary, 
a Bayesian approach avoids this difficulty (see Raiffa and Schlaifer, 1961, 
and Berger and Wolpert, 1988, p. 81). 
t:, 
A justification of the Likelihood Principle has been provided by Birn-
baum (1962) who established that it is implied by the Sufficiency Principle, 
conditionally on the acceptance of a second principle. 
Conditionality Principle If two experiments on the parameter 0, 
£1 and £2, are available and if one of these two experiments is 
selected with probability 0.5, the resulting inference on 0 should 
only depend on the selected experiment. 
This principle seems difficult to reject when the selected experiment is 
known, as shown by the following example. 
Example 1.14 (Cox, 1958) In a research laboratory, a physical quantity 
o can be measured by a precise but often busy machine, which provides a 
measurement, Xl rv N(O, 0.1), or through a less precise but always available 
machine, which gives X2 rv N(O, 10). The machine being selected at random, 
depending on the availability of the more precise machine, the inference 
on () when it has been selected should not depend on the fact that the 

18 
1. Introduction 
alternative machine could have been selected. In fact, a classical confidence 
interval at level 5% taking into account this selection, i.e., averaging over all 
the possible experiments, is of half-length 5.19, while the interval associated 
with £1 is of half-length 0.62. 
L:. 
The equivalence result of Birnbaum (1962) is then as follows: 
Theorem 1.1 The Likelihood Principle is equivalent to the con-
junction of the Sufficiency and the Conditionality Principles. 
Proof. 
We define first the evidence associated with an experiment £, 
Ev(£, x), as the collection of the possible inferences on the parameter () 
directing this experiment. Let £* denote the mixed experiment starting 
with the choice of £i with probability 0.5 (i = 1,2), thus with result (i, Xi). 
Under these notations, the Conditionality Principle can be written as 
(1.3) 
Consider x7 and xg such that 
(1.4) 
The Likelihood Principle then implies 
(1.5) 
Let us assume that (1.4) is satisfied. For the mixed experiment £* derived 
from the two initial experiments, consider the statistic 
T(. 
.) = { (1, x7) 
if j = 2, X2 = xg, 
], xJ 
(j, Xj) 
otherwise, 
which takes the same value for (1, x7) and for (2, xg). Then, this statistic 
is sufficient since, if t i= (1, x7), 
and 
Pe(X* = (1, x~)IT = (1, x~)) = _c_, 
l+c 
due to the proportionality of the likelihood functions. The Sufficiency Prin-
ciple then implies that 
Ev(£*, (1, xd) = Ev(£*, (2, X2)) 
(1.6) 
and, combined with (1.3), leads to (1.5). 
The reciprocal of this theorem can be derived for the Conditionality 
Principle from the fact that the likelihood functions of (j, Xj) and Xj are 
proportional and for the Sufficiency Principle from the factorization theo-
rem. 
•• 

1.3. Likelihood Principle and Sufficiency Principle 
19 
It thus seems quite justified to follow the Likelihood Principle since it 
can be derived from the unassailable Sufficiency and Conditionality Prin-
ciples. However, this principle is altogether too "vague" as it does not lead 
to the selection of a particular procedure when faced with a given infer-
ential problem. It has been argued that the role of the statistician should 
stop with the determination of the likelihood function (Box and Tiao, 1973) 
since it is sufficient for clients to draw their inference, but this extreme view 
only stands in the most simple cases (or from a Bayesian decisional point 
of view, if the decision-maker also provides a prior distribution and a loss 
function). This "vagueness" of the Likelihood Principle calls for a reinforce-
ment of the axiomatic bases of the inferential process, i.e., for additional 
structures in the construction of statistical procedures. For instance, an 
effective implementation of the Likelihood Principle is the maximum likeli-
hood estimation method, when it leads to a single procedure. Similarly, the 
Bayesian paradigm allows for implementation of the Likelihood Principle in 
practice, with the additional advantage of including the decision-related re-
quirements of the inferential problem and even getting optimal procedures 
from a frequentist point of view (see below). 
If we keep in mind the inversion aspect of Statistics presented in §1.2, 
it is tempting to consider the likelihood as a generalized density in (), whose 
mode would then be the maximum likelihood estimator, and to work with 
this density as with a regular distribution. This approach was somewhat ad-
vocated by Laplace when he suggested using the uniform prior distribution 
when no information was available on () (see Examples 1.6-1.8). Similarly, 
Fisher introduced the fiducial approach to try to circumvent the determi-
nation of a prior distribution while putting into practice the Likelihood 
Principle, the choice of his distribution being "objective" (since depend-
ing only on the distribution of the observations). However, this approach 
is at most defensible when () is a location parameter (see also Example 
1.18), since it leads in general to paradoxes and contradictions (the most 
immediate being that .e(()lx) is not necessarily integrable as a function of 
()). The derivation of "objective" posterior distributions actually calls for 
a more advanced theory of noninformative distributions (see Chapter 3), 
which shows that the likelihood function cannot always be considered as 
the most natural posterior distribution. 
Many approaches have been suggested to implement the Likelihood 
Principle like, for instance, penalized likelihood theory (Akaike, 1978, 1983) 
or stochastic complexity theory (Rissanen, 1983, 1990). See also Bj0rnstad 
(1990) for a survey of non-Bayesian methods derived from the Likelihood 
Principle in the prediction area. The overall conclusion of this section is 
nonetheless that, apart from the fact that many of these theories have a 
"Bayesian flavor", a truly Bayesian approach is the most appropriate to 
take advantage of the Likelihood Principle (see Berger and Wolpert, 1988, 
Chap. 5, for an extensive discussion of this point). 

20 
1. Introduction 
Note that the Likelihood Principle is distinct from the maximum like-
lihood estimation approach, which is only one of several ways to implement 
the Likelihood Principle. Since we encounter this technique quite often in 
the next chapters, and also as it can be situated at the "fringe" of the 
Bayesian paradigm, we recall briefly basic facts about the maximum likeli-
hood approach. Extended coverage can be found in Lehmann (1983). 
When x '" f(xl()) is observed, the maximum likelihood approach con-
siders the following estimator of (): 
0= Arg supl(()lx), 
(J 
(1. 7) 
i.e., the value of () which maximizes the density at x, f(xl()), or, informaly, 
the probability to observe the given value of x. The maximization (1.7) 
is not always possible (see, e.g., the case of a mixture of two normal dis-
tributions, which is detailed in Chapter 9) or can lead to several maxima 
(see, e.g., the case of a Cauchy distribution, C(O, 1), with two well-separated 
observations). Nevertheless, the maximum likelihood estimator method is 
widely used, partly because of this intuitive motivation of maximizing the 
probability of occurrence, and partly because of strong asymptotic proper-
ties (consistency and efficiency). An interesting feature of maximum like-
lihood estimators is also that they are parametrization-invariant. That is 
to say, for any function h(()), the maximum likelihood estimator of h(()) is 
h(O) (even when h is not one-to-one). This property is not enjoyed by any 
other statistical approach (except by Bayes estimators in the special case 
of intrinsic losses, see §2.5.4). 
The maximum likelihood method also has drawbacks. First, the prac-
tical maximization of l(()lx) can be quite complex, especially in multidi-
mensional and constrained settings. Consider, for instance, the examples of 
a mixture of normal distributions, of a truncated Weibull distribution 
n 
l(()l, ()2IXl, ... ,xn ) = (()1()2t(Xl ... Xn)(Jl exp -()2 L Xfl 
i=l 
(see Exercise 1.22) or of a 10 x 10 table where Xij '" N(()ij, 1) when ()ij 
is increasing in i and j (see Robert and Hwang, 1993, and Exercises 1.23-
1.24). Some numerical procedures have been tailored for this approach, like 
the EM algorithm of Dempster et al. (1977) for missing data models or the 
algorithm of Robertson et al. (1988) for order-restricted parameter spaces 
(see Exercises 1.23 and 1.24), but there are still unsolved difficulties in this 
regard. Second, a maximization technique is bound to give estimators which 
lack smoothness, as opposed to integration for instance. This is particularly 
true when the parameter space is restricted. For example, Saxena and Alam 
(1982) show that, if x '" X;(>,), i.e., a noncentral chi-squared distribution 

1.4. Prior and Posterior Distributions 21 
with p degrees of freedom, 8 the maximum likelihood estimator of >. is equal 
to 0 for x < p. Similarly, maximum likelihood estimators can be quite 
unstable, i.e., vary widely for small variations of the observations, at least 
for reduced sample sizes (see Exercise 1.25). A last but important defect 
of the maximum likelihood approach is that it lacks decision-theoretic and 
probabilistic supports. In fact, it does not incorporate the requirements 
of a decision-theoretic analysis and also fails to provide evaluation tools 
for the estimators it proposes. For instance, tests are not possible in a 
purely maximum likelihood context: it is necessary to call for frequentist 
justifications, even if those are based upon a likelihood ratio (see §5.2). 
1.4. Prior and Posterior Distributions 
Let us assume at this point that, in addition to the sample distribution, 
f(xIO), a prior distribution on 0, 7f(0), is available, i.e., that we deal with 
a complete Bayesian model. Chapter 3 considers the preliminary problem 
of deriving this distribution from the prior information. Given these two 
distributions, we can construct several distributions, namely: 
( a) the joint distribution of (0, x), 
r.p(0, x) = f(xIO)7f(O); 
(b) the marginal distribution of x, 
m(x) = J 
r.p(0, x) dO 
= J 
f(xIO)7f(O) dO; 
(c) the posterior distribution of 0, obtained by Bayes's formula, 
f(xIO)7f( 0) 
7f(Olx) = J f(xIO)7f(O) dO 
f(xIO)7f(O) 
m(x) 
Example 1.15 Using Bayes's example, if x rv B(n,p) and p rv Be(a,(3) 
(with a = (3 = 1 in the particular case of Bayes), 
f(xlp) = (:)pX(l-Pt- x , 
x=O,l, ... ,n, 
1 
7f(p) = B(a,(3)pa-l(1-p)f3-1 , 
O:Sp:S1. 
8 This example also exhibits a limitation of the invariance mentioned above: 
when y '" Np(9,Ip), the maximum likelihood estimator of>. = 119112 is IlyW = 
x '" X~(>'), which differs from the maximum likelihood estimator based on x 
(see Exercise 3.45). 

22 
1. Introduction 
The joint distribution of (x,p) is then 
'P(x p) = 
(~) 
p<>+x-l(l_ pt-x+,B-l 
, 
B(a,(3) 
and the marginal distribution of x is 
-
(~) 
-
m(x)- B(a,(3)B(a+x,n 
x+(3) 
_ (n) r(a + (3) r(a + x)r(n - x + (3) 
-
x r(a)r((3) 
r(a + (3 + n) 
, 
since the posterior distribution of p is 
p<>+x-l(l _ p),B+n-x-l 
7r(Plx) = 
B(a+x,(3+n-x) , 
i.e., a beta distribution Be(a + x, (3 + n - x). 
Among these distributions, the main tool of the Bayesian approach is 
the posterior distribution. In fact, this distribution works conditionally on 
the observations, thus operates automatically the inversion of probabilities 
defined in §1.2, while incorporating the requirement of the Likelihood Prin-
ciple. It thus avoids averaging over the nonobserved values of x, which is 
the essence of the frequentist approach. Indeed, the posterior distribution 
is the updating of the information available on (), due to the information 
contained in £(Olx), while 7r(()) represents the information available a priori. 
It may happen that the observations do not modify the distribution of 
some parameters. This is obviously the case when the distribution of x does 
not depend on these parameters but also when the number of parameters 
gets too large compared with the sample size (see also Exercise 1.30). 
Example 1.16 A general setting where this situation occurs is when the 
number of parameters is infinite, for instance, when the inference en-
compasses a whole distribution. Studden (1990) considers n observations 
Xl, ... ,Xn from a mixture of geometric distributions, 
Xcv 101 OX(1-0)dG(()), 
x taking its values in IN and the probability distribution G being un-
known. In this setup, G can be represented by the sequence of its non-
central moments Cl, C2, • . •• The likelihood function is then derived from 
P(X = k) = Ck -Ck+1' Studden (1990) shows that, although the Ci are con-
strained by an infinite number of inequalities (starting with C! > C2 > c1), 
it is possible to derive independent functions of the Ci'S, Pl,P2, ... , taking 
values in [0,1] and such that Ci only depends on PI, ... ,Pi (see Exercise 
1.36 for details). Therefore, if the prior distribution of Pl,P2, ... is 

1.4. Prior and Posterior Distributions 23 
+00 
7r(PI,P2, ... ) = II 7ri(Pi) , 
i=l 
and if the largest observation in the sample is k, the posterior distribution 
of Pk+2, ... does not depend on the observations: 
+00 
7r(Pk+2, .. ·lxI, ... ,xn ) = 7r(Pk+2, ... ) = II 7ri(Pi). 
6 
i=k+2 
Conversely, the marginal distribution does not involve the parameter 
of interest (). It is therefore rarely of direct use, except in the empirical 
Bayesian approach (see Chapter 8), since the posterior distribution is much 
more well adapted to inferential purposes. The marginal distribution can, 
however, be used in the derivation of the prior distribution if the available 
information has been gathered from different experiments, i.e., dealing with 
different ()'s as in meta-analysis (see Mosteller and Chalmers (1992) and 
Mengersen and Tweedie (1993)). 
Given a probability distribution 7r on (), the Bayesian inferential scope is 
much larger than in a classical perspective. For instance, not only the mean, 
the mode, or the median of 7r(()lx) can be computed, but also evaluations 
of the performances of these estimators (through their variance and higher-
order moments) are available. Moreover, the knowledge of the posterior 
distribution also allows for the derivation of confidence regions, through 
highest posterior density (HPD) regions, i.e., regions of the form 
{(); 7r(()lx) 2 k}, 
in both unidimensional and multidimensional cases. Similarly, it is possible 
to derive quite naturally the probability of an hypothesis Ha, by condition-
ing on the observations, i.e., Y"(8 E HaJx). Let us stress that the Bayesian 
approach is the only one justifying such an expression since, the expression 
P(() = 5.2) = 0.95 is meaningless unless () is a random variable. From a 
Bayesian point of view, this expression signifies that we are ready to bet 
that () is equal to 5.2 with a 95/5 odd ratio or, in other words, that the 
uncertainty about the value of () is reduced to a 5% zone. Chapters 4 and 
5 are devoted to the study of estimation techniques which incorporate the 
decisional requirements. We just illustrate the simplicity of this derivation 
by constructing a confidence interval in the following example: 
Example 1.17 Consider x rv N((),l) and () rv N(O,lO). Therefore, for a 
given9 x, 
9 The proportionality symbol ex: is to be taken for functions of 8 (not of x). 
While being entirely rigorous, computations using proportionality signs lead to 
greater efficiency in the derivation of posterior distributions. In fact, probability 
densities are uniquely determined by their functional form and the normalizing 
constant can be recovered, when necessary, at the end of the computation. This 
technique will therefore be used extensively in this book. 

24 
1. Introduction 
and Blx '" Nn~x, iV. A natural confidence region is then 
C = {B; 1f(Blx) > k} 
= {B; IB - ~~ xl > k'} 
We can also associate a confidence level 0: with this region in the sense that, 
if Za/2 is the 0:/2 quantile of N(O, 1), 
Co ~ [:~ x - z",,~, :~ x + zO/2~l 
has a posterior probability (1 - 0:) of containing B. 
We will see in Chapter 8 that the posterior distributions can sometimes 
be decomposed into several levels according to a hierarchical structure, the 
parameters of the first levels being considered as random variables with 
additional prior distributions. But this decomposition is instrumental and 
does not modify the fundamental structure of the Bayesian model. A prob-
lem we did not mention above is that, although all posterior quantities are 
automatically defined from a conceptual point of view as integrals with re-
spect to the posterior distribution, it may be quite difficult to provide a 
numerical value in practice and, in particular, an explicit form of the pos-
terior distribution cannot always be derived. In fact, the complexity of the 
posterior distributions increases when the parameters are continuous and 
when the dimension of e is large. These computational difficulties are stud-
ied in Chapter 9 and some general solutions are provided. Still, they should 
not be considered as a major drawback of the Bayesian approach. Indeed, 
computational Statistics is currently undergoing such a rapid development 
that we can clearly reject the notion of a prior distribution chosen for its 
computational tractability, even though we still rely on these particular 
distributions to present simpler and clearer examples in this book. On the 
contrary, it is indeed stimulating to see that we are getting closer to the 
aim of providing more powerful and more efficient statistical tools because 
of these new computational techniques, as they allow for the use of more 
complex prior distributions which are more representative of the available 
prior information. 

1.5. Improper Prior Distributions 25 
1.5. Improper Prior Distributions 
When the parameter B can be considered as a random variable with known 
probability distribution 7r, we saw in the previous section that Bayes's The-
orem is the basis of Bayesian inference, since it leads to the posterior dis-
tribution. In most cases, however, the prior distribution is determined on 
a subjective or theoretical basis which provides a a-finite measure on the 
parameter space 8 instead of a probability measure, i.e., a measure 7r such 
that 
17r( B) dB = +00. 
In such cases, the prior distribution is said to be improper (or generalized). 
(An alternative definition of generalized Bayes estimators is considered in 
Chapter 2.) 
When this distribution stems from subjective reasons, i.e., when the 
decision-maker is weighting the relative likelihoods of different parts of the 
parameter space 8 (see Chapter 3), it really makes sense that for large 
parameter spaces, for instance when 8 is noncountable, the sum of these 
weights, i.e., the measure of 8, should be infinite. 
Example 1.18 Consider a distribution f(x-B) where the location parameter 
B is in JR with no restriction. If no prior information is available on the 
parameter B, it is quite acceptable to consider that the likelihood of an 
interval [a, bj is proportional to its length b - a, therefore that the prior is 
proportional to the Lebesgue measure on JR. This was also the distribution 
selected by Laplace (see Example 1.8). 
6 
When such improper prior distributions are derived by 'automatic' 
methods from the density f(xIB) (see Chapter 3), they seem more open to 
criticism but let us point out that: 
(1) These automatic approaches are usually the only way to derive prior 
distributions in "noninformative" settings, i.e., in cases where the only 
available (or retained) information is the knowledge of the sample dis-
tribution, f(xIB). This generalization of the usual Bayesian paradigm 
thus makes possible a further extension of the scope of Bayesian tech-
niques. 
(2) The performances of the estimators derived from these generalized dis-
tributions are usually good enough to justify these distributions. More-
over, they often permit recovery of usual estimators like maximum like-
lihood estimators, thus guaranteeing a closure of the inferential field 
by presenting alternative approaches at the boundary of the Bayesian 
paradigm. 
(3) The generalized prior distributions often occur as limits of proper dis-
tributions (according to various topologies). They can thus be inter-
preted as extreme cases where the reliability of the prior information 

26 
l. Introduction 
has completely disappeared and seem to provide a more robust (or 
more objective) answer in terms of a possible misspecijication of the 
prior distribution (i.e., a wrong interpretation of the sparse prior in-
formation). 
(4) Such distributions are generally more acceptable to non-Bayesians, 
partly for the reasons (2) and (3), but also because they may have 
frequentist justifications such as: 
(i) minimaxity, which is related to the usually improper "least favorable 
distributions" (see Chapter 2); 
(ii) admissibility, as admissible estimators are most often corresponding 
to proper and some improper distributions (see Chapter 6); and 
(iii) invariance, as the best equivariant estimator is a Bayes estimator 
for the generally improper Haar measure associated with the trans-
formation group (see Chapter 7). 
These reasons are not necessarily convincing enough for all Bayesians (see 
for instance, de Finetti (1974) who proposes an approach based on additive, 
not O"-additive, measures), but the inclusion of improper distributions in the 
Bayesian paradigm allows for a closure of the inferential scope (figuratively 
as well as topologically). 
From a more practical perspective, the fact that the prior distribution 
is improper weakens the above symmetry between the observations and the 
parameters, but as long as the posterior distribution is defined, Bayesian 
methods apply as well. In fact, the notion of conditional measures is not 
clearly defined in measure theory, although Hartigan (1983) advocates such 
an extension, but the usual convention is to take the posterior distribution 
7r(elx) associated with an improper prior 7r as given by Bayes's formula 
f(xle)7r(e) 
7r(elx) = Ief(xle)7r(e) de' 
when the "marginal distribution" Ie f(xle)7r(e) de is well defined. 
Example 1.18 (Cont.) If f(x - e) is the normal distribution with mean 
e and 7r( e) = c, an arbitrary constant, the "marginal distribution" is the 
measure 
m(x) = cj+oo ~ 
exp {-(x - e)2/2} de = c 
-00 
V 27r 
and, by Bayes's formula, the posterior distribution of e is 
i.e., N(x, 1). Note that the constant c does not play any role in the posterior 
distribution and that the posterior distribution is actually the likelihood 
function. Therefore, even though improper priors cannot be "normalized," 

1.5. Improper Prior Distributions 27 
it does not matter since· the constant is of no interest for the statistical 
inference (see Chapter 5 for an exception). 
D 
Since, according to the Bayesian version of the Likelihood Principle, 
only posterior distributions are of importance, this generalization should 
be used similarly to "regular" posterior distributions, when it is defined, 
even though the interpretation of the prior distribution is more delicate. 
For instance, in Example 1.18, the relative prior weight of any interval is 
null but this does not mean that this interval is a priori unlikely. Actually, 
an interpretation of improper priors as regular prior distributions may lead 
to difficulties like marginalization paradoxes (see Chapter 3) because the 
usual calculus of conditional probability does not apply in this setting. It 
may also happen that, for some observations x, the posterior distribution 
is not defined. The usual solution is to determine the improper answer 
as a limit for a sequence of proper distributions (while also checking the 
justifications of the improper distribution). 
Example 1.19 Consider a binomial observation, x rv B(n,p), as in the 
original example of Bayes. Some authors (see Novick and Hall (1965) and 
Villegas (1977)) reject the choice of the uniform distribution on [0,1] as 
"automatic" prior distribution, because it seems to be biased against the 
extreme values, 0 and 1. They propose to consider instead the Haldane 
(1931) prior 
In this case, the marginal distribution, 
m(x) = fa1 [P(I- p)t1 (:)px(1- p)n-xdp 
= B(x,n - x), 
is only defined for x =I=- 0, n . Therefore, 7r(plx) does not exist for these 
two extreme values of x. For the other values, the posterior distribution is 
Be(x, n-x), with posterior mean x/n, which is also the maximum likelihood 
estimator. 
The difficulty in 0 and n can be overcome as follows. The prior measure 
7r* appears as a limit of "unnormalized" beta distributions, 
when a and f3 go to O. These distributions 7r a.,j3 lead to beta posterior dis-
tributions, Be(a+x, f3 +n -x), notwithstanding the lack ofthe normalizing 
factor, since the choice of the constant in the prior distribution is irrelevant. 
The posterior distribution 7ra.,j3(plx) has the expectation 
81r
() 
x+a 
a.,j3 x = a + {3 + n' 

28 
1. Introduction 
which goes to x/n when a and f3 go to o. If the posterior mean is the 
quantity of interest, we can then extend the inferential procedure to the 
cases x = 0 and x = n by taking also x/n as a formal Bayes estimator. 6. 
Example 1.20 Consider x rv N(O, (12). It follows from invariance considera-
tions that an interesting prior distribution on (1 is the measure 11"((1) = 1/(1 
(see Chapter 7). It gives the posterior distribution 
_x2 /2u2 
1I"((12Ix) ex: e 
2 
' 
(1 
which is not defined for x = O. However, due to the continuity of the random 
variable x, this difficulty is of little importance compared with Example 
1.19. 
6. 
Obviously, these limiting arguments are only ad hoc expedients which 
are not always justified, in particular, because the resulting estimator may 
depend on the choice of the converging sequence. An example of this phe-
nomenon is provided by Richard (1973) (see also Bauwens, 1991) in the case 
of a normal distribution N((},(12), when 11"((}) is the Lebesgue measure and 
(1-2 is distributed according to a gamma distribution O(a, s~), i.e., when 
11"((}, (12) ex: 
1 
e-8~/2u2 . 
(12(<>+1) 
, 
the estimator of () then depends on the behavior of the ratio s~/ (a -1) when 
both numerator and denominator go to o. Moreover, when estimating a 
discontinuous function of (), the estimator for the limiting distribution may 
differ from the limit of the estimators. This is, for instance, the case in 
testing theory with the Jeffreys-Lindley paradox (see Chapter 5). Finally, 
there may be setups where improper prior distributions cannot be used at 
all, like in mixture estimation (see Chapter 9) or in testing theory when 
testing two-sided hypotheses (see DeGroot, 1973, and Chapter 5). 
It is thus important to exercise additional caution when dealing with 
improper distributions in order to avoid ill-defined distributions. In this 
book, improper distributions will be used under the implicit assumption 
that the corresponding posterior distributions are defined. Let us stress 
again that the main justification for using improper prior distributions is 
to provide a completion of the Bayesian inferential field for subjective, ax-
iomatic (in relation with complete class results, see Chapter 6), and practi-
cal reasons. This extension does not modify the complexity of the inference 
however, since the posterior distribution is truly a probability distribution. 
1.6. The Bayesian Choice 
To close this Introduction, let us insist once more on the coherence of the 
axioms of Bayesian statistical inference. By modeling the unknown param-
eters of the sampling distribution through a probability structure, i.e., by 

Exercises 29 
"probabilizing uncertainty", the Bayesian approach authorizes a quanti-
tative discourse on these parameters. It also allows incorporation in the 
inferential procedure of the prior information and of the imprecision of this 
information. Besides, apart from subjective and axiomatic arguments in 
favor of the Bayesian approach, which is the only system allowing for con-
ditioning on the observations (and thus for an effective implementation of 
the Likelihood Principle), Bayes estimators are also quintessential for the 
frequentist optimality notions of Decision Theory. In fact, they can provide 
essential tools even to those who reject prior elicitation and the Bayesian 
interpretation of reality. 
Exercises 10 
Section 1.1 
1.1 * (Kelker, 1970) A vector x E lRP is distributed according to a spherically 
symmetric distribution if e.x has the same distribution than x for every 
orthogonal transform e. 
a. Show that, when a spherically symmetric distribution has a density, it 
is a function of xtx only. 
b. Show that, if the density of x is 'P(xtx), the density of r = Ilxll is 
proportional to 
and give the proportionality coefficient. 
c. Show that, if x = 
(x~, x~)' with Xl E IRq and X2 E IRp-q, and IIxl12 = 
IIxll12 + Ilx2112, the density of (rl,r2) = (1Ixlll, IIx211) is proportional to 
d. Deduce that 
u = 
IlxlW 
IIxll12 + IIx2112 
is distributed according to a beta distribution Be(q/2, (p - q)/2). 
e. Conclude that 
is distributed according to the F-distribution Fp-q,q independently of 
the spherically symmetric distribution of x. Deduce that the F-ratio is a 
robust quantity in the sense that its distribution is constant on a range 
of spherically symmetric distributions. 
1.2* (Gourieroux and Monfort, 1989) This exercise points out that the bound-
ary between parametric and nonparametric models is quite difficult to de-
termine. However, in the second case, the "parameter" cannot be identified. 
a. Show that a c.dJ. is characterized by the values it takes at the rational 
numbers. 
10 The exercises with asterisks are more advanced but offer a broader view of the 
topics treated in each chapter. They can be be considered as useful complements 
or as a guided lecture of relevant papers by most readers. 

30 
1. Introduction 
b. Deduce that the collection of the c.dJ.'s on lR has the power of contin-
uum (i.e., the cardinal of the set of the parts of IN) and thus that all 
probability distributions on lR can be indexed by a real parameter. 
1.3 Show that, if Xl, ... ,Xn are known explanatory variables and YI, ... ,Yn are 
distributed as IE[Yi) = bXi, the least squares estimator of b, solution of 
n 
mln 2)Yi - bXi)2, 
i=l 
is also a maximum likelihood estimator under a normality assumption. 
Section 1.2 
1.4 Derive the probabilities of Example 1.7 from the approximation 
""() 
1 
_x2 /2 
':l:' -x ~ --e 
, 
v'27Tx 
which is valid when X is large. 
1.5 An examination has 15 questions, each with 3 possible answers. Assume 
that 70% of the students taking the examination are prepared and answer 
correctly each question with probability 0.8; the remaining 30% answer at 
random. 
a. Characterize the distribution of S, score of a student if one point is 
attributed to each correct answer. 
b. Eight good answers are necessary to pass the examination. Given that 
a student has passed the examination, what is the probability that he 
was prepared? 
1.6 Prove the discrete and continuous versions of Bayes's Theorem. 
1. 7* (Romano and Siegel, 1986) The Simpson paradox provides an illustration 
of the need for a conditional approach in Statistics. Consider two medical 
treatments, TI and T2, TI being applied to 50 patients and T2 to 50 others. 
The result of the experiment gives the following survival percentages: 40% 
for treatment TI, 32% for treatment T2. Therefore, treatment TI seems 
better since it leads to an higher survival rate. However, if age is taken into 
account, dividing the subjects between 'juniors' (50) and 'seniors' (50), the 
success rates are described in the following table: 
TI 
T2 
junior 
40 
50 
senior 
10 
35 
and TI is worse than T2 in both cases. Explain the paradox in terms of 
Bayes's Theorem. 
Section 1.3 
1.8 A statistic S is said to be ancillary if its distribution does not depend on 
the parameter () and it is said to be complete if IEo[g(S)) = 0 for every () 
implies g( 8) == O. Show that, if S is complete and minimal sufficient, it is 
independent of every ancillary statistic. (Note: This result is called Basu's 
Theorem. The reverse is false.) 
1.9 Consider a sample Xl, ... ,Xn of i.i.d. variables with c.dJ. F. 

Exercises 31 
a. Give the density of the order statistic. 
b. Show that 0 = (X(1) , ... , X(n») is sufficient. What is the conditional 
distribution of (Xl, ... , Xn) given 07 
c. Consider Xl, ... , Xn Li.d. with totally unknown density. Show that 0 is 
then complete. 
1.10 a. Show that a statistic T is sufficient if and only if 
t'(8Ix) ()( t'(8IT(x)). 
b. Consider 
u(X) = {x'; t'(8Ix) ()( t'(8Ix')}. 
Show that u is minimal sufficient. 
c. Apply to the case when Xl, ... , Xn are Li.d. Cauchy (8,1). 
1.11 Show that u is minimal sufficient if and only if it indexes the different 
likelihood functions t'(8Ix). 
1.12 (Berger and Wolpert, 1988, p. 21) Consider X with support {I, 2, 3} and 
distribution f(· I 0) or f(· 11) where 
X 
1 
2 
3 
f(xIO) 0.9 0.05 0.05 
f(xI1) 0.1 0.05 0.85 
Show that the procedure which rejects the hypothesis Ho : 8 = 0 (to accept 
Hl : 8 = 1) when X = 2,3 has a probability 0.9 to be correct (under Ho 
as well as under the alternative). What is the implication of the Likelihood 
Principle when X = 27 
1.13 Show that the Stopping Rule Principle given in Example 1.13 is a conse-
quence of the Likelihood Principle for the discrete case. (Note: See Berger 
and Wolpert (1988) for the extension to the continuous case.) 
1.14 For Example 1.13, show that the stopping rule T is finite with probability 
1. (Hint: Use the law of the iterated logarithm. See Billingsley, 1986.) 
1.15 (Raiffa and Schlaifer, 1961) Show that, if z rv f(zI8) and if x = t(z), x is a 
sufficient statistic if and only if for every prior 7r on 8, 7r(8Ix) = 7r(8Iz). 
1.16 Consider Xl, ... ,xn distributed according to Exp()..). The data is censored 
in the sense that there exist n random variables Yl, ... ,Yn distributed ac-
cording to f(y), independent of ).., and Zl = Xl 1\ Yl, ... , Zn = Xn 1\ Yn are 
the actual observations. 
a. Show that, according to the Likelihood Principle, the inference on ).. 
should not depend on f. 
b. Extend this independence to other types of censoring. 
1.17 Compare the lengths of the confidence intervals at level 10% in the setting 
of Example 1.14. 
1.18 (Berger, 1985a) In the setting of Example 1.11, show that, for the UMPU 
test of Ho : p = 1/2, the null hypothesis will be accepted or rejected at level 
5%, depending on the distribution considered. Deduce that the frequentist 

32 
1. Introduction 
theory of tests is not compatible with the Likelihood Principle. (Hint: See 
Chapter 5 for definitions.) 
1.19 This exercise aims at generalizing Examples 1.11 and 1.12 in the contin-
uous case by showing that there can also be incompatibility between the 
frequentist approach and the Likelihood Principle in continuous settings. 
a. If f(xIB) is a density such that x is a complete statistic, show that there 
no other density g(xIB) such that the two likelihood functions £f(Blx) = 
f(xIB) and £g(Blx) = g(xIB) are proportional (in B) for every x. 
b. Consider now a sample Xl, ... , Xn from f(xIB). We assume that there 
exists a complete sufficient statistic T(XI' ... , Xn) of dimension 1 and an 
ancillary statistic S(XI, ... ,xn) such that the couple (T, S) is a one-to-
one function of (Xl, ... ,Xn). Show that, if there exists another density 
g(XI, . .. ,xnIB) such that the two likelihood functions are proportional, 
the proportionality factor w only depends on S(XI, ... , Xn). 
c. In the particular case when f(xIB) is the exponential density, f(xIB) = 
Be-ex, give an example of a density g(xI, ... ,xnIB) such that the two 
likelihood functions are proportional. (Hint: Find an ancillary statistic 
S and derive a function h(XI, ... , xn) depending only on S(XI, ... , Xn) 
such that lEe[h(XI, ... ,xn)] = 1.) 
The following exercises (1.20 to 1.29) present some additional aspects of 
maximum likelihood estimation: 
1.20 Consider a Bernoulli random variable Y rv B([l + ee]-l). 
a. If y = 1, show that there is no maximum likelihood estimator of B. 
b. Show that the same problem occurs when YI, Y2 rv B([l + eerl) and 
Yl = Y2 = 0 or YI = Y2 = 1. Give the maximum likelihood estimator in 
the other cases. 
1.21 Consider Xl, X2 two independent observations from C(B, 1). Show that, when 
IXI - x21 > 2, the likelihood function is bimodal. Find examples of Xl, X2, X3 
i.i.d. C(B, 1) for which the likelihood function has three modes. 
1.22 The Wei bull distribution We(a, c) is widely used in engineering and relia-
bility. Its density is given by 
a. Show that, when c is known, this model is equivalent to a Gamma model. 
b. Give the likelihood equations in a and c and show that they do not allow 
for explicit solutions. 
c. Consider an i.i.d. Xl, ... , xn sample from We(a, c) censored from the 
right in Yo. Give the corresponding likelihood function when a and c 
are unknown and show that there is no explicit maximum likelihood 
estimators in this case either. 
1.23* (Robertson et al., 1988) For a sample Xl, ... , x n , and a function f on X, the 
isotonic regression of f with weights Wi is the solution of the minimization 
in 9 of 
n 
i=l 

Exercises 33 
under the constraint g(Xl) ::; ... ::; g(Xn). 
a. Show that a solution to this problem is obtained by the pool-adjacent-
violators algorithm: if f is not isotonic, find i such that f(Xi-l) > f(Xi), 
replace f(Xi-d and f(xd by 
!*(Xi) = !*(Xi-l) = Wi/(Xi) +Wi-I!(Xi-I) , 
Wi + Wi-l 
and repeat until the constraint is satisfied. Take 9 = f*. 
b. Apply to the case n = 4, f(xI) = 23, f(X2) = 27, f(X3) = 25, f(X4) = 28, 
when the weights are all equal. 
1.24* (Cont.) The simple tree-ordering is obtained when one compares some 
treatment effects with a control state. The isotonic regression is then ob-
tained under the constraint g(Xi) 2: g(Xl) for i = 2, ... , n. 
a. Show that the following algorithm provides the isotonic regression g*: if 
f is not isotonic, assume w.l.o.g. that the f(Xi) are in increasing order 
(i 2: 2). Find the smallest j such that 
and take g*(Xl) = Aj = g*(X2) = ... = g*(Xj), g*(Xj+l) = f(xj+I), .... 
b. Apply to the case where n = 5, f(Xl) = 18, f(X2) = 17, f(X3) = 12, 
f(X4) = 21 and f(X5) = 16, with Wl = W2 = W5 = 1 and W3 = W4 = 3. 
1.25 (Olkin et al., 1981) Consider n observations Xl, ... ,xn from B(k,p) where 
both k and p are unknown. 
a. Show that the maximum likelihood estimator of k, k, is such that 
n 
n 
(k(l - p)t 2: II (k - Xi) 
and ((k + 1)(1 - p)t < II (k + 1 - Xi), 
i=l 
i=l 
where p is the maximum likelihood estimator of p. 
b. If the sample is 16, 18,22,25,27, show that k = 99. 
c. If the sample is 16, 18,22,25,28, show that k = 190 and conclude on the 
stability of the maximum likelihood estimator. 
1.26 Give the maximum likelihood estimator of p for Example 1.5 if the other 
parameters are known and if there are two observations. Compare with the 
mean of the posterior distribution if p rv U[O,l]' 
1.27 (Basu, 1988) An urn contains 1000 tickets; 20 are tagged () and 980 are 
tagged lOB. A ticket is drawn at random with tag x. 
a. Give the maximum likelihood estimator of B, 8(x), and show that 
P(8(x) = (}) = 0.98. 
b. Suppose now there are 20 tickets tagged Band 980 tagged aiB (i ::; 980), 
such that ai E [10,10.1] and ai i= aj (i i= j). Give the new maximum 
likelihood estimator, 8', and show that P(8'(x) < lOB) = 0.02. Conclude 
about the appeal of maximum likelihood estimation in this case. 

34 
1. Introduction 
1.28 (Romano and Siegel, 1986) Given 
(x > 0), 
show that f is integrable and that there exist a, b > 0 such that 
lb af(x) dx = 1 and Ib af(x) dx = 0.99. 
For the distribution with density 
give the maximum likelihood estimator, 8(y), and show that P(8(y) > 
100) = 0.99. 
1.29 (Romano and Siegel, 1986) Consider Xl,X2,X3 i.i.d. N(0,(J"2). 
a. Give the maximum likelihood estimator of (J"2 if (Xl,X2,X3) = (9,10,11) 
or if (Xl,X2,X3) = (29,30,31). 
b. Given three additional observations X4, X5, X6, give the maximum like-
lihood estimator if (Xl, ••• ,X6) = (9,10,11,29,30,31). Does this result 
contradict the Likelihood Principle? 
Section 1.4 
1.30 Given a proper distribution 7r(0) and a sampling distribution f(xO), show 
that the only case when 7r(OJx) and 7r(0) are identical occurs when f(xJO) 
does not depend on O. 
1.31 Consider a prior distribution 7r positive on e and x '" f(xJO). Assume that 
the likelihood £(8Jx) is bounded, continuous, and has a unique maximum 
O(x). 
a. Show that, when considering a virtual sample Xn = (x, ... , x) made of 
n replications of the original observation x, the posterior distribution 
7r(OJXn) converges to a Dirac mass in O(x). 
b. Derive a Bayesian algorithm for computing maximum likelihood estima-
tors. 
1.32* Given a couple (x, y) of random variables, the marginal distributions f(x) 
and f(y) are not sufficient to characterize the joint distribution of (x, y). 
a. Give an example of two different bivariate distributions with the same 
marginals. 
b. Show that, on the contrary, if the two conditional distributions f(xJy) 
and f(yJx) are known, the distribution of the couple (x, y) is also defined. 
c. Show that this property does not necessarily hold if f(xJy) and f(x) are 
known, i.e., that several distributions f(y) can relate f(x) and f(xJy). 
(Hint: Exhibit a counterexample.) 
d. Give some sufficient conditions on f(xJy) for the above property to be 
true. (Hint: Relate this problem to the theory of complete statistics.) 
1.33 Consider Xl, ... ,Xn i.i.d. P()"). Show that L~=l Xi is a sufficient statistic 
and give a confidence region as in Example 1.17 when 7r()..) is a 9(a, (3) 
distribution. For a given a level, compare its length with an equal tail 
confidence region. 

Exercises 35 
1.34 Give the posterior and the marginal distributions in the following cases: 
(i) xiO" '" N(O, 0"2), 1/0"2 '" 9(1,2); 
(ii) xi). '" P()'), ). '" 9(2, 1); and 
(iii) xip '" Neg(lO,p), P'" Be(I/2, 1/2). 
1.35 Show that, for a sample Xl, ... ,xn from a distribution with density f(xiO), 
the posterior distribution derived by actualizing sequentially the posterior 
distributions, i.e., by acting as if the observations Xi were obtained one at 
a time and the posterior distribution updated after each Xi was observed, 
is identical to the posterior distribution obtained by considering the whole 
sample (Xl, ... , Xn) at once. 
1.36* (Studden, 1990) In the setting of Example 1.16, we define the canonical mo-
ments of a distribution and show that they can be used as a representation 
of this distribution. 
a. Show that the two first moments Cl and C2 are related by the two fol-
lowing inequalities: 
and that the sequence (Ck) is monotonically decreasing to O. 
b. Consider a kth degree polynomial 
k 
Pk(X) = 2: aix i. 
i=O 
Deduce from 
11 P~(x)g(x) dx ;::: 0 
(1.8) 
that 
(1.9) 
where 
c,~ e 
Cl 
C2 
... 
c, ) 
C2 
C3 
... 
C~~l 
.. . 
Ck 
Ck+l 
... 
C2k 
and at = (ao, al, ... , ak). 
c. Show that for every distribution g, the moments Ck satisfy 
1 
> O. 
(1.10) 
(Hint: Interpret (1.9) as a property of Ck.) 
d. Using inequalities similar to (1.8) for the polynomials t(1 -
t)P~(t), 
tP~(t), and (1 -
t)P~(t), derive the following inequalities on the mo-
ments of g: 

36 
1. Introduction 
Cl -
C2 
C2 -
C3 
Ck-l -
Ck 
C2 -
C3 
C3 -
C4 
Ck -
Ck+l 
> 0, 
(1.11) 
Ck-l -
Ck 
C2k-l -
C2k 
Cl 
C2 
Ck 
C2 
C3 
Ck+l 
> 0, 
(1.12) 
Ck 
Ck+l 
C2k-l 
1 -
Cl 
Cl -
C2 
Ck-l -
Ck 
Cl -
C2 
C2 -
C3 
Ck -
Ck+l 
> 0. 
(1.13) 
Ck-l -
Ck 
C2k-2 -
C2k-l 
e. Show that (1.10) (resp. (1.11)) induces a lower (resp. upper) bound f2k 
(resp. C2k) on C2k and that (1.12) (resp. (1.13)) induces a lower (resp. 
upper) bound f2k-l (resp. C2k-l) on C2k-l. 
f. Defining Pk as 
Ck -
fk 
Pk = -_--, 
Ck -
fk 
show that the relation between (Pl"",Pn) and (Cl, ... ,Cn ) is one-to-one 
for every n and that the Pi are independent. 
g. Show that the inverse transform is given by the following recursive for-
mulas. Let us define 
Then 
qi = 1 - pi, 
(i = Piqi-l 
1 
Sl,k = (1 + ... + (k 
(k 2': 1), 
k-j+l 
Sj,k = 2: (iSj-l,i+j-l 
(j 2': 2), 
i=l 
Cn 
= Sn,n. 
(i 2': 2). 
Section 1.5 
1.37 (Raiffa and Schlaifer, 1961) Consider a Be(o;m, (l-m)o;) prior on P E [0,1]. 
Show that, if m is held fixed and 0; approaches 0, the prior distribution 
converges to a two-point mass distribution with weight m on P = 1 and 
(1 - m) on P = 0. Discuss the drawbacks of such a setting. 
1.38 (Bauwens, 1991) Consider Xl, ... ,Xn Li.d. N(B, (J'2) and 
a. Compute the posterior distribution 71'( B, (J'2Ixl, ... ,xn ) and show that it 
only depends on x and 8 2 = L~=l (Xi - X? 
b. Derive the posterior expectation ]E1I'[Blxl, ... ,xn ] and show that its be-
havior when 0; and 80 both converge to ° 
depend on the limit of the 
ratio 86/0; - 1. 
1.39 Show that if the prior 7r(B) is improper and the sample space X is finite, 
the posterior distribution 7r(Blx) is not defined for some values of x. 

Exercises 37 
1.40 Consider Xl, ... , Xn distributed according to N({}j, 1), with {}j rv N(p" (J2) 
(1 :::; j :::; n) and 7r(p,,(J2) = (J-2. Show that the posterior distribution 
7r(p" (J2Ixl, ... , Xn) is not defined. 
1.41 In the setting of Example 1.5, show that the maximum likelihood estimator 
is not defined when all the parameters are unknown. Similarly, show that it 
is not possible to use an improper prior to estimate these parameters. (Hint: 
Write the likelihood as a sum of n + 1 terms, depending on the number of 
observations allocated to the first component.) 
1.42 Construct a limiting argument as in Example 1.19 to solve the undetermi-
nacy of Example 1.20. Derive the posterior mean. 
1.43 Show that, if the prior distribution is improper, the "marginal distribution" 
is also improper. 

2 
Decision-Theoretic Foundations of 
Statistical Inference 
2.1. Evaluating Estimators 
Considering that the overall purpose of most inferential studies is to provide 
the statistician (or a client) with a decision, it seems reasonable to ask for an 
evaluation criterion of decision procedures which assesses the consequences 
of each decision and depends on the parameters of the model, i.e., the true 
state of the "world" (or of "Nature"). These decisions can be of various 
kinds, ranging from buying stock market shares depending on their future 
returns () to stopping an agriculture experiment on the productivity () of 
a new crop species, and including estimation of the underground economy 
contribution to the U.S. GNP, (), or deciding whether the number () of home-
less people has increased since the last census. If no evaluation criterion is 
available, it is impossible to compare different decision procedures and ab-
surd solutions, like proposing {} = 3 for any real estimation problem or even 
more dramatically the answer one wants to impose, can only be eliminated 
by ad hoc reasoning. To avoid such reasoning implies a reinforced axiom-
atization of the statistical inferential framework, called Decision Theory. 
This augmented theoretical structure is necessary for Statistics to reach a 
coherence otherwise unattainable.1 
Although (almost) everybody agrees on the need for such an evaluation 
criterion, there is an important controversy running about the choice of this 
evaluation criterion. This difficulty even led some statisticians to totally 
1 The Bayesian approach is, from our point of view, the ultimate step in this 
quest for coherence. 

40 
2. Decision-Theoretic Foundations of Statistical Inference 
reject Decision Theory, on the basis that a practical determination of the 
decision-maker evaluation criterion is utterly impossible in most cases. This 
criterion is usually called loss and is defined as follows, if V denotes the set 
of possible decisions; 1) is called the decision space and most theoretical 
examples focus on the case V = e. 
Definition 2.1 A loss function is any function L from e x V in 
[0,+00). 
This loss function is supposed to evaluate the "penalty" (or error) 
L(O, d) associated with the decision d when the parameter takes the value 
O. In a more traditional setting of parameter estimation, when V is e or 
h(e), the loss function L(O, 8) measures the error made in evaluating h(O) 
by 8. Section 2.2 introduces a set of "rationality axioms" which ensures the 
existence of such a function in a decision setup. The actual determination 
of the loss is often awkward in practice, in particular, because the deter-
mination of the consequences of each action for each value of 0 is usually 
impossible when V and e are large (e.g., infinite). Moreover, in qualitative 
models, it may be delicate to quantify the consequences of each decision. 
We will see through paradoxes like the Saint-Petersburg paradox that even 
when the loss function seems obvious, for instance, when errors can be ex-
pressed as monetary losses, the actual loss function can be quite different 
from its "intuitive" and linear approximation. 
The complexity of determining the subjective loss function of the 
decision-maker often prompts the statistician to use "classical" (or canoni-
can losses, selected because of their simplicity and mathematical tractabil-
ity. Such losses are also necessary for a theoretical treatment of the deriva-
tion of optimal procedures, when there is no practical motivation for the 
choice of a particular loss function. The term classical is related to their 
long history, dating back to Gauss (1810) for the quadratic loss (2.6), when 
errors in terms of performance of estimators or. consequences of decisions 
were confused with errors in terms of the irreducible variability of ran-
dom variables (variance). But this attribute should not be taken as a value 
statement, since an extensive use of these losses does not legitimize them 
any further. In fact, the recourse to such "automatic" (or "generic") losses, 
although often justified in practice-it is still better to take a decision in a 
finite time using an approximate criterion rather that spending an infinite 
time to determine exactly the proper loss function-has generated a large 
part of the criticisms addressed to Decision Theory. It is however a funda-
mental basis of Bayesian Decision Theory that statistical inference should 
start with the rigorous determination of three factors: 
- the distribution family for the observations, f(xIO); 
- the prior distribution for the parameters, 71"(0); and 
- the loss associated with the decisions, L(O, 8); 
the prior and the loss (and even sometimes the sampling distribution) 
being derived from partially subjective considerations. Classical decision-

2.2. Existence of a Utility Function 41 
theoreticians usually omit the second point. The frequentist criticisms of 
the Bayesian paradigm often fail to take into account the problem of the 
construction of the loss function, even though this may be at least as com-
plicated as the derivation of the prior distribution. In addition, to presup-
pose the existence of a loss function implies that some information about 
the problem at hand is available. This information could therefore be used 
more efficiently by building up a prior distribution. Actually, Lindley (1985) 
states that loss and prior are difficult to separate and should be analyzed si-
multaneously. We will see in §2.4 an example of the duality existing between 
these two factors. We also mention in §2.5.4 how "classic" losses could be 
replaced by more intrinsic losses (similar to the noninformative priors intro-
duced in Chapter 3), when no information at all is available on the penalty 
associated with erroneous decisions or even with the parametrization of 
interest. 
In some cases, it is possible to reduce the class of acceptable loss func-
tions by invariance considerations, e.g., when the model is invariant under 
the action of a group of transformations. Such considerations apply as well 
to the choice of the prior distribution, as we will see in Chapter 7. It is 
also interesting to note that these invariance motivations are often used in 
other decision-theoretic approaches, where a drastic reduction of the class 
of inferential procedures is necessary to select a "best" solution. 
Example 2.1 Consider the problem of estimating the mean () of a normal 
vector, x rv Nn ((), E), where 17 is a known diagonal matrix with diagonal 
elements a'f (1 ::::; i ::::; n). In this case, 1) = e = IRP, and 8 stands for 
an evaluation of (). If no additional information is available on the model, 
it seems logical to choose the loss function so that it weights equally the 
estimation of each component, i.e., to use a loss of the form 
where L takes its minimum at O. Indeed, for such losses, the components 
with larger variances do not strongly bias the selection of the resulting 
estimator. In other words, the components with a larger variance are not 
overly penalized when the estimation errors (8i -
()i) are normalized by 
ai. The usual choice of L is the quadratic loss L(t) = t2 , i.e., the global 
estimation error is the sum of the squared componentwise errors. 
D" 
2.2. Existence of a Utility Function 
The notion of utility (defined as the opposite of loss) is used not only in 
Statistics but also in Economics and in other fields like Game Theory where 
it is necessary to order consequences of actions or decisions. Consequences 

42 
2. Decision-Theoretic Foundations of Statistical Inference 
(or rewards) are generic notions which summarize the set of outcomes re-
sulting from the decision-maker's action. In the simplest cases, it may be 
the monetary profit-positive or negative-resulting from the decision. In 
an estimation setup, it may be a measure of distance between the evalua-
tion and the true value of the parameter, as in Example 2.1. The axiomatic 
foundations of utility are due to Von Neumann and Morgenstern (1947) and 
led to numerous extensions, in particular in Game Theory. This approach is 
considered in a statistical framework by Wald (1950) and Ferguson (1967). 
Extensions and additional comments can be found in DeGroot (1970, Chap. 
7) and recent references on Utility Theory are Fishburn (1988) and Machina 
(1982, 1987). 
The general framework behind utility theory considers R, space of 
rewards, which is assumed to be completely known. For instance, R = JR. 
We also suppose that it is possible to order the rewards, i.e., that there 
exists a total ordering, ::5, on R such that, if rl and r2 are in R, 
(1) rl ::5 r2 or r2 ::5 rl; and 
(2) if rl ::5 r2 and r2 ::5 r3, then rl ::5 r3· 
These two properties seem to be minimal requirements in a decision-making 
setup. In particular, transitivity (2) is absolutely necessary to allow a com-
parison of decision procedures. Otherwise, we may end up with cycles like 
rl ::5 r2 ::5 r3 ::5 rl and be at a loss about selecting the best reward among 
the three. Section 2.6 presents a criterion which is intransitive (and thus 
does not pertain to Decision Theory). We denote by -< and rv the strict 
order and equivalence relations derived from ::5. Therefore, one and only 
one of the three following relations is satisfied by any couple (rl, r2) in R2: 
To proceed further in the construction of the utility function, it is 
necessary to extend the reward space from R to P, the space of proba-
bility distributions on R. This also allows the decision-maker to take into 
account partially randomized decisions and, moreover, it convexifies the 
reward space. 
Example 2.2 In most real-life setups, the rewards associated with an action 
are not exactly known when the decision is taken or, equivalently, some 
decisions involve a gambling step. For instance, in finance, the monetary 
revenue r E R = JR derived from stock market shares is not guarranteed 
when the share-holder has to decide from which company he/she should 
buy shares. In this case, V = {d1 , • •• ,dn } where dk represents the action 
"buy the share from company k." At the time of the decision, the rewards 
associated with the different shares are random dividends, only known by 
the end of the year. 
t::, 
The order relation ::5 is also assumed to be available on P. For instance, 
when the rewards are monetary, the order relation on P can be derived by 

2.2. Existence of a Utility Function 43 
comparing the average yields associated with the distributions P. Therefore, 
it is possible to compare two distributions of probability on R, P1 and P2 . 
We thus assume that :::S satisfies the extensions of the two hypotheses (1) 
and (2) to P: 
(Ad P1 ::::S P2 or P2 ::::S P1 ; and 
(A2) if P1 :::S P2 and P2 :::S P3, then P1 :::S P3. 
The order relation on R then appears as a special case of the order on P 
by considering the Dirac masses Or (r E R). 
The existence of the order :::S on P relies on the assumption that there 
exists an "optimal" reward, therefore, that there exists at least a partial 
ordering on the consequences, even when they are random. This is obviously 
the case when there exists a function U on R associated with :::S, such that 
P1 :::S P2 is equivalent to 
as in the above monetary example. This function U is called utility function. 
We now present an axiomatic system on :::S which ensures the existence of 
U. 
For simplicity's sake, we only consider here the set of bounded distri-
butions, PB, corresponding to the distributions for which there exist rl and 
r2 such that 
For Pl, P2 in PB, we define the mixture P = O'.P1 + (1- 0'.)P2 as the distri-
bution which generates a reward from P1 with probability 0'. and a reward 
from P2 with probability (1 - 0'.). For instance, O'.rl + (1 - 0'.)r2 is the dis-
tribution which gives the reward rl with probability 0'. and the reward r2 
with probability (1 - 0'.). Two additional assumptions (or axioms) are nec-
essary to derive the existence of a utility function on R. First, there must 
be conservation of the ordering under indifferent alternatives: 
(A3) if P1 ::::S P2, O'.P1 + (1 - O'.)P :::S O'.P2 + (1 - O'.)P for every PEP. 
For example, if the share buyers of Example 2.2 can compare two companies 
with dividend distributions P1 and P2 , they should be able to keep a ranking 
of the two companies if there is a chance (1 - 0'.) that both dividends are 
replaced by State bounds with dividend distribution P. The order relation 
must also be connected (or closed): 
(A4) if P1 :::S P2 :::S P3, there exist 0'. and (3 EjO, 1[ such that 
O'.P1 + (1 - 0'.)P3 :::S P2 :::S (3P1 + (1 - (3)P3. 
The last assumption then implies the following result: 
Lemma 2.1 If rl, r2, and r are rewards in R with rl -< r2 and 
rl :::S r :::S r2, there exists a unique v (0 ::; v ::; 1) such that 
r '"" vrl + (1- v)r2. 

44 
2. Decision-Theoretic Foundations of Statistical Inference 
Lemma 2.1 is actually the key to the derivation of the utility function, 
U, on n. Indeed, given rl and r2, two arbitrary rewards such that r2 -< rl, 
we can define U in the following way. For every r E n, consider 
(i) U(r)=v ifr2:::sr:::srl andrrvvrl+(1-v)r2; 
(ii) U(r) = l-::"vv if r :::S r2 and r2 rv vri + (1 - v)r; and 
(iii) U(r) = ~ if rl :::S rand rl rv vr + (1 - v)r2; 
In particular, U(rl) = 1 and U(r2) = O. Moreover, this function U preserves 
the order relation on n (see DeGroot, 1970, p. 105, for a proof). 
Lemma 2.2 If rl, r2, and r3 are three rewards in n such that 
r2 rv arl + (1 - a)r3 
Actually, the axioms (A3) and (A4) can be further reduced while Lemma 
2.2 still holds. It is indeed sufficient that they are satisfied on n only. The 
extension of the definition of the utility function to PB calls for an additional 
assumption. Given P such that P(h, r2]) = 1, define 
and 
Then the additional axiom, 
implies that, if r is equivalent to a(r)rl + (1- a(r))r2 for every r E [rl, r2], 
this equivalence must hold on average. In fact, note that f3 is derived from 
the expected utility, 
f3 = lEP[U(r)]- U(rl) , 
U(r2) - U(rt} 
and this assumption provides a definition of U on PB. As in Lemma 2.2 
where U is restricted to n, and as shown by the following result, Assump-
tion (A5) indicates that U provides a linearization (or a linear parametriza-
tion) of the order relation :::S on PB. Although slightly tautological- since 
it involves in its formulation the utility function we are trying to derive -
(A5) indeed leads to the following extension of Lemma 2.2 to PB. 
Theorem 2.3 Consider PI and P2 in PB. Then, 
if and only if 

2.2. Existence of a Utility Function 45 
Moreover, if U* is another utility function satisfying the above 
equivalence relation, there exist a > ° 
and b such that 
U*(r) = aU(r) + b. 
Proof. Consider rl and r2 such that 
(with rl -< r2). Since 
and 
p. 
IEP2[U(r)]- U(rt) 
U(r2) - IEP2[U(r)] 
2 '" 
r2 + 
rt, 
U(r2) - U(rl) 
U(r2) - U(rt) 
PI ~ P2 is truly equivalent to 
IEPl[U(r)]- U(rl) 
IEP2[U(r)]- U(rl) 
U(r2) - U(rl) 
:S 
U(r2) - U(rl) 
, 
i.e., IEPl [U (r)] :S IEP2 [U (r)]. Moreover, for any other utility function U*, 
there exist a and b such that U*(rl) = aU(rl) + b, U*(r2) = aU(r2) + b. 
The extension of this relation to every r En follows from Lemma 2.2 .•• 
Note that the above derivation does not involve any restriction on the 
function U. Therefore, it does not need to be bounded, although this condi-
tion is often mentioned in textbooks. It may be argued that this generality is 
artificial and formal, since subjective utility functions are always bounded. 
For instance, when considering monetary rewards, there exists a psycholog-
ical threshold like, say, $100,000,000, above which (most) individuals have 
an almost constant utility function. However, this upper bound varies from 
individual to individual and even more from individuals to companies or 
states. It is also important to incorporate "unacceptable" rewards, although 
the assumption (A4) prevents rewards with utility equal to -00. (This re-
striction implies that the death of a patient in a pharmaceutical study or 
a major accident in a nuclear plant have a finite "utility".) Moreover, most 
theoretical losses are not bounded. A counterpart of this generality is that 
the above results have only been established for PB. Actually, they can be 
extended to Pc, the set of distributions P in P such that IEP[U(r)] is finite, 
under the assumption that (AI)-(A5) and two additional hypotheses are 
satisfied for P£ (see Exercise 2.3). 
Theorem 2.4 Consider P and Q, two distributions in Pc. Then, 
P ~ Q if and only if 
IEP[U(r)] :S IEQ[U(r)]. 

46 
2. Decision-Theoretic Foundations of Statistical Inference 
Of course, Theorem 2.4 fails to deal with infinite utility distributions. If 
such distributions exist, they must be compared between themselves and a 
separate utility function constructed on this restricted class, since they are 
in a sense the only distributions of interest. However, the loss functions con-
sidered in the sequel are bounded from below, usually by O. Therefore, the 
corresponding utility functions, opposites of the loss functions, are always 
bounded from above and infinite reward paradoxes can be avoided. (Rubin 
(1984) and Fishburn (1987) provide reduced axiomatic systems ensuring 
the existence of a utility function.) 
Many criticisms have been addressed on theoretical or psychological 
grounds against the notion of rationality of decision-makers and the associ-
ated axioms (Ad-(A4). First, it seems illusory to assume that individuals 
can compare all rewards, i.e., provide a total ordering of P (or even of 
R), because their discriminating abilities are necessarily limited, especially 
about contiguous or extreme alternatives. The transitivity assumption is 
also too strong, since examples in sports or politics show that real-life or-
derings of preferences often lead to nontransitivity, as illustrated by Con-
dorcet and Simpson paradoxes (see Casella and Wells (1993) and Exercises 
1.7 and 2.10). More fundamentally, the assumption that the ordering can 
be extended from R to P has been strongly attacked, because it implies 
that a social ordering can be derived from a set of individual orderings 
and this is not possible in general (see Arrow (1951) or Blyth (1993». 
However, while recognizing this fact, Rubin (1987) notes that this impos-
sibility just implies that utility and prior are not separable, not that an 
optimal (Bayesian) decision cannot be obtained, and he gives a restricted 
set of axioms pertaining to this purpose. In general, the above criticisms 
are obviously valuable but cannot stand in front of the absolute need of 
an axiomatic framework validating decision-making under uncertainty. As 
already mentioned in Chapter 1, statistical modeling is and must be re-
ductive; although necessarily missing part of the complexity of the world, 
the simplified representation it gives of this very world allows statisticians 
and others to reach decisions. Decision Theory thus describes an idealized 
setting, under an ultimate rationality actual decision-makers fail to attain 
but aim at.2 
From a more practical point of view, the above derivation of the utility 
function can be criticized as being unrealistic. Berger (1985a) provides a 
few examples based on DeGroot (1970), deriving the utility function from 
successive partitions of the reward space (see also Raiffa and Schlaifer, 
1961). However, if R is large (e.g., noncountable), U cannot be evaluated 
for each reward r, even though the linearity exhibited by Lemma 2.2 allows 
for approximations when R c JR. In a multidimensional setup, linear ap-
2 To borrow from Smith (1984), to criticize the idealized structures of Decision 
Theory because of human limitations is somehow like attacking integration 
because some integrals can only be solved numerically. 

2.2. Existence of a Utility Function 47 
proximations are no longer possible unless one uses a linear combination of 
componentwise utilities, i.e., 
n 
U(rl, r2,···, rn) = L O!iUi(ri) 
i=l 
(see Raiffa (1968), Keeney and Raifa (1976) and Smith (1988) for a discus-
sion). In general, practical utility functions will thus only approximate the 
"true" utility functions. 
Even cases when the reward is purely monetary call for rigorous deter-
mination of the utility function, as U may be far from linear, especially for 
large rewards. This means that a gain of $3000 with probability 1/2 may 
not be equivalent to earning $1500 with certainty. To solve this paradox, 
Laplace (1795) introduced the notion of moral expectation, derived from the 
relative value of an increase of wealth, "absolute value divided by the total 
wealth of the involved person." Laplace deduces that the moral expecta-
tion "coincides with the mathematical expectation when the wealth becomes 
infinite compared with the variations due to uncertainty," i.e., that the util-
ity is indeed linear only around O. Otherwise, risk aversion attitudes slow 
down the utility curve, which is typically concave for large values of rewards 
and bounded above. (Persons with a convex utility function are called risk 
lovers, because they prefer a random gain to the expectation of this gain. 
Note that this attitude is quite understandable in a neighborhood of 0.) To 
construct the money utility function is obviously more cumbersome than to 
use a linear utility, but this derivation gives a more accurate representation 
of reality and can even prevent paradoxes like the following one: 
Example 2.3 (Saint-Petersburg Paradox) Consider a game where a coin is 
thrown until head appears. When this event occurs at the nth throw, the 
player gain is 3n , leading to an average gain of 
+00 
1 
L3n 2n = +00. 
n=l 
Every player should then be ready to pay an arbitrarily high entrance fee 
to play this game, even though there is less than a 0.05 chance to go farther 
than the fifth throw! This modeling does not take into account the fact that 
the fortune of every player is necessarily bounded and that he/she can only 
playa limited number of games. A solution to this paradox is to substitute 
for the linear utility function a bounded utility function, like 
r 
U(r) = -8 -+r 
(8)0, r>-8), 
and U(r) = -00 otherwise. This construction is quite similar to Laplace's 
moral expectation. An acceptable entrance fee e will then be such that the 
expected utility of the game is larger than the utility of doing nothing, i.e., 

48 
2. Decision-Theoretic Foundations of Statistical Inference 
IE[U(r - e)] ~ U(O) = O. 
Consider now a modification of the game where the player can leave the 
game at any time n and take the gain 3n if head has not appeared yet. The 
average gain at time n is then 
~2-n 
8 +3n 
' 
which can provide an optimal leaving time no, depending on the utility 
parameter 8, which somehow characterizes the risk aversion of the player 
(see Smith (1988) for a more thorough description). For instance, 8 may 
represent the fortune of the player. The particular choice of U can obviously 
be criticized, but a more accurate representation of the utility function re-
quires a detailed analysis of the motivations of the player (see also Exercise 
2.9). 
/::, 
2.3. Utility and Loss 
Let us switch back to a purely statistical setup. From a decision-theoretic 
point of view, the statistical model now involves three spaces: X, observa-
tion space, e, parameter space, and 'D, decision space (or action space). 
Statistical inference then consists of taking a decision d E 'D related to the 
parameter () E e based on the observation x EX, x and () being related 
by the distribution f(xIB). In most cases, the decision d will be to evalu-
ate (or estimate) a function of (), h(()), as accurately as possible. Decision 
Theory assumes in addition that each action d can be evaluated (Le., that 
its accuracy can be quantified) and lead to a reward r, with utility U(r) 
(which exists under the assumption of rationality of the decision-makers). 
From now on, this utility is written as U ((), d) to stress that it only depends 
on these two factors. In cases when other random factors are involved in U, 
we assume that U((), d) = IEo,d[U(r)]. Therefore, U((), d) can be seen as a 
measure of proximity between the proposed estimate d and the true value 
h( ()). 
Once the utility function has been constructed, we derive the corre-
sponding loss function 
L((), d) = -U((), d). 
In general, the loss function is supposed to be nonnegative, which implies 
that U((), d) ::; 0, therefore that there is no decision with infinite utility. The 
existence of a lower bound on L can be criticized as being too stringent, but 
it does avoid paradoxes as those mentioned above. It can also be argued 
that, from a statistical point of view, the loss function L indeed represents 
the loss (or error) due to a bad evaluation of the function of () of interest 
and therefore that even the best evaluation of this function, Le., when () is 

2.3. Utility and Loss 
49 
known, can induce at best a null loss. Otherwise, there would be a break 
of continuity around 0 which could even prevent the choice of a decision 
procedure. 
Obviously, except for the most trivial settings, it is generally impossible 
to uniformly minimize (in d) the loss function L(O, d) when 0 is unknown. 
In order to derive an effective comparison criterion from the loss function, 
the jrequentist approach proposes to consider instead the average loss (or 
jrequentist risk) 
R(O, 8) = lEe [L(O, 8(x»] 
= L 
L(O, 8(x»f(xIO) dx, 
where 8(x) is the decision rule, i.e., the allocation of a decision to each 
outcome x '" f(xIO) from the random experiment. The function 8, from X 
in 1), is usually called estimator (while the value 8(x) is called estimate of 
0). When there is no risk of confusion, we also denote the set of estimators 
by 1). 
The frequentist paradigm relies on this criterion to compare estimators 
and, if possible, to select the "best" estimator. Note, however, that there 
are several difficulties associated with this approach. 
(1) The error (loss) is averaged over the different values of x proportionally 
to the density f(xIO). Therefore, it seems the observation x is not taken 
into account any further. The risk criterion thus evaluates procedures 
on their long run performances and not directly for the given obser-
vation, x. Such an evaluation may be satisfactory for the statistician, 
but it is not so appealing for a client. 
(2) The frequentist analysis of the decision problem implicitly assumes that 
this problem will be met again and again, for the frequency evaluation 
to make sense. Indeed, R( 0, 8) is approximately the average loss over 
a repetition of the same experiment, according to the Law of Large 
Numbers. However, on both philosophical and practical grounds, there 
is a lot of controversy about the very notion of repeatability of experi-
ments (see Jeffreys (1961) and also Berliner (1992) for a link with chaos 
theory). 
(3) For a procedure 8, the risk R(O,8) is a function of the parameter O. 
Therefore, the frequentist approach does not induce a total ordering 
on the set of procedures. It is generally impossible to compare decision 
procedures with this criterion, since two crossing risk functions prevent 
comparison. At best, one may hope for a procedure 80 which uniformly 
minimizes R( 0, 8), but such cases rarely occur unless the space of deci-
sion procedures is restricted. "Best" procedures can only be obtained 
by restricting rather artificially the set of "allowed" procedures. 
Example 2.4 Consider Xl and X2, two observations from 
Pe(x = 0 - 1) = Pe(x = 0 + 1) = 0.5, 
o E JR. 

50 
2. Decision-Theoretic Foundations of Statistical Inference 
The parameter of interest is () (i.e., V = 8) and it is estimated by estimators 
8 under the loss 
L«(},8) = 1- ][0(8), 
often called 0-1 loss, which penalizes errors of estimation by 1. Considering 
the particular estimator 
its risk function is 
R«(},80 ) = 1 - Po (80 (Xl, X2) = (}) 
= 1 -
PO(X1 =f. X2) = 0.5. 
This computation shows that the estimator 80 is correct half of the time. 
Actually, this estimator is always correct when Xl =f. X2 and always wrong 
otherwise. Note that the estimator 81 (Xl, X2) = Xl + 1 also has a risk 
function equal to 0.5. Therefore, 81 and 80 are not comparable. 
6 
On the contrary, the Bayesian approach integrates on the space 8 since 
() is unknown, instead of integrating on the space X as X is known. It relies 
on the posterior expected loss 
p(7r, dlx) = ]E1I'[L«(}, d) Ix] 
= l L((}, d)7r((}lx) d(}, 
which averages the error (Le., the loss) according to the posterior distribu-
tion of the parameter (), conditionally on the observed value x. Given x, the 
average error resulting from decision d is actually p( 7r, dlx). The posterior 
expected loss is thus a function of X but this dependence is not troublesome, 
as opposed to the frequentist dependence of the risk on the parameter since 
x, contrary to (), is unknown. Given a prior distribution 7r, it is also possible 
to define the integrated risk, which is the frequentist risk averaged over the 
values of () according to their prior distribution 
r(7r,8) = ]E1I'[R((}, 8)] 
= l L 
L((}, 8(x)) f(xl(}) dx 7r((}) d(}. 
One particular interest of this second concept is that it associates a real 
number with every estimator, not a function of (). It therefore induces a 
total ordering on the set of estimators, i.e., allows for the direct comparison 
of estimators. This implies that, while taking into account the prior infor-
mation through the prior distribution, the Bayesian approach is sufficiently 
reductive (in a positive sense) to reach an effective decision. Moreover, the 
above two notions are equivalent in the sense that they lead to the same 
decision. 

2.3. Utility and Loss 
51 
Theorem 2.5 An estimator minimizing the integrated risk r(,rr, 15) 
can be obtained by selecting, for every x E X, the value c5(x) which 
minimizes the posterior expected loss, p(7l",c5lx), since 
r('rr,8) = Ix p(7l", c5(x)lx)m(x) dx. 
(2.1) 
Proof. Equality (2.1) follows directly from Fubini's Theorem since, as 
L(O,c5) 2::0, 
r(7l",8) = llx L(O,c5(x))f(xIO)dx 7l"(0) dO 
= Ix Ie L(O, c5(x))f(xIO)7l"(O) dOdx 
= Ix l L(O, 8(x))7l"(0Ix) dO m(x) dx . 
This result leads to the following definition of a Bayes estimator: 
Definition 2.2 A Bayes estimator associated with a prior distri-
bution 7l" and a loss function L is any estimator c57r which mini-
mizes r(7l",c5). For every x E X, it is given by 87r(x), argument of 
mind p(7l", dlx). The value r(7l") = r(7l",c57r ) is then called the Bayes 
risk. 
•• 
Theorem 2.5 thus provides a constructive tool for the determination 
of the Bayes estimators. Note that, from a strictly Bayesian point of view, 
only the posterior expected loss p(7l",c5lx) is important, as the Bayesian 
paradigm is based on the conditional approach. To average over all possible 
values of x when we know the observed value of x, seems to be a waste 
of information. Nonetheless, the equivalence exhibited in Theorem 2.5 is 
important, because, on one hand, it shows that the conditional approach is 
not necessarily as dangerous as frequentists may depict it.3 On the other 
hand, this equivalence provides a connection between the classical results of 
Game Theory (see the next section) and the axiomatic Bayesian approach, 
based on the posterior distribution. It also explains why Bayes estimators 
play an important role in frequentist optimality criteria. 
The above result is valid for proper and improper priors, as long as 
the Bayes risk r(7l") is finite. Otherwise, the notion of a (decision-theoretic) 
Bayes estimator is meaningless. In such cases, we still define a generalized 
Bayes estimator as the minimizer, for every x, of the posterior expected 
loss. In terms of frequentist optimality, we will see that the division be-
tween proper and improper priors is much less important than the division 
3 Indeed, although it works conditionally on the actual observation x, the 
Bayesian approach also incorporates the probabilistic properties of the dis-
tribution of the observation, f(xIO). 

52 
2. Decision-Theoretic Foundations of Statistical Inference 
between regular and generalized Bayes estimators, since the formers are 
admissible. Note that, for strictly convex losses, the Bayes estimators are 
unique. 
We conclude this section with an example of construction of a loss 
function in an expert calibration framework. References on this topic are 
DeGroot and Fienberg (1983), Murphy and Winkler (1984), Bayarri and 
DeGroot (1988) and Schervish (1989). Smith (1988, Chap. 4) also shows 
how forecaster evaluation can help to improve the assessment of prior prob-
abilities. 
Example 2.5 Meteorological forecasts are often given as probability state-
ments like, for instance, "the probability of rain for tomorrow is 0.4." Such 
forecasts being quantified, it is of interest to evaluate weather forecasters 
through a loss function (for their employers as well as users). 
For a given forecaster, let N be the number of different percentages 
predicted at least once in a year and let Pi (1 :S i :S N) be the corresponding 
percentages. For instance, we may have N = 5 and 
Pl = 0, P2 = 0.45, P3 = 0.7, P4 = 0.9, 
and P5 = 0.95. 
In this case, the parameters Oi are "actually" observed, i.e., 
0i = number of rainy days when Pi is forecasted 
number of days when Pi is forecasted 
(more exactly, this ratio is a good approximation of Oi). 
If qi denotes the proportion of days where Pi is forecasted, a possible 
loss function for the forecasters is 
N 
N 
L(O,p) = L qi(Pi - Oi)2 + L qdOg(qi)' 
i=l 
i=l 
For a given set of O/s (1 :S i :S N), the best forecaster is the "perfectly 
calibrated" forecaster, i.e., the one who satisfies Pi = Oi (1 :S i :S N). 
Moreover, among these "perfect forecasters", the best one is the most well 
balanced, satisfying qi = I/N (1 :S i :S N), i.e., the more daring forecaster, 
as opposed to an forecaster which would always give the same forecast, Pia' 
This is why we consider an additional term in L(O,p). However, the distance 
(Pi-Oi)2 could be replaced by any other function taking its minimum at Pi = 
Oi (see Exercises 2.12 and 2.14). The weight qi in the first sum is also used 
to calibrate more properly forecasters, in order to prevent overpenalization 
of rare forecasts. 
This loss has been constructed with a bias in favor of forecasters with 
large N, since the entropy log( N) increases with N. However, a better 
performance for a larger N requires that Pi is (almost) equal to Oi and qi 
is close to 1/ N. 
6 

2.4. Two Optimalities: Minimaxity and Admissibility 53 
2.4. Two Optimalities: Minimaxity and 
Admissibility 
This section deals with the two fundamental notions of frequentist Decision 
Theory, as introduced by Wald (1950) and Neyman and Pearson (1933a,b). 
As mentioned above and contrary to the Bayesian approach, the frequen-
tist paradigm is not reductive enough to lead to a single optimal estimator. 
While we are mainly concerned in this book with the Bayesian aspects of 
Decision Theory, it is still necessary to study these frequentist notions in 
detail as they show that Bayes estimators are often optimal for the frequen-
tist concepts of optimality, therefore should still be considered even when 
prior information is ignored. In other words, one can reject the Bayesian 
paradigm and ignore the meaning of the prior distribution and still obtain 
well-performing estimators from a frequentist point of view when using this 
prior distribution. Therefore, in this technical sense, frequentists should also 
take into account the Bayesian approach, since it provides a tool for the 
derivation of optimal estimators (see Brown (1971), Alam (1973), Straw-
derman (1974), Berger (1985a), or Berger and Robert (1990) for examples). 
Moreover, these properties can be helpful in the selection of a prior distri-
bution, when prior information is not precise enough to lead to a single 
prior distribution (see Chapter 3). 
2.4.1. Randomized Estimators 
Similar to the study of the utility function, where we extended the reward 
space to P, we need to extend the decision space to the set of randomized 
estimators, taking values in V*, space of the probability distributions on 
V. The loss of a randomized estimator 8* is defined as the average loss 
L(O, 8*(x)) = 1 
L(O, a)8*(x, a) da, 
where 8*(x,·) is a probability density on V. This extension is necessary 
to deal with minimaxity and admissibility. Obviously, such estimators are 
not to be used, if only because they contradict the Likelihood Principle, 
giving several possible answers for the same value of x (and thus of f(Olx)). 
Moreover, it seems quite paradoxical to add noise to a phenomenon in order 
to take a decision under uncertainty! 
Example 2.4 (Cont.) We can also consider the randomized estimator 
where Iv denotes the Dirac mass at v. Actually, if Xl = X2, the two values 
81 = Xl - 1 and 82 = Xl + 1 have the same likelihood. Compared with 80 

54 
2. Decision-Theoretic Foundations of Statistical Inference 
which never estimates e correctly if Xl = X2, 8* is exact with probability 
1/2. However, when 8* misses e, it is farther away from ethan 80' The 
choice of the estimator then depends on the loss function, i.e., the way the 
distance between the estimator and e (or the error) is measured. 
L:,. 
Randomized estimators are nonetheless necessary from a frequentist 
point of view, for instance, for the frequentist theory of tests, as they provide 
access to confidence levels otherwise unattainable (see Chapter 5). The set 
V* thus appears as a completion of V. However, this modification of the 
decision space does not modify the Bayesian answers, as shown by the 
following result (where V* also denotes the set of functions taking values 
in V*). 
Theorem 2.6 For every prior distribution Jr on 8, the Bayes risk 
on the set of randomized estimators is the same as the Bayes risk 
on the set of nonrandomized estimators, i. e., 
inf r(Jr, 8) = inf r(Jr, 8*) = r(Jr). 
8EV 
8*EV* 
This result actually holds even when the Bayes risk r( Jr) is infinite. The 
proof relies on the fact that a randomized procedure averages the risks of 
nonrandomized estimators and thus cannot improve on them (see DeGroot, 
1970). However, this property does not hold for the frequentist risk unless 
some conditions are imposed on the loss function. 
2.4.2. Minimaxity 
The minimax criterion we introduce now appears as an "insurance against 
the worst case," as it aims at minimizing the expected loss in the least 
favorable case. It also represents a frequentist effort to skip the Bayesian 
paradigm while producing a (weak) total ordering on V*. 
Definition 2.3 The minimax risk associated with a loss function 
L is the value 
R = inf sup R(e,8) = inf sup IEo(e, 8(x)), 
8EV* 
0 
8EV* 
0 
and a minimax estimator is any (possibly randomized) estimator 
80 such that 
sup R(e, 80) = R. 
o 
This notion is validated by Game Theory where two adversaries (here, 
the "Statistician" and "Nature") are competing. Once the statistician has 
determined his/her procedure, Nature selects the state of nature (i.e., the 
parameter) which maximizes the loss of the statistician. (We will see below 
that this choice is usually equivalent to the choice of a prior distribution 

2.4. Two Optimalities: Minimaxity and Admissibility 55 
7r. Therefore, the Bayesian approach does not really fit in that conflicting 
framework, since the prior distribution is also supposed to be known.) In 
general, it seems unfortunate to resort to such an antagonistic perspective in 
a statistical analysis. Indeed, to perceive Nature (or "reality") as an enemy 
involves a bias toward the "worst cases" and prevents the statistician from 
using the available information (for an analysis and a defense of minimaxity, 
see Brown, 1993). 
The notion of minimaxity provides a good illustration of the conserva-
tive aspects of the frequentist paradigm. Since this approach refuses to make 
any assumption on the parameter (), it has to consider the 'worst' cases as 
equally likely and thus needs to focus on the maximal risk. Actually, from 
a Bayesian point of view, it is often like putting a prior concentrated on 
these worst cases (see below). In most settings, this point of view is thus 
too conservative because some values of the parameter are less likely than 
others. 
Example 2.6 The first oil-drilling platforms in the North Sea were designed 
according to a minimax principle. In fact, they were supposed to resist the 
conjugate action of the worst gale and the worst storm ever observed, at the 
minimal record temperature. This strategy obviously gives a comfortable 
margin of safety but is quite costly. For more recent platforms, engineers 
have taken into account the distribution of these weather phenomena in 
order to reduce the production cost. 
f::::. 
Example 2.7 A waiting queue at a red light is usually correctly repre-
sented by a Poisson distribution. The number of cars arriving during the 
observation time, N, is thus distributed according to P(A), with the mean 
parameter A to be estimated. Obviously, the values of A above a given limit 
are quite unlikely. For instance, if Ao is the number of cars in the whole city, 
the average number of cars waiting at a given traffic light will not exceed 
AO. However, it may happen that some estimators are not minimax because 
their risk are above R for the largest values of A. 
f::::. 
The above example does not directly criticize the minimax principle 
but rather argues for the fact that some residual information is attached 
to most problems and that it should be used, even marginally. In a similar 
manner, Example 2.8 exhibits two estimators, 81 and 82, such that 81 has a 
constant minimax risk Rand 82 has a risk which can be as low as R/l0 but 
goes slightly above R for the largest values of the parameter (see Figure 
2.1). Therefore, according to the minimax principle, 81 should be preferred 
to 82, although the values of () for which 81 dominates 82 are the most 
unlikely (see Exercise 2.28 for another striking example). 
Example 2.8 For reasons explained in §2.4.5, we consider the following 
estimator: 

56 
2. Decision-Theoretic Foundations of Statistical Inference 
82(x) = 
1 - TxIP 
X 
If Ilxll ~ 2p - 1, 
{ ( 
2p -1) . 
2 
o 
otherwise, 
to estimate () when x '" Np((), Ip). This estimator, called the positive-part 
James-Stein estimator, is evaluated under quadratic loss, 
Figure 2.1 gives a comparison of the respective risks of 82 and 81(x) = x, 
maximum likelihood estimator, for p = 9. This figure shows that 82 is indeed 
not minimax, since the maximum risk of 82 is above the (constant) risk of 
81, i.e., R((),82 ) = lEe[ll() - 82(x)112] = p. (We show in §2.4.3 that 81 is 
actually minimax in this case.) But the estimator 82 is definitely superior 
on the most interesting part of the parameter space, the additional loss 
being in perspective quite negligible. 
6 
10 
8 
6 
4 
2 
0 
0 
2 
4 
6 
8 
10 
12 
116112 
FIGURE 2.1. Comparison of the risks of the estimators 81 and 82 . 
The opposition between minimax and Bayesian analyses is illustrated 
by the following example, which borrows from Game Theory (since there 
is no observation nor statistical model). 
Example 2.9 Two people, A and B, suspected of being accomplices in a 
robbery, have been apprehended and placed in separate cells. Both suspects 
are questioned and enticed to confess the burglary. Although they cannot 
be convicted if none of them talks, the incentive is that the first person 
to cooperate will get a reduced sentence. Table 2.1 provides the rewards as 
perceived by A (in years of freedom), where a1 (resp. ()1) represents the fact 
that A (resp. B) talks. The two suspects have an optimal gain if none of 
them speaks. However, from A's point of view, the optimal strategy is to be 
the first one to talk, i.e., aI, since maxe R( a1, ()) = 4 and maxe R( a2, ()) = 
10. Therefore, both burglars will end up in jail! 

2.4. Two Optimalities: Minimaxity and Admissibility 57 
TABLE 2.1. Utility function U(Oi,aj). 
al 
a2 
(h 
-4 
-10 
()2 
8 
30 
On the contrary, if 7r is the (subjective) probability assigned by A to 
the event; "B talks," i.e., to ()l, the Bayes risk of al is 
r(7f,al) = IE7r[-U((),adJ = 47r - 8(1-7r) = 127r - 8 
and, for a2, 
It is straightforward to check that, for 7r :::; 11/14, r(7r, a2) is smaller than 
r( 7r, al). Therefore, unless A is convinced that B will talk, it is better for 
A to keep silent. 
/:::,. 
2.4.3. Existence of Minimax Rules and Maximin Strategy 
An important difficulty related with minimaxity is that a minimax estima-
tor does not necessarily exist (see Ferguson (1967) and Berger (1985a, Chap. 
5) for sufficient conditions). In particular, there exists a minimax strategy 
when (9 is finite and the loss function is continuous. More generally, Brown 
(1976) (see also Le Cam (1986) and Strasser (1985)) considers the decision 
space 'D as embedded in another space so that the set of risk functions on 
'D is compact in this larger space. From this perspective and under addi-
tional assumptions, it is then possible to derive minimax estimators when 
the loss is continuous. However, these extensions involve topological tech-
niques too advanced to be considered in this book. Therefore, we only give 
the following result (see Blackwell and Girshick, 1954). 
Theorem 2.7 If'D c ffik is a convex compact set and ifL((),d) is 
continuous and convex as a function of d for every () E (9, there 
exists a non randomized minimax estimator. 
The restriction to nonrandomized estimators when the loss is convex 
is due to Jensen's inequality, since 
L((),o*) = IE6*[L((),o)J2:: L((),IE6*(o)). 
This result is a weak version of the Rao-Blackwell Theorem (see Lehmann, 
1983, p. 50). 
Example 2.4 (Cont.) The randomized estimator 0* is uniformly dominated 
for every convex loss by the nonrandomized estimator IE6* [O*(Xl' X2)], i.e., 

58 
2. Decision-Theoretic Foundations of Statistical Inference 
8(x X)={t(Xl+X2) 
ifXli=X2, 
1 
1, 2 
2(Xl - 1) + ~(Xl + 1) = Xl 
otherwise, 
which is actually identical to the estimator 80 considered originally. Note 
that this is not true for the 0 - 1 loss where 8* dominates 81. 
6. 
The following result points out the connection between the Bayesian 
approach and the minimax principle. (The proof is straightforward and thus 
omitted.) 
Lemma 2.8 The Bayes risks are always smaller than the minimax 
risk, i.e., 
R = supr(1I") = sup inf r(1I",8) S fl = inf sup R(B,8). 
11" 
11" 
OE'V 
OE'V" 
8 
The first value is called maximin risk and a distribution 11"* such that 
r(1I"*) = R is called a least favorable distribution, when such distributions 
exist. In general, the upper bound r(1I"*) is rather attained by an improper 
distribution, limit of proper prior distributions 1I"n, but this phenomenon 
does not necessarily deter from the derivation of minimax estimators (see 
Lemma 2.10). When they exist, least favorable distributions are those with 
the largest Bayes risk, thus the less interesting distributions in terms of loss 
performances if they are not suggested by the available prior information. 
The above result is quite logical, in the sense that prior information can 
only improve the estimation error, even in the worst case. 
A particularly interesting case corresponds to the following definition: 
Definition 2.4 The estimation problem is said to have a value 
when R = fl, i.e., when 
sup inf r(1I",8) = inf sup R(B,8). 
11" 
OE'V 
OE'V" 
8 
When the problem has a value, some minimax estimators are the Bayes 
estimators for the least favorable distributions. However, they may be ran-
domized, as illustrated by the following example. Therefore, the minimax 
principle does not always lead to acceptable estimators. 
Example 2.104 
Consider a Bernoulli observation, X '" Be(B) with B E 
{0.1,0.5}. Four nonrandomized estimators are available, 
8l (x) = 0.1, 
We assume in addition that the penalty for a wrong answer is 2 when 
() = 0.1 and 1 when B = 0.5. The risk vectors (R(O.I, 8), R(0.5, 8)) of the 
4 The computations in this example are quite simple. We refer the reader to 
Berger (1985a) for other examples using the risk space and to Chapter 6 for 
details. 

2.4. Two Optimalities: Minimaxity and Admissibility 59 
four estimators are then, respectively, (0,1), (2,0), (0.2,0.5), and (1.8,0.5). 
It is straightforward to see that the risk vector of any randomized estimator 
is a convex combination of these four vectors or, equivalently, that the risk 
set, R, is the convex hull of the above four vectors, as represented by Figure 
2.2. 
In this case, the minimax estimator is obtained at the intersection 
of the diagonal of m? with the lower boundary of R. As can be seen in 
Figure 2.2, this estimator {)* is randomized and takes the value {)2(X) with 
probability a = 0.87 and {)3(X) with probability 1 - a. The weight a is 
actually derived from the equation 
0.2a + 2(1- a) = 0.5a. 
This estimator {)* is also a (randomized) Bayes estimator with respect to 
the prior 
11'(0) = 0.2210.1(0) + 0.7810.5(0); 
the prior probability 11'1 = 0.22 corresponds to the slope between (0.2,0.5) 
and (2,0), i.e., 
11'1 
0.5 
1 -
11'1 
1.8 
Note that every randomized estimator which is a combination of {)2 and 
of {)3 is a Bayes estimator for this distribution but that {)* only is also a 
minimax estimator. 
!:::. 
(t.) 
~ 
' I 
O ~------------1-----------~~~-----
o 
2 ~ ~O. 5' 1 + 1.8' 2 = I 
FIGURE 2.2. Risk set for the estimation of the Bernoulli parameter. 
Similar to the problem of the existence of a minimax estimator, a 
least favorable distribution does not necessarily exist since its existence 
depends on a separating hyperplane theorem which does not always apply 
(see Pierce (1973), Brown (1976), Berger (1985a), and Chapter 6). For 
instance, Strawderman (1973) shows that, when x rv Np(O, Ip), there is no 

60 
2. Decision-Theoretic Foundations of Statistical Inference 
minimax proper Bayes estimator if p ::; 4. From a more practical point of 
view, Lemma 2.8 provides sufficient conditions of minimaxity. 
Lemma 2.9 If Do is a Bayes with respect to 7fo and if R((), Do) ::; 
r( 7fo) for every () in the support of 7fo, Do is minimax and 7fo is the 
least favorable distribution. 
Example 2.11 (Berger, 1985a) Consider x '" B(n, ()) when () is to be esti-
mated under the quadratic loss, 
Bayes estimators are then given by posterior expectations (see §2.5) and, 
when () '" Be ( v;:, v;:), the posterior mean is 
D*(X) = x + vn/2. 
n+vn 
Moreover, this estimator has constant risk, R((), 15*) = 1/4(1 + vn)2. There-
fore, integrating out (), r(7f) = R((),D*) and 15* is minimax according to 
Lemma 2.9. Note the difference with the maximum likelihood estimator, 
Do (x) = x / n, for the small values of n, and the unrealistic concentration of 
the prior around 0.5 for larger values of n. 
6 
Since minimax estimators usually correspond to generalized Bayes es-
timators, it is often necessary to use a limiting argument to establish min-
imaxity, rather than computing directly the Bayes risk as in Lemma 2.9. 
Lemma 2.10 If there exists a sequence (7fn ) of proper prior distri-
butions such that the generalized Bayes estimator Do satisfies 
R((), Do)::; lim r(7fn ) < +00 
n-+oo 
for every () E (9, then Do is minimax. 
Example 2.12 
When x '" N((),l), the maximum likelihood estimator 
80(x) = x is a generalized Bayes estimator associated with the Lebesgue 
measure on 1R and the quadratic loss. Since R( 80, ()) = lEe (x - ())2 = 1, this 
risk is the limit of the Bayes risks r(7fn ) when 7fn is equal to N(O, n), as 
r(7fn ) = n~l. Therefore, the maximum likelihood estimator Do is minimax. 
Note that this argument can be extended directly to the case x '" Np((), Ip) 
to establish that 80 is minimax for every p. 
6 
When the space (9 is compact, minimax Bayes rules (or estimators) 
can be exactly described, due to the separated zeros principle in complex 
calculus. 
Theorem 2.11 
Consider a statistical problem which simultane-
ously has a value, a least favorable distribution 7fo, and a minimax 

2.4. Two Optimalities: Minimaxity and Admissibility 61 
estimator 87ro • Then, if e c IR is compact and if R( (), 87ro ) is 
an analytic function of (), then either 71'0 has a finite support or 
R( (), 87ro ) is constant. 
Example 2.13 Consider x rv N((), 1), with I()I :=:; m, namely, () E [-m, m]. 
Then, according to Theorem 2.11, least favorable distributions have neces-
sarily a finite support, {±()i, I:=:; i :=:; w}, with cardinal 2w and supporting 
points ()i depending on m. In fact, the only estimator with constant risk 
is 80(x) = x, which is not minimax in this case. In general, the exact de-
termination of n and of the points ()i can only be done numerically. For 
instance, when m :=:; 1.06, the prior distribution with weights 1/2 at ±m 
is the unique least favorable distribution. Then, for 1.06 :=:; m :=:; 2, the 
support of 71' contains -m, 0, and m. (See Casella and Strawderman (1981) 
and Bickel (1981) for details, and Johnstone and McGibbon (1992) for a 
similar treatment of the Poisson model.) 
t::, 
The above examples show why, while being closely related to the 
Bayesian paradigm, the minimax principle is not necessarily appealing from 
a Bayesian point of view. Indeed, apart from the fact that minimax esti-
mators are sometimes randomized (Example 2.10), Examples 2.11 and 2.13 
show that the least favorable prior is often unrealistic since it induces a 
strong prior bias towards a few points of the sample space. For Example 
2.13, Gatsonis et al. (1987) have shown that uniform priors are good sub-
stitutes to the point mass priors, although they are not minimax. 
Extensions of Theorem 2.11 to the noncompact case are given in 
Kempthorne (1988). In multidimensional setups, when the problem is in-
variant under rotation, the least favorable distributions are uniform on a 
sequence of embedded spheres (see Robert et al., 1990). The practical prob-
lem of determining the points of the support is considered in Kempthorne 
(1987), Eichenauer and Lehn (1989), and Bock and Robert (1991). 
In settings where the problem has a value, it is often difficult to derive 
the least favorable distribution and alternative methods are then neces-
sary to produce a minimax estimator. Chapter 7 shows how the exhibition 
of some invariance structures of the model may lead to identify the best 
equivariant estimator and a minimax estimator (Hunt-Stein Theorem). Un-
fortunately, the conditions under which this theorem applies are difficult to 
check. 
Last, when a minimax estimator has been derived, its optimality is still 
to be assessed. In fact, there may exist several minimax estimators and some 
may perform uniformly better than others. It is then necessary to introduce 
a second (and more 'local') criterion to compare minimax estimators, i.e., 
estimators which perform well "globally". 

62 
2. Decision-Theoretic Foundations of Statistical Inference 
2.4.4. Admissibility 
This second frequentist criterion induces a partial ordering on V (and even 
on V*) by comparing the frequentist risks of the estimators, R((},8). 
Definition 2.5 An estimator 80 is inadmissible if there exists an 
estimator 81 which dominates 80, i.e., such that, for every (}, 
R((},80) 2:: R((},81) 
and, for at least one value (}o of the parameter, 
R((}0,80) > R((}o, 81). 
Otherwise, 80 is said to be admissible. 
This criterion is particularly interesting for its reductive action. Indeed, 
at least in theory, it seems logical to advocate that inadmissible estimators 
should not be considered at all since they can be improved uniformly. For 
instance, the Rao-Blackwell Theorem then implies that, for convex losses, 
randomized estimators are inadmissible. However, admissibility alone is not 
enough to validate the use of an estimator. For instance, constant estimators 
8(x) = (}o are usually admissible because they produce the exact value at 
(} = (}o. From a frequentist point of view, it is then important to look for 
estimators satisfying both optimalities, i.e., minimaxity and admissibility. 
In this regard, two results can be mentioned. 
Proposition 2.12 If there exists a unique minimax estimator, this 
estimator is admissible. 
The proof of this result is straightforward. Note that the converse is false, 
since there can exist several minimax admissible estimators. When the loss 
function L is strictly convex (in d), it also allows for the following charac-
terization: 
Proposition 2.13 If 80 is admissible with constant risk, 80 is the 
unique minimax estimator. 
Proof. For any (}o E 8, SUPe R((}, 80) = R((}o, 80), Therefore, if there exists 
81 such that H ~ sUPeR((},81) < R((}o, 80), 80 cannot be admissible. Sim-
ilarly, if H = sUPe R( (}, 81) = R( (}o, 80) and (}1 is such that R( (}1, 81) < H, 
81 dominates 80 . Therefore, when 80 is admissible, the only possible case is 
that there exists 81 such that R( (}, 81) = R( (}, 80 ) for every (} E 8. And this 
is also impossible when 80 is admissible (see Exercise 2.36). 
•• 
Again, note that the converse to this result is false. There may be mini-
max estimators with constant risk which are inadmissible: actually, they 
are certainly inadmissible if there exist other minimax estimators (see next 
section). There also exist cases where there is no minimax admissible es-
timator (this requires that there is no minimal complete class, see Brown 
(1976) and Chapter 6). 

2.4. Two Optimalities: Minimaxity and Admissibility 63 
The previous section showed that minimaxity can sometimes be con-
sidered from a Bayesian perspective as the choice by "Nature" of a maximin 
strategy (least favorable distribution), 7r, therefore that some minimax esti-
mators are Bayes (but not all). Admissibility is even more strongly related 
to the Bayes paradigm in the sense that, in most statistical problems, the 
Bayes estimators are "spanning" the class of admissible estimators, i.e., the 
latter can be expressed as Bayes estimators or generalized Bayes estimators 
or limits of Bayes estimators. Chapter 6 deals in more detail with the re-
lations between Bayes estimators and admissibility. We only give here two 
major results. 
Proposition 2.14 If a prior distribution 7r is strictly positive on e, 
with finite Bayes risk and the risk junction, R( (}, 0), is a continu-
ous function of (} for every 0, the Bayes estimator 07r is admissible. 
Proof. Suppose 07r is inadmissible and consider 0' which uniformly domi-
nates 07r. Then, for every (}, R( (}, 0') ::; R( (}, 07r) and, in an open set C of e, 
R((},o') < R((}, 07r). Integrating out this inequality, we derive that 
r(7r, 0') < r(7r,07r) = Ie R((},o7r)7r((})d(}, 
which is impossible. 
Proposition 2.15 If the Bayes estimator associated with a prior 7r 
is unique, it is admissible. 
•• 
The proof of this result is similar to the proof of Proposition 2.12. In cases 
where the Bayes estimator is not unique, it is still possible to exhibit at least 
one admissible Bayes estimator. When the loss function is strictly convex, 
the Bayes estimator is necessarily unique and thus admissible, according to 
the above proposition. 
Example 2.11 (Cont.) The estimator 0* is a (proper) Bayes estimator, 
therefore admissible, and it has constant risk, therefore it is the unique 
minimax estimator under squared error loss. 
!::::. 
Note that Proposition 2.14 contains the assumption that the Bayes 
risk is finite. Otherwise, every estimator is, in a way, a Bayes estimator (see 
Exercise 2.46). On the other hand, some admissibility results can be estab-
lished for improper priors. This is why we prefer to call generalized Bayes 
estimators the estimators associated with an infinite Bayes risk rather those 
corresponding to an improper prior. This choice implies that the Bayes es-
timators of different quantities associated with the same prior distribution 
can be simultaneously regular Bayes estimators and generalized Bayes es-
timators, depending on what they estimate, but it also guarantees that 
regular Bayes estimators will always be admissible, as shown by the follow-
ing result: 

64 
2. Decision-Theoretic Foundations of Statistical Inference 
Proposition 2.16 If a generalized Bayes estimator, 87r, is such that 
the formal Bayes risk, 
r{-7r) = Ie R(O, 87r)7r(O) dO, 
is finite, 87r is admissible. 
Example 2.14 Consider x rv N(O, 1) and the null hypothesis Ho: 0::; 0 is 
tested against the alternative hypothesis HI: 0 > O. This testing problem 
is an estimation problem if we consider the estimation of the indicator 
function ][Ho(O). Under the quadratic loss 
we can propose the following estimator: 
. 
p(x) = Po(X > x) 
= 1 - <.p(x), 
(X rv N(O, 1)) 
called the p-value, which is considered as a 'good' frequentist answer (see 
Kiefer (1977) and Casella and Berger (1987)). Using Example 1.18, it is easy 
to show that p is a generalized Bayes estimator under Lebesgue measure 
and quadratic loss, since 7r(Olx) is N(x, 1) and 
p(x) = 1E7r[][Ho(O)lx] = p7r(O < Olx) 
= p7r(O -
X < -xix) = 1 - <.p(x). 
Moreover, one can show that the (formal) Bayes risk of p is finite. Therefore, 
the p-value, when taken as an estimator of ][Ho' is admissible. (See §5.3 for 
an extended analysis of the properties of the p-value.) 
t::, 
Example 2.15 In the setup of the previous example, if 0 is the parameter 
of interest, 80(x) = x is a generalized Bayes estimator under quadratic loss, 
but 
r(7r, 80) = [:00 R(O, 80) dO 
= 1+00 1 dO = +00. 
-00 
Therefore, Proposition 2.15 is useless in this case to assess the admissibility 
of 80 . While 80 is actually admissible, admissibility must be established 
through a sequence of proper priors, as shown in Chapter 6. 
t::, 
Example 2.16 
Consider x rv Np(O, Ip). If the parameter of interest is 
110112 and the prior distribution is the Lebesgue measure on lRP , since 
1E7r [IIOI12Ix] = 1E[lIYI12], with y rv Np(x,Ip), the Bayes estimator under 
quadratic loss is 

2.4. Two Optimalities: Minimaxity and Admissibility 65 
This generalized Bayes estimator is not admissible, because it is dominated 
by 80(x) = IIxl12 - p (see Exercise 2.35). This phenomenon shows that 
Lebesgue measure is not necessarily the best 'automatic' choice for a prior 
measure when the parameter of interest lies in a subspace of the parameter 
space (see Chapter 3). 
6. 
2.4.5. The Stein Effect 
If there is a unique minimax estimator, this estimator is admissible, ac-
cording to Proposition 2.12. Conversely, if a minimax estimator 80 is in-
admissible, there exist other minimax estimators which improve upon 80 
(under some minor regularity conditions, see Brown, 1976). In particular, 
if the constant risk minimax estimator is inadmissible, this is the worst 
minimax estimator in the sense that every other minimax estimator has 
a uniformly smaller risk. Until 1955, it was assumed that the least square 
estimator, 80(x) = x, when x "-' Np(e, Ip), was admissible and, since its 
risk is constant, that it was the unique minimax estimator. Stein (1955a) 
showed that this result only holds for p = 1,2 and hence discovered "the 
Stein effect" phenomenon, i.e., the exhibition of apparently paradoxical 
domination results for usual estimators. Formally, the Stein paradox is as 
follows: if a standard estimator 8*(x) = (80 (xd, ... , 80(xp)) is evaluated 
under weighted quadratic loss 
p 
'"' w.(8. - e·)2 
L..J 
't 
1. 
't, 
(2.2) 
i=l 
with Wi > 0 (i = 1, ... , p), there exists Po such that 8* is not admissible 
for p 2: Po, although the components 80(xi) are separately admissible to es-
timate the ei's. The Stein effect can be explained through the use of the 
joint loss (2.2), which allows the dominating estimator to "borrow strength" 
from the other components, even when they are independent and deal with 
totally different estimation problems. The literature on the Stein effect and 
related phenomena is now too extensive for us to give here a comprehensive 
covering of the results in this field. We refer the reader to Judge and Bock 
(1978), Lehmann (1983), and Berger (1985a) for a more detailed bibliog-
raphy and we develop in Chapter 8 a Bayesian analysis of the Stein effect. 
The remainder of this section briefly presents the main results about the 
Stein effect from a frequentist point of view. 
First, as Stein's (1955a) proof of inadmissibility was nonconstructive, 
James and Stein (1961) exhibited an estimator which uniformly dominates 
80(x) = x under quadratic loss for p 2: 3 in the normal case, i.e., such that, 
for every e, 
This estimator, 

66 
2. Decision-Theoretic Foundations of Statistical Inference 
JS 
(p -2) 
6 (x) = 1- ~ 
x, 
(2.3) 
is now called the James-Stein estimator. Note the strange behavior of 6JS 
when x gets near o. The factor 1 -
IT~r becomes negative and even goes 
to -00 as Ilxll goes to O. However, oJS still dominates 60 for all O's. (This 
is a consequence of Theorem 2.17 below.) Baranchick (1970) corrected this 
paradoxical behavior by showing that the truncated estimators (p - 2 ~ c ~ 
2(P - 2)) 
6t(x) = (1- 1I~12 ) + X 
= {(1- Ilxl1 2 )x if IIxl12 > c, 
o 
otherwise, 
(2.4) 
uniformly dominate their nontruncated counterparts and, in particular, 
that 6:_2 was improving on 6Js. They are, moreover, noncomparable (as 
c varies). This class of estimators is important because, although made of 
inadmissible estimators (see Chapter 6), estimators which dominate the 
truncated James-Stein estimator are quite difficult to derive and do not 
bring significant improvement in terms of risk (see Bock (1988) and Shao 
and Strawderman (1994)). On the contrary, the truncated (or positive-part) 
James-Stein estimators improve quite significantly on the least square es-
timator, as illustrated in Figure 2.1 for p = 9 and c = 2p - l. 
Following James and Stein (1961), more general classes of estimators 
dominating 60 have been proposed by Alam (1973), Berger and Bock (1976), 
Judge and Bock (1978), Stein (1981), George (1986a,b), and Brandwein et 
al. (1992). These estimators are called shrinkage estimators because, as (2.3) 
and (2.4), they shrink x toward o. Stein effects have also been exhibited 
for distributions other than the normal distribution and losses other than 
the quadratic loss by Berger (1975), Brandwein and Strawderman (1980), 
Hwang (1982a), Ghosh et al. (1983), Bock (1985), Haff and Johnston (1987), 
Srivastava and Bilodeau (1988), Brandwein and Strawderman (1990). Some 
restrictions on the classes of shrinkage estimators have been proposed, in or-
der to integrate the admissibility requirement (Brown (1971), Alam (1973), 
Strawderman (1974), Brown (1975), Berger and Srinivasan (1978), Brown 
and Hwang (1982), Das Gupta and Sinha (1986), Brown (1988), and Fraisse 
et al. (1990)). Bondar (1987) has shown that the improvement (in terms 
of risk) brought by the shrinkage estimators is only significant on a lim-
ited part of the parameter space, but George (1986a,b) introduced the 
concept of multiple shrinkage estimators to extend the region where the 
improvement occurs (see Exercise 8.32). The Stein effect is also robust in 
the sense that it depends mainly on the loss function rather than on the 
exact distribution of the observations, as shown by Brown (1975), Shinozaki 
(1980, 1984), Berger (1980a,b), Das Gupta (1984), Bilodeau (1988), Cel-
lier, Fourdrinier and Robert (1989), Brandwein and Strawderman (1990) or 
Kubokawa, Robert and Saleh (1991, 1992, 1993). It is not limited to point 

2.4. Two Optimalities: Minimaxity and Admissibility 67 
estimation but also occurs for confidence regions (Stein (1962a), Hwang 
and Casella (1982, 1984), Casella and Hwang (1983, 1987), Robert and 
Casella (1990), Hwang and Ullah (1994)) and in accuracy (or loss) estima-
tion (Johnstone (1988), Rukhin (1988a,b), Lu and Berger (1989a,b), Robert 
and Casella (1993a), Fourdrinier and Wells (1993)), George and Casella 
(1994). However, Gutmann (1982) established that the Stein effect cannot 
occur in finite parameter spaces. Brown (1971) (see also Srinivasan (1981), 
Johnstone (1984), and Eaton (1992)) showed that admissibility is related 
to the recurrence of a stochastic process associated with the estimator and 
Brown (1980) shows the surprising result (called Berger's phenomenon, 
from Berger (1980b)) that there always exists a loss function such that the 
boundary between admissibility and inadmissibility for the usual estimator 
is an arbitrary dimension Po. 
This hasty overview poorly reflects the richness of the work on the 
Stein effect. The advances realized in this field in the last thirty years have 
been quite beneficial to Decision Theory in general and to Bayesian De-
cision Theory in particular. In fact, one of the main impacts of the Stein 
paradox is to signify the end of a "Golden Age" for classical Statistics, 
since it shows that the quest for the best estimator, i.e., the unique min-
imax admissible estimator, is hopeless, unless one restricts the class of 
estimators to be considered or incorporates some prior information. The 
works on the Stein effect have thus led to the progressive abandonment 
of unbiasedness, to a deeper understanding of minimaxity and admissibil-
ity, and to the improvement of frequentist techniques of risk computation 
(with Stein's (1973) idea of unbiased estimator of the risk). However, its 
main consequence has been to reinforce the Bayesian-frequentist interface,5 
by inducing frequentists to call for Bayesian techniques (see, for instance, 
Bock's (1988) idea of pseudo-Bayes estimators) and Bayesians to robustify 
their estimators in terms of frequentist performances and prior uncertainty 
(Berger (1980b, 1982a, 1984a), George (1986a,b), Lu and Berger (1989a,b), 
Berger and Robert (1990)). We refer the reader to the books mentioned 
above as well as to Brandwein and Strawderman (1990) and Casella et al. 
(1994) for additional references. 
We conclude this section with the proof of the inadmissibility of 
8o(x) = x in the estimation of 0 for spherically symmetric distributions, 
i.e., distributions with densities f(llx - 011) in lRP (p ;:::: 3). References on 
these distributions which generalize the normal distribution in linear re-
gression models are given in Kelker (1970), Eaton (1986) and Fang and 
Anderson (1990) (see also Exercise 1.1). This result was first established in 
Cellier et al. (1989). 
Theorem 2.17 Consider z = (xt, yt)t E lRP , with distribution 
(2.5) 
5 A typical example is provided by the development of the empirical Bayes tech-
niques (see Chapter 8). 

68 
2. Decision-Theoretic Foundations of Statistical Inference 
and x E IRq, y E IRp-q. An estimator 
dominates 80 under quadratic loss if there exist a, (3 > 0 such 
that: 
(1) tCXh(t, u) is a nondecreasing function oft for every U; 
(2) u-f3h(t,u) is a nonincreasing function ofu for every t; and 
(3) 0::; (tju)h(t, u) ::; 
2(q - 22)a 4(3 
p-q- + 
The above conditions on h are thus independent of f in (2.5), which 
does not need to be known, and, moreover, they are identical to those 
obtained in the normal case (see Brown (1975) and Cellier et al. (1989)). 
The occurrence of the Stein effect is then robust in the class of spherically 
symmetric distributions with finite quadratic risk. 
Proof. Conditions (1) and (2) imply 
{ t thh(t, u) ~ -ah(t, u), 
uauh(t,u)::; (3h(t,u). 
The risk of 8h can be developed as follows: 
RC9,6.) ~ IE, [t {x; - 9; - hCllxl12, IIYI12)x;} 2] 
= lEe [t(Xi-Oi)2]-2lEe [th(IIXI12,IIYI12)Xi(Xi-Oi)] 
+ lEe [h2(llxI12, IlyW)llxI12] . 
An integration by parts shows that 
with 
1
+00 
P(t) = 
t 
f(u)du. 
Therefore, 
IE, [t hCllxll2, Ilyll')x;Cx; - 9;)] 
= ( 
[qh(llxI12, IIYI12) + 2h~(llxI12, IlyW)llxI12] P(llx - 0112 + Ily112) dz 
JIRP 

2.5. Usual Loss Functions 
69 
where h~ (t, u) = fth(t, u). Similarly, 
lEe[h2(llxI12, IIYI12)llxI12] = lEe [::~::~ h2(llxW, IIYI12)llyI12] 
= kp IIxl12 ~ 
8~j (h2(llxI12, IIYI12) II~fI2) F(llx - 8112 + IIYI12) dz 
= kp IIxl12 [4h(IIXI12, IlyI12)h;(llxW, Ily112)llx112 
+ (p - q - 2)h2(llxW, IIYI12) IIY~12 ] F(llx - 8W + IIYI12) dz, 
where h~(t,u) = tuh(t,u). The difference of the risks is then 
R(8,oo) - R(8, Oh) = 
kp {2 [qh(llx I12, IIYI12) + 2h~ (1IxI12, IIYI12) Ilx112] IIxl12 h(llxI12, IIYI12) 
[4h;(llxI12, IIYI12) - (p - q - 2)h(llxI12, IIYI12) 11:112]} 
x F(llx - 8112 + IIYI12) dz 
2kp h(llxI12, IIYI12) [-h(llxI12, IIYI12) ::~::~ (p - q - 2 + 4(3) 
+ 2(q - 2(0)] F(llx - 8112 + IIYI12) dz > 0, 
which concludes the proof. 
•• 
Note that this domination result includes as a particular case the es-
timation of a normal mean vector when the variance is known up to a 
multiplicative factor, i.e., the problem originally considered in James and 
Stein (1961). When h(t, u) = au/t, the bound on a is 2(q - 2)/(p - q + 2), 
as obtained in James and Stein (1961). 
2.5. Usual Loss Functions 
When the setup of an experiment is such that the utility function cannot be 
determined (lack of time, limited information, etc.), a customary alternative 
is to resort to classical losses, which are mathematically tractable and well 
documented. Of course, this approach is an approximation of the underlying 
statistical model and should only be adopted when the utility function 
is missing. We conclude this section with a note on more intrinsic loss 
functions, although these are rarely used in practice. 

70 
2. Decision-Theoretic Foundations of Statistical Inference 
2.5.1. The Quadratic Loss 
Proposed by Legendre (1805) and Gauss (1810), this loss is undoubtedly the 
most common evaluation criterion. Founding its validity on the ambiguity 
of the notion of error in statistical setups (i.e., measurement error versus 
random variation), it also gave rise to many criticisms, commonly dealing 
with the fact that the squared error loss 
L(O, d) = (0 - d)2 
(2.6) 
penalizes large deviations too heavily. 
However, convex loss functions like (2.6) have the incomparable ad-
vantage of avoiding the paradoxes of risk lovers and to exclude randomized 
estimators. Another usual justification for the quadratic loss is that it pro-
vides a Taylor expansion approximation to more complex symmetric losses 
(see Exercise 4.13 for a counterexample). In his 1810 paper, Gauss already 
acknowledged the arbitrariness of the quadratic loss and was defending it 
on grounds of simplicity. Although the criticisms about a systematic use of 
the quadratic loss are quite valid, this loss is nonetheless extensively used 
since it gives intuitively sound Bayesian solutions, i.e., those one would nat-
urally suggest as estimators for a non-decision-theoretic inference based on 
the posterior distribution. In fact, the Bayes estimators associated with the 
quadratic loss are the posterior means. However, note that the quadratic 
loss is not the only loss enjoying this property. Losses leading to posterior 
means as the Bayes estimators are called proper losses and characterized in 
Lindley (1985), Schervish (1989), van der Meulen (1992), and Hwang and 
Pemantle (1994). (See also Exercise 2.15.) 
Proposition 2.18 The Bayes estimator 87r associated with the prior 
distribution 7f and with the quadratic loss (2.6), is the posterior 
expectation 
7r( ) _ 
7r[ I l- Ie OJ(xIO)7r(O) dO 
8 x -]E 0 x - Ie J(xIO)7r(O) dO . 
Proof. Since 
the posterior loss actually attains its minimum at 87r(x) = ]E7r[0 I xl. •• 
The following corollaries are straightforward to derive. 
Corollary 2.19 The Bayes estimator 87r associated with 7r and with 
the weighted quadratic loss 
L(O, 8) = w(O)(O - 8)2, 
(2.7) 
where w(O) is a nonnegative junction, is 

2.5. Usual Loss Functions 
71 
Corollary 2.20 When e E lRP, the Bayes estimator 87r associated 
with 1[" and with the quadratic loss, 
L(8,8) = (8 - 8)tQ(8 - 8), 
is the posterior mean, 87r (x) = lE7r [8Ix], for every positive-definite 
symmetric p x p matrix Q. 
Corollary 2.19 exhibits a (weak) duality between loss and prior distri-
bution, in the sense that it is equivalent to estimate 8 under (2.7) with the 
prior 1f or under (2.6) with the prior 1fw (8) ex 1f(8)w(8). Moreover, while ad-
missibility is independent of the weight factor, the Bayes estimator strongly 
depends on the function w. For instance, 87r may not exist if w increases too 
fast to +00. On the other hand, Corollary 2.20 shows that the Bayes esti-
mators are robust with respect to the quadratic form Q. (Shinozaki (1977) 
has also proved that admissibility does not depend on Q.) 
The quadratic loss is particularly interesting in the setup of bounded 
parameter spaces when the choice of a more subjective loss is impossible. In 
fact, this loss is quite tractable and the approximation error is usually negli-
gible. Indeterminacy about the loss function (and thus its replacement by a 
quadratic approximation) often occurs in accuracy evaluation, including for 
instance loss estimation (see Rukhin (1988a,b), Lu and Berger (1989a,b), 
Hwang, Casella et al. (1992), Robert and Casella (1993a,b), and Casella et 
al. (1994)). 
Example 2.4 (Cont.) We are looking for an evaluation of the estimator 
{
Xl + X2 
8(XI' X2) = 
2 
if Xl #- X2, 
Xl + 1 
otherwise, 
by a(xI' X2) under the quadratic criterion 
where Ie (v) is 1 if v = 8, 0 otherwise; the function a somehow evaluates the 
probability that 8 takes the true value 8. Two estimators can be proposed: 
(i) ao(xl, X2) = 0.75, which is the expectation of Ie(8(XI, X2)); and 
( .. ) 
( 
) 
{ 1 
if Xl #- X2, 
11 
al Xl, X2 = 
0 50 
'f 
_ 
. 
1 Xl -
X2. 
The risks of the two evaluators are then 
R(8, ao) = lEe (Ie(8(XI, X2)) - 0.75)2 
= 0.75 - (0.75)2 = 0.1875 

72 
2. Decision-Theoretic Foundations of Statistical Inference 
and 
R(e,ad = lEe (][e(8(X1,X2)) - al(X1,X2))2 
21 
= (0.5) 2 = 0.125 . 
Therefore, a1 is to be preferred to aD. As mentioned in Berger and Wolpert 
(1988), this domination result is quite logical and calls for a conditional 
evaluation of estimators. 
6. 
2.5.2. The Absolute Error Loss 
An alternative solution to the quadratic loss is to use the absolute error 
loss, 
L (e, d) = I e - d I, 
already considered by Laplace (1773) or, more generally, a multilinear func-
tion 
if e > d , 
otherwise. 
(2.8) 
Such functions increase more slowly than the quadratic loss. Therefore, 
while remaining convex, they do not overpenalize large but unlikely errors. 
Huber (1964) also proposed a mixture of the absolute error loss and of the 
quadratic loss, in order to keep a quadratic penalization around 0, 
-
_{(d-e? 
L(e,d) -
2k I d-e 1- k2 
if 1 d - e 1< k, 
otherwise. 
Although a convex6 loss, the mixed loss slows down the progression of the 
quadratic loss for large errors and has a robustifying effect. Unfortunately, 
there is usually no explicit derivation of Bayes estimators under this loss :L. 
Proposition 2.21 A Bayes estimator associated with the prior dis-
tribution 7r and the linear loss (2.8) is a (k2/(k1 + k2)) fractile of 
7r(elx). 
Proof. The following classical equality 
6 Again, if we insist so much on convexity, it is because it ensures that random-
ized estimators are suboptimal from a frequentist point of view. Therefore, a 
statistical decision-theoretic approach which would agree as much as possible 
with the Likelihood Principle necessarily calls for convex losses. This require-
ment obviously eliminates bounded losses. 

2.5. Usual Loss Functions 
73 
is obtained by an integration by parts. Taking the derivative in d, we get 
i.e., 
P7r(8 < dlx) = k k2 k 
I + 2 
•• 
In particular, if kl = k2' i.e., in the case of the absolute error loss, the 
Bayes estimator is the posterior median, which is the estimator obtained by 
Laplace (see Example 1.7). Note that, when 7r has a nonconnected support, 
Proposition 2.21 provides examples of multiple Bayes estimators for some 
values of x (see Exercise 2.43). 
2.5.3. The "0-1" Loss 
This loss is mainly used in the classical approach to hypothesis testing, 
as formalized by Neyman and Pearson (see §5.2). More generally, this is a 
typical example of a nonquantitative loss. In fact, for this loss, the penalty 
associated with an estimate 8 is 0 if the answer is correct and 1 otherwise. 
Example 2.17 Consider the test of Ho : 8 E 8 0 versus HI : 8 tf- 8 0 , Then 
1) = {O, I}, where 1 stands for acceptance of Ho and 0 for rejection (in 
other words, the function of 8 to be estimated is 180 (8)). For the "0-1" 
loss, i.e., 
L(8 d) = { 1 - d if 8 E ~o 
, 
d 
otherwIse, 
the associated risk is 
R(8,8) = IEo[L(8, 8(x))] 
= {Po(8(X) = 0) 
Po(8(x) = 1) 
if 8 E 8 0 , 
otherwise, 
(2.9) 
which are exactly the type-one and type-two errors underlying the Neyman-
Pearson theory. 
6. 
This loss is not very interesting because of its nonquantitative aspect, 
and we will consider in Chapter 5 some alternative theories for testing hy-
potheses. The associated Bayes estimators also reflect the primitive aspect 
of such a loss (see also Exercise 2.44). 
Proposition 2.22 The Bayes estimator associated with 7r and with 
the loss (2.9) is 
87r (x) = {I if P(8 ~ 8 01x) > P(8 tf- 8 0Ix), 
o otherw2se, 
i.e., 87r (x) is equal to 1 if and only if P(8 E 8 0 1x) > 1/2. 

74 
2. Decision-Theoretic Foundations of Statistical Inference 
2.5.4. Intrinsic Losses 
It may occur that some settings are so uninformative that not only the loss 
function is unknown but there is not even a natural parametrization. Such 
cases happen when the distribution !(xIO) itself is of interest, for instance, 
in prediction setups. 
However, as noted in the previous section, the choice of the parametriza-
tion is important because, contrary to the maximum likelihood estimation 
approach, if g is a one-to-one transformation of 0, the Bayes estimator of 
g(O) is usually different from the transformation by g of the Bayes estima-
tor of 0 under the same loss (see Exercise 2.36). This lack of invariance, 
although often troubling to beginners, is not usually a concern for decision-
makers, as it shows how the Bayesian paradigm can adapt to the estimation 
problem at hand and the selected loss function, while maximum likelihood 
estimation is totally loss-blind. But the few cases where loss function and 
"natural" parametrization are completely unavailable may call for this kind 
of ultimate invariance. 
In such noninformative settings, it seems natural to use losses which 
compare directly the distributions !(·IO) and !(·18) associated with the true 
parameter 0 and the estimate 8. Such loss functions, 
L(0,8) = d(f('IO), !(·18)), 
are indeed parametrization-free. Two usual distribution distances are 
the entropy distance, 
[ 
( !(XIO))] 
Le(0,8) = IEo log !(xI8) 
; 
(2.10) 
the Hellinger distance, 
!(xI8) _ 1) 2] 
!(xIO) 
. 
(2.11) 
Example 2.18 Consider x "" N(O, 1). Then we have 
1 
1 
Le(O, 8) = 2IEo[-(x - 0)2 + (x - 8)2] = 2(8 - 0)2, 
LH (0,8) = 1 - exp{ -(8 - 0)2/8}. 
Considering the normal case when 7r(Olx) is a N(J-l(x),a2 ) distribution, it 
is straightforward to show that the Bayes estimator is 87r(x) = J-l(x) in both 
~. 
~ 
The Hellinger loss is undoubtedly more intrinsic than the entropy loss, 
if only because it always exists (note that (2.11) is bounded above by 1). 

2.6. Criticisms and Alternatives 75 
Unfortunately, while leading to explicit expressions of LH(O, 8) for the usual 
distribution families, it does not allow for an explicit derivation of the Bayes 
estimators, except in the special case treated above. On the contrary, in 
exponential families, the entropy loss provides explicit estimators which are 
the posterior expectations for the estimation of the natural parameter (see 
Chapter 3). Moreover, although quite different from the Hellinger loss, the 
entropy loss provides similar answers for the usual distribution families (see 
Robert, 1993c). 
2.6. Criticisms and Alternatives 
Some criticisms about the frequentist notions of minimaxity and admis-
sibility have been mentioned in the previous sections. These concepts are 
actually of secondary interest from a purely Bayesian point of view, since 
on one hand, admissibility is automatically satisfied by most Bayes esti-
mators. On the other hand, minimaxity is somehow incompatible with the 
Bayesian paradigm, since, under a prior distribution, each value of the pa-
rameter cannot be equally weighted. However, minimaxity may be relevant 
from a robustness point of view, i.e., when the prior information is not 
precise enough to determine the prior distribution. 
It may happen that the decision maker cannot define exactly his/her 
loss function. For instance, when the decision maker is a committee made 
of several experts, it is often the case that they differ about the relevant 
loss function (and sometimes even about the prior distribution). Starting 
with Arrow (1951), the literature on these extensions of classical Decision 
Theory is quite extensive (see Genest and Zidek (1986), Rubin (1987), and 
Van Eeden and Zidek (1993) for details and references). 
When the loss function has not been completely determined, it might 
be assumed to belong to a parametrized class of loss functions, the decision 
maker selecting the most accurate parameter. Apart from Lp losses, two 
other possible classes are 
An alternative approach more in tune with the Bayesian paradigm is to 
consider that, since the loss is partially unknown, this uncertainty can be 
represented by using a random loss L(O, 8). The evaluation of estimators is 
then done by integrating out with respect to this additional variable: If F 
is the distribution of the loss, the objective function to minimize (in 8) is 
li 
L(O, 8, w)dF(w) dn(Olx), 
(2.12) 
where F possibly depends on 0. This case is actually the only interesting 
extension since, otherwise, to minimize (2.12) is equivalent to using the 
average loss 

76 
2. Decision-Theoretic Foundations of Statistical Inference 
1(8,8) = in L(8, 8, w) dF(w). 
Another approach to the lack of precision on the loss function is to 
consider simultaneously a set of losses and look for estimators performing 
well for all these losses. Obviously, this multidimensional criterion only 
induces a partial ordering on estimators. 
Example 2.19 Consider x", Np(8, Ip). The parameter 8 is estimated under 
quadratic loss. If the loss matrix Q is not exactly determined, a robust 
alternative is to include the losses associated with the matrices Q such that 
Q1 ::S Q ::S Q1 (where A ::S B means that the matrix B - A is nonnegative 
definite). Note that, according to Corollary 2.20, the Bayes estimator is the 
same for all Q's. 
/'::. 
Example 2.20 In the setup of the above example, Brown (1975) shows that 
a shrinkage estimator of the form (1 - h(x))x dominates 80(x) = x for a 
class of quadratic losses, i.e., a class of matrices Q if and only if 
tr(Q) - 2Amax(Q) > ° 
(2.13) 
for every matrix in the class (where Amax denotes the largest eigenvalue). 
Note that this condition excludes the case p :::; 2, where 80 is actually ad-
missible. The constant tr(Q) - 2.Amax(Q) also appears in the majorization 
constant of IlxI1 2h(llxI1 2) (see Theorem 2.17). Therefore, (2.13) is simulta-
neously a necessary and sufficient condition for the Stein effect to occur. 
/'::. 
The ultimate criterion in loss robustness is called universal domination 
and was introduced in Hwang (1985). It actually takes into account the set 
of all losses C(118 - 81IQ), for a given norm IlxllQ = xtQx and all nonde-
creasing functions C. An estimator 81 will be said to universally dominate 
another estimator 82 if, for every C, 
A second criterion is called stochastic domination: 81 stochastically domi-
nates 82 if, for every c > 0, 
Although this criterion seems more intrinsic and less related to Decision 
Theory than universal domination, Hwang (1985) has shown that the two 
criteria are actually equivalent. 
Theorem 2.23 An estimator 81 universally dominates an estima-
tor th if and only if 81 stochastically dominates 82 . 
Proof. The estimator 81 stochastically dominates 82 if, for every c > 0, 

2.6. Criticisms and Alternatives 77 
This can be rewritten as 
Since f(t) = ll[c,+oo[(t) is a nondecreasing function of t, universal domina-
tion implies stochastic domination. The converse follows from the fact that 
the first moments of two stochastically ordered random variables are also 
ordered. 
__ 
Moreover, these two criteria are not meaningless since Hwang (1985) 
has established the following domination result: If x'" Ta(P" (J2), Student's 
t~distribution with 0: degrees of freedom, some shrinkage estimators uni-
versally dominate 80 (x) = x. If the dimension is not too small (usually, 
p = 4 is sufficient), Brown and Hwang (1989) virtually showed that, if 
x'" Np(e, E), the estimator 80(x) is admissible for universal domination if 
and only if Q = 17. For other choices of the matrix Q and p large enough, 
80 is stochastically dominated. Therefore, even though this criterion is less 
discriminating than usual losses, it allows for comparison and even for a 
Stein effect, since classical estimators are not necessarily optimal. 
The study of multiple losses is not very developed from a Bayesian 
point of view, since Bayes estimators usually vary with a change of loss 
function. However, in a very special case, Rukhin (1978) has shown that 
the Bayes estimators were independent of the loss function. Under some 
regularity assumptions, this case corresponds to the following equation: 
where 7r is the prior distribution. Therefore, for this exponential family (see 
§3.2.2), 
(2.14) 
the Bayes estimators are universal, because they do not depend on the loss. 
The next chapter covers in detail the case of exponential families, which 
are classes of distributions on IRk with densities 
f(xle) = c(e)h(x) exp[R(e) . T(x)], 
where R(e), T(x) E IRP. However, note that (2.14) is a rather special expo-
nential family. 
Another approach has also been proposed as an alternative to Decision 
Theory by Pitman (1937). In order to compare two estimators of e, 81 and 
82 , he indeed suggested the comparison of the distribution of their distance 
(or closeness) to e, i.e., 
If this probability is uniformly larger than 0.5, 81 is said to dominate 82 in 
Pitman's sense, with the implicit message that 81 should be preferred to 

78 
2. Decision-Theoretic Foundations of Statistical Inference 
82 in this case. Even though formally close to stochastic domination, this 
criterion, called Pitman closeness, exhibits important flaws and we suggest 
it not be used as a comparison criterion. Nonetheless, the literature on the 
subject is quite important (see, e.g., Blyth (1972), Rao (1980, 1981), Blyth 
and Pathak (1985), Rao et at. (1986), Keating and Mason (1985), Peddada 
and Khattree (1986), Sen et at. (1989), Ghosh and Sen (1989)). These pa-
pers studt the properties of Pitman closeness and stress its intrinsic aspect 
since it involves the whole distribution of 1181(x) -
811 (as opposed to the 
"reductive" evaluation through a loss, like the quadratic loss). On the other 
hand, Robert et at. (1993) expose the fundamental drawbacks of this crite-
rion. We present here two characteristic points (see Exercises 2.53-2.58 for 
other illustrations). 
A first major criticism against Pitman closeness deals with its non-
transitivity. Indeed, it does not provide a mean of selecting an 'optimal' 
estimator or even to order estimators. Pitman (1937) already pointed out 
this defect, but some proponents of the criterion (see, e.g., Blyth, 1993) 
paradoxically assert that this property is an additional advantage of the 
criterion, since it better reflects the complexity of the world. As discussed 
above, it may indeed happen that realistic orderings of preferences are not 
always transitive. But, apart from the utmost necessity for reducing this 
complexity, note that the Pitman closeness criterion is advocated as a com-
parison criterion, an alternative to regular loss functions: when nontransi-
tivity occurs, the ordering derived from the criterion is not absolute since, 
as the following example shows, there is always a chance for a "preference 
cycle". In such cases, the criterion cannot provide a selection of the best 
estimator. 
Example 2.21 
Consider U 
f'.J U[-0.9,1.1] and x = ()U. Then, it can be 
shown that, under the Pitman closeness criterion, 80(x) = x dominates 
81(x) = 0.9Ixl, 81 dominates 82(x) = 3.2Ixl, and 82 dominates 80 , If one of 
the three estimators 80 , 81, and 82 has to be selected, the criterion is of no 
~p. 
6 
Obviously, nontransitivity prevents the Pitman criterion from being 
equivalent to a loss; therefore, it does not pertain to Decision Theory. For 
the same reason, it cannot be equivalent to stochastic domination. Actually, 
Blyth and Pathak (1985) provide an example where the two criteria give 
opposed ordering. It is also impossible to define a (decision-theoretic) Bayes 
estimator for the Pitman criterion (although a posterior Pitman estimator 
may exist. See Bose (1991) and Ghosh et al. (1993).) 
A second major defect of Pitman closeness is that it may exclude some 
classical estimators although these are admissible under most losses. For 
instance, Efron (1975) noticed that it is possible to dominate 80 (x) = x 
for the Pitman closeness in the normal case, x 
f'.J N((),l). Robert et at. 
(1993) show that there is a Stein effect for Np((),Ip) (p ~ 2), and that 
the dominating condition only involves an upper bound on the shrinkage 

Exercises 
79 
function h (see also Sen et al .. and Exercise 2.58). The following result 
extends Efron (1975) to the general case when x cv f(x - 8) and 8 is the 
median of the distribution (see Exercise 2.55 for a proof). 
Proposition 2.24 Under the above conditions, the estimator Do(x) 
= x is inadmissible for the Pitman criterion. 
Moreover, the dominating estimators may have a strange behavior, like 
being 0 on large parts of the sample space (see Exercise 2.54). 
These multiple drawbacks seem to indicate clearly that the Pitman 
closeness is not a viable alternative to Decision Theory. On the other hand, 
the failure of this substitution reinforces our belief that Decision Theory is 
the proper setup to take decisions under uncertainty. As stressed in the In-
troduction, determination of the loss is an important step in the derivation 
of the model. This requirement is too often bypassed by resorting to classi-
cal losses, and it would be interesting to consider loss robustness analyses, 
similar to those conducted about the influence of the prior distribution (see 
§3.4). However, the difficulty of the task at hand is not enough to justify 
the abandonment of the coherence inherent to Decision Theory for exotic 
criteria like the Pitman closeness. 
Exercises 
Section 2.2 
2.1 
Show that, if the utility function U is convex, every P E PE satisfies 
JEP[r] = 1 
rdP(r) j P. 
Conclude that a concave loss is not realistic. 
2.2 Consider four dice with respective numbers on their faces (4,4,4,4,0,0), 
(3,3,3,3,3,3), (6,6,2,2,2,2), (1,1,1,5,5,5). Two players roll one die each 
and compare their outcome. Show that the relation die [i] beats die b] is 
intransitive, Le., that, for every choice of the first player, the second player 
can choose a die so that the probability of winning is greater than 0.5. 
Relate this example to the Pitman closeness setup of §2.6. 
2.3 Show that PB c PE, Le., that bounded reward distributions have a finite 
expected utility. 
2.4 Show Lemmas 2.1 and 2.2. 
2.5* (De Groot, 1970) In order to show the extension of Theorem 2.3 from PB 
to PE, consider a sequence Sm decreasing (for j) in R such that, for every 
r E R, there exists m with Sm j r. If P E PE and if P({Sm j r}) > 0, 
denote by Pm the conditional distribution 
P (A) _ p(An {sm j r}) 
m 
-
P( {sm j r}) 
. 
Similarly, if tn is an increasing sequence in R such that, for every r E R, 
there exists n with r :< tn, we define pn as 

80 
2. Decision-Theoretic Foundations of Statistical Inference 
when P( {'I' j tn }) > O. We assume such sequences can be exhibited in R. 
a. Show that pn and Pm are included in 'PH. 
We introduce the additional hypothesis: 
(A6) For every P, Q E 'Ps, such that there exists '1'0 E R satisfying P( {'I' j 
ro}) = Q( {ro j r}) = 1, the ordering P j Q is necessarily satisfied. 
b. Show that (A6) is actually satisfied in 'PH. 
c. Show that, for every P E 'Ps, 
lEP[U(r)] = 
lim lEP=[U(r)] = lim lEpn[U(r)]. 
m~+~ 
n~+~ 
d. Consider P E 'Ps and m < m1, n < n1 such that P({Sm j r}) > 0 and 
P( {'I' j tn }) > O. Show that 
The second additional hypothesis: 
(A7) Consider P and Q in 'Ps. If there exists mo such that Pm ~ Q when 
m :::: mo, then P ~ Q . Moreover, if there exists no such that pn j Q 
when n :::: no, then P j Q, 
is assumed to hold below. 
e. Consider P and Q in 'Ps with '1'1, '1'2 in R such that 
P({r1 j r}) = Q({r2 j r}) = 1. 
Show that P j Q if and only if lEP[U(r)] ::; lEQ[U(r)]. (Hint: Consider 
the sequences pn, Pm, and am = lEP=[U(r)], bn = lEpn[U(r)]. Use 
hypothesis (A4) and questions c. and d.) 
f. Deduce from the above question that, if P, Q E 'Ps, P j Q if and only 
if lEP[U(r)] ::; lEQ[U(r)]. 
2.6 In the setup of Example 2.3 on the Saint-Petersburg paradox, give the av-
erage utility of a player for 8 = 1 and 8 = 10. Compute the average number 
of games a player is ready to play in the modified game. 
2.7* (Smith, 1988) An expert has a preference ordering such that the rewards 
ooI(x+h) + (l-oo)I(x_h) and x are equivalent, with a independent of x. Show 
that the utility function of this expert is either linear (when a = 1/2), of 
the form eCx (c> 0) (a < 1/2), or of the form 1 - e- cx (a> 1/2). 
2.8 
(Raiffa, 1968) In a first setup, a person has to choose between a sure gain of 
$10,000 (a1) and a gain of $50,000 with probability 0.89 (a2). The second 
setup is such that a gain of $50,000 with probability 0.1 (a3) is opposed 
to a gain of $10,000 with probability 0.11 (a4). Show that, even if it seems 
natural to prefer a1 to a2 and a3 to a4, there is no utility function preserving 
the order a1 j a2 and a3 j a4. 
2.9 In the setup of the Saint-Petersburg paradox defined in Example 2.3, con-
sider the following three classes of utility functions: 
(i) U(r) = log(8 + '1'); 
(ii) U(r) = (8 + r)P (0 < p < 1); and 
(iii) U(r)=I-e8+ r . 

Exercises 81 
For each class, determine the maximum entrance fee and the optimal num-
ber of games. 
Section 2.3 
2.10 (Casella, 1990) Show that, if the function r, from IR+ in 1R+, is concave, 
then r(t) is nondecreasing and r(t)/t is nonincreasing. 
2.11 Considering the loss proposed in Example 2.5, show that a perfect expert for 
N = 2 dominates a perfect expert for N = 1. Does the same phenomenon 
occur for N = 37 
2.12 (Smith, 1988) Using the notations of Example 2.5, the Brier score is defined 
as the following loss function: 
N 
N 
L(O,p) = I: qi(Pi - Oi)2 + q(l - q) - I: qi(Pi _ q)2, 
i=l 
i=l 
with q = 2::':1 qiOi, the proportion ofrainy days. Show that a perfect expert 
PI is better than a perfect expert P2 if its "resolution" 
N 
R = I: qi(Oi - q)2 
i=l 
is larger. Comment on the form of the loss. 
2.13 Show that, for a loss function L(O, d) strictly increasing in Id - 01 such that 
L(O,O) = 0, there is no uniformly optimal statistical procedure. Give a 
counterexample when 
2.14 In relation to Example 2.5, the scoring rule of a weather forecaster is the 
sum, over the year, of the errors (IAij - Pi)2 for all the days where the 
probability Pi was announced and where Aij is the event that it actually 
rained. If ni is the number of days that Pi was forecasted, show that the 
scoring rule can be decomposed as 
N 
ni 
N 
I: I: (IAij -Oi)2+ I:ni(Oi-Pi)2. 
i=l j=l 
i=l 
2.15* (Schervish, 1989) Consider an inferential problem where the probability 
P of an event E is to be forecasted. The answer 8 E [0,1] of a forecaster is 
evaluated through a scoring rule L(E, 8), which takes the value 9i(8) ~ 0 if 
IE = i. The scoring rule is said to be proper if the average error 
m(8) = P91(8) + (1 - P)90(8) 
is minimized for 8 = p. 
a. Show that, for a proper scoring rule, 90 is nondecreasing and gl is non-
increasing. 
b. Show that, if the gi are differentiable, the scoring rule is proper if and 
only if 

82 
2. Decision-Theoretic Foundations of Statistical Inference 
-P9~(P) = (1- P)9~(1- p) 
for every p in [0,1]. 
c. Deduce that, when the scoring rule is proper, there exists a nonnegative 
function h, integrable on [0,1] such that 
90(r) = 1 h(t) dt 
[O,r] 
and 
91(r)=1 
-t-h(t)dt. 
[l-r,l] 1 - t 
2.16 Show through discrete and continuous examples that a Bayes estimator can 
correspond to several prior distributions for the same loss function. 
2.17 Two experts must provide an estimate of p E [0,1] under the loss (8 _ p)2. 
They have the respective prior distributions 7r1 and 7r2, equal to Be(1,2) 
and Be(2, 3). 
a. Give both estimates 81 and 82 when the experts answer separately (with 
no observation). 
b. Expert 1 knows 82 . We assume that the quantity p is observed afterward 
and that the best expert is fined (8i - p? while the worst expert is fined 
a fixed amount A. Show that the loss function for expert 1 is 
(81 - p)2II61-pl::S:162-pl + AII61-pl>162-pl' 
Deduce that, if A is large enough, the optimal answer for expert 1 is 
81 = 82 . 
c. Modify the above loss function in order to force expert 1 to give an 
honest answer, i.e., the original 81 . 
2.18 (Raiffa and Schlaifer, 1961) Given a loss function L(e, d), define the opti-
mal decision as the decision de which minimizes L(e, d) for a given e. The 
opportunity loss is then defined as L*((),d) = L((),d) - L((),do). 
a. Show that this is equivalent to assume that infe L(e, d) = 0 for every e. 
b. Show that the set of classical (frequentist) optimal procedures (admissi-
ble, minimax) is the same for Land L * . 
c. Show that the Bayes procedures are the same for Land L *. 
2.19 (Raiffa and Schlaifer, 1961) Given a loss function L((), d) and a prior dis-
tribution 7r, the optimal prior decision is d1r which minimizes JE1r [L(e,d)]. 
a. Consider V = {d1 , d2} and L(e, d1 ) = 0.5 + e, L(e, d2 ) = 2 - e. Give the 
optimal prior decisions when 7r is Be(l, 1) and Be(2, 2). 
b. The value of sample information X is defined as 
where 81r (x) is the regular Bayesian estimator of e. Indicate why v(x) ~ 0 
and give the value of sample information when X"" B(n, e) for the above 
loss function and priors. 
c. When e = V = JR, xle "" N(e, 1), and e "" N(eo, 102 ), show that the 
optimal prior decision under squared error loss is d1r = eo and that the 
value of sample information is (eo - x? Conclude about the coherence 
of this notion. 
2.20 An investment strategy can be conducted according to two different state-
gies, d1 and d2 • The benefit (or utility) of the investment depends on a 
rentability parameter e E JR and is U(e, di) = ki + Kie. 

Exercises 83 
a. Given a prior distribution 7r on (), what is the optimal prior decision? 
b. Let x rv N((), 1) and let () rv N(O, 10). Give the optimal prior and pos-
terior strategies. Give the improvement brought by the observation of x 
in terms of posterior utility and expected utility. 
c. If there is a cost Cs for the observation of x, determine the maximum 
cost Cs when the advantage of observing x disappears. 
2.21 (Raiffa and Schlaifer, 1961) In a setup similar to the above exercise, the 
decision space is 'D = {d l ,d2 } and the parameter () E [0,1]. The utility 
function is L((), di) = ki + Ki(). 
a. Defining 'P = (kl -
k2)/(Kl - K2), show that 'P rf- (0,1) implies that 
one of the two decisions is always optimal. In the following questions, 
we assume 'P E (0,1). 
b. Let xl() rv B(n, ()) and let () rv Be(r, n' - r). Compute the optimal prior 
and posterior decisions and the expected improvement (in utility) gained 
by using the observation x. 
c. Given an observation cost of K for each Bernoulli random variable, de-
termine the optimal sample size n for the expected utility. 
Section 2.4.1 
2.22 Prove Theorem 2.6 when r(7r) is finite. 
2.23 Compare 00 and 0* of Example 2.4 under "0-1" loss. Does this result con-
tradict the Rao-Blackwell Theorem (Theorem 2.7)? 
Section 2.4.2 
2.24 Produce an example similar to Example 2.9, but where A would be forced 
to confess from a Bayesian point of view. 
2.25 Consider the case when e = {()l, ()2} and 'D = {dl , d2, d3}, for the following 
loss structure: 
dl 
d2 
d3 
()l 
2 
° 
0.5 
()2 
0 
2 
1 
a. Determine the minimax procedures. 
b. Identify the least favorable prior distribution. (Hint: Represent the risk 
space associated with the three actions as in Example 2.10.) 
2.26 Consider the following risk function for e = {()l,()2} and 'D = {dl ,d2,d3}: 
dl 
d2 
d3 
()l 
1 
2 
1.75 
()2 
2 
1 
1.75 
a. Draw the risk diagram as in Example 2.10 and deduce the minimax 
estimators. 
b. Deduce from this example that minimaxity is not coherent in the fol-
lowing sense: dl ,d2,d3 may be such that maxeR((),dl) 2': maxeR((),d3) 
and maXe R((), d2 ) 2': maxe R((), d3 ), while the minimax estimator is of 
the form adl + (1 - a)d2 • 

84 
2. Decision-Theoretic Foundations of Statistical Inference 
Section 2.4.3 
2.27 Prove Lemma 2.8. 
2.28 Consider x '" B(n,B), with n known. 
a. If 71'(B) is the beta distribution Be( y'ri/2, y'ri/2) , give the associated pos-
terior distribution 71'(Blx) and the posterior expectation, 811'(x). 
b. Show that, when L( 8, B) = (B - 8?, the risk of 811' is constant. Conclude 
that 811' is minimax. 
c. Compare the risk for 8'" with the risk function of 80(x) = x/n for n = 
10,50, and 100. Conclude about the appeal of 811'. 
2.29 Prove Lemmas 2.9 and 2.10. 
2.30 Consider x '" N(B, 1) and B '" N(O, n). Show that the Bayes risk is equal 
to n/(n + 1). Conclude about the minimaxity of 80 (x) = x. 
2.31 * Give the density of the uniform distribution on the sphere of radius c and 
derive the marginal distribution of x'" Np(B, Ip), when B is uniformly dis-
tributed on this sphere. Compute the posterior expectation 8'" and study 
its properties. 
2.32 Show the equivalent of Example 2.12 when x '" P('\), i.e., that 80 (x) = x 
is minimax. (Hint: Note that 80 is a generalized Bayes estimator for 71'(.\) = 
1/.\ and use a sequence of 9(0.,(3) priors.) 
2.33 Establish Propositions 2.12, 2.15, and 2.16. 
Section 2.4.4 
2.34 Show that the formal Bayes risk of the p-value defined in Example 2.14 is 
indeed bounded. 
2.35 Consider x ",Np(B, Ip). A class of estimators of IIBW is given by 
8c(x) = IIxl1 2 + c, c E JR. 
a. Show that, under quadratic loss, 8_p minimizes the risk for every B 
among the estimators 8c • Does this estimation problem have a value? 
b. How can we choose w(B) so that the risk of 8- p is uniformly bounded for 
the quadratic loss weighted by w(B)? Conclude about the minimaxity of 
8-p • 
c. Show that 8~p is not admissible and propose an estimator which domi-
nates 8_p uniformly. 
2.36 Show that, under squared error loss, if two real estimators 81 and 82 are 
distinct and satisfy 
the estimator 81 is not admissible. (Hint: Consider 83 = (81 + 82)/2 or 
84 = 8f8~-a.) Extend this result to all strictly convex losses and construct 
a counterexample when the loss function is not convex. 
2.37 Let e = {B1' B2} and consider the case when the risk set is R = {( Tl, T2); 
(T1 - 2)2 + (T2 - 2)2 < 2, T1 ::; 2, T2 ::; 2}. 
a. Draw R and deduce whether there exists a minimax point. 
b. Exhibit the two admissible rules for this problem. 
c. What can be said about the existence of Bayes procedures? 

Exercises 85 
2.38 Two experts have different loss functions described in the following table 
for D = {d1,d2 ,d3} and e = {B1 ,B2 }: 
d1 
1/1 
1.5/4 
d2 
d3 
2.5/1.5 2/2.5 
2/3.5 
3/3 
a. Plot the risk sets for both experts and identify minimax and admissible 
procedures in each case. 
b. There are several ways to combine the expert opinions, i.e., to derive a 
single loss function. For each of the following choices, derive the risk set 
and the optimal procedures: 
(iii) L = v'L1L2 . 
c. For which choice of L above are the admissible rules admissible for one 
of the two original losses? In which case is the risk set convex? 
Section 2.4.5 
2.39 Show that the Stein paradox (as described in §2.4.5) cannot occur when 
150 is a proper Bayes estimator whatever the dimension p is. (Note: Brown 
(1971) shows that there are also generalized Bayes estimators which enjoy 
this property.) 
2.40 Show that the majorizing constant in Theorem 2.17 can be replaced by 
c = 2 
q - 20: 
. 
P - q + 4,6 
(Hint: Bound h2(t,u) by c(u/t)h(t,u) first.) Compare the two bounds. 
2.41 * (Stein, 1973) Establish Stein's lemma: If x ~ N(B, 1) and f is continuous 
and a. e. differentiable, then 
lEo [(x - B)f(x)] = lEo [!'(x)]. 
Deduce that, if x ~ Np(B, E), b(x) = x+E,(x), and L(B, b) = (b-B)tQ(b-
B), with, differentiable, then 
R(B, b) = lEo [tr(QE) + 2tr(JI'(x)Q*) + ,(x)tQ*,(x)] , 
where tr(A) is the trace of A, Q* = EQE and JI'(x) is the matrix with 
generic element -fL,j(x). (Note: This representation of the risk leads to 
the technique of ;:r'ibiased estimation of the risk, which is quite influential 
in the derivation of sufficient conditions of domination of usual estimators. 
See Berger (1985a) and Johnstone (1988).) 
Section 2.5 
2.42* Establish Propositions 2.18,2.19, and 2.20. Show Shinozaki's lemma (1977): 
if 15 is admissible for the usual quadratic loss, it is admissible for every 
quadratic loss. 
2.43 Consider 71"(B) = (1/3)(U[0,1] (B) + U[2,3] (B) +U[4,5j(B)) and f(xIB) = Be-ox. 
Show that, under the loss (2.8), for every x, there exist values of kl and k2 
such that the Bayes estimator is not unique. 

86 
2. Decision-Theoretic Foundations of Statistical Inference 
2.44 Establish Proposition 2.22 and show that the loss L considered in Example 
2.18 is equivalent to estimate llHo un under the absolute error loss, 
L(8, 6) = 18 - 61· 
Derive the Bayes estimator associated with the quadratic loss. Conclude. 
2.45*(Zellner, 1986a) Consider the LINEX loss in IR, defined by 
L(8, d) = ecce-d) - c(8 - d) - 1. 
a. Show that L(8, d) > 0 and plot this loss as a function of (8 - d) when 
c = 0.1,0.5,1,2. 
b. Give the expression of a Bayes estimator under this loss. 
c. If Xl, ... ,Xn rv N(8, 1) and 7r(8) = 1, give the associated Bayes estima-
tor. 
2.46 (Berger, 1985a) Consider X rv N(8, 1), 8 rv N(O, 1) and the loss 
L(8,6) = e3e2 / 2(8 _ 6)2. 
a. Show that 611'(x) = 2x. 
b. Show that 611' is uniformly dominated by 6o(x) = X and that r(7r) = +00. 
2.47 Determine the Bayes estimator associated with the absolute error loss in 
IRk, 
L(8,6) = 118 - 611. 
2.48 Consider the following questions for the entropic and the Hellinger intrinsic 
losses: 
a. Show that Le (resp. LH) is nonnegative, is equal to 0 when d = 8, 
and determine under which condition d = 8 is the unique solution of 
Le(8, d) = 0 (resp. of LH(8, d) = 0). 
b. Give the expressions of both losses when X rv N(O, 8) and x rv Be(n, 8). 
c. Show that, if x rv 9(0:,8) and 8 rv 9(v, xo), the Bayes estimator of 8 
under the Hellinger loss is of the form kj(xo + x). 
2.49* (Wells, 1992) As mentioned in §2.5.4, the Bayes estimators are not invari-
ant under arbitrary reparametrizations. In the normal case, x rv N(8, 1), 
show that the only transformations of 8 for which the Bayes estimators are 
invariant under squared error loss are the affine transformations, TJ = a8 + b. 
2.50* (Efron, 1992) Derive the Bayes estimators of 8 when 81x rv N(f1(x) , 1) and 
when the loss function is the asymmetric squared error loss, 
L(8 6) = {W(8 - 6? 
if 6 < 8, 
, 
(1 - w)(8 - 6? otherwise. 
2.51 Consider y = X+E with E and x independent random variables and IE[E] = O. 
a. Show that IE[ylx] = x. 
b. Show that the reverse does not necessarily hold, i.e., that IE[xly] is not 
always equal to y. (Hint: Consider, for instance, the case when x rv 
pN(81, 1) + (1 - p)N(82 , 1) and E rv N(O, 1).) 
Section 2.6 

Exercises 87 
2.52 Show that, for the universal distributions of Rukhin (1978), the Bayes esti-
mators are indeed independent of the loss function. In the particular case 
when x '" 9(1/, 1/1/) identify (), A 1(x), A 2(x), and the universal prior 7r(()). 
The following exercises (2.53-2.58) consider the Pitman closeness criterion. An 
p 
estimator 01 of () is said to Pitman-dominate an estimator 02, denoted 01>-02, if, 
for every () E e, 
The notion of Pitman-admissibility follows directly. 
2.53* Consider a median unbiased estimator OM, i.e., OM such that 
VB, 
PO(OM (x) :::; ()) = 0.5. 
a. Show that OM is the best estimator (for the Pitman criterion) among 
the linear estimators OM (x) + K, K E JR. 
b. If () > 0 and OM > 0, show that OM is also the best estimator (for the 
Pitman criterion) among the estimators KoM , K > O. 
2.54* Consider X = ()U, () > 0, U '" U( -0.9,1.1). Show that 
p 
p 
p 
X >- 0.91XI >- 3.21XI >- X . 
2.55* (Robert et al., 1993) Consider X '" f(x - ()), with 
1~ f(u) du = 1/2 
and f(O) > O. If F is the c.dJ. of X for () = 0, the function E(()) is defined 
by 
F( _()) = { Po(O < X < E(())) 
if () > 0, 
1- Po(O > X> -E(())) 
if () < 0, 
and E(O) = O. Consider 
()1 = Arg{min I() + E(())I}, 
(}2 = Arg{min I() - E(())I}· 
0>0 
0<0 
The truncated version of E is defined by 
The set A satisfies 
(x,()) E A 
if and only if 
() < x:::; () + E*(()) 
for () > 0, and 
(x, ()) E A 
if and only if 
() - E*(()) :::; X < (). 
for () < O. 
a. Justify the truncation of E in terms of A and represent A in a special 
case when the derivation of E* is manageable. 

88 
2. Decision-Theoretic Foundations of Statistical Inference 
b. Show that, if o(x) is a nondecreasing function such that (x,o(x)) E A, 
p 
then 0>- oo(x) = x. 
c. Show that, if F(c) - F( -c) = 1/2, every estimator 0 such that 
o(x) = 0 
when 
Ixl < c 
(2.15) 
is Pitman-admissible. 
d. When 0 is monotone, satisfies (2.15), and belongs to A, show that 0 is 
Pitman-admissible and Pitman-dominates 00. Show that 
and conclude about the existence of such estimators. 
2.56 Consider a couple of random variables (x, y) with joint c.dJ. 
xy 
) 
Fa(x,y) = l+a(l_x)(l_y):U:ro,l]2(x,y. 
a. Show that Fa is indeed a c.d.f. and deduce the density Ja(X,y). 
b. Give the marginal distribution of x and y. 
c. Suppose two estimators 01 and 02 are distributed according to 0- 2 
Ja(01/0, 02/0). What can be said about the Pitman closeness to O? (Hint: 
Compute P(lo1 - 01 < 102 - (1).) 
-P 
2.57*Show that, if Xl, X 2 ~ J(xIO), X >- Xl. Apply this result to the case of 
the Cauchy distribution. Show that, for every real 7], X is Pitman-closer 
to 7] than Xl, even if 7] is arbitrary. (Nate: This property is not specific to 
Pitman closeness, as it is also satisfied by the quadratic loss.) 
2.58* (Robert et ai., 1993) 
Show (or use the result) that, if X;(p,)..) is the 
a-quantile of a noncentral chi-squared distribution, X~()..), it satisfies 
p - 1 +).. :s X6.5(P,)..) :s X6.5(P,O) +)... 
a. Deduce from this inequality that the James-Stein estimators 
( 
hex) ) 
Oh(X) = 1- W 
x 
Pitman-dominate 00 when x ~ N(O, Jp ) and 
0< hex) :s 2(p - 1). 
b. Show that this condition is also necessary when h is constant. 

3 
From Prior Information 
to Prior Distributions 
Undoubtedly, the most critical and most criticized point of Bayesian anal-
ysis deals with the choice of the prior distribution. Indeed, in practice, it 
seldom occurs that the available prior information is precise enough to lead 
to an exact determination of the prior distribution, in the sense that many 
probability distributions are compatible with this information. It is then 
necessary to use an approximation which choice can drastically alter the 
subsequent inference. In particular, the systematic use of parametrized dis-
tributions (like the normal, gamma, beta, etc., distributions) or conjugate 
distributions cannot be justified, because it trades an improvement in the 
analytical treatment of the problem for the subjective determination of the 
prior distribution. It may therefore ignore part of the prior information. 
Some settings call for a partially automated determination of the prior dis-
tribution when prior information is too expensive, sparse, or totally lacking. 
We propose in this chapter two appropriate methods, the conjugate prior 
approach, which requires a limited amount of information, and the Jeffreys 
noninformative priors, which can be directly derived from the sampling 
distribution. 
Historically, criticisms on the choice of the prior distribution can be 
traced back to Laplace as, while Bayes was able to justify his prior modeling 
on the billiard balls by a physical reasoning (see §1.2), the abstract model-
ings of Laplace on the distribution of white balls in an urn (Example 1.6), 
or on the proportion of boys (Example 1. 7) were more apt to give an open-
ing for criticisms which indeed appeared soon after (see Boole (1854), Venn 
(1866), Bertrand (1889), and Chrystal (1891)). The attacks of these oppo-
nents to the Bayesian approach were justified in the sense that it is always 

90 
3. From Prior Information to Prior Distributions 
possible to choose a prior distribution which gives the answer one wishes: in 
other words, ungrounded prior distributions produce unjustified posterior 
inference. In 1939, the work of Jeffreys (1961) thus came as a blessing for 
the Bayesian community since it gives a method to derive the prior distri-
bution directly from the sampling distribution, although some Bayesians 
disagree with the use of such automated methods (see, e.g., Lindley, 1971). 
More recently, theoretical developments on robustness and sensitivity anal-
ysis also provided a sounder basis for Bayesian analysis when it is faced 
with incomplete prior information. 
3.1. Subjective Determination and Approximations 
Unless the decision maker is informed about the (physical, economical, bi-
ological, etc.) mechanism underlying the generation of the parameter (), it 
is generally quite difficult to propose an exact or even a parametrized form 
for the prior distribution on (). Indeed, in most cases, () does not have an 
(intrinsic) existence of its own, but rather corresponds to an indexing of the 
distributions describing the random phenomenon of interest. The prior 7r 
is then a tool summarizing the available information on this phenomenon, 
as well as the uncertainty related with this information. Such settings ob-
viously imply approximations of the "true" prior distribution (if there is 
such a thing!). 
Example 3.1 Assume that the decision maker wants to model the distribu-
tions on both the observations and the parameter as normal distributions: 
Xl,"" Xn '" N((}, 1) and () '" N(I1-, T). Since the posterior mean of () is 
7r 
XT + l1-/n 
{j (Xl, ... , xn) = 
1/' 
T+ 
n 
the hyperparameter l/T behaves like the sample size, n. Therefore, this 
hyperparameter can be approximated by deriving a "sample-equivalent" of 
the amount of information brought through 11-, for instance, by considering 
that the (known) mean 11- is the average of a virtual sample of size l/T. 6. 
When the parameter space, e, is finite, one can often obtain a subjec-
tive evaluation of the probabilities of the different values of (). Sometimes, 
it is possible to use past experiments of the same type, but this is not 
always possible (think, for instance, of constructing the probability of a nu-
clear war!) and, more fundamentally, this frequentist approach leads to the 
conceptual question of the repeatability of experiments (Are experimental 
setups always the same? Can a previous experiment be without effect on 
the following one?); Jeffreys (1961) provides an extended criticism of this 
approach. 
From another point of view, it is also possible to build up a prior distri-
bution the way utility functions were constructed in the previous chapter, 

3.1. Subjective Determination and Approximations 
91 
by determining a scale of the respective likelihoods of the values of the pa-
rameter (). When the scaling is coherent, i.e., respects some axioms given 
below, the existence of a prior distribution can deduced. The existence of 
subjective prior distributions as a consequence of an ordering of relative 
likelihoods is very important, since it allows us to escape the restrictive 
framework of frequentist justifications which are not always applicable. We 
describe below the axioms underlying this derivation of the existence of a 
prior distribution from the ordering on the likelihoods and refer the reader 
to DeGroot (1970, Chap. 6) for a more thorough treatment (see also Jef-
freys, 1961). 
Consider, thus, that the decision maker (or the statistician) is able to 
determine an order relation on a a-algebra [3(8). This order relation, de-
noted by::::s, is such that B -< A means that A is more likely than B, B ::::S A, 
that A is at least as likely as B, and B cv A, that A and B are equally likely. 
Obviously, if there exists a probability distribution on (8,[3(8)), P, P au-
tomatically induces an order relation on [3(8). We consider below under 
which hypotheses the reciprocal can be established. A first assumption is 
that the order relation is total: 
(Ad For all measurable sets A and B, one and only one of the following 
relations is satisfied: 
A -< B, 
B -< A 
or A cv B. 
Another assumption is: 
(A2) If AI, A2, BI , B2 are four measurable sets satisfying Al n A2 = BI n 
B2 = 0 and Ai ::::S Bi (i = 1,2), then Al U A2 ::::S BI U B2. Moreover, 
if Al -< BI , Al UA2 -< BI UB2· 
This natural hypothesis implies transitivity for the order relation. The fol-
lowing assumption ensures that there is no measurable set with a negative 
likelihood (i.e., less likely than the empty set): 
(A3) For every event A, 0::::s A and 0 -< 8. 
The additional condition 0 -< 8 avoids the trivial case where all events are 
equivalent. It is also necessary to allow for the comparison of an infinite 
sequence of events. 
(A4) If Al =:J A2 =:J .•. is a decreasing sequence of measurable sets and B 
is a given event such that B ::::S A for every i, then 
This assumption somehow ensures the "continuity" of the preference or-
dering and is related to the a-additivity property of probability measures. 
However, these axioms (Ad-(A4) are still not sufficient to derive the ex-
istence of a probability distribution from the likelihood ordering. In fact, 

92 
3. From Prior Information to Prior Distributions 
a last assumption is also necessary to move from a qualitative comparison 
scaling to a quantitative comparison. 
(A5) There exists a random variable X on (8,B(8)) with uniform dis-
tribution on [0,1], i.e., such that, for all h, 12, intervals on [0,1]' it 
satisfies 
if and only if 
where>. is the Lebesgue measure. 
This additional hypothesis is then sufficient to establish the following exis-
tence result (see DeGroot, 1970, for a proof): 
Theorem 3.1 Under the axioms (Al)-(A5), there exists a distri-
bution P such that P(A) ::; P(B) if and only if A ~ B. 
Compared with the utility function derivation in Chapter 2, the pre-
vious developments on the axiomatic foundations of the prior distribution 
may seem rather limited. A first reason for this brevity is that the above 
hypotheses and the surrounding setup are more difficult to justify. Indeed, 
when an experimenter is able to talk about the likelihood of an event, it 
implies that he has, consciously or not, built up an underlying probabilis-
tic model and, therefore, the previous construction is rather tautological. 
Assumption (A5) is particularly demanding and can seldom be verified in 
practice. Note, however, that a similar criticism could be addressed to the 
derivation of the utility function. A second reason for this limitation takes 
place at a more pragmatic level; in fact, according to Theorem 3.1, the de-
cision maker can recover a prior distribution from his likelihood ordering. 
However, it is most likely, especially when 8 is not finite, that this ordering 
will be coarse, i.e., that the derived a-algebra B(8) will not correspond 
to the usual Borelian a-algebra on 8, thus preventing the use of classical 
distributions on O. Nevertheless, it is comforting to be able to justify the 
use of a prior distribution on an alternative basis than on the frequentist 
model implying repeatability of experiments, even though it is of limited 
use in practice. 
It often occurs that the subjective determination of the prior distri-
bution leads to incoherencies in the likelihood ordering, for psychological 
reasons, but also because the ability of individuals to identify small proba-
bilities is quite limited. On this topic, but also on the practical construction 
of probability distributions and the assessment of forecasters, the reader is 
referred to DeGroot and Fienberg (1983), Dawid (1984), Lindley (1985) 
and Smith (1988). 
Example 3.2 A study in the New England Journal of Medicine showed 
that 44% of the questioned individuals were ready to undertake a treat-
ment against lung cancer when told that the survival probability was 68%. 

3.1. Subjective Determination and Approximations 
93 
However, only 18% were still willing to undertake it when told that the 
probability of failure (death) was 32%. 
,6, 
When the parameter space 8 is uncountable, for instance, equal to 
an interval, the subjective determination of the prior 7r is obviously much 
more complicated. A first approximation of 7r is usually obtained through a 
partition of 8 in sets (e.g., intervals) and determination of the probability of 
each set; 7r(B) is thus approached by an histogram. An alternative approach 
is to select significant elements of 8, to evaluate their respective likelihoods 
and to deduce a likelihood curve proportional to 7r. In both cases, a major 
difficulty occurs when 8 is not bounded, dealing with the construction of the 
tails of the distribution, since it is quite complicated to evaluate subjectively 
the probabilities of the extreme regions of the parameter space, while the 
shape and properties of the resulting estimators deeply depend on them 
(see Example 3.5). 
When no direct information is available on B, an alternative approach 
is to use the marginal distribution of x, 
m(x) = Ie f(xIB)7r(B) dB 
to derive information on 7r. Several techniques have been proposed in the 
literature (see Berger, 1985a, §3.5); apart from the moments method, we 
can mention the maximum entropy and the ML-II methods (Good, 1983). 
The basic reason justifying this derivation is that it may occur that the 
observed random phenomenon can be incorporated into a larger class (or a 
metamodel) about which information is available. For instance, if B is the 
average daily milk production of a given dairy cow, information about B 
can be gathered from the production of the herd it belongs to, although 
these observations originate from the marginal distribution. 
When some characteristics of the prior distribution (moments, quan-
tiles, etc.) are known, assuming that they can be written as 
(3.1) 
(k = 1, ... , K), a way to select a prior 7r satisfying these constraints is the 
maximum entropy method, justified through signal processing arguments 
(see Billingsley (1965) and Jaynes (1983)). Indeed, the prior 7r maximizing 
the entropy is, in a sense, minimizing the prior information brought through 
7r about B. When 8 is discrete, the entropy is defined as 
and the maximum entropy distribution, under the restriction (3.1), is given 
by 

94 
3. From Prior Information to Prior Distributions 
the numbers Ak being derived from (3.1) as Lagrange multipliers. For in-
stance, if there is no constraint on 7r, the maximum entropy distribution is 
the uniform distribution on e. 
The extension to the continuous case is quite delicate, since it involves 
the choice of a reference measure, 7ro, which can be characterized as the "to-
tally noninformative distribution." In fact, this distribution can be selected 
in many ways (see §3.4) and the maximum entropy distribution depends on 
this choice. When a group structure is available (and accepted as part of the 
prior information) for the problem of interest, it is usually agreed that the 
right-invariant Haar measure associated with this group is an acceptable 
choice for 7ro. (Justifications for such a choice are given in Chapter 7.) The 
distribution 7ro being selected, the entropy of 7r is defined as 
£(7r) = lE7I"o [lOg (~)] 
7ro(e) 
J ( 
7r(e) ) 
= 
log 7ro(e) 
7ro(de) , 
which is also the Kullback-Leibler distance between 7r and 7ro. In this case, 
the maximum entropy distribution under (3.1) is given by 
(3.2) 
thus showing the importance of 7ro. Note that the above distributions 7r* are 
necessarily in an exponential family (see §3.2.2). In addition to the depen-
dency on 7ro exhibited in (3.2), another drawback of the maximum entropy 
method is that the constraints (3.1) are not always sufficient to derive a 
distribution on e. Note that this is often the case when characteristics (3.1) 
are related with the quantiles, since the functions gk (e) are of the form 
I( -oo,ak] (e) or I(bk ,00] (e). 
Example 3.3 Consider e, a real parameter such that lE7I"[e] = /-t. If the 
reference measure 7ro is the Lebesgue measure on nt, the maximum entropy 
prior satisfies 7r* (e) oc eA9 and cannot be normalized into a probability 
distribution. On the contrary, if in addition it is known that var( e) = 0-2 , 
the corresponding maximum entropy prior is 
i.e., the normal distribution N(/-t, 0-2 ). 
A rather frequently used alternative when building up a continuous 
prior is to arbitrarily restrict the choice of 7r to a parametrized type of 
density and to determine the corresponding parameters either through the 
moments, or through the quantiles, since the latter are more robust. For 

3.1. Subjective Determination and Approximations 95 
instance, subjective evaluations of the median and of the 75% quantile are 
enough to identify the two parameters of a normal distribution. 
Example 3.4 Let Xi '" B(ni,Pi) be the number of passing students in 
a freshman calculus course of ni students. Over the previous years, the 
average of the Pi is 0.70, with variance 0.1. If we assume that the Pi's 
are all generated according to the same beta distribution, Be(o;,f3), the 
parameters 0; and 13 can be estimated through 
0; 
0;+13 =0.7, 
0;13 
= 01 
(0;+13)2(0;+13+ 1) 
., 
i.e. 0; = 0.77,13 = 0.33, leading to the prior distribution 
P'" Be(0.77, 0.33). 
The choice of a beta distribution is motivated in this setup by conjugate 
prior arguments (see §3.2). 
L:. 
The moments method is often impractical and sometimes produces 
impossible values of the parameters; for instance, it can give negative vari-
ances. However, a deeper drawback of most parametric approaches is that 
the selection of the parametrized family is based on ease in the mathe-
matical treatment, not on a subjective basis like a preliminary histogram 
approximating 7r. These approaches may even lead to a partial rejection of 
the available information, on the grounds that it is not compatible with 
the parametric distribution. For instance, in Example 3.4, the additional 
prior knowledge of the median may prevent the use of a beta distribution. 
Actually, the derivation of a distribution from a histogram may also be 
misleading since different families may fit the histogram and still lead to 
quite different inferences. (Nonetheless, we will study in the next section 
a particular parametrized prior determination in detail, because limited 
information setups call for parametrized prior distributions.) 
Example 3.5 (Berger, 1985a) 
Let x '" N((),l). Assume that the prior 
median of () is 0, the first quartile is -1, and the third quartile is +1. 
Then, if the prior distribution on () is of the form N(p"T), we must have 
() '" N(O, 2.19). On the contrary, the choice of a Cauchy distribution implies 
() '" C(O, 1). Under a quadratic loss, the Bayes estimator will be in the first 
case 
8f(x) = x -
3~9 
and 
87r(x) ~ X _
_ x_ 
2 
1 + x 2 
for Ixl ~ 4 in the second case (see Berger and Srinivasan, 1978). There-
fore, for x = 4, which is an observation quite compatible with the prior 
information in both cases, the two estimations would be 81(4) = 2.75 and 
82(4) = 3.76. 
L:. 

96 
3. From Prior Information to Prior Distributions 
These posterior discrepancies call for some tests on the validity (or 
robustness) of the selected priors, depending on the observation, in order 
to evaluate how a slight change in the prior distribution is perceived in 
the inference about the parameter of interest. (Section 3.4 deals with this 
evaluation.) The example below illustrates again the fact that a too 'vague' 
information can produce very different conclusions, depending on the way 
it is interpreted. 
TABLE 3.1. Ranges of the posterior moments for fixed prior moments. (Source: 
Goutis, 1990.) 
Minimum Maximum Maximum 
/-l2 
x 
mean 
mean 
variance 
3 0 
-1.05 
1.05 
3.00 
3 1 
-0.70 
1.69 
3.63 
3 2 
-0.50 
2.85 
5.78 
1.5 0 
-0.59 
0.59 
1.50 
1.5 
1 
-0.37 
1.05 
1.97 
1.5 
2 
-0.27 
2.08 
3.80 
Example 3.6 (Goutis, 1990) Let x'" f(xIB), with B E IR, and assume that 
the prior mean of B, /-l1, is known. Too many prior distributicns agree with 
this piece of information, since 
inf JE1I" [Blx] = -00 
11" 
and 
supJE1I"[Blx] = +00 
11" 
and no useful inference can be derived from this single fact; note that, in 
this setting, it is not possible to construct a maximum entropy distribution 
either (see Example 3.3). If, in addition, the prior variance /-l2, is fixed, the 
variability of the posterior answers is more restricted since 
-00 < infJE1I"[Blx] ::; supJE1I"[Blx] < +00, 
11" 
11" 
(3.3) 
as long as f(xIB) is positive in a neighborhood of /-ll and bounded when 
IB -
/-l11 is large. Under the same set of assumptions, we have, in addition, 
0= infVar1l"[Blx] ::; sup Var1l" [Blx] < +00, 
11" 
11" 
(3.4) 
Table 3.1 gives the exact range of the bounds (3.3) and (3.4) for a normal 
distribution N(B, 1) and /-ll = 0.' 
6. 
Empirical and hierarchical Bayes methods are two other (rather an-
tagonistic) approaches which naturally incorporate uncertainty about the 

3.2. Conjugate Priors 97 
prior distribution. The first technique relies on the observations (and the 
marginal distribution) to estimate the parameters of the prior distribution; 
it is used by frequentists more often than by Bayesians, because it does 
not belong to the Bayesian paradigm. Formally, it seems paradoxical to 
choose a posteriori a prior distribution. More fundamentally, the choice 
of 7f depending on x, the derived estimators do not enjoy the optimality 
properties of the true Bayes estimators. A last criticism is that too many 
choices are possible for the estimation techniques used in the construction 
of the prior distribution, thus leading to an important arbitrariness in the 
selection of the prior. The second approach (hierarchical Bayes) models the 
lack of information on the parameters of the prior distribution according 
to the Bayesian paradigm, i.e., through another prior distribution on these 
parameters (the parameters of this distribution are then called hyperpa-
rameters and this new prior an hyperprior). Although this choice may seem 
conceptually too abstract, Bayesians usually prefer this approach over the 
empirical Bayes alternative, because it generally provides better estimators 
in practical and theoretical senses. (Chapter 8 presents and compares these 
two methods.) 
3.2. Conjugate Priors 
3.2.1. Introduction 
When prior information about the model is too vague or unreliable, a sub-
jective derivation of the prior distribution is obviously impossible. Other 
reasons (time delays, cost, lack of communication between the statistician 
and the decision maker, etc.) may explain the absence of a well-defined prior 
distribution. Moreover, "objectivity" requirements may force the statisti-
cian to provide an answer with as little subjective input as possible, in order 
to base the inference on the sampling model alone. These settings may seem 
to call for a non-Bayesian solution (maximum likelihood estimator, best un-
biased estimator, etc.). However, keeping in mind the Bayesian foundations 
of the frequentist optimality criteria (see Chapters 2, 6 and 7), it appears 
preferable to follow a Bayesian approach, using an 'objective prior' derived 
from the model as a technical tool. When no prior information at all is 
available, these priors are called "noninformative" and are considered in 
Section 3.4. First, we study in this section a classical parametric approach 
which involves a subjective input as limited as possible, and which also 
underlies the empirical Bayes techniques. 
Definition 3.1 A family F of probability distributions on e is said 
to be conjugate (or closed under sampling) if, for every 7f E F, the 
posterior distribution 7f(t'Jlx) also belongs to F. 

98 
3. From Prior Information to Prior Distributions 
A trivial example of a conjugate family is the set Fo made of all distri-
butions on 8, which is, of course, useless for the choice of a prior distribu-
tion. The main interest of conjugacy becomes more apparent when F is as 
small as possible and parametrized. Indeed, when F is parametrized, switch-
ing from prior to posterior distribution is reduced to an updating of the 
corresponding parameters. This property alone can explain why conjugate 
priors are so popular, as the posterior distributions are always computable 
(at least to a certain extent). On the contrary, such a justification is rather 
weak from a subjective point of view and any other parametrized family 
would be as convenient. Note that the goal to obtain the minimal conjugate 
family as the intersection of all conjugate families is unfortunately doomed 
to failure, since this intersection is generally empty. 
The conjugate prior approach, which originated in Raiffa and Schlaifer 
(1961), can be partially justified through an invariance reasoning. Actually, 
when the observation of x rv f(xIB) modifies 7r(B) into 7r(Blx), the infor-
mation conveyed by x about B is obviously limited; therefore, it should 
not lead to a modification of the whole structure of 7r(B), but only of its 
parameters. In other words, the modification resulting from the observa-
tion of x should be of finite dimension. A more radical change of 7r is thus 
unacceptable and the choice of the prior distributions should always be 
made among conjugate distributions, whatever the prior information is. De 
Finetti (1974) somehow held similar views as he considered that the prior 
information could be translated into virtual past observations as in Ex-
ample 3.1, necessarily leading to conjugate priors for exponential families 
(see below). This requirement gets paradoxical in the extreme case when 
the whole prior distribution is already available! But conjugate priors are 
mainly used in limited information environments, since they only call for 
the determination of a few parameters. Another justification for using con-
jugate priors is that some Bayes estimators are then linear, as shown by 
Diaconis and Ylvisaker (1979) (see Proposition 3.3 below). Nonetheless, the 
main motivation for using conjugate priors is their tractability. 
This particular modeling through a parametrized family of priors is 
indeed attractive, as it allows for an explicit treatment of posterior dis-
tributions. These conjugate priors are sometimes called objective because 
the sampling model, f(xIB), entirely determines the class of priors. 1 A con-
trario, the use of conjugate priors is strongly suspicious for most Bayesians 
since it is mainly justified on technical grounds rather than for fitting prop-
erly the available prior information. Their role is then to provide a first 
approximation to the adequate prior distribution which should be followed 
by a robustness analysis (see §3.4). We will see in Section 3.3 that they 
are more justified if considered as a basis (in the functional sense) for prior 
information modeling. 
1 Any method deriving priors automatically from sampling distributions would 
be similarly "objective." 

3.2. Conjugate Priors 99 
3.2.2. Exponential Families 
Conjugate prior distributions are usually associated with a particular type 
of sampling distributions which always allow for their derivation. These 
distributions constitute what is called exponential families, studied in detail 
in Brown (1986). 
Definition 3.2 Let p, be a u-finite measure on X, and let e be the 
parameter space. Let C and h be functions, respectively, from X 
and e to IR+, and let Rand T be functions from e and X to IRk. 
The family of distributions with densities (w.r.t. p,) 
f(xI8) = C(8)h(x) exp{R(8) . T(x)} 
is called an exponential family of dimension k. In the particular 
case when e c IRk, X C IRk and 
f(xI8) = C(8)h(x) exp{ 8· x}, 
the family is said to be natural. 
(3.5) 
(3.6) 
Note that a change of variables from x to z = T(x) and a reparametriza-
tion from 8 to TJ = R( 8) authorizes us to consider mainly the natural form 
(3.6), although the spaces T(X) and R( e) may be difficult to describe 
and work with. From an analytic point of view, exponential families have 
many interesting properties (see Brown, 1986). In particular, they are such 
that, for any sample from (3.5), there exists a sufficient statistic of constant 
dimension. Indeed, if Xl,"" Xn ,....., f(xI8), with f satisfying (3.6), 
1 n 
X = - LXi E IRk 
n i=l 
is sufficient for all n. The converse to this result has also been shown by 
Pitman (1936) and Koopman (1936): if a family of distributions f('18) is 
such that, for a sample size large enough, there exists a sufficient statis-
tic of constant dimension, the family is exponential if the support of f('18) 
does not depend on 8. (See Jeffreys (1961, §3.71) for a proof.) The restric-
tion on the support of f(xI8) is necessary for the lemma to hold since 
the uniform U[-O,Oj and the Pareto P(o:,8) distributions also satisfy this 
property (see Example 3.11). These distributions could actually be called 
quasi-exponential families because they partake of many interesting prop-
erties of exponential families, including the existence of constant dimension 
sufficient statistics and of conjugate priors. 
Many common continuous and discrete distributions belong to expo-
nential families. 
Example 3.7 If S is 1R k simplex, 

100 3. From Prior Information to Prior Distributions 
k 
S = {W = (WI, ... ,Wk); LWi = 1, Wi> O}, 
i=1 
the Dirichlet distribution on S, 'Dk(aI, ... , ak), is defined by 
k 
f( I ) = r(a1 + ... + ak) II ':"i- 11 ( ) 
P a 
r() r() 
P~ 
s P , 
0'.1 .•. 
ak 
i=1 
where P = (pI, ... ,Pk). Since 
k 
f(pla) = C(a)h(p) exp (L adog(Pi)) , 
i=l 
the Dirichlet distributions constitute a natural exponential family for 
T(p) = (lOg(Pl), ... ,log(Pk)). 
6 
Example 3.8 Let x rv Np((), O'2Ip). Then 
lIP 
f(xl()) = o'P (27r)k/2 exp ( - ~(Xi - ()i)2/2O'2) 
= C((),O')h(x)exp{x.(()/O'2) + IlxI1 2(-1/2O'2)} 
and the normal distribution belongs to an exponential family with natural 
parameters ()/O'2 and -1/20'2. Similarly, if XI, ... ,Xn rv Np((),O'2Ip), the 
joint distribution satisfies 
f(xI, ... , xn) = C'((), O')h'(x1, ... , xn) 
x exp {nx. (()/O'2) + t Ilxi - XW(-1/2O'2)} 
and the statistic (x, ~i Ilxi - x11 2) is sufficient for all n 2: 2. 
In the previous example, the parameter space is of dimension n + l. 
While the dimension of an exponential family is not fixed, since it is al-
ways possible to add convex combinations of the original parameters as 
additional (and useless) parameters, there exists an intrinsic minimal di-
mension associated with this family. 
Definition 3.3 Let f(xl()) = C(())h(x) exp(().x) be a natural expo-
nential family. The natural parameter space is 
N = {(); Ix elJ.xh(x) dJ.L(x) < +00 } . 
The family is said to be regular if N is an open set and minimal 
if dim(N) = dim(K) = k, where K is the closure of the convex 
envelope of the support of J.L. 

3.2. Conjugate Priors 101 
It is always possible to reduce an exponential family to a standard and 
minimal form of dimension m, where m does not depend on the chosen 
parametrization (see Brown, 1986, pp. 13-16). 
Natural exponential families can also be rewritten under the form 
f(xIO) = h(x)ee.x-,P(e) 
(3.7) 
and 'ljJ( 0) is called the cumulant generating function for the following reason, 
whose proof is left to the reader. 
Lemma 3.2 If 0 E NO, the cumulant generating function 'ljJ is Coo 
and 
IEe[x] = '\l'ljJ(0), 
where '\l denotes the gradient operator. 
Example 3.9 Let x rv P(A). Then 
and 'ljJ(0) = exp(O) for the natural parameter 0 = log A. Therefore, IE.x[x] = 
ee = A and var(x) = A. 
6:, 
The regular structures of exponential families allow for numerous sta-
tistical developments, as shown by the extensive literature on the subject. 
(See, for instance, the classification of exponential families according to the 
type of variance function: Morris (1982), Letac and Mora (1990), and Ex-
ercises 3.21 and 8.26.) We show in Section 3.2.3 that they also allow for a 
straightforward derivation of conjugate priors. 
Example 3.10 (Robert, 1991) If x rv N(O, ( 2 ) in a multiplicative model, 
the conjugate prior is not the normal distribution. The likelihood is pro-
portional to 
and the distribution induces an exponential family of dimension 2. There-
fore, the generalized inverse normal distributions I N(a, J.L, T), with density 

102 3. From Prior Information to Prior Distributions 
2.39 
J.I=2 
1.88 
1.25 
-1.5 
3 
FIGURE3.1. Densities of IN(a,p"T) for a = 2, T = 1, and p, = 0,1,2. (Source: 
Robert, 1991.) 
constitute a conjugate family in this model. This family of distributions 
generalizes the distribution of the inverse of a normal observation (which 
corresponds to the case a = 2). 
!::, 
Obviously, most distributions do not belong to an exponential family! 
For instance, the Student's t-distribution, Tp(v, e, (J"2), cannot be written 
under the form (3.5). Definition 3.2 also excludes all distributions with 
nonconstant support. It is sometimes possible to derive a conjugate prior 
for some of these distributions but they are often impractical and depend 
on many hyperparameters. 
Example 3.11 Pareto distributions, P(a, e), with density 
(e > 0), 
are an exception to this rule since, although outside the exponential family 
framework as their support depend on e, they allow for simple conjugate 
distributions on e, namely, Pareto distributions for l/e. 
!::, 
Other examples of families where conjugate priors are available are 
U[_II,II] and U[O,II] distributions; these distributions are also quasi-exponen-
tial, since they allow for sufficient statistics of constant dimension. For 
instance, if Xl, ... ,Xn rv U[ -II ,11], a sufficient statistic is the order statistic 
(X(l), X(n))' 
Note that, in Example 3.10, the conjugate prior on e depends on three 
parameters (more exactly hyperparameters), a, /-l, and 7 2; therefore, its 
use induces a greater complexity than the sampling distribution. This phe-
nomenon, i.e., the fact that the closure of the model requires a much larger 
number of hyperparameters, is often encountered for curved exponential 
families, i.e., when a natural reparametrization by TJ = R(e) is not use-
ful because of the constraints on the natural parameters. It is obviously a 

3.2. Conjugate Priors 103 
drawback, since the values of these hyperparameters have to be determined 
to derive an inference on B using conjugate priors. 
Some distributions, like Student's t-distribution, do not allow for con-
jugate families, except the trivial Fo. In such cases, however, it is sometimes 
possible to express the distribution as a mixture of distributions from ex-
ponential families; f is then said to be a hidden mixture, since this mixture 
representation is of no importance for the inferential problem, but is useful 
for the practical computation of posterior distributions and Bayes estima-
tors, as shown in Chapter 9. 
Example 3.12 (Dickey, 1968) For Student's t-distribution, there exists a 
hidden mixture representation through the normal distribution, since f(xIB) 
is the mixture of a normal distribution and an inverse gamma distribution: 
If x'" Ti(p,B,a2 ), 
xlz '" N(B, za2), 
Z-l '" Q(p/2,p/2). 
A technically interesting prior on B is then N(J.L, 7 2) and most of the compu-
tations can be done conditionally on z. This decomposition is particularly 
useful for larger dimensions since it allows for a reduction of the number of 
integrals to one. 
6 
Example 3.13 Several noncentral distributions can be written as the (hid-
den) mixture of the corresponding central distribution by a Poisson dis-
tribution, due to an infinite divisibility property (see Feller, 1971, Chap. 
9). For instance, this is the case for the noncentral chi-squared distribution, 
x;(..\). In fact, when x'" X;(.).), the generation of x can also be decomposed 
as 
z '" P()../2). 
This decomposition is used in James and Stein (1961) to express the risk of 
the James-Stein estimator and derive a sufficient condition of domination 
of the maximum likelihood estimator (see §2.4.6). 
6 
3.2.3. Conjugate Distributions for Exponential Families 
Consider f(xIB) = h(x)eo.x-w(lJ), a generic distribution from an exponential 
family. It then allows for a conjugate family, as shown by the following result 
whose proof is straightforward: 
Proposition 3.3 A conjugate family for f(xIB) is given by 
(3.8) 
the posterior distribution being 11"( BIJ.L + x,).. + 1). 
The measure defined by (3.8) is finite; thus, it induces a probability 
distribution on e if and only if 

104 3. From Prior Information to Prior Distributions 
and 
!!:. E NO 
). 
, 
where NO is the interior of N (see Exercise 3.31). Therefore, there exists 
an automated way to deduce a conjugate distribution from f(xIO); this is 
why (3.8) is often called the natural conjugate distribution of f. Table 3.2 
presents the conjugate distributions for the usual distributions belonging to 
an exponential family.2 Obviously, Bayesian inference cannot be conducted 
unless the hyperparameters J.l and ). are known. The automatic aspect of 
conjugate priors is thus misleading since they still require a subjective input 
through the determination of these values. Note also that (3.8) requires an 
additional parameter, compared with f(xIO). 
TABLE 3.2. Natural conjugate priors for usual exponential families 
f(xI9) 
7r(9) 
7r(9Ix) 
Normal 
Normal 
N(9,(J"2) 
N(/l-,72) 
N(p((J"2/l- + 72X), p(J"272) 
p-l = (J"2 +72. 
Poisson 
Gamma 
P(9) 
Q(a,{3) 
I 
Q(a+x,{3+1) 
Gamma 
Gamma 
Q(II,9) 
Q(a,{3) 
I 
Q(a+II,{3+x) 
Binomial 
Beta 
B(n,9) 
Be(a, (3) 
I Be(a+x,{3+n-x) 
Negative Binomial 
Beta 
Neg(m,9) 
Be(a,{3) 
I 
Be(a+m,{3+x) 
Multinomial 
Dirichlet 
Mk(9l , ... ,9k) 
V(al, ... , ak) 
I V(al + Xl, ... , ak + Xk) 
Normal 
Gamma 
N(/l-,1/9) 
Qa(a, (3) 
I Q(a+0.5,{3+(/l--x?/2) 
For natural exponential families, conjugate priors have an additional 
appeal, as shown by Diaconis and Ylvisaker (1979): If ~(O) is the expectation 
of x'" f(xIO), the posterior mean of ~(O) is linear in x for a conjugate prior 
distribution. 
Proposition 3.4 If (3 is an open set in lR k and 0 has the prior 
distribution 
with Xo EX, then 
2 Since the conjugate distributions are also from an exponential family, Bar Lev 
et al. (1990) have studied a reciprocal problem, namely the determination of 
the distributions 7r( 9) for which an exponential family has 7r( 9) as conjugate 
distribution. 

3.2. Conjugate Priors 105 
Therefore, if Xl,"" Xn are i.i.d. f(xle), 
7r 
Xo + nx 
]E [~(e)IXI"'" Xn] = 
. 
..\+n 
(3.9) 
This result is well known for the normal distributions and can then 
be generalized for all exponential families. Note that ..\ is similar to the 
sample size n. Its determination can therefore be achieved, if necessary, 
by considering that the prior information on Xo originated from a virtual 
sample of size ..\. Brown (1986) shows that Proposition 3.4 can be extended 
to the case where 7f'\,xQ is improper. This result can be related to the fact 
that X is the maximum likelihood estimator of ~(e). 
Diaconis and Ylvisaker (1979) have shown, in addition, a reciprocal to 
this proposition, namely, that, if the dominating measure is continuous with 
respect to the Lebesgue measure, linearity of ]E7r [~( e) Ix] as in (3.9) implies 
that the prior distribution is of the form (3.6). Discrete-case extensions are 
more delicate. 
While exponential families usually allow for an easy processing and, 
in particular, for the convenient call to conjugate prior distributions and 
the analytical derivation of posterior means, as in Proposition 3.4, this is 
not always the case. For instance, when X rv Be(a, e) with known a, the 
distribution belongs to an exponential family since 
f( Ie) 
r(a + e)(l - x)iJ 
x 
ex 
r(e) 
but the conjugate distributions are not manageable, as 
( r(a+e))'\ 
iJ 
7f(elxo,..\) ex 
r(e) 
(1 - xo) . 
Example 3.14 Logistic regression is used to describe qualitative models as 
in Example 1.1. Given an indicator variable y, which only takes values in 
{O, I}, and explanatory variables x E IRk, the distribution of Y conditional 
on x IS 
exp(atx) 
Pa(Y = 1) = 1 - Pa(Y = 0) = -1-+-=-ex-'-p--'--(a-'-tx--'-) 
(3.10) 
This model allows for the extension of the quite useful linear regression 
model to more qualitative settings. For a sample (YI, xd, ... , (Yn, xn) from 
(3.10), the model is indeed exponential conditionally on the x/s, as 
n 
n 
f(YI,"" YnIXI,"" Xn, a) = exp(at I: YiXi) II (1 + eatxi)-l, 
i=l 
i=l 

106 3. From Prior Information to Prior Distributions 
which only depends on the sufficient statistic L~=l YiXi. In practice, the 
conjugate priors are quite difficult to handle since they are of the form 
n 
7r(aIYo, >.) <X eO/YO II (1 + eatxi)-'X. 
i=l 
They must be simulated according to techniques presented in Chapter 9 
(see Mengersen and Tweedie, 1993, and Robert, 1993a). 
6. 
3.3. Criticisms and Extensions 
As noticed above, the automated aspect of conjugate distributions is si-
multaneously an advantage and a nuisance. In addition to invariance and 
linearity arguments, it has been argued that this is an objective approach, 
where the subjective input is reduced to the choice of the hyperparame-
ters. Barring the fact that "objectivity" is a concept difficult to define, it 
can be countered that any other prior distribution with the same number 
of hyperparameters would seem equally objective. Moreover, the conjugate 
priors are not necessarily the most robust prior distributions (see §3.4) and, 
from this point of view, alternative distributions could be preferred, if the 
imperative is to minimize the influence of the prior input on the inferential 
output. The following example, derived from Diaconis and Ylvisaker (1985), 
shows how the choice of the prior can modify the posterior distribution for 
small sample sizes. 
Example 3.15 When a coin is spun on its edge, instead of being thrown 
in the air, the proportion of heads is rarely close to 1/2, but is rather 1/3 
or 3/4 because of irregularities in the edge which cause the game to favor 
one side or the other. When spinning, n times, a given coin on its edge, 
we observe the number of heads, x I"V 13(n,p). The prior distribution on p 
is then likely to be bimodal; this cannot be modeled through a conjugate 
prior 7rl like 13e(l, 1). A mixture prior distribution 7r2 like 
1 2 [13e(lO, 20) + 13e(20, 10)] 
is indeed more appropriate. It may also be the case that previous experi-
ments with the same coin have already hinted at a bias toward head and 
that they lead to the following alternative, 7r3: 
0.513e(1O, 20) + 0.213e(15, 15) + 0.313e(20, 10). 
Figure 3.2 provides the graphs of the two prior densities above, along 
with the neutral13e(l, 1) prior, the differences between the three prior mod-
elings being quite important. If, for n = 10, we observe x = 3, the corre-
sponding posterior distributions are 

3.3. Criticisms and Extensions 107 
(i) Be(l + x, 1 + n - x), i.e., Be(4, 8); 
(ii) 0.84 Be(13, 27) + 0.16 Be(23, 17); and 
(iii) 0.77 Be(13, 27) + 0.16 Be(18, 22) + 0.07 Be(23, 17). 
In (ii), the posterior probability weights are obtained as being proportional 
to 
and, for (iii), 
1 B(13, 27) 
2 B(lO, 20) 
and 
1 B(23, 17) 
2 B(20, 10) 
o 5B (13, 27) 
. B(lO, 20)' 
B(18,22) 
0.2 B(15, 15) , 
and 
B(23, 17) 
0.3 B(20, 10) , 
where 
B( b) = r(a)r(b) 
a, 
r(a+b) 
is the normalizing term in the beta density. 
3.00 
2.50 
2.00 
1.50 
1.00 +----+----+---f--~r+_---
0.50 
0.00 ..L....""""f-+---I--+--+--+-+---+-~--I P 
1.00 
0.00 
0.20 
0.40 
0.60 
0.80 
FIGURE 3.2. Three prior distributions for a spinning coin experiment. (Source: 
Diaconis and Ylvisaker, 1985.) 
Therefore, for this sample, the three posterior means, 1/3, 0.365, and 
0.362, are already quite close but the shapes of the posterior distributions 
still differ (see Figure 3.3(a)). Consider now a sample of size n = 50 with 
x = 36. The posterior distributions are 
(i) Be(15,37); 
(ii) 0.997 Be(24, 56) + 0.003 Be(34, 46); and 
(iii) 0.95 Be(24, 56) + 0.047 Be(29, 51) + 0.003 Be(34, 46). 

108 3. From Prior Information to Prior Distributions 
4.50 
8.00 
4.00 
7.00 
3.50 
6.00 
3.00 
5.00 
2.50 
4.00 
2.00 
3.00 
1.50 
1.00 
2.00 
0.50 
1.00 
0.00 
0.00 
0.00 
0.20 
0040 
0.60 
0.80 
1.00 
0.00 
0.20 
0040 
0.60 
0.80 
1.00 
FIGURE3.3(a). Posterior distribu-
tions for the spinning model for 10 
observations. 
FIGURE3.3(b). Posterior distribu-
tions for 50 observations. (Source: Di-
aconis and Ylvisaker, 1985.) 
They are then much closer than for n = 10, as shown by Figure 3.3(b). l:::, 
Two general remarks logically stem from this example. First, it shows 
that prior modeling is indeed important for small sample sizes, but that 
it becomes of minor importance as the sample size gets larger. When the 
sample size goes to infinity, most priors will lead to the same inference and 
this inference will be equivalent to the one based only on the likelihood 
function (see also Lehmann, 1983, Chap. 5). Moreover, this example also 
shows that mixtures of conjugate priors are as easy to manipulate as regular 
conjugate distributions, while leading to a greater freedom in the modeling 
of the prior information. In fact, mixtures of natural conjugate distributions 
also make conjugate families. 
Lemma 3.5 Let F be the natural conjugate family of an exponential 
family (3.6). Then the set of mixtures of N conjugate distributions, 
FN ~ {t, wi~(OIAi' ~i); t,Wi ~ 1, Wi > o}, 
is also a conjugate family. Moreover, i/7r(O) = L~l W(lr(OI).i, J.ti), 
the posterior distribution is a mixture 7r(Olx) = L!l w~(X)7r(OIAi+ 
1, J.ti + x), with 
'( ) _ 
WiK(J.ti,).i)/K(J.ti +X,).i + 1) 
Wi X 
-
N 
• 
Lj=l wjK(J.tj, ).j)/ K(J.tj + x,).j + 1) 

3.3. Criticisms and Extensions 109 
Mixtures can then be used as a basis to approximate any prior 
distribution.3 
Theorem 3.6 If 8 is the natural parameter space for the exponen-
tial family f(xle) and Jr is a prior distribution on 8, then, for any 
E > 0, there exist N and if E :iN such that d(Jr, if) < E, where d is 
the Prohorov distance. 
The Prohorov distance between two measures Jr and if is defined as the 
infimum of the E'S such that Jr(A) ::; if(AE) + E for every Borel set A. The 
set AE denotes the set of points at distance at most E of A (see Le Cam, 
1986). The proof of this theorem can be related to the fact that finite mix-
tures of Dirac measures constitute a dense set for the Prohorov topology 
and that Dirac masses can be approximated by mixtures of conjugate pri-
ors. (For more details, see Diaconis and Ylvisaker (1985), or Brown (1986, 
pp. 254-267).) This result justifies the use of conjugate priors much more 
strongly than the invariance, linearity, or simplicity arguments presented in 
the previous section. Whichever prior information is available, it could be 
modeled through a mixture from:iN with N as small as possible. However, 
this approximation result is also incomplete, since it does not indicate how 
the approximation is transferred to posterior quantities, while Bayesian in-
ference only considers these posterior quantities. Berger (1985b) illustrates 
this difference through the following example: 
Example 3.16 Consider x rv N(e,l) when the associated prior Jra is a 
Cauchy distribution, C(O, 1). The natural conjugate priors being N(f.1, A), 
Jra can be approximated by 
N 
7T = L AiJri, 
i=l 
where Jri is N(f.1i, Ai), according to Theorem 3.6. Actually, when x goes to 
+00, Jra(elx) goes to N(x, 1) while 7T(elx) is roughly N(f.1(x) , p), with 
p = 
A*A' f.1(x) = px + (1- p)f.1*, A* = max{Ad, 
f.1* = max f.1i· 
1 + * 
2 
Ai=A* 
Therefore, Jra(elx) and 7T(elx) will significantly differ for large values of x. 
One could argue that such values are not compatible with the prior infor-
mation anyway and should lead to a modification of the prior modeling. But 
these differences still show that the prior approximation is not uniformly 
valid a posteriori. 
/':,. 
Example 3.16 illustrates rather forcibly the following point: Distribu-
tions with heavy tails will not be properly approximated by lighter tail 
3 One could draw a parallel with the use of mixtures in nonparametric density 
estimation, since kernel methods are approximating the sample density by a 
mixture of normal densities (see West, 1992). 

110 3. From Prior Information to Prior Distributions 
distributions. This difficulty, and more generally, the problem of approxi-
mating the posterior distributions somehow disappear in the generalization 
of Dalal and Hall (1983) since they consider continuous mixtures (in the 
continuous case). We briefly describe their approach below. Consider 
f(xIO) = exp{x· r(O) - -y(0)}, 
with IE[x] = O. (This parametrization is called mean parametrization, see 
Brown, 1986, Chap. 3.) A sequence of natural conjugate distributions is 
given by 
hm(Ols) = exp{s· r(O) - m-y(O)}em(s), 
(3.10) 
where cm(s) is the normalizing factor. Note again that the prior distri-
bution (3.10) corresponds to m previous fictious (or virtual) observations 
XI, ... , xm from f(xIO), with s = 2::'1 Xi. Moreover, (3.10) is also the den-
sity of s for a measure, dVm, called natural measure. If Sm is the space in 
which s varies, and dQm is a probability measure on Sm, 
(3.11) 
constitutes a (continuous) mixture of conjugate priors. For a prior distri-
bution 7r on e, defining 
we get an approximation of 7r, as: 
Theorem 3.7 If 
(i) Vm is absolutely continuous with respect to the Lebesgue 
measure; 
or if 
(ii) Vm is absolutely continuous with respect to the counting 
measure on Sm; 
with density f m (s), and if f m (s) uniformly converges to 1 on Sm 
when m goes to +00, then 
pointwise and in L1. 

3.3. Criticisms and Extensions 111 
TABLE 3.3. Approximation of prior distributions by mixtures of conjugate priors. 
(Source: Dalal and Hall, 1983.) 
Distribution 
7'( 6), 'Y( 6) 
cm(s) 
hm (6Is) prior 
f(x,6) 
distribution 
Normal 
6, 62/2 
vrn'P (s/vrn) 
6~N(;;;,~) 
N(x 16) 
Ga 
Q(~,6) 
-~, -f3log (~) 
smf3- 1 
1 
f3r(mf3 - 1) 
"9 ~ Q(sf3, mf3 - 1) 
Poisson 
P(6) 
log 6, 6 
m 8+! /r(s + 1) 
6 ~ Q(m, s + 1) 
Bernoulli 
B(1,6) 
6 
1 
(m+ 1)! 
Negative 
log-- log--
s!(m - s)! 
6 ~ Be(s + 1, m - s + 1) 
1-6' 
1-6 
binomial 
Neg (r, r:6) 
6 
r 
rmr(mr + s - 1)! _r_ ~ Be(mr _ 1, s + 1) 
log --, log(r + 6) 
rs!(mr - 2)! 
r+6 
r+6 
Moreover, 
Theorem 3.8 If Pm, marginal distribution of x under hm' is finite 
and if rr(O) and rr(Olx) are proper, vm(Olx) converges to rr(Olx), 
pointwise and for the total variation norm. 
The total variation norm is defined as 
Ilrr - 7i'IITV = sup Irr(A) - 7i'(A)I· 
A 
The approximative posterior distribution is, for n observations and t 
L~lXi' 
ISm hm+n(Ols + t) Cm::~:~t) rr(slm) dVm(s) 
vm(Oln, t) = 
( ') 
ISm Cm::(:/+t) rr(s' 1m) dvm(s') 
and Table 3.3 provides the values of T, 'Y and Cm for some usual distribu-
tions. 
Compared with the results of Diaconis and Ylvisaker (1985), Theorems 
3.7 and 3.8 are indeed more general and ensure, in addition, convergence of 
the 'posterior distributions. The drawback, however, is that this approach 
does not keep the advantage of conjugate priors, namely their simplicity. 
Simulation methods such as those presented in Chapter 9 are then necessary 
to derive these Bayes estimators. 

112 3. From Prior Information to Prior Distributions 
3.4. Noninformative Prior Distributions 
The previous section has shown that conjugate priors were useful as approx-
imations of the true prior distributions. However, when no prior information 
is available, their sole justification is analytical, as they can lead to closed 
form expressions for some posterior quantities. In such settings, it is impos-
sible to justify the choice of prior distributions on a subjective basis and the 
hyperparameters of the conjugate prior cannot be determined. Instead of 
turning back to classical alternatives, like maximum likelihood estimation, 
it may still be preferable to use Bayesian techniques, if only because they 
underlie classical optimality criteria (see Chapters 2, 6, and 7). Then, these 
particular prior distributions must be derived from the sample distribution, 
since this is the only available "information." For obvious reasons, they are 
called noninformative priors. 
Historically, Laplace was the first to use noninformative techniques, 
since, while he had no information about the number of white balls in the 
urn or the proportion of male births (Examples 1.6 and 1.7), he put a prior 
distribution on these parameters which took into account his ignorance 
and gave the same likelihood to each value of the parameter, i.e., used an 
uniform prior. His reasoning was based on the equiprobability of elementary 
events and therefore appeared to be sound enough. 
Two criticisms were addressed soon after about this choice. First, the 
resulting distributions are improper when the parameter space is not com-
pact and some statisticians object to the use of improper priors, arguing 
that they lead to difficulties like the marginalization paradoxes (see Exer-
cises 3.47-3.53). Such misgivings are not really justified since it is actually 
possible to work with improper priors, as seen in §1.5, as long as we do not 
try to interpret them as probability distributions (see also Stone, 1976). 
As mentioned in §3.1, it may be argued that, on the contrary, a subjective 
determination of the prior distribution should lead to an improper prior. 
The second criticism is more fundamental, as it deals with the problem 
of invariance under reparametrization. If we switch from () E e to TJ = g( (}) 
by a one-to-one transformation g, prior information is still totally missing 
and should not be modified. However, if 7r((}) = 1, the corresponding prior 
distribution on TJ is 7r*(TJ) = I d~g-l(TJ)1 by the Jacobian formula. Therefore, 
7r(TJ) is usually not constant. 
Example 3.17 If p, male births proportion, has a uniform prior distribution 
on [0,1]' the odds ratio parameter p = 
l~p has a prior distribution with 
density 1/(1 + p)2 which is therefore not constant. 
6. 
Of course, it can sometimes be argued that there exists a natural pa-
rameter of interest, therefore that the choice of a uniform prior on the 
parameter of interest does not need to be invariant under reparametriza-
tion. But this argument does not hold if more than one inference about () is 

3.4. Noninformative Prior Distributions 113 
necessary; for instance, we may need to derive the first two posterior mo-
ments of (), but the latter is also the expectation of ()2. Or, in Example 3.17, 
both the probability () and the odds ratio p may be of interest. Therefore, it 
seems that a more intrinsic and more acceptable notion of noninformative 
priors should satisfy invariance under reparametrization. A first solution is 
to take advantage of the invariance characteristics of the problem, i.e., to 
use the groups 9 acting on X which induce groups 9* acting on e (i.e., 
the distribution of x is closed under the action of 9). Chapter 7 details the 
links between invariance structures and the Bayesian approach, as these 
structures allow for derivation of a noninformative prior which is compat-
ible with the invariance requirement, namely, the right Haar measure on 
9*. Two introductory examples are presented below. 
Example 3.18 The family f(x - ()) is translation invariant, i.e., y = x - xo 
has a distribution in the same family for every xo, f(y - (() - xo)); () is then 
said to be a location parameter and an invariance requirement is that the 
prior distribution should be translation invariant, i.e., satisfy 
n( ()) = n( () - ()o) 
for every ()o. The solution is n(()) = c, the uniform "distribution" on e. L:, 
Example 3.19 If the distribution family is parametrized by a scale pa-
rameter, i.e., is of the form l/af(x/a) (a > 0), it is scale-invariant, i.e., 
y = x/a rv f(y). A scale invariant prior n satisfies n(A) = n(A/c) for every 
measurable set A in (0, +(0) and c > 0, i.e. 
1 
a 
n(a) = -n( -). 
c 
c 
This implies n(a) = a/a, where a is a constant. Therefore, the invariant 
measure is not constant anymore. 
L:, 
This approach is only partially satisfactory, because it implies the ref-
erence to an invariance structure, which may be chosen in several ways, may 
not exist (see Chapter 7) or may be of no interest to the decision maker. 
Jeffreys (1961) proposes a more intrinsic approach which indeed avoids the 
need to take the invariance structure into account, even though it is of-
ten compatible with it. The Jeffreys noninformative prior distributions are 
based on Fisher information, given by 
I(()) = IEo (8l0g~~X I ())) 2 
in the one-dimensional case. Under some regularity assumptions, this quan-
tity can also be written as 
-IE (82l0gf(X I ())) 
o 
8()2 
. 
(3.12) 

114 3. From Prior Information to Prior Distributions 
The corresponding prior distribution is 
modulo a normalization coefficient when 11"* is proper. It actually satisfies 
the invariant reparametrization requirement, since we have the transforma-
tion 
1(0) = I(h(O))(h'(O))2 
(which explains the exponent 1/2). Moreover, it also provides the invariant 
distributions obtained in Examples 3.18 and 3.19. More fundamentally, the 
choice of a prior depending on Fisher information is justified by the fact that 
1(0) is widely accepted as an indicator ofthe amount of information brought 
by the model (or the observation) about 0 (see Fisher (1956) or Lehmann 
(1983, 1986)). Therefore, it seems intuitively justified that the values of 0 
for which 1(0) is larger should be more likely for the prior distribution. 
In other words, 1(0) can evaluate the ability of the model to discriminate 
between 0 and 0 + dO through the slope of log f(xIO). To favor the values 
of 0 for which 1(0) is large is equivalent to minimizing the influence of the 
prior distribution and is therefore as noninformative as possible. In fact, 
the Jeffreys prior is usually improper but the developments of §1.5 show 
how to enhance a Bayesian analysis in this case. 
Example 3.17 (Cont.) If x rv B(n,p), 
f(xlp) = (:)PX(I_ pt-x , 
fJ2log f(xlp) 
x 
n - x 
-----=:~'----'=-..:... = - + -,-,-----,-;:-
fJp2 
p2 
(1 _ p)2' 
and 
[1 1] 
n 
I(p)=n :P+l-p =p(l-p)" 
Therefore, the Jeffreys prior for this model is 
1I"*(p) ex: [P(I- p)t1/ 2 
and is thus proper, since it is a Be(I/2, 1/2) distribution. 
When 0 is a multidimensional parameter, the Fisher information ma-
trix is defined as a generalization of (3.12). For 0 E IRk, 1(0) has the 
following elements, 
(i,j = 1, ... ,k), 
and the Jeffreys noninformative prior is then defined by 
11"*(0) ex: [det(I(O))]1/2. 

3.4. Noninformative Prior Distributions 115 
It is still reparametrization-invariant. Note that, if f(xI8) belongs to an 
exponential family, 
f(xI8) = h(x) exp(8· x -1j;(8)), 
the Fisher information matrix is given by 1(8) = \7\7t1j;(8) and 
( 
k 
) 1/2 
n*(8) ex g 
1j;~~(8) 
, 
(3.13) 
where 1j;~~(8) = ~1j;(8). 
In the multidimensional case, the Jeffreys noninformative approach 
may lead to incoherences or even paradoxes (see Examples 3.21 and 3.24) 
and we must stress that Jeffreys was mainly emphasizing the use of these 
distributions in the one-dimensional case (see Berger and Bernardo, 1992). 
However, his method provides one of the best 'automated' techniques to 
derive noninformative prior distributions. Moreover, it is often related to 
some classical estimators. 
Example 3.20 Consider x '" N(8, Ip). Since this is a location family, the 
Jeffreys prior is constant. The corresponding generalized Bayes estimator 
is given by 
811'* (x) = fIRP8exp(-llx-8112/2)d8 =x 
fIRpexp(-llx-8112/2)d8 
. 
It is minimax for every p and admissible for p ::::: 2. Note that this estimator 
is, in addition, the best invariant estimator for location parameters (see 
Chapter 7). 
6. 
Example 3.21 Consider x '" N(/1, ( 2) with 8 = (/1, a) unknown. In this 
case, 
( 
1/a2 
1(8) = lEe 
2(x _ /1)/a3 
= (1/;2 
2/~2) 
and the corresponding noninformative prior distribution is n(8) ex 1/a2• If, 
however, /-L and a are assumed to be a priori independent, the corresponding 
noninformative prior would be n(/-L, a) = a-I, which is also the invariant 
Haar measure for this location-scale model (see Example 3.19 and Chapter 
~. 
6. 
This approach is criticized by some Bayesians, as being merely a tool 
without subjective justifications in terms of prior information. However, 
the only alternative to an automated approach is to require that prior in-
formation is always available, a requirement which cannot hold in every 
setting. Another criticism of the Jeffreys method is that, although it meets 

116 3. From Prior Information to Prior Distributions 
the repammetrization-invariance requirement, it does not satisfy the Like-
lihood Principle. In fact, the Fisher information can differ for two exper-
iments which provide proportional likelihoods, as shown by the following 
example: 
Example 3.22 We saw in Example 1.11 that binomial and negative bino-
mial modelings could lead to the same likelihood. However, if x rv B(n, B), 
the noninformative prior 71"1 (B) is Be(I/2,1/2) (Example 3.17) and, if 
n rv N"eg(x, B), the Jeffreys prior is 
7I"2(B) = -1Eli [::2 10gf(xIB)] 
[ X 
n-x] 
x 
= 1Eli B2 + (1 - B)2 = B2(1 - B)' 
i.e., 7I"2(B) ex: B-1(1 - B)-1/2, which is improper and, more importantly, 
differs from 71"1. 
6 
This chapter does not consider the practical problems related to the 
use of noninformative priors. In fact, this difficulty is considered in general 
in Chapter 9. Moreover, it often occurs that a noninformative distribution 
is a limit of conjugate priors. 
Example 3.23 If x rv U([O, BD, a conjugate prior is the Pareto distribution, 
Pa(Bo,a), 
71"( B) = aBo B-a- 11[lio,+oo[( B), 
leading to the posterior distribution Pa(max(Oo, x), a + 1). Under the in-
variant loss 
L(B 8) = (0 - 8)2 
, 
B2' 
the Bayes estimator is, if Bo V x = max( 00 , x), 
converging to the minimax estimator, 80(x) = (3/2)x, when a and Bo go 
to O. Since B is a scale parameter, the noninformative distribution can be 
taken to be 7I"(B) = I/B, which is also the Jeffreys prior for this model. 
This distribution corresponds to Bo = 0 and a = 0 for an "unnormalized" 
Pareto distribution (i.e., without the scaling factor aBo). This representa-
tion can also be used to show that 80 is admissible, using Stein's sufficient 
admissibility condition (see Chapter 6). 
6 
A more important drawback of noninformative prior distributions is 
that they do not necessarily perform satisfactorily for all inferential pur-
poses, in particular when considering subvectors of interest. The following 
problem was pointed out by Stein (1959) (see also Tibshirani, 1989): 

3.4. Noninformative Prior Distributions 117 
Example 3.24 If x'" N(B, Ip), the noninformative prior is K(B) = 1. The re-
sulting estimator of B, x, is quite acceptable, as seen in Example 3.20. Now, 
as Blx '" Np(x,Ip), the posterior distribution of TJ = IIBI12 is x;(llxI12), the 
noncentral chi-squared distribution. When TJ is the parameter of interest, 
the posterior mean of TJ is 87r(x) = IE7r[TJlx] = IIxl12 + p. However, the best 
estimator among the estimators of the form IIxl12 + c (for quadratic loss) is 
IIxl12 - p, which uniformly dominates the generalized Bayes estimator, 87r 
(see Exercise 2.35). Therefore, the marginal distribution on TJ deduced from 
the Jeffreys noninformative prior on B is definitely suboptimal. Moreover, 
the Jeffreys noninformative distribution derived from the reduced observa-
tion z = IIxl12 is quite different from x;(llxI12) and leads to an estimator of 
TJ with much more acceptable performance (see Exercise 3.42). 
6. 
This type of problem was taken into account by Bernardo (1979) who 
proposes a modification of the Jeffreys approach called the reference prior 
approach. A major difference is that this method distinguishes between 
parameters of interest and nuisance parameters (for instance, IIBI12 and 
B fIIBII). Therefore, the resulting prior distribution depends not only on 
the sample distribution, but also on the inferential problem at hand. The 
remainder of this section briefly presents the derivation of reference priors. 
For a detailed study, see Berger and Bernardo (1989, 1990, 1992). Ghosh 
and Mukerjee (1992) also give some motivations for the reference prior in 
terms of asymptotic optimality. 
Consider x '" f(xIB), with BEe c IRk. Assume that the Fisher in-
formation matrix I(B) exists and is of full rank. We denote S = I- 1(B). 
Parameters are separated into m groups which correspond to their respec-
tive levels of importance, 
(3.14) 
with Ni = 2:;=1 nj (and a possible reindexing of the components of B). 
The reference prior method derives a prior distribution on (B(l), ... , B(m») 
which takes into account this division, i.e., which truly separates between 
nuisance parameters and parameters of interest, even allowing a finer level of 
separation between the respective levels of importance of these parameters. 
We define the following notation: for j = 1, ... , m, 
and 
The matrix S is decomposed according to the partition (3.14), 
and Sj is the upper left (Nj , Nj ) corner of S. (For instance, Sl = Au.) 
We denote H j = Sjl and h j is the lower right (nj,nj) corner of H j . (In 

118 3. From Prior Information to Prior Distributions 
particular, hl = Ail.) The reference prior construction then proceeds as 
follows: 
Initialization: 
Iteration: 
For j = m - 1, ... , 1, 
where 
IEj[g(O)IO[jJl = J 
g(0)7I"j+1(0[~jJI0[jJ)dOHJ' 
Conclusion: 
The reference prior is 71"(0) = 7I"l(O[~oJIO[oJ)' 
Often, some of the integrals appearing in this algorithm are not defined. 
Berger and Bernardo (1989) then propose to derive the reference prior for 
compact subsets en of e and to consider the limit of the corresponding 
reference priors 71" n as n goes to infinity and en goes to e. In general, the 
resulting limit does not depend on the choice of the sequence of compact 
sets. This algorithm is justified as providing the prior distribution which 
maximizes the posterior information (see Bernardo, 1979, and Berger and 
Bernardo, 1992). 
Example 3.24 (Cont.) Since TJ = IleW is the parameter of interest, e can 
be written in polar coordinates (ry, 'Pl,···, 'Pp-d, with 
01 = y'ij cos( 'Pd, 
O2 = y'ijsin('Pd COS('P2), 
Op-l = y'ij sin( 'PI) ... cos( 'Pp-l), 
Op = y'ij sine 'PI) ... sine 'Pp-l). 
The Fisher information matrix for (ry, 'PI, ... ,'Pp-l) is then H = JJt, where 
J is the Jacobian matrix D(((h, ... ,8p ) 
). It can be shown that J is of the 
"/''Pl,···,'Pp-l 
form 
J= [Atjy'ij] 
J17B ' 
with A E lRP and B (p - 1) x p matrix. Thus, for the partition of 0 in 
0(1) = ry, 0(2) = ('PI, ... ,'Pp-l), we get 
71"2 ('PI , ... , 'Pp-llry) ex: IH2211/2, 
which does not depend on ry. The marginal distribution of ry is 

3.4. Noninformative Prior Distributions 119 
and I~~~I ex: (1/1]). Therefore, 
which leads to an estimator of IIel1 2 more interesting than IlxW+p (see Ex-
ercise 3.42). Actually, the same marginalization problem appears for maxi-
mum likelihood estimation. In fact, the maximum likelihood estimator of 1] 
based on the sample is Ilx11 2 , which is also dominated by IIxl1 2 - p. On the 
contrary, the maximum likelihood estimator derived from 
behaves similarly to (1IxI1 2-p)+ (see Saxena and Alam (1982), Chow (1987), 
Chow and Hwang (1990), and Bock and Robert (1991)). 
I':::" 
Reference prior distributions also depend on the way parameters are 
ordered (see also Exercise 3.46), which is an advantage, compared with the 
Jeffreys method, since nuisance parameters are considered in a different way. 
Paradoxes like those of Example 3.24 are then avoided. It may seem unrea-
sonable to modify the prior distributions according to the problem of inter-
est but one has to realize that, apart from the sample distribution f(xle), 
these inferential problems are the unique available information.4 Note that 
invariance under reparametrization is preserved only if the changes are bi-
jective and within each of the groups in (3.14). However, the invariance 
requirement is of less importance in this setting since the ordering (3.14) 
somehow prohibits a reparametrization between the classes, as the different 
groups are not of the same type. In the case when no such ordering can 
be proposed, Berger and Bernardo (1990) suggest that one considers as a 
noninformative prior the reference prior for which each component of e is 
considered separately. (On the contrary, the Jeffreys noninformative prior 
considers e as a single group.) 
Example 3.25 (Berger and Bernardo, 1990) Consider an analysis of variance 
model 
Xij=/-L+ai+Eij, i=l, ... ,p, j=l, ... ,n, 
with ai '" N(O, 7 2 ), Eij '" N(O, 0'2). For different orderings of the parame-
ters, /-L, 7 2 , 0'2, we get the following reference priors: 
4 If a loss function L is available, it also contains some information about () and 
one could use the duality between loss and prior distribution to derive a prior 
distribution adapted to this loss. (See Chapter 2 and Rubin, 1987.) But very 
little has been done about this derivation of a prior distribution from a loss 
function. 

120 3. From Prior Information to Prior Distributions 
7fl ((IL, 0-2,72 )) ex: 0--2( m
2 + 0-2 )-3/2; 
7f2(1L, 0-2,72 ) ex: 7-Cn 0-2 [(n - 1) + (1 + n72 /0-2 )-2] 1/2 ; 
7f3(1L, (0-2,72 )) ex: 0--2(n72 + 0-2)-\ 
7f4((1L, 0-2 ), 72) ex: 0--5/2(n72 + 0-2)-\ 
Alternative approaches to noninformative Bayesian analysis are de-
scribed in Berger (1985a, Chap. 3). For instance, we can mention Rissa-
nen (1983, 1990), who uses transmission information theory as in Shannon 
(1948). Considering the transmission of a binary message by a physical 
device, the noninformative prior distribution for a model f(xIO) is the min-
imum length of message necessary to describe this model. In the simplest 
case, these distributions are similar to the Jeffreys priors and this similar-
ity should also hold in general because of the connections existing between 
statistical information and information theory. A recent survey of this the-
ory of stochastic complexity is given in Dawid (1992). See also Kass and 
Wasserman (1993) for a general survey of noninformative approaches. 
3.5. Posterior Validation and Robustness 
Even in cases where prior information is available, it rarely occurs that 
this information leads to an exact determination of the prior distribution, 
7f((}) , if only because the discriminating power of individuals is restricted 
and practical determination of the tails of a distribution is almost impos-
sible. In most cases, there is therefore an uncertainty about the selected 
prior distribution used for Bayesian inference. Obviously, if the information 
is precise, the prior will be better defined than in a noninformative setup. 
However, it always matters that the influence of this indeterminacy in the 
prior distribution on posterior quantities is clearly assessed and that the ar-
bitrary part of the prior distribution does not get predominant. The assess-
ment of the influence of the prior is called sensitivity analysis (or robustness 
analysis). The concern about robustness and the derivation of appropriate 
tools to deal with this problem appear in the works of Good (1983) and 
Berger (1982b, 1984a, 1985a, 1990a). Other references on this problem are 
Berger and Berliner (1986), Berger and Sellke (1987), Berger and Delam-
pady (1987), O'Hagan and Berger (1988), Sivaganesan and Berger (1989), 
Walley (1991), and Wasserman (1992). 
Following Berger's (1990a) classification, we consider that uncertainty 
about the prior distribution 7f can be represented by the assumption that 
the (unknown) prior belongs to a class of distributions, F. These classes 
can be determined from a subjective or practical perspective. The major 
types of robustness classes considered in the literature are given below. 

3.5. Posterior Validation and Robustness 121 
(i) 
Conjugate prior classes. Such classes are typically chosen for practical 
reasons, since they generally provide explicit bounds on the quantity 
of interest. For instance, Das Gupta and Studden (1988) consider the 
case when x '" Np((),Ip) and () '" Np(O, E), where 1.71 ::S 1.7 ::S 1.72, the 
order relation ::S being that the difference of the two matrices is posi-
tive semidefinite. The above criticisms on conjugate prior distributions 
obviously apply in this case and even more strongly, since the resulting 
class is only made of convenient distributions, but does not lead to a 
wide set of prior distributions compatible with the prior information. 
(ii) Determined moments classes. If we assume that the (limited) prior 
information is only providing bounds on some moments of 7r, the cor-
responding class is 
rM = {7r; ai::::; JE'7r[()i]::::; bi,i = 1, ... ,k}. 
However, rM is not really more satisfactory than the previous classes in 
(i), as it imposes strong conditions on the tails of the prior and contains 
unrealistic prior distributions (including finite support distributions). 
Actually, in most cases, the bounds on the posterior quantities will be 
attained for finite support distributions, due to convexity reasons. 
(iii) Neighborhood classes. Following its introduction by Huber (1972) for 
outliers detection, a rather popular class in robustness studies is the 
E-contamination class around a given prior distribution 7ro, 
re,Q = {7r = (1- E)7rO + Eq; q E Q}, 
where Q is a class of distributions, to be chosen according to the pre-
cision of the prior information. Berger and Berliner (1986) and Siva-
ganesan and Berger (1989) provide examples where such classes can 
be used. The main drawback in using re•Q is that E and Q need to be 
determined and it is usually difficult to derive them from the degree of 
uncertainty about 7ro. But mixture estimation techniques may be in-
strumental in this setting when the prior information is derived from a 
sample of (possibly virtual) previous observations (see §9.4). A related 
relation would be to consider a "true" neighborhood associated with a 
given functional distance like Hellinger or Kullback~Leibler distances 
(see §2.5.4). The difficulty is then in the scaling ofthese neighborhoods. 
(iv) Underspecified classes. Such classes result from a construction of the 
prior on a sub-O"-algebra, i.e., on a coarser set of events than the one 
of interest. This approach is strongly related to the axiomatic devel-
opments of §3.1, since the ordering on the relative likelihoods does 
not necessarily lead to a prior distribution on the Borel O"-field. For 
instance, it may be the case that the prior distributions have some 
determined quantiles, 
rQ ={7r; £i::::; r 7r(())dB::::;ui,i=l, ... ,m} 
JIi 

122 3. From Prior Information to Prior Distributions 
where It, ... ,Im is a partition of 8. These classes are therefore prefer-
able to (ii), but it may still be necessary to eliminate unrealistic prior 
distributions from rQ as in O'Hagan and Berger (1988). However, it 
seems that this approach is the most realistic, as, for instance, fractiles 
are usually easier to determine than moments, and the most apt to give 
rise to practical implementation among the classes we consider here. 
(v) Ratio of densities classes. Considering as for (iv) a subjective deriva-
tion of the prior distribution, this may also be done by a histogram 
representation. In such a case, the uncertainty about the prior infor-
mation can be represented by upper and lower bounds on the density 
7r and leads to the class 
rR = {7r; L(O) :::; 7r(O) :::; U(O)}, 
where Land U are specified. The choice of these functions is difficult 
but is quite influential, as, if they are similar, all the distributions in rR 
will have the same behavior in the tails. See DeRobertis and Hartigan 
(1981) for a related class. 
Berger (1990a) and Wasserman (1992) also provide computational 
tools to derive bounds on posterior quantities for the above classes. In 
fact, the robustness point of view substitutes for the current estimator Q( 7r) 
the range of possible values of the estimator when the prior 7r varies in the 
class r, 
Goutis (1990) (see Example 3.6) illustrates this approach for class (ii). 
Chapter 5 presents such a study in order to derive conservative bounds on 
posterior probabilities of a null hypothesis. 
A more conservative approach to robustness requirements is to look 
for robust prior distributions, i.e., for parametrized distributions which are 
as insensitive as possible to small variations in the prior information. For 
instance, it can be shown that Student's t-distributions are preferable to 
normal priors in the normal case, although the latter distributions are conju-
gate and also are maximum entropy priors in some cases (see Zellner (1971), 
Angers (1987), and Angers and MacGibbon (1990)). Similarly, poly-t dis-
tributions, derived from the product of several Student's t densities, are 
used in the econometric analysis of simultaneous equations for the same 
reason (see Dreze and Morales (1976), Richard and Tompa (1980), and 
Bauwens (1984)). In general, as opposed to conjugate distributions, these 
robust priors will have heavy tails. 
Another approach robustifies the conjugate distributions by hierarchi-
cal modeling. The hierarchical Bayes approach is presented in Chapter 8 but 
it seems quite intuitive that an additional level in the prior modeling should 
increase the robustness of the prior distribution. Consider a conjugate prior 

3.5. Posterior Validation and Robustness 123 
for f(xIO), 1Tl(OI>'). As mentioned above, classes like (i) are not veryeffi-
cient in terms of robustness and, moreover, they require the specification of 
bounds on the hyperparameters >.. Since these hyperparameters are (par-
tially or totally) unknown, a natural extension (in a Bayesian framework) 
is to introduce a noninformative prior on >., 1T2 (or a hyperprior compat-
ible with the available information). This modeling induces the following 
hierarchical structure: 
>. rv 1T2(>'), 
01>' rv 1Tl(OI>'), 
xlO rv f(xIO). 
The prior distribution on 0 is then the marginal distribution derived from 
1Tl(OI>')1T2(>'), i.e., by integrating>. out, 
(3.15) 
This prior distribution is not conjugate in general, but the main purpose of 
the hierarchical extension was actually to avoid the restrictive framework 
of conjugate priors. By integrating out the hyperparameters >., we derive a 
distribution (3.15) which usually enjoys heavier tails than conjugate priors. 
For instance, the Student's t-distribution can be written as (3.15) with 
1T2 an inverse gamma distribution (see Example 3.12). Hierarchical setups 
are also quite interesting from a computational point of view, as shown in 
Chapter 9. 
Other perspectives incorporate the loss function in the robustness 
study, in order to select an estimator which is conservative with respect 
to all possible priors 1T E r. For instance, 8* can be the solution of 
inf sup r(1T,8) 
6 
7I:Er 
or 
inf sup [r(1T, 8) - r(-rr, 871:)], 
6 
7I:Er 
the first quantity being the r -minimax risk and the second criterion the 
r-minimax regret, as developed in Robbins (1951) and Good (1952). See 
Berger and Berliner (1986), Berger (1985a), and Kempthorne (1988) for 
additional references. 
The literature on Bayesian robustness has considerably increased in 
the last few years and we refer the reader to the papers mentioned above 
for additional references. To conclude this chapter, let us point out that the 
choice of the prior distribution determines the resulting Bayesian inference, 
that this choice may sometimes be trivial and sometimes quite delicate, 
but that it should be justified in term of the available prior information 
in all cases and, moreover, that a robustness analysis should be conducted 
in order to assess the amount of posterior modification a change in the 
prior distribution induces. Obviously, this assessment will also depend on 
the evaluation measures considered for the quantities of interest, i.e., on 
the losses used in the estimation process. This leads to the possibility of 

124 3. From Prior Information to Prior Distributions 
using the knowledge of the loss function to determine noninformative prior 
distributions, but little work has been done in this direction, even though 
many Bayesians point out that loss and prior are undistinguishable (see, 
e.g., Lindley (1985) and Exercise 3.56.) 
Exercises 
Section 3.1 
3.1 Determine the prior distributions in Example 3.5, when the first and third 
quartiles are 2 and -2 and the median is 0. 
3.2 Show that, if the constraints (3.1) are all associated with functions gk of the 
form gk(B) = I(-oo,akl(B), there is no maximum entropy prior distribution 
for e = IR and 1l'o the Lebesgue measure on IR. 
3.3 Consider B E IR and a prior 1l' such that varll'(B) = 1, 1l'(B < -1) = 0.1, 
and 1l'(B > 1) = 0.1. Derive the maximum entropy prior associated with the 
Lebesgue measure on IR if this is possible. 
3.4 Let 1l'o be a reference measure for the maximum entropy method and 1l'b a 
measure which is absolutely continuous with respect to 1l'o. 
a. Give examples where the maximum entropy priors associated with 1l' and 
1l'o coincide. 
b. Apply this to the case when 1l'o is the Lebesgue measure on IR, 1l'b is the 
N(O, 1) distribution, and the constraints (3.1) are 1E1l'[B] = 0, varll'(B) = 
a2 , depending on the value of a. 
3.5 Consider B E IR+. Determine whether there exists a maximum entropy prior 
under the constraint 1E1l'[B] = fJ- for 1l'o(B) = 1 and 1l'o(B) = I/B. 
3.6 Let x '" P(>.). 
a. Find the maximum entropy prior associated with 1l'o(B) = l/ve and 
1E1l'[B] = 2. 
b. Determine the hyperparameters of the prior distribution 1l' if 1l' is 
(i) eXP(fJ-)i (ii) Q(2, (j). 
c. Derive the three corresponding posterior distributions when x = 3 and 
compare the Bayes estimators of B under the loss L( B, 8) = B( B - 8? 
3.7 Let x '" B(n,B) and B '" Be(a,{3). Determine whether there exist values of 
a,{3 such that 1l'(Blx) is the uniform prior on [0,1], even for a single value 
of x. 
3.8 Let x '" Pa(a, B), a Pareto distribution, and B '" Be(fJ-, v). Show that, if 
a < 1 and x > 1, a particular choice of fJ- and v gives 1l'(Blx) as the uniform 
prior on [0,1]. 
Section 3.2.1 
3.9 If 1l' is a finite mixture of conjugate distributions, give the form of 1l'(Blx). 
In particular, derive the posterior weights. Deduce the results of Example 
3.15. 
3.10 Determine symmetric distributions, Le., distributions such that conjugate 
distributions and sampling distributions belong to the same parametrized 
family. 
3.11 Based on Proposition 3.3, show that the intersection of all conjugate families 
is empty. (Consider disjoint sets for the hyperparameter >..) 

Exercises 125 
3.12 Consider a population divided into k categories (or cells) with probability 
Pi for an individual to belong to the ith cell (1 ::; i ::; n). A sequence (7rk) 
of prior distributions on pk = (PI, ... , Pk), k E IN, is called coherent if any 
grouping of cells into m categories leads to the prior 7rm for the transformed 
probabilities. 
a. Determine coherence conditions on the sequence (7rk). 
b. In the particular case when 7rk is a Dirichlet distribution 'Dk (aI, ... , ak), 
express these conditions in terms of the ak's. 
c. Does the Jeffreys prior induce a coherent sequence? 
d. What about 7rk(pk) ex IIp;l/k, proposed by Perk (1947)7 
Section 3.2.2 
3.13 Show that, if the support of f(xIB) does not depend on B and if there 
exists a parametrized conjugate prior family F = {7r(BIA), A E A} with 
dim(A) < +00, f(xIA) is necessarily an exponential family. (Hint: This is a 
consequence of the Pitman-Koopman lemma.) 
3.14 Give a sufficient statistic associated with a sample Xl, ... ,Xn from a Pareto 
Pa(a, B) distribution. 
3.15 Give a sufficient statistic associated with a sample Xl, ... ,Xn from a trun-
cated normal distribution 
f( Ill) 
-(x-e)2/21 
( ) 
X (7 ex e 
[e-c,e+c] X , 
when c is known. 
3.16* (Brown, 1986) Show that, for every exponential family, there exists a 
reparametrization which gives a natural exponential family. Show also that 
the dimension of a natural reparametrization does not depend on the choice 
of the reparametrization. 
3.17* (Dynkin, 1951) Show that the normal distributions and distributions of 
the form clog(y), when y rv 9(a,;3), are the only ones which can belong 
to an exponential family and a location family. Deduce that the normal 
distribution is the only distribution from an exponential family which is 
also spherically symmetric (see Exercise 1.1). 
3.18* Consider X = (Xij) and E = (O'ij) symmetric positive-definite m x m 
matrices. The Wishart distribution, Wm(a, E), is defined by the density 
",-(=+1) 
(X) _ IXI-2- exp(-tr(E-lX)/2) 
P""E 
-
rm(a)IEI"'/2 
' 
with tr(A) the trace of A and 
rm(a) = 2",m/27rm(m-l)/4 IT r (a - ~ + 1). 
i=l 
a. Show that this distribution belongs to an exponential family. Give its 
natural representation and derive the mean of Wm(a, E). 
b. Show that, if Zl, ... ,Zn rv Nm(O, E), 
n L Zi Z; rv Wm(n, E). 
i=l 

126 3. From Prior Information to Prior Distributions 
3.19* (Pitman, 1936) 
Show the Pitman-Koopman lemma: If, for n ~ no, 
there exists Tn from lRn in lRk such that Tn(X1, ... ,Xn) is sufficient when 
Xl, ... , Xn are i.i.d. f(xIO), the distribution f necessarily belongs to an ex-
ponential family if the support of f does not depend on O. Study the case 
when the support of f depends on O. 
3.20* (Brown, 1986) A natural exponential family f(xIO) = exp(O . X - 'lj;(0)) is 
said to be steep if, for every 00 E NO, 01 EN-No, and Op = pOl +(l-p)Oo, 
it satisfies 
lim aa'lj; (Op) = +00. 
p ..... 1 
P 
a. Show that the family is steep if and only if 
for every 0 E N - NO. 
b. Show that the Inverse Gaussian family, with density 
where Z E lR+ and 01, O2 E lR_, is exponential and steep but not regular. 
c. Show that a minimal steep exponential family can be reparametrized 
by e(O) = IEo[x] = \1'lj;(0) and that this function defines a one-to-one 
transformation from NO to KO. 
d. Show that, for minimal steep exponential families, the maximum likeli-
hood estimator of 0, 8(x), satisfies 
e(8(x)) = x. 
3.21* (Morris, 1982) A restricted natural exponential family on lR is defined by 
Po(X E A) = 1 
exp{Ox - 'lj;(0)} dF(x), 
OEe. 
(3.16) 
a. Show that, if 0 E e, F is necessarily a cumulative distribution function. 
Otherwise, show that the transformation of F into 
dFo(x) = exp{Oox - '¢'(O)} dF(x), 
for an arbitrary 00 E e and the replacement of 0 by 0 - 00, provides this 
case. 
b. Show that, in this restricted sense, Be(mp" m(l- p,)) and the lognormal 
distribution logN(a, 0"2) do not belong to an exponential family. 
c. If p, = 'lj;' (0) is the mean of the distribution (3.16), the variance function 
of the distribution is defined by V(p,) = 'lj;"(0) = varo(x). Show that V 
is indeed a function of p, and, moreover, that if the variation space of 
p" il, is known, the couple (V, il) completely characterizes the family 
(3.16) by 
'lj; (l~ V~:)) = l~ ;t;· 
(Note that 0 = 1.1-' dm/V(m).) Show that V(p,) = p,2 defines two fami-
1-'0 
lies, depending on whether il = lR- or il = lR+. 

Exercises 127 
d. Show that V(JL) = JL(1- JL)/(m + 1) corresponds simultaneously to the 
binomial distribution 8(m, JL) and to 8e(mJL, m(l- JL)). Deduce that the 
characterization by V is only valid for natural exponential families. 
e. Show that exponential families with quadratic variance functions, i.e., 
(3.17) 
include the following distributions: normal, N(JL, (}2), Poisson, P(JL), 
gamma, 9(r, JL/r) , binomial, 8(m, mJL), and negative binomial, Neg(r,p), 
defined in terms of the number of successes before the rth failure, with 
JL = rp/(l - p). 
f. Show that the normal distribution (respectively the Poisson distribution) 
is the unique natural exponential distribution with a constant (respec-
tively, of degree one) variance function. 
g. Assume V2 -I- ° 
in (3.17) and define d = vI -
4VOV2' discriminant of 
(3.17), a = 1 if d = ° 
and a = y(fi);, otherwise. Show that x* = aV'(x) is 
a linear transformation of x which has the following variance function: 
(3.18) 
where JL* = aV'(JL) and s = -sign(dv2). Show that it is sufficient to con-
sider V* to characterize natural exponential families with a quadratic 
variance function, in the sense that other families are obtained by in-
verting the linear transform. 
h. Show that (3.18) corresponds to six possible cases depending on the sign 
of V2 and the value of s (-1,0,1). Eliminate the two impossible cases and 
identify the families given in e. Show that the remaining case is V2 > 0, 
s = 1. For V2 = 1, show that this case corresponds to the distribution of 
x = log{y/(l- Y)}/7r, where 
7r 
101 < 2' 
and 
f(xIO) = exp[Ox + log(cos(O))l. 
2 cosh( 7rx/2) 
(3.19) 
(The reflection formula B(0.5+t, 0.5-t) = 7r / cos(7rt) can be of use.) The 
distributions spanned by the linear transformations of (3.19) are called 
GHS(r, A) (meaning generalized hyperbolic secant), with A = tan(O), r = 
1/v2, and JL = TA. Show that the density of GHS(r, A) can be written 
fr,>.(x) = (1 + A2rr/2 exp{x arctan(A)}fr,o(x) 
(do not try to derive an explicit expression for fr,o). 
Note: Exercise 8.26 exhibits additional properties of the quadratic vari-
ance exponential families in terms of conjugate families and Bayes esti-
mators. Exercise 9.16 shows how orthogonal polynomials can be related 
to each distribution in the quadratic variance exponential families. 
3.22 Compare usual exponential families with the distributions (2.12) obtained 
in Chapter 2 and check whether they give universal estimators. 
3.23 Show that, for every exponential family, the natural space N is convex. 

128 3. From Prior Information to Prior Distributions 
3.24 Show the decomposition of Example 3.12: 
(i) directly; and 
(ii) through a usual representation of Student's t-distribution. 
3.25 An alternative to the logistic regression introduced in Example 3.14 is the 
pro bit model, where 
i = 1, ... ,n, 
and if> is the c.dJ. of the standard normal distribution. 
a. Show that this alternative does not belong to an exponential family, even 
conditionally on the Xi'S. 
b. The observation Yi can be considered as the indicator function .u:z<atx 
where Zi is an unobserved N(O, 1) random variable. Show that, 'if th~ 
Zi'S are known, the Lebesgue measure provides an explicit posterior dis-
tribution. (Note: The interest in this remark appears in Chapter 9, since 
the missing data ZI, ... ,Zn can be simulated.) 
Section 3.2.3 
3.26 A classical linear regression can be written as Y '" N p (X{3, (J"2 Jp ) with X a 
p x q matrix and {3 E JR q. When X is known, give the natural parametriza-
tion of this exponential family and derive the conjugate priors on ({3, (J"2). 
Generalize to Np (X{3, E). 
3.27 Consider X '" N(B, B) with B > O. 
a. Determine the Jeffreys prior 7rJ (B). 
b. Indicate whether the distribution of x belongs to an exponential family 
and derive the conjugate priors on B. 
c. Use Proposition 3.4 to relate the hyperparameters of the conjugate priors 
with the mean of B. 
3.28 Show that, if x'" Be(Bl ,B2 ), there exist conjugate priors on B = (Bl ,B2 ) 
but that they do not lead to tractable posterior quantities, except for the 
computation of lE7r [Bl /(Bl + (2 )lx], according to Proposition 3.4. 
3.29* (Robert, 1991) The generalized inverse normal distribution 'IN(a, /k, T) 
has the density 
with a > 0, /k E JR, and T > O. 
a. Show that this density is well defined and that the normalizing factor is 
K(a,/k,T)-1 = Ta-le-1"2/27"22Ca-l)/2 rCa - 1) IFI (a -1; 1/2; /k22) , 
2 
2 
2T 
where IFI is the confluent hypergeometric function (see Abramowitz and 
Stegun, 1964). 
b. Show that this distribution generalizes the distribution of Y = l/x when 
x '" N(/k, T2). Check that the above normalizing constant is correct in 
this particular case. 
c. Deduce that the mean of 'IN(a, /k, T) is defined for a > 2 and is 
lE 
B = ~ IFl(a~I;3/2;/k2/2T2) 
a,I",7"[ 1 
T2 IFl(~;1/2;/k2/2T2)' 

Exercises 129 
d. Show that these distributions IN(a., f.J" 7) constitute a conjugate family 
for the multiplicative model N((), ()2). 
3.30 Show that a Student's t-distribution 7;,(1/, (), 7 2) does not allow for a conju-
gate family, apart from the trivial family Fa. 
3.31 Proposition 3.3 exhibits a conjugate family for every exponential family, of 
the form (3.8), 
7r(()loX, f.J,) = exp{() . f.J, - oX'IjJ(())}K(f.J" oX). 
a. Show that the distribution (3.8) is actually well defined when oX > 0 and 
(f.J,loX) E NO. 
b. Give the constant K for normal, gamma, and negative binomial distri-
butions. 
c. Deduce that the likelihood function R(()lx) is a particular prior distribu-
tion for exponential families (modulo a reparametrization) and give the 
corresponding prior for the above families. 
d. Is this property characterizing exponential families? Give a counterex-
ample. 
3.32* Show Proposition 3.4 and its reciprocal in the continuous case. Apply to 
the distributions in Table 3.2. 
3.33 Show that the distributions in Table 3.2 are actually conjugate: 
(i) directly; and 
(ii) through Proposition 3.4. 
3.34 Consider x '" (}((),(3), Le., ff3(xl()) = ~x/i-Ie-f3X. Can you exhibit a 
conjugate family for this distribution? Consider the case where () E IN. 
Same question for x '" Be(l, ()). 
3.35 Show that, for exponential families, a multiplication of the number of hier-
archicallevels does not modify the conjugate nature of the resulting prior if 
conjugate distributions with fixed scale parameters are used at every level 
of the hierarchy. (Consider, for instance, the normal case.) 
3.36* (Robert, 1993a) Consider f(xl()) from an exponential family, 
and 7ro(()lxo, >.) a conjugate prior distribution, 
7ro(()lxo, oX) = eli-xo->.1f;(/i). 
We are looking for an 'objective estimation' of V'IjJ(()) based on an arbitrary 
prior distribution 7ro(()lxo, oX). To this effect, we replace the distribution 7ro 
by 7r1(()lxI, oX) defined by the relation 
(3.20) 
in order to reduce the influence of Xo. 
a. Deduce the relation between Xl and Xo. 
b. We iterate the updating process (3.20) in order to eliminate, as much 
as possible, the influence of Xo and we construct in this way a sequence 
7rn(()lxn, oX) of conjugate priors. Give the relation between Xn and Xn-l 
and deduce the limit of the sequence (Xn). 

130 3. From Prior Information to Prior Distributions 
c. Give the corresponding limit of the Bayes estimators of "V'Ij;(()). How do 
you characterize the resulting estimator? Is it still a Bayes estimator? 
d. In the particular case when x rv N((),l), the parameter of interest is 
h(()) = e-o. Give the estimator h(()) obtained this way using the iterative 
updating 
lE"n [h(())] = lE"n-l [h(())lx]. 
e. Consider the case x rv 9(a, ()) and h(()) = ()k to show that this iter-
ative method, called Prior Feedback, does not always converge to the 
maximum likelihood estimator. 
f. Show that the limit of the Prior Feedback estimate when .A goes to +00 
is the maximum likelihood estimator of h(()), for an arbitrary function 
h and every exponential family. 
Section 3.3 
3.37 Apply Dalal and Hall's (1983) decomposition to the following cases: 
(i) x rv N((),Ip) , () rv Tp(m, 0, T2); and 
(ii) x rv Neg(N,p), p/(l- p) rv 9(1/2,1/2). 
3.38* Find the natural measures lim of Dalal and Hall (1983) for the distributions 
of Table 3.3. 
3.39 In the setup of Example 3.15, build up a prior distribution by observing a 
few coins and imposing a mixture of beta distributions as in Diaconis and 
Ylvisaker (1985). Select one of these coins and derive a posterior distribution 
on (), probability of heads, after 10 trials and 50 trials. 
3.40 Consider x rv N(O, 1) and () rv 1i(5, 0,1). 
a. Devise a method to approximate this prior distribution by a mixture of: 
(i) two normal distributions; and (ii) five normal distributions. 
b. In each case, give the approximating posterior expectation of () when 
x = 1 and compare with the exact value. 
Section 3.4 
3.41 In relation to Example 3.22, if x rv B(n,p), find a prior distribution on n 
such that 7l'(nlx) is Neg(x,p). 
3.42* Show that the Bayes estimator of T/ = 11()11 2 under quadratic loss for 7l'(T/) = 
1/y'rj and x rvN((),Ip) can be written as 
8"(x) = IFt(3/2;p/2; IIxl1 2 /2) 
1Ft (1/2; p/2; IIxl1 2 /2) , 
where IFI is the confluent hypergeometric function. Deduce from the series 
development of IFI the asymptotic development of 8" (for IlxW -- +00) 
and compare with 80 (x) = IIxl1 2 - p. Study the behavior of these estimators 
under the weighted quadratic loss 
and conclude. 
3.43 Find a transform of (), T/ = g(()), such that the Fisher information I(T/) is 
constant for: 
(i) the Poisson distribution, P(()); 

(ii) the gamma distribution, 9(00, e), with a = 1,2,3; and 
(iii) the binomial distribution, B(n, e). 
Exercises 131 
3.44 Assuming that 71'(e) = 1 is an acceptable prior for real parameters, show that 
this generalized prior leads to 71'(0') = 1/0' if 0' E IR+ and to 71'(e) = 1/ e(l-e) 
if e E [0,1] by considering the natural transformations e = log(O') and 
e = log(e/(I- e)). 
3.45* (Saxena and Alam, 1982) In a setting identical to the one of Exercise 3.42, 
give the maximum likelihood estimator of IleW when x rv N(e, Ip) and show 
that the maximum likelihood estimator derived from z = IIxl1 2 satisfies the 
following implicit equation: 
(z > p), 
where Iv is the modified Bessel function (see Abramowitz and Stegun, 1964 
or Exercise 4.25). Use the series expansion of Iv to show that the maximum 
likelihood estimator 5. satisfies 
5.(z) = z - p + 0.5 + 0(1/ z). 
Show that 5. is dominated by (z - p)+ under quadratic loss. 
3.46 If x rv N(e, (72), give the reference prior distributions for {e, O'} and {O', e}. 
The following exercises (3.47-3.53) present the marginalization paradox 
through several examples and show that it can only occur for improper priors. 
Dawid et al. (1973), Stone (1976), and Jaynes (1980) give some partial resolu-
tions of these paradoxes. Note that a fundamental explanation is that the improper 
distribution 71'(&'1, de) = 71'("1) d"l de does not induce the 'marginal distribution' 
71'(d"l) = 71'("1) d"l. 
3.47* (Dawid et al., 1973) Consider n random variables Xl, ... ,xn , such that 
the first ~ of these variables has an Exp("I) distribution and the n -
~ other 
have a Exp(c"l) distribution, where c is known and ~ takes its values in 
{I, 2, ... , n - I}. 
a. Give the shape of the posterior distribution of ~ when 71'(~, "I) = 71'(~) 
and show that it only depends on z = (Z2, ... , Zn), with Zi = Xi/Xl. 
b. Show that the distribution of z, f(zl~), only depends on ~. 
c. Show that the posterior distribution 71'(~lx) cannot be written as a poste-
rior distribution for z rv f(zl~), whatever 71'(~), although it only depends 
on z. How do you explain this phenomenon? 
d. Show that the paradox does not occur when 71'(~, "I) = 71'(~)"I-l. 
3.48* (Dawid et al., 1973) Consider Ul,U2,S2 such that 
and ( = (/kl - /k2)/(0'V2) is the parameter of interest. The prior distribution 
is 
1 
71'(/kl, /k2, 0') = -. 
0' 
a. Show that the posterior distribution 71'((lx) only depends on 

132 3. From Prior Information to Prior Distributions 
Ul -
U2 
Z = sv'2 . 
b. Show that the distribution of Z only depends on (, but that a paradox 
occurs; it is still impossible to derive 7r((lx) from f(zl(), even though 
7r((lx) only depends on z. 
c. Show that the paradox does not occur when 
3.49* (Dawid et al., 1973) Consider 
Xll, ... ,Xln ",N(Ml,a2), 
X21, ... , X2n '" N(M2, ( 2), 
2n independent random variables. 
a. The parameter of interest is ~ = (6,6) = (M1/a, M2/a) and the prior 
distribution is 
7r(Ml,M2,a) = a-Po 
Show that 7r(~lx) only depends on z = (Zl,Z2) = (X1/S,X2/S) and that 
the distribution of z only depends on ~. Derive the value of p which 
avoids the paradox. 
b. The parameter of interest is now ( = 6. Show that 7r((lx) only depends 
on Zl and that f(Zll~) only depends on (. Give the value of p which 
avoids the paradox. 
c. Consider the previous questions when a '" Pa(a, ao). 
3.50* (Dawid et al., 1973) Consider (Xl, X2) with the following distribution: 
f(Xl, x210) ex 1+
00 t2n- l exp [-~ {t2 + n(Xlt - ()2 + n(X2t _ ~)2}] dt, 
with 0 = ((,~). Justify this distribution by considering the setting of Exer-
cise 3.49. The prior distribution on 0 is 7r( 0) = l. 
a. Show that 7r((lx) only depends on Xl and that f(X1IO) only depends on 
(, but that 7r((lx) cannot be obtained from Xl'" f(X11(). 
b. Show that, for any distribution 7r(O) such that 7r((lx) only depends on 
Xl, 7r((lx) cannot be proportional to 7r(()f(X11(). 
3.51 * (Jaynes, 1980) In the setting of Exercise 3.47, consider 7r(~, TJ) = 7r(~)7r(TJ). 
a. Show that 
with 
e 
n 
Q= LZi+cLzi. 
i=l 
e+l 
b. Examine whether the paradox occurs for 7r(TJ) = TJ- k (k> -n - 1). 
c. Same question for TJ '" Pa(a,TJo). 
3.52* (Jaynes, 1980) Consider 

Exercises 133 
(O:Sy:Sz), 
with 0 < 'f/ < 1. 
a. Show that J(zl'f/, () only depends on ( and derive the distribution J(y, 
zl'f/, () from J(ylz, 'f/, (). 
b. Show that, for every 11'('f/), the paradox does not occur. 
3.53* (Dawid et al., 1973) Consider x = (y, z) with distribution J(xIB) and 
B = ('f/, e)· Assume that 11'(elx) only depends on z and that J(zIB) only 
depends on e. 
a. Show that the paradox does not occur if 11'( B) is proper. 
b. Generalize to the case where I 11'('f/, e) d'f/ = 11'(e) and examine whether 
the paradox is evacuated. 
3.54 Consider B E [a, b) and 11'(B) IX l/B. 
a. Determine the normalizing factor of 11'. 
b. Compute Pi = 11'(i :S B < i + 1) for a :S i :S b - 1. 
c. Deduce the limit of Pi as a goes to 0 or b goes to 00. (Note: This exercise 
is related to the table entry problem, namely, the fact that in many 
numerical tables, the frequency of the first significant digit is log 10 (1 + 
C l ) (1 :S i :S 9). See Berger (1985a, p. 86) for a detailed account.) 
3.55 The Fisher information is not always defined when the support of J(xIB) 
depends on B. Consider the following cases: 
(i) x ",U[-9,9]; 
(ii) x'" Pa(a,B); 
(iii) J(xIB) IX e-(x-9)2/2][[0,91(X). 
3.56 Show that a second-order approximation of both the entropy and Hellinger 
losses introduced in §2.5.4 is (B - 8)21(B). Does this result give additional 
support to the use of the Jeffreys prior? 
3.57 Consider x '" P(B). 
a. Determine the Jeffreys prior 11'J and discuss whether the scale-invariant 
prior 11'0(B) = l/B is preferable. 
b. Find the maximum entropy prior for the reference measure 11'~ and the 
constraints IE1I"[B) = 1, var1l"(B) = 1. What about using 11'0 instead? 
c. Actually, x is the number of cars crossing a railroad in a period T. Show 
that x is distributed according to a Poisson distribution P(B) if the 
interval between two arrivals is distributed according to £xp().). Note 
that B = )'T. 
d. Use the above derivation of the Poisson distribution to justify the use of 
11'0· 
3.58 Consider Xl, ••• ,Xn '" N(p, + 1/,0"2), with 11'(p" 1/) IX I/O". 
a. Show that the posterior distribution is not defined for every n. 
b. Extend this result to overparametrized models with improper priors. 
Section 3.5 
3.59* (Berger, 1990a) Consider the class T.,Q defined in §3.5 (iii), with 
Q = { unimodal distributions symmetric around Bo}. 
When 11' varies in Q, the marginal 

134 3. From Prior Information to Prior Distributions 
m('if) = J 
f(xl8)'if(O) dO 
varies between upper and lower bounds, m U and m L . 
a. Show that every unimodal distribution which is symmetric around 00 
can be written as a mixture of uniform distributions symmetric around 
00 , U[8o-a,8o+aj. 
b. Deduce that 
1
8o+z f( 10) 
mU = sup m('if) = (1 - E)m('ifo) + ESUP 
--+- dO. 
"Er,.Q 
z>o 8o-z 
Z 
c. If the quantity of interest is the Bayes factor, 
where 'if! is 'if conditioned by 0 i= 00 and 'ifo is the Dirac mass at 00 , show 
that 
3.60 Consider the class of prior distributions 
r = {N(p" 7 2 ), ° 
:::; p, :::; 2, 2:::; 7 2 :::; 4} 
when x '" N(O, 1). 
a. Study the variations of JE"[Olx] and var"(Olx) when 'if E r. 
b. Study p('if, 8"') when 'if, 'if' E rand 8"(x) = JE"[Olx], L(0,8) = (0 - 8? 
in order to determine the r-minimax estimator. 
3.61 * (Walley, 1991) Suppose that, instead of defining a prior distribution 'if on 
the IT-algebra of e, one defines some upper and lower bound measures on 'if, 
'if and K. For any event A, K(A) represents the largest amount one is willing 
to bet to receive one unit if A occurs. Similarly, 1 - 'if(A) is the smallest 
amount one is ready to bet against the event A. 
a. Show that, if a prior distribution 'if is available, K = 'if = 'if. 
b. Show that K(A) + K(AC) :::; 1 :::; 'if(A) + 'if(AC) for every A if sure loss is 
to be avoided. 
c. If K(AUB) is the maximum bet one is ready to place on AUB, show that 
K(A U B) 2: K(A) + K(B) and, similarly, that 'if(A U B) :::; 'if(A) + 'if(B). 
3.62* (Cont.) If, instead, one considers gambles, i.e., bounded real-valued func-
tions X on a measured space n which corresponds to variable rewards 
depending on the uncertainty state wEn, it is also possible to define upper 
and lower previsions, P and E, where E(X) denotes the maximum price 
acceptable to get the reward X and P(X) the maximum selling price. 
a. A gamble is desirable if there is a chance one gambles for it. Justify the 
following axioms: 
(A) If sUPw X(w) < 0, then X is not desirable; 
(B) If inC X(w) > 0, then X is desirable; 
(C) If X is desirable and>' > 0, then >.X is desirable; and 
(D) If X and Yare both desirable, then X + Y is desirable. 

Exercises 135 
b. Justify the following coherence axioms on E and show that they corre-
spond to (B), (C) and (D) above: 
(Pl ) E(X) ;:: infw X(w); 
(P2) E(AX) = AE(X); and 
(P3) E(X + Y) ;:: E(X) + E(Y). 
c. Given a lower prevision E, the conjugate upper prevision is defined by 
P(X) = -E(-X). Show that, if E is coherent and P is the conjugate 
of E, they satisfy 
inf X(w) :::; E(X) :::; P(X) :::; supX(w) 
w 
w 
and deduce that P is a convex function. 
d. Show that, when E is self-conjugate, then E(X) = P(X) and it satisfies 
the linearity requirements 
E(X + Y) = E(X) + E)Y) 
and 
E(AX) = AE(X), A E JR. 
3.63* (Cont.) A lower prevision E is said to avoid sure loss if, for every n ;:: 1 
and every set of gambles Xl, ... , X n, 
n 
sup L Xi - E(Xi ) ;:: o. 
w 
i=l 
a. Show that E avoids sure loss if and only if 
n 
sup L Ai(Xi - E(Xi )) ;:: 0 
w 
i=l 
for every n;:: 1, every set of gambles Xl, ... ,Xn and every Ai ;:: O. 
b. Assuming that E avoids sure loss, show that, for every A ;:: 0, 
E(AX) :::; AP(X), 
P(AX) ;:: AE(X), 
E(AX + (1 - A)Y) :::; AP(X) + (1 - A)P(Y). 
when P is the conjugate upper prevision. 
c. A lower prevision is coherent if 
s~p [t(Xi - E(Xi )) - m(Xo - E(XO))] ;:: 0 
for every m, n and every set of gambles X o, ... ,Xn . Show that E is 
coherent if and only if it satisfies axioms (Pl ), (P2), and (P3). 
d. Show that linearity is equivalent to coherence plus self-conjugacy, if lin-
earity is defined by 
,~p { t 
X,(w) -t Y;(w) } :> t 
E(X,) -t E(Y;) 
for every n, m and every set of gambles Xl, ... , X n , Yl , ... , Ym . 
e. Show that E is a linear prevision ifand only if E(X + Y) = E(X) + E(Y) 
and E(X) ;:: inL X(w). Deduce that E is a linear prevision if and only 
if it satisfies linearity, (P2), and 
(P4) if X ;:: 0, then E(X) ;:: 0; and 
(P5 ) E(l) = 1. 


4 
Bayesian Point Estimation 
4.1. Bayesian Inference 
When the prior distribution n(O) is available, the posterior distribution 
n(Olx) can be formally derived from the observation x with distribution 
f(xIO). This updated distribution is then the extensive summary of the 
information available on the parameter 0, integrating simultaneously prior 
information and information brought by the observation x. (The same ob-
viously holds when a sample xl, ... ,Xn is available but it can usually be 
reduced to the above situation through a sufficient statistic.) The Bayesian 
version of the likelihood principle thus implies that the inference on 0 should 
rely entirely on the posterior distribution n(Olx). Even though 0 is not nec-
essarilya random variable, the distribution n(Olx) can be used as a regular 
probability distribution to describe the properties of O. Summarizing indices 
for n(Olx) like the mean, the mode, the variance, the median (even in mul-
tidimensional problems, see Small, 1990), etc., can be used. For instance, 
when the quantity of interest is h(O), a possible estimator of h(O) is the 
posterior mean JE71"[h(O)lx]. (As mentioned in §3.4, when the distribution n 
is a noninformative prior, some marginalization difficulties may occur and 
it is sometimes necessary to derive a new reference prior for the parameter 
of interest, h(O).) 
If a choice must be made among the above summaries, there is no way 
of selecting a best estimator, short of using a loss criterion. Nonetheless, 
a possible estimator of 0 based on n(Olx) is the maximum Bayesian likeli-
hood estimator, defined as the posterior mode, which maximizes £(Olx)n(O), 
this quantity bypassing the computation of the marginal distribution. This 

138 4. Bayesian Point Estimation 
natural estimator can be also expressed as a penalized maximum likelihood 
estimator in the classical sense (see Akaike, 1978, 1983). Note that the 
asymptotic optimality properties of the regular maximum likelihood esti-
mator (consistency, efficiency) are preserved for these Bayesian extensions, 
under a few regularity conditions on f and 7r (see Lehmann (1983, Chap. 
6), Diaconis and Freedman (1986), and Ibragimov and Has'minskii (1981)). 
This extension of the asymptotic properties of the maximum likelihood es-
timator is intuitively sound since, as the sample size grows to infinity, the 
information contained in this sample becomes predominant compared with 
the fixed information brought by the prior distribution 7r (see Lehmann, 
1983, and Hartigan, 1983). Therefore, maximum Bayesian likelihood esti-
mators are asymptotically equivalent to the classical maximum likelihood 
estimators but, furthermore, they have the additional advantage of being 
available for finite sample sizes, while the latter are mainly justified on 
asymptotic grounds. 
Example 4.1 Consider x rv B(n,p). We saw in the previous chapter that 
the Jeffreys prior in this setup is the beta distribution Be(1/2, 1/2), i.e., 
1 
7r*(p) = 
p-1/2(1 _ p)-1/2. 
B(1/2, 1/2) 
Two other noninformative distributions have been proposed in the literature 
by Laplace and Haldane (1931) (see also Exercise 4.4), 
and 
The corresponding maximum Bayesian likelihood estimators are then, for 
n> 2, 
8* (x) = max 
, ° , 
( X -1/2 ) 
n-1 
X 
81(x) = -, 
n 
82(x) = max (~ = 
~, 0) . 
When n = 1, 8* and 82 are equal to 81. For n = 2 and x = 1, the estimator 
82 is also equal to 81, which is the regular maximum likelihood estimator. 
Note that, when n is large, the three estimators are indeed equivalent. 6. 
Example 4.2 Consider x rv C (B, 1), i.e., 
and 7r(B) = ~e-Iel. The maximum Bayesian likelihood estimator of B is then 
8*(x) = 0, as the maximum of exp( -IBI)[1+(x-B?t1 is attained for B = 0, 
whatever the value of x. This behavior may be explained by the flatness 
of the likelihood function, which is not informative enough, compared with 

4.1. Bayesian Inference 139 
the sharp prior distribution. Of course, from a practical point of view, this 
estimator is useless (see also Exercise 4.6). 
I:::,. 
Bayesian inference thus appears as a way to implement efficiently the 
Likelihood Principle, since it provides an estimator, by selecting for in-
stance, as in Example 4.3 below, one of several maxima of the likelihood 
function. As stressed by Savage (1962) and Berger and Wolpert (1988), 
there are many philosophical and practical considerations linking the Likeli-
hood Principle to a robust Bayesian implementation. In particular, it allows 
for the elimination of some classical paradoxes as those of Stein (1962b), 
Stone (1976), Fraser, Monette and Ng (1984), and Le Cam (1990). The 
following example illustrates the resolution of the paradox of Fraser et al. 
(See also Joshi (1990) for an extended analysis of the phenomenon.) 
Example 4.3 (Berger and Wolpert, 1988) Consider X = e =]N* and 
1 
{B/2' 2B, 2B + 1 
f(xIB) = "3 for 
(B - 1)/2, 2B, 2B + 1 
1,2,3 
The likelihood function is then 
1 
{ x/2, 2x, 2x + 1 
£(Blx) = "3 for 
(x - 1)/2, 2x, 2x + 1 
1,2,3 
if B is even, 
if B is odd and B #- 1, 
if B = 1. 
if x is even, 
if x is odd and x #- 1, 
if x = 1, 
(4.1) 
and the three values of B where £(Blx) #- 0 are equally weighted by the 
likelihood function. Consider the three following estimators: 
{ 
x/2 
81 (x) = 
~x - 1)/2 
and 
if x is even, 
if x is odd and x #- 1, 
if x = 1, 
They are equivalent from the Likelihood Principle point of view but 02 and 
03 are quite suboptimal estimators since 
P(o (x) = B) = P(x = B/2) = {1/3 if B is ~ven, 
2 
0 
otherWIse, 
P(o (x) = B) = P(x = (B _ 1)/2) = {1/3 if B #- ~ is odd, 
3 
0 
otherWIse, 
while 
P(o (x) _ B) _ { 1 
if B = 1, 
I 
-
-
2/3 otherwise. 

140 4. Bayesian Point Estimation 
The estimator th is therefore preferable under losses like the 0 - 1 loss. 
When the information available on the model is reduced to the likelihood 
function (4.1), a possible noninformative distribution on () is Jr(()) = 1/(), 
since () can approximately be considered as a scale parameter. In this case, 
and this posterior distribution gives 81 (x) as being four times more likely 
than 82 or 83 , It can also be shown that plr(() = 81(x)lx) C::' 2/3 for large 
x's. This gives a good justification to the choice of 81. A more informative 
prior modeling would lead to a similar conclusion (as a proper distribution 
Jr(()) must be decreasing for () large enough). 
6 
Berger and Wolpert (1988) provide similar resolutions of the paradoxes 
exhibited by Stein (1962b) and Stone (1976). An immediate advantage of 
the Bayes approach over alternatives implementations of the Likelihood 
Principle is to take care of the nuisance parameters in the likelihood function 
by integrating them out. In fact, if £((), Tlx) also depends on a nuisance 
parameter T, a natural derivation of an estimate (j of () is to consider the 
maximum of the integrated likelihood 
J 
£((), Tlx)Jr((), T) dT 
instead of the more classical "profile" likelihood, 
max £((), Tlx)Jr((), T). 
T 
See also Basu (1988) for an extensive analysis of the treatment of the nui-
sance parameters. 
Berger (1985a) points out the interest of a noninformative Bayesian 
approach for restricted parameter spaces, as the prior distribution is just 
the truncation of the nonrestricted noninformative distribution. From a 
classical point of view, the derivation of restricted maximum likelihood es-
timators is often complicated, especially when the constraints are nonlinear 
(see Robertson et al., 1988). On the contrary, the implementation of the 
Bayesian approach through a Monte-Carlo simulation scheme (see Chapter 
9 and Gelfand et al., 1992) allows for an easy derivation of the Bayes esti-
mators. (This advantage can even be used to compute restricted maximum 
likelihood estimators via Bayesian techniques. See Geyer and Thompson, 
1992, and Robert and Hwang, 1993.) 
Example 4.4 Consider the estimation of the linear model regression 
(4.2) 
which relates direct incomes (XI), saving incomes (X2 ), and savings (y). 
A careful estimation of the saving rates b1 and b2 is important for the 

4.1. Bayesian Inference 141 
government to determine its fiscal and interest rates policies. The sav-
ing rates are obviously constrained by 0 S; b1 , b2 S; 1. Consider a sam-
ple (Y1,Xn,X2d, ... ,(Yn,X1n,X2n) from (4.2) and assume that the er-
rors Ei are independent and distributed according to N(O,l), i.e., that 
Yi ,....., N(b1Xli + b2X 2i , 1). The corresponding noninformative distribution 
is then the proper distribution 
7r(b1, b2 ) = 1[0,1] (bdl [o,l] (b2 ) 
and the posterior mean is given by (i = 1,2) 
7r 
fo1 fo1 bi I17=1 'P(Yj - b1X 1j - b2X 2j ) db1 db2 
IE [biIYl,···,Yn] = 
lIn 
' 
fo fo I1j =l 'P(Yj - b1X 1j - b2X 2j ) db1 db2 
where 'P is the density of the standard normal distribution. If we denote by 
(b 1 , b2 ) the unconstrained least square estimator of (b1 , b2 ), which is also 
the regular maximum likelihood estimator of (b1 , b2 ), the unconstrained 
posterior distribution on (b1 , b2 ) is 
(4.3) 
with 
x = (~.~1 ~~1). 
X 1n 
X2n 
Therefore, the restricted Bayes estimator is given by (i = 1,2) 
where the right-hand term is computed under the distribution (4.3). If we 
denote 

142 4. Bayesian Point Estimation 
and 
Note that this second integral can be obtained in closed form using the 
standard normal c.dJ. P, but that the denominator cannot be computed 
analytically. It is therefore more efficient to compute both integrals by a 
Monte Carlo simulation (see Chapter 9). 
In the particular case where b1 and b2 are independent a posteriori, 
i.e., when 0"12 = 0, the Bayes estimators are explicit and given by (i = 1,2) 
Note that a Bayesian modeling is also quite appropriate to incorporate 
vague information, i.e., cases where a restriction On the parameter space is 
likely but not certain. Chapter 8 demonstrates that a typical way to do so 
is to use a hierarchical or an empirical Bayes modeling. 
Since the whole posterior distribution 71"(0 Ix) is available, it is possible 
to associate to an estimator 87r(x) of h(O) an evaluation of the precision of 
the estimation, through, for instance, the posterior squared error, 
equal to var7r(h(O)lx) when 87r(x) = JE7r [h(O) Ix]. Similarly, in a multi-
dimensional setup, the covariance matrix characterizes the performances 
of estimators. These additional indications provided by the posterior dis-
tribution illustrate the operational advantage of the Bayesian approach, 
since the classical approach usually has difficulties to motivate the choice 
of these evaluations. Moreover, Bayesian evaluation measures are always 
conditional, while the frequentist approach usually relies On upper bounds 
through the minimax principle, since the parameter 0 is unknown (see 
Berger and Robert, 1990, for a comparison of both approaches). 
Example 4.1 (Cont.) Consider the maximum likelihood estimator of p, 
D1(X) = x/no Then 

4.1. Bayesian Inference 143 
JE7r[(81(x) - p)2Ix] = JE7r[(p - x/n)2Ix] 
= (x + 1/2 _ ~) 2 + (x + 1/2)(n - x + 1/2) 
n+1 
n 
(n+1)2(n+2) 
= (x - n/2)2 + (x + 1/2)(n - x + 1/2) 
(4.4) 
(n + 1)2n2 
(n + 1)2(n + 2) 
, 
since 7f(plx) is the beta distribution l3e(x + 1/2, n - x + 1/2). From a fre-
quentist viewpoint, the risk of the maximum likelihood estimator is 
and 
supp(l - p)/n = 1/4n. 
p 
Developing (4.4), it is easy to verify that the maximum of (4.4) is 
1/[4(n + 2)], 
always smaller than 1/ 4n. The major advantage of the quantity (4.4), 
though, is still to provide an adjustable answer for the evaluation of 81 , 
since (4.4) varies between 1/[4(n + 2)] and 3/[4(n + l)(n + 2)]. Obviously, 
a frequentist approximation of p(l - p)/n can also be proposed, namely, 
(x/n)(l- x/n)/n. This evaluation has then the opposite drawback of 1/4n 
since it varies too widely, as shown by Figure 4.1. It can even take the 
value 0 when x = 0, n. A similar behavior is discussed in Berger (1990b) in 
a general framework. 
£:0. 
Furthermore, Bayesian inference can operate as well in prediction prob-
lems. If x rv f(xIB) and z rv g(zIB), the predictive distribution of z after the 
observation of x is given by 
g(zlx) = fe g(zIB)7f(Blx) dB. 
(4.5) 
The distribution of z is thus quite logically averaged over the values of B 
according to the posterior distribution, which is also the actualized distri-
bution of B. It is possible to use (4.5) to derive the predictive mean and 
variance of the random variable z. In §4.4.1, we consider a particular exam-
ple of determination of a discrete predictive distribution (see also Exercise 
4.30). Note that the decision-theoretic approach developed in the following 
sections is also applicable in a prediction setup, even though we do not 
mention it later. Indeed, if a prediction loss L(z, 8) is available, a predictor 
8(x) can be chosen in order to minimize the expected prediction error (the 
expectation being with respect to the predictive distribution (4.5)). (See 
Exercise 4.33.) 

144 4. Bayesian Point Estimation 
0.08 
0.06 
0.04 
0.02 
FIGURE 4.1. Comparison of Bayesian and frequentist evaluations of the estima-
tion error in the binomial case (n = 3). 
Given the scope of possible uses of the posterior distribution, some 
Bayesians consider that clients should be provided with the posterior dis-
tribution so that they could use it at their convenience. While the commu-
nication of Jr(Olx) is indeed of interest for small dimensions, the information 
provided by Jr(Olx) gets blurred by its own complexity for large dimensions. 
The posterior distribution is obviously essential in the decision-making pro-
cess but it is part of the statistician's role to assist the decision-maker fur-
ther, in order to extract the features of interest from Jr(Olx). We thus face 
again the major problem of selecting among estimators and we have seen 
in Chapter 2 that this selection is efficient and coherent only when based 
on a loss criterion. The following sections are thus exposing Bayesian De-
cision Theory, with particular attention to the normal and sampling cases. 
Testing perspectives and confidence set estimation are treated separately 
in Chapter 5. 
4.2. Bayesian Decision Theory 
Let us recall here that, given a loss function L(O, 8) and a prior distribution 
(or a measure) Jr, the Bayes rule 87r (x) is solution of 
min 1E7r [L(O, 8)lx]. 
{j 

4.2. Bayesian Decision Theory 145 
Depending on the complexity of the loss L and of the posterior distribution 
7r(Blx), the estimator 81r will be determined analytically or numerically, 
similar to maximum likelihood estimation. 
As shown in Chapter 2, the solutions associated with classical losses 
are formally known and correspond to the natural indicators associated 
with a distribution (mean, median, mode, quantiles, etc.). For instance, the 
Bayes estimator associated with the quadratic loss is the posterior mean 
(Proposition 2.18 and Corollary 2.19). Of course, this formal derivation of 
classical Bayes estimators does not always avoid a numerical approximation 
of the estimators, in particular, in multidimensional settings. 
Example 4.5 Consider x '" Np((),Ip). As mentioned in §3.6, Student's t-
distribution provides a robust alternative to the conjugate normal prior for 
estimating (). Consider thus B '" Tp(a,O,r2Ip), i.e., 
_ 
r((a + p)/2) 
( 
~) 
-(a+p)/2 
7r(Bla, r) - (ar7r)p/2 r(a/2) 
1 + ar2 
Therefore, 
which does not lead to a closed-form expression for the posterior distribu-
tion. However, it is still possible to reduce the computational problem to a 
single integration, for every value of p, as shown by Dickey (1968). In fact, 
if () '" Tp(a,O,r2Ip), the posterior distribution of B can be expressed as a 
hidden mixture (see Example 3.11), 
()Iz '" Np(O, r2 zIp), 
Z-l '" 9(a/2, a/2), 
where z is an auxiliary random variable. Conditionally on z, the posterior 
distribution of B is 
and, since 
we derive the Bayes estimator as 
[+00 
81r(x) = Jo 
IE1r[()lx, z]7r(zlx) dz 
_ 
Jo+ oo (1 + r2 z)-(P+2)/2e-llxI12 /2(1+r2z) z-(a+2)/2e-a/2z dz 
-x 
. 
Jo+ 00 (1 + r2z)-p/2e-llxI12/2(Hr2z)z-(a+2)/2e-a/2z dz 

146 4. Bayesian Point Estimation 
This estimator can therefore be expressed through a single integral for every 
~~~~ 
6 
However, decomposition subtleties as in the above example are not 
always available and the computation of a Bayes estimator then calls for 
more general methods like those described in Chapter 9. An interesting 
result is that, when the marginal distribution m(x) is available, the Bayes 
estimator of the natural parameter can be easily derived for exponential 
families. 
Lemma 4.1 Consider f(xIB) = h(x)eo.x-'ljJ(O), a distribution from 
an exponential family. For every prior distribution 7r, the posterior 
mean of B is given by 
<51r(x) = \7 log m 1r (x) - \7 log h(x), 
(4.6) 
where \7 denotes the gradient operator and m 1r is the marginal 
distribution associated with 7r. 
Proof. The posterior expectation is given by 
Note that this lemma is satisfied for every 7rj it appears as the dual 
result of the derivation of the moments of f(xIB) from the derivative of'IjJ in 
exponential families (see Lemma 3.1). Its practical interest is rather limited 
since the derivation of the marginal distribution is usually quite delicate and 
to know m 1r(x) explicitly is equivalent to knowing 7r(Blx) explicitly. From 
a theoretical viewpoint, a consequence of this lemma is to show that Bayes 
estimators are analytic (or holomorphe) functions for exponential families 
such that the function h spanning the exponential family is holomorphe 
(since m1r/h is the Laplace transform of e-'ljJ(O)7r(B)). Chapter 6 derives an 
inadmissibility criterion from this property. 
Example 4.6 We introduced in §2.5.4 the truncated James-Stein estimator, 
JS 
p- 2 
( 
) + 
<5 
(x) = 1- IIxl1 2 
X 
when x ,,-,Np((),Ip). In the normal case, (4.6) reduces to 

4.2. Bayesian Decision Theory 147 
Although there exists a function m such that 8JS can be written as above 
(see Bock, 1988), m is not a marginal distribution and this estimator cannot 
be a Bayes estimator: it is equal to 0 on the open set {II x 112 < p - 2} and 
it should be null everywhere were it analytic. 
D 
The representation (4.6) of the Bayes estimators is also useful in tech-
niques underlying the Stein effect, either to establish domination condi-
tions as in Stein (1981), George (1986a), Berger and Robert (1990), and 
Brandwein and Strawderman (1990), or to point out the inadmissibility of 
some estimators as in Bock (1988) and Brown (1988). (See Exercise 4.31.) 
TABLE4.1. The Bayes estimators of the parameter 0 under quadratic loss for 
conjugate distributions in the usual exponential families. 
Distribution 
Conjugate distribution 
Posterior expectation 
Normal 
Normal 
JUj2 + 7 2X 
N(O, ()2) 
N(p" 7 2 ) 
()2 + 72 
Poisson 
Ga 
a+x 
P(O) 
9(a,{3) 
(3+1 
Ga 
Ga 
a+v 
9(v,O) 
9(a,{3) 
(3+x 
Binomial 
Beta 
a+x 
B(n,O) 
Be(a, (3) 
a+{3+n 
Negative binomial 
Beta 
a+n 
Neg(n,O) 
Be(a, (3) 
a+{3+x+n 
Multinomial 
Dirichlet 
ai +Xi 
Mk(n; OI, ... , Ok) 
D(al, ... ,ak) 
(L: j aj) + n 
Normal 
Ga 
a+l 
N(p" I/O) 
9(a/2,{3/2) 
(3+(p,_X)2 
In the particular case of conjugate distributions, the posterior expecta-
tions of the natural parameters can obviously be expressed analytically and 
this is practically the only case where closed-form expressions are available 
in such generality. Table 4.1 presents the Bayes estimators associated with 
the usual distributions and their conjugate priors. Note that when several 
observations from f(xl6l) are available, the conjugate distributions are the 
same and that only the parameters in the estimator are modified. 
Example 4.7 If Xl, ... , Xn are independent observations from Neg(m,6l) 
and if 6l cv Be(ex, (3), the posterior distribution of 6l is the beta distribution 
Be (ex + mn, L:~=l Xi + (3) and 

148 4. Bayesian Point Estimation 
This result is a straightforward consequence of 2:7=1 Xi rv Neg(mn, e). D 
Example 4.8 Consider n observations Xl, ... , Xn from U([O, e]) and e rv 
Pa(eo, a). Then 
and 
811"(Xl, .. "Xn ) = 
a+n 1 max(eo,xl, ... ,Xn ). 
a+n-
Therefore, compared with the maximum likelihood estimator, 
80(Xl' ... , xn) = max(xl' ... , xn), 
the Bayes estimator gives a more 'optimistic' estimation of e, since n~!~l > 
1. On the contrary, the best equivariant estimator of e under squared er-
ror loss is n~l 80(Xl, ... , xn) (see Chapter 7), larger than 811" when eo is 
small. This shrinking behavior of 811" is explained by the choice of 1r, which 
decreases with e, thus favoring values of e close to eo. 
D 
Similarly, recall that the estimation of a function of e, g(e), under 
quadratic loss gives 811"(x) = IE11"[g(e)lx] as the Bayes estimator. 
Example 4.9 Consider X 
rv O(v, e) and e rv O(a, (3). The parameter of 
interest is lie, the expectation of x. Under the quadratic loss 
the Bayes estimator is then 
811"(X) = ((3 + x)n+v r+ oo ~ en+v- l e-C/3+x )IJde 
1 
r(a+v) io 
e 
(3+x 
a+v-l 
Under a renormalized (or weighted) quadratic loss, 
L(e,8) = w(e) II 8 - e lib, 
where Q is a p x p nonnegative symmetric matrix, the corresponding Bayes 
estimator is 
Example 4.9 (Cont.) A scale-invariant loss, which does not depend on the 
unit of measurement, may be more relevant for the estimation of lie. For 
instance, the loss 

4.2. Bayesian Decision Theory 149 
gives the Bayes estimator 
7r 
JE7r [02/0 I xl 
82 (x)= JE7r[02Ix] 
ft)O Ooo+v-le-({3+x)(i dO 
ft)O Oa+v+le-((3+x)(idO 
,8+x 
=O:+1I-1 87r(x) 
O:+1I+1 
O:+1I+1 
2 
• 
Let us stress again that, even for conjugate distributions, the fact that 
the Bayes estimator of any function of 0 involves posterior expectations does 
not necessarily avoid numerical computations as analytical integration may 
be impossible, in particular, in multidimensional problems. 
Example 4.10 Consider x'" Np(O,Ip) and h(O) = 110112. The loss considered 
in Saxena and Alam (1982) is 
since, if 80(x) = IIxl12 - p, 
() 
1 
12 
2 
2 
R 80 ,0 = 2110112 + p JE(llxl 
-11011 - p) = 2 
and 80 has a constant risk. Without this renormalization, all estimators have 
a maximum risk equal to +00, while under L, the estimator 80 is minimax. 
Then, even for the conjugate distributions, N(O, 7 2), the computation of 
87r(x) = JE7r [l10112/(2110112 + p)lx] 
JE7r[1/(211811 2 + p)lx] 
cannot be conducted analytically. 
In the previous examples, we resorted rather heavily to the quadratic 
loss since it constitutes a standard loss and allows, as much as possible, for 
explicit computations. We refer the reader to Chapter 2 for criticisms about 
the arbitrariness of standard losses and the opposition between bounded 
concave and unbounded convex losses, the former leading to the risk-lover 
paradox and the latter to more instability in the resulting procedures (see 
Kadane and Chuang (1978), Smith (1988), and Exercises 4.1 and 4.13). The 
main point is, nonetheless, that, when the loss function is truly determined 
by the decision maker, it is usually complex and most often calls for a 
numerical minimization to determine the Bayes estimator. 
For a given loss function, L(O, 8), it may also be of interest to assess 
the performance of the Bayes estimator 87r(x). This evaluation can be per-
ceived from a decision-theoretic point of view as the estimation of the loss 
L(8,67r(x)) by ,,((x) under a loss function, like 

150 4. Bayesian Point Estimation 
(4.7) 
Again, the quadratic loss (4.7) is no more justified as an automatic loss in 
this context than in other estimation setups. But, apart from tractability 
reasons, the choice of the quadratic loss can be grounded on a lack of utility 
foundations and thus a closer perception of the error as a variance. Under 
(4.7), the Bayesian evaluation of the performances of {j7r is given by the 
following result. 
Proposition 4.2 The Bayes estimator of the loss L(O, {j7r(x)) under 
(4.7) for the prior distribution 7r is 
This result directly follows from Proposition 2.18, since, conditionally 
on x, the purpose is to estimate a particular function of ° 
under quadratic 
loss. Note that the dependence of this function on x does not matter in a 
Bayesian perspective. Similarly, for the absolute error loss, the Bayes esti-
mator of the loss is the median of the posterior distribution of L(O, {j7r(x)), 
which is usually more difficult to obtain. When L is the quadratic loss, the 
posterior variance, var7r(x), is thus the Bayes estimator of the loss associ-
ated with {j7r. 
In a frequentist perspective, loss estimation has been studied by John-
stone (1988) and Rukhin (1988a,b), the former establishing that, for a mini-
max estimator with constant risk p, the evaluation ')'( x) = p is not necessar-
ily admissible under (4.7). Berger (1984b, 1985b) (see also Lu and Berger, 
1989a, b) develops an additional concept for loss estimation, called frequen-
tist validity: an estimator ')' of the loss L( 0, {j (x)) is said to be frequency 
valid if 
IEo[')'(x)] ~ R(O, {j(x)),O E 8, 
i.e., if, in the long run, this estimator never underestimates the error result-
ing from the use of {j. Such a restriction may seem intuitively appealing, 
but is based on an intuition which was also at the basis of the notion of 
unbiased estimation, and this restriction comes to contradict the Likelihood 
Principle. Robert and Casella (1993a) propose a purely decision-theoretic 
approach of loss estimation in the setup of confidence regions (see Chap-
ter 5). If C (x) is a confidence region for 0, the usual loss underlying the 
estimation process is the '0-1' loss, 
L(C(x), 0) = 1- ][C(x) (0), 
and a loss estimator ')'(x) thus evaluates the coverage rate of C(x), i.e., 
somehow approximates the coverage probability of the confidence region. 
Hwang and Brown (1991) have shown that, for the usual confidence regions 
Co, in the normal setup, the constant estimator 
a = P(O ~ Co(x)) 

4.3. The Particular Case of the Normal Model 151 
is admissible among frequency valid estimators, while inadmissible for p > 5 
without the restriction (see §5.4). 
Example 4.11 
Consider x rv Np(B, a2Ip) and B rv Np(O, T2Ip). Under 
quadratic loss, 
a 2 
87r(x)= 
2 
2
X 
a +T 
a2T2 
and V 7r(x) = 
2 
2 p. 
a +T 
On the contrary, the frequentist approach gives +00 as the maximal risk 
for 87r and is thus ill-adapted to this problem. 
!::,. 
4.3. The Particular Case of the Normal Model 
4.3.1. Introduction 
When Gauss introduced the normal distribution around 1810, Laplace 
thought this was actually the ideal error distribution (see Example 1.8). 
Later, relying on the Central Limit Theorem, statisticians in the first half 
of the nineteenth century were almost always referring to the normal distri-
bution (see Stigler, 1986). There are obviously many phenomena for which 
a normal model is not applicable, but it is still extensively used, in par-
ticular, in Econometrics and in fields where the Central Limit Theorem 
approximation can be justified (Particle Physics, etc.). In fact, the normal 
approximation is often justified for asymptotic reasons (see also Cox and 
Reid, 1987). Therefore, it is of interest to study in detail this particular 
distribution from a Bayesian viewpoint. See, e.g., Maddala (1977) for more 
econometric examples. 
Given one observation from a multivariate normal distribution, Np(B, 
E), with known covariance matrix 17, the conjugate distribution is also 
normal, Np(p" A), and the posterior distribution 1f(Blx) is 
Under quadratic loss, the Bayes estimator is then the posterior mean 
87r(x) = X - 17(17 + A)-l(X - p,) 
= (17-1 + A-lrl (17-lx + A-lp,); 
note that 87r(x) can be written as a convex combination of the observation, 
x, and of the prior mean, p" the weights being proportional to the inverses 
of the covariance matrix. The more accurate the prior information on B is, 
the closer to p, the Bayes estimator is. Note also that the prior information 
(resp., the observation of x) brings a reduction of the variance from 17 
(respectively, A) to (17- 1 + A-I rl. For repeated observations of the above 
normal model, Xl, ... , X n , the sufficient statistic 

152 4. Bayesian Point Estimation 
directly extends the previous analysis. 
A criticism already mentioned in Chapter 3 is that the conjugate nor-
mal prior distributions are not sufficiently robust and that it would be 
preferable to use Student's t-distributions for 7r(8). The Cauchy distribu-
tion, the limiting case of a Student's t-distribution, can then be used because 
of its heavier tails, but it still prohibits exact computation (see Example 
4.5), although Angers (1992) proposes an analytical resolution using con-
fluent hypergeometric functions. 
4.3.2. Estimation of Variance 
In most cases, the variance of the model is partially or totally unknown. It 
is then necessary to consider prior distributions on the parameter (8, E). 
If the variance is known up to a multiplicative constant, (]'2, it is usually 
possible to get back to the unidimensional case, i.e., where Xl, ... , Xn are 
i.i.d. N(8, (]'2), by sufficiency reasons. (The particular case where (]'2 only 
is unknown is treated in Tables 3.2 and 4.2). If we define the statistics 
x = ~ ~~=l Xi and S2 = ~~=l (Xi - X?, the likelihood can be written 
£(8, (]' I x, S2) ex: (]'-n exp [- 2~2 {S2 + n (x - 8)2}] 
and the Bayes estimators only depend on x and s2. We showed in Example 
3.20 that the Jeffreys distribution for this model is 7r*(8, (]') = ;2 and men-
tioned that it is better to consider the alternative ir( 8, (]') = ;;. for invariance 
reasons. In this case, 
Therefore, 
Proposition 4.3 
If Xl,"" Xn are i.i.d. N(8, (]'2), the posterior 
distribution of (8, (]') associated with ir is 
81(]',x,s2 ""N (x, :), 
2 
2 
(n - 1 S2) 
(]' lx,s ""IQ -2-'2 . 
(4.9) 
Equation (4.9) really defines the posterior distribution of (8, (]'2), since 
it provides the marginal distribution of (]'2 and the distribution of 8 condi-
tional on (]'2. The proof of this proposition is a direct consequence of (4.8), 
as 

4.3. The Particular Case of the Normal Model 153 
if(8, 0"21x, 82) ex: 0"-1e-n(x-(l)2 /2a2 0"-ne-s2 /2a2 0"-1, 
and the inverse gamma distribution IQ (a, (3) has the density 
7f(xla,{3) = r(~:O:+1 e-i3/ X I(o,+oo) (x). 
Thus, the marginal posterior distribution of 0"2 is of the same type 
than when 8 is known. On the contrary, the marginal posterior distribution 
of 8 is modified since it follows from (4.9) that 
if(8Ix, s2) ex: {s2 + n(x _ 8)2} -n/2 , 
i.e., 
81x, S2 rv'Ii (n -1, X, n(:~ 1)) . 
(4.10) 
For the Jeffreys distribution, 7f*, the equivalent of (4.10) is a Student's t-
distribution with n degrees of freedom, always defined, while (4.10) is only 
defined for n ;::: 2. (Note that the exclusion of n = 1 could be an additional 
argument in favor of if since, in a noninformative setup, it seems difficult 
to propose an inference about the whole parameter (8,0") with a single 
observation. ) 
Conjugate distributions have the same form as (4.9). They exhibit a 
puzzling peculiarity, namely, that 8 and 0"2 are not a priori independent. 
Therefore, the prior distribution on the mean 8 depends on the precision 
associated with the measure of the mean. Some setups can justify this 
dependence,1 but it cannot hold for every estimation problem, and can 
even less be argued to be a representative standard prior distribution (see 
Berger, 1985a). However, these subjective criticisms are not seconded by 
particularly negative properties of the resulting estimators. Consider then 
7f(8,0"2) = 7fl(810"2)7f2(0"2), 
where 7f1 is a normal distribution N(J1, 0"2/no) and 7f2 is a inverse gamma 
distribution IQ(v /2, s~/2). The posterior distribution satisfies 
7f(8, 0"21x) ex: 0"-n-II-3 exp { -~ [S2 + s~ + no(8 - J1)2 + n(x - 8)2] /0"2 } 
where 
= 0"-n-II-3 exp { -t [sf + n1(8 - (1)2] /0"2}, 
1 
n1 = n + no, 
81 = -
(n080 + nx) , 
n1 
2 
2 
2 (-1 
_1)-1 (8 
-)2 
81 = S + So + no + n 
0 - x 
. 
1 When the prior distribution is built from previous observations, it makes sense 
that the prior variance of () involves 0'2 (conditionally). 

154 4. Bayesian Point Estimation 
These distributions are actually conjugate since 
As in the noninformative case, the marginal posterior distribution of () is 
a Student's t-distribution. Note that, except when 7r is built from previous 
(or virtual) observations, no is not a sample size. Rather, no/n character-
izes the relative precision of the determination of the prior distribution as 
compared with the precision of the observations. In general, no is smaller 
than the sample size n. Note also that, if no/n goes to 0, we get the limit-
ing case ()Ix, (72 '" N(x, (72/n), corresponding to the posterior distribution 
associated with the Jeffreys prior. This fact is yet another illustration of 
the phenomenon that noninformative distributions often occur as limits of 
conjugate distributions. 
Statistical inference based on the above conjugate distribution requires 
a careful determination of the hyperparameters ()o, 
s~, no, 1/, in order to 
express the Bayes estimators. If the determination of ()o and no is rather 
classical, it is usually more difficult to get a prior information on (72. Recall 
that, if (72 '" IQ(I/ /2, sV2), the two first moments are given by 
'II" 
2 
2s~ 
var ((7 ) = (1/ _ 2)2(1/ _ 4)" 
These formulas can then be used to model a prior information into the 
conjugate form, i.e., to determine s~ and 1/. 
When the parameter ((), E) is totally unknown, it is still possible to 
derive conjugate prior distributions. Given n observations XI, ... , Xn of 
Np ( (), E), a sufficient statistic is 
n 
S = ~)Xi - X)(Xi - x)t, 
i=l 
and 
The form of the likelihood function then suggests the following conjugate 
distributions: 
()I17 '" N p (M' ~). 
(4.11) 
17-1 '" Wp(a, W), 
where Wp denotes the Wishart distribution, defined in Exercise 3.18. The 
posterior distributions are then 

4.3. The Particular Case of the Normal Model 155 
with 
WI (X, S)-1 = W-1 + S + ~(X 
- p,)(X _ p,)t. 
n+no 
Note that this multidimensional case is the generalization of the unidi-
mensional case considered above, since the Wishart distribution Wp is the 
generalization in dimension p of chi-squared distributions. Let us recall here 
that the two first moments of E = (~ij) rv Wp (a, W) are 
JE[E] = aW, 
and that the hyperparameters of the prior distribution of E can be derived 
from 
JE[E] = 
W- 1 l' 
a-p-
if E- 1 rv Wp(a, W) and W- 1 = (wij ) (see Eaton, 1982, and Anderson, 
1984). 
In this setup, the Jeffreys distribution is also a limiting case of con-
jugate distributions since Geisser and Cornfield (1963) have shown that it 
is 
J 
1 
7r ((), E) = IEI(p+I)/2' 
therefore corresponding to the limit of the Wishart distribution Wp(a, W) 
on E- 1 when W- 1 goes to 0 and a to O. In fact, the density of E when 
E- 1 rv Wp(a, W) is 
f(Ela, W) ex IEI-(o+P+I)/2 exp { - ~tr(W-l E- 1 ) } 
(see Anderson, 1984). 
4.3.3. Linear Models and g-Priors 
The usual regression model, 
(4.12) 
with E rv Nk(O, E), (3 E IRP, can be analyzed as above if the covariance 
matrix E is known, when working conditionally on X. In fact, a sufficient 
statistic is then ~ = (Xt E-1 X)-1 X t E-1y, the maximum likelihood esti-
mator and the least squares estimator of (3. It is distributed according to a 
Np((3, (xt E- 1 X)-I) distribution. Lindley and Smith (1972) have studied 
conjugate distributions of the type 

156 4. Bayesian Point Estimation 
where 0 E IRq (q ::; p). In this model, the regressor matrix X is considered 
to be constant. In other words, the inference is made conditionally on X. 
(Usually, X is also partially random but this conditioning is justified by the 
Likelihood Principle as long as the distribution of X does not depend on 
the parameters of the regression model.) Therefore, A, C, or 0 can depend 
on X (see below for the example of the g-priors of Zellner, 1971). When 
the stochastic nature of X has to be considered, the usual approach is to 
study a random effects model, 
which can be decomposed as 
with a prior distribution 
yl01 rv Nk(X101, L\), 
01102 rv Np (X202' E2), 
02103 rv Nq(X303, E3)' 
Smith (1973) analyzes this model and shows that 
011y,03 rv Np(O~, D1), 
with 
O~ = D1 [bI 101 + (E2 + X2E3X~)-1 X2X303] , 
DI1 = DI1 + (E2 + X2E3X~)-1, 
involving the classical least squares estimators 
D
A -1 _ Xt D-1x 
1 
-
2':'1 
2, 
A 
A 
t-1 
01 = D1X2E1 y. 
Therefore, the Bayes estimator 0i is a convex combination of the least 
square estimator, 01, and of the prior mean, X 2X 303 . 
We introduce below an example where an unknown variance structure 
still allows for closed-form derivation of the Bayes estimators. However, if 
the variance E is totally unknown, it is not possible to derive conjugate 
prior distributions, as noticed by Lindley and Smith (1972). Press (1989) 
proposes a resolution in a particular case where independent observations 
are available for every component of {3. In the general case, the Jeffreys 
prior is again (see Geisser and Cornfield, 1963) 
1 
7r({3, E) = IEI(k+1)/2' 
The likelihood 

4.3. The Particular Case of the Normal Model 157 
then suggests the use of Wishart distributions, but the posterior marginal 
distributions on (3 are only defined for sufficiently large sample sizes and, 
moreover, are not explicit, whatever the sample size (see Exercise 4.32). 
In the particular case where the variance of the model (4.12) is known 
up to a multiplicative factor u2 , it is possible to rewrite the model as E rv 
Nk(O, u2 h) and the least squares estimator S has a normal distribution 
Np((3,u2(XtX)-1). A family of conjugate distributions on ((3,u2) is then 
(3lu2 rv Np (JL' ~: (xt X)-l) , 
(4.13) 
Indeed, 
7r((3, u21S, 82) <X (u2)-k/2 exp [- 2~2 {((3 - S)t xt X((3 - S) + 82}] 
x exp (- no ((3 - JL)t xt X((3 - JL)) (u2)-V/2-1 exp (_ 8~ ) 
2u2 
2u2 
<X (u2)-p/2 exp {_ no + 1 ((3 _ noJL + S) t xt X ((3 _ noJL + S) } 
2u2 
no + 1 
no + 1 
xu-(k-p+v+2) exp [ __ 1_ {82 + 82 + ~(JL - S)txtX(JL - S)}] . 
2u2 
0 
no + 1 
Although (4.13) is only a particular case of conjugate distribution, many 
criticisms have been raised about this choice, developed by Zellner (1971, 
1986b) under the name of g-prior8. These criticisms do not usually address 
the problem of the reducing aspect of conjugate modeling, a quite legitimate 
argument already mentioned in Chapter 3, but rather the dependency of 
the prior distribution on X. It can be argued that X is also a random 
variable and therefore that an a priori modeling should not depend on X. 
In fact, the alternative prior distributions 

158 4. Bayesian Point Estimation 
also constitute a conjugate family which is less arguable if A is fixed. How-
ever, we consider that the debate is rather vacuous since: 
(1) The whole regression model is conditional on the explanatory vari-
ables. The prior distribution (4.13) can then be perceived as a poste-
rior distribution with respect to these variables (or to extend the usual 
hypothesis of independence between the explanatory variables and the 
errors to the hypothesis of Bayesian independence with the parame-
ters). This approach is thus quite justified from both the conditional 
and Bayesian points of view, the conditioning being operated in two 
steps. 
(2) The g-prior distribution suggests a constant distribution on the mean 
of y, () = lEe[YIX], rather than on {3. The prior distribution is then 
determined with respect to the subspace spanned by the columns of 
X, not with respect to a special basis of this subspace. 
(3) This modeling is adapted to take into account the problems of multi-
collinearity, since it allows for a large prior variance on the components 
affected by multicollinearity (hence the most difficult to estimate). (See 
Zellner, 1971, Casella, 1985b, Steward, 1987, or Robert, 1988, for ref-
erences on multicollinearity.) 
(4) From the practical and subjective viewpoints, the determination of a 
matrix A instead of a scalar no requires a larger amount of prior in-
formation. Since the use of conjugate distributions indicates a setting 
where the prior information is sparse and where the derivation of hy-
perparameters is quite difficult, the resort to the covariance matrix 
a 2(Xt X)-l Ino prevents a possibly unrealistic determination of A. 
Again, note that these attacks on g-priors hardly ever consider its major 
drawback, namely, that its choice is not based on prior information. For ap-
plications of g-priors in regression setups, see Ghosh et al. (1989), Blattberg 
and George (1991), and Robert and Saleh (1991). 
4.3.4. Ranking and Selection 
A great deal of effort has been dedicated to the problem of estimating and 
comparing several normal means. We mention briefly a few approaches here 
to illustrate the interest of the Bayes treatment, referring the reader to the 
literature for a more developed discussion. See, for instance, Gibbons et al. 
(1977), Gupta and Panchapakasan (1979), and Dudewicz and Koo (1982), 
following the introductory papers of Bechhofer (1954) and Gupta (1965). 
As noted by Berger and Deely (1988), ranking and selection techniques also 
appear as substitutes for the analysis of variance methodology. 
Given Xl rv N((}l, a~), ... , Xk rv N((}k, a~), the problem is to select 
the population with the highest mean, (}[k]. The variances a~, ... ,a~ are 
supposed to be known but the more general setup where they are estimated 
by a~, ... ,a~ can be treated similarly by the Bayesian paradigm. Berger 

4.3. The Particular Case of the Normal Model 159 
and Deely (1988) rewrite the problem to answer the following questions: 
(a) Can we accept the hypothesis Ho : 01 = ... = Ok? (b) In the event 
of a negative answer to (a), what is the largest mean? They solve the first 
question by computing the Bayes factor against Ho and then the posterior 
probabilities Pj that OJ is the largest mean (1 ~ j ~ k). (Chapter 5 covers 
definition and computation of these quantities.) The prior distributions they 
use are hierarchical 
The special form of the prior distribution on 0"; is necessary to test whether 
the Oi's are actually identical. For 7r22' Berger and Deely (1988) suggest the 
informative choice 
where C and m can be derived from prior quantiles. For a noninformative 
choice, possibilities are 7r22 (0";) = 1 and 
k 
7r;2(0";) = II (0"; + 0";)-1/k, 
i=1 
although these priors may lead to difficulties in the derivation of the pos-
terior probability of Ho (see Chapter 5). 
Goel and Rubin (1977) adopt a more decision-theoretic perspective, 
considering as decision space V the set of all nonempty parts of {I, ... ,k}, 
denoted {SI' S2, ... , S K } where K = 2k -1. They introduce the loss function 
where lsi denotes the cardinality of s and Os = maxjEs OJ. This loss includes 
a penalization cost c for each population involved in the decision set s. This 
is quite logical since a parsimony requirement forces the decision set s to be 
as small as possible, the ideal setting being lsi = 1. Goel and Rubin (1977) 
first show that a Bayes rule associated with this loss and a symmetric 
prior distribution has to be chosen among the sets sj = {Wk, ... ,Wk-j+l} 
(1 ~ j ~ k), where Wj denotes the population of x(j). The Bayes rule s1r is 
then a solution of 
p(7r, s1r lx) = . min p(7r, sjlx), 
J=I, ... ,k 
where p(7r, six) = clsl + IE1r[O[kJ - Os Ix]. Introducing 
(1 ~ m ~ k - 1), 
the Bayes rule is sk if A = {j; Llj 2: O} is empty and s:n otherwise, where 
m = min(A). A difficult point in the derivation of s1r is obviously the 
computation of the posterior expectations IE1r [O[k]-O s Ix]. The authors detail 

160 4. Bayesian Point Estimation 
the particular case of a normal exchangeable prior on the ej's, which still 
depends on the function 
1
+00 
tm(z)= 
-00 <l>m(z+x)<l>(-x)dx. 
Nonetheless, they show that, in the noninformative case, when 0"1 = ... = 
O"k, the Bayes rule is si when C/O"l ;::: 1/1[2. 
4.4. Sampling Models 
In this section, we consider three sampling problems in which a Bayesian 
approach is easily implement able. Note that, in general, discrete models 
require less prior information to build up a prior distribution. The first 
problem we consider is related to the Laplace succession rule and was in-
troduced in 1774 by Laplace. The second problem was studied under the 
name of the tramcar problem by Neyman in the 1930s. The last section stud-
ies the capture-recapture models, which are of interest in animal biology and 
other population estimation modelings. The three problems have in com-
mon that they involve an inference on a finite population or subpopulation. 
These are cases where some prior information is usually available or where 
the choice of a noninformative prior can be made rather unambiguously. 
4.4.1. Laplace Succession Rule 
Consider a population of known size N divided into two subpopulations, of 
respective sizes N1 and N2 = N - N 1, which are unknown. When sampling 
without replacement x individuals from this population, Xl individuals be-
long to the first subpopulation and X2 = x -
Xl to the second. When no 
information is available on N 1 , a noninformative distribution is 
and the corresponding posterior distribution of N1 is (Xl::::; N1 ::::; N - (x-
xd) 
Let E be the event that the next draw will give an individual from the first 
subpopulation, p being the probability of E. Then 
N1 -
Xl 
P(EIN1,xd = N -
X 
• 
Therefore. 

4.4. Sampling Models 161 
(Nl) (N-Nl) 
P(E N I ) = NI -
Xl 
Xl 
X-Xl 
, 
I Xl 
N _ X 
(N+I) 
x+l 
( Nl ) (N-Nl) 
Xl + 1 xl+I 
X-Xl 
N -
X 
(N+I) 
x+l 
and 
(N+I) 
= P(EI ) = Xl + 1 ~ 
= Xl + 1 
P 
Xl 
N-X(N+I) 
x+2' 
x+l 
which does not depend on N. Therefore, the predictive distribution of the 
outcome ofthe (x+ l)th draw is a Bernoulli distribution, 13(1, (Xl + 1)/(x+ 
2)). Laplace considered the special case X = Xl and derived his succession 
rule: If n first draws all give an outcome from the same subpopulation, the 
probability that the next draw will also give an outcome from this population 
is ~t~. A consequence of the Laplace succession rule is that the probability 
that the whole population is of the same kind as the n first observations 
is ~t~. Some criticized this succession rule as being biased in favor of the 
most common subpopulation, since rare populations will not be detected 
(see also Popper, 1983). On the contrary, Jeffreys (1961, §3.22) maintains 
that, in Physics at least, this rule leads quite often to rejection of the 
proposed distributions. 
4.4.2. The Tramcar Problem 
Jeffreys (1961, p. 238) mentions the following problem, attributed to Ney-
man. "A man traveling in a foreign country has to change train at a junc-
tion, and goes into the town, the existence of which he has only just heard. 
He has no idea of its size. The first thing that he sees is a tramcar numbered 
100. What can he infer about the number of tramcars in the town? It may be 
assumed that they are numbered consecutively from 1 upwards." This prob-
lem has obviously less anecdotal applications. For instance, it is related to 
many coincidence problems as described in Diaconis and Mosteller (1989). 
Example 4.12 Consider a cyclic phenomenon with unknown period T (stock 
market crises, comet occurrences, animal mutations, traffic lights, etc.) and 
the observation that, at times iI and t2, the phenomenon is in the same 
state. The inferential problem is to derive T from the observation of the 
difference t2 - iI. 
6 
In the particular case of the tramcar problem, the total number N 
can take the values 1,2, .... Instead of a uniform distribution on ]N*, it is 
preferable to consider the following noninformative distribution: 
1 
7r(N) = N' 

162 4. Bayesian Point Estimation 
since N is somewhat a scale parameter. Moreover, the uniform prior does 
not lead to a defined posterior distribution. If T is the observed tramcar 
number, it is distributed as 
Therefore, 
and 
1 
f(tIN) = P(T = tiN) = N 
(t = 1,2, ... ,N). 
",+00 1/n2 
r+00(1/x2)dx 
T 
P"'(N > niT) = L.m=no 
~ Jno 
= -. 
-
0 
L~:T 1/n2 
J;00(1/x2)dx 
no 
In this case, the posterior median is approximately N"'(T) = 2T, which is 
the estimator usually considered in the tramcar problem. In fact, note that 
the mean of T conditionally on N is N 21 ~ ~. 
4.4.3. Capture-Recapture Models 
When working with an hypergeometric distribution 1i(N, n,p), the parame-
ter p is most often the parameter of interest but it may also occur that the 
population size, N, is unknown and has to be estimated. More generally, 
in cases where a census of a population is impossible (or too costly), it is 
necessary to provide estimation methods for its size. 
Example 4.13 An herd of deer is living on an island of Nova-Scotia which 
is isolated from any predator. To prevent the deer from endangering the 
ecological equilibrium of the island, it is necessary to keep the number of 
deer under 40 by culling. An annual census of all deer is however too time-
consuming. 
!::::,. 
We could mention many examples in biology, sociology, psychology, 
meteorology, ecology, etc., where an evaluation of a population size is nec-
essary. The usual approach is called capture-recapture, because it relies on 
taking at least two successive samples from the population of interest and 
was first implemented in animal biology, where individuals were actually 
captured. See Seber (1983, 1986) and Pollock (1991) for a survey. 
We use, in this section, the general framework of Wolter (1986), who 
shows that most capture-recapture models can be described by a multino-
mial distribution for each individual i in the population (1 ::; i ::; N). The 
following table describes the probability of capture: 
Sample 1 
Sample 2 
captured 
missed 
captured missed 
Pi1 
Pi2 
P~l 
P~2 

4.4. Sampling Models 163 
withPil +pi2+P~1 +P~2 = 1. For instance, Pi2 represents the probability of 
being captured only in the first sample. After the two capture experiments, 
the population is divided in 
Sample 1 
Sample 2 
captured 
missed 
captured missed 
with nu +n12 +n21 +n22 = N (the fourth sample size n22 being unknown). 
For the simplest model, called uniform, each individual has the same prob-
ability P of being captured in both experiments. Therefore, pu = p2, 
P12 = P21 = p(l - p), and P22 = (1 - p)2. The likelihood can be writ-
ten as 
where n. = 2nu + n12 + n21 is the total number of captured individuals 
and 
is the multinomial coefficient. For n(N,p) = n(N)n(p) with n(p) a beta 
distribution Be(a, (3), the conditional posterior distribution on p is 
n(plN n 
n 
n 
) ex pQ+n.-1(1 _ p)i3+2N- n.-1 
, 
U, 12, 
21 
, 
i.e., 
piN, n. '" Be(a + n., (3 + 2N - n.). 
Unfortunately, the marginal posterior distribution of N is quite compli-
cated. For instance, if n(N) = 1, it satisfies 
(NI) 
( N) B(a+n.,(3+2N -n.) 
n 
n. ex 
n+ 
B(a, (3) 
, 
(4.14) 
where n+ = nu + n12 + n21 is the number of different captured individuals. 
This distribution is sometimes called a beta-Pascal distribution (see Raiffa 
and Schlaifer, 1961), but it is untractable. The same complexity occurs if 
n(N) = liN as in Castledine (1981) or if n(N) is a Poisson distribution 
P()..) as in Raftery (1988), George and Robert (1992), and Dupuis (1993). 
Obviously, N being an integer random variable, it is always possible to 
approximate the normalizing factor in (4.14) by summing out on N. But, 
apart from the required computing time, the approximation errors can be-
come important when Nand n+ are large. Note that, for the Poisson prior, 

164 4. Bayesian Point Estimation 
therefore the conditional posterior distributions are available (Chapter 9 
makes use of this property). Extensions of the uniform model are described 
in Wolter (1986) and George and Robert (1992). 
A simpler model used in capture-recapture settings is the hypergeo-
metric model, also called the Darroch model (Darroch, 1958), in which the 
two sample sizes nl = nu + n12 and n2 = nu + n2l are fixed. In this case, 
the above description does not apply and the only remaining random vari-
able is nu, with distribution 1i(N, n2, 11)' In fact, in practice, the values 
nl and n2 are not fixed in advance but rather determined by a stopping 
rule which is generally unknown. However, if the prior distribution on N 
is noninformative and with a countable support, the computation of the 
Bayes estimators is of the same order of complexity. But, since the Darroch 
model can be written as a particular case of the Wolter model (see Exercise 
4.49), it is then possible to extend the approximation techniques developed 
for Wolter's modeling to this setup (see Chapter 9). 
For the Darroch model, the classical estimator of N is the maximum 
likelihood estimator 
A 
nl 
N = (nU/n2) ' 
which identifies the proportion in the population (nl / N) and the proportion 
in the sample (nu/n2)' This estimator presents an important drawback: 
it cannot be used when nu = O. This situation would call for a third 
draw of n3 individuals, and the observation of nUl individuals common 
with the first or the second sample. Since the number of tagged individuals 
increases with the number of samples, the probability of observing only new 
individuals at each draw decreases. It is nonetheless unreasonable to call for 
additional sampling when the initial objective of the statistical modeling 
was to reduce sampling costs. 
A Bayesian analysis does not suffer from this defect, as it reaches a 
conclusion even when nu = O. Given a prior distribution 7f on N, it is 
formally easy to derive the posterior 7f(N = nlnu) and draw an inference 
on N. 
Example 4.13 (Cont.) Birth and death patterns for the deer imply that 
the number of deer varies between 36 and 50. A more thorough biological 
study of the deer life expectation could certainly help to refine the prior 
modeling on N but we will use here a uniform distribution on {36, ... , 50}. 
Considering nl = n2 = 5, the Bayes formula, 
leads to Table 4.2, which provides the posterior distribution of N. 
6 
Since the complete posterior distribution of N is available, we can 
derive the posterior mean, median, or mode of N (or any other Bayes 

4.4. Sampling Models 165 
estimator). Table 4.3 gives the posterior means for different values of nn 
(to be compared with the classical estimator 25/nn for nn =f. 0). 
6. 
TABLE 4.2. Posterior distribution of the deer population size, 7l'(Nlnll). 
nll 
0 
1 
N 
2 
3 
4 
5 
36 
0.058 0.072 0.089 0.106 0.125 0.144 
37 
0.059 0.072 0.085 0.098 0.111 0.124 
38 
0.061 0.071 0.081 0.090 0.100 0.108 
39 
0.062 0.070 0.077 0.084 0.089 0.094 
40 
0.063 0.069 0.074 0.078 0.081 0.082 
41 
0.065 0.068 0.071 0.072 0.073 0.072 
42 
0.066 0.068 0.067 0.067 0.066 0.064 
43 
0.067 0.067 0.065 0.063 0.060 0.056 
44 
0.068 0.066 0.062 0.059 0.054 0.050 
45 
0.069 0.065 0.060 0.055 0.050 0.044 
46 
0.070 0.064 0.058 0.051 0.045 0.040 
47 
0.071 0.063 0.056 0.048 0.041 0.035 
48 
0.072 0.063 0.054 0.045 0.038 0.032 
49 
0.073 0.062 0.052 0.043 0.035 0.028 
50 
0.074 0.061 0.050 0.040 0.032 0.026 
TABLE 4.3. Posterior mean of N. 
nll 
0 
1 
2 
3 
4 
5 
lE(Nlnll) 43.32 42.77 42.23 41.71 41.23 40.78 
If, instead of the squared error, we use the following loss: 
L(N, 8) = { 10(8 - N) 
if 8> !'!, 
N - 8 
otherwIse , 
in order to avoid an overestimation of the number of deer (this would be 
more dramatic for the future of the herd), the Bayes estimator is the (1/11)-
quantile of 7r(Nlnn), given in Table 4.4 for different values of nn. 
6. 
TABLE 4.4. Estimators of N under asymmetric loss. 
nll 
0 
1 
2 
3 
4 
5 
611' (nll) 
37 
37 
37 
36 
36 
36 

166 4. Bayesian Point Estimation 
A very interesting Bayesian application of capture-recapture inference 
is given by Mosteller and Wallace (1984). It deals with author identification 
by statistical linguistics when the origin of some literary work is uncertain. 
For instance, Mosteller and Wallace (1984) study the federalist papers, a col-
lection of declarations written in 1787 in order to support the new American 
constitution. Twelve of these essays can be attributed to either Hamilton 
or to Madison. Using authenticated writings of the two authors, Mosteller 
and Wallace derive the frequencies of thirty current words and deduce from 
a capture-recapture approach that the twelve essays should be attributed 
to Madison. Efron and Thisted (1976) have also used capture-recapture 
to study Shakespeare's vocabulary and later identify in Thisted and Efron 
(1987) a recently discovered poem as being written by Shakespeare. 
Exercises 
Section 4.1 
4.1 (Smith, 1988) Consider x, a random variable with mean J.L, c.d.f. F, and 
density f. The two functions f and l' are supposed to be bounded. Define 
a sequence of random variables Yn with c.dJ. 's 
Gn(y) = (1 - ~) F(y) + ~Hn(Y)' 
satisfying 
(i) IEHn [y] = n2 j and 
(ii) H~ = hn and h~ are bounded. 
Show that Gn -> F, G~ = gn -> f, and g~ -> 1', but that 1J.L-IE[Yn]l-> 00. 
4.2 If "p(9Ix) is a posterior distribution associated with f(xI9) and a (possibly 
improper) prior distribution 71", show that 
"p(8Ix) 
f(xI8) = k(x)7I"(8). 
a. Deduce that, if f belongs to an exponential family, the posterior distri-
bution also belongs to an exponential family, whatever 71" is. 
b. Show that if"p belongs to an exponential family, the same holds for f. 
4.3* (Berger and Wolpert, 1988) In the following setup, Stein (1962b) points 
out some limitations of the Likelihood Principle. Assume that a value 8 > 0 
can be assessed either by x f'V N(O, 0'2) (with known 0'2) or by 
-1 {d2 ( 
O)2} 
Y f'V f(YI8) = cy 
exp -2" 1- Y 
I[o,b9] (y), 
where b is huge and d large (50, say). 
a. Show that the two maximum likelihood estimators of 8 are 81(X) = x 
and 82(Y) = y. 
b. Consider the special case x = y = ad. Explain why the inference on 8 
should be the same in both cases. 

Exercises 167 
c. Explain why 
[x - (1.96)0", X + (1.96)0"] 
could be proposed as a confidence interval on 0 at the level 95%. 
d. Deduce that 
[y - (1.96)(y/d), Y + (1.96)(y/d)] 
can be used as a confidence interval if y is observed. 
e. Show that 
P(y - (1.96)(y/d) < 0 < y + (1.96)(y/d)) 
can be made as small as wished for an adequate choice of b. 
f. Conclude that the above confidence interval is not appropriate for large 
values of x = y and 0" and discuss the relevance of a confidence interval 
for the Likelihood Principle. 
g. Study the problem with the prior distribution 7r(O) = I/O. 
4.4 Show that, if P E [0,1]' 0 = p/(I-p) and if 7r(O) = I/O, the prior distribution 
7r(p) is Haldane distribution. 
4.5 Show that a setting opposite to Example 4.2 may happen, namely, a case 
when the prior information is negligible. (Hint: Consider 7r(O) to be C(f-t, 1) 
and f(xIO) ex exp -Ix - 01, and show that the maximum Bayesian likelihood 
estimator does not depend on f-t.) 
4.6 In the setup of Example 4.2, consider 7r(O) ex exp -alOI and show that, for 
a small enough, the maximum Bayesian likelihood estimator is not always 
equal to O. 
4.7 A contingency table is a k x £ matrix such that the (i, j)th element is nij, 
the number of simultaneous occurences of the ith modality of a first charac-
teristic, and of the jth modality of a second characteristic in a population 
of n individuals (1 ::; i ::; k, 1 ::; j ::; g). The probability of this occurence is 
denoted by Pij. 
a. Show that these distributions belong to an exponential family. 
b. Determine the distributions of the margins of the table, i.e., of ni. 
nil + '" + nil and n.j = nlj + ... + nkj. Deduce the distributions of 
(nh." ,nk.) and of (n.l, ... , n.t). 
c. Derive conjugate priors on P = (Pij) and the Jeffreys prior. 
d. In the particular case of independence between the two variables, the 
parameters are supposed to satisfy the relations Pij = Pi.Poi where 
(Ph'" ,Pk') (P·l, ... ,p.t) are two vectors of probabilities. Relate these 
vectors to the distributions derived in b. and construct the corresponding 
conjugate priors. 
e. Compare the posterior expectations of Pij for the conjugate priors of c. 
and d. (Note: See Santner and Duffy (1990) for a detailed presentation 
of the Bayesian processing of these models.) 
4.8 Determine whether the following distributions are possible posterior distri-
butions: 
(i) Ti(k, f-t(x) , T2(x)) when x ",N(O, 0"2) and 0"2 is known; 
(ii) a truncated normal distribution N(f-t(x) , T2(X)) when x '" P(O); and 
(iii) Pa(a(x), f-t(x)) when x '" B(n, I/O). 
4.9* (Cont.) Given a sample distribution f(xIO) and a conditional distribution 
g(Olx), give a necessary and sufficient condition for g(Olx) to be a posterior 
distribution associated with f(xIO) and an arbitrary prior distribution 7r(O). 

168 4. Bayesian Point Estimation 
4.10 Let (Xn) be a Markov chain with finite state space {I, ... ,p} and transition 
matrix P. 
a. If the sample is Xl, ... , X n , express the likelihood function and derive 
conjugate priors for the components of P. 
b. The Markov chain is now observed at random times t1 < ... < tn. Give 
the likelihood function £( PIXtl , ... , Xt n ) when the distribution of the ti'S 
does not depend on P and examine whether the above prior distributions 
are still manageable for posterior computations. 
c. A random variable Yt is observed for t = 1, ... ,n with conditional dis-
tribution f(YI8 xt ). We assume the Yt'S to be independent conditional on 
the Xt's. Show that the marginal distribution of the Yt'S is a mixture of 
the distributions f(YI8k). 
d. If only the Yt'S are observed, the model is called a hidden Markov chain. 
When f(YI8) belongs to an exponential family, give the likelihood func-. 
tion and the conjugate priors on (P, 81 , ... , 8p ). 
e. Consider the special case p = 2 and f(YI8) = 8exp(-8y)IIR+(Y) to 
examine whether the above priors are manageable. 
4.11 Consider X ~ B(m,p) and p ~ Be(I/2, 1/2). 
a. Show that this prior is equivalent to an uniform prior on 8 = arc sin( y'P). 
How can you justify this transformation? (Note: See Feller (1970) for 
details on the arcsine distribution.) 
b. Let Y ~ B(n, q) an independent observation with q ~ Be(I/2, 1/2). Use 
the approximation arcsinx ~ N(8, 1/4m) to give an approximate pos-
terior distribution of arc sin( y'P) - arc sin( y'q). 
c. Deduce an approximation of 
7l'(larcsin(y'P) - arc sin(y'q) I < O.llx,y). 
4.12 The logistic distribution is defined by the density 
e-(x-8) /1 + e-(x-8) 
on JR. 
a. Show that the above function is truly a density and derive the maximum 
likelihood estimator of 8. 
b. Show that this distribution does not belong to an exponential family (i) 
directly; and (ii) using Exercise 3.17. Deduce that there is no associated 
conjugate prior and propose a noninformative prior. 
c. What is the maximum likelihood estimator of 8 for a sample Xl, ... , xn? 
Show through an example that the likelihood can be multimodal. 
d. Relate logistic regression and logistic distribution by exhibiting latent 
logistic random variables in the logistic regression model. Is there a con-
tradiction between b. and the fact that the logistic regression model 
belongs to an exponential family, as shown in Example 3.14? 
Section 4.2 
4.13 (Smith, 1988) A usual justification of quadratic losses is that they provide 
a second-order approximation for symmetric losses. Consider the loss 

Exercises 169 
and 7r(l:Ilx) = (1/2){cp(l:I; 8,1) + cp(l:I; -8, I)}, a mixture of two normal dis-
tributions with means 8 and -8, and variance 1. 
a. Show that 7r(l:Ilx) can actually be obtained as a posterior distribution. 
b. Show that JE7r[l:Ilx] is a local maximum of the posterior loss. 
c. Relate the loss L(I:I, 8) with the intrinsic losses of §2.5.4. 
4.14 Consider x ~ P(>..) and 7r(>..) = e-"'. The purpose of the exercise is to 
compare the estimators 8c(x) = ex under the quadratic loss L(>..,8) = (8-
>..? 
a. Compute R(8c , >..) and show that 8c is not admissible for e> 1. 
b. Compute r( 7r, 8c ) and deduce the optimal e7r. 
c. Derive the best estimator 8c for the minimax criterion. 
d. Solve the above questions for the loss 
L' (>", 1:1) = (~ _ 1) 2 
4.15 Show that a Bayes estimator associated with a quadratic loss and a proper 
prior distribution cannot be unbiased. Does this result hold for generalized 
Bayes estimators? for other losses? 
4.16 Consider x ~ B(n,p) and p ~ Be(a, (3). 
a. Derive the posterior and marginal distributions. Deduce the Bayes esti-
mator under quadratic loss. 
b. If the prior distribution is 7r(p) = [P(1 - p) r1 1(0,1) (p), give the general-
ized Bayes estimator of p (when it is defined). 
c. Under which condition on (a, (3) is 87r unbiased? Is there a contradiction 
with Exercise 4.15? 
d. Give the Bayes estimator of p under the loss 
L(p 8) = (8 - p)2 
, 
p(1- p) 
4.17 Using the estimators in Table 4.1, show that the estimators corresponding 
to noninformative prior distributions can be written as limits of conjugate 
estimators. Does this convergence extend to other posterior quantities for 
the same sequence of conjugate hyperparameters? Try to derive a general 
result. 
4.18 Consider x ~ N(I:I, 1), 1:1 ~ N(O, 1), and L(I:I, 8) = I{b<e}. Show that, in this 
case, there is no Bayes estimator. 
4.19 Consider x ~ P(I:I), with e = {1:I1 ,1:I2 } and 1) = {d1,d2,d3 }. The loss 
function is defined by the matrix 
( 0 
20 
10) 
L = 
50 
0 
20 
(where Lij = L(l:Ii, dj), i = 1,2, j = 1,2,3). Show that the Bayes estimators 
are of the form 
if x < k - 10g2 3, 
if x> k -1, 
otherwise, 
and define k in terms of the prior distribution 7r. 

170 4. Bayesian Point Estimation 
4.20 (Ferguson, 1967) Consider x from the renormalized negative binomial dis-
tribution, 
f(xI9) = (r +: -1) 9"'(1 + 
9)-(r+"'), 
x = 0,1, ... , 
9 E IR:t-, 
so that IE9[XJ = r9 (i.e., 9 = p/(l - p)). The loss function is the weighted 
squared error 
(9 - 8)2 
L(9,8) = 9(1 + 9) 
a. Give the maximum likelihood estimator of 9. 
b. Show that 80(x) = x/r has a constant risk and is a generalized Bayes 
estimator for 7r(9) = 1 if r > 1. What happens for r = I? 
c. Show that 
8 
Q+x-1 
a,/3(x) = .B+r+1 
is a Bayes estimator for 
and that this distribution is conjugate for f(xI9). 
d. Deduce that 81(x) = x/(r + 1) is a minimax estimator. 
4.21 (Ferguson,1967) Consider e = [0, 1J and L(9, 8) = (91~6/ ,for the geometric 
distribution 
f(xI9) = 9"'(1- 9) 
(x E IN). 
a. Give a power series representation of R(9, 8) . 
b. Show that the unique nonmndomized estimator with constant risk is 80 
such that 
80 (0) = 1/2, 
80(x) = 1 if x ~ 1. 
c. Show that, if 87r is the Bayes estimator associated with 7r, 87r (n) 
/-tn-I! /-tn, where /-ti is the ith moment of 7r. 
d. Show that 80 is minimax. 
4.22* (Casella and Strawderman, 1981) Consider x '" N(9, 1) with 191 :::; m 
(m < 1). 
a. Show that 8m (x) = m tanh(mx) is a Bayes estimator associated with 
b. Show that, for the quadratic loss, r( 7rm , 8m ) = R( 8m , ±m) and deduce 
that 8m is minimax. (Note: This is actually the unique minimax estima-
tor in this case.) 
c. Compare with the estimator 8u associated with the uniform prior 
1 
7r( 9) = 2m I[ -m,m} (9), 
in terms of m. (Note: Gatsonis et al. (1987) give a detailed study of the 
performance of 8u in term of minimaxity.) 
4.23 (Casella and Berger, 1990) Consider x '" U{1,2, ... ,9} and 9 E e = IN*. 

Exercises 171 
a. If D = e, show that, under quadratic loss, ]E7I"[9Ix) is not necessarily the 
Bayes estimator. 
b. If D = [1, +00), show that ]E7I"[9Ix) is the Bayes estimator (when it 
exists). 
c. Show that 80 (x) = x is admissible, for every choice of D. (Hint: Start 
with R(1,80).) 
d. Show that 80 is a Bayes estimator and that there exist other Bayes 
estimators for this prior distribution with different risk functions. 
4.24 Consider xl, X2 LLd. with distribution f(xI9) = (1/2) exp( -Ix - (1) and 
7r( 9) = 1. Determine the Bayes estimators associated with the quadratic and 
absolute error losses. Same question for an additional observation. (Note: 
See Example 1.8 for an historical motivation.) 
Section 4.3.1 
4.25* (Robert, 1990a) The modified Bessel function Iv (II :2: 0) is a solution to the 
differential equation Z2!" + zf' - (Z2 + 112)f(z) = 0 and can be represented 
by the power series 
( Z)V 00 
(Z/2)2k 
Iv(z) = 2 l: k! r(1I + k + 1)" 
k=O 
a. Show that the above series converges in JR. 
b. Developing 
171" eZ cos(9) sin2v (9) d9 
in a power series, show that I v can be written as 
I ( ) = 
(z/2t 
171" zcos(9) . 2V(9) d9 
(4.15) 
vZ 
7r1/2r(II+~)oe 
sm 
. 
c. Establish the following recurrence formulas: 
d. Derive from (4.15) by an integration by parts that, for Z > 0, 
e. Derive from the power series representation of Iv that C
V Iv(t) is in-
creasing in t. If we define Tv as 
(t) = IV+1 (t) 
Tv 
Iv(t) , 
show that Tv is increasing, concave, and that Tv(t)/t is decreasing. 
f. Show that 
lim Tv(t) = 1, 
t-+oo 
lim Tv(t) = 
1 
, 
hoo 
t 
2(11 + 1) 
and that 
I 
211 + 1 
2 
Tv(t) = 1 - -t 
-Tv(t) - T.,(t). 

172 4. Bayesian Point Estimation 
g. Show that the density of the noncentral chi-squared distribution with 
noncentrality parameter A and v degrees of freedom can be expressed 
using a modified Bessel function, namely, 
4.26* (Bock and Robert, 1991) On IRP, the sphere of radius e is defined by 
a. If x rv Np((), Ip), with p :::: 3, and () has the prior distribution 1I"e, uniform 
distribution on Se, show that the marginal density of x is proportional 
to 
b. Show that the proportionality coefficient is independent of e and recall 
why it does not appear in the posterior distribution. 
c. Derive from a. the posterior mean 6e by a differential computation. 
d. Show that, if e :::: "jP, 6e is a shrinkage estimator outside the ball 
{x; Ilxll ~ p} and an expander within this ball. Determine the boundary 
value p. 
e. Show that 6e cannot be minimax. Is this estimator admissible? 
f. Explain why 6e never belongs to the sphere Se while 11" e is concentrated 
on Se. Is 6e the "true" Bayes estimator then? 
g. Using the recurrence relations of Exercise 4.25, show that 
( 
p- 2) 
2 
6e(x) = 1- W 
x + he(llxll )x, 
where he(t) > 0 when t ~ max(e2 ,p-2). Try to propose a more appealing 
estimator. 
4.27 Consider Xl, ... ,XlO Li.d. N((), ()2), with () > 0, which represents ten obser-
vations of the speed of a star. Justify the choice 11"(()) = 1/() and determine 
the generalized Bayes estimator associated with the invariant loss 
(Hint: Use Exercise 3.29.) 
4.28 (Lindley, 1965) Consider Xl, ... , Xn a sample from N((), 0"2) with 0"2 known. 
The prior density 11"( ()) is such that there exist E, M, and c such that C(1-E) ~ 
11"(()) ~ c(l + E) for () E I = [x - 1.960"1 yn, x + 1.96 0"/ Vnl and 7r(O) ~ Me 
otherwise. 
a. Show that these constraints are compatible, i.e., that there exists such 
a prior distribution. 
b. Show that 

Exercises 173 
ifOEland 
otherwise. 
c. Discuss the interest of the approximations when 0 E I and when 0 'f- I. 
Can you derive a conservative confidence region? 
4.29 Consider a normal random variable, x rv N(O, 1) and the one-to-one trans-
form T] = sinh(O). 
a. When 7r(T]) = 1, show that the resulting posterior distribution on 0 is 
7r(Olx) = eX N(x + 1,1) + e-x N(x - 1,1). 
b. Compare the behavior of this posterior distribution with the usual Jef-
freys posterior N(x, 1) in term of posterior variance, posterior quantiles 
and modes. In particular, determine the values of x for which the pos-
terior distribution· is bimodal and those for which there are two global 
maxima. 
c. Consider the behavior of 7r(Olx) for large values of x and conclude that 
the prior 7r(T]) = 1 is unreasonable. 
Section 4.3.2 
4.30 (Jeffreys, 1961) Consider Xl, ... , X n1 LLd. N(O, a2 ). Let Xl, s~ be the as-
sociated statistics. For a second sample of observations, give the predictive 
distribution of (X2'S~) under the noninformative distribution 7r(O,a) = ~. 
If s~ = sfly and y = eZ , deduce that z follows a Fisher's F distribution. 
Section 4.3.3 
4.31 a. If X rv Np(O, E), show that, for every prior distribution 7r, 
8"(x) = X + 17V'logm,,(x). 
b. (Bock, 1988) Pseudo-Bayes estimators are defined as the estimators of 
the form 
8(x) = x + V'logm(x) 
in the case where x rv Np(O, lp). Show that the truncated James-Stein 
estimator given in Example 4.6 is a pseudo-Bayes estimator (Le. define 
the corresponding m). Can this estimator be a Bayes estimator? 
4.32* For a normal model Nk(Xf3, E) where the covariance matrix 17 is totally 
unknown, give the noninformative Jeffreys prior. 
a. Show that the posterior distribution of 17 conditionally on f3 is a Wishart 
distribution and deduce that there is no proper marginal posterior dis-
tribution on f3 when the number of observations is smaller than k. 
b. Explain why it is not possible to derive a conjugate distribution in this 
setting. Consider the particular case when 17 has a Wishart distribution. 

174 4. Bayesian Point Estimation 
c. What is the fundamental difference which prevents what was possible in 
§4.3.2? 
4.33* Consider a linear regression prediction setup, where y = X(3 + € has been 
observed with (3 E ffi,k and € '"" Np(O, E), and z = T(3 + €' is to be predicted 
(with T known and €' '"" Np(O, E) independent of f). 
a. If 8 is the predictor and the prediction error is evaluated through the 
loss L(z, 8) = liz - 811 2 , show that the frequentist expected error is 
IEZ'''[L(z,8(x))] = treE) + IE"[118(x) - T(311 2]. 
b. Show that the problem can be expressed as the estimation of (3 under 
the quadratic loss associated with Q = TtT. (Hint: Show first that 8(x) 
is necessarily of the form T'Y(x), with 'Y(x) E ffi,k, or dominated by an 
estimator of this form.) 
c. Deduce from the fact that Q is degenerate with a single eigenvalue dif-
ferent from 0 that a Stein effect cannot occur in this setting. 
d. Consider now that T is a random matrix with mean 0 and IE[TtT] = M. 
Show that, when 8(x) = T'Y(x), the frequentist risk is 
IE Z ,,,,T[L(z,8(x))] = treE) + IE" [b(x) - (3)t Mb(x) - (3)]. 
and therefore that a Stein effect is possible when M has at least three 
positive eigenvalues. (Note: This phenomenon is related to the ancillar-
ity paradoxes developed in Brown (1990). See also Foster and George 
(1994).) 
e. Let (3 '"" Nk(O, (J"2Ik). Derive the Bayes predictor of z when T is fixed 
and when T is random. Conclude. 
4.34 Tobit models are used in Econometrics (see Maddala, 1977) to represent 
truncated setups. Consider ylx '"" N((3tx, 0"2) which is only reported when 
y is positive, x being an explanatory variable in ffi,p. 
a. Show that tobit models are a mixture of probit models (when y < 0) 
and of regular regression models (when y ~ 0). 
b. Give the likelihood function £«(3, 0"2IYI, ... , Yn) associated with a sample 
YI, ... , Yn, Xl, ... ,Xn and derive sufficient statistics for this model. 
c. Conditionally on (Xl, ... , xn ), show that this model belongs to an ex-
ponential family and propose a conjugate prior on «(3, (J"). Are the corre-
sponding computations tractable? 
4.35* The inverse regression (or calibmtion) model is given by 
2 
2 2 
S 
'"" (J" Xq, 
with (3 E ffi,P, .Ao E ffi,. 
a. Give the maximum likelihood estimator of.A and show that its quadratic 
risk can be infinite. 
b. Compute the Jeffreys prior on «(3, (J"2, .Ao) and show that the corre-
sponding posterior expectation of .Ao is the inverse regression estimator, 
Of (y, z, s) = ytz/(s + lIyW). 
c. Using the technique of the reference prior introduced in §3.4, propose an 
alternative prior distribution 7r(.Ao, «(3, (J"2)) when «(3, (J"2) is considered as 
a nuisance parameter. Derive the corresponding posterior expectation of 
.Ao,8R (y,z,s). 

Exercises 175 
d. Show that, when q goes to infinity, 81 a.s. converges to ° 
but that 8R 
is free of this inconsistency drawback. (Note: See Osborne (1991) for 
a survey of calibration models and Kubokawa and Robert (1994) for 
decision-theoretic perspectives on these estimators.) 
4.36* An autoregressive model AR(I) relates the following points of a sample 
Xl, ... , Xn through the relation Xt+1 = I}Xt + Et, where Et '" N(O,0'2) is 
independent of Xt. 
a. Show that the Xt'S induce a Markov chain and derive a stationarity 
condition on I}. Under this condition, what is the stationary distribution 
of the chain? 
b. Give the covariance matrix of (Xl, ... , Xn). 
c. If Xo is a (fixed) starting value for the chain, express the likelihood 
function and derive a conjugate prior on (I}, 0'2). (Hint: Note that 
xtlxt-1 '" N(I}Xt-1, 0'2).) 
d. The quantity of interest is Xo, the starting value of the chain. Compute 
a reference prior for (xO,(1},0'2)) and derive an estimator of Xo under 
quadratic loss. 
Section 4.3.4 
4.37 (Deely and Gupta, 1968) Consider Xl '" N((h,d), ... ,Xk '" N((h,O'~) 
when the quantity of interest is O[k], the largest mean among 01 , •.. , Ok. 
The loss function is L( 0, 'P) = O[kl - 'P. 
a. Show that, if 0'1 = ... = O'k are known and 7r(01) = ., . = 7r(Ok) = 1, the 
Bayes estimator selects the population with the largest observation. 
b. Generalize to the case where the Oi'S have an exchangeable prior distri-
bution N(O, T2). 
4.38*(Goel and Rubin, 1977) Show that the sj truly constitute a complete class 
when the prior distribution on 0 = (0 1 , ••• , Ok) is symmetric. (Hint: Show 
that sj is optimal among the subsets of size Isjl.) 
4.39 (Cont.) Extend this result to the distributions f(xIO) with monotone like-
lihood ratio property in O. 
4.40 (Chernoff and Yahav, 1977) Extend the complete class result of Exercise 
4.38 to the loss function 
L(O, s) = C(8[kl - ( 8 ) -
.; I: 
OJ. 
jEs 
(Hint: Show that, if Oil ::::: ... ::::: Oij' s = {i 1 , ••. , i j } is dominated by the set 
{ij }. ) 
Section 4.4.1 
4.41 Chrystal (1891) writes: "No one would say that, if you simply put two white 
balls into a bag containing one of unknown color, equally likely to be black 
or white, this action raised the odds that the unknown ball is white from 
even to 3 to 1," as an argument against the Laplace succession rule. Do you 
consider this criticism as acceptable? (See Zabell, 1989.) 
4.42 (Jeffreys, 1961) 
a. Show that 
N (i)(N-i) 
I: Xl 
X - Xl 
~=1 
(N +1) 
x+l 

176 4. Bayesian Point Estimation 
(i) algebraically; and (ii) using combinatorics. 
b. If the sample contains x = Xl +X2 individuals, show that the probability 
that the following Y = YI + Y2 draws will contain YI individuals from the 
first and Y2 from the second population is 
( 
I 
) - ~ 
(Xl + 1) ... (Xl + YI)(X2 + 1) ... (X2 + Y2) 
P YI, Y2 Xl, X2 -
, 
, 
() ( 
) 
. 
YI. Y2. 
X + 2 ... X + Y + 1 
c. If X = Xl, deduce that the probability that the Y next draws are of the 
same type is 
x+l 
x+y+l 
4.43 Generalize the Laplace succession rule for a multinomial model. 
Some problems similar to the Laplace succession rule have been considered by 
Lewis Carroll in his Pillow Problems. Seneta (1993) gives a detailed commentary 
on these problems, two of which are given below. 
4.44 Consider two bags, Hand K, with two balls each. Each ball is either black 
or white. A white ball is added to bag H and a hidden ball is transferred 
at random from bag H to bag K. 
a. What is the chance of drawing a white ball from bag K? 
b. A white ball is then added to bag K and a hidden ball is transferred 
from bag K to bag H. What is the chance now of drawing a white ball 
from bag H? 
4.45 "If an infinity of rods is broken, find the chance that one at least is broken 
in the middle." While this question is ill-formulated, a discrete solution is 
proposed below. 
a. Assume that each rod has 2m + 1 breaking points and that there are 
exactly 2m + 1 rods. Give the probability that no rod breaks in the 
middle and derive the limiting value when m goes to infinity. 
b. Study the dependency of this limit upon the assumption that the number 
of breaking points is equal to the number of rods. 
Section 4.4.2 
4.46 In the setup of Example 4.12, develop a Bayesian model for the distribution 
of (t2 - tl). Extend to the following problem: Given that a traffic light has 
been red for one minute, what is the probability that it will turn green in 
the next minute? 
4.47 Show that, for the tramcar problem, the maximum likelihood estimator 
N = T is admissible under any loss function of the form L(IN - NI) where 
L is strictly increasing. (Hint: Consider the case where N = 1 first.) 
Section 4.4.3 
4.48 During the launch of a new campus journal, nl = 220 and n2 = 570 persons 
have bought the two test issues -1 and o. The number of persons who 
bought both issues is nl1 = 180. Give a Bayes estimator of N, total number 
of readers, assuming that a capture-recapture modeling applies here and 
that 7r(N) is P(lOOO). 
4.49 (Castledine, 1981) For the Wolter modeling introduced in §4.4.3, i.e., in the 
case when nl and n2 are random variables, the temporal model considers 

Exercises 177 
the case when all individuals have the same probability of capture for a 
given experiment but where the probability varies between the first and the 
second captures. These two probabilities are denoted PI and P2 . 
a. Give the likelihood and the maximum likelihood estimator associated 
with this model when PI and P2 are known. 
b. Show that the posterior distribution of N given PI and P2 only depends 
on n+ = nl +n2-nl1 and f-t = 1-(1-PI)(1-p2). If the prior distribution 
of N is 7r(N) = 1, show that 7r(Nln+, f-t) is Neg(n+, f-t). 
c. Give the posterior marginal distribution of N if PI '" 8( a, (3) and P2 '" 
8(a, (3). 
d. Show that, if a = 0, (3 = 1, we recover the Darroch model as the marginal 
distribution of N. Does this decomposition facilitate the derivation of a 
Bayes estimator? 

5 
Tests and Confidence Regions 
Although testing theory can be perceived as a special case of Decision The-
ory for a restricted decision space (and even as an estimation problem), 
we consider testing inference in a separate chapter because there is much 
more ambiguity about the real inferential purpose of testing than when 
estimating a regular function of the parameter. In fact, this part of statisti-
cal inference is still incomplete, in the sense that many alternative answers 
have been proposed, none being entirely satisfactory.In particular, there 
exist strong differences between frequentist and Bayesian testing theories. 
This is nonetheless a setting where a Bayesian approach is quite appealing, 
if only because the notion of probability of a hypothesis is well defined. 
But there are controversies running about noninformative perspectives for 
point null hypotheses and model choice settings. 
We first consider in §5.1 the usual Bayesian approach to testing, i.e., 
through an evaluation of decisions by 0-1 losses, and compare the Bayesian 
procedures with their frequentist counterparts in §5.2. We then propose 
in §5.3 an alternative decision-theoretic approach through more adaptive 
losses which emphasize the "postdata" evaluation of testing procedures (as 
opposed to Neyman-Pearson procedures for which the evaluation is oper-
ated in a "predata" spirit). This chapter exhibits a strong contrast between 
Bayesian and frequentist approaches under different evaluation tools; it is 
revealing because this points out the incompleteness of the classical mod-
eling, which relies on artificial concepts to derive its optimal procedures. 
Contrary to point estimation settings, these optimal frequentist procedures 
are no longer limits of Bayes procedures and differ numerically from their 
Bayesian counterparts. However, we moderate this rejection in §5.2 by show-

180 5. Tests and Confidence Regions 
ing that classical answers may sometimes lead to similar conclusions than 
noninformative Bayes procedures. 
5.1. A First Approach to Testing Theory 
Consider a statistical model f(xIO) with 0 E 8. Given a subset of interest 
of 8, 8 0 , which sometimes consists of a single point {Oo}, the question to 
be answered is whether the true value of the parameter 0 belongs to 8 0 , 
i.e. to test the hypothesis1 
Ho: 0 E 8 0 , 
usually called the null hypothesis. In linear models, 8 0 may be a subspace 
of the vector space 8 and the testing problem is then a particular case of 
a model choice problem. 
Example 5.1 Consider a logistic regression model, 
a,x E IRP, 
which models the probability of developing a prostate cancer in a lifetime in 
terms of explanatory variables x = (Xl, ... , xp). Of particular interest is the 
dependency on work environment variables (like asbestos concentration) 
and a company or a union may want to test whether the coefficients ai 
corresponding to these variables are null, i.e., whether the vector a belongs 
to a subspace of IRP. 
!':::. 
In the Neyman-Pearson perspective, the testing problem is formal-
ized through a decision space V restricted to {yes, no} or, equivalently, to 
{1,0}. In fact, it makes sense to perceive testing problems as an inference 
about the indicator function Iso (0) and therefore to propose answers in 
Iso (8 = {O, I}. Of course, the relevance of such a restriction is less obvious 
when considering that testing setups often occur as components (or prelim-
inary steps) or more complex inferential structures and, in particular, that 
the answer to a test question has also consequences in terms of (regular) 
estimation errors. It may then be more interesting to propose procedures 
taking values in [0,1]. (We discuss this approach in §5.3.) 
In some cases, additional information is available about the support of 
0, namely, that 0 E 8 0 U 8 1 #- 8. In such settings, we define the alternative 
hypothesis against which we test Ho as 
Under this formalization, every test procedure 'P appears as an estimator 
of Iso (0) and we only need a loss function L( 0, 'P) to derive the Bayes 
1 There is a certain amount of ambiguity involved in the terminology: Tests are 
simultaneously the testing procedures and the test questions. 

5.1. A First Approach to Testing Theory 181 
estimators. For instance, the loss function proposed by Neyman and Pearson 
is the "0 - 1" loss 
L(O )={1 if'P:f::O:eo(O), 
, 'P 
0 otherwise, 
introduced in Chapter 2. For this loss, the Bayesian solution is 
'P7r(x) = {1 if P7r(O. E eolx) > p7r(O E eolx), 
o otherwIse. 
This estimator is easily justified on an intuitive basis since it chooses the 
hypothesis with the largest posterior probability. A generalization of the 
above loss is to penalize differently errors when the null hypothesis is true 
or false. The weighted 0 - 1 losses 
{ 
0 
if'P = :O:eo(O), 
L(O,'P) = 
ao 
if 0 E eo and 'P = 0, 
al 
if 0 ¢ eo and 'P = 1, 
(5.1) 
are called "ao - al" for obvious reasons. The associated Bayes estimator is 
then given by the following result. 
Proposition 5.1 Under the loss (5.1), the Bayes estimator associ-
ated with a prior distribution Jr is 
Proof. Since the posterior loss is 
L(Jr, 'PIx) = Ie L(O, 'P)Jr(Olx)dO 
= aop7r(O E eolx):O:{o}('P) + alp7r(O ¢ eOIX):O:{I} ('P), 
the Bayes estimator can be derived directly. 
•• 
For this class of losses, the null hypothesis Ho is rejected when the pos-
terior probability of Ho is too small, the acceptance level ad(ao + al) being 
determined by the choice of the loss function. Note that 'P7r only depends 
on ao/al and that the larger ao/al is, i.e., the more important a wrong 
answer under Ho is relative to HI, the smaller the posterior probability of 
Ho needs to be for Ho to be accepted. 
Example 5.2 Consider x rv B(n,p) and eo = [0,1/2]. Under the uniform 
prior distribution Jr(p) = 1, the posterior probability of Ho is 

182 5. Tests and Confidence Regions 
t/2 pX(l - p)n-xdp 
(1/2)n+1 
p7r (p < 1/2Ix) = 0 
= -=-:-----'---'----"-__ 
-:-
-
B(x+1,n-x+1) 
B(x+1,n-x+1) 
{ 
1 
n - X 
(n - X)!X!} 
x+1+ (x+1)(x+2) + ... + (n+1)! 
which can be easily computed and compared to the acceptance level. 
l::::,. 
Example 5.3 Consider x rvN((),a2) and () rvN(p"r2). Then 7r(()lx) is the 
normal distribution N(p,(x),w2) with 
a2p, + r 2x 
p,(x) = 
a2 + r2 
and 
To test Ho : () < 0, we compute 
p7r(() < Olx) = p7r (() -:(x) < -~x)) 
=iP(-p,(x)/w). 
If Zao ,al is the at! (ao + al) quantile, i.e., if it satisfies iP( Zao ,al) = at! (ao + 
ad, Ho is accepted when 
-p,(x) > zao,alw, 
the upper acceptance bound then being 
Again, note that, from a Bayesian point of view, it seems natural to 
base the decision upon the posterior probability that the hypothesis is true. 
In §5.3, we show that an alternative decision-theoretic approach leads to 
this posterior probability as the Bayesian estimator itself and thus avoids 
the comparison to a predetermined acceptance level. In fact, a major dif-
ficulty with the losses (5.1) is the choice of the weights ao and al, since 
they are usually selected automatically rather than determined from utility 
considerations. 
Another notion is also often considered for Bayesian testing: 
Definition 5.1 The Bayes factor is the ratio of the posterior prob-
abilities of the null and the alternative hypotheses over the ratio of 
the prior probabilities of the null and the alternative hypotheses, 
i.e. 
This ratio evaluates the modification of the odds of 8 0 against 8 1 due to 
the observation and can naturally be compared to 1, although an exact 
comparison scale can only be based upon a loss function. In the particular 

5.1. A First Approach to Testing Theory 183 
case where 8 0 = {Bo} and 8 1 = {B1}, the Bayes factor simplifies to the 
usual likelihood ratio 
B1r( ) = f(xIBo) 
x 
f(xIBd' 
In general, the Bayes factor depends on prior information but is still pro-
posed as an "objective" Bayesian answer, since it partially eliminates the 
influence of the prior modeling and emphasizes the role of the observations. 
Actually, it can be perceived as a Bayesian likelihood ratio since, if 11'0 is the 
prior distribution under Ho and 11'1 the prior distribution under H1, B1r(x) 
can be written as 
Jp f(xIBo)11'0(B) dB 
B1r ( x) = --;;"':-'0'---,----,---,-----,-,-_ 
Jel f(xIBd11'1(B) dB' 
Alternatively, if eo is the maximum likelihood estimator on 8 0 and e1 the 
maximum likelihood estimator on 8 1 , the likelihood ratio 
R(x) = f(xl~o) = sUPeo f(xIB) 
f(xlBd 
sUPel f(xIB) 
appears as a particular caSe of B1r(x) when 11'0 and 11'1 are Dirac masses at 
eo and e1. This does not legitimize the use of R(x) in the least since 11'0 and 
11'1 depend on x. 
Although some authors consider the Bayes factor on its own ground 
(see, e.g., Kass and Raftery, 1993), a decision-theoretic consideration of 
the Bayes factor does not lead to a different conclusion than the posterior 
probability as, under (5.1), Ho is accepted when 
B 1r(x) > a1 (20 = aU?l, 
ao 
Q1 
aoQo 
(5.2) 
where 
Qo = 11'(B E 8 0) 
and 
Q1 = 11'(B E 8d = 1 - Qo. 
(5.3) 
This alternative version of Proposition 5.1 thus provides an illustration of 
the duality existing between loss and prior distribution, already mentioned 
in Chapter 2. Indeed, (5.2) shows that it is equivalent to weight both hy-
potheses by the same weight Qo = Q1 = 1/2, and to modify the error 
penalties into a~ = ai11'i (i = 0,1) or to penalize similarly both types of 
errors (a1 = ao = 1) when the prior distribution incorporates the actual 
weights in the weighted prior probabilities, 
The above definition is also instrumental in pointing out an important 
aspect of Bayesian testing. In fact, the Bayes factor is only defined when 
Qo #- 0 and Q1 #- O. This implies that, if Ho or H1 are a priori impossible, the 
observations will not modify this "absolute" information: Null probabilities 

184 5. Tests and Confidence Regions 
are "absorbing states"! Therefore, a point null hypothesis Ho : e = eo 
cannot be tested under a continuous prior distribution. More generally, 
model choice is incompatible with prior distributions which are absolutely 
continuous with respect to the Lebesgue measure on the largest space. We 
therefore assume that it is possible to derive a prior distribution on both 
subsets 8 0 and 8 1, for instance, the probabilities 7ro and 7r1 with densities 
go(e) ex 7r(e)Ieo(e), 
gl(e) ex 7r(e)Ie1 (e), 
(with respect to the natural measures on 8 0 and ( 1) although this defi-
nition is not always free of ambiguity (see Exercise 5.12). Joined with the 
prior probabilities [lo and [l1 of 8 0 and 8 1 given by (5.3), 7ro and 7r1 define 
the prior 7r. In other words, 
7r( e) = [lo7ro (e) + [l17r1 (e). 
(When 8 0 = {eo}, the prior distribution on 8 0 is just the Dirac mass at 
eo.) This assumption may appear to be too strong, in informative as well 
as noninformative setups, since the inferential problem imposes a modifica-
tion of the prior. However, unless the decision maker is adamant about the 
prior distribution 7r, in which case Ho should be rejected if 7r does not give 
any weight to 8 0 , the testing problem can be considered as providing some 
additional (although vague) information about e. Indeed, to test for e E 8 0 
implies that there is a chance that e truly belongs to 8 0 and therefore that 
some possibly ill-defined indication has been provided about this fact. To 
consider testing setups as sources of information is even more convincing 
if the final decision is not the answer to the test but the estimation of a 
function of B, i.e., if the test appears as the choice of a submodel. A prelim-
inary test about the vague information may then improve the estimation 
step. Moreover, keeping this model choice perspective as the real purpose 
of the analysis, it also makes sense to build up a separate prior distribu-
tion for each subspace since only one of the two 8 i will be considered after 
the testing step. For instance, given a point null hypothesis, Ho : e = eo, 
the noninformative distribution 7r(B) = 1 cannot be considered as an ac-
ceptable prior on 8, because the particular value eo has been singled out 
as a possible value for e. In general, to consider that the testing problem 
occurs because of (unavailable) additional observations may help in the 
derivation of a noninformative prior, even though there is no consensus on 
noninformative Bayes modeling for tests (see §5.2.5). 
A usual criticism of point null hypothesis setups is that they are not 
realistic (see, e.g., Casella and Berger, 1987). For instance, as pointed out by 
Good (1980), it does not actually make sense to test whether the probability 
of rain for tomorrow is 0.7163891256 .... 2 However, some statistical prob-
lems definitely call for point null hypothesis testing. For instance, in mixture 
2 But it would still make sense to test whether the prediction of 75% given by 
the local weather forecaster is exact, i.e., whether the probability of rain for the 
given day is 0.75 or another of the probabilities announced by the forecaster 
(see Example 2.5). 

5.1. A First Approach to Testing Theory 185 
estimation (see §1.1 and §9.4), it may be important to know whether a mix-
ture distribution has two or three components, so one may test whether one 
of the component weights is O. Similarly, in linear regression, tests on the 
nullity of the regression coefficients are useful for the elimination of useless 
exogenous variates, as in Example 5.1. More generally, two-sided hypothe-
ses like Ho: () E 6>0 = [()o - E, ()o + E] can be approximated by Ho: () = ()o, 
with hardly any modification of the posterior probabilities when E is small 
enough. For instance, this is the case when the likelihood is constant in a 
neighborhood of ()o (see Berger, 1985a, and Berger and Delampady, 1987). 
Point null hypotheses are also quite important in practice; for instance, 
while it makes sense to determine whether a medical treatment has a pos-
itive or negative effect, the first issue may be to decide whether it has an 
effect at all. 
Considering the point null hypothesis Ho: () = ()o, we denote by [20 
the prior probability that () = ()o and by gl the prior density under the 
alternative. The prior distribution is then 7l'0(()) = [2olloo(()) + (1- (20)gl(()) 
and the posterior probability of Ho is given by 
the marginal distribution on HI being 
This posterior probability can also be written as 
Similarly, the Bayes factor is 
and we derive the following general relation between the two quantities: 
1 - [20 
1 
[ 
]
-1 
7l'(6)0Ix) = 1 + ---;;- B7r(x) 
Example 5.2 (Cont.) Consider the test of Ho : P = 1/2 against p ::j=. 1/2. 
For gl(P) = 1, the posterior probability is then given by 
1 - [20 
[ 
]
-1 
7l'(6)0Ix) = 
1 + ---;;-2n B(x + 1, n - x + 1) 
[1 + 1- [20 x!(n - X)!2n]-1 
(20 
(n - I)! 

186 5. Tests and Confidence Regions 
since m(x) = C)B(x + 1,n - x + 1). For instance, if n = 5, x = 3, and 
{!o = 1/2, the posterior probability is 
( 
2 
) -1 
15 
1+ 12025 
= 23 
and the corresponding Bayes factor is 15/8, close to 2. So, in the most 
supporting cases, the posterior probabilities tend to favor Ho. When the 
sample size increases, the range of the possible answers also grows. For 
instance, if 7r(p) is Be(1/2, 1/2) and n = 10, the posterior probabilities are 
given in Table 5.1 and support Ho for x close to 5, even though the prior 
distribution is rather biased against the null hypothesis (since it heavily 
weights the extreme values, 0 and 1). 
b. 
TABLE5.1. Posterior probabilities of p = 1/2 when n = 10. 
x 
0 
1 
2 
3 
4 
5 
P(p = 1/2Ix) 0.0055 0.0953 0.3737 0.6416 0.7688 0.8025 
Example 5.3 (Cont.) Consider the test of Ho : 0 = O. It seems reasonable to 
choose 7r1 as N(/L, 7 2) and /L = 0, if no additional information is available. 
Then 
= J u2 ~ 72 exp {2u2(~2X: 72)}' 
and the posterior probability can be derived as 
[ 
1- {!O~2 (72x2 
)]-1 
7r(O = Olx) = 
1 + --
2 
2 exp 2 2( 2 
2) 
{!o 
U +7 
U 
U +7 
In the special case when (!o = 1/2 and 7 = u, Table 5.2 gives the posterior 
probabilities in terms of z = x / u. 
TABLE5.2. Posterior probabilities of () = 0 for different values of z = x/u 
and for 7 = u. 
z 
0 
0.68 
1.28 
1.96 
7r(O = Olz) 0.586 0.557 0.484 0.351 
Consider now the alternative case 7 = lOu; it is supposed to indicate a 
more diffuse prior information on O. The posterior probabilities of Ho are 
then modified as shown in Table 5.3. 
b. 

5.1. A First Approach to Testing Theory 187 
TABLE 5.3. Posterior probabilities of () = 0 for 7 2 = lOa2 
and z = x/a. 
z 
0 
0.68 
1.28 
1.96 
71"(0 = Olx) 0.768 0.729 0.612 0.366 
The recourse to noninformative prior distributions for testing hypothe-
ses is rather limited, if not simply discouraged as in DeGroot (1973). In fact, 
as noticed previously, the testing setup is not coherent with an absolute lack 
of information, since it implies at least a division of the parameter space into 
two subsets. However, the inconvenience with the use of improper prior dis-
tributions goes deeper since it seems they are incompatible with most tests 
of point null hypotheses. In the following paragraphs, we consider in detail 
the normal setup, x rv N(O, 1), for the point null hypothesis Ho: 0 = 0 to 
test against HI : 0 i- 0 to illustrate this difficulty. 
If we use the improper prior 71"(0) = 1 on {O i- O}, i.e., if 71" is 
1 
1 
71"(0) = 2][0(0) + 2 ·1, 
the posterior probability of Ho is 
e-x2 / 2 
1 
7I"(O=Olx)= 
- .  
e-x2 / 2 + J~: e-(x-O)2/2 dO 
1 + v'2iiex2 / 2 
Therefore, this posterior probability of Ho is bounded from above by 
1/(1 + v'2ii) = 0.285. This implies that the posterior distribution is rather 
biased against Ho, even in the most favorable case. Unless the scale of com-
parison, i.e., the loss, is modified to account for these low values, the null 
hypothesis will be rejected quite often. A similar phenomenon occurs when 
8 0 is compact. For instance, the test of Ho: 101:s 1 versus HI: 101 > 1 
leads to the following posterior probability: 
t I e-(x-O)2/2 dO 
71"(101 < llx) = ----,--'-"------
-
J~: e-(x-O)2/2 dO 
= 4>(1- x) - 4>(-1- x) 
= 4>(x + 1) - 4>(x - 1), 
whose numerical values are given in Table 5.4. Therefore, the maximal 
support of Ho, 0.683, is still moderate. 
TABLE 5.4. Posterior probabilities of I()I < 1. 
x 
0.0 
0.5 
1.0 
1.5 
2.0 
71"(101 :s llx) 0.683 0.625 0.477 0.302 0.157 

188 5. Tests and Confidence Regions 
An interesting feature of the Lebesgue prior distribution can be ex-
hibited for the point null hypothesis Ho : () = O. The resulting procedure 
agrees with the corresponding classical answer, as shown by Table 5.5. 
TABLE 5.5. Posterior probabilities of e = 0 for the Jeffreys prior. 
x 
0.0 
1.0 
1.68 
1.96 2.58 
71'(() = Olx) 0.285 0.195 0.089 0.055 0.014 
The posterior probability 71'(() = Olx) is indeed quite close to the classical 
significance levels 0.10, 0.05, and 0.01 when x is 1.68, 1.96, or 2.58 (it will 
be demonstrated in §5.2.4 that this comparison is meaningfull). This coinci-
dence does not hold for all values of x but shows that, for usual significance 
levels (and testing purposes), the classical answer could be considered as 
a noninformative Bayes answer, even though it corresponds to a hardly 
defendable prior. 
Another illustration of the delicate issue of improper priors in testing 
setups is provided by the Jeffreys-Lindley paradox. In fact, limiting argu-
ments are not valid in testing settings and prevent an alternative derivation 
of noninformative answers. For instance, considering the conjugate prior 
distributions introduced in Example 5.3, the posterior probabilities are 
{ 
}
-I 
1 - eo 
(J2 
7 2X 2 
71'(() = Olx) = 
1 + -- ~ 
exp [2 2( 2 
2)] 
, 
eo V~ 
(J 
(J +7 
which converge to 1 when the prior variance 7 goes to +00, for every 
x. This limit differs from the "noninformative" answer derived previously 
[1 + J27fexp(x2j2)]-1 and, more importantly, is totally useless. This phe-
nomenon can also be observed by comparing Tables 5.2 and 5.3, since the 
probability is larger when 7 = 10(J than when 7 = (J for all the values of z 
considered in the tables. See Aitkin (1991) and Robert (1993b) for recent 
discussions on this paradox. 
Paradoxes associated with improper priors like the Jeffreys-Lindley 
example are actually due to a weighting indeterminacy which does not 
occur for point estimation or even for one-sided tests. 
Example 5.4 Consider x"" N((), 1) and Ho : ():::; 0 to test versus HI : () > O. 
For the diffuse distribution 71'( ()) = 1, 
71'( e :::; Olx) = -
e-(x-O)2/2 de 
1 JO 
J27f 
-00 
= <1>( -x). 
In this case, the generalized Bayes answer is also the classical procedure, 
called the p-value (see §5.2.4). 
!::. 

5.2. Comparisons with the Classical Approach 189 
For two-sided problems, if go and gl are a-finite measures correspond-
ing to truncated noninformative priors on the subspaces 8 0 and 8 1 , the 
choice of the normalizing constants will influence the Bayesian estimator. 
In fact, if gi is replaced by cigi (i = 0,1), the Bayes factor is multiplied by 
CO/C1. For instance, if the Jeffreys prior is uniform and go = Co, gl = C1, 
the posterior probability is 
QoCo Ie f(xIO) dO 
1[(0 E 8 0 1x) = 
0 
• 
QoCo Ieo f(xIO) dO + (1 -
QO)C1 Ie 1 f(xIO) dO 
It is therefore necessary to extend the noninformative perspective to these 
testing settings by developing a technique able to derive the weights Ci in 
a noninformative and acceptable way. Bernardo (1980), Spiegelhalter and 
Smith (1980), Smith and Spiegelhalter (1982), Aitkin (1991), Pettit (1992), 
Berger and Perrichi (1993) and Robert (1993b) have made proposals in this 
direction. Note that Jeffreys (1961) proposed instead to use proper priors 
in such settings, like C(O, ( 2 ) or N(O, 10(2 ) in the case of x rv N(O, ( 2 ) 
and Ho : 0 = O. The problem is then that the choice of the proper prior 
distribution will influence the answer to the test. 
In the present state of the art, however, it does not seem reasonable 
to use improper priors, like the Jeffreys priors, for two-sided tests since 
they seem to lead to too much arbitrariness and are usually quite biased 
in favor of the alternative hypothesis or, more precisely, in favor of the 
noncompact subset. We consider in §5.2 an alternative approach which 
defines a 'least favorable' Bayesian answer as a lower bound on the (proper) 
Bayes estimators. The difficulties encountered with noninformative priors 
in testing setups also point out that a testing problem cannot be treated in a 
coherent way if no prior information is available, i.e., that the information 
brought by the observations alone is usually not enough to infer about 
the truth of a hypothesis in a categorical fashion (yes/no). This obviously 
reinforces the motivation for a Bayesian treatment of such testing problems, 
as it is the only coherent approach which takes advantage of the residual 
information. 
5.2. Comparisons with the Classical Approach 
5.2.1. UMP and UMPU Tests 
The classical approach to testing theory is the theory of Neyman-Pearson, 
as presented, for instance, in Lehmann (1986). For the "0-1" loss, denoted 
L below, the corresponding notion of optimality is the following one: 
Definition 5.2 If a EjO, 1[ and Co: is the class of the procedures 'P 
satisfying the following constraint on the type II error: 

190 5. Tests and Confidence Regions 
sup IEo[L(O, cp(x»] = sup Po(cp(x) = 0) ::; c¥, 
OEBo 
OEBo 
a test procedure cp is said to be uniformly most powerful at level 
c¥ (UMP3) if it minimizes the risk IEo[L(O, cp(x))] uniformly on 8 1 
in Co:. 
This optimality is much weaker than the notion of admissibility devel-
oped in §2.4. In fact, the loss is bidimensional in this setup because of the 
restriction on the type I error, namely, sUPBo IEo[L(O, cp)] ::; c¥. This restric-
tion is usually necessary to obtain an optimal test procedure, since the risk 
functions of admissible procedures cross but: 
(i) It leads to an asymmetry between the null and the alternative hypothe-
ses, which induces an unnatural behavior for the test procedures. In 
fact, since the type I error is fixed, a balance between the two types 
of error (acceptance under HI and rejection under Ho) is impossi-
ble, hence a much bigger type II error. This lack of symmetry is also 
responsible for this theory bypassing minimaxity considerations. For 
instance, this is the case when the two hypotheses Ho and HI are con-
tiguous, i.e., when it is possible to go from 8 0 to 8 1 by a continuous 
transformation. 
(ii) It implies the selection of a significance level c¥ by the decision maker, 
in addition to the choice of the loss function L, and this generally leads 
to the call to "standard" levels, 0.05 or 0.01, and the drawbacks ofthese 
"universal" levels (see below). 
(iii) It does not necessarily imply a sufficient reduction of the class of test 
procedures and does not always allow for the selection of a unique opti-
mal procedure. It is sometimes necessary to impose further constraints 
on these classes. 
In the simplest case in which null and alternative hypotheses are point 
hypotheses, Ho: 0 = 00 versus HI: 0 = 01, the Neyman-Pearson lemma 
establishes that there exist UMP test procedures and that they are of the 
form4 
(x) = {I if f(xI01) < kf(xIOo), 
cp 
0 otherwise, 
k being related to the selected significance level c¥. Obviously, the fact that 
8 1 is reduced to {(h} is quite helpful since it allows for a total ordering of the 
procedures of Co:. For monotone likelihood ratio families, i.e., parametrized 
families for which there exists a statistic T(x) such that 
3 The power of a test is the probability of rejecting Ho under the alternative 
hypothesis, i.e. (3((}) = 1 - IEe[cp(x)] for (} E 8 1 . The quantity 1 - (3((}) is also 
called type II error. 
4 Conserving the interpretation that a test procedure is an estimator of ][eo ((}), 
the test procedures in this book are complements to 1 of the classical Neyman-
Pearson procedures, for which a value of 1 corresponds to the rejection of Ho. 

5.2. Comparisons with the Classical Approach 191 
f(xje') 
f(xIO) 
is increasing in T(x) for 0' > 0, Karlin and Rubin (1956) have established 
the following extension of the Neyman-Pearson lemma (see Lehmann, 1986, 
p. 79, for a proof). 
Proposition 5.2 Consider f(xIO) with a monotone likelihood ratio 
in T(x). For Ho: 0::; 00 and HI: 0 > 00 there exists a UMP 
test such that 
ifT(x) < c, 
ifT(x)=c, 
otherwise, 
"( and c being determined by the constraint 
Karlin and Rubin (1956) have also shown that, for the loss functions 
of the class (5.1), the test procedures provided in Theorem 5.2 form an 
essentially complete class, i.e., a class of procedures large enough to be 
at least as good as any other procedure (see Chapter 6). Moreover, if the 
support of the distribution f(xIO) is independent of 0, the class obtained in 
Proposition 5.2 is minimal essentially complete: it cannot be reduced any 
further (see Lehmann, 1986, pp. 82-83), and therefore only contains optimal 
procedures. 
Note that an important class of monotone likelihood ratio families 
consists of the exponential families, since 
f(xIO') 
eO'x-,jJ((n 
f(xIO) 
eO'x-'ljJ(O') 
e(e' -O)x 
e'IjJ(O')-'ljJ(O') 
is increasing in x. Pfanzagl (1968) has also established a reciprocal to Propo-
sition 5.2 in the spirit of the Pitman-Koopman lemma (see §3.2.2), namely, 
that the existence of a UMP test for every sample size and a given level Q 
implies that the distribution belongs to an exponential family. 
Example 5.5 Consider x rv P(>.) and Ho: >.::; >'0, HI: >. > >'0' For 
m independent observations from this distribution, a sufficient statistic is 
s = L:i Xi rv P(m>.) and, according to Proposition 5.2, a UMP test is given 
by 
{ 
1 if s < k, 
<p(x)= 
"( ifs=k, 
o otherwise, 
for IE>.o[<P(x)] = Pm>.o(s > k) + "(Pm>'o(s = k) = Q. 
Proposition 5.2 and the above example stresses a major difficulty with 
the Neyman-Pearson approach, namely, that arbitrary significance levels 
are not necessarily attainable unless one calls for randomization. Indeed, 

192 5. Tests and Confidence Regions 
as the decision space is V = {O, I}, <p( x) = , means that <p( x) = 1 with 
probability, (and 0 otherwise). Such procedures are obviously incompat-
ible with the Likelihood Principle, although they only appear for discrete 
cases. Lehmann (1986) indicates that the significance level Q should be 
modified until randomization is avoided but this modification points out 
another drawback. The choice of the significance level then depends on the 
observation, not on a utility function. 
Moreover, Proposition 5.2 only applies to one-sided hypotheses. In a 
particular case of two-sided hypotheses, we can exhibit an optimality result 
(see Lehmann, 1986, pp. 101-103). 
Proposition 5.3 Consider an exponential family 
f(xI8) = eIJT(x)-I/J(IJ)h(x) 
and Ho: 8:::; 81 or 8 ~ 82, HI: 81 < 8 < 82 . There exists a 
UMP test of the form 
{ 
0 
if Cl < T(x) < C2, 
<p(x) = 
'Ii 
ifT(x) = Ci 
(i = 1,2), 
otherwise, 
with (i = 1,2) 
lEeJ<P(x)] = Q. 
However, there is no corresponding UMP test for the opposite case, 
i.e., Ho: 81
:::; 8 :::; 82 . This paradox illustrates quite forcibly the lack 
of symmetry of the UMP criterion but is also quite puzzling and casts a 
doubt on the validity of the Neyman-Pearson analysis or the relevance of 
a symmetric loss like the 0 - 1 loss. In these cases, the Neyman-Pearson 
solution is to propose an additional reduction of the class of test procedures 
by considering unbiased tests, i.e., those which also satisfy 
supPe(<p(x) = 0):::; infPIJ(<p(x) = 0). 
80 
8 1 
In other words, <p must also satisfy 
inf lEIJ [<p(x)] ~ sup lEe [<p(x )]. 
8 0 
8 1 
The notion of uniformly most powerful unbiased tests (UMPU) then fol-
lows. However, this restriction induces a further assymmetry between Ho 
and HI. Although intuitively acceptable, this notion of unbiasedness is yet 
another example of the restrictions imposed by the frequentist approach to 
optimality which denaturate the true purpose of Decision Theory. 
Example 5.6 If, for x rv N(8, I), we test Ho: 8 = 0 versus HI: 8 =I 0, 
there is no UMP test. A UMPU test at level Q = 0.05 is 
<p(x) = {I if Ixl :::;.1.96, 
6 
o otherwIse. 

5.2. Comparisons with the Classical Approach 193 
5.2.2. Least Favorable Prior Distributions 
When no UMPU test is available, it gets quite difficult for the classical 
approach to defend or even construct a specific testing procedure. Apart 
from restricting any further the class of acceptable procedures, a usual 
alternative is to consider the likelihood ratio 
sUPoEeo f(xI8) 
sUPoEel f(xI8) 
(5.4) 
and its distribution, or to base the test upon the asymptotic distribution 
of (5.4). The ratio (5.4) exhibits a link with the Bayesian approach, since, 
as mentioned above, it appears as a Bayes factor for a prior distribution 7r 
which is supported by 00 and 01 , maximum likelihood estimators of 8 on 
8 0 and 8 1. This analysis is rather formal since Dirac masses are artificial 
priors and, moreover, the O/s depend on the observation. However, it also 
indicates that the likelihood ratio has a Bayesian motivation. 
Relations between Bayesian testing procedures and Neyman-Pearson 
optimal tests are given in Lehmann (1986) through the notion of a least 
favorable distribution, described below.5 Consider Ho: 8 E 80, H1 : 8 = 81 
with 7r a prior distribution on 8 0 , From a Bayesian point of view, the test 
problem can be represented as the test of Hn:: x rv m7r versus H1 : x rv 
f(xI8d, where m is the marginal distribution under Ho 
m7r(x) = r f(xI8)7r(8) dO. 
Jeo 
Since both hypotheses (H7r and Hd are point hypotheses, the Neyman-
Pearson lemma ensures the existence of a UMP test 'P7r' at significance 
level a, with power i37r = POI ( 'P7r ( x) = 0). This test is of the form 
( ) _ {1 if m7r(x) > kf(xI8d, 
'P7r x -
o otherwise. 
Definition 5.3 A least favorable distribution is any prior distribu-
tion 7r which maximizes the power i37r' 
This definition is used in the following result (Lehmann, 1986, p. 105): 
Theorem 5.4 Consider Ho: 0 E 8 0 to be tested against a point 
alternative H1 : 0 = 01 . If the UMP test 'P7r at level a for H7r 
versus H1 satisfies 
sup IEo[L(O,'P7r)] ::; a, 
OEeo 
5 The remainder of this section is not used later. The connection stressed here 
is of lesser importance than the corresponding relation obtained in minimaxity 
theory (see §2.4.3). Moreover, it only applies to specific cases and does not 
validate any further the classical answers, which still cannot be obtained as 
limits of Bayesian procedures (see §5.3). 

194 5. Tests and Confidence Regions 
then 
(i) 
!.p7r is UMP at level a; 
(ii) if!.p7r is the unique a-level test of H7r versus HI, !.p7r is the 
unique UMP test at level a to test Ho versus HI; and 
(iii) 7r is a least favorable distribution. 
The constraint in the above theorem may seem unnecessary but note 
that !.p7r is defined by 
r 
m7r(x) dx = a. 
J{m", (x»kf(xlotl} 
This relation does not guarantee that IEo[L(B,!.p7r)] :S a for every B E 8 0 . 
5.2.3. Criticisms 
Theorem 5.4 exhibits a connection between Bayesian and UMP tests in 
the same vein that least favorable distributions lead to minimax estimators 
in point estimation problems with a value (see §2.4), although the Bayes 
procedure corresponds to a modified testing problem involving 7r. We do 
not pursue this connection any further because, like other authors, we op-
pose the Neyman-Pearson approach as a whole. Indeed, in addition to the 
randomization problems mentioned above, a major drawback of this per-
spective is to restrict the decision space to the couple {a, I}, thus to force a 
categorical decision. It seems to us that a more adaptive answer is prefer-
able. Moreover, UMP (and UMPU) tests, when they exist, depend on an 
evaluation measure (the significance level a) which is not reconsidered pos-
terior to the observation. For instance, in Example 5.6, the level being fixed 
at 0.05, the classical answer is identical for x = 1.96 and x = 100. From a 
purely decision-theoretic point of view, it also seems paradoxical to force 
the inferential procedures into a restricted framework, since it can (and 
does) lead to suboptimal procedures. In particular, the notion of unbiased-
ness, which has been successfully removed from point estimation tools by 
the Stein effect (§2.4.5), should also disappear from the testing machinery. 
A more fundamental criticism of the Neyman-Pearson approach (and, 
basically, of every frequentist approach) is that it bases rejection of Ho on 
unlikely events that did not occur, to quote Jeffreys (1961). In fact, a UMP 
rejection region is of the form 
{T(X) 2:: T(x)} 
if the distribution has monotone likelihood ratio in T, since, under the null 
hypothesis, 
P(T(X) 2:: T(x)) < a. 
(5.5) 
However, the event which actually occurs is {T(X) = T(x)}. There is there-
fore a loss of information in the (classical) decision process which is usually 

5.2. Comparisons with the Classical Approach 195 
biased against the null hypothesis. Indeed, the region {T(X) ::::: T(x)} is 
relatively more unlikely than a neighborhood of T(x), thus explaining the 
more optimistic values of the Bayesian answers (see §5.2.5). Of course, the 
only coherent approach which allows for conditioning on {T(X) = T(x)}, 
i.e., on the observation, is the Bayesian approach. On the contrary, to choose 
a procedure on the basis of (5.5) involves the whole distribution of x and 
thus potentially contradicts the Likelihood Principle, as shown by Exam-
ples 1.11 and 1.13. In fact, the Stopping Rule Principle cannot allow for 
a frequency-based theory of tests, as the distribution of the sample size 
should not be relevant for the selection of a testing procedure. There is in-
deed this apparent paradox with the Likelihood Principle that a procedure 
based on a likelihood ratio is acceptable as long as it does not involve the 
distribution of this ratio. 
Example 5.7 The chi-squared test is a simple procedure (if not always 
justified) to test the goodness of fit of a sample to a distribution (or to a 
family of distributions). If the sample of size n is divided into k classes, 
with theoretical sizes Ni = npi and observed sizes ni, it follows from the 
Central Limit Theorem that 
is approximately distributed as a XE random variable, the degrees of free-
dom £ depending on the problem. (It is usually k - 1 minus the number of 
estimated parameters.) As pointed out by Jeffreys (1961), the classical ap-
proach rejects the null hypothesis (of goodness of fit to the proposed family 
of distributions) if D2 is too large, for instance, if 
for Z r"V Xr However, there is no reason to accept the null hypothesis (i.e., 
that D2 is approximately distributed as XE) if 
P(z < D2) :::; 0.05, 
since such values of D2 are not more compatible with the distribution than 
when P(z > D2) :::; 0.05. From this point of view, it would also be justified 
to reject the validity of the null hypothesis, but the classical approach fails 
to do so. 
6 
Example 5.8 A well-known Bayesian criticism of Neyman-Pearson theory is 
the following opposition exhibited by Lindley (1957, 1961). Consider xn r"V 
N(O, lin) the average of a normal sample and () r"V N(O, 1). To test Ho : 
() = 0 versus HI: () #- 0, the corresponding UMPU tests only depend on 
Zn = Ixnlfo. Consider Zn = 1.97. At the significance level 5%, the test 
procedure rejects Ho for every n. On the contrary, the Bayesian posterior 
probability of Ho is (see Example 5.3) 

196 5. Tests and Confidence Regions 
n(() = O!Zn) = (1 + 1 - (}o k 
exp{z;n/2(n + In) -1, 
(}o 
n + 1 
and thus goes to 1 as n goes to infinity. Actually, this result holds for 
most prior distributions, due to the asymptotic normality of the posterior 
distributions (see Hartigan, 1983). This paradox can be related to Kepler's 
problem (see Jeffreys, 1961, or Berger, 1985a), which is that, in astronomy, 
a null hypothesis-for instance, the elliptical nature of planet trajectories-
is always rejected from a frequentist point of view for a sample size large 
enough, i.e., when enough observations have been accumulated. 
f::::. 
Another major difficulty with the Neyman-Pearson approach is that 
the selection of the level a should be equivalent to the selection of the 
weights ao and a1 in the loss function, and thus should be based on utility 
considerations. Instead, the practice is to completely bypass this selection 
and, following a suggestion by Fisher (1956), it became a formal rule to 
adapt "classical" a-levels of 5% or 1%, no matter what the problem, the 
sample size, or the type II error are. Since the Neyman-Pearson approach is 
quite predominant nowadays, this dogmatic attitude created a publication 
bias since results of experiments which are not "significant at level 5%" are 
most often rejected by editors or even by the authors themselves in many 
fields, including Biology, Medicine, and the Social Sciences. 
5.2.4. The p- Values 
Frequentists (and practitioners) tried to circumvent the drawbacks of the 
Neyman-Pearson approach by removing the significance level a and propos-
ing an answer taking values in [0, 1], and more importantly depending on 
the observations on a more adaptive way than comparing T(x) with a given 
threshold separating acceptance and rejection. The following notion was 
first introduced by Fisher (1956) (in this regard, see Gigerenzer, 1991, for 
an account of the evolution of Fisher's perception of testing). 
Definition 5.4 The p-value associated with a test is the smallest 
significance level a for which the null hypothesis is rejected. 
A general definition for point null hypotheses (see Thompson, 1989) 
considers that a p-value is any statistic with a uniform distribution under 
the null hypothesis but it leads to the difficult problem of selecting one 
of these statistics, even though the same can be said about the test intro-
duced in the above definition. Actually, if a test with rejection region Ra. 
is available for every significance level a and if these regions are nested 
(Ra. C Rf3 if /3 > a), the procedure 
p(x) = inf{a; x ERa.} 
is uniformly distributed if IEoo[IR" (x)] = a (see Goutis et al., 1993). In the 
event of several competing tests, we suggest using the distribution of the 
likelihood ratio under the null hypothesis if it is a point null hypothesis. 

5.2. Comparisons with the Classical Approach 197 
Example 5.6 (Cont.) Since the critical region (i.e., the rejection region for 
Ho) of the UMPU test is {Ixl > k}, an usual p-value is 
p(x) = inf{o:; Ixl > koJ 
= pX (IXI > Ixl), 
X rv N(O, 1) 
= 1 - 4>(lxl) + 4>(lxl) = 2[1 - 4>(lxl)]· 
Therefore, if x = 1.68, p(x) = 0.10 and, if x = 1.96, p(x) = 0.05. 
6 
Example 5.9 Consider x rv B(n,p), when the hypothesis to be tested is 
Ho : p = 1/2 and Hl : p -=I- 1/2. The p-value associated with the likelihood 
ratio 
f(xI1/2) 
sUPp f(xlp) 
is the function 
p(x) = Pl/2 (XX (n - x)(n-X) ::; xX(n - x)(n-x)) , 
where X rv B(n, 1/2). 
p-values are thus procedures which can be acceptable from a frequentist 
point of view and which, furthermore, meet the requirements of Kiefer 
(1977) and Robinson (1979) for a conditionalfrequentist approach. However, 
they are still exposed to criticisms since: 
(i) p-values also evaluate the "wrong" quantity, namely, the probability 
of overpassing the observed value of the test statistic. They therefore 
contradict the Likelihood Principle by involving the whole distribution 
of the observation. 
(ii) Even if derived from optimal test procedures, p-values have no intrinsic 
optimality as they are not evaluated under a loss function. In fact, as 
shown in §5.3, they may even be suboptimal. 
(iii) The new decision space, V = [0,1], lacks a decision-theoretic founda-
tion and thus the use of p-values is not explicited. In particular, the 
p-values are often perceived as providing a frequentist approximation 
to P(() E 8 olx) even though this expression is meaningless in a non-
Bayesian setup. 
(iv) In a classical perspective, p-values do not summarize the whole in-
formation about the testing problem, since they should be compared 
with type II errors, which are usually omitted from the analysis. Berger 
and Wolpert (1988) illustrate the danger of using only p-values by the 
following example: If x rv N((),1/2), to test () = -1 versus () = 1 
when x = a leads to an (UMP) p-value of 0.072, seemingly indicating 
a strong rejection of the null hypothesis, although the corresponding 
p-value for the test reversing Ho and Hl takes exactly the same value. 
In fact, while a rejection of Ho should not always imply acceptance 
of H l , practitioners often consider p-values as the testing procedure 

198 5. Tests and Confidence Regions 
and they assume that it encompasses the whole information about the 
testing problem, thus ending with this implication. 
5.2.5. Least Favorable Bayesian Answers 
The problem of evaluating p-values under an adapted loss is considered in 
§5.3. We conclude §5.2 with a comparison of p-values with their Bayesian 
counterparts, the posterior probabilities. To consider the lower posterior 
probability on a class of prior distributions provides a Bayesian least favor-
able answer with respect to the null hypothesis. This lower bound cannot 
be considered as a noninformative procedure since it enhances the prior 
most opposed to the null hypothesis and is both biased against Ho and 
dependent on the observation. It should be interpreted as an indicator of 
the range of the posterior probabilities, the most favorable answer being l. 
An extensive literature is now available on this approach and we refer to 
Berger and Sellke (1987), Berger and Delampady (1987) and Berger and 
Mortera (1991) for additional references. 
Berger and Sellke (1987) and Berger and Delampady (1987) consider 
the case of a point null hypothesis, Ho: 0 = 00 , against the alternative 
hypothesis H 1
: 
0 =I- 00 , For a family G of prior distributions on the 
alternative hypothesis, the evaluation measures of the veracity of Ho are 
given by the lower bounds 
. 
f(xIOo) 
B(x, G) = ~~& Ie f(xIO)g(O) dO' 
P(x G) = inf 
f(xIOo) 
-, 
gEG f(xIOo) + Ie f(xIO)g(O) dO 
on the Bayes factors and posterior probabilities (for eo = 1/2, considered to 
give equal weights to both hypotheses). These bounds can also be written 
as 
B( G) = 
f(xIOo) 
-
x, 
SUPgEG Je f(xIO)g(O)dO' 
[ 1]-1 
P(x, G) = 
1 + l1(x, G) 
They obviously vary, depending on the class G considered. In the more gen-
eral case, i.e., when G is G A, the set of all prior distributions, the following 
result is straightforward. 
Lemma 5.5 If there exists a maximum likelihood estimator of 0, 
O(x), the lower bounds on the Bayes factors and posterior proba-
bilities of Ho are, respectively, 
B(x G ) = f(xIOo) 
-
,A 
f(xIO(x)) ' 
P(x G ) = [1 + f(X 1o(x))]-1 
-
, 
A 
f(xIOo) 

5.2. Comparisons with the Classical Approach 199 
A consequence of Lemma 5.5 is that the Bayesian answer will never 
strongly favor the null hypothesis, since 
This behavior is not particularly surprising as the lower bounds correspond 
to the worst possible choice of 9 with respect to Ho. A more surprising 
phenomenon is that the decrease of these bounds when Ixl increases is 
much slower than for the p-values, as shown by the following example: 
Example 5.6 (Cont.) In the normal case, the lower bounds associated with 
Ho : 00 = 0 are 
B(x G ) = e-x2j2 
_ 
, 
A 
leading to Table 5.6, which compares the p-values with the Bayesian least 
favorable answers. 
TABLE 5.6. Comparison between p-values and Bayesian answers 
in the normal case. (Source: Berger and Sellke, 1987.) 
p-value 0.10 
0.05 
0.01 0.001 
P 
0.205 0.128 0.035 0.004 
f3 
0.256 0.146 0.036 0.004 
Therefore, the difference with the frequentist answers is quite impor-
tant. p-values are smaller for the significance levels of interest, thus reject 
the null hypothesis Ho "too often." Of course, for smaller values of x, the 
p-values are larger than the lower bounds but what matters is that in the 
range of values of x where the decision is the most difficult to take, i.e., for 
significance levels between 0.01 and 0.1, there is such a discrepancy between 
the Bayesian and frequentist answers. 
6 
Results such as those above are quite surprising because classical pro-
cedures usually belong to the range of Bayesian answers. Moreover, the 
class G A is rather unreasonable, including point masses leading to the lower 
bound. The only justification of this class of priors relates to the minimax 
principle and the corresponding least favorable distribution. The above ex-
ample shows that p-values are not minimax in this sense. Obviously, the 
discrepancy is more important for smaller classes of distributions. For in-
stance, if Gis Gs, the set of distributions which are symmetric around 00 , 
the equivalent of Lemma 5.5 is: 
Lemma 5.6 The smallest Bayes factor when g E G s is 
B(x Gs ) = 
f(xIOo) 
, 
-, 
sup~ ~[f(xIOo -~) + f(xlOo + ~)l 

200 5. Tests and Confidence Regions 
which leads to the corresponding lower bound on posterior proba-
bilities. 
This result is derived from the fact that every symmetric distribu-
tion is a mixture of distributions with a two-point support of the form 
{Oo -
~, 00 + O. For multidimensional extensions, the supremum is to be 
taken on uniform distributions on spheres centered at 00 (see Berger and 
Delampady, 1987). Discrete setups call for some refinements, if only to de-
fine the notion of a symmetric distribution. For instance, in the binomial 
case, the corresponding class is Gs, made of the distributions which are 
symmetric in 
P-Po 
Jp(1- p) 
Example 5.9 (Cont.) For Ho: p = 1/2, Table 5.7 provides p-values and 
Bayesian lower bounds associated with Gs (Po = 1/2). 
TABLE 5.7. Comparison between p-values and Bayesian answers 
in the binomial case. (Source: Berger and Delampady, 1987.) 
p-value 
0.0093 0.0507 0.1011 
P 
0.0794 0.2210 0.2969 
Note that in this case, the p-values are not the standard levels, because 
of the discrete nature of the binomial distribution. 
/':" 
Another interesting class of priors is the class of unimodal distributions 
which are symmetric around 00 , Gsu. These distributions can be writ-
ten as mixtures of uniform symmetric distributions in dimension 1 (Berger 
and Sellke, 1987). Therefore, the computation of the lower bounds is still 
tractable. It is necessary to use such classes in multidimensional setups as 
the lower bounds associated with more general classes like G A are close to 
o for most values of the observation. 
Example 5.6 (Cont.) In the normal case, if Ixl ::; 1, B(x, Gsu) = 1 and 
P(x, Gsu ) = 1/2. However, if Ixl > 1, defining g(O) = (1/2K)I{IOI < K}, 
we get 
J 
f(xIO)g(O) dO = 2~ [q>(K - x) - q>( -K - x)] 
and the lower bound is associated with K maximizing this expression. Table 
5.8 gives the values of Band P corresponding to p-values of 0.1 and 0.01, 
exhibiting a significant discrepancy with the frequentist answer. 
/':" 

5.2. Comparisons with the Classical Approach 201 
TABLE5.8. Bayesian answers for p-values of 0.01 (above) and 0.1 (below) 
in the normal case. (Source: Berger and Delampady, 1987.) 
dim. 
1 
3 
5 
P 
0.109 
0.083 
0.076 
0.392 
0.350 
0.339 
B 
0.123 
0.090 
0.082 
0.644 
0.540 
0.531 
A first consequence of these comparisons is that, from a Bayesian view-
point, p-values are not a valid tool for conducting testing experiments on 
null hypotheses. Contrary to regular point estimation settings as those de-
veloped in Chapter 4, frequentist answers do not seem to be expressible 
as limits of Bayesian answers and we give in §5.3 a formal proof of this 
fact. Since p-values are strictly smaller than Bayesian answers (for levels 
which really matter in a testing decision-theoretic process), the null hy-
pothesis Ho is rejected more often under the frequentist approach, while 
the Bayesian approach shows that the ratio of the posterior likelihoods of 
Ho and HI is quite moderate for the usual significance levels (0.05 or 0.01). 
This important discrepancy between the two approaches definitely calls for 
Bayesian modeling, since this approach includes more naturally the notion 
of the probability of a hypothesis. It also shows that the argument of fre-
quentist validity, Le., the long-run justification provided by a significance 
level of 5% or of 1 %, is rather illusory and that the division introduced by 
the Neyman-Pearson theory in the treatment of Ho and HI (between type 
I and type II errors) leads to a bias in favor of the alternative hypothesis 
for larger values of x or T(x). 
A strong criticism of the above comparison and of the comparisons of 
Berger and Sellke (1987) and Berger and Delampady (1987) is that they are 
"meaningless," the two types of answers being conceptually different. This 
attack considers that one of the two answers should be "normalized" before 
the comparison. We show below that this criticism does not hold since, 
from a decision-theoretic point of view, p-values and Bayesian posterior 
probabilities are addressing the same inferential problem. Thus it does make 
sense to compare them directly. 
Consider an ao - al loss function as in (5.1). The UMPU minimax test 
is then 
<p(x) = {1 if p(x) : 
ao~al' 
o otherwIse. 
In fact, when power functions are continuous and hypotheses are contiguous 
(see Lehmann, 1986, Chap. 4), a UMPU test satisfies 
SUPp(/(<p(x) = 0) = a = inf p(/(<p(x) = 0) = 1- SUPp(/(<p(x) == 1). 
~ 
~ 
~ 
Moreover, when <p is minimax under this loss, it satisfies 

202 5. Tests and Confidence Regions 
supR(O,cp) = ao sup Pn('P(x) = 0) 
eo 
eo 
= supR(O, '1') = al supPn('P(X) = 1). 
e1 
e1 
Therefore, under regularity assumptions satisfied, for instance. by exponen-
tial families, 'I' is such that 
al 
supPn(cp = 0) =--
eo 
al + ao 
It then follows from Proposition 5.1 that it is legitimate to compare the 
p-value p(x) with posterior probabilities, since the Bayesian decision pro-
cedure is given by 
')'11"(x) = {1 if P11"(O. E 8 01x) > ao~a1' 
o otherWIse 
and both approaches compare a continuous evaluation (p-values or posterior 
probability) to the same bound. 
A second criticism, found for instance in Casella and Berger6 (1987), 
is that the lower bound is not computed on the set of all prior distributions 
since it only considers the prior probability eo = 1/2. Obviously, if eo can 
be modified too, it is always possible to find a Bayesian answer smaller than 
the p-value since the lower bound over all Bayesian answers is then 0 for 
every x (corresponding to eo = 0). A refined version of this criticism is to 
consider that the weight eo = 1/2 is not necessarily the most "objective" 
probability and that it should be determined in terms of the prior 'Tr itself. In 
fact, as mentioned above, priors of the form 'Tr(0) = eoino (0) + (1- eO)'Tr1 (0) 
are quite artificial. While such priors are necessary to solve the testing 
problem, it is more natural to think of 'Tr as a modification of the original 
priOr'Trl in the light of this problem. The inferential problem, i.e., the fact 
that 00 is of interest, contains some residual information strong enough to 
justify a modification of the prior distribution (otherwise, the test question 
should be modified to become compatible with the prior information). It 
thus makes sense to require that the weight eo should appear as a function 
Of'Trl. 
Example 5.6 (Cont.) Since Ho : ° 
= 0 is to be tested, the prior probability 
of Ho is null under any continuous prior 'Tri. Nonetheless, it is reasonable 
to require that Ho should have a larger prior probability if'Trl is N(O, 1) 
than if'Trl is N(O, 10), since every neighborhood of 0 is less probable under 
the latter distribution. This is why the Jeffreys-Lindley paradox is coined a 
"paradox": increase in the probabilities from Table 5.2 to Table 5.3 seems 
counterintuitive. 
b. 
Unfortunately, a determination of the weight eo as a function of 'Trl 
is quite controversial and we only briefly mention a solution proposed in 
6 Roger Berger, not James Berger! 

5.2. Comparisons with the Classical Approach 203 
Robert and Caron (1992), which constitutes a personal view (see Spiegel-
halter and Smith, 1980, for another approach based on the most favorable 
virtual observations). The basic idea is that the weight {!o should satisfy 
in order for ()o to be equally weighted under both hypotheses. Of course, we 
are comparing a weight under the Dirac mass at 0, eo, with an 'instanta-
neous' weight with respect the Lebesgue measure, (1 - eO)11"I(()O), and the 
comparison is not justified from a mathematical point of view (this may ac-
count for the controversy!). Moreover, the above equation does not always 
allow for a solution. 
Example 5.6 (Cont.) When 11"1(()) is a normal prior N(O,n), the above 
equality leads to the weight 
11"1 (0) 
eo = 1 + 11"1(0) 
1 
and the corresponding posterior probability of Ho is 
( 1+ 1-eoml(X))-1 = (1+)211" n eX2/2-x2/2(n+ll)-1 
eo 
'P(x) 
n+1 
( 
(2irn 
n 
X 2)-1 
= 
1 + V ;+1e 2(n+l) 
Note that this approach avoids the Jeffreys-Lindley paradox, since the lim-
iting probability (when n goes to +(0) is 
(1 + y'2;ex2 /2) -1 
This value also happens to be the posterior probability associated with the 
Lebesgue prior, 11"(()) = 1. 
6 
One-sided hypotheses (e.g., Ho: ()::; ()o versus HI: () > ()o) do not 
exhibit such contrasts between frequentist and Bayesian solutions. Indeed, 
as shown in Example 5.4, the p-value can be written as a generalized Bayes 
estimator and, therefore, as a limit of Bayesian answers (since renormalizing 
does not matter). Thus, it is impossible to exhibit a dichotomy between both 
approaches as in the two-sided case. Casella and Berger (1987) consider this 
setting and generalize the above "reconciliation" phenomenon. 
Theorem 5.7 Let x rv f(x - ()), with f symmetrical around o. 
The null hypothesis to be tested is Ho: ()::; o. If f is a mono-
tone likelihood ratio distribution, the p-value p( x) is equal to the 
lower bound on the posterior probabilities, E.(x, Gsu ), when this 
bound is computed for the class G su of unimodal symmetric prior 
distributions and when x > o. 

204 5. Tests and Confidence Regions 
Proof. In this case, the p-value is 
1
+00 
p(x) = Pe=o(X > x) = 
x 
f(t) dt 
and 
B(x, Gsu) = inf F"(B:::; Olx) 
7rEGs u 
. 
J~oo f(x - B)Jr(B) dB 
mf -'-;-+-=-00=--------
7rEGsu 1-00 f(x - B)Jr(B) dB 
. 
J~Kf(x-B)dB 
=lnf~~-----
K J~K f(x - B) dB' 
(5.6) 
due to the representation of symmetric unimodal prior distributions as mix-
tures of uniform distributions on [-K, K]. The monotone likelihood ratio 
property then implies that (5.6) is attained for K = +00. 
• • 
A consequence of Theorem 5.7 is that the lower bound of the Bayesian 
answers over all prior distributions is smaller than the p-value. 
Example 5.10 Consider X '" C(B,l), the Cauchy distribution, when the 
hypothesis to be tested is Ho: B:::; 0 versus HI: B > O. If the prior 
distribution of B is assumed to be in the class of distributions symmetric 
around 0, the lower bounds on the Bayesian answers and the corresponding 
p-values are given in Table 5.9. 
TABLE 5.9. Comparison between p-values and Bayesian posterior probabilities 
in the case of a Cauchy distribution. (Source: Casella and Berger, 1987.) 
p-value 
0.437 0.102 0.063 0.013 0.004 
P 
0.429 0.077 0.044 0.007 0.002 
The differences in the numerical values are not as striking as in the 
previous examples. 
l:::, 
The distinction between one-sided and two-sided cases calls for the 
following comments: 
(i) 
As mentioned several times above, Bayesian modeling in a two-sided 
setup is usually quite delicate, especially for point null hypotheses, 
since it implies a modification of the prior distribution which is imposed 
by the inferential problem. This is not contradictory with the Bayesian 
paradigm if we consider that this modification results from additional 
(if vague) information, but how to use this information remains unclear. 

5.3. A Second Decision-Theoretic Approach 205 
An illustration of this difficulty is the case of noninformative distribu-
tions where several (and not entirely compatible) Bayesian paradigms 
are competing. 
(ii) That the p-value is close to the lower bound in the one-sided case illus-
trates the conservative (or minimax) behavior of the procedure. As it 
may be written as a generalized Bayes answer, this induces us to think 
that the p-value could also be expressed as a noninformative answer 
in the two-sided cases. Obviously, this does not necessarily imply that 
this answer should be used since an effective use of the information 
contained in the testing problem itself is generally possible. 
(iii) p-values are derived from UMP or UMPU tests by an ad hoc empir-
ical construction. The comparisons in Berger and Sellke (1987) and 
Casella and Berger (1987) show that they differ (or do not differ) from 
their Bayesian counterparts. While these studies point out the exis-
tence of a theoretical problem, they are not, from a frequentist view-
point, sufficient to reject the use of p-values. It is thus necessary to 
use a decision-theoretic perspective which is adapted to the evaluation 
of p-values. The next section deals with this comparison. It also pro-
vides additional explanations for the two-sided/ one-sided dichotomy 
exhibited above. 
5.3. A Second Decision-Theoretic Approach 
As just stressed, p-values have no intrinsic justification, since they derive 
their claimed "optimality" from the optimality of the test procedures they 
are built on. In a sense, the same comment holds for the posterior probabil-
ities since, although they are intuitively justifiable, they are not validated 
by a decision process. In this section, we construct an alternative to the 
Neyman-Pearson approach in order to justify the posterior probabilities 
and evaluate the p-values. 
As shown in §5.1, the testing problem formalized by Neyman and Pear-
son can be expressed as estimating the indicator function Keo (0) under the 
0-1 loss or, equivalently, the absolute error loss 
(5.7) 
Indeed, if the estimators cp are only taking the values 0 and 1, there are 
many ways to write the 0-1 loss, (5.7) being one of them. But, as indicated 
above, the Neyman-Pearson theory is predominantly a "predata" theory 
which does not provide a "postdata" (or more adaptive) solution. We then 
turn to a less restrictive theory, where estimators take values in D = [0, 1] 
and can be considered as indicators of the degree of evidence in favor of 
Ho· 

206 5. Tests and Confidence Regions 
Parallel to Schaafsma et al. (1989) and van der Meulen (1992), Hwang 
et al. (1992) examine this alternative approach to testing, in which the esti-
mators of leo (0) belong to [0, 1]. When the restriction to {O, I} is dropped, 
the choice of the loss gets more important. For instance, (5.7) is too similar 
to the 0 - 1 loss function as it provides the same Bayes procedures 
'P1r(x) = {I if P7r(O. E 8 01x) > P7r (B fj. 8 0Ix), 
o otherWIse. 
In the opposite, strictly convex losses, such as the quadratic loss 
lead to more adaptive estimators. 
Proposition 5.8 Under the loss (5.8), the Bayes estimator associ-
ated with 1l" is the posterior probability 
(5.8) 
Indeed, the posterior expectation of leo (0) is nothing but the posterior 
probability of 8 0 . The quadratic loss (5.8) thus provides a decision-theoretic 
foundation to the use of posterior probabilities as Bayesian answers. Such 
losses are said to be proper (see Lindley, 1985, and Schervish, 1989; Exercise 
2.15 characterizes proper losses). There exist other proper losses in addition 
of the quadratic loss, but Hwang and Pemantle (1994) have shown that it 
is sufficient to consider the quadratic loss in terms of admissibility and 
complete classes (see Chapter 6). 
We consider in this section the special case of natural exponential fam-
ilies, 
f(xIO) = e8x-'¢(8) , 
o E 8 c JR, 
and we introduce the following definition, due to Farrell (1968a), which 
allows us to evaluate procedures on an interval when they are constant 
outside this interval: 
Definition 5.5 For a one-sided test, i.e., for hypotheses of the form 
Ho: O:S 00 versus HI: 0 > 00 , an interval [tl' t2] is said to be 
a truncation set for the estimator 'P if 'P(t) = 1 when t < iI and 
'P(t) = 0 when t > t2. For a two-sided test of Ho: 0 E [01, O2], the 
interval [tl' t2] is said to be a truncation set for the estimator 'P if 
'P(t) = 0 when t fj. [iI, t2]. 
The following results have been obtained in Hwang et al. (1992), based 
on a result of Brown (1986), which shows that every admissible estimator is 
a pointwise limit of Bayes estimators for a sequence of measures with finite 
supports (see §6.2.4): 
Theorem 5.9 For the two-sided problem 

5.3. A Second Decision-Theoretic Approach 207 
an estimator cp with truncation set ttl, t2J is admissible if there 
exist a probability measure ?To on [(h,02J and a a-finite measure 
?TI on [01, 02Jc such that 
J f(xIO)?To(O) dO 
cp(x) = J f(xIO)?To(O)dO + J f(xIO)?Tl(O) dO' 
(5.10) 
for x E [tl, t2J. Conversely, if cp is admissible, there exist [tl' t2], 
?To, and?Tl such that (5.10) is satisfied. 
In the one-sided case, we can only propose an admissibility necessary 
condition but it implies that the generalized Bayes estimators form a com-
plete class. 
Theorem 5.10 For the one-sided problem 
Ho: 0::; 00 
versus 
HI: 0 > 00 , 
(5.11) 
if cp is admissible, there exists an increasing procedure cp' such 
that cp' is (risk) equivalent to cp. If cp is an increasing admissible 
procedure and ttl, t2J is a truncation set such that 0 < cp(x) < 1 on 
[tl, t2], there exist two a-finite measures on J-oo, OoJ and [00, +00[, 
?To, and ?TI, such that 
1 = J 
etoO-,p(lJ) (?TO (0) + ?TI (0)) dO 
for tl < to < t2 and cp is given by (5.10) on [h, t2J. 
These two complete class theorems show that it is sufficient to con-
sider the generalized Bayes estimators to obtain admissible estimators un-
der quadratic loss. Theorem 5.10 shows in addition that the monotone 
estimators form an essentially complete class. These results can be used 
to evaluate p-values. Note again that the Bayes estimators are underly-
ing (classical) optimal estimators. (Chapter 6 exposes more thoroughly the 
Bayesian foundations of admissibility.) 
Recall also that Casella and Berger (1987) have shown that p-values 
were within the variation range of Bayesian posterior probabilities in one-
sided settings. It is therefore natural to examine the admissibility of p-
values. The examples below show that they are admissible for most one-
sided tests. 
Example 5.11 Consider again x'" N(O, 1) and Ho of the form (5.11). We 
showed in Example 5.4 that 
p(x) = POo(X > x) = 1- <I>(x - 00) 

208 5. Tests and Confidence Regions 
is a generalized Bayes estimator with respect to the Lebesgue measure. 
Moreover, the risk of the p-value is 
1+00 
r(?r, p) = -00 R(p, 0) dO 
1+00 1+00 
= -00 -00 (p(x) - lleo(O))2 f(xIO) dxdO 
1
00 1+00 
= -00 -00 (1 - <l>(x - ( 0))2 f(xIO) dx dO+ 
r+oo 1+00 
Joo 
-00 <l>(x - ( 0)2 f(xIO) dx dO 
1+00 
= 2 -00 (1 - <l>(x - OO))2<l>(X - (0 ) dx 
by the Fubini Theorem. This integral is finite. Therefore, r(?r) < +00 and 
cp7r is admissible under (5.8) (see §2.4). 
6. 
Example 5.12 Consider x '" B(n,O). The p-value for the test of (5.10) is 
then 
p(x) = POo(X ~ x) = ~ 
(~)O~(l- oot-x, 
which is also a generalized Bayes estimator under the prior distribution 
?r(O) = I/O. It is again possible to show that p has a finite Bayes risk 
and is thus admissible. A similar result can be established for a Poisson 
distribution, P(O) (see Hwang et al., 1992). 
6. 
In two-sided settings, on the contrary, p-values are not admissible, as 
suggested by the comparisons of Berger and Sellke (1987) and Berger and 
Delampady (1987). 
Theorem 5.11 For the test of (5.9), when the sampling distribution 
is continuous with respect to the Lebesgue measure, the p-value is 
inadmissible for the loss (5.8). 
Proof. The result relies on the fact that the p-value p is equal to the value 
1 with positive probability (see Hwang et al., 1992, §4.1.2). In fact, if p were 
admissible, it can be written under the form (5.10). Since it is positive, 
Therefore, by continuity, the equality (5.10) holds everywhere andp(xo) = 1 
implies ?r = ?ro, i.e., p(x) = 1 for every x, which cannot true. 
__ 
This result agrees with the observations of Berger and Sellke (1987) 
who showed that p-values do not belong to the range of Bayesian answers. 

5.4. Confidence Regions 209 
It thus justifies the rejection of p-values for two-sided hypotheses. Further-
more, Hwang and Pemantle (1994) show that the inadmissibility of p-values 
can be extended to most bounded proper losses. As a concluding note, let 
us point out that it is now necessary to construct estimators dominating 
the p-values. In the normal case, Hwang et al. (1992) show that it cannot 
be done using a proper Bayes estimator, but Hwang and Pemantle (1994) 
give numerical arguments in favor of a dominating estimator. 
5.4. Confidence Regions 
Apart from providing a decision-maker with approximations of the "true" 
value of a parameter (), namely, point estimators, and with answers to ques-
tions about the inclusion of () in a specific domain, i.e., testing procedures, 
it is sometimes necessary to give in addition confidence regions on (), i.e., 
subsets Cx of the parameter space e where () should be with high proba-
bility (in the frequentist or in the Bayesian sense). This is particularly of 
interest in forecasting settings. 
In the Neyman-Pearson theory, confidence regions can be deduced 
from UMPU tests by a duality argument: If 
Ce = {x; cpe(x) = I} 
is the acceptance region for the null hypothesis Ho: () = ()o, CPeo being a 
UMPU test at level a, the corresponding confidence region is 
Cx = {(); x E Ce} 
= {();cpe(x) = I} 
and P(() E Cx) = I-a. More generally, a region Cx is said to be a confidence 
region at level a (in the frequentist sense) if, for every () E e, P(() E Cx) 2: 
I-a. 
Example 5.13 If x rv N((),0'2), the 95% UMPU test is cpe(x) = 1[0,1.96] 
(Ix - ()I/O') and the corresponding confidence region, when 0' is known, is 
Cx = [x - 1.960', X + 1.960'J. 
Example 5.14 Consider x rv Tp(N, (), Ip), 
t-distribution with N degrees of 
freedom, and density 
( 
1 
) -(N+p)/2 
f(x I ()) ex 
1 + N II x - () 112 
Since ~ II x - () 11 2rv F(p, N), we can derive a 1 - a% confidence ball 
Cx = {(); II x - () 11 2:s pfo(P, N)} , 

210 5. Tests and Confidence Regions 
where fo(P, N) is the a-quantile of F(p, N). 
These confidence regions, although used quite extensively in practice 
(for instance, in the case of the linear regression), have been criticized on 
frequentist, conditional, and Bayesian grounds. First, as seen in the previ-
ous sections, the Neyman-Pearson approach itself is not free of drawbacks 
and the optimality of UMPU tests can be contested. Therefore, confidence 
regions derived from these tests (called uniformly most accumte regions by 
Lehmann, 1986) do not necessarily have a proper behavior. Moreover, even 
fro1I1 a frequentist perspective, the inversion of optimal test procedures into 
confidence regions does not automatically grant these regions with a derived 
optimality, despite the above denomination. 
A first critical assessment of the Neyman-Pearson confidence regions 
follows from the conditional analysis of Kiefer (1977) and Robinson (1979). 
Lehmann (1986, Chap. 10) gives an overview of this approach (see also 
Buehler, 1959, Pierce, 1973, Casella, 1987, 1992, Maata and Casella, 1990, 
and Goutis and Casella, 1991). These works have shown that the classical 
confidence procedures are often suboptimal when considered from a condi-
tional viewpoint. 
Definition 5.6 Consider Cx, a confidence region at significance 
level a. A set A c X is said to be a negatively biased relevant 
subset for the confidence region Cx if there exists E > 0 such that 
Pe(O E Cxlx E A) :::; 1- a -
E 
for every 0 E e. 
We can define similarly positively biased relevant subsets. This notion 
is generalized in Robinson (1979) into the concept of relevant betting proce-
dures. The existence of such sets questions the very notion of a confidence 
level a since, depending on the conditioning set, the coverage probability 
may vary and even fall below the nominal minimal confidence statement. 
Obviously, this criticism can be transfered to testing procedures by a du-
ality argument. In the setup of Example 5.14, while working on t-tests, 
Brown (1967) establishes that there exist positively biased relevant sets of 
the form {Ixl < k} and this implies 
Pe(O E Cxllxl > k) :::; 1- a 
(see also Exercise 5.41). Such phenomena led Kiefer (1977) to suggest a 
partition of the sample space X into subsets and to allocate each of these 
subsets with a different confidence level (see also Brown, 1978). Following 
Fisher's analysis, he suggested that these subsets should be indexed by an-
cillary statistics. For instance, the adequate ancillary statistic for Example 
2.4 is Xl -
X2. Unfortunately, in most settings, the choice of the ancillary 
statistic modifies the confidence report, and Berger and Wolpert (1988) 

5.4. Confidence Regions 211 
give an example in which different ancillary statistics lead to different con-
fidence statements, a setup incompatible with the Likelihood Principle. We 
consider that, fundamentally, the problem exhibited by the existence of rel-
evant biased sets is not related to the confidence region ex itself but rather 
with the associated confidence level a, which should be replaced by a more 
adaptive (or more conditional) confidence statement a(x) (see §4.2). In fact, 
the existence of relevant betting procedures is equivalent to the domination 
of the constant confidence report under quadratic loss (see Robinson, 1979). 
Usual confidence regions can also be criticized from a frequentist per-
spective. Following Stein (1962a) and Lindley (1962), Brown (1966) and 
Joshi (1967) have indeed established that these regions e~ are not always 
optimal in the following sense: there may exist another set e~ such that 
Pe(B E e~) 2: Pe(B E e~) 
and 
vol(e~):::; vol(e~). 
Therefore, the set e~ is to be preferred to e~ since, for a smaller volume, 
it has a larger probability of containing the true value of the parameter. 
For instance, in the normal case, Joshi (1969) has established that, if x "-' 
Np(B, Ip), the confidence region 
is admissible (in the above sense) if and only if p :::; 2 (see also Cohen and 
Strawderman, 1973). For larger dimensions, it is possible to exhibit more 
efficient confidence regions. This phenomenon pertains to the Stein effect 
establishing the inadmissibility of the maximum likelihood estimator for 
p 2: 3 (see §2.4.5). Hwang and Casella (1982) have taken advantage of this 
analogy to show that, if 
JS 
a 
( 
) + 
fj 
(x) = 
1 - IIxl1 2 
X 
is a truncated James-Stein estimator, the recentered confidence region 
has the same volume as the usual ball e~ and satisfies 
(5.12) 
for a small enough. Therefore, e;!,s dominates e~ in the above sense. An 
extensive amount of literature on this subject of recentered confidence re-
gions has been initiated by Hwang and Casella (1982, 1984), similar to the 
point estimation literature outburst associated with the Stein effect (see 
§2.4.5). New recentered regions have been proposed in Hwang and Casella 
(1984) and Casella and Hwang (1983, 1987). Hwang and Chen (1986) and 
Robert and Casella (1990) have extended domination results to spherically 
symmetric distributions, although the case of the unknown variance normal 

212 5. Tests and Confidence Regions 
problem is still unsolved (see Hwang and Ullah, 1994). Shinozaki (1990) has 
also devised a confidence region with exactly the same coverage probability 
but with a smaller volume, taking advantage of the inadmissibility of the 
usual region the opposite way to (5.12). Lu and Berger (19S9a), George 
and Casella (1994), and Robert and Casella (1993a) have also taken ad-
vantage of (5.12) to propose improved confidence reports for the usual and 
recentered sets. For the problem of estimating a normal variance, similar 
improvements can be found in Cohen (1972), Shorrock (1990), and Goutis 
and Casella (1991). 
As in the testing setup, the Bayesian paradigm proposes an alternative 
notion of confidence regions, which is more natural since, again, the notation 
P(() E Cx) is meaningful even conditionally on x. 
Definition 5.7 For a prior distribution 7r, a set Cx is said to be an 
a-credible set if 
P""(() E Cxlx) ~ 1- a. 
This region is called an HPD a-credible region (for highest poste-
rior density) if it can be written under the form7 
{(); 7r(()lx) > ka } C C; C {(); 7r(()lx) ~ ka }, 
where ka is the largest bound such that 
P""(() E C~lx) ~ 1 - a. 
To consider only HPD regions is motivated by the fact that they min-
imize the volume among a-credible regions. 
Example 5.13 (Cont.) If () rv N(O, T2), the posterior distribution of () is 
N(/L(x),w- 2 ) with w2 = T- 2 + 0--2 and /L(x) = T 2X/(T2 + 0-2 ). Then 
where ka is the a/2-quantile of N(O, 1). In particular, if T goes to +00, 7r(()) 
converges to the Lebesgue measure on 1R and gives 
i.e., the usual confidence interval, as a generalized Bayes estimator. 
6 
Example 5.15 Consider x rv B(n,p) and the noninformative distribution 
P rv Be(1/2, 1/2). Then pix rv Be(x + 1/2, n - x + 1/2) and confidence 
intervals on p can be derived from the c.d.f. of the beta distribution. Table 
5.10 gives these intervals for n = 5 and a = 5%, 10%. 
!:::. 
7 This formulation allows for coverage of the special case when {8;Jr(8Ix) = kn } 
is not empty. 

5.4. Confidence Regions 213 
TABLE 5.10. Confidence intervals for the binomial distribution. 
x 
0 
1 
2 
a=5% 
[0.000,0.38] 
[0.022,0.621] [0.094, 0.791] 
a= 10% [0.000,0.308] [0.036,0.523] 
[0.128,0.74] 
Note the significant advantage of using a Bayesian approach in this setup 
of discrete distributions, as compared with a classical approach. In fact, the 
usual confidence intervals involve a randomization step to attain nominal 
confidence levels (see Blyth and Hutchinson (1961) for an illustration in 
the binomial case). Prior modeling avoids this addition of random noise 
and, on the contrary, takes advantage of the available prior information. 
Note also that improper priors can be used in this setting and do not 
encounter the same difficulties as for testing point null hypotheses. In fact, 
posterior credible regions can be derived as long as the posterior distribution 
is defined. Some classical confidence regions can be expressed as credible 
regions associated with generalized distributions. 
Example 5.16 Consider Xl, ... , Xn i.i.d. N((), (72). The prior distribution is 
the noninformative prior 
2 
1 
7r((), (7 ) = 2"' 
(7 
We showed in §4.3.2 that the marginal posterior distribution for 1/(72 is a 
gamma distribution 9 ((n - 1)/2, s2/2) with s2 = L:(Xi - X)2. Therefore 
2 
S 
_ 
2 
2 
2"ix,s rvXn_l, 
(7 
and we get the same confidence interval as in the classical approach, but it 
is now justified conditionally on S2. 
£:::,. 
Example 5.17 Consider x rv B(n,p) and p rv Be(a,j3). In this case, 7r(pix) 
is the beta distribution Be(a + X, 13 + n - x). Depending on the values of 
a, 13, n, and x, the confidence regions are of four types: 
(i) O:::;p:::;K(x); 
(ii) K(x) :::; p:::; 1; 
(iii) Kl(X) :::; p :::; K2(X); and 
(iv) 0:::; p:::; Kl(X) or K2(X) :::; p:::; l. 
The last region is quite artificial and rather useless. Note that it corresponds 
to the case 
a + X < 1, 
13 + n - x < 1, 
thus implies a < 0 or 13 < O. These generalized distributions are usually 
unacceptable, since the limiting case a = 13 = 0, which corresponds to 
Haldane's (1931) distribution 
7r(p) = [P(l - p)r l , 

214 5. Tests and Confidence Regions 
is already strongly criticized and the corresponding posterior distributions 
are not defined for all x's (see also Example 1.19). 
t::,. 
When phenomena like those of Example 5.17 occur, i.e., when the con-
fidence region is not connected (see also Exercise 5.12), the usual solution 
is to replace the HPD a-credible region by an interval with equal tails, i.e., 
[C1(X),C2(x)] such that 
P7r(O < C1(x)lx) = p7r(O > C2(x)lx) = a/2. 
Berger (1985a) notes that the occurrence of nonconnected HPD regions also 
points out a discrepancy between the prior distribution and the observations 
and that this phenomenon should question the choice of the prior or of the 
sampling distribution. 
If, conceptually, the determination of credible sets is rather straight-
forward, the practical derivation of these regions can be quite involved, 
especially when the dimension of e is large or when the posterior distribu-
tion is not available in a closed form. A first solution is to use numerical 
methods similar to those developed in Chapter 9, the problem being to 
assess the impending error (which can be much larger than the point esti-
mation approximation errors). A second solution, used in Berger (1980a), 
is to build up a normal approximation, i.e., to consider that the posterior 
distribution of 0 is roughly Np (lE7r(Olx) , Yar7r (Olx)), and to derive from this 
approximation the confidence region 
Co. = {O; (0 -lE7r(O I x))tYar7r(Olx)-l(O -lE7r(Olx)) :s k~}, 
where k~ is the a-quantile of X~. This approximation is only justified for a 
large sample size (see Hartigan, 1983), but it still provides fast and rather 
efficient confidence regions (see also Berger, 1985a). 
As the reader may have noticed, the above construction of confidence 
regions has been done in a rather off-handed manner, with no decision-
theoretic justifications. The choice of HPD regions is usually related to a 
volume minimization requirement, under the coverage constraint 
P(O E Calx) ~ 1 - a. 
Several authors have proposed alternative derivations of confidence regions 
according to a purely decision-theoretic criterion. They consider loss func-
tions which incorporate at once volume and coverage requirements. (In a 
way, the above approach corresponds to a bidimensional loss with compo-
nents vol(C) and 1-IdO).) For instance, a simple version of this decision-
theoretic perspective is to consider the linear combination 
L(C, 0) = vol(C) + C:U:li~C' 
(5.13) 
leading to the risk 
R(C, 0) = lE(vol(Cx )) + cP(O tf- Cx). 

5.4. Confidence Regions 215 
(The constant c can be related to a particular confidence level.) In addition, 
Cohen and Sackrowitz (1984) have shown that the above bidimensional loss 
can be related to the linear loss (5.13) when c is considered as an additional 
parameter of the model. Meeden and Vardeman (1985) also propose differ-
ent evaluations of Bayesian confidence regions. They show that admissible 
and Bayesian confidence sets are equivalent for some criteria. An important 
defect of the linear loss has been pointed out by James Berger (see Casella 
et al., 1993a,b). The problem is a consequence of the unequal penalization 
between volume and coverage. In fact, the indicator function varies between 
o and 1 while the volume can increase to infinity and this asymmetry leads 
to a bias in favor of small confidence sets. 
Example 5.18 Consider Xl, ... ,Xn Li.d. N((),a2). The classical t-interval 
on (), 
Ck(X,8) = (X-k In,x+k In), 
is an HPD region when 
n 
n 
X= Lxdn, 
8 2 = L(Xi - x)2/(n - 1), 
2 
1 
and 7r((), a ) = 2' 
a 
i=l 
i=l 
Jeffreys noninformative distribution. Indeed, in this case, 
()-x 
vn -- I X,8 rv 'Tn-ll 
8 
Student's t-distribution with n - 1 degrees of freedom. Under (5.13), the 
posterior loss is 
8 
g(7r, Ck(X, 8)lx, 8) = 2k Vn - cP1r (() E Ck(X, 8)lx, 8) 
8 
= 2k Vn - cP(ITn-ll ::; k). 
Then, it is easy to see that the HPD region is dominated by the truncated 
region 
G'(X 8) = {Ct(X, 8) if 8 < Vnc/(2k), 
t, 
{x} 
otherwise. 
This domination is counterintuitive, C: proposes the single point {x} (or 
equivalently 0), seemingly indicating certainty, when the empirical vari-
ance increases, indicating growing uncertainty. A similar phenomenon oc-
curs when k depends on 8, i.e., the size of the credible region decreases to 
o as 8 increases (see Casella et al., 1993a,b). 
6. 
The above paradox exposes the limitations of the linear loss (5.13). 
Casella et al. (1993a) propose an alternative class of loss functions which 
avoid the paradox. The simplest of these losses are the so-called rational 
losses 

216 5. Tests and Confidence Regions 
vol( C) 
L( C, B) = vol( C) + k + llof/'c 
(k > 0), 
where both terms are then bounded by One. The Bayes estimators asso-
ciated with these losses are still HPD regions but remain nonempty for 
all conjugate priors in the normal case. The parameter k can be obtained 
through techniques similar to those developed for regular losses, namely, by 
comparing the volume penalizations associated with different regions and 
approximating the utility function. 
We do not pursue any further the decision-theoretic study of Bayesian 
confidence regions. Indeed, an important aspect usually overlooked in the 
derivation of confidence regions deals with how they will be used, although 
this very use is essential in the construction of the loss function. In fact, 
the decision maker's purpose can be 
(1) to consider set estimation as a preliminary step to point estimation 
(and, for instance, derive a prior distribution with support equal to 
the estimated confidence region); 
(2) to rely On the obtained confidence region to solve a testing problem 
(and reject a null hypothesis if the confidence region does not contain 
a specific value); 
(3) to derive from the size (volume) of the confidence region an indicator of 
the performances of an associated estimator, for instance, the center of 
the region. A performance curve for this estimator can then be derived 
by relating size and confidence levels. 
These three perspectives of confidence region estimation definitely lead 
to different loss functions and it may be illusory to try to build up a global 
loss function unifying such contrasted purposes. In fact, separate losses are 
preferable since, in accordance with the foundations of Decision Theory, 
the decision maker should select a loss function according to his/her needs. 
Note also that the three purposes considered above correspond to inferential 
problems already studied previously and thus that a specific approach to 
confidence regions may be partially useless. Therefore, it seems to us that, 
at least, a more conditional approach should be used in the construction 
of confidence regions. Following Kiefer (1977), we suggest associating to a 
given set Cx a confidence index ')'(x), evaluated under the loss 
(5.14) 
The confidence region is thus replaced by a confidence procedure, related 
to the conditional perspective of Robinson (1979). From this point of view, 
the procedure [8,1] is unfortunately "perfect", a drawback which indicates 
that an additional evaluation of Cx should be included in the loss function, 
as in Rukhin (1988a,b). Similarly, the Bayesian procedure associated with 
an HPD region Co. is [Co., 1 - a], as can be verified by minimizing the 
posterior loss. For an arbitrary region, Cx, the corresponding procedure is 
[Cx, ')'1r(x)], where 

Exercises 217 
Introducing a global loss function which combines volume, coverage, and 
confidence report as (5.14), the optimal procedures would then be those 
which minimize the maximal posterior (or frequentist) error. However, this 
direction has not been yet studied in the literature. 
Exercises 
Section 5.1 
5.1 In the setup of Example 5.3, study the modification of the posterior proba-
bility of Ho when x = 0 and T / 0- goes to +00. Compare with the noninfor-
mative answer associated with 7l'(B) = 1. 
5.2 Consider x rv P()"). The hypothesis to test is Ho: )..::; 1 versus H1 : ).. > 1. 
Give the posterior probability of Ho for x = 1 and)" rv 9(0:, (3). 
a. How does this probability get modified when 0: and (3 go to O? Does this 
answer depend 011 the rates of convergence of 0: and (3 to O? 
b. Compare with the probability associated with the noninformative dis-
tribution 7l'()..) = 1/)". Is it always possible to use this improper prior? 
5.3 Consider x rv B(n,p), Ho: p = 1/2, and H1 : p i- 1/2. The prior 
distribution 7l'(p) is a beta distribution Be( 0:,0:). Determine the limiting 
posterior probability of Ho when n = 10, x = 5 and n = 15, x = 7 as 0: goes 
to +00. Are these values intuitively logical? Give the posterior probabilities 
for Laplace, Jeffreys, and Haldane noninformative priors. 
5.4 Solve Exercises 5.2 and 5.3 for the Bayes factors instead of the posterior 
probabilities. 
5.5 When x rv N(B, 1) and B rv N(O, 0-2 ), compare the Bayesian answers for the 
two testing problems 
when E and 0- vary. 
HJ: () = 0 versus Ht: () of- 0, 
H6: IBI::; E versus Hi: IBI > E, 
5.6 In the setup of Example 5.2, if x rv B(n,p) and Ho : p = 1/2 is to be tested, 
study the variation of the Bayesian answers as a function of n for x = 0 and 
x = n/2 if the prior distribution is the Jeffreys distribution. 
5.7 Consider x rv N ( B, 1). The hypothesis to test is H 0: I B I ::; c versus H 1 
IBI > c when 7l'(B) = 1. 
a. Give the graph of the maximal probability of Ho as a function of c. 
b. Determine the values of c for which this maximum is 0.95 and the Bayes 
factor is 1. Are these values actually appealing? 
5.8* (Berger and Delampady, 1987) Consider x rv N(B, 1). The purpose of the 
exercise is to compare Ho: IB-Bol::; E with the approximation H5 : B = Bo. 
Denote by 90 and 91 the prior densities on {I B - Bo I ::; E} and {I B - Bo I > E}. 
Let 9 be a density on lR such that 
9((}) ex: 91((}) 
if IB - (}ol > E, 

218 5. Tests and Confidence Regions 
and 
A = 1 
g(B) dB, 
le-eol~€ 
is small enough. We denote 
B = ~e-eol<€ f(xIB)go(B) dB 
~e-eOI>f f(xIB)gI (B) dB 
t = (x - Bo) and 
and B = f(xIBo) = 
f(xIB) 
mg(x) 
J f(xIB)g(B) dB' 
1 
'Y = 2€'P(t) [<p(t + €) - <p(t - €)] - 1. 
Show that, if It I ;::: 1, € < Itl- 1, and B :::; (1 + 'Y)-I, then 
B = B(1 + g) 
with 
5.9 In a normal setting, determine whether there exists a normalization prob-
lem associated with noninformative prior distributions for tests of one-sided 
hypotheses as 
Ho: BE [0,1] 
versus 
HI: B > 1. 
Replace 1 by € and consider the evolution of the optimal answer as € goes 
to O. 
5.10 A professor at Cornell University has to give an examination on two differ-
ent days. Since students are sitting next to each other, he gives two different 
examinations alternatively to students in order to reduce cheating. He then 
repeats the same technique with a different class and the same two exam-
inations the next day. The results are as follows: nIA = 17 students took 
examination A the first day and n2A = 19 the second day, nIB = 15 took ex-
amination B the first day and n2B = 19 the second day. The average grades 
(out of 20) are {LIA = 10.3, {L2A = 10.2, {LIB = 7.9, and {L2B = 8.7, with 
standard deviations o-IA = 2.67, o-2A = 2.89, o-IB = 2.98, and o-2B = 2.91. 
a. Test whether there is a class effect, an examination effect, or a class-
and-examination effect by modeling the results in an analysis of vari-
ance setup, namely, by assuming that each student grade x is normally 
distributed with mean /Lo + /Le + /Lc and variance cr;c (e = A, B, c = 1,2) 
where /LA + /LB = 0, /LA + /LB = O. 
b. A student forgot to give back his copy of examination A the first day. 
Can you detect a cheating effect on the second day? 
5.11 (Pearl, 1988) After communicating a rumor to a neighbor, you hear it again 
from the same neighbor a few days after. Build up a model to test whether 
your neighbor has also heard this rumor from another person. 
5.12* Consider two independent standard normal observations x and y. The polar 
coordinates of (x,y) are (r,B), with x = rcosB and y = rsinB. 

Exercises 219 
a. Given that 2r2 = (x - y)2 + (x + y? and that x - y and x + yare 
independent, show that the distribution of r2 given x = y is 9(1/2,1). 
b. Show that rand () are independent and deduce that the distribution of 
r2 given () = 7r /4, 57r /4 is 9(1/2,1/2). 
c. Since {x = y} = {() = 7r / 4, 57r / 4}, explain the apparent paradox of the 
two different conditional distributions for a same event. (Hint: Replace 
the conditioning in a proper perspective of cr-algebras and compare the 
cr-algebras spanned by x - y and by ().) 
Section 5.2.1 
5.13 Let f and 9 be two nondecreasing real functions. 
a. Show that 
lEo[f(x)g(x)] 2: lEo[f(x)]lEo[g(x)] 
for every distribution Po on x. 
b. Use a. to show that, if f(xl(}) is a monotone likelihood ratio density 
in T(x), the expectation lEe[g(T(x))] is a nondecreasing function of (). 
(Hint: Use f(x) = 1- f(xl(}')/f(xl(}) and show that lEe [f(x)] = 0.) 
5.14 Show that Student's t and noncentral X2 distributions have monotone like-
lihood ratio. 
Section 5.2.4 
5.15 For the p-value p defined in Example 5.9, determine the values of p(x) for 
n = 15 and compare with 
p(x) = Pl / 2 [f(XI1/2) > f(xI1/2)]. 
5.16 (Johnstone and Lindley, 1994) Consider a point null hypothesis Ho : () = (}o 
where the p-value 'P is well defined. The only available information is that 
the data is significant at level a, i.e., that rp(x) < a. 
a. Give the Bayes factor Ra of Ho versus Hl : () =I (}o when the data are 
significant at level a, for an arbitrary prior distribution 7r. 
b. Given a second significance level (3 with (3 < a, we assume that Ra < R(3. 
Establish a sufficient condition on 7r for this condition to be satisfied. 
c. If Ral(3 is the Bayes factor based on the information (3 < rp(x) < a, show 
that Ra = wR(3 + (1 - w)Ral(3 and deduce that R(3 > Re, > Ral(3· 
d. In the particular case when 7r((}) is /?o][eo((}) + (1 - /?o)N((}o,r2) and 
Xl, ... , Xn rv N((}, cr2), show that Ra converges to (1 - /?o)/ /?oa when n 
goes to infinity but that Ral(3 goes to O. 
Section 5.2.5 
5.17 For x rv N((}, 1) and Ho: () = 0, determine when the p-value crosses the 
lower bounds E(x, GA) and E(x, Gs). 
5.18 (Berger and Delampady, 1987) Consider the case x '" 13(n,p) when Ho : 
p = 1/2. For the following class of prior distributions: 
Gc = {conjugate distributions with mean 1/2}, 
show that 

220 5. Tests and Confidence Regions 
E(x, Gc) = inf P(Holx) 
gEGc 
[ 
1 -7ro 
r(c)r(x + c/2)r(n - x + C/2)]-1 
= 1 + -- sup -'--'----'-::--:--,-'-:-:,.:...,-,.:-----,--'--'-
7ro 
c>o 
r(c/2)2 r(n + c) 
and derive a table of these lower bounds and the corresponding p-values for 
n = 10,20,30 and x going from 0 to n/2. 
5.19* (Casella and Berger, 1987) Establish the following lemma, used in Lemma 
5.6 and Theorem 5.7: if the family G is constituted of the mixtures 
g(8) = i g~(8)h(e) de, 
for every density h on :5, with g~ E Go and 
Go = {g~; e E :5}, 
then, for any f, 
:~~ J 
f(xI8)g(8) d8 = ~~~ J 
f(xI8)g~(8) d8. 
5.20 In the case when x '" N(8, 1) and Ho: 8::; 0, determine the lower bound 
E(x,Gsu)= inf pg(8::;0Ix) 
gEGSU 
= inf 
f~oo f(x - 8)g(8) d8 
gEGsu r:: f(x - 8)g(8) d8 
for x < O. Does the conclusion of Casella and Berger (1987) still hold? Can 
you explain why? 
5.21 * (Casella and Berger, 1987) Consider a bounded symmetric unimodal func-
tion, g. The family of the scale mixtures of 9 is defined by 
G g = {7r".; 7r".(8) = (1/u)g(8/u), u > O}. 
If the sample density is f(x - 8), with f symmetric in 0, if it satisfies the 
monotone likelihood ratio property, and if x > 0, show that 
E(x, Gg ) = p(x) 
for the test of Ho: 8::; O. 
5.22* (Casella and Berger, 1987) Consider the test of Ho: 8::; 0 versus H1 : 
8> 0 when x '" f(x - 8). Let hand 9 be densities on (-00,0] and (0, +(0). 
a. Show that, if 7r(8) = goh(8) + (1 - go)g(8), 
supp"(e::; Olx) = 
gOf~X2 
h 
gof(x) + (1 - go) fo 
f(x - 8)g(8) d8 
and deduce that the supremum actually favors Ho by putting all the 
mass at the boundary e = o. 

Exercises 221 
b. If 
show that, when cr1 is fixed 
lim p"(e:::; Olx) = 1 
(72 -+00 
and that, when cr2 is fixed, 
lim p"(e:::;olx) =0. 
al -+00 
5.23* (Caron, 1994) In order to alleviate criticisms directed toward point null 
hypotheses, Ho : e = eo, the formulation of the null hypothesis can be 
modified according to the prior distribution. For instance, given a prior 
distribution 7r on e with mode in eo which does not give any prior weight 
to eo, we can propose the transformed hypothesis Ho : 7r(e) > k", where 
the size of the HPD region is determined by the "objective" requirement 
7r(7r(e) > k") = 0.5. Consider the case x '" N(e, 1) and eo = O. 
a. When 7r belongs to the family of the N(O, cr2) distributions, determine k" 
and derive the lower bound on the Bayesian answers within this family. 
Compare with the posterior probabilities of Berger and Sellke (1987) for 
the values of interest. 
b. Determine whether the Jeffreys-Lindley paradox occurs in this approach. 
c. For the alternative families U[-c,c] (c > 0) and 7r(el>') ex exp(->'Iel) 
(>. > 0), derive the corresponding lower bounds. 
5.24* (Cont.) Consider the case x '" C(e, 1) when Ho : e = O. 
a. Under Berger and Sellke (1987) approach, show that the posterior prob-
ability of Ho when 7rc is U[-c,c] is 
7rc(Holx) = [1 + (1 + x 2)(arctan(c - x) + arctan(c + x))/2cr1 . 
b. Under the approach developed in the previous exercise, show that the 
corresponding probability is 
(H"I ) _ arctan(c/2 - x) + arctan(c/2 + x)) 
7rc 
a x -
. 
arctan(c - x) + arctan(c + x)) 
c. Compute and compare the lower bounds for both approaches. 
d. Show that 
1. 
infc7rc(Holx) 
2 
1m 
-
x~oo infc7rc(Holx) 
3 
Section 5.3 
5.25 (Hwang et ai., 1992) Show that, under the loss (5.8), the p-values defined 
in Example 5.12 are indeed admissible. (Hint: Show that the Bayes risks are 
finite. ) 
5.26 (Hwang et al., 1992) The goal of this exercise is to show that, for the two-
sided test (5.9), the p-value p(x) can take the value 1. (Hint: Remember 
that the UMPU test in this setup is of the form 

222 5. Tests and Confidence Regions 
(x) = {o if T(x) < Co or T(x) > Cl, 
'P 
1 otherwise, 
with CO = co(a:) and Cl = Cl(a:).) 
a. Consider (}l -# (}2 and 
C· = inf{T(x); f(xl(}2) > f(xl(}l)}. 
Show that c· E [cO(a:),Cl(a:)] for every 0 < a: < l. 
b. Consider (}l = (}2. Apply the previous result to 
and conclude. 
5.27 (Hwang et al., 1992) In the normal setup, consider the point null hypothesis 
Ho : () = o. Show that, under the loss (5.8), the p-value cannot be dominated 
by a proper posterior probability. (Hint: Show first that, for every a and E, 
when () goes to infinity.) 
5.28 (Hwang et al., 1992) Under the loss (5.8), show that 'P(x) = 1/2 is the 
unique minimax estimator. Extend to all strictly convex losses. In this setup, 
does there exist least favorable distributions? 
5.29 (Robert and Casella, 1993b) A modification of the loss function (5.7) in-
troduces a distance weight in order to penalize in a different maner errors 
made in the vicinity of the boundary between H 0 and H 1 and those made 
far away from this boundary. 
a. If the null hypothesis is H 0 : () ~ (}o for x rv N ( (), 1) and the loss function 
is 
give the general form of the Bayes estimators. 
b. If 7r((}) = 1, show that the Bayes estimator is smaller than the p-value if 
x > (}o and larger if x < (}o. 
5.30 (Robert and Casella, 1993b) In a model-choice perspective, the loss function 
incorporates the consequences of an acceptance or of a rejection of the null 
hypothesis Ho : () = (}o in terms of estimation. 
a. For the loss function 
L l ((), ('P, 8)) = d((} - 8)11 - 'PI + d((}o - (})I'PI, 
show that the Bayes estimators are (0, 871" (x)) where 871" (x) is the regular 
Bayes estimator of () under d( () - 8) for every d and 7r. 
b. For the loss function 
L 2 ((}, ('P, 8)) = d((} - 8)11 - 'PI + d((}o - 8)1'P1, 
show that the Bayes rule is (1, (}o) for every 7r and d. 
c. For the loss function 

Exercises 223 
show that the associated Bayes rule is (0, (}o), i.e., that the Bayes pro-
cedure always rejects the null hypothesis Ho : () = (}o but always uses (}o 
as an estimator of (). 
d. Study the Bayes procedures under the modified loss 
to examine whether they are less paradoxical. 
e. Show that the loss function 
provides a reasonable 'pre-test' Bayes procedure which avoids the para-
doxes of Ll, L2 , and L3 if and only if € > 1. 
Section 5.4 
5.31 Consider two independent observations Xl, X2 from a Cauchy distribution 
C((), 1). For 7r((}) = 1, give the shape of the a-credible HPD region. Which 
alternative (and more appealing) a-credible region could you propose? 
5.32* Domination of the usual estimator as center of a confidence region does 
not necessarily follow from the corresponding domination for the quadratic 
loss. Show that, in the normal case, if 
JS 
( 
a) 
6a (x) = 
1 -
IIxl1 2 
x, 
the recentered confidence region 
does not dominate the usual confidence region, even though 6~s dominates 
60 when a ::; 2(p - 2). (Hint: Consider () = 0.) 
5.33 Give the a-credible region when x rv P(A) and A rv 9(6, (3). Study the 
evolution of this region as a function of 6 and (3. Examine the particular 
case of the noninformative distribution. 
5.34* An alternative notion of a-credible regions is studied in this exercise. The 
best Bayes center at level a is the estimator 6~ (x), center of the ball of 
smallest radius with coverage 1 - a, i.e., 
P"(II() -
6~(x)11 < klx) = supP"(II(} - 6(x)11 < klx) = 1- a. 
6 
a. Show that, if the posterior distribution is spherically symmetric and 
unimodal, the corresponding region is the HPD region. 
b. Consider x rv N((},1), () rv N(0,r 2 ), and 7r(r2) = 1/r3/ 2 • Determine 
the posterior distribution. Show that this distribution is unimodal when 
o < x 2 < 2 and bimodal otherwise, with second mode 
( 
1- J1- (2/X2 )) 
6(x) = 
1 -
2 
x. 
Derive the best Bayes center and show that, if a is large enough, 6~ is 
discontinuous and close to 

224 5. Tests and Confidence Regions 
1 
+ 
¢(x) = (1- 2x2 ) x, 
i.e., that this Bayes estimator mimics the James~Stein estimator. 
c. Generalize b. in the case where 7r( 7 2 ) = 7~v. 
d. Show that the best Bayes center associated with a proper prior distri-
bution 7r is admissible under the loss 
5.35 (Casella and Berger, 1990) Consider x ""' N(J-L, 1) and 
Ca(x) = {J-L; min(O, x - a)::; J-L::; max(O,x + an· 
a. Consider a = 1.645. Show that Ca is a confidence interval at level 95% 
with 
PoCO E Ca(x)) = 1. 
b. If 7r(J-L) = 1 and a = 1.645, show that Ca is also a O.l-credible region and 
that 
P"'(J-L E Ca(x)lx) = 0.90 
if Ixl ::; 1.645 and 
lim 
P"'(J-L E Ca(x)lx) = 1. 
Ixl--++= 
5.36 (Casella et al., 1993a) Show that the rational loss given in §5.4, 
vol(C) 
L(O, C) = k + vol(C) - 1c(0) , 
does not lead to Berger's paradox in the normal case. 
5.37* (Casella et al., 1993b) Consider a general loss function of the form 
L(O, C) = S(vol(C)) - le(O), 
with S increasing, 0 ::; Set) ::; 1. 
a. Show that the Bayes estimators are the HPD regions. 
b. Show that, if x ""' Np(O, Ip) and 0 ""' Np(J-L, 7 2Ip), the Bayesian credible 
sets C'" are not empty if Set) = tl(a + t). 
c. Determine the smallest radius of C'" as 7 varies. 
d. Consider x ""' N(O, (j2 In) and S2 ""' (j2X~. Under the rational loss, show 
that 
C'" (x, S2) = {o; 10 - xl ::; ~}, 
where t* is the solution of 
. ( 
.2tslvn 
) 
mill 
/ vn -
P(ITn~ll < t) . 
t 
a + 2ts 
n 
Deduce that P(ITn~ll < t*(s)ls) ::::: 1/2. 
5.38 Consider x ""' f(xIO) with 0 E IR. and 7r a prior distribution on O. If we 
define the a-credible set (-00, Ox) by P'" (0 ::::: Ox Ix) = a, show that this 

Exercises 225 
one-sided interval cannot be at level a in the frequentist sense. (Hint: Show 
that p(e 2:: exle ::; eo) > a for some eo.) 
5.39* (Thatcher, 1964) Consider x '" B(n, e) and, for 0 < a < 1 and a prior 7r 
on e, define e; by p7r(e::; e;lx) = a. 
a. If 7r(e) = (1 - e)-I, show that po(e ::; e;) ::; a for e > O. 
b. If 7r(e) = e-l, show that po(e ::; e;) 2:: a for e < 1. 
c. Define e; associated with 7r(e) = e>.-l(l- e)-A, 0 ::; A ::; 1. Show that 
e; is increasing in A and deduce that 
5.40* (Hartigan, 1983) Consider x '" P(A) and for 0 < a < 1, and a prior 7r on 
A, define A; by 
P7r(O::; A::; A;lx) = a. 
a. Show that, if 7r(A) = I/A, P>.(A::; A;) ::; a for every A. 
b. Show that, if 7r(A) = 1, P>.(A ::; A;) 2:: a for every A. (Hint: Use the 
following relation: 
~ ->. AX 1
00 
uxo- 1 
-u 
) 
~ 
e I' = 
(_)' e 
duo 
X. 
0 
Xo 
1. 
X=XQ 
5.41 * (Brown, 1967) In the setup of Example 5.18, show that 
P (folx - el ::; ksls ::; 1) ::; a > P (folx - el ::; ksls > 1) 
and derive a positively relevant subset. (Hint: Show that 
is increasing in s.) 
5.42 A famous problem in classical Statistics is the Behrens-Fisher problem. 
It stems from a simple setting of two normal populations with unknown 
means and variances, because there is no UMP or UMPU test to compare 
the means. Consider Xl, ... ,Xn a sample from N(e,lj2) and Yl, ... ,Ym a 
sample from N(/-L, T2) where e, /-L, T, Ij are unknown. 
a *. Show that there is no UMPU test procedure for the hypothesis Ho : e = 
/-L. (Hint: Condition on s~ and s;, given below, to show that the UMPU 
procedures vary with s~ and s;.) 
b. Explain why a reasonable test should be based on the pivotal quantity 
T = -'-( 
er-~/-L=) =-=( x=;;=-=y:=,-) 
Jsi/n+sUm 
with x = I:i Xi/n, y = I:j W/m, s~ = I:i(Xi - X)2/n - 1, and s; = 
I:j (Yj - y)2/m - 1. 
C. Show that the distribution of T depends on Ij /T even when e = /-L and 
is not a Student's t-distribution. 
d. Give the posterior of T when 7r(e,/-L,Ij,T) = 1/lj2T2 and show that it 
depends only on (sx/ ..jii)(Sy(.JiTi). (Note: See Robinson, 1982, for a 
detailed survey of the different issues related to this problem.) 

226 5. Tests and Confidence Regions 
5.43 (Walley, 1991) 
Consider the double-exponential distribution, f(xIO) 
(1/2) exp( -Ix - (1). 
a. Show that Cx = (-00, x) is a 50% confidence interval. 
b. Show that Po(O E Cxlx < 0) < 0.5 for every O. 
c. Let <p(x) = e2x /2Ix<o. Show that 
and deduce that "((x) = 1/2 is not an admissible confidence report under 
squared error loss for Cx . 
5.44 (Walley, 1991) Consider a sample Xl, ... ,Xn from U[O,O+l]' 
a. Show that uniformly more accurate one-sided confidence intervals are of 
the form Cx = [(x(1) + 1 - K) 1\ (X(n) -l),x(1) + 1) and check that the 
confidence level is "( = 1 - (1- K/2)n. 
b. For n = 1 and "( = 1/2, show that Cx = [x, x + 1). Consider a strictly 
decreasing bounded function f and <p(x) = (f(x) - f(x + 1)) 1\ (f(x -
1) - f(x)). Verify that 
lEo [f(Icx (0) - 0.5)) = 0.2510+1 (f(x - 1) - f(x)) dx 
and 
110+1 
lEo[<p(X)) :::;"8 
0 
(f(x - 1) - f(x)) dx. 
c. Deduce that 
lE(I[f(Icx(O) - 0.5) - <p(x)) ~ 0 
for every 0 and that "( = 1/2 is not an admissible report. 
d. For n ~ 2, we define 
B = {(Xl, ... , xn); X(n) - X(1) ~ 2 - K}. 
Show that 
and conclude that B is a relevant subset. 
5.45* (Fieller, 1954) In the setup of calibration (see Exercise 4.35), confidence sets 
need to have infinite length to maintain a fixed confidence level, as shown 
by GIeser and Hwang (1987). Consider (Xl, Yl), ... , (xn, Yn) a sample from 
N2 ({t, E). The parameter of interest is 0, the ratio of the two means {tx and 
{ty. 
a. Define Z(I = Y - Ox. Show that 
and that 
Vo = ~1 
(s~ - 20sxy + 02sx) 
n-
is an unbiased estimator of V(I, the variance of Z(I, when x, y, s;, Sxy, 
and s; denote the usual empirical moments and 

Exercises 227 
o-xy ) 
2 
. 
o-y 
b. Show that ze and ve are independent and that (n - l)ve/ve rv X~-l' 
Deduce that {B; ze/ve ::; t~-1,"/2} defines a (1 - a) confidence set. 
c. Show that this confidence set defines a parabola in B and can be an 
interval, the complement of an interval or the whole real line. 

6 
Admissibility and Complete Classes 
The previous chapters mentioned repeatedly that the Bayes estimators were 
instrumental for the frequentist notions of optimality, in particular, for ad-
missibility. This chapter provides a more detailed description of this phe-
nomenon. In §6.1, it considers the performances of the Bayes and general-
ized Bayes estimators in terms of admissibility. Then, §6.2 studies Stein's 
sufficient condition in order to relate the admissibility of a given estima-
tor with a sequence of prior distributions. The notion of complete class 
introduced in §6.3 is also fundamental, as it provides a characterization 
of admissible estimators or at least a substantial reduction in the class of 
acceptable estimators. We show that, in many cases, the set of the Bayes es-
timators constitutes a complete class and that, in other cases, it is necessary 
to include generalized Bayes estimators. In a more general although non-
Bayesian perspective, §6.4 presents a method introduced by Brown (1971) 
and developed by Hwang (1982b), which provides necessary admissibility 
conditions. For a more technical survey of these topics, see Rukhin (1994). 
6.1. Admissibility of the Bayes Estimators 
Let us recall first the two following results about the admissibility of 
(proper) Bayes estimators, already stated in Chapter 2 (Propositions 2.14 
and 2.15): 
Proposition 6.1 If a Bayes estimator is unique, it is admissible. 

230 6. Admissibility and Complete Classes 
Proposition 6.2 
When the risk function is continuous in () for 
every estimator 8, if 7r is equivalent to the Lebesgue measure on 
e, i.e., absolutely continuous with a positive density on e, a Bayes 
estimator associated with 7r is admissible. 
On the contrary, if the support of 7r is different from the whole space, it 
is possible that an associated Bayes estimator is inadmissible. Similarly, the 
Bayes estimators will often be inadmissible when the Bayes risk is infinite. 
Example 6.1 Consider a normal setup x '" N((), 1) with a conjugate prior 
2 
2 
() '" N(O, a2 ). The posterior distribution is then NC/?+l x, ag-+l) and the 
2 
Bayes estimator under quadratic loss is 87r(x) = ag-+l x, which is admissible, 
as shown in Corollary 6.6. On the contrary, if the quadratic loss is modified 
into 
L",((),8) = e(P/2",(() - 8)2, 
the corresponding Bayes estimator is inadmissible for a small enough. In 
fact, the formal generalized Bayes estimator associated with L", is 
foo ()eo2 /2"'e -(0-6" (x))2 "22"t/ d() 
8~(x) = 
-00 
2' 
J~oo e02 /2"'e-(O-6"(x))2"2"V d() 
provided both integrals are finite. Since 
• 
2 
8~ IS defined for a > ag-+l and 
The corresponding Bayes estimator is 
r(7r) = 1:
00 eo2/2'''e-02/2a2 d(), 
i.e., is infinite for a :S a 2 . Moreover, since 
a 
f:7r() 
a 
a 2 
v 
X 
-
---x 
a 2 
-
a 2 
2 + 1 
a -
a 2+1 
a -
a 2+1 a 
a 
-"..-".----x 
a 2+1 l' 
a-;;:r -

6.1. Admissibility of the Bayes Estimators 231 
the Bayes estimator 6~ (x) is of the form ex with e > 1 when 
(J2 + 1 
a> a--2 - -1, 
(J 
i.e., when a < (J2. And, in this case, 
R(O,6~) = JEo[(ex - O?Je02 /2a 
= {(e - 1)202 + e2}e02/2a > e'P /20' 
implies that 6~ is inadmissible, since it is dominated by 60(x) = x. Note 
that 60 is also a Bayes estimator under La when a < (J2 since the Bayes 
risk is infinite. It is interesting to note that the limiting case a = (J2 leads 
to the admissible estimator 6;2 (x) = x with an infinite Bayes risk. 
/':;. 
Example 6.2 Consider y cv (J2X~. The conjugate prior distribution for (J2 is 
the inverse gamma distribution I9(v /2, a/2) (see Chapter 3) and 7r((J2Jy) is 
the distribution I9((v + p)/2, (a + y)/2), leading to the following posterior 
expectation: 
67r (y) = JE7r[(J2Jy] = 
a + y 
v,a 
v+p- 2 
Consider v = 2. In this case, 67r(y) = (y/p)+(a/p). Since yip is an unbiased 
estimator of (J2, the estimators 62 a are not admissible under square error 
(as a > 0). The same result holds' when v < 2. It is easy to check that the 
Bayes risk of 67r is infinite in this case (see Lehmann, 1983, p. 270). 
/':;. 
Example 6.3 On the contrary, the constant estimators 60 (x) = 00 are the 
Bayes estimators corresponding to a Dirac mass prior in 00 and are almost 
always admissible under quadratic losses. In fact, 
lEoo(8(x) -
(10)2 = (lEoo(8(x)) -
(10)2 + varoo(8(x)) = 0 
implies that varoo(6(x)) = 0 and therefore that 6(x) = 00 uniformly, unless 
the distribution is degenerated in 00 (see Exercise 6.6). 
,0,. 
A result similar to Proposition 6.2 can be established in the discrete 
case (the proof is straightforward and left as an exercise). 
Proposition 6.3 If (9 is a discrete set and 7r(O) > 0 for every 
o E (9, a Bayes estimator associated with 7r is admissible. 
We saw in §3.2 that, if x has a distribution from an exponential family 
f(xIO) = h(x)eo.T (x)-'1f;(O) , 
the conjugate distributions are also in exponential families and the posterior 
expectation of the mean of T(x) is then affine in T(x), i.e., 
JE7r[V'1/>(O)Jx] = T(x) + to = _l_T(x) + 'YoA 
(6.1) 
A+1 
>'+1 
>.+1' 

232 6. Admissibility and Complete Classes 
when 
n(Blto, A) = e()·to-A'</J(()) 
and 'Yo = toj A. In the case where B E IR and the natural parameter space 
is N = [fl, OJ, Karlin (1958) exhibits a sufficient admissibility condition for 
these estimators of the mean (see also Exercises 6.1 and 6.2). 
Theorem 6.4 If A > 0, a sufficient condition for the estimator 
(6.1) to be admissible under a quadratic loss is that, for every 
fl < Bo < 0, 
This theorem is derived from the Cramer-Rao inequality (Lehmann, 
1983, pp. 271-272). It also appears as a corollary to the Stein necessary and 
sufficient condition (see §6.2.3). Berger (1982b) considers the reciprocal to 
Theorem 6.4, i.e., shows that, under a few additional assumptions, this 
condition is also necessary (see Exercise 6.4). 
Example 6.2 (Cont.) For the chi-squared distribution, the natural parame-
trization is 
and 
1 
B=2' 
a 
1jJ(B) = -~ log(B), 
lC e-iOA()B- Ap/2 dB 
is infinite if AP ~ 2. Similarly, 
1+
00 e-ioA()B- Ap/2 dB = +00 
if 'YoA < 0 or 'YoA = 0 and Ap ::; 2. Therefore, the Bayes estimator 
1r 
'Yo A 
1 
y 
8 (y) = 1 + A - 1 + A '2 
is admissible if 'Yo = 0 and A = 2jp or 'Yo < 0 and A ~ 2jp; these conditions 
lead to the estimators 
p (-y) 
'PI (y) = p + 2 "2 
and 
for the estimation of lEa(-yj2) = _~a2, i.e., to the following admissible 
Bayes estimators of a 2 : 
and 
1 
b> 0, 0 < a < --. 
-
- p+2 

6.1. Admissibility of the Bayes Estimators 233 
Example 6.4 Consider x f'V B(n,p). The natural parametrization is given 
by 0 = n 10g(P/ q) since 
f(xIO) = (:) e(x/n)O (1 + eo/n) -n . 
Then the two integrals 
100 
( 
)An 
-00 e-'YoAO 1 + eO/ n 
dO 
and 
cannot diverge simultaneously if >. < O. Consider thus>. > O. The second 
integral is divergent at +00 if >'(1 - 'Yo) > 0, Le., 'Yo < 1. And the first 
integral is divergent at -00 if 'Yo>' :2: O. We then derive from Theorem 6.4 
that a class of admissible Bayes estimators of p is 
X 
87r(x) = a- + b, 
n 
o :S a :S 1, 
b :2: 0, 
a + b :S 1. 
Given that the Bayes estimators are not necessarily admissible, inad-
missibility obviously occurs more frequently for generalized ~ayes estima-
tors. The particular case when the Bayes risk of a generalized Bayes estima-
tor is finite (and thus when this estimator is admissible-see Proposition 
2.16) does not occur very often, except in testing and other bounded loss 
setups (see Example 2.14), and it is then necessary to use more advanced 
results to establish admissibility, like Stein's condition. 
Example 6.5 Consider x f'V Np ( 0, I p) and 80 (x) = x; 80 is a generalized 
Bayes estimator for the prior distribution 7f(O) = 1. The Stein effect states 
that 80 is admissible under quadratic loss if p :S 2 (see Corollary 6.6) and 
inadmissible otherwise (§2.4.6). 
l::!,. 
Example 6.6 The prior distribution used in Example 6.5 can also produce 
more extreme cases of inadmissibility. For instance, if 7f(O) = 1 and if the 
parameter of interest is 'TJ = 110112, Example 3.22 has shown that the pos-
terior distribution of'TJ is a x~(llxI12) distribution, leading to the following 
generalized Bayes estimator: 
As indicated previously, this estimator is inadmissible and dominated by 
8(x) = (11x112 -p)+. Example 3.22 proposes an alternative prior distribution 
which is more appropriate in this setting. 
l::!,. 
Example 6.7 Consider x f'V Q(a, 0) when a is known. As 0 is a scale param-
eter, 7f(O) = I/O is an appropriate noninformative distribution (see Chapter 
7). The corresponding posterior distribution is Q(a, x) and thus 
87r(x) = ~ 
X 

234 6. Admissibility and Complete Classes 
is the generalized Bayes estimator of 0 under quadratic loss. For an estima-
tor of the form 8c(x) = c/x, the quadratic risk is 
R(0,8c ) = IEe (~_ 0)2 = c2IEe(x-2) - 2cOIEe(x-1) + 02. 
For a > 2, we have 
and 
( -1) __ 
1_ r+ oo on n-2 -ex d _ Or(a - 1) _ _ 0_ 
IEe x 
- r ( a) } 0 
x 
e 
x -
r ( a ) 
- a-I· 
This implies that the best estimator of the form 8c is associated with 
* 
OIEe(x-1) 
02/(a-1). 
c -
-
= a - 2, 
-
IEe(x-2) - 02/(a - l)(a - 2) 
and thus that 81f is dominated by 8c*. 
The three previous examples show that all behaviors are indeed possi-
ble for generalized Bayes estimators, from the admissibility of x for p = 1,2 
(Example 6.5) to the strong inadmissibility of the estimators in Examples 
6.6 and 6.7, including the weak1 inadmissibility of x for p 2: 3 (Example 
6.5). 
For multidimensional exponential families, Brown and Hwang (1982) 
have extended Theorem 6.4 to arbitrary generalized prior distributions. 
Consider thus a random variable 
X rv f(xIO) = h(x)ee.x-1/J(e) , 
where 0 and x belong to IRP. Given a measure 7r with density g on e, we 
assume that 
(6.2) 
When estimating "V'¢(O) under quadratic loss, the Bayes estimator associ-
ated with g can be written as 
(6.3) 
1 In fact, 80 (x) = x is still a minimax estimator for every dimension and the 
estimators which dominate 80 only improve significantly upon 80 (in terms of 
risk) in a relatively small region of the sample space (see, for instance, Bondar, 
1987). 

6.1. Admissibility of the Bayes Estimators 235 
The following conditions on g: 
and 
r 
g~B) 
dB < +00, 
J{lloll>l} IIBI1 2 log (IIBII V 2) 
J 
IIVg(B)W dB < +00 
g(B) 
, 
VB E 8, 
R(B,8g ) < +00, 
are sufficient to establish the admissibility of 8g • 
Theorem 6.5 
Under the conditions (6.4), (6.5), and (6.6), the 
estimator (6.3) is admissible. 
(6.4) 
(6.5) 
(6.6) 
The proof of this result is postponed until Example 6.9, because it relies 
on the Blyth condition given in §6.2.2. Note that this result has important 
consequences since it covers the estimation of the expectation parameter 
for all continuous exponential families on lRP• For instance, it gives, as a 
particular application, Stein's (1955b) inadmissibility result for all expo-
nential families. It also generalizes Zidek (1970), who was dealing with the 
one-dimensional case (see Exercise 6.5). 
Corollary 6.6 If (9 = lRP and p :::; 2, the estimator 8o(x) = x is 
admissible. 
Proof. Consider g == 1, then Vg == 0 and 8g (x) = x. Conditions (6.4), (6.5) 
and (6.6) being satisfied, 8g is admissible. 
__ 
Example 6.5 (Cont.) If x rv Np(B, Ip), B is the natural parameter of the 
distribution and Corollary 6.6 actually provides Stein's (1955a) original 
result. Note that Theorem 6.5 also provides a tool to check the admissibility 
of other generalized Bayes estimators of B, including those considered by 
Strawderman (1971) (see Exercise 8.1) and Berger (1980a). 
f:,. 
Example 6.8 Consider Xl, X2, two random variables from P(Ai) (i = 1,2). 
If Bi = log(Ai), 8o(x) = (Xl, X2) is an admissible estimator of (AI, A2) = 
(e~,e~). This result does not extend to larger dimensions, as shown by 
Hwang (1982a) and Johnstone (1984). 
f:,. 
Brown and Hwang (1982) present various generalizations of Theorem 
6.5 which allow us to include cases where (9 #- lRP , like the gamma and 
geometric distributions. They also show that, in the special case of p obser-
vations Xi from independent Poisson distributions, P(Ai), the generalized 
Bayes estimator 
[ 
(3+P-1] 
8cz(x)= 1- (3+p-1+S x, 

236 6. Admissibility and Complete Classes 
with S = Li Xi, which was proposed by Clevenson and Zidek (1975) to 
improve upon X = (Xl"'" xp), is admissible for (3 > 0 and p 2: 2 under the 
loss 
Das Gupta and Sinha (1986) also provide sufficient admissibility conditions 
which apply for the estimation of independent gamma means. 
In the particular case of a normal multidimensional distribution, 
Np(e, E), when E is known, Brown (1971) characterizes more thoroughly 
the admissible Bayes estimators under quadratic loss by providing a neces-
sary and sufficient condition. Note that Shinozaki (1975) implies that the 
choice E = Ip does not restrict the generality of the treatment (see §2.5.1 
and Exercise 2.42). 
Theorem 6.7 Consider X '" Np(e, Ip). A generalized Bayes esti-
mator of the form 
o(x) = (1- h(llxll))x 
is 
(i) 
inadmissible if there exist E > 0 and K < +00 such that, for 
Ilxll >K, 
IlxI1 2h(llxll) < p - 2 -
E; 
(ii) admissible if there exist KI and K2 such that h(llxll)llxll ~ 
KI for every x and, for Ilxll > K 2, 
IlxI1 2h(llxll) 2: p - 2. 
The proof of this result is rather advanced and the derivation of (i) 
and (ii) involves the recurrence or the transience of a random process2 
associated with o. (See Srinivasan, 1981, for a simpler description.) Part 
(i) also appears as a consequence of Lemma 6.22. Note the factor (p - 2), 
which delineates the boundary between admissibility and inadmissibility of 
the usual estimator 00 (x) = x. The relation between this result and the 
Stein phenomenon is explained in §6.4. 
Johnstone (1984) provides an equivalent to Theorem 6.7 in the case of a 
Poisson model. If Xi'" P(Ai) (i = 1, ... ,p), the parameter A = (A!, ... , Ap) 
is estimated under the loss 
2 Random walks are always recurrent in dimensions 1 or 2 and may be tran-
sient for larger dimensions (see Feller, 1971, or Meyn and Tweedie, 1993). The 
connection exhibited by Brown (1971) then points out that the similar role of 
p = 3 as a limiting case in both problems is not a mere coincidence. 

6.1. Admissibility of the Bayes Estimators 237 
Then: 
Theorem 6.8 A generalized Bayes estimator of the form 
8(x) = (1 - h(s))x, 
where s = Li Xi, is 
(i) 
inadmissible if there exist E > 0 and K < +00 such that, for 
s>K, 
sh(s) < (p - 1 -
E)j 
(ii) admissible if there exist Kl and K2 such that .,;s h(s) ::; Kl 
for every s and, for s > K2, 
sh(s) 2 (p - 1). 
In addition, Eaton (1992) exhibits connections similar to Brown (1971) 
between the admissibility of an estimator and the recurrence of an associ-
ated Markov chain. We mention the main results of this paper below but 
urge the reader to investigate this paper not only for the proofs but also 
for its deeper implications. The problem considered by Eaton (1992) is to 
determine whether, for a bounded function g(O), a generalized Bayes esti-
mator associated with a prior measure 7r is admissible under quadratic loss. 
Assuming that the posterior distribution 7r(Olx) is well defined, we consider 
the transition kernel 
K(O, TJ) = Ix 7r(Olx)f(xITJ) dx, 
which is associated with a Markov chain (o(n)) generated as follows: the 
transition from o(n) to o(n+l) is done by generating first x rv f(xlo(n)) and 
then e(n+l) rv 7r(Olx). (For the use of this kernel in Markov Chain Monte 
Carlo methods and more details about Markov chain theory, see Tierney 
(1991), Schervish and Carlin (1992), and Chapter 9.) For every measurable 
set C such that 7r(C) < +00, we define 
V(C) = {h E .c2(7r)j h(O) 20 and h(O) 2 1 when 0 E C} 
and 
Ll(h) = J J 
{h(O) - h(TJ)}2 K(O, TJ)7r(TJ) dO dTJ· 
The following result then characterizes admissibility for all bounded func-
tions in terms of Ll and V (C), i.e., independently of the estimated functions 
g: 
Theorem 6.9 If, for every C such that 7r(C) < +00, 
inf Ll(h) = 0, 
hEV(C) 
(6.7) 

238 6. Admissibility and Complete Classes 
then the Bayes estimator JE7r[g(O) Ix] is admissible under quadratic 
loss for every bounded function g. 
This result is obviously quite general but only mildly helpful in the 
sense that the practical verification of (6.7) for every set G can be over-
whelming. Note also that (6.7) always holds when 7r is a proper prior distri-
bution since h == 1 belongs to .c2(7r) and ,,1(1) = 0 in this case. The exten-
sion then considers approximations of 1 by functions in V(G). (See Chapter 
7 for a similar relation between amenability and minimaxity.) Eaton (1992) 
exhibits a connection with the Markov chain (o(n) which gives a condition 
equivalent to Theorem 6.9. First, for a given set G, a stopping rule ac is 
defined as the first integer n > 0 such that (o(n) belongs to G (and +00 
otherwise). The chain (o(n) is said to be 7r-recurrent if the probability that 
ac is finite is 1 for 7r-almost every starting point 0(0). 
Theorem 6.10 For every set G such that 7r(G) < +00, 
inf Ll(h) = ({1- P(ac < +0010(0) = ry)} 7r(ry) dry. 
hEV(C) 
lc 
Therefore, the generalized Bayes estimators of bounded functions 
of 0 are admissible if and only if the associated Markov chain (o(n) 
is 7r -recurrent. 
Again, we refer to Eaton (1992) for extensions, examples, and com-
ments on this result. Note, however, that the verification of the recurrence 
of the Markov chain (o(n) is much easier to operate than the determina-
tion of the lower bound of ..d(h). Moreover, this result suggests a possible 
numerical verification of admissibility based on the generation of the chain 
(o(n) which is in a way similar to the numerical minimaxity verification 
proposed in Berger and Robert (1990). 
6.2. Necessary and Sufficient Admissibility 
Conditions 
The results obtained in the previous section only apply to generalized Bayes 
estimators. Moreover, some conditions are rather arduous to verify-see, 
e.g., (6.4) or (6.5). We present in this section a general necessary and suf-
ficient admissibility condition which does not require estimators to be gen-
eralized Bayes estimators. It somehow formalizes our repeated assertion 
that "admissible estimators are limits of Bayes estimators .... " A first ver-
sion of the Stein condition only allows for the comparison of continuous 
risk estimators but § 6-.2.1 indicates why it is usually sufficient to consider 
continuous risk estimators. 

6.2. Necessary and Sufficient Admissibility Conditions 239 
6.2.1. Continuous Risks 
It is often necessary to restrict the scope of the study to continuous risk 
function estimators in order to produce a sufficient admissibility condition. 
However, in some setups, all estimators have continuous risks. In other 
cases, the "interesting" estimators, i.e., the admissible estimators, neces-
sarily have continuous risks. 
Lemma 6.11 
Consider f) c lRm. The loss function L(0,8) is 
assumed to be bounded and continuous as a function of 0 for every 
8 E V. If f(xIO) is continuous in 0 for every x, the risk function 
of every estimator is continuous. 
Proof. Given an estimator 8, the difference of the risks in 0 and 0' E f) is 
IR(0, 8) - R(O', 8)1 = I J 
L(O, 8(x))f(xI0) dx - J 
1(0', 8(x))f(xI0') dxl 
:::; J 
IL(O, 8(x)) - L(O', 8(x))lf(xI0) dx 
+ I J 
L(O, 8(x))(f(xI0) - f(xIO')) dxl· 
Since L is continuous and bounded by C, there exist 7]0 > 0 and a compact 
set Ko such that 
[e f(xIO) dx < 8~ 
and 
o 
when 110 - 0'11 < 7]0· Thus, 
r IL(O, 8(x)) - L(O', 8(x))lf(xI0) dx < ~ 
lKo 
J 
IL(O, 8(x)) - L(O', 8(x))lf(xI0) dx < ~. 
Moreover, f(xIO) being a continuous function of 0, a similar argument can 
be applied: there exist 7]1 > 0 and a compact set K1 such that 
I J 
L(O, 8(x))(f(xI0) - f(xIO')) dxl :::; C [1 If(xIO) - f(xIO') 1 dx 
+ C [e [f(xIO) + f(xIO')] dx < ~ 
1 
and 
when 110 - 0' II < 7]1. Therefore, R( 0,8) is actually continuous. 
- -
Lemma 6.11 is somehow of limited interest since the most delicate ad-
missibility problems occur when L is unbounded. Some settings still allow 

240 6. Admissibility and Complete Classes 
for a reduction in the class of estimators to consider to the class of contin-
uous risk estimators, i.e., for a complete class characterization. 
Definition 6.1 A class C of estimators is said to be complete if, for 
every 8' ~ C, there exists 8 E C which dominates 8'. The class is 
essentially complete if, for every 8' ~ C, there exists 8 E C which 
is at least as good as 8'. 
Apart from trivial cases like the class of all estimators, the determi-
nation of useful complete classes is not always possible. For instance, there 
are cases where the class of admissible estimators is not a complete class 
although such setups seldom occur (see Blackwell and Girshik, 1954, The-
orem 5.7.1, or Brown, 1976). Section 6.3 analyzes the relations between 
Bayes estimators, generalized Bayes estimators, and complete classes. The 
following result is a complete class lemma which gives sufficient conditions 
for considering only continuous risk estimators. 
Lemma 6.12 Consider a statistical decision model X, e c 1R. with 
a closed decision space V c 1R.. Assume that f(xIB) has the mono-
tone likelihood ratio property and is continuous in B. If 
(i) L(B, d) is a continuous function of B for every d E V; 
(ii) L is decreasing in d for d < B and increasing for d > B; 
and 
(iii) there exist two functions Kl and K2 bounded on the com-
pact sets of e, such that 
then the estimators with finite and continuous risks form a com-
plete class. 
See Ferguson (1967) and Brown (1976) for additional results. For in-
stance, it is possible to show that if the problem is monotone, then mono-
tone estimators constitute a complete class (see Exercise 6.21 and Theorem 
5.10). 
6.2.2. Blyth Sufficient Condition 
Prior to Stein's (1955b) derivation of his necessary and sufficient condition 
(§6.2.3), Blyth (1951) proposed a sufficient admissibility condition, relat-
ing admissibility of an estimator with the existence of a sequence of prior 
distributions approximating this estimator. 
Theorem 6.13 
Consider a nonempty open set e c 1R.p • As-
sume that the estimators with continuous risk constitute a com-
plete class. If, for a continuous risk estimator 80 , there exists a 
sequence (7r n) of generalized prior distributions such that 
(i) r(7rn ,80 ) is finite for every n; 

6.2. Necessary and Sufficient Admissibility Conditions 241 
(ii) for every nonempty open set C c 8, there exist K > o and 
N such that, for every n 2 N, 7rn(C) 2 K; and 
(iii) 
lim r(7rn' 80) - r(7rn) = 0; 
n-+oo 
then the estimator 80 is admissible. 
Proof. If 80 is not admissible, there exists an estimator 8' which dominates 
80 , i.e., such that R(B, 8) - R(B, 8') 20 and 
R(B,8) - R(B, 8') > E 
on an open set C c 8 (for E small enough). It then follows from assumptions 
(i) and (ii), that for n 2 N, 
r(7rn, 80) - r(7rn) 2 r(7rn, 80) - r(7rn, 8') 
= lE7r[R(B,80 ) - R(B,8')] 
2 fc (R(B, 80) - R(B, 8'))7rn(B) dB 
2 E fc 7rn(B) dB 2 EK. 
•• 
This result can be used to establish the admissibility of generalized 
Bayes estimators since the measures 7r associated with these estimators can 
be written as limits of sequences of proper distributions 7rn. However, the 
choice of these sequences is not necessarily straightforward, as shown by 
Berger (1982b) or Brown and Hwang (1982). Theorem 6.13 also applies to 
other estimators, in settings where there exist admissible estimators which 
are not generalized Bayes (see §6.3). 
Example 6.9 The proof of Theorem 6.5 is a first illustration of the Blyth 
condition. Consider hn with values in [0,1]' differentiable, satisfying hn(B) = 
o if IIBII > n and hn(B) = Ion a set S such that 
Is g(B) dB > O. 
We then define a sequence of associated measures with densities gn ((}) = 
h;(B)g(B) and the corresponding Bayes estimator 8n. Reverting to the no-
tation Ix(.) introduced in (6.2), the difference of the integrated Bayes risks 
is 
r(7rn,8g ) - r(7rn) = J 
118g(x) - 8n(x)1I 2Ix(gn) dx 
= J 
II IxC'Vg) - Ix(h;\1g) - Ix(g\1hn) 112 Ix (gn) dx, 
Ix (g) 
Ix (gn) 
. Ix (gn) 
using the representation (6.3). Therefore, 

242 6. Admissibility and Complete Classes 
The second term, An, is bounded from above by 
In the particular case where hn is 
hn(O) = { : _ 10g(IIOII) 
log(n) 
° 
we have actually 
for 11011 < 1, 
for 1 < 11011 < n, 
otherwise, 
and condition (6.4) implies that An converges to ° 
as n goes to infinity. 
The first term satisfies 
Bn = JllIx (gnI;~~~) _h~\7g)112 /(Ix(gn))dX 
= JllIx (gn [I;~~~) _ :g])11
2 /(Ix(gn))dX 
~ J Ix (g r;~~~) -:g 112) dx. 
Using (6.5), we can then derive from the dominated convergence theorem 
that Bn goes to 0, since gn converges to g. This completes the proof of 
Theorem 6.5. 
6 
In practice, a usual way to apply the Blyth condition to a generalized 
Bayes estimator, 80 , is to exhibit a sequence of proper Bayes estimators 
which converge to 80 and then denormalize the sequence of the associated 
prior distributions in a suitable way. 
Example 6.10 Consider x rv N(e,l) and oo(x) = x, an estimator of e. 
Since 80 corresponds to 7r(O) = 1 under quadratic loss, we choose 7rn as the 
measure with density 

6.2. Necessary and Sufficient Admissibility Conditions 243 
i.e., the density of the normal distribution N(O, n) without the normalizing 
factor 1/ V27fn. Since the densities gn increase with n, condition (ii) of 
Theorem 6.13 is satisfied, as well as (i): The Bayes estimator for 7fn is still 
nx 
8n (x) =-, 
n+l 
since the absence of the normalizing factor is of no importance in this case, 
and 
while 
r(7fn' 80 ) = L 
1 gn(e) de = V27fn. 
The two risks are then finite. Moreover, 
converges to O. The Blyth condition thus provides another proof of admis-
sibility for 80 (x) = x in the normal case. On the contrary, the proof of the 
admissibility of 80 in dimension two necessitates a more complex sequence 
(see Stein, 1955a). 
6 
Example 6.11 Consider x '" B(m, e). The inferential problem is to test the 
null hypothesis Ho: e:::; eo under the quadratic loss introduced in §5.3, 
The p-value is then 
In this case, the natural conjugate distributions are beta distributions. This 
suggests approximating <p(x) by a sequence of estimators associated with 
an appropriate sequence of beta distributions. In fact, <p(x) can be written 
(for x =1= 0) 
<p(x) = 
( 
1 
) [0
0 tX - 1(1 _ t)m-x dt = P(T :::; eolx) 
B x,m-x+ 1 Jo 
when T '" Be(x, m - x + 1), which corresponds to the generalized prior 
distribution 
(o<e<l). 
Consider then 7f n with density 

244 6. Admissibility and Complete Classes 
on [0,1] and let the sequence (an) go to O. In this case, the Bayes procedure 
is 
and 
m 
r(7rn) = L B(k + an, m - k + 1)-y7l"n (k)(1 - 'Y7I"n (k)), 
k=O 
m 
r(7rn, <p) = L B(k + an, m - k + 1)('"t7l"n(k) - 2'Y7I"n<p(k) + <p2(k)). 
k=O 
Therefore, 
m 
r(7rn, <p) - r(7rn) = L B(k + an, m - k + 1)('"t7l"n(k) - <p(k))2. 
k=O 
If k =I- 0, it is straightforward to verify that 
Similarly, we get 
to ta-1(1 - t)m-1dt 
lim 
0 
= 1 
a--+O f01 ta - 1 (1 - t)m- 1dt 
which takes care of the case k = O. Moreover, condition (ii) is also satisfied. 
The p-value <p is then admissible in this setup. Example 5.12 provides a 
more direct proof of this result since the Bayes risk is finite. 
t:::, 
Examples 6.9 and 6.11 take advantage of a general result, namely, the 
fact that, under quadratic loss, condition (iii) of Theorem 6.13 implies the 
quadratic convergence of the Bayes estimators to 80 in the sense of the 
marginal measures. 
Proposition 6.14 If L is a quadratic loss and if there exists a 
sequence (7rn ) satisfying conditions (i), (ii) and (iii) of Theorem 
6.13, the Bayes estimators 871"n converge quadratically to 80 for the 
marginal measures 
Proof. It is enough to write the difference of the risks as 

6.2. Necessary and Sufficient Admissibility Conditions 245 
r( 7rn , 80 ) - r( 7rn ) 
since 
= L le (1180(x) - BW -IWrn(x) - BI12)7rn (Blx) dBmn(x) dx 
= L 
[1180(x) - 87rn (x)112 
+ 2(80(x) - 87rn (x)) ·le (87rn (x) - B)7rn(Blx) dB] mn(x) dx 
= L 
1180(x) - 87rn (x) 11 2m n(x) dx, 
•• 
Unfortunately, this convergence depends on (mn ), except in cases 
where it is possible to establish an uniform equivalence with the Lebesgue 
measure or another fixed measure, in which case there is quadratic con-
vergence in the usual sense. This is, for instance, what occurs when the 
sequence (mn ) is increasing, as in Examples 6.9, 6.10, and 6.11. Section 
6.2.4 provides a more fundamental result of Brown (1986), which shows 
that pointwise convergence of the 87rn to 80 , independently of the measures 
m n , is actually necessary. 
6.2.3. Stein Necessary and Sufficient Condition 
The completion of the previous condition by Stein (1955b) and Farrell 
(1968b) is even more important than Theorem 6.13 since it shows that 
all admissible estimators are limits of sequences of Bayes estimators (in 
the sense of the Bayes risk). The assumptions in Farrell (1968b) are that 
(i) 
f(xIB) is continuous in B and strictly positive on e; and 
(ii) the loss L is strictly convex, continuous and, if E c e is compact, 
lim 
inf L(B, 8) = +00. 
11811-->+00 (}EE 
Note that this second assumption necessarily eliminates bounded losses. 
Theorem 6.15 Under the hypotheses (i) and (ii), an estimator 8 is 
admissible if and only if there exist a sequence (Fn) of increasing 
compact sets such that e = Un Fn, a sequence (7rn) of finite mea-
sures with support Fn, and a sequence (8n) of Bayes estimators 
associated with 7r n such that 
(i) there exists a compact set Eo c e such that infn 7rn(Eo) 2: 
1; 
(ii) if E C e is compact, sUPn 7rn(E) < +00; 

246 6. Admissibility and Complete Classes 
(iii) limn r(7rn, 8) - r(7rn) = 0; and 
(iv) limn R(0,8n ) = R(0,8). 
This fundamental theorem underlies most of the admissibility and com-
plete class results presented in §6.3. A proof of Theorem 6.15 is given in 
Farrell (1968b). The sufficient part of this result is close to the Blyth con-
dition but the necessary part allows for the exclusion of many inadmissible 
estimators. 
6.2.4. Another Limit Theorem 
Brown (1986) provides an alternative and quite general characterization of 
admissible estimators. Consider x rv f(xIO), with f(xIO) > 0, and assume 
that D is a closed convex set. Moreover, the loss function L is supposed to 
be lower semicontinuous and such that 
lim 
L(0,8) = +00. 
116"~+oo 
(Note that this is roughly assumption (ii) of Farrell (1968b).) The main 
result of Brown (1986) is to show that, under these conditions, the closure 
(for the pointwise convergence) of the set of the Bayes estimators is a com-
plete class. The following convergence result rephrases this completeness 
(see Brown, 1986, pp. 254-267): 
Proposition 6.16 If L is strictly convex, every admissible estima-
tor of 0 is a pointwise limit of Bayes estimators for a sequence of 
prior distributions with finite supports. 
This result can be compared with the results of Dalal and Hall (1983) 
and of Diaconis and Ylvisaker (1985), presented in §3.3, which show that, 
in an exponential family setting, every prior distribution is a limit of mix-
tures of conjugate prior distributions. Therefore, for exponential families, 
an admissible estimator is also a limit of Bayes estimators associated with 
a mixture of conjugate prior distributions. When the model is invariant 
under spherical transformations, the distributions with finite support can 
be replaced by distributions supported on embedded spheres, since they 
preserve symmetry. In this case, if 7r c is the uniform distribution on the 
sphere with radius c, 
Sc = {OJ 11011 = c}, 
and 8c is the associated Bayes estimator under quadratic loss, i.e., the 
posterior mean, Robert (1990a) derives the following limit theorem: 
Proposition 6.17 If x rv Np(O,Ip) and 7r is a prior distribution 
which is spherically symmetric around 0, there exist two sequences, 
(q~) and (c~), such that L~l q~ = 1 and 

6.3. Complete Classes 247 
m 7r(x) = ( f(xI0)7l'(0) dO = lim ~ 
q~mci (x), 
illlRP 
n---t+oo ~ 
n 
.=1 
where 
Moreover, under quadratic loss, 
(6.8) 
Therefore, in the normal case, every Bayes estimator associated with 
a spherically symmetric prior distribution is a pointwise limit of Bayes 
estimators associated with uniform distributions on spheres. Recall that 
the estimators 8c can be written as 
(6.9) 
where Iv is the modified Bessel function (Exercises 4.25 and 4.26). It actu-
ally follows from Kempthorne (1988) that every admissible estimator 8(x) 
can be written under the form (6.9) or that there exists an estimator 8' of 
the form (6.9) which is equivalent to 8 (in risk). See Robert et al. (1990) 
for comments on the choice of (q~) and (c~). 
6.3. Complete Classes 
The previous section established in a general setup that admissible esti-
mators are limits of Bayes estimators from several points of view. In some 
particular cases, it is possible to improve upon this description of admis-
sible estimators and to show that they are necessarily generalized Bayes 
estimators. Such results are interesting because, on one hand, they restrict 
farther the class of estimators to be considered and, on the other hand, 
they point out the advantage of using solely Bayes and generalized Bayes 
estimators from a frequentist point of view. This is, for instance, the case 
when testing procedures are evaluated under a quadratic loss, as seen in 
§5.3 (Theorems 5.9 and 5.10). This section provides similar results for point 
estimation. Additional references are given by Brown (1986) and Rukhin 
(1994). 
As an introductory example, consider the almost caricatural case when 
e = {01, 02 }, since it allows for a graphical representation of the risk set, 
'R = {r = (R(fh,8),R(02,8)), 8 E 1)*}, 

248 6. Admissibility and Complete Classes 
where V* is the set of randomized estimators. Assume the risk set R is 
bounded and closed from below, i.e., such that all risk points on the lower 
boundary of R are in R and have finite components. This is the case when 
the loss is positive. This lower boundary, denoted r(R), is important be-
cause it actually provides the admissible points of R. Indeed, if r E r(R), 
there cannot exist r' E R such that r~ :S rl and r~ :S r2 with strict in-
equality on one of the two axis. Moreover, for every r E r(R), there exists 
a tangent line to R going through r, with positive slope and equation 
i.e., such that every r' E R satisfies Plr~ + p2r~ ~ k, as shown by Figure 
6.1. (In fact, this is a consequence of the convexity of R.) This property 
implies that r is a Bayes estimator for the prior distribution 7['( (Ji) = Pi 
(i = 1,2) since it minimizes the Bayes risk Plrl +P2r2. We derive from this 
argument the following general result. 
Proposition 6.18 If e is finite and if the risk set R is bounded 
and closed from below, the set of Bayes estimators constitutes a 
complete class. 
o 
r, 
FIGURE 6.1. Risk set and admissible estimators for e = {Bl ,B2}. 
This characterization relies on a separating hyperplane theorem since, 
under the assumptions of the theorem, there exists a hyperplane tangent to 
the risk set for each point of the lower boundary and that this hyperplane 
defines a prior distribution on e by duality. The extension of this complete 
class result to denumerable and noncountable parameter spaces e calls for 
an equivalent generalization of separating hyperplane theorems to spaces of 
functions on e. For instance, Brown (1976) mentions the following result, 
o 
where S denotes the interior of S: 

6.3. Complete Classes 249 
Lemma 6.19 Consider S a convex subset of a topological vector 
o 
0 
space £. If S i=- 0 and Yo ¢. S, there exists f E £* such that S is 
included in {y; f(y) ~ f(yo)}· 
We derive from this lemma the following complete class result, due to 
Wald (1950), which generalizes Proposition 6.18: 
Theorem 6.20 Consider the case when 8 is compact and the risk 
set R is convex. If all estimators have a continuous risk function, 
the Bayes estimators constitute a complete class. 
Proof. This result is indeed a consequence of Lemma 6.19 since, if 80 is 
admissible, the risk function R((),80 ) belongs to the lower boundary of the 
risk set. Therefore, there exists a linear functional on R, 'lj;*, such that, for 
every estimator 8, 
'lj;*(R(·, 8)) ~ 'lj;*(R(·, 80 )). 
We can then derive from the Riesz representation theorem that there exists 
a finite measure 7r on 8 such that 
'lj;*(R(·,8)) = Ie R((), 8)7r(())d(), 
and that this measure can be renormalized into i(()) = 7r((})/7r(8), thus 
defining a prior distribution. The above inequality can be rewritten as 
J 
R((),8)ir(())d() ~ J 
R((),80)i(())d() 
and implies that 80 is a Bayes estimator for ir. 
•• 
If 8 is not a compact space, we have already seen examples where the 
Bayes estimators cannot constitute a complete class. For instance, when 
estimating the mean () of a normal random variable x '" N((), 1), the esti-
mator 8(x) = x is admissible but is not a Bayes estimator. However, in many 
cases, complete classes are made of generalized Bayes estimators (meaning, 
obviously, Bayes and generalized Bayes estimators). For instance, Berger 
and Srinivasan (1978) have established that, when estimating the natural 
parameter () of an exponential family 
under quadratic loss, every admissible estimator is a generalized Bayes es-
timator. They thus extend Brown (1971) who considered the normal case. 
Example 6.12 In the normal case, x'" Np((), Ip), we repeatedly mentioned 
the truncated James-Stein estimator, 
JS 
P - 2 
( 
) + 
8 (x) = 1- IIxl12 
x. 
(6.10) 

250 6. Admissibility and Complete Classes 
Although well performing, this estimator is not admissible because, other-
wise, it would be a generalized Bayes estimator. Since 8JS is not analytical, 
this is impossible (see Exercise 6.24). 
6. 
Chow (1987) establishes a similar result for families with noncentrality 
parameters, X; (A) and Fp,q (A), thus giving an illustration of the complete-
ness of the generalized Bayes rules outside the framework of exponential 
families. This complete class theorem leads, in particular, to the inadmis-
sibility of the classical estimator, (x - p)+, in the case of the distribution 
X;(A), although Saxena and Alam (1982) have shown that this estimator is 
already efficient, since it dominates the maximum likelihood estimator (see 
also Exercise 3.22). 
Fraisse et al. (1990) derive a result similar to Berger and Srinivasan 
(1978) in the presence of a nuisance parameter. Consider x = (u, z) with 
u E IRk and z E IR. The density of x with respect to v is 
f(xl{),8) = h(u,z)eIJ.u+6z-1/J(IJ,8) 
with () E e c IRk and 8 E Ll, a compact interval of IR~. As in the normal 
setup, the problem at hand is to estimate () / 8 under a quadratic loss. For 
this model, the complete class theorem is given by: 
Proposition 6.21 If 'P is an admissible estimator of () / 8, there 
exists a measure 7r on e x Ll such that, for v-almost every (u, z), 
r 
()eIJ.u+6z-1/J(IJ,8)7r(d{) d8) 
( 
) 
JexLl 
' 
'P u, z = J. 
8eIJ.u+8z-'l/J(1J,8)7r(d() d8) 
exLl 
' 
(6.11) 
Therefore, the complete class theorem of Berger and Srinivasan (1978) 
is still valid in the presence of nuisance parameters. The proof of Proposition 
6.21 actually relies on Proposition 6.16 (see Exercise 6.25). 
Example 6.13 Consider x '" Np ((), (l2Ip) and S2 '" (l2X~, independent of 
x. In this setting, 8o(x, s2) = x is also inadmissible for p 2: 3. We consider 
extensions of the James-Stein estimator (6.10) of the form 
where Band Care (p x p) matrices, his a.e. differentiable, and Ilxllb = 
xtCx. These estimators are called matricial shrinkage estimators (see Judge 
and Bock, 1978). Proposition 6.21 implies that a necessary condition for 'P 
to be admissible is that h is infinitely differentiable and also that Band C 
are proportional (see Exercise 6.26). 
6. 
Brown (1988) considers the estimation of the mean of an exponential 
family, ~({)). In dimension one, he establishes that admissible estimators 
have an integral expression close to (6.11). In fact, admissible estimators 
are then equal to generalized Bayes estimators on intervals. In the case of 

6.4. Necessary Admissibility Conditions 251 
distributions with discrete support, the completeness of generalized Bayes 
estimators does not always hold and complete classes involve piecewise-
Bayesian procedures (see Berger and Srinivasan (1978), Brown (1981), and 
Brown and Farrell (1985)). The complete class results obtained in §5.3 for 
testing under quadratic loss are of this type, as we saw that admissible 
estimators are identical to generalized Bayes estimators on truncation in-
tervals. 
6.4. Necessary Admissibility Conditions 
When a complete class theorem which restricts the choice of estimators to 
generalized Bayes estimators is not available, it is necessary to derive some 
alternative criteria to exclude inadmissible estimators as much as possi-
ble. While being necessary, the Stein condition does not usually provide 
an efficient tool for the elimination of inadmissible estimators, as its main 
practical interest is the Blyth sufficient condition. Moreover, the results of 
§6.2 cannot be applied in this general context since they only deal with 
generalized Bayes estimators. For quadratic losses, Hwang (1982b) devel-
oped a technique introduced in Brown (1971) and called STUB (for semitail 
upper bounds), which gives an effective necessary admissibility condition. 
It is based upon the following lemma. 
Lemma 6.22 Consider two estimators 81 and 82 with finite risks, 
such that 
for every () E e and a given positive-definite matrix Q. Then, 
every estimator 8 satisfying a. e. the inequality 
is inadmissible under every quadratic loss. 
Proof. Consider the new estimator 8'(x) = 8(x) + 81(x) - 82(x). Then 
R((),8') = lEe [(8'(x) - ())tQ(8'(x) - ())] 
= R((), 8) + 2lEe [(81 (x) - 82(x))tQ(8(x) - ())] 
+ lEe [(81 (x) - 82(x))tQ(81 (x) - 82(x))] 
:::; R((), 8) + 2lEe [(81 (x) - 82(x) )tQ(82(x) - ())] 
+ lEe [(81(x) - 82(x))tQ(81(x) - 82(x))] 
= R((), 8) + R((), 8d - R((), 82 ) < R((),8) 
and 8' dominates 8. 
•• 

252 6. Admissibility and Complete Classes 
This lemma may appear quite rudimentary at first sight, but it is 
actually quite powerful since it introduces a new necessary admissibility 
condition for every (risk) ordered couple (01,02), Moreover, since admissi-
bility does not depend on the matrix Q, it provides an extended battery of 
inadmissibility criteria. In particular, it recovers the necessary admissibility 
condition (i) of Theorem 6.7. 
Example 6.14 Consider x '" Np(O, Ip). It follows from James and Stein 
(1961) (see §2.4.6) that, among the estimators 
Op-2 is optimal for the usual quadratic loss. Therefore, Lemma 6.22 implies 
that every estimator 0 satisfying 
t a - (p - 2) 
( 
a) 
o(x) x 
IIxl1 2 
~ 1 - IIxll 2 
(a - (p - 2)) 
(6.12) 
is inadmissible. Consider 0 of the form 
( 
h(x) ) 
o(x) = 
1 - IIxll 2 
X. 
Then (6.12) implies that 0 is inadmissible if 
h(x)~a<p-2 
or 
h(x) ~ a > p - 2. 
Therefore, every estimator such that h is uniformly greater or smaller than 
(p - 2) is inadmissible. The necessary part of Theorem 6.7 follows by con-
sidering instead the truncated estimators 
(a~p-2), 
and showing that a* = p - 2 corresponds to the optimal estimator of this 
class (see Exercise 6.18). Lemma 6.22 then implies that, if 
h(x)~a<p-2 
for IIxll 2 > K, the estimator 0 is also inadmissible. 
In fact, note also that in Lemma 6.22 the strict inequality R(O,od < 
R(0,02) does not need to hold for every 0 but only for some O's, as long as 
R((),Ol)::; R((),02) is satisfied for every () E 8. 
Example 6.15 Das Gupta (1984) derives from Lemma 6.22 a necessary ad-
missibility condition for exponential distributions. If Xl, ... , xp are random 
variables from £XP(Oi), every estimator 0 of (B-t1, ... , 0:;;1) satisfying 

6.4. Necessary Admissibility Conditions 253 
i=l 
i=l 
for Xi ~ M, X = (Xl, ... ,xn ), and 
B 
Xi [ 
cxi4 
1 
8c,i(X) ="2 1+ 
2 
' 
2 (2:~=1 Xj2) 
o < C < 2(p - 1), is inadmissible. The estimator 8~i was introduced by 
Berger (1980b) to improve upon the usual estimator,'x/2, for p;::: 2. Note 
that x/2 actually dominates the maximum likelihood estimator, X (see Ex-
ercise 6.30). 
!::::. 
It is also possible to derive from Lemma 6.22 a necessary admissibility 
condition for the estimation of a normal mean vector when the variance 
is known up to a multiplicative factor, 0"2, as in Example 6.13. Consider 
X 
r..J Np(O,0"2Ip) and s2 
r..J 0"2X~ an independent observation of 0"2. The 
following result provides a necessary admissibility condition (Robert, 1987). 
Proposition 6.23 If, for the estimator 
there exist Ct, M1, and M2 such that 
(i) for t ;::: Ml and u ~ M 2 , 
t 
p-2 
-h(t,u) ~ Ct < --; 
u 
q+2 
or 
(ii) for t ~ Ml and u ;::: M 2 , 
t 
p-2 
-h(t,u);::: Ct > --2; 
u 
q+ 
8 is inadmissible under quadmtic loss. 
The proof of this result is based on the existence of an optimal estima-
tor in the class 
where A = [Kl'+OO) x [0,M2] or A = [0,K1] X [M2' +(0). To motivate 
Proposition 6.23, recall that, in this setting, the James-Stein estimators 
are of the form 
JS 
2 
as 
( 
2 ) 
8a (x, s ) = 1 - I/xl/ 2 
X 

254 6. Admissibility and Complete Classes 
and that 
p-2 
a*=--
q+2 
gives an optimal estimator in the class 8~s. Therefore, 8~~ gives the minimal 
shrinkage factor for II x 112 / 82 large and the maximal shrinkage for II x W / 82 
small. The estimator 8~~ is nonetheless inadmissible (Example 6.12). F'raisse 
et al. (1994) extend this result to exponential families with a nuisance pa-
rameter in the same setup as in Proposition 6.2l. 
Example 6.13 (Cont.) Among matricial shrinkage estimators, the only in-
teresting estimators are of the form 
(6.13) 
since the other estimators are inadmissible. Proposition 6.23 implies that, 
if, for every (t, u), 
t 
p-2 
-h(t, u) ::; 0: < --, 
u 
q+2 
these estimators are also inadmissible. In addition, note that a necessary 
minimaxity condition of <p under quadratic loss is 
t h( 
) 
2 tr(B) - 2Amax(B) 
1 
-
tu< 
--
u 
' 
-
Amax(B) 
q+2' 
where tr(B) denotes the trace and Amax(B) the largest eigenvalue of B (see 
Brown, 1975, and Cellier et al., 1989). Therefore, a necessary condition for 
the existence of an estimator satisfying both admissibility and minimaxity 
requirements is 
p+2 
tr(B) > Amax(B) -2-' 
which excludes estimators shrinking toward subspaces of small dimensions. 
This result also points out that admissibility and minimaxity are 
not totally compatible. In fact, an estimator which is admissible under 
a quadratic loss is admissible under all quadratic losses. On the contrary, 
Brown (1975) shows that the unique estimator of the form (6.13), which is 
minimax for all quadratic losses, is 80(x) = x. This result also relates to the 
V-admissibility of the estimator 80 established in Brown and Hwang (1989) 
(see §2.6). 
6 
Exercises 
Section 6.1 
6.1 
(Lehmann, 1986) Consider a random variable x with mean jJ, and variance 
(J"2. 
a. Show that 8(x) = ax+b is an inadmissible estimator of jJ, under quadratic 
loss if 
(a) a> 1; 

Exercises 255 
(b) a < 0; and 
(c) a = 1 and b # O. 
b. Generalize to the case where 8(x) = (1 + h(x))x with h(x) > O. 
6.2 (Cont.) Deduce from Exercise 6.1 that it is sufficient to consider>. ;::: 0 for 
the estimators (6.1) used in Theorem 6.4. 
6.3 Consider x'" U[-O,O] when 7l"(8) is the uniform distribution UfO,!]. 
a. Show that 
{ 
1-JxJ 
8~(x) = 
~Og(l/JxJ) 
if JxJ :5 1, 
otherwise, 
is a Bayes estimator which is inadmissible and dominated under the 
usual quadratic loss by 
8"(x) = {81(x) if JxJ :5 1, 
2 
JxJ 
otherwise. 
b. Show that 8~ is also a Bayes estimator for 7l". 
6.4* (Berger, 1982b) Consider x distributed according to 
x'" f(xJ8) = h(x)eox-..p(O) 
for x E [a, b]. Given two positive differentiable functions, mo and d, define 
80(x) = m~(x) _ h'(x) , 'V(x) 
2d'(x) 
and 8(x) = 80(x) + 'V(x). 
mo(x) 
h(x) 
f 
= 
d(x) , 
f 
a. Show that, under quadratic loss, 
R(8, 8) - R(8, 80) = lEo (d~) [dll(X) + d'(x) ::~:~]) , 
under some regularity conditions including 
lim h(xh(x)eoX = lim h(xh(x)eoX = O. 
x-a 
x_b 
(Make these conditions more explicit.) 
b. Assume that one of the two functions 
or 
I
b 
1 
g2(X) = 
x mo(y) dy 
is finite on [a, b]. Denote this function by gi. Show that if, in addition, 
lEo 1 d~ loggi 12 < +00 
and 
lim h(x)eoxgHx) = lim h(x)eoxgHx) = 0, 
x ..... a 
gi(X) 
x ..... b 
gi(X) 
then 80 is inadmissible and dominated by 8 for 'Y(x) = 2ag~(x)/gi(X) if 
O:5a:51. 
c. Apply to the case where x '" 9(1/,8) and 

256 6. Admissibility and Complete Classes 
1 
1 
7l'(e) = --e2' 
7l'1+ 
6.5* (Zidek, 1970) For x "" f(xle), e E ffi, such that {e; f(xle) > O} is an 
interval, consider the estimation of g(e) under quadratic loss. We want to 
study a sufficient condition for the generalized Bayes estimator 
{j"'(x) _ ,,---f """,g(_e)_f_(x_1 e_)7l'_(e_) d_e 
-
f f(xle)7l'(e) de 
' 
to be admissible when 7l' is a measure and 
j R(e, 8")7l'(e) de = +00. 
a. Let us define 
(+= 
M(x, e) = 19 
[g(t) - 8"(X)]2 f(xlt)7l'(t) dt 
and 
j[ M(X,e)]2 
h(e) = 
f(xle)7l'(e) 
f(xle) dx. 
Show that there exists a function q(e) such that ii"(e) = q(e)7l'(e) is a 
probability density and that 
j R(e, 8")ii"(e) de < +00. 
b. Let 15 be the Bayes estimator associated with ii". Show that 
r = j[R(e 8") - R(e 8)]ii"(e) de = j [f q'(e)M(x, e) de]2 dx. 
" 
f f(xle)7l'(e) de 
c. Denoting q( e) by f2 (e), derive from the Cauchy-Schwarz inequality that 
d. Show that if, for every (eo, e1 ) and E > 0, there exist a function q such 
that q(t) = 1 on (eo, e1 ) and r < E, the estimator 8" is admissible. 
e. Consider the condition (E): If 
J
+= 
t 
R(e, 8")7l'(e) de = +00, 
J
+= 
1 
then 
t 
h(e)7l'(e) de = +00. 
Let 
1
9 
1 
y(e) = 
91 h(t)7l'(t) dt 
and 
( 
y(t)) 
f(t) = 
1 - F 
lIo:c;y(t):C;F' 

Show that 
and that 
1'(t) = 
1 
(0:::; y(t) :::; F), 
Fh(t)7r(t) 
1
+= 
1 
[1' (t)]2 h(t)7r(t) dt = F' 
Ih 
Exercises 257 
Deduce from (E) that it is possible to choose F such that r < E. Con-
clude. 
f. Replicate e. for the symmetric assumption, i.e., that, if 
then j
t 
1 
_= h(8)7r(8) d8 = +00. 
6.6 Consider x '" B(n,p) and determine whether 80 :; 0 is an admissible esti-
mator of p under quadratic loss. 
6.7 Determine the beta priors Be( cr, (3) which correspond to the admissible es-
timators of Example 6.4. 
6.8 In the setting of Example 6.7, show that the Bayes risk of 81'0 is infinite and 
determine whether 8c* is a Bayes estimator. 
6.9 Show that the estimators 8cz proposed in §6.1 in a Poisson framework are 
indeed generalized Bayes estimators by exhibiting the corresponding prior 
distributions. 
6.10 (Johnson, 1971) Consider x '" B(n, 8). 
a. Show that 80 (x) = x is the maximum likelihood estimator of 8 and also 
a Bayes estimator under quadratic loss for 7r(8) = 1/8(1 - 8). 
b. Show that (80,1 - 80) is admissible under the loss 
(6.14) 
(Hint: Use the Bayes representation of 80 to show that 
J 
d8 
[R(8,8) - R(8, (80 , 1 - 80 ))] 8(1 _ 8) 20 
and to deduce that equality only occurs for 81 = 80, 82 = 1 - 80.) 
c. Show that a complete class for the loss (6.14) is made of the estimators 
such that 81 = 1 - 82 • 
d. Generalize the result of b. to the multinomial setting x '" Mk(n,P1, ... , 
Pk). (Hint: Use induction.) 
6.11 Establish the representation formula (6.3) and check the equalities in Ex-
ample 6.9. 
6.12 Consider the bounded loss 
L(8,8) = 1 _ e-a(II-6)2 
(a> 0), 
for the estimation of 8 when x '" N(8, 1). 
a. Determine the Bayes estimators associated with the conjugate priors 
() '" N(p" 7 2 ). 

258 6. Admissibility and Complete Classes 
b. Determine the Bayes estimators associated with the prior distributions 
11"( B) IX exp( - AlB - J.LI). 
c. Examine the admissibility of the generalized Bayes estimator associated 
with the Jeffreys prior 1I"(B) = 1 when a varies. (Hint: Determine if the 
Bayes risk is finite and apply the Blyth method if necessary.) 
Section 6.2 
6.13 Verify that the three conditions of Lemma 6.12 are actually satisfied in the 
case of a quadratic loss, 
L(B, 8) = (8 - B)tQ(8 - B), 
for every positive-definite matrix Q. 
6.14* (Clevenson and Zidek, 1975) Consider (Xl, ... , Xn) distributed as indepen-
dent Poisson random variables, Xi '" P(Ai). 
a. Use a sequence of conjugate priors and the Blyth method to show that 
80 (Xi) = Xi is an admissible estimator of Ai under quadratic loss. 
b. For n 2:: 2, show that 
and deduce that 80(Xl, ... ,xn ) = (Xl, ... ,xn ) is an inadmissible estima-
tor of A = (AI, ... , An). (Hint: Minimize (in A) lE>.[I:i A;l(axi - Ai)2] 
and replace the solution a by I:i xii I:i Xi + n - 1.) 
6.15 Establish the equivalent of Example 6.11 for the Poisson distribution, i.e., 
show that, if Ho: A ~ Ao and rp(x) = P>'o(X 2:: x), with X '" P(Ao), rp is 
admissible under quadratic loss. (Hint: Use the Blyth condition.) 
6.16 Solve Exercise 6.15 for the gamma distribution, 9(v, B) and Ho: B ~ Bo. 
6.17 Consider X '" N2(B, h). Check whether the Blyth condition for the admis-
sibility of 80 (x) = X is satisfied by the sequence 1I"n(B) equal to 
In the case that this sequence cannot be used, propose another sequence. 
6.18*(Hwang and Brown, 1991) Consider X '" Np(B, Ip). The usual confidence 
region is 
ex = {B; liB - xii < e}, 
with Po(B E ex) = I-a. Using the Blyth method, show that the evaluation 
')'0 (x) = 1 - a is admissible under the quadratic loss 
for p ~ 4. (Note: Robert and Casella (1993a) complete this result by showing 
that this constant estimator is inadmissible for p 2:: 5. On the contrary, 
Hwang and Brown (1991) establish that under frequentist validity ')'0 is 
admissible for every p (see §5.4).) 
6.19 In the setup of Example 6.11, show that, for X -I- 0, 

Exercises 259 
<p(x) = 
1 
l
liO t"'-1(1 _ t)m-x dt 
B(x,m-x+1) 
0 
and derive the corresponding representation for x = o. 
Section 6.3 
6.20 A class C is said to be minimal complete if C is complete and every proper 
subset of C is not complete. 
a. Show that every complete class contains every admissible estimator. 
b. Show that, if there exists a minimal complete class, it is exactly made 
of the admissible estimators. 
6.21 (Karlin and Rubin, 1956) Consider f(xI9) satisfying the monotone likeli-
hood ratio property (in x E JR), with £I E 8. The estimation problem is said 
to be monotone if L(9, 0) is minimum for 0 = q(9), with q increasing in £I, 
and if L(9, 0) is an increasing function of 10 - q(9)1. 
a. Show that, if L is convex, the estimators which are increasing functions 
of x constitute a complete class. 
b. Show that, if 00 is not monotone, the monotone estimator OM, defined 
by 
Pq-l(a)(OM(X) ::; a) = Pq-l(a) (oo(X) ::; a), 
Va 
dominates 00. 
c. If OM is strictly increasing, show that the above relation implies that 
OM (x) is a number a such that 
6.22 Apply Exercise 6.21 to the case where x rv N(9, 1), L(9, 0) = (£I - 0)2 and 
oo(x) = -ex + b, with c > o. 
6.23 (Berger, 1985a) Consider 8, a finite set of cardinality p, and assume that 
the risk set R is bounded and closed from below. Let r(R) be the lower 
boundary of R, i.e., 
r(R) = {r E R; lJr' E R, r' f= r and r~ ::; ri, 1::; i::; p} C R. 
The loss L is supposed to be convex. 
a. Show that the set of the estimators with risk vector in r(R) is a minimal 
complete class. 
b. Show that the set of the Bayes estimators is a complete class and that 
the set of the admissible Bayes estimators is a minimal complete class. 
c. Generalize to the case where L is not convex. 
6.24* (Berger and Srinivasan, 1978) Consider x rv Np (9, E) with E known. The 
mean £I is estimated under quadratic loss. Show that an estimator 00 is a 
generalized Bayes estimator if and only if 
(i) g(x) = E-100(x) is continuously differentiable, with symmetric Ja-
cobian matrix Jg(x) = VVtg(x); and 
(ii) for g(x) = Vr(x), exp{r(x)} can be expressed as a Laplace transform. 
6.25* (Fraisse et al., 1990) Consider x = (u, z) with u E JRk and z E JR, with 
density 
f(xI9,0) = exp{9· u + oz - K(9, o)} 

260 6. Admissibility and Complete Classes 
with respect to a o--finite v measure, with BEe c lRk and 8 E .d, compact 
subset of lR't-. 
a. Show (or accept) the following lemma: If (/Ln) is a sequence of measures 
with finite support such that, for almost every (u, z), 
supIIV1j!/Ln(z)11 < +00, 
n 
then there exist a measure /L and a subsequence (nk) such that 
and 
with 
b. Deduce from Proposition 6.16 that, for every admissible estimator 'P of 
B/8 under the squared error loss 82 11'P - B/811 2 , there exists a sequence 
of measures (Pn) with finite supports on e x .d such that 
with /Ln(dB,d8) = e- K (6,b)Pn(B,8). 
c. Show that the condition of the above lemma is satisfied and that for 
every admissible estimator 'P, there exists /Lo such that, a.e., it satisfies 
J Be6,uHz /Lo(dB, d8) 
'P(u, z) = J 8e(}·uHz/Lo(dB, d8)' 
i.e., 'P is a generalized Bayes estimator associated with /Lo. 
6.26 (Fraisse et al., 1990) Consider x '" Np(B, 0-2Ip) and S2 '" 0-2X~' The mean 
B is estimated under a quadratic loss, with 0- E [a, b]. 
a. Show that this model fits into the framework of Exercise 6.24. 
b. Consider the estimator 
Show that, if'P is admissible, there exists p E lR't- such that B = pC. 
c. Compare with the results of Exercise 6.24. 
6.27* (Moors, 1981) Consider x '" Be(p), with 0.2 ::; p ::; 0.8, and the parameter 
p is to be estimated under quadratic loss. 
a. Show that 811"(1) = 1 - 811"(0) when the prior 7r(p) is symmetric around 
1/2. 
b. Show that 811"(1) ::; maxp [l - 2p(1 - p)] = 0.68. 
c. Deduce that, if an estimator satisfies 8(1) = 1 - 8(0) and 8(1) > 0.68, it 
is inadmissible. 
6.28* (Johnson, 1971) 
Consider x '" B(n, B), with B to be estimated under 
quadratic loss. 
a. Recall why all admissible estimators are necessarily Bayes estimators. 

Exercises 261 
b. Show that the reverse is false, Le., exhibit some inadmissible Bayes es-
timators. 
c. Show that the set of admissible Bayes estimators is constituted of the 
estimators 
o 
liOSxS~ 
O.,.(x) = 
11 llX-!!(l _llr-x- n- 1 dT(ll) 
~ 
if 11 < x < n, 
lllX-!!-1(1-llr-x-n-1 dT(ll) 
1 
lin S x S n. 
d. Explain why 0.,. is a Bayes estimator for a whole class of prior distribu-
tions T. 
6.29 (Hwang et al., 1992) Consider Ho: 
II E 8 0 • Testing procedures 'Y are 
compared under a strictly convex loss, L(Ieo(ll),'Y). 
a. Show that 'Yo(x) = 1/2 is the only minimax estimator. 
b. Deduce that 'Yo is admissible. 
c. Is it possible to write 'Yo as a generalized Bayes estimator? Does this 
phenomenon contradict the complete class result of §5.3 (Theorems 5.9 
and 5.1O)? 
6.30 Given x rv exp(ll) and oc(x) = ex, determine the best estimator Oc of 
ll-l under quadratic loss. Show that this estimator is a generalized Bayes 
estimator and discuss its admissibility. 
Section 6.4 
6.31 (Robert and Casella, 1993b) Consider x rv N(ll, 1) and the usual confidence 
set Ox = [x-c, x+c]. Instead of using the fixed confidence report Q = Fo(ll E 
Ox), a procedure <p is proposed and evaluated under the loss 
L(ll,<p) = d(ll,Ox)(Ic.,(ll) _ <p)2, 
the weight d(ll, Ox) being a measure of the distance between () and the 
border of Ox. 
a. Motivate the use of a data-dependent assessment of a confidence interval 
and of the distance weight. 
b. In the particular case 
d((}, Ox) = 1- e-w(O-x)2 (1- e-W (O-X)2) , 
show that this distance is minimal for I(} - xl = c if w = 10g(2)/c2 • 
c. Give the general form of the Bayes estimators under this loss and show 
that the complete class result obtained in Theorem 5.9 still applies. 
d. For the class of symmetric distances of the form h(l(} - xl) and 7I"(ll) = 1, 
show that the Bayes estimators are constant and not necessarily equal 
to Q. Are these estimators admissible? 
6.32 Derive Proposition 6.23 from Lemma 6.22. 
6.33 Show that, if x rv Np((}, Ip), oo(x) = x is admissible when considered under 
the class of losses 

262 6. Admissibility and Complete Classes 
L(8, 6) = (8 - 6)tQ(8 - 6), 
where Q varies in the set of symmetric positive-definite matrices. 
6.34 (Hwang, 1982b) Consider x "" N p (8, Jp ). A class of estimators of 8 is given 
by 
for 0 ::; a ::; (p - 2). 
a. Show that 'Pa* associated with a* = p - 2 is optimal among the estima-
tors 'Pa under the usual quadratic loss. 
b. Derive the result of Example 6.14. 
c. Reproduce this technique with 
and b ~ (p - 2). Derive a STUB condition. 

7 
Invariance, Haar Measures, and 
Equivariant Estimators 
7.1. Invariance Principles 
Invariance can be seen as a notion introduced in frequentist settings to 
restrict the range of acceptable estimators sufficiently so that an optimal 
estimator can be derived. From this point of view, it appears as an al-
ternative to unbiasedness and is thus similarly at odds with the Bayesian 
paradigm. However, it also partakes from a non-decision-theoretic heuristic, 
namely that estimators should meet some consistency requirements under 
a group of transformations, and it is thus of interest to consider this notion. 
Moreover, a Bayesian perspective of invariance is justified by the fact that 
optimal (equivariant) estimators are always Bayes or generalized Bayes es-
timators. The corresponding measures can be considered as noninformative 
priors induced by the invariance structure. Therefore, a Bayesian study of 
invariance is appealling, not because classical optimality once more relies 
on Bayesian estimators, but mainly because of the connection between in-
variance structures and the derivation of noninformative distributions. 
A first version of the invariance principle is to consider that the prop-
erties of a statistical procedure should not depend on the unit of measure-
ment. If x and e are measured in unit Ul and if y and 'f/ are the transforms 
of x and e for the new unit U2, an estimator 82(y) of'f/ should then corre-
spond to the estimator P(x) of e by the same change of unit. Of course, 
the notion of unit of measurement is to be understood in a general sense: 
for instance, it can indicate the choice of a particular scale (cm vs. m)-and 
estimators should be scale invariant-the choice of a particular origin-in 
which case estimators should be translation equivariant-or even the order-

264 7. Invariance, Haar Measures, and Equivariant Estimators 
ing of the observations of the sample x-in which case estimators should 
be symmetric. 
Example 7.1 
Consider the problem of estimating the speed of light, 0, 
given an observation x, with distribution U[II-E,O+E] , measured in meters per 
second. A typical change of unit in this setup is the scale modification, y = 
TX, where, for instance, T = 10-3 for a switch from meters to kilometers. 
In this case, y rv U[ry-E' ,ry+E'] with 'TJ = TO, E' = TE, but the quantity 'TJ still 
represents the same intrinsic quantity, i.e., the speed of light. If 80 is an 
estimator of 0 in the initial unit, it seems legitimate to impose that the 
estimator in the transformed problem, 8*, satisfies the scale equivariance 
property 
Moreover, assume that the loss is the scaled quadratic loss 
L(O, d) = (1 _ 
~) 2 
It satisfies 
Therefore, the loss is invariant under this change of unit and the two esti-
mation problems are formally identical. It is then natural to select the same 
estimator for both problems, namely, 15* (y) = 150 (y). Considering both equa-
tions simultaneously, it follows that the estimator should satisfy 
for all T and y. Therefore, the decision rules which comply with the in-
variance requirements are necessarily of the form 150(x) = ax, where a is a 
positive constant. 
6 
This principle is often extended to a formal invariance principle, ac-
cording to which two problems with identical formal structures, (X, f(xIO), 
L), should lead to the same decision rule, even though they are not related 
physically as in the restricted invariance principle: in the previous example 
where the speed of light is always the same object. This extension does not 
seem so natural in a Bayesian perspective since the prior information is not 
necessarily the same in both problems. It is thus only in a noninformative 
setting that both approaches can be compatible. 
A Bayesian approach to invariance is thus justified for the following 
reasons: 
(i) 
The best invariant (or equivariant) estimator is a generalized Bayes 
estimator with respect to a particular measure called a Haar measure. 

7.2. The Particular Case of Location Parameters 265 
(ii) This measure can be defended in a noninformative setting as invariance 
provides an alternative method for constructing noninformative prior 
distributions. 
(iii) The most efficient method for deriving the best equivariant estimators 
is to use a Bayesian approach. 
Therefore, invariance considerations reinforce the Bayesian paradigm since 
it underlies once more a frequentist optimality criterion. For deeper cover-
ages of invariance, from both general and Bayesian perspectives, see Berger 
(1985a, Chap. 6), Eaton (1989), and Wijsman (1990). 
7.2. The Particular Case of Location Parameters 
Consider (Xl"'" xn) with density f(xI - 8, ... , Xn - 8), with an unknown 
location parameter 8 E IR. The natural invariance structure of this prob-
lem is invariance by translation. In fact, if (Xl"'" Xn) is transformed into 
(YI,"" Yn) = (Xl + a, ... , xn + a), this new random variable (YI,"" Yn) 
is distributed according to f(YI - 8 - a, ... , Yn - 8 - a) and 'f) = 8 + a is 
the corresponding location parameter. Therefore, the transformed vector 
has the same type of density and the problem is invariant under translation 
transformations. It seems logical to reproduce this structure by imposing 
the following invariance restriction on the estimators 8 of 8: 
(7.1) 
This condition is satisfied, for instance, by 80(XI, ... , xn) = x. Moreover, 
it also seems natural to impose a similar invariance restriction on the loss 
function, namely, that L(8+a, d+a) = L(8, d) for every a. A loss compatible 
with the invariance structure should then be of the form 
L(8, d) = L(O, d - 8) = p(d - 8). 
(7.2) 
The estimators satisfying (7.1) are called equivariant and the loss functions 
satisfying (7.2) invariant, both under the action of the translation group. 
The main purpose of these restrictions is obviously to reduce sufficiently the 
class of "acceptable" estimators so that there exists a single best equivariant 
estimator under the loss (7.2), since it is not possible without this restriction 
(see Exercise 2.36). The following lemma shows why there can be a single 
optimal estimator: 
Lemma 7.1 Under losses of the form (7.2), equivariant estimators 
have a constant risk. 
Proof. In fact, 

266 7. Invariance, Haar Measures, and Equivariant Estimators 
R(8, (}) = lEe [p(8(x) - (})] 
= lEe[p(8(XI - (}, ... , Xn -
(}))] 
= lEo [p( 8(xl, ... ,xn ))] = R( 8,0). 
--
Therefore, the particular setting of equivariant estimators under an 
equivariant loss is similar to the general case of all estimators under the 
Bayes risk: There exists a total ordering on this restricted class since the 
comparison of estimators is equivalent to a comparison of real numbers. 
This is why a best equivariant estimator can exist. 
The classical determination of this best estimator proceeds by condi-
tioning on a maximal ancillary statistic, like y = (Xl -
X n , • .. ,Xn-l -
xn). 
It is then straightforward to check that every equivariant estimator can 
be written as 8o(x) + v(y), where 80 is a particular equivariant estimator, 
80(x) = Xn say. 
Lemma 7.2 If there exists a function v* (y) which minimizes 
lEo[p(80(x) + v(y))ly], 
the best equivariant estimator under the loss (7.2) is given by 
8*(x) = 80 (x) + v*(y). 
Proof. By definition, the best equivariant estimator minimizes (in v) the 
constant risk 
R(8, (}) = lEo[p(8(x))] = lEo[p(80(x) + v(y))]. 
Since y is an ancillary statistic, it is possible to condition on y, decomposing 
the risk as 
lEo[p(80(x) + v(y))] = lE [lEo [p(80 (x) + v(y))lyJ]. 
If v*(y) minimizes the integrand for each y, 8* minimizes the risk over the 
class of the equivariant estimators. 
__ 
In the particular case where p( 8 - (}) = (8 - ())2, the optimal factor v* 
is given by 
v*(y) = -lEo[80(x)ly]. 
We have then derived the best equivariant estimator of Pitman (1939). 
Corollary 7.3 Under the quadratic loss L((}, d) = (() - d)2, the best 
equivariant estimator of () is 

7.2. The Particular Case of Location Parameters 267 
Proof. Consider 80 (X) = xn as the particular equivariant estimator used 
in Lemma 7.2 and let us denote Yn = Xn to complete y. The density of 
(Yl,"" Yn) is then (for 8 = 0) 
gY(Yl,"" Yn) = f(Yl + Yn,···, Yn-l + Yn, Yn), 
since Yi = Xi - Xn (i =I- n) and the Jacobian determinant is equal to l. 
Moreover, 
r~: tf(Yl + t, ... ,Yn-l + t, t) dt 
IEo [Yn IYl, ... ,Yn-l] = -+~oo:"'-----------
1-00 f(Yl + t, ... ,Yn-l + t, t) dt 
J~: tf(Xl - Xn + t, ... ,Xn-l - Xn + t, t) dt 
J~: f(Xl - Xn + t, ... , Xn-l - Xn + t, t) dt 
J~: 8 f(Xl - 8, ... ,Xn-l - 8, Xn - 8) d8 
=Xn -
-~-~-------------
J~: f(Xl - 8, ... ,Xn - 8) d8 
by the change of variable 8 = Xn - t. Since 
8* (Xl, ... ,xn) = Xn - IEO[YnIYl' ... ,Yn-l], 
the above expression of 8* follows. 
•• 
The main appeal of Corollary 7.3, besides providing the best equivari-
ant estimator, is to exhibit this estimator as a Bayes estimator, although 
the whole derivation does not involve any Bayesian input. The Pitman es-
timator is indeed a Bayes estimator associated with the prior distribution 
1r(8) = 1, i.e., the usual noninformative distribution for location parame-
ters (see Chapter 3). This result actually holds for the other invariant losses 
(7.2), as shown in §7.4. Therefore, the best equivariant estimator can be 
derived as the estimator 8 which minimizes the posterior loss 
J+OO p(8 - 8)f(Xl - 8 
X - 8) d8 
IE7r[L(8,8)lx]= -00 +00 
, ... , n 
, 
1-00 f(Xl - e, ... ,Xn - 8) d8 
or, equivalently, 
1
+00 
-00 p(8 - 8)f(Xl - 8, ... , Xn - 8) d8, 
and this representation drastically simplifies the derivation of the best 
equivariant estimators. Section 7.4 shows that the connection between best 
equivariant estimators and a particular class of Bayes estimators holds in 
much greater generality than for the estimation of location parameters. 

268 7. Invariance, Haar Measures, and Equivariant Estimators 
7.3. Invariant Decision Problems 
A general description of the relations between invariant problems and 
Bayesian analysis involves an abstract description of invariance through the 
action of invariance groups. Consider a statistical model, (X, 8, f(xIO)), 
and an inferential problem on 0 represented by a decision space, V. Assume 
in addition that a group g of transformations on X is provided with the 
pro blem. (It can also be perceived as a particular case of prior information.) 
The existence of such a group is important in the following case: 
Definition 7.1 The statistical model is said to be invariant (or 
closed) under the action of the group g if, for every g E g, there 
exists a unique 0* E 8 such that y = g(x) is distributed according 
to the density f(YIO*). We denote 0* = g(O). 
Example 7.2 Consider x '" f(x - 0) and the translation group 
The statistical model is then actually invariant under the action of g. This 
is not the case with the multiplicative group 
g' = {gc; gc(x) = ex, c > O}, 
since 
1 (Y-CO) 
y=cx", ~f -c-
. 
When the group g has a globally invariant action on the model, it 
naturally induces a set 9 of transformations on 8 and the fact that 9 is 
also a group is left as an exercise for the reader. To simplify notations, we 
will write g(x) as gx and g(O) as gO in the sequel. 
We assume in addition that the loss function associated with the model, 
L from 8 x V in IR +, is discriminant in the sense that two different de-
cisions are associated with different losses and, moreover, that the loss is 
compatible with the invariance structure in the following sense: 
Definition 7.2 If the model is invariant under the action of g, the 
loss L is said to be invariant under g if, for every 9 E g and d E V, 
there exists a unique decision d* E V such that L(O, d) = L(gO, d*) 
for every 0 E 8. This decision is denoted d* = g(d) and the 
decisional problem is said to be invariant under g. 
In this case, the group g induces a second group g, acting on V. Given 
these three groups g, g, and 9 and the above assumptions on the decision 
problem, it seems logical to restrict the class of estimators to the equivariant 
estimators, i.e., to those which satisfy 
8(gx) = g8(x). 

7.3. Invariant Decision Problems 269 
These estimators were also called invariant in the past. A particular case 
of interest is when () is estimated, i.e., when V = 8, since 9 = 9 in such 
settings. 
Example 7.2 (Cont.) Consider the estimation of () under the quadratic loss 
(() - d)2. The decisional problem is then invariant and 9 = 9 = 9. 
6 
Example 7.3 Consider x rv N(O, 0"2). The variance 0"2 is estimated under 
the entropy loss, 
8 
L(0",8) = 2" -10g(8j0"2) - 1, 
0" 
introduced in Chapter 2. If the group considered in this case is the group 
of scale transformations, 
9 = {gc; gc(x) = cx, c > O}, 
the associated groups are 
-
-
{-
2 
2 2 
} 
9=9= gc(O")=cO",c>O 
and the loss, thus the decisional problem, are also invariant under the action 
of9. 
6 
Example 7.4 Consider x rv Tp(v, (), Ip) and let 1I()I12 be the parameter of 
interest. A natural invariance structure is then invariance under orthogonal 
transformations, 
and the problem is invariant if the loss can be written as 
L((),8) = L(II()W,8), 
since there is always an orthogonal matrix A such that A() = II()II (1,0, ... , 
O)t and 9 reduces to the identity transformation. In this case, the equivari-
ant estimators only depend on Ilx112. 
6 
Definition 7.3 When 9 is a group operating on 8, ()l and (}2 are 
said to be equivalent if there exists 9 E 9 with ()2 = g()l. An orbit 
of 8 is an equivalence class for this relation and the group 9 is 
said to be transitive if 8 has a single orbit. 
If the group 9 is small enough, there may be many orbits. For instance, 
when x rv B(n,p) and 9 is restricted to go(x) = x and gl(X) = n - x, 
Q = {gO,gl} with gl(P) = 1 - p. Then there is an orbit associated with 
every p E [0,0.5]. However, when 9 is larger, this notion usually allows for 
the generalization of the phenomenon observed in the case of the location 
parameters. 
Theorem 7.4 
The risk of an equivariant estimator is constant 
within each orbit of 8, i. e., 

270 7. Invariance, Haar Measures, and Equivariant Estimators 
R( 0, (}) = R( 0, g(}) 
for every 9 E g. 
Proof. As for the estimators of location parameters, we derive that 
R(o,(}) = IEo [L((},o(x))] = IEo [L(g(},go(x))] 
= IEo [L(g(}, o(gx))] 
= IEgO [L(g(},o(x))] = R(o,g(}) 
for every 9 E g. 
An immediate consequence of Theorem 7.4 is the following result: 
Corollary 7.S If 9 is tmnsitive, every equivariant estimator has 
a constant risk. 
•• 
For transitive groups, it is thus legitimate to look for the best equiv-
ariant estimator by minimizing the constant risk R(o, (}o) on the class of 
equivariant estimators. However, the call to ancillary statistics, as in §7.2, 
is not always straightforward. A classical approach is to consider the max-
imal invariant statistic in order to reduce the dimension of the problem, 
similar to the call to minimal sufficient statistics under convex losses. 
Definition 7.4 For a group of transformations g, a statistic T(x) 
is said to be invariant if T(gx) = T(x) for every x E X and every 
9 E g. It is said to be maximal invariant if it is invariant and 
T(xt} = T(x2) implies that Xl and X2 are equivalent. 
In other words, a maximal invariant statistic is indexing the orbits of 
g. In particular, if g is transitive, the only maximal invariant statistics 
are constant. Moreover, it is straightforward to see that every invariant 
statistic is a function of a maximal invariant statistic. Note also that, if 9 
is transitive, T(x) is necessarily ancillary. 
Example 7.S Consider a distribution with a scale parameter a, 
1 
(Xl 
Xn) 
X = (Xb ... ,Xn) rv -f -, ... , -
, 
an 
a 
a 
when g is the multiplicative group, made of the transformations 
Then, if z = Ilxll, 
T(x) = {~ 
is a maximal invariant statistic. 
if z = 0, 
otherwise, 
(c> 0). 
Example 7.4 (Cont.) Similarly, if z = IIxll, the statistic 

T(X)={~ 
7.3. Invariant Decision Problems 271 
if z = 0, 
otherwise, 
is also maximal invariant for this problem. 
When determining the best equivariant estimator, the maximal in-
variant statistic can be used by conditioning. (Note that the choice of a 
particular maximal invariant statistic does not matter since they generate 
the same a-algebra, being in one-to-one correspondence with each other.) 
In fact, if g is transitive and T is a maximal invariant statistic, every equiv-
ariant estimator b satisfies 
R( b, e) = R( b, eo) 
= IEoo [L(eo, b(x))] 
= IE~o{IEoo[L(eo,b(x))IT(x) = t]} 
for an arbitrary value eo (as the risk is constant). Since T is maximal invari-
ant, every x such that T(x) = t can be written gXt, where Xt is a selected 
member of the orbit of x (assuming the axiom of choice holds). Therefore, 
for an equivariant estimator, b (x) = fib (Xt). It is then sufficient to minimize 
the above quantity in b(xt), conditionally on T, to obtain the best equivari-
ant estimator. Although straightforward, the above conditioning is actually 
instrumental in the determination of the best equivariant estimators and 
will be used in the sequel. 
Example 7.5 (Cont.) Note that, in this case, T is also an ancillary statistic. 
For the entropy loss, the minimization problem (in b) is over 
IEl[b(x) -logb(x)IT(x) = t] = IEdb(zt) -logb(zt)IT(x) = t] 
= IEdzb(t) -logb(t) -log(z)IT(x) = t] 
(where z = Ilxll). By linearity of the expectation, b(t) is minimizing 
IEl[ziT = t]b(t) -logb(t), 
and therefore satisfies 
b*(t) = IEdzl~ = t]· 
The best equivariant estimator of a is thus 
* 
Ilxll 
b (x) = IEl[ziT = x/llxll] 
In the particular case where Xi rv N(O, a 2 ), we derive that the best equiv-
ariant estimator of a is 
* 
Ilxll 
b (x) = IEl(llxll) 
r(p/2) 
y'2r(p + 1/2) Ilxll· 

272 7. Invariance, Haar Measures, and Equivariant Estimators 
Further details on this technique are given in Berger (1985a, §6.5) and 
Eaton (1989, §2.3). 
7.4. Best Equivariant Estimators and 
N oninformative Distributions 
In this section, we generalize the result obtained in §7.2 in the particular 
case of location parameters. We show that it is indeed possible to relate 
the best equivariant estimator to a a-finite measure on 8 called a right 
invariant Haar measure. For a more detailed and more rigorous treatment, 
see Eaton (1989) and Wijsman (1990). 
Let us assume first that, for a statistical problem which is invariant 
under the action of Q, there exists a probability distribution rr* on 8 which 
is also invariant under the action of g, i.e., such that 
rr*(gA) = rr*(A) 
for every measurable set in 8, i.e., every A E B(8), and for every 9 E Q. In 
this case, the Bayes estimator associated with rr*, 8*, minimizes 
L 
R(8*, 0) drr*(O) = L 
R(8*,gO)drr*(0) 
= L 
IEo [L(0,g-18*(gx))] drr*(O) 
and, if the Bayes estimator is unique, it satisfies 
8*(x) = g-18*(gx) 
rr-almost everywhere, the set of measure zero where the equality does not 
hold depending on g. Therefore, a Bayes estimator associated with an in-
variant prior and a strictly convex invariant loss is almost equivariant. 
When Q is not countable, the collection of the above sets of measure zero 
over all g's is not necessarily of measure zero, but it is possible to show 
that, under additional conditions (see Lehmann, 1986, Chap. 6, Theorem 
4), there exists an equivariant estimator which is a Bayes estimator with 
respect to rr* (see also Strasser, 1985). 
Example 7.6 Consider 81T"(x) = IE1T"[Olx] under an invariant proper loss. If 
rr* is an invariant probability distribution, the Bayes estimator associated 
with rr* satisfies 
81T"(gx) = Ie Of(gxIO) drr*(O) 
Ie f(gxIO) drr*(O) 
_ Ie Of(xlg-10) drr*(O) 
- Ie f(xlg-10) drr*(O) 
_ Ie g17f(xl17)drr*(17) 
- Ie f(xl17) drr*(17) . 

7.4. Best Equivariant Estimators and Noninformative Distributions 273 
Therefore, if 
l gTJf(xITJ) d7r*(TJ) = 9 l TJf(xITJ) d7r*(TJ), 
for every g E g, 8* is indeed equivariant. 
Actually, invariant probability distributions are rare, since they can 
only exist for compact groups 1 g (see Lehmann, 1983, Chap. 4, Example 
4.2, for an illustration on a noncountable group). In other setups, it is 
necessary to consider invariant measures, for which the above results do 
not necessarily hold (since formal Bayes estimators are not always defined). 
Example 7.2 (Cont.) If 7r is invariant under the action of the translation 
group, it satisfies 7r( ()) = 7r( () + c) for every () and for every c, which implies 
that 7r(()) = 7r(0) uniformly on ffi and thus leads to the Lebesgue measure 
as an invariant measure. 
6, 
Example 7.7 Consider Xl, ... , Xn a sample from N((), 0'2), with unknown 
() and 0'2. For sufficiency reasons, we can consider the couple (x, s), where 
x is the empirical mean and S2 is the sum of the squared errors. In this 
setting, the group to consider is the affine group 
g={ga,b; ga,b(X,S) = (ax+b,as), a>O,bEffi} 
and g = 9 = 9 if the parameter to be estimated is ((), 0'). If 7r is an invariant 
measure, its density satisfies 
a27r(a() + b, aO') = 7r((), 0'), 
Va > 0, Vb E ffi 
which implies 
Therefore, an invariant measure is proportional to 7r((), 0') = 1/0'2 and cor-
responds to the Jeffreys measure obtained in Chapter 3. 
6, 
In general, given a locally compact topological group 9 and defining 
K(9) as the set of continuous real functions on 9 with compact support, 
we introduce for g E 9 the transformation Lg on K(Q) as 
(Lgf)(x) = f(gx) 
for f E K (9), X E g. 
An integral Jon K(9) is said to be left invariant if 
J(Lgf) = J(f) 
1 When 9 is not a subset of lRT, the topological structure induced by 9 is the 
topology induced by the group composition and inversion, i.e., the smallest 
collection of open sets such that the group composition and inversion are con-
tinuous (see Rudin, 1976). 

274 7. Invariance, Haar Measures, and Equivariant Estimators 
for every f E K(Q) and for every 9 E 9. The Radon measure Vi associated 
with J is said to be a left Haar measure and it can be shown (see Nachbin, 
1965) that this measure is unique up to a multiplicative factor. Defining Rg 
on K(9) by 
(Rgf)(x) = f(xg), 
for f E K(9), x E 9, 
we derive similarly right invariant integmls and a right Haar measure Vr, 
also defined up to a multiplicative constant. As mentioned above, the finite-
ness of the Haar measure, i.e., the existence of an invariant probability dis-
tribution, is in fact equivalent to the compactness of 9. See Eaton (1989, 
Chap. 1) for examples of Haar measures; Berger (1985a) details the case 
where 9 c JRk • 
The modulus of 9 is defined as the multiplier Ll-i.e., a real-valued 
function satisfying Ll(glg2) = Ll(gl)Ll(g2)-which relates left and right 
Haar measures by 
vr(dx) = Ll(x-1)vt(dx) 
(see Exercises 7.13 and 7.15). We assume the existence of a Radon measure 
J..l on X such that, for every f, 
This relation shows the connection between the modulus of 9 and the Jaco-
bian of the transformation of x in gx. Consider the distributions p(), () E 8, 
with density f(xl()) with respect to J..l. Then, for every 9 E 9, 
We also assume that 9 acts tmnsitivelyon 8. As shown in Eaton (1989, p. 
84), some additional assumptions then ensure the validity of a theorem a 
la Fubini: If Vr is the right Haar measure on 9, Q is the projection of X 
on X / 9, and (T f) is defined on x;g by 
(Tf)(Q(x)) = l f(gx)vr(dg), 
then there exists an integml h defined on K(X /9) such that 
This can be rewritten as the fact that the integral of f with respect to J..l is 
the integral over all the orbits of X (i.e., on X /9) of the average of f with 
respect to the right Haar measure on each orbit, Tf. 
Consider a nonrandomized estimator 8 and, for a fixed () E 8, let us 
define 
fo(x) = L((),8(x))f(xl()), 

7.4. Best Equivariant Estimators and Noninformative Distributions 275 
then 
R(o, e) = Ix fo(x)J1(dx). 
It follows from the above theorem a la Fubini that there exists an integral 
J1 on K(X /9) such that 
with 
(Tfo)(Q(x)) = i L(e, o(gx))f(gxle)vr(dg) 
= i L(ge, o(x))f(xlge)vr(dg) 
(see Eaton, 1989, p. 85). We also define 
H(a, x) = i L(ge, a)f(xl!Je)vr(dg), 
which does not depend on e (since Q acts transitively on 8). Note that 
H(o(x), x) gives the risk of 0 conditionally on the orbit of x. It is instru-
mental in the derivation of the best equivariant estimator. 
Theorem 7.6 If there exists ao(x) such that 
(i) H(a,x) 2: H(ao(x),x) for every a E D, x E X; and 
(ii) ao(gx) = gao(x) for every g E Q, x E x: 
then 00 (x) = ao (x) is a best equivariant estimator. 
Proof. Consider an equivariant estimator o. Then 
h 
L(ge, o(x))f(xlge)vr(dg) 2: h 
L(ge, ao(x))f(xlge)vr(dg). 
Integrating with respect to J1 , it follows that R(8, e) 2: R(oo, 0). The esti-
mator 80 then dominates o. 
• • 
This theorem points out the relation existing between the best equiv-
ariant estimator and a particular Bayes estimator, since H(a, x) can also 
be interpreted as a posterior Bayes risk. In fact, if eo E 8 is arbitrarily 
selected, the function T(g) = geo defines a surjection from Q to 8, because 
of the transitivity of Q. It therefore induces a measure on 8, called a right 
Haar measure on 8, which is defined by 7r*(B) = Vr(T- 1(B)) for every 
BE 13(8), and is obviously invariant under the action of Q. Moreover, 
H(a, x) = Ie L(e, a)f(xle) d7r*(e). 
This extension of the right Haar measure to 8 implies the following result 
which expresses the best equivariant estimator as a Bayes estimator for 
every transitive group acting on a statistical model. 

276 7. Invariance, Haar Measures, and Equivariant Estimators 
Corollary 7.7 
The best equivariant estimator of () is the Bayes 
estimator associated with the right H aar measure on 8, 7f*, and 
the corresponding invariant loss. 
Therefore, we have obtained a method which derives the best equivari-
ant estimators directly from the right Haar measure. (See Stein, 1965, and 
Zidek, 1969, for similar results.) 
In the above development, the dominating measure is /-L, which is rel-
atively invariant with multiplier the modulus ,1-1. In fact, if the measure 
/-L is relatively invariant with an arbitrary multiplier X, i.e., such that, for 
every f E K(Q), L 
f(gx)/-L(dx) = X(g) L 
f(x)/-L(dx) , 
Corollary 7.7 will still hold (see Eaton, 1989, p. 87). 
Example 7.7 (Cont.) We obtained the following left Haar measure on 8: 
7fc ( (), 0") = 1/0"2. 
The right Haar measure can be derived by inversion: if g = (a, b) and 
go = (ao, bo), ggo = (aao, abo + b) for the group composition. Taking the 
Jacobian into account, we want the right Haar measure to satisfy 
for every ((),O") and uniformly in ao, bo; this implies 
up to a multiplicative factor. Therefore, the right Haar measure is different 
from the left Haar measure and gives the noninformative alternative to the 
Jeffreys prior (see §3.5). Under the invariant quadratic loss, 
(7.3) 
the best equivariant estimator is the Bayes estimator associated with the 
prior distribution 7fT, i.e., 
Since 
this is a special case of conjugate distribution on ((), 0") and 
8~(x, s) = x, 
8*(x s) = 
r(n/2) 
s 
2' 
J2r((n + 1)/2) . 

7.4. Best Equivariant Estimators and Noninformative Distributions 277 
Note that 82 is also the estimator obtained in Example 7.5. 
Example 7.8 (Eaton, 1989) Consider a multiplicative model N(e, e2), with 
n observations Xl, .•. ,Xn . This model appears in setups where the difficulty 
to measure an object increases with the magnitude of this object (Particle 
Physics, Astronomy, etc.). If we estimate e under the loss 
L(e d) = (e-d)2 
, 
e2
' 
the problem is invariant under the action of the multiplicative group. The 
right Haar measure is then 7r(e) = l/lel. (It is also the left Haar measure 
since the group is commutative.) 
Therefore, the best equivariant estimator of e is 
and 
for S2 = I:~=1 x;. The posterior distribution is then a generalized inverse 
normal distribution IN(2, nx/ s2, 1/ S2) (Robert, 1991) and 
Therefore, 
In this case, the best equivariant estimator dominates the maximum likeli-
hood estimator 
, _ 
-x + (x2 + 4S2 )1/2 
8(x,s) = 
2 
' 
which is also equivariant. For additional results on the multiplicative mod-
els, see GIeser and Healy (1976), Kariya (1984), Kariya et al. (1988), and 
Perron and Giri (1990). 
6. 
The reader is referred to Eaton (1989), Lehmann (1986), and Berger 
(1985a) for other examples of the use of Haar measures in the derivation of 
best equivariant estimators in the case of tests and confidence regions. A 
general reference on Haar measures is Nachbin (1965). 

278 7. Invariance, Haar Measures, and Equivariant Estimators 
7.5. The Hunt-Stein Theorem 
If we consider the particular case discussed at the beginning of the previous 
section, namely the case when 9 is compact and where there exists an 
invariant probability distribution on 8, the best equivariant estimator is a 
(proper) Bayes estimator and is therefore admissible in most cases. Since 
its risk is constant when 9 is transitive, the best equivariant estimator 
is also minimax. When 9 is not compact, the best equivariant estimator 
is a generalized Bayes estimator associated with the right Haar measure, 
and therefore is not necessarily admissible. The Stein effect (see §2.4.6) 
is an illustration of this possible suboptimality since the best equivariant 
estimator of a location parameter x is inadmissible for the quadratic loss 
in dimension 3 and more, as shown by Stein (1955a) and Brown (1966). 
Therefore, the question of the admissibility of the best equivariant estimator 
cannot be considered in general for noncompact groups. 
On the contrary, it is possible to extend the minimaxity property fur-
ther than for the compact case, through the Hunt-Stein Theorem. 2 This 
result is intuitively sound: When a problem is invariant, there exists an 
equivariant estimator with a constant risk which attains the lower bound 
of the maximal risks, 
inf sup R( 8, 0). 
8 e 
Furthermore, using the natural invariant structures of the model, it seems 
legitimate to improve on an estimator 8, by averaging it, i.e., by integrating 
over g 
8*(x) = ~ 8(gx)vr(dg), 
if L(O, d) is convex in d and if the theorem a la Fubini given in §7.4 applies 
(assuming 8* is well defined). In fact, we would then get (in an informal 
way) 
R(8, 0) = JEe[L(O, 8(x))] 
= JET(JEe[L(O, 8(x))IQ(x) = T]) 
~ JET[L(O, 8* (t))] 
= R(8*, 0). 
This improvement is similar to the domination result of the Rao-Blackwell 
Theorem, when conditioning on a sufficient statistic. We formalize below 
this sketch of proof a bit further by introducing the notion of an amenable 
group presented in detail in Bondar and Milnes (1981). First, the following 
counterexample shows that intuition is not always satisfactory, in particu-
lar, when the invariance structures are too strong, i.e., when 9 is too large. 
2 This theorem is also famous for remaining without published proof for a long 
time, although Kiefer (1957) established this result in a particular case. 

7.5. The Hunt-Stein Theorem 279 
Example 7.9 (Stein, 1965) Consider x rv Np(O, E) and y rv Np(O, pE) with 
p ?: 2. The parameter p is estimated under the loss function 
L((p,E),d) = 1[1/2,+00) (11 - ~I). 
The problem is then invariant under the action of the linear group GLp 
since, if B is a nonsingular matrix, Bx rv Np(O, BEBt) and By rv Np(O, 
pBEBt). As 9B(P, E) = (p, BEBt), the equivariant estimators are actually 
invariant 
8(Bx, By) = 8(x, y) 
for every x, y, and B. If x and yare linearly independent (an event which 
occurs with probability 1), we can find B such that 
Bx = (1,0, ... ,O)t 
and 
By = (0,1,0, ... ,O)t, 
which implies that the equivariant estimators are almost everywhere con-
stant. Since 
R(80 , (p, E)) = 1 
if 11- ;1 > 1/2 
for a given constant 80, the minimax risk of the equivariant estimators is 1. 
On the contrary, defining 
the risk of 81 is 
R(81 , ()) = Pp,E (11-1 ~lp II ?: 1/2) 
= P (11 -I ;~ II ?: 1/2) , 
where Zl, Z2 are i.i.d. N(O, 1). Therefore, this risk is also constant but strictly 
smaller than 1. Note that 81 is also an equivariant estimator for the multi-
plicative group which then appears as a more appropriate invariance struc-
ture. 
~ 
For a general approach to this problem, consider a locally compact 
group of transformations g, with a right Haar measure /Jr' Let V be an 
algebra of real-valued essentially bounded measurable functions on g, such 
that the constant function 1 is in V. 
Definition 7.5 A mean on V is a linear and continuous functional 
m on V such that 
(i) m(l) = 1; and 
(ii) m(J) ?: ° 
if f E V and f ?: ° 
(a.s.). 

280 7. Invariance, Haar Measures, and Equivariant Estimators 
That such a functional m exists is actually a necessary and sufficient 
condition for the Hunt-Stein Theorem to hold. In this case, it is then pos-
sible to average on the orbits of X with respect to g, as suggested at the 
beginning of this section. 
Example 7.10 (Bondar and Milnes, 1981) For 9 = lR and n E 1N, consider 
1 jn 
mn(f) = 2n -n f(x) dx; 
then mn defines a mean on £00 (lR). Moreover, the sequence (mn) has an 
accumulation point m in the sense of the weak topology on £00: For every 
f E £00' E> 0, and no E 1N, there exists n 2: no such that 
In particular, this accumulation point satisfies m(f) = 0 for every f such 
that f(x) goes to 0 when x goes to ±oo. Note also that m is not a-additive 
and that the sequence (mn ) does not converge to m in the sense of the weak 
topology. 
D" 
Definition 7.6 The mean m is said to be right invariant if, for 
every f E V and 9 E g, m(fg) = m(f), where fg(x) = f(xg). The 
group 9 is said to be amenable if there exists a right invariant mean 
on £00(9) or, equivalently, on CB(Q), the space of the continuous 
bounded functions on g. 
As shown in Bondar and Milnes (1981), the existence of an amenable 
group is equivalent to the existence of a sequence of almost right invari-
ant probability measures: in such a case, there exists a sequence (Pn ) of 
probability measures on 9 such that, for every B E B(Q) and every 9 E g, 
Moreover, there exists a sequence (Gn ) of nested compact sets such that 
the density of Pn is IIr (Gn )-l:n:On(g) (with respect to IIr ). Therefore, the 
existence of the sequence (Gn ) allows for the approximation of the Haar 
measure IIr by a sequence of probability distributions and these probabilities 
are almost invariant in the sense that if BnGn = BgnGn, Pn(B) = Pn(Bg) 
(see also Strasser, 1985, and Lehmann, 1986). Example 7.10 provides a 
direct illustration of this result. 
Examples of amenable groups are the additive and multiplicative 
groups, the group of location-scale transformations (see Example 7.6), and 
the group Tp of invertible upper triangular matrices. On the contrary, the 
linear group G Lp and the group SLp of matrices with determinant 1 are 
not amenable. Bondar and Milnes (1981) provide many other structural 
examples of amenable and nonamenable groups. 
The Hunt-Stein Theorem then states the announced result about the 
minimaxity of the best equivariant estimator. 

7.5. The Hunt~Stein Theorem 281 
Theorem 7.8 If the group g is amenable and the statistical prob-
lem (X, f(xle), V, L) is invariant under the action of g, the exis-
tence of a minimax estimator implies the existence of a minimax 
equivariant estimator. Moreover, an equivariant estimator which 
is minimax among the equivariant estimators is minimax. 
A proof of this theorem is provided by Berger (1985a, §6.7) in the 
case where g is finite, by Lehmann (1983, §9.5) for tests, and by Le Cam 
(1986, §8.6) in more general settings, as a consequence of the fixed point 
theorem of Markov and Kakutani. As mentioned at the beginning of this 
section, the Hunt-Stein Theorem relies on an adapted version of the Fubini 
Theorem. To give a quick sketch of a proof, let us assume L is convex. For 
a real-valued estimator 8, define 
where m is the right invariant mean and 8x (g) = 8(gx). The estimator 8* 
is then equivariant since, if go E g, 
8*(gox) = 10 g~18(ggox) dm(g) 
= 10 gOgolg~18(ggox) dm(g) 
= go 10 g-18(gx) dm(g) = g08*(x), 
because of the right invariance of m. Moreover, 
sup R(8*, e) :::; sup r r L (e, g-18(gx)) f(xle) dx dm(g) 
(7.4) 
e 
e }g}x 
from the convexity of L. Therefore 
supR(8*, e) :::; sup r r L(ge,8(gx))f(xle)dxdm(g) 
IJ 
IJ }g}x 
= sup r R(ge, 8) dm(g) :::; sup R(8, e), 
IJ }g 
IJ 
which implies3 the domination of 8 by 8*. 
A consequence of the Hunt-Stein Theorem is that, in the normal case, 
the maximum likelihood estimator, x '" Np(e,Ip), is minimax for every 
value of p, although inadmissible for p 2: 3. The same result holds if x '" 
3 Note that these indications do not constitute a rigorous proof, since the ap-
plication of the Fubini Theorem in (7.4) is not always justified. In fact, this 
"averaging" can only be used under particular conditions. Otherwise, it would 
also lead to a general admissibility result for the best equivariant estimator 
under convex losses, a result negated by the Stein effect. 

282 7. Invariance, Haar Measures, and Equivariant Estimators 
Np((), O'2Ip) and if the unknown variance 0'2 is estimated by s2 jq, when 
S2 '" O'2x~. 
7.6. The Role of Invariance in Bayesian Statistics 
As a conclusion to this chapter, let us reiterate the reservations expressed 
in Berger (1985a) about the implications of the invariance requirements 
on the Bayesian approach, in particular, as a determination technique for 
noninformative distributions, even though it provides a justification for the 
choice of an alternative to the Jeffreys prior (see Example 7.6). 
A first criticism of the notion of invariance is that, although intuitively 
attractive, it is not devoid of ambiguity and that, since it is sometimes 
possible to consider several globally invariant groups, the resulting best 
equivariant estimators can lead to distinct inferences, in contradiction with 
the Likelihood Principle. 
A second point is that the "natural" invariance structures of a sta-
tistical model can be either too weak and thus of no use to determine an 
estimator, or too strong and therefore too constraining. An extreme exam-
ple of the first setting is the Poisson distribution, where there is actually no 
invariance structure at all. The following example illustrates the opposite 
case (see also Example 7.9): 
Example 7.11 Consider a distribution family which is symmetric around 
a location parameter (), Le., such that x '" f(lx - (1). The loss function is 
p(ld - (1). If the invariance by symmetry, Le., the fact that the distribution 
of y = -x belongs to the same family, is taken into account, the estimators 
which correspond to rr(()) = 1 and satisfy 
8(x+c) = 8(x) +c 
and 
8(-x) = -8(x) 
reduce to 8(x) = x, which is not necessarily a good estimator. 
An excess of invariance can obviously be reduced by taking into account 
only a part of the invariance structures, Le., by considering a subgroup go of 
g which induces a transitive action on e, while being as small as possible. 
Nonetheless, the choice of this subgroup, when possible, can be crucial in 
the resulting inference. 
As a last important point, note that a modeling of statistical prob-
lems based on invariant structures can be damaging from a subjective point 
of view, since it constrains the decision structures to be compatible with 
invariance-therefore, in particular, to choose an invariant loss-and can 
conflict with the prior information-the only compatible prior distribu-
tion being the Haar measure-as well as from an efficiency point of view, 
since the equivariant estimators can be strongly inadmissible, as shown by 
the Stein effect and Example 7.9 (see also Examples 4.4-4.6 in Lehmann, 

Exercises 283 
1983, §4.4). Moreover, invariance does not necessarily lead to a good non-
informative distribution, as shown by Example 7.11. And, in practice, the 
computation and the use of right Haar measures can be quite involved. 
Exercises 
Section 7.2 
7.1 
(Blackwell and Girshick, 1954) Consider the distribution f with weights 
f(k) = l/k(k + 1) for k = 1,2, ... and x "" f(x - 0), with 0 E JR. Under the 
loss function, 
L(O d)= {d-O 
ifd>~, 
, 
0 
otherwIse, 
show that the equivariant estimators are of the form x - c and that ev-
ery equivariant estimator has an infinite risk. Compare with the constant 
estimator 80(x) = c. 
7.2 Consider x an observation from a C(O, 1) distribution. Under quadratic loss, 
show that all equivariant estimators have infinite risk. Propose a finite risk 
estimator other than the constant estimator. 
7.3 (Berger, 1985a) Consider 
x = (Xl, ... ,Xn ) "" f(XI - 0, ... ,Xn - 0), 
where 0 is unknown. The hypothesis Ho : f = fo is to be tested against 
HI : f = !I under the "0 - I" loss. 
a. Show that T(x) = (XI-Xn , ... ,Xn-I-Xn ) is a maximal invariant statis-
tic for the group of transformations 
9 = {ge; ge(XI, ... ,Xn ) = (Xl + C, ... ,Xn + c), c E JR}. 
b. Deduce that every invariant test only depends on y = T(x) and that the 
optimal tests have the following rejection region: 
where ft is the density of y under Hi. 
7.4 (Berger, 1985a) Consider X distributed according to 
Po(X = 0 - 1) = Po(x = 0 + 1) = 1/2. 
The associated loss function is 
L(O, d) = { 110 - dl 
if 10 - dl :5 1, 
otherwise. 
Give the best equivariant estimators for the translation group and show 
that they are dominated by 
8*(x) = {X + 1 if X :5~, 
x-I otherwIse. 
7.5 (Berger, 1985a) Consider Xl, ... ,Xn a sanIple from the truncated normal 
distribution, with density 

284 7. Invariance, Haar Measures, and Equivariant Estimators 
(2) 1/2 
2 
f(xle) =:;;: 
e-(x-8) /2][[8,+00) (X). 
Show that the best equivariant estimator of e under quadratic loss is 
*() 
_ 
exp{ -n(x(1) - x? /2} 
8x=x-
. 
v2mr<P( y'n(x(1) - x)) 
Section 7.3 
7.6 Consider x '" N(e, ae2 ), with e E IR and known a > O. The parameter e is 
estimated under the loss L(e,d) = (~-1? 
a. Show that the problem is invariant under the group of transformations 
9 = {gcj gc(x) = CX, c> O}. 
Is the action of the group transitive? 
b. Give the best equivariant and the maximum likelihood estimators of e. 
c. Compare with the estimators obtained in Exercise 3.29 and in Example 
7.8. 
d. Use Exercise 3.29 to show that the best equivariant estimator 80 is a 
generalized Bayes estimator. 
7.7 (Lehmann, 1983) Consider the estimation of a scale parameter (J, under 
the loss 
(7.5) 
for n observations 
Xl, ... , Xn '" ~ 
f (Xl, ... , Xn) . 
(In 
(J 
(J 
a. If z == (Xl/Xn, ... , Xn-dXn, Xn/lxnl), show that every estimator of (J 
equivariant under scale transformations can be written 
8(x) = 80 (x)/w(z), 
where 80 is a particular equivariant estimator, and that z is a maximal 
invariant statistic. 
b. Determine the function w* which minimizes 
under (7.5) and deduce the best equivariant estimator. 
c. Write this estimator in an appropriate form in order to find the result 
of §7.4 with the corresponding Haar measure. 
d. Consider the previous questions for the estimation of (JT (r E IR:t) under 
the loss 
7.8 Apply the results of Exercise 7.7 to the following cases: 
(i) Xl, ... , Xn are i.i.d. N(O, (J2)j 
(ii) Xl, ... ,Xn are LLd. 9(o:,(J)j and 
(iii) Xl, ... , Xn are Li.d. UfO, (Jl. 

Exercises 285 
7.9 Examine Exercise 7.7 under the following losses: 
7.10 (Lehmann, 1983) Consider the estimation of a in the case where 
1 
(Xl-B 
xn-B) 
X=(Xl, ... ,xn)rv-f --, ... ,--
, 
an 
a 
a 
under the action of the affine group 
ga = {ga,b; ga,b(X) = ax + b1, a> 0, bE JR}, 
where 1 = (1, ... ,1) E JRn . 
a. Determine the best equivariant estimator under the loss (7.5) similarly 
to Exercise 7.7. (Hint: Use the transformations Yi = Xi - Xn and define 
Zi = Y;/Yn-l (i -=I- n - 1), Zn-l = Yn-dIYn-ll·) 
b. Compare with a Bayesian formulation using the right Haar measure. 
c. Consider the previous questions when estimating B under the loss 
d. Apply to the case where Xi - B rv £xp(a) and show that the best equiv-
ariant estimator of B is 
8*(x) = XCI) -
~2 t(Xi -XC!))· 
i=l 
7.11 * (Eaton, 1989) Consider 9 c JR:t x JR, with the group operation 
(aI, bl )(a2, b2) = (ala2, alb2 + bl ). 
If D = {x E JRn; Xl = ... = x n }, consider X = JRn - D. Assume that 9 
acts on X by 
(a, b)x = ax + ben, 
where en = (1, ... , l)t. Show that the maximal invariant statistic is 
f(x) = X ~:)en , 
with x = '£Xi/n, S2(X) = '£(Xi - X)2. 
7.12* (Eaton, 1989) Verify that if there exists a multiplier eon g, i.e., a real-
valued function such that e(glg2) = e(gl)e(g2), which satisfies 
f(XIB) = f(gxlgB)e(g) 
uniformly on X, 8, g, the family 
P = {J(xIB); BE 8} 
is g-invariant. Deduce that, in this case, the maximum likelihood estimator 
is equivariant, as well as every Bayes estimator associated with a relatively 

286 7. Invariance, Haar Measures, and Equivariant Estimators 
invariant prior measure, i.e., such that there exists a multiplier 6 with 
7r(gB) = 6 (g)7r(B) uniformly in Band g. 
7.13* (Delampady, 1989b) Consider x rv Np ((}, Jp ). The hypothesis Ho: () = (}o 
is tested against HI : () =f. (}o. This problem is invariant under the action 
of the orthogonal group Yo and we only consider prior distributions in the 
invariant class 
a. Show that t(x) = IIxl12 is a maximal invariant statistic, distributed as 
a noncentral X~, with the noncentrality parameter 11((}) = 11(}112 (the 
corresponding maximal invariant statistic on go) and that its density 
can be written 
q(t(X)I11((})) = 1 
f(gxl(}) dp,(g) , 
go 
where p, is the Haar measure on Yo. 
b. Deduce that if B''' is the Bayes factor, it satisfies 
. f B7r( ) _ q(t(x)l(}o) 
!~I 
x -
q(t(x) 11]) , 
where 1] is the maximum likelihood estimator of 11. 
c. Compare with the p-value for different values of t(x). 
7.14 Show that the intrinsic losses defined in §2.5.4 are naturally invariant. 
7.15 Consider x rv N((},(j2) and the parameter of interest is ee, when (j2 is 
known. 
a. Show that 
2 
b. Among the estimators of the form bc(x) = eX+C(T , determine the best 
estimator for the quadratic loss L2, b* . Show that b* is a Bayes estimator 
and determine the corresponding prior 7r*. (Consider first the Lebesgue 
measure and the weighted quadratic loss 
What is the Bayes estimator for the Lebesgue prior under L2?) 
c. Consider the previous question for the absolute error loss, 
Show that the best estimator is associated with 7r( (}) = e -e. Is this 
answer surprising from an invariance point of view? 
d. Given the estimator b*, we want to evaluate the performances of b* 
under Lo and L2, i.e., to estimate Lo ((), b* (x)) and L2 ((), b* (x)) under 
the quadratic loss 
(Lo((), b*(x)) - "()2. 
(7.6) 
Show that, for 7r((}) = 1, the posterior loss IE7r[Lo((}, b*)lx] is constant 
and equal to the constant risk of b* . 
e. Show that, for 7r*((}) = exp(-2(}), the posterior variance of b* is 

Exercises 287 
,),71"(x) = e2x-2a2 (1- e- (2 ) 
• 
Show that ')'71" is an unbiased estimator of the risk, JEe[L2(0, 8* (x))] and 
that it is dominated by the Bayes estimator of L2(0, 8* (x))] under K(O) = 
e-4e . Can you justify the use of this prior on invariance grounds? 
Section 7.4 
7.16* (Eaton, 1989) Show that, for a topological group g, two left invariant 
integrals, Le., functionals such that 
1 
f(gx)p,(dx) = 1 
f(x)p,(dx) 
for every f E {,1 (p,) and 9 E g, are necessarily proportional. 
7.17* (Eaton, 1989) Consider Ve a left Haar measure, f E K(9) and 
a. Show that J1 is left invariant. Deduce that there exists a function .1 on 
9 such that 
J1(f) = .1(g) 1 
f(x)ve(dx) = .1(g)J(f). 
The function .1 is called the modulus of g. 
b. Show that .1 does not depend on the choice of J1 and that .1(glg2) = 
.1(gl).1(g2) (Le., .1 is a multiplier). 
c. Consider h such that 
Show that h is right invariant and satisfies 
Deduce that, if Ve is a left Haar measure, 
is a right Haar measure. 
d. If 9 is compact, show that .1 is identically equal to 1. (Hint: Use the 
continuity of .1 and the fact that .1(9) is compact.) 
e. Consider 9 = GLn , the linear group of IRn. We denote by dx the 
Lebesgue measure on {,n,n, the vector space of n x n matrices. Show 
that 
1 
dx 
J(f) = 
9 f(x) Idet(x)ln 
is simultaneously right and left invariant. Deduce that .1 
compact? 
1. Is 9 

288 7. Invariance, Haar Measures, and Equivariant Estimators 
7.18* (Eaton, 1989) Consider 9 a compact group acting on X, and 1/ the unique 
Haar probability distribution on 9. Define U, a uniform random variable on 
9, by 
P(U E B) = I/(B). 
a. Consider x EX. Show that /-Lx, defined by 
/-Lx(B) = P(Ux E B) 
is the unique 9-invariant probability on the orbit of x, Ox. 
b. If P is a 9-invariant distribution on X, show that 
P = l/-LxP(dX). 
c. A measurable section Y c X is defined by 
(i) Y is measurable; 
(ii) Yx E X, Y n Ox = {y(x)}; and 
(iii) the function t(x) = y(x) is measurable for the a-algebra induced on 
YbyX. 
Show that, for every probability distribution Q on Y, 
P = l/-LyQ(dY) 
is 9-invariant on X and that, reciprocally, every 9-invariant probability 
can be written this way. 
d. Consider U a uniform random variable on 9, Y a measurable section 
of X, and X a random variable on X. Deduce from c. the equivalence 
between the following properties: 
(i) the distribution of gX is independent of g E 9; and 
(ii) there exists Y, random variable on Y, independent of U, such that 
UY has the same distribution as X. 
e. Apply to the case X = {O, l}n. 
7.19 Consider x '" N (8, 1) when the quantity of interest is h( 8) = eCo . 
a. Give the risk of the Bayes estimator of h(8) associated with 7r(8) = 1 
and the quadratic loss, R(8,811'), and show that the Bayes estimator of 
h(8) associated with 7r'(8) = R(8,811')-1 dominates 811'. 
b. Note that R( 8,811') -1 (eCo -8? is an invariant loss and derive the following 
result: For every invariant loss L(8, 8), if 811' is the estimator associated 
with L and the Haar measure 7r, and if w(8) = lEo[L(8,811'(x))], the 
estimator associated with Land 7r'(8) = 7r(8)/w(8) is the best equivariant 
estimator. 
Section 7.5 
7.20* (Berger, 1985a) Consider the particular case where the group 9 is finite, 
i.e. 
Let us assume that the loss L(8, a) is invariant, convex in a, and, in addition, 
that the action induced by the group 9 on 1) satisfies 

Exercises 289 
Establish the Hunt-Stein Theorem under the additional assumption that D 
is convex. (Hint: Show that, for every estimator 8, there exists an associated 
invariant estimator 8f which dominates 8.) 
7.21 In the setup of Example 7.9, derive the exact risk of the estimator 81 (Hint: 
Note that Zl/Z2 is distributed as a Cauchy random variable.) 
7.22 Examine the estimation of p in Example 7.9 for the invariance structure 
induced by the multiplicative group. 
7.23 Consider (Xl, ... , Xp) and (Yl, ... , Yp) with normal distributions Np(O, E) 
and Np(O, .,1E). The hypothesis Ho : .,1 ::; .,10 is to be tested versus HI : 
.,1 > .,1~. 
a. Show that the problem is invariant under QCp , the group of nonsingular 
linear transformations. 
b. Show that QCp is transitive on the sample space, modulo a set of mea-
sure O. Deduce that the equivariant estimators are constant, i.e., that 
invariant tests at level a are <Pa(X, y) = 1 - a. 
c. Consider <Pc(x,y) = :O:y2<c,,2 and show that it dominates <Pa under the 
1-
1 
"0 -I" loss for a = PLlo(Y? > cx~). 
d. Is QCp amenable? 
7.24 Consider Xl, ... ,Xn rv C(1-",(},2). 
a. Show that the Haar measure is 7rH (1-", (}') tX 1/ (}'. 
b. Consider the reparametrization Yi = l/xi. Show that Yi rv C(II,72) and 
derive II and 7 in terms of I-" and (}'. 
c. Show that 7rH (11,7) tX 1/7 is not the transform of 7rH (1-", (}') and conclude 
about the limitations of invariance in terms of reparametrization. 
Section 7.6 
7.25* (Villegas, 1990) Consider a family of probability distributions Pe on X, 
with () E e and T(x) taking values in an euclidean affine space E, such that 
the likelihood function is 
£(()JX) = Cl(X)C2(()) exp{ -JJT(x) - ()JJ2 /2}. 
This model is called euclidean Bayesian if 7r( ()) = 1. 
a. Deduce that the corresponding euclidean prior distribution in the case 
of a Poisson model peA) is 7r(A) = 1/ A. 
b. Show that the p-value p(x) = P>"o(X ~ x) when testing Ho: A::; Ao 
against HI: A > Ao is related to this prior distribution, but that this 
relation does not hold for the alternative test of Ho: A ~ Ao against 
HI: A < Ao. 
c. Show that the Haldane prior distribution 
1 
7r(p) = p(1 _ p) 
(7.7) 
also appears as a euclidean model when X rv B(n,p). Is (7.7) still the 
euclidean prior for the negative binomial distribution, Neg(n,p)? 

290 7. Invariance, Haar Measures, and Equivariant Estimators 
d. If 0 < x < n, show that, in the binomial case, the p-values Ppo(X ::; x) 
and Ppo (X :2: x) associated with the hypotheses Ho: p:2: Po and 
Ho: p::; po do not correspond to the euclidean distribution (7.7). 
e. In the normal case N(p" (T2), show that the euclidean prior distributions 
are the following ones: 
(i) 1I"(B) = 1 if B = p,; 
(ii) 1I"(B) = 1 if B = (T-2; and 
(iii) 1I"(B) = B2 if (BI, ( 2) = (p" (T-2). 
7.26 Examine the issue of compatibility between the invariance requirements and 
the Likelihood Principle. In particular, determine whether the maximum 
likelihood estimator is always an invariant estimator. 
7.27* For an arbitrary loss function L(B,6) and a given prior distribution 11", 
assume that the Bayes estimator 67r is such that 0 < R(B,6Pi) < 00 for 
every B. 
a. If we define L 7r ( B, 6) = L ( B, 6) I R( B, 67r), show that 67r has constant risk 
1. Does this imply that 67r is minimax? (Hint: Note that 67r is not nec-
essarily the Bayes estimator under L 7r .) 
b. Consider the special case when x'" N(B, 1) and 11" is N(Bo, 7 2 ). Compute 
R(B,67r ) and study the behavior of the Bayes estimator associated with 
11" and L 7r, compared with 67r (numerically, if necessary). 
c. In the event 61 is associated with 11" and L1 = L7r is different from 
67r , a sequence of estimators 6~ can be defined sequentially by L~ = 
LI R(B, 6~-1). What can be said about the limit of the sequence (6~)? 
d. Study the above sequence when x '" P(>..) , 11"(>") = 1, and L(>..,6) = 
(1->"16? 

8 
Hierarchical and Empirical 
Bayes Extensions 
8.1. Introduction 
In the previous chapters, we have noticed the ambivalent aspect of Bayesian 
analysis: It is sufficiently reducing to produce an effective decision, but 
this efficiency can also be misused. For instance, the subjective aspects of 
Bayesian analysis can always be modified so that it produces conclusions 
fixed in advance. Of course, the same misappropriation is possible in a 
frequentist framework through the choice of the loss or of the estimation 
criterion, while the classical approach does not distinguish between the sub-
jective and the objective inputs of the analysis. The main point is that, as 
mentioned in Chapter 3, the choice of a prior distribution should always be 
justifiable by the statistician, i.e., it must be based on sound (or "repeat-
able") arguments. So the fact that Bayesian tools may lead to dishonest 
inferences cannot be taken as a flaw of the Bayesian paradigm. 
A more fundamental criticism is that the prior information is rarely 
rich enough to define exactly a prior distribution. In such cases, it seems 
necessary to include this uncertainty in the Bayesian model, although the 
concept of prior distribution may seem insufficient to represent such a de-
gree of ignorance. In fact, the residual uncertainty prompted some exten-
sions of the Bayesian paradigm, like the upper and lower probabilities of 
Dempster (1968) or the imprecise probabilities of Walley (1991). The hierar-
chical Bayes analysis considers nonetheless that this is can be done within 
the Bayesian paradigm. This particular modeling of the prior information 
decomposes the prior distribution into several conditional levels of distri-
butions and thus allows for a distinction between structural and subjective 

292 8. Hierarchical and Empirical Bayes Extensions 
items of information. According to the Bayesian paradigm, uncertainty at 
any of these levels is incorporated into additional prior distributions. In 
the simplest cases, the hierarchical structure is reduced to two levels, the 
parameters of the first level being associated with a prior distribution de-
fined on the second level. The first level distribution is generally a conju-
gate prior, because of the computational tractability of these distributions 
but also because the upper level somehow compensates for modeling er-
rors at the lower levels. (Another motivation for a conjugate modeling is 
provided by Dalal and Hall (1983) and Diaconis and Ylvisaker (1985), see 
§3.3.) A general characteristic of the hierarchical modeling is to improve 
the robustness of the resulting Bayes estimators: While still incorporating 
prior information, they are also well performing from a frequentist point of 
view (minimaxity and admissibility), although these two requirements are 
usually difficult to reconcile. Additional motivations for hierarchical Bayes 
modeling stem from real life, since there are settings in medicine, biology, 
animal breeding, economy, etc., where the population of interest can be per-
ceived as a subpopulation of a meta-population or even as a subpopulation 
of a subpopulation of a global population. This is, for instance, the case 
with meta-analysis where several experiments about the same phenomenon 
undertaken at different places with different subjects and different protocols 
are pooled together (see, e.g., Mosteller and Chalmers, 1992, or Mengersen 
and Tweedie, 1993). 
The empirical Bayes analysis is based on the same perception of im-
precision about the prior information, but at a more pragmatic level. In 
fact, this approach considers that it is illusory to try to model this impre-
cision by several levels of conditional distributions when the first level is 
already partially or totally unknown. Rather paradoxically, the empirical 
Bayes analysis still relies on a conjugate prior modeling, where the hyperpa-
rameters are estimated from the observations and this "estimated prior" is 
then used as a regular prior in the subsequent inference. The substitution 
of hyperparameters by estimated hyperparameters which is at the basis 
of the empirical Bayes analysis definitely excludes this technique from the 
Bayesian paradigm, but allows the statistician to take advantage of diffuse 
prior information in a simplified way. Moreover, it is often the case that the 
resulting estimators have good frequentist properties, although there is too 
much arbitrariness in the determination of the estimated hyperparameters 
to make a general rule of this fact. A related interest in the empirical Bayes 
modeling is to provide Bayesian motivations for the Stein effect (see §2.4.5). 
The empirical Bayes analysis may also appear as a convenient alternative 
in settings where a hierarchical Bayes analysis is too involved, even though 
increasingly well-performing computation techniques progressively suppress 
the need for such approximations (see Chapter 9). 

8.2. Hierarchical Bayes Analysis 293 
8.2. Hierarchical Bayes Analysis 
For reasons due to the modeling of the observations or to the decomposition 
of the prior information, it may happen that the Bayesian statistical model 
is hierarchical, i.e., involves several levels of conditional prior distributions. 
Definition 8.1 A hierarchical Bayes model is a Bayesian statis-
tical model, (J(xIB), 7r(B)), where the prior distribution 7r(B) is 
decomposed in conditional distributions 
and a marginal distribution 7r n+1 (Bn) such that 
7r(B) = 1 
7rl(BIBl)7r2(BlIB2)" '7rn+1(Bn) dBl ··· dBn+l . 
(8.1) 
elX ... Xen 
The parameters Bi are called hyperparameters of level i. 
Before we justify this decomposition by its usefulness, note that hier-
archical structures can also occur in classical statistical models. 
Example 8.1 A classical occurrence of hierarchical models is the inclusion 
of random effects in a linear model. This extension can be written under 
the form 
ylB r-v Np(B, L\), 
BI,6 r-v Np(X,6, 172), 
with no reference to a Bayesian modeling. The mean of y, B, is decomposed 
in fixed effects, X,6, and in random effects, Z"" where", is normal with mean 
o (the covariance matrix 172 can then be singular). These models are often 
used in Biometry, in particular, in animal breeding, in order to distinguish 
between the influence of the fixed effect (e.g., sires, breed, year, etc.) and 
the influence of random factors (e.g., dams within sires). 
6. 
Another classical example of a non-Bayesian hierarchical model is the 
following one: 
Example 8.2 A fly lays N eggs according to a Poisson distribution P()..) 
and each egg survives with probability p. The distribution of the number 
of surviving eggs x is then hierarchical 
xlN r-v B(N,p), 
N r-v P()"), 
where both levels are structural. 
Such models also point out that the boundary between classical and 
Bayesian models is sometimes fuzzy and mainly depends on the interpreta-
tion of the parameters. For instance, in the random effect model, we operate 
according to a classical perspective if the inference is about the fixed effects 

294 8. Hierarchical and Empirical Bayes Extensions 
((3) and according to a Bayesian perspective when considering the global 
effect (B). 
A second important preliminary remark is that a hierarchical Bayes 
model is nothing but a special case of a Bayesian model. In fact, if 
we recover an usual Bayesian model 
X rv f(xIB), 
B rv 7f(B), 
for the prior 
7f(B) = r 
7fl(BIB1)" .7fn(Bn-lIBn)7fn+l(Bn)dBl,,·dBn' 
Je1xoo.xen 
This reduction shows that hierarchical modelings are indeed included in the 
Bayesian paradigm, therefore that this approach enjoys the general optimal-
ity properties of the Bayesian approach with some additional advantages 
related to the decomposition of the prior distribution (see §8.3). It also in-
dicates why it is seldom necessary to go further than two conditional levels 
in the hierarchical decomposition. In fact, if the hyperparameters B1, ... ,Bn 
are of no interest for the inference (about B), it is equivalent to consider the 
simpler hierarchical model 
xlB rv f(xIB), 
which eliminates intermediary steps and additional hyperparameters. None-
theless, a more elaborate decomposition may still be of interest for the 
construction and the practical computation of the Bayes estimators, as 
shown in Chapter 9. 
The hierarchical Bayes analysis is partially based on the work of Good 
(see Good, 1980, 1983, for references) and is exposed in Lindley and Smith 
(1972) for the particular case of the linear model, where the authors use the 
duality between the usual Bayesian analysis of a random effect model and 
the hierarchical Bayes analysis of a regular regression model. Despite the 
reduction (8.1), which shows that a hierarchical Bayes model is actually a 
particular case of a Bayesian model, the decomposition 
may be preferred for several reasons: 
(i) Some objective reasons based on the modeling of the observed phe-
nomenon as a special case of a meta-population may lead to the first 
two levels, the Bayesian approach being justified by a prior knowledge 

8.2. Hierarchical Bayes Analysis 295 
of the meta-population. This is the case of Examples 8.1 and 8.2. More 
generally, as mentionned in §8.1, hierarchical Bayes models naturally 
appear in meta-analysis where several studies have to be pooled to-
gether. 
(ii) In connection with the above justification, the experimenter may wish 
to separate the prior modeling into two parts, the first one correspond-
ing to the structural information about the model, the second level 
to the more subjective information. For instance, the information may 
consist of uncertain linear restrictions on the parameters of a regression 
model, while the distribution on the hyperparameters 7r2(8d accounts 
for the imprecision of these restrictions. 
(iii) On the contrary, in a noninformative setting, a hierarchical Bayes 
model suggests a compromise between the Jeffreys noninformative dis-
tributions, which are diffuse but sometimes difficult to use or to justify, 
and the conjugate distributions which have no subjective justification 
but are analytically tractable. When the hyperparameters have a prior 
hyperdistribution, the noninformative perspective is reinforced, while 
generally providing a defined posterior distribution on 8. A possibil-
ity is to iterate this argument by introducing a conjugate distribution 
on 81, 7r2 (81182), and a noninformative distribution on 82. However, 
the choice of a conjugate distribution on 81 does not guarantee closed-
form expressions for the Bayes estimators, and, more fundamentally, 
does not seem to improve the robustness of the model. Whatever the 
number of levels in the distribution, the averaging on the unknown 
hyperparameters can only reinforce the robustness of the prior distri-
bution when compared with a classical conjugate approach. See Berger 
(1985a) for the specific interest of a hierarchical modeling from the ro-
bustness point of view. 
(iv) Another beneficial aspect of the hierarchical Bayes analysis is that it 
also robustifies the usual Bayesian analysis from a frequentist point of 
view, since it reduces the arbitrariness of the hyperparameter choice 
(sometimes transferred to a higher level) and averages the conjugate 
Bayesian answers. We show in §8.3 that, in the normal case, many 
prior distributions on the hyperparameters lead to minimax generalized 
Bayes estimators. 
(v) A last justification of the hierarchical Bayes approach is that it can 
often simplify Bayesian calculations. In fact, the decomposition of a 
prior distribution 7r in its components 7r1, ... , 7rn (which can be, for in-
stance, conjugate distributions) may allow for an easier approximation 
of some posterior quantities by simulation. This decomposition princi-
ple, called the hidden mixture technique (Robert, 1990c), was proposed 
by Dickey (1968) for Student's t-distribution. Chapter 9 explains how 
Gibbs sampling techniques make use of the above decomposition. 
Example 8.3 (Berger, 1985a) Consider Xi '"" N(f3i' 10) (i = 1, ... ,7) which 

296 8. Hierarchical and Empirical Bayes Extensions 
are yearly and independent measures of the intellectual quotient (IQ) of a 
child, for seven consecutive years. Since IQ tests are supposed to account for 
an age effect, it is reasonable to consider that the (3i'S have the same mean 
0, the "true" value of the IQ. A corresponding first level prior distribution 
is then 
(i = 1, ... ,7) .. 
Moreover, if the child belongs to a well-studied population of children, it 
may be the case that, for this population, 
where e and T are known and this provides the second level of the analysis. 
Otherwise, a noninformative alternative is to take 7r2 (0) = 1. 
t::, 
Example 8.4 
Consider the usual regression model, y = X(3 + f, i.e., 
y rv Nn(X(3, 0'2 In), where (3 E lRP • For structural reasons, the coefficients 
of the regression are similar. For instance, the (3i'S can describe the in-
vestment rates of different European automobile companies, for which the 
rates are quite similar. We then assume that (3i rv N(e, a;), where e repre-
sents the common value. Such a model is called exchangeable. If additional 
information is available about the common value, we can take e = eo or 
~ rv N(~o, T2). Otherwise, the second level can be noninformative, i.e., 
7r2(e) = 1. 
t::, 
Example 8.1 (Cont.) In the setup of the random effects linear model, 
ylO rv Np(O, L\), 
01(3 rv Np(X(3, 172 ), 
Lindley and Smith (1972) and Smith (1973) assume that (3 also satisfies a 
linear relation and use the following prior: 
An alternative prior which robustifies the model is 
but this distribution simply involves an additional level in the hierarchical 
model compared with the original normal distribution, as shown by Dickey 
(1968). In fact, 
Z rv Q(a/2, a/2), 
in this case. This decomposition also illustrates (iii) in the above list of 
arguments since, if we consider (3lz rv Np(p" z173) (conjugate distribution) 
and 7r(z) = l/z (noninformative distribution) the marginal distribution 

8.2. Hierarchical Bayes Analysis 297 
is thus a proper distribution, contrary to the noninformative distribution 
7r((J) = 1. 
6 
A practical interest in hierarchical models is that they allow for condi-
tioning on all levels and this easy decomposition of the posterior distribution 
may compensate for the apparent complexity induced by these successive 
levels. For instance, if 
we have the following result: 
Lemma 8.1 The posterior distribution of ° 
is 
where 
( £JI£J 
) = f(xIO) 7r1(010d 
7rUUl,X 
m1(xI01)
' 
ml(xlOd = Ie f(xI0)7rl(0101) dO, 
( £J I ) = ml(xIOl)7r2(01) 
7rUlX 
m(x) 
, 
m(x) = ( ml(xIOd7r2(01) dOl. 
le l 
Moreover, this decomposition also works for the posterior mo-
ments, i.e., for every function h, 
where 
This result is a straightforward consequence of Bayes's Theorem, the 
last equality being easily established by the Fubini Theorem. It bears im-
portant consequences in terms of the computation of Bayes estimators since 
7r(Olx) can be simulated by generating, first, 01 from 7r(01Ix) and then ° 
from 
7r(0101, x), if these two conditional distributions are easier to work with (see 
Chapter 9). 
Obviously, Lemma 8.1 only holds when the various integrals are well 
defined. In fact, as the second-level distributions are generally improper, 
this is not always the case. The following lemma gives a sufficient condition 
for the posterior moments to exist when xlO rv Np(O, E) (see Berger and 
Robert (1990) for a proof): 

298 8. Hierarchical and Empirical Bayes Extensions 
Lemma 8.2 If the marginal distribution 
m(x) = Ie J(x/O)7r(O) dO 
is finite for every x E lRk, the mean and the variance of the pos-
terior distribution 7r(O/x) always exist. 
A drawback of hierarchical models is that they usually prevent an 
explicit derivation of the corresponding Bayes estimators, even when the 
successive levels are conjugate, and therefore that they call for numerical 
approximations. But, as mentionned above, the decomposition provided by 
Lemma 8.1 can be used in this respect. 
Example 8.S Consider x rv B( n, p) and p/m rv Be( m, m) with m E N*. 
Therefore, 
If the second level prior distribution is 7r2(m) = 1/(2m - 1), the prior 
distribution on p is then 
7r(p) = r 7rl(p/m)7r2(m) dm 
IN-
= ~ 
C:)~(l-p)ln. 
The posterior distribution 
cannot be obtained in a closed form since, while 7r(p/m, x) is the beta dis-
tribution Be(m + x, m + n - x), 7r(m/x) is 
(m + x - 1) ... m (m + n - x - 1) ... m 
(2m + n - 1) ... (2m) (2m -1) 
up to a normalization factor. It is thus necessary to use numerical approx-
imations to compute lE7r~/xl. 
6. 
Example 8.6 
Consider x rv Np(O,E) and O/t.t,~ rv Np(t.t,B(~)) where 
B(~) = ~C - E. The positive definite matrix C is fixed and ~ varies on the 
half-line [Amax(C-1 E), +00), where Amax(A) denotes the largest eigenvalue 
of A. This representation of the posterior covariance matrix simplifies the 
computations while providing "robust estimators." For instance, a second 
level modeling on (t.t,~) may involve a noninformative distribution. How-
ever, a usual assumption is that t.t = y (3 for (3 E lR k, with a given regressor 
y such that ytCY is full rank, with a noninformative distribution on (3. It 

8.2. Hierarchical Bayes Analysis 299 
can then be shown that m(x) < +00 if p > 2 + k (see Berger and Robert, 
1990). 
6 
In the rest of the section, as well as in §8.3, we only consider the case 
of the normal distribution, x rv Np ((), E), as in Lindley and Smith (1972), 
Smith (1973) and Berger (1985a), with a first-level conjugate distribution 
() rv Np(fJ, 177r)' This choice allows for an easier decomposition of the esti-
mators, as shown in the following result: 
Lemma 8.3 In the conjugate normal model, the hierarchical Bayes 
estimator is 
with 
8(xlfJ, 177r) = X - 17W(x - fJ), 
W = (17 + 177r)-l, 
7r2(fJ, 177rlx) ex (det W)l/2 exp{ -(x - fJ)tW(x - fJ)/2}7r2(fJ, 177r)' 
The proof is a direct consequence of Lemma 8.1 and of the fact that 
ml(xlfJ,177r) is a normal distribution Np(fJ, W- l ). 
Example 8.6 (Cont.) The choice of a flat prior distribution on (3 leads to 
a closed-form expression for 87r (x). In fact, there exists a function hk (see 
Exercise 8.9) such that 
with 
p = y(ytC-ly)-lytC-l, 
Ilxll: = xC-l(Ip - P)x. 
Note that Px is the orthogonal projection of x on the subspace H = {fJ = 
y (3, (3 E IRk} according to the metrization defined by C-l. The estimator 
87r is thus a weighted sum of x and of this projection. Therefore, 87r takes 
the prior information into account in a modulable way, depending on the 
distance Ilxll* of x to H. 
6 
Example 8.7 Consider the exchangeable hierarchical model: 
xl() rv Np((), ai Ip), 
()I~ rv Np(O, a;Jp) , 
~ rv N(~o, 7 2 ), 
where 1 = (1, ... , l)t E IRP. In this case, 

300 8. Hierarchical and Empirical Bayes Extensions 
7I"2(~' 0"; Ix) ex (O"i + 0";)-p/2 exp{ - ~I(:f ~;i2) }e-(~-~o)2 /27271"2(0";) 
71"2(0";) 
{p(x -
~)2 
82 
(~- ~O)2} 
ex (O"i + 0"; )p/2 exp - 2( O"i + 0";) - 2( O"r + 0";) -
272 
with 82 = L:i(Xi - x)2. Therefore, 7I"2(~10";, x) is the normal distribution 
N(/-L(x, 0";), V7r (O";)), where 
Then 
and 
1 [82 
p(x -
~O)2 ] 
7 exp - -
+ ----=."..:.-"""""""""'"'::.......:....----=-
( 21 ) 
2 O"r + 0"; 
p72 + O"r + 0"; 
(2 ) 
71"2 0"7r X ex 
(O"f + 0";)(p-l)/2(O"f + 0"; + P72)1/2 
71"2 0"7r . 
(8.2) 
Berger (1985a, pp. 184-185) provides a detailed proof of this result, as well 
as the corresponding expression for the posterior variance of (). Note the 
particular form of the hierarchical Bayes estimator 
The two hierarchical levels induce two different types of shrinkage in the 
Bayes estimator. First, the exchangeability assumption justifies the second 
term, (x-xl), which is shrinking the observation toward the common mean 
x; this would be the estimator to use in the case of an exact relation between 
the parameters of the model. Similarly, the third term originates from the 
assumption that the common mean varies around ~o. In the event that this 
information is unreliable, a noninformative distribution can be proposed for 
the second level, i.e., 71"2(0";) = 1 and 7 2 = +00. Then, for p ~ 4, 
(8.4) 
and 

8.2. Hierarchical Bayes Analysis 301 
the function hk being introduced in Example 8.4 (see also Exercise 8.9). It 
can be verified that (8.4) and (8.5) are derived from (8.2) and (8.3) when 7 2 
goes to +00 and that (8.5) only corresponds to a proper distribution when 
p ~ 4. The usefulness of the exchangeability assumption in dimension 3 
relies on an additional amount of information, i.e., a prior information on 
the location of the common mean ~. This constraint agrees with frequentist 
results on the minimaxity of (8.4), which only holds for p ~ 4 (Brown, 
1988). 
Note that, if 0'1 is also unknown, with (possibly noninformative) prior 
distribution 7ro, the quantities (8.3) and (8.4) are still valid if the expec-
tations are considered with respect to the posterior distribution 7r( O'I, 0';' Ix). 
Similarly, if ~ is distributed according to Student's t-distribution T(o:, ~o, 7 2 ) 
instead of a normal distribution, we showed in Example 8.1 that this distri-
bution can be decomposed as a mixture of a normal distribution N (~o, 7 2 / z) 
by a gamma distribution 9(0:/2,0:/2) on z. Therefore, 87r can be derived 
from the expressions (8.3) and (8.4) by integrating with respect to z. See 
Angers (1987,1992) for a more detailed treatment of a prior modeling by 
Student's t-distributions. 
6 
Example 8.4 (Cont.) In the setup of the usual regression model, an ex-
changeability assumption on the parameters (3i (1 ::; i ::; p) leads to esti-
mators similar to the ones derived above. When 
and 
7r(~) = 1, 
an analysis similar to Example 8.7 was conducted by Lindley and Smith 
(1972) and provided the estimator 
where /3 is the least squares estimator /3 = (Xt X)-l xty and Jp is the 
(p x p) matrix made of 1. The analogy with the above example is more 
striking when 87r is written in the form 
(since (Ip - p- 1Jp)!31 = 0), as the Bayes estimator is shrinking toward the 
common mean 13 (in a matricial sense). Note that it can also be written as 
This expression points out how the exchangeability assumption alleviates 
the numerical and statistical problems caused by near collinearities in the 
columns of X. Indeed, the matrix 

302 8. Hierarchical and Empirical Bayes Extensions 
plays the role of stabilizer in the estimator. If, in the second level prior, we 
consider instead ~ = 0, the Bayes estimator is then (see Exercise 8.16) 
tat 
( 
2 )-1 
= X X + a;/p 
X y. 
(8.6) 
These estimators are called ridge estimators and have been introduced by 
Hoerl and Kennard (1970) as an answer to multicollinearity problems in the 
matrix X t X, i.e., when two (or more) of the regressors are almost collinear. 
The matricial factor 
[Ip + k(Xt X)-lr 1 
stabilizes the least squares estimator when some eigenvalues of X t X are 
close to 0 (see also Lindley and Smith, 1972, and Goldstein and Smith, 
1974). These estimators have been generalized later by considering a ma-
tricial factor of the form 
which may correspond to the case when a; is unknown, with prior distri-
bution 1f2 (a;), since the Bayes estimator is then 
From a classical point of view, it appears that the imperatives of a reduction 
of multicollinearity and of minimaxity are contradictory since Casella (1980, 
1985b) has shown that necessary minimaxity conditions for the ridge esti-
mators cannot agree with a stabilizing influence of these estimators. Robert 
(1988) exhibits the same phenomenon for other classes of shrinkage estima-
tors and points out that the antagonism is due to the unidimensionality of 
the multicollinearity problem, which explains why a uniform improvement 
over /J is impossible. 
6 
This section is only a short introduction to hierarchical Bayes analysis 
and it focusses on particular aspects. Chapter 9 shows, in addition, that the 
decomposition of a distribution in a hierarchical structure by the method 
of hidden mixtures may lead to a simplification of Bayesian calculations. 
For a more thorough treatment ofthis topic, see Berger (1985a), in relation 
to the robustness aspects, and Deely and Lindley (1981), Dumouchel and 
Harris (1983), George (1986a), Angers (1987), and Angers and MacGibbon 
(1990). For applications to animal breeding, see, e.g., Fouley et al. (1992). 

8.3. Optimality of Hierarchical Bayes Estimators 303 
8.3. Optimality of Hierarchical Bayes Estimatorsl 
From a general point of view, since hierarchical Bayes estimators cannot 
be really distinguished from the usual Bayes estimators, these estimators 
are not more and not less admissible than the Bayes estimators derived in 
the previous chapters. For instance, the necessary and sufficient conditions 
obtained in Chapter 6 also apply in the case of hierarchical Bayes esti-
mators. Similarly, the invariance aspects of Chapter 7 ignore the possibly 
hierarchical structure of prior distribution. 
On the contrary, we will see in a particular case that it is possible to de-
rive a general minimaxity condition which takes advantage of the specificity 
of hierarchical Bayes estimators since this condition involves the second-
level prior distributions. Such results point out the robustifying aspect of 
the hierarchical Bayes approach, which relegates the more subjective as-
pects of prior modeling to higher levels and thus provides an intermediary 
position between a straightforward Bayesian analysis and frequentist im-
peratives. 
Consider again the normal model, x '" Np ((), E) where 17 is known. As 
in §8.1, the first level prior distribution on () is conjugate, () '" Np(f.L, 177r). 
The prior distribution 7r2 of the hyperparameters f.L, 177r can be decomposed 
as follows: 
In this case, 
with 
Moreover, the Bayes estimator 
can be written 
with 
87r (x) = X + 17V'logm(x) 
8(xlf.L) = x + 17V'logm(xlf.L), 
2( I ) _ m(xlf.L)7r~(f.L) 
7r2 f.L x -
m(x) 
. 
These conditional decompositions will be used below. 
(8.7) 
1 This section can be omitted in a first reading since it deals with the minimaxity 
of a particular class of hierarchical Bayes estimators in the normal case. Its main 
interest is to illustrate the increased robustness brought about by hierarchical 
modeling. 

304 8. Hierarchical and Empirical Bayes Extensions 
Consider Q, a (p x p) symmetric positive-definite matrix associated 
with the quadratic loss 
(8.8) 
An estimator 8 is minimax for the loss (8.8) if it satisfies 
R(O,8) = lEo[LQ(O, 8(x))] :::; tr(17Q), 
since tr(17Q) is the minimax risk of 8o(x) = x. The method of the unbiased 
estimator of the risk has been developed by Stein (1973,1981) to derive 
sufficient minimaxity conditions. (See Brown (1988) and Rukhin (1994) 
for detailed reviews of this method.) It consists of obtaining a differential 
operator V, independent of 0, such that 
R(O, 8) = lEo [V8(x)], 
for every parameter ° 
and every estimator 8. This technique indeed gives a 
sufficient minimaxity condition of the form V8(x) :::; tr(Q17) (see Exercise 
2.41). In the particular case of (8.7), the differential operator is provided 
by the following result (Berger and Robert, 1990): 
Lemma 8.4 If m( x) satisfies the three conditions 
(1) lEoIIV'logm(x)112 < +00; 
and(1:::;i:::;p) 
(3) 
lim 
IV'logm(x)lexp{-(1/2)(x-O)t17-l(X-O)} =0, 
Ixd-+oo 
the unbiased estimator of the risk of 87r is given by 
V87r(x) = tr(Q17) 
2 
-
-
+ m(x) tr(Hm(x)Q) - (V'logm(x))tQ(V'logm(x)), 
where 
O=17Q17, 
This unbiased estimator of the risk then induces a sufficient minimaxity 
condition, 
2 
-
-
m(x) tr(Hm(x)Q) - (V'logm(x))tQ(V'logm(x)) :::; O. 
We denote by div the divergence operator, i.e., 
divf(x) = t ~~. (x), 
i=l 
• 

8.3. Optimality of Hierarchical Bayes Estimators 305 
for a differentiable function f from IR n to IR n. 
Corollary 8.5 If m satisfies the conditions of Lemma 8.4 and if 
div (QV'Jm(x)) :::; 0, 
(8.9) 
87r is minimax. 
Proof. It is sufficient to consider the development of div(QV'Jm(x)) to 
obtain 
div(QV'Jm(x)) = ~div (Q ~) 
2 
m(x) 
( 
)
t 
1 
-
1 
V'm x 
-
= J11iTX) div(QV'm(x)) -
-4 
~ 
QV'm(x) 
2 m(x) 
m(x) m(x) 
J11iTX) [ 2 
-
-
] 
4 
m(x) tr(Hm(x)Q) - V'log m(x)tQV' log m(x) 
and get the additional term in D87r (x). 
•• 
In the particular case where E = Q = Ip , the condition of Corollary 
8.5 can be written more simply as a condition on the Laplacian of m(x)1/2 
since it is 
( J m( x) is then said to be superharmonic). The verification of this condition 
is generally quite complicated. A more explicit minimaxity condition can 
be derived from Corollary 8.5 by conditioning on /.t. 
Lemma 8.6 The estimator 87r is minimax if 
Proof. In fact, 
div(QV'm(x)) = J 
div (QV'm(xl/.t)) 1T~(/.t) d/.t 
and (8.10) implies (8.9). 
(8.10) 
•• 
Therefore, if Q = Ip and m(xl/.t) is superharmonic, the corresponding 
hierarchical Bayes estimator is minimax. This result may appear to be triv-
ial, in its proof and statement, but it is actually quite general. In fact, it 
provides a necessary and sufficient condition of minimaxity which does not 
depend on 1T~(/.t) and thus allows for every possible modeling on the hyper-
parameter /.t. From a subjective point of view, to have complete freedom 

306 8. Hierarchical and Empirical Bayes Extensions 
of choice on the prior distribution of fJ is more much important than the 
alternative choice on Err, since it is usually easier to get information on 
fJ than on Err. The following example shows moreover that the condition 
(8.10) is satisfied by a large class of distributions 7r§: 
Example 8.6 (Cont.) Consider again the case where Err = ~C - E and 
Q = E-1CE-1 (therefore Q = C). It follows from Lemma 8.2 that 
{= 
{ 
(x - fJ)tc-1(x - fJ)} 
m(xlfJ) ex Jo C p/2exp 
-
2~ 
7r~WfJ)~· 
Therefore, 
div (Q\7m(xl fJ)) ex 1= ( 
-~ + (x - fJ)t~~l(x - fJ)) 
x e-(x-lL)tc-1(x_IL)/2~Cp/27r~(~lfJ) d~ 
and (8.10) is equivalent to 
1j;(a) = 1= (2a - p~)c(P+4)/2e-a/~7r~(~lfJ) d~ ::; 0, 
If 7r~ is a.e. differentiable, an integration by parts gives 
Va:::: O. 
1j;(a) = -2e-a/~o~~P/27r~(~olfJ) -1+= CP/2e-a/~7r~(~lfJ) d~, 
~o 
where ~o = inf(supp(7r§)) and 7r~ is the derivative of 7r~. This expression 
implies: 
Proposition 8.7 If, for every fJ E IRP, 7r§WfJ) is nondecreasing, 
8rr is minimax for every prior distribution 7r~. 
Therefore, if 7r~WfJ) = 1 for ~o ::; ~ when Amax(C-1E) ::; ~o, the corre-
sponding Bayes estimator is minimax. 
!'::. 
The above example can be extended to the case where e '" Np(fJ, a;E) 
and where 7rHa;lfJ) is increasing (C = E and ~ = a; - 1). This class ob-
viously fails to include all hierarchical estimators or all minimax estima-
tors, but it is large enough to contain the minimax estimators proposed by 
Strawderman (1971) and Berger (1976,1980a), some of them being more-
over admissible (see also Kubokawa (1991) and Exercise 8.29). Note that 
Proposition 8.7 suggests the use of unnatural prior distributions: actually, 
it seems difficult to argue in favor of an increasing distribution on the 
variance, on a subjective or a noninformative basis. On the contrary, the 
prior distributions are, in general, decreasing for large a; 'so This is, for in-
stance, the case for the Jeffreys noninformative distribution, 7r(a;) = l/a;. 
Therefore, this result stresses indirectly the artificial aspect of the notion of 
minimaxity: To similarly weight a posteriori all the possible values of the 
parameter is equivalent to favor a priori the more unlikely values. 2 
2 
The denomination of least favorable distributions then gets even more justified. 

8.4. The Empirical Bayes Alternative 307 
The example below illustrates the advantage of the hierarchical Bayes 
modeling from a minimax viewpoint, even when the first-level distribution 
is more rudimentary. It also exhibits a minimaxity robustness property, in 
the sense that minimaxity does not depend as much on the normality of the 
prior distribution as on its spherical symmetry. This result thus appears as 
a Bayesian counterpart to the frequentist results of Cellier et ai. (1989). 
Example 8.8 Consider x "" Np((), Ip). The mean () is estimated under 
quadratic loss. Instead of assuming a conjugate first-level distribution, we 
propose the uniform distribution on the sphere of radius c, 
thus assuming only spherical symmetry for the overall prior distribution. 
The second-level prior distribution 7r2(C) is a gamma distribution, 9(0'., (3). 
The Bayes estimator is then (see Robert et ai. 1990) 
611'(x) _ 20'. _1_ lFl(O'. + 1; (p + 2)/2; IIxl1 2 /(2 + 4(3)) x 
-
p 1+2(3 
lFl (O'.;p/2;llxI1 2/(2+4(3)) 
, 
where lFl is the confluent hypergeometric function. When 0'.< 1 and (3 = 0, 
we get 
611'(x) _ 20'. IF1(O'.+1;(p+2)/2;llxI1 2/2) x 
-
p 
IFl(O'.;p/2; IlxI1 2/2) 
, 
which is a minimax and admissible estimator (see Alam, 1973). 
8.4. The Empirical Bayes Alternative 
The method we examine in the remainder of this chapter does not partake 
in the Bayesian paradigm, as it approximates the prior distribution by fre-
quentist methods when the prior information is too vague. We still consider 
it in this book because 
(i) it can be perceived as a dual method of the hierarchical Bayes analysis 
presented above; 
(ii) it is asymptotically equivalent to the Bayesian approach; 
(iii) it is usually classified as Bayesian by frequentists and practitioners; 
and 
(iv) it may be an acceptable approximation in problems where a genuine 
Bayes modeling is too complicated or too costly. 
We will see how the empirical Bayes analysis occupies an intermediate po-
sition between the classical and Bayesian methods, and also that the hier-
archical alternative is often preferable. Note that this section is only a short 
introduction to the empirical Bayes approach. See Morris (1983b), Berger 
(1985a), or Maritz and Lwin (1989) for more extensive developments. 

308 8. Hierarchical and Empirical Bayes Extensions 
Introduced by Robbins (1951, 1955, 1964, 1983), the empirical Bayes 
perspective can be stated as follows: Given (n+ 1) independent observations 
Xl,"" Xn+l with densities f(XiIBi), the problem is to draw an inference on 
Bn+l' under the additional assumption that the Bi'S have all been generated 
according to the same unknown prior distribution g. From a Bayesian point 
of view, the sampling distribution is known but the prior distribution is 
not. The marginal distribution, 
fg(x) = J 
f(xIB)g(B) dB, 
must then be used to recover the distribution 9 from the observations since 
Xl,.'" Xn can be considered as an Li.d. sample from fg' Deriving an ap-
proximation 9n in this manner, we can use it as a substitute for the true 
prior distribution in the posterior distribution 
(8.11) 
Obviously, this derivation is not Bayesian, although it relies on the Bayes 
formula (8.11), and can also correspond to a classical modeling. A Bayesian 
approach, arguing from the ignorance on g, would index this distribution 
by an hyperparameter >. and would thus represent ignorance by a second-
level prior distribution, 7l'2(>')' (Note that indexing by >. is not formally 
restrictive, as shown in Exercise 1.2.) Deely and Lindley (1981) oppose the 
two approaches in the case of a Poisson distribution. 
The initial approach of Robbins (1955) is essentially nonparametric 
and uses the observations Xl,"" Xn+l to estimate fg. (In the general case, 
the marginal density fg can be estimated by the kernel method, see e.g., 
Devroye and Gyorfi (1985).) 
Example 8.9 Consider Xi distributed according to P(Bi) (i = 1, ... , n). If 
Pk(Xl, ... , xn) is the number of observations equal to k, k E IN, Pk(Xl,.'" 
Xn) gives an estimation of the marginal distribution, 
If xn+l rv P(Bn+d and Bn+l is estimated under quadratic loss, the Bayes 
estimator is 
~+oo e-()Bxn+1+lg(B) dB 
8g (Xn+ 1) = lEg [B I Xn+ lJ = ,,-,o,,---+,oo~--------'-'---
fo 
e-()BXn+l g( B) dB 
_ fg(Xn+l + 1) ( 
+ 1) 
-
f ( 
) 
X n+l 
. 
9 X n+l 
Therefore, the empirical Bayes approximation of 8g is 
(8.12) 

8.4. The Empirical Bayes Alternative 309 
where fg is replaced by its approximation. 
Several problems can be pointed out about this method: 
(i) To use nonparametric estimation, for instance of the prior density, to 
initiate a parametric estimation procedure seems to be suboptimal as 
the errors made in the nonparametric estimation step are always more 
difficult to assess. For instance, in the above example, if the numerator 
of (8.12) is null, the estimator is null. 
(ii) Functional relations between the mean (or any other quantity of inter-
est) and the marginal distribution are quite rare. In cases where such a 
relation does not exist, the derivation of an estimator of 9 is generally 
too complicated to guarantee that the resulting estimators are good 
approximations of the true Bayes estimators. 
(iii) The approximation is actually justified for large sample sizes only, 
i.e., when the estimator of the marginal distribution, I;, provides an 
acceptable approximation of the marginal distribution. Otherwise, as 
shown by Example 8.9, I; varies too widely and needs to be smoothed 
to be of any use (see Maritz and Lwin, 1989). Moreover, the assump-
tion that many identical and independent problems are available about 
the same prior distribution is a strong assumption which can fail to be 
satisfied in practice. Therefore, a single sample, even very large, cannot 
lead to the estimator of fg as it corresponds to an unique observation 
of (). This criticism remains valid for the parametric approach (see, for 
instance, Proposition 8.9). 
For these reasons, we do not proceed any further in the study of the non-
parametric empirical Bayes analysis and consider only a restricted version 
called parametric empirical Bayes by Morris (1983b). 
The main appeal of the empirical Bayes techniques is to provide ap-
proximations in noninformative settings. We showed in the previous chap-
ters that the Bayesian approach provides efficient tools for the frequentist 
optimality concepts. The empirical Bayes analysis can then be perceived as 
a practical approximation of this tool. The prior distribution being unavail-
able, a simple choice is to take a conjugate prior associated with f(xIO), 
7l"(OI-X). While the hierarchical approach introduces an additional distribu-
tion on the hyperparameters -X, the empirical Bayes analysis proposes to 
estimate these hyperparameters from the marginal distribution 
m(xl-X) = Ie f(xIO)7l"(OI-X) d() 
by ~(x) and to use 7l"(()I~(x),x) as a pseudoposterior distribution. This 
method then appears as the parametric version of the original approach by 
Robbins. 
A main drawback of the empirical Bayes perspective is that it relies on 
frequentist methods to estimate the hyperparameters of m(xl-X). Therefore, 

310 8. Hierarchical and Empirical Bayes Extensions 
many alternatives are available and the estimator can be derived by the 
moment method, the maximum likelihood method, or yet another method. 
The corresponding arbitrariness of empirical Bayes analysis can then be 
perceived as the major flaw of this theory, since it prohibits a decision-
theoretic treatment of the empirical Bayes estimators and often appears as 
a posterior justification of existing estimators (see §8.5). The most common 
approach is to use maximum likelihood estimators, for practical and the-
oretical reasons, in particular, because of the proximity of the maximum 
likelihood estimation to the Bayesian paradigm. An additional justification 
of this choice is given below in the particular case of the estimation of the 
natural parameter of an exponential family under quadratic loss. 
Lemma 8.8 Consider 
IfB is distributed according to 7r(BI>'), >. E IRP, and ,x(x) is the so-
lution of the likelihood equations associated with m(xl>.), the em-
pirical Bayes estimator of B satisfies 
Proof. In fact, 
8EB(X) = (\7 log m(xl>')) IA=~(X) - \7 log h(x) 
= \7[logm(xl,X(x))]- \710gh(x). 
\710gm(xl'x(x)) = (\710gm(xl>')) IA=~(X) + \7x'x(x)\7Am(xl>')IA=~(X)' 
where \7Am(xl>') is the vector with components a~~iIA) (1 ::::: i ::::: p), and 
\7 x,x(x) is the (k xp) matrix with components a~~(x) (1 ::::: i ::::: p, 1 ::::: j ::::: k). 
J 
By definition of ,x(x), the second term is null. 
__ 
Therefore, a regular Bayesian derivation using the approximate poste-
rior distribution 7r(BI,X(x)) gives the same result as the naive empirical Bayes 
approach where>. is replaced by 'x(x). This justification is obviously quite 
limited since it only works for the posterior mean of the natural parameter 
in exponential families. 
Example 8.9 (Cont.) 
Consider the case when 7r(BI>') is an exponential 
distribution £xp(>'). Then 
m(xil>') = r+oo e-oB~; >'e-oAdB 
Jo 
x,. 
>. 
(1 )Xi 
>. 
(>. + l)xi+l = 
>. + 1 
>. + l' 
and Xi I>' ("V geo( AI >. + 1). The maximum likelihood estimator of >. is ,X( x) = 
IIi; and the empirical Bayes estimator of Bi is 

8.4. The Empirical Bayes Alternative 311 
EB 
Xn+l + 1 
X 
8 
(xn+1) = 
A 
= -_ -(Xn+l + 1), 
>'+1 
x+l 
the average x being taken on the n first observations. 
Example 8.10 Consider Xl,'" ,Xn, n independent observations from 13(m, 
Pi). Casella (1985a) (see also Morisson, 1979) applies this model to the in-
tentions of buying a new car in the coming year. The assumption is that the 
parameters Pi (1 :::; i :::; n) are distributed according to the same conjugate 
prior distribution 
The corresponding Bayes estimator of Pi is 
87f(x.) _ 
a + {J _a_ + (1 _ a + (J 
) Xi 
t 
t 
-
a+{J+la+{J 
a+{J+l 
m 
and the marginal distribution of Xi is called beta-binomial, 
P( . = kl 
(.I) = B(k + a, m - k + (J) 
X t 
a, fJ 
B( a, (J) 
. 
It is shown in Kendall and Stuart (1979) that, for this marginal distribution, 
1 
a{J 
a + (J + m 
var(xilm) = - ( 
{J)2 
{J 
. 
m a+ 
a+ +1 
When a and {J are estimated by the method of moments, the resulting 
empirical Bayes estimator of Pi is 
EB 
& + (xdm) 
'Yi 
(Xl, ... ,Xn)= 
A 
• 
&+{J+l 
(Exercise 8.16 provides the data of Morisson (1979).) 
Section 8.5 indicates how the Stein effect is strongly related to the 
empirical Bayes approach and how the latter can provide well-performing 
estimators for point estimations as well as for tests and confidence regions. 
The following result shows on the contrary why "empirical Bayes tests" are 
of limited interest for a single sample. 
Proposition 8.9 Consider the test of Ho: 8 = 80 against HI : 
8 = 81 based on a sample Xl,,,,,Xn, i.i.d. f(xI8). An empirical 
Bayes approach gives the likelihood ratio test procedure 
(X) = {I if TI~l f(xiI 80) > TI~=l f(XiI 8l), 
'P 
0 
otherwise, 
(8.13) 
for every confidence level. 
Proof. In this setup, the unknown parameters are reduced to 7ro, the prior 
probability of Ho. The marginal distribution of X is then 

312 8. Hierarchical and Empirical Bayes Extensions 
n 
n 
m(xl?To) = ?To IT f(x; 1(0) + (1 - ?To) IT f(x; 18d 
;=1 
i=l 
and gives the following maximum likelihood estimator of ?To: 
A 
( 
) 
{I if TI~=l f(xiI 80) > TI~l f(xiI8d, 
?To Xl,·· . , Xn = 
0 otherwise. 
The Bayesian answer being 
11'( 
) {I if P(8 = 8
0Ix1, ... , Xn, ?To) > a, 
i.p Xl,···, Xn = 
0 
h 
. 
ot erWISe, 
the posterior probability of Ho is 
( 
I 
A 
) 
71'0 TI~=l f(xiI 80) 
P 8=8o X1,···,Xn,?To = 
A 
TIn 
f( ·18 )+(1-
A )TIn f( ,18) 
?To 
i=l 
X, 
0 
?To 
i=l 
X, 
1 
and (8.13) follows. 
•• 
When several testing problems are considered simultaneously, this ex-
treme behavior of the empirical Bayes tests disappears (see Maritz and 
Lwin, 1989). However, it is rather rare to have to test simultaneously hy-
potheses on parameters from the same distribution, and the practical in-
terest of the empirical Bayes approach for tests is thus quite limited. We 
consider the estimation of the confidence regions in §8.5, in relation to the 
Stein effect. For an alternative review, see Laird and Louis (1987) or Carlin 
and Gelfand (1990). 
Note as a conclusion that a refinement of the empirical Bayes approach 
is to consider instead mixtures of conjugate distributions, since they also 
constitute a conjugate family (see Lemma 3.4). If Xi'" f(xiI8i) and 
n 
8i '" LPj?T(8iIAj), 
j=l 
the marginal distribution of Xi is 
Titterington et al. (1985) present an extensive overview of the different es-
timation techniques for finite mixtures and we consider in §9.1 and §9.4 the 
Bayesian analysis of this problem. Maritz and Lwin (1989) consider more 
particularly the application to the empirical Bayes analysis. A drawback 
of this extension is obviously that it calls for a larger number of hyperpa-
rameters, thus for a larger number of independent samples, while retaining 
some of the difficulties mentioned before. 

8.5. Empirical Bayes Motivations of the Stein Effect 313 
Let us stress again that the main legitimacy of the empirical Bayes 
methods is asymptotic (see Deely and Lindley, 1981). Their popularity is 
due to the good frequentist properties of some resulting estimators, and also 
to the simplification they brought to the treatment of complex problems, 
compared with a hierarchical Bayes analysis. See, for instance, Carter and 
Rolph (1974) or Hui and Berger (1983). For finite problems, the empirical 
Bayes methods are only approximations of the exact Bayesian methods and 
cannot claim the same coherency. In particular, it is not possible to draw a 
full Bayesian inference using n(Olx, >.(x)) , because it is not a posterior dis-
tribution. Moreover, with the increasing power of computational methods 
(see Chapter 9), the need for empirical approximations to more complex 
hierarchical analyses diminishes (see Berger, 1985a, Berger and Berliner, 
1986, and Berger and Robert, 1990). 
8.5. Empirical Bayes Motivations of the Stein Effect 
The empirical Bayes analysis of the Stein effect described in §2.4.6 uni-
fies the different occurrences of this paradox, where the simultaneous es-
timation of independent parameters can lead to a global improvement in 
estimation performances, although each component cannot be improved 
uniformly. Moreover, this analysis explains the form of the original James-
Stein estimators and points out that they correspond to the vague prior 
information that 0 is close to O. 
Example 8.11 Consider x "" Np(O,Ip) and Oi "" N(0,72 ). The marginal 
distribution of x is then 
and leads to the following maximum likelihood estimator of 7 2, 
f2 = {(llxI12/p) -1 if IlxW > p, 
o 
otherwise. 
The corresponding empirical Bayes estimator of Oi under quadratic loss is 
derived by replacing 7 2 by f2 in the Bayes estimator, 
(8.14) 
The estimator (8.14) is actually a truncated James-Stein estimator. There-
fore, these estimators can be interpreted as empirical Bayes estimators re-
lated to the vague information that the expectations of the observations 

314 8. Hierarchical and Empirical Bayes Extensions 
are close to 0. The original James-Stein estimator can also be expressed as 
an empirical Bayes estimator, using an alternative frequentist estimation 
method. In fact, given the marginal distribution of x, the best unbiased 
estimator of 1/(1 + T2) is (p - 2)/llxW, which leads to 
EB 
(P-2) 
8 
(x) = 1- ~ 
x. 
(8.15) 
This example also illustrates the ambivalent aspect of the empirical Bayes 
approach which fails to provide a comparison tool between the different 
methods for estimating the hyperparameters. This ambivalence is actually 
characteristic of the whole frequentist paradigm. The comparison between 
the estimators (8.14) and (8.15) must rely on "exterior" considerations. !'::. 
Example 8.12 Consider two independent vectors, x rv Np(B, (J"2 Ip) and 
y rv Nq(O, (J"2 Iq), as for a linear regression. The parameter of interest is the 
variance factor (J"2, evaluated under the entropic loss, 
Apart from intrinsic considerations (see §2.5.4), this loss is often preferred 
to the quadratic loss since it gives the maximum likelihood estimator 
Ilyl12/p + q as the best equivariant estimator3 of (J"2. Under this loss, the 
Bayes estimator of (J"2 is 
Consider the gamma-normal conjugate distribution on (B, (J"2), 
BI(J"2 rv Np(O, T(J"2 Ip), 
The estimator (8.16) is then 
(J"-2 rv Q(v/2, (3j2). 
(8.16) 
and maximization of the marginal likelihood (in (T, v, {3)) leads to the fol-
lowing empirical Bayes estimator (see Kubokawa et al., 1992): 
(8.17) 
Note the intuitive aspect of this estimator, which uses the additional infor-
mation about (J"2 contained in x only if IIxW is not "too" large, i.e., if B is 
close to 0, as 
3 This argument does not justify the use of the entropic loss, since it legitimizes 
a posteriori a given estimator, instead of being based on utility considerations 
and leading to the determination of an estimator. 

8.5. Empirical Bayes Motivations of the Stein Effect 315 
IlxW + IIyl12 
p+q 
is the best scale equivariant estimator of a2 when 0 = O. The main interest 
in this result is that (8.17) has been obtained in Brewster and Zidek (1974) 
as a uniform improvement on the best equivariant estimator Ilyl12/q under 
entropic loss. (See Maatta and Casella, 1990, for an exhaustive review of 
the different perspectives in variance estimation.) 
D,. 
Morris (1983b) considers the Stein effect in greater generality than in 
Example 8.11. In fact, he studies the Bayesian model 
xlO '" Np(O, A), 
Ol/J, a; '" Np(Z/J, a;Ip) , 
with A = diag(At, ... , Ap) and Z a (p x q) full rank matrix. The marginal 
distribution of x is then 
xil/J, a; '" N(z~/J, a; + Ai) 
and the posterior distribution of 0 is 
Oilxi, /J, a; '" N ((1 - bi)Xi + biZ~/J, Ai(l - bi)) , 
with bi = Ad (Ai + a;). If all the variances Ai are identical and equal to a2, 
the best equivariant estimators of /J and b are given by 
and 
A 
(p - q - 2)a2 
b = 
2 
' 
8 
with 82 = L:f=l (Xi -
z~S)2. We deduce from these estimators of the hyper-
parameters the corresponding empirical Bayes estimator of 0 
OEB(X) =zS+ (1- (p-q_~)a2) (x-ZS), 
Ilx - Z/J112 
(8.18) 
which is of the form of the general Stein estimators. In the particular case 
where the means are assumed to be identical (exchangeability), the matrix 
Z reduces to the vector I and /J is a real number; the empirical Bayes 
estimator is then 
EB 
_ 
( 
(p - 3)a2 ) 
_ 
o (x)=xl+ 1-llx-xII12 (x-xl). 
It thus provides the Stein estimator which shrinks toward the common 
mean, as in Efron and Morris (1975). See Morris (1983b) for an extension 
to the case where the variances Ai are not identical. 
As mentioned above, the estimation of the hyperparameters /J and 
a; considerably modifies the behavior of the resulting procedures. If the 
resulting point estimators are generally efficient, as shown in the above 

316 8. Hierarchical and Empirical Bayes Extensions 
examples, the estimation of the posterior variance of 1r(Blx, /3, b) by the em-
pirical variance, var(Bilx,~, b), induces an underestimation of this variance. 
Thus, using empirical Bayes analysis to assess the performances of OEB by 
estimating its quadratic loss (Bi - O~B)2 as var(Bi Ix,~, b) is misleading since 
it underates the error resulting from using OEB. Morris (1983b) takes into 
account the additional variability due to the estimation of the hyperparam-
eters through a modification of the estimators. In the exchangeable case, 
the resulting procedures are 
OEB(X) = X - B(x - :r1), 
ViEB(x) = (0'2 - p; 1 B) + p: 3b(xi - x)2, 
with 
and 
-
p - 3 
. ( 
0'2 (p - 1) ) 
B = -- mm 1, II 
-
112 
. 
p -1 
x - xl 
2 
This last quantity estimates the ratio ~+ 
. However, this modification, 
(Y 
(Y 7C 
although more satisfactory, suffers from the general drawback of empirical 
Bayes inference, namely, that the procedures are usually justified by ad hoc 
reasons which cannot be extended in a general principle (although Kass and 
Steffey, 1989, provide a partial generalization). Note the analogy between 
the modified empirical variance ViEB and the hierarchical variance for the 
same model, 
ViHB(X) = 0'2 (1 - P - 1 IE7r [ 20'2 2 Ix] ) + var [ 20'2 2 Ix] (Xi -
X)2 
P 
0' +0'7r 
0' +0'7r 
(see Berger, 1985a). This resemblance is not incidental, since this modifi-
cation brings an improvement in the naive empirical Bayes approach by 
taking advantage of the true Bayesian approach one step further. Ghosh 
et al. (1989), Blattberg and George (1991), and Robert and Saleh (1991) 
provide econometric illustrations of the empirical Bayes analysis and the 
connection with Stein estimators in regression models. 
Another aspect of the Stein effect can be interpreted in an empirical 
Bayes manner. In the case of recentered confidence regions (see §5.4), Hwang 
and Casella (1982) have shown that some of these regions allow for a larger 
coverage probability than the usual confidence set for an identical volume. 
These sets can also be expressed as empirical HPD regions. 
Example 8.13 In Hwang and Casella (1982), the usual confidence region 
Co(x) = {B; liB - xl1 2 ::; cal, 
with x rv Np(B, Ip), is compared with 

8.5. Empirical Bayes Motivations of the Stein Effect 317 
Ca(X) = {O; 110 - 8a (x)112 ::; co}, 
where 8a(x) = (1- (alllxI1 2))+x. Hwang and Casella (1982) show that, for 
a small enough and p 2: 4, the set Ca satisfies, for every 0, 
p()(O E Ca(x)) > p()(O E Co(x)) = 1 -
0:. 
Casella and Hwang (1983) also consider recentered regions with a variable 
volume 
C8(X) = {O; 110 - 8(x)112 ::; v(x)} 
and they determine 8 and v by an empirical Bayes analysis based on an 0:-
credible HPD region. The center of the region is the James-Stein estimator 
( 
p - 2)+ 
8(x) = 1 - IIxI12 
X 
and the radius is provided by 
v(X) = {(1-~) [Co - plog (1- Pc~2)] 
( 1 - IT;j12 ) [Co - p log (1 - 1i';j12)] 
otherwise. 
The shape of the variable radius is justified in terms of a linear loss 
L(O, C) = k vol(C) - ][0(0), 
already presented in §5.4 (see Exercise 8.22). This empirical Bayes confi-
dence region has then at least a confidence level of 1 - 0: (in the frequentist 
sense), except for the smallest values of p. 
l':,. 
Example 8.14 A usual rejection of recentered confidence regions is based 
on the fact that they are useless in practice since the reported confidence 
level is still 
inf P()(O E Ca(x)) = 1 -
0: = p()(O E Co(x)). 
() 
In this sense, the usual regions can be argued to be more accurate since 
they coincide exactly with the reported confidence level. The actual value 
of such confidence levels has already been discussed in §5.4 and the reader 
is referred to Chapter 5 for criticisms on the artificial aspect of the notion 
of confidence levels. An alternative answer is also mentioned at the end of 
Chapter 5: It is to propose a conditional confidence level, 'Y(x), which is 
more adapted to the recentered region Ca(x) and to evaluate it under the 
quadratic loss 
(8.19) 
For the model presented in Example 8.12, George and Casella (1994) pro-
pose an empirical Bayes solution to this evaluation problem for a recentered 
region of the form 

318 8. Hierarchical and Empirical Bayes Extensions 
and a confidence report 
'YEB(X) = P(X; ~ c/(l - b)). 
In fact, if () rv Np(O, 7 2Ip), the Bayesian answer would be 
'Y71"(x) = p71"((} E CB(x)lx) 
= P71"(II(} _ (1 - b)xll2 ~ clx) 
= P(X; ~ c/(l - b)), 
since (}Ix rv Np((l - b)x, (1 - b)) with 1 - b = 7 2/(a2 + 7 2). The empirical 
Bayes estimators derived by George and Casella (1994) in 'YEB are 
A 
( 
a ) 
2 
1 - b(x) = max d,l - IIxl12 = ua,d(IIxil ), 
while CEB is centered in the truncated Stein estimator associated with a 
and d ~ 1. Actually, George and Casella (1994) show that the empirical 
Bayes estimator obtained this way, 
EB) 
[ 2 
C 
] 
'Y 
(x = P Xp ~ max{d, (IIxll2 _ a)/IIxll2} , 
dominates the constant report 1 - a under the quadratic loss (8.19), for 
d ~ 1 and a small enough. A suggested value of d is 
2c 
d = --::--t===7==:==;:: 
c + 2a + vi c( c + 4a) 
See Lu and Berger (1989b) for a different solution. 
To conclude this overview of empirical Bayes methods, let us point 
out once more their ambivalence: they draw strength simultaneously from 
frequentist and Bayesian methods to derive inferential procedures. It can 
be justifiably argued that the improvements these estimators bring on clas-
sical frequentist estimators is actually due to the imitation of the Bayesian 
approach while their sub optimality (in terms of admissibility for instance) 
can be attributed to the refusal to adopt a fully Bayesian perspective and to 
the subsequent arbitrariness in the choice of the resulting method. Funda-
mentally, it is quite logical that a method which relies on classical but sub-
optimal estimators (like the maximum likelihood estimator of the mean in 
the multidimensional normal case) and ad hoc concepts lacking a decision-
theoretic basis (like unbiased estimation or moment methods) cannot pro-
vide optimal procedures. The domination of these estimators by genuine 
Bayes estimators (see Brown, 1988) is another argument in favor of a com-
plete adoption of the Bayesian paradigm, even if it requires a hierarchical 

Exercises 319 
modeling. As shown in the next chapter, the development of new numerical 
tools to deal with far more complex models than before comes as a last 
blow to these methods which were previously alleviating the difficulties of 
fully Bayesian analyses. 
Exercises 
Section 8.2 
8.1 Consider J", Mk(N;Pl, ... ,Pk), a multinomial random variable. Assume 
that N is generated according to a Poisson distribution with parameter A. 
Determine the marginal distribution of J. Give, in particular, the covari-
ance matrix. Extend to the case where P = (PI, ... ,Pk) '" 1)(0;1, ... , o;k), a 
Dirichlet distribution. 
8.2 Compute the marginal distribution of x and the posterior distribution of N 
for Example 8.2. 
8.3 If ylO '" Np(O, L\), 01,6 '" N p(X,6, 172 ), and ,6 '" Nq(J-L, 173), compute the 
prior and posterior distributions of O. 
8.4 Establish Lemmas 8.1 and 8.2. 
8.5 (Berger and Robert, 1990) Consider x '" Np(O, E), 0", N p(y,6, O";Ip) , and 
,6 '" Nf (,60 , A), with rank(A) = m. 
a. Show that if, for K > 0, the two integrals 
are finite, then m(x) < +00 for every x E IRP. 
b. Show that condition a. is satisfied if, for E > 0, Kl > 0, K2 > 0, 
thus if 7l"2(0";) = 1 and P -l + m > 2. 
8.6 (Berger and Robert, 1990) In the setup of Example 8.6, assume that J-L E 
H = {J-L = Y,6; ,6 E lRf} and 7l"2(,6, 0";) = 1. Show that m(x) < +00 if 
p> 2 +C. 
8.7 (Berger, 1985a) In the setup of Example 8.7, compute the posterior vari-
ance. Consider also the noninformative case. 
8.8 (Lindley and Smith, 1972) Extend Example 8.7 to the general model 
and check the results of Example 8.4. 
8.9 (Berger, 1985a) Show that, for the model of Example 8.7 and a noninfor-
mative distribution on ~ and 0";, the hierarchical Bayes estimator is 
with 

320 8. Hierarchical and Empirical Bayes Extensions 
P 
hp(t) = 2t (1 - Hp(t)), 
(p/2)! { et -
L:;:~2)/2 ti /i!} 
t p /2 
r( /2) { t[2ifJ(y"2t) - 1] _ ",(p-3)/2 t(i+3)/2 } 
p 
e 
L....i=l 
r(i+3/2) 
if p is even, 
if p is odd. 
8.10 Consider the setting of a logistic regression, i.e., of observations (Xl, YI), ... , 
(Xn,Yn) such that Xi E JRk and Yi E {O, 1} with 
P(Yi = 1lxi) = exp(x;,6)/(l + exp(x;,8)) 
and derive a sufficient condition on 7r( 7) for the posterior distribution of ,8 
to be defined when ,817'" Nq(O, 7 2Ip). (The xi's are considered to be fixed.) 
8.11 Reproduce Exercise 8.10 in the setup of a probit model, i.e., when 
P(Yi = llxi) = ifJ(x;,8) 
and ifJ is the c.d.f. of the standard normal distribution. 
8.12 In the setup of Example 8.2, when p is known, give the posterior distribution 
of N if 7r2(A) = I/A. Examine the generalization to the case when p is 
unknown and 7r1 (p) = l. 
8.13 Compare the models 
and 
in terms of estimators of (). 
8.14 In the setup of Example 8.5, compute the posterior mean of p when X = 
3, n= 5. 
8.15 Consider Xi '" N(p,i' (J"2) and P,ilp" 7 '" N(p" 7 2 ) (i = 1, ... , n). 
a. Show that 7r(p" 7) = 1/7 leads to an undefined posterior distribution. 
b. Show that 7r(/.t,7) = 1 escapes the above problem. 
8.16 In the setup of Example 8.4, show that the Bayes estimator 
can be written in the form 
(Hint: Use a simultaneous diagonalization of I p and X t X.) Explain how 
this estimator can help to reduce multicollinearity. 

Exercises 321 
Section 8.3 
8.17 (Stein,1981) Establish Lemma 8.4 by some integrations by parts and relate 
this result to Exercise 2.41. 
8.18 If H is the Hessian matrix defined in Lemma 8.4, show that the equivalent 
of (8.8) for the covariance matrix is 
EB 
H(x) 
t 
V 
(x) = 17 + 17 m(x/~' - 17(\7logm(x))(\7logm(x)) 17. 
Using a technique as in Exercise 8.17, show that an unbiased estimator of 
the average matricial error 
can be written in the differential form 
VOHB(X) = 17 + 217~~~~ 17 - 17(\7logm(x))(\7logm(x))t 17. 
Derive from this expression the unbiased estimator of the quadratic risk. 
8.19 Use the following approximation of IFI(a; b; z): 
F ( . b' ) '" r(b) z/2( /2)a-b (1 (1 -a)(b - a)) 
1 
1 a, ,Z -
r(a) e 
Z 
+ 
(z/2) 
to provide an approximation of the estimator 81r given in Example 8.8 and 
compare with the James-Stein estimator. 
8.20 Consider x rv N p((}, Ip), () '" Np(O, 7 2Ip), and, if", = 1/(1 + 72), assume 
7r2("') = ",2-(P/2). Show that the corresponding hierarchical Bayes estimator 
can be written explicitly as 
HB (1 
2 ) 
8 
(x) = 1- e-II"'112/2 - IIyl12 
x 
and determine whether it is minimax and admissible. 
8.21 * (Hartigan, 1983) Consider an observation x '" Np((}, Ip). 
a. If f is a positive nondecreasing function which is bounded above by 
2(p - 2), show that 
dominates 80 (x) = x for the usual quadratic loss. (Hint: Use the unbiased 
estimator of the risk obtained in Exercise 2.41.) 
b. Let 7r be a prior on () such that, conditionally on 72, () '" Np(O, 72) and 
72 '" 7rI. The hyperprior 7rI is assumed to be a log-concave function of 
10g(72 + 1) and (72 + 1)I-"7rI(72) is increasing in 72 • Using the general 
result of a., show that the hierarchical Bayes estimator associated with 
7r dominates 80 if 4 - 2Q :::; p. (Hint: Show that 81r(x) = (1 -1E[(72 + 
l)-Ilx])x and that 1E[(72 + 1)-1 Ix]) is increasing in IIxl12 while being 
obviously bounded by 2(p - 2).) 

322 8. Hierarchical and Empirical Bayes Extensions 
c. Show that such priors can only be proper for a < 0 and therefore that 
these minimax Bayes estimators are guaranteed to be admissible only 
for P 2: 5. 
d. Show that the Bayes risk is actually finite for a < 2 and deduce that the 
resulting hierarchical Bayes estimators are admissible for every p. (Note: 
Strawderman (1971) considered the particular case 11"1(72 ) = (1+72)"'-1 
to show that the limiting dimension for the existence of proper Bayes 
minimax estimators is exactly P = 5.) 
Section 8.4 
8.22 (Casella, 1985a) In a survey about car buying intentions, 447 households 
provide their evaluation of the probability they will buy a new car in the 
coming year. The result of the survey is given in Table 8.1. 
TABLE8.1. Car buying intentions of households. 
Intentions 
0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0 
Answers 
293 26 
21 
21 
10 
9 
12 
13 
11 
10 21 
The answers Xi (1 ::; i ::; 447) are modeled as issued from a renormal-
ized binomial B(lO,Pi) distribution, i.e., lOXi rv B(lO,Pi) and the Pi are 
distributed according to Be(a,j3). 
a. Use the marginal distribution to provide estimators of a and j3 by the 
method of moments. 
b. Derive an empirical Bayes estimator of the Pi'S under quadratic loss. 
The true intentions Pi have actually been observed at the end of the year 
and Table 8.2 gives the difference with the declared intentions. 
TABLE 8.2. Proportions of car acquisitions depending on the intention. 
Intentions 
0 
0.1---0.3 
0.4---0.6 
0.7---0.9 
1 
Declared 
0 
0.19 
0.51 
0.79 
1 
Realized 
0.07 
0.19 
0.41 
0.48 
0.583 
c. Compare the quadratic losses of the classical estimator (i.e., Pi = Xi), 
the empirical Bayes estimator, and a Bayes estimator of your choice. 
8.23 Establish the equivalent of Proposition 8.9 if the test is about Ho: B = Bo 
versus HI : B = B1 for two independent problems with samples Xl, ..• ,Xn rv 
f(xIB), Y1, ••• , Ym rv f(yIB'), and P(B = Bo) = P(B' = Bo) = 11"0. Generalize 
to P samples and apply in the case of the test of Bi = 0 versus Bi = 1 for 
Xi rv N(Bi, 1) (1 ::; i ::; p). 
8.24" (Hartigan, 1983) Consider X rv N p((}, a 2Ip) and () ("V Np(O, 7 2Ip), with a 2 
unknown and 8 2 ("V a2x~. 
a. Give an empirical Bayes estimator of B based on the maximum likelihood 
estimators of 72 and a 2 and determine whether the resulting estimator 
is minimax. (Hint: Use Exercise 8.21.) 

Exercises 323 
b. Compare with the empirical Bayes estimators based on the moment 
estimators of a 2 and 7 2 . 
c. If 7r(a2 , 7 2 ) ex (a2 + a5),,-1 (a2 ),B-l, show that the posterior distribution 
of (a- 2 , (a 2 + 72)-1) is 
XL2,B/S x X;_2a/llxI12Iu2$u2+T2. 
Show that the resulting estimator is minimax if 
P - a 
2(p - 2) 
~~~~ < 
. 
k-f3-2 -
k+1 
(Hint: Use Theorem 2.17.) 
8.25 (Hartigan, 1983) Consider a multinomial model Mk(njPl, ... ,Pk) and the 
observation (nl, ... , nk). A possible conjugate prior is the Dirichlet distri-
bution, V(al, ... , ak). 
a. Show that 
k [2: 2 
a+1 
JE 
nil = n + (n -l)-k--' 
a+1 
i=l 
and determine when the moment equation derived from this equality has 
a positive solution. Derive an empirical Bayes estimator of (PI, ... ,Pk) 
in this case. 
b. Compute an alternative empirical Bayes estimator by using maximum 
likelihood estimators of the ai's. (Note: See Good, 1975, for details on 
this model.) 
8.26 (Morris, 1983a) An exponential family with density 
f(xI9) = h(x)eox-'l/J(O) 
is said to be with quadratic variance if the variance can be written 
V(p.) = 'ljJ"(9) = Va + VIP. + V2Jl?, 
where p. = 'ljJ'(9) is the expectation of f(xI9). Morris (1982) has charac-
terized the six families with quadratic variance (see Exercise 3.7). These 
distributions are denoted N EF(p" V(p,)). 
a. Show that the conjugate distribution in p, can be written 
(8.20) 
and that 
JE"[p,] = p,o, 
V"( ) -
2 _ 
V(p,o) 
P, -70 - ---, 
m-V2 
Therefore, the conjugate distribution is also an exponential family with 
quadratic variance. Derive a table of the correspondence between sample 
and conjugate prior distributions for the six families obtained in Exercise 
3.2l. 
b. Show that the Bayes estimator associated with (8.20) for n independent 
observations Xl, ... ,Xn and quadratic loss is 

324 8. Hierarchical and Empirical Bayes Extensions 
where 
B = 
V(/1o) + V2 7g 
V(/10) + (n + V2)7g· 
c. Show that, for the conjugate distribution (8.20), the marginal moments 
of x are 
lE[x] = /10, 
var(x) = V(/1o) m + n . 
n 
m-V2 
d. Consider k independent observations 
(1 SiS k), 
with independent parameters /1i from the conjugate distribution (8.20). 
If x = I:i xi/k and s = I:i(Xi - X)2 and if 
lE[V(x)(k - 1)] = lE [V(X)(k - 3)] 
lE[s] 
s 
(the expectations being taken under the marginal distribution), show 
that an empirical Bayes estimator for /1i is 
with 
B = min (~ 
k - 1 
+ _n_ (k - 3)V(x) ,1) . 
n + V2 
k 
n + V2 
ns 
Section 8.5 
8.27 Show that, for the marginal distribution of Example 8.11, (p - 2)/llxlf is 
indeed an unbiased estimator of 1/(1 + 7 2 ). 
8.28 Derive formula (8.17) of Example 8.12. 
8.29* (Kubokawa, 1991) Consider oJs(x) = [1 - (p - 2)/llxI1 2]x, the original 
James-Stein estimator and x '" Np(e, Ip). Define>. = IleW /2; fp(t; >.) is the 
noncentral chi-squared density with noncentrality parameter >.. 
a. For the truncation of oJS 
01(x;c,r) = { (1- 1I~12) x 
if IlxW < r, 
oJs(x) 
otherwise, 
show that the quadratic risk of 01 (.; c, r) is minimized for 
c1(r >.) -
- 2 _ 
2fp(r; >.) 
, 
- P 
I; (l/t)fp(t; >.) dt· 
b. Let us define 
2 
C1 ( r) = p - 2 -
. 
101 tp/2 - 2e(1-t)r/2dt 
Show that 01 (x; C1 (r), r) dominates oJS for every r. 
c. Using a limiting argument, show that 

Exercises 325 
dominates 8Js . (Nate: This estimator is proposed in Strawderman, 1971, 
and Berger, 1976. See Exercise 8.21.) 
d. Show that 8i is admissible. (Hint: The sufficient condition of Theorem 
6.5 can be used.) 
8.30* (Bock and Robert, 1991) Consider x '" Np(B, Jp) and B '" U{IIOI12=c}, the 
uniform distribution on the sphere with radius c. Propose an empirical Bayes 
estimator of B based on IlxW and show that, if this estimator is derived from 
the maximum likelihood estimator of c, then 8EB (x) = h(x)x with 
Comment on the robustness of the Stein effect in terms of spherical sym-
metry. 
8.31 * (Casella and Hwang, 1983) Consider x '" Np(B, Jp). Under the linear loss, 
L(B,C) = k vol(C) - ][c(B), 
recall that the Bayes estimators are HPD regions of the form {B; 71'( Blx) ::::: k} 
when 71'({B;71'(Blx) = k}) = O. Moreover, if 
k = ko = e~c2/2 /(271'y/2, 
Joshi (1969) has established that the usual region 
C~ = {B; liB - xii ~ c}, 
is minimax. 
a. Show that, if B '" Np(O, 72 Jp), the Bayes set is 
C; = {B; liB - 8"(x)112 ~ - 7;~ 1 log [k (:271';21) P/2] }, 
where 8"(x) = (72/72 + l)x is the Bayes estimator of B. For k = ko, 
show that this set can be written 
C; = {B; liB - 8"(x)112 ~ 727: 1 
[c2 - plog (727: I)]}' 
b. Deduce that a naive empirical Bayes set is 
C~B = {B; liB - 8EB (X)112 ~ VEB(X)} , 
with 8EB (x) = (1- [(p - 2)/llxI12])x and 
EB 
(p - 2) ( 2 
1 p - 21) 
v 
(x) = 
1 - "fIXTI2 
c - plog 1 -"f1XT12 
. 
c. Explain why it is preferable to consider 

326 8. Hierarchical and Empirical Bayes Extensions 
+ 
p-2 
( 
)
+ 
8 (x) = 1- IIxl12 
X 
and 
if IlxW < c, 
otherwise. 
d. Extend to the case where x '" Np (8, (J'2 Jp ) and 8 2 '" (J'2X~. 
8.32* (George, 1986a) Consider Y '" Np(8, Ip). This exercise derives an estimator 
which selects among several partitions of Y into subvectors before shrinking 
the observation toward each of these subvectors. For k = 1, ... , K, let us 
denote 
and 
as the partitions of Y and 8 in subvectors Ykj and 8kj of dimension Pkj (1 ::; 
j::; Jk), where Ck is a permutation matrix made of O's and 1's with a single 
1 per row and per column. For k = 1, ... , K, consider 8k = (8k1, ... , 8kJk)Ck 
an estimator with components 
where the functions mkj from IRPkj in IR are twice differentiable. We also 
denote 
Jk 
K 
mk(Y) = II mkj(Ykj) 
and 
m*(y) = LWkmk(Y), 
j=l 
k=l 
for Wk ~ 0 (1 ::; k ::; K) and Lk Wk = 1. 
a. If 7fkj is a prior distribution on 8kj and mkj is the corresponding marginal 
distribution on Ykj (1 ::; k ::; K, 1 ::; j ::; Jk), show that mk is the 
marginal distribution of Y for the prior distribution 
Jk 
7fk (8) = II 7fkj (8kj) 
j=l 
and that 8k is the posterior mean for this posterior distribution. 
b. Deduce that 
8*(y) = Y + V'logm*(y) 
is the Bayes estimator for the prior distribution 
K 
7f*(8) = LWk7fk(8). 
k=l 
c. Show that 8* can also be written under the form 
K 
8*(y) = LPk(y)8k(Y), 
k=l 

Exercises 327 
with Pk(Y) = Wkmk(y)/m*(y), and interpret this result. 
d. Show that if, for k = 1, ... , K, 
IB2m k (Y)/ 
I 
IE9 
By? 
mk(Y) < +00, 
IE91IVlogmk(y)112 < +00, 
the unbiased estimator of the risk of {)* can be written 
with 
1){)k(Y) = IIVlogmk(y)112 - 2L1mk (y)/mk (y). 
(Hint: Use Lemma 8.4 with Q = E = Ip.) 
e. Deduce that, if mkj is superharmonic, Le., such that L1mkj (Ykj) ~ 0 
for 1 ~ k ~ K, 1 ~ j ~ Jk, {)* is minimax. (Note: This result can be 
described as the fact that a "proper" convex combination of minimax 
estimators is still minimax.) 
f. For 1 ~ k ~ K, 1 ~ j 
~ Jk, we denote by Vkj a subspace of IRPkj, 
with dim Vkj = Pkj - qkj and qkj :2: 3; Pkj is the associated orthogonal 
projector from IRPjk on Vkj and Skj = IIYkj - PkjYkj 112. Give the multiple 
shrinkage estimator {)* associated with 
mkj(Ykj) = { ( q~s: 2) (qkj-2)/2 
if Skj :2: qkj - 2, 
exp( -Skj /2) 
otherwise. 
(Hint: The solution is the truncated James-Stein estimator.) 
8.33* (Kubokawa et al., 1993) Consider x '" Np(B, (J'2 Ip), Y '" Nq(e, (J'2 Iq), and 
S '" (J'2X~, with unknown B, e, and (J'. An empirical Bayes estimator of B is 
the James-Stein estimator 
JS 
( 
(p - 2)s 
) 
{) 
(x, s) = 1- (n + 2)llx11 2 
x. 
The purpose of this exercise is to show that the substitution of s by a more 
efficient estimator of (J'2 can lead to an improvement in the estimation of B. 
a. Show that, if-yh(Y, s) = sh(IIYI12/S) dominates 'Yo(s) = s/(n + 2) under 
the invariant quadratic loss 
{)JS is dominated by 
. 
((P - 2)-y(y, S)) 
{)(x,y,s) = 1-
IlxW 
x 
under quadratic loss. (Hint: Recall that 'Yo is the best equivariant esti-
mator of (J'2 . ) 

328 8. Hierarchical and Empirical Bayes Extensions 
b. Consider 
( 
(p - 2)s 
2 
2) 
Og(X,y, s) = 
1-
IIxI1 2 g(llyll /s,llxll /s) x. 
Define 
*( 
) 
. (( 
) 1 + u + v) 
9 u, v = mIn 9 u, v , 
, 
p+q+n 
and assume 9 and g* are absolutely continuous functions of v. Show 
that, if 
1E [ag* (U, V) _ ag(U, V)] > 0 
av 
av 
-, 
when U = IlyW/s and V = IlxI12/s, Og* dominates Og. 
c. Deduce that 
O( 
)_ 
p-2 
. { 
s 
s+llyW S+llxW+IIYW} 
2 x,y,s -x-W mm n+2'n+q+2' n+p+q+2 
x 
dominates oJS. 

9 
Bayesian Calculations 
9.1. Implementation Difficulties 
Before concluding this book, we need to discuss a practical aspect of the 
Bayesian paradigm, namely, the computation of Bayes estimators. The ulti-
mate simplicity of the Bayesian approach is that, given a loss function Land 
a prior distribution 7r, the Bayes estimate associated with an observation x 
is the (usually unique) decision d minimizing the posterior loss 
L(7r, dlx) = Ie L(O, d)7r(Olx) dO. 
(9.1) 
However, minimizing (9.1) can be hindered by two difficulties in practice: 
(i) the explicit computation of the posterior distribution, 7r(Olx), may be 
impossible; and 
(ii) even if 7r(Olx) is known, this does not necessarily imply that minimizing 
(9.1) is an easy task; indeed, when analytic integration is impossible, 
numerical minimization sometimes calls for a formidable amount of 
computing time, especially when e and V have large dimensions. 
Point (i) may seem to be a minor and formal difficulty since minimizing 
(9.1) is actually equivalent to minimizing 
Ie L(O, 8)7r(0)f(xI0) dO, 
which does not require an evaluation of 7r(Olx). However, we have seen in 
previous chapters that classical losses, like the quadratic losses, lead directly 

330 9. Bayesian Calculations 
to estimators expressed through the posterior distribution, like the posterior 
mean 
87r(x) = Ie B1r(Blx) dB 
Ie B 1r(B)f(xIB) dB 
Ie 1r(B)f(xIB) dB ' 
for the quadratic loss; they thus necessitate direct computation of posterior 
moments or of other posterior quantities. A similar comment applies for 
the derivation of other posterior quantities of interest such as posterior 
quantiles, Bayes factors, or confidence regions. 
A simplifying answer to these computational difficulties is to only use 
sampling models, prior distributions, and losses which lead to explicit solu-
tions for the minimization of (9.1). This restrictive approach was technically 
justified when the computational tools described below were not available 
but is unacceptable on a subjective ground, since loss functions and prior 
distributions should be constructed according to the decision problem, not 
because they provide closed-form answers, as already stressed in Chapter 
3. 1 
This chapter is thus intended to avoid a systematic recourse to 'easy' 
prior distributions and losses by providing the reader with an array of re-
cent and sophisticated approximation methods which can be used when no 
analytical expression of the posterior distribution or of the estimators are 
available. However, we do not cover minimization in this book, since this 
problem is more directly related to Numerical Analysis than to Statistics; 
moreover, usual optimization methods like the Newton-Raphson algorithm 
are covered by classical Statistics books for the computation of maximum 
likelihood estimators and, more generally of M-estimators (see, e.g., Titter-
ington et at., 1985). Lastly, if 1r(Blx) can be correctly approximated, e.g., 
simulated by one ofthe methods described in §9.2 and §9.3, it is usually pos-
sible to derive an approximation of L(1r, 81x) for an arbitrary 8 and then to 
use a classical minimization method. Recent papers (Geyer and Thomson, 
1992; Robert, 1993a) have proposed more statistical methods of optimiza-
tion which are based upon Markov Chain Monte Carlo methods presented 
below. We now introduce a series of examples which are used throughout 
this chapter to illustrate different computational methods. 
Example 9.1 Consider Xl, ... , Xn a sample from C(B, 1), a Cauchy distri-
bution with location parameter B, and B '" N(j.l, 0-2), with known hyperpa-
rameters j.l and 0-2 . The posterior distribution of B is then 
1 Classical illustrations resort to such simple setups because they allow for a 
clearer and more concise presentation of points of interest and this book has 
made intensive use of exponential families, conjugate priors, and quadratic 
losses for this reason. Nevertheless, a more adaptive approach, relying for in-
stance on mixtures of conjugate priors, should be adopted in practical settings. 

9.1. Implementation Difficulties 331 
n 
7r(BIXI, ... ,Xn ) ex e-(O-J-L)2/2a2 il[1 + (Xi - B)2rl, 
i=l 
which cannot be integrated analytically. When 81r is the posterior mean, 
1r 
J~: Be-(O-J-L)2/2a2 I1~=1[1 + (Xi - B)2]-ldB 
8 (Xl, ... ,Xn ) = r:: c(O-J-L)2/2a2 I1~=I[1 + (Xi - B)2]-ldB ' 
its derivation requires two numerical integrations (one for the numerator 
and one for the denominator). The computation of the variance calls for an 
additional integration. Moreover, the usually multimodal structure of this 
distribution (see Exercise 1.21) prevents the use of standard integration 
packages. 
!:::, 
As we have seen before, the computational problem may be due to the 
choice of the loss, even though the prior distribution is conjugate. 
Example 9.2 Let xlB rv Np(B, rr2Ip) and Blp" T rv Np(p" T2Ip), with known 
hyperparameters p, and T. The posterior distribution on 61 is then quite 
manageable since 
( rr2p,+T2x 
rr2T2 
) 
Blx rv Np 
2 
2' 2 
2Ip. 
rr +T 
rr +T 
When 1161112 is the parameter of interest, the usual rescaled quadratic loss is 
as in Saxena and Alam (1982). It leads to the following Bayes estimator: 
81r ( 
) = IE1r[II£1112 /(211£1112 + p)lx] 
X 
IE1r[I/(21IBI12 + p)lx] 
Although (rr-2 + T-2)IIBI12 is distributed a posteriori as a X~(.A) random 
variable, with 
Ilrr2p, + T2XI12 
A = '-'-::----':--c----::----'-',-,--
rr2T2(rr2 + T2)' 
an analytic version of 81r does not exist and numerical approximation is 
again necessary. Note that, in this case, numerical integration is more com-
plicated than for Example 9.1, because the density of X~(A) (see Appendix 
A) involves a modified Bessel function, I(p-2)/2(t), which must be approxi-
mated in most settings by a series of weighted central chi-squared densities 
or by a continued fraction approximation (see Exercise 4.25). An alternative 
approach is to integrate instead over 61, but this is only feasible for small 
p's. 
!:::, 
Chapter 8 provides numerous examples where approximations of Bayes 
estimators are necessary. Indeed, most hierarchical Bayes estimators cannot 

332 9. Bayesian Calculations 
be computed analytically; for instance, this is the case for normal obser-
vations (see Lemma 8.3). Moreover, a numerical approximation of these 
estimators can get quite involved, especially for higher dimensions. 
Example 9.3 The call to an auxiliary variable in a multivariate Student's t 
model reduces the number of integrations to one, as pointed out by Dickey 
(1968). Let us recall that, if 
we can write 
with 
C 2 + 
2 
~(x) = <,,(J J-l 
7 X 
~(J2 + 7 2 
(see Example 8.1). Consider the following generalization: 
when B and A 
(1 ~ i ~p) 
diag( (Jf, ... ,(J~) are unknown, with prior distributions 
In this case (1 ~ i ~ p), 
BilXirvT vi+ 1, 
, 
(
Xi + ni/.Li 
ni + 1 
(Vi + l)-l(ni + 1)-1 [8; + n1n~ 1 (Xi - J-li)2]) , 
and the call to an auxiliary variable ~i for each component Bi does not 
modify the complexity of the estimation problem, since it does not change 
the number of integrals. 
l::, 
The two examples we consider below are coined as "paradoxical" , in the 
sense that a formal explicit expression of the Bayes estimators is available 
but it cannot readily be used in practice, either because it induces numerical 
instability and thus unreliability of the result (Example 9.4), or because 
the actual computation of the resulting Bayes estimator is impossible in 
the sense that it cannot be done in a reasonable amount of time for most 
samples sizes (Example 9.5). 

9.1. Implementation Difficulties 333 
Example 9.4 In the setup of capture-recapture models, we consider the 
following temporal model (see §4.4.3) with conjugate priors 
xilN,Pi ""B(N,Pi), 
7r(N) = liN, 
Pi ""Be(a,{3) 
(1::; i ::; n). 
If X+ denotes the number of different individuals captured at least once 
during the n captures, the posterior distribution on Nand P = (Pl,'" ,Pn) 
is, for x = (Xl, ... ,Xn,X+), 
and the marginal distribution of N can be derived as 
(9.2) 
Therefore, the posterior distribution can be written in the "explicit" form 
Actually, because of the ratios in the numerator and denominator, formula 
(9.3) does not require any computation of the gamma function but only the 
use of the recursive formula T(x + 1) = xT(x). Nonetheless, if n is large, 
i.e., if many captures have been undertaken, and if, moreover, the resulting 
capture sizes Xi are very different, the computation of the posterior distri-
bution (9.3) will be quite difficult. The quantities (9.2) can fluctuate widely 
and the stopping rule for the computation of the infinite sum in (9.3) must 
be devised accordingly, lest it ignores the significant terms corresponding 
to larger values of M. Moreover, the computation of the sequence (9.2) 
through the following recurrence formula: 
7r(N+1Ix) 
N 
fr,8+N-X i 
7r(Nlx) 
- N + 1- x+ i=l a +,8 + N' 
although possible, can be quite damaging because it increases the approxi-
mation error at each step, especially when the Xi'S are very different. The 
same criticism applies for the computation of the posterior mean 

334 9. Bayesian Calculations 
Therefore, even though this discrete model seems analytically tractable, 
the above explicit formulas can only be used for the simplest examples. 
When the numbers of observations and of captures get large, numerical 
alternatives become necessary. Furthermore, the appeal of these formulas 
disappears for a hierarchical extension, since they cannot be used when a 
hyperprior on (ex, (3) is considered (see George and Robert, 1992). 
!::::. 
Example 9.5 Consider a sample Xl, ... ,Xn from 
(9.4) 
i.e., from a mixture of two normal distributions with means /1i, variances 
(jT (i = 1,2) and weight P (0 < P < 1). We introduced a radiological 
application of this model in Example 1.5. A study on a first set of lung 
radiographs showed that images were distributed with parameters varying 
according to Table 9.1. 
TABLE 9.1. Parameters statistics for a lung radiograph model. 
(Source: Plessis, 1989.) 
/11 
/12 
(j1 
(j2 
P 
Average 
105.33 188.9 
32.3 18.2 
0.5 
Standard deviation 11.18 
7.38 
5.62 
4.5 
0.08 
As a first approximation, given the information provided by Table 9.1, 
a possible modeling is to use "conjugate" priors on () = (/11,(jr,p,/12,(j~), 
and to derive the hyperparameters from Table 9.1 by the moments method. 2 
In fact, these distributions are not conjugate in the sense of Definition 3.1, 
but the corresponding posterior distribution is 
n 
7l'(Bl x1,"" xn) ex II {p'P(Xj; /11, (j1) + (1- p)'P(Xj; /12, (j2)} 7l'(B) , 
j=l 
thus corresponds to a mixture of the above prior distributions, when ex-
panding the product of sums. A straightforward development shows that 
this expansion can be written as 
n 
7l'(Blx1,"" xn) = L L w(kt )7l'(BI(kt )), 
£=0 (ktl 
(9.5) 
2 Note that this modeling differs from an empirical Bayes modeling. Indeed, 
although the resulting prior is only an approximation and the hyperparameters 
are estimated through a classical method, this distribution is based on previous 
observations, which can be considered as prior information, not on the observed 
sample for which the parameter () is unknown. 

9.1. Implementation Difficulties 335 
where £ denotes the number of observations attributed to the first com-
ponent and where the second sum takes into account every permutation 
(kt) of {1,2, ... ,n} which gives a different partition of {X1, ... ,Xn } into 
{Xk 1 , ••• , Xke} and {XkHll ... , Xk n }, thus characterizing the £ observations 
attributed to the first component. The posterior weight of a partition (kt ) 
is (see below for notation) 
normalized so that 
n 
LLw(kt) = l. 
£=0 (kt ) 
For a given permutation (kt ), the conditional posterior distribution is 
;r(BI(kt )) =N (6(kt), n1U!£) x IQ((V1 +£)/2,Sl(kt)/2) 
x He(D'. + £, f3 + n - £) 
xN (6(kt), 
u§ 
£) x IQ((V2 + n - £)/2, s2(kt)/2), 
n2 +n-
where 
1 £ 
£ 
x1(kt) = C LXkt, sl(kt) = 2:)Xkt - x1(kt))2, 
t=l 
t=l 
1 
n 
n 
x2(kt) = n _ £ L 
Xkt, s2(kt) = L 
(Xkt - x2(kt))2 
t=£+l 
t=£+l 
are the usual statistics for the two subsamples induced by the permutation 
and 
(: (k) = n1~1 +£x1(kt) 
(: (k) = n26 + (n - £)X2(kt) 
<,,1 
t 
+ /J 
' 
<,,2 
t 
+ 
/J 
' 
n1 
-t 
n2 
n --t 
sl(kt) = si + si(kt) + n1£ /J(6 - x1(kt))2, 
n1 +-t 
2 
,2 
n2(n-£) ( 
-()2 
s2(kt) = s2 + s2(kt) + 
£ 6 - X2 kd , 
n2 +n-
are the posterior updates of the hyperparameters, conditionally on the par-
tition (kt ). This decomposition is quite interesting since it shows that, be-
hind a seemingly inextricable formula, the Bayesian analysis of a mixture 

336 9. Bayesian Calculations 
distribution like (9.4) is quite logical. Indeed, the posterior distribution 
takes into account every possible partition of the sample, specifying from 
which component each observation originated. It then attributes a weight 
w(kt ) to the partition, which can be viewed as a posterior probability ofthe 
selected partition, and operates as if each observation was actually coming 
from the selected component, since the (conditional) posterior distribu-
tions 7f(BI(kt )) are identical to the usual posterior distributions on (f-Ll, O"d 
and (f-L2,0"2) resulting from the separate observation of Xk 1 ,···, Xke and 
Xke+1 , ••• ,Xkn • Similar comments apply for the posterior distribution of p 
since, conditionally on the partition (kt), it corresponds to the observation 
of a binomial random variable B( n, p), which is the number of observations 
attributed to the first component. 
The decomposition (9.5) provides the following Bayes estimator of B: 
n 
811" (Xl, ... ,Xn ) = L L w(kt )JE1I" [Blx, (kt )], 
£=O(ktl 
the weighted sum of the Bayes estimators for each partition. For instance, 
the Bayes estimator of f-Ll is 
n 
f-Lr(Xl, ... ,Xn ) = LLw(kt )6(kt ). 
(9.6) 
£=0 (ktl 
These developments are very satisfactory from a theoretical point of view 
because the resulting estimators are easy to interpret and intuitively con-
vincing. Quite naturaly, since the originating component of each observation 
in the sample is unknown, the posterior distribution takes into account the 
possibility that this observation was generated by the first or second com-
ponent. However, the practical calculation of (9.6) involves two sums with 
2n terms each, which exactly correspond to the different partitions of the 
sample. It is therefore impossible to compute a Bayes estimator this way 
for most sample sizes.3 
!'::, 
Example 9.5 is quite representative of a whole class of statistical mod-
els where similar problems occur, including most missing data problems 
like mixtures, censored models, classification, clustering, etc. (see Smith 
and Makov (1978), Binder (1978), Silverman (1980), Bernardo and Giron 
(1986, 1988), Heitjan and Rubin (1991), Qian and Titterington (1991), and 
Diebolt and Robert (1994)). They are paradoxical in the sense that "ex-
plicit" derivations of the Bayes estimators are formally available but prac-
tically useless and that, moreover, the computational difficulty increases 
with the sample size, leading to what could be called an "information para-
dox" since the more information one gets the more difficult it becomes to 
3 For instance, if it takes one second of CPU time to evaluate (9.6) for a sample 
of size 20, the computation of the corresponding estimator for a sample of size 
40 would require twelve days. 

9.2. Classical Approximation Methods 337 
draw an inference4 about (). Note also that, in such setups, numerical ap-
proximations methods are seldom appropriate. Some tailored solutions are 
then necessary; they will be developed in §9.3 and §9.4. 
9.2. Classical Approximation Methods 
This section briefly covers some classical techniques which can facilitate 
Bayesian calculations, while the next section deals with a new simulation 
method which seems particularly adapted to some requirements of Bayesian 
computation. A more detailed survey of these techniques is provided in 
Smith et al. (1985), Tanner (1991), and Gilks et al. (1994); Goel (1988) 
and Press (1989) survey available Bayesian software. 
9.2.1. Numerical Integration 
Starting with the primitive Simpson's method,5 many approaches have been 
devised by applied mathematicians to approximate integrals numerically. 
For instance, polynomial quadrature is intended to approximate integrals 
related with distributions close to the normal distribution (see Naylor and 
Smith (1982) and Smith et al. (1985) for a detailed introduction). The basic 
approximation is given by 
where 
2n - 1n!y'n 
w· -
-;:-,.--,.--:'--:-= 
• -
n 2[Hn - 1(ti)J2 
and ti is the ith zero of the nth Hermite polynomial, Hn(t). Other related 
integral approximations are also available, based upon different classical 
orthogonal bases (see Abramowitz and Stegun, 1964), or even the wavelets 
method (see Meyer, 1990), but these methods usually require regularity as-
sumptions on the function f, and preliminary studies in order to determine 
which basis is the most appropriate and how accurate the approximation 
is. For instance, transformations of the model may be necessary to apply 
the above Hermite approximation (see Naylor and Smith (1982) and Smith 
and Hills (1992)); Morris (1982) (see also Diaconis and Zabell, 1991) shows 
4 Strictly speaking, the computational difficulty is always increasing with the 
sample size, even in setups where there exists a sufficient statistic. However, in 
the case of Example 9.5, the difficulty is increasing so fast (at an exponential 
rate) that it completely prevents the actual computation. (Such problems are 
called NP-hard in Operation Research.) 
5 See Stigler (1986) for a closer relation between Simpson (1710-1761) and 
Bayesian Statistics. 

338 9. Bayesian Calculations 
how distributions from the quadratic variance exponential families (see Ex-
ercises 3.21 and 8.26) can be associated with particular orthogonal bases 
(see Exercise 9.17). However, it seems that, whichever numerical integra-
tion method is used, its accuracy dramatically decreases as the dimension 
of 8 increases. In fact, an empirical rule of thumb is that most standard 
methods should not be used for integration in dimensions larger than 4, 
although they keep improving over the years. But the size of the part of 
the space which is irrelevant for the computation of a given integral grows 
considerably with the dimension of the space. 
9.2.2. Monte Carlo Methods 
In a statistical problem, the approximation of the integral 
fe g(0)J(xI0)7r(0) dO, 
(9.7) 
should take as much advantage as possible of the special nature of (9.7), 
namely, the fact that 7r is a probability density (or at least that J(xI0)7r(0) 
is proportional to a density distribution). A straightforward way to do so is 
to generate random variables 01 , ..• , Om from 7r(0Ix) (or, more exactly, to 
use a deterministic "pseudorandom generator" which mimicks generation 
from 7r, see Appendix B). According to the law of large numbers, there is 
convergence of the average 
to (9.7) when m goes to +00. Moreover, there is no need to simulate exactly 
from 7r or 7r('lx) to get a good approximation. If h is a probability density 
on 8, the Monte Carlo method with importance function h is defined the 
following way: generate 01, ... ,Om according to h and approximate (9.7) 
through 
1 m 
-
Lg(Oi)Wi(Oi), 
m i=l 
with the weights W(Oi) = J(XIOi)7r(Oi)/h(Oi). The law of large numbers 
ascertains that, when (9.7) is defined and 
this approximation also converges to (9.7) in probability, since 
r g(0)J(xI0)7r(0) dO = r g(0)J(xI0)7r(0) h(O) dO. 
le 
le 
h(O) 
Therefore, 

9.2. Classical Approximation Methods 339 
]E71"[g(O)lx] = Ie g(O)J(xIO)7r(O) dO ~ 2::1 g(Oi)W(Oi) 
(9.8) 
Ie J(xIO)7r(O) dO 
2::1 W(Oi) 
Although (9.8) theoretically converges to ]E71"[g(O)lx] for most functions 
h, the choice of the importance function is crucial. First, simulation accord-
ing to h must be easily implemented and thus requires a fast and reliable 
pseudo-random generator. (Appendix B indicates some classical algorithms 
for the usual distributions. A thorough study of nonuniform generators is 
given in Devroye (1985), while Marsaglia and Zaman (1993) have proposed 
a 286 period uniform generator.) Moreover, the function h(O) must be close 
enough to 7r(Olx), in order to reduce the variability of (9.8) as much as 
possible; otherwise, most of the weights W(Oi) will be quite small and a 
few will be overinfluential. For instance, if the posterior distribution 7r( Olx) 
is actually available, i.e., if one can simulate from 7r(Olx), a good choice is 
obviously h(O) = 7r(Olx) (if not necessarily the best choice, as shown by 
Exercise 9.13). 
Example 9.2 (Cont.) The posterior distribution of 17 = 11011 2 is well known, 
since 7r(17lx) is a noncentral chi-squared distribution X~(.>') rescaled by 
(j2T2 j((j2 + T2). Writing 17 as (j2T2(x2 + z)j((j2 + T2), where x rv N( V). , 1) 
and z rv X~-l' it follows that simulating a sample 171, ... ,17m from 7r( 17lx) 
is straightforward and we can approximate (9.2) by 
(9.9) 
Moreover, the variance of (9.9) controls the precision of the approximation 
(and the choice of m). 
6 
In cases where the posterior distribution is not available, another sim-
ple choice of importance function is to take the prior distribution 7r. It is 
obviously interesting in cases where 7r is not necessarily explicit but easy to 
simulate, for instance, in hierarchical models where both levels are proper. 
The same call for caution still applies, though, as 7r must be close enough 
to 7r(Olx). 
Example 9.1 (Cont.) Since 7r(0) is the normal distribution N(f-t, (j2), it is 
possible to simulate a normal sample 01 , ... , OM and to approximate the 
Bayes estimator by 
8'71"( 
) _ 2:~1 Ot I1~=1[1 + (Xi - Ot)2]-1 
Xl,··· ,Xn 
-
M 
2:t=l I1~=1[1 + (Xi - Ot)2]-l 
In the case where the xi's are all far from f-t, this choice may be detrimental 
since the denominator and the weights of the Ot'S in the denominator are 
small for most Ot'S and the approximation 871" is therefore quite unstable. 6 
Example 9.6 Consider, as in Example 8.8, X rv Np(O, Ip), Ole rv U{IIOI12=c}, 
and e rv 9(0:, (3). Although 

340 9. Bayesian Calculations 
leads to an explicit posterior distribution and an explicit Bayes estimator 
(see Example 8.8), it might be more interesting to generate Cl, ... ,Cm ac-
cording to Q(a,(3), then the (}i's according to U{IIOI12=Ci} (1::; i ::; m) and 
to approximate the posterior mean by 
since this alternative avoids the computation of confluent hypergeometric 
functions. 
l:::,. 
When the likelihood .e((}lx) can be normalized into a density, a possible 
choice is h((}) ex .e((}lx), if 7I"((}lx) is almost proportional to the likelihood-
and this is the case for large sample sizes or of almost constant prior dis-
tributions. For instance, this may occur in exponential setups since, if 
f(xl(}) ex eO.x-,p(O) , 
a sample (}l, ... ,(}m from 
h((}) ex eO.x-,p(O) 
can easily be obtained in general (see Exercise 9.20 for a limitation to this 
approach). 
A last remark about the choice of the importance function is that there 
is generally a trade-off between preliminary studies leading to a "good" h 
and fast algorithms. For instance, when h is chosen because it makes the 
simulation of the (}i's easier, attention should be paid to the tails of h 
so that they are heavier than the tails of 71"( (}Ix) in order to avoid slow 
convergence. We should see in the near future the development of more 
general simulation methods in statistical packages along the lines of the 
Metropolis algorithm (see below) and of the general accept-reject method 
of Gilks and Wild (1992) (see Exercise 9.14). 
Compared with numerical integration methods, Monte Carlo methods 
have the additional advantage that, once the sample (}l,"" (}n is gener-
ated, it can be used repeatedly for most inferential purposes, even for the 
derivation of the Bayes rules from the approximated posterior loss 
Additional references and more detailed discussions about Monte Carlo 
methods, including the improved techniques of antithetic and control vari-
ates, and of their application to Bayesian Statistics are given in Steward 
(1979, 1983), Van Dijk and Kloeck (1984), Bauwens (1984), Bauwens and 

9.2. Classical Approximation Methods 341 
Richard (1985), Geweke (1988, 1989), Shao (1989), and Oh and Berger 
(1993). Rubinstein (1981) and Ripley (1987) present stochastic simulation 
methods from a more general point of view. 
9.2.3. Laplace Analytic Approximation 
When the function to integrate in (9.7) is regular enough, there exists an 
analytic-although asymptotic-alternative to Monte Carlo simulations. 
This method was introduced by Laplace and is thus called Laplace approx-
imation. Consider the posterior expectation of interest 
71'[ ( )1 ] = Ieg(O)f(xIO)rr(O)dO 
IE 9 0 x 
Ie f(xIO)rr(O) dO 
This ratio of integrals can be written as 
[ ( )1] 
Ie bN(O) exp{ -nhN(O)} dO 
IE7I' gO X = 
, 
Ie bD(O) exp{ -nhD(O)} dO 
(9.10) 
where the dependence on x is suppressed for simplicity's sake and where 
n is usually the sample size (although it may sometimes correspond to 
the inverse prior variance, as in Robert (1993a) or in Example 9.7). When 
hN(O) = hD(O), IE7I'[g(O)lx] is said to be written in standard form; when 
bN(O) = bD(O), the posterior expectation (9.10) is written in fully exponen-
tial form, according to the terminology of Tierney and Kadane (1986). The 
Laplace expansion of a general integral is given by 
f b(O)e-nh«())dO = ~O'e-nh{ b + 2~ [O'2bll -
O'4b'h'" 
+ 152b(h"')2 O'6 -
~bh(4)O'4]} + 0(n-2), 
where b, h, etc., denote the values of b, h, and of their derivatives for 
o = B, which minimizes h, and 0'2 = [h"(B)]-l (see also Olver, 1974). 
This second-order approximation only requires computation of the two 
first derivatives of g, as opposed to a similar approach proposed by Lind-
ley (1980). Assuming, in addition, that hN and hD satisfy hN - hD = 
0(n- 1), ... , hW - h~) = O(n-l) (as is obviously the case for the standard 
form), Laplace expansion leads to the following approximation of IE7I'[g(O) Ix] 
(with bD = bD(BD), bN = bN(BN), etc.): 

342 9. Bayesian Calculations 
Lemma 9.1 If bD -=I- 0, 
Ie bN(B) exp{ -nhN(B)} dB 
Ie bdB) exp{ -nhD(B)} dB 
= _e-n(hN-hD ) 
-A 
- + ---4-
bDb'!v 
aN 
' 
, 
[bN 
a 2 
{A A 
aD 
bD 
2nb'b 
-bNb'jy -
a'bh'E(bDb~ - bNb~)}] + O(n-2 ). 
A proof of this result is given in Tierney et at. (1989) (see also Exercise 
9.16). Lemma 9.1 thus implies the following development for the two forms 
of the ratio (9.10): 
Corollary 9.2 When JE7f[g(B)lx] is written in standard form, 
2b' AI 
2 All 
4h///AI 
JE7f[g(B)lx] = g + aD A Dg + aDg _ aD 
9 + O(n-2 ). 
(9.11) 
nbD 
2n 
2n 
For the fully exponential form, if 9 is positive and g(OD) is uni-
formly (in n) bounded away from 0, 
Proof. For the standard form, hN = hD; therefore, bN = gbD, OD = ON. 
Thus, 
and 
b Db'!v - b Nb'jy _ All 
2 b~ AI 
A2 
- 9 + 
A g. 
bD 
bD 
The result then follows from Lemma 9.l. 
In the fully exponential case, hN = hD - (lin) log(g). Since we assume 
that g(OD) 2 c > ° 
for every n, eN - eD = O(n- 1). As bD = bN, this 
implies be;) - bCj) = O(n-l) (i = 0,1,2). Additional terms in Lemma 9.1 
can therefore be neglected. 
__ 
Corollary 9.2 clearly points out the advantage of the fully exponential 
interpretation of (9.10), since it avoids computation of the first and second 
derivatives, g' and gil, appearing in (9.11). Note that (9.12) can also be 
written 

9.2. Classical Approximation Methods 343 
The assumption on g, namely, that 9 is positive and bounded away from 
o in eD, is however quite restrictive. Moreover, the usual decomposition 
9 = g+ - g- does not work in this setting. Tierney et al. (1989) overcome 
this drawback by first evaluating the moment generating function of g(8), 
M(s) = IE7r [exp{sg(8n Ix]' 
obviously positive, by M(s) through (9.12), and they derived IE7r [g(8) Ix] as 
d 
A 
2 
IE7r [g(8)lx] = ds (log M(s)) 18=0 + O(n- ). 
They also establish the rather surprising result that this approach provides 
the standard development (9.11) without requiring an evaluation of the first 
and second derivatives of 9 (see Exercise 9.17). 
Example 9.7 (Tierney et al., 1989) Let 7r(8Ix) be a Be(a, (3) distribution, 
the posterior expectation of 8 is then 
87r (x) = ~(3. 
a+ 
This exact computation can be compared with the approximations (9.11), 
and (9.12), 
'7r( ) = a2 + a(3 + 2 - 4a 
0(( 
(3)-2) 
u x 
(a+(3-2)2 
+ 
a+ 
, 
Denoting p = a/(a + (3) and n = a + (3, the approximation error is 
Lls = 21 - 2p + 0(n-3 ) 
n 2 
in the standard case, and 
LlE=21-13p2 +0(n-3 ) 
12pn2 
in the fully exponential case. The second development is then better for the 
median values of p. 
l':,. 
The reader is referred to Leonard (1982), Tierney and Kadane (1986), 
Tierney et al. (1989), and Kass and Steffey (1989) for additional results 
and comments. Note that a reservation made in Smith et al. (1985) about 
Laplace approximation is that it is only justified asymptotically; the spe-
cific verifications conducted in the different papers cannot provide a global 
justification of the method, even though it seems to perform quite well in 
most cases. Other criticisms about this approach are (a) that analytical 

344 9. Bayesian Calculations 
methods always imply delicate preliminary studies about the regularity of 
the integrated function which are not necessarily feasible: (b) that the pos-
terior distribution should be similar enough to the normal distribution (for 
which Laplace approximation is exact); and (c) that such methods cannot 
be used in settings like those of Example 9.5, where the computation of 
the maximum likelihood estimator is quite difficult. Extensions of Laplace 
methods to saddle point approximations are reviewed in Kass (1989). 
9.3. Bayesian Sampling and Markov Chain Monte 
Carlo Methods 
We consider in this section a more general Monte Carlo method which ap-
proximates the generation of random variables from a posterior distribution 
1f(Blx) when this distribution cannot be directly simulated. Its advantage 
upon classical Monte Carlo methods as described in §9.2.2 or in Exercise 9.9 
is that it does not require an importance function and takes into account 
most of the characteristics of 1f(Blx). This extension, called Markov Chain 
Monte Carlo, has almost unlimited applicability, even though its perfor-
mances vary widely depending on the complexity of the problem. In this 
book, we mainly focus on a special case of the Markov Chain Monte Carlo 
method called Bayesian (or Gibbs) sampling and refer to Geyer (1992), 
Tierney (1991, 1994), and Gilks et al. (1994) for a broader perspective. 
Based on works by Geman and Geman (1984), Tanner and Wong 
(1987), and Gelfand and Smith (1990), Bayesian sampling techniques take 
advantage of the hierarchical structure of a Bayesian model, when it can be 
written under the form 
(9.13) 
to generate the random variables £11, ... , £1m . Obviously, when both distri-
butions 1fl(Blx, >.) and 1f2(>.lx) are known, the generation of £I according to 
(9.13) is equivalent to the generation of >. according to 1f2(>'lx), and of £I 
according to 1f1 (Blx, >'). 
Example 9.8 (Casella and George, 1992) Consider (£I, >.) E :IN x [0,1] and 
1f(B,>.lx) ex (;)>.&+<>-1(1_ >.)n-&+i3- 1 , 
where the parameters a and (3 actually depend on x. This model can then 
be written in a hierarchical form, with 1f1 (Blx, >.) a binomial distribution, 
B(n, >'), and 1f2(>'lx) a beta distribution, Be(a, (3). The marginal distribu-
tion of £I is then 
(lll ) = (n) B(a + £I, (3 + n - B) 
1f (7 x 
£I 
B(a, (3) 
, 

9.3. Bayesian Sampling and Markov Chain Monte Carlo Methods 345 
i.e., a beta-binomial distribution. While this distribution has been studied 
(see Kendall and Stuart, 1979), it is not particularly easy to work with. For 
instance, the computation ofIE[B /(B+ l)lx] or of the posterior distribution of 
TJ = e-02 cannot be done explicitly and may involve intricate computations, 
even from a numerical point of view, when a, (3, and n are large. Therefore, 
depending on the inferential problem, it may be more advantageous to 
simulate (>'1, Bd, ... , (Am, Bm) with Ai rv Be(a, (3) and Bi rv B(n, Ai); for 
instance, IE[B/(B + l)lx] can be approximated this way by 
However, the marginal distribution 7r2(Alx) is not always available (in 
analytical and algorithmic forms) and the classical Monte Carlo method 
cannot be implemented. But it may be the case that both conditional 
posterior distributions, 7rl(Blx,A) and 7r2(Alx,B), can be simulated. Since 
they are sufficiently informative about the joint distribution, 7r(B, Alx), as 
7r( B, Alx) can be recovered from the conditional densities (see Exercise 9.21), 
it seems conceptually possible to base a simulation algorithm of 7r(Blx) on 
these conditional distributions. 
Example 9.4 (Cont.) For the temporal capture-recapture model, the two 
conditional posterior distributions are (1 :::; i :::; n) 
and 
with 
Pilx, N rv Be(a + Xi, (3 + N - Xi) 
N - x+lx,p rv Neg(x+, (2), 
n 
(2 = 1 - II (1 - Pi). 
i=1 
On the contrary, the posterior marginal distribution 7r2 (pix) cannot be ob-
tained in a closed form or directly simulated. 
L 
A first Bayesian sampling technique called data augmentation was in-
troduced by Tanner and Wong (1987) to take advantage of the conditional 
distributions according to the following iterative algorithm: 
Initialization: Start with an arbitrary value A(O). 
Iteration: For 1:::; i :::; k, generate 
a. 
B(i) according to 7rl(Blx, A(i-l)) 
b. 
A(i) according to 7r2(Alx, B(i)). 
For k large enough, the resulting random variable B(k) can be consid-
ered to have approximately the distribution 7r(Blx), whatever the starting 
value A(O) is; in other words, the chain (B(k)) is ergodic with stationary 
distribution 7r(Blx) under some fairly general regularity conditions. These 
conditions are detailed in Geman and Geman (1984), Tanner and Wong 

346 9. Bayesian Calculations 
(1987), Schervish and Carlin (1992), Tierney (1991, 1994), Roberts and 
Polson (1993), Smith and Roberts (1992), Diebolt and Robert (1994), and 
Robert (1993d). For instance, Robert (1993d) obtained the following con-
dition: 
Lemma 9.3 If 0 (or if >..) takes values in a compact space e (A, 
resp.) and if 7l'1 (Olx, >..) > 0 on e (7l'2(>"lx,0) > 0 on A, resp.), 
both sequences (o(m») and (>..(m») are ergodic Markov chains with 
invariant distributions 7l'(0Ix) and 7l'(>"lx). 
Moreover, it can be shown that, if the convergence is geometric for one 
of the two chains, e.g., if it takes values in a finite space, the convergence 
to the stationary distribution is also geometric for the other chain (see 
Exercise 9.22); this additional property allows us to consider small k's in 
the practical implementation of the algorithm. It seems that k = 200 is 
often enough for one-dimensional settings. But Raftery and Lewis (1992) 
and Mengersen and Tweedie (1993) provide more advanced tools to assess 
the proper value of k. Tierney (1991) exhibits another sufficient condition 
for the convergence of the Markov chain: (o(m») is ergodic with stationary 
distribution 7l'(0Ix) if the kernel 
K(O, 0') = i 7l'2(>..lx,0)7l'1(O'lx, >..) d>" 
satisfies 
K(O, A) = i K(O, 0') dO' > 0 
for every A such that 7l'(Alx) > O. (This condition is actually enough to 
ensure 7l'-irreducibility of the chain (o(m») and ergodicity follows from the 
existence of a stationary distribution, 7l'(0Ix). See Revuz (1984) or Meyn 
and Tweedie (1993) for a general introduction to Markov chain theory.) 
Once 01 = O(k) is obtained, a naive way to build an Li.d. sample 
01, ... , Om from 7l'(0Ix) is to repeat the same algorithm with another ini-
tial value >..~O) to get O2 after k iterations, and so on until Om. As noticed 
by Casella and George (1992), O(k) (or >..(k») can be taken as a new start-
ing value and this should speed up convergence to 7l'(0Ix) in the following 
steps while introducing dependence on the Oi'S. However, dependence is not 
crucial since the Ergodic Theorem implies that the average 
K 
~ L f(O(k») 
k=l 
converges to IE7I'[f(0)lxj as long as this expectation is finite when K goes to 
infinity (see Revuz, 1984). Moreover, this property is also satisfied by any 
subsequence of (O(k»). Therefore, the Ergodic Theorem indicates that there 
is no need for several starting values. Indeed, as noted in Geyer (1992), 

9.3. Bayesian Sampling and Markov Chain Monte Carlo Methods 347 
the available Markov chain theory does not indicate when stationarity is 
"attained" since this is only an asymptotic property of the chain. There-
fore, it is better to consider a single sequence (e(k)), as each simulation step 
brings us closer (in probability) to a realization from the stationary distri-
bution, 7f(elx), while multiple starts simulation is not totally validated-in 
particular, the number k of iterations should not be the same for every 
starting value--and rejects most of the simulated values, thus inducing a 
considerable waste. 
When required, quasi-independence can be achieved by "batch sam-
pling," i.e., by keeping only one member of the chain out of t iterations 
for the effective simulated sample, with t = 5 or t = 10, since these sizes 
are usually large enough (see Raftery and Lewis (1992) for a discussion on 
the size of the batches in different setups). However, the respective advan-
tages of multiple versus single run simulations are still under discussion, 
as shown in Geyer (1992), Besag and Green (1993), or Smith and Roberts 
(1992), since multiple runs can help to detect artificial stationarities (see 
Gelman and Rubin, 1992). Nevertheless, we advise single runs since mul-
tiple run monitoring is mainly used for convergence assessments and that 
results in this area are not yet quite satisfactory (see Myrkand et al., 1992, 
and Robert, 1993d, for connections with renewal theory). The choice of K 
in the practical implementation of the Ergodic Theorem has thus to be de-
rived by some empirical method like stabilization on the same value for K 
and 5K or simultaneous stabilization of different quantities. But the coming 
years will undoubtedly see techniques, borrowing more heavily from Markov 
chain theory, improve upon the practical determination of K and thus upon 
the convergence monitoring of Bayesian sampling and other Markov Chain 
Monte Carlo methods. 
Example 9.8 (Cont.) The conditional distributions are 
elx, A'" E(n, A), 
Alx, e '" Ee(o: + e, (3 + n - e) 
and allow for Bayesian sampling. Figure 9.1 gives a comparison of the his-
togram of a sample of 500 observations obtained by batch sampling (with 
t = 10) with the histogram of a sample of 500 observations simulated di-
rectly from the beta-binomial distribution. Although the number of iter-
ations is rather small, the comparison shows that the Bayesian sampling 
approximation is quite acceptable. 
l':,. 
The sample e1 , ... , em obtained this way can be used similarly to those 
obtained by the classical Monte Carlo method, but Gelfand and Smith 
(1990) notice that the conditional structure of the sampling algorithm and 
the dual sample, AI, ... , Am, should be exploited. Indeed, if the quantity of 
interest is lE7r [g( e) Ix], one can use the average of the conditional expecta-
tions 

348 9. Bayesian Calculations 
when they can be computed easily, instead of using the direct average 
1 m 
81 = -
Lg(Oi). 
m i=1 
70 
60 
60 
50 
50 
40 
40 
30 
30 
20 
20 
111 __ . 
10 
10 
II. 
0 
0 
2 
6 
10 
14 
2 
6 
10 
14 
(a) 
(b) 
FIGURE 9.1. Histograms for samples of size 500 of the beta-binomial distribution 
with parameters n = 16, Q = 2, and f3 = 4: (a) directly simulated; (b) obtained 
by Bayesian sampling. (Source: Casella and George, 1992). 
This modification is based on the Rao-Blackwell theorem (see Theorem 
2.7) and should improve the efficiency of estimation under quadratic loss 
since, were the Ai'S and Oi'S independent, 
1 
lE7r [(81 -lE7r[g(O)lx])2Ix] = -var7r(g(O)lx) 
m 
1 
~ _var7r (lE7r[g(O)lx, Allx) 
m 
= lE7r [(82 -lE7r[g(O)lx, A]) 2 Ix] . 
Therefore, under quadratic loss and any other strictly convex loss, it is bet-
ter to work with conditional expectations. (See Liu et al., 1992, for a more 
rigorous justification of the "Rao-Blackwellization" for a single run of the 
Markov chain.) In fact, the same argument leads us to propose the approx-
imation of the posterior density n(Olx) by the average of the conditional 
densities 
1 m 
- L n(Olx, Ai), 
m i=1 
instead of using regular kernel estimation methods (see Tanner and Wong 
(1987) and Gelfand and Smith (1990)). 

9.3. Bayesian Sampling and Markov Chain Monte Carlo Methods 349 
Example 9.9 (Casella and George, 1992) Consider the following conditional 
distributions (with x omitted): 
n(BIA) ex Ae-O", 
n(AIB) ex Be->"o, 
0< B < B, 
0< A < B. 
The marginal distribution of B (or of A) cannot be computed but the condi-
tional distributions are easy to simulate, being truncated exponential dis-
tributions. Since IE7f[BIA] ~ l/A for B large, IE7f [Blx] can be approximated 
by 
1 m 
- LBi 
m i=l 
or 
1 m 
1 
mL~· 
i=l 
" 
For this particular example, the complete symmetry existing between the 
two conditional distributions implies that both estimators have exactly the 
same probabilistic properties, besides converging to the same value. 
I':::,. 
A generalization of the hierarchical model (9.13) is to consider several 
groups of parameters, B, AI, ... , Ap , such that 
(9.14) 
This generalization corresponds to the introduction of additional levels in 
the hierarchical model, either for modeling reasons or for simulation reasons 
(see below the example of hidden mixtures); it may also occur because of the 
decomposition of the hyperparameter A or of the parameter B in components 
of smaller dimensions. 
Example 9.8 (Cont.) If the population size n has a Poisson prior, P(~), the 
overall joint posterior distribution is 
and the marginal distribution of B cannot be derived. On the contrary, the 
conditional distributions have explicit expressions, since 
Blx, A, ~ "-J l3(n, A), 
Alx, B, ~ "-J l3e(B + 0:, n - B + (3), 
n - Blx, B, A "-J P(~(l - A)). 
Simulation according to these conditional distributions is thus possible. I':::,. 
Example 9.10 (Tanner and Wong, 1987) Consider a multinomial model, 
y "-J M5 (n; al/-L + bl , a2/-L + b2, a37) + b3, a47) + b4, c(l -
/-L -7))), 
parametrized by /-L and 7), where 

350 9. Bayesian Calculations 
4 
o ~ a1 + a2 = a3 + a4 = 1 - I: bi = C ~ 1 
i=l 
and c, ai, bi ~ 0 are known. This model stems from sampling according to 
with an aggregation of some observations 
A natural prior distribution on (f-l, TJ) is the Dirichlet distribution D( aI, a2, 
(3), 
7r(f-l, TJ) <X f-lQI-1TJQ2-1(1 -
TJ - f-l)Q3-1, 
where a1 = a2 = a3 = 1/2 corresponds to a noninformative modeling. In 
this setup, the posterior distributions cannot be derived explicitly. However, 
if we define the missing data Z = (Xl, X3, X5, X7), X is indeed equivalent to 
(y, z) and 
7r(TJ, f-lly, z) = 7r(TJ, f-llx) 
<X f-lZ1 f-lZ2TJZ3TJZ4 (1 -
TJ - f-l)YS+Q3-1 f-lQI-1TJQ2-1. 
Therefore, 
-1 
f-l Iy, z, TJ tv 13e(zl + Z2 + aI, Y5 + (3), 
-TJ 
-1 
TJ 
Iy, z, f-l tv 13e(z3 + Z4 + a2, Y5 + (3), 
-f-l 
and 
f-l, TJly, Z tv D(ZI + Z2 + aI, Z3 + Z4 + a2, Y5 + (3). 
Moreover, 
( 
aif-l) 
zily, f-l, TJ tv 13 Yi, aif-l + bi 
(i=1,2), 
( 
aiTJ
) 
zily, f-l, TJ tv 13 
Yi, aiTJ + bi 
(i=3,4). 
Defining () = (f-l, TJ) and A = Z = (Zl' Z2, Z3, Z4), it thus appears that some 
conditional distributions can be simulated in this setting. Note that the 
missing data Z does not appear in the original formulation of the problem 
and is somehow "artificial." However, it greatly facilitates the simulation 
of the (}'s. Similar behavior will occur in other missing data and hidden 
mixture models. 
6 
In this generalized hierarchical setup, implementation of the Bayesian 
sampling can be done in many ways. If the decomposition of ((), A) in 
((), AI, ... , Ap) corresponds to a division of the model into its hierarchical 
levels, it seems logical to simulate according to the conditional distributions 

9.3. Bayesian Sampling and Markov Chain Monte Carlo Methods 351 
7r(Olx, AI, ... , Ap), 
7r(Ailx, 0, (Aj)j#i) 
(1:S i :S p), 
(9.15) 
whatever the dimensions of 0 and of Aj are. For instance, in Example 9.10, 
(/-L, 'rJ) could thus be generated conditionally on (y, z) according to a Dirich-
let distribution and z conditionally on (/-L, 'rJ). An alternative proposed in 
Gelfand and Smith (1990) is to neglect hierarchical divisions, to consider 
only one-dimensional parameters (or whatever decomposition is more ap-
propriate) and to generate them conditionally on the other parameters. 
Formally, this approach corresponds to the decomposition (9.15). This al-
ternative fits into what is now called the Gibbs sampling, even though it 
is only remotedly connected with the Gibbs distribution (see Geman and 
Geman, 1984). This is why we prefer the more neutral term of Bayesian 
sampling. In Example 9.10, Gibbs sampling is equivalent to the iterative 
simulation of 
/-L(i) '" (1 - .,p-1))8e (zii-l) + Z~i-l) + (};t, Y5 + (};3) , 
'rJ(i) '" (1 - /-L(i))8e (4-1) + Z~i-l) + (};2, Y5 + (};3) , 
(i) 
( 
aj/-L(i)) 
Zj '" 8 
Yj, 
C) 
b 
(j = 1,2), 
aj/-L t + j 
(i) 
( 
aj'rJ(i)) 
Zj ",8 Yj'aj'rJ(i)+bj 
(j=3,4). 
The first approach (also called substitution sampling in Gelfand and Smith, 
1990) should be preferred since it respects the initial hierarchical model-
ing and also converges more rapidly to the stationary distribution (see Liu 
et al., 1992). Convergence diagnostics are also easier to establish in these 
settings, as a duality principle usually allows for the transfer of probabilis-
tic properties from the simplest chain to the chain of interest (see Diebolt 
and Robert, 1994, and Exercise 9.22). However, to be able to use data 
augmentation (or substitution sampling), one needs the conditional distri-
butions for each hierarchical level (as 7r(rJ, /-Lly, z) in Example 9.10), and 
they may be more difficult to derive than fully conditional distributions 
(see Exercise 9.40 for an example where data augmentation is impossible). 
Moreover, general Gibbs sampling does not actually require the 0 and the 
Ai'S to be onedimensional and the choice of the additional hyperparame-
ters can then be entirely based on simulation reasons. Note also that, when 
reduced conditional distributions, like 7r(Olx, Aio), are available for simula-
tion, it is obviously preferable to use these distributions since they increase 
convergence speed by reducing the dependency on the other parameters. 
Example 9.4 (Cont.) When N, the size of the population, is the parameter 
of interest, Bayesian sampling provides a sample, N1, •.. , Nm , starting with 
an initial value of p = (piO), . .. ,p~)) and iteratively generating according 
to 

352 9. Bayesian Calculations 
NU) - X+IX,p(j-I) rv Neg(x+, pU-I)), 
p~j) lx, N(j) rv Be(a + Xi, (3 + N(j) - Xi) 
(1::; i ::; n). 
The sample Nt, ... ,Nm is then obtained by taking Nl = N(ko+T), N2 = 
N(ko+2T), ... , Nm = N(ko+mT). Bayesian sampling simultaneously gives a 
sample pI, ... ,pm. The expectation JE7r [Nix] can then be approximated by 
according to the "Rao-Blackwellization" argument mentioned above. 
George and Robert (1992) provide hierarchical extensions in this setup by 
considering different families of hyperpriors on (a, (3). 
D, 
This particular Monte Carlo method may seem to apply only in a 
quite restrictive setting, since it involves hierarchical structures, as in (9.13). 
Moreover, it still requires some partial knowledge about the posterior con-
ditional distributions. Examples in Gelfand and Smith (1990), Racine-Poon 
et al. (1990), Gelfand et al. (1990), Tanner (1991), and in other papers ref-
erenced in Casella and George (1992) and Gilks et al. (1994) show to the 
contrary that the field of application of Bayesian sampling is quite wide. In 
fact, as noted in Robert (1990c), the hierarchical decomposition (9.13) is 
not particularly restrictive; indeed, numerous distributions (on the obser-
vation or the parameter) can be written as hidden mixtures, with a totally 
artificial parameter >.. Therefore, even when the hierarchical structure is 
missing in the original problem, it can often be forced to appear and thus 
improve the computation of the Bayes estimators or even the choice of the 
prior distribution. 
The hierarchical decomposition is particularly interesting when the 
initial distribution does not belong to an exponential family and there is no 
corresponding conjugate family. For instance, this is the case for Student's 
t and noncentral chi-squared distributions. Decomposition of f(xIO) under 
the form 
f(xIO) = J 
f(xIO, z)g(zIO) dz 
can then allow for a prior modeling on 0 through conjugate priors (for 
f(xIO, z) or g(zIO)). 
Example 9.11 Consider x rv X; (0), an observation from a noncentral chi-
squared distribution. It can also be written as a mixture 
xlO, z rv X;+2Z, 
zlO rv P(Oj2). 

9.3. Bayesian Sampling and Markov Chain Monte Carlo Methods 353 
Therefore, only g(zle) depends on e and a possible prior distribution on e 
is 9(00, (3), since it is conjugate for the Poisson distribution. 
6. 
Example 9.12 Consider xlJ.1" IJ rv T(m, J.1" 1J2). Following Dickey's represen-
tation (1968), 
we can propose 
as a prior distribution and we derive 
(9.16) 
The conditional distributions (9.16) directly allow for simulation through 
Bayesian sampling. Note the difference with the classical normal example 
(see §4.3). In this case, 1J2 has a gamma prior instead of an inverse gamma 
distribution and, more importantly, J.1, and IJ are a priori independent. The 
conditional decomposition thus leads to a modeling which is more satisfac-
tory than in the normal case. 
6. 
The resort to a hidden mixture, either for f(xle) or for 7r(e), may also 
be helpful to simulate 7r(elx) through Bayesian sampling when the posterior 
distribution is not available. 
Example 9.12 (Cont.) If, for robustness, the prior distribution is actually 
the corresponding hidden mixture representation is 
J.1,18 rv N(~, 8), 
and the simulation of 7r(J.1" IJlx) can be done by Bayesian sampling according 
to the following conditional distributions: 

354 9. Bayesian Calculations 
As mentioned at the beginning of this section, Bayesian sampling is 
only a special case of Markov Chain Monte Carlo methods (MCMC). These 
methods supplement the limitations of the usual Monte Carlo techniques 
by constructing Markov chains whose stationary distributions are the dis-
tributions of interest. For estimation purposes, the resulting sample can be 
used as an i.i.d. sample, the Ergodic Theorem extending the Law of Large 
N umbers, although the control of convergence issues is far more delicate 
(see Geyer, 1992, or Tierney, 1994). 
An algorithm producing Markov chains with the adequate stationary 
distribution has been constructed by Metropolis et al. (1953) in mechanical 
physics, but it actually applies to a wide variety of settings, the main re-
striction to its use being that the support of the distribution to simulate has 
to be determined, at least by excess. In its modern version, the Metropo-
lis algorithm can be described as follows. Given a density 1l"( 0) known up 
to a normalizing factor and a conditional density q(OIO'), the algorithm 
generates the chain (o(m)) by: 
(i) Start with an arbitrary initial value 0(0); 
(ii) Update from oem) to o(m+l) by 
1. Generate ~ rv q(~lo(m)); 
2. Define 
3. Take 
o(m+1) _ {~ 
with probability (!, 
-
e(m) 
otherwise. 
When the support of q(·IO') contains the support of 1l" for every 0' such 
that 1l"(O') > 0, this algorithm is indeed converging to 1l" as the only sta-
tionary distribution (see Exercise 9.19). Many papers have considered the 
problem of selecting the distribution q (Hasting, 1970; Geyer, 1992; Miiller, 
1991; Mengersen and Tweedie, 1993) but note that any distribution satisfy-
ing the above condition is formally appropriate. This algorithm is therefore 
widely applicable and, moreover, has limited 'tune-up' requirements since 
q can be chosen almost independently of the true density 1l". In addition, in 
most Bayesian setups, 1l" is actually known up to a multiplicative factor and 
the Metropolis algorithm can be implemented in every case where Bayesian 
sampling works (see Exercise 9.31). It also contains the Gibbs sampling as 
a particular case where {! is always 1 (see Exercise 9.32). 
Example 9.13 Weibull distributions are intensively used in reliability and 
other engineering applications, partly for their ability to describe different 
hazard rates behaviors and partly for customary reasons. Since they do not 
belong to any exponential family, as 
(9.17) 

9.4. An Application to Mixture Estimation 355 
they cannot lead to explicit posterior distributions on the parameters a and 
'f/. Moreover, there is no tractable hidden mixture representation of (9.17) 
and a convenient prior and a Bayesian sampling scheme cannot be easily 
derived. Considering the prior 
7r(a,'f/) ex: e-a.'f/{3-le-t;"r/ 
and observations Xl, ... ,Xn from (9.17), a Metropolis algorithm for the sim-
ulation of 7r( a, 'f/lxl' ... ,xn ) can be based upon the conditional distribution 
q(a, 'f/la', 'f/') = +,exp (_ a, _ 'f/,), 
a'f/ 
a 
'f/ 
i.e., on two independent exponential distributions with means a' and 'f/'. 
The resulting probability weight is then 
if (a, 'f/) is the simulated value and (a', 'f/') is the current value of the pa-
rameters. 
~ 
9.4. An Application to Mixture Estimation 
We conclude this chapter by showing how Bayesian sampling is appropriate 
for the derivation of the Bayes estimators of the parameters of a mixture 
of normal distributions, considered in Example 9.5. Extensions to other 
distributions from an exponential family are straightforward. As detailed in 
§9.1, a Bayesian analysis leads to the "information paradox" that an explicit 
estimator is available and intuitively justified, but cannot be computed 
when the number of observations gets too large. Moreover, the maximum 
likelihood estimators of the parameters of (9.4) are not clearly defined, 
solutions to the likelihood equations are difficult to estimate and neither 
Monte Carlo simulation, nor analytical methods can be used to provide an 
approximation for the Bayes estimator in this case. 
The classical treatment of estimation of finite mixtures of distribu-
tions is presented in Titterington et al. (1985) and MacLachlan and Bas-
ford (1987). Dempster et al. (1977) and Redner and Walker (1984) have 
studied a special algorithm called EM (for Estimation-Maximization) for 
maximum likelihood estimation, and Broniatowski et al. (1983), Celeux and 
Diebolt (1985,1990), and Qian and Titterington (1991) have proposed some 
stochastic extensions of the EM algorithm. Quasi-Bayesian approaches to 
the estimation problem are developed in Smith and Makov (1978), Silver-
man (1980), and Bernardo and Giron (1986, 1988). A more detailed study 
of Bayesian sampling for mixtures is proposed in Diebolt and Robert (1994) 

356 9. Bayesian Calculations 
and Robert (1994) (see also Verdinelli and Wasserman (1991) for an appli-
cation to outlier detection). Let us stress again the importance of mixtures 
of the usual distributions from a modeling perspective. In fact, these distri-
butions are located at the boundary between parametric and nonparametric 
modeling and allow for the description of more complex phenomena, while 
keeping a reasonable size (i.e., a reasonable number of parameters). 
Bayesian sampling for mixtures relies on a missing data representation, 
as in Dempster et al. (1977) and Tanner and Wong (1987), to build up a 
hierarchical structure similar to (9.13). Consider 
k 
X rv f(xIO) = LPi<P(X; J-Li, ai), 
(9.18) 
i=l 
a mixture of k normal distributions with means J-Li and variances a; (1 ::; 
i ::; k) and LiPi = 1 (Pi> 0). Given a sample from (9.18), Xl, ... ,Xn , we 
define the missing value Zj (1 ::; j ::; n) as the component indicator vector 
for Xj, i.e., 
Zi. = {I if Xj rv <p(x; J-Li, ai), 
J 
0 otherwise, 
and Li Zij = 1. This vector can also be considered as an additional param-
eter and it provides the following conditional distributions (1 ::; j ::; n): 
The prior distribution on 0 = (J-LI, al,PI, ... , J-Lk, ak,Pk) can be taken 
to be the product of conjugate distributions 7ri (J-Li , ai), with 7ri(J-Lilai) a 
normal distribution N(~i' ar/ni) , 7ri(a;) an inverse gamma distribution 
IQ(vd2, s; /2), and 7r(p) a Dirichlet distribution, "D(al, ... , ak), thus gen-
eralizing Example 9.5. 
Note that, once the attribution vectors Zj (1 ::; j ::; n) are known, 
the mixture structure actually disappears, since this additional information 
breaks down the sample into subsamples according to the values of Zij. 
Although the posterior distribution of 0 cannot be used per se, as shown 
in Example 9.5, conditioning on Z = (Zl, ... , zn) removes the difficulty. 
Indeed, we get the following posterior distributions (1 ::; j ::; n): 
(9.19) 
with (1 ::; i :s; k) 
and 

where 
and 
n 
mi(Z) = LZij, 
j=l 
9.4. An Application to Mixture Estimation 357 
(9.20) 
n 
S~(X,Z) = LZij(Xj - Xi(Z))2. 
j=l 
Conditionally on z, the posterior distributions only take into account the 
subsamples related with each component, in a manner similar to the de-
composition (9.5) of the true posterior distribution. In addition, simula-
tions from (9.19) and (9.20) are particularly straightforward. Therefore, it 
is much easier to produce a sample (h, ... , Om from n(Olx) by Bayesian 
sampling than to use directly the true posterior distribution. 
Lemma 9.3 implies that Bayesian sampling leads to geometric conver-
gence for the chain (o(m)). The onedimensional Gibbs sampling version of 
this algorithm only modifies the simulation for ai, which is then, condition-
ally on /-li (1 ~ i ~ k) 
Although the change is minor, compared with (9.20), convergence results 
are much more difficult to establish in this setting. In particular, geometric 
convergence cannot be established without imposing restrictions on the ai's 
(see Diebolt and Robert, 1994). Moreover, since data augmentation can be 
implemented in this setting and is usually preferable to the Gibbs sampling, 
there is no reason to use the latter. In the setup of hidden Markov chains, 
which generalize mixture models like (9.18) by introducing Markovian de-
pendence between the x/s, this is no longer possible and Gibbs sampling 
must be used (see Exercise 9.40 and Robert et al., 1993). 
As a final remark, let us point out that Bayesian sampling has brought 
considerable improvement to the Bayesian approach to mixture models, 
not only for estimation as shown above, but also for testing and modeling 
since tests on the number of components of a mixture have been proposed 
(Mengersen and Robert, 1993). Moreover, these studies have also exhibited 
interesting noninformative extensions. In fact, the peculiar properties of 
mixtures prohibit the use of improper priors since, as the likelihood is 

358 9. Bayesian Calculations 
(9.21 ) 
the posterior distribution can be written, as in (9.5), as a sum over all pos-
sible partitions of the sample. Therefore, some of these partitions do not 
attribute any observation to the first component of the mixture. Condi-
tionally on one of these particular partitions, the posterior distribution on 
the parameters of the first component is identical to the prior distribution 
on these parameters; this, obviously, implies that the prior distributions on 
the parameters of every component must be proper. A similar restriction 
applies for the prior distribution on the weights Pi. However, as shown in 
Mengersen and Robert (1993), the prior input can be reduced to the choice 
of a single hyperparameter under a new parametrization of the mixture 
model. Indeed, if (9.18) is written as 
PIN(/-L, r2) + (1 - PI) {P2N(/-L + rfh, r2a-i} 
+(1 - P2) {P3N(/-L + rfh + ral B2, r2aiaD + ... } } , 
an acceptable prior distribution only depends on ~ > 0 and is of the form 
7r(/-L, r) = l/r, Pi IV Be(1/2, 1/2), Bi IV N(O, e), and ai IV (1/2)U[O,lj + 
(1/2)Pa(2, 1), the later distribution being justified by a uniform distribu-
tion on either ai or l/ai. 
Exercises 
Section 9.1 
9.1 For a mixture of two normal distributions as studied in Example 9.5 and 
the data of Table 9.1, identify the hyperparameters of the conjugate distri-
butions by the moments method. 
9.2 In the setup of Example 9.5, show that the posterior distribution can actu-
ally be written as (9.5) and develop w(kt ) and 7r(OJ (kt )). Give the expressions 
of the Bayes estimators of J.L1, 0"1, and P for the hyperparameters obtained 
in Exercise 9.10. 
9.3 Establish the equivalent of Exercise 9.2 for 
(i) a mixture of two exponential distributions; and 
(ii) a mixture of three uniform distributions. 
9.4 In the setting of Exercise 9.2, how does the computing time evolve with the 
sample size when 
(i) only the weight p is unknown; and 
(ii) all the parameters are unknown. 
9.5* (Smith and Makov, 1978) Consider 
k 
X ~ J(xJp) = LPdi(x), 
i=l 
where Pi > 0, Li Pi = 1, and the densities Ji are known. The prior 7r(p) is 
a Dirichlet distribution '0(01, ... , Ok). 

Exercises 359 
a. Show that the computing time gets prohibitive as the sample size in-
creases. 
A sequential alternative which approximates the Bayes estimator is to re-
place 7r(plx1, . .. , Xn) by V(o~n), ... , o~n)), with 
(n) 
(n-1) 
P( 
11) 
(n) 
(n-1) 
P( 
11) 
°1 
= °1 
+ 
Zn1 = 
Xn , ... , Ok 
= Ok 
+ 
Znk = 
Xn , 
and Zni (1 :::; i :::; k) is the component indicator vector of Xn as defined in 
§9.4. 
b. Justify this approximation and compare with the updating of 7r(9Ix1, 
... , Xn-1) when Xn is observed. 
c. Examine the performances of this approximation for a mixture of two 
normal distributions N(O, 1) and N(2, 1) when P = 0.1,0.25,0.5. 
d. If 7rf = P(Zni = llxn), show that 
A(n)( 
) _ A(n-1)() 
{A(n-1) 
n} 
Pi 
Xn - Pi 
Xn-1 - an-1 Pi 
- 7r; , 
where p~n) is the quasi-Bayesian approximation of JE1r(Pilx1, ... , Xn). 
9.6 In the setting of Example 9.4, determine the posterior distribution of 
7r(Nlx): (a) for n = 10 and similar Xi'S; and (b) for n = 30 and very 
different xi's. Consider the same problem when 7r(N) is a Poisson distribu-
tion P()..) and)" varies. Pay particular attention to the potential problems 
linked with the direct evaluation. 
Section 9.2.1 
9.7* (Morris, 1982) Given the quadratic variance natural exponential families 
studied in Exercises 3.21 and 8.26, consider 
a. Show that Pm is a polynomial of degree m in x and in 11" 
b. Show that (m > 1) 
Pm+1(X,P,) = 
[H(x, p,) - mV'(p,)]Pm(x, p,) - m[1 + (m - I)V2]V(p,)Pm-1(X, p,), 
where yep,) = Va + V1P, + V2p,2. 
c. Show that the polynomials Pm are orthogonal, and that JEI-'[P!(x, p,)] = 
amVm(p,). 
d. Give the polynomials associated with the normal, Poisson, gamma, bi-
nomial, and negative binomial distributions. (Note: They are called Her-
mite, Poisson-Charlier, generalized Laguerre, Krawtchouk, and Meixner 
polynomials, respectively.) 
Section 9.2.2 
9.8 Test the algorithms proposed in Appendix B by a Kolmogorov-Smirnov 
test for several sample sizes. They can also be tested by a chi-squared test 
considered from a Bayesian point of view (see Delampady and Berger, 1990). 
9.9 The regular accept-reject simulation algorithm is defined as follows: If f and 
g are densities such that there exists M with f(x) :::; Mg(x): 

360 9. Bayesian Calculations 
1. Generate y '" g(x) and u '" U[O,ll ; 
2. If u> f(y)/A1g(y) , go back to 1; 
3. Take x = y. 
Show that this algorithm actually provides an observation x from f(x). 
9.10 Establish the validity of the algorithms provided in Appendix B. 
9.11 Check the Box-Muller normal variate generation algorithm given in Ap-
pendix B by computing the correlation between Xl and X2. 
9.12 Assess the sensitivity of the algorithms proposed in Appendix B by simu-
lating them for different uniform variate generators. Compare convergence, 
convergence speed, and variance for different quantities of interest. 
9.13* (Ripley, 1987) Consider the integral 
1= lb f(x) dx, 
approximated by a Monte Carlo method with importance function h: 
, 
1 ~ 
1= m ~ 
f(Xi)/h(Xi). 
i=l 
a. Show that the variance of i is 
var(i) = ~ lb (~~:~ _ I) 2 hex) dx 
and deduce that it is minimized by h rx f. 
Consider 0:::; f(x) :::; c, Vl, ... ,Vm '" U[O,el, and Ul, .. ·,Um '" U[a,bl' We 
define 
, 
1 ~ 
I=(b-a)m~f(ui) 
-
1 I:
m 
and 
1= c(b - a)-
Iv <f(u)· 
m 
'1-_ 
'" 
i=l 
i=l 
b. Show that 
1= c(b - a)P(V :::; feU)) 
for U '" U[a,bl and V '" U[O,el' 
c. Deduce that JE[i] = I and var(i) :::; var(i). 
d. Discuss the relevance of the notion of a "best" importance function h. 
(Hint: Consider a sequence of normal distributions centered at the value 
of interest, i.e., at x* such that f(x*) = I and with variance decreasing 
to 0.) 
9.14* (Gilks and Wild, 1992) A general accept-reject simulation method is pro-
posed for log-concave densities on IR. The method is based on adaptive upper 
and lower bounds on the density which are updated after each simulation 
step. 
a. Given f(x) proportional to the density to be simulated, we assume there 
exist u(x) and R(x), upper and lower bounds on f(x) such that U is 
a density. The simulation algorithm is as follows: Generate x '" u(x) 

Exercises 361 
and U rv U[O,I], and accept x if U ::; £(x)/u(x) or if, otherwise, U ::; 
f (x) / u( x). If x is rejected, iterate the simulation. Show that this method 
actually produces a random variable with distribution f. 
b. The two bounding functions can be constructed automatically for f log-
concave as follows. For the first simulation, take three arbitrary values 
Xl, X2 > Xl, and X3 > X2 such that one at least is on each side of the 
mode of f. (Explain why this can be done without requiring an explicit 
derivation of the mode.) Show that the lower bound log£(x) on logf(x) 
can be derived by joining the three points (Xi, log f(Xi)) and £(x) to be 
o outside the interval [XI,X3]. The upper bound logu(x) is constructed 
by taking the complements of the segments used for log£(x) until they 
meet: the tails are thus made of the extensions of the chords (Xl, X2) and 
(X2, X3)j logu(x) is completed by adding the vertical lines going through 
Xl and X3 until they meet the two chords. 
c. Indicate a method to update the upper and lower bounds after each 
simulation requiring the computation of f(x). 
d. Show that the two functions u(x) and £(x) are piecewise exponential and 
indicate how one can simulate from distributions proportional to these 
functions. 
e. Illustrate the above algorithm for the simulation from a N(O, 1) distri-
bution. When does it stop to be interesting to improve the bounds, i.e., 
when does it become more time consuming to evaluate and simulate 
from a better upper bound? 
Section 9.2.3 
9.15 Justify the Laplace approximation when h(()) = (() -
{L)2 and b(()) is a 
polynomial of degree 2. What happens if b is of higher degree? Derive the 
general Laplace expansion by using Taylor series for band h. 
9.16* (Tierney et al., 1989) Deduce from the Laplace approximation that 
where 
A(K) = 17K exp{ -nhd [bK + 2~ {(j'ib'k 
hAll/bAI 
2 + 5 bA (hAI/I)2 
6 
1bA 
2 h(4)}] 
-
K K(jK 
12 K K 17K - 4: K(jK K 
and K = N, D, if hK 
h(eK), etc., and eK is minimizing hK. Deduce 
Lemma 9.1 under the assumption that hCf) - h~) = O(n-l) for i = 0, ... ,4 
and bD i- O. What happens if bD = O? 
9.17* (Tierney et al., 1989) If M(s) is the moment generating function of g(()) 
and M is the Laplace approximation of M for (9.12), with bN = bD = b > 0 
and 
hD(()) = {log[fxl())] + log[7r(())]-log[b(())]}/n, 
hN(()) = hD (()) - sg(())/n, we define 
lE(g) = M'(O). 

362 9. Bayesian Calculations 
a. Show that lE7r [g(B)lx] = lE(g) + O(n- 2 ). 
b. Let 0 be the minimum of hD, let Os be the minimum of hN, and let 
(J; = h~)(Bs). Show that 
A 
A did 
AI 
lE(g) = g(B) + ds log(Js s=o + ds logb(Bs) s=o' 
c. Deduce that 
2 AI/ 
4 hillA' 
2 b' 
A' 
lE(g) = 9 + (JDg _ (JD D9 + (JD A D9 
2n 
2n 
nbD 
and therefore that this method actually gives the approximation (9.11) 
for the standard form. 
9.18 In the setup of Example 9.7, choose the standard and fully exponential 
representations which lead to the proposed approximations. 
Section 9.3 
9.19* (Metropolis et al., 1953) The Metropolis algorithm can be used for simu-
lating from any density 7r(B) known up to a multiplicative factor. 
a. Show that this algorithm reduces to regular simulation from 7r when 
q( BIB') = 7r( B). 
b. Give the simplified version of the Metropolis algorithm when q(BIB') is 
symmetric in its arguments, i.e., when q(BIB') = q(B'IB). 
c. Show that 7r(B) is indeed a stationary distribution for this algorithm 
when the support of q contains the support of 7r. (Hint: Compute the 
probability distribution function of B(m+1) when B(m) '" 7r(B) by breaking 
up the integral into four parts and exchange the dummy variables Band 
.; in two of the four integrals.) 
d. In the particular case when 7r is a N(O, 1) distribution and q(BIB') is a 
N(B', (J2) distribution, study the probability of acceptance of'; in the 
mth step as a function of (J. What is the exact distribution of B(m)? 
Deduce the best choice of (J. 
9.20 (Robert, 1993a) Consider n observations Yl, ... ,Yn from a general logistic 
regression model with 
eXPWXi) 
P(Yi = 1) = 1 - P(Yi = 0) = 1 
(Bt)' 
+ exp 
Xi 
and Xi, BE llF. 
a. Show that, conditionally on the Xi'S, this distribution belongs to an 
exponential family and that l:i YiXi is a sufficient statistic. 
b. Give the general form of the conjugate prior distributions for this model 
and show that the normalization factor cannot be computed explicitly. 
Give an interpretation of the hyperparameters (';,.>..) of the conjugate 
prior in terms of previous observations. 
c. Show that the maximum likelihood estimator of B, 0, cannot be ob-
tained explicitly and that it satisfies the following implicit equations 
(j=l, ... ,p): 
(9.22) 

Exercises 363 
d. Approximate a conjugate distribution by the Metropolis algorithm. 
(Note: If a normal conditional distribution is used, attention should be 
paid to the variance factor.) 
e. Explain why (9.22) can be used to control the convergence of the al-
gorithm for some special values of the hyperparameter vector, (~, .>..), 
namely, those for which 
n 
i=l 
9.21 The data augmentation algorithm is based on the conditional distributions, 
11"(01'>") and 11"('>"10). As described in §9.3, it successively simulates from 11"(01'>") 
and from 11"('>"10). This exercise shows why such a simulation of 11"(0,.>..) is 
justified from a probabilistic point of view. 
a. Derive the joint distribution 11"(0,.>..) in terms of these conditional distri-
butions. 
b. Given two functions q(OI.>..) and 8('>"10), what is a necessary and sufficient 
condition for q and 8 to be proportional to conditional distributions? 
c. Consider the above questions in the case of n levels for the completed 
models, i.e., when conditional distributions are available for 0, '>"1, ... , 
'>"n-l. 
9.22* (Diebolt and Robert, 1994) Consider the two Markov chains (o(m») and 
(.>..(m») used in data augmentation with conditional distributions 11"1 (Olx, .>..) 
and 11"2 ('>"Ix, 0). 
a. Show that the respective transition kernels of these chains are 
K(O, 0') = 111"1(0Ix,'>")1I"2('>"lx, 0') d'>", 
H('>", .>..') = 1 
11"2 ('>"Ix, 0)11"1 (Olx, .>..') dO. 
b. Show that 1I"1(0Ix) and 1I"2(.>..lx) are indeed stationary for these kernels. 
c. Establish that, if o(m) rv 1I"1(0Ix, .>..(0») and .>..(m) rv 11"2 ('>"Ix, .>..(0»), 
111I"1(·lx, .>..(0») - 1I"1(·lx)lll :s: 111I"2(·lx, .>..(0») - 1I"2(·lx)lh. 
d. Derive Lemma 9.3 from c. and from the fact that irreducible Markov 
chains on compact spaces are ergodic. Show that, if (.>..(m») is geometri-
cally ergodic with rate (J, (o(m») is also converging with rate (J, i.e., 
e. The chain (.>..(m») is 'P-mixing ifthere exists 'P, geometrically decreasing, 
and a finite measure fL such that 
Show that, when (.>..(m») is 'P-mixing, 

364 9. Bayesian Calculations 
and deduce that, if A is compact, (o(m)) is also rp-mixing. 
f. Similarly, show that geometric convergence of (.>..(m)) and compact-
ness of A are sufficient to ensure that, for every function h satisfying 
IE"[llh(0)112Ix,.>..] < 00, there exists Ch such that 
II IE"?' [h(O)lx, .>..(0)]- IE"l [h(O)lx] 112 ::; Chfr. 
g. Take advantage of the fact that, when A is finite, the chain (.>..(m)) is 
necessarily geometrically converging and rp-mixing (Meyn and Tweedie, 
1993). Assess the importance of the above results in the setting of mix-
ture estimation. 
h. Extend the duality principle to the case of a hierarchical model with 
multiple levels, using the fact that conditional distributions only depend 
on the neighboring levels. 
9.23 Show that, in the setting of Example 9.8, the marginal distributions on 
o and'>" cannot be derived explicitly and that, moreover, the restriction 
B < +00 is necessary for the marginal distributions to be defined. 
9.24 Considering the multinomial model of Example 9.10, explain why simulat-
ing from 71"( (IL, 7]) Ix) rather than from 71"(lLlx) and 71"( 7]lx) should speed up 
convergence. 
9.25 Does the decomposition of the noncentral chi-squared distribution proposed 
in Example 9.11 allow for implementation of the Bayesian sampling? Give 
an approximation by the Metropolis algorithm. 
9.26 (Heitjan and Rubin, 1991) Coarse data are defined as an aggregation of the 
observations in classes. Given a "complete" random variable Yi ~ f(yIO), 
taking values in y, and a partition Aj (j E I) of y, the observations are 
Xi = j if Yi E A j . 
a. Give a real-life motivation for this model. 
b. Propose a Bayesian sampling algorithm in the case where j(·10) is a 
normaldistributionN(~,(T2)withO = (~,(T2) andAj = [j,j+1) (j E 7l). 
c. Frequencies of car passages during a one-minute period have been ob-
served for 360 consecutive minutes and the resulting observations are 
given in Table 9.2. 
TABLE 9.2. Frequencies of car passages for a sequence of one-minute intervals. 
Number of 
cars 
Number of 
occurrences 
o 
1 
2 
3 
139 
128 
55 
25 
4 or 
more 
13 
Assuming a Poisson P(O) distribution for this model, apply Bayesian 
sampling to estimate the parameter 0 for this data set and the prior 
71"(0) = I/O. 
9.27 (Rubin et al., 1992) A study was conducted on the campus of Cornell Uni-
versity to model the sexual behavior of undergraduates. Out of a population 

Exercises 365 
of Rm (Rf) male (female) undergraduates, rm (rf) answered the survey and 
tm (tf) were found to be sexually active (in the past two months). 
a. The first quantities of interest are Tf and T m, number of female and 
male undergraduates who were sexually active. Using an hypergeometric 
model on tm and tf and taking rm and rf as fixed, derive a Bayes 
estimator of Tf and T m when 
Pi '" Be( a, (3), 
7r(a, (3) = 1/a(3 
(i = I,m). 
(Numerical application: Rf = 5211, rf = 253, tf = 111, Rm = 6539, 
rm = 249 and tm = 22.) 
During the study, sexually active respondents were asked about the number 
of partners they had during the two last months, Yf and Ym, as well as the 
number of Cornell undergraduate partners, Xm and x f. 
b. Assuming a Poisson distribution P()..i) for the number of 'additional' 
partners Yi - 1 and a binomial distribution B(Yi, (h) on the number of 
Cornell undergraduate partners (i = I, m), with {!f = Tm/Nm and {!m = 
Tf / N f, derive a Bayes estimator of the population in sexual contact with 
the Cornell undergraduates, N m and Nf. The prior distributions are 
(!i '" Be(-y, 8), 
(Numerical application: Ym = 54, Xm = 31, Yf = 135, xf = 67.) 
c. Compare your results with the maximum likelihood estimators obtained 
in the study: Nf = 4186, N m = 1473, Tf = 2323 and Tm = 615. 
d. Repeat the estimation for the hyperpriors 
and 
9.28 Show that, in a Gibbs sampling algorithm, if an arbitrary simulation step, 
like the simulation from 7r( (}11(}2, ... , (}k) say, is replaced by a single step of 
a Metropolis algorithm, the validity of the algorithm is preserved. Discuss 
the interest of this property for practical issues. 
9.29* Given a density of interest, 7r, and an available density I such that 7r / I :::; 
M, samples from 7r can be produced either by accept/reject, (}i1), ... ,(}~1), 
. 
. 
(}(2) 
(2) 
. 
(3) 
(}(3) C 
by 1mportance samplmg, 1 , ... , (}n ,or by Metropoils, (}1 , ... , n . om-
pare the variances of 
n 
(2) 
.!. " 
7r( (}i 
) (}(2) 
n 6 
I((}(2)) i 
, 
~=1 
1. 
~ t(}?)· 
i=l 
(Note: p denotes the random number of observations produced after n iter-
ations of the accept/reject algorithm.) 
9.30 Two machines run in parallel with breakdown times x '" I(xl(}) and Y '" 
g(YI7J). The defective machine is supposed to be known when a breakdown 
occurs. 

366 9. Bayesian Calculations 
a. Give the distribution of z, breakdown time of the system, and derive a 
Gibbs sampling algorithm to get posterior estimators of 8 and TJ when a 
sample Zl, ... ,Zn is available. 
b. Implement this algorithm in the special cases when (a) f and 9 are 
normal densities with means 8 and TJ; and (b) f and 9 are exponential 
distributions with parameters 8 and TJ. 
9.31 Consider a distribution 7r(8l , 82 ) which is not available under closed form 
but such that the two conditional distributions 7r(8l I82 ) and 7r(82 18l ) are 
known and can be simulated from. 
a. Show that the Metropolis algorithm can be implemented. (Hint: Show 
that the only difficulty is to simulate from 7r(8l ) or from 7r(82 ) and use 
Exercise 9.21.) 
b. Deduce that in every setting Gibbs sampling can be used, the same 
applies to the general form of the Metropolis algorithm. 
9.32 Show that Gibbs sampling is a special case of the Metropolis algorithm 
where the acceptance probability is always equal to 1. 
9.33 Consider a probability distribution P and a function {! such that 0 :::; {!(x) :::; 
1 and JEP[1/ (!(x)] < 00. A Markov chain x(n) is derived as follows: Update 
x(n) into x(n+l) by generating y '" P and take 
with probability {!(x(n)), 
with probability 1 - (!(x(n)). 
a. Show that this variation of the Metropolis algorithm is converging to 
the stationary distribution with density 
with respect to P. 
b. Apply to the case when P is a Be(n + 1, 1) distribution and {!(x) = x. 
Section 9.4 
9.34 For a normal mixture, detail the reasoning leading to the conditional dis-
tributions (9.19) and (9.20) and give an explicit expression ofJE"[J.tilx,z]. 
9.35 For a small sample size, run several simulations to compare Bayesian sam-
pling with a direct computation of the Bayes estimator for a mixture of two 
normal distributions. 
9.36 Show that conjugate priors cannot lead to a noninformative answer in the 
case of a two-component normal mixture when the variances of the prior 
distributions go to 00. 
9.37 (Robert and Soubiran, 1993) Derive the formulas equivalent to (9.19) and 
(9.20) for a mixture of multidimensional normal distributions. (Hint: Use 
§4.3.1 for the choice of conjugate prior distributions and detail the simula-
tion of Wishart distributions.) 
9.38 (Binder, 1978) Consider a sample Xl, ... ,Xn from the mixture 
k 
x'" f(xI8) = Lpdi(X), 
i=l 

Exercises 367 
where the densities Ji and the weights Pi are known. The problem is to 
identify the origins of the observations, g = (gl, ... ,gn), with 
k 
gj = L iIzij=l 
i=l 
(1 ~ j ~ n). 
a. Show that calculation difficulties also occur in this setup for the compu-
tation of the Bayes estimators. 
b. Give the Bayes estimator of g when P '" V(1/2, ... ,1/2) and Ji(X) 
ip(x; /-ti, 1) with /-ti '" N(~i, 1). 
c. How can Bayesian sampling be implemented for this problem? 
9.39 Adapt the Bayesian sampling techniques developed in §9.4 in the case of a 
mixture of distributions to the case of a censored model, i.e., for observations 
Y; such that 
* _ {Yi 
Yt -
c 
if Yi ~ c, 
otherwise, 
and Yi '" J(yIO), with J('IO) belonging to an exponential family. 
9.40 (Robert et at., 1993) 
An hidden Markov model generalizes the mixture 
model studied in Example 9.5 and in §9.4 by introducing dependencies 
between the observations Xl, ... , Xt. When completing these observations 
by (unknown) missing state indicators Zi, the model becomes hierarchical 
(1 ~ i ~ t): 
and (Zi) constitutes a Markov chain on {1, ... , K} with transition matrix 
p = (Pjk), where 
(2 ~ i ~ t) 
(taking Zl = 1 for identifiability reasons). We also assume that f('10) belongs 
to an exponential family. 
a. Give the likelihood of this model and deduce that neither maximum 
likelihood, nor Bayesian estimation with conjugate priors on 0 and P 
can be derived explicitly in this case. 
b. Considering the particular case when f('10) is N(f", 0"2) with 0 = (f", 0"2), 
show that a Bayesian sampling implementation with iterative simula-
tions from 7r(Olx, z) and 7r(zlx,O) is quite time-consuming because of 
7r(zlx, 0). 
c. Show that the fully conditional distributions 7r(Zi lx, 0, Z#i) only depend 
on Zi-l and Zi+1 and are much easier to simulate. 
d. Propose a Gibbs sampling algorithm for this model. Show that the con-
dition Pkj > 0 for all 1 ~ j, k ~ K is sufficient to ensure geometric 
convergence of the chains (oem)) and (pem)) to the true posterior dis-
tributions. (Hint: Arguments similar to those of Exercise 9.22 can be 
used.) 
9.41 In the setup of logistic regression (see Exercise 9.20), a missing data struc-
ture can be exhibited and exploited by a Gibbs sampling algorithm. 
a. Derive the distribution of Zi such that the observation Yi is IZi~x;e· 

368 9. Bayesian Calculations 
b. Give the likelihood of the completed model and examine whether a Gibbs 
algorithm similar to those of §9.4 can be constructed in the special case 
0", N"p(p" E). 
c. Compare the performance of this algorithm with a more straightforward 
Metropolis algorithm of your choice. 
9.42 A probit model is a qualitative regression model where the dependency on 
the auxiliary variables is given by 
PO(Yi = 1) = 1 - PO(Yi = 0) = <P(OtXi)' 
a. Show that, as in Exercise 9.41, it is possible to complete the model by 
exhibiting a continuous latent variable Zi. 
b. Propose a Gibbs sampling algorithm based upon the completed data 
when 0 '" N"p(p" E). 
9.43 In a mixture setup, compare the performance (in terms of computing time) 
of a Gibbs sampling with those of a more straightforward Metropolis algo-
rithm. 
9.44 A truncated normal distribution N"p(O, Jp) restricted to the polygon of Xi :::; 
Zi (1 :::; i :::; n) is to be simulated. 
a. Give the distribution of OJ conditional on Ok (k =1= j) and derive a Gibbs 
implementation for the simulation of this truncated normal distribution. 
b. Propose a Metropolis alernative based upon aN"p(p" E) simulation, when 
p, and E are derived from the polygon boundaries. 
c. Compare both algorithms. 

10 
A Defense of the Bayesian Choice 
This book has exposed the main aspects of Bayesian inference in Statistics 
from a decision-theoretic point of view. The coverage is obviously anything 
but exhaustive: on one hand, the topics we consider are often treated in 
more detail in the references mentioned at various points. On the other 
hand, Bayesian analysis can be applied to many fields, among which are 
Econometrics (see Zellner (1971, 1984), Box and Tiao (1973), Maddala 
(1977), or Chow (1983)), Time Series (see West and Harrison, 1989), ap-
plied Statistics, but also in theoretical Statistics like sequential analysis (see 
Pilz, 1991). Moreover, it is not surprising to find Bayesian perspectives in 
fields where Statistics and prior information playa role: finance and insur-
ance, expert systems (Spiegelhalter and Cowell, 1992; Gilks et al., 1993), 
pattern recognition (Ripley, 1986), image processing (Geman and Geman, 
1984, Besag, 1986, Geman, 1988), neural networks (Ripley, 1992), numeri-
cal analysis (Diaconis, 1988, O'Hagan, 1992), chaos theory (Berliner, 1991, 
1992), etc. 
Nonetheless, it is important to consider Bayesian statistical analysis 
primarily from this theoretical and decisional perspective, before paying 
more attention to its potential for applications. First, this study exhibits the 
inherent coherence of the Bayesian approach in comparison with alternative 
classical theories. Second, to develop an efficient approach for the processing 
of applications requires a solid background on theoretical issues. We present, 
in this concluding chapter, a justification of the Bayesian approach which 
summarizes the various arguments advanced throughout the book. 

370 10. A Defense of the Bayesian Choice 
(1) Opting for a probabilistic representation 
To propose a distribution on the unknown parameters of a statisti-
cal model can be characterized as a probabilization of uncertainty, i.e., 
as an axiomatic reduction from the notion of unknown to the notion 
of random. This reduction being acceptable-and usually accepted by 
most statisticians~for sampling models, it should be acceptable as 
well for the parameters directing these models. For one thing, the dis-
tinction between sample and parameters is not always clearcut. Con-
sider, for instance, random effects models (Chapter 8) or allocation 
vectors in a mixture model (Chapter 9). More fundamentally, a prob-
abilistic model is most often nothing but an interpretation of a given 
phenomenon~as opposed to an explanation of this phenomenon. If 
we consider, for instance, econometric models, where the differences 
between the realizations of endogenous variables and their linear pre-
diction on exogenous variables are explained through a random per-
turbation, it is clear that the random nature of this difference is of 
little importance, as the experiment cannot be replicated. 1 Therefore, 
the representation of unknown phenomena by a probabilistic model, 
at the observation level as well as at the parameter level, does not 
need to correspond effectively~or physically~to a generation from a 
probability distribution nor does it require us to enter a supradeter-
ministic scheme, fundamentally because of the overall nonrepeatability 
of most experiments. The probabilistic representation of partially ex-
plained phenomena should be perceived mainly as a simplifying but 
efficient tool which conveys and quantitatively analyzes these phenom-
ena. This perspective is really similar to the way Physics can be seen as 
an interpretation of the world which is a tool, efficient enough to allow 
for a better understanding of this world (and incidentally for technical 
progress), while it does not need to correspond to a "truth" definitely 
unattainable. 2 
(2) Conditioning on the data 
The basis of statistical inference is fundamentally an inversion process, 
since it aims at deriving effects from causes by taking into account the 
probabilistic nature of the model and the influence of totally random 
(Le., unexplained) factors. In both its discrete and continuous versions, 
Bayes Theorem formalizes this inversion, as does the notion of the like-
lihood function £(Blx), substituted for the density f(xIB). The failure of 
fiducial Statistics to provide a satisfactory inferential system (see §1.2) 
can be attributed to a refusal to pursue this inversion to its logical con-
sequences and, relatedly, to a certain confusion between observations 
1 To put it bluntly, an arbitrary number can always be perceived as a single 
realization from an infinity of distributions! 
2 See also Popper (1983) for his alternative motivation of scientific modeling 
through the metaphysical realism he opposes to this instrumental approach. 

A Defense of the Bayesian Choice 371 
and random variables. From a probabilistic point of view, a quantita-
tive analysis on the parameters () which is operated conditionally on x 
strictly requires a corresponding distribution on the parameter (), 7f(()), 
in order to invert the probabilistic model. Taking this requirement into 
account, the Bayesian approach is thus the unique coherent paradigm 
which respects the inversion perspective. The practical problem of the 
determination of the prior distribution 7f does not take place in the 
same conceptual space (see point (ii) below). 
(3) Exhibiting the true likelihood 
In relation to points (1) and (2), note also that the prior modeling on 
the parameters of the model authorizes a complete quantitative infer-
ence on these parameters, therefore the effective determination of the 
likelihood of () conditional on the observation x. On the contrary, clas-
sical Statistics fail to attain this completeness. In particular, as long as 
() is taken to be an unknown but fixed quantity, the likelihood function 
f(()lx) cannot be considered as a density conditionally on x, despite 
the formal resemblance. This impossibility of the classical approach to 
provide quantitative conclusions is particularly well illustrated in the 
case of confidence regions and tests, where it proposes an inappropri-
ate problematic (and therefore an inappropriate answer). As we saw in 
Chapter 5, the classical procedure, whether a 95% interval or a p-value, 
derives its probabilistic nature from a frequentist interpretation. It is 
not the parameter () which belongs to an interval with probability 95% 
conditionally on x, but the interval derived from x which contains the 
fixed value () with probability 0.95. Again, the nonrepeatability of most 
practical experiments comes to question this frequentist point of view 
(see also point (9)). 
(4) Using priors as tools and summaries 
The choice of a prior distribution 7f does not require any kind of be-
lief in this distribution. It is actually quite rare to have a completely 
specified prior distribution, the original example of Thomas Bayes 
being paradoxically an exceptional counterexample where a physical 
knowledge of the experiment leads to the construction of the prior dis-
tribution. In general, 7f should rather be considered either as a tool 
which provides a single inferential procedure with acceptable frequen-
tist properties (see points (6) and (8)) or as a way to summarize the 
available prior information and the uncertainty surrounding this in-
formation. That Bayesian analysis can be extended to noninformative 
settings-with a few exceptions, like some testing situations-is ac-
tually an indicator of this polyvalence. Moreover, the fact that many 
usual estimators can be recovered through a noninformative modeling 
signifies that the use of a prior distribution does not necessarily intro-
duce a bias in the statistical process but, on the contrary, authorizes 
in addition the quantitative treatment already mentioned in point (3). 

372 10. A Defense of the Bayesian Choice 
These "coincidences" actually enhance the superiority of the Bayesian 
approach, since it provides at once a full inferential treatment around 
these classical estimators. 
(5) Recognizing the subjective basis of knowledge 
From a philosophical point of view, it is generally agreed that knowl-
edge stems from a confrontation between a prioris and experiments. 
For instance, according to Kant, although knowledge starts with ex-
perimenting, it does not follow that knowledge is entirely derived from 
experimenting. In fact, without a prioris, i.e., without a preestablished 
structure of the world, observation (or praxis) is meaningless, as it does 
not come as a support to or as a confrontation of a referential model. 
Therefore, the building of knowledge through experiments implies the 
existence of a prior representation system, which is very primitive at 
the beginning but is progressively actualized via these experiments. 
From this perspective, learning can be expressed as the critical exam-
ination of preexistent exterior systems subjected to experiments with 
respect to this overall referential representation of the world. This point 
of view is also adopted by Poincare (1902): 
It is often stated that one should experiment without pre-
conceived ideas. This is simply impossible; not only would it 
make every experiment sterile, but even if we were ready to 
do so, we could not implement this principle. Everyone stands 
by his own conception of the world which he cannot get rid 
of so easily. 
The Bayesian approach is obviously in accordance with this perspective 
since prior distributions are most often based on the results of previous 
experiments. Actually, even the subjective aspect of the choice of the 
prior distribution can be integrated in this theory of knowledge, since 
it implies that every acquisition of knowledge is essentially subjective, 
resulting from an interaction between the individual perceptions and 
the exterior reality.3 In his epistemological theory, Feyerabend (1975) 
also stresses that individualism (i.e., subjectivity) is an important but 
blatantly ignored factor in scientific discoveries. Although opposed to 
this subjectivist approach of knowledge, Popper (1983) also recognizes 
the role of prior intuitions (or systems), not always grounded on ex-
periments, in the history of sciences-the most striking example being, 
from his point of view, atomism, i.e., the representation of matter as 
constituted by atoms, which it took more than twenty centuries to 
ascertain experimentally. 
(6) Choosing a coherent and unique inference systematically 
The ultimate goal of Statistics is, arguably, to provide an inference 
3 In fact, Bayesian Statistics could answer this wish of Kant: "Philosophy needs 
a science able to determine the possibility, the principles and the scope of 
our whole prior knowledge" (Criticism of Pure Reason, Introduction, Garnier-
Flammarion, Paris). 

A Defense of the Bayesian Choice 373 
about a parameter B given some observations x related to B through 
a probability distribution f(xIB). Moreover, it seems only natural to 
seek efficiency (or optimality) in this inference, the notion of optimal-
ity being defined explicitly by the statistician (or the decision maker). 
To force inference into a decision-theoretic mold through the choice 
of a loss function allows for a clarification of the way inferential tools 
should be evaluated, therefore implies a conscious (although subjec-
tive) choice of the retained optimality. In addition, when the decision-
theoretic framework is completed by the choice of a prior distribu-
tion, the above inferential goals are automatically satisfied since the 
Bayesian approach usually leads to a unique procedure, depending on 
the requested properties and the prior knowledge. Obviously, unique-
ness of the decision procedure is not a sufficient validation per se since 
many obnoxious although unique procedures can be proposed instantly. 
The important feature of a Bayesian approach is thus that Bayes es-
timators are derived via an eminently logical process: Starting from 
requested properties, summarized in the loss function and the prior 
distribution, the Bayesian paradigm derives the best solution satisfy-
ing these properties. On the contrary, classical procedures are ad hoc 
in the sense that they start from an "arbitrary" estimator (maximum 
likelihood estimator, least squares estimator, etc.) and then examine 
its frequentist properties, not necessarily in a decision-theoretic setup 
and with no pretense at a global optimality, as shown by the Stein 
effect. In other cases, classical approaches also set up a criterion for 
the choice of an estimator (best unbiased estimator, best equivariant 
estimator, uniformly most powerful test, etc.) but they cannot provide 
a universal method, i.e., an algorithm, for the derivation of optimal 
estimators (see also point (10)) and it is even sometimes necessary to 
restrain further the class of considered estimators as, for instance, in 
the case of the uniformly most powerful unbiased tests. This opposition 
in the logical foundations of the two theories reinforces the coherence 
of the Bayesian approach, since it is the only one-when incorporating 
the case of the best equivariant estimators as a Bayesian estimation 
method under the invariant Haar measure---to provide an universal 
and implementable process which stems from inferential requirements. 
(7) Implementing the Likelihood Principle in practice 
The Likelihood Principle is, as shown in Chapter 1, based on the 
quite logical Sufficiency and Conditionality Principles. Therefore, it 
should always direct the choice of estimation procedures, adding a de-
sirable property to those already discussed in point (6). The Bayesian 
paradigm provides an implementation technique for this principle, 
since it allows for the derivation of decisions compatible with these dif-
ferent requirements. Moreover, while formally incorporating the maxi-
mum likelihood estimation method as a particular case (for 7r(B) = 1), 
the Bayesian approach can also avoid some likelihood paradoxes like 

374 10. A Defense of the Bayesian Choice 
those presented in §4.1 by using the Jeffreys noninformative distri-
butions even though these priors are not entirely compatible with 
the Likelihood Principle. An additional important advantage of the 
Bayesian approach, compared with the maximum likelihood method, 
is that it can also incorporate the requirements of a loss function and 
thus enter into the framework of Decision Theory while being accept-
able for the Likelihood Principle. 
(8) Looking for optimal frequentist procedures 
From the point of view of frequentist theory, the most convincing argu-
ment in favor of the Bayesian approach is that it intersects widely with 
the three notions of classical optimality, namely, minimaxity, admissi-
bility and equivariance. We indeed saw in Chapters 2, 6 and 7 that 
most estimators which are optimal according to one of these criteria 
are Bayes estimators or limits of Bayes estimators (the notion of limit 
depending on the context). Thus, not only is it possible to produce 
Bayes estimators which satisfy one, two, or three of the optimality 
criteria, but, more importantly, the Bayes estimators are essentially 
the only ones to achieve this aim. Therefore, a frequentist statistician 
may be opposed to any subjective input in his/her inferential treat-
ment and still remain in agreement with his/her paradigm by using 
only Bayes or generalized Bayes estimators, since most of them behave 
satisfactorily.4 Moreover, these estimators are easy to derive, compared 
with the choice of an ad hoc estimator and the subsequent verification 
that it is actually a limit of Bayes estimators. From this point of view, 
prior distributions are again considered as an inferential tool, not as an 
exhaustive summary of the prior information, but their shape and their 
posterior uses obviously remain the same. The optimality of the Bayes 
procedures also holds for asymptotic criteria since, under the condi-
tions ensuring efficiency of the maximum likelihood estimator, most 
Bayes estimators are asymptotically efficient and become equivalent 
to the maximum likelihood estimator as the sample size increases (see 
Lehmann (1983) and Ibragimov and Has'minskii (1982)), even though 
this type of optimality is less important from our point of view. 
(9) Solving the actual problem 
It is also necessary to provide an alternative to the frequentist approach 
from a pmctical point of view. In fact, frequentist methods are justi-
fied on a long-term basis: For instance, a confidence interval at level 
95% used for many independent problems will have a success rate close 
to 95%, which is satisfactory for the statistician. On the contrary, for 
a decision maker ("the client"), these long-term properties have little 
4 In this regard, note that the frequentist pretensions to objectivity (as opposed 
to the Bayesian inherent subjectivity) are actually quite limited. In fact, it 
is necessary to select the estimators to be compared and the choice of these 
estimators is partially subjective. 

A Defense of the Bayesian Choice 375 
appeal since he/she is interested by the performances of the proposed 
procedure for the problem at hand. For instance, the fact that a drug 
is successful 99% of the time is not directly interesting for a particular 
patient, compared with his/her chances of recovery! This request ob-
viously calls for an inference which is conditional on x and thus brings 
us back to the Bayesian approach (see point (2)). This argument does 
not seem to apply to statistical setups which involve repeated experi-
ments where the decision is taken by the same individual, as in quality 
control. But such setups may also justify a Bayesian implementation 
since they are most likely to allow the experimenter to borrow strength 
from previous studies through a prior distribution. 
(10) Computing procedures as a minimization problem 
An important point in favor of the Bayesian choice is that the Bayesian 
procedures are easier to compute than in alternative theories. This as-
sertion may appear paradoxical when considering the developments 
of Chapters 8 and 9 and, for instance, the difficulties encountered in 
the treatment of finite mixtures; more generally, we also saw that the 
Bayes estimators are seldom derived in closed forms, except in the 
rather special case of conjugate distributions. However, an additional 
appeal of the Bayesian approach is to provide an universal method for 
the computation of Bayes estimators, whatever the loss and the distri-
bution of the observations are, which is to minimize the posterior loss, 
even if this minimization requires a call to numerical algorithms. On 
the contrary, the frequentist theory does not provide any indication, 
even partial, for the derivation of minimax or admissible estimators, 
except to use a Bayesian approach through least favorable priors or 
proper distributions.5 Similarly, the only procedure providing a gen-
eral derivation of best equivariant estimators is to use Haar measures 
and the corresponding Bayesian representation, as shown in Chapter 
7. From another point of view, maximum likelihood estimators also 
proceed from a general optimization program but their derivation can 
get quite complicated and, more importantly, this method does not 
provide a complete inferential scope. Moreover, the Bayes estimators 
allow for integral representations under usual losses while the maxi-
mum likelihood method does not necessarily lead to an estimator. For 
instance, this is the case for normal mixtures, where the likelihood is 
not bounded, or in settings where there are several maxima of the like-
lihood function. From a pragmatic and computational point of view, 
it can be argued that the effective calculation of the Bayes estimators 
is often more delicate since it usually involves multiple integrations. 
5 Although they both minimize losses, the main difference between the two ap-
proaches is that, for the frequentist approach, the minimization is done on a 
functional space--the space of estimators-while the Bayesian approach oper-
ates the minimization on a decision space--the space of estimates. The respec-
tive complexities of these two spaces are generally considerably different. 

376 10. A Defense of the Bayesian Choice 
While being actually of major concern, this type of drawback takes 
place at a "material" level, in the sense that it should progressively 
disappear as computation methods evolve and improve. This type of 
difficulty is indeed of another order of magnitude, although the opening 
provided by Markov Chain Monte Carlo methods and the subsequent 
derivation of Bayesian solutions in many new domains show that com-
putational issues may be an important slowing factor. Nevertheless, 
what really matters is that there exists a unique process leading to 
the Bayes estimator, whatever the inferential problem, the loss and 
the prior distribution. This perspective definitely singles out Bayesian 
analysis. 
The reader still skeptical about the advantages of a Bayesian approach 
is referred to the books mentioned in the previous chapters for additional 
arguments, in particular, to Jeffreys (1961), Lindley (1971), Berger (1985a, 
§4.1 and §4.12), and Berger and Wolpert (1988). Smith (1984) also provides 
a similar list of motivations for the choice of the Bayesian paradigm. 
For the sake of objectivity (!), we should also present a symmetric list 
of criticisms of the Bayesian approach by the alternative statistical per-
spectives. However, we consider that none of these attacks exhibits strong 
incoherencies of the Bayesian paradigm.6 Therefore, we will only consider 
below three issues about the prior distributions, which are the essential 
basis of the Bayesian paradigm and the focus of most criticisms. 
(i) 
The passage from prior information, which can be vague or ill-defined, 
to the posterior distribution is not explained by the Bayesian paradigm. 
A partial although superficial answer to this point would be that a 
similar criticism applies to the sampling distribution, which is always 
assumed to be known exactly. In many cases, and in most theories, 
modeling strongly influences the further developments of the analysis, 
but it cannot be formalized as precisely as these subsequent steps. The 
diversity of information sources, the various degrees of precision of this 
information and the assessment of the consequences of the prior distri-
bution selection keep modeling closer to an art than to a well-mastered 
technique. More fundamentally though, we saw in §3.1 that some co-
herence axioms on the prior likelihood ordering justify the existence 
of a prior distribution, even though it may be on a cruder a-algebra 
than expected. From a practical point of view, the development of a 
prior distribution relies on the ability of individuals to represent their 
knowledge and the limitations of this knowledge in terms of probabil-
ities. That individuals are not presently able to do so does not imply 
that they will never be able to assess probability distributions, nor 
that they should not be trained toward this goal. In fact, a proper 
6 Note, however, that Diaconis and Freedman (1986) have shown that some Bayes 
estimators are suboptimal from an asymptotic point of view (in terms of con-
sistency and efficiency). 

A Defense of the Bayesian Choice 377 
formation could get us closer to this aim, in the same sense that social 
evolution has allowed the majority of individuals to deal constantly 
with figures. (See also Smith, 1988.) Another point is that Bayesian 
analysis provides, in addition, some tools to deal with imprecisions on 
the prior distribution, through robustness and hierarchical analyses. 
The important aspect of the partial arbitrariness associated with the 
choice of a prior distribution is the influence of the prior information 
modeling on the resulting inference. In fact, many different modelings 
can provide very similar inferences. When discrepancies occur, it is 
necessary to assess more thoroughly the influence of the choice of the 
prior by a sensitivity analysis, in order to expose the influential factors 
of the prior modeling, instead of rejecting the available information. 
This very exposition of the influential factors is actually an additional 
advantage of a Bayesian analysis (see below). 
(ii) Subjectivity is nothing but a pretext for all kinds of abductions, includ-
ing the choice of the most advantageous procedures. 
Again, a similar criticism could be addressed to frequentist methods 
about the choice of the loss or of the estimator to be studied; for in-
stance, Brown (1980) shows that, for every dimension Po, there exists a 
loss function such that the Stein effect occurs only when the dimension 
of the problem is larger than Po (see §2.4.6). Nonetheless, the above 
remark is justified since the recourse to an additional factor in the 
inferential model can always be diverted and misappropriated. Dirac 
masses as prior distributions are a naive and straightforward illustra-
tion of such a danger, but there also exist more subtle devices to direct 
inference at will. This is unfortunately the price we have to pay for 
greater freedom and superior power of adaptivity, but an implicit re-
quirement of the Bayesian paradigm is, however, that the choice of the 
prior distribution must be justifiable (or testable) in the sense that the 
statistician must be able to account for the passage from prior infor-
mation to prior distribution-even if the justification is partially based 
on computational simplicity. This possibility of a verification is quite 
similar to the imperative of the repeatability of the experiments in other 
fields and is not directly present in alternative statistical approaches 
where there is an inherent ambiguity about the choice of an estimation 
procedure, for instance, between the maximum likelihood estimator 
and the least squares estimator. It can actually be argued the opposite 
way, namely, that the Bayesian approach is essentially more objective 
than other inferential methods because, first, it separates the different 
subjective inputs of the inferential process (sample distribution, prior, 
loss function), thus leaving ground for possible modifications, and, sec-
ond, it develops in addition objective tools to assess the influence of 
the prior distribution (noninformative distributions, sensitivity analy-
sis, etc.). In this regard, Poincare (1902) brings an additional argument 
following the quotation provided in point (5): 

378 10. A Defense of the Bayesian Choice 
We have, for one thing, to use a language and our language 
is entirely constituted of preconceived ideas and has to be so. 
However, these are unconscious preconceived ideas, which are 
a million times more dangerous than the other ones. Were we 
to assert that if we are including other preconceived ideas, 
consciously stated, we would aggravate the evil! I do not be-
lieve so: I rather maintain that they would balance one an-
other. 
The Stopping Rule Principle illustrates this objectivity, since the 
Bayesian decision is independent of the stopping criterion, therefore 
is not influenced by the subjective motivations which led to the re-
sulting sample size. Again, in a frequentist framework, the choice of 
the statistical model and of the loss function are equally determining 
factors which are usually overlooked. 7 
(iii) In a completely noninformative setting, the choice of the so-called non-
informative prior has no justification whatsoever and only stands as a 
pretext for an extension of the Bayesian scope. 
Although we see no harm in extending the Bayesian scope, points (1), 
(2), (3), (4), and (6) partially address this issue. In fact, in a non-
informative setup, while the prior distribution cannot correspond to 
a modeling of the prior information, it can still be perceived as an 
efficient inferential tool. 8 In this sense, noninformative Bayesian meth-
ods are not more ad hoc than the maximum likelihood method, since 
they all stem from the distribution of the observations which repre-
sents the only available information. If a loss function is also provided 
by the decision maker, it constitutes an additional piece of informa-
tion and the Bayesian approach can make good use of it, contrary to 
the maximum likelihood method. Furthermore, since these methods 
often provide the usual estimators, they cannot be rejected on the sole 
grounds that they are Bayesian! A Bayesian rebuttal would be on the 
opposite that the acceptable properties of these estimators are due to 
their Bayesian justification (see Jaynes, 1980). Last, we insist in most 
of the above points on the necessity of conditioning on x. This condi-
tioning necessarily implies a probabilistic modeling of () through a prior 
distribution 7f(()), since the maximum likelihood approach cannot pro-
vide a complete statistical inference and does not usually function as 
an "objective" distribution on (). The Jeffreys method thus appears 
as a technique which takes advantage of the information of the model 
(Le., of the information brought by x about ()), while retaining the 
richness of the Bayesian approach and the compatibility with intuitive 
requirements such as invariance, and including most of the usual sta-
7 Good (1973) calls this attitude SWUC for "sweep under the carpet"! 
8 The above criticism proceeds from an argument which rejects the use of the 
prior information except when it is unavailable! 

A Defense of the Bayesian Choice 379 
tistical procedures. The necessity of this approach is made quite clear 
in testing theory where the Neyman-Pearson approach has been seen 
to be suboptimal from several perspectives. While there are some tech-
nical difficulties in the treatment of the nuisance parameters (as in the 
marginalization paradoxes in §3.4), the reference prior generalization 
of Bernardo (1979) brings a partial solution to this problem. The other 
difficulty mentioned in this book, namely, mixture estimation as pre-
sented in Chapter 9, is more delicate but is fundamentally linked with 
an identifiability problem, the maximum likelihood estimator being also 
undetermined in this case. 
A positive aspect of such criticisms is that they point out the necessity 
for Bayesians to build up rigorously the prior distribution, to strengthen 
noninformative techniques, for instance, by taking advantage of the infor-
mation contained in the loss function. They also push toward a faster de-
velopment of "automatic" (or semiautomatic) techniques of determination 
of the prior distribution for a more widespread use of Bayesian methods 
in Applied Statistics. Bayesian softwares are already available in this area 
(see, for instance, the surveys of Goel (1988) or Press (1989)). In connection 
with the approximation techniques presented in Chapter 9 and developing 
robustness methods, such techniques should improve the penetration of 
the Bayesian paradigm to a wider audience by simplifying the access to 
Bayesian methodology. The current explosion of applied Bayesian studies 
is a sure indicator that this Bayesian expansion is under way. 
Let us conclude this book with a moderating note. External observers 
may get perplexed and even weary of the continual bickering between 
Bayesians and frequentists. Recent developments of Decision Theory have 
reinforced the Bayesian foundations of the frequentist optimality notions 
(see (6)), while the latest works in the Bayesian robustness area have been 
aiming at reducing prior misspecification errors by taking into account these 
frequentist criteria (like minimaxity or Bayes minimaxityas in Kempthorne 
(1988)). In practice, it is also often necessary to call for frequentist ap-
proximations when the complete elicitation of a prior distribution gets too 
complicated, for instance, when the Fisher information is not available in 
a closed form or when the number of parameters is too large. The various 
developments of the empirical Bayes techniques provide a rather convinc-
ing illustration9 of the need for an 'interface' between the Bayesian and 
the frequentist approach (as shown, for instance, by Hui and Berger, 1983). 
Our overall choice of the Bayesian side is thus based on the reconciliation 
9 However, let us remind the reader of the dangers of an empirical Bayes analy-
sis where unavoidable resorts to ad hoc manipulations mar its credibility. The 
approximation of a genuine Bayesian analysis provided by the empirical Bayes 
methods is only partial but gives the illusion of providing a "true" alternative 
prior distribution. The suboptimality of the resulting empirical Bayes estima-
tors (see Chapter 8) emphasizes the fundamental differences between the two 
approaches. 

380 10. A Defense of the Bayesian Choice 
of most classical procedures with a Bayes or generalized Bayes analysis, on 
the strong appeal of its completeness and its global coherence and also on 
its ability to push further the inferential process, not on a categorical rejec-
tion of all classical procedures. This Bayesian choice really stemmed from 
the progressive realization that the Bayesian approach was indeed more ap-
propriate and efficient to deal with inferential problems, while being more 
attractive from an intellectual point of view. 

Appendix A 
Usual Probability Distributions 
We recall here the density and the two first moments of most of the distri-
butions used in this book. An exhaustive review of probability distributions 
is provided by Johnson and Kotz (1969-1972). The densities are given with 
respect to the Lebesgue or the counting measure depending on the context. 
A.I. Normal Distribution, Np((), E) 
(B E IRP and E is a (p x p) symmetric positive-definite matrix.) 
f(xIB, E) = (det E)-1/2(27l')-p/2e-(x-O)tL'-1(x-O)/2. 
IEO,L'[x] = Band IEO,L' [(x - B)(x - B)t] = E. 
When E is not definite, the Np(B, E) distribution has no density with re-
spect to the Lebesgue measure on IRP. For p = 1, the log-normal distribution 
is defined as the distribution of eX when x rv N(B, (}2). 
A.2. Gamma Distribution, Q( 0, (3) 
(ct, (3 > 0.) 
f( I (3) -
(3CX 
cx-I -(3x:n: 
( ) 
x ct, 
- r(ct) x 
e 
[O,+oo[ x . 

382 
Appendix A 
IE",,!3[x] = 0.//3 and var",,!3(x) = 0.//32. 
Particular cases of the gamma distribution are the Erlang distribution, 
g(a, 1), the exponential distribution g(l, /3) (denoted exp(/3)), and the chi-
squared distribution, g(v/2, 1/2), (denoted X~). 
A.3. Beta Distribution, Be( ll, (3) 
(0.,/3>0.) 
x",-l(l - x)!3-1 
f(xla,/3) = 
B(a,/3) 
I[O,lj(X) 
where 
B( 
/3) = r(a)r(/3) 
a, 
r(a + /3) . 
IE",,!3[x] = 0./(0. + /3) and var",,!3(x) = 0./3/[(0. + /3)2(0. + /3 + 1)]. 
The Beta distribution can be obtained as the distribution of yt/(Yl + Y2) 
when Yl rv g(a, 1) and Y2 rv g(/3, 1). 
A.4. Student's t-Distribution, Tp(v, (), E) 
(v > 0, () E lRP, and E is a (p x p) symmetric positive-definite matrix.) 
f( I () E) = r«v + p)/2)/ r(v /2) [1 
(x - ())t E-1(x - ())] -(V+p)/2 
xv, , 
(detE)1/2(V7r)p/2 
+ 
v 
IEv,e,.dx] = () (v> 0) and IEe,.d(x - ())(x - ())t] = vE/(v - 2) (v> 2). 
When p = 1, a particular case of Student's t-distribution is the Cauchy 
distribution, C«(), (12), which corresponds to v = 1. Student's t-distribution 
can be derived as the distribution of x/ z when x rv Np «(), E) and vz2 rv X~. 
A.5. Fisher's F-Distribution, F(v, p) 
(v,p> 0.) 
r«v + p)/2)vp/2pv/2 
x(v-2)/2 
f(xlv, p) = 
r(v /2)r(p/2) 
(v + pX)(V+P)/2 1[O,+OO[(x). 
IEv,p[x] = p/(p-2) (p> 2) and varv,p(x) = 2p2(v+p-2)/[v(p-4)(p-2)2] 
(p> 4). 

Usual Probability Distributions 
383 
The distribution F(p, q) is also the distribution of (x - O)t 17-1 (x - O)/p 
when x '" Tp(q, 0, E). Moreover, if x'" F(v, p), px/(v + px) '" Be(v, p). 
A.5. Inverse Gamma Distribution, IQ(a, {3) 
(a, (3 > 0.) 
(301 e-(3/x 
f(xla,{3) = F(a) xOl+l I[o,+oo[(x). 
IEOI,(3[x] = a/{3 and varOl,(3(x) = a/{32. 
This distribution is the distribution of x-I when x '" Q(a,{3). 
A.7. Noncentral Chi-Squared Distribution, X~(A) 
(,X 2: 0.) 
f(xl'x) = ~ (x/ ,X)(p-2)/4 I(p-2)/2( V:X;)e-(>.+x)/2. 
IE>.[x] = p +,X and var>.(x) = 3p + 4,X. 
This distribution can be derived as the distribution of x~ + ... + x~ when 
Xi'" N(Oi, 1) and O~ + ... + O~ = ,X. 
A.B. Dirichlet Distribution, Dk(Ol, ... ,Ok) 
f( I 
) 
F(ao) 
011-1 
OIk-lI 
x al, ... , ak = F(at} ... F(ak) Xl 
... Xk 
{Lx;=l}· 
IEOI[Xi] = ai/ao, var(Xi) = (ao -
ai)ai/[a~(ao + 1)] and COV(Xi,Xj) = 
-aiaj/[a~(ao + 1)] (i # j). 
As a particular case, note that (x,l - x) '" 1)2 ( aI, (2) is equivalent to 
x'" Be(al, (2). 
A.9. Pareto Distribution, Pa( 0, xo) 
(a > 0 and Xo > 0.) 

384 
Appendix A 
xCt 
f(xlo:, xo) = 0: XCt~l I[xo,+oo[(x). 
lECt,xo[xJ = o:xo/(o: - 1) (0: > 1) and varCt,xo(x) = o:x~/[(o: - 1)2(0: - 2)J 
(0: > 2). 
A.10. Binomial Distribution, B(n,p) 
(0:::; P :::; 1.) 
f(xlp) = (:)pX(I_ p)n-xI{o, ... ,n}(x). 
lEp(x) = np and var(x) = np(1 - p). 
A.ll. Multinomial Distribution, Mk(niPl, ... ,Pk) 
(Pi 2: 0 (1 :::; i :::; k) and 2:iPi = 1.) 
lEp(Xi) = npi, var(xi) = npi(l- Pi), and COV(Xi,Xj) = -npiPj (i =f j). 
Note that, if x rv Mk(n;Pl, ... ,Pk), Xi rv B(n,Pi), and that the binomial 
distribution x rv B(n,p) corresponds to (x,n - x) rv M 2(n;p, 1- p). 
A.12. Poisson Distribution, P(A.) 
(,x> 0.) 
A.13. Negative Binomial Distribution, Neg(n,p) 
(o:::;p:::;1.) 
f(xlp) = ( 
x 
l)pn(1 - p)XIN(x). 
n+x+ 
lEp[xJ = n(l- p)/p and varp(x) = n(l- p)/p2. 

Usual Probability Distributions 
385 
A.14. Hypergeometric Distribution, 1iyp(N; n;p) 
(0:::; P:::; 1, n < Nand pN E IN.) 
(P;) ((l;;~~N) 
f(xlp) = 
(~) 
I{n-(l-p)N, ... ,pN}(x)I{o,l, ... ,n}(x). 
JEN,n,p[x] = np and varN,n,p(X) = (N - n)np(l - p)/(N - 1). 

Appendix B 
Usual Pseudorandom Generators 
This appendix provides some pseudo-random generators for the usual prob-
ability distribution. They can be of use in the implementation of the Monte 
Carlo techniques described in Chapter 9. Additional details about their 
performances, their limitations, and their justification are given in Devroye 
(1985) and Ripley (1987). Note that the algorithms given here should not 
be used blindly: for extreme values of the parameters or extreme simula-
tion needs, their efficiency decreases rapidly. In fact, when pseudorandom 
generators are already available on the machine (e.g., in Gauss, S-Plus, or 
Mathematica) , they are reliable enough to be used directly. 
The algorithms below all rely on the generation of uniform random 
variables on [0,1] and the uniform generator proposed in Ripley (1987) is 
the following congruencial method: 
- Start with an initial arbitrary seed xa 
- Iterate 
Xi = (69069xi-l + 1) mod 232 , 
ui = 2-32Xi. 
The sequence of the Ui can then be considered to be Li.d. U[a,l]' 
Marsaglia and Zaman (1993) have developed a simple uniform generator 
with multiple seeds whose period is larger than 295 . 

388 
Appendix B 
B.l. Normal Distribution, N(O, 1) 
The Box-Muller method (1958) provides two independent normal observa-
tions out of two uniform random variables. 
1. Generate UI , U2 • 
2. Take 
Xl = v' -2 log UI cos(27fU2 ) , 
X2 = v' -2 log UI sin(27fU2 ). 
B.2. Exponential Distribution, £Xp(A) 
1. Generate U. 
2. Take X = -log(U)/..\. 
This generator can also be used for the geometric distribution Qeo(p) since, 
if X rv Qeo(p), P(x = r) = P(r ::; E < r + 1), with E rv [xp( -log(l - p)). 
3. Student's t-Distribution, T(v, 0,1) 
Kinderman et al. (1977) provide an alternative to the generation of a normal 
random variable and a chi-square random variable. 
1. Generate UI , U2 • 
2. If UI < 0.5, x = 1/(4UI -1) and v = X- 2U2 ; 
otherwise, x = 4UI - 3 and v = U2 • 
3. If v<1-(lxl/2) or v«1+(x2/v))-(v+I)/2, take x; 
otherwise, repeat. 
B.4. Gamma Distribution, Q(a, 1) 
The simulation methods differ according to the value of a (note that the 
scale factor (3 can be assumed to be 1). When a > 1, the Cheng and Feast 
algorithm (1979) is: 
O. Define cI=a-1, c2=(a-(1/6a))/cI, c3=2/CI, c4=1+c3 
and c5 = 1/ va . 
1. Repeat 
generate UI , U2 and take UI 

Usual Pseudorandom Generators 
389 
a> 2.5 
until 0 < U1 < 1. 
2. W=C2U2/Ul. 
3. If C3Ul + W + W- 1 :::; C4 or c3logUl -logW + W :::; 1, take 
c1W; 
otherwise, repeat. 
If a is very large (a > 50), it is better to use a normal approximation based 
on the Central Limit Theorem. 
When a < 1, a possible algorithm is: 
1. Generate U and y""' 9(a + 1,1). 
2. Take yU1/o:. 
Ahrens and Dieter (1974) propose the following alternative: 
1. Generate Uo, U1 • 
2. If Uo>e/(e+a), x=-log{(a+e)(1-Uo)/ae} and y=xo:- 1 ; 
otherwise, x = {(a + e)Uo/ep/o: and y = e-x • 
3. If U1 < y, take x; 
otherwise, repeat. 
The beta, Fisher, and chi-squared distributions can also be simulated 
using these algorithms since they can be derived from the gamma distribu-
tion by elementary transformations (see Appendix A). Ahrens and Dieter 
(1974) and Schmeiser and Shalaby (1980) provide alternative algorithms. 
B.5. Binomial Distribution, B( n, p) 
When n is reasonably small (n :::; 30), an elementary algorithm is to generate 
n uniform random variables and to count those less than p. For large n's, 
Knuth (1981) provides an alternative algorithm. 
O. Def ine k = n, () = p and x = O. 
1. Repeat 
i = [1 + k()] 
v""' Be(i, k + 1 - i) 
if () > v, () = () / v and k = i-I ; 
otherwise, x = x+i, () = (()-v)/(l-v) and k = k-i 
until k:::; K. 
2. For i=1,2, ... ,k, 
generate Ui 
if Ui<p, x=x+1. 
3. Take x. 

390 
Appendix B 
The constant K can be chosen as a function of n in order to increase the 
efficiency of the algorithm. 
B.6. Poisson Distribution, P(A) 
Again, if"\ is reasonably small (..\ < 30), a simple algorithm is to generate 
uniform variables, in relation with the Poisson process: 
O. p=1, N=O, c=e-A • 
1. Repeat 
generate Ui 
p=pUi , N=N+1 
until p < c. 
3. Take x = N - 1. 
For large ..\'s, Atkinson (1979) proposes a more efficient alternative. 
O. Define c=0.767-(3.36/..\), ,8=71"(3..\)-1/2, 0.=,8..\, k=logc-
..\ -log,8. 
1. Repeat 
generate U1 
x = [a. -log((1- Ud/U1)l/,8 
until x> -1/2. 
2. Generate U2 • 
3. N= [x+0.5]. 
4. If a. -,8x + log{U2/[1 + exp(o. - ,8x)]2} S k + Nlog..\ -logN!, 
take N; 
otherwise, repeat. 
For large n's, the negative binomial distribution N eg( n, p) can also be 
generated from this algorithm since, if y '" Q(n, (1- p)/p) and xly '" P(y), 
then x ",Neg(n,p) (see Devroye, 1985). 

Notation 
Mathematical 
A-<B 
IAI 
a+ 
(;) 
IF1(a;b;z) 
F(a) 
][A (t) 
Iv(z) 
(Pl.~pJ 
Amax(A) 
V J(Z) 
V t J(Z) 
11J(z) 
11(g) 
lin lit 
J(t) ex g(t) 
tr(A) 
xVy 
xl\y 
(B - A) is nonnegative definite 
determinant of A 
max(a,O) 
binomial coefficient 
confluent hypergeometric function 
gamma function (a> 0) 
indicator function (1 if tEA, ° 
otherwise) 
modified Bessel function 
multinomial coefficient 
largest eigenvalue of the matrix A 
gradiant of J(z) (f(z) E IR and z E IR.P) 
divergence of J(z) (f(z) E IRP and z E IRP) 
Laplacian of J(z) 
multiplier acting on a group 
right and left Haar measures 
the functions J and 9 are proportional 
trace of the matrix A 
maximum of x and y 
minimum of x and y 

392 
Notation 
Probabilistic 
8()o (B) 
£(7r) 
IEVg(x)] 
IE [h(v)] 
IE7r [he B) Ix] 
f(xIB) 
A(dx) 
p() 
!pet) 
tJ>( t) 
x '" f(xIB) 
Dirac mass at Bo 
entropy of the distribution 7r 
expectation of g(x) for the distribution f(xIB) on x 
expectation of h( v) for the distribution of V 
expectation of h( B) for the distribution of B condition-
ally on x, 7r(Blx) 
density of x indexed by the parameter B with respect to 
the Lebesgue or the counting measure 
Lebesgue measure (also noted dA(X)) 
(discrete) probability distribution indexed by a param-
eter B 
density of the normal distribution N(O, 1) 
c.dJ. of the normal distribution N(O, 1) 
x is distributed according to the distribution with den-
sity f(xIB) 
Distributional 
B(n,p) 
Be(n, (3) 
C(B,a2 ) 
Vk(nl,"" nk) 
£(A) 
F(p, q) 
g(n,(3) 
Ig(n,(3) 
X~(A) 
Mk(n;Pb ··,Pk) 
N(B, a2 ) 
Np(B, E) 
Neg(n,p) 
NEF(IL, V(IL)) 
peA) 
P(xo, n) 
Tp(v, B, E) 
U[a,bJ 
We(a, c) 
Wk(P,E) 
binomial distribution 
beta distribution 
Cauchy distribution 
Dirichlet distribution 
exponential distribution 
Fisher F-distribution 
gamma distribution 
inverse gamma distribution 
noncentral chi-squared distribution 
multinomial distribution 
unidimensional normal distribution 
multidimensional normal distribution 
negative binomial distribution 
quadratic variance exponential family 
Poisson distribution 
Pareto distribution 
multidimensional Student's t-distribution 
(continuous) uniform distribution 
Weibull distribution 
Wishart distribution 

Statistical 
B7r (x) 
8EB(x) 
8JS (x) 
87r (x) 
8+(x) 
8*(x) 
Ho 
J(e) 
£(elx) 
p 
)-
n(e) 
n J (e) 
n(elx) 
82 
X 
Decisional 
v 
9 
g 
9 
9 Q 
L(e,8) 
R(e,8) 
r(n,8) 
p(n,8Ix) 
fJ 
X 
Bayes factor 
empirical Bayes estimator 
James-Stein estimator 
Bayes estimator 
positive-part James-Stein estimator 
randomized estimator 
null hypothesis 
Fisher information 
Notation 
393 
likelihood, as a function of e, identical to f(xle) 
Pitman closeness domination 
generic prior distribution for e 
Jeffreys prior distribution for e 
generic posterior distribution for e 
sum of the squared deviations from the empirical mean 
empirical mean 
decision space 
grou p acting on X 
element of 9 associated to 9 E 9 
group induced by 9 acting on fJ 
element of Q associated to 9 E 9 
group induced by 9 acting on V 
loss function of 8 in e 
frequentist risk of 8 in e 
the Bayes risk of 8 for the prior distribution n 
posterior risk of 8 for the prior distribution n 
parameter space 
observation space 

References 
Abramowitz, M. and Stegun, I. (1964) Handbook of Mathematical Functions. 
Dover, New York. 
Ahrens, J. and Dieter, U. (1974) Computer methods for sampling from gamma, 
beta, Poisson and binomial distributions. Computing 12, 223-246. 
Aitkin, M. (1991) Posterior Bayes factors (with discussion). J. Royal Statist. Soc. 
(Ser. B) 53, 111-142. 
Akaike, H. (1978) A new look at the Bayes procedure. Biometrika 65, 53-59. 
Akaike, H. (1983) Information measure and model selection. Bull. Int. Statist. 
Inst. 50, 277-290. 
Alam, K (1973) A family of admissible minimax estimators of the mean of a 
multivariate normal distribution. Ann. Statist. 1, 517-525. 
Anderson, T.W. (1984) An Introduction to Multivariate Statistical Analysis (2nd 
edition). J. Wiley, New York. 
Angers, J.F. (1987) Development of robust Bayes estimators for a multivariate 
normal mean. Ph.D. Thesis, Purdue University, West Lafayette, Indiana. 
Angers, J.F. (1992) Use of the Student's t-prior for the estimation of normal 
means: A computational approach. In Bayesian Statistics 4, J.M. Bernardo, 
J.O. Berger, A.P. Dawid and A.F.M. Smith (Eds.), 567-575. Oxford University 
Press, London. 
Angers, j.F. and MacGibbon, KB. (1990) Hierarchical Bayes Estimation in linear 
models with robustness against partial prior misspecification. Rapport n069, 
Dept. de MatMmatiques et d'Informatique, Universite de Sherbrooke. 
Arrow, KS. (1951) Social Choice and Individual Values. J. Wiley, New York. 
Atkinson, A. (1979) The computer generation of Poisson random variables. Appl. 
Statist. 28, 29-35. 
Baranchick, A.J. (1970) A family of minimax estimators of the mean of a multi-
variate normal distribution. Ann. Math. Statist. 41, 642-645. 

396 
References 
Bar-Lev, S., Enis, P. and Letac, G. (1990) Models which admit a given exponential 
family as an a priori conjugate model. Rapport Tech., Universite Paul Sabatier, 
Toulouse. 
Barnard, G.A. (1949) Statistical inference (with discussion). J. Royal Statist. Soc. 
(Ser. B) 11, 115-159. 
Basu, D. (1988) Statistical Information and Likelihood, J.K. Ghosh (Ed.). 
Springer-Verlag, New York. 
Bauwens, L. (1984) Bayesian Full Information of Simultaneous Equations Models 
Using Integmtion by Monte Carlo. Lecture Notes in Economics and Mathemat-
ical Systems 232, Springer-Verlag, New York. 
Bauwens, L. (1991) The "pathology" of the natural conjugate prior density in the 
regression model. Ann. d'Eco. et Statist. 23, 49--64. 
Bauwens, L. and Richard, J.F. (1985) A 1-1 Poly-t random variable generator 
with application to Monte Carlo integration. J. Econometrics 29, 19-46. 
Bayarri, M.J. and DeGroot, M.H. (1988) Gaining weight: a Bayesian approach. In 
Bayesian Statistics 3, J.M. Bernardo, M.H. DeGroot, D. Lindley and A.F.M. 
Smith (Eds.), 25-44. Oxford University Press; London. 
Bayes, T. (1763) An essay towards solving a problem in the doctrine of chances. 
Phil. Trans. Roy. Soc. 53, 370--418. 
Bechofer, R.E. (1954) A single-sample multiple decision procedure for ranking 
means of normal populations with known variance. Ann. Math. Statist. 25, 
16-39. 
Berge, P., Pommeau, Y. and Vidal, C. (1984) Drdre Within Chaos. J. Wiley, New 
York. 
Berger, J.O. (1975) Minimax estimation of location vectors for a wide class of 
densities. Ann. Statist. 3, 1318-1328. 
Berger, J.O. (1976) Admissibility results for generalized Bayes estimators of a 
location vector. Ann. Statist. 4, 334-356. 
Berger, J.O. (1980a) A robust generalized Bayes estimators and confidence region 
for a multivariate normal mean. Ann. Statist. 8, 716--76l. 
Berger, J.O. (1980b) Improving on inadmissible estimators in continuous expo-
nential families with applications to simultaneous estimation of gamma scale 
parameters. Ann. Statist. 8, 545-57l. 
Berger, J.O. (19S2a) Selecting a minimax estimator of a multivariate normal 
mean. Ann. Statist. 10, 81-92. 
Berger, J.O. (1982b) Estimation in continuous exponential families: Bayesian es-
timation subject to risk restrictions and inadmissibility results. In Statistical 
Decision Theory and Related Topics III, S.S. Gupta and J.O. Berger (Eds.), 
109-142. Academic Press, New York. 
Berger, J.O. (1984a) The robust Bayesian viewpoint (with discussion). In Robust-
ness of Bayesian Analysis, J. Kadane (Ed.). North-Holland, Amsterdam. 
Berger, J.O. (1984b) The frequentist viewpoint and conditioning. In Proceedings 
of the Berkeley Oonference in Honor of Kiefer and Neyman, L. Le Cam and 
R. Olshen (Eds.). Wadsworth, Belmont, California. 
Berger, J.O. (1985a) Statistical Decision Theory and Bayesian Analysis (2nd edi-
tion). Springer-Verlag, New York. 
Berger, J.O. (1985b) Discussion of 'Quantifying prior opinion' by Diaconis and 
Ylvisaker. In Bayesian Statistics II, J.M. Bernardo, M. DeGroot, D.V. Lindley 
and A.F.M. Smith (Eds.). North-Holland, Amsterdam. 
Berger, J.O. (1990a) Robust Bayesian analysis: sensitivity to the prior. J. Statist. 
Plann. Inference 25, 303-328. 
Berger, J.O. (1990b) On the inadmissibility of unbiased estimators. Statist. Prob. 
Letters 5, 71-75. 
Berger, J.O. and Berliner, L.M. (1986) Robust Bayes and empirical Bayes analysis 
with c-contamined priors. Ann. Statist. 14, 461-486. 
Berger, J.O. and Bernardo, J.M. (1989) Estimating a product of means: Bayesian 
analysis with reference priors. J. Amer. Statist. Assoc. 84, 200--207. 
Berger, J.O. and Bernardo, J.M. (1990) Reference priors in a variance components 
problem. Tech. Report # 89-32C, Purdue University, West Lafayette, Indiana. 

References 
397 
Berger, J.O. and Bernardo, J.M. (1992) On the development of the reference prior 
method. In Bayesian Statistics 4, J.O. Berger, J.M. Bernardo, A.P. Dawid and 
A.F.M. Smith (Eds.), 35-49. Oxford University Press, London. 
Berger, J.O. and Bock, M.E. (1976) Eliminating singularities of Stein-type esti-
mators oflocation vectors. J. Royal Statist. Soc. (Ser. B) 39, 166-170. 
Berger, J.O. and Deely, J.J. (1988) A Bayesian approach to ranking and selection 
of related means with alternatives to Anova methodology. J. Amer. Statist. 
Assoc. 83, 364-373. 
Berger, J.O. and Delampady, M. (1987) Testing precise hypotheses (with discus-
sion). Statist. Science 2, 317-352. 
Berger, J.O. and Mortera, J. (1991) Interpreting the stars in precise hypothesis 
testing. Int. Statist. Rev. 59, 337-353. 
Berger, J.O. and Perrichi, L.R. (1993) The intrinsic Bayes factor for model se-
lection and prediction. Tech. Report # 93-43C, Dept. of Statistics, Purdue 
University, West Lafayette, Indiana. 
Berger, J.O. and Robert, C. (1990) Subjective hierarchical Bayes estimation of 
a multivariate normal mean: on the frequentist interface. Ann. Statist. 18, 
617-651. 
Berger, J.O. and Sellke, T. (1987) Testing a point null hypothesis: the irreconcil-
ability of significance levels and evidence (with discussion). J. Amer. Statist. 
Assoc. 82, 112-122. 
Berger, J.O. and Srinivasan, C. (1978) Generalized Bayes estimators in multivari-
ate problems. Ann. Statist. 6, 783-80l. 
Berger, J.O. and Wolpert, R. (1988) The Likelihood Principle (2nd edition). IMS 
Lecture Notes -
Monograph Series 9, Hayward, California. 
Berliner, L.M. (1991) Likelihood and Bayesian prediction of chaotic models. J. 
Amer. Statist. Assoc. 86, 938-952. 
Berliner, L.M. (1992) Statistics, probability and chaos. Statist. Science 7,69-122. 
Bernardo, J.M. (1979) Reference posterior distributions for Bayesian inference 
(with discussion). J. Royal Statist. Soc. (Ser. B) 41,113-147. 
Bernardo, J.M. (1980) A Bayesian analysis of classical hypothesis testing. In 
Bayesian Statistics, J.M. Bernardo, M.H. deGroot, D.V. Lindley and A.F.M. 
Smith (Eds.). University Press, Valencia. 
Bernardo, J.M. and Giron, F.J. (1986) A Bayesian approach to cluster analysis. 
In Second Catalan International Symposium on Statistics, Barcelona, Spain. 
Bernardo, J.M. and Giron, F.J. (1988) A Bayesian analysis of simple mixture 
problems. In Bayesian Statistics 3, J.M. Bernardo, M.H. DeGroot, D.V. Lindley 
and A.F.M. Smith (Eds.), 67-78. Oxford University Press, London. 
Bertrand, J. (1889) Calcul des Probabilites. Gauthier-Villars, Paris. 
Besag, J. (1986) Statistical analysis of dirty pictures (with discussion). J. Royal 
Statist. Soc. (Ser. B) 48, 259-302. 
Besag, J. and Green, P.J. (1993) Spatial Statistics and Bayesian computation 
(with discussion). J. Royal Statist. Soc. (Ser. B) 55, 25-38. 
Bickel, P.J. (1981) Minimax estimation of the mean of a normal distribution when 
the parameter space is restricted. Ann. Math. Statist. 9, 1301-1309. 
Billingsley, P. (1965) Ergodic Theory and Information. J. Wiley, New York. 
Billingsley, P. (1986) Probability and Measure (2nd edition). J. Wiley, New York. 
Bilodeau, M. (1988) On the simultaneous estimation of scale parameters. Canad. 
J. Statist. 14, 169-174. 
Binder, D. (1978) Bayesian cluster analysis. Biometrika 65, 31-38. 
Birnbaum, A. (1962) On the foundations of statistical inference (with discussion). 
J. Amer. Statist. Assoc. 57, 269-326. 
Bjornstad, J. (1990) Predictive likelihood: a review. Statist. Science 5, 242-265. 
Blackwell, D. and Girshick, M.A. (1954) Theory of Games and Statistical Deci-
sions. J. Wiley, New York. 
Blattberg, R.C. and George, E.1. (1991) Shrinkage estimation of price and promo-
tion elasticities: seemingly unrelated equations. J. Amer. Statist. Assoc. 86, 
304-315. 
Blyth, C.R. (1951) On minimax statistical decisions procedures and their admis-
sibility. Ann. Math. Statist. 22, 22-42. 

398 
References 
Blyth, C.R. (1972) Some probability paradoxes in choice form among random 
alternatives (with discussion). J. Amer. Statist. A.ssoc. 67, 366-387. 
Blyth, C.R. (1993) Discussion of Robert, Hwang and Strawderman (1993). J. 
Amer. Statist. Assoc. 88, 72-74. 
Blyth, C.R. and Hutchinson, D. (1961) Tables of Neyman-shortest confidence 
interval for the binomial parameter. Biometrika 47, 381-391. 
Blyth, C.R. and Pathak, P.K. (1985) Does an estimator distribution suffice? In 
Proc. Berkeley Conf. in Honor of J. Neyman and J. Kiefer,1. L. Le Cam and 
A. Olshen (Eds.). Wadsworth, Belmont, California. 
Bock, M.E. (1985) Minimax estimators that shift towards a hypersphere for loca-
tion of spherically symmetric distributions. J. Multivariate Anal. 9, 579--588. 
Bock, M.E. (1988) Shrinkage estimators: pseudo-Bayes rules for normal vectors. 
In Statistical Decision Theory and Related Topics IV, S.S. Gupta and J.O. 
Berger (Eds.), 281-297. Springer-Verlag, New York. . 
Bock, M.E. and Robert, C. (1991) Bayes estimators with respect to uniform dis-
tributions on spheres (I): the empirical Bayes approach. Unpublished Report, 
Purdue University, West Lafayette, Indiana. 
Bondar, J.V. (1987) How much improvement can a shrinkage estimator give? 
In Foundations of Statistical Inference, I. McNeill and G. Umphreys (Eds.). 
Reidel, Dordrecht. 
Bondar, J.V. and Milnes, P. (1981) Amenability: a survey for statistical appli-
cations of Hunt-Stein and related conditions on groups. Z. Wahrsch. verw. 
Gebiete 57, 103-128. 
Boole G. (1854) A Investigation of the Laws of Thought. Walton and Maberly, 
London. 
Bose, S. (1991) Some properties of posterior Pitman closeness. Comm. Statist. 
(Ser. A) 20, 3697-3412. 
Bosq, D. and Lecoutre, J.P. (1988) Theorie de l'Estimation Fonctionnelle. Eco-
nomica, Paris. 
Box, G.E.P. and Muller, M. (1958) A note on the generation of random normal 
variates. Ann. Math. Statist. 29, 61D--Ul1. 
Box, G.E.P. and Tiao, G.C. (1973) Bayesian Inference in Statistical Analysis. 
Addison-Wesley, Reading, Massachusetts. 
Brandwein, A. and Strawderman, W.E. (1980) Minimax estimators of location 
parameters for spherically symmetric distributions with concave loss. Ann. 
Statist. 8, 279-284. 
Brandwein, A. and Strawderman, W.E. (1990) Stein estimation: the spherically 
symmetric case. Statist. Science 5, 356-569. 
Brandwein, A. and Strawderman, W.E. (1991) Generalizations of James-Stein 
estimators under spherical symmetry. Ann. Statist. 19, 1639--1650. 
Brandwein, A., Strawderman, W.E. and Ralescu, S. (1992) Stein estimation for 
non-normal spherically symmetric location families in three dimensions. J. Mul-
tivariate Anal. 42, 35-50. 
Brewster, J.F. and Zidek, J.V. (1974) Improving on equivariant estimators. Ann. 
Statist. 2, 21-38. 
Broniatowski, M., Celeux, G. and Diebolt, J. (1983) Reconnaissance de melanges 
de densites par un algorithme d'apprentissage probabiliste. In Data Analysis 
and Informatics 3, E. Diday (Ed.). North-Holland, Amsterdam. 
Brown, L.D. (1966) On the admissibility of invariant estimators of one or more 
location parameters. Ann. Math. Statist. 37, 1087-1136. 
Brown, L.D. (1967) The conditional level of Student's t-test. Ann. Math. Statist. 
38, 1068-1071. 
. 
Brown, L.D. (1971) Admissible estimators, recurrent diffusions, and insoluble 
boundary-value problems. Ann. Math. Statist. 42, 855-903. 
Brown, L.D. (1975) Estimation with incompletely specified loss functions. J. 
Amer. Statist. Assoc. 70, 417-426. 
Brown, L.D. (1976) Notes on Statistical Decision Theory. Unpublished Lecture 
Notes, Ithaca, New York. 
Brown, L.D. (1978) A contribution to Kiefer's theory of conditional confidence 
procedures. Ann. Statist. 6, 59--71. 

References 
399 
Brown, L.D. (1980) Examples of Berger's phenomenon in the estimation of inde-
pendent normal means. Ann. Statist. 9, 1289-1300. 
Brown, L.D. (1981) A complete class theorem for statistical problems with finite 
sample spaces. Ann. Statist. 9, 1289-1300. 
Brown, L.D. (1986) Foundations of Exponential Families. IMS Lecture Notes -
Monograph Series 6, Hayward, California. 
Brown, L.D. (1988) The differential inequality of a statistical estimation problem. 
In Statistical Decision Theory and Related Topics IV, S.S. Gupta and J.O. 
Berger (Eds.). Springer-Verlag, New York. 
Brown, L.D. (1990) Ancilarity paradoxes. Ann. Statist .. 
Brown, L.D. (1993) Minimaxity, more or less. In Statistical Decision Theory and 
Related Topics V, S.S. Gupta and J.O. Berger (Eds.), 1-18. Springer-Verlag, 
New York. 
Brown, L.D. and Farrell, RH. (1985) Complete class theorems for estimation of 
multivariate Poisson means and related problems. Ann. Statist. 8, 377-398. 
Brown, L.D. and Hwang, J.T. (1982) A unified admissibility proof. In Statistical 
Decision Theory and Related Topics III, S.S. Gupta and J.O. Berger (Eds.), 
205-230. Academic Press, New York. 
Brown, L.D. and Hwang, J.T. (1989) Universal domination and stochastic dom-
ination: U-admissibility and U-inadmissibility of the least squares estimator. 
Ann. Statist. 17, 252-267. 
Buehler, RJ. (1959) Some validity criteria for statistical inference. Ann. Math. 
Statist. 30, 845-863. 
Carlin, B. and Gelfand, A. (1990) Approaches for empirical Bayes confidence 
intervals. J. Amer. Statist. Assoc. 85, 105-114. 
Caron, N. (1994) Approches alternatives d'une tMorie non-informative des tests 
bayesiens. These d'Universite, Dept. de MatMmatique, Universite de Rouen. 
Carter, G. and Rolph, J. (1974) Empirical Bayes methods applied to estimating 
fire alarm probabilities. J. Amer. Statist. Assoc. 69, 882-885. 
Casella, G. (1980) Minimax ridge regression estimation. Ann. Statist. 8, 1036-
1056. 
Casella, G. (1985a) An introduction to empirical Bayes data analysis. Amer. 
Statist. 39, 83-87. 
Casella, G. (1985b) Condition number and minimax ridge regression estimation. 
J. Amer. Statist. Assoc. 80, 753-758. 
Casella, G. (1987) Conditionally acceptable recentered set estimators. Ann. 
Statist. 15, 1364-137I. 
Casella, G. (1990) Estimators with nondecreasing risks: application of a chi-
squared identity. Statist. Prob. Lett. 10, 107-109. 
Casella, G. (1992) Conditional inference for confidence sets. Current Issues in 
Statistical Inference: Essays in Honor of D. Basu, M. Ghosh and P.K. Pathak 
(Eds.), 1-12. IMS Lectures Notes -
Monograph Series 17, Hayward, Califor-
nia. 
Casella, G. and Berger, R (1987) Reconciling Bayesian and frequentist evidence 
in the one-sided testing problem. J. Amer. Statist. Assoc. 82, 106-11I. 
Casella, G. and Berger, R (1990) Statistical Inference. Wadsworth, Belmont, 
California. 
Casella, G. and George, E.!. (1992) An introduction to Gibbs sampling. Amer. 
Statist. 46,167-174. 
Casella, G. and Hwang, J.T. (1983) Empirical Bayes confidence sets for the mean 
of a multivariate normal distribution. J. Amer. Statist. Assoc. 78, 688-698. 
Casella, G. and Hwang, J.T. (1987) Employing vague prior information in the 
construction of confidence sets. J. Multivariate Anal. 21, 79-104. 
Casella, G., Hwang, J.T. and Robert, C.P. (1993a) A paradox in decision-theoretic 
set estimation. Statist. Sinica 3, 141-155. 
Casella, G., Hwang, J.T.G. and Robert, C.P. (1993b) Loss function for set esti-
mation. In Statistical Decision Theory and Related Topics V, J.O. Berger and 
S.S. Gupta (Eds.), 237-252. Springer-Verlag, New York. 
Casella, G., Hwang, J.T.G. and Robert, C.P. (1994) Statistical Confidence (to 
appear). Chapman and Hall, New York. 

400 
References 
Casella, G. and Robert, C. (1988) Non optimality of randomized confidence sets. 
Tech. Report # 88-9, Dept. of Statistics, Purdue University, West Lafayette, 
Indiana. 
Casella, G. and Strawderman, W.E. (1981) Estimating a bounded normal mean. 
Ann. Statist. 4, 283-300. 
Casella, G. and Wells, M. (1993) Discussion of Robert, Hwang and Strawderman 
(1993). J. Amer. Statist. Assoc. 88, 70-71. 
Castledine, B. (1981) A Bayesian analysis of multiple-recapture sampling for a 
closed population. Biometrika 67, 197-210. 
Celeux, G. and Diebolt, J. (1985) The SEM algorithm: a probabilistic teacher 
algorithm derived from the EM algorithm for the mixture problem. Comput. 
Statist. Quater. 2, 73-82. 
Celeux, G. and Diebolt, J. (1990) Une version de type recuit simule de l'algorithme 
EM. Notes aux Comptes Rendus de l'Academie des Sciences 310, 119-124. 
Cellier, D., Fourdrinier, D. and Robert, C. (1989) Robust shrinkage estimators of 
the location parameter for elliptically symmetric distributions. J. Multivariate 
Anal. 29, 39-52. 
Cheng, R. and Feast, G. (1979) Some simple gamma variate generators. Appl. 
Statist. 28, 290-295. 
Chernoff, H. and Yahav, J.A. (1977) A subset selection employing a new criterion. 
In Statistical Decision Theory and Related Topics II, S.S. Gupta and D. Moore 
(Eds.). Academic Press, New York. 
Chow, G.C. (1983) Econometrics. McGraw-Hill, New York. 
Chow, M.S. (1987) A complete class theorem for estimating a non-centrality pa-
rameter. Ann. Statist. 15, 869-876. 
Chow, M.S. and Hwang, J.T. (1990) The comparison of estimators for the non-
centrality of a chi-square distribution. Tech. Report, Dept. of Mathematics, 
Cornell University, Ithaca, New York. 
Chrystal, G. (1891) On some fundamental principles in the theory of probability. 
Trans. Actuarial Soc. Edinburgh 2, 421-439. 
Clevenson, M. and Zidek, J.V. (1975) Simultaneous estimation of the mean of 
independant Poisson laws. J. Amer. Statist. Assoc. 70, 698-705. 
Cohen, A. (1972) Improved confidence intervals for the variance of a normal 
distribution. J. Amer. Statist. Assoc. 67, 382-387. 
Cohen, A. and Sackrowitz, H. (1984) Decision Theoretic results for vector risks 
with applications. Statist. Decisions Supplement Issue 1, 159-176. 
Cohen, A. and Strawderman, W.E. (1973) Admissible confidence intervals and 
point estimators for translation or scale parameters. Ann. Statist. 1, 545-550. 
Cox, D.R. (1958) Some problems connected with statistical inference. Ann. Math. 
Statist. 29, 357-425. 
Cox, D.R. (1990) Role of models in statistical analysis. Statist. Science 5, 169-
174. 
Cox, D.R. and Reid, N. (1987) Orthogonal parameters and approximate condi-
tional inference (with discussion) J. Royal Statist. Soc. (Ser. B) 49, 1-39. 
Dalal, S.R. and Hall, W.J. (1983) Approximating priors by mixtures of natural 
conjugate priors. J. Royal Statist. Soc. (Ser. B) 45, 278-286. 
Darroch, J. (1958) The multiple-recapture census. I: Estimation of a closed pop-
ulation. Biometrika 45, 343-359. 
Das Gupta, A. (1984) Admissibility in the gamma distribution: two examples. 
Sankhya (Ser. A) 46, 395-407. 
Das Gupta, A. and Sinha, B.K. (1986) Estimation in the multiparameter expo-
nential family: admissibility and inadmissibility results. Statist. Decisions 4, 
101-130. 
Das Gupta, A. and Studden, W. (1988) Frequentist behavior of smallest volume 
robust Bayes confidence sets. Tech. Report, Dept. of Statistics, Purdue Uni-
versity, West Lafayette, Indiana. 
Dawid, A.P. (1984) Probability Forecasts. Research Report, University College 
London. 

References 
401 
Dawid, A.P. (1992) Prequential analysis, stochastic complexity and Bayesian in-
ference. In Bayesian Statistics 4, J.O. Berger, J.M. Bernardo, A.P. Dawid and 
A.F.M. Smith (Eds.), 109-121. Oxford University Press, London. 
Dawid, A.P., DeGroot, M.H. and Mortera, J. (1993) Coherent combination of 
experts' opinions. In Statistical Decision Theory and Related Topics V, J.O. 
Berger and S.S. Gupta (Eds.) Springer-Verlag, New York. 
Dawid, A.P., Stone, N. and Zidek, J.V. (1973) Marginalization paradoxes in 
Bayesian and structural inference (with discussion). J. Royal Statist. Soc. (Ser. 
B) 35, 189-233. 
Deely, J.J. and Gupta, S.S. (1968) On the property of subset selection per order. 
Sankhya (Ser. A) 30, 37-50. 
Deely, J.J. and Lindley, D.V. (1981) Bayes empirical Bayes. J. Amer. Statist. 
Assoc. 76, 833-841. 
DeGroot, M.H. (1970) Optimal Statistical Decisions. McGraw-Hill, New York. 
DeGroot, M.H. (1973) Doing what comes naturally: Interpreting a tail area as 
a posterior probability or as a likelihood ratio. J. Amer. Statist. Assoc. 68, 
966-969. 
DeGroot, M.H. and Fienberg, S. (1983) The comparison and evaluation of fore-
casters. The Statistician 32, 12-22. 
Delampady, M. (1989a) Lower bounds on Bayes factors for interval null hypothe-
ses. J. Amer. Statist. Assoc. 84, 120-124. 
Delampady, M. (1989b) Lower bounds on Bayes factors for invariant testing sit-
uations. J. Multivariate Anal. 28, 227-246. 
Delampady, M. and Berger, J.O. (1990) Lower bounds on Bayes factors for multi-
nomial and chi-squared tests of fit. Ann. Statist. 18, 1295-1316. 
Dempster, A.P. (1968) A generalization of Bayesian inference (with discussion). 
J. Royal Statist. Soc. (Ser. B) 30, 205-248. 
Dempster, A.P., Laird, N.M. and Rubin, D.B. (1977) Maximum likelihood from 
incomplete data via the EM algorithm (with discussion). J. Royal Statist. Soc. 
(Ser. B) 39, 1-38. 
DeRobertis, L. and Hartigan, J.A. (1981) Bayesian inference using intervals of 
measures. Ann. Statist. 9, 235-244. 
Devroye, L. (1985) Non- Uniform Random Variate Generation. Springer-Verlag, 
New York. 
Devroye, L. and Gyorfi, L. (1985) Nonparametric Density Estimation: the L1 
View. J. Wiley, New York. 
Diaconis, P. (1988) Bayesian numerical analysis. In Statistical Decision Theory 
and Related Topics IV, S. Gupta and J.O. Berger (Eds.), 163-176. Springer-
Verlag, New York. 
Diaconis, P. and Freedman, D.A. (1986) On the consistency of Bayes estimates. 
Ann. Statist. 14, 1-26. 
Diaconis, P. and Mosteller, F. (1989) Methods for studying coincidences. J. Amer. 
Statist. Assoc. 84, 853-861. 
Diaconis, P. and Ylvisaker, D. (1979) Conjugate priors for exponential families. 
Ann. Statist. 7, 269-281. 
Diaconis, P. and Ylvisaker, D. (1985) Quantifying prior opinion. In Bayesian 
Statistics II, J.M. Bernardo, M.H. DeGroot, D.V. Lindley, A. Smith (Eds.), 
163-175. North-Holland, Amsterdam. 
Diaconis, P. and Zabell, S. (1991) Closed form summation for classical distribu-
tions: variations on a theme of De Moivre. Statist. Science 6, 284-302. 
Dickey, J.M. (1968) Three multidimensional integral identities with Bayesian ap-
plications. Ann. Statist. 39, 1615-1627. 
Diebolt, J. and Robert, C.P. (1990a) Bayesian estimation of finite mixture distri-
butions, Part I: Theoretical aspects. Rapport Tech. # 110, LSTA, Universite 
Paris VI. 
Diebolt, J. and Robert, C.P. (1990b) Bayesian estimation of finite mixture dis-
tributions, Part II: Sampling implementation. Rapport Tech. # 111, LSTA, 
U niversite Paris VI. 
Diebolt, J. and Robert, C.P. (1994) Estimation of finite mixture distributions by 
Bayesian sampling. J. Royal Statist. Soc. (Ser. B) 2, 363-375. 

402 
References 
Drezes, J.H. and Morales, J.A. (1976) Bayesian full information analysis of the 
simultaneous equation model. Econometrica 44, 1045-1075. 
Dudewicz, E.J. and Koo, J.O. (1982) The Complete Categorized Guide to Sta-
tistical Selection and Ranking Procedures. American Science Press, Columbus, 
Ohio. 
Dumouchel, W.M. and Harris, J.E. (1983) Bayes methods for combining the re-
sults of cancer studies in human and other species (with discussion). J. Amer. 
Statist. Assoc. 78, 293-315. 
Dupuis, J.A. (1993) Bayesian estimation of movement probabilities in open popu-
lations using hidden Markov chains. Rapport Technique No. 9341, Crest, Insee, 
Paris. 
Dynkin, E.B. (1951) Necessary and sufficient statistics for a family of probability 
distributions. Selected Transl. Math. Statist. Prob. 1 (1961), 23-41. 
Eaton, M.L. (1982) Multivariate Statistics. J. Wiley, New York. 
Eaton, M.L. (1986) A characterization of spherical distributions. J. Multivariate 
Anal. 20, 272-276. 
Eaton, M.L. (1989) Group Invariance Applications in Statistics. Regional Con-
ference Series in Probability and Statistics, Vol. 1. Institute of Mathematical 
Statistics, Hayward, California. 
Eaton, M.L. (1992) A statistical dyptich: admissible inferences-recurrence of 
symmetric Markov chains. Ann. Statist. 20,1147-1179. 
Efron, B. (1975) Biased versus unbiased estimation. Adv. in Math. 16, 259-277. 
Efron, B. (1992) Regression percentile using asymmetric squared error loss. 
Statist. Sinica 1, 93-125. 
Efron, B. and Morris, C. (1973) Stein's estimation rule and its competitors - an 
empirical Bayes approach. J. Amer. Statist. Assoc. 68, 117-130. 
Efron, B. and Morris, C. (1975) Data analysis using Stein's estimator and its 
generalizations. J. Amer. Statist. Assoc. 70, 311-319. 
Efron, B. and Thisted, RA. (1976) Estimating the number of species: How many 
words did Shakespeare know? Biometrika 63, 435-447. 
Eichenauer, J. and Lehn, J. (1989) Gamma-minimax estimators for a bounded 
normal mean under squared erros-loss. Statist. Decisions 7, 37-62. 
Escobar, M.D. (1989) Estimating the means of several normal populations by 
estimating the distribution of the means. Unpublished Ph.D. thesis, Yale Uni-
versity, New Haven, Connecticut. 
Escobar, M.D. and West, M. (1994) Bayesian prediction and density estimation. 
J. Amer. Statist. Assoc. (to appear). 
Fang, K.T. and Anderson, T.W. (1990) Statistical Inference in Elliptically Con-
toured and Related Distributions. Allerton Press, New York. 
Farrell, RH. (1968a) Towards a theory of generalized Bayes tests. Ann. Math. 
Statist. 38, 1-22. 
Farrell, RH. (1968b) On a necessary and sufficient condition for admissibility of 
estimators when strictly convex loss is used. Ann. Math. Statist. 38, 23-28. 
Farrell, RH. (1985) Multivariate Calculation. Springer-Verlag, New York. 
Feller, W. (1970) An Introduction to Probability Theory and its Applications., Vol. 
1. J. Wiley, New York. 
Feller, W. (1971) An Introduction to Probability Theory and its Applications., Vol. 
2. J. Wiley, New York. 
Ferguson, T.S. (1967) Mathematical Statistics: a Decision-Theoretic Approach. 
Academic Press, New York. 
Ferguson, T.S. (1973) A Bayesian analysis of some nonparametric problems. Ann. 
Statist. 1, 209-230. 
Ferguson, T.S. (1974) Prior distributions in spaces of probability measures. Ann. 
Statist. 2, 615-629. 
Feyerabend, P. (1975) Against Method. New Left Books, London. 
Field, A. and Ronchetti, E. (1990) Small Sample Asymptotics. IMS Lecture Notes 
-
Monograph Series, Hayward, California. 
Fieller, E.C. (1954) Some problems in interval estimation. J. Royal Statist. Soc. 
(Ser. B) 16, 175-185. 
de Finetti, B. (1972) Probability, Induction and Statistics. J. Wiley, New York. 

References 
403 
de Finetti, B. (1974) Theory of Probability, Vol. 1. J. Wiley, New York. 
de Finetti, B. (1975) Theory of Probability, Vol. 2. J. Wiley, New York. 
Fishburn, P.C. (1988) Non-Linear Preferences and Utility Theory. Harvester Whe-
at sheaf, Brighton, Sussex. 
Fisher, R.A. (1956) Statistical Methods and Scientific Inference. Oliver and Boyd, 
Edinburgh. 
Fisher, R.A. (1959) Mathematical probability in the natural sciences. Technomet-
rics 1, 21-29. 
Florens, J.P., Mouchart, M. and Rolin, J.M. (1990) Elements of Bayesian Statis-
tics. Marcel Dekker, New York. 
Foster, D.P. and George, E.1. (1994) An ancillarity paradox for a univariate nor-
mal scale mixture. Scand. J. Statist. (to appear). 
Fouley, J.L., San Cristobal, M., Gianola, D. and 1m, S. (1992) Marginal likelihood 
and Bayesian approaches to the analysis of heterogeneous residual variances in 
mixed linear gaussian models. Comput. Statist. Data Anal. 13, 291-305. 
Fourdrinier, D. and Wells, M. (1993) Risk comparison of variable selection rules. 
Doc. Travail, Universite de Rouen. 
Fraisse, A.M., Raoult, J.P., Robert, C. and Roy, M. (1990) Une condition 
necessaire d'admissibilite et ses consequences sur les estimateurs a retrecisseur 
de la moyenne d'une loi normale. Can ad. J. Statist. 18, 213-220. 
Fraisse, A.M., Robert, C. and Roy, M. (1987) Estimateurs a retrecisseur matriciel, 
pour un coiit quadratique general. Ann. d'Eco. Statist. 8, 161-175. 
Fraisse, A.M., Roy, M. and Robert, C.P. (1994) STUB for admissible estimators 
in continuous exponential families with nuisance parameters. Statist. Decisions 
(to appear). 
Fraser, D.A.S., Monette, G. and Ng, K.W. (1984) Marginalization, likelihood and 
structural models. In Multivariate Analysis VI, P. Krishnaiah (Ed.). North-
Holland, Amsterdam. 
Gatsonis, C., MacGibbon, K.B. and Strawderman, W.E. (1987) On the estimation 
of a truncated normal mean. Statist. Prob. Lett. 6, 21-30. 
Gauss, C.F. (1810) Methode des Moindres Carres. Memoire sur la Combination 
des Observations. Transl. J. Bertrand. Mallet-Bachelier, Paris (1955). 
Geisser, S. and Cornfield, J. (1963) Posterior distributions for multivariate normal 
parameters. J. Royal Statist. Soc. (Ser. B) 25, 368-376. 
Gelfand, A., Hills, S., Racine-Poon, A. and Smith, A.F.M. (1990) Illustration of 
Bayesian inference in normal models using Gibbs sampling. J. Amer. Statist. 
Assoc. 85, 972-982. 
Gelfand, A. and Smith, A.F.M. (1990) Sampling based approaches to calculating 
marginal densities. J. Amer. Statist. Assoc. 85, 398-409. 
Gelfand, A., Smith, A.F.M. and Lee, T.M. (1992) Bayesian analysis of con-
strained parameters and truncated data problems using Gibbs sampling. J. 
Amer. Statist. Assoc. 87, 523-532. 
Gelman, A. and Rubin, D.B. (1992) Inference from iterative simulation using 
multiple sequences (with discussion). Statist. Science 7, 457-511. 
Geman, S. (1988) Experiments in Bayesian image analysis. In Bayesian Statis-
tics 3, J.M. Bernardo, M.H. DeGroot, D.V. Lindley and A.F.M. Smith (Eds.). 
Oxford University Press, London. 
Geman, S. and Geman, D. (1984) Stochastic relaxation, Gibbs distributions and 
the Bayesian restoration of images. IEEE Trans. Pattern Anal. Mach. Intell. 
6,721-740. 
Genest, C. and Zidek, J.V. (1986) Combining probability distributions: A critique 
and an annotated bibliography. Statist. Science 1, 114-135. 
George, E.1. (1986a) Combining minimax shrinkage estimators. J. Amer. Statist. 
Assoc. 81, 437-445. 
George, E.1. (1986b) Minimax multiple shrinkage estimators. Ann. Statist. 14, 
188-205. 
George, E.T. and Casella, G. (1994) Empirical Bayes confidence estimation. 
Statist. Sinica (to appear). 
George, E.1. and Robert, C.P. (1992) Calculating Bayes estimates for capture-
recapture models. Biometrika 4, 677-683 

404 
References 
Geweke, J. (1988) Antithetic acceleration of Monte Carlo integration in Bayesian 
inference. J. Econometrics 38, 73-90. 
Geweke, J. (1989) Bayesian inference in econometrics models using Monte Carlo 
integration. Econometrica 57, 1317-1340. 
Geyer, C.J. (1992) Practical Monte Carlo Markov Chain (with discussion). Statist. 
Science 7, 473-51l. 
Geyer, C.J. and Thompson, E.A. (1992) Constrained Monte Carlo maximum 
likelihood for dependent data (with discussion). J.Royal Statist. Soc. (Ser. B) 
54, 657-699. 
Ghosh, M., Hwang, J.T. and Tsui, K. (1983) Construction of improved estima-
tors in multiparameter estimation for discrete exponential families (with dis-
cussion). Ann. Statist. 11, 351-376. 
Ghosh, M., Keating, J.P. and Sen, P.K. (1993) Discussion of Robert, Hwang and 
Strawderman (1993). J. Amer. Statist. Assoc. 88,63-66. 
Ghosh, M. and Mukerjee, R. (1992) Hierarchical and empirical Bayes multivariate 
estimation. In Current Issues in Statistical Inference: Essays in Honor of D. 
Basu, M. Ghosh and P.K. Pathak (Eds.), 1-12. IMS Lecture Notes -
Mono-
graph Series 17, Hayward, California. 
Ghosh, M. and Sen, P.K. (1989) Median unbiasedness and Pitman closeness. J. 
Amer. Statist. Assoc. 84, 1089-109l. 
Ghosh, M., Sen, P.K. and Saleh, A.K.Md.E. (1989) Empirical Bayes subset esti-
mation in regression models. Statist. Decisions 7, 15-35. 
Gibbons, J.D., Olkin, 1. and Sobel, M. (1977) Selecting and Ordering Populations. 
J. Wiley, New York. 
Gigerenzer, G. (1991) The Superego, the Ego and the Id in statistical reasoning. In 
Methodological and Quantitative Issues in the Analysis of Psychological Data, 
G. Keren and C. Lewis (Eds.). Erlbaum, Hillsdale, New Jersey. 
Gilks, W., Clayton, D.G., Spiegelhalter, D.L, Best, N.G., Sharples, L.D. and 
Kirby, A.J. (1993) Modelling complexity: applications of Gibbs sampling in 
medicine (with discussion). J. Royal Statist. Soc. (Ser. B) 55, 39-52. 
Gilks, W., Richardson, S. and Spiegelhalter, D. (1994) Practical Monte-Carlo 
Markov Chain. Chapman and Hall, New York. 
Gilks, W.R. and Wild, P. (1992) Adaptive rejection sampling for Gibbs sampling. 
Appl. Statist. 41, 337-348. 
Gleick, J. (1987) Chaos. Penguin, New York. 
GIeser, L.J. and Healy, J.D. (1976) Estimating the mean of a normal distribution 
with known coefficient of variation. J. Amer. Statist. Assoc. 71, 977-98l. 
GIeser, L.J. and Hwang, J.T. (1987) The non-existence of 100(1- a)% confidence 
sets of finite expected diameters in errors-in-variable and related models. Ann. 
Statist. 15, 1351-1362. 
Goel, P.K. (1988) Software for Bayesian analysis. In Bayesian Statistics 3, J.M. 
Bernardo, M.H. DeGroot, D.V. Lindley and A.F.M. Smith (Eds.), 173-188. 
Oxford University Press, London. 
Goel, P.K. and Rubin, H. (1977) On selecting a subset containing the best 
population-a Bayesian approach. Ann. Statist. 5, 969-983. 
Goldstein, M. and Smith, A.F.M. (1974) Ridge-type estimators for regression 
analysis. J. Royal Statist. Soc. (Ser. B) 36, 284-219. 
Good, LJ. (1952) Rational decisions. J. Royal Statist. Soc. (Ser. B) 14, 107-114. 
Good, 1.J. (1973) The probabilistic explication of evidence, causality, explanation 
and utility. In Foundations of Statistical Inference, V.P. Godambe and D.A. 
Sprott (Eds.). Holt, Rinehart and Winston, Toronto. 
Good, 1.J. (1975) Bayesian estimation methods for two-ways contingency tables. 
J. Royal Statist. Soc. (Ser. B) 37, 23-37. 
Good, I.J. (1980) Some history of the hierarchical Bayesian methodology. In 
Bayesian Statistics II, J.M. Bernardo, M.H. DeGroot, D.V. Lindley, A.F.M. 
Smith (Eds.). North-Holland, Amsterdam. 
Good, LJ. (1983) Good Thinking: The Foundations of Probability and Its Appli-
cations. University of Minnesota Press, Minneapolis. 
Gourh~roux, C. and Monfort, A. (1989) Statistique et Modeles Econometriques. 
Economica, Paris. 

References 
405 
Goutis, C. (1990) Ranges of posterior measures for some classes of priors with 
specified moments. Tech. Report 70, University College London. 
Goutis, C. and Casella, G. (1991) Improved invariant confidence intervals for a 
normal variance. Ann. Statist. 19, 2015-2031. 
Goutis, C. and Casella, G. (1994) Increasing the confidence in Student's t-interval. 
Ann. Statist. (to appear). 
Goutis, C., Casella, G. and Wells, M.T. (1993) Assessing evidence in multiple 
hypotheses. Tech. Report 70, University College London. 
Gradshteyn, I. and Ryzhik, I. (1980) Tables of Integrals, Series and Products. 
Academic Press, New York. 
Gupta, S.S. (1965) On multiple decision (selection and ranking) rules. Techno-
metrics 7, 222-245. 
Gupta, S.S. and Panchapakesan, S. (1979) Multiple Decision Procedures. J. Wiley, 
New York. 
Gutmann, S. (1982) Stein's paradox is impossible in problems with finite sample 
space. Ann. Statist. 10, 1017-1020. 
Haft', L. and Johnstone, RW. (1986) The superharmonic condition for simultane-
ous estimation of means in exponential families. Canad. J. Statist. 14, 43-54. 
Hajek, J. and Sidak, Z. (1967) Theory of Rank Test. Academic Press, New York. 
Haldane, J. (1931) A note on inverse probability. Proc. Cambridge Philos. Soc. 
28,55-61. 
Hartigan, J.A. (1983) Bayes Theory. Springer-Verlag, New York. 
Hasting, W.K. (1970) Monte Carlo sampling methods using Markov chains and 
their application. Biometrika 57,97-109. 
Heitjan, D.F. and Rubin, D.B. (1991) Ignorability and coarse data. Ann. Statist. 
19, 2244-2253. 
Hoerl, A. and Kennard, R (1970) Ridge regression: biased estimators for non-
orthogonal problems. Technometrics 12, 55-67. 
Huber, P.J. (1964) Robust estimation of a location parameter. Ann. Math. Statist. 
35,73-101. 
Huber, P.J. (1972) Robust Statistics: a review. Ann. Math. Statist. 47, 1041-1067. 
Hui, S. and Berger, J.O. (1983) Empirical Bayes estimation ofrates in longitudinal 
studies. J. Amer. Statist. Assoc. 78, 753-760. 
Huzurbazar, V.S. (1976) Sufficient Statistics. Marcel Dekker, New York. 
Hwang, J.T. (1982a) Improving upon standard estimators in discrete exponential 
families with applications to Poisson and negative binomial cases. Ann. Statist. 
10, 857-867. 
Hwang, J.T. (1982b) Semi-tail upper bounds on the class of admissible estima-
tors in discrete exponential families, with applications to Poisson and negative 
binomial distributions. Ann. Statist. 10, 1137-1147. 
Hwang, J.T. (1985) Universal domination and stochastic domination: decision 
theory simultaneously under a broad class of loss functions. Ann. Statist. 13, 
295-314. 
Hwang, J.T. and Brown, L.D. (1991) Estimated confidence under the validity 
constraint. Ann. Statist. 19, 1964-1977. 
Hwang, J.T. and Casella, G. (1982) Minimax confidence sets for the mean of a 
multivariate normal distribution. Ann. Stat. 10, 868-881. 
Hwang, J.T. and Casella, G. (1984) Improved set estimators for a multivariate 
normal mean. Statist. Decisions Supplement Issue 1, 3-16. 
Hwang, J.T., Casella, G., Robert, C., Wells, M.T. and Farrel, R (1992) Estima-
tion of accuracy in testing. Ann. Statist. 20, 490-509. 
Hwang, J.T. and Chen, J. (1986) Improved confidence sets for the coefficients of 
a linear model with spherically symmetric errors. Ann. Statist. 14, 444-460. 
Hwang, J.T. and Pemantle, R (1994) Evaluation of estimators of statistical sig-
nificance under a class of proper loss functions. Statist. Decisions (to appear). 
Hwang, J.T. and Ullah, A. (1994) Confidence sets recentered at James-Stein 
estimators-A surprise concerning the unknown variance case. J. Econometrics 
(to appear). 
Ibragimov, I. and Has 'minskii , R (1981) Statistical Estimation. Asymptotic The-
ory. Springer-Verlag, New York. 

406 
References 
James, W. and Stein, C. (1961) Estimation with quadratic loss. In Proc. Fourth 
Berkeley Symp. Math. Statist. Probab. 1, 361-380. University of California 
Press, Berkeley. 
Jaynes, E.T. (1980) Marginalization and prior probabilities. In Bayesian Analysis 
in Econometrics and Statistics, A. Zellner (Ed.). North-Holland, Amsterdam. 
Jaynes, E.T. (1983) Papers on Probability, Statistics and Statistical Physics, R.D. 
Rosencrantz (Ed.). Reidel, Dordrecht. 
Jeffreys, H. (1961) Theory of Probability (3rd edition). Oxford University Press, 
London. [First edition: 1939.J 
Johnson, B.M. (1971) On the admissible estimators for certain fixed sample bi-
nomial problems. Ann. Math. Statist. 41, 1579-1587. 
Johnson, N.L. and Kotz, S.V. (1969--1972) Distributions in Statistics (4 vols.). J. 
Wiley, New York. 
Johnstone, D.J. and Lindley, D.V. (1994) Bayesian inference given data "signifi-
cant at a": tests of point null hypotheses. Theory and Decision (to appear). 
Johnstone, LM. (1984) Admissibility, difference equations, and recurrence in es-
timating a Poisson mean. Ann. Statist. 12, 1173-1198. 
Johnstone, LM. (1986) Admissible estimation, Dirichlet principles and recurrence 
of birth-death chains in 7l~. Z. Wahrsch. Verw. Gebiete 71, 231-270. 
Johnstone, LM. (1988) On the inadmissibility of Stein's unbiased estimate of 
loss. In Statistical Decision Theory and Related Topics IV, S.S. Gupta and 
J.O. Berger (Eds.). Springer-Verlag, New York. 
Johnstone, LM. and MacGibbon, B.K. (1992) Minimax estimation of a con-
strained Poisson vector. Ann. Statist. 20, 807-831. 
Joshi, V.M. (1967) Admissibility of the usual confidence set for the mean of a 
multivariate normal population. Ann. Math. Statist. 38, 1868-1875. 
Joshi, V.M. (1969) Admissibility of the usual confidence set for the mean of a 
univariate or bivariate normal population. Ann. Math. Statist. 40, 1042-1067. 
Joshi, V.M. (1990) The censoring concept and the likelihood principle. J. Statist. 
Plann. Inference 26, 109-111. 
Judge, G. and Bock, M.E. (1978) Implications of Pre-Test and Stein Rule Esti-
mators in Econometrics. North-Holland, Amsterdam. 
Kadane, J.B. and Chuang, D. (1978) Stable decision problems. Ann. Statist. 6, 
1095-1111. 
Kariya, T. (1984) An invariance approach to estimation in a curved model. Tech. 
Report 88, Hifotsubashi University, Japan. 
Kariya, T., Giri, N. and Perron, F. (1988) Invariant estimation of mean vector p, 
of N(p" E) with p,' E- 1 p, = 1 or E- 1/ 2 p, = C or E = 62 p,p,' I. J. Multivariate 
Anal. 27, 270--283. 
Karlin, S. (1958) Admissibility for estimation with quadratic loss. Ann. Math. 
Statist. 29,406-436. 
Karlin, S. and Rubin, H. (1956) The theory of decision procedures for distributions 
with monotone likelihood ratio. Ann. Math. Statist. 27, 272-299. 
Kass, R.E. (1989) The geometry of asymptotic inference. Statist. Science 4, 188-
234. 
Kass, R.E. and Raftery, A.E. (1993) Bayes factor and model uncertainty. Tech. 
Report 571, Carnegie Mellon University, Pittsburgh, Pennsylvania. 
Kass, R.E. and Steffey, D. (1989) Approximate Bayesian inference in condition-
ally independent hierarchical models (parametric empirical Bayes models). J. 
Amer. Statist. Assoc. 87, 717-726. 
Kass, R.E. and Wasserman, L. (1993) Formal rules of selecting prior distributions: 
a review and annotated bibliography. Tech. Report 571, Carnegie Mellon Uni-
versity, Pittsburgh, Pennsylvania. 
Keating, J.P. and Mason, R. (1988) James-Stein estimation from an alternative 
perspective. Amer. Statist. 42, 160--164. 
Keeney, R.L. and Raiffa, H. (1976) Decisions with Multiple Objectives. J. Wiley, 
New York. 
Kelker, D. (1970) Distribution theory of spherical distributions and a location-
scale parameter generalization. Sankhya (Ser. A) 32, 419-430. 

References 
407 
Kempthorne, P.J. (1987) Numerical specification of discrete least favorable prior 
distributions. SIAM J. Statist. Comput. 8, 178-184. 
Kempthorne, P.J. (1988) Controlling risks under different loss functions: the com-
promise decision problem. Ann. Statist. 16, 1594-1608. 
Kendall, M. and Stuart, A. (1979) The Advanced Theory of Statistics, Volume II: 
Inference and Relationships (4th edition). MacMillan, New York. 
Kiefer, J. (1957) Invariance, minimax sequential estimation and continuous time-
processes. Ann. Math. Statist. 28, 573-60l. 
Kiefer, J. (1977) Conditional confidence statements and confidence estimators 
(theory and methods). J. Amer. Statist. Assoc. 72, 789-827. 
Kinderman, A., Monahan, J. and Ramage, J. (1977) Computer methods for sam-
pling from Student's t distribution. Math. Comput. 31, 1009-1018. 
Knuth, D. (1981) The Art of Computer Progmming. Volume 2: Seminumerical 
Algorithms (2nd ed.). Addison-Wesley, Reading. 
Koopman, B. (1936) On distributions admitting a sufficient statistic. Trans. 
Amer. Math. Soc. 39, 399-409. 
Kubokawa, T. (1991) An approach to improving James-Stein estimator. J. Mul-
tivariate Anal. 36, 121-126. 
Kubokawa, T., Morita, S., Makita, S. and Nagakura, K. (1993) Estimation of the 
variance and its applications. J. Statist. Plann. Inference 35, 319-333. 
Kubokawa, T. and Robert, C.P. (1994) New perspectives on linear calibration. J. 
Multivariate Anal. (to appear). 
Kubokawa, T., Robert, C. and Saleh, A.K.Md.E. (1991) Robust estimation of 
common regression coefficients under spherical symmetry. Ann. Inst. Statist. 
Math. 43, 677-688. 
Kubokawa, T., Robert, C. and Saleh, A.K.Md.E. (1992) Empirical Bayes esti-
mation of the covariance matrix of a normal distribution with unknown mean 
under an entropy loss. Sankhya (Ser. A) 54, 402-410. 
Kubokawa, T., Robert, C. and Saleh, A.K.Md.E. (1993) Estimation of noncen-
trality parameters. Canad. J. Statist. 21, 54-58. 
Laird, N.M. and Louis, T.A. (1987) Confidence intervals based on bootstrap sam-
ples. J. Amer. Statist. Assoc. 82, 739-750. 
Laplace, P.S. (1773) Memoire sur la probabilite des causes par les evenenements. 
Memoires de l'Academie Royale des Sciences presentes par divers savans 6, 
621-656. [Reprinted in Laplace (1878) 8, 27-65.] 
Laplace, P.S. (1786) Sur les naissances, les mariages et les morts a Paris depuis 
1771 jusqu'a 1784 et dans toute l'etendue de la France, pendant les annees 
1781 et 1782. Memoires de l'Academie Royale des Sciences presentes par divers 
savans. [Reprinted in Laplace (1878) 11, 35-46.] 
Laplace, P.S. (1795) Essai Philosophique sur les Probabilites. [Reprinted in Chris-
tian Bourgeois, colI. 'Episteme', 1986.] 
Laplace, P.S. (1812) Theorie Analytique des Probabilites. Courcier, Paris. 
Laplace, P.S. (1878-1912) (Euvres Completes de Laplace. Gauthier-Villars, Paris. 
Le Cam, L. (1986) Asymptotic Methods in Statistical Decision Theory. Springer-
Verlag, New York. 
Le Cam, L. (1990) Maximum likelihood: an introduction. Int. Statist. Rev. 58, 
153-172. 
Lee, P. (1989) Bayesian Statistics: an Introduction. Oxford University Press, Lon-
don. 
Legendre, A. (1805) Nouvelles Methodes pour la Determination des Orbites des 
Cometes. Courcier, Paris. 
Lehmann, E.L. ~1983~ Theory of Point Estimation. J. Wiley, New York. 
Lehmann, E.L. 1986 Testing Statistical Hypotheses. J. Wiley, New York. 
Lehmann, E.L. 1990 Model specification. Statist. Science 5, 160-168. 
Leonard, T. (1982) Comments on Lejeune and Faulkenberry (1982) J. Amer. 
Statist. Assoc. 77, 657-658. 
Letac, G. (1990) Personal communication. 
Letac, G. and Mora, M. (1990) Natural real exponential families with cubic vari-
ance functions. Ann. Statist. 18, 1-37. 
Lindley, D.V. (1957) A statistical paradox. Biometrika 44, 187-192. 

408 
References 
Lindley, D.V. (1961) The use of prior probability distributions in statistical in-
ference and decision. In Proc. Fourth Berkeley Symp. Math. Statist. Probab. 1, 
453-468. University of California Press, Berkeley. 
Lindley, D.V. (1962) Discussion of Professor Stein's paper 'Confidence sets for 
the mean of a multivariate normal distribution'. J. Royal Statist. Soc. (Ser. B) 
24, 265-296. 
Lindley, D.V. (1965) Introduction to Probability and Statistics from a Bayesian 
Viewpoint (Parts 1 and 2). Cambridge University Press, Cambridge. 
Lindley, D.V. (1971) Bayesian Statistics, A Review. SIAM, Philadelphia. 
Lindley, D.V. (1980) Approximate Bayesian methods. In Bayesian Statistics II, 
J.M. Bernardo, M. DeGroot, D.V. Lindley and A.F.M. Smith (Eds.). North-
Holland, Amsterdam. 
Lindley, D.V. (1982) Scoring rules and the inevitability of probability. Int. Statist. 
Rev. 50, 1-26. 
Lindley, D.V. (1985) Making Decisions (2nd edition). J. Wiley, New York. 
Lindley, D.V. and Phillips, L.D. (1976) Inference for a Bernouilli process (a 
Bayesian view). Amer. Statist. 30, 112-119. 
Lindley, D.V. and Smith, A.F.M. (1972) Bayes estimates for the linear model. J. 
Royal Statist. Soc. (Ser. B) 34, 1-4l. 
Liu, J., Wong, W.H. and Kong, A. (1992) Correlation structure and convergence 
rate of the Gibbs sampler. Tech. Reports No. 299 and 304. Department of 
Statistics, University of Chicago. 
Lu, K and Berger, J.O. (1989a) Estimated confidence procedures for multivariate 
normal means. J. Statist. Plann. Inference 23, 1-19. 
Lu, K and Berger, J.O. (1989b) Estimation of normal means: frequentist estima-
tors of loss. Ann. Statist. 17, 890-907. 
Maatta, J. and Casella, G. (1990) Developments in decision theoretic variance 
estimation (with discussion). Statist. Science 5, 90-120. 
Machina, G. (1982) "Expected Utility" analysis without the independence axiom. 
Econometrica 50, 277-323. 
Machina, G. (1987) Choice under uncertainty: problems solved and unsolved. J. 
Econom. Perspectives 1, 121-154 
MacLachlan, G. and Basford, K (1987) Mixture Models. Marcel Dekker, New 
York. 
Maddala, G. (1977) Econometrics. McGraw-Hill, New York. 
Maritz, J.S. and Lwin, T. (1989) Empirical Bayes Methods (2nd edition). Chap-
man and Hall, London. 
Marsaglia, G. and Zaman, A. (1993) The KISS Generator. Tech. Report, Dept. 
of Statistics, University of Florida. 
Meeden, G. and Vardeman, S. (1985) Bayes and admissible set estimation. J. 
Amer. Statist. Assoc. 80, 465-47l. 
Mengersen, KL. and Robert, C.P. (1993) Testing for mixtures: a Bayesian en-
tropic approach. Doc. Travail No. 9340, Crest, Insee. 
Mengersen, KL. and Tweedie, R.L. (1993) Meta-analysis approaches to dose-
response relationships with application in studies of lung cancer and passive 
smoking. Statist. Medicine-Proc. NIH Conf. on Meta-Analysis, D. Williamson 
(Ed.). 
Metropolis, N., Rosenbluth, A.W., Rosenbluth, M.N., Teller, A.H., Teller, E. 
(1953) Equations of state calculations by fast computing machines. J. Chem. 
Phys. 21, 1087-1092. 
Meyer, Y. (1990) Ondelettes. Hermann, Paris. 
Meyn, S.P. and Tweedie, R.L. (1993) Markov Chains and Stochastic Stability. 
Springer-Verlag, London. 
Moors, J.J.A. (1981) Inadmissibility of linearly invariant estimators in truncated 
parameter spaces. J. Amer. Statist. Assoc. 76, 910-915. 
Morisson, D. (1979) Purchase intentions and purchase behavior. J. Marketing 43, 
65-74. 
Morris, C. (1982) Natural exponential families with quadratic variance functions. 
Ann. Statist. 10, 65-80. 

References 
409 
Morris, C. (1983a) Natural exponential families with quadratic variance functions: 
statistical theory. Ann. Statist. 11, 515-529. 
Morris, C. (1983b) Parametric empirical Bayes inference: theory and applications. 
J. Amer. Statist. Assoc. 78, 47-65. 
Mosteller, F. and Chalmers, T.C. (1992) Some progress and problems in meta-
analysis of clinical trials. Statist. Science 7, 227-236. 
Mosteller, F. and Wallace, D.L. (1984) Applied Bayesian and Classical Inference. 
Springer-Verlag, New York. 
Miiller, P. (1991) A generic approach to posterior integration and Gibbs sampling. 
Tech. Report # 91-09, Purdue University, West Lafayette, Indiana. 
Murphy, A.H. and Winkler, RL. (1984) Probability forecasting in meteorology. 
J. Amer. Statist. Assoc. 79, 489-500. 
Myrkand, P., Tierney, L. and Yu, B. (1992) Regeneration in Markov chain sam-
plers. Tech. Report 299, School of Statistics, University of Minnesota. 
Nachbin, L. (1965) The Haar Integral. Van Nostrand, New York. 
Naylor, J.C. and Smith, A.F.M. (1982) Application of a method for the efficient 
computation of posterior distributions. Appl. Statist. 31, 214-225. 
Neyman, J. and Pearson, E.S. (1933a) On the problem of the most efficient tests 
of statistical hypotheses. Phil. Trans. Royal Soc. Ser. A 231, 289-337. 
Neyman, J. and Pearson, E.S. (1933b) The testing of statistical hypotheses in 
relation to probabilities a priori. Proc. Cambridge Philos. Soc. 24, 492-510. 
Novick, M.R and Hall, W.J. (1965) A Bayesian indifference procedure. J. Amer. 
Statist. Assoc. 60, 1104-1117. 
Nummelin, E. (1984) General Irreducible Markov Chains and Non-Negative Op-
erators. Cambridge University Press, Cambridge. 
Oh, M.S. (1989) Integration of multimodal functions by Monte Carlo importance 
sampling, using a mixture as an importance function. Tech. Report, Dept. of 
Statistics, University of California, Berkeley. 
Oh, M.S. and Berger, J.O. (1993) Integration of multimodal functions by Monte-
Carlo importance sampling. J. Amer. Statist. Assoc. 88, 450-456. 
O'Hagan, A. (1992) Some Bayesian numerical analysis. In Bayesian Statistics 4, 
J.O. Berger, J.M. Bernardo, A.P. Dawid and A.F.M. Smith (Eds.), 345-355. 
Oxford University Press, London. 
O'Hagan, A. and Berger, J.O. (1988) Ranges of posterior probabilities for quasi-
unimodal priors with specified quantiles. J. Amer. Statist. Assoc. 83, 503-508. 
Olkin, I., Petkau, A.J. and Zidek, J.V. (1981) A comparison of n estimators for 
the binomial distribution. J. Amer. Statist. Assoc. 76, 637-642. 
Olver, F.W.J. (1974) Asymptotics and Special Functions. Academic Press, New 
York. 
Osborne, C. (1991) Statistical calibration: a review. Int. Statist. Rev. 59, 309-336. 
Pearl, J. (1988) Probabilistic Reasoning in Intelligent Systems. Morgan Kaufman, 
Palo Alto, California. 
Peddada, S. and Khattree, R. (1986) On Pitman nearness and variance of esti-
mators. Comm. Stat. 15, 3005-3018. 
Perk, W. (1947) Some observations on inverse probability including a new indif-
ference rule. J. Inst. Actuaries 73, 285-312. 
Perron, F. and Giri, N. (1990) On the best equivariant estimator of mean of a 
multivariate normal population. J. Multivariate Anal. 32, 1-16. 
Pettit, L.1. (1992) Bayes factors for outlier models using the device of imaginary 
observations. J. Amer. Statist. Assoc. 87, 541-545. 
Pfangzagl, J. (1968) A characterization of the one parameter exponential family 
by existence of uniformly most powerful tests. Sankhya (Ser. A) 30, 147-156. 
Pierce, D. (1973) On some difficulties in a frequency theory of inference. Ann. 
Statist. 1, 241-250. 
Pilz, J. (1991) Bayesian Estimation and Experimental Design in Linear Regres-
sion Models (2nd edition). J. Wiley, New York. 
Pitman, E.J.G. (1936) Sufficient statistics and intrinsic accuracy. Proc. Cambridge 
Philos. Soc. 32, 567-579. 
Pitman, E.J.G. (1937) The closest estimates of statistical parameters. Proc. Cam-
bridge Philos. Soc. 33, 212-222. 

410 
References 
Pitman, E.J.G. (1939) The estimation of location and scale parameters of a con-
tinuous population of any given form. Biometrika 30, 391-42l. 
Plessis, B. (1989) Context dependent enhancements for digitized radiographs. MS 
Sci. Thesis, Dept. of Electrical Engineering, Universite d'Ottawa. 
Poincare, H. (1902) La Science and l'Hypothese. Flammarion, Paris. [Reprinted 
in Champs, 1989.] 
Pollock, K. (1991) Modeling capture, recapture and removal statistics for estima-
tion of demographic parameters for fish and wildlife populations: past, present 
and future. J. Amer. Statist. Assoc. 86, 225-238. 
Popper, K. (1983) Postface to the Logic of Scientific Discovery. I-Realism and 
Science. Hutchinson, London. 
Press, J.S. (1989) Bayesian Statistics. J. Wiley, New York. 
Qian, W. and Titterington, D.M. (1991) Estimation of parameters in hidden 
Markov models. Phil. Trans. Roy. Soc. London A 337, 407-428. 
Racine-Poon, A., Smith, A.F.M. and Gelfand, A. (1991) Bayesian analysis of 
population models using the Gibbs sampler. Tech. Report, Dept. of Statistics, 
University of Nottingham. 
Raftery, A.E. (1988) Inference for the binomial N parameter hierarchical Bayes 
approach. Biometrika 75, 355-363. 
Raftery, A.E. and Lewis, S. (1992) How many iterations in the Gibbs sampler? 
In Bayesian Statistics 4, J.O. Berger, J.M. Bernardo, A.P. Dawid and A.F.M. 
Smith (Eds.), 763-773. Oxford University Press, London. 
Raiffa, H. (1968) Decision Analysis: Introductory Lectures on Choices under Un-
certainty. Addison-Wesley, Reading. 
Raiffa, H. and Schlaifer, R. (1961) Applied Statistical Decision Theory. Division 
of Research, Graduate School of Business Administration, Harvard University. 
Rao, C.R. (1980) Discussion of J. Berkson's paper 'Minimum chi-square, not 
maximum likelihood'. Ann. Statist. 8, 482-485. 
Rao, C.R. (1981) Some comments on the minimum mean square error as criterion 
of estimation. In Statistics and Related Topics, M. Csorgo, D. Dawson, J.N.K. 
Rao, and A. Saleh (Eds.), 123-143. 
Rao, C.R., Keating, J.P. and Mason, R. (1986) The Pitman nearness criterion 
and its determination. Comm. Statist.-Theory Methods 15, 3173-319l. 
Redner, R. and Walker, H. (1984) Mixture densities, maximum likelihood. and 
the EM algorithm. SIAM Rev. 26, 195-239. 
' 
Revuz, D. (1984) Markov Chains (2nd edition). North-Holland, Amsterdam. 
Richard, J.F. (1973) Posterior and Predictive Densities for Simultaneous Equa-
tion Models. Springer-Verlag, Berlin. 
Richard, J.F. and Tompa, H. (1980) On the evaluation ofpoly-t density functions. 
J. Econometrics 12, 335-35l. 
Ripley, B. (1986) Statistics, images and pattern recognition. Canad. J. Statist. 
14,83-111. 
Ripley, B. (1987) Stochastic Simulation. J. Wiley, New York. 
Ripley, B. (1992) Neural networks. In Networks and Chaos-Statistical and Prob-
abilistic Aspects, O. Barnorff-Nielsen et al. (Eds.). Monographs in Statistics 
and Applied Probabilities, Chapman and Hall, London. 
Rissanen, J. (1983) A universal prior for integers and estimation by minimum 
description length. Ann. Statist. 11, 416-43l. 
Rissanen, J. (1990) Complexity of models. In Complexity, Entropy, and the 
Physics of Information VIII, W. Zurek (Ed.). Adc:iison-Wesley, Reading. 
Robbins, H. (1951) Asymptotically subminimax solutions to compound statistical 
decision problems. In Proc. Second Berkeley Symp. Math. Statist. Probab. 1. 
University of California Press, Berkeley. 
Robbins, H. (1955) An empirical Bayes approach to statistics. In Proc. Third 
Berkeley Symp. Math. Statist. Probab. 1. University of California Press, Berke-
ley. 
Robbins, H. (1964) The empirical Bayes approach to statistical decision problems. 
Ann. Math. Statist. 35, 1-20. 
Robbins, H. (1983) Some thoughts on empirical Bayes estimation. Ann. Statist. 1, 
713-723. 

References 
411 
Robert, C. (1987) Two techniques of integration by parts and some applications. 
Tech. Report # 87-51, Dept. of Statistics, Purdue University, West Lafayette, 
Indiana. 
Robert, C. (1988) Performances d'estimateurs it retnkisseur en situation de mul-
ticolineariM. Ann. d'Eco. Statist. 10, 97-119. 
Robert, C. (1990a) Modified Bessel functions and their applications in Probability 
and Statistics. Statist. Prob. Lett. 9, 155-161. 
Robert, C.P. (1990b) On some accurate bounds for the quantiles of a non-central 
chi-squared distribution. Statist. Prob. Lett. 10, 101-106. 
Robert, C.P. (1990c) Hidden mixtures and Bayesian sampling. Rapport tech. 115, 
LSTA, UniversiM Paris VI. 
Robert, C.P. (1991) Generalized Inverse Normal distributions. Statist. Prob. Lett. 
11,37-41. 
Robert, C.P. (1993a) Prior Feedback: A Bayesian approach to maximum likeli-
hood estimation. Comput. Statist. 8, 279-294. 
Robert, C.P. (1993b) A Note on the Jeffreys-Lindley paradox. Statist. Sinica 3, 
601-608. 
Robert, C.P. (1993c) Intrinsic losses.'Doc. Travail No. 9348, Crest, Insee. 
Robert, C.P. (1993d) Convergence assessment for Markov Chain Monte Carlo 
algorithms. Doc. Travail No. 9349, Crest, Insee. 
Robert, C.P. (1994) Inference in mixture models. In Pmctical MCMC, W.R. Gilks, 
S. Richardson and D.J. Spiegelhalter (Eds.). Chapman and Hall, London. 
Robert, C., Bock, M.E. and Casella, G. (1990) Bayes estimators associated with 
uniform distributions on spheres (II): the hierarchical Bayes approach. Tech. 
Report BU-1002-M, Cornell University. 
Robert, C.P. and Caron, N. (1992) Noninformative Bayesian testing and neutral 
Bayes factors. Rapport Technique 148, LSTA, UniversiM Paris 6. 
Robert, C. and Casella, G. (1990) Improved confidence sets for spherically sym-
metric distributions. J. Multivariate Anal. 32, 84-94. 
Robert, C.P. and Casella, G. (1993a) Improved confidence statements for the 
usual multivariate normal confidence set. In Statistical Decision Theory and 
Related Topics V, J.~. Berger and S.S. Gupta (Eds.), 351-368. Springer-Verlag, 
New York. 
Robert, C.P. and Casella, G. (1993b) Distance penalized losses for testing and 
confidence set evaluation. Test (to appear). 
Robert, C.P. and Hwang, J.T.G. (1993) Maximum likelihood estimation under 
order constraints. Doc. Travail, Crest, Insee. 
Robert, C.P., Hwang, J.T.G. and Strawderman, W.E. (1993) Is Pitman closeness 
a reasonable criterion? (with discussion). J. Amer. Statist. Assoc. 88, 57-76. 
Robert, C.P. and Saleh, A.K.Md.E. (1991) Point estimation and confidence set 
estimation in a parallelism model: an empirical Bayes approach. Ann. d'Eco. 
Statist. 23, 65-89. 
Robert, C.P. and Soubiran, C. (1993) Estimation of a mixture model through 
Bayesian sampling and prior feedback. Test 2, 125-146. 
Roberts, G. and Polson, N. (1990) A note on the geometric convergence of the 
Gibbs sampler. Tech. Report, Dept. of Statistics, University of Nottingham. 
Robertson, T., Wright, F.T. and Dykstra, R.L. (1988) Order Restricted Statistical 
Inference. J. Wiley, New York .. 
Robinson, G.K. (1976) Properties of Student's t and of the Behrens-Fisher solu-
tion to the two means problem. Ann. Statist. 4, 963-971. 
Robinson, G.K. (1979) Conditional properties of statistical procedures. Ann. 
Statist. 7, 742-755. 
Robinson, G.K. (1982) Behrens-Fisher problem. In Encyclopedia of Statistical 
Science 1, S.V. Kotz and N.J. Johnson (Eds.), 205-209. J. Wiley, New York. 
Romano, J.P. and Siegel, A.F. (1986) Counterexamples in Probability and Statis-
tics. Wadsworth, Belmont, California. 
Rubin, D.B. (1984) Bayesianly justifiable and relevant frequency calculations for 
the applied statistician. Ann. Statist. 12, 1151-1172. 

412 
References 
Rubin, G., Umbach, D., Shyu, S.F. and Castillo-Chavez, C. (1992) Using mark-
recapture methodology to estimate the size of a population at risk for sexually 
transmitted diseases. Statist. Medicine 11, 1533-1549. 
Rubin, H. (1987) A weak system of axioms for rational behavior and the nonsep-
arability of utility from prior. Statist. Decision 5, 47-58. 
Rubinstein, RY. (1981) Simulation and the Monte Carlo Method. Wiley, New 
York. 
Rudin, W. (1976) Principles of Real Analysis. McGraw-Hill, New York. 
Rukhin, A.L. (1978) Universal Bayes estimators. Ann. Statist. 6, 345-351. 
Rukhin, A.L. (1988a) Estimated loss and admissible loss estimators. In Statistical 
Decision Theory and Related Topics IV, S.S. Gupta and J.O. Berger (Eds.), 
409-420. Springer-Verlag, New York. 
Rukhin, A.L. (1988b) Loss functions for loss estimations. Ann. Statist. 16, 1262-
1269. 
Rukhin, A.L. (1994) Admissibly. Statist. Science (to appear). 
Santner, T.J. and Duffy, D. (1990) The Statistical Analysis of Discrete Data. 
Springer-Verlag, New York. 
Savage, L.J. (1962) The Foundations of Statistical Inference. Methuen, London. 
Saxena, K. and Alam, K. (1982) Estimation of the non-centrality parameter of a 
chi-squared distribution. Ann. Statist. 10, 1012-1016. 
Schaafsma, W., Tolboom, J. and van der Meulen, B. (1989) Discussing truth or 
falsity by computing a Q-value. In Statistics, Data Analysis and Informatics, 
V. Dodge (Ed.). North-Holland, Amsterdam. 
Schervish, M.J. (1989) A general method for comparing probability assessors. 
Ann. Statist. 17, 1856-1879. 
Schervish, M.J. and Carlin, B. (1992) On the convergence of successive substitu-
tion sampling. J. Comput. Graphical Statist. 1, 111-127. 
Schmeiser, B. and Shalaby, M. (1980) Acceptance/rejection methods for beta 
variate generation. J. Amer. Statist. Assoc. 75, 673-678. 
Seber, G.A.F. (1983) Capture-recapture methods. In Encyclopedia of Statistical 
Science, S. Kotz and N. Johnson (Eds.). J. Wiley, New York. 
Seber, G.A.F. (1986) A review of estimation of animal abundance. Biometrics 
42, 267-292. 
Sen, P.K., Kubokawa, T. and Saleh, A.K.Md.E. (1989) The Stein paradox in the 
sense of Pitman measure of closeness. Ann. Statist. 17, 1375-1384. 
Seneta, E. (1993) Lewis Carroll's pillow problems. Statist. Science 8, 180-186. 
Shannon, C. (1948) A mathematical theory of communication. Bell System Tech. 
J. 27, 379-423 and 623-656. 
Shao, J. (1989) Monte Carlo approximation in Bayesian decision theory. J. Amer. 
Statist. Assoc. 84, 727-732. 
Shao, J. and Strawderman, W.E. (1994) Improving on the James-Stein positive-
part estimator. Ann. Statist. (to appear). 
Shinozaki, N. (1977) Ph.D. Thesis, Keio University. 
Shinozaki, N. (1980) Estimation of a multivariate normal mean with a class of 
quadratic loss. J. Amer. Statist. Assoc. 75, 973-976. 
Shinozaki, N. (1984) Simultaneous estimation of location parameters under 
quadratic loss. Ann. Statist. 12, 322-335. 
Shinozaki, N. (1990) Improved confidence sets for the mean of a multivariate 
normal distribution. Ann. Inst. Statist. Math. 41, 331-346. 
Shorrock, G. (1990) Improved confidence intervals for a normal variance. Ann. 
Statist. 18, 972-980. 
Silverman, B. (1980) Some asymptotic properties of the probabilistic teacher. 
IEEE Trans. Inform. Theory 26, 246-249. 
Sivaganesan, S. and Berger, J.O. (1989) Ranges of posterior measures for priors 
with unimodal contaminations. Ann. Statist. 17, 868-889. 
Small, C. (1990) A survey of multidimensional medians. Int. Statist. Rev. 58, 
263-277. 
Smith, A.F.M. (1973) A general Bayesian linear model. J. Royal Statist. Soc. 
(Ser. B) 35, 67-75. 

References 
413 
Smith, A.F.M. (1984) Present position and potential developments: some personal 
view on Bayesian statistics. J. Royal Statist. Soc. (Ser. A) 147, 245-259. 
Smith, A.F.M. and Hills, S. (1992) Parametrizations issues in Bayesian inference. 
In Bayesian Statistics 4, J.O. Berger, J.M. Bernardo, A.P. Dawid and A.F.M. 
Smith (Eds.), 227-238. Oxford University Press, London. 
Smith, A.F.M. and Makov, U.E. (1978) A quasi-Bayes sequential procedure for 
mixtures. J. Royal Statist. Soc. (Ser. B) 40, 106-112. 
Smith, A.F.M. and Roberts, G.O. (1992) Bayesian computation via Gibbs and 
related Markov chain Monte Carlo methods (with discussion). J. Royal Statist. 
Soc. (Ser. B) 55, 3-24. 
Smith, A.F.M., Sken, A., Shaw, J., Naylor, J.C. and Dransfield, M. (1985) The 
implementations of the Bayesian paradigm. Gomm. Statist.-Theory Methods 
14, 1079-1102. 
Smith, A.F.M. and Spiegelhalter, D.J. (1982) Bayes factors for linear and log-
linear models with vague prior information. J. Royal Statist. Soc. (Ser. B) 44, 
377-387. 
Smith, J.Q. (1988) Decision Analysis: A Bayesian Appmach. Chapman and Hall, 
London. 
Spiegelhalter, D.J. and Cowell, R. (1992) Learning in probabilistic expert systems. 
In Bayesian Statistics 4, J.O. Berger, J.M. Bernardo, A.P. Dawid and A.F.M. 
Smith (Eds.), 447-460. Oxford University Press, London. 
Spiegelhalter, D. and Smith, A.F.M. (1980) Bayes factors and choice criteria for 
linear models. J. Royal Statist. Soc. (Ser. B) 42, 215-220. 
Srinivasan, C. (1981) Admissible generalized Bayes estimators and exterior bound-
ary value problems. Sankhya (Ser. A) 43, 1-25. 
Srivastava, M. and Bilodeau, M. (1988) Estimation of the MSE matrix of the 
Stein estimator. Ganad. J. Statist. 16, 153-159. 
Stein, C. (1955a) Inadmissibility of the usual estimator for the mean of a mul-
tivariate normal distribution. In Pmc. Third Berkeley Symp. Math. Statist. 
Pmbab. 1, 197-206. University of California Press, Berkeley. 
Stein, C. (1955b) A necessary and sufficient condition for admissibility. Ann. 
Math. Statist. 26, 518-522. 
Stein, C. (1959) An examination of wide discrepancy between fiducial and confi-
dence intervals. Ann. Math. Statist. 30, 877-880. 
Stein, C. (1962a) Confidence sets for the mean of a multivariate normal distribu-
tion (with discussion). J. Royal Statist. Soc. (Ser. B) 24, 573-610. 
Stein, C. (1962b) A remark on the likelihood principle. J. Royal Statist. Soc. (Ser. 
A) 125, 565-568. 
Stein, C. (1965) Approximation of improper prior measures by prior probability 
measures. In Bernoulli, Bayes, Laplace Anniversary Volume. Springer-Verlag, 
New York. 
Stein, C. (1973) Estimation of the mean of a multivariate distribution. In Pro-
ceedings of the Prague Symposium on Asymptotic Statistics. 
Stein, C. (1981) Estimation of the mean of a multivariate normal distribution. 
Ann. Statist. 9, 1135-115l. 
Steward, G. (1987) Collinearity and least squares regression. Statist. Science 2, 
68-100. 
Steward, L. (1979) Multiparameter univariate Bayesian analysis. J. Amer. Statist. 
Assoc. 74, 684-693. 
Steward, L. (1983) Bayesian analysis using Monte Carlo integration-a powerful 
methodology for handling some difficult problems. it The Statistician 32, 195-
200. 
Stigler, S. (1986) The History of Statistics. Belknap, Harvard. 
Stone, M. (1967) Generalized Bayes decision functions, admissibility and the ex-
ponential family. Ann. Math. Statist. 38, 818-822. 
Stone, M. (1976) Strong inconsistency from uniform priors (with discussion). J. 
Amer. Statist. Soc. 71, 114-125. 
Strasser, H. (1985) Mathematical Theory of Statistics. de Gruyter, Berlin. 
Strawderman, W.E. (1971) Proper Bayes minimax estimators of the multivariate 
normal mean. Ann. Math. Statist. 42, 385-388. 

414 
References 
Strawderman, W.E. (1973) Proper Bayes minimax estimation of the multivariate 
normal mean. Ann. Math. Statist. 42, 385-388. 
Strawderman, W.E. (1974) Minimax estimation of location parameters for certain 
spherically symmetric distributions. J. Multivariate Anal. 4, 255-264. 
Studden, W. (1990) Private communication. 
Tanner, M. (1991) Tools for Statistical Inference: Observed Data and Data Aug-
mentation Methods. Lecture Notes in Statistics 67, Springer-Verlag, New York. 
Tanner, M. and Wong, W. (1987) The calculation of posterior distributions by 
data augmentation. J. Amer. Statist. Assoc. 82, 528-550. 
Thatcher, A.R (1964) Relationships between Bayesian and confidence limits in 
prediction. J. Royal Statist. Soc. (Ser. B) 26, 176-210. 
Thisted, RA. and Efron, B. (1987) Did Shakespeare write a newly-discovered 
poem? Biometrika 74, 445-468. 
Thompson, P.M. (1989) Admissibility of p-value rules. Ph.D. Thesis, University 
of Illinois, Urbana. 
Tibshirani, R (1989) Noninformative priors for one parameter of many. Biometri-
ka 76,604-608. 
Tierney, L. (1991) Markov chains for exploring posterior distributions. Computer 
Sciences and Statistics: Proc. 23d Symp. Interface, 563-570. 
Tierney, L. (1994) Markov chains for exploring posterior distributions. Ann. 
Statist. (to appear). 
Tierney, L. and Kadane, J.B. (1986) Accurate approximations for posterior mo-
ments and marginal densities. J. Amer. Statist. Assoc. 81, 82-86. 
Tierney, L., Kass, RE. and Kadane, J.B. (1989) Fully exponential Laplace ap-
proximations to expectations and variances of non-positive functions. J. Amer. 
Statist. Assoc. 84, 710-716. 
Titterington, D.M., Smith, A.F.M. and Makov, U.E. (1985) Statistical Analysis 
of Finite Mixture Distributions. J. Wiley, New York. 
van der Meulen, B. (1992) Assessing weights of evidence for discussing classical 
statistical hypotheses. Ph.D. Thesis, University of Groningen. 
Van Dijk, H.K. and Kloeck, T. (1984) Experiments with some alternatives for 
simple importance sampling in Monte Carlo integration. In Bayesian Statistics 
II, J.M. Bernardo, M.H. DeGroot, D.V. Lindley and A.F.M. Smith (Eds.). 
North-Holland, Amsterdam. 
van Eeden, C. and Zidek, J. (1993) Group Bayes estimation of the exponential 
mean: a retrospective view of the Wald theory. In Statistical Decision Theory 
and Related Topics V, J.O. Berger and S.S. Gupta (Eds.), 35-50. Springer-
Verlag, New York. 
Venn, J. (1886) The Logic of Chance. Macmillan, London. 
Verdinelli, I. and Wasserman, L. (1991) Bayesian analysis of outliers problems 
using the Gibbs sampler. Statist. Comput. 1, 105-117. 
Villegas, C. (1977) On the representation of ignorance. J. Amer. Statist. Assoc. 
72, 651-654. 
Villegas, C. (1990) Bayesian inference in models with euclidian structure. J. Amer. 
Statist. Assoc. 85, 1159-1164. 
Von Neumann, J. and Morgenstern, O. (1947) Theory of Games and Economic 
Behavior (2nd edition). Princeton University Press, Princeton. 
Wald, A. (1950) Statistical Decision Functions. J. Wiley, New York. 
Walley, P. (1991) Statistical Reasoning with Imprecise Probability. Chapman and 
Hall, London. 
Wasserman, L. (1992) Recent methodological advances in robust Bayesian infer-
ence. In Bayesian Statistics 4, J.O. Berger, J.M. Bernardo, A.P. Dawid and 
A.F.M. Smith (Eds.), 483-490. Oxford University Press, London. 
Wells, M.T. (1992) Private communication. 
West, M. (1992) Modelling with mixtures. In Bayesian Statistics 4, J.O. Berger, 
J.M. Bernardo, A.P. Dawid and A.F.M. Smith (Eds.), 503-525. Oxford Uni-
versity Press, London. 
West, M. and Harrison, J. (1989) Bayesian Forecasting and Dynamic Models. 
Springer-Verlag, New York. 

References 
415 
Wijsman, RA. (1990) Invariant Measures on Groups and their Use in Statistics. 
IMS Lecture Notes~Monographs Series, Hayward, California. 
Wilkinson, G. (1977) On resolving the controversy in statistical inference. J. Royal 
Statist. Soc. (Ser. B) 39, 119-171. 
Wolter, W. (1986) Some coverage error models for census data. J. Amer. Statist. 
Assoc. 81, 338-346. 
Zabell, S.L. (1989) RA. Fisher on the history of inverse probability. Statist. Sci-
ence 4, 247-263. 
Zabell, S.L. (1992) RA. Fisher and the fiducial argument. Statist. Science 7, 
369-387. 
Zellner, A. (1971) An Introduction to Bayesian Inference in Econometrics. J. 
Wiley, New York. 
Zellner, A. (1976) Bayesian and non-Bayesian analysis of the regression model 
with multivariate Student-t error term. J. Amer. Statist. Assoc. 71, 400-405. 
Zellner, A. (1984) Basic Issues in Econometrics. University of Chicago, Chicago. 
Zellner, A. (1986a) Bayesian estimation and prediction using asymmetric loss 
functions. J. Amer. Statist. Assoc. 81, 446-451. 
Zellner, A. (1986b) On assessing prior distributions and Bayesian regression anal-
ysis with g-priors distributions. In Bayesian Inference and Decision Techniques, 
P. Goel and A. Zellner (Eds.), 233-243. Elsevier, North-Holland, Amsterdam. 
Zidek, J.V. (1969) A representation of Bayes invariant procedures in terms of 
Haar measure. Ann. Inst. Statist. Math. 21, 291-308. 
Zidek, J.V. (1970) Sufficient conditions for the admissibility under squared error 
loss of formal Bayes estimators. Ann. Math. Statist. 41, 1444-1447. 

Author Index 
Abramowitz, M. 131,337 
Ahrens, J. 389 
Aitkin, M. 34, 188-189 
Akaike, H. 19, 138 
Alam, K. 20, 53, 66, 119, 131, 149, 
250, 307, 331 
Anderson, T.W. 67, 155 
Angers, J.F. 122, 152, 301, 303 
Arrow, K.S. 46,75 
Atkinson, A. 390 
Baranchick, A.J. 65 
Bar-Lev, S. 104 
Barnard, G.A. 15 
Basford, K. 355 
Basu, D. 31, 33, 140 
Bauwens, L. 28, 36, 122, 340 
Bayarri, M.J. 52 
Bayes, T. 9-11,13,17-20,27,89 
Bechofer, RE. 158 
Berge, P. 2 
Berger, J.O. 15-19, 31-32, 46, 53, 
57-60,65-67,71-72,86,93, 
95,109,115,117-123,133-
134,139-143,147,150,153, 
158-159,166-167,185,196-
201,205,208,210,212,214-
215,217-221,232,235,238, 
241,249-251,253,255,259, 
265,272,274,277,280-284, 
288-289,295-297,299-304, 
306,308,313,316,318-320, 
325, 341, 359, 376, 379 
Berger, R 6,64,170-171,184,202-
205, 207, 220-221, 224 
Berliner, L.M. 2, 49, 120-121, 123, 
313,369 
Bernardo, J.M. 8,115,117-119,189, 
336, 355, 379 
Bertrand, J. 89 
Besag, J. 347, 369 
Best, N.G. 343 
Bickel, P.J. 61 
Billingsley, P. 37, 93 
Bilodeau, M. 66 
Binder, D. 308, 331, 336, 366-367 
Birnbaum, A. 15, 18 
Bj!1Srnstad, J. 19 
Blackwell, D. 57, 240, 283 
Blattberg, RC. 158, 316 
Blyth, C.R 46, 78, 213, 240-241 
Bock, M.E. 61,65-67,119,146-147, 
172-173,247,250,307,325 
Bondar, J.V. 66, 234, 278, 280 
Boole G. 89 

418 
Author Index 
Bose, S. 78 
Bosq, D. 101, 280 
Box, G.E.P. 19, 369, 388 
Brandwein, A. 66-67, 147 
Brewster, J.F. 315 
Broniatowski, M. 355 
Brown, L.D. 53, 55, 57, 59, 62, 65-
68,76-77,85,99-101,105, 
109-110,125-126,147,150, 
174,206,210-211,225,229, 
234-237,240-241,245-251, 
254,258,278,301,304,319, 
377 
Buehler, RJ. 210 
Carlin, B. 237, 312, 346 
Caron, N. 203,221 
Carroll, L. 176 
Carter, G. 313 
Casella, G. 6, 46, 61, 64, 66-67, 71, 
81,150,158,170-171,184, 
196,202-212,215-216,220-
224,247,258,261,302,307, 
311,315,317,322,325-326, 
344-349 
Castillo-Chavez, C. 364-365 
Castledine, B. 163, 176-177 
Celeux, G. 355, 367 
Cellier, D. 66-68, 254, 307 
Chalmers, T.C. 23, 292 
Chen, J. 211 
Cheng, R. 388 
Chernoff, H. 175 
Chow, G.C. 369 
Chow, M.S. 119, 250 
Chrystal, G. 89, 175 
Chuang, D. 149 
Clayton, D.G. 343 
Clevenson, M. 236, 258 
Cohen, A. 211-212, 215 
Cornfield, J. 155-156 
Cowell, R 369 
Cox, D.R 5,17-18,151 
Dalal, S.R 110-111, 130, 246, 292 
Darroch, J. 164 
Das Gupta, A. 66, 121, 236, 252 
Dawid, A. 75,92, 120, 131-133 
Deely, J.J. 158-159, 175,303,308, 
313 
DeGroot, M.H. 28, 42, 46, 52, 54, 
75, 79-80, 91-92, 187 
Delampady, M. 120, 185, 198-201, 
208,217-220,286,359 
Dempster, A.P. 20, 291, 355-356 
DeRobertis, L. 122 
Devroye, L. 2, 308, 339, 387, 390 
Diaconis, P. 98, 104-109, 111, 130, 
138,161,246,292,337,369, 
376 
Dickey, J.M. 103, 145, 295-296, 332 
Diebolt, J. 336, 346, 351, 355, 357, 
363-364, 367 
Dieter, U. 389 
van Dijk, H.K. 340 
Dransfield, M. 337, 343 
Drezes, J.H. 122 
Dudewicz, E.J. 158 
Duffy, D. 167 
Dumouchel, W.M. 303 
Dupuis, J.A. 163 
Dykstra, R.L. 20, 32-33, 140 
Dynkin, E.B. 52, 125 
Eaton, M.L. 67, 155, 237-238, 265, 
272, 274-277, 285-288 
Efron, B. 65, 78-79, 86, 166, 316 
Eichenauer, J. 61 
Enis, P. 104 
Escobar, M.D, 7, 356 
Fang, K.T. 67 
Farrell, RH. 71, 205-209, 221-222, 
245-246, 251, 261 
Feast, G. 388 
Feller, W. 103, 168, 236 
Ferguson, T.S. 7, 42, 57, 170, 240 
Feyerabend, P. 372 
Field, A. 5 
Fieller, E.C. 226-227 
Fienberg, S. 52, 92 
de Finetti, B. 26, 98 
Fishburn, P.C. 42, 46 
Fisher, RA. 8, 14-15, 19, 114, 196, 
210 

Florens, J.P. 163, 333 
Foster, D.P. 123,174 
Fouley, J.L. 303 
Fourdrinier, D. 66-68, 254, 307 
Fraisse, A.M. 66, 250, 259-260 
Fraser, D.A.S. 139 
Freedman, D.A. 138, 376 
Gatsonis, C.F. 61, 170 
Gauss, C.F. 13, 40, 70, 151 
Geisser, S. 155-156 
Gelfand, A. 140,312,344,348,351-
352 
Gelman, A. 347 
Geman, D. 344-345,351,369 
Geman, S. 344-345, 351, 369 
Genest, C. 75 
George, E.1. 66-67, 147, 158, 163-
164,174,212,303,316,318, 
326-327,334,344-349,352 
Geweke, J. 312, 341 
Geyer, C.J. 140,330,344,346-347, 
354 
Ghosh, J.K. 117 
Ghosh, M. 66, 78, 158, 316 
Gianola, D. 303 
Gibbons, J.D. 158 
Gigerenzer, G. 196 
Gilks, W. 337, 340, 344, 352, 360-
361,369 
Giri, N. 277, 283 
Giron, F.J. 336, 355 
Girshick, M.A. 57, 240 
Gleick, J. 2 
GIeser, L.J. 226, 277 
Goel, P.K. 159-160, 175, 337, 379 
Goldstein, M. 302 
Good, I.J. 93, 120, 123, 184, 294, 
323,378 
GouriE§roux, C. 30 
Goutis, C. 96, 122, 196, 210, 212 
Gradsteyn, 1. 46, 213, 344 
Green, P.J. 347 
Gupta, S.S. 158, 175 
Gutmann, S. 66 
Gyorfi, L. 308 
Haif, L. 66 
Author Index 
419 
Hajek, J. 5 
Haldane, J. 126, 213 
Hall, W.J. 27, 110-111, 130, 246, 
292 
Hamilton, J. 166 
Harris, J.E. 303 
Harrison, J. 369 
Hartigan, J.A. 
26, 122, 138, 196, 
214,225,321-323 
Has'minskii, R 138, 374 
Hasting, W.K. 354 
Healy, J.D. 277 
Heitjan, D.F. 336, 364 
Hills, S. 337, 352 
Hoerl, A. 273 
Huber, P.J. 72, 121 
Hui, S. 313, 379 
Hutchinson, D. 213 
Huzurbazar, V.S. 14 
Hwang, J.T. 20, 66-67, 70-71, 76-
78, 87-88, 119, 140, 142, 
150,205-209,211,215-216, 
221-222,224,226,229,234-
236,241,251,254,258,261-
262,317-318,325-326 
Ibragimov, 1. 138, 374 
1m, S. 303 
James, W. 65---66, 69, 103 
Jaynes, E.T. 93, 131-133, 378 
Jeffreys, H. 8, 49, 90, 99, 113, 115, 
161,173,175-176,189,194-
196,376 
Johnson, B.M. 257, 260-261 
Johnson, N.L. 381 
Johnstone, D.J. 219 
Johnstone, I.M. 61, 66---67, 150, 235-
236 
Johnstone, RW. 292 
Joshi, V.M. 139, 211, 325 
Judge, G. 65-66, 250 
Kadane, J.B. 149,341-343,361-362 
Kant, E. 372 
Kariya, T. 277 
Karlin, S. 191, 232, 259 
Kass, RE. 120, 183, 316, 341-344, 
361-362 

420 
Author Index 
Keating, J.P. 78 
Keeney, RL. 47 
Kelker, D. 29, 67 
Kempthorne, P.J. 61, 123, 247, 379 
Kendall, M. 311, 345 
Kennard, R 273 
Khattree, R 78 
Kiefer, J. 64, 210, 216, 278 
Kinderman, A. 388 
Kirby, A.J. 343 
Kloeck, T. 340 
Knuth, D. 389 
Kong, A. 348, 351 
Koo, J.O. 158 
Koopman, B. 99 
Kotz, S.V. 381 
Kubokawa, T. 66, 78, 175, 306, 315, 
324-325, 327-328 
Laird, N.M. 20, 312, 355-356 
Laplace, P.S. 9-12, 25, 47, 72-73, 
89, 151, 160-161, 341 
Le Cam, L. 57, 109, 139, 281 
Lecoutre, J.P. 
Lee, P. 107 
Lee, T.M. 140 
Legendre, A. 13, 70 
Lehmann, E.L. 5-6, 13-14, 20, 57, 
65, 108, 114, 138, 189, 191-
193,210,231-232,254-255, 
272-273,277,280-285,374 
Lehn, J. 61 
Leonard, T. 343 
Letac, G. 101, 104 
Lewis, S. 346-347 
Lindley, D.V. 13,41, 70, 90-92, 124, 
155-156,172-173,195,206, 
211,219,294,296,299,301-
303,308,313,320,341,376 
Liu, J. 348, 351 
Louis, T.A. 312 
Lu, K 66-67, 71, 150, 212, 318 
Lwin, T. 308-309, 312-313 
Maatta, J. 210, 315 
MacGibbon, KB. 61, 122, 170, 303 
Machina, G. 42 
MacLachlan, G. 355 
Maddala, G. 150,174,369 
Madison, J. 166 
Makita, S. 327-328 
Makov, U.E. 313,330,336,355,359 
Maritz, J.S. 308-309, 312-313 
Marsaglia, G. 339, 387 
Mason, R 78 
Meeden, G. 215 
Mengersen, KL. 23, 106, 292, 346, 
354, 357-358 
Metropolis, N. 354, 362 
Meyer, Y. 5, 337 
Meyn, S.P. 236, 346, 364 
Milnes, P. 278, 280 
Monahan, J. 388 
Monette, G. 139 
Monfort, A. 30 
Moors, J .A. 260 
Mora, M. 101 
Morales, J.A. 122 
Morgenstern, O. 42 
Morisson, D. 311 
Morita, S. 327-328 
Morris, C. 67, 101, 126-127, 308-
309,315-316,323-324,337, 
359 
Mortera, J. 75, 198 
Mosteller, F. 23, 161, 166, 292 
Mouchart, M. 163, 333 
Mukerjee, R 117 
Muller, M. 388 
Miiller, P. 354 
Murphy, A.H. 52 
Myrkand, P. 347 
Nachbin, L. 274, 277 
Nagakura, K 327-328 
Naylor, J.C. 337, 343 
Neyman,J. 16,53,73,160-161,205 
Ng, KW. 139 
Novick, M.R 27 
Nummelin, E. 371 
Oh, M.S. 341 
O'Hagan, A. 120, 122, 369 
Olkin, I. 33, 158 

Olver, F.W.J. 341 
Osborne, C. 175 
Panchapakasan, S. 158 
Pathak, P.K. 78 
Pearl, J. 218 
Pearson, E.S. 16, 53, 73, 205 
Peddada, S. 78 
Pemantle, R. 70, 206, 208-209 
Perk, W. 36, 125 
Perrichi, L.R. 189 
Perron, F. 277 
Petkau, A.J. 33 
Pettit, L.I. 189 
Pfanzagl, J. 191 
Pierce, D. 59, 210 
Pilz, J. 369 
Pitman, E.J.G. 77-79, 99, 126 
Plessis, B. 4-5, 334 
Poincare, H. 372, 377-378 
Pollock, K. 162 
Polson, N. 346 
Pommeau, Y. 2 
Popper, K. 161, 369, 372 
Press, J.S. 156, 337, 379 
Price, R. 9 
Qian, W. 336, 355 
Racine-Poon, A. 352 
Raftery, A.E. 163, 183, 346-347 
Raiffa, H. 17,31,36,46-47,80,82-
83,98, 163 
Ralescu, S. 66 
Ramage, J. 388 
Rao, C.R. 78 
Raoult, J.P. 66, 250, 259-260 
Redner, R. 355 
Reid, N. 151 
Revuz, D. 346 
Richard, J.F. 28, 122, 341 
Richardson, S. 337, 344, 352, 369 
Ripley, B. 2, 341, 360, 369, 387 
Rissanen, J. 19, 120 
Robbins, H. 123, 308, 310 
Robert, C.P. 20, 53, 61, 66-68, 71, 
75,78,87-88,101-102,106, 
119,128-130,140,147,150, 
Author Index 
421 
158,163-164,171-172,175, 
188-189,203,205-209,211-
212,215-216,221-224,238, 
246-247,250,253-254,258-
261,277,295,297,302,304, 
307,313,315-316,319,325, 
330,334,336,341,346-347, 
351-352,355-358,362-364, 
366-367 
Roberts, G. 346-347 
Robertson, T. 20, 32-33, 140 
Robinson, G.K. 210-211, 216, 225 
Rolin, J.M. 333 
Rolph, J. 313 
Romano, J.P. 30, 34 
Ronchetti, E. 5 
Rosenbluth, A.W. 354,362 
Rosenbluth, M.N. 354, 362 
Ro~ M. 66, 250, 259-260 
Rubin, D.B. 20, 46, 336, 347, 355-
356,364 
Rubin, G. 364-365 
Rubin, H. 
75, 119, 159-160, 175, 
259 
Rubinstein, R.y. 341 
Rudin, W. 273 
Rukhin, A.L. 
66, 71, 77, 87, 150, 
216, 229, 247, 304 
Ryzhik, I. 46, 213, 344 
Sackrowitz, H. 215 
Saleh, A.K.Md.E. 66, 78, 158, 315-
316 
San Cristobal, M. 303 
Santner, T.J. 167 
Savage, L.J. 127, 139 
Saxena, K. 20, 119, 131, 149, 250, 
331 
Schaafsma, W. 205 
Schervish, M.J. 52,70,81-82,206, 
237, 346 
Schlaifer, R. 17, 31, 36, 46, 82-83, 
98, 163 
Schmeiser, B. 389 
Seber, G.A.F. 12, 162 
Sellke, T. 120, 198-201, 205, 208, 
221 
Sen, P.K. 78, 158, 316 

422 
Author Index 
Seneta, E. 176 
Shakespeare, W. 166 
Shalaby, M. 389 
Shannon, C. 120 
Shao, J. 66, 341 
Sharples, L.D. 343 
Shaw, J. 337, 343 
Shinozaki, N. 66, 71, 85, 211, 236 
Shorrock, G. 212 
Shyu, S.F. 364-365 
Sidak, Z. 5 
Siegel, A.F. 30, 34 
Silverman, B. 336, 355 
Simpson, T. 337 
Sinha, B.K. 66, 236 
Sivaganesan, S. 120-121 
Sken, A. 337, 343 
Small, C. 137 
Smith, A.F.M. 46,52,92,140,155-
156,189,203,294,296,299, 
301-302,313,320,330,336-
337,343-344,346-348,351-
352, 355, 359, 376 
Smith, J.Q. 47-48,80-81, 149, 166, 
168-169, 377 
Sobel, M. 158 
Soubiran, C. 366 
Spiegelhalter, D.1. 98, 189,203, 337, 
344, 353, 369 
Srinivasan, C. 67,95, 236, 249-251, 
259 
Srivastava, M. 66 
Steffey, D. 316, 343 
Stegun, I. 131, 337 
Stein, C. 8, 65-67, 69, 85, 103, 116, 
139-140,147,166,211,235, 
240,243,245-246,276,278-
279, 304, 321 
Steward, G. 158 
Steward, L. 340 
Stigler, S. 7,9,11-12,139,151,337 
Stone, M. 112, 131-133, 139-140 
Strasser, H. 57, 272, 280 
Strawderman, W.E. 34, 53, 59, 61, 
66-67,78,87-88,147,170, 
211, 235, 306, 322, 325 
Stuart, A. 311, 345 
Studden, W. 22-23, 35-36, 121 
Tanner, M. 337, 344-345, 348-350, 
352, 356 
Teller, A.H. 354, 362 
Teller, E. 354, 362 
Thatcher, A.R. 225 
Thisted, R.A. 166 
Thompson, P.M. 196 
Thomson, E.A. 140,330 
Tiao, G.C. 19, 369 
Tibshirani, R. 116 
Tierney, L. 237, 341-344, 346-347, 
354, 361-362 
Titterington, D.M. 313, 330, 336, 
355 
Tolboom, J. 205 
Tompa, H. 122 
Tsui, K. 66 
Tweedie, R.L. 
23, 106, 236, 292, 
346, 354, 364 
Ullah, A. 66, 211 
Umbach, D. 364-365 
Van der Meulen, B. 70,205 
van Eeden, C. 75 
Vardeman, S. 215 
Venn, J. 89 
Verdinelli, 1. 356 
Vidal, C. 2 
Villegas, C. 27, 289-290 
Von Neumann, J. 42 
Wald, A. 16,42,53,249 
Walker, H. 355 
Wallace, D.L. 166 
Walley, P. 120, 134-136, 226, 291 
Wasserman, L. 120, 122, 356 
Wells, M.T. 62,66,71,86,196,205-
209, 221-222, 261 
West, M. 7, 109, 369 
Wijsman, R.A. 265, 272 
Wild, P. 340, 360-361 
Wilkinson, G. 8 
Winkler, R.L. 52 
Wolpert, R. 15, 19,31,72, 139-140, 
166-167,197-198,210,376 
Wolter, W. 162-164 
Wong, W.H. 344-345, 348-351, 356 

Wright, F.T. 20, 32-33, 140 
Yahav, J.A. 175 
Ylvisaker, D. 98, 104-109, 111, 130, 
246, 292 
Yu, B. 347 
Zabell, S.L. 8, 175, 337 
Zaman, A. 339, 387 
Zellner, A. 86, 122, 156-158, 369 
Zidek, J.V. 33, 75, 131-133, 235-
236, 256-258, 276, 315 
Author Index 
423 

Subject Index 
Absolute error loss, 12, 72-73, 205 
Acceptance level, 181-182 
Accuracy evaluation see Loss esti-
mation) 
Action space, 48 
Additive measures, 26 
Admissibility, 53, 62-65, 229-262, 
374 
and Bayes estimators, 26, 63-
64, 75, 229-238, 248-251 
for bounded functions, 237-238 
of linear estimators, 254-255 
versus minimaxity, 61, 65-68, 
254 
necessary, condition, 229, 236-
247, 251-254 
of the p-value, 206-208 
sufficient, condition, 232, 235-
247, 255 
Algorithm 
accept-reject, 340, 359-361 
EM, 20,355 
hybrid, 365 
MCMC, see Markov 
Metropolis, 340, 354, 362 
Newton-Raphson, 330 
pool-adjacent-violators, 33 
Prior Feedback, 34, 129-130, 
140,330 
Simpson's, 337 
a-credible set 212-214 
Amenability, 238, 278-281 
Analyticity of Bayes estimator, 146 
Analysis of variance, 119, 158 
Ancillary paradoxes, 174 
Ancillary statistics, 30,32,210,266, 
270 
Animal biology, 160, 162 
Approximation of prior distributions 
by mixtures, 106-111,246 
Arcsine distribution, 168 
Astronomy, 12, 196 
Asymmetric loss, 165 
Asymptotic 
justifications, 5, 20, 108-109, 
151,307-309,313,341,343, 
374 
properties, 347 
optimality, 138 
Autoregressive model (AR), 175 
Axioms 
of rationality see Rationality 
for the existence of a prior dis-

426 
Subject Index 
tribution, 
91~92, 121 
Basu's theorem, 30 
Bayes estimators 
admissible, see Admissibility 
as tools, 53, 97, 137, 291, 371, 
374 
derivation of, 12~ 13, 50-51, 329~ 
330,373 
for exponential families, 
146~ 
147 
generalized, see Generalized 
independent of the loss func-
tion, 77 
invariant, 26, 263~265, 267, 272~ 
273, 275~278 
linearity of, 98, 104 
minimax, 26, 57~62, 75, 295; 
see also Hunt~Stein 
optimality of, 53, 149 
randomized, 54, 59 
Bayes factor, 134, 159, 182~183 
Bayesian sampling, 
344~345, 349-
354, 356~357 
Bayesian Statistics 
and Decision Theory, 10-41, 50-
53, 67, 144~151 
and invariance, 282 
and the Likelihood Principle, 19, 
26, 112, 137~ 140 
coherence of, see Coherence 
criticisms of, see Criticisms 
foundations of, 7, 25, 29, 90, 
369~380 
history of, 7, 10~ 13 
subjective motivations for, 40, 
122, 153 
versus frequentist Statistics, 16, 
67, 179, 194, 293 
Bayes risk, 51, 54, 231, 275 
Bayes rule, 144; see also Bayes esti-
mators 
Bayes Theorem, 
8~9, 30 
as an actualization principle, 9, 
336 
conditioning on the data, 10, 
50, 370~371, 374~375, 378 
history of, 10 
Behrens~Fisher problem, 225 
Berger's phenomenon, 67 
Best Bayes center, 223 
Best equivariant estimators, 26, 148, 
265~266,270~272,288,314-
315,373 
admissibility and minimaxity of, 
278~281 
as Bayes estimators, 267 
Beta-binomial distribution, 345,347 
Beta distribution, 22, 27, 29, 382, 
389 
Beta-Pascal distribution, 163 
Bias, 55 
Bimodal distributions, 4, 32, 173 
Binomial distribution, 10, 384, 389 
Blyth sufficient admissibility condi-
tion, 240-245 
Bounded parameter space, 93 
Brier score, 81 
Calibration, 174, 226 
expert, 52 
forecaster, 52, 92 
Capture-recapture, 3, 160, 162~166, 
333~334, 365 
Carroll's Pillow Problems, 176 
Cauchy distribution, 
21, 95, 138, 
152, 189 
Causes versus effects, 
7~9, 13 
Censored data, 31, 336, 367 
Census, 162 
Central Limit Theorem, 3, 151,389 
Chaos, 2, 49, 369 
Chi-squared test, 195, 359 
Classes 
conjugate priors, 121 
determined moments, 121 
neighborhood, 121 
of prior distributions, 120 
ratio of density, 122 
underspecified, 121 
Closed under sampling family, 97 
Coarse data, 364 
Coherence 
axioms, 135 
of Decision Theory, 39,79,144, 
373 
of the Bayesian approach, 
7~ 
10,13,29,89-90,189,369-

373,380 
of a family of prior distributions, 
125 
of a scaling, 91 
of the value of sample informa-
tion, 82 
Coincidence, 161 
Committee, 75 
Communication, 144 
Compact parameter space, 60, 118 
Comparison of means, 158-160 
Comparison of procedures, 49-50; 
see also Loss 
Complete class, 229, 240 
essentially, 191, 240 
results, 28, 62, 206-207, 246-
251 
Complete statistics, 30, 32, 34 
Completion, 54 
Complexity, 5, 28 
stochastic, 19, 120 
Computational difficulties, 24, 293-
295,307,313,319,329-337 
Computational Statistics, 24 
Computational techniques, 337-358, 
375-376 
Conditional distributions, 34, 163, 
345, 349-352 
Conditional perspective, 8-10, 13, 
16, 23, 216-217, 370-371, 
375 
in evaluation of procedures, 49, 
51, 142, 150 
frequentist, 197, 210-211 
in regression, 105, 158 
Conditionality Principle, 17 
Confidence assessment, 216,258,261, 
318 
Confidence level, 24, 209-211, 213-
216,317 
Confidence region, 23, 34, 66, 150, 
166, 173,209-217,371 
recentered, 211,312,317-319 
Confluent hypergeometric function, 
128, 130, 152, 308, 340 
Conjugate family, 98-106, 216 
for exponential families, 103-
106, 129, 310-311 
minimal, 98 
Subject Index 
427 
natural, 104 
for the normal model, 151-153, 
156-157 
parametrized, 98 
Conjugate prior distributions, 89, 
95,97-106 
and empirical Bayes modeling, 
309, 311-312 
and hierarchical Bayes model-
ing, 123, 129, 292, 295 
as a modeling basis, 98, 106-
111 
robustness of, 121, 123 
tractability of, 98, 105, 111 
Consequences, 41-42 
ordering of, 42 
Consistency, 20, 263, 376 
Contiguity, 190 
Contingency table, 167 
Continuous risk, 238-240, 249 
Convergence, 351 
geometric, 346, 357, 364, 367 
monitoring, 347, 351-352, 363 
Cornell University, 218, 364-365 
Cramer-Rao inequality, 232 
Criticisms 
of Bayesian Statistics, 11, 41, 
51, 291, 376-379 
on the choice of the prior dis-
tribution, 89, 376-379 
of confidence regions, 210-212, 
318 
of conjugate priors, 106-109, 
121 
of Decision Theory, 75-79 
of empirical Bayes motivations, 
309-310, 318-319, 379 
of frequentist motivations, 55-
57, 90, 306 
of invariance, 282 
of Laplace expansions, 343-344, 
361-362 
of Neyman-Pearson approach, 
194-196 
of noninformative priors, 115-
116, 357-358, 378 
of point null hypothesis priors, 
184, 188-189, 202-203 
of statistical modeling, 7 

428 
Subject Index 
of Utility Theory, 46 
Cumulant generating function, 101 
Darroch model, 164, 177 
Data augmentation, 345-349, 351 
Data collection, 1 
Decision, 39 
as consequence, 40 
errors versus variability, 40, 70, 
150 
invariant, 268-272 
making under uncertainty, 46 
space, 40, 48 
Decision Theory, 53-64, 159, 179, 
192 
and Bayes estimators, 29, 50-
52,144-151 
foundations of, 1,7,39,78-79, 
373 
and the Likelihood Principle, 19, 
21, 74, 374 
for testing problems, 205-209 
Determinism, 2, 9-10 
Dickey's decomposition, 
103, 145, 
295, 301, 332, 352 
Dirichlet distribution, 100,356-357, 
383 
Dirichlet process, 7 
Discontinuity, 28 
Discrete model, 160-166, 231, 250 
Duality Principle 
Bayesian Statistics as, 7, 248 
between loss and prior, 41, 71, 
119, 183, 378 
for MCMC algorithms, 
346-
347, 351, 363-364 
between tests and confidence re-
gions, 209-210 
Econometrics, 151, 174, 369-370 
Efficiency, 20 
EM (Expectation-maximization), 20, 
355 
Empirical Bayes approach, 23, 67, 
97, 142, 292, 307-313 
versus hierarchical Bayes approach, 
308 
Entropy, 52 
as a distance, 74,121,133,269, 
271,314 
maximum, 93-94, 124 
E-contamination classes, 121 
Equiprobable events, 11, 112 
Ergodicity, 345-346 
Ergodic theorem, 346-347, 352 
Error see Loss 
Estimation 
as evaluation, 48-49 
versus evaluation, 6, 39-41 
versus testing, 6, 64, 179 
Estimator, 49 
best, 49, 67, 137 
best equivariant, see Best 
versus estimate, 49 
equivariant, 268 
minimax, 54 
randomized, 52, 70, 170, 191, 
213 
Euclidean Bayesian model, 289 
Evaluation 
of actions, 48 
of a population size, 162 
of procedures, 39, 142, 149, 194 
postdata versus predata, 179, 
194,205 
Evidence, 17 
Exchangeability, 159, 175, 296, 315 
Expected utility, 48 
Experiment, 17, 372 
mixed, 17 
Exponential distribution, 3, 382, 388 
double, 12 
Exponential families, 14,75,77,99-
106, 125-128, 166, 191 
Bayes estimators for, 147,231, 
234-235 
computation for, 174 
curved, 102 
empirical Bayes estimators for, 
324 
Fisherinformation for, 115,173 
and maximum entropy solutions, 
94 
minimal, 100 
natural, 126 
quasi-, 99 
regular, 100 

steep, 126 
tests for, 206-209 
variance of, 101, 126-127 
F-distribution, 29, 382, 389 
Federalist papers, 166 
Fiducial Statistics, 8, 19, 370 
paradoxes of, 8 
Fieller's problem, 226-227 
Fisher information, 
113-115, 118, 
130-131,379 
for exponential families, 115 
multidimensional, 114 
F-ratio, 29 
Frequentist justifications, 90 
Frequentist Statistics, 16 
conservative aspects of, 55, 143-
144, 205 
in Decision Theory, 49-69, 150 
and the Likelihood Principle, 16, 
32 
tests with, 32 
Frequentist validity, 150-151, 201, 
258 
Fubini theorem, 51, 208 
Gamble, 134 
desirable, 134 
Game Theory, 41-42, 51, 54, 56 
Gamma distribution, 32, 236, 381, 
388 
r minimax perspective, 123,379 
Generators see Pseudorandom 
Generalized Bayes estimator, 
51-
52, 60, 63, 169 
admissibility of, 63-64, 85, 233-
238, 249 
Generalized hyperbolic secant distri-
bution, 127 
Generalized inverse normal distribu-
tion, 101, 128-129, 277 
Generalized prior see Improper prior 
Geometric distribution, 22, 384, 388 
Gibbs sampling, 351, 357; see also 
Bayesian sampling 
g-priors, 156-158 
Haar measure, 264 
Subject Index 
429 
right, 
26, 94, 113, 115, 272-
282, 287, 373 
Haldane prior distribution, 27, 167, 
213, 217, 289 
Hellinger distance, 74, 121, 133 
Hidden mixtures 
for noncentral chi-squared dis-
tribution, 103 
for Student's t distribution, 103, 
145 
Hierarchical Bayes 
computational advantages of, 123, 
292,294,297,332,344,349 
modeling, 13, 24, 97, 122, 142, 
156, 291-302 
Highest posterior density region (HPD), 
23, 212-216, 325 
Histogram, 4, 93, 122 
Huber's loss, 72 
Hunt-Stein theorem, 61, 278-281, 
288 
Hypergeometric distribution, 3, 162, 
385 
Hyperparameters, 97,102,123,293-
294 
Hyperpriors, 97 
Hypothesis 
alternative, 180 
null, 180, 196-199 
one-sided, 192, 203 
point null, 179, 184-188, 193, 
196 
for testing, 6, 23 
two-sided, 185, 192 
Image processing, 4 
Importance function for Monte Carlo 
simulation, 338-340 
Improper prior distributions, 25,37, 
187-189, 213 
admissibility for, 63 
justifications of, 12, 112 
as least favourable distributions, 
58, 189 
Inadmissibility, 62 
criterion, 146 
Incoherencies in scaling, 92 
Inconsistency of a generalized Bayes 
estimator, 175 

430 
Subject Index 
Indifferent alternatives, 43 
Inference 
Bayesian, 23, 116-117, 119, 137-
144 
decision theoretic, 40 
on a finite population, 160 
foundations of, 1-2, 370-372 
statistical, 5, 7, 13, 19 
Information 
amount of, 114 
contained in the loss function, 
41, 119, 205 
of an experiment, 15, 137 
fixed prior, 138 
incomplete, 90, 98 
incorporation of, 13, 55 
loss of, 4 
negligible, 167 
posterior, 118 
prior, 9-10, 25, 50, 53, 89-90, 
112,137,158,183,301,334, 
371 
sample, 9 
subjective, 90 
subjective versus structural, 291, 
295 
theory, 120 
unavailable, 112 
update, 22 
vague, 13, 95, 142, 184, 313 
Instability of procedures, 20-21, 33, 
149, 332-334, 340 
Interpretation versus explanation, 1-
2,90,370 
Intrinsic losses, 20, 41, 69, 74-75, 
86, 133, 286 
Invariance 
of distributions under sampling, 
22 
under a group action, 26, 28, 
41, 51, 94, 113, 263-290, 
374, 378 
loss based on, 41 
from prior to posterior type, 98 
under reparametrization, 
74, 
86, 112-113, 115, 119 
Invariant measures, 273-278, 280 
Inverse Gamma distributions, 153 
Inverse Gaussian distributions, 126 
Inverse Probability see History of 
Bayesian Statistics 
Inverse regression see Calibration 
Inversion of perspectives between Prob-
ability and Statistics, 8, 
13, 19, 21, 370 
Isotonic regression, 32-33 
James-Stein estimators, 65, 88, 103, 
250,253,313-316,327-327 
positive-part, 55, 66, 146, 173, 
249, 314 
Jeffreys-Lindley paradox, 28, 188, 
195, 202-203, 221 
Jeffreys noninformative priors see Non-
informative 
Jensen inequality, 57 
Kolmogorov-Smirnov test, 359 
Kullback-Leibler distance see Entropy 
Lagrange multipliers, 94 
Laplace distribution, 12 
Laplace expansion, 341-344 
standard and full exponential 
forms, 341-344 
Laplace succession rule, 
160-161, 
175-176 
Laplace transform, 146 
Law of Large Numbers, 49,338 
Law of the Iterated Logarithm, 31 
Least favorable Bayesian answer, 198-
205 
Least favorable distribution, 26, 58-
61, 83, 193, 307, 375 
example of unique, 61 
existence of, 59 
Least squares estimator, 30,65, 141, 
155,377 
Lebesgue measure, 25 
Likelihood function, 8, 19 
as prior distribution, 129, 371; 
see also Fiducial 
Likelihood Principle, 12-21, 31-34, 
72, 137, 139, 150, 155, 210 
Bayesian version of, 
27, 371, 
373 
implementation of, 19,29,373 
limitations of, 166-167 

and noninformative priors, 116, 
282 
and randomized estimators, 53, 
192 
Likelihood ratio, 182, 193, 197; see 
also Monotone 
Limits 
of Bayes estimators, 238-246, 
374 
as closure of a set 26, 248 
of conjugate distributions, 154 
of proper distributions, 26-28, 
60, 116, 203, 206 
Linear model, 3, 128, 140, 155-158, 
174, 185, 294, 314 
LINEX loss, 86 
Location parameter, 19,25,113,264-
267 
Logistic distribution, 168 
Logistic model, 
2, 105, 127, 168, 
180,320,362-363,367-368 
Long run performances, 49 
Loss estimation, 66, 142, 149-150 
from a frequentist point of view, 
150 
Loss function 
asymmetric, 165 
as basis of Decision Theory, 13, 
39-41, 79 
bounded, 72-73, 245, 255 
classical, 
40, 69-75, 79, 145, 
149, 329 
construction of, 41, 48 
convex, 57, 72, 84, 149 
definition of, 40 
examples of, 12, 69-75 
intrinsic, see Intrinsic 
invariant, 
172, 267-268, 272, 
276 
joint, 65 
nonquantitative, 73 
opportunity, 82 
posterior expected, 50 
random, 75 
rational, 215 
and robustness, 123 
for set estimation, 214-217,224 
strictly convex, 51, 63, 348 
undeterminacy on, 71 
Subject Index 
431 
"0 - 1", 50, 73, 179--181 
Marginal distribution, 
21, 23, 34, 
37, 93, 123, 308-309 
Marginalization paradoxes, 27, 112, 
119, 131-133, 137,379 
Markov chain, 
167, 175, 237-238, 
345, 366 
hidden, 168, 357, 367 
renewal theory, 347 
Markov Chain Monte-Carlo (MCMC), 
237, 344-355, 376 
batch sampling for, 347 
single versus multiple sequences 
for, 347 
Maximin strategy, 57; see also Least 
favourable distribution 
Maximization, 20, 330 
Maximum Bayesian Likelihood Es-
timation, 137-139 
Maximum entropy see Entropy 
Maximum Likelihood Estimation, 26, 
129-130, 310 
limitations of, 
164, 250, 355, 
375 
method, 19-21, 32-34 
penalized, 19, 138 
Mean, functional, 279-281 
Measures, upper and lower bound, 
134,291 
Meta-analysis, 23, 292, 295 
Meta-model, 93, 292, 294 
Minimal complete class, 
62, 258-
261 
Minimal dimension, 100 
Minimal sufficient statistics, 30-32 
Minimax estimators, 54 
admissibility of, 61, 65 
Bayes estimators as, 58-59, 62, 
199 
and equivariant estimators, 61 
existence of, 57, 59, 297-298 
optimality of, 61 
uniqueness of, 63, 65, 261 
Minimaxity, 53-61, 374 
and Bayes estimators, 26; see 
also Least favorable 
of best equivariant estimators 
see Hunt-Stein 

432 
Subject Index 
versus colinearity reduction, 302 
sufficient conditions of, 59, 303, 
305 
of hierarchical Bayes estimators, 
303-307 
and randomized estimators, 53-
54 
in testing setups, 190, 193, 201-
202, 222, 261 
Minimax principle, 55, 142, 199 
Missing data, 20, 128, 336, 350, 356 
Mixture 
of conjugate priors, 108, 130, 
312, 330, 334 
estimation, 121, 184, 355-358 
of exponential families, 103,246 
finite, 4, 20, 28, 106, 124, 134, 
168,174,200,334-336,370 
hidden, 103,295,302,349,352-
353 
infinite, 22,110-111,220 
of rewards, 43 
scale, 220 
ML-II method, 93 
Model 
Bayesian statistical, 9 
choice, 15, 179-184, 222 
parametric statistical, 5-6, 46 
Modeling 
hierarchical, 13, 142, 291-292, 
294-296 
parametric, 5 
parametric versus nonparamet-
ric, see Nonparametric 
prior, 90-97, 108,371,376-378 
probabilistic, 1-3, 7, 10 
reducive effect of, 
5, 46, 50, 
157,370 
statistical, 5 
Modified Bessel function, 171-172, 
247, 331 
Moments 
canonical, 23, 35-36 
generating function, 343 
method, 93 
Monetary rewards, 47 
Monotone likelihood ratio, 175, 190, 
203, 219, 240, 258-259 
Monte Carlo simulation, 111, 140, 
142, 338-341, 387-390 
Markov Chain, see Markov 
Moral expectation, 47-48 
Multicolinearity, 158, 301-302, 321 
Multidimensional consequences, 47 
Multidimensional median, 137 
Multinomial coefficient, 163, 384 
Multiple shrinkage, 66, 326-327 
Multiplicative model, 277 
Natural parameter 
estimation, 75, 147, 310 
of an exponential family, 99 
space, 100 
Neyman-Pearson lemma, 190-191 
Neyman-Pearson theory, 16,73,180, 
189-198, 205, 209, 379 
criticisms, 194-196 
Noncentral chi-squared distribution, 
88,117,172,250,324,338, 
383 
Noninformative approach 19, 74, 112-
120, 295, 371 
criticism of, 378-379 
fiducial Statistics as, 8 
and improper priors, 25, 357-
358 
and invariance, 263-264 
Noninformative prior distributions, 
97, 112-120 
Jeffreys, 89, 113-117, 119, 189, 
276, 282, 295, 306, 374 
as limits of conjugate priors, 116 
for the normal model, 152, 155 
for ranking and selection, 159 
for tests, 184, 187, 189 
as tools, 97, 115, 378 
uniform, see Uniform 
Nonlinear constraints, 33, 140 
Nonparametric density estimation, 109, 
308,348 
Nonparametric versus parametric, 5, 
30,309,356 
Nontransitivity of Pitman criterion, 
78 
Normal distribution, 381, 388 
approximation of, 30 
as the ideal distribution, 13 

inference for, 13-14, 26, 151-
160,182,186-188,192,203, 
299-307 
mean estimation, 68-69, 151-
152,230-231,236,246-247, 
253, 299-307 
mean norm estimation, 64, 117-
119,131,149,233,250,286, 
331,339 
Normalizing constant, 24,27-28, 188-
189 
Notations, 13, 24, 381-393 
NP-hard problems, 337 
Numerical 
computations, 149,329-331,337, 
375 
integration, 337-338 
verifications of minimaxity and 
admissibility, 238 
Objectivity requirements, 97, 106 
Observation space, 48 
Odds, 182 
Optimality criteria, 373 
frequentist, 51,53-64, 112,229, 
264, 309, 379 
Optimal prior decision, 82 
Optimal procedures 
and Bayesian procedures, 19, 
112,292 
versus classical procedures, 13, 
53, 197,373 
and reference priors, 117 
search for, 7, 12, 179, 191,374 
unicityof, 81, 373 
Optimal reward, 43 
Orbit of a group, 269, 275 
Order relation, 42, 91 
connected, 43 
linearization of, 44 
between parameters, 119 
partial, 61, 76 
Order-restricted parameters, 20, 32-
33, 140 
Order statistics, 102 
Orthogonal polynomials, 127, 337, 
359 
Outlier detection, 356 
Overparametrized models, 133 
Subject Index 
433 
Paradoxes 
ancillarity, 174 
Berger's, 215, 224 
computational, 332-333, 355 
Condorcet, 46 
conjugate priors justification, 98 
convergence, 28, 36 
infinite rewards, 46, 48 
Jeffreys-Lindley, 28, 188 
likelihood, 21, 118-119, 139-
140, 373 
marginalization, 27, 131-133 
of monetary rewards, 47 
Saint-Petersburg, 40,47-48,80 
Simpson, 30, 46 
Stein effect, 65, 85, 174, 211, 
233 
Parameter 
of interest, 10, 117-120 
nuisance, 
117-120, 140, 250, 
378 
space, 48 
Parametric Histogram Specification, 
4-5 
Parametrization, 20, 74 
invariance, 20-21 
mean, 110 
Pareto distribution, 102, 383 
Parsimony requirement, 159 
7r-irreducibility, 346, 363 
Pitman closeness, 77-79, 87-88 
Pitman estimator, 267 
Pitman-Koopman lemma, 99, 125-
126, 191 
Poisson distribution, 55, 163, 236-
237, 282, 308, 384, 390 
Polynomial quadrature, 337 
Poly-t distribution, 122 
Posterior distribution, 9, 21, 137 
conditional, 345, 352 
existence of, 27-28, 36-37 
numerical difficulties with, 24, 
298, 329, 339, 344 
Posterior expectation, 70, 104, 147 
Posterior median, 12, 73 
Posterior mode 137 
Posterior moments, range, 96, 122 
Posterior probabilities, 181, 206, 336 

434 
Subject Index 
range of, 186, 198-205, 207 
Power 
of continuum, 30 
of a test, 190 
Prediction, 19, 74, 143 
Predictive distribution, 143 
Prior distributions, 21 
approximated by mixtures, 110-
111, 330 
axiomatic foundations of, 91-
92, 121 
choice of, 10, 24-25, 53-54, 89, 
106,123,214,291,306,371-
373, 376-379 
conjugate, see Conjugate 
continuous, 183, 221 
depending on the observation, 
97 
depending on the sampling dis-
tribution, 89-90, 98, 115 
exchangeable, 
159, 296, 299, 
301 
generalized, see Improper 
improper, see Improper 
justifications of, 91-92,123,370-
372, 376-379 
minimizing the amount of, 114 
mispecification of, 26, 291, 377 
modified by the inferential prob-
lem, 184, 202-204 
noninformative, see Noninforma-
tive 
parametrized families of, 94-
95 
rejection of prior information for, 
95 
as representations of prior in-
formation, 
9, 25, 89-90, 
115 
role of, 10 
separability of utility and, 46, 
124 
subjective determination of, 93, 
291,372 
uncertainty on, 67, 97, 120 
Prior information see Information 
Prior probabilities, 122 
assessment, 52 
Probabilistic representation, 1-5,370 
Probabilities, upper and lower, 134-
135,291 
Probit model, 128, 320, 368 
Profile likelihood, 140 
Prohorov distance, 109 
Proper distributions, 25-26, 189, 358 
and the Stein effect, 85, 322 
Proper losses, 70, 206, 208 
Proper scoring rule, 81-82 
Pseudo-Bayes estimators, 67, 147, 
173, 310 
Pseudo-random generators, 2, 338-
339, 387-390 
~value, 188, 196-198, 207 
admissibility of, 64, 84, 243-
244 
criticisms, 197-198,201-202 
Quadratic loss, 55, 60, 67, 70-72, 
150, 206, 330 
Quadratic variance function, 
127, 
323-324, 338, 359 
Quantiles, 94,121-122 
Quantum Physics, 10 
Random effects model, 
156, 293-
296,370 
Random walk, 236 
Ranking and selection, 158-161 
Rank tests, 5 
Rao-Blackwell Theorem, 14, 57, 83, 
278, 348-349, 352 
Rare populations, 161 
Rationality axioms, 40, 46, 48 
Reduction of a class of estimators, 
41, 62; see also Invariance 
and Unbiasedness 
Reduction by modeling see Model-
ing 
Reference measure, 94 
Reference priors, 117-120,137,174 
Regression, 155, 294, 316 
Rejection region, 196 
Relevant subsets, 210, 226 
Renormalization, 149 
Reparametrization 289, 358 
natural, 125 
Repeatability of experiments, 
49, 
90,92 

Ridge estimators, 302 
Risk 
aversion, 47-48 
Bayes, 51 
constant, 60, 62, 150, 265, 270, 
278 
frequentist, 49 
integrated, 50 
lover, 47, 70, 149 
minimax, 54 
set, 54-55, 247-249 
vector, 58 
Robustness, 26, 29, 67, 71-72, 75, 
139, 298, 308 
computational aspects of, 122 
under different loss functions, 
75 
of hierarchical Bayes modelings, 
292, 295, 303, 377 
for imprecise prior information, 
90, 96, 98, 120-124, 377 
between prior distributions, 106, 
122 
of Student's t priors, 122, 152 
Saddle-point approximations, 344 
Saint-Petersburg paradox, 40, 47-
48, 80 
Sample-equivalent, 90 
Sampling 
models, 160-166 
sequential, 35, 359 
Scale invariant family, 113, 264, 269 
Scale invariant loss, 148, 172 
Scale parameter, 113, 116, 140 
Scaling 
of distances, 121 
of events, 91-92 
of prior likelihoods, 93 
Scoring rule, 81 
Sculling, 162 
Sensitivity analysis, 90, 120, 377 
Separated zeros theorem, 60 
Separating hyperplane theorem, 59 
Set estimation appraisal, 216-217 
Shakespeare's vocabulary, 166 
Shinozaki's lemma, 85 
Shrinkage estimators, 66, 172, 300; 
see also James-Stein 
Subject Index 
435 
CT-additivity, 91 
CT-algebra, 92, 219 
CT-finite measure, 25 
Significance level, 188-191, 194, 196, 
201 
Simpson paradox, 30, 46 
Simulation methods see Monte Carlo 
Simultaneous equations, 122 
Smoothness, 20 
Social ordering, 46 
Speed of light, 10 
Spherically symmetric distributions, 
29, 67-69, 125, 211, 247, 
308 
Spinning coin experiment, 106-108 
Squared error loss, 12 
asymmetric, 86 
Stationary distribution, 345-347,352 
Statistic 
ancillary, see Ancillary 
complete, see Complete 
definition of, 14 
maximal invariant, 270, 283-
284 
minimal sufficient, 14 
sufficient, 14, 34 
Statistical linguistics, 165 
Stein effect, 65--69,76-78, 147,236, 
278, 281, 373 
Bayesian motivations for, 292, 
313-319 
for Poisson means, 258 
robustness of, 66-69, 307, 325, 
377 
Stein lemma, 85 
Stein sufficient admissibility condi-
tion, 116, 245-246 
Stochastic domination, 76-78 
Stopping rule, 16, 238, 333 
Stopping Rule Principle, 16,31,159, 
378 
STUB (Semi-tail upper bounds), 251-
254 
Student's t-distribution, 152, 382, 
388 
Subjectivity, 
25, 90-97, 282, 291, 
306,330,371,374,377-378 
Suboptimality of Jeffreys priors, 116-
117,282 

436 
Subject Index 
Substitution sampling, 351 
Sufficiency, 14, 31, 278 
and exponential families, 
14, 
99 
for the normal model, 151-152 
Sufficiency Principle, 13-14, 18-19 
Superharmonic functions and mini-
maxity, 305, 327 
Sure loss, 134 
Symmetric distributions, 124 
Symmetry 
of losses, 70, 168 
of parameters and observations, 
8 
Table entry problem, 132 
Tail behavior, 93,109,120-123,152, 
340 
Temporal model, 176, 345 
Tests, 21, 73, 179-209, 3ll, 371 
on the number of components 
of a mixture, 357 
Tobit model, 174 
Total ordering, 42, 46, 49-50, 266 
Total variation norm, III 
Tramcar problem, 3, 160-162, 176 
Transitive group, 269-270, 274 
Translation invariant family, 113 
Tree ordering, 33 
Truncation set, 206-207, 251 
Type I, II errors, 73, 189-190, 197 
UMP (Uniformly most powerful) tests, 
189-196, 373 
UMPU (Uniformly most powerful un-
biased) tests, 189-196,201 
Unbiased estimator of the risk, 67, 
85,304,321 
Unbiasedness, 13, 67, 150, 192, 194 
Uncertainty versus randomness, 9-
10,29,370 
Uniform distribution, 84, 163, 196, 
246, 254, 307, 387 
compatible with prior scaling, 
92 
and order statistics, 102 
as prior distribution, ll-13,19, 
27, 61, 63, ll2, 161 
Uniformly most accurate regions, 210 
Unimodal distributions, 133, 200 
Uninformative settings, 74 
Universal Bayes estimators, 77, 87, 
127 
Universal domination, 76-77 
Utility function, 41-48, 69 
bounded, 45, 79 
linearity of, 47 
infinite, 45, 48 
Utility Theory, 41-48, 180 
axiomatic foundations of, 42 
reduced axiomatic systems for, 
46 
Value 
of a problem, 58 
of sample information, 82 
Variance estimation, 152-155, 315 
Variates, antithetic and control, 341 
Virtual sample, 
90, 98, 105, llO, 
121, 153, 203 
Waiting queue, 55 
Wald complete class theorem, 249 
Weibull distribution, 20, 32, 354-
355 
Wishart distribution, 125, 154, 157, 
366 

Springer Texts in Statistics (continued from page ii) 
Keyfitz 
Kiefer 
Kokoska and Nevison 
Lindman 
Madansky 
McPherson 
Nguyen and Rogers 
Nguyen and Rogers 
Noether 
Peters 
Pfeiffer 
Pitman 
Robert 
Santner and Duffy 
Saville and Wood 
Sen and Srivastava 
Whittle 
Zacks 
Applied Mathematical Demography, 
Second Edition 
Introduction to Statistical Inference 
Statistical Tables and Formulae 
Analysis of Variance in Experimental Design 
Prescriptions for Working Statisticians 
Statistics in Scientific Investigation: Its Basis, 
Application, and Interpretation 
Fundamentals of Mathematical Statistics: 
Volume I: Probability for Statistics 
Fundamentals of Mathematical Statistics: 
Volume II: Statistical Inference 
Introduction to Statistics: 
The Nonparametric Way 
Counting for Something: Statistical Principles 
and Personalities 
Probability for Applications 
Probability 
The Bayesian Choice: A Decision-Theoretic 
Motivation 
The Statistical Analysis of Discrete Data 
Statistical Methods: The Geometric Approach 
Regression Analysis: Theory, Methods, and 
Applications 
Probability via Expectation, Third Edition 
Introduction to Reliability Analysis: Probability 
Models and Statistical Methods 

