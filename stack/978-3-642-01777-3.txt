
Kang Feng 
Mengzhao Qin 
 
 
Symplectic Geometric Algorithms  
for Hamiltonian Systems 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 

Kang Feng 
Mengzhao Qin 
 
 
 
 
Symplectic Geometric  
Algorithms for 
Hamiltonian Systems 
 
 
With 62 Figures 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
                              
ZHEJIANG PUBLISHING UNITED GROUP 
ZHEJIANG SCIENCE AND TECHNOLOGY PUBLISHING HOUSE 

Authors 
Kang Feng (1920-1993)                           
Mengzhao Qin 
Institute of Computational                                  
Institute of Computational 
Mathematics and Scientific/                                 Mathematics and Scientific/ 
Engineering Computing                                       Engineering Computing 
Beijing 100190, China                                          Beijing 100190, China 
                                                                             Email: qmz@lsec.cc.ac.cn 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
ISBN 978-7-5341-3595-8 
Zhejiang Publishing United Group, Zhejiang Science and Technology Publishing House, 
Hangzhou 
 
ISBN 978-3-642-01776-6                                   ISBN 978-3-642-01777-3 (eBook)
Springer Heidelberg Dordrecht London New York 
 
Library of Congress Control Number: 2009930026 
  
 Zhejiang Publishing United Group, Zhejiang Science and Technology Publishing House, 
Hangzhou and Springer-Verlag Berlin Heidelberg 2010 
This work is subject to copyright. All rights are reserved, whether the whole or part of the material 
is concerned, specifically the rights of translation, reprinting, reuse of illustrations, recitation, 
broadcasting, reproduction on microfilm or in any other way, and storage in data banks. 
Duplication of this publication or parts thereof is permitted only under the provisions of the 
German Copyright Law of September 9, 1965, in its current version, and permission for use must 
always be obtained from Springer. Violations are liable to prosecution under the German Copyright 
Law. 
The use of general descriptive names, registered names, trademarks, etc. in this publication does not 
imply, even in the absence of a specific statement, that such names are exempt from the relevant 
protective laws and regulations and therefore free for general use.    
 
Cover design: Frido Steinen-Broo, EStudio Calamar, Spain 
  
Printed on acid-free paper 
  
Springer is part of Springer Science+Business Media (www.springer.com) 

“. . . In the late 1980s Feng Kang pro-
posed and developed so-called symplec-
tic algorithms for solving equations in
Hamiltonian form. Combining theoreti-
cal analysis and computer experimenta-
tion, he showed that such methods, over
long times, are much superior to standard
methods. At the time of his death, he was
at work on extensions of this idea to other
structures . . . ”
Peter Lax
Cited from SIAM News November 1993

Kang Feng giving a talk at an international conference
“ A basic idea behind the design of nu-
merical schemes is that they can preserve
the properties of the original problems as
much as possible . . . Different represen-
tations for the same physical law can lead
to different computational techniques in
solving the same problem, which can pro-
duce different numerical results . . .”
Kang Feng (1920 – 1993)
Cited from a paper entitled “How to compute property Newton’s equation of motion”

Prize certiﬁcate
Author’s photograph taken in Xi’an in 1989

Foreword
Kang Feng (1920–1993), Member of the Chinese Academy of Sciences, Professor and
Honorary Director of the Computing Center of the Chinese Academy of Sciences,
famous applied mathematician, founder and pioneer of computational mathematics
and scientiﬁc computing in China.
It has been 16 years since my brother Kang Feng passed away. His scientiﬁc
achievements have been recognized more and more clearly over time, and his contri-
butions to various ﬁelds have become increasingly outstanding. In the spring of 1997,
Professor Shing-Tung Yau, a winner of the Fields Medal and a foreign member of the
Chinese Academy of Sciences, mentioned in a presentation at Tsinghua University,
entitled “The development of mathematics in China in my view”, that “there are three
main reasons for Chinese modern mathematics to go beyond or hand in hand with
the West. Of course, I am not saying that there are no other works, but I mainly talk
about the mathematics that is well known historically: Professor Shiingshen Chern’s
work on characteristic class, Luogeng Hua’s work on the theory of functions of several
complex variables, and Kang Feng’s work on ﬁnite elements.” This high evaluation of
Kang Feng as a mathematician (not just a computational mathematician) sounds so
refreshing that many people talked about it and strongly agreed with it. At the end
of 1997, the Chinese National Natural Science Foundation presented Kang Feng et
al. with the ﬁrst class prize for his other work on a symplectic algorithm for Hamil-
tonian systems, which is a further recognition of his scientiﬁc achievements (see the
certiﬁcate on the previous page). As his brother, I am very pleased.
Achieving a major scientiﬁc breakthrough is a rare event. It requires vision, ability
and opportunity, all of which are indispensable. Kang Feng has achieved two major
scientiﬁc breakthroughs in his life, both of which are very valuable and worthy of
mention. Firstly, from 1964 to 1965, he proposed independently the ﬁnite element
method and laid the foundation for the mathematical theory. Secondly, in 1984, he
proposed a symplectic algorithm for Hamiltonian systems. At present, scientiﬁc inno-
vation has become the focus of discussion. Kang Feng’s two scientiﬁc breakthroughs
may be treated as case studies in scientiﬁc innovation. It is worth emphasizing that
these breakthroughs were achieved in China by Chinese scientists. Careful study of
these has yet to be carried out by experts. Here I just describe some of my personal
feelings.
It should be noted that these breakthroughs resulted not only from the profound
mathematical knowledge of Kang Feng, but also from his expertise in classical physics
and engineering technology that were closely related to the projects. Scientiﬁc break-
throughs are often cross-disciplinary. In addition, there is often a long period of time
before a breakthrough is made-not unlike a long time it takes for a baby to be born,
which requires the accumulation of results in small steps.

x
Foreword
The opportunity for inventing the ﬁnite element method came from a national re-
search project, a computational problem in the design of the Liu Jia Xia dam. For
such a concrete problem, Kang Feng found a basis for solving of the problem using
his sharp insight. In his view, a discrete computing method for a mathematical and
physical problem is usually carried out in four steps. Firstly, one needs to know and
deﬁne the physical mechanism. Secondly, one writes the appropriate differential equa-
tions accordingly. In the third step, design a discrete model. Finally, one develops the
numerical algorithm. However, due to the complexity of the geometry and physical
conditions, conventional methods cannot always be effective. Nonetheless, starting
from the physical law of conservation or variational principle of the matter, we can
directly relate to the appropriate discrete model. Combining the variational principle
with the spline approximation leads to the ﬁnite element method, which has a wide
range of adaptability and is particularly suited to deal with the complex geometry of
the physical conditions of computational engineering problems. In 1965, Kang Feng
published his paper entitled “Difference schemes based on the variational principle”,
which solved the basic theoretical issues of the ﬁnite element method, such as conver-
gence, error estimation, and stability. It laid the mathematical foundation for the ﬁnite
element method. This paper is the main evidence for recognition by the international
academic community of our independent development of the ﬁnite element method.
After the Chinese Cultural Revolution, he continued his research in ﬁnite element
and related areas. During this period, he made several great achievements. I remem-
ber that he talked with me about other issues, such as Thom’s catastrophe theory,
Prigogine’s theory of dissipative structures, solitons in water waves, the Radon trans-
form, and so on. These problems are related to physics and engineering technology.
Clearly he was exploring for new areas and seeking a breakthrough. In the 1970s,
Arnold’s “Mathematical Method of Classical Mechanics” came out. It described the
symplectic structure for Hamiltonian equations, which proved to be a great inspira-
tion to him and led to a breakthrough. Through his long-term experience in mathe-
matical computation, he fully realized that different mathematical expressions for the
same physical law, which are physically equivalent, can perform different functions
in scientiﬁc computing (his students later called this the “Feng’s major theorem”).
In this way, for classical mechanics, Newton’s equations, Lagrangian equations and
Hamiltonian equations will show a different pattern of calculations after discretiza-
tion. Because the Hamiltonian formulation has a symplectic structure, he was keenly
aware that, if the algorithm can maintain the geometric symmetry of symplecticity, it
will be possible to avoid the ﬂaw of artiﬁcial dissipation of this type of algorithm and
design a high-ﬁdelity algorithm. Thus, he opened up a broad way for the computa-
tional method of the Hamiltonian system. He called this way the “Hamiltonian way”.
This computational method has been used in the calculation of the orbit in celestial
mechanics, in calculations for the particle path in accelerator, as well as in molecular
dynamics. Later, the scope of its application was expanded. For example, it has also
been widely used in studies of the atmosphere and earth sciences and elsewhere. It

Foreword
xi
has been effectively applied in solving the GPS observation operator, indicating that
Global Positioning System data can be dealt with in a timely manner. This algorithm
is 400 times more efﬁcient than the traditional method. In addition, a symplectic al-
gorithm has been successfully used in the oil and gas exploration ﬁelds. Under the
inﬂuence of Kang Feng, international research on symplectic algorithm has become
popular and ﬂourishing, nearly 300 papers have been published in this ﬁeld to date.
Kang Feng’s research work on the symplectic algorithm has been well-known and
recognized internationally for its unique, innovative, systematic and widespread prop-
erties, for its theoretical integrity and fruitful results.
J. Lions, the former President of the International Mathematics Union, spoke at
a workshop when celebrating his 60th birthday: “This is another major innovation
made by Kang Feng, independent of the West, after the ﬁnite element method.” In
1993 one of the world’s leading mathematicians, P.D. Lax, a member of the Ameri-
can Academy of Sciences, wrote a memorial article dedicated to Kang Feng in SIAM
News, stating that “In the late 1980s, Kang Feng proposed and developed so-called
symplectic algorithms for solving evolution equations . . .. Such methods, over a long
period, are much superior to standard methods.” E. J. Marsden, an internationlly well-
known applied mathematician, visited the computing institute in the late 1980s and
had a long conversation with Kang Feng. Soon after the death of Kang Feng, he pro-
posed the multi-symplectic algorithm and extended the characteristics of stability of
the symplectic algorithm for long time calculation of Hamiltonian systems with inﬁ-
nite dimensions.
On the occasion of the commemoration of the 16th anniversary of Kang Feng’s
death and the 89th anniversary of his birth, I think it is especially worthwhile to praise
and promote what was embodied in the lifetime’s work of Kang Feng — “ indepen-
dence in spirit, freedom in thinking”. 1 Now everyone is talking about scientiﬁc inno-
vation, which needs a talented person to accomplish. What type of person is needed
most? A person who is just a parrot or who has an “independent spirit, freely think-
ing”? The conclusion is self-evident. Scientiﬁc innovation requires strong academic
atmosphere. Is it determined by only one person or by all of the team members? This
is also self-evident. From Kang Feng’s scientiﬁc career, we can easily ﬁnd that the key
to the problem of scientiﬁc innovation is “independence in spirit, freedom in thinking”,
and that needs to be allowed to develop and expand.
Kang Feng had planned to write a monograph about a symplectic algorithm for
Hamiltonian systems. He had accumulated some manuscripts, but failed to complete
it because he died too early due to sickness. Fortunately, his students and Professor
Mengzhao Qin (see the photo on the previous page), one of the early collaborators,
spent 15 years and ﬁnally completed this book based on Kang Feng’s plan, realizing
his wish. It is not only an authoritative exposition of this research ﬁeld, but also an
1 Yinke Chen engraved on a stele in 1929 in memory of Guowei Wang in campus of Tsinghua
University.

xii
Foreword
exposure of the academic thought of a master of science, which gives an example of
how an original and innovative scientiﬁc discovery is initiated and developed from
beginning to end in China.
We would also like to thank Zhejiang Science and Technology Publishing House,
which made a great contribution to the Chinese scientiﬁc cause through the publication
of this manuscript.
Although Kang Feng died 16 years ago, his scientiﬁc legacy has been inherited and
developed by the younger generation of scientists. His scientiﬁc spirit and thought still
elicit care, thinking and resonance in us. He is still living in the hearts of us.
Duan, Feng
Member of Chinese
Academy of Sciences
Nanjing University
Nanjing
September 20, 2009

Preface
It has been 16 years since Kang Feng passed away. It is our honor to publish the En-
glish version of Symplectic Algorithm for Hamiltonian Systems, so that more readers
can see the history of the development of symplectic algorithms. In particular, after
the death of Kang Feng, the development of symplectic algorithms became more so-
phisticated and there have been a series of monographs published in this area, e.g.,
Sanz-Serna & M.P. Calvo’s Numerical Hamiltonian Problems published in 1994 by
Chapman and Hall Publishing House; E. Hairer, C. Lubich and G. Wanner’s Geo-
metrical Numerical Integration published in 2001 by Springer Verlag; B. Leimkuhler
and S. Reich’s Simulating Hamiltonian Dynamics published in 2004 by Cambridge
University Press. The symplectic algorithm has been developed from ordinary dif-
ferential equations to partial differential equations, from a symplectic structure to a
multi-symplectic structure. This is largely due to the promotion of this work by J.
Marsden of the USA and T. Bridge and others in Britain. Starting with a symplectic
structure, J. Marsden ﬁrst developed the Lagrange symplectic structure, and then to
the multi-symplectic structure. He ﬁnally proposed a symplectic structure that meets
the requirement of the Lagrangian form from the variational principle by giving up
the boundary conditions. On the other hand, T. Bridge and others used the multi-
symplectic structure to derive directly the multi-symplectic Hamilton equations, and
then constructed the difference schemes that preserve the symplectic structure in both
time and space. Both methods can be regarded as equivalent in the algorithmic sense.
Now, in this monograph, most of the content refers only to ordinary differential
equations. Kang Feng and his algorithms research group working on the symplectic
algorithm did some foundation work. In particular, I would like to point out three nega-
tive theorems: “ non-existence of energy preserving scheme”, “ non-existence of mul-
tistep linear symplectic scheme”, and “ non-existence of volume-preserving scheme
form rational fraction expression”. In addition, generating function theory is not only
rich in analytical mechanics and Hamilton–Jacobi equations. At the same time, the
construction of symplectic schemes provides a tool for any order accuracy difference
scheme. The formal power series proposed by Kang Feng had a profound impact on
the later developed “ backward error series” work ,“ modiﬁed equation” and “ modiﬁed
integrator”.
The symplectic algorithm developed very quickly, soon to be extended to the ge-
ometric method. The structure preserving algorithm (not only preserving the geomet-
rical structure, but also the physical structure, etc.) preserves the algebraic structure
to present the Lie group algorithm, and preserves the differential complex algorithm.
Many other prominent people have contributed to the symplectic method in addition
to those mentioned above. There are various methods related to structure preserving
algorithms and for important contributions the readers are referred to R. McLach-
lan & GRW Quispel “ Geometric integration for ODEs” and T. Bridges & S. Reich
“ Numerical methods for Hamiltonian PDEs”.
The book describes the symplectic geometric algorithms and theoretical basis for
a number of related algorithms. Most of the contents are a collection of lectures given

xiv
Preface
by Kang Feng at Beijing University. Most of other sections are a collection of papers
which were written by group members.
Compared to the previous Chinese version, the present English one has been im-
proved in the following respects. First of all, to correct a number of errors and mis-
takes contained in the Chinese version. Besides, parts of Chapter 1 and Chapter 2
were removed, while some new content was added to Chapter 4, Chapter 7, Chapter
8, Chapter 9 and Chapter 10. More importantly, four new chapters — Chapter 13 to
Chapter 16 were added. Chapter 13 is devoted to the KAM theorem for the symplectic
algorithm. We invited Professor Zaijiu Shang , a former PhD student of Kang Feng
to compose this chapter. Chapter 14 is called Variational Integrator. This chapter re-
ﬂects the work of the Nobel Prize winner Professor Zhengdao Li who proposed in
the 1980s to preserve the energy variational integrator, but had not explained at that
time that it had a Lagrange symplectic type, which satisﬁed the Lagrange symplectic
structure. Together with J. Marsden he proposed the variational integrator trail con-
nection, which leads from the variational integrator. Just like J. Marsden, he hoped
this can link up with the ﬁnite element method. Chapter 15 is about Birkhofﬁan Sys-
tems, describing a class of dissipative structures for Birkohofﬁan systems to preserve
the dissipation of the Birkhoff structure. Chapter 16 is devoted to Multisymplectic
and Variational Integrators, providing a summary of the widespread applications of
multisymplectic integrators in the inﬁnitely dimensional Hamiltonian systems.
We would also like to thank every member of the Kang Feng’s research group
for symplectic algorithms: Huamo Wu, Daoliu Wang, Zaijiu Shang, Yifa Tang, Jialin
Hong, Wangyao Li, Min Chen, Shuanghu Wang, Pingfu Zhao, Jingbo Chen, Yushun
Wang, Yajuan Sun, Hongwei Li, Jianqiang Sun, Tingting Liu, Hongling Su, Yimin
Tian; and those who have been to the USA: Zhong Ge, Chunwang Li, Yuhua Wu,
Meiqing Zhang, Wenjie Zhu, Shengtai Li, Lixin Jiang, and Haibin Shu. They made
contributions to the symplectic algorithm over different periods of time.
The authors would also like to thank the National Natural Science Foundation, the
National Climbing Program projects, and the State’s Key Basic Research Projects for
their ﬁnancial support. Finally, the authors would also like to thank the Mathematics
and Systems Science Research Institute of the Chinese Academy of Sciences, the
Computational Mathematics and Computational Science and Engineering Institute,
and the State Key Laboratory of Computational Science and Engineering for their
support.
The editors of this book have received help from E. Hairer, who provided a tem-
plate from Springer publishing house. I would also like to thank F. Holzwarth at
Springer publishing house and Linbo Zhang of our institute, and others who helped
me successfully publish this book.
For the English translation, I thank Dr. Shengtai Li for comprehensive proof-
reading and polishing, and the editing of Miss Yi Jin. For the English version of the
publication I would also like to thank the help of the Chinese Academy of Sciences
Institute of Mathematics. Because Kang Feng has passed away, it may not be possible
to provide a comprehensive representation of his academic thought, and the book will
inevitably contain some errors. I accept the responsibility for any errors and welcome
criticism and corrections.

Preface
xv
We would also like to thank Springer Beijing Representation Ofﬁce and Zhejiang
Science and Technology Publishing House, which made a great contribution to the
Chinese scientiﬁc cause through the publication of this manuscript. We are especially
grateful to thank Lisa Fan, W. Y. Zhou, L. L. Liu and X. M. Lu for carefully reading
and ﬁnding some misprints, wrong signs and other mistakes.
This book is supported by National Natural Science Foundation of China under
grant No.G10871099 ; supported by the Project of National 863 Plan of China (grant
No.2006AA09A102-08); and supported by the National Basic Research Program of
China (973 Program) (Grant No. 2007CB209603).
Mengzhao Qin
Institute of Computational
Mathematics and Scientiﬁc
Engineering Computing
Beijing
September 20, 2009

Contents
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1
Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 35
1.
Preliminaries of Differentiable Manifolds. . . . . . . . . . . . . . . . . . . . . . . . . 39
1.1
Differentiable Manifolds. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40
1.1.1
Differentiable Manifolds and Differentiable Mapping . . . . 40
1.1.2
Tangent Space and Differentials . . . . . . . . . . . . . . . . . . . . . . 43
1.1.3
Submanifolds . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 46
1.1.4
Submersion and Transversal . . . . . . . . . . . . . . . . . . . . . . . . . 51
1.2
Tangent Bundle . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 56
1.2.1
Tangent Bundle and Orientation . . . . . . . . . . . . . . . . . . . . . . 56
1.2.2
Vector Field and Flow . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 62
1.3
Exterior Product . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 64
1.3.1
Exterior Form . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 66
1.3.2
Exterior Algebra. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 68
1.4
Foundation of Differential Form . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 75
1.4.1
Differential Form . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 76
1.4.2
The Behavior of Differential Forms under Maps . . . . . . . . 80
1.4.3
Exterior Differential. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 82
1.4.4
Poincar´e Lemma and Its Inverse Lemma. . . . . . . . . . . . . . . 84
1.4.5
Differential Form in R3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . 86
1.4.6
Hodge Duality and Star Operators . . . . . . . . . . . . . . . . . . . . 88
1.4.7
Codifferential Operator δ . . . . . . . . . . . . . . . . . . . . . . . . . . . 89
1.4.8
Laplace–Beltrami Operator. . . . . . . . . . . . . . . . . . . . . . . . . . 90
1.5
Integration on a Manifold . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 91
1.5.1
Geometrical Preliminary . . . . . . . . . . . . . . . . . . . . . . . . . . . . 91
1.5.2
Integration and Stokes Theorem . . . . . . . . . . . . . . . . . . . . . . 93
1.5.3
Some Classical Theories on Vector Analysis . . . . . . . . . . . 96
1.6
Cohomology and Homology . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 98
1.7
Lie Derivative. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 99
1.7.1
Vector Fields as Differential Operator . . . . . . . . . . . . . . . . . 99
1.7.2
Flows of Vector Fields . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 101
1.7.3
Lie Derivative and Contraction . . . . . . . . . . . . . . . . . . . . . . . 103
Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 111

xviii
Contents
2.
Symplectic Algebra and Geometry Preliminaries . . . . . . . . . . . . . . . . . . 113
2.1
Symplectic Algebra and Orthogonal Algebra . . . . . . . . . . . . . . . . . . . 113
2.1.1
Bilinear Form . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 113
2.1.2
Sesquilinear Form . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 116
2.1.3
Scalar Product, Hermitian Product . . . . . . . . . . . . . . . . . . . . 117
2.1.4
Invariant Groups for Scalar Products . . . . . . . . . . . . . . . . . . 119
2.1.5
Real Representation of Complex Vector Space . . . . . . . . . 121
2.1.6
Complexiﬁcation of Real Vector Space and Real Linear
Transformation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 123
2.1.7
Lie Algebra for GL(n, F) . . . . . . . . . . . . . . . . . . . . . . . . . . . 124
2.2
Canonical Reductions of Bilinear Forms . . . . . . . . . . . . . . . . . . . . . . 128
2.2.1
Congruent Reductions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 129
2.2.2
Congruence Canonical Forms of Conformally Symmet-
ric and Hermitian Matrices . . . . . . . . . . . . . . . . . . . . . . . . . . 130
2.2.3
Similar Reduction to Canonical Forms under Orthogo-
nal Transformation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 134
2.3
Symplectic Space. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 137
2.3.1
Symplectic Space and Its Subspace . . . . . . . . . . . . . . . . . . . 137
2.3.2
Symplectic Group . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 144
2.3.3
Lagrangian Subspaces . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 147
2.3.4
Special Types of Sp(2n) . . . . . . . . . . . . . . . . . . . . . . . . . . . . 148
2.3.5
Generators of Sp(2n) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 155
2.3.6
Eigenvalues of Symplectic and Inﬁnitesimal Matrices . . . 158
2.3.7
Generating Functions for Lagrangian Subspaces . . . . . . . . 160
2.3.8
Generalized Lagrangian Subspaces . . . . . . . . . . . . . . . . . . . 162
Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 164
3.
Hamiltonian Mechanics and Symplectic Geometry . . . . . . . . . . . . . . . . . 165
3.1
Symplectic Manifold . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 165
3.1.1
Symplectic Structure on Manifolds . . . . . . . . . . . . . . . . . . . 165
3.1.2
Standard Symplectic Structure on Cotangent Bundles. . . . 166
3.1.3
Hamiltonian Vector Fields . . . . . . . . . . . . . . . . . . . . . . . . . . 167
3.1.4
Darboux Theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 168
3.2
Hamiltonian Mechanics on R2n . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 168
3.2.1
Phase Space on R2n and Canonical Systems . . . . . . . . . . . 169
3.2.2
Canonical Transformation . . . . . . . . . . . . . . . . . . . . . . . . . . 172
3.2.3
Poisson Bracket . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 177
3.2.4
Generating Functions. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 180
3.2.5
Hamilton–Jacobi Equations . . . . . . . . . . . . . . . . . . . . . . . . . 182
Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 185
4.
Symplectic Difference Schemes for Hamiltonian Systems. . . . . . . . . . . . 187
4.1
Background . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 187
4.1.1
Element and Notation for Hamiltonian Mechanics . . . . . . 187

Contents
xix
4.1.2
Geometrical Meaning of Preserving Symplectic Struc-
ture ω . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 189
4.1.3
Some Properties of a Symplectic Matrix . . . . . . . . . . . . . . . 190
4.2
Symplectic Schemes for Linear Hamiltonian Systems . . . . . . . . . . . 192
4.2.1
Some Symplectic Schemes for Linear Hamiltonian Sys-
tems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 192
4.2.2
Symplectic Schemes Based on Pad´e Approximation . . . . . 193
4.2.3
Generalized Cayley Transformation and Its Application . . 197
4.3
Symplectic Difference Schemes for a Nonlinear Hamiltonian Sys-
tem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 200
4.4
Explicit Symplectic Scheme for Hamiltonian System . . . . . . . . . . . . 203
4.4.1
Systems with Nilpotent of Degree 2 . . . . . . . . . . . . . . . . . . 204
4.4.2
Symplectically Separable Hamiltonian Systems. . . . . . . . . 205
4.4.3
Separability of All Polynomials in R2n . . . . . . . . . . . . . . . 207
4.5
Energy-conservative Schemes by Hamiltonian Difference . . . . . . . . 209
Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 211
5.
The Generating Function Method . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 213
5.1
Linear Fractional Transformation . . . . . . . . . . . . . . . . . . . . . . . . . . . . 213
5.2
Symplectic, Gradient Mapping and Generating Function . . . . . . . . 215
5.3
Generating Functions for the Phase Flow . . . . . . . . . . . . . . . . . . . . . 221
5.4
Construction of Canonical Difference Schemes . . . . . . . . . . . . . . . . . 226
5.5
Further Remarks on Generating Function . . . . . . . . . . . . . . . . . . . . . . 231
5.6
Conservation Laws . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 234
5.7
Convergence of Symplectic Difference Schemes . . . . . . . . . . . . . . . . 239
5.8
Symplectic Schemes for Nonautonomous System . . . . . . . . . . . . . . . 242
Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 247
6.
The Calculus of Generating Functions and Formal Energy . . . . . . . . . . 249
6.1
Darboux Transformation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 249
6.2
Normalization of Darboux Transformation. . . . . . . . . . . . . . . . . . . . . 251
6.3
Transform Properties of Generator Maps and Generating Functions 255
6.4
Invariance of Generating Functions and Commutativity of Gener-
ator Maps . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 261
6.5
Formal Energy for Hamiltonian Algorithm . . . . . . . . . . . . . . . . . . . . 264
6.6
Ge–Marsden Theorem. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 273
Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 275
7.
Symplectic Runge–Kutta Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 277
7.1
Multistage Symplectic Runge–Kutta Method . . . . . . . . . . . . . . . . . . . 277
7.1.1
Deﬁnition and Properties of Symplectic R–K Method. . . . 277
7.1.2
Symplectic Conditions for R–K Method . . . . . . . . . . . . . . . 281
7.1.3
Diagonally Implicit Symplectic R–K Method . . . . . . . . . . 284
7.1.4
Rooted Tree Theory . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 288
7.1.5
Simpliﬁed Conditions for Symplectic R–K Method . . . . . 297

xx
Contents
7.2
Symplectic P–R–K Method . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 302
7.2.1
P–R–K Method . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 302
7.2.2
Sympliﬁed Order Conditions of Explicit Symplectic R–K
Method . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 307
7.3
Symplectic R–K–N Method . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 319
7.3.1
Order Conditions for Symplectic R–K–N Method . . . . . . . 319
7.3.2
The 3-Stage and 4-th order Symplectic R–K–N Method . 323
7.3.3
Sympliﬁed Order Conditions for Symplectic R–K–N
Method . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 327
7.4
Formal Energy for Symplectic R–K Method . . . . . . . . . . . . . . . . . . . 333
7.4.1
Modiﬁed Equation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 334
7.4.2
Formal Energy for Symplectic R–K Method . . . . . . . . . . . 339
7.5
Deﬁnition of a(t) and b(t) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 345
7.5.1
Centered Euler Scheme . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 345
7.5.2
Gauss–Legendre Method . . . . . . . . . . . . . . . . . . . . . . . . . . . 346
7.5.3
Diagonal Implicit R–K Method . . . . . . . . . . . . . . . . . . . . . . 347
7.6
Multistep Symplectic Method . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 347
7.6.1
Linear Multistep Method. . . . . . . . . . . . . . . . . . . . . . . . . . . . 347
7.6.2
Symplectic LMM for Linear Hamiltonian Systems . . . . . . 348
7.6.3
Rational Approximations to Exp and Log Function . . . . . . 352
Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 357
8.
Composition Scheme . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 365
8.1
Construction of Fourth Order with 3-Stage Scheme . . . . . . . . . . . . . 365
8.1.1
For Single Equation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 365
8.1.2
For System of Equations . . . . . . . . . . . . . . . . . . . . . . . . . . . . 370
8.2
Adjoint Method and Self-Adjoint Method . . . . . . . . . . . . . . . . . . . . . 372
8.3
Construction of Higher Order Schemes . . . . . . . . . . . . . . . . . . . . . . . 377
8.4
Stability Analysis for Composition Scheme . . . . . . . . . . . . . . . . . . . . 388
8.5
Application of Composition Schemes to PDE . . . . . . . . . . . . . . . . . . 396
8.6
H-Stability of Hamiltonian System . . . . . . . . . . . . . . . . . . . . . . . . . . . 401
Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 405
9.
Formal Power Series and B-Series . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 407
9.1
Notation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 407
9.2
Near-0 and Near-1 Formal Power Series . . . . . . . . . . . . . . . . . . . . . . . 409
9.3
Algorithmic Approximations to Phase Flows . . . . . . . . . . . . . . . . . . . 414
9.3.1
Approximations of Phase Flows and Numerical Method . 414
9.3.2
Typical Algorithm and Step Transition Map . . . . . . . . . . . . 415
9.4
Related B-Series Works . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 417
9.4.1
The Composition Laws . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 418
9.4.2
Substitution Law . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 432
9.4.3
The Logarithmic Map . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 434
Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 441

Contents
xxi
10.
Volume-Preserving Methods for Source-Free Systems . . . . . . . . . . . . . . 443
10.1
Liouville’s Theorem . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 443
10.2
Volume-Preserving Schemes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 444
10.2.1
Conditions for Centered Euler Method to be Volume
Preserving . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 444
10.2.2
Separable Systems and Volume-Preserving Explicit Meth-
ods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 447
10.3
Source-Free System. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 449
10.4
Obstruction to Analytic Methods . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 450
10.5
Decompositions of Source-Free Vector Fields . . . . . . . . . . . . . . . . . . 452
10.6
Construction of Volume-Preserving Schemes. . . . . . . . . . . . . . . . . . . 454
10.7
Some Special Discussions for Separable Source-Free Systems . . . . 458
10.8
Construction of Volume-Preserving Scheme via Generating Func-
tion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 460
10.8.1
Fundamental Theorem. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 460
10.8.2
Construction of Volume-Preserving Schemes . . . . . . . . . . . 464
10.9
Some Volume-Preserving Algorithms . . . . . . . . . . . . . . . . . . . . . . . . . 467
10.9.1
Volume-Preserving R–K Methods . . . . . . . . . . . . . . . . . . . . 467
10.9.2
Volume-Preserving 2-Stage P–R–K Methods . . . . . . . . . . . 471
10.9.3
Some Generalizations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 473
10.9.4
Some Explanations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 474
Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 476
11.
Contact Algorithms for Contact Dynamical Systems . . . . . . . . . . . . . . . 477
11.1
Contact Structure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 477
11.1.1
Basic Concepts of Contact Geometry . . . . . . . . . . . . . . . . . 477
11.1.2
Contact Structure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 480
11.2
Contactization and Symplectization . . . . . . . . . . . . . . . . . . . . . . . . . . 484
11.3
Contact Generating Functions for Contact Maps . . . . . . . . . . . . . . . . 488
11.4
Contact Algorithms for Contact Systems . . . . . . . . . . . . . . . . . . . . . . 492
11.4.1
Q Contact Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 493
11.4.2
P Contact Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 493
11.4.3
C Contact Algorithm . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 493
11.5
Hamilton–Jacobi Equations for Contact Systems . . . . . . . . . . . . . . . 494
Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 497
12.
Poisson Bracket and Lie–Poisson Schemes . . . . . . . . . . . . . . . . . . . . . . . . 499
12.1
Poisson Bracket and Lie–Poisson Systems . . . . . . . . . . . . . . . . . . . . . 499
12.1.1
Poisson Bracket . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 499
12.1.2
Lie–Poisson Systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 501
12.1.3
Introduction of the Generalized Rigid Body Motion . . . . . 505
12.2
Constructing Difference Schemes for Linear Poisson Systems . . . . 507
12.2.1
Constructing Difference Schemes for Linear Poisson
Systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 508

xxii
Contents
12.2.2
Construction of Difference Schemes for General Pois-
son Manifold . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 509
12.2.3
Answers of Some Questions . . . . . . . . . . . . . . . . . . . . . . . . . 511
12.3
Generating Function and Lie–Poisson Scheme . . . . . . . . . . . . . . . . . 514
12.3.1
Lie–Poisson–Hamilton–Jacobi (LPHJ) Equation and Gen-
erating Function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 514
12.3.2
Construction of Lie–Poisson Schemes via Generating
Function . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 519
12.4
Construction of Structure Preserving Schemes for Rigid Body . . . . 523
12.4.1
Rigid Body in Euclidean Space . . . . . . . . . . . . . . . . . . . . . . 523
12.4.2
Energy-Preserving and Angular Momentum-Preserving
Schemes for Rigid Body . . . . . . . . . . . . . . . . . . . . . . . . . . . . 525
12.4.3
Orbit-Preserving and Angular-Momentum-Preserving Ex-
plicit Scheme . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 527
12.4.4
Lie–Poisson Schemes for Free Rigid Body . . . . . . . . . . . . 530
12.4.5
Lie–Poisson Scheme on Heavy Top . . . . . . . . . . . . . . . . . . . 535
12.4.6
Other Lie–Poisson Algorithm . . . . . . . . . . . . . . . . . . . . . . . . 538
12.5
Relation Among Some Special Group and Its Lie Algebra . . . . . . . . 543
12.5.1
Relation Among SO(3), so(3) and SH1, SU(2) . . . . . . . 543
12.5.2
Representations of Some Functions in SO(3) . . . . . . . . . . 545
Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 547
13.
KAM Theorem of Symplectic Algorithms . . . . . . . . . . . . . . . . . . . . . . . . 549
13.1
Brief Introduction to Stability of Geometric Numerical Algorithms 549
13.2
Mapping Version of the KAM Theorem . . . . . . . . . . . . . . . . . . . . . . 551
13.2.1
Formulation of the Theorem . . . . . . . . . . . . . . . . . . . . . . . . . 551
13.2.2
Outline of the Proof of the Theorems . . . . . . . . . . . . . . . . . 554
13.2.3
Application to Small Twist Mappings . . . . . . . . . . . . . . . . . 558
13.3
KAM Theorem of Symplectic Algorithms for Hamiltonian Systems559
13.3.1
Symplectic Algorithms as Small Twist Mappings . . . . . . . 560
13.3.2
Numerical Version of KAM Theorem . . . . . . . . . . . . . . . . . 564
13.4
Resonant and Diophantine Step Sizes . . . . . . . . . . . . . . . . . . . . . . . . . 568
13.4.1
Step Size Resonance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 568
13.4.2
Diophantine Step Sizes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 569
13.4.3
Invariant Tori and Further Remarks . . . . . . . . . . . . . . . . . . . 574
Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 578
14.
Lee-Variational Integrator . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 581
14.1
Total Variation in Lagrangian Formalism . . . . . . . . . . . . . . . . . . . . . . 581
14.1.1
Variational Principle in Lagrangian Mechanics . . . . . . . . . 581
14.1.2
Total Variation for Lagrangian Mechanics . . . . . . . . . . . . . 583
14.1.3
Discrete Mechanics and Variational Integrators . . . . . . . . . 586
14.1.4
Concluding Remarks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 591
14.2
Total Variation in Hamiltonian Formalism . . . . . . . . . . . . . . . . . . . . . 591
14.2.1
Variational Principle in Hamiltonian Mechanics . . . . . . . . 591

Contents
xxiii
14.2.2
Total Variation in Hamiltonian Mechanics . . . . . . . . . . . . . 593
14.2.3
Symplectic-Energy Integrators . . . . . . . . . . . . . . . . . . . . . . . 596
14.2.4
High Order Symplectic-Energy Integrator . . . . . . . . . . . . . 600
14.2.5
An Example and an Optimization Method . . . . . . . . . . . . . 603
14.2.6
Concluding Remarks . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 605
14.3
Discrete Mechanics Based on Finite Element Methods. . . . . . . . . . . 606
14.3.1
Discrete Mechanics Based on Linear Finite Element. . . . . 606
14.3.2
Discrete Mechanics with Lagrangian of High Order . . . . . 608
14.3.3
Time Steps as Variables . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 613
14.3.4
Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 614
Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 615
15.
Structure Preserving Schemes for Birkhoff Systems . . . . . . . . . . . . . . . . 617
15.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 617
15.2
Birkhofﬁan Systems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 618
15.3
Generating Functions for K(z, t)-Symplectic Mappings . . . . . . . . . 621
15.4
Symplectic Difference Schemes for Birkhofﬁan Systems . . . . . . . . . 625
15.5
Example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 629
15.6
Numerical Experiments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 634
Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 639
16.
Multisymplectic and Variational Integrators . . . . . . . . . . . . . . . . . . . . . . 641
16.1
Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 641
16.2
Multisymplectic Geometry and Multisymplectic Hamiltonian Sys-
tems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 642
16.3
Multisymplectic Integrators and Composition Methods . . . . . . . . . . 646
16.4
Variational Integrators . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 652
16.5
Some Generalizations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 654
Bibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 658
Symbol . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 663
Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 669

Introduction
The main theme of modern scientiﬁc computing is the numerical solution of various
differential equations of mathematical physics bearing the names, such as Newton, Eu-
ler, Lagrange, Laplace, Navier–Stokes, Maxwell, Boltzmann, Einstein, Schr¨odinger,
Yang-Mills, etc. At the top of the list is the most celebrated Newton’s equation of mo-
tion. The historical, theoretical and practical importance of Newton’s equation hardly
needs any comment, so is the importance of the numerical solution of such equations.
On the other hand, starting from Euler, right down to the present computer age, a
great wealth of scientiﬁc literature on numerical methods for differential equations
has been accumulated, and a great variety of algorithms, software packages and even
expert systems has been developed. With the development of the modern mechanics,
physics, chemistry, and biology, it is undisputed that almost all physical processes,
whether they are classical, quantum, or relativistic, can be represented by an Hamilto-
nian system. Thus, it is important to solve the Hamiltonian system correctly.
1.
Numerical Method for the Newton Equation of Mo-
tion
In the spring of 1991, the ﬁrst author [Fen92b] presented a plenary talk on how to com-
pute the numerical solution of Newton classical equation accurately at the Annual
Physics Conference of China in Beijing.
It is well known that numerically solving so-called mathematics-physics equa-
tions has become a main topic in modern scientiﬁc computation. The Newton equation
of motion is one of the most popular equations among various mathematics-physics
equations. It can be formulated as a group of second-order ordinary differential equa-
tions, f = ma = m¨x. The computational methods of the differential equations ad-
vanced slowly in the past due to the restriction of the historical conditions. However, a
great progress was made since Euler, due to contributions from Adams, Runge, Kutta,
and St¨omer, etc.. This is especially true since the introduction of the modern com-
puter for which many algorithms and software packages have been developed. It is
said that the three-body problem is no longer a challenging problem and can be easily
computed. Nevertheless, we propose the following two questions:
1◦
Are the current numerical algorithms suitable for solving the Newton equa-
tion of motion?
2◦
How can one calculate the Newton equation of motion more accurately?
It seems that nobody has ever thought about the ﬁrst issue seriously, which may be
the reason why the second issue has never been studied systematically. In this book, we
will study mainly the fundamental but more difﬁcult Newton equation of motion that
is in conservative form. First, the conservative Newton equation has two equivalent
mathematical representations: a Lagrange variation form and a Hamiltonian form. The

2
Introduction
latter transforms the second-order differential equations in physical space into a group
of the ﬁrst-order canonical equations in phase space. Different representations for
the same physical law can lead to different computational techniques in solving
the same problem, which can produce different numerical results. Thus making a
wise and reasonable choice among various equivalent mathematical representations is
extremely important in solving the problem correctly.
We choose the Hamiltonian formulation as our basic form in practice based on the
fact that the Hamiltonian equations have symmetric and clean form, where the physical
laws of the motion can be easily represented. Secondly, the Hamiltonian formulation
is more general and universal than the Newton formulation. It can cover the classical,
relativistic, quantum, ﬁnite or inﬁnite dimensional real physical processes where dis-
sipation effect can be neglected. Therefore, the success of the numerical methods for
Hamiltonian equations has broader development and application perspectives. Thus, it
is very surprising that the numerical algorithms for Hamiltonian equations are almost
nonexistent after we have searched various publications. This motivates us to study
the problem carefully to seek the answers to the previous two questions.
Our approach is to use the symplectic geometry, which is the geometry in phase
space. It is based on the anti-symmetric area metric, which is in contrast to the sym-
metric length metrics of Euclid and Riemann geometry. The basic theorem of the clas-
sic mechanics can be described as “the dynamic evolution of all Hamiltonian systems
preserves the symplectic metrics, which means it is a symplectic (canonical) transfor-
mation”. Hence the correct discretization algorithms to all the Hamiltonian systems
should be symplectic transformation. Such algorithms are called symplectic (canoni-
cal) algorithms or Hamiltonian algorithms. We have intentionally analyzed and eval-
uated the derivation of the Hamiltonian algorithm within the symplectic structures.
The fact proved that this approach is correct and fruitful. We have derived a series of
symplectic algorithms, found out their properties, laid out their theoretical foundation,
and tested them with extremely difﬁcult numerical experiments.
In order to compare the symplectic and non-symplectic algorithm, we proposed
eight numerical experiments: harmonic oscillator, nonlinear Dufﬁng oscillator, Huy-
gens oscillator, Cassini oscillator, two dimensional multi-crystal and semi-crystal lat-
tice steady ﬂow, Lissajous image, geodesic ﬂow on ellipsoidal surface, and Kepler
motion. The numerical experiments demonstrate the superiority of the symplectic al-
gorithm. All traditional non-symplectic algorithms fail without exception, especially
in preserving global property and structural property, and long-term tracking capabil-
ity, regardless of their accuracy. However, all the symplectic algorithms passed the
tests with long-term stable tracking capability. These tests clearly demonstrate the su-
periority of the symplectic algorithms.
Almost all of the traditional algorithms are non-symplectic with few exceptions.
They are designed for the asymptotic stable system which has dissipation mechanism
to maintain stability, whereas the Hamiltonian system does not have the asymptotic
stability. Hence all these algorithms inevitably contain artiﬁcial numerical dissipation,
fake attractors, and other parasitics effects of non-Hamiltonian system. All these ef-
fects lead to seriously twist and serious distortion in numerical results. They can be
used in short-term transient simulation, but are not suitable and can lead to wrong

Introduction
3
conclusions for long-term tracking and global structural property research. Since the
Newton equation is equivalent to Hamiltonian equation, the answer to the ﬁrst ques-
tion is “No”, which is quite beyond expectation.
The symplectic algorithm does not have any artiﬁcial dissipation so that it can con-
genitally avoid all non-symplectic pollution and become a “clean” algorithm. Hamil-
tonian system has two types of conservation laws: one is the area invariance in phase
space, i.e., Liouville–Poincar´e conservation law; the other is the motion invariance
which includes energy conservation, momentum and angular momentum conserva-
tion, etc. We have proved that all symplectic algorithms have their own invariance,
which has the same convergence to the original theoretical invariance as the conver-
gence order of the numerical algorithm. We have also proved that the majority of in-
variant tori of the near integrable system can be preserved, which is a new formulation
of the famous KAM (Kolmogorov–Arnorld–Moser) theorem[Kol54b,Kol54a,Arn63,Mos62].
All of these results demonstrate that the structure of the discrete Hamiltonian algo-
rithm is completely parallel to the conservation law, and is very close to the original
form of the Hamiltonian system. Moreover, theoretically speaking, it has inﬁnite long-
term tracking capability. Hence, a correct numerical method to solve the Newton equa-
tion is to Hamiltonize the equation ﬁrst and then use the Hamiltonian algorithm. This
is the answer to the second question. We will describe in more detail the KAM theory
of symplectic algorithms for Hamiltonian systems in Chapter 13. In the following we
present some examples to compare the symplectic algorithm and other non-symplectic
algorithms in solving Newton equation of motion.
(1)
Calculation of the Harmonic oscillator’s elliptic orbit
Calculation of the Harmonic oscillator’s elliptic orbit (Fig. 0.1(a)) uses Runge–Kutta
method (R–K) with a step size 0.4. The output is at 3,000 steps. It shows artiﬁcial
dissipation, shrinking of the orbit. Fig. 0.1(b) shows the results using Adams method
with a step size 0.2. It is anti-dissipative and the orbit is scattered out. Fig. 0.1(c)
shows the results of two-step central difference (leap-frog scheme). This scheme is
symplectic to linear equations. The results are obtained with a step size 0.1. It shows
that the results of three stages for 10,000,000 steps: the initial 1,000 steps, the middle
1,000 steps, and the ﬁnal 1,000 steps. They are completely in agreement.
(2)
The elliptic orbit for the nonlinear oscillator
Fig. 0.2(a) shows the results of two-step central-difference. This scheme is non-
symplectic for nonlinear equations. The output is for step size 0.2 and 10,000 steps.
Fig. 0.2(a) shows the initial 1,000 steps and Fig. 0.2(b) shows the results between
9,000 to 10,000 steps. Both of them show the distortion of the orbit. Fig. 0.2(c) is for
the second-order symplectic algorithm with 0.1 step size, 1,000 steps.

4
Introduction
Fig. 0.1.
Calculation of the Harmonic oscillator’s elliptic orbit
Fig. 0.2.
Calculation of the nonlinear oscillator’s elliptic orbit

Introduction
5
Fig. 0.3.
Calculation of the nonlinear Huygens oscillator
(3)
The oval orbit of the Huygens oscillator
Using the R–K method, the two ﬁxed points on the horizontal axes become two fake
attractors. The probability of the phase point close to the two attractors is the same.
The same initial point outside the separatrix is attracted randomly either to the left
or to the right. Fig. 0.3(a) shows the results with a step size 0.10000005 and 900,000
steps, which approach the left attractor. Fig. 0.3(b) shows the results with a step size
0.10000004 and 900,000 steps, which approach the right attractor. Fig. 0.3(c) shows
the results of the second-order symplectic algorithm with a step size 0.1. Four typical
orbits are plotted and each contains 100,000,000 steps: for every orbit ﬁrst 500 steps,
the middle 500 steps, and the ﬁnal 500 steps. They are in complete agreement.
(4)
The dense orbit of the geodesic for the ellipsoidal surface
The dense orbit of the geodesic for the ellipsoidal surface with irrational frequency ra-
tio. The square of frequency ratio is 5/16, step size is 0.05658, 10,000 steps. Fig.0.4(a)
is for the R–K method which does not tend to dense. Fig. 0.4(b) is for the symplectic
algorithm which tends to dense.

6
Introduction
Fig. 0.4.
Geodesics on ellipsoid, frequency ratio
√
5 : 4, non dense (a), dense orbit (b)
(5)
The close orbit of the geodesic for the ellipsoidal surface
The close orbit of the geodesic for the ellipsoidal surface with rational frequency
ratio. The frequency ratio is 11/16, step size is 0.033427, 100,000 steps and 25 cycles.
Fig.0.5(a) is for the R–K method which does not lead to the close orbit. Fig. 0.5(b) is
for the symplectic algorithm which leads to the close orbit.
Fig. 0.5.
Geodesics on ellipsoid, frequency ratio 11:16, non closed (a), closed orbit (b)
(6)
The close orbit of the Keplerian motion
The close orbit of the Keplerian motion with rational frequency ratio. The frequency
ratio is 11/20, step size is 0.01605, 240,000 steps and 60 cycles. Fig. 0.6(a) is for the
R–K method which does not lead to the close orbit. Fig. 0.6(b)is for the symplectic
method which leads to the close orbit.

Introduction
7
Fig. 0.6.
Geodesics on ellipsoid, frequency ratio 11:20, non closed (a), closed orbit (b)
2.
History of the Hamiltonian Mechanics
We ﬁrst consider the three formulations of the classical mechanics. Assume a motion
has n degrees of freedom. The position is denoted as q = (q1, · · · , qn). The potential
function is V = V (q). Then we have
md2 q
d t2 = −∂
∂q V,
which is the standard formulation of the motion. It is a group of second-order differen-
tial equations in space Rn. It is usually called the standard formulation of the classical
mechanics, or Newton formulation.
Euler and Lagrange introduced an action on the difference between the kinetic
energy and potential energy
L(q, ˙q) = T( ˙q) −V (q) = 1
2( ˙q, M ˙q) −V (q).
Using the variational principle the above equation can be written as
d
d t
∂L
∂˙q −∂L
∂q = 0,
which is called the variational form of the classical mechanics, i.e., the Lagrange form.
In the 19th century, Hamilton proposed another formulation. He used the momen-
tum p = M ˙q and the total energy H = T + V to formulate the equation of motion
as
˙p = −∂H
∂q ,
˙q = ∂H
∂p ,
which is called Hamiltonian canonical equations. This is a group of the ﬁrst-order
differential equations in 2n phase space (p1, · · · , pn, q1, · · · , qn). It has simple and
symmetric form.

8
Introduction
The three basic formulations of the classical mechanics have been described in
almost all text-books on theoretical physics or theoretical mechanics. These different
mathematical formulations describe the same physics law but provide different ap-
proaches in problem solving. Thus equivalent mathematical formulation can have
different effectiveness in computational methods. We have veriﬁed this in our own
simulations.
The ﬁrst author did extensive research on Finite Element Method (FEM) in the
1960s [Fen65] which represents a systematic algorithm for solving equilibrium problem.
Physical problems of this type have two equivalent formulations: Newtonian, i.e., solv-
ing the second-order elliptic equations, and variational formulation, i.e., minimization
principle in energy functional. The key to the success of FEM in both theoretical and
computational methods lies in using a reasonable variational formulation as the basic
principle. After that, he had attempted to apply the FEM idea to the dynamic problem
of continuum media mechanics, but not yet achieved the corresponding success, which
appears to be difﬁcult to accomplish even today. Therefore, the reasonable choice for
computational method of dynamic problem might be the Hamiltonian formulation.
Initially it is a conjecture and requires veriﬁcation from the computational experi-
ments. We have investigated how others evaluated the Hamiltonian system in history.
First we should point out that Hamilton himself proposed his theory based on the ge-
ometric optics and then extended it to mechanics that appears to be a very different
ﬁeld. In 1834 Hamilton said, “This set of idea and method has been applied to optics
and mechanics. It seems it can be applied to other areas and developed into an inde-
pendent knowledge by the mathematicians”[Ham34]. This is just his expectation, and
other peers in the same generation seemed indifferent to this set of theory, which was
“beautiful but useless”[Syn44] to them. Klein, a famous mathematician, while giving a
high appreciation to the mathematical elegance of the theory, suspected its applicabil-
ity, and said: “. . . a physicist, for his problems, can extract from these theories only
very little, and an engineer nothing”[Kle26]. This claim has been proved wrong at least
in physics aspect in the later history. The quantum mechanics developed in the 1920s
under the framework of the Hamiltonian formulation. One of the founders of the quan-
tum mechanics, Schr¨odinger said, “Hamiltonian principle has been the foundation for
modern physics . . . If you want to solve any physics problem using the modern theory,
you must represent it using the Hamiltonian formulation”[Sch44].
3.
The Importance of the Hamiltonian System
The Hamiltonian system is one of the most important systems among all the dynam-
ics systems. All real physical processes where the dissipation can be neglected can be
formulated as Hamiltonian system. Hamiltonian system has broad applications, which
include but are not limited to the structural biology, pharmacology, semiconductivity,
superconductivity, plasma physics, celestial mechanics, material mechanics, and par-
tial differential equations. The ﬁrst ﬁve topics have been listed as “Grand Challenges”
in Research Project of American government.

Introduction
9
The development of the physics veriﬁes the importance of the Hamiltonian sys-
tems. Up to date, it is undisputed that all real physical processes where the dissipation
can be neglected can be written as Hamiltonian formulation, whether they have ﬁnite
or inﬁnite degrees of freedom.
The problem with ﬁnite degrees of freedom includes celestial and man-made
satellite mechanics, rigid body, and multi-body (including the robots), geometric op-
tics, and geometric asymptotic method (including ray-tracing approximation method
in wave-equation, and WKB equation of quantum mechanics), conﬁnement of the
plasma, the design of the high speed accelerator, automatic control, etc.
The problem with inﬁnite degrees of freedom includes ideal ﬂuid dynamics, elas-
tic mechanics, electrical mechanics, quantum mechanics and ﬁeld theory, general rel-
ativistic theory, solitons and nonlinear waves, etc.
All the above examples show the ubiquitous and nature of the Hamiltonian sys-
tems. It has the advantage that different physics laws can be represented by the same
mathematical formulation. Thus we have conﬁdence to say that successful develop-
ment of the numerical methods for Hamiltonian system will have extremely broad
applications.
We now discuss the status of the numerical method for Hamiltonian systems.
Hamiltonian systems, including ﬁnite and inﬁnite dimensions, are Ordinary Differ-
ential Equations (ODE) or Partial Differential Equations (PDE) with special form.
The research on the numerical method of the differential equations started in the 18th
century and produced abundant publications. However, we ﬁnd that few of them dis-
cuss the numerical method speciﬁcally for Hamiltonian systems. This status is in sharp
contrast with the importance of the Hamiltonian system. Therefore, it is appealing and
worthy to investigate and develop numerical methods for this virgin ﬁeld.
4. Technical Approach — Symplectic Geometry Method
The foundation for the Hamiltonian system is symplectic geometry, which is increas-
ingly ﬂourishing in both theory and practice. The history of symplectic geometry can
be traced back to Astronomer Hamilton in the 19th century. In order to study the New-
ton mechanics, he introduced generalized coordinates and generalized momentums to
represent the energy of the system, which is now called Hamiltonian function now. For
a system with n degrees of freedom, the n generalized coordinates and momentums
are spanned into a 2n phase space. Thus the Newton mechanics becomes the geometry
in phase space. In terms of the modern concept, this is a kind of symplectic geometry.
Later, Jacobi, Darboux, Poincar´e, Cartan, and Weyl did a lot of research on this topic
from different points of view (algebra and geometry). However, the major develop-
ment of the modern symplectic geometry started with the discovery of KAM theorem
(1950s to the beginning of 1960s). In the 1970s, in order to research Fourier integral
operator, quantum representation of the geometry, group representation theory, classi-
ﬁcation of the critical points, Lie Algebra, etc., people did a lot of work on symplectic
geometry (e.g., Arnold[Arn89], Guillemin[GS84], Weinstein[Wei77], Marsden[AM78], etc.),
which promoted the development in these areas. In the 1980s, the research on total

10
Introduction
symplectic geometry emerged subsequently, such as the research on “coarse” sym-
plectic (e.g., Gromov et al.), ﬁx point for symplectic map (e.g., Conley, Zehnder’s
Arnold conjecture), the convexity of the matrix mapping (e.g., Atiyah, Guillemin,
Sternberg et al.). The research on symplectic geometry is not only extremely enriched
and vital, but its application is also widely applied to different areas, such as celes-
tial mechanics, geometric optics, plasma, the design of high speed accelerators, ﬂuid
dynamics, elastic mechanics, optimal control, etc.
Weyl[Wey39] said the following in his monograph on the history of the symplectic
group: “I called it complex group initially. Because this name can be confused with the
complex number, I suggest using symplectic, a Greek word with the same meaning.”
An undocumented law for the modern numerical method is that the discretized
problem should preserve the properties of the original problem as much as possible.
To achieve this goal, the discretization should be performed in the same framework
as the original problem. For example, the ﬁnite element method treats the discretized
and original problem in the same framework of the Sobolev space so that the basic
properties of the original problem, such as symmetry, positivity, and conservativ-
ity, etc., are all preserved. This not only ensures the effectiveness and reliability in
practice, but also provides a theoretical foundation.
Based on the above principle, the constructed numerical methods for the Hamil-
tonian system should preserve the Hamiltonian structure, which we call “Hamiltonian
algorithm”. The Hamiltonian algorithm must be constructed in the same framework
as the Hamiltonian system. In the following, we will describe the basic mathematical
framework of the Hamiltonian system and derive the Hamiltonian algorithm from the
same framework. This is our approach.
We will use the Euclid geometry as an analogy to describe the symplectic geome-
try. The structure of an Euclid space Rn lies in the bilinear, symmetric, non-degenerate
inner product,
(x, y) = ⟨x, Iy⟩,
I = In.
Since it is non-degenerate, (x, x) is always positive when x ̸= 0. Therefore we can
deﬁne the length of the vector x as ||x|| =

(x, x) > 0. All the linear operators that
preserve the inner product, i.e., satisfy ATIA = I, form a group O(n), called the
orthogonal group, which is a typical Lie group. The corresponding Lie algebra o(n)
consists of all the transformation that satisﬁes AT + A = AI + IA = 0, which is
inﬁnitesimal orthogonal transformation.
The symplectic geometry is the geometry on the phase space. The symplectic
space, i.e, the symplectic structure in phase space, lies in a bilinear, anti-symmetric,
and non-degenerate inner product,
[x, y] = ⟨x, Jy⟩,
J = J2n =

O
In
−In
O

,
which is called the symplectic inner product. When n = 1,
[x, y] =
 x1
y1
x2
y2
,

Introduction
11
which is the area of the parallel quadrilateral with vectors x and y as edges. Generally
speaking, the symplectic inner product is an area metric. Due to the anti-symmetry
of the inner product, [x, x] = 0 always holds for any vector x. Thus it is impos-
sible to derive the concept of length of a vector from the symplectic inner product.
This is the fundamental difference between the symplectic geometry and Euclid ge-
ometry. All transformations that preserve the symplectic inner product form a group,
called a symplectic group, Sp(2n), which is also a typical Lie group. Its corresponding
Lie algebra consists of all inﬁnitesimal symplectic transformations B, which satisfy
BTJ + JB = 0. We denote it as sp(2n). Since the non-degenerate anti-symmetric
matrix exists only for even dimensions, the symplectic space must be of even dimen-
sions. The phase space exactly satisﬁes this condition.
Overall the Euclid geometry is a geometry for studying the length, while the sym-
plectic geometry is for studying the area.
The one-to-one nonlinear transformation in the symplectic geometry is called sym-
plectic transformation, or canonical transformation. The transformation whose Jaco-
bian is always a symplectic matrix plays a major role in the symplectic geometry. For
the Hamiltonian system, if we represent a pair of n-dim vectors with a 2n-dim vector
z = (p, q), the Hamiltonian equation becomes
d z
d t = J−1 ∂H
∂z .
Under the symplectic transformation, the canonical form of the Hamiltonian equation
is invariant. The basic principle of the Hamiltonian mechanics is for any Hamiltonian
system. There exists a group of symplectic transformation (i.e., the phase ﬂow) Gt1,t0
H
that depends on H and time t0, t1, so that
z(t1) = Gt1,t0
H
z(t0),
which means that Gt1,t0
H
transforms the state at t = t0 to the state at t = t1. Therefore,
all evolutions of the Hamiltonian system are also evolutions of the symplectic trans-
formation. This is a general mathematical principle for classical mechanics. When
H is independent of t, Gt1,−t2
H
= Gt1,−t0
H
, i.e., the phase ﬂow depends only on the
difference in parameters t1 −t0. We can let Gt
H = Gt,0
H .
One of the most important issues for the Hamiltonian system is stability. The fea-
ture of this type of problems in geometry perspective is that its solution preserves the
metrics. Thus the eigenvalue is always a purely imaginary number. Therefore, we can-
not use the asymptotic stability theory of Poincar´e and Liapunov. The KAM theorem
must be used. This is a theory about the total stability and is the most important break-
through for Newton mechanics. The application of the symplectic geometry to the nu-
merical analysis was ﬁrst proposed by K. Feng [Fen85]in 1984 at the international con-
ference on differential geometry and equations held in Beijing. It is based on a basic
principle of the analytical mechanics: the solution of the system is a volume-preserved
transformation (i.e., symplectic transformation) with one-parameter2 on symplectic
2 Before K.Feng’s work, there existed works of de Vorgelaere[Vog56], Ruth[Rut83] and
Menyuk[Men84].

12
Introduction
integration. Since then, new computational methods for the Hamiltonian system have
been developed and we have studied the numerical method of the Hamiltonian system
from this perspective. The new methods make the discretized equations preserve the
symplectic structure of the original system, i.e., to restore the original principle of the
discretized Hamiltonian mechanics. Its discretized phase ﬂow can be regarded as a
series of discrete symplectic transformations, which preserve a series of phase area
and phase volume. In 1988, K. Feng described his research work on the symplectic
algorithm during his visit to Western Europe and gained the recognition from many
prominent mathematicians. His presentation on “Symplectic Geometry and Compu-
tational Hamiltonian Mechanics” has obtained consistent high praise at the workshop
to celebrate the 60th birthday of famous French mathematician Lions. Lions thought
that K. Feng founded the symplectic algorithm for Hamiltonian system after he devel-
oped the ﬁnite element methods independent of the efforts in the West. The prominent
German numerical mathematician Stoer said, “This is a new method that has been
overlooked for a long time but should not be overlooked.”
We know that we can not study the Hamiltonian mechanics without the symplectic
geometry. In the meantime, the computational method of the Hamiltonian mechanics
doesn’t work without the symplectic difference scheme. The classical R–K method is
not suitable to solve this type of problems, because it cannot preserve the long-term
stability. For example, the fourth-order R–K method obtains a completely distorted
result after 200,000 steps with a step size 0.1, because it is not a symplectic algorithm,
but a dissipative algorithm.
We will describe in more detail the theory of symplectic geometry and symplectic
algebra in Chapters 1, 2 and 3.
5.
The Symplectic Schemes
Every scheme, whether it is explicit or implicit, can be treated as a mapping from this
time to the next time. If this mapping is symplectic, we call it a symplectic geometric
scheme, or in short, symplectic scheme.
We ﬁrst search the classical difference schemes. The well-known Euler midpoint
scheme is a symplectic scheme
zn+1 = zn + J−1Hz
zn+1 + zn
2

.
The symplectic scheme is usually implicit. Only for a split Hamiltonian system, we
can obtain an explicit scheme in practice by alternating the explicit and implicit
stages. Its accuracy is only of ﬁrst order. Symmetrizing this ﬁrst-order scheme yields
a second-order scheme (or so-called reversible scheme). There exist multi-stage R–K
symplectic schemes among the series of R–K schemes. It is proved that the 2s-order
Gauss multi-stage R–K scheme is symplectic. We will give more details on these top-
ics in Chapters 4 , 7 and 8. The theoretical analysis and a priori error analysis will be
described in Chapter 6 and 9.

Introduction
13
In addition, the ﬁrst author and his group constructed various symplectic schemes
with arbitrary order of accuracy using the generating function theory from the ana-
lytical mechanics perspective. In the meantime, he extended the generating function
theory and Hamilton–Jacobi equations by constructing all types of generating function
and the corresponding Hamilton–Jacobi equations. The generating function theory and
the construction of the symplectic schemes will be introduced in Chapter 5.
6.
The Volume-Preserving Scheme for Source-free Sys-
tem
Among the various dynamical systems, one of them is called source-free dynamical
system, where the divergence of the vector ﬁeld is zero:
d x
d t = f(x),
div f(x) = 0.
The phase ﬂow to this system is volume-preserved, i.e., det
∂xn+1
∂xn

= 1. Therefore,
the numerical solution should also be volume-preserved.
We know that Hamiltonian system is of even dimensions. However, the source-free
system can be of either even or odd dimensions. For the system of odd dimensions,
the Euler midpoint scheme may not be volume-preserved. ABC (Arnold–Beltrami–
Childress) ﬂow is one of the examples. Its vector ﬁeld has the following form:
˙x = A sin x + C cos y,
˙y = B sin x + A cos z,
˙z = C sin y + B cos x,
which is a source-free system and the phase ﬂow is volume-preserved. This is a split
system and constructing the volume-preserving scheme is easy. Numerical experi-
ments show that the volume-preserving scheme can calculate the topological structure
accurately, whereas the traditional schemes can not[FS95,QZ93]. We will give more de-
tails in Chapter 10.
7.
The Contact Schemes for Contact System
There exists a special type of dynamical systems with odd dimensions. They have
similar symplectic structure as the systems of even dimensions. We call them contact
systems. The reader can ﬁnd more details in Chapter 11.
Consider the contact system in R2n+1 space

14
Introduction
(2n + 1) −dim vector :
⎡
⎣
x
y
z
⎤
⎦, where x =
⎡
⎢⎣
x1
...
xn
⎤
⎥⎦, y =
⎡
⎢⎣
y1
...
yn
⎤
⎥⎦, z = (z);
(2n + 1) −dim v.f. :
⎡
⎢⎣
a(x, y, z)
b(x, y, z)
c(x, y, z)
⎤
⎥⎦, where a =
⎡
⎢⎣
a1
...
an
⎤
⎥⎦, b =
⎡
⎢⎣
b1
...
bn
⎤
⎥⎦, c = (c).
A contact system can be generated from a contact Hamiltonian function K(x, y, z):
d x
d t = −Ky + Kzx = a,
d y
d t = Kx = b,
d z
d t = Ke = c,
Ke(x, y, z) = K(x, y, z) −(x, Ky(x, y, z)).
The contact structure in R2n+1 space is deﬁned as
α = xd y + d z = [0, x, 1]
⎡
⎣
d x
d y
d z
⎤
⎦.
A transformation f is called the contact transformation if it could preserve the contact
structure with a pre-factor μf. A scheme which can preserve the contact structure is
called contact scheme[FW94,Shu93].
The contact schemes have potential applications in the propagation of the wave
front[MF81,QC00], the applications in thermal dynamics[MNSS91,EMvdS07], and the charac-
teristic method for the ﬁrst-order differential equations[Arn88].
The symplectic algorithm, the volume-preserving algorithm, the contact algo-
rithm, and the Lie–Poisson algorithm are all schemes that preserve the geometry
structure of the phase space. We call these methods “geometric integration for dy-
namic system”[FW94,LQ95a]. The geometric integration was ﬁrst introduced by the ﬁrst
author[FW94] and has been widely accepted and used by the international scientists.
The 1996 workshop on the advance of the numerical method, held in England, men-
tioned the importance of the structure-preserving schemes for the dynamics system. In
that workshop, a series of high-order structure preserving schemes has been proposed
via the multiplicative extrapolation method[QZ92,QZ94]. We have extended the explicit
schemes of Yoshida[Yos90] to all self-adjoint schemes. By using the product of the
schemes and their adjoint, we have constructed very high order self-adjoint schemes.
The details are described in Chapter 8. Concerning the Lie–Poisson algorithm we will
describe more details in Chapter 12.

Introduction
15
8.
Applications of the Symplectic Algorithms for Dy-
namics System
(1)
Applications of symplectic algorithms to large time scale sys-
tem
Nearly all systems of celestial mechanics and dynamic astrophysics are Hamiltonian
or approximately Hamiltonian with few dissipations. Such systems can be described
by canonical forms of Hamiltonian systems, which has now become one of the most
important research areas of dynamical system. However, due to the complicated non-
linearity of those canonical Hamiltonian systems, few analytic solutions are available.
Although sometimes approximate analytic solutions in form of power series can be
obtained by the perturbation method, the long time dynamics, the quantity property,
and the intrinsic nonlinearity are overlooked by such solutions. Thus, the numerical
methods are required to study those problems to get more accurate and quantitative
numerical solutions, which not only provide the information and images on the whole
phase space of the given mechanical system for further qualitative analysis, but also
lead to some important results for the system. There are two ways to analyze Hamil-
tonian system qualitatively. One way is to get the numerical solution of the canoni-
cal Hamiltonian system directly by the numerical methods, and the other is simpler
discretization process to the equation of motion, which becomes a simple mapping
question which making computing easier. The later method reduces the computational
effort so that it can be performed by normal computers to study the large time scale
evolution of dynamical systems.
Traditional numerical methods for dynamics system can be categorized into single-
step methods, e.g. the R–K method, and multi-step methods, e.g. the widely used
Adams method for the ﬁrst order differential equations, and Cowell methods for the
second order differential equations. However, all the methods have the artiﬁcial nu-
merical dissipations so that the corresponding total energy of the Hamiltonian system
will change linearly. This will distort basic property of Hamiltonian system and lead
to wrong results for a long time computation. By quantitative analysis, we know that
the dissipation of the total energy will accumulate errors of the numerical trajectories
of the celestial bodies. The errors will increase at least squarely with respect to the
integration time step.
In the 1980s, the ﬁrst author and his group established the theory of the symplec-
tic algorithms for Hamiltonian system. The signiﬁcance of this theory is not only to
present a new kind of algorithms, but also to elucidate the reason for the false dis-
sipation of the traditional methods, i.e.,that the main truncation error terms of those
non-symplectic methods are dissipative terms, whereas the main truncation error terms
of symplectic algorithms are not dissipative terms. Thus the numerical energy of the
system will not decrease linearly, but change periodically. Due to the conservation of
the symplectic structure of the system, which is the basic property, the symplectic al-
gorithms have the long time capacity to simulate the evolution of the celestial bodies.
As the energy is a very important parameter of such a system, the numerical results
of symplectic algorithms, which can preserve the energy approximatively, are more

16
Introduction
reasonable. Furthermore, because the errors of the energy are controlled, the errors of
numerical trajectories of celestial bodies are no longer along the track by (t −t0)2
laws of the fast-growing, and with only a t −t0 linear growth, this to the long arc
computation is extremely advantageous.
For the advantages of the symplectic algorithms, nowadays they have been widely
used in the study of dynamical astronomy, especially in the qualitative analysis of the
evolution of solar system, e.g. to analyze the stable motion area, space distributions
and trajectory resonance of little planets, long time evolution of large planets and
extra-planets, and other hot topics in the dynamical astronomy.
(2)
Applications of symplectic algorithms to qualitative analysis
We ﬁrst use two simple examples to illustrate the special affects of symplectic schemes
on the qualitative analysis in dynamics astronomy[LZL93,JLL02,LL95,LL94,Lia97,LLZW94].
Example I.
The Keplerian motions. It is the elliptical motions of two-body problem.
The corresponding Hamiltonian function is:
H(p, q) = T(p) + V (q),
where p and q are the generalized coordinates and generalize momentum, T and V
are the kinetic and potential energies. The analytic solution is a ﬁxed ellipse. When
we simulate this problem by the R–K methods and symplectic algorithms, the former
ones shrink the ellipse gradually, whereas the later ones preserve the shape and size
of the ellipse (see the numerical trajectories after 150 and 1000 steps respectively in
Fig. 0.7(a), e=0.7 and Fig. 0.7(b), e=0.9 where e is the eccentricity of the ellipse).
This means the non-symplectic R–K methods have the false energy dissipation and
the symplectic algorithms preserve the main character of the Kepler problem because
of the conservation of the symplectic structure.
Example II.
The axial symmetry galaxy’s stellar motion question. Its simpliﬁed
dynamic model corresponding to the Hamiltonian function is:
H(p, q) = 1
2(p2
1 + p2
2) + 1
2(q2
1 + q2
2) + (2q2
1q2 −2
3p3
2).
To obtain the basic character of the dynamics of this system, we compute it with
order 7 and order 8 Runge–Kutta–Fehlberg methods (denoted as RKF(7) and RKF(8)
resp.), as well as the order 6 explicit symplectic algorithm (SY6). The numerical re-
sults are listed in Fig. 0.8 to Fig. 0.10. In these ﬁgures (Fig. 0.8 to Fig. 0.9), we see that
the symplectic algorithm preserves the energy H very well in both of the two cases
(ordered LCN= 0 and disorder region LCN> 0), while the RKF methods increase the
energy with the evolution of time ΔH. In Fig. 0.10 (a) and Fig. 0.10 (b), the symplec-
tic algorithms present numerically the basic characters of the system: the ﬁxed curve
in case of LCN= 0 and the chaos property in case of LCN> 0.

Introduction
17
Fig. 0.7.
Comparison of calculation of Keplerian motion by R–K and symplectic methods.
Fig. 0.8.
Curves of ΔH obtained by RKF(8)[left] and SY6 [right] both with H0 = 0.553,
LCN=0.
Fig. 0.9.
Curves of ΔH obtained by RKF(8)[left] and SY6 [right] both with H0
=
0.0148, LCN > 0
The symplectic algorithms can preserve the symplectic structure of Hamiltonian
systems and the basic evolutionary property of such dynamical systems. Therefore,

18
Introduction
Fig. 0.10.
Poincar´e section obtained by RKF(8)[left] with H0 = 0.553,LCN=0 and SY6
[right] with H0 = 0.0148,LCN>0
the symplectic algorithms were widely used to study the dynamical astronomy. Cur-
rently, it is a hot topic to study the dynamical evolution of the solar system, such
as the long-term trajectory evolution of large planet and extra-planet, the space dis-
tribution of little planets in main zone (Kirkwood interstice phenomenon), trajectory
resonance, the evolution of satellite system of a large planet, the birth and evolution of
planet loops and the trajectory evolution of a little planet near Earth. All these prob-
lems require numerical simulation for a very long time, e.g. 109 years or more for the
solar system. Thus, the time steps for the numerical methods shall be large enough
due to limitations of our computers, while the basic property of the system should be
preserved. This excludes all the non-symplectic methods, whilst just lower order sym-
plectic algorithms are valid for the task. In recent years, many astronomers in Japan
and America, e.g. Kinoshita[KYN91], Bretit[GDC91] and Wisdom[WHT96,WH91], have done
a large amount of research on the evolution of the solar system. The following con-
tribution of Wisdom has been widely cited. He derived the Hamiltonian function in
Jacobin coordinates of the solar system as
H(p, q) =
n−1

i=1
Hi(p, q) + εΔH(p, q),
where Hi(p, q) is corresponding Hamiltonian function for a two-body system, ε ≪1
is a small parameter. By splitting the Hamiltonian function, explicit symplectic al-
gorithms with different orders can be constructed. The advantage of those symplec-
tic algorithms is that the truncation errors are as small as order of ε than those of
algorithms constructed by the ordinary splitting for the Hamiltonian function (i.e.,
H(p, q) = T(p) + V (q)). Even the lower order symplectic algorithms obtained by
this splitting method are very effective in a study of the evolution of the solar system.
Since the 1980s , Chinese astronomers have also made some progress in the applica-
tions of symplectic algorithms to the research of dynamical astronomy, such as[WH91]

Introduction
19
1◦
For the restrictive three-body system constituted by solar, the major planet
and the planetoid, some new results have been obtained after studying its correspond-
ing resonance of 1:1 orbit and the triangle libration point. These results can success-
fully explain the distribution of stability region [ZL94,ZLL92] of Trojan planetoid, as well
the actual size of the stable region of distributed triangle libration points corresponding
to several relate major planet.
2◦
Adopting the splitting method of Wisdom for the Hamiltonian function to
study the long-term trajectories evolution of some little planets.
H(p, q) = H0(p, q) + εH1(q),
where H0(p, q) is the Hamiltonian function for an integrable system, ε ≪1 is a
little parameter. The numerical results obtained by using this splitting method are
very reasonable because the energy is preserved in a controlled range and no false
dissipation occurs.
3◦
Application of symplectic algorithms to galaxy system. The bar phenomenon
and the evolution of stars in NGC4736 Galaxy were simulated successfully by the
symplectic algorithms.
4◦
Some useful results on how to describe the evolutionary features of celes-
tial dynamical system were obtained by further study on the symplectic integrators
and the existence of their formal integrations, as well as the changes of all kinds of
conservation laws.
Besides the research on Hamilton systems in dynamics astronomy mentioned
above, the small diffusion situation were also discussed and applied. In view of the fact
that the diffusion factor is relatively weak, a mixed symplectic algorithm constituted
by the explicit scheme and the centered Euler scheme is applied for the conservative
part (the main part corresponding to mechanic system) and the dissipative part, which
is remarkably effective, because it could maintain the features of Hamilton system in
the main part of this system.
(3)
Applications of symplectic algorithms to quantitative compu-
tations
Because the structure could be preserved by the symplectic algorithms, the errors of
their numerical energy don’t accumulate linearly. When the celestial systems are inte-
grated by symplectic algorithms, errors of trajectories will increase linearly as t −t0,
whereas errors of the non-symplectic methods increase rapidly as (t −t0)2. We show
some examples next.
Taking the trajectory of Lageos satellite as background, we consider two mechan-
ics system of the Earth perturbation problems. The ﬁrst one just takes into account the
nonspherical perturbation of the Earth and the second one takes into account the non-
spherical perturbation of the Earth and the perturbation of atmospheric resistance. The
former problem corresponds to a Hamiltonian system, while the later one corresponds
to a quasi-Hamiltonian system because of very small dissipation. We use the RKF7(8)
methods and revised order 6 symplectic algorithm (denoted as SY6) to compute the

20
Introduction
two problems, respectively. The numerical results of the errors Δ(M + ω) of main
1000 cycles trajectory are listed in Table 0.1 and Table 0.2. From the two tables, we
can clearly see that the errors of the non-symplectic methods, though very small at the
beginning, increase rapidly as (t −t0)2; whereas the errors of symplectic algorithm
increase linearly as t −t0. The results of symplectic algorithms are much better. This
indicates that though the accuracy order of symplectic algorithms is the same as for
other methods, they have more application value in the quantitative computations. We
also improve the RKF7(8) for energy conserving methods by compensating the en-
ergy at every time step. We denote such method as the RKH method whose numerical
results are also listed in the two tables. From the results, we can see that we have
made much improvement of the schemes. The results of the energy error by the RKH
are almost same with those by the symplectic algorithm. Thus the RKH methods not
only have high order accuracy, but also can preserve the energy approximately as the
symplectic algorithms.
Table 0.1.
Errors of trajectories with nonspherical perturbation of the EarthΔ(M + ω)
method
N of steps / circle
100 circles
1000 circles
10000 circles
FKF7(8)
100
1.5 E −10
1.4 E −08
1.3 E −06
SY6
50
0.5 E −09
0.6 E −08
1.0 E −07
RKH
100
0.9 E −11
0.9 E −10
0.9 E −09
Table 0.2.
Errors of trajectories with perturbation of atmospheric resistanceΔ(M + ω)
method
N of steps / circle
100 circles
1000 circles
10000 circles
FKF7(8)
100
1.4 E −410
1.3 E −08
1.3 E −06
SY6
50
0.6 E −09
0.7 E −08
1.0 E −07
RKH
100
2.1 E −11
3.5 E −10
6.2 E −09
(4)
Applications of symplectic algorithms to quantum systems
The governing equation of the time evolution of quantum system is the Schr¨odinger
equation
i∂ψ
∂t = ˆHψ,
ˆH = ˆH0(r) + ˆV (t, r),
(0.1)
where the operator ˆH is Hermitian.
According to the basic theory of quantum mechanics, the initial state of a quantum
system uniquely determines all the states after initial moment of time. That is to say,
if the state function ψ(t1, r) is given at time t1, then the solution (so-called wave
function) of Equation (0.1) is determined as

Introduction
21
ψ(t, r) = a(t, r) + ib(t, r),
where functions a and b are real.
Such a solution can be generated by a group of time evolutionary operators
{U t1,t2
ˆ
H
}, i.e.,
ψ(t2, r) = U t1,t2
ˆ
H
ψ(t1, r).
Every operator is unitary and depends on t1, t2 and ˆH. They are independent of the
state ψ(t1, r) at time t1. Therefore, the time evolutions of the quantum system are
evolutions of unit transformation in this sense. Every operator can induce an operator,
which acts on the real function vector. The two components of the real functions vector
are the real part and the image part of the wave function, i.e.,
 b(t2, r)
a(t2, r)

= St1,t2
ˆ
H
 b(t1, r)
a(t1, r)

.
The operator St1,t2
ˆ
H
preserves the inner product and symplectic wedge product for
any two real function vectors. It is simply called norm-preserving symplectic evolu-
tion. The quantum system is a Hamiltonian system (with inﬁnite dimensions) and the
time evolution of the Schr¨odinger equation can be rewritten as a canonical Hamilto-
nian system for the two real functions of the wave function as the generalized mo-
mentum and generalized coordinates. The norm of wave function is the conservation
law of the canonical system. Thus it is reasonable to integrate such a system by the
norm-preserving symplectic numerical methods. To apply such a method to the in-
ﬁnite dimensional system, we should ﬁrst space discretize the system into a ﬁnite
dimensional canonical Hamiltonian system, which also preserves the norm of wave
function. Suppose the characteristic functions of the operator ˆH0(r) for the evolution-
ary Schr¨odinger equation with some given boundary conditions contain the discrete
states and continuous states.
When the Hamiltonian ˆH is independent on time explicitly, the energy of the quan-
tum system ⟨ψ|, ˆH|ψ⟩= ZTHZ is a conservation law both for the canonical system
and norm-preserving symplectic algorithm. Such a norm-preserving symplectic algo-
rithm with the fourth order accuracy can be constructed by the order 4 diagonal Pad´e
approximations to the exponential function eλ.
In the following, we take an example to introduce the method to discretize the time
involved Schr¨odinger equation to a canonical system[LQHD07,QZ90a].
Consider the time evolution of an atom moving in one dimensional space by the
action of some strong ﬁeld V (t, x) is
i∂ψ
∂t = ˆHψ,
ˆH = ˆH0(r) + ˆV (t, r),
ˆH0 = −1
2
∂2
∂x2 + V0(x),
V0(x) =
 0,
0 < x < 1,
∞,
x ≤0
or
x ≥1.

22
Introduction
In contrast to the characteristic function expanding method, we don’t make any trun-
cation for the wave function when discretizing the Schr¨odinger equation. Therefore,
the resulting canonical system contains all the characteristic states of ˆH0.
The numerical conservation laws of explicit symplectic algorithms will converge
to the corresponding conservation laws of the system as the time step tends to zero.
Thus, although numerical energy and norm of the wave function presented by explicit
symplectic algorithms will not be preserved exactly, they will converge to the true
energy and norm of the wave function of the system as the time step reduces.
The time dependent Schr¨odinger equation (TDSE) in one dimensional space by
the action of some strong ﬁeld V (t, x) is
i∂ψ
∂t = ˆHψ,
ˆH = ˆH0(x) + ε ˆV (t, x),
ˆH0 = −1
2
∂2
∂x2 + V0(x),
V0(x) =

0,
0 < x < 1,
∞,
x ≤0
or
x ≥1.
V (x) =
⎧
⎪
⎨
⎪
⎩
2x,
0 < x < 0.5,
2x −2x,
0.5 ≤x ≤1,
0,
x ≤0
or
x ≥1.
Using the similar method as before, we expand the wave function as the character-
istic functions {Xn(x) =
√
2 sin nπx, n = 1, 2, · · ·} of ˆH0 to discretize the TDSE.
Because the Hamiltonian operator is real, the discrete TDSE is a separable linear
canonical Hamiltonian system with the parameters as follows.
S = (Smn),
Smn = n2π2
2
δmn + εvmn,
vmn =
⎧
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎩
1
2 + 1 −(−1)n
n2π2
,
m = n,
0,
|m −n| = 1, 3, 5, · · · ,
−16mn(1 −(−1)
m−n
2
)
(m2 −n2)2π2
,
|m −n| = 2, 4, 6, · · · , n = 2, 4, 6, · · · ,
−8|2mn −(−1)
m−n
2
(m2 −n2)|
(m2 −n2)2π2
, |m −n| = 2, 4, 6, · · · , n = 1, 3, 5, · · · .
The initial state is taken as
ψ(0, x) = 1 + i
2
|X1(x) + X2(x)|,
ε = 5π2.
The energy of the system is conserved because the Hamiltonian does not depend
on the time explicitly. E(b, a) = e0 = 42.0110165. The norm of wave function keeps
unitary, i.e., N(b, a) = n0 = 1. We take the Euler midpoint rule, order 2 explicit
symplectic algorithm and the order 2 R–K method to compute the problem with the
same time step h = 10−3. The numerical results are as follows:

Introduction
23
1◦
The R–K method can not preserve the energy and the norm of wave function,
as evident by ER–K in Fig. 0.11(left) and NR–K in Fig. 0.11(right).
2◦
The Euler midpoint rule can preserve the energy and norm, as evident by EE
in Fig. 0.11(left) and NE in Fig. 0.11(right). Note that for EE in Fig. 0.11(left), there
is a very small increase at some time because of the implicity of the Euler scheme.
Fig. 0.11.
Energy [left] and norm [right] comparison among the 3 difference schemes
3◦
The explicit symplectic algorithms can preserve exactly the energy ˜E(bk, ak; h)
and norm ˜N(bk, ak; h), as evident by E′
S in Fig. 0.11(left) and N ′
S in Fig. 0.11(right).
If we want to get further insight into these conservation laws within smaller scales, we
ﬁnd that as the time steps get smaller, the numerical energy of symplectic algorithm
converges to the true energy of the system e0 = 42.0110165 and the numerical norm
converges to unit n0 = 1. See Table 0.3 showing the numerical energy and norm as
well as their errors. The errors are deﬁned as
CE(h) = max
k
|Ek
S −e0|,
CN(h) = max
k
|N k
S −n0|.
Actually, the numerical energy and norm obtained by symplectic algorithm oscillate
slightly, as shown by ES and NS in Fig. 0.12. However, the amplitude of their oscil-
lations will converge to zero, if the time step tends to zero. As the time step tends to
zero, we have
e(h) −→e0,
CE(h) = maxk |Ek
S −e0| −→0,
n(h) −→n0,
CN(h) = maxk |N k
S −n0| −→0.

24
Introduction
Table 0.3.
The change of energy and norm of the wave function with the step size
h
e(h)
CS(h)
n(h)
CN(h)
10−3
42.0169964
0.0445060
0.9996509
0.0003106
10−4
42.0110763
0.0004195
0.9999965
0.0000030
10−5
42.0110171
0.0000018
0.9999990
0.0000000
10−6
42.0110165
0.0000000
1.0000000
0.0000000
10−7
42.0110165
0.0000000
1.0000000
0.0000000
exact value
42.0110165
0.0000000
1.0000000
0.0000000
Fig. 0.12.
Energy E and norm N obtained from explicit symplectic scheme
In all, for a quantum system with real Hamiltonian function independent of time
explicitly, the explicit symplectic algorithms can preserve the energy and norm of the
wave function to any given accuracy. They overcome the main disadvantages of the
traditional numerical methods.
Next, we look at the quantum system with real Hamiltonian function, which is
dependent on time explicitly. In this case, the resulting system after semi-discretization
is an m-dimensional, separable, linear, Hamiltonian canonical system. The energy of
the system is not conserved any more, but the norm of the wave function is still a
quadratic conservation law.
The TDSE for an atom in one dimensional space with the action of some strong
ﬁeld V (t, x) = εx sin(ωt) is
i ∂ψ
∂t = ˆHψ,
ˆH = ˆH0(x) + ε ˆV (t, x),
ˆH0 = −1
2
∂2
∂x2 + V0(x).
By the similar method as before, we expand the wave function as the characteristic
functions Xnx =
√
2 sin nπx(n = 1, 2, · · ·) of ˆH0 to discretize the TDSE. Because

Introduction
25
Fig. 0.13.
ω = 3π2/2, ε = π2/2: Graph of norm[left]; graph of probability[right]
the Hamiltonian operator is real, the discrete TDSE is a separable linear canonical
Hamiltonian system with the parameters as follows.
S(t) = (s(t)mn),
s(t)mn = n2π2
2
δm,n + εv(t)mn;
v(t)mn =
⎧
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎩
sin(ωt),
m = n,
0,
|m −n| = 2, 4, 6, · · · ,
8mn sin (ω t)
(m2 −n2)2π2 ,
|m −n| = 1, 3, 5, · · · .
The initial state is taken as ψ(0, x) = X1(x) =
√
2 sin(πx). The energy of the
system is not conserved in this case because the Hamiltonian depends on the time
explicitly. The norm of wave function remains unitary, i.e., N(b, a) = n0 = 1. We
take the Euler midpoint rule scheme, order 2 explicit symplectic algorithm and the
order 2 R–K method to compute the problem with the same time step h = 4 × 10−3.
The numerical results are as follows:
1◦
The R–K method increases the norm of wave function rapidly, see NR–K in
Fig. 0.13(left). It leads to unreasonable results, see in Fig. 0.13(right).
2◦The Euler midpoint rule scheme can preserve the norm, see NE in Fig.0.13(left).
These results are in good agreement with the theoretical results. See Fig. 0.13(right)
for the results for weak ﬁelds ε = π
2 . When ω = ΔE1n, i.e., resonance occurs, the
basic state and the ﬁrst inspired state will intermix and the variation period of the
energy is identical to the period of intermixing. See the corresponding results in Fig.
0.14(left) and Fig. 0.14(right). When ω ̸= ΔE1n there will not be intermixing. See the
corresponding numerical results in Fig. 0.15(left) and Fig. 0.15(right), where O is the
basic state. When the ﬁeld is strong, the selection rule is untenable, and no resonance
occurs, but the basic state will intermix with the ﬁrst, second, . . . inspired states. See
the results for ω = 5π2
4
in Fig. 0.16(left) and Fig. 0.16(right) and ω = 3π2
2
= ΔE12
in Fig. 0.17(left) and Fig. 0.17(right).

26
Introduction
Fig. 0.14.
ω = 3π2/2, ε = π2/2: Graph of probability[left]; graph of norm[right]
Fig. 0.15.
ω = 5π2/4, ε = 3π2/2: Graph of probability[left]; graph of norm[right]
3◦
The order 2 explicit symplectic algorithms can not preserve the norm exactly.
The numerical norms oscillate near the unit. See NS in Fig. 0.13, where changes of
numerical energy and states of intermixing obtained by symplectic algorithms are
similar to the results of Euler midpoint rule scheme.
We can conclude that for this system the R–K method can not preserve the norm of
wave function and its results are unreasonable; the Euler scheme can preserve the norm
and its results are in agreement with the theoretical results; the second order scheme
obtains the numerical norm which oscillates near the unit and its energy and states of
intermixing are the same as for the results of Euler scheme. Thus, the Euler scheme
(an implicit symplectic scheme) and the second order explicit symplectic algorithm
are good choices for studying the quantum system with the Hamiltonian dependent on
time explicitly. They overcome the drawbacks of the traditional R–K methods.
(5)
Applications to computation of classical trajectories
Applications of symplectic algorithms to computation of classical trajectories of A2B
molecular reacting system [LDJW00].
To study the classical or semi-classical trajectories of the dynamical system, mi-
croscopic chemistry is an effective theory method.

Introduction
27
Fig. 0.16.
ω = 5π2/4, ε = 50π2: Graph of probability[left]; graph of norm[right]
Fig. 0.17.
ω = 3π2/2, ε = 50π2: Graph of probability[left]; graph of norm[right]
The classical trajectory method regards the atom approximatively as a point and
the system as a system of some points, and advances the process of action as the clas-
sical motions of point system in potential energy plane of the electrons. It was Bunker
who ﬁrst applied the R–K method to computations of classical trajectory of molecular
reacting system. Karplus et al. did a large number of computations by all kinds of
numerical methods and screened out the R–K–G (Runge–Kutta–Gear) method to pro-
long the computation time from 10−15s to 10−12s. The R–K–G method made rapid
progress in the theoretical study of reacting dynamics of microscopic chemistry and
was widely used for computation of classical trajectory. However, its valid computa-
tion time is much less than 10−8s which is necessary time for study of chemical re-
actions. Moreover, there were many differences between the numerical quantities and
theoretical quantities of some parameters. The classical trajectory method describes
the microscopic reaction system approximately as a Hamiltonian system which natu-
rally has symplectic structure. Thus, it is expected that the symplectic algorithms will
overcome the shortages of the R–K–G method and improve the numerical results.
Here we take the mass of the proton as the unit mass and 4.45 × 10−14s as unit
time.
Consider the classical motions of the A2B type molecules like H2O and SO2 mov-
ing in the electron potential energy plane of the reaction system and preserving the

28
Introduction
symmetry of C2v. Set the masses of A and B to be mA = 1 and mB = 2 resp., the
center of mass of the molecule be the origin of some coordinate, the C2 axes be z axes,
and the coordinates of two atoms A and the atom B be (y1, z1), (y2, z2) and (y3, z3)
reps. in the ﬁxed coordinate system. By Banerjee’s coordinates separating method, we
can get the generalized coordinates of the A2B molecule as
q1 = z1 + z2 −2z3,
q2 = y2 −y1,
and the generalized mass as M1 = 0.25, M2 = 0.5, further the generalized momen-
tum as
p1 = 0.25d q1
d t ,
p2 = 0.5d q2
d t ,
and the kinetic energy of system as
K(p) = 2p2
1 + p2
2.
The potential energy suggested by Banerjee, who introduced the symmetry C2v
and notation D =

q2
1 + q2
2, was
V (q) = 5π2(D2 −5D + 6.5) + 4D−1
+0.5π2(|q2| −1.5)2 + |q2|−1.
The Hamiltonian function for the A2B molecular system is
H(p, q) = K(p) + V (q),
and the canonical equations for the classical trajectories are
d p1
d t = −∂V
∂t = −f1(q),
d q1
d t = ∂K
∂p1 = g1(p),
d p2
d t = −∂V
∂q2 = −f2(q),
d q2
d t = ∂K
∂p2 = g2(p).
It is a separated Hamiltonian system, which can be integrated by explicit symplec-
tic algorithms. We can obtain its numerical solutions of some initial values as
tk = kh,
pk
1 = p1(tk),
qk
1 = q1(tk),
pk
2 = p2(tk),
qk
2 = q2(tk),
and further its classical trajectories of A2B system and the changes of kinetic energy,
potential energy and total energy with time by following relations:
y3 = 0,
z3 = −q1
4 ;
y2 = −y1 = q2
2 ,
z2 = z1 = q1
4 .
The initial values are taken as
q1(0) = 3,
q2(0) = 3
2;
p1 = 0,
p2 = 0.

Introduction
29
Fig. 0.18.
The potential energy curve of the electronic potential function in phase space
We compute this system with order 4 explicit symplectic algorithm and R–K
method. The time step is taken as h = 0.01 for both. The numerical classical tra-
jectories, kinetic energy, potential energy and total energy are recorded. Fig. 0.18
shows the potential energy curve of the electronic potential function in phase space. If
|q1| →+∞, then V (q) →+∞; if |q2| →0 or |q2| →+∞, then V (q) →+∞. By
the theoretical analysis, we know that the total energy of the system will be conserved
all the time, the three atoms will oscillate nearly periodically, and the whole geometry
structure of the system may be reversed but kept periodic. The changes of the total
energy with time are shown in Fig.0.19, where we can see that the total energy ob-
tained by symplectic algorithms are preserved up to 6.23 × 10−9s, whereas the R–K
method reduces them rapidly with time. The motion trajectories of the system in the
plane by the symplectic algorithms and R–K method are shown in Fig. 0.20 (a), (c),
(e) and (b), (d), (f) resp., where we can see that the numerical results of symplectic al-
gorithms are coincident with the theoretical results but the results of R–K method are
not. We also applied the order 1 and 2 symplectic algorithms, the Euler method and the
revised Euler method to compute the same problem. The conclusions are almost the
same. Because all the traditional methods such as R–K methods, Adams methods and
Euler methods can not preserve the symplectic structure of this microscopic system,
they will bring false dissipations inevitably, which will make their numerical results
meaningless after long-term computations. On the contrary, symplectic algorithms can
preserve the structure and do not bring any false dissipations. Therefore, they are suit-
able for long-term computations and greatly improve the classical trajectory methods
for studying the microscopic dynamical reactions of chemical systems.

30
Introduction
Fig. 0.19.
The changes of the total energy with the time
(6)
Applications to computation of classical trajectories of di-
atomic system [Dea94,DLea96]
Consider the classical motion of AB diatomic molecule system in electron potential
energy plane. Set the masses of A and B to be m1 and m2 resp., the center of mass to
be the origin of some coordinate with ﬁxed axes Ox, the coordinates of two atoms A
and B to be −x1 and x2 resp. Then the generalized coordinate is q = x2 + x1 and the
generalize mass is M =
m1m2
m1 + m2 . Further, the generalized momentum is p = M d q
d t
and the generalized kinetic energy is U(p) =
p2
2M . Take the potential function as the
Morse potential
V (q) = D{e−2a(q−qe) −2e−a(q−qe)},
where the parameters D, a, qe were derived by E. Ley and Koo recently. Thus, the total
energy for such system is H(p, q) = U(p) + V (q), and the canonical Hamiltonian
system for the classical trajectory is
d p
d t = −d V (q)
d t
= −f(q),
d q
d t = d U(p)
d t
= g(p).
It is a separable system. By explicit symplectic algorithms, we can get its numeri-
cal solutions as
tk = kh,
pk = p(tk),
qk = q(tk),
and advance its classical trajectories of AB two-atom system as
x1 =
m2q
m1 + m2
,
x2 =
m1q
m1 + m2
,

Introduction
31
Fig. 0.20.
The motion trajectories of the system in the plane,(a) and (b) period range from
4.45×10−10s to (4.45×10−10 +4.45×10−13)s. (c) and (d) period range from 6.23×10−9s
to (6.23 × 10−9 + 4.45 × 10−13)s. (e) and (f) period range from 6.23 × 10−9s to (6.23 ×
10−9 + 4.45 × 10−13)s. (a), (c), (e) is the symplectic algorithm path, (b), (d), (f) is the R–K
method path
as well as the changes of kinetic energy, potential energy and total energy with the
variation of time.
We compute some states of two homonuclear molecules Li2 and N2 and two
heteronuclear molecules CO and CN by using the order 1, 2 and 4 explicit sym-
plectic algorithms and compare the numerical results of total energy and classical
trajectories with the Euler method and order 2 and 4 order R–K methods. In Fig.
0.21, Fig. 0.22 and Fig. 0.23, we show the numerical results of the classical tra-
jectories, total energy and the trajectories in p −q phase space obtained by order
4 explicit symplectic algorithm and order 4 R–K method respectively. The parame-

32
Introduction
Fig. 0.21.
Classical orbit of two homonuclear molecules Li2
Fig. 0.22.
Comparison of energy of two homonuclear molecules Li2
ters in those computations are taken as the time step h = 0.005, the initial values
q(0) = qe, p(0) =
√
2MD −0.0001, and D = 8541cm−1, qe = 2.67328 ˚A, a =
0.867 ˚A
−1, ˚A = 0.1nm. The results show that the symplectic algorithms can preserve
the energy after 106 time steps and the facts that the two Li atoms oscillate periodically
and their trajectories in phase remain invariant are simulated by the symplectic algo-
rithm. The results are opposite for the R–K method. The numerical total energy, and
the oscillation period and amplitude of the two atoms were reduced, after 3000 time
steps. Furthermore, the trajectories in the phase space became ﬂat to q axis after 50000
time steps and lost entirely their shape as manifested in the theory analysis and exper-
iments (Fig. 0.21, Fig. 0.22, Fig. 0.23). The results of the other molecules N2, CO and
CN are similar. Thus, we can draw the conclusion that the symplectic algorithms can
preserve the symplectic structure and the basic properties of the microscopic system.
Therefore they are capable of long time computations for such systems.

Introduction
33
Fig. 0.23.
The trajectories in p −q phase space
(7)
Applications to atmospheric and geophysical science
Recently, the symplectic algorithms have been applied to study the observation opera-
tor of the global positioning system (GPS) by Institute of Atmospheric Physics of the
Chinese Academy of Science[WZJ95,WJX01]. Numerical weather forecasting needs very
large amount of atmospheric information from GPS. One of the key problems in this
ﬁeld is how to reduce largely the computational costs and to compute it accurately
for a long time. The symplectic algorithms provide rapid and accurate numerical al-
gorithms for them to deal with the information of GPS efﬁciently. The computational
costs of the symplectic algorithms are one four hundredth of the costs of traditional
algorithms. For the complicated nonlinear system of atmosphere and ocean, symplec-
tic algorithms can preserve its total energy, total mass, total potential so well that the
relative errors of potential height is below 0.0006 (see Fig. 0.24).
Another application of symplectic algorithms to geophysics is carried out by In-
stitute of Geophysics to prospect for the oil and natural gas[GLCY00,LLL01a,LLL01b,LLL99],
which has obtained several great achievements. For example, the spread waves of
earthquake under the framework of Hamiltonian system and the corresponding sym-
plectic algorithms have been investigated. Moreover, “the information of oil reserves
and geophysics and its process system ” has been produced, and the task of prospecting
for 1010m3 of natural gas, which has obtained. Fig. 0.25 shows the numerical results of
prestack depth migration in the area of Daqing Xujiaweizi by applying symplectic al-
gorithms to Marmousi model. Recently, Liuhong et.al. proposed a new method[LYC06]
to calculate the depth extrapolation operator via exponential of pseudo-differential op-
erator in lateral varied medium. The method offers the phase of depth extrapolation
operator by introducing lateral differential to velocity, which in fact is an application
of Lie group method.

34
Introduction
Fig. 0.24.
The relative errors of potential height is below 0.0006 after 66.5 days
Fig. 0.25.
Numerical results of prestack depth migration in the area of Daqing Xujiaweizi
obtained by applying symplectic algorithms to Marmousi model

Bibliography
[AM78] R. Abraham and J. E. Marsden: Foundations of Mechanics. Addison-Wesley, Reading,
MA, Second edition, (1978).
[Arn63] V. I. Arnold: Small denominators and problems of stability of motion in classical and
celestial mechanics. Russian Math. Surveys, 18:85–191, (1963).
[Arn88] V. I. Arnold: Geometrical Methods In The Theory Of Ordinary Differential Equations.
Springer-Verlag, Berlin , (1988).
[Arn89] V. I. Arnold: Mathematical Methods of Classical Mechanics. Springer-Verlag, GTM
60, Berlin Heidelberg, Second edition, (1989).
[Dea94] P. Z. Ding and et al: Symplectic method of time evolution problem for atomic system.
Atomic and Molecular Physics (in Chinese), 6:440, (1994).
[DLea96] P. Z. Ding, Y. Li and et al: Symplectic method of caculation classical trojectory
for microscopic chemical reaction. Chinese Academic Journals Science and Technology
Abstracts (Express), 2(2):111, (1996).
[DLM97a] A. Dullweber, B. Leimkuhler, and R. McLachlan: Symplectic splitting methods for
rigid body molecular dynamics. J. Chem. Phys., 107:5840–5851, (1997).
[DLM97b] A. Dullweber, B. Leimkuhler, and R. I. McLachlan: Split-Hamiltonian Methods for
Rigid Body Molecular Dynamics. Technical Report 1997/NA11, Department of Applied
Mathematics and Theoretical Physics, University of Cambridge, (1997).
[EMvdS07] D. Eberard, B.M. Maschkea, and A.J. van der Schaftb: An extension of Hamil-
tonian systems to the thermodynamic phase space: Towards a geometry of nonreversible
processes. Reports on Mathematical Physics, 60(2):175–198, (2007).
[Fen65] K. Feng: Difference schemes based on variational principle. J. of Appl. and Comput.
Math.in Chinese, 2(4):238–262, (1965).
[Fen85] K. Feng: On difference schemes and symplectic geometry. In K. Feng, editor, Pro-
ceedings of the 1984 Beijing Symposium on Differential Geometry and Differential Equa-
tions, pages 42–58. Science Press, Beijing, (1985).
[Fen92] K. Feng: How to compute property Newton’s equation of motion. In L. A. Ying, B.Y.
Guo, and I. Gladwell, editors, Proc of 2nd conf. on numerical method for PDE’s, pages 15–
22. World Scientiﬁc, Singapore. (1992). Also see Collected Works of Feng Kang. Volume
I, II. National Defence Industry Press, Beijing, (1995).
[FQ87] K. Feng and M.Z. Qin: The symplectic methods for the computation of Hamiltonian
equations. In Y. L. Zhu and B. Y. Guo, editors, Numerical Methods for Partial Differential
Equations, Lecture Notes in Mathematics 1297, pages 1–37. Springer, Berlin, (1987).
[FQ91a] K. Feng and M.Z. Qin: Hamiltonian Algorithms for Hamiltonian Dynamical Systems.
Progr. Natur. Sci., 1(2):105–116, (1991).
[FQ91b] K. Feng and M.Z. Qin: Hamiltonian algorithms for Hamiltonian systems and a com-
parative numerical study. Comput. Phys. Comm., 65:173–187, (1991).
[FQ03] K. Feng and M. Q. Qin: Symplectic Algorithms for Hamiltonian Systems. Zhejiang
Press for Science and Technology, Hangzhou, in Chinese, First edition, (2003).
[FS95] K. Feng and Z. J. Shang: Volume-preserving algorithms for source-free dynamical
systems. Numer. Math., 71:451–463, (1995).

36
Bibliography
[FW94] K. Feng and D.L. Wang: Dynamical systems and geometric construction of algo-
rithms. In Z. C. Shi and C. C. Yang, editors, Computational Mathematics in China, Con-
temporary Mathematics of AMS Vol 163, pages 1–32. AMS, (1994).
[GDC91] B. Gladman, M. Duncan, and J. Candy: Symplectic integrators for long-term inte-
gration in celestial mechanics. Celest. Mech., 52:221–240, (1991).
[GLCY00] L. Gao, Y. Li, X. Chen, and H. Yang:
An attempt to seismic ray tracing with
symplectic algorithm. Chinese Journal Geophys., 43(3):402–409, (2000).
[Gol80] H. Goldstein: Classical Mechanics. Addison-Wesley Reading, Massachusetts, (1980).
[GS84] V. Guillemin and S. Sternberg: Symplectic Techniques in Physics. Cambridge Univer-
sity Press, Cambridge, (1984).
[GS94a] Z. Ge and C. Scovel: Hamiltonian truncation of shallow water equations. Letters in
Mathematical Physics, 31:1–13, (1994).
[Ham34] Sir W. R. Hamilton: On a general method in dynamics; by which the study of the
motions of all free systems of attracting or repelling points is reduced to the search and
differentiation of one central relation, or characteristic function. Phil. Trans. Roy. Soc.
Part II for 1834, 247–308; Math. Papers, Vol. II, 103–161, Second edition, (1834).
[Ham40] W.R. Hamilton: General methods in dynamics, volume I,II. Cambridge Univ. Press,
(1940).
[HIWZ95] T. Y. Huang, K. A. Innanen, C. B. Wang, and Z. Y. Zhao: Symplectic methods
and their application to the motion of small bodies in the solar system. Earth, Moon, and
Planets,, 71(3):179–183, (1995).
[HKRS97] M. Hankel, B. Karas¨ozen, P. Rentrop, and U. Schmitt: A Molecular Dynamics
Model for Symplectic Integrators.
Mathematical Modelling of Systems, 3(4):282–296,
(1997).
[HL97a] E. Hairer and P. Leone: Order barriers for symplectic multi-value methods. In D.F.
Grifysis, D.F.Higham, and G.A. Watson, editors, Numerical analysis 1997 Proc. of the 17th
Dundee Biennial Conference, June 24-27, 1997, Pitman Reserch Notes in math. series 380,
pages 133–149, (1997).
[IMKNZ00] A. Iserles, H. Z. Munthe-Kaas, S. P. Nørsett, and A. Zanna: Lie-group methods.
Acta Numerica, 9:215–365, (2000).
[JLL02] J. Ji, G. Li, and L. Liu: The dynamical simulations of the planets orbiting gj 876.
Astrophys. J., 572: 1041C-1047, (2002).
[Kle26] F. Klein: Vorlesungen ¨uber die Entwicklung der Mathematik in 19 Jahrhundert. Teub-
ner, (1926).
[Kol54a] A. N. Kolmogorov: General theory of dynamical systems and classical mechanics.
In Proc. Inter. Congr. Math., volume 1, pages 315–333, (1954).
[Kol54b] A. N. Kolmogorov: On conservation of conditionally periodic motions under small
perturbations of the Hamiltonian. Dokl. Akad. Nauk SSSR, 98:527–530, (1954).
[KYN91] H. Kinoshita, H. Yoshida, and H. Nakai: Symplectic integrators and their application
to dynamical astronomy. Celest. Mech. and Dyn. Astro., 50:59–71, (1991).
[LDJW00] Y. X. Li, P. Z. Ding, M. X. Jin, and C. X. Wu: Computing classical trajectories of
model molecule A2B by symplectic algorithm. Chemical Journal of Chinese Universities,
15(8):1181–1186, (2000).
[Lia97] X. Liao: Symplectic integrator for general near-integrable Hamiltonian systems. Ce-
lest. Mech. and Dyn. Astro., 66:243–253, (1997).
[LL94] L. Liu and X. H. Liao: Numerical calculations in the orbital determination of an artiﬁ-
cial satellite for a long arc. Celest. Mech., 59:221–235, (1994).
[LL95] L. Liu and X. H. Liao: Existence of formal integrals of symplectic integrators. Celest.
Mech., 63(1):113–123, (1995).
[LL99] L. D. Landau and E. M. Lifshitz:
Mechanics, Volume I of Course of Theoretical
Physics. Corp. Butterworth, Heinemann, New York, Third edition, (1999).
[LLL99] M. Luo, Y. Li, and H. Lin: The symplectic geometric description and algorithm of
seismic wave propagation. In The 69-th Ann. Seg mecting, volume 199, pages 1825–1828,
(1999).

Bibliography
37
[LLL01a] Y. M. Li, H. Liu, and M. Q. Luo: Seismic wave modeling with implicit symplectic
method based on spectral factorization on helix. Chinese Journal Geophys., 44(3):379–388,
(2001).
[LLL01b] M. Q. Luo, H. Liu, and Y. M. Li: Hamiltonian description and symplectic method
of seismic wave propagation. Chinese Journal Geophys., 44(1):120–128, (2001).
[LLZD01] X. S. Liu, X. M. Liu, Z. Y. Zhao, and P. Z. Ding: Numerical solution of 2-D time-
independent schr¨odings. Int. J. Quant. Chem., 83:303–309, (2001).
[LLZW94] L. Liu, X. Liao, Z. Zhao, and C. Wang: Application of symplectic integrators to
dynamical astronomy(3). Acta Astronomica Sinica, 35:1, (1994).
[LQ88] C.W. Li and M.Z. Qin: A symplectic difference scheme for the inﬁnite dimensional
Hamiltonian system. J. Comput. Appl. Math., 6:164–174, (1988).
[LQ95a] S. T. Li and M. Qin: Lie–Poisson integration for rigid body dynamics. Computers
Math. Applic., 30:105–118, (1995).
[LQ95b] S. T. Li and M. Qin: A note for Lie–Poisson Hamilton-Jacobi equation and Lie-
Poisson integrator. Computers Math. Applic., 30:67–74, (1995).
[LQHD07] X.S. Liu, Y.Y. Qi, J. F. He, and P. Z. Ding: Recent progress in symplectic algorithms
for use in quantum systems. Communications in Computational Physics, 2(1):1–53, (2007).
[LSD02a] X. S. Liu, L. W. Su, and P. Z. Ding: Symplectic algorithm for use in computing the
time independent Schrodinger equation. Int. J. Quant. Chem., 87:1–11, (2002).
[LSD02b] X.S. Liu, L.W. Su, and P. Z. Ding: Symplectic algorithm for use in computing the
time independent schr¨odinger equation. Int. J. Quant. Chem., 87(1):1–11, (2002).
[LYC06] H. Liu, J.H. Yuan, J.B. Chen, H. Shou, and Y.M. Li: Theory of large-step depth
extrapolation. Chinese Journal Geophys., 49(6):1779–1793, (2006).
[LZL93] X. Liao, Z. Zhao, and L. Liu: Application of symplectic algorithms in computation
of LCN. Acta Astronomica Sinica, 34(2):201–207, (1993).
[Men84] C.R. Menyuk: Some properties of the discrete Hamiltonian method. Physica D,
11:109–129, (1984).
[MF81] V.P. Maslov and M. V. Fedoriuk: Semi-classical approximation in quantum mechanics.
D. Reidel Publishing Company, Dordrecht Holland, First edition, (1981).
[MK95] H. Munthe-Kaas. Lie–Butcher theory for Runge–Kutta methods. BIT, 35(4):572–587,
(1995).
[MK98] H. Munthe-Kaas: Runge–Kutta methods on Lie groups. BIT, 38(1):92–111, (1998).
[MK99] H. Munthe-Kaas: High order Runge–Kutta methods on manifolds. Appl. Numer.
Math., 29:115–127, (1999).
[MKO99] H. Munthe-Kaas and B. Owren: Computations in a free Lie algebra. Phil. Trans.
Royal Soc. A, 357:957–981, (1999).
[MKQZ01] H. Munthe-Kaas, G. R. W. Quispel, and A. Zanna: Generalized polar decom-
positions on Lie groups with involutive automorphisms. Foundations of Computational
Mathematics, 1(3):297–324, (2001).
[MKZ97] H. Munthe-Kaas and A. Zanna: Numerical integration of differential equations on
homogeneous manifolds. In F. Cucker and M. Shub, editors, Foundations of Computational
Mathematics, pages 305–315. Springer Verlag, (1997).
[MM05] K.W. Morton and D.F. Mayers: Numerical Solution of Partial Differential Equations:
an introduction. Cambridge University Press, Cambridge, Second edition, (2005).
[MR99] J. E. Marsden and T. S. Ratiu: Introduction to Mechanics and Symmetry. Number 17
in Texts in Applied Mathematics. Springer-Verlag, second edition, (1999).
[MNSS91] R. Mrugała, J.D. Nulton, J.C. Schon, and P. Salamon: Contact structure in thermo-
dynamic theory. Reports on Mathematical Physics, 29:109C121, (1991).
[Mos62] J. Moser: On invariant curves of area-preserving mappings of an annulus. Nachr.
Akad. Wiss. Gottingen, II. Math.-Phys., pages 1–20, (1962).
[QC00] M. Z. Qin and J.B. Chen: Maslov asymptotic theory and symplectic algorithm. Chi-
nese Journal Geophys., 43(4):522–533, (2000).
[Qin89] M. Z. Qin: Cononical difference scheme for the Hamiltonian equation. Mathematical
Methodsand in the Applied Sciences, 11:543–557, (1989).

38
Bibliography
[Qin97a] M. Z. Qin: A symplectic schemes for the pde’s. AMS/IP studies in Advanced Math-
emateics, 5:349–354, (1997).
[QT90] G. D. Quinlan and S. Tremaine: Symmetric multistep methods for the numerical inte-
gration of planetary orbits. Astron. J., 100:1694–1700, (1990).
[QZ90] M. Z. Qin and M. Q. Zhang: Explicit Runge–Kutta–like Schemes to Solve Certain
Quantum Operator Equations of Motion. J. Stat. Phys., 60(5/6):839–843, (1990).
[QZ92] M. Z. Qin and W.J. Zhu: Construction of Higher Order Symplectic Schemes by Com-
position. Computing, 47:309–321, (1992).
[QZ93a] M. Z. Qin and W. J. Zhu: Volume-preserving schemes and numerical experiments.
Computers Math. Applic., 26:33–42, (1993).
[QZ93b] M. Z. Qin and W. J. Zhu: Volume-preserving schemes and applications. Chaos,
Soliton & Fractals, 3(6):637–649, (1993).
[QZ94] M. Z. Qin and W. J. Zhu: Multiplicative extrapolation method for constructing higher
order schemes for ode’s. J. Comput. Math., 12:352–356, (1994).
[Rut83] R. Ruth: A canonical integration technique. IEEE Trans. Nucl. Sci., 30:26–69, (1983).
[Sch44] E. Schr¨odinger: Scripta mathematica, 10:92–94, (1944).
[Shu93] H.B. Shu: A new approach to generating functions for contact systems. Computers
Math. Applic., 25:101–106, (1993).
[ST92a] P. Saha and S. Tremaine: Symplectic integrators for solar system dynamics. Astron.
J., 104:1633–1640, (1992).
[Syn44] J.L. Synge: Scripta mathematica, 10:13–24, (1944).
[Vog56] R. de Vogelaere: Methods of integration which preserve the contact transformation
property of the Hamiltonian equations. Report No. 4, Dept. Math., Univ. of Notre Dame,
Notre Dame, Ind., Second edition, (1956).
[War83] F. W. Warner: Foundations of Differentiable Manifolds and Lie Groups. GTM 94.
Springer-Verlag, Berlin, (1983).
[Wei77] A. Weinstein: Lectures on symplectic manifolds. In CBMS Regional Conference, 29.
American Mathematical Society,Providence,RI, (1977).
[wey39] H. weyl: The Classical Groups. Princeton Univ. Press, Princeton, Second edition,
(1939).
[WH91] J. Wisdom and M. Holman: Symplectic maps for the N-body problem. Astron. J.,
102:1528–1538, (1991).
[WHT96] J. Wisdom, M. Holman, and J. Touma: Symplectic Correctors. In Jerrold E. Mars-
den, George W. Patrick, and William F. Shadwick, editors, Integration Algorithms and
Classical Mechanics, volume 10 of Fields Institute Communications, pages 217–244.
Fields Institute, American Mathematical Society, July (1996).
[WJX01] B. Wang, Z. Ji, and Q. Xiao: the atmospheric dynamics of the equation Hamiltonian
algorithm. Chinese Journal Computational Physics, 18(1):289–297, (2001).
[WZJ95] B. Wang, Q. Zhen, and Z. Ji: The system of square conservation and Hamiltonian
systems. Science in China (series A), 25(7):765–770, (19950.
[Yos90] H. Yoshida: Construction of higher order symplectic integrators. Physics Letters A,
150:262–268, (1990).
[ZL93] Z. Zhao and L. Liu: The stable regions of triangular libration points of the planets .
Acta Astronomica Sinica, 34(1):56–65, (1993).
[ZL94] Z. Zhao and L. Liu: The stable regions of triangular libration points of the planets II.
Acta Astronomica Sinica, 35(1):76–83, (1994).
[ZLL92] Z. Zhao, X. Liao, and L. Liu: Application of symplectic integrators to dynamical
astronomy. Acta Astronomica Sinica, 33(1):33–41, (1992).

Chapter 1.
Preliminaries of Differentiable Manifolds
Before introducing the concept of differentiable manifold, we ﬁrst explain what map-
ping is. Given two sets X, Y, and a corresponding principle, if for any x ∈X, there
exists y = f(x) ∈Y to be its correspondence, then f is a mapping of the set X into
the set Y , which is denoted as f : X →Y. X is said to be the domain of deﬁnition of
f, and f(x) = {f(x) | x ∈X} ⊂Y is said to be the image of f. If f(X) = Y , then
f is said to be surjective or onto; if f(x) = f(x′) ⇒x = x′, then f is said to be injec-
tive (one-to-one); if f is both surjective and injective (i.e., X and Y have a one-to-one
correspondence under f), f is said to be bijective. For a bijective mapping f, if we
deﬁne x = f −1(y), then f −1 : Y →X is said to be the inverse mapping of f. In ab-
stract algebra, a homomorphism is a structure-preserving map between two algebraic
structures (such as groups, rings, or vector spaces). For example, for two groups G and
G′ and a mapping f : G →G′, a →f(a), if f(a, b) = f(a) · f(b), ∀a, b ∈G, then f
is said to be a homomorphism from G to G′. A homomorphism is a map from one al-
gebraic structure to another of the same type that preserves all the relevant structures,
i.e., properties such as identity element, inverse element, and binary operations. An
isomorphism is a bijective homomorphism. If f is a G →G′ homomorphic mapping,
and also a one-to-one mapping from G to G′, then f is said to be a G →G′ isomor-
phic mapping. An epimorphism is a surjective homomorphism. Given two topological
spaces (x, τ) and (y, τ), if the mapping f : X →Y is one-to-one, and both f and its
inverse mapping f −1 : Y →X are continuous, then f is said to be a homeomorphism.
If f and f −1 are also differentiable, then the mapping is said to be diffeomorphism.
A monomorphism (sometimes called an extension) is an injective homomorphism. A
homomorphism from an object to itself is said to be an endomorphism. An endomor-
phism that is also an isomorphism is said to be an automorphism. Given two mani-
folds M and N, a bijective mapping f from M to N is called a diffeomorphism if
both f : M →N and its inverse f −1 : N →M are differentiable (if these functions
are r times continuously differentiable, f is said to be a Cr-diffeomorphism).
Many differential mathematical methods and concepts are used in classical me-
chanics and modern physics: differential equations, phase ﬂow, smooth mapping,
manifold, Lie group and Lie algebra, and symplectic geometry. If one would like to
construct a new numerical method, one needs to understand these basic theories and
concepts. In this book, we brieﬂy explain manifold, symplectic algebra, and symplec-
tic geometry. In a series of books[AM78,Che53,Arn89,LM87,Ber00,Wes81] can be found these
materials.

40
1. Preliminaries of Differentiable Manifolds
1.1 Differentiable Manifolds
The concept of manifold is an extension of Euclidean space. Roughly speaking, a
manifold is an abstract mathematical space where every point has a neighborhood that
resembles Euclidean space (homeomorphism). Differentiable manifold is one of the
manifolds that can have differentiable structures.
1.1.1 Differentiable Manifolds and Differentiable Mapping
Deﬁnition 1.1. A Hausdorff space M with countable bases is called an n-dimensional
topological manifold, if for any point in M there exists an open neighborhood home-
omorphic to an open subset of Rn.
Remark 1.2. Let (U, ϕ), (V, ψ) be two local coordinate systems (usually called
chart) on the topological manifold M. (U, ϕ), (V, ψ) are said to be compatible, if
U ∩V = Ø, or the change of coordinates ϕ ◦ψ−1 and ψ ◦ϕ−1 are smooth when
U ∩V ̸= Ø.
Deﬁnition 1.3. A chart is a domain U ⊂Rn together with a 1 to 1 mapping ϕ : W →
U of a subset W of the manifold M onto U. ϕ(x) is said to be the image of the point
x ∈W ⊂M on the chart U.
Deﬁnition 1.4. A collection of charts ϕi : Wi →Ui is an atlas on M if
1◦
Any two charts are compatible.
2◦
Any point x ∈M has an image on at least one chart.
Remark 1.5. If a smooth atlas on a topological manifold M possesses with its all
compatible local coordinate systems (chart), then this smooth atlas is called the maxi-
mum atlas.
Deﬁnition 1.6. If an n-dimensional topological manifold M is equipped with the
maximal smooth atlas A, then (M, A) is called the n-dimensional differentiable man-
ifold, and A is called the differentiable structure on M.
Deﬁnition 1.7. Two atlases on M are equivalent if their union is also an atlas (i.e., if
any chart of the ﬁrst atlas is compatible with any chart of the second).
Remark 1.8. Suppose M is the n-dimensional topological manifold, A = {(Uλ, ϕλ)}
is a smooth atlas on M. Then there exists a unique differentiable structure A∗, which
contains A. Hence, a smooth atlas determines a unique differentiable structure on M.
The local coordinate system will be called (coordinate) chart subsequently.
Deﬁnition 1.9. A differentiable manifold structure on M is a class of equivalent at-
lases.
Deﬁnition 1.10. A differentiable manifold M is a set M together with a differentiable
manifold structure on it. A differentiable manifold structure is induced on set M if an
atlas consisting of compatible charts is prescribed.

1.1 Differentiable Manifolds
41
Below are examples of differentiable manifold.
Example 1.11. Rn is an n-dimensional differentiable manifold.
Let A ={(Rn, I)}, where I is the identity mapping.
Example 1.12. Sn is an n-dimensional differentiable manifold.
We only discuss the n = 1 case. Let
U1 = {(u1, u2) ∈S1|u1 > 0},
U2 = {(u1, u2) ∈S1|u1 < 0},
U3 = {(u1, u2) ∈S1|u2 > 0},
U4 = {(u1, u2) ∈S1|u2 < 0}.
Deﬁne ϕi : Ui →(−1, 1), such that (s.t.)
ϕi(u1, u2) = u2,
i = 1, 2;
ϕi(u1, u2) = u1,
i = 3, 4.
Note that on ϕ1(U1 ∩U3)
ϕ3 ◦ϕ−1
1
: u2 −→(

1 −(u2)2, u2) −→

1 −(u2)2
is smooth, then A ={(Uk, ϕk)} is a smooth atlas on S1.
Example 1.13. RP n is an n-dimensional differentiable manifold.
Let
Uk = {[(u1, · · · , un+1)] | (u1, · · · , un+1) ∈Sn, uk ̸= 0},
k = 1, · · · , n + 1
deﬁnes ϕk : Uk →Int Bn(1), s.t.
ϕk([(u1, · · · , un+1)]) = uk|uk|−1(u1, · · · , uk−1, uk+1, · · · , un+1),
where Bn(1) =

(u1, · · · , un) ∈Rn
n

i=1
(ui)2 ≤1

. It is easy to prove that A
={(Uk, ϕk)} is a smooth atlas on RP n.
Example 1.14. Let M, N be m- and n-dimensional differentiable manifolds, respec-
tively, then M ×N is a m+n dimensional differentiable manifold (product manifold).
Suppose A = {(Uα, ϕα)}, B = {(Vα, ψα)} are smooth atlases on M, N re-
spectively. Denote A × B={(Uα × Vλ, ϕα × ψλ)}, where ϕα × ψλ: Uα × Vλ →
ϕα(Uα) × ψλ(Vλ),(ϕα × ψλ)(p, q) =

ϕα(p), ψλ(q)

, (p, q) ∈Uα × Vλ, then A × B
is a smooth atlas on M × N .
Deﬁnition 1.15. Let M, N be m- and n-dimensional differentiable manifolds, respec-
tively. A continuous mapping f : M →N is called Ck differentiable at p ∈M, if
the local representation f = ψ ◦f ◦ϕ−1 : ϕ(U) →ψ(V ) is Ck differentiable for
the charts (U, ϕ), (V, ψ) corresponding to points p and f(p), and f(U) ⊂V . If f is
Ck differentiable in each p ∈M , then f is called Ck differentiable, or called Ck
mapping. See Fig. 1.1.

42
1. Preliminaries of Differentiable Manifolds
Fig. 1.1.
A differentiable mapping
Example 1.16. Let M1, M2 be m- and n-dimensional differentiable manifolds, re-
spectively. Deﬁne θ1 : M1 × M2 →M1, θ2 : M1 × M2 →M2, such that
θ1(p, q) = p,
θ2(p, q) = q,
∀(p, q) ∈M1 × M2,
then θ1, θ2 are all smooth mappings.
If the charts on M1, M2 are denoted by (U, ϕ), (V, ψ), then it is easy to show that
(U × V, ϕ × ψ) is the chart on M1 × M2. Thus, the local coordinate expression of θ1,
θ1 = ϕ ◦θ1 ◦(ϕ × ψ)−1 : (ϕ × ψ)(U × V ) −→ϕ(U),
θ1(u, v) = u
is a smooth mapping. Therefore, θ1 is a smooth mapping. Likewise, θ2 is also a smooth
mapping.
Example 1.17. Let M, N1, N2 be differentiable manifolds.
f1 : M −→N1,
f2 : M −→N2
are Ck-mapping. Deﬁne
f : M −→N1 × N2,
f(p) = (f1(p), f2(p)),
∀p ∈M,
then f is a Ck-mapping.
∀p0 ∈M, let N1 contain the chart (V, ψ) of f1(p0), and let N2 contain the chart
(W, χ) of f2(p0), and M contain the chart (U, ϕ) of p0. Assume f1(U) ⊂V, f2(U) ⊂
W, and
f1 : ψ ◦f1 ◦ϕ−1 : ϕ(U) −→ψ(V ),
f2 : χ ◦f2 ◦ϕ−1 : ϕ(U) −→χ(W)
are all Ck-mapping, and (V × W, ϕ × χ) is a chart that contains (f1(p0), f2(p0)) =
f(p0) on the product manifold N1 × N2, which satisﬁes f(U) ⊂V × W. Then we
have
f = (ψ × χ) ◦f ◦ϕ−1 : ϕ(U) −→(ψ × χ)(U × W),
f = ( f1, f2),
i.e., f is Ck-mapping.

1.1 Differentiable Manifolds
43
Remark 1.18. According to the deﬁnition, if f : M →N, g : N →L are Ck-
mappings, then g ◦f : M →L is also a Ck-mapping.
Deﬁnition 1.19. Let M, N be differentiable manifolds, f : M →N is a homeomor-
phism. If f, f −1 are smooth, then f is called diffeomorphism from M to N. If there
exists a diffeomorphism between differentiable manifolds M and N, then M and N
are called differentiable manifolds under diffeomorphism, denoted by M ≃N.
If we deﬁne two smooth atlases (R, I), (R, ϕ) on R, and ϕ : R →R, ϕ(u) = u3,
because the change of coordinates I ◦ϕ−1(u) =
3√u in u = 0 is not differentiable,
then (R, I) and (R, ϕ) determine two different differentiable structures A, A′ on R.
However, if we deﬁne f : (R, A) →(R, A′), {f(u)} = u3, then (R, A) ≃(R, A′).
In fact, there exist examples that are not homeomorphism in a differentiable man-
ifold, like the famous Milnor exotic sphere.
1.1.2 Tangent Space and Differentials
In order to establish the differential concept for differentiable mapping on a differen-
tiable manifold, we ﬁrst need to extend the concept of tangent of curve and tangent
plane of surface in Euclidean space. If we take the tangent vector in Euclidean space
not simply as a vector with size and direction, but as a linear mapping, which satisﬁes
the Leibniz rule, from the differentiable functional space to R, then the deﬁnition of
tangent vector can be given similarly for a manifold.
Let M be the m-dimensional differentiable manifold, p ∈M be a ﬁxed point. Let
C∞(p) be the set of all smooth functions that are deﬁned in some neighborhood of p.
Deﬁne operations on M that have the following properties:
(f + g)(p) = f(p) + g(p),
(αf)(p) = αf(p),
(fg)(p) = f(p)g(p).
Deﬁnition 1.20. A tangent vector Xp at the point p ∈M is a mapping
Xp : C∞−→R,
that has the following properties:
1◦
Xp(f) = Xp(g), if f, g ∈C∞(p) are consistent in some neighborhood of
the point p.
2◦
Xp(αf + βg) = αXp(f) + βXp(g), ∀f, g ∈C∞(p), ∀α, β ∈R.
3◦
Xp(fg) = f(p)Xp(g) + g(p)Xp(f), ∀f, g ∈C∞(p) (which is equivalent
to the derivative operation in Leibniz rule).
Denote TpM={All tangent vectors at the point p ∈M } and deﬁne operation:
(Xp + Yp)(f) = Xp(f) + Yp(f),
(kXp)(f) = kXp(f),
∀f ∈C∞(p).

44
1. Preliminaries of Differentiable Manifolds
It is easy to verify that TpM becomes the vector space that contains the above op-
eration, which is called the tangent space at the point p of the differential manifold
M.
Remark 1.21. By deﬁnition of the tangent vector, it is easy to know that if f is the
constant function, Xp(f) = 0 for Xp ∈TpM.
Lemma 1.22. Let (U, ϕ) be the chart that contains p ∈M, and let x1, · · · , xm, ϕ(p)
= (a1, · · · , am) be the coordinate functions. If f ∈C∞(p), then there exists a function
gi in some neighborhood W of p ∈M, such that
f(q) = f(p) +
m

i=1
(xi(q) −ai)gi(q),
∀q ∈W,
and gi(p) = ∂f
∂xi

p

where ∂f
∂xi

p =
∂
∂xi

p(f) = ∂f ◦ϕ−1
∂ui

ϕ(p)

.
Proof. Assume ϕ(p) = O ∈Rm, and f is well deﬁned in some neighborhood of p.
Let W = ϕ−1(Bm). Then ∀q ∈W and we have
f(q) −f(p) = f ◦ϕ−1(u) −f ◦ϕ−1(O).
After calculation, we obtain
f(q) −f(p) =
m

i=1
uigi(u),
where gi(u) =
 1
0
∂f ◦ϕ−1
∂ui
(su1, · · · , sum) d s (i = 1, · · · , m). Let gi(ϕ(q)) =
gi(q), then gi is smooth on W, and satisﬁes
f(q) = f(p) +
m

i=1
xi(q)gi(q),
gi(p) = gi(O) = ∂f ◦ϕ−1
∂ui

O = ∂f
∂xi

p.
Hence lemma is proved.
▲
Theorem 1.23. Deﬁne
∂
∂xi

p : C∞(p) →R,
∂
∂xi

p(f) = ∂f ◦ϕ−1
∂ui

ϕ(p), ∀f ∈
C∞(p), then
∂
∂xi

p (i = 1, · · · , m) is a group of bases for TpM. Therefore, dim TpM
= m, and for Xp ∈TpM, we have
Xp =
m

i=1
Xp(xi) ∂
∂xi

p.

1.1 Differentiable Manifolds
45
Proof. ∀Xp ∈TpM, as f ∈C∞(p). By Lemma 1.22, we know
f = f(p) +
m

i=1
(xi −ai)gi,
then
Xp(f) =
m

i=1
Xp[(xi −ai)gi] =
m

i=1
Xp(xi) ∂f
∂xi

p =
m

i=1
Xp(xi) ∂
∂xi

p(f).
The decomposed coefﬁcients, {Xp(xi)}, of Xp with respect to (w.r.t.) the bases
∂
∂xi

p (i = 1, · · · , m) are called coordinates of the tangent vector Xp w.r.t. the
chart(U, ϕ).
▲
Remark 1.24. By Theorem 1.23 we know: if the coordinates of Xp w.r.t. chart (U, ϕ)
are deﬁned as (Xp(x1), · · ·, Xp(xm)), then TpM and Rm are isomorphisms, and the
basis for TpM corresponds exactly to the standard basis for Rm, i.e.,
∂
∂xi

p →ei =
(0, · · · , 1, 0, · · · , 0).
1.
Deﬁnition and properties of differentials of mappings
The deﬁnition of differentials of a mapping is as follows:
Deﬁnition 1.25. Let f : M →N be a smooth mapping. ∀p ∈M, Xp ∈TpM, we
deﬁne f∗p : TpM →Tf(p)N that satisﬁes:
f∗p(Xp)(g) = Xp(g ◦f),
∀g ∈C∞(f(p)).
This linear mapping f∗p is called the differential of f at the p ∈M.
Deﬁnition 1.26. The differential of the identity mapping I is an identity mapping,
i.e., I∗p : TpM →TpM.
Remark 1.27. Let M, N, L be differentiable manifolds, p ∈M, and f : M →N, g :
N →L are smooth mappings, then (g ◦f)∗p = g∗f(p) ◦f∗p.
Remark 1.28. If f : M →N is a diffeomorphism, then f∗p : TpM →Tf(p)N is a
isomorphism.
Proposition 1.29. Let x1, · · · , xm, y1, · · · , yn be the coordinate functions of (U, ϕ),
(V, ψ) respectively, then
f∗p
 ∂
∂xi

p

=
n

j=1
∂fj
∂xi

p
∂
∂yj

f(p),
where fj = yj ◦f.

46
1. Preliminaries of Differentiable Manifolds
Proof. Since
f∗p
 ∂
∂xi

p

(yk) =
∂
∂xi

p(yk ◦f) = ∂fk
∂xi

p,
therefore, by Theorem 1.23 we have
f∗p
 ∂
∂xi

p

=
n

i,j=1
∂fj
∂xi

p
∂yk
∂yj

f(p)
=
n

i,j=1
∂fj
∂xi

p
∂
∂yj

f(p)(yk).
Therefore the proposition is completed.
▲
Let Xp =
n

i=1
αi ∂
∂xi

p, f∗p(Xp) =
n

j=1
βj ∂
∂yj

f(p), by Proposition 1.29, we
have
⎛
⎜
⎝
β1
...
βn
⎞
⎟
⎠=
⎛
⎜
⎜
⎜
⎝
∂f1
∂x1
· · ·
∂f1
∂xm
...
...
∂fn
∂x1
· · ·
∂fn
∂xm
⎞
⎟
⎟
⎟
⎠
⎛
⎜
⎝
α1
...
αm
⎞
⎟
⎠.
This matrix
 ∂fi
∂xj

n×m is the Jacobian matrix of f at p w.r.t. charts (U, ϕ), (V, ψ).
Its rank rkpf is called the rank of f : M →N at the p. From the above equations,
we can easily observe that f∗p is equivalent to D f(ϕ(p)) under the assumption of
isomorphism, where D f(ϕ(p)) is the differential at ϕ(p) of the local representation of
f, f = ψ ◦f ◦ϕ−1.
2.
Geometrical meaning of differential of mappings
A smooth curve on M is a smooth mapping c : (a, b) →M. The tangent vector,
c∗t0
 d
d t

t0

on Tc(t0)M is called the velocity vector of c at t0. Let f : M →N be a
smooth mapping. Then, f ◦c is a smooth curve on N that passes f(p). By composite
differentiation, we have
(f ◦c)∗t0
 d
d t

t=t0

= f∗p0 ◦c∗t0
 d
d t

t=t0

,
i.e., f∗p0 transforms the velocity vector of c at t0 to the velocity vector of f ◦c at t0.
1.1.3 Submanifolds
The extension of the curve and surface on Euclidean space to the differentiable mani-
fold is the submanifold. In the following section, we focus on the deﬁnitions of three
submanifolds and their relationship. First, we describe a theorem.

1.1 Differentiable Manifolds
47
1.
Inverse function theorem
Theorem 1.30. Let M, N be m-dimensional differentiable manifolds, f : M →N
is a smooth mapping, p ∈M. If f∗p : TpM →Tf(p)N is an isomorphism, then there
exists a neighborhood, W of p ∈M , such that
1◦
f(W) is a neighborhood of f(p) in N.
2◦
f|W : W →f(W) is a diffeomorphism (this theorem is an extension of the
inverse function theorem for a manifold).
Proof. Consider charts (U, ϕ) on M about p ∈M and (V, ψ) on N about f(p) ∈N,
so that f(U) ⊂V . Then, the local representation f = ψ ◦f ◦ϕ−1 : ϕ(U) →ψ(V )
is a smooth mapping. Since f∗p : TpM →Tf(p)N is an isomorphism, D ˆf(ϕ(p)) :
Rm →Rm is also an isomorphism. By the inverse function theorem, there exists
a neighborhood O of ϕ(p) ∈Rm such that f(O) is a neighborhood of ψ(f(p)) in
Rm, and f : O →f(O) is a diffeomorphism. O has to be chosen appropriately. Let
O ⊂ϕ(U), and f(O) ⊂ψ(V ). Let W = ϕ−1(O). Then, W is the neighborhood of
p, which meets our requirement.
▲
Remark 1.31. Given a chart (V, ψ) on N, f(p) ⊂V , choose ϕ = ψ ◦f and some
neighborhood U of p, such that ϕ(U) ⊂V . By 2◦of Theorem 1.30, f|W : W →
f(W) is a diffeomorphism and (U, ϕ) is a chart on M. Hence f = ψ ◦f ◦ϕ−1 = I
is an identity mapping from ϕ(U) to ψ(V ).
Example 1.32. Suppose f : R →S1, deﬁned by f(t) = (cos t, sin t). Using the
chart of Example 1.11, we obtain
f ′(t) =

cos t,
t ∈

kπ −π
2 , kπ + π
2

,
−sin t,
t ∈(kπ, (k + 1)π).
Obviously, f ′(t) ̸= 0, ∀t ∈R. However, f : R →S1 is not injective. Thus, f is not
a diffeomorphism. This example shows that f∗p : TpM →Tf(p) N isomorphism and
f : M →N homeomorphism at some neighborhood of p are only local properties.
We have discussed the case where f∗p : TpM →Tf(p)N is an isomorphism. In
the following section we turn to the case when f∗p is injective.
2.
Immersion
Deﬁnition 1.33. Let M, N be differentiable manifolds, and f : M →N a smooth
mapping, and p ∈M. If f∗p : TpM →Tf(p)N is injective (i.e., rkpf = m), then f
is said to immerse at p. If f immerses at every p ∈M, then f is called an immersion.
Below are some examples of immersion.
Example 1.34. Let U ∈Rm be an open subset, α : U →Rn, α(u1, · · · , um) =
(u1, · · · , um, 0, · · · , 0).
By deﬁnition, α is obviously an immersion, and is often called a model immersion.

48
1. Preliminaries of Differentiable Manifolds
Proposition 1.35. Let M, N be m- and n-dimensional differentiable manifolds re-
spectively; f : M →N is a smooth mapping, p ∈M. If f immerses at p, then there
exist charts (U, ϕ) on M about p ∈M and (V, ψ) on N about f(p) ∈N in which the
coordinate description f = ψ ◦f ◦ϕ−1 : ϕ(U) →ψ(V ) has the form
f(u1, · · · , um) = (u1, · · · , um, 0, · · · , 0).
Proof. Choose charts (U1, ϕ1) and (V1, ψ1) appropriately so that p ∈U1, f(p) ∈
V1, ϕ1(p) = 0 ∈Rm, ψ1(f(p)) = 0′ ∈Rn and f(U1) ⊂V1. Since f immerses
at p, the rank of Jacobian J f(0) =
 ∂fi
∂uj

0 is m, where f = ( f1, · · · , fn). We can
assume that the ﬁrst m rows in the Jacobian matrix J f(0) are linearly independent.
Then, deﬁne a mapping for ϕ1(U1) × Rn−m →Rn = Rm × Rn−m by
g(u, v) = f(u) + (0, v).
It is easy to prove that g(u, 0) = f(u) maps origin 0′ to itself in Rn and the rank of
Jg(O′) =
 
J f(O)
0
In−m
!
is n, where 0 denotes a m × (n −m) zero matrix, and by
the inverse function theorem, g is a diffeomorphism from a neighborhood of origin of
Rm to a neighborhood of origin of Rn. Shrink U1, V1 so that they become U, V , and
let ϕ = ϕ1|U, ψ = g−1 ◦(ψ|V ). Since ψ ◦f ◦ϕ−1 = g−1 ◦ψ1 ◦f ◦ϕ−1
1
= g−1 ◦f =
g(u, 0), the proposition is proved.
▲
Remark 1.36. By deﬁnition of immersion, if f : M →N immerses at p ∈M, then
f immerses in some neighborhood of p.
Remark 1.37. By Proposition 1.35, f limited in some neighborhood of p has a local
injective expression f = (u1, · · · , um, 0, · · · , 0). Then, f limited in some neighbor-
hood of p is injective. Note that this is only a local injection, not total injective.
Deﬁnition 1.38. Let N, N ′ be differentiable manifolds, N ′ ⊂N. If the inclusion
map i : N ′ →N is an immersion, then N ′ is said to be an immersed submanifold of
N.
Remark 1.39. Suppose f is an immersion and injective (such f would henceforth be
called injective immersion), M is a smooth atlas A = {(Uα, ϕα)}. Denote fA =
{(f(Uα), ϕα ◦f −1)}. Then, it is easy to prove that {f(M), fA} is a differentiable
manifold. Since f has a local expression f = ϕα ◦f −1 ◦f ◦ϕ−1
α
= I : ϕα(Uα) →
ϕα(Uα), f : M →f(M) is a diffeomorphism, i.e., f∗p : TpM →Tf(p)f(M) is an
isomorphism. Since f is an immersion, the inclusion map i : f(M) →N is also an
immersion. Hence, f(M) is an immersed submanifold of N.
From the following example, we can see that the manifold topology of an immersed
submanifold may be inconsistent with its subspace topology and can be very complex.

1.1 Differentiable Manifolds
49
Example 1.40. T 2 = S1 × S1 = {(z1, z2) ∈C × C | |z1| = |z2| = 1}. Deﬁne
f : R →T 2, s.t. f(t) = (e2πit, e2πiα), where α is an irrational number. We can
prove that f(R), which is a differentiable manifold derived from f, is an immersed
submanifold of T 2, and f(R) is dense in T 2.
We may regard T 2 as a unit square on the plane of R2, which is also a 2D manifold
that has equal length on opposite sides. It can be represented by a pair of ordered real
numbers (x, y), where x, y are mod Z real numbers. Deﬁne
ϕ : R2 −→S1 × S2,
ϕ(u1, u2) = (e2πiu1, e2πiu2)
and deﬁne “ ∼” : (u1, u2) ∼(v1, v2) ⇔u1 = v1(mod Z), u2 = v2(mod Z), and
let W =

u1
0 −1
2, u1
0 + 1
2

×

u2
0 −1
2, u2
0 + 1
2

. Then, (ϕ(W), ϕ−1) is a chart
of T 2 = S1 × S1 that contains f(t0). Choose a neighborhood U of t0 ∈R so that
f(U) ⊂ϕ(W). Then, the local expression of f, f = (t, αt) is an immersion at t0. It
is easy to prove that if ϕ−1f(R) is dense in R2, then f(R) is dense in T 2 = S1 ×S1.
By deﬁnition, f is injective. It is concluded that the topology of T 2 is different from
the topology of f(U), which derives from f(R).
3.
Regular submanifolds
The type of submanifold given below has a special relationship to its parent differential
manifold, which is similar to that of Euclidean space and its subspace.
Deﬁnition 1.41. Let M ′ ⊂M have the subspace topology, and k be some nonnega-
tive integer, 0 ≤k ≤m. If there exists a chart (U, ϕ) of M that contains p in every
p ∈M ′, so that
1◦
ϕ(p) = O ∈Rm.
2◦
ϕ(U ∩M ′) = {(u1, · · · , um) ∈ϕ(U) | uk+1 = · · · = um = 0}.
Then M ′ is said to be a k-dimensional regular submanifold of M, and the chart is
called submanifold chart.
Let A′ = {(Uα, ϕα)} be a set that contains all submanifold charts on M. Denote
"
A={("Uα, "ϕα)}, where "Uα = Uα ∩M ′, "ϕα = π ◦(ϕα|"Uα), π : Rk × Rm−k →Rk.
Since M ′ has the subspace topology, "Uα is an open set of M ′, and "ϕα : "Uα →"ϕα("Uα)
is a homeomorphism for "Uα to "ϕα("Uα) ⊂Rk. Moreover, Uα
# "Uα = M ′, and hence
"
A is an atlas of M ′. ∀("Uα, "ϕα), ("Uβ, "ϕβ) ∈"
A and "Uα ∩"Uβ ̸= Ø, we have
$
ϕβ ◦"ϕ−1
α (u1, · · · , uk) = π ◦ϕβ ◦ϕ−1
α (u1, · · · , uk, 0, · · · , 0).
Obviously, "
A is a smooth atlas of M ′, which determines a differentiable structure of
M ′. Thus, M ′ is a k-dimensional differentiable manifold.
Below is an example of regular submanifold.
Example 1.42. Let M, N be m- and n-dimensional differentiable manifolds respec-
tively, and f : M →N be a smooth mapping. Then, the graph of f
gr(f) = {(p, f(p)) ∈M × N | p ∈M}
is an m-dimensional closed submanifold of M × N ( closed regular submanifold ).

50
1. Preliminaries of Differentiable Manifolds
Proof. Consider charts (U, ϕ), (V, ψ), p0 ∈U, f(p0) ∈V, ϕ(p0) = O ∈Rm,
ψ(f(p0)) = O′ ∈Rn, f(U) ⊂V , and deﬁne G : ϕ(U) × ψ(V ) →Rn+m =
Rm × Rn, so that
G(u, v) = (u, v −f(u)).
It is easy to prove that G(gr( f)) = {(u, O′) | u ∈ϕ(U)}, and the rank of
JG(O, O′) =
%
Im
O
−D f(O)
In
&
is n+m. Since G(O, O′) = (O, O′), G homeomorphically maps some neighborhood
"U of (O, O′) on ϕ(U)×ψ(V ) to some neighborhood "V of (O, O′) on Rn+m. Denote
W = (ϕ × ψ)−1("U),
χ = G ◦(ϕ × ψ)|W.
Then, (W, χ) is a chart of M × N that contains (p0, f(p0)), and
χ(p0, f(p0)) = (O, O′) ∈Rn+m,
χ(W ∩gr(f)) = {(u, v) ∈χ(W)|v = 0}.
The proof can be obtained.
▲
Remark 1.43. If N ′ is a regular submanifold N, f : M →N is a smooth mapping,
f(M) ⊂N ′, then f : M →N ′ is also a smooth mapping. Let (U, ϕ), (V, ψ) be
charts of N, then ("V , "ψ) is a induced chart of N ′ from N. Then, by the fact that N ′ is
a regular submanifold of N, we know ψ ◦f ◦ϕ−1(u) = ( "ψ ◦f ◦ϕ−1(u), 0). Then,
the smoothness of f : M →N leads to the smoothness of f : M →N ′.
Remark 1.44. Let M ′ be a k-dimensional regular submanifold of M, then i : M ′ →
M is the inclusion mapping. Take a submanifold chart (U, ϕ) of M that induces the
chart ("U, "ϕ) of M ′. Then,i = ϕ ◦i ◦"ϕ−1 : "ϕ("U) →ϕ(U) has the form
i (u1, · · · , uk) = (u1, · · · , uk, 0, · · · , 0).
Thus, i∗p : TpM ′ →TpM is injective, which means that the regular submanifold is
deﬁnitely an immersed submanifold.
4.
Embedded submanifolds
Deﬁnition 1.45. Let f : M →N be an injective immersion. If f : M →f(M) is
a homeomorphism, where f(M) has the subspace topology of N, then f(M) is an
embedded submanifold of N.
Proposition 1.46. Suppose f : M →N is an embedding, then f(M) is a regular
submanifold of N, and f : M →f(M) is a diffeomorphism.

1.1 Differentiable Manifolds
51
Proof. Since f is an embedding, f is an immersion ,∀q ∈f(M), ∃p ∈M so that
f(p) = q. Let charts (U, ϕ), (V, ψ), p ∈U, f(p) ∈V so that ϕ(p) = O ∈Rm, ψ(q) =
O′ ∈Rn, f(U) ⊂V , and f(u1, · · · , um) = (u1, · · · , um, · · · , 0). Since f : M →
f(M) is a homeomorphism, if U is an open subset of M, then f(U) is an open subset
of f(M), and there exists an open subset W1 ⊂N so that f(U) = W1 ∩f(M).
Denote W = V ∩W1, χ = ψ|W. Then, χ(q) = O′ ∈Rn, and
χ(W ∩f(M)) = {(u1, · · · , un) ∈χ(W) | um+1 = · · · = un = 0},
i.e., (W, χ) is a submanifold chart of N that contains q, which also means that f(M)
is a regular submanifold of N. Let ($
W, "χ) be a chart of f(M) induced from (W, χ).
Then from χ ◦f ◦ϕ−1(u) = ("χ ◦f ◦ϕ−1(u), 0), we conclude that f : M →f(M)
is a diffeomorphism.
▲
Remark 1.47. If f is an immersion, then we can appropriately choose the charts of
M, N, such that f has the local expression f(u1, · · ·, um) = (u1, · · · , um, · · · , 0).
Therefore, it is easy to see that f can be an injective immersion in the neighborhood
U of p, and f : U →f(U) is a homeomorphism. Obviously, f(U) has the induced
subspace topology from N. Therefore, f | U : U →N is an embedding.
Deﬁnition 1.48. Let X, Y be two topological spaces, and f : X →Y be continuous.
If for every compact subset K in Y , we have f −1(K) to be a compact subset in X,
then f is said to be a proper mapping.
Proposition 1.49. Let f : M →N be an injective immersion. If f is a proper map-
ping, then f is an embedding.
Proof. It would be sufﬁcient to prove f −1 : f(M) →M is continuous. Assume there
exist an open set W of M and a sequence of points {qi} of f(M) s.t. qi /∈f(W),but
{qi} converges to some point qi of f(W). Denote pi = f −1(qi), p0 = f −1(q0), p0 ∈
W. Since {q0, qi}(i = 1, 2, · · ·) is compact, and f is a proper mapping, {p0, pi}(i =
1, 2, · · ·) is a compact set of M. Let p1 ∈M be the convergence of {pi}. Since
f is continuous, {f(pi)} converges to f(p1), i.e., f(p1) = f(p0). Thus, p0 = p1.
Therefore, when i is large enough, there exists pi ∈W, and qi = f(pi) ∈f(W). This
is in contradiction with qi /∈f(W).
▲
Remark 1.50. Let f be an injective immersion. If M is compact, then f is a proper
mapping. By Proposition 1.49, f is an embedding.
1.1.4 Submersion and Transversal
Below we will discuss the local property of f when f∗p : TpM →Tf(p)N is surjec-
tive.
Deﬁnition 1.51. f is smooth, p ∈M. If f∗p : TpM →Tf(p)N is surjective, then f is
a submersion at p; if f is a submersion at every p ∈M, then f is said be a submersion.
Similar to the proposition for f that immerses at p, we have the following propo-
sition.

52
1. Preliminaries of Differentiable Manifolds
Proposition 1.52. Given a smooth f and p ∈M, if f submerses at p, then there
exists chart (U, ϕ) on M about p and (V, ψ) on N about f(p) ∈N in which f =
ψ ◦f ◦ϕ−1 : ϕ(U) →ψ(V ) has the form
f(u1, · · · , um) = (u1, · · · , un).
Proof. Take charts (U1, ϕ1), (V, ψ1), p ∈U1, f(p) ∈V, ϕ1(p) = O ∈Rm, ψ1(f(p))
= O′ ∈Rn and f(U1) ⊂V . Since f is a submersion, J f(O) =
 ∂fi
∂uj

O has rank
n, where f = ( f1, · · · , fn). We assume that the ﬁrst n rows of J f(O) are linearly
independent. Let g : ϕ1(U1) →ψ(V ) × Rm−n satisfy
g(u1, · · · , um) = ( f(u1, · · · , um), un+1, · · · , um).
Then, g(O) = O, and Jg(O) =
 
J f(O)
O
Im−n
!
has rank n. By the inverse function
theorem, g(O) maps a neighborhood W at O diffeomorphically to a neighborhood of
g(W) ⊂ψ(V )×Rm−n. Let U = W ∩U1, ϕ = g ◦(ϕ1|U), then ψ ◦f ◦ϕ−1
1 ◦g−1 =
β ◦g ◦g−1 = β, and β : Rm →Rn, β(u1, · · · , um) = (u1, · · · , un) is a projection
from Rm →Rn.
▲
Remark 1.53. By Deﬁnition 1.51, if f : M →N is a submersion at p ∈M , then f
is a submersion in some neighborhood of p.
Remark 1.54. If f : M →N is a submersion, then f is an open mapping (i.e., open
set mapping to an open set). Furthermore, f(M) is an open subset of N.
Let G be an open subset of M, ∀q ∈f(G). There exists a p ∈G, s.t. f(p) = q.
Since f is a submersion, there exist charts (U, ϕ), (V, ψ), p ∈U, q ∈V , s.t. U ⊂G,
and f : ϕ(U) →ψ(V ), f(u1, · · · , um) = (u1, · · · , un). Let H = β(ϕ(U)), where
β(u1, · · · , um) = (u1, · · · , un), s.t. H ⊂ψ(V ). Thus, ψ−1(H) is a neighborhood of
q ∈N , ψ−1(H) ⊂f(G), i.e., f(G) is an open subset of N.
Next, we consider under what condition would f −1(q0) be a regular submanifold
of M, and ∀q0 ∈N be ﬁxed.
Deﬁnition 1.55. Given f : M →N is smooth, p ∈M, if f∗p : TpM →Tf(p)N is
surjective, then p is said to be a regular point of f (i.e., f submerses at p), otherwise p
is said to be a critical point of f, and q ∈N is called a regular value of f, if q /∈f(M)
or q ∈f(M), but each p ∈f −1(q) is a regular point of f; otherwise, q is called a
critical value of f.
Remark 1.56. When dim M < dim N, as a result of dim TpM = dim M <
dim N = dim Tf(p)N, for q ∈f(M), p ∈f −1(q), p cannot be a regular point
of f. Hence, q ∈N is a regular value of f ⇔q /∈f(M).
Theorem 1.57. Let f : M →N be smooth, q ∈N; if q is a regular value of f,
and f −1(q) ̸= Ø, then f −1(q) is an (m −n)-dimensional regular submanifold of M.
Moreover, ∀p ∈f −1(q),
Tp{f −1(q)} = ker f∗p.

1.1 Differentiable Manifolds
53
Proof. Since q is a regular value, ∀p ∈f −1(q), f submerses at p by deﬁnition. By
the Proposition 1.52, there exist charts (U, ϕ), (V, ψ), p ∈U, f(p) = q ∈V, ϕ(p0) =
O ∈Rm, ψ(q) = O′ ∈Rn, and ψ ◦f ◦ϕ−1(u1, · · · , um) = f(u1, · · · , um) =
(u1, · · · , un), ϕ{U ∩f −1(q)} = {(u1, · · · , um) ∈ϕ(U) | u1 = · · · = un = 0},
i.e., (U, ϕ) is a submanifold chart of M that contains p. Therefore, f −1(q) is a regular
submanifold of M, and dim f −1(q) = m −n.
Note that f|f −1(q) : f −1(q) →M, f|f −1(q) = f ◦i, i : f −1(q) →M is an inclu-
sion mapping. Since f|f −1(q) = q is a constant mapping, f∗p◦i∗p = (f|f −1(q))∗p = 0,
i.e., i∗p(Tp{f −1(q)}) ⊂ker f∗p. Furthermore, because q is a regular value of f,
f∗p(TpM) = TqN, and dim ker f∗p = dim TpM −dim f∗p(TpM) = m −n =
dim f −1(q). Therefore, we have Tp{f −1(q)} = ker f∗p.
▲
Remark 1.58. Given f : M →N is smooth, dim M = dim N, M is compact. If
q ∈N is a regular value of f, then f −1(q) = Ø or f −1(q) consists of ﬁnite points.
By Theorem 1.57, if f −1(q) ̸= Ø, then f −1(q) is a 0-dimensional regular sub-
manifold of M. By deﬁnition, we have ϕ(U ∩f −1(q)) = O ∈Rm, i.e., every point
in f −1(q) is an isolated point. Moreover due to the compactness of f −1(q), f −1(q)
must consist of ﬁnite points.
Below, we give some applications of Theorem 1.57.
Example 1.59. Let f : Rn+1 →R, and f(u1, · · · , un+1) =
n+1

i=1
(ui)2.
From the Jacobian matrix of f at (u1, · · · , un+1), we know f is not a submersion
at (u1, · · · , un+1) ⇔u1 = · · · = un+1 = 0. Therefore, any non-zero real number is
a regular value of f. According to the Theorem 1.57, the n-dimensional unit sphere
Sn = f −1(1) is an n-dimensional regular submanifold on Rn+1.
Example 1.60. Let f : R3 →R, and f(u1, u2, u3) = (a −

(u1)2 + (u2)2 )2 +
(u3)2, a > 0.
The assumption tells us that any non-zero real number is a regular point of f. Then,
0 < b2 < a2 is a regular value of f. Therefore, by Theorem 1.57, T 2 = f −1(b2) is a
2-dimensional regular submanifold on R2.
If M ′ is a regular submanifold of M, then dim M −dim M ′ =codim M ′ is called
the M-codimension of M ′ . Denote M ′ = {p ∈M | fi(p) = 0 (i = 1, · · · , k)} and
consider the mapping
F : M −→Rk,
F(p) = (f1(p), · · · , fk(p)).
If fi : M →R is smooth, then F is smooth too, and M ′ = F −1(O).
Proposition 1.61. Suppose M ′ is a subset of M. Then, M ′ is a k-codimensional reg-
ular submanifold of M if and only if for all q ∈M ′, there exists a neighborhood U of
q ∈M and a smooth mapping F : U →Rk, s.t.
1◦
U ∩M ′ = F −1(O).
2◦
F : U →Rk is a submersion.

54
1. Preliminaries of Differentiable Manifolds
Proof. Necessity. By the deﬁnition of the regular submanifold, if M ′ is a k-codimen-
sional regular submanifold of M, then ∀p ∈M ′, there exists a submanifold chart
(U, ϕ) of M that contains p s.t. ϕ(p) = O ∈Rm, and ϕ(U ∩M ′) = {(u1, · · · , um) ∈
ϕ(U) | um−k+1 = · · · = um = 0}. Let us denotes the projection by π : Rm =
Rm−k × Rk →Rk, let F = π ◦ϕ : U →Rk. Then, F is smooth, and F −1(O) =
(π◦ϕ)−1(O) = U ∩M ′, F∗q = π∗ϕ(q) ◦ϕ∗q. Since ϕ∗q is an isomorphism and π∗ϕ(q)
is surjective, F submerses at q.
Sufﬁciency. If ∀q ∈U ∩M ′, F submerses at q, then O ∈Rk is a regular value
of F. By Theorem 1.57, F −1(O) is a k-codimensional regular submanifold of U, i.e.,
M ′ is a k-codimensional regular submanifold of M.
▲
We know that if q ∈N is a regular value of f : M →N, and f −1(q) ̸= Ø, then
f −1(q) is a regular submanifold of M. Assume that Z is a regular submanifold of N.
Then, under what condition would f −1(Z) be a regular submanifold of M? For this
question, we have the following deﬁnition.
Deﬁnition 1.62. Suppose Z is a regular submanifold of N, f : M →N is smooth,
p ∈M. Then, we say f is transversal to Z at p, if f(p) /∈Z or when f(p) ∈Z has
f∗pTpM + Tf(p)Z = Tf(p)N,
denoted by f⊤pZ. If ∀p ∈M, f⊤pZ, then f is transversal to Z, denoted by f⊤Z.
Remark 1.63. If dim M +dim Z < dim N, then f⊤Z ⇔f(M)∩Z = Ø; if q ∈N
is a regular value of f, then ∀p ∈f −1(q), f⊤pZ; if f : M →N is a submersion,
then for any regular submanifold Z of N, f⊤Z.
For transversality, we focus on its geometric property.
Example 1.64. M = R, N = R2, Z is x-axis in R2, f : M →N, f(t) = (t, t2).
When t ̸= 0, as a result of f(t) /∈Z, f⊤tZ;
When t = 0, Jf(0) = (1, 0)′, note that f∗0
 d
d t

0

=(1, 0)
 ∂
∂u1 ,
∂
∂u2
′
=
d
d u1 ,
f∗0T0M = T(0,0)Z. Therefore, f∗0T0M + T(0,0)Z = T(0,0)N is impossible to estab-
lish. Thus, f is not transversal to Z at 0.
However, if we change f to f(t) = (t, t2 −1), we obtain: when t ̸= ±1, f(t) /∈
Z, so f⊤tZ; when t = 1, Jf(1) = (1, 2)′, therefore f∗1
 d
dt

1

=
∂
∂u1

(1,0) +
2 ∂
∂u2

(1,0), i.e., f∗1T1M + T(1,0)Z = T(1,0)N, and hence f⊤1Z. Similarly, we have
f⊤−1Z. Thus, f⊤Z.
Submanifold transverse: Let Z, Z′ be two regular submanifolds of N, i : Z′ →N
is an inclusion mapping. If i⊤Z, then submanifold Z′ is transversal to Z, denoted as
Z′⊤Z. If Z′⊤Z, ∀p ∈Z ∩Z′, by deﬁnition, we have
i∗p(TpZ′) + TpZ = TpN,
i.e.,

1.1 Differentiable Manifolds
55
TpZ′ + TpZ = TpN.
We assume that f : M →N is smooth, and Z is a k-codimensional regular
submanifold of N, p ∈M, f(p) = q ∈Z. According to the Proposition 1.61, there
exists a submanifold chart (V, ψ) of N that contains q, s.t. π ◦ψ : V →Rk is a
submersion, and Z ∩V = (π ◦ψ)−1(O). Now, take a neighborhood of p in M, s.t.,
f(U) ⊂V , then π ◦ψ ◦f : U →Rk.
Proposition 1.65. f⊤pZ ⇔π ◦ψ ◦f : U →Rk submerses at p.
Proof. Since π ◦ψ submerses at f(p), O ∈Rk is a regular value of π ◦ψ. From
Z ∩V = (π◦ψ)−1(O), we know for every q ∈Z ∩V , there exists a (π◦ψ)∗qTqN =
ToRk. By Theorem 1.57, ker(π ◦ψ)∗q = TqZ. Therefore, f∗pTpM +TqZ = TqN ↔
(π◦ψ)∗q(f∗pTpM) = ToRk ↔(π◦ψ◦f)∗p(TpM) = ToRk, i.e., π◦ψ◦f submerses
at p.
▲
Remark 1.66. Extending from the conclusion of Proposition 1.65, we have f⊤Z ↔
O ∈Rk are regular values of π ◦ψ ◦f : U →Rk.
Remark 1.67. Since f⊤pZ, i.e., π ◦ψ ◦f : U →Rk submerses at p. By Proposition
1.52, we can choose a coordinate chart s.t. π ◦ψ ◦f ◦ϕ−1 : ϕ(U) →Rk has the form
(π ◦ψ ◦f ◦ϕ−1)(u1, · · · , um) = (um−k+1, · · · , um).
Then, f = ψ ◦f ◦ϕ−1 can be represented by
f = (η1(u1, · · · , um), · · · , ηn−k(u1, · · · , um), um−k+1, · · · , um).
Theorem 1.68 (Extension of Theorem 1.57). Suppose f : M →N is smooth, Z is
a k-codimensional regular submanifold of N. If f⊤Z and f −1(Z) ̸= Ø, then f −1(Z)
is a k-codimensional regular submanifold of M, and ∀p ∈f −1(Z),
Tp{f −1(Z)} = f −1
∗p {Tf(p)Z}.
Proof. ∀p ∈f −1(Z), there exists q ∈Z, denoted by q = f(p). Since Z is a k-
codimensional regular submanifold of N, there exists a submanifold chart (V, ψ) of
N that contains p. Let U = f −1(V ). From f⊤Z, we know that O ∈Rk is a regular
value of π ◦ψ ◦f, and
U ∩f −1(Z) = (π ◦ψ ◦f)−1(O).
By Theorem 1.57, U ∩f −1(Z) is a k-codimensional regular submanifold of U, and
Tp{f −1(Z)}
= ker(π ◦ψ ◦f)∗p
= f −1
∗p {(π ◦ψ)−1
∗q (O)}
= f −1
∗p {Tf(p)Z}.
The theorem is proved.
▲

56
1. Preliminaries of Differentiable Manifolds
1.2 Tangent Bundle
The tangent bundle of a differentiable manifold M is the disjoint union of the tangent
spaces of M. It is useful, in distinguishing between the tangent space and bundle, to
consider their dimensions, n and 2n respectively. In other words, the tangent bundle
accounts for dimensions in the positions in the manifold as well as directions tangent
to it. Since we can deﬁne a projection map, for each element of the tangent bun-
dle giving the element in the manifold whose tangent space the ﬁrst element lies in,
tangent bundles are also ﬁber bundles.
1.2.1 Tangent Bundle and Orientation
In this section, we will discuss two invariable properties under diffeomorphism–
tangent bundle and orientation.
1.
Tangent Bundle
Deﬁnition 2.1. The Triple (TM, M, π) is called tangent bundle of differentiable man-
ifold M (sometimes simply called TM), where TM =
#
p∈M
TpM, projection map
π : TM →M satisﬁes π(Xp) = p, ∀Xp ∈TM. For every p ∈M, π−1(p) = TpM
is called ﬁber at p of tangent bundle TM.
Proposition 2.2. Let M be an m-dimensional differentiable manifold, then TM is a
2m-dimensional differentiable manifold, and π : TM →M is a submersion.
Proof. Let (U, ϕ) be a chart on M, and its coordinate function be x1, · · · , xm. Then,
∀Xp ∈π−1(U), Xp =

i
ai ∂
∂xi

p. Deﬁne ϕU : π−1(U) →ϕ(U) × Rm, s.t.
ϕU(Xp) = (ϕ(p); a1, · · · , am),
obviously ϕU is a 1 to 1 mapping.
Note that as (U, ϕ) takes all the charts on M, all the corresponding π−1(U) con-
stitutes a covering of TM. Hence, if the topology of π−1(U) is given, the subset of
π−1(U) is open, iff the image of ϕU is an open set of ϕ(U) × Rm. It is easy to prove
that by the 1 to 1 correspondence of ϕU, the topology of ϕU on the Rm×Rm = R2m
subspaces can be lifted on π−1(U). The topology on TM can be deﬁned as follows:
W is called an open subset of TM, iff W ∩π−1(U) is an open subset of π−1(U). It
is easy to deduce that TM constitutes a topological space that satisﬁes the following
conditions:
1◦
TM is a Hausdorff space that has countable bases.
2◦
π−1(U) is an open subset of TM, and ϕU is a homeomorphism from π−1(U)
to an open subset of R2m.
Furthermore, it can be proved that the manifold structure on TM can be naturally
induced from the manifold structure on M. We say that {(π−1(U), ϕU)} = A is a
smooth atlas of TM. For any chart (π−1(U), ϕU), there exists a (π−1(V ), ψV ) ∈

1.2 Tangent Bundle
57
A, and π−1(U) ∩π−1(V ) ̸= Ø. Let x1, · · · , xm and y1, · · · , ym be the coordinate
functions of the charts (U, ϕ), (V, ψ). Then,
ψV ◦ϕ−1
U (u; a1, · · · , am) = ψV
% 
i
ai ∂
∂xi

ϕ−1(u)
&
= ψV
% 
j
% 
i
ai ∂yj
∂xi

ϕ−1(u)
& ∂
∂yj

ψ◦ϕ−1(u)
&
=
%
ψ ◦ϕ−1(u);

i
ai ∂y1
∂xi

ϕ−1(u)
, · · · ,

i
ai ∂ym
∂xi

ϕ−1(u)
&
.
It is easy to conclude that TM is a 2m-dimensional manifold, A is a differentiable
structure on TM. From the charts (U, ϕ) of M and (π−1(U), ϕU) of TM, we know
π = ϕ ◦π ◦ϕ−1
U
: ϕ(U) × Rm →ϕ(U) has the form:
π(u; a1, · · · , am) = u.
By the deﬁnition of submersion, π is a submersion.
▲
Given below are examples of two trivial tangent bundles (if there exists a diffeo-
morphism from its tangent bundle TM to M × Rm, and this diffeomorphism limited
on each ﬁber of TM (TpM) is a linear isomorphism from TpM to {p} × Rm).
Example 2.3. Let U be an open subset of Rm and TU ≃U × Rm.
∀Xu ∈TU, Xu =

i
ai ∂
∂ui

u, where
 ∂
∂ui

u (i = 1, · · · , m)

is the basis of
TuU. Then, it is easy to prove that
Xu −→(u; a1, · · · , am)
is a diffeomorphism from TU to U × Rm. Moreover, since each ﬁber TuU of TU is
a linear space, maps limited on TuU is a linear isomorphism from TuU to {u} × Rm,
i.e., TU is a trivial tangent bundle.
Example 2.4. TS1 is a trivial tangent bundle, i.e., TS1 ≃S1 × R.
Let A={(U, ϕ), (V, ψ)} be a smooth atlas on S1, where
U = {(cos θ, sin θ)|0 < θ < 2π},
ϕ(cos θ, sin θ) = θ,
V = {(cos θ, sin θ)| −π < θ < π},
ψ(cos θ, sin θ) = θ,
ψ ◦ϕ−1(θ) =
'
θ,
0 < θ < π,
θ −2π,
π < θ < 2π.
Deﬁne f : TS1 →S1 × R, s.t.
f(Xp) =
⎧
⎪
⎪
⎨
⎪
⎪
⎩
(p; a),
p ∈U,
Xp = a ∂
∂x

p,
(p; b),
p ∈V,
Xp = b ∂
∂y

p,

58
1. Preliminaries of Differentiable Manifolds
where x, y are the coordinate functions on (U, ϕ), (V, ψ) respectively. When p ∈U ∩
V , we have
∂
∂x

p = ∂y
∂x

p
∂
∂y

p = ∂
∂y

p.
Therefore, f has the deﬁnition and is a 1 to 1 correspondence. Moreover, f and f −1
are smooth. Hence, TS1 is a trivial tangent bundle.
Apart from trivial tangent bundles, there exists a broad class of nontrivial tangent
bundles. For an example, TS2 is a nontrivial tangent bundle.
Deﬁnition 2.5. Let f : M →N be smooth. Deﬁne a mapping Tf : TM →TN, s.t.
Tf|TpM = f∗p,
∀p ∈M,
then Tf is called the tangent mapping of f.
Remark 2.6. ∀Xp ∈TpM, there exist charts (U, ϕ) on M about p and (V, ψ)
on N about f(p), s.t. f(U) ⊂V . By π1 : TM →M, π2 : TN →N, it
is naturally derived that (π−1
1 (U), ϕU), (π−1
2 (V ), ψV ) are charts on TM, TN, and
Tf(π−1
1 (U)) ⊂π−1
2 (V ). Note that
ψV ◦Tf ◦ϕ−1
U (u; a1, · · · , am)
=

ψ ◦f ◦ϕ−1
U ;

i
ai ∂f1
∂xi

ϕ−1(u), · · · ,

i
ai ∂fn
∂xi

ϕ−1(u)

,
which may be simpliﬁed as
ψV ◦Tf ◦ϕ−1
U (u; α) =
 f(u); D ˆf(u)α

,
where α = (a1, · · · , am). Therefore, Tf is a smooth mapping.
Remark 2.7. Let M, N, L be the differentiable manifolds. By the deﬁnition of tan-
gent mapping, if f : M →N and g : N →L are smooth, then
T(g ◦f) = Tg ◦Tf.
Remark 2.8. If f : M →N is a diffeomorphism, then Tf : TM →TN is also a
diffeomorphism.
2.
Orientation
Next, we introduce the concept of orientation for differentiable manifolds.
Given V as a m-dimensional vector space, {e′
1, · · · , e′
m}, {e′′
1, · · · , e′′
m} as V ’s two
ordered bases, if e′′
j =
m

i=1
aije′
i (j = 1, · · · , m), then
(e′′
1, · · · , e′′
m) = (e′
1, · · · , e′
m)A,

1.2 Tangent Bundle
59
where A = (aij)m×m. If det A > 0, we call {e′′
i } and {e′
j} concurrent; otherwise,
if det A < 0, we call {e′′
i } and {e′
j} reverse. Then, a direction μ of V can be ex-
pressed by a concurrent class [{e′
j}] equivalent to {e′
j}. The other direction −μ can
be expressed by an equivalent class to the reverse direction of {e′
j}. (V, μ) is called an
orientable vector space.
Let (V, μ), (W, ν) be two orientable vector spaces. A : V →W is a linear isomor-
phism from V to W. If the orientation of W, which is induced by A, is consistent with
ν, i.e., Aμ = ν, then A preserves orientations. Otherwise, A reverses orientations. In
the below section, we extend the orientation concept to differentiable manifolds.
Deﬁnition 2.9. Let M be an m-dimensional differentiable manifold, ∀p ∈M, μp is
the orientation of TpM, s.t.
ϕ∗q : (TqM, μq) −→(Tϕ(q)Rm, νϕ(q)),
∀q ∈U
are all linear isomorphisms that preserves orientations, where (U, ϕ) is a chart that
contains p, and
νϕ(q) =
 ∂
∂u1

ϕ(q), · · · ,
∂
∂um

ϕ(q)

.
Then, μ = {μp| p ∈M} is the orientation on M, and (M, μ) is called an orientable
differentiable manifold.
Remark 2.10. The Deﬁnition 2.9 shows that if (M, μ) is an orientable differentiable
manifold, W is an open subset of M, then ∀p ∈M and there exists an orientation μp
of TpM. This gives an orientation on W, denoted by μ|W. Then, (W, μ|W) is also an
orientable differentiable manifold. Speciﬁcally, if (U, ϕ) is a chart on M, then (U, μp)
is an orientable differentiable manifold.
Remark 2.10 shows that M may be locally orientable. Next, we discuss how to
construct a global orientation.
Proposition 2.11. Let M be an m-dimensional differentiable manifold, then M is
orientable, iff there exists a smooth atlas, A = {(Uα, ϕα)}, on M, s.t. ∀(Uα, ϕα),
(Uβ, ϕβ) ∈A, if Uα ∩Uβ ̸= Ø, then
det Jϕβ◦ϕ−1
α (ϕα(q)) > 0,
∀q ∈Uα ∩Uβ,
where Jϕβ◦ϕ−1
α (ϕα(q)) is the Jacobian matrix of ϕβ ◦ϕ−1
α
at ϕα(q).
Proof. Necessity. Since M is orientable, select one of the orientations of M, μ =
{μp | p ∈M}. According to Deﬁnition 2.9, ∀p ∈M, there exists a chart (U, ϕ) on
M about p, s.t. ∀q ∈U,
ϕ∗qμq =
 ∂
∂u1

ϕ(q), · · · ,
∂
∂um

ϕ(q)

.
Denote a set consisting of all such charts by A. Then, A is a smooth atlas of M,
and the properties of A described in the proposition are easy to prove.

60
1. Preliminaries of Differentiable Manifolds
Sufﬁciency. Let A be an atlas that satisﬁes all the properties of the proposition.
Choose (Uα, ϕα), (Uβ, ϕβ) ∈A and Uα ∩Uβ ̸= Ø, and use x1, · · · , xm and
y1, · · · , ym to represent the coordinate functions of (Uα, ϕα), (Uβ, ϕβ) respectively.
Note that
 ∂
∂x1

p, · · · ,
∂
∂xm

p

=
 ∂
∂y1

p, · · · ,
∂
∂ym

p

Jϕβ◦ϕ−1
α (ϕα(q)),
and by supposition Jϕβ◦ϕ−1
α (ϕα(q)) > 0, we have
 ∂
∂x1

p, · · · ,
∂
∂xm

p

=
 ∂
∂y1

p, · · · ,
∂
∂ym

p

,
i.e., M is orientable.
▲
Remark 2.12. If f : M →N is a diffeomorphism, fA = {f(Uα), ϕα ◦f −1} is
a smooth atlas. Pick two charts on N, (f(ϕα), ϕα ◦f −1), (f(ϕβ), ϕβ ◦f −1), we
have det Jϕβ◦f −1◦f◦ϕ−1
α (ϕα(q)) = det Jϕβ◦ϕ−1
α (ϕα(q)), ∀q ∈Uα ∩Uβ. If M is
orientable, then N is possible, which means orientation is an invariable property under
diffeomorphism.
Proposition 2.13. Let M be a connected differentiable manifold; if M is orientable,
then M has only two orientations.
Proof. If μ = {μp | p ∈M} is an orientation of M, then −μ is also an orientation.
Therefore, M has at least two orientations. Assume there exists another orientation,
denoted as ν = {νp | p ∈M}. Let S = {p ∈M | μp = νp}. ∀p ∈S, take charts
(U, ϕ), (V, ψ) of M about p, s.t. μ, ν satisfy all the requirements of Deﬁnition 2.9. As
a result of μp = νp, we have
det Jψ◦ϕ−1(ϕ(p)) > 0.
By continuity, there exists a neighborhood of ϕ(p), W ⊂ϕ(U ∩V ), s.t.
det Jψ◦ϕ−1(ϕ(u)) > 0,
∀u ∈W.
Denote O = ϕ−1(W). Then, O is a neighborhood of p in M, and O ⊂S, i.e., S is an
open subset of M. Similarly, M\S is also an open subset of M. Since M is connected,
we have either S = Ø or S = M. If S = Ø, then μ = −ν; if S = M, then μ = ν. ▲
Remark 2.14. By the Proposition 2.13, any connected open set on an orientable dif-
ferentiable manifold M has two and only two orientations.
Remark 2.15. Let (U, ϕ), (V, ψ) be two charts on M, and U and V be connected. If
U ∩V ̸= Ø, then det Jψ◦ϕ−1 preserves the orientation on ϕ(U ∩V ).
Example 2.16. S1 is an orientable differential manifold. Let the smooth atlas of S1
be A = {(U+, ϕ+), (U−, ϕ−)}, where

1.2 Tangent Bundle
61
U+ = S1\{(0, −1)},
U−= S1\{(0, 1)},
ϕ± : U± →R, s.t.
ϕ+(u1, u2) =
u1
1 + u2 ,
ϕ−(u1, u2) =
−u1
u2 −1.
Since
ϕ+ ◦ϕ−1
−(u) = −1
u,
∀u ∈ϕ−(U+ ∩U−),
we have
det Jϕ+◦ϕ−1
−(u) = 1
u2 > 0,
∀u ∈ϕ−(U+ ∩U−).
Similarly
det Jϕ−◦ϕ−1
+ (u) > 0,
∀u ∈ϕ+(U+ ∩U−),
i.e., S1 is orientable.
Example 2.17. M¨obius strip is a non-orientable surface. Deﬁne equivalent relation“∼”
on [0, 1] × (0, 1):
(u, v) ∼(u, v),
0 < u < 1,
0 < v < 1,
(0, v) ∼(1, 1 −v),
0 < v < 1,
[0, 1] × (0, 1)\ ∼is a M¨obius strip, A = {(U, ϕ), (V, ψ)} is its smooth atlas
U = M\{0} × (0, 1),
V = M\
1
2

× (0, 1),
ϕ : U −→(0, 1) × (0, 1),
ψ : V −→

−1
2, 1
2

× (0, 1),
which satisﬁes:
ϕ(u, v) = (u, v),
ψ(u, v) =
⎧
⎪
⎨
⎪
⎩
(u, v),
0 ≤1
2,
(u −1, 1 −v),
1
2 < u ≤1,
ψ ◦ϕ−1(u, v) =
⎧
⎪
⎨
⎪
⎩
(u, v),
(u, v) ∈

0, 1
2

× (0, 1),
(u −1, 1 −v),
(u, v) ∈
1
2, 1

× (0, 1),
i.e.,
det Jψ◦ϕ−1(u, v) =
⎧
⎪
⎨
⎪
⎩
1,
(u, v) ∈

0, 1
2

× (0, 1),
−1,
(u, v) ∈
1
2, 1

× (0, 1).
By the Remark 2.15, M¨obius strip is a nonorientable surface.

62
1. Preliminaries of Differentiable Manifolds
Deﬁnition 2.18. Let M, N be two orientable differential manifolds, and f : M →N
be a local diffeomorphism ( diffeomorphism in the neighborhood of any p ∈M ). If
for every p ∈M, there exists a f∗p : TpM →Tf(p)N that preserves (or reverses) the
orientation, then f is said to preserve the orientation (or reverse the orientation).
Proposition 2.19. f : M →N is a diffeomorphism; if M is a connection, then f
preserves the orientation or reverses the orientation.
Proof. Let S = {p ∈M | f∗p : TpM →Tf(p)N preserves the orientation}. ∀p ∈S,
because f∗p preserves orientation, det Jf(p) > 0. From the continuity, there exists U,
s.t. det Jf(q) > 0, ∀q ∈U, i.e., U ⊂S. Similarly, M\S is also an open subset of M.
Since M is connected, S = Ø or S = M. When S = Ø, then f preserves the inverse
orientation, otherwise (S = M) f preserves the orientation.
▲
1.2.2 Vector Field and Flow
Similar to Euclidean space, differentiable manifold also has the concept of vector ﬁeld
and curve of solution.
Deﬁnition 2.20. Let M be a differentiable manifold. If map X : M →TM has the
property π ◦X = I : M →M, then X is said to be a vector ﬁeld of M, and is also
called a section in the tangent bundle TM, where π : TM →M is a projection. If
the map X is smooth, then X is called a smooth vector ﬁeld.
Proposition 2.21. X is a smooth vector ﬁeld on M, iff for every f ∈C∞(M) there
exists a Xf ∈C∞(M), and C∞(M) = {all smooth functions on M}, Xf :
M →R, Xf(p) = Xp(f), ∀p ∈M, f ∈C∞(M).
Proof. Necessity. Suppose (U, ϕ) is a chart of M, and (π−1(U), ϕU) is an induced
natural chart of TM. Suppose X can be expressed as
Xp =

i
ai(p) ∂
∂xi

p,
∀p ∈U,
by

X = ϕU ◦X ◦ϕ−1 : ϕ(U) −→ϕ(U) × Rm,

X(u) = (u; a1 ◦ϕ−1(u), · · · , am ◦ϕ−1(u)),
we know, if X is smooth, then a1, · · · , am are smooth too. Since
(Xf)(p) = Xpf =

i
ai(p) ∂f
∂xi

p,
∀p ∈U,
(Xf)|U is smooth.
Sufﬁciency. ∀p ∈M, let (U, ϕ) be a chart on M about p, where its coordinate
function x1, · · · , xm may be expanded to smooth "xi on the entire M, and satisfy "xi =
xi on some neighborhood of p on V ⊂U. Then,

1.2 Tangent Bundle
63
Xq =

i
Xq("xi) ∂
∂xi

q,
∀q ∈U,
by the supposition Xq("xi) is smooth, i.e., X is also smooth.
▲
Deﬁnition 2.22. Let X be a smooth vector ﬁeld on the differentiable manifold M.
The solution curve of X through p refers to a smooth mapping c : J →M s.t.
c(0) = p, and
c∗t
 d
dt

t

= Xc(t),
∀t ∈J,
i.e., the velocity vector at t of a smooth curve c is exactly the value of the vector ﬁeld
at p on M.
Proposition 2.23. Let f : M →N be a diffeomorphism, X be a smooth vector ﬁeld
on M. If we denote f∗X = Tf ◦X ◦f −1 : N →TN, then f∗X is a smooth vector
ﬁeld on N, and c is a solution curve of X through p ∈M, iff f ◦c is a solution curve
of f∗X through f(p).
Proof. By the deﬁnition of tangent mapping, we have
π2 ◦(f∗X)
= π2 ◦(Tf ◦X ◦f −1)
= f ◦(π1 ◦X) ◦f −1 = I.
Since f −1, X, Tf are smooth, f∗X is a smooth vector ﬁeld on N.
If c : J →M is a solution curve of X through p, then f ◦c(0) = f(0) = f(p),
and
(f ◦c)∗t
 d
d t

t

= f∗c(t) ◦c∗t
 d
d t

t

= f∗c(t)(Xc(t)) = (f∗X)f◦c(t),
∀t ∈J.
Therefore the proposition is completed.
▲
Remark 2.24. Let X be a smooth vector ﬁeld on the differentiable manifold M, and
(U, ϕ) be a chart on M. By Proposition 2.23, we have ϕ∗(X | U) to be a smooth
vector ﬁeld of ϕ(U).
Remark 2.25. If ϕ∗(X | U) has an expression
{ϕ∗(X | U)}u =
m

i=1
ai(u) ∂
∂ui

u,
∀u ∈ϕ(U),
then
(ϕ ◦c)∗t
 ∂
∂t

t

=
m

i=1
∂(ϕ ◦c)i
∂t

t
∂
∂ui

ϕ◦c(t),
∀t ∈J,
where (ϕ ◦c)i is the i-th component of ϕ ◦c.
Therefore, according to Proposition 2.23, there exists a solution curve, c : J →U,
of X through p, iff ϕ ◦c is a solution of

64
1. Preliminaries of Differentiable Manifolds
⎧
⎨
⎩
d ui
d t = ai(u1, · · · , um),
i = 1, · · · , m,
u(0) = ϕ(p).
Strictly speaking, a vector ﬁeld on Rn is a mapping A : Rn →T(Rn),i.e.,
∀x ∈Rn,
A(x) ∈TxRn.
Since (e1)x, · · · , (en)x form a basis on TxRn, we can write
 ∂
∂x1 , · · · ,
∂
∂xn

, there-
fore
A(x) =
n

i=1
Ai(x)(ei)x.
If Ai(x) ∈C∞, then A(x) is called a smooth vector ﬁeld on Rn. The set of all smooth
vector ﬁelds on Rn is denoted by X(Rn). For any vector A(x), B(x) ∈X(Rn),
deﬁne:
(αA + βB)(x) = αA(x) + βB(x),
α, β ∈R,
(fA)(x) = f(x)A(x),
f(x) ∈C∞(Rn).
Then, X(Rn) is a C∞module of C∞-vector on Rn.
If we denote A(x) ∈X(Rn) by (A1(x), · · · , An(x))′, i.e.,
A(x) =
n

i=1
Ai(x)(ei)x = (A1(x), · · · , An(x))′,
then A(x) is a C∞n-value function.
1.3 Exterior Product
Exterior product is one of the algebraic operations. It has quite an interesting geomet-
ric background. In this section, we would like to construct a new linear space from
an original linear space so that the new space has not only the linear space algebraic
structure, but also a new algebraic operation — exterior product. This forms a basis
for the differential form introduced later. These materials can be found in a series of
books[AM78,Che53,Arn89,Ede85,Fla].
In R3, let the vectors be
a1 = a11i + a12j + a13k,
a2 = a21i + a22j + a23k,
a3 = a31i + a32j + a33k,
where a1, a2, a3 are linearly independent. Then,

1.3 Exterior Product
65
V =
(
x ∈R3 | x = α1a1 + α2a2 + α3a3, 0 ≤α1, α2, α3 ≤1
)
a spanned parallelepiped by vectors a1, a2, a3. We introduce a new operation, ∧be-
tween a1, a2, a3 as follows:
a1 ∧a2 ∧a3 =

a11
a12
a13
a21
a22
a23
a31
a32
a33

.
The geometric meaning of a1∧a2∧a3 is the orientable volume of V , where orientation
means the sign of the volume is positive or negative. If the right hand law is followed,
the volume has the plus sign, otherwise it has the minus sign . It is easy to see that
operation ∧satisﬁes the following laws:
1◦
Multilinear. Let a2 = βb + γc, b, c be vectors, β, γ be real numbers. Then,
a1 ∧(βb + γc) ∧a3 = β(a1 ∧b ∧a3) + γ(a1 ∧c ∧a3).
2◦
Anti-commute
a1 ∧a2 ∧a3 = −a2 ∧a1 ∧a3,
a1 ∧a2 ∧a3 = −a3 ∧a2 ∧a1,
a1 ∧a2 ∧a3 = −a1 ∧a3 ∧a2.
From 2◦we know that if a1, a2, a3 has two identical vectors, then a1∧a2∧a3 = 0.
Example 3.1. Let e1, e2, e3 be a basis in R3, which are not necessarily orthogonal,
and let a1, a2, a3 be three vectors in R3, which can be represented by
a1 = a11e1 + a12e2 + a13e3,
a2 = a21e1 + a22e2 + a23e3,
a3 = a31e1 + a32e2 + a33e3.
By multilinearity and anti-commutativity of ∧, after the computation, we have
a1 ∧a2 ∧a3 =

a11
a12
a13
a21
a22
a23
a31
a32
a33

e1 ∧e2 ∧e3.
Example 3.2. Let e1, e2, e3 be a basis in R3, and
a1 = a11e1 + a12e2 + a13e3,
a2 = a21e1 + a22e2 + a23e3.
Then,
a1 ∧a2 =

a11
a12
a21
a22
 e1 ∧e2 +

a12
a13
a22
a23
 e2 ∧e3 +

a13
a11
a23
a21
 e3 ∧e1.
The geometric signiﬁcance of this formula is that the projection of the par-
allelepiped spanned by the pair of vectors a1 and a2 onto the coordinate plane
e1e2, e2e3, e3e1 is equal to A12, A23, and A31 respectively. Abstracting from the mul-
tilinearity and the anti-commutativity, which is satisﬁed by the operation wedge, we
can obtain the concept of exterior product.

66
1. Preliminaries of Differentiable Manifolds
1.3.1 Exterior Form
1.
1- Form
In this section, Rn is an n-dimensional real vector space, where the vectors are de-
noted by ξ, η, · · · ∈Rn.
Deﬁnition 3.3. A form of degree 1 (or a 1-form) on Rn is a linear function ω : Rn →
R, i.e.,
ω(λ1ξ1 + λ2ξ2) = λ1ω(ξ1) + λ2ω(ξ2),
λ1, λ2 ∈R,
ξ1, ξ2 ∈Rn.
The set of all 1-forms on Rn is denoted by Λ1(Rn). For ω1, ω2 ∈Λ1(Rn), deﬁne
(λ1ω1 + λ2ω2)(ξ) = λ1ω1(ξ) + λ2ω2(ξ),
λ1, λ2 ∈R.
Then, Λ1Rn becomes a vector space, i.e., the dual space (Rn)∗of Rn.
Let
e1 =
⎡
⎢⎢⎢⎣
1
0
...
0
⎤
⎥⎥⎥⎦,
e2 =
⎡
⎢⎢⎢⎣
0
1
...
0
⎤
⎥⎥⎥⎦,
· · · ,
en =
⎡
⎢⎢⎢⎣
0
0
...
1
⎤
⎥⎥⎥⎦
be the standard basis on Rn. x1, x2, · · · , xn forms the coordinate system on Rn, i.e.,
if ξ = a1e1 +a2e2 +· · ·+anen, then xi(ξ) = ai, especially xi(ej) = δij. Obviously,
xi ∈Λ1(Rn). For any ω ∈Λ1(Rn),
ω(ξ) = ω

n

i=1
aiei

=
n

i=1
aiω(ei) =
i=1

n
ω(ei)xi(ξ),
and so
ω = ω(e1)x1 + ω(e2)x2 + · · · + ω(en)xn.
Thus, x1, · · · , xn is a basis on Λ1(Rn), Λ1(Rn) = {xi}i=1,···,n.
Example 3.4. If F is a uniform force ﬁeld on a Euclidean space R3, then its work A
on a displacement ξ is a 1-form acting on ξ,
ωF (ξ) = (F, ξ) = F1a1 + F2a2 + F3a3,
ξ = a1e1 + a2e2 + a3e3
or
ωF = F1x1 + F2x2 + F3x3.
2.
2-Forms
Deﬁnition 3.5. An exterior form of degree 2 (or a 2-form) is a bilinear, skew-
symmetric function ω2: Rn × Rn →R, i.e.,
ω2(λ1ξ1 + λ2ξ2, ξ3) = λ1ω2(ξ1, ξ3) + λ2ω2(ξ2, ξ3),
ω2(ξ1, ξ2) = −ω2(ξ2, ξ1),
ξ1, ξ2, ξ3 ∈Rn,
λ1, λ2 ∈R.

1.3 Exterior Product
67
The set of all 2-forms on Rn is denoted by Λ2(Rn) = Λ2.
Similarly, if we deﬁne the sum of two 2-forms ω2
1, ω2
2 and scalar multiplication as
follows
(λ1ω2
1 + λ2ω2
2)(ξ1, ξ2) = λ1ω2
1(ξ1, ξ2) + λ2ω2
2(ξ1, ξ2),
ω2
1, ω2
2 ∈Λ2(Rn),
λ1, λ2 ∈R,
then Λ2(Rn) becomes a vector space on R.
Property 3.6. The skew-symmetric condition ω2(ξ1, ξ2)−ω2(ξ2, ξ1) is equivalent to
ω2(ξ, ξ) = 0, ∀ξ ∈Rn since from the latter it follows that
0
= ω2(ξ1 + ξ2, ξ1 + ξ2)
= −ω2(ξ1, ξ1) + ω2(ξ1, ξ2) + ω2(ξ2, ξ1) + ω2(ξ2, ξ2)
= ω2(ξ1, ξ2) + ω2(ξ2, ξ1).
i.e., ω2(ξ1, ξ2) = ω2(ξ2, ξ1).
Example 3.7. Let S(ξ1, ξ2) be the oriented area of the parallelogram constructed on
the vector ξ1 and ξ2 of the oriented Euclidean plane R2, i.e.,
S(ξ1, ξ2) =

ξ11
ξ12
ξ21
ξ22
 ,
where
ξ1 = ξ11e1 + ξ12e2,
ξ2 = ξ21e1 + ξ22e2.
Example 3.8. Let v be a given vector on the oriented Euclidean space R3. The triple
scalar product on other two vectors ξ1 and ξ2 is a 2-form:
ω(ξ1, ξ2) = (v, [ξ1, ξ2]) =

v1
v2
v3
ξ11
ξ12
ξ13
ξ21
ξ22
ξ23

,
where v =
3

i=1
viej
i, ξj =
3

i=1
ξjiei (j = 1, 2).
3.
k-Forms
We denote the set of all permutations of the set {1, 2, · · · , k} by Sk and its element by
σ = {σ(1), σ(2), · · · , σ(k)} = {i1, i2, · · · , ik} ∈νk,
ε(σ) =
 1,
if σ ∈νk is even,
−1,
if σ ∈νk is odd.

68
1. Preliminaries of Differentiable Manifolds
Deﬁnition 3.9. An exterior form of degree k (or a k-form) is a function of k vectors
that is k-linear and skew-symmetric:
ω(λ1ξ′
1 + λ2ξ′′
1 , ξ2, · · · , ξk) = λ1ω(ξ′
1, ξ2, · · · , ξk) + λ2ω(ξ′′
1 , ξ2, · · · , ξk),
ω(ξi1, ξi2, · · · , ξik) = ε(σ)ω(ξ1, ξ2, · · · , ξk),
ξ′
1, ξ′′
1 , ξ2, · · · , ξk ∈Rn,
λ1, λ2 ∈R,
σ ∈νk,
where σ = (i1, i2, · · · , ik) ∈Sk.
Example 3.10. The oriented volume of the parallelepiped with edges ξ1, ξ2, · · · , ξn
in the oriented Euclidean space Rn is an n-form.
V (ξ1, ξ2, · · · , ξn) =

ξ11
· · ·
ξ1n
ξ21
· · ·
ξ2n
...
...
ξn1
· · ·
ξnn

,
where ξi = ξi1e1 + · · · + ξinen.
The set of all k-forms in Rn is denoted by Λk(Rn). It forms a real vector space if
we introduce operations of addition.
(λ1ωk
1 + λ2ωk
2)(ξ1, ξ2, · · · , ξk) = λ1ωk
1(ξ1, ξ2, · · · , ξk) + λ2ωk
2(ξ1, ξ2, · · · , ξk),
ωk
1, ωk
2 ∈Λk(Rn),
λ1, λ2 ∈R.
it
Question 3.11. Show that if ηj =
k

i=1
ajiξi (j = 1, · · · , k), then
ωk(η1, η2, · · · , ηk) = det (aji)ωk(ξ1, ξ2, · · · , ξk).
1.3.2 Exterior Algebra
1. The exterior product of two 1-forms
In the previous section, we have deﬁned various exterior forms. We now introduce one
more operation: exterior multiplication of forms. As a matter of fact, these forms can
be generated from the 1-forms by an operation called exterior product.
Deﬁnition 3.12. For ω1 and ω2 ∈Λ1(Rn), the exterior product of ω1 and ω2 denoted
by ω1 ∧ω2 is deﬁned by the formula
(ω1 ∧ω2)(ξ1, ξ2) =

ω1(ξ1)
ω2(ξ1)
ω1(ξ2)
ω2(ξ2)
 ,
ξ1, ξ2 ∈Rn,

1.3 Exterior Product
69
which denotes the oriented area of the image of the parallelogram with sides ω(ξ1)
and ω(ξ2) on the ω1, ω2 plane.
It is not hard to verify that ω1 ∧ω2 really is a 2-form and has properties
ω1 ∧ω2 = −ω2 ∧ω1,
(λ1ω′
1 + λ2ω′′
1) ∧ω2 = λ1ω′
1 ∧ω2 + λ2ω′′
1 ∧ω2.
Now suppose we have chosen a system of linear coordinates on Rn, i.e., we are given
n independent 1-forms, x1, x2, · · · , xn. We will call these forms basic. The exterior
products of the basic forms are the 2-forms xi ∧xj. By skew-symmetry,
xi ∈Λ1(Rn),
xi ∧xi = 0,
xi ∧xj = −xj ∧xi,
(xi ∧xj)(ξ1, ξ2) =

xi(ξ1)
xj(ξ1)
xi(ξ2)
xj(ξ2)

=

ai
aj
bi
bj
 = aibj −ajbi,
where ξ1 =

i
aiei, ξ2 =

i
biei. It is the oriented area of the parallelogram with
sides (xi(ξ1), xi(ξ2)) and (xj(ξ1), xj(ξ2)) in the (xi, xj)-plane.
For any ω ∈Λ2(Rn),
ω(ξ1, ξ2) =
n

i,j=1
ω(aiei, bjej) =
n

i,j=1
aibjω(ei, ej)
=

i<j
(aibj −ajbi)ω(ei, ej) =

i<j
ω(ei, ej)(xi ∧xj)(ξ1, ξ2),
where ξ1 =

i
aiei, ξ2 =

i
biei. Thus,
ω =

i<j
ω(ei, ej)xi ∧xj,
i.e., {xi ∧xj}i<j generate Λ2(Rn). In addition, if

i<j
aijxi ∧xj = 0,
acting on el, ek(l < k), we get
akl =

i<j
aij(xi ∧xj)(el, ek) = 0.
Thus, {xi∧xj}i<j are linearly independent and they form a base of Λ2(Rn), which
implies that the dimension of Λ2(Rn) is
 n
2

.

70
1. Preliminaries of Differentiable Manifolds
In the oriented Euclidean space R3, the base of Λ2(R3) is x1 ∧x2, x2 ∧x3, and
x3 ∧x1 = −x1 ∧x3. Any 2-form ω ∈Λ2(R3) can be represented as
ω = Px2 ∧x3 + Qx3 ∧x1 + Rx1 ∧x2.
2.
Exterior monomials
Deﬁnition 3.13. For ω1, · · · , ωk ∈Λ1(Rn), we deﬁne their exterior product ω1 ∧
· · · ∧ωk as follows:
(ω1 ∧· · · ∧ωk)(ξ1, · · · , ξk) =

ω1(ξ1)
· · ·
ω1(ξk)
...
...
ωk(ξ1)
· · ·
ωk(ξk)

.
In other words, the value of a product of 1-forms on the parallelepiped ξ1, · · · , ξk
is equal to the oriented volume of the image of the parallelepiped in the oriented
Euclidean coordinate space Rn under the mapping ξ →(ω1(ξ), · · · , ωk(ξ)).
Question 3.14. Prove that ω1 ∧· · · ∧ωk really is a k-form.
Property 3.15. We have the following properties:
1◦
(λ′ω′
1 + λ′′ω′′
1) ∧ω2 ∧· · · ∧ωk = λ′ω′
1 ∧· · · ∧ωk + λ′′ω′′
1 ∧· · · ∧ωk.
2◦
ωσ(1) ∧ωσ(2) ∧· · · ∧ωσ(k) = ε(σ)ω1 ∧ω2 ∧· · · ∧ωk.
3◦
If i ̸= j, ωi = ωj, then ω1 ∧· · · ∧ωk = 0.
4◦
If ω1, · · · , ωk are linearly dependent, then ω1 ∧· · · ∧ωk = 0.
5◦
If βi =
k

j=1
aijωj (i = 1, · · · , k), then
β1 ∧· · · ∧βk = det (aij)ω1 ∧· · · ∧ωk.
Proof. Here we only prove 5◦, the others are easy. By the linearity of the exterior
product,
β1 ∧· · · ∧βk
=
*
k

i1=1
a1i1ωi1
+
∧· · · ∧
*
k

ik=1
akikωik
+
=
k

i1,···,ik=1
a1i1 · · · akikωi1 ∧· · · ∧ωik
=

i1,···,ik∈νk
a1i1 · · · akikε(i1, · · · , ik)ω1 ∧· · · ∧ωk
(by 2◦)
= det (aij)ω1 ∧· · · ∧ωk.
The proof can be obtained.
▲

1.3 Exterior Product
71
Theorem 3.16. {xi1 ∧· · · ∧xik}i1<···<ik form a basis on Λk(Rn),and so the dimen-
sion of Λk(Rn) =
 n
k

.
Proof. For ξi =
n

j=1
ξijej (i = 1, · · · , k), ξi ∈Rn, then
ω(ξ1, · · · , ξk)
= ω

n

j1=1
ξi,j1ej1, · · · ,
n

jk=1
ξkjkejk

=
n

j1,···,jk=1
ξij1 · · · ξkjkω(ej1, · · · , ejk)
=

i1<···<ik

(j′
1,···,j′
k)∈νk(i1,···,ik)
ε(j′
1, · · · , j′
k)
· ξ1j′
1 · · · ξkj′
kω(ξi1, · · · , ξik)
=

i1<···<ik
ω(ei1, · · · , eik)xi1 ∧· · · ∧xik(ξ1, · · · , ξk).
So
ω =

i1<···<ik
ω(ei1, · · · , eik)xi1 ∧· · · ∧xik.
Thus, {xi1 ∧· · · ∧xik}i1<···<ik generate Λk(Rn). Obviously, they are linearly inde-
pendent. Consequently, they form a basis on Λk(Rn).
In particular,
dim Λk(Rn) =
 n
k

.
If k = n, then dim Λn(Rn) =
 n
n

= 1, ∀ω ∈Λn(Rn), and there must be
ω = ax1 ∧· · · ∧xk, for some number a ∈R.
For k > n,
dim (Λk(Rn)) = 0,
Λk(Rn) = {0}.
Therefore, the theorem is completed.
▲
Deﬁnition 3.17. Let ωk = ω1∧· · ·∧ωk, ωl = ωk+1∧· · ·∧ωk+l, ωi ∈Λ1(Rn) (i =
1, · · · , k + l). Deﬁne their product ωk ∧ωl to be the monomial
ωk ∧ωl
=
(ω1 ∧· · · ∧ωk) ∧(ωk+1 ∧· · · ∧ωk+l)
=
ω1 ∧· · · ∧ωk ∧ωk+1 ∧· · · ∧ωk+l.
Property 3.18. If ω1, ω2, and ω3 are monomials, then
1◦
(λ1ω1 + λ2ω2) ∧ω3 = λ1ω1 ∧ω3 + λ2ω2 ∧ω3.

72
1. Preliminaries of Differentiable Manifolds
2◦
ω1 ∧ω2 = (−1)klω2 ∧ω1, ω1 ∈Λk, ω2 ∈Λl.
3◦
(ωk
1 ∧ωl
2) ∧ωm
3 = ωk
1 ∧(ωl
2 ∧ωm
3 ), ω1 ∈Λk, ω2 ∈Λl, ω3 ∈Λm.
3.
Exterior product of forms
We now turn to deﬁne the exterior product of an arbitrary k-form ωk with an arbitrary
l-form ωl.
Deﬁnition 3.19. The exterior product ωk ∧ωl of a k-form ωk on Rn with an l-form
ωl on Rn is the (k + l)-form on Rn, deﬁned by the formula
(ωk ∧ωl)(ξ1, · · · , ξk+l) =

i1<···<ik; j1<···<jl
ε(σ)ωk(ξi1, · · · , ξik)ωl(ξj1, · · · , ξjl),
(3.1)
where σ = (i1, i2, · · · , ik, j1, · · · , jl) is a permutation of the numbers (1, · · · , k + l).
Example 3.20. For k = l = 1,
(ω1 ∧ω2)(ξ1, ξ2) = ω1(ξ1)ω2(ξ2) −ω1(ξ2)ω2(ξ1)
=

ω1(ξ1)
ω2(ξ1)
ω1(ξ2)
ω2(ξ2)
 ,
which agrees with the deﬁnition of multiplication of 1-forms.
Example 3.21. For ω1 ∈Λ2 and ω2 ∈Λ1,
(ω1 ∧ω2)(ξ1, ξ2, ξ3) = ω1(ξ1, ξ2)ω2(ξ3) −ω1(ξ1, ξ3)ω2(ξ2)
+ ω1(ξ2, ξ3)ω2(ξ1).
Proposition 3.22. ωk ∧ωl deﬁned above is actually a (k + l)-form.
The linearity of ωk∧ωl is based on the linearity of ωk and ωl. The skew-symmetry
is based on the following.
Lemma 3.23. If ω is a k-linear function on R, then the following conditions are
equivalent.
1◦
ω(ξσ(1), · · · , ξσ(k)) = ε(σ)ω(ξ1, · · · , ξk), ∀σ ∈νk.
2◦
ω(ξ1, · · · , ξi, · · · , ξj, · · · , ξk) = −ω(ξ1, · · · , ξj, · · · , ξi, · · · , ξk), ∀i ̸= j.
3◦
ω(ξ1, · · · , ξk) = 0, if ξi = ξj, ∀i ̸= j.
4◦
ω(ξ1, · · · , ξk) = 0, where ξi = ξi+1 (1 ≤i ≤n −1).
5◦
ω(ξ1, · · · , ξk) = 0, ξ1, · · · , ξk are linearly dependent.
The proof is left to the reader. Now we turn to prove Proposition 3.22. For this we
only need to prove 4◦of Lemma 3.23.

1.3 Exterior Product
73
Proof. By 4◦in Lemma 3.23, we only need to prove that if ξi′ = ξi′+1, then (ωk ∧
ωl)(ξ1, · · ·, ξi′, ξi′+1, · · · , ξk+l) = 0.
Consider the terms of the right hand side in (1.2). If i′, i′ + 1 ∈(i1, · · · , ik), then
ωk(ξi1, · · · , ξik) = 0. Therefore,
ωk(ξi1, · · · , ξik)ωl(ξj+1, · · · , ξj+l) = 0.
When i′, i′ + 1 ∈(j1, · · · , jl), the case is similar. If i′ ∈(i1, · · · , ik) and i′ + 1 ∈
(j1, · · · , jl), i.e., i1 < · · · < ih < i′ < ih+1 < · · · < ik and j1 < · · · < jn < i′ +1 <
jn+1 < · · · < jl, then there is another term such that
i1 < · · · < ih < i′ + 1 < ih+1 < · · · < ik,
j1 < · · · < jn < i′ < jn+1 < · · · < jl.
The condition ξi′+1 = ξi′ implies that
ωk(ξ1, · · · , ξi′, · · · , ξik)ωl(ξj1, · · · , ξi′+1, · · · , ξjl)
= ωk(ξ1, · · · , ξi′+1, · · · , ξik)ωl(ξj1, · · · , ξi′, · · · , ξjl).
However, the sign ε(σ) = −ε(σ′) where
σ = (i1, · · · , i′, · · · , ik, j1, · · · , i′ + 1, · · · , jl),
σ′ = (i1, · · · , i′ + 1, · · · , ik, j1, · · · , i′, · · · , jl).
Thus, the right side in 1◦is equal to 0, i.e.,
(ωk ∧ωl)(ξ1, · · · , ξk+l) = 0.
Hence lemma is proved.
▲
Theorem 3.24. The exterior product of forms deﬁned above is skew-commutative, dis-
tributive, and associative, i.e.,
1◦
skew-commutative: ωk ∧ωl = (−1)klωl ∧ωk.
2◦
distributive : (λ1ωk
1 + λ2ωk
2) ∧ωl = λ1ωk
1 ∧ωl + λ2ωk
2 ∧ωl.
3◦
associative : (ωk ∧ωl) ∧ωm = ωk ∧(ωl ∧ωm).
For monomials, it coincides with the exterior product deﬁned above.
Distributivity follows from the fact that every term in Equation (1.2) is linear with
respect to ωk and ωl.
Since
(ωk ∧ωl)(ξ1, · · · , ξk+l)
=

i1<···<ik; j1<···<jl
ε(i1, · · · , ik, j1, · · · , jl)ωk(ξi1, · · · , ξik)ωl(ξj1, · · · , ξjl)
=

i1<···<ik; j1<···<jl
(−1)klε(j1, · · · , jl, i1, · · · , ik) ωl(ξj1, · · · , ξjl)ωk(ξi1, · · · , ξik)
= (−1)kl(ωl ∧ωk)(ξ1, · · · , ξk+l),

74
1. Preliminaries of Differentiable Manifolds
we get skew-commutativity.
In order to prove associativity, we ﬁrst prove that for monomials the exterior prod-
uct deﬁned by Deﬁnition 3.19 coincides with the exterior product in Deﬁnition 3.17.
Since we have not get proved the equivalence of the Deﬁnition 3.17 of exterior product
of k 1-forms with the Deﬁnition 3.19 , we will temporarily denote the exterior product
of k 1-forms by the symbol ∧, so that our monomials have the form
ωk = ω1∧· · · ∧ωk
and
ωl = ωk+1∧· · · ∧ωk+l.
where ω1, · · · , ωk+l are 1-forms.
Lemma 3.25. The exterior product of two monomials is a monomial.
(ω1∧· · · ∧ωk) ∧(ωk+1∧· · · ∧ωk+l) = ω1∧· · · ∧ωk∧ωk+1∧· · · ∧ωk+l.
Proof.
((ω1∧· · · ∧ωk) ∧(ωk+1∧· · · ∧ωk+l))(ξ1, · · · , ξk+l)
=

i1<···<ik; j1<···<jl
ε(i1, · · · , ik, j1, · · · , jl)(ω1∧· · · ∧ωk)(ξi1, · · · , ξik)
·(ωk+1∧· · · ∧ωk+l) (ξj1, · · · , ξjl)
=

i1<···<ik; j1<···<jl
ε(i1, · · · , ik, j1, · · · , jl)
det
1≤i≤k; 1≤m≤k ωi(ξim)
·
det
k+1≤j≤k+l; 1≤m≤k ωj(ξjm)
=
det
1≤i≤k+l; 1≤j≤k+l ωi(ξj) = ω1∧· · · ∧ωk+l(ξ1, · · · , ξk+l).
Therefore, the lemma is completed.
▲
Thus,
ω1∧ω2 = ω1 ∧ω2,
ω1∧ω2∧ω3 = (ω1∧ω2) ∧ω3 = (ω1 ∧ω2) ∧ω3,
ω1∧ω2∧ω3 = ω1 ∧

ω2∧ω3

= ω1 ∧(ω2 ∧ω3).
It follows that
(ω1 ∧ω2) ∧ω3 = ω1 ∧(ω2 ∧ω3),
and denoted by ω1 ∧ω2 ∧ω3. Thus, ω1∧ω2∧ω3 = ω1 ∧ω2 ∧ω3.
In general, we have
ω1∧ω2∧· · · ∧ωk = (· · · ((ω1 ∧ω2) ∧ω3) ∧· · · ∧ωk).
We now prove associativity. By Theorem 3.16, ωk ∈Λk, ωl ∈Λl and ωm ∈Λm
can be represented by the following formulae resp.

1.4 Foundation of Differential Form
75
ωk =

ai1···ikxi1 ∧· · · ∧xik,
ωl =

bj1···jlxj1 ∧· · · ∧xjl,
ωm =

ch1···hmxh1 ∧· · · ∧xhm.
By distributivity and associativity for monomials,
(ωk ∧ωl) ∧ωm
=

k,l,m
abc ((xi1 ∧· · · ∧xik) ∧(xj1 ∧· · · ∧xjl)) ∧(xh1 ∧· · · ∧xhm)
=

k,l,m
abc (xi1 ∧· · · ∧xik) ∧((xj1 ∧· · · ∧xjl) ∧(xh1 ∧· · · ∧xhm))
= ωk ∧(ωl ∧ωm).
Based on linear space Λk (k = 0, 1, 2, · · · , n), we may construct a bigger linear space
Λ, which is a direct sum of Λ1, Λ1, · · · , Λn, i.e.,
Λ = Λ0 ˙+Λ1 ˙+ · · · ˙+Λn.
Each element ω may be represented as
ω = ω0 + ω1 + · · · + ωn,
ωi ∈Λi,
and this kind of expression is unique. In Λ there is not only algebraic structure of the
linear space, but also the deﬁnition of the exterior product. Direct sum Λ is the Grass-
mann algebra produced by the linear space which contained the entire real number
ﬁeld and the linear space.
1, x1, · · · , xn,
xi ∧xj (i < j), · · · , x1 ∧x2 ∧· · · ∧xn
form the basis of Λ, whose dimension is dim(Λ) =
n

i=0
 n
i

= 2n.
1.4 Foundation of Differential Form
There is no strict deﬁnition on how to deﬁne df for a smooth function and dx for
dx1, · · · , dxn, in classical mathematical analysis. The differential of the independent
variable is equal to its increment in classical mathematical analysis, which is improper
in a general sense. Here, we always regard dx1, · · · , dxn as some basis of a linear
space, which is called the differential space.

76
1. Preliminaries of Differentiable Manifolds
1.4.1 Differential Form
A vector ξ on Rn is a vector from 0 into ξ. A tangent vector (x, ξ) ∈TxRn on Rn
at x is a vector from x to x + ξ i.e., a ﬁxed vector starting from x to x + ξ. Tangent
vector (x, ξ) is usually denoted by ξx.
For (x, ξ), (x, η) ∈TxRndeﬁne:
α(x, ξ) + β(x, η) = (x, αξ + βη),
α, β ∈R
or αξx + βηx = (αξ + βη)x.Then, the tangent space TxRn to Rn at x forms a vector
space, and (e1)x, · · · , (en)x is its standard basis. The set
T(Rn) =
,
x∈Rn
TxRn
is called the tangent bundle on Rn, see Section 1.2. Notice that the tangent bundle
T(Rn) consists of all ﬁxed vectors on Rn.
The mapping π : TRn →Rn deﬁned by the following formula:
π(ξx) = x,
∀ξx ∈TxRn
is called the tangent bundle projection. π−1(x) = TxRn is called the ﬁber of the
tangent bundle over the point. The dual space of TxRn denoted by T ∗
xRn is called the
cotangent vector space to Rn at x consisting of all linear functions from TxRn into
Rn. Its element is called a covector (covariant vector) or a cotangent vector to Rn at
x, and
T ∗(Rn) =
,
x∈Rn
T ∗
xRn
is called the cotangent bundle.
The cotangent bundle projection:
π∗: T ∗(Rn) −→Rn
is similarly deﬁned :
π∗(ωx) = x,
∀ωx ∈T ∗
xRn.
We now introduce a natural topological structure into T ∗Rn. The element in
T ∗Rn can be represented as a vector consisting of 2n components (q1, · · · , qn, p1, · · · ,
pn), where (q1, · · · , qn)′ ∈Rn, (p1, · · · , pn)′ ∈T ∗
q Rn, viewed as Rn. Thus, topol-
ogy in T ∗Rn is the product topology in Rn × Rn. T ∗Rn equipped with such a
topology forms a 2n-dimensional manifold.
For any tangent space TxRn to Rn at x denoted by TxRn = {(x, ξ)|ξ ∈Rn},
the set of all k-forms on TxRn is denoted by Λk(TxRn).
Λk(Rn) =
#
x∈Rn Λk(TxRn) is called the exterior k-forms bundle on Rn. The
direct sum Λn(Rn) of k-form bundles Λk(Rn)(k = 0, 1, · · · , n),
Λ(Rn) = Λ0(Rn) ˙+Λ1(Rn) ˙+ · · · ˙+Λn(Rn)
is called the bundle of exterior forms on Rn ( where Λ0(Rn) = Rn).

1.4 Foundation of Differential Form
77
Deﬁnition 4.1. A differential k-form is a mapping ω : Rn →Λk(Rn), such that
ω(x) ∈Λk(TxRn). If ϕ1(x), · · · , ϕn(x) is the dual basis to (e1)x, · · · , (en)x on Rn,
then
ω(x) =

i1<···<ik
ai1···ik(x)ϕi1(x) ∧· · · ∧ϕik(x),
where ai1···ik(x) ∈F(Rk), the totality of functions on Rn.
ω is called continuous, differentiable, etc., if ai1···ik is continuous, differentiable
etc., respectively. From now on, we shall assume that forms that are differentiable will
always mean (C∞).
The set of all differentiable k-differential forms on Rn is denoted by Ωk(Rn), in
particular Ω0(Rn) = C∞(Rn). ∀ω1, ω2 ∈Ωk(Rn), f ∈C∞(Rn), deﬁne:
(ω1 + ω2)(x) = ω1(x) + ω2(x),
(fω)(x) = f(x) · ω(x).
Then, Ω∞(Rn) forms a C∞(Rn)-module, i.e., vector space over a ring. ∀ωk ∈
Ωk(Rn), ωl ∈Ωl(Rn), deﬁne their exterior product ωk ∧ωl ∈Ωk+l(Rn) as
(ωk ∧ωl)(x) = ωk(x) ∧ωl(x).
By this formula, we have:
f · ω = f ∧ω,
f ∈C∞(Rn)
(= Ω0(Rn)).
By the Theorem 3.24, the exterior product of differential forms deﬁned above is dis-
tributive, skew-symmetric, and associative.
If f : Rn →R is differentiable, then Df(x) ∈Λ1(Rn), where Df is the deriva-
tive of f(x) at x. Thus, we get a differential 1-form df ∈Ω1(Rn), deﬁned as
df(ξx) = Df(x)ξ =
n

i=1
Dif(x)ξi,
ξ =

ξiei.
Replacing f with xi for any x = (x1, · · · , xi, · · · , xn) yields:
dxi(ξx) = Dxi(ξ) = ξi,
or
dxi((ej)x) = Dxi(ej) = δij.
Thus, dx1, · · · , dxn form the dual basis to (e1)x, · · · , (en)x. ∀ω ∈Ωk(Rn), ω can
be written as
ω(x) =

i1<···<ik
ai1···ik(x)dxi1 ∧· · · ∧dxik,
where ai1···ik(x) ∈C∞(Rn).
Represented by dx1, · · · , dxn, the differential df 1-form is

78
1. Preliminaries of Differentiable Manifolds
df = D1fdx1 + · · · + Dnfdxn
or in a classical notation
df = ∂f
∂x1 dx1 + · · · + ∂f
∂xn dxn,
since
df(ξx) = D f(x)(ξ) =
n

i=1
ξiDif =
n

i=1
Difdxi(ξx),
∀ξx ∈TxRn.
Theorem 4.2. Every differential k-form on the space Rn with a given coordinate
system x1, · · · , xn can be represented uniquely in the form
ωk =

i1<···<ik
ai1···ik(x)dxi1 ∧· · · ∧dxik,
where the ai1···ik(x) are smooth functions on Rn.
As a particular case of Theorem 4.2, let k = 1. Thus, we have:
Theorem 4.3. Every differential 1-form on the space Rn with a given coordinate
system x1, · · · , xn can be represented uniquely with smooth function ai(x) as follows:
ω = a1(x)dx1 + · · · + an(x)dxn.
Example 4.4. Calculate the value of the forms ω = dr2(r2 = (x1)2 + (x2)2) on the
vectors ξ1, ξ2, ξ3. (Fig. 4.1), the results in full in the Table 4.1.
6
-
6
~
=
0
1
2
3
x1
x2
1
2
ξ1
ξ2
ξ3
Fig. 4.1.
Example 4.4 graphical representations
Table 4.1.
Example 4.4 table representations
ξ1
ξ2
ξ3
ω1
0
−1
1
ω2
0
−2
−2
ω3
0
−8
0
For example, calculate the value of ω3 in vectors ξ1, ξ2, ξ3 as follows:

1.4 Foundation of Differential Form
79
ω3(x)(ξi) = dr2 = 2x1dx1 + 2x2dx2,
ω3(x)(ξ1) = 2 · 0 · dx1(ξ1) + 2 · 0 · dx2(ξ1) = 0,
ω3(x)(ξ2) = 2 · 2 · dx1(ξ2) + 2 · 2 · dx2(ξ2) = 4 × (−1) + 4 × (−1) = −8,
ω3(x)(ξ3) = 2 · 2 · dx1(ξ3) + 2 · 2 · dx2(ξ3) = 4 × 1 + 4 × (−1) = 0.
Example 4.5. Calculate ω1 = dx1∧dx2, ω2 = x1dx3∧dx2−x2dx2∧dx1, and ω3 =
rdr ∧dϕ(x1 = r cos ϕ, x2 = r sin ϕ) in vectors (ξ1, η1), (ξ2, η2), and (ξ3, η3)(see
Fig. 4.2), result as follows:
Table 4.2.
Example 4.5 table representations
(ξ1, η1)
(ξ2, η2)
(ξ3, η3)
ω1
1
1
−1
ω2
2
1
−3
ω3
1
1
−1
6
-
6
R
-


6
0
1
2
x1
1
2
3
x2
ξ2
η2
ξ3
η3
ξ1
η1
Fig. 4.2.
Example 4.5 graphical representations
Example 4.6. Calculate the value of the forms ω1 = dx2 ∧dx3, ω2 = x1dx3 ∧
dx2, ω3 = dx3 ∧dr2 on the vectors ξ, η at the point x, where r2 = (x1)2 + (x2)2 +
(x3)2, ξ = (1, 1, 1)′, η = (1, 2, 3)′, x = (2, 0, 0).
The detailed calculation is shown bellow as follows:
ω1(ξ, η) = dx2 ∧dx3(ξ, η) =

dx2(ξ)
dx3(ξ)
dx2(η)
dx3(η)
 =

1
1
2
3
 = 1,
ω2(ξ, η) = 2 · dx3 ∧dx2(ξ, η) = −2ω1(ξ, η) = −2,
ω3(ξ, η) = dx3 ∧dr2(ξ, η)
= dx3 ∧(2x1dx1 + 2x2dx2 + 2x3dx3)(ξ, η)
= 2x1dx3 ∧dx1(ξ, η) −2x2dx2 ∧dx3(ξ, η)
= 2 · 2 · dx3 ∧dx1(ξ, η) −2 · 0 · dx2 ∧dx3(ξ, η)
= 4

dx3(ξ)
dx1(ξ)
dx3(η)
dx1(η)
 = 4

1
1
3
1
 = −8.

80
1. Preliminaries of Differentiable Manifolds
1.4.2 The Behavior of Differential Forms under Maps
First, we consider the behavior of differential forms under maps. Let f : Rn →Rm
be a differential mapping. Df(x) is the linear transformation from Rn to Rm, which
is the derivative of f, and DF(x) = ∂f i
∂xj the Jacobian of f at x. It induces a linear
transformation f∗from the tangent space TxRn to Rn at x into the tangent space
Tf(x)Rm to Rm at f(x), i.e.,
f∗(ξx) = (Df(x)(ξ))f(x),
∀ξx ∈TxRn.
Deﬁnition 4.7. Let f ∗: Ωk(Tf(x)Rm) →Ωk(TxRn) be a linear map:
(f ∗ω(x))(ξ1, · · · , ξk) = ω(f(x))(f∗ξ1, · · · , f∗ξk),
ξi ∈TxRn.
f ∗can be expanded on Ωk(Rm):
(f ∗ω)(x) = f ∗ω(x).
f ∗ω is called the pull-back of ω under f, which is the dual transformation of f∗.
Theorem 4.8. Let f : Rn →Rm, h : Rm →Rl, f, h ∈C∞. Then,
1◦
f ∗(d yi) =
n

j=1
∂f i
∂xj d xj.
2◦
f ∗(ω1 + ω2) = f ∗ω1 + f ∗ω2.
3◦
f ∗(ω ∧η) = f ∗ω ∧f ∗η.
4◦
f ∗(g · ω) = (g ◦f) · f ∗ω, ∀g ∈C∞(Rm).
5◦
(h ◦f)∗= f ∗◦h∗.
Proof. The proof is not difﬁcult. We only prove 1◦, 4◦and 5◦. ∀ξx ∈TxRn,
f ∗(d yi)(ξx) = d xi(f∗ξx) = (f∗ξ)i
=
n

j=1
∂f i
∂xj ξj =
n

j=1
∂f i
∂xj d xj(ξx).
Thus, we have
f ∗(dyi) =
n

j=1
∂f i
∂xj d xj.
The theorem is proved.
▲
Example 4.9. Let y = f(x1, x2) = (x1)2 + (x2)2, ω = dy,
f ∗ω = d x(f∗ξx) = ∂f
∂x1 d x1(ξx) + ∂f
∂x2 d x2(ξx)
= 2x1d x1 + 2x2d x2.

1.4 Foundation of Differential Form
81
Before proving 4◦, let us understand the following theorem.
Theorem 4.10. Let f = (f 1, · · · , f m)′ = (y1, · · · , ym), f : Rn →Rm be a differ-
entiable mapping with Jacobian
 ∂f i
∂xj

m×n =
 ∂yi
∂xj

m×n. For ω ∈Ωk(Rm),
ω =

i1<···<ik
ai1,···,ik(y)dyi1 ∧· · · ∧dyik,
we have
f ∗ω =

i1<···<ik; j1<···<jk
ai1,···,ik(f(x))Δ
 i1
· · ·
ik
j1
· · ·
jk
!
dxj1 ∧· · · ∧dxjk,
where Δ
 i1
· · ·
ik
j1
· · ·
jk
!
is the
 i1
· · ·
ik
j1
· · ·
jk
!
-minor of matrix
 ∂yi
∂xj

i = 1, · · · , m
j = 1, · · · , n
.
Proof.
f ∗ω = f ∗
*

i1<···<ik
ai1,···,ik(y)dyi1 ∧· · · ∧dyik
+
=

i1<···<ik
ai1,···,ik(f(x))f ∗(dyi1) ∧· · · ∧f ∗(dyik)
=

i1<···<ik
ai1,···,ik(f(x))
⎛
⎝
n

j1=1
∂yi1
∂xj1 dxj1
⎞
⎠∧· · · ∧
⎛
⎝
n

jk=1
∂yik
∂xjk dxjk
⎞
⎠
=

i1<···<ik
ai1,···,ik(f(x))
n

j1,···,jk=1
∂yi1
∂xj1 · · · ∂yik
∂xjk dxj1 ∧· · · ∧dxjk
=

i1<···<ik
ai1,···,ik(f(x))

j1<···<jk
n

(j1,···,jk)∈νk
ε
% j1
· · ·
jk
j′
1
· · ·
j′
k
& ∂yi1
∂xj′
1
· · · ∂yik
∂xj′
k dxj1 ∧· · · ∧dxjk
=

i1<···<ik; j1<···<jk
ai1,···,ik(f(x))Δ
%
i1
· · ·
ik
j1
· · ·
jk
&
dxj1 ∧· · · ∧dxjk.
The proof can be obtained.
▲
The following deduction gives the proof for 4◦.
Proof. If f : Rn →Rn is differentiable, then
f ∗(gdx1 ∧· · · ∧dxn) = g ◦f det (f ′)dx1 ∧· · · ∧dxn,
where f ′ = Df =
 ∂f i
∂xj

.
▲

82
1. Preliminaries of Differentiable Manifolds
For proof of 5◦:
Proof.
[f ∗(h∗ω)](x)(ξ1, · · · , ξp) =
(h∗ω)(f(x))(f∗ξ1, · · · , f∗ξp)
=
ω(h(f(x)))(h∗f∗ξ1, · · · , h∗f∗ξp)
=
ω(h ◦f)(x)((hf)∗ξ1, · · · , (hf)∗ξp)
=
[(h ◦f)∗ω](x)(ξ1, · · · , ξp).
Therefore, (h ◦f)∗= f ∗◦h∗.
▲
1.4.3 Exterior Differential
We now deﬁne an operator similar to differentiation in classical mathematical analysis.
We have introduced the function differential on the manifold, namely if f ∈C∞(Rn),
and df|x ∈TxRn, then df is a 1-form on Rn. Therefore, we may say operator
d : Ω0(Rn) →Ω1(Rn) maps the 0-form deﬁned on Rn onto the 1-form on Rn. We
need to extend this operator to the exterior algebra Ω(Rn) on M.
Deﬁnition 4.11. The exterior differential operator d on an exterior algebra ω(Rn) of
manifold M is a mapping
d : Ωk(Rn) −→Ωk+1(Rn),
where k = 0, 1, · · · , n.
Exterior algebra may be represented by the local coordinate system of M as
ω =

1≤i1<···<ik≤n
ai1,···,ikdxi1 ∧· · · ∧dxik,
which is a k-form. Then,
dω
=

1≤i1<···<ik≤n
dai1,···,ik ∧dxi1 ∧· · · ∧dxik
=

1≤i1<···<ik≤n
n

j=1
∂ai1,···,ik
∂xj
dxj ∧dxi1 ∧· · · ∧dxik.
Here d is called an exterior differential operator.
In particular, if ω = f ∈Ω0(Rn) = C∞(Rn), then
dω =
n

j=1
∂f
∂xj dxj.
From this, we can see that when ω ∈Ωn(Rn), dω = 0.

1.4 Foundation of Differential Form
83
Theorem 4.12. Exterior differential operator d has the following properties:
1◦
d(ω + η) = dω + dη.
2◦
∀ωk ∈Ωk, ωl ∈Ωl, has d(ωk ∧ωl) = dωk ∧ωl + (−1)kωk ∧dωl.
3◦
d(dω) = 0 or in simple form d2ω = 0.
4◦
f ∗d ω = df ∗ω.
Proof. 1◦
The proof is obvious.
2◦
Let
ωk(x) =

i1<···<ik
ai1,···,ikdxi1 ∧· · · ∧dxik,
ωl(x) =

j1<···<jl
bj1,···,jldxj1 ∧· · · ∧dxjl.
Then,
ωk ∧ωl =

i1<···<ik; j1<···<jl
ai1,···,ik(x)bj1,···,jl(x)dxi1 ∧· · · ∧dxik ∧dxj1 ∧· · · ∧dxjl.
By deﬁnition,
d(ωk ∧ωl) =

i1<···<ik; j1<···<jl
n

i=1
∂(ab)
∂xi dxi ∧dxi1 ∧· · · ∧dxik ∧dxj1 ∧· · · ∧dxjl
=

i1<···<ik; j1<···<jl
* n

i=1
bj1···jl
∂ai1···ik
∂xi
+ ai1···ik
∂bj1···jl
∂xi
+
dxi ∧dxi1 ∧· · · ∧dxik
∧dxj1 ∧· · · ∧dxjl
=

i1<···<ik; j1<···<jl
n

i=1
bj1···jl
∂ai1···ik
∂xi
dxi ∧dxi1 ∧· · · ∧dxik ∧dxj1 ∧· · · ∧dxjl
+

i1<···<ik; j1<···<jl
n

i=1
ai1···ik
∂bj1···jl
∂xi
(−1)kdxi ∧dxi1 ∧· · · ∧dxik ∧dxj1 ∧· · · ∧dxjl
= dωk ∧ωl + (−1)kωk ∧dωl.
3◦
The proof is as follows:
d(dω)
=

i1<···<ik
n

i,j=1
∂2a
∂xi∂xj dxi ∧dxj ∧dxi1 ∧· · · ∧dxik
=

i1<···<ik

i<j
%
∂2a
∂xi∂xj −
∂2a
∂xj∂xi
&
dxi ∧dxj ∧dxi1 ∧· · · ∧dxik
= 0,
since

84
1. Preliminaries of Differentiable Manifolds
∂2a
∂xi∂xj =
∂2a
∂xj∂xi .
4◦
By Theorem 4.8, 1 ◦∀ω = g ∈C∞(Rn), we have:
f ∗dg =
f ∗
* m

i=1
∂g
∂yi dyi
+
=
m

i=1
∂g
∂yi ◦f · f ∗(dyi)
=
n

j=1
m

i=1
∂g(f(x))
∂yi
· ∂f i
∂xj dxj
=
n

j=1
∂g(f(x))
∂xj
dxj = d(g ◦f) = df ∗g.
Furthermore, ∀ω ∈Ωk(Rm),
f ∗(dω)
= f ∗
*

i1<···<ik
m

i=1
∂a
∂yi dyi ∧dyi1 ∧· · · ∧dyik
+
= f ∗
*

i1<···<ik
da ∧dyi1 ∧· · · ∧dyik
+
=

i1<···<ik
f ∗(da) ∧f ∗
dyi1 ∧· · · ∧dyik
=

i1<···<ik
d(f ∗a) ∧f ∗
dyi1 ∧· · · ∧dyik
= d
*

i1<···<ik
f ∗a ∧f ∗
dyi1 ∧· · · ∧dyik
+
(by 3◦)
= df ∗ω.
Therefore, the theorem is completed.
▲
1.4.4 Poincar´e Lemma and Its Inverse Lemma
Deﬁnition 4.13. A differential form ω is closed if dω = 0, and is exact if there exists
a differential form η such that ω = dη.
Clearly if ω is exact, then it is closed by the formula d2ω = 0. However, the con-
verse is not always true. The following Poincar´e lemma asserts that in the neighbour-
hood of each point, the closed is equivalent to the exact. Before stating the Poincar´e
lemma, we introduce a notion.
Deﬁnition 4.14. An open set A ⊂Rn is star-shaped with respect to 0, if for any
x ∈A the set {αx | α ∈[0, 1]} ⊂A.

1.4 Foundation of Differential Form
85
Evidently, Rn is a star-shaped open set, and every convex set containing 0 is a
star-shaped open set with respect to 0.
Theorem 4.15 (Poincar´e lemma). Let A ⊂Rn be an open star-shaped set with
respect to 0. Then, every closed form on A is exact.
Proof. We will construct an R-linear mapping H : Ωk(A) →Ωk−1(A), such that
d◦H +H ◦d = id: Ωk(A) →Ωk(A), i.e., ω = d◦H(ω)+Hdω. Then, from dω = 0,
if follows that ω = d(H(ω)). Taking η = H(ω), we get
ω = dη.
Let
ω =

i1<···<ik
ai1···ik(x)dxi1 ∧· · · ∧dxik.
Deﬁne
H(ω)(x) =

i1<···<ik
k

j=1
(−1)j−1
% - 1
0
tk−1ai1···ik(tx)dtxij
· dxi1 ∧· · · ∧.
dxij ∧· · · ∧dxik
&
,
where the symbol “  ” over dxij indicates that it is omitted.
dH(ω) =

i1<···<ik
k

j=1
(−1)j−1
%- 1
0
tk−1a(tx)dt
&
dxij ∧dxi1 ∧· · · ∧dxik
+

i1<···<ik
k

j=1
(−1)j−1
* n

i=1
- 1
0
tk ∂a(tx)
∂xi
dxidt
+
xij ∧dxi1 ∧· · · ∧dxik
= k

i1<···<ik
%- 1
0
tk−1a(tx)dt
&
dxi1 ∧· · · ∧dxij ∧· · · ∧dxik
+

i1<···<ik
k

j=1
(−1)j−1
n

i=1
- 1
0
tk ∂a(tx)
∂xi
dtxijdxi ∧dxi1 ∧· · ·
∧.
dxij ∧· · · ∧dxik.
(4.1)
On the other hand,

86
1. Preliminaries of Differentiable Manifolds
dω =

i1<···<ik
n

i=1
∂a
∂xi dxi ∧dxi1 ∧· · · ∧d xik,
Hdω =

i1<···<ik
'
n

i=1
 - 1
0
tk ∂a(tx)
∂xi
dt

xidxi1 ∧· · · ∧dxik
+
n

i=1
k

j=1
(−1)j
- 1
0
tk ∂a(tx)
∂xi
dtxijdxi ∧dxi1 ∧· · ·
∧.
dxij ∧· · · ∧dxik
/
.
The second term of the right hand side in this equality coincides with the second term
in Equation (1.3) except for the sign. Adding them together, we get
dH(ω) + Hdω
= k

i1<···<ik
- 1
0
tk−1a(tx)dt dxi1 ∧· · · ∧dxik
+

i1<···<ik
n

i=1
- 1
0
tk ∂a(tx)
∂xi
dtxi dxi1 ∧· · · ∧dxik
=

i1<···<ik
- 1
0
*
ktk−1a(tx) +
n

i=1
tk ∂a(tx)
∂xi
xi
+
dt dxi1 ∧· · · ∧dxik.
Notice that
ktk−1a(tx) +
n

i=1
tkxi ∂a(tx)
∂xi
= d
dt

tka(tx)

.
Thus,
- 1
0
*
ktk−1a(tx) +
n

i=1
tk ∂a(tx)
∂xi
xi
+
dt
=
- 1
0
d
dt

tka(t, x)

dt = a(x).
Then, we have
dH(ω) + Hdω =

i1<···<ik
ai1···ik(x)dxi1 ∧· · · ∧dxik = ω,
i.e.,
dH + Hd = id.
Therefore, the theorem is completed.
▲
1.4.5 Differential Form in R3
We now assume that R3 is a three-dimensional oriented Euclidean space. The square
of the length element in R3 has the form

1.4 Foundation of Differential Form
87
ds2 = (dx1)2 + (dx2)2 + (dx3)2.
For any vector A ∈R3, we deﬁne a corresponding 1-form ω1
A and a 2-form ω2
A by
the formula
ω1
A(ξ) = (A, ξ),
ω2
A(ξ, η) = (A, [ξ, η]),
∀ξ, η ∈R3,
where ( , ) stands for usual inner product and ( , [ ]) for triple scalar product.
Let A = A1e1 + A2e2 + A3e3 and ω1
A = a1dx1 + a2dx2 + a3dx3. Then by
deﬁnition, on one hand, ωA(ej) =
3

i=1
aidx1(ej) = Aj; on the other hand, ωA(ej) =
(A, ej) = Aj. Thus, aj = Aj, i.e., ω1
A = A1dx1 + A2dx2 + A3dx3. Similarly, we
can get
ω2
A = A1dx2 ∧dx3 + A2dx3 ∧dx1 + A3dx1 ∧dx2.
It is easy to observe that
ω2
A =∗(ω1
A),
ω1
A = b(A).
Here, the top left hand corner “*” (“b”) represents the Hodge (sharp) operator respec-
tively, namely ∗: ∧k(Rm) →∧n−k(Rm); b : R →R∗.
We now introduce three operators that play an important role in classical vector
analysis, i.e., gradient, curl, and divergence.
Deﬁnition 4.16. Let f ∈C∞(R3) and A ∈X(R3). The grad f and curl A ∈X(R3)
and div (A) ∈C∞(R3) deﬁned as follows
ω1
gradf = df,
ω2
curl A = dω1
A,
and
dω2
A = div A = ω3
A,
where ω3 = dx1 ∧dx2 ∧dx3 is the volume element in R3.
By this deﬁnition,
ω1
grad f = df = ∂f
∂x1 dx1 + ∂f
∂x2 dx2 + ∂f
∂x3 dx3.
Thus,
grad f = ∂f
∂x1 e1 + ∂f
∂x2 e2 + ∂f
∂x3 e3
=
 ∂f
∂x1 , ∂f
∂x2 , ∂f
∂x3

= ∂f
∂x,
and so

88
1. Preliminaries of Differentiable Manifolds
ω2
curl A =
dω1
A = d

A1(x)dx1 + A2(x)dx2 + A3(x)dx3
=
∂A1
∂x1 dx1 + ∂A1
∂x2 dx2 + ∂A1
∂x3 dx3
∧dx1
+
∂A2
∂x1 dx1 + ∂A2
∂x2 dx2 + ∂A2
∂x3 dx3
∧dx2
+
∂A3
∂x1 dx1 + ∂A3
∂x2 dx2 + ∂A3
∂x3 dx3
∧dx3
=
∂A3
∂x2 −∂A2
∂x3

dx2 ∧dx3 +
∂A1
∂x3 −∂A3
∂x1

dx3 ∧dx1
+
∂A2
∂x1 −∂A1
∂x2

dx1 ∧dx2,
where
curl A =
∂A3
∂x2 −∂A2
∂x3

e1 +
∂A1
∂x3 −∂A3
∂x1

e2 +
∂A2
∂x1 −∂A1
∂x2

e3
=

e1
e2
e3
∂
∂x1
∂
∂x2
∂
∂x3
A1
A2
A3

,
ω3
div A = dω2
A = d(A1dx2 ∧dx3 + A2dx3 ∧dx1 + A3dx1 ∧dx2)
=
∂A1
∂x1 + ∂A2
∂x2 + ∂A3
∂x3

dx1 ∧dx2 ∧dx3.
Therefore,
div A = ∂A1
∂x1 + ∂A2
∂x2 + ∂A3
∂x3 .
Since
ω2
curl grad f = d ω1
grad f = d (d f) = 0,
div curl (A)ω3 = d

ω2
curl A

= d (d ω1
A) = 0,
we easily get two equalities in classical vector analysis:
curl grad = 0,
div curl = 0.
1.4.6 Hodge Duality and Star Operators
Let us introduce the Hodge operator as a linear transformation:
∗: Λp −→Λn−p.
Deﬁnition 4.17. Denoting ∗υ as a element in Λn−p, ∀u ∈Λp, we have

1.4 Foundation of Differential Form
89
uΛ ∗υ = (u, υ)en.
For brevity, we write uΛ ∗υ as u ∗υ.
If υ is a scalar, u must also be a scalar. By the above formula, we get ∗υ = υen.
Example 4.18. If
α =

i1<···<ip
ai1···ipdxi1 ∧· · · ∧dxip,
then
∗α =

i1<···<ip
bj1···jn−pdxj1 ∧· · · ∧dxjn−p,
where
bj1···jn−p =

i1<···<ip
εi1···ipj1···jn−pai1···ip,
εi1···ipj1···jn−p is the generalized Kronecker symbol.
Star operators in 3-dimensional space have the following properties:
Property 4.19.
1◦
∗d x = d y ∧d z.
2◦
∗d y = d z ∧d x.
3◦
∗d z = d x ∧d y.
4◦
∗(d x ∧d y ∧d z) = 1.
5◦
Let ω = a1d x1 + a2d x2 + a3d x3, then
∗dω =
%∂a3
∂x2 −∂a2
∂x3
&
d x1 +
%∂a1
∂x3 −∂a3
∂x1
&
d x2 +
%∂a2
∂x1 −∂a1
∂x2
&
d x3.
6◦
∗d ∗ω = ∂a1
∂x1 + ∂a2
∂x2 + ∂a3
∂x3 .
7◦
grad = d (operation on Λ0(R3)).
8◦
rot = ∗d (operation on Λ1(R3)).
9◦
div = ∗d∗(operation on Λ2(R3)).
1.4.7 Codifferential Operator δ
We know that the exterior differential operator d : Λk(M) →Λk+1(M) is a linear
differential operator of ﬁrst order, which increases one order in the form of differential
form. However, Hodge star operator ∗: Λk(M) →Λn−k(M) essentially is a dual
operator. From this, one may ask whether it is possible to deﬁne a kind of −1 linear
differential operator δ : Λk(M) →Λk−1(M). The answer is yes.
Deﬁnition 4.20. The codifferential operator δ is a kind of linear differential operator
of −1 order. δ: Λk(M) →Λk−1(M). It can be represented by
δ = −(−1)g(−1)n(k+1) ∗d ∗.
If our manifold is an oriented Riemann manifold, then g = 1.

90
1. Preliminaries of Differentiable Manifolds
Deﬁnition 4.21. The k-form ω is called coclosed, if δω = 0; it is called coexact, if
there exists a θ ∈Λk+1(M) s.t. ω = δθ. The relation between operators δ, d, and ∗
leads to the following theorem.
Theorem 4.22. A codifferential operator δ has the following properties:
1◦
δ2 = 0.
2◦
∗δd = dδ∗, ∗dδ = δd∗.
3◦
d ∗δ = δ ∗d = 0.
4◦
∗(δω) = (−1)kd(∗ω), ω ∈Λk(M).
5◦
δ(∗ω) = (−1)n−k+1(dω), ω ∈Λk(M).
1.4.8 Laplace–Beltrami Operator
Deﬁnition 4.23. Linear mapping
Δ = d δ + δ d,
Λk(M) −→Λk(M)
is called Laplace–Beltrami operator on Riemann manifold.
If k = 0, for f ∈Λ0(M), we have δf = 0, and then
Δf = δdf.
Theorem 4.24. The Laplace–Beltrami operator obeys the following rule:
1◦
Δ = (d + δ)2.
2◦
d · Δ = Δ · d = d · δ · d.
3◦
δ · Δ = Δ · δ = δ · d · δ.
4◦
∗Δ = Δ ∗.
Example 4.25. Let f ∈Λ0(R3). For a rectangular coordinate system δ, we have
Δf = δdf = δ ∂f
∂xi dxi.
Since δ = −(−1)g(−1)n(k+1) ∗d∗= ∗d∗,
Δf = ∗d ∗
% ∂f
∂xi dxi
&
=

∂2f
(∂xi)2 .
Obviously, for R3, the Laplace–Beltrami operator Δ : Λ0(R3) →Λ0(R3) is the
usual Laplace operator Δ =
3

i=1
∂2
(∂xi)2 .
The corresponding relationship in action on the form operators d and δ and action on
the coefﬁcient of vector analysis can be summarized as follows:

1.5 Integration on a Manifold
91
form:
Λ0
d
⇄
δ
Λ1
d
⇄
δ
Λ2
d
⇄
δ
Λ3
coef.:
scalar
grad
⇄
−div
vector
curl
⇄
curl
vector
div
⇄
−grad
scalar
We can easily obtain two equations in classical vector analysis:
d d = 0 :
rot grad = 0,
div rot = 0.
δ δ = 0 :
−rot grad = 0,
−div rot = 0.
1.5 Integration on a Manifold
The integral of an n-form on an n-manifold is deﬁned in terms of integral over sets in
Rn by means of partition of unity subordinate of an atlas.
1.5.1 Geometrical Preliminary
Chains. A singular k-cube in M ⊂Rn is a continuous function c : [0, 1]k →M,
where [0, 1]n = [0, 1] × · · · × [0, 1]
0
12
3
n
, R0 = [0, 1]0 = {0}.
A singular 0-cube in M is a function c : [0, 1]0 = {0} →M, i.e., a point in M.
A singular 1-cube in M is a usual curve. The standard n-cube in Rn is the identity
mapping In : [0, 1]n →Rn, In(x) = x, ∀x ∈[0, 1]n.
Deﬁnition 5.1. A k-chain C in M is a linear combination of ﬁnite singular k-cubes
ci in M, i.e.,
c = α1c1 + · · · + αrcr,
αi ∈R,
i = 1, · · · , r.
The set of all k-chains in M is denoted by Ck(M). Ck(M) forms a vector space
on R if we introduce in Ck(M) the addition and multiplication by scalar by the fol-
lowing formulae:
c1 + c2 =
r

i=1
α1
i ci +
r

i=1
α2
i ci =
r

i=1
(α1
i + α2
i )ci,
αc1 = α
r

i=1
α1
i ci =
r

i=1
(αα1
i )ci,

92
1. Preliminaries of Differentiable Manifolds
where cj =
r

i=1
αj
ici (j = 1, 2) are two k-chains in M. Without loss of generality,
we assume that different chains c1 and c2 are generated by the same set of k-cubes
{c1, · · · , cr}. For example, let c1 = c1 + 2c2, c2 = c1 + c3, where c3 ̸= c2. We only
need to rewrite c1 and c2 as c1 = c1 + 2c2 + 0 · c3, c2 = c1 + 0 · c2 + c3.
Boundary of Chains
Corresponding to the exterior operator d: Ωk →Ωk+1, there
is a boundary operator ∂: Ck(M) →Ck−1(M), as deﬁned below:
∂[0, 1] = {1} −{0},
∂[0, 1]2 = ∂

[0, 1] × [0, 1]

= {1} × [0, 1] −{0} × [0, 1]
−[0, 1] × {1} + [0, 1] × {0}.
For general [0, 1]k, ∀x ∈[0, 1]k−1, denote
Ik
(i,0)(x) = Ik(x1, · · · , xi−1, 0, xi, · · · , xk−1),
Ik
(i,1)(x) = Ik(x1, · · · , xi−1, 1, xi, · · · , xk−1).
We call Ik
(i,0) and Ik
(i,1) as (i, 0)- and (i, 1)-surface respectively, and
∂Ik = ∂[0, 1]k =
k

i=1

α=0,1
(−1)i+αIn
(i,α).
For any k-cube c : [0, 1]k →M, the (i, α)-surface is deﬁned as
c(i,α) = c ◦Ik
(i,α).
The boundary ∂c of the k-cube c is
∂c =
k

i=1

α=0,1
(−1)i+αc ◦Ik
(i,α) =
k

i=1

α=0,1
(−1)i+αc(i,α).
The boundary of any k-chain c =

j
αjcj is
∂c =

j
αj∂cj.
Theorem 5.2. For any k-chain c, ∂(∂c) = 0, or brieﬂy ∂2 = 0.
Proof. Firstly, assume i ≤j and consider (Ik
(i,α))(j,β). For x ∈[0, 1]k−2, we have
(Ik
(i,α))(j,β)(x) = Ik
(i,α)(x1, · · · , xj−1, β, xj, · · · , xk−2)
= Ik(x1, · · · , xi−1, α, xi, · · · , xj−1, β, xj, · · · , xk−2).

1.5 Integration on a Manifold
93
Similarly, we have
(Ik
(j+1,β))(i,α)(x) = Ik
(j+1,β)(x1, · · · , xi−1, α, xi, · · · , xk−2)
= Ik(x1, · · · , xi−1, α, xi, · · · , xj−1, β, xj, · · · , xk−2).
Thus, if i ≤j, (Ik
(i,α))(j,β)(x) = (Ik
(j+1,β))(i,α)(x), it is easy to see that for any
k-cube c, (c(i,α))(j,β) = (c(j+1,β))(i,α) as i ≤j. Now,
∂(∂c) = ∂
* k

i=1

α=0,1
(−1)i+αc(i,α)
+
=
k

i=1

α=0,1
k−1

j=1

β=0,1
(−1)i+α+j+β(c(i,α))(j,β).
In this sum, (c(i,α))(j,β) and (c(j+1,β))(i,β) occur simultaneously with the opposite
sign. Then, all terms disappear in pairs and ∂(∂c) = 0. Consequently, for any k-chain
c =
r

i=1
αici, where ci (i = 1, · · · , r) are the k-cubes,
∂(∂c) = ∂
* r

i=1
ai∂ci
+
=
r

i=1
ai∂(∂ci) = 0.
The theorem is proved.
▲
Deﬁnition 5.3. A k-chain c is called a cycle if ∂c = 0. A k-chain c is called a bound-
ary if there is a k + 1-chain c1 such that c = ∂c1. Obviously, boundaries imply cycles.
However, the converse is not always true.
1.5.2 Integration and Stokes Theorem
For any ω ∈Ωk([0, 1]k), there is a f ∈C∞((0, 1)k) such that ω = fdx1 ∧· · · ∧dxk.
Deﬁne the integral of ω on [0, 1]k as
-
[0,1]k ω =
-
[0,1]k f,
i.e.,
-
[0,1]k ω =
-
[0,1]k fdx1 · · · dxk,
where the right hand side is a Riemannian integral of f on [0, 1]k.
If ω ∈Ck(M) and c is a k-cube in M, we deﬁne the integral of ω on c as
-
c
ω =
-
[0,1]k c∗ω.

94
1. Preliminaries of Differentiable Manifolds
In particular,
-
Ik fdx1 ∧· · · ∧dxk =
-
[0,1]k(Ik)∗(fdx1 ∧· · · ∧dxk)
=
-
[0,1]k f(x1, · · · , xk) dx1 · · · dxk.
If c is a 0-cube, we deﬁne
-
c
ω = ω(c(0)).
The integral of ω on a k-chain c =

i
aici is
-
c
ω =

i
ai
-
ci
ω,
where ci are k-cubes in M.
Example 5.4. For k = 1, c : [0, 1] →R2 is a curve deﬁned by x = cos 2πθ, y =
sin 2πθ (1 ≤θ ≤1), i.e., a circle on (x, y)-plane. Let
ω = P(x, y)dx + Q(x, y)dy,
then, the integral of ω on c is
-
c
ω =
-
c
P(x, y)dx + Q(x, y)dy
=
-
[0,1]
c∗(P(x, y)dx + Q(x, y)dy)
=
- 1
0

−P(cos 2πθ, sin 2πθ)2π sin 2πθ
+Q(cos 2πθ, sin 2πθ)2π cos 2πθ

d θ,
which is the usual integral along a curve.
Theorem 5.5 (Stokes theorem). If ω is a (k −1)-form on an open set M ⊂Rn and
c is a k-chain in M, then
-
c
dω =
-
∂c
ω.
Proof. 1◦
Firstly, we assume c = Ik and ω is a (k −1)-form on [0, 1]k. Then, ω is
a sum of (k −1)-forms of the type
fdx1 ∧· · · ∧4
dxi ∧· · · ∧dxk.

1.5 Integration on a Manifold
95
Thus, it sufﬁces to prove the theorem for each of these.
-
Ik dω =
-
Ik d(fdx1 ∧· · · ∧4
dxi ∧· · · ∧dxk)
=
-
[0,1]k
 ∂f
∂xi dxi ∧dx1 ∧· · · ∧4
dxi ∧· · · ∧dxk
=
-
[0,1]k(−1)i−1 ∂f
∂xi dx1 ∧· · · ∧4
dxi ∧· · · ∧dxk
= (−1)i−1
-
[0,1]k
∂f
∂xi (x1, · · · , xk)dx1 · · · dxk
= (−1)i−1
-
[0,1]k−1

f(x1, · · · , 1, · · · , xk)
−f(x1, · · · , 0, · · · , xk)

dx1 ∧· · · ∧4
dxi ∧· · · ∧dxk.
Notice that
-
[0,1]k−1 Ik∗
(j,α)(fdx1 ∧· · · ∧4
dxi ∧· · · ∧dxk)
=
-
[0,1]k−1 f(x1, · · · , xj−1, α, xj, · · · , xk)

Ik∗
(j,α)dx1
∧· · · ∧dxi ∧· · · ∧

Ik∗
(j,α)dxk
=
⎧
⎪
⎨
⎪
⎩
0,
i ̸= j,
-
[0,1]k−1 f(x1, · · · , α, · · · , xk) dx1 · · · 4
dxi · · · dxk,
i = j.
Thus,
-
∂Ikfdx1 ∧· · · ∧4
dxi ∧· · · ∧dxk
=
n

j=1

α=0,1
(−1)j+α
-
[0,1]k−1 Ik∗
(j,α)(fdx1 ∧· · · ∧4
dxi ∧· · · ∧dxk)
= (−1)i+1
-
[0,1]k−1

f(x1, · · · , xi−1, 1, · · · , xk)
−f(x1, · · · , 0, · · · , xk)

d x1 ∧· · · ∧.
d xi ∧· · · ∧d xk.
In other words,
-
Ik dω =
-
∂Ik ω.
2◦
For a singular k-cube c, since

96
1. Preliminaries of Differentiable Manifolds
∂c =
k

i=1

α=0,1
(−1)i+αc(i,α)
=
k

i=1

α=0,1
(−1)i+αc ◦Ik
(i,α),
by deﬁnition of integration,
-
∂c
ω =
k

i=1

α=0,1
(−1)i+α
-
c◦Ik
(i,α)
ω
=
k

i=1

α=0,1
(−1)i+α
-
I∗
(i,α)
c∗ω =
-
∂Ik c∗ω,
-
c
dω =
-
Ik c∗dω =
-
Ik dc∗ω =
-
∂Ik c∗ω,
and so
-
c
dω =
-
∂c
ω, for any singular k-cube c.
Finally, if c is a k-chain, i.e., c =
k

i=1
αici, where ci are singular k-cubes, then
-
c
dω =
k

i=1
ai
-
ci
dω =
k

i=1
ai
-
∂ci
ω =
-
∂c
ω.
Therefore, the theorem is completed.
▲
Example 5.6. Consider the 1-form
ω1 = p1dq1 + · · · + pndqn,
on R2n with the coordinates p1, · · · , pn, q1, · · · , qn; dω1 = dp1 ∧dq1 + · · · + dpn ∧
dqn = dp ∧dq. Thus,
- -
ci
dp ∧dq =
-
∂ci
p dq.
In particular, if ci is a cycle , i.e., ∂ci = 0, then
- -
ci
dp ∧dq = 0.
1.5.3 Some Classical Theories on Vector Analysis
Here, we assume R3 is the oriented 3-dim Euclidian space. By Subsection 1.4.5, every
vector ﬁeld A on R3 corresponds to a 1-form ω1
A and a 2-form ω2
A:

1.5 Integration on a Manifold
97
A = (A1(x), A2(x), A3(x)),
ω1
A = A1(x)dx1 + A2(x)dx2 + A3(x)dx3,
ω2
A = A1(x)dx2 ∧dx3 + A2(x)dx3 ∧dx1 + A3(x)dx1 ∧dx2.
Suppose a 1-chain c1 represents a curve l (with the same orientation). Then,
-
c1
ω1
A =
-
c1
A1dx1 + A2dx2 + A3dx3 =
-
l
A · dl,
which shows that the integral of ω1
A on a l-chain c1 representing a curve l is the circu-
lation of the ﬁeld A over the curve l. If A is a force ﬁeld, then the integral of ω1
A on a
1-chain c1 is the work done by A along the curve l.
Suppose a 2-chain c2 represents an oriented surface S. Then,
-
c2
ω2
A =
-
c2
A1dx2 ∧dx3 + A2dx3 ∧dx1 + A3dx1 ∧dx2
=
-
S
A1dx2dx3 + A2dx1dx3 + A3dx1dx2
=
-
S
Adn.
In other words, the integral of ω2
A on a 2-chain c2 representing an oriented surface
S is the ﬂux of the ﬁeld A though the surface S.
Applying the Stokes’ theorem to different cases, we can get three important theo-
rems in classical calculus, Green theorem, Gauss theorem, and Stokes theorem.
Theorem 5.7 (Green theorem). Let c2 represent a 2-dim domain D, ∂c2 the bound-
ary l of D, and ω = P(x, y)dx + Q(x, y)dy ∈C1(R2). Then,
-
c2
dω =
-
c2
d(Pdx + Qdy),
-
∂c2
ωdl =
-
l
Pdx + Qdy
=
-
c2
∂Q
∂x −∂P
∂y

dx ∧dy =
-
D
∂Q
∂x −∂P
∂y

dxdy.
Proof. Since
d (Pdx + Qdy) =
∂Q
∂x −∂P
∂y

dx ∧dy,
the Stokes theorem
-
∂c
ωdl =
-
c
dω implies
-
D
∂Q
∂x −∂P
∂y

dxdy =
-
l
Pdx + Qdy,
which is the classical Green theorem.
▲

98
1. Preliminaries of Differentiable Manifolds
Theorem 5.8 (Gauss theorem). If a 3-chain c3 represents a domain in R3, ∂c3
represents the boundary S = ∂D of D, and ω2
A = Axdy∧dz+Aydz∧dx+Azdx∧dy
is a 2-form on R3, then
-
c3
dω2
A =
-
c3
∂Ax
∂x + ∂Ay
∂y + ∂Az
∂z

dx ∧dy ∧dz
=
-
D
div Adxdydz,
-
∂c3
ω =
-
S
Axdydz + Aydxdz + Azdxdy.
Thus, by Stokes’ theorem, we obtain Gauss theorem.
Theorem 5.9 (Classical Stokes theorem).
-
D
div Adxdydz =
-
S
Axdydz + Aydxdz + Azdxdy.
If a 2-chain C in R3 represents an oriented surface S, its boundary is l = ∂S =
∂c2 and ω1
A = Axdx + Aydy + Azdz is a 1-form on R3. Then, the Stokes’ theorem
shows
-
l
Ax dx + Ay dy + Az dz =
-
S
curl A ds.
Here we use the equality: dω1
A = ω1
curl A.
1.6 Cohomology and Homology
The set of all closed k-forms, denoted by Zk, forms a subspace of Ωk and the set of
all exact k-forms, denoted by Bk, also forms a subspace of Ωk. The quotient space
Hk(M, R) = Zk
Bk ≡
ker dk
imdk−1
,
is called the k-th cohomology space. An element in Hk is an equivalent class of closed
forms, in which two closed forms ω1 and ω2 are equivalent if there is a (k −1)-form
θ such that ω1 −ω2 = dθ, where d is called the exterior differential operator. It is a
mapping
d : Ωk(M) −→Ωk+1(M).
The kernel of d is the subspace Zk of the closed k-form, the image of d is the
space Bk of exact differential form. For every k-form, we have dωk = 0. Then
Bk ⊆Zk.

1.7 Lie Derivative
99
Similarly, the set of all k-cycles, denoted by Zk, and the set of all k-boundaries,
denoted by Bk, form a subspace of the vector space Ck. The corresponding quotient
space
Hk(M, R) = Zk
Bk
= ker ∂k
im∂k+1
is called the k-th homology space. An element in Hk is a class of cycles differing from
one another only by a boundary.
Deﬁnition 6.1. The dimension of Hk(Hk), denoted by bk(bk), is called the k-th Betti
number.
Theorem 6.2 (De Rham theorem). The two Betti numbers are the same, i.e.,
bk = bk.
Example 6.3. M ⊂Rn is an open set. We consider H0(M, R) and H0(M, R), B0 =
{0}, for there is no such form smaller than 0-form. If ω ∈Ω0(M), then ω = f ∈
C∞(M), df = 0 means that f is equal to a constant (local), and:
Z0(M) = R × · · · × R
0
12
3
m
.
If M has components connected by m paths. Since H0(M, R) = Z0(M), and
b0 = dim (H0(M, R)) = m, it is easy to see that , Z0(M) is generated by all points
in M and m1, m2 ∈M ⊂Z0(M) is equivalent, iff they have components connected
by the same path. Thus, H0(M, R) = R × · · · × R
0
12
3
m
and b0 = dim (H0(M, R)) = m.
We have b0 = b0. The De Rham theorem holds good for k = 0 in this case.
1.7 Lie Derivative
The Lie derivative may be deﬁned in several equivalent ways. In this section, to keep
things simple, we begin by deﬁning the Lie derivative acting on scalar functions and
vector ﬁelds. The Lie derivative can also be deﬁned to act on general tensors, as dis-
cussed later in the article.
1.7.1 Vector Fields as Differential Operator
Let X(x) =
n

i=0
Xi(x)ei = (X1(x), · · · , Xn(x)) be a vector ﬁeld on Rn, and ω1 =
n

i=0
ai(x) dxi be a 1-form on Rn. ⟨ω1, X⟩(x) = ⟨ω1(x), X(x)⟩is the function on

100
1. Preliminaries of Differentiable Manifolds
Rn, where ⟨, ⟩is the dual bracket between TxRn and T ∗
xRn. This deﬁnes the natural
bilinear mapping of
Λ1(Rn) × X(Rn) −→C∞(Rn).
If ω1 = df =
 ∂f
∂xi dxi, then
⟨df, X⟩=
n

i=1
∂f
∂xi Xi =
n

i=1
Xi(x) ∂f
∂xi .
Denote ⟨df, X⟩= LXf, i.e., LXf =
n

i=1
Xi
∂f
∂xi , ∀f ∈C∞(Rn). Thus, any smooth
vector ﬁeld may be viewed as a linear partial differential operator on Rn of order 1,
without zero terms and smooth coefﬁcient, i.e., there is a correspondence between
X(x) ∈X(Rn) and LX:
X(x) =
n

i=1
Xi(x)ei −→LX =
n

i=1
Xi(x) ∂
∂xi .
It is one to one, and so hereafter, we can also write X(x) =
n

i=1
Xi(x)ei as
X(x) =
n

i=1
Xi(x) ∂
∂xi .
Deﬁnition 7.1. For any two vector ﬁelds X, Y ∈X(Rn), deﬁne
[X, Y ] = XY −Y X,
i.e.,
[X, Y ]f = X(Y f) −Y (Xf),
∀f ∈C∞(R),
where Xf is viewed as LXf, and [X, Y ] is called the commutator or the Poisson
bracket of X, Y .
Proposition 7.2. Let X =
n

i=1
Xi(x) ∂
∂xi , Y =
n

i=1
Yi(x) ∂
∂xi , then
[X, Y ] =
n

i=1
n

k=1

Xk
∂Yi
∂xk −Yk
∂Xi
∂xk
 ∂
∂xi .
Proof. ∀f ∈C∞(Rn),

1.7 Lie Derivative
101
[X, Y ]f = X(Y f) −Y (Xf)
= X

n

i=1
Yi
∂f
∂xi

−Y

n

i=1
Xi
∂f
∂xi

=
n

k=1
n

i=1

Xk
∂Yi
∂xk
∂f
∂xi + XkYi
∂2f
∂xi∂xk −Yk
∂Xi
∂xk
∂f
∂xi −YkXi
∂f 2
∂xi∂xk

=
n

i=1
n

k=1

Xk
∂Yi
∂xk −Yk
∂Xi
∂xk
 ∂f
∂xi .
Thus,
[X, Y ] =
n

i=1
n

k=1

Xk
∂Yi
∂xk −Yk
∂Xi
∂xk
 ∂
∂xi .
The i-th component of [X, Y ] is
[X, Y ]i =
n

k=1

Xk
∂Yi
∂xk −Yk
∂Xi
∂xk

.
In this manner, [X, Y ] may be represented by ∂Y
∂x X −∂X
∂x Y , where ∂Y
∂x is the Jaco-
bian of Y .
▲
Theorem 7.3. Let X1, X2, X3 ∈X(Rn) and f, g ∈C∞(Rn). Then,
1◦
[X1, X2] = −[X2, X1].
2◦
[α1X1 + α2X2, X3] = α1[X1, X3] + α2[X2, X3].
3◦
[fX1, gX2] = f(X1g)X2 −g(X2f)X1 + fg[X1, X2].
4◦
[X1, [X2, X3]] + [X2, [X3, X1]] + [X3, [X1, X2]] = 0.
The equality 4◦is called Jacobi identity.
Proof. 1◦and 2◦are evident. 4◦follows immediately from the expansion 3◦:
[fX1, gX2]
= (fX1)(gX2) −(gX2)(fX1)
= f(X1g)X2 + fgX1X2 −g(X2f)X1 −fgX2X1
= f(X1g)X2 −g(X2f)X1 + fg[X1, X2].
The proof can be obtained.
▲
1.7.2 Flows of Vector Fields
In Subsection 1.2.2, we have already discussed vector ﬁeld and the ﬂow of a general
differentiable manifold. Now, we focus on applications to the dynamic system.

102
1. Preliminaries of Differentiable Manifolds
(1) Phase space:
The set of all possible states of a process is called phase space. For
example, consider the motion of system in classical mechanics, whose future and past
are uniquely determined by the initial position and initial velocities of all points in the
system. The phase space of a mechanical system is the set whose elements are the sets
of positions and velocities of all points of the given system. This is exactly the tangent
space we discussed earlier.
(2) Differentiable process:
A process is called differentiable if its phase space has
the structure of a differentiable manifold, and the change of state with time is described
by differentiable functions. Let M be the phase space. A point of this space is a deﬁned
state of the process. Assume that at instant t = 0 the process was in state x. Then at
another moment, the process t will be in another state. Denote this new state of the
process by gtx. We have deﬁned for each t a mapping gt
gt : M −→M.
This is called the transformation in time t, which takes the state at instance 0 to the
state at the instant t
g0 = id,
gt+s = gt · gs.
Let y = gsx be the state after time s, and the state z = gty again after time t. The
effect is the same as advancing x to time t + s, i.e.,
z = gt+sx.
Thus, we can deﬁne a one parameter transformation group.
Deﬁnition 7.4. The mapping family {gt}of set M to itself is called a one parameter
transformation group on ﬁled M, if ∀s, t ∈R satisﬁes:
gt+s = gt · gs,
g0 = I.
Deﬁnition 7.5. The set M and the corresponding one parameter transformation group
{gt} that maps M to itself compose (M, {gt}), which is called the phase ﬂow, where
set M is called the phase space, and its element is called the phase point.
(3) Diffeomorphism:
If there exists a 1−1 map f : U →V so that f and f −1 :
V →U are both differentiable, then f is said to be a diffeomorphism.
(4)
One parameter diffeomorphism groups:
The one parameter differmorphism
group {gt} on manifold M is a collection of mappings from the direct product R×M
to M:
g : R × M −→M,
g(t, x) = gt · x,
t ∈R, x ∈M
which satisﬁes:
1◦
g is a differentiable mapping.
2◦
∀t ∈R, gt : M →M is a differomorphism.
3◦
Family {gt, t ∈R} is one parameter transformation group for M.
Dynamical system: the autonomous differential equation deﬁned by a ﬁeld X is
the equation

1.7 Lie Derivative
103
d x(t)
d t
= X(x(t)),
x|t=0 = x0
(initial value).
The image of the mapping x(t) is called a phase space, and the graph of the map-
ping x(t) is called an integral curve. The integral curve lies in the direct product of
the time axis and the phase space, which is called M × R extended space. Such an
equation is called a dynamic system, whose phase ﬂow gt, M →M, {gt, t ∈R}
composes a group:
gt · gs = gt+s,
g0 = id,
g−t = {gt}−1.
Let X be a smooth vector ﬁeld on Rn. The solution curve through x0 is a differ-
entiable mapping t →x(t): I →Rn, where I is an interval in R and 0 ∈I, such
that
d x(t)
dt
= ˙x(t) = X(x(t)),
t ∈I,
x(0) = x0.
(7.1)
It can be represented by its components as
d xi(t)
dt
= Xi(x1(t), · · · , xn(t)),
t ∈I;
i = 1, · · · , n,
xi(0) = xi0,
where x(t) = (x1(t), · · · , xn(t)). It is well known that there is a unique differentiable
solution x(t, x0) for the above system, which depends differentiably on the initial
value x0 in some neighborhood.
The mapping φt
X from (some neighborhood of) Rn to itself is deﬁned by
φt
X(x0) = x(t, x0).
Suppose t is small enough, and is a diffeomorphism in (some neighborhood of) Rn.
It has the following properties:
1◦
φt1+t2
X
= φt1
X · φt2
X.
2◦
φ0
X = id.
3◦
φ−t
X = (φt
X)−1.
Thus, such a class {φt
X} of the mappings φt
X forms a group, called as a local 1-
parameter transformations group in Rn, or a local dynamics system in Rn, or a ﬂow
in Rn.
1.7.3 Lie Derivative and Contraction
Let ϕ : Rn →Rn be a diffeomorphism and Y ∈X(Rm) be a smooth vector ﬁeld on
Rn. The pullback ϕ∗Y of Y is a smooth vector ﬁeld on Rn, deﬁned by the formula
(ϕ∗Y )(x) = (Dϕ−1)(y)Y (y) = ϕ−1
∗(y)Y (y),
y = ϕ(x).
Deﬁnition 7.6. Let X and Y be two vector ﬁelds. The Lie derivative LXY of Y with
respect to X is deﬁned by
LXY = d
dt

φt∗
XY

t=0,
where φt
X is the ﬂow of X.

104
1. Preliminaries of Differentiable Manifolds
Theorem 7.7. Let X and Y be two vector ﬁelds. Then we have
1◦
(φt
XY )f = φt∗
X(Y φ−t∗
X f),
∀f ∈C∞(Rn).
2◦
d
dt(φt∗
Xf) = φt∗
X(Xf).
3◦
LXY = [X, Y ].
Proof. 1◦
By deﬁnition,
(φt∗
XY )f(x) = ⟨df(x), (φt∗
X · Y )(x)⟩= ⟨df(x), Dφ−t
X (y)Y (y)⟩

y = φt
X(x)

= ⟨(Dφ−t
X (y))′df(x), Y (y)⟩
= ⟨d(f ◦φ−1
X (y))′, Y (y)⟩
= ⟨d "f(y), Y (y)⟩
 "f = f ◦φt
X

= (Y "f)(y) = (Y "f)(φt
X(x))
= φt∗
X(Y "f)(x) = φt∗
X

Y f(φ−t
X (y))

(x)
= φt∗
X

Y (φ−t∗
X f)

(x).
2◦
The proof is as follows:
d
d t

φt∗
Xf

= d
d tf

φt
X(x)

=
n

i=1
∂f
∂xi Xi

φt
X(x)

= (Xf)

φt
X(x)

= φt∗
X(Xf).
3◦
The proof is as follows:
(LXY )f = d
dt

φt∗
XY

f

t=0 = d
dt

φt∗
X(Y · φ−t∗
X f)

t=0
=

φt∗
XXY · φ−t∗
X f −φt∗
XY φ−t∗
X Xf

t=0
= XY f −Y Xf = [X, Y ]f,
∀f.
Thus, we get
LXY = [X, Y ].
Therefore, the theorem is completed.
▲
By the equality 3◦, the Jacobi identity about the Poisson bracket { , } shows that
the operator LX is a { , }-derivative on the algebra X(Rn) with binary operator [ , ],
i.e.,
LX{X1, X2} = {LXX1, X2} + {X1, LXX2}.
Deﬁnition 7.8. ∀ω ∈Ωk(Rn), the Lie derivative LXω of ω with respect to a vector
ﬁeld X ∈X(Rn) is deﬁned by
LXω = d
dtφt∗
Xω

t=0 = lim
t→0
1
t

φt∗
Xω −ω

.

1.7 Lie Derivative
105
Theorem 7.9. The Lie derivative LX with respect to X ∈X(Rn) has the following
properties:
1◦
LXf = Xf =
n

i=1
Xi
∂f
∂xi , f ∈C∞(Rn), i.e., the Lie derivatives of a
function f with respect to X is the directional derivative in direction X(x).
2◦
LX is a Λ-derivative, i.e., LX is R-linear,
LX(αω1 + βω2) = αLXω1 + βLXω2,
LX(ω1 ∧ω2) = LXω1 ∧ω2 + ω1 ∧LXω2.
3◦
LXd = d LX.
Proof. 1◦We have d
d tφt∗
Xf = φt∗
X(Xf), and so
LXf = d
d t

t=0(φt∗
Xf) = (φt∗
XXf)

t=0 = Xf.
2◦
It is obvious that LX is R-linear,
LX(ω1 ∧ω2) =
d
d t

t=0φt∗
X(ω1 ∧ω2)
=
d
d t

t=0

φt∗
Xω1 ∧φt∗
Xω2

=
 d
d t

t=0φt∗
Xω1

∧ω2 + ω1 ∧d
d t

t=0φt∗
Xω2
= LXω1 ∧ω2 + ω1 ∧LXω2.
3◦
The proof is as follows:
LXdω =
d
d t

t=0φt∗
Xdω = d
d t

t=0dφt∗
Xω
= d d
d t

t=0φt∗
Xω = d LXω.
Therefore, the theorem is completed.
▲
Deﬁnition 7.10. Let X ∈X(Rn) and ω ∈Ωk(Rn). The contraction iXω of X and
ω is deﬁned by
iXω(ξ1, · · · , ξk−1) = ω(X(x), ξ1, · · · , ξk−1),
ξi ∈TkRn,
i = 1, · · · , k −1.
iXf = 0, for f ∈C∞(Rn) = Ω0(Rn). iX maps k-forms into (k −1)-forms, i.e.,
Ωk(Rn) −→Ωk−1(Rn).

106
1. Preliminaries of Differentiable Manifolds
Theorem 7.11. Let ω1, ω2 ∈Ωk(Rn), ω3 ∈Ωl(Rn). Then,
1◦
iX is a Λ-antiderivative, i.e., R-linear.
R-linear : iX(α1ω1 + α2ω2) = α1iXω1 + α2iXω2,
α1, α2 ∈R.
anti-derivative : iX(ω1 ∧ω3) = iXω1 ∧ω3 + (−1)kω1 ∧iXω3.
2◦
ifX+gY = fiX + giY , ∀f, g ∈C∞(Rn), X, Y ∈X(Rn).
3◦
iXdf = LXf, f ∈C∞(Rn).
4◦
LX = iXd + diX, (Cartan’s Magic formula).
5◦
LfX = fLX + df ∧iX.
Proof.
1◦
R-linearity of ix is evident.
iX1(ω1 ∧ω3)(ξ2, · · · , ξk+l−1)
= (ω1 ∧ω3)(X1(x), ξ2, · · · , ξk+l)
= (ω1 ∧ω3)(ξ1, ξ2, · · · , ξk+l)
(denote ξ1 = X1(x))
=

σ(1)<···<σ(k); σ(k+1)<···<σ(k+l)
ε(σ)ω1(ξσ(1), · · · , ξσ(k))ω3(ξσ(k+1), · · · , ξσ(k+l))
=
′

i∈{σ(1)···σ(k)}
+
′′

i∈{σ(k+1)···σ(k+l)}
.
In the ﬁrst part, it must be σ(1) = 1 since σ(1) < · · · < σ(k). Similarly, in the second
part, σ(k + 1) = 1.
Set
σ′ = {σ(2), · · · , σ(k), σ(k + 1), · · · , σ(k + l)},
σ′′ = {σ(1), · · · , σ(k), σ(k + 2), · · · , σ(k + l)}.
Then,
ε(σ) = ε(σ′),
if
i ∈{σ(1), · · · , σ(k)},
ε(σ) = (−1)kε(σ′′),
if
i ∈{σ(k + 1), · · · , σ(k + l)}.
Thus,

1.7 Lie Derivative
107
iX(ω1 ∧ω3)(ξ2, · · · , ξk+2)
=
′

σ(2)<···<σ(k), σ(k+1)<···<σ(k+l)
ε(σ′)ω1(ξ1, ξσ(2), · · · , ξσ(k))
· ω3(ξσ(k+1), · · · , ξσ(k+l))
+
′′

σ(1)<···<σ(k), σ(k+1)<···<σ(k+l)
(−1)kε(σ′′)ω1(ξσ(1), · · · , ξσ(k))
· ω3(ξ1, ξσ(k+2), · · · , ξσ(k+l))
=
′

σ′(1)<···<σ′(k), σ′(k−1)<···<σ′(k+l−1)
ε(σ′)(iXω1)(ξσ′(1), · · · , ξσ′(k−1))
· ω3(ξσ′(k), · · · , ξσ′(k+l−1))
+
′′

σ′′(1)<···<σ′′(k), σ′′(k+1)<···<σ′′(k+l−1)
(−1)kε(σ′′)ω1(ξσ′′(1), · · · , ξσ′′(k))(iXω3)
· (ξσ′′(k+1), · · · , ξσ′′(k+l−1))
=
(iXω1 ∧ω3)(ξ2, · · · , ξk+l) + (−1)k(ω1 ∧iXω3)(ξ2, · · · , ξk+l).
Thus, we get the equality
iX(ω1 ∧ω3) = iXω1 ∧ω3 + (−1)kω1 ∧iXω3.
2◦
The proof is as follows:
(ifX+gY ω)(ξ1, · · · , ξk−1)
= ω(fX + gY, ξ1, · · · , ξk−1)
= f(x)ω(X(x), ξ1, · · · , ξk−1) + g(x)ω(Y (x), ξ1, · · · , ξk−1)
= f(x)iXω(ξ1, · · · , ξk−1) + g(x)iY ω(ξ1, · · · , ξk−1)
= (f(x)iX + g(x)iY )(ξ1, · · · , ξk−1).
This is the equation 2◦.
3◦
iXdf = df(X) = Xf = LXf.
4◦
By induction with respect to k. k = 0. i.e., 3◦.
Suppose that 4◦holds good for k. Then for k + 1, ω can be written as a sum of
the forms like ω1 ∧df where ω1 ∈Ωk(Rn) and f ∈C∞(Rn). By linearity of LX,
without loss of generality we may assume ω = ω1 ∧df. Then,
LX(ω ∧df) = LXω ∧df + ω ∧LXdf
= (iXdω + diXω) ∧df + ω ∧dLXf.
On the other hand,

108
1. Preliminaries of Differentiable Manifolds
(iXd + diX)(ω ∧df)
= iXd(ω ∧df) + (diX)(ω ∧df)
= iX(dω ∧df) + d(iXω ∧df + (−1)kω ∧iXdf)
= iXdω ∧df + (−1)k+1dω ∧iXdf + diXω ∧df
+(−1)kdω ∧iXf + (−1)2kω ∧dLXf
= (iXd + diX)ω ∧df + ω ∧dLXf,
thus, LX(ω ∧df) = (iXd + diX)(ω ∧df), i.e.,
LX = iXd + diX.
5◦
The proof is as follows:
LfX = (difX + ifXd)ω
= d(fiXω) + fiXdω
= df ∧iXω + fdiXω + fiXdω
= (fLX + df ∧iX)ω,
so
LfX = fLX + df ∧iX.
Therefore, the theorem is completed.
▲
Every k-form ω on Rn can also be considered as a function on X k(Rn): X k(Rn)
→C∞(Rn), i.e.,
ω(X1, · · · , Xk)(x) = ω(x)(X1(x), · · · , Xk(x)),
Xi ∈X(Rn),
i = 1, · · · , k.
It is linear, skew-symmetric.
Theorem 7.12. Let ω ∈Ωk(Rn), Xi (i = 1, · · · , k) be vector ﬁelds on Rn. Then,
1◦(LXω)(X1, · · · , Xk) = LX(ω(X1, · · · , Xk))−
k

i=1
ω(X1, · · · , LXXi, · · · , Xk).
2◦dω(X0, · · · , Xk) =
k

i=0
(−1)iLXi(ω(X0, · · · , 
Xi, · · · , Xj, · · · , Xk)
+

i<j
(−1)i+jω(LXiXj, X0, · · · , 
Xi, · · · , 
Xj, · · · , Xk).
Proof.
1◦
By the deﬁnition of LX and the Theorem 7.7, since

1.7 Lie Derivative
109
(φt∗
Xω)(X1, · · · , Xk) = ω(φt
Xω)(φt
X∗X1, · · · , φt
X∗Xk)
= ω(φ−t∗
X X1, · · · , φ−t∗
X Xk)(φt
XX)
= φt∗
X(ω(φ−t∗
X X1, · · · , φ−t∗
X Xk)),
we have
(LXω)(X1, · · · , Xk) = d
d t

t=0(φt∗
Xω)(X1, · · · , Xk)
= d
d t

t=0

φt∗
Xω(φ−t∗
X X1, · · · , φ−t∗
X Xk)

= LX

ω(X1, · · · , Xk)

−
k

i=1
ω(X1, · · · , LXXi, · · · , Xk).
2◦
By induction with respect to k, k = 0 is evident:
df(X) = LXf,
f ∈C∞(Rn) = Ω0(Rn).
Suppose 2◦holds for k −1. Then for k, by 1◦,
dω(X0, X1, · · · , Xk) = (iX0dω)(X1, · · · , Xk)
= (LX0ω)(X1, · · · , Xk) −(diX0ω)(X1, · · · , Xk)
= LX0

ω(X1, · · · , Xk)

−
k

i=1
ω(X1, · · · , LX0Xi, · · · , Xk)
−(diX0ω)(X1, · · · , Xk),
where iX0ω ∈Ωk−1(Rn). By inductive hypothesis,
(diX0ω)(X1, · · · , Xk)
=
k

i=1
(−1)i−1LXi

iX0ω(X1, · · · , 
Xi, · · · , Xk)

+

1≤i≤j≤k
(−1)i+jiX0ω(LXiXj, X1, · · · , 
Xi, · · · , 
Xj, · · · , Xk)
=
k

i=1
(−1)i−1LXi

ω(X0, X1, · · · , 
Xi, · · · , Xk)

+

1≤i≤j≤k
(−1)i+j−1ω(LXiXj, X0, · · · , 
Xi, · · · , 
Xj, · · · , Xk).
Thus, we get

110
1. Preliminaries of Differentiable Manifolds
d ω(X0, · · · , Xk)
= LX0

ω(X1, · · · , Xk)

+
k

j=1
(−1)jω(X1, · · · , LX0Xj, · · · , Xk)
+
k

i=1
(−1)iLXi

ω(X0, · · · , 
Xi, · · · , Xk)

+

1≤i<j<k
(−1)i+jω(LXiXj, X0, · · · , 
Xi, · · · , 
Xj, · · · , Xk)
=
k

i=0
(−1)iLXi

ω(X0, · · · , 
Xi, · · · , Xk)

+

i<j
(−1)i+jω(LXiXj, X0, · · · , 
Xi, · · · , 
Xj, · · · , Xk).
Finally , the theorem is completed.
▲

Bibliography
[AA88] D.V. Anosov and V.I. Arnold: Dynamical Systems I. Springer, Berlin, (1988).
[AA89] V. I. Arnold and A. Avez: Ergodic Problems of Classical Mechanics. Addison-Wesley
and Benjamin Cummings, New York, (1989).
[Abd99] S. S. Abdullaev: A new integration method of Hamiltonian systems by symplectic
maps. J. Phys. A: Math. Gen., 32(15):2745–2766, (1999).
[Abd02] S. S. Abdullaev: The Hamilton–Jacobi method and Hamiltonian maps. J. Phys. A:
Math. Gen., 35(12):2811–2832, (2002).
[AKN78] V. I. Arnold, V. V. Kozlov, and A. I. Neishtadt: Mathematical Aspects of Classical
and Celestial Mechanics. Springer, Berlin, Second edition, (1978).
[AM78] R. Abraham and J. E. Marsden: Foundations of Mechanics. Addison-Wesley, Reading,
MA,Second edition, (1978).
[AMR88] R. Abraham, J. E. Marsden, and T. Ratiu: Manifolds, Tensor Analysis, and Applica-
tions. AMS 75. Springer-Verlag, Berlin, Second edition, (1988).
[AN90] A. I. Arnold and S.P. Novikov: Dynamical System IV. Springer Verlag, Heidelberg,
(1990).
[AP92] D. K. Arrowsmith and C. M. Place: Dynamical Systems: Differential Equations, Maps,
and Chaotic Behavior. Chapman & Hall, New York, (1992).
[Arn78] V. I. Arnold: Ordinary Differential Equations. The MIT Press, New York (1978).
[Arn88] V. I. Arnold: Geometrical Methods in the Theory of Ordinary Differential Equations.
Springer-Verlag, Berlin, (1988).
[Arn89] V. I. Arnold:
Mathematical Methods of Classical Mechanics.
Berlin Heidelberg:
Springer-Verlag, GTM 60, Berlin ,Second edition, (1989).
[Ber00] R. Berndt: An Introduction to Symplectic Geometry. AMS Providence, Rhode Island,
(2000).
[Bir23] G. D. Birkhoff: Relativity and Modern Physics. Harvard Univ. Press, Cambridge,
Mass., Second edition, (1923).
[BK89] G.W. Bluman and S. Kumei:
Symmetries and Differential Equations. AMS 81.
Springer-Verlag, New York, (1989).
[Car65] C. Carathe’odory: Calculus of Variation and Partial Differential Equations of First
Order, Vol.1. Holden-Day, San Franscisco, (1965).
[Car70] H. Cartan: Differential Forms. Houghton-Mifﬂin, Boston, (1970).
[Che53] S. S. Chern: Differential Manifolds. Lecture notes. University of Chicago, (1953).
[Ede85] D. G. B Edelen: Applied Exterior Calculus. John Wiley and Sons, New York, First
edition, (1985).
[Fla] H. Flanders: Differential Forms. Academie Press, New York, Second edition. (1963).
[GS84] V. Guillemin and S. Sternberg: Symplectic Techniques in Physics. Cambridge Univer-
sity Press, Cambridge, (1984).
[Lan95] S. Lang: Differential and Riemannian Manifolds. Springer-Verlag, New York, (1995).
[LM87] P. Libermann and C.M. Marle: Symplectic Geometry and Analytical Mechanics. Rei-
del Pub. Company, Boston, First edition, (1987).
[Mac70] S. MacLanc: Hamiltonian mechanics and geometry. Amer. Math. Mon., 77(6):570–
586, (1970).

112
Bibliography
[Poi93] H. Poincar´e: Les M´ethodes Nouvelles de la M´ecanique C´eleste, Tome II. Gauthier-
Villars, Paris, Second edition, (1893).
[Poi99] H. Poincar´e: Les M´ethodes Nouvelles de la M´ecanique C´eleste. Tome III. Gauthiers-
Villars, Paris, Second edition, (1899).
[Sc77] M. Schreiber: Differential Forms. Springer-Verlag, New York, First edition, (1977).
[Sie43] C.L. Siegel: Symplectic geometry. Amer.and math. J. Math, 65:1–86, (1943).
[Spi68] M. Spivak: Calculus on Manifolds. The Benjamin/Cummings publishing company,
London, New York, First edition, (1968).
[Tre75] F. Treves: Pseodo-Differential Operator. Acad. Press, New York, First edition, (1975).
[Wei77] A. Weinstein: Lectures on symplectic manifolds. In CBMS Regional Conference, 29.
American Mathematical Society, Providence, RI, (1977).
[Wes81] C. Von. Westenholz: Differential Forms in Mathmatical Physics. North-Holland,
Amsterdam, Second edition, (1981).

Chapter 2.
Symplectic Algebra and Geometry
Preliminaries
In order to deeply understand Hamiltonian mechanics, it is necessary to know basic
concepts of symplectic algebra and geometry.
2.1 Symplectic Algebra and Orthogonal Algebra
Symplectic algebra and orthogonal algebra have several similar concepts. First, we
start with the bilinear form.
2.1.1 Bilinear Form
1.
Bilinear form
Deﬁnition 1.1 (Bilinear Form). Let Fn be an n-dimensional linear space. A bilinear
form on Fn is a mapping ϕ : Fn × Fn →Fn that satisﬁes:
1◦
ϕ(αu + βv, y) = αϕ(u, y) + βϕ(v, y).
2◦
ϕ(x, αu + βv) = αϕ(x, u) + βϕ(x, v), ∀α, β ∈F, u, v, x, y ∈Fn.
It is obvious that there exists a 1-1 correspondence between the matrix space M(n, F)
and the space of the bilinear form on Fn. As a matter of fact, given a matrix A ∈
M(n, F), there is a bilinear form ϕA on Fn corresponding to
ϕA(x, y) = x′Ay =
n

i,j=1
aijxiyj.
Conversely, given a bilinear form on Fn, there is also a matrix A ∈M(n, F) corre-
sponding to
A = Aϕ = [aij] = [ϕ(ei, ej)] ∈M(n, F),
such that ϕ(x, y) = x′Ay, where e1, e2, · · · is a set of basis of Fn.
Deﬁnition 1.2 (Symmetric or Antisymmetric). A bilinear form ϕ = ϕA is called
symmetric or antisymmetric if
ϕ(x, y) = ϕ(y, x)
or
ϕ(x, y) = −ϕ(y, x),
∀x, y ∈Fn,
i.e., A′ = A, A′ = −A, respectively.

114
2. Symplectic Algebra and Geometry Preliminaries
Deﬁnition 1.3 (Conformally Symmetric). A bilinear form A is called conformally
symmetric if
ϕ(x, y) = 0 ⇐⇒ϕ(y, x) = 0,
i.e.,
{(x, y) ∈Fn × Fn | ϕ(x, y) = 0} = {(x, y) ∈Fn × Fn | ϕ(y, x) = 0}.
A matrix A is called conformally symmetric if x′Ay = 0 ⇔x′A′y = 0,
which
is equivalent to saying that ϕA is conformally symmetric.
ϕ is a non-degenerate map (or non-singular) if ∃x ̸= 0 s.t. ϕ(x, y) = 0, ∀y ∈Fn.
Proposition 1.4. It is evident that the following claims are equivalent:
1◦
ϕA is non-degenerate.
2◦
If ∀y ∈Fn, ϕA(x, y) = 0, then x = 0.
3◦
A is non-degenerate.
Deﬁnition 1.5 (Conformally Identical). A bilinear form ϕA is called conformally
identical to ϕB if
{(x, y) ∈Fn × Fn | ϕA(x, y) = 0} = {(x, y) ∈Fn × Fn | ϕB(y, x) = 0}.
Proposition 1.6. The following claims are equivalent:
1◦
ϕA is conformally identical to ϕB.
2◦
ϕA(x, y) = 0, iff ϕB(x, y) = 0.
3◦
x′Ay = 0, iff x′By = 0.
4◦
∃μ ∈F, μ ̸= 0, such that A = μB.
The equivalence of 1◦, 2◦and 3◦is trivial. Next, we prove the equivalence be-
tween 1◦and 4◦.
Theorem 1.7. {(x, y) ∈Fn × Fn | ϕA(x, y) = 0} = {(x, y) ∈Fn × Fn |
ϕB(y, x) = 0},
iff ∃μ ∈F, μ ̸= 0, such that A = μB.
Proof. The sufﬁciency is trivial. We only need to prove the necessity. Without loss of
generality, we can assume F = R. Then, we have
ker(A) = {y ∈Rn | Ay = 0} = {y ∈Rn | x′Ay = 0, ∀x ∈Rn},
ker(B) = {y ∈Rn | By = 0} = {y ∈Rn | x′By = 0, ∀x ∈Rn}.
By our assumption, x′Ay = 0 ⇔x′By = 0. Hence, ker(A) = ker(B), denoted as V ,
i.e., V = ker(A) = ker(B). Then ∀v ∈Rn,
Av ̸= 0 ⇐⇒Bv ̸= 0.
Since x′Ay = 0 ⇔x′By = 0, {Av}⊥= {Bv}⊥, and so

2.1 Symplectic Algebra and Orthogonal Algebra
115
{Av} = {Bv}.
This shows that there exists μ(v) ∈R, μ ̸= 0 such that Av = μ(v)Bv.
Next, we show μ(v) is a non-zero constant.
Take a basis of Rn = {v1, · · · , vr, vr+1, · · · , vn}, such that
{vr+1, · · · , vn} = V = ker(A) = ker(B).
Thus, Avi ̸= 0 (i = 1, · · · , r), A(v1 + v2 + · · · + vr) ̸= 0.
The above shows that there exist μ1, · · · , μr, μ (all of which are no-zero), such
that
Avi = μiBvi,
i = 1, · · · , r,
A(v1 + v2 + · · · + vr) = μB(v1 + v2 + · · · + vr).
Then,
μ1Bv1 + · · · + μrBvr = μB(v1 + v2 + · · · + vr)
= μBv1 + · · · + μBvr.
After manipulation, we get (μ1 −μ)Bv1 + · · · + (μr −μ)Bvr = 0, i.e.,
B ((μ1 −μ)v1 + · · · + (μr −μ)vr) = 0.
Since (μ1 −μ)v1 + · · · + (μr −μ)vr ∈{v1, · · · , vr}, it must be
(μ1 −μ)v1 + · · · + (μr −μ)vr = 0.
Then by the linear independence of v1, · · · , vr, we have
μ = μ1 = · · · = μr.
Therefore,
Avi = μBvi,
i = 1, · · · , r.
Similarly for i = r +1, · · · , n, Avi = 0 = μBvi. Thus, we have obtained A = μB. ▲
From Theorem 1.7, we can easily derive the following theorems.
Theorem 1.8. ϕA is conformally symmetric, iff ∃μ ∈F, μ ̸= 0, such that A′ = μA.
Theorem 1.9. A ∈M(n, R) is conformally symmetric, iff A′ = ±A, i.e., A is sym-
metric or antisymmetric.
2.
Quadratic forms induced by bilinear form
Given a bilinear form ϕA(x, y) =
n

i,j
aijxiyj, we can get a quadratic bilinear form
ϕA(x, x) =
n

i,j
aijxixj. Obviously, we have the following propositions:

116
2. Symplectic Algebra and Geometry Preliminaries
Proposition 1.10. ϕA(x + y, x + y) −ϕA(x, x) −ϕA(y, y) = ϕA(x, y) + ϕA(y, x).
Proposition 1.11. ϕA is antisymmetric, iff ϕA(x, x) = 0, ∀x ∈Fn.
Proposition 1.12. ∀x ∈Fn, ϕA(x, x) = ϕB(x, x), iff A + A′ = B + B′.
Proposition 1.13. If A = A′, B = B′, then ∀x ∈Fn, ϕA(x, x) = ϕB(x, x) ⇔
A = B.
Proposition 1.14. The following assertions are equivalent :
1◦
ϕA = ϕB.
2◦
(
(x, y) ∈Fn ×Fn | ϕA(x, y) = 1
)
=
(
(x, y) ∈Fn ×Fn | ϕB(x, y) = 1
)
.
3◦
ϕA(x, y) = 1 ⇔ϕB(x, y) = 1.
4◦
x′Ay = 1 ⇔x′By = 1.
2.1.2 Sesquilinear Form
1.
Sesquilinear form
In a complex ﬁeld C, there is an automorphism
C ∋z = x + i y →z = x −i y ∈C,
such that
z1 · z2 = z1 · z2,
z1 + z2 = z1 + z2.
This leads to a new kind of binary forms.
Deﬁnition 1.15 (Sesquilinear). A sesquilinear form on Cn is a mapping φ : Cn ×
Cn →C, such that for all u, v, x ∈Cn, α, β ∈C, we have
1◦
φ(αu + βv, x) = α φ(u, x) + β φ(v, x).
2◦
φ(x, αu + βv) = α φ(x, u) + β φ(x, v).
Similarly, there exists a 1-1 correspondence between the complex matrix space M(n, C)
and the space of sesquilinear forms on Cn.
In fact, a complex matrix A ∈M(n, C) has a natural correspondence to a
sesquilinear form φA, which satisﬁes
φA(x, y) = x∗Ay =
n

i,j
aijxiyj.
Conversely, a sequilinear form φ has a natural correspondence to a complex matrix
A = Aφ = [aij] = [φ(ei, ej)] ∈M(n, C),
which satisﬁes φ(x, y) = x∗Aφy.
Deﬁnition 1.16 (Hermitian). φ = φA is Hermitian or anti-Hermitian, if ∀x, y ∈
Cn, φ(x, y) =φ(y, x) or φ(x, y) = −φ(y, x), i.e., A∗= A or A∗= −A. Such a
complex matrix A is called Hermitian or anti-Hermitian.

2.1 Symplectic Algebra and Orthogonal Algebra
117
Deﬁnition 1.17 (Conformally Hermitian). φ = φA is called conformally Hermi-
tian, if φ(x, y) = 0 ⇔φ(y, x) = 0, then
{(x, y) ∈Cn × Cn | φ(x, y) = 0} = {(x, y) ∈Cn × Cn | φ(y, x) = 0},
or
x∗Ay = 0 ⇐⇒x∗A∗y = 0.
The matrix A satisfying the above condition is called conformally Hermitian.
φ = φA is non-degenerate iff ∄x ∈Cn, x ̸= 0, such that φA(x, y) = 0,
∀y ∈
Cn; or iff ∀y ∈Cn, φ(x, y) = 0, then x = 0; or iff A is non-degenerate.
2.
Hermitian forms induced by sesquilinear forms
From a sesquilinear form on Cn, φA(x, y) = x∗Ay =
n

i,j
aijxiyj, we can induce a
correspondent Hermitian form on Cn,
φA(x, x) = x∗Ax =
n

i,j
aijxixj.
If A is Hermitian, then ∀x ∈Cn, φA(x, x) ∈R.
Remark 1.18. Hermitian forms have properties similar to Propositions 1.10 – 1.14,
and Theorems 1.7 – 1.8.
Remark 1.19. Hermitian analogue of Theorem 1.9 as follows.
Theorem 1.20. A ∈M(n, C) is conformally Hermitian, iff ∃μ ∈C, |μ| = 1, such
that A∗= μA; or iff ∃θ ∈R, such that A∗=eiθA.
Proof. A = A∗∗= μA∗= μμA = |μ|2A. Thus, |μ|2 = 1.
▲
2.1.3 Scalar Product, Hermitian Product
A scalar product on Fn is a non-degenerate conformally symmetric bilinear form
φG(x, y), where G′ = ±G.
Symmetric products in Rn : (x, y)S = ϕS(x, y) = x′Sy, S′ = S, |S| ̸= 0.
Anti-symmetric product in Rn :[x, y]K = ϕK(x, y) = x′Ky, K′ = −K, |K| ̸=
0.
Remark 1.21. There does not exist any anti-symmetric scalar product in F2n+1 since
|K| = 0 if K′ = −K.
Hermitian products in Cn are non-degenerate Hermitian forms in Cn, i.e.,
⟨x, y⟩= x∗Gy = φG(x, y),
G∗= G,
|G| ̸= 0.
Typical Examples are given below:

118
2. Symplectic Algebra and Geometry Preliminaries
Example 1.22 (Symmetric case). Euclidean scalar product (Euclidean form) in Rn:
(x, y) = (x, y)I = x′y =
n

i=1
xiyi,
I′ = I.
This induces a Euclidean length measure |x|2 = (x, x) =
n

i=1
x2
i .
Example 1.23 (Anti-symmetrical case). Standard symplectic scalar product (sym-
plectic form) in R2n:
[x, y] = [x, y]J = x′Jy =
n

i=1
(xiyn+i −xn+iyi),
where
J =
 
0
In
−In
0
!
= J2n,
J′ = J−1 = −J.
As n = 1, we have
[x, y] = x1y2 −x2y1 =

x1
y1
x2
y2
 ,
which represents the oriented area of the parallelogram formed by the vector x, y in
R2 (see the image below).
x
y
(x1, y1)
(x2, y2)
6
-
O

:
For general n, we get
[x, y] = x′Jy =
n

i=1

xi
yi
xn+i
yn+i

which represents a sum of oriented areas of the parallelograms formed by projecting
vectors x, y ∈R2n to the (xi, xn+i) coordinate planes.
Remark 1.24 (Pfafﬁan theorem). For any n, there exists a polynomial Pn(xij) with
integer coefﬁcients in variables xij(i < j) such that
det K = det [kij] = [Pn(kij)]2 ,
∀anti-symmetric matrix K.
Example 1.25 (Hermitian case). Unitary product in Cn:
⟨w, z⟩= ⟨w, z⟩I = w∗Iz = w∗z,
w, z ∈Cn, I∗= I,
⟨w, z⟩induces ∥z∥= z∗z, which is the Euclidean length measure in Cn.

2.1 Symplectic Algebra and Orthogonal Algebra
119
2.1.4 Invariant Groups for Scalar Products
This topic is discussed in detail in books[Wey39,Wey40,Art57].
General linear group: GL(n, F)={A ∈M(n, F) | detA ̸= 0}.
Special linear group: SL(n, F)={A ∈GL(n, F) | detA=1}.
Orthogonal group: invariant group for the Euclidean scalar product (x, y)=ϕI(x, y) =
x′y,
O(n, F) = {A ∈GL(n, F) | (Ax, Ay) = (x, y), ∀x, y ∈Fn}.
From deﬁnition, we have
A ∈O(n, F) ⇐⇒A′IA = A′A = I.
In particular, we denote O(n, R) as O(n), i.e., O(n, R) ≡O(n).
Symplectic group: invariant group for the anti-symmetric scalar product [x, y] =
ϕJ(x, y) = x′Jy,
Sp(2n, F) =
(
A ∈GL(2n, F) | [Ax, Ay] = [x, y], ∀x, y ∈F2n)
.
From deﬁnition, we have
A ∈Sp(n, F) ⇐⇒¯A′JA = J.
We denote Sp(n, F) ≡Sp(n).
Unitary group: invariant group for the Hermitian scalar product ⟨x, y⟩=x∗y.
U(n, C) =
(
A ∈GL(n, C) | ⟨Ax, Ay⟩= ⟨x, y⟩, ∀x, y ∈Cn)
.
From deﬁnition, we have
A ∈U(n, C) ⇐⇒A∗IA = I.
Similarly, we denote U(n, C) ≡U(n).
Invariant Group for Scalar Product ϕG, φG.
Here:
ϕG(x, y) = x′Gy,
G′ = ±G, |G| ̸= 0,
φG(x, y) = x∗Gy,
G∗= G, |G| ̸= 0.
The invariant group for ϕG is
G(G, n, F) =
(
A ∈GL(n, F) | ϕG(Ax, Ay) = ϕG(x, y), ∀x, y ∈Fn)
=
(
A ∈GL(n, C) | A′GA = G}
=
(
A ∈GL(n, C) | A−1 = G−1A′G
)
.
The symmetric case G = S, S′ = S, ϕS(x, y) = (x, y)S = x′Sy, where G is
called an S-orthogonal group.

120
2. Symplectic Algebra and Geometry Preliminaries
O(S, n, F) = G(S, n, F)
=
(
A ∈GL(n, F) | (Ax, Ay)S = (x, y)S, ∀x, y ∈Fn)
=
(
A ∈GL(n, F) | A′SA = S}
=
(
A ∈GL(n, F) | A−1 = S−1A′S
)
.
Special case: O(¯I, n, F) ≡O(n, F).
Anti-symmetrical case: G = K, K′ = −K, ϕK(x, y) = [x, y]K = x′Ky, where
G is called a K-symplectic group.
Sp(K, n, F) = G(K, 2n, F)
=
(
A ∈GL(2n, F) | [Ax, Ay]K = [x, y]K, ∀x, y ∈F2n)
=
(
A ∈GL(2n, F) | A′KA = K
)
=
(
A ∈GL(2n, F) | A−1 = K−1A′K
)
.
Special case: Sp(J, 2n, F) ≡Sp(2n, F).
Hermitian case:
G = H ∈M(n, C), H∗= H, |H| ̸= 0, φH(x, y) = ⟨x, y⟩H = x∗Hy,
U(H, n, C) =
(
A ∈GL(n, C) | ⟨Ax, Ay⟩H = ⟨x, y⟩H, ∀x, y ∈Cn)
=
(
A ∈GL(n, C) | A∗HA = H
)
=
(
A ∈GL(n, F) | A−1 = H−1A∗H
)
.
Special case: U(I, n, C) ≡U(n, C) ≡U(n).
Conformally Invariant Group for scalar Product ϕG.
CG(G, n, F) =
(
A ∈GL(n, F) | ϕG(Ax, Ay) = 0 ⇐⇒ϕG(x, y) = 0
)
=
(
A ∈GL(n, F) | ∃μ ∈F, μ ̸= 0, such that A′GA = μG
)
=
(
A ∈GL(n, F) | ∃μ ∈F, μ−1 ̸= 0, A−1 = μ−1G−1A′G
)
.
When G = S, S′ = S, we denote CG(S, n, F) as CO(S, n, F).
When G = K, K′ = −K, we denote CG(K, n, F) as CSp(K, n, F).
When G = H, H∗= H, we have
CU(H, n, C) =
(
A ∈GL(n, C) | ⟨Ax, Ay⟩H = 0 ⇐⇒⟨x, y⟩H = 0
)
=
(
A ∈GL(n, C) | ∃μ ∈C, μ ̸= 0, such that A∗HA = μH
)
=
(
A ∈GL(n, C) | ∃μ ∈C, μ ̸= 0, A−1 = μ−1H−1A∗H
)
.

2.1 Symplectic Algebra and Orthogonal Algebra
121
2.1.5 Real Representation of Complex Vector Space
Consider a mapping from Cn to R2n ρ : z = x + i y →ρ(z) = [x, y]′, z ∈
Cn, x, y ∈Rn. Evidently ρ : Cn →R2n is injective, and it satisﬁes the following
properties:
Property 1.26.
1◦
ρ(z + w) = ρ(z) + ρ(w),
∀z, w ∈Cn.
2◦
ρ(αz) = αρ(z),
∀α ∈R.
3◦
ρ(iz) = ρ(−y + ix) =
 −y
x
!
=
 0
−I
I
0
!  x
y
!
= −Jρ(z).
4◦
ρ((α + iβ)z) = (αI −βJ)ρ(z),
α + iβ ∈C.
5◦
ρ(0) = 0 ∈R2n, 0 ∈Cn.
For C = A + iB ∈M(n, C), set R(C) =
 A
−B
B
A
!
∈M(2n, R).Similarly,
R : C →R(C), M(n, C) →M(2n, R) is injective.
Assume C = A + iB ∈M(n, C), w = Cz. Then,
w = u + iv = (A + iB)(x + iy) = (Ax −By) + i(Bx + Ay),
i.e.,
 u
v
!
=
 A
−B
B
A
!  x
y
!
,
or
ρ(w) = R(C)ρ(z) = ρ(Cz).
Analogously, R satisﬁes the following properties:
Property 1.27.
1◦
R(On) = O2n, On ∈M(n, C).
2◦
R(In) = I2n, In ∈M(n, C).
3◦
R(αC) = αR(C), ∀α ∈R.
4◦
R( i C) = R( iA −B) =
 −B
−A
A
−B
!
= −JR(C).
5◦
R(C1 + C2) = R(C1) + R(C2), ∀C1, C2 ∈M(n, C).
6◦
R(C1 · C2) = R(C1)R(C2).
C invertible ⇐⇒R(C) invertible.
The last assertion follows from the theorem below.
Theorem 1.28.
det(A + iB) ̸= 0 ⇐⇒

A
−B
B
A
 ̸= 0.

122
2. Symplectic Algebra and Geometry Preliminaries
Real Representation of Unitary Group:
If det(H) ̸= 0, H = P + iQ ∈M(n, C) is Hermitian, iff
P ′ = P,
Q′ = −Q.
For w = u + iv, z = x + iy ∈Cn, deﬁne⟨w, z⟩H = w∗Hz.
w∗Hz = (u + iv)∗H(x + iy)
= (u + iv)∗(P + iQ)(x + iy)
= (u′, v′)
 P
−Q
Q
P
!  x
y
!
+ i(u′, v′)
 
Q
P
−P
Q
!  x
y
!
.
The above equation shows that the Hermitian scalar product of z and w, ⟨w, z⟩H
consists of two parts: its real part is a Euclidean scalar product in R2n (whose measure
is a symmetric matrix S), denoted by the round bracket and its imaginary part can be
taken as a new scalar product in R2n (whose measure is an anti-symmetric matrix K),
denoted by the square bracket. Therefore, we have ⟨w, z⟩H=(W, Z)S + i [W, Z]K,
where
W = ρ(w) =
 u
v
!
,
Z = ρ(z) =
 x
y
!
∈R2n,
H = P + i Q,
P ′ = P,
Q′ = −Q, S = S′ =
 P
−Q
Q
P
!
,
K = −K′ =
 
Q
P
−P
Q
!
.
Let T = R(C) = R(A + iB). Then,
⟨w, z⟩H = ⟨Cw, Cz⟩H ⇐⇒(W, Z)S + i [W, Z]K = (TW, TZ)S + i [TW, TZ]K.
From this, we can derive the following equivalent conditions:
Proposition 1.29.
1◦
U(H, n, C) ∋C = A + i B
=
(
C ∈GL(n, C) | ⟨Cw, Cz⟩H = ⟨w, z⟩H, ∀w, z ∈Cn)
.
2◦
T =
 A
−B
B
A
!
, det T ̸= 0,
(W, Z)S = (TW, TZ)S,
[W, Z]K = [TW, TZ]K.
3◦
T ∈GL(n, C), T ∈O(S, 2n, R) ∩Sp(K, 2n, R), where K = SJ.
4◦
TJ = JT, det T ̸= 0, and T ′ST = S, T ′SJT = SJ.

2.1 Symplectic Algebra and Orthogonal Algebra
123
Hence, GL(n, C) is identiﬁed with its real image GL(n, R) = {T ∈GL(2n, R) |
TJ = JT}, and U(H, n, C) is identiﬁed with its real image in GL(2n, R).
Since H = P + i Q is non-degenerate, and S = R(H), K = SJ are also non-
degenerate, we have: if TJ = JT,
T ′ST = S, then T ′SJT = T ′STJ = SJ; if
TJ = JT and T ′SJT = SJ, then T ′ST = T ′SJ(−J)T = −T ′SJTJ = −SJ2 =
S; if T ′ST = S and T ′SJT = SJ, then |T|2 = 1, T invertible, ST = T ′−1S.
Hence, if SJT = T ′−1SJ = STJ, then JT = TJ.
Therefore, we have
U(H, n, C) = GL(n, C) ∩O(S, 2n, R) ∩Sp(K, 2n, R)
= GL(n, C) ∩O(S, 2n, R)
= GL(n, C) ∩Sp(K, 2n, R)
= O(S, 2n, R) ∩Sp(K, 2n, R),
where H = P + iQ, P ′ = P, Q′ = −Q, S = R(H), K = SJ, |H| ̸= 0.
In particular, if H = I, S = I2n, K = J2n, then
U(n, C) = GL(n, C) ∩O(2n, R) ∩Sp(2n, R)
= GL(n, C) ∩O(2n, R)
= GL(n, C) ∩Sp(2n, R)
= O(2n, R) ∩Sp(2n, R).
2.1.6 Complexiﬁcation of Real Vector Space and Real Linear
Transformation
In a complex vector space V , we not only have the additive operator, but also the scalar
multiplication by complex numbers: for u ∈V, α+iβ ∈C, then (α+iβ)u ∈V . This
can be realized by a scalar multiplication by real numbers u ∈V, α ∈R ⇔αu ∈V
plus a single scalar multiplication by an imaginary unit i, i: u ∈V ⇔iu ∈V , which
can be seen as an operator
l : V −→V,
u −→i u = l(u).
l is a real linear transformation of V , i.e.,
l(αu + βv) = αl(u) + βl(v),
u, v ∈V,
α, β ∈R.
Moreover, a complex linear transformation T of V satisﬁes:
the additive property:
T(u + v) = T(u) + T(v),
the multiplication property:
T((α + i β)u) = (α + i β)T(u).
The latter is simply the commutativity of complex linear transformation and complex
scalar multiplication, which can be realized by

124
2. Symplectic Algebra and Geometry Preliminaries
T(i u) = i T(u) ∼Tl = lT.
Let
L(V, R)
= {T | T(u + v) = T(u) + T(v), T(αu) = αT(u), ∀u, v ∈V, α ∈R},
L(V, C)
= {T | T(u + v) = T(u) + T(v), T((α + i β)u)
= (α + iβ)T(u),
∀u, v ∈V, α, β ∈R}.
Evidently, T ∈L(V, C) ⇔iff T ∈L(V, R) and T(i u) = i T(u). Thus, the
operator l satisﬁes
l ∈L(V, R),
i2 = −1,
and
T ∈L(V, C)
iff
T ∈L(V, R),
and
Tl = lT.
These observations form the basis for the following deﬁnitions and the method of
complexiﬁcation of real vector space.
Deﬁnition 1.30. A real vector space V = V (R) is complexiﬁable if there exists an
operator l in L(V, R) such that l2 = −I.
We can easily see that V is complexiﬁable iff dimV (R) = 2n. This is because the
operator equation l2 = −I in L(V, R) corresponds to the matrix equation X2 = −I
in M(m, R), m =dimR(V ), which has no real solution for m = 2n + 1. (Since
from X2 = −I it follows that all eigenvalues of X are ±i, while for m = 2n + 1,
X ∈M(m, R) has at least one real eigenvalue.) When m = 2n, there is a special
solution
X = ±J,
(±J)2 = −I.
If we introduce an isomorphism J on R2n, which satisﬁes J2 = −I, then we
say that R2n is equipped with the complex structure. Hence, we can deﬁne operation
(a + ib)u = au + bJu, and R2n becomes the complex n-dimensional space. Cn is
called R2n complexiﬁable.
2.1.7 Lie Algebra for GL(n, F)
1.
Lie algebra
Deﬁnition 1.31. For B1, B2 ∈M(n, F), we deﬁne a commutator of B1, B2 as fol-
lows:
{B1, B2} = B1B2 −B2B1,
which satisﬁes the following properties:
1◦
{B1, B2} = −{B2, B1}.
2◦
{B1, {B2, B3}} + {B2, {B3, B1}} + {B3, {B1, B2}} = 0.
The equation 2◦is called Jacobi identity.

2.1 Symplectic Algebra and Orthogonal Algebra
125
Deﬁnition 1.32. A Lie algebra is a vector space equipped with a binary operation
L × L →L, which satisﬁes the Jacobi identity.
Hence, M(n, F), equipped with the above commutator, becomes a Lie algebra,
denoted as gl(n, F). Since gl(n, F) is the tangent vector space to GL(n, F) at I,
gl(n, F) is called Lie algebra of the Lie group GL(n, F).
Deﬁnition 1.33. The Lie algebra of the Lie group SL(n, F) is deﬁned as follows:
sl(n, F) = {B ∈gl(n, F) | trB = 0}.
Remark 1.34. If trB1 = trB2 = 0, then tr{B1, B2} = tr(B1B2 −B2B1) = 0.
Therefore, sl(n, F) is closed under { , }. As the matter of fact, for any A, B, tr{A, B}
is always equal to 0.
Deﬁnition 1.35. The Lie algebra of the Lie group G(G, n, F) is deﬁned as follows:
g(G, n, F) = {B ∈gl(n, F)|B′G + GB = 0}.
Remark 1.36. g(G, n, F) is closed under { , }, i.e.,
{B1, B2} ∈g(G, n, F),
∀B1, B2 ∈g(G, n, F).
If B′
iG = −GBi (i = 1, 2), then
{B1, B2}′G = (B1B2 −B2B1)′G
= (B′
2B′
1 −B′
1B′
2)G
= B′
2B′
1G −B′
1B′
2G
= B′
2(−GB1) −B′
1(−GB2)
= G(B2B1 −B1B2)
= −G{B1, B2}.
2.
Exponential matrix transform
Deﬁnition 1.37. For B ∈M(n, C), deﬁne
exp(B) =
∞

k=0
1
k!Bk = lim
n→∞
n

k=0
1
k!Bk.
Take the Chebyshev matrix norm
||B|| = max
i
m

j=1
|bij|.
Then, |bij| ≤||B||, ||Bk|| ≤||B||k. Hence, the n2 series
* ∞

k=0
1
k!Bk
+
ij
are always
uniformly convergent, and convergent uniformly if ||B|| ≤β, ∀β > 0.

126
2. Symplectic Algebra and Geometry Preliminaries
Proposition 1.38. We have the following results:
1◦
exp (T −1BT) = T −1 exp (B)T, ∀T ∈GL(n, C).
2◦
If B has eigenvalues λ1, · · · , λn (with multiplicities), then exp B has the
eigenvalues exp λ1, · · · , exp λn.
3◦
det (exp B) = exp (tr B), tr B =
n

i=1
bii.
4◦
exp B ∈GL(n, C), ∀B ∈M(n, C).
5◦
If B1, B2 ∈M(n, C), B1B2 = B2B1, then
exp (B1 + B2) = exp B1 · exp B2 = exp B2 · exp B1.
6◦
exp B′ = (exp B)′, exp B = exp B.
7◦
∀t ∈R, if exp (tB) ∈GL(n, C), then
exp ((t1 + t2)B) = exp (t1B) · exp (t2B),
exp (0 · B) = I,
exp (−tB) = (exp (tB))−1.
Therefore, the mapping t ∈R →exp (tB) ∈GL(n, C) for a given B is a group
homomorphism of the additive group R into the multiplicative group GL(n, C).
Theorem 1.39. There exists a neighborhood W of On in M(n, C) such that the ex-
ponential mapping exp : M(n, C) →GL(n, C) is a diffeomorphism on W.
Proof.
The series
∞

k=0
Bk
k! is uniformly convergent in ||B|| ≤ρ (ρ > 0). Therefore,
Fij = (exp B)ij are the entire analytic functions of the complex variables bkl (k, l =
1, · · · , n),
Fij(bkl) = δij + bij + · · · + (terms of degree) ≥2.
Therefore, the Jacobian matrix is
∂(expB)ij
∂¯bkl
= ∂Fij(bkl)
∂bkl
= δkl
ij ,
where δkl
ij =
' 1,
k = i,
l = j,
0,
otherwise.
Since det (δkl
ij ) = 1 ̸= 0, by implicit function theorem, there exists a neighborhood
W ⊂{||B|| < ρ}, such that B →exp B is a diffeomorphism on W.
▲
Remark 1.40. The inverse function to B →exp B = A is
A −→log A = log (I + (A −I)) =
∞

k=1
(−1)k
k
(A −I)k,
which is uniformly convergent for ||A −I|| ≤ρ < 1.

2.1 Symplectic Algebra and Orthogonal Algebra
127
Proposition 1.41. The function A(t) = exp (tB), ∀t ∈R satisﬁes the following prop-
erties:
A(0) = I,
A(t1 + t2) = A(t1)A(t2) = A(t2)A(t1),
A(−t) = (A(t))−1,
d
d tA(t) = BA(t),
d
d tA(t)|t=0 = B.
Proposition 1.42. For A1, A2 ∈GL(n, C), its commutator is deﬁned by
{A1, A2}G = A1A2A−1
1 A−1
2
(commutator in Lie group).
Then for Ai(t) = exp tBi (i = 1, 2), ∀t ∈R, we have
{A1(t), A2(t)}G = I + t2{B1, B2}g + o(t4),
{A1(t), A2(t)}G|t=0 = In,
d
d t{A1(t), A2(t)}G|t=0 = 0,
1
2
d2
d t2
(
A1(t), A2(t)
)
G|t=0 = {B1, B2}g,
where {B1, B2}g = B1B2 −B2B1 is the commutator in Lie algebra.
Proposition 1.43. If B ∈g(G, n, F) and f(λ) =
n

k=0
αkλk, αk ∈F, then (Bk)′G =
G(−B)k, (f(B))′G = Gf(−B).
Theorem 1.44. A(t) = exp (tB) ∈G(G, n, F), ∀t ∈R iff B ∈g(G, n, F).
Proof. Let C(t) = A′(t)GA(t), then C(0) = G,
d
d tC(t) =
d A′(t)
d t
GA(t) + A′(t)Gd A(t)
d t
= BA′(t)GA(t) + A′(t)GBA(t)
= A′(t)(B′G + GB)A(t).
(1.1)
Thus, A(t) ∈G(G, n, F), ∀t ∈R iff C(t) ≡G, i.e., d
d tC(t) = 0. Then, in order
to prove the theorem, we need only to show that the latter condition is equivalent to
B ∈g(G, n, F), i.e., B′G + GB = 0.
If d
d tC(t) = 0, then d
d tC(t)

t=0 = I′(B′G + GB)I = B′G + GB = 0, and so
B ∈g(G, n, F). Conversely, if B′G + GB = 0, by (1.1),
d
d tC(t) = 0,
then C(t) = C(0) = G, i.e., A′(t)GA(t) = G, ∀t ∈R.
▲

128
2. Symplectic Algebra and Geometry Preliminaries
3.
Lie algebra of conformally invariant groups CG(G, n, F)
Deﬁnition 1.45. Deﬁne
cg(G, n, F) =
(
B ∈gl(n, F) | B′G + GB = βG, for some β ∈F}.
Since B1, B2 ∈cg(G, n, F), then
{B1, B2}′G = (B1B2 −B2B1)′G = B′
2B′
1G −B′
1B′
2G
= B′
2(β1G −GB1) −B′
1(β2G −GB2)
= β1β2G −β1GB2 −(β2G −GB2)B1
−β1β2G + β2GB1 + (β1G −GB1)B2
= G(B2B1 −B1B2) = −G{B1, B2}.
{B1, B2} ∈cg(G, n, F). This shows that cg(G, n, F) is closed under { , }. There-
fore, cg(G, n, F) is a subalgebra of gl(n, F) equipped with the induced binary opera-
tion { , }, called as the Lie algebra of the conformally invariant group CG(G, n, F).
Theorem 1.46. Let A(t)= exp(tB), then A(t) ∈CG(G, n, F) iff B ∈cg(G, n, F).
2.2 Canonical Reductions of Bilinear Forms
In Section 2.1, we have seen that for a given bilinear form ϕ on Fn, there is a matrix
G in M(n, F) such that under natural base, ϕ can be represented by G:
ϕ(x, y) = x′Gy,
Gij = ϕ(ei, ej).
The representative matrix G will change as the base changes. In this section, we want
to make sure how the matrix G changes.
Let Fn = {e1, · · · , en} = {f1, · · · , fn}, where e1, · · · , en is the standard base and
f1, · · · , fn is a new base. Then,
fi =
n

j=1
tjiej,
T = [tij] ∈GL(n, F),
x =
n

i=1
xiei =
n

i=1
ui ¯fi,
x =
⎡
⎢⎣
x1
...
xn
⎤
⎥⎦= Tu = T
⎡
⎢⎣
u1
...
un
⎤
⎥⎦,
y =
n

i=1
yiei =
n

i=1
vi ¯fi,
y =
⎡
⎢⎣
y1
...
yn
⎤
⎥⎦= Tv = T
⎡
⎢⎣
v1
...
vn
⎤
⎥⎦.

2.2 Canonical Reductions of Bilinear Forms
129
Assume that under the new base ¯f1, · · · , ¯fn, the representative matrix of ϕ is G. Then,
Gij = ϕ( ¯fi, ¯fj) = ϕ
%
n

k=1
tkiek,
n

l=1
tljel
&
=
n

k,l=1
tkiϕ(ek, el)tlj = (T ′GT)ij,
i.e.,
G = T ′GT,
ϕ(x, y) = ϕ

n

i=1
xiei,
n

j=1
yjej

=
n

i,j=1
xiϕ(ei, ej)yj =
n

i,j=1
xiGijyj = x′Gy
= ϕ

n

i=1
ui ¯fi,
n

j=1
vj ¯fj

=
n

i,j=1
uiϕ( ¯fi, ¯fj)vj
=
n

i,j=1
uiGijvj = u′Gv.
2.2.1 Congruent Reductions
Deﬁnition 2.1. Let G1 and G2 ∈M(n, F). G1 is congruent to G2, if there exists a
non-singular matrix T ∈GL(n, F), such that T ′G1T = G2, denoted by G1 ∼G2.
Thus, the representative matrices of a bilinear form ϕ on Rn under different bases
are congruent to one another.
If G1 is congruent to G2, then the equality G′
1 = εG1 implies the equality G′
2 =
εG2 with the same parity ε and rank G1 = rank G2.
Let φ be a conjugate bilinear form on Cn. G is the representative matrix of φ under
the standard base, i.e.,
φ(x, y) = x∗Gy,
y =
⎡
⎢⎣
y1
...
yn
⎤
⎥⎦,
x =
⎡
⎢⎣
x1
...
xn
⎤
⎥⎦∈Cn.
If ¯f1, · · · , ¯fnis another base on Cn and ¯fj =
n

i=1
tijei, T = [tij] ∈GL(n, C),
then similarly we can get
G = T ∗GT,
where G is the representative matrix of φ under the base ¯f1, · · · , ¯fn.

130
2. Symplectic Algebra and Geometry Preliminaries
Deﬁnition 2.2. Let G1 and G2 ∈M(n, C). G1 is congruent to G2 if there exists a
matrix T ∈GL(n, C), such that T ∗G1T = G2, denoted by G1
c∼G2.
If G1
c∼G2, then rank G1 = rank G2 and the equality G∗
1 = εG1 implies the
equality G∗
2 = εG2 with the same factor ε.
Remark 2.3. G is a conformal Hermitian matrix, i.e., G
′ = εG with G, ε ∈C, and
|ε| = 1, if and only if ε = eiθ and G∗= eiθG, if and only if eiθ
2 G is a Hermitian
matrix.
Deﬁnition 2.4. Let ϕ(x, y) = ϕG(x, y) = x′Gy be a bilinear form induced by G.
For a subspace U ⊂Rn/Cn, the subspace U ϕ ⊂Rn/Cn deﬁned by
U ϕ = {x ∈Rn/Cn | ϕ(x, y) = x′Gy = 0, ∀y ∈U}
is called the G-orthogonal complement of U.
2.2.2 Congruence Canonical Forms of Conformally Symmetric
and Hermitian Matrices
We list congruence canonical forms of conformally symmetric and Hermitian matrices
in Table 2.1 as a comparison.
F = R/C.
1.
Alternative canonical forms
Let T =
1
√
2
 I
I
I
−I
!
, then T ′
 O
I
I
O
!
T =
 I
O
O
−I
!
. where Fn = V +
U, U = {x ∈Fn | ϕ(x, y) = 0, ∀y ∈Fn} = (Fn)ϕ, dim V = r, dim U =
n −r, ϕ is non-singular, and J canonical symplectic quadratic form

0
1
−1
0

.
Let T = [tij], tij =
'
δk,j,
i = 2k −1,
δk+n,j,
i = 2k,
i, j = 1, · · · , 2n. Then,
T ′
⎡
⎢⎢⎢⎢⎢⎣
0
1
±1
0
...
0
1
±1
0
⎤
⎥⎥⎥⎥⎥⎦
T =
 
O
In
±In
O
!
2n×2n
.
Thus, the canonical forms listed in Table 2.1 have the following alternative forms:

2.2 Canonical Reductions of Bilinear Forms
131
Table 2.1.
Canonical form of conformal matrix and Hermitian matrices
Matrix
Canonical form
G′ = G, in C or R,
⎡
⎢⎢⎢⎢⎢⎢⎢⎣
J
J
...
s-block
J
On−r
⎤
⎥⎥⎥⎥⎥⎥⎥⎦
2s = r
∃u, v ∈Rr, s.t.
ϕ(u, v) ̸= 0. Let a1 = u,
a2 =
v
ϕ(u, v) =⇒ϕ(a1, a1)
= ϕ(a2, a2) = 0,
ϕ(a1, a2)
= −ϕ(a2, a1) = 1
{a1, a2} ∩{a1, a2}ϕ
= {0},
G ∼
5
J
O
O
G1
6
G′ = G, in C,
⎡
⎢⎢⎢⎢⎣
Ir
...
. . .
. . .
...
On−r
⎤
⎥⎥⎥⎥⎦
∃u ∈Cr, s.t.
ϕ(u, u) ̸= 0.
Let a1 =
u

ϕ(u, u)
=⇒ϕ(a1, a1) = 1
{a1} ∩{a1}ϕ = {0},
{a1}ϕ = {a2, · · · , ar},
G ∼
5
1
0
0
G1
6
G′ = G, in R,
⎡
⎢⎣
Ip
−Iq
On−r
⎤
⎥⎦
p + q = r
∃u ∈Rr, s.t.
ϕ(u, u) ̸= 0.
Let a1 =
u

|ϕ(u, u)|
=⇒ϕ(a1, a1) = ±1
{a1} ∩{a1}ϕ = {0},
{a1}ϕ = {a2, · · · , ar},
G ∼
⎡
⎣
±1
0
0
G1
⎤
⎦
G∗= G,
G∗= eiθG
⎡
⎢⎣
Ip
−Iq
On−r
⎤
⎥⎦,
⎡
⎢⎢⎢⎣
e
−iθ
2 Ip
−e
−iθ
2 Iq
On−r
⎤
⎥⎥⎥⎦
p + q = r
∃u ∈Cr, s.t.
ϕ(u, u) ̸= 0.
Let a1 =
u

|ϕ(u, u)|
=⇒ϕ(a1, a1)
= signϕ(u, u)
= ±1
{a1} ∩{a1}ϕ = {0},
{a1}ϕ = {a2, · · · , ar},
G ∼
⎡
⎣
±1
0
0
G1
⎤
⎦
⎡
⎣
0
Ir
−Ir
0
On−r
⎤
⎦∼G′ = −G,
in R
or
in C,
 
Ir
On−r
!
∼G′ = G,
in C,
⎡
⎢⎣
0
Is
Is
0
σId
On−r
⎤
⎥⎦∼G′ = G,
in R
or
(G∗= G, in C ),
⎡
⎢⎢⎢⎣
0
Is
e−iθIs
0
σe−iθ
2 Id
On−r
⎤
⎥⎥⎥⎦G∗= eiθG,
in C,

132
2. Symplectic Algebra and Geometry Preliminaries
where s = min(p, q), d = |p −q|, σ = sign(p −q), p + q = r = 2s + d, p −q =
σd, p = 1
2(r + σd) = s + 1
2(1 + σ)d, q = 1
2(r −σd) = s + 1
2(1 −σ)d.
2.
Invariants under congruences
Theorem 2.5. Let G be a conformally symmetric matrix in Fn(= Rn or Cn), i.e.,
G′ = εG. Then, the quantities ε(G), r(G) and s(G) are the invariants under congru-
ences. Moreover, if ε = −1, then r = 2s, if ε = 1, then p(G), q(G), d(G) and σ(G)
are invariants under congruences.
If G is conformal Hermitian, i.e., G∗= εG with ε = eiθ, then the quantities
ε(G), r(G), s(G), p(G), q(G) and σ(G) are invariants under congruences.
Theorem 2.6 (Sylvester’s law of inertia). Let ϕ(x) be a quadratic form in Rn and
x = Ty, det(T) ̸= 0. If
ϕ(x) = x2
1 + x2
2 + · · · + x2
p −x2
p+1 −· · · −x2
n
= y2
1(x) + y2
2(x) + · · · + y2
q(x) −y2
q+1(x) −· · · −y2
n(x),
(2.1)
then p = q.
Similarly, let φ(x) be a quadratic form in Cn and x = Ty, det T ̸= 0. If
φ(x) = |x1|2 + |x2|2 + · · · + |xp|2 −|xp+1|2 −· · · −|xn|2
= |y1|2 + |y2|2 + · · · + |yq|2 −|yq+1|2 −· · · −|yn|2,
then p = q.
Proof. If p > q, then p + (n −q) > n. Thus, the equations x1 = 0, · · · , xp =
0, yq+1(x) = 0, · · · , yn(x) = 0 has a non-zero solution ξ ̸= 0. By (2.1),
y2
1(ξ) + · · · + y2
q(ξ) + ξ2
p+1 + · · · + ξ2
n = ξ2
1 + · · · + ξ2
p + y2
q+1(ξ) + · · · + y2
n(ξ) = 0,
and thus ξp+1 = 0, . . . , ξn = 0. Then, we have ξ = 0, which is a contradiction. This
shows that p ≤q. Similarly, q ≤p, then p = q.
▲
Theorem 2.7 (Witt). If a non-singular Hermitian matrix
 G0
0
0
G1
!
is conjugate
congruent to
 G0
0
0
G2
!
, then G1 is conjugate congruent to G2.
Proof. We ﬁrst prove the case G0 = 1, i.e.,
 1
0
0
G1
!
∼
 1
0
0
G2
!
.
Let T =
 a
¯b′
c
d
!
and T ∗
 1
0
0
G1
!
T =
 1
0
0
G2
!
. Then,
 
1
0
0
G2
!
=
 a
c∗
¯b
d∗
!  
1
0
0
G1
!  
a
¯b′
c
d
!
=
5
aa + c∗G1c
a¯b′ + c∗G1d
¯ba + d∗G1c
¯b¯b′ + d∗G1d
6
,i.e.,

2.2 Canonical Reductions of Bilinear Forms
133
aa + c∗G1c = 1,
a¯b′ + c∗G1d = 0,
¯ba + d∗G1c = 0,
¯b¯b′ + d∗G1d = G2.
Let dλ = d + λcb′,
d∗
λG1dλ = (d∗+ λ¯bc∗)G1(d + λc¯b′)
= d∗G1d + λ¯bc∗G1d + λd∗G1c¯b′ + |λ|2¯bc∗G1c¯b′
= G2 −¯b¯b′ −λ¯ba¯b′ −λ¯ba¯b′ + |λ|2(¯b¯b′ −aa¯b¯b′)
= G2 −(1 + λa + aλ −(1 −|a|2)|λ|2)¯b¯b′.
If λ satisﬁes the equation
1 + λa + aλ −(1 −|a|2)|λ|2 = 0,
then
d∗
λG1dλ = G2.
It only needs to take
λ =
⎧
⎨
⎩
−1
2,
if a = 1,
1
1 −a,
if a ̸= 1.
If the order r of G0 is larger than 1, then
G0
c∼
⎡
⎢⎣
±1
0
...
0
±1
⎤
⎥⎦
r×r
,
and thus
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
⎛
⎜
⎝
±1
...
±1
⎞
⎟
⎠
r
· · ·
· · ·
· · ·
0
...
...
...
...
...
0
· · ·
G1
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
c∼
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
⎛
⎜
⎝
±1
...
±1
⎞
⎟
⎠
r
· · ·
· · ·
· · ·
0
...
...
...
...
...
0
· · ·
G2
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
.
We denote
$
G1 =
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
⎛
⎜
⎝
±1
...
±1
⎞
⎟
⎠
r−1
· · ·
· · ·
· · ·
0
...
...
...
...
...
0
· · ·
G1
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
,

134
2. Symplectic Algebra and Geometry Preliminaries
$
G2 =
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
⎛
⎜
⎝
±1
...
±1
⎞
⎟
⎠
r−1
· · ·
· · ·
· · ·
0
...
...
...
...
...
0
· · ·
G2
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
,
then by the result just proved above, $
G1
c∼$
G2. By recursions, we can ﬁnally get
G1
c∼G2.
The Witt theorem gives another proof of the invariance of index p. If
 Ip
0
0
−In−p
!
c∼
 Ip′
0
0
−In−p′
!
,
and p > p′, then
 Ip−p′
0
0
−In−p

c∼

∗
−In−p′
!
,
i.e., there exists a matrix T ∈GL(n −p′, C), such that
 Ip−p′
0
0
−In−p
!
= −T ∗T.
The (1,1) element of the given matrix is
1 = −(|ti1|2 + · · · + |tn−p′|2),
which is a contradiction.
▲
2.2.3 Similar Reduction to Canonical Forms under Orthogonal
Transformation
For comparison, we list the canonical forms of Hermitian, conformal Hermitian ma-
trices, real symmetric, and anti-symmetric matrices under unitary or orthogonal trans-
formations in the Table 2.2. The content can be found in any standard textbook.

2.2 Canonical Reductions of Bilinear Forms
135
Table 2.2.
H, S and K under unitary or orthogonal transformations
Matrices
Canonical form
H∗= H,
λk ∈R
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
λ1
...
λr
0
...
0
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
If λ1 is an eigenvalue of H, then :
∃w1 ̸= 0, s.t.Hw1 = λ1w1,
⟨w1, w1⟩= 1.
⟨w1, Hw1⟩= ⟨w1, λ1w1⟩= λ1.
⟨w1, Hw1⟩∈R ⇒λ1 ∈R.
z ∈{w1}⊥⇒Hz1 ∈{w1}⊥
So, ∃T0 ∈U(n, C), s.t.
T −1
0
HT0 =
 
λ1
0
0
H1
!
,
where H∗
1 = H1
H∗= ei θH,
λk ∈R
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
e−i θ/2λ1
...
e−iθ/2λr
0
...
0
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
S is a real matrix, S′ = S ⇒S
is a Hermitian matrix.
If λ1is an eigenvalue, then:
∃w1 ∈R, s.t. Sw1 = λ1w1,
(w1, w1) = 1.Similarly,
x ∈{w1}⊥⇒Sx ∈{w1}⊥.
Analogous, ∃T0 ∈O(n, R), s.t.
T −1
0
ST0 =
 
λ1
0
0
S1
!
,
where S1 = S′
1
S′ = S,
λk ∈R
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
λ1
...
λr
0
...
0
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
K′ = −K, λk > 0,
2s = r
⎡
⎢⎢⎢⎢⎢⎢⎢⎣
0
λ1
−λ1
0
...
0
λs
−λs
0
On−r
⎤
⎥⎥⎥⎥⎥⎥⎥⎦
or
⎡
⎣
0
A
−A
0
On−r
⎤
⎦
where A = diag{λ1, λ2, · · · , λs}
K anti-symmetrical,
iK is a Hermitian matrix,
its eigenvalues are real.
If λ1 ̸= 0 is an eigenvalue of iK,
then ∃w1 = u −i v ̸= 0,
s.t. i K(u −i v) = λ1(u −i v).
Therefore : (1) Kv = λ1u,
(2) Ku = −λ1v.
⇒
λ1(u, v) = (v, Kv) = 0.
Sinceλ1 ̸= 0, we have(u, v) = 0.
From (1) and (2), we get u ̸= 0, v ̸= 0.
Suppose : (u, u) = (v, v) = 1.
Then : (u, Ku) = 0, (u, Kv) = λ1,
(v, Kv) = 0, (v, Ku) = −λ1.
If x ∈{u, v}⊥, then :
Kx ∈{u, v}⊥. Thus,
∃T0 ∈O(n, R), s.t.
T −1
0
KT0 =
⎡
⎣
0
λ1
−λ1
0
K1
⎤
⎦,
where K′
1 = K1

136
2. Symplectic Algebra and Geometry Preliminaries
Next, we consider Jordan canonical forms. Let us ﬁrst recall the Jordan canonical form
for a general real matrix A ∈M(n, R). A Jordan canonical form viewed in real space
is different from the Jordan canonical form viewed in complex space.
1.
Elementary divisors in complex space
In complex space, the elementary divisor corresponding to a paired-complex conjugate
eigenvalue α ± iβ, β ̸= 0 is of the form
[λ −(α + iβ)]p,
[λ −(α −iβ)]p.
The corresponding Jordan blocks are
⎡
⎢⎢⎢⎢⎣
α + i β
1
α + i β
...
...
1
α + i β
⎤
⎥⎥⎥⎥⎦
p×p
,
⎡
⎢⎢⎢⎢⎣
α −i β
1
α −i β
...
...
1
α −i β
⎤
⎥⎥⎥⎥⎦
p×p
.
The elementary divisor corresponding to a real eigenvalue γ is of the form
(λ −γ)q.
Its Jordan block is
⎡
⎢⎢⎢⎢⎣
γ
1
γ
...
...
1
γ
⎤
⎥⎥⎥⎥⎦
q×q
∼(λ −γ)q.
2.
Elementary divisor in real space
In real space, the elementary divisor corresponding to a paired complex conjugate
eigenvalues α± iβ, (β ̸= 0) is of the form
[λ2 −2αλ + (α2 + β2)]p.
Its Jordan block is
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
0
1
−(α2 + β2)
2α
1
0
1
−(α2 + β2)
2α
1
...
...
1
0
1
−(α2 + β2)
2α
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
2p×2p
.
The elementary divisor and the Jordan block corresponding to a real eigenvalue γ
is the same as in complex space, i.e.,

2.3 Symplectic Space
137
⎡
⎢⎢⎢⎢⎣
γ
1
γ
...
...
1
γ
⎤
⎥⎥⎥⎥⎦
q×q
∼(λ −γ)q.
2.3 Symplectic Space
A symplectic vector space is a vector space V equipped with a nondegenerate, skew-
symmetric, bilinear form ω called the symplectic form.
Explicitly, a symplectic form is a bilinear form ω : V × V →R that is
1◦
Skew-symmetric: ω(u, v) = −(v, u) ∀u, v ∈V .
2◦
Nondegenerate: if ω(u, v) = 0 ∀v ∈V , then u = 0.
Working in a ﬁxed basis, ω can be represented by a matrix. The two conditions
above imply that this matrix must be skew-symmetric and nons-singular. This is not
the same as a symplectic matrix, which represents a symplectic transformation of the
space.
2.3.1 Symplectic Space and Its Subspace
1.
Comparison between symplectic and Euclidian space[Tre75,LM87,FQ91a,Wei77]
In this section, we restrict ourselves to R2n. The symbol ⇔, which stands for “if and
only if”, will be widely adopted under J orthogonality and I Orthogonality.
Sympl. Structure J-Sympl. Matrix
Euclidian Structure I-Unit Matrix
[x, y] = x′Jy,
(x, y) = x′Iy;
[y, x] = −[x, y],
(y, x) = (x, y);
[x, x] = 0, ∀x,
(x, x) > 0, ∀x ̸= 0;
[x, y] = (x, Jy).
(x, y) = [x, J−1y].
J-Orthogonality
I-Orthogonality
x⊤y ⇐⇒[x, y] = 0 ⇐⇒y⊤x,
x⊥y ⇐⇒(x, y) = 0 ⇐⇒y⊥x.
U⊤V ⇐⇒[x, y] = 0, ∀x ∈U, y ∈V,
U⊥V ⇐⇒(x, y) = 0, x ∈U, y ∈V.
U⊤V ⇐⇒U⊥JV,
U⊥V ⇐⇒U⊤J−1V.
Deﬁnition 3.1. V ⊤= {x ∈R2n | [x, y] = 0, ∀y ∈V }. V ⊥= {x ∈R2n | (x, y) =
0, ∀y ∈V }.
By deﬁnition, we have V ⊤= (JV )⊥, V ⊥= (J−1V )⊤.

138
2. Symplectic Algebra and Geometry Preliminaries
Proposition 3.2. U ⊂R2n, V ⊂R2n. Then,
U ⊂V ⇐⇒U ⊤⊃V ⊤,
U ⊂V ⇐⇒U ⊥⊃V ⊥;
(U ∩V )⊤= U ⊤+ V ⊤,
(U ∩V )⊥= U ⊥+ V ⊥;
(U + V )⊤= U ⊤∩V ⊤,
(U + V )⊥= U ⊥∩V ⊥;
dim U + dim U⊤= 2n,
dim U + dim U⊥= 2n;
U ⊤⊤= U,
U ⊥⊥= U;
∃U, U ∩U ⊤̸= {0},
U ∩U ⊥= {0};
U + U ⊤̸= R2n,
U + U ⊥= R2n.
Deﬁnition 3.3. U ⊂R2n, deﬁne U 0 = U ∩U ⊤, called as the radical of U.
2.
Special classes of subspaces[HW63,Tre75,LM87,Wei77]
(1)
V degenerate subspace : V 0
=
V ∩V ⊤̸= 0
⇐⇒dim V is
odd.
(2)
V isotropic subspace : V
⊂
V ⊤
⇐⇒V ∩V ⊤= V 0 = V
⇐⇒[x, y] = 0 on V
=⇒dim V ≤n
⇐⇒V ⊤coisotropic
⇐= dim V = 1.
(3)
V coisotropic subspace : V ⊤
⊂
V
⇐⇒V ∩V ⊤= V 0 = V ⊤
⇐⇒[x, y] = 0 on V ⊤
=⇒dim V ≥n
⇐⇒V ⊤isotropic
⇐= dim V = 2n −1.

2.3 Symplectic Space
139
(4)
V Lagrangian : V ⊤
=
V
⇐⇒V is isotropic and coisotropic
⇐⇒V is isotropic and dim V = n
⇐⇒V is coisotropic and dim V = n
⇐⇒V maximally isotropic
⇐⇒V minimally coisotropic.
(5)
V non-degenerate : V ∩V ⊤
=
{0}
⇐⇒V + V ⊤= R2n
⇐⇒[x, y] non-degenerate on V
⇐⇒If [x, y] = 0 ∀y ∈V, then x = 0
⇐⇒V ⊤non-degenerate
=⇒dim V is even.
(6)
Coordinate subspaces.
Deﬁne ν = {1, 2, · · · , n} with the natural order. If α = {i1, i2, · · · , ik} ⊂ν (i1
< · · · < ik), the total number of α′s is 2n. Denote α = ν\α = {j1, · · · , jn−k} (j1
< . . . < jn−k), ν = ∅, α ∪α = ν, α ∩α = ∅.
Deﬁnition 3.4. Deﬁne a coordinate subspace Rα,β = {ei, fj}i∈α,j∈β, where
e1 =
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
1
0
...
0
...
0
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
, · · · , en =
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
0
...
1
0
...
0
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
, f1 =
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
0
...
0
1
...
0
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
, · · · , fn =
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
0
...
0
0
...
1
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
.
The total number of coordinate subspaces Rα,β is 22n.
Problem 3.5. We have the following issues to address:
1◦
Under what conditions about α, β is Rα,β isotropic, coisotropic, Lagrangian?
2◦
Deﬁne Iα = [diδij], di =
'
1,
i ∈α,
0,
i ∈α.
Proof. .
Iν = In, Iν = I∅= On,
I2
α = Iα,
IαIα = On,
IαIβ = Iα∩β,
Iα + Iα = I,
Iα + Iβ = Iα∩β + Iα∪β = Iα∪β + IαIβ.
The proof can be obtained.
▲

140
2. Symplectic Algebra and Geometry Preliminaries
3◦
Show that the subspaces D = {pi = ±qi, i = 1, 2, · · · , n} are Lagrangian
and transversal to all coordinate Lagrangian subspaces.
Theorem 3.6. Let W be non-degenerate and W = U ⊤
⃝V, where U ⊤
⃝V stands for
the J-orthogonal sum. Then U, V both are non-degenerate.
Proof. Let x ∈U such that [x, y] = 0, ∀y ∈U. Then, from U ⊂V ⊤, it follows
that [x, z] = 0, ∀z ∈V . Therefore, [x, w] = 0, ∀w ∈W. By assumption, W is
non-degenerate, and so x = 0. This shows U is non-degenerate. Similarly, V is non-
degenerate too.
▲
Theorem 3.7. If U is isotropic, then there exists a Lagrangian subspace V ⊃U.
Proof. Without loss of generality, we can assume that dim U = k < n. Therefore,
there exists a vector ak+1 ∈U ⊤\U ̸= ∅, V = U + {ak+1} ⊃U, V is isotropic.
▲
By repeating this procedure, we can get a Lagrangian subspace V ⊃U.
Theorem 3.8. For a given Lagrangian subspace U = {a1, a2, · · · , an}, there exists
another Lagrangian subspace V = {b1, b2, · · · , bn}, such that
R2n = P1 ⊤
⃝P2 ⊤
⃝· · · ⊤
⃝Pn = U ˙+V,
where Pi = {ai, bi}, [ai, aj] = [bi, bj] = 0, [ai, bj] = δij.
Proof. We proceed by induction with respect to dimension n. For n = 1, by non-
degenerality of R2, there is a vector b1, satisfying [a1, b1] = 1. Of course, {b1} is
Lagrangian. Thus, this theorem is true for n = 1.
Assume that for n−1, the theorem is true. Then, for R2n, {a1} ̸⊂{a2, a3, · · · , an},
and so {a2, a3, · · · , an}⊤\{a1}⊤̸= ∅, there is a vector b1 ∈{a2, a3, · · · , an}⊤\
{a1}⊤, such that
[a1, b1] = 1,
[a2, b1] = · · · = [an, b1] = 0.
Set P1 = {a1, b1}. By above subspace(5) and Theorem 3.6,
R2n = P1 ⊤
⃝P ⊤
1 ,
P1 ∩P ⊤
1 = {0},
dim P ⊤
1
= 2(n −1), {a2, a3, · · · , an} ⊂P ⊤
1 is maximally isotropic in P ⊤
1 , i.e.,
a Lagrangian subspace of P ⊤
1 . By inductive assumption, there exists b2, · · · , bn and
{b2, · · · , bn} is Lagrangian space in P ⊤
1 . Moreover,
[ai, aj] = [bi, bj] = 0,
[ai, bj] = δij,
i, j = 2, · · · , n.
Therefore, for all i, j, we have
[ai, aj] = [bi, bj] = 0,
[ai, bj] = δij.
Set Pi = {ai, bi}, then R2n = P1 ⊤
⃝P2 ⊤
⃝· · · ⊤
⃝Pn.
▲

2.3 Symplectic Space
141
Theorem 3.9. Let U, V be two Lagrangian subspaces, U = {a1, a2, · · · , an}, U ∩
V = {0}. Then, there exists a unique base b1, b2, · · · , bn, such that V = {b1, b2, · · · ,
bn}, and
[ai, aj] = [bi, bj] = 0,
[ai, bj] = δij.
Proof. Similarly manner, by induction with respect to dimension n, the proof can be
obtained.
▲
Theorem 3.10. If U is not isotropic, then there exists a non-degenerate subspace N ⊂
U, N ̸= {0}, such that
U = U 0 ⊤
⃝N,
U 0 = U ∩U ⊤.
Proof. By assumption U 0 = {x ∈U|[x, y] = 0, ∀y ∈U} ̸= U. Therefore, there is a
subspace N ⊂U, N ̸= {0}, such that N ∩U 0 = {0} and U = N ˙+U 0.
Since U 0⊤U, of course U 0⊤N. If x ∈N and [x, y] = 0, ∀y ∈N, then by U 0⊤N,
we have [x, z] = 0, ∀z ∈U 0 i.e., [x, y] = 0, ∀y ∈U. Thus, x ∈U 0 ∩N = {0}, and
x must be = 0. Therefore, N is non-degenerate.
▲
Theorem 3.11. Let V1, V2 be two disjoint isotropic subspaces. Then, there exist two
Lagrangian subspaces W1, W2 that are disjoint. W1 ∩W2 = {0} such that W1 ⊃
V1, W2 ⊃V2.
Proof. Let U = V1 ˙+V2, U 0 = U ∩U ⊤= (V1 ˙+V2) ∩(V1 ˙+V2)⊤.
1◦
If U is isotropic. Assume
V1 = {a1, · · · , ar},
V2 = {br+1, · · · , br+s}.
By Theorem 3.7, there exists V3 = {ar+s+1, · · · , an}, such that
V1 ˙+V2 ˙+V3 = {a1, · · · , ar, br+1, · · · , br+s, ar+s+1, · · · , an}
is Lagrangian. Moreover, by Theorem 3.8, there exist b1, · · · , br, ar+1, · · · , ar+s,
br+s+1, · · ·, bn ∈R2n, such that
[ai, aj] = [bi, bj] = 0,
[ai, bj] = δij.
Set W1 = {a1, · · · , ar, ar+1, · · · , ar+s, ar+s+1, · · · , an}, W2 = {b1, · · · , bn}.
Obviously, W1, W2 are Lagrangian and W1 ∩W2 = {0}, V1 ⊂W1, V2 ⊂W2.
2◦
If U is not isotropic. Set U 0
1 = V1 ∩V ⊤
2 , U 0
2 = V2 ∩V ⊤
1 , then
U 0 = U 0
1 ˙+U 0
2 ,
U 0
i = Vi ∩U 0,
i = 1, 2.
Evidently,
U 0
i
= Vi ∩U 0 = Vi ∩U ∩U ⊤
= Vi ∩(V1 ˙+V2)⊤= Vi ∩(V ⊤
1 ∩V ⊤
2 ),
i = 1, 2.

142
2. Symplectic Algebra and Geometry Preliminaries
By assumption, Vi(i = 1, 2) are isotropic, i.e., Vi ⊂V ⊤
i (i = 1, 2). By the following
Lemma 3.12,
U 0
1 ˙+U 0
2 = V1 ∩(V ⊤
1 ∩V ⊤
2 ) ˙+V2 ∩(V ⊤
1 ∩V ⊤
2 )
= (V1 ˙+V2) ∩(V ⊤
1 + V ⊤
2 )
= U ∩U ⊤= U 0.
Take Ni ⊂Vi(i = 1, 2), such that Vi = U 0
i ⊤
⃝Ni.
Set N = N1 ˙+N2, then
U = V1 ∔V2 = U 0
1 ∔N1 ∔U 0
2 ∔N2 = U 0 ∔N.
Similar to the proof of Theorem 3.10, we can see that N is non-degenerate and
U = U 0 ⊤
⃝N. Of course, Ni = N ∩Vi(i = 1, 2), and N1 ⊂N ∩V1.
If x ∈N ∩V1, then x = x1 + x2, x1 ∈N1, x2 ∈N2. Moreover, by x ∈V1,
we have x2 = x −x1 ∈V1. Thus, x2 ∈V1 ∩V2 = {0}, x2 = 0. This shows that
x = x1 ∈N1.
As N is non-degenerate, R2n = N ⊤
⃝N ⊤, U 0 = U 0
1 ∔U 0
2 ⊂N ⊤. By N = N1 ∔
N2 and N1, N2 being isotropic, we know that N1, N2 both are maximal isotropic,
i.e., Lagrangian in N.
For the non-degenerate subspace N ⊤, since U 0 = U 0
1 ∔U 0
2 ⊂N ⊤is isotropic,
applying results 1◦of Theorem 3.11 , there exist two Lagrangian subspaces W1, W2,
in N ⊤, such that Wi ⊃U 0
i (i = 1, 2) and W 1 ∩W 2 = {0}. Set W1 = W1 ∔
N1, W2 = W2 ∔N2. Then, Wi(i = 1, 2) are Lagrangian in R2n(i = 1, 2) and
Vi ⊂Wi(i = 1, 2), W1 ∩W2 = {0}.
▲
Lemma 3.12. If A ⊂A1, B ⊂B1, then
(A + B) ∩(A1 ∩B1) = A ∩(A1 ∩B1) + B ∩(A1 ∩B1)
= A ∩B1 + B ∩A1.
Proof. (A + B) ∩(A1 ∩B1) ⊂A ∩(A1 ∩B1) + B ∩(A1 ∩B1) is trivial. Let
x ∈(A + B) ∩(A1 ∩B1). Since x ∈A + B, then exists a decomposition
x = a + b,
a ∈A ⊂A1,
b ∈B ⊂B1.
Since x ∈A1 ∩B1, a = x −b1 ∈B1, b = x −a ∈A1.
Thus, a ∈A ∩B1, b ∈B ∩A1, i.e., x = a + b ∈A ∩B1 + B ∩A1.
▲
Lemma 3.13. Let U, V, W ⊂Rm, V ∔W = Rm. Deﬁne a linear projection πW
V
along W into V as πW
V : Rm →Rm,
πW
V x =
' x,
∀x ∈V,
0,
∀x ∈W.
Then, U ∔W = Rm, iff πW
V : U →V is non-singular and onto.

2.3 Symplectic Space
143
Proof. Assume x ∈U, πW
V x = 0. From V ∔W = Rm, it follows that there exists a
decomposition
x = v + w,
where
v ∈V and w ∈W.
Thus,
0 = πW
V x = πW
V (v + w) = πW
V v + πW
V w = πW
V v = v.
Then, x = w ∈W, i.e., x ∈U ∩W = {0}. We get x = 0.
Conversely, if x ∈U ∩W, then x ∈W, x ∈U. By the deﬁnition of π, we have
πx = 0. π : U →V is non-singular and so x = 0, i.e.,
W ∩U = {0},
U ∔W = Rm.
Therefore, the lemma is completed.
▲
Theorem 3.14. For every Lagrangian subspace L in R2n, there exists a coordinate
Lagrangian subspace Rα,α transversal to L, i.e., ∃α ⊂ν , such that Rα,α+L = R2n.
Proof. Since (Rν,0 ∩L) ⊂Rν,0, ∃α ⊂ν, such that
Rα,0 ∩(Rν,0 ∩L) = {0},
Rα,0 + (Rν,0 ∩L) = Rν,0.
RT
ν,0
Lag.
= Rν,0 ⊂Rα,α + L
Lag.
= RT
α,α + L⊤= (Rα,α ∩L)⊤.
Therefore,
Rα,α ∩L = (Rα,α ∩Rν,0) ∩(Rν,0 ∩L)
= Rα,0 ∩(Rν,0 ∩L) = {0}.
Then,
Rα,α + L = R2n.
The theorem is proved.
▲
3.
Matrix representation of subspaces in R2n
A =
⎡
⎢⎣
a11
· · ·
a1k
...
...
a2n,1
· · ·
a2n,k
⎤
⎥⎦= [a1, a2, · · · , ak] =
 A1
A2
!
,
where A ∈M(2n, k), ai ∈M(2n, 1), Aj ∈M(n, k).
Deﬁnition 3.15. A ∈M(2n, k) is non-singular, if rankA = k.
Let A ∈M(2n, k), B ∈M(2n, l). Then, [A, B] ∈M(2n, k + l). If [A, B] is
non-singular, then both A and B are non-singular.
G2n,k = {all k-dim subspaces in R2n}, called as Grassmann manifold.
If A ∈M(2n, k) is non-singular, we deﬁne {A} = {a1, · · · , ak} to be a k-dim
subspace in R2n generated by k column vectors a1, · · · , ak of A.

144
2. Symplectic Algebra and Geometry Preliminaries
Proposition 3.16. Let A, B ∈M(2n, k) be non-singular. {A} = {B}, iff ∃Q ∈
GL(k), such that AQ = B, i.e.,
 
A1Q
A2Q
!
=
 
B1
B2
!
.
Deﬁnition 3.17. Let A, B ∈M(2n, k). If there is a matrix Q ∈GL(k), and AQ =
B, then we say that A is equivalent to B, denoted by A ∼B.
Proposition 3.18. G2n,k consists of equivalent classes of non-singular elements un-
der M(2n, k) i.e.,
G2n,k ≈{equivalent classes of non-singular elements under “∼” in M(2n, k)}.
Deﬁnition 3.19. Λn = { all Lagrangian subspaces in R2n} ⊂G2n,n.
Deﬁnition 3.20. A =
 A1
A2
!
∈M(2n, n) is called a symmetric pair of square
matrices, if
A′JA = On,
i.e., A′
1A2 −A′
2A1 = On, where J =
 
0
In
−In
0
!
.
Evidently, A =
 A1
A2
!
is a symmetric pair iff A′
1A2 ∈SM(n), or A′
2A1 ∈SM(n).
All symmetric pairs of square matrices are denoted by SM 2n,n.
In particular, A =
 S
I
!
or
 
I
S
!
∈SM 2n,n, iff S ∈SM(n).
A =
 A1
A2
!
, |A1| ̸= 0,
A ∈SM 2n,n ⇐⇒A2A−1
1
∈SM(n).
|A2| ̸= 0,
A ∈SM 2n,n ⇐⇒A1A−1
2
∈SM(n).
Deﬁnition 3.21. Let A, B ∈M(2n, n). A is conjugate to B if A′JB = In. A is
conformally conjugate to B if ∃μ = μ(A, B) ̸= 0, such that A′JB = μIn.
Obviously, A is conjugate to B iff −B is conjugate to A; A is conformally conju-
gate to B iff B is conformally conjugate to A with μ(B, A) = −μ(A, B).
2.3.2 Symplectic Group
Let

2.3 Symplectic Space
145
A =
 
A1
A2
!
= [a1, · · · , an] ∈M(2n, n),
B =
 
B1
B2
!
= [b1, · · · , bn] ∈M(2n, n),
M = [A, B] =
 
A1
B1
A2
B2
!
= [a1, · · · , an, b1, · · · , bn] ∈M(2n),
M ∈Sp(2n) ⇐⇒M ′JM = J
⇐⇒A, B are a symmetric pair, A is conjugate to B
⇐⇒A′JA = On = B′JB, A′JB = In
⇐⇒A′
1A2 −A′
2A1 = On = B′
1B2 −B′
2B1, A′
1B2 −A′
2B1 = In
⇐⇒a′
iJaj = b′
iJbj = 0, a′
iJbj = δij,
i.e., a1, · · · , an,¯b1, · · · ,¯bn is a symplectic basis
⇐⇒M ′ =
 A′
1
A′
2
B′
1
B′
2
!
∈Sp(2n)
⇐⇒
 A′
1
B′
1
!
,
 A′
2
B′
2
!
are symmetric pairs and are conjugate to each other
⇐⇒A1B′
1 −B1A′
1 = On = A2B′
2 −B2A′
2; A1B′
2 −B1A′
2 = In.
M ∈CSp(2n)
⇐⇒∃μ ̸= 0, M ′JM = μJ
⇐⇒A, B form a symmetric pair and A is conformally conjugate to B
⇐⇒A′JA = On = B′JB, ∃μ ̸= 0, s.t. A′JB = μIn
⇐⇒A′
1A2 −A′
2A1 = On = B′
1B2 −B′
2B1, A′
1B2 −A′
2B1
= μIn, μ ̸= 0
⇐⇒M ′ =
 
A′
1
A′
2
B′
1
B′
2
!
∈CSp(2n)
⇐⇒
 
A′
1
B′
1
!
,
 
A′
2
B′
2
!
are symmetric pairs and are conformally
conjugate to each other
⇐⇒A1B′
1 −B1A′
1 = On = A2B′
2 −B2A′
2; A1B′
2 −B1A′
2
= μIn, μ ̸= 0.
Proposition 3.22. If M ′JM = J, then MJM ′ = J. Generally speaking, if K2 =
±I, then M ′KM = K, iff MKM ′ = K.
Proof. If M ′KM = K, then K = M −1′KM −1,

146
2. Symplectic Algebra and Geometry Preliminaries
K−1 = (M −1′KM −1)−1 = MK−1M ′.
By assumption, K2 = ±I, and so K−1 = ±K. Therefore, MKM ′ = K.
▲
If M ∈Sp(2n), then A is a symmetric pair, iff MA is a symmetric pair; and A is
conjugate to B, iff MA is conjugate to MB.
If M ∈CSp(2n), then A is a symmetric pair iff MA is a symmetric pair; A is
conformally conjugate to B iff MA is conformally conjugate to MB.
M
=
[A, B] ∈O2n ⇐⇒M ′M = I2n
⇐⇒A′A = B′B = In, A′B = On.
M
=
[A, B] ∈Un = Sp(2n) ∩O2n
=
GL(n, C) ∩Sp(2n) = GL(n, C) ∩O2n
⇐⇒A′JA = B′JB = On, A′B = On, A′JB = A′A = B′B = In.
⇐⇒A is non-singular symmetric pair, A′A = InB = J−1A
(see Theorem 3.34).
Theorem 3.23. Let M be non-singular. M ∈CSp(2n) iff
MZ ∈SM 2n×n,
∀Z ∈SM 2n×n,
Z non-singular.
Proof. We only need to prove the sufﬁciency. Let M = [A, B] =
 A1
B1
A2
B2
!
.
1◦
Take Z =
 I
O
!
∈SM 2n×n, MZ = [A, B]
 I
O
!
= A.
By assumption, MZ ∈SM 2n×n, i.e., (MZ)′JMZ = A′JA = O.
2◦
Take Z =
 O
I
!
∈SM 2n×n, similarly, B′JB = 0.
3◦
Take Z =
 S
I
!
, S′ = S, and so Z ∈SM 2n×n.
By (MZ)′JMZ = 0, we have
(AS + B)′J(AS + B) = S′A′JAS + B′JB + S′A′JB + B′JAS
= S′A′JB + B′JAS = O.
Let C = A′JB. Then, S′C = C′S, ∀S′ = S. Take S = I. Then, C′ = C, CS =
SC, ∀S′ = S. This shows that C must be μI, i.e., A′JB = μI.
The μ ̸= 0 follows from |M| ̸= 0. In fact, if μ = 0, then A′JB = O. Hence,
A′JA = A′JB = 0. Thus, A′J[A, B] = 0. This leads to A′ = 0, and therefore, A is
also equal to 0. This is a contradiction. Therefore, M ∈CSp(2n).
▲
Remark 3.24. If CS = SC, ∀S′ = S, then C = μI.

2.3 Symplectic Space
147
2.3.3 Lagrangian Subspaces
Theorem 3.25. {A} ∈Λn ⇔A is a non-singular symmetric pair. M ∈Sp(2n) or
CSp(2n) implies that {A} ∈Λn, iff M{A} ∈Λn.
Examples of Lagrangian subspaces:
Coordinate Lagrangian subspaces[Arn89,Wei77,AM78,HW63] :
Rν,0 = Rν,ν =
 I
O
!
, in which
 I
O
!
is a non-singular symmetric pair;
R0,ν = Rν,ν =
 O
I
!
, in which
 O
I
!
is a non-singular symmetric pair;
Rν,ν = {Iα,α}
in which
Iα,α =
 Iα
Iα
!
is a non-singular symmetric pair.
Proposition 3.26. We have the following results:
1◦
Let {A} be k-dim, {B} be l-dim. Then, {A} ⊂{B}⊤, iff A′JB = Ok×l.
2◦
Let A, B be non-singular. Then, {A}∩{B} = {0}, iff [A, B] is non-singular.
3◦
If dim{A} = dim{B} = n, then {A} ∩{B} = {0}, iff
det [A, B] ̸= 0.
4◦
{A} is isotropic of k-dim ⇔A′JA = Ok.
5◦
{A} is Lagrangian ⇔A′JA = On.
6◦
k-dimensional subspaces {A} is non-degenerate iff |A′JA| ̸= 0, k = 2s, iff
∃B, such that {B} = {A}, B′JB = J2s.
7◦
{A} is degenerate ⇔|A′JA| = 0.
Theorem 3.7 to Theorem 3.14 can be restated in matrix language as follows:
Theorem 3.27. If A′JA = Ok, A is non-singular. Then, there exists B ∈M(2n, n−
k), such that [A, B] is a non-singular symmetric pair.
Theorem 3.28. If A ∈M(2n, n) is a non-singular symmetric pair, then there exists
a matrix, B ∈M(2n, n), such that [A, B] ∈Sp(2n).
Theorem 3.29. If A, C ∈M(2n, n) are two non-singular symmetric pairs and
det [A, C] ̸= 0, then there exists uniquely a non-singular symmetric pair B such that
B ∼C and [A, B] ∈Sp(2n).
Theorem 3.30. Let A ∈M(2n, k), B ∈M(2n, l), A′JA = Ok, B′JB = Ol,
and [A, B] be non-singular. Then, there exist C, D, such that [A, C], [B, D] are non-
singular symmetric pairs and det [A, C, B, D] ̸= 0.
Theorem 3.31. If A =
 A1
A2

is a non-singular symmetric pair, then ∃α ⊂ν, such
that
|IαA1 + IαA2| ̸= 0.

148
2. Symplectic Algebra and Geometry Preliminaries
Theorem 3.32. For two mutually transversal Lagrangian subspaces {A}, {B}, there
always exists a third Lagrangian subspace {C}, transversal to {A} and {B}.
Proof. Take {a1, a2, · · · , an} = {A}, {B} = {b1, b2, · · · , bn}, such that
A′JA = O,
B′JB = O,
A′JB = In,
B′JA = −In.
Set C = A + B. Then,
(A + B)′J(A + B) = (A′ + B′)J(A + B)
= A′JA + A′JB + B′JA + B′JB = O;
and
det [A, A + B] = det [A, B] ̸= 0,
det [B, A + B] = det [A, B] ̸= 0.
The theorem is proved.
▲
Theorem 3.33. For any two Lagrangian subspaces {A}, {B} there exists another
Lagrangian subspace {C}, transversal to {A} and {B}.
Proof. Assume U0 = {A, B} ̸= 0. Take
{a1, · · · , ak} = {A} ⊂{A},
{¯b1, · · · ,¯bk} = {B} ⊂{B},
{c1, · · · , cn−k} = U 0,
such that
{a1, · · · , ak, c1, · · · , cn−k} = {A},
{¯b1, · · · ,¯bk, c1, · · · , cn−k} = {B},
[ai, aj] = 0 = [¯bi,¯bj],
[ai,¯bj] = δij,
i, j = 1, · · · , k.
Set C = {a1 + ¯b1, · · · , ak + ¯bk, d1, · · · , dn−k}, where
[di, dj] = 0,
[di, cj] = δij,
[di, aj] = [di,¯bj] = 0.
Then, {C} is what we want to ﬁnd out.
▲
2.3.4 Special Types of Sp(2n)
Set M = [A, B] =
 A1
B1
A2
B2
!
∈Sp(2n). The following are special types of
Sp(2n).

2.3 Symplectic Space
149
(0)
M ∈Sp(2n) ∩O2n = Un
=⇒M = [A, J−1A], A′JA = On, A′A = In.
(I)
Sp(2n) ∋M =
 
A1
O
O
B1
!
, which are diagonal blocks
=⇒M =
 A1
O
O
A−1
1
′
!
, A1 ∈GL(n, R).
(II)
Sp(2n) ∋M =
 I
B1
O
B2
!
=⇒M =
 I
S
O
I
!
, S′ = S.
(II′)
Sp(2n) ∋M =
 A1
O
A2
I
!
=⇒M =
 I
O
S
I
!
, S′ = S.
(III)
Sp(2n) ∋M = Jα =
 Iα
Iα
−Iα
Iα
!
, α ⊂ν, and symplectic substitution
Jα =
 Iα
Iα
−Iα
Iα
!
.
1.
Several special types
(1)
Sp2n(0).
Sp2n(0) = Sp2n ∩O2n = Un.
Theorem 3.34. M = [A, B] ∈Sp2n(0) = Un ⇔B = J−1A, A′A = I, A′JA
= O.
Proof. Evidently, if A′A = I, A′JA = O. Then, [A, J−1A] ∈Sp2n(0). Conversely,
M = [A, B] ∈Sp2n =⇒A′JA = O, A′JB = I.
M = [A, B] ∈O2n =⇒A′B = O, B′B = I.
A′JA = O
A′B = O
7
=⇒A′(JA + B) = O
B′JA = −I
B′B = I
/
=⇒B′(JA + B) = O
⎫
⎪
⎪
⎪
⎪
⎬
⎪
⎪
⎪
⎪
⎭
=⇒
 A′
B′
!
(JA + B) = O
=⇒M ′(JA + B) = O =⇒JA + B = O =⇒B = J−1A.
The theorem is proved.
▲
Lemma 3.35. There exist polynomials ϕn(A) = ϕn(ajk), ψn(A) = ψn(ajk) in 2n×
n variables a11, · · · , a2n,n with integer coefﬁcients such that

150
2. Symplectic Algebra and Geometry Preliminaries
det [A J′A] = det
 
A1
−A2
A2
A1
!
= (ϕn(A))2 + (ψn(A))2 ≥0,
where
A =
⎡
⎢⎣
a11
· · ·
a1n
...
...
a2n,1
· · ·
a2n,n
⎤
⎥⎦.
Proof.

A1
−A2
A2
A1
 =

A1 + i A2
−A2 + i A1
A2
A1

=

A1 + i A2
−A2 + i A1 −i (A1 + i A2)
A2
A1 −i A2

=

A1 + i A2
O
A2
A1 −i A2

= (A1 + i A2) (A1 −i A2)
= (A1 + i A2) (A1 + i A2)
= (Re|A1 + i A2|)2 + (Im|A1 + i A2|)2
= (ϕn(A))2 + (ψn(A))2 ≥0.
Therefore, the lemma is completed.
▲
Theorem 3.36. M ∈Sp2n(0) = Un ⇒|M| = 1.
Proof. We will prove that
M ′M = I =⇒|M|2 = 1 =⇒|M| = ±1
By Lemma 3.35,
M = [A, J−1A] =⇒|M| ≥0
7
=⇒|M| = 1.
The proof can be obtained.
▲
(2)
Sp2n (I).
M =
 A1
O
O
B1
!
,
in which diagonal blocks ∈GL(n, R),
M =
 A1
O
O
A−1
1
′
!
, A1 ∈GL(n, R), |M| = |A1||A′
1|−1 = 1,
A1 ∈GL(n, R) =⇒A1 = TP, T ′T = In, P ′ = P > 0(positive deﬁnite),
R2n ∋
 
p
q
!
−→M
 
p
q
!
=
 
A1p
(A−1
1 )′q
!
∈R2n,
 A1
O
O
A−1
1
′
!
=
 T
O
O
T
!  P
O
O
P −1
!
,
 T
O
O
T
!
∈On ⊂Un,

2.3 Symplectic Space
151
where
On =
' 
T
O
O
T
!
, T ′T = In
/
= Un ∩GL(n, R) = Sp2n(0) ∩Sp2n(I),
' 
P
O
O
P −1
!
, P ′ = P > 0
/
is not a group,
' P
O
O
P −1
!
, P ′ = P > 0
/
∩Sp2n(0) = {I2n}.
(3)
Sp2n(II).
Sp2n(II) =
' I
S
O
I
!
, S′ = S
/
≃Sp2n(II′) =
' I
O
S
I
!
, S′ = S
/
, which is a multiplicative group
≃SM n = {S, S′ = S}, which is an additive group.
(4)
Sp2n(I, II).
Sp2n(I, II)
=
' Q
QS
O
Q′−1
!
=
 Q
O
O
Q′−1
!  I
S
O
I
!
, Q ∈GL(n, R), S′ = S
/
.
M ∈Sp2n(I,II) =⇒|M| = 1.
Sp2n(II) ∩Sp2n(0) = Sp2n(II′) ∩Sp2n(0) = {I}.
(5)
Sp2n(III).
Jα =
 Iα
Iα
−Iα
Iα
!
,
J′
α = J−1
α
=
 Iα
−Iα
Iα
Iα
!
,
α ⊂ν.
In particular, Jν = J2n, J0 = I2n, |Jα| = 1. {Symplectic Substitution} = {Jα, J′
α}
is not a group. Total number of Jα = 2n, total number of {Jα, J′
α} = 2n+1 −1, and
 
I
O
−S
I
!
= J′
2n
 
I
S
O
I
!
J2n,
which is the bijection from Sp2n(II) to Sp2n(II′).
2.
Some theorems about Sp(2n)
Theorem 3.37. If {A}, {B} ∈Λn, then there exists M ∈Sp(2n), such that MA =
B. Moreover, M{A} = {B}.

152
2. Symplectic Algebra and Geometry Preliminaries
Proof. By Theorem 3.28, there exist C, D ∈M2n,n, such that
[A, C] = MA ∈Sp(2n),
[B, D] = MB ∈Sp(2n).
Set M = MBM −1
A . Then, MMA = MB, i.e., M[A, C] = [B, D]. Therefore, MA
= B.
▲
Theorem 3.38. If {A}, {B} ∈Λn, then there exists
M ∈Sp2n(0) = Un = Sp2n ∩O2n,
such that
M{A} = {B}.
Proof. From the procedure of Grass-Schmidt’s orthogonal normalization, we can get
two matrices C and D of order 2n × n i.e., C, D ∈M(2n, n), such that
{C} = {A},
C′JC = O,
C′C = I.
{D} = {B},
D′JD = O,
D′D = I.
Set MC = [C, J−1C], MD = [D, J′D]. Obviously,
MC, MD ∈Sp2n(0) = Un.
Set M = MDM −1
C . Then, MMC = MD, i.e.,
M[C, J−1C] = [D, J′D].
Thus, MC = D.
We obtain M{C} = {MC} = {D}, i.e., M{A} = {B}.
▲
Theorem 3.39. Let G = CSp(2n), Sp(2n), or Sp2n(0) = Un. Then, the following
action of G on Λn : M{A} = {MA}(A ∈Λn, M ∈G) is
1◦
Transitive, i.e., ∀{A}, {B} ∈Λn, ∃M ∈G, such that M{A} = {B}.
2◦
If for any {A} ∈Λn, M{A} = {A} then M = ±I2n when G = Sp(2n) or
Sp2n(0); and M = μI2n when G = CSp(2n).
Proof. 1◦can be obtained by Theorem 3.37 and Theorem 3.38.
2◦
Assume M =
 A
B
C
D
!
. Taking {A} =
'
I
O
/
,
' O
I
/
∈Λn, respec-
tively, we have
M
'
I
O
/
=
'
I
O
/
and
M
'
O
I
/
=
'
O
I
/
,
i.e., for some Q ∈GL(n),
 A
B
C
D
!  I
O
!
=
 A
C
!
=
 I
O
!
Q =
 Q
O
!
,

2.3 Symplectic Space
153
 
A
B
C
D
!  
O
I
!
=
 
B
D
!
=
 
O
I
!
Q =
 
O
Q
!
,
and so B = C = O. Again, take {A} =
'
I
P
/
, P ′ = P. Then, from the equality
M
'
I
P
/
=
'
I
P
/
,
it follows that
 A
O
O
D
!  I
P
!
=
 A
DP
!
=
 I
P
!
Q =
 Q
PQ
!
,
for some Q ∈GL(n) and ∀P ′ = P, i.e., A = Q, and DP = PQ = PA. Set
P = I, D = A. Then, we get
AP = PA,
∀P ′ = P.
This implies that A = μI(μ ̸= 0) (since |M| ̸= 0). Besides, if M ∈Sp(2n) or
Sp2n(0) then μ2I = I, i.e., μ2 = 1. Therefore, we have M = ±I.
▲
Theorem 3.40. Λn ≃Un/On = Sp2n(0)/Sp2n(0) ∩Sp2n(I), or
ϕ : Un / On −→Λn,
ϕ(MOn) = M
 I
O
!
,
M ∈Un,
is a bijection from Un /On to Λn.
Proof. First, ϕ is well-deﬁned. In fact, if M1On = M2On, or M1 ∈M2On, then
M1 = M2
 T
O
O
T
!
.
For some T’= T, M1
' I
O
/
= M2
 T
O
O
T
!  I
O
!
Q = M2
 T
O
!
Q
= M2
 I
O
!
TQ = M2
' I
O
/
.
It follows from the Theorem 3.38 that ϕ is surjective. We will prove that ϕ is injective.
If M1
' I
O
/
= M2
' I
O
/
, then M −1
2 M1
' I
O
/
=
' I
O
/
.
Set M = M −1
2 M1 =
 A
B
C
D
!
∈Sp2n(0). Then, M
' I
O
/
=
' I
O
/
, i.e.,
 A
B
C
D
!  I
O
!
=
 A
C
!
=
 I
O
!
Q.

154
2. Symplectic Algebra and Geometry Preliminaries
Thus, C = O.
Since
 
A
B
C
D
!
∈Sp2n(0), by Theorem 3.34:
 
B
D
!
= J−1
 
A
O
!
=
 
O
−I
I
O
!  
A
O
!
=
 
O
A
!
and
[A′, O]
 A
O
!
= A′A = I.
This means that M =
 A
O
O
A
!
, A′A = I ∈On.
▲
Theorem 3.41. Λn ≃Sp(2n)/Sp2n(I,II), or the mapping
ϕ : Sp(2n)/Sp2n(I, II) −→Λn,
ϕ(MSp2n(II)) = M
 I
O
!
, M ∈Sp
is a bijection.
Proof. If M1Sp2n(I, II) = M2Sp2n(I, II), then M1 ∈M2Sp2n(I, II), i.e.,
M1 = M2
 Q
QS
O
Q−1′
!
for some Q ∈GL and S ∈SM(n).
Thus,
M1
' I
O
/
= M2
 Q
QS
O
Q−1′
!  I
O
!
P = M2
 Q
O
!
P
= M2
 
I
O
!
QP = M2
'
I
O
/
.
This implies that ϕ is well-deﬁned.
By Theorem 3.37, we know that ϕ is surjective.
Last, ϕ is injective too. As a matter of fact, if M1
' I
O
/
= M2
' I
O
/
, then
M −1
2 M1
' I
O
/
=
' I
O
/
.
Set M = M −1
2 M1 =
 A
B
C
D
!
; then M
' I
O
/
=
' I
O
/
, i.e.,
 A
B
C
D
!  I
O
!
=
 A
C
!
=
 I
O
!
P =
 P
O
!
, for some P ∈GL(n).
Thus, C = O.

2.3 Symplectic Space
155
M =
 
A
B
C
D
!
=
 A
O
O
A−1′
!  
I
B1
O
D1
!
∈Sp(2n),
where B1 = A−1B, D1 = A′D. Since M ∈Sp(2n) and
 A
O
O
A′−1
!
∈Sp(2n),
 
I
B1
O
D1
!
must be symplectic too.
By deﬁnition,
 I
B1
O
D1
!
∈Sp2n(II). Therefore, M ∈Sp2n(I, II).
▲
2.3.5 Generators of Sp(2n)
Theorem 3.42. Every symplectic matrix M can be decomposed as the multiplication
of three kinds of special symplectic matrices
M = M0M1M2,
where
M0 ∈Sp2n(0),
M1 ∈Sp2n(I),
M2 ∈Sp2n(II).
Proof. Let M = [A, B] ∈Sp2n; then {A} ∈Λn. By Theorem 3.38, there exists
M0 ∈Sp2n(0) = Un, such that
A = M0
 I
O
!
Q = M0
 Q
O
!
= M0
 Q
O
O
Q′−1
!  I
O
!
.
Let
B1 =
 Q
O
O
Q′−1
!−1
M −1
0 B,
i.e.,
B = M0
 Q
O
O
Q′−1
!  C1
C2
!
.
Thus,
M = [A, B]
=
 
M0
 Q
O
O
Q′−1
!  
I
O
!
, M0
 Q
O
O
Q′−1
!  
C1
C2
!!
= M0
 Q
O
O
Q′−1
!  
I
C1
O
C2
!
∈Sp(2n)
= M0M1M2,
where M1 =
 Q
O
O
Q′−1
!
∈Sp2n(I),
M2 =
 
I
C1
O
C2
!
∈Sp2n(II).
▲

156
2. Symplectic Algebra and Geometry Preliminaries
Proposition 3.43. |M| = 1, ∀M ∈Sp(2n).
Theorem 3.44. The following decomposition of a symplectic matrix M ∈Sp(2n) is
unique.
M = M0M1M2,
where M0 ∈Sp2n(0), M1 =
 
P
O
O
P −1
!
, P ′ = P > 0, M2 ∈Sp2n(II).
Proof. A non-singular matrix Q ∈GL(n) can be uniquely decomposed as a multi-
plication of an orthogonal matrix T and a positive deﬁnite matrix P : Q = TP. By
Theorem 3.42, we have a decomposition
M = M 0M 1M 2 = M 0
 Q
O
O
Q′−1
!
M 2
= M 0
 T
O
O
T
!  P
O
O
P −1
!
M 2
= M0M1M2,
where
M0 = M 0
 T
O
O
T
!
∈Sp2n(0),
M2 = M 2 ∈Sp2n(II),
M1 =
 P
O
O
P −1
!
,
P ′ = P > 0.
We need to prove that such a decomposition is unique.
▲
Suppose M = M01M11M21 is another decomposition, where
M11 =
 P1
O
O
P −1
1
!
,
P ′
1 = P1 > 0,
M21 =
 I
S1
O
I
!
.
By the equality M0M1M2 = M01M11M21, we have
Sp2n(0) ∋M −1
01 M0 = M11M21M −1
2 M −1
1
=
 P1
O
O
P −1
1
!  
I
S1
O
I
!  I
−S
O
I
!  P −1
O
O
P
!
=
 P1
O
O
P −1
1
!  
I
S1 −S
O
I
!  
P −1
O
O
P
!
=
 P1P −1
P1(S1 −S)P
O
P −1
1
P
!
∈Sp2n(0).
Thus,

2.3 Symplectic Space
157
 P1(S1 −S)P
P −1
1
P
!
= J′
 
P1P −1
O
!
=
 
O
−I
I
O
!  
P1P −1
O
!
=
 
O
P1P −1
!
.
Then, P1(S1 −S)P = O
and P −1
1
P = P1P −1, i.e., S1 = S and P 2
1 = P 2.
Therefore, P1 = P, since P1, P are positive deﬁnite. It follows that, M −1
01 M0 = I,
i.e., M0 = M01. This is what we need to prove.
Theorem 3.45. If M =
 A1
B1
A2
B2
!
∈Sp(2n) with |A1| ̸= 0, then it can be de-
composed as
M = M2′M1M2,
where M2′ ∈Sp2n(II′), M1 ∈Sp2n(I), M2 ∈Sp2n(II).
This leads to |M| = 1.
Proof. By Gauss elimination,
 A1
B1
A2
B2
!  
I
−A−1
1 B1
O
I
!
=
 A1
O
A2
B2 −A2A−1
1 B1
!
,
 
I
O
−A2A−1
1
I
!  A1
O
A2
B2 −A2A−1
1 B1
!
=
 A1
O
O
B2 −A2A−1
1 B1
!
.
M = [A, B] ∈Sp(2n), and so A′JB = I and A′ is a symmetric pair, i.e.,
A′
1B2 −A′
2B1 = I,
A2A−1
1
∈SM.
Thus,
A−1′
1
= B2 −A−1′
1
A′
2B1 = B2 −(A2A−1
1 )′B1 = B2 −A2A−1
1 B1.
Obvioualy,
M1 =
 A1
O
O
B2 −A2A−1
1 B1
!
=
 A1
O
O
A−1′
1
!
∈Sp2n(I),
M2′ =
 I
O
−A2A−1
1
I
!−1
∈Sp2n(II′),
M2 =
 
I
−A−1
1 B1
O
I
!−1
∈Sp2n(II),
by which we get the decomposition M = M2′M1M2.
▲

158
2. Symplectic Algebra and Geometry Preliminaries
Theorem 3.46. Every symplectic matrix M can be decomposed as
M = M3M2′M1M2,
where M3 ∈Sp2n(III), M2′ ∈Sp2n(II′), M1 ∈Sp2n(I), M2 ∈Sp2n(II), and it
reduces |M| = 1 too.
Proof. It follows from that there exists α ⊂ν such that J−1
α
 A1
B1
A2
B2
!
=
 C1
D1
C2
D2
!
with |C1| ̸= 0 and Theorem 3.45.
▲
2.3.6 Eigenvalues of Symplectic and Inﬁnitesimal Matrices
Deﬁnition 3.47. A real polynomial Pm(λ) = a0λm + a1λm−1 + · · · + am is called
reﬂective if Pm(λ) = λmPm(1/λ).
It is easy to see that Pm is reﬂective if and only if ai = am−i (i = 0, · · · , m).
Lemma 3.48. We have the following results:
1◦
Q(λ) = b0λ2 +b1λ +b2 is reﬂective iff b0 = b2, i.e., Q(λ) = b0(λ−α)(λ −
1/α).
2◦
L(λ) = c0λ + c1 is reﬂective iff c0 = c1, i.e., L(λ) = c0(λ + 1).
Property 3.49. We have the following properties:
1◦
P1, P2 reﬂective ⇒P1 · P2 reﬂective.
2◦
P = P1 · P2, P, P1 reﬂective ⇒P2 reﬂective.
3◦
m = 2n, Pm reﬂective ⇒Pm =
n
;
i=1
Qi(λ), Qi reﬂective of order 2.
4◦
m = 2n + 1, Pm reﬂective ⇒Pm = L(λ)
n
;
i=1
Qi(λ), Qi, L reﬂective of
order 2 and 1, respectively.
Lemma 3.50. The characteristic polynomial of a symplectic matrix M ∈Sp(2n),
P(λ) = |M −λI| is reﬂective.
Theorem 3.51. [Arn89,AM78] λ0 is an eigenvalue of a symplectic matrix M with multi-
plicity k. Then, λ−1
0 , λ0, λ
−1
0
are also the eigenvalues of M with the same multiplicity.
If ±1 are the eigenvalues of M, then their multiplicity is even.
Possible cases of distribution of eigenvalues of a symplectic matrix of order 4 are
depicted in Fig. 3.1.
Deﬁnition 3.52. A real polynomial P2n(λ) = a0λ2n + a1λ2n−1 + · · · + a2n is even
if P(λ) = P(−λ).

2.3 Symplectic Space
159
complex saddle
saddle center
real saddle
generic center
(2)
(2)
(4)
(2)
(2)
degenerate saddle
identity
degenerate center
Fig. 3.1.
Distribution of Eigenvalues of a symplectic matrix of Sp(4)
Obviously, P2n(λ) is even iff a2i+1 = 0 (i = 0, 1, · · · , n −1). Every even poly-
nomial P2n(λ) can be rewritten in the following form
P2n(λ) = a0
n
;
i=1
(λ2 −ci).
Lemma 3.53. The characteristic polynomial of every inﬁnitesimal symplectic matrix
is even.
Theorem 3.54. [Arn89,AM78] If λ0 is an eigenvalue of on inﬁnitesimal symplectic matrix
B with multiplicity k, then −λ0, λ0 and −λ0 are the eigenvalues of B with the same
multiplicity. If 0 is an eigenvalue of B, then its multiplicity is even.
The possible cases of distribution of eigenvalues of an inﬁnitesimal symplectic
matrix of order 4 are depicted in Fig. 3.2.

160
2. Symplectic Algebra and Geometry Preliminaries
(2)
(2)
(4)
(2)
(2)
Fig. 3.2.
Distribution of eigenvalues of an inﬁnitesimal symplectic matrix of sp(4)
2.3.7 Generating Functions for Lagrangian Subspaces
Special cases
L =
 S
I

=
' p
q

∈R2n  (p′, q′)J
 S
I

= O
/
(S′ = S)
=
' p
q

∈R2n  (p′, q′)

I
−S

= O
/
=
' p
q

∈R2n  p = Sq
/
=
' p
q

∈R2n  p = ∂ϕ
∂q
/
,
where we deﬁne ϕ(q) = 1
2q′Sq, called as a generating function [Wei77,FWQW89,Fen95,Ge91]
for L.
Remark 3.55. There exists a generating function for Lagrangian subspace transversal
to Rν,0 or R0,ν.
Theorem 3.56. For a non-singular symmetric pair A, there is α ⊂ν such that
det(J−1
α A)2 ̸= 0 and det(J−1
α A)1 ̸= 0, where J−1
α A and J−1
α A are non-singular
symmetric pairs.
Proof. By Theorem 3.14, there exists α ⊂ν such that {A} ˙+{Rα,α} = R2n. This
shows that the matrix
 
Iα
A1
Iα
A2
!
is non-singular.
Multiplying by J−1
α , we have
J−1
α
 
Iα
A1
Iα
A2
!
=
 
Iα
−Iα
Iα
Iα
!  
Iα
A1
Iα
A2
!
=
 
O
(J−1
α A)1
I
(J−1
α A)2
!
.

2.3 Symplectic Space
161
Therefore, det (J−1
α A)1 ̸= 0.
If replace J−1
α
with J−1
α , then det (J−1
α A)2 ̸= 0.
▲
For a general case, we have the following theorem:
Theorem 3.57. For every Lagrangian subspace L = {A} =
'
A1
A2
/
, there exist an
α ⊂ν and a generating function ϕ, a quadratic form in n-variables {pi, qj}i∈α,j∈α
such that
L =
'% p
q
&
∈R2n  pi = ∂ϕ
∂qi , i ∈α; qi = −∂ϕ
∂pi , i ∈α
/
.
Proof. Taking α ⊂ν in Theorem 3.56, the matrix
 B1
B2
!
= B = J−1
α A =
 IαA1 −IαA2
IαA1 + IαA2
!
is Lagrangian with |B2| ̸= 0. Deﬁne
 u
v
!
= J−1
α
 p
q
!
=
 Iαp −Iαq
Iαp + Iαq
!
;
then,
ui =
' pi,
i ∈α,
−qi,
i ∈α,
vi =
' pi,
i ∈α,
qi,
i ∈α,
[p′, q′]J
 A1
A2
!
=
 p
q
!′
Jα(J−1
α JJα)J−1
α
 A1
A2
!
=
 
J−1
α
 p
q
!!′
J
 B1
B2
!
= [u′, v′] J
 S
I
!
B2,
where S = B1B−1
2 , S′ = S, and J−1
α
= J′
α ∈Sp(2n). Thus, if we deﬁne ϕ(v) =
1
2v′Sv, then
L =
' 
p
q
!
∈R2n
 [p′, q′]J
 
A1
A2
!
= O
/
=
' 
u
v
!
∈R2n
 [u′, v′]J
 
S
I
!
= O
/
=
' 
u
v
!
∈R2n
u = Sv
/
=
' 
u
v
!
∈R2n
u = ∂ϕ
∂v
/
=
' 
p
q
!
∈R2n

 
p
q
!
= Jα
 
u
v
!
, u = ∂ϕ
∂v
/
=
' 
p
q
!
∈R2n
 pi = ∂ϕ
∂qi , i ∈α; qi = −∂ϕ
∂pi , i ∈α
/
.
Therefore, the theorem is completed.
▲

162
2. Symplectic Algebra and Geometry Preliminaries
2.3.8 Generalized Lagrangian Subspaces
In the previous sections, we have considered in detail the special symplectic space
with the special symplectic structure
ωJ(x, y) = ϕJ(x, y) = x′Jy,
J =
 
O
I
−I
O
!
.
For every non-singular anti-symmetric matrix K of order 2n, ωK(x, y) = ϕK(x, y) =
x′Ky is a symplectic structure on R2n, and so (R2n, ωK) is also a symplectic space.
Several previous results can be directly applied to this case. Here, we only give a few
different theorems [FW91b,FWQW89].
Deﬁnition 3.58. {A}(or A) is called as a K-Lagrangian subspace, if A′KA =
0, and A is non-singular.
Let us denote:
Λn(K) = {{A} | {A} is a K-Lagrangian subspace} ,
Sp(K, 2n) = {M ∈M(2n) | M ′KM = K} ,
CSp(K, 2n) = {M ∈M(2n) | M ′KM = μK, μ ̸= 0} .
Elements of Sp(K, 2n) or CSp(K, 2n) are called as K-symplectic matrices and
conformally K-symplectic matrices respectively.
Theorem 3.59. Let M be non-singular.
1◦
M ∈CSp(K, 2n), iff A ∈Λn(K) ⇒MA ∈Λn(K).
2◦
M ∈Sp(K, 2n), iff (MA)′K(MB) = A′KB
or
ϕk(MA, MB) = ϕk(A, B),
∀A, B ∈Λn(K).
Proof. 1◦
“⇒” is trivial. We know that for any non-singular anti-symmetric matrix
K, there exists Q ∈GL such that K = Q′JQ, where J =
% O
I
−I
O
&
. Thus,
A′KA = A′Q′JQA = (QA)′J(QA),
(MA)′K(MA) = A′M ′Q′JQ(MA)
= A′Q′Q′−1M ′Q′JQMQ−1QA
= (QA)′(QMQ−1)′J(QMQ−1)(QA).
A ∈Λn(K) =⇒MA ∈Λn(K) ⇐⇒QA ∈Λn(J) =⇒QMQ−1 ∈QA ∈Λn(J).
By Theorem 3.23, we get QMQ−1 ∈CSp(J), i.e.,
(QMQ−1)′J(QMQ−1) = μJ,
μ ̸= 0.
This leads to M ′Q′JQM = μQ′JQ, i.e., M ′KM = μK.

2.3 Symplectic Space
163
2◦
Similarly, we only need to prove the sufﬁciency. By 1◦, we have M ′KM =
μK, μ ̸= 0. Thus, ∀A, B ∈Λn(K), we have
A′KB = μ−1A′M ′KMB = μ−1A′KB.
Taking A and B ∈Λn(K) such that A′KB ̸= 0, we get μ = 1. Therefore,
M ′KM = K.
The theorem is proved.
▲
Deﬁnition 3.60. Let K1 and K2 be two non-singular, anti-symmetric matrices of or-
der 2n. Deﬁne
Sp(K1, K2) = {M ∈M(2n) | M ′K1M = K2} ,
CSp(K1, K2) = {M ∈M(2n) | ∃μ ̸= 0, s.t. M ′K1M = μK2} .
Remark 3.61. Sp(K1, K2) and CSp(K1, K2) are not groups. However,
Sp(K2, K1) = Sp(J),
CSp(K2, K1) = CSp(J)
have the same power. In fact, ∃Q1, Q2 ∈GL, such that K1 = Q′
1JQ1, K2 =
Q′
2JQ2,
M ′K2M = K1 ⇐⇒M ′Q′
2JQ2M = Q′
1JQ1,
i.e.,
Q−1
1
′M ′Q′
2JQ2MQ−1
1
= J.
It is equivalent to Q2MQ−1
1
∈Sp(J). Hence, the mapping: M ∈Sp(K2, K1) →
Q2MQ−1
1
∈Sp(J) is a one-to-one correspondence. It is also a one-to-one correspon-
dence between CSp(K2, K1) and CSp(J).
In addition, M can be viewed as a mapping from Λn(K2) to Λn(K1):
M : Λn(K2) −→Λn(K1), A ∈Λn(K2) −→MA ∈Λn(K1).
We have the following theorem similar to Theorem 3.23 and Theorem 3.59.
Theorem 3.62. Let M be non-singular. Then,
1◦
M ∈CSp(K2, K1), iff MA ∈Λn(K1), ∀A ∈Λn(K2).
2◦
M ∈Sp(K2, K1), iff (MA)′K1(MB) = A′K2B, ∀A, B ∈Λn(K2).
Proof. The proof is omitted, as it is similar to the proof of Theorem 3.59.
▲

Bibliography
[AM78] R. Abraham and J. E. Marsden: Foundations of Mechanics. Reading, MA: Addison-
Wesley, Second edition, (1978).
[Arn89] V. I. Arnold: Mathematical Methods of Classical Mechanics. Springer-Verlag, GTM
60, Berlin Heidelberg, Second edition, (1989).
[Art57] E. Artin: Geometrical Algebra. Interscience Publishers, New York, Second edition,
(1957).
[Car65] C. Carathe’odory: Calculus of Variation and Partial Differential Equations of First
Order, Vol.I. Holden-Day, San Franscisco, (1965).
[Fen95] K. Feng: Collected Works of Feng Kang. Volume I, II. National Defence Industry
Press, Beijing, (1995).
[FQ91] K. Feng and M.Z. Qin: Hamiltonian Algorithms for Hamiltonian Dynamical Systems.
Progr. Natur. Sci., 1(2):105–116, (1991).
[FW91] K. Feng and D.L. Wang: Symplectic Difference Schemes for Hamiltonian Systems in
General Symplectic Structures. J. Comput. Math., 9(1):86–96, (1991).
[FWQW89] K. Feng, H. M Wu, M.Z. Qin, and D.L. Wang: Construction of canonical dif-
ference schemes for Hamiltonian formalism via generating functions. J. Comput. Math.,
7:71–96, (1989).
[Ge91] Z. Ge: Equivariant symplectic difference schemes and generating functions. Physica
D, 49:376–386, (1991).
[HW63] L.G. Hua and Z.X. Wan: Classical Groups. Shanghai Science and Technology Pub-
lishing House, in Chinese, Shanghai, (1963).
[LM87] P. Libermann and C.M. Marle: Symplectic Geometry and Analytical Mechanics. Rei-
del pub. company, Boston, First edition, (1987).
[Tre75] F. Treves: Pseudo-Differential Operator. Acad.Press, New York, First edition, (1975).
[Wei77] A. Weinstein: Lectures on symplectic manifolds. In CBMS Regional Conference, 29.
American Mathematical Society, Providence, RI, (1977).
[Wey39] H. Weyl: The Classical Groups. Princeton Univ. Press, Princeton, Second edition,
(1939).
[Wey40] H. Weyl: The method of orthogonal projection in potential theory. Duke Math. J.,
7:411–444, (1940).

Chapter 3.
Hamiltonian Mechanics and Symplectic
Geometry
Hamiltonian mechanics is geometry in phase space. Phase space has the structure of a
symplectic manifold.
3.1 Symplectic Manifold
A symplectic manifold is a smooth manifold M equipped with a closed, nondegener-
ate, 2-form called the symplectic form. On a symplectic manifold, as on a Riemannian
manifold, there is a natural isomorphism between the vector ﬁeld and the 1-form. Sym-
plectic manifolds arise naturally in abstract formulations of classical mechanics and
analytical mechanics as the cotangent bundles of manifolds, e.g., in the Hamiltonian
formulation of classical mechanics, which provides one of the major motivations for
the ﬁeld. The set of all possible conﬁgurations of a system is modelled as a manifold,
and this manifold’s cotangent bundle describes the phase space of the system.
Any real-valued differentiable function H on a symplectic manifold can serve as
an energy function or Hamiltonian. Associated to any Hamiltonian is a Hamiltonian
vector ﬁeld; the integral curves of the Hamiltonian vector ﬁeld are solutions to the
Hamilton–Jacobi equations. The Hamiltonian vector ﬁeld deﬁnes a ﬂow on the sym-
plectic manifold, called a Hamiltonian ﬂow or symplectomorphism. By Liouville’s
theorem, Hamiltonian ﬂows preserve the volume form on the phase space. The vector
ﬁelds on a manifold form a Lie algebra. The Hamiltonian vector ﬁelds on a symplectic
manifold form a Lie algebra. The operation in this algebra is called Poisson bracket.
3.1.1 Symplectic Structure on Manifolds
Deﬁnition 1.1. Let M2n be an even-dimensional differential manifold. A symplectic
structure on M2n is a closed nondegenerate differential 2-form ω on M2n[AM78,Arn89].
1◦
d ω = 0 is closed.
2◦
∀x ∈M, ∃ξ ∈TxM, s.t., if
ω(ξ, η) = 0,
∀η ∈TxM,
then ξ = 0 (nondegenerate).
The pair (M, ω) is called a symplectic manifold. We call it a presymplectic (almost
symplectic) manifold, if only condition 1◦(2◦) is satisﬁed.

166
3. Hamiltonian Mechanics and Symplectic Geometry
Example 1.2. Consider the vector space R2n with coordinates (pi, qi). Let ω =
n

i=1
d pi ∧d qi. Then, ω deﬁnes a symplectic structure. Given two tangent vectors
ξj = (ξj
1, · · · , ξj
n; ηj
1, · · · , ηj
n),
j = 1, 2,
we have
ω(ξ1, ξ2) =
n

i=1
η1
i · ξ2
i −η2
i · ξ1
i .
This example shows that any symplectic manifold can have standard symplectic
structure at least locally.
Exercise 1.3. Verify that (R2n, ω) is a symplectic manifold. For n = 1, ω becomes
an area measure on a plane.
3.1.2 Standard Symplectic Structure on Cotangent Bundles
Let M be an n-dimensional differential manifold. A 1-form on TxM, the tangent
space to M at a point x, is called a cotangent vector to M at x. The set of all cotan-
gent vectors to M at x forms an n-dimensional vector space, dual to the tangent space
TxM. We will denote this vector space of cotangent vectors by T ∗
xM and call it the
cotangent space to M at x. The union of the cotangent space to the manifold at all of
its points is called cotangent bundle, denoted as T ∗M. Let (q1, · · · , qn) be the local
coordinates of Mand (p1, · · · , pn) be the coordinates of the ﬁber. Then (q, p) becomes
a local coordinate of T ∗M, and T ∗M is equipped with a structure of differential mani-
fold. Locally, ω =
n

i=1
dpi∧dqi is a natural symplectic structure of T ∗M [AM78,Arn89]. In
order to give a coordinate-free deﬁnition of the form ω, we ﬁrst deﬁne a distinguished
1-form on T ∗M. Let π : T ∗M →M be a natural projection. Let ξ ∈Tp(T ∗M) be
a vector tangent to the cotangent bundle at the point p ∈T ∗
xM. The derivative taken
tangent mapping π∗: Tp(T ∗M) →Tπ(p)M of the natural projection π : T ∗M →M
takes ξ to a vector π∗(ξ) tangent to M at x = π(p). We deﬁne the 1-form σ on T ∗M
by the relation σ = p(π∗(ξ)), which has a form under the local coordinate as follows
ξ =
n

i=1
ai
∂
∂pi
+ bi
∂
∂qi
,
π∗(ξ) =
n

i=1
bi
∂
∂qi
.
Therefore, p(π∗(ξ)) =
n

i=1
pibi, which results in
σ =
n

i=1
pidqi,
ω = dσ =
n

i=1
dpi ∧dqi.

3.1 Symplectic Manifold
167
3.1.3 Hamiltonian Vector Fields
As we pointed out in Section 2.3 of Chapter 2, the symplectic structure of a symplectic
space is similar to a Euclidean structure in some aspects. The symplectic structure
on a symplectic manifold is also similar to a Riemann structure, which deﬁnes the
Euclidean structure on a tangent space so that the tangent space becomes isomorphic
to the cotangent space. The same is true for a symplectic structure. Let (M, ω) be a
symplectic manifold; ∀η ∈TxM, there exists a linear form on TxM: TxM ∋ξ →
ω(ξ, η); therefore, ω( · , η) deﬁnes an element of the cotangent space. Thus, we get a
linear mapping Ω : TxM →T ∗
xM, η →ω( · , η). The non-degeneracy of ω shows
that Ω is an injective. Since TxM and T ∗
xM have the same dimensions, Ω must be an
isomorphism, i.e.,
ω(ξ, η) = (Ωη)ξ.
Using the local coordinates, we can set (M, ω) = (R2n, d p ∧d q). For ξ = (q1, · · ·,
qn; p1, · · · , pn), η = (q′
1, · · · , q′
n; p′
1, · · · , p′
n), (Ωη)ξ = ω(ξ, η) =
n

i=1
piq′
i −p′
iqi,
Ω has a matrix representation as
 O
−I
I
O
!
, i.e., Ω = −J, Ω−1 = J.
Although the above results are deﬁned for the tangent and cotangent space at a
speciﬁc point x ∈M, they can be easily extended to the entire tangent and cotangent
bundle. Let θ be a 1-form on M, i.e., a C∞section on T ∗M. Ω−1θ should be on
a vector ﬁeld on M, i.e., a section on TM. One of the most important cases is when
θ = dH is an exact differential form, i.e., θ is a C∞total differential on M. We denote
it by Ω−1 = J.
We often say that JdH is Hamiltonian vector ﬁeld [AM78,Arn89] with Hamilto-
nian function H, which can be represented using the local coordinate as (M, ω) =
(R2n, dp ∧dq).
We will use J :
T ∗M →TM∗to denote the above isomorphism. Let H be a
function on the symplectic manifold M 2n. Then, dH is a 1-form on M, and at every
point there exists a tangent vector associated with it. Thus, we can obtain a vector ﬁeld
JdH on M. From
J =
5
O
I
−I
O
6
,
d H = Hq d q + Hp d p,
we obtain the Hamiltonian vector ﬁeld
JdH =
5
O
I
−I
O
6 5
Hq
Hp
6
=
5
Hp
−Hq
6
,
which has an expression under local basis for the tangent ﬁeld
Hp
∂
∂q −Hq
∂
∂p.

168
3. Hamiltonian Mechanics and Symplectic Geometry
3.1.4 Darboux Theorem
Symplectic geometry arises from the globalization of the symplectic algebra consid-
ered in the previous chapter. First, we prove Darboux’s theorem, according to which
every symplectic manifold has local coordinates p, q in which the symplectic structure
can be written in the simplest way ω = dp ∧dq.
Theorem 1.4 (Darboux theorem). Let ω be a closed non-degenerate 2-form on a
manifold M 2n. Then, dω = 0 iff there exists a local coordinate system (u, ϕ) for
every m ∈M, such that
ϕ(m) = 0,
ϕ(u) = (x1(u), · · · , xn(u), y1(u), · · · , yn(u)),
and
ω|u =
n

i=1
d xi ∧d yi.
Proof. The sufﬁciency can be easily derived, since
n

i=1
dxi ∧dyi is a closed form.
Necessity. We ﬁrst assume that M = E is a linear space, and m = 0 ∈E.
Let ω1 be the constant-form ω(0), "ω = ω1 −ω, ωt = ω + t"ω (0 ≤t ≤1).
For each t, ωt(0) = ω(0) is nondegenerate. Hence, by the openness of the set of
isomorphisms from E to E∗, there exists a neighborhood of 0 on which ωt (0 ≤
t ≤1) is nondegenerate for all 0 ≤t ≤1. We can assume that this neighborhood
is a ball. Thus by Poincar´e lemma, there exists a 1-form θ s.t. "ω = dθ. Without loss
of generality, we assume θ(0) = 0. Since ωt is nondegenerate, there exists a smooth
vector ﬁeld X, s. t. iXωt = −θ. Since Xt(0) = 0, from the local existence theory
of ODEs, there is a sufﬁciently small ball on which the integral curves of Xt are
well deﬁned for t ∈[0, 1]. Let Ft be the ﬂow starting at F0 = identity. By the Lie
derivative formula for a time-dependent vector ﬁeld, we have
d
d t(F ∗
t ωt) = F ∗
t (LXtωt) + F ∗
t
d
d tωt
= F ∗
t d iXtωt + F ∗
t "ω = F ∗
t (−d θ + "ω) = 0.
Therefore, F ∗
1 ω1 = F ∗
0 ω = ω. So F1 provides the chart transforming ω to the constant
form ω1.
▲
3.2 Hamiltonian Mechanics on R2n
Darboux theorem shows that every symplectic manifold of dimension 2n is locally
identiﬁed with the standard symplectic manifold (R2n, ω). Thus, the results obtained
in (R2n, ω) can be locally transferred to any ﬁnite-dimensional symplectic manifolds.
Therefore, in this section, we only consider Hamiltonian systems in R2n with the
standard symplectic structure ω = dp ∧dq.

3.2 Hamiltonian Mechanics on R2n
169
3.2.1 Phase Space on R2n and Canonical Systems
1.
1-form and 2-form in R2n
In R2n, we denote
z = (z1, · · · , zn, zn+1, · · · , z2n)′
= (p1, · · · , pn, q1, · · · , qn)′
=
5
p
q
6
∈R2n,
where the prime indicates the matrix transpose.
Deﬁnition 2.1. A fundamental differential 1-form and 2-form in R2n are deﬁned by
the following formulae:
1-form : θ =
n

i=1
pi d qi =
n

i=1
zi d zn+i;
2-form : ω = d θ = d p ∧d q =
n

i=1
d pi ∧d qi =
n

i=1
d zi ∧d zn+i.
Thus, it can be seen that ω satisﬁes the following propoties:
1◦
Closed: d ω = d d θ = 0.
2◦
Non-degenerate: ω(ξ, η) = 0, ∀η ∈TzR2n ⇒ξ = 0, ∀z ∈R2n.
3◦
Anti-symmetric: ω(ξ, η) = −ω(η, ξ), ∀ξ, η ∈TzR2n, z ∈R2n.
Any differential 2-form satisfying the conditions 1, 2 and 3 is called a symplectic
structure in R2n. ω is called the standard symplectic structure in R2n. θ is called the
standard 1-form. R2n equipped with ω is called the symplectic space, or symplectic
manifold, denoted by (R2n, ω), or brieﬂy, R2n.
Let ξ =
2n

i=1
ξi
∂
∂zi ,
η =
2n

i=1
ηi
∂
∂zi ∈TzR2n. Then,
ω(ξ, η) =
n

i=1
d zi ∧d zn+i(ξ, η) =
n

i=1
(ξiηn+i −ηiξn+i)
= (ξ1, · · · , ξ2n)
5
O
In
−In
O
6 ⎡
⎢⎣
η1
...
η2n
⎤
⎥⎦
= ξ′Jη,
(2.1)
where J =
 
O
In
−In
O
!
, and (ξ1, · · · , ξ2n)′ represents the vector ξ ∈TzR2n con-
sisting of components ξi. The Equation (2.1) is the matrix representation of the 2-form
ω on TzR2n.
2.
Hamiltonian vector ﬁelds on R2n

170
3. Hamiltonian Mechanics and Symplectic Geometry
To each vector ξ, tangent to the symplectic manifold (R2n, ω) at the point z, we
associate a 1-form ω1
ξ on TzR2n by the formula
ω1
ξ(η) = ω2(η, ξ),
∀η ∈TzR2n.
We denote this correspondence by
Ω : TzR2n −→T ∗
z R2n,
i.e.,
ω1
ξ(η) = Ωξ(η) = ω2(η, ξ) = (−iξω)η,
∀η ∈TzR2n,
or
ω1
ξ = Ωξ = −iξω.
From the equation ω(η, ξ) = η′Jξ = (Jξ)′η, it follows that
ω1
ξ = Ωξ = Jξ
or
ω1
ξ = Ωξ =
2n

i=1
(Jξ)i dzi
= ξn+1 d z1 + · · · + ξ2n d zn −ξ1 d zn+1 −ξn d z2n.
Obviously, Ω is an isomorphism from the tangent space TzR2n into the cotangent
space T ∗
z R2n. This naturally induces a mapping from X(R2n) into Ω1(R2n):
ω1
X = Ω(X)(z) = Ω(X(z)) = −iXω,
∀X ∈X(R2n).
In particular, if H ∈C∞(R2n), then dH ∈Ω1(R2n), Ω−1dH is a vector ﬁeld on
R2n, and we denote it as XH.
Deﬁnition 2.2. The vector ﬁeld XH = Ω−1dH is called a Hamiltonian vector ﬁeld,
and H is called the Hamiltonian function.
If we write d H = (Hz1, · · · , Hz2n)′ = Hz, then
XH = J−1Hz,
d H = ΩXH = −iXω.
3.
Canonical systems
Now, we consider a canonical equation in R2n.
Deﬁnition 2.3.
d z
d t = J−1Hz
(2.2)
or
d p
d t = −Hq,
d q
d t = Hp.
(2.3)

3.2 Hamiltonian Mechanics on R2n
171
Since J−1Hz is the matrix representation of a Hamiltonian vector ﬁeld Ω−1d H =
XH, the Equation (2.2) can be rewritten as
d z
d t = XH(z).
(2.4)
The phase ﬂow of the Hamiltonian vector ﬁeld is denoted as φt
H, and called the
Hamiltonian phase ﬂow.
Theorem 2.4. A Hamiltonian phase ﬂow preserves the symplectic structure :
(φt
H)∗ω = ω.
Proof. Since
d
d t(φt
H)∗ω =
d
d s(φt+s
H )∗
s=0ω
=
d
d s(φt
H)∗· (φs
H)∗
s=0ω
= (φt
H)∗LXHω,
and
LXHω = (iXHd + d iXH)ω = iXHd ω + d iXHω
= 0 + (−d (dH)) = 0,
we have
d
d t(φt
H)∗ω = 0,
i.e.,
(φt
H)∗ω = (φt
H)∗
t=0ω = ω.
The theorem is proved.
▲
4.
Integral invariants[Arn89]
Let g : R2n →R2n be a differentiable mapping.
Deﬁnition 2.5. A differential k-form ωk is called an integral invariant of the map g,
if the integrals of ω on any k-chain c and on its image under g are the same, i.e.,
-
gc
ωk =
-
c
ωk.
Example 2.6. If n = 1, ω2 = d p ∧d q is the area element, then ω2 is the integral
invariant of the map whose Jacobian determinant is equal to 1.
Theorem 2.7. A k-form ωk is an integral invariant of a map g if and only if
g∗ωk = ωk.

172
3. Hamiltonian Mechanics and Symplectic Geometry
The proof is left for the reader to derive as a separate exercise.
Theorem 2.8. If the forms ωk and ωl are integral invariants of the map g, then the
form ωk ∧ωl is also an integral invariant of g.
This follows immediately from the Theorem 2.7.
Theorem 2.9. Let ω2 be a standard symplectic structure. Then, ω2, (ω2)2 = ω2 ∧
ω2, (ω2)3 = ω2 ∧ω2 ∧ω2, · · · are all the integral invariants of a Hamiltonian phase
ﬂow.
We deﬁne a volume element on R2n using (ω2)n. Then, a Hamiltonian phase ﬂow
preserves volume, and we obtain Liouville’s theorem from the Theorem 2.4. Since the
form (ω2)k is proportional to
ω2k =

i1<···<ik
dpi1 ∧· · · ∧dpik ∧dqi1 ∧· · · ∧dqik,
the integral of ω2k is equal to the sum of the oriented volume of projections onto
the coordinate planes (pi1, · · · , pik, qi1, · · · , qik). Therefore, a Hamiltonian phase ﬂow
preserves the sum of the oriented area as projections onto the coordinate planes
(pi1, · · · , pik, qi1, · · · , qik) (1 ≤k ≤n).
3.2.2 Canonical Transformation
Deﬁnition 2.10. [Arn89] A diffeomorphism g : R2n →R2n, z = g(z) is called a
canonical transformation on R2n, if for every z ∈R2n, M = ∂z
∂z ∈Sp(2n).
It is easy to see that a linear canonical transformation is a symplectic transforma-
tion.
Theorem 2.11. A diffeomorphism g is canonical if and only if g preserves ω, i.e.,
g∗ω = ω. In other words, if we denote z = g(z) =
 P(z)
Q(z)

, i.e.,
z =
5
p
q
6
g
−→
5
P(z)
Q(z)
6
= z,
then g is canonical iff d P ∧d Q = d p ∧d q.
Thus, a Hamiltonian phase ﬂow φt
H is a one-parameter group of canonical trans-
formations on R2n.
Proof. For every ξ, η ∈TzR2n,
(g∗ω)(ξ, η) = ω(g∗ξ, g∗η) = ξ′M ′JMη,
where M = g∗= ∂g
∂z is Jacobian of g.

3.2 Hamiltonian Mechanics on R2n
173
g canonical
⇐⇒M ′JM = J,
∀z ∈R2n,
⇐⇒ξ′M ′JMη = ξ′Jη,
∀ξ, η ∈TzR2n, z ∈R2n,
⇐⇒g∗ω(ξ, η) = ω(ξ, η),
∀ξ, η ∈TzR2n,
⇐⇒g∗ω = ω.
Therefore, the theorem is completed.
▲
Deﬁnition 2.12. A diffeomorphism g : R2n →R2n is conformally canonical if its
Jacobian M(z) = ∂g(z)
∂z
∈CSp(2n), ∀z ∈R2n.
Besides the parameters above, a canonical transformation g(z) can be determined
by whether or not it transforms every canonical equation into a canonical equation.
We ﬁrst consider a conformally canonical transformation.
Let z = g(z, t) be a time-dependent transformation and M(z, t) =
∂z
∂z
=
∂g(z, t)
∂z
, the Jacobian of g(z, t) with respect to z.
Theorem 2.13. The time-dependent transformation z = g−1(z, t) : R2n →R2n
transforms every canonical equation
d z
d t = J−1 Hz(z),
with the Hamiltonian H(z) into a canonical equation
d z
d t = J−1Hz(z),
with some Hamiltonian H(z), iff M(z, t) = ∂z
∂z satisﬁes
M ′JM = μJ,
where μ ̸= 0, independent of z and t.
Proof.
d z
d t = ∂z
∂z
d z
d t + ∂g
∂t = M d z
d t + ∂g
∂t .
Set H(z) = H(g(z, t), t) = H ◦g; then Hz =
∂z
∂z
′ Hz. Thus, from the equation
d z
d t = J−1 Hz,
we have
M d z
d t + ∂g
∂t = J−1M −1′Hz,

174
3. Hamiltonian Mechanics and Symplectic Geometry
i.e.,
d z
d t
= M −1 
J−1M −1′Hz −∂g
∂t

= J−1 
JM −1J−1M −1′Hz −JM −1 ∂g
∂t

= J−1(u + v),
where u = BHz, B = JM −1J−1M −1′, v = C ∂g
∂t , C = −JM −1, and u depends
on the Hamiltonian H as well as on z, and v depends only on z.
For every H ∈C∞(R2n), there exists another function H(z), such that
d z
d t = J−1Hz,
iff there exists a function H(z) ∈C∞(R2n), such that
u + v = ∂H
∂z ,
i.e., u + v is a gradient transformation. We know that a Jacobian matrix which equals
to u + v and ∂(u + v)
∂z
is symmetric, i.e.,
∂ui
∂zk + ∂vi
∂zk = ∂uk
∂zi + ∂vk
∂zi ,
∀H(z),
i, k = 1, · · · , 2n.
In the above equation , taking H as a constant, we get
∂vi
∂zk = ∂vk
∂zi ,
i, k = 1, · · · , 2n.
(2.5)
Consequently,
∂ui
∂zk = ∂uk
∂zi ,
∀H(z),
i, k = 1, · · · , 2n.
(2.6)
Notice that ui = (BHz)i =
2n

j=1
BijHzj, (2.6) becomes
∂
∂zk
 2n

j=1
Bij
∂H
∂zj

=
∂
∂zi
 2n

j=1
Bkj
∂H
∂zj

.
(2.7)
Expanding it, we get
2n

j=1
∂Bij
∂zk
∂H
∂zj +
2n

j=1
Bij
∂2 H
∂zk∂zj =
2n

j=1
∂Bkj
∂zi
∂H
∂zj +
2n

j=1
Bkj
∂2 H
∂zi∂zj .
(2.8)
Take H(z) = zl ◦g−1(l = 1, · · · , 2n), then H(z) = zl (l = 1, · · · , 2n). By this,
Equation (2.8) gets split into classes of equations:

3.2 Hamiltonian Mechanics on R2n
175
∂Bij
∂zk
= ∂Bkj
∂zi ,
i, k, j = 1, · · · , 2n,
(2.9)
2n

j=1
Bij
∂2 H
∂zk∂zj =
2n

j=1
Bkj
∂2 H
∂zi∂zj ,
i, k = 1, · · · , 2n.
(2.10)
Set A =
∂2 H
∂zk ∂zj . Obviously, A is symmetric, i.e., A′ = A. Then, (2.10) indicates
BA = (BA)′ = A′B′ = AB′,
∀A′ = A.
This implies
B = μ(z, t)I,
(2.11)
where μ ̸= 0. Since |B| ̸= 0, or
Bij = μ(z, t)δij.
Substituting it into (2.9), we get
∂μ
∂zk δij = ∂μ
∂zi δkj,
i, j, k = 1, · · · , 2n.
(2.12)
From this, it follows that
∂μ
∂zi = 0,
i = 1, · · · , 2n,
i.e., μ = μ(t) is independent of z. Thus, JM −1J−1M −1′ = B = μ(t)I, i.e.,
M ′JM = μ−1(t)J, M is conformally symplectic with μ−1(t).
We now prove that μ is independent of t. Since
JM −1J−1M −1′ = μ(t)I,
C = −JM −1 = −μ(t)M ′J,
Cij = −μ(t)∂zl
∂zi Jlj,
v = C ∂g
∂t ,
we have
vi = Cij
∂gj
∂t = −μ(t)∂zl
∂zi Jlj
∂gj
∂t ,
∂vi
∂zk
=
∂
∂zk

−μ(t)∂zl
∂zi Jlj
∂gj
∂t

= −μ(t)
 ∂2 zl
∂zk∂zi Jlj
∂gj
∂t + ∂zl
∂zi Jlj
∂2gj
∂zk∂t

.
Then, the system (2.5)
∂vi
∂zk = ∂vk
∂zi ,
i, k = 1, · · · , 2n
is equivalent to

176
3. Hamiltonian Mechanics and Symplectic Geometry
−μ(t)
 ∂2 zl
∂zk∂zi Jlj
∂gj
∂t + ∂zl
∂zi Jlj
∂2 gj
∂zk∂t

= μ(t)
 ∂2 zl
∂zi∂zk Jlj
∂gj
∂t + ∂zl
∂zk Jlj
∂2 gj
∂zi∂t

,
i.e.,
∂zl
∂zi Jlj
 ∂zj
∂zk

t = ∂zl
∂zk Jlj
∂zj
∂zi

t,
i.e.,
(M ′JMt)ik = (M ′JMt)ki,
which shows show that M ′JMt is a symmetric matrix. Therefore,
M ′JMt = (M ′JMt)′ = M ′
tJ′M = −M ′
tJM.
Then, we have
(M ′JM)t = M ′
tJM + M ′JMt = M ′
tJM −M ′
tJM = 0.
However, M ′JM = μ(t)J, and so it follows that μ(t) = μ =constant. Consequently,
M ′JM = μJ, μ independent of z and t.
▲
In particular, if g is independent of t, then v = 0 and u = μHz(z). Thus, we
obtain the following Theorem 2.14.
Theorem 2.14. A transformation g(z) = z : R2n →R2n is conformally canonical
with μ independent of z iff z = g−1(z) transforms every canonical system
d z
dt = J−1 Hz
with the Hamiltonian H(z) into a canonical system
d z
d t = J−1Hz(z),
with the Hamiltonian H(z) = μ H(g(z)) = μ H ◦g.
For a further transform, we obtain Theorem 2.15.
Theorem 2.15. A transformation z = g(z) : R2n →R2n is canonical iff g−1 trans-
forms a canonical system
d z
d t = J−1 Hz
with the Hamiltonian H(z) into a canonical system
d z
d t = J−1Hz,
with Hamiltonian H(z) = H(g(z)) = H ◦g.

3.2 Hamiltonian Mechanics on R2n
177
3.2.3 Poisson Bracket
1.
Poisson bracket
Deﬁnition 2.16. The Poisson bracket {φ(z), ψ(z)} of smooth functions φ(z) and
ψ(z) on R2n is also a smooth function on R2n, deﬁned by the formula
{φ, ψ}(z) = φ′
zJ−1ψz = [φ′
p, φ′
q]
5
O
−I
I
O
6 5
ψp
ψq
6
= −(φ′
pψq −φ′
qψp).
Property 2.17. Let φ, ψ, χ be smooth functions on R2n, then the Poisson bracket has
following basic properties:
1◦
anti-symmetric: {φ, ψ} = −{ψ, φ}.
2◦
bilinear: {αφ + βψ, χ} = α{φ, χ} + β{ψ, χ}, α, β ∈R.
3◦
Jacobi identity: {{φ, ψ}, χ} + {{ψ, χ}, φ} + {{χ, φ}, ψ} = 0.
1◦and 2◦are self-evident. The Jacobi identity can be proved by direct computa-
tion, but it also follows from the following proposition and the corresponding Jacobi
identity of the vector ﬁeld.
Proposition 2.18. Let φ and ψ be smooth functions on R2n. Then,
1◦
{φ, ψ} = −ω(Xφ, Xψ).
2◦
{φ, ψ} = d φ(Xψ) = iXφω(Xψ).
3◦
{φ, ψ} = iXφiXψω .
4◦
{φ, ψ}(z) = d
d t

t=0φ(φt
ψz) = LXψφ(z).
5◦
Ω−1d {φ, ψ} = −[Ω−1d φ, Ω−1d ψ] = −[Xφ, Xψ] ⇔X{φ,ψ} = −[Xφ, Xψ],
where Xφ = Ω−1d φ is the Hamiltonian vector ﬁeld of a Hamiltonian function φ.
Each of the equalities 1◦, 2◦, 3◦and 4◦can be a deﬁnition of the Poisson bracket
of functions.
Proof. By deﬁnition,
{φ, ψ}(z) = φ′
zJ−1ψz = φ′
zJ−1JJ−1ψz
= −(J−1φz)′J(J−1ψz) = −ω(Xφ, Xψ)
(2.13)
= −iXφω(Xψ) = d φ(Xψ),
(2.14)
where Xφ = Ω−1 d φ =
2n

i=1
(J−1φz)i d zi. The Equations (2.13) and (2.14) are just
1◦and 2◦of Proposition 2.18 respectively. However,
−ω(Xφ, Xψ) = ω(Xψ, Xφ) = iXψω(Xφ) = iXφiXψω,
and so {φ, ψ} = iXφiXψω, which is 3◦. For 4◦, by Equation (2.14),

178
3. Hamiltonian Mechanics and Symplectic Geometry
{φ, ψ} = d φ(Xψ) = iXψ d φ = LXψφ,
since for φ ∈C∞(R2n), LXφ = iXdφ. Finally, for 5◦, we have
[Xφ, Xψ] = (J−1ψz)zJ−1φz −(J−1φz)zJ−1ψz
= J−1ψzzJ−1φz −J−1φzzJ−1ψz,
and
{φ, ψ}z = (φ′
zJ−1ψz)z = φzzJ−1ψz −ψzzJ−1φz,
Ω−1 d {φ, ψ} = J−1{φ, ψ}z
= J−1φzzJ−1ψz −J−1ψzzJ−1φz = −[Xφ, Xψ].
Therefore, the proposition is completed.
▲
Exercise 2.19. Show that the map g : R2n →R2n, sending(p, q) →(P(p, q), Q(p, q))
is canonical, iff the Poisson bracket of any two functions in variables (p, q) and (P, Q)
coincide:
{φ ◦g−1, ψ ◦g−1} = {φ, ψ} ◦g−1,
∀φ, ψ ∈C∞(R2n).
i.e.,
{φ, ψ}p,q =
∂ψ
∂p
∂φ
∂q −∂ψ
∂q
∂φ
∂p
=
∂ψ
∂P
∂φ
∂Q −∂ψ
∂Q
∂φ
∂P
= {φ, ψ}P,Q.
Theorem 2.20. A function F is a ﬁrst integral of the phase ﬂow with the Hamiltonian
H iff its Poisson bracket with H is identically zero:
{F, H} = 0.
Proof. By the 4◦of proposition above,
LXHF = d
d t

t=0(φt
H)∗F = {F, H} = 0.
Thus,
d
d tF(φt
H(z)) =
d
d t(φt
H)∗F(z) = d
d s

s=0(φt+s
H )∗F(z)
=
d
d s(φt∗
Hφs∗
H )

s=0F(z)
= φt∗
H
d
d s(φs
H)∗
s=0F(z) = φt∗
HLXHF(z) = 0,
i.e., F is a ﬁrst integral of the phase ﬂow with the Hamiltonian H. The necessary
condition is evident.
▲

3.2 Hamiltonian Mechanics on R2n
179
From the Theorem 2.20, we immediately obtain the following.
Theorem 2.21. H is a ﬁrst integral of the phase ﬂow with Hamiltonian function H.
Theorem 2.22 (E. Noether theorem). If a Hamiltonian H is a ﬁrst integral of the
phase ﬂow with a Hamiltonian function H, then F is also a ﬁrst integral of the phase
ﬂow with the Hamiltonian function H.
This follows immediately from the Theorem 2.21 and the fact that {F, H} =
−{H, F}.
Theorem 2.23 (Poisson theorem).
The Poisson bracket of the two ﬁrst integrals
F1, F2 of a system with a Hamiltonian function H is again a ﬁrst integral.
Proof. By the Jacobi identity,
(
{F1, F2}, H
)
=
(
F1, {F2, H}
)
+
(
F2, {H, F1}
)
= 0 + 0 = 0,
which is what we require.
▲
2.
Lie algebras of Hamiltonian vector ﬁelds and functions
Deﬁnition 2.24. A Lie algebra is a vector space L, together with a bilinear skew-
symmetric operation [ , ] : L × L →L, which satisﬁes the Jacobi identity.
The operation [ , ] is usually called the commutator.
Therefore, the set of all vector ﬁelds on R2n, X(R2n), together with the Poisson
bracket [ , ], forms a Lie algebra; the set of all smooth functions on R2n, C∞(R2n),
together with the Poisson bracket { , }, forms a Lie algebra too.
Deﬁnition 2.25. A linear subspace of a Lie algebra is called a subalgebra if the sub-
space is closed under the commutator, i.e., the commutator of any two elements of the
subspace belongs to it.
Evidently, a subalgebra of a Lie algebra is itself a Lie algebra with the original
commutator.
By the proposition and theorems above, we have:
Corollary 2.26. The Hamiltonian vector ﬁelds on R2n form a subalgebra of the Lie
algebra of all vector ﬁelds.
Corollary 2.27. The commutator of the Hamiltonian phase ﬂow with a Hamiltonian
form a subalgebra of the Lie algebra of all functions.

180
3. Hamiltonian Mechanics and Symplectic Geometry
3.2.4 Generating Functions
Let a subset S ⊂R2n be an r-dimensional submanifold in R2n. For any ﬁxed point
s ∈S, there exists an open set U ⊂Rr and a diffeomorphism ϕ : U →S such that
s ∈ϕ(U). For simplicity, we consider the case only locally.
Deﬁnition 2.28. A subset S ⊂R2n is an r-dim submanifold if there exists a one-to-
one smooth map Z : U ⊂Rr →R2n such that
S = {z = Z(x) ∈R2n | x ∈U ⊂Rr}.
The tangent space TzS to S at z = Z(x) is
TzS =
∂Z
∂x

=
⎡
⎢⎢⎢⎢⎣
∂Z1
∂x1
· · ·
∂Z1
∂xr
...
...
∂Z2n
∂x1
· · ·
∂Z2n
∂xr
⎤
⎥⎥⎥⎥⎦
=
⎡
⎢⎣
∂P
∂x
∂Q
∂x
⎤
⎥⎦⊂TzR2n,
where Z(x) =
 P(x)
Q(x)

.
Let f : Rn →Rn be a smooth function. The graph of f in the product space
Rn × Rn = R2n,
gr (f) := Gf =
5
f(q)
q
6
∈R2n | q ∈Rn
7
is an n-dim submanifold in R2n, and its tangent space TzGf =
⎧
⎨
⎩
∂f
∂q
I
⎫
⎬
⎭is transver-
sal to Rn
p =
 I
O

in TzR2n for any z ∈Gf.
Theorem 2.29. Let S be an n-dim submanifold in R2n. S is a graph of some function
f iff for any z ∈S, its tangent space TzS to S at z is transversal to Rn
p in TzR2n.
Proof. We need to only prove the sufﬁciency. By deﬁnition, there are two functions
P(x) and Q(x), such that
S =
5
p
q
6
=
5
P(x)
Q(x)
6
| x ∈U ⊂Rn
7
.
Since TzS =
⎡
⎢⎣
∂P
∂x
∂Q
∂x
⎤
⎥⎦is transversal to Rn
p =
 I
O

in TzR2n, we have
∂Q
∂x
 ̸= 0.
By the inverse function theorem, q = Q(x) has an inverse function x = X(q) with
the Jacobian ∂X
∂q =
 ∂Q
∂X
−1
. This implies that

3.2 Hamiltonian Mechanics on R2n
181
TzS =
⎡
⎢⎣
∂P
∂x
∂Q
∂x
⎤
⎥⎦=
⎡
⎢⎣
∂P
∂x
%
∂Q
∂q
&−1
I
⎤
⎥⎦=
⎡
⎣
∂P
∂x
∂X
∂q
I
⎤
⎦=
⎡
⎣
∂
∂q (P ◦X)
I
⎤
⎦.
Setting f = P ◦X, we get
S =
5
P(x)
Q(x)
6
∈R2n
7
=

P ◦X(q)
q
7
=

f(q)
q
7
,
TzS =
⎡
⎣
∂f
∂q
I
⎤
⎦,
i.e., S is the graph of the function f(q) = P ◦X(q).
Let W : R2n →R2n, z = W(z) =
 U(p, q)
V (p, q)

, z =

p
q

be a diffeomor-
phism with the Jacobian
∂W
∂z =
⎡
⎢⎢⎣
∂U
∂p
∂U
∂q
∂V
∂p
∂V
∂q
⎤
⎥⎥⎦=
5 A
B
C
D
6
.
If f(q) is a function with Jacobian M = ∂f
∂q , and S = Gf, the graph of f, then
W(S) =

z = W(z) | z =
5
f(q)
q
6
∈S
7
is an n-dim submanifold in R2n with Jacobian
TzW(S) = ∂W
∂z
⎡
⎣
∂f
∂q
I
⎤
⎦=
5 A
B
C
D
6 5 M
I
6
=
5 AM + B
CM + D
6
.
Therefore, the theorem is completed.
▲
By Theorem 2.29, W(s) is a graph of some function g iff TzW(s) =
 AM + B
CM + D

is transversal to Rn
p on W(S), i.e., |CM + D| ̸= 0. Thus, we obtain the following
theorem.
Theorem 2.30. Let W(z) : R2n →R2n be a diffeomorphism with Jacobian ∂W
∂z =
 A
B
C
D

and f(q) be a function with Jacobian M = ∂f
∂q . Then, M satisﬁes the
transversality condition: |CM +D| ̸= 0, iff there exists a function g(q) with Jacobian
N = ∂g
∂q = (AM + B)(CM + D)−1 such that W(Gf) = Gg, i.e., W transforms
the graph of f into the graph of g.

182
3. Hamiltonian Mechanics and Symplectic Geometry
Deﬁnition 2.31. Let f : Rn →Rn be a transformation and ϕ : Rn →R be a scalar
function; if f =grad ϕ = ϕq(q), then ϕ is called a generating function of f and f
called a gradient transformation[AM78,Fen86,FWQW89].
Given an n-value function f on Rn, we may construct a differential 1-form ω1 =
f d q = f1 d q1 + · · · + fn d qn. If there exists a 0-form ϕ such that ω1 = fd q =
d ϕ, i.e., ω1 is exact, then f = ϕq. In Rn, by Poincare lemma 4.15 in Subsection
1.4.4, the only requirement is that ω1 is closed, i.e., ∂f
∂g is symmetric. Thus, any
transformation from Rn into itself with a symmetric Jacobian may be called a locally
gradient transformation.
Deﬁnition 2.32. Let S be an r-dim submanifold in R2n. S is called an isotropic,
coisotropic, Lagrangian, or K-Lagrangian submanifold if for any z ∈S, TzS is an
isotropic, coisotropic, Lagrangian, or K-Lagrangian subspace of TzR2n respectively.
It is obvious that the graph of any gradient transformation is Lagrangian.
Corollary 2.33. A Lagrangian submanifold S in R2n is the graph of some gradient
transformation f : Rn →Rn, S = Gf, iff its tangent space TzS is transversal to Rn
p
in TzR2n for any z ∈S.
Corollary 2.34. A transformation W(z) : R2n →R2n is a conformally canonical
transformation iff W(s) is Lagrangian for any Lagrangian submanifold S.
3.2.5 Hamilton–Jacobi Equations
Consider a canonical system
d z(t)
d t
= J−1Hz,
z(0) = z0,
(2.15)
with the Hamiltonian H(z) = H(p, q). Let z(t) = (p(t), q(t))′ be its solution and
G(t) the 1-parameter group of diffeomorphisms in R2n.
G(t) : z0 =
5
p0
q0
6
−→z(t) = G(t)z0 =
5
p(t)
q(t)
6
,
G(0) = I.
Let M0 =
 p0
q0

be an n-dim initial manifold, p0 a function of q0, and M0
form a Lagrangian manifold, i.e., M0 =
 p0(q0)
q0

and ∂p0
∂q0 ∈Sm. Since G(t) :
 p0
q0

→
 p(t)
q(t)

is a canonical transformation for a ﬁxed t in some neighbourhood
of R2n, and

3.2 Hamiltonian Mechanics on R2n
183
G∗(t) =
5 A
B
C
D
6
=
⎡
⎢⎢⎣
∂p
∂p0
∂p
∂q0
∂q
∂p0
∂q
∂q0
⎤
⎥⎥⎦
is a symplectic matrix,
5 Y1
Y2
6
= G∗
⎡
⎣
∂p0
∂q0
I
⎤
⎦=
⎡
⎢⎢⎣
A∂p0
∂q0 + B
C ∂p0
∂q0 + D
⎤
⎥⎥⎦
is a symmetric pair. If
C ∂p0
∂q0 + D
 ̸= 0, then
 Y1
Y2

∼
 N
I

, where
N =

A∂p0
∂q0 + B
 
C ∂p0
∂q0 + D
−1
∈Sm(n).
By Theorem 2.29, p can be represented as a function of q, i.e., p(t) = p(q, t).
Let H(q) = −H(p, q)|p=p(q) = −H(p(q), q). Consider a 1-form in Rn+1:
ω1 = p d q + H d t.
There is a scalar function ϕ(q, t) such that
ω1 = p d q + H d t = d ϕ,
iff ω1 is closed, i.e., the following matrix
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
∂p1
∂q1
· · ·
∂p1
∂qn
∂p1
∂t
...
...
...
∂pn
∂q1
· · ·
∂pn
∂qn
∂pn
∂t
∂H
∂q1
· · ·
∂H
∂qn
∂H
∂t
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
=
⎡
⎢⎢⎣
∂p
∂q
∂p
∂t
∂H
′
∂q
∂H
∂t
⎤
⎥⎥⎦
is symmetric. We know that the matrix ∂p
∂q is symmetric, and so we need to only prove
∂p
∂t = ∂H
∂q .
By canonical Equations (2.15),
−Hq = d p(q, t)
d t
= ∂p
∂q
∂q
∂t + ∂p
∂t = ∂p
∂q Hp + ∂p
∂t .
In addition,

184
3. Hamiltonian Mechanics and Symplectic Geometry
∂H
∂q = −∂H(p(q, t), q)
∂q
= −
∂p
∂t
′Hp −Hq.
Thus,
∂p
∂t = −Hq −∂p
∂q Hp = ∂H
∂q .
Consequently, there exists a scalar function ϕ(q, t), s.t.
p d q + H d t = d ϕ.
Thus, it follows that
p = ∂ϕ
∂q ,
ϕt = H = −H(p, q) = −H(ϕq, q),
or
ϕt + H(ϕq, q) = 0,
which is called the Hamilton–Jacobi equation.

Bibliography
[AA88] D.V. Anosov and V.I. Arnold: Dynamical Systems I. Springer, Berlin, (1988).
[AA89] V. I. Arnold and A. Avez: Ergodic Problems of Classical Mechanics. Addison-Wesley,
New York, (1989).
[Abd02] S. S. Abdullaev: The Hamilton-Jacobi method and Hamiltonian maps. J. Phys. A:
Math. Gen., 35(12):2811–2832, (2002).
[AKN78] V. I. Arnold, V. V. Kozlov, and A. I. Neishtadt: Mathematical Aspects of Classical
and Celestial Mechanics. Springer, Berlin, Second edition, (1978).
[AM78] R. Abraham and J. E. Marsden: Foundations of Mechanics. Reading, MA: Addison-
Wesley, Second edition, (1978).
[AMR88] R. Abraham, J. E. Marsden, and T. Ratiu: Manifolds, Tensor Analysis, and Applica-
tions. AMS 75. Springer-Verlag, Berlin, Second edition, (1988).
[AN90] A. I. Arnold and S.P. Novikov: Dynamical System IV. Springer Verlag, Berlin, (1990).
[Arn88] V. I. Arnold: Geometrical Methods in The Theory of Ordinary Differential Equations.
Springer-Verlag, Berlin, (1988).
[Arn89] V. I. Arnold:
Mathematical Methods of Classical Mechanics.
Berlin Heidelberg:
Springer-Verlag, GTM 60, Second edition, (1989).
[Ber00] R. Berndt: An Introduction to Symplectic Geometry. AMS Providence, Rhode Island,
(2000).
[Bir23] G. D. Birkhoff: Relativity and Modern Physics. Harvard Univ. Press, Cambridge,
Mass., Second edition, (1923).
[BK89] G.W. Bluman and S. Kumei:
Symmetries and differential equations. AMS 81.
Springer-Verlag, New York, (1989).
[Car65] C. Carathe’odory: Calculus of Variation and Partial Differential Equations of First
Order, Vol.1. Holden-Day, San Franscisco, (1965).
[Car70] H. Cartan: Differential Forms. Houghton-Mifﬂin, Boston, (1970).
[CH53] R. Courant and D. Hilbert: Methods of Mathematical Physics. Interscience, New York,
Second edition, (1953).
[Che53] S. S. Chern: Differential Manifolds. University of Chicago, (1953). Lecture notes.
[Fen86] K. Feng: Difference schemes for Hamiltonian formalism and symplectic geometry. J.
Comput. Math., 4:279–289, (1986).
[Fla] H. Flanders: Differential Forms. Academie Press, New York, Second edition, (1963).
[FQ87] K. Feng and M.Z. Qin: The symplectic methods for the computation of Hamiltonian
equations. In Y. L. Zhu and B. Y. Guo, editors, Numerical Methods for Partial Differential
Equations, Lecture Notes in Mathematics 1297, pages 1–37. Berlin, Springer, (1987).
[FQ91a] K. Feng and M.Z. Qin: Hamiltonian Algorithms for Hamiltonian Dynamical Systems.
Progr. Natur. Sci., 1(2):105–116, (1991).
[FQ91b] K. Feng and M.Z. Qin: Hamiltonian algorithms for Hamiltonian systems and a com-
parative numerical study. Comput. Phys. Comm., 65:173–187, (1991).
[FQ03] K. Feng and M. Z. Qin: Symplectic Algorithms for Hamiltonian Systems. Zhejiang
Science and Technology Publishing House, Hangzhou, in Chinese, First edition, (2003).

186
Bibliography
[FWQW89] K. Feng, H. M. Wu, M.Z. Qin, and D.L. Wang: Construction of canonical dif-
ference schemes for Hamiltonian formalism via generating functions. J. Comput. Math.,
7:71–96, (1989).
[Gol80] H. Goldstein: Classical Mechanics. Addison-Wesley Reading, Massachusetts, (1980).
[GS84] V. Guillemin and S. Sternberg: Symplectic Techniques in Physics. Cambridge Univer-
sity Press, Cambridge, (1984).
[Lan95] S. Lang: Differential and Riemannian Manifolds. Springer-Verlag, Berlin, (1995).
[LL99] L. D. Landau and E. M. Lifshitz:
Mechanics, Volume I of Course of Theoretical
Physics. Corp. Butterworth, Heinemann, New York, Third edition, (1999).
[LM87] P. Libermann and C.M. Marle: Symplectic Geometry and Analytical Mechanics. Rei-
del Pub. Company, Boston, First edition, (1987).
[Mac70] S. MacLanc: Hamiltonian mechanics and geometry. Amer. Math. Mon., 77(6):570–
586, (1970).
[Sie43] C.L. Siegel: Symplectic geometry. Amer. J. Math, 65:1–86, (1943).
[Tre75] F. Treves: Pseodo-Differential Operator. N.Y.: Acad. Press, First edition, (1975).
[Wei77] A. Weinstein: Lectures on symplectic manifolds. In CBMS Regional Conference, 29.
American Mathematical Society, Providence, RI , (1977).
[Wes81] C. Von. Westenholz: Differential Forms in Mathematical Physics. North-Holland,
Amsterdam, Second edition, (1981).

Chapter 4.
Symplectic Difference Schemes for
Hamiltonian Systems
The canonicity of the phase ﬂow for time-independent Hamiltonian systems is one of
the most important properties. It ensures the preservation of phase areas and the phase
volume. Thus, preserving the canonicity of transition of difference schemes from one
time step to the next is also important in the numerical solutions of Hamiltonian sys-
tems. The goal of this chapter is to ﬁnd some simple symplectic schemes, i.e., to
identify which one, among the existing difference schemes, is symplectic.
4.1 Background
It is well known that Hamiltonian systems have many intrinsic properties: the preser-
vation of phase areas of even dimension and the phase volume, the conservation laws
of energy and momentum, and other symmetries.
4.1.1 Element and Notation for Hamiltonian Mechanics
Let H be a smooth function of 2n variables p1, · · · , pn, q1, · · · , qn. Then, the Hamil-
tonian canonical systems are of the form :
˙p = −Hq,
˙q = Hp,
(1.1)
where p = (p1, · · · , pn)T, q = (q1, · · · , qn)T. Let z =
 p
q
!
, and the standard
symplectic matrix be:
J =
5
O
In
−In
O
6
,
(1.2)
where In is the n × n identity matrix, and J has property J−1 = J′ = −J. Then,
system (1.1) can be written in a compact form:
˙z = J−1Hz,
(1.3)
where Hz =
 Hq
Hp
!
; H is called the Hamiltonian function of the system. The phase
ﬂow of system (1.1) can be represented as gt
H. According to the fundamental theorem

188
4. Symplectic Difference Schemes for Hamiltonian Systems
of a Hamiltonian system, the solution of a canonical system is a one-parameter sym-
plectic group Gt, denoted by Sp(2n). Therefore, symplectic geometry serves as the
mathematical foundation of Hamiltonian mechanics. For simplicity, we consider only
the classical phase space R2n = Rn
p × Rn
q , where Rn
p is called the momentum space,
and Rn
q the conﬁguration space. Locally, every 2n-dimensional manifold is diffeo-
morphic to a neighborhood of a point on R2n. The phase space R2n is equipped with
a standard symplectic structure deﬁned by
ωJ =
n

i=1
d zi ∧d zn+i =
n

i=1
d pi ∧d qi,
(1.4)
i.e., for each z of R2n, it is a bilinear antisymmetric form:
ωJ(ξ, η) = ξ′Jη,
∀ξ, η ∈TzR2n,
for each pair of tangent vector ξ, η at point z ∈TzR2n, where J is the standard
symplectic structure Equation (??).
Let w : R2n →R2n be a differential mapping, z ∈R2n →w(z) ∈R2n; the
corresponding Jacobian matrix is denoted by
∂w
∂z =
⎡
⎢⎢⎢⎢⎢⎢⎢⎣
∂w1
∂z1
· · ·
∂w1
∂z2n
...
...
∂w2n
∂z1
· · ·
∂w2n
∂z2n
⎤
⎥⎥⎥⎥⎥⎥⎥⎦
.
The mapping w induces, for each z ∈R2n, a linear mapping w∗(z) from the tangent
space at z into the the tangent space at w(z):
ξ = (ξ1, · · · , ξ2n)′ −→w∗ξ = ∂w
∂z ξ.
Each 2-form w on R2n also induces a 2-form w∗ω on R2n by the formula
w∗ω(ξ, η)z ≡ω
∂w
∂z ξ, ∂w
∂z η

w(z) .
If ω(ξ, η)z = ξ A(z) η, A′(z) = −A(z), then w∗ω(ξ, η) = ξ B(z) η, i.e.,
B(z) =
∂w
∂z
′
A(w(z))
∂w
∂z

.
Refer to Deﬁnition 4.7 from Chapter 1.
Deﬁnition 1.1 (Diff). A diffeomorphism (differentiable one to one onto mapping )
of R2n is called a canonical transformation if w preserves the standard symplectic
structure. i.e., w∗ωJ = ωJ,

4.1 Background
189
 ∂w
∂z
!′
J
 ∂w
∂z
!
= J,
(1.5)
i.e., Jacobian ∂w
∂z is a symplectic matrix for every z.
Its geometric meaning is depicted in Fig. 1.1. According to the general theory of ODE,
for each Hamiltonian system (1.1), there corresponds a one parameter group of dif-
feomophisms gt, at least locally in t and z, of R2n such that
g0 = id,
gt1+t2 = gt1 · gt2.
∂w
∂z ξ
∂w
∂z η
p
q

:
6
-
O
-
[ ∂w
∂z ]
p
q
ξ
η
6
-
O

1
Fig. 1.1.
Geometric meaning of preserving symplectic structure
4.1.2 Geometrical Meaning of Preserving Symplectic Structure ω
If z(0) is taken as an initial value, then the solution of (1.1) can be written as
z(t) = gtz(0).
The basic property of a Hamiltonian system is that gt is a canonical transformation,
i.e.,
(gt)∗ωJ = ωJ,
for all t. This leads to the following class of phase-area conservation law:
-
gtσ2 ωJ =
-
σ2 ωJ,
every 2-chain σ2 ⊂R2n,
-
gtσ4 ωJ ∧ωJ =
-
σ4 ωJ ∧ωJ,
every 4-chain σ4 ⊂R2n,
· · ·
· · ·
-
gtσ2n ωJ ∧· · · ∧ωJ =
-
σ2n ωJ ∧· · · ∧ωJ,
every 2n-chain σ2n ⊂R2n,
where the last one is the Liouville’s phase-volume conservation law. Another class of
conservation law is related to the energy and all the ﬁrst integrals. A smooth function
ϕ(x) is said to be a ﬁrst integral if ϕ(gtz) = ϕ(z), for all t, z. The latter is equivalent
to the condition {ϕ, H} = 0; H usually represents the energy, which is a ﬁrst integral
of itself.

190
4. Symplectic Difference Schemes for Hamiltonian Systems
The above situations can be generalized. A symplectic structure in R2n is speciﬁed
by a non-degenerate, closed 2-form
ωK =

i<j
Kij(z) d zi ∧d zj,
(1.6)
i.e.,
ωK(ξ, η)z = 1
2ξ′K(z)η,
K′(z) = −K(z),
det K(z) ̸= 0.
A differentiable mapping w : R2n →R2n called K-symplectic, if w∗ωK = ωK,
i.e.,
%∂w
∂z
&′
K

w(z)
∂w
∂z = K(z).
(1.7)
The Darboux theorem establishes the equivalence between all symplectic struc-
tures. Every non-singular closed 2-form ωK can be brought to the standard form

i<j
Kij(z) d zi ∧d zj =

i<j
d ωi ∧d wn+j
locally by suitable coordinate transformation z →w(z).
4.1.3 Some Properties of a Symplectic Matrix
From Subsection 2.3.2, a matrix S of order 2n is called a symplectic matrix if it
satisﬁes:
S′JS = J,
(1.8)
where S′ is the transpose of S. All symplectic matrices form a symplectic group
Sp(2n).
Deﬁnition 1.2. A matrix B of order 2n is called inﬁnitesimal symplectic, if
JB + B′J = O.
(1.9)
All inﬁnitesimal symplectic matrices form a Lie algebra with commutation operation
[A, B] = AB −BA, denoted as sp(2n). sp(2n) is the Lie algebra of the Lie group
Sp(2n). We have the following well-known proposition[FWQ90], which can be found
in Chapter 2. Here, we omit the proof.
Proposition 1.3. det S = 1, if S ∈Sp(2n).
Proposition 1.4. S−1 = −JS′J = J−1S′J, if S ∈Sp(2n).
Proposition 1.5. SJS′ = J, if S ∈Sp(2n).

4.1 Background
191
Proposition 1.6. Let S =
 
A
B
C
D
!
, A, B, C, D be an n × n matrix; then S ∈
Sp(2n) iff:
AB′ −BA′ = O,
CD′ −DC′ = O,
AD′ −BC′ = I,
A′C −C′A = O,
B′D −D′B = O,
A′D −C′B = I.
Proposition 1.7. Matrices
5
I
B
O
I
6
,
5
I
O
D
I
6
are symplectic, iff B′ = B, D′ = D.
Proposition 1.8. Matrices
5 A
O
O
D
6
∈Sp(2n),
iff A = (D′)−1.
Proposition 1.9. Matrices
S = M −1N ∈Sp(2n),
iff MJM ′ = NJN ′.
Proposition 1.10. Matrices
5
Q
I −Q
−(I −Q)
Q
6
∈Sp(2n),
iff Q2 = Q,
Q′ = Q.
Proposition 1.11. If B ∈sp(2n), then exp (B) ∈Sp(2n).
Proposition 1.12. If B ∈sp(2n), and |I + B| ̸= 0, then F = (I + B)−1(I −B) ∈
Sp(2n), the B Cayley transform of B.
Proposition 1.13. If B ∈sp(2n), then (B2m)′J = J(B2m).
Proposition 1.14. If B ∈sp(2n), then (B2m+1)′J = −J(B2m+1).
Proposition 1.15. If f(x) is an even polynomial, and B ∈sp(2n), then f(B′)J =
Jf(B).
Proposition 1.16. If g(x) is an odd polynomial, and B ∈sp(2n), then g(B) ∈
sp(2n), i.e.,
g(B′)J + Jg(B) = O.

192
4. Symplectic Difference Schemes for Hamiltonian Systems
4.2 Symplectic Schemes for Linear Hamiltonian
Systems
A Hamiltonian system (1.1 ) is called linear, if the Hamiltonian is a quadratic form of
z:
H(z) = 1
2z′Cz,
C′ = C,
and J is a standard antisymmetric matrix:
J =
 
O
In
−In
O
!
,
J′ = −J = J−1,
det J = 1.
Then, the canonical system (1.1), (1.3) become:
d z
d t = Bz,
B = J−1C,
C′ = C,
(2.1)
where B = J−1C is inﬁnitesimal symplectic. The solution of (1.1 ) is:
z(t) = gtz(0),
gt = exp (tB),
(2.2)
where gt, as the exponential transformation of inﬁnitesimal symplectic tB, is sym-
plectic (Proposition 1.11 ).
Consider now a quadratic form F(z) =
1
2z′Az. The Poisson bracket of two
quadratic forms H, F is also a quadratic form:
{H, F} = 1
2z′(AJC −CJA)z.
Theorem 2.1. The condition for the quadratic form F to be an invariant integral of
the linear Hamiltonian (2.1) can be expressed in any one of the following equivalent
ways:
F

(exp (tJ−1C))z

≡F(z),
(2.3)
{H, F} = 0,
(2.4)

exp (tJ−1C)
′A

exp (tJ−1C)

= A,
(2.5)
AJC = CJA.
(2.6)
4.2.1 Some Symplectic Schemes for Linear Hamiltonian Systems
Some types of the symplectic schemes for system (1.1 ) are proposed[Fen85], the ﬁrst
of which is called the time-centered Euler schemes (or midpoint Euler)
zn+1 −zn
τ
= B zn+1 + zn
2
.
(2.7)
The transition zn →zn+1 is given by

4.2 Symplectic Schemes for Linear Hamiltonian Systems
193
zn+1 = Fτzn,
Fτ = φ

−τ
2B

,
φ(λ) = 1 −λ
1 + λ,
(2.8)
where Fτ is a Cayley transformation of the inﬁnitesimal symplectic −τ
2B, and is
symplectic according to Proposition 1.12.
The second scheme we consider is the staggered explicit scheme for a separable
Hamiltonian. For a separable Hamiltonian H(p, q) = U(p) + V (q),
H(p, q) = 1
2[p′, q′] S
 p
q

= 1
2 p′Up + 1
2q′V q = U(p) + V (q),
(2.9)
where
S =
5
U
O
O
V
6
.
U ′ = U is positive deﬁnite and V ′ = V , the canonical Equation (1.1), becomes:
d p
d t = −Vq,
d q
d t = Up.
(2.10)
The staggered explicit scheme is:
1
τ (pn+1 −pn) = −V
n+ 1
2
q
,
(2.11)
1
τ

qn+ 1
2 +1 −qn+ 1
2

= U n+1
p
.
(2.12)
pTs are deﬁned at integer time t = nτ, and qTs at half-integer times t =

n + 1
2

τ.
The transition
wn =
5
pn
qn+ 1
2
6
−→
5
pn+1
qn+ 1
2 +1
6
= wn+1
is given by the following:
wn+1 = Fτwn,
where
Fτ =
5
I
O
−τ U
I
6−1 5
I
−τ V
O
I
6
,
(2.13)
as the product of two symplectic matrices, is symplectic (Proposition 1.7 ), and the
scheme has second order of accuracy.
4.2.2 Symplectic Schemes Based on Pad´e Approximation
We know that the trajectory z(t) = gtz0 is the solution satisfying the initial condition
z(0) = z0. In a linear system, gt coincides with its own Jacobian. One might asks how
to approximate to of exp (tB). This can be simply described in terms of Pad´e rational
approximation [FWQ90,Qin89]. Here, we consider the rational approximation to exp (x)
deﬁned by

194
4. Symplectic Difference Schemes for Hamiltonian Systems
exp (x) ∼nlm(x)
dlm(x) = glm(x),
(2.14)
where
nlm(x) =
m

k=0
(l + m −k) ! m !
(l + m) ! k ! (m −k) !xk,
(2.15)
dlm(x) =
l

k=0
(l + m −k) ! l !
(l + m) ! k ! (l −k) !(−x)k.
(2.16)
For each pair of nonnegative integers l and m, the Taylor series expansion of
nlm(x)
dlm(x) about the origin point is:
exp (x) −nlm(x)
dlm(x) = o(|x|m+l+1),
|x| −→0,
(2.17)
and the resulting (l + m)-th order Pad´e approximation of exp (x) is denoted by glm.
Theorem 2.2. Let B be an inﬁnitesimal symplectic; then, for sufﬁciently small |t|,
glm(tB) is symplectic iff l = m, i.e., gll(x) is the (l, l) diagonal Pad´e approximant to
exp (x).
Proof. Sufﬁciency. Let nll(x) = f(x) + g(x), dll = f(x) −g(x), where f(x) is an
even polynomial, g(x) is an odd one. In order to prove gtt(tB) ∈Sp(2n), we only
need to verify Proposition 1.9 .

f(tB)+g(tB)

J

f(tB)+g(tB)
′ =

f(tB)−g(tB)

J

f(tB)−g(tB)
′. (2.18)
By Propositions 1.15 and 1.16, the L.H.S of Equation (2.18) is:

f(tB)+g(tB)

J

f(tB′)+g(tB′)

=

f(tB)+g(tB)

f(tB)−g(tB)

J. (2.19)
Similarly for the R.H.S of Equation (2.18), we have:

f(tB)−g(tB)

J

f(tB′)−g(tB′)

=

f(tB)−g(tB)

f(tB)+g(tB)

J. (2.20)
Comparing Equations (2.19) and (2.20) completes the proof of the “if” part of the
theorem.
The “only if” part. Without loss of generality, we may take l > m. We only need to
notice that in Equation (2.18), the order of the polynomial on the right hand is higher
than that on the left hand.
▲
From Theorem 2.2, we can obtain a sequence of symplectic difference schemes based
on the diagonal (k, k) Pad´e table. In Table 2.1, the element of l-th row, m-th column is
denoted by (l, m). For the (1,1) approximation (i.e., l = 1, m = 1), we have the Euler
centered scheme

4.2 Symplectic Schemes for Linear Hamiltonian Systems
195
zn+1 = zn + τB
2 (zn + zn+1),
(2.21)
F (1,1)
τ
= φ(1,1)(τB),
φ(1,1)(λ) =
1 + λ
2
1 −λ
2
.
(2.22)
This scheme has second order accuracy.
For the (2,2) Pad´e approximation, we have:
zn+1 = zn + τB
2 (zn + zn+1) + τ 2B2
12 (zn −zn+1),
(2.23)
whose transition is
F (2,2)
τ
= φ(2,2)(τB),
φ(2,2)(λ) =
1 + λ
2 + λ2
12
1 −λ
2 + λ2
12
.
(2.24)
This scheme has fourth order accuracy.
For the (3,3) approximation, we have:
zn+1 = zn + τB
2 (zn + zn+1) + τ 2B2
10 (zn −zn+1) + τ 3B3
120 (zn + zn+1). (2.25)
F (3,3)
τ
= φ(3,3)(τB),
φ(3,3)(λ) =
1 + λ
2 + λ2
10 + λ3
120
1 −λ
2 + λ2
10 −λ3
120
.
(2.26)
This scheme has sixth order accuracy.
For the (4,4) approximation, we have:
zn+1 = zn + τB
2 (zn + zn+1) + 3τ 2B2
28
(zn −zn+1)
+τ 3B3
84 (zn + zn+1) + τ 4B4
1680 (zn −zn+1),
(2.27)
F (4,4)
τ
= φ(4,4)(τB),
φ(4,4)(λ) =
1 + λ
2 + 3λ2
28 + λ3
84 +
λ4
1680
1 −λ
2 + 3λ2
28 −λ3
84 +
λ4
1680
.
(2.28)
This scheme has eighth order accuracy.
Theorem 2.3. The difference schemes
zn+1 = gll(τB)zk,
l = 1, 2, · · ·
for a linear Hamiltonian system (2.1) are symplectic of 2l-th order accuracy .

196
4. Symplectic Difference Schemes for Hamiltonian Systems
Table 2.1.
Pad´e approximation table (l, m)
l
m
0
1
2
3
4
0
1
1
1
1 −x
1
1 −x + x2
2
1
1 −x + x2
2 −x3
6
1
1 −x + x2
2 −x3
6 + x4
24
1
1 + x
1
1 + x
2
1 −x
2
1 + x
3
1 −2x
3 + x3
6
1 + x
4
1 −3x
4 + x2
4 −x3
24
1 + x
5
1 −4x
5 + 3x2
10 −x3
15 + x4
120
2
1 + x + x2
2
1
1 + 2x
3 + x2
6
1 −x
3
1 + x
2 + x2
12
1 −x
2 + x2
12
1 + 2x
5 + x2
20
1 −3x
5 + x2
20 −x3
60
1 + x
3 + x2
30
1 −2x
3 + x2
20 −x3
30 + x4
360
3
1 + x + x2
2 + x3
6
1
1 + 3x
4 + x2
4 + x3
24
1 −x
4
1 + 3x
5 + 3x2
20 + x3
60
1 −2x
5 + x2
20
1 + x
2 + x2
10 + x3
120
1 −x
2 + x2
10 −x3
120
1 + 3x
7 + x2
14 + x3
210
1 −4x
7 + x2
7 −4x3
210 + x4
840
4
1 + x + x2
2 + x3
6 + x4
24
1
1 + 4x
5 + 3x2
10 + x3
15 + x4
120
1 −x
5
1 + 2x
3 + x2
20 + x3
30 + x4
360
1 −x
3 + x2
30
1 + 4x
7 + x2
7 + 4x3
210 + x4
840
1 −3x
7 + x2
14 −x3
210
1 + x
2 + 3x2
28 + x3
84 +
x4
1680
1 −x
2 + 3x2
28 −x3
84 +
x4
1680
.

4.2 Symplectic Schemes for Linear Hamiltonian Systems
197
4.2.3 Generalized Cayley Transformation and Its Application
Deﬁnition 2.4. A matrix B is called non-exceptional, if
det (I + B) ̸= 0.
(2.29)
Let B be non-exceptional; let us introduce a matrix S by
I + S = 2(I + B)−1,
(2.30)
whose inversion is
I + B = 2(I + S)−1.
(2.31)
Therefore S is non-exceptional, and we have the Cayley transformation[FWQ90]:
S = (I −B)(I + B)−1 = (I + B)−1(I −B),
(2.32)
and
B = (I −S)(I + S)−1 = (I + S)−1(I −S).
(2.33)
Let A be an arbitrary matrix. The equation
S′AS = A
(2.34)
expresses the condition that the substitution of S into both variables z, w leaves in-
variant the bilinear form z′Aw.
Lemma 2.5. [Wey39] If the non-exceptional matrices B and S are connected by (2.32)
and (2.33), and A is an arbitrary matrix, then
S′AS = A
(2.35)
iff
B′A + AB = O.
(2.36)
Proof. Taking the transpose of (2.33), we obtain
B′(I + S′) = I −S′.
Right multiplying by AS on both sides, and from (2.35), we obtain
A(S −I) = B′A(S + I).
Right multiplying by (S + I)−1 again on both sides, we obtain
−AB = B′A.
Conversely, by assuming (2.36) and right multiplying the transposed equation
S′(I + B′) = I −B′

198
4. Symplectic Difference Schemes for Hamiltonian Systems
of (2.33) by A on both sides, we have
S′A(I −B) = A(I + B),
which yields (2.35) on post-multiplication by (I + B)−1.
Let φ(λ) = (1 −λ)/(1 + λ); then the Cayley transform of B is denoted by
φ(B) = (I + B)−1/(I −B). By taking successively A = J and A = A′ in Lemma
2.5, this lemma is proved.
▲
Theorem 2.6. The Cayley Transform of a non-exceptional inﬁnitesimal symplectic
(symplectic) matrix is a non-exceptional symplectic (inﬁnitesimal symplectic) matrix.
If B = J−1C, C′ = C, B ∈sp(2n), det (I + τB) ̸= 0, A′ = A, then

φ(τ B)
′ A

φ(τB)

= A
(2.37)
iff
B′A + AB = O.
In other words, a quadratic form F(z) = 1
2z′Az is invariant under the symplectic
transformation φ(τB) iff F(z) is an invariant integral of the Hamiltonian system (2.1).
Theorem 2.7. [FWQ90] Let ψ(λ) be a function of a complex variable λ, satisfying:
1◦
ψ(λ) is analytic with real coefﬁcients in a neighborhood D of λ = 0.
2◦
ψ(λ)ψ(−λ) = 1 in D.
3◦
ψλ(0) ̸= 0. Let A, B be matrices of order 2n. Then,

ψ(τB)
′A

ψ(τB)

= A,
for all τ with sufﬁcient small |τ|, iff
B′A + AB = O.
We call these ψ(λ) the generalized Cayley transformation.
Proof. Condition 2◦implies ψ2(0) ̸= 0. Thus, ψ(0) ̸= 0, if

ψ(τB)
′A

ψ(τB)

= A,
for all τ with |τ| sufﬁciently small. Then, differentiating both sides of the above equa-
tion with respect to τ, we get
B′
ψλ(τB)
′Aψ(τB) +

ψ(τB)
′ABψλ(τB) = O.
Setting τ = 0, it becomes
(B′A + AB)ψ(0) ψλ(0) = O.
From condition 3◦, we get
B′A + AB = O.

4.2 Symplectic Schemes for Linear Hamiltonian Systems
199
Conversely, if B′A + AB = 0, then it is not difﬁcult to verify that the equations
ψλ(τB′)A = Aψλ(τB),
ψ(τB′)A = Aψ(−τB)
hold good for any analytic function ψ. From condition 2◦, it follows that
ψλ(λ) ψ(−λ) −ψ(λ) ψλ(−λ) = 0.
Therefore,
d
d τ

ψ(τB)′ A ψ(τB)

=
d
d τ

ψ(τ B′) A ψ(τ B)

= B′ψλ(τ B′) Aψ(τ B) + ψ(τ B′) ABψλ(τ B)
= B′Aψλ(−τ B) ψ(τ B) + ABψλ(−τB) ψ(τ B)
= (B′A + AB) ψλ(−τ B) ψ(τ B) = O,
i.e.,
ψ(τ B′) Aψ(τ B) = ψ(0) Aψ(0) = Aψ2(0) = A.
The proof is completed.
▲
By taking successively A = J and A′ = A in Theorem 2.8 and using (2.3) – (2.6),
we obtain the following theorems.
Theorem 2.8. Take |τ| sufﬁciently small so that τB has no eigenvalue at the pole
of the function φ(λ) in Theorem 2.7. Then, ψ(τB) ∈Sp(2n) iff B ∈sp(2n). Let
B = J−1C, C′ = C, A′ = A; then,
ψ(τJ−1C)′ Aψ(τJ−1C) = A,
(2.38)
iff
AJC = CJA.
In other words, a quadratic form F(z) = 1
2z′Az, is invariant under the symplectic
transformation ψ(τB), iff F(z) is an invariant integral of the system (2.1).
The transformation φ(τB) based on Theorem 2.7 includes exponential transfor-
mation exp(τB), Cayley transformation ψ(−τB/2), and diagonal Pad´e transforma-
tion as special cases. Taking φ(λ) in Theorem 2.7 as a rational function, then nec-
essarily ψ(λ) =
P(λ)
P(−λ), P(λ) is a polynomial, and is often normalized by setting
P(0) = 1, P ′(0) ̸= 0.
Theorem 2.9. Let P(λ) be a polynomial P(0) = 1, P ′(0) ̸= 0, and
exp (λ) −P(λ)
P(−λ) = O (|λ|2k+1).
(2.39)

200
4. Symplectic Difference Schemes for Hamiltonian Systems
Then,
P(−τB)zm+1 = P(τB)zm,
i.e.,
zm+1 = P(τB)
P(−τB)zm
(2.40)
is a symplectic scheme of order 2k for a linear system (2.1). This difference scheme
and the original system (2.1) have the same set of quadratic invariants.
In order to ﬁnd the approximate P(x)
P(−x) to exp (x) , we may express exp(x) in various
rational fraction ways. The following are examples:
(1)
exp (x) ∼
nll(x)
nll(−x) = dll(−x)
dll(x) .
(2)
exp (x) ∼1
2glm(x) · 1
2gml(x).
(3)
exp (x) =
1 + tanh x
2
1 −tanh x
2
.
(4)
exp (x) = e
x
2
e−x
2 .
(5)
exp (x) =
1
2(1 + ex)
1
2(1 + e−x)
.
Each denominator and numerator in the above expressions can be expanded about
the origin in Taylor series. The ﬁrst term of the approximation gives the function
ψ(x) =

1 + x
2
<
1 −x
2

, which yields the Euler centered scheme. Keeping m(> 1)
terms in the expansions for both the denominator and numerator, we will get a function
ψ(x) that will extend the Euler centered schemes. The schemes obtained in this way
are all symplectic; however, the order of accuracy of the ﬁrst and third schemes is
higher than that of the last two kinds. For example, if in the formula (5) the ﬁrst three
terms of the expansions of the denominator and numerator are retained, then the 4-th
order symplectic scheme is obtained. However, the same kind of truncation gives 6-th
order schemes from (1) and (3).
4.3 Symplectic Difference Schemes for a Nonlinear
Hamiltonian System
For a nonlinear Hamiltonian system, we give some simple symplectic difference
schemes.
Centered Euler scheme. For Equation (1.3), we give Euler centered schemes [Fen85]:
1
τ (zm+1 −zm) = J−1Hz
%zm+1 + zm
2
&
,
(3.1)
where the mapping Fτ: zm →zm+1 is nonlinear. By differentiation,

4.3 Symplectic Difference Schemes for a Nonlinear Hamiltonian System
201
∂zm+1
∂zm
= I + τJ−1Hzz
%zm+1 + zm
2
& %1
2
∂zm+1
∂zm
+ 1
2I
&
,
where Hzz
%
zm+1 + zm
2
&
is the Hessian matrix of the function H(z) at point z =
zm+1 + zm
2
, and ∂zm+1
∂zm
is the Jacobian matrix of Fτ. We have
Fτ =
 
I −τ
2J−1Hzz
zm+1 + zm
2
!−1  
I + τ
2J−1Hzz
zm+1 + zm
2
!
.
When z remains bounded and by taking τ to be sufﬁciently small, we can keep the
inﬁnitesimally symplectic matrix τ
2J−1Hzz
%
zm+1 + zm
2
&
non-exceptional. Then,
Fτ as a Cayley transform is symplectic. Thus, all the conservation laws for phase
areas remain true. However, unlike the linear case, the ﬁrst integral φ(x) including H
itself are not conserved exactly. Indeed, it satisﬁes conservation law only nearby:
ϕ(zm+1) = ϕ(zm)
mod o(τ 3).
Property 3.1. Let f(z) = 1
2z′Bz be a conservation law for the Hamiltonian system
(1.3). Then, it is also a conservation law of the Euler centered scheme for system (1.3).
Proof.
=
B(zk+1 + zk), zk+1 −zk
τ
>
=
=
B(zk+1 + zk), J−1Hz
zk+1 + zk
2
>
=
=
(zk+1 + zk), BJ−1Hz
zk+1 + zk
2
>
= 0,
and so
⟨Bzk, zk⟩= ⟨Bzk+1, zk+1⟩.
The proof is proved.
▲
The last equation comes from the conservation law of original system.
Remark 3.2. As Euler centered schemes, high-order schemes constructed by the di-
agonal element in the Pad´e table preserve all quadratic ﬁrst integrals of the original
Hamiltonian system.
It is worth to point out that the trapezoidal scheme:
1
τ (zm+1 −zm) = J−1 1
2

Hz(zm+1) + Hz(zm)

(3.2)
is non-symplectic, because the transition

202
4. Symplectic Difference Schemes for Hamiltonian Systems
Fτ =

I −τ
2 J−1Hzz(zm+1)
−1 
I + τ
2 J−1Hzz(zm)

is non-symplectic in general. By a nonlinear transformation [Dah59,QZZ95],
ξk = ρ(zk) = zk + h
2 f(zk),
ξk+1 = ρ(zk+1) = zk+1 + h
2 f(zk+1),
(3.3)
and the trapezoidal scheme can be transformed into a symplectic Euler centered
scheme
ξk + ξk+1 = zk + zk+1 + h
2

f(zk) + f(zk+1)

.
Applying (3.2) to the above formula, we get
ξk + ξk+1 = zk + zk+1 + zk+1 −zk = 2zk+1.
By taking zk+1 = ξk + ξk+1
2
in the second equation of (3.3), we obtain
ξk+1 = ξk + ξk+1
2
+ h
2 f
%ξk + ξk+1
2
&
,
i.e.,
ξk+1 = ξk + hf
%ξk + ξk+1
2
&
,
which is a Euler centered scheme.
Theorem 3.3. The trapezoidal scheme (3.2) preserves the following symplectic
structure[WT03]:
J + h2
4 Hzz(z)JHzz(z),
(3.4)
i.e.,
%∂zk+1
∂zk
&′ %
J + h2
4 Hzz(zk+1)JHzz(zk+1)
& ∂zk+1
∂zk
= J+h2
4 Hzz(zk)JHzz(zk).
Proof. The proof can be easily obtained by direct calculation using nonlinear trans-
form of (3.3) to (1.7).
▲
Remark 3.4. For the canonical system with general separable Hamiltonian, H(p, q) =
U(p) + V (q), and we have
d q
d t = −Vq(q),
d p
d t = Up(p),
(3.5)
1
τ (pm+1 −pm) = −Vq(qm+ 1
2 ),
1
τ (qm+1+ 1
2 −qm+ 1
2 ) = Up(pm+1).
(3.6)

4.4 Explicit Symplectic Scheme for Hamiltonian System
203
The transition Fτ :
 
pm
qm+ 1
2
!
→
 
pm+1
qm+1+ 1
2
!
has the Jacobian:
Fτ =
5
I
O
−τ M
I
6−1 5
I
−τ L
O
I
6
.
From Proposition 1.7, it is symplectic, but with M = Upp(pm+1), L = Vqq(qm+ 1
2 ).
Property 3.5. Let f(p, q) = p′Bq be a conservation law of (3.5). Then, (pk+1)′Bqk+ 3
2
= (pk)′Bqk+ 1
2 is a conservation law of the difference scheme (3.6) also.
Proof. Indeed, because f(p, q) is a conservation law of the original Hamiltonian sys-
tem

Bp, Up(p)

= 0,

Bq, Vq(q)

= 0,
we get
%
qk+ 3
2 −qk+ 1
2
τ
, Bpk+1
&
=

Up(pk+1), Bpk+1
= 0,
%
pk+1 −pk
τ
, Bqk+ 1
2
&
=

Vq(qk+ 1
2 ), Bqk+ 1
2 
= 0.
Subtracting the two equations above, we get
(Bpk+1, qk+ 3
2 ) = (Bpk, qk+ 1
2 ).
The proof can be obtained.
▲
4.4 Explicit Symplectic Scheme for Hamiltonian
System
The oldest and simplest difference scheme is the explicit Euler method. Usually, it is
not symplectic for general Hamiltonian systems. It is interesting to ask: under what
condition of Hamiltonian systems, can the explicit Euler method become symplectic?
In fact, the explicit Euler scheme should be the phase ﬂow of a system (i.e., exact
solution) to be symplectic. Most of the important Hamiltonian systems can be decom-
posed into the sum of these simple systems. Then, the composition of the Euler method
acting on these systems yields a symplectic method, which is also explicit. These sys-
tems are called symplectically separable. So classical separable Hamiltonian systems
are symplectically separable. In this section, we will prove that any polynomial Hamil-
tonian is symplectically separable.

204
4. Symplectic Difference Schemes for Hamiltonian Systems
4.4.1 Systems with Nilpotent of Degree 2
For a Hamiltonian system (1.3), the oldest and simplest is the explicit Euler scheme:
z = Eτ
Hz := z + τJHz(z),
(4.1)
where Eτ
H = 1 + τJHz. Usually, the scheme (4.1) is non-symplectic. However, it is
symplectic for a speciﬁc kind of Hamiltonian system, called a system with nilpotent
of degree 2.
Deﬁnition 4.1. [FW98] A Hamiltonian system is nilpotent of degree 2 if it satisﬁes
JHzz(z)JHz(z) = 0,
∀z ∈R2n.
(4.2)
Evidently, H(p, q) = φ(p) or H(p, q) = ψ(q), which represents inertial ﬂow and
stagnant ﬂow, are nilpotent of degree 2 since for H(p, q) = φ(p),
Hzz(z)JHz(z) =
5
φpp
O
O
O
6 5
O
−I
I
O
6 5
φp
O
6
=
5
φpp
O
O
O
6 5
O
φp
6
= O,
and for H(p, q) = ψ(q),
Hzz(z)JHz(z) =
5
O
O
O
ψqq
6 5
O
−I
I
O
6 5
O
ψq
6
=
5
O
O
O
ψqq
6 5
−ψq
O
6
= O.
Theorem 4.2. If H is nilpotent of degree 2, then the explicit Euler scheme Eτ
H is the
exact phase ﬂow of the Hamiltonian system, and hence symplectic.
Proof. Let z = z(0). From the condition (4.2), it follows that
¨z(t) = d
d tJHz(z(t)) = (JHz(z(t)))z ˙z(t) = JHzz(z(t))JHz(z(t)) = 0,
and therefore,
˙z(t) = ˙z(0) = JHz(z(0)).
Hence,
z(t) = z(0) + tJHz(z(0)) = z + tJHz(z) = Et
H(z).
This is just the explicit Euler scheme Et
H. This shows that for such a system, the
explicit Euler scheme Eτ
H is the exact phase ﬂow, and therefore symplectic.
▲
Theorem 4.3. Let φ(u) : Rn →R be a function on n variables u, φ(u) = φ(u1,
u2, · · ·, un). Let Cn×2n = (A, B) be a linear transformation from R2n to Rn. Then,
the Hamiltonian H(z) = φ(Cz) satisﬁes
JHzz(z)JHz(z) = O,
∀φ, z,
(4.3)
iff
CJCT = O.
(4.4)

4.4 Explicit Symplectic Scheme for Hamiltonian System
205
Proof. Since
JHzz(z)JHz(z) = JCTφuu(CJCTφu(Cz)),
(4.5)
the sufﬁcient condition is trivial.
We now prove the necessity. If
JHzz(z)JHz(z) = O,
∀φ, z,
then from (4.5) it follows that
JCTφuu(Cz)(JCTφu(Cz) = O,
∀φ, z.
Especially take φ(u) = 1
2uTu, then
JCTCJCTCz = O,
∀z,
i.e.,
JCTCJCTC = O.
Left multiplying by C and right multiplying JCT by this equation, we get:
(CJCT)3 = O.
The anti-symmetry of CJCT implies CJCT = O.
▲
Lemma 4.4. Let C = (A, B); then CJCT = O, if and only if ABT = BAT.
Theorem 4.5. For any Hamiltonian system:
H(z) = H(p, q) = φ(Cz) = φ(Ap + Bq),
ABT = BAT,
where φ(u) is any n variable function. The explicit Euler method
z = Eτ
Hz = Eτ
φz = z + τJHz(z) = z + τJCTφu(Cz)
is the exact phase ﬂow, i.e.,
eτ
φ := Eτ
φ = 1 + τJHz = 1 + τJCTφu ◦C,
hence, Eτ
φ is symplectic.
4.4.2 Symplectically Separable Hamiltonian Systems
Deﬁnition 4.6. [FW98,FQ91] Hamiltonian H(z) is separable, if
H(z) =
m

i=1
Hi(z),
Hi(z) = φi(Ciz) = φ(Aip + Biq),
(4.6)

206
4. Symplectic Difference Schemes for Hamiltonian Systems
where φi are functions of n variables and Ci = (Ai, Bi) satisﬁes the condition
AiBT
i = BiAT
i (i = 1, · · · , m). Obviously, we have the following proposition.
Proposition 4.7. A linear combination of a symplectic separable Hamiltonian is sym-
plectically separable.
For a symplectically separable Hamiltonian (4.6), the explicit composition scheme
gτ
H
=
Eτ
m ◦Eτ
m−1 ◦· · · ◦Eτ
2 ◦Eτ
1
:= Eτ
Hm ◦Eτ
Hm−1 ◦· · · ◦Eτ
H2 ◦Eτ
H1
(4.7)
is symplectic and of order 1. As a matter of fact:
Eτ
H2 ◦Eτ
H1 = (1 + τJH2,z) ◦(1 + τJH1,z)
= 1 + τJH2,z + τJH1,z + O(τ 2)
= 1 + τJ(H2,z + H1,z) + O(τ 2),
gτ
H = Eτ
m ◦Eτ
m−1 ◦· · · ◦Eτ
2 ◦Eτ
1
= (1 + τJHm,z) ◦

1 + τJ
m−1

i=1
Hi,z + O(τ 2)

= 1 + τJ
m

i=1
Hi,z + O(τ 2)
= 1 + τJHz + O(τ 2).
The symplecticity of gτ
H follows from the fact that symplectic maps on R2n form a
group under composition.
Similarly,
gτ
H = Eτ
1 ◦Eτ
2 ◦· · · ◦Eτ
m−1 ◦Eτ
m
is symplectic and of order 1.
More discussion on how to construct separable schemes with high order is pro-
vided in Chapter 8.
Example 4.8. The Hamiltonian [FW98,FQ91]
Hk(p, q) =
k−1

i=0
cos
%
p cos 2π i
k
+ q sin 2π i
k
&
with k-fold rotational symmetry in a phase plane[2,4] are not separable in the conven-
tional sense if k ̸= 1, 2, 4. Otherwise they are symplectically separable, since every
term cos

p cos 2π i
k
+ q sin 2π i
k

is nilpotent of degree 2 according to Theorem 4.3.
For example, for k = 3,
H3(p, q) = cos p + cos

p cos 2π
3 + q sin 2π
3

+ cos

p cos 4π
3 + q sin 4π
3

= cos p + cos
%
1
2p −
√
3
2 q
&
+ cos
%
−1
2 p −
√
3
2 q
&
,

4.4 Explicit Symplectic Scheme for Hamiltonian System
207
and the explicit symplectic schemes of order 1 are
q1 = q −1
2τ sin
%
1
2p +
√
3
2 q
&
,
p1 = p +
√
3
2 τ sin
%
1
2p +
√
3
2 q
&
,
q2 = q1 −1
2τ sin
%
1
2p1 −
√
3
2 q1
&
,
p = p1 −
√
3
2 τ sin
%
1
2p −
√
3
2 q
&
,
q = q2 −τ sin p.
Using the composition theory discussed in Chapter 8 , we can construct an explicit
symplectic scheme with higher order accuracy.
4.4.3 Separability of All Polynomials in R2n
Theorem 4.9. [FW98] Every monomial xn−kyk of degree n in 2 variables x and y,
n ≤2, 0 ≤k ≤n can be expanded as a linear combination of n + 1 terms:
{(x + y)n, (x + 2y)n, · · · , (x + 2n−1y)n, xn, yn}.
Proof. Using binomial expansion,
(x + y)n = xn + C1
nxn−1y1 + C2
nxn−2y2 + · · · + Cn−2
n
x2yn−2 + C1
nx1yn−1 + yn.
Deﬁne
P1(x, y) : = (x + y)n −xn −yn
= C1
nxn−1y1 + C2
nxn−2y2 + · · · + C2
nx2yn−2 + C1
nx1yn−1,
which is separable, and the right side consists of mixed terms; P1 is a linear combina-
tion of 3 terms (x + y)n, xn, and yn.
P1(x, 2y) = 2C1
nxn−1y1 + 22C2
nxn−2y2 + · · · + 2n−2C2
nx2yn−2 + 2n−1C1
nx1yn−1,
2P1(x, 1y) = 2C1
nxn−1y1 + 2C2
nxn−2y2 + · · · + 2C2
nx2yn−2 + 2C1
nx1yn−1.
Deﬁne
P2(x, y) : = P1(x, 2y) −2P1(x, y)
= (22 −2)C2
nxn−2y2 + · · · + (2n−2 −2)C2
nx2yn−2
+(2n−1 −2)C1
nx1yn−1,
which is separable in 4 terms (x + y)n, (x + 2y)n, xn, and yn.

208
4. Symplectic Difference Schemes for Hamiltonian Systems
P3(x, y) = P2(x, 2y) −22P2(x, y)
= (23 −22)(23 −2)C3
nxn−3y3 + · · · + (2n−2 −22)(2n−2 −2)C2
nx2yn−2
+(2n−1 −22)(2n−1 −2)C1
nx1yn−1,
which is separable in 5 terms (x + y)n, (x + 2y)n, (x + 22y)n, xn, and yn. Deﬁne:
Pn−2(x, y) : = Pn−3(x, 2y) −2n−3Pn−3(x, y)
= (2n−2 −2n−3) · · · (2n−2 −2)C2
nx2yn−2
+(2n−1 −2n−3) · · · (2n−1 −2)C1
nx1yn−1,
which is separable in n terms (x + y)n, (x + 2y)n, · · · , (x + 2n−3y)n, xn, and yn.
Finally, we get:
Pn−1(x, y) = Pn−2(x, 2y) −2n−2Pn−2(x, y)
= (2n−1 −2n−2)(2n−1 −2n−3) · · · (2n−1 −2)C1
nx1yn−1
= γn−1x1yn−1,
γn−1 ̸= 0.
The separable n + 1 terms are (x + y)n, (x + 2y)n, · · · , (x + 2n−2y)n, xn, and yn.
Hence, the mixed term xyn−1 is separable into n + 1 terms. Then, from the separa-
bility of Pn−2(x, y) and xyn−1, we know that x2yn−2 is separable into n + 1 terms.
Similarly, x3yn−3, x4yn−4, · · · , xn−2y2, and xn−1y is separable into n + 1 terms. ▲
Remark 4.10. We can also work with the following formulae:
1
2(x + y)2m+1 + 1
2(x −y) −x2m+1
= C2
2m+1x2m−1y2 + C4
2m+1x2m−3y4 + · · · + C2m
2m+1xy2m,
1
2(x + y)2m+1 −1
2(x −y)2m+1 −y2m+1
= C1
2m+1x2my + C3
2m+1x2m−2y3 + · · · + C2m−1
2m+1x2y2m−1,
1
2(x + y)2m + 1
2(x −y)2m −x2m −y2m
= C2
2mx2m−2y2 + C4
2mx2m−4y4 + · · · + C2m−2
2m
x2y2m−2,
1
2(x + y)2m −1
2(x −y)2m
= C1
2mx2m−1y + C3
2mx2m−3y3 + · · · + C2m−1
2m
xy2m−1,
by means of elimination to get more economic expansions, e.g.,
xy = 1
2(x + y)2 −1
2x2 −1
2y2 = 1
4(x + y)2 −1
4(x −y)2.

4.5 Energy-conservative Schemes by Hamiltonian Difference
209
Theorem 4.11. Every polynomial P(x, y) of degree n in variables p and q can be
expanded as n + 1 terms P1(x, y), P2(x, y), · · · , Pn−1(x, y), Pn(x), Pn+1(y), where
each Pi(u) is a polynomial of degree n in one variable or more. Generally, every
polynomial P(p, q) can be expanded as
P(p, q) =
m

i=1
Pi(aip + biq),
m ≤n + 1,
where Pi(u) are polynomials of degree n in one variable.
Theorem 4.12. Every monomial in 2n variables is of the form
f(p, q) = (pm1−k1
1
qk1
1 )(pm2−k2
2
qk2
2 ) · · · (pmn−kn
n
qkn
n )
and can be expanded as a linear combination of the terms in the form:
φ(Ap + Bq) = (a1p1 + b1q1)m1(a2p2 + b2q2)m2 · · · (anpn + bnqn)mn,
where φ(u) = φ(u1, · · · , un) = um1
1 um2
2
· · · umn
n
is the monomial in n with total de-
gree m =
m

i=1
mi and with degree mi in variable ui. A and B are diagonal matrices
of order n:
A =
⎛
⎜
⎜
⎜
⎝
a1
0
· · ·
0
0
a2
· · ·
0
...
...
...
0
0
· · ·
an
⎞
⎟
⎟
⎟
⎠,
B =
⎛
⎜
⎜
⎜
⎝
b1
0
· · ·
0
0
b2
· · ·
0
...
...
...
0
0
· · ·
bn
⎞
⎟
⎟
⎟
⎠,
which automatically satisﬁes ABT = BAT. The elements ai, bi can be chosen as
integers.
Theorem 4.13. Every polynomial P(p1, q1, · · · , pn, qn) of degree m in 2n variables
can be expanded as [FW98]
P(p, q) =
m

i=1
Pi(Aip + Biq),
where each Pi is a polynomial of degree m in n variables, and Ai, Bi are diagonal
matrices (satisfying AiBT
i = BiAT
i ). Thus, for polynomial Hamiltonian, the symplec-
tic explicit Euler composite schemes of order 1, 2, or and 4 can be easily constructed.
4.5 Energy-conservative Schemes by Hamiltonian
Difference
Now, we consider energy-conservative schemes by Hamiltonian differencing, which
was ﬁrst proposed by A.J. Chorin[CHMM78], and later considered by K. Feng[Fen85].

210
4. Symplectic Difference Schemes for Hamiltonian Systems
However, these schemes are not symplectic. For simplicity, we illustrate the cases
only when n = 2. Let z = zm, ¯z = zm+1.
1
τ (¯p1 −p1) = −
1
¯q1 −q1 {H(p1, p2, ¯q1, q2) −H(p1, p2, q1, q2)},
1
τ (¯p2 −p2) = −
1
¯q2 −q2 {H(¯p1, p2, ¯q1, ¯q2) −H(¯p1, p2, ¯q1, q2)},
1
τ (¯q1 −q1) =
1
¯p1 −p1 {H(¯p1, p2, ¯q1, q2) −H(p1, p2, ¯q1, q2)},
1
τ (¯q2 −q2) =
1
¯p2 −p2 {H(¯p1, ¯p2, ¯q1, ¯q2) −H(¯p1, p2, ¯q1, ¯q2)}.
(5.1)
By addition and cancellation, we have energy conservation for the arbitrary Hamil-
tonian H(¯p1, ¯p2, ¯q1, ¯q2) = H(p1, p2, q1, q2).
Since the proposed energy conservative schemes based on Hamiltonian differenc-
ing only have the ﬁrst order accuracy, Qin[Qin87] ﬁrst proposed another more symmet-
ric form in 1987, which possesses the second order accuracy. Independently, Itoh and
Abe[IA88] also proposed the same schemes in 1988.
For simplicity, we consider only the case n = 2, and the following difference
schemes are given:
d p1
d t = −1
4
H(p1, p2, ¯q1, q2) −H(p1, p2, q1, q2)
Δq1
−1
4
H(p1, ¯p2, ¯q1, ¯q2) −H(p1, ¯p2, q1, ¯q2)
Δq1
−1
4
H(¯p1, p2, ¯q1, q2) −H(¯p1, p2, q1, q2)
Δq1
−1
4
H(¯p1, ¯p2, ¯q1, ¯q2) −H(¯p1, ¯p2, q1, ¯q2)
Δq1
,
d q1
d t = 1
4
H(¯p1, p2, ¯q1, q2) −H(p1, p2, ¯q1, q2)
Δp1
+ 1
4
H(¯p1, ¯p2, ¯q1, ¯q2) −H(p1, ¯p2, ¯q1, ¯q2)
Δp1
+1
4
H(¯p1, p2, q1, q2) −H(p1, p2, q1, q2)
Δ p1
+ 1
4
H(¯p1, ¯p2, q1, ¯q2) −H(p1, ¯p2, q1, ¯q2)
Δp1
,
d p2
d t = −1
4
H(¯p1, p2, ¯q1, ¯q2) −H(¯p1, p2, ¯q1, q2)
Δ q2
−1
4
H(p1, p2, q1, ¯q2) −H(p1, p2, q1, q2)
Δq2
−1
4
H(¯p1, ¯p2, ¯q1, ¯q2) −H(¯p1, ¯p2, ¯q1, q2)
Δq2
−1
4
H(p1, ¯p2, q1, ¯q2) −H(p1, ¯p2, q1, q2)
Δ q2
,
d q2
d t = 1
4
H(¯p1, ¯p2, ¯q1, ¯q2) −H(¯p1, p2, ¯q1, ¯q2)
Δp2
+ 1
4
H(p1, ¯p2, q1, ¯q2) −H(p1, p2, q1, ¯q2)
Δ p2
+1
4
H(¯p1, ¯p2, ¯q1, q2) −H(¯p1, p2, ¯q1, q2)
Δ p2
+ 1
4
H(p1, ¯p2, q1, q2) −H(p1, p2, q1, q2)
Δ p2
.
From the above ﬁrst two equations, we have:
1
2(H(¯p1, p2, ¯q1, q2) + H(¯p1, ¯p2, ¯q1, ¯q2)) = 1
2(H(p1, ¯p2, q1, ¯q2) + H(p1, p2, q1, q2)).
From the last two equations, we have:
1
2(H(¯p1, ¯p2, ¯q1, ¯q2) + H(p1, ¯p2, q1, ¯q2) = 1
2(H(¯p1, p2, ¯q1, q2) + H(p1, p2, q1, q2)).
Combining these equations, we observe that these schemes have exact conservation
of the Hamiltonian H. Further research about conservative energy scheme can be re-
ferred in recent studies[WWM08].

Bibliography
[Car65] C. Carathe’odory: Calculus of Variation and Partial Differential Equations of First
Order, Vol.1. Holden-Day, San Franscisco, (1965).
[CHMM78] A. Chorin, T. J. R. Huges, J. E. Marsden, and M. McCracken: Product formulas
and numerical algorithms. Comm. Pure and Appl. Math., 31:205–256, (1978).
[Dah59] G. Dahlquist: Stability and error bounds in the numerical integration of ordinary
differential equations.
Trans. of the Royal Inst. of Techn., Stockholm, Sweden, 130:87,
(1959).
[Fen85] K. Feng: On difference schemes and symplectic geometry. In K. Feng, editor, Pro-
ceedings of the 1984 Beijing Symposium on Differential Geometry and Differential Equa-
tions, pages 42–58. Science Press, Beijing, (1985).
[FQ87] K. Feng and M.Z. Qin: The symplectic methods for the computation of Hamiltonian
equations. In Y. L. Zhu and B. Y. Guo, editors, Numerical Methods for Partial Differential
Equations, Lecture Notes in Mathematics 1297, pages 1–37. Springer, Berlin, (1987).
[FQ91] K. Feng and M.Z. Qin: Hamiltonian algorithms for Hamiltonian systems and a com-
parative numerical study. Comput. Phys. Comm., 65:173–187, (1991).
[FW98] K. Feng and D.L. Wang: On variation of schemes by Euler. J. Comput. Math., 16:97–
106, (1998).
[FWQ90] K. Feng, H.M. Wu, and M.Z. Qin: Symplectic Difference Schemes for Linear Hamil-
tonian Canonical Systems. J. Comput. Math., 8(4):371–380, (1990).
[IA88] T. Itoh and K. Abe: Hamiltonian-conserving discrete canonical equations based on
variational difference quotients. J. Comp. Phys., 76:85–102, (1988).
[Men84] C.R. Menyuk: Some properties of the discrete Hamiltonian method. Physica D,
11:109–129, (1984).
[Qin87] M. Z. Qin: A symplectic scheme for the Hamiltonian equations. J. Comput. Math.,
5:203–209, (1987).
[Qin89] M. Z. Qin: Cononical difference scheme for the Hamiltonian equation. Mathematical
Methods and in the Applied Sciences, 11:543–557, (1989).
[QZZ95] M. Z. Qin, W. J. Zhu, and M. Q. Zhang: Construction of symplectic of a three stage
difference scheme for ODEs. J. Comput. Math., 13:206–210, (1995).
[Wey39] H. Weyl: The Classical Groups. Princeton Univ. Press, Princeton, Second edition,
(1939).
[WT03] D. L. Wang and H. W. Tam: A symplectic structure preserved by the trapezoidal rule.
J. of Phys. Soc. of Japan, 72(9):2193–2197, (2003).
[WWM08] Y. S. Wang, B. Wang, and M. Z.Qin: Local structure-preserving algorithms for
partial differential equations. Science in China (Series A), 51(11):2115–2136, (2008).

Chapter 5.
The Generating Function Method
This chapter discusses the construction of the symplectic difference schemes via gen-
erating function and their conservation laws.
5.1 Linear Fractional Transformation
Deﬁnition 1.1. Let α =
 Aα
Bα
Cα
Dα
!
∈GL(2m). A linear fractional transforma-
tion is deﬁned by[Sie43,Hua44,FWQW89,Fen86]
σα : M(m) −→N(m),
M −→N = σα(M) = (AαM + Bα)(CαM + Dα)−1,
(1.1)
under the transversality condition
|CαM + Dα| ̸= 0.
(1.2)
Proposition 1.2. Let α ∈GL(2m), and the inverse α−1 =
 Aα
Bα
Cα
Dα
!
, then
|CαM + Dα| ̸= 0
iff
|MCα −Aα| ̸= 0,
|AαM + Bα| ̸= 0
iff
|Bα −MDα| ̸= 0.
(1.3)
Thus the linear fractional transformation σα in (1.1) can be represented as
σα(M) = (MCα −Aα)−1(Bα −MDα).
(1.4)
Proof. From the relation
5 Aα
Bα
Cα
Dα
6 5 Aα
Bα
Cα
Dα
6
=
5 Aα
Bα
Cα
Dα
6 5 Aα
Bα
Cα
Dα
6
= I2m,
i.e.,

214
5. The Generating Function Method
AαAα + BαCα = AαAα + BαCα = Im,
CαBα + DαDα = CαBα + DαDα = Im,
AαBα + BαDα = AαBα + BαDα = O,
CαAα + DαCα = CαAα + DαCα = O,
(1.5)
we obtain the following identities:
5
I
−M
Cα
Dα
6 5
Aα
Bα
Cα
Dα
6
=
5
Aα −MCα
Bα −MDα
O
I
6
,
5
I
−M
Aα
Bα
6 5 Aα
Bα
Cα
Dα
6
=
5 Aα −MCα
Bα −MDα
I
O
6
.
(1.6)
In addition, we have:
5
I
−M
Cα
Dα
6
=
5
I
O
Cα
I
6 5
I
−M
O
CαM + Dα
6
,
5
I
−M
Aα
Bα
6
=
5
I
O
Aα
I
6 5
I
−M
O
AαM + Bα
6
.
(1.7)
Inserting (1.7) into (1.6), taking their determinate, we obtain
|CαM + Dα| |α|−1 = |Aα −MCα|,
|AαM + Bα| |α|−1 = (−1)m|Bα −MDα|.
(1.8)
Note that since α is a non-singular matrix, (1.3) is valid.
By (1.8), Equation (1.4) is well deﬁned. The only remaining step is to verify the
equation
(MCα −Aα)−1(Bα −MDα) = (AαM + Bα)(CαM + Dα)−1,
i.e.,
(Bα −MDα)(CαM + Dα) = (MCα −Aα)(AαM + Bα).
Expanding it and using the conditions (1.5), we know that it holds.
▲
Proposition 1.3. We have the following well-known relation
(CαN + Dα)(CαM + Dα) = I,
(1.9)
hence
|CαN + Dα| ̸= 0
iff
|CαM + Dα| ̸= 0,

5.2 Symplectic, Gradient Mapping and Generating Function
215
where N = σα(M). Under the transversality condition (1.2), σα has an inverse linear
fractional transformation σ−1
α
= σα−1,
M = σα−1(N) = (AαN + Bα)(CαN + Dα)−1
= (NCα −Aα)−1(Bα −NDα).
(1.10)
Proof.
(CαN + Dα)(CαM + Dα)
= (Cα(AαM + Bα)(CαM + Dα)−1 + Dα)(CαM + Dα)
= (CαAα + DαCα)M + CαBα + DαDα
= I
(by (1.5)),
which is (1.9). The ﬁrst equation of (1.10) can be obtained from (1.4) and the second
equation can be derived from (1.1).
▲
Combining (1.2) and (1.3) together, we obtain the following four mutually equiv-
alent transversality conditions:
|CαM + Dα| ̸= 0,
(1.11)
|MCα −Aα| ̸= 0,
(1.12)
|CαN + Dα| ̸= 0,
(1.13)
|NCα −Aα| ̸= 0,
(1.14)
where
N = σα(M) = (AαM + Bα)(CαM + Dα)−1,
M = σα−1(N) = (AαN + Bα)(CαN + Dα)−1.
Moreover, the linear fractional transformation σα from {M ∈M(m) | |CαM +
Dα| ̸= 0} to {N ∈M(m) | |CαN + Dα| ̸= 0} is 1-1 surjective.
5.2 Symplectic, Gradient Mapping and Generating
Function
To study the symplectic structure and Hamiltonian system in R2n phase space, we
need R4n symplectic structure as a product of R2n space. Its symplectic structure
comes from the product of original symplectic structure in R2n
"Ω =
n

i=1
d zi ∧d zi+n −
n

i=1
d zi ∧d zi+n,
(2.1)

216
5. The Generating Function Method
where the corresponding matrix is given by "J4n =
 J2n
O
O
−J2n

. We denote
"R4n = (R4n, "J4n).
On the other hand, R4n has its standard symplectic structure:
Ω =
2n

i=1
d wi ∧d wi+2n,
(2.2)
where (w1, · · · , w2n, w1, · · · , w2n)T represents its coordinate. The corresponding ma-
trix is given by
J4n =
5
O
I2n
−I2n
O
6
.
We denote manifold R4n = (R4n, J4n).
Now we ﬁrst review some notations and facts of the symplectic algebra. Every
4n × 2n matrix of rank 2n can be represented as:
A =
5
A1
A2
6
∈M(4n, 2n),
A1, A2 ∈M(2n),
deﬁnes a 4n-dim subspace {A} spanned by its 2n column vectors. Evidently, {A} =
{B} iff ∃P ∈GL(2n) such that
AP = B,
i.e.,
5
A1P
A2P
6
=
5
B1
B2
6
.
A 2n-dim subspace {X} =
 X1
X2

of R4n, X1, X2 ∈M(2n), is a J4n-Lagrangian,
if
XTJ4nX = O,
i.e.,
XT
1 X2 −XT
2 X1 = O
or
XT
1 X2 ∈Sm(2n).
According to Siegel[Sie43], we call such a 4n × 2n matrix X =
 X1
X2

a symmetric
pair. Moreover, if |X2| ̸= 0, then X1X−1
2
= N ∈Sm(2n) and
 X1
X2

=
 N
I

.
Similarly, a 2n-dim subspace {Y } =
 Y1
Y2

is ˜J4n-Lagrangian, if
Y T ˜J4nY = O,
i.e.,
Y T
1 J2nY1 = Y T
2 J2nY2,

5.2 Symplectic, Gradient Mapping and Generating Function
217
the 4n×2n matrix Y =
 Y1
Y2

is called a symplectic pair. |Y2| ̸= 0 implies Y1Y −1
2
=
M ∈Sp(2n), and
 Y1
Y2

=
 M
I

.
Theorem 2.1. A transformation α =
 Aα
Bα
Cα
Dα

∈GL(4n) carries every ˜J4n-
Lagrangian subspace into a J4n-Lagrangian subspace if and only if α ∈CSp( ˜J4n, J4n),
i.e.,
αTJ4nα = μ ˜J4n,
for some μ = μ(α) ̸= 0.
(2.3)
Proof. The “if” part is obvious, we need only to prove the “only if” part.
Taking α0 ∈Sp( ˜J4n, J4n) (which always exists), e.g., α0 =
5
J2n
J2n
1
2 I2n
1
2 I2n
6
,
we have
CSp( ˜J4n, J4n) = CSp(4n) · α0.
Therefore, it sufﬁces to show that if α carries every J4n- Lagrangian subspace into
J4n-Lagrangian subspace, then α ∈CSp(4n), i.e.,
αTJ4nα = μJ4n
for some μ ̸= 0.
1◦
Take the symmetric pair X =
 I2n
O2n

. By assumption,
αX =
5
Aα
Bα
Cα
Dα
6 5
I
O
6
=
5
Aα
Cα
6
is also a symmetric pair, i.e., AT
αCα −CT
α Aα = O. Similarly, BT
α Dα −DT
αBα = O.
2◦
Take the symmetric pair X =
 S
I

, S ∈Sm(2n). Then every
αX =
5
Aα
Bα
Cα
Dα
6 5
S
I
6
=
5
AαS + Bα
CαS + Dα
6
is also a symmetric pair, i.e.,
O = (αX)TJ4n(αX)
=

STAT
α + BT
α , STCT
α + DT
α
  O
I
−I
O
!  AαS + Bα
CαS + Dα
!
= S(AT
αCα −CT
α Aα)S + S(AT
αDα −CT
α Bα)
−(DT
αAα −BT
α Cα)S + BT
α Dα −DT
αBα
= S(AT
αDα −CT
α Bα) −(AT
αDα −CT
α Bα)TS,
∀S ∈Sm(2n).

218
5. The Generating Function Method
Set P = AT
αDα −CT
α Bα, then the above equation becomes
SP = P TS,
∀S ∈Sm(2n).
It follows that P = μI, i.e.,
AT
αDα −CT
α Bα = μI.
So
αTJ4nα =
5
Aα
Bα
Cα
Dα
6T 5
O
I
−I
O
6 5
Aα
Bα
Cα
Dα
6
=
5 AT
αCα −CT
α Aα
AT
αDα −CT
α Bα
BT
α Cα −DT
αAα
BT
α Dα −DT
αBα
6
= μ
5
O
I
−I
O
6
= μJ4n,
α ∈GL(4n) implies μ ̸= 0.
▲
The inverse matrix of α is denoted by α−1 =
 Aα
Bα
Cα
Dα

. By (2.3), we have
AT
αCα −CT
α Aα = μJ,
AT
αDα −CT
α Bα = O,
BT
α Cα −DT
αAα = O,
BT
α Dα −DT
αBα = −μJ,
(2.4)
Aα = μ−1JCT
α ,
Bα = −μ−1JAT
α,
Cα = −μ−1JDT
α,
Dα = μ−1JBT
α .
(2.5)
Theorem 2.2. Let α =
 Aα
Bα
Cα
Dα

∈CSp( ˜J4n, J4n). The linear fractional trans-
formation σα:{M ∈Sp(2n) | |CαM +Dα| ̸= 0}→{N ∈Sm(2n) | |CαN +Dα| ̸=
0} is one to one and onto.
Proof. From above we know that |CαM + Dα| ̸= 0, iff |CαN + Dα| ̸= 0. Now we
need only to prove M ∈Sp(2n) iff N = σα(M) ∈Sm(2n). It is derived from direct
calculation, since N ∈Sm(2n) iff

(AαM + Bα)(CαM + Dα)−1T = (AαM + Bα)(CαM + Dα)−1,
i.e.,
(M TAT
α + BT
α )(CT
α M T + Dα) = (M TCT
α + DT
α)(AαM + Bα).
Expanding and combining them together, we obtain

5.2 Symplectic, Gradient Mapping and Generating Function
219
O = M T(AT
αCα −CT
α Aα)M + BT
α Dα −DT
αBα
+M T(AT
αDα −CT
α Bα) + (BT
α Cα −DT
αAα)M
= M TJM −J,
then (2.4) holds, iff M ∈Sp(2n).
▲
Deﬁnition 2.3. A mapping w →w = f(w) : R2n →R2n is called a gradient, if its
Jacobian N(w) = fw(w) ∈Sp(2n) everywhere.
Deﬁnition 2.4. A 2n-dim submanifold U of R4n is a "J4n-Lagrangian submanifold
or J4n-Lagrangian submanifold if its tangent plane TzU at z for any z ∈U is a 4n
tangent space of "J4n-Lagrangian subspace or J4n-Lagrangian subspace.
For a symplectic mapping z →z = g(z), the graph[Fen86,FWQW89,Ge91]
Γg = gr(g) :=
 z
z

∈R4n | z = g(z), z ∈R2n
7
is always a "J4n-Lagrange submanifold. For every gradient mapping w →w = f(w),
its graph
Γf = gr(f) :=
 w
w

∈R4n | w = f(w), w ∈R2n
7
is always a J4n-Lagrange submanifold.
Let α =
 Aα
Bα
Cα
Dα

∈CSp( "J4n, J4n), it deﬁnes a linear fractional transfor-
mation
 w
w

= α
 z
z

,
 z
z

= α−1 w
w

,
i.e.,
w = Aαz + Bαz,
z = Aα w + Bαw,
w = Cαz + Dαz,
z = Cα w + Dαw.
(2.6)
Theorem 2.5. Let α ∈CSp( ˜J4n, J4n). Let z →z = g(z) : R2n →R2n be a
canonical mapping with Jacobian M(z) = gz(z) ∈Sp(2n) satisfying (1.2) in (some
neighborhood of) R2n. Then there exists a gradient mapping w →w = f(w) in
(some neighborhood of) R2n with Jacobian N(w) = fw(w) ∈Sm(2n) and a scalar
function —generating function— φ(w) (depending on α and g) such that
1◦
f(w) = ∇φ(w);
(2.7)
2◦
Aαg(z) + Bαz = f(Cαg(z) + Dαz) = ∇φ(Cαg(z) + Dαz);
(2.8)
3◦
N = σα(M) = (AαM + Bα)(CαM + Dα)−1,
M = σα−1(N) = (AαN + Bα)(CαN + Dα)−1;
(2.9)
4◦
Γf = α(Γg), Γg = α−1(Γf).
(2.10)

220
5. The Generating Function Method
Proof. Under the linear transformation α, the image of Γg is
α(Γg) =
' w
w

∈R4n | w = Aαg(z) + Bαz, w = Cαg(z) + Dαz
/
.
Since Γg is a ˜J4n-Lagrangian submanifold and α ∈CSp( ˜J4n, J4n), the tangent plane
of α(Γg) deﬁned by

AαM(z) + Bα
CαM(z) + Dα
7
is a J4n-Lagrangian subspace. So α(Γg) is a J4n-Lagrangian submanifold. By as-
sumption, |CαM + Dα| ̸= 0, and by the implicit function theorem, w = Cαg(z) +
Dαz is invertible and its inverse is denoted by z = z(w). Set:
w = f(w) = (Aαg(z) + Bαz)

z=z(w)= Aαg(z(w)) + Bαz(w),
(2.11)
obviously, such a f(w) satisﬁes the identity
Aαg(z) + Bαz ≡f(Cαg(z) + Dαz).
(2.12)
The Jacobian of f(w) is
N(w) = fw(w) = ∂w
∂w = ∂w
∂z = ∂w
∂z
∂w
∂z
−1
= (AαM(z) + Bα)(CαM(z) + Dα)−1 = σα(M(z)).
(2.13)
By Theorem 2.2 it is symmetric. So f(w) is a gradient map. By the Poincar´e lemma,
there exists a scalar function φ(w), such that
f(w) = ∇φ(w).
In addition, we have
Γf =
 w
w

∈R4n | w = f(w) = Aαg(z(w)) + Bαz(w)

= α(Γg).
Therefore, the theorem is completed.
▲
This theorem tells us that for a ﬁxed α, the corresponding symplectic mapping
determines only one gradient mapping with accuracy up to a constant factor.
Theorem 2.6. Let α ∈CSp( ˜J4n, J4n). Let φ(w) be a scalar function and w →w =
f(w) = ∇φ(w) be its induced gradient mapping and N(w) = fw(w) = φww(w),
the Hessian matrix of φ(w), satisfy (1.13) in (some neighborhood of) R2n. Then, there
exists a canonical map z →z = g(z) with Jacobian M(z) = gz(z) satisfying (1.11)
such that
1◦
Aαf(w) + Bαw = g(Cαf(w) + Dαw), identically in w .
2◦
M = σα−1(N) = (AαN + Bα)(CαN + Dα)−1 ,
N = σα(M) = (AαM + Bα)(CαM + Dα)−1 .
3◦
Γg = α−1(Γf), Γf = α(Γg).
By the way, we can get the original symplectic mapping, if f(w) or φ(w) is ob-
tained from Theorem 2.5.

5.3 Generating Functions for the Phase Flow
221
5.3 Generating Functions for the Phase Flow
Consider the Hamiltonian system
d z
d t = J−1
2n ∇H(z),
z ∈R2n,
(3.1)
where H(z) is a Hamiltonian function. Its phase ﬂow is denoted as gt(z) = g(z, t) =
gH(z, t), being a one-parameter group of canonical maps, i.e.,
g0 = identity,
gt1+t2 = gt1 ◦gt2,
and if z0 is taken as an initial condition, then z(t) = gt(z0) is the solution of (3.1)
with the initial value z0.
Theorem 3.1. Let α ∈CSp( ˜J4n, J4n). Let z →z = g(z, t) be the phase ﬂow of
the Hamiltonian system (3.1) and M0 ∈Sp(2n). Set G(z, t) = g(M0z, t) with Ja-
cobian M(z, t) = Gz(z, t). It is a time-dependent canonical map. If M0 satisﬁes the
transversality condition (1.2), i.e.,
|CαM0 + Dα| ̸= 0,
(3.2)
then there exists, for sufﬁciently small |t| and in (some neighborhood of) R2n, a time-
dependent gradient map w →w = f(w, t) with Jacobian N(w, t) = fw(w, t) ∈
Sm(2n) satisfying the transversality condition (1.13) and a time-dependent generat-
ing function φα,H(w, t) = φ(w, t), such that
1◦f(w, t) = ∇φ(w, t).
(3.3)
2◦
∂
∂tφ(w, t) = −μH(Aα∇φ(w, t) + Bαw).
(3.4)
3◦AαG(z, t) + Bαz ≡f(CαG(z, t) + Dαz, t) ≡∇φ(CαG(z, t) + Dαz, t).(3.5)
4◦N = σα(M) = (AαM + Bα)(CαM + Dα)−1,
M = σα−1(N) = (AαN + Bα)(CαN + Dα)−1.
(3.6)
(3.4) is the most general Hamilton–Jacobi equation for the Hamiltonian system
(3.1) with the linear transformation α.
Proof. Since g(z, t) is differentiable with respect to z and t, so is G(z, t). Condition
(3.2) implies that for sufﬁciently small |t| and in some neighborhood of R2n,
|CαM(z, t) + Dα| ̸= 0.
(3.7)
Thus, by Theorem 2.5, there exists a time-dependent gradient map w = f(w, t), such
that it satisﬁes (3.2) and (3.6).
Set:
H(w, t) = −μH(z)

z=Aα w(w,t)+Bαw
= −μH(Aα w(w, t) + Bαw).
(3.8)

222
5. The Generating Function Method
Consider the differential 1-form
ω1 =
2n

i=1
wi d wi + H(w, t) d t,
then
d ω1 =
2n

i,j=1
∂wi
∂wj d wj ∧d wi +
2n

i=1
∂wi
∂t d t ∧d wi +
2n

i=1
∂H
∂wi d wi ∧d t
=

i<j
 ∂wi
∂wj −∂wj
∂wi

d wj ∧d wi +
2n

i=1
∂wi
∂t −∂H
∂wi

d t ∧d wi. (3.9)
Since N(w, t) = fw(w, t) = ∂w
∂w is symmetric, the ﬁrst term of (3.9) is zero.
Notice that z = G(z, t) = g(M0z, t),
d z
d t = d g(M0z, t)
d t
= J−1∇H(G(z, t)).
(3.10)
So G(z, t) is the solution of the following initial-value problem:
⎧
⎨
⎩
d z
d t = J−1∇H(z),
z(0) = M0z.
Therefore, from the equations
w = AαG(z, t) + Bαz,
w = CαG(z, t) + Dαz,
it follows that
d w
d t = AαJ−1∇H(z),
d w
d t = CαJ−1∇H(z).
Since d w
d t = ∂w
∂w
d w
d t + ∂w
∂t , combining these equations, we obtain
∂w
∂t =

Aα −∂w
∂wCα

J−1 ∇H(z).
On the other hand,
∇w H(w, t) =

Hw(w, t)
T = μ

−Hz ·

Aα ∂w
∂w + BαT
= −μ

(Bα)T +
∂w
∂w
T
(Aα)T
∇H(z)
=

AαJ−1 −∂w
∂wCαJ−1
∇H(z)

by (2.5) and N ∈Sm(2n)

=
∂w
∂t .
So d ω1 = 0. By Poincar´e lemma, there exists, in some neighborhood of R2n+1, a
scalar function φ(w, t), such that

5.3 Generating Functions for the Phase Flow
223
ω1 = w d w + H d t = d φ(w, t),
i.e.,
f(w, t) = ∇wφ(w, t),
∂
∂t φ(w, t) = −μH

Aα∇wφα,H(w, t) + Bαw

.
Therefore, the theorem is completed.
▲
Examples of generating functions are:
(I)
α =
⎡
⎢⎢⎣
O
O
−In
O
In
O
O
O
O
O
O
In
O
In
O
O
⎤
⎥⎥⎦,
μ = 1,
M0 = J,
|CαM0 + Dα| ̸= 0;
w =
 q
q

,
φ = φ(q, q, t);
w =
 −p
p

=
 φq
φq

,
φt = −H(φq, q).
This is the generating function and H.J. equation of the ﬁrst kind.
(II)
α =
⎡
⎢⎢⎣
O
O
−In
O
O
−In
O
O
O
O
O
In
In
O
O
O
⎤
⎥⎥⎦,
μ = 1, M0 = I, |CαM0 + Dα| ̸= 0;
w =
 q
p

,
φ = φ(q, p, t);
w = −
 p
q

=
 φq
φp

,
φt = −H(p, −φp).
This is the generating function and H.J. equation of the second kind.
(III)
α =
⎡
⎣
−J2n
J2n
1
2I2n
1
2I2n
⎤
⎦,
μ = 1,
M0 = I,
|CαM0 + Dα| ̸= 0;
w = 1
2(z + z),
φ = φ(w, t);
w = J(z −z) = ∇φ,
φt = −H

w −1
2J−1∇φ

.
This is the Poincar´e’s generating function[Wei72] and H.J. equation.
If the Hamiltonian function H(z) depends analytically on z then we can derive the
explicit expression of the corresponding generating function via recursions .
Theorem 3.2. Let H(z) depend analytically on z. Then φα,H(w, t) is expressible as
a convergent power series in t for sufﬁciently small |t|, with recursively determined
coefﬁcients:

224
5. The Generating Function Method
φ(w, t) =
∞

k=0
φ(k)(w)tk,
(3.11)
φ(0)(w) =
1
2wTN0w,
N0 = (AαM0 + Bα)(CαM0 + Dα)−1,
(3.12)
φ(1)(w) = −μ(α)H(E0w),
(3.13)
E0 = AαN0 + Bα = M0(CαM0 + Dα)−1.
If k ≥1,
φ(k+1)(w) = −μ(α)
k + 1
k

m=1
1
m!
2n

i1,···,im=1

j1+···+jm=k
jl≥1
Hzi1,···,zim (E0w)
· (Aα∇φ(j1))i1, · · · , (Aα∇φ(jm))im,
(3.14)
where Hzi1,···,zim(E0w) is the m-th partial derivative of H(z) w.r.t. zi1, · · · , zim,
evaluated at z = E0w and

Aα∇φ(jl)(w)

il is the il-th component of the column
vector Aα∇φ(jl)(w).
Proof. Under our assumption, the generating function φα,H(w, t) depends analyti-
cally on w and t in some neighborhood of R2n and for small |t|. Expand it as a power
series as follows:
φ(w, t) =
∞

k=0
φ(k)(w)tk.
Differentiating it with respect to w and t, we get
∇φ(w, t) =
∞

k=0
∇φ(k)(w)tk,
(3.15)
∂
∂tφ(w, t) =
∞

k=0
(k + 1)tkφ(k+1)(w).
(3.16)
By (3.15),
∇φ(0)(w) = ∇φ(w, 0) = f(w, 0) = N0w.
So we can take φ(0)(w) = 1
2wTN0w. We denote E0 = AαN0 + Bα. Then
Aα∇φ(w, t) + Bαw = E0w +
∞

k=1
Aα∇φ(k)(w)tk.
Substitutes it in H

Aα∇φ(w, t) + Bαw

and expanding at z = E0w, we get

5.3 Generating Functions for the Phase Flow
225
H(Aα∇φ(w, t) + Bαw)
= H
*
E0w +
∞

k=1
Aα∇φ(k)(w)tk
+
= H(E0w) +
∞

m=1
1
m !
2n

i1,···,im=1
∞

j1,···,jm=1
tj1+···+jmHzi1,···,zim
· (E0w)(Aα∇φ(j1)(w))i1 · · · (Aα∇φ(jm)(w))im
= H(E0w) +
∞

m=1
1
m !
2n

i1,···,im=1

k≥m
tk

j1+···+jm=kjl≥1
Hzi1,···,zim
· (E0w)(Aα∇φ(j1)(w))i1 · · · (Aα∇φ(jm)(w))im
= H(E0w) +
∞

k=1
tk
k

m=1
1
m !
2n

i1,···,im=1

j1+···+jm=kjl≥1
Hzi1,···,zim
· (E0w)(Aα∇φ(j1))i1 · · · (Aα∇φ(jm))im.
Substituting this formula into the R.H.S. of (3.4), and (3.5) into the L.H.S. of (3.4),
then comparing the coefﬁcients of tk on both sides, we obtain the recursions Equations
(3.13) and (3.14).
▲
In the next section when we use generating functions φα,H to construct difference
schemes we always assume M0 = I. For the sake of convenience, we restate Theorem
3.1 and Theorem 3.2 as follows.
Theorem 3.3. Let α ∈CSp( ˜J4n, J4n). Let z →z = g(z, t) be the phase ﬂow of the
Hamiltonian system (3.1) with Jacobian M(z, t) = gz(z, t). If
|Cα + Dα| ̸= 0,
then there exists, for sufﬁciently small |t| and in (some neighborhood of) R2n, a time-
dependent gradient map w →w = f(w, t) with Jacobian N(w, t) = fw(w, t) ∈
Sm(2n) satisfying the transversality condition (1.13) and a time-dependent generat-
ing function φα,H(w, t) = φ(w, t) such that
f(w, t) = ∇φ(w, t);
(3.17)
∂φ
∂t = −μH(Aα∇φ(w, t) + Bαw);
(3.18)
Aαg(z, t) + Bαz ≡f(Cαg(z, t) + Dαz, t)
≡∇φ(Cαg(z, t) + Dαz, t);
(3.19)
N = σα(M) = (AαM + Bα)(CαM + Dα)−1;
(3.20)
M = σα−1(N) = (AαN + Bα)(CαN + Dα)−1.
(3.21)

226
5. The Generating Function Method
Theorem 3.4. Let H(z) depend analytically on z. Then φα,H(w, t) is expressible as
a convergent power series in t for sufﬁciently small |t|, with the recursively determined
coefﬁcients:
φ(w, t) =
∞

k=0
φ(k)(w)tk;
(3.22)
φ(0)(w) = 1
2wTN0w,
N0 = (Aα + Bα)(Cα + Dα)−1;
(3.23)
φ(1)(w) = −μ(α)H(E0w),
E0 = (Cα + Dα)−1.
(3.24)
If k ≥1,
φ(k+1)(w) = −μ(α)
k + 1
k

m=1
1
m!
2n

i1,···,im=1

j1+···+jm=k
jl≥1
Hzi1,···,zim (E0w)
· (Aα∇φ(j1))i1 · · · (Aα∇φ(jm))im.
(3.25)
5.4 Construction of Canonical Difference Schemes
In this section, we consider the construction of canonical difference schemes for the
Hamiltonian system (3.1). By Theorem 3.1, for a given time-dependent scalar function
ψ(w, t) : R2n × R →R, we can get a time-dependent canonical map ˜g(z, t). If
ψ(w, t) approximates some generating function φα,H(w, t) of the Hamiltonian system
(3.1), then ˜g(z, t) approximates the phase ﬂow g(z, t). Then, ﬁxing t as a time step,
we can get a difference scheme —the canonical difference scheme—whose transition
from one time-step to the next is canonical. By Theorem 3.4, the generating functions
φ(w, t) can be expressed as a power series. So a natural way to approximate φ(w, t)
is to take the truncation of the series. More precisely, we have:
Theorem 4.1. Using Theorems 3.3 and 3.4, for sufﬁciently small τ > 0 as the time-
step, we deﬁne
ψ(m)(w, τ) =
m

i=0
φ(i)(w)τ i,
m = 1, 2, · · · .
(4.1)
Then the gradient mapping
w →w = ˜f(w, τ) = ∇ψ(m)(w, τ)
(4.2)
deﬁnes an implicit canonical difference scheme z = zk →zk+1 = z,
Aαzk+1 + Bαzk = ∇ψ(m)(Cαzk+1 + Dαzk, τ)
(4.3)
of m-th order of accuracy.

5.4 Construction of Canonical Difference Schemes
227
Proof. Since ψ(m)(w, 0) = φ(w, 0), so ψ(m)
ww (w, 0) = φww(w, 0) = fw(w, 0) =
N(w, 0) satisﬁes the transversality condition (1.13), i.e., |CαN(w, 0) + Dα| ̸= 0.
Thus for sufﬁciently small τ and in some neighborhood of R2n, N (m)(w, τ) =
ψ(m)
ww (w, τ) satisﬁes the transversality condition (1.13), i.e., |CαN (m)(w, τ)+Dα| ̸=
0. By Theorem 4.1, the gradient mapping w →w = ˜f(w, τ) = ∇ψ(m)(w, τ) deﬁnes
implicitly a time-dependent canonical mapping z →z = ˜g(z, τ) by the equation
Aαz + Bαz = ∇ψ(m)(Cαz + Dαz, τ).
Thus, the equation
Aαzk+1 + Bαzk = ∇ψ(m)(Cαzk+1 + Dαzk, τ)
is an implicit canonical difference scheme.
Since ψ(m)(w, τ) is the m-th order approximation to φ(w, τ), so is ˜f(w, τ) =
∇ψ(m)(w, τ) to f(w, τ), it follows that the canonical difference scheme given by
(4.3) is of m-th order of accuracy.
▲
Therefore, for every α ∈CSp( "J4n, J4n), we can construct a series of symplectic
schemes for arbitrary order accuracy.
Examples of the canonical difference scheme:
Type (I). Constructing symplectetic scheme by the ﬁrst kind of the generating
function. From Theorem 3.2, as μ = 1,
φ(0)(w) =
1
2wTN0w,
N0 = (Aα + Bα)(Cα + Dα)−1,
φ(1)(w) = −H(E0w),
E0 = (Cα + Dα)−1,
φ(2)(w) =
1
2(∇H)TAαET
0 (∇H)(E0w),
φ(3)(w) = −1
3(∇H)TAα∇wφ(2) −1
6(Aα∇φ(1))THzz(Aα∇φ(1))
= −1
6(∇H)TAα(ET
0 HzzAαET
0 ∇H + ET
0 HzzE0AαT∇H)
−1
6(∇H)TE0AαTHzzAαET
0 ∇H
= −1
6{(∇H)TAαET
0 Hzz(AαET
0 + E0AαT)∇H
+(∇H)TE0AαTHzzAαET
0 ∇H}.
Here we use the matrix notation instead of the component notation in Theorem 3.4.
Hzz denotes the Hessian matrix of H, and all derivatives of H are evaluated at z =
E0w.
Type (II). Constructing symplectetic scheme by the second kind of the generating
function

228
5. The Generating Function Method
α =
⎡
⎢⎢⎣
O
O
−In
O
O
−In
O
O
O
O
O
In
In
O
O
O
⎤
⎥⎥⎦,
αT = α−1 =
⎡
⎢⎢⎣
O
O
O
In
O
−In
O
O
−In
O
O
O
O
O
In
O
⎤
⎥⎥⎦.
w =
 q
p

,
w = −
 p
q

,
N0 = −
 O
I
I
O

,
E0 =
 O
I
I
O

,
AαET
0 = −
 O
O
I
O

,
φ(1)(w) = −H(p, q),
φ(2)(w) = −1
2
n

i=1
(HqiHpi)(p, q),
φ(3)(w) = −1
6
n

i,j=1
(HpipjHqiHqj + HqiqjHpiHpj + HqipjHpiHqj),
where H(z) = H(p1, · · · , pn, q1, · · · , qn), Hzi = ∂H
∂zi .
a.
The ﬁrst order scheme.
ψ(1)(w, τ) = φ(0)(w) + τφ(1)(w).
The equation w = ∇ψ(1)(w, τ) deﬁnes a ﬁrst order canonical difference scheme

pk+1
i
= pk
i −τHqi(pk+1, qk),
qk+1
i
= qk
i + τHpi(pk+1, qk),
i = 1, · · · , n.
(4.4)
When H is separable, H = U(p) + V (q). So
Hqi(pk+1, qk) = Vqi(qk),
Hpi(pk+1, qk) = Upi(pk+1).
At this time, (4.4) becomes

pk+1
i
= pk
i −τVqi(qk),
qk+1
i
= qk
i + τUpi(pk+1),
i = 1, · · · , n.
(4.5)
Evidently, (4.4) is an explicit difference scheme of 1-st order of accuracy. If we set q’s
at half-integer times t =

k + 1
2

τ, then (4.4) becomes
 pk+1
i
= pk
i −τVqi(qk+ 1
2 ),
q
k+ 1
2 +1
i
= q
k+ 1
2
i
+ τUpi(pk+1),
i = 1, · · · , n.
(4.6)
(4.6) is a staggered explicit scheme of 2-nd order accuracy.
b.
The second order scheme.
ψ(2)(w, τ) = ψ(1)(w) + τ 2φ(2)(w).

5.4 Construction of Canonical Difference Schemes
229
The induced gradient map is
w = ∇wψ(2) = −
 
p
q
!
−τ
 
∇qH
∇pH
!
−τ 2
2
⎡
⎢⎢⎢⎣
∇q

n

i=1
HqiHpi

∇p

n

i=1
HqiHpi

⎤
⎥⎥⎥⎦.
So the second order scheme is
⎧
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎩
pk+1
i
= pk
i −τHqi(pk+1, qk) −τ 2
2

n

j=1
HqjHpj

qi
(pk+1, qk),
qk+1
i
= qk
i + τHpi(pk+1, qk) + τ 2
2

n

j=1
HqjHpj

pi
(pk+1, qk),
i = 1, · · · , n.
This scheme is already implicit even when H(z) is separable.
c.
The third order scheme is
pk+1
i
= pk
i −τHqi(pk+1, qk) −τ 2
2
n

j=1

HqjHpj

qi(pk+1, qk)
−τ 3
6
n

l,j=1

HplpjHqlHqj + HqlqjHplHpj + HplqjHqlHpj

qi(pk+1, qk),
qk+1
i
= qk
i + τHpi(pk+1, qk) + τ 2
2
n

j=1

HqjHpj

pi(pk+1, qk)
+τ 3
6
n

l,j=1

HplpjHqlHqj + HqlqjHplHpj + HplqjHqlHpj

pi(pk+1, qk),
where i = 1, · · · , n.
Type (III). Constructing symplectetic scheme by Poincar´e type generating function
α =
⎡
⎣
−J2n
J2n
1
2I2n
1
2I2n
⎤
⎦,
α−1 =
⎡
⎢⎣
1
2J2n
I2n
−1
2J2n
I2n
⎤
⎥⎦.
(4.7)
w = 1
2(z + z),
w = J(z −z).
(4.8)
N0 = 0,
E0 = I,
AαET
0 + E0AαT = 0.
(4.9)
φ(0) = φ(2) = φ(4) = 0,
(4.10)
φ(1)(w) = −H
1
2(z + z)

,
(4.11)
φ(3)(w) = 1
24(∇H)TJHzzJ∇H,
(4.12)
ψ(2)(w, τ) = −τH,
(4.13)
ψ(4)(w, τ) = −τH + τ 3
24(∇H)TJHzzJ∇H.
(4.14)

230
5. The Generating Function Method
a.
The second order scheme is
J(z −z) = w = ∇wψ(2)(w, t) = −τ∇H
1
2(z + z)

,
i.e.,
zk+1 = zk + τJ−1∇H
1
2(zk+1 + zk)

.
(4.15)
It is centered Euler scheme.
b.
The 4-th order scheme is
J(z −z) = w = ∇wψ(4)(w, t) = −τ∇H
1
2(z + z)

+ τ 3
24∇z

(∇H)TJHzzJ∇H

,
(4.16)
i.e.,
zk+1 = zk+τJ−1∇H
% 1
2(zk+1+zk)
&
−τ 3
24J−1∇z

(∇H)TJHzzJ∇H
% 1
2(zk+1+zk)
&
.
It is not difﬁcult to show that the generating function φ(w, t) of type (III) is odd in
t. Hence, Theorem 4.1 leads to a family of canonical difference schemes of arbitrary
even order accuracy.
Theorem 4.2. Let α =
5
−J2n
J2n
1
2I2n
1
2I2n
6
. For sufﬁciently small τ > 0 as the time-
step, we deﬁne
ψ(2m)(w, τ) =
m

i=1
φ(2i−1)(w)τ 2i−1,
m = 1, 2, · · · .
(4.17)
Then the gradient map
w −→w = ˜f(w, τ) = ∇ψ(2m)(w, τ)
deﬁnes implicitly canonical difference schemes z = zk →zk+1 = z,
zk+1 = zk −J−1∇ψ(2m)1
2(zk+1 + zk), τ

(4.18)
of 2m-th order of accuracy. The case m = 1 is the Euler centered scheme.
Remark 4.3. We have following diagram commutes:
phase ﬂow
gradient transf.
generating function
g(z, t)
f(w, t)
φ(w, t)
gm(z, t)
˜f(w, t)
ψ(w)
-
-
α
∇φ

α−1
 ∇ψ
6
?
o(tm+1)

5.5 Further Remarks on Generating Function
231
5.5 Further Remarks on Generating Function
Now we want to construct unconditional Hamiltonian algorithms, i.e., they are sym-
plectic for all Hamiltonian systems.
First we consider the one-leg weighted Euler schemes , i.e.,
z = Es
H,cz :
z = z + sJHz(cz + (1 −c)z),
(5.1)
with real number c being unconditionally symplectic if and only if c = 1
2, which
corresponds to the centered Euler scheme
z = z + sJHz
 z + z
2

.
(5.2)
These simple propositions illustrate a general situation: apart from some very rare
exceptions, the vast majority of conventional schemes are non-symplectic. However, if
we allow c in (5.1) to be a real matrix of order 2n, we get a far-reaching generalization:
(5.1) is symplectic iff
c = 1
2(I2n + J2nB),
BT = B,
cTJ + Jc = J.
(5.3)
The simplest and important cases are[FQ91]:
C :
c = 1
2I2n,
z = z + sJHz
 z + z
2

,
P :
c =
% I
O
O
O
&
,
p
= p −sHq(p, q),
q
= q + sHp(p, q),
Q :
c =
% O
O
O
I
&
,
p
= p −sHq(p, q),
q
= q + sHp(p, q).
(5.4)
For H(p, q) = φ(p) + ψ(q), the above schemes P and Q reduce to explicit schemes.
A matrix α of order 4n is called a Darboux matrix if
αTJ4nα = ˜J4n,
J4n =
% O
−I2n
I2n
O
&
,
˜J4n =
% J2n
O
O
−J2n
&
,
α =
%
a
b
c
d
&
,
α−1 =
% a1
b1
c1
d1
&
.
Every Darboux matrix induces a (linear) fractional transform between symplectic and
symmetric matrices
σα :
Sp(2n) −→Sm(2n),
σα(S) = (aS + b)(cS + d)−1 = A
for
|cS + d| ̸= 0

232
5. The Generating Function Method
with the inverse transform σ−1
α
= σα−1
σ−1
α
:
Sm(2n) −→Sp(2n),
σ−1
α (A) = (a1A + b1)(c1A + d1)−1 = S
for
|c1A + d1| ̸= 0,
where Sp(2n) = {S ∈GL(2n, R) | STJ2nS = J2n} is the group of symplectic ma-
trices.
The above mechanism can be extended to generally non-linear operators on R2n.
Let totally symplectic operators be denoted by SpD2n , and symm(2n) the totality of
symmetric operators (not necessary one-one). Every f ∈symm(2n) corresponds, at
least locally, to a real function φ (unique up to a constant) such that f is the gradient
of φ : f(w) = ∇φ(w), where ∇φ(w) = (φw1(w), · · · , φw2n(w)) = φw(w). Then we
have
σα :
SpD2n −→symm (2n),
σα(g) = (a ◦g + b) ◦(c ◦g + d)−1 = ∇φ
for
|cgz + d| ̸= 0
or alternatively
ag(z) + bz = (∇φ)

cg(z) + dz

,
where φ is called the generating function of Darboux type α for the symplectic oper-
ator g.[FQ91] Then
σ−1
α
:
symm(2n) −→SpD2n,
σ−1
α (∇φ) = (a1 ◦∇φ + b1) ◦(c1 ◦∇φ + d1)−1 = g,
(5.5)
for
|c1φww + d1| ̸= 0
or alternatively
a1∇φ(w) + b1(w) = g(c1∇φ(w) + d1w),
(5.6)
where g is called the symplectic operator of Darboux type α for the generating func-
tion φ.
For the study of symplectic difference scheme, we may narrow down the class of
Darboux matrices to the subclass of normal Darboux matrices, i.e., those satisfying
a + b = 0, c + d = I2n. The normal Darboux matrices α can be characterized as
α =
*
a
b
c
d
+
=
*
J
−J
c
I −c
+
,
c = 1
2(I + JB),
BT = B,
(5.7)
α−1 =
*
a1
b1
c1
d1
+
=
*
(c −I)J
I
cJ
I
+
.
(5.8)
The fractional transform induced by a normal Darboux matrix establishes a 1-1
correspondence between symplectic operators near identity and symmetric operators
near nullity. Then the determinantal conditions could be taken for granted. Those B’s
listed in section 5 correspond to the most important normal Darboux matrices. For

5.5 Further Remarks on Generating Function
233
every Hamiltonian H with its phase ﬂow et
H and for every normal Darboux matrix α,
we get the generating function φ(w, t) = φt
H(w) = φt
H,α(w) of normal Darboux
type α for the phase ﬂow of H by
∇φt
H,α = (Jet
H −J) ◦(cet
H + I −c)−1
for small |t|.
(5.9)
φt
H,α satisﬁes the Hamilton–Jacobi equation
∂
∂tφ(w, t) = −H(w + a1∇φ(w, t)) = −H(w + c1∇φ(w, t))
(5.10)
and can be expressed by Taylor series in |t|:
φ(w, t) =
∞

k=1
φ(k)(w)tk,
|t| small enough.
(5.11)
The coefﬁcients can be determined recursively
φ(1)(w) = −H(w),
and for
k ≥0,
a1 = (c −I)J;
φ(k+1)(w) =
−1
k + 1
k

m=1
1
m! ·

j1+j2+···+jm=k
jl⩾1
DmH(w)
·

(a1∇φ(j1)(w), · · · , a1∇φ(jm)(w)),
(5.12)
where we use the notation of the m-linear form
DmH(w)(a1∇φ(j1)(w), · · · , a1∇φ(jm)(w))
:=
2n

i1,···,im=1
Hzi1···zim(w)(a1∇φ(j1)(w))i1 · · · (a1∇φ(jm)(w))im.
By (5.9), the phase ﬂow z = et
Hz satisﬁes
z −z = −J∇φt
H,α

cz + (I −c)z

= −
∞

j=1
tjJ∇φ(j)
cz + (I −c)z

.
(5.13)
Let ψs be a truncation of φs
H,α up to a certain power, e.g., sm. Using the inverse
transformation σ−1
α , we obtain the symplectic operator
gs = σ−1
α (∇ψs),
|s| small enough,
(5.14)
which depends on s, H, α (or equivalently B) and the mode of truncation. It is a
symplectic approximation to the phase ﬂow es
H and can serve as the transition operator
of a symplectic difference scheme for the Hamiltonian system (3.1)
z −→z = gsz :
z = z −J∇ψs(cz + (I −c)z),
c = 1
2(I + JB).
(5.15)
Thus, using the technique of the phase ﬂow generating functions, we have constructed,
for every H and every normal Darboux matrix, a hierarchy of symplectic schemes by
truncation. The simple symplectic schemes (5.4) correspond to the lowest truncation.

234
5. The Generating Function Method
5.6 Conservation Laws
The conservation laws we refer to here[FQ91,FW91a,GF88,Ge91] have two meanings. As it
is well known, the Hamiltonian system (3.1) itself has ﬁrst integrals which are con-
served in time evolution, e.g., the Hamiltonian is always a ﬁrst integral. Hence, the
ﬁrst question is how many ﬁrst integrals of Hamiltonian system (3.1) can be preserved
by symplectic algorithms. The second question is whether or not there exist their own
ﬁrst integrals in case the original ﬁrst integrals can not be preserved by symplectic
algorithms.
We ﬁrst consider preservation of the ﬁrst integrals of Hamiltonian systems by sym-
plectic algorithms. The detailed discussion is referred to references[FQ91,Fen93b,GF88,Wan94].
Consider the Hamiltonian system
d z
d t = J∇H(z).
(6.1)
Suppose
z = gs
H(z)
(6.2)
is a symplectic algorithm. Under a symplectic transformation z = S(y), system (6.1)
can be transformed into
d y
d t = J∇˜H(y),
(6.3)
where ˜H(y) = H(S(y)) and scheme (5.6) can be transformed into
y = S−1 ◦gs
H ◦S(y).
(6.4)
On the other hand, the algorithm gs can be applied to system (6.3) directly and the
corresponding scheme is
y = gs
˜
H(y).
(6.5)
Naturally, one can ask if (6.4) and (6.5) are the same. This introduces the following
concept.
Deﬁnition 6.1. A symplectic algorithm gs is invariant under the group G of symplec-
tic transformations, or G-invariant, for Hamiltonian H if
S−1 ◦gs
H ◦S = gs
H◦S,
∀S ∈G;
gs is symplectic invariant for Hamiltonian H, if
S−1gs
H ◦S = gs
H◦S,
∀S ∈Sp(2n).
In practice, the second case is more common. Generally speaking, numerical al-
gorithms depend on the coordinates, i.e., they are locally represented. But many nu-
merical algorithms may be independent of the linear coordinate transformations.

5.6 Conservation Laws
235
Theorem 6.2. [FW91a,GF88,Coo87] Suppose F is a ﬁrst integral of the Hamiltonian sys-
tem (6.1) and et
F is the corresponding phase ﬂow. Then F is conserved up to a constant
by the symplectic algorithm gs
H,
F ◦gs
H = F + c,
c is a constant
(6.6)
if and only if gs
H is et
F -invariant.
Proof. We ﬁrst assume that the symplectic algorithm gs
H is et
F -invariant, i.e.,
e−t
F ◦gs
H ◦et
F = gs
H◦et
F ,
∀t ∈R.
(6.7)
Since F is a ﬁrst integral of the Hamiltonian system (6.1) with the Hamiltonian
H, H is also the ﬁrst integral of the Hamiltonian system (5.6) with the Hamiltonian
F, i.e.,
H ◦et
F = H.
(6.8)
It follows from (5.6) and (6.8) that
e−t
F ◦gs
H ◦et
F = gs
H,
i.e.,
et
F = (gs
H)−1 ◦et
F ◦gs
H.
(6.9)
Differentiating (6.9) with respect to t at point 0 and noticing that
d et
F
d t

t=0 = J∇F,
we get
J∇F = (gs
H)−1
∗J∇F ◦gs
H.
(6.10)
Since gs
H is symplectic, i.e.,
(gs
H)−1
∗J = J(gs
H)T
∗,
we have
J∇F = J(gs
H)T
∗∇F ◦gs
H = J∇(F ◦gs
H),
then
∇F = (gs
H)T
∗∇F ◦gs
H = ∇(F ◦gs
H).
It follows that
F ◦gs
H = F + c.
(6.11)
We now assume that F is conserved by gs
H, i.e., (6.6) is valid. Then noticing that
the phase ﬂows of the vector ﬁelds J∇F and (gs
H)−1
∗J∇F ◦gs
H are et
F and (gs
H)−1 ◦
et
F ◦gs
H respectively, we can get (5.6) similarly, i.e., gs
H is et
F -invariant.
Symplectic invariant algorithms are invariant under the symplectic group Sp(2n)
and hence invariant under the phase ﬂow of any quadratic Hamiltonian.
▲

236
5. The Generating Function Method
Corollary 6.3. Symplectic invariant algorithms for Hamiltonian systems preserve all
quadratic ﬁrst integrals of the original Hamiltonian systems up to a constant.
If a symplectic scheme has a ﬁxed point, i.e., there is a point z such that gs
H(z) = z,
then the constant c = 0 and the ﬁrst integral is conserved exactly. Since linear schemes
always have the ﬁx point 0, we have the following result.
Corollary 6.4. Linear symplectic invariant algorithms for linear Hamiltonian sys-
tems preserve all quadratic ﬁrst integrals of the original Hamiltonian systems.
Example 6.5. Centered Euler scheme and symplectic Runge–Kutta methods are sym-
plectic invariants. Hence they preserve all quadratic ﬁrst integrals of system (6.1) up
to a constant.
Example 6.6. Explicit symplectic scheme (4.5), and other explicit symplectic schemes
(2.1) – (2.4) considered in Chapter 8 are invariant under the linear symplectic transfor-
mations of the form diag (A−T, A), A ∈GL(n). Thus they preserve angular momen-
tum pTBq of the original Hamiltonian systems, since their inﬁnitesimal symplectic
matrices are diag (−BT, B), B ∈gl(n).
In fact, these results can be improved. Symplectic Runge–Kutta methods preserve
all quadratic ﬁrst integrals of system (6.1) exactly. For generating function methods,
we have the following result[FW91a,GF88,FQ87].
Theorem 6.7. Let gs
H,α be a symplectic method constructed by the generating func-
tion method with the Darboux type α. If F(z) = 1
2zTAz, A ∈Sm(2n), is a quadratic
ﬁrst integral of the Hamiltonian system (6.1) and
AJB −BJA = O,
(6.12)
then F(z) is conserved by gs
H,α, i.e.,
F(z) = F(z),
or
F ◦gs
H,α = F.
(6.13)
For B = O, i.e., the case of centered symplectic difference schemes, (6.12) is
always valid. So all centered symplectic difference schemes preserve all quadratic
ﬁrst integrals of the Hamiltonian system (6.1) exactly.
Proof. Since F(z) is the ﬁrst integral of system (6.1),
1
2 zTAz = 1
2zTAz,
z = et
H.
It can be rewritten as
1
2(z + z)TA(z −z) = 0,
z = et
H.
(6.14)
From (6.12), it follows that

5.6 Conservation Laws
237
1
2

JB(z −z)
TA(z −z) = 1
4(z −z)T(AJB −BJA)(z −z) = 0,
∀z, z ∈R2n.
Combining it with (6.14), we have

cz + (I −c)z
TA(z −z) = 0.
Using (5.13), it becomes

cz + (I −c)z
TAJ
∞

j=1
tj∇φ(j)
cz + (I −c)z

= 0.
From this, we get
wTAJ∇φ(j)(w) = 0,
∀j ≥1,
∀w ∈R2n.
Taking w = cz + (I −c)z, where
z = gs
H,αz = z −J∇ψ(m)
cz + (I −c)z

= z −
m

j=1
sjJ∇φ(j)
cz + (I −c)z

,
we have
wTA(z −z) = −
m

j=1
sjwTAJ∇φ(j)(w) = −AJ∇ψ(w) = 0,
since
wTA(z −z) =
1
2 zTAz −1
2zTAz + 1
2(z −z)T(AJB −BJA)(z −z)
=
1
2 zTAz −1
2zTAz.
Therefore, the theorem is completed.
▲
We list some of the most important normal Darboux matrices c, the type matrices
B, together with the corresponding form of symmetric matrices A of the conserved
quadratic invariants F(z) = 1
2zTAz:
c = I −c = 1
2I,
B = O,
A arbitrary,
c =
 In
O
O
O

,
c =
 O
O
O
In

,
B =

O
−In
−In
O

,
B =
 O
In
In
O

,
A =
 O
b
bT
O

,
b arbitrary;
angular
momemtum.
c = 1
2

In
±In
∓In
In

, B = ∓I2n,
A =

a
b
−b
a

,aT = a, bT = −b;
Hermitian type.
c = 1
2

I
±I
±I
O

,
B = ±
 In
O
O
−In

, A =

a
b
−b
−a

, aT = a,
bT = −b.

238
5. The Generating Function Method
Apart from the ﬁrst integrals of the original Hamiltonian systems, a linear sym-
plectic algorithm has its own quadratic ﬁrst integrals. For the linear Hamiltonian sys-
tem
d z
d t = Lz,
L = JA ∈sp(2n)
(6.15)
with a quadratic Hamiltonian H(z) = 1
2zTAz, AT = A, let us denote its linear
symplectic algorithm by
z = gs
H(z) = G(s, A)z,
G ∈Sp(2n).
(6.16)
Let us assume that the scheme (6.16) is of order r. Then G(s) has the form
G(s) = I + sL(s),
L(s) = L + s
2 !L2 + s2
3 !L3 + · · · + sr−1
r ! Lr + O(sr).
For sufﬁciently small time step size s, G(s) can be represented as
G(s) = es"L(s),
"L(s) = L + O(sr),
"L(s) ∈sp(2n).
So (6.16) becomes
z = es"L(s)z.
This is the solution z(t) of the linear Hamiltonian system
d z
d t = "L(s)z,
"L(s) ∈sp(2n),
(6.17)
with the initial value z(0) = z0 evaluated at time s. The symplectic numerical solution
zk = Gk(s)z0 = eks"L(s)z0
is just the solution of system (6.17) at discrete points ks, k = 0, ±1, ±2, · · ·. Hence,
for sufﬁciently small s, scheme (6.16) corresponds to a perturbed linear Hamiltonian
system (6.17) with the Hamiltonian
"H(z, s) = 1
2

z, J−1"L(s)z

= 1
2zTJ−1Lz + O(sr) = H(z) + O(sr).
(6.18)
It is well-known that the linear Hamiltonian system has n functionally independent
quadratic ﬁrst integrals. So does the scheme (6.15). The following
"Hi(z, s) = 1
2zTJ−1"L2i−1(s)z,
i = 1, 2, · · · , n
(6.19)
are the ﬁrst integrals of the perturbed system (6.17), therefore, of scheme (6.16), which
approximate the ﬁrst integrals of system (6.15)
Hi(z) = 1
2zTJ−1L2i−1z,
i = 1, 2, · · · , n

5.7 Convergence of Symplectic Difference Schemes
239
up to O(sr). Another group of ﬁrst integrals of (6.16) is
Hi(z, s) = zTJ−1Gi(s)z,
i = 1, 2, · · · , n.
They can be checked easily. The ﬁrst one is[FW94]
H1(z, s) = zTJ−1G(s)z = zTJ−1(I + sL(s))z
= szTJ−1L(s)z = 2sH(z) + O(s3).
5.7 Convergence of Symplectic Difference Schemes
We considered Hamiltonian systems
d z
d t = JHz,
z ∈U ⊂R2n.
(7.1)
In this section, we shall prove that all symplectic schemes for Hamiltonian systems
constructed by generating functions are convergent, if τ →0.
A normal Darboux matrix, which will be introduced in the next chapter, has the
form
α =
5
Aα
Bα
Cα
Dα
6
=
⎡
⎣
J
−J
1
2(I + JB)
1
2(I −JB)
⎤
⎦,
BT = B,
α−1 =
5
Aα
Bα
Cα
Dα
6
=
⎡
⎢⎣
1
2(JBJ −J)
I
1
2(JBJ + J)
I
⎤
⎥⎦,
(7.2)
which deﬁnes a linear transformation in the product space R2n × R2n:
5
w
w
6
= α
5
z
z
6
,
5
z
z
6
= α−1
5
w
w
6
,
i.e.,
w = Jz −Jz,
w = 1
2(I + JB) z + 1
2(I −JB) z,
BT = B.
(7.3)
Let z →z = g(z, t) be the phase ﬂow of the Hamiltonian systems (5.7); it is a time
dependent canonical map. There exist, for sufﬁciently small |t| and in (some neigh-
borhood of) R2n, a time-dependent gradient map w →w = f(w, t) with Jacobian
fw(w, t) ∈Sm(2n) (i.e.,everywhere symmetric) and a time-dependent generating
function φ = φα,H, such that
f(w, t) = ∇φα,H(w, t),
Aαg(z, t) + Bαz = ∇φ(Cαg(z, t) + Dαz, t).
(7.4)

240
5. The Generating Function Method
On the other hand, for a given time-dependent scalar function ψ(w, t) : R2n × R →
R, we can obtain a time-dependent canonical map "g(z, t). If ψ(w, t) approximates the
generating function φα,H(w, t) of the Hamiltonian system (5.7), then "g(z, t) approxi-
mates the phase ﬂow g(z, t). For sufﬁciently small τ > 0 as the time step, deﬁne
φ(m) =
m

k=1
φ(k)(w)τ k,
(7.5)
where φ(1)(w) = −H(w), and for k ≥0, Aα = 1
2(JBJ −J),
φ(k+1)(w) =
−1
k + 1
k

m=1
1
m!
2n

i1,···,in=1
Hzi1 · · · zim(w)
·

j1+···+jm=k

Aα∇φ(j1)(w)

i1 · · ·

Aα∇φ(jm)(w)

im. (7.6)
Then, ψ(m)(w, τ) is the m-th approximation of φα,H(w, τ) , and the gradient map,
w −→w = "f(w, τ) = ∇ψ(m)(w, τ).
(7.7)
Deﬁne a canonical map z →z = "g(z, τ) implicitly by equation
Aαz + Bαz = (∇ψ(m))(Cαz + Dαz, z).
(7.8)
The implicit canonical difference scheme of m-th order accuracy
z = zk −→z = zk+1 = "g(zk, τ),
(7.9)
for system (5.7) is obtained.
For the sake of simplicity, we denote "gτ(z) = "g(z, τ). Then
"g0(z) = z,
di "gτ(z)
d τ i

τ=0 = di gτ(z)
d τ i

τ=0,
(7.10)
where gτ(z) is the phase ﬂow of g(z, τ).
Theorem 7.1. If H is analytical in U ⊂R2n, then the scheme (7.9) is convergent
with m-th order accuracy[CHMM78,QZ93].
Proof. For the step-forward operator "gτ, we set
z1 = "gτ(z), z2 = "gτ(z1), · · · , zk = "gτ(zk−1),
we have zk = "gk
τ .
First, we prove that the convergence holds locally. We begin by showing that for
any z0, the iterations are deﬁned for "zn
t/k (n ≤k), if t is sufﬁciently small. Indeed,
in the neighborhood of z0, "gτ(z) = z + o(τ), thus, if "gl
t
k (z) (l = 1, 2, · · · , n −1) is
deﬁned for z in the neighborhood of z0,

5.7 Convergence of Symplectic Difference Schemes
241
"gn
t
k (z) −z =

"gn
t
k (z) −"gn−1
t
k
(z)

+

"gn−1
t
k
(z) −"gn−2
t
k
(z)

+ · · · +

"g t
k (z) −z

= o
 t
k

+ · · · + o
 t
k

0
12
3
n
= o(t).
which is small and independent of k for sufﬁciently small t. So "gn
t/k (n ≤k) is deﬁned
and remains in Uz0 for z near z0.
Since H is analytical, for any z1, z2 ∈Uz0, there exists a constant C, such that
∥JHz(z1) −JHz(z2)∥≤∥J∥∥Hz(z1) −Hz(z2)∥≤C∥z1 −z2∥.
Let F(t) = ∥g(z1, t)−g(z2, t)∥, where g(zi, t) = zi+
- t
0
JHz(g(zi, s)) d s (i = 1, 2),
F(t) =
????
- t
0
JHz

g(z1, s)

d s −
- t
0
JHz

g(z2, s)

d s + z1 −z2
????
≤∥z1 −z2∥+ C
- t
0
F(s) d s,
using Gronwall inequality, we have
F(t) = ∥g(z1, t) −g(z2, t)∥≤eC|t| ∥z1 −zn∥,
gt(z) −"gk
t
k
= gk
t
k (z) −"gk
t
k
= gk−1
t
k
g t
k (z) −gk−1
t
k
"g t
k (z) + gk−2
t
k
g t
k (y1)
−gk−2
t
k
"g t
k (y1) + · · · + gk−1
t
k
g t
k (yl−1)
−gk−1
t
k
"g t
k (yl−1) + · · · + g t
k (yk−1) −"g t
k (yk−1),
where yl = "gl
t
k (z). Then we have
∥gt(z) −"gk
t
k (z)∥≤
k

e=1
exp
C
k −l |t|

k

∥g t
k (yl−1) −"g t
k (yl−1)∥
≤k exp (C|t|) o
 t
k
m
−→0,
if k −→∞.
Here, we use consistent supposition gτ(z) −"gτ(z) = o(τ)m.
Now, we assume that g(z, t) is deﬁned for 0 ≤t ≤T. We shall show that "gk
t
k con-
verges to g(z, t). By the above proof and domain compactness, if N is large enough,
g t
N = lim
k→∞"gk
t
k N uniformly convergent on a neighborhood of the curve t →gt(z).
Thus, for 0 ≤t ≤T, gt(z) = gN
t
N =
lim
k→∞("gk
t
k N)N(z). By the uniformity of t,
gt(z) = lim
k→∞"gk
t
k (z).
From this proof, one can see that if H is not analytical but Hz satisﬁes the local
Lipschitz condition, then the scheme (7.9) is convergent with order m = 1 .
▲

242
5. The Generating Function Method
5.8 Symplectic Schemes for Nonautonomous System
We consider the following system of canonical equations:
d pi
d t = −∂H
∂qi ,
d qi
d t = ∂H
∂pi ,
i = 1, 2, · · · , n
(8.1)
with Hamiltonian function H(p1, p2, · · · , pn, q1, q2, · · · , qn, t). This is a nonautono-
mous Hamiltonian system. This approach, which is applied particularly to nonau-
tonomous system, is to consider the time t as an additional dependent variable. Now
we can choose a parameter τ as a new independent variable. The original problem
therefore becomes one of ﬁnding q1, · · · , qn with t as a function of an independent
variable τ. Hence, we set the coordinate qi by adding t = qn+1.
The corresponding phase space must have 2n+2 dimensions, z = (p1, p2, · · · , pn,
h, q1, q2, · · · , qn, t), here t and h being merely alternative notations for qn+1 and pn+1.
The new momentum h associated with the time t is, as its physical interpretation, the
negative of the total energy. We call this new space the extended phase space.
An advantage of adding another degree of freedom to the analysis is that the sys-
tem now resembles an autonomous system [Arn89,Qin96,Gon96] with 2n + 2 degree free-
dom, because its Hamiltonian is not an explicit function of τ.
In the extended phase space, (8.1) becomes
d z
d t = J ∇K(z),
J = J2n+2 =
5
O
−J2n+1
J2n+1
O
6
,
(8.2)
where K(z) = h + H(p1, p2, · · · , pn, q1, q2, · · · , qn, t), which we call the “extended
Hamiltonian function”. We write (8.2) in another form
d pi
d τ = −∂H
∂qi ,
d qi
d τ = ∂H
∂pi ,
i = 1, 2, · · · ,
(8.3)
d pn+1
d τ
= −∂H
∂qn+1 ,
(8.4)
d qn+1
d τ
= 1.
(8.5)
Equation (8.4) shows that our normalized parameter now becomes equal to qn+1,
which is the time t. The Equation (8.3) is the original canonical equation. The last
Equation (8.5) gives the law according to which the negative of the total energy, pn+1,
changes with the time.
The general form of the canonical Equation (8.2) has great theoretical advantages.
It shows the role of conservative system in a new light. We notice that after adding the
time t to the mechanical variables, every system becomes conservative. The extended
Hamiltonian function k does not depend on variable τ explicitly and thus our system is
a conservative system in the extended phase space. The method of generating function
plays a central role in the construction of symplectic schemes. In [Fen86] a constructive

5.8 Symplectic Schemes for Nonautonomous System
243
general theory of generating function roughly reads as follows. Let a normal Darboux
matrix be
α =
5
Aα
Bα
Cα
Dα
6
=
⎡
⎣
J
−J
1
2(I + JB)
1
2(I −JB)
⎤
⎦,
BT = B,
α−1 =
5
Aα
Bα
Cα
Dα
6
=
⎡
⎢⎣
1
2(JBJ −J)
I
1
2(JBJ + J)
I
⎤
⎥⎦.
Deﬁne a linear transformation in product space R2n+2 × R2n+2 by
 w
w
!
= α
 z
z
!
,
 z
z
!
= α−1
 w
w
!
,
(8.6)
i.e.,
w = Jz −Jz,
w = 1
2(I + JB)z + 1
2(I −JB)z,
BT = B.
(8.7)
Let z →z = g(z, τ) be the phase ﬂow of the Hamiltonian system (8.2). It is a
time-dependent canonical map. There exists, for a sufﬁciently small τ and in (some
neighborhood of) R2n+2, a time-dependent gradient mapping w →w = f(w, τ) with
Jacobian fw(w, t) ∈Sm(2n + 2) (i.e., symmetric everywhere) and a time-dependent
generating function φ = φα,K(w, τ), such that
∂φ
∂τ = −K

Aα∇φ(w) + Bαw

,
f(w, τ) = ∇φα,K(w, τ),
Aαg(z, t) + Bαz ≡(∇φ)

Cαg(z, t) + Daz, t

.
(8.8)
On the other hand, for a given time-dependent scalar function ψ(w, t) : R2n+2×R →
R, we can get a time-dependent canonical map "g(z, τ). If ψ(w, τ) approximates the
generating function φα,K(w, τ) of the Hamiltonian system (8.2), "g(z, t) approximates
the phase ﬂow g(z, t).
For a sufﬁciently small s > 0 as the time-step, deﬁne
ψ(m) =
m

k=1
φ(k)(w) sk,
(8.9)
where
φ(1)(w) = −K(w),
Aα = 1
2(JBJ −J).
For k ≥0,

244
5. The Generating Function Method
φ(k+1)(w) =
−1
k + 1
k

m=1
1
m !
2n

i1,···,im=1
Kzi1···zim(w)
·

j1 + · · · + jm = k
jl = 0

Aα∇φ(j1)(w)

i1 · · ·

Aα∇φ(jm)(w)

im.
(8.10)
Then ψ(m)(w, s) is the m-th approximation of φα,K(w, s), and the gradient mapping
w −→w = "f(w, s) = ∇ψ(m)(w, s)
(8.11)
deﬁnes a canonical map z →z = "g(z, s) implicitly by equation
Aαz + Bαz = (∇ψ(m))(Cαz + Dαz, s).
(8.12)
An implicit canonical difference scheme
z = zk −→z = zk+1 = "g(zk, s),
(8.13)
for system (8.2) is obtained[Qin96], and this scheme is of m-th order of accuracy.
Let B = 0,
φ(1)(w) = −K(w),
φ(2) = φ(4) = 0,
φ(3) = 1
24(∇K)TJKzzJ∇K.
We have a scheme of second order:
J(z −z) = w = ∇φ(2)(w, s) = −s∇K
 z + z
2

,
zk+1 = zk + sJ∇K
zk+1 + zk
2

,
pk+1
i
= pk
i −sHqi
pk+1 + pk
2
, qk+1 + qk
2
, tk+1 + tk
2

,
qk+1
i
= qk
i + sHpi
pk+1 + pk
2
, qk+1 + qk
2
, tk+1 + tk
2

,
hk+1 = hk −sHt
pk+1 + pk
2
, qk+1 + qk
2
, tk+1 + tk
2

,
tk+1 = tk + s.
(8.14)
This is the time-centered Euler scheme.
Scheme of the fourth order:
J(zk+1 −zk) = ∇φ(4)zk+1 + zk
2

= −s∇K
zk+1 + zk
2

J∇K
zk+1 + zk
2

+ s3
24∇z

(∇K)TJKzzJ∇K

,
zk+1 = zk + sJ∇K
zk+1 + zk
2

−s3
24J∇z

(∇K)TJKzzJ∇K

,
(8.15)

5.8 Symplectic Schemes for Nonautonomous System
245
i.e.,
pk+1
i
= pk
i −sHqi
pk+1 + pk
2
, qk+1 + qk
2
, tk+1 + tk
2

−s3
24(HpjplqiHqjHql + 2HpjplHqjqiHql −2HqjplqiHpjHql
−2HqjplHpjqiHql −2HqjplHpjHqlqi + 2HqjqlHplqiHpj + HqjqlqiHplHpj
−2HqjqiHpjt −2HqjHpjqit + 2HpjqiHqjt + 2HpjHqjqit + Hqitt),
qk+1
i
= qk
i + sHpj
pk+1 + pk
2
, qk+1 + qk
2
, tk+1 + tk
2

+ s3
24(HpjplpiHqjHql + 2HpjplHqjpiHql −2HqjplpiHpjHql
−2HqjplHpjpiHql −2HqjplHpjHqlpi + 2HqjplHplqiHpj + HqjqlpiHplHpj
−2HqjpiHpjt −2HqjHpjpit + 2HpjpiHqjt + 2HpjHqjpit + Hpitt),
hk+1 = hk −sHt
pk+1 + pk
2
, qk+1 + qk
2
, tk+1 + tk
2

−s3
24(HpjpltHqjHql + 2HpjplHqjtHql −2HqjpltHpjHql
−2HqjplHpjtHql −2HqjplHpjHqlt + 2HqjqlHpltHql + HqjqltHplHpj
−2HqjtHpjt −2HqjHpjtt + 2HpjtHqjt + 2HpjHqit + Httt),
tk+1 = tk + s.
(8.16)
Let
B = −
 O
I
I
O
!
,
w =
 p
q
!
.
We have
φ(1) = −K(w),
φ(2) = −1
2(KqiKpi)(w),
φ(3) = −1
6(KpjplKqjKql + KqjqlKpjKpl + KqjplKpjKql)(w),
or
φ(2) = −1
2(HqiHpj + Ht)(w),
φ(3) = −1
6(HpjplHqiHql + HqlHqjplHpj + HqlHplt
+HqjqlHpjHpl + 2HpjHqjt + Htt).
(8.17)
Scheme of the ﬁrst order

246
5. The Generating Function Method
pk+1
i
= pk
i −sHqi(pk+1, qk, tk),
qk+1
i
= qk
i + sHpi(pk+1, qk, tk),
hk+1 = hk −sHt(pk+1, qk, tk),
tk+1 = tk + s.
(8.18)
Scheme of the second order
pk+1
i
= pk
i −sHqi(pk+1, qk, tk) −s2
2 (Hqit + HqjqiHpj + HqjHpjqi)(pk+1, qk, tk),
qk+1
i
= qk
i + sHpi(pk+1, qk, tk) + s2
2 (Hpit + HqjpiHpj + HqjHpjpi)(pk+1, qk, tk),
hk+1 = hk −sHt(pk+1, qk, tk) −s2
2 (Htt + HqjtHpj + HqjHpjt)(pk+1, qk, tk),
tk+1 = tk + s.
(8.19)
Scheme of the third order
pk+1
i
= pk
i −sHqi(pk+1, qk, tk) −s2
2 (Hqit + HqjqiHpj + HqjHpjqi)
· (pk+1, qk, tk) −s3
6 (Htt + 2HpjHqjt + HqlHplt + HpjplHqjHql
+HqlHqjplHpj + HqjqlHpjHpl)qi(pk+1, qk, tk),
qk+1
i
= qk
i + sHpi(pk+1, qk, tk) + s2
2 (Hpit + HqjpiHpj + HqjHpjpi)
· (pk+1, qk, tk) + s3
6 (Htt + 2HpjHqjt + HqlHplt + HpjplHqjHql
+HqlHqjplHpj + HqjqlHpjHpl)pi(pk+1, qk, tk),
hk+1 = hk −sHt(pk+1, qk, tk) −s2
2 (Htt + HqjtHpj + HqjHpjt)
· (pk+1, qk, tk) −s3
6 (Htt + 2HpjHqjt + HqlHplt + HpjplHqjHql
+HqlHqjplHpj + HqjqlHpjHpl)t(pk+1, qk, tk),
tk+1 = tk + s.
(8.20)

Bibliography
[Arn89] V. I. Arnold: Mathematical Methods of Classical Mechanics. Springer-Verlag, GTM
60, Berlin Heidelberg, Second edition, (1989).
[CHMM78] A. Chorin, T. J. R. Huges, J. E. Marsden, and M. McCracken: Product formulas
and numerical algorithms. Comm. Pure and Appl. Math., 31:205–256, (1978).
[Coo87] G. J. Cooper: Stability of Runge–Kutta methods for trajectory problems. IMA J.
Numer. Anal., 7:1–13, (1987).
[Fen86] K. Feng: Difference schemes for Hamiltonian formalism and symplectic geometry. J.
Comput. Math., 4:279–289, (1986).
[Fen93b] K. Feng: Symplectic, contact and volume preserving algorithms. In Z.C Shi and
T. Ushijima, editors, Proc.1st China-Japan conf. on computation of differential equation-
sand dynamical systems, pages 1–28. World Scientiﬁc, Singapore, (1993).
[FQ91] K. Feng and M.Z. Qin: Hamiltonian algorithms for Hamiltonian systems and a com-
parative numerical study. Comput. Phys. Comm., 65:173–187, (1991).
[FW91] K. Feng and D.L. Wang: A Note on Conservation Laws of Symplectic Difference
Schemes for Hamiltonian Systems. J. Comput. Math., 9(3):229–237, (1991).
[FW94] K. Feng and D.L. Wang: Dynamical systems and geometric construction of algo-
rithms. In Z. C. Shi and C. C. Yang, editors, Computational Mathematics in China, Con-
temporary Mathematics of AMS Vol 163, pages 1–32. AMS, (1994).
[FWQW89] K. Feng, H. M. Wu, M.Z. Qin, and D.L. Wang: Construction of canonical dif-
ference schemes for Hamiltonian formalism via generating functions. J. Comput. Math.,
7:71–96, (1989).
[Ge91] Z. Ge: Equivariant symplectic difference schemes and generating functions. Physica
D, 49:376–386, (1991).
[GF88] Z. Ge and K. Feng: On the Approximation of Linear Hamiltonian Systems. J. Comput.
Math., 6(1):88–97, (1988).
[Gon96] O. Gonzalez: Time integration and discrete Hamiltonian systems. J. Nonlinear. Sci.,
6:449–467, (1996).
[Hua44] L. K. Hua: On the theory of automorphic function of a matrix I, II. Amer. J. Math.,
66:470–488, (1944).
[LL99] L. D. Landau and E. M. Lifshitz:
Mechanics, Volume I of Course of Theoretical
Physics. Corp. Butterworth, Heinemann, New York, Third edition, (1999).
[Qin96] M.Z. Qin: Symplectic difference schemes for nonautonomous Hamiltonian systemes.
Acta Applicandae Mathematicae, 12(3):309–321, (1996).
[Qin97a] M. Z. Qin: A symplectic schemes for the PDEs. AMS/IP studies in Advanced Math-
emateics, 5:349–354, (1997).
[QZ93] M. Z. Qin and W. J. Zhu: A note on stability of three stage difference schemes for
ODE’s. Computers Math. Applic., 25:35–44, (1993).
[Sie43] C.L. Siegel: Symplectic geometry. Amer. J. Math., 65:1–86, (1943).
[Wan94] D. L. Wang: Some acpects of Hamiltonian systems and symplectic defference meth-
ods. Physica D, 73:1–16, (1994).
[Wei72] A. Weinstein: The invariance of Poincar´es generating function for canonical transfor-
mations. Inventiones Math., 16:202–213, (1972).

Chapter 6.
The Calculus of Generating Functions and
Formal Energy
In the previous chapter, we constructed the symplectic schemes of arbitrary order via
generating function. However the construction of generating functions is dependent
on the chosen coordinates. One would like to know under what circumstance will the
construction of generating functions be independent of the coordinates. The generating
functions are deeply associated with the conservation laws, so it is important to study
their properties and computations.
6.1 Darboux Transformation
Consider a cotangent bundle T ∗Rn ≃R2n with natural symplectic structure[Fen98a]:
J2n =
5
O
In
−In
O
6
.
(1.1)
Now we consider R4n and the product of cotangent bundles T ∗R × T ∗R ≃R4n
with natural product symplectic structure:
"J4n =
5 −J2n
O
O
J2n
6
.
(1.2)
Correspondingly, we consider the product space Rn × Rn ≃R2n. Its cotangent
bundle, T ∗(Rn × Rn) = T ∗R2n ≃R4n has a natural symplectic structure:
J4n =
5
O
I2n
−I2n
O
6
.
(1.3)
Choose symplectic coordinates z = (p, q) on the symplectic manifold, then for sym-
plectic transformation, g : T ∗Rn →T ∗Rn, we have
gr (g) =
5 gz
z
6
, z ∈T ∗Rn
7
,
(1.4)
it is a Lagrangian submanifold of T ∗Rn × T ∗Rn in "R4n = (R4n, "J4n). Note that on
R4n here is a standard symplectic structure (R4n, J4n): A generating map

250
6. The Calculus of Generating Functions and Formal Energy
α : T ∗Rn × T ∗Rn −→T ∗(Rn × Rn)
maps the symplectic structure (1.2) to the standard one (1.3). In particular, α maps La-
grangian submanifolds in (R4n, "J4n) to Lagrangian submanifolds Lg in (R4n, J4n).
Suppose that α satisﬁes the transversality condition of g Chapter 5, Equation (1.2),
then
Lg =
5 dφg(ω)
ω
6
,
ω ∈T ∗R2n
7
,
(1.5)
φg is called generating function of g. We call this generating map α (linear case) or
α∗(nonlinear case) Darboux transformation, in other words, we have the following
deﬁnition.
Deﬁnition 1.1. A linear map
α =
5 Aα
Bα
Cα
Dα
6
,
(1.6)
which acts as the followings:
R4n ∋
5 z0
z1
6
−→α
5 z0
z1
6
=
5 Aαz0 + Bαz1
Cαz0 + Dαz1
6
=
5 w0
w1
6
∈R4n,
is called a Darboux transformation, if
α′J4nα = "J4n.
(1.7)
Denote
Eα = Cα + Dα,
Fα = Aα + Bα,
(1.8)
then, we have:
Deﬁnition 1.2. Let α be a Darboux tramsformation. Then we deﬁne
Sp( "J4n, J4n) =
(
α ∈GL(4n) | α′J4nα = "J4n
)
= Sp( "J, J),
Sp(J4n) =
(
β ∈GL(4n) | β′J4nβ = J4n
)
= Sp(4n),
Sp( "J4n) =
(
γ ∈GL(4n) | γ′ "J4nγ = "J4n
)
= "Sp(4n).
(1.9)
Deﬁnition 1.3. A special case of Darboux transformation
α0 =
⎡
⎣
J2n
−J2n
1
2I2n
1
2I2n
⎤
⎦
is called Poincar´e transformation.

6.2 Normalization of Darboux Transformation
251
Remark 1.4. From the deﬁnition above, we know α0 ∈Sp( "J4n, J4n).
Proposition 1.5. If α ∈Sp( "J4n, J4n), β ∈Sp(4n), γ ∈"Sp(4n), then βαγ ∈
Sp( "J4n, J4n).
Proposition 1.6. ∀α ∈Sp( "J4n, J4n), we have
Sp( "J4n, J4n) = Sp(4n)α0 = α0 "Sp(4n),
Sp( "J4n, J4n) = Sp(4n)α = α"Sp(4n).
Proposition 1.7. Let α =
 Aα
Bα
Cα
Dα
!
∈Sp( "J4n, J4n), then:
α−1 =
5 −J2nC′
α
J2nA′
α
J2nD′
α
−J2nB′
α
6
=
5 Aα−1
Bα−1
Cα−1
Dα−1
6
.
Hint: Using the ﬁrst equation of (1.2) in Deﬁnition 1.2.
Theorem 1.8. If α ∈Sp( "J4n, J4n) satisﬁes transversality condition |Cα + Dα| ̸= 0,
then for all symplectic diffeomorphism z →g(z), g ∼I2n(near identity), gz ∈
Sp(2n), there exists a generating function:
φα,g : R2n −→R,
such that
Aαg(z) + Bαz = ∇φα,g(Cαg(z) + Dαz),
i.e.,
(Aαg + Bα)(Cαg + Dα)−1z = ∇φα,g(z).
6.2 Normalization of Darboux Transformation
Denote M ≡Sp( ˜J4n, J4n) a submanifold in GL(4n), dimM = 1
24n(4n + 1) =
8n2+2n. Denote M ∗≡{α ∈M | |Eα| ̸= 0} an open submanifold of M, dimM ∗=
dimM. Denote M ′ ≡{α ∈M | Eα = In, Fα = 0} ⊂M ∗⊂M.
Deﬁnition 2.1. A Darboux transformation is called a normalized Darboux transform-
ation[Fen98a], if
Eα = I2n,
Fα = O2n.
The following theorem answers the question on how to normalize a given Darboux
transformation.

252
6. The Calculus of Generating Functions and Formal Energy
Theorem 2.2. ∀α ∈M ∗, there exists
β1 =
5 I2n
P
O
I2n
6
∈Sp(4n),
β2 =
⎡
⎣(T −1)
T
O
O
T
⎤
⎦∈Sp(4n),
|T| ̸= 0,
such that β2β1α ∈M ′.
Proof. We need only to take P = −FαE−1
α
= −(Aα+Bα)(Cα+Dα)−1, T = E−1
α ,
then
β2β1α =
5 ET
α
O
O
E−1
α
6 5 I
−FαE−1
α
O
I
6 5 Aα
Bα
Cα
Dα
6
=
 Aβ2β1α
Bβ2β1α
Cβ2β1α
Dβ2β1α
!
= α1 =
5 E′
α(Aα −FαE−1
α Cα)
E′
α(Bα −FαE−1
α Dα)
E−1
α Cα
E−1
α Dα
6
. (2.1)
It’s easy to verify that
Aβ2β1α + Bβ2β1α = O2n,
Cβ2β1α + Dβ2β1α = I2n.
The theorem is proved.
▲
From now on we will assume α is a normalized Darboux transformation unless it
is speciﬁed otherwise.
Theorem 2.3. A Darboux transformation can be written in the standard form as
α =
⎡
⎣
J2n
−J2n
1
2(I + V )
1
2(I −V )
⎤
⎦,
V ∈sp(2n).
Proof. It’s not difﬁcult to show:
∀α1 ∈M =⇒∃β ∈Sp(4n),
β =
5 Aβ
Bβ
Cβ
Dβ
6
,
such that α1 = β, where α0 is a Poincar´e transformation. After computation, we get
α1 =
⎡
⎢⎣
AβJ2n + 1
2Bβ
−AβJ2n + 1
2Bβ
CβJ2n + 1
2Dβ
−CβJ2n + 1
2Dβ
⎤
⎥⎦.

6.2 Normalization of Darboux Transformation
253
Because α1 ∈M ′, we have Dβ = I2n, Bβ = O, i.e., β =
 
Aβ
O
Cβ
I2n
!
. Since
β ∈Sp(4n), we have β =
 
I2n
O
Q
I2n
!
, Q ∈Sm(2n). Thus:
α1
=
5 I2n
O
Q
I2n
6 ⎡
⎣
J2n
−J2n
1
2I2n
1
2I2n
⎤
⎦
=
⎡
⎣
J2n
−J2n
1
2I2n + QJ2n
1
2I2n −QJ2n
⎤
⎦
=
⎡
⎣
J2n
−J2n
1
2(I2n + V )
1
2(I2n −V )
⎤
⎦,
where Q′ = Q, V = 2QJ. We shall write
αV =
⎡
⎣
J2n
−J2n
1
2(I2n + V )
1
2(I2n −V )
⎤
⎦,
α−1
V
=
⎡
⎢⎣
−1
2(I2n −V )
I2n
1
2(I2n + V )
I2n
⎤
⎥⎦.
Therefore, the theorem is completed.
▲
Corollary 2.4. Every α =
 Aβ
Bβ
Cβ
Dβ
!
∈M ∗has a normalized Darboux form
αV ∈M ′,
V = (Cα + Dα)−1(Cα −Dα) ∈sp(2n).
This result can be derived from (2.1).
From the following theorem, we can show that the normalization condition is nat-
ural.
Theorem 2.5. Let Gτ be a consistent difference scheme for equation ˙z = J−1Hz,
i.e.,
1◦
Gτ(z)|τ=0 = z, ∀z, H.
2◦
∂Gτ(z)
∂τ

τ=0 = J−1Mz, ∀z, H.
iff the generating Darboux transformation is normalized with A = −J.
Proof. We take symplectic difference scheme of ﬁrst order via generating function of
type α =
 
A
B
C
D
!
, we have
AGτ(z) + Bz = −τHz(CGτ(z) + Dz).
(2.2)

254
6. The Calculus of Generating Functions and Formal Energy
We ﬁrst prove the “ only if ” part of the theorem. When taking τ = 0, we have
AG0(z) + Bz = (A + B)z = 0,
∀z =⇒A + B = O.
Differentiating (2.2) yields
A∂Gτ(z)
∂τ

τ=0 = −Hz((C + D)z).
Since
∂Gτ(z)
∂τ

τ=0 = J−1Hz(z),
we have
AJ−1Hz(z) = −Hz((C + D)z),
∀H, z.
Take special form H(z) = zTb, and substitute it into above equation, we have
AJ−1b = −b,
∀b,
which results in A = −J.
On the other hand, since Hz(z) = Hz((C + D)z), ∀H, z take special form
H = 1
2zTz, and substitute it into the above equation, we get
z = (C + D)z,
∀z =⇒C + D = I.
Now we prove the “ if ” part. Take
A + B = O,
A = −J,
C + D = I,
(2.3)
then
A(Gτ(z) −z) = −τHz(CGτ(z) + Dz),
A = −J,
τ = 0 =⇒Gτ(z)

τ=0 = z.
On the other hand, we have
A
%∂Gτ(z)
∂τ
&
τ=0
= −Hz((C+D)z) =⇒
%∂Gτ(z)
∂τ
&
τ=0
= J−1Hz(z),
∀z, H.
Therefore, the theorem is completed.
▲
Theorem 2.6. A normalized Darboux transformation with A = −J can be written in
the standard form
α =
⎡
⎣
−J
J
1
2(I −V )
1
2(I + V )
⎤
⎦,
∀V ∈sp(2n).

6.3 Transform Properties of Generator Maps and Generating Functions
255
6.3 Transform Properties of Generator Maps and
Generating Functions
Let
α =
5 Aα
Bα
Cα
Dα
6
∈Sp( "J4n, J4n),
denote Eα = Cα + Dα, Fα = Aα + Bα. Let g ∈Sp-diff. From now on, we always
assume that transversality condition is satisﬁed, i.e., |Eα| ̸= 0.
Theorem 3.1. ∀T ∈GL(2n), let βT =
 (T −1)T
O
O
T
!
∈Sp(4n), βT α ∈
Sp( "J4n, J4n), we have:
φβT α,g ∼= φα,g ◦T −1.
(3.1)
Proof. Since
βT α =
⎡
⎣(T −1)
TAα
(T −1)
TBα
TCα
TDα
⎤
⎦=
5 AβT α
BβT α
CβT α
DβT α
6
,
we have
Aαg(z) + Bαz = ∇φα,g ◦(Cαg(z) + Dαz),
(3.2)
and
(T −1)
TAαg(z) + (T −1)
TBαz = ∇φβT α,g ◦(TCαg(z) + TDαz)
⇐⇒Aαg(z) + Bαz = T ′(∇φβT α,g) ◦T(Cαg(z) + Dαz)
= ∇(φβT α,g ◦T)(Cαg(z) + Dαz).
(3.3)
Comparing (3.2) with (3.3) for all z, we ﬁnd:
∇φα,g(Cαg(z) + Dαz) = ∇(φβT α,g ◦T)(Cαg(z) + Dαz).
Thus we obtain
φα,g ∼= φβT α,g ◦T
or
φα,g ◦T −1 ∼= φβT α,g
The theorem is proved.
▲
Theorem 3.2. ∀S ∈Sp(2n), deﬁne γS =
 S
O
O
S
!
∈"Sp(4n). Then we have
φαγS,g ∼= φα,S◦g◦S−1
(3.4)

256
6. The Calculus of Generating Functions and Formal Energy
Proof. Since:
αγS =
5 AαS
BαS
CαS
DαS
6
=
5 AαγS
BαγS
CαγS
DαγS
6
,
we have
AαS ◦g ◦S−1z + Bαz = ∇φα,S◦g◦S−1(CαS ◦g ◦S−1z + Dαz).
Since S is nonsingular, replacing z with S(z) results in
AαS ◦g(z) + BαSz = ∇φα,S◦g◦S−1(CαS ◦g(z) + DαSz),
∀z.
(3.5)
On the other hand,
(AαS)g(z) + (BαS)z = ∇φαγS,g[(CαS)g(z) + DαSz],
∀z.
(3.6)
Compare (3.5) with (3.6) and note that
|Cα + Dα| ̸= 0 ⇐⇒|CαS + DαS| ̸= 0 ⇐⇒|CαSgz(z) + DαS| ̸= 0.
Finally, we obtain:
∇φαγS,g = ∇φα,S◦g◦S−1,
i.e.,
φαγS,g ∼= φα,S◦g◦S−1.
The proof can be obtained.
▲
Theorem 3.3. Take β =
 I2n
P
O
I2n
!
∈Sp(4n), P ∈Sm(2n), α ∈Sp( "J4n, J4n),
then:
φβα,g ∼= φα,g + ψp,
(3.7)
where ψp = 1
2w′Pw ( function independent of g).
Proof. Since:
βα =
5 I2n
P
O
I2n
6 5 Aα
Bα
Cα
Dα
6
=
5 Aα + PCα
Bα + PDα
Cα
Dα
6
,
Eβα = Eα,
Fβα = Fα + PEα,
obviously,
Aβαg(z) + Bβαz = ∇φβα,g(Cβαg(z) + Dβαz),
(3.8)
Aαg(z) + Bαz + (PCαg(z) + PDαz) = ∇φβα,g(Cαg(z) + Dαz). (3.9)
On the other hand,

6.3 Transform Properties of Generator Maps and Generating Functions
257
∇ψP (Cαg(z) + Dαz) = P(Cαg(z) + Dαz).
(3.10)
Inserting (3.10) into (3.9), we obtain
Aαg(z) + Bαz = ∇φβα,g(Cαg(z) + Dαz) −∇ψP (Cαg(z) + Dαz)
= ∇(φβα,g −ψP )(Cαg(z) + Dαz).
(3.11)
Compare (3.11) with
Aαg(z) + Bαz = ∇φα,g(Cαg(z) + Dαz),
we obtain
φβα,g −ψP ∼= φα,g.
Analogically, we have:
▲
Theorem 3.4. If we take β =
 I2n
O
Q
I2n
!
∈Sp(4n), Q ∈Sm(2n), then
φα,g + 1
2(∇wφα,g(w))′Q(∇wφα,g(w)) ∼= φβα,g(w + Q∇φα,g(w)).
(3.12)
Theorem 3.5. We have the following relation:
φ⎡
⎣A
B
C
D
⎤
⎦,g−1
∼= −φ⎡
⎣−B
−A
D
C
⎤
⎦,g
.
(3.13)
Proof. Since
Aαg−1(z) + Bαz = ∇φα,g−1(Cαg−1(z) + Dαz),
replacing z with g(z) yields
Aαz + Bαg(z) = ∇φα,g−1(Cαz + Dαg(z)).
(3.14)
Comparing (3.14) with
−Bαg(z) −Aαz = ∇φ5 −B
−A
D
C
6
,g
(Dαg(z) + Cαz),
the proof is complete.
▲
Theorem 3.6. If
φ⎡
⎣A
B
C
D
⎤
⎦,g−1
∼= −φ⎡
⎣A
B
C
D
⎤
⎦,g−1
,
∀g,
then
A + B = O,
C = D.

258
6. The Calculus of Generating Functions and Formal Energy
Proof. By Theorem 3.5 and the uniqueness of Darboux transformation in Theorem
4.2, we have
5 A
B
C
D
6
= ±
5 −B
−A
D
C
6
.
We only consider the case “+”, where we have A + B = O, C = D.
▲
Remark 3.7. For Poincar´e map α0 =
5
J
−J
1
2I
1
2I
6
, we have:
φα0,g−1 ∼= −φα0,g,
∀g ∈Sp-diff.
Theorem 3.8. Let gt
H be the phase ﬂow of Hamiltonian system H(z). Then under
Poincar´e map α0 the generating function for gt
H is an odd function w.r.t t, i.e.,
φα0,gt
H(w, t) = −φα0,gt
H(w, −t),
∀w ∈R2n,
t ∈R.
Proof. By the properties of generating function for gt
H, we have
g−t
H = (gt
H)−1,
φα0,g−t
H (w, t) = φα0,gt
H(w, −t) = φα0,(gt
H)−1(w, t) = −φα0,gt
H(w, t).
The theorem is proved.
▲
Theorem 3.9. If S ∈Sp(2n), α ∈Sp( "J4n, J4n), γ1 =
 S
O
O
I
!
, then
αγ1 =
 AαS
Bα
CαS
Dα
!
.
Assume |Eαγ1| = |CαS + Dα| ̸= 0, we have
φα,S◦g ∼= φαγ1,g,
(3.15)
i.e.,
φ5 A
B
C
D
6
,S◦g
∼= φ5 AS
B
CS
D
6
,g
.
Theorem 3.10. If
γ2 =
5 I
O
O
S
6
,
α ∈Sp( "J4n, J4n),
αγ2 =
5 Aα
BαS
Cα
DαS
6
,
assume |Bα + DαS| ̸= 0, we have
φα,g◦S−1 ∼= φαγ2,g,
(3.16)
i.e.,
φ5 A
B
C
D
6
,g◦S−1
∼= φ5 A
BS
C
DS
6
,g
.

6.3 Transform Properties of Generator Maps and Generating Functions
259
Proof. Since
Ag(S−1z) + Bz = ∇φα,g◦S−1
Cg(S−1z) + Dz

,
∀z,
replacing z with Sz yields
Ag(z) + BSz
= ∇φα,g◦S−1(Cg(z) + DSz)
= ∇φ⎡
⎣A
BS
C
DS
⎤
⎦,g
(Cg(z) + DSz),
φ⎡
⎣A
BS
C
DS
⎤
⎦,g
∼= φ⎡
⎣A
B
C
D
⎤
⎦,g◦S−1
.
Therefore, the theorem is completed.
▲
The proof of Theorem 3.9 is similar.
Theorem 3.11. If
β =
 λI2n
O
O
I2n
!
∈CSp(4n),
α ∈Sp( "J4n, J4n),
λ ̸= 0,
β α =
 λA
λB
C
D
!
∈CSp( "J4n, J4n),
μ(βα) = λ,
then we have
φ⎡
⎣λA
λB
C
D
⎤
⎦,g
∼= λφ⎡
⎣A
B
C
D
⎤
⎦,g
.
(3.17)
Proof. Since
α ∈Sp( "J4n, J4n) =⇒Ag(z) + Bz = ∇φ⎡
⎣A
B
C
D
⎤
⎦,g
(Cg(z) + Dz),
β ∈CSp( "J4n, J4n) =⇒λAg(z) + λBz = ∇φ⎡
⎣λA
λB
C
D
⎤
⎦,g
(Cg(z) + Dz),
L.H.S = λAg(z) + λBz = λ∇φ⎡
⎣A
B
C
D
⎤
⎦,g
(Cg(z) + Dz),
R.H.S = ∇φ⎡
⎣λA
λB
C
D
⎤
⎦,g
(Cg(z) + Dz),
then we have

260
6. The Calculus of Generating Functions and Formal Energy
∇φ⎡
⎣λA
λB
C
D
⎤
⎦,g
(Cg(z) + Dz) = λ∇φ⎡
⎣A
B
C
D
⎤
⎦,g
(Cg(z) + Dz),
φ⎡
⎣λA
λB
C
D
⎤
⎦,g
∼= λφ⎡
⎣A
B
C
D
⎤
⎦,g
.
The theorem is proved.
▲
Theorem 3.12. Let
β =
5 I2n
O
O
λI2n
6
∈CSp(J4n),
λ ̸= 0,
α ∈Sp( "J4n, J4n),
βα =
5
A
B
λC
λD
6
∈CSp( "J4n, J4n),
μ(βα) = λ,
then we have:
φ⎡
⎣
A
B
λC
λD
⎤
⎦,g
∼= λφ⎡
⎣A
B
C
D
⎤
⎦,g
◦λ−1I2n.
(3.18)
Proof. Since
 
A
B
λC
λD
!
∈CSp( "J4n, J4n),
Ag(z) + Bz = ∇φ⎡
⎣
A
B
λC
λD
⎤
⎦,g
(λCg(z) + λDz),
L.H.S = ∇φ⎡
⎣A
B
C
D
⎤
⎦,g
(Cg(z) + Dz),
R.H.S =
⎛
⎜
⎜
⎝φ⎡
⎣
A
B
λC
λD
⎤
⎦,g
⎞
⎟
⎟
⎠◦λI2n(Cg(z) + Dz)
= λ−1∇
⎛
⎜
⎜
⎝φ⎡
⎣
A
B
λC
λD
⎤
⎦,g
◦λI2n
⎞
⎟
⎟
⎠(Cg(z) + Dz),
hence
φ⎡
⎣A
B
C
D
⎤
⎦,g
∼= λ−1φ⎡
⎣
A
B
λC
λD
⎤
⎦,g
◦λI2n.
Therefore, the theorem is completed.
▲

6.4 Invariance of Generating Functions and Commutativity of Generator Maps
261
Before ﬁnishing this section, we will give two conclusive theorems which can
include the contents of the seven theorems given before. They are easy to prove and
the proofs are omitted here.
Let
α ∈CSp( "J4n, J4n),
β ∈CSp(J4n),
β =
 
a
b
c
d
!
,
obviously
β α ∈CSp( "J4n, J4n),
μ(βα) = λ(β)μ(α),
and then the following theorem.
Theorem 3.13. For φβα,g, we have
φβα,g(c∇wφα,g(w) + dw)
(3.19)
∼= λ(β)φα,g(w) +
'1
2w′(d′b)w + (∇wφα,g(w))′
·(c′b)w 1
2(∇wφα,g(wλ))′(c′a)(∇wφα,g(w))
/
.
(3.20)
We now formulate the other one. Let α ∈CSp( "J4n, J4n), γ ∈CSp( "J4n) ⇔
γ′ "J4nγ = ν(γ) "J4n ⇒αγ ∈CSp( "J4n, J4n), μ(αγ) = μ(α)ν(γ), γ =
 a
b
c
d
!
.
We have the following theorem.
Theorem 3.14. For φαγ,g, we have
φαγ,g ∼= φα,(ag+b)(cg+d)−1.
(3.21)
6.4 Invariance of Generating Functions and
Commutativity of Generator Maps
First we present the uniqueness theorem of the linear fractional transformation.
Theorem 4.1. Let
α =
5 Aα
Bα
Cα
Dα
6
,
α =
5 Aα
Bα
Cα
Dα
6
∈Sp( "J4n, J4n),
|Eα| ̸= 0,
|Eα| ̸= 0.
If
(AαM + Bα)(CαM + Dα)−1 = (AαM + Bα)(CαM + Dα)−1,
∀M ∼I2n,
M ∈Sp(2n),
then
α = ±α.

262
6. The Calculus of Generating Functions and Formal Energy
Proof. Let
N0 = (AαI + Bα)(CαI + Dα)−1
= (AαI + Bα)(CαI + Dα)−1.
Suppose β ∈Sp(4n), ﬁrst we prove that if
(AβN + Bβ)(CβN + Dβ)−1 = N,
∀N ∽N0,
N ∈Sm(2n),
then β = ±I4n. Now we have two cases:
1◦
(AβN0 + Bβ)(CβN0 + Dβ)−1 = N0 ⇒AβN0 + Bβ = N0CβN0 + N0Dβ.
2◦
Take N = N0 + εI ⇒Aβ(N0 + εI) + Bβ = (N0 + εI)Cβ(N0 + εI) +
(N0 + εI)Dβ.
From 1◦, 2◦⇒εAβ = εN0Cβ + εCβN0 + εDβ + ε2Cβ, ∀ε, which results in
Aβ −Dβ −N0Cβ −CβN0 = εCβ = 0 =⇒Cβ = 0,
thus Aβ = Dβ.
From 1◦, we have B =
 Aβ
Bβ
O
Aβ
!
, Bβ = B′
β. Therefore
AβNA−1
β
= N −BβA−1
β .
Subtracting this formula by AβN0A−1
β
= N0 −BβA−1
β
yields
Aβ(N −N0) = (N −N0)Aβ.
Take N −N0 = εS, ∀S ∈Sm(2n) ⇒AβS = SAβ, ∀S ∈Sm(2n) ⇒Aβ = λI2n
(This can be proved by mathematical induction).
Then from 1◦, AβN0 + Bβ = N0Aβ ⇒Bβ = 0, and
β =
 Aβ
O
O
Aβ
!
= λI4n ∈Sp(4n) =⇒λ = ±1.
Let β = αα−1, then the fractional transformation of β preserves all symmetric N ∼
N0. Because α ∈Sp( "J, J), α−1 ∈Sp(J, "J), we have αα−1 ∈Sp(J, J) = Sp(4n).
The theorem is proved.
▲
We now present the uniqueness theorem for Darboux transformations.
Theorem 4.2. Suppose α, α ∈Sp( "J, J), then
φα,g ∼= φα,g,
∀g ∈Sp-diff,
g ∼I2n =⇒α = ±α.
Proof. From the hypothesis, we have
φα,g ∼= φα,g =⇒Hessian(φα,g) = (φα,g)ww
= (Aαg(z) + Bα)(Cαg(z) + Dα)−1,

6.4 Invariance of Generating Functions and Commutativity of Generator Maps
263
(φα,g)ww = (Aαg(z) + Bα)(Cαg(z) + Dα)−1,
∀g(z) ∈Sp(2n) ∼I.
Then by uniqueness theorem of the linear fractional transformation α = ±α. From
the above proof, we get
Hessian (φα,g) = Hessian (φ−α,g),
∀g ∈I, α.
The generating function φα,g depends on Darboux transformation α, symplectic dif-
feomorphism g and coordinates. If we make a symplectic coordinate transformation
w →S(z), then φ(S) ⇒φ(S(z)), while the symplectic diffeomorphism g is repre-
sented in z coordinates as S−1 ◦g ◦S, i.e.,
φα,S−1◦g◦S = φα,g ◦S
For the invariance of generating function φg(S) under S, one would like to expect
φα,S−1◦g◦S = φα,g ◦S,
∀g ∼I.
This is not true in general case. We shall study under what condition this is true for the
normalized Darboux transformation αV . The following theorem answers this ques-
tion.
▲
Theorem 4.3. Let
α = αV =
⎡
⎣
J2n
−J2n
1
2(I + V )
1
2(I −V )
⎤
⎦,
∀V ∈sp(2n),
αV ∈M ′,
S ∈Sp(2n),
βS =
5 (S−1)T
O
O
S
6
∈Sp(J4n),
γS =
5 S
O
O
S
6
∈Sp( "J4n).
Then the following conditions are equivalent:
1◦
φαV ,S◦g◦S−1 = φα,g ◦S−1, ∀g ∽I.
2◦
φαV γS,g = φβSαV ,g, ∀g ∽I.
3◦
αV γS = βSαV .
4◦
SV = V S.
Proof. 1◦⇔2◦from Theorems 3.1 and Theorem 3.2. 2◦⇒3◦using the uniqueness
theorem on Darboux transformation 4.2. For
αV γS = ±βSαV ,
since JS = S′−1J, sign “−” case is excluded. The rest of the proof is trivial.
There is a deep connection between the symmetry of a symplectic difference
scheme and the conservation of ﬁrst integrals.
Let F be the set of smooth functions deﬁned on Rn.
▲

264
6. The Calculus of Generating Functions and Formal Energy
Theorem 4.4. If Hamiltonian function H is invariant under phase ﬂow gF with
Hamiltonian function F, then F is ﬁrst integral of the system with Hamiltonian func-
tion H.
Let H, F ∈F, then
F ◦gt
H = F ⇐⇒{F, H} = 0 ⇐⇒H ◦gt
F = H ⇐⇒gt
H
= g−S
F
◦gt
H ◦gS
F .
Theorem 4.5. Let F be a conservation law of Hamiltonian system, then phase ﬂow
gt
H (or symplectic schemes φτ
H) keeps phase ﬂow gt
F with F (or φτ
F ) invariant iff
F ◦gH = F + C. Let F ∈F, g ∈Sp-diff, then
g = g−t
F ◦g ◦gt
F (or gt
F = g−1gt
F (g(z)) ⇐⇒F ◦g = F + c.
Proof. The “ if ” part of the proof is obvious. Since
F ◦g = F + c =⇒∇F = ∇F ◦g =⇒gt
F = gt
F ◦g
= g−1 ◦gt
F ◦g
= g−1gt
F (g(z)) ⇐⇒g = g−t
F ◦g ◦gt
F .
On the other hand, take the derivative of both sides of the following equation w.r.t. t
at t = 0,
gt
F (z) = g−1gt
F (g(z)),
and notice that g∗(z) ∈Sp, g−1
∗J−1 = J−1gT
∗, we get
J−1∇F(z) = g−1
∗(z)J−1∇F(g(z)) = J−1gT
∗(z)∇F(g(z)),
then we have
∇F = ∇F ◦g =⇒F ◦g = F + c.
Therefore, the theorem is completed.
▲
6.5 Formal Energy for Hamiltonian Algorithm
Let F s be an analytic canonical transformation for s, i.e.,
1◦
F s ∈Sp-diff.
2◦
F 0 = id.
3◦
F s analytic if |s| is small enough.
Then there exists a “formal” energy, i.e., a formal power series in s,
hs(z) = h(s, z) =
∞

i=1
sihi(z)

6.5 Formal Energy for Hamiltonian Algorithm
265
with the following property: if hs(z) converges, the phase ﬂow gt
hs is a canoni-
cal transformation with Hamiltonian function hs(z), which is considered as a time-
independent Hamiltonian with s as a parameter and satisﬁes “equivalence condition”
gt
hs

t=s = F s.
(5.1)
Therefore hs(z) = hs(F sz), ∀z ∈R2n, thus hs(z) is invariant under F s (for those
s, z in the domain of convergence of hs(z)).
The generating function with F s, the new Hamiltonian function and α, the Dar-
boux transformation is
φF s,α(w) : ψ(s, w) =
∞

k=1
skψ(k)(w).
(5.2)
Introduce formal power series
hs(z) = h(s, w) =
∞

k=1
sihi(w).
Assuming it converges, we associate the phase ﬂow with the generating function
hs(z) −→ψt
hs,α(w) : χ(t, s, w) =
∞

k=1
tkχ(k)(s, w),
χ(1)(s, w) = −h(s, w).
(5.3)
For k > 1,
χ(k+1)(s, w) = −
k

m=1
1
(k + 1)m!
2n

l1,···,lm=1

k1+···+km=k
hwl1,···,wlm (s, w)
·(A1χ(k1)
w
(s, w))l1 · · · (A1χ(km)
w
(s, w))lm
=
k

m=1
1
(k + 1)m!

k1+···+km=k
χ(1)
wl1,···,wlm (s, w)
·(A1χ(k1)
w
(s, w))l1 · · · (A1χ(km)
w
(s, w))lm.
(5.4)
Let χ(k)(s, w) =
∞

i=0
siχ(k,i)(w), then χ(t, s, w) =
∞

k>1
∞

i=0
tksiχ(k,i)(w). Then
∞

i=0
siχ(k+1,i)(w) =
∞

i=0
si
k

m=1
1
(k + 1)m!

i0 + i1 + · · · + im = i
k1 + · · · + km = k
·
2n

l1,···,lm=1
χ(1,i0)
wl1,···,wlm(w)(A1χ(k1,i1)
w
(w))l1 · · ·
·(A1χ(km,im)
w
(w))lm.
(5.5)

266
6. The Calculus of Generating Functions and Formal Energy
Thus
χ(k+1,i)(w) =
k

m=1
1
(k + 1)m!

i0+i1+···+im=i
k1+···+km=k
2n

l1,···,lm=1
χ(1,i0)
wl1,···,wlm (w)
·(A1χ(k1,i1)
w
(w))l1 · · · (A1χ(km,im)
w
(w))lm.
(5.6)
Let
χ(1)(s, w) =
∞

i=0
siχ(1,i)(w) = −h(s, w) = −
∞

i=0
sihi(w),
so the coefﬁcient χ(k+1,i) can be obtained by recursion,
χ(1,i) = −h(i),
i = 0, 1, 2, · · · .
(5.7)
Note that χ(k+1,i) is determined only by the values of χ(k′,i′)(k′ ≤k, i′ ≤i),
χ(1,0)
χ(1,1)
χ(1,2)
· · ·
χ(1,i)
χ(1,i+1)
...
...
...
...
...
χ(k,0)
χ(k,1)
χ(k,2)
· · ·
χ(k,i)
χ(k,i+1)
χ(k+1,0)
χ(k+1,1)
χ(k+1,2)
· · ·
χ(k+1,i)
χ(k+1,i+1)
(5.8)
The condition (5.1) can be now reexpressed as
χ(t, s, w)|t=s = χ(s, s, w) = ψ(s, w),
i.e.,
∞

k>1
sk
∞

i=0
siχ(k,i)(w) =
∞

k>1
skψ(k)(w),
∞

i=0
si 
j=0
χ(k−j,j)(w) =
∞

i=1
siψ(k)(w),
k−1

j=0
χ(k−j,j)(w) = ψ(k),
k = 2, 3, · · · ,
χ(1,0) = ψ(1),
k

i=0
χ(k+1−i,i) = ψ(k+1),
k = 2, 3, · · · .
(5.9)
So

6.5 Formal Energy for Hamiltonian Algorithm
267
−h(0)
−h(1)
−h(2)
· · ·
−h(k−1)
−h(k)
ψ(1)
χ(1,0)
χ(1,1)
χ(1,2)
· · ·
χ(1,k−1)
χ(1,k)
ψ(2)
χ(2,0)
χ(2,1)
χ(2,2)
· · ·
χ(2,k−1)
...
...
...
ψ(k)
χ(k,0)
χ(k,1)
ψ(k+1)
χ(k+1,0)
(5.10)
and
χ(1,0) = ψ(1),
χ(2,0) + χ(1,1) = ψ(2),
χ(3,0) + χ(2,1) + χ(1,2) = ψ(3),
...
χ(k+1,0) + χ(k,1) + · · · + χ(2,k−1) + χ(1,k) = ψ(k+1).
(5.11)
Now if ψ(1), ψ(2), · · · , ψ(k), ψ(k+1), · · · are known, then
h(0) = −χ(1,0), h(1) = −χ(1,1), · · · , h(k−1) = −χ(1,k−1), h(k) = −χ(1,k), · · ·
can be determined. We get:
h(0) = −ψ(1),
h(1) = −ψ(2) + χ(2,0),
h(2) = −ψ(3) + (χ(3,0) + χ(2,1)),
...
h(k) = −ψ(k+1) + (χ(k+1,0) + χ(k,1) + · · · + χ(2,k−1)),
...
(5.12)
So h(0), h(1), h(2), · · · can be recursively determined by ψ(1), ψ(2), · · ·. So we get the
formal power series hs =
∞

i=0
sih(i)(z), and in case of convergence, it satisﬁes
gt
hs

t=s = F s.
We now give a special example to show how to calculate the formal energy. Let us
consider normal Darboux transformation with

268
6. The Calculus of Generating Functions and Formal Energy
V = −E =
5 O
−I
−I
O
6
,
α−1
V
=
5 A1
B1
C1
D1
6
,
where
A1 = 1
2(JV J −J) =
5 O
O
−I
O
6
.
Suppose we just use the ﬁrst term of the generating function of the generating map
αV , i.e., we just consider the ﬁrst order scheme
F s ∼ψ(s, w) = −sH(w) =
∞

i=1
skψ(k).
Let us assume ψ(1) = −H(w). If ψ(2) = ψ(3) = · · · = 0, then χ(1,0) = ψ(1) = −H.
We need to calculate χ(2,0). Since
χ(1,0)
z
= −
5 Hp
Hq
6
,
A1χ(1,0)
z
=
5 O
O
−I
O
6 5 −Hp
−Hq
6
=
5 O
Hp
6
,
χ(1,0)
zz
= −
5 Hpp
Hpq
Hqp
Hqq
6
.
By formula (5.6), we get
χ(2,0) =
1
2 × 1!
2n

i0+i1=0
2n

k1=1
2n

l1=1
χ(1,i0)
zl1
(A1χ(k1,i1)
z
)l1
= 1
2(χ(1,0)
z
)′A1χ(1,0)
z
= −1
2
5 Hp
Hq
6′ 5
0
Hp
6
= −1
2H′
qHp.
From formula (5.10), we get
χ(2,0) + χ(1,1) = ψ(2) = 0 =⇒χ(1,1) = −χ(2,0) = 1
2H′
qHp.
In order to obtain χ(1,2), we ﬁrst determine χ(3,0) and χ(2,1), and for the latter we
need to caculate

6.5 Formal Energy for Hamiltonian Algorithm
269
χ(1,1)
z
= 1
2
⎡
⎢⎢⎢⎢⎢⎣
∂
∂p
n

j=1
HqjHpj
∂
∂q
n

j=1
HqjHpj
⎤
⎥⎥⎥⎥⎥⎦
= 1
2
5 HpqHp + HppHq
HqqHp + HqpHq
6
,
A1χ(1,1)
z
=
5 O
O
−I
O
6
χ(1,1)
z
= −1
2
5
O
HpqHp + HppHq
6
,
A1χ(2,0)
z
= −A1χ(1,1)
z
= 1
2
5
O
HpqHp + HppHq
6
.
For k = 2, i = 0, we have
χ(3,0) =
1
3
 1
1!
2n

i0+i1=0
2n

k1=2
2n

l1=1
χ(1,0)
zl1 (A1χ(k1,0)
z
)l1
+
2n

l1,l2=1

i0+i1+i2=0

k1+k2=2
χ(1,0)
zl1,zl2 (A1χ(k1,0)
z
)l1(A1χ(k2,0)
z
)l2

=
1
3

χ(2,0)
z
TA1χ(2,0)
z
+ 1
6

A1χ(1,0)
z
Tχ(1,0)
zz
A1χ(1,0)
z
= −1
6(HT
q HpqHp + HT
q HppHq + HT
pHqqHp).
For k = 1, i = 1, we have
χ(2,1) =
1
2
2n

i0+i1=1
2n

k1=1
2n

l1=1
χ(1,i0)
zl1
(A1χ(k1,i1)
z
)l1
=
1
2

χ(1,0)
z
TA1χ(1,1)
z
+

χ(1,1)
z
TA1χ(1,0)
z

=
1
4(HT
q HppHq + HT
pHqqHp) + 1
2HT
q HpqHp.

270
6. The Calculus of Generating Functions and Formal Energy
From (5.11), we have
χ(3,0) + χ(2,1) + χ(1,2) = ψ(3) = 0 =⇒χ(1,2) = −(χ(3,0) + χ(2,1)).
For k = 1, i = 2,
χ(1,2) = −

−1
6(HT
q HppHq + HT
pHqqHp) −1
6HT
q HpqHp
+1
4(HT
q HppHq + HT
pHqqHp) + 1
2HT
q HpqHp

= −1
12(HT
q HppHq + HT
pHqqHp + 4HT
q HpqHp).
Finally, we get the formal power series of energy
h(s, z) = −(χ(1,0) + sχ(1,1) + s2χ(1,2)) + O (s3)
= H(z) −s
2H′
qHp + s2
12(H′
qHppHq + H′
pHqqHp + 4H′
qHpqHq) + O (s3).
Now, let H(z) be a time-independent Hamiltonian, let its phase ﬂow be gt
H, and
let its generating function be
φgt
H(w) = φ(t, w) =
∞

k=1
tkφ(k)(w).
Then we have
φ(1)(w) = −H(w),
for k ≥1,
φ(k+1)(w) =
k

m=1
1
(k + 1)m!
2n

l1,···,lm=1

k1+···+km=k
φ(1)
wl1···wlm (w)
·

A1φ(k1)
w
(w)

l1 · · ·

A1φ(km)
w
(w)

lm.
(5.13)
Theorem 5.1. [Fen98a] Let F s be a Sp-diff operator of order m for Hamiltonian H,
i.e., φ(s, w) −ψ(s, w) = O(|s|m+1), and
⎧
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎩
ψ(1)(w) = φ(1)(w) = −H(w),
ψ(2)(w) = φ(2)(w),
...
ψ(m)(w) = φ(m)(w),
then

6.5 Formal Energy for Hamiltonian Algorithm
271
h(0)(w) = H(w), h(1)(w) = h(2)(w) = · · · = h(m−1)(w) = 0,
i.e.,
h(s, w) −H(w) = o (|s|m)
and
h(m)(w) = ψ(m+1)(w) −φ(m+1)(w).
Proof. First we show that χ(k+1,i) depends only on derivatives of χ(k′,i′) (k′ ≤
k, i′ ≤i). The recursion for i = 0 is the same as the recursion of phase ﬂow generat-
ing function with Hamiltonian χ(1,0)(w). For i ≥1, χ(k+1,i) = 0, if χ(k′,i′) = 0 for
all i′, k′, such that 1 ≤i′ ≤i, 1 ≤k′ ≤k. We have
ψ(1) = χ(1,0) = χ(1,0)
recursion
−−−−−→χ(2,0), χ(3,0), χ(4,0), · · ·
ψ(2) = χ(1,1) + χ(2,0) =⇒χ(1,1)
recursion
−−−−−→χ(2,1), χ(3,1), χ(4,1), · · ·
ψ(3) = χ(1,2) + χ(2,1) + χ(3,0) =⇒χ(1,2)
recursion
−−−−−→χ(2,2), χ(3,2), χ(4,2), · · ·
ψ(4) = χ(1,3) + χ(2,2) + χ(3,1) + χ(4,0) =⇒χ(1,3)
recursion
−−−−−→χ(2,3), χ(3,3), χ(4,3), · · ·
...
ψ(k) = χ(1,k−1) + χ(2,k−2) + · · · + χ(k,0) =⇒χ(1,k−1)
recursion
−−−−−→χ(2,k−1), χ(3,k−1), χ(4,k−1), · · ·
(5.14)
So, χ(k,i) can be generated successively through (5.9), (5.6). Then
h(s, w) =
∞

i=0
siχ(1,i)(w).
Using equation H = ψ(1) = φ(1) = χ(1,0) and (5.9), (5.14) ,we get
χ(2,0) = φ(2), χ(3,0) = φ(3), · · · , χ(k,0) = φ(k), · · ·
Using Equation (5.14), we get
ψ(2) = φ(2) = χ(1,1) + φ(2) =⇒χ(1,1) = 0.
Applying Equations (5.9) and (5.14), we get

272
6. The Calculus of Generating Functions and Formal Energy
χ(2,1) = 0 =⇒χ(3,1) = χ(4,1) = · · · = χ(k,1) = · · · = 0.
Applying equation
ψ(3) = φ(3) = χ(1,2) + χ(2,1) + χ(3,0) = χ(1,2) + 0 + φ(3) =⇒χ(1,2) = 0,
then
χ(2,2) = χ(3,2) = χ(4,2) = · · · = χ(k,2) = · · · = 0.
Finally
ψ(m) = φ(m) = χ(1,m−1) + χ(2,m−2) + · · · + χ(m−1,1) + φ(m) =⇒χ(1,m−1) = 0,
then
χ(2,m−1) = χ(3,m−1) = χ(4,m−1) = · · · = χ(k,m−1) = · · · = 0.
Since χ(k,i) = 0, ∀i = 1, 2, · · · , m −1 and k = 1, 2, 3 · · ·, then the equation
ψ(m+1) = χ(1,m) + χ(2,m−1) + · · · + χ(m,1) + χ(m+1,0)
=⇒χ(1,m) = ψ(m+1) −φ(m+1),
so we ﬁnally get
h(s, z) =
∞

i=0
siχ(1,i) = H(z) + sm(ψ(m+1) −φ(m+1)) + O (|s|m+1),
i.e.,
h(s, z) −H(z) = sm(ψ(m+1)(z) −φ(m+1)(z)) + O(|s|m+1).
So in particular, if F s ∼ψ(s, w) is given by the truncation of phase ﬂow generating
function, i.e.,
ψ(1) = φ(1) = H,
ψ(2) = φ(2), · · · , ψ(m) = φ(m),
ψ(m+1) = φ(m+1) = 0,
then
h(s, z) = H(z) −O(|s|m+1).
Therefore, the theorem is completed.
▲

6.6 Ge–Marsden Theorem
273
6.6 Ge–Marsden Theorem
In this section, we describe the result of Ge–Marsden, which talks about nonexistence
of symplectic schemes that preserving energy. Due to the importance of preserving
energy for a numerical method, extensive effort has been made by many people in
searching for energy-preserving symplectic scheme, yet none of them is successful.
Ge Zhong, a former Ph.D. student of Prof. Feng, ﬁrst proved in his thesis [Ge88] the
non-existence of the energy-preserving symplectic schemes. The result was published
later in [GM88] by himself and Marsden, and now is called Ge–Marsden theorem.
Let H be such a Hamiltonian function, where in its neighborhood of some level
surface (energy surface), there exists no other conservation law exception energy. In
other words, given a function f deﬁned in a neighborhood of energy surface H = c0,
if {f, H} = 0, then f = g(H), where g is a function on R1.
A symplectic scheme can be regarded as a one-parameter family of symplectic
transformation φτ(τ ≥0). A well-posed difference scheme should satisfy the consis-
tency condition which ensures φτ depends smoothly on parameter τ.
Now suppose that we have a symplectic scheme which preserves the energy, i.e.,
H ◦φτ = H,
where φτ maps energy surface H = c to itself. We denote the mapping φτ, gτ
H
restricted on to the level surface H = c respectively as
f τ
H|H=c ,
φτ|H=c .
Theorem 6.1 (G–M theorem). [Ge88] There exists a function τ = τ(c, t)deﬁned on a
neighborhoold of 0 ∈R, such that
φτ(c,t)
H=c = gt
H=c.
This means that if we can ﬁnd a symplectic scheme preserving energy, we can solve the
original Hamiltonian system equivalently by a reparametrization of time parameter in
phase ﬂow gt
H. In general this is impossible.
The proof of above Theorem 6.1 bases on the following Lemma 6.2.
Lemma 6.2. Let gt
A1, gt
A2 be solutions of following systems of ODE respectively.
dx
dt = A1(x, t),
dx
dt = c(t)A1(x, t),
where c(t) is function of t, then
gt
A1 = gτ(t)
A2 ,
where τ(t) is the solution of following system:
dτ
d t = c(t),
τ(o) = 0.

274
6. The Calculus of Generating Functions and Formal Energy
Proof. omit.
▲
Now we give a proof of Theorem 6.1.
Proof. Let F(z, τ) be a Hamiltonian function, whose phase ﬂow is φτ. Then from
H ◦φτ = H and Theorem2.20 of Chapter 3 we get {F(·, τ), H} = 0. According to
the assumption, there exists a F1 such that:
F(z, τ) = F1

H(z), τ

,
and the vector ﬁeld generated by Hamiltonian function F(z, τ) is
J−1F ′
1(H(z), τ)Hz,
which is tangent to the energy surface H = c. Its restriction to the level surface H = c
is
J−1F ′
1(c, τ)Hz

H=c.
It differs from the restriction of vector ﬁeld J−1Hz to the level surface H = c only
by a constant F ′
1(c, τ). By Lemma 6.2 the proof is completed.
▲
All symplectic transformations that keep H invariant compose a group S(H).
S(H) is a rigidity under which S0(H) is a contained connected support set of unit
transformation of group S(H). S0(H) induces the level surface H = c by the set of
all transformation, denoted by S0(H)|H=0. Then S0(H) is a curve
S0(H) = {gt
H

H=c, t ∈R}.
Note that the rigidity of S0(H) exactly counteracts the existence of energy-preserving
symplectc scheme.

Bibliography
[Fen98] K. Feng: The calculus of generating functions and the formal energy for Hamiltonian
systems. J. Comput. Math., 16:481–498, (1998).
[FQ87] K. Feng and M.Z. Qin: The symplectic methods for the computation of Hamiltonian
equations. In Y. L. Zhu and B. Y. Guo, editors, Numerical Methods for Partial Differential
Equations, Lecture Notes in Mathematics 1297, pages 1–37. Springer, Berlin, (1987).
[FQ91a] K. Feng and M.Z. Qin: Hamiltonian Algorithms for Hamiltonian Dynamical Systems.
Progr. Natur. Sci., 1(2):105–116, (1991).
[FQ91b] K. Feng and M.Z. Qin: Hamiltonian algorithms for Hamiltonian systems and a com-
parative numerical study. Comput. Phys. Comm., 65:173–187, (1991).
[FQ03] K. Feng and M. Z. Qin: Symplectic Algorithms for Hamiltonian Systems. Zhejiang
Press for Science and Technology, Hangzhou, in Chinese, First edition, (2003).
[Ge88] Z. Ge: Symplectic geometry and its application in numerical analysis. PhD thesis,
Computer Center, CAS, (1988).
[Ge91] Z. Ge: Equivariant symplectic difference schemes and generating functions. Physica
D, 49:376–386, (1991).
[GM88] Z. Ge and J. E. Marsden: Lie–Poisson Hamilton–Jacobi theory and Lie–Poisson inte-
grators. Physics Letters A, pages 134–139, (1988).
[GW95] Z. Ge and D.L. Wang: On the invariance of generating functions for symplectic trans-
formations. Diff. Geom. Appl., 5:59–69, (1995).

Chapter 7.
Symplectic Runge–Kutta Methods
In this chapter we consider symplectic Runge–Kutta (R–K) method.
7.1 Multistage Symplectic Runge–Kutta Method
Now we study Multistage Symplectic Runge–Kutta Method. A key feature of the R–K
method is using the linear combination of the ﬁrst-order derivatives of the numerical
solution of differential equations to achieve the higher-order approximation.
7.1.1 Deﬁnition and Properties of Symplectic R–K Method
Consider the following Hamiltonian system:
dpi
dt = −∂H
∂qi ,
dqi
dt = ∂H
∂pi ,
i = 1, 2, · · · , n,
(1.1)
where H = H(p1, · · · , pn, q1, · · · , qn) is a Hamiltonian function independent of t. For
t-dependent Hamiltonian (e.g., nonautonomous system), we can introduce two new
variables and transform the system into another one which has (1.1) form[Qin96,Gon96].
In order to facilitate the expression, we denote
z =
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
p1
...
pn
q1
...
qn
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
=
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
z1
...
zn
zn+1
...
z2n
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
,
Hz =
⎡
⎢⎢⎢⎢⎢⎢⎣
Hz1
...
Hzn
...
Hz2n
⎤
⎥⎥⎥⎥⎥⎥⎦
,
J = J2n =
 
O
In
−In
O
!
,
J′ = J−1 = −J,
where In is n × n identity matrix, J is a standard symplectic matrix. Using this nota-
tion, we can rewrite Equation (1.1) into

278
7. Symplectic Runge–Kutta Methods
dz
dt = J−1Hz,
(1.2)
or
dz
dt = J−1Hz = f(z).
(1.3)
The s-stage R–K method for (1.3) has the following form:
zk+1 = zk + h
s

i=1
bif(Yi),
Yi = zk + h
s

j=1
aijf(Yj),
1 ≤i ≤s,
(1.4)
where h = tk+1 −tk (k ≥0), bi, aij (i, j = 1, 2, · · · , s) are real parameters. The
properties of a R–K method (consistency, accuracy, and stability, etc.) are determined
completely by these parameters. In scheme (1.4), if j ≥i (1 ≤i ≤s), aij = 0, then
all Yi
Yi = zk + h
i−1

j=1
aijf(Yj) + aiif(Yi),
1 ≤i ≤s,
(1.5)
can be computed in an explicit way from Y1, Y2, · · · , Yi−1. Such scheme is therefore
called explicit R–K scheme. In scheme (1.4), when j > i (1 ≤i < s), aij = 0,
and has certain aii ̸= 0 in the diagonal line (1 ≤i ≤s), the scheme is called semi-
implicit scheme. Each Yi may deﬁned implicitly by a 2n-dimensional equation. The
importance of semi-implicit methods is that the computation of Y1, Y2, · · · , Yi−1 can
be carried out in sequence as s system of 2n algebraic equation rather than as one
system of s × 2n equations. Sometimes we referred this scheme as diagonal implicit.
If the method is neither explicit, nor diagonally implicit, and is just called implicit,
then all Yi must be computed simultaneously. Explicit methods are much easier to
apply than implicit ones. On the other hand implicit methods possess good stability
properties.
Butcher in[But87] proposed the so-called Butcher-array which provides a condensed
representation of the R–K method (1.4),
c
A
bT
c1
a11
· · ·
a1s
c2
a21
· · ·
a2s
...
...
...
cs
as1
· · ·
ass
b1
· · ·
bs
(1.6)
where ci =
s

j=1
aij (i = 1, 2, · · · , s). Thus, a s-stage R–K method is determined
completely by the mathmatical tableau (1.6). Therefore this kind of expression is often
called the Butcher tableau (or form).

7.1 Multistage Symplectic Runge–Kutta Method
279
We regard a single-step difference scheme as a transition mapping from time tk to
tk+1 .
Deﬁnition 1.1. A symplectic R–K method is a R–K method whose transitional trans-
formation of (1.4), i.e., Jacobian matrix ∂zk+1
∂zk
is symplectic.
Deﬁnition 1.2. An s-stage R–K method is said to satisfy simplifying condition if
B(p) :
s

i=1
bick−1
i
= 1
k,
k = 1(1)p,
C(η) :
s

j=1
aijck−1
j
= ck
i
k ,
k = 1(1)η,
D(ζ) :
s

i=1
bick−1
i
aij = bj(1 −ck
j )
k
,
j = 1(1)s,
k = 1(1)ζ,
where A is s×s matrix, b and c are s×1 vectors of weights and abscissae, respectively.
In 1964 Butcher proved the following fundamental theorem [But87]:
Theorem 1.3. If the coefﬁcients A, b, c of a R–K method satisfy B(p), C(η), D(ζ)
(p ≤η + ζ + 1, and p ≤2η + 2), then the R–K method is of order p[HNW93].
R–K method is based on high order quadrature rule. Thus one can derive a R–K
method of order s for any set of distinct abscissas ci (i = 1, · · · , s). A high order can
be obtained for the following special sets of abscissas:
1◦
Using shifted zeros of the Gauss–Legendre polynomial to obtain ci and con-
dition C(s) of Deﬁnition 1.2 to obtain the Gauss–Legendre method.
2◦
Using zeros of Radau polynomial:
(1)
ds−1
dxs−1

xs(x −1)s−1
(left Radau),
(2)
ds−1
dxs−1

xs−1(x −1)s
(right Radau),
with condition D(s) of Deﬁnition 1.2 to obtain Radau I A method, or with condition
C(s) to obtain Radau II A method.
3◦
Using zeros of Lobatto polynomial
ds−2
d xs−2

xs−1(x −1)s−1
with coefﬁcients bi satisfying condition 1.2 B(2s −2) to obtain
(1)
Lobatto III A if aij is determined by C(s);
(2)
Lobatto III B if D(s) is satisﬁed;
(3)
Lobatto III C if ai1 = b1, ∀i = 1, · · · , s, and the rest of aij is determined
by C(s −1).
Radau I A:

280
7. Symplectic Runge–Kutta Methods
0
1
1
0
1
4
−1
4
2
3
1
4
5
12
1
4
3
4
Radau II A:
1
1
1
1
3
5
12
−1
12
1
3
4
1
4
3
4
1
4
Lobatto III A:
0
0
0
1
1
2
1
2
1
2
1
2
0
0
0
0
1
2
5
24
1
3
−1
24
1
1
6
2
3
1
6
1
6
2
3
1
6
Lobatto III B:
0
1
2
0
1
1
2
0
1
2
1
2
0
1
6
−1
6
0
1
2
1
6
1
3
0
1
1
6
5
6
0
1
6
2
3
1
6
Lobatto III C:

7.1 Multistage Symplectic Runge–Kutta Method
281
0
1
2
−1
2
1
1
2
1
2
1
2
1
2
0
1
6
−1
3
1
6
1
2
1
6
5
12
−1
12
1
1
6
2
3
1
6
1
6
2
3
1
6
We present a table of these conditions for methods which are based on high order
quadrature rule, see Table 1.1.
Table 1.1.
The simpliﬁed conditions for s-stage method based on high order quadrature rule
method
simpliﬁed
condition
order of accuracy
Pad´e approx
Gauss–Legendre
B(2s)
C(s)
D(s)
2s
(s, s)
Radau I A
B(2s −1)
C(s −1)
D(s)
2s −1
(s −1, s)
Radau II A
B(2s −1)
C(s)
D(s −1)
2s −1
(s −1, s)
Lobatto III A
B(2s −2)
C(s)
D(s −2)
2s −2
(s −1, s −1)
Lobatto III B
B(2s −2)
C(s −2)
D(s)
2s −2
(s −1, s −1)
Lobatto III C
B(2s −2)
C(s −1)
D(s −1)
2s −2
(s −2, s)
7.1.2 Symplectic Conditions for R–K Method
In this subsection a sufﬁcient condition for R–K method to be symplectic is given. Let
B = diag[b1, b2, · · · , bs] be a diagonal matrix, M = BA + A′B −bb′. The following
condition was ﬁrst proposed by Sanz-Serna during his visit to China[SS88].
Theorem 1.4. If M = 0, then an s-stage R–K method (1.4) is symplectic[SS88,Las88,Sur88].
Proof. Here we give our own proof[QZ92a]. To prove the scheme (1.4) is symplectic
when M = 0, we only need to verify the Jacobian matrix is symplectic. From the
scheme (1.4) we have
∂zk+1
∂zk
= I + h
s

i=1
biDf(Yi) ∂Yi
∂zk ,
(1.7)
∂Yi
∂zk = I + h
s

j=1
aijDf(Yj)∂Yj
∂zk ,
1 ≤i ≤s,
(1.8)
where D f is the derivative of function f.

282
7. Symplectic Runge–Kutta Methods
Denote Di = D f(Yi), ∂Yi
∂zk = Xi (i = 1, 2, · · · , s), and let f = J−1Hz, then
JDi + D′
iJ = 0,
(1.9)
and
%
∂zk+1
∂zk
&′
J ∂zk+1
∂zk
= J + h
* s

i=1
biDiXi
+′
J + hJ
* s

i=1
biDiXi
+
+
*
h
s

i=1
biDiXi
+′
J
*
h
s

i=1
biDiXi
+
= J + h
s

i=1
bi [(DiXi)′J + JDiXi]
+h2
* s

i=1
biDiXi
+′
J
* s

i=1
biDiXi
+
.
It follows from (1.8)
(DiXi)′JXi = (DiXi)′J + h
s

j=1
aij(DiXi)′JDjXj,
(Xi)′JDiXi = JDiXi + h
s

j=1
aij(DjXj)′JDiXi.
Using Equation (1.9), we obtain
%
∂zk+1
∂zk
&′
J ∂zk+1
∂zk
= J +
*
h
s

i=1
biDiXi
+′
J
*
h
s

i=1
biDiXi
+
+h
s

i=1
bi [X′
iD′
iJXi + X′
iJDiXi]
−h
s

i=1
bi
 
h
s

j=1
aij(DiXi)′JDjXj
+h
s

j=1
aij(DjXj)′JDiXi
!
= J + h2
s

i=1
s

j=1
(bibj −biaij −bjaji)(DiXi)′JDjXj.
It is easy to see that if M = 0, then

7.1 Multistage Symplectic Runge–Kutta Method
283
%
∂zk+1
∂zk
&′
J ∂zk+1
∂zk
= J,
i.e., the Jacobian matrix of transitional mapping ∂zk+1
∂zk
is symplectic.
▲
Remark 1.5. If R–K method is non-reducible, then condition M = 0 is also neces-
sary.
From subsection 7.1.1 we know that a R–K method is determined completely by
the coefﬁcients ci, aij, bi (i, j = 1, · · · , s). Now we introduce the Gauss–Legendre
method: let ci (i = 1, · · · , s) be zeros of shifted Legendre polynomial Qs(x), where
the Legendre polynomials are deﬁned as
Ps(x) =
1
2ss!
ds
d xs {(x2 −1)s},
(1.10)
Qs(x) = Ps

x −1
2

.
(1.11)
Let this method satisfy simpliﬁed conditions B(s) and C(s). Solve equations
s

i=1
bick−1
i
= 1
k (1 ≤k ≤s) for bi (i = 1, · · · , s), and solve equations
s

j=1
aijck−1
j
= 1
k ck
i (1 ≤
k ≤s, 1 ≤i ≤s) for aij (i, j = 1, · · · , s). Then the scheme determined by bi and aij
is the only R–K method that has achieved 2s-order of accuracy. We listed Butcher’s
tableau for s ≤2 as follows
s = 1:
1
2
1
2
1
(1.12)
s = 2:
3 −
√
3
6
1
4
3 −2
√
3
12
3 +
√
3
6
3 + 2
√
3
12
1
4
1
2
1
2
(1.13)
It is easy to see that s = 1 is exactly the case of the Euler centered scheme:
zk+1 = zk + hf
%1
2(zk + zk+1)
&
.
(1.14)

284
7. Symplectic Runge–Kutta Methods
It is not difﬁcult to verify that both schemes (1.12) and (1.13) satisfy the conditions
M = 0, and hence are symplectic. Furthermore, we have the following conclusions:
Theorem 1.6. An s-stage Gauss–Legendre method is a symplectic scheme with 2s-
order of accuracy.
Proof. Since the scheme satisﬁes conditions D(s), C(s), B(2s), i.e.,
s

i=1
biaijcl−1
i
=
1
l bj(1 −cl
j) = 1
l bj −1
l bjcl
j
=
s

i=1
bibjcl−1
i
−
s

i=1
bjajicl−1
i
,
which results in
s

i=1
(biaij + bjaji −bibj)cl−1
i
= 0,
l, j = 1, 2, · · · , s.
Since c1, c2, · · · , cs are not equal mutually, we obtain M = 0.
▲
7.1.3 Diagonally Implicit Symplectic R–K Method
In this subsection, we will give some diagonal symplectic R–K formulas. These
schemes not only have advantages with regards to computational convenience and
good stability, but also are symplectic.
Let us consider a diagonally s-stage implicit R–K method that satisﬁes M = 0.
Without loss of generality we assume that bi ̸= 0 (i = 1, 2, · · · , s). Because of the
condition M = 0, we have
bibj −biaij −bjaji = 0,
i, j = 1, 2, · · · , s.
(1.15)
If bk = 0, then biaik = 0 (i = 1, 2, · · · , s), the method is equivalent to a method with
fewer stages.
The following theorem is ﬁrst proposed by the authors, sees the literature [QZ92a,SA91].
Theorem 1.7. If an s-stage diagonally implicit method satisﬁes M = 0, then we can
write the method in the following form:
c1
b1
2
c2
b1
b2
2
c3
b1
b2
b3
2
...
...
...
...
cs
b1
b2
b3
· · ·
bs
2
b1
b2
b3
· · ·
bs
(1.16)

7.1 Multistage Symplectic Runge–Kutta Method
285
where ci =
i

j=1
bj−1 + bi
2 (i = 1, · · · , s, b0 = 0).
Proof. Since the scheme is diagonally implicit, aij = 0 (j > i); to satisfy M = 0,
we have bibj −biaij −bjaji = 0 (i, j = 1, 2, · · · , s), which results in
aij = bj,
aii = bi
2 ,
i = 1, · · · , s,
i > j.
The theorem is proved.
▲
Corollary 1.8. Explicit R–K method with any order does not satisfy condition M = 0.
Remark 1.9. Tableau (1.16) Cooper[Coo87] has discussed the condition (1.15) and con-
structed a method of family (1.16) with s = 3 and order 3.
Below we give diagonally implicit symplectic R–K methods for s ≤3:
s = 1:
1
2
1
2
1
(1.17)
s = 2 :
1
4
1
4
0
3
4
1
2
1
4
1
2
1
2
(1.18)
s = 3 :
1
2a
1
2a
3
2a
a
1
2a
1
2 + a
a
a
1
2 −a
a
a
1 −2a
(1.19)
where a = 1.351207, which is a real root of polynomial 6x3 −12x2 + 6x −1 [Coo87].
The above three schemes have accuracy o(Δt2), o(Δt2), o(Δt3) respectively.

286
7. Symplectic Runge–Kutta Methods
Corollary 1.10. If s = 3, and the elements in Butcher tableau are taken in symmetri-
cal version (a11 = a33).
1
2a
1
2a
1
2
a
1
2 −a
1 −1
2a
a
1 −2a
1
2a
a
1 −2a
a
(1.20)
Then this scheme has 4th-order accuracy.
In Chapter 8 we will see that this is a typical example that using Euler centered
scheme and multiplication extrapolation to achieve 4th order accuracy.
Now we consider s = 4, Butcher tableau can be represented as follows:
b1
2
b1
2
b1 + b2
2
b1
b2
2
b1 + b2 + b3
2
b1
b2
b3
2
b1 + b2 + b3 + b4
2
b1
b2
b3
b4
2
b1
b2
b3
b4
(1.21)
We expect this method to have 4th-order accuracy. According to Taylor expansion,
the coefﬁcients in the method must satisfy the system of equations:
s

i=1
bi = 1,
(1.22)
s

i=1
bici = 1
2,
(1.23)
s

i=1
bic2
i = 1
3,
(1.24)
s

i,j=1
biaijcj = 1
6,
(1.25)

7.1 Multistage Symplectic Runge–Kutta Method
287
s

i=1
bic3
i = 1
4,
(1.26)
s

i,j=1
biciaijcj = 1
8,
(1.27)
s

i,j=1
biaijc2
j = 1
12,
(1.28)
s

i,j,k=1
biaijajkck = 1
24.
(1.29)
Now we have 8 equations with 4 unknowns. Luckily we ﬁnd a set of solutions using
computer, which is
b1 = −2.70309412,
b2 = −0.53652708,
b3 = 2.37893931,
b4 = 1.8606818856.
Perhaps we can reduce the equations to the form of 4 equations with 4 unknowns and
get the exact solution. For an example, using
s

i=1
bi = 1, bibj −biaij = 0 (i, j =
1, 2, · · · , s), we have
s

i=1,j=1
biai,j =
s

i=1
bici = 1
2. So we can remove Equation
(1.23) from the system. In an implementation of this R–K method, we rewrite it in the
following form:
Y1 = zk + b1h
2 f(Y1),
Y2 = 2Y1 −zk + b2h
2 f(Y2),
Y3 = 2Y2 −(2Y1 −zk) + b3h
2 f(Y3),
Y4 = 2Y3 −(2Y2 −2Y1 + zk) + b4h
2 f(Y4),
zk+1 = 2Y4 −(2Y3 −2Y2 + 2Y1 −zk).
(1.30)
Corollary 1.11. This scheme (1.30) can be obtained by applying the implicit midpoint
scheme over 4 steps of length b1h, b2h, b3h, b4h. It has 4-th order accuracy.
Let

288
7. Symplectic Runge–Kutta Methods
z
1
4 = z0 + b1hf
z
1
4 + z0
2

,
z
2
4 = z
1
4 + b2hf
z
2
4 + z
1
4
2

,
z
3
4 = z
2
4 + b3hf
z
3
4 + z
2
4
2

,
z1 = z
3
4 + b4hf
z1 + z
3
4
2

,
(1.31)
Rewrite it in the following form:
z
1
4 + z0
2
= z0 + b1
2 hf
%
z
1
4 + z0
2
&
,
z
2
4 + z
1
4
2
= z
1
4 + b2
2 hf
%
z
2
4 + z
1
4
2
&
,
z
3
4 + z
2
4
2
= z
2
4 + b3
2 hf
%
z
3
4 + z
2
4
2
&
,
z1 + z
3
4
2
= z
3
4 + b4
2 hf
%
z1 + z
3
4
2
&
.
(1.32)
Let
z0 + z
1
4
2
= Y1,
z
1
4 + z
2
4
2
= Y2,
z
2
4 + z
3
4
2
= Y3,
z
3
4 + z1
2
= Y4,
then (1.32) becomes scheme (1.30).
There are similar results for s ≤3. More detail can be seen later in Section 8.1.
All schemes proposed in this section can be applied to general ODE’s as well.
Exercise 1.12. Does there exist 5-stage diagonally implicit R–K method with 5th-
order accuracy?
7.1.4 Rooted Tree Theory
1.
High order derivatives and rooted tree theory
The basic method to construct the numerical scheme for ordinary differential equa-
tions is Taylor expansion. If only a single (scalar) equation is considered, Taylor ex-
pansion can be used in studying the convergence, compatibility, and order conditions
for R–K methods. However, if the system of differential equations are considered,
Taylor expansion is intractable. Consider system of ODE’s:
˙y = f(y),
y(0) = η,
f : Rm →Rm,
m > 1.
(1.33)

7.1 Multistage Symplectic Runge–Kutta Method
289
For brevity, let m = 2, and y = (1y, 2y)′, f = (1f, 2f)′, introduce the following
notations
ifj := ∂if
∂(jy),
ifjk :=
∂2(if)
∂(jy)∂(ky),
we have
1y(1) = 1f,
2y(1) = 2f,
1y(2) = 1f1(1f) + 1f2(2f),
2y(2) = 2f1(1f) + 2f2(2f).
(1.34)
Using matrix and vector symbols, we have
y(2) =
5 1f1
1f2
2f1
2f2
6
f.
(1.35)
The second order derivative can be expressed via Jacobian matrix. However, the
third-order derivative y(3), can no longer be expressed via matrix and vector sym-
bol, not to mention the higher order derivative. This has motivated people to study
the structure of the Taylor expansion of high order derivatives and search for a better
symbol to simplify the Taylor expansion of high order derivatives. Then the rooted tree
theory[But87,Lam91,HNW93,SSC94] (With the tree roots skill to express high order deriva-
tive) emerged. Take y(3) as an example:
1y(3) =
1f11(1f)2 + 1f12(1f)(2f) + 1f1
1f1(1f) + 1f2(2f)

+1f21(2f)(1f) + 1f22(2f)2 + 1f2
2f1(1f) + 2f2(2f)

,
2y(3) =
2f11(1f)2 + 2f12(1f)(2f) + 2f1
1f1(1f) + 1f2(2f)

+2f21(2f)(1f) + 2f22(2f)2 + 2f2
2f1(1f) + 2f2(2f)

.
(1.36)
Deﬁnition 1.13. Let z, f(z) ∈Rm, f (M)(z) be the M-th Frechet derivatives of f.
It is an operator on Rm × Rm × · · · × Rm (M times), and is linear in each operand,
f (M)(z)(K1, K2, · · · , KM)
=
m

i=1
m

j1=1
m

j2=1
· · ·
m

jM=1
ifj1j2···jM
j1Kj2
1 K2 · · · jM KM · ei,
(1.37)
where z is the argument, K1, K2, · · · , KM operands, and
Kt =
1Kt, 2Kt, · · · , mKt
T ∈Rm,
t = 1, 2, · · · , M,
ifj1j2···jM
=
∂M
∂(j1z)∂(j2z) · · · ∂(jM z)
if(z)
(1.38)
and
ei = [0, 0, · · · , 0,
1
0123
i
, 0, · · · , 0]T ∈Rm.

290
7. Symplectic Runge–Kutta Methods
We have the following comments:
(1)
The value of f (M)(z)(· · ·) is a vector in Rm.
(2)
Repeated subscripts are permitted in (1.37), so that all possible partial deriva-
tives of order M are involved. Thus, if M = 3, m = 2, the following partial deriva-
tives will appear:
if111 = ∂3(if)
∂(1z)3 ;
if112 = if121 = if211 =
∂3(if)
∂(1z)2∂(2z),
if122 = if212 = if221 =
∂3(if)
∂(1z)∂(2z)2 ,
if222 = ∂3(if)
∂(2z)3 ,
i = 1, 2.
(3)
The argument z simply denotes the vector with respect to whose component
we are performing the partial differentiations.
(4)
An M times Frechet derivatives has M operands. This is an important prop-
erty to note.
Take m = 2, we have
Case M = 1,
f(1)(z)(K1) =
2

i=1
2

j1=1
ifj1(j1K1)ei
=
5 1f1(1K1) + 1f2(2K1)
2f1(1K1) + 2f2(2K1)
6
,
(1.39)
where
if1 = ∂(if)
∂(1z),
if2 = ∂(if)
∂(2z),
i = 1, 2.
Replace z with y, and K1 with f, (1.39) becomes
f (1)(y)(f(y)) =
5 1f1(1f) + 1f2(2f)
2f1(1f) + 2f2(2f)
6
= y(2).
(1.40)
(1.40) can be brieﬂy denoted as
y(2) = f (1)(f).
(1.41)
Case M = 2,
f (2)(z)(K1, K2) =
2

i=1
2

j1=1
2

j2=1
ifj1j2(j1K1)(j2K2)ei
=
5
1f11(1K1)(1K2) + 1f12(1K1)(2K2) + 1f21(2K1)(1K2) + 1f22(2K1)(2K2)
2f11(1K1)(1K2) + 2f12(1K1)(2K2) + 2f21(2K1)(1K2) + 2f22(2K1)(2K2)
6
.
Use y to replace z, and let K1 = K2 = f, we obtain

7.1 Multistage Symplectic Runge–Kutta Method
291
f (2)(y)(f(y), f(y)) =
5 1f11(1f)2 + 2(1f12)(1f)(2f) + 1f22(2f)2
2f11(1f)2 + 2(2f12)(1f)(2f) + 2f22(2f)2
6
,
(1.42)
which is only part of the right side of (1.36), but not all. The absent terms are
5 1f1
1f1(1f) + 1f2(2f)

+ 1f2
2f1(1f) + 2f2(2f)

2f1
1f1(1f) + 1f2(2f)

+ 2f2
2f1(1f) + 2f2(2f)

6
.
(1.43)
Now if we replace the operand f(y) with f (1)(y)(f(y)) in (1.40), the result is exactly
(1.43). Hence, shortening the notation as in (1.41), (1.36) can be written as
y(3) = f (2)(f, f) + f (1)(f (1)(f)).
(1.44)
Thus we have seen that y(2) is a single Frecht derivative of order 1, and that y(3) is
a linear combination of Frecht derivatives of order 1 and 2. In general, y(p) turns out
to be a linear combination of Frecht derivatives of order up to p −1. The components
in such linear combination are called elementary differentials.
Deﬁnition 1.14. The elementary differential Fs : Rm →Rm of f, and their order
are deﬁned respectively by
1◦
f is only elementary differential of order 1, and
2◦
if Fs (s = 1, 2, · · · , M) are elementary differential of order rs, then the
Frecht derivative
F (M)(F1, F2, · · · , FM),
(1.45)
is an elementary of order
1 +
M

s=1
rs.
(1.46)
Remark 1.15. We have following:
1◦
The elementary differential F1, F2, · · · , FM appearing as operands in (1.45)
need not be distinct.
2◦
{F1, F2, · · · , FM} : f (M)(F1, F2, · · · , FM).
(1.47)
3◦
The order of the elementary differential (1.47) is, by (1.46), the sum of the
orders of the elementary differentials plus 1, i.e., 1+
M

s=1
rs, where 1 is “for the brack-
ets”.
Order 1 has only one elementary differential, i.e., f.
Order 2 has only one elementary differential, i.e., f (1)(f) = {f}.
Order 3 has two elementary differentials, i.e.,
M = 2 =⇒operand f, f =⇒elementary differential {f 2},
M = 1 =⇒operand f (1)(f) = {f} =⇒elementary differential {{f}} = {2f}2.

292
7. Symplectic Runge–Kutta Methods
Order 4 has four elementary differentials, i.e.,
M = 3 =⇒operandf, f, f
=⇒elementary differential {f 3},
M = 2 =⇒operand f, {f} =⇒elementary differential {f{f}2(≡{2f}f}),
M = 1 =⇒operand {f 2}
=⇒elementary differential {2f 2}2,
operand {2f}2 =⇒elementary differential {3f}3.
2.
Labeled graph
Let n be a positive integer. A labeled n-graph g is a pair {V, E} formed by a set V
collection with card (V ) = n, and a set E of unordered pairs (v, w) as a collection of
elements, of which v, w are point of the set V , and v ̸= w. Therefore g may be empty.
V and E elements are known as the vertices and edges respectively. Two vertices v, w
is said to be the adjacent if (v, w) ∈E. Fig. 1.1 shows labeled graph for n = 2, 3, 4.
◦
◦
◦
◦
i
j
l
k
n = 4
n = 2
n = 3
i
j
k
l
◦
◦
◦
◦
◦
◦
◦
◦
l
k
j
i
◦
◦
◦
◦
◦
i
j
i
j
k
Fig. 1.1.
Labeled graph for n = 2, 3, 4
A graph can have many different types of label. However for the same graph, there
exists a isomorphic mapping χ between two different labels. For an example, for one
of the graphs in Fig. 1.1, depicted also in Fig. 1.2, we can take two types of label, as
shown in Fig. 1.3.
i
j
k
l
◦
◦
◦
◦
Fig. 1.2.
Labeled of graph 4
m
n
p
q
◦
◦
◦
◦
i
j
k
l
◦
◦
◦
◦
Fig. 1.3.
2 kind labeled of graph

7.1 Multistage Symplectic Runge–Kutta Method
293
We take mapping χ to be
χ : i −→m,
j −→n,
k −→p,
l −→q,
i.e.,
χ : V1 −→V2,
V1 = {i, j, k, l},
V2 = {m, n, p, q},
then
χ :
(i, j) −→(m, n),
(j, k) −→(n, p),
(k, l) −→(p, q),
i.e.,
χ :
E1 −→E2,
E1 = {(i, j), (j, k), (k, l)},
E2 = {(m, n), (n, p), (p, q)}.
Therefore χ : Lg1 →Lg2, where Lg1 = {V1, E1}, Lg2 = {V2, E2} are two different
labels in Fig. 1.3. In fact, if there exists a isomorphic mapping between two labels
g1, g2, they can be regarded as two types of labels for the same tree. Therefore a
graph is an equivalent class, which consists of a variety of different labeled graphs
corresponding to different types of label. These labeled graphs are equivalent, i.e.,
there exists an isomorphic mapping between them.
3.
Relationship between rooted tree and elementary differential
Next we can see that there is a 1 to 1 correspondence between elementary and trees.
(1)
Let f be the unique elementary differential of order 1. Then f corresponds
to the unique tree of order 1, which consists of a single vertex.
(2)
If the elementary differential Fs of order rs (s = 1, 2, · · · , M) corre-
sponds to trees ts of order rs (s = 1, 2, · · · , M), then the elementary differential
{F1, F2, · · · , FM} of order 1 +
M

1
rs corresponds to the tree of order 1 +
M

s=1
rs,
obtained by grafting the M trees Fs (s = 1, 2, · · · , M) onto a new root.
Example 1.16. If F1 ∼t1
◦
◦
◦,
F2 ∼t2 =◦
◦,
F3 ∼t3 =
◦
◦
◦
◦
, then
{F1, F2, F3} ∼
◦
◦
◦
◦
◦
◦
◦
◦◦
◦
.
We need a notation to represent trees similar to the notation for elementary differ-
ential. All trees can be labeled with combination of the symbol of τ for the unique tree
of order 1 (consisting of a single node) and the symbol [· · ·], meaning we have grafted
the trees appearing between the brackets onto a new root. We shall denote n copies of
tree t1 by tn
1,
[[[···[
ktimes by [k, and
]···]]]
ktimes by ]k. For example

294
7. Symplectic Runge–Kutta Methods
t1 = [τ]=◦
◦,
t2 =
@
τ[τ]
A
=
@
[τ]τ
A
=
@
τ[τ]2 =
◦
◦
◦
◦
,
t3 = [t1, t2
2] =
@
[τ] [τ[τ]], ] [τ[τ] ]
A
= [2τ] [τ[τ]2[τ[τ]3 =
◦
◦
◦
◦
◦
◦
◦
◦
◦
◦
◦
.
Deﬁnition 1.17. The order r(t), symmetry σ(t) and density (tree factorial) γ(t) are
deﬁned by
r(τ) = σ(τ) = γ(τ) = 1,
and
r

[tn1
1 tn2
2 · · ·]

= 1 + n1r(t1) + n2r(t2) + · · · ,
(number of vertices)
σ

[tn1
1 tn2
2 · · ·]

= n1 !n2 ! · · ·

σ(t1)
n1 
σ(t2)
n2 · · · ,
γ

[tn1
1 tn2
2 · · ·]

= r

[tn1
1 tn2
2 · · ·]

γ(t1)
n1
γ(t2)
n2 · · · .
Let α(t) (tree multiplicity) be the number of essentially different ways of labeling
the vertices of the tree t with the integers 1, 2, · · · , r(t) such that labels are monotone
increase. Essentially different labeling is illustrated in the following examples:
Example 1.18. t1 = [τ 3] = ◦
◦◦
◦
, its labeling trees are ◦
◦◦
◦1
2
3
4
and ◦
◦◦
◦1
4
2
3
,
are not regarded as essentially different labelings, hence α(t1) = 1.
Example 1.19. t2 =
@
τ[τ]
A
=
◦
◦
◦
◦, its labeling trees are
◦
◦
◦
◦
1
4
2
3 ,
◦
◦
◦
◦
1
4
3
2
and
◦
◦
◦
◦
1
3
4
2are regarded as essentially different labelings, and α(t2) = 3.
From above, we have a easy way of computing α(t), namely
α(t) =
r(t) !
σ(t)γ(t).
(1.48)

7.1 Multistage Symplectic Runge–Kutta Method
295
4.
Order conditions for multi-stage R–K method
Deﬁnition 1.20. The function F is deﬁned on the set T of all trees by
F(τ) = f,
F([t1, t2, · · · , tM]) = {F(t1), F(t2), · · · , F(tM)}.
(1.49)
The proof of the following two theorems was established by Butcher in 1987 [But87].
Theorem 1.21. Let ˙y = f(y), f : Rm →Rm, then
y(q) =

r(t)=q
α(t)F(t),
(1.50)
where F(t) is deﬁned by (1.49), and α(t) by (1.48).
Below let us apply this theorem for p ≤4 to obtain y(q):
y(2) = {f},
y(3) = {f 2} + {2f}2,
y(4) = {f 3} + 3{f{f}2 + {2f 2}2 + {3f}3.
Let us deﬁne the right side of Equation (1.4) to be yn(h), which is then expanded as a
Taylor series about h = 0,
y(xn+1) = y(xn) + hy(1)(xn) + 1
2h2y(2)(xn) + · · · ,
(1.51)
where
dq
d hq yn(h)

h=0 =

r(t)=q
α(t)γ(t)φ(t)F(t).
(1.52)
We ﬁrst slightly modify the notation in Butcher array of a. Let as+1,i = bi (i =
1, 2, · · · , s), we get the following Table 1.2.
Deﬁnition 1.22. 1◦
For i = 1, 2, · · · , s, s + 1, deﬁne the function of φi on the set T
of all trees by:
φi(τ) =
s

j=1
aij,
φi([t1, t2, · · · , tM]) =
s

j=1
aijφj(t1)φj(t2) · · · φj(tM).
2◦
deﬁne φ(t) = φs+1(t).

296
7. Symplectic Runge–Kutta Methods
Table 1.2.
Tree and elementary differential up to 4
tree
t
F (t)
r(t)σ(t)γ(t)α(t)φi(t), i = 1, · · · , s
φ(t)
◦
τ
f
1
1
1
1

j
aij(= ci)

i
bi
◦
◦
[τ] {f} = f ′f
2
1
2
1

j
aijcj

i
bici
◦
◦
◦
[τ 2] {f 2} = f ′′(f, f)
3
2
3
1

j
aijc2
j

i
bic2
i
◦
◦
◦
[[τ]] {2f}2 = f ′f ′f
3
1
6
1

j
aij

k
ajkck

i,j
biaijcj
◦
◦◦
◦
[τ 3] {f 3} = f ′′′(f, f, f)
4
6
4
1

j
aijc3
j

i
bic3
i
◦
◦
◦
◦[τ[τ]] {f{f}2 = f ′′(f, f ′f) 4
1
8
3

j
aijcj

k
ajkck

i,j
biciaijcj
◦
◦
◦
◦
[[τ 2]] {2f 2}2 = f ′f ′′(f, f) 4
2
12
1

j
aij

k
ajkc2
k

i,j
biaijc2
j
◦
◦
◦
◦

[[τ]]

{3f}3 = f ′f ′f ′f
4
1
24
1

j
aij

k
ajk

n
akncn

i,j,k
biaijajkck
Remark 1.23. Functions φi has representations on the set T
φi(τ) =

j
aij = ci,
∀i = 1, 2, · · · , s,
φ(τ) =

j
as+1,j =

j
bj =

i
bi,
φi([τ]) =

j
aijφj(τ) =

j
aijcj,
∀i = 1, 2, · · · , s,
φ([τ]) =

j
as+1,jcj =

j
bjcj =

i
bici,
φi([[τ]]) =

j
aijφj([τ]) =

j
aij

k
ajkck,
∀i = 1, 2, · · · , s,
φ([[τ]]) =

j
as+1,j

k
ajkck =

jk
bjajkck =

ij
biaijcj.
Theorem 1.24. R–K method has order p, if

7.1 Multistage Symplectic Runge–Kutta Method
297
φ(t) =

i
biφi =
1
γ(t),
∀r(t) ≤p,
t ∈T,
(1.53)
and does not hold for some tree of order p + 1.
From Table 1.3, we then obtain the following number of orders trees (see Table 1.4).
Table 1.3.
Number of trees up to order 10
order p
1
2
3
4
5
6
7
8
9
10
number of trees Tp
1
1
2
4
9
20
48
115
286
719
Table 1.4.
Number of conditions up to order 10
order p
1
2
3
4
5
6
7
8
9
10
number of conditions
1
2
4
8
17
37
85
200
486
1205
Number of order conditions for Multi-stage R–K up to order 10, can be seen in the
following Table 1.4.
7.1.5 Simpliﬁed Conditions for Symplectic R–K Method
There are four types of trees, which can be deﬁned as follows[SA91]:
(1)
A labeled n-tree λτ is a labeled n-graph {V, E}, such that for any pair of
distinct vertices v and w, there exists a unique path that joins v and w.
(2)
Two labeled n-trees {V1, E1}, {V2, E2} are said to be isomorphic, if a bi-
jection of V1 onto V2 exists that transforms edges in E1 into edges in E2, vertices V1
into V2. n-trees τ is an equivalence class that consists of labeled n-trees isomorphic
to it. Each of the labeled n-trees that represent τ is called a labeling of τ.
(3)
A rooted labeled n-tree ρλτ is a labeled n-tree, in which one of the vertices
r, called the root, has been highlighted. The vertices adjacent to the root are called the
sons of the root. The sons of the remaining vertices are deﬁned in an obvious recursive
way. In fact, when some point is deﬁned as root, the tree becomes a directed graph,
i.e., any edge (v, w) in set E has a direction to represent the relationship between
father and son. Let T be a mapping from son to father. Since any point v has a path to
the root, e.g. v = v0, v1, · · · , vm = r, r may be obtained through the sequential action
of T on v. Therefore a direction can be deﬁned from v to r, and the entire root also
become oriented.
(4)
Two labeled n-trees {V1, E1, r1}, {V2, E2, r2} are said to be root isomor-
phic, if a bijection of V1 onto V2 exists that transforms edges in E1 onto E2 and maps

298
7. Symplectic Runge–Kutta Methods
r1 onto r2. A rooted n-trees ρτ is an equivalence class that comprises of a the rooted
labeled n-tree and all rooted labeled n-trees root-isomorphic to it. Fig. 1.4 is an exam-
ple of rooted tree.
Fig. 1.5 shows that there is only one unlabeled 3-tree for n = 3, τ31, which repre-
sents three different labeled trees denoted by (A, B, C). Each labeled tree represents
three rooted labeled trees denoted by lower case letter (a, b, · · ·). The 9 rooted labeled
trees can be classiﬁed into two rooted trees ρτ31, ρτ32. The tree τ31 at the last row
can be considered as the result of the identiﬁcation of ρτ31 with ρτ32. In general, trees
can be considered to be equivalent classes of rooted trees, because a root isomorphism
is an isomorphism. For each rooted tree ρτ, we denote α(ρτ) as the number of the
monotonic rooted labeled trees. The latter only allow so called monotonic rooted la-
belings where each vertex is labeled using an integer number (≤n) smaller than all
its sons.
R 
◦
◦
◦
i +
j
k

R

◦
◦
◦
◦
i +
l
j
k
+
s
+
◦
◦
◦
◦
l
k
j
i
+
Fig. 1.4.
A rooted tree
Unless otherwise speciﬁed, it is assumed that the set of vertices of a labeled n
graph is always {1, 2, · · · , n}. In order to clarify the above four types of trees, we use
Fig. 1.5 to illustrate.
(+)1-2-3 1-(+)2-3 1-2-(+)3 (+)3-1-2 3-(+)1-2 3-1-(+)2 (+)2-3-1 2-(+)3-1 2-3-(+)1
a
b
c
d
e
f
g
h
i
A
B
C
τ31
⃝
⃝
⃝
1
2
3
3
1
2
2
3
1
◦
◦
◦
ρτ31
◦
◦
◦
ρτ32
◦
◦
◦
τ31
(nolabeled 3-tree)
(rooted 3-tree)
(rooted labeled 3-tree)
(labeled 3-trees)
(nolabeled 3-tree)
Fig. 1.5.
The 3-tree, labeled 3-trees (A) −(C), rooted labeled 3-tree (a) −(i), and rooted
3-tree

7.1 Multistage Symplectic Runge–Kutta Method
299
ρτ11
•+
τ11
•
ρτ21
•+
•
τ21
• •
Fig. 1.6.
Rooted n-tree (n=1,2)
ρ τ31
•
•
•+
ρτ32
•+
•
•
τ31
•
•
•
ρτ41
•
•
•
•+
ρτ42
•+
• •
•
τ41
•
•
•
•
1
2
3
4
ρτ43
•
•
•
•+
ρτ44
•+
• •
•
τ42
•
•
•
•
Fig. 1.7.
Rooted n-tree (n=3,4)
⃝
k
⃝
i
⃝
m
⃝
p
⃝
o
⃝j
⃝
l
⃝n
•
•+ ρτi
•
•
•
•
•
•
•
•+
ρτI
•
•
•
•+
ρτJ
•
•
•
•
+
ρτj
•
•
•
•
•
•
Fig. 1.8.
4 rooted tree in Lemma 1.25
Superﬂuous trees. Let τ be an n-tree and choose one of its labelings λτ. This
labeling gives rise to n different rooted labeled trees ρλτ1, · · · , ρλτn, where ρλτi has
its root at the integer i (1 ≤i ≤n). If for each edge (i, j) in λτ, ρτi and ρτj represent
different rooted trees; then τ is called non-superﬂuous. Consider the 3-tree τ31 in

300
7. Symplectic Runge–Kutta Methods
Fig.1.5. When choosing the labeled 3-tree A, we see that for the edge 1-2, choosing 1
as the root leads to ρτ31, and choosing 2 as the root leads to ρτ32. For the edge 2-3,
choosing 2 as the root leads to ρτ32, and choosing 2 as the root leads to ρτ31. Therefore
τ31 is non-superﬂuous. One the other hand the 4-tree with labeling is superﬂuous (see
Fig. 1.6 and 1.7), since changing the root from 2 to the adjacent 3 does not result in
different rooted trees.
•
•
•
•
1
2
3
4
In order to simplify the order conditions for symplectic R–K,we need some lem-
mas. Before introducing the lemmas, let us ﬁrst look at Fig. 1.8: 4-rooted tree.
Look at ﬁrst rooted tree ρτi (i.e., root at i) and rooted tree ρτj. The root of the
rooted trees ρτI, ρτJ in Fig. 1.8 is at vertex i and j, they are removed edge joining i
and j in the top left-hand corner graph.
Lemma 1.25. With the above notations
1◦
1
γ(ρτi) +
1
γ(ρτj) =
1
γ(ρτI) ·
1
γ(ρτJ).
(1.54)
2◦
For the symplectic R–K method, weighted coefﬁcients of elementary differ-
ential satisfy
φ(ρτi) + φ(ρτj) = φ(ρτI)φ(ρτJ).
(1.55)
3◦
For order ≥(r −1), symplectic R–K method,
φ(ρτi) + φ(ρτj) =
1
γ(ρτi) +
1
γ(ρτj).
(1.56)
Therefore ρτi order conditions hold iff order conditions of ρτj hold.
Proof. By the deﬁnition of γ, we have
γ(ρτi) = rγ(ρτJ)γ(ρτI)
r(ρτI) ,
(1.57)
γ(ρτj) = rγ(ρτI)γ(ρτJ)
r(ρτJ) ,
(1.58)
where r(ρτI) and r(ρτJ) are the orders of ρτI and ρτJ. Then, insert r(ρτI) in formula
(1.57) and r(ρτJ) in formula (1.58) into r(ρτI)+r(ρτJ) = r to obtain (1.54). Rewrite
the left side of formula (1.55) into
φ(ρτi) + φ(ρτj) =

ij···
biaij
;
+

ij···
bjaij
;
,
(1.59)
where B represents a product of r −2 factors akl. Equality (1.55) can be obtained
using order condition (1.15) of the symplectic R–K method.
▲
Example 1.26. See the simple examples below. From Fig. 1.8 we have

7.1 Multistage Symplectic Runge–Kutta Method
301
φ(ρτ v) =

vw1···4
bivaiviwaivi1aivi2aiwi3aiwi4,
φ(ρτ w) =

vw1···4
biwaiwivaiwi3aiwi4aivi1aivi2.
•v
•1
•2
•w
• 3
•4
From Fig.1.8 we have
φ(ρτv) =

v12
bivaivi1aivi2,
•v
•1
•2
φ(ρτw) =

w34
biwaiwi3ai3i4.
• w
• 3
• 4
Theorem 1.27. [SA91] Assume that a symplectic R–K method satisﬁes the order con-
ditions for order ≥(r −1) with (r ≥2). Then, to ensure that the method to have
order ≥r, it is sufﬁcient that, for each non-superﬂuous tree τ with r vertices, there is
one rooted tree ρτ associated with τ for which
φ(ρτ) =
1
γ(ρτ).
(1.60)
Proof. Choose ﬁrst a non-superﬂuous tree τ. Assume that condition (1.60) is satisﬁed
for a suitable rooted tree ρτi of τ. From the Lemma 1.25 we choose j as any of the
vertices adjacent to i. By condition (1.56), the order condition (1.60) is also satisﬁed
for ρτj. Since any two vertices of a tree can be joined through a chain of pairwise
adjacent vertices, the iteration of this argument leads to the conclusion that the method
satisﬁes the order conditions that arise from any rooted tree in τ. In the case of a
superﬂuous tree τ , by deﬁnition, it is possible to choose adjacent vertices i, j, such
that ρτi and ρτj are in fact the same rooted tree. Then condition (1.56) shows that
(1.60) holds for the rooted tree ρτi. Therefore (1.60) holds for all rooted tree in τ. ▲
Example 1.28. For r = 2, there is only one tree τ21, this is a superﬂuous tree.
Example 1.29. For r = 3, there is again only one tree τ31. It has two rooted trees
ρτ31, ρτ32. Hence the order conditions become
3

i,j,k=1
biaijaik = 1
3,
or
3

i,j,k=1
biaijajk = 1
6.
Example 1.30. For r = 4, there is only one non-superﬂuous tree τ42. We impose
either the order conditions for ρτ43 or the order conditions for ρτ44.
We see that for symplectic R–K methods it is sufﬁcient to obtain the order con-
ditions only for non-superﬂuous trees rather than every rooted trees. The reduction
in the number of order conditions is given in Table 1.5. Comparison order conditions
between symplectic R–K (R–K–N) method.

302
7. Symplectic Runge–Kutta Methods
Table 1.5.
Order conditions between symplectic R–K (R–K–N) method
Order
R–K method
symp. R–K method
R–K–N method
symp. R–K–N method
1
1
1
1
1
2
2
1
2
2
3
4
2
4
4
4
8
3
7
6
5
17
6
13
10
6
37
10
23
15
7
85
21
43
25
8
200
40
79
39
Example 1.31. For diagonally symplectic R–K method, see tableau (1.16).
If r = 3, according to Theorem 1.27 and Table 1.5, symplectic R–K method has
only two conditions. One condition is for r = 1,
b1 + b2 + b3 = 1.
(1.61)
another condition is for r = 3, which has only one non-superﬂuous tree with two
rooted trees, ρτ31, ρτ32. Choose one of them
r(ρτ31)φ(ρτ31) = 1,
3

i=1
bic2
i = 1
3,
After simplifying, we obtain
b3
1 + b3
2 + b3
3 = 0.
(1.62)
Since we have two equations with three unknowns, one of which can be freely
chosen, for example:
b1 = b3 =
1
2 −
3√
3,
b2 =
−
3√
2
2 −
3√
3
see (1.20).
(1.63)
7.2 Symplectic P–R–K Method
In this section we study symplectic Partitioned–Runge–Kutta method(P–R–K method).
7.2.1 P–R–K Method
In this subsection we focus on a class of special Hamiltonian system i.e., separable
systems:
H(p, q) = u(p) + v(q).
(2.1)
Its corresponding Hamiltonian equations are
⎧
⎪
⎨
⎪
⎩
d p
d t = −vq(q) = f(q),
d q
d t = up(p) = g(p).
(2.2)

7.2 Symplectic P–R–K Method
303
Let us suppose that the component p of the ﬁrst set of system (2.2) are integrated by
an R–K method and the component q in second part of system are integrated with
a different R–K method. The overall scheme is called a Partitioned– Runge–Kutta
method, or shortly called P–R–K method. It can be speciﬁed by two Butcher tableaux:
c1
...
cs
a11
· · ·
a1s
...
...
...
as1
· · ·
ass
b1
· · ·
bs
C1
...
Cs
A11
· · ·
A1s
...
...
...
As1
· · ·
Ass
B1
· · ·
Bs
(2.3)
The application of (2.3) to the system (2.2) results in
⎧
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎩
Pi = pn + h
s

j=1
aijf(Qj),
Qi = qn + h
s

j=1
Aijg(Pj),
pn+1 = pn + h
s

i=1
bif(Qi),
qn+1 = qn + h
s

i=1
Big(Pi).
i = 1, · · · , s,
(2.4)
These tableaux are coefﬁcients of P–R–K method.
Theorem 2.1. If coefﬁcients of P–R–K (2.4) satisﬁes the following conditions:
M = biAij + Bjaji −biBj = 0,
i, j = 1, · · · , s
(2.5)
then this P–R–K method is symplectic[AS93,Sur90,Sun93b,SSM92].
Proof. Let
Ki = f(Qi),
li = g(Pi),
(2.6)
and
d pn+1 ∧d qn+1 −d pn ∧d qn
= h
s

i=1

bid Ki ∧d Qi + Bid Pi ∧d li

−h2
s

i,j=1
(biAij + Bjaji −biBj)d Ki ∧d lj.
(2.7)
Note that the ﬁrst term on the right side of Equation (2.7) is

304
7. Symplectic Runge–Kutta Methods
bid Ki ∧d Qi + Bid Pi ∧d li
=
s

i,j=1
−vqqd Qi ∧d Qj + uppd Pi ∧d Pj = 0.
In order to satisfy the equality (2.5), it is sufﬁcient to make
biAij + Bjaji −biBj = 0.
Therefore, the theorem is completed.
▲
W-transformation (deﬁned below) proposed by Hairer and Wanner in 1981 has
the intention of simplifying the order condition C(·) and D(·), as well as their re-
lationship. Through the W- transformation, it is easy to construct higher order R–K
method[HW81]. Let us suppose polynomials pi (0 ≤i ≤(s −1)), are orthogonal to the
following inner product
(p, q) =
s

i=1
bip(ci)q(ci),
introducing matrix
W =
⎡
⎢⎢⎢⎢⎢⎣
p0(c1)
p1(c1)
· · ·
ps−1(c1)
p0(c2)
p1(c2)
· · ·
ps−1(c2)
· · ·
· · ·
· · ·
· · ·
p0(cs)
p1(cs)
· · ·
ps−1(cs)
⎤
⎥⎥⎥⎥⎥⎦
,
by the orthogonality of pi (i = 1, · · · , s −1), we have
W TBW = I.
We take pk(x) as a standard shifted Legendre polynomial, deﬁned by
pk(x) =
√
2k + 1
k

i=0
(−1)k+i k
i
 k + i
i

xi,
k = 0, 1, · · · , s −1.
For an s-stage R–K method (A, b, c), let X = W −1AW = W TBAW, then for the
high order R–K method based on the high order quadrature formula their transforma-
tion matrix X is given by Table 2.1[Sun93a,Sun94,Sun95].

7.2 Symplectic P–R–K Method
305
Table 2.1.
Matrix X form
method
Xs,s−1
Xs−1,s
Xs,s
symplectic
Gauss
ξs−1
−ξs−1
0
yes
Lobatto III A
ξs−1u
0
0
no
Lobatto III B
0
−ξs−1u
0
no
Lobatto III C
ξs−1u
−ξs−1u
u2
2(2s −1)
no
Lobatto III S
ξs−1uσ
−ξs−1uσ
0
yes
Radau I A
ξs−1
−ξs−1
1
4s −2
no
Radau II A
ξs−1
−ξs−1
1
4s −2
no
Radau I B
ξs−1
−ξs−1
0
yes
Radau II B
ξs−1
−ξs−1
0
yes
For the Gauss–Legendre method
XGL =
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎢⎢⎣
1
2
−ξ1
ξ1
0
−ξ2
O
ξ2
...
...
...
...
...
O
...
...
−ξs−1
ξs−1
0
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎥⎥⎦
,
where ξk =
1
2
√
4k2 −1 (k = 0, 1, · · · , s −1).
Corollary 2.2. If coefﬁcients of
P–R–K method satisfy bi = Bi, ci = Ci, ci and
bi ̸= 0 (i = 1, · · · , s), and
W TMW = X + X
T −e1eT
1 ,
then P–R–K method is symplectic.
Corollary 2.3. (Sun)[Sun93b] Given a s-stage R–K method and its coefﬁcients (A, b, c).
If the coefﬁcients ci, bi ̸= 0 (i = 1, · · · , s) satisfy order conditions of R–K method
B(p), C(η) and D(ζ), then the
P–R–K method produced by the coefﬁcient of
aij, ¯aij = bj

1 −aji
bi

, bi, ci is symplectic with order r = min (p, 2η + 2, 2ζ +
2, η + ζ + 1).
Corollary 2.4. Method of Radau IA has order 2s −1, by Corollary 2.3, method of
Radau IA and Radau I A is symplectic with order 2s −1.
Example 2.5. P–R–K method with ﬁrst order accuracy Radau IA–I A
0
1
1
0
0
1
=⇒
1
2
1

306
7. Symplectic Runge–Kutta Methods
Example 2.6. P–R–K method with third order accuracy Radau I A – IA
0
1
4
−1
4
2
3
1
4
5
12
1
4
3
4
0
0
0
2
3
1
3
1
3
1
4
3
4
=⇒
1
8
−1
8
7
24
3
8
1
4
3
4
Corollary 2.7. Constructs symplectic P–R–K method Radau II A – Radau II A with
the similar method.
Example 2.8. P–R–K method with ﬁrst order accuracy Radau II A – Radau II A
1
1
1
1
0
1
=⇒
1
2
1
Example 2.9. P–R–K method with third order accuracy Radau II A – Radau II A
1
3
5
12
−1
12
1
3
4
1
4
3
4
1
4
1
3
1
3
0
1
1
0
3
4
1
4
=⇒
3
8
−1
24
7
8
1
8
3
4
1
4
Corollary 2.10. Using same method constructed symplectic P–R–K method Lobatto
III C – III C with 2s −2 order accuracy.
Example 2.11. Symplectic P–R–K Lobatto III C–III C method with 2 order accuracy,
its coefﬁcients are
0
1
2
−1
2
1
1
2
1
2
1
2
1
2
0
0
0
1
1
0
1
2
1
2
=⇒
1
4
−1
4
3
4
1
4
1
2
1
2
Example 2.12. Symplectic P–R–K Lobatto III C – III C method, its coefﬁcients are

7.2 Symplectic P–R–K Method
307
0
1
6
−1
3
1
6
1
2
1
6
5
12
−1
12
1
1
6
2
3
1
6
1
6
2
3
1
6
0
0
0
0
1
2
1
4
1
4
0
1
0
1
0
1
6
2
3
1
6
=⇒
1
12
−1
6
1
12
5
24
4
12
−1
24
1
12
5
6
1
12
1
6
2
3
1
6
Corollary 2.13. The s-stage P–R–K Lobatto III A–III B method is symplectic with
2s −2 order accuracy.
Example 2.14. Symplectic P–R–K Lobatto III A–III B method, its coefﬁcients are
0
0
0
1
1
2
1
2
1
2
1
2
0
1
2
0
1
1
2
0
1
2
1
2
=⇒
1
4
0
1
2
1
4
1
2
1
2
0
0
0
5
24
1
3
−1
24
1
6
2
3
1
6
1
6
2
3
1
6
1
6
−1
6
0
1
6
1
3
0
1
6
5
6
0
1
6
2
3
1
6
=⇒
1
12
−1
12
0
2
16
1
3
−1
48
1
6
2
12
1
12
1
6
2
3
1
6
With the help of symplectic conditions of P–R–K methods, we can construct sym-
plectic R–K method. We have the following corollary:
Corollary 2.15. [Sun][Sun00] The s-stage R–K method with coefﬁcients a∗
ij = 1
2(aij +
Aij), b∗
i = bi = Bi and c∗
i = ci are symplectic and at least satisfy B(p), C(ξ) and
D(ξ), i.e., order
r = min(p, 2ξ + 1),
where
ξ = min (η, ζ).
Example 2.16. If we take the coefﬁcients in Example 2.14, we know that the right of
the table is a special case of 2-order accuracy of R–K methods of Lobatto III S

i.e.,
σ = 1
2 situation of literature [Chi97], see Table 2.1

.
7.2.2 Sympliﬁed Order Conditions of Explicit Symplectic R–K
Method
The following s-stage scheme is well-known[ZQ95b]

308
7. Symplectic Runge–Kutta Methods
pi = pi−1 + cihf(qi−1),
qi = qi−1 + dihg(pi),
i = 1, 2, · · · , s,
(2.8)
where f = −vq(q), g = up(p). We can regard f, g as a function of z = (p, q), for f
(or g) with the p (or q) variables of coefﬁcient 0, i.e., f(q, 0 · p) (or g(p, 0 · q). In order
to facilitate the writing in a uniﬁed form, we make:
p = ya,
q = yb,
f = fa,
g = fb,
ya,0 = p0,
yb,0 = q0,
and ya,1 = ps−1, yb,1 = qs−1, then Equation (2.8) is transformed into an s-stage
P–R–K form:
g1,a = ya,0 = p0,
g1,b = yb,0 = q0,
g2,a = ya,0 + c1τfa(q0) = ya,0 + c1hfa(g1,b) = p1,
g2,b = yb,0 + d1τfb(p1) = yb,0 + d1hfb(g2,a) = q1,
...
gs,a = ya,0 + h
s−1

j=1
cjfa(gj,b) = ps−1,
gs,b = yb,0 + h
s−1

j=1
djfb(gj+1,a) = qs−1.
(2.9)
(2.9) is equivalent to
gi,a = ya,0 + h
i−1

j=1
cjfa(gj,b),
gi,b = yb,0 + h
i−1

j=1
djfb(gj+1,a),
i = 2, · · · , s,
ya,1 = ya,0 + h
s−1

j=1
cjfa(gj,b),
yb,1 = yb,0 + h
s−1

j=1
djfb(gj+1,a).
(2.10)
And (2.2) can be rewritten with new variables as
5
˙ya
˙yb
6
=
5
fa(yb)
fb(ya)
6
.
(2.11)
Let
a1 = c1,
a2 = c2,
· · · ,
as−1 = cs−1,
as = 0,
b1 = 0,
b2 = d1,
· · · ,
bs−1 = ds−2,
bs = ds−1,
(2.12)
then schemes (2.10) now become

7.2 Symplectic P–R–K Method
309
gi,a = ya,0 + h
i−1

j=1
ajfa(gj,b) = ya,0 + h
i−1

j=1
ajRj,a,
gi,b = yb,0 + h
i

j=1
djfb(gj,a) = yb,0 +
i

j=1
bjRj,b,
i = 2, · · · , s,
ya,1 = ya,0 + h
s

j=1
ajRj,a,
yb,1 = yb,0 + h
s

j=1
bjRj,b.
(2.13)
Where
Ri,a = fa(gi,b),
Ri,b = fb(gi,a).
(2.14)
Now, we just need to study the order conditions of scheme (2.13) when as = b1 = 0.
Notice that as = b1 = 0 is necessary for (2.13) to be canonical and is also crucial for
simplifying order conditions, as we will see later.
A P-graph (denoted by PG) is a special graph which satisﬁes the following con-
ditions: (i) its vertices are divided into two classes: “white” ◦“black” •, sometimes
instead “meagre” and “fat”. (ii) the two adjacent vertices of a PG cannot be of the
same class. If we give the vertices of PG an arbitrary set of labels, we get a label P-
graph, and we say P-graph∈PG. Two labeled P-graphs are said to be isomorphic
labeled P-graphs if they are just two different labelings of the same P-graph.
A simple path joins a pair of vertices v and w, v ̸= w, and is a sequence of pairwise
distinct vertices v = v0, v1, · · · , vn−1 = w, where vi ̸= vi−1, (vi−1, vi) ∈E. Fig.
2.1 shows an example of a simple path of v and w for n = 4.
◦
◦
◦
Fig. 2.1.
A simple path of v and w black • and white ◦, for n=4
(1)
The deﬁnition of a P-tree Pτ, a labeled P-tree (denoted by λPτ), a rooted
labeled P-tree ρλPτ of the same order n are just as that of tree τ, labeled by tree λτ,
rooted tree ρτ, and rooted labeled tree ρλτ, where the general graph is substituted by
the P-graph.
(2)
We deﬁne the isomorphism of two labeled P-trees below. Generally tree’s
isomorphism and the P-tree’s isomorphism are all in accordance with the type of
labeling used. This has been described before. Here we give the precise deﬁnition for
a P-tree.
Two labeled P-trees {V1, E1} and {V2, E2} are called isomorphism, if the order
of these tree is the same, and there exists a bijection mapping χ, from V1 to V2 and E1
to E2 satisﬁes

310
7. Symplectic Runge–Kutta Methods
K(χ(v1)) = K(v1),
where v1 ∈V1, and
K(v) =

1,
for v black,
0,
for v white.
A P-tree (n order) is the equivalent of such a class, it consists of a labeled P-tree and
all of its isomorphism. We use [HNW93] the P-series and tree method to derive the order
condition of Equation (2.13) below. We ﬁrst introduce some deﬁnitions and notations.
(3)
Two rooted labeled P-trees with same order, {V1, E1, r1} and {V2, E2, r2}
(where ri (i = 1, 2) denoted rooted label), are called rooted isomorphism if there
exists a χ that satisﬁes the condition of (2), and χ(r1) = r2 holds.
A rooted P-tree, denoted by ρPτ, is an equivalence class which contains a labeled
P-tree and all of its isomorphic P-trees. We denote ρPτa(ρPτb) as ρPτ with white
(black) root, and ρλPτ as rooted labeled P-tree, which is obtained by adding label to
ρPτ. Thus ρλPτ ∈ρPτ.
We denote by ρPτa (resp. ρPτb ) for a rooted P-tree ρPτ that has a white (resp.
black) root. If we give the vertices of a rooted P-tree ρPτ such a set of labels so
that the label of a father vertex is always smaller than that of its sons, we then get a
monotonically labeled rooted P-tree MρλPτ. We denote by α(ρPτ) the number of
possible different monotonic labelings of ρPτ when the labels are chosen from the set
Aq = { the ﬁrst q letters of i < j < k < l < · · ·}, where q is the order of ρPτ.
The set of all rooted trees of order n with a white (resp. black) root is denoted by
TP a
n (resp. TP b
n). Let us denote by λPτ a
n (resp. λPτ b
n) the set of all rooted labeled
P-trees of order n with a white (resp. black) root vertex, and MλPτ a
n (resp. MλPτ b
n)
the set of all monotonically labeled P-tree of order n with a white (resp. black) root
vertex when the labels are chose from the set An.
(4)
The density γ(ρλτ) of a rooted P-tree ρλτ is deﬁned recursively as
γ(ρλτ) = r(ρλτ)γ(ρλτ 1) · · · γ(ρλτ m),
where r(ρλτ) is order of ρλτ, and ρλτ 1, · · · , ρλτ m are the sub-trees which arise when
the root of ρλτ is moved from the tree. The density of rooted P-tree ρPτ is calculated
by regarding them as general rooted tree neglecting the difference between with the
black and white vertices .
(5)
Let ρPτ 1, · · · , ρPτ m be rooted P-tree. We denote by ρPτ = a[ρPτ 1, · · · ,
ρPτ m] the unique rooted P-tree that arises when the roots of ρPτ 1, · · · , ρPτ m are
all attached to a white root vertex. Similarly denote it by b[ρPτ 1, · · · , ρPτ m] when
the root of the P-tree is black. We say ρPτ 1, · · · , ρPτ m are sub-trees of ρPτ. We
further denote the rooted P-tree of order 1, which has a white (resp.black) root vertex
by ta(resp.tb).
(6)
(2.11) is deﬁned recursively as:
F(ta)(y) = fa(y),
F(tb)(y) = fb(y),
F(ρPτ)(y) =
∂mfw(ρP t)(y)
∂yw(ρP τ 1) · · · ∂yw(ρP τ m)

F(ρPτ 1)(y) · · · F(ρPτ m)(y)

, (2.15)

7.2 Symplectic P–R–K Method
311
where y = (ya, yb), and ρPτ = a[ρPτ 1, · · · , ρPτ m] or ρPτ = b[ρPτ 1, · · · , ρPτ m],
and w(ρPτ) is deﬁned by:
w(ρPτ) =
 a,
if ρPτ attached to a white root vertex,
b,
if ρPτ attached to a black root vertex.
We see that F(ρPτ) is independent of labeling. Here, and in the remainder of this
book, in order to avoid sums and unnecessary indices, we assume that ya and yb are
scalar quantities , and fa,fb scalar functions. All subsequent formulas remain valid for
vectors if the derivatives are interpreted as multi-linear mapping.
Lemma 2.17. The derivatives of the exact solution of (2.11) satisfy:
y(a)
a
=

ρλP τ∈MλT P a
q
F(ρλPτ)(ya, yb) =

ρP τ∈T P a
q
α(ρPτ)F(ρPτ)(ya, yb),
y(a)
b
=

ρλP τ∈MλT P b
q
F(ρλPτ)(ya, yb) =

ρP τ∈T P b
q
α(ρPτ)F(ρPτ)(ya, yb),
(2.16)
where q = 1, 2, · · ·.
It is convenient to introduce two new rooted P-trees of order 0: ∅a and ∅b. The
corresponding elementary differential are F(∅a) = ya, F(∅b) = yb.
We further set
TP a = ∅a ∪TP a
1 ∪TP a
2 ∪· · · ,
TP b = ∅b ∪TP b
1 ∪TP b
2 ∪· · · ,
λTP a = ∅a ∪λTP a
1 ∪λTP a
2 ∪· · · ,
λTP b = ∅b ∪λTP b
1 ∪λTP b
2 ∪· · · ,
MλTP a = ∅a ∪MλTP a
1 ∪MλTP a
2 ∪· · · ,
MλTP b = ∅b ∪MλTP b
1 ∪MλTP b
2 ∪· · · .
(2.17)
p-series: let c(∅a), c(∅b), c(ta), c(tb), · · · be real coefﬁcients deﬁned for all P-
trees, c : TP a ∪TP b →R. The series p(c, y) = (pa(c, y), pb(c, y))
is deﬁned
as
pa(c, y)
=

ρλP τ∈MλT P a
hr(ρλP τ)
r(ρλPτ)!c(ρλPτ)F(ρλPτ)(y)
=

ρP τ∈T P a
α(ρPτ)hr(ρλP τ)
(ρλPτ)! c(ρλPτ)F(ρλPτ)(y),
pb(c, y)
=

ρλP τ∈MλT P b
hr(ρλP τ)
(ρλPτ)! c(ρλPτ)F(ρλPτ)(y)
=

ρP τ∈T P b
α(ρPτ) hr(ρλP τ)
r(ρλPτ) !c(ρλPτ)F(ρλPτ)(y).
(2.18)

312
7. Symplectic Runge–Kutta Methods
Notice that c is deﬁned on TP a∪TP b, and for any labelings of ρPτ (especially for
monotonic labeling ρλPτ), we have c(ρλPτ) = c(ρPτ). Lemma 2.17 states simply
that the exact solution is a p-series,

ya(t0 + h), yb(t0 + h)
T = p

Y, ya(t0), yb(t0)

,
where Y (ρPτ) = 1 for all rooted P-trees ρPτ. The following theorem is from the
book[HNW93].
Theorem 2.18. Let c : TP a ∪TP b →R, be a sequence of coefﬁcients such that
c(∅a) = c(∅b) = 1. Then
h
 fa

p(c, (ya, yb))

fb

p(c, (ya, yb))


= p

cT, (ya, yb)

,
with
cT(∅a) = cT(∅b) = 0,
cT(ta) = cT(tb) = 1,
cT(ρPτ) = r(ρPτ)c(ρPτ 1) · · · c(ρPτ m),
ρPτ = a[ρPτ 1, · · · , ρPτ m],
or
ρPτ = b[ρPτ 1, · · · , ρPτ m].
Let
⎧
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎩
Ri,a = pa

Ki, (ya,0, yb,0)

,
Ri,b = pb

Ki, (ya,0, yb,0)

,
gi,a = pa

Gi, (ya,0, yb,0)

,
gi,b = pb

Gi, (ya,0, yb,0)

,
i = 1, · · · , s,
(2.19)
where Ki (i = 1, · · · , s) : TP a ∪TP b →R, Gi (i = 1, · · · , s) : TP a ∪TP b →R
are two sets of p-series. From (2.10), we have Gi(∅a) = Gi(∅b) = 1. Hence, From
(2.14), we have
p

Ki, (ya,0, yb,0)

=
 pa

Ki, (ya,0, yb,0)

pb

Ki, (ya,0, yb,0)

!
=
 Ri,a
Ri,b
!
= h
 fa(gi,b)
fb(gi,a)
!
= h
 fa

pb

Gi, (ya,0, yb,0)

fb

pa

Gi, (ya,0, yb,0)

!
= h
 fa

p

Gi, (ya,0, yb,0)

fb

p

Gi, (ya,0, yb,0)

!
= p

G′
i, (ya,0, yb,0)

.
Then from Theorem 2.18, we get
Ki = G′
i,
∀i = 1, · · · , s.
But from (2.13), we have

7.2 Symplectic P–R–K Method
313
p

Gi, (ya,0, yb,0)

=
 pa

Gi, (ya,0, yb,0)

pb

Gi, (ya,0, yb,0)

!
=
⎡
⎢⎢⎢⎢⎢⎣
ya,0 + h
i−1

j=1
ajRj,a
yb,0 + h
i

j=1
bjRj,b
⎤
⎥⎥⎥⎥⎥⎦
=
⎡
⎢⎢⎢⎢⎢⎣
ya,0 + h
i−1

j=1
ajpa

Kj, (ya,0, yb,0)

yb,0 + h
i

j=1
bjpb

Kj, (ya,0, yb,0)

⎤
⎥⎥⎥⎥⎥⎦
.
Thus:
Gi(ρPτa) =
i−1

j=1
ajKj(ρPτa),
Gi(ρPτb) =
i

j=1
bjKj(ρPτb),
∀r(ρPτ) ≥1.
(2.20)
From (2.13), we also have
ya,1 = ya,0 + h
s

i=1
pa

Ki, (ya,0, yb,0)

,
yb,1 = yb,0 + h
s

i=1
pb

Ki, (ya,0, yb,0)

.
(2.21)
Comparing the numerical solution obtained from (2.13) and the exact solution from
(2.11), we get the order condition for scheme (2.13).
Theorem 2.19. Scheme (2.13) is p-order accuracy iff its coefﬁcients ai, bi satisfy:
⎧
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎩
s

i=1
aiKi(ρPτa) = 1,
1 ≤r(ρPτa) ≤p,
s

i=1
biKi(ρPτb) = 1,
1 ≤r(ρPτb) ≤p,
(2.22)
where Ki (i = 1, · · · , s) are deﬁned recursively by
⎧
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎩
Ki = G′
i,
Gi(∅a) = Gi(∅b) = 1,
Gi(ρPτa) =
i−1

j=1
ajKj(ρPτa),
Gi(ρPτb) =
i

j=1
bjKj(ρPτb),
r(ρPτa), r(ρPτb) ≥1.
(2.23)
From the ﬁrst and second equations of (2.23) we know Ki(∅a) = Ki(∅b) =
0, Ki(ta) = Ki(tb) = 1, from the last two equations of (2.23) we can obtain
Gi(ta), Gi(tb). Repeating this procedure, we can obtain Ki(ρPτa), Ki(ρPτb), by P-
tree order from low to high.

314
7. Symplectic Runge–Kutta Methods
Next we rewrite equations (2.23) into more intuitive forms. From (2.23), we have
⎧
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎩
Ki(ρPτa) = r(ρPτa)
*
i

j=1
bjKj(ρPτ 1
b )
+
· · ·
*
i

j=1
bjKj(ρPτ m1
b
)
+
,
Ki(ρPτb) = r(ρPτb)
*i−1

j=1
ajKj(ρPτ 1
a)
+
· · ·
*i−1

j=1
ajKj(ρPτ m2
a
)
+
,
i = 2, 3, · · · , s,
(2.24)
where
ρPτa = a[ρPτ 1
b , · · · , ρPτ m1
b
],
ρPτb = b[ρPτ 1
a, · · · , ρPτ m2
a
].
(2.25)
We now deﬁne elementary weight φ(ρPτ) for a rooted P-tree. Choose any labeling
ρλPτ for ρPτ; without loss of generality we choose a monotonic one with labels
i < j < k < l < · · ·, where the rooted labeling is i. Then φ can be obtained
recursively (Note the difference of solving for φ between the original tree and its sub-
tree)
⎧
⎪
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎪
⎩
φ(ρPτa) =
s−1

i=1
ai

φ(ρPτ 1
b ), · · · , φ(ρPτ m1
b
)

,
φ(ρPτb) =
s

i=1
bi

φ(ρPτ 1
a), · · · , φ(ρPτ m2
a
)

,
φ(∅a) = φ(∅b) = 1,
r(ρPτa), r(ρPτb) ≥1,
(2.26)
where ρPτa, ρPτb and (2.25) are the same. Here, notice that i is the root of ρPτa or
ρPτb, and s is the label for an imaginary father vertex to the root i. The summation is
always with respect to subscripts of the son’s vertex, from 1 adds to the father vertex
or it reduces by 1. Now s is order of scheme (2.13). We are doing this only for ease
of the recursive deﬁnition; otherwise vertex i has no father vertex and the summation
superscript cannot be determined. Regarding the subtrees of ρPτa, ρPτb, the father
vertex for their root labeling is i. It is not necessary to add an extra father vertex. So
the weight for a p-tree as the original tree is different from the weight as another subset
tree. By (2.26) we can see that the elementary weight of a tree φ is not related to its
labeling as long as the imaginary father of maintaining root label is always the order
of the scheme (2.13).
Theorem 2.20. [AS93,ZQ95b,SSC94] Order conditions in Theorem 2.19 are equivalent to
φ(ρPτ) =
1
γ(ρPτ),
∀ρPτ ∈TP a ∪TP b,
r(ρPτ) ≤p.
(2.27)
Proof. We just need to prove
⎧
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎩
φ(ρPλτa)γ(ρλPτb) =
s−1

j=1
ajKj(ρPτa),
φ(ρλPτb)γ(ρλPτa) =
s

j=1
bjKj(ρλPτb).
(2.28)

7.2 Symplectic P–R–K Method
315
From (2.23), we have
⎧
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎩
Ki(ρλP τa) = r(ρλP τa)
⎛
⎝
i

j1=1
bj1Kj1(ρλP τ 1
b )
⎞
⎠· · ·
⎛
⎝
i

jm1 =1
bjm1 Kjm1 (ρλP τ m1
b
)
⎞
⎠,
Ki(ρλP τb) = r(ρλP τb)
⎛
⎝
i−1

j1=1
ajm2 Kjm2 (ρλP τ 1
a)
⎞
⎠· · ·
⎛
⎝
i−1

jm2 =1
ajm2 Kjm2 (ρλP τ m2
a
)
⎞
⎠,
(2.29)
where i = 2, 3, · · · , s, and
ρλPτa = a[ρPτ 1
b , · · · , ρλPτ m1
b
],
ρλPτb = b[ρλPτ 1
a, · · · , ρλPτ m2
a
],
(2.30)
while j1, · · · , jm1 and j1, · · · , jm2 are the labels of the roots of ρλPτ 1
b , · · · , ρλPτ m1
b
and λPτ 1
a, · · · , ρλPτ m2
a
respectively. Due to
R.S. of(2.28) ⇐⇒
⎧
⎪
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎪
⎩
s−1

i=1
air(ρλP τa)
*
i

j1=1
bj1Kj1(ρλP τ 1
b )
+
· · ·
*
i

jm1 =1
bjm1 Kjm1 (ρλP τ m1
b
)
+
,
s

i=1
bir(ρλP τb)
*
i−1

j1=1
aj1Kj1(ρλP τ 1
a)
+
· · ·
*
i−1

jm2 =1
ajm2 Kjm2 (ρλP τ m2
a
)
+
,
L.S. of (2.28) ⇐⇒
⎧
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎩
s−1

i=1
air(ρλP τa)

φ(ρλP τ 1
b )γ(ρλP τ 1
b )

· · ·

φ(ρλP τ m1
b
)γ(ρλP τ m1
b
)

,
s

i=1
bir(ρλP τb)

φ(ρλP τ 1
a)γ(ρλP τ 1
a)

· · ·

φ(ρλP τ m2
a
)γ(ρλP τ m2
a
)

,
so we have to prove
φ(ρλPτ l
b)γ(ρλPτ l
b) =
i

jn=1
bjnKjn(ρPτ l
b)
for
n = 1, · · · , m1,
and
φ(ρPτ l
a)γ(ρPτ l
a) =
i−1

jn=1
ajnKjn(ρPτ l
a)
for
n = 1, · · · , m2.
Continue this process and ﬁnally we see it is enough to prove
φ(ta)γ(ta) =
f(l)−1

l=1
alKl(ta),
φ(tb)γ(tb) =
f(l)−1

l=1
blKl(tb),
(2.31)
where l is the label of ta or tb and f(l) is the label of the father. Since
φ(ta)γ(ta) =
f(l)−1

l=1
al · 1 =
f(l)−1

l=1
al · Kl(ta) =
f(l)−1

l=1
al,
φ(tb)γ(tb) =
f(l)

l=1
bl · 1 =
f(l)

l=1
bl · Kl(tb) =
f(l)

l=1
bl,
and
Kl(ta) = 1,
Kl(tb) = 1.
The theorem is proved.
▲

316
7. Symplectic Runge–Kutta Methods
Let Pτ be a tree of order p (p ≥2) P-tree. Choose any label to obtain λPτ. Let v
and w be two adjacent vertices. We consider four rooted P-tree . Denote ρPτ v(resp.
ρPτ w) as the rooted P-tree obtained by regarding the vertex v (resp.w) as the root of
ρPτ. Denote ρPτv (resp.ρPτw) the rooted P-tree, which arises when the edge (v, w)
is deleted from Pτ and has the root v (resp.w). Without loss of generality, let v be
white, and w be black.
Theorem 2.21. [AS93,ZQ95b,SSC94] With the above notations, we have:
1◦
1
γ(ρPτ v) +
1
γ(ρPτ w) =
1
γ(ρPτv)γ(ρPτw).
2◦
φ(ρPτ v) + φ(ρPτ w) = φ(ρPτv)φ(ρPτw), when as = b1 = 0.
Proof. By the deﬁnition of γ, we have
γ(ρPτ v) = nγ(ρPτw)γ(ρPτv)
r(ρPτv) ,
γ(ρPτ w) = nγ(ρPτv)γ(ρPτw)
r(ρPτw) .
Due to r(ρPτv) + r(ρPτw) = n, therefore
1
γ(ρPτ v) +
1
γ(ρPτ w) =
r(ρPτv)
nγ(ρPτw)γ(ρPτv) +
r(ρPτw)
nγ(ρPτw)γ(ρPτv)
=
1
γ(ρPτw)γ(ρPτv).
i.e., 1◦.
Also has
φ(ρPτ v)
=
s−1

iv=1
aiv
iv
;
1
iv

iw=1
biw
iw
;
2
,
φ(ρPτ w) =
s

iw=1
biw
iw
;
2
iw−1

iv=1
aiv
iv
;
1
,
where
iv
;
1

resp.
iw
;
2

is the product of all φ(ρPτ v)

resp. φ(ρPτ w)

, while
ρλPτa = a[ρPτ 1
b , · · · , ρλPτ m1
b
],
ρλPτb = b[ρλPτ 1
a, · · · , ρλPτ m2
a
],
and iv, iw are labels of v and w respectively.
iv
;
1

resp.
iw
;
2

varies only according to
iv, (resp. iw), therefore
φ(ρPτv) =
s−1

iv=1
aiv
iv
;
1
,
φ(ρPτw) =
s

iw=1
biw
iw
;
2
,

7.2 Symplectic P–R–K Method
317
then
φ(ρPτv)φ(ρPτw) =
s−1

iv=1
aiv
iv
;
1
s

iw=1
biw
iw
;
2
=
s−1

iv=1
aiv
iv
;
1

iv

iw=1
biw
iw
;
2
+
s

iw=iv+1
biw
iw
;
2

=
s−1

iv=1
aiv
iv
;
1
iv

iw=1
biw
iw
;
2
+
s−1

iv=1
aiv
iv
;
1
s

iw=iv+1
biw
iw
;
2
.
After manipulation, we can get
s−1

iv=1
aiv
iv
;
1
s

iw=iv+1
biw
iw
;
2
=
s

iw=2
biw
iw
;
2
iw−1

iv=1
aiv
iv
;
1
=
s

iw=1
biw
iw
;
2
iw−1

iv=1
aiv
iv
;
1
,
b1 = 0.
From this, 2◦holds.
▲
Corollary 2.22. Let scheme (2.13) be at least (p −1)-order, where p ≥2, then order
conditions
φ(ρPτ v) =
1
γ(ρPτ v)
satisﬁes, iff
φ(ρPτ w) =
1
γ(ρPτ w).
Proof. Because scheme (2.13) is at least (p −1)-order, by Theorem 2.20, we know
the following two relations hold:
φ(ρPτ v) =
1
γ(ρPτv),
φ(ρPτ w) =
1
γ(ρPτw).
By Theorem 2.21, we have
φ(ρPτ v) + φ(ρPτ w) =
1
γ(ρPτ v) +
1
γ(ρPτ w).
The corollary is obviously established.
▲
So far we draw the following conclusion for this section:
Theorem 2.23. [AS93,ZQ95b,SSC94] Symplectic scheme (2.13) (as = b1 = 0) is of p-
order, if and only if any of P-tree pτ, r(pτ) ≤p there is a rooted P-tree ρPτ ∈pτ,
such that
φ(ρPτ) =
1
γ(ρPτ).

318
7. Symplectic Runge–Kutta Methods
Proof. By Corollary 2.22, we know that any two kinds of rooted label method of the
Pτ lead to equivalent conditions. Therefore, we only need to take one of them to get
the order conditions.
▲
By Theorem 2.23, we simplify the order conditions. Originally, every rooted P-
tree has a corresponding order condition. Now every P-tree, no matter how different
the root is chosen, has a corresponding order condition. For the case of 4-order, the
number of order conditions reduces from 16 to 8, and the corresponding 8 P-trees are
as follows:
•
τa
τb
a[τb]
•
•
•
b[τa, τa]
•
b[τb, τb]
•
b[a[τb, τb]]
•
•
•
a[b[τa, τa]]
•
•
a[a[a[τb]]]
Fig. 2.2.
8 P-trees
Finally, according to Theorem 2.23, we can simplify the order conditions for
P–R–K method, which is given in Table 2.2. Calvo and Hairer[CH95] further reduce
the number of independent condition in P–R–K method. See Table 2.3. For general
Hamiltonian, the corresponding values are given by Table 2.4 which is obtained by
Mirua[Mur97].
Table 2.2.
Order conditions P–R–K method and Symplectic P–R–K method for separable
case
Order
P–R–K method
Symplectic P–R–K method
1
2
2
2
4
3
3
8
5
4
16
8
5
34
14
6
74
24
7
170
46
8
400
88

7.3 Symplectic R–K–N Method
319
Table 2.3.
Further reduction in Order conditions for P–R–K method in separable case
Order
P–R–K method
Symp. P–R–K method
expl. Symp. P–R–K method
1
2
1
1
2
2
1
1
3
4
2
2
4
8
3
3
5
18
6
6
6
40
10
9
7
96
22
18
8
230
42
30
Table 2.4.
Order conditions P–R–K method and Symplectic P–R–K method for general case
Order
P–R–K method
Symplectic P–R–K method
1
2
1
2
4
1
3
14
3
4
52
8
5
214
27
6
916
91
7
4116
350
8
18996
1376
7.3 Symplectic R–K–N Method
Symplectic Runge–Kutta–Nystr¨om method is abbreviated as symplectic R–K–N method.
The main purpose of this section is to develop and simplify the order conditions for R–
K–N methods, while the simpliﬁed order conditions for canonical R–K–N methods,
which are applied to special kind of ODE’s, are also obtained here. Then, using the
simpliﬁed order condition , we construct some 5 stage, ﬁfth-order symplectic R–K–N
schemes.
7.3.1 Order Conditions for Symplectic R–K–N Method
We consider a special kind of second order ODE’s:
¨yJ = f J(y1, y2, · · · , yn),
J = 1, · · · , n,
(y1, · · · , yn) ∈Rn.
(3.1)
We can transform (3.1) into a system of ﬁrst order ODE’s

320
7. Symplectic Runge–Kutta Methods
 
˙y
¨y
!
=
 
˙y
f(y)
!
,
(3.2)
by adding another group of variables ˙yJ (J = 1, · · · , n). Since canonical difference
schemes are meaningful only to Hamiltonian systems, we assume that (3.2) can be
written as
5
˙y
¨y
6
=
⎡
⎢⎣
∂H(y, ˙y)
∂˙y
−∂H(y, ˙y)
∂y
⎤
⎥⎦,
(3.3)
where H(y, ˙y) is scalar function that satisﬁes
⎧
⎪
⎨
⎪
⎩
∂H(y, ˙y)
∂˙y
= ˙y,
−∂H(y, ˙y)
∂y
= f(y).
So H must be in the form H = 1
2 ˙yT ˙y −u(y), ∂u
∂y = f(y). Therefore only when
f(g) is a gradient of some scalar function, its symplectic algorithm is meaningful. A
general s-stage R–K–N method can be written as
⎧
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎩
gi = y0 + cih ˙y0 + h2
s

j=1
aijf(gj),
i = 1, · · · , n,
y1 = y0 + h ˙y0 + h2
s

j=1
bjf(gj),
˙y1 = ˙y0 + h
s

j=1
bjf(gj).
(3.4)
The corresponding Butcher tableau is
c
A
b′
b′
c1
a11
· · ·
a1s
c2
a21
· · ·
a2s
...
...
· · ·
...
c3
as1
· · ·
ass
b1
· · ·
bs
b1
· · ·
bs
Theorem 3.1. If the coefﬁcients of scheme (3.4) satisfy
bj = bj(1 −cj),
1 ≤j ≤s,
(3.5)
biaij −bjaji + bibj −bibj = 0,
1 ≤i, j ≤s,
(3.6)
then scheme is symplectic[Sur90,Sur89,CS93,ZQ93].

7.3 Symplectic R–K–N Method
321
Proof. The proof of Theorem 3.1 can be ﬁnd in [Sur89,OS92]. Here, we only point out
that under conditions (3.5), (3.6) are equivalent to
biaij −bjaji + bibj(cj −ci) = 0,
1 ≤i, j ≤s.
(3.7)
Therefore, the theorem is completed.
▲
Similar to Section 7.1, we ﬁrst introduce some necessary deﬁnitions and notations,
and then derive order conditions. Some deﬁnitions of Section 7.1 can still be used.
Here we only introduce some special deﬁnitions and notations.
(1)
S-graph. A S-graph, denoted as S-g, is a special P-graph where any two
adjacent vertices belong to different categories: “ white (meagre)” or “ black (fat)”.
The Labeled S-graph has a deﬁnition similar to the labeled P-graph.
(2)
S-tree. A S-tree, denoted as Sτ, has a deﬁnition similar to the P-tree of
7.2: replacing the P-graph in the deﬁnition of original P-tree with S-graph gives the
deﬁnition of S-tree. The deﬁnition of labeled S- tree, λSτ, rooted S-tree, ρSτ, rooted
labeled S-tree, ρλSτ, and isomorphic labeled S-trees, root-isomorphic labeled S-tree
are deﬁned using the same method as we have used to deﬁne P-trees, labeled P-trees,
etc. We should point out that in this section, we just consider S-trees with “ black” root
vertices. So when we refer to rooted S-tree, we mean that its S-tree has a “ black” root.
Moreover, order r, density γ also has similar deﬁnition as mentioned in Section 7.1.
But the elementary weight deﬁnition is completely different, which we will redeﬁne
subsequently.
Deﬁnition 3.2. We deﬁne the elementary weight φ(ρλSτ) corresponding to a rooted
labeled S-tree. At ﬁrst, for convenience, we assume ρλSτ is monotonically labeled.
Later, we will see this is unnecessary. In the remainder of this section, without speci-
ﬁcation, the labels of the vertices are always j < k < l < m < · · ·. For a monotonic
labeling, the label of the root is j. Then φ(ρλSτ) is a sum over the labels of all fat
vertices of ρλsτ, the general term of the sum is a product of
1◦
bj (j is a rooted vertex).
2◦
akl, if the fat vertex k is connected via a meagre son with another fat vertex l.
3◦
cm
k , if the fat vertex k has m meagre end-vertices as its sons, where an end-
vertex is the vertex which has no son.
We see that, for two different rooted labeled S-trees: ρλSτ 1 and ρλSτ 2, we have
φ(ρλSτ 1) = φ(ρλSτ 2). Thus, the choosing of the monotonic labeling is unnecessary.
For example, for
•
k
•l
m
j
+
ρλSτ 1
and
•
m
•l
j
k
+
ρλSτ 2
, we have
φ(ρλSτ 1) =

j,m
bjcjajm =

j,k
bkakjck = φ(ρλSτ 2) = φ(ρSτ).
Because ρλSτ 1 and ρλSτ 2 are rooted isomorphism, they belong to a rooted tree ρSτ:
•
•
+ . Therefore, they form an equivalence class. The following theorem can be seen
in the literature [HNW93]. We omit the proof here.

322
7. Symplectic Runge–Kutta Methods
Theorem 3.3. P-K-N method (3.4) is order of p iff:
φ(ρSτ) =
1
γ(ρSτ), for rooted S-tree ρSτ, r(ρSτ) ≤p,
(3.8)
φ′(ρSτ) =
1
γ(ρSτ)(r(ρSτ) + 1), for rooted S-treeρλSτ, r(ρSτ) ≤(p −1). (3.9)
The explanation for φ′(ρSτ) is similar to that of φ(ρSτ), which only needs to sub-
stitute bj in φ(ρSτ) (suppose j is the label of rooted tree, corresponding to a certain
label choosing) by ¯bj. Because φ and φ′ is independent of the chosen label, (3.8) and
(3.9) can take any of the labels to calculate.
We ﬁnd that (3.8) and (3.9) are not independent under symplectic conditions.
Theorem 3.4. Under symplectic condition (3.5), order condition (3.8) implies condi-
tion (3.9)[ZQ95b].
Proof. Let ρSτ be ≤p −1 order S-tree, and let ρSu be such a rooted S-tree with
r(ρSτ) + 1 order that is obtained from ρSτ rooted tree by attaching a new branch
with a meagre vertex to the root of τ. Therefore from deﬁnition of φ, we have
φ(ρSu) =

j
bjcj
 ;
,
φ(ρSτ) =

j
bj
 ;
,
where we assume that ρSτ and ρSu have monotonic labels j < k < l < · · ·. Then for
ρSu, apart from the added root of the meagre leaf node, the remaining vertices have
the same labeling as ρSτ, and

is a sum for all non-fat root vertices, and
;
is a
product of aij and ci that are contained in ρSτ and ρSu. From the deﬁnition of φ, we
have
γ(ρSu) = (r(ρSτ) + 1)γ(ρSτ)
r(ρSτ)
,
therefore,
φ′(ρSτ) =

j
bj
 ;
=

j
bj(1 −cj)
 ;
=

j
bj
 ;
−

j
bjcj
 ;
= φ(ρSτ) −φ(ρSu)
=
1
γ(ρSτ) −
1
γ(ρSu) =
1
(r(ρSτ) + 1)γ(ρSτ).
(3.10)
Since the formula(3.8) is held for ≤p-order S-tree and (3.9) is held only for
≤p −1-order S-tree, the order of the tree obtained by adding a leaf node to any
≤p −1-order tree on the root must be ≤p and (3.8) must be satisﬁed. Therefore the
ﬁnal equal sign in (3.10) holds. Thus we reach the conclusion of this section.
▲
Theorem 3.5. R–K–N method (3.4) is symplectic, and is of p-order iff:

7.3 Symplectic R–K–N Method
323
biaij −bjaji + bibj(cj −ci) = 0,
1 ≤i, j ≤s,
(3.11)
¯bi = bi(1 −ci),
1 ≤i ≤s,
(3.12)
φ(ρSτ) =
1
γ(ρSτ)
for rooted S-tree ρSτ, r(ρSτ) ≤p.
(3.13)
Note that the conditions we have given here are necessary and sufﬁcient. How-
ever some conditions of (3.13) are still redundant, which means some conditions are
mutually equivalent. We will see more details about this in Section 7.4.
7.3.2 The 3-Stage and 4-th order Symplectic R–K–N Method
For convenience, we construct only explicit schemes here[QZ91]. Suppose the parame-
ters aij of a R–K–N method to be a matrix A
A =
⎡
⎢⎢⎢⎢⎢⎣
0
0
· · ·
0
0
a21
0
· · ·
0
0
a31
a32
· · ·
0
0
...
...
...
...
as1
as2
· · ·
as,s−1
0
⎤
⎥⎥⎥⎥⎥⎦
.
By the symmetry of Equations (3.11) in Theorem 3.5, we have
biaij −bjaji + bibj(cj −ci) = 0 ⇐⇒bjaji −biaij + bjbi(ci −cj) = 0,
hence Equations (3.11) can be simpliﬁed into
biaij −bjaji + bibj(cj −ci) = 0,
1 ≤j < i ≤s.
Since when j < i, aji = 0, the above formula can be written as
biaij + bibj(cj −ci) = 0,
1 ≤j < i ≤s.
For conditions of 3-stage of 3rd-order R–K–N method, we get equations for parame-
ters :
⎧
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎩
b2a21 + b2b1(c1 −c2) = 0,
b3a31 + b3b1(c1 −c3) = 0,
b3a32 + b3b2(c2 −c3) = 0,
b1 + b2 + b3 = 1,
b1c1 + b2c2 + b3c3 = 1
2,
b1c2
1 + b2c2
2 + b3c2
3 = 1
3,
b2a21 + b3a31 + b3a32 = 1
6,
(3.14)
and
bi = bi(1 −ci),
i = 1, 2, 3.
(3.15)

324
7. Symplectic Runge–Kutta Methods
Direct veriﬁcation shows
A =
⎡
⎢⎢⎢⎣
0
0
0
7
36
0
0
0
−1
2
0
⎤
⎥⎥⎥⎦,
b1 = 7
24,
b2 = 3
4,
b3 = −1
24,
c1 = c3 = 0,
c2 = 2
3
is a set of solutions for system (3.14).
The number of order conditions becomes 7 for a scheme of order 4. In addition,
if the scheme is of 3-stage, there are 3 equations for canonicity. Therefore we have
a total of 10 equations with 9 unknown variables (systems (3.14) plus parameters
¯bi (i = 1, 2, 3)). So we ﬁrst construct a 4-stage scheme of 4th order, which requires
13 equations with 14 variables:
A 3-stage symplectic scheme needs to satisfy the following 6 conditions
b2a21 + b2b1(c1 −c2) = 0,
b3a31 + b3b1(c1 −c3) = 0,
b3a32 + b3b2(c2 −c3) = 0,
b4a41 + b4b1(c1 −c4) = 0,
b4a42 + b4b2(c2 −c4) = 0,
b4a43 + b4b3(c3 −c4) = 0,
and equations that satisfy 4th-order conditions are as follows:
b1 + b2 + b3 + b4 = 1,
b1c1 + b2c2 + b3c3 + b4c4 = 1
2,
b1c2
1 + b2c2
2 + b3c2
3 + b4c2
4 = 1
3,
b2a21 + b3a31 + b3a32 + b4a41 + b4a42 + b4a43 = 1
6,
b1c3
1 + b2c3
2 + b3c3
3 + b4c3
4 = 1
4,
b2c2a21 + b3c3a31 + b3c3a32 + b4c4a41 + b4c4a42 + b4c4a43 = 1
8,
b2a21c1 + b3a31c1 + b3a32c2 + b4a41c1 + b4a42c2 + b4a43c3 = 1
24.
Set c4 = 0, we have
b2a21 + b2b1(c1 −c2) = 0,
(3.16)
b3a31 + b3b1(c1 −c3) = 0,
(3.17)
b3a32 + b3b2(c2 −c3) = 0,
(3.18)
b4a41 + b4b1c1 = 0,
(3.19)

7.3 Symplectic R–K–N Method
325
b4a42 + b4b2c2 = 0,
(3.20)
b4a43 + b4b3c3 = 0,
(3.21)
b1 + b2 + b3 + b4 = 1,
(3.22)
b1c1 + b2c2 + b3c3 = 1
2,
(3.23)
b1c2
1 + b2c2
2 + b3c2
3 = 1
3,
(3.24)
b2a21 + b3a31 + b3a32 + b4a41 + b4a42 + b4a43 = 1
6,
(3.25)
b1c3
1 + b2c3
2 + b3c3
3 = 1
4,
(3.26)
b2c2a21 + b3c3a31 + b3c3a32 = 1
8,
(3.27)
b2a21c1 + b3a31c1 + b3a32c2 + b4a41c1 + b4a42c2 + b4a43c3 = 1
24.(3.28)
We obtain a set of numerical solutions of (3.16) – (3.28):
a21 = 0.2232896E −01,
a31 = 0.2822977E −08,
a32 = 0.2886753,
a41 = 0.3053789E −01,
a42 = −0.1057342,
a43 = −0.4251137,
b1 = −0.3867491E −01,
b2 = 0.5000003,
b3 = 0.5386746,
b4 = −0.9129767E −07,
c1 = 0.7886753,
c2 = 0.2113249,
c3 = 0.7886752.
Guessing from these numerical solutions, we obtain
a31 = 0,
b2 = 1
2,
b3 = 1
2 −b1,
b4 = 0,
c1 = c3,
c2 = 1 −c1.
Inserting them into (3.16) – (3.28), we have
(3.16) ⇐⇒a21 + b1(2c1 −1) = 0,
(3.17) ⇐⇒0 = 0,
(3.18) ⇐⇒
1
2 −b1

a32 +
1
2 −b1
1
2(1 −2c1) = 0,
(3.19), (3.20), (3.21), (3.22), (3.23) ⇐⇒0 = 0,
or
1 = 1,
(3.24) ⇐⇒1
2c2
1 + 1
2(1 −c1)2 = 1
3,
(3.25) ⇐⇒1
2a21 +
1
2 −b1

a32 = 1
6,
(3.26) ⇐⇒c2
1 −c1 + 1
6 = 0,
(3.27) ⇐⇒1
2(1 −c1)a21 + c1a32
1
2 −b1

= 1
8,
(3.28) ⇐⇒1
2a21c1 +
1
2 −b1

a32(1 −c1) = 1
24.

326
7. Symplectic Runge–Kutta Methods
So we obtain a system of equations of the variables a21, a32, b1, c1
a21 + b1(2c1 −1) = 0,
(3.29)
1
2 −b1

a32 +
1
2 −b1
1
2(1 −2c1) = 0,
(3.30)
1
2c2
1 + 1
2(1 −c1)2 = 1
3,
(3.31)
1
2a21 +
1
2 −b1

a32 = 1
6,
(3.32)
1
2(1 −c1)a21 + c1a31
1
2 −b1

= 1
8,
(3.33)
1
2a21c1 +
1
2 −b1

a32(1 −c1) = 1
24.
(3.34)
From (3.31), we have c2
1−c1+1
6 = 0, which leads to c1 = 3 +
√
3
6

or c1 = 3 −
√
3
6

.
Suppose b1 ̸= 1
2, from (3.30) we obtain
a32 = 1
2(2c1 −1),
(3.35)
so a32 =
√
3
6

or a32 = −
√
3
6

. Under (3.35), Equation (3.32) becomes
1
2a21 +
%1
2 −b1
&
× 1
2(2c1 −1) = 1
6.
(3.36)
Adding (3.36) and (3.29) together, we ﬁnd
2a21 = 1
3 −1
2(2c1 −1),
i.e.,
a21 = 2 −
√
3
12

or
2 +
√
3
12

.
From (3.29), we obtain b1 = 3 −2
√
3
12

or 3 + 2
√
3
12

. Therefore, we have reason to
speculate that
a21 = 2 −
√
3
12
,
a32 =
√
3
6 ,
b1 = 3 −2
√
3
12
,
c1 = 3 +
√
3
6
and
a21 = 2 +
√
3
12
,
a32 = −
√
3
6 ,
b1 = 3 + 2
√
3
12
,
c1 = 3 −
√
3
6
are two sets of solutions of (3.29) – (3.34). Direct veriﬁcation shows that they are
indeed solutions of the equations of (3.16) – (3.28). Thus we obtain two sets of analytic
solutions of the original equations of system (3.16) – (3.28).
Solution 1:
a21 = 2 −
√
3
12
, a31 = 0, a32 =
√
3
6 , a41, a42, a43 arbitrary.
b1 = 3 −2
√
3
12
,
b2 = 1
2,
b3 = 3 + 2
√
3
12
,
b4 = 0,
c1 = 3 +
√
3
6
,
c2 = 3 −
√
3
6
,
c3 = 3 +
√
3
6
,
c4 = 0.

7.3 Symplectic R–K–N Method
327
Solution 2:
a21 = 2 +
√
3
12
, a31 = 0, a32 = −
√
3
6 , a41, a42, a32 arbitrary.
b1 = 3 + 2
√
3
12
,
b2 = 1
2,
b3 = 3 −2
√
3
12
,
b4 = 0,
c1 = 3 −
√
3
6
,
c2 = 3 +
√
3
6
,
c3 = 3 −
√
3
6
,
c4 = 0.
Since b4 = c4 = 0, and ¯b4 = b4(1 −c4) = 0 in the two solutions, we obtain two
3-stage symplectic explicit R–K–N method of order 4. They are
Scheme 1:
ci
aij
3 +
√
3
6
0
0
0
3 −
√
3
6
2 −
√
3
12
0
0
3 +
√
3
6
0
√
3
6
0
bi
5 −3
√
3
24
3 +
√
3
12
1 +
√
3
24
bi
3 −2
√
3
12
1
2
3 + 2
√
3
12
Scheme 2:
ci
aij
3 −
√
3
6
0
0
0
3 +
√
3
6
2 +
√
3
12
0
0
3 −
√
3
6
0
−
√
3
6
0
bi
5 + 3
√
3
24
3 −
√
3
12
1 −
√
3
24
bi
3 + 2
√
3
12
1
2
3 −2
√
3
12
Remark 3.6. We can obtain the required solutions easily by solving only the ﬁrst 6
equations from the simpliﬁed order conditions of symplectic R–K–N.
7.3.3 Sympliﬁed Order Conditions for Symplectic R–K–N Method
In subsection 7.3.1, we have a preliminary brieﬁng of sympliﬁed order conditions for
the symplectic R–K–N methods. In this section, we will simplify them further. The
key is to make full use of symplectic conditions [ZQ95b].

328
7. Symplectic Runge–Kutta Methods
Let Sτ be an S-tree of order n ≥3. It has at least two fat vertices. Let λSτ be a
labeling. Let v and w be two fat vertices connected via a meagre vertex u. For order
≤2 S-tree, the root S-trees contains only one the ﬁrst-order and one the second-
order. Therefore there are no such issues that the order conditions for the trees with
the same order are related to each other. We consider six rooted S-trees. Let us denote
ρSτ v (resp. ρSτ w) as the rooted S-tree obtained by regarding the vertex v (resp. w)
as the root of Sτ. Let us denote ρSτ vu (resp. ρSτ wu) as the rooted S-tree with root
v (resp. w) that arises when the edge (u, w)(resp. (v, u)) is deleted from sτ. Let us
denote ρSτv and ρSτw as the rooted S-tree with root v and w respectively which arise
when edges, (u, v) and (u, w) are deleted from Sτ. Fig. 3.1 shows the rooted trees of
Theorem 3.7.
v
u
w +
ρSτ w
•
v
u
+
w
ρSτ v
•
v
u
w
Sτ
•
w
+
ρSτw
v
+
ρSτv
u
w+
ρSτ wu
•
v
u
+
ρSτ vu
•
Fig. 3.1.
Rooted S-trees
Theorem 3.7. With the above notations, we have:
1◦
1
γ(ρSτ v) −
1
γ(ρSτ w) =
1
γ(ρSτ vu)γ(ρSτw) −
1
γ(ρSτ wu)γ(ρSτv).
And if the R–K–N method (3.4) satisﬁes (3.7), then,
2◦
φ(ρSτ v) −φ(ρSτ w) = φ(ρSτ vu)φ(ρSτw) −φ(ρSτ wu)φ(ρSτv).
Proof. Let
r(ρSτv) = x,
r(ρSτw) = ˙y,
n = r(Sτ) = x + y + 1.
By deﬁnition of γ, we have
γ(ρSτ v) = n
;
1
(x + 1)γ(ρSτw),
γ(ρSτ w) = n
;
2
(y + 1)γ(ρSτv),
(3.37)
where
;
1
 ;
2

denotes the product of γ(τ1)(γ(τ2)) of the sub-trees, τi which arise
when v (resp. w) is chopped from ρSτv (resp. ρSτw). Notice that γ is calculated as

7.3 Symplectic R–K–N Method
329
the general tree τ, with the difference between the black and white vertices neglected.
Then from (3.37), we have
1
γ(ρSτ v) −
1
γ(ρSτ w) = n
n
%
2(y + 1)γ(ρSτv) −1(x + 1)γ(ρSτw)
1(x + 1)γ(ρSτv)2(y + 1)γ(ρSτw)
&
.
(3.38)
Because
γ(ρSτ vu) = (x + 1)
;
1
,
γ(ρSτ wu) = (y + 1)
;
2
,
and
γ(ρSτv) = x
;
1
,
γ(ρSτw) = y
;
2
,
we have
1
γ(ρSτ v) −
1
γ(ρSτ w) =
n
n
⎛
⎜
⎝
;
2
(y + 1)γ(ρSτv) −
;
1
(x + 1)γ(ρSτw)
γ(ρSτ vu)γ(ρSτ wu)γ(ρSτv)γ(ρSτw)
⎞
⎟
⎠
=
1
n
⎛
⎜
⎝
;
1
;
2
(x2 −y2 + x −y)
γ(ρSτ vu)γ(ρSτ wu)γ(ρSτv)γ(ρSτw)
⎞
⎟
⎠.
However,
1
γ(ρSτ vu)γ(ρSτw) −
1
γ(ρSτ wu)γ(ρSτv)
=
n

γ(ρSτ wu)γ(ρSτv) −γ(ρSτ vu)γ(ρSτw)

n

γ(ρSτ vu)γ(ρSτw)γ(ρSτ wu)γ(ρSτv)

=
n
*;
2
(y + 1)
;
1
x −
;
1
(x + 1)
;
2
y
+
n

γ(ρSτ vu)γ(ρSτ wu)γ(ρSτv)γ(ρSτw)

=
;
1
;
2
(x + y + 1)

x(y + 1) −(x + 1)y

n

γ(ρSτ vu)γ(ρSτ wu)γ(ρSτv)γ(ρSτw)

=
;
1
;
2
(x2 −y2 + x −y)
n

γ(ρSτ vu)γ(ρSτ wu)γ(ρSτv)γ(ρSτw)
.
(3.39)
Thus, we get 1◦.
▲
By deﬁnition of φ, we have

330
7. Symplectic Runge–Kutta Methods
⎧
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎩
φ(ρSτ vu) =

iv
bivciv
v
;
,
φ(ρSτv) =

iv
biv
v
;
,
φ(ρSτ wu) =

iw
biwciw
w
;
,
φ(ρSτw) =

iw
biw
w
;
,
and
⎧
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎩
φ(ρSτ v) =

iv
biv

iv
aiviw
* v
; w
;+
,
φ(ρSτ w) =

iw
biw

iw
aiwiv
* v
; w
;+
,
(3.40)
where
v
;  w
; 
denotes part of φ(ρSτ v)(resp. φ(ρSτ w), which is the sum over black
vertices of ρSτv(ρSτw). From symplectic order condition (3.11), we have
φ(ρSτ v) −φ(ρSτ w) =

iv,iw
(bivaiviw −biwaiwiv)
w
;
v
;
=

iv,iw
bivbiw(civ −ciw)
v
; w
;
=

iv
bivciv
v
; 
iw
biw
w
;
−

iw
biwciw
w
; 
iv
biv
v
;
= φ(ρSτ vu)φ(ρSτw) −φ(ρSτ wu)φ(ρSτv).
(3.41)
Thus, the second part 2◦of Theorem 3.7 is held. The following corollary is trivial.
Corollary 3.8. Suppose that the R–K–N method (3.4) satisfying (3.7), has order at
least n −1, with n ≥3. If ρSτ v and ρSτ w are different rooted S-trees of order n,
then the order condition is the same as given in Theorem 3.7.
φ(ρSτ v) =
1
γ(ρSτ v)
holds, iff
φ(ρSτ w) =
1
γ(ρSτ w)
is satisﬁed.
Proof. Because R–K–N method (3.4) is of at least n −1-order, by Theorem 3.5, we
have

7.3 Symplectic R–K–N Method
331
φ(ρSτ vu) =
1
γ(ρSτ vu),
φ(ρSτ wu) =
1
γ(ρSτ wu),
and
φ(ρSτv) =
1
γ(ρSτv),
φ(ρSτw) =
1
γ(ρSτw),
similarly by Theorem 3.1, corollary is proved.
▲
So we have the conclusion of this subsection.
Theorem 3.9. [SSC94,ZQ95b] A R–K–N method (3.4) that satisﬁes symplectic conditions
is order of p, iff for every S-tree Sτ there exists a rooted S-tree ρSτ v which arises
when a black vertex v of Sτ is lifted as the root, such that
φ(ρSτ) =
1
γ(ρSτ).
Proof. By Corollary 3.8 we know that any two different methods of choosing the
corresponding root have equivalent order conditions. Hence the theorem is proved. ▲
As an application of Theorem 3.9, we consider the explicit R–K–N method, i.e.,
aij = 0, for j > i (i, j = 1, 2, · · · , s), and the non-redundant case, i.e., bi ̸= 0 (i =
1, 2, · · · , s), see [OS92]. Then, we have aij = bj(ci−cj), for i ≥j, (i, j = 1, 2, · · · , s).
So we obtain the following corollary.
Corollary 3.10. Non-redundant R–K–N method (3.4) is explicit symplectic and of
order p, iff:
1◦
aij = bj(ci −cj), 1 ≤j < i ≤s.
2◦
bj = bj(1 −cj), 1 ≤j ≤s.
3◦
For every S-tree sτ, there exist a rooted S-tree ρSτ v, which arises when a
black vertex v of sτ is lifted as the root, such that:
φ(ρSτ) =
1
γ(ρSτ).
To obtain a 5-stage ﬁfth order non-redundant symplectic explicit R–K–N method,
the following equations are satisﬁed:
aij = bj(ci −cj),
1 ≤j < i ≤s,
(3.42)
bj = bj(1 −cj),
1 ≤j ≤s,
(3.43)
and
5

j=1
bj = 1,
(3.44)
5

j=1
bjcj = 1
2,
(3.45)

332
7. Symplectic Runge–Kutta Methods
5

j=1
bjc2
j = 1
3,
(3.46)
5

j,l=1
bjajl = 1
6,
(3.47)
5

j=1
bjc3
j = 1
4,
(3.48)
5

m,j=1
bjcjajm = 1
8,
(3.49)
5

j=1
bjc4
j = 1
5,
(3.50)
5

j,p=1
bjc2
jajp = 1
10,
(3.51)
5

j,l,p=1
bjajlajp = 1
20,
(3.52)
5

j,l=1
bjcjajlcl = 1
30.
(3.53)
Replacing aij of system equations (3.44) – (3.53) by (3.42), we get a system of
10 equations for parameters bi, ci (i = 1, · · · , 5). Every order condition of system
(3.44) −(3.53) corresponds to the S-trees of the same number in Fig. 3.2.
j
+
1
l
•
j
+
2
l
•
k
•
j
+
3
•
k
l
j
+
4
k
l
m
•
•
•
j
+
5
•
k
• l
m
j
+
6
j
+
l
m
p
k
•
•
•
•
7
•
k
• m
l
•
p
j
+
8
•
k
• m
l
p
j
+
9
•
k
• p
l
j
+
m•
10
Fig. 3.2.
Rooted S-trees corresponding to order condition (3.44) – (3.53)
For the sake of convenience, we choose monotonic labelings for trees in Fig. 3.2.
We obtain the Equations (3.46). In the following list we provide four sets of numerical
solutions, whose laws are yet to be studied further.

7.4 Formal Energy for Symplectic R–K Method
333
i
1
2
3
4
5
1
 bi
ci
0.396826
0.961729
−0.824374
0.866475
0.204203
0.127049
1.002182
0.754358
0.221161
0.229296
2
 bi
ci
0.221160
0.770703
1.002182
0.245641
0.204203
0.872950
−0.824375
0.133524
0.396827
0.038270
3
 bi
ci
−1.670799
0.694313
1.221431
0.637071
0.088495
−0.020556
0.959970
0.795861
0.400902
0.301165
4
 bi
ci
0.400902
0.698834
0.959969
0.204138
0.088495
1.020556
1.221434
0.362928
−1.670802
0.305086
Remark 3.11. R–K, P–R–K, and R–K–N methods have corresponding order condi-
tions. The order conditions for symplectic R–K, symplectic P–R–K, and symplectic
R–K–N method can be simpliﬁed using symplectic conditions. The order conditions
for order 1 to 8 have already been listed in Table 1.4. Calvo and Hairer[CH95] further
reduce the number of independent condition in R–K–N method. See Table 3.1.
Table 3.1.
Order conditions R–K–N method and Symplectic R–K–N method for general case
Order
R–K–N method
Symplectic R–K–N method
1
1
1
2
1
1
3
2
2
4
3
2
5
6
4
6
10
5
7
20
10
8
36
14
7.4 Formal Energy for Symplectic R–K Method
The energy H(z) of a Hamiltonian system is also an invariant of the system. How-
ever, under normal circumstances, no symplectic scheme can preserve all the original
Hamilton energy [Fen98a]. On the other hand, any symplectic scheme preserves a for-
mal Hamiltonian energy, which approaches the original Hamiltonian energy with the
precision of numerical scheme. The calculation of formal energy can be done in many
ways. First, we have obtained a complete method in theory to obtain the formal energy
of a symplectic difference scheme constructed by generating function [Fen98a]. Yoshida
[Yos90] uses Lie series of BCH Formula to determine the formal energy of separable
Hamiltonian. What is insufﬁcient is that the existing formal energy computational

334
7. Symplectic Runge–Kutta Methods
methods for symplectic R–K method mostly use Poincar´e lemma, and then use the
quadrature method. Although theoretically primary function (total differential) does
exist, obtaining the primary function through the integral is not that easy. Therefore,
we attempt to calculate the formal energy of a symplectic R–K method in a easy way
that does not need the integral and also does not need any differentiation.
7.4.1 Modiﬁed Equation
Consider the numerical solution of ODEs
˙z = f(z),
z ∈Rn.
(4.1)
The R–K method for Equation (4.1) is deﬁned as follows:
ki = f
*
z0 + h
s

j=1
aijkj
+
,
(4.2)
z1 = z0 + h
s

i=1
biki.
(4.3)
Since the fundamental work of Butcher, numerical solution z1 can be written as
(suppose f is sufﬁciently differentiable):
z1 = z0 +

t∈T
hr(t)
r(t) ! α(t)
*
γ(t)
s

i=1
biφi(t)
+
F(t)(z0).
(4.4)
Deﬁnition 4.1. [Hai94] Let t be a rooted tree. A partition of t into k subtrees {s1, . . . , sk}
is a set S, consisting of k −1 branches of t such that the trees s1, . . . , sk are obtained
when the branches of S are removed from t. Such a partition is denoted by (t, S). We
further denote α(t, S) as the number of possible monotonic labelings of t such that
the vertices of the subtrees sj are labeled consecutively.
Example 4.2. All partitions of t = [[τ], [τ]], t into k subtrees with the numbers
α(t, S):
\
\
/
/
...
·
...
...
·
...
3
•
•
•
•
•
\
\
/
/
...
·
...
2
•
•
•
•
•
\
\
...
·
...
...
·
...
k = 4
3
k = 5
•
•
•
•
•
\
\
/
/
1
•
•
•
•
•
...
·
...
...
·
...
2
•
•
•
•
•
/
/
...
·
...
k = 3
1
•
•
•
•
•
\
\
...
·
...
1
•
•
•
•
•
\
\
k = 2
1
•
•
•
•
•
...
·
...
2
•
•
•
•
•
k = 1
3
•
•
•
•
•
Suppose a numerical method can be expressed as a formal series
z1 = z0 +

t∈T
hr(t)
r(t) ! α(t)a(t)F(t)(z0),
(4.5)

7.4 Formal Energy for Symplectic R–K Method
335
Table 4.1.
Relation between coefﬁcients a(t) and b(t)(1)
t = •
a(•)
=
b(•)
t =
•
•
a
•
•


=
b
•
•


+ b ( • )2
t =
•
•
•
a
•
•
•


=
b
•
•
•


+ 3
2 b
•
•


b( • ) + b( • )3
t =
•
•
•
a
•
•
•


=
a
•
•
•


+ 3b
•
•


b ( • ) + b ( • )3
where a : T →R is an arbitrary function. Such a series is called a B-series. If
function f(z) is only N-times continuously differentiable, then the series (4.5) has to
be interpreted as a ﬁnite sum over t ∈T with (r(t) ≤N).
Theorem 4.3. [Hai94] Let a : T →R be an arbitrary mapping, and the right side
of equation (4.1) f(z) is N-times continuously differentiable. The numerical solution
given by (4.5) satisﬁes
z1 = "z(t0 + h) + O(hN+1).
(4.6)
Here, "z(t) is the exact solution of the modiﬁed equation:
"˙z =

r(t)≤N
hr(t)−1
r(t) ! α(t)b(t)F(t)("z),
(4.7)
where the coefﬁcients b(t) can be deﬁned recursively by:
a(t) =
r(t)

k=1
1
k !

(t,S)

r(t)
r(s1), · · · , r(sk)
α(t, S)
α(t)
b(s1) · · · b(sk).
(4.8)
The second sum in (4.8) is over all partitions of t into k subtrees {s1, · · · , sk}.
By (4.8), we can deﬁne relation between coefﬁcients a(t) and b(t), See Table 4.1
to Table 4.4[LQ01].
According to Table 4.1 – Table 4.4, we can determine modiﬁed equation for R–K
equation (up to 5 orders, it is clear that as long as the order continues to add 6, 7-order
tree · · · equation can be modiﬁed to any order).
Remark 4.4. If numerical method is symmetrical (or time-reversible), then when r(t)
is even, b(t) = 0.
Remark 4.5. If numerical method is p-order, in other words when r(t) ≤p, a(t) =
1; then, if 2 ≤r(t) ≤p, b(•) = 1, b(t) = 0; if r(t) = p + 1, b(t) = a(t) −1.

336
7. Symplectic Runge–Kutta Methods
Table 4.2.
Relation between coefﬁcients a(t) and b(t)(2)
t = • • •
•
a
 • • •
•

= b
 • • •
•

+ 2b( • )b
•
•
•

+ 2b( • )2b( /•
• ) + b( • )4
t =
•
•
•
•
a
%
•
•
•
•
&
= b
%
•
•
•
•
&
+ 4
3b( • )b
•
•
•

+ 2
3b( • )b
• •
•

+ b( /•
• )2
+10
3 b( • )2b( /•
• ) + b( • )4
t =
•
•
•
•
a
%
•
•
•
•
&
= b
%
•
•
•
•
&
+ 2b( • ) b
•
•
•

+ 2b( • )b
• •
•

+4b( • )2b( /•
• ) + b(•)4
t = •
• •
•
a
%
•
• •
•
&
= b
%
•
• •
•
&
+ 4b( • ) b
• •
•

+ 3b( /•
• )2
+6b( • )2b( /•
• ) + b( • )4
Example 4.6. Centered Euler scheme
zn+1 = zn + hf
zn + zn+1
2

.
Modiﬁed equation can be deﬁned1
"˙z = f("z) −h2
24

f (2)(f, f) −2f (1)f (1)f

+ h4
120
 7
48f (4)(f, f, f, f)
+1
4f (3)(f, f, f(1)f) −1
4f (2)
f, f (2)(f, f)

−3
2f (2)(f, f(1)f (1)f)
+3
4f (2)(f (1)f, f (1)f) −7
12f (1)f (3)(f, f, f) −1
2f (1)f (2)(f, f(1)f)
+1
4f (1)f (1)f (2)(f, f) + 3
2f (1)f (1)f (1)f (1)f

+ O(h6).
Example 4.7. 2-stage Gauss–Legendre method [HNW93]:
1 b(t) by Section 7.5.

7.4 Formal Energy for Symplectic R–K Method
337
Table 4.3.
Relation between coefﬁcients a(t) and b(t)(3)
t = • ••
• •
a
 • ••
• •

= b
 • ••
• •

+ 5
2b( • )b(• • •
•
) + 10
3 b( • )2b(•
•
•
)
+5
2 b ( • )3b( /•
• ) + b( • )5
t =
• • •
•
•
a
%• • •
•
•
&
= b
%• • •
•
•
&
+ 5
2b( • )b
•
•
•
•

+ 5
2b( • )b
• • •
•

+ 10
3 b( • )2b
• •
•

+10
3 b( • )2 b
•
•
•

+ 5b( • )3b(/•
• ) + b( • )5
t =•
•
• •
•
a
%
•
•
• •
•
&
= b
%
•
•
• •
•
&
+ 5b( • ) b
%
•
• •
•
&
+ 10b( /•
• )b
• •
•

+ 10b( • )2b
• •
•

+15b( • )b( /•
• )2 + 10b( • )3b( /•
• ) + b( • )5
1
2 −
√
3
6
1
4
1
4 −
√
3
6
1
2 +
√
3
6
1
4 +
√
3
6
1
4
1
2
1
2
Modiﬁed equation is deﬁned2
"˙z(t) = f("z) −37h4
8840
@
f (4)(f, f, f, f) −4f (1)f (3)(f, f, f)
A
−h4
720
@
f (3)(f, f, f(1)f)
−f (2)
f, f (2)(f, f)

−2f (1)(f (2)f, f (1)f) + f (1)f (1)f (2)(f, f)
A
−37h4
2880
@
f (2)(f (1)f, f (1)f) −2f (2)(f, f(1)f (1)f) + 2f (1)f (1)f (1)f (1)f
A
+O(h6).
Example 4.8. 2-order diagonal implicit R–K method:
Modiﬁed equation:
2 b(t) by Section 7.5.

338
7. Symplectic Runge–Kutta Methods
Table 4.4.
Relation between coefﬁcients a(t) and b(t)(4)
t =
•
•
• •
•
a
%•
•
• •
•
&
= b
%•
•
• •
•
) + 5
2b
%
• )b
%
•
• •
•
&
+ 5b( /•
• )b
•
•
•
) + 5
2b( • )b
% •
•
•
•
&
+ 20
3 b( • )2b
• •
•

+ 10
3 b( • )2b
•
•
•

+ 5b( • )b(/•
• )2
+ 15
2 b( • )3b( /•
• ) + b( • )5
t =
•
•
•
•
•
a
%•
•
•
•
•
&
= b
%•
•
•
•
•
&
+ 5
2b( • )b

•
•
•
• 
+ 5
6b( • )b
%
•
• •
•
&
+ 5
3b( • )b
% •
•
•
•
&
+ 5
3b(/•
• )b
• •
•

+ 40
9 b( • )2b
• •
•
) + 5b( • )b(/•
• )2
+ 20
9 b( • )2b(•
•
•
) + 20
3 b( • )3b(/•
• ) + b( • )5
t =
•
• • •
•
a
%
•
• • •
•
&
= b
%
•
• • •
•
&
+ 5
4b( • )b
 • • •
•

+ 5
4b( • )b
%
•
•
•
• &
+ 5
6b
•
•
•

b(/•
• ) + 25
9 b( • )2b
•
•
•

+ 5
3b( • )b(/•
• )2
+ 5
9b( • )2b
• •
•

+ 15
4 b( • )3b(/•
• ) + b( • )5
t =
•
•
•
•
•
a
%
•
•
•
•
•&
= b
%
•
•
•
•
•&
+ 5
8b( • )b
% •
•
•
•
&
+ 5
4b(/•
• )b
•
•
•

+ 15
8 b( • )b
%
•
•
•
• &
+ 10
3 b( • )2b
•
•
•

+ 5
3b( • )2b
• •
•

+ 5
4b( • )b(/•
• )2 + 35
8 b( • )3b(/•
• ) + b( • )5
t =
•
•
•
•
•
a
%
•
•
•
•
• &
= b
%
•
•
•
•
• &
+ 5
8b( • )b
%
•
• •
•
&
+ 5
4b(/•
• )b
• •
•

+ 5
2b(/•
• )b
•
•
•

+ 15
8 b( • )b

•
•
•
• &
+ 10
3 b( • )2b
• •
•

+ 5b( • )b(/•
• )2
+ 5
3b( • )2b
•
•
•

+ 25
4 b( • )3b(/•
• ) + b( • )5
t =
•
•
•
•
•
a
% •
•
•
•
•&
= b
%•
•
•
•
•&
+ 5
2b( • )b

•
•
•
• 
+ 5
3b(/•
• )b
• •
•

+ 5b( • )b(/•
• )2
+ 10
9 b( • )2b
• •
•

+ 20
9 b( • )2b
•
•
•

+ 5b( • )3b(/•
• )
+b( • )5
"˙z(t) =
f("z) −h2
96
@
f (2)(f, f) −2f (1)f (1)f
A
−17h4
10240
@
f (4)(f, f, f, f)
−4f (1)f (3)(f, f, f)
A
−13h4
2560
@
f (3)(f, f, f(1)f) −f (2)(f, f(2)(f, f))
−2f (1)(f (2)f, f (1)f) + f (1)f (1)f (2)(f, f)
A
−
h4
2560
@
f (2)(f (1)f, f (1)f)
−2f (2)(f, f (1)f (1)f) + 2f (1)f (1)f (1)f (1)f
A
+ O(h6).

7.4 Formal Energy for Symplectic R–K Method
339
1
4
1
4
0
3
4
1
2
1
4
1
2
1
2
7.4.2 Formal Energy for Symplectic R–K Method
Let T be a set of all rooted trees. On set T we deﬁne a relation ∼, as follows:
1◦
t ∼t.
2◦
u ◦v ∼v ◦u.
3◦
If u1 ◦v1 ∼u2 ◦v2, u2 ◦v2 ∼u3 ◦v3, then u1 ◦v1 ∼u3 ◦v3.
Where u ◦v and v ◦u is deﬁned by
if u = [u1, · · ·, um], v = [v1, · · · , vm], then
u ◦v = [u1, · · · , um, v],
v ◦u = [v1, · · · , vm, u].
Obviously “∼” expresses an equivalent relation. Using this equivalent relation to
classify the root tree collection T, we can obtain a quotient space, denoted by TE.
Then we may construct another set T "E, which is obtained by ﬁltering every equivalent
class of TE. The ﬁltering rule is as follows: if t ∈TE, then t is a rooted tree’s subset
class. We sort the element of t according to σ(t), and choose t so that σ(t) is the
biggest. In general, such t is not unique and we can choose any one of them. For each
element in the T "E we deﬁne a quasi elementary differential
F ∗(t) = f (m−1)
F(t1), F(t2), · · · , F(tm)

.
(4.9)
The reason why we call (4.9) quasi elementary differential is because under normal
circumstances, elementary differential has been deﬁned as:
F(t) = f (m)
F(t1), F(t2), · · · , F(tm)

,
where f (m)(K1, K2, · · · , Km) is m-order Frechet derivative.
Here, we regard f (m−1)(K1, K2, · · · , Km) as a formal deﬁnition. Obviously,
when f is a differential of some function, f (m−1)(K1, K2, · · · , Km) will become m-
order Frechet derivative of its primary function. For example, t = [τ, τ, τ, τ], F ∗[t] =
f (3)(f, f, f, f). Let f = JHz, then F ∗(t) becomes JH(4)(JHz, JHz, JHz, JHz),
which is obviously a fourth-order Frechet derivative. We use L to express this map-
ping, namely
L :
f (m−1)(K1(f), K2(f), · · · , Km(f))
−→JH(m)(K1(JHz), K2(JHz), · · · , Km(JHz)).
Obviously, L is a 1 to 1 mapping. From now on, we will always use L to express this
mapping unless it is speciﬁed otherwise. We will no longer differentiate F ∗(t) with
L(F ∗(t)). The operation of F ∗(t) is always thought as operation of L(F ∗(t)).

340
7. Symplectic Runge–Kutta Methods
Lemma 4.9. Let (A, b) be a symplectic R–K method, a(t) = γ(t)
s

j=1
bjφj(t), then:
a(u ◦v)
γ(u ◦v) + a(v ◦u)
γ(v ◦u) = a(u)
γ(u) · a(v)
γ(v),
u, v ∈TP.
(4.10)
Proof. [CS94].
▲
Lemma 4.10. Let "H(z, h) be the formal energy of symplectic R–K method (A, b),
then the corresponding modiﬁed equation is (possible differ by an arbitrary constant):
"˙z = "f("z) = J "H˜z.
(4.11)
Conversely, if modiﬁed equation of symplectic R–K the method (A, b) are "f("z), then
we have
"Hz = −J "f(z).
(4.12)
Proof. Note that both the modiﬁed equation and the formal energy can be obtained
essentially via series expansion, Lemma 4.10 is obvious.
▲
Lemma 4.11. Let (A, b) be a symplectic R–K method, a(t) = γ(t)
s

j=1
bjφj(t), then:
b(u ◦v)
γ(u ◦v) + b(v ◦u)
γ(v ◦u) = 0,
u, v ∈TP,
u ̸= v,
(4.13)
where b(t) is determined recursively by (4.8).
Proof. Using the method that proves Lemma 10 in literature[Hai94] and modifying it
slightly will complete the proof. We leave out its detail here.
▲
Remark 4.12. By (4.13) and relation α(t)γ(t)σ(t) = r(t) we obtain
α(u ◦v) b(u ◦v)
α(v ◦u) b(v ◦u) + σ(v ◦u)
σ(u ◦v) = 0.
(4.14)
We now need another coefﬁcient ν(t) related to rooted tree. Note ﬁrst that the
rooted trees u◦v and v ◦u represent an identical unrooted tree with different root, i.e.,
selecting the other vertex of u ◦v as root leads to tree v ◦u. Thus, in an equivalent
class, it can always transform one rooted tree to another by selecting a different root.
Take ¯t ∈TE, then ¯t is one equivalent class of rooted tree collection (t represents the
element). Let u ∈¯t, then u can be obtained by selecting some vertex of t as the root
node. We denote ν(u) as number of vertices of t which may be selected.
Example 4.13. t = [τ, τ, [τ]], then ¯t = {t1, t2, t3, t4}, where
t1 =
•
• • •
•
,
t2 =
•
•
•
•
•
,
t3 =
•
•
• •
•
,
t4 =
•
•
•
•
•
.
We have

7.4 Formal Energy for Symplectic R–K Method
341
ν(t1) = 1,
ν(t2) = 1,
ν(t3) = 1,
ν(t4) = 2.
Then, the following relation for ν(t) is hold
ν(u ◦v) · σ(u ◦v) = ν(v ◦u) · σ(v ◦u).
(4.15)
Lemma 4.14. Let rooted tree u ̸= v, then
F ∗(u ◦v) = −F ∗(v ◦u).
(4.16)
Proof. F ∗(u◦v) = JJ−1F(u)JJ−1F(v). Let α = J−1F(u), β = J−1F(v), where
F(u), F(v) are elementary differentials. If u = [u1, u2, · · · , um], then
F(u) = f (m)
F(u1), F(u2), · · · , F(um)

,
where f = JHz, and F(v) is similar to F(u).
By properties of elementary differential (multilinear mapping), α,β are 2n-dimensional
vectors, and
F ∗(u ◦v) = J(α, Jβ) = JαTJβ = −JβTJα = −F ∗(v ◦u).
Therefore, the lemma is completed.
▲
Lemma 4.15. Let t∗∈T "E, then
α(t∗)b(t∗)∇F ∗(t∗) =

t∈¯t∗
α(t)b(t)F(t).
(4.17)
Proof. First the right side of (4.17) is uniquely determined, and on the left side the
selection of t∗may not necessarily be unique. Therefore, it is required to prove that
(4.17) the left side of the formula is independent of selection of t∗. We explain it as
follows: given t∗1 ∈t∗, such that σ(t∗) = σ(t∗1), then there exists a series of u ◦v,
such that
t∗= u1 ◦v1∼v1 ◦u1 = u2 ◦v2∼v2 ◦u2 = · · · ∼um ◦vm = t∗1.
(4.18)
Let m = 2, i.e., t∗= u1 ◦v1, t∗1 = v1 ◦u1, then by (4.14)
α(t∗)b(t∗) = −α(t∗1)b(∗1),
and by Lemma 4.14
F ∗(u ◦v) = −F ∗(v ◦u) =⇒∇F ∗(u ◦v) = −∇F ∗(v ◦u),
therefore
α(t∗)b(t∗)∇F ∗(t∗) = α(t∗1)b(t∗1)∇F ∗(t∗1).
(4.19)
For m > 2, t∗1 must be a node of (4.18), (4.19) is also held.
Next, ∇F ∗(t∗) must be a linear combination of basic differentials in the same
class, i.e.,

342
7. Symplectic Runge–Kutta Methods
∇F ∗(t∗) =

t∈¯t∗
β(t)F(t).
Consider a special case:
•
•
•
•
•
k
l
m
j
,
t∗=
i
F ∗(t∗) = f (2)(f, f, f(1)f).
The differentiation of F ∗(t∗) can be seen as a following process: ﬁrst differentiate
w.r.t. the root node one time, obtain f (3)(f, f, f(1)f), and then differentiate w.r.t. each
vertex one time, i.e., add 1 to each vertex superscript and then move it in front of its
father along with its substance, continue moving until it reaches the front of root node.
In this process, according to (4.4), every move accompanies a change in sign. Using
the above example, differentiating w.r.t. the point i, j, k, l, m respectively, we obtain
m
−→−f (1)f (2)(f, f (1)f),
l −→−f (1)f (2)(f, f(1)f),
j
−→−f (2)(f, f (2)(f, f)),
k −→f (1)f (1)f (2)(f, f).
Thus, we get:
∇F ∗(t∗) = f (3)(f, f, f(1)f) −2f (1)f (2)(f, f(1)f)
−f (2)(f, f(2)(f, f)) + f (1)f (1)f (2)(f, f).
It is easy to see,
β(t) = ± ν(t)
ν(t∗),
where “±” is selected using the following rule: if d(·) expresses the distance between
the vertex to the root node, i.e., the least number of vertices passed from this vertex to
the root node along the connection between vertices (including initial point and root
node), then sign (β(t)) = (−1)d(t). Using the above example
d(i) = 0,
d(m) = d(l) = d(j) = 1,
d(k) = 2.
By sign (b(u ◦v)) = −sign (b(v ◦u)), we have
(−1)d(t) = sign (b(t))
sign (b(t∗)),
therefore:
∇F ∗(t∗) =

t∈¯t∗
α(t)b(t)
α(t∗)b(t∗) F(t).

7.4 Formal Energy for Symplectic R–K Method
343
Thus, we get
α(t∗)b(t∗)∇F ∗(t∗) =

t∈¯t∗
α(t)b(t)F(t).
Therefore, the lemma is completed.
▲
With the above results, we describe the main result of this section[Hai94].
Theorem 4.16. Given a R–K method (A, b), A = (aij)s×s, b = (b1, b2, · · · , bs)′, its
formal energy is
"H(z, h) = −J

ρ(t)≤N
hρ(t)−1
ρ(t)! α(t)b(t)F ∗(t),
t ∈T "E,
(4.20)
where b(t) is determined by a(t) (According to Table 4.1 to Table 4.4), i.e.,
a(t) = γ(t)
s

j=1
bjφj(t).
Proof. Let the modiﬁed equation be
"˙z =

t∈T P
hr(t)−1
r(t) ! α(t)b(t)F(t)("z),
then
"˙z =

t∗∈T "E
hr(t∗)−1
r(t∗) !

t∈¯t∗
α(t)b(t)F(t)("z)
=

t∗∈T "E
hr(t∗)−1
r(t∗) ! α(t∗)b(t∗)∇F ∗(t∗).
By Lemma 4.10
"Hz = −J

t∗∈T "E
hr(t∗)−1
r(t∗)! α(t∗)b(t∗)∇F ∗(t∗),
which leads to (differ by an arbitrary constant)
"H(z, h) = −J

t∗∈T "E
hr(t∗)−1
r(t∗) ! α(t∗)b(t∗)F ∗(t∗).
The theorem is proved.
▲
Remark 4.17. Literature [Tan94] pointed out that each item of series expansion of for-
mal energy of symplectic R–K scheme has 1 to 1 corresponding relationship with
unrooted trees collection. This theorem speciﬁcally indicates this 1 to 1 correspon-
dences.

344
7. Symplectic Runge–Kutta Methods
Finally we sum up the method to construct the formal energy of a symplectic R–K
method: given a symplectic R–K method (A, b, c), let a(t) = γ(t)

j
bjφj(t). Then
according to Table 4.1 to Table 4.4 identify the corresponding b(t) to each rooted
tree in T "E. Using (4.20), we can directly write the formal energy. Without loss of
generality, in practice we can choose
T "E =

• ,
•
•
•
,
• • •
•
,
•
•
•
• •
,
•
• • •
•
,
•
•
•
•
•
, · · ·
7
.
If we know the order of method or the method are time reversible (symmetrical),
then according to Remark 4.4 and Remark 4.5 many calculations can be left out.
Example 4.18. Centered Euler scheme
zn+1 = zn + hf
zn + zn+1
2

.
Its formal energy[Tan94]:
"H(z, h) =
H(z) + h2
24 Jf (2)(f, f) −7h4
5760 Jf(3)(f, f, f, f)
−h4
480 Jf(2)(f, f, f(1)f) −h4
160 Jf(2)(f (1)f, f (1)f) + O(h6).
Example 4.19. Gauss–Legendre method
1
2 −
√
3
6
1
4
1
4 −
√
3
6
1
2 +
√
3
6
1
4 +
√
3
6
1
4
1
2
1
2
Its formal energy:
"H(z, h) = H(z) + 37h4
8840 Jf(3)(f, f, f, f) + h4
720 Jf(2)(f, f, f(1)f)
+37h4
2880 Jf(1)(f (1)f, f (1)f) + O(h6).
Example 4.20. Diagonal implicit R–K method
1
4
1
4
0
3
4
1
2
1
4
1
2
1
2

7.5 Deﬁnition of a(t) and b(t)
345
Its formal energy
"H(z, h) = H(z) + h2
96 Jf(1)(f, f) + 17h4
10240 Jf(3)(f, f, f, f)
+13h4
2560 Jf(2)(f, f, f(1)f) +
h4
2560 Jf(1)(f (1)f, f (1)f) + O(h6).
7.5 Deﬁnition of a(t) and b(t)
We consider following schemes.
7.5.1 Centered Euler Scheme
1
2
1
a( • ) = 1
a(/•
• ) = 1
b( • ) = 1
b

/•
•

= 0
a
•
•
•

= 3
4
a
• •
•

= 3
2
b
•
•
•

= −1
4
b
• •
•

= 1
2
a
 • • •
•

= 1
2
a

•
•
•
• 
= 1
b
 • • •
•

= 0
b

•
•
•
• 
= 0
a
•
•
•
•

= 3
2
a

•
• •
•

= 3
b
•
•
•
•

= 0
b

•
• •
•

= 0
a
 • ••
• •

= 5
16
a
 •
• • •
•

= 5
8
b
 • ••
• •

= 7
48
b
 •
• • •
•

= 1
24
a
•
•
•
•
•

= 15
16
a

•
•
•
•
• 
= 15
8
b
•
•
•
•
•

= −1
16
b

•
•
•
•
• 
= −3
8

346
7. Symplectic Runge–Kutta Methods
a
•
•
•
•
•
= 5
4
a
• • •
•
•

= 5
4
b
•
•
•
•
•
= 1
4
b
• • •
•
•

= −7
12
a
•
•
•
•
•

= 5
2
a
•
•
• •
•

= 15
4
b
•
•
•
•
•

= −1
6
b
•
•
• •
•

= 1
4
a

•
•
• •
•

= 15
2
b

•
•
• •
•

= 3
2
7.5.2 Gauss–Legendre Method
1
2 −
√
3
6
1
4
1
4 −
√
3
6
1
2 +
√
3
6
1
4 +
√
3
6
1
4
1
2
1
2
a( • ) = 1
a( /•
• ) = 1
b( • ) = 1
b

/•
•

= 0
a(•
•
• ) = 1
a(• •
•
) = 1
b
•
•
•

= 0
b
• •
•

= 0
a(• • •
• ) = 1
a
•
•
•
•

= 1
b
• • •
•

= 0
b
•
•
•
•

= 0
a

•
•
•
• 
= 1
a

•
• •
•

= 1
b

•
•
•
• 
= 0
b

•
• •
•

= 0
a
 •
•
•
• •

= 35
72
a

•
• • •
•

= 35
36
b
 •
•
•
• •

= −37
72
b
 •
• • •
•

= −1
36
a
•
•
•
•
•
= 35
72
b
•
•
•
•
•
= −37
72

7.6 Multistep Symplectic Method
347
7.5.3 Diagonal Implicit R–K Method
1
4
1
4
0
3
4
1
2
1
4
1
2
1
2
a( • ) = 1
a( /•
• ) = 1
b( • ) = 1
b

/•
•

= 0
a(•
•
• ) = 15
16
a
• •
•
) = 9
8
b
•
•
•

= −1
16
b
• •
•

= 1
8
a(• • •
• ) = 1
2
a
•
•
•
•

= 1
b
• • •
•

= 0
b
•
•
•
•

= 0
a

•
•
•
• 
= 3
2
a

•
• •
•

= 3
b

•
•
•
• 
= 0
b

•
• •
•

= 0
a
 •
•
•
• •

= 205
256
a
 •
• • •
•

= 115
128
b
 •
•
•
• •

= −51
256
b
 •
• • •
•

= −13
128
a
•
•
•
•
•
= 65
64
b
•
•
•
•
•
= −1
64
7.6 Multistep Symplectic Method
We present in this section Multistep method for Hamiltonian system.
7.6.1 Linear Multistep Method
Consider the autonomous ODEs on Rn
d z
d t = a(z),
(6.1)
where z = (z1, · · · , zn) and a(z) = (a1(z), · · · , an(z)) is a smooth vector ﬁeld on
Rn. For Equations (6.1) we deﬁne a linear m step method (LMM) in standard form
by
m

j=0
αjzj = τ
m

j=0
βjQj,
(6.2)
where αj and βj are constants subject to the conditions
αm = 1,
|α0| + |β0| ̸= 0.

348
7. Symplectic Runge–Kutta Methods
If m = 1, we call (6.2) a single step method. Otherwise, we call it a multi-step method.
The linearity means that the right hand of (6.2) linearly depends on the value of a(z)
on integral points. For compatibility of (6.2) with Equation (6.1), it must be of at least
order one and thus satisﬁes
(1)
α1 + α2 + · · · + αm = 0;
(2)
β0 + β1 + · · · + βm =
m

j=0
jαj ̸= 0.
LMM method (6.2) has two characteristic polynomials
ξ(λ) =
m

i=0
αiλi,
σ(λ) =
m

i=0
βiλi.
(6.3)
Equation (6.2) can be written as
ξ(E) = τa(σ(E)yn).
(6.4)
In next subsection, we propose a new deﬁnition for symplectic multi-step methods.
This new deﬁnition differs from the old ones given for the single step method. It
is deﬁned directly on M which corresponds to the m step scheme deﬁned on M,
while the old deﬁnitions are given by deﬁning a corresponding one step method on
M × M × · · · × M = M m with a set of new variables. The new deﬁnition introduces
a step transition operator g : M →M. Under our new deﬁnition, the leap-frog method
is symplectic only for linear Hamiltonian systems. The transition operator g will be
constructed via continued fractions and rational approximation.
7.6.2 Symplectic LMM for Linear Hamiltonian Systems
First we consider a linear Hamiltonian system
d z
d t = az,
(6.5)
where a is an inﬁnitesimal 2n × 2n symplectic matrix a ∈sp(2n). Its phase ﬂow is
z(t) = exp (ta)z0. The LMM for (6.5) is
αmzm + · · · + α1z1 + α0z0 = τa(βmzm + · · · + β1z1 + β0z0).
(6.6)
Our goal is to ﬁnd a matrix g, i.e., a linear transformation g : R2n →R2n which
can satisfy (6.6)
αmgm(z0)+· · ·+α1g(z0)+α0z0 = τa

βmgm(z0)+· · ·+β1g(z0)+β0z0

. (6.7)
Such a map g exists for sufﬁciently small τ and can be represented by continued
fractions and rational approximations. We call this transformation step transition
operator[Fen98b].
Deﬁnition 6.1. If g is a symplectic transformation, then its corresponding LMM (6.6)
is symplectic (we simply call the method SLMM).

7.6 Multistep Symplectic Method
349
From (6.7), we have
τa = α0I + α1g1 + · · · + αmgm
β0I + β1g1 + · · · + βmgm .
(6.8)
The characteristic equation for LMM is
ξ(λ) = τμσ(λ),
(6.9)
where μ is the eigenvalue of the inﬁnitesimal symplectic matrix a and λ is the eigen-
value of g.
Let
ψ(λ) = ξ(λ)
σ(λ),
(6.10)
then (6.9) can be written as
τμ = ψ(λ).
(6.11)
Its inverse function is
λ = φ(τμ).
(6.12)
To study the symplecticity of the LMM, one only needs to study the properties
of functions φ and ψ. We will see that if φ is of the exponential form or ψ is of
logarithmic form, the corresponding LMM is symplectic. We ﬁrst study the properties
of the exponential functions and logarithmic functions.
Explike and loglike functions
First we describe the properties of exponential functions:
(1)
exp (x)|x=0 = 1.
(2)
d
d x exp (x)|x=0 = 1.
(3)
exp (x + y) = exp (x) · exp (y).
If we substitute y with −x, we have
exp (x) exp (−x) = 1.
(6.13)
Deﬁnition 6.2. If a function φ(x) satisﬁes φ(0) = 1, φ′(0) = 1 and φ(x)φ(−x) = 1,
we call this function an explike function.
It is well known that the inverse function of an exponential function is a logarith-
mic function x →log (x). It has the following properties:
(1)
log x|x=1 = 0;
(2)
d
d x log x|x=1 = 1;
(3)
log xy = log x + log y.
If we take y = 1
x, we get
log x + log 1
x = 0.
(6.14)

350
7. Symplectic Runge–Kutta Methods
Deﬁnition 6.3. If a function ψ satisﬁes ψ(1) = 0, ψ′(1) = 1, and
ψ(x) + ψ
% 1
x
&
= 0,
(6.15)
we call it a loglike function.
Obviously, polynomials can not be explike functions or loglike functions, so we
try to ﬁnd explike and loglike functions in the form of rational functions.
Theorem 6.4. [Fen98b] LMM is symplectic for linear Hamiltonian systems iff its step
transition operator g = φ(τa) is explike, i.e., φ(μ)·φ(−μ) = 1, φ(0) = 1, φ′(0) = 1.
Theorem 6.5. [Fen98b] LMM is symplectic for linear Hamiltonian systems iff ψ(λ) =
ξ(λ)
σ(λ) is a loglike function, i.e., ψ(λ) + ψ
 1
λ

= 0, ψ(1) = 0, ψ′(1) = 1.
Proof. From Theorem 6.4, we have φ(μ)φ(−μ) = 1, so λ = φ(μ), 1
λ = φ(−μ). The
inverse function of φ satisﬁes ψ(λ) = μ, ψ
 1
λ

= −μ, i.e., ψ(λ) + ψ
 1
λ

= 0,
ψ(1) = 0, ψ′(1) = 1 follows from consistency condition (1), (2).
On the other side, if ψ(λ) = −ψ
 1
λ

, let ψ(λ) = μ, then its inverse function is
φ(μ) = λ and φ(−μ) = 1
λ, we then have φ(μ) · φ(−μ) = 1.
▲
Theorem 6.6. If ξ(λ) is a antisymmetric polynomial, σ(λ) is a symmetric one, then
ψ(λ) = ξ(λ)
σ(λ), satisﬁes
ψ(1) = 0,
ψ
 1
λ

+ ψ(λ) = 0.
Proof. Since
ξ(λ) = λmξ
 1
λ

=
m

i=0
am−iλi = −
m

i=1
aiλi = −ξ(λ),
σ(λ) = λmσ
 1
λ

=
m

i=0
βm−iλi =
m

i=1
βiλi = σ(λ),
ψ(λ) = ξ(λ)
σ(λ),
ψ
 1
λ

=
ξ
% 1
λ
&
σ
% 1
λ
& =
λmξ
% 1
λ
&
λmσ
% 1
λ
& = −ξ(λ)
σ(λ) ,
we obtain ψ(λ) + ψ
 1
λ

= 0. Now ξ(1) =
m

k=0
αk = 0, σ(1) =
m

k=0
βk ̸= 0, then
ψ(1) = ξ(1)
σ(1) = 0.
▲

7.6 Multistep Symplectic Method
351
Corollary 6.7. If above generating polynomial is consistent with ODE (6.1), then
ψ(λ) is loglike function, i.e., ψ
 1
λ

+ ψ(λ) = 0, ψ(1) = 0, ˙ψ(1) = 1.
Proof. ψ′(1) =
˙ξσ −˙ξξ
σ2
=
˙ξ(1)
σ(1) = 1. This condition is just consistence condition. ▲
Theorem 6.8. Let ψ(λ) = ξ(λ)
σ(λ) irreducible loglike function, then ξ(λ) is an anti-
symmetric polynomial while σ(λ) is a symmetric one.
Proof. We write formally
ξ(λ) = αmλm + αm−1λm−1 + · · · + α1λ + α0,
σ(λ) = βmλm + βm−1λm−1 + · · · + β1λ + β0.
If deg ξ(λ) = p < m, set ai = 0 for i > p; if deg σ(λ) = q < m, set βi = 0 for
i > q. ψ(1) = 0 ⇒ξ(1) = 0, since otherwise, if ξ(1) ̸= 0, then ψ(1) = ξ(1)
σ(1) ̸= 0.
Now ξ(1) = 0 ⇔σ(1) ̸= 0, since otherwise ξ(1) = σ(1) ⇒ξ(λ), σ(λ) would have
common factor. So we have
ξ(1) =
m

k=0
αk =
p

k=0
αk = 0,
σ(1) =
m

k=0
βk =
q

k=0
βk ̸= 0.
If m = deg ξ = p, then am = ap ̸= 0. If m = deg σ = q, then βm = βp ̸= 0.
ψ
 1
λ

=
ξ
% 1
λ
&
σ
% 1
λ
& =
λmξ
% 1
λ
&
λmσ
% 1
λ
& = ξ(λ)
σ(λ).
Since ψ(λ) + ψ
 1
λ

= 0, we have
ξ(λ)
σ(λ) = −ξ(λ)
σ(λ) ⇐⇒ξ(λ)σ(λ) = −ξ(λ)σ(λ)
=⇒ξ(λ)|ξ(λ)σ(λ) and σ(λ)|σ(λ)ξ(λ).
Since ξ(λ), σ(λ) have no common factor, then ξ(λ)|ξ(λ),
σ(λ)|σ(λ). If m =
deg ξ(λ) ⇒deg ξ ≤deg ξ ⇒∃c,
ξ(λ) = cξ(λ) =⇒σ(λ) = −cσ(λ).
Since αm ̸= 0 ⇒αmλm + αm−1λm−1 + · · · + α0 = c(αm + · · · + α0wn) ⇒αm =
cα0, α0 = cαm ⇔αm = c2αm, therefore c2 = 1, c = ±1. Suppose c = +1, then

352
7. Symplectic Runge–Kutta Methods
σ(λ) = −¯σ(λ), and
m

k=0
βk = σ(1), then−¯σ(1) = σ(1) ⇔σ(1) = 0, which leads to
a contradiction with the assumption σ(1) ̸= 0. Therefore c = −1, i.e.,
ξ(λ) = −˜ξ(λ),
αj = −αm−j,
j = 0, 1, · · · , m,
σ(λ) = ˜σ(λ),
βj = βm−j,
j = 0, 1, · · · , m.
The theorem is proved.
▲
The proof for the case m = deg σ(λ) proceeds in exactly the same manner as above.
7.6.3 Rational Approximations to Exp and Log Function
1.
Leap-frog scheme
We ﬁrst study a simple example:
z2 = z0 + 2τaz1.
(6.16)
Let z1 = cz0, then z0 = c−1z1, insert this equation into (6.16),we get
z2 = 2τaz1 + 1
c z1 =
%
2τa + 1
c
&
z1 = d1z1,
z1 =
1
2τa + 1
c
z2 = z2
d1 ,
z3 = z1 + 2τaz2 =
⎛
⎜
⎝2τa +
1
2τa + 1
c
⎞
⎟
⎠z2 = d2z2,
z2 =
1
2τa +
1
2τa + 1
c
z3,
z4 =
⎛
⎜
⎜
⎜
⎜
⎜
⎝
2τa +
1
2τa +
1
2τa + 1
c
⎞
⎟
⎟
⎟
⎟
⎟
⎠
= d4z3,
· · · .
Where dk can be written in the form of continued fractions
dk = 2τa +
1
2τa+
1
2τa+ · · · +
1
2τa+ · · ·,
(6.17)
lim
k→∞dk = g = τa +

1 + (τa)2.
(6.18)
We assume the transition operator of Leap-frog to be g, from (6.16) we have
g2 −1 = 2τag,
now we have g = τa ±

1 + (τa)2. Here only sign + is meaningful, thus g =
τa +

1 + (τa)2 which is just the limit of continued fraction (6.17). It is easy to
verify that g is explike, i.e., g(μ)g(−μ) = 1. So the Leap-frog scheme is symplectic
for linear Hamiltonian systems according to our new deﬁnition.

7.6 Multistep Symplectic Method
353
2.
Exponential function
exp(z) = 1 +
∞

k=1
zk
k! .
(6.19)
We have Lagrange’s continued function
exp (z) = 1 + z
1+
−z
2 + · · · +
z
2n −1+
−z
2 +· · ·
= b0 + a1
b1 +
a2
b2 + · · · +
a2n−1
b2n−1 +
a2n
b2n +· · ·,
(6.20)
where
a1 = z, a2 = −z, · · · , a2n−1 = z, a2n = −z,
n ≥1,
b0 = 1, b1 = 1, b2 = 2, · · · , b2n−1 = 2n −1, b2n = 2,
n ≥1,
and Euler’s contract expansion
exp (z) = 1 +
2z
2 −z +
z2
6 + · · · +
z2
2(2n −1)+ · · ·
= B0 + A1
B1 +
A2
B2 + · · · +
An
Bn + · · ·,
(6.21)
where
A1 = 2z, A2 = z2, · · · , An = z2,
n ≥2,
B0 = 1, B1 = 2 −z, B2 = 6, · · · , Bn = 2(2n −1),
n ≥2.
We have
P0
Q0 = p0
q0 = 1,
p1
q1 = 1 + z
1
,
p2
q2 = P1
Q1 = 2 + z
2 −z ,
p3
q3 = 6 + 4z + z2
6 −2z
,
p4
q4 = P2
Q2 = 12 + 6z + z2
12 −6z + z2 + · · · .
(6.22)
In general p2n−1(z) is a polynomial of degree n, q2n−1 is a polynomial of degree n−1,
so p2n−1
q2n−1 is not explike. While p2n = Pn(x), q2n = Qn(x) are both polynomials of
degree n and from the recursions
P0 = 1,
P1 = 2 + z,
Pn = z2Pn−2 + 2(2n −1)Pn−1,
Q0 = 1,
Q1 = 2 −z,
Qn = z2Qn−2 + 2(2n −1)Qn−1.
(6.23)
It’s easy to see that for n = 0, 1, · · ·,
Qn(z) = Pn(−z),
Pn(0) > 0.
So the rational function
φn(z) = Pn(z)
Qn(z) = Pn(z)
Pn(−z)
is explike and

354
7. Symplectic Runge–Kutta Methods
φn(z) −exp(z) = o(|z|2n+1),
where
P0 = 1,
P1 = 2+z,
Pn(z) = z2Pn−2(z)+2(2n−1)Pn−1(z),
n ≥2. (6.24)
This is just the diagonal Pad´e approximation.
3.
Logarithmic function
log w =
∞

k=1
(w −1)k
kwk
,
(6.25)
we have the Lagrange’s continued fraction
log w =
w −1
1
+
w −1
2
+
w −1
3
+
2(w −1)
2
+ · · · +
(n −1)(w −1)
2n −1
+
n(w −1)
2
+ · · ·
=
a1
b1 +
a2
b2 +
a3
b3 +
a4
b4 + · · · +
a2n−1
b2n−1 +
a2n
b2n + · · ·,
(6.26)
where
a1 = w −1,
a2 = w −1,
a3 = w −1,
a4 = 2(w −1),
· · · ,
b0 = 0,
b1 = 1,
b2 = 2,
b3 = 3,
b4 = 2,
· · · ,
and
a2n−1 = (n −1)(w −1),
a2n = n(w −1),
n ≥2,
b2n−1 = 2n −1,
b2n = 2,
n ≥2,
and the Euler’s contracted expansion
log w = 2(w −1)
w + 1 –
2(w −1)
6(w + 1)–

2 × 2(w −1)
2
2.5(w + 1)
– · · · –

2(n −1)(w −1)
2
2(2n −1)(w + 1) – · · ·
= A1
B1 +
A2
B2 +
A3
B3 + · · · +
An
Bn + · · ·,
(6.27)
where
A1 = 2(w −1),
A2 = −2(w −1), · · · , An = −(2(n −1)(w −1))2,
n ≥3,
B0 = 0, B1 = w + 1, B2 = 6(w + 1), · · · , Bn = 2(2n −1)(w + 1),
n ≥2.
The following can be obtained by recursion
P0
Q0 = p0
q0 = 0,
p1
q1 = w −1,
p2
q2 = P1
Q1 = 2(w −1)
w + 1 ,
p3
q3 = w2 + 4w −5
4w + 2
,
p4
q4 = P2
Q2 =
3(w2 −1)
w2 + 4w + 1.
(6.28)
In general
p2n−1(w)
q2n−1(w) −log (w) = O (|w −1|2n),
p2n(w)
q2n(w) −log (w) = O (|w −1|2n+1).
The rational function p2n−1(w)
q2n−1(w) approximates log w only by odd order 2n −1, it does
not reach the even order 2n, and is not loglike. However

7.6 Multistep Symplectic Method
355
Rn = ψn(w) = p2n(w)
q2n(w) = Pn(w)
Qn(w)
is a loglike function. In fact, by recursion, it’s easy to see that
Pn(w) = −wnPn
% 1
w
&
,
Qn(w) = wnQn
% 1
w
&
,
(6.29)
and ∀n, Qn(1) ̸= 0.We also have
P0 = 0,
P1(w) = 2(w −1),
P2(w) = 3(w2 −1),
Q0 = 1,
Q1(w) = w + 1,
Q2(w) = w2 + 4w + 1,
and for n ≥3,
Pn(w) = −(2(n −1)(w −1)2Pn−2(w) + 2(2n −1)(w −1)Pn−2(w)),
Qn(w) = −((2n −1)(w −1)2Qn−2(w) + 2(2n −1)(w −1)Qn−2(w)).
(6.30)
So we see R1(λ) is just the Euler midpoint rule and R2(λ) =
3(λ2 −1)
λ2 + 4λ + 1 is just the
Simpson scheme.
Conclusion: The odd truncation of the continued fraction of the Lagrange’s ap-
proximation to exp(x) and log (x) is neither explike nor loglike, while the even trun-
cation is explike and loglike. The truncation of the continued fraction obtained from
Euler’s contracted expansion is explike and loglike.
4.
Obreschkoff formula
Another rational approximation to a given function is the Obreschkoff formula[Obr40]:
Rm,n(x) =
n

k=0
Ck
n
Ck
m+n k!(x0 −x)kf (k)(x) −
m

k=0
Ck
m
Ck
m+n k !
(x −x0)kf (k)(x0)
=
1
(m + n)!
- x
x0
(x −t)m(x0 −t)nf m+n+1(t)dt.
(6.31)
(1)
Take f(x) = ex, x0 = 0, we obtain Pad´e approximation exp(x) .= Rm,n(x).
If m = n, we obtain Pad´e approximation Rm,m(x).
(2)
Take f(x) = log(x), x0 = 1, we obtain log(x) .= Rm,n(x). If m = n, we
obtain loglike function Rm(x),
Rm(λ) =
1
λm
m

k=1
Ck
m
Ck
2mk
(λ −1)k(λm−k + (−1)k−1λm),
i.e.,
Rm(λ) + Rm
% 1
λ
&
= 0.
We have

356
7. Symplectic Runge–Kutta Methods
Rm(λ) −log (λ) = O (|λ|2m+1),
R1 = λ2 −1
2λ
,
R2 =
1
12λ2 (−λ4 + 8λ3 −8λ + 1),
R3 =
1
60λ3 (λ6 −9λ5 + 45λ4 −45λ2 + 9λ −1),
· · ·
where R1(λ) is just the leap-frog scheme.
5.
Nonexistence of SLMM for Nonlinear Hamiltonian Systems (Tang Theorem)
For nonlinear Hamiltonian systems, there exists no symplectic LMM. When equa-
tion (6.1) is nonlinear, how to deﬁne a symplectic LMM? The answer is to ﬁnd the
step-transition operator g : Rn →Rn, let
z = g0(z),
z1 = g(x),
z2 = g(g(z)) = g ◦g(z) = g2(z),
...
zn = g(g(· · · (g(z)) · · ·)) = g ◦g ◦· · · ◦g ◦(z) = gn(z),
(6.32)
we get from (6.2)
k

i=0
αigi(z) = τ
n

i=0
βif ◦gi(z).
(6.33)
It’s easy to prove that if LMM (6.33) is consistent with Equation (6.1), then for smooth
f and sufﬁciently small step-size τ, the operator g deﬁned by (6.32) exists and it can
be represented as a power series in τ and with ﬁrst term equal to identity. Consider a
case where Equation (6.1) is a Hamiltonian system, i.e., a(z) = J∇H(z), we have
the following deﬁnition.
Deﬁnition 6.9. LMM is symplectic if the transition operator g deﬁned by (6.32) is
symplectic for all H(z) and all step-size τ, i.e.,
gT
∗Jg∗(z) = J.
(6.34)
This deﬁnition is a completely different criterion that can include the symplec-
tic condition for one-step methods in the usual sense. But Tang in[Tan93a] has proved
that nonlinear multistep method can satisfy such a strict criterion. Numerical experi-
ments of Li[Fen92b] show that the explicit 3-level centered method (Leap-frog method)
is symplectic for linear Hamiltonian systems H = 1
2(p2 + 4q2) (see Fig. 0.2 in
introduction of this book) but is non-symplectic for nonlinear Hamiltonian systems
H = 1
2(p2 + q2) + 2
3q4 (see Fig. 0.3 (a,b,c) in introduction of this book).

Bibliography
[AS93] L. Abia and J.M. Sanz-Serna: Partitioned Runge–Kutta methods for separable Hamil-
tonian problems. Math. Comp., 60:617–634, (1993).
[But87] J.C. Butcher: The Numerical Analysis of Ordinary Differential Equations. John Wiley,
Chichester, (1987).
[CH95] M.P. Calvo and E. Hairer: Further reduction in the number of independent order condi-
tions for symplectic, explicit partitioned Runge-Kutta and Runge–Kutta–Nystr¨om methods.
Appl. Numer. Math., 18:107–114, (1995).
[Chi97] S. A. Chin: Symplectic integrators from composite operator factorization. Physics
Letters A, 226:344–348, (1997).
[Coo87] G. J. Cooper: Stability of Runge–Kutta methods for trajectory problems. IMA J.
Numer. Anal., 7:1–13, (1987).
[CS93] M.P. Calvo and J.M. Sanz-Serna: High-order symplectic Runge-Kutta-Nystr¨om meth-
ods. SIAM J. Sci. Comput., 114:1237–1252, (1993).
[CS94] M.P. Calvo and J.M. Sanz-Serna: Canonical B-Series. Numer. Math., 67:161–175,
(1994).
[DV84] K. Dekker and J.G. Verwer: Stability of Runge-Kutta Methods for Stiff Initial Value
Problems. North-Holland, Amsterdam, (1984).
[Fen65] K. Feng: Difference schemes based on variational principle. J. of Appl. and Comput.
Math.in Chinese, 2(4):238–262, (1965).
[Fen85] K. Feng: On difference schemes and symplectic geometry. In K. Feng, editor, Pro-
ceedings of the 1984 Beijing Symposium on Differential Geometry and Differential Equa-
tions, pages 42–58. Science Press, Beijing, (1985).
[Fen86a] K. Feng:
Canonical Difference Schemes for Hamiltonian Canonical Differential
Equations. In International Workshop on Applied Differential Equations (Beijing, 1985),
pages 59–73. World Sci. Publishing, Singapore, (1986).
[Fen86b] K. Feng: Difference schemes for Hamiltonian formalism and symplectic geometry.
J. Comput. Math., 4:279–289, (1986).
[Fen86c] K. Feng: Symplectic geometry and numerical methods in ﬂuid dynamics. In F.G.
Zhuang and Y.L. Zhu, editors, Tenth International Conference on Numerical Methods in
Fluid Dynamics, Lecture Notes in Physics, pages 1–7. Springer, Berlin, (1986).
[Fen91] K. Feng: The Hamiltonian Way for Computing Hamiltonian Dynamics. In R. Spigler,
editor, Applied and Industrial Mathematics, pages 17–35. Kluwer, The Netherlands, (1991).
[Fen92a] K. Feng: Formal power series and numerical methods for differential equations. In
T. Chan and Z.C. Shi, editors, International conf. on scientiﬁc computation, pages 28–35.
World Scientiﬁc, Singapore, (1992).
[Fen92b] K. Feng: How to compute property Newton’s equation of motion. In L. A. Ying,
B.Y. Guo, and I. Gladwell, editors, Proc of 2nd Conf. on Numerical Method for PDE’s,
pages 15–22.World Scientiﬁc, Singapore, (1992). Also see Collected Works of Feng Kang.
Volume I, II. National Defence Industry Press, Beijing, (1995).
[Fen93a] K. Feng: Formal dynamical systems and numerical algorithms. In K. Feng and
Z.C Shi, editors, International conf. on computation of differential equationsand dynamical
systems, pages 1–10. World Scientiﬁc, Singapore, (1993).

358
Bibliography
[Fen93b] K. Feng: Symplectic, contact and volume preserving algorithms. In Z.C. Shi and
T. Ushijima, editors, Proc.1st China-Japan conf. on computation of differential equation-
sand dynamical systems, pages 1–28. World Scientiﬁc, Singapore, (1993).
[Fen95] K. Feng: Collected Works of Feng Kang. volume I,II. National Defence Industry
Press, Beijing, (1995).
[Fen98a] K. Feng: The calculus of generating functions and the formal energy for Hamiltonian
systems. J. Comput. Math., 16:481–498, (1998).
[Fen98b] K. Feng: The step-transition operator for multi-step methods of ODEs. J. Comput.
Math., 16(3), (1998).
[FQ87] K. Feng and M.Z. Qin: The symplectic methods for the computation of Hamiltonian
equations. In Y. L. Zhu and B. Y. Guo, editors, Numerical Methods for Partial Differential
Equations, Lecture Notes in Mathematics 1297, pages 1–37. Springer, Berlin, (1987).
[FQ91a] K. Feng and M.Z. Qin: Hamiltonian Algorithms for Hamiltonian Dynamical Systems.
Progr. Natur. Sci., 1(2):105–116, (1991).
[FQ91b] K. Feng and M.Z. Qin: Hamiltonian algorithms for Hamiltonian systems and a com-
parative numerical study. Comput. Phys. Comm., 65:173–187, (1991).
[FQ03] K. Feng and M. Q. Qin: Symplectic Algorithms for Hamiltonian Systems. Zhejiang
Science and Technology Publishing House, Hangzhou, in Chinese, First edition, (2003).
[FW91a] K. Feng and D.L. Wang:
A note on conservation laws of symplectic difference
schemes for Hamiltonian systems. J. Comput. Math., 9(3):229–237, (1991).
[FW91b] K. Feng and D.L. Wang: Symplectic difference schemes for Hamiltonian systems in
general symplectic structure. J. Comput. Math., 9(1):86–96, (1991).
[FW94] K. Feng and D.L. Wang: Dynamical systems and geometric construction of algo-
rithms. In Z. C. Shi and C. C. Yang, editors, Computational Mathematics in China, Con-
temporary Mathematics of AMS Vol 163, pages 1–32. AMS, (1994).
[FW98] K. Feng and D.L. Wang: On variation of schemes by Euler. J. Comput. Math., 16:97–
106, (1998).
[FWQ90] K. Feng, H.M. Wu, and M.Z. Qin: Symplectic difference schemes for linear Hamil-
tonian canonical systems. J. Comput. Math., 8(4):371–380, (1990).
[FWQW89] K. Feng, H.M. Wu, M.Z. Qin and D.L. Wang: Construction of canonical dif-
ference schemes for Hamiltonian formalism via generating functions. J. Comput. Math.,
7:71–96, (1989).
[Ge88] Z. Ge: Symplectic geometry and its application in numerical analysis. PhD thesis,
Computer Center, CAS, (1988).
[Ge90] Z. Ge: Generating functions, Hamilton–Jacobi equations and symplectic groupoids on
Poisson manifolds. Indiana Univ. Math. J., 39:859, (1990).
[Ge91] Z. Ge: Equivariant symplectic difference schemes and generating functions. Physica
D, 49:376–386, (1991).
[Ge95] Z. Ge: Symplectic integrators for Hamiltonian systems. In W. Cai et al., editor, Nu-
merical Methods in Applied Sciences, pages 97–108, Science Press, New York, (1995).
[Gon96] O. Gonzalez: Time integration and discrete Hamiltonian systems. J. Nonlinear. Sci.,
6:449–467, (1996).
[Hai94] E. Hairer: Backward analysis of numerical integrators and symplectic methods. Annals
of Numer. Math., 1:107–132, (1994).
[Hai97b] E. Hairer: Variable time step integration with symplectic methods. Appl. Numer.
Math., 25:219–227, (1997).
[Hai99] E. Hairer: Backward error analysis for multistep methods. Numer. Math., 84:199–232,
(1999).
[Hai00] E. Hairer: Symmetric projection methods for differential equations on manifolds. BIT,
40:726–734, (2000).
[Hai01] E. Hairer: Geometric integration of ordinary differential equations on manifolds. BIT,
41:996–1007, (2001).
[Hai03] E. Hairer: Global modiﬁed Hamiltonian for constrained symplectic integrators. Nu-
mer. Math., 95:325–336, (2003).

Bibliography
359
[Hen62] P. Henrici: Discrete Variable Methods in Ordinary Differential Equations. John Wiley
& Sons, Inc., New York, Second edition, (1962).
[HL97a] E. Hairer and P. Leone: Order barriers for symplectic multi-value methods. In D.F.
Grifysis, D.F.Higham, and G.A. Watson, editors, Numerical Analysis 1997 Proc.of the 17-
th Dundee Biennial Conference,June 24-27, 1997, Pitman Reserch Notes in math. series
380, pages 133–149, (1997).
[HL97b] E. Hairer and Ch. Lubich: The life-span of backward error analysis for numerical
integrators. Numer. Math., 76:441–462, (1997).
[HL97c] M. Hochbruck and Ch. Lubich: On Krylov subspace approximations to the matrix
exponential operator. SIAM J. Numer. Anal., 34(5), (1997).
[HL97d] W. Huang and B. Leimkuhler: The adaptive Verlet method. SIAM J. Sci. Comput.,
18(1):239, (1997).
[HL99a] E. Hairer and Ch. Lubich: Invariant tori of dissipatively perturbed Hamiltonian sys-
tems under symplectic discretization. Appl. Numer. Math., 29:57–71, (1999).
[HL99b] M. Hochbruck and Ch. Lubich: Exponential integrators for quantum-classical molec-
ular dynamics. BIT, 39:620–645, (1999).
[HL00a] E. Hairer and P. Leone: Some properties of symplectic Runge–Kutta methods. New
Zealand J. of Math., 29:169–175, (2000).
[HL00b] E. Hairer and Ch. Lubich:
Energy conservation by St¨ormer-type numerical inte-
grators. In G.F. Grifﬁths and G.A. Watson, editors, In Numerical Analysis 1999, pages
169–190. CRC Press LLC, (2000).
[HL00c] E. Hairer and Ch. Lubich: Long-time energy conservation of numerical methods for
oscillatory differential equations. SIAM J. Numer. Anal., 38:414–441, (2000).
[HL00d] J. L. Hong and Y. Liu: Symplectic integration of linear discontinues Hamiltonian
systems. Neural Parallel Sci Comput., 8:317–325, (2000).
[HL03] M. Hochbruck and C. Lubich: On magnus integrators for time-dependent Schr¨odinger
equations. SIAM J. Numer. Anal., 41:945–963, (2003).
[HL04a] E. Hairer and C. Lubich: symmetric multistep methods over long times. Numer.
Math., 97:699–723, (2004).
[HLR01] T. Holder, B. Leimkuhler, and S. Reich:
Explicit variable step-size and time-
reversible integration. Appl. Numer. Math., 39:367–377, (2001).
[HLS98] M. Hochbruck, C. Lubich, and H. Selhofer: Exponential integrators for large systems
of differential equations. SIAM J. Sci. Comput., 19(5):1552–1574, (1998).
[HLW02] E. Hairer, Ch. Lubich, and G. Wanner: Geometric Numerical Integration. Num-
ber 31 in Springer Series in Computational Mathematics. Springer-Verlag, (2002).
[HLW03] E. Hairer, C. Lubich and G. Wanner:
Geometric integration illustrated by the
St¨ormer-Verlet method. Acta Numerica, pages 399–450, (2003).
[HM04] P. Hydon and E.L. Mansﬁeld: A variational complex for difference equations. Foun-
dations of Computational Mathematics, 4:187–217, (2004).
[HMM95] P. Hut, J. Makino and S. McMillan:
Building a better leapfrog.
Astrophys. J.,
443:L93–L96, (1995).
[HMSS93] E. Hairer, A. Murua and J.M. Sanz-Serna: The non-existence of symplectic multi-
derivative Runge–Kutta methods. Preprint, (1993).
[HNW93] E. Hairer, S. P. Nørsett, and G. Wanner: Solving Ordinary Differential Equations I,
Nonstiff Problems. Springer-Verlag, Second revised edition, (1993).
[HOS99] D.J. Hardy, D.I. Okunbor, and R.D. Skeel: Symplectic variable step size integration
for n-body problems. Appl. Numer. Math., 29:19–30, (1999).
[HS81] W. H. Hundsdorfer and M. N. Spijker: A note on B-stability of Runge–Kutta methods.
Numer. Math., 36:319–331, (1981).
[HS94] A. R. Humphries and A. M. Stuart: Runge-Kutta methods for dissipative and gradient
dynamical systems. SIAM J. Numer. Anal., 31(5):1452–1485, (1994).
[HS97a] E. Hairer and D. Stoffer: Reversible long-term integration with variable stepsizes.
SIAM J. Sci. Comput., 18:257–269, (1997).

360
Bibliography
[HS05] E. Hairer and G. S¨oderlind: Explicit time reversible adaptive step size control. SIAM
J. Sci. Comput., 26:1838–1851, (2005).
[HW74] E. Hairer and G. Wanner: On the Butcher group and general multivalue methods.
Computing, 13:1–15, (1974).
[HW81] E. Hairer and G. Wanner: Algebraically stable and implementable Runge–Kutta meth-
ods of high order. SIAM J. Numer. Anal., 18:1098–1108, (1981).
[HW91] E. Hairer and G. Wanner:
Solving Ordinary Differential Equations II, Stiff and
Differential-Algebraic Problems. Springer, Berlin, (1991).
[HW94] E. Hairer and G. Wanner: Symplectic Runge-Kutta methods with real eigenvalues.
BIT, 34:310–312, (1994).
[HW96] E. Hairer and G. Wanner:
Solving Ordinary Differential Equations II. Stiff and
Differential-Algebraic Problems, 2nd edition, Springer Series in Computational Mathemat-
ics 14. Springer-Verlag Berlin, Second edition, (1996).
[IA88] T. Itoh and K. Abe: Hamiltonian-conserving discrete canonical equations based on
variational difference quotients. J. of Comp. Phys., 76:85–102, (1988).
[Jay96] L. O. Jay: Symplectic partitioned Runge–Kutta methods for constrained Hamiltonian
systems. SIAM J. Numer. Anal., 33:368–387, (1996).
[Jay97] L. O. Jay: Lagrangian integration with symplectic methods. Technical Report AH-
PCRC Preprint 97-009, University of Minnesota, (1997).
[Jay99] L. O. Jay:
Structure preservation for constrained dynamics with super partitioned
additive Runge–Kutta methods. SIAM J. Sci. Comput., 20(2):416–446, (1999).
[Jim94] S. Jim´enez: Derivation of the discrete conservation laws for a family of ﬁnite differ-
ence schemes. Applied Mathematics and Computation, 64:13–45, (1994).
[JL06] Z. Jia and B. Leimkuhler: Geometric integrators for multiple time-scale simulation. J.
Phys. A: Math. Gen., 39:5379–5403, (2006).
[Kar96a] B. Karas¨ozen: Comparison of reversible integrators for a Hamiltonian in normal
form. In E. Kreuzer and O. Mahrenholz, editors, Proceedings of the Third International
Congress on Industrial and Applied Mathematics, ICIAM 95, Issue 4: Applied Sciences,
especially Mechanics (Minisymposia), pages 563–566, (1996).
[Kar96b] B. Karas¨ozen: Composite integrators for Bi-Hamiltonian systems. Comp. & Math.
with Applic., 32:79–86, (1996).
[Kar96c] B. Karas¨ozen: Numerical Studies on a Bi-Hamiltonian H´enon-Heiles System. Tech-
nical Report No 133, Middle East Technical University, Department of Mathematics,
Ankara, Turkey, (1996).
[Kar97] B. Karas¨ozen: Reﬂexive methods for dynamical systems with conserved quantities.
Technical Report Nr. 1897, Technische Hochschule Darmstadt, FB Mathematik, (1997).
[KHL08] L. H. Kong, J. L. Hong, and R. X. Liu:
Long-term numerical simulation of the
interaction between a neutron ﬁeld and meson ﬁeld by a symplectic-preserving scheme. J.
Phys. A: Math. Theor., 41:255207, (2008).
[Kir86] U. Kirchgraber: Multi-step methods are essentially one-step methods. Numer. Math.,
48:85–90, (1986).
[Lam91] J.D. Lambert: Numerical Methods for Ordinary Differential Equations, The Initial
Value Problem. Wiley, Chichester, (1991).
[Las88] F.M. Lasagni: Canonical Runge–Kutta methods. Z. Angew. Math. Phys., 39:952–953,
(1988).
[LDJW00] Y.X. Li, P. Z. Ding, M. X. Jin, and C. X. Wu: Computing classical trajectories of
model molecule A2B by symplectic algorithm. Chemical Journal of Chinese Universities,
15(8):1181–1186, (2000).
[Lei99] B. J. Leimkuhler: Reversible adaptive regularization: Perturbed Kepler motion and
classical atomic trajectories. Phil. Trans. Royal Soc. A, 357:1101, (1999).
[Leo00] P. Leone: Symplecticity and Symmetry of General Integration Methods. Th`ese, Section
de Math´ematiques, Universit´e de Gen`eve, Second edition, (2000).
[LP96] B. J. Leimkuhler and G. W. Patrick: A symplectic integrator for Riemannian manifolds.
J. Nonlinear. Sci., 6(4):367–384, (1996).

Bibliography
361
[LP01] L. Lopez and T. Politi: Applications of the cayley approach in the numerical solution
of matrix differential systems on quadratic groups. Appl. Numer. Math., 36:35–55, (2001).
[LQ01] H. W. Li and M. Z. Qin: On the formal energy of symplectic R–K method. Math.
Num. Sinica, 23:75–92, (2001).
[LQHD07] X.S. Liu, Y.Y. Qi, J. F. He, and P. Z. Ding: Recent progress in symplectic algorithms
for use in quantum systems. Communications in Computational Physics, 2(1):1–53, (2007).
[LR94a] B. Leimkuhler and S. Reich: Symplectic integration of constrained Hamiltonian sys-
tems. Math. Comp., 63:589–605, (1994).
[LR05] B. Leimkuhler and S. Reich: Simulating Hamiltonian Dynamics. Cambridge Univer-
sity Press, Cambridge, First edition, (2005).
[LvV97] B. J. Leimkuhler and E. S. van Vleck: Orthosymplectic integration of linear Hamil-
tonian systems. Numer. Math., 77:269–282, (1997).
[LW76] J. D. Lambert and I. A. Watson: Symmetric multistep methods for periodic initial
value problems. J. Inst. Maths. Applics., 18:189–202, (1976).
[LYC06] H. Liu, J.H. Yuan, J.B. Chen, H. Shou, and Y.M. Li: Theory of large-step depth
extrapolation. Chinese journal Geophys., 49(6):1779–1793, (2006).
[McL95c] R. I. McLachlan: On the numerical integration of ODE’s by symmetric composition
methods. SIAM J. Numer. Anal., 16:151–168, (1995).
[McL95d] R. I. McLachlan: On the numerical integration of ordinary differential equations by
symmetric composition methods. SIAM J. Sci. Comput., 16:151–168, (1995).
[McL96] R. I. McLachlan: More on Symplectic Correctors. In Jerrold E. Marsden, George
W. Patrick, and William F. Shadwick, editors, Integration Algorithms and Classical Me-
chanics, volume 10 of Fields Institute Communications. Fields Institute, American Mathe-
matical Society, July (1996).
[McL02] R. McLachlan: Splitting methods. Acta Numerica, 11:341–434, (2002).
[Mie89] S. Miesbach: Symplektische Phasenﬂuß approximation zur Numerischen Integration
Kanonischer Differentialgleichungen. Master’s thesis, Technische Universit¨at M¨unchen,
(1989).
[MP92] S. Miesbach and H.J. Pesch: Symplectic phase ﬂow approximation for the numerical
integration of canonical systems. Numer. Math., 61:501–521, (1992).
[MPQ04] R.I. McLachlan, M. Perlmutter, and G.R.W. Quispel: On the nonlinear stability of
symplectic integrators. BIT, 44:99–117, (2004).
[MQ98a] R. I. McLachlan and G. R. W. Quispel: Generating functions for dynamical systems
with symmetries, integrals, and differential invariants. Physica D, 112:298–309, (1998).
[MQ98b] R.I. McLachlan and G.R.W. Quispel: Numerical integrators that preserve symme-
tries and reversing symmetries. SIAM J. Numer. Anal., 35:586–599, (1998).
[MQ02] R. I. McLachlan and G. R. W. Quispel: Splitting methods. Acta Numerica, 11:341–
434, (2002).
[MQ03] R.I. McLachlan and G.R.W. Quispel: Geometric integration of conservative polyno-
mial ODEs. Appl. Numer. Math., 45:411–418, (2003).
[MQ04] D.I. McLaren and G.R.W. Quispel: Integral-preserving integrators. J. Phys. A: Math.
Gen., 37:L489–L495, (2004).
[MQR98] R. I. McLachlan, G. R. W. Quispel, and N. Robidoux: A uniﬁed approach to Hamil-
tonian systems, Poisson systems, gradient systems, and systems with Lyapunov functions
and/or ﬁrst integrals. Physical Review Letters, 81:2399–2403, (1998).
[MQR99] R. I. McLachlan, G. R. W. Quispel, and N. Robidoux: Geometric integration using
discrete gradients. Phil. Trans. Royal Soc. A, 357:1021–1046, (1999).
[MQT98] R. I. McLachlan, G. R. W. Quispel, and G. S. Turner: Numerical integrators that
preserve symmetries and reversing symmetries.
SIAM J. Numer. Anal., 35(2):586–599,
(1998).
[MS95c] R. I. McLachlan and C. Scovel: Equivariant constrained symplectic integration. J.
Nonlinear. Sci., 5:233–256, (1995).

362
Bibliography
[MS96] R. I. McLachlan and C. Scovel: A Survey of Open Problems in Symplectic Integration.
In J. E. Mardsen, G. W. Patrick, and W. F. Shadwick, editors, Integration Algorithms and
Classical Mechanics, pages 151–180. American Mathematical Society, (1996).
[Mur97] A. Murua: On order conditions for partitioned symplectic methods. SIAM J. Numer.
Anal., 34:2204–2211, (1997).
[Mur99] A. Murua: Formal series and numerical integrators, part I: Systems of odes and sym-
plectic integrators. Appl. Numer. Math., 29:221–251, (1999).
[Obr40] N. Obreschkoff: Neue Quadraturformeln. Abhandlungen pr¨oß Klasse Acad Wiss
Mathnatuwiss, 1–20.(1940).
[Oku93] D. Okunbor: Variable step size does not harm second-order integrators for Hamilto-
nian systems. J. Comput. Appl. Math, 47:273–279, (1993).
[Oku95] E. I. Okunbor: Energy conserving, Liouville, and symplectic integrators. J. of Comp.
Phys., 120(2):375–378, (1995).
[OS92] D. Okunbor and R.D. Skeel: Explicit canonical methods for Hamiltonian systems.
Math. Comp., 59:439–455, (1992).
[QD97] G. R. W. Quispel and C. Dyt: Solving ODE’s numerically while preserving symme-
tries, Hamiltonian structure, phase space volume, or ﬁrst integrals. In A. Sydow, editor,
Proceedings of the 15th IMACS World Congress, pages 601–607. Wissenschaft & Technik,
Berlin, (1997).
[Qin87] M. Z. Qin: A symplectic schemes for the Hamiltonian equations. J. Comput. Math.,
5:203–209, (1987).
[Qin89] M. Z. Qin: Cononical difference scheme for the Hamiltonian equation. Mathematical
Methodsand in the Applied Sciences, 11:543–557, (1989).
[Qin90] M. Z. Qin: Multi-stage symplectic schemes of two kinds of Hamiltonian systems of
wave equations. Computers Math. Applic., 19:51–62, (1990).
[Qin96] M. Z. Qin: Symplectic difference schemes for nonautonomous Hamiltonian systemes.
Acta Applicandae Mathematicae, 12(3):309–321, (1996).
[Qin97a] M. Z. Qin:
A symplectic schemes for the PDE’s.
AMS/IP studies in Advanced
Mathemateics, 5:349–354, (1997).
[QT90a] G. D. Quinlan and S. Tremaine: Symmetric multistep methods for the numerical
integration of planetary orbits. Astron. J., 100:1694–1700, (1990).
[QT90b] G.D. Quinlan and S. Tremaine:
Symmetric multistep methods for the numerical
integration of planetary orbits. Astron. J., 100:1694–1700, (1990).
[QT96] G. R. W. Quispel and G. S. Turner: Discrete gradient methods for solving ODE’s
numerically while preserving a ﬁrst integral. Physics Letters A, 29:L341–L349, (1996).
[QWZ91] M. Z. Qin, D. L. Wang, and M. Q. Zhang: Explicit symplectic difference schemes
for separable Hamiltonian systems. J. Comput. Math., 9(3):211–221, (1991).
[QZ90a] M. Z. Qin and M. Q. Zhang: Explicit Runge-Kutta-like schemes to solve certain
quantum operator equations of motion. J. Stat. Phys., 60(5/6):839–843, (1990).
[QZ91] M. Z. Qin and W. J. Zhu: Canonical Runge-Kutta-Nystr¨om(RKN) methods for second
order ode’s. Computers Math. Applic., 22:85–95, (1991).
[QZ92a] M. Z. Qin and M. Q. Zhang: Symplectic Runge-Kutta Schemes for Hamiltonian
System. J. Comput. Math., Supplementary Issue: pages 205–215, (1992).
[QZ92b] M. Z. Qin and W. J. Zhu: Construction of higher order symplectic schemes by com-
position. Computing, 47:309–321, (1992).
[QZ94] M. Z. Qin and W. J. Zhu: Multiplicative extrapolatio method for constructing higher
order schemes for ODE’s. J. Comput. Math., 12:352–356, (1994).
[QZZ95] M. Z. Qin, W. J. Zhu, and M. Q. Zhang: Construction of symplectic of a three stage
difference scheme for ODE’s. J. Comput. Math., 13:206–210, (1995).
[Rei94a] S. Reich: Momentum conserving symplectic integrators. Physica D, 76:375–383,
(1994).
[Rei95c] S. Reich: Smoothed dynamics of highly oscillatory Hamiltonian systems. Physica
D, 89:28–42, (1995).
[Rei96a] S. Reich: Enhancing energy conserving methods. BIT, 1:122–134, (1996).

Bibliography
363
[Rei96b] S. Reich: Symplectic integration of constrained Hamiltonian systems by composition
methods. SIAM J. Numer. Anal., 33:475–491, (1996).
[Rei96c] S. Reich: Symplectic Methods for Conservative Multibody Systems. In J. E. Mard-
sen, G. W. Patrick, and W. F. Shadwick, editors, Integration Algorithms and Classical Me-
chanics, pages 181–192. American Mathematical Society, (1996).
[Rei97] S. Reich: On higher-order semi-explicit symplectic partitioned Runge–Kutta methods
for constrained Hamiltonian systems. Numer. Math., 76(2):249–263, (1997).
[Rei99] S. Reich: Backward error analysis for numerical integrators. SIAM J. Numer. Anal.,
36:475–491, (1999).
[Rut83] R. Ruth: A canonical integration technique. IEEE Trans. Nucl. Sci., 30:26–69, (1983).
[SA91] J.M. Sanz-Serna and L. Abia: Order conditions for canonical Runge-Kutta schemes.
SIAM J. Numer. Anal., 28:1081–1096, (1991).
[SS88] J. M. Sanz-Serna: Runge–Kutta schemes for Hamiltonian systems. BIT, 28:877–883,
(1988).
[SSC94] J. M. Sanz-Serna and M. P. Calvo: Numerical Hamiltonian Problems. AMMC 7.
Chapman & Hall, (1994).
[SSM92] S. Saito, H. Sugiura, and T. Mitsui:
Family of symplectic implicit Runge-Kutta
formulae. BIT, 32:539–543, (1992).
[SSM92b] S. Saito, H. Sugiura, and T. Mitsui: Butcher’s simplifying assumption for symplec-
tic integrators. BIT, 32:345–349, (1992).
[Sto93b] D.M. Stoffer: Variable step size destabilizes the St¨ormer/leap-frog/Verlet method.
BIT, 33:172–175, (1993).
[Sto95] D. Stoffer: Variable steps for reversible integration methods. Computing, 55:1–22,
(1995).
[Sto97] D. Stoffer: On the Qualitative Behaviour of Symplectic Integrators Part I: Perturbed
Linear Systems. Numer. Math., 77(4):535–548, (1997).
[Sto98a] D. Stoffer: On the gualitative behavior of symplectic integrator. II: Integrable systems.
J. of Math. Anal. and Applic., 217:501–520, (1998).
[Sto98b] D. Stoffer:
On the qualitative behaviour of symplectic integrators. III: Perturbed
integrable systems. J. of Math. Anal. and Appl., 217:521–545, (1998).
[Sun93a] G. Sun: Construction of high order symplectic Runge-Kutta methods. J. Comput.
Math., 11(3):250–260, (1993).
[Sun93b] G. Sun: Symplectic partitioned Runge–Kutta methods. J. Comput. Math., 11:365–
372, (1993).
[Sun94] G. Sun: Characterization and construction of linear symplectic R–K methods. J.
Comput. Math., 12(2):101–112, (1994).
[Sun95] G. Sun: Construction of high order symplectic Partitioned–Runge–Kutta methods. J.
Comput. Math., 13(1):40–50, (1995).
[Sun00] G. Sun: A simple way constructing symplectic Runge–Kutta methods. J. Comput.
Math., 18:61–68, (2000).
[Sur88] Y.B. Suris: On the conservation of the symplectic structure in the numerical solu-
tion of Hamiltonian systems(in Russian), In: Numerical Solution of Ordinary Differential
Equations, ed. S.S. Filippov, Keldysh Institute of Applied Mathematics. USSR Academy
of Sciences, Moscow, Second edition, (1988).
[Sur89] Y.B. Suris:
The canonicity of mappings generated by Runge–Kutta type methods
when integrating the systems ¨x = −∂U
∂x . U.S.S.R. Comput. Maths. Math. Phys., 29:138–
144, (1989).
[Sur90] Y.B. Suris: Hamiltonian methods of Runge–Kutta type and their variational interpre-
tation. Math. Model., 2:78–87, in Russian, (1990).
[Tan93a] Y. F. Tang: The symplecticity of multi-step methods. Computers Math. Applic.,
25:83–90, (1993).
[Tan93b] Y. F. Tang: The necessary condition for Runge–Kutta schemes to be symplectic for
Hamiltonian systems. Computers Math. Applic., 26:13–20, (1993).

364
Bibliography
[Tan94] Y. F. Tang: Formal energy of a symplectic scheme for Hamiltonian systems and its
applications. Computers Math. Applic., 27:31–39, (1994).
[Vog56] R. de Vogelaere: Methods of integration which preserve the contact transformation
property of the Hamiltonian equations. Report No. 4, Dept. Math., Univ. of Notre Dame,
Notre Dame, Ind., Second edition, (1956).
[Wan91a] D. L. Wang: Semi-discrete Fourier spectral approximations of inﬁnite dimensional
Hamiltonian systems and conservations laws. Computers Math. Applic., 21:63–75, (1991).
[Wan91b] D. L. Wang: Symplectic difference schemes for Hamiltonian systems on Poisson
manifolds. J. Comput. Math., 9(2):115–124, (1991).
[Wan91c] D. L. Wang: Poisson difference schemes for Hamiltonian systems on Poisson man-
ifolds. J. Comput. Math., 9:115–124, (1991).
[Wan93] D. L. Wang: Decomposition vector ﬁelds and composition of algorithms. In Proceed-
ings of International Conference on computation of differential equations and dynamical
systems, Beijing, 1993. World Scientiﬁc, (1993).
[Wan94] D. L. Wang: Some acpects of Hamiltonian systems and symplectic defference meth-
ods. Physica D, 73:1–16, (1994).
[Yos90] H. Yoshida: Conserved quantities of symplectic integrators for Hamiltonian systems.
Preprint, (1990).
[ZQ93a] M. Q. Zhang and M. Z. Qin: Explicit symplectic schemes to solve vortex systems.
Comp. & Math. with Applic., 26(5):51, (1993).
[ZQ93b] W. Zhu and M. Qin: Applicatin of higer order self-adjoint schemes of PDE’s. Com-
puters Math. Applic.,26(3):15–26, (1993).
[ZQ93c] W. Zhu and M. Qin: Constructing higer order schemes by formal power series. Com-
puters Math. Applic.,25(12):31–38, (1993).
[ZQ93] W. Zhu and M. Qin: Order conditionof two kinds of canonical difference schemes.
Computers Math. Applic., 25(6):61–74, (1993).
[ZQ94] W. Zhu and M. Qin: Poisson schemes for Hamiltonian systems on Poisson manifolds.
Computers Math. Applic., 27:7–16, (1994).
[ZQ95a] W. Zhu and M. Qin: Reply to “comment on Poisson schemes for Hamiltonian systems
on Poisson manifolds”. Computers Math. Applic., 29(7):1, (1995).
[ZQ95b] W. Zhu and M. Qin:
Simpliﬁed order conditions of some canonical difference
schemes. J. Comput. Math., 13(1):1–19, (1995).
[ZS75] K. Zare and V. Szebehely: Time transformations in the extended phase-space. Celest.
Mech., 11:469–482, (1975).
[ZS95] M. Q. Zhang and R. D. Skeel: Symplectic integrators and the conservation of angular
momentum. J. Comput. Chem., 16:365–369, (1995).
[ZS97] M. Q. Zhang and R. D. Skeel: Cheap implicit symplectic integrators. Appl. Numer.
Math., 25(2):297, (1997).
[ZW99] H. P. Zhu and J. K. Wu: Generalized canonical transformations and symplectic algo-
rithm of the autonomous Birkhofﬁan systems. Progr. Natur. Sci., 9:820–828, (1999).
[ZzT96] W. Zhu, X. zhao, and Y Tang: Numerical methods with a high order of accuracy
applied in the quantum system. J. Chem. Phys., 104(6):2275–2286, (1996).

Chapter 8.
Composition Scheme
In this chapter, we consider a class of reversible schemes also called symmetrical
schemes. In algebraic language, it is not other, just like self-adjoint schemes . Here, we
only deal with one-step reversible schemes. We will introduce the concept of adjoint
methods and some of their properties. We will show that there is a self-adjoint scheme
of even order in every method. Using the self-adjoint schemes with lower order, we
can construct higher order schemes by “composing” a method, and this construct-
ing process can be continued to obtain arbitrary even order schemes. The composing
method presented here can be used to in both non-symplectic and symplectic schemes.
In [Yos90], H.Yoshida proposed a new method to get multistage higher order explicit
symplectic schemes for separable Hamiltonian systems by composing lower order
ones. However, in [QZ92,Wru96,Suz92], we found that this method can also be applied to
non-symplectic schemes for both Hamiltonian and non-Hamiltonian systems.
8.1 Construction of Fourth Order with 3-Stage Scheme
In this section, we construct a 3-stage difference scheme of fourth order by the method
of composing 2nd order schemes symmetrically.
8.1.1 For Single Equation
We know that trapezoid scheme
Zk+1 = Zk + h
2

f(Zk) + f(Zk+1)

(1.1)
with h the step length, is order 2 for ODEs,
˙Z = f(Z).
(1.2)
We expect that the 3-stage method of the form
Z1 = Z0 + c1h

f(Z0) + f(Z1)

,
Z2 = Z1 + c2h

f(Z1) + f(Z2)

,
Z3 = Z2 + c3h

f(Z2) + f(Z3)

(1.3)

366
8. Composition Scheme
would be of order 4 (i.e., Z3 −Z(t + h) = O(h5)), where Z0 = Z(t). Z(t + h) is the
exact solution at t + h and Z3 the numerical one when the parameters c1, c2, and c3
are chosen properly.
We will use the method of Taylor expansion to deal with the simple case when
there is only one ordinary differential equation (ODE). When we deal with the case of
systems of ODEs, the Taylor expansions become very complex, although they surely
can be applied and the same conclusion as in the former case can be derived. We
introduce another method[HNW93], known as “trees and elementary differentials” to
deal with the latter case. In fact, the essence of the two methods is the same; they are
just two different ways of expression.
In this section, without speciﬁc statements, the values of all functions and their
derivatives are calculated at Z0, and we consider only the terms up to o(h4) in the
following calculations, while the higher order terms of h are omitted,
f = f(Z0),
f ′ = f ′(Z0), . . . , etc.
First, we calculate the Taylor expansion of the exact solution. Since
⎧
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎩
˙Z = f,
¨Z = f ′ · ˙Z = f ′f,
Z(3) = f ′′f 2 + f ′2f,
Z(4) = f ′′′f 3 + 4f
′′f ′f 2 + f ′3f,
(1.4)
we have, with Z0 = Z(t),
Z(t+h) = Z0+hf+h2
2 ! f ′f+h3
3 ! (f ′′f 2+f ′2f)+h4
4 ! (f ′′′f 3+4f ′′f ′f 2+f ′3f)+O(h5).
(1.5)
Now, we turn to the Taylor expansion of the numerical solution. We can rewrite
(1.3) as
Z3 = Z0 + c1h(f(Z0) + f(Z1)) + c2h(f(Z1)
+f(Z2)) + c3h(f(Z2) + f(Z3))
= Z0 + h(c1f(Z0) + (c1 + c2)f(Z1)
+(c2 + c3)f(Z2) + c3f(Z3)).
(1.6)
We use the same technique to expand the Taylor expansions of f(Z2), f(Z3).
Since
Z2 −Z0 = c1h(f(Z1) + f(Z0)) + c2h(f(Z2) + f(Z1))
= c1hf(Z0) + (c1 + c2)hf(Z1) −c2hf(Z2).
(1.7)
We need to calculate f(Z1), f(Z2), f(Z3) Taylor expansion up to the terms of
order 3 of h
f(Zi) = f(Z0) + f ′(Zi −Z0) + f ′′
2 ! (Zi −Z0)2 + f ′′′
3 ! (Zi −Z0)3 + O(h4). (1.8)

8.1 Construction of Fourth Order with 3-Stage Scheme
367
Since Z1 = Z0 + c1h(f(Z1) + f(Z0)) by (1.8), we have
f(Z1) = f(Z0) + f ′
c1hf(Z0) + c1hf(Z1)

+ f′′
2 !

c1hf(Z0) + c1hf(Z1)
2
+ f′′′
3 !

c1hf(Z0) + c1hf(Z1)
3
+ O(h4).
(1.9)
Inserting the Taylor expansion of f(Z1) into right side of (1.9), we get
f(Z1) = f(Z0) + c1hf ′
f(Z0) + f(Z0) + c1hf ′
f(Z0) + f(Z1)

+ f′′
2 ! (c1h)2
f(Z0) + f(Z1)
2
+ f′′
2 ! (c1h)2
f(Z0) + f(Z0)
+c1hf ′
f(Z0) + f(Z1)
2
+ f′′′
3 ! (c1h)3
f(Z0) + f(Z0)
3
+ O(h4)
= f(Z0) + c1hf ′
2f(Z0) + c1hf ′
f(Z0) + f(Z0) + c12hf ′f(Z0)

+(c1h)2 f′′
2 !

f(Z0) + f(Z0)
2
+ (c1h)2 f′′
2 !

2f(Z0) + c1hf ′
f(Z0)
+f(Z0)
2
+ (c1h)3 f′′′
3 !

2f(Z0)
3
+ O(h4)
= f(Z0) + c1h

2f ′f(Z0)

+ (c1h)2
2f ′2f(Z0) + 2f ′′f 2(Z0)

+(c1h)3
2f ′3f(Z0) + 6f ′′f ′f 2(Z0) + 4
3f ′′′f 3(Z0)

+ O(h4).
(1.10)
Similarly, developing f(Z2) and f(Z3), since
Z2 −Z0
= c1h

f(Z1) + f(Z0)

+ c2h

f(Z2) + f(Z1)

= c1hf(Z0) + (c1 + c2)hf(Z1) + c2hf(Z2),
therefore
f(Z2) = f(Z0) + hf ′
c1f(Z0) + (c1 + c2)f(Z1) + c2f(Z2)

+ f ′′
2 ! h2
c1f(Z0)
+(c1 + c2)f(Z1) + c2f(Z2)
2
+ f ′′′
3 ! h3
c1f(Z0) + (c1 + c2)f(Z1)
+c2f(Z2)
3
+ O(h4)
= f(Z0) + hf ′
%
c1f(Z0) + (c1 + c2)f(Z1) + c2

f(Z0) + hf ′
c1f(Z0)
+(c1 + c2)f(Z1) + c2

f(Z0) + hf ′
c1f(Z0) + (c1 + c2)f(Z1) + c2f(Z0)

+f ′′
2 ! h2
c1f(Z0) + (c1 + c2)f(Z1) + c2f(Z0)
2&
+ f ′′
2 ! h2
%
c1f(Z0)
+(c1 + c2)f(Z1) + c2

f(Z0) + hf ′
c1f(Z0) + (c1 + c2)f(Z1)
+c2f(Z2)
&2
+ f ′′′
3 ! h3
c1f(Z0) + (c1 + c2)f(Z1) + c2f(Z0)
3
+ O(h4).
(1.11)

368
8. Composition Scheme
Similarly, inserting Taylor expansion of f(Z1) into (1.11), we get
f(Z2) = f(Z0) + hf ′
c1f(Z0) + (c1 + c2)

f(Z0) + (c1h)2f ′f(Z0)
+(c1h)2
2f ′2f(Z0) + 2f ′′f 2(Z0)

+ c2

f(Z0)
+hf ′
c1f(Z0) + (c1 + c2)

f(Z0) + (c1h)2f ′f(Z0)

+ c2

f(Z0)
+hf(c1 + c2)2f(Z0)

+ f ′′
2! h2(c1 + c2)24f 2(Z0)

+f ′′
2 ! h2
c1f(Z0) + (c1 + c2)

f(Z0) + (c1h)2f ′f(Z0)) + c2

f(Z0)
+hf ′(c1 + c2)

f(Z0) + f(Z0)
2
+ f ′′′
3 ! h3(c1 + c2)38f 3(Z0)
+O(h4)
= f(Z0) + h

2(c1 + c2)f
′f(Z0)

+ h2
(c1 + c2)2
2f ′2f(Z0)
+2f ′′f 2(Z0)

+ h3
(c1 + c2)(c2
1 + c1c2 + c2
2)2f ′3f(Z0)
+

(c1 + c2)2c2
1 + 2c2(c1 + c2)2 + 4(c1 + c2)3
f ′′f ′f 2(Z0)
+4
3(c1 + c2)3f ′′′f 3(Z0)

+ O(h4).
(1.12)
Using the above identical method, we have
f(Z3) = f(Z0) + hf ′
c1f(Z0) + (c1 + c2)f(Z1) + (c2 + c3)f(Z2) + c3f(Z3)

+h2 f ′′
2 !

c1f(Z0) + (c1 + c2)f(Z1) + (c2 + c3)f(Z2) + c3f(Z3)
2
+h3 f ′′′
3 !

c1f(Z0) + (c1 + c2)f(Z1) + (c2 + c3)f(Z2) + c3f(Z3)
3
+O(h4)
= f(Z0) + hf ′
c1f(Z0) + (c1 + c2)f(Z1) + (c2 + c3)f(Z2) + c3

f(Z0)
+hf ′
c1f(Z0) + (c1 + c2)f(Z1) + (c2 + c3)f(Z2) + c3

f(Z0)
+hf ′
(c1 + c3)f(Z0) + (c1 + c2)f(Z1) + (c2 + c3)f(Z2)

+h2 f ′′
2 !

c1f(Z0) + (c1 + c2)f(Z1) + (c2 + c3)f(Z2) + c3f(Z0)
2
+h2 f ′′
2 !

c1f(Z0) + (c1 + c2)f(Z1) + (c2 + c3)f(Z2) + c3

f(Z0)
+hf ′
c1f(Z0) + (c1 + c2)f(Z1) + (c2 + c3)f(Z2) + c3f(Z0)
3
+h3 f ′′′
3 !

(c1 + c3)f(Z0) + (c1 + c2)f(Z1) + (c2 + c3)f(Z2)
3
+O(h4).
(1.13)
Inserting the Taylor expansion of f(Z1) and f(Z2) into (1.13)
f(Z3) =
f(Z0) + h

2(c1 + c2 + c3)f ′f(Z0)

+ h2
(c1 + c2 + c3)22f ′2f(Z0)

8.1 Construction of Fourth Order with 3-Stage Scheme
369
+(c1 + c2 + c3)22f ′′f 2(Z0)

+ h3
c1 + c2)c2
1 + (c2 + c3)(c1 + c2)2
+c3(c1 + c2 + c3)2
2f ′3f(Z0) +

(c1 + c2)c2
1 + (c2 + c3)(c1 + c2)2
+c3(c1 + c2 + c3)2 + 2(c1 + c2 + c3)3
2f ′′f ′f 2f(Z0)
+4
3(c2 + c2 + c3)3
f ′′′f 3(Z0) + O(h4).
(1.14)
Let c1 = c3 = w1
2 , c2 = w0
2 , take into account (1.5) and (1.6), and compare the
Taylor expansion of the exact solution (1.5) with the above one. In order to get fourth
order accuracy schemes (1.3), we need to solve the following equations for coefﬁcients
c1, c2, c3:
hf ′ : c1 + (c1 + c2) + (c2 + c3) + c3 = 1 =⇒2w1 + w0 = 1,(1.15)
h2f ′f : (c1 + c2)2c1 + (c2 + c3)2(c1 + c2) + c32(c1 + c2 + c3)
= 1
2,
(1.16)
h3f ′′f 2, h3f ′2f : (c1 + c2)2c2
1 + (c2 + c3)2(c1 + c2)2 + c32(c1 + c2 + c3)2
= 1
6,
(1.17)
h4f ′′′f 3 : (c1 + c2)4
3c3
1 + (c2 + c3)4
3(c1 + c2)3 + c3
4
3(c1 + c2 + c3)3
= 1
24,
(1.18)
h4f ′3f : (c1 + c2)2c3
1 + (c1 + c2)2(c2
1 + c2
2 + c1c2)(c2 + c3)
+c32

(c1 + c2)c2
1 + (c2 + c3)(c1 + c2)2 + c3(c1 + c2 + c3)2
= 1
24,
(1.19)
h4f ′′f ′f 2 : (c1 + c2)6c3
1 + (c2 + c3)

4(c1 + c2)3 + 2c2
1(c1 + c2)
+2c2(c1 + c2)2
+ c32(c2
1(c1 + c2) + (c2 + c3)(c1 + c2)2
+c3(c1 + c2 + c3)2 + 2(c1 + c2 + c3)3
= 1
24.
(1.20)
When 2w1 +w0 = 1 holds, the Equation (1.16) becomes 1
2 = 1
2, i.e., identity, and
the Equations (1.17) – (1.20) become the same, i.e.,
6w3
1 −12w2
1 + 6w1 −1 = 0.
Thus, we get the conditions for the difference scheme (1.3) to be of order 4:

2w1 + w0 = 1,
6w3
1 −12w2
1 + 6w1 −1 = 0.
(1.21)
Thus we get,
w0 =
−2
1
3
2 −2
1
3 ,
w1 =
1
2 −2
1
3 .

370
8. Composition Scheme
Now, scheme (1.3) becomes
⎧
⎪
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎪
⎩
Z1 = Z0 +
1
2(2 −2
1
3 )
h

f(Z0) + f(Z1)

,
Z2 = Z1 +
−2
1
3
2(2 −2
1
3 )
h

f(Z1) + f(Z2)

,
Z3 = Z2 +
1
2(2 −2
1
3 )
h

f(Z2) + f(Z3)

.
(1.22)
8.1.2 For System of Equations
We use the “method of tree and elementary differentials” [HNW93]given in Chapter 7.
We ﬁrst rewrite the scheme (1.3) in the R–K methods:
⎧
⎪
⎨
⎪
⎩
Z1 = Z0 + h

c1f(Z0) + c1f(Z1)

,
Z2 = Z0 + h

c1f(Z0) + (c1 + c2)f(Z1) + c2f(Z2)

,
Z3 = Z0 + h

c1f(Z0) + (c1 + c2)f(Z1) + (c2 + c3)f(Z2) + c3f(Z3)

.
(1.23)
Obviously, the above equation is equivalent to following
⎧
⎪
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎪
⎩
g1 = Z0,
g2 = Z0 + c1hf(g1) + c1hf(g2),
g3 = Z0 + c1hf(g1) + (c1 + c2)hf(g2) + c2hf(g3),
g4 = Z0 + c1hf(g1) + (c1 + c2)hf(g2) + (c2 + c3)hf(g3) + c3hf(g4),
Z = Z0 + h

c1f(g1) + (c1 + c2)f(g2) + (c2 + c3)f(g3) + c3f(g4)

,
(1.24)
where g2 = Z1, g3 = Z2, g4 = Z3, and Z = Z3. Thus, the Butcher tableau
C
A
bT
takes the following form:
0
0
0
0
0
2c1
c1
c1
0
0
2(c1 + c2)
c1
c1 + c2
c2
0
2(c1 + c2 + c3)
c1
c1 + c2
c2 + c3
c3
c1
c1 + c2
c2 + c3
c3
From the previous chapter, we have the order condition for R–K method as follows:
Theorem 1.1. R–K method

8.1 Construction of Fourth Order with 3-Stage Scheme
371
gJ
i = ZJ
0 +
s

j=1
aijf J(g1
j , · · · , gh
j ),
ZJ
1 = ZJ
0 +
s

j=1
bjhf J(g1
j , · · · , gh
j )
is order of p, iff
s

j=1
bjφj(ρt) =
1
γ(ρt)
for all rooted tree ρt, have r(ρt) ≤p, where Z0 = (Z1
0, · · · , Zn
0 )T, f J = (f 1, f 2, · · · , f n)T.
Since rooted tree ρt of Theorem 1.1 is deﬁned in Chapter 7, deﬁnitions of φj(ρt)
are as follows:
φj(ρt) =

k,l,···
ajka · · · ,
where ρt is a labelled tree with root j, the sum over the r(ρt) −1 remaining indices
k, l, · · ·. The summand is a product of r(ρt) −1 a’s, where all fathers stand two by
two with their sons as indices.
⎧
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎩
4

j=1
bj = 1,
4C
j=1
bj
4

k=1
ajk = 1
2,
4

j=1
bj
4

k,l=1
ajkajl = 1
3,
4

j=1
bj
4

k,l=1
ajkakl = 1
6,
4

j=1
bj
4

k,l,m=1
ajkajlajm = 1
4,
4

j=1
bj
4

k,l,m=1
ajkaklajm = 1
8,
4

j=1
bj
4

k,l,m=1
ajkaklakm = 1
12,
4

j=1
bj
4

k,l,m=1
ajkaklalm = 1
24.
(1.25)
From the previous chapter on simplifying condition of symplectic R–K, we know
that the system of Equation (1.25) only exists in 3 independent conditions (equa-
tion). In the above equation, last 4 conditions have only one independent condition.
By symmetrically choosing c1 = c3, this condition is satisﬁed automatically. Taking
c1 = c3 = w1
2 , c2 = w0
2 , by the ﬁrst two conditions of Equation (1.25), we obtain the
same equation
2w1 + w0 = 1.
(1.26)
Substituting the relation (1.26) in the order of conditions (1.25), we get
2w3
1 + w3
0 = 0.
(1.27)
These Equations (1.26) and (1.27) are just the same as in Subsection 8.1.1 for single
equation.

372
8. Composition Scheme
From the literature[Fen85], we know that the centered Euler scheme is symplectic,
but trapezoidal scheme (1.1) is right non-symplectic as a result of nonlinear transfor-
mation [Dah75,QZZ95,Fen92], the scheme (1.1) can transform the Euler center point form,
therefore the trapezoidal form is nonstandard symplectic, just as discussed in Section
4.3 of Chapter 4. It is the same with the trapezoidal form, the centered Euler scheme
may also be used to construct the higher order scheme. Because
⎧
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎩
Z1 = Z0 + d1hf
Z0 + Z1
2

,
Z2 = Z1 + d2hf
Z1 + Z2
2

,
Z3 = Z2 + d3hf
Z2 + Z3
2

,
it is equally the same in R–K method with in the following Butcher tableau:
d1
2
d1
2
0
0
d1 + d2
2
d1
d2
2
0
d1 + d2 + d3
2
d1
d2
d3
2
d1
d2
d3
Using the same method, we can prove that , when d1 = d3 =
1
2 −2
1
3 , d2 =
−2
1
3
2 −2
1
3 , the above scheme is fourth order, and the coefﬁcient is entirely the same as in
trapezoidal method.
8.2 Adjoint Method and Self-Adjoint Method
Here, we will introduce the concept of adjoint scheme and self-adjoint scheme. These
two kinds of schemes are the foundation that construct higher order scheme in the
future. First, we see several higher order schemes as the example, and seek common
character which may supply method for constructing higher order scheme; In the Sec-
tion 4.4 of Chapter 4, we discussed an explicit scheme for separable Hamiltonian
system. We know
 pn+1 = pn −τVq(qn),
qn+1 = qn + τUp(pn+1)
(2.1)
(where τ is step size, pn, qnare numerical solution in step n) is of order 1. We shall
compose this scheme (2.1) to a 2nd order scheme choosing a suitable coefﬁcient of τ,

8.2 Adjoint Method and Self-Adjoint Method
373
⎧
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎩
pn+ 1
2 = pn −τ
2Vq(qn),
qn+ 1
2 = qn + τUp(pn+ 1
2 ),
pn+1 = pn+ 1
2 −τ
2Vq(qn+ 1
2 ),
qn+1 = qn+ 1
2 .
This scheme is equal to the following:
⎧
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎩
pn+ 1
2 = pn −τ
2Vq(qn),
qn+ 1
2 = qn + τ
2Up(pn+ 1
2 ),
qn+1 = qn+ 1
2 + τ
2Up(pn+ 1
2 ),
pn+1 = pn+ 1
2 −τ
2Vq(qn+1).
(2.2)
This 2nd order scheme can also be deﬁned as a self-adjoint scheme, see also [Yos90].
Ruth[Rut83], using scheme (2.1), constructed a 3rd order scheme via composition
method,
⎧
⎪
⎨
⎪
⎩
p1 = pk −c1τVq(qk),
q1 = qk + d1τUp(p1),
p2 = p1 −c2τVq(q1),
q2 = q1 + d2τUp(p2),
pk+1 = p2 −c3τVq(q2),
qk+1 = q2 + d3τUp(pk+1).
(2.3)
When c1 = 7
24, c2 = 4
3, c3 = −1
24, d1 = 2
3, d2 = −2
3, d3 = 1, this scheme is
3rd order. We may construct multistage schemes, in order to achieve the higher order
precision. In literature[QZ92,Fen86,Fen91,FR90,Rut83] , we may see the following 4th order
form:
⎧
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎩
p1 = pk −c1τVq(qk),
q1 = qk + d1τUp(p1),
p2 = p1 −c2τVq(q1),
q2 = q1 + d2τUp(p2),
p3 = p2 −c3τVq(q2),
q3 = q2 + d3τUp(p3),
pk+1 = p3 −c4τVq(q3),
qk+1 = q3 + d4τUp(pk+1),
(2.4)
where
⎧
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎩
c1 = 0,
c2 = c4 = −1
3(2 + α),
c3 = 1
3(1 + 2α),
d1 = d4 = 1
6(2 + α),
d2 = d3 = 1
6(1 −α),
α =
3√
2 +
3
D
1
2,
or
⎧
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎩
c1 = c4 = 1
6(2 + α),
c2 = c3 = 1
6(1 −α),
d1 = d3 = 1
3(1 + 2α),
d2 = −1
3(1 + 2α),
d4 = 0,
α =
3√
2 +
3
D
1
2.

374
8. Composition Scheme
The above examples in the 3-stage fourth-order scheme give us an understanding. We
can construct the higher order scheme through the low-order scheme, and this method
is not limited the symplictic type. Because the usual structure uses the Taylor ex-
pansion, the comparison of coefﬁcient of structure in the higher order form will be
cumbersome, therefore in this section and next, we will use the Lie series method.
This method is already used widely , for example Stanly. Stenberg, Alex, J. Dragt
and F. Neri used the Lie series to study the differential equation, see also the litera-
ture [Ste84,DF76,DF83,Ner87]. Using the Lie series to study our question is convenient as
there is no need to extract the Lie series item truly to which form it corresponds, but
must use its form only. We will see this later.
We know that each scheme is always formal and is expressed as follows:
yn+1 = S(τ)yn,
(2.5)
where τ is the step size. S(τ) is called the integrator, but yn+1 and yn are numerical
solutions of equation in steps n + 1 and n .
Deﬁnition 2.1. An integrator S∗(τ) is called the adjoint integrator S(τ), if
S∗(−τ)S(τ) = I,
(2.6)
S(τ)S∗(−τ) = I.
(2.7)
That means yn+1 = S(τ)yn, yn = S∗(−τ)yn+1, or yn+1 = S∗(−τ)yn, yn =
S(τ)yn+1. In fact, (2.6) – (2.7) equations are equivalent to
S(−τ)S∗(τ) = I,
(2.8)
S∗(τ)S(−τ) = I.
(2.9)
In order to prove this, set τ = −τ
′, then (2.6) – (2.7) becomes
⎧
⎨
⎩
S∗(τ
′)S(−τ
′) = I,
S(−τ
′)S∗(τ
′) = I.
τ expresses the length of arbitrary step; therefore, the above equations are formula of
(2.8), (2.9). Further, we would like to point out that the two conditions (2.6) and (2.7)
are the same. Since form S∗(−τ)S(τ) = I, we get
S∗(−τ) = S−1(τ),
where S−1(τ) is the inverse of the integrator S(τ). Here, we always assume S(τ) is
invertible. So, we have
S(τ)S∗(−τ) = S(τ)S−1(τ) = I.
The formula may result in (2.7) by (2.6), and vice versa.
But note the difference between S∗(τ) and S−1(τ), that is, S∗(−τ) = S−1(τ).
Here, S∗(τ) and S(τ) is the same push-forward mapping, but S−1(τ) is the pull-back
mapping.

8.2 Adjoint Method and Self-Adjoint Method
375
For a convenient deduction in Section 8.3, we give another deﬁnition of a self-
adjoint method[HNW93] here, and show that it is equivalent to deﬁnition adjoint (2.1).
We rewrite (2.5) as follows:
yn+1 = yn + τφ(x, yn, τ).
(2.10)
yn, yn+1 is numerical solution for the equation y′ = f(x) in the n and n + 1 step, and
φ is increment function which the form (2.5) corresponds.
Deﬁnition 2.2. Scheme yn+1 = yn + τφ∗(x, yn, τ) is an adjoint scheme (2.10), if it
satisﬁes:
B = A −τφ(x + τ, A, −τ),
(2.11)
A = B + τφ∗(x, B, τ).
(2.12)
Theorem 2.3. Deﬁnition 2.1 and Deﬁnition 2.2 are equivalent.
Proof. Since (2.8) – (2.9) and (2.6) – (2.7) are equivalent, (2.6) and (2.9) are also
equivalent. It is enough to prove that (2.9) is equivalent to (2.11) – (2.12). Let

S∗(τ)yn = yn + τφ∗(x, yn, τ),
S(τ)yn = yn + τφ(x, yn, τ),
ﬁrst prove that (2.9) →(2.11) – (2.12). Let

A = yn+1,
B = A −τφ(x + τ, A, −τ),
(2.13)
prove that (2.12), due to
S∗(τ)S(−τ)yn+1 = S∗(τ)

yn+1 −τφ(x + τ, yn+1, −τ)

= yn+1 −τφ(x + τ, yn+1, −τ)
+τφ∗
x, yn+1 −τφ(x + τ, yn+1, −τ), τ

= yn+1 −τφ(x + τ, yn+1, −τ) + τφ∗(x, B, τ)
= B + τφ∗(x, B, τ)
= IA.
By the last equality, also because S∗(τ)S(−τ) = I, we have
B + τφ∗(x, B, τ) = A,
this is the formula (2.12).
Now, we will prove : (2.11) – (2.12) ⇒(2.9). Let
' A = yn+1,
B = A −τφ(x + τ, A, −τ).

376
8. Composition Scheme
Since
S∗(τ)S(−τ)yn+1 = S∗(τ)

yn+1 −τφ(x + τ, yn+1, −τ)

= A −τφ(x + τ, A, −τ) + τφ∗(x, B, τ),
from (2.12), we have
S∗(τ)S(−τ)A = B + τφ∗(x, B, τ) = A = IA,
i.e., S∗(τ)S(−τ) = I.
▲
Deﬁnition 2.4. An integrator S(τ) is self-adjoint, if
S∗(τ) = S(τ),
i.e.,
S(−τ)S(τ) = I.
In[Yos90], the integrator with the property S(−τ)S(τ) = I. H. Yoshida called this
operator as reversible. We see that time reversibility and self-adjointness are the same.
The time reversible (i.e., self-adjoint) integrator plays an important role in this chapter
due to its special property.
Theorem 2.5. For every integrator S(τ), S∗τ
2

S
τ
2

or S
τ
2

S∗τ
2
 
is self-
adjoint integrator[QZ92,Str68].
Proof. We must prove that S∗τ
2

= S
τ
2

is self-adjoint, i.e.,

S∗(τ)S(τ)
∗= S∗(τ)S(τ).
By Deﬁnition 2.1,we have S∗(τ)S(−τ) = I, then

S∗(τ)S(τ)
∗=

S∗(−τ)S(−τ)
−1
= S−1(−τ)

S∗(−τ)
−1
= S∗(τ)

S∗(−τ)
−1.
Because we also have
S∗(−τ)S(τ) = I,
i.e.,

S∗(−τ)
−1 = S(τ),
therefore

S∗(τ)S(τ)
∗= S∗(τ)S(τ).
Therefore, the theorem is completed.
▲
Theorem 2.6. If S1(τ) and S2(τ) are self-adjoint integrators, then symmetrical com-
position S1(τ)S2(τ)S1(τ) is self-adjoint[QZ92].

8.3 Construction of Higher Order Schemes
377
Proof. Consider S1(τ) and S2(τ) are self-adjoint integrators, then

S1(τ)S2(τ)S1(τ)
∗=

S1(−τ)S2(−τ)S1(−τ)
−1
= S1(−τ)−1S2(−τ)−1S1(−τ)−1
= S∗
1(τ)S∗
2(τ)S∗
1(τ) = S1(τ)S2(τ)S1(τ).
The theorem is proved.
▲
We pointed out that generally, a combination of self-adjoint operators is not necessar-
ily from the self-adjoint. One simple example is

S1(τ)S2(τ)
∗= S2(τ)S1(τ) ̸= S1(τ)S2(τ),
where S1(τ) and S2(τ) are self-adjoint operators, but they not commutative. We will
construct a higher order form in the below section.
8.3 Construction of Higher Order Schemes
We will ﬁrst give constructed method for the higher difference scheme, and will further
prove that the Gauss–Legendre method is a self-adjoint method. We have given some
example for structured higher order schemes.
In this section, we will introduce ﬁrst-order differential operators, Lie series and
some of their properties, all these are the basis of further deduction.
Denote:
f = (f1, f2, · · · , fn)T
g = (g1, g2, · · · , gn)T
D =
%
d
d y1 , · · · ,
d
d yn
&T
,
where f1, f2, · · · , fn and g1, g2, · · · , gn are scalar function. Let
Lf = f TD =
n

i=1
fi
∂
∂yi
(3.1)
be a ﬁrst-order differential operator. The action of Lf on a scalar function ϕ is,
Lfϕ =
* n

i=1
fi
∂
∂yi
+
ϕ = f TDϕ(y).
It is linear and satisﬁes the Leibniz formula, i.e., for two scalar functions ϕ1 and ϕ2,
(1)
Lf(λ1ϕ1 + λ2ϕ2) = λ1Lfϕ1 + λ2Lfϕ2,
∀λ1, λ2 ∈R.
(3.2)
(2)
Lf(ϕ1ϕ2) = ϕ1Lfϕ2 + ϕ2Lfϕ1.
(3.3)

378
8. Composition Scheme
Deﬁnition 3.1. The commutator of two ﬁrst-order differential operators Lf and Lg is
deﬁned by
[Lf, Lg] = LfLg −LgLf.
(3.4)
The commutator of the two ﬁrst-order differential operators is still a ﬁrst differen-
tial operator, since
LfLgϕ =f TDgTDϕ =
n

j=1
fj ∂
∂yj
n

i=1
gi ∂
∂yi ϕ =
n

i,j=1
fj ∂gi
∂yj
∂
∂yi ϕ +
n

i,j=1
fjgi
∂2ϕ
∂yj∂yi ,
LgLfϕ =gTDf TDϕ =
n

j=1
gj ∂
∂yj
n

i=1
fi ∂
∂yi ϕ =
n

i,j=1
gj ∂fi
∂yj
∂
∂yi ϕ +
n

i,j=1
gjfi
∂2ϕ
∂yj∂yi ,
therefore,
(LfLg −LgLf)ϕ =
n

i,j=1
%
fj
∂gi
∂yj
−gj
∂fi
∂yj
& ∂
∂yi
ϕ,
this means
[Lf, Lg] = Lc,
c = [c1, c2, · · · , cn],
ci =
n

j=1
%
fj
∂gi
∂yj
−gj
∂fi
∂yj
&
,
and Lc will still be the ﬁrst-order differential operator. It is very easy to prove the
following properties of bracket
[Lf, Lf] = 0,
(3.5)
[λ1Lf1 + λ2Lf2, Lg] = λ1[Lf1, Lg] + λ2[Lf2, Lg],
∀λ1, λ2 ∈R.
(3.6)
The commutator also satisﬁes the Jacobi identity, i.e., if Lf, Lg, Lh are three ﬁrst-
order differential operators, then
@
[Lf, Lg], Lh
A
+
@
[Lg, Lh], Lf
A
+
@
[Lh, Lf], Lg
A
= 0.
(3.7)
(3.7) is very easy to prove, the detailed proof process is seen [Arn89]. From the above,
we know that ﬁrst-order differential operator forms a Lie algebra.
Deﬁnition 3.2. A Lie series is an exponential of a ﬁrst-order linear differential oper-
ator
etLf =
∞

n=0
tnLn
f
n ! .
(3.8)
The action of a Lie series a scalar function ϕ(y) is given by:
etLf ϕ =
∞

k=0
tkLk
f
k ! ϕ(y) =
∞

k=0
tk
k !

f T(y)D
kϕ(y)
= ϕ(y) + tf T(y)(D(y)) + t2
2 f T(y)D

f T(y)Dϕ(y)

+ · · · .
(3.9)

8.3 Construction of Higher Order Schemes
379
Taylor expansion gives us an one elementary example of a Lie series
et[1,1,···,1]Dϕ(y)
=
∞

k=0
tk
k !
* n

i=1
d
dyi
+k
ϕ(y)
= ϕ

y + t(1, 1, · · · , 1)T
.
(3.10)
We have seen several properties of Lie series, which are similar to those of [Ste84]. Let,
f = (f1(y), f2(y), · · · , fn(y))T,
g = (g1(y), g2(y), · · · , gn(y))T,
and
etf TDg =

etf TDg1, etf TDg2, · · · , etf TDgn
T,
then, we have the following:
Property 3.3. The Lie series has the compositionality
etLf g(y) = g(etLf y).
(3.11)
Proof. It is enough to prove
etLf gm(y) = gm(etLf y).
Since
etLf y =
∞

k=0
tkLk
f
k ! y =
∞

k=0
tk
k !
* n

i=1
fi
∂
∂yi
+k
y,
considering j component (1 ≤j ≤n), in etLf y , we have
etLf yj =
∞

k=0

n

i=1
fi
∂
∂yi
k
yj = yj +
∞

k=1
tk
k !Lk−1
f
fj,
then
gm(etLf y) = gm
*
y1 +
∞

k=1
tk
k !Lk−1
f
f1(y), · · · , yn +
∞

k=1
tk
k !Lk−1
f
fn(y)
+
=
∞

k=0
tk
k !
* n

i=1
fi(y) ∂
∂yi
+k
gm(y) = etLf gm(y).
The proof can be obtained.
▲
Property 3.4. Product preservation property
etLf (pq) = (etLf p)(etLf q),
(3.12)

380
8. Composition Scheme
where p(y), q(y) are scalar functions.
Proof. By (3.2) – (3.3) and (3.8), (3.12) can be obtained by direct computation.
▲
Property 3.5. Baker-Campbell-Hausdroff formula (simply called BCH formula): All
ﬁrst differential operators constituted a Lie algebra. Therefore, we have the following
BCH formula:
etLf etLg = et(Lf +Lg)+t2w2+t3w3+t4w4+···,
(3.13)
where
w2 = 1
2[Lf, Lg],
w3 = 1
12
@
[Lf, Lg], Lf
A
+ 1
12
@
[Lf, Lg], Lg
A
,
w4 = 1
24
@
Lf,
@
Lg
@
Lg, Lf]
AA
,
· · · .
Property 3.6. If the differential equation property is,
y(t) = etf TDy,
y = y(0),
then
˙y(t) = f(y(t)).
Proof. Since yi(t) = etf T(y)Dyi(0), then
d
d tyi(t) = etf T(y)Df T(y)Dyi(0) = etf TDfi(y).
From Property 3.3, we have
d
d tyi(t) = fi(etf TDy) = fi

y1(t), y2(t), · · · , yn(t)

= fi(y(t)).
The proof can be obtained.
▲
From Property 3.6, we know that equation ˙y = f(y) can express the solution y(t) =
etLf y(0), Section 8.2 has discussed that the integral S(τ) can also be represented
in this form. If S(τ) has the group property about τ, it will be the phase ﬂow of
autonomous ODE d y
d τ = f(y). However, in our problem, there is just one parameter
family S(τ) without group property. So, there just exists a formal vector ﬁeld f τ(y),
which deﬁnes only the formal autonomous system
d y
d t = f τ(y).
Its formal phase ﬂow concerning two parameters τ, t, can be expressed by etLfτ . Take
the diagonal phase ﬂow

8.3 Construction of Higher Order Schemes
381
etLfτ |t=τ = eτLfτ .
This is just S(τ) Lie series expression. See the next chapter to know more about the
formal vector ﬁeld and the formal phase ﬂow. Since f τ(y) is a formal vector ﬁeld, it
is a formal power series in τ. Thus, the exponential representation of S(τ) will the
following form:
S(τ) = exp (τA + τ 2B + τ 3C + τ 4D + τ 5E + · · ·),
and series
τA + τ 2B + τ 3C + τ 4D + τ 5E + · · ·
may not be convergence, where A, B, C, D, E, · · · are ﬁrst-order differential opera-
tors. Therefore, we have:
Theorem 3.7. Every integrator S(τ) has a formal Lie expression [QZ92].
We use Theorem 3.7 to derive an important conclusion.
Theorem 3.8. Every self-adjoint integrator has an even order of accuracy[QZ92].
Proof. Let S(τ) be a self-adjoint integrator. Expand S(τ) in the exponential form
S(τ) = exp (τw1 + τ 2w2 + τ 3w3 + · · ·).
Suppose S(τ) is of order n, then
S(τ)y(0) = eτLf y(0) + O(τ n+1),
when the ODE to be solved is ˙y = f(y). Since
eτLf + o(τ n+1) = eτLf +O(τ n+1),
then
S(τ) = eτLf +O(τ n+1).
We must show that n is an even number. This means that we have to prove
w2 = w4 = w6 = w8 = · · · = 0.
Since
S(−τ) = exp (−τw1 + τ 2w2 −τ 3w3 + · · ·),
and using the BCH formula, we get
S(τ)S(−τ) = exp (2τ 2w2 + O(τ 3)).
(3.14)
Since S(τ) is self-adjoint, i.e., S(τ)S(−τ) = I, So (3.14) means w2 = 0, and (3.14)
becomes
S(τ)S(−τ) = exp

2τ 4w4 + O(τ 5)

.
This leads to w4 = 0. Continuing this process, we have

382
8. Composition Scheme
w2 = w4 = w6 = · · · = w2k = · · · = 0.
Thus S(τ) becomes
S(τ) = exp (τw1 + τ 3w3 + τ 5w5 + · · ·).
Therefore, if S(τ) is of order n, then n must be an even number. Since S(τ) is at least
of order 1, and if n ⩾2, we have w1 = Lf, because S(τ) Lie series expression is
unique.
▲
Now, we will provide a corollary on the construction of higher order schemes.
Corollary 3.9. Let S(τ) be a self-adjoint integrator with order 2n, if c1, c2 satisﬁes
2c2n+1
1
+ c2n+1
2
= 0,
2c1 + c2 = 1,
then composition integrator S(c1τ) S(c2τ) S(c1τ) is of order 2n + 2, solving the
above equations, we get [QZ92]:
c1 =
1
2 −
2n+1√
2,
c2 =
2n+1√
2
2 −
2n+1√
2.
Proof. From Theorem 2.6, we know S(c1τ)S(c2τ)S(c1τ) is a self-adjoint operator
and Theorem 3.8 shows it to be even order. Since S(τ) is of order 2n, the expansions
in exponential form of S(c1τ), S(c2τ) are
S(c1τ) = exp

c1τw1 + τ 2n+1c2n+1
1
w2n+1 + O(τ 2n+3)

,
S(c2τ) = exp

c2τw1 + τ 2n+1c2n+1
2
w2n+1 + O(τ 2n+3)

.
Again, by BCH formula, we get
S(c1τ)S(c2τ)S(c1τ)
= exp

(2c1 + c2)τw1 + (2c2n+1
1
+ c2n+1
2
)τ 2n+1w2n+1 + O(τ 2n+3)

= exp

τw1 + O(τ 2n+3)

.
The proof can be obtained.
▲
H. Yoshida in [Yos90] obtained the same result for symplectic explicit integrator
used to solve separable systems. The result can be applied to non-Hamiltonian systems
and non-symplectic integrators.
In this chapter, we will extend these results to solve general autonomous system’s
form. Some examples of adjoint scheme and its construction are given below. A con-
crete method to construct an adjoint for any given scheme is also given. This method
can be referred in literature [HNW93]. If the numerical solution is yτ, then any given
scheme may be expressed as:
yτ(x + τ) = yτ(x) + τφ(x, yτ(x), τ),
(3.15)

8.3 Construction of Higher Order Schemes
383
where φ is increment function corresponding to the scheme and τ is step size. By
substituting −τ instead of τ in (3.15), we get
y−τ(x −τ) = y−τ(x) −τφ

x, y−τ(x), −τ

,
and x + τ instead of x, we get
y−τ(x) = y−τ(x + τ) −τφ(x + τ, y−τ(x + τ), −τ).
(3.16)
For sufﬁciently τ, Equation (3.16), for y−τ(x+τ) possesses a unique solution (by the
implicit function theorem) and expresses in the following form:
y−τ(x + τ) = y−τ(x) + τφ∗
x, y−τ(x), τ

,
(3.17)
and (3.17) is just the adjoint scheme for (3.15). y−τ is the adjoint scheme of numerical
solution. φ∗is the increment function corresponding to the adjoint scheme (the above
process equals to: ﬁrst solve S(−τ), then solve S−1(−τ)). In fact; let y−τ(x + τ) =
A, y−τ(x) = B, from (3.16) and (3.17), we have

B = A −τφ(x + τ, A, −τ),
A = B + τφ∗(x, B, τ),
as in Equations (2.11) and (2.12) in Deﬁnition 2.2. Next, we would like to consider
self adjoint conditions for R–K method. Since most one-step multistage methods can
be written in R–K form, we now turn to the R–K methods to get some results which
may be useful. The general s-stage R–K method is in the form R–K .
⎧
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎩
ki = f

x0 + ciτ, y0 + τ
s

j=1
aijkj

,
y1 = y0 + τ
s

i=1
biki,
(3.18)
where y0 is numerical solution in x0, y1 is numerical value in x0 + τ, then
ci =
s

j=1
aij
(3.19)
may be expressed in Butcher tableau:
c1
a11
a12
· · ·
a1s
c2
a21
a22
· · ·
a2s
...
...
...
...
...
cs
as1
as2
· · ·
ass
b1
b2
· · ·
bs
The proof for the following Lemma 3.10 see [HNW93]. It can be proved by Deﬁnition
2.2 directly. Since we have proved the equivalence between Deﬁnition 2.1 and 2.2.

384
8. Composition Scheme
Lemma 3.10. Every R–K method has an adjoint method, whose coefﬁcients a∗
ij, b∗
j, c∗
j
(i, j = 1, · · · , s) can be written as follows:
⎧
⎪
⎨
⎪
⎩
c∗
i = 1 −c∗
s+1−i,
a∗
ij = bs+1−j −as+1−i,s+1−j,
b∗
j = bs+1−j.
(3.20)
Lemma 3.11. If as−i+1,s−j+1 + aij = bs−j+1 = bj, then the corresponding R–K
method (3.18) is self-adjoint.
Concentrating on semi-explicit symplectic R–K method, we have:
Theorem 3.12. The semi-explicit symplectic R–K method for autonomous systems is
self-adjoint if its Butcher tableau is of the form[QZ92].
Table 3.1.
Butcher tableau in theorem 3.12
b1
2
b1
b2
2
...
...
...
b1
b2
· · ·
b2
2
b1
b2
· · ·
b2
b1
2
b1
b2
· · ·
b2
b1
Proof. We know that the Butcher tableau of semi-explicit symplectic R–K method
must be of the form
b1
2
b1
b2
2
...
...
...
b1
b2
· · ·
bs−1
2
b1
b2
· · ·
bs−1
bs
2
b1
b2
· · ·
bs−1
bs
Tab. 3.1is obvious from Lemma 3.11.
By Lemma 3.11, we know that possesses such form of Table 3.1 is evident. For
non self-adjoint symplectic integrator S(τ), S∗(τ)S(τ) is self-adjoint, and is sym-
plectic. In order to prove that it is symplectic, it is enough to prove S∗(τ) is sym-
plectic. If S∗(τ)S(−τ) = I, then S∗(τ) = S−1(−τ). As S(τ) is symplectic, S(−τ)

8.3 Construction of Higher Order Schemes
385
and S−1(−τ) are symplectic integrators, and therefore S∗(τ) is also symplectic. The
two Lemmas given below can be seen in paper[HNW93]. Lemma 3.13 is derived from
Theorem 1.24 of Chapter 7 and Theorem 1.1 of Chapter 8.
▲
Lemma 3.13. If in an implicit s-stage R–K method, all ci (i = 1, · · · , s) are different
and at least of order s, then it is a collocation method iff it is satisﬁes:
s

j=1
aijcq−1
j
= cq
i
q ,
i = 1, · · · , s,
q = 1, · · · , s.
(3.21)
Lemma 3.14. Based on the symmetrical distribution, collocation algorithm is self-
adjoint.
As the Legendre polynomial is the orthogonal, coefﬁcient of Gauss–Legendre
method ci (i = 1, · · · , s) takes the root of Legendre polynomial Ps(2c −1) in which
the root is not mutually same. Moreover, the coefﬁcient of Gauss–Legendre method
aij (i, j = 1, · · · , s) satisﬁes formula (3.21) , and the Gauss–Legendre method is of
the order 2s; therefore, it is the collocation method. For details, see[HNW93]. We have:
Theorem 3.15. Gauss–Legendre methods are self-adjoint.
Proof. Since Gauss–Legendre method is collocation method, we only need to prove
ci = 1−cs+1−i, and ci are symmetrical distributions, where c1, c2, · · · , cs are the root
of Legendre polynomial Ps(2c −1) (lower index denotes order of polynomial). If the
root of Ps(w) are w1, w2, · · · , ws, then
ci = 1
2 −wi
2 ,
i = 1, · · · , s,
i.e., ci = 1 −cs+1−i and wi + ws+1−i = 0 are equivalent.
Legendre polynomial can be constructed by
 q0(w) = 1,
q−1(w) = 0,
qi+1(w) = (w −δi+1)qi(w) −γ2
i+1qi−1(w),
i = 0, 1, · · · ,
where
δi+1 = (wqi, qi)
(qi, qi) ,
i ≥0,
γ2
i+1 =
⎧
⎨
⎩
0,
for
i = 0,
(qi, qi)
(qi−1, qi−1),
for
i ≥1,
and
(qi, qj) =
- 1
−1
qi(w)qj(w) d w.
We obtain q1 = w, q2 = w2 −1
3, assuming q2n(w) is an even function and q2n−1 (w)
is an odd function. We proceed by induction on n, for n = 1, this has established.

386
8. Composition Scheme
Suppose q2n is an even function, and q2n−1 is an odd function. Prove that n+1 is also
true.
Since
δ2n+1 = (wq2n, q2n)
(q2n, q2n) =
- 1
−1
odd d w
(q2n, q2n)
= even|1
−1
(q2n, q2n) = 0,
then q2n+1 = wq2n −γ2
2n+1q2n−1(w) = odd function−odd function = odd function.
δ2n+2 = (wq2n+1, q2n+1)
(q2n+1, q2n+1) =
- 1
−1
odd dw
(q2n+1, q2n+1) = 0,
then q2n+2 = wq2n+1 −γ2
2n+2q2n(w) = is an even function. We have proved this
conclusion for n + 1. From this, the P2n(w) root may be written in the following
sequence:
−w1, −w2, · · · , −wn, wn, · · · , w2, w1.
But the root of p2n+1(w) has the following form:
−w1, −w2, · · · , −wn, 0, wn, · · · , w2, w1,
where wi > 0, wi > wi+1 (i = 1, · · · , n), therefore wi + wn+1−i = 0. Even though
we have the direct proof of Theorem 3.15, the computation is tedious. As a result of
Gauss–Legendre method coefﬁcient aij, bj satisﬁes the following equation:
s

j=1
aijcq−1
j
= cq
i
q ,
i = 1, · · · , s,
q = 1, · · · , s,
(3.22)
s

j=1
bjcq−1
j
= 1
q ,
q = 1, · · · , s.
(3.23)
Using the linear algebra knowledge, we have
aij =
s

k=1
(−1)n+k ck
i
k
;
j̸=l
(cj −cl)
ϕkj,
n = s
2,
bj =
s

k=1
(−1)n+k 1
k
;
j̸=l
(cj −cl)
ϕkj,
i, j, l = 1, · · · , s,
where
⎧
⎪
⎨
⎪
⎩
ϕkj =

{t1,t2,···,ts−k}⊂{1,2,···,j−1,j+1,···,s}
ct1ct2 · · · cts−k,
k < s,
ϕsj = 1.

8.3 Construction of Higher Order Schemes
387
The direct calculation may result in
s

k=1
(−1)n+k ck
i
k
;
j̸=l
(cj −cl)
ϕkj =
- ci
0
lj(t)d t,
j = 1, · · · , s,
(3.24)
s

k=1
(−1)n+k 1
k
;
j̸=l
(cj −cl)
ϕkj =
- 1
0
lj(t)d t,
j = 1, · · · , s,
(3.25)
where lj =
B
k̸=j
(t −ck)
B
k̸=j
(cj −ck), when ci = 1 −cs+1−i, we have li(t) = ls+1−i(1−t), then
as+1−i,s+1−j + aij = bs+1−j = bj,
from (3.24) and (3.25), it is easy to prove.
▲
Below given is an example to construct a self-adjoint scheme using a given scheme
[QZ92].
Example 3.16. It is well know that scheme (2.1) is of the ﬁrst order. From the above
method, the adjoint scheme will be

qn+1 = qn + τUp(pn),
pn+1 = pn −τVq(qn+1).
(3.26)
Composition scheme (2.2) from (2.1) and (3.26) is of order 2. In order to maintain
the transient step size, original τ will shrink and will become τ
2, because the present
scheme is S∗τ
2

S
τ
2

. If it is self-adjoint, the transient length of step size is main-
tained as τ.
Example 3.17. It is easy to prove that scheme
y1 = y0 + τ
2
@
f(y1) + f(y0)
A
is self-adjoint, and will be of order 2. Symmetrical composition scheme (1.22) is 3-
stage of 4th order and also self-adjoint.
Example 3.18. The explicit 4th order symplectic scheme (2.4) can be composed by
S2(x1τ) S2(x2τ) S2(x1τ) and developed as follows:
SV (c1τ)SU(d1τ)SV
0
12
3
S2(x1τ)
(c2 τ)SU(d2τ)SV
0
12
3
S2(x2τ)
(c3τ)SU(d3τ)SV (c4
0
12
3
S2(x1τ)
τ)SU(d4τ).
noting Corollary 3.9, we get:

388
8. Composition Scheme
c1 = c4 = x1
2 =
1
2 −
3√
3 = 0.6756035,
d1 = d3 = x1 =
1
2(2 −
3√
2) = 1.35120719,
d2 =
−
3√
2
2 −
3√
2 = x2 = −1.7024142,
d4 = 0,
c2 = c3 = x1 + x2
2
=
1 −
3√
2
2(2 −
3√
2) = −0.1756036.
Example 3.19. By literature[FQ91], we know that one class of symplectic scheme for
equation d y
d t = J∇H is
yk+1 = yk + τJ(∇H)
%1
2(I + JB)yk+1 + 1
2(I −JB)yk
&
,
BT = B,
(3.27)
J =
5 O
−In
In
O
6
,
I =
5 In
O
O
In
6
,
this scheme is of order 1, if B ̸= O; if B = O, then the scheme will be of order 2.
In scheme (3.27), if B = O, we can prove it is self-adjoint.
When B ̸= O, if integrator of scheme (3.27) is S(τ, H, B), then adjoint integrator
of scheme (3.27) will be
S(τ, H, −B) = S∗(τ, H, B).
Composition integrator from S
τ
2

and S∗τ
2

is self-adjoint with second order,
concrete scheme is
⎧
⎪
⎨
⎪
⎩
y1 = yk + τ
2J(∇H)
1
2(I −JB)y1 + 1
2(I + JB)yk
,
yk+1 = y1 + τ
2J(∇H)
1
2(I + JB)yk+1 + 1
2(I −JB)y1

.
8.4 Stability Analysis for Composition Scheme
In this paragraph, will discuss the stability of the three-stage [QZ93], fourth order
scheme which was constructed in Section 8.1
yn+ 1
3 = yn +
1
2(2 −2
1
3 )
τf

f(yn) + f(yn+ 1
3 )

,
yn+ 2
3 = yn+ 1
3 +
−2
1
3
2(2 −2
1
3 )
τ

f(yn+ 1
3 ) + f(yn+ 2
3 )

,
yn+1 = yn+ 2
3 +
1
2(2 −2
1
3 )
τ

f(yn+ 2
3 ) + f(yn+1)

.
(4.1)

8.4 Stability Analysis for Composition Scheme
389
We will prove that although the trapezoid method is A-stable, scheme (4.1) is not
A-stable. Fortunately , the unstable region is very small, as Fig. 4.2 (enlaged ﬁgure is
Fig.4.1) shows, and scheme (4.1) is still useful for solving stiff systems. Judging from
the size and location of the unstable region of scheme (4.1), we know it is safe for
systems which have eigenvalues not very adjacent to the real axis, while some other
methods which have unstable regions near the imaginary axis, such as Gear’s are safe
for systems which have eigenvalues not very adjacent to the imaginary axis.
–0.603 –0.596 –0.587 –0.579 –0.571 –0.563
–0.020
–0.012
–0.004
0.004
0.012
0.020
S
Fig. 4.1.
Closed curve S which contains all zero point of scheme (4.1)
–1.0
–0.6
–0.2
0.2
0.6
1.0
–2.0 –1.6
–1.2
–0.8
–0.4
0.0
Fig. 4.2.
Stability region size and position of (4.1)
Just the same as in scheme (4.1), the Euler midpoint rule can also be used to
construct a scheme:
⎧
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎩
yn+ 1
3 = yn +
1
2 −2
1
3 τf
%yn + yn+ 1
3
2
&
,
yn+ 2
3 = yn+ 1
3 +
−2
1
3
2 −2
1
3 τf
%yn+ 1
3 + yn+ 2
3
2
&
,
yn+1 = yn+ 2
3 +
1
2 −2
1
3 τf
%yn+ 2
3 + yn+1
2
&
.
(4.2)

390
8. Composition Scheme
Scheme (4.2) is symplectic, but scheme (4.1) is non-symplectic. We now study the
stability of scheme (4.1). Note that scheme (4.1) is not A- stable, whereas the trapezoid
method is. To show this, we apply scheme (4.1) to test equation
˙y = λy,
y(0) = y0,
λ ∈C,
Re λ < 0,
(4.3)
which yields
⎧
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎩
yn+ 1
3 = yn + c1
τ
2

λyn + λyn+ 1
3

,
yn+ 2
3 = yn+ 1
3 + c2
τ
2

λyn+ 1
3 + λyn+ 2
3

,
yn+1 = yn+ 2
3 + c1
τ
2

λyn+ 2
3 + λyn+1

,
(4.4)
i.e.,
⎧
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎩
yn+ 1
3 =
1 + c1λτ
2
1 −c1λτ
2
yn,
yn+ 2
3 =
1 + c2λτ
2
1 −c2λτ
2
yn+ 1
3 ,
yn+1 =
1 + c1λτ
2
1 −c1λτ
2
yn+ 2
3 ,
(4.5)
where c1 =
1
2 −2
1
3 , c2 =
−2
1
3
2 −2
1
3 . Let λτ
2 = z, z ∈C, we have
yn+1 = (1 + c1z)(1 + c2z)(1 + c1z)
(1 −c1z)(1 −c2z)(1 −c1z)yn.
(4.6)
Deﬁnition 4.1. The stable region R of scheme (4.1) is:
R =
⎧
⎪
⎨
⎪
⎩
λτ ∈C


%
1 + c1λτ
2
&%
1 + c2λτ
2
&%
1 + c1λτ
2
&
%
1 −c1λτ
2
&%
1 −c2λτ
2
&%
1 −c1λτ
2
&
 < 1, Re (λτ) < 0
⎫
⎪
⎬
⎪
⎭
,
i.e.,
R =

z ∈C

(1 + c1z)(1 + c2z)(1 + c1z)
(1 −c1z)(1 −c2z)(1 −c1z)
 < 1, Re z < 0
7
.
(4.7)
Obviously, when z →1
c2 (< 0), we have

(1 + c1z)(1 + c2z)(1 + c1z)
(1 −c1z)(1 −c2z)(1 −c1z)
 −→∞.

8.4 Stability Analysis for Composition Scheme
391
This means schemes (4.1) cannot be stable in the adjacent region 1
c2 . Thus, we obtain
the following theorem:
Theorem 4.2. Scheme (4.1) is not A-stable.
Since scheme (4.1) is not A-stable, we will ﬁgure out the stable region of it. To do
this, we will ﬁrst study the roots of the following equation:

(1 + c1z)(1 + c2z)(1 + c1z)
(1 −c1z)(1 −c2z)(1 −c1z)
 = 1.
(4.8)
Once the roots of (4.8) are known, it is not difﬁcult to get the stable region of (4.1).
Note Equation (4.8) is equivalent to
(1 + c1z)(1 + c2z)(1 + c1z)
(1 −c1z)(1 −c2z)(1 −c1z) = eiθ,
0 ≤θ < 2π.
(4.9)
From (4.9), we get the following polynomial:
c2
1c2(1 + eiθ)z3 + (2c1c2 + c2
1)(1 −eiθ)z2
+(2c1 + c2)(1 + eiθ)z + (1 −eiθ) = 0,
0 ≤θ < 2π.
(4.10)
Since 2c1 + c2 = 1, and a = c2
1c2, b = 2c1c2 + c2
1, then (4.10) becomes:
a(1 + eiθ)z3 + b(1 −eiθ)z2 + (1 + eiθ)z + (1 −eiθ) = 0,
0 ≤θ < 2π.
(4.11)
Consider the roots of (4.11) in two cases.
Case 4.3. 1 + eiθ ̸= 0 (i.e., 0 ≤θ < 2π, θ ̸= π).
By computing the roots of polynomial (4.11), we get
z1 = x + yi,
z2 = −x + yi,
z3 = wi,
x, y, w ∈C
(4.12)
when θ is chosen as a deﬁnite value. z1, z2, z3 should satisfy
(z −z1)(z −z2)(z −z3)
=
a(1 + eiθ)z3 + b(1 −eiθ)z2 + (1 + eiθ)z
+(1 −eiθ) = 0
⇐⇒
⎧
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎩
z1 + z2 + z3 = −b
a
1 −eiθ
1 + eiθ

,
z1z2 + z1z3 + z2z3 = 1
a,
z1z2z3 = −1
a
1 −eiθ
1 + eiθ

.
(4.13)
Since

392
8. Composition Scheme
1 −eiθ
1 + eiθ = (1 −cos θ) −i sin θ
(1 + cos θ) + i sin θ = −
sin θ
1 + cos θi,
then
⎧
⎪
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎪
⎩
z1 + z2 + z3 = b
a
sin θ
1 + cos θ i = ip1,
z1z2 + z1z3 + z2z3 = 1
a = p2,
z1z2z3 = 1
a
sin θ
1 + cos θ i = ip3,
(4.14)
where p1, p2, p3 are real numbers. From (4.12) and (4.14), we have equations of
x, y, w as the following:
2y + w = p1,
(4.15)
x2 + y2 + 2yw = −p2,
(4.16)
x2w + y2w = −p3.
(4.17)
Now, we will prove that Equations system (4.15)–(4.17) exists as a set of real solution.
In fact, from (4.16) and (4.17), we get:
p2w + 2yw2 = p3.
(4.18)
From (4.15) and (4.18), we have
w3 −p1w2 −p2w + p3 = 0.
(4.19)
Since p1, p2, p3 are all real, (4.19) is a polynomial with real coefﬁcient and has one
real root and two conjugate complex roots. Using the real root w from (4.19), we can
get a real value of y from (4.15) , and from (4.16) and (4.17), we have x2 = real, then
x is real or pure imaginary. If x is pure imaginary, then from (4.12), z1, z2, z3 are all
pure imaginaries, so all the the roots of (4.11) are on the imaginary axis. This means
that if we assume
V (z) =

(1 + c1z)(1 + c2z)(1 + c1z)
(1 −c1z)(1 −c2z)(1 −c2z)
 ,
then, V (z) > 1 or V (z) < 1 for Re (z) < 0. For the same reason that scheme (4.1)
cannot be A-stable, V (z) > 1 for Re (z) < 0 is possible, but we have V (−0.5) < 1,
and V (z) is continuous except at 1
c2 . Thus, x is impossible to be pure imaginary, so
it must be real. Since polynomial (4.11) only has three roots, we will get the same
results of z1, z2, z3 if we use other value of w, real or complex.
Case 4.4. 1 + eiθ = 0 (i.e., θ = π).
When θ = π, (4.11) becomes z2 = −1
b > 0, then it has two real roots ±
D
−1
b .
Eventually, we get the following:

8.4 Stability Analysis for Composition Scheme
393
Theorem 4.5. The three roots of polynomial (4.11) are in the form :
z1 = −x + yi,
z2 = x + yi,
z3 = wi,
where x, y, w are all real.
Theorem 4.5 tells us that there is a root of (4.10) on the imaginary, and that the two
other roots are located symmetrically with respect to the imaginary axis. Thus, there
is only one root on the left open semi-plane. Computation shows that these roots form
a closed curve S (when θ changes from 0 to 2π), as in Fig. 4.1.
From (4.15) – (4.17), we get the equation for S:
 x2 −3y2 + 2p1y + p2 = 0,
2yx2 + 2y3 −p1x2 −p1y2 −p3 = 0,
0 ≤θ < 2π,
θ ̸= π.
(4.20)
and
x = ±
D
−1
b ,
y = 0,
for θ = π,
(4.21)
where z = −x + iy, p1 =
b sin θ
a(1 + cos θ), p2 = 1
a, p3 =
sin θ
a(1 + cos θ).
Since in S, V (z) > 1, and when z →∞, V (Z) →1, we can conclude the
stability of scheme (4.1).
Theorem 4.6. The stable region R of scheme (4.1) is [QZ93] :
R = {z ∈C | z outside S and Re z < 0},
i.e.,
R = {λτ ∈C | λτ outside S∗and Re (λτ) < 0}, where S∗=
(
z ∈C | z
2 ∈S
)
.
Scheme (4.1) is not A-stable, the outside region of it is inﬁnite, and the unstable
region is very small. The unstable region is blackened in Fig. 4.2, it is a little “disk”
about −1.18 on the real axis. For every deﬁnite λ, we can choose some special step
length τ, such that λτ will not be in S∗, while the step-length τ need not be very small
for λ which has a big modulus. Because of linear cases, scheme (4.2) is equivalent to
(4.1). So, scheme (4.2) has exactly the same stable region as (4.1). Thus, we conclude
that scheme (4.1) and (4.2) are still useful for solving stiff problems, which we wanted
to show in example.
Following are some numerical tests for stability of scheme (4.1).
Example 4.7. Numerical test for orders of schemes (4.1) and (4.2).
To test the order scheme (4.1) and (4.2), we apply them to the following Hamilto-
nian system:
⎧
⎪
⎪
⎨
⎪
⎪
⎩
d p
d t = −∂H
∂q = −w2q −q3,
d q
d t = ∂H
∂p = p,
(4.22)

394
8. Composition Scheme
where the Hamiltonian H = 1
2

p2 + w2q2 + 1
2q4
, and compare the numerical solu-
tions with trapezoid method and centered Euler scheme.
For convenience, the numerical solution of p and q can be denoted as
1◦
(4.1) by T4p, T4q.
2◦
(4.2) by E4p, E4q.
3◦
trapezoid scheme by T2p, T2q.
4◦
centered Euler scheme by E2p, E2q. Respectively, we use double precision
in all computations. We can see the following explicit scheme:
⎧
⎪
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎪
⎩
pn+ 1
2 = pn −τ
2Vq(qn),
qn+ 1
2 = qn + τ
2Up(pn+ 1
2 ),
qn+1 = qn+ 1
2 + τ
2Up(pn+ 1
2 ),
pn+1 = pn+ 1
2 −τ
2Vq(qn+1),
(4.23)
c1 = c4 = x1
2 =
1
2 −
3√
3 = 0.6756035,
d1 = d3 = x1 =
1
2(2 −
3√
2) = 1.35120719,
d2 =
−
3√
2
2 −
3√
2 = x2 = −1.7024142,
d4 = 0,
c2 = c3 = x1 + x2
2
=
1 −
3√
2
2(2 −
3√
2) = −0.1756036.
A separable system with H = V (q) + U(p) is self-adjoint, so it can be used
to construct fourth-order scheme to get (4.1) and (4.2). From Sections 8.2 and 8.3,
the simpliﬁed fourth-order scheme can be written taking c1 =
1
2 −2
1
3 = c3, c2 =
−2
1
3
2 −2
1
3 , x1 = x3 = 1.35120719, x2 = −1.7024142. For details see Example 3.18.
⎧
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎩
pn+ 1
4 = pn −x1
τ
2Vq(qn),
qn+ 1
3 = qn + x1τUp(pn+ 1
4 ),
pn+ 1
2 = pn+ 1
4 −x1 + x2
2
τVq(qn+ 1
3 ),
qn+ 2
3 = qn+ 1
3 + x2τUp(pn+ 1
2 ),
pn+ 3
4 = pn+ 1
2 −x2 + x3
2
τVq(qn+ 2
3 ),
qn+1 = qn+ 2
3 + x3τUp(pn+ 3
4 ),
pn+1 = pn+ 3
4 −x3
τ
2Vq(qn+1),
(4.24)
where pn+ 1
4 , pn+ 1
2 , pn+ 3
4 and qn+ 1
3 , qn+ 2
3 denote the numerical solution of different
stages at every step. Scheme (4.24) has been proved by H. Yoshida to be a fourth-
order scheme in [Yos90]. We can apply scheme (4.24) to Equation (4.22) and compare

8.4 Stability Analysis for Composition Scheme
395
Table 4.1.
Numerical comparison between several schemes
Step N
Numerical solution and exact solution
EXp = −1.131 156 917 000000
EXq = −0.021 512 660 000000
T 4p −EXp = 0.000 014 55000
T 4q −EXq = −0.000 003 728
N = 10
E4p −EXp = 0.000 068 24300
E4q −EXq = −0.000 029 687
T 2p −EXp = 0.000 641 21600
T 2q −EXq = 0.003 917 96400
E2p −EXp = 0.000 025 85700
E2q −EXq = 0.004 206 14700
EXp = −0.578 997 162 000000
EXq = −0.479 477 967 00000
T 4p −EXp = 0.000 004 11500
T 4q −EXq = −0.000 002 660
N = 20
E4p −EXp = −0.000 116 088
E4q −EXq = −0.000 029 838
T 2p −EXp = −0.014 158 525
T 2q −EXq = −0.003 977 057
E2p −EXp = −0.015 197 562
E2q −EXq = −0.004 255 307
EXp = −1.083 692 040 00000
EXq = 0.163 258 193 0000000
T 4p −EXp = −0.000 104 873
T 4q −EXq = −0.000 195 865
N = 100
E4p −EXp = 0.000 145 7860
E4q −EXq = 0.000 131 2730
T 2p −EXp = 0.024 490 7400
T 2q −EXq = 0.036 283 1300
E2p −EXp = 0.027 254 9000
E2q −EXq = 0.039 223 1760
EXp = −1.089 537 517 000000
EXq = −0.153 288 801 000000
T 4p −EXp = 0.000 560 51300
T 4q −EXq = −0.001 139 354
N = 500
E4p −EXp = −0.000 250 063
E4q −EXq = 0.000 559 4940
T 2p −EXp = −0.040 591 714
T 2q −EXq = 0.188 655 9980
E2p −EXp = −0.037 488 191
E2q −EXq = 0.204 743 2350
EXp = −0.966 531 326 000000
EXq = −0.293 028 275 000000
T 4p −EXp = 0.002 470 90100
T 4q −EXq = 0.002 014 58300
N = 1000
E4p −EXp = −0.001 281 080
E4q −EXq = −0.000 988 873
T 2p −EXp = −0.603 588 331
T 2q −EXq = −0.233 974 665
E2p −EXp = −0.668 484 708
E2q −EXq = −0.243 402 518
the results with that of schemes we mentioned above. We denote EXp and EXq as
the exact solution of p and q for system (4.22), and present our results when taking
w = 2, τ = 0.1, p0 = 0.5, q0 = 0.5 in Table 4.1. From Table 4.1, we can see that
T4p, T4q and E4p, E4q are more approximate to EXp, EXq than T2p, T2q and
E2p, E2q. Thus, we conclude that scheme (4.1) and (4.2) have a higher order than
trapezoid method and centered Euler scheme. Table 4.1 also shows that although the
trapezoid scheme (4.1) is non-symplectic, it can be used to solve a Hamiltonian system
to get satisfactory results than the centered Euler scheme, by nonlinear transformation;
the latter can be obtained from the former, see Section 8.1.
Example 4.8. Numerical test for stability of schemes (4.1) and (4.2). To consider
the unstable case, we take λ = −11.8, τ = 0.1, and initial value y0 = 1.0 in the
test equation, so λτ falls into the unstable region. While the exact solution decreases
quickly, the numerical solution obtained by scheme (4.1) grows to inﬁnity as shown
in Table 4.2.
Example 4.9. For the stable case, we consider a linear stiff system

˙y1 = −501y1 + 500y2,
˙y2 = 500y1 −501y2,
(4.25)
which has eigenvalues λ1 = −1001, λ2 = −1. The exact solution is

396
8. Composition Scheme
Table 4.2.
Stability test
Step number
Numerical and exact solution
Step1
0.576776990×101
0.307278738
Step10
0.407404568×108
0.000007504
Step50
0.112235299×1039
0.000000000
Step100
0.816583328×1075
0.000000000
Table 4.3.
Test for stiff system
Step N
Numerical solution and exact solution
EXY 1 = 0.998364638
EXY 2 = 0.991660285
N = 10
T 4Y 1 = 0.998453117
T 4Y 2 = 0.991571619
T 4Y 1 −EXY 1 = 0.000088478
T 4Y 2 −EXY 2 = −0.000088666
EXY 1 = 0.985112102
EXY 2 = 0.985111801
N = 30
T 4Y 1 = 0.985111988
T 4Y 2 = 0.985111662
T 4Y 1 −EXY 1 = −0.000000114
T 4Y 2 −EXY 2 = −0.000000138
EXY 1 = 0.975309908
EXY 2 = 0.975309908
N = 50
T 4Y 1 = 0.975309788
T 4Y 2 = 0.975309788
T 4Y 1 −EXY 1 = −0.000000120
T 4Y 2 −EXY 2 = −0.000000120
EXY 1 = 0.006571583
EXY 2 = 0.006571583
N = 100
T 4Y 1 = 0.006571770
T 4Y 2 = 0.006571771
T 4Y 1 −EXY 1 = −0.000000186
T 4Y 2 −EXY 2 = −0.000000188
EXY 1 = 0.000000298
EXY 2 = 0.000000298
N = 200
T 4Y 1 = 0.000000298
T 4Y 2 = 0.000000298
T 4Y 1 −EXY 1 = −0.000000000
T 4Y 2 −EXY 2 = −0.000000000
⎧
⎨
⎩
y1(t) = f1(y1, y2) = 0.5

y1(0) −y2(0)

e−1001t + 0.5

y1(0) + y2(0)

e−t,
y2(t) = f2(y1, y2) = −0.5

y1(0) −y2(0)

e−1001t + 0.5

y1(0) + y2(0)

e−t,
(4.26)
where y1(0), y2(0) denote the initial value. Since system (4.25) is linear, schemes
(4.1) and (4.2) are equivalent in this case. We present a numerical solution using
scheme (4.1) here. In Table 4.3, we denote the numerical solution of y1 and y2 using
(4.1) by T4Y 1, T4Y 2, and the exact solution of y1 and y2 by EXY 1 and EXY 2. We
also assume τ = 0.1, y1(0) = 1.5, y2(0) = 0.5, in the Table 4.3, while τ = 0.0005
in the ﬁrst 50 steps, and τ = 0.1 in the remaining steps.
8.5 Application of Composition Schemes to PDE
When solving partial differential equations (PDEs), there are several methods such as
spectral methods and ﬁnite difference methods which can be used to achieve high-
order accuracy in the space direction, while it is difﬁcult to obtain high-order accu-
racy in time direction. So it is obvious that the overall accuracy is often inﬂuenced
strongly by the relatively unsatisfactory approximation in the time direction. Though
the self-adjoint schemes (also called symmetrical schemes or reversible schemes) are
well known, such as the composed Strang scheme [Str68] which is of order 2, the ad-
vantage of these schemes which can be used to construct higher order schemes is long

8.5 Application of Composition Schemes to PDE
397
neglected. In this section, we use scheme (4.1) to solve two kinds of PDEs in order to
show that the technique introduced in previous section can be used to overcome the
deﬁciency in the time direction, since theoretically, we can construct arbitrary even
order schemes in the time direction[ZQ93b].
Let us ﬁrst consider the following one-dimensional ﬁrst-order wave equation
 ut + ux = 0,
u(x, 0) = f(x),
0 ≤x ≤2π,
(5.1)
with periodic boundary conditions
u(0, t) = u(2π, t).
Since collocation, Galerkin, and tau methods are identical in the absence of essen-
tial boundary conditions, we will analyze the Fourier collocation or pseudospectral
method. Let us introduce the collocation points xn = 2πn/2N (n = 0, · · · , 2N −1),
and let u = (u0, · · · , u2N−1), where un = u(xn, t). The collocation equation that
approximates (5.1) is as follows:
∂u
∂t = C−1DCu,
(5.2)
where C and D are 2N × 2N matrices whose entries are
ckl =
1
√
2N
exp
@
(k −N)xl
A
,
(5.3)
dkl = −k∗δkl,
(5.4)
where k∗= k −N (1 ≤k ≤2N −1), and k∗= 0, if k = 0. For the process of
the discretization, see also literature [GO77], we leave out the proof in this, but directly
quote. To solve this, let us consider Equation (5.1) with initial value f(x) = sin x, and
compare the numerical solution with the exact solution u(x, t) = sin (x −t), we use
scheme (4.1) and trapezoid scheme (crank-Nicolson) to solve Equation (5.2) (N = 5).
All u values are calculated in the collocation points taking the time step size
τ = 0.1 and 0.01, and respectively calculating 100 steps with the double precision.
ORD.4 and ORD.2, represent results that use (4.1) and the trapezoidal form obtained
numerical solution respectively. ERR.4 and ERR.2 represent error between numer-
ical solution ORD.4 and ORD.2 and the exact solution, where the collocation point
is n. We list u(x, t) in each step with values 0, 5, 9 as collocation points. The exact
solution is denoted by EX. From Table 5.1 and Table 5.2 we can see that the solution
of the 4th order scheme is more precise than the solution of the 2nd order scheme,
when τ = 0.1 precise 2, when τ = 0.01 precise 4.

398
8. Composition Scheme
Table 5.1.
Comparison between numerical and exact solution when τ =0.1
Step N
n
EX
ORD.4
ORD.2
ERR.4
ERR.2
0
−0.099833416647
−0.099832763924
−0.099750623437
0.000000652723
0.000082793209
N = 1
5
0.099833416647
0.099832763924
0.099750623438
−0.000000652723
−0.000082793209
9
−0.665615704994
−0.66561545443
−0.665553604585
0.000000489551
0.000062100409
0
−0.841470984808
−0.841467440655
−0.841021115481
0.000003544153
0.000449869327
N = 10
5
0.841470984808
0.841467440655
0.841021115481
−0.000003544153
−0.000449869327
9
−0.998346054152
−0.998346431587
−0.998393545150
−0.000000377435
−0.000047490998
0
0.544021110889
0.543966068061
0.537020563223
−0.000055042829
−0.007000547666
N = 100
5
−0.544021110889
−0.543966068061
−0.537020563223
0.000055042829
0.007000547666
9
0.933316194418
0.933292641025
0.930296266090
−0.000023553213
−0.003019928328
Table 5.2.
Comparison between numerical and exact solution when τ = 0.01
Step N
n
EX
ORD.4
ORD.2
ERR.4
ERR.2
0
0.009999833340
−0.099998333280
−0.009999750000
0.000000000007
0.000000083334
N = 1
5
0.009999833340
0.009999833280
0.009999750000
−0.000000000007
−0.000000083334
9
−0.595845898383
−0.595845898378
−0.595845831454
0.000000000005
0.000000066929
0
−0.099833416647
−0.099833416582
−0.099832587427
0.000000000065
0.000000829220
N = 10
5
0.099833416647
0.099833416582
0.099832587427
0.000000000042
−0.000000829220
9
−0.665615704994
−0.665615704952
−0.665615083044
0.000000000003
0.000000621950
0
−0.841470984808
−0.841470984547
−0.841466481987
0.000000000261
−0.000004502821
N = 100
5
0.841470984808
0.841470984547
0.841466481987
−0.000000000267
−0.000004502871
9
−0.998346054152
−0.998346054304
−0.998346533230
−0.000000000152
−0.000000479078
Similarly, in 2nd order PDE, the result of the 4th order scheme is more precise
when compared to the result of the 2nd order scheme in 2 - 4 precision.
Let us take the second order heat conductivity equation
⎧
⎪
⎪
⎨
⎪
⎪
⎩
∂u(x, t)
∂t
=
∂2u(x, t)
∂x2
,
0 < x < π,
t ≥0,
u(0, t) = u(π, t) = 0,
t > 0,
u(x, 0) = f(x),
0 ≤x ≤π.
(5.5)
By applying Fourier sine approach in Equation (5.5), we get
uN(x, t) =
N

n=1
an(t) sin nx,
(5.6)
and
⎧
⎪
⎪
⎨
⎪
⎪
⎩
d an
d t = −n2an,
an(0) = 2
π
- π
0
f(x) sin nx d x.
(5.7)

8.5 Application of Composition Schemes to PDE
399
Table 5.3.
Comparison between numerical and exact solution when τ =0.1
Step N
n
EX
ORD.4
ORD.2
ERR.4
ERR.2
1
0.531850090044
0.5318500444815
0.531805704455
0.0000003547710
−0.000044385589
N = 1
2
0.860551522611
0.8605520966420
0.860479705219
0.0000005740310
−0.000071817391
3
0.860551522611
0.8605520966420
0.860479705219
0.0000005740310
−0.000071817391
4
0.531850090044
0.5318504448150
0.531805704455
0.0000003547710
−0.000443855890
1
0.216234110142
0.2162355525360
0.216053719560
0.0000001442394
−0.000180390582
N = 10
2
0.349814139737
0.3498764735800
0.349582261644
0.0000023338430
−0.000291878093
3
0.349814139737
0.3498764735800
0.349582269644
0.0000123338430
−0.000291878093
4
0.216234110142
0.2162355522536
0.216053719560
0.0000014423940
−0.000180390582
1
0.003960465877
0.0039605979700
0.003943973573
0.0000001320940
−0.000164923040
N = 50
2
0.006408168400
0.0064083821320
0.006381483292
0.0000002137320
−0.000026685108
3
0.006408168400
0.0064083821320
0.006381483292
0.0000002137320
−0.000026685108
4
0.003960465877
0.0039605979700
0.003943973573
0.0000001320940
−0.000164923040
The initial value of an can be represented in another form. Let xj =
πj
N + 1 (j =
1, · · · , N) be collocation points, from collocation equation
N

n=1
an sin πjn
N + 1 = u(xj),
j = 1, · · · , N,
(5.8)
we get explicit solution
an =
2
N + 1
N

j=1
u(xj) sin πjn
N + 1,
n = 1, · · · , N.
Since u(x, 0) = f(x), we get:
an(0) =
2
N + 1
N

j=1
f(xj) sin
πjn
N + 1,
n = 1, · · · , N.
(5.9)
The exact solution for Equation (5.5) with boundary condition f(x) = sin x is
e−t sin x. In Table 5.3 and Table 5.4, all symbols carry the same signiﬁcance. We
take N = 4 for computation.
To solve the semi-discrete spectral approximations
ut = LNu,
(5.10)
of the differential equation
ut = Lu,
(5.11)
where L denotes the spacial operator, we often use the Crank–Nicolson scheme, back-
ward Euler scheme, and leap-frog scheme. However, we know the backward and for-
ward Euler schemes are not self-adjoint, nor the leap-frog scheme. But the ﬁrst two
schemes are adjoint to each other and the composition is the Crank–Nicolson scheme

400
8. Composition Scheme
Table 5.4.
Comparison between numerical and exact solution when τ =0.01
Step N
n
EX
ORD.4
ORD.2
ERR.4
ERR.2
1
0.581936691312
0.581936691316
0.581936642817
−0.000000000004
−0.000000048495
N = 1
2
0.941593345844
0.941593345850
0.941593267377
0.000000000006
−0.000000078467
3
0.941593345844
0.941593345850
0.941593267377
0.000000000006
−0.000000078467
4
0.581936693120
0.581936691316
0.581936642817
−0.000000000004
−0.000000048495
1
0.216234110142
0.216234110285
0.216232308172
0.0000000001430
−0.000001801970
N = 100
2
0.349874139137
0.349874139969
0.349811224088
0.0000000002310
−0.000002915049
3
0.349874139137
0.349874139969
0.349811224088
0.0000000000231
−0.000002915049
4
0.276234110142
0.216234110285
0.216232308172
0.0000000001430
−0.000001801970
un+1 −un = Δt1
2

LNun+1 + LNun
.
(5.12)
which is self-adjoint and of order 2. We can construct a fourth-order scheme by com-
position
un+1/3 = un +
1
2(2 −21/3)Δt

LNun + LNun+1/3
,
un+2/3 = un+1/3 −
21/3
2(2 −21/3)Δt

LNun+1/3 + LNun+2/3
,
(5.13)
un+1 = un+2/3 +
1
2(2 −21/3)Δt

LNun+2/3 + LNun+1
.
Finally, we can point out that scheme (5.13) is unstable for some special step size of
t. Since the diameter of the unstable region is very small, we can always avoid taking
those step-size Δt which make λΔt (λ denotes the eigenvalue of the system to be
solved) fall into the unstable region. Fig. 5.1 shows the solution of the heat equation
when we use scheme (5.13) to solve the (5.11) We take Δt = 0.0097 and N = 24. We
can conclude that while the Crank–Nicolson remains stable, the scheme (5.13) does
not, and solution tends to overﬂow. For a Detailed numerical test about this problem,
see[ZQ93b].
Fig. 5.1.
Stability comparison between schemes of Crank–Nicolson (L), (5.13) (M) and exact
solution (R) of the heat equation

8.6 H-Stability of Hamiltonian System
401
8.6 H-Stability of Hamiltonian System
We know that Hamiltonian system always appears in space of even dimension. A
more important fact is that there is no asymptotically stable linear Hamiltonian system.
They are either Liapunov stable or unstable, so are the linear symplectic algorithms.
Therefore, the usual stability concepts in numerical methods for ODEs are not suitable
to symplectic algorithms for Hamiltonian systems, for example, A-stability and A(α)
stability, α ≤π
2 . Hence, usual A(α) stability is useless for α ≤π
2 and A-stability
needs to be modiﬁed. Here, we introduce a new test system and a new concept-H-
stability (Hamiltonian stability) for symplectic algorithms and discuss the H-stability
of symplectic invariant algorithms and the H-stability intervals of explicit symplectic
algorithms.
For the linear Hamiltonian system
d z
d t = Lz,
L = JA ∈sp(2n),
H = (z, Az), AT = A,
(6.1)
a linear symplectic algorithm
zk+1 = gt
H(zk) = G(s, A)zk,
k ⩾0
(6.2)
is stable, if ∃C > 0, such that
∥zk∥= ∥Gk(s, A)z0∥⩽C∥z0∥,
∀k > 0,
(6.3)
where∥• ∥is a well-deﬁned norm, such as Euclidean norm. Evidently, it is equivalent
to ∥Gk(s)∥bounded, or the eigenvalues of G(s) are in the unit disk and its elementary
divisors corresponding to the eigenvalues on the unit circle are linear. Since G(s) is
symplectic, then
G−1(s) = J−1G(s)TJ.
(6.4)
Hence, if λ is an eigenvalue of G(s), so is λ−1, and they have the same elementary
divisors. Therefore, the eigenvalue with the module less than 1 is always accompa-
nied with the eigenvalue with the module great than 1. This implies that the linear
symplectic method (6.1) cannot be asymptotically stable. We have:
Theorem 6.1. Linear symplectic method (6.1) is stable iff the eigenvalues of G(s) are
unimodular and their elementary divisors are linear [Wan94].
Here, we introduce the test Hamiltonian system
dz
dt = αJz,
α ∈R,
(6.5)
with
H(z) = H(p, q) = α
2 zTz = α
2 (p2 + q2),
A = αI.

402
8. Composition Scheme
Deﬁnition 6.2. A symplectic difference method is H-stable at μ = αs, if it is stable
for the test Hamiltonian system (6.2) with the given μ, such μ is called a stable point.
The maximum interval in which every point is stable and which contains the original
point is called the H-stability interval of the method. A symplectic difference method
is H-stable if its H-stability interval is the whole real axis. In this case, its numerical
solutions are bounded for (6.2) with α ∈R.
Remark 6.3. It is reasonable to choose (6.5) as the model equation because any linear
Hamiltonian system may turn into the standard form
H(p, q) = 1
2
n

i=1
αi(p2
i + q2
i ).
Test Equations (6.2) and (6.1) become
zk+1 = G(μ)zk,
(6.6)
where G(μ) is 2 × 2 symplectic matrix. If
G(μ) =
5 a1
a2
a3
a4
6
,
then det G(μ) = a1a4 −a2a3 = 1. Its characteristic polynomial is
|G(μ) −λI| =

a1 −λ
a2
a3
a4 −λ
 = λ2 −(a1 + a4)λ + 1.
So, its eigenvalues are
λ± = a1 + a4
2
±
E%a1 + a4
2
&2
−1.
(6.7)
Lemma 6.4. Scheme (6.6) is stable at μ ̸= 0, iff
a1 + a4
2
2
< 1,
i.e., −1 < a1 + a4
2
< 1.
(6.8)
Example 6.5. Applying the centered Euler scheme to the test system (6.5), it becomes
z = z + 1
2μJ(z + z),
μ = αs,
z =

I + 1
2μJ
−1 
I −1
2μJ

z,
where

8.6 H-Stability of Hamiltonian System
403
G(μ) =
1
1 + 1
4μ2
⎡
⎢⎣
1 −1
4μ2
−μ
μ
1 −1
4μ2
⎤
⎥⎦,
(6.9)
therefore
%a1 + a4
2
&2
=
⎛
⎝1 −1
4μ2
1 + 1
4μ2
⎞
⎠< 1,
∀μ ̸= 0.
By Lemma 6.4, we know that the centered Euler scheme to all μ ̸= 0 is stable, cer-
tainly it is also stable for μ = 0, therefore, the centered Euler scheme is H-stable.
For the stability region of certain explicit scheme, see the literature [Wan94,QZ90].
In Section 8.2, we have constructed schemes of difference from 1st order to 4th
order. We will now discusses its stability by applying these schemes to the model
Equation (6.5), we get
zk+1 = Gi(μ)zk,
μ = αs,
i = 1, 2, 3, 4
Gi is the step transition equation.
G1(μ) =
* 1
−μ
μ
1 −μ2
+
,
G2(μ) =
⎛
⎜
⎝
1 −1
2μ2
−μ
μ

1 −1
4μ2
1 −1
2μ2
⎞
⎟
⎠,
G3(μ) =
⎛
⎜
⎝
1 −1
2μ2 + 1
72μ4
−μ

1 −1
6μ2 +
7
1728μ4
μ

1 −1
6μ2 + 1
72μ4
1 −1
2μ2 + 5
72μ4 −
7
1728μ6
⎞
⎟
⎠,
G4(μ) =
* a1
a2
a3
a4
+
,
a1 = 1 −1
2μ2 + 1
24μ4 +
1
144(1 + β)2μ6,
a2 = −μ

1 −1
6μ2 −
1
216(2 + β)(1 + 2β)2μ4
,
a3 = μ

1 −1
6μ2 −
1
216(2 + β)(1 −β)μ4 +
1
864(2 + β)(1 + β2)μ6
,
a4 = 1 −1
2μ2 + 1
24μ4 +
1
144(1 + β)2μ6.

404
8. Composition Scheme
Theorem 6.6. From the explicit scheme above, the H-stability intervals are (−2, 2),
(−2, 2), (−2.507, 2.507) and (−1.573, 1.573).
Proof. Proof of this theorem can be found in paper of Daoliu Wang[Wan94] and paper
of Mengzhao Qin and Meiqing Zhang[QZ90].
▲

Bibliography
[Arn89] V. I. Arnold: Mathematical Methods of Classical Mechanics. Springer-Verlag, GTM
60, Berlin, Second edition, (1989).
[Dah75] G. Dahlquist: Error analysis for a class of methods for stiff nonlinear initial value
problems.
In G.A. Watson, editor, Lecture Notes in Mathematics, Vol. 506, Numerical
Analysis, Dundee, pages 60–74. Springer, Berlin, (1975).
[DF76] A. J. Dragt and J. M. Finn: Lie series and invariant functions for analytic symplectic
maps. J. of Math. Phys., 17:2215–2227, (1976).
[DF83] A.J. Dragt and E. Forest: Computation of nonlinear behavior of Hamiltonian systems
using Lie algebraic methods. J. of Math. Phys., 24(12):2734–2744, (1983).
[Fen85] K. Feng: On difference schemes and symplectic geometry. In K. Feng, editor, Pro-
ceedings of the 1984 Beijing Symposium on Differential Geometry and Differential Equa-
tions, pages 42–58. Science Press, Beijing, (1985).
[Fen86] K. Feng: Difference schemes for Hamiltonian formalism and symplectic geometry. J.
Comput. Math., 4:279–289, (1986).
[Fen91] K. Feng: The Hamiltonian Way for Computing Hamiltonian Dynamics. In R. Spigler,
editor, Applied and industrial Mathmatics, pages 17–35. Kluwer, The Netherlands, (1991).
[Fen92] K. Feng: Formal power series and numerical methods for differential equations. In
T. Chan and Z.C. Shi, editors, International conf. on scientiﬁc computation, pages 28–35.
World Scientiﬁc, Singapore, (1992).
[For92] E. Forest: Sixth-order Lie group integrators. J. of Comp. Phys., 99:209–213, 1992.
[For06] E. Forest. Geometric integration for particle accelerators. J. Phys. A: Math. Gen.,
39:5321–5377, (2006).
[FQ91] K. Feng and M.Z. Qin: Hamiltonian algorithms for Hamiltonian systems and a com-
parative numerical study. Comput. Phys. Comm., 65:173–187, (1991).
[FR90] E. Forest and R. D. Ruth: Fourth-order symplectic integration. Physica D, 43:105–117,
(1990).
[GO77] D. Gottlib and A. Orsag: Numerical Analysis of Spectral Methods, Theory and Appli-
cation. SIAM, Philadelphia, (1977).
[HNW93] E. Hairer, S. P. Nørsett, and G. Wanner: Solving Ordinary Differential Equations I,
Nonstiff Problems. Springer-Verlag, Berlin, Second revised edition, (1993).
[McL95a] R. I. McLachlan: Comment on “ Poisson schemes for Hamiltonian systems on Pois-
son manifolds”. Computers Math. Applic., 29:1, (1995).
[McL95b] R. I. McLachlan: Composition methods in the presence of small parameters. BIT,
35:258–268, (1995).
[McL95c] R. I. McLachlan: On the numerical integration of ODE’s by symmetric composition
methods. SIAM J. Numer. Anal., 16:151–168, (1995).
[McL95d] R. I. McLachlan: On the numerical integration of ordinary differential equations by
symmetric composition methods. SIAM J. Sci. Comput., 16:151–168, (1995).
[MSS99] A. Murua and J. M. Sanz-Serna: Order conditions for numerical integrators obtained
by composing simpler integrators. Phil. Trans. Royal Soc. A, 357:1079–1100, (1999).

406
Bibliography
[MSSS97] A. Murua, J. M. Sanz-Serna, and R. D. Skeel: Order conditions for numerical inte-
grators obtained by composing simpler methods. Technical Report 1997/7, Departemento
de Matem´atica Aplicada y Computati´on, Universidad de Valladolid, Spain, (1997).
[Mur97] A. Murua: On order conditions for partitioned symplectic methods. SIAM J. Numer.
Anal., 34:2204–2211, (1997).
[Mur99] A. Murua: Formal series and numerical integrators, part I: Systems of ODEs and
symplectic integrators. Appl. Numer. Math., 29:221–251, (1999).
[Mur06] A. Murua: The Hopf algebra of rooted trees, free Lie argebra,and Lie series. Founda-
tions of Computational Mathematics, 6(4):387–426, (2006).
[Ner87] F. Neri: Lie algebras and canonical integration. University of Maryland Tech. report,
(1987).
[QWZ91] M. Z. Qin, D. L. Wang, and M. Q. Zhang: Explicit symplectic difference schemes
for separable Hamiltonian systems. J. Comput. Math., 9(3):211–221, (1991).
[QZ90] M. Z. Qin and M. Q. Zhang: Multi-stage symplectic schemes of two kinds of Hamil-
tonian systems for wave equations. Computers Math. Applic., 19:51–62, (1990).
[QZ90a] M. Z. Qin and M. Q. Zhang: Explicit Runge–Kutta–like schemes to solve certain
quantum operator equations of motion. J. Stat. Phys., 60(5/6):839–843, (1990).
[QZ92] M. Z. Qin and W. J. Zhu: Construction of higher order symplectic schemes by com-
position. Computing, 47:309–321, (1992).
[QZ93] M. Z. Qin and W. J. Zhu: A note on stability of three stage difference schemes for
ODEs. Computers Math. Applic., 25:35–44, (1993).
[QZZ95] M. Z. Qin, W. J. Zhu, and M. Q. Zhang: Construction of symplectic of a three stage
difference scheme for ODEs. J. Comput. Math., 13:206–210, (1995).
[Rut83] R. Ruth: A canonical integration technique. IEEE Trans. Nucl. Sci., 30:26–69, (1983).
[Ste84] S. Steinberg: Lie series and nonlinear ordinary equations. J. of Math. Anal. and Appl.,
101:39–63, (1984).
[Str68] G. Strang: On the construction and comparison of difference schemes. SIAM J. Numer.
Anal., 5:506–517, (1968).
[Suz77] M. Suzuki: On the convergence of exponential operators the zassenhuas formula,
BCH formula and systematic approximants. Communications in Mathematical Physics,
57:193–200, (1977).
[Suz90] M. Suzuki: Fractal decomposition of exponential operators with applications to many-
body theories and Monte Carlo simulations. Physics Letters A, 146:319–323, (1990).
[Suz92] M. Suzuki: General theory of higher-order decomposition of exponential operators
and symplectic integrators. Physics Letters A, 165:387–395, (1992).
[Wan94] D. L. Wang: Some acpects of Hamiltonian systems and symplectic defference meth-
ods. Physica D, 73:1–16, (1994).
[Wru96] O. Wrubel: Qin-Kompositionen mit Lie-Reihen. Diplomarbeit Uni Karlsruhe (TH),
(1996).
[Yos90] H. Yoshida: Construction of higher order symplectic integrators. Physics Letters A,
150:262–268, (1990).
[ZQ93] W. Zhu and M. Qin: Applicatin of higer order self-adjoint schemes of PDEs. Comput-
ers Math. Applic., 26(3):15–26, 1993.

Chapter 9.
Formal Power Series and B-Series
We study vector ﬁelds, their associated dynamical systems and phase ﬂows together
with their algorithmic approximations in RN from the formal power series approach
[Fen93a,Fen92].
9.1 Notation
Our considerations will be local in both space and time, all related objects are C∞
smooth. We use coordinate description and matrix notation, the coordinate vec-
tors in RN and vector functions a : RN →RN are denoted by column matri-
ces. The identity vector function 1N is given by 1N(x) = x. For vector function
a = (a1, · · · , aN)T : RN →RN,
a∗: =
 ∂ai
∂xj

= Jacobian matrix a,
a∗: =

ai
∂
∂xi = linear differential operator of ﬁrst order associated to a,
the association a →a∗is linear, a∗operates on scalar functions φ : RN →R
a∗φ =

ai
∂φ
∂xi
,
and on vector functions b : RN →RN as
a∗b = a∗(b1, · · · , bN)T = (a∗b1, · · · , a∗bN)T = b∗a,
a∗1N = a.
Multiple applications of linear differential operators are naturally deﬁned, such as
a∗b∗, (a∗b∗)c∗, a∗(b∗c∗), etc. The operations are multilinear, associative but non-
commutative; thus, powers can be deﬁned as
a∗k = a∗a∗· · · a∗(k time),
ak := a∗k1N,
the identity operator I operates on scalar and vector functions φ and b as Iφ = φ,
Ib = b.

408
9. Formal Power Series and B-Series
We identify all vector functions a : RN →RN as vector ﬁelds. All vector ﬁelds
in RN form a (∞-dimensional) real Lie bracket under Lie bracket
[a, b] := a∗b −b∗a = b∗a −a∗b = (b∗a∗−a∗b∗)1N.
The Lie algebra VN is associated with the (∞-dimensional) local Lie group DN of
near-identity diffeomorphisms—or simply near-1 maps—of RN.
Consider the dynamical system in RN
dx
dt = a(x),
(1.1)
deﬁned by a vector ﬁeld a. It possesses a phase ﬂow et
a = et, which is a one-parameter
(in t) group of near-1 maps of RN,
e0 = 1N,
et+s = et ◦es,
and generates the solution by x(0) →et
ax(0) = x(t). The phase ﬂow is expressible
as a convergent power series in t:
et
a = 1N +
∞

k=1
tkek,
e0 = 1N,
ek = 1
ka∗ek−1 = 1
k!(a∗)k1N = 1
k!ak.
We deﬁne
Exp ta∗:= I +
∞

k=1
1
k!(ta)∗k,
I is the identity operator.
This is an operator power series operating on scalar and vector functions, and deﬁned
by
exp ta := (Exp ta∗)1N = 1N +
∞

k=1
1
k!(ta∗)k1N = 1N +
∞

k=1
tk
k!ak,
(1.2)
then
et
a = (Exp ta∗)1N = exp ta,
(1.3)
for scalar function
φ ◦et
a = φ ◦exp ta = (Exp ta∗)φ,
for vector function
b ◦et
a = b ◦exp ta = (Exp ta∗)b = (Exp ta∗)b∗1N.
Each numerical algorithm solving the system (1.1) possesses the step transition map
f s
a which is one-parameter (in step-size s) family (in general not a one-parameter
group in s) of near-1 maps on RN, expressible as a convergent power series in s

9.2 Near-0 and Near-1 Formal Power Series
409
f s
a = 1N +
∞

k=1
skfk,
(1.4)
the coefﬁcients can be determined recursively form the deﬁning difference equation.
The transition generates the numerical solution x(0) →(f s
a)Nx(0) ≈x(Ns) by
iterations with step-size s chosen ﬁxed in general.
The main problem is to construct and analyze the algorithmic approximations
f s
a ≈et
a

t=s = es
a in a proper way. For this purpose, we propose a uniﬁed frame-
work based on the apparatus of formal power series, Lie algebra of vector ﬁelds, and
the corresponding Lie group of diffeomorphisms [Lie88,Olv93].
9.2 Near-0 and Near-1 Formal Power Series
Among the formal power series
∞

0
skak, ak : RN →RN, we pick out two special
classes. The ﬁrst class consists of those with a0 = 0, called near-0 formal vector
ﬁelds and the second class consists of those with a0 = 1N, called near-1 formal maps
(diffeomorphisms).
All near-0 formal vector ﬁelds as =
∞

1
skak form a (∞-dim.) real Lie algebra
FVN under the Lie bracket
[as, bs] =
5 ∞

k=1
skak,
∞

k=1
skbk
6
:=
∞

k=2
sk 
i+j=k
[ai, bj].
The associated near-0 formal differential operators and their products are
(as)∗: =
* ∞

k=1
skak
+
∗
: =
∞

k=1
skak∗,
as∗:=
* ∞

k=1
skak
+∗
: =
∞

k=1
ska∗
k,
as∗bs∗: =
∞

k=2
sk 
i+j=k
a∗
i b∗
j,
(as∗)2 : = as∗as∗, etc.
For any vector function a = (a1, · · · , aN)T : RN →RN and any near-1 formal
map gs = 1 +
∞

k=1
skgk, we deﬁne the composition,

410
9. Formal Power Series and B-Series
(a ◦gs)(x) = a(gs(x)) = a(x) +
∞

k=1
sk(a ◦g)k(x),
(a ◦g)k =
k

m=1

k1+···+km=k
1
m!(Dma)(gk1, · · · , gkm),
where
Dma = (Dma1, · · · , DmaN)T,
Dmai(v1, · · · , vm) =
N

j1,···,jm=1
∂mai
∂xj1 · · · ∂xjm
v1j1 · · · vmjm,
is the usual m-th differential multi-linear form for m tangent vectors vi = (vi1, · · ·,
viN )T (i = 1, · · · , m) at point x ∈RN, which is invariant under permutation of
vectors. Using the identities,
(D1a)(b) = b∗a,
(D2a)(b, c) = (c∗b∗−(c∗b)∗)a,
(D3a)(b, b, b) = (b∗3 + 2b3∗−3b∗b2∗)a.
We get in particular
(a ◦g)1 = g∗
1a,
(a ◦g)2 = g∗
2a + 1
2(g∗2
1 −g2∗
1 )a,
(a ◦g)3 = g∗
3a + ((g∗
2g∗
1 −(g∗
2g1)∗)a + 1
3!(g∗3
1 + 2g3∗
1 −3g∗
1g2∗
1 )a.
For any two near-1 formal maps
f s = 1N +
∞

k=1
skfk,
gs = 1N +
∞

k=1
skgk,
the composition f s ◦gs is deﬁned in a term by term way:
(f s ◦gs)(x) = f s(gs(x)) = 1N(gs(x)) +
∞

k=1
skfk(gs(x))
=: 1N(x) +
∞

k=1
sk(f ◦g)k(x),
(f ◦g)1 = f1 + g1,
(f ◦g)k = fk + gk + δ(f1, · · · , fk−1; g1, · · · , gk−1),
k ≥2,
δ(f1, · · · , fk−1; g1, · · · , gk−1) =
k−1

i=1
i

m=1

i1+···+im=i
1
m!(Dmfk−i)(gi1, · · · , gim).

9.2 Near-0 and Near-1 Formal Power Series
411
In particular we get,
(f ◦g)2 = f2 + g2 + g∗
1f1,
(f ◦g)3 = f3 + g3 + g∗
1f2 + g∗
2f1 + 1
2(g∗2
1 −g2∗
1 )f1,
(f ◦g)4 = f4 + g4 + g∗
1f3 + g∗
2f2 + g∗
3f1 + 1
2(g∗2
1 −g2∗
1 )f2
+(g∗
2g∗
1 −(g∗
2g1)∗)f1 + 1
3 !(g∗3
1 + 2g3∗
1 −3g∗
1g2∗
1 )f1.
Under this composition rule, all near-1 formal maps
f s = 1N +
∞

k=1
skfk
form a (∞-dim) formal Lie group FDN. In group FDN, inverse elements, square
roots, rational powers, etc., always exist, and their coefﬁcients can always be deter-
mined recursively by the deﬁning composition relations. For example, the inverse
(f s)−1 := 1 +
∞

k=1
skhk = hs is deﬁned by (f s ◦hs) = 1N, hence
f1 + h1 = 0,
fk + hk + δ(f1, · · · , fk−1; h1, · · · , hk−1) = 0,
k ≥2.
In particular,
h1 = −f1,
h2 = −f2 + f 2
1 ,
h3 = −f3 + f ∗
1 f2 + (f ∗
2 −f 2∗
1 )f1 −1
2f 3
1 + 1
2f 2∗
1 f1.
There is an obvious one-one correspondence between the Lie algebra FVN and the
Lie group FDN, established simply by +1N and −1N. However, the more signiﬁcant
one-one correspondence between them is given by exp and its inverse log.
exp :
FVN →FDN,
as =
∞

k=1
skak =⇒exp as =: 1N +
∞

m=1
1
m!(as∗)m1N
=: 1N +
∞

k=1
skfk = f s.
(2.1)
Note that
(as∗)m =
* ∞

k1=1
sk1a∗
k1
+
· · ·
*
∞

km=1
skma∗
km
+
=
∞

k1,···,km=1
sk1+···+kma∗
k1 · · · a∗
km,

412
9. Formal Power Series and B-Series
so we get easily
fk =
k

m=1
1
m!

k1+···+km=k
a∗
k1 · · · a∗
km1N,
k ≥1, f1 = a1,
fk = ak +
k

m=2
1
m!

k1+···+km=k
a∗
k1 · · · a∗
km1N, k ≥2, f2 = a2 + 1
2a2
1. (2.2)
Note that (2.2) provides a 2-way recursion formula from a1, · · · , ak to f1, · · · , fk and
vice versa. Therefore, exp maps FVN one-one onto FDN and its inverse, i.e., log is
deﬁned by the same (2.2):
log = (exp)−1 : FDN −→FVN,
log exp as = as,
exp log f s = f s.
In particular,
a1 = f1,
a2 = f2 −1
2a2
1,
a3 = f3 −1
2(a∗
1a2 + a∗
2a1) −1
3 !a3
1,
a4 = f4 −1
2(a∗
1a3 + a2
2 + a∗
3a1) −1
3 !(a∗
1a∗
1a2 + a∗
1a∗
2a1 + a∗
2a∗
1a1) −1
4 !a4
1,
ak = fk −
k−1

m=2
1
m !

k1+···+km=k
a∗
k1 · · · a∗
km1N −1
k !ak
1,
k ≥3.
An equivalent construction of log f s = as is
log f s =
∞

m=1
(−1)m−1
m
hs
m,
(2.3)
where
hs
1 = f s −1N,
hs
m = hs
m−1 ◦f s −hs
m−1.
It is easy to compute
hs
1 =
∞

k=1
skfk =
∞

k1=1
sk1(1N ◦f)k1,
hs
2 =
∞

k1,k2=1
sk1+k2((1N ◦f)k1 ◦f)k2,
hs
3 =
∞

k1,k2,k3=1
sk1+k2+k3(((1N ◦f)k1 ◦f)k2 ◦f)k3,
· · · .

9.2 Near-0 and Near-1 Formal Power Series
413
Substituting in (2.3) and equating with
∞

k=1
skak, we get
ak =
k

m=1
(−1)m−1
m

k1+···+km=k
(· · · ((1N ◦f)k1 ◦f)k2 · · · ◦f)km.
(2.4)
It is easy to verify log exp as = as for this log, so this is precisely the inverse of exp,
thus agreeing with the previous one.
We use the above construction (2.4) to establish the formal Baker–Campbell–
Hausdorff formula[Bak05,Hau06]. For arbitrary near-1 formal maps f s, gs,
log (f s ◦gs) = log f s + log gs +
∞

k=1
dk(log f s, log gs),
where log f s = as, log gs = bs, then[Dyn46]
dk(as, bs) = 1
k
k

m=1
(−1)m−1
m

p1+q1+···+pm+qm=k
pi+qi≥1,pi≥0,qi≥0
[(as)p1(bs)q1 · · · (as)pm(bs)qm]
p1!q1! · · · pm!qm!
,
where
(x)p = xx · · · x (p times),
[x1x2x3 · · · xn] = [[· · · [[x1, x2], x3], · · ·], xn].
In particular,
d1 = 1
2[as, bs],
d2 = 1
12

[asbsbs] + [bsasas]

,
d3 = −1
24[asbsbsas].
Let log (f s ◦gs) = cs =
∞

k=1
skck, then
c1 = a1 + b1,
c2 = a2 + b2 + 1
2[a1b1],
c3 = a3 + b3 + 1
2([a1b2] + [a2b1]) + 1
12([a1b1b1] + [b1a1a1]),
c4 = a4 + b4 + 1
12([a1b3] + [a2b2] + [a3b1])
+ 1
12([a1b1b2] + [a1b2b1] + [a2b1b1] + [b1a1a2] + [b1a2a1] + [b2a1a1])
−1
24[a1b1b1a1],
etc.
Note that the classical BCH formula is restricted to the composition of two one-
parameter groups, where log f s = sa1 and log gs = sb1.
The log transform reduces matters at the Lie group level to those at the easier level
of Lie algebra. All properties of near-1 formal maps have their logarithmic interpreta-
tions.

414
9. Formal Power Series and B-Series
Proposition 2.1. [Fen93a,Fen92,Fen93b] We list some of them, let log f s = as =
∞
C
k=1
skak:
1◦
f s is a phase ﬂow, i.e., f s+t = f s ◦f t ⇔log f s = sa1.
2◦
f s is revertible, i.e., f s ◦f −s = 1N ⇔log f s is odd in s.
3◦
f s raised to real μ-th power (f s)μ ⇔log (f s)μ = μ log f s. In particular,
log (f s)−1 = −log f s, log √f s = 1
2 log f s.
4◦
f s scaled to f αs ⇔log (f αs) = (log f)αs. In particular,
log (f −s) = (log f)−s.
5◦
f s −gs = O(sp+1) ⇔log f s −log gs = O(sp+1).
6◦
f s◦gs = gs◦f s ⇔[log f s, log gs] = 0 ⇔log (f s◦gs) = log f s+log gs.
7◦
(f s◦gs) = hs ⇔log hs = log (f s◦gs) = log f s+log gs+
∞
C
k=1
dk(log f s, log gs).
8◦
f s symplectic ⇔all ak are Hamiltonian ﬁelds (see Chapter 5).
9◦
f s contact ⇔all ak are contact ﬁelds (see Chapter 11).
10◦
f s volume-preserving ⇔all ak are source-free ﬁelds (see Chapter 10).
The log transform has important bearing on dynamical systems with Lie algebra
structure. The structure-preserving property of maps f s at the Lie group (G ⊂Dm)
level can be characterized through their logarithms at the associated Lie algebra (L ⊂
Vm) level.
9.3 Algorithmic Approximations to Phase Flows
9.3.1 Approximations of Phase Flows and Numerical Method
We return to the main problem of approximation to the phase ﬂow for dynamical
system d x
d t = a(x).
f s
a = f s = 1N +
∞

k=1
skfk ≈es
a = 1N +
∞

k=1
skek,
ek = ak
k! .
If fk = ek (1 ≤k ≤p), we say f s
a is accurate to order ≥p, if moreover, fp+1 ̸= ep+1,
we say it is accurate to order p.
Let log f s = as =

skak. Note that the ﬁrst p+1 equations in (2.2) completely
determine a1, a2, · · ·, ap+1 and f1, f2, · · ·, fp+1 each other. It is then easy to establish
fk = ek,
1 ≤k ≤p;
fp+1 ̸= ep+1 ⇐⇒
a = a1 = e1;
ak = 0,
1 < k ≤p;
ap+1 = fp+1 −ep+1 ̸= 0.
(3.1)
So, the orders of approximation for f s
a ≈es
a and for log f s
a −sa are the same.
Moreover, note that we have a formal ﬁeld

9.3 Algorithmic Approximations to Phase Flows
415
s−1 log f s = s−1as = a +
∞

k=1
sk+1ak+1 = a + O(sp),
which is the original ﬁeld a up to a near-0 perturbation and deﬁnes a formal dynamical
system
d x
d t = (s−1 log f s)(x) = a(x) +
∞

k=1
sk+1ak+1(x)
having a formal phase ﬂow (in two parameters t and s with group property in t)
et
s−1as = exp ts−1as whose diagonal formal ﬂow et
s−1as|t=s is exactly f s. This
means that any compatible algorithm f s
a of order p gives perturbed solution of a right
equation with ﬁeld a; however, it gives the right solution of a perturbed equation with
ﬁeld s−1 log f s
a = a+O(sp). There could be many methods with the same formal or-
der of accuracy but with quite different qualitative behavior. The problem is to choose
among them those leading to allowable perturbations in the equation. For systems
with geometric structure, the 8◦, 9◦, 10◦of Proposition 2.1 provide guidelines for a
proper choice. The structure-preservation requirement for the algorithms precludes all
unallowable perturbations alien to the pertinent type of dynamics. Take, for example,
Hamiltonian systems. A transition map f s
a for Hamiltonian ﬁeld a is symplectic if and
only if all ﬁelds ak are Hamiltonian, i.e., the induced perturbations in the equation
are Hamiltonian. So symplectic algorithms are clean, inherently free from all kinds
of perturbations alien to Hamiltonian dynamics (such as artiﬁcial dissipation inherent
in the vast majority of conventional methods), this accounts for their superior perfor-
mance. The situations are the same for contact and volume-preserving algorithms .
The Proposition 2.1 profound impact on later developed called “Backward error se-
ries” work, “Modiﬁed equation” and “Modiﬁed integrator”[Hai94,CHV05,CHV07].
9.3.2 Typical Algorithm and Step Transition Map
Finally we give, as an illustration, four simplest methods together with step transition
maps and their logarithms.
es
a = 1N + sa + 1
2s2a2 + 1
3!s3a3 + O(s4).
(1)
Explicit Euler method (E):
x1 −x0 = sa(x0),
f s −1N = sa,
f s
E = 1N + sa,
log f s
E = sa −s2
2 a2 + O(s3),
non-revertible, order = 1.
(2)
Implicit Euler method (I):

416
9. Formal Power Series and B-Series
x1 −x0 = sa(x1),
f s −1N = sa ◦f s,
f s
I = (1N −sa)−1 = (f −s
E )−1 = 1 + sa + s2a2 + O(s3),
log f s
I = sa + s2
2 a2 + O(s3),
non-revertible, order = 1.
(3)
Trapezoidal method (T):
x1 −x0 = s
2(a(x1) + a(x0)),
f s −1N = s
2(a ◦f s + a),
f s
T =

1N −s
2a
−1
◦

1N + s
2a

= f
s
2
I ◦f
s
2
E
= (f
s
2
E )−1 ◦f s
C ◦f
s
2
E = 1N + sa + s2
2 a2 + s3
4 a3 + O(s4),
log f s
T = sa + s3
12a3 + O(s5),
revertible, order = 2, symplectic for linear Hamiltonian but non-symplectic for non-
linear Hamiltonian systems, where f s
C denoting following centered Euler scheme.
(4)
Centered Euler method (C):
x1 −x0 = sa
1
2(x1 + x0)

,
f s −1N = sa ◦
1
2(f s + 1N)

,
2-stage version recommended for implementation:
¯x = x + s
2a(¯x),
x1 = 2¯x −x0,
¯x = f
s
2
I (x0),
x1 = 2f
s
2
I (x0) −1N(x0),
f s
C = 2f
s
2
I −1N =

1N + s
2a

◦

1N −s
2a
−1
= f
s
2
E ◦f
s
2
I
= 1N + sa + s2
2 a2 + s3
8 (a∗a2 + a3) + O(s4),
log f s
C = sa + s3 1
8a∗a2 −1
24a3
+ O(s5),
revertible, order = 2, unconditionally symplectic with preservation of all quadratic
invariants for Hamiltonian systems.
Note the similarities and delicate differences between C and T: Both can be com-
posed by a s
2 implicit and a s
2 explicit stages but in opposite orderings. Moreover, they

9.4 Related B-Series Works
417
are conjugate to each other. C is far less known than T, it becomes prominent only
after the recent development of symplectic algorithms [Fen85]. In crucial aspects, C is
superior.
Remark 3.1. The above log f s
C is not others but just formal vector ﬁelds for centered
Euler scheme or present called backward error analysis
¯f = f + s2
12(f ′f ′f −1
2f ′′(f, f)).
9.4 Related B-Series Works
Consider the numerical solution of ODEs
˙z = f(z),
z ∈Rn.
(4.1)
B-series methods: B-series were introduced by Harier and Wanner[HW74]. The Taylor
series of exact solution of (4.1) with initial value z(0) = z can be written as
z(h) = z + hf(z) + h2
2! f ′(z)f(z) + h3
3!

f ′′(f(z), f(z)) + f ′(z)f ′(z)f(z)

+ · · · .
(4.2)
B-series methods are numerical integrators zn+1 = Φh(zn) whose Taylor series have
the same structure with real coefﬁcients a(τ):
Φh(z) = z + ha( )f(z) + h2a( )f ′(z)f(z) + h3a(
)
2!
f ′′(f(z), f(z))
+a( )f ′(z)f ′(z)f(z)

+ · · · ,
(4.3)
where coefﬁcients a(τ) are deﬁned for all rooted trees and characterize the integrator.
Every numerical integrator (including R–K method) can be expanded into a B-
series as introduced and studied in[HW74].
Deﬁnition 4.1 (rooted tree and forest). The set of rooted tree T and forest F are
deﬁned recursively by
1◦
The tree
, only one vertex belong to T;
2◦
If τ1, · · · , τn are n tree of τ, the forest u = τ1, · · · , τn is the commutative
product of τ1, · · · , τn;
3◦
If u is a forest of F, then u = |τ| is a tree of T.
Let T = { ,
,
, · · ·} be the set of rooted trees and let ∅be the empty tree. For
τ1, · · · , τn ∈T, we denote by τ = [τ1, · · · , τn] the tree obtained by grafting the roots
of τ1, · · · , τn to a new vertex which becomes the root of τ. Elementary differentials
Ff(τ) are deﬁned by induction as
Ff( )(z) = f(z),
Ff(τ)(z) = f (m)(z)

Ff(τ1), · · · , Ff(τm)(z)

.
(4.4)
For real coefﬁcients a(∅) and a(τ), τ ∈T a B-series is a series of the form

418
9. Formal Power Series and B-Series
B(f, a, z) = a(∅)Id +

τ∈T
h|τ|
σ(τ) a(τ) Ff(τ)(z)
(4.5)
= a(∅)Id + ha( )f + h2a( )f ′f + h3a(
)/2f ′′(f, f) + · · · , (4.6)
where Id stands for the identity; Id(z) = z and the scalars a(τ) are the known nor-
malization coefﬁcients[BSS96]. Now, we give following examples:
Example 4.2. The Taylor series of the exact solution of (4.1) can be written as a B-
series z(h) = B(f, e)(z0) with coefﬁcients a(τ) = e(τ) =
1
γ(τ), ∀τ ∈T.
Example 4.3. The coefﬁcient B-series for explicit Euler scheme a(τ) = 0, ∀τ ∈T
except a( ) = 1.
Example 4.4. The coefﬁcient B-series for implicit Euler scheme a(τ) = 1, ∀τ ∈T.
Example 4.5. The coefﬁcient B-series for centered Euler scheme a(τ) =
1
2
|τ|−1
,
∀τ ∈T.
Example 4.6. The coefﬁcient B-series for trapezoidal scheme a( ) = 1, a( ) =
1
2, a(
) = 1
2, a( ) = 1
4, · · · .
Example 4.7. The coefﬁcient B-series for R–K method (A, b, c), a(τ) = bTφ(τ), ∀τ ∈
T.
Partitions and skeletons: A partition pτ of a tree τ is obtained by cutting some of the
edges [CHV07]. The resulting list of trees is denoted by P(pτ). Eventually, the set of all
partitions pτ of τ is denoted by P(pτ). Now, given a partition pτ, the corresponding
skeleton χ(pτ), as introduced in [CHV07], is the tree obtained by contracting each tree of
P(pτ) to a single vertex
and by re-establishing the cut edges (see Tables 4.1 – 4.25).
We observe that a tree τ ∈T has exactly 2|τ|−1 partitions pτ and that different parti-
tions may lead to the same P(pτ). An admissible partition is a partition with at most
one cut along any part from the root to any terminal vertex. We denote APτ as the set
of admissible partition of τ and by convention, we suppose that ∅∈APτ. We denote
#(pτ) as number of subtrees. We denote this distinguished tree by R(pτ)(or rp). We
denote P ∗(pτ) = P(pτ) \ R(pτ) as the list of forest that do not contain the root of τ.
We distinguish rp as the tree vp (or P(pτ)) whose root coincides with the root of τ.
This tree is usually referred to as a subtree of τ and we denoted by v∗
p (or P ∗(pτ)) the
forest obtained by removing rp from vp. The above deﬁnition can be seen in Tables
4.1 – 4.25.
9.4.1 The Composition Laws
The following theorem result on the composition of B-series was obtained by[HW74].
Now we formulate this theorem in the form [CHV07]:

9.4 Related B-Series Works
419
Theorem 4.8. Let a, b : T ∪{∅} →R be two mappings, with a(∅) = 1. Then B-series
B(f, a)(z) inserted into B(f, b)(·) is still a B-series
B(f, b)

B(f, a)(z)

= B(f, a · b)(z),
(4.7)
and a · b : T ∪{∅} →R is deﬁned by
(a · b) = b(∅) = b(∅),
∀τ ∈T,
(a · b) =

p∈AP(τ)
b(rp)a(v∗
p),
(4.8)
where a is extended to F, as follows:
∀u = τ1 · · · τn ∈F,
a(u) =
n
;
i=1
a(τi).
(4.9)
Table 4.1.
The partitions of a tree of order 2 with associated skeleton and forest
pτ
•
•
•
•
···
χ(pτ)
•
•
•
P(pτ)
•
•
'
/
• •


R(pτ)
•
•
•
P ∗(pτ)
∅


•


#(pτ)
1
2
pτ ∈APτ
yes
yes

420
9. Formal Power Series and B-Series
Table 4.2.
The partitions of a tree of order 3 with associated skeleton and forest
pτ
•
•
•
•
•
···•
•
•
···
•
•
•
···
•
···
χ(pτ)
•
•
•
•
•
•
•
•
P(pτ)
•
•
•
'
/
•
•
•


•
•
•


•
•
•


R(pτ)
•
•
•
•
•
•
•
•
P ∗(pτ)
∅


•


•


• •


#(pτ)
1
2
2
3
pτ ∈APτ
yes
yes
yes
yes
Table 4.3.
The partitions of a tree of order 3 with associated skeleton and forest
pτ
•
•
•
•
•
•
···
•
•
•···
•
•
•···
···
χ(pτ)
•
•
•
•
•
•
•
•
P(pτ)
•
•
•
'
/
•
•
•


•
•
•


•
•
•


R(pτ)
•
•
•
•
•
•
•
P ∗(pτ)
∅


•
•
'
/
•


• •


#(pτ)
1
2
2
3
pτ ∈APτ
yes
yes
yes
no

9.4 Related B-Series Works
421
Table 4.4.
The partitions of a tree of order 4 with associated skeleton and forest
pτ
•
•
•
•
•
•
···
•
•
•
•
···•
•
•
•
•···•
•
•
···
···
•
•
•
•
···•···•
•
•
···
•···•
•
•
···
···
•···•
χ(pτ)
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
P(pτ)
•
•
•
•
'
/
•
•
•
•
'
/
•
•
•
•
'
/
•
•
•
•
'
/
• ••
•
'
/
• ••
•
'
/
• ••
•
'
/
•
•
•
•


R(pτ)
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
P ∗(pτ)
∅


•


•
•


•


•
•
•


• •


• •


• • •


#(pτ)
1
2
2
2
3
3
3
4
pτ ∈APτ
yes
yes
yes
yes
yes
no
yes
no
Table 4.5.
The partitions of a tree of order 4 with associated skeleton and forest
pτ
•
•
•
•
···•
•
•
•
···
•
•
•
•
···
•
•
•
•
···
···
•
•
•
•
···
···•
•
•
•
···
···•
•
•
•
··· ···
····•
•
•
•
χ(pτ)
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
P(pτ)
'
•
•
•
•
/ '
•
•
•
•
/ '
•
•
•
•
/ '
•
•
•
•
/
• •
•
•
'
/
• •
•
•
'
/
• •
•
•
'
/
•
•
•
•


R(pτ)
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
P ∗(pτ)
∅


•
•
•
'
/
•


•


• , •


,
•
•
•
'
/
,
•
•
•
'
/
,
• • •
,


#(pτ)
1
2
2
2
3
3
3
4
pτ ∈APτ
yes
yes
yes
yes
yes
no
no
no

422
9. Formal Power Series and B-Series
Table 4.6.
The partitions of a tree of order 4 with associated skeleton and forest
pτ
•
•
•
•
•
•
•···•
•
•
•
···
•
•
•
•···
•
•
···
•
•···
•
•
···
•
•···•
•
•
•······
•
•
•
•
···
······
•
χ(pτ)
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
P(pτ)
•
•
•
•
'
/
•
•
•
•
'
/
•
•
•
•
'
/
•
•
•
•
'
/
• ••
•
'
/
• ••
•
'
/
• ••
•
'
/
•
•
•
•


R(pτ)
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
P ∗(pτ)
∅


•
•
•
'
/
•


•
•


• •


•
•
•


•
•
•


• • •


#(pτ)
1
2
2
2
3
3
3
4
pτ ∈APτ
yes
yes
yes
yes
no
no
no
no
Table 4.7.
The partitions of a tree of order 5 with associated skeleton and forest
pτ
•
•
•
•
•
•
···
•
•
•
•
···•
•
•
•
···
•
•
•
•
··· ···•
•
•
•
···
···
•
•
•
•
···
···•
•
•
•
···
··· ···•
•
χ(pτ)
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
P(pτ)
•
•
•
•
'
/
•
•
•
•
'
/
•
•
•
•
'
/
•
•
•
•
'
/
• •
•
•
'
/
• •
•
•
'
/
• •
•
•
'
/
•
•
•
•
'
/
R(pτ)
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
P ∗(pτ)
∅
'
/
'
/
•
'
/
•
'
/
•
• •
'
/
• •
'
/
• •
'
/
• •
'
/
•
#(pτ)
1
2
2
2
3
3
3
4
pτ ∈APτ
yes
yes
yes
yes
yes
yes
yes
yes

9.4 Related B-Series Works
423
Table 4.8.
The partitions of a tree of order 5 with associated skeleton and forest
pτ
•
•
•
•
•
•
···
•
•
•
•
•
•
•
•
···•
•
···
•
•
•
•
•
•
•
•
···
•
•
•
•
···
•
•
···
•
•
•···•
•
···
•
•
•···
···•
•
χ(pτ)
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
P(pτ)
•
•
•
•
•
'
/
•
•
•
•
•
'
/
•
•
•
•
•
'
/
•
•
•
'
/
•
•
•
•
•
'
/
•
•
•
•
•
'
/
••
•
•
•
'
/
••
•
•
•
'
/
••
R(pτ)
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
P ∗(pτ)
∅


•
•
•
•


•
•
•
'
/
•
•
•
'
/
• •


•
•
•
•
'
/
•
•
•
•
'
/
#(pτ)
1
2
2
2
2
3
3
3
pτ ∈APτ
yes
yes
yes
yes
yes
no
no
no
Table 4.9.
Continuous partitions of the above tree of order 5 with associated skeleton and
forest
pτ
•
•
•
•
•
···
•
•
···
•
···•
•
•
•
···
•
•
•
•
···
•
···
•
·········
•
•
•
•
•
•
•
•·········
•
•
•
•
···
···•
•
···
•
•
•···•
•
···
···
•
•
•···
···•
•
···
•
···
χ(pτ)
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
P(pτ)
•
•
• •
'
/
•
•
•
• •
'
/
•
•
•
• •
'
/
•
•
• •
'
/
• •
•
••
'
/
• •
•
••
'
/
• •
•
• •
'
/
• •
•
••
'
/
••
R(pτ)
•
•
•
•
•
•
•
•
•
•
•
P ∗(pτ)
•
•
•
•
'
/
•
•
'
/
•
•
•
'
/
•
• •


•
•
••
'
/
•
•
••
'
/
•
•
•
'
/
• •
•
•
•
•


#(pτ)
3
3
3
4
4
4
4
5
pτ ∈APτ
no
no
no
no
no
no
no
no

424
9. Formal Power Series and B-Series
Table 4.10.
The partitions of a tree of order 5 with associated skeleton and forest
pτ
•
•
•
•
•
•
•
•
•
···
•
•
•
•
•
···
•
•
•
•
•
···
•
•
•
•
•
···
•
•
•
•
•
··· ···
•
•
•
•
•
···
···
•
•
•
•
•
···
···
•
χ(pτ)
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
P(pτ)
•
•
•
•
•

 •
•
•
•
•

 •
•
•
•
•

 •
•
•
•
•


•
•
•
•
•


•
•
•
•
•


•
•
•
•
•


•
•
•
•
•


R(pτ)
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
P ∗(pτ)
∅




•


•


•


•
• •


• •


• •


#(pτ)
1
2
2
2
2
3
3
3
pτ ∈APτ
yes
yes
yes
yes
yes
yes
yes
yes
Table 4.11.
Continuous partitions of the above tree of order 5 with associated skeleton and
forest
pτ
•
•
•
•
•···
···
•
•
•
•
•···
···
•
•
•
•
•···
···
•
•
•
•
•···
···
···
•
•
•
•
•···
···
···
•
•
•
•
•···
···
···
•
•
•
•
•···
···
···
•
•
•
•
•···
···
···
···
pτ
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
P(pτ)
•
•
•
•
•


•
•
•
•
•


•
•
•
•
•


•
• •
'
/
• •
•
• •
'
/
• •
•
• •
'
/
• •
•
• •
'
/
• •
•
•
•
•
•


R(pτ)
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
P ∗(pτ)
• •


• •


• •


• •


•
• •


•
• •


•
• •


•
•
•
•
•


#(pτ)
3
3
3
4
4
4
4
5
pτ ∈APτ
yes
yes
yes
yes
yes
yes
yes
yes

9.4 Related B-Series Works
425
Table 4.12.
The partitions of a tree of order 5 with associated skeleton and forest
pτ
•
•
•
•
•
•
•
•
•
•···
•
•
···
•
•
•
•
•
···•
•
•
•
•
···
•
•
•
•
•
···
···
•
•
•
•
•
···
···
•
•
•
•
•
···
•
•
•···
χ(pτ)
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
P(pτ)
•
•
•
•
•
'
/
•
•
•
•
•


•
•
•
•
•
'
/ •
•
•
•
•
'
/ •
•
•
•
•
'
/
•
•
•
•
•


•
•
•
•
•


•
•
•
•
•


R(pτ)
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
P ∗(pτ)
∅


•
•
•
•
'
/ 

•


•


•
•
•
•
•
'
/
•
•
•
•
'
/
•
•
•
•
'
/
3
1
2
2
2
2
3
3
4
pτ ∈APτ
yes
yes
yes
yes
yes
no
no
no
Table 4.13.
Continuous partitions of the above tree of order 5 with associated skeleton and
forest
pτ
•
•
···
···
•
•
•
•
•
···
•
•
•
···
•
•
···
•
•
•
···
•
•
···
···
···
•
•
•
•
•
···
···
···
•
•
•
•
•
···
·
·····
•
•
•
•
•
···
······
•
•
•
•
•
···
···
······
•
•
•
χ(pτ)
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
P(pτ)
•
•
•
•
'
/
•
•
•
•
•
'
/
•
•
•
•
•
'
/
•
•
•
•
•
•
'
/
•
•
•
•
•
'
/
•
•
•
•
•
'
/
•
•
•
•
•
'
/
•
•
•
•
•


R(pτ)
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
P ∗(pτ)
• •


• •


• •


• •


•
•
•
'
/
• •
•
•
'
/
• •
•
•
'
/
• •
•
•
•
•


#(pτ)
3
3
3
4
4
4
4
5
pτ ∈APτ
yes
yes
yes
yes
no
no
no
no

426
9. Formal Power Series and B-Series
Table 4.14.
The partitions of a tree of order 5 with associated skeleton and forest
pτ
•
•
•
•
•
•
•
•
···
•
•
•
•
•···•
•
•
•
···•
•
•
•···•
•
•
•
•
•
•···•
•
···
•
•
•
•
···
···
•
•
•
•
•
•
···
•
•
···
χ(pτ)
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
P(pτ)
•
•
•
•
•
'
/
•
•
•
•
'
/
•
•
•
•
•
•
'
/
•
•
•
•
•
'
/
•
•
•
•
•
'
/
•
•
•
•
•
'
/
•
•
•
•
•
'
/
•
••
•
•
'
/
R(pτ)
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
P ∗(pτ)
∅




•
•
•
'
/
•
•
•
'
/


•
• •


•
•
•
•
'
/
•
•
'
/
•
#(pτ)
1
2
2
2
2
3
3
3
pτ ∈APτ
yes
yes
yes
yes
yes
no
yes
no
Table 4.15.
Continuous partitions of the above tree of order 5 with associated skeleton and
forest
pτ
•
•
···
•
···
•
•
•
•
······ •
•
•
•
•
···
•···•
•
•
•
···•······
•
•
•
···•
•
···
···•
•
•
•
•
•
···•
···
•
•
···
•
•
•
•
···
···
•···•
•
•
•
···
•······
•
•
···
χ(pτ)
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
···•
•
P(pτ)
•
•
•
• •
'
/
•
•
• •
'
/
•
•
•
• •
'
/
•
•
•
•
•
•
'
/
•
•
•
•
•
'
/
•
•
•
•
•
'
/
•
•
•
•
•
'
/
•
•
•
•
•


R(pτ)
•
•
•
•
•
•
•
•
•
•
•
•
•
•
P ∗(pτ)
• •


•
•
'
/
•
•
•
'
/
•
• •


•
• •


•
•
•
'
/
• •
•
•
'
/
• •
•
•
•
•


#(pτ)
3
3
3
4
4
4
4
5
pτ ∈APτ
yes
no
yes
no
no
no
no
no

9.4 Related B-Series Works
427
Table 4.16.
The partitions of a tree of order 5 with associated skeleton and forest
pτ
•
•
•
•
•
•
•
•
···
•
•
•
•
•
···•
•
•
•
···
•
•
•
•
•
···•
•
•
•
•
•
···
···
•
•
•
•
···
···•
•
•
•
•
···
•
···
•
•
χ(pτ)
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
P(pτ)
•
•
•
•
•
'
/
•
•
•
•
'
/
•
•
•
•
•
'
/
•
•
•
•
•
•
'
/
•
•
•
•
•
'
/
•
•
•
•
•
'
/
•
•
• •
'
/
•
•
•
•
• •
'
//
R(pτ)
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
P ∗(pτ)
∅




•
•


•
•


•
•


• •


•
•
•
•
'
/
• •


#(pτ)
1
2
2
2
2
3
3
3
pτ ∈APτ
yes
yes
yes
yes
yes
yes
yes
no
Table 4.17.
Continuous partitions of the above tree of order 5 with associated skeleton and
forest
pτ
···
•
•
•
···•
•
···
•
•
•
···
•
•
•
•
···
•
···•
•
···
•
•
···
•
···•
•
···
•
•
···
•
···
•
•
•
•
···
•
···•
•
···
•
•
···•
···
···•
•
•
•
···
•
···•
•
···
···
χ(pτ)
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
P(pτ)
•
•
•
• •
'
/
'
/
•
•
• •
'
/
•
•
•
• •
'
/
•
•
•
•
•
•
'
/
•
•
•
•
•
'
/
•
•
•
•
•
'
/
•
•
•
•
•
'
/
•
•
•
•
•


R(pτ)
•
•
•
•
•
•
•
•
•
•
•
•
•
•
P ∗(pτ)
• •


•
•
'
/
•
•
•
'
/
•
•
•
•
•
•
'
/
•
•
•
•
•
'
/
••


•
• •


•
••


••
#(pτ)
3
3
3
4
4
4
4
5
pτ ∈APτ
no
yes
yes
no
no
no
no
no

428
9. Formal Power Series and B-Series
Table 4.18.
The partitions of a tree of order 5 with associated skeleton and forest
pτ
•
•
•
•
•
···
•
•
•
•
•
···
•
•
•
···
•
•
•
•
•
···•
•
•
•
•
···
··
•
•
···
•
•
•
···
•
•
•
•
•
··· ···•
•
•
•
•
···
···
•
•
χ(pτ)
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
P(pτ)
•
•
•
•
•
'
/
•
•
•
•
•


•
•
•
•
'
/
•
•
•
•
•
'
/
•
•
•
•
•
•
'
/
•
•
•
•
•
'
/
•
•
•
• •
/
'
•
•
• •
'
/
•
R(pτ)
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
P ∗(pτ)
∅


•


•


•


•
•
'
/
• •


• •


•
•
'
/
•
#(pτ)
1
2
2
2
2
3
3
3
pτ ∈APτ
yes
yes
yes
yes
yes
no
yes
yes
Table 4.19.
Continuous partitions of the above tree of order 5 with associated skeleton and
forest
pτ
···
•
•
•
···•
•
···
···
•
•
•
•
•
•
•
•
···
···•
•
•
•
•
···
···
··
··· ···•
•
···
•
•
•
···
···•
•
···
•
•
•
···
···
•
•
···
···
•
•
•
··· ···•
•
···
•
•
•
···
··· ···•
•
χ(pτ)
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
···
•
•
•
•
•
•
•
•
•
•
•
P(pτ)
•
•
•
•
•
'
/
•
•
•
•
•
'
/
•
•
• •
'
/
•
•
•
•
•
•
'
/
•
•
•
•
•
'
/
•
•
•
•
•
'
/
•
•
•
•
•
'
/
•
•
•
•
•


R(pτ)
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
P ∗(pτ)
• •


• •


•
•
'
/
•
•
•
'
/
••
• •


•
• •


•
• •


•
• •


• •
#(pτ)
3
3
3
4
4
4
4
5
pτ ∈APτ
yes
yes
yes
yes
no
no
yes
no

9.4 Related B-Series Works
429
Table 4.20.
The partitions of a tree of order 5 with associated skeleton and forest
pτ
•
•
•
•
•
•
•
•
•
•
···
•
•
•
•
•
···
•
•
•
•
•
···
•
•
•
•
•
···
•
•
•
•
•
···
···
•
•
•
•
•
··· ···
•
•
•
•
•
···
···
χ(pτ)
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
P(pτ)
•
•
•
•
•
'
/
•
•
•
•
'
/
•
•
•
•
•
'
/
•
•
•
•
•
•
'
/ •
•
•
•
•
'
/
•
•
•
•
•
'
/
•
•
•
•
•
'
/
•
•
•
•
•
'
/
R(pτ)
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
P ∗(pτ)
∅


•


•


•
•
•
'
/
•


• •


•
•
•
•
'
/
• •


#(pτ)
1
2
2
2
2
3
3
3
pτ ∈APτ
yes
yes
yes
yes
yes
yes
yes
yes
Table 4.21.
Continuous partitions of the above tree of order 5 with associated skeleton and
forest
pτ
•
•
•
•···•
···
•
•
•
•···•
···
•
•
•
•
···•
···
•
•
•
•···•
···
···
•
•
•
•···
···
···
•
···
•
•
•
•
•
•···•
···
···
•
•
•
•
···•
···
···
•
•
•
•···
···•
···
···
χ(pτ)
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
P(pτ)
•
•
• •


•
•
•
• •


•
•
•
•
••
'
/
•
•
•
•
•


•
•
•
•
•


•
•
•
•
•


•
•
•
•
•


•
•
•
•
•


R(pτ)
•
•
•
•
•
•
•
•
•
•
•
•
•
•
P ∗(pτ)
•
•


•
•
•


•
• •


• •


•
•
•


• •
•
•


• •
• •


•
• •


• •
#(pτ)
3
3
3
4
4
4
4
5
pτ ∈APτ
no
no
yes
no
no
no
no
no

430
9. Formal Power Series and B-Series
Table 4.22.
The partitions of a tree of order 5 with associated skeleton and forest
pτ
•
•
•
•
•
•
•
•
•
···•
•
•
•
•
···
•
•
•
•
•
···
•
•
•
•
•
•
•
•···
•
•
•
•
•
•
•
···•···
•
•···
···
•
•
•
•
•
···
•
•
···
•
χ(pτ)
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
P(pτ)
•
•
•
•
•
'
/
•
•
•
•
•
'
/
•
•
•
•
•
'
/
•
•
•
•
•
'
/
•
•
•
•
•
'
/
•
•
•
•
•
'
/
•
•
•
• •
'
/
•
•
•
•
'
/
•
R(pτ)
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
P ∗(pτ)
∅


•
•
•
•
'
/
•
•
•
'
/
•


•


•
•
•
•
'
/
•
•


•
•
'
/
•
#(pτ)
1
2
2
2
2
3
3
3
pτ ∈APτ
yes
yes
yes
yes
yes
no
yes
no
Table 4.23.
Continuous partitions of the above tree of order 5 with associated skeleton and
forest
pτ
•
•
···
•
•
···•
•
•···
•
•···•
•
•···
•
•
···•
•
•······
•
•···•
•
•······
•
•
···•
•
•
······
•
•
···•···
•
•···
•
•
···•···
•
•······
•
•
···•···
χ(pτ)
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
P(pτ)
•
•
•
•
•
'
/
•
•
•
•


•
•
•
•
•
•
'
/
•
•
•
•
•


•
•
•
•
•


•
•
•
•
•


•
•
•
•
•


•
•
•
•
•


R(pτ)
•
•
•
•
•
•
•
•
•
•
P ∗(pτ)
•
•
•
•
'
/
•
•


•
•
•
•
•
'
/
• •


•
•
•


• •
•
•


• •
•
•


• •
••


• •
#(pτ)
3
3
3
4
4
4
4
5
pτ ∈APτ
no
no
no
no
no
no
no
no

9.4 Related B-Series Works
431
Table 4.24.
The partitions of a tree of order 5 with associated skeleton and forest
pτ
•
•
•
•
•
•
•
•
•···•
•
•
•
···
•
•
•
•···•
•
•
•
•
•
···
•
•
•
•···•
···
•
•
•
•
•
···
···
•
•
•
•
•
··
•···•
χ(pτ)
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
P(pτ)
•
•
•
•
•
'
/
•
•
••
•
'
/
•
•
•
•
•
'
/
•
•
•
•
•
'
/
•
•
•
•
•
'
/
•
•
•
• •
'
/
•
•


• •
•
•
•
• •
'
/
R(pτ)
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
P ∗(pτ)
∅


•
•
•
•
'
/
•


•


•
•


• •


•
•


•
•
•
•
•
'
/
#(pτ)
1
2
2
2
2
3
3
3
pτ ∈APτ
yes
yes
yes
yes
yes
no
yes
no
Table 4.25.
Continuous partitions of the above tree of order 5 with associated skeleton and
forest
pτ
•
•
•
···
•···•
•
•···•
•···•
•
•···•
···
•
•
•
•···•
···
···
•
•
•
•···•
···
•···•
•
•···•
···
•···•
•
•
•
···
···
•···•
•
•···•
···
···
•···•
χ(pτ)
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
•
P(pτ)
•
•


• •
•
•
•
•
•
'
/
•
•
•
•
•
'
/
•
•
•
•
•


•
•
•
•
•


•
•
•
•
•


•
•
•
•
•


•
•
•
•
•


R(pτ)
•
•
•
•
•
•
•
•
•
•
•
P ∗(pτ)
•
•
•
•


•
•
•
•


• •


• •


•
•
•


••
•
•


••
•
•


••
••


• •
#(pτ)
3
3
3
4
4
4
4
5
pτ ∈APτ
no
no
yes
no
no
no
no
no

432
9. Formal Power Series and B-Series
9.4.2 Substitution Law
In[CHV07,CHV05],they introduce a new composition law on B-series, denoted by ∗and
called law of substitution, obtained as a result of the substitution of vector ﬁeld g(z) =
1
hB(f, b)(z) with b(∅) = 0, into another B-series B(g, a)(z). Chartier, Hairer, and
Vilmart give the following theorem:
Theorem 4.9. For b(∅) = 0, the vector ﬁeld h−1B(f, b) gives a B-series
B(h−1B(f, b), a) = B(f, b ∗a).
(4.10)
We have (b ∗a)(∅) = a(∅) and for all τ ∈T,
(b ∗a)(τ) =

p∈P(τ)
a(χp)b(vp),
(4.11)
where b is extended to F as follows:
∀u = τ1 · · · τn ∈F,
a(u) =
n
;
i=1
a (τi).
(4.12)
Remark 4.10. The composition law for the trees of order ≤5 is listed in Example
4.22.
Remark 4.11. The Substitution law for the (backward error) trees of order ≤5 is
listed in Example 4.24.
Remark 4.12. The Substitution law for the trees of order ≤5 is listed in Example
4.23.
Modiﬁed integrators (called generating function method or preprocessed vector ﬁeld
integrators): Let Ψf,h is the exact h-ﬂow for Equation (4.1) which is a B-series with
coefﬁcient e(τ) =
1
γ(τ). Consequently, the coefﬁcient ˘b(τ) of the modiﬁed differen-
tial equation for Φf,h = B(f, a) is obtained from
(˘b ∗a)(τ) = e(τ),
∀τ ∈T.
(4.13)
Backward error analysis (called formal vector ﬁeld, modiﬁed equation or postpro-
cessed vector ﬁeld): The modiﬁed differential equation of a method Ψf,h = B(f, e)
is obtained by putting Φf,h equal to the exact ﬂow. Its coefﬁcient b(τ) is therefore
obtained from
(b ∗e)(τ) = a(τ),
∀τ ∈T.
(4.14)
Remark 4.13. Substituting the expression 1
γ given in (4.13) into (4.14) gives ˘b∗b∗a =
a. Therefore, ˘b and b(τ) are inverse elements for substitution law ∗
˘b(τ) ∗b(τ) = b(τ) ∗˘b(τ) = δ•(τ).
(4.15)

9.4 Related B-Series Works
433
Proposition 4.14. Using formulae (4.13) and (4.11) in Example 4.23, we easily ob-
tain modiﬁed centered Euler scheme of sixth order ﬁrst ﬁnd in[CHV07] :
˙z = f(z) + h2
24
@
f (2)(f, f) −2f (1)f (1)f
A
+ h4
120
 3
48f (4)(f, f, f, f)
−1
4f (3)(f, f, f(1)f) + 1
4f (2)(f, f (2)(f, f)) −f (2)(f, f (1)f (1)f)
+2
4f (2)(f (1)f, f (1)f) −3
12f (1)f (3)(f, f, f) + 1
2f (1)f (2)(f, f (1)f)
−1
4f (1)f (1)f (2)(f, f) + f (1)f (1)f (1)f (1)f

+ O(h6).
Proof. First, we must point out ˘b(τ) = 0, ∀|τ| = even. We calculate coefﬁcient ˘b(
)
as follows
˘b(
) + 2a( )˘b( )2˘b( ) + a(
)˘b( )2˘b( )
+a( )˘b( )2˘b(
) + a(
)˘b( )5 = e(
).
Note the formula in Example 4.23, coefﬁcient a(τ) in Example 4.5, and γ(τ) in Table
4.26, we have ˘b(
) = 1
40 + 1
24 −1
16 =
1
240.
The proof of others is left to the reader.
▲
Proposition 4.15. In 2001, the author ﬁrst obtained modiﬁed equation for centered
Euler scheme given in Example 4.6 of Chapter 7. Using formulas (4.14) and (4.23) in
Example 4.24, we can obtain this formula again.
Proof. First, we must point out b(τ) = 0, ∀|τ| = even. We calculate coefﬁcient
b(
) as follows
b(
) + 6e(
)b( )2b(
) + 1
γ (
) = a(
).
Note the formula in Example 4.22, coefﬁcient a(τ) in Example 4.5, and γ(τ) in Table
4.26, we have b(
) = 1
16 + 1
6 −1
5 =
7
240. The proof of others is left to the reader.
▲
Remark 4.16. After calculating the coefﬁcients ˘b(τ) and b(τ), we list following in
Table 4.26.
Remark 4.17. Can directly test following equation
˘b(τ) ∗b(τ) = δ•(τ),
(4.16)
via ∗operation formula (4.11).
Remark 4.18. Relating the previous laws to two Hopf algebra introduced, respectively, by
Connes and Kremer[CK98] and by Calaque, Ebrahimi-Fard, and Manchon[CEFM08], we can see
these papers[Bro00],[CHV08]].

434
9. Formal Power Series and B-Series
Table 4.26.
Coefﬁcients σ(τ), γ(τ),˘b(τ), and b(τ) for trees of order ⩽5
τ
∅
σ(τ)
1
1
2
1
6
1
2
1
γ(τ)
1
2
3
6
4
8
12
24
˘b(τ)
0
1
0
1/12
−1/12
0
0
0
0
b(τ)
0
1
0
−1/12
1/12
0
0
0
0
τ
σ(τ)
24
2
2
6
1
1
2
1
2
γ(τ)
5
10
20
20
40
30
60
120
15
˘b(τ)
1/80
−1/240
1/120
−1/80
1/240
−1/120
−1/240
1/120
1/240
b(τ)
7/240
1/240
1/80
−7/240
−1/240
−1/80
1/240
1/80
−1/240
9.4.3 The Logarithmic Map
The coefﬁcient ω(τ) can be interpreted as the coefﬁcient of the modiﬁed ﬁeld obtained
by backward error analysis, for the explicit Euler method z1 = z0 + hf(z0), corre-
sponding to a = δ∅+ δ•. They can be computed by formula (4.11) or (4.22). Murua
in[Mur06] gives the following formula
log (a) = (a −b∅) ∗ω.
(4.17)
Properties of logarithmic map has been discussed in Proposition 2.1. Using formula
of Example 4.24, determined ω(τ)(= b(τ)) recursively , because a(τ) = 0 ∀τ ∈T
except a( ) = 1.
For example: from 14 formula of Example 4.24, we have
b(
) + 1
2(−1
12) + (1
2)(−1
2)(1
6) + 1
2(−1
2)(1
3) + 1
2(−1
4) + 1
6(1
6) + 2(1
6)(1
4)
+(1
3)(1
4) + 2(1
3)(1
3) + ( 1
24)(−1
2) + 3(1
8)(−1
2) + 1
30 = 0,
then we get
ω(
) = b(
) = 1
20.
The test of others ω(τ) is left the reader.
We give following Table 4.27(compare with [Mur06],[CHV05][CHV08],[CEFM08]).

9.4 Related B-Series Works
435
Table 4.27.
Coefﬁcient ω(τ) for trees of order ⩽5
τ
∅
ω(τ)
0
1
−1/2
1/6
1/3
0
−1/12
−1/6
−1/4
τ
ω(τ)
–1/30
–1/60
1/30
1/30
1/10
1/20
3/20
1/5
1/60
Deﬁnition 4.19. (Lie derivative of B-series) Let b(τ) with b(∅) = 0 and a(τ) be the
coefﬁcient of two B-series and let z(t) be a formal solution of the differential equation
h ˙z(t) = B(b, z(t)). The Lie derivatives of the function B(a, z(t)) with respect to the
vector ﬁeld B(b, z(t)) is again B-series
h d
d tB(a, z(t)) = B(∂ba, z(t)).
(4.18)
Its coefﬁcients are given by ∂ba(∅) = 0 and for |τ| ≥1 by
∂ba(τ) =

θ∈SP (τ)
a(θ)b(τ \ θ),
∂ba(τ) =

pτ ∈P(τ)
a(χp)b(vp).
(4.19)
Exercise 4.20. [HLW02] Prove that the coefﬁcient of modiﬁed differential equation are
recursively deﬁned by b(∅) = 0, b(·) = 1 and
b(τ) = a(τ) −
|τ|

j=2
1
j !∂j−1
b
b(τ),
(4.20)
where ∂j−1
b
b(τ) is the (j −1)-th iterative of the Lie-derivative ∂b.
Proposition 4.21. The above-mentioned formula (4.20) is just formula b ∗
1
γ(τ) =
a(τ) namely
|τ|

j=1
1
j ! ∂j−1
b
b(τ) = b(τ) ∗
1
γ(τ).
(4.21)
Proof. Note that formula (4.23) in Example 4.24 and Tables 4.1 – 4.25, can obtain
this results directly.
▲

436
9. Formal Power Series and B-Series
For Example: from 4th formula of Example 4.24, we have
e( )b( ) + 2e( )b( )b( ) + e( )b( )3 = a( ),
b( ) + b( )b( ) + 1
6b( )3 = a( ),
b( ) = a( ) −b( )b( ) −1
6b( )3.
Example 4.22. The composition laws for the trees of order ≤5 are
a · b( ) = b(∅) · a( ) + b( )
a · b( ) = b(∅) · a( ) + b( ) · a( ) + b( )
a · b(
) = b(∅) · a(
) + b( ) · a( )2 + 2b( ) · a( ) + b(
)
a · b( ) = b(∅) · a( ) + b( ) · a( ) + b( ) · a( ) + b( )
a · b(
) = b(∅) · a(
) + b( ) · a( )3 + 3b( ) · a( )2 + 3b(
) · a( )
+b(
)
a · b(
) = b(∅) · a(
) + b( ) · a( )a( ) + b( ) · a( ) + b( ) · a( )2
+b(
) · a( ) + b( ) · a( ) + b(
)
a · b(
) = b(∅) · a(
) + b( ) · a(
) + b( ) · a( )2 + 2b( ) · a( ) + b(
)
a · b( ) = b(∅) · a( ) + b( ) · a( ) + b( ) · a( ) + b( ) · a( ) + b( )
a · b(
) = b(∅) · a(
) + b( ) · a( )4 + 4b( ) · a( )3 + 6b(
) · a( )2
+4b(
) · a( ) + b(
)
a · b(
) = b(∅) · a(
) + b( ) · a( )3 + b( ) · a( ) · a( )2
+2b( ) · a( ) · a( ) + b(
) · a( ) + b( ) · a( )2
+2b(
) · a( )2 + 2b(
) · a( ) + b(
) · a( ) + b(
)
a · b(
) = b(∅) · a(
) + 2b( ) · a( ) · a( ) + b( ) · a( )2 + b(
) · a( )2
+2b( ) · a( ) + 2b(
) · a( ) + b(
)
a · b(
) = b(∅) · a(
) + b( ) · a( )3 + 3b( ) · a( )2 + 3b(
) · a( )
+b( ) · a(
) + b(
)
a · b(
) = b(∅) · a(
) + b( ) · a( ) · a( ) + b( ) · a( )2 + b( ) · a( )
+b(
) · a( ) + b( ) · a( ) + b( ) · a(
) + b(
)
a · b(
) = b(∅) · a(
) + b( ) · a( ) · a( ) + b( ) · a( ) · a( ) + b( ) · a( )
+b(
) · a( ) + b( ) · a( )2 + b( ) · a( ) + b(
) · a( ) + b(
)

9.4 Related B-Series Works
437
a · b( ) = b(∅) · a( ) + b( ) · a(
) + b( ) · a(
) + b( ) · a( )2
+2b( ) · a( ) + b( )
a · b( ) = b(∅) · a( ) + b( ) · a( ) + b( ) · a( ) + b( ) · a( )
+b( ) · a( ) + b( )
a · b( ) = b(∅) · a( ) + 2b( ) · a( )2 + b( ) · a( ) · a(
) + b(
) · a( )2
+b(
) · a( ) + 2b(
) · a( ) + b( ) · a(
) + b( )
Example 4.23. The substitution law ∗deﬁned in for the trees of order ≤5.
b ∗a( ) = a( )b( )
b ∗a( ) = a( )b( ) + a( )b( )2
b ∗a(
) = a( )b(
) + 2a( )b( )b( ) + a(
)b( )3
b ∗a( ) = a( )b( ) + 2a( )b( )b( ) + a( )b( )3
b ∗a(
) = a( )b(
) + 3a( )b( )b(
) + 3a(
)b( )2b( ) + a(
)b( )4
b ∗a(
) = a( )b(
) + a( )b( )b( ) + a( )b( )2 + a( )b( )b(
)
+2a(
)b( )2b( ) + a( )b( )2b( ) + a(
)b( )4
b ∗a(
) = a( )b(
) + a( )b( )b(
) + 2a( )b( )a( ) + a(
)b( )2b( )
+2a( )b( )2b( ) + a(
)b( )4
b ∗a( ) = a( )b( ) + 2a( )b( )b( ) + a( )b( )2 + 3a( )b( )2b( )
+a( )b( )4
b ∗a(
) = a( )b(
) + 4a( )b( )b(
) + 6a(
)b( )2b(
)
+4a(
)b( )3b( ) + a(
)b( )5
b ∗a(
) = a( )b(
) + a( )b( )b(
) + 2a( )b( )b(
) + a( )b( )b(
)
+a( )b( )2b(
) + 2a(
)b( )2b(
) + a(
)b( )2b( )
+2a(
)b( )b( )2 + 2a(
)b( )3b( ) + 2a(
)b( )3b( )
+a(
)b( )5
b ∗a(
) = a( )b(
) + 2a( )b( )b(
) + 2a( )b( )b( )
+a(
)b( )2b(
) + 2a( )b( )2b( ) + 3a(
)b( )b( )2
+4a(
)b( )3b( ) + a(
)b( )5

438
9. Formal Power Series and B-Series
b ∗a(
) = a( )b(
) + a( )b( )b(
) + 3a( )b( )b(
)
+3a( )b( )2b(
) + 3a(
)b( )2b( ) + a(
)b( )3b( )
+3a(
)b( )3b( ) + a(
)b( )5
b ∗a(
) = a( )b(
) + a( )b( )b(
) + a( )b( )b( ) + a( )b( )b(
)
+a( )b( )b( ) + 2a( )b( )2b( ) + a(
)b( )b( )2
+a( )b( )b( )2 + a( )b( )2b(
) + a(
)b( )2b( )
+a(
)b( )3b( ) + a( )b( )3b( ) + 2a(
)b( )3b( )
+a(
)b( )5
b ∗a(
) = a( )b(
) + a( )b( )b(
) + a( )b( )b(
) + a( )b( )b( )
+a( )b( )b( ) + a( )b( )2b(
) + 2a( )b( )b( )2
+a(
)b( )b( )2 + 2a(
)b( )2b( ) + a( )b( )3b( )
+3a(
)b( )3b( ) + a(
)b( )5
b ∗a( ) = a( )b( ) + a( )b( )b(
) + 2a( )b( )b( ) + a( )b( )b(
)
+2a( )b( )b( )2 + 2a( )b( )2b( )
+a( )b( )2b(
)
+a(
)b( )2b( ) + 2a(
)b( )3b( ) + 2a( )b( )3b( )
+a( )b( )5
b ∗a( ) = a( )b( ) + 2a( )b( )b( ) + 2a( )b( )b( ) + 3a( )b( )2b( )
+3a( )b( )b( )2 + 4a( )b( )3b( ) + a( )b( )5
b ∗a( ) = a( )b( ) + 2a( )b( )b(
) + a( )b( )b(
) + a( )b( )b(
)
+2a(
)b( )2b(
) + 2a(
)b( )2b( ) + 2a( )b( )b( )2
+a(
)b( )3b( ) + 2a(
)b( )3b( )
+a(
)b( )3b( ) + a( )b( )5
(4.22)

9.4 Related B-Series Works
439
Example 4.24. The substitution law ∗deﬁned in for the trees of order ≤5
b ∗e( ) = e( )b( )
b ∗e( ) = e( )b( ) + e( )b( )2
b ∗e(
) = e( )b(
) + 2e( )b( )b( ) + e(
)b( )3
b ∗e( ) = e( )b( ) + 2e( )b( )b( ) + e( )b( )3
b ∗e(
) = e( )b(
) + 3e( )b( )b(
) + 3e(
)b( )2b( ) + e(
)b( )4
b ∗e(
) = e( )b(
) + e( )b( )b( ) + e( )b( )2 + e( )b( )b(
)
+2e(
)b( )2b( ) + e( )b( )2b( ) + e(
)b( )4
b ∗e(
) = e( )b(
) + e( )b( )b(
) + 2e( )b( )e( ) + e(
)b( )2b( )
+2e( )b( )2b( ) + e(
)b( )4
b ∗e( ) = e( )b( ) + 2e( )b( )b( ) + e( )b( )2 + 3e( )b( )2b( )
+e( )b( )4
(4.23)
b ∗e(
) = e( )b(
) + 4e(
)b( )b(
) + 6e(
)b( )2b(
)
+4e(
)b( )3b(
) + e(
)b( )5
b ∗e(
) = e( )b(
) + e(
)b( )b(
) + 2e(
)b( )b(
) + e(
)b(
)b(
)
+e(
)b( )2b(
) + 2e(
)b( )2b(
) + e(
)b( )2b(
)
+2e(
)b( )b(
)2 + 2e(
)b( )3b(
) + 2e(
)b( )3b(
)
+e(
)b( )5
b ∗e(
) = e( )b(
) + 2e(
)b( )b(
) + 2e(
)b(
)b(
) + e(
)b( )2b(
)
+2e(
)b( )2b(
) + 3e(
)b( )b(
)2 + 4e(
)b( )3b(
)
+e(
)b( )5
b ∗e(
) = e( )b(
) + e(
)b( )b(
) + 3e(
)b( )b(
)
+3e(
)b( )2b(
) + 3e(
)b( )2b(
) + e(
)b( )3b(
)
+3e(
)b( )3b(
) + e(
)b( )5

440
9. Formal Power Series and B-Series
b ∗e(
) = e( )b(
) + e(
)b( )b(
) + e(
)b( )b(
) + e(
)b( )b(
)
+e(
)b(
)b(
) + 2e(
)b( )2b(
) + e(
)b( )b(
)2
+e(
)b( )b(
)2 + e(
)b( )2b(
) + e(
)b( )2b(
)
+e(
)b( )3b(
) + e(
)b( )3b(
) + 2e(
)b( )3b(
) + e(
)b( )5
b ∗e(
) = e( )b(
) + e(
)b( )b(
) + e(
)b(
)b(
) + e(
)b(
)b(
)
+e(
)b( )b(
) + e(
)b( )2b(
) + 2e(
)b( )b(
)2
+e(
)b( )b(
)2 + 2e(
)b( )2b(
) + e(
)b( )3b(
)
+3e(
)b( )3b(
) + e(
)b( )5
b ∗e( ) = e( )b( ) + e(
)b( )b(
) + 2e(
)b( )b(
) + e(
)b(
)b(
)
+2e(
)b( )b(
)2 + 2e(
)b( )2b(
) + e(
)b( )2b(
)
+e(
)b( )2b(
) + 2e(
)b( )3b(
) + 2e(
)b( )3b(
) + e( )b( )5
b ∗e(
) = e( )b(
) + 2e(
)b( )b(
) + 2e(
)b(
)b(
) + 3e(
)b( )2b(
)
+3e(
)b( )b(
)2 + 4e(
)b( )3b(
) + +e(
)b( )5
b ∗e(
) = e( )b(
) + 2e(
)b( )b(
) + e(
)b(
)b(
) + e(
)b( )b(
)
+2e(
)b( )2b(
) + 2e(
)b( )2b(
) + 2e(
)b( )b(
)2
+e(
)b( )3b(
) + 2e(
)b( )3b(
) + e(
)b( )3b(
) + e(
)b( )5

Bibliography
[Bak05] H. F. Baker: Alternants and continuous groups. Proc. London Math. Soc., 3:24–47,
(1905).
[Bro00] Ch. Brouder: Runge–Kutta methods and renormalization. Euro. Phys. J. C, 12:521–
534, (2000).
[BSS96] J. C. Butcher and J. M. Sanz-Serna: The number of conditions for a Runge–Kutta
method to have effective order p. Appl. Numer. Math., 22:103–111, (1996).
[CEFM08] D. Calaque, K. Ebrahimi-Fard, and D. Manchon: Two Hopf algebra of trees inter-
acting. arXiv: 0806.2238 v 2, (2008).
[CHV05] P. Chartier, E. Hairer, and G. Vilmart: A substitution law for B-series vector ﬁelds.
Technical Report 5498, INRIA, (2005).
[CHV07] P. Chartier, E. Hairer, and G. Vilmart: Numerical integration based on modiﬁed
differential equations. Math. Comp., 76(260):1941–1953, (2007).
[CHV08] P. Chartier, E. Hairer, and G Vilmart: Composing and substituting S-series and B-
series of integrators and vector ﬁelds.
Preprint, www.irisa.fr/ipso/ﬁchiers/algebraic.pdf,
(2008).
[CK98] A. Connes and D. Kreimer: Hopf algebra, renormazation and noncommutative geom-
etry. Communications in Mathematical Physics, 199:203–242, (1998).
[Dyn46] E. B. Dynkin: Normed Lie algebra and analytic groups, volume 1. Amer. Math. Soc.
(translation), (1946).
[Fen85] K. Feng: On difference schemes and symplectic geometry. In K. Feng, editor, Pro-
ceedings of the 1984 Beijing Symposium on Differential Geometry and Differential Equa-
tions, pages 42–58. Science Press, Beijing, (1985).
[Fen92] K. Feng: Formal power series and numerical methods for differential equations. In
T. Chan and Z. C. Shi, editors, International conf. on scientiﬁc computation, pages 28–35.
World Scientiﬁc, Singapore, (1992).
[Fen93a] K. Feng: Formal dynamical systems and numerical algorithms. In K. Feng and Z.
C. Shi, editors, International conf. on computation of differential equations and dynamical
systems, pages 1–10. World Scientiﬁc, Singapore, (1993).
[Fen93b] K. Feng: Symplectic, contact and volume preserving algorithms. In Z.C. Shi and
T. Ushijima, editors, Proc.1st China-Japan conf. on computation of differential equations
and dynamical systems, pages 1–28. World Scientiﬁc, Singapore, (1993).
[Hai94] E. Hairer: Backward analysis of numerical integrators and symplectic methods. Annals
of Numer. Math., 1:107–132, (1994).
[Hau06] F. Hausdorff: Die symbolische exponentialformel in der gruppentheorie. Berichte der
Sachsischen Akad. der Wissensch., 58:19–48, (1906).
[HLW02] E. Hairer, Ch. Lubich, and G. Wanner: Geometric Numerical Integration. Num-
ber 31 in Springer Series in Computational Mathematics. Springer-Verlag, Berlin, (2002).
[HW74] E. Hairer and G. Wanner: On the Butcher group and general multivalue methods.
Computing, 13:1–15, (1974).
[Lie88] S. Lie; Zur theorie der transformationsgruppen. Christiania, Gesammelte Abh., Christ.
Forh. Aar., 13, (1988).

442
Bibliography
[Mur06] A. Murua: The Hopf algebra of rooted trees, free Lie algebra, and Lie series. Foun-
dations of Computational Mathematics, 6(4):387–426, (2006).
[Olv93] P. J. Olver: Applications of Lie Groups to Differential Equations. GTM 107. Springer-
Verlag, Berlin, Second edition, (1993).
[Ote91] J. A. Oteo: The Baker–Campbell–Hausdorff formula and nested commutator identi-
ties. J. of Math. Phys., 32(2):419–424, (1991).
[OW00] B. Owren and B. Welfert: The Newton iteration on Lie groups. BIT, 40(1):121–145,
(2000).
[Owr06] B. Owren: Order conditions for commutator-free Lie group methods. J. Phys. A:
Math. Gen., 39:5585–5599, (2006).
[Rei99] S. Reich: Backward error analysis for numerical integrators. SIAM J. Numer. Anal.,
36:475–491, (1999).
[SS96] J. M. Sanz-Serna: Backward Error Analysis for Symplectic Integrators. In J. E. Mard-
sen, G. W. Patrick, and W. F. Shadwick, editors, Integration Algorithms and Classical Me-
chanics, pages 193–206. American Mathematical Society, New York, (1996).
[SS97] J. M. Sanz-Serna: Geometric integration. In The State of the Art in Numerical Analysis
(York, 1996), volume 63 of Inst. Math. Appl. Conf. Ser. New Ser., pages 121–143, Oxford
Univ. Press, New York, (1997).

Chapter 10.
Volume-Preserving Methods for Source-Free
Systems
Source-free dynamical systems is an important system in recent mechanics and
physics. It has a abroad application. Therefore, designing a proper numerical method
for this system is signiﬁcant. It is well known that phase ﬂow of source-free system
is a volume-preserving transformation. Therefore, the transient operator of the numer-
ical method that we design should be volume-preserving. We call this algorithm the
volume-preserving algorithm.
10.1 Liouville’s Theorem
Let x = (x1, x2, · · · , xN)T, and f(x) = (f1(x), f2(x), · · · , fN(x))T : RN →RN,
then the dynamical system
d x
d t = f(x)
(1.1)
is source-free (i.e., divergence-free), when
N

i=1
∂fi
∂xi = 0 (i.e., div f(x) = 0). The ﬂow
of a source-free system is volume-preserving, i.e.,
det (et
f(x))∗= 1,
∀x, t,
here et
f denotes the ﬂow of system (1.1) and (et
f(x))∗the Jacobian of et
f at x. Thus,
volume-preserving schemes are required for computing the numerical solution of
(1.1). If det
∂xn+1
∂xn

= 1, we call this scheme volume-preserving, where xn denotes
the numerical solution at step n.
We know that the phase ﬂow of Hamiltonian system preserves phase volume in-
variable. The source-free system is more general than the Hamiltonian system, we
must prove that the phase ﬂow preserving phase volume is invariable, considering the
dynamic system (1.1), its phase ﬂow is
gt(x) = x + f(x)t + o(t2).
(1.2)
Let D(0) be a region in x space and V (0) is its volume, then
V (t) = volume of D(t),
D(t) = gtD(0).

444
10. Volume-Preserving Methods for Source-Free Systems
Theorem 1.1 (Liouville’s Theorem). If div f = 0, then gt preserving the volume is
invariable, V (t) = V (0).
Proof. First proof
d V (t)
d t

t=0 =
-
D(0)
div fd x,
(1.3)
for any t, using the formula for changing variables in a multiple integral gives
V (t) =
-
D(0)
det ∂gtx
∂x d x.
Calculating ∂gtx
∂x by formula (1.2), we ﬁnd
∂gtx
∂x
= E + ∂f
∂xt + O(t2),
as t →0.
but
det (E + At) = 1 + t tr A + O(t2),
t →0,
where tr A =
n

i=1
aii. Therefore
V (t) =
-
D(0)
[1 + t div f + O(t2)]d x,
(1.4)
d V (t)
d t

t=0 =
-
D(0)
div fd x.
Then Equation (1.3) is proved. Now we take t = t0 is no worse than t = 0, therefore
d V (t)
d t

t=t0 =
-
D(t0)
div fd x,
and if div f = 0, d V (t)
d t
= 0. This completes the proof.
▲
In particular, for Hamiltonian equation
div f = ∂
∂p

−∂H
∂q

+ ∂
∂q
∂H
∂p

= 0,
Liouville’s theorem is proved specially.
10.2 Volume-Preserving Schemes
10.2.1 Conditions for Centered Euler Method to be Volume
Preserving
Let us consider centered Euler scheme

10.2 Volume-Preserving Schemes
445
xn+1 = xn + τf
xn+1 + xn
2

,
(2.1)
where τ is the step size in t. We then have
∂xn+1
∂xn
= IN + τDf
xn+1 + xn
2
 1
2
∂xn+1
∂xn
+ 1
2IN

,
∂xn+1
∂xn
=
IN + τ
2 Df(x∗)
IN −τ
2 Df(x∗)
.
Here, Df = fx = ∂f
∂x ≡B = (bij), x∗= xn+1 + xn
2
. The condition det
∂xn+1
∂xn

=
1, now requires
|IN + τ
2 Df(x∗)|
|IN −τ
2 Df(x∗)|
= 1. Let P(λ) = |Df(x∗) −λIn| be the character-
istic matrix of Df(x∗). Since
IN + τ
2 Df(x∗)

IN −τ
2 Df(x∗)

=

τ
2
%
Df(x∗) + 2
τ IN
& 
 −τ
2
%
Df(x∗) −2
τ IN
& 
= (−1)N
P
% 2
τ
&
P
%
−2
τ
&,
we then get the condition for scheme (2.1) to be volume-preserving[QZ93], i.e.,
P(λ) = (−1)NP(−λ).
Let us consider some particular cases of N to show that scheme (2.1) is not always
volume preserving.
Case 2.1. In this case, we have
P(λ) = λ2 + (b11 + b22)λ + b11b22 −b12b21.
(2.2)
Since
N

i=1
∂fi
∂xi
= 0, i.e., tr B = 0, then P(λ) = λ2 + b11b22 −b12b21, and
P(−λ) = P(λ).
Thus, the scheme (2.1) is always volume-preserving for source-free systems of dim.2.
Case 2.2. Here
P(λ) = −λ3 + (b11 + b22 + b33)λ2 −cλ + |B| = −λ3 −cλ + |B|,
(2.3)
where
c =

b11
b12
b21
b22
 +

b22
b23
b32
b33
 +

b11
b13
b31
b33
 .

446
10. Volume-Preserving Methods for Source-Free Systems
The volume-preserving condition for Euler method is now |B| = 0. For example,
(ABC ﬂow) when system (1.1) takes the form
d x
d t = cy −bz,
d y
d t = az −cx,
a, b, c ∈R,
d z
d t = bx −ay,
we have |B| = 0. For this dynamical system, centered Euler method is volume-
preserving.
Lemma 2.3. Let P(λ) be the characteristic polynomial of matrix AN×N, then
P(λ) = |A −λIN| = (−1)N
λN −P1λN−1 + P2λN−2 + · · · + (−1)NPN

, (2.4)
where
P1 =
N

i
aii = tr A,
P2 =
N

i<j

aii
aij
aji
ajj
 ,
P3 =
N

i<j<k

aii
aij
aik
aji
ajj
ajk
aki
akj
akk

,
· · ·
PN = |A|.
(2.5)
Using Lemma 2.3, we can discuss the case N = 4.
Case 2.4. At this time,
P(λ) = λ4 −P1λ3 + P2λ2 −P3λ + |B|.
Since P1 = tr (B) = 0, then P(−λ) = (−1)4P(λ) requires P3 = 0.
It must be pointed out that, when N increases, more increasing number of condi-
tions is required for system (2.1) to be volume-preserving, and it seems impossible to
satisfy all these condition. But fortunately, for the special case when system (1.1) is
Hamiltonian, i.e.,
f = J∇H,
J =
5
O
−Ik
Ik
O
6
,
N = 2k.
Scheme (2.1) is volume-preserving. This is because the Hamiltonian system is source-
free and Df is an inﬁnitesimal symplectic matrix, we have the following Lemma.

10.2 Volume-Preserving Schemes
447
Lemma 2.5. Let M be an inﬁnitesimal symplectic matrix, if λ is an eigenvalue of M,
so are −λ, ¯λ, −¯λ.
From Lemma 2.5, we know that P(−λ) = (−λ)2kP(λ) is valid when system
(1.1) is Hamiltonian, so Euler method is volume-preserving for Hamiltonian systems.
In fact, the method is even symplectic for Hamiltonian systems, that is to say it also
preserve the symplectic structure of Hamiltonian systems which is a much stronger
property than volume-preserving.
10.2.2 Separable Systems and Volume-Preserving Explicit
Methods
In this section, we consider a special kind of source-free systems called separable
systems. System (1.1) is separable if
d xi
d t = fi(x1, x2, · · · , xi−1, xi+1, · · · , xN),
i = 1, 2, · · · , N.
(2.6)
We can divide the above system into N source-free systems:
⎧
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎩
d x1
d t = f1(x2, · · · , xN),
d x2
d t = 0,
...
d xN
d t
= 0.
(2.7)
⎧
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎩
d x1
d t = 0,
d x2
d t = f2(x1, x3, · · · , xN),
...
d xN
d t
= 0.
(2.8)
· · ·
⎧
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎩
d x1
d t = 0,
...
d xN−1
d t
= 0,
d xN
d t
= fN(x1, · · · , xN−1).
(2.9)

448
10. Volume-Preserving Methods for Source-Free Systems
The ﬁrst order explicit Euler method can be applied to them to get the exact solutions
of them, i.e., the phase ﬂows of them. Using the composition method[QZ92], we can
construct ﬁrst order explicit Euler volume-preserving scheme for system (2.6). The
adjoint of this scheme is obtained from the implicit Euler method and is also explicit.
Composing these two schemes, we get a reversible explicit. This process can be ex-
pressed by formal power series as shown below.
From Chapter 9, we know the ﬂow of (1.1) can be represented by power of series.
eτ
f = 1N +
∞

k=1
τ kek,f,
ek,f : RN −→RN,
ek,f = 1
k !f ∗k1N,
where f ∗denotes the ﬁrst order differential operator , f ∗=
N

i=1
fi
∂
∂xi
, f ∗2 = f ∗×
f ∗, f ∗3 = f ∗× f ∗× f ∗, · · · , 1N is the identity vector function, 1N(x) = x. For
simplicity, we just write out
eτ
A · eτ
B = eτ
cτ ,
(2.10)
the ﬁrst several terms are
cτ = A + B + τ
2[A, B] + o(τ 2),
where [A, B] = A∗B −B∗A is the Lie bracket of A and B, A∗, B∗denotes the
Jacobian matrix of A and B .
We now rewrite system of Equations (2.7) – (2.9) in compact form as
d x
d t = ai(x),
ai = (0, · · · , 0, fi, 0, · · · , 0)T,
i = 1, 2, · · · , N.
(2.11)
These integrable systems have ﬂow
eτ
ai = 1N +
inf

k=1
τ kek,ai,
i = 1, 2, · · · , N.
(2.12)
Since we have a∗N
i
1N(x) = a∗k
i x = 0, when k ≥2, then
eτ
ai(x) = x +
inf

k=1
τ kek,ai(x) = x +
inf

k=1
τ k
k !a∗
i
k1N(x) = x + τai(x).
(2.13)
Using the formula (2.10), we ﬁnd
eτ
aN × eτ
aN−1 × · · · × eτ
a2 × eτ
a1 = eτ
f+o(τ).
(2.14)
This means the concatenation eτ
aN × eτ
aN−1 × · · · × eτ
a1 approximates the ﬂow eτ
f to
the ﬁrst order of τ.
Because the equations in the system (2.11) are all source-free, their ﬂows are all
volume-preserving and the concatenation of them remains volume-preserving, so

10.3 Source-Free System
449
det

(eτ
aN × eτ
aN−1 × · · · × eτ
a1)(x)

∗
= det

eτ
aN (xN−1))∗× det (eτ
aN−1(xN−2))∗× · · · × det (eτ
a1(x0))∗= 1,
where x0 = x, x1 = eτ
a1(x0), · · · , xN−1 = eτ
aN−1(xN−2), xN = eτ
aN (xN−1).
Thus, from system (2.6) we get volume-preserving scheme of ﬁrst order. This is an
explicit scheme since eτ
ai (i = 1, · · · , N) are ﬂows of integrable systems which can be
written as (2.13). From [QZ92] , we know the concatenation eτ
aN ×eτ
aN−1 ×· · ·×eτ
a1with
its adjoint eτ
a1 × eτ
a2 × · · · × eτ
aN produces a reversible scheme
e
τ
2aN × e
τ
2aN−1 × · · · × eτ
a1 × · · · × e
τ
2aN−1 × e
τ
2aN
of second order, but is still explicit. We can use theory of composition[QZ92] to con-
struct symplectic scheme of arbitrary order.
10.3 Source-Free System
Source-free dynamical systems on the Euclidean space Rn are deﬁned by source-free
(or divergence-free) vector ﬁelds a : Rn →Rn,
div a(x) =
n

i=1
∂ai(x)
∂xi
= 0,
∀x ∈Rn,
(3.1)
through equations
d x
d t = ˙x = a(x),
(3.2)
here and hereafter, we use the coordinate description and matrix notation
x = (x1, · · · , xn)T,
a(x) = (a1(x), · · · , an(x))T,
(3.3)
where T denotes the transpose of a matrix.
In this subsection, we mainly analyze and construct numerical algorithms proper
for source-free systems. Such systems constitute one of the most important classi-
cal cases of dynamical systems preserving certain geometric structure and arise in
many physical problems such as particle tracking in incompressible ﬂuids and toroidal
magnetic surface-generation in stellarators. Because of the difﬁculty and even impos-
sibility of solving equations by quadrature, the numerical methods certainly play an
important role in understanding the dynamic behavior of a system and in solving phys-
ical and engineering problems. On the other hand, the problem of whether a numerical
algorithm is proper for a system is closely related to the problem of whether the al-
gorithmic approximation to the corresponding phase ﬂow approximates perfectly in
some sense and even strictly preserve the structure of the system itself if the system
has such structure. It has been evidenced with some typical examples in the Hamilto-
nian case that “nonproper” algorithms will result in essentially wrong approximations

450
10. Volume-Preserving Methods for Source-Free Systems
to the solutions of systems and “proper” algorithms may generate remarkably right
ones.
But how does one evaluate a numerical algorithm to be proper for source-free
systems? It is well known that intrinsic to all source-free systems there is a volume
form of the phase space Rn, say
α = dx1 ∧dx2 ∧· · · ∧dxn
(3.4)
such that the evolution of dynamics preserves this form. In other words, the phase ﬂow
et
a, of source-free system (3.2), satisﬁes the volume-preserving condition
(et
a)∗α = α,
(3.5)
or equivalently,
det ∂et
a(x)
∂x
= 1,
∀x ∈Rn,
t ∈R.
(3.6)
In addition to this, et
a satisﬁes the group property in t,
e0
a = identity,
et+s
a
= et
a ◦es
a.
(3.7)
In fact, (3.5) and (3.7) completely describe the properties of the most general
source-free dynamical systems. This fact suggests that a proper algorithmic approxi-
mation gs
a to phase ﬂow es
a for source-free vector ﬁeld a : Rn →Rn should satisfy
these two requirements. However, the group property (3.7) is too stringent in general
for algorithmic approximations because only the phase ﬂows satisfy it. Instead of it, a
weaker requirement, i.e.,
g0
a = identity,
gs
a ◦g−s
a
= identity,
(3.8)
is reasonable and practicable for all vector ﬁelds a : Rn →Rn . We call such algo-
rithmic revertible approximations, that means gs
a always generate coincident forward
and backward orbits.
As for the volume-preserving property (3.5), it characterizes the geometric struc-
ture —volume-preserving structure—of source-free systems. Our aim here is just
to construct difference schemes preserving this structure, which we call volume-
preserving schemes, in sense that the algorithmic approximations to the phase ﬂows
satisfy (3.5) for the most general source-free systems.
10.4 Obstruction to Analytic Methods
We note that for n = 2, source-free vector ﬁelds = Hamiltonian ﬁelds, and area-
preserving maps = symplectic maps, so the problem for area-preserving algorithms
has been solved in principle.
But for n ≥3, the problem is new, since all the conventional methods plus even the
symplectic methods are generally not volume-preserving, even for linear source-free
systems. As an illustration, see example and Lemma of Feng and Shang[FS95].

10.4 Obstruction to Analytic Methods
451
Example 4.1. Solve on R3
dx
dt = a(x) = Ax,
tr A = 0,
(4.1)
by the Euler centered method, we get algorithmic approximation Gs to es
a = exp (sA)
with
Gs =

I −s
2A
−1 
I + s
2A

.
(4.2)
Simple calculations show that in 3-dimensions, if tr A = 0, then det Gs = 1 ⇔
det A = 0, which is exceptional. A more general conclusion in linear case is
Lemma 4.2. Let sl(n) denote the set of all n × n real matrices with trace equal to
zero and SL(n) the set of all n × n real matrices with determinant equal to one. Then
for any real analytic function φ(z) deﬁned in a neighborhood of z = 0 in C satisfying
the conditions:
1◦
φ(0) = 1;
2◦
˙φ(0) = 1.
We know that φ(sl(n)) ⊂SL(n) for some n ≥3 if and only if φ(z) = exp (z).
Proof. “If part” is a known conclusion, for the “only if part” it sufﬁces to show it for
n = 3. For this, we consider matrices of the diagonal form
D(s, t) =
⎡
⎢⎢⎣
s
0
0
0
t
0
0
0
−(s + t)
⎤
⎥⎥⎦∈sl(3),
s, t ∈R.
(4.3)
Since φ is analytic in a neighborhood of the origin in C, we have
φ(D(s, t)) =
⎡
⎢⎢⎣
φ(s)
0
0
0
φ(t)
0
0
0
φ(−(s + t))
⎤
⎥⎥⎦,
s, t ∽0.
(4.4)
By assumption, det φ(D(s, t)) = 1, for s, t ∽0. So
φ(s)φ(t)φ(−(s + t)) = 1,
s, t ∽0,
(4.5)
together with the condition φ(0) = 1, we have
φ(s)φ(−s) = 1,
s ∽0.
(4.6)
Multiplying the both sides of Equation (4.5) by φ(s + t) and using (4.6), we get
φ(s)φ(t) = φ(s + t),
s, t ∽0.
(4.7)
This, together with the conditions 1◦and 2◦of the lemma, implies
φ(z) = exp (z),
which completes the proof.
▲

452
10. Volume-Preserving Methods for Source-Free Systems
Lemma 4.2 says that there are no consistent analytic approximations to the expo-
nential function sending sl(n) into SL(n) at the same time other than the exponential
itself. This shows that it is impossible to construct volume-preserving algorithms ana-
lytically depending on source-free vector ﬁelds. Thus we have:
Theorem 4.3 (Feng-Shang). All the conventional methods including the well-known
Runge–Kutta methods, linear multistep methods and Euler methods (explicit, implicit
and centered) are non-volume-preserving.
The above lemma tell us we cannot construct volume-preserving scheme for all
source-free system. But we can split class sl(n) to subclass and perhaps in subclass,
there exists volume-preserving scheme.
In Subsection 10.2.1, we get some condition for centered Euler scheme to be
volume-preserving scheme. It is the best elucidation.
Consequently, to construct volume-preserving algorithms for source-free systems,
we must break through the conventional model and explore new ways.
10.5 Decompositions of Source-Free Vector Fields
In R2, every source-free ﬁeld a = (a1, a2)T corresponds to a stream function or
2-dimensional Hamiltonian ψ, unique up to a constant:
a1 = −∂ψ
∂x2 ,
a2 = ∂ψ
∂x1 .
(5.1)
In R3, every source-free ﬁeld a = (a1, a2, a3)T corresponds to a vector potential
b = (b1, b2, b3)T, unique up to a gradient:
a = curl b,
a1 = ∂b3
∂x2 −∂b2
∂x3 ,
a2 = ∂b1
∂x3 −∂b3
∂x1 ,
a3 = ∂b2
∂x1 −∂b1
∂x2 ,
(5.2)
then we get source-free decomposition
a =
⎡
⎢⎢⎣
a1
a2
a3
⎤
⎥⎥⎦=
⎡
⎢⎢⎢⎢⎢⎣
0
∂b1
∂x3
−∂b1
∂x2
⎤
⎥⎥⎥⎥⎥⎦
+
⎡
⎢⎢⎢⎢⎢⎣
−∂b2
∂x3
0
∂b2
∂x1
⎤
⎥⎥⎥⎥⎥⎦
+
⎡
⎢⎢⎢⎢⎢⎣
∂b3
∂x2
−∂b3
∂x1
0
⎤
⎥⎥⎥⎥⎥⎦
= a(1)+a(2)+a(3). (5.3)
As a generalization of cases n = 2, 3, on Rn, we have[FS95]:
Lemma 5.1. To every source-free ﬁeld a = (a1, a2, · · · , an)T, there corresponds a
skew symmetric tensor ﬁeld of order 2, b = (bik)1≤i,k≤n, bik = −bki, so that
ai =
n

k=1
∂bik
∂xk ,
i = 1, 2, · · · , n.
(5.4)

10.5 Decompositions of Source-Free Vector Fields
453
Proof. With the given a = (a1, · · · , an)T, we deﬁne the 1-form on Rn
α =
n

i=1
ai(x)d xi.
(5.5)
Since a is source-free, we have
δα = −
n

i=1
∂ai
∂xi = −div a = 0,
where δ is codifferential operator. The above equation means that α is δ-closed. By
Poincar´e’s lemma, there exists a 2-form, say β, so that
α = δβ.
(5.6)
But for the 2-form β, there exists a skew symmetric tensor of order 2, b = (bik)1≤i.k≤n,
bik = −bki, so that
β =
n

i,k=1
bikd xi ∧d xk.
(5.7)
Take (5.7) codifferential,
δβ =
n

i=1
* n

k=1
∂bik
∂xk
+
d xi,
(5.8)
and from Equations (5.5) and (5.6), we get (5.4). The proof is completed.
▲
By (5.4), we can decompose
a =

1≤i<k≤n
a(ik),
a(ik) =

0, · · · , 0, ∂bik
∂xk
, 0, · · · , −∂bik
∂xi
, 0, · · · , 0
T
,
i < k.
(5.9)
Every vector ﬁeld a(ik) in (5.9) is a 2-dimensional Hamiltonian on the xi-xk plane
and zero in other dimensions. We call such decompositions essentially Hamiltonian
decompositions.
We note that the tensor potential b = (bik)1≤i,k≤n is far from uniquely determined
for a given source-free ﬁeld a = (a1, · · · , an)T from Equation (5.4). For uniqueness,
one may impose normalizing conditions in many different ways. One way is to impose,
as done by H. Weyl in[Wey40] in 3-dimensional case:
N0 : bik = 0,
|i −k| ≥2,
(5.10)
this condition is ineffective for n = 2. The non zero components are
b12 = −b21,
b23 = −b32, · · · , bn−1,n = −bn,n−1.
(5.11)
Nk : bk,k+1|xk+1=0 = 0,
1 < k ≤n −2
(5.12)

454
10. Volume-Preserving Methods for Source-Free Systems
this condition is ineffective for n = 2,
Nn−1 : bn−1,n|xn−1=xn=0 = 0.
(5.13)
Then, simple calculations show that all bk,k+1 are uniquely determined by quadra-
ture
b12 =
- x2
0
a1d x2,
(5.14)
bk,k+1 =
- xk+1
0

ak + ∂bk−1,k
∂xk−1

d xk+1,
2 ≤k ≤n −2,
(5.15)
bn−1,n =
- xn
0
%
an−1 + ∂bn−2,n−1
∂xn−2
&
d xn −
- xn−1
0
an|xn=0d xn−1. (5.16)
So, one gets an essentially Hamiltonian decomposition for a as
a =
n−1

k=1
a(k),
a(k) =
%
0, · · · , 0, ∂bk,k+1
∂xk+1 , −∂bk,k+1
∂xk
, 0, · · · , 0
&T
,
(5.17)
or in components,
⎧
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎩
a1 = ∂b12
∂x2 ,
a2 = −∂b12
∂x1 + ∂b23
∂x3 ,
...
an−1 = −∂bn−2,n−1
∂xn−2
+ ∂bn−1,n
∂xn
,
an = −∂bn−1,n
∂xn−1 .
(5.18)
10.6 Construction of Volume-Preserving Schemes
In this section, we give a general way to construct volume-preserving difference
schemes for source-free systems by means of essentially the Hamiltonian decom-
positions of source-free vector ﬁelds and the symplectic difference schemes for 2-
dimensional Hamiltonian systems. With this aim, we ﬁrst prove:
Lemma 6.1. Let a be a smooth vector ﬁeld on Rn and have decomposition
a =
m

i=1
a(i),
(6.1)
with smooth ﬁelds a(i):Rn →Rn (i = 1, · · · , m). Suppose that, for each i =
1, · · · , m, Gτ
i is an approximation of order p to eτ
a(i), the phase ﬂow of the system

10.6 Construction of Volume-Preserving Schemes
455
associated to the ﬁeld a(i), in the sense that lim
τ→0
1
τ p (Gτ
i (x) −eτ
a(i)(x)) = 0 for all
x ∈Rn with some p ≥1. Then, we have:
1◦
For any permutation (i1i2 · · · im) of (12 · · · m), the compositions
1Gτ
i1i2···im := Gτ
im ◦· · · ◦Gτ
i2 ◦Gτ
i1,
1 Gτ
i1i2···im :=

1G−τ
i1i2···im
−1
(6.2)
are approximations, of order one, to eτ
a; and the compositions
2gτ
i1i2···im := 1 G
τ
2
i1i2···im ◦1G
τ
2
i1i2···im,
2gτ
i1i2···im := 1G
τ
2
i1i2···im ◦1 G
−τ
2
i1i2···im (6.3)
are revertible approximations, of order 2, to eτ
a;
2◦
If, for each i = 1, 2, · · · , m, Gτ
i is an approximation, of order 2, to eτ
a, then
2Gτ
i1i2···im := G
τ
2
im ◦· · · ◦G
τ
2
i2 ◦G
τ
2
i1 ◦G
τ
2
i1 ◦G
τ
2
i2 ◦· · · ◦G
τ
2
im
(6.4)
is an approximation, of order 2, to eτ
a; and it is revertible if each Gτ
i is revertible;
3◦
If 2Gτ is a revertible approximation, of order 2, to eτ
a, then the symmetric
composition[QZ92]
4Gτ = 2Gα1τ ◦2Gβ1τ ◦2Gα1τ
(6.5)
with
α1 = (2 −2
1
3 )−1,
β1 = 1 −2α1 < 0,
(6.6)
is a revertible approximation, of order 4, to eτ
a; and generally, the symmetric compo-
sition, recursively is deﬁned as follows,
2(l+1)Gτ = 2lGαlτ ◦2lGβlτ ◦2lGαlτ,
(6.7)
with
αl = (2 −2
1
(2l+1) )−1,
βl = 1 −2αl < 0,
(6.8)
as a revertible approximation, of order 2(l + 1), to eτ
a.
Proof. It is only needed to prove for (i1i2 · · · im) = (12 · · · m).
1◦
It is easy to prove that the phase ﬂow et
a has the series expansion
et
a(x) = x +
∞

k=1
tk
k!ak(x),
x ∈Rn,
t ∽0,
(6.9)
where
a1(x) = a(x),
a2(x) = ∂a1(x)
∂x
a(x),
ak(x) = ∂ak−1(x)
∂x
a(x),
k = 1, 2, · · · .
(6.10)
The assumption that for i = 1, 2, · · · , m, Gτ
i are approximations of order p ≥1, to
eτ
a(i) implies that for all x ∈Rn,

456
10. Volume-Preserving Methods for Source-Free Systems
Gτ
i (x) = x + τa(i)(x) + O(τ 2),
τ ∽0,
i = 1, 2, · · · , m.
(6.11)
So, from Taylor expansion, we have that for x ∈Rn,
(Gτ
2 ◦Gτ
1)(x) = Gτ
2

Gτ
1(x)

= x + τ(a(1)(x) + a(2)(x)) + O(τ 2),
τ ∽0. (6.12)
By induction for m, we get
1Gτ
(12···m)(x) = (Gτ
m ◦· · · ◦Gτ
2 ◦Gτ
1)(x)
= x + τ(a(1)(x) + a(2)(x) + · · · + a(m)(x)) + O(τ 2)
= x + τa(x) + O(τ 2),
τ ∽0.
(6.13)
This implies that 1Gτ
(12···m) is an approximation, of order one, to eτ
a, which provides
the proof needed.
In[QZ92] that 2gτ
i1i2···im and 2gτ
i1i2···im, deﬁned by Equation (6.2), are revertible
approximations, of order 2, to eτ
a, the conclusion 1◦of the Lemma 6.1 is proved.
2◦
By assumption, we have that for x ∈Rn and τ ∼0,
Gτ
i (x) = x + τa(i)(x) + 1
2τ 2
a(i)2(x) + O(τ 3),
i = 1, 2, · · · , m.
(6.14)
Taylor expansion of the right hand side of Equation (6.4) with (i1i2 · · · im) =
(12 · · · m) yields
2Gτ
(12···m)(x) = x + τ
m

i=1
a(i)(x) + 1
2τ 2
⎛
⎝
m

i,j=1
a(i)a(j)
⎞
⎠(x) + O(τ 3),
τ ∽0.
(6.15)
Here, we have used the convention
(ab)(x) = (a∗b)(x) = a∗(x)b(x),
a∗(x) = ∂a(x)
∂x ,
(6.16)
for a, b : Rn →Rn. However, we have
a2 = a∗a =
* m

i=1
a(i)
+
∗
 m

j=1
a(j)
=
m

i,j=1
(a(i))∗a(j) =
m

i,j=1
a(i)a(j).
(6.17)
So
eτ
a(x) = x + τa(x) + 1
2τ 2a2(x) + O(τ 3) = 2Gτ
(12···m)(x) + O(τ 3),
τ ∼0.
This shows that 2Gτ
(12···m) is an approximation, of order 2, to eτ
a. By direct veriﬁca-
tion, this is revertible if each component Gτ
i is revertible.
The conclusion 3◦directly follows from Qin-Zhu’s paper[QZ93].
▲

10.6 Construction of Volume-Preserving Schemes
457
Lemma 6.2. Given system
˙x = a(k)(x),
a(k)(x) =

0, · · · , 0, ∂bk,k+1
∂xk+1 (x), −∂bk,k+1
∂xk
(x), 0, · · · , 0
T
,
(6.18)
with x = (x1, · · · , xk, xk+1, · · · , xn)T and smooth function bk,k+1 : Rn →Rn .
Then any symplectic difference scheme, of order p ≥1, of the Hamiltonian system on
the xk-xk+1 plane
˙xk = ∂bk,k+1
∂xk+1
,
˙xk+1 = −∂bk,k+1
∂xk
,
(6.19)
with xj, j ̸= k, k + 1 as parameters naturally gives a volume-preserving differ-
ence scheme, of order p, of the source-free system (6.18) on the n-dimensional
(x1, · · · , xn)T-space by simply freezing the coordinates xj, j ̸= k, k + 1 and trans-
forming xk and xk+1 according to the symplectic difference scheme for (6.19) in which
xj, j ̸= k, k + 1 are considered as frozen parameters.
Proof. It is obvious that the so-constructed difference scheme is of order p. As to the
volume-preserving property, we easily prove that it is true by direct calculation of the
determinant of the Jacobian of the step-transition map of the scheme, with the notice
of the fact that the determinant of the Jacobian of a symplectic map is equal to one.
Now, we construct volume-preserving difference schemes for source-free systems.
Let a = (a1, · · · , an)T be a source-free ﬁeld. As was proved in Section 10.5, we
have essentially Hamiltonian decomposition (5.17) for a with the functions bk,k+1
given from a by (5.14) – (5.16). We denote by Sτ
k the step transition map of a
volume-preserving difference scheme with step size τ, as constructed in Lemma 6.2,
associated to the vector ﬁeld a(k) =
%
0, · · · , 0, ∂bk,k+1
∂xk+1 , −∂bk,k+1
∂xk
, 0, · · · , 0
&T
for
k = 1, 2, · · ·.
▲
Then by Lemma 6.1, we have:
Theorem 6.3. [FW94] 1◦
A simple composition of the n−1 components Sτ
1 , Sτ
2 , · · · ,
Sτ
n−1, say
1Gτ := Sτ
n−1 ◦· · · ◦Sτ
2 ◦Sτ
1
is a volume-preserving algorithmic approximation, of order one, to eτ
a; and
2gτ := 1 G
τ
2 ◦1G
τ
2 ,
2gτ = 1G
τ
2 ◦1 G
τ
2
are revertible volume-preserving algorithmic approximations, of order 2.
2◦
If each Sτ
k is an approximation, of order 2, to eτ
a(k), then the symmetric com-
position
2Gτ = S
τ
2
n−1 ◦· · · ◦S
τ
2
2 ◦S
τ
2
1 ◦S
τ
2
1 ◦S
τ
2
2 ◦· · · ◦S
τ
2
n−1
(6.20)
is a volume-preserving approximation, of order 2, to eτ
a.
3◦
If each Sτ
k is revertible, then the so-constructed 2Gτ is revertible too.
4◦
From the above constructed revertible algorithmic approximation 2gτ or
2Gτ, we can further recursively construct revertible approximations, of all even
orders, to eτ
a according to the process of Lemma 6.1.

458
10. Volume-Preserving Methods for Source-Free Systems
Remark 6.4. If a has essentially Hamiltonian decompositions other than (5.17) and
(5.14) – (5.16), then one can construct volume-preserving difference schemes corre-
sponding to these decompositions in a similar way to the above.
10.7 Some Special Discussions for Separable
Source-Free Systems
For a source-free ﬁeld a = (a1, · · · , an)T with essentially Hamiltonian decomposition
(5.17), we take Sτ
k : x = (x1, · · · , xn)T →x = (x1, · · · , xn)T as determined from
the following:
⎧
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎩
xj = xj,
j ̸= k, k + 1,
xk = xk + τ ∂bk,k+1
∂xk+1 (x1, · · · , xk−1, xk, xk+1, · · · , xn),
xk+1 = xk+1 −τ ∂bk,k+1
∂xk
(x1, · · · , xk−1, xk, xk+1, · · · , xn).
(7.1)
Then, simple calculations show that 1Gτ = Sτ
n−1 ◦· · · ◦Sτ
2 ◦Sτ
1 from
⎧
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎩
x1 = x1 + τa1(x1, x2, · · · , xn),
xj = xj + τaj(x1, · · · , xj, xj+1, · · · , xn)
+τ
- xj
xj
j−1

l=1
∂al
∂xl (x1, · · · , xj−1, t, xj+1, · · · , xn)dt,
j = 2, · · · , n −1,
xn = xn + τan(x1, · · · , xn−1, xn),
(7.2)
and 1 Gτ =

1G−τ−1
is given from
⎧
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎩
xn = xn + τan(x1, · · · , xn−1, xn),
xj = xj + τaj(x1, · · · , xj, xj+1, · · · , xn)
−τ
- xj
xj
j−1

l=1
∂al
∂xl
(x1, · · · , xj−1, t, xj+1, · · · , xn)d t,
j = 2, · · · , n −1,
x1 = x1 + τa1(x1, x2, · · · , xn).
(7.3)
(7.2) and (7.3) are both volume-preserving difference scheme, of order 1, of the
source-free system associated to the ﬁeld a, with the step-transition maps 1Gτ and
1 Gτ. They can be composed into revertible volume-preserving schemes of order 2,
say, 2-stage scheme with step transition map 2gτ = 1G
τ
2 ◦1 G
τ
2 : x = (x1, · · · , xn)T →
x = (x1, · · · , xn)T as follows,

10.7 Some Special Discussions for Separable Source-Free Systems
459
⎧
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎩
x
1
2n = xn + τ
2an

x1, · · · , xn−1, x
1
2n

,
x
1
2
i = xi + τ
2ai

x1, · · · , xi, x
1
2
i+1, · · · , x
1
2n

−τ
2
- x
1
2
i
xi
i−1

l=1
∂al
∂xl

x1, · · · , xi−1, t, x
1
2
i+1, · · · , x
1
2n

d t,
i = 2, · · · , n −1,
x
1
2
1 = x1 + τ
2a1

x1, x
1
2
2 , · · · , x
1
2n

,
x1 = x
1
2
1 + τ
2a1

x1, x
1
2
2 , · · · , x
1
2n

,
xj = x
1
2
j + τ
2aj

x1, · · · , xj, x
1
2
j+1, · · · , x
1
2n

+τ
2
- xj
x
1
2
j
j−1

l=1
∂al
∂xl

x1, · · · , xj−1, t, x
1
2
j+1, · · · , x
1
2n

d t,
j = 2, · · · , n −1,
xn = x
1
2n + τ
2an

x1, · · · , xn−1, x
1
2n

.
(7.4)
Either (7.2) or (7.3) contains n −1 implicit equations generally. But for ﬁelds a with
some speciﬁc properties, it will turn into explicit. For example,
∂ai
∂xi = 0,
i = 1, · · · , n
(7.5)
(i.e., ai does not depend on xi), then (7.2) turns into explicit[QZ93]
⎧
⎪
⎪
⎨
⎪
⎪
⎩
x1 = x1 + τa1(x2, · · · , xn),
xj = xj + τaj(x1, · · · , xj−1, xj+1, · · · , xn),
j = 2, · · · , n −1,
xn = xn + τan(x1, · · · , xn−1, xn).
(7.6)
For details, see the Section 10.2.
We note that, for a = (a1, · · · , an)T,
a =
n

k=1
a{k},
a{k} = (0, · · · , 0, ak, 0, · · · , 0)T,
k = 1, 2, · · · , n.
(7.7)
It is easy to verify that if a = (a1, · · · , an)T satisﬁes the condition (7.5), then the
scheme (7.6) is just the result of composing the Euler explicit schemes of the systems
associated to the ﬁelds a{k}(k = 1, · · · , n), i.e., we have
1Gτ = Eτ
a{n} ◦· · · ◦Eτ
a{2} ◦Eτ
a{1},
(7.8)
where
Eτ
a{k} = I + τa{k},
k = 1, 2, · · · , n,
I = identity.
(7.9)

460
10. Volume-Preserving Methods for Source-Free Systems
In fact, Eτ
a{k} are the phase ﬂows eτ
a{k}, since a{k}
∗
a{k} = 0 for k = 1, 2, · · · , n,
which is implied by the condition (7.5). According to Theorem 6.3, we then get a 2nd
order explicit revertible volume-preserving scheme, with step transition map
2Gτ = E
τ
2
a{n} ◦· · · ◦E
τ
2
a{2} ◦E
τ
2
a{1} ◦E
τ
2
a{1} ◦E
τ
2
a{2} ◦· · · ◦E
τ
2
a{n}
=
1G
τ
2 ◦1 G
τ
2 = 2gτ.
(7.10)
10.8 Construction of Volume-Preserving Scheme via
Generating Function
Not only symplectic scheme can be constructed via generating function, but volume-
Preserving scheme is also constructed via generating function. A. Thyagaraja and
F.A. Haas[TH85,Sco91]give an important type generating function for volume-preserving
mapping in 3-dimensions. It is however, not complete both in generality and in sys-
tematization. The complete results are given by Z.J. Shang[Sha94a,Sha94b].
10.8.1 Fundamental Theorem
Theorem 8.1. Let α =
5
Aα
Bα
Cα
Dα
6
∈GL(2n), α−1 =
5
Aα
Bα
Cα
Dα
6
. Assume
that g : Rn →Rn, z = g(z) is a differentiable mapping given, in some point z0 ∈
Rn, satisfying transversality condition
Cα
∂g(z)
∂z
+ Dα
 ̸= 0.
(8.1)
Then, in Rn neighborhood W of point w0 = Cαg(z0) + Dαz0 exists a unique differ-
entiable mapping f(w) = fα,g = (f1(w), f2(w), · · · , fn(w)): Wn →Rn such that
z = g(z) satisfying condition

∂f(w)
∂w
Cα −Aα
 =
Bα −∂f(w)
∂w
Dα
 ̸= 0,
(8.2)
such that, mapping z = g(z) can reconstruct in a neighborhood V of the point z = z0
from w = f(w) by the relation
Aαz + Bαz = f(Cαz + Dαz).
(8.3)
Conversely, for any differential mapping f(w) = (f1(w), · · · , fn(w)) : Rn →
Rn, satisfying condition (8.2) at the point w0 ∈Rn, we give a unique differential
mapping in some neighborhood V of the point z0 = Cαf(w)+Dαw0 (8.3). Moreover,
the transversality condition (8.1) is satisﬁed for the mapping g at the point z0 =
Cαf(w) + Dαw0.

10.8 Construction of Volume-Preserving Scheme via Generating Function
461
Remark 8.2. Generally speaking, a volume-preserving mapping f is uniquely deter-
mined by the matrix α ∈GL(2n) and mapping g as above by relation (8.3) determined
by mapping f = fα,g. We called f = fα,g as generating mapping dependent on α, g.
Remark 8.3. We only consider some typical types generating mapping
α(s,s) =
5 In −Ess
Ess
Ess
In −Ess
6
,
1 ≤s ≤n,
(8.4)
where Ess denotes the n × n matrix, of which only the entry at the s-th row and the
s-th column is equal to 1, and all other entries are 0. In this case, (8.2) and (8.3) have
much more simple forms. For example, for α = α(1,1), (8.2) turns into
∂f1
∂w1
=

∂(f2, · · · , fn)
∂(w2, · · · , wn)
 ̸= 0,
(8.5)
and (8.3) turns into
z1 = f1( z1, z2, · · · , zn),
z2 = f2(z1, z2, · · · , zn),
· · ·
zn = fn(z1, z2, · · · , zn).
(8.6)
The same situation also applies for α(s,s).
Remark 8.4. For such a matrix α(1,1), generating mapping f(w) of type α(1,1), there
are n component f(w) = (f1(w), f2(w), · · · , fn(w)), in which n −1 component
f2(w), · · · , fn(w) is linear independent, satisfying condition

∂(f2, · · · , fn)
∂(w2, · · · , wn)
 ̸= 0,
then we can express the ﬁrst component f1 of f by other n −1 component
f1(w1, w2, · · · , wn) = C(w2, · · · , wn) +
- w1
w1,0

∂(f2, · · · , fn)
∂(w2, · · · , wn)
 (ξ, w2, · · · , wn)dξ,
(8.7)
where C is scalar function dependent n −1 variable.
Theorem 8.5. Let α =
 Aα
Bα
Cα
Dα

∈GL(2n) and α−1 =
 Aα
Bα
Cα
Dα

. Sup-
pose |Cα +Dα| ̸= 0 for some M0 ∈GL(2n), then there exists a dependent at t and α
of the diffeomorphism gt
α(M0z) generating mapping, f(w, t) = fα,a(w, t), its phase
ﬂow gt
α satisfying
˙z = a(z),
a(z) = (a1(z), · · · , an(z))T,
z = (z1, · · · , zn)T,
(8.8)

462
10. Volume-Preserving Methods for Source-Free Systems
such that
∂f
∂t =
%
Aα −∂f
∂ω Cα
&
a(Aαf + Bαω),
(8.9)
f(w, 0) = (Aα + Bα)(Cα + Dα)−1ω.
(8.10)
We call (8.9) a Hamilton–Jacobi equation. The proofs of Theorems 8.1 and 8.2
can found in [Sha94b].
Remark 8.6. If α = α(1,1), then relations (8.9) and (8.10) turn into
∂f1
∂t = −a1(w1, f2, · · · , fn) ∂f1
∂w1 ,
(8.11)
∂fk
∂t = ak(w1, f2, · · · , fn) −a1(w1, f2, · · · , fn) ∂fk
∂w1 ,
k = 2, · · · , n, (8.12)
fk(w1, · · · , wn, 0) = wk,
k = 1, 2, · · · , n.
(8.13)
When a is source-free system, i.e.,
div a(z) =
n

k=1
∂ak
∂zk
(z) = 0,
z ∈Rn,
(8.14)
then gt
α is volume-preserving, we get
∂f1
∂w1
(w, t) =

∂(f2, · · · , fn)
∂(w2, · · · , wn)
 (w, t).
(8.15)
From (8.11), (8.13), and (8.15), we get
f1(w, t) = w1 −
- t
0
a1(w1, f2(w, τ), · · · , fn(w, τ1))

∂(f2, · · · , fn)
∂(w2, · · · , wn)
 (w, τ)dτ.
(8.16)
f2, · · · , fn is independently determined by (8.12) and (8.13) (for k = 2, · · · , n) we
call these as generating function type α(1,1) for source-free system (8.8).
Theorem 8.7. Suppose vector ﬁeld a is analytical function of z, then f(w, t) =
fα,a(w, t), is solution of Cauchy problem (8.9) and (8.10), it is expressible as a con-
vergent power series in t for sufﬁciently small |t|, with the recursively determined
coefﬁcients
f(w, t) =
∞

k=0
f (k)(w)tk,
(8.17)
f 0(w) = N0w,
N0 = (Aα + Bα)(Cα + Dα)−1,
(8.18)
f 1(w) = L0a(E0w),
E0 = (Cα + Dα)−1,
L0 = Aα −N0Cα, (8.19)
for k ≥1, we have

10.8 Construction of Volume-Preserving Scheme via Generating Function
463
f (k+1)(w) =−
1
k + 1
∂f (k)(w)
∂w
Cαa(E0w) −
1
k + 1
k

m=1
m

j=1
ip≥1

i1+···+ij=m
1
j!
·∂f (k−m)(w)
∂w
CαDj
α,E0w(Aαf (i1)(ω), · · · , Aαf (ij)(w))
+
1
k + 1
k

m=1

i1+···+im=k
ip⩾1
1
m!AαDm
α,E0w(Aαf (i1)(ω), · · · , Aαf (im)(w)),
(8.20)
where for ξ(k) = (ξ(k)
1 , · · · , ξ(k)
n )T ∈Rn (k = 1, 2, · · · , m), we get
Dm
α,w(ξ(1), · · · , ξ(m)) =
⎡
⎢⎢⎢⎢⎢⎢⎢⎣
n

α1,···,αm=1
∂ma1(w)
∂zα1 · · · ∂zαm
ξ1
α1 · · · ξm
αm
...
n

α1,···,αm=1
∂man(w)
∂zα1 · · · ∂zαm
ξ1
α1 · · · ξm
αm
⎤
⎥⎥⎥⎥⎥⎥⎥⎦
.
(8.21)
Proof. Under the above proposition, if generating function f(w, t) = fα,a(w, t) is
dependent analytically on w and t in some neighborhood Rn for sufﬁcient small t,
then it can be expressed as a power series
f(w, t) =
∞

k=0
f (k)(w)tk.
Differentiating it with respect to w and t, we get
∂f
∂w(w, t) =
∞

k=0
∂f (k)(w)
∂w
tk,
(8.22)
∂f
∂t (w, t) =
∞

k=0
(k + 1)f (k+1)(w)tk.
(8.23)
By (8.10),
f (0)(w) = f(w, 0) = N0w.
This is (8.19). Denote E0 = AαN0 + Bα = (Cα + Dα)−1, then
Aαf(w, t) + Bαw = E0w +
∞

k=1
Aαf (k)(w)tk.
Expanding a(z) at z = E0w, we get

464
10. Volume-Preserving Methods for Source-Free Systems
α(Aαf(w, t) + Bαw) = a
*
E0w +
∞

k=1
Aαf (k)(w)tk
+
= a(E0w) +
∞

k=1
tk
k

m=1

i1+···+im=k
ip⩾1
1
m!Dm
a,E0w(Aαf (i1)(w), · · · , Aαf (im)(w)).
(8.24)
Here, Da,E0 is multilinear operator deﬁned by (8.21).
Substituting (8.22) and (8.24) in the right hand side of Equation (8.9), substituting
(8.23) in the left hand side of (8.9), and then comparing the coefﬁcients of tk on both
sides, we get the recursions (8.18) – (8.20). The proof is completed.
▲
Remark 8.8. Let α = α(1,1), then (8.18) – (8.20) turn into
f (0)(w) = w,
(8.25)
f (1)(w) = "a(w),
"a(w) = (−a1(w), a2(w), · · · , an(w))T,
(8.26)
for k ≥1,
f (k+1)
i
(w)
=
1
k+1 $
a1(w)
∂f(k)
i
(w)
∂w1
+
1
k+1
k−1

m=1
m

j=1

i1+···+ij =m
ip⩾1
n

α1,···,αj =2
1
j !
· ∂f (k−m)
i
(w)
∂w1
∂j "a1(w)
∂wα1 · · · ∂wαj
f (i1)
α1 (w) · · · f
(ij )
αj
(w)
+
1
k + 1
k

m=1

i1+···+im=k
ip⩾1
n

α1,···,αm=2
1
m!
∂m "ai(w)
∂wα1 · · · ∂wαm
f (i1)
α1 (w) · · · f (im)
αm (w),
i = 1, 2, · · · , n.
(8.27)
10.8.2 Construction of Volume-Preserving Schemes
In this subsection, we consider the construction of volume-preserving schemes[Sha94a]
for the source-free system (8.8). By Remark 8.3 of Theorem 8.1, for given time-
dependent scalar functions φ2(w, t), · · · , φn(w, t) : Rn × R →R and C( "w, t) :
Rn−1 × R →R, we can get a time-dependent volume-preserving mapping "g(z, t). If
φ2(w, t), · · · , φn(w, t) approximates the generating functions f2(w, t), · · · , fn(w, t)
of the type α(1,1) of the source-free system (8.8), then suitable choice C( "w, t), "g(w, t)
approximates the phase ﬂow gt
α(z) = g(z, t). Fixing t as a time step, we can get a
difference scheme (volume-preserving schemes) whose transition from one time step
to the next is volume-preserving. By Remark 8.8 of Theorem 8.7, generating functions
f2(w, t), · · · , fn(w, t) can be expressed as power series. So, a natural way to approx-
imate f2(w, t), · · · , fn(w, t) is take the truncation of the series. However, we have to
choose a suitable C( "w, t) in (8.7) to guarantee the accuracy of the scheme.
Assume that
φm
i (w, t) =
m

k=0
f (k)
i
(w)tk,
i = 2, · · · , n
(8.28)

10.8 Construction of Volume-Preserving Scheme via Generating Function
465
and
ψm
1 (w, t) =
m

k=0
f (k)
1
(w)tk.
(8.29)
Let for some ﬁxed value w1,0,
Cm(w2, · · · , wn, t) = ψ(m)
1
(w1,0, w2, · · · , wn, t)
(8.30)
and
φ(m)
1
(w, t) = C(m)(w2, · · · , wn, t)+
- w1
w1,0

∂(φ(m)
2
, · · · , φ(m)
n
)
∂(w2, · · · , wn)
 (ξ, w2, · · · , wn, t)d ξ,
(8.31)
then we have,
Theorem 8.9. Using Theorem 8.5 and Theorem 8.7 for sufﬁciently small τ ≥0
as the time step, deﬁning mapping φ(m)(w, τ) = (φ(m)
1
(w, τ), φ(m)
2
(w, τ), · · · ,
φ(m)
n
(w, τ))T with the components φ(m)
i
(w, τ)(i = 1, 2, · · · , n) given as above for
m = 1, 2, · · · , then the mapping
w −→w = φ(m)(w, τ),
(8.32)
deﬁnes a volume-preserving scheme z = zk →zk+1 = z
⎧
⎨
⎩
zk
1 = φ(m)
1
(zk+1
1
, zk
2, · · · , zk
n, τ),
zk+1
i
= φ(m)
i
(zk+1
1
, zk
2, · · · , zk
n, τ),
i = 2, · · · , n,
(8.33)
of m-th order of accuracy of the source-free system (8.8).
Proof. Since φ(m)
i
(w, 0) = f 0
i (w, 0) = wi (i = 2, · · · , n),

∂(φ(m)
2
, · · · , φ(m)
n
)
∂(w2, · · · , wn)
 (w, 0) = 1.
Therefore, for sufﬁciently small τ and in some neigbourhood of Rn

∂(φ(m)
2
, · · · , φ(m)
n
)
∂(w2, · · · , wn)
 (w, τ) ̸= 0.
By Theorem 8.1, Remark 8.3, Remark 8.4, and Equation (8.31), the relation (8.33)
deﬁnes a time-dependent volume-preserving z = zk →zk+1 = z = "g(z, τ). That is,
(8.33) is a volume-preserving scheme.
Noting that
φ(m)
i
(w, τ) = fi(w, τ) + O(τ m+1),
i = 2, · · · , n,
ψ(m)
1
(w, τ) = f1(w1, τ) + O(τ m+1),

466
10. Volume-Preserving Methods for Source-Free Systems
for sufﬁciently small τ and
f1(w, τ) = f1(w1,0, w2, · · · , wn, τ) +
- w1
w1,0

∂(f2, · · · , fn)
∂(w2, · · · , wn)
 (ξ, w2, · · · , wn)d ξ,
we have from (8.31)
φ(m)
1
(w, τ) = f1(w, τ) + O(τ m+1).
So, φ(m)(w, τ) = (φ(m)
1
(w, τ), · · · , φ(m)
n
(w, τ)) is an m-th order approximant to
f(w, τ) = (f1(w, τ), · · · , fn(w, τ)), the generating function of the type α1,1 of gt
α
and hence the volume-preserving scheme (8.33) is of m-th order of accuracy. The
proof is completed.
▲
Remark 8.10. We note that the volume-preserving scheme z = zk →zk+1 given by
(8.33) is implicit for only one new variable zk+1
1
and explicit for all other new variables
zk+1
i
(i = 2, · · · , n) in terms of the old variables zk
i (i = 2, · · · , n).
Remark 8.11. We can get volume-preserving scheme similar to the above one if we
consider the types α = α(s,s) (2 ≤s ≤n), instead of α = α(1,1).
Example 8.12. First order scheme:
⎧
⎪
⎨
⎪
⎩
zk
1 = φ(1)
1 (zk+1
1
, zk
2, · · · , zk
n, τ),
zk
i = φ(1)
i (zk+1
1
, zk
2, · · · , zk
n, τ),
i = 2, · · · , n,
where
φ(1)
1 (w, τ)
=
−τa1(0, w2, · · · , wn)
+
- w1
0

1 + τ ∂a2
∂w2
τ ∂a2
∂w3
· · ·
τ ∂a2
∂wn
τ ∂a3
∂w2
1 + τ ∂a3
∂w3
· · ·
τ ∂a3
∂wn
...
...
...
τ ∂an
∂w2
τ ∂an
∂w3
· · ·
1 + τ ∂an
∂wn

(ξ, w2, · · · , wn)d ξ,
φ(1)
i
(w, τ)
=
wi + τai(w).
Second order scheme:
⎧
⎪
⎨
⎪
⎩
zk
1 = φ(2)
1 (zk+1
1
, zk
2, · · · , zk
n, τ),
zk+1
i
= φ(2)
i (zk+1
1
, zk
2, · · · , zk
n, τ),
i = 2, · · · , n,

10.9 Some Volume-Preserving Algorithms
467
where
φ(2)
1 (w, τ) = ψ(2)
1 (0, w2, · · · , wn, τ) +
- w1
0

∂(ψ(2)
2 , · · · , ψ(2)
n )
∂(w2, · · · , wn)
 (ξ, w2, · · · , wn)d ξ,
φ(2)
i (w, τ) = ψ(2)
i
(w, τ),
i = 2, · · · , n,
and
ψ(2)(w, τ) =

ψ(2)
1 (w, τ), · · · , ψ(2)
n (w, τ)
T = w + τ"a(w) + 1
2τ 2 ∂"a(w)
∂w1 "a(w),
"a(w) =

−a1(w), a2(w), · · · , an(w)
T.
10.9 Some Volume-Preserving Algorithms
In this section, we analyze and study under conditions a source-free system that has
volume-preserving R–K schemes.
10.9.1 Volume-Preserving R–K Methods
Consider the system
d z
d t = a(z),
where
z =
5
x
y
6
,
x ∈Rp,
y ∈Rq,
a(z) =
 g(y)
f(x)

.
(9.1)
Obviously, this is a source-free system. Its phase ﬂow in Rp+q preserves the phase
volume of (p + q) form
d x1 ∧d x2 ∧· · · ∧d xp ∧d y1 ∧d y2 ∧· · · ∧d yq.
Only R–K and P–R–K are to be discussed. We wish, some of the phase volume is
preserved.
The formula of a general m-th stage P–R–K method with time step h applied to
system (9.1) is read as

468
10. Volume-Preserving Methods for Source-Free Systems
ξi = xn + h
m

j=1
dijg(ηj), ηi = yn + h
m

j=1
cijf(ξj),
1 ≤i ≤m,
xn+1 = xn + h
m

j=1
δjg(ηj),
yn+1 = yn + h
m

j=1
γjf(ξj),
(9.2)
here ξi ∈Rp, ηi ∈Rq (1 ≤i ≤m) are auxiliary vectors used to compute updates
(xn+1, yn+1).
Suppose (9.2) is irreducible, that is, if i ̸= j, then ξi ̸= ξj or ηi ̸= η[DV84]
j
.
We have following Lemma of Y.B. Suris[Sur96].
Lemma 9.1. Let δ = [δ1, δ2, · · · , δm]T, D = (dij), C = (cij), e = [1, 1, · · · , 1]T
be a m-dimensional vector D−= eδT −D, C−= eδT −C. The P–R–K method
preserves phase volume for system (9.1) in arbitrary dimensions, iff
dk1l1cl,k2 · · · dkr−1lr−1clr−1krdkrlrclrk1
= d−
k1l1c−
l1k2 · · · d−
kr−1lr−1c−
lr−1krd−
krlrc−
lrk1.
For arbitrary 1 ≤r ≤m and two arbitrary ordered sets (k1, · · · , kr) and (l1, · · · , lr)
of different natural numbers from (1, m), dij and cij are elements (i, j) with respect
to matrix D−and C−.
Next, for system (9.1), we construct some volume-preserving method by P–R–K
method, using the above criteria.
First we consider volume-preserving by R–K method for linear system.
Linear system of ODE is read as
˙y = My,
(9.3)
where M is n × n matrix with trace M = 0. If det M = 0, the system (9.3) can
degrade to a lower stage, so we assume det M ̸= 0. Now, we assume that M is a
constant matrix. As in R–K method, (A.b.c) applied to system (9.3) takes the form
Yi = yn + h
s

j=1
aijMYj,
yn+1 = yn + h
s

j=1
bjMYj,
(9.4)
where A = (aij)s×s, b = [b1, b2, · · · , bs]T.
Here, we just talk about R–K method and according to Lemma 4.2, we cannot
ﬁnd a general volume-preserving R–K method. So, our hope is to distinguish M into

10.9 Some Volume-Preserving Algorithms
469
different classes and ﬁnd out whether there are volume-preserving R–K method in any
class.
Now, we need the following notations:
A = A ⊗En,
M = diag (M, M, · · · , M) = Es ⊗M,
b = bT ⊗En,
Y = [Y1, Y2, · · · , Ys]T
yn = [yn, yn, · · · , yn]T,
e = e ⊗es,
(9.5)
where En is an n-stage identical matrix and e = [1, 1, · · · , 1]T is a n-dimensional
vector. For R–K method to be volume-preserving, we have equivalent condition:
det ∂yn+1
∂yn
≡1. So, we need to calculate the matrix ∂yn+1
∂yn
≡1. In matrix notations,
R–K method (9.4) reads
yn+1 = yn + hMbY,
Y = (1 −hM A)−1yn.
(9.6)
So,
yn+1
=
(En + (hMb(I −hM A)−1e)yn
=⇒∂yn+1
∂yn
= En + hMb(I −hM A)−1e.
(9.7)
Lemma 9.2. Let A, D be non-degenerate m×m and n×n matrices respectively and
B an m × n and C an n × m matrix, then
det A det (D + CA−1B) = det D det (A + BD−1C).
(9.8)
The proof can be found in any textbook of linear algebra.
By Lemma 9.2, it is easy to get from (9.7)
det
%
∂yn+1
∂yn
&
= det (I −hM A −eMb)
det (I −hM A)
.
Additionally, we deﬁne the notations
A−= (a−
ij),
a−
ij = aij −bj,
N = A ⊗M,
N −= A−⊗M.
(9.9)
In these notations, (9.7) reads as
det
%
∂yn+1
∂yn
&
= det (I −hN −)
det (I −hN) .
(9.10)
Now, if (9.10) is identical to 1, we arrive at the criterion for R–K method (9.4) to be
volume-preserving scheme as
det (λI −N −) = det (λI −N),
∀λ ∈R.
(9.11)

470
10. Volume-Preserving Methods for Source-Free Systems
Theorem 9.3. If dimension of M is odd, then all the R–K methods based on high or-
der quadrature formula such as Gauss–Legendre, Radau, and Lobatto are not volume-
preserving.
Proof. Note that N = A ⊗Mand N −= A−⊗M. If the method is volume-
preserving, then
det N = det(N −) ⇐⇒det(A ⊗M) = det(A−⊗M)
⇐⇒(det A)n(det(M))s = (det(A−))n(det M)s
⇐⇒(det A)n = (det(A−))n
⇐⇒det A = det(A−).
(9.12)
Now, we need the W-transformation proposed by Hairer and Wanner[HW81]. They
introduced a generalized square matrix W deﬁned by
W = (p0(c), p1(c), · · · , pn−1(c)),
(9.13)
where the normalized shifted Legendre polynomials are deﬁned by
pk(x) =
√
2k + 1
k

i=0
(−1)k+i k
i
 k + i
i

xi,
k = 0, 1, · · · , s −1.
(9.14)
For Gauss–Legendre, let X = W −1AW, then
X =
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
1
2
−ξ1
ξ1
0
−ξ2
ξ2
...
...
−ξs−1
ξs−1
0
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
,
(9.15)
where ξk =
1
2
√
4k2 −1 (k = 0, 1, · · · , s −1).
However, X−= W −1A−W, then
X−=
⎡
⎢⎢⎢⎢⎢⎢⎢⎣
−1
2
−ξ1
ξ1
0
−ξ2
ξ2
...
...
−ξs−1
ξs−1
0
⎤
⎥⎥⎥⎥⎥⎥⎥⎦
.
It is easy to verify that det X ̸= det(X−) ⇒det A ̸= det(A−). So, Gauss–Legendre
method is not volume-preserving.
Using the Table 2.1 of Chapter 7, the remaining part of the proof is similar, where
σ ∈R and uσ ̸= 0.
▲

10.9 Some Volume-Preserving Algorithms
471
Theorem 9.4. [QL00] If the dimension of M is even, then the R–K methods based on
high order quadrature formulas such as Gauss–Legendre, Lobatto III A, Lobatto III
B, Lobatto III S, Radau IB, and Radau IIB are volume-preserving, iff
λ(M) = (λ1, λ2, · · · , λ n
2 , −λ1, −λ2, · · · , −λ n
2 ).
Proof. Assume A, B are n×n and m×m matrices respectively, and their eigenvalue
are respectively{λ1, λ2, · · · , λn} and {μ1, μ2, · · · , μm}. Then according to the prop-
erty of Kronecker product, we have λ(A ⊗B) = {λiμj, i = 1, · · · , n; j = 1, · · · , m}.
For R–K methods to be volume-preserving schemes, according to (9.11), N and N −
must have same eigenvalue, that is to say, A ⊗M and A−⊗M must have the
same eigenvalues. For example, for Gauss–Legendre method, λ(A) = λ(X) and
λ(A−) = λ(X−), however, it is obvious that λ(X) = −λ(X−), so according to
the properties of Kronecker product, we can easily verify that A ⊗M and A−⊗M
have the same eigenvalues.
▲
Remark 9.5. If (9.3) is a Hamiltonian system, that is to say, M = J−1S, where
J =

0
In
−In
0

and S′ = S is an n × n invertible matrix, then
λ(M) =

λ1, λ2, · · · , λ n
2 , −λ1, −λ2, · · · , λ n
2

.
So, the R–K method based on high order quadrature formula (Gauss–Legendre,
Lobatto IIIA, Lobatto IIIB, Lobatto IIIS, Radau IB, and Radau IIB) are volume-
preserving. The Theorem 9.4 says that for the methods to preserve volume, the system,
in some sense, must be similar to a Hamiltonian system. If the matrix M similar to
an inﬁnitesimally symplectic matrix, i.e., there is an invertible matrix P, subjected
to P −1MP = JS, ST = S, then we can transform the system to a Hamiltonian
system by a coordinate transformation. In this situation, the volume-preserving R–K
methods and the symplectic R–K methods almost have no difference, that is, if P is a
symplectic matrix, then volume-preserving R–K methods are equivalent to symplec-
tic R–K methods; and in this case, they can be transformed to one another by a linear
transformation.
10.9.2 Volume-Preserving 2-Stage P–R–K Methods
In the case r = 1, if the necessary and sufﬁcient condition of Lemma 9.5 are sat-
isﬁed, then a 2-stage P–R–K method is volume-preserving. This condition is the
same condition of symplecity on the class of separable Hamiltonian system. Thus
for system (9.3), all 2-stage P–R–K methods proposed in[Sun95] are volume-preserving
algorithms[QL00].
Example 9.6. 3th order Radau IA-IA method

472
10. Volume-Preserving Methods for Source-Free Systems
0
1
4
−1
4
2
3
1
4
5
12
1
4
3
4
0
0
0
2
3
1
3
1
3
1
4
3
4
Example 9.7. 3th order Radau IIA-IIA method
1
3
5
12
−1
12
1
3
4
1
4
3
4
1
4
1
3
1
3
0
1
1
0
3
4
1
4
Example 9.8. 2nd order Lobatto IIIC-IIIC method
0
1
2
−1
2
1
1
2
1
2
1
2
1
2
0
0
0
1
1
0
1
2
1
2
Example 9.9. 4th order Gauss IA-IA method
1
2 −
√
3
6
1 + 2σ
4
1 −2σ
4
−
√
3
6
1
2 +
√
3
6
1 −2σ
4
+
√
3
6
1 + 2σ
4
1
2
1
2
1
2 −
√
3
6
1 −2σ
4
1 + 2σ
4
−
√
3
6
1
2 +
√
3
6
1 + 2σ
4
+
√
3
6
1 −2σ
4
1
2
1
2

10.9 Some Volume-Preserving Algorithms
473
10.9.3 Some Generalizations
Method in[Sur96] can be applied to the extension of following system:
˙x = g(y),
˙y = h(z),
˙z = f(x),
x, y, z ∈RP .
(9.16)
For this system, we consider multi-stage P–R–K method
ξi = xn + h
m

j=1
dijg(ηj), ηi = yn + h
m

j=1
cijh(wj), wj = zn + h
m

j=1
eijf(ξj),
(9.17)
xn+1 = xn+h
m

j=1
αjg(ηj), yn+1 = yn+h
m

j=1
βjh(wj), zn+1 = zn+h
m

j=1
γj(ξj).
Theorem 9.10. A multi-stage P–R–K method is volume-preserving for a system type
(9.17), iff
dk1l1cl1m1em1k2dk2l2cl2m2em2k3 · · · dkrlrclrmremrkr
= d−
k1l1c−
l1m1e−
m1k2d−
k2l2c−
l2m2e−
m2k3 · · · d−
krlrc−
lrmre−
mrkr
(9.18)
for arbitrary 1 ≤r ≤m and three arbitrary ordered sets (k1, · · · , kr), (l1, · · · , lr),
and (m1, · · · , mr) of different natural number form [1, · · · , m], here dij, cij, eij, d−
ij,
c−
ij, e−
ij are deﬁned by Lemma 9.5.
Example 9.11. A multi-stage P–R–K method
0
1
2
−1
2
1
1
2
1
2
1
2
1
2
0
0
0
1
1
0
1
2
1
2
a
a
0
b + c
b
c
b
2c
Suitably choose a, b, c, as method can get global truncation error with order O(h2).
Remark 9.12. Dimension of x, y, z may be different.
Remark 9.13. Theorem 9.10 can be extended with no difﬁculty to the following sys-
tem:
˙x1 = f2(x2)
˙x2 = f3(x4),
· · · ,
˙xn = f1(x1).
(9.19)

474
10. Volume-Preserving Methods for Source-Free Systems
10.9.4 Some Explanations
We usually state that symplectic method is volume-preserving scheme. But this par-
lance is somewhat irrelevancy because symplectic scheme (satisfying symplectic con-
dition), true only in this case, that it applied to Hamiltonian system. For P–R–K
method (dij, δi, cij, γj), if it satisﬁes
γidij + δicji −γiδj = 0,
we can say this integrator is symplectic. If system is not Hamiltonian, we cannot say
that this P–R–K method is symplectic. The main problem is that we say a scheme
is symplectic because it preserves symplectic structure for a given system. Therefore,
only Hamiltonian system possesses symplectic structure. Consequently, we cannot say
“volume-preserving P–R–K methods form a subset of symplectic ones”.
Until now, we gave some criteria for volume-preserving by R–K and P–R–K
methods. In fact, it is almost impossible based on these criteria to construct volume-
preserving algorithm with high order accuracy. Indeed, we even cannot predict that
there exists schemes which satisﬁed those criteria. We are too far to resolve these
problems.
It should be noted that in the above discussion, we always suppose system is not
reducible. In other words, det M ̸= 0. But in practice, some systems are reducible, for
example
˙x = cy −bz,
˙y = az −cx,
a, b, c ∈R.
˙z = bx −ay,
In fact, for this system, centered Euler scheme is volume-preserving. Furthermore,
LobattoIIIA, LobattoIIIB, LobattoIIIS, RadauIB, RadauIIB etc. are also volume-
preserving. With detailed analysis of the process in Subsection 10.9.2, it is easy to
get the following[QL00].
Theorem 9.14. If the dimension of M is odd, then the R–K methods based on high
order quadrature formulae, such as LobattoIIIA, LobattoIIIB, LobattoIIIS, RadauI,
RadauIIB etc., are volume-preserving, iff
λ(M) =

λ1, λ2, · · · , λ n
2 , 0, −λ1, −λ2, −· · · , −λ n
2

.
We also ﬁnd that in Theorem 9.4, det M ̸= 0 is not necessary.
As for nonlinear systems, we cannot give some satisfactory results. A nonlinear
system
˙y = f(y),
t ∈R, y ∈Rn,
is said to be source-free if divf =
n

i=1
∂fi(y)
∂yi
= 0. Such system preserves the phase
volume on the phase Rn. For these systems, we only point out the centered Euler

10.9 Some Volume-Preserving Algorithms
475
schemes is volume-preserving iff the Jacobian ∂fi
∂yi = M is, in some sense, similar to
an inﬁnitesimally symplectic matrix. That is, the eigenvalues of M can be speciﬁed as
λ(M) =

λ1, λ2, · · · , λ n
2 , −λ1, −λ2, −· · · , −λ n
2

,
or
λ(M) =

λ1, λ2, · · · , λ n
2 , 0, −λ1, −λ2, −· · · , −λ n
2

.

Bibliography
[DV84] K. Dekker and J.G. Verwer: Stability of Runge–Kutta Methods for Stiff Initial Value
Problems. Elesevier Science Pub. B. V., North-Holland, Amsterdam, (1984).
[FS95] K. Feng and Z. J. Shang: Volume-preserving algorithms for source-free dynamical
systems. Numer. Math., 71:451–463, (1995).
[FW94] K. Feng and D.L. Wang: Dynamical systems and geometric construction of algo-
rithms. In Z. C. Shi and C. C. Yang, editors, Computational Mathematics in China, Con-
temporary Mathematics of AMS, Vol. 163, pages 1–32. AMS, (1994).
[HW81] E. Hairer and G. Wanner: Algebraically stable and implementable Runge–Kutta meth-
ods of high order. SIAM J. Numer. Anal., 18:1098–1108, (1981).
[MQ04] R.I. McLachlan and G.R.W. Quispel: Explicit geometric integration of polynomial
vector ﬁelds. BIT, 44:513–538, (2004).
[QD97] G. R. W. Quispel and C. P. Dyt: Solving ODE’s numerically while preserving sym-
metries, Hamiltonian structure, phase space volume, or ﬁrst integrals. In A. Sydow, editor,
Proceedings of the 15th IMACS World Congress, pages 601–607. Wissenschaft & Technik,
Berlin, (1997).
[QD98] G. R. W. Quispel and C. P. Dyt:
Volume-preserving integrators have linear error
growth. Physics Letters A, 202:25–30, (1998).
[QL00] M. Z. Qin and H. W. Li: Volume preserving R–K methods for linear systems. Acta
Applicandae Mathematicae, 16:430–434, (2000).
[QM03] G. R. W. Quispel and D. I. McLaren: Explicit volume-preserving and symplectic
integrators for trigonometric polynomial ﬂows. J. of Comp. Phys., 186(1):308–316, (2003).
[Qui95] G. R. W. Quispel:
Volume-preserving integrators.
Physics Letters A, 206:26–30,
(1995).
[QZ92] M. Z. Qin and W. J. Zhu: Construction of higher order symplectic schemes by com-
position. Computing, 47:309–321, (1992).
[QZ93] M. Z. Qin and W. J. Zhu: Volume-preserving schemes and numerical experiments.
Computers Math. Applic., 26:33–42, (1993).
[Sco91] C. Scovel: Symplectic numerical integration of Hamiltonian systems. In T. Ratiu,
editor, The Geometry of Hamiltonian Systems, pages 463–496. Springer, New York, (1991).
[Sha94a] Z Shang: Construction of volume-preserving difference schemes for source-free sys-
tems via generating functions. J. Comput. Math., 12:265–272, (1994).
[Sha94b] Z. Shang:
Generating functions for volume-preserving mappings and Hamilton–
Jacobi equations for source-free dynamical systems. Science in China (series A), 37:1172–
1188, (1994).
[Sun95] G. Sun: Construction of high order symplectic Partitioned–Runge–Kutta methods. J.
Comput. Math., 13(1):40–50, (1995).
[Sur96] Y. B. Suris: Partitioned–Runge–Kutta methods a phase volume preserving integrators.
Physics Letters A, 220:63–69, (1996).
[TH85] A. Thyagaraja and F.A. Haas: Representation of volume-preserving maps induced by
solenoidal vector ﬁelds. Phys. Fluids, 28:1005, (1985).
[Wey40] H. Weyl: The method of orthogonal projection in potential theory. Duke Math. J.,
7:411–444, (1940).

Chapter 11.
Contact Algorithms for Contact Dynamical
Systems
An odd-dimensional manifold cannot admit a symplectic structure. The analogue of
symplectic structure for odd-dimensional manifolds is a little less symmetric, but is
also a very interesting structure – the contact structure. In this chapter, we apply the
ideas of preserving Lie group and Lie algebra structure of dynamical systems in con-
structing symplectic algorithms for Hamiltonian systems to the study of numerical
algorithms for contact dynamical systems and present so-called contact algorithms,
i.e., algorithms preserving contact structure, for solving numerically contact systems.
11.1 Contact Structure
The source of contact structures are manifolds of contact element of conﬁguration
spaces. It is also of basic importance in physical and engineering sciences. Contact
geometry has – as does symplectic geometry – broad applications in physics, e.g.
geometrical optics, classical mechanics, thermodynamics, geometric quantization, and
applied mathematics such as control theory.
11.1.1 Basic Concepts of Contact Geometry
Contact geometry[Arn89,Arn88] is the study of a geometric structure on smooth manifolds
given by a hyperplane distribution in the tangent bundle and speciﬁed by a one-form,
both of which satisfy a “maximum non-degeneracy” condition called “complete non-
integrability”.
The integration of ﬁrst-order partial differential equations is reduced to the in-
tegration of a system of ordinary differential equations, the so-called characteristic
equations. The basic of this reduction is a simple geometric analysis of the formula-
tion of curves. Let M be a smooth manifold and let V be a direction ﬁeld on M.
Deﬁnition 1.1. N ⊂M is called an integral surface of V if the tangent plane of N
contains the direction of V at every point (Fig. 1.1).
Let Γ be a k-dimensional submanifold in an n-dimensional manifold M (Fig. 1.2),
Γ is called a hypersurface if k = n −1.
The Cauchy problem for the direction ﬁeld v with initial manifold Γ is the prob-
lem of ﬁnding a (k + 1)-dimensional integral submanifold of v containing the initial
submanifold Γ.

478
11. Contact Algorithms for Contact Dynamical Systems
6
-
/
.
....................................................
.................................................
..............................................
............................................
.........................................
.
.....................................................................................................................................................................................
.
....................................................
.......................................................
...........................................................
..............................................................
.................................................................
.
.................
....................
......................
........................
...........................
.............................
................................
..................................
z
y
x
M
O
V
N
.
.............................................
.
.............................................
.
.......................................................
.
...........................................
6
-
/
....... .........
............
...............
...................
......................
.........................
............................
................................
...................................
.
................................
.............................
...........................
.........................
......................
....................
..................
................
..............
z
y
x
M
O
V
N
Fig. 1.1.
Meaning of deﬁnition
6
-
/
.
.................................
................................
..............................
.............................
...........................
..........................
..........................
.
..................................
...............................
............................
.........................
......................
...................
...............
............
.........
......
.
....................................................
..................................................
................................................
..............................................
............................................
..........................................
.
......................................................
......................................................
......................................................
.....................................................
.....................................................
z
y
x
M
V k+1
V
Γ k
Fig. 1.2.
Integral surface with initial manifold of Γ
Every point in n-dimensional space existence an (n −1)-dimensional hyperplane,
codim = 1 ﬁeld of hyperplane, this means ﬁeld of tangent hyperplane can be locally
described by 1-form, and α =
n

i=1
αidxi, and
n

i=1
α2
i (x) ̸= 0,
∀x ∈Rn.
Hyperplane in Fig. 1.3 is null space of 1-form α. Relation between hyperplane and
its 1-form is not 1- to -1 correspondence. They may be different up to multiplication
by a non zero constant. This multiplicator is dependent of point.
We consider what a ﬁled of hyperplane looks like in general in a neighborhood of
a point in an n-dimensional manifold. For example, let n = 2. Then the manifold is
a surface and ﬁeld of hyperplane is a ﬁeld of straight line. Such a ﬁeld in a neighbor-
hood of a point is always constructed very simply, namely, as a ﬁeld of tangent to a
family of parallel lines in a plane. More precisely, one of the basic results of the local
theory of ODEs is that it is possible to change any smooth ﬁeld of tangent lines on a
manifold into a ﬁeld of tangents to family of straight lines in Euclidean space by using
a diffeomorphism in a sufﬁciently small neighborhood of any point of the manifold.

11.1 Contact Structure
479
6
-
/
.
............................................
..........................................
........................................
......................................
.....................................
...................................
.
.........................................................................................................................................................................................
.
.....................................................
.........................................................
............................................................
...............................................................
...................................................................
. ................
..................
...................
.....................
.......................
.........................
...........................
.............................
...............................
z
y
x
6
Fig. 1.3.
Hyperplane
If n > 2, then a hyperplane is not a line. For example, if n = 3, most ﬁeld of
2-dimensional tangent planes in ordinary 3-dimensional space cannot be diffeomor-
phically mapped onto a ﬁeld of parallel planes. The reason is that there exists ﬁelds of
tangent planes for which it is impossible to ﬁnd integral surfaces, i.e., surface which
have the prescribed tangent plane at each point.
A 1-form in 3-dimensional can be written in following standard form
α = xd y + d z.
Every tangent hyperplane in point x, which is denoted by Πx, have:
[ηx, ηy, ηz]
⎡
⎢⎣
0
x
1
⎤
⎥⎦= 0,
and [0, x, 1] not all equal to zero, it is deﬁned as a 2-dimensional ﬁeld of hyperplane.
When x = 0,
⎡
⎢⎣
0
0
1
⎤
⎥⎦
T ⎡
⎢⎣
ηx
ηy
0
⎤
⎥⎦= 0.
Each point with a hyperplane intersecting wall deﬁnes a direction ﬁeld, see Fig. 1.4
and 1.5.
Next, we prove that in R3 space, there does not exist an integral surface which
can be given by the 1-form α = xd y + d z, where x, y is horizontal coordinate, z is
vertical coordinate, see Fig. 1.6.
Consider a pair of vectors emanating from the origin (0,0,0) and lying in the hori-
zontal plane of our coordinate systems; another integral curve from (0,0,0) to (0,1,0),
and then from (0,1,0) to (1,1,0), and another integral curve from (0,0,0) to (1,0,0),
and then from (1,0,0) to (1,1, −1). As a result, these two curves cannot close up. The
difference in the heights of these points is 1, this difference can be considered as a
measure of the nonintegrability of the ﬁeld.
We have four direction ﬁelds from the origin point 0 to walls of east, south, west,
and north, respectively, describing by Fig. 1.5.

480
11. Contact Algorithms for Contact Dynamical Systems
Fig. 1.4.
Deﬁnes the ﬁeld of 2n-dimensional plane α = 0 in R2n+1
-
-
-
-
:
:
:
:
:
:
~
~
~
~
North
West
East
South
Fig. 1.5.
Direction ﬁelds in each wall
11.1.2 Contact Structure
A contact element to an n-dimensional smooth manifold at some point is an (n −1)-
dimensional plane tangent to the manifold at that point, i.e., an (n −1)-dimensional
subspace of the n-dimensional tangent space at that point. At the n-dimensional space
for each point there is a n −1 dimensional hyperplane, dimensions of this hyperplane
ﬁeld is n −1. We note ﬁrst that a ﬁeld of hyperplanes can be given locally by a
differential 1-form: a plane in the tangent space gives a 1-form up to multiplication
by a non zero constant. We choose this constant so that the value of the form on
vertical basic vector is equal to 1. The Hyperplanes of the ﬁeld are null space of the
1-form[Arn89,Arn88].
Deﬁnition 1.2. A ﬁeld of hyperplanes is said to be nondegenerate at a point if the
rank of the 2-form dα|ω=0 in the plane of the ﬁeld passing through this point is equal
to the dimension of the plane.
Deﬁnition 1.3. A differential 1-form α which is nowhere equal to the zero form on
a manifold M is called a contact form if the exterior derivative dα of α deﬁnes a
nondegenerate exterior 2-form in every plane α = 0.

11.1 Contact Structure
481
Fig. 1.6.
Integral curves constructed for a non-integrable ﬁeld of planes
Example 1.4. Consider the space R2n+1 with the contact structure by the 1-form
α = d u + p d q. Where q = (q1, · · · , qn), u, p = (p1, · · · , pn), α is not equal to zero
form at any point in R2n+1, and consequently deﬁnes the ﬁeld of 2n-dimensional
planes α = 0 in R2n+1.
Example 1.5. The form constructed in Example 1.4 is a contact form, the exterior
derivatives of the form α is equal to
d α|α=0 = d q1 ∧d p1 + · · · + d qn ∧d pn.
In the plane α = 0, (q1, · · · , qn; p1, · · · , pn) may serve as coordinate.
The matrix of the form ω = dα|α=0 has the form
 O
−I
I
O

, where I is the
identity matrix of order n. The determinant of this matrix is equal to 1. Consequently,
the 2-form ω is nondegenerate. In other words, the rank of this form is 2n, so our ﬁeld
is nondegenerate at the origin and thus also in a neighborhood of the origin (in fact,
this ﬁeld of planes is nondegenerate at all points of the space).
Deﬁnition 1.6. A contact structure on the manifold M is a ﬁeld of tangent plane
which are given locally as the set of zeros of a contact 1-form. The hyperplanes of
the ﬁeld are called contact hyperplanes. We can denote by Πx the contact hyperplane
at the point x. Putting brieﬂy, a contact structure on a manifold is a nondegenerate
ﬁeld of tangent hyperplane.
.
Deﬁnition 1.7. A ﬁeld of planes is called nondegenerated on a manifold if it is non-
degenerate at every point of the manifold.
It should be noted that on the even-dimensional manifold there cannot be a non-
degenerate ﬁeld of hyperplanes, on such a manifold a hyperplane is odd-dimensional,
and the rank of every skew-symmetric bilinear form on an odd-dimensional space is
less than the dimension of the space. Nondegenerate ﬁeld of hyperplane do exist on
odd-dimensional manifold.

482
11. Contact Algorithms for Contact Dynamical Systems
Deﬁnition 1.8. A hyperplane (dimension n −1) tangent to a manifold at some point
is called a contact element, and this point is called the point of contact.
The set of all contact element of an n-dimensional manifold has the structure of
a smooth manifold of dimension 2n −1. The manifold of all contact elements of an
n-dimensional manifold is a ﬁber bundle whose base is our manifold and whose ﬁber
is (n −1)-dimensional projective space.
Theorem 1.9. The bundle of contact element is the projectivization of the cotangent
bundle: it can be obtained from the cotangent bundle by changing every cotangent
n-dimensional vector space into on (n −1)-dimensional projective space (a point of
which is a line passing through the origin in the cotangent space).
Proof. A contact element is given by a 1-form on the tangent space, for which this
element is not zero, and it is determined up to multiplication by a non zero number.
But a form on the tangent space is a vector of the cotangent space. Therefore, a non
zero vector of the cotangent space, determined up to a multiplication by a non zero
number, is a non zero vector of the cotangent space, determined up to a multiplication
by a non zero number, i.e., a point of the projectivized cotangent space.
▲
In this chapter, we simply consider the Euclidean space R2n+1 of 2n+1 dimensions
as our basic manifold with the contact structure given by the normal form
α =
n

i=1
xid yi + d z = xd y + d z = (0, xT, 1)
⎡
⎢⎢⎣
d x
d y
d z
⎤
⎥⎥⎦,
(1.1)
here we have used 3-symbol notation to denote the coordinates and vectors on R2n+1
x = (x1, · · · , xn)T,
y = (y1, · · · , yn)T,
z = (z).
(1.2)
A contact dynamical system on R2n+1 is governed by a contact vector ﬁeld f =
(aT, bT, c) : R2n+1 →R2n+1 through equations
˙x = a(x, y, z),
˙y = b(x, y, z),
˙z = c(x, y, z),
· =: d
d t,
(1.3)
where the contactivity condition of the vector ﬁeld f is
Lfα = λfα,
(1.4)
with some function λf :
R2n+1 →R, called the multiplier of f. In (1.4), Lfα
denotes the Lie derivation of α with respect to f and is usually calculated by the
formula (see Chapter 1 of book)[Arn88]
Lfα = ifd α + d ifα.
(1.5)
It is easy to show from (1.4) and (1.5) that to any contact vector ﬁeld f on R2n+1,
there corresponds a function K(x, y, z), called contact Hamiltonian, such that

11.1 Contact Structure
483
a = −Ky + Kzx,
b = Kx,
c = K −xTKx =: Ke.
(1.6)
In fact, (1.6) represents the general form of a contact vector ﬁeld. Its multiplier, de-
noted as λf from now, is equal to Kz.
Deﬁnition 1.10. A contact transformation g is a diffeomorphism on R2n+1
g :
⎛
⎜
⎜
⎝
x
y
z
⎞
⎟
⎟
⎠
−→
⎛
⎜
⎜
⎝
x(x, y, z)
y(x, y, z)
z(x, y, z)
⎞
⎟
⎟
⎠
conformally preserving the contact structure, i.e., g∗α = μgα, that means
n

i=1
xid yi + d z = μg
* n

i=1
xid yi + d z
+
,
(1.7)
for some everywhere non-vanishing function μg : R2n+1 →R, called the multiplier
of g.
The explicit expression of (1.7) is
(0, xT, 1)
⎡
⎢⎢⎣
xx
xy
xz
yx
yy
yz
zx
zy
zz
⎤
⎥⎥⎦= μg(0, xT, 1).
A fundamental fact is that the phase ﬂow gt
K of a contact dynamical system associated
with a contact Hamiltonian K : R2n+1 →R is a one parameter (local) group of
contact transformations on R2n+1, i.e., gt
K satisﬁes
g0
K = identity map on R2n+1;
(1.8)
gt+s
K
= gt
K ◦gs
K,
∀t, s ∈R;
(1.9)
(gt
K)∗α = μgt
Kα,
(1.10)
for some everywhere non-vanishing function μgt
K : R2n+1 →R. Moreover, we have
the following relation between μG∗
k and the Hamiltonian K:
μgt
K = exp
- t
0
(Kz ◦gs
K)d s.
(1.11)
For general contact systems, condition (1.10) is stringent for algorithmic approx-
imations to phase ﬂows because only the phase ﬂows themselves satisfy it. We will
construct algorithms for contact systems such that the corresponding algorithmic ap-
proximations to the phase ﬂows satisfy the condition (1.10), of course, probably, with
different, but everywhere non-vanishing, multipliers from μgt
K. We call such algo-
rithms as contact ones.

484
11. Contact Algorithms for Contact Dynamical Systems
11.2 Contactization and Symplectization
There is a well known correspondence between contact geometry on R2n+1 and conic
(or homogeneous) symplectic geometry on R2n+2. To establish this correspondence,
we introduce two spaces R2n+2
+
and R+ × R2n+1.
a.
We use the 4-symbol notation for the coordinates on R2n+2
⎡
⎢⎢⎢⎣
p0
p1
q0
q1
⎤
⎥⎥⎥⎦,
p0 = (p0),
q0 = (q0),
p1 =
⎡
⎢⎢⎢⎣
p11
...
p1n
⎤
⎥⎥⎥⎦,
q1 =
⎡
⎢⎢⎣
q11
...
q1n
⎤
⎥⎥⎦.
(2.1)
Consider
R2n+2
+
=
(
(p0, p1, q0, q1) ∈R2n+2 | p0 > 0
)
(2.2)
as a conic symplectic space with the standard symplectic form
ω = dp0 ∧dq0 + dp1 ∧dq1.
(2.3)
Deﬁnition 2.1. Function φ : R2n+2
+
→R is called a conic function if it satisﬁes
φ(p0, p1, q0, q1) = p0φ

1, p1
p0
, q0, q1

,
∀p0 > 0.
(2.4)
So, a conic function on R2n+2 depends essentially only 2n + 1 variables.
Deﬁnition 2.2. F : R2n+2
+
→R2n+2
+
is called a conic map if
F ◦Tλ = Tλ ◦F,
∀λ > 0,
(2.5)
where Tλ is the linear transformation on R2n+2
Tλ
5 p
q
6
=
5 λp
q
6
,
p =
5 p0
p1
6
,
q =
5 q0
q1
6
.
(2.6)
The conic condition (2.5) for the mapping F : (p0, p1, q0, q1) →(P0, P1, Q0, Q1)
can be expressed as follows:
P0(p0, p1, q0, q1) = p0P0

1, p1
p0 , q0, q1

> 0,
P1(p0, p1, q0, q1) = p0P1

1, p1
p0 , q0, q1

,
Q0(p0, p1, q0, q1) = Q0

1, p1
p0 , q0, q1

,
Q1(p0, p1, q0, q1) = Q1

1, p1
p0 , q0, q1

,
∀p0 > 0.
(2.7)

11.2 Contactization and Symplectization
485
So, a conic map is essentially depending only on 2n+2 functions in 2n+1 variables.
It should be noted that, in some cases, we also consider conic functions and conic
maps deﬁned on the whole Eucildean space. The following lemma gives a criterion of
a conic symplectic map.
Lemma 2.3. F : (p0, p1, q0, q1) →(P0, P1, Q0, Q1) is a conic symplectic map if and
only if (0, 0, P T
0 , P T
1 )F∗−(0, 0, pT
0 , pT
1 ) = 0, where F∗is the Jacobi matrix of F at
the point (p0, p1, q0, q1).
Proof. For F : (p0, p1, q0, q1) →(P0, P1, Q0, Q1), the condition
(0, 0, P T
0 , P T
1 )F∗−(0, 0, pT
0 , pT
1 ) = 0,
(2.8)
is equivalent to the condition
P0d Q0 + P1d Q1 = p0d q0 + p1d q1,
or
Pd Q = pd q,
(2.9)
where P = (P0, P1), Q = (Q0, Q1), p = (p0, p1), q = (q0, q1). Hence in matrix
form, it can be written as
QT
p · P = 0,
QT
q · P = p.
(2.10)
Notice that a function f(x1, x2, · · · , xn) is homogeneous of degree k, i.e.,
f(λx1, λx2, · · · , λxn) = λkf(x1, x2, · · · , xn),
if and only if

xifxi(x1, x2, · · · , xn) = kf(x1, x2, · · · , xn).
Therefore, the condition (2.7) is equivalent to
Pp(p, q) · p = P(p, q),
Qp(p, q) = 0.
(2.11)
If F is conic symplectic, then
QT
p Pp −P T
p Qp = O,
QT
q Pq −P T
q Qq = O,
QT
q Pp −P T
q Qp = I.
(2.12)
Combining with (2.11), we get
p = QT
q Ppp −P T
q Qpp = QT
q P, O = QT
p Ppp −P T
p Qpp = QT
p P.
(2.13)
This proves the “only if” part.
Conversely, if F satisﬁes the condition (2.8), then it satisﬁes (2.9), which means
that it is symplectic. We know that if a matrix is symplectic, then its transpose is also
symplectic. Therefore,
PqP T
p −PpP T
q = O,
QqQT
p −QpQT
q = O,
PpQT
q −PqQT
p = I.
(2.14)

486
11. Contact Algorithms for Contact Dynamical Systems
Combining with (2.10), we get
P = PpQT
q P −PqQT
p P = Ppp,
0 = QqQT
p P −QpQT
q P = Qqp.
(2.15)
This means that F is conic. This ﬁnishes the proof.
▲
b.
Consider R+ × R2n+1 as the product of the positive real space R+ and the
contact space R2n+1. We use (w, x, y, z) to denote the coordinates of R+ × R2n+1
with w > 0 and with x, y, z as before.
Deﬁnition 2.4. A map G: R+ × R2n+1 →R+ × R2n+1 is called a positive product
map if it is composed by a map g : R2n+1 →R2n+1 and a positive function γ :
R2n+1 →R+ in the form
⎡
⎢⎢⎢⎣
w
x
y
z
⎤
⎥⎥⎥⎦−→
⎡
⎢⎢⎢⎣
W
X
Y
Z
⎤
⎥⎥⎥⎦,
W = w γ(x, y, z),
(X, Y, Z) = g(x, y, z).
(2.16)
We denote γ ⊗g the positive product map composed of map g and function γ.
c.
Deﬁne mapping S : R+ × R2n+1 →R2n+2
+
⎡
⎢⎢⎢⎣
w
x
y
z
⎤
⎥⎥⎥⎦−→
⎡
⎢⎢⎢⎣
p0 = w
p1 = wx
q0 = z
q1 = y
⎤
⎥⎥⎥⎦.
(2.17)
Then the inverse S−1 : R2n+2
+
→R+ × R2n+1 is given by
⎡
⎢⎢⎢⎣
p0
p1
q0
q1
⎤
⎥⎥⎥⎦−→
⎡
⎢⎢⎢⎢⎣
w = p0
x = p1
p0
y = q1
z = q0
⎤
⎥⎥⎥⎥⎦
,
p0 ̸= 0.
(2.18)
Lemma 2.5. [Fen93b,Fen95] Given a transformation F : (p0, p1, q0, q1) →(P0, P1, Q0,
Q1) on R2n+2
+
and let G = S−1 ◦F ◦S. Then we have:
1◦
F is a conic map on R2n+2
+
if and only if G is a positive product map on
R+ × R2n+1; in this case, if we write G = γ ⊗g, then
γ(x, y, z) = P0(1, x, z, y),
(2.19)
and g : (x, y, z) →(X, Y, Z) is given by

11.2 Contactization and Symplectization
487
X = P1(1, x, z, y)
P0(1, x, z, y),
Y = Q1(1, x, z, y),
Z = Q0(1, x, z, y).
(2.20)
2◦
F is a conic symplectic map if and only if G is a positive product map, say
γ ⊗g, on R+ × R2n+1 with g also a contact map on R2n+1. Moreover, in this case,
the multiplier of the contact map g is just equal to γ−1 = P −1
0
(1, x, z, y).
Proof. The conclusion 1◦is easily proved by some simple calculations. Below we
devote to the proof of 2◦. Let F send (p0, p1, q0, q1) →(P0, P1, Q0, Q1), G send
(w, x, y, z) →(W, X, Y, Z). Then by using the conclusion 1◦, we have
P0 ◦S = wP0(1, x, z, y) = wγ, P1 ◦S = wP1(1, x, z, y) = wγX(x, y, z),
S∗=
⎡
⎢⎢⎢⎢⎢⎣
1
0
0
0
x
wIn
0
0
0
0
0
1
0
0
In
0
⎤
⎥⎥⎥⎥⎥⎦
,
G∗= ∂(W, X, Y, Z)
∂(w, x, y, z)
=
⎡
⎢⎢⎢⎣
γ
wγx
wγy
wγz
0
0
g∗
0
⎤
⎥⎥⎥⎦,
S∗◦G =
⎡
⎢⎢⎢⎣
1
0
0
0
X
WIn
0
0
0
0
0
1
0
0
In
0
⎤
⎥⎥⎥⎦,
and compute

((0, 0, P T
0 , P T
1 )F∗−(0, 0, pT
0 , pT
1 )) ◦S

S∗
=

(0, 0, P T
0 , P T
1 ) ◦S

(F∗◦S)S∗−

(0, 0, pT
0 , pT
1 ) ◦S

S∗
= (0, 0, wγ, wγXT)(F∗◦S)S∗−(0, 0, w, wxT)S∗
= (0, 0, wγ, wγXT)(S∗◦G)G∗−(0, 0, w, wxT)S∗
= wγ

0, (0, XT, 1)g∗

−wγ

0, γ−1(0, xT, 1)

.
Noting that S is a diffeomorphism, S∗is non-singular, w > 0, γ > 0, we obtain
(0, 0, P T
0 , P T
1 )F∗−(0, 0, pT
0 , pT
1 ) ≡0 ⇐⇒(0, XT, 1)g∗−γ−1(0, xT, 1) ≡0,
which proves the conclusion 2◦.
▲
Lemma 2.5 establishes correspondences between conic symplectic space and con-
tact space and between conic symplectic maps and contact maps. We call the transform
from F to G = S−1 ◦F ◦S = γ ⊗g contactization of conic symplectic maps, the
transform from G = γ ⊗g to F = S ◦GS−1 symplectization of contact maps and
call the transform S : R+ × R2n+1 →R2n+1
+
symplectization of contact space, and
the transform C = S−1 : R2n+2
+
→R+ × R2n+1 contactization of conic symplectic
space.

488
11. Contact Algorithms for Contact Dynamical Systems
11.3 Contact Generating Functions for Contact Maps
With the preliminaries of the last section, it is natural to derive contact generating func-
tion theory for contact maps from the well known symplectic analog[Fen93b,Fen95,Shu93].
The following two lemmas can be proved easily[Fen95].
Lemma 3.1. Hamiltonian φ : R2n+2 →R is a conic function if only if the associated
Hamiltonian vector ﬁeld aφ = J∇φ is conic, i.e., a(Tλz) = Tλa(z),
λ ̸= 0, z ∈
R2n+2, where J =
 
O
−In+1
In+1
O
!
.
Lemma 3.2. Linear map
5
p
q
6
→C
5
p
q
6
is a conic transformation on R2n+2,
i.e., C ◦Tλ = Tλ ◦C, if and only if the matrix C has the diagonal form C =
5
C0
O
O
C1
6
with (n + 1) × (n + 1) matrix C0 and C1.
Noting that the matrix in gl(2n + 2)
C = 1
2(I + JB),
B = BT ∈Sm(2n + 2),
(3.1)
establishes a 1-1 correspondence between near-zero Hamiltonian vector ﬁelds z →
a(z) ≡J∇φ(z) and near-identity symplectic maps z →g(z) via generating relation
g(z) −z = J∇φ(Cg(z) + (I −C)z),
(3.2)
and combining Lemma 3.1 and Lemma 3.2, we ﬁnd that matrix
C =
5 C0
O
O
I −CT
0
6
,
C0 ∈gl(n + 1),
(3.3)
establishes a 1-1 correspondence between near-zero conic Hamiltonian vector ﬁelds
z →a(z) = J∇φ(z) and near-identity conic symplectic maps z →g(z) via generat-
ing relation (3.3).
Write C0 =
 
α
βT
γ
δ
!
with α ∈R, β, γ ∈Rn and δ ∈gl(n). Then the
generating relation (3.2) with generating matrix C given by (3.3) can be expressed as
⎧
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎩
p0 −p0 = −φq0(p, q),
p1 −p1 = −φq1(p, q),
q0 −q0 = φq0(p, q),
q1 −q1 = φq1(p, q),
(3.4)

11.3 Contact Generating Functions for Contact Maps
489
where p =
5
p0
p1
6
and q =
5
q0
q1
6
are given by
⎧
⎪
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎪
⎩
p0 = αp0 + (1 −α)p0 + βT(p1 −p1),
p1 = δp1 + (I −δ)p1 + γ(p0 −p0),
q0 = (1 −α)q0 + αq0 −γT(q1 −q1),
q1 = (I −δT)q1 + δTq1 −β(q0 −q0).
(3.5)
Every conic function φ can be contactized as an arbitrary function ψ(x, y, z) as
follows
ψ(x, y, z) = φ(1, x, z, y),
(3.6)
i.e.,
φ(p0, p1, q0, q1) = p0φ(1, p1/p0, q0, q1) = p0ψ(p1/p0, q1, q0),
p0 ̸= 0,
and we have the partial derivative relation:
⎧
⎪
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎪
⎩
φq0(p0, p1, q0, q1) = p0ψz(x, y, z),
φq1(p0, p1, q0, q1) = p0ψy(x, y, z),
φp0(p0, p1, q0, q1) = ψ(x, y, z) −xTψx(x, y, z) = ψe(x, y, z),
φp1(p0, p1, q0, q1) = ψx(x, y, z),
(3.7)
where x = p1
p0 , y = q1, z = q0 on the right hand side. So, under contactizing
transforms
S :
⎡
⎢⎢⎢⎢⎢⎢⎣
w
x
y
z
⎤
⎥⎥⎥⎥⎥⎥⎦
−→
⎡
⎢⎢⎢⎢⎢⎢⎣
p0
p1
q0
q1
⎤
⎥⎥⎥⎥⎥⎥⎦
=
⎡
⎢⎢⎢⎢⎢⎢⎣
w
wx
z
y
⎤
⎥⎥⎥⎥⎥⎥⎦
,
⎡
⎢⎢⎢⎢⎢⎢⎣
w
x
y
z
⎤
⎥⎥⎥⎥⎥⎥⎦
−→
⎡
⎢⎢⎢⎢⎢⎢⎣
p0
p1
q0
q1
⎤
⎥⎥⎥⎥⎥⎥⎦
=
⎡
⎢⎢⎢⎢⎢⎢⎣
w
wx
z
y
⎤
⎥⎥⎥⎥⎥⎥⎦
,
⎡
⎢⎢⎢⎢⎢⎢⎣
w
x
y
z
⎤
⎥⎥⎥⎥⎥⎥⎦
−→
⎡
⎢⎢⎢⎢⎢⎢⎣
p0
p1
q0
q1
⎤
⎥⎥⎥⎥⎥⎥⎦
=
⎡
⎢⎢⎢⎢⎢⎢⎣
w
w x
z
y
⎤
⎥⎥⎥⎥⎥⎥⎦
,
(3.8)
the generating relation (3.4) turns into

490
11. Contact Algorithms for Contact Dynamical Systems
⎧
⎪
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎪
⎩
w −w = −wψz(x, y, z),
wx −wx = −wψy(x, y, z),
z −z = ψe(x, y, z),
y −y = ψx(x, y, z),
(3.9)
and Equation (3.5) turns into
⎧
⎪
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎪
⎩
w = α w + (1 −α)w + βT( wx −wx),
w x = δ wx + (I −δ)wx + γ( w −w),
z = (1 −α)z + αz −γT(y −y),
y = (I −δT)y + δTy −β(z −z).
(3.10)
Since the p0-axis is distinguished for the contactization in which we should always
take p0 ̸= 0, it is natural to require β = 0 in (3.5). Let μ = w
w = p0
p0 and μ = w
w = p0
p0
,
we obtain from Equations (3.9) and (3.10)
μ =
1 + αψz(x, y, z)
1 −(1 −α)ψz(x, y, z),
μ = 1 + αψz(x, y, z),
(3.11)
and the induced contact transformation on the contact (x, y, z) space R2n+1 is
⎧
⎪
⎪
⎨
⎪
⎪
⎩
x −x = −ψy(x, y, z) + ψz(x, y, z)

(1 −α)x + αx

,
y −y = ψx(x, y, z),
z −z = ψe(x, y, z),
(3.12)
with the bar variables on the right hand side given by x, y, z
⎧
⎪
⎪
⎨
⎪
⎪
⎩
x = d1x + d2x + d0,
y = (I −δT)y + δTy,
z = (1 −α)z + αz −γT(y −y),
(3.13)
where
⎧
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎩
d1 =

I −(1 −α)ψz(x, y, z)

δ,
d2 =

I + αψz(x, y, z)

(I −δ),
d0 = −ψz(x, y, z)γ.
(3.14)
Summarizing the above discussions, we have:
Theorem 3.3. Relations (3.12) – (3.14) give a contact map (x, y, z) →(x, y, z) via
contact generating function ψ(x, y, z) under the type C0 =
 α
O
γ
δ

. Vice versa.

11.3 Contact Generating Functions for Contact Maps
491
However, the difﬁculty in the algorithmic implementation lies in the fact that, un-
like ¯y and z, which are linear combinations of y, y and z, z with constant matrix coef-
ﬁcients, since x = d1x+d2x+d0 and d1, d2 are matrices with coefﬁcients depending
on ¯ψz = ψz(x, y, z) which in turn depends on (x, y, z) the combination of x from x
and x is not explicitly given, the entire equations for solving x, y, z in terms of x, y, z
are highly implicit. The exceptional cases are the following:
(E1)
α = 0, δ = On, γ = O,
μ = 1 −ψz(x, y, z),
μ = 1,
(3.15)
⎧
⎪
⎪
⎨
⎪
⎪
⎩
x −x = −ψy(x, y, z) + xψz(x, y, z),
y −y = ψx(x, y, z),
z −z = ψe(x, y, z) = ψ(x, y, z) −xTψx(x, y, z).
(3.16)
(E2)
α = 1, δ = In, γ = O,
μ = μ = 1 + ψz(x, y, z),
(3.17)
⎧
⎪
⎪
⎨
⎪
⎪
⎩
x −x = −ψy(x, y, z) + xψz(x, y, z),
y −y = ψx(x, y, z),
z −z = ψe(x, y, z) = ψ(x, y, z) −xTψx(x, y, z).
(3.18)
(E3)
α = 1
2, δ = 1
2In, γ = O,
μ =
1 + 1
2ψz(x, y, z)
1 −1
2ψz(x, y, z)
,
μ = 1 + 1
2ψz(x, y, z),
(3.19)
⎧
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎩
x −x = −ψy(x, y, z) + ψz(x, y, z) x + x
2
,
y −y = ψx(x, y, z),
z −z = ψe(x, y, z) = ψ(x, y, z) −xTψx(x, y, z),
(3.20)
with
x = x + x
2
−1
4ψz(x, y, z)(x −x),
y = y + y
2
,
z = z + z
2
.
(3.21)
For ψz = λ = constant, the case (E3) reduces to
μ =
1 + 1
2λ
1 −1
2λ
,
μ = 1 + 1
2λ,
(3.22)
⎧
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎩
x −x = −ψy(x, y, z) + ψz(x, y, z) x + x
2
,
y −y = ψx(x, y, z),
z −z = ψe(x, y, z) = ψ(x, y, z) −xTψx(x, y, z),
(3.23)

492
11. Contact Algorithms for Contact Dynamical Systems
with
x = x + x
2
−1
4λ (x −x),
y = y + y
2
,
z = z + z
2
.
(3.24)
Note that the symplectic map induced by generating function φ from the relation
(3.2) can be represented as the composition of the maps, non-symplectic generally,
z →z and z →z
z = z + CJ∇φ(z),
z = z + (I −C)J∇φ(z).
Theorem 3.4. Contact map (x, y, z) →(x, y, z) induced by contact generating func-
tion ψ from the relations (3.12)–(3.14) can be represented as the composition of the
maps (x, y, z) →(x, y, z) and (x, y, z) →(x, y, z) which are not contact generally
and given, respectively, as follows
⎧
⎪
⎪
⎨
⎪
⎪
⎩
x −x = −δψy(x, y, z) + αψz(x, y, z)x −γψz(x, y, z),
y −y = (I −δT)ψx(x, y, z),
z −z = (1 −α)ψe(x, y, z) −γTψx(x, y, z)
(3.25)
and
⎧
⎪
⎪
⎨
⎪
⎪
⎩
x −x = −(I −δ)ψy(x, y, z) + (1 −α)ψz(x, y, z)x + γψz(x, y, z),
y −y = δTψx(x, y, z),
z −z = αψe(x, y, z) + γTψx(x, y, z).
(3.26)
(3.25) and (3.26) are the 2-stage form of the generating relation (3.12) of the contact
map induced by generating function ψ under the type C0 =
 α
O
γ
δ

. Correspond-
ing to the exceptional cases (E1), (E2) and (E3), the above 2-stage representation has
simpler forms, we no longer use them here.
11.4 Contact Algorithms for Contact Systems
Consider contact system (1.3) with the vector ﬁeld a deﬁned by contact Hamiltonian
K according to Equation (1.6). Take ψ(x, y, z) = sK(x, y, z) in (3.12) – (3.14) as the
generating function, we then obtain contact difference schemes with 1st order of ac-
curacy of the contact system (1.3) associated with all possible types C0 =
 α
O
γ
δ

.
The simplest and important cases are (write Kx = Kx(x, y, z), etc.) as follows[Fen95].

11.4 Contact Algorithms for Contact Systems
493
11.4.1 Q Contact Algorithm
Q. Contact analog of symplectic method (p, Q)1 (α = 0, δ = 0n, γ = 0).
1-stage form :
x = x + s

−Ky(x, y, z) + xKz(x, y, z)

,
y = y + sKx(x, y, z),
z = z + sKe(x, y, z);
2-stage form :
x = x,
y = y + s Kx,
z = z + s Ke,
x = x + s(−Ky + x Kx),
y = y,
z = z.
(4.1)
11.4.2 P Contact Algorithm
P. Contact analog of symplectic method (P, q)(α = 1, δ = In, γ = O).
1-stage form:
x = x + s

−Ky(x, y, z) + xKz(x, y, z)

,
y = y + sKx(x, y, z),
z = z + sKe(x, y, z);
2-stage form:
x = x + s(−Ky + x Kz),
y = y,
z = z,
x = x,
y = y + s Kx,
z = z + s Ke.
(4.2)
11.4.3 C Contact Algorithm
C. Contact version of Poincar´e generating function method similarly to symplectic
case

α = 1
2, δ = 1
2In, γ = O

.
2-stage form:
x = x + s
2(−Ky + xKz),
y = y + s
2Kz,
z = z + s
2Ke,
x = x + s
2(−Ky + xKx) =

x −s
2Ky
 
1 −s
2Kz
−1
,
y = y + s
2Kx = 2y −y,
z = z + s
2Ke = 2z −z.
(4.3)
One might suggest, for example, the following scheme for (1.3):
1 For Hamiltonian system ˙p = −Hq(p, q), ˙q = Hp(p, q), the difference scheme p =
p −sHq(p, q), q = q + sHp(p, q) is symplectic and we call it (p, Q) method because
the pair (p, q), composed of the old variables of p and the new variables of q, emerges in the
Hamiltonian. The following (P, q) method has the similar meaning.

494
11. Contact Algorithms for Contact Dynamical Systems
x = x + sa(x, y, z),
y = y + sb(x, y, z),
z = z + sc(x, y, z).
It differs from (4.2) only in one term for x, i.e., xK(x, y, z) instead of xK(x, y, z).
This minute, but delicate, difference makes (4.2) contact and the other non-contact!
It should be noted that the Q and P methods are of order one of accuracy and the
C method is of order two. The proof is similar to that for symplectic case. In principle,
one can construct the contact difference schemes of arbitrarily high order of accuracy
for contact systems, as was done for Hamiltonian systems, by suitably composing the
Q, P or C method and the respective reversible counterpart[QZ92]. Another general
method for the construction of contact difference schemes is based on the generat-
ing functions for phase ﬂows of contact systems which will be developed in the next
section.
11.5 Hamilton–Jacobi Equations for Contact Systems
We recall that a near identity contact map g : (x, y, z) →(x, y, z) can be gen-
erated from the so-called generating function ψ(x, y, z), associated with a matrix
C0 =
 
α
O
γ
δ
!
, by the relations (3.12) – (3.14). Accordingly, to the phase ﬂow et
K
of a contact system with contact Hamiltonian K, there corresponds a time-dependent
generating function ψt(x, y, z) such that the map et
K : (x, y, z) →(x, y, z) is gen-
erated from ψt by the relations (3.12) – (3.14), in which ψ is replaced by ψt and C0
is given in advance as above. The function ψt should be determined by K and C0.
Below we derive the relevant relations between them.
Let H(p0, p1, q0, q1) = p0K
p1
p0 , q1, q0

, p0 ̸= 0. With this conic Hamiltonian
and with normal Darboux matrices C =
 
C0
O
O
I −C0
!
, where C0 =
 
α
O
γ
δ
!
,
we get the Hamilton–Jacobi equation
∂
∂tφt(u) = H

u + (I −C)J∇φt(u)

,
with
u = (p0, p1, q0, q1)T,
(5.1)
satisﬁed by the generating function φt(u) of the phase ﬂow gt
H of the Hamiltonian
system associated with the Hamiltonian H while the phase ﬂow gt
H is generated from
φt by the relation
gt
H(u) −u = Jφt
Cgt
H(u) + (I −C)u

.
(5.2)
On the other hand, according to the discussion in Section 11.3, we have
φt(p0, p1, q0, q1) = p0ψt(x, y, z),
with
x = p1
p0
,
y = q1,
z = q0.
So, by simple calculations, we have

11.5 Hamilton–Jacobi Equations for Contact Systems
495
u + (I −C)J∇φt(u) =
⎡
⎢⎢⎢⎢⎢⎢⎣
p0 −(1 −α)φq0
p1 + γφq0 −(I −δ)φq1
q0 + αφp0 + γTφp1
q1 + δTφp1
⎤
⎥⎥⎥⎥⎥⎥⎦
=
⎡
⎢⎢⎢⎢⎢⎢⎣
p0(1 −(1 −α)ψz)
p0(x + γψz −(I −δ)ψy)
z + αψe + γTψx
y + δTψx
⎤
⎥⎥⎥⎥⎥⎥⎦
and
H(u + (I −C)J∇φt(u))
= p0

1 −(1 −α)ψz

K
%
x −(I −δ)ψy + γψz
1 −(1 −α)ψz
, y + δTψx, z + αψe + γTψx
&
.
Therefore, from Equation (5.1), ψt(x, y, z) satisﬁes
∂
∂tψt =

1 −(1 −α)ψz

K
%
x −(I −δ)ψy + γψz
1 −(1 −α)ψz
, y + δTψx, z + αψe + γTψx
&
.
(5.3)
Now we claim1. From (5.2), it follows that u = gt
H(¯u). The claim is then proved,
since H(gt
H(¯u)) = H(¯u), for all u. The following equality is valid
H

u + (I −C)J∇φt(u)

= H

u −CJ∇φt(u)

.
(5.4)
So, replacing C by C −I in above discussions or, equivalently, replacing α and δ by
α −1 and δ −1 with γ unchanging in (5.3), we can derive equation satisﬁed by the ψt
∂
∂tψt = (1+αψz)K
%x + δψy + γψz
1 + αψz
, y + (δT −I)ψx, z + (α −1)ψe + γTψx
&
.
(5.5)
(5.3) and (5.5) deﬁne the same function ψt. When t = 0, et
K = I, so we should
impose the initial condition
ψ0(x, y, z) = 0,
(5.6)
for solving the ﬁrst order partial differential equation (5.3) or (5.5). We call both equa-
tions the Hamilton–Jacobi equations of the contact system associated with the contact
Hamiltonian K and the matrix C0 =
 
α
O
γ
δ
!
.
Speciﬁcally, we have Hamilton–Jacobi equations for particular cases:
(E1) α = 0, δ = O, γ = O.
∂
∂tψt = (1 −ψt
z)K
%x −ψt
y
1 −ψtz
, y, z
&
= K(x, y −ψt
x, z −ψt
e).
(5.7)
(E2) α = 1, δ = In, γ = O.
1 Proof of the claim: let u = u + (I −C)J∇φt(u) and ¯u = u −CJ∇φt(u), then we have
u = Cu + (I −C)¯u.

496
11. Contact Algorithms for Contact Dynamical Systems
∂
∂tψt = K(x, y + ψt
x, z + ψt
e) = (1 + ψt
z)K
%
x + ψt
y
1 + ψtz , y, z
&
.
(5.8)
(E3) α = 1
2, δ = 1
2In, γ = O.
∂
∂tψt =

1 −1
2ψt
z

K
⎛
⎝
x −1
2ψt
y
1 −1
2ψtz
, y + 1
2ψt
x, z + 1
2ψt
e
⎞
⎠
=

1 + 1
2ψt
z

K
⎛
⎝
x + 1
2ψt
y
1 + 1
2ψtz
, y −1
2ψt
x, z −1
2ψt
e
⎞
⎠.
(5.9)
Remark 5.1. On the construction of high order contact difference schemes.
If K is analytic, then one can solve ψt(x, y, z) from the above Hamilton–Jacobi
equations in the forms of power series in time t. Its coefﬁcients are recursively de-
termined by the K and the related matrix C0. The power series are simply given
from the corresponding conic Hamiltonian generating functions φt(p0, p1, q0, q1) by
ψt(x, y, z) = ψt(1, x, z, y), since the power series expressions of φt with respect to
t from the conic Hamiltonian H(p0, p1, q0, q1) = p0K
p1
p0 , q1, q0

have been well
given in[FW94]. Taking a ﬁnite truncation of the power series up to order m, an arbi-
trary integer, with respect to the time t and replacing by the truncation the generating
function ψ in (3.12)–(3.14), then one obtains a contact difference scheme of order
m for the contact system deﬁned by the contact Hamiltonian K. The proofs of these
assertions are similar to those in the Hamiltonian system case, hence are omitted here.

Bibliography
[Arn78] V. I. Arnold: Ordinary Differential Equations. The MIT Press, New York, (1978).
[Arn88] V. I. Arnold: Geometrical Methods In The Theory of Ordinary Differential Equations.
Springer-Verlag, Berlin, (1988).
[Arn89] V. I. Arnold: Mathematical Methods of Classical Mechanics. Springer-Verlag, GTM
60, Berlin Heidelberg, Second edition, (1989).
[Etn03] J. Etnyre: Introductory lectures on contact geometry. In Proc. Sympos. Pure Math,
volume 71, page 81C107. SG/0111118, (2003).
[Fen93b] K. Feng: Symplectic, contact and volume preserving algorithms. In Z.C. Shi and
T. Ushijima, editors, Proc.1st China-Japan conf. on computation of differential equation-
sand dynamical systems, pages 1–28. World Scientiﬁc, Singapore, (1993).
[Fen95] K. Feng: Collected works of Feng Kang. volume I,II. National Defence Industry
Press, Beijing, (1995).
[FW94] K. Feng and D.L. Wang: Dynamical systems and geometric construction of algo-
rithms. In Z. C. Shi and C. C. Yang, editors, Computational Mathematics in China, Con-
temporary Mathematics of AMS, Vol 163, pages 1–32. AMS, (1994).
[Gei03] H. Geiges: Contact geometry. Math.SG/0307242, (2003).
[MNSS91] R. Mrugała, J.D. Nulton, J.C. Schon, and P. Salamon: Contact structure in thermo-
dynamic theory. Reports on Mathematical Physics, 29:109C121, (1991).
[QZ92] M. Z. Qin and W. J. Zhu: Construction of higher order symplectic schemes by com-
position. Computing, 47:309–321, (1992).
[Shu93] H.B. Shu: A new approach to generating functions for contact systems. Computers
Math. Applic., 25:101–106, (1993).

Chapter 12.
Poisson Bracket and Lie–Poisson Schemes
In this chapter, a clear Lie–Poisson Hamilton–Jacobi theory is presented. It is also
shown how to construct a Lie–Poisson scheme integrator by generating function,
which is different from the Ge–Marsden[GM88] method.
12.1 Poisson Bracket and Lie–Poisson Systems
Before introducing the Lie–Poisson system, let us ﬁrst review more general about the
Poisson system.
12.1.1 Poisson Bracket
Take a system with ﬁnite dimensions as an example. Give a manifold M and two
smooth functions F, G on M, i.e., F, G ∈C∞(M). If an operation {·, ·} deﬁned on
C∞(M) satisﬁes the following 4 properties, then {·, ·} is called Poisson bracket, and
(M, {·, ·}) is called Poisson manifold[Olv93].
1.
Bilinearity
{aF1 + bF2, H} = a{F1, H} + b{F2, H},
{F, aH1 + bH2} = a{F, H1} + b{F, H2}.
2.
Skew-Symmetry
{F, H} = −{H, F}.
3.
Jacobi Identity
{{F, H}, G} + {{H, G}, F} + {{G, F}, H} = 0.
4.
Leibniz Rule
{F1 · F2, H} = F1{F2, H} + F2{F1, H}.
Given a Hamiltonian function H ∈C∞(M), the induced equation
˙F = {F, H},
∀F ∈C∞(M)

500
12. Poisson Bracket and Lie–Poisson Schemes
is called the generalized Hamiltonian equation. The most general case of Hamiltonian
system is the one with symplectic structure, whose equations have the form:
˙z = JHz,
J =
5 O
I
I
O
6
,
z =
5 p
q
6
.
According to Darboux theorem, a general Poisson system with ﬁnite dimensions
can be transformed into a local coordinate form, whose equations may be written as
˙z = K(z)Hz,
(1.1)
the corresponding Poisson bracket is
{F, H} = (∇zF(z))TK(z)∇zH(z),
∀F, H ∈C∞(M).
K(z) satisﬁes 4 properties the above , if and only if K(z) = (kij(z)) satisﬁes
kij(z)∂klm(z)
∂zi
+ kil(z)∂kmj
∂zi + kim(z)∂kjl
∂zi = 0,
j, l, m = 1, 2, · · · , n.
(1.2)
We remark that any antisymmetry constant matrix satisﬁes (1.2) and hence is a Hamil-
tonian operator, and the bracket deﬁned by it is a Poisson bracket. We will discuss its
algorithm in more detail in the next section.
Deﬁnition 1.1. A diffeomorphism z →z = g(z) : M →M is called a Poisson
mapping, if it preserves the Poisson bracket, i.e.,
{F ◦g, H ◦g} = {F, H} ◦g,
∀F, H ∈C∞(M).
(1.3)
Theorem 1.2. For a Poisson manifold with structure matrix K(z), Equation (1.3) is
equivalent to
gzK(z)gT
z = K(z),
where gz is the Jacobian matrix of g with respect to z.
Proof.
{F ◦g, H ◦g} =

∇(F ◦g)
TK(z)∇

H ◦g(z)

= (F ◦g)zK(z)(H ◦g)T
z
= Fz(g(z))∂g
∂z K(z)
∂g
∂z
T 
Hz(g(z)
T
= (∇F ◦g)T ∂g
∂z K(z)
∂g
∂z
T
(∇H ◦g),
and
{F, H} ◦g = ∇F TK∇H(g(z)) = (∇F ◦g)TK(g(z))(∇H ◦g).
By comparison, we get
gz(z)K(z)(gz(z))T = K(g(z)) = K(z).
The theorem is proved.
▲

12.1 Poisson Bracket and Lie–Poisson Systems
501
A Hamiltonian system on a Poisson manifold usually refers to the following ODEs
d z
d t = K(z)∇H(z),
(1.4)
where H(z) is a Hamiltonian function.
The phase ﬂow of the Equation (1.4), which is expressed as gt(z) = g(t, z) =
gH(t, z), is a one parameter diffeomorphism group (at least locally), i.e.,
g0 = identity,
gt1+t2 = gt1 ◦gt2.
Theorem 1.3. The phase ﬂow gH(z, t) of the Hamiltonian system (1.4) is a one pa-
rameter group of Poisson maps, i.e.,
{F ◦g(z, t), G ◦g(z, t)} = {F, G} ◦g(z, t).
(1.5)
Proof. See[Olv93].
▲
By Theorem 1.2, we get
gz(z, t)K(z)(gz(z, t))T = K(g(z)).
(1.6)
Deﬁnition 1.4. A smooth function C(z) is called a Casimir function, if
{C(z), F(z)} = 0,
∀F ∈C∞(M).
Deﬁnition 1.5. F(z) ∈C∞(M) is a ﬁrst integral of Hamiltonian system, iff {F, H} =
0. Obviously, every Casimir function is a ﬁrst integral.
12.1.2 Lie–Poisson Systems
The Lie–Poisson system is a type[MW83,MR99] of common Poisson systems. Its struc-
ture space is the dual space of any Lie algebra, and its bracket is called Lie–Poisson
bracket. There are two types of deﬁnition for the Lie–Poisson bracket: one relies on
the coordinate deﬁnition, and the other does not rely on the coordinate deﬁnition.
Lie–Poisson bracket. Let g be a r-dimensional Lie algebra, Ck
ij (i, j, k = 1, 2, · · · , r)
be the conﬁguration constants of g w.r.t. basis v1, v2, · · · , vr. Let V be another r-
dimensional linear space, with coordinate x = (x1, x2, · · · , xr). Then Lie–Poisson
bracket is deﬁned by:
{F, H} =
r

i,j,k=1
Ck
ijxk ∂F
∂xi
∂H
∂xj ,
∀F, H ∈C∞(R).
(1.7)
According to the notation of the Poisson system
kij(x) =
r

l=1
Cl
ijxl.
It is easy to verify that {F, H} satisﬁes the 4 properties of a Poisson bracket. For
the inﬁnite dimensional evolution equations, there exists a corresponding coordinate
deﬁnition; see the literatures[Arn89,MR99].

502
12. Poisson Bracket and Lie–Poisson Schemes
Lie group action and momentum mapping. The Lie–Poisson system is closely re-
lated to the Hamiltonian system with symmetry.
Deﬁnition 1.6. The invariant property of a Hamiltonian system under one parameter
differomorphism group is called symmetry of the Hamiltonian system. Under certain
circumstance, this invariant property is called momentum. The corresponding map-
ping is called momentum mapping.
The Lie group, action on manifold M, ∀g ∈G, and corresponds to a self-homeomorph-
ism φg on M. Below, we consider only the translation action of G on itself and the
induced action on TG and T ∗G.
Deﬁnition 1.7. Inﬁnitesimal generator vector ﬁeld: let g be a Lie algebra of G, ξ ∈g,
then exp tξ ∈G,
ξM = d
d t

t=0φexp tξ(x),
x ∈M
is called inﬁnitesimal generator vector ﬁeld of the ﬂow Ft = φexp tξ.
Deﬁnition 1.8 (Lifted action).
Action φg : M →M may induce action "φg :
T ∗M →T ∗M, which is deﬁned as follows:
"φg(α) = T ∗φg−1 = (T ∗φg)−1(α),
α ∈T ∗
φ(g)(x).
Thus, we can prove that the lifted mapping of a diffeomorphism is symplectic.
Deﬁnition 1.9 (Momentum mapping). Let (P, ω) be a connected symplectic mani-
fold. Let G be a Lie group, φg : P →P a symplectic action. We call J : P →g∗(g∗
is the dual space of g) a momentum mapping, if J satisﬁes
∀ξ ∈g,
d 
J (ξ) = iξpω,
where 
J (ξ) is deﬁned by 
J (ξ)(x) = ⟨J (x), ξ⟩, ⟨· , · ⟩denotes a scalar product, and
ξp is the inﬁnitesimal generator of the action to ξ.
Theorem 1.10 (Generalized Noether theorem). Let φ be a symplectic action of G
on (P, ω) with a momentum mapping J . Suppose H : P →R is G-invariant, i.e.,
H(x) = H(φg(x)),
∀x ∈P,
g ∈G,
(1.8)
then 
J is a ﬁrst integral of XH, i.e., if Ft is the phase ﬂow of XH, then
J (Ft(x)) = J (x).
Proof. See[MW83].
▲
Deﬁnition 1.11. A momentum mapping J is called Ad∗-equivariant, if
J (φg(x)) = Ad∗
g−1J (x),
∀g ∈G,
that is, the following diagram commutes

12.1 Poisson Bracket and Lie–Poisson Systems
503
P
φg
−−−−→P
J
⏐⏐G
J
⏐⏐G
g∗
Ad∗
g−1
−−−−→g∗
and we call such a group action as a Poisson action[AN90].
Theorem 1.12. [MR99] J is Ad∗-equivariant momentum mapping, iff
{ 
J (ξ), 
J (η)} = 
J ([ξ, η]),
i.e., 
J is a Lie homomorphism.
Corollary 1.13. Let φ be a Poisson action of G on the manifold M, and "φ be the lifted
action on T ∗(M) = P. Then this action "φ is symplectic and has an Ad∗-equivariant
momentum mapping given by
J : P −→g∗,

J (ξ)(α(q)) = α(q) · ξM(q),
q ∈M,
α(q) ∈T ∗M.
ξM is the inﬁnitesimal generator of φ on M.
Below, we will discuss the translation action of a Lie group on itself using the
above theorem and deduction.
Let G be a Lie group, φ : G × G →G be a left translation action (g, h) →gh.
Then its inﬁnitesimal generator is
ξG(g) = TeRgξ = R∗
gξ.
Because lifted action is symplectic, by Corollary 1.13, we can obtain the momentum
mapping:
J (αq)(ξ) = αqTeRgξ = αqR∗
gξ =⇒J (αq) = TeR∗
gαq = R∗
gαq,
or can rewrite it as
JL(αq) = R∗
gαq.
Likewise, we can obtain the similar result for the right translation
JR(αq) = L∗
gαq.
Lie–Poisson bracket and motion equation. In the previous sections, we have intro-
duced the Lie–Poisson bracket and equations which are expressed by the local coordi-
nates. Below, we will introduce an intrinsic deﬁnition of Lie–Poisson bracket and its
induced equation of motion.
Let ⟨· , · ⟩be the pairing between g∗and g, ∀F : g∗→R, δ F
δ μ ∈g, μ ∈g∗, is
deﬁned by
DF(μ)γ =
=
γ, δ F
δ μ
>
,
γ ∈g∗.

504
12. Poisson Bracket and Lie–Poisson Schemes
If we regard g∗∗≃g, then DF(μ) ∈g∗∗becomes an element of g,
{F, G}(μ) = −
=
μ,
δF
δμ , δG
δμ
>
,
where [ · , · ] is the Lie bracket on g. The above equation is usually denoted as {F, G}.
It is easy to verify that { · , · } satisﬁes the 4 properties of Poisson bracket, and are
often called as (⟨⟨−⟩⟩) Lie–Poisson bracket. They are ﬁrst proposed by Lie[Lie88] and
are redeﬁned by Berezin and others thereafter. We can prove that { · , · } can be derived
from the left translation reduction of a typical Poisson bracket on T ∗G. If the right
translation reduction is used, we have the Lie–Poisson bracket (⟨⟨+⟩⟩):
{F, G}(μ) =
=
μ,
δF
δμ , δG
δμ
>
= {F, G}+.
Given a Lie–Poisson bracket, we can deﬁne the Lie–Poisson equation. Take { · , · } as
an example.
Proposition 1.14. If H−∈C∞(g∗) is a Hamiltonian function, then the evolutionary
equation on g∗is:
˙F = {F, H}−,
i.e.,
˙μ = XH−(μ) = ad∗
δH
δμ μ.
(1.9)
Proof. Because
˙F(μ) = DF(μ) · ˙μ =
=
˙μ, δF
δμ
>
,
and
{F, H−}−(μ) = −
=
μ,
δF
δμ , δH
δμ
>
=
=
μ, ad δH
δμ
δF
δμ
>
=
=
ad∗
δH
δμ μ, δF
δμ
>
.
Since F is arbitrary, we obtain
˙μ = ad∗
δH
δμ μ.
Likewise, for the right invariant system, the equation is
˙μ = −ad∗
δH
δμ μ.
Henceforth, we will denote the system of left translation reduction as g∗
+, and the right
translation reduction as g∗
−. Generally speaking, the rigid body and Heavy top system
belongs to the left invariant system g∗
−, and the continuous systems, such as plasma
and the incompressible ﬂow, are right invariant system g∗
+.
▲
Lemma 1.15. JL, JR are Poisson mapping.
Proof. See[MW83].
▲

12.1 Poisson Bracket and Lie–Poisson Systems
505
From this lemma, we can obtain the following reduction theorem (it will be used
in the generating function theory later).
Theorem 1.16. 1◦
For the left invariant system g∗
−, we have the following diagram
commutes:
T ∗G
Gt
H◦JR
−−−−−→T ∗G
JR
⏐⏐G
JR
⏐⏐G
g∗
−
Gt
H
−−−−→
g∗
−
where H : g∗→R is a Hamiltonian function on g∗
−, Gt
H is a phase ﬂow of Hamilto-
nian function H on g∗
−, and Gt
H◦JR is phase ﬂow of Hamiltonian function H ◦JR on
T ∗G.
2◦
Similarly for right invariant system g∗
+, we have
T ∗G
Gt
H◦JL
−−−−→T ∗G
JL
⏐⏐G
JL
⏐⏐G
g∗
+
Gt
H
−−−−→
g∗
+
Theorem 1.17. The solutions of a Lie–Poisson system are a bundle of coadjoint or-
bits. Each coadjoint orbit is a symplectic manifold and is called symplectic leave of
the Lie–Poisson system.
This theorem is from literature[AM78]. For Lie–Poisson system such as Heavy Top
and the compressible ﬂows, similar set of theories can be established. The readers can
refer to literature[MRW90] for more details.
12.1.3 Introduction of the Generalized Rigid Body Motion
Let G be a Lie group (ﬁnite dimensional), g(t) be a movement on G. We deﬁne:
Velocity: V (t) = ˙g(t) ∈Tg(t)G;
Angular velocity in body description:
WB(t) = TLg(t)−1(˙g(t)) ∈g;
Angular velocity in space description: WS(t) = TRg(t)−1(˙g(t)) ∈g;
Momentum : M(t) = Ag ˙g, where Ag : TgG →T ∗
g G is called a moment of
inertia operator, it relates to the kinetic energy by
T = 1
2(˙g, ˙g)g = 1
2(WB, WB) = 1
2⟨AWB, WB⟩= 1
2⟨Ag ˙g, ˙g⟩,
where A: g→g∗is a value of Ag at g = e;
Angular momentum in body description: MB(t) = T ∗Rg(t)(M(t)) ∈g∗;
Angular momentum in space description: MS(t) = T ∗Lg(t)(M(t)) ∈g∗.

506
12. Poisson Bracket and Lie–Poisson Schemes
From the above deﬁnition, we can obtain the following conclusions:
WS(t) = Adg(t)WB(t),
MS(t) = Ad∗
g(t)−1MB(t),
MB(t) = AWB(t).
By Theorem 1.10, we get:
Theorem 1.18. Conservation of spatial angular momentum theorem
d
d tMS(t) = 0.
(1.10)
Because the system that takes kinetic energy T as the Hamiltonian function is left
invariant, MS(t) is the momentum mapping exactly.
Corollary 1.19. Euler equation
d
d tMB(t) = {WB(t), MB(t)} = {A−1MB(t), MB(t)},
(1.11)
where { · , · } is deﬁned by:
{ξ, a} = ad∗
ξa,
∀ξ ∈g,
a ∈g∗.
Given below are two different proofs of the Euler equation.
Proof. 1◦
From the Lie–Poisson equation of the motion ˙μ = ad∗
∂H
∂μ μ, we can obtain
directly
H = 1
2(WB(t), MB(t)) = 1
2

A−1MB(t), MB(t)

,
δ H
δ MB = A−1MB(t) = WB(t).
2◦
By the deﬁnition of spatial angular momentum, we have
MB(t) = Ad∗
g(t)Ad∗
g(0)−1MB(0) = Ad∗
g(t)η.
(1.12)
Since
MS(t) = MS(0) =⇒Ad∗
g(t)−1MB(t) = Ad∗
g(0)−1MB(0) = η.
This also indicates that the trajectory of Lie–Poisson equation lies in some coadjoint
orbit. From
⟨MB(t), ξ⟩= ⟨Ad∗
g(t)η, ξ⟩= ⟨η, Adg(t)ξ⟩,
∀ξ ∈g,
taking time derivatives on two sides, we get
=d MB(t)
d t
, ξ
>
=
H
η, [TRg(t)−1(˙g(t)), Adg(t)ξ]
I
,
since
d
d tAdg(t)ξ = [TRg(t)−1 ˙g(t), Adg(t)ξ]

12.2 Constructing Difference Schemes for Linear Poisson Systems
507
(see[AM78]), then
=d MB(t)
d t
, ξ
>
=
⟨η, [TRg(t)−1 ˙g(t), Adg(t)ξ]⟩
=
⟨η, Adg(t)[TLg(t)−1 ˙g(t), ξ]⟩
=
⟨Ad∗
g(t)η, adT Lg(t)−1 ˙g(t)ξ⟩
=
⟨MB(t), adT Lg(t)−1 ˙g(t)ξ⟩
=
⟨ad∗
T Lg(t)−1 ˙g(t)MB(t), ξ⟩
=⇒
d MB(t)
d t
= ad∗
T Lg(t)−1 ˙g(t)MB(t) = {WB(t), MB(t)}.
The proof can be obtained.
▲
Generally speaking, an equation of motion on T ∗G, if it has Hamiltonian function
H = T, it can be expressed by
˙g(t) = TLg(t)
∂H
∂μ = Lg(t)∗∂H
∂μ ,
(1.13)
˙μ(t) = ad∗
∂H
∂μ μ(t).
(1.14)
Its solution is μ(t) = Ad∗
g(t)Ad∗
g(0)−1μ(0). The Equation (1.14) is called as the Lie–
Poisson equation.
12.2 Constructing Difference Schemes for Linear
Poisson Systems
Since the phase ﬂow of Hamiltonian system is Poisson phase ﬂow, which preserves
the Poisson structure, it is important to construct difference schemes for system (1.4)
that preserve the same property. Difference scheme that preserves the Poisson bracket
is called as the Poisson difference scheme.
One special case of the Poisson phase ﬂow is the symplectic phase ﬂow. How to
construct the symplectic difference schemes has already been described in the previ-
ous chapters. The reader can also refer to literatures[Fen85,FWQW89,FQ87,CS90] for more
details. However, the numerical algorithm for a general Poisson phase ﬂow is still
in its infancy. So far the results are limited to cases where structure matrix K is
constant[Wan91,ZQ94,AKW93,Kar04] and K(z) is linear (Lie–Poisson) only. We will dis-
cuss the results for the Lie–Poisson case in the next section. In this section, we will
discuss the results when K is a constant matrix.

508
12. Poisson Bracket and Lie–Poisson Schemes
12.2.1 Constructing Difference Schemes for Linear Poisson
Systems
Without loss of generality, we assume that K is an odd-dimensional matrix. Because
odd dimensional antisymmetric matrix is deﬁnitely degenerated, there exists a coordi-
nate transformation P ∈GL(n) such that PKP T =
 
J2r
O
O
Os
!
.
Deﬁnition 2.1. A difference scheme z = gτ
H(z) is called a Poisson scheme, if and
only if gzKgT
z = K.
Next, we have:
Deﬁnition 2.2. SK(n) = {A ∈GL(n) | AKAT = K}, then the set SK(n) has the
following properties:
1◦
When the rank of K is an even number and non-singular, then K has all the
properties of a symplectic matrix.
2◦
When the rank of K is an odd number, it must be degenerated. It is easy to
verify that SK(n) is a group and we call it as K-symplectic group. Its Lie algebra is
sK(n) = {a ∈gl(n) | aK + KaT = 0}.
According to Feng et al.[FWQ90], we can establish the relationship between SK(n) and
sK(n) via Cayley transformation. If A ∈SK(n), namely if AKAT = K, then
B = (I −A)(I + A)−1 = (I + A)−1(I −A)
is an element of sK(n). However, if B ∈sK(n), then
A = (I −B)(I + B)−1 = (I + B)−1(I −B)
is an element of SK(n) .
For a generalized Cayley transformation, we have the following result similarly:
Theorem 2.3. Given φ(Λ) =
p(Λ)
p(−Λ), p(Λ) is a polynomial that satisﬁes p(0) = 1,
˙p(0) ̸= 0, if B ∈sK(n), then
A = φ(B) ∈SK(n).
Therefore, we may use Pad´e approximation and pseudo-spectral method (the
Chebyshev spectral method) to construct the Poisson schemes for the linear Poisson
system. The Pad´e approximation has been described in the literatures[Qin89,ZQ94,FWQ90]
in detail. Below, we will brieﬂy describe the Chebyshev spectral method to construct
the Poisson scheme. The Chebyshev spectral method is a highly effective method to
approximate eA. The detailed explanation of this is described in literature[TF85]. Here,
we give only the result.
The Chebyshev spectral method is an approach based on series expansion by
Chebyshev polynomial, i.e.,

12.2 Constructing Difference Schemes for Linear Poisson Systems
509
ex =
∞

k=0
CkJk(R)Qk
 x
R

,
|x| < R,
(2.1)
where x is a real number and Qk is the Chebyshev complex orthogonal multinomial.
Qk satisﬁes the following recurrence relation:
Q0(x) = 1,
Q1(x) = x,
Qk+1(x) = Qk−1(x) + 2xQk(x),
where C0 = 1, and Ck = 2 for k > 0. Jk denotes the k-order Bessel function. Qk
denotes the Chebyshev polynomial. R is chosen arbitrarily. During computing, we
calculate Jk(R) ﬁrst, and then calculate Qk using the above recursive procedure.
Using the generalized Cayley transformation, and
eA = e
A
2
e
−A
2 ,
and applying the Chebyshev spectral method to the numerator and denominator re-
spectively, we can obtain the Poisson algorithm.
It was pointed out in literature[TF85] that when k > R, the series converges ex-
ponentially. Therefore, the summation in (2.1) is always ﬁnite. Where to truncate the
series is determined by the size of Jk(R). Since Jk(R) converges exponentially too,
only a few steps of iteration is enough. Numerical tests show that this method has high
accuracy and efﬁciency, especially when A is a dense matrix. The above method can
be applied only to the linear dynamic system, where H is a quadratic form of z,
˙z = KBz.
12.2.2 Construction of Difference Schemes for General Poisson
Manifold
For a general H, there are other methods to construct Poisson integrator such as
method of generating function. The reader can refer to literatures[Fen85,FWQW89,FQ87]
for more details. For a low-order scheme, we can construct directly using the implicit
Euler scheme and verify it by criterion (1.3).
Let
˙z = K ∂H
∂z ,
construct
zk+1 = zk + τK∇H
1
2(I + B)zk+1 + 1
2(I −B)zk
.
(2.2)
Take derivative of (2.2) w.r.t. zk,
zz = I + τKHzz
1
2(I + B)zz + 1
2(I −B)

,

510
12. Poisson Bracket and Lie–Poisson Schemes
i.e.,

I −1
2τKHzz(I + B)

zz = I + 1
2τKHzz(I −B),
where zk+1 = z, zk = z, xy = ∂x
∂y , therefore,
zz =

I −1
2τKHzz(I + B)
−1
I + 1
2τKHzz(I −B)

.
To become a Poisson scheme, it should satisfy
zzKzT
z = K,
i.e.,

I −1
2τKHzz(I + B)
−1 
I + 1
2τKHzz(I −B)

K
·

I + 1
2τKHzz(I −B)
T 
I −1
2τKHzz(I + B)
−1
= K.
After manipulation, we obtain
KHzz(KBT + BK)HzzK = O.
Therefore, if KBT + BK = O, i.e., BT ∈sK(n), this scheme is a Poisson scheme.
When B = O, then the scheme becomes Euler midpoint scheme.
Denote
zk+1 = Gτ
H,Bzk,
then for B = O, the scheme is of second-order, for B ̸= O, it is only of ﬁrst order.
Using
zk+1 = Gτ
H,±Bzk,
we can construct a composite scheme,
Gτ
H,±B = G
τ
2
H,B ◦G
τ
2
H,−B,
Gτ
H,∓B = G
τ
2
H,−B ◦G
τ
2
H,B.
Proposition 2.4. The above scheme has the second-order accuracy and the following
proposition can be easily derived.
If φA(z) = 1
2zTAz, where AT = A, is a conservative quantity of Hamiltonian
system d z
d t = K ∂H
∂z , and if A satisﬁes BTA + ABT = 0, then φA(z) is also a
conservative quantity of difference scheme Gτ
H,−B.
Proof. Because φA(z) is a conservative quantity of Hamiltonian system,
1
2 zTAz = 1
2zTAz,

12.2 Constructing Difference Schemes for Linear Poisson Systems
511
then
1
2(z + z)TA(z + z) = 0.
From BTA + ABT = 0, we obtain
1
2(B(z −z))TA(z −z) = 1
2(z −z)BTA(z −z)
= 1
4(z −z)T(BTA + AB)(z −z) = 0,
1
2(z + z) + 1
2B(z −z)
T
A(z −z) = 0
=⇒τwTAKHz(w) = 0,
∀w ∈Rn.
Let
w = 1
2(zk+1 + zk) + 1
2B(zk+1 −zk),
we obtain
1
2(zk+1)TAzk+1 = 1
2(zk)TAzk.
The proof can be obtained.
▲
12.2.3 Answers of Some Questions
1.
Euler explicit scheme[LQ95a]
For a separable Hamiltonian H in a standard Hamiltonian system, there exists an
Euler explicit symplectic scheme. Similar question is raised for the Poisson system:
does there exist an Euler explicit Poisson scheme for a separable H? The answer is
“may not be”. We take n = 3 as an example to explain this point. Let
K =
⎡
⎢⎢⎣
0
−c
b
c
0
−a
−b
a
0
⎤
⎥⎥⎦,
H = 1
2(z2
1 + z2
2 + z2
3),
then
˙z = K ∂H
∂z = Kz.
To make scheme
zk+1 = zk + τK∇H
1
2(I + B)zk+1 + 1
2(I −B)zk
a Poisson scheme, we should have
KHzz(KBT + BK)HzzK = K2BTK + KBK2 = O,

512
12. Poisson Bracket and Lie–Poisson Schemes
i.e., K2BTK ∈Sm(n) (symmetrical matrix), here KBT ∈Sm(n), i.e., BK ∈
Sm(n). Expand scheme
zk+1 = zk + τK∇H(w),
w = 1
2(I + B)zk+1 + 1
2(I −B)zk
into
⎧
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎩
zk+1
1
= zk
1 −cτw2 + bτw3,
zk+1
2
= zk
2 + cτw1 −aτw3,
zk+1
3
= zk
3 −bτw1 + aτw2.
To make sure the scheme is explicit, w2, w3 have to be a function of zk only. From
w2 = 1
2(zk+1
2
+ zk
2) + 1
2b21(zk+1
1
−zk
1) + 1
2b23(zk+1
3
−zk
3) + 1
2b22(zk+1
2
−zk
2),
we obtain b21 = 0 = b23, b22 = −1. Likewise, b31 = b32 = 0, b33 = −1. Then B
has the form
⎡
⎢⎢⎣
b1
b2
b3
0
−1
0
0
0
−1
⎤
⎥⎥⎦,
substituting it into BK(∈Sm(n)), we know only when a = 0, the scheme becomes
an explicit scheme. Note that when a = 0, K is degenerated to the symplectic case.
Therefore, in many situations, the separable system does not have an explicit scheme.
Here the explicit scheme refers to the low-order ﬁnite-difference scheme, not the ex-
plicit analytic solution.
2.
Midpoint scheme and Euler scheme
Below, we will answer the questions whether the midpoint scheme is a Lie–Poisson
scheme of Euler equation, and whether there exists a Lie–Poisson scheme in a gener-
alized Euler scheme[LQ95a,LQ95b].
We already know that the answer for the ﬁrst question is “no”. Now, we turn to the
second question. The Euler equation has the form
˙z = J(z)Hz = f(z).
For the case n = 3,
J(z) =
⎡
⎢⎢⎣
0
−z3
z2
z3
0
−z1
−z2
z1
0
⎤
⎥⎥⎦,
H = 1
2
%
z2
1
I1 + z2
2
I2 + z2
3
I3
&
.
We construct a generalized Euler scheme:

12.2 Constructing Difference Schemes for Linear Poisson Systems
513
z = z + τJ(w)Hz(w) = z + τf(w),
where
w = 1
2(z + z) + 1
2B(z −z) = 1
2(I + B)z + 1
2(I −B)z.
The Jacobian matrix of map z →z is
A = ∂z
∂z = I + τD∗f(w)
%∂w
∂z
&
,
where
D∗f(z) = D∗J(z)Hz =
⎡
⎢⎢⎢⎢⎢⎢⎣
0
I2 −I3
I2I3 z3
I2 −I3
I2I3 z2
I3 −I1
I1I3 z3
0
I3 −I1
I1I3 z1
I1 −I2
I1I2 z2
I1 −I2
I1I2 z1
0
⎤
⎥⎥⎥⎥⎥⎥⎦
,
∂w
∂z = 1
2(I + B)A + 1
2(I −B),
therefore
A = (I −τD∗f(w)(I + B))−1(I + τD∗f(w)(I −B)).
For the Euler scheme to be a Poisson scheme, it has to be AJ(z)AT = J(z), therefore:
AJ(z)AT = (I −τD∗f(w)(I + B))−1(I + τD∗f(w)(I −B))J(z)
· (I + τ(I −BT)(D∗f(w))T)(I −τ(I + B)(D∗f(w))T)−1
= J(z),
i.e.,
(I + τD∗f(w)(I −B))J(z)(I + τ(I −BT)(D∗f(w))T)
= (I −τD∗f(w)(I + B))J(z)(I −τ(I + BT)(D∗f(w))T),
after manipulation,
J(z) −J(z) + τ 2D∗f(w)[(I + B)J(z)(I + BT) −(I −B)J(z)(I −BT)](D∗f(w))T
= τ[J(z)(I −BT) + J(z)(I + BT)](D∗f(w))T + τD∗f(w)[(I −B)J(z) + (I + B)J(z)]
= J(z −z) + τ 2D∗f(w)[J(z −z) + BJ(z + z) + J(z + z)BT + BJ(z −z)BT](D∗f(w))T.
Because τ is arbitrary, and z −z = O(τ), we can have
⎧
⎪
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎪
⎩
J(z −z) = τJ(z + z)(D∗f(w))T + τD∗f(w)J(z + z),
τ 2D∗f(w)[BJ(z + z) + J(z + z)BT](D∗f(w))T
= τJ(z −z)BT(D∗f(w))T + τD∗f(w)BJ(z −z),
D∗f(w)[J(z −z) + BJ(z −z)BT](D∗f(w))T = O.

514
12. Poisson Bracket and Lie–Poisson Schemes
When B = O, the above equation is the midpoint scheme, w = 1
2(z + z). It is
easy to verify that the last equality in the above equations is dissatisﬁed. Hence the
midpoint scheme is not a Poisson scheme. When B ̸= O, after complex computation,
we can obtain similarly that there does not exist any B ∈gl(n) to satisfy the above
3 formulas. Therefore, there does not exist a Poisson scheme in a generalized Euler
form.
12.3 Generating Function and Lie–Poisson Scheme
The generating function method plays a crucial role in constructing the symplectic
scheme (see the literatures[FWQW89,CS90,CG93] for details). Therefore, how to use the
generating function method to construct the Lie–Poisson scheme becomes a research
hot spot. The literatures in this aspect include[GM88,Ge91,CS91]. We have also investi-
gated the generating function for Lie–Poisson system in details, and discovered that
the Ge–Marsden method needs further improvement. Below is our understanding and
derivation on the generating function and the Hamilton–Jacobi theory[LQ95b].
12.3.1 Lie–Poisson–Hamilton–Jacobi (LPHJ) Equation and
Generating Function
According to the diagram in Section 12.1 (for the left invariant system),
T ∗G
Gt
H◦JR=S
−−−−−−−→T ∗G
JR
⏐⏐G
JR
⏐⏐G
g∗
Gt
H=P
−−−−−−→
g∗
the phase ﬂow determined by H on g∗can induce a phase ﬂow on T ∗G determined
by H ◦JR. Let ut(q, q0) be a ﬁrst kind generating function of the symplectic map S.
Then we have the following properties.
Property 3.1. If u : G × G →R is invariant under the left action of G, i.e.,
ut(gq, gq0) = ut(q, q0),
(3.1)
then the symplectic mapping generated by u, S : (q0, p0) →(p, q), where:
p0 = −∂ut(q, q0)
∂q0
,
p = ∂ut(q, q0)
∂q
,
(3.2)
preserves momentum mapping JL. That is to say,
JL ◦S = JL.
For the right-invariant translation on G,
JR ◦S = JR.

12.3 Generating Function and Lie–Poisson Scheme
515
Deﬁnition 3.2. If G acts on the conﬁguration space without ﬁxed point, then we say
G acts on G freely.
Property 3.3. If G acts on G freely, and its induced symplectic mapping S preserves
the momentum mapping JL, then the ﬁrst-kind generating function of S is left invari-
ant.
Proof. See[GM88].
▲
For a left-invariant system, such as a generalized rigid body, the Hamiltonian func-
tion is left invariant, the phase ﬂow is also left invariant, the momentum mapping JL is
a ﬁrst integral for this dynamics, i.e., JL is invariant under the phase ﬂow of Gt
H◦JR.
Therefore, if the action is free (generally speaking, the action is locally free), the ﬁrst-
kind generating function is left invariant.
Let ut(q, q0) be the ﬁrst-kind generating function of S, then by the left invariance
ut(q, q0) = ut(e, q−1q0) = "ut(g),
g = q−1q0.
By Equation (3.2), we have
p0 = −∂ut(q, q0)
∂q0
= −∂"ut(q−1q0)
∂q0
= −∂"ut(Lq−1q0)
∂q0
= −L∗
q−1 ∂"u
∂g

g=q−1q0,
p = ∂ut(q, q0)
∂q
= ∂"u(q−1q0)
∂q
= ∂"u(Rq0V (q))
∂"q
= V ∗R∗
q0
∂"u
∂g

g=q−1q0
,
V (q) = q−1,
V ∗= −L∗
q−1R∗
q−1,
then
p = −L∗
q−1R∗
q−1R∗
q0
∂"u
∂g

g=q−1q0
,
therefore,
μ0 = L∗
q0p0 = −L∗
q0L∗
q−1 ∂"u
∂g

g=q−1q0
= −L∗
q−1q0
∂"u
∂g

g=q−1q0 = −L∗
g
∂"u
∂g

g=q−1q0,
and
μ = L∗
qp = −L∗
qL∗
q−1R∗
q−1R∗
q0
∂"u
∂g

g=q−1q0
= −R∗
q−1q0
∂"u
∂g

g=q−1q0
= −R∗
g
∂"u
∂g

g=q−1q0
.
Through the above derivation, it is easy to prove (3.1)

516
12. Poisson Bracket and Lie–Poisson Schemes
M0 = R∗
q0p0 = −R∗
q0L∗
q−1 ∂"u
∂g

g=q−1q0
,
M = R∗
qp = −R∗
qL∗
q−1R∗
q−1R∗
q0
∂"u
∂g

g=q−1q0
= −L∗
q−1R∗
q0
∂"u
∂g

g=q−1q0
= −R∗
q0L∗
q−1 ∂"u
∂g

g=q−1q0
= M0,
i.e.,
JL ◦S = JL.
Take g = q−1q0, then
⎧
⎪
⎪
⎨
⎪
⎪
⎩
μ0 = −L∗
q
∂"u(g)
∂g ,
μ = −R∗
g
∂"u(g)
∂g
= Ad∗
g−1μ0,
(3.3)
therefore ut(q, q0) = "ut(q−1q0) = "ut(g) deﬁnes a Poisson mapping:
μ0 →μ = Ad∗
g−1μ0.
We now derive the conditions that ut(q, q0) must meet.
ut(q, q0) generates a symplectic map S = Gt
H◦J = Gt
H, where H = H ◦J , and
S : (p0, q0) −→(p, q),
p0 = −∂u
∂q0 ,
p = ∂u
∂q .
(3.4)
Because
pd q −p0d q0 = ∂u
∂q d q + ∂u
∂q0 d q0,
d u = ∂u
∂q d q + ∂u
∂q0 d q0 + ∂u
∂t d t = pd q −p0d q0 + ∂u
∂t d t,
we have
d
%
pd q −p0d q0 + ∂u
∂t d t
&
= 0.
Note that

12.3 Generating Function and Lie–Poisson Scheme
517
d (pd q −p0d q0) = d p ∧d q −d p0 ∧d q0
=
% ∂p
∂p0 d p0 + ∂p
∂q0 d q0 + ∂p
∂t d t
&
∧
% ∂q
∂p0 dp0 + ∂q
∂q0 dq0 + ∂q
∂t d t
&
−d p0 ∧d q0
=
% ∂p
∂p0
∂q
∂q0 −∂p
∂q0
∂q
∂p0
&
d p0 ∧d q0 −d p0 ∧d q0
+ ∂q
∂t
∂p
∂p0 d p0 ∧d t + ∂q
∂t
∂p0
∂q0 d q0 ∧d t
−∂p
∂t
∂q
∂p0 dp0 ∧dt −∂p
∂t
∂p
∂q0 d q0 ∧d t
= f1 + f2 + f3.
Since (p0, q0) →(p, q) is symplectic, we have
gzJgT
z = J =⇒f1 = 0.
Because
⎧
⎪
⎪
⎨
⎪
⎪
⎩
∂q
∂t = ∂H
∂p
∂p
∂t = −∂H
∂q
=⇒
⎧
⎪
⎪
⎨
⎪
⎪
⎩
f2 = ∂H
∂p d p ∧d t
f3 = ∂H
∂q d q ∧d t
,
therefore,
d p ∧d q −d p0 ∧d q0
= ∂H
∂p d p ∧d t + ∂H
∂q d q ∧d t = d H ∧d t
=⇒d H ∧d t + d
%
∂H
∂t
&
∧d t = 0.
We have
d
%
H + ∂H
∂t
&
∧d t = 0.
Therefore,
∂u
∂t + H(p, q, t) = c.
Taking a proper initial value, we can obtain:
∂u
∂t + H(p, q, t) = 0,
i.e.,
∂ut(p, q)
∂t
+ H ◦JR(p, q, t) = 0.
Therefore we obtain the LPHJ equations
∂u(g)
∂t
+ H

−R∗
g
∂u(g)
∂g

= 0,
(3.5)
g = q−1q0.

518
12. Poisson Bracket and Lie–Poisson Schemes
Remark 3.4. If we can construct a generating function u(g), we then have u(q0, q).
This function can generate a symplectic mapping on T ∗G. By the commutative dia-
gram, a Poisson mapping on g∗can also be induced. This is a key point of constructing
a Lie–Poisson integrator by generating function.
Remark 3.5. In order that the induced phase ﬂow is a Poisson phase ﬂow, the phase
ﬂow on T ∗G should be symplectic. Therefore, the condition of g = q−1q0 cannot be
discarded. Namely, when t →0, g = q−1q0 (unit element).
Remark 3.6. Only when g = q−1q0 is satisﬁed, the momentum mapping is invariant.
This is because the momentum mapping is
JL(p, q) = R∗
qp = Ad∗
q−1JR(p, q).
To make sure
JL(p0, q0) = JL(p, q) =⇒Ad∗
q−1
0 JR(p0, q0) = Ad∗
q−1JR(p, q)
=⇒JR(p, q) = Ad∗
qAd∗
q−1
0 JR(p0, q0)
=
Ad∗
(q−1q0)−1JR(p0, q0) = Ad∗
g−1JR(p0, q0).
If g = q−1q0, deriving back, we obtain the momentum mapping is invariant.
Remark 3.7. The above generating function theory can be transformed into the gen-
erating function theory on g (for details see literature[CS90]). That is to say, the above
generating function theory on T ∗G can be reformulated by the exponential mapping in
terms of algebra variables, which has been done by Channell and Scovel[CS90]. Below,
we list only some of their results.
For g ∈G, choose ξ ∈g, so that g = exp (ξ). Then the LPHJ equation can be
transformed into
⎧
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎩
∂s
∂t + H(−ds · ψ(adξ)) = 0,
M0 = −ds · χ(adξ),
M = −ds · ψ(adξ),
(3.6)
where
⎧
⎨
⎩
χ(adξ) = id + 1
2adξ + 1
12ad2
ξ + · · · ,
ψ(adξ) = χ(adξ) · e−adξ ∽χ(adξ) −adξ,
(3.7)
and the condition g = q−1q0 is transformed into
s(ξ, 0) = s0(ξ) = s0(I),
(3.8)
i.e.,
ξ|t=0 = id.

12.3 Generating Function and Lie–Poisson Scheme
519
12.3.2 Construction of Lie–Poisson Schemes via Generating
Function
The generating function theory to construct the symplectic scheme has been described
in detail in the literatures[LQ95a,Fen86,FWQW89]. The next step is to use the generating
function theory to construct the Lie–Poisson schemes. As we know, the generating
function must generate identity transformation at time zero. From the previous sec-
tion, the generating function should satisfy the condition (3.8), i.e., the group element
becomes a unit element at t = 0. We are not able to ﬁnd a generating function univer-
sally applicable to a general Lie–Poisson system after a long time pursuit. Scovel[MS96]
once suggested a possible solution using the Morse bundle theory. However, for the
Hamilton function of quadratic form, we can ﬁnd the low-order generating function.
Below, we will give a brief description:
The Hamiltonian for so(3)∗is H(M) = 1
2MI−1M. From (3.6) and (3.7), using
u as the generating function, we have:
M = −d u · ψ(adξ) = −d u

1 −1
2adξ + 1
12ad2
ξ + O(ad3
ξ)

= −d u + 1
2d u · adξ + O(ad2
ξ).
(3.9)
After substituting H into Equation (3.6) and using expansion of ψ, we have
∂u
∂t + H

−d u + 1
2d u · adξ −O(ad2
xi)

= ∂u
∂t + 1
2

−d u + 1
2du · adξ + O(ad2
ξ)

I−1 
−d u + 1
2d u · adξ + O(ad2
ξ)

=∂u
∂t + 1
2I−1d ud u −1
2I−1d ud u(adξ) + O(ad2
ξ).
(3.10)
Because ξ and time τ have the same order of magnitude, the Equation (3.10) can
be simpliﬁed as
∂u
∂t + H(M) =
∂u
∂t + 1
2I−1 ∂u
∂ξ
∂u
∂ξ −1
2I−1 ∂u
∂ξ
%
∂u
∂ξ adξ
&
+ O(τ 2)
=
∂u
∂t + 1
2I−1 ∂u
∂ξ
∂u
∂ξ + O(τ 2)
= 0.
From this, we can obtain a ﬁrst-order generating function. Taking
u = Iξ · ξ
2τ .
(3.11)
It can be easily veriﬁed that the Equation (3.11) satisﬁes (3.10) to the approximate
order. Therefore, we can use u to construct the Lie–Poisson scheme.

520
12. Poisson Bracket and Lie–Poisson Schemes
We ﬁrst calculate ξ by solving
M0 = −Iξ · χ(ξ),
(3.12)
and then substitute it into Equation (3.6). Next, we calculate M = exp (ξ)M0. On
repeating this procedure, we can obtain a Lie–Poisson algorithm.
Below, we will apply this algorithm to free rigid body. For motion of the rigid
body, χ(ξ) has a closed expression (see Subsection 12.5.2). Solving nonlinear (3.12)
for ξ becomes a key point. It is necessary to linearize (3.12). The iterative formula for
ξ is

1 + τ

c1ξ −

c3ξ(ξ + c4)


(I−1M0 × ξ) + c2(
I−1p0)

δ ξ = ξk+1 −ξk,
where
c1 = 2 −|ξ| sin |ξ| −2 cos |ξ|
|ξ|4
,
c2 = cos |ξ| −1
|ξ|2
,
c3 = −2|ξ| −|ξ| cos |ξ| + 3 sin |ξ|
|ξ|5
,
c4 = 2|ξ| −sin |ξ|
|ξ|3
.
In fact, the above algorithm is applicable even when H is a polynomial.
Ge–Marsden[GM88] have proposed an algorithm, which neglects the generating
function condition (3.8). Therefore, it has certain ﬂaw. Below, we will explain it from
the theoretical point of view.
First, we should point out that the Ge–Marsden algorithm can only give the ﬁrst-
order scheme for simple system such as the free rigid body. Its second-order scheme,
however, is not a second-order approximation to the original system, as we will prove
it below.
Generally speaking, a generating function can be given as the following equation
u = u0 +
∞

n=1
(δt)n
n! un,
(3.13)
where u0 = (ξ, ξ)
2
generates the identical transformation at time t = 0. Substituting
(3.13) into the LPHJ equation, we have
u1 = −H(V ),
u2 = ∂H
∂V · du1 · ψ(adξ), · · · .
(3.14)
Below, we will take so(3)∗as an example to explain the ﬂaw of this algorithm.
For so(3)∗, u0 = ξ2
2 , and hence V = ξ. The ﬁrst-order scheme is
S1 = u0 + τu1 = ξ2
2 −τH(ξ) = ξ2
2 −τ
2ξI−1ξ.
The generating function for the second-order scheme is

12.3 Generating Function and Lie–Poisson Scheme
521
S2 = S1 + τ 2
2 u2 = ξ2
2 −τH(ξ) + τ 2
2
∂H
∂V · du1 · ψ(adξ)
=
ξ2
2 −τ
2ξI−1ξ −τ 2
2 I−1ξ

I−1ξ · ψ(ξ)

.
Using the system of Equation (3.6) (for SO(3) M, M0 denote angular momentum),
we get:
M −M0 = −du · adξ.
(3.15)
Next, we will prove that S1 indeed generates a ﬁrst-order Lie–Poisson scheme to
the Euler equation. However, S2 actually is not a second-order approximation to the
Euler equation. Furthermore, we will ﬁnd that with this algorithm, it is impossible to
construct difference scheme that preserves the momentum mapping.
Because
d S1 = d
%
ξ2
2 −τ
2ξ · I−1ξ
&
= ξ −τI−1ξ
and M0 = −dS1 · χ(adξ) = (−ξ + τI−1ξ) · χ(ξ), we have ξ = −M0 + O(τ). By
Equation (3.15) and applying ξ · adξ = 0, we obtain
M −M0 = (ξ −τI−1ξ) · adξ = −τI−1ξ · adξ
= τ[ξ, I−1ξ] = τ[−M0 + O(τ), I−1(−M0 + O(τ))]
= τ[M0, I−1M0] + O(τ 2).
This is a ﬁrst-order approximation to the Euler equation
˙M = [M, I−1M].
(3.16)
For the second-order generating function S2, we ﬁrst calculate χ(ξ). Let χ(ξ) =
1+a1ξ+a2ξ2, where a1, a2 have closed analytical expression (see Subsection 12.5.2)
as follows
a1 =
1 −cos |ξ|
sin2 |ξ| + (1 −cos |ξ|)2 ,
a2 =
(cos |ξ| −1)2
|ξ|2
+ sin |ξ| −|ξ|
|ξ|
+ (sin |ξ| −|ξ|)|ξ|
sin2 |ξ| + (1 −cos |ξ|)2
,
therefore,
u2 = −I−1ξ(I−1ξ · ψ(ξ))
= −⟨I−1ξ, I−1ξ⟩−a2I−1ξ(I−1ξ · ξ2),
then
d S2 = ξ −τI−1ξ −τ 2(I−1)2ξ −τ 2
2 d

a2I−1ξ · (I−1ξ · ξ2)

,
by

522
12. Poisson Bracket and Lie–Poisson Schemes
M0 = −d S2 · χ(ξ) = −ξ + τξ · χ(ξ) + O(τ 2),
we have
ξ = −M0 + τξ · χ(ξ) + O(τ 2).
From Equation (3.15), we get
M −M0 = −dS2 · adξ
= −(ξ −τI−1ξ −τ 2(
I−1ξ)2 −τ 2
2 d(a2I−1ξ · (I−1ξ · ξ2))) · ξ
= τ[M0, I−1M0] + a1τ 2
[[M0, I−1M0], I−1M0]
+[M0, I−1[M0, I−1M0]]

+a2

I−1M0(I−1M0 · 4
M 2
0 ) + I−1(I−1M0 · 4
M 2
0 )M0

−τ 2
2 d

a2 · I−1ξ(I−1ξ · ξ2)

· ξ + O(τ 3).
(3.17)
According to the Euler equation (3.16), its second-order approximation should be
M −M0 =
τ[M0, I−1M0] + τ 2
2 ([[M0, I−1M0], I−1M0]
+[M0, I−1[I−1M0, M0]]) + O(τ 3).
(3.18)
As t →0, ξ →M0, by comparison, we found that the Equation (3.17) is not an
approximation to the Equation (3.18). Therefore, the generating function S2 cannot
generate the second-order approximation to the Euler equation.
We have shown that S1 generates a ﬁrst-order Lie–Poisson scheme. However, a
momentum mapping preserving scheme should satisfy JL(q, M) = JL(q0, M0). For
T ∗SO(3), this becomes qM = q0M0, and hence M = q−1q0M0. Therefore, it is
necessary to estimate q ∈G. If we had formula M = gM0, a very natural idea is
to make g = q−1q0, which leads to q = q0g−1. An algorithm well constructed on
so(3)∗should lead to a good approximation of q ∈SO(3) to equation of motion. The
scheme that satisﬁes Equations (3.6) and the condition (3.8) and is generated by our
generating function theory that belongs to this type. However, the scheme constructed
via algorithm[GM88] does not belong to this type. Because the condition (3.8) is ne-
glected, it is impossible to construct the algorithm on G using algorithm[GM88]. This
can be illustrated as follows.
Using another representation of (3.6)
M0 = −du · χ(adξ),
M = exp (adξ)M0,
(3.19)
and ξ = (−M0 +τI−1ξ)·χ(ξ), if we let q = q0g−1 = q0 exp (−ξ) = q0 exp ((M0 −
τI−1ξ)·χ(ξ)), then q is not a ﬁrst-order approximation to the equation of motion ˙q =
qI−1 4
M. In fact, the algorithm[GM88] cannot produce the form of q alone to construct
momentum mapping preserving scheme.

12.4 Construction of Structure Preserving Schemes for Rigid Body
523
12.4 Construction of Structure Preserving Schemes for
Rigid Body
We have already introduced the equation of motion for generalized rigid body in pre-
vious section. In this section, we will take SO(3) as an example to explain how to
construct structure-preserving schemes.
12.4.1 Rigid Body in Euclidean Space
Let Λ(t) ∈SO(3), such that Λ(t)Λ(t)T = I, |Λ(t)| = 1. Then the equation of motion
for the free rigid body can be formulated as
˙Λ(t) = Λ(t)4
W(t),
(4.1)
where 4
W(t) ∈so(3), so(3) is the Lie algebra of SO(3). The isomorphism relation,
so(3) ≃R3, can be realized through the following equations:
4
W(t) ≃W(t) ∈R3,
⎡
⎢⎢⎣
0
−w3
w2
w3
0
−w1
−w2
w1
0
⎤
⎥⎥⎦≃
⎡
⎢⎢⎢⎢⎣
w1
w2
w3
⎤
⎥⎥⎥⎥⎦
,
4
W(t) · a = W × a,
a ∈R3.
The 4
W(t) in Equation (4.1) is called angular velocity in the body description. 4
W(t) =
Λ(t)−1 ˙Λ(t) is consistent with the deﬁnition of generalized rigid body. The corre-
sponding Euler equation is
˙M = [M, W],
M = JW,
(4.2)
where J is called inertia operator, M the body angular momentum. The body variables
and the spatial variables have the following relations:
⎧
⎪
⎪
⎨
⎪
⎪
⎩
ω = AW,
m = ΛM,
a = ΛA,
ω = Λ4
WΛT =⇒ω = ΛW,
here A is an acceleration.
Operator “  ” has the following equalities:

524
12. Poisson Bracket and Lie–Poisson Schemes

u × v = [u, v],
u · v = u × v,
[u, v] · w = (u × v) × w,
u · v =
1
2tr (u v).
The equation of motion of the rigid body may be expressed on space SU(2) or SH1
(unit quaternion). Applying their equivalence (their Lie algebra is isomorphism), we
may obtain different forms of the Equation (4.1) under SU(2) and SH1.
SU(2):
U ∈SU(2), satisﬁes
UU ∗= I,
|U| = 1.
The equation of motion becomes
˙U = UΩu,
where Ωu = U ∗U ∈su(2), satisﬁes Ωu + Ω∗
u = 0, tr Ωu = 0. In su(2), we choose
{(−iσ1), (−iσ2), (−iσ3)}
as a basis, where
σ1 =
5 0
1
1
0
6
,
σ2 =
5 0
−i
i
0
6
,
σ3 =
5 1
0
0
−1
6
,
σ0 =
5 1
0
0
1
6
are 4 Pauli matrices.
It is easy to see that
3

i=1
ωiσi =
5
−iω3
−ω2 −iω1
ω2 −iω1
iω3
6
∈SU(2).
Hence
Ωu = (ω1, ω2, ω3) ∈su(2) ≃R3 ≃so(3),
using the matrix notation, rewrite the equation:
5
˙σ
˙β
˙γ
˙δ
6
=
5 σ
β
γ
δ
6 5
−iω3
−ω2 −iω1
ω2 −iω1
iω3
6
.
∀Q ∈SH1, ∥Q∥= 1, Q = (q0, q1, q2, q3) ∈H (set of all quaternion). The equa-
tion of motion becomes ˙Q = QΩh, where Ωh = Q ˙Q = Q−1 ˙Q ∈sh1 (quaternion
with zero real part). Let

12.4 Construction of Structure Preserving Schemes for Rigid Body
525
Ωh = ω1i + ω2j + ω3k = (0, ω1, ω2, ω3),
ωh = (ω1, ω2, ω3).
Rewrite the equation of motion into the quaternion form
( ˙q0, ˙q1, ˙q2, ˙q3)
=
(q0, q1, q2, q3) · (0, ω1, ω2, ω3)
=⇒
 ˙q0 = −qω = −(q, ω),
˙q = q0ωT + qω,
q = (q1, q2, q3).
The Euler equation of motion becomes
so∗
3 :
d M
d t = [M, W];
su∗
2 :
d Mu
d t
= 1
2[Mu, Wu] = [Mu, W],
Mu = 2M,
ωu = 1
2W;
sh∗
1 :
d Mh
d t
= 1
2[Mh, Wh] = [Mh, W],
Mh = 2M,
ωh = 1
2W.
If the uniﬁed Euler equation of motion is used, we have
d M
d t = [M, W].
If ω is assigned using the values of SO(3), then the corresponding equation of motion
becomes:
˙Λ = Λ4
W(t),
W(t) = (ω1, ω2, ω3),
˙Q = QΩh,
Ωh =

0, ω1
2 , ω2
2 , ω3
2

,
˙U = UΩu,
Ωu =
ω1
2 , ω2
2 , ω3
2

.
After the above transformation, the equation of motion becomes more simpler. The
number of unknowns become fewer from the original 9 (SO(3)) to 4 complex vari-
ables (SU(2)), and then reduced to 4 real variables (SH1). The computation storage
and operation may be sharply reduced for large-scale scientiﬁc computations.
More details about the relations among SO(3), SU(2) and SH1 will be given in
Section 12.5.
12.4.2 Energy-Preserving and Angular Momentum-Preserving
Schemes for Rigid Body
With the equation of motion of rigid body, we may construct the corresponding differ-
ence scheme[LQ95a]. One type of important schemes is the structure-preserving scheme.
Structure-preserving may have some different meaning for different systems. For ex-
ample, it could mean to preserve the original system’s physical structure, the symme-
try, or invariant physical quantities.

526
12. Poisson Bracket and Lie–Poisson Schemes
The total energy and the angular momentum, especially the angular momentum,
are important invariants for the rigid motion. Many experiments indicated that the
energy and the angular momentum can be well maintained, which is essential for
computer simulation to have a good approximation to the real motion.
The equation of motion for the rigid body is
⎧
⎨
⎩
˙Λ(t) = Λ(t)4
W(t),
˙M(t) = M(t) × W(t)
M(t) = I · W(t)
/
=⇒I · ˙W(t) = IW(t) × W(t),
where I is the inertia operator.
Note that the energy function H = 1
2(M(t), W(t)) = 1
2
4
W(t)J4
W(t) is a Hamil-
tonian function and the spatial angular momentum M(t) = ΛM(t) ⇔4
M(t) =
Λ4
M(t)Λ(t)T becomes momentum mapping. To maintain the energy and the angu-
lar momentum invariant is just to maintain the Hamilton function and the momentum
mapping of the Lie–Poisson system invariant.
The energy invariance is mainly manifested in solving Euler equations, and the
angular momentum invariance concerns more with equations of motion on SO(3).
Using relation Λn+1Mn+1 = ΛnMn, we can derive the formula for which Λn+1
should satisfy. For Euler equation ˙M(t) = M(t) × W(t) = M(t) × I−1M(t), the
midpoint scheme preserves the Hamiltonian function, i.e., it is energy-preserving (in
fact midpoint scheme preserves all functions of quadratic form).
The midpoint scheme for Euler equation is
Mn+1 −Mn
δ t
= Mn+1 + Mn
2
× I Mn+1 + Mn
2
,
(4.3)
multiply I−1 Mn+1 + Mn
2
via inner product on both sides,
(Mn+1 −Mn) · (I−1(Mn+1 + Mn)) = 0 =⇒I−1Mn+1 · Mn+1 = I−1Mn · Mn,
i.e., Hn+1 = Hn. Since I−1 is a symmetric operator, we have
Mn · I−1Mn+1 = Mn+1 · I−1Mn.
Rewrite scheme (4.3) into
Mn+1
=
Mn + δt
4 (Mn+1 + Mn) × I−1(Mn+1 + Mn)
=⇒
%
I + δt
4 I−1

(Mn+1 + Mn)
&
Mn+1 =
%
I −δt
4 I−1(

Mn+1 + Mn)
&
Mn
=⇒Mn+1 =
%
I + δ t
4 I−1

(Mn+1 + Mn)
&−1 %
I −δt
4 I−1(

Mn+1 + Mn)
&
Mn
=
Λ−1
n+1ΛnMn.

12.4 Construction of Structure Preserving Schemes for Rigid Body
527
By conservation of angular momentum:
Λn+1Mn+1 = ΛnMn.
By comparison, we obtain
Λn+1 = Λn

I −δt
4 I−1(

Mn+1 + Mn)
−1
I + δt
4 I−1(

Mn+1 + Mn)

.
Since
δt
4 I−1

(Mn+1 + Mn) = δt
2 Wn + O(δt2),
from Cayley transformation, we know this is a second-order approximation to equa-
tion ˙Λ = Λ4
W.
In brief, if we construct an energy-preserving scheme on so(3)∗, we may obtain
a scheme approximate to the equation of motion by using the conservation of an an-
gular momentum. We remark that this highly depends on the schemes constructed on
so(3)∗. Not every scheme on so(3)∗corresponds to a good approximation scheme to
the equation of motion on SO(3). Ge–Marsden algorithm for Lie–Poisson system is
a typical example.
12.4.3 Orbit-Preserving and Angular-Momentum-Preserving
Explicit Scheme
The orbit-preserving[LQ95a] here means the motion trajectory remains at coadjoint or-
bit. For rigid body this means in every time step
Mn+1 = ΛnMn,
∃Λn ∈SO(3).
The midpoint scheme constructed in (4.2) is a kind of implicit orbit-preserving
scheme. Below, we will derive explicit orbit-preserving schemes.
The equation is
˙M = M × W = −W × M = −4
W · M,
4
W ∈SO(3),
4
W = I−1M.
Assume the difference scheme to be constructed has the form
Mn+1 = exp (b(δt))Mn.
(4.4)
It is easy to see when b(δt) = −δtWn = −δt(I−1Mn), (4.4) is a ﬁrst-order scheme.
Expanding the scheme (4.4), we obtain
Mn+1 = Mn + b(δt)Mn + 1
2

b(δt)
2Mn + 1
3 !

b(δt)
3Mn + · · · .
(4.5)
Using Taylor expansion, we have

528
12. Poisson Bracket and Lie–Poisson Schemes
Mn+1 = Mn −δt4
WnMn +
 ¨
M
2

δt2 +
M (3)
3!

δt3 + · · ·
= Mn −δt4
WnMn + δt2
2 (Mn × Wn × Wn)
+δt2
2

Mn × I−1(Mn × Wn)

+ · · · .
(4.6)
Let
b(δt) = δtB1 + δt2B2 + δt3B3 + · · · ,
substitute it into (4.5), and retain only the ﬁrst two terms
Mn+1 = Mn + δtB1Mn + δt2B2Mn + 1
2(δtB1 + δt2B2)2Mn + o(δt3)
= Mn + δtB1Mn + δt2B2Mn + 1
2δt2B2
1Mn + o(δt3).
(4.7)
Comparing the coefﬁcients of Equation (4.6) with those of (4.7), we have
B1 = −4
Wn,
(B2
1 + 2B2)Mn = (Mn × Wn × Wn) + (Mn × I−1(Mn × Wn))
= 4
W 2
nMn −

I−1(

Mn × Wn)

Mn,
then
B1 = −4
Wn,
B2 = −1
2

I−1(

Mn × Wn)

.
Likewise, we can construct third or fourth order schemes. Here we give only the result
B3 =
1
6
4
W

I−1( 
M × W)

+ 2I−1( 
M × W)4
W + I−1(

M × W × W)
+

I−1

M × I−1(M × W)

−1
2B1B2 −1
2B2B1.
Another way to construct the orbit-preserving scheme is the modiﬁed R–K method,
which can be described as follows.
If the initial value M0 is known, let:

12.4 Construction of Structure Preserving Schemes for Rigid Body
529
μ0 = M0,
μ1 = eτc10(−
I−1μ0)M0,
μ2 = eτc21(−
I−1μ1)eτc20(−
I−1μ0)M0,
· · ·
μr = eτcr,r−1(−

I−1μr−1)eτcr,r−2(−

I−1μr−2) · · · eτcr,0(−
I−1μ0)M0,
the (r + 1)-th order approximation of the equation is
M = eτcr(−
I−1μr)eτcr−1(−

I−1μr−1) · · · eτc0(−
I−1μ0)M0.
Comparing the coefﬁcients between the above equation and the Taylor expansion
(4.6), we obtain cij and cs. Take r = 1 as an example.
μ1 = eτc10(−
I−1μ0)M0 = eτc10(−
I−1M0)M0 = e−τc10( 
I−1M0)M0
=

1 −τc10 
I−1M0 + τ 2
2 c2
10( 
I−1M0)2 + O(τ 3)

M0,
M = eτc1(−
I−1μ1)eτc0(−
I−1μ0)M0 = e−τc1 
I−1μ1e−τc0 
I−1μ0M0
=

1 −τc1 
I−1μ1 + τ 2
2 c2
1( 
I−1μ1)2 + O(τ 3)

1 −τc0 
I−1M0
+τ 2
2 c2
0( 
I−1M0)2 + O(τ 3)

M0
=

1 −τc0 
I−1M0 −τc1 
I−1μ1 + τ 2
2 c2
0( 
I−1M0)2 + τ 2
2 c2
1( 
I−1μ1)2
+τ 2c0c1 
I−1μ1 · 
I−1M0 + O(τ 3)

M0
=

1 −τc0 
I−1M0 −τc1 
I−1M0 + τ 2c1c10

I−1(M0 × I−1M0)
+τ 2
2 c2
0( 
I−1M0)2 + τ 2
2 c2
1( 
I−1M0)2 + τ 2c0c1( 
I−1M0)2 + O(τ 3)

M0
= M0 −τ(c0 + c1)

I−1M0 · M0 + τ 2c1c10

I−1(M0 × I−1M0) · M0
+τ 2
2 (c2
0 + c2
1 + 2c0c1)( 
I−1M0)2M0 + O(τ 3).
By the Taylor expansion, we have
⎧
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎩
c0 + c1 = 1,
c1c10 = 1
2,
c2
0 + c2
1 + 2c0c1 = (c0 + c1)2 = 1,
=⇒
⎧
⎨
⎩
c0 + c1 = 1,
c1c10 = 1
2.

530
12. Poisson Bracket and Lie–Poisson Schemes
Set c0 = c1 = 1
2, c10 = 1 or c0 = 0, c1 = 1, c10 = 1
2, we obtain a second-order
modiﬁed R–K method.
Literature[CG93] gives the modiﬁed R–K methods for general dynamic system. The
scheme on so(3)∗constructed via the above methods can be written as Mn+1 = ΛMn.
Take Λ−1
n+1Λn = Λ, we obtain Λn+1 = ΛnΛ−1. It is easy to verify that the Λn+1 =
ΛnΛ−1 approximates ˙Λ = ΛW in the same order of accuracy as scheme Mn+1 =
ΛMn.
12.4.4 Lie–Poisson Schemes for Free Rigid Body
We have mentioned how to construct a scheme to preserve the angular momentum
and the Lie–Poisson structure. The free rigid motion is a simple Lie–Poisson sys-
tem. Among existing methods, Ge–Marsden algorithm is a ﬁrst-order method to pre-
serve the Lie–Poisson structure (we thus prove that this method is unable to maintain
angular momentum). In Section 12.3, we introduced a generating-function method
which is slow. We will introduce a fast method in this section. It is a split Lie–Poisson
method[LQ95a]. It is also an angular momentum preserving method.
Because the free rigid motion’s Hamiltonian function is separable, we can use the
composite method to construct Lie–Poisson scheme according to separable system’s
procedure. MacLachlan introduced an explicit method[McL93] which requires analytic
solution for each split subsystem at every step. The midpoint method proposed below
is also an explicit Lie–Poisson method but with few computations.
The rigid motion’s Lie–Poisson equation is
⎡
⎢⎢⎢⎣
˙x1
˙x2
˙x3
⎤
⎥⎥⎥⎦=
⎡
⎢⎢⎢⎣
0
−x3
x2
x3
0
−x1
−x2
x1
0
⎤
⎥⎥⎥⎦
⎡
⎢⎢⎢⎢⎢⎢⎢⎣
∂H
∂x1
∂H
∂x2
∂H
∂x3
⎤
⎥⎥⎥⎥⎥⎥⎥⎦
,
(4.8)
where x = (x1, x2, x3)T ∈R3 is an angular momentum, H = 1
2⟨I−1x, x⟩is a
Hamiltonian function and energy function of system.
For a separable system, I is usually a diagonal matrix. Without loss of generality,
let H = 1
2(a1x2
1 + a2x2
2 + a3x2
3). According to the decomposition rule, the fewer
the split steps the better. We can use Casimir function of the Lie–Poisson equation
to rewrite the system’s Hamilton function, and obtain an equivalent system. Note that
|x|2 =
n

i=1
x2
i is a ﬁrst integral of the system. Let
H = H −1
2a1|x|2 = 1
2(a2 −a1)x2
2 + 1
2(a3 −a1)x2
3 = H1 + H2,
where H1 = 1
2(a2 −a1)x2
2, H2 = 1
2(a3 −a1)x2
3.

12.4 Construction of Structure Preserving Schemes for Rigid Body
531
Substituting H1 into the Lie–Poisson equation (1.1), we have
˙x = J(x) ∂H1
∂x =
⎡
⎢⎢⎣
−(a2 −a1)x2x3
0
(a2 −a1)x1x2
⎤
⎥⎥⎦,
(4.9)
where
J(x) =
⎡
⎢⎢⎣
0
−x3
x2
x3
0
−x1
−x2
x1
0
⎤
⎥⎥⎦.
This equation can be simpliﬁed as a standard symplectic system
 ˙x1 = −(a2 −a1)x2x3,
˙x3 = (a2 −a1)x1x2,
(4.10)
where x2 is a constant.
Among symplectic difference schemes for the standard symplectic system (4.10),
only a few of them can preserve the Lie-Poisson structure of the original system (4.9).
Theorem 4.1. For the system (4.9), the midpoint scheme is a Lie–Poisson scheme[LQ95a].
In order to prove the Theorem 4.1, we need the following lemma ﬁrst.
Lemma 4.2. For the system (4.9), a symplectic algorithm for the standard symplectic
system (4.10) preserves Poisson structure, if and only if the following three conditions
are satisﬁed
⎧
⎪
⎪
⎨
⎪
⎪
⎩
−x11x3 + x13x1 = −x3,
x31x3 −x33x1 = −x1,
x12x1 + x32x3 = 0,
(4.11)
where xi = xn
i , xi = xn+1
i
, xij = ∂xi
∂xj .
Proof. By the Theorem 1.2, a scheme is of Poisson if and only if
%∂x
∂x
&
J(x)
%∂x
∂x
&T
= J(x).
Expanding the above equation, we get

532
12. Poisson Bracket and Lie–Poisson Schemes
⎡
⎢⎢⎣
x11
x12
x13
0
1
0
x31
x32
x33
⎤
⎥⎥⎦
⎡
⎢⎢⎣
0
−x3
x2
x3
0
−x1
−x2
x1
0
⎤
⎥⎥⎦
⎡
⎢⎢⎣
x11
0
x31
x12
1
x32
x13
0
x33
⎤
⎥⎥⎦
=
⎡
⎢⎢⎣
0
−x3
x2
x3
0
−x1
−x2
x1
0
⎤
⎥⎥⎦,
i.e.,
⎡
⎢⎢⎣
0
−x11x3 + x13x1
a13
x11x3 −x13x1
0
x31x3 −x33x1
−a13
x33x1 −x31x3
0
⎤
⎥⎥⎦=
⎡
⎢⎢⎣
0
−x3
x2
x3
0
−x1
−x2
x1
0
⎤
⎥⎥⎦,
where a13 = (x12x3 −x13x2)x31 + (x13x1 −x11x3)x32 + (x11x2 −x12x1)x33.
Since the scheme is symplectic for (4.10), we have
−x13x31 + x11x33 = 1.
So a13 can be simpliﬁed as:
a13 = (x3x31 −x1x33)x12 + (x13x1 −x11x3)x32 + x2.
Comparing the corresponding elements of the matrix on both sides and using the con-
dition x2 = x2, we have
⎧
⎪
⎪
⎨
⎪
⎪
⎩
x11x3 −x13x1 = x3,
x31x3 −x33x1 = −x1,
x12x1 + x32x3 = 0.
Thus before the lemma is proved.
▲
Now we will prove the Theorem 4.1.
Proof. The midpoint scheme for system (4.9) is (here, I = (I1, I2, I3) = (a1, a2, a3))
⎧
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎩
x1 = x1 + τ(I1 −I2) x3 + x3
2
x2,
x2 = x2,
x3 = x3 + τ(I2 −I1) x1 + x1
2
x2.
Its Jacobian matrix is
⎡
⎢⎣
x11
x12
x13
0
1
0
x31
x32
x33
⎤
⎥⎦, where

12.4 Construction of Structure Preserving Schemes for Rigid Body
533
⎧
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎩
x11 = 1 + τ
2(I1 −I2)x2x31,
x12 = τ
2(I1 −I2)(x3 + x3) + τ
2(I1 −I2)x2x32,
x13 = τ
2(I1 −I2)x33x2 + τ
2(I1 −I2)x2,
x31 = τ
2(I2 −I1)x11x2 + τ
2(I2 −I1)x2,
x32 = τ
2(I2 −I1)(x1 + x1) + τ
2(I2 −I1)x2,
x33 = 1 + τ
2(I2 −I1)x2x13.
Solving the above equations, we get
⎧
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎩
x11 = x33 = 1 −a2
1 + a2 ,
x12 =
τ
2 (I1 −I2)x3
1 + a2
,
x13 = −x31 = −
2a
1 + a2 ,
x32 =
τ
2 (I2 −I1)x1
1 + a2
,
(4.12)
where
a = τ
2(I2 −I1)x2.
(4.13)
Substituting the system of Equations (4.12) into condition (4.11), we ﬁnd that all con-
ditions are satisﬁed. Therefore, by Lemma 4.2, the scheme is of Poisson.
▲
Lemma 4.3. [FQ91] Consider dynamic system ˙x = a(x). If a can be split into a =
a1 + a2 + · · · + ak, and gs ∽es
a is phase ﬂow of a dynamic system, then
gs
i ∽es
ai,
2nd-order,
∀i =⇒g
s
2
1 ◦· · · g
s
2
k ◦g
s
2
k ◦· · · g
s
2
1 ∽es
a,
2nd-order.
Proof. For the standard symplectic system (4.10), the generalized Euler scheme
x = x + τJ∇H(Bx + (I −B)x)
is symplectic, iff
B = 1
2(I + C),
JC + CTJ = O.
(4.14)
It is natural to ask what kind of symplectic difference scheme for the system (4.10)
is also a Poisson scheme for the system (4.9). Below we restrict our discussion to the
generalized Euler scheme (4.14).
Let C =
 c1
c2
c3
c4
!
, then the symplectic condition (4.14) turns into c4 = −c1.
Therefore,

534
12. Poisson Bracket and Lie–Poisson Schemes
B = 1
2
5
1 + c1
c2
c3
1 −c1
6
,
then
Bx + (I −B)x =
1
2
5 (1 + c1)x1 + (1 −c1)x1 + c2(x3 −x3)
c3(x1 −x1) + (1 −c1)x3 + (1 −c1)x3
6
=
1
2
5 z1
z3
6
,
(4.15)
then Euler scheme becomes
 x1 = x1 −az3,
x3 = x3 −az1,
(4.16)
where a is deﬁned by Equation (4.13), z1, z3 are deﬁned by Equation (4.15).
After complex computations, the elements of Jacobian matrix of the solution are
x11 = (1 + ac3)(1 −ac2) −a2(1 −c1)2
(1 + ac3)(1 −ac2) + a2(1 −c2
1) ,
x13 =
−2a(1 −ac2)
(1 + ac3)(1 −ac2) + a2(1 −c2
1),
x3 = ((1 + ac3)(1 −ac2) −a2(1 −c1)2)x3 + 2a(1 + ac3)x1
(1 + ac3)(1 −ac2) + a2(1 −c2
1)
,
x11x3 −x13x1 = x3
(see (4.11)).
Since x1, x3 are arbitrary real number, we can get
c1 = 0,
c2 = −c3.
(4.17)
Substituting Equation (4.17) into (4.16), and recalculating the Jacobian matrix, we
have
x31 =
2a(1 −ac2)
a2 + (1 −ac2)2 ,
x33 = (1 −ac2)2 −a2
a2 + (1 −ac2)2 ,
x1 = ((1 −ac2)2 −a2)x1 −2a(1 −ac2)x3
a2 + (1 −ac2)2
.
It is easy to see that one of the conditions (4.11)
x31x3 −x33x1 = −x1
is satisﬁed. Likewise, we can prove that another condition of (4.11) is also satisﬁed.
From (4.17), we have C = cJ, where c is an arbitrary constant and

12.4 Construction of Structure Preserving Schemes for Rigid Body
535
J =
5
0
1
−1
0
6
.
Therefore, the lemma is completed.
▲
12.4.5 Lie–Poisson Scheme on Heavy Top
The Lie–Poisson algorithm as we discussed in the previous sections are based on the
dual space of semi-simple Lie algebra. In practice, we often have some Lie-Poisson
system whose conﬁguration space is not based on semi-simple Lie algebra, but on the
dual space of the semi-product of Lie algebra and linear space. Such systems include
but not limited to heavy top and compressible hydrodynamics ﬂows. The reader can
refer to literature[MRW90] for a more detailed discussion. In such conﬁguration space,
there exists no momentum mapping as we discussed in previous sections. The angu-
lar momentum is preserved only along a speciﬁc direction. Therefore, the generating
function theory is no longer valid. However, using Lie–Poisson equations under local
coordinates, we can construct the Lie–Poisson algorithm and the angular momentum
preserving scheme. We will illustrate this by heavy top as an example.
Heavy top is a gravity body under the action of gravity with a ﬁxed point. The free
rigid body is a heavy top with the ﬁxed point in center of mass. Its conﬁguration space
is 3 dimensional Euclid space E(3). Its Lie algebra is no longer semisimple. Its phase
space e∗(3) has 6 coordinates {x1, x2, x3, p1, p2, p3}. The Poisson bracket operation
on e∗(3) is
{xi, xj} = εijkxk,
{xi, pi} = εijkpk,
{pi, pj} = 0,
(4.18)
where
εijk =
 (i, j, k),
i, j, k is not the same,
0,
i, j, k is the same.
There are two independent Casimir functions for bracket (4.18)
f1 =
3

i=1
p2
i ,
f2 =
3

i=1
pixi.
Let H(x, p) be the Hamiltonian function of system. Introducing notation ui =
∂H
∂pi , Ωi = ∂H
∂xi . Then the Lie–Poisson equation has the form of Kirchhoff equation
˙p = [p, Ω],
˙x = [x, ω] + [p, u],
(4.19)
where square bracket denotes cross product. H is the system’s energy, x and p are
angular momentum, and momentum under momentum coordinate. For a general case,
energy H is of quadratic form about x, p, and positive deﬁnite, which can be given as
follows

536
12. Poisson Bracket and Lie–Poisson Schemes
2H =
3

i=1
aix2
i +
3

i,j=1
bij(pixj + xipj) +
3

i,j=1
cijpipj.
(4.20)
For heavy top, the energy is often expressed as the sum of kinetic energy and
potential energy, i.e.,
H(x, p) = x2
1
2I1 + x2
2
2I2 + x2
3
2I3 + γ1p1 + γ2p2 + γ3p3,
(4.21)
where Ii is the main movement inertia of the rigid body, γi (i = 1, 2, 3) are three
coordinates of the center of mass. It is easy to see that this is a separable system.
The structure matrix of the Lie–Poisson system is
5 J(x)
J(p)
J(p)
O
6
,
where J(x) is deﬁned in Subsection 12.4.4.
It is difﬁcult to construct Lie–Poisson algorithm on heavy top than on the free rigid
body because the generating function methods are no longer suitable. However, it may
become easier by the composition method and the Lemma 4.3.
We will ﬁrst split the Hamiltonian function H of heavy top system into six part
H =
6

i=1
Hi, where
Hi = x2
i
2Ii ,
Hi+3 = γipi,
i = 1, 2, 3.
We will take H1, H4 as examples to construct Lie–Poisson scheme.
First, we will take H1 as the Hamilton function, then
5 ˙x
˙p
6
=
5 J(x)
J(p)
J(p)
0
6 ⎡
⎣
∂H1
∂x
0
⎤
⎦,
after manipulating, we get
⎧
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎩
x1 = 0,
x2 = x3x1
I1 ,
x3 = −x2x1
I1 ,
p1 = 0,
p2 = x1p3
I1 ,
p3 = −x1p2
I1 .
(4.22)

12.4 Construction of Structure Preserving Schemes for Rigid Body
537
Theorem 4.4. The Midpoint scheme of (4.22) is Poisson scheme for heavy top.
Proof. By Theorem 1.2, the midpoint scheme is the Poisson scheme iff mapping
(x, p) −→(x, p)
satisﬁes
⎡
⎢⎢⎣
∂x
∂x
∂x
∂p
∂p
∂x
∂p
∂p
⎤
⎥⎥⎦
5 J(x)
J(p)
J(p)
O
6⎡
⎢⎣
∂x
∂x
∂p
∂x
∂x
∂p
∂p
∂p
⎤
⎥⎦=
5 J(x)
J(p)
J(p)
O
6
.
(4.23)
Denote
∂y
∂z

= yz, then the expand Equation (4.23),
⎧
⎪
⎪
⎨
⎪
⎪
⎩
xxJ(x)xT
x = J(x),
xxJ(x)pT
x + xxJ(p)pT
p = J(p),
pxJ(x)pT
x + ppJ(p)pT
x + pxJ(p)pT
p = 0.
(4.24)
From the results of Subsection12.4.4, the ﬁrst equation of system (4.24) is obviously
hold. Note also
px =
⎡
⎢⎢⎣
0
p21
p31
0
0
0
0
0
0
⎤
⎥⎥⎦,
pp =
⎡
⎢⎢⎣
1
0
0
0
p22
p23
0
p32
p33
⎤
⎥⎥⎦,
where p21 = ∂p2
∂x1 , p31 = ∂p3
∂x1 , pij = ∂pi
∂pj (i, j = 2, 3). Through the computation,
we have
p22 = x22,
p23 = x23,
p32 = x32,
p33 = x33,
p21 =
τ p3
I1
1 + a2 ,
p31 =
−τ p2
I1
1 + a2 ,
(4.25)
where a is deﬁned by the Euler scheme (4.16).
Substituting (4.25) into Equation (4.24), the 2nd and 3rd equations of (4.24) are
also hold.
▲
If H4 is taken as Hamiltonian function of a system, the equation degenerates into
a constant equation. Then constructing Lie–Poisson scheme is trivial.
For a Hamiltonian function of general form, we need to perform a transformation,
so that the equation is easier for constructing the Lie–Poisson scheme. Take the free
rigid body as the example.
For a quadratic form, we have

538
12. Poisson Bracket and Lie–Poisson Schemes
H = Hi + Hij = 1
2aix2
i + 1
2aij(xi + xj)2,
i.e., we can eliminate the mixed items and transform it into a sum of squares. Next,
we can construct Lie–Poisson scheme for system with Hij as Hamiltonian function.
Take H12 as an example
˙x = J(x)∂H12
∂x .
(4.26)
It is easy to see that x1 + x2 is a Casimir function of system. Expanding Equation
(4.26) yields
⎡
⎢⎢⎣
˙x1
˙x2
˙x3
⎤
⎥⎥⎦=
⎡
⎢⎢⎣
−a12x3(x1 + x2)
a12x3(x1 + x2)
a12(x2
1 −x2
2)
⎤
⎥⎥⎦.
(4.27)
Since x1 + x2 is a constant, denote c = x1 + x2, the Equation (4.27) becomes
⎧
⎪
⎪
⎨
⎪
⎪
⎩
˙x1 = −ca12x3,
˙x2 = ca12x3,
˙x3 = ca12(c −2x2).
(4.28)
The midpoint scheme to the above equations is no longer Lie–Poisson scheme. How-
ever, we can solve system of the Equations (4.28) analytically without difﬁculty.
12.4.6 Other Lie–Poisson Algorithm
Apart from the Lie–Poisson algorithm described above, we have other Lie–Poisson
algorithms, which include but not limited to Scovel and MacLaclan[MS95] constrained
Hamiltonian algorithm, and Veselov[Ves91b,Ves88] discrete Lagrangian system approach,
as well as the reduction method mentioned before. Below, we will give a brief intro-
duction to these method.
1.
Constrained Hamiltonian algorithm
The detailed description about the constrained Hamiltonian algorithm can be
found in literature[MS95] and its references. Here we apply it to rigid motion only.
The structure space for a rigid motion is SO(n) = N. Take a larger linear space
M = gl(n). Then the constraint function of N on M is
φ(q) = qTq −1,
∀q ∈M.
Note that φ(q) = 0 on N, and d φ(q) = Tq(M) →R is a differential mapping.
Assume on T ∗M, there exists a non-constraint system of Hamiltonian equations
 ˙p = −∂qH,
˙q = ∂pH.

12.4 Construction of Structure Preserving Schemes for Rigid Body
539
Then on T ∗N, if the local coordinates (p, q) on T ∗M is still used, we should have
φ(q) = 0 =⇒dφ · ˙q = dφ · ∂pH = {H, φ}.
Therefore, on T ∗M, there exists an embedded submanifold
CM = {(p, q) ∈T ∗M : φ(q) = 0, {H, φ} = 0},
which can induce a mapping
ψ :
CM −→T ∗M,
(p, q) →(p−, q),
where p−= ψ(p, q). It is easy to verify that this is an isomorphic mapping and pre-
serving the symplectic structure.
There exist constrained equations of dynamic system on CM,
 ˙q = ∂pH,
˙p = −∂qH + dφ · μ.
(4.29)
If it is easy to construct structure-preserving scheme for the Equation (4.29) (e.g. when
(4.29) is a separable system), then we can use map ψ to induce the algorithm on TN.
Take SO(n) as an example.
On TM we have a Lagrangian function L(q, ˙q) = 1
2 tr ( ˙qJ ˙qT). Using the Legen-
dre transformation, we can obtain Hamiltonian function H(p, q) = 1
2 tr (pJ−1pT) on
T ∗M. Therefore, using (4.29), we can obtain the constrained Hamiltonian equation of
the dynamic system:
⎧
⎨
⎩
˙q = 1
2pJ−1,
˙p = dψ · μ = 2qμ,
(4.30)
which is a separable Hamilton system obviously. It is easy to construct the ex-
plicit symplectic difference scheme. But on TN, the Hamiltonian function becomes
H(p, q) = 1
4tr (I−1(qTp)(qTp)T), and its Hamiltonian equations are
⎧
⎪
⎪
⎨
⎪
⎪
⎩
˙q = qI−1(qTp) = ∂H
∂p ,
˙p = pI−1(qTp) = −∂H
∂q ,
(4.31)
where q ∈SO(n), qTp ∈so(n). This is not a separable Hamilton system. Therefore,
constructing its symplectic difference method will be difﬁcult and computationally
complicated. However using (4.30) and maps ψ, we can construct the algorithm for
SO(n) easily. Note that ψ(p) = 1
2(p −qpTq) in this case.
Scovel and McLachlan[MS95]proved this algorithm preserves the momentum map-
ping. We remark that the constraint Hamiltonian system has advantage only when the

540
12. Poisson Bracket and Lie–Poisson Schemes
expansion system is separable. Otherwise this algorithm is impractical. Take the rigid
body as an example. On T ∗SO(3), if Euler equation is to be solved, there are only
6 unknowns. If we expand it to T ∗GL(n), the number of unknown becomes 18. If
system is not separable, then the computation cost will deﬁnitely increase.
2.
Veselov–Moser algorithm
Veselov–Moser algorithm[MV91] is to discretize Lagrange function ﬁrst and then
apply Legendre transformation to the discrete Lagrange function. The constructed al-
gorithm preserves discreted symplectic structure, thus also preserves system’s Lie–
Poisson structure. The concrete procedure is as follows:
1◦
First discretize the Lagrange function.
2◦
Add constraint and ﬁnd the solution for δS = 0.
3◦
Obtain the discrete equation.
4◦
Solve this equation.
For SO(n), S =
n

k=1
tr (XkJXT
k+1). The constrained Lagrange function is
L = S +
n

k=1
(XkXT
k −1),
then
δL = 0 =⇒Xk+1J + Xk−1J = ΛkXk,
∀k ∈Z,
from this, we can have a system of equations
 Mk+1 = wkMkw−1
k ,
Mk = wT
k J −Jwk,
wk ∈O(n),
(4.32)
where wk = X−1
k+1Xk. It is easy to prove that this discrete system of equations con-
verges to continuous system of Euler-Arnold equations:

˙M = [M, Ω],
M = JΩ + ΩJ,
Ω ∈o(n).
(4.33)
To solve Equation (4.32), the key lies in solving for wk. In order to make iteration
(Xk, Yk) →(Xk+1, Yk+1) symplectic, Yk = Xk+1, we need
Yk+1J + XkJ = ΛkXk+1,
Λk ∈Sm(n).
This is because
Yk+1J + XkJ = Xk+1wT
k+1J + XkJ
= Xk+1(wT
k+1J + XT
k+1XkJ)
= Xk+1(wT
k+1J + wkJ).

12.4 Construction of Structure Preserving Schemes for Rigid Body
541
See also
JwT
k −wkJ = Mk+1 = wT
k+1J −Jwk+1,
then
JwT
k + Jwk+1 = wT
k+1J + wkJ,
i.e., wT
k+1J + wkJ is symmetric. Thus ∃Λk, Λk = ΛT
k , so that
Xk+1(wT
k+1J + wkJ) = ΛkXk+1.
Therefore,
Yk+1J + XkJ = ΛkXk+1
satisﬁes symplectic condition.
The next question is how to solve wT
k J −Jwk = Mk = tmk for wk? The nu-
merical experiments show that not all solutions wk that satisfy Equations (4.32) are
the solutions we want. To solve ωk quickly, we propose to use the Quaternion method.
w ∈SO(3) corresponds to an element q = (q0, q1, q2, q3) in SH1. Their relations
will be given in Section 12.5. Then the second equation in Equation (4.32) becomes
⎧
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎩
2(α2 −α1)q2q1 + 2(α1 + α2)q3q0 = −δtm3,
2(α3 −α1)q3q1 −2(α3 + α1)q2q0 = δtm2,
2(α3 −α2)q3q2 + 2(α3 + α2)q1q0 = −δtm1,
in addition,
q2
0 + q2
1 + q2
2 + q2
3 = 1.
Solving the above nonlinear equations for (q0, q1, q2, q3) is not an easy task. We found
that when iteration step size is small, q0, q1, q2, q3 behaves reasonable. However, when
the step size is large, the solution behaves erratically. Numerical experiments show that
solving these nonlinear equations is quite time-consuming, and hence this method is
not recommended in practice.
3.
Reduction method
Reduction method bases on the momentum mapping discussed in previous sec-
tions. We have mentioned that the solution of a Lie–Poisson system lies in a coadjoint
orbit in Section 12.2, and this orbit has non-degenerated symplectic structure. If we
can construct the symplectic algorithm on this reduced orbit, then this algorithm is
naturally Lie–Poisson. Moreover it preserves the Casimir function and also preserves
the orbit. Below, we will take SO(3) as an example to illustrate this method.
The coadjoint orbit of SO(3) is a two dimensional spherical surface Sr
2. On Sr
2,
we have a symplectic structure
ωμ(ξg∗(μ), ηg∗(μ)) = −μ[ξ, η],
and Hamiltonian function
Hμ(Ad∗
g−1μ) = 1
2I−1(Ad∗
g−1μ)2,

542
12. Poisson Bracket and Lie–Poisson Schemes
where Ad∗
g−1μ denotes an element on Sr
2.
How to choose the chart and local coordinate on Sr
2, so that the symplectic struc-
ture becomes simple, is very important. We once selected the spherical coordinate to
be the local coordinate and the corresponding symplectic structure and Hamiltonian
function become very complicated. However, if the Euler angle coordinate is used, the
equations become very simple.
Let
Sr
2 = {(x, y, z) | x2 + y2 + z2 = r2},
where x, y, z are three angular momentums in the body description. Using Euler angle
coordinate θ, ψ to do the following coordinate transformation:
⎧
⎪
⎪
⎨
⎪
⎪
⎩
x = r sin θ cos ϕ,
y = r sin θ sin ϕ,
z = r cos θ.
Lie–Poisson (Euler) equation may become the following Hamiltonian equations:
⎧
⎪
⎨
⎪
⎩
˙θ = −
1
r sin θ
∂H
∂ϕ ,
˙ϕ =
1
r sin θ
∂H
∂θ ,
(4.34)
where
H = 1
2
%
r2 sin2 θ cos2 ϕ
I1
+ r2 sin2 θ sin2 ϕ
I2
+ r2 cos2 θ
I3
&
.
We can construct a non-standard symplectic algorithm for Equations (4.34) or we can
simplify the problem further by transformation
(θ, ϕ) →(cos θ, ϕ) = (x1, x2),
then
⎧
⎪
⎨
⎪
⎩
d x1
d t = 1
r
∂H
∂x2 ,
d x2
d t = −1
r
∂H
∂x1 .
This is a Hamiltonian system with standard symplectic structure, and its symplectic
algorithm is easy to construct.
To sum up, constructing Lie–Poisson scheme for a Lie–Poisson system has three
methods. The ﬁrst method is to lift it to T ∗G and construct the symplectic algorithm
(includes constraint Hamiltonian method) on it. The second is the direct construction
based on g∗(generating function method and composition method). The third is to
construct symplectic algorithm on the reduced coadjoint orbit.

12.5 Relation Among Some Special Group and Its Lie Algebra
543
12.5 Relation Among Some Special Group and Its Lie
Algebra
In this section, we present relation among special group and its Lie algebra.
12.5.1 Relation Among SO(3), so(3) and SH1, SU(2)
Let
Λ ∈SO(3),
ΛΛ = 1,
|Λ| = 1,
ξ ∈so(3) =⇒ξ + ξ T = 0,
q ∈SH1 is a normal Quaternion q = (q0, q) = (q0, q1, q2, q3), q = (q1, q2, q3),
q2
0 + ∥q∥2 = 1 = q2
0 + q2
1 + q2
2 + q2
3.
We assume
∀ξ ∈R3,
ξ = (ξ1, ξ2, ξ3) =⇒ξ =
⎡
⎢⎢⎣
0
−ξ3
ξ2
ξ3
0
−ξ1
−ξ2
ξ1
0
⎤
⎥⎥⎦∈so(3),
ξ is called the axial quantity of ξ. When A ∈so(3), A expresses its axial quantity.
1.
Transformation between SO(3) and SH1
∀q ∈SH1, x ∈q0 ≃R3, qxq−1 represents a rotation of x. Using isomorphic
mapping:
A(q) =
 
q0 + q1i
q2 + q3i
−q2 + q3i
q0 −q1i
!
,
H ≃C2,
we can obtain ∀q ∈H, ∃Λ ∈SO(3), ∀x ∈R3, we have
A(qxq−1) = A(0, Λx).
From this we can get Λ.
Given q = (q0, q1, q2, q3), then
Λ = 2
⎡
⎢⎢⎢⎢⎣
q2
0 + q2
1 −1
2
q1q2 −q0q3
q0q2 + q1q3
q1q2 + q0q3
q2
0 + q2
2 −1
2
q2q3 −q0q1
q1q3 −q0q2
q0q1 + q2q3
q2
0 + q2
3 −1
2
⎤
⎥⎥⎥⎥⎦
,
or simplify as
Λ = (2q2
0 −1)1 + 2q0q + 2q ⊗q.
It is easy to see that, if Λ = (Λij) is known, then

544
12. Poisson Bracket and Lie–Poisson Schemes
q0 = 1
2
√
1 + tr Λ,
q1 = (Q32 −Q23)
4q0
q2 = (Q13 −Q31)
4q0
q3 = (Q21 −Q12)
4q0
⎫
⎪
⎪
⎪
⎪
⎪
⎬
⎪
⎪
⎪
⎪
⎪
⎭
=⇒q =
1
4q0 (Λ −ΛT).
2.
Relation between so(3) and SO(3)
The relation between so(3) and SO(3) is the relation between Lie algebra and Lie
group. Let ξ be an antisymmetry matrix for the axial quantity ξ, then exp (ε) denotes
a rotation in SO(3). We have the expansion
exp (ξ) =
∞

n=0
1
n !
ξ
n
∈SO(3).
According to the properties of SO(3), this expansion has a closed form, i.e., the Ro-
drigue formula
Λ = exp (ξ) = 1 + sin ∥ξ∥
∥ξ∥
ξ + 1
2
sin2
% 1
2∥ξ∥
&
% 1
2∥ξ∥
&2
ξ
2
.
We have two proofs of the above formula: one is from the geometry point of view and
the other is from algebra point of view. Below, we will give details on the algebraic
proof.
∀ξ ∈so(3), the following results hold after simple calculations:
ξ
3
= −ξ,
ξ
4
= −ξ
2
,
|ξ| = 1.
Substitute them into the above series expansion,
exp (ξ) = exp (∥ξ∥· n)

n =
ξ
∥ξ∥

= 1 + sin ∥ξ∥n + (1 −cos ∥ξ∥)n2
= 1 + sin ∥ξ∥
∥ξ∥
ξ + 1
2
sin2 1
2∥ξ∥
% 1
2∥ξ∥
&2 ξ
2
.
We can prove that ∥ξ∥is the angle of rotation exp (ξ).

12.5 Relation Among Some Special Group and Its Lie Algebra
545
3.
Transformation between SO(3) and SH1
The relation between SO(3) and SH1 is manifested by the relation between so(3)
and SH1. A rotation in SO(3), (θ, n) ↔(∥ξ∥, ξ),
∀(∥ξ∥, ξ) ∈SO(3) =⇒ξ ∈so(3)
=⇒q0 = cos 1
2∥ξ∥,
q
=
1
2
⎛
⎝
sin 1
2∥ξ∥
1
2∥ξ∥
⎞
⎠ξ.
When ∥ξ∥≪1, we use
sin x
x
= 1 −x2
6 + x4
120 −
x6
5040
to deal with the singularity situation.
If q2
0 + ∥q∥2 ̸= 1, normalization is needed, which is just divided by

q2
0 + ∥q∥2.
Given (q0, q) ∈SH1, we need to solve for ξ. Since ξ has the same direction as q,
we have
ξ = ∥ξ∥
q
∥q∥,
where ∥ξ∥can be given by ∥ξ∥= 2 sin−1(∥q ∥).
12.5.2 Representations of Some Functions in SO(3)
By deﬁnition, we have
iex(ξ) =
∞

n=0
ξn
(n + 1) !,
χ(ξ)iex(−ξ) = Idξ.
For ξ ∈so(3), from
% ξ
∥ξ∥
&3
= −
ξ
∥ξ∥, we have
iex(−ξ) =
∞

n=0
(−ξ)n
(n + 1)! =
∞

k=0
(ξ)2k
(2k + 1)! +
∞

k=0
(−ξ)2k+1
(2k + 2)!
= 1 +
∞

k=1
(−1)k+1∥ξ∥2k
(2k + 1)!
% ξ
∥ξ∥
&2
+
∞

k=0
(−1)k+1∥ξ∥2k+1
(2k + 2)!
·
ξ
∥ξ∥
= 1 + |ξ| −sin |ξ|
|ξ|3
ξ
2
+ cos |ξ| −1
|ξ|2
ξ
= 1 + c1ξ + c2ξ
2
,

546
12. Poisson Bracket and Lie–Poisson Schemes
where c1 =
cos |ξ| −1
|ξ|2
, c2 =
|ξ| −sin |ξ|
|ξ|3
.
χ(ξ) can be obtained by formula
χ(ξ)iex(−ξ) = Idξ.
Let χ(ξ) = 1 + a1ξ + a2ξ
2
, then
χ(ξ)iex(−ξ) = (1 + a1ξ + a2ξ
2
)(1 + c1ξ + c2ξ
2
)
= 1 + (a1 + c1)ξ + (a1c1 + c2 + a2)ξ
2
+ (a1c2 + a2c1)ξ
3
+ a2c2ξ
4
= 1 + (a1 + c1 −(a1c2 + a2c1)|ξ|2)ξ + (c2 + a2 + a1c1 −a2c2|ξ|2)ξ
2
= Id,
therefore
 a1 + c1 −(a1c2 + a2c1)|ξ|2 = 0,
a1c1 + c2 + a2 −a2c2|ξ|2 = 0.
Solving the above equations, we have
a1 =
−c1
(1 −c2|ξ|2)2 + c2
1|ξ|2 =
1 −cos |ξ|
(sin |ξ|)2 + (1 −cos |ξ|)2 ,
a2 =
−c2 + c2|ξ|2 + c2
1
(1 −c2|ξ|2)2 + c2
1|ξ|2 =
(cos |ξ| −1)2
|ξ|2
+ sin |ξ| −|ξ|
|ξ|
+ (sin |ξ| −|ξ|)|ξ|
(sin |ξ|)2 + (1 −cos |ξ|)2
.

Bibliography
[AKW93] M. Austin, P. S. Krishnaprasad, and L.-S. Wang: Almost Poisson integration of rigid
body systems. J. of Comp. Phys., 107:105–117, (1993).
[AM78] R. Abraham and J. E. Marsden: Foundations of Mechanics. Addison-Wesley, Reading,
MA, Second edition, (1978).
[AN90] A. I. Arnold and S.P. Novikov: Dynomical System IV. Springer Verlag, Berlin Heidel-
berg, (1990).
[Arn89] V. I. Arnold: Mathematical Methods of Classical Mechanics. Springer-Verlag, GTM
60, Berlin Heidelberg, Second edition, (1989).
[CFSZ08] E. Celledoni, F. Fass`o, N. S¨afstr¨om, and A. Zanna: The exact computation of the
free rigid body motion and its use in splitting methods. SIAM J. Sci. Comput., 30(4):2084–
2112, (2008).
[CG93] P. E. Crouch and R. Grossman: Numerical integration of ordinary differential equa-
tions on manifolds. J. Nonlinear. Sci., 3:1–33, (1993).
[CS90] P. J. Channell and C. Scovel: Symplectic integration of Hamiltonian systems. Nonlin-
earity, 3:231–259, (1990).
[CS91] P. J. Channel and J. S. Scovel: Integrators for Lie–Poisson dynamical systems. Physica
D, 50:80–88, (1991).
[Fen85] K. Feng: On difference schemes and symplectic geometry. In K. Feng, editor, Pro-
ceedings of the 1984 Beijing Symposium on Differential Geometry and Differential Equa-
tions, pages 42–58. Science Press, Beijing, (1985).
[Fen86] K. Feng: Symplectic geometry and numerical methods in ﬂuid dynamics. In F. G.
Zhuang and Y. L. Zhu, editors, Tenth International Conference on Numerical Methods in
Fluid Dynamics, Lecture Notes in Physics, pages 1–7. Springer, Berlin, (1986).
[FQ87] K. Feng and M.Z. Qin: The symplectic methods for the computation of Hamiltonian
equations. In Y. L. Zhu and B. Y. Guo, editors, Numerical Methods for Partial Differential
Equations, Lecture Notes in Mathematics 1297, pages 1–37. Springer, Berlin, (1987).
[FQ91] K. Feng and M.Z. Qin: Hamiltonian algorithms for Hamiltonian systems and a com-
parative numerical study. Comput. Phys. Comm., 65:173–187, (1991).
[FWQ90] K. Feng, H.M. Wu, and M.Z. Qin: Symplectic difference schemes for linear Hamil-
tonian canonical systems. J. Comput. Math., 8(4):371–380, (1990).
[FWQW89] K. Feng, H. M. Wu, M.Z. Qin, and D.L. Wang: Construction of canonical dif-
ference schemes for Hamiltonian formalism via generating functions. J. Comput. Math.,
7:71–96, (1989).
[Ge91] Z. Ge: Equivariant symplectic difference schemes and generating functions. Physica
D, 49:376–386, (1991).
[GM88] Z. Ge and J. E. Marsden: Lie–Poisson–Hamilton–Jacobi theory and Lie–Poisson in-
tegrators. Physics Letters A, pages 134–139, (1988).
[HV06] E. Hairer and G. Vilmart: Preprocessed discrete Moser–Veselov algorithm for the full
dynamics of the rigid body. J. Phys. A, 39:13225–13235, (2006).
[Kar04] B. Karas¨ozen: Poisson integrator. Math. Comput. Modelling, 40:1225–1244, (2004).
[Lie88] S. Lie: Zur theorie der transformationsgruppen. Christiania, Gesammelte Abh., Christ.
Forh. Aar., 13, (1988).

548
Bibliography
[LQ95a] S. T. Li and M. Qin: Lie–Poisson integration for rigid body dynamics. Computers
Math. Applic., 30:105–118, (1995).
[LQ95b] S. T. Li and M. Qin: A note for Lie–Poisson– Hamilton–Jacobi equation and Lie–
Poisson integrator. Computers Math. Applic., 30:67–74, (1995).
[McL93] R.I. McLachlan: Explicit Lie–Poisson integration and the Euler equations. Physical
Review Letters, 71:3043–3046, (1993).
[MR99] J. E. Marsden and T. S. Ratiu: Introduction to Mechanics and Symmetry. Number 17
in Texts in Applied Mathematics. Springer-Verlag, Berlin, Second edition, (1999).
[MRW90] J.E. Marsden, T. Radiu, and A. Weistein: Reduction and hamiltonian structure on
dual of semidirect product Lie algebra. Contemporary Mathematics, 28:55–100, (1990).
[MS95] R. I. McLachlan and C. Scovel: Equivariant constrained symplectic integration. J.
Nonlinear. Sci., 5:233–256, (1995).
[MS96] R. I. McLachlan and C. Scovel: A Survey of Open Problems in Symplectic Integration.
In J. E. Mardsen, G. W. Patrick, and W. F. Shadwick, editors, Integration Algorithms and
Classical Mechanics, pages 151–180. American Mathematical Society, New York, (1996).
[MV91] J. Moser and A. P. Veselov: Discrete versions of some classical integrable systems and
factorization of matrix polynomials. Communications in Mathematical Physics, 139:217–
243, (1991).
[MW83] J.E. Marsden and A. Weinstein: Coadjoint orbits, vortices and Clebsch variables for
incompressible ﬂuids. Phys D, 7: (1983).
[MZ05] R.I. McLachlan and A. Zanna: The discrete Moser–Veselov algorithm for the free
rigid body. Foundations of Computational Mathematics, 5(1):87–123, (2005).
[Olv93] P. J. Olver: Applications of Lie Groups to Differential Equations. GTM 107. Springer-
Verlag, Berlin, Second edition, (1993).
[Qin89] M. Z. Qin: Cononical difference scheme for the Hamiltonian equation. Mathematical
Methodsand in the Applied Sciences, 11:543–557, (1989).
[TF85] H. Tal-Fzer: Spectral method in time for hyperbolic equations. SIAM J. Numer. Anal.,
23(1):11–26, (1985).
[Ves88] A.P. Veselov: Integrable discrete-time systems and difference operators. Funkts. Anal.
Prilozhen, 22:1–33, (1988).
[Ves91] A.P. Veselov: Integrable maps. Russian Math. Surveys,, 46:1–51, (1991).
[Wan91] D. L. Wang: Symplectic difference schemes for Hamiltonian systems on Poisson
manifolds. J. Comput. Math., 9(2):115–124, (1991).
[ZQ94] W. Zhu and M. Qin: Poisson schemes for Hamiltonian systems on Poisson manifolds.
Computers Math. Applic., 27:7–16, (1994).
[ZS07a] R.van Zon and J. Schoﬁeld: Numerical implementation of the exact dynamics of free
rigid bodies. J. of Comp. Phys., 221(1):145–164, (2007).
[ZS07b] R.van Zon and J. Schoﬁeld: Symplectic algorithms for simulations of rigid body
systems using the exact solution of free motion. Physical Review E, 50:5607, (2007).

Chapter 13.
KAM Theorem of Symplectic Algorithms
Numerical results have shown the overwhelming superiority of symplectic algorithms
over the conventional non-symplectic systems, especially in simulating the global and
structural dynamic behavior of the Hamiltonian systems. In the class of Hamiltonian
systems, the most important and better-understood systems are completely integrable
ones. Completely integrable systems exhibit regular dynamic behavior which corre-
sponds to periodic and quasi-periodic motions in the phase spaces. In this chapter,
we study problems as to whether and to what extent symplectic algorithms can simu-
late qualitatively and approximate quantitatively the periodic and quasi-periodic phase
curves of integrable Hamiltonian systems.
13.1 Brief Introduction to Stability of Geometric
Numerical Algorithms
Among the various kinds of equations of mathematical physics, only a few can be
integrated exactly by quadrature and the rest are unsolvable. However, even an ap-
proximate solution is also valuable in many scientiﬁc and engineering problems. In a
wide range of applications, the most powerful and perhaps the only practically feasible
approximation is the numerical method — this is the case, especially in the computer
era. A question arises accordingly: Whether a numerical method can reﬂect the real
information of exact solutions of original problems properly or simulate accurately?
To a problem described by time evolutionary equations, the solutions can often be
represented by a ﬂow (or semi-ﬂow), which is locally deﬁned on a phase space. Curves
on the phase space which are invariant under the action of the ﬂow (or semi-ﬂow) are
called invariant curves (or positively invariant curves) of the ﬂow (or semi-ﬂow). There
is a natural correspondence between the solutions of the equations and the invariant
curves (or positively invariant curves) of the ﬂow (or semi-ﬂow). The invariant curves,
or positively invariant curves, are called solution curves of the equations. The quali-
tative analysis concerns with problems about understanding topological structures of
the solution curves and their limit sets, which are often sub-manifolds of the phase
space. The aim of the numerical method, in principle, not only pursues an optimal
quantitative approximation to the real solution of the considered problem locally but
also preserves as well as possible the topological and even geometrical properties of

550
13. KAM Theorem of Symplectic Algorithms
the solution curves and their limit sets globally. The latter constitutes the main content
of qualitative analysis of the numerical method.
Qualitative analysis becomes important in the study of numerical methods be-
cause instability phenomena take place very often even in the numerical simulations
of very stable systems. Numerical treatments of stiff problems show that explicit
methods have a severe time-step restriction, which lead to Dahlquist’s pioneering
work about A-stability[Dah63]. Various notions of stability for numerical methods have
been established since then, classifying different types of stable methods for differ-
ent problems. The celebrated linear stability theory (A-stability, A(α)-stability, and
L-stability)[Wid76,Ehl69] is based on the scalar linear equation1
˙y = λy
(1.1)
and turns out to be powerful for the numerical study of all linear-dissipation-dominated
problems. G-stability, which was also developed by Dahlquist[Dah75], is characterized
by retaining the contractivity property of any two solutions of nonlinear “contractive”
systems
˙y = f(y).
(1.2)
Here, the “contractivity” of the system (1.2) is deﬁned by the condition
⟨f(u) −f(v), u −v⟩≤0,
(1.3)
which implies that d
d t∥u(t) −v(t)∥≤0 for any two solutions u(t) and v(t) of (1.2).
It is remarkable that for linear multistep one-leg methods, G-stability is equivalent
to A-stability[Dah78]. Butcher extended Dahlquist’s idea and developed B-stability the-
ory for Runge–Kutta methods[But75]. An elegant algebraic criterion of B-stability for
Runge–Kutta methods was given by Burrage and Butcher, who further suggested the
notion of algebraic stability of Runge–Kutta methods by only using the algebraic con-
ditions of the criterion[BB79]. The algebraically stable Runge–Kutta methods can in-
herit very important dynamic properties of dissipative systems[HS94]. In many cases,
algebraic stability is equivalent to B-stability[HS81]. Many notions and results about
stability were also generalized to the general linear methods[HLW02,HNW93]. In almost
the whole latter half of the last century, one of the central tasks of numerical analy-
sis was the construction and analysis of numerical methods, satisfying these various
stability conditions.
Stable methods have no stringent step-size restriction in their own applicable
ranges. They can preserve the dynamic stability properties (ﬁxed points, periodic
curves, and attractors) of most of dissipative systems[SH96]. Even explicit methods can
also properly reﬂect the key dynamics of dissipative systems if sufﬁciently small step
sizes are used[Bey87,SH96]. It was also proved that Runge–Kutta methods (including Eu-
ler methods), with small step sizes, can preserve the topological structures of dynamic
trajectories of many structure-stable systems[Li99,Gar96].
The application of a numerical method to a generic system deﬁnitely changes the
structure of the system. On the other hand, conventional methods do not change the
1 Dahlquist test equation.

13.2 Mapping Version of the KAM Theorem
551
topological structures of most dynamic trajectories of typical stable systems (e.g., dis-
sipative systems having motion stability and Morse–Smale systems and Axiom A sys-
tems having structure-stability)[SH96,Li99]. However, this remarkable advantage of the
conventional methods does not carry over to conservative systems. Most of the sta-
ble methods introduce artiﬁcial dissipation into conservative systems. They produce
illusive attractors and therefore destroy the qualitative character of the conservative
systems even if sufﬁciently small step sizes of the numerical method are used. The
approximate solutions of conservative systems ask for new numerical methods which
require more stringent stability.
Geometric numerical integration theory for conservative systems has been devel-
oped rapidly in recent twenty years. The monographs[SSC94,HLW02,FQ03,LR05] summarize
the main developments and important results of this theory. Qualitative behavior of ge-
ometric integrators has been investigated by many authors[Sha99,Sha00b,HL97,Sto98a,HLW02].
For symplectic integrators applied to Hamiltonian systems, some stability results, ei-
ther in the spirits of the KAM theory or based on the backward analysis, have been
well established[Sha99,Sha00b,HL97,CFM06,DF07]. The typical stable dynamics of Hamilto-
nian systems, e.g., quasi-periodic motions and their limit sets — minimal invariant
tori, can be topologically preserved and quantitatively approximated by symplectic
discretizations. In this chapter, we give a review about these results. For more details,
readers refer to the relevant references[Sha99,Sha00b,HLW02,CFM06,DF07].
13.2 Mapping Version of the KAM Theorem
In this section, we introduce the mapping version of the celebrated KAM theorem.
The main results of the theorem stem from answering a question about the stability
of motions of planets in the solar system. This question attracted many great scien-
tists in history and the culminated breakthrough was given by Kolmogorov (1954),
Arnold (1963) and Moser (1962). The monograph[HLW02] gives a nice introduction to
the KAM theorem based on the Hamiltonian perturbation theory. We present some re-
sults about differentiable Cantorian foliation structures of invariant tori in phase space
of an integrable symplectic mapping under perturbations. We give relevant estimates
explicitly in terms of the diophantine constant and nondegeneracy parameters of the
frequency map of the integrable system. As a direct application of these estimates,
we state a generalization of Moser’s small twist theorem to higher dimensions, which
can be applied to prove a numerical version of the KAM theorem for symplectic algo-
rithms.
13.2.1 Formulation of the Theorem
Consider an exact symplectic mapping S : (p, q) →(p, q) to be deﬁned in the phase
space I × Tn
p = p −∂2H(p, q),
q = q + ∂1H(p, q),
(2.1)

552
13. KAM Theorem of Symplectic Algorithms
where H : I × Tn →R is the generating function, I is an open and usually
bounded set of Rn and Tn is the standard n-torus. In (2.1), ∂1 and ∂2 denote the gra-
dient operators with respect to the ﬁrst n and the last n variables respectively. When
H(p, q) = H0(p) does not depend on q, then (2.1) represents an integrable mapping
S = S0 : (p, q) →(p, q) = (p, q + ω(p)) with the frequency map
ω(p) = ∂H0(p),
p ∈I,
(2.2)
where ∂denotes the gradient operator with respect to p. Under the mapping S0,
the phase space I × Tn is completely foliated into invariant n-tori {p} × Tn,
p ∈I. On each torus, the iterations of S0 are linear with frequencies ω = ω(p).
This is a typical integrable case. When a perturbation h(p, q) is added to H0, i.e.,
H(p, q) = H0(p) + h(p, q), (2.1) does not deﬁne an integrable mapping generally.
However, KAM theorem shows that the perturbed mapping S still exhibits to a large
extent the integrable behavior in the phase space if the frequency map ω is nondegen-
erate in some sense (see[Arn63,AA89,Arn89,Kol54b,Mos62] for Kolmogorov’s nondegeneracy
and[CS94,R¨us90] for weak nondegeneracy) and the perturbation h is sufﬁciently small in
some function space. In this chapter, we consider the following nondegeneracy condi-
tion for ω : I →Ω:
θ |p1 −p2| ≤|ω(p1) −ω(p2)| ≤Θ |p1 −p2|
(2.3)
for some 0 < θ ≤Θ. Here I and Ω are the domains of action variables and the
corresponding frequency values respectively. We always assume that I and Ω are open
in Rn and ω is analytic and can be analytically extended to some complex domain,
say I + r, of the real domain I, where r is the extension radius. We assume (2.3) is
satisﬁed for p1, p2 ∈I +r with |p1 −p2| ≤r. Note that this nondegeneracy condition
implies that the frequency map ω is invertible in any ball of radius r and centered in I,
which is stronger than the standard Kolmogorov’s nondegeneracy assumption of the
following (this was already noticed by P¨oschel in[P¨os82],
θ|d p| ≤|d ω(p)| ≤Θ|d p|
for
p ∈I + r.
(2.4)
An invariant torus of the integrable system is naturally speciﬁed by its frequency
vector. Those tori are rationally dependent and even Liouville frequency vectors
are generally destroyed by perturbations (Poincar`e and Mather[Mat88]). The invari-
ant tori of KAM type are speciﬁed by the so-called diophantine frequency vectors
ω = (ω1, · · · , ωn),
ei⟨k,ω⟩−1
 ≥
γ
|k|τ
for 0 ̸= k = (k1, · · · , kn) ∈Zn
(2.5)
with some constants γ > 0, τ > 0, where ⟨k, ω⟩=
n

j=1
kjωj and |k| =
n

j=1
|kj| for
integers k ∈Zn.
We introduce some notations. For an open or closed set I ⊂Rn and for a ≥0,
denote by Ca(I×Tn), the class of isotropic differentiable functions of order a deﬁned

13.2 Mapping Version of the KAM Theorem
553
on I ×Tn in the sense of Whitney. The norm of a function u ∈Ca(I ×Tn) is denoted
by ∥u∥a,I×Tn. Since we also get the anisotropic differentiability of the foliations of
invariant tori, we need the class Cν1,ν2(I×Tn), of anisotropic differentiable functions
of order (ν1, ν2), with the norm denoted by ∥u∥ν1,ν2;I×Tn for a function u in the class.
These two classes, endowed with the corresponding norms, are both Banach spaces.
We also use another norm ∥· ∥ν1,ν2;I×Tn,ρ for ρ > 0 deﬁned by
∥u∥ν1,ν2;I×Tn,ρ = ∥u ◦σρ∥ν1,ν2;σ−1
ρ
(I×Tn)
(2.6)
for u ∈Cν1,ν2(I × Tn), where σρ denotes the partial stretching (x, y) →(ρx, y) for
(x, y) ∈I × Tn. Note that the following relation between these two norms is valid
for 0 < ρ ≤1:
∥u∥ν1,ν2;ρ ≤∥u∥ν1,ν2 ≤ρ−ν1 ∥u∥ν1,ν2;ρ ,
(2.7)
where we dropped the domains to simplify the notations.
Take Ω = ω(I) and denote by Ωγ the set of those frequencies, in Ω, which satisfy
the diophantine condition (2.5) for given γ > 0 and whose distance to the boundary
of Ω is at least equal to 2γ. The set Ωγ is a Cantor set2 and the difference Ω \ #
γ>0
Ωγ
is a zero set if τ > n + 1. Therefore Ωγ is large for small γ.
The main results of this section are stated as follows:
Theorem 2.1. Given positive integer n and real number τ > n+1, consider mapping
S deﬁned in phase space I×Tn by (2.1) with H(p, q) = H0(p)+h(p, q), where H0 is
analytic in I + r with r > 0 and h(p, q) belongs to the Whitney’s class Cαλ+λ+τ(I ×
Tn) for some λ > τ + 1 and α > 1,
α /∈Λ =
 i
λ + j : i, j ≥0 integer

.
Suppose the frequency map ω = ∂H0 : I →Ω satisﬁes the nondegeneracy condition
(2.3) for p1, p2 ∈I + r with |p1 −p2| ≤r where the constants θ and Θ satisfy
0 < θ ≤Θ, then there exists a positive constant δ0, depending only on n, τ, λ and α,
such that for any 0 < γ ≤min

1, 1
2rΘ

, if
∥h∥αλ+λ+τ,I×Tn;γΘ−1 ≤δ0γ2θΘ−2,
(2.8)
then there exists a Cantor set Iγ ⊂I, a surjective map ωγ : Iγ →Ωγ of Cα+1 class
and a symplectic injection Φ : Iγ × Tn →Rn × Tn of Cα,αλ class, in the Whitney’s
sense, such that
1◦
Φ is a conjugation from S to R. That is, the following equation holds:
S ◦Φ = Φ ◦R,
(2.9)
where R is the integrable rotation on Iγ ×Tn with frequency map ωγ, i.e., R(P, Q) =
(P, Q+ωγ(P)) for (P, Q) ∈Iγ ×Tn. Moreover, Equation (2.9) may be differentiated
as often as Φ allows.
2 A subset of Rn is called a Cantor set if it is nowhere dense and complete in Rn.

554
13. KAM Theorem of Symplectic Algorithms
2◦
If Ω is a bounded open set of type D in the Arnold’s sense3, then we have the
following measure estimate
mEγ ≥

1 −c4

θΘ−1−n
γ

m E,
(2.10)
where Eγ = Φ(Iγ × Tn) is the union of invariant tori Φ({P} × Tn), P ∈Iγ, of S
and m denotes the invariant Liouville measure on the phase space E = I × Tn; c4 is
a positive constant depending on n, τ, a and the geometric property of the domain Ω.
3◦
If h is of Cβλ+λ+τ class with α ≤β not in Λ, then we have further that
ωγ ∈Cβ+1(Iγ) and Φ ∈Cβ,βλ(Iγ × Tn). Moreover,
???σ−1
γΘ−1 ◦(Φ −I)
???
β,βλ;γΘ−1 , γ−1 ∥ωγ −ω∥β+1;γΘ−1 ≤c5γ−2Θ ∥h∥βλ+λ+τ;γΘ−1
(2.11)
with constant c5 depending on n, τ, λ and β, here we have dropped the domains in
the notation of norms.
4◦
For each ω∗∈Ωγ, there exists p∗∈I and P ∗∈Iγ such that ω(p∗) =
ωγ(P ∗) = ω∗and
|P ∗−p∗| ≤c6

γθΘ−1−1
∥h∥αλ+λ+τ,I×Tn;γΘ−1,
(2.12)
where c6 is a positive constant depending on n, τ, λ and α.
Theorem 2.2. If the frequency map ω satisﬁes the nondegeneracy condition (2.4),
then the conclusions of Theorem 2.1 are still true with the same estimates (2.10) –
(2.12) under the following smallness condition for h,
∥h∥αλ+λ+τ,I×Tn;γΘ−1 ≤δ0γ2θ2Θ−3,
(2.13)
where δ0 > 0 is depending only on n, τ, λ and α and is sufﬁciently small.
Remark 2.3. The above two theorems are stated for the case when h is ﬁnitely many
times differentiable. If h is inﬁnitely many times differentiable or analytic, we have the
following conclusions, which are easily derived by similar remarks to those of[P¨os82].
1◦
If h ∈C∞(I × Tn), then ωγ ∈C∞(Iγ) and Φ ∈C∞(Iγ × Tn) and the
estimates (2.8) hold for any β ≥α.
2◦
If h ∈Cω(I × Tn), then we have further Φ ∈C∞,ω(Iγ, Tn) under an
additional smallness condition for δ0 which also depends on the radius of analyticity of
h with respect to angle variables. Here Cω denotes the class of real analytic functions.
13.2.2 Outline of the Proof of the Theorems
In this section, we give an outline of the proof of Theorem 2.1. For detailed arguments
refer to [Sha00a].
3 For example, a domain with piece-wise smooth boundary is of type D in the Arnold’s sense.

13.2 Mapping Version of the KAM Theorem
555
a.
We transform the mapping S, by a partial coordinates stretching σρ : (x, y) →
(p, q) = (ρx, y), to T = σ−1
ρ
◦S ◦σρ : (x, y) →(x, y). The mapping T is determined
by
x = x −∂2F(x, y),
y = y + ∂1F(x, y),
(2.14)
where
F(x, y) = F0(x) + f(x, y)
(2.15)
is well deﬁned on Iρ × Tn with
F0(x) = ρ−1H0(ρx),
f(x, y) = ρ−1h(ρx, y)
(2.16)
and
Iρ = ρ−1I = {x ∈Rn|ρx ∈I}.
(2.17)
For the time being, ρ is regarded as a free parameter. F0(x) is real analytic in
Iρ + rρ and f belongs to the class Ca(Iρ × Tn) where rρ = ρ−1r, a = αλ + λ + τ.
So the new mapping T satisﬁes the assumptions of Theorem 2.1 in which only I,
r, H, H0, and h are replaced by Iρ, rρ, F, F0, and f respectively. Accordingly, the
frequency map of the integrable mapping associated to the generating function F0
turns into
"ω(x) = ∂F0(x),
x ∈Iρ,
and the nondegeneracy condition for the mapping turns out to be
ρθ |x1 −x2| ≤|"ω(x1) −"ω(x2)| ≤ρΘ |x1 −x2|
(2.18)
for x1, x2 ∈Iρ + rρ with |x1 −x2| ≤rρ. In addition, from (2.16), we have
∥f∥a,Iρ×Tn = ρ−1 ∥h∥a,I×Tn;ρ .
From now on, we ﬁx ρ = γΘ−1. Then the assumption 0 < γ ≤1
2rΘ in Theorem
2.1 implies that 0 < ρ ≤1
2r. Hence, rρ ≥2. Let I∗
ρ be the set of points in Iρ with the
distance to its boundary at least one and let
Iρ;γ = "ω−1(Ωγ) ∩Iρ.
(2.19)
Then, from (2.18) and the deﬁnition of Ωγ it follows that
(Iρ;γ + 1) ∩Rn ⊂I∗
ρ ⊂(I∗
ρ + 1) ∩Rn ⊂Iρ,
(2.20)
and
γμ |x1 −x2| ≤|"ω(x1) −"ω(x2)| ≤γ |x1 −x2| ,
μ = θΘ−1
(2.21)
for x1, x2 ∈Iρ + 2 with |x1 −x2| ≤2.
b.
We approximate f by real analytic functions. Let
sj = s04−j,
rj = sλ
j ,
j = 0, 1, 2, · · ·
(2.22)

556
13. KAM Theorem of Symplectic Algorithms
with ﬁxed λ > τ + 1 and s0 > 0. Let
Uj = Iρ × Tn + (4sj, 4sj)
be the complex extended domain of Iρ × Tn with extended widths 4sj of Iρ and
Tn respectively[P¨os82]. By an approximation lemma [P¨os82], there exists real analytic
functions fj deﬁned on U0 with f0 = 0 such that, in case f ∈Cb(I ×Tn) with b ≥a,
|fj −fj−1|Uj ≤sb
jcb ∥f∥b;Iρ×Tn
j = 1, 2, · · · ,
∥f −fj∥b′,I∗
ρ ×Tn −→0
(j −→∞)
for 0 < b′ < b,
(2.23)
where cb is a positive constant only depending on b, n and s0 but not depending on the
domain Iρ and hence not depending on the parameter ρ. Moreover, we may require fj
to be 2π-periodic in the last n variables. In (2.23), | · |Uj denotes the maximum norm
of analytic functions on the complex domain Uj.
c.
We give the KAM iteration process which essentially follows P¨oschel [P¨os82] in
the Hamiltonian system case. For each fj, we deﬁne a mapping Tj : (x, y) →(x, y)
by
x = x −∂2Fj(x, y),
y = y + ∂1Fj(x, y)
(2.24)
with Fj(x, y) = F0(x)+fj(x, y). For each j, the function Fj(x, y) is well-deﬁned and
real analytic on Uj if 4sj ≤rρ = ρ−1r — this inequality is satisﬁed for j = 0, 1, · · ·
if we choose 0 < s0 ≤4−1
noting that 0 < γ < 1
2rΘ

. We can show that each Tj
for j ≥0 is a well-deﬁned analytic mapping on a domain of complex extension of
the phase space Iρ × Tn, which is appropriate for the KAM iterations if h is bounded
by (2.8) with a sufﬁciently small δ0 > 0. It follows from (2.23) that Tj converges to
T in Cb−1−κ-norm for any κ > 0 on some subdomain I∗
ρ × Tn of the phase space
Iρ × Tn, where T is well-deﬁned. The central problem is to ﬁnd transformations
Φj and integrable rotations Rj, deﬁned on a sequence of nested complex domains
that intersect a nonempty Cantor set, say "Iρ;γ × Tn, such that the following holds as
j →∞on "Iρ;γ × Tn in some Whitney’s classes,
Cj = R−1
j
◦Φ−1
j
◦Tj ◦Φj −→identity, Φj −→"Φ, Rj −→"R,
(2.25)
where "Φ and "R are well-deﬁned on "Iρ;γ × Tn. In this case, we have
T ◦"Φ = "Φ ◦"R
on
"Iρ;γ × Tn.
(2.26)
Transforming the mapping T back to S by the partial coordinates stretching σρ,
and meanwhile transforming "Φ and "R to Φ and R respectively, we have
S ◦Φ = Φ ◦R
on Iγ × Tn,
where
Iγ = ρ"Iρ;γ = {p ∈Rn | ρ−1p ∈"Iρ;γ}

13.2 Mapping Version of the KAM Theorem
557
is a Cantor set of I. In fact, due to the nondegeneracy of the frequency map ω in the
sense of (2.3), we may keep the frequencies prescribed by (2.5) ﬁxed in the above
approximation process. As a result, we have ωγ(Iγ) = Ωγ, where ωγ is the frequency
map of the integrable rotation R on Iγ×Tn. This is just the conclusion (1) of Theorem
2.1.
The construction of Φj and Rj uses the KAM iteration, which is described as
follows.
Assume
|fj −fj−1| ∼εj,
j = 1, 2, · · · ,
(2.27)
where εj is a decreasing sequence of positive numbers . Suppose we have already
found a transformation Φj and a rotation Rj with frequency map ω(j) such that
Cj = R−1
j
◦Φ−1
j
◦Tj ◦Φj
(2.28)
satisﬁes
|Cj −I| ∼εj+1.
(2.29)
Then, we construct a transformation Ψj and a new rotation Rj+1 with frequency map
ω(j+1) such that
Φj+1 = Φj ◦Ψj
(2.30)
and (2.29) is also true for the next index j + 1 with Cj+1 deﬁned by (2.28) in which
j is replaced by j + 1. As was remarked by P¨oschel in[P¨os82], “for this procedure
to be successful it is essential to have precise control over the various domains of
deﬁnition”.
We deﬁne transformation Ψj : (ξ, η) →(x, y) implicitly with the help of a gener-
ating function ψj by
x = ξ + ∂2ψj(ξ, y),
y = η −∂1ψj(ξ, y).
(2.31)
To deﬁne ψj, we consider mapping
Bj = R−1
j
◦Φ−1
j
◦Tj+1 ◦Φj.
(2.32)
Bj is near identity and is assumed to be given implicitly from its generating function
bj by
x = x −∂2bj(x, y),
y = y + ∂1bj(x, y).
(2.33)
The function ψj is then determined from bj by the following homological equation
ψj(x, y + ω(j)(x)) −ψj(x, y) + "bj(x, y) = 0,
(2.34)
where "bj(x, y) = bj(x, y) −[bj](x) with [bj] being the mean value of bj with respect
to the angle variables over Tn. Deﬁne
ω(j+1)(x) = ω(j)(x) + ∂[bj](x).
(2.35)
Then Rj+1 : (x, y) →(x, y) is just given by

558
13. KAM Theorem of Symplectic Algorithms
x = x,
y = y + ω(j+1)(x).
(2.36)
With the so deﬁned Ψj and Rj+1, we easily show that, formally,
Ψ−1
j
◦Rj ◦Bj ◦Ψj = Rj+1 ◦Cj+1.
Formal calculations similar to those in[P¨os82] show that (2.29) is valid if we replace j
by j + 1.
We do not solve the Equation (2.34) exactly. Instead, we will solve an approximate
equation by truncating the fourier expansion of "bj with respect to angle variables to
some ﬁnite order so that “only ﬁnitely many resonances remain, and we obtain a real
analytic solution ψj deﬁned on an open set”[P¨os82]. This idea was ﬁrst successfully
used by Arnold[Arn63,AA89].
For an earnest proof, we need more precise arguments by carefully controlling the
domains of deﬁnition of functions and mappings in the iterative process. Readers can
refer to[Sha00a] for details.
13.2.3 Application to Small Twist Mappings
In this section, we state a theorem of KAM type for small twist mappings. Such
a theorem ﬁrst appeared in Moser’s celebrated paper[Mos62] for 2-dimensional area-
preserving mappings. Its generalization to higher dimensions was given in[Sha00a], as a
direct application of the theorems of the last section. The result may be formulated as
follows:
Theorem 2.4. Consider one parameter family of mappings St : (p, q) →(p, q) with
S0 = I and S1 = S, deﬁned in phase space I × Tn by
 p = p −t∂2H(p, q) = p −t∂2h(p, q),
q = q + t∂1H(p, q) = q + tω(p) + t∂1h(p, q),
(2.37)
where H(p, q) = H0(p) + h(p, q) and ω(p) = ∂H0(p). Under the assumptions of
Theorem 2.1 (Theorem 2.2) for H, if h satisﬁes the smallness condition of Theorems
2.1 (Theorem 2.2), then the corresponding conclusions of the theorem are still valid
for St (0 < t ≤1), only with the following remarks:
1◦
Ωγ is replaced by
Ωt,γ =

ω ∈Ω∗:
ei⟨k,tω⟩−1
 ≥tγ
|k|τ
for k ∈Zn \ {0}

,
(2.38)
where Ω∗denotes the set of points in Ω with distance to its boundary at least equal to
2γ. Accordingly, Iγ, ωγ, Φ, and R are replaced by It,γ, ωt,γ, Φt and Rt,respectively.
2◦
If Ω is a bounded open set of type D in the Arnold’s sense[Arn63], then we have
the following Lebesgue measure estimate
m(Ω \ Ωt,γ) ≤DγmΩ
(2.39)

13.3 KAM Theorem of Symplectic Algorithms for Hamiltonian Systems
559
for t ∈(0, 1], with constant D only depending on n, τ and the geometry of Ω. So in
this case, Ωt,γ is still a large Cantor set in Ω when γ is small enough.
3◦
If h ∈C∞(B × Tn), then ωγ,t ∈C∞(Bγ,t) and Φt ∈C∞(Bγ,t × Tn)
which satisfy the estimates (2.11) for any β ≥α.
4◦
If h is analytic with the domain of analyticity containing
S(r, ρ) =
(
(p, q) ∈C2n : |p −p′| < r, |Im q| < ρ with p′ ∈B and Re q ∈Tn)
for some r > 0 and ρ > 0 (Re q and Im q denote the real and imaginary parts of q
respectively) and if h satisﬁes
∥h∥r,ρ =
sup
(p,q)∈S(r,ρ)
|h(p, q)| ≤δ0γ2θ2Θ−3
(2.40)
for some sufﬁciently small δ0 > 0 depending on n, τ, r and ρ, then all the con-
clusions of Theorem 2.1 (Theorem 2.2) are still true with ωγ,t ∈C∞(Bγ,t), Φt ∈
C∞,ω(Bγ,t × Tn) and the estimate (2.11) holds for any β ≥0.
We have presented the results about the existence of differentiable foliation struc-
tures in the sense of Whitney of invariant tori for nearly integrable symplectic map-
pings and for mappings with small twists. Such a result was proved ﬁrst by Lazutkin
in 1974[Laz74] for planar twist maps and was generalized to higher dimensions by
Svanidze in 1980[Sva81]. For the case of Hamiltonian ﬂows of arbitrary dimensions,
the generalizations were given by J. P¨oschel in 1982[P¨os82], Chierchia and Gallavotti
in 1982[CG82]. The perturbation and measure estimates in terms of γ were studied
by R¨ussmann in 1981[R¨us81], Svadnidze in 1981[Sva81], Neishtadt in 1982[Nei82] and
P¨oschel in 1982[P¨os82]. The estimates in terms of θ and Θ were given by Shang in
2000[Sha00a], which are also crucial in the small twist mapping case.
13.3 KAM Theorem of Symplectic Algorithms for
Hamiltonian Systems
In this section, we study stability of symplectic algorithms when applied to typical
nonlinear Hamiltonian systems. We introduce a numerical version of the KAM the-
orem. Such a theorem was already suggested by Channel and Scovel in 1990[CS90],
Kang Feng 1991[Fen91], and Sanz-Serna and Calvo in 1994[SSC94]. Its rigorous for-
mulation and proof were given by Shang in 1999 and 2000[Sha99,Sha00b] based on the
thesis[Sha91]. The main results consist of the existence of invariant tori, with a smooth
foliation structure, of a symplectic numerical algorithm when it applies to a generic in-
tegrable Hamiltonian system with arbitrarily many degrees of freedom if the time-step
size of the algorithm is sufﬁciently small and falls in a Cantor set of large measure.
This existence result also implies that the algorithm, when it is applied to a generic
integrable system of n degrees of freedom, possesses n independent smooth invariant
functions which are in involution and well-deﬁned on the set ﬁlled by the invariant
tori in the sense of Whitney. The invariant tori are just the level sets of these functions.
Quantitative analysis shows that the numerical invariant tori of a symplectic algorithm
can approximate the corresponding exact invariant tori of the systems.

560
13. KAM Theorem of Symplectic Algorithms
13.3.1 Symplectic Algorithms as Small Twist Mappings
We consider a Hamiltonian system with n degrees of freedom in canonical form
˙x = −∂K
∂y (x, y),
˙y = ∂K
∂x (x, y),
(x, y) ∈D,
(3.1)
where D is a connected bounded, open subset of R2n; x and y are both n-dimensional
Euclidean coordinates with ˙x and ˙y the derivatives of x and y with respect to the time
“t” respectively; K : D →R1 is the Hamiltonian.
A symplectic algorithm that is compatible with the system (3.1) is a discretization
scheme such that, when applied to the system (3.1), it uniquely determines one param-
eter family of symplectic step-transition maps Gt
K that approximates the phase ﬂow
gt
K in the sense that
lim
t→0
1
ts

Gt
K(z) −gt
K(z)

= 0
for any z = (x, y) ∈D
(3.2)
for some s ≥1, here t > 0 is the time-step size of the algorithm and s, the largest
integer such that (3.2) holds, is the order of accuracy of the algorithm approximating
the continuous systems. Note that the domain in which Gt
K is well-deﬁned, say "Dt,
depends on t generally and converges to D as t →0 — this means that any z ∈D
may be contained in "Dt when t is sufﬁciently close to zero.
From (3.2), we may assume
Gt
K(z) = gt
K(z) + tsRt
K(z),
(3.3)
where
Rt
K(z) = 1
ts

Gt
K(z) −gt
K(z)

is well-deﬁned for z ∈"Dt ⊂D and has the limit zero as t →0 for z ∈D. Below, we
prove the main results of this chapter by simply regarding the approximation Gt
K to
the phase ﬂow gt
K of the above form as a symplectic discretization scheme of order s.
We assume that the system (3.1) is integrable. That is, there exists a system of
action-angle coordinates (p, q) in which the domain D can be expressed as the form
B × Tn and the Hamiltonian depends only on the action variables, where B is a
connected bounded, open subset of Rn and Tn the standard n-dimensional torus. Let
us denote by Ψ : B × Tn →D the coordinate transformation from (p, q) to (x, y),
then Ψ is a symplectic diffeomorphism from B × Tn onto D. The new Hamiltonian
K ◦Ψ(p, q) = H(p),
(p, q) ∈B × Tn
(3.4)
only depends on p. Therefore, in the action-angle coordinates (p, q), (3.1) takes the
simple form
˙p = 0,
˙q = ω(p) = ∂H
∂p (p)
(3.5)
and the phase ﬂow gt
H is just the one parameter group of rotations (p, q) →(p, q +
tω(p)) which leaves every torus {p} × Tn invariant.

13.3 KAM Theorem of Symplectic Algorithms for Hamiltonian Systems
561
Assume K is analytic and, without loss of generality, assume the domain of ana-
lyticity of K contains the following open subset of C2n
Dα0 =
(
z = (x, y) ∈C2n : d(z, D) < α0
)
,
(3.6)
with some α0 > 0, where
d(z, D) = inf
z′∈D |z −z′|
denotes the distance from the point z ∈C2n to the set D ⊂C2n in which |z| =
max
1≤j≤2n |zj| for z = (z1, · · · , z2n). Also, we assume that Ψ extends analytically to the
following complex domain
S(r0, ρ0) =
(
(p, q) ∈C2n : d(p, B) < r0, Re q ∈Tn, |Im q| < ρ0
)
(3.7)
with r0 > 0, ρ0 > 0 and has period 2π in each component of q. In (3.7), B is
considered as a subset of C2n. Without loss of generality, we suppose "D(r0, ρ0) =
Ψ

S(r0, ρ0)

⊂Dα0 and further that Ψ is a diffeomorphism from S(r0, ρ0) onto
"D(r0, ρ0). So the Equation (3.4) is valid for (p, q) ∈S(r0, ρ0) and
Ψ−1 ◦gt
K ◦Ψ = gt
H
(3.8)
on this complex domain of coordinates (p, q).
Checking the existing available symplectic algorithms, we ﬁnd that Gt
K is always
analytic if the Hamiltonian K is analytic. Note that the domain in which Gt
K is well-
deﬁned converges to the domain of deﬁnition of gt
K as t approaches zero. We may
assume, without loss of generality, Gt
K is well-deﬁned and analytic in the complex
domain Dα0 for t sufﬁciently close to zero. Moreover, in the analytic case, we have
Gt
K(z) −gt
K(z)
 ≤ts+1M(z, t)
with an everywhere positive continuous function M : Dα0 × [0, δ1] →R for some
sufﬁciently small δ1 > 0.
Lemma 3.1. There exists δ2 > 0 such that for t ∈[0, δ2], "Gt
K = Ψ−1 ◦Gt
K ◦Ψ is
well-deﬁned and real analytic on the closed complex domain S
r0
2 , ρ0
2

and
 "Gt
K(p, q) −gt
H(p, q)
 ≤Mts+1,
(p, q) ∈S
r0
2 , ρ0
2

,
t ∈[0, δ2],
(3.9)
where M is a positive constant depending on r0, ρ0, α0, δ1, Ψ and K, not on t.
Proof. Let U1 = S
r0
2 , ρ0
2

and V1 = Ψ

S
r0
2 , ρ0
2

. Since U1 is a closed subset
of S(r0, ρ0) and Ψ is a diffeomorphism from S(r0, ρ0) onto Dα0, V1 is closed in Dα0.
Let ξ be the distance from V1 to the boundary of Dα0, then ξ > 0. The compactness
of V1 implies that there exists 0 < δ
′
1 < δ1 such that gt
K maps V1 into V1 + ξ
2 for

562
13. KAM Theorem of Symplectic Algorithms
t ∈[0, δ
′
1], where V1 + ξ
2 denotes the union of all complex open balls centered in V1
with radius ξ
2. Since M(z, t) is continuous and positive for (z, t) ∈V1 × [0, δ
′
1], there
exists a constant M0 > 0 which is an upper bound of M(z, t) on V1 × [0, δ
′
1]. Let
δ2 = min

1, δ
′
1,
D
ξ
4M0

. Then for t ∈[0, δ2], Gt
K maps V1 into Dα0 and hence
"Gt
K = Ψ−1 ◦Gt
K ◦Ψ is well-deﬁned on U1. The real analyticity of the map follows
from the real analyticity of Ψ and K. To verify Equation (3.9) , we ﬁrst note that the
analyticity of Ψ−1 on V1 + 3ξ
4 ⊂Dα0 implies that
∂Ψ−1
∂z (z)
 ≤M1
for all z ∈V1 + 3ξ
4 with some constant M1 > 0,and then Taylor formula gives
Ψ(p, q) ∈V1 and
Rt
K(Ψ(p, q))
 =
Gt
K(Ψ(p, q)) −gt
K(Ψ(p, q))
 ≤M0ts+1 ≤ξ
4
for (p, q) ∈U1 and t ∈[0, δ2]. Therefore,
| "Gt
K(p, q) −gt
H(p, q)| = |Ψ−1(gt
K(Ψ(p, q)) + Rt
K(Ψ(p, q))) −Ψ−1(gt
K(Ψ(p, q)))|
≤2nM1M0ts+1.
Let M = 2nM1M0, then (3.9) is veriﬁed.
▲
The above lemma shows that "Gt
K is an approximant to the one parameter group
of integrable rotations gt
H up to order ts+1 as t approaches zero. To apply Theorem
2.4, we need to verify the exact symplecticity of "Gt
K so that it can be expressed by
globally deﬁned generating function. Because Ψ is not necessarily exact symplectic,
the exact symplecticity of "Gt
K = Ψ−1 ◦Gt
K ◦Ψ is not trivially observed.
Lemma 3.2. Let G be an exact symplectic mapping of class C1 from D into R2n
where D is an open subset of R2n and let Ψ be a symplectic diffeomorphism from
B × Tn onto D. Then Ψ−1 ◦G ◦Ψ is an exact symplectic mapping in the domain in
which it is well-deﬁned.
Proof. Let (p, q) = Ψ−1 ◦G ◦Ψ(p, q) and let γ be any given closed curve in the
domain of deﬁnition of "G =: Ψ−1 ◦G ◦Ψ, which is an open subset of B × Tn. The
exact symplecticity of "G will be implied by[Arn89]
I(γ) =
-
γ
p d q −
-
γ
p d q = 0.
(3.10)
Now we verify (3.10). Let (x, y) = Ψ(p, q) and (x, y) = Ψ(p, q). Then (x, y) =
G(x, y). Since G is an exact symplectic, we have

γ x d y −

γ x d y = 0, where x,

13.3 KAM Theorem of Symplectic Algorithms for Hamiltonian Systems
563
y, x, y are considered as functions of (p, q), which vary over γ. Therefore, with these
conventions and with γ′ = Ψ−1 ◦G ◦Ψ(γ),
I(γ) =
-
γ
p d q −
-
γ
x d y +
-
γ
x d y −
-
γ
p d q
=
-
γ′ p d q −
-
Ψ(γ′)
x d y +
-
Ψ(γ)
x d y −
-
γ
p d q
=
-
γ′−γ
p d q −
-
Ψ(γ′)−Ψ(γ)
x d y.
(3.11)
Note that G is exact and hence it is homotopic to the identity. This implies that Ψ−1 ◦
G ◦Ψ is homotopic to the identity too. So γ′ and γ belong to the same homological
class in the fundamental group of the manifold B × Tn. Therefore, one may ﬁnd a
2-dimensional surface, say σ, in the phase space B × Tn, which is bounded by γ′ and
γ. Ψ(σ) is then a 2-dimensional surface in D bounded by Ψ(γ′) and Ψ(γ). By stokes
formula and from (3.11), we get
I(γ) =
-
σ
d p ∧d q −
-
Ψ(σ)
d x ∧d y,
which is equal to zero because Ψ preserves the two form d p ∧d q.
▲
Checking the existing available symplectic algorithms, we observe that they are
generally constructed by discretizing Hamiltonian systems, therefore, they generate
exact symplectic step transition maps. In our case, this means that Gt
K is a one-
parameter family of exact symplectic mappings. By Lemma 3.2, so is "Gt
K. As a result,
"Gt
K can be re-expressed by generating function. On the other hand, by Lemma 3.1, we
see that "Gt
K is near the identity and approximates gt
H up to order ts+1 on S
r0
2 , ρ0
2

for t ∈[0, δ2]. A simple argument of implicit function theorem, with the notice of the
exact symplecticity of "Gt
K, will show the following:
Lemma 3.3. There exists a function ht which depends on the time step t such that it is
well-deﬁned and real analytic on the domain S
r0
4 , ρ0
4

for t ∈[0, δ3] with δ3 being
a sufﬁciently small positive number so that "Gt
K : (p, q) →(p, q) can be expressed by
ht as follows:
p = p −ts+1 ∂ht
∂q (p, q),
q = q + tω(p) + ts+1 ∂ht
∂p (p, q).
(3.12)
Proof. It follows immediately from Lemmas 3.1 and 3.3 that
????
∂ht
∂p
???? r0
4 , ρ0
4
≤M,
????
∂ht
∂q
???? r0
4 , ρ0
4
≤M.
Fix (p0, q0) ∈D and let ht(p0, q0) = 0. For any (p, q) ∈S
r0
4 , ρ0
4

, integrating
the exact differential one form ∂ht
∂p d p + ∂ht
∂q d q along one of the shortest curves from

564
13. KAM Theorem of Symplectic Algorithms
(p0, q0) to (p, q) in S
r0
4 , ρ0
4

and then taking the maximal norm of the integration
for (p, q) over S
r0
4 , ρ0
4

, we obtain the estimate
∥ht∥r0
4 , ρ0
4 ≤2nML,
for t ∈[0, δ3],
(3.13)
where M is the constant in Lemma 3.1 and L is an upper bound of the length of
the shortest curves from (p0, q0) to points of S
r0
4 , ρ0
4

, which is clearly a ﬁnite
positive number. Note that B is a connected bounded, open subset of Rn and therefore,
S
r0
4 , ρ0
4

is bounded too.
▲
13.3.2 Numerical Version of KAM Theorem
We formulate the main result of this chapter as follows.
Theorem 3.4. Let Hamiltonian system (3.1) be integrable in a connected bounded,
open domain D of R2n, and let K be real analytic and nondegenerate in the sense
of Kolmogorov after expressed as action-angle variables. For an analytic symplectic
algorithm4 compatible with the system, as long as the time-step t of the algorithm is
small enough, most nonresonant invariant tori of the integrable system do not vanish,
but are only slightly deformed, so that in the phase space D, the symplectic algorithm
also has invariant tori densely ﬁlled with phase orbits winding around them quasi-
periodically, with a number of independent frequencies equal to the number of degrees
of freedom. These invariant tori are all analytic manifolds and form a Cantor set, say
Dt. The Lebesgue measure mDt of the Cantor set Dt tends to mD as t tends to zero.
Moreover, on Dt, the algorithm is conjugate to a one parameter family of rotations of
the form (p, q) →(p, q + tωt(p)) by a C∞-symplectic conjugation Ψt : Bt × Tn →
Dt, where (p, q) are action-angle coordinates and ωt is the frequency map deﬁned on
a Cantor set Bt ⊂Rn of actions.
More quantitative results hold. For any given and sufﬁciently small γ > 0, if the
time step t is sufﬁciently small, then there exists closed subsets Bγ,t of Bt and Dγ,t of
Dt such that Dγ,t = Ψt(Bγ,t × Tn) and the following hold:
1◦
mDγ,t ≥(1 −c′
1γ)mD, where c′
1 is a positive constant not depending on t
and γ;
2◦
∥Ψt −Ψ∥β,βλ;Bγ,t×Tn, ∥ωt −ω∥β+1;Bγ,t ≤c′
2γ−(2+β) · ts for any β ≥0,
where s is the accuracy order of the algorithm, λ > n + 2, c′
2 is a positive constant
not depending on γ and t. The norms here are understood in the sense of Whitney;
3◦
Every numerical invariant torus in Dγ,t is ts-close to the invariant torus of
the same frequencies of the original integrable system (3.1) in the sense of Hausdorff 5.
4 An analytic algorithm is an algorithm generating an analytic step-transition map whenever
the Hamiltonian is analytic. Note that all the existing available symplectic algorithms are
analytic in this sense.
5 The Hausdorff distance of two sets A and B is deﬁned as[Bey87] d(A, B)
=
max

sup
x∈A
dist(x, B), sup
y∈B
dist(y, A)

, where dist(x, B) = inf
y∈B |x −y|.

13.3 KAM Theorem of Symplectic Algorithms for Hamiltonian Systems
565
Proof. Now the analytic version of Theorem 2.4 can be applied to St = "Gt
K. The
conditions required by Theorem 2.4 are satisﬁed clearly according to the assumptions
of Theorem 2.1. For example, the nondegeneracy of the integrable system in the sense
of Kolmogorov means that the frequency map ω : B →Rn is nondegenerate and
therefore, there exists positive constants θ ≤Θ such that ω satisﬁes (2.4) with some
positive numbers r ≤r0. We assume r = r0 here without loss of generality. In
Theorem 2.4, the function h is replaced by tsht which satisﬁes the estimate (2.40)
with r = r0
4 and ρ = ρ0
4 if we choose
γ = γt =: Γtd,
with 0 < d ≤s
2 and Γ =
D
2nML
δ0
θ−1Θ
3
2
(3.14)
and if t is sufﬁciently small, where δ0 is the bound given by (2.40) of Theorem 2.4.
It is clear that the so chosen γ satisﬁes the condition γ ≤min

1, 1
2rΘ

required by
Theorem 2.4 for t sufﬁciently close to zero. By Theorem 2.4, we then have the Cantor
sets Bt = Bγ,t ⊂B and Ωt = Ωγ,t ⊂ω(B), a surjective map ωt = ωγ,t : Bt →Ωt
of class C∞and a symplectic mapping Φt : Bt × Tn →Rn × Tn of class C∞,ω,
in the sense of Whitney, such that the conclusions (1) – (4) of Theorem 2.4 hold with
γ = Γtd. From (2.10), invariant tori of "Gt
K ﬁll out a set Et = Eγ,t = Φt(Bt × Tn) in
phase space E = B × Tn with measure estimate
mEt ≥

1 −c4Γ

θΘ−1−ntd
mE.
(3.15)
From (2.11), with the notice of (2.7) and the fact that
∥ht∥βλ+λ+τ ≤c7∥ht∥r0
4 , ρ0
4
by Cauchy’s estimate for derivatives of an analytic function, we have
∥Φt −I∥β,βλ;Bt×Tn ≤

γΘ−1−β∥σ−1
γΘ−1 ◦(Φt −I)∥β,βλ;γΘ−1
≤c5c7γ−(2+β)Θ1+β∥tsht∥r0
4 , ρ0
4
≤c8θ2+βΘ−(2+β/2) · ts−(2+β)d
(3.16)
for t sufﬁciently close to zero, where
c8 = c5c7(2nML)−β
2 δ
1+ β
2
0
.
In the last inequality of (3.16), we have used the estimate (3.13) for ht. From (2.11),
we also get
∥ωt −ω∥β+1;Bt ≤(γΘ−1)−(β+1)∥ωt −ω∥β+1;γΘ−1
≤c8θ2+βΘ−(1+β/2) · ts−(2+β)d.
(3.17)
Let Ψt = Ψ ◦Φt and Dt = Ψ(Et), then Gt
K ◦Ψt = Ψt ◦Rt, which means that
Ψt realizes the conjugation from Gt
K to Rt : (p, q) →(p, q + tωt(p)) and for any

566
13. KAM Theorem of Symplectic Algorithms
ﬁxed P ∈Bt, Ψt(P, Tn) is an invariant torus of Gt
K, which is an analytic Lagrangian
manifold since Ψt is a symplectic diffeomorphism and analytic with respect to the
angle variables. On the torus, the iterations of Gt
K starting from any ﬁxed point are
quasi-periodic with frequencies tωt(p) which are rationally independent and satisfy
the diophantine condition (4.3) with ω = ωt(p) and γ = Γtd. These invariant tori
distribute C∞-smoothly in the phase space due to the C∞-smoothness of the conju-
gation Ψt. Moreover, we have the same estimates for the measure of Dt and for the
closeness of Ψt to Ψ as (3.15) and (3.16), with larger constants c4 and c8, in which Et,
E, Φt and I are replaced by Dt, D, Ψt and Ψ respectively. For β ≥0, if we choose d
satisfying
0 < d <
s
2 + β ,
(3.18)
then, from the above estimates, we see that Ψt, with the domain of deﬁnition Bt×Tn,
converges to the Ψ in Cβ,βλ-norm and ωt, with the domain of deﬁnition Bt, converges
to ω with respect to the Cβ+1-norm as t tends to zero; the measure of Dt, the union
of invariant tori of Gt
K, tends to the measure of the phase space D. These arguments
just complete the proof of the ﬁrst part of Theorem 3.4.
Now, we prove the remainder of Theorem 3.4. From the estimates (3.15) – (3.17)
and the uniform boundedness of the diffeomorphism Ψ and its inverse as well as their
derivatives, we see that if we choose γ being ﬁxed in advance and not depending on
the time-step size t of the algorithm, then we have
mDγ,t ≥

1 −"c4(θΘ−1)−nγ

mD,
(3.19)
with constant "c4 > 0 not depending on γ and t, where Dγ,t = Ψ(Eγ,t) with Eγ,t =
Φt(Bγ,t × Tn) and with Bγ,t being the subset of B as indicated above. Note that
Bγ,t is a closed subset of Bt and Dγ,t a closed subset of Dt if t is sufﬁciently small.
Moreover, the estimate
∥Ψt −Ψ∥β,βλ;Bγ,t×Tn ≤"c8γ−(2+β)Θ1+β · ts
(3.20)
and
∥ωt −ω∥β+1;Bγ,t ≤"c8γ−(2+β)Θ2+β · ts
(3.21)
hold for any β ≥0 with "c8 > 0 not depending on γ and t. The conclusions (1)
and (2) of the last part of Theorem 3.4 are proved if we set c′
1 = "c4

θΘ−1−n and
c′
2 = "c8·max(Θ1+β, Θ2+β). From (3.19), it follows that for a sufﬁciently small γ > 0,
Dγ,t has a positive Lebesque measure. From (2.12), it follows that for any ω∗∈Ωγ,t,
there exists p∗∈B and P ∗∈Bγ,t such that ω(p∗) = ωt(P ∗) = ω∗and
|P ∗−p∗| ≤2nMLc6c7

γθΘ−1−1 · ts,
which implies that
|Ψ(P ∗, q) −Ψ(p∗, q)| ≤4n2ML$
M1c6c7

γθΘ−1−1 · ts,

13.3 KAM Theorem of Symplectic Algorithms for Hamiltonian Systems
567
uniformly for q ∈Tn, where $
M1 is an upper bound of the norm of ∂Ψ
∂z (p, q) for
(p, q) ∈S
r0
2 , ρ0
2

. This estimate, together with (3.20), proves the third conclusion
of the second part of Theorem 3.4. Theorem 3.4 is completely proved.
▲
A natural corollary of the above theorem is:
Corollary 3.5. Under the assumptions of the above theorem, there exists n functions
F t
1, · · · , F t
n which are deﬁned on the Cantor set Dt and of class C∞in the sense of
Whitney such that:
1◦
F t
1, · · · , F t
n are functionally independent and in involution (i.e., the Poisson
bracket of any two functions vanishes on Dt);
2◦
Every F t
j (j = 1, · · · , n), is invariant under the difference scheme and the
invariant tori are just the intersection of the level sets of these functions;
3◦
F t
j (j = 1, · · · , n) approximate n independent integrals in involution of the
integrable system, with a suitable order of accuracy with respect to the time-step t
which will be explained in the proof.
Proof. By Theorem 3.4, we have
Gt
K ◦Ψt(p, q) = Ψt ◦Rt(p, q),
for (p, q) ∈Bt × Tn,
(3.22)
where Rt is the integrable rotation (p, q) →(p, q + tωt(p)) and admits n invariant
functions, say, p1, · · · , pn, analytically deﬁned on Bt × Tn. Let
F t
i = pi ◦Ψ−1
t ,
i = 1, · · · , n,
then they are well-deﬁned on the Cantor set Dt and of class C∞in the sense of
Whitney due to the C∞-smoothness of Ψ−1
t
on Dt. Moreover, we easily verify by
(3.22) that
F t
i ◦Gt
K = F t
i ,
i = 1, · · · , n,
and this means that F t
i (i = 1, · · · , n) are n invariant functions of Gt
K. These n invari-
ant functions are functionally independent because pi (i = 1, · · · , n) are functionally
independent and Ψt is a diffeomorphism. The claim that F t
i and F t
j are in involution
for 1 ≤i, j ≤n simply follows from the fact that pi and pj are in involution and Ψt
is symplectic. Note that the Poisson bracket is invariant under symplectic coordinate
transformations. Finally, it is observed from the proof of Theorem 3.4 that for each of
j = 1, · · · , n, F t
j approximates
Fj = pj ◦Ψ−1
as t →0, with the order of accuracy equal to ts−(2+β)d 
0 < d <
s
2 + β is given

on
the set Dt (note that this set depends also on d by deﬁnition) and equal to ts on Dγ,t,
a subset of Dt, in the norm of the class Cβ for any given β ≥0. It is clear that the
functions Fj (j = 1, · · · , n) are integrals of the integrable system and that any two of
them are in involution by the symplecticity of Ψ−1. Corollary 3.5 is then proved.
▲

568
13. KAM Theorem of Symplectic Algorithms
13.4 Resonant and Diophantine Step Sizes
It is observed from the proof of Theorem 3.4 that the preserved invariant tori have
frequencies of the form ωt = tω, where t is the step size of the algorithm and ω
belongs to the frequency domain of the system, which the algorithm applies to. The
frequency tω is required to satisfy the diophantine condition
 exp (i⟨k, tω⟩) −1
 ≥tγ
|k|τ ,
0 ̸= k ∈Zn
(4.1)
with some γ > 0 and τ > 0, where ⟨u, v⟩denotes the inner product of vectors u and
v in Rn. Note that t > 0 may be arbitrarily small.
For any ﬁxed ω ∈Rn, even if it is a diophantine vector, there exists some t in any
small neighborhood of the origin such that (4.1) does not hold for any γ > 0 and any
τ > 0. In fact, one can choose t to satisfy the resonance relation
exp (i⟨k, tω⟩) = 1
(4.2)
for some 0 ̸= k ∈Zn. In the next section, we will show that such t forms a dense set
in R.
We note that a one-step algorithm, when applied to system of differential equa-
tions, can be regarded as a perturbation of the phase ﬂow of the system. On the other
hand, according to Poincar´e, arbitrarily small perturbations in the generic case may
destroy those resonant invariant tori of an integrable system. Therefore, to simulate
the invariant torus with a given frequency of some Hamiltonian system by symplectic
algorithms, one is forced to be very careful to select step sizes, say, to keep them away
from some dense set.
Some questions arise: is it possible to simulate an invariant torus of an integrable
system by symplectic algorithms? If possible, how does one select the step sizes and
what structure does the set of those admitted step sizes have? In this paper, we try to
answer these questions.
13.4.1 Step Size Resonance
For any frequency vector, step size resonance may take place very often.
Lemma 4.1. For any ω ∈Rn, there exists a dense subset, say D(ω), of R such that
for any t ∈D(ω), the resonance relation (4.2) holds for some 0 ̸= k ∈Zn.
Proof. If ⟨k, ω⟩= 0 for some 0 ̸= k ∈Zn, then D(ω) = R. If ⟨k, ω⟩̸= 0 for any
0 ̸= k ∈Zn, then
D(ω) =

t =
2πl
⟨k, ω⟩: 0 ̸= k ∈Zn, l ∈Z

,
(4.3)
which is clearly dense in R and the resonance relation (4.2) holds for any t ∈D(ω).
The proof of the lemma is completed.
▲

13.4 Resonant and Diophantine Step Sizes
569
Deﬁnition 4.2. D(ω) is called the resonant set of step sizes with respect to the fre-
quency ω ∈Rn. Any t ∈D(ω) is called a resonant step size with respect to ω.
From Lemma 3.1, If ω ∈Rn is a resonant frequency, i.e., ⟨k, ω⟩= 0 for some
0 ̸= k ∈Zn, then D(ω) = R. In other words, each step size is resonant with respect
to a resonant frequency. If ω ∈Rn is a nonresonant frequency, i.e., ⟨k, ω⟩̸= 0 for
any 0 ̸= k ∈Zn, then D(ω) is a countable and dense set of R. Because a resonant
torus may be destroyed by arbitrarily small Hamiltonian perturbations (Poincar´e), any
invariant torus with frequency ω of a generic integrable system may not be preserved
by symplectic algorithms with step sizes in D(ω). To simulate an invariant torus of
the frequency ω, it is natural to consider those step sizes which are far away from
the resonant set D(ω). Note that if ω is of at least 2 dimensions, the resonant set
D(ω) is “denser” than the rational numbers in R because the set D(ω) consists of all
real numbers in the case when ω is resonant and consists of all numbers of the form
αkr in the case when ω is nonresonant, where r takes any rational number and, for
k ∈Zn \ {0}, αk =
2π
⟨k, ω⟩which may be arbitrarily small and large, and moreover,
there are arbitrarily many pairs of rationally independent numbers in αk. Anyway, for
nonresonant ω, D(ω) is countable.
13.4.2 Diophantine Step Sizes
Even though the step size may encounter resonance densely, we can still have a big
possibility to select step sizes to keep away from resonance. We discuss this as follows.
Deﬁnition 4.3. A number t ∈R is said to be of diophantine type with respect to the
nonresonant frequency ω ∈Rn, if
t −
2πl
⟨k, ω⟩
 ≥
λ
lμ|k|τ ,
0 ̸= k ∈Zn, 0 < l ∈Z
(4.4)
for some constants λ > 0, μ and τ > 0.
We denote by Iλ,μ,τ(ω), the set of numbers τ satisfying (4.4) for given constants
λ > 0, μ and τ > 0. Then, Iλ,μ,τ(ω) is a subset of R which is far away from resonance
with respect to ω. For this set, we have:
Lemma 4.4. For any nonresonant frequency ω ∈Rn, and for any λ > 0, any μ and
any τ > 0, the set Iλ,μ,τ(ω) is nowhere dense and closed in R. Moreover, if μ > 1
and τ > n, then we have
meas

R \ Iλ,μ,τ(ω)

≤cλ,
(4.5)
where c is a positive number depending only on n, μ and τ.
Proof. The nowhere denseness and the closedness of Iλ,μ,τ(ω) follow from the fact
that the complement of the set is both open and dense in R for any λ > 0, μ and
τ > 0. It remains to prove (4.5). Since

570
13. KAM Theorem of Symplectic Algorithms
R \ Iλ,μ,τ(ω) =
,
0<l∈Z
0̸=k∈Zn
'
t ∈R :
t −
2πl
⟨k, ω⟩
 <
λ
lμ|k|τ
/
,
we have
meas

R \ Iλ,μ,τ(ω)

≤

0<l∈Z
0̸=k∈Zn
2λ
lμ|k|τ ≤2λ
∞

l=1
1
lμ ·

0̸=k∈Zn
1
|k|τ .
Deﬁne
cμ =
∞

l=1
1
lμ .
Then cμ < ∞when μ > 1 and

0̸=k∈Zn
|k|−τ =
∞

m=1
1
mτ · #{k ∈Zn : |k| = m} ≤2n
∞

m=1
1
mτ Cn+m−1
m
≤22n−1
∞

m=1
1
mτ−n+1 = 22n−1 cτ−n+1 < ∞
when τ > n, here #S denotes the number of the elements of the set S and Cs
k are
binomial coefﬁcients. (4.5) is veriﬁed with
c = 4ncμcτ−n+1.
(4.6)
Therefore, the lemma is completed.
▲
Remark 4.5. We may deﬁne Iλ,μ,τ(ω) to be empty for any resonant frequency ω and
any λ > 0, any μ and any τ > 0 because no number t satisﬁes (4.4) in this case. It is
possible that the set Iλ,μ,τ(ω) may still be empty even for nonresonant frequencies ω
if here the numbers μ and τ are not properly chosen. Anyway, the above lemma shows
that if μ > 1 and τ > n, then the set Iλ,μ,τ(ω) has positive Lebesgue measure and
hence is nonempty for any λ > 0.
Remark 4.6. If λ1 > λ2 > 0, then Iλ1,μ,τ(ω) ⊂Iλ2,μ,τ(ω). Therefore, if ω is a
nonresonant frequency and μ > 1 and τ > n, then the set of all real numbers t
satisfying (4.4) for some λ > 0 has full Lebesgue measure in any measurable set
of R. It should be an interesting number theoretic problem to study the cases when
μ ≤1 or τ ≤n. In numerical analysis, the step sizes are usually considered only in a
bounded interval. We take the interval [−1, 1] as illustration without loss of generality.
Lemma 4.7. For a nonresonant frequency ω = (ω1, ω2, · · · , ωn), assume 0 < λ <
2π
|ω| with |ω| = max
1≤j≤n |ωj|. If −1 ≤μ ≤1 and μ + τ > n + 1, then we have
meas

[−1, 1] \ Iλ,μ,τ(ω)

≤"cλ,
(4.7)
where "c is a positive number depending not only on n, μ and τ but also on |ω|.

13.4 Resonant and Diophantine Step Sizes
571
Proof. The set [−1, 1] \ Iλ,μ,τ(ω) is contained in the union of all subintervals
% 2πl
⟨k, ω⟩−
λ
lμ|k|τ ,
2πl
⟨k, ω⟩+
λ
lμ|k|τ
&
for those l ∈Z, l > 0 and k ∈Zn \ {0} such that
2πl
|⟨k, ω⟩| < 1 +
λ
lμ|k|τ .
(4.8)
Since −1 ≤μ ≤1, we have that τ > n + 1 −μ ≥n and (3.30) implies that
|k| >
 2π
|ω| −λ

l. Therefore,
meas

[−1, 1] \ Iλ,μ,τ(ω)

≤
∞

l=1

|k|>Nl,λ
2λ
lμ|k|τ ≤4nλ
∞

l=1
1
lμ

m>Nl,λ
1
mτ−n+1 ,
where Nl,λ =
 2π
|ω| −λ

l which is positive for positive l. We will use the following
estimate which is easy to prove:

m>N
1
mτ−n+1 ≤
⎧
⎨
⎩
cτ−n+1,
0 < N ≤1,
1
(τ −n)(N −1)τ−n ,
N > 1.
(4.9)
Assume lλ is the integer such that Nlλ,λ ≤1 and Nlλ+1,λ > 1. Then (4.7) is veriﬁed
with
"c = 4n
⎛
⎜
⎜
⎜
⎝cτ−n+1
lλ

l=1
1
lμ +
1
τ −n
∞

l=lλ+1
1
lμ
%%
2π
|ω| −λ
&
l −1
&τ−n
⎞
⎟
⎟
⎟
⎠
(4.10)
which is ﬁnite because the conditions μ + τ > n + 1 and 0 < λ < 2π
|ω| guarantee the
convergence of the inﬁnite summation in (4.1). If lλ = 0, then we take
lλ

l=1
1
lμ
= 0
and hence the ﬁrst term in the bracket of Equation (4.10) disappears in this case. Note
that here the number "c depends also on λ, but this dependence is not fatal essentially
because the only harmful case is when λ is close to 2π
|ω|. However, this case is not of
interest and may always be avoided. For example, we simply assume 0 < λ ≤π
|ω| in
the lemma. The proof of Lemma 4.7 is completed.
▲
Therefore, to guarantee the positiveness of the Lebesgue measure of the set
Iλ,μ,τ(ω), it is not necessary to assume μ > 1. One may require μ to only sat-
isfy μ ≥−1. In the case −1 ≤μ ≤1, however, one has to additionally require

572
13. KAM Theorem of Symplectic Algorithms
μ + τ > n + 1, which automatically implies that τ > n. One may also consider how
big the set Iλ,μ,τ(ω) is in other unit intervals with integer endpoints, but we do not go
further in this direction.
Remark 4.8. It remains to study the set Iλ,μ,τ(ω) in other cases: μ < −1 or τ ≤n
or μ + τ ≤n + 1. I believe the Lebesgue measure of the set is zero in each of these
cases. It is also an interesting problem to calculate the Hausdorff dimensions of the
set Iλ,μ,τ(ω) in all of these cases. The cases when −1 ≤μ ≤1 and ν = n −μ + 1
and when μ > 1 and τ = n should be particularly interesting. In all other cases, I
intend to believe the set is empty. Note that a special case when n = 1, μ = 0 and
τ = n−μ+1 = 2 with ω = 2π just corresponds to the classical diophantine problem
on approximating an irrational number by rational ones.
To any nonresonant frequency ω in Rn, we have associated a 3-parameter family
of sets Iλ,μ,τ(ω) on the real line. The set Iλ,μ,τ(ω) has positive Lebesgue measure
and hence is nonempty if μ ≥−1, τ > n, μ + τ > n + 1 and λ > 0 suitably small
(in the case when μ > 1 and τ > n, Iλ,μ,τ(ω) has positive Lebesgue measure for
any λ > 0). But to guarantee an invariant torus of the frequency tω for symplectic
algorithms with the step size t, it seems that the only way is to require tω satisfy a
diophantine condition of the type (1.1) (J. Mather showed in [Mat88]) that for any exact
area-preserving twist mapping, an invariant circle with any Liouville frequency can be
destroyed by arbitrarily small perturbations in C∞-topology). This is the case when
one requires both ω be a diophantine frequency and t be a diophantine step size with
respect to the ω, as the following lemma shows.
Lemma 4.9. Let γ > 0 and 0 < λ ≤1. Then for any ω ∈Ωγ(τ1)6 and any t ∈
[−1, 1] ∩Iλ,μ,τ2(ω), we have
ei⟨k,tω⟩−1
 ≥
|t|"γ
|k|μ+τ1+τ2 ,
0 ̸= k ∈Zn,
(4.11)
where
"γ =
2λγ
π

1 + 1
2π |ω|
μ .
(4.12)
Proof. It is easy to prove that for k ∈Zn, k ̸= 0, there exists l ∈Z such that
ei⟨k,tω⟩−1
 ≥2
π
⟨k, tω⟩+ 2πl
.
We have two cases:
1◦
l = 0. Since ω ∈Ωγ(τ1),
ei⟨k,tω⟩−1
 ≥2
π
⟨k, tω⟩
 ≥2|t|γ
π|k|τ1 ;
6 We denote by Ωγ(τ), the set of all vectors ω ∈Rn satisfying the diophantine condition of
the form
|⟨k, ω⟩| ≥
γ
|k|τ ,
0 ̸= k ∈Zn.

13.4 Resonant and Diophantine Step Sizes
573
2◦
l ̸= 0. Since t ∈Iλ,μ,τ2(ω) and ω ∈Ωγ(τ1),
ei⟨k,tω⟩−1
 ≥2
π

J
k,

t +
2πl
⟨k, ω⟩

ω
K = 2
π
t +
2πl
⟨k, ω⟩

⟨k, ω⟩

≥2
π ·
λγ
lμ|k|τ1+τ2 .
But
|2πl| ≤|⟨k, tω⟩+ 2πl| + |⟨k, tω⟩| ≤π
2
ei⟨k,tω⟩−1
 + |t||⟨k, ω⟩|
≤π + |t| |ω||k|,
therefore,
ei⟨k,tω⟩−1
 ≥
2λγ
π
% 1
2 + |t|
2π |ω|
&μ
|k|μ+τ1+τ2
.
Combining the two cases, (4.11) is veriﬁed and hence Lemma 2.4 is proved.
▲
From the above lemmas and the fact that meas

Rn \ #
γ>0
Ωγ(τ)

= 0 for τ >
n −1, we conclude that for almost all ω ∈Rn and almost all t ∈[−1, 1], tω satisﬁes
a diophantine condition of the mapping type (2.5). As the step size of a difference
scheme, however, t may fall into an arbitrarily small neighbourhood of the origin.
The next lemma shows that for a nonresonant frequency ω ∈Rn and for μ ≥−1,
τ > n + 1, μ + τ > n + 1 and 0 < λ < 2π
|ω|, the set Iλ,μ,τ(ω) has large measure near
the origin of the real line.
Lemma 4.10. Let ω be a nonresonant frequency of Rn. Let λ > 0, μ ≥−1, τ > n
and μ + τ > n + 1. For any δ > 0, let
Jδ
λ,μ,τ(ω) = (−δ, δ) \ Iλ,μ,τ(ω).
If λ + δ < 2π
|ω|, then
meas Jδ
λ,μ,τ(ω) ≤dδτ−n,
(4.13)
where
d = 4nλ
τ −n
∞

l=1
1
lμ
%%
2π
|ω| −λ
&
l −δ
&τ−n < ∞.
(4.14)
Consequently, if in addition τ > n + 1, then
lim
δ→0+
meas

Iλ,μ,τ(ω) ∩(−δ, δ)

meas(−δ, δ)
= 1.
(4.15)

574
13. KAM Theorem of Symplectic Algorithms
Proof. Let t ∈Jδ
λ,μ,τ. By deﬁnition, we have
−δ −
λ
lμ|k|τ ≤
2πl
⟨k, ω⟩≤δ +
λ
lμ|k|τ
(4.16)
for some k ∈Zn and 0 < l ∈Z. Fix l ∈Z, l ̸= 0, denoted by Kδ
l the set of k ∈Zn
satisfying (4.16). If k ∈Kδ
l , then
2πl
δ +
λ
lμ|k|
≤
2πl
δ +
λ
lμ|k|τ
≤|⟨k, ω⟩| ≤|k| |ω|,
which implies that
|k| >
* 2π
|ω| −λ
δ
+
l .= N δ
l
since μ ≥−1. This shows that Kδ
l ⊂
(
k ∈Zn : |k| > N δ
l
)
and therefore,
meas Jδ
λ,μ,τ(ω) ≤
∞

l=1

k∈Zn
|k|>Nδ
l
2λ
lμ|k|τ ≤4nλ
∞

l=1
1
lμ

m>Nδ
l
1
mτ−n+1 .
Because 0 < δ + λ < 2π
|ω|, we have N δ
l > 1. (4.13) follows from (4.9) with the
constant d deﬁned by (4.14), which is ﬁnite because τ > n and μ + τ −n > 1. (4.15)
is true if, in addition, τ > n + 1.
▲
13.4.3 Invariant Tori and Further Remarks
Now, we summarize the main result of this section as follows.
Theorem 4.11. Given an analytic, nondegenerate and integrable Hamiltonian system
of n degrees of freedom, and given a frequency ω, in the domain of the frequencies of
the system, which satisﬁes the diophantine condition of the form
|⟨k, ω⟩| ≥
γ
|k|τ ,
0 ̸= k = (k1, · · · , kn) ∈Zn
(4.17)
for some γ > 0 and τ > 0, there exists a Cantor set I(ω) of R, for any symplectic
algorithm applied to the system, there exists a positive number δ0 such that if the step
size t of the algorithm falls into the set (−δ0, δ0)∩I(ω), then the algorithm, if applied
to the integrable system, has an invariant torus of frequency tω. The invariant torus of
the algorithm approximates the invariant torus of the system in the sense of Hausdorff
with the order equals to the order of accuracy of the algorithm. The Cantor set I(ω)
has density one at the origin in the sense that
lim
δ→0+
m

(−δ, δ) ∩I(ω)

m(−δ, δ)
= 1.
(4.18)

13.4 Resonant and Diophantine Step Sizes
575
Proof. For the given ω, we deﬁne I(ω) = Iλ,μ,"τ(ω) for some λ > 0, μ > 1 and
"τ > n + 1. By Lemma 3.7, we have for any t ∈[−1, 1] ∩I(ω),
ei⟨k,tω⟩−1
 ≥
|t|"γ
|k|μ+τ+"τ ,
0 ̸= k ∈Zn
with "γ given by (4.12). The analytic version of Theorem 2.4 may be applied and there-
fore, for a symplectic algorithm applied to the given system7, we can ﬁnd a positive
number δ0, which depends on the numbers n, γ, τ, λ, μ, "τ and |ω| and on the non-
degeneracy and the analyticity of the system and, of course, also on the algorithm,
such that the algorithm has an invariant torus of the frequency tω with the required
approximating property to the corresponding invariant torus of the system if the step
size t falls into the set [−δ0, δ0] ∩I(ω). It follows from Lemma 3.8 that the set I(ω)
has density one at the origin because we have chosen μ > 1 and "τ > n + 1.
▲
Remark 4.12. In practical computations, one would like to choose big step sizes. It
is interesting to look at how the δ0 in Theorem 4.11 depends on the nonresonance
property of the frequency ω and how the δ0 relates to the size of the diophantine set
I(ω) of step sizes. It is known that the parameters γ and ν describe the nonresonance
property of the frequency ω and the parameters λ, μ and "ν determine the size of the
set I(ω). Among them, the most interesting are γ and λ because we may ﬁx all others
in advance without loss of generality. For a given ω, we deﬁne γ to be the biggest
one such that (4.17) holds for a ﬁxed τ > n −1. It is easy to see, from Lemma 4.9
and Theorem 2.4, that δ0 may be chosen to be proportional to (γλ)
2
s , where s is the
order of accuracy of the algorithm considered in Theorem 4.11. Note that the more
nonresonant the ω is, the bigger γ will be and therefore the bigger δ0 is admitted. On
the other hand, for a given ω, the bigger step size is taken, the bigger λ has to be
chosen and in this case, the set I(ω) turns out to be smaller. But anyway, the set I(ω)
is of density one at the origin. Consequently, to simulate an invariant torus, one has
much more possibilities to select available small step sizes than to select available big
ones.
Remark 4.13. It is interesting to make some comparisons between Theorem 3.4 and
Theorem 4.11. Theorem 3.4 shows that a symplectic algorithm applied to an analytic
nondegenerate integrable Hamiltonian system has so many invariant tori that the tori
form a set of positive Lebesgue measures in the phase space if the step size of the algo-
rithm is sufﬁciently small and ﬁxed in an arbitrary way. No additional nonresonance or
diophantine condition is imposed on the step size. But the set of frequencies of the in-
variant tori depends on the step size and, therefore, changes in general as the step size
changes. It is a fact that the measure of the set of frequencies of the invariant tori be-
comes larger and larger as the step size gets smaller and smaller. These sets, however,
may not intersect at all for step sizes taken over any interval near the origin. There-
fore, the invariant tori of any frequencies may not be guaranteed for any symplectic
algorithm with step size randomly taken in any neighbourhood of the origin. Theorem
7 So far, the available symplectic algorithms are exact symplectics when they are applied to
global Hamiltonian systems and analytics when applied to analytic systems.

576
13. KAM Theorem of Symplectic Algorithms
4.11 shows that an invariant torus with any ﬁxed diophantine frequency of an analytic
nondegenerate integrable Hamiltonian system can always be simulated very well by
symplectic algorithms for any step size in a Cantor set of positive Lebesgue measure
near the origin. The following theorem shows that one can simulate simultaneously
any ﬁnitely many invariant tori of given diophantine frequencies by symplectic algo-
rithms with a sufﬁciently big probability to select available step sizes. The step sizes,
of course, also have to be restricted to a Cantor set.
Theorem 4.14. Given an analytic, nondegenerate and integrable Hamiltonian system
of n degrees of freedom. Given N diophantine frequencies ωj (j = 1, 2, · · · , N), in
the domain of the frequencies of the system, there exists a Cantor set I of R, depending
on the N frequencies, such that for any symplectic algorithm applied to the system,
there exists a positive number δ0 such that if the step size t of the algorithm falls
into the set (−δ0, δ0) ∩I, then the algorithm has N invariant tori of the frequencies
τωj (j = 1, 2, · · · , N) when it applies to the integrable system. These invariant tori
approximate the corresponding ones of the system in the sense of Hausdorff with the
order equal to the order of accuracy of the algorithm. The Cantor set I has density
one at the origin.
Proof. The proof of Theorem 4.14 follows from Theorem 4.11 and
▲
Lemma 4.15. For any integer N ≥1, any ωj ∈Ωγ(τ) (j = 1, 2, · · · , N) and any
δ > 0, put AN = (ω1, ω2, · · · , ωN) and
IN
λ,μ,"τ(AN) =
N
L
j=1
Iλ,μ,"τ(ωj),
Jδ
λ,μ,"τ(AN) = (−δ, δ) \ IN
λ,μ,"τ(AN)
with given λ > 0, μ ≥−1, "τ > n + 1 and μ + "τ > n + 1. Then we have
meas Jδ
λ,μ,"τ(AN) ≤Ndδ"τ−n
if λ + δ <
2π
|AN|, where |AN| =
max
1≤j≤N |ωj| and d is deﬁned by (4.14) where τ is
replaced by "τ and |ω| replaced by |AN|. Consequently, the set IN
λ,μ,"τ(AN) has density
one at the origin. Moreover, for any t ∈[−1, 1] ∩IN
λ,μ,"τ(AN), we have
ei⟨k,tωj⟩−1
 ≥
|t|"γ
|k|μ+τ+"τ ,
0 ̸= k ∈Zn,
j = 1, 2, · · · , N
with "γ given by (4.12) where |ω| replaced by |AN|.
Proof. Lemma 4.15 is a natural corollary of Lemmas 4.9 and 4.10.
▲
Remark 4.16. There have been some works about exponential stability of symplec-
tic algorithms in simulating invariant tori with given diophantine frequencies of in-
tegrable or nearly integrable systems (Benettin and Giorgilli (1994)[BG94], Hairer and
Lubich in 1997[HL97] and Stoffer in 1998[Sto98b]). The result, for example, of Hairer and

13.4 Resonant and Diophantine Step Sizes
577
Lubich[HL97] shows that during a very long interval of iteration steps (exponentially
long in 1/t ), the numerical orbits of a symplectic algorithm approximate the exact
orbits of some perturbed Hamiltonian system8 with a very small error (exponentially
small in −1/t ) if the starting values of the numerical orbits and the exact ones are the
same and are taken on the invariant torus of the perturbed system (the invariant torus
is guaranteed by the KAM theorem)[HL97] (Corollary 7) or taken in a neighbourhood
of the invariant torus with the radius of order t2n+2 (this is easily derived from Hairer
and Lubich (1997, Corollary 8)), here n is the degrees of freedom of the Hamiltonian
system and t is the step size of the algorithm which is assumed to be sufﬁciently small.
Theorems 4.11 and 4.14 show that one may generate quasi-periodic (therefore, perpet-
ually stable) numerical orbits using a symplectic algorithm which approximate exact
quasi-periodic orbit of an analytic nondegenerate integrable Hamiltonian system if the
step sizes of the algorithm fall into a Cantor set of large density near the origin. As the
step size in this Cantor set gets smaller and smaller, more and more stable numerical
orbits appear. For such a stability consideration, Theorem 3.4 shows much more: the
perpetually stable numerical orbits take up a large set of the phase space so that the
Lebesgue measure of the set approaches the Lebesgure measure of the phase space
as the step size approaches zero. Due to the well-known topological conﬁnement of
the phase plane between invariant closed curves, this implies the perpetual stability of
symplectic algorithms applied to one degree of freedom systems for any initial values
if the step size is small.
Remark 4.17. Generally speaking, it is difﬁcult to check the diophantine condition
for a step size with respect to a nonresonant frequency vector. An obvious fact is
fortunately, however, that step sizes N −1, with N being integers, satisfy the diophan-
tine condition (4.4) with respect to frequency vectors satisfying diophantine condition
(2.8). This fact was checked by Dujardin and Faou in 2007[DF07] for the 1 + 1 di-
mensional linear Schr¨odinger equation with a periodic potential, where a spatially
periodic solution can be stably simulated using nonresonant step size t = 1
5 = 0.2,
but is quickly violated using resonant step size t =
2π
62 −22 ∼0.196.
8 The perturbed Hamiltonian system approximates the symplectic algorithm and is determined
uniquely, in the setting of the backward analysis, by the algorithm and the Hamiltonian
system which the algorithm applies to[Hai94].

Bibliography
[AA89] V. I. Arnold and A. Avez: Ergodic Problems of Classical Mechanics. Addison-Wesley
and Benjamin Cummings, New York, (1989).
[Arn63] V.I. Arnold:
Proof of A. N. kolmogorov’s theorem on the preservation of quasi-
periodic motions under small perturbations of the Hamiltonian,. Russian Math. Surveys,
18(5):9–36, (1963).
[Arn89] V. I. Arnold: Mathematical Methods of Classical Mechanics. Springer-Verlag, GTM
60, Berlin, Heidelberg, Second edition, (1989).
[BB79] K. Burrage and J.C. Butcher: Stability criteria for implicit Runge–Kutta methods.
SIAM J. Numer. Anal., 16:46–57, (1979).
[Bey87] W. J. Beyn: On invariant closed curves for one-step methods. Numer. Math., 51:103–
122, (1987).
[BG94] G. Benettin and A. Giorgilli: On the Hamiltonian interpolation of near to the identity
symplectic mappings with application to symplectic integration algorithms. J. Stat. Phys.,
74:1117–1143, (1994).
[But75] J. C. Buther: A stability property of implicity Runge–Kutta methods. BIT, 15(3):358–
361, (1975).
[CD09] F. Castella and G. Dujardin: Propagation of gevrey regularity over long times for
the fully discrete Lie-Trotter splitting scheme applied to the linear Schr¨odinger equation.
ESIAM: Mathmatical Modelling and Numericalo Analysis, 43(4):651–676, (2009).
[CFM06] P. Chartier, E. Faou, and A. Murua: An algebraic approach to invariant preserving
integrators; the case of quadratic and Hamiltonian invariants. Numer. Math., 103(4):575–
590, (2006).
[CG82] L. Chierchia and G. Gallavotti: Smooth prime integralsfor quasi-integrable Hamilto-
nian systems. IL Nuovo Cimento, 67, 277– 295, (19820.
[CS90] P.J. Channell and C. Scovel: Symplectic integration of Hamiltonian systems. Nonlin-
earity, 3:231–259, (1990).
[CS94] C. G. Cheng and Y. S. Sun: Existence of KAM tori in degenerate Hamiltonian systems.
J. Differential Equations, 114(1):288–335, (1994).
[Dah63] G. Dahlquist: A special stability problem for linear multistep methods. BIT, 3(1):27–
43, (1963).
[Dah75] G. Dahlquist: Error analysis for a class of methods for stiff nonlinear initial value
problems.
In G.A. Watson, editor, Lecture notes in Mathematics, Vol. 506, Numerical
Analysis, Dundee, pages 60–74. Springer, Berlin, (1975).
[Dah78] G. Dahlquist: G-stability is equivalent to A-stability. BIT, 18:384–401, (1978).
[DF07] G. Dujardin and E. Faou: Normal form and long time analysis of splitting schemes
for the linear Schr¨odinger equation with small potential. Numer. Math., 108(2):223–262,
(2007).
[Ehl69] B. L. Ehle: On Pad´e approximations to the exponential function and A-stable methods
for the numerical solution of initial value problems. Technical Report, Research Rep. No.
CSRR 2010, University of Waterloo Dept. of Applied Analysis and Computer Science,
(1969).

Bibliography
579
[Fen91] K. Feng: The Hamiltonian Way for Computing Hamiltonian Dynamics. In R. Spigler,
editor, Applied and industrial Mathmatics, pages 17–35. Kluwer, The Netherlands, (1991).
[FQ03] K. Feng and M. Q. Qin: Symplectic Algorithms for Hamiltonian Systems. Zhejiang
Science and Technology Publishing House,Hangzhou, in Chinese, First edition, (2003).
[Gar96] B. M. Garay: On structural stability of ordinary differential equations with respect to
discretization methods. Numer. Math., 72:449–479, (1996).
[Hai94] E. Hairer: Backward analysis of numerical integrators and symplectic methods. Annals
of Numer. Math., 1:107–132, (1994).
[HL97] E. Hairer and Ch. Lubich: The life-span of backward error analysis for numerical
integrators. Numer. Math., 76:441–462, (1997).
[HLW02] E. Hairer, Ch. Lubich, and G. Wanner: Geometric Numerical Integration. Num-
ber 31 in Springer Series in Computational Mathematics. Springer-Verlag, Berlin, (2002).
[HNW93] E. Hairer, S. P. Nørsett, and G. Wanner: Solving Ordinary Differential Equations I,
Nonstiff Problems. Springer-Verlag, Berlin, Second revised edition, (1993).
[HS81] W. H. Hundsdorfer and M. N. Spijker: A note on B-stability of Runge–Kutta methods.
Numer. Math., 36:319–331, (1981).
[HS94] A. R. Humphries and A. M. Stuart: Runge–Kutta methods for dissipative and gradient
dynamical systems. SIAM J. Numer. Anal., 31(5):1452–1485, (1994).
[Kol54b] A. N. Kolmogorov: On conservation of conditionally periodic motions under small
perturbations of the Hamiltonian. Dokl. Akad. Nauk SSSR,, 98:527–530, (1954).
[Laz74] V. F. Lazutkin: On Moser’s theorem on invariant curves. In Voprsoy raspr. seism. voln.
vyp. Nauka Leningrad, 14:105–120, (1974).
[Li99] M. C. Li: Structural stability for Euler method. SIAM J. Math. Anal., 30(4):747–755,
(1999).
[LR05] B. Leimkuhler and S. Reich: Simulating Hamiltonian Dynamics. Cambridge Univer-
sity Press, Cambridge, First edition, (2005).
[Mat88] J. Mather: Destruction of invariant circles. Ergod. Theory & Dynam. Sys, 8:199–214,
(1988).
[Mos62] J. Moser: On invariant curves of area-preserving mappings of an annulus. Nachr.
Akad. Wiss. Gottingen, II. Math.-Phys., pages 1–20, (1962).
[Nei82] A. I. Neishtadt: Estimates in the Kolmogorov theorem on conservation of condition-
ally periodic motions. J. Appl. Math. Mech., 45(6):766–772, (1982).
[P¨os82] J. P¨oschel: Integrability of Hamiltonian systems on Cantor sets. Comm. Pure and
Appl. Math., 35:653–695, (1982).
[R¨us81] H. R¨ussmann: On the existence of invariant curves of twist mappings of an anulus.
In J. Palis, editor, Geometric Dynamics, Lecture Notes in Math. 1007, pages 677–718.
Springer-Verlag, Berlin, (1981).
[R¨us90] H. R¨ussmann: On twist Hamiltonian. In in Colloque Internationa: M´ecanique c´eleste
et syst`emes hamiltoniens. Marseille, (1990).
[SH96] A.M. Stuart and A.R. Humphries: Dynamical Systems and Numerical Analysis. Cam-
bridge University Press, Cambridge, Second edition, (1996).
[Sha91] Z. J. Shang: On the KAM theorem of symplectic algorithms for Hamiltonian systems,.
Ph.D. thesis (in Chinese), Computing Center, Academia Sinica, (1991).
[Sha99] Z. Shang: KAM theorem of symplectic algorithms for Hamiltonian systems. Numer.
Math., 83:477–496, (1999).
[Sha00a] Z. J. Shang: A note on the KAM theorem for symplectic mappings. J. Dynam.
Differential eqns., 12(2):357–383, (2000).
[Sha00b] Z. J. Shang:
Resonant and diophantine step sizes in computing invariant tori of
Hamiltonian systems. Nonlinearity, 13:299–308, (2000).
[SSC94] J. M. Sanz-Serna and M. P. Calvo: Numerical Hamiltonian Problems. AMMC 7.
Chapman & Hall, London, (1994).
[Sto98a] D. Stoffer: On the qualitative behavior of symplectic integrator. II: Integrable systems.
J. of Math. Anal. and Applic., 217:501–520, (1998).

580
Bibliography
[Sto98b] D. Stoffer:
On the qualitative behaviour of symplectic integrators. III: Perturbed
integrable systems. J. of Math. Anal. and Appl., 217:521–545, (1998).
[Sva81] N. V. Svanidze: Small perturbations of an integrable dynamical system with an integral
invariant. In Proceedings of the Steklov Institute of Mathematics, Issue 2, pages 127–151,
(1981).
[Wid76] O. B. Widlund: A note on unconditionally stable linear multistep methods. BIT,
7(1):65–70, (1976).

Chapter 14.
Lee-Variational Integrator
In the 1980s, Lee proposed an energy-preserving discrete mechanics with variable
time steps by taking time (discrete) as a dynamical variable [Lee82,Lee87]. On the other
hand, motivated by the symplectic property of Lagrangian mechanics, a version of
discrete Lagrangian mechanics has been developed and variational integrators that
preserve discrete symplectic 2-form have been obtained [MPS98,MV91,Ves88,Ves91a,WM97],
but variational integrators obtained in this way ﬁx the time steps and consequently,
they are not energy-preserving in general.
Obviously, energy-preserving discrete mechanics and variational integrators are
more preferable, since solutions of the Euler–Lagrange equations of conservative con-
tinuous systems are not only symplectic but also energy-preserving. To attain this
goal, we should study some discrete mechanics with discrete energy conservation and
symplectic variational integrators. Recently, Kane, Marsden, and Ortiz have employed
appropriate time steps to conserve a deﬁned energy and developed what they called
symplectic energy-momentum-preserving variational integrators in [KMO99]. Although
their approach is more or less related to Lee’s discrete mechanics, the discrete energy-
preserving condition is not derived by the variational principle.
14.1 Total Variation in Lagrangian Formalism
The purpose of this section is to generalize or improve the above mentioned ap-
proaches as well as to explore the relations among discrete total variation, Lee’s dis-
crete mechanics, and Kane–Marsden–Ortiz integrators. We will present a discrete total
variation calculus with variable time steps and a discrete mechanics that is discretely
symplectic, energy-preserving and has the correct continuous limit. In fact, this dis-
crete variation calculus and mechanics is a generalization of Lee’s discrete mechan-
ics in symplectic-preserving sense and can derive directly the variational symplectic-
energy-momentum integrators of Kane, Marsden, and Ortiz.
14.1.1 Variational Principle in Lagrangian Mechanics
Before beginning this section, we will recall very brieﬂy the ordinary variational prin-
ciple in Lagrangian mechanics for later use. Suppose Q denotes the extended con-
ﬁguration space with coordinates (t, qi) and Q(1) the ﬁrst prolongation of Q with

582
14. Lee-Variational Integrator
coordinates (t, qi, ˙qi)[Olv93]. Here t denotes time and qi(i = 1, 2, · · · , n) denote the
positions. Consider a Lagrangian L : Q(1) →R. The corresponding action functional
is deﬁned by
S(qi(t)) =
- b
a
L(t, qi(t), ˙qi) d t,
(1.1)
where qi(t) is a C2 curve in Q.
Hamilton’s principle seeks a curve qi(t) denoted by Cb
a with endpoints a and b,
for which the action functional S is stationary under variations of qi(t) with ﬁxed
endpoints. Let
V = φi(t, q) ∂
∂qi
(1.2)
be a vertical vector ﬁeld on Q, here q = (q1, · · · , qn). By a vertical vector ﬁeld we
mean a vector ﬁeld on Q which does not involve terms of form ξ(t, q) ∂
∂t, for example,
time t does not undergo variation.
Let F ε be the ﬂow of V , i.e., a one-parameter group of transformations on Q :
F ε(t, qi) = (˜t, ˜qi).
˜t = t,
(1.3)
˜qi = gi(ε, t, q),
(1.4)
where
d
d ε

ε=0 gi(ε, t, q) = φi(t, q) := δqi(t).
(1.5)
In other words, the deformation (1.3) – (1.4) transforms the curve qi(t) into a
family of curves ˜qi(ε, ˜t) in Q denoted by Cb
εa which are determined by
˜t = t,
(1.6)
˜qi = gi(ε, t, q(t)).
(1.7)
Thus, we obtain a (sufﬁciently small) set of curves Cb
εa around Cb
a. Corresponding to
this set of curves there is a set of Lagrangian and action functionals
S(qi(t)) −→S(˜qi(ε, ˜t)) =
- b
a
L(˜qi(ε, ˜t), d
d ˜t ˜qi(ε, ˜t)) d ˜t.
(1.8)
Now, we can calculate the variation of S at q(t) as follows:
δS =
d
dε

ε=0S(˜qi(ε, ˜t))
=
- b
a
 %
∂L
∂qi −d
d t
∂L
∂˙qi
&
φi
!
d t + ∂L
∂˙qi φi
b
a.
(1.9)
For the ﬁxed endpoints, φi(a, q(a)) = φi(b, q(b)) = 0, the requirement of Hamilton’s
principle, δS = 0, yields the Euler–Lagrange equation for q(t)

14.1 Total Variation in Lagrangian Formalism
583
∂L
∂qi −d
d t
∂L
∂˙qi = 0.
(1.10)
If we drop the requirement of φi(a, q(a)) = φi(b, q(b)) = 0, we can naturally
obtain the Lagrangian 1-form on Q(1) from the second term in (1.9):
θL = ∂L
∂˙qI d qi,
(1.11)
where d qi are dual to
∂
∂qj , d qi ∂
∂qj

= δi
j. Furthermore, it can be proved that the
solution of (1.10) preserves the Lagrangian 2-form
ωL := dθL.
(1.12)
On the other hand, introducing the Euler–Lagrange 1-form
E(qi, ˙qi) =
' ∂L
∂qi −d
d t
∂L
∂˙qi
/
d qi,
(1.13)
the nilpotency of d leads to
d E(qi, ˙qi) + d
d tωL = 0,
(1.14)
namely, the necessary and sufﬁcient condition for symplectic structure preserving is
that the Euler–Lagrange 1-form is closed[GLW01a,GLWW01,GW03].
14.1.2 Total Variation for Lagrangian Mechanics
Consider a general vector ﬁeld on Q
V = ξ(t, q) ∂
∂t + φi(t, q) ∂
∂qi ,
(1.15)
here q = (q1, · · · , qn). Let F ε be the ﬂow of V . The variations of (t, qi) ∈Q are
described in such a way
(t, qi) −→F ε(t, qi) = (˜t, ˜qi),
(1.16)
where
˜t = f(ε, t, q),
˜qi = gi(ε, t, q)
(1.17)
with
d
dε

ε=0f(ε, t, q) = ξ(t, q) := δt,
d
dε

ε=0gi(ε, t, q) = φi(t, q) := δqi.
(1.18)
The deformations (1.17) transform a curve qi(t) in Q denoted by Cb
a into a set of
curves ˜qi(ε, ˜t) in Q denoted by C˜b
ε˜a, determined by

584
14. Lee-Variational Integrator
˜t = f(ε, t, q(t)),
˜qi = gi(ε, t, q(t)).
(1.19)
Before calculating the total variation of S, we will introduce the ﬁrst-order prolonga-
tion of V denoted as pr1V
pr1V = ξ(t, q) ∂
∂t + φi(t, q) ∂
∂qi + αi(t, q, ˙q) ∂
∂˙qi ,
(1.20)
here
αi(t, q, ˙q) = Dtφi(t, q) −˙qiDtξ(t, q),
(1.21)
where Dt denotes the total derivative with respect to t, for example,
Dtφk(t, qi) = φk
t + φk
qi ˙qi,
φk
t = ∂φk
∂t .
For prolongations of the vector ﬁeld and the related formulae, refer to[Olv93].
Now, we let us calculate the total variation of S straightforwardly:
δS =
d
dε

ε=0S(˜qi(ε, ˜t)) = d
dε

ε=0
- ˜b
˜a
L

˜t, ˜qi(ε, ˜t), d
d˜t ˜qi(ε, ˜t)

d ˜t
=
d
dε

ε=0
- b
a
L

˜t, ˜qi(ε, ˜t), d
d ˜t ˜qi(ε, ˜t)
d˜t
dt d t
˜t = f(ε, t, q(t))

=
- b
a
d
d ε

ε=0L

˜t, ˜qi(ε, ˜t), d
d ˜t ˜qi(ε, ˜t)

d t +
- b
a
L

t, qi(t), ˙qi(t)

Dtξ d t
=
- b
a
∂L
∂t ξ + ∂L
∂qi φi + ∂L
∂˙qi (Dtφi −˙qiDtξ)

d t +
- b
a
LDtξ d t
=
- b
a
 ∂L
∂t + d
dt
 ∂L
∂˙qi ˙qi −L

ξ +
 ∂L
∂qi −d
dt
∂L
∂˙qi

φi
!
d t
+
 
L −∂L
∂˙qi ˙qi
ξ + ∂L
∂˙qi φi
! 
b
a.
(1.22)
Here we have made use of (1.18), (1.20), (1.21) and
d
d ε

ε=0
d ˜t
d t = d
d t
d
d ε

ε=0
˜t = Dtξ.
If ξ(a, q(a)) = ξ(b, q(b)) = 0 and φi(a, q(a)) = φi(b, q(b)) = 0, the requirement
of δS = 0 yields the equation from ξ, the variation along the base manifold, i.e., the
time.
∂L
∂t + d
dt
 ∂L
∂˙qi ˙qi −L

= 0,
(1.23)
and the Euler–Lagrange equation from φi, the variation along the ﬁber, i.e., the con-
ﬁguration space,
∂L
∂qi −d
dt
∂L
∂˙qi = 0.
(1.24)

14.1 Total Variation in Lagrangian Formalism
585
Here ξ and φi are regarded as independent components of total variation. However,
there is another decomposition for the independent components, i.e., the vertical and
horizontal variations; see Remark1.2 below.
If L does not depend on t explicitly, i.e., L is conservative, ∂L
∂t = 0, then (1.23)
becomes the energy conservation law
d
dtH = 0,
H :=
 ∂L
∂˙qi ˙qi −L

.
(1.25)
By expanding the left-hand side of (1.25), we obtain
d
dt
% ∂L
∂˙qi ˙qi −L
&
= −
% ∂L
∂qi −d
dt
∂L
∂˙qi
&
˙qi.
(1.26)
Thus, for a conservative L, energy conservation is a consequence of Euler–Lagrange
equation. This agrees with Noether theorem which states that the characteristic of an
inﬁnitesimal symmetry of the action functional S is that of a conservation law for the
Euler–Lagrange equation. For a conservative L, ∂
∂t is an inﬁnitesimal symmetry of
the action functional S, and its characteristic is −˙qi. From Noether theorem, there
exits a corresponding conservation law in the characteristic form
−
% ∂L
∂qi −d
d t
∂L
∂˙qi
&
˙qi = 0.
(1.27)
If we drop the requirement
ξ(a, q(a)) = ξ(b, q(b)) = 0,
φi(a, q(a)) = φi(b, q(b)) = 0,
(1.28)
we can deﬁne the extended Lagrangian 1-form on Q(1) from the second term in (1.22)
ϑL :=
%
L −∂L
∂˙qi ˙qi
&
dt + ∂L
∂˙qi d qi.
(1.29)
Suppose gi(t, vqi) is a solution of (1.24) depending on the initial condition vqi ∈Q(1).
Restricting ˜qi(ε, ˜t) to the solution space of (1.24) and using the same method in[MPS98],
it can be proved that the extended symplectic 2-form is preserved:
(pr1gi)∗ΩL = ΩL,
ΩL := dϑL,
(1.30)
where pr1gi(s, vqi) =

s, gi(s, vqi), d
d s gi(s, vqi)

denotes the ﬁrst-order prolonga-
tion of gi(s, vqi)[Olv93].
Remark 1.1. If ξ in (1.15) is independent of q, the deformations in (1.17) are called
ﬁber-preserving. In this case, the domain of deﬁnition of ˜qi(ε, ˜t) only depends on the
deformations in (1.17). While in the general case, the domain of deﬁnition of ˜qi(ε, ˜t)
depends on not only the deformations in (1.17) but also on qi(t).

586
14. Lee-Variational Integrator
Remark 1.2. Using the identity
∂L
∂t + d
dt
% ∂L
∂˙qi ˙qi −L
&
= −
% ∂L
∂qi −d
dt
∂L
∂˙qi
&
˙qi,
(1.31)
the Equation (1.22) becomes
δS =
- b
a
% ∂L
∂qi −d
d t
∂L
∂˙qi
&
(φi −ξ ˙qi)d t +
 ∂L
∂˙qi (φi −ξ ˙qi)
! 
b
a + (Lξ)
b
a. (1.32)
According to (1.18), φi = δqi should be regarded as the total variation of qi, δqi =
δV qi + δHqi, since the variation of t also induces the variation of qi, denoted as δHqi,
the horizontal variation of qi. Substituting ξ = δt in (1.18), the horizontal variation of
qi should be δHqi = ξ ˙qi, and consequently φi −ξ ˙qi is interpreted as vertical variation
δV qi, i.e., the variation of qi(t) at the moment t (for e.g., see[CH53]) . Therefore, the ﬁrst
two terms in (1.32) come from vertical variation δV qi and the last term comes from
horizontal variation δt. The horizontal variation of S with respect to the horizontal
variation δHqi = ξ ˙qi gives rise to the identity (1.31).
14.1.3 Discrete Mechanics and Variational Integrators
In this subsection, by calculus of discrete total variations, we will develop a discrete
Lagrangian mechanics, which includes the boundary terms in Lee’s discrete mechan-
ics that give rise to the discrete version of symplectic preserving. The discrete varia-
tion calculus is mainly analog to Lee’s idea that time (discrete) is regarded as a dy-
namical variable, i.e., the time steps are variable[Lee82,Lee87]. The vertical part of this
discrete variation calculus is similar to the one in[KMO99,MV91,Ves88,Ves91a,WM97]. Using
this calculus for discrete total variations we naturally derive the Kane–Marsden–Ortiz
integrators.
We use Q × Q to denote the discrete version of the ﬁrst prolongation for the
extended conﬁguration space Q. A point (t0, q0; t1, q1) ∈Q × Q 1, corresponds to a
tangent vector q1 −q0
t1 −t0 . A discrete Lagrangian is deﬁned to be L : Q × Q →R and
the corresponding action as
S =
N−1

k=0
L(tk, qk, tk+1, qk+1)(tk+1 −tk).
(1.33)
The discrete variational principle in total variation is to extremize S for variations of
both qk and tk with ﬁxed end points (t0, q0) and (tN, qN). This discrete variational
principle determines a discrete ﬂow Φ : Q × Q →Q × Q by
Φ(tk−1, qk−1, tk, qk) = (tk, qk, tk+1, qk+1).
(1.34)
Here (tk+1, qk+1) are calculated from the following discrete Euler–Lagrange equa-
tion, i.e., the variational integrator, and the discrete energy conservation law (for con-
servative L)
1 In this section, q is an abbreviation of (q1, q2, · · · , qn).

14.1 Total Variation in Lagrangian Formalism
587
(tk+1 −tk)D2L(tk, qk, tk+1, qk+1) + (tk −tk−1)D4L(tk−1, qk−1, tk, qk) = 0,
(1.35)
and
(tk+1 −tk)D1L(tk, qk, tk+1, qk+1) + D3L(tk−1, qk−1, tk, qk)(tk −tk−1)
−L(tk, qk, tk+1, qk+1) + L(tk−1, qk−1, tk, qk) = 0,
(1.36)
for all k ∈{1, 2, · · · , N −1}. Here Di denotes the partial derivative of L with respect
to the i-th argument. The Equation (1.35) is the discrete Euler–Lagrange equation.
The Equation (1.36) is the discrete energy conservation law for a conservative L. The
integrator (1.35) – (1.36) is the Kane–Marsden–Ortiz integrator.
Using the discrete ﬂow Φ, the Equations (1.35) and (1.36) become
(tk+1 −tk)D2L ◦Φ + (tk −tk−1)D4L = 0,
(1.37)
((tk+1 −tk)D1L −L) ◦Φ + D3L + L = 0,
(1.38)
respectively. If (tk+1 −tk)D2L and (tk+1 −tk)D1L−L are invertible, the Equations
(1.37) and (1.38) determine the discrete ﬂow Φ under the consistency condition
((tk+1−tk)D1L−L)−1◦(D3L+L) = ((tk+1−tk)D2L)−1◦(tk−tk−1)D4L. (1.39)
Now, we will prove that the discrete ﬂow Φ preserves a discrete version of the
extended Lagrange 2-form ΩL. As in continuous case, we will calculate d S for varia-
tions with variable end points.
d S(t0, q0, · · · , tN, qN) · (δt0, δq0, · · · , δtN, δqN)
=
N−1

k=0
(D2L(tk, qk, tk+1, qk+1)δqk + D4L(tk, qk, tk+1, qk+1)δqk+1)(tk+1 −tk)
+
N−1

k=0
(D1L(tk, qk, tk+1, qk+1)δtk + D3L(tk, qk, tk+1, qk+1)δtk+1)(tk+1 −tk)
+
N−1

k=0
L(tk, qk, tk+1, qk+1)(δtk+1 −δtk)
=
N−1

k=0
D2L(tk, qk, tk+1, qk+1)(tk+1 −tk)δqk
+
N

k=1
D4L(tk−1, qk−1, tk, qk)(tk −tk−1)δqk
+
N−1

k=0
D1L(tk, qk, tk+1, qk+1)(tk+1 −tk)δtk
+
N

k=1
D3L(tk−1, qk−1, tk, qk)(tk −tk−1)δtk

588
14. Lee-Variational Integrator
+
N−1

k=0
L(tk, qk, tk+1, qk+1)(−δtk) +
N

k=1
L(tk−1, qk−1, tk, qk)δtk
=
N−1

k=1
(D2L(tk, qk, tk+1, qk+1)(tk+1 −tk)
+D4L(tk−1, qk−1, tk, qk)(tk −tk−1))δqk
+
N−1

k=1
(D1L(tk, qk, tk+1, qk+1)(tk+1 −tk)
+D3L(tk−1, qk−1, tk, qk)(tk −tk−1))
(1.40)
+L(tk−1, qk−1, tk, qk) −L(tk, qk, tk+1, qk+1))δtk
+D2L(t0, q0, t1, q1)(t1 −t0)δq0 + D4L(tN−1, qN−1, tN, qN)(tN −tN−1)δqN
+(D1L(t0, q0, t1, q1)(t1 −t0) −L(t0, q0, t1, q1))δt0
+(D3L(tN−1, qN−1, tN, qN)(tN −tN−1) + L(tN−1, qN−1, tN, qN))δtN.
We can see that the last four terms in (1.40) come from the boundary variations. Based
on the boundary variations, we can deﬁne two 1-forms on Q × Q
θ−
L (tk, qk, tk+1, qk+1)
= (D1L(tk, qk, tk+1, qk+1)(tk+1 −tk) −L(tk, qk, tk+1, qk+1))dtk
+D2L(tk, qk, tk+1, qk+1)(tk+1 −tk)dqk,
(1.41)
and
θ+
L (tk, qk, tk+1, qk+1)
= (D3L(tk, qk, tk+1, qk+1)(tk+1 −tk) + L(tk, qk, tk+1, qk+1))d tk+1
+D4L(tk, qk, tk+1, qk+1)(tk+1 −tk)d qk+1,
(1.42)
having employed the notations in [MPS98]. We regard the pair (θ−
L , θ+
L ) as the discrete
version of the extended Lagrange 1-form ϑL deﬁned in (1.29).
Now, we parameterize the solutions of the discrete variational principle by the
initial condition (t0, q0, t1, q1) and restrict S to that solution space. Then Equation
(1.40) becomes
dS(t0, q0, · · · , tN, qN) · (δt0, δq0, · · · , δtN, δqN)
= θ−
L (t0, q0, t1, q1) · (δt0, δq0, , δt1, δq1)
+θ+
L (tN−1, qN−1, tN, qN) · (δtN−1, δqN−1, δtN, δqN)
= θ−
L (t0, q0, t1, q1) · (δt0, δq0, δt1, δq1)
+(ΦN−1)∗θ+
L (t0, q0, t1, q1)(δt0, δq0, δt1, δq1).
(1.43)
From (1.43), we obtain
d S = θ−
L + (ΦN−1)∗θ+
L .
(1.44)
The Equation (1.44) holds for arbitrary N > 1. By taking N = 2, we get

14.1 Total Variation in Lagrangian Formalism
589
d S = θ−
L + Φ∗θ+
L .
(1.45)
By exterior differentiation of (1.45), we obtain
Φ∗(d θ+
L ) = −d θ+
L .
(1.46)
From the deﬁnition of θ−
L and θ+
L , we know that
θ−
L + θ+
L = d (L(tk+1 −tk)).
(1.47)
By exterior differentiation of (1.47), we obtain d θ+
L = −d θ−
L . Deﬁne
ΩL ≡d θ+
L = −d θ−
L .
(1.48)
Finally, we have shown that the discrete ﬂow Φ preserves the discrete extended La-
grange 2-form ΩL
Φ∗(ΩL) = ΩL.
(1.49)
Now, the variational integrator (1.35), the discrete energy conservation law (1.36),
and the discrete extended Lagrange 2-form ΩL converge to their continuous counter-
parts as tk+1 →tk, tk−1 →tk.
Consider a conservative Lagrangian L(q, ˙q). For simplicity, we choose the discrete
Lagrangian as
L(tk, qk, tk+1, qk+1) = L
%
qk, qk+1 −qk
tk+1 −tk
&
.
(1.50)
The variational integrator (1.35) becomes
∂L
∂qk (qk, Δt qk) −
1
tk+1 −tk
%
∂L
∂Δt qk (qk, Δtqk) −
∂L
∂Δt qk−1 (qk−1, Δt qk−1)
&
= 0,
(1.51)
where Δtqk = qk+1 −qk
tk+1 −tk , Δtqk−1 = qk −qk−1
tk −tk−1 .
It is easy to see that, as tk+1 →tk, tk−1 →tk, the Equation (1.51) converges to
∂L
∂qk
−d
d t
∂L
∂˙qk
= 0.
(1.52)
The discrete energy conservation law (1.36) becomes
Ek+1 −Ek
tk+1 −tk
= 0,
(1.53)
where
Ek+1 =
∂L
∂Δtqk
Δtqk −L
%
qk, qk+1 −qk
tk+1 −tk
&
,
Ek =
∂L
∂Δtqk−1
Δtqk−1 −L
%
qk−1, qk −qk−1
tk −tk−1
&
.
The Equation (1.53) converges to

590
14. Lee-Variational Integrator
d
d t
% ∂L
∂˙qk
˙qk −L
&
= 0
(1.54)
as tk+1 →tk, tk−1 →tk.
Now, we will consider the discrete extended Lagrange 2-form ΩL deﬁned by
(1.48). By discretization of (1.50), the discrete extended Lagrange 1-form θ+
L deﬁned
in (1.42) becomes
θ+
L =
%
L(qk, Δtqk) −
∂L
∂Δtqk
Δtqk
&
d tk+1 +
∂L
∂Δtqk
d qk+1.
(1.55)
From (1.55), we can deduce that θ+
L converges to the continuous Lagrangian 1-form
ϑL deﬁned by (1.29) as tk+1 →tk, tk−1 →tk. Thus, we obtain
ΩL = dθ+
L −→dϑL = ΩL,
tk+1 →tk,
tk−1 →tk.
(1.56)
In general, the variational integrator (1.35) with ﬁxed time steps does not ex-
actly conserve the discrete energy, and the computed energy will not have secular
variation[GM88,SSC94]. In some cases, such as in discrete mechanics proposed by Lee
in [Lee82,Lee87], the integrator (1.35) is required to conserve the discrete energy (1.36)
by varying the time steps. In other words, the steps can be chosen according to (1.36)
so that the integrator (1.35) conserves the discrete energy (1.36). The resulting inte-
grator also conserves the discrete extended Lagrange 2-form dθ+
L . This fact had not
been discussed in Lee’s discrete mechanics.
Example 1.3. Let us consider an example. For the classical Lagrangian
L(t, q, ˙q) = 1
2 ˙q2 −V (q),
(1.57)
we choose the discrete Lagrangian L(tk, qk, tk+1, qk+1) as
L(tk, qk, tk+1, qk+1) = 1
2
%qk+1 −qk
tk+1 −tk
&2
−V
%qk+1 −qk
2
&
.
(1.58)
The discrete Euler–Lagrange equation (1.35) becomes
%qk+1 −qk
tk+1 −tk
−qk −qk−1
tk −tk−1
&
+ V ′(¯qk)(tk+1 −tk) + V ′(¯qk−1)(tk −tk−1)
2
= 0,
(1.59)
which preserves the Lagrange 2-form
%
1
tk+1 −tk + tk+1 −tk
4
V ′′(¯qk)
&
d qk+1 ∧d qk,
(1.60)
where ¯qk = qk + qk+1
2
, ¯qk−1 = qk−1 + qk
2
.
If we take ﬁxed variables tk+1 −tk = tk −tk−1 = h, then (1.59) becomes
qk+1 −2qk + qk−1
h2
+ V ′(¯qk) + V ′(¯qk−1)
2
= 0,
which preserves the Lagrange 2-form
% 1
h + h
4 V ′′(¯qk)
&
d qk+1 ∧d qk.

14.2 Total Variation in Hamiltonian Formalism
591
14.1.4 Concluding Remarks
We have presented the calculus of total variation problem for discrete mechanics with
variable time steps referring to continuous mechanics in this section. Using the cal-
culus for discrete total variations, we have proved that Lee’s discrete mechanics is
symplectic and derived Kane–Marsden–Ortiz integrators. It is well known that an
energy-preserving variational integrator is a more preferable and natural candidate of
approximations for conservative Euler–Lagrange equation, since the solution of con-
servative Euler–Lagrange equation is not only symplectic but also energy-preserving.
As is mentioned, Kane–Marsden–Ortiz integrators are related closely to the dis-
crete mechanics proposed by Lee[Lee82,Lee87]. In Lee’s discrete mechanics, the differ-
ence equations are the same as Kane–Marsden–Ortiz integrators. However, Lee’s dif-
ference equations are solved as boundary value problems, while Kane–Marsden–Ortiz
integrators are solved as initial value problems.
Finally, it should be mentioned that in very recent works[GLW01a,GLWW01,GW03], two
of the authors (HYG and KW) and their collaborators have presented a difference dis-
crete variational calculus and the discrete version of Euler–Lagrange cohomology for
vertical variation problems in both Lagrangian and Hamiltonian formalism for dis-
crete mechanics and ﬁeld theory. In their approach, the difference operator with ﬁxed
step-length is regarded as an entire geometric object. The advantages of this approach
have already been seen in the last subsection in the course of taking continuous limits
although the difference operator Δt in (1.50) is of variable step-length. This approach
may be generalized to the discrete total variation problems.
14.2 Total Variation in Hamiltonian Formalism
We present a discrete total variation calculus in Hamiltonian formalism in this section.
Using this discrete variation calculus and generating function for ﬂows of Hamiltonian
systems, we derive symplectic-energy integrators of any ﬁnite order for Hamiltonian
systems from a variational perspective. The relationship between the symplectic in-
tegrators derived directly from the Hamiltonian systems and the variationally derived
symplectic-energy integrators is explored.
14.2.1 Variational Principle in Hamiltonian Mechanics
Let us begin by recalling the ordinary variational principle in Hamiltonian formalism.
Suppose Q denotes the conﬁguration space with coordinates qi, and T ∗Q the phase
space with coordinates (qi, pi) (i = 1, 2, · · · , n). Consider a Hamiltonian H : T ∗Q →
R. The corresponding action functional is deﬁned by
S((qi(t), pi(t))) =
- b
a
(pi · qi −H(qi, pi)) d t,
(2.1)
where (qi(t), pi(t)) is a C2 curve in phase space T ∗Q.

592
14. Lee-Variational Integrator
The variational principle in Hamiltonian formalism seeks the curves (qi(t), pi(t))
for which the action functional S is stationary under variations of (qi(t), pi(t)) with
ﬁxed end points. We will ﬁrst deﬁne the variation of (qi(t), pi(t)).
Let
V =
n

i=1
φi(qqq,ppp) ∂
∂qi +
n

i=1
ψi(qqq,ppp) ∂
∂pi ,
(2.2)
be a vector ﬁeld on T ∗Q, here qqq = (q1, · · · , qn),ppp = (p1, · · · , pn). For simplicity, we
will use Einstein convention and omit the summation notation C in the following.
Let us denote the ﬂow of V by F ε : F ε(qqq,ppp) = (˜q˜q˜q, ˜p˜p˜p), which is written in compo-
nents as
˜qi = f i(ε,qqq,ppp),
(2.3)
˜pi = gi(ε,qqq,ppp),
(2.4)
where (qqq,ppp) ∈T ∗Q and
d
d ε

ε=0 f i(ε,qqq,ppp) = φi(qqq,ppp),
d
dε

ε=0 gi(ε,qqq,ppp) = ψi(qqq,ppp).
Let (qi(t), pi(t)) be a curve in T ∗Q. The transformation (2.3) and (2.4) transforms
(qi(t), pi(t)) into a family of curves

˜qi(t), ˜pi(t)

=

f i(ε,qqq(t),ppp(t)), gi(ε,qqq(t),ppp(t))

.
Next, we will deﬁne the variation of

qi(t), pi(t)

:
δ

qi(t), pi(t)

=: d
d ε

ε=0

˜qi(t), ˜pi(t)

=

φi(qqq,ppp), ψi(qqq,ppp)

.
(2.5)
Next, we will calculate the variation of S at

qi(t), pi(t)

as follows:
δS
=
d
d ε

ε=0
S

(˜qi(t), ˜pi(t))

=
d
dε

ε=0
S

(f i(ε,qqq(t),ppp(t)), gi(ε,qqq(t),ppp(t)))

=
d
dε

ε=0
- b
a
%
gi
ε,qqq(t),ppp(t)
 d
d tf i
ε,qqq(t),ppp(t)

−H

f i(ε,qqq(t),ppp(t)), gi(ε,qqq(t),ppp(t))
&
d t
=
- b
a
 %
˙qi −∂H
∂pi
&
ψi +
%
−˙pi −∂H
∂qi
&
φi
!
d t + piφi
b
a.
(2.6)
If φi
qqq(a),ppp(a)

φi
qqq(b),ppp(b)

= 0, the requirement of δS = 0 yields the Hamil-
ton equation for

qi(t), pi(t)

:

14.2 Total Variation in Hamiltonian Formalism
593
˙qi = ∂H
∂pi ,
˙pi = −∂H
∂qi .
(2.7)
If we drop the requirement of φi
qqq(a),ppp(a)

φi
qqq(b),ppp(b)

= 0, we can naturally
obtain the canonical 1-form on T ∗Q from the second term in (2.6): θ = pidqi. Fur-
thermore, restricting

(˜qi(t), ˜pi(t))

to the solution space of (2.7), we can prove that
the solution of (2.7) preserves the canonical 2-form ω = d θL = d pi ∧d qi.
On the other hand, it is not necessary to restrict ((˜qi(t), ˜pi(t)) to the solution space
of (2.7). Introducing the Euler–Lagrange 1-form
E(qi, pi) =

˙qi −∂H
∂pi

d pi +

−˙pi −∂H
∂qi

d qi,
(2.8)
the nilpotency of d leads to
d E(qi, pi) + d
d tω = 0,
(2.9)
namely, the necessary and sufﬁcient condition for symplectic structure preserving is
that the Euler–Lagrange 1-form (2.8) is closed[GLW01a,GLWW01,GLW01b,GW03].
Based on the above-given variational principle in Hamiltonian formalism and
using the ideas of discrete Lagrange mechanics[Ves88,Ves91b,MPS98,WM97], we can de-
velop a natural version of discrete Hamilton mechanics with ﬁxed time steps and
derive symplectic integrators for Hamilton canonical equations from a variational
perspective[GLWW01].
However, the symplectic integrators obtained in this way are not energy-preserving,
in general, because of its ﬁxed time steps[GM88]. An energy-preserving symplectic in-
tegrator is a more preferable and natural candidate of approximations for conservative
Hamilton equations since the solution of conservative Hamilton equations is not only
symplectic but also energy-preserving. To attain this goal, we use variable time steps
and a discrete total variation calculus developed in [Lee82,Lee87,KMO99,CGW03]. The basic
idea is to construct a discrete action functional with variable time steps and then apply
a discrete total variation calculus. In this way, we can derive symplectic integrators
and their associated energy conservation laws. These variationally derived symplectic
integrators are two-step integrators. If we take ﬁxed time steps, the resulting integra-
tors are equivalent to the symplectic integrators derived directly from the Hamiltonian
systems in some special cases.
14.2.2 Total Variation in Hamiltonian Mechanics
In order to discuss total variation in Hamiltonian formalism, we will work with ex-
tended phase space R × T ∗Q with coordinates (t, qi, pi). Here t denotes time. For
details, see [Arn89,GPS02]. By total variation, we refer to variations of both (qi, pi) and t.
Consider a vector ﬁeld on R × T ∗Q,
V = ξ(t,qqq,ppp) ∂
∂t + φi(t,qqq,ppp) ∂
∂qi + ψi(t,qqq,ppp) ∂
∂pi .
(2.10)

594
14. Lee-Variational Integrator
Let F ε be the ﬂow of V . For (t, qi, pi) ∈R×T ∗Q, we have F ε(t, qi, pi) = (˜t, ˜qi, ˜pi):
˜t = h(ε, t,qqq,ppp),
(2.11)
˜qi = f i(ε, t,qqq,ppp),
(2.12)
˜pi = gi(ε, t,qqq,ppp),
(2.13)
where
d
d ε

ε=0h(ε, t,qqq,ppp) = ξ(t,qqq,ppp),
(2.14)
d
d ε

ε=0f i(ε, t,qqq,ppp) = φi(t,qqq,ppp),
(2.15)
d
d ε

ε=0gi(ε, t,qqq,ppp) = ψi(t,qqq,ppp).
(2.16)
The transformation (2.11) – (2.13) transforms a curve (qi(t), pi(t)) into a family of
curves (˜qi(ε, ˜t), ˜pi(ε, ˜t)) determined by
˜t = h

ε, t,qqq(t),ppp(t)

,
(2.17)
˜qi = f i
ε, t,qqq(t),ppp(t)

,
(2.18)
˜pi = gi
ε, t,qqq(t),ppp(t)

.
(2.19)
Suppose we can solve (2.17) for t : t = h−1(ε, ˜t). Then,
˜qi(ε, ˜t) = f i(ε, h−1(ε, ˜t),qqq(h−1(ε, ˜t)),ppp(h−1(ε, ˜t))),
(2.20)
˜qi(ε, ˜t) = f i(ε, h−1(ε, ˜t),qqq(h−1(ε, ˜t)),ppp(h−1(ε, ˜t))).
(2.21)
Before calculating the variation of S directly, we will ﬁrst consider the ﬁrst-order
prolongation of V ,
pr1V = ξ(t,qqq,ppp) ∂
∂t + φi(t,qqq,ppp) ∂
∂qi + ψi(t,qqq,ppp) ∂
∂pi + αi(t,qqq,ppp,·q
·q
·q,·p
·p
·p) ∂
∂˙qi + βi(t,qqq,ppp, ˙q˙q˙q, ˙p˙p˙p) ∂
∂˙pi ,
(2.22)
where pr1V denotes the ﬁrst-order prolongation of V and
αi(t,qqq,ppp, ˙q˙q˙q, ˙p˙p˙p) = Dtφi(t,qqq,ppp) −˙qiDtξφi(t,qqq,ppp),
(2.23)
βi(t,qqq,ppp, ˙q˙q˙q, ˙p˙p˙p) = Dtψi(t,qqq,ppp) −˙piDtξφi(t,qqq,ppp),
(2.24)
where Dt denotes the total derivative. For example,
Dtφi(t,qqq,ppp) = φi
t + φq ˙q˙q˙q + φppp ˙p˙p˙p.
For prolongation of vector ﬁeld and formulae (2.23) and (2.24), refer to[Olv93].
Now, let us calculate the variation of S directly as follows:
δS =
d
d ε

ε=0S

(˜qi(ε, ˜t), ˜pi(ε, ˜t))

=
d
d ε

ε=0
- ˜b
˜a

˜pi(ε, ˜t)
 d
d˜t ˜qi(ε, ˜t) −H

˜qi(ε, ˜t), ˜pi(ε, ˜t)

d ˜t

14.2 Total Variation in Hamiltonian Formalism
595
=
d
d ε

ε=0
- b
a

˜pi(ε, ˜t) d
d ˜t ˜qi(ε, ˜t) −H

(˜qi(ε, ˜t), ˜pi(ε, ˜t)
d ˜t
d t d t
˜t = h

ε, t,qqq(t),ppp(t)

=
- b
a
d
d ε

ε=0

˜pi(ε, ˜t) d
d ˜t ˜qi(ε, ˜t) −H

˜qi(ε, ˜t), ˜pi(ε, ˜t)

d t
+
- b
a

pi(t) ˙qi(t) −H

qi(t), pi(t)

Dtξ d t
(2.25)
=
- b
a
 d
d tH

qi(t), pi(t)

ξ +

−˙pi −∂H
∂qi

φi +

˙qi −∂H
∂pi

ψi
d t
+
@
piφi −H(qi, pi)ξ
Ab
a.
(2.26)
In (2.25), we have used (2.14)and the fact
d
d ε

ε=0
d ˜t
d t = d
d t
d
d ε

ε=0
˜t = Dt ξ.
In (2.26), we have used the prolongation formula (2.23).
If ξ

a,qqq(a),ppp(a)

= ξ

b,qqq(b),ppp(b)

= 0 and φi
a,qqq(a),ppp(a)

= φi
b,qqq(b),ppp(b)

= 0, the requirement of δS = 0 yields the Hamilton canonical equation
˙qi = ∂H
∂pi ,
˙pi = −∂H
∂qi
(2.27)
from the variation φi, ψi and the energy conservation law
d
d tH(qi, pi) = 0
(2.28)
from the variation ξ. Since
d
d tH(qi, pi) = ∂H
∂qi · qi + ∂H
∂pi · pi,
we can very well see that the energy conservation law (2.28) is a natural consequence
of the Hamilton canonical Equation (2.27).
If we drop the requirement
ξ

a,qqq(a),ppp(a)

= ξ

b,qqq(b),ppp(b)

= 0,
φi
a,qqq(a),ppp(a)

= φi
b,qqq(b),ppp(b)

= 0,
we can deﬁne the extended canonical 1-form on R × T ∗Q from the second term in
(2.26)
θ = pi d qi −H(qi, pi)d t.
(2.29)
Furthermore, restricting

˜qi(t), ˜pi(t)

to the solution space of (2.27), we can prove
that the solution of (2.27) preserves the extended canonical 2-form
ω = d θ = d pi ∧d qi −d H(qi, pi) ∧d t
(2.30)
by using the same method in[MPS98].

596
14. Lee-Variational Integrator
14.2.3 Symplectic-Energy Integrators
In this section, we will develop a discrete version of total variation in Hamiltonian for-
malism. Using this discrete total variation calculus, we will derive symplectic-energy
integrators.
Let
L(qi, pi, ˙qi, ˙pi) = pi ˙qi −H(qi, pi)
be a function from R × T(T ∗Q) to R. Here L does not depend on t explicitly.
We use P ×P for the discrete version R×T(T ∗Q). Here P is the discrete version
of R × T ∗Q. A point (t0,qqq0,ppp0; t1,qqq1,ppp1) ∈P × P corresponds to a tangent vector
q1 −q0
t1 −t0
, p1 −p0
t0 −t0

.
For simplicity, the vector symbols qqq = (q1, · · · , qn) and ppp = (p1, · · · , pn) are
used throughout this section. A discrete L is deﬁned to be L : P × P →R and the
corresponding discrete action as
S =
N−1

k=0
L(tk,qqqk,pppk, tk+1,qqqk+1,pppk+1)(tk+1 −tk),
(2.31)
where t0 = a, tN = b. The discrete variational principle in total variation is to
extremize S for variations of both qqqk,pppk and tk holding the end points (t0,qqq0,ppp0)
and (tN,qqqN,pppN) ﬁxed. This discrete variational principle determines a discrete ﬂow
Φ : P × P →P × P by
Φ(tk−1,qqqk−1,pppk−1, tk,qqqk,pppk) = (tk,qqqk,pppk, tk+1,qqqk+1,pppk+1).
(2.32)
Here, (tk+1,qqqk+1,pppk+1) for all k ∈(1, 2, · · · , N −1) are found from the following
discrete Hamilton canonical equation
(tk+1 −tk)D2L(tk,qqqk,pppk, tk+1,qqqk+1,pppk+1) + (tk −tk−1)D5L(tk−1,qqqk−1,pppk−1, tk,qqqk,pppk) = 0,
(2.33)
(tk+1 −tk)D3L(tk,qqqk,pppk, tk+1,qqqk+1,pppk+1) + (tk −tk−1)D6L(tk−1,qqqk−1,pppk−1, tk,qqqk,pppk) = 0
and the discrete energy conservation law
(tk+1−tk)D1L(tk,qqqk,pppk, tk+1,qqqk+1,pppk+1)+(tk−tk−1)D4L(tk−1,qqqk−1,pppk−1, tk,qqqk,pppk)
(2.34)
−L(tk,qqqk,pppk, tk+1,qqqk+1,pppk+1) + L(tk−1,qqqk−1,pppk−1, tk,qqqk,pppk) = 0.
Di denotes the partial derivative of L with respect to the ith argument. Equation (2.33)
is the discrete Hamilton canonical equation (variational integrator). Equation (2.34)
is the discrete energy conservation law associated with (2.33). Unlike the continu-
ous case, the variational integrator (2.33) does not satisfy (2.34) for arbitrarily given
tk+1 in general. Therefore, we need to solve (2.33) and (2.34) simultaneously with
qk+1, pk+1 and tk+1 taken as unknowns.
Now, we will prove that the discrete ﬂow determined by (2.33) and (2.34) pre-
serves a discrete version of the extended Lagrange 2-form ω deﬁned in (2.30) so that

14.2 Total Variation in Hamiltonian Formalism
597
we call (2.33) and (2.34) a symplectic-energy integrator. We will do this directly from
the variational point of view, consistent with the continuous case[MPS98].
As in the continuous case, we will calculate dS for variations with varied end
points.
dS(t0,qqq0,ppp0, · · · , tN,qqqN,pppN) · (δt0, δqqq0, δppp0, · · · , δtN, δqqqN, δpppN)
=
N−1

k=0
%
D2L(vvvk)δqqqk + D5L(vvvk)δqqqk+1 + D3L(vvvk)δpppk + D6L(vvvk)δpppk+1
&
(tk+1 −tk)
+
N−1

k=0

D1L(vvvk)δtk + D4L(vvvk)δtk+1

(tk+1 −tk) +
N−1

k=0
L(vvvk)(δtk+1 −δtk)
=
N−1

k=1
%
D2L(vvvk)(tk+1 −tk) + D5L(vvvk−1)(tk −tk−1
&
δqqqk
+
N−1

k=1
%
D3L(vvvk)(tk+1 −tk) + D6L(vvvk−1)(tk −tk−1
&
δpppk
+
N−1

k=1

D1L(vvvk)(tk+1 −tk) + D4L(vvvk−1)(tk −tk−1) + L(vvvk−1) −L(vvvk)

δtk
+D2L(vvv0)(t1 −t0)δqqq0 + D3L(vvv0)(t1 −t0)δp0 +

D1Lvvv0)(t1 −to) −L(vvv0)

δt0
+D5L(vvvN−1)(tN −tN−1)δqqqN + D6L(vvvN−1)(tN −tN−1)δpppN
+

D4L(vvvN−1)(tN −tN−1) −L(vvvN−1)

δtN,
(2.35)
where vvvk = (tk,qqqk,pppk, tk+1,qqqk+1,pppk+1) (k = 0, 1, · · · , N −1). We can see that the
last six terms in (2.35) come from the boundary variations. Based on the boundary
variations, we can deﬁne two 1-forms on P × P,
θ−
L (vvvk) = D2L(vvvk)(tk+1 −tk)dqqqk + D3L(vvvk)(tk+1 −tk)dpppk
+D1L(vvvk)(tk+1 −tk) −L(vvvk)dtk
(2.36)
and
θ+
L (vvvk) = D5L(vvvk)(tk+1 −tk)dqqqk+1 + D6L(vvvk)(tk+1 −tk)dpppk+1
+D4L(vvvk)(tk+1 −tk) −L(vvvk)dtk+1.
(2.37)
Here, we have used the notation in [MPS98]. We regard the pair (θ−
L , θ+
L ) as being the
discrete version of the extended canonical 1-form θ deﬁned in (2.29).
Now, we will parametrize the solutions of the discrete variational principle by
(t0, q0, t1, q1), and restrict S to that solution space. Then, Equation (2.35) becomes
d S(t0,qqq0,ppp0, · · · , tN,qqqN,pppN) · (δt0, δqqq0, δppp0, · · · , δtN, δqqqN, δpppN)
= θ−
L (t0,qqq0,ppp0, t1,qqq1,ppp1) · (δt0, δqqq0, δppp0, δt1, δqqq1, δppp1)
+θ+
L (tN−1,qqqN−1,pppN−1, tN,qqqN,pppN) · (δtN−1, δqqqN−1, δpppN−1, δtN, δqqqN, δpppN)
= θ−
L (t0,qqq0,ppp0, t1,qqq1,ppp1) · (δt0, δqqq0, δppp0, δt1, δqqq1, δppp1)
+(ΦN−1)∗θ+
L (t0,qqq0,ppp0, t1,qqq1,ppp1) · (δt0, δqqq0, δppp0, δt1, δqqq1, δppp1).
(2.38)

598
14. Lee-Variational Integrator
From (2.38), we can obtain
d S = θ−
L + (ΦN−1)∗θ+
L .
(2.39)
The Equation (2.39) holds for arbitrary N > 1. Taking N = 2, we obtain
d S = θ−
L + Φ∗θ+
L .
(2.40)
By exterior differentiation of (2.40), we obtain
Φ∗(d θ+
L ) = −d θ−
L .
(2.41)
From the deﬁnition of θ−
L and θ+
L , we know that
θ−
L + θ+
L = d L.
(2.42)
By exterior differentiation of (2.42), we obtain dθ+
L = −d θ−
L . Deﬁne
ωL ≡d θ+
L = −d θ−
L .
(2.43)
Finally, we have shown that the discrete ﬂow Φ preserves the discrete extended canon-
ical 2-form ωL:
Φ∗(ωL) = ωL.
(2.44)
We can now call the coupled difference system (2.33) and (2.34) a symplectic-
energy integrator in the sense that it satisﬁes the discrete energy conservation law
(2.34) and preserves the discrete extended canonical 2-form ωL.
To illustrate the above-mentioned discrete total variation calculus, we present an
example. We choose L in (2.31) as
L(tk,qqqk,pppk, tk+1,qqqk+1,pppk+1) = pppk+1/2
qqqk+1 −qqqk
tk+1 −tk −H(qqqk+1/2,pppk+1/2),
(2.45)
where
pppk+1/2 = pppk + pppk+1
2
,
qqqk+1/2 = qqqk + qqqk+1
2
.
Using (2.33), we can obtain the corresponding discrete Hamilton equation
qqqk+1 −qqqk−1
2
−1
2
*
(tk+1 −tk)∂H
∂ppp
(qqqk+1/2,pppk+1/2) + (tk −tk−1)∂H
∂ppp
(qqqk+1/2,pppk+1/2
+
= 0,
pppk+1 −pppk−1
2
+ 1
2
*
(tk+1 −tk)∂H
∂qqq
(qqqk+1/2,pppk+1/2) + (tk −tk−1)∂H
∂qqq
(qqqk+1/2,pppk+1/2)
+
= 0,
(2.46)
where
pppk−1/2 =
pppk+pppk−1
2
,
qqqk−1/2 =
qqqk+qqqk−1
2
.
Using (2.34), we can obtain the corresponding discrete energy conservation law
H

qqqk+1/2,pppk+1/2

= H

qqqk+1/2,pppk+1/2

.
(2.47)
The symplectic-energy integrator (2.46) and (2.47) preserves the discrete 2-form:

14.2 Total Variation in Hamiltonian Formalism
599
1
2

dpppk ∧dqqqk+1 + dpppk+1 ∧dqqqk

−H

qqqk+1/2,pppk+1/2

∧
d tk + dtk+1
2

. (2.48)
If we take ﬁxed time steps tk+1 −tk = h (h is a constant), then (2.46) becomes
qqqk+1 −qqqk−1
2h
= 1
2
∂H
∂ppp

qqqk+1/2,pppk+1/2

+ ∂H
∂ppp

qqqk−1/2,pppk−1/2

,
pppk+1 −pppk−1
2h
= −1
2
∂H
∂qqq

qqqk+1/2,pppk+1/2) + ∂H
∂qqq (qqqk−1/2,pppk−1/2

.
(2.49)
Now, we will explore the relationship between (2.49) and the midpoint integrator for
the Hamiltonian system
˙qqq =
∂H
∂ppp ,
˙ppp = −∂H
∂qqq .
(2.50)
The midpoint symplectic integrator for (2.50) is
qqqk+1 −qqqk
h
=
∂H
∂ppp

qqqk+1/2,pppk+1/2

,
pppk+1 −pppk
h
= −∂H
∂qqq

qqqk+1/2,pppk+1/2

.
(2.51)
Replacing k by k −1 in (2.51), we obtain
qqqk −qqqk−1
h
=
∂H
∂ppp

qqqk−1/2,pppk−1/2

,
pppk −pppk−1
h
= −∂H
∂qqq

qqqk−1/2,pppk−1/2

.
(2.52)
Adding (2.52) to (2.51) results in (2.49). Therefore, if we use (2.51) to obtain pppk,qqqk,
the two-step integrator (2.49) is equivalent to the midpoint integrator (2.51). However,
the equivalence does not hold in general. For example, choose L in (2.31) as
L

tk,qqqk,pppk, tk+1,qqqk+1,pppk+1

= pppk
qqqk+1 −qqqk
tk+1 −tk
−H

qqqk+1/2,pppk+1/2

,
(2.53)
and take ﬁxed time steps tk+1 −tk = h. Then (2.33) becomes
qqqk+1 −qqqk
h
=
1
2
∂H
∂ppp

qqqk+1/2,pppk+1/2

+ ∂H
∂ppp

qqqk−1/2,pppk−1/2

,
pppk −pppk−1
h
= −1
2
∂H
∂qqq

qqqk+1/2,pppk+1/2

+ ∂H
∂qqq

qqqk−1/2,pppk−1/2

.
(2.54)
The integrator (2.54) is a two-step integrator which preserves dpk∧dqk+1. In this case,
we cannot ﬁnd an one-step integrator which is equivalent to (2.54). In conclusion,
using discrete total variation calculus, we have derived two-step symplectic-energy
integrators. When taking ﬁxed time steps, some of them are equivalent to one-step
integrators derived directly from the Hamiltonian system while the others do not have
this equivalence.

600
14. Lee-Variational Integrator
14.2.4 High Order Symplectic-Energy Integrator
In this subsection, we will develop high order symplectic-energy integrators by using
the generating function of the ﬂow of the Hamiltonian system
˙zzz = J∇H(zzz),
(2.55)
where
zzz = (ppp,qqq)T,
J =
 O
−I
I
O

.
Let us ﬁrst recall the generating function with normal Darboux matrix of a symplectic
transformation. For details, see Chapters 5 and 6, or [Fen86,FWQW89].
Suppose α is a 4n × 4n nonsingular matrix with the form
α =
*
A
B
C
D
+
,
where A, B, C and D are both 2n × 2n matrices.
We denote the inverse of α by
α−1 =
*
A1
B1
C1
D1
+
,
where A1, B1, C1 and D1 are both 2n × 2n matrices. We know that a 4n × 4n matrix
α is a Darboux matrix if
αTJ4nα = "J4n,
(2.56)
where
J4n =
*
O
−I2n
I2n
O
+
,
˜J4n =
*
J2n
O
O
−J2n
+
,
J2n =
*
O
−In
In
O
+
,
where In is an n × n identity matrix and I2n is a 2n × 2n identity matrix.
Every Darboux matrix induces a fractional transform between symplectic and
symmetric matrices
σα : Sp(2n) −→Sm(2n),
σα = (AS + B)(CS + D)−1 = M,
for
S ∈Sp(2n), det (CS + D) ̸= 0
with the inverse transform σ−1
α
= σα−1
σ−1
α
: Sm(2n) −→Sp(2n),
σα = (A1M + B1)(C1M + D1)−1 = S,
where Sp(2n) is the group of symplectic matrices and Sm(2n) the set of symmetric
matrices.

14.2 Total Variation in Hamiltonian Formalism
601
We can generalize the above discussions to nonlinear transformations on R2n.
Let us denote the set of symplectic transformations on R2n by SpD2n and the set of
symmetric transformations (i.e., transformations with symmetric Jacobian) on R2n by
Symm(2n). Every f ∈Symm(2n) corresponds, at least locally, to a real function φ
(unique to a constant) such that f is the gradient of φ,
f(www) = ∇φ(www),
(2.57)
where ∇φ(www) =

φw1(www), · · · , φw2n(www)

and www = (w1, w2, · · · , w2n).
Then, we have
σα : SpD2n −→Symm(2n),
σα = (A ◦g + B) ◦(C ◦g + D)−1 = ∇φ, for g ∈SpD2n, det(Cgz + D) ̸= 0
or alternatively
Ag(zzz) + Bzzz = (∇φ)(Cg(zzz) + Dzzz),
where ◦denotes the composition of transformation and the 2n × 2n constant matrices
A, B, C and D are regarded as linear transformations. gzzz denotes the Jacobian of
symplectic transformation g.
Let φ be the generating function of Darboux type α for symplectic transformation
g.
Conversely, we have
σ−1
α
: Symm (2n) −→SpD2n,
σ−1
α (∇φ) = (A1 ◦∇φ + B1) ◦(C1 ◦∇φ + D1)−1 = g, for det(C1φw
w
www
w + D1) ̸= 0,
or alternatively
A1∇φ(www) + B1www = g(C1∇φ(www) + D1www),
where g is called the symplectic transformation of Darboux type α for the generating
function φ.
For the study of integrators, we will restrict ourselves to normal Darboux matrices,
i.e., those satisfying A + B = 0, C + D = I2n. The normal Darboux matrices can be
characterized as
α =
*
J2n
−J2n
E
I2n −E
+
,
E = 1
2(I2n + J2nF),
F T = F,
(2.58)
and
α−1 =
*
(E −I2n)J2n
I2n
EJ2n
I2n
+
.
(2.59)
The fractional transform induced by a normal Darboux matrix establishes a one-
one correspondence between symplectic transformations near identity and symmetric
transformations near nullity.
For simplicity, we will take F = 0, then E = 1
2I2n and

602
14. Lee-Variational Integrator
α =
* J2n
−J2n
1
2I2n
1
2I2n
+
.
(2.60)
Now, we will consider the generating function of the ﬂow of (2.55) and denote it by
et
H. The generating function φ(www, t) for the ﬂow et
H of Darboux type (2.60) is given
by
∇φ = (J2n ◦et
H −J2n) ◦
1
2et
H + 1
2I2n
−1
,
for small
|t|,
(2.61)
where φ(www, t) satisﬁes the Hamilton–Jacobi equation
∂
∂tφ(www, t) = −H

www + 1
2J2n∇φ(www, t)

(2.62)
and can be expressed by Taylor series in t,
φ(www, t) =
∞

k=1
φk(w)tk,
for small
|t|.
(2.63)
The coefﬁcients φk(w) can be determined recursively as
φ1(www)
= −H(w),
φk+1(www) =
−1
k + 1
k

m=1
1
m !

j1 + · · · + jm = k
jl ≥1
DmH
% 1
2J2n∇φj1, · · · , 1
2J2n∇φjm
&
, (2.64)
where k ≥1, and we use the notation of the m-linear form
DmH
1
2J2n∇φj1, · · · , 1
2J2n∇φjm

:=
2n

i1,···,im=1
Hzzzi1···zzzim(zzz)
1
2J2n∇φj1(www)

i1 · · ·
1
2J2n∇φjm(www)

im.
From (2.61), we can see that the phase ﬂow zzz := et
Hzzz satisﬁes
J2n(zzz −zzz) = ∇φ
zzz −zzz
2

=
∞

j=1
tj∇φjzzz + zzz
2

.
(2.65)
Now, we will choose L in (2.31) as
L(tk,qqqk,pppk, tk+1,qqqk+1,pppk+1) = pppk+1/2
qqqk+1 −qqqk
tk+1 −tk
−ψm(qqqk+1/2,pppk+1/2), (2.66)
where
ψm(qqqk+1/2,pppk+1/2) =
m

j=1
tjφj(qqqk+1/2,pppk+1/2).
(2.67)

14.2 Total Variation in Hamiltonian Formalism
603
The corresponding symplectic-energy integrator (2.33) and (2.34) is
qqqk+1 −qqqk−1
2
−1
2
*
(tk+1 −tk)∂ψm
∂ppp
(qqqk+1/2,pppk+1/2) + (tk −tk−1)∂ψm
∂ppp
(qqqk−1/2,pppk−1/2)
+
= 0,
(2.68)
pppk+1 −pppk−1
2
+ 1
2
*
(tk+1 −tk)∂ψm
∂qqq
(qqqk+1/2,pppk+1/2) + (tk −tk−1)∂ψm
∂qqq
(qqqk−1/2,pppk−1/2)
+
= 0,
ψm(qqqk+1/2,pppk+1/2) = ψm(qqqk−1/2,pppk−1/2),
which satisﬁes the discrete extended canonical 2-form
1
2(dpppk ∧dqqqk+1 + dpppk+1 ∧dqqqk) −ψm(qqqk+1/2,pppk+1/2) ∧
dtk + dtk+1
2

. (2.69)
The integrator (2.68) is a two-step symplectic-energy integrator with 2m-th order
of accuracy.
14.2.5 An Example and an Optimization Method
In this subsection, we will see an example. We will take the Hamiltonian as
H(q, p) = 1
2p2 + 1
2(q4 −q2),
(2.70)
where q and p are scalars.
Corresponding to (2.70) the discrete Lagrangian (2.31) is chosen as
L(tk, qk, pk, tk+1, qk+1, pk+1) = pk+1/2
qk+1 −qk
tk+1 −tk
−1
2(q4
k+1/2 −q2
k+1/2). (2.71)
The corresponding symplectic-energy integrator (2.33) and (2.34) become
qk+1 −qk−1
2
−1
2 ((tk+1 −tk)pk+1/2 + (tk −tk−1)pk−1/2) = 0,
(2.72)
pk+1 −pk−1
2
+ 1
2 ((tk+1 −tk)(2q3
k+1/2 −qk+1/2) + (tk −tk−1)(2q3
k−1/2 −qk−1/2)) = 0,
1
2
p2
k+1/2 + 1
2 (q4
k+1/2 −q2
k+1/2) = 1
2 p2
k−1/2 + 1
2 (q4
k−1/2 −q2
k−1/2),
where tk−1, qk−1, pk−1 and tk, qk, pk are given and tk+1, qk+1, pk+1 are unknowns.
In the following numerical experiment, we will use a robust optimization method
suggested in [KMO99] to solve (2.72). Concretely, let
A =
qk+1−qk−1
2
−1
2

(tk+1 −tk)pk+1/2 + (tk −tk−1)pk−1/2

,
B =
pk+1−pk−1
2
+ 1
2

(tk+1 −tk)(2q3
k+1/2 −qk+1/2)+(tk −tk−1)(2q3
k−1/2 −qk−1/2)

,
C = 1
2p2
k+1/2 + 1
2(q4
k+1/2 −q2
k+1/2) −1
2p2
k−1/2 −1
2(q4
k−1/2 −q2
k−1/2).
Then, we will minimize the quantity
F = A2 + B2 + C2
(2.73)

604
14. Lee-Variational Integrator
Fig. 2.1.
The orbits calculated by (2.72), (2.74) left plot q0 = 0.77, p0 = 0 and right plot q0 = 0.99, p0 = 0
Fig. 2.2.
The energy evaluation by (2.72), (2.74) left plot q0 = 0.77, p0 = 0 and right plot q0 = 0.99, p0 = 0
over qk+1, pk+1 and tk+1 under the constraint tk+1 > tk. This constraint guarantees
that no singularities occur in choosing time steps.
We will compare (2.72) with the following integrator with ﬁxed time steps:
qk+1 −qk−1
2h
−1
2(pk+1/2 + pk−1/2) = 0,
pk+1 −pk−1
2h
+ 1
2

(2q3
k+1/2 −qk+1/2) + (2q3
k−1/2 −qk−1/2)

= 0.
(2.74)
In our numerical experiment, we use two initial conditions q0 = 0.77, p0 = 0, t =
0 and q0 = 0.99, p0 = 0, t = 0. To obtain q1 and p1, we apply the midpoint integrator
with t1 = 0.1. In Fig. 2.1, the orbits calculated by (2.72) and (2.74) are shown for
the two initial conditions. The two orbits in each initial condition are almost indis-
tinguishable. In Fig.2.2, we plot the evolution of the energy H(qk+1/2, pk+1/2) for
both (2.72) and (2.74). The oscillating curve is for (2.74) and the lower line for (2.72).
For more numerical examples, see [KMO99] in the Lagrangian setting. In principle, the
results in[KMO99] apply to the Hamiltonian setting in the present method as well taking
qk+1 −qk
h
= pk+1/2. The purpose is to develop a discrete total variation calculus in

14.2 Total Variation in Hamiltonian Formalism
605
the Hamiltonian setting and obtain the symplectic-energy integrators. The comprehen-
sive implementation of the obtained integrators is not the subject of present and will
be a topic for future research.
14.2.6 Concluding Remarks
We will develop a discrete total variation calculus in Hamiltonian formalism in this
subsection. This calculus provides a new method for constructing structure-preserving
integrators for Hamiltonian system from a variational point of view. Using this calcu-
lus, we will derive the energy conservation laws associated with integrators. The cou-
pled integrators are two-step integrators and preserve a discrete version of the extended
canonical 2-form. If we take ﬁxed time steps, the resulting integrators are equivalent
to the symplectic integrators derived directly from the Hamiltonian systems only in
special cases. Thus, new two-step symplectic integrators are variationally obtained.
Using generating function method, we will also obtain higher order symplectic-energy
integrators.
In principle, our discussions can be generalized to multisymplectic Hamiltonian
system
Mzzzt + Kzzzx = ∇xH(zzz),
zzz ∈Rn,
(2.75)
where M and K are skew-symmetric matrices on Rn(n ≥3) and S : RRRn →RRR is
a smooth function [Bri97,BD01]. We call the above-mentioned system a multisymplectic
Hamiltonian system, since it possesses a multisymplectic conservation law
∂
∂tω + ∂
∂xκ = 0,
(2.76)
where ω and κ are the presymplectic forms
ω = 1
2dzzz ∧Mdzzz,
κ = 1
2dzzz ∧Kdzzz.
The constructed action functional is
S =
- 1
2zzzT(Mzzzt + Kzzzx) −H(zzz)

d x ∧d t.
(2.77)
Performing total variation on (2.77), we can obtain the multisymplectic Hamiltonian
system (2.75), the corresponding local energy conservation law
∂
∂t

S(z) −1
2zTKzx

+ ∂
∂x
1
2zTKzt

= 0,
(2.78)
and the local momentum conservation law
∂
∂t
1
2zTMzx

+ ∂
∂x

S(z) −1
2zTMzt

= 0.
(2.79)
In the same way, we can develop a discrete total variation in the multisymplectic form
and obtain multisymplectic-energy-momentum integrators. This will be discussed in
detail in Chapter 16.

606
14. Lee-Variational Integrator
14.3 Discrete Mechanics Based on Finite Element
Methods
Now, we will consider mechanics based on ﬁnite element methods. Let us go back
to the variation problem of the action factional (1.1). The ﬁnite element method is an
approximate method for solving the variation problem. Instead of solving the vari-
ation problem in the space C2([a, b]), the ﬁnite element method solves the problem
in a subspace Vhm([a, b]) of C2([a, b]). Vhm([a, b]) consists of piecewise m-degree
polynomials interpolating the curves q(t) ∈C2([a, b]).
14.3.1 Discrete Mechanics Based on Linear Finite Element
First, let us consider the piecewise linear interpolation. Given a partition of [a, b]
a = t0 < t1 < · · · < tk < · · · < tN−1 < tn = b,
the intervals Ik = [tk, tk+1] are called elements. hk = tk+1 −tk.Vh([a, b]) consists
of piecewise linear function interpolating q(t) at (tk, qk)(k = 0, 1, · · · , N). Now, we
will derive the expressions of qh(t) ∈Vh([a, b]). First, we will construct the basis
functions ϕk(t), which are piecewise linear functions on [a, b] satisfying ϕk(ti) =
δi
k (i, k = 0, 1, · · · , N).
ϕ0(t) =

1 −t −t0
h0
,
t0 ≤t ≤t1;
0,
otherwise;
ϕN(t) =

1 + t −tN
hN−1 ,
tN−1 ≤t ≤tN;
0,
otherwise;
(3.1)
and for k = 1, 2, · · · , N −1,
ϕk(t) =
⎧
⎪
⎪
⎨
⎪
⎪
⎩
1 + t −tk
hk−1 ,
tk−1 ≤t ≤tk;
1 −t −tk
hk
,
tk ≤t ≤tk+1;
0,
otherwise.
(3.2)
Using these basis functions, we obtain the expression qh ∈Vh([a, b]):
qh(t) =
N

k=0
qkϕk(t).
(3.3)
In the space Vh([a, b]), the action functional (1.1) becomes
S

(t, qh(t))

=
- b
a
L(t, qh(t), ˙qh(t))dt

14.3 Discrete Mechanics Based on Finite Element Methods
607
=
N−1

k=0
- tk+1
tk
L
*
t,
N

i=0
(qiϕi(t), d
d t
N

i=0
(qiϕi(t))
+
d t
=
N−1

k=0
L(tk, qk, tk+1, qk+1)(tk+1 −tk),
(3.4)
where
L(tk, qk, tk+1, qk+1) =
1
tk+1 −tk
- tk+1
tk
L
*
t,
N

i=0
(qiϕi(t), d
d t
N

i=0
(qiϕi(t))
+
d t
=
1
tk+1 −tk
- tk+1
tk
L
*
t,
k+1

i=k
(qiϕi(t), d
d t
k+1

i=k
(qiϕi(t))
+
d t.
(3.5)
Therefore, restricting to the subspace Vh([a, b]) of C2([a, b]), the original varia-
tional problem reduces to the extremum problem of the function (3.4) in qk (k =
0, 1, · · · , N). Note that (3.4) is one of the discrete actions (1.33). Thus, what remains
to be done is just to perform the same calculation on (3.4) as on (1.33). We can then
obtain the discrete Euler–Lagrange equation (1.35) which preserves the discrete La-
grange 2-form (1.48). Therefore, discrete mechanics based on ﬁnite element methods
consists of two steps: ﬁrst, use ﬁnite element methods to obtain a kind of discrete
Lagrangian, second, use the method of Veselov mechanics to obtain the variational
integrators.
Let us consider the previous example again. For the classical Lagrangian (1.57),
we choose the discrete Lagrangian L(tk, qk, tk+1, qk+1) as
L(tk, qk, tk+1, qk+1)
=
1
tk+1 −tk
- tk+1
tk
⎛
⎝1
2
*
d
dt
N

i=0
(qiϕi(t))
+2
−V
* N

i=0
(qiϕi(t))
+⎞
⎠d t
=
1
tk+1 −tk
- tk+1
tk
*
1
2
% qk+1 −qk
tk+1 −tk
&2
−V
% tk+1 −t
tk+1 −tk qk +
t −tk
tk+1 −tk qk+1
&+
d t
= 1
2
% qk+1 −qk
tk+1 −tk
&2
−F(qk, qk+1),
(3.6)
where
F(qk, qk+1) =
1
tk+1 −tk
- tk+1
tk
V
% tk+1 −t
tk+1 −tk
qk +
t −tk
tk+1 −tk
qk+1
&
d t.
(3.7)
The discrete Euler–Lagrange equation (1.35) becomes
%qk+1 −qk
tk+1 −tk
−qk −qk−1
tk −tk−1
&
+ ∂F(qk, qk+1)
∂qk
(tk+1 −tk)
+∂F(qk−1, qk)
∂qk
(tk −tk−1) = 0,
(3.8)

608
14. Lee-Variational Integrator
which preserves the Lagrange 2-form
%
1
tk+1 −tk
+ (tk+1 −tk)∂2F(qk, qk+1)
∂qk∂qk+1
&
d qk+1 ∧d qk.
(3.9)
Again, if we take ﬁxed time steps tk+1 −tk = tk −tk−1 = h, (3.8) becomes
qk+1 −2qk + qk−1
h2
+ ∂F(qk, qk+1)
∂qk
+ ∂F(qk−1, qk)
∂qk
= 0,
which preserves the Lagrange 2-form
% 1
h + h∂2F(qk, qk+1)
∂qk∂qk+1
&
d qk+1 ∧d qk.
Suppose qk is the solution of (3.8) and q(t) is the solution of
d2 q
d t2 + ∂V (q)
∂q
= 0,
(3.10)
then from the convergence theory of ﬁnite element methods[Cia78,Fen65], we have
∥q(t) −qh(t)∥≤Ch2,
(3.11)
where ∥· ∥is the L2 norm. qh(t) =
N

k=0
qk, h = max
k {hk} and C is a constant
independent of h.
If we use midpoint numerical integration formula in (3.7), we obtain
F(qk, qk+1)
=
1
tk+1 −tk
 tk+1
tk
V
%
tk+1 −t
tk+1 −tk qk +
t −tk
tk+1 −tk qk+1
&
d t
≈v
qk + qk+1
2

.
In this case, (3.8) is the same as (1.59). We can also use trapezoid formula or Simpson
formula and so on to integrate (3.7) numerically and obtain another kind of discrete
Lagrangian.
14.3.2 Discrete Mechanics with Lagrangian of High Order
Now, we will consider piecewise quadratic polynomial interpolation, which will result
in a kind of discrete Lagrangian of high order. To this aim, we add an auxiliary node
tk+ 1
2 to each element Ik = [tk, tk+1]. There are two kinds of quadratic basis functions:
φk(t) for nodes tk and φk+ 1
2 (t) for tk+ 1
2 that satisfy
φk(ti) = δk
i ,
φk

ti+ 1
2

= 0,
φk+ 1
2

ti+ 1
2

= δk
i ,
φk+ 1
2 (ti) = 0,
i, k = 0, 1, · · · , N.

14.3 Discrete Mechanics Based on Finite Element Methods
609
We have the basis functions as follows:
φ0(t) =
⎧
⎨
⎩
2(t −t0)
h0
−1
t −t0
h0
−1

,
t0 ≤t ≤t1;
0,
otherwise;
(3.12)
φN(t) =
⎧
⎨
⎩
2(tN −t)
hN−1
−1
tN −t
hN−1 −1

,
tN−1 ≤t ≤tN;
0,
otherwise;
(3.13)
and for k = 1, 2, · · · , N −1,
φk(t) =
⎧
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎩
%
2(tk −t)
hk−1
−1
& %
tk −t
hk−1 −1
&
,
tk−1 ≤t ≤tk;
%
2(t −tk)
hk
−1
& t −tk
hk
−1

,
tk ≤t ≤tk+1;
0,
otherwise;
(3.14)
and for k = 0, 1, · · · , N −1,
φk+ 1
2 (t) =

4t −tk
hk

1 −t −tk
hk

,
tk ≤t ≤tk+1;
0,
otherwise.
(3.15)
Using these basis functions, we will construct subspace Vh2([a, b]) of C2([a, b]):
qh2(t) =
N

k=0
qkφk(t) +
N−1

k=0
qk+ 1
2 φk+ 1
2 (t),
qh2(t) ∈Vh2([a, b]).
(3.16)
In the space Vh2([a, b]), the action functional (1.1) becomes
S

(t, qh2(t))

=
- b
a
L

t, qh2(t), ˙qh2(t)

d t
=
N−1

k=0
- tk+1
tk
L

t, qh2(t), ˙qh2(t)

d t
=
N−1

k=0
L(tk, qk, qk+ 1
2 , tk+1, qk+1)(tk+1 −tk),
(3.17)
where
L(tk, qk, qk+ 1
2 , tk+1, qk+1) =
1
tk+1 −tk
- tk+1
tk
L

t, qh2(t), ˙qh2(t)

d t.
(3.18)
For the discrete action (3.17), we have

610
14. Lee-Variational Integrator
d S(q0, q 1
2 , q1, · · · , qN−1+ 1
2 , qN) · (δq0, δq 1
2 , δq1, · · · , δqN−1+ 1
2 , δqN)
=
N−1

k=0
(D2L(wk)δqk + D3L(wk)δqk+ 1
2 + D5L(wk)δqk+1)(tk+1 −tk)
=
N−1

k=0
(D2L(wk)δqk + D3L(wk)δqk+ 1
2 )(tk+1 −tk)
+
N

k=1
D5L(wk−1)(tk −tk−1)δqk
=
N−1

k=1
(D2L(wk)(tk+1 −tk) + D5L(wk−1)(tk −tk−1)δqk
+
N−1

k=0
D3L(wk)δqk+ 1
2 (tk+1 −tk) + D2L(w0)(t1 −t0)δq0
+D5L(wN−1)(tN −tN−1)δqN,
(3.19)
where wk = (tk, qk, qk+ 1
2 , tk+1, qk+1) (k = 0, 1, · · · , N −1). From (3.19), we obtain
the discrete Euler–Lagrange equation
D2L(wk)(tk+1 −tk) + D5L(wk−1)(tk −tk−1) = 0,
(3.20)
D3L(tk, qk, qk+ 1
2 , tk+1, qk+1) = 0,
(3.21)
D3L(tk−1, qk−1, qk−1+ 1
2 , tk, qk) = 0.
(3.22)
From (3.21) and (3.22), we can solve for qk+ 1
2 and qk−1+ 1
2 respectively, then
substitute them into (3.20) and ﬁnally solve for qk+1. Therefore, the discrete Euler–
Lagrange equation (3.20) – (3.22) determines a discrete ﬂow
Ψ : M × M −→M × M,
Ψ(tk−1, qk1, tk, qk) = (tk, qk, tk+1, qk+1).
From (3.19), we can deﬁne two 1-forms
Θv−
L (tk, qk, qk+ 1
2 , tk+1, qk+1) = D2L(tk, qk, qk+ 1
2 , tk+1, qk+1)(tk+1 −tk)dqk,
and
Θv+
L (tk, qk, qk+ 1
2 , tk+1, qk+1) = D5L(tk, qk, qk+ 1
2 , tk+1, qk+1)(tk+1 −tk)dqk+1.
Using the same method as before, we can prove that
Ψ∗(dΘv+
L ) = −dΘv−
L .
(3.23)
From the deﬁnition of Θv−
L
and Θv+
L , we have
Θv−
L
+ Θv+
L
= d((tk+1 −tk)L) −D3L(tk, qk, qk+ 1
2 , tk+1, qk+1)dqk+ 1
2 .
(3.24)

14.3 Discrete Mechanics Based on Finite Element Methods
611
From (3.21), we obtain D3L(tk, qk, qk+ 1
2 , tk+1, qk+1) = 0. Thus
Θv−
L
+ Θv+
L
= d((tk+1 −tk)L),
which means
dΘv+
L
= −dΘv−
L .
(3.25)
From (3.23) and (3.25), we arrive at
Ψ∗(Ωv
L) = Ωv
L,
(3.26)
where Ωv
L = dΘv+
L .
For the classical Lagrangian (1.57), from (3.16) and (3.18), we obtain
L(tk, qk, qk+ 1
2 , tk+1, qk+1)
=
1
tk+1 −tk
- tk+1
tk
%1
2

˙qh2(t)
2 −V

qh2(t)
&
d t
= 1
2
%1
3a2(t2
k+1 + tktk+1 + t2
k) + ab(tk + tK+1) + b2
&
−G(qk, qk+ 1
2 , qk+1),
(3.27)
where
a = 4
h2
k

qk + qk+1 −2qk+ 1
2

,
b = 1
h2
k

4(tk + tk+1)qk+ 1
2 −(3tk + tk+1)qk+1 −(tk + 3tk+1)qk

,
and
G(qk, qk+ 1
2 , qk+1) =
1
tk+1 −tk
- tk+1
tk
V

qkfk(t)+qk+1fk+1(t)+qk+ 1
2 fk+ 1
2 (t)

d t,
where
fk(t) =
%
2(t −tk)
hk
−1
& t −tk
hk
−1

,
fk+1(t) =
%
2(tk+1 −t)
hk
−1
& tk+1 −t
hk
−1

,
fk+ 1
2 (t) = 4t −tk
hk

1 −t −tk
hk

.
For the discrete Lagrangian (3.27), the discrete Euler–Lagrange equations (3.20) –
(3.22) become
a1qk−1 + a2qk + a3qk+1 + a4qk−1
2 + a5qk+ 1
2 −d1hk −d2hk−1 = 0, (3.28)
−8
3h2
k

qk + qk+1 −2qk+ 1
2

−
∂G(qk, qk+ 1
2 , qk+1)
∂qk+ 1
2
= 0,
(3.29)
−
8
3h2
k−1

qk−1 + qk −2qk−1+ 1
2

−
∂G(qk−1, qk−1+ 1
2 , qk)
∂qk−1+ 1
2
= 0,
(3.30)

612
14. Lee-Variational Integrator
where
a1 = 1
3
1
hk−1 ,
a2 = 7
3
%
1
hk−1 + 1
hk
&
,
a3 = 1
3
1
hk ,
a4 = −8
3
1
hk−1 , a5 = −8
3
1
hk , d1 =
∂G(qk, qk+ 1
2 , qk+1)
∂qk
, d2 =
∂G(qk−1, qk−1+ 1
2 , qk)
∂qk
.
The solution of (3.28) – (3.30) preserves the Lagrange 2-form
*
1
3hk −hk
∂2 G(qk, qk+ 1
2 , qk+1)
∂qk∂qk+1
−M
+
d qk ∧d qk+1,
(3.31)
where
M =
*
16
3hk + hk
∂2G(qk, qk+ 1
2 , qk+1)
∂qk+ 1
2 ∂qk
+ *
16
3hk + hk
∂2G(qk, qk+ 1
2 , qk+1)
∂qk+ 1
2 ∂qk
+
*
32
3hk −hk
∂2G(qk, qk+ 1
2 , qk+1)
∂q2
k+ 1
2
+
.
If we take the ﬁxed time steps hk−1 = hk = h, then (3.28) – (3.30) become
qk−1 −8qk−1
2 + 14qk −8qk+ 1
2 + qk+1
3h2
−d1hk −d2hk−1 = 0,
(3.32)
−8
3h2

qk + qk+1 −2qk+ 1
2

−
∂G(qk, qk+ 1
2 , qk+1)
∂qk+ 1
2
= 0,
(3.33)
−8
3h2

qk−1 + qk −2qk−1+ 1
2

−
∂G(qk−1, qk−1+ 1
2 , qk)
∂qk−1+ 1
2
= 0,
(3.34)
which preserve
*
1
3h −h
∂2G(qk, qk+ 1
2 , qk+1)
∂qk∂qk+1
−M
+
d qk ∧d qk+1,
(3.35)
where
M =
*
16
3hk + h
∂2G(qk, qk+ 1
2 , qk+1)
∂qk+ 1
2 ∂qk
+ *
16
3hk + h
∂2G(qk, qk+ 1
2 , qk+1)
∂qk+ 1
2 ∂qk
+
*
32
3h −h
∂2G(qk, qk+ 1
2 , qk+1)
∂q2
k+ 1
2
+
.
Suppose qk is the solution of (3.28) – (3.30) and q(t) is the solution of (3.10), then
from the convergence theory of ﬁnite element methods [Cia78,Fen65], we have
∥q(t) −qh2(t)∥≤Ch3,
(3.36)
where
qh2(t) =
N

k=0
qkφk(t) +
N−1

k=0
qk+ 1
2 φk+ 1
2 (t),
h = maxk{hk} and C is a constant independent of h.

14.3 Discrete Mechanics Based on Finite Element Methods
613
14.3.3 Time Steps as Variables
In the above section, the time steps tk play the role of parameters. They are determined
beforehand according to some requirements. In fact, we can also regard tk as variables
and the variation of the discrete action with respect to tk yields the discrete energy
conservation law. This fact was ﬁrst observed by Lee[Lee82,Lee87]. The symplecticity
of the resulting integrators was investigated in [CGW03,KMO99]. These results are also
applied to the discrete mechanics based on ﬁnite element methods.
We regard tk as variables and calculate the variation of the discrete action (1.33)
as follows:
d S(t0, q0, · · · , tN, qN) · (δt0, δq0, · · · , δtN, δqN)
= d
d ε

ε=0S(t0 + εδt0, q0 + εδq0, · · · , tN + εδtN, qN + εδqN)
=
N−1

k=1
[D2L(wk)(tk+1 −tk) + D4L(wk−1)(tk −tk−1)]δqk
+
N−1

k=1
[D1L(wk)(tk+1 −tk) + D3L(wk−1)(tk −tk−1) + L(wk−1) −L(wk)]δtk
+D2L(w0)(t1 −t0)δq0 + D4L(wN−1)(tN −tN−1)δqN
+[D1L(w0)(t1 −t0) −L(w0)]δt0
+[D3L(wN−1)(tN −tN−1) + L(wN−1)]δtN,
(3.37)
where wk = (tk, qk, tk+1, qk+1) (k = 0, 1, · · · , N −1), so that we have the discrete
energy evolution equation from the variation δqk
D2L(wk)(tk+1 −tk) + D4L(wk−1)(tk −tk−1) = 0,
(3.38)
and the discrete energy evolution equation from the variation δtk
D1L(wk)(tk+1 −tk) + D3L(wk−1)(tk −tk−1) + L(wk−1) −L(wk) = 0, (3.39)
which is a discrete version of (1.23). For a conservative L, (3.39) becomes the discrete
energy conservation law.
From the boundary terms in (3.37), we can deﬁne two 1-forms
θ−
L (wk) = (D1L(wk)(tk+1 −tk) −L(wk))dtk + D2L(wk)(tk+1 −tk)dqk, (3.40)
and
θ+
L (wk) = (D3L(wk)(tk+1 −tk) + L(wk))dtk+1 + D4L(wk)(tk+1 −tk)dqk+1.
(3.41)
These two 1-forms are the discrete version of the extended Lagrange 1-form (1.29).
Unlike the continuous case, the solution of (3.38) does not satisfy (3.39) in general.
Therefore, we must solve (3.38) and (3.39) simultaneously. Using the same method in
the above section, we can show that the coupled integrator

614
14. Lee-Variational Integrator
D2L(wk)(tk+1 −tk) + D4L(wk−1)(tk −tk−1) = 0,
D1L(wk)(tk+1 −tk) + D3L(wk−1)(tk −tk−1) + L(wk−1) −L(wk) = 0,
(3.42)
preserves the extended Lagrange 2-form ωL = dθ+
L .
For the discrete Lagrangian (3.6), (3.42) becomes
%
qk+1 −qk
tk+1 −tk −qk −qk−1
tk −tk−1
&
+ ∂F(wk)
∂qk
hk + ∂F(wk−1)
∂qk
hk−1 = 0,
1
2
%
qk+1 −qk
tk+1 −tk
&2
+ F(wk) −∂F(wk)
∂tk
hk
= 1
2
%
qk −qk−1
tk −tk−1
&2
+ F(wk−1) + ∂F(wk−1)
∂tk
hk−1.
For the kind of high order discrete Lagrangian, we can obtain similar formulae.
14.3.4 Conclusions
Recently, it has been proved [GLWW01] that the symplectic structure is preserved not
only on the phase ﬂow but also on the ﬂow with respect to symplectic vector ﬁelds
as long as certain cohomological condition is satisﬁed in both continuous and discrete
cases. This should be able to be extended to the cases in this chapter.

Bibliography
[Arn89] V. I. Arnold: Mathematical Methods of Classical Mechanics. Springer-Verlag, GTM
60, Berlin Heidelberg, Second edition, (1989).
[BD01] T. J. Bridges and G. Derks: The symplectic evans matrix, and the instability of solitary
waves and fonts. Arch. Rat. Mech. Anal, 156:1–87, (2001).
[Bri97] T. J. Bridges: Multi-symplectic structures and wave propagation. Math. Proc. Cam.
Phil. Soc., 121:147–190, (1997).
[CGW03] J. B. Chen, H.Y. Guo, and K. Wu: Total variation in Hamiltonian formalism and
symplectic-energy integrators. J. of Math. Phys., 44:1688–1702, (2003).
[CH53] R. Courant and D. Hilbert: Methods of Mathematical Physics. Interscience, New York,
Second edition, (1953).
[Cia78] D. G. Ciarlet: The Finite Element for Elliptic Problem. North-Holland, Amsterdam,
First edition, (1978).
[Fen65] K. Feng: Difference schemes based on variational principle. J. of appl. and comput.
math.in chinese, 2(4):238–262, (1965).
[Fen86] K. Feng: Difference schemes for Hamiltonian formalism and symplectic geometry. J.
Comput. Math., 4:279–289, (1986).
[FWQW89] K. Feng, H. M. Wu, M.Z. Qin, and D.L. Wang: Construction of canonical dif-
ference schemes for Hamiltonian formalism via generating functions. J. Comput. Math.,
7:71–96, (1989).
[GLW01a] H. Y. Guo, Y. Q. Li, and K. Wu: A note on symplectic algorithms. Commun.Theor.
Phys., 36:11–18, (2001).
[GLW01b] H. Y. Guo, Y. Q. Li, and K. Wu: On symplectic and multisymplectic structures and
their discrete version in Lagrange formalism. Commun.Theor. Phys., 35:703–710, (2001).
[GLWW01] H. Y. Guo, Y. Q. Li, K. Wu, and S. K. Wang: Difference discrete variational
principle, Euler-Lagrange cohomology and symplectic, multisymplectic structures. arXiv:
math-ph/0106001, (2001).
[GM88] Z. Ge and J. E. Marsden: Lie–Poisson–Hamilton–Jacobi theory and Lie–Poisson in-
tegrators. Physics Letters A, pages 134–139, (1988).
[GPS02] H. Goldstein, C. Pole, and J. Safko: Classical Mechanics. Addison Wesley, New
York, Third edition, (2002).
[GW03] H. Y. Guo and K. Wu: On variations in discrete mechanics and ﬁeld theory. J. of
Math. Phys., 44:5978–6044, (2003).
[KMO99] C. Kane, J. E. Marsden, and M. Ortiz: Symplectic-energy-momentum preserving
variational integrators. J. of Math. Phys., 40:3353–3371, (1999).
[Lag88] J. L. Lagrange: M´ecanique Analytique, 2 vols. Gauthier-Villars et ﬁls, Paris, 4-th
edition, 1888-89, (1781)
[Lee82] T. D. Lee: Can time be a discrete dynamical variable? Phys.Lett.B, 122:217–220,
(1982).
[Lee87] T. D. Lee: Difference equations and conservation laws. J. Stat. Phys., 46:843–860,
(1987).

616
Bibliography
[MPS98] J. E. Marsden, G.P. Patrick, and S. Shloller: Multi-symplectic geometry, variational
integrators, and nonlinear PDEs. Communications in Mathematical Physics, 199:351–395,
(1998).
[MV91] J. Moser and A. P. Veselov: Discrete versions of some classical integrable systems and
factorization of matrix polynomials. Communications in Mathematical Physics, 139:217–
243, (1991).
[Olv93] P. J. Olver: Applications of Lie Groups to Differential Equations. GTM 107. Springer-
Verlag, Berlin, Second edition, (1993).
[SSC94] J. M. Sanz-Serna and M. P. Calvo: Numerical Hamiltonian Problems. AMMC 7.
Chapman & Hall, London, (1994).
[Ves88] A. P. Veselov: Integrable discrete-time systems and difference operators. Funkts. Anal.
Prilozhen, 22:1–33, (1988).
[Ves91a] A. P. Veselov: Integrable Lagrangian correspondences and the factorization of matrix
polynomials. Funkts. Anal. Prilozhen, 25:38–49, (1991).
[Ves91b] A. P. Veselov: Integrable maps. Russian Math. Surveys, 46:1–51, (1991).
[WM97] J. Wendlandt and J. Marsden: Mechanical integrators derived from a discrete varia-
tional principle. Physica D, 106:223–246, (1997).

Chapter 15.
Structure Preserving Schemes for Birkhoff
Systems
A universal symplectic structure for a Newtonian system including nonconservative
cases can be constructed in the framework of Birkhofﬁan generalization of Hamilto-
nian mechanics. In this chapter, the symplectic geometry structure of Birkhofﬁan sys-
tem is discussed, and the symplecticity of Birkhofﬁan phase ﬂow is presented. Based
on these properties, a way to construct symplectic schemes for Birkhofﬁan systems by
the generating function method is explained[SSQS07],[SQ03].
15.1 Introduction
Birkhofﬁan representation is a generalization of Hamiltonian representation, which
can be applied to hadron physics, statistical mechanics, space mechanics, engineering,
biophysics, etc. Santilli[San83a,San83b]. All conservative or nonconservative, self-adjoint
or non self-adjoint, unconstrained or nonholonomic constrained systems always ad-
mit a Birkhofﬁan representation (Guo[GLSM01] and Santilli[San83b]). In last 20 years,
many researchers have studied Birkhofﬁan mechanics and obtained a series of results
in integral theory, stability of motion, inverse problem, and algebraic and geometric
description, etc.
Birkhoff’s equations are more complex than Hamilton’s equations, and the study
of the computational methods of the former is also more complicated. There are no
result on computational methods for Birkhofﬁan system before. In general, the known
difference methods are not generally applicable to Birkhofﬁan system. A difference
scheme used to solve Hamiltonian system should be Hamiltonian scheme (Hairer, Lu-
bich and Wanner[HLW02] and Sanz-Serna and Calvo[SSC94]), so a difference scheme to
simulate Birkhofﬁan system should be a Birkhofﬁan scheme. However, the conven-
tional difference schemes such as Euler center scheme, leap-frog scheme, etc., are not
Birkhofﬁan schemes. So, a way to systematically construct a Birkhofﬁan scheme is
necessary, and this is the main context in this chapter.
Both the Birkhofﬁan and Hamiltonian systems are usually of ﬁnite dimensional
(Arnold[Arn89] and Marsden and Ratiu[MR99]), inﬁnite dimension system has not been
proposed before. The algebraic and geometric proﬁles of ﬁnite dimensional Birkhof-
ﬁan systems are described in local coordinates, and general nonautonomous Hamil-
tonian systems are considered as autonomous Birkhofﬁan systems (Santilli[San83b]).
Symplectic schemes are systematically developed for standard Hamiltonian systems

618
15. Structure Preserving Schemes for Birkhoff Systems
and for general Hamiltonian systems on the Poisson manifold, which belong to au-
tonomous and semi-autonomous Birkhofﬁan systems (Feng and Wang[FW91bandFW91a]
and Feng and Qin[FQ87]). So, in this chapter, we just discuss the nonautonomous
Birkhofﬁan system in detail. Thereby, Einstein’s summation convention is used.
In Section 15.2, Birkhofﬁan systems are sketched out via variational self-adjointness,
with which we shows the relationship between Birkhofﬁan and Hamiltonian systems
more essentially and directly. Then the basic geometrical properties of Birkhofﬁan sys-
tems are presented. In Section 15.3, the deﬁnitions of "K(z)-Lagrangian submanifolds
is extended to "K(z, t)-Lagrangian submanifolds with parameter t. Then the relation-
ship between symplectic mappings and gradient mappings are discussed. In Section
15.4, the generating functions for the phase ﬂow of the Birkhofﬁan systems are con-
structed and the method to simulate Birkhofﬁan systems by symplectic schemes of any
order is given. Section 15.5 contains an illustrating example. Schemes of order one,
two, and four are derived for the linear damped oscillator. In the last Section 15.6,
numerical experiments are given.
15.2 Birkhofﬁan Systems
The generalization of Hamilton’s equation is given by
%
∂Fj
∂zi −∂Fi
∂zj
&
d zi
d t −
%
∂B(z, t)
∂zi
+ ∂F(z, t)
∂t
&
= 0,
i, j = 1, 2, · · · , 2n,
(2.1)
where the following abbreviations
Kij = ∂Fj
∂zi −∂Fi
∂zj ,
K = (Kij)i,j=1,···,2n
are further used. Following the terminology suggested by Santilli[San83b], this is called
Birkhoff’s equation or Birkhofﬁan system under some additional assumptions. The
function B(z, t) is called the Birkhofﬁan function because of certain physical differ-
ence with Hamiltonian. Also, the Fi (i = 1, 2, · · · , 2n) are Birkhofﬁan functions. A
representation of Newton’s equations via Birkhoff’s equation is called a Birkhofﬁan
representation.
Deﬁnition 2.1. Birkhoff’s equations (2.1) are called autonomous when the functions
Fi and B are independent of the time variable. In this case, the equations are of the
simple form
Kij(z)d zj
d t −∂B(z)
∂zi
= 0.
(2.2)
They are called semi-autonomous when the functions Fi do not depend explicitly on
time. In this case, the equations have the more general form
Kij(z)d zj
d t −∂B(z, t)
∂zi
= 0.

15.2 Birkhofﬁan Systems
619
They are called nonautonomous when both the functions Fi and B explicitly depen-
dent on time. Then, the equations read as follow:
Kij(z, t)d zj
d t −∂B(z, t)
∂zi
−∂Fi(z, t)
∂t
= 0.
(2.3)
They are called regular when the functional determinant is unequal to zero in the
region considered, i.e.,
det (Kij)($
Re ) ̸= 0,
otherwise, degenerate.
Given an arbitrary analytic and regular ﬁrst-order system
Kij(z, t)d zi
d t + Di(z, t) = 0,
i = 1, 2, · · · , 2n,
(2.4)
which is self-adjoint if and only if it satisﬁes the following conditions in $
Re
∗for
i, j = 1, 2, · · · , 2n[AH75]:
Kij + Kji = 0,
∂Kij
∂zk + ∂Kjk
∂zi
+ ∂Kki
∂zj
= 0,
∂Kij
∂t
= ∂Di
∂zj −∂Dj
∂zi .
(2.5)
We now simply introduce the geometric signiﬁcance of the condition of variational
self-adjointness [MP91,SVC95]. Here the region considered is a star-shaped region $
Re
∗
of points of R×T ∗M, T ∗M the cotangent space of the M, M a 2n-dimensional man-
ifold. The geometric signiﬁcance of self-adjointness condition (2.5) is the integrability
condition for a 2-form to be an exact symplectic form.
Consider ﬁrst the case for which Kij = Kij(z). Given a symplectic structure
written as the 2-form in local coordinates
Ω =
2n

i,j=1
Kij(z, t) d zi ∧d zj.
One of the fundamental properties of symplectic form is that dΩ = 0. Because the
exact character of 2-form implies that
Ω = d (Fi d zi),
(2.6)
this geometric property is fully characterized by the ﬁrst two equations of the condition
(2.5); i.e., the 2-form (2.6) describes the geometrical structure of the autonomous case
(2.2) of the Birkhoff’s equations, it even sketches out the geometric structure of the
semi-autonomous case.

620
15. Structure Preserving Schemes for Birkhoff Systems
For the case Kij = Kij(z, t), the full set of condition (2.5) must be consid-
ered. The corresponding geometric structure can be better expressed by transition
of the symplectic geometry on the cotangent bundle T ∗M with local coordinates
zi to the contact geometry on the manifold R × T ∗M with local coordinates "zi
(i = 0, 1, 2, · · · , 2n), "z0 = t[San83b]. More general formulations of an exact contact
2-form exist, although it is now referred to as a (2n+1)-dimensional space,
Ω =
2n

i,j=0
Kij d "zi ∧d "zj = Ω + 2 Di d zi ∧d t,
where
K =
5
0
−DT
D
K
6
,
D = (D1, · · · , D2n)T.
If the contact form is also of the exact type,
Ω = d ( "Fi d "zi),
"Fi =

−B,
Fi,
(2.7)
the geometric meaning of the condition of the self-adjointness is then the integrability
condition for the exact contact structure (2.7). Here B can be calculated from
−∂B
∂zi = Di + ∂Fi
∂t
for
∂
∂zj

Di + ∂Fi
∂t

=
∂
∂zi

Dj + ∂Fj
∂t

.
All the above discussion can be expressed via the following property.
Theorem 2.2 (Self-Adjointness of Birkhofﬁan System). For a general nonautonom-
ous ﬁrst-order system (2.4), a necessary and sufﬁcient condition for self-adjointness
in $
Re
∗of points of R × T∗R2n is that it is of the Birkhofﬁan type, i.e., the following
representation holds for i, j = 1, 2, · · · , 2n,
Kij(z, t)d zi
d t + Di(z, t) =
∂Fj
∂zi −∂Fi
∂zj
d zi
d t −

∇B(z, t) + ∂F(z, t)
∂t

.
(2.8)
Remark 2.3. The functions Fi and B can be calculated according to the rules [AH75]
Fi = 1
2
- 1
0
zj · Kji(λz, t) d λ,
B =
- 1
0
zi ·

Di + ∂Fi
∂t

(λz, t) d λ.

15.3 Generating Functions for K(z, t)-Symplectic Mappings
621
Due to the self-adjointness of Birkhoff’s equations, the phase ﬂow of the system
(2.8) conserves the symplecticity
d
d t Ω = d
d t(Kij d zi ∧d zj) = 0.
So denoting the phase ﬂow of the Equation (2.8) with (z, t) yields
Kij(z, t) d zi ∧d zj = Kij(z, t) d zi ∧d zj,
respectively the algebraic representation
∂z
∂z
T
K(z, t) ∂z
∂z = K(z, t).
In the latter, the algorithm preserving this geometric property of the phase ﬂow in
discrete space will be constructed.
15.3 Generating Functions for K(z, t)-Symplectic
Mappings
In this section, general K(z, t)-symplectic mappings and their relationships with the
gradient mappings and their generating functions are considered [FW91b,FW91a,FQ87].
Deﬁnition 3.1. Let denote
J2n =
5
O
In
−In
O
6
,
J4n =
5
O
I2n
−I2n
O
6
,
"J4n =
5
J2n
O
O
−J2n
6
,
"K(z, z, t, t0) =
5
K(z, t)
O
O
−K(z, t0)
6
.
Then a 2n-dimensional submanifold L ⊂R4n
L =
' z
z

∈R4n | z = z(x, t0), z = z(x, t), x ∈U ⊂R2n, open set
/
is called a J4n- or "J4n- or "K(z, z, t, t0)-Lagrangian submanifold if it holds
(TxL)TJ4n(TxL) = 0,
(TxL)T "J4n(TxL) = 0
or
(TxL)T "K(z, z, t, t0)(TxL) = 0,
where TxL is the tangent space to L at x.

622
15. Structure Preserving Schemes for Birkhoff Systems
Deﬁnition 3.2. The mapping with parameters t and t0 is z →z = g(z, t, t0) :
R2n →R2n is called a canonical map or a gradient map or a K(z, t)-symplectic
map if its graph
Γg =
' z
z

∈R4n | z = g(z, t, t0), z = z ∈R2n
/
is a J4n- or "J4n- or "K(z, z, t, t0)-Lagrangian submanifold.
For differentiable mappings, there exists an equivalent deﬁnition for the K-
symplecticness, which is also useful for difference schemes.
Deﬁnition 3.3. A differentiable mapping g : M →M is K(z, t)-symplectic if
∂g
∂z
T
K

g(z, t, t0), t
∂g
∂z = K(z, t0).
A difference scheme approximating the Birkhofﬁan system (2.8) with step size τ
zk+1 = gk(zk, tk + τ, tk),
k ⩾0
is called a K-symplectic scheme, if gk is K-symplectic for every k, i.e.,
∂gk
∂zk
T
K(zk+1, tk+1) ∂gk
∂zk = K(zk, tk).
The graph of the phase ﬂow of the Birkhofﬁan system (2.8) is gt(z, t0) =
g(z, t, t0) which is a "K(z, z, t, t0)-Lagrangian submanifold for
gt
z(z, t0)TK

gt(z, t0), t

gt
z(z, t0) = K(z, t0).
Similarly, the graph of the phase ﬂow of standard Hamiltonian system is a "J4n-
Lagrangian submanifold.
Consider the nonlinear transformation with two parameters t and t0 from R4n to
itself,
α(t, t0) :
5 z
z
6
−→
5 w
w
6
=
5 α1(z, z, t, t0)
α2(z, z, t, t0)
6
,
(3.1)
α−1(t, t0) :
5 w
w
6
−→
5 z
z
6
=
5 α1( w, w, t, t0)
α2( w, w, t, t0)
6
.
Let denote the Jacobian of α and its inverse by
α∗(z, z, t, t0) =
5 Aα
Bα
Cα
Dα
6
,
α−1
∗( w, w, t, t0) =
5 Aα
Bα
Cα
Dα
6
.

15.3 Generating Functions for K(z, t)-Symplectic Mappings
623
Let α be a diffeomorphism from R4n to itself, then it follows that α carries ev-
ery "K-Lagrangian submanifold into a J4n-Lagrangian submanifold, if and only if
αT
∗J4nα∗= "K, i.e.,
5
Aα
Bα
Cα
Dα
6T 5
J2n
O
O
−J2n
6 5
Aα
Bα
Cα
Dα
6
=
5
K(z, t)
O
O
−K(z, t0)
6
.
Conversely, α−1 carries every J4n-Lagrangian submanifold into a "K-Lagrangian sub-
manifold.
Theorem 3.4. Let M ∈R2n×2n, α given as in (3.1), and deﬁne a fractional trans-
formation
σα : M −→M,
M −→N = σα(M) = (AαM + Bα)(CαM + Dα)−1
under the transversality condition |CαM + Dα| ̸= 0. Then the following four condi-
tions are mutually equivalent:
|CαM + Dα| ̸= 0,
|MCα −Aα| ̸= 0,
|CαN + Dα| ̸= 0,
|NCα −Aα| ̸= 0.
The proof is direct and simple, so it is omitted here.
Theorem 3.5. Let α be deﬁned as in (3.1). Let z →z = g(z, t, t0) be a K(z, t)-
symplectic mapping in some neighborhood "R of R2n with Jacobian gz(z, t, t0) =
M(z, t, t0). If M satisﬁes the transversality condition in "R
Cα(g(z, t, t0), z, t, t0)M(z, t, t0) + Dα(g(z, t, t0), z, t, t0)
 ̸= 0,
(3.2)
then there uniquely exists in "R a gradient mapping w →w = f(w, t, t0) with Ja-
cobian fw(w, t, t0) = N(w, t, t0) and a uniquely deﬁned scalar generating function
φ(w, t, t0), such that
f(w, t, t0) = φw(w, t, t0),
α1(g(z, t, t0), z, t, t0) = f

α2(g

z, t, t0), z, t, t0

, t, t0

= φw

α2

g(z, t, t0), z, t, t0

, t, t0

,
(3.3)
and
N = (AαM + Bα)(CαM + Dα)−1,
M = (AαN + Bα)(CαN + Dα)−1.
Proof. Under the transformation α, the image of the graph Γg is
α(Γg) =
5
w
w
6
∈R4n |
5 w = α1

g(z, t, t0), z, t, t0

w = α2

g(z, t, t0), z, t, t0

67
.

624
15. Structure Preserving Schemes for Birkhoff Systems
Inequality (3.2) implies
∂w
∂z
 =
∂α2
∂z · ∂z
∂z + ∂α2
∂z
 =
CαM + Dα
 ̸= 0,
so w = α2

g(z, t, t0), z, t, t0

is invertible, the inverse function is denoted by z =
z(w, t, t0). Set
w = f(w, t, t0) = α1

g(z, t, t0), z, t, t0

|z=z(w,t,t0),
(3.4)
then
N = ∂f
∂w =
∂α1
∂z
∂g
∂z + ∂α1
∂z
 ∂z
∂w

= (AαM + Bα)(CαM + Dα)−1.
Notice that the tangent space to α(Γg) at z is
Tz

α(Γg)

=
⎡
⎢⎣
∂w
∂z
∂w
∂z
⎤
⎥⎦=
5 AαM + Bα
CαM + Dα
6
.
It can be concluded that α (Γg) is a J4n-Lagrangian submanifold for
Tz

α(Γg)
TJ4nTz

α(Γg)

=

(AαM + Bα)T, (CαM + Dα)T
J4n
5
AαM + Bα
CαM + Dα
6
= (M T, I)αT
∗J4nα∗
 M
I

= (M T, I) "K
 M
I

= 0.
So,
(AαM + Bα)T(CαM + Dα) −(CαM + Dα)T(AαM + Bα) = 0,
i.e., N = (AαM + Bα)(CαM + Dα)−1 is symmetric. This implies that w =
f(w, t, t0) is a gradient mapping. By the Poincar´e lemma, there is a scalar function
φ(w, t, t0) such that
f(w, t, t0) = φw(w, t, t0).
(3.5)
Consider the construction of f(w, t, t0) and z(w, t, t0). Since z(w, t, t0)◦α2(g(z, t, t0),
z, t, t0) ≡z, substituting w = α2(g(z, t, t0), z, t, t0) in (3.4) and (3.5) yields Equa-
tion (3.3).
▲
Theorem 3.6. f(w, t, t0) obtained in Theorem 3.5 is also the solution of the following
implicit equation:
α1
f(w, t, t0), w, t, t0

= g

α2(f(w, t, t0), w, t, t0), t, t0

.

15.4 Symplectic Difference Schemes for Birkhofﬁan Systems
625
Theorem 3.7. Let α be deﬁned as in Theorem 3.5, let w →w = f(w, t, t0) be
a gradient mapping in some neighborhood "R of R2n with Jacobian fw(w, t, t0) =
N(w, t, t0). If N satisﬁes in "R the condition
Cα
f(w, t, t0), w, t, t0

N(w, t, t0) + Dα
f(w, t, t0), w, t, t0
 ̸= 0,
then in "R there uniquely exists a K(z,t)-symplectic mapping z →z = g(z, t, t0) with
Jacobian g(z, t, t0) = M(z, t, t0) such that
α1(f(w, t, t0), w, t, t0) = g(α2(f(w, t, t0), w, t, t0), t, t0),
M = (AαN + Bα)(CαN + Dα)−1,
N = (AαM + Bα)(CαM + Dα)−1.
Remark 3.8. The proofs of Theorems 3.6 and 3.7 are similar to that of Theorem 3.5
and are omitted here. Similar to Theorem 3.6, the function g(z, t, t0) is the solution of
the implicit equation
α1(g(z, t, t0), z, t, t0) = f(α2(g(z, t, t0), z, t, t0), z, t, t0).
15.4 Symplectic Difference Schemes for Birkhofﬁan
Systems
In Section 15.2, it is indicated that for a general Birkhofﬁan system, there exists the
common property that its phase ﬂow is symplectic. With the result in the last sec-
tion, symplectic schemes for Birkhofﬁan systems are constructed by approximating
the generating functions.
Birkhoff’s phase ﬂow is denoted by gt(z, t0) and it is a one-parameter group of
K(z, t)-symplectic mappings at least local in z and t, i.e., gt0 = identity, gt1+t2 =
gt1 ◦gt2. Here z is taken as an initial value when t = t0, and z(z, t, t0) = gt(z, t0) =
g(t; z, t0) is the solution of the Birkhofﬁan system (2.8).
Theorem 4.1. Let α be deﬁned as in Theorem 3.5. Let z →z = gt(z, t0) be the phase
ﬂow of the Birkhofﬁan system (2.8), M(t; z, t0) = gz(t; z, t0) is its Jacobian. At some
initial point z, i.e., t = t0, z = z, if
|Cα(z, z, t0, t0) + Dα(z, z, t0, t0)| ̸= 0,
(4.1)
then for sufﬁciently small |t −t0| and in some neighborhood of z ∈R2n there exists
a gradient mapping w →w = f(w, t, t0) with symmetric Jacobian fw(w, t, t0) =
N(w, t, t0) and a uniquely determined scalar generating function φ(w, t, t0) such that

626
15. Structure Preserving Schemes for Birkhoff Systems
f(w, t, t0) = φw(w, t, t0),
(4.2)
∂
∂tφw(w, t, t0) = A

φw(w, t, t0), w, φww(w, t, t0), t, t0

,
(4.3)
A

w, w, ∂w
∂w, t, t0

=
¯
A

z( w, w, t, t0), z( w, w, t, t0), ∂w
∂w , t, t0

,
(4.4)
¯
A

z, z, ∂w
∂w, t, t0

=
d
d t w(z, z, t, t0) −∂w
∂w
d
d tw(z, z, t, t0)
=

Aα −∂w
∂wCα

K−1D(z, t) + ∂α1
∂t −∂w
∂w
∂α2
∂t ,(4.5)
α1(g(t; z, t0), z, t, t0) = f

α2

g(t; z, t0), z, t, t0

, t, t0

= φw

α2

g(t; z, t0), z, t, t0

, t, t0

,
and
N = σα(M) = (AαM + Bα)(CαM + Dα)−1,
M = σα−1 = (AαN + Bα)(CαN + Dα)−1.
Proof. M(t; z, t0) is differentiable with respect to z and t. Condition (4.1) guarantees
that for sufﬁciently small |t −t0| and for z in some neighborhood of z ∈R2n, there is
Cα(z, z, t, t0)M(t; z, t0) + Dα(z, z, t, t0)
 ̸= 0.
Additionally, the Birkhofﬁan phase ﬂow is a symplectic mapping; therefore, by The-
orem 3.5, there exists a time-dependent gradient map w = f(w, t, t0) and a scalar
function φ(w, t, t0), such that
f(w, t, t0) = φw(w, t, t0),
∂f(w, t, t0)
∂t
= ∂φw(w, t, t0)
∂t
.
(4.6)
Notice that z = g(t; z, t0) is the solution of the following initial-value problem;
⎧
⎪
⎨
⎪
⎩
d z
d t = K−1(z, t)

∇B + ∂F
∂t

(z, t),
z|t=t0 = z,
therefore, from the equation in (3.2), it follows that
d w
d t = ∂w
∂z · d z
d t + ∂
∂tα1(z, z, t, t0) = AαK−1
∇B + ∂F
∂t

+ ∂α1
∂t ,
d w
d t = CαK−1
∇B + ∂F
∂t

+ ∂α2
∂t ,
so
∂w
∂t = d w
d t −∂w
∂t
d w
d t =

Aα −∂w
∂t Cα

K−1
∇B + ∂F
∂t

+ ∂α1
∂t −∂w
∂w
∂α2
∂t .
Since ∂w
∂w ̸= 0, so w = w( w, t) exists and is solvable in ( w), but it cannot be solved
explicitly from the transformation α and α−1, we have
¯
A

z, z, ∂w
∂w, t, t0

= ∂w
∂t ,
and the Equations (4.4) and (4.5). Then, from (4.6), the Equation (4.3) follows.
▲

15.4 Symplectic Difference Schemes for Birkhofﬁan Systems
627
According to[FW91b,FW91a,FQ87], we can easily construct symplectic difference schemes
of any order for the autonomous or semi-autonomous Birkhofﬁan systems. Because of
the simplicity of the ordinary geometry structure, the transformation α in (3.1) needed
in these cases is independent of the parameter t, accordingly
∂w
∂t
=
d w
d t −∂w
∂t
d w
d t =

Aα −∂w
∂t Cα

K−1∇B
= −

BαT +
∂w
∂w
T
AαT
∇zB
= −Bw

z( w, w)


or = −Bw(z( w, w), t)

.
Therefore, the corresponding Birkhofﬁan system is completely a Hamiltonian system
∂φ(w, t)
∂t
= −B

z(φw, w)

,
∂φ(w, t, t0)
∂t
= −B

z(φw, w), t

(4.7)
in the autonomous and semi-autonomous case, respectively.
Remark 4.2. Because of the forcing term in (2.1), the Hamilton–Jacobi equation
for the generating function φ(w, t, t0) cannot directly be derived, but instead the
Hamilton–Jacobi equation (4.3) for φw(w, t, t0) can be easily derived. Assume the
generating function φw(w, t, t0) can be expanded as a convergent power series in t
φw(w, t, t0) =
∞

k=0
(t −t0)kφ(k)
w (w, t0).
(4.8)
Lemma 4.3. The k-th order total derivative of A deﬁned as in Theorem 4.1 with re-
spect to t can be described as
Dk
t A = ∂φwA
 ∞

i=0
(t −t0)iφ(k+i)
w

+ ∂φwwA
 ∞

i=0
(t −t0)iφ(k+i)
ww

+∂t ∂φw A
 ∞

i=0
(t −t0)i φ(k−1+i)
w

+ ∂t ∂φww A
 ∞

i=0
(t −t0)iφ(k−1+i)
ww

+
k

m=0
Cm
k
k−m

n=1
Cn
k−m
k−m−n

l=1

h1+···+hn
+j1+···+jl=k−m
∂n
φw ∂l
φww∂m
t A
·
 ∞

i=0
(t −t0)iφ(h1+i)
w
, · · ·,
∞

i=0
(t −t0)iφ(hn+i)
w
,
·
∞

i=0
(t −t0)iφ(j1+i)
ww
, · · ·,
∞

i=0
(t −t0)iφ(jl+i)
w

,
then at the point of t = t0, the total derivative of A is as

628
15. Structure Preserving Schemes for Birkhoff Systems
Dk
t At0 = ∂φw At0φ(k)
w + ∂φwwAt0φ(k)
ww
+∂t ∂φw At0φ(k−1)
w
+ ∂t ∂φwwAt0φ(k−1)
ww
+
k

m=0
Cm
k
k−m

n=1
Cn
k−m
k−m−n

l=1

h1+···+hn
+j1+···+jl=k−m
∂n
φw ∂l
φww ∂m
t At0
·

φ(h1)
w
, · · · , φ(hn)
w
, φ(j1)
ww , · · · , φ(jl)
ww

,
where At0 = A(φ(0)
w , w, φ(0)
ww, t0, t0).
By means of the representations of the total derivative of A, the following results
are proved.
Theorem 4.4. Let A and α be analytic. Then the generating function φwα,A(w, t, t0)
= φw(w, t, t0) can be expanded as a convergent power series in t for sufﬁciently small
|t −t0|
φw(w, t, t0) =
∞

k=0
(t −t0)kφ(k)
w (w, t0),
(4.9)
and φ(k)
w (k ≥0), can be recursively determined by the following equations
φ(0)
w (w, t0) = f(w, t0, t0),
(4.10)
φ(1)
w (w, t0) = A

φ(0)
w , w, φ(0)
ww, t0, t0

,
(4.11)
φk+1
w
(w, t0) =
1
(k + 1) !Dk
t A

φ(0)
w , w, φ(0)
ww, t0, t0

.
(4.12)
Proof. Differentiating Equation (4.9) with respect to w and t, we derive
φww(w, t, t0) =
∞

k=0
(t −t0)kφ(k)
ww(w, t0),
(4.13)
∂
∂tφw(w, t, t0) =
∞

k=0
(k + 1)(t −t0)kφ(k+1)
w
(w, t0).
(4.14)
By Equation (4.2),
φ0
w(w, t0) = φw(w, t0, t0) = f(w, t0, t0).
Substituting Equations (4.9) and (4.13) in A

w, w, ∂w
∂w, t, t0

, and expanding A in
t = t0, we get
A(φw, w, φww, t, t0) = A(f(w, t0, t0), w, fw(w, t0, t0), t0, t0)
+
∞

k=1
1
k !(t −t0)kDk
t A(φ(0)
w , w, φ(0)
ww, t0, t0). (4.15)
Using Equation (4.3) and comparing (4.15) with (4.14), we get (4.11) and (4.12).
▲

15.5 Example
629
In the autonomous and semi-autonomous case, A is replaced by the Birkhofﬁan B,
which makes it much easier to expand the generating functions φ. With Theorems 3.5
and 3.7, the relationship between the Birkhofﬁan phase ﬂow and the generating func-
tion φ(w, t, t0) is established. With this result, K(z, t)-symplectic difference schemes
can be directly constructed.
Theorem 4.5. Let A and α be analytic. For sufﬁciently small time-step τ > 0, take
ψ(m)
w
(w, t0 + τ, t0) =
m

i=0
τ iφ(i)
w (w, t0),
m = 1, 2, · · · ,
where φ(i)
w are determined by Equations (4.10) – (4.12).
Then, ψ(m)
w
(w, t0 + τ, t0) deﬁnes a K(z,t)-symplectic difference scheme z = zk →
zk+1 = z,
α1(zk+1, zk, tk+1, tk) = ψ(m)
w

α2(zk+1, zk, tk+1, tk), tk+1, tk

(4.16)
of m-th order of accuracy.
Proof. Let be N = φww(w0, t0, t0) = ψ(m)
ww (w0, t0, t0) and w0 = α(z, z, t0, t0),
then Theorem 3.7 yields |CαN + Dα|, because of
|Cα(z, z, t0, t0) + Dα(z, z, t0, t0)| ̸= 0.
Thus, for sufﬁciently small τ and in some neighborhood of w0, there exists
|CαN (m)(w, t0 + τ, t0) + Dα| ̸= 0,
where
N (m)(w, t0 + τ, t0) = ψ(m)
ww (w, t0 + τ, t0).
By Theorem 3.7, ψ(m)
w
(w, t0 + τ, t0) deﬁnes a K(z, t)-symplectic mapping which
is expressed in (3.3). Therefore, Equation (4.16) determines a m-th order K(z, t)-
symplectic difference scheme for the Birkhofﬁan system (2.8).
▲
15.5 Example
In this section, an example illustrates how to obtain schemes preserving the symplectic
structure for a nonconservative system expressed in Birkhofﬁan representation. Con-
sider the linear damped oscillator
¨r + ν ˙r + r = 0.
(5.1)
We introduce a gradient function p satisfying p = ˙r, then a Birkhofﬁan representation
of (5.1) is given by

630
15. Structure Preserving Schemes for Birkhoff Systems
5
0
−eνt
eνt
0
6 5
˙r
˙p
6
=
5
νeνtp + eνtr
eνtp
6
.
(5.2)
The structure and functions are
K =
5
0
−eνt
eνt
0
6
,
K−1 =
5
0
e−νt
−e−νt
0
6
,
F =
⎡
⎣
1
2eνtp
−1
2eνtr
⎤
⎦,
B = 1
2eνt(r2 + rp + p2),
and the energy function reads as follows:
H(q, p) = 1
2(q2 + p2) −νp2.
(5.3)
The Euler midpoint scheme (or one-step Gauss–Runge–Kutta method) for the sys-
tem (5.2), which can be derived via the discrete Lagrange–d’Alembert principle[MW01],
reads as follows:
qk+1 −qk
τ
= pk+1 + pk
2
,
pk+1 −pk
τ
= −ν pk+1 + pk
2
−qk+1 + qk
2
,
and hence,
5
qk+1
pk+1
6
= 1
Δ
5
−τ 2 + 2ντ
4τ
−4τ
−τ 2 −2ντ + 4
6 5
qk
pk
6
,
(5.4)
where Δ = τ 2 + 2ντ + 4, is not a K(z, t)-symplectic scheme.
Now, let the transformation α in (3.1) be
Q = eνtp −eνt0p,
P = q −q,
Q = 1
2(q + q),
P = −1
2(eνtp + eνt0p),
(5.5)
where the Jacobian of α is
α∗=
⎡
⎢⎢⎢⎢⎢⎣
0
eνt
0
−eνt0
1
0
−1
0
1
2
0
1
2
0
0
−1
2eνt
0
−1
2eνt0
⎤
⎥⎥⎥⎥⎥⎦
.
The inverse transformation is
q = 1
2
P + Q,
p = 1
2e−νt Q −e−νtP,
q = −1
2
P + Q,
p = −1
2eνt0 Q −e−νt0P,
(5.6)

15.5 Example
631
and
α−1
∗
=
⎡
⎢⎢⎢⎢⎢⎢⎢⎣
0
1
2
1
0
1
2e−νt
0
0
−e−νt
0
−1
2
1
0
−1
2e−νt0
0
0
−e−νt0
⎤
⎥⎥⎥⎥⎥⎥⎥⎦
.
Consequently, using (5.5), (5.6) and (5.2), we derive
d w
d t =
5
νeνtp + eνt ˙p
˙q
6
=
5
−eνtq
p
6
=
⎡
⎢⎣
−1
2eνt P −eνtQ
1
2e−νt Q −e−νtP
⎤
⎥⎦,
d w
d t =
⎡
⎢⎣
1
4e−νt Q −1
2e−νtP
1
4eνt P + 1
2eνtQ
⎤
⎥⎦.
Simple calculations (for m = 0,1) yields,
φ(0)
w =
5 Q
P
6 
t=t0
=
 0
0

,
φ(1)
w = d w
d t

t=t0 −φ(0)
ww d w
d t

t=t0 =
5
−eνt0Q
−e−νt0P
6
.
Set w = φ(0)
w +φ(1)
w τ, so the ﬁrst order scheme for the system (5.2) reads as follows:
qk+1 −qk
τ
= e−νtk+1 eνtk+1pk∗1 + eνtkpk
2
,
eνtk+1pk+1 −eνtkpk
τ
= −eνtk qk+1 + qk
2
,
and hence
5
qk+1
pk+1
6
= 1
Δ
5
4 −τ 2
4τ
−4τe−ντ
(4 −τ 2)e−ντ
6 5
qk
pk
6
,
(5.7)
where Δ = 4 + τ 2. The transition matrix denoted by A satisﬁes
AT
5
0
−eνtk+1
eνtk+1
0
6
A =
5
0
−eνtk
eνtk
0
6
.
Then, consider the transformation α in (3.1) to be

632
15. Structure Preserving Schemes for Birkhoff Systems
Q = eνt/2p −eνt0/2p,
P = −eνt/2q + eνt0/2q,
Q = 1
2(eνt/2q + eνt0/2q),
P = −1
2(eνtp + eνt0p).
The Jacobian of α is
α∗=
⎡
⎢⎢⎢⎢⎢⎣
0
eνt/2
0
−eνt0/2
−eνt/2
0
eνt0/2
0
1
2eνt/2
0
1
2eνt0/2
0
0
−1
2eνt
0
−1
2eνt0
⎤
⎥⎥⎥⎥⎥⎦
and the inverse
α−1
∗
=
⎡
⎢⎢⎢⎢⎢⎢⎢⎢⎣
0
1
2
1
0
1
2e−νt
0
0
−e−νt
0
−1
2
1
0
−1
2e−νt0
0
0
−e−νt0
⎤
⎥⎥⎥⎥⎥⎥⎥⎥⎦
.
Direct calculation yields the scheme of second order
eνtk+1/2qk+1 −eνtk/2qk
τ
= eνtk+1/2pk+1 + eνtk/2pk
2
+ ν eνtk+1/2qk+1 + eνtk/2qk
4
,
eνtk+1/2pk+1 −eνtk/2pk
τ
= eνtk+1/2qk+1 + eνtk/2qk
2
−ν eνtk+1/2pk+1 + eνtk/2pk
4
,
and hence,
5
qk+1
pk+1
6
= e−ντ/2
Δ
5
w1
−16τ
16τ
w −2
6 5
qk
pk
6
,
(5.8)
where Δ = ν2τ 2 −4τ 2 −16,
w1 = −16 −8ντ −ν2τ 2 + 4τ 4,
w2 = −16 + 8ντ −ν2τ 2 + 4τ 2.
Abbreviating the matrix e−ντ/2
Δ
(∗) in (5.8) by M(τ), then by composition[Yos90,QZ92]
we have the scheme of order four
5
qk+1
pk+1
6
= M(c1τ)M(c2τ)M(c1τ)
5
qk
pk
6
,
(5.9)
where
c1 =
1
2 −21/3 ,
c2 =
−21/3
2 −21/3 .
If take m = 2, we have
φ(2)
w = 0.

15.5 Example
633
Now take m = 3,
φ(3)
w
=
1
3 !
∂
∂t
 ∂
∂t
d "w
d t

+ ∂
∂"w
d "w
d t
∂"w
∂t −∂"w
∂w
∂
∂"w
d w
d t
∂"w
∂t
−∂"w
∂w
∂
∂t
d w
d t

−∂
∂t
∂"w
∂w
d w
d t

.
(5.10)
For equation ¨q + ν ˙q + q = 0, 3rd derivatives of φ in time t = t0, only one term to
appear, i.e.,
−∂
∂t
∂"w
∂w
 ∂
∂"w
d w
d t
∂"w
∂t .
Simple calculation yields
φ(3)
w

t=t0 = −1
6

−1
−ν
2
−ν
2
−1


1
8
−ν
8
−ν
8
1
4


−ν
2P −Q
−ν
2Q −P

= −1
6


−1
4 + 1
16ν2
Q + νP
2


−1
4 + 1
16ν2νQ
2 + P


=

ν2
2 −2

Q +
ν2
2 −2
ν
2P
ν2
2 −2

P +
ν2
2 −2
ν
2Q

,
we get 4-th order symmetrical symplectic scheme: "w = φ(1)
w Δt + φ(3)
w Δt2, i.e.,
eνtk+1/2qk+1 −eνtk/2qk
τ
=
eνtk+1/2pk+1 + eνtk/2pk
2
+ ν eνtk+1/2qk+1 −eνtk/2qk
4
+τ 2
1
24 × 4
ν2
2 −2

eνtk+1/2pk+1 + eνtk/2pk

+
ν2
2 −2
ν
2

eνtk+1/2qk+1 + eνtk/2qk

,
eνtk+1/2pk+1 −eνtk/2pk
τ
=
eνtk+1/2qk+1 + eνtk/2qk
2
−ν eνtk+1/2pk+1 + eνtk/2pk
4
−τ 2
1
24 × 4
ν2
2 −2

eνtk+1/2qk+1 + eνtk/2qk

+
ν2
2 −2
ν
2

eνtk+1/2pk+1 + eνtk/2pk

.
(5.11)
This method is easily extended to more general ODEs such as

˙p + β′(t)p + V (q, t) = 0,
˙q −G(p, t) = 0.
(5.12)

634
15. Structure Preserving Schemes for Birkhoff Systems
Remark 5.1. The derived schemes (5.7), (5.8), and (5.9) are K(z, t)-symplectic, i.e.,
for τ > 0 and k ≤0 they satisfy the Birkhofﬁan condition
eνtk+1 d qk+1 ∧d pk+1 = eνtk d qk ∧d pk.
15.6 Numerical Experiments
In this section, we present numerical results for the linear damped oscillator (5.1),
resp., (5.2) using the derived K(z, t)-symplectic schemes (5.7), (5.8), and (5.9) of
order one, two, and four, respectively. Further, we use Euler’s midpoint scheme (5.4),
which is not K(z, t)-symplectic but shows convenient numerical results[MW01], and
further Euler’s explicit scheme for comparison.
In the presented ﬁgures, the initial values are always chosen as q(0) = 1,
p(0) = ˙q(0) = −1, and the time interval is from 0 to 25. There are only small
differences in the behavior of the different schemes choosing other initial values. The
actual error, err = |approximate solution - true solution|, is computed with step size
τ = 0.2. Using different step sizes, the schemes always show the same quality, which
is emphasized by representing the results in a double logarithmic scale using step sizes
τ = 0.01, 0.02, 0.05, 0.1, 0.2, 0.5. The orbits are computed with step size τ = 0.05.
The ﬁrst comparison is given between scheme (5.7) and Euler’s explicit scheme
both are of order one. For smaller ν, i.e., 0 ≤ν ≤1.3 scheme (5.7) is better, and for
ν > 1.3 Euler’s explicit scheme is better. The second comparison is given between
scheme (5.8) and Euler’s midpoint scheme (5.4) both are of order two. For 0 ≤ν ≤
0.5 both schemes show the same behavior, for 0.5 < ν < 2.8 scheme (5.8) is better,
where the most advantage is around ν = 2, and for 2.8 ≤ν Euler’s midpoint scheme
behaves better. The third comparison is given between scheme (5.9) of order four and
scheme (5.8) of order two. Both schemes have the same structure preserving property,
and therefore the higher order scheme (5.9) shows a clear superiority over the two-
order scheme. These differences between the discussed schemes are illustrated by the
error curves (Figs. 6.1 and 6.4).
For the energy function (5.3), the comparisons of the energy error H, between the
different schemes are also done in double logarithmic scales (Figs. 6.5 and 6.8). The
result shows that the dominance is not clear between scheme (5.7) and Euler’s explicit
scheme while scheme (5.8) is always better than Euler’s midpoint scheme for growing
ν, even for ν ≥2.8. Scheme (5.9) keeps its superiority in the comparisons.
The comparisons also show that it is possible for different schemes obtained from
different transformation α, that different quantities are preserved. This point is proved
to be true in the generating function method for Hamiltonian systems (see Feng et
al[FW91b,FW91a]). The extension to application in Birkhofﬁan systems will also be stud-
ied in a prospective paper.

15.6 Numerical Experiments
635
10
−2
10
−1
10
0
10
−10
10
−8
10
−6
10
−4
10
−2
10
0
tau
max−err
q’’ + 0.6 * q’ + q = 0    ( tau = 0.01, 0.02, 0.05, 0.1, 0.2, 0.5 )
expl Euler
midpoint (5.4)
scheme (5.7)
scheme (5.8)
scheme (5.9)
Fig. 6.1.
Error comparison between the different schemes for ν = 0.6
10
−2
10
−1
10
0
10
−10
10
−8
10
−6
10
−4
10
−2
10
0
tau
max−err
q’’ + 1.3 * q’ + q = 0    ( tau = 0.01, 0.02, 0.05, 0.1, 0.2, 0.5 )
expl Euler
midpoint (5.4)
scheme (5.7)
scheme (5.8)
scheme (5.9)
Fig. 6.2.
Error comparison between the different schemes for ν = 1.3

636
15. Structure Preserving Schemes for Birkhoff Systems
10
−2
10
−1
10
0
10
−14
10
−12
10
−10
10
−8
10
−6
10
−4
10
−2
10
0
tau
max−err
q’’ + 1.9 * q’ + q = 0    ( tau = 0.01, 0.02, 0.05, 0.1, 0.2, 0.5 )
expl Euler
midpoint (5.4)
scheme (5.7)
scheme (5.8)
scheme (5.9)
Fig. 6.3.
Error comparison between the different schemes for ν = 1.9
10
−2
10
−1
10
0
10
−10
10
−8
10
−6
10
−4
10
−2
10
0
tau
max−err
q’’ + 2.8 * q’ + q = 0    ( tau = 0.01, 0.02, 0.05, 0.1, 0.2, 0.5 )
expl Euler
midpoint (5.4)
scheme (5.7)
scheme (5.8)
scheme (5.9)
Fig. 6.4.
Error comparison between the different schemes for ν = 2.8

15.6 Numerical Experiments
637
10
−2
10
−1
10
0
10
−10
10
−8
10
−6
10
−4
10
−2
10
0
tau
max−err−H
q’’ + 2.8 * q’ + q = 0    ( tau = 0.01, 0.02, 0.05, 0.1, 0.2, 0.5 )
expl Euler
midpoint (5.4)
scheme (5.7)
scheme (5.8)
scheme (5.9)
Fig. 6.5.
Energy error comparison between the different schemes for ν = 0.6
10
−2
10
−1
10
0
10
−12
10
−10
10
−8
10
−6
10
−4
10
−2
10
0
tau
max−err−H
q’’ + 1.3 * q’ + q = 0    ( tau = 0.01, 0.02, 0.05, 0.1, 0.2, 0.5 )
expl Euler
midpoint (5.4)
scheme (5.7)
scheme (5.8)
scheme (5.9)
Fig. 6.6.
Energy error comparison between the different schemes for ν = 1.3

638
15. Structure Preserving Schemes for Birkhoff Systems
10
−2
10
−1
10
0
10
−14
10
−12
10
−10
10
−8
10
−6
10
−4
10
−2
10
0
tau
max−err−H
q’’ + 1.9 * q’ + q = 0    ( tau = 0.01, 0.02, 0.05, 0.1, 0.2, 0.5 )
expl Euler
midpoint (5.4)
scheme (5.7)
scheme (5.8)
scheme (5.9)
Fig. 6.7.
Energy error comparison between the different schemes for ν = 1.9
10
−2
10
−1
10
0
10
−10
10
−8
10
−6
10
−4
10
−2
10
0
tau
max−err−H
q’’ + 2.8 * q’ + q = 0    ( tau = 0.01, 0.02, 0.05, 0.1, 0.2, 0.5 )
expl Euler
midpoint (5.4)
scheme (5.7)
scheme (5.8)
scheme (5.9)
Fig. 6.8.
Energy error comparison between the different schemes for ν = 2.8

Bibliography
[AH75] R.W. Atherton and G.M. Homsy: On the existence and formulation of variational prin-
ciples for nonlinear differential equations. Studies in Applied Mathematics, LIV(1):1531–
1551, (1975).
[Arn89] V. I. Arnold: Mathematical Methods of Classical Mechanics. Springer-Verlag, GTM
60, Berlin Heidelberg, Second edition, (1989).
[FQ87] K. Feng and M.Z. Qin: The symplectic methods for the computation of Hamiltonian
equations. In Y. L. Zhu and B. Y. Guo, editors, Numerical Methods for Partial Differential
Equations, Lecture Notes in Mathematics 1297, pages 1–37. Springer, Berlin, (1987).
[FW91a] K. Feng and D.L. Wang: A Note on conservation laws of symplectic difference
schemes for Hamiltonian systems. J. Comput. Math., 9(3):229–237, (1991).
[FW91b] K. Feng and D.L. Wang: Symplectic difference schemes for Hamiltonian systems in
general symplectic structure. J. Comput. Math., 9(1):86–96, (1991).
[GLSM01] Y.X. Guo, S.K. Luo, M. Shang, and F.X. Mei: Birkhofﬁan formulations of non-
holonomic constrained systems. Reports on Mathematical Physics, 47:313–322, (2001).
[HLW02] E. Hairer, Ch. Lubich, and G. Wanner: Geometric Numerical Integration. Num-
ber 31 in Springer Series in Computational Mathematics. Springer-Verlag, Berlin, (2002).
[MP91] E. Massa and E. Pagani: Classical dynamics of non-holonomic systems : a geomet-
ric approach. Annales de l’institut Henri Poincar (A) Physique thorique, 55(1):511–544,
(1991).
[MR99] J. E. Marsden and T. S. Ratiu: Introduction to Mechanics and Symmetry. Number 17
in Texts in Applied Mathematics. Springer-Verlag, Berlin, second edition, (1999).
[MW01] J. E. Marsden and M. West: Discrete mechanics and variational integrators. Acta
Numerica, 10:357–514, (2001).
[QZ92] M. Z. Qin and W. J. Zhu: Construction of higher order symplectic schemes by com-
position. Computing, 47:309–321, (1992).
[San83a] R.M. Santilli; Foundations of Theoretical Mechanics I. Springer-Verlag, New York,
Second edition, (1983).
[San83b] R.M. Santilli: Foundations of Theoretical Mechanics II. Springer-Verlag, New York,
Second edition, (1983).
[SQ03] H. L. Su and M. Z. Qin: Symplectic schemes for Birkhofﬁan system. Technical Report
arXiv: math-ph/0301001, (2003).
[SSC94] J. M. Sanz-Serna and M. P. Calvo: Numerical Hamiltonian Problems. AMMC 7.
Chapman & Hall, London, (1994).
[SSQS07] H. L. Su, Y.J. Sun, M. Z. Qin, and R. Scherer: Symplectic schemes for Birkhofﬁan
system. Inter J of Pure and Applied Math, 40(3):341–366, (2007).
[SVC95] W. Sarlet, A. Vandecasteele, and F. Cantrijn: Derivations of forms along a map:
The framework for time-dependent second-order equations. Diff. Geom. Appl., 5:171–203,
(1995).
[Yos90] H. Yoshida: Construction of higher order symplectic integrators. Physics Letters A,
150:262–268, (1990).

Chapter 16.
Multisymplectic and Variational Integrators
Recently, multisymplectic discretizations have been drawing much attention and,
therefore, have become the vigorous component of the structure-preserving algo-
rithms. In this chapter, we systematically develop what our research group has achieved
in the ﬁeld of multisymplectic discretizations. Some very interesting new issues aris-
ing in this ﬁeld are also given. Multisymplectic and variational integrators are stud-
ied from a comparative point of view. The implementation issues of multisymplectic
integrators are discussed, and composition methods to construct higher order mul-
tisymplectic integrators are presented. The equivalence of variational integrators to
multisymplectic integrators is proved. Several generalizations are also described.
16.1 Introduction
The introduction of symplectic integrators is a milestone in the development of numer-
ical analysis[Fen85]. It has led to the establishment of structure-preserving algorithms, a
very promising subject. Due to its high accuracy, good stability and, in particular, the
capability for long-term computation, the structure-preserving algorithms have proved
to be very powerful in numerical simulations. The applications of structure-preserving
algorithms can be found on diverse branches of physics, such as celestial mechanics,
quantum mechanics, ﬂuid dynamics, geophysics[LQHD07,MPSM01,WHT96], etc.
Symplectic algorithms for ﬁnite dimensional Hamiltonian systems have been well
established. They not only bring new insights into existing methods but also lead to
many powerful new numerical methods. The structure-preserving algorithms for in-
ﬁnite dimensional Hamiltonian systems are comparatively less explored. Symplec-
tic integrators for inﬁnite dimensional Hamiltonian systems were also considered
[Qin90,LQ88,Qin87,Qin97a]. The basic idea is, ﬁrst to discretize the space variables appro-
priately so that the resulting semi-discrete system is a Hamiltonian system in time;
and second, to apply symplectic methods to this semi-discrete system. The symplectic
integrator obtained in this way preserves a symplectic form which is a sum over the
discrete space variables. In spite of its success, a problem remains: the change of the
symplectic structure over the spatial domain is not reﬂected in such methods.
This problem was solved by introducing the concept of multisymplectic integra-
tors (Bridges and Reich[BR01a,BR06]). In general, an inﬁnite dimensional Hamiltonian
system can be reformulated as a multisymplectic Hamiltonian system in which as-
sociated to every time and space direction, there exists a symplectic structure and a

642
16. Multisymplectic and Variational Integrators
multisymplectic conservation law is satisﬁed. The multisymplectic conservation law is
completely local and reﬂects the change of the symplecticity over the space domain. A
multisymplectic integrator is a numerical scheme for the multisymplectic Hamiltonian
system which preserves a discrete multisymplectic conservation law, characterizing
the spatial change of the discrete symplectic structure. The multisymplectic integrator
is the direct generalization of the symplectic integrator and has good performance in
conserving local conservation laws. A disadvantage of the multisymplectic integrator
is the introduction of many new variables which usually are not needed in numerical
experiments. To solve this problem, we can eliminate the additional variables from
some multisymplectic integrators and obtain a series of new schemes for the equa-
tions considered. On the construction of multisymplectic integrators, it was proved
that using symplectic Runge–Kutta integrators in both directions lead to multisym-
plectic integrators[Rei00]. In this chapter, another approach, namely the composition
method will be presented.
The multisymplectic integrator is based on the Hamiltonian formalism. In the La-
grangian formalism, a geometric-variational approach to continuous and discrete me-
chanics and ﬁeld theories is known by Marsden, Patrik, and Shkoller[MPS98]. The mul-
tisymplectic form is obtained directly from the variational principle, staying entirely
on the Lagrangian side, but the local energy and momentum conservation laws are not
particularly addressed. By disretizing the Lagrangian and using a discrete variational
principle, variational integrators are obtained, which satisfy a discrete multisymplectic
form[MPS98]. Taking the sine-Gordon equation and the nonlinear Schr¨odinger equation
as examples, we will show that some variational integrators are equivalent to multi-
symplectic integrators.
In addition to the standard multisymplectic and variational integrators, we have
more ambitious goal of presenting some generalizations, including multisymplec-
tic Fourier pseudospectral methods on real space, nonconservative multisymplectic
Hamiltonian systems, constructions of multisymplectic integrators for modiﬁed equa-
tions and multisymplectic Birkhofﬁan systems[SQ01,SQWR08,SQS07].
This chapter is organized as follows. In the next Section 16.2, the basic theory
of multisymplectic geometry and multisymplectic Hamiltonian systems is presented.
Section 16.3 is devoted to developing multisymplectic integrators. In Section 16.4, the
variational integrators are discussed. In Section 16.5, some generalizations are given.
16.2 Multisymplectic Geometry and Multisymplectic
Hamiltonian Systems
In this section, the basic theory needed for multisymplectic and variational integra-
tors is discussed. The basic theory includes multisymplectic geometry and multi-
symplectic Hamiltonian system. We will present the theory from the perspective of
the total variation[Lee82,Lee87], always named Lee variational integrator (see Chapter
14)[Che02,CGW03].

16.2 Multisymplectic Geometry and Multisymplectic Hamiltonian Systems
643
1.
Multisymplectic geometry Exclusively, local coordinates are used and the notion
of prolongation spaces instead of jet bundles[Olv86,Che05c] is employed. The covariant
conﬁguration space is denoted by X × U and X represents the space of independent
variables with coordinates xμ (μ = 1, 2, · · · , n, 0), and U the space of dependent
variables with coordinates uA (A = 1, 2, · · · , N). The ﬁrst-order prolongation of X ×
U is deﬁned to be
U (1) = X × U × U1,
(2.1)
where U1 represents the space consisting of ﬁrst-order partial derivatives of uA with
respect to xμ.
Let φ : X →U be a smooth function, then its ﬁrst prolongation is denoted by
pr1φ = (xμ, φA, φA
μ ).
A Lagrangian density, L is deﬁned as follows:
L : U (1) −→Λn+1(X),
L(pr1φ) = L(xμ, φA, φA
μ ) dn+1 x,
(2.2)
where Λn+1(X) is the space of n + 1 forms over X.
Corresponding to the Lagrangian density (2.2), the action functional is deﬁned by
S(φ) =
-
M
L(xμ, φA, φA
μ ) dn+1 x,
M is an open set in X.
(2.3)
Let V be a vector ﬁeld on X × U with the form
V = ξμ(x)
∂
∂xμ + αA(x, u)
∂
∂uA ,
where x = (x1, · · · , xn, x0), u = (u1, · · · , uN) and we use Einstein summation
convention here.
The ﬂow exp(λV ) of the vector ﬁeld V is a one-parameter transformation group of
X × U and transforms a map φ : M →U to a family of maps ˜φ : ˜
M →U depending
on the parameter λ. Now, we calculate the variation of the action functional (2.3). For
simplicity , let n = 1, N = 1 and x1 = x, x0 = t, u1 = u, α1 = α, then it follows
that
δ S = d
d λ

λ=0S(˜φ) = d
d λ

λ=0
-
˜
M
L(˜x, ˜t, ˜φ, ˜φ˜x, ˜φ˜t) d ˜x ∧d ˜t = A + B,
where
A =
-
M
 ∂L
∂t + Dt
 ∂L
∂φt φt −L

+ Dx
 ∂L
∂φx φt

ξ0
+
∂L
∂x + Dx
 ∂L
∂φx φx −L

+ Dt
 ∂L
∂φt φx

ξ1
+
∂L
∂φ −Dx
∂L
∂φx −Dt
∂L
∂φt

α
!
d x ∧d t,
(2.4)

644
16. Multisymplectic and Variational Integrators
and
B =
-
∂M
  ∂L
∂φt φt −L

d x −∂L
∂φx φt d t

ξ0
+

L −∂L
∂φx φx

d t + ∂L
∂φt φxd x

ξ1
+
 ∂L
∂φx d t −∂L
∂φt d x

α
!
.
(2.5)
If ξ1(x), ξ0(x), and α(x, t, φ(x, t)) have compact support on M, then B = 0. In this
case, with the requirement of δS = 0 and from (2.4), the variation ξ0 yields the local
energy evolution equation
∂L
∂t + Dt
 ∂L
∂φt φt −L

+ Dx
 ∂L
∂φx φt

= 0,
(2.6)
and the variation ξ1 the local momentum evolution equation
∂L
∂x + Dx
 ∂L
∂φx φx −L

+ Dt
 ∂L
∂φt φx

= 0.
(2.7)
For a conservative L, i.e., the one that does not depend on x, t explicitly, (2.6) and
(2.7) become the local energy conservation law and the local momentum conservation
law respectively.
The variation α yields the Euler–Lagrange equation
∂L
∂φ −Dx
∂L
∂φx
−Dt
∂L
∂φt
= 0.
(2.8)
If the condition that ξ1(x, t), ξ0(x, t), α(x, t, φ(x, t)) have compact support on M is
not imposed, then from the boundary integral B, we can deﬁne the Cartan form
ΘL = ∂L
∂φx
d φ ∧d t −∂L
∂φt d φ ∧d x +

L −∂L
∂φx φx −∂L
∂φt φt

d x ∧d t,
(2.9)
which satisﬁes using the interior product
and the pull-back mapping ()∗,
B =
-
∂M

pr1φ
∗
pr1V
ΘL

.
(2.10)
The multisymplectic form is deﬁned to be ΩL = d ΘL.
Theorem 2.1. [MPS98,GAR73] Suppose φ is the solution of (2.8), and let ηλ and ζλ be
two one-parameter symmetry groups of Equation (2.8), and V1 and V2 be the corre-
sponding inﬁnitesimal symmetries, then we have the multisymplectic form formula
-
∂M

pr1φ
∗
pr1V1
pr1V2
ΩL

= 0.
(2.11)

16.2 Multisymplectic Geometry and Multisymplectic Hamiltonian Systems
645
2.
Multisymplectic Hamiltonian systems
A large class of partial differential equations can be represented as[BR06,Bri97]
Mzt + Kzx = ▽zS(z),
(2.12)
where z ∈Rn, M and K are antisymmetric matrices in Rn×n, n ≥3 and S : Rn →
R is a smooth function. Here for simplicity, we only consider one space dimension.
We call (2.12) a multisymplectic Hamiltonian system, since it possesses a multi-
symplectic conservation law
Dtω + Dxκ = 0,
(2.13)
where Dt = d
d t, Dx =
d
d x and ω and κ are the presymplectic form
ω = 1
2 d z ∧M d z,
κ = 1
2 d z ∧K d z,
which are associated to the time direction and the space direction, respectively.
The system (2.12) satisﬁes a local energy conservation law
DtE + DxF = 0,
(2.14)
with energy density
E = S(z) −1
2zTKzx
and energy ﬂux
F = 1
2zTKzt.
The system (2.12) also has a local momentum conservation law
DtI + DxG = 0
(2.15)
with momentum density
I = 1
2zTMzx
and momentum ﬂux
G = S(z) −1
2zTMzt.
The multisymplectic Hamiltonian system can be obtained from the Lagrangian
density and the covariant Legendre transform, or Legendre–Hodge transformation[Bri06].
The relationship between the Lagrangian and the Hamiltonian formalisms is ex-
plained in the following diagram, where in each line the corresponding equations are
given[Che05c,Che02,LQ02].

646
16. Multisymplectic and Variational Integrators
L = L(φ, φx, φt) ⇐⇒H = L −∂L
∂φx φx −∂L
∂φt φt,
∂L
∂φ −Dx
∂L
∂φx −Dt
∂L
∂φt = 0 ⇐⇒Mzt + Kzx = ▽zS(z),
-
∂M
(pr1φ)∗(pr1V1
pr1V2
ΩL) = 0 ⇐⇒Dtω + Dxκ = 0,
Dt
%
∂L
∂φt φt −L
&
+ Dx
%
∂L
∂φx φt
&
= 0 ⇐⇒DtE + DxF = 0,
Dx
%
∂L
∂φx φx −L
&
+ Dt
%
∂L
∂φt φx
&
= 0 ⇐⇒DtI + DxG = 0.
16.3 Multisymplectic Integrators and Composition
Methods
The concept of the multisymplectic integrators for the system (2.12) was introduced
by Bridges and Reich[BR01a]. A multisymplectic integrator is a numerical scheme for
(2.12) which preserves a discrete multisymplectic conservation law. The multisym-
plectic integrator is the direct generalization of the symplectic integrator and has good
performance in maintaining local conservation laws. Using symplectic Runge–Kutta
integrators in both directions leads to multisymplectic integrators[Rei00].
A popular multisymplectic integrator is the multisymplectic Preissman integrator
which is obtained by using the midpoint method in both directions. Discretizing (2.12)
by the midpoint method in both directions with step-size Δt and Δτ yields
M
zj+1
i+ 1
2 −zj
i+ 1
2
Δ t
+ K z
j+ 1
2
i+1 −z
j+ 1
2
i
Δ x
= ∇z S

z
j+ 1
2
i+ 1
2

,
(3.1)
where Δ t and Δ x are the time step size and space step size, respectively, and
zj
i ≈z(iΔz, jΔt),
zj+1
i+ 1
2 = 1
2

zj+1
i
+ zj+1
i+1

,
z
j+ 1
2
i+ 1
2 = 1
4

zj
i + zj
i+1 + zj+1
i
+ zj+1
i+1

,
etc.
The scheme (3.1) satisﬁes the discrete multisymplectic conservation law
ωj+1
i+ 1
2 −ωj
i+ 1
2
Δ t
+ κ
j+ 1
2
i+1 −κ
j+ 1
2
i
Δ x
= 0,
(3.2)
which can be proved by direct calculations.
Example 3.1. First, consider the sine-Gordon equation[Che06b,WM01]
utt −uxx + sin u = 0.
(3.3)

16.3 Multisymplectic Integrators and Composition Methods
647
Introducing the new variables v = ut and w = ux, Equation (3.3) is equivalent to the
system
−vt + wx = sin u,
ut = v,
−ux = −w,
(3.4)
which can be represented as
M1zt + K1zx = ∇z S1(z),
(3.5)
where
z = (u, v, w)T,
S1(z) = 1
2(v2 −w2) −cos (u)
and
M1 =
⎛
⎜
⎝
0
−1
0
1
0
0
0
0
0
⎞
⎟
⎠,
K1 =
⎛
⎜
⎝
0
0
1
0
0
0
−1
0
0
⎞
⎟
⎠.
Applying the multisymplectic integrator (3.1) to (3.3) yields
−
vj+1
i+ 1
2 −vj
i+ 1
2
Δ t
+ w
j+ 1
2
i+1 −w
j+ 1
2
i
Δ x
= sin u
j+ 1
2
i+ 1
2 ,
uj+1
i+ 1
2 −uj
i+ 1
2
Δ t
= v
j+ 1
2
i+ 1
2 ,
−u
j+ 1
2
i+1 −u
j+ 1
2
i
Δ x
= −w
j+ 1
2
i+ 1
2 .
(3.6)
Eliminating v and w from (3.6), a nine-point integrator for u is derived
uj+1
(i) −2uj
(i) + uj−1
(i)
Δ t2
−u(j)
i+1 −2u(j)
i
+ u(j)
i−1
Δ x2
+ sin (¯uj
i) = 0,
(3.7)
where
ul
(i) = ul
i−1 + 2ul
i + ul
i+1
4
,
l = j −1, j, j + 1,
u(j)
m = uj−1
m
+2uj
m+uj+1
m
4
,
m = i −1, i, i + 1,
sin(¯uj
i) = 1
4

sin (¯uj
i) + sin (¯uj
i−1) + sin (¯ui−1j−1) + sin (¯uij−1)

,
¯uj
i = 1
4

uj
i + uj
i+1 + uj+1
i+1 + uj+1
i

,
¯uj
i−1 = 1
4

uj
i−1 + uj
i + uj+1
i
+ uj+1
i−1

,
¯uj−1
i−1 = 1
4

uj−1
i−1 + uj−1
i
+ uj
i + uj
i−1

,
¯uj−1
i
= 1
4

uj−1
i
+ uj−1
i+1 + uj
i+1 + uj
i

.
Second, consider the nonlinear Schr¨odinger equation, written in the form
iψt + ψxx + V ′ 
|ψ|2
ψ = 0.
(3.8)

648
16. Multisymplectic and Variational Integrators
Using ψ = p + iq and introducing a pair of conjugate momenta v = px, w = qx,
Equation (3.8) can be represented[Che06b,Che05b,CQ02,CQT02,SHQ06,SMM04,SQL06,Che04a] as a
multisymplectic Hamiltonian system
M2zt + K2zx = ▽zS2(z),
(3.9)
where
z = (p, q, v, w)T,
S2(z) = 1
2

v2 + w2 + V (p2 + q2)

and
M2 =
⎛
⎜
⎜
⎜
⎜
⎝
0
1
0
0
−1
0
0
0
0
0
0
0
0
0
0
0
⎞
⎟
⎟
⎟
⎟
⎠
,
K2 =
⎛
⎜
⎜
⎜
⎜
⎝
0
0
−1
0
0
0
0
−1
1
0
0
0
0
1
0
0
⎞
⎟
⎟
⎟
⎟
⎠
.
From the multisymplectic Preissman integrator (3.1), we obtain a six-point integrator
for (3.8)
i
ψj+1
[i]
−ψj
[i]
Δt
+ ψ
j+ 1
2
i+1 −2ψ
j+ 1
2
i
+ ψ
j+ 1
2
i−1
Δx2
+ 1
2Gi,j = 0,
(3.10)
where
ψr
[i] = 1
4

ψi−1,r + 2ψi,r + ψi+1,r

,
r = j, j + 1,
Gi,j = V ′ψ
j+ 1
2
i−1
2

2
ψ
j+ 1
2
i−1
2 + V ′ψ
j+ 1
2
i+ 1
2

2
ψ
j+ 1
2
i+ 1
2 .
Third, consider the KdV equation (Korteweg & de Vries)
ut + 3(u2)x + uxxx = 0.
(3.11)
Introducing the new variables φ, v and w, Equation (3.11) can be represented as
M3zt + K3zx = ▽zS3(z),
(3.12)
where
z = (φ, u, v, w)T,
S3(z) = 1
2v2 + u2 −uw
and
M3 =
⎛
⎜
⎜
⎜
⎜
⎜
⎜
⎝
0
1
2
0
0
−1
2
0
0
0
0
0
0
0
0
0
0
0
⎞
⎟
⎟
⎟
⎟
⎟
⎟
⎠
,
K3 =
⎛
⎜
⎜
⎜
⎜
⎝
0
0
0
1
0
0
−1
0
0
1
0
0
−1
0
0
0
⎞
⎟
⎟
⎟
⎟
⎠
.
From the multisymplectic Preissman integrator (3.1), we obtain an eight-point inte-
grator

16.3 Multisymplectic Integrators and Composition Methods
649
uj+1
(i) −uj
(i)
Δ t
+ 3 ¯u2
i+1 −¯u2
i−1
2Δ x
+ u
j+ 1
2
i+1 −3u
j+ 1
2
i
+ 3u
j+ 1
2
i−1 −u
j+ 1
2
i−2
Δ x3
= 0,
(3.13)
where
ul
(i) = ul
i−2 + 3ul
i−1 + 3ul
i + ul
i+1
8
,
l = j, j + 1,
¯u2
m = 1
2

(u
j+ 1
2
m+1)2 + (u
j+ 1
2
m
)2
,
m = i −1, i + 1.
A twelve-point integrator for the KdV equation is known[ZQ00,AM04,MM05], which can
be reduced to the eight-point integrator (3.13). Numerical experiments with the in-
tegrators mentioned above are given in[WM01,CQT02,ZQ00]. For other soliton equations
such as the ZK equation and the KP equation, similar results are obtained[Che03,LQ02].
The coupled Klein–Gordon–Schr¨odinger equation[KLX06]
i ψt + 1
2ψxx + ψϕ = 0,
ϕtt −ϕxx + ϕ −|ψ|2 = 0,
i = √−1
(3.14)
is a classical model which describes interaction between conservative complex neu-
tron ﬁeld and neutral meson Yukawa in quantum ﬁeld theory.
KGS equation with initial boundary value conditions
ψ(0, x) = ψ0(x),
ϕ(0, x) = ϕ0(x),
ϕt(0, x) = ϕ1(x),
(3.15)
ψ(t, xL) = ψ(t, xR) = ϕ(t, xL) = ϕ(t, xR) = 0,
(3.16)
where ψ0(x), ϕ0(x) and ϕ1(x) are known functions. The problems (3.14), (3.15) and
(3.16) has conservative quantity
∥ψ∥2 =
- xR
xL
ψ ¯ψ d x = 1.
Setting ψ = p + i q, ψx = px + i qx = f + i g,
pt = v,
ϕx = w,
z = (p, q, f, ϕ, v, w)T.
The multisymplectic formation of KGS system (3.14) is

650
16. Multisymplectic and Variational Integrators
⎧
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎨
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎪
⎩
qt + 1
2fx = −ϕp,
pt + 1
2gx = −ϕq,
−1
2px = 1
2f,
−1
2qx = −1
2g,
−1
2vt + 1
2wx = 1
2ϕ −1
2(p2 + q2),
1
2ϕt = 1
2v,
−1
2ϕx = −1
2w.
(3.17)
System (3.17) can be written in standard Bridge form
M ∂z
∂t + K ∂z
∂x = ∇S,
(3.18)
where matrices M and K (3.18) are
M = 1
2
⎛
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎝
0
−2
0
0
0
0
0
2
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
−1
0
0
0
0
0
1
0
0
0
0
0
0
0
0
0
⎞
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎠
,
K = 1
2
⎛
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎝
0
0
1
0
0
0
0
0
0
0
1
0
0
0
−1
0
0
0
0
0
0
0
−1
0
0
0
0
0
0
0
0
0
0
0
1
0
0
0
0
0
0
0
0
0
0
0
−1
0
0
⎞
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎠
respectively, and the Hamiltonian function is
S(z) = −1
2ϕ(p2 + q2) + 1
4(ϕ2 + v2 −w2 −f 2 −g2).
For the three local conservation laws corresponding to (3.17), (3.18), we have
ω(z) = −2 d p ∧d q −d ϕ ∧d v,
κ(z) = d p ∧d f + d q ∧d q + d ϕ ∧d w,
E(z) = −1
2ϕ(p2 + q2) + 1
4(ϕ2 + v2 −pfx −qgx −ϕwx),
F(z) = 1
4(pft + qgt + ϕwt −fpt −gqt −rw),
I(z) = −1
2ϕ(p2 + q2) + 1
4(ϕ2 −w2 −f 2 −g2 + ϕvt) + 1
2(pqt −qpt),
G(z) = 1
4(−2pg + 2qf −qvx + vw).
(3.19)

16.3 Multisymplectic Integrators and Composition Methods
651
Recently, many math physical equations can be solved by Multisymlectic methods, such
as Gross–Pitaevskii equation[TM03,TMZM08], Maxwell’s equations[SQS07,SQ03,CYWB06,STMM07],
Camassa–Holm equation[Dah07], Kadomtsev–Petviashvili equation[JYJ06], Seismic
wave equation[Che04b,Che04a,Che07a,Che07c,Che07b], Dirac equation[HL04], and nonlinear
“good” Boussinesq equation[HZQ03,Che05a], etc.
Now, let us discuss the composition method for constructing high order multisym-
plectic integrators[Che05c,CQ03]. First, recall the deﬁnition of a composition method for
ODEs[Yos90,QZ92,Suz92]: Suppose there are n integrators with corresponding operators
s1(τ), s2(τ), · · ·, sn(τ) of corresponding order p1, p2, · · · , pn, respectively, having
maximal order μ =maxi(pi). If there exists constants c1, c2, · · · , cn such that the or-
der of the integrator whose operator is the composition s1(c1τ)s2(c2τ) · · · sn(cnτ)
is m > μ, then the new integrator is called composition integrator of the original n
integrators. This construction of higher order integrators from the lower order ones is
called the composition method.
While constructing higher order integrators, the main task is to determine con-
stants c1, c2, · · ·, cn such that the scheme with the corresponding operator
Gm(τ) = s1(c1τ)s2(c2τ) · · · sn(cnτ)
has order m > μ. Now, we will present the basic formula for determining the constants
ci (i = 1, · · · , n). For this purpose, we introduce the symmetrization operator S
S(xpzq) =
p ! q !
(p + q) !

Pm
Pm(xpzq),
where x, z are arbitrary noncommutable operators, Pm denotes the summation of all
the operators obtained in all possible ways of permutation[Suz92].
We also introduce a time-ordering operator P:
P(xixj) =
 xixj,
if i < j;
xjxi,
if j < i,
where xi, xj are noncommutable operators[Suz92].
Set Gm(τ) = s1(c1τ) · · · sn(cnτ). The condition on which Gm has order m reads
PS(xn1
1 xn2
2 xn3
3 · · ·) = 0,
n

i=1
ci = 1,
(3.20)
where n1 + 2n2 + 3n3 + · · · ≤m, excluding n2 = n3 = · · · = 0.
Given a multisymplectic integrator for (2.12) with accuracy of order O(τ p + τ q),
M

s(τ)zi,j

+ K

s(τ)zi,j

= ∇z (˜zi,j),
(3.21)
where s(τ) and s(τ) are discrete operators in t-direction and x-direction respectively,
and τ and τ are time step and space step respectively. ˜zi,j = fs,s(zi,j) is a function of
zi,j corresponding to the operators s(τ) and s(τ).

652
16. Multisymplectic and Variational Integrators
Suppose Gm(τ) is the composition operator of s(τ) with accuracy of order
O(τ m), and Gn(τ) is the composition operator of s(τ) with accuracy of order O(τ n),
then the multisymplectic integrator
M

Gm(τ)zi,j

+ K
 Gn(τ)zi,j

= ∇zS(˜zi,j)
(3.22)
has accuracy of order O

τ m + τ n
.
16.4 Variational Integrators
In this section, variational integrators are discussed. First, we present Veselov-type
dicretizations of ﬁrst-order multisymplectic ﬁeld theory developed in [MPS98]. For sim-
plicity, let n = 1, N = 1, X = (x, t), U = (u), and take X = (xi, tj) and U = (uij)
as the discrete versions of X and U. It is more suitable to use only the indices of the
grid and set X = (i, j).
A rectangle 2 of X is an ordered quadruple of the form
2 =

(i, j), (i + 1, j), (i + 1, j + 1), (i, j + 1)

.
(4.1)
The i −th component of 2 is the i −th vertex of the rectangle, denoted by 2i. A
point (i, j) ∈X is touched by a rectangle if it is a vertex of that rectangle. If M ⊆X,
then (i, j) is an interior point of M, if M contains all four rectangles that touch (i, j).
We denote M as the union of all rectangles touching interior points of M. A boundary
point of M is a point in M which is not an interior point. If M = M, we call M regular.
int M is the set of the interior points of M, and ∂M is the set of boundary points.
The discrete ﬁrst-order prolongation of X × U is deﬁned by
U(1) ≡(2; uij, ui+1j, ui+1j+1, uij+1),
and the ﬁrst order prolongation of the discrete map ϕ : X →U; ϕ(i, j) := ϕi,j by
pr1ϕ ≡(2; ϕij, ϕi+1j, ϕi+1j+1, ϕij+1).
(4.2)
Corresponding to a discrete Lagrangian L : U(1) →R, we deﬁne the discrete
functional
S(ϕ) =

2⊂M
L(pr1ϕ)ΔxΔt =

2⊂M
L(2, ϕij, ϕi+1j, ϕi+1j+1, ϕij+1)ΔxΔt, (4.3)
where Δx and Δt are the grid sizes in direction x and t, and M is a subset of X. In
this chapter, only an equally spaced grid is considered.
Now for brevity of notations, let M = [a, b] × [c, d] be a rectangular domain and
consider a uniform rectangular subdivision
a = x0 < x1 < · · · < xM−1 < xM = b, c = t0 < t1 < · · · < tN−1 < tN = d,
xi = a + i Δ x,
tj = c + j Δ t,
i = 0, 1, · · · , M, j = 0, 1, · · · , N,
MΔ x = b −a,
NΔ t = d −c.
(4.4)

16.4 Variational Integrators
653
For autonomous Lagrangian and uniform rectangular subdivisions, the discrete action
functional takes the form
S(ϕ) =
M−1

i=0
N−1

j=0
L

ϕij, ϕi+1j, ϕi+1j+1, ϕij+1

Δ x Δ t.
(4.5)
Using the discrete variational principle, we obtain the discrete Euler–Lagrange equa-
tion (variational integrator)
D1 Lij + D2 Li−1j + D3 Li−1j−1 + D4 Lij−1 = 0,
(4.6)
which satisﬁes the discrete multisymplectic form formula

2;2∩∂M̸=∅
⎛
⎝

l;2l∈∂M
(pr1 ϕ)∗
pr1 V1
pr1 V2
Ωl
L

⎞
⎠= 0,
(4.7)
where Ωl
L = d Θl
L (l = 1, · · · , 4) and V1 and V2 are solutions of the linearized
equation of (4.6). Now the discretizations of an autonomous Lagrangian L(ϕ, ϕx, ϕt)
is considered
L(ϕij, ϕi+1,j, ϕi+1,j+1, ϕi,j+1) = L

¯ϕij,
ϕi+1,j+ 1
2 −ϕij+ 1
2
Δ x
,
ϕi+ 1
2 j+1 −ϕi+ 1
2 j
Δ t

,
(4.8)
where
¯ϕij = 1
4 (ϕij + ϕi+1j + ϕi+1j+1 + ϕij+1) ,
ϕij+ 1
2 = 1
2 (ϕij + ϕij+1) ,
ϕi+ 1
2 j+1 = 1
2 (ϕij+1 + ϕi+1j+1)
etc. For the discrete Lagrangian, the discrete Euler–Lagrange equation (4.6) is a nine-
point variational integrator. The following results demonstrate the equivalence of vari-
ational integrators and multisymplectic integrators. Consider the sine-Gordon equa-
tion (3.3), then the Lagrangian is given by
L(u, ux, ut) = 1
2u2
x −1
2u2
t −cos (u).
(4.9)
The discrete Euler–Lagrange equation (4.6) corresponding to (4.9) is just the nine-
point integrator (3.7). Consider the nonlinear Schr¨odinger equation (3.8), then the
Lagrangian for (3.8) is given by
L(p, q, px, qx, pt, qt) = 1
2
@
p2
x + q2
x + pqt −qpt −V (p2 + q2)
A
.
(4.10)
The discrete Euler–Lagrange equation (4.6) corresponding to (4.10) reads

654
16. Multisymplectic and Variational Integrators
i
ψj+1
[i]
−ψj−1
[i]
2Δ t
+ ψ
j+ 1
2
i+1 + ψ
j−1
2
i+1 −2ψ
j+ 1
2
i
−2ψ
j−1
2
i
+ ψ
j+ 1
2
i−1 + ψ
j−1
2
i−1
Δ x2
+1
4Gi,j + 1
4Gi,j−1 = 0.
(4.11)
The integrator (4.11) is equivalent to the integrator (3.10), since replacing j by j −1
in (3.10) and adding the resulting equation to (3.10) leads to (4.11) (see [CQ03]).
16.5 Some Generalizations
In this section, some generalizations based on the multisymplectic geometry and mul-
tisymplectic Hamiltonian systems are presented.
1.
Multisymplectic Fourier pseudospectral methods
On Fourier space, multisymplectic Fourier pseudospectral methods were considered
in [BR01b]. Now, we discuss these methods on real space [CQ01a] and take the nonlinear
Schr¨odinger equation as an example. Applying the Fourier pseudospectral method to
the multisymplectic system (3.9) and using the notations
p = (p0, · · · , pN−1)T,
q = (q0, · · · .qN−1)T,
v = (v0, · · · , vN−1)T,
w = (w0, · · · .wN−1)T,
it follows
d qj
d t −(D1v)j = 2(p2
j + q2
j )pj,
−d pj
d t −(D1w)j = 2(p2
j + q2
j )qj,
(5.1)
(D1p)j = vj,
(D1q)j = wj,
where j = 0, 1, · · · , N −1 and D1 is the ﬁrst order spectral differentiation matrix.
The Fourier pseudospectral semidiscretization (5.1) has N semidiscrete multisym-
plectic conservation laws
d
d tωj +
N−1

k=0
(D1)j,kκjk = 0,
j = 0, 1, · · · , N −1,
(5.2)
where
ωj = 1
2(d zj ∧M d zj),
κjk = d zj ∧K d zk,
and zj = (pj, qj, vj, wj)T (j = 0, 1, · · · , N −1).
2.
Nonconservative multisymplectic Hamiltonian systems
Nonconservative multisymplectic Hamiltonian systems refer to those depending on

16.5 Some Generalizations
655
the independent variables explicitly. Such an example is the Schr¨odinger equation
with variable coefﬁcients[HLHKA06]. Another example is the three-dimensional scalar
seismic wave equation[Che04b,Che06a,Che07a,Che07b,Che04a]
∇2u −
1
c(x, y, z)2 utt = 0,
(5.3)
where ∇2u = uxx + uyy + uzz and c(x, y, z) is the wave velocity.
Introducing the new variables
v =
1
c(x, y, z)ut,
w = ux,
p = uy,
q = uz,
Equation (5.3) can be rewritten as
M(x, y, z)Zt + KZx + LZy + NZz = ∇ZS(Z),
(5.4)
where Z = (u, v, w, p, q)T, S(Z) = 1
2(v2 −w2 −p2 −q2) and
M(x, y, z) =
⎛
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎜
⎝
0
−
1
c(x, y, z)
0
0
0
1
c(x, y, z)
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
⎞
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎟
⎠
,
K =
⎛
⎜
⎜
⎜
⎜
⎜
⎜
⎝
0
0
1
0
0
0
0
0
0
0
−1
0
0
0
0
0
0
0
0
0
0
0
0
0
0
⎞
⎟
⎟
⎟
⎟
⎟
⎟
⎠
,
L =
⎛
⎜
⎜
⎜
⎜
⎜
⎜
⎝
0
0
0
1
0
0
0
0
0
0
0
0
0
0
0
−1
0
0
0
0
0
0
0
0
0
⎞
⎟
⎟
⎟
⎟
⎟
⎟
⎠
,
N =
⎛
⎜
⎜
⎜
⎜
⎜
⎜
⎝
0
0
0
0
1
0
0
0
0
0
0
0
0
0
0
0
0
0
0
0
−1
0
0
0
0
⎞
⎟
⎟
⎟
⎟
⎟
⎟
⎠
.
The corresponding four presymplectic forms associated to the time direction and three
space directions are respectively:
ω = 1
2 d Z ∧M(x, y, z) d Z,
κx = 1
2 d Z ∧K d Z,
κy = 1
2 d Z ∧L d Z,
κz = 1
2 d Z ∧N d Z.
(5.5)

656
16. Multisymplectic and Variational Integrators
Note that the time direction presymplectic form ω depends on the space variables
(x, y, z). We can also obtain the corresponding multisymplectic integrators[Che06a].
3.
Construction of multisymplectic integrators for modiﬁed equations
Consider the linear wave equation
utt = uxx.
(5.6)
Based on the two Hamiltonian formulations of (5.6) and using the hyperbolic func-
tions, various symplectic integrators were constructed in[QZ93]. By deriving the cor-
responding Lagrangians and their discrete counterparts, these symplectic integrators
were proved to be multisymplectic integrators for the modiﬁed versions of (5.6)
in[SQ00].
Let us present an example. Using hyperbolic function tanh(x), we can obtain a
symplectic integrator for (5.6) of accuracy O(Δ t2s + Δ x2m):
uj+1
i
−2uj
i +uj−1
i
= tanh

2s, Δ t
2

tanh

2s, Δ t
2 Δ (2m)

(uj+1
i
−2uj
i +uj−1
i
),
(5.7)
where
Δ (2m) = ∇+∇−
m−1

j=0
(−1)j βj
Δ x2∇+ ∇−
4
j
,
where
βj =
[(j !)222j]
[(2j + 1) ! (j + 1)]
and ∇+ and ∇−are forward and backward difference operators respectively.
For m = 2 and s = 2, the integrator (5.7) is a multisymplectic integrator of the
modiﬁed equation
utt = uxx −Δ t2
6 uxxxx −Δ t4
144 uxxxxxx.
(5.8)
For other hyperbolic functions, we can obtain similar results.
4.
Multisymplectic Birkhofﬁan systems
The multisymplectic Hamiltonian system can be generalized to include dissipation
terms. This generalization leads to the following multisymplectic Birkhofﬁan system
M(t, x, z)zt + K(t, x, z)zx = ∇z B(t, x, z) + ∂F
∂t + ∂G
∂x ,
(5.9)
where z = (z1, · · · , zn)T, F = (f1, · · · , fn)T, G = (g1, · · · , gn)T and M = (mij)
and K = (kij) are two antisymmetric matrices with entries respectively:
mij = ∂fj
∂zi −∂fi
∂zj ,
kij = ∂gj
∂zi −∂gi
∂zj .

16.5 Some Generalizations
657
The system (5.9) satisﬁes the following multisymplectic dissipation law:
d
d t
1
2d z ∧M d z

+ d
d x
1
2d z ∧K d z

= 0.
(5.10)
Let us present an example[SQ03,SQWR08]. Consider the equation describing the linear
damped string:
utt −uxx + u + αut + βux = 0.
(5.11)
Introducing new variables p = ut and q = ux, the Equation (5.11) can be cast into the
form of (5.9) with
M =
⎛
⎜
⎝
0
eαt−βx
0
−eαt−βx
0
0
0
0
0
⎞
⎟
⎠,
K =
⎛
⎜
⎝
0
0
−eαt−βx
0
0
0
eαt−βx
0
0
⎞
⎟
⎠,
and
z = (u, p, q)T,
B = −1
2eαt−βx(u2 + p2 −q2 + αup + βuq),
F =

−1
2eαt−βxp, 1
2eαt−βxu, 0
T
,
G =
1
2eαt−βxq, 0, −1
2eαt−βxT
.
Similarly, we can develop multisymplectic dissipation integrators for the system (5.9)
which preserve a discrete version of the multisymplectic dissipation law (5.10).
5.
Differential complex, methods and multisymplectic structure
Differential complexes have come to play an increasingly important role in numerical
analysis recently. In particular, discrete differential complexes are crucial in design-
ing stable ﬁnite element schemes[Arn02]. With regard to discrete differential forms, a
generic Hodge operator was introduced in[Hip02]. It was shown that most ﬁnite ele-
ment schemes emerge as its specializations. The connection between Veselov discrete
mechanics and ﬁnite element methods was ﬁrst suggested in[MPS98]. Symplectic and
multisymplectic structures in simple ﬁnite element methods are explored in[GjLK04]. It
will be of particular signiﬁcance to study the multisymplectic structure for the ﬁnite
element methods by using discrete differential complexes and in particular, discrete
Hodge operators[STMM07]. We will explore this issue in the future.

Bibliography
[AM04] U.M. Ascher and R.I. McLachlan: Multisymplectic box schemes and the Korteweg-de
Vries equation. Appl. Numer. Math., 39:55–269, (2004).
[Arn02] D.N. Arnold: Differential complexes and numerical stability. Plenary address deliv-
ered at ICM 2002. Beijing, China, (2002).
[BR01a] T. J. Bridges and S. Reich:
Multi-symplectic integrators: numerical schemes for
Hamiltonian PDEs that conserve symplecticity. Physics Letters A, 284:184–193, (2001).
[BR01b] T.J. Bridges and S. Reich: Multi-symplectic spectral discretizations for the Zakharov-
Kuznetsov and shallow water equations. Physica D, 152:491–504, (2001).
[BR06] T. J. Bridges and S. Reich: Numerical methods for Hamiltonian PDEs. J. Phys. A:
Math. Gen., 39:5287–5320, (2006).
[Bri97] T. J. Bridges: Multi-symplectic structures and wave propagation. Math. Proc. Cam.
Phil. Soc., 121:147–190, (1997).
[Bri06] T. J. Bridges: Canonical multisymplectic structure on the total exterior algebra bundle.
Proc. R. Soc. Lond. A, 462:1531–1551, (2006).
[CGW03] J. B. Chen, H.Y. Guo, and K. Wu: Total variation in Hamiltonian formalism and
symplectic-energy integrators. J. of Math. Phys., 44:1688–1702, (2003).
[Che02] J. B. Chen: Total variation in discrete multisymplectic ﬁeld theory and multisymplec-
tic energy momentum integrators. Letters in Mathematical Physics, 51:63–73, (2002).
[Che03] J. B. Chen: Multisymplectic geometry, local conservation laws and a multisymplectic
integrator for the Zakharov–Kuznetsov equation. Letters in Mathematical Physics, 63:115–
124, (2003).
[Che04a] J. B. Chen:
Multisymplectic geometry for the seismic wave equation.
Com-
mun.Theor. Phys., 41:561–566, (2004).
[Che04b] J. B. Chen: Multisymplectic Hamiltonian formulation for a one-way seismic wave
equation of high order approximation. Chin Phys. Lett., 21:37–39, (2004).
[Che05a] J. B. Chen: Multisymplectic geometry, local conservation laws and Fourier pseu-
dospectral discretization for the ”good” Boussinesq equation. Applied Mathematics and
Computation, 161:55–67, (2005).
[Che05b] J. B. Chen: A multisymplectic integrator for the periodic nonlinear Schr¨odinger
equation. Applied Mathematics and Computation, 170:1394–1417, (2005).
[Che05c] J. B. Chen: Variational formulation for multisymplectic Hamiltonian systems. Let-
ters in Mathematical Physics, 71:243–253, (2005).
[Che06a] J. B. Chen: A multisymplectic variational formulation for the nonlinear elastic wave
equation. Chin Phys. Lett., 23(2):320–323, (2006).
[Che06b] J. B. Chen: Symplectic and multisymplectic Fourier pseudospectral discretization
for the Klein-Gordon equation. Letters in Mathematical Physics, 75:293–305, (2006).
[Che07a] J. B. Chen:
High order time discretization in seismic modeling.
Geophysics,
72(5):SM115–SM122, (2007).
[Che07b] J. B. Chen: Modeling the scalar wave equation with Nystr¨on methods. Geophysics,
71(5):T158, (2007).
[Che07c] J. B. Chen: A multisymplectic pseudospectral method for seismic modeling. Applied
Mathematics and Computation, 186:1612–1616, (2007).

Bibliography
659
[CQ01a] J. B. Chen and M. Z. Qin: Multisymplectic fourier pseudospectral method for the
nonlinear Schr¨odinger equation. Electronic Transactions on Numerical Analysis, 12:193–
204, (2001).
[CQ02] J.-B. Chen and M. Z. Qin. A multisymplectic variational integrator for the nonlinear
Schr¨odinger equation. Numer. Meth. Part. Diff. Eq., 18:523–536, 2002.
[CQ03] J. B. Chen and M. Z. Qin: Multisymplectic composition integrators of high order. J.
Comput. Math., 21(5):647–656, (2003).
[CQT02] J. B. Chen, M. Z. Qin, and Y. F. Tang: Symplectic and multisymplectic methods for
the nonlinear Schr¨odinger equation. Computers Math. Applic., 43:1095–1106, (2002).
[CWQ09] J. Cai, Y. S. Wang, and Z. H. Qiao: Multisymplectic Preissman scheme for the
time-domain Maxwell’s equations. J. of Math. Phys., 50:033510, (2009).
[CYQ09] J. X. Cai, Y.S.Wang, and Z.H. Qiao: Multisymplectic Preissman scheme for the
time-domain Maxwell’s equations. J. of Math. Phys., 50:033510, (2009).
[CYWB06] J. X. Cai, Y.S.Wang, B. Wang, and B.Jiang: New multisymplectic self-adjoint
scheme and its composition for time-domain Maxwell’s equations.
J. of Math. Phys.,
47:123508, (2006).
[Dah07] M. L. Dahlby: Geometrical integration of nonlinear wave equations. Master’s thesis,
Norwegian University, NTNU, Trondheim, (2007).
[Fen85] K. Feng: On difference schemes and symplectic geometry. In K. Feng, editor, Pro-
ceedings of the 1984 Beijing Symposium on Differential Geometry and Differential Equa-
tions, pages 42–58. Science Press, Beijing, (1985).
[FQ87] K. Feng and M. Z. Qin: The symplectic methods for the computation of Hamiltonian
equations. In Y. L. Zhu and B. Y. Guo, editors, Numerical Methods for Partial Differential
Equations, Lecture Notes in Mathematics 1297, pages 1–37. Springer, Berlin, (1987).
[GAR73] P.L. GARCIA: The Poincare–Cartan invariant in the calculus of variations symposia
mathematica. In in Convegno di Geometria Simplettica e Fisica Mathmatica XIV, pages
219–243. Academic Press, London, (1973).
[GjLK04] H.Y. Guo, X.M. Ji, Y.Q. Li, and K.Wu:
symplectic, multisymplectic structure-
preserving in simple ﬁnite element method, Preprint arXiv: hep-th/0104151. (2004).
[Hip02] R. Hiptmair: Finite elements in computational electromagnetism. Acta Numerica,
11:237–339, (2002).
[HL04] J. Hong and C. Li: Multi-symplectic Runge–Kutta methods for nonlinear Dirac equa-
tions. J. of Comp. Phys., 211:448–472, (2004).
[HLHKA06] J. L. Hong, Y. Liu, H.Munthe-Kass, and Zanna A: On a multisymplectic scheme
for Schr¨odinger equations with variable coefﬁcients.
Appl. Numer. Math., 56:816–843,
(2006).
[HZQ03] L. Y Huang, W. P. Zeng, and M.Z. Qin: A new multi-symplectic scheme for nonlinear
“good” Boussinesq equation. J. Comput. Math., 21:703–714, (2003).
[JYJ06] B. Jiang, Y.S.Wang, and Cai J.X:
New multisymplectic scheme for generalized
Kadomtsev-Petviashvili equation. J. of Math. Phys., 47:083503, (2006).
[KLX06] L. H. Kong, R. X. Liu, and Z.L. Xu:
Numerical simulation interaction between
Schr¨odinger equation, and Klein–Gorden ﬁeld by multi-symplecticic methods. Applied
Mathematics and Computation, 181:342–350, (2006).
[Lag88] J. L. Lagrange: M´ecanique Analytique Blanchard, Paris, 5th edition, vol. 1, (1965).
[Lee82] T. D. Lee: Can time be a discrete dynamical variable? Phys.Lett.B, 122:217–220,
(1982).
[Lee87] T. D. Lee: Difference equations and conservation laws. J. Stat. Phys., 46:843–860,
(1987).
[LQ88] C.W. Li and M.Z. Qin: A symplectic difference scheme for the inﬁnite dimensional
Hamiltonian system. J. Comput. Appl. Math, 6:164–174, (1988).
[LQ02] T. T. Liu and M. Z. Qin: Multisymplectic geometry and multisymplectic Preissman
scheme for the KP equation. J. of Math. Phys., 43:4060–4077, (2002).

660
Bibliography
[LQHD07] X. S. Liu, Y.Y. Qi, J. F. He, and P. Z. Ding: Recent progress in symplectic algo-
rithms for use in quantum systems. Communications in Computational Physics, 2(1):1–53,
(2007).
[MM05] K.W. Morton and D.F. Mayers: Numerical Solution of Partial Differential Equations:
an introduction. Cambridge University Press, Cambridge, Second edition, (2005).
[MPS98] J. E. Marsden, G.P. Patrick, and S. Shloller: Multi-symplectic geometry, variational
integrators, and nonlinear PDEs. Communications in Mathematical Physics, 199:351–395,
(1998).
[MPSM01] J. E. Marsden, S. Pekarsky, S. Shkoller, and M.West: Variational methods, multi-
symplectic geometry and continuum mechanics. J.Geom. Phys., 38:253–284, (2001).
[Olv86] P.J. Olver: Applications of Lie Groups to Differential Equations. Springer, New York,
(1986).
[Qin87] M. Z. Qin: A symplectic schemes for the Hamiltonian equations. J. Comput. Math.,
5:203–209, (1987).
[Qin90] M. Z. Qin: Multi-stage symplectic schemes of two kinds of Hamiltonian systems of
wave equations. Computers Math. Applic., 19:51–62, (1990).
[Qin97a] M. Z. Qin: A symplectic schemes for the PDEs. AMS/IP studies in Advanced Math-
emateics, 5:349–354, (1997).
[QZ92] M. Z. Qin and W. J. Zhu: Construction of higher order symplectic schemes by com-
position. Computing, 47:309–321, (1992).
[QZ93] M. Z. Qin and W. J. Zhu: Construction of symplectic scheme for wave equation via
hyperbolic functions sinh(x), cosh(x) and tanh(x). Computers Math. Applic., 26:1–11,
(1993).
[Rei00] S. Reich: Multi-symplectic Runge–Kutta collocation methods for Hamiltonian wave
equations. J. of Comp. Phys., 157:473–499, (2000).
[SHQ06] J. Q. Sun, W. Hua, and M. Z. Qin:
New conservation scheme for the nonlinear
Schrodinger system. Applied Mathematics and Computation, 177:446–451, (2006).
[SMM04] J. Q. Sun, Z. Q. Ma, and M. Z. Qin:
RKMK method of solving non-damping
LL equations for ferromagnet chain equations. Applied Mathematics and Computation,
157:407–424, (2004).
[SMQ06] J. Q. Sun, Z. Q. Ma, and M. Z. Qin: Simulation of envelope Rossby solution in pair
of cubic Schrodinger equations.
Applied Mathematics and Computation, 183:946–952,
(2006).
[SNW92] J.C. Simo, N.Tarnow, and K.K. Wong: Exact energy-momentum conserving algo-
rithms and symplectic schemes for nonlinear dynamics. Comput. Methods Appl. Mech.
Engrg., 100:63–116, (1992).
[SQ00] Y. J. Sun and M.Z. Qin: Construction of multisymplectic schemes of any ﬁnite order
for modiﬁed wave equations. J. of Math. Phys., 41:7854–7868, (2000).
[SQ01] H. L. Su and M. Z. Qin: Multisymplectic Birkhofﬁan structure for PDEs with dissipa-
tion terms, arxiv:math.na 0302299, (2001).
[SQ03] H. Su and M. Z. Qin: Symplectic schemes for Birkhofﬁan system. Technical Report
arXiv: math-ph/0301001, (2003).
[SQ04] Y. J. Sun and M. Z. Qin: A multi-symplectic schemes for RLW eqution. J. Comput.
Math., 22:611–621, (2004).
[SQ05] H. Su and M. Z. Qin: Multisymplectic geometry method for Maxwell’s equations and
multisymplectic scheme. Technical Report arXiv. org math-ph/0302058, (2005).
[SQL06] J. Q. Sun, M.Z. Qin, and T.T. Liu: Total variation and multisymplectic structure for
the CNLS system. Commun.Theor. Phys., 46(2):966–975, (2006).
[SQS07] H. L. Su, M.Z. Qin, and R. Scherer: Multisymplectic geometry method for Maxwell’s
equations and multisymplectic scheme. Inter. J of Pure and Applied Math, 34(1):1–17,
(2007).
[SQWD09] J. Q. Sun, M. Z. Qin, H. Wei, and D. G. Dong: Numerical simulation of collision
behavior of optical solitons in bireﬁngent ﬁbres.
Commun Nonlinear Science and Numerical Simulation, 14:1259–1266, (2009).

Bibliography
661
[SQWR08] H. L. Su, M. Z. Qin, Y. S. Wang, and R. Scherer: Multisymplectic Birkhofﬁan
structure for PDEs with dissipation terms. Preprint No:2, Karlsruhe University, (2008).
[STMM07] A. Stern, Y. Tong, M.Desbrun, and J.E. Marsden: Electomagnetism with varia-
tional integration and discretedifferential forms, arXiv:0707.4470v2, (2007).
[Str68] G. Strang: On the construction and comparison of difference schemes. SIAM J. Numer.
Anal., 5:506–517, (1968).
[Str96] M. Struwe: Variational Methods Application to nonlinear PDEs and Hamiltonian sys-
tems, volume 34 of A Series of Modern Surveys in Mathematics. Springer-Verlag, Berlin,
Second edition, (1996).
[Suz92] M. Suzuki: General theory of higher-order decomposition of exponential operators
and symplectic integrators. Physics Letters A, 165:387–395, (1992).
[TM03] Y.M. Tian and M.Z.Qin: Explicit symplectic schemes for investigating the evolution
of vortices in a rovating Bose–Einstein condensate. Comput. Phys. Comm., 155:132–143,
(2003).
[TMZM08] Y.M. Tian, M.Z.Qin, Y. M. Zhang, and T. Ma: The multisymplectic method for
Gross–Pitaevskii equation. Comput. Phys. Comm., 176:449–458, (2008).
[WHT96] J. Wisdom, M. Holman, and J. Touma: Symplectic Correctors. In Jerrold E. Mars-
den, George W. Patrick, and William F. Shadwick, editors, Integration Algorithms and
Classical Mechanics, volume 10 of Fields Institute Communications, pages 217–244.
Fields Institute, American Mathematical Society, July (1996).
[WM01] Y. S. Wang and M. Z.Qin: Multisymplectic geometry and multisymplectic scheme
for the nonlinear Klein–Gordon equation. J. of Phys.soc. of Japan, 70:653–661, (2001).
[WWQ08] Y.S. Wang, B. Wang, and M. Z. Qin: Local structure-preserving algorithms for
partial differential equation. Science in China (series A), 51(11):2115–2136, (2008).
[Yos90] H. Yoshida: Construction of higher order symplectic integrators. Physics Letters A,
150:262–268, (1990).
[Zha91b] M. Q. Zhang: Explicit unitary schemes to solve quantum operator equations of mo-
tion. J. Stat. Phys., 65(3/4), (1991).
[Zha93a] M. Q. Zhang: Algorithms that preserve the volume ampliﬁcation factor for linear
systems. Appl. Math. Lett., 6(3):59–61, (1993).
[Zha93b] M. Q. Zhang: Computation of n-body problem by 2-body problems. Physics Letters
A, 197:255–260, (1993).
[ZQ93a] M. Q. Zhang and M. Z. Qin: Explicit symplectic schemes to solve vortex systems.
Comp. & Math. with Applic., 26(5):51, (1993).
[ZQ93b] W. Zhu and M. Qin: Application of higer order self-adjoint schemes of PDEs. Com-
puters Math. Applic., 25(12):31–38, (1993).
[ZQ00] P. F. Zhao and M. Z. Qin: Multisymplectic geometry and multisymplectic Preissman
scheme for the KdV equation. J. Phys. A: Math. Gen., 33:3613–3626, (2000).
[ZW99] H.P. Zhu and J.K. Wu: Generalized canonical transformations and symplectic algo-
rithm of the autonomous Birkhofﬁan systems. Progr. Natur. Sci., 9:820–828, (1999).
[ZzT96] W. Zhu, X. Zhao, and Y. Tang: Numerical methods with a high order of accuracy
applied in the quantum system. J. Chem. Phys., 104(6):2275–2286, (1996).

Symbol
Symbol
A, B
A∗= A
′
A′, AT
A⊤
A⊥
A = {Uλ, ϕλ}
Ad
Ad∗
adv
ad∗
v
Br(a)
Bk
Bk
bk, bk
B(ρ), C(η), D(ζ)
C
Cn
Ck
C∞
C(z)
Ck(M)
Ci
jk
d
dxi
D
det A
div
deg ω (deg f)( deg P(x))
Eτ
e
ex
ei, {ei, fj}
et
a
exp, Exp
F(t)f
Description
Matrix A = {aij ∈M(n)}
conjugate transpose of A
transpose of A
J-orthogonal complement of A
orthogonal complement of A
smooth atlas
adjoint representation
coadjoint representation
adjoint vector ﬁeld
coadjoint vector ﬁeld
take a as the center of circle, r is the radius ball
space consist of all exact k-form
set of all k-boundaries
Betti number
order conditions of Butcher.
the complex numbers
complex vector space of complex n-vector
space of k-times differentiable functions
space of smooth functions
Casimir function
k-dimensional chain on M
structure constant
exterior derivative, exterior differential operator
basis differential 1-form
total differential
determinant of matrix A
divergence
order of form (order of map) (order of polynomial)
Euler step-transient operator
identity element of group
exponential function of x
basis, symplectic basis
phase of ﬂow with vector ﬁeld a
exponential map
differential element of function f

664
Symbol
Symbol
F
Fn
f∗p
F(Rn)
gk(M)
G
G2n,k
g
g∗
Gl(n), Gl(n, R), Gl(n, C)
gl(n)
grad
HK(M, R)(HK(M, R))
H(p, q), H(z)
i
iX,
I
In, I2n
id (Id)
im L
J
I2n, J4n
"J4n
K
ker L
L[u] =

L dx
LXY, LXω
M, N
M(n, m, R)
M(n, m, C)
M(n, R)
M(n, C)
M(n, F)
O(n), o(n)
O
P
p
Q
q
p
R
Rn
Rn
p, Rn
q
RP n
r(t)
S
h, s
Description
a ﬁeld (usually R or C)
vector space (over F) of n-vectors
differential of the map f in the p place
a class of all differentiable function on Rn
set of all k-differential form on M
group, Lie group
M(2n, k) nonsingular equivalent class
Lie algebra
dual to the Lie algebra
linear group on Rn,(Cn)
Lie algebra of n × n matrix
gradient
k-th cohomology (homology) group on M
Hamiltonian function
including map
contraction, interior product
identity map
identity matrix, standard Euclidean structure
identity
image of map L
momentum map
symplectic structure
"J4n-symplectic structure
K-symplectic structure
kernel of mapping L
variation of L
vector ﬁeld Y , differential form ω of Lie derivative
manifold
set of all real matrix with n-row and m-column
set of all complex matrix with n-row and m-column
set of all real matrix of order n × n on Rn
set of all complex matrix of order n × n on Cn
set of all matrix of order n × n on Fn
orthogonal group, orthogonal Lie algebra
zero matrix
coordinate in momentum space
coordinate in conﬁguration space
order of p
real number
n-dimensional real vector space
momentum space, conﬁguration space in Rn
real projection space
order of t-tree
symplectic transformation, S-transformation
step of time

Symbol
665
Symbol
SL(n), SL(n, R), SL(n, C)
sl(n)
SO(n)
so(n)
Sp(2n)
sp(2n)
CSp(2n)
Sp(0)
Sp(I)
Sp(II)
Sp(III)
Sp-diff or Sp-Diff
TM
TxM
T ∗M
T ∗
xM
Sm
u, v
(U, ϕ), (V, ϕ)
V
Xp
˙x, ¨x
x, xi
y, yi
X(M)
XH
X(Rn)
α =
 Aα
Bα
Cα
Dα

α−1 =
 Aα
Bα
Cα
Dα

δ
σ(t)
γ(t)
δj
i
α(t)
Γf, Gf, gr (f)
Δt, τ, s
Δx
θ
dθ
π
TRn −→Rn
π−1(x) = TxRn
Description
special linear group, (real), (complex)
Lie algebra of special linear group
special orthogonal group
Lie algebra of special orthogonal group
symplectic group, symplectic matrix
symplectic algebra, inﬁnitesimal symplectic matrix
conformal symplectic group
0-class of symplectic matrix
I-class of symplectic matrix
II-class of symplectic matrix
III-class of symplectic matrix
symplectic diffeomorphism
tangent bundle
tangent space in place x
cotangent bundle
cotangent space in place of x
symmetric group
vector in Rn space
local coordinate
vector space
vector ﬁeld in place p on manifold
ﬁrst, second, order derivative at x
x vector, coordinate component
y vector, coordinate component
set of all tangent vector on M
Hamiltonian vector ﬁeld
set of all smooth vector ﬁeld on Rn
Darboux transformation
inverse of Darboux transformation
variational derivative, codifferential operator
symmetry of t-tree
density of t-tree
Kronecker symbol
essential different labelings
graphic of f
step size of time
step size of apace
differential 1-form
exterior of differential 1-form
projection TRn to Rn
ﬁber in point x

666
Symbol
Symbol
ϕ∗ω
(ϕ∗ω)
ϕ∗f
(ϕ∗f)
ϕ∗Y
(ϕ∗Y )
×
∧
Λk(Rn)
Λn
Λn(K)
f⊤Z
f⊤pZ
Ω
Ω#
Ωb
Ωk(Rn), Ω0(Rn) = C∞(Rn)
∂
∂xI or ∂xi
∂
▽× f
▽· f

pds

ω
∅
⊗
∩
∪
⊂
∈
∋
◦

f ◦g = f(g)

/
̸∈
∀
≃
∽
∼=
≡
:=
∼
c∼
−→
=⇒
⇐⇒
Cn
k =
 n
k

=
n!
k!(n −k)!
Description
pull back of differential form (push-forward)
pull back of function(push-forward)
pull back of vector ﬁeld (push-forward)
product
exterior product
k-th exterior bundle over Rn
Lagrangian subspace
K-Lagrangian subspace
f transverse to Z
f in the p transverse to Z
standard symplectic structure
lift of mapping Ω#(z1)(z2) = Ω−1(z1, z2)
down mapping Ωb(z1)(z2) = Ω(z1, z2)
k-differential form on Rn
partial derivative with respect to xi
boundary operator
rotation
divergence
boundary integral
integral of differential form
empty set
tensor product
set-theoretic intersection
set-theoretic union
inclusion
element of
element of
composition
division
not element of
for
homomorphism
approximate
similarly
identity
deﬁnition
corresponding, equivalent, congruent relation
conjugate congruent
mapping
extrusion
extrusion mutually
binomial coefﬁcient

Symbol
667
Symbol
*
n
k1, k2, · · · , kr
+
=
n!
k1!k2! · · · , kr!
where k1 + k2 + · · · + kr = n
(a, b)
[a, b]
[u, w]
[A, B]
[F, H]
(u, v)
[U, V ]
∥B∥
U
◦+ V
P1 ⊤
⃝P2
⟨, ⟩
{ϕ, φ}
a⊥b
a⊤b
1N(x) = x
Description
multinomial coefﬁcients.
open interval
closed interval
Lie bracket
matrix commutator
Poisson bracket
inner product, Euclidean inner product
symplectic inner product
norm of matrix
direct sum
symplectic direct sum
inner product
Poisson bracket
vector a orthogonal to b (Euclidean)
vector a symplectic orthogonal to b
identity function

Index
A
A(α)-stability, 550
a*–linear differential operator, 407
a∗–Jacobian matrix, 407
A-stability, 550
ABC ﬂow, 446
action functional of Lagrangian density, 643
Ad*-equivariant, 503
adjoint integrator, 374
adjoint method, 372
all polynomials is symplectically separability
in R2n, 207
alternative canonical forms, 130
angular momentum in body description, 505
angular momentum in space description, 505
angular momentum-preserving schemes for
rigid body, 525
angular velocity in body description, 505
angular velocity in space description, 505
anti-symmetric product, 117
atlas, 40
automorphism, 39
autonomous Birkhoff’s equations, 618
B
B-series, 417
B-stability, 550
backward error analysis, 432
base of tangent space, 45
BCH formula, 380, 413
Betti numbers, 99
bijective, 39
bilinear antisymmetric form, 188
binary forms, 116
Birkhofﬁan system, 618
black (fat )vertex, 309
boundary of chains, 92
Butcher tableau, 278
C
calculate the formal energy, 267
canonical equation, 170
canonical forms under orthogonal
transformation, 134
canonical reductions of bilinear forms, 128
canonical transformation, 172, 188
Cartan form, 644
Cartan’s Magic formula, 106
Casimir function, 501
Cayley transformation, 193
centered Euler method, 416
centered Euler scheme, 192, 200, 231
chains, 91
characteristic equations, 477
chart, 40
Chebyshev spectral method, 508
classical Stokes theorem, 98
closed form, 84
closed nondegenerate differential 2-form, 165
coadjoint orbits, 505
coclosed form, 90
codifferential operator, 89
coefﬁcient B-series for centered Euler
scheme, 418
coefﬁcient B-series for exact solution, 418
coefﬁcient B-series for explicit Euler scheme,
418
coefﬁcient B-series for implicit Euler scheme,
418
coefﬁcient B-series for R–K method, 418
coefﬁcient B-series for trapezoidal scheme,
418
coefﬁcients can be determined recursively,
233
coexact form, 90
cohomology space, 98
coisotropic subspace, 138
commutativity of generator maps, 261
commutator, 124, 179

670
Index
commutator of two vector ﬁelds, 100
comparison order conditions between
symplectic R–K (R–K–N) method, 302
comparison order conditions P–R–K method
and symplectic P–R–K method, 318, 319,
333
compatible of two local coordinate systems,
40
complete non-integrability, 477
complexiﬁable, 124
complexiﬁcation of real vector space and real
linear transformation, 123
composition laws, 419
composition of centered Euler scheme, 372
composition of trapezoid scheme, 365
composition scheme is not A-stable, 389
compositional property of Lie series, 379
condition for centered Euler to be volume-
preserving, 444
condition of symplectic P–R–K method, 303
condition of variational self-adjointness, 619
conﬁguration space, 188
conformally K-symplectic group
CSp(K, n, F), 120
conformally canonical transformation, 173,
182
conformally Hermitian, 117
conformally identical, 114
conformally orthogonal group CO(S, n, F),
120
conformally symmetric, 114
conformally symplectic group CSp(2n), 144
conformally unitary group CU(H, n, C),
120
congruence canonical forms of conformally
symmetric, 130
congruence canonical forms of Hermitian
matrices, 130
congruent reductions, 129
conic function, 484
conic Hamiltonian vector ﬁelds, 488
conic map, 484
conic symplectic, 484
conic symplectic map, 484
conic transformation, 488
conservation Laws, 234
conservation of spatial angular momentum
theorem, 506
constrained Hamiltonian algorithm, 537
construction of the difference schemes via
generating function, 213
construct volume-preserving difference
schemes, 454
constructing s-scheme by 2nd kind g.f., 227
constructing s-scheme by Poincar´e type g.f.,
229
constructing s-scheme via 1st kind g.f., 227
construction of volume-preserving schemes
via g.f., 464
contact 1-form, 480
contact algorithm, 483
contact algorithm–C, 493
contact algorithm–P, 492
contact algorithm–Q, 492
contact difference schemes, 492
contact dynamical systems, 477
contact element, 482
contact generating function, 487
contact geometry, 477
contact Hamiltonian, 483, 492
contact map, 486
contact structure, 477, 481
contact transformation, 483
contactization of conic symplectic maps, 487
contraction, 105
convergence of symplectic difference
schemes, 239
coordinate Lagrangian subspaces, 147
coordinate of tangent vector, 45
coordinate subspaces, 139
cotangent bundle, 76, 249
cotangent vector, 76
cycle, 93
D
Darboux matrix, 231, 600
Darboux theorem, 168, 190
Darboux transformation, 249
De Rham theorem, 99
decomposed theorem of symplectic matrix,
155
decompositions of source-free vector ﬁelds,
452
deﬁnition of symplectic for LMM, 356
density of tree γ(t), 294
diagonal formal ﬂow, 415
diagonal Pad´e approximant, 194
diagonally implicit method, 284
diagonally implicit symplectic R–K method,
284
diffeomorphism, 39, 102, 126, 188
diffeomorphism group, 102
differentiable manifold, 40
differentiable manifold structure, 40
differentiable mapping, 41
differentiable mapping, differential concept,
43

Index
671
differentiable structure, 40
differential, 45
differential k-form, 77
differential complex, 657
diophantine condition, 566, 572
diophantine frequency vectors, 552
diophantine step sizes, 569
direction ﬁeld, 477
discrete energy conservation law, 587
discrete Euler–Lagrange equation, 587, 652
discrete extended Lagrange 2-form, 589
discrete Lagrange 2-form, 589
discrete Lagrangian, 652
discrete mechanics based on ﬁnite element
methods, 606
discrete multisymplectic conservation law,
646
discrete multisymplectic form formula, 652
discrete total variation in the multisymplectic
form, 605
discrete variational principle in total
variation, 596
divergence-free system, 443, 449
E
eigenvalues of inﬁnitesimal symplectic
matrix, 159
eigenvalues of symplectic matrix, 158
elementary divisor in real space, 136
elementary divisors in complex space, 136
embedded submanifold, 538
embedding submanifold, 51
endomorphism, 39
energy conservation law, 645
energy density, 645
energy equation, 644
energy ﬂux, 645
energy-preserving schemes for rigid body,
525
epimorphism, 39
equivalent atlas, 40
Euclidean form, 118
Euclidian structure, 137
Euler centered scheme, 194
Euler equation, 506
Euler–Lagrange 1-form, 583
Euler–Lagrange equation, 644
Euler–Lagrange equation in FEM, 607
even polynomial, 159
exact form, 84
exact symplectic mapping, 551
exp maps, 412
explicit Euler method, 415
explicit Euler scheme, 204
explike function, 349
exponential matrix transform, 125
extended canonical two form, 595
extended conﬁguration space, 581
extended Lagrangian 1-form, 585
extended phase space, 242
extended symplectic 2-form, 585
exterior algebra, 68
exterior differential operator, 82
exterior form, 66
exterior monomials, 70
exterior product, 64
exterior product of forms, 72
F
fathers’ and sons’ relations, 297
ﬁber of tangent bundle, 56
ﬁrst integrals, 234
ﬁrst order prolongation, 594, 643
ﬁrst order prolongation of V , 584
ﬁxed point, 236
formal energy, 264
formal energy for symplectic R–K method,
333, 339
formal energy of centered Euler scheme, 344
formal power series, 265, 407
formal vector ﬁeld, 432
fourth order with 3-stage scheme, 365
Frechet derivatives, 289
free rigid body, 529
G
G-stability, 550
Gauss IA-IA, 472
Gauss theorem, 98
Gauss–Legendre polynomial, 279
Ge–Marsden theorem, 273
general Hamilton–Jacobi equation, 221
general linear group GL(n, F), 119
general vector ﬁeld, 583
generalized Cayley transformation, 197, 198
generalized Euler schemes, 231
generalized Hamiltonian equation, 500
generalized Lagrangian subspaces, 162
generalized Noether theorem, 502
generating function, 182, 219, 233, 601
generating function and H.J. equation of the
ﬁrst kind, 223
generating function and H.J. equation of the
second kind, 223

672
Index
generating function for Lie–Poisson system,
519
generating function for volume-preserving,
460
generating function method, 432
generating functions, 221, 255
generating functions for Lagrangian
subspaces, 160
generator map, 255
generators of Sp(2n), 155
gradient map, 220
gradient mapping, 219
gradient transformation, 174
graph of gradient map, 219
graph of symplectic map, 219
Grassmann algebra, 75
Grassmann manifold, 143
Green theorem, 97
Gronwall inequality, 241
group homomorphism, 126
group of contact transformations, 483
H
H-Stability, 401
H-stability interval of explicit scheme, 404
Hamilton–Jacobi equation, 182, 233, 462,
602
Hamilton–Jacobi equation for contact system,
494
Hamiltonian function, 187
Hamiltonian mechanics, 165, 168
Hamiltonian operator, 500
Hamiltonian phase ﬂow, 171
Hamiltonian systems, 187
Hamiltonian vector ﬁelds, 167, 170
Hamiltonian–Jacobi equation, 627
heavy top, 534
Hermitian form, 117
Hermitian, anti-Hermitian, 116
high order symplectic-energy integrator, 600
Hodge operator, 88
homeomorphism, 39
homogeneous symplectic, 484
homology space, 99
homomorphism, 39
Hopf algebra, 433
horizontal variation of qi, 586
hyperplane, 478
hypersurface, 477
I
immersed submanifold, 48
immersion, 47
implicit Euler method, 415
impossible to construct volume-preserving
algorithms analytically depending on
source-free vector ﬁelds, 452
inﬁnitesimal generator vector ﬁeld, 502
inﬁnitesimal symplectic matrices, 190
injective, 39
integral invariant, 171
integral surface, 477
integrator S(τ) has a formal Lie expression,
381
invariance of generating functions, 261
invariant groups for scalar products, 119
invariant integral, 192
invariant tori, 574
invariant under the group G of symplectic
transformations, 234
invariant under the phase ﬂow of any
quadratic Hamiltonian, 235
invariants under congruences, 132
inverse mapping, 39
isomorphic mapping, 39
isotropic subspace, 138
isotropic, coisotropic, Lagrangian, 182
J
Jacobi identity, 124, 177
J4n, ˜J4n-Lagrangian submanifold, 219, 622
jet bundles, 643
K
"K-Lagrangian submanifold, 623
K(z, t)-symplectic, 621
k-forms, 67
K-symplectic group, 120
K-symplectic scheme, 622
K-symplectic structure, 190
KAM iteration process, 556
KAM theorem, 551
KAM theorem of symplectic algorithms, 559
Kane–Marsden–Ortiz integrator, 587
L
L-stability, 550
labeled n-tree λτ, 297
labeled P-tree, 309
labeled graph, 292
labeled trees, 298
Lagrange 2-form in FEM, 607
Lagrangian 2-form, 583
Lagrangian density, 643

Index
673
Lagrangian mechanics, 581
Lagrangian submanifold, 182, 250
Lagrangian subspace, 138
Lee-variational integrator, 581
left translation action, 503
Legendre transform, 645
Legendre–Hodge transformation, 645
Lie algebra, 125, 179, 190, 409
Lie algebra of conformally invariant groups,
128
Lie bracket, 409
Lie derivative, 103
Lie group, 125
Lie group action, 502
Lie series, 377
Lie–Poisson bracket, 501, 504
Lie–Poisson equation, 504
Lie–Poisson scheme, 519
Lie–Poisson systems, 501
Lie-Poisson-Hamilton-Jacobi equation, 514
lifted action, 502
linear damped oscillator, 629
linear fractional transformation, 213
linear Hamiltonian systems, 192
linear multistep method, 347
Liouville frequency vectors, 552
Liouville’s phase-volume conservation law,
189
Liouville’s theorem, 172, 443
Lobatto III A, 279, 280
Lobatto III B, 279, 280
Lobatto III C, 279, 280
Lobatto IIIC-IIIC, 472
Lobatto polynomial, 279
local coordinate systems, 40
log maps, 412
logarithmic map, 434
loglike function, 350
M
M¨obius strip, 61
manifold, 40
matrix representation of subspaces, 143
maximum non-degeneracy, 477
modiﬁed centered Euler scheme of sixth
order, 433
modiﬁed equation, 334, 432
modiﬁed equation for centered Euler scheme,
336, 433
modiﬁed integrators, 432
momentum, 502
momentum conservation law, 605, 645
momentum density, 645
momentum equation, 644
momentum ﬂux, 645
momentum mapping, 502
monomial, 207
monomorphism, 39
monotonic rooted labeled trees, 298
Morse–Smale systems, 551
multi-stage P–R–K method, 473
multisymplectic Birkhofﬁan systems, 656
multisymplectic conservation law, 605, 645
multisymplectic dissipation law, 656
multisymplectic form, 644
multisymplectic form formula, 644
multisymplectic Fourier pseudospectral
methods, 654
multisymplectic geometry, 643
multisymplectic Hamiltonian system, 605
multisymplectic Hamiltonian system for KdV
equation, 648
multisymplectic Hamiltonian system for
KGS equation, 649
multisymplectic Hamiltonian system for
Schr¨odinger equation, 647
multisymplectic Hamiltonian system for
sine-Gordon equation, 646
multisymplectic Hamiltonian systems, 645
multisymplectic integrators, 646
multisymplectic integrators for modiﬁed
equations, 655
multisymplectic-energy-momentum
integrators, 605
N
natural product symplectic structure, 249
near-0 formal power series, 409
near-1 formal power series, 409
nilpotent of degree 2, 204
Noether theorem, 179
non-exceptional matrices, 197
non-existence of symplectic schemes
preserving energy, 273
non-superﬂuous tree, 299
nonautonomous Birkhoff’s equation, 619
nonautonomous Hamiltonian System, 242
nonconservative multisymplectic Hamilto-
nian systems, 654
nonexistence of SLMM for nonlinear
Hamiltonian systems, 356
nonresonant frequencies, 570
normal Darboux matrix, 232, 239, 494
normal Darboux matrix of a symplectic
transformation, 600
normalization coefﬁcient B-series, 418

674
Index
normalization Darboux transformation, 251
normalizing conditions, 453
null space of 1-form, 478
number of essential different labelings α(t),
294
numerical version of KAM theorem, 564
O
obstruction, 450
one-form (1-form), 66
one-leg weighted Euler schemes, 231
one-parameter group of canonical maps, 221
operation ∧, 65
optimization Method, 603
orbit-preserving schemes, 527
order conditions for symplectic R–K–N
method, 319
orientable differentiable manifold, 59
orientable vector spaces, 59
orthogonal group O(n, F), 119
P
P–R–K method, 302
Pad´e approximation, 193
Pad´e approximation table, 196
partitions and skeletons, 418
Pfafﬁan theorem, 118
phase ﬂow, 102, 221, 408
phase ﬂow of contact system, 483
phase ﬂow- et
F , 235
phase space, 102
phase-area conservation law, 189
Poincar´e lemma, 85, 220, 222
Poincar´e transformation, 250
Poincar´e’s generating function and H.J.
equation, 223
Poisson bracket, 177, 192, 499
Poisson manifold, 499
Poisson mapping, 500
Poisson scheme, 508
Poisson system, 500
Poisson theorem, 179
postprocessed vector ﬁeld, 432
Preissman integrator, 646
preprocessed vector ﬁeld integrators, 432
preserve all quadratic ﬁrst integrals of system,
236
preserve angular momentum pT Bq, 236
preserving the contact structure, 483
presymplectic form, 645
presymplectic forms, 605
product of cotangent bundles, 249
product preservation property of Lie series,
379
prolongation spaces, 643
proper mapping, 51
properties of Lie series, 379
pull-back, 80
pull-back mapping, 374
push-forward mapping, 374
Q
quadratic bilinear form, 115
quaternion form, 524
R
Radau I A, 279
Radau IA-IA, 471
Radau II A, 280
Radau IIA-IIA, 472
Radau polynomial, 279
rational fraction, 200
real representation of complex vector space,
121
reduction method, 540
reﬂective polynomial, 158
regular submanifold, 51, 53
relationship between rooted tree and
elementary differential, 293
resonant, 568
revertible approximations, 450
Riemann structure, 167
right translation, 503
rigid body in Euclidean space, 523
Rodrigue formula, 543
root isomorphism, 298
rooted n-tree, 299
rooted P-tree, 309
rooted S-tree, 321
rooted 3-tree, 298
rooted labeled n-tree ρλτ, 297
rooted labeled P-tree, 309
rooted labeled S-tree, 321
rooted labeled 3-tree, 298
rooted labeled trees, 298
S
S-graph, 321
S-orthogonal group, 119
S-tree, 321
scalar product, 117
section of tangent bundle, 62
self-adjoint integrator, 376
self-adjoint method, 372

Index
675
semi-autonomous Birkhoff’s equation, 618
separable Hamiltonian system, 202
separable systems for source-free systems,
447
sesquilinear form, 116
simplify symplectic R–K conditions, 300
simplifying condition of R–K method, 279
Sm(2n)matrices, 600
small twist mappings, 558
some theorems about Sp(2n), 151
sons of the root, 297
source-free system, 443, 449, 467
Sp(2n) matrices, 600
SpD2n the totality of symplectic operators,
232
SpD2n the set of symplectic transformations,
601
special linear group SL(n, F), 119
special separable source-free systems, 458
special type Sp2n(I), 150
special type Sp2n(II), 151
special type Sp2n(III), 151
special type Sp2n(I, II), 151
special types of Sp(2n), 148
stability analysis for composition scheme,
388
standard antisymmetric matrix, 192
standard symplectic structure, 169, 188, 249
star operators, 88
step size resonance, 568
step transition, 415
step-forward operator, 240
Stokes theorem, 93
structure-stability, 551
subalgebra of a Lie algebra, 179
submanifold, 46
submersion, 51
substitution law, 432
superﬂuous trees, 298
surjective, 39
Sylvester’s law of inertia, 132
Symm(2n) the set of symmetric
transformations, 601
symm(2n) the totality of symmetric
operators, 232
symmetric operators near nullity, 232
symmetric pair, 216
symmetric product, 117
symmetrical composition, 376
symmetry of tree σ(t), 294
symplectic algebra, 216
symplectic algorithms as small twist
mappings, 560
symplectic basis, 145
symplectic conditions for R–K method, 281
symplectic explicit R–K–N method
(non-redundant 5-stage ﬁfth order), 331
symplectic form, 118
symplectic geometry, 165, 188
symplectic group, 188
symplectic group Sp(2n), 144
symplectic group Sp(2n, F), 119
symplectic invariant algorithms, 235
symplectic leave, 505
symplectic LMM for linear Hamiltonian
systems, 348
symplectic manifold, 165
symplectic map, 220
symplectic mapping, 215
symplectic matrix, 189
symplectic operators near identity, 232
symplectic pair, 217
symplectic R–K method, 277, 279
symplectic R–K–N method, 319
symplectic R–K–N method (3-stage and 4-th
order), 323
symplectic schemes for Birkhofﬁan Systems,
625
symplectic schemes for nonautonomous
system, 244
symplectic space, 137
symplectic structure, 137, 165, 215, 477
symplectic structure for trapezoidal scheme,
202
symplectic structure in product space, 215
symplectic subspace, 137
symplectic-energy integrator, 596, 602
symplectic-energy-momentum, 581
symplectically separable Hamiltonian
systems, 205
symplectization of contact space, 487
sympliﬁed order conditions for symplectic
R–K–N method, 327
sympliﬁed order conditions of explicit
symplectic R–K method, 307
T
table of coefﬁcient ω(τ) for trees of order
⩽5, 435
table of coefﬁcients σ(τ), γ(τ),˘b(τ), andb(τ),
434
table of composition laws for the trees of
order ≤4, 436
table of substitution law ∗deﬁned in for the
trees of order ≤5, 437
tangent bundle, 56
tangent mapping, 58

676
Index
tangent space, 44
tangent vector, 43
the elementary differential, 291
the inverse function to exp, 126
the order of tree r(t), 294
time-dependent gradient map, 221
topological manifold, 40
total variation for Lagrangian mechanics, 583
total variation in Hamiltonian mechanics, 593
transversal, 54, 140, 143
transversal Lagrangian subspaces, 148
transversality condition, 181, 213, 221, 225,
227, 250, 251, 460, 623
trapezoidal method, 416
trapezoidal scheme, 201
tree, 298
trivial tangent bundle, 57
truncation, 233
two-forms (2-forms), 66
U
Unitary group U(n, C), 119
Unitary product, 118
V
variational integrators, 651
variational principle in Hamiltonian
mechanics, 591
vector ﬁeld, 62
vertical vector ﬁeld, 582
Veselov–Moser algorithm, 539
volume-preserving 2-Stage P–R–K methods,
471
volume-preserving P-R–K method, 467
volume-preserving R–K method, 467
volume-preserving schemes, 444
W
W-transformation, 304, 470
white (meagre) vertex, 309
Witt theorem, 132
X
X-matrix, 305

