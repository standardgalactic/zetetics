
The Industrial Electronics Handbook
S E c o n d  E d I T I o n
Fundamentals oF 
IndustrIal electronIcs
© 2011 by Taylor and Francis Group, LLC

The Industrial Electronics Handbook
S E c o n d  E d I T I o n
Fundamentals oF IndustrIal electronIcs
Power electronIcs and motor drIves 
control and mechatronIcs
IndustrIal communIcatIon systems
IntellIgent systems
© 2011 by Taylor and Francis Group, LLC

The Electrical Engineering Handbook Series
Series Editor
Richard C. Dorf
University of California, Davis
Titles Included in the Series
The Avionics Handbook, Second Edition, Cary R. Spitzer
The Biomedical Engineering Handbook, Third Edition, Joseph D. Bronzino
The Circuits and Filters Handbook, Third Edition, Wai-Kai Chen
The Communications Handbook, Second Edition, Jerry Gibson
The Computer Engineering Handbook, Vojin G. Oklobdzija
The Control Handbook, Second Edition, William S. Levine 
CRC Handbook of Engineering Tables, Richard C. Dorf
Digital Avionics Handbook, Second Edition, Cary R. Spitzer
The Digital Signal Processing Handbook, Vijay K. Madisetti and Douglas Williams
The Electric Power Engineering Handbook, Second Edition, Leonard L. Grigsby
The Electrical Engineering Handbook, Third Edition, Richard C. Dorf
The Electronics Handbook, Second Edition, Jerry C. Whitaker
The Engineering Handbook, Third Edition, Richard C. Dorf
The Handbook of Ad Hoc Wireless Networks, Mohammad Ilyas
The Handbook of Formulas and Tables for Signal Processing, Alexander D. Poularikas
Handbook of Nanoscience, Engineering, and Technology, Second Edition,
   William A. Goddard, III, Donald W. Brenner, Sergey E. Lyshevski, and Gerald J. Iafrate
The Handbook of Optical Communication Networks, Mohammad Ilyas and 
   Hussein T. Mouftah
The Industrial Electronics Handbook, Second Edition, Bogdan M. Wilamowski 
   and J. David Irwin
The Measurement, Instrumentation, and Sensors Handbook, John G. Webster
The Mechanical Systems Design Handbook, Osita D.I. Nwokah and Yidirim Hurmuzlu
The Mechatronics Handbook, Second Edition, Robert H. Bishop
The Mobile Communications Handbook, Second Edition, Jerry D. Gibson
The Ocean Engineering Handbook, Ferial El-Hawary
The RF and Microwave Handbook, Second Edition, Mike Golio
The Technology Management Handbook, Richard C. Dorf
Transforms and Applications Handbook, Third Edition, Alexander D. Poularikas
The VLSI Handbook,  Second Edition, Wai-Kai Chen
© 2011 by Taylor and Francis Group, LLC

The Industrial Electronics Handbook
S E c o n d  E d I T I o n
Fundamentals oF 
IndustrIal electronIcs
Edited by
Bogdan M. Wilamowski
J. david Irwin
© 2011 by Taylor and Francis Group, LLC

MATLAB® is a trademark of The MathWorks, Inc. and is used with permission. The MathWorks does not warrant the 
accuracy of the text or exercises in this book. This book’s use or discussion of MATLAB® software or related products 
does not constitute endorsement or sponsorship by The MathWorks of a particular pedagogical approach or particular 
use of the MATLAB® software.
CRC Press
Taylor & Francis Group
6000 Broken Sound Parkway NW, Suite 300
Boca Raton, FL 33487-2742
© 2011 by Taylor and Francis Group, LLC
CRC Press is an imprint of Taylor & Francis Group, an Informa business
No claim to original U.S. Government works
Printed in the United States of America on acid-free paper
10 9 8 7 6 5 4 3 2 1
International Standard Book Number: 978-1-4398-0279-3 (Hardback)
This book contains information obtained from authentic and highly regarded sources. Reasonable efforts have been 
made to publish reliable data and information, but the author and publisher cannot assume responsibility for the valid-
ity of all materials or the consequences of their use. The authors and publishers have attempted to trace the copyright 
holders of all material reproduced in this publication and apologize to copyright holders if permission to publish in this 
form has not been obtained. If any copyright material has not been acknowledged please write and let us know so we may 
rectify in any future reprint.
Except as permitted under U.S. Copyright Law, no part of this book may be reprinted, reproduced, transmitted, or uti-
lized in any form by any electronic, mechanical, or other means, now known or hereafter invented, including photocopy-
ing, microfilming, and recording, or in any information storage or retrieval system, without written permission from the 
publishers.
For permission to photocopy or use material electronically from this work, please access www.copyright.com (http://
www.copyright.com/) or contact the Copyright Clearance Center, Inc. (CCC), 222 Rosewood Drive, Danvers, MA 01923, 
978-750-8400. CCC is a not-for-profit organization that provides licenses and registration for a variety of users. For 
organizations that have been granted a photocopy license by the CCC, a separate system of payment has been arranged.
Trademark Notice: Product or corporate names may be trademarks or registered trademarks, and are used only for 
identification and explanation without intent to infringe.
Library of Congress Cataloging‑in‑Publication Data
Fundamentals of industrial electronics / editors, Bogdan M. Wilamowski and J. David Irwin.
p. cm.
“A CRC title.”
Includes bibliographical references and index.
ISBN 978-1-4398-0279-3 (alk. paper)
1.  Industrial electronics.  I. Wilamowski, Bogdan M. II. Irwin, J. David. III. Title.
TK7881.F86 2010
621.381--dc22 
2010019980
Visit the Taylor & Francis Web site at
http://www.taylorandfrancis.com
and the CRC Press Web site at
http://www.crcpress.com 
© 2011 by Taylor and Francis Group, LLC

vii
Contents
Preface....................................................................................................................... xi
Acknowledgments................................................................................................... xiii
Editorial Board..........................................................................................................xv
Editors..................................................................................................................... xvii
Contributors����������������������������������對������������������������������������對������������������������������������對�xxi
Part I  Circuits and Signals
	 1	 DC and Transient Circuit Analysis.................................................................1-1
Carlotta A. Berry and Deborah J. Walter
	 2	 AC Circuit Analysis........................................................................................ 2-1
Carlotta A. Berry and Deborah J. Walter
	 3	 Computational Methods in Node and Loop Analyses................................... 3-1
Stephen M. Haddock and J. David Irwin
	 4	 Transistor Operation and Modeling............................................................... 4-1
Tina Hudson
	 5	 Application of Operational Amplifiers.......................................................... 5-1
Carlotta A. Berry and Deborah J. Walter
	 6	 Frequency Response and Bode Diagrams....................................................... 6-1
Thomas F. Schubert, Jr. and Ernest M. Kim
	 7	 Laplace Transforms..........................................................................................7-1
Dalton S. Nelson
Part II  Devices
	 8	 Semiconductor Diode...................................................................................... 8-1
Bogdan M. Wilamowski
	 9	 Bipolar Junction Transistor............................................................................ 9-1
Bogdan M. Wilamowski and Guofu Niu
© 2011 by Taylor and Francis Group, LLC

viii 
Contents
	10	 Field Effect Transistors..................................................................................10-1
Bogdan M. Wilamowski and J. David Irwin
	11	 Noise in Semiconductor Devices................................................................... 11-1
Alicja Konczakowska and Bogdan M. Wilamowski
	12	 Physical Phenomena Used in Sensors............................................................12-1
Tiantian Xie and Bogdan M. Wilamowski
	13	 MEMS Devices...............................................................................................13-1
José M. Quero, Antonio Luque, Luis Castañer, Angel Rodríguez, 
Adrian Ionescu, Montserrat Fernández-Bolaños, Lorenzo Faraone, 
and John M. Dell
	14	 MEMS Technologies.......................................................................................14-1
Antonio Luque, José M. Quero, and Carles Cané
	15	 Applications of MEMS...................................................................................15-1
Antonio Luque, José M. Quero, Robert Lempkowski, and Francisco Ibáñez
	16	 Transistors in Switching Circuits..................................................................16-1
Tina Hudson
	17	 Transistors in Amplifier Circuits.................................................................. 17-1
Tina Hudson
	18	 A Simplistic Approach to the Analysis of Transistor Amplifiers.................18-1
Bogdan M. Wilamowski and J. David Irwin
	19	 Analog and Digital VLSI Design...................................................................19-1
Vishal Saxena and R. Jacob Baker
Part III  Digital Circuits
	20	 Digital Design—Combinational Logic..........................................................20-1
Buren Earl Wells and Sin Ming Loo
	21	 Digital Design—Sequential Logic.................................................................. 21-1
Sin Ming Loo and Arlen Planting
	22	 Soft-Core Processors......................................................................................22-1
Arlen Planting and Sin Ming Loo
	23	 Computer Architecture..................................................................................23-1
Victor P. Nelson
	24	 FPGAs and Reconfigurable Systems..............................................................24-1
Juan J. Rodriguez-Andina and Eduardo de la Torre
© 2011 by Taylor and Francis Group, LLC

Contents 
ix
Part IV  Digital and Analog Signal Processing
	25	 Signal Processing............................................................................................25-1
James A. Heinen and Russell J. Niederjohn
	26	 Analog Filter Synthesis..................................................................................26-1
Nam Pham and Bogdan M. Wilamowski
	27	 Active Filter Implementation......................................................................... 27-1
Nam Pham, Bogdan M. Wilamowski, and John W. Steadman
	28	 Designing Passive Filters with Lossy Elements.............................................28-1
Marcin Jagiela and Bogdan M. Wilamowski
Part V  Electromagnetics
	29	 Electromagnetic Fields I................................................................................29-1
Sadasiva M. Rao, Tyler N. Killian, and Michael E. Baginski
	30	 Propagating Electromagnetic Fields..............................................................30-1
Michael E. Baginski, Sadasiva M. Rao, and Tyler N. Killian
	31	 Transmission Line Time-Domain Analysis and Signal Integrity................. 31-1
Edward Wheeler, Jianjian Song, and David R. Voltmer
Index..................................................................................................................Index-1
© 2011 by Taylor and Francis Group, LLC

xi
Preface
The field of industrial electronics covers a plethora of problems that must be solved in industrial practice. 
Electronic systems control many processes that begin with the control of relatively simple devices like 
electric motors, through more complicated devices such as robots, to the control of entire fabrication 
processes. An industrial electronics engineer deals with many physical phenomena as well as the sensors 
that are used to measure them. Thus, the knowledge required by this type of engineer is not only tra-
ditional electronics but also specialized electronics, for example, that required for high-power applica-
tions. The importance of electronic circuits extends well beyond their use as a final product in that they 
are also important building blocks in large systems, and thus the industrial electronics engineer must 
also possess knowledge of the areas of control and mechatronics. Since most fabrication processes are 
relatively complex, there is an inherent requirement for the use of communication systems that not only 
link the various elements of the industrial process but are also tailor-made for the specific industrial 
environment. Finally, the efficient control and supervision of factories require the application of intelli-
gent systems in a hierarchical structure to address the needs of all components employed in the produc-
tion process. This is accomplished through the use of intelligent systems such as neural networks, fuzzy 
systems, and evolutionary methods. The Industrial Electronics Handbook addresses all these issues and 
does so in five books outlined as follows:
	
1.	 Fundamentals of Industrial Electronics
	
2.	 Power Electronics and Motor Drives
	
3.	 Control and Mechatronics
	
4.	 Industrial Communication Systems
	
5.	 Intelligent Systems
The editors have gone to great lengths to ensure that this handbook is as current and up to date as pos-
sible. Thus, this book closely follows the current research and trends in applications that can be found 
in IEEE Transactions on Industrial Electronics. This journal is not only one of the largest engineering 
publications of its type in the world, but also one of the most respected. In all technical categories in 
which this journal is evaluated, its worldwide ranking is either number 1 or number 2 depending on 
category. As a result, we believe that this handbook, which is written by the world’s leading researchers 
in the field, presents the global trends in the ubiquitous area commonly known as industrial electronics.
Fundamentals of Industrial Electronics deals with the fundamental areas that form the basis for 
the field of industrial electronics. Because of the breadth of this field, the knowledge required spans a 
wide spectrum of technology, which includes analog and digital circuits, electronics, electromagnetic 
machines, and signal processing. The knowledge gained here is then applied in Power Electronics and 
Motor Drives, Control and Mechatronics, Industrial Communication Systems, and Intelligent Systems, 
and in total form the Industrial Electronics Handbook.
© 2011 by Taylor and Francis Group, LLC

xii 
Preface
For MATLAB• and Simulink• product information, please contact
The MathWorks, Inc.
3 Apple Hill Drive
Natick, MA, 01760-2098 USA
Tel: 508-647-7000
Fax: 508-647-7001
E-mail: info@mathworks.com
Web: www.mathworks.com
© 2011 by Taylor and Francis Group, LLC

xiii
Acknowledgments
The editors wish to express their heartfelt thanks to their wives Barbara Wilamowski and Edie Irwin for 
their help and support during the execution of this project.
© 2011 by Taylor and Francis Group, LLC

xv
Editorial Board
Jake Baker
Boise State University
Boise, Idaho
Alicja Konczakowska
Gdansk University of Technology
Gdansk, Poland
Victor P. Nelson
Auburn University
Auburn, Alabama
Guofu Niu
Auburn University
Auburn, Alabama
John W. Steadman
University of South Alabama
Mobile, Alabama
© 2011 by Taylor and Francis Group, LLC

xvii
Editors
Bogdan M. Wilamowski received his MS in computer engineering in 
1966, his PhD in neural computing in 1970, and Dr. habil. in integrated 
circuit design in 1977. He received the title of full professor from the 
president of Poland in 1987. He was the director of the Institute of 
Electronics (1979–1981) and the chair of the solid state electronics 
department (1987–1989) at the Technical University of Gdansk, 
Poland. He was a professor at the University of Wyoming, Laramie, 
from 1989 to 2000. From 2000 to 2003, he served as an associate 
director at the Microelectronics Research and Telecommunication 
Institute, University of Idaho, Moscow, and as a professor in the elec-
trical and computer engineering department and in the computer sci-
ence department at the same university. Currently, he is the director 
of ANMSTC—Alabama Nano/Micro Science and Technology Center, Auburn, and an alumna professor 
in the electrical and computer engineering department at Auburn University, Alabama. Dr. Wilamowski 
was with the Communication Institute at Tohoku University, Japan (1968–1970), and spent one year at 
the Semiconductor Research Institute, Sendai, Japan, as a JSPS fellow (1975–1976). He was also a visiting 
scholar at Auburn University (1981–1982 and 1995–1996) and a visiting professor at the University of 
Arizona, Tucson (1982–1984). He is the author of 4 textbooks, more than 300 refereed publications, and 
has 27 patents. He was the principal professor for about 130 graduate students. His main areas of interest 
include semiconductor devices and sensors, mixed signal and analog signal processing, and computa-
tional intelligence.
Dr. Wilamowski was the vice president of the IEEE Computational Intelligence Society (2000–2004) 
and the president of the IEEE Industrial Electronics Society (2004–2005). He served as an associate edi-
tor of IEEE Transactions on Neural Networks, IEEE Transactions on Education, IEEE Transactions on 
Industrial Electronics, the Journal of Intelligent and Fuzzy Systems, the Journal of Computing, and the 
International Journal of Circuit Systems and IES Newsletter. He is currently serving as the editor in chief 
of IEEE Transactions on Industrial Electronics.
Professor Wilamowski is an IEEE fellow and an honorary member of the Hungarian Academy of 
Science. In 2008, he was awarded the Commander Cross of the Order of Merit of the Republic of Poland 
for outstanding service in the proliferation of international scientific collaborations and for achieve-
ments in the areas of microelectronics and computer science by the president of Poland.
© 2011 by Taylor and Francis Group, LLC

xviii 
Editors
J. David Irwin received his BEE from Auburn University, Alabama, 
in 1961, and his MS and PhD from the University of Tennessee, 
Knoxville, in 1962 and 1967, respectively.
In 1967, he joined Bell Telephone Laboratories, Inc., Holmdel, New 
Jersey, as a member of the technical staff and was made a supervisor 
in 1968. He then joined Auburn University in 1969 as an assistant 
professor of electrical engineering. He was made an associate profes-
sor in 1972, associate professor and head of department in 1973, and 
professor and head in 1976. He served as head of the Department of 
Electrical and Computer Engineering from 1973 to 2009. In 1993, 
he was named Earle C. Williams Eminent Scholar and Head. From 
1982 to 1984, he was also head of the Department of Computer Science and Engineering. He is currently 
the Earle C. Williams Eminent Scholar in Electrical and Computer Engineering at Auburn.
Dr. Irwin has served the Institute of Electrical and Electronic Engineers, Inc. (IEEE) Computer 
Society as a member of the Education Committee and as education editor of Computer. He has served 
as chairman of the Southeastern Association of Electrical Engineering Department Heads and the 
National Association of Electrical Engineering Department Heads and is past president of both the 
IEEE Industrial Electronics Society and the IEEE Education Society. He is a life member of the IEEE 
Industrial Electronics Society AdCom and has served as a member of the Oceanic Engineering Society 
AdCom. He served for two years as editor of IEEE Transactions on Industrial Electronics. He has served 
on the Executive Committee of the Southeastern Center for Electrical Engineering Education, Inc., 
and was president of the organization in 1983–1984. He has served as an IEEE Adhoc Visitor for ABET 
Accreditation teams. He has also served as a member of the IEEE Educational Activities Board, and 
was the accreditation coordinator for IEEE in 1989. He has served as a member of numerous IEEE com-
mittees, including the Lamme Medal Award Committee, the Fellow Committee, the Nominations and 
Appointments Committee, and the Admission and Advancement Committee. He has served as a mem-
ber of the board of directors of IEEE Press. He has also served as a member of the Secretary of the Army’s 
Advisory Panel for ROTC Affairs, as a nominations chairman for the National Electrical Engineering 
Department Heads Association, and as a member of the IEEE Education Society’s McGraw-Hill/Jacob 
Millman Award Committee. He has also served as chair of the IEEE Undergraduate and Graduate 
Teaching Award Committee. He is a member of the board of governors and past president of Eta Kappa 
Nu, the ECE Honor Society. He has been and continues to be involved in the management of several 
international conferences sponsored by the IEEE Industrial Electronics Society, and served as general 
cochair for IECON’05.
Dr. Irwin is the author and coauthor of numerous publications, papers, patent applications, and 
presentations, including Basic Engineering Circuit Analysis, 9th edition, published by John Wiley & 
Sons, which is one among his 16 textbooks. His textbooks, which span a wide spectrum of engineering 
subjects, have been published by Macmillan Publishing Company, Prentice Hall Book Company, John 
Wiley & Sons Book Company, and IEEE Press. He is also the editor in chief of a large handbook pub-
lished by CRC Press, and is the series editor for Industrial Electronics Handbook for CRC Press.
Dr. Irwin is a fellow of the American Association for the Advancement of Science, the American 
Society for Engineering Education, and the Institute of Electrical and Electronic Engineers. He 
received an IEEE Centennial Medal in 1984, and was awarded the Bliss Medal by the Society of 
American Military Engineers in 1985. He received the IEEE Industrial Electronics Society’s Anthony 
J. Hornfeck Outstanding Service Award in 1986, and was named IEEE Region III (U.S. Southeastern 
Region) Outstanding Engineering Educator in 1989. In 1991, he received a Meritorious Service 
Citation from the IEEE Educational Activities Board, the 1991 Eugene Mittelmann Achievement 
Award from the IEEE Industrial Electronics Society, and the 1991 Achievement Award from the IEEE 
Education Society. In 1992, he was named a Distinguished Auburn Engineer. In 1993, he received the 
IEEE Education Society’s McGraw-Hill/Jacob Millman Award, and in 1998 he was the recipient of the 
© 2011 by Taylor and Francis Group, LLC

Editors 
xix
IEEE Undergraduate Teaching Award. In 2000, he received an IEEE Third Millennium Medal and 
the IEEE Richard M. Emberson Award. In 2001, he received the American Society for Engineering 
Education’s (ASEE) ECE Distinguished Educator Award. Dr. Irwin was made an honorary profes-
sor, Institute for Semiconductors, Chinese Academy of Science, Beijing, China, in 2004. In 2005, he 
received the IEEE Education Society’s Meritorious Service Award, and in 2006, he received the IEEE 
Educational Activities Board Vice President’s Recognition Award. He received the Diplome of Honor 
from the University of Patras, Greece, in 2007, and in 2008 he was awarded the IEEE IES Technical 
Committee on Factory Automation’s Lifetime Achievement Award. In 2010, he was awarded the elec-
trical and computer engineering department head’s Robert M. Janowiak Outstanding Leadership and 
Service Award. In addition, he is a member of the following honor societies: Sigma Xi, Phi Kappa Phi, 
Tau Beta Pi, Eta Kappa Nu, Pi Mu Epsilon, and Omicron Delta Kappa.
© 2011 by Taylor and Francis Group, LLC

xxi
Contributors
Michael E. Baginski
Department of Electrical and Computer 
Engineering
Auburn University
Auburn, Alabama
R. Jacob Baker
Department of Electrical and Computer 
Engineering
Boise State University
Boise, Idaho
Carlotta A. Berry
Department of Electrical and Computer 
Engineering
Rose-Hulman Institute of Technology
Terre Haute, Indiana
Carles Cané
National Microelectronics Center
Barcelona, Spain
Luis Castañer
Department of Electronic Engineering
Polytechnic University of Catalonia
Catalonia, Spain
John M. Dell
Microelectronics Research Group
University of Western Australia
Perth, Western Australia, Australia
Lorenzo Faraone
Microelectronics Research Group
University of Western Australia
Perth, Western Australia, Australia
Montserrat Fernández-Bolaños
Ecole Polytechnique Fédérale de Lausanne
Lausanne, Switzerland
Stephen M. Haddock
Department of Electrical and Computer 
Engineering
Auburn University
Auburn, Alabama
James A. Heinen
Department of Electrical and Computer 
Engineering
Marquette University
Milwaukee, Wisconsin
Tina Hudson
Department of Electrical and Computer 
Engineering
Rose-Hulman Institute of Technology
Terre Haute, Indiana
Francisco Ibáñez
European Commission
Brussels, Belgium
© 2011 by Taylor and Francis Group, LLC

xxii 
Contributors
Adrian Ionescu
Ecole Polytechnique Fédérale de Lausanne
Lausanne, Switzerland
J. David Irwin
Department of Electrical and Computer 
Engineering
Auburn University
Auburn, Alabama
Marcin Jagiela
Faculty of Applied Informatics
University of Information Technology 
and Management in Rzeszów
Rzeszów, Poland
Tyler N. Killian
Department of Electrical and Computer 
Engineering
Auburn University
Auburn, Alabama
Ernest M. Kim
Department of Engineering
University of San Diego
San Diego, California
Alicja Konczakowska
Faculty of Electronics, Telecommunications 
and Informatics
Gdansk University of Technology
Gdansk, Poland
Robert Lempkowski
Motorola Applied Research and Technology Center
Schaumburg, Illinois
Sin Ming Loo
Department of Electrical and Computer 
Engineering
Boise State University
Boise, Idaho
Antonio Luque
Department of Electronic Engineering
University of Seville
Sevilla, Spain
Dalton S. Nelson
Department of Electrical and Computer 
Engineering
The University of Alabama at Birmingham
Birmingham, Alabama
Victor P. Nelson
Department of Electrical and Computer 
Engineering
Auburn University
Auburn, Alabama
Russell J. Niederjohn (deceased)
Department of Electrical and Computer 
Engineering
Marquette University
Milwaukee, Wisconsin
Guofu Niu
Department of Electrical and Computer 
Engineering
Auburn University
Auburn, Alabama
Nam Pham
Department of Electrical and Computer 
Engineering
Auburn University
Auburn, Alabama
Arlen Planting
Department of Electrical and Computer 
Engineering
Boise State University
Boise, Idaho
José M. Quero
Department of Electronic Engineering
University of Seville
Sevilla, Spain
Sadasiva M. Rao
Department of Electrical and Computer 
Engineering
Auburn University
Auburn, Alabama
© 2011 by Taylor and Francis Group, LLC

Contributors 
xxiii
Angel Rodríguez
Department of Electronic Engineering
Polytechnic University of Catalonia
Catalonia, Spain
Juan J. Rodriguez-Andina
Department of Electronic Technology
University of Vigo
Vigo, Spain
Vishal Saxena
Department of Electrical and Computer 
Engineering
Boise State University
Boise, Idaho
Thomas F. Schubert, Jr.
Department of Engineering
University of San Diego
San Diego, California
Jianjian Song
Department of Electrical and Computer 
Engineering
Rose-Hulman Institute of Technology
Terre Haute, Indiana
John W. Steadman
College of Engineering
University of South Alabama
Mobile, Alabama
Eduardo de la Torre
Center of Industrial Electronics
Polytechnic University of Madrid
Madrid, Spain
David R. Voltmer
Department of Electrical and Computer 
Engineering
Rose-Hulman Institute of Technology
Terre Haute, Indiana
Deborah J. Walter
Department of Electrical and Computer 
Engineering
Rose-Hulman Institute of Technology
Terre Haute, Indiana
Buren Earl Wells
Department of Electrical and Computer 
Engineering
The University of Alabama in Huntsville
Huntsville, Alabama
Edward Wheeler
Department of Electrical and Computer 
Engineering
Rose-Hulman Institute of Technology
Terre Haute, Indiana
Bogdan M. Wilamowski
Department of Electrical and Computer 
Engineering
Auburn University
Auburn, Alabama
Tiantian Xie
Department of Electrical and Computer 
Engineering
Auburn University
Auburn, Alabama
© 2011 by Taylor and Francis Group, LLC

1-1
1.1  Introduction
Direct current (DC) circuit analysis is the study of circuits with a constant voltage or current source. The 
most popular example of a DC circuit is a battery and a light bulb. A DC circuit contains an active circuit 
element (i.e., battery) capable of generating electric energy. These electric sources convert nonelectric 
energy to electric energy (i.e., a voltage or current). Independent electric sources produce a constant 
voltage or current in the circuit regardless of the current through or voltage across the source. The sym-
bols for an ideal DC voltage and current source are shown in Figure 1.1. It should be noted that an ideal 
voltage and current source can deliver or absorb power to an electric circuit. An example of an ideal 
voltage source absorbing power is a rechargeable battery.
Dependent sources establish a voltage or current in a circuit that is based upon the value of a voltage 
or current elsewhere in the circuit. One use of dependent sources is to model operational amplifiers and 
transistors. Table 1.1 presents a summary of the four types of dependent sources.
A passive circuit element models devices that cannot generate electric energy such as a light bulb. 
The most common passive circuit elements are inductors, capacitors, and resistors. The voltage–current 
relationships for these devices will be described in the subsequent section.
1.1.1  Ohm’s Law
Ohm’s law states that the voltage (V) difference across a resistor is linearly related to the current (I) 
through the resistor (see Equation 1.1):
	
V
IR
=
	
(1.1)
1
DC and Transient 
Circuit Analysis
1.1	
Introduction....................................................................................... 1-1
Ohm’s Law  •  Inductors and Capacitors  •  Kirchhoff’s 
Current Law  •  Kirchhoff’s Voltage Law  •  Series and Parallel 
Relationships  •  Voltage and Current Divider Rule  •  Delta–Wye 
(Δ–Y) Transformations
1.2	
Systematic Circuit Analysis Techniques........................................ 1-7
Node-Voltage Method  •  Mesh-Current Method  •  Superposition
1.3	
Circuit Modeling Techniques.........................................................1-16
Source Transformations  •  Thevenin and Norton Equivalent 
Circuits  •  Maximum Power Transfer
1.4	
Transient Analysis........................................................................... 1-19
First-Order Circuits  •  Second-Order Circuits
1.5	
Conclusions...................................................................................... 1-36
Bibliography................................................................................................. 1-36
Carlotta A. Berry
Rose-Hulman Institute 
of Technology
Deborah J. Walter
Rose-Hulman Institute 
of Technology
© 2011 by Taylor and Francis Group, LLC

1-2 
Fundamentals of Industrial Electronics
where R is the resistance of the resistor in Ohms (Ω). The conductance 
(G) of a resistor is the inverse of the resistance (1/R) and is in units of 
Siemens (S). Resistors always absorb power, so the standard way to rep-
resent a resistive element is to draw the resistor in the passive sign con-
vention (see Figure 1.2). If the resistor is not drawn in the passive sign 
convention, then V = −IR.
1.1.2  Inductors and Capacitors
As previously stated, the other two passive circuit elements are inductors and capacitors. Both the 
inductor and the capacitor have the ability to store energy. Inductors store energy in the form of current 
and capacitors store energy in the form of voltage. The energy stored in these elements is released back 
into the circuit when a DC source is removed. Therefore, these two elements exhibit behavior that is a 
function of time. The analysis of these types of circuits is transient analysis that will be addressed later 
in this chapter. Table 1.2 describes the current–voltage relationship for inductors and capacitors where 
the inductance (L) is in henrys (H), capacitance (C) is in farads (F), and time (t) is in seconds (s).
1.1.3  Kirchhoff’s Current Law
The law of conservation of energy states that energy can neither be created nor destroyed, only trans-
ferred. Another way to state this law is for any electric circuit, the total power delivered by the elements 
must be equal to the total power absorbed by the elements. Kirchhoff’s current law (KCL) is based upon 
the law of conservation of energy. A node in a circuit is any point at which two or more circuit elements 
are connected. KCL states that the sum of currents entering a node is zero (i.e., current in = current out). 
KCL can be applied to any node in a closed circuit. The circuit in Figure 1.3 has three branch currents: 
I1, I2, and I3. Since all of these currents are leaving Node A, KCL at this node yields Equation 1.6:
	
I
I
I
1
2
3
0
+
+
=
	
(1.2)
TABLE 1.1  Summary of Dependent Sources
Element
Description
Symbols
Current-controlled 
current source (CCCS)
Establishes a current in the 
circuit based upon the 
value of controlling 
variable, Ix , and the gain α
αIx
Voltage-controlled 
voltage source (VCVS)
Establishes a voltage in the 
circuit based upon the 
value of controlling 
variable, Vx , and the gain β
+
βVx
–
Voltage-controlled 
current source (VCCS)
Establishes a current in the 
circuit based upon the 
value of controlling 
variable, Vx , and the gain μ
μVx
Current-controlled 
voltage source (CCVS)
Establishes a voltage in the 
circuit based upon the 
value of controlling 
variable, Ix , and the gain ρ
ρIx
+
–
Vs
(a)
Is
(b)
FIGURE 
1.1  Ideal 
DC 
sources. (a) Voltage source. 
(b) Current source.
© 2011 by Taylor and Francis Group, LLC

DC and Transient Circuit Analysis 
1-3
1.1.4  Kirchhoff’s Voltage Law
Kirchhoff’s voltage law (KVL) is also based upon the law of conservation 
of energy. A loop is any closed path in a circuit. KVL states that the sum 
of the voltages around a loop is zero (i.e., sum of the voltage drops = 
sum of the voltage rises). KVL is applied to the loop shown in Figure 1.4. 
Note that the direction of the loop goes from the negative terminal to the 
I
+
V
R
–
FIGURE 1.2  Resistor.
TABLE 1.2  Inductor and Capacitor Current–Voltage Relationships
Element
Circuit Symbol
Relationship
Inductor
i
+
–
v
L
v
L di
dt
=
	
(1.3)
i
L
vdt
i
t
=
+
∫
1
0
0
( )
	
(1.4)
Capacitor
i
+
–
V
C
i
C dv
dt
=
	
(1.5)
v
C
idt
v
t
=
+
∫
1
0
0
( ) 	
(1.6)
Vs
+
–
I1
I2
I3
R1
R2
R3
A
FIGURE 1.3  KCL at Node A.
Vs
V1
Loop A
R1
R2
R3
V2
+
+
+
–
–
–
FIGURE 1.4  KVL applied around Loop A.
© 2011 by Taylor and Francis Group, LLC

1-4 
Fundamentals of Industrial Electronics
positive terminal on the voltage source, which indicates it is a voltage rise. For the KVL expression in 
Equation 1.7, voltage rises are negative and voltage drops are positive:
	
−
+
+
=
V
V
V
s
1
2
0 	
(1.7)
Example 1.1:  DC Circuit Analysis with Independent Sources
For the circuit shown in Figure 1.5, apply Ohm’s law, KVL, and KCL to solve for the labeled voltages and 
currents.
The first step in the analysis is to apply KCL at Node A and KVL at the left and right loop. These equa-
tions are provided in Equations 1.8 through 1.10:
	
KCL at Node A :
−
+
+
=
I
I
I
s
2
3
0 	
(1.8)
	
KVL at left loop :
−
+
+
=
120
0
1
2
V
V
	
(1.9)
	
KVL at right loop :
−
+
+
=
V
V
V
2
3
4
0 	
(1.10)
Next, use Ohm’s law to rewrite Equations 1.9 and 1.10 in terms of the branch currents and resistor values. 
These equations are shown in Equations 1.11 and 1.12:
	
KVL at left loop: 50
100
120
2
I
I
s +
=
	
(1.11)
	
KVL at right loop:
−
+
+
=
100
20
80
0
2
3
3
I
I
I
	
(1.12)
Solving the simultaneous set of equations, (1.8), (1.11), and (1.12) yields
	
I
I
I
s =
=
=
1 2
0 6
0 6
2
3
.
,
.
,
.
A
A
A 	
(1.13)
The results in (1.13) and Ohm’s law can be used to find the unknown voltages:
	
V
Is
1
50
60
=
=
V 	
(1.14)
	
V
I
2
100
60
=
=
2
V 	
(1.15)
	
V
I
3
V
 = 20  = 12 
3
	
(1.16)
	
V
I
4 = 80  = 48 V
3
	
(1.17)
120 V
+
–
–
–
–
–
+
+
+
+
I2
I3
Is
V1
A
50 Ω
20 Ω
80 Ω
100 Ω
V3
V2
V4
FIGURE 1.5  DC circuit with independent sources.
© 2011 by Taylor and Francis Group, LLC

DC and Transient Circuit Analysis 
1-5
1.1.5  Series and Parallel Relationships
At times, it is useful to simplify resistive networks by combining resistors in series and parallel into an 
equivalent resistance. Exactly two resistors that are connected at a single node share the same current 
and are said to be connected in series. It is important to note that the equivalent resistance of series resis-
tors is larger than each of the individual resistances. Resistors that are connected together at a pair of 
nodes (“single node pair”) have the same voltage and are said to be connected in parallel. The equivalent 
conductance of resistors in parallel is the sum of the conductances of the individual resistors. Therefore, 
the reciprocal of the equivalent resistance is the sum of the individual conductances. Note that the 
equivalent resistance of parallel resistors is smaller than each of the individual resistances. Figure 1.6a 
provides an example of a circuit with series resistors and the equivalent resistance seen by the voltage 
source. Figure 1.6b provides an example of a circuit with parallel resistors and the equivalent resistance 
seen by the current source.
Example 1.2:  Analysis of Example  1.1 by Combining Resistors
It is possible to analyze the circuit in Example 1.1, to find the source current, Is. The first step is to recognize 
that the 80 and 20 Ω resistors are in series and combine to yield 100 Ω. This simplified circuit is shown 
in Figure 1.7.
The next step is to note that the two 100 Ω resistors are in parallel. Combine these two resistors to 
yield the equivalent resistance of 50 Ω (see Figure 1.8).
The last simplification is to note that the 50 Ω resistors in Figure 1.8 are in series and yield the equiva-
lent resistance of 100 Ω (see Figure 1.9).
Vs
+
–
16 Ω
12 Ω
4 Ω
(a)
(b)
Is
96 Ω
120 Ω
80 Ω
Req=16+12+4=32 Ω
1 +
96
Req=
1
(–1)
= 32 Ω
80
1 +
120
FIGURE 1.6  Resistors in (a) series and (b) parallel.
120 V
+
–
Is
50 Ω
100 Ω
100 Ω
FIGURE 1.7  Circuit in Example 1.1 simplified by putting 80 W in series with 20 W.
© 2011 by Taylor and Francis Group, LLC

1-6 
Fundamentals of Industrial Electronics
Finally, the last step is to use Ohm’s law to solve Is, which yields
	
Is =
=
120
100
1 2. A
	
(1.18)
Note that this result is consistent with the answer to Example 1.1.
1.1.6  Voltage and Current Divider Rule
Given a set of series resistors with a voltage sourced across them, 
the voltage across each individual resistor divides in direct pro-
portion to the value of the resistor. This relationship is referred to 
as the voltage divider rule and it can be derived from KVL. Given 
a set of parallel resistors with a current sourced through them, the 
current through each individual resistor divides inversely pro-
portional to the value of the resistor. This relationship is defined 
as the current divider rule and it can be derived from KCL. These 
two rules are shown for the circuits in Figure 1.6 and are shown 
in Figure 1.10.
Example 1.3:  Analysis of Example 1.1 Using Voltage and Current Divider
For the circuit in Figure 1.5, given that Is = 1.2 A, use the current divider to find I2 and the voltage divider to 
find V4. The first step in the analysis is to recognize that the 100 Ω resistor is in parallel with the 80 and 20 
Ω series combination. The current divider relationship to find I2 is shown in Equation 1.19:
	
I
Is
2
100 80
20
100
0 6
=
+
=
(
)
. A
	
(1.19)
120 V
+
–
Is
50 Ω
50 Ω
FIGURE 1.8  Circuit in Figure 1.7 simpli-
fied by putting 100 W resistors in parallel.
120 V
+
–
Is
100 Ω
FIGURE 1.9  Circuit in Figure 1.8 
simplified by putting 50 W resistors in 
series.
8  V
+
–
16 Ω
12 Ω
4 Ω
48 mA
96 Ω
120 Ω
80 Ω
16
(16+12+4)8
V16Ω=
=4 V
16
(16+12+4)8
V12Ω=
=3 V
4
(16+12+4)8
V4Ω=
=1 V
(a)
96||120||80
96
I96Ω=
48 = 16 mA
96||120||80
120
=
48 = 12.8 mA
96||120||80
80
=
48 = 19.2 mA
I120Ω
I80Ω
(b)
FIGURE 1.10  Voltage and current divider rule for circuits in Figure 1.6. (a) Series circuit (voltage divider). 
(b) Parallel circuit (current divider).
© 2011 by Taylor and Francis Group, LLC

DC and Transient Circuit Analysis 
1-7
Ohm’s law can be used to find the voltage, V2, across the 100 Ω resistor, V2 = 100I2 = 60  V. The voltage 
divider can be used to find the voltage, V4, as shown in Equation 1.20:
	
V
V
4
2
80
80
20
48
=
+
=
V
	
(1.20)
Note that these results are consistent with the solution to Example 1.1.
1.1.7  Delta–Wye (Δ–Y) Transformations
There are some resistance configurations that are neither in series or parallel. These special configura-
tions are referred to as delta (“Δ”) or wye (“Y”) interconnections. These two configurations are equiva-
lent based upon the relationships shown in Table 1.3. Equivalence means that both configurations 
have the same voltage and current characteristics at terminals a, b, however internal to the network, 
the values may not be the same.
1.2  Systematic Circuit Analysis Techniques
There are two general approaches to solving circuits using systematic techniques. The systematic tech-
niques are the node-voltage method based on KCL and the mesh-current method based on KVL. These 
techniques are used to derive the minimum number of linearly independent equations necessary to find 
the solution.
1.2.1  Node-Voltage Method
The node-voltage method is a general technique that can be applied to any circuit. An independent KCL 
equation can be written at every essential node (nodes with three or more elements connected) except 
for one. The standard practice is to choose the ground node as the reference node and omit the ground 
TABLE 1.3  Delta–Wye (Δ–Y) Transformations
Δ Configuration
Y Configuration
Rc
Ra
Rb
a
b
c
R3
R2
R1
a
b
c
R
R R
R R
R R
R
a =
+
+
1
2
2
3
3
1
1
R
R R
R
R
R
b
c
a
b
c
1 =
+
+
R
R R
R R
R R
R
b =
+
+
1
2
2
3
3
1
2
R
R R
R
R
R
a
c
a
b
c
2 =
+
+
R
R R
R R
R R
R
c =
+
+
1
2
2
3
3
1
3
R
R R
R
R
R
a
b
a
b
c
3 =
+
+
© 2011 by Taylor and Francis Group, LLC

1-8 
Fundamentals of Industrial Electronics
node from the set of equations. Next, each essential node is labeled with a voltage variable (V1, V2, etc.). 
The node voltage represents the positive voltage difference at the labeled node with respect to the refer-
ence node. A KCL equation is written summing the currents leaving the node in terms of the unknown 
node voltages. Lastly, this set of linearly independent equations is solved for the unknown node voltages. 
Finally, the node voltages can be used to find any current in the circuit.
Example 1.4:  Node-Voltage Method with Independent Sources
Given the circuit in Figure 1.11, use the node-voltage method to find the power delivered by 
each source.
Recall that the first step in the analysis was to label the essential nodes. The four essential nodes in 
Figure 1.11 have already been labeled as V1, V2, V3, and ground (0 V). Since V1 is the voltage at that node 
with respect to the reference node (“ground node”), it is tied to the 200 V source so V1 = 200 V. The node 
voltages V2 and V3 are unknown, thus KCL must be performed to find these values. In order to simplify 
analysis, the KCL equations are derived such that the current is drawn leaving the node if it is not given. 
The KCL equations at V2 and V3 are given in Equations 1.21 and 1.22:
	
KCL at V
I
I
I
V
V
V
V
V
2
500
250
400
2
1
2
2
3
500
250
400
0
:
Ω
Ω
Ω
+
+
=
−
+
+
−
=
	
(1.21)
	
KCL at 
100
V
I
I
V
V
V
V
3 :
Ω
Ω
+
−=
−
+
−
−=
400
3
1
3
2
1
100
400
1 0
	
(1.22)
By substituting V1 = 200 into Equations 1.21 and 1.22, and solving the simultaneous system of equations 
yields
	
V
V
V
1
2
3
 = 200 V, 
 = 125 V,      
 = 265 V 	
(1.23)
Using the results of Equation 1.23, it is possible to find the power associated with the 1 A current source. 
Since the voltage across the current source is V3, and it is not in the passive sign convention, the power is 
200 V
500 Ω
100 Ω
400 Ω
250 Ω
1 A
V1
V2
V3
+
–
FIGURE 1.11  Node-voltage method circuit.
© 2011 by Taylor and Francis Group, LLC

DC and Transient Circuit Analysis 
1-9
P = −V3 (1) = −265 W or 265 W delivered. In order to find the current through the 200 V source, it is necessary 
to use KCL at V1. The KCL equation at V1 is given in Equation 1.24:
	
KCL at V
I
I
I
I
V
V
V
V
s
s
1:
+
+
=
+
−
+
−
=
500
100
1
2
1
3
500
100
0
Ω
Ω
	
(1.24)
	
Is = 500 mA 	
(1.25)
Since the 200 V source obeys the passive sign convention, the power is P = 100Is =100 W absorbed. In 
order to check that the analysis is correct, the law of conservation can be used to verify that the sum of 
all of the power delivered equals the sum of all of the power absorbed.
Example 1.5:  Analysis of Example 1.4 with 𝚫-Y Transformations
For the circuit in Figure 1.11, use Δ-Y transformations to find the power associated with the 200 V source. 
The first step in the analysis is to identify that the 500, 100, and 400 Ω resistors form a Δ configuration as 
Ra, Rb, and Rc, respectively. This circuit can be simplified by converting the Δ configuration to a Y configu-
ration. Equations 1.26 through 1.28 are used to find the resistor values in the Y configuration. The simpli-
fied circuit is shown in Figure 1.12.
	
R
R R
R
R
R
b
c
a
b
c
1
400 100
500
100
400
40
=
+
+
=
+
+
=
(
)(
)
Ω
	
(1.26)
	
R
R R
R
R
R
c
a
a
b
c
2
400 500
500
100
400
200
=
+
+
=
+
+
=
(
)(
)
Ω
	
(1.27)
	
R
R R
R
R
R
a b
a
b
c
3
500 100
500
100
400
50
=
+
+
=
+
+
=
(
)(
)
Ω
	
(1.28)
In order to find the power associated with the 200 V source, perform KCL at essential Node A. The equa-
tion and solution are shown in Equations 1.29 and 1.30:
	
KCL at V
I
I
I
V
V
V
A
s
A
A
:
+
−=
−
+
−=
+
200
250
1
50
450
1 0
Ω
	
(1.29)
	
VA =  225 V 	
(1.30)
+
200 V
200 Ω
250 Ω
50 Ω
40 Ω
V1
A
1 A
V2
V3
R3
R1
R2
–
FIGURE 1.12  Circuit in Figure 1.11 simplified.
© 2011 by Taylor and Francis Group, LLC

1-10 
Fundamentals of Industrial Electronics
Using the result in Equation 1.30 to find the current through the 200 V source yields
	
I
V
s
A
=
−
=
2
5
5
 mA
00
0
00
	
(1.31)
Thus, the power absorbed by the 200 V source is 100 W, consistent with the prior solution.
Example 1.6:  Node-Voltage Method with Dependent Sources
The circuit in Figure 1.13 models an operational amplifier. An operational amplifier is an active circuit 
element used to perform mathematical operations such as addition, subtraction, multiplication, divi-
sion, differentiation, and integration. This electronic unit is an integrated circuit that can be modeled as 
a VCVS. The gain of the op amp is the ratio of the output voltage to the input voltage, (Vo /Vs ). Use KCL to 
determine the gain of the circuit in Figure 1.13.
The KCL equations at Nodes A and B are shown in Equations 1.32 and 1.33:
	
KCL at 
k
M
k
V
I
I
I
V
V
V
V
V
A
A
s
A
B
A
:
10
2
20
10
20
2
0
Ω
Ω
Ω
+
+
=
−
+
−
+
=
k
k
M
	
(1.32)
	
KCL at 
k
V
I
I
V
V
V
V
B
B
A
B
d
:
50
20
5
20
2 10
50
0
Ω
Ω
+
=
−
+
−×
=
k
	
(1.33)
Note that the dependent source introduces a constraint equation based upon the relationship between 
the node voltage and the controlling voltage, Vd. This relationship is VA = −Vd. This produces two equa-
tions and two unknowns that can be solved for the gain shown in Equation 1.34:
	
V
V
o
s
≈−
= −
20
10
2
k
k
	
(1.34)
A special case of the node-voltage method is when there is a voltage source between two nonreference 
essential nodes (see Figure 1.14).
In this case, an additional unknown variable must be introduced to describe the current in the branch 
with the voltage source. To minimize the number of unknowns, an alternate method to introducing 
another variable is to label the voltage source and any element in parallel with it as a supernode. The 
supernode in Figure 1.14 is denoted by the superimposed oval. The node-voltage method with super-
nodes involves deriving a KCL and KVL equation at the supernode as well as KCL equations at any other 
essential nodes where the voltage is unknown and solving the simultaneous system of equations.
+
10 kΩ
20 kΩ
50 Ω
2 MΩ
2 × 105 Vd
Vo
Vd
Vs
A
B
–
+
+
+
–
–
–
FIGURE 1.13  DC circuit with dependent sources (operational amplifier model).
© 2011 by Taylor and Francis Group, LLC

DC and Transient Circuit Analysis 
1-11
Example 1.7:  Node-Voltage Method with Supernodes
Use the node-voltage method on the circuit in Figure 1.14 to find the current through the voltage source. 
The first step in the analysis is to label the node voltages and supernode. These have already been labeled 
in the circuit in Figure 1.14. Next, KCL at the supernode yields Equation 1.35, and KVL at the supernode 
yields Equation 1.36:
	
KCL at supernode: 2
2
500
100
125
0
500
100
125
1
2
2
+
+
+
=
+
+
+
=
I
I
I
V
V
V
Ω
Ω
Ω
	
(1.35)
	
KVL at supernode
 25 
 
1
2
:
−
+
+
=
V
V
0 	
(1.36)
Solving these two equations and two unknowns yields
	
V1
775 V
= −
.
	
(1.37)
	
V2
1 25 V
= −0 .
	
(1.38)
To find the current through the voltage source, it is necessary to perform KCL at V1 or V2. Since the 
2 A current source is connected to V1, this selection will have one less term with a voltage variable. 
Assuming the current through the voltage source, Is, flows from right to left and applying KCL at V1 yields 
the following equation:
	
KCL at supernode:
 = 2 + 
  + 
 = 2 
 155 m + 100
500
250
I
I
I
s
Ω
Ω
−
 m = 1.945 A 	
(1.39)
1.2.2  Mesh-Current Method
The goal of the mesh-current method is to determine all of the unknown mesh currents in a circuit. 
A mesh is a loop in a circuit that does not contain any other loops. The mesh-current method is only 
applicable to planar circuits, circuits that can be drawn on a plane with no crossing branches. The first 
step in the analysis is to label all of the mesh currents in a circuit. The mesh currents are fictitious cur-
rents that circulate in a mesh. Note that a mesh current may or may not be a branch current, but all of the 
branch currents can be found from the mesh currents. The next step is to write KVL equations summing 
voltage drops around the mesh in terms of the unknown mesh currents. For n meshes, there will be n 
linearly independent mesh-current equations to solve.
+
2 A
25 V
V1
V2
500 Ω
100 Ω
125 Ω
250 Ω
–
FIGURE 1.14  Node-voltage method with a supernode.
© 2011 by Taylor and Francis Group, LLC

1-12 
Fundamentals of Industrial Electronics
Example 1.8:  Mesh-Current Method on Example 1.6
For the circuit in Figure 1.15, use the mesh-current method to determine the output voltage Vo if the 
input voltage Vs = 3 V.
The first step in the analysis is to label the two mesh currents, and this has been done in Figure 1.15. 
The second step is to write the KVL equations around meshes 1 and 2 in terms of the mesh currents, 
I1 and I2 (see Equations 1.40 and 1.41):
	
KVL at mesh 1:
3 + 10
 + 2
 (
) = 0
1
1
2
k
M
I
I
I
−
	
(1.40)
	
KVL at mesh 2: 2
 (
) + 20
 +50  + 2 10  
 = 0
2
1
2
2
5
M
k
I
I
I
I
V
−
×
d
	
(1.41)
Similar to the prior analysis, the dependent source introduces the following constraint equation:
	
constraint:
 = 2
 (
)
V
I
I
d
M
2
1
−
	
(1.42)
Solving these three simultaneous equations for the mesh currents yields
	
I
I
Vd
1
2
A
A
 = 299.997 
,   
 = 300.002  
,  
 = 
30.075  V
µ
µ
µ
−
	
(1.43)
Using the mesh current value to find Vo yields
	
V
I
V
o
d
 = 50  + 2 
 10  
 = 
6 V
5
2
×
−
	
(1.44)
The reader should verify that this gain is consistent with Example 1.6.
A special case of the mesh-current method occurs when a current source is shared between two 
meshes. In this case, it is necessary to introduce another variable to describe the voltage across the 
current source in order to write the KVL equation. An alternate approach is to define the two meshes 
that include the current source and anything in series with it as a supermesh. The 6 A current source 
in series with the 1 Ω resistor in Figure 1.16 creates a supermesh denoted by the superimposed 
rectangle.
In order to analyze a supermesh, it is necessary to perform KVL and KCL at the supermesh. Lastly, write 
a KVL equation for any other unknown mesh currents in the circuit and solve the simultaneous system of 
equations. This method will be demonstrated on the circuit in Figure 1.16.
+
10 kΩ
20 kΩ
50 Ω
2 MΩ
2 × 105 Vd
Vo
Vd
Vs
I1
I2
3 V
A
B
–
–
+
+
+
–
–
FIGURE 1.15  Mesh-current method example.
© 2011 by Taylor and Francis Group, LLC

DC and Transient Circuit Analysis 
1-13
Example 1.9:  Mesh-Current Method with a Supermesh
Use the mesh-current method to find the power associated with the 6 A current source. The first step in 
the analysis is to label the supermesh and mesh currents. These have already been labeled in the circuit 
in Figure 1.16. The next step is to derive the KVL and KCL equations at the supermesh and these are 
shown in Equations 1.45 and 1.46:
	
KVL at supermesh: 
2 + 3  +5
10 + 9  + 7  = 0
2
1
−
−
I
I
I
I
1
2
	
(1.45)
	
KCL at supermesh: 
 
  = 6
2
I
I
1 −
	
(1.46)
Solving this simultaneous set of equations yields
	
I
I
1
2
 = 4 , 
 = 
2 
A
A
−
	
(1.47)
In order to determine the power associated with the 6 A current source, it is necessary to perform KVL 
at the left or right mesh to find the voltage across the current source. Assuming the voltage across the 
current source, Vs, is positive on top and applying KVL at the left mesh yields
	
KVL at mesh 1: 
 = 1(  
 ) 
 3  + 2 
 7  = 
44 V
2
1
1
1
V
I
I
I
I
s
−
−
−
−
	
(1.48)
The 6A current source is drawn in the passive sign convention and since Vs is negative, the power associ-
ated with this source is P = +(–44)(6) = –264 W or 264 W delivered.
1.2.3  Superposition
Superposition applies to linear circuits that have multiple independent sources. The principle of super-
position states that the electrical quantities, voltage or current, due to all the sources acting at the 
+
1 Ω
7 Ω
5 Ω
3 Ω
9 Ω
6 A
10 V
I1
I2
2 V
–
+
–
FIGURE 1.16  Mesh-current method with a supermesh.
© 2011 by Taylor and Francis Group, LLC

1-14 
Fundamentals of Industrial Electronics
same time is equal to the sum of the same quantity due to each source acting alone. The method to 
solve for an unknown variable in a circuit involves solving for the variable of interest for one source 
acting alone by deactivating all the other independent sources, then sum the results for each source 
act­ing alone. To deactivate an independent voltage source, replace the voltage source with a short cir-
cuit (0 V). To deactivate an independent current source, replace the current source with an open 
cir­cuit (0 A). Dependent sources are never deactivated (“turned off ”). The benefit in applying the 
principle of superposition is that many times, the circuit with the deactivated source is simpler to solve 
for the unknown value.
Example 1.10:  Circuit Analysis Using Superposition
For the circuit in Figure 1.16, apply the principle of linear superposition to solve for the unknown branch 
current I1 (see Figure 1.17).
The first step in the analysis is to disable the 6 A and 10 V sources and use KVL to calculate I1. The solu-
tion to this analysis is shown in Equation 1.49. The variable of interest is given a prime to denote that it is 
due to one source acting alone (see Figures 1.18 through 1.20).
	
KVL at mesh 1: 
2 + 3  + 5  +9  + 7  = 0
1
1
1
1
−
I
I
I
I
	
l1’
.
mA
= 83 33
	
(1.49)
+
1 Ω
3 Ω
5 Ω
7 Ω
9 Ω
V1
I1
2 V
–
FIGURE 1.18  Superposition circuit with 2 V source activated.
+
1 Ω
3 Ω
5 Ω
7 Ω
9 Ω
6 A
10 V
I1
2 V
–
+
–
FIGURE 1.17  Superposition circuit for Example 1.10.
© 2011 by Taylor and Francis Group, LLC

DC and Transient Circuit Analysis 
1-15
In the next step, disable the 2 V and 6 A sources and use KVL to calculate I1. The solution to this analysis 
is shown in Equation 1.50:
	
KVL at mesh 1: 3  + 5
10 +9  + 7  = 0
1
1
1
1
I
I
I
I
−
	
l1
416 67
’’
.
mA
=
	
(1.50)
In the next step, disable the 2 and 10 V sources and use KCL at V1 to calculate I1. The solution to this analy-
sis is shown in Equation 1.51:
	
KCL at V
V
V
1:
3
7
1
+
+
+
+
=
6
5
9
0
1
	
V1
V
 = 
35 
−
	
l
V
1
1
0
7
3
3 5
’’’
. A
=
−
+
=
	
(1.51)
Applying the principle of superposition yields
	
l
l
l
l
1
1
1
1
4A
=
+
+
=
’
’’
’’’
	
(1.52)
Note that the value for I1 is consistent with the solution to Example 1.9.
1 Ω
3 Ω
5 Ω
7 Ω
9 Ω
10 V
V1
I1
+
–
FIGURE 1.19  Superposition circuit with 10 V source activated.
1 Ω
3 Ω
5 Ω
7 Ω
6 A
9 Ω
I1
V1
FIGURE 1.20  Superposition circuit with 6 A source activated.
© 2011 by Taylor and Francis Group, LLC

1-16 
Fundamentals of Industrial Electronics
1.3  Circuit Modeling Techniques
Just like it is possible to model the behavior of multiple resistors connected in parallel and series with a 
single equivalent resistance, it is also possible to model resistive circuits containing sources and resistors 
as either a Thevenin or Norton equivalent model. These models are useful simplifying techniques when 
only the circuit behavior at a single port is of interest.
1.3.1  Source Transformations
Source transformations are another simplifying technique for circuit analysis. Source transformations 
are based upon the concept of equivalence of the voltage and current terminal characteristics at a single 
port. A voltage source in series with a resistor can be replaced by a current source in parallel with a resis-
tor if they have the relationships given in Figure 1.21.
1.3.2  Thevenin and Norton Equivalent Circuits
A simple resistive circuit can be simplified to an independent voltage source in series with a resistor and this 
is referred to as the Thevenin equivalent circuit. The voltage source is referred to as the Thevenin voltage, VTH, 
and the resistor is the Thevenin resistance, RTH. In addition, a simple resistive circuit can be simplified to an 
independent current source in parallel with a resistor and this is referred to as the Norton equivalent circuit. 
The current source is the Norton current, IN, and the resistance is the same as the Thevenin resistance. These 
are important simplification techniques when the values of interest are the port characteristics such as the 
voltage, current, or power delivered to a load placed across the terminals. The method to find the Thevenin 
voltage is to determine the open circuit voltage across terminals a and b. The method to find the Norton cur-
rent is to find the short circuit current between terminals a and b. There are several techniques to find the 
Thevenin equivalent resistance. When there are only independent sources, one of the more popular methods 
is to deactivate all independent sources and find the equivalent resistance of the network across terminals 
a and b. Alternately, the Thevenin resistance can be calculated by using the following formula:
	
R
V
I
V
I
oc
sc
TH
N
TH =
=
	
(1.53)
where
Voc represents the open circuit voltage across terminals a and b
Isc represents the short circuit current between terminals a and b
Rs
Vs
a
b
+
–
(a)
(b)
b
a
Rp
Ip
Vs=IpRp
Rs=Rp
Rp= Rs
Vs
Rs
=
Ip
FIGURE 1.21  Source transformation relationships. (a) Series circuit, Vs=IpRp, Rs=Rp and (b) parallel circuit, 
Ip=Vs/Rs, Rp=Rs.
© 2011 by Taylor and Francis Group, LLC

DC and Transient Circuit Analysis 
1-17
Note that when there are dependent sources in the circuit, there is a third technique based upon deacti-
vating all independent sources and using a test voltage or current at terminals a and b to find the equiva-
lent resistance. The reader is encouraged to review this technique for future study.
Example 1.11:  Thevenin Equivalent Resistance
For the circuit in Figure 1.22, determine the Thevenin equivalent resistance to the left of terminals 
a and b.
In order to find the Thevenin equivalent resistance, deactivate the two independent sources and find 
the equivalent resistance to the left of terminals a and b. The circuit in Figure 1.22 is shown in Figure 1.23 
with the sources deactivated.
In the circuit in Figure 1.23, the 10 and 40 Ω resistors are in parallel. This parallel combination is 
in series with the 8 Ω resistor. Equation 1.54 shows the derivation of the Thevenin equivalent resis-
tance, RTH:
	
RTH = 10 || 40 + 8 = 16 Ω	
(1.54)
Example 1.12:  Thevenin and Norton Equivalent Circuits
For the circuit in Figure 1.22, find the Thevenin and Norton 
equivalent circuit to the left of terminals a and b. The first step 
in the analysis is to find the open circuit voltage between 
terminals a and b (VTH = Voc = Va ). Either the node-voltage or 
mesh-current method would be an acceptable technique to 
find this value, however the node-voltage method was used by 
writing the KCL equation at V1 and Va and these are shown in 
Equation 1.55:
	
KCL at V
V
V
V
Va
1
1
:
−
+
+
−
=
60
10
40
8
0
1
1
	
(1.55)
KCL at V
V
V
a
a
:
−
=
1
8
4
4 A
a
b
60 V
V1
10 Ω
+
–
8 Ω
40 Ω
FIGURE 1.22  Circuit for Thevenin equivalent example.
a
b
10 Ω
8 Ω
40 Ω
FIGURE 1.23  Circuit in Figure 1.22 
with independent sources deactivated.
© 2011 by Taylor and Francis Group, LLC

1-18 
Fundamentals of Industrial Electronics
V
V
V
V
TH
oc
a
1 = 80 V, 
 
 = 
 =  = 112 V
The next step in the analysis is to find the short circuit current between terminals a and b (IN = Isc = Iab ). 
The mesh-current method will be used to determine short circuit current, Isc, as shown in Figure 1.24. The 
result of the analysis is shown in Equation 1.56:
	
KVL at : 
60 + 10(  
 4) + 40 (  
 ) = 0
1
1
1
I
I
I
IN
−
−
−
	
(1.56)
	
KVL at : 
40 (  
 ) + 8(  
 4) = 0
1
I
I
I
I
N
N
N
−
−
	
I
I
I
I
N
sc
ab
1 = 7.6 A, 
 = 
 = 
 = 7 A
The Thevenin equivalent resistance can also be found from
	
R
V
I
V
I
TH
oc
sc
TH
N
=
=
=
=
112
7
16 Ω
	
(1.57)
Note that this Thevenin resistance is consistent with Example 1.11. The final step in the result is to 
draw the Thevenin and Norton equivalent circuits to the left of terminals a and b. These are shown 
in Figure 1.25.
4 A
a
b
60 V
V1
10 Ω
8 Ω
40 Ω
+
I1
IN
–
FIGURE 1.24  Circuit in Figure 1.22 with terminals a and b short-circuited.
a
b
112 V
(a)
+
–
VTH
RTH
16 Ω
a
b
7 A
IN
RTH
16 Ω
(b)
FIGURE 1.25  Thevenin and Norton equivalent of circuit in Figure 1.22. (a) Thevenin equivalent. (b) Norton 
equivalent.
© 2011 by Taylor and Francis Group, LLC

DC and Transient Circuit Analysis 
1-19
1.3.3  Maximum Power Transfer
One benefit and purpose for determining the Thevenin (Norton) equivalent of a circuit is to determine 
the power delivered to a load placed across terminals a and b. With the knowledge of the Thevenin and 
Norton equivalent, it is possible to design a circuit or select a load for maximum power transfer to the 
load. It can be shown that if the load resistance is equal to the Thevenin equivalent resistance, then 
maximum power is transferred to the load. Therefore, the condition for maximum power transfer is to 
set the load resistance equal to the Thevenin equivalent resistance. When the load resistance is equal to 
the Thevenin equivalent resistance, the maximum power delivered to the load is
	
P
V
R
L
TH
TH
=
2
4
	
(1.58)
Example 1.13:  Maximum Power Transfer
For the circuit shown in Figure 1.22, determine the value of a load resistor placed across terminals a and b 
for maximum power transfer and calculate the value of the power for the load selected (see Figure 1.26).
Since the Thevenin equivalent resistance of this circuit is 16 Ω, select RL = RTH = 16 Ω for maximum 
power transfer. Finally, the value of the power delivered to the 16 Ω is calculated as follows:
	
P
V
R
L
TH
TH
=
=
=
2
2
4
112
4 16
196
(
)
W
	
(1.59)
1.4  Transient Analysis
Transient analysis describes a circuit’s behavior as a function of time. Since capacitors and inductors 
store energy in the electric or magnetic field, transient analysis focuses on the current and voltage values 
in circuits where energy is either stored by or released by an inductor or a capacitor.
1.4.1  First-Order Circuits
First-order circuits contain resistors and either capacitors or inductors, but not both. These configura-
tions are either RL circuits or RC circuits based upon whether they have resistors and capacitors or 
resistors and inductors, respectively. RL and RC circuits are known as first-order circuits because the 
a
b
60 V
RL
V1
4 A
8 Ω
10 Ω
40 Ω
+
–
FIGURE 1.26  Circuit for maximum power transfer example.
© 2011 by Taylor and Francis Group, LLC

1-20 
Fundamentals of Industrial Electronics
equations that describe these circuits are first-order ordinary differential equations. If a voltage or cur-
rent source is suddenly applied to a first-order circuit (i.e., a switch), then energy will begin to store in 
the capacitor as an electric field or in the inductor as a magnetic field. When a source is instantaneously 
applied, the time-dependent current or voltage in the circuit is called the step response. If the source of 
energy is suddenly removed, then the time-dependent current or voltage in the circuit is called the natu-
ral response. It is important to note that the voltage across a capacitor cannot change instantaneously 
and the current through an inductor cannot change instantaneously. The natural and step response of 
first-order circuits can be found by using circuit analysis techniques such as KVL and KCL to derive the 
first-order differential equation that describes the circuit. Using the initial conditions and differential 
equations, these equations can be solved for voltage and current. In order to find the initial conditions 
for a first-order circuit, it is necessary to draw the circuit under DC conditions before the switching 
occurs. Note that under DC or steady state conditions, inductors can be modeled as short circuits and 
capacitors can be modeled as open circuits. The general form of the solution for a first-order circuit is 
the sum of the transient response and the steady-state response. The transient response is the portion of 
the response that decays over time. The steady-state response is the portion of the response that remains 
after a long time. Furthermore, the general form of the solution can be described as the sum of the natu-
ral response and the forced response. The forced response is the portion due to the independent sources 
and the natural response is due to the energy stored in the circuit. The general solution for natural and 
step responses for first-order circuits is given in Equation 1.60:
	
x t
x
x
x t
x t
x t
steady-state
transient
t
( )
(
)
[ (
0 )
(
)]
/
=
+
=
→∞+
=
−
→∞
+
−
e
τ
x t
x
x
x t
x t
x t
step
natural
t
t
( )
(
)
(
)e
(
)
/
/
=
+
=
→∞−
→∞

+
=
−
+
−
τ
τ
0
e
	
(1.60)
where
τ = RTH C or τ = L/RTH
RTH is equivalent resistance across the inductor or the capacitor
x(t) is either voltage or current
The time constant, τ, is in units of seconds and describes how fast the transient signal settles. At a time 
equal to 5τ, the transient solution will settle to within 1% of the steady-state or final value. The general 
solution can be applied to any RL or RC circuit provided that the initial and final conditions and equiva-
lent resistance seen by the inductor or capacitor can be found.
Example 1.14:  Natural Response of an RL Circuit
For the circuit in Figure 1.27, assume that the switch is in position a for a long time and moves to position 
b at t = 0. Find the current through the inductor, i(t), and the voltage across the inductor, v(t), for t > 0.
a
b
10 V
i(t)
v(t)
t=0
4 Ω
20 Ω
1 Ω
+
–
+
–
100 mH
FIGURE 1.27  RL circuit for Example 1.14.
© 2011 by Taylor and Francis Group, LLC

DC and Transient Circuit Analysis 
1-21
The first step in the analysis is to find the initial conditions for the circuit in Figure 1.27. In order to find 
the initial conditions, redraw the circuit at t = 0− (before the switching occurs) under DC conditions. The 
circuit to find the initial conditions is shown in Figure 1.28. Since an inductor under DC or steady-state 
conditions is modeled as a short circuit, the initial voltage, v(0−), is 0 V. It is modeled as a short circuit 
because the current is constant with time; therefore, the time rate of change of the current (diL/dt) is zero 
and the voltage (vL = L(diL/dt)) over the inductor is 0 V. Using Ohm’s law on the circuit in Figure 1.28, it is 
possible to find the initial current, i(0−) as shown in Equation 1.61. Note that because the inductor is a 
short circuit, the 20 Ω resistor is shorted out and has no affect on the circuit.
	
i(
)
0
10
1
10
−=
=
A
	
(1.61)
Since the voltage across an inductor can change instantaneously, the circuit must also be analyzed 
immediately after switching occurs at t = 0+. For this analysis, model the inductor as a 10 A current source 
because current cannot change instantaneously so i(0+) = i(0−) = 10 A. Next, use KCL to find the voltage 
across the inductor. The circuit is shown in Figure 1.29 and the analysis in Equation 1.62:
	
v(0 ) =
[(4 + 1)||20]10 =
40 V
+
−
−
	
(1.62)
The circuit in Figure 1.29 can also be used to find the time constant, τ = L/RTH, where RTH is the equivalent 
resistance seen by the inductor. Since the 4 and 1 Ω resistors are in series and they are in parallel with the 
20 Ω resistor, RTH is given by Equation 1.63:
	
RTH  = (4 + 1)||20 = 4 Ω	
(1.63)
a
b
10 V
v(0–)
i(0–)
1 Ω
4 Ω
20 Ω
+
+
–
–
FIGURE 1.28  RL circuit at t = 0−.
b
10 A
v(0+)
i(0+)
1 Ω
4 Ω
20 Ω
+
–
FIGURE 1.29  RL circuit at t = 0+.
© 2011 by Taylor and Francis Group, LLC

1-22 
Fundamentals of Industrial Electronics
The time constant is given by Equation 1.64.
	
τ =
=
=
L
RTH
0 1
4
25
.
ms
	
(1.64)
In order to find the final value for the current and voltage, analyze the circuit under steady-state conditions 
a long time after switching occurs. This circuit is shown in Figure 1.30; note that once again the 20 Ω resistor 
is shorted out. Since, it is assumed that the circuit has been in this state for a long time, the current through 
the inductor and voltage across the inductor can be represented as i(∞) and v(∞), respectively. Since the 
inductor is still modeled as a short circuit, thus v(∞) = 0 V and since there are no sources, i(∞) is 0 A.
These values make sense because for the natural response of a first-order circuit, the inductor has 
stored energy in the form of current and over time, it discharges until it is eventually 0 A. Using the gen-
eral solution equation in (1.60) yields
	
i t
i
i
i
t
t
t
( )
( ) [ (
)
( )]
,
/
= ∞+
−∞
=
>
+
−
−
0
10
0
40
e
e
A
τ
	
(1.65)
	
v t
v
v
v
t
t
t
( )
( ) [ (
)
( )]
,
/
=
∞+
−
∞
= −
>
+
−
−
0
40
0
40
e
e
V
τ
b
4 Ω
i(∞)
v(∞)
1 Ω
20 Ω
+
–
FIGURE 1.30  RL circuit at t = ∞.
v(t), V
Time, ms
10
–10
–25
25
50
75
100
125
150
–20
–30
–40
–50
(a)
i(t), A
Time, ms
15
10
5
–5
–25
25
50
75
100
125
150
(b)
0
0
0
0
FIGURE 1.31  Graphs of voltage and current for the inductor in Example 1.14. (a) Voltage across the inductor and 
(b) current through the inductor.
© 2011 by Taylor and Francis Group, LLC

DC and Transient Circuit Analysis 
1-23
The graphs of v(t) ad i(t) are shown in Figure 1.31; note that these are exponentially decaying functions 
to represent the natural response and the fact that the inductor is discharging. Also notice that there is 
a discontinuous step at t = 0 for the voltage across the inductor to denote the change from storing or 
stored energy to releasing energy.
Example 1.15:  Step response of an RC Circuit
For the circuit in Figure 1.32, the switch has been in position a for a long time, and at t = 0, it moves to 
position b Find the voltage across the capacitor, v(t), and the current through the capacitor, i(t), for t > 0.
The first step in the analysis is to find the initial conditions by analyzing the circuit under steady-state 
conditions before switching occurs to find i(0−) and v(0−). Since a capacitor under DC or steady-state condi-
tions is modeled as an open circuit, the initial current, i(0−), is 0 A. It is modeled as an open circuit because 
the voltage is constant with time; therefore, the time rate of change of the voltage (dvC /dt) is zero and 
the current (iC = CdvC /dt) over the inductor is 0 A. The circuit is shown in Figure 1.33 and the analysis using 
Ohm’s law yields Equation 1.66:
	
v(0 ) = (
)(
) = 1 V
−
1
1
m
k
	
(1.66)
Since the current through a capacitor can change instantaneously, the circuit must be analyzed right 
after switching occurs to find i(0+). However, since voltage across a capacitor cannot change instanta-
neously, after switching occurs, the capacitor can be modeled as a 1 V source (i.e., v(0−) = v(0+) = 1 V). 
This circuit is shown in Figure 1.34. KCL can be used to analyze this circuit to find the current through the 
capacitor as shown in Equation 1.67:
	
i(
)
1
12
.
A
0
30
1
6
4 75
+ = −
+
−=
k
k
m
	
(1.67)
a
b
1 mA
0.5 μF
30 V
i(t)
v(t)
t =0
1 kΩ
1 kΩ
6 kΩ
12 kΩ
1 kΩ
+
–
+
–
FIGURE 1.32  RC circuit for Example 1.15.
a
1 mA
i(0–)
v(0–)
1 kΩ
1 kΩ
1 kΩ
+
–
FIGURE 1.33  RC circuit for initial conditions (t = 0−).
© 2011 by Taylor and Francis Group, LLC

1-24 
Fundamentals of Industrial Electronics
The circuit in Figure 1.34 can also be used to find the time constant, τ = RTHC. The equivalent resistance 
across the capacitor can be found by disabling the 30 V source. After deactivating the 30 V source, the 
6 kΩ resistor is in parallel with the 12 kΩ resistor, thus RTH = 4 kΩ. The time constant is τ = RTHC = (4 k)
(0.5 μ) = 2 ms. Finally, to find the steady-state voltage and current for the capacitor, analyze the circuit 
under steady-state conditions a long time after switching occurs. Since the capacitor is modeled as an 
open circuit under steady-state conditions, i(∞) = 0 A. The circuit is shown in Figure 1.35. The final value of 
the capacitor voltage, v(∞), can be found by using the voltage divider as shown in Equation 1.68:
	
v( )
(
)
∞=
+
=
12
12
6 30
20 V
	
(1.68)
Using the general solution for a first-order circuit in Equation 1.60 yields the following equations for v(t) 
and i(t):
	
i t
i
i
i
t
t
t
( )
( ) [ (
)
( )]
.
,
/
= ∞+
−∞
=
>
+
−
−
0
4 75
0
500
e
e
mA
τ
	
(1.69)
	
v t
v
v
v
e
t
t
t
( )
( ) [ (
)
( )]
,
/
=
∞+
−
∞
=
−
>
+
−
−
0
20
19
0
500
τ
e
V
The graphs of the current and voltage for the capacitor are shown in Figure 1.36. Note that since this is a 
step response and the capacitor voltage is charging, the graph is an exponentially increasing function. 
Also, since current through a capacitor can change instantaneously, there is a discontinuous step in the 
graph at t = 0 when the capacitor begins charging from 1 to 20 V.
b
+
–
+
–
30 V
i(0+)
v(0+)
6 kΩ
12 kΩ
+
–
1 V
FIGURE 1.34  RC circuit for initial conditions (t = 0+).
b
+
–
30 V
i(∞)
v(∞)
6 kΩ
12 kΩ
+
–
FIGURE 1.35  RC circuit for final conditions (t = ∞).
© 2011 by Taylor and Francis Group, LLC

DC and Transient Circuit Analysis 
1-25
1.4.2  Second-Order Circuits
Second-order circuits contain resistors, capacitors, and inductors. These circuits are known as second-
order circuits because the equations that describe these circuits are second-order ordinary differential 
equations. Second-order circuits also exhibit a natural and step response based upon whether the capac-
itor and inductor are storing or releasing energy. To solve these types of circuits, use circuit analysis to 
generate the second-order differential equation governing the behavior and then use differential equa-
tions and initial conditions to solve for the solution. One approach to solving the differential equation 
describing the transient response is to guess a solution and plug into the differential equation. Then the 
initial and final values can be used to determine the time response. For example, the general differential 
equation for these types of circuits is given by
	
d x
dt
dx
dt
x
K
o
2
2
2
2
+
+
=
α
ω
	
(1.70)
where
x represents the voltage or current
α is the Neper frequency in rad/s
ωo is the resonant frequency in rad/s
K is related to the steady-state value of the variable of interest
The damping factor and resonant frequency can be identified from the second-order equation derived 
for the circuit. To solve these equations, assume that the solution is of the form x(t) = Aest. Substitute 
this value into Equation 1.71 to yield the following:
	
Ae
s
s
K
st
o
(
)
2
2
2
+
+
=
α
ω
	
(1.71)
Thus, the characteristic equation of any second-order circuit is s
s
o
2
2
2
+
+
α
ω . The general form of the 
solution to the second-order differential equation in (1.72) is given by
	
x t
A
A
x t
s t
s t
( )
(
)
=
+
+
→∞
1
2
1
2
e
e
	
(1.72)
The roots of the characteristic equation, s1 and s2, can be used to determine the type of response. There are 
three types of responses for second-order circuits: overdamped, critically damped, and underdamped. 
v(t), V
Time, ms
25
20
15
10
5
–5
(a)
0
5
10
15
(b)
i(t), mA
Time, ms
0.5
1
1.5
2
2.5
3.5
4.5
3
4
5
–5
0
5
10
15
0
0
FIGURE 1.36  Graphs of voltage and current for the capacitor in Example 1.15. (a) Voltage across the capacitor 
and (b) current through the capacitor.
© 2011 by Taylor and Francis Group, LLC

1-26 
Fundamentals of Industrial Electronics
The overdamped response has a slow response and long settling time. The critically damped response 
has a fast response and short settling time. The underdamped response has the fastest response and 
a long settling time. Table 1.4 presents the relationship between the three responses, the roots of the 
characteristics equation, the Neper frequency, resonant frequency, form of the solution, and the graph.
Example 1.16:  Natural Response of an RLC Circuit
For the circuit in Figure 1.37, assume that the switch opens instantaneously at t = 0, what is the voltage, 
v(t) across the capacitor and current, i(t) through the capacitor.
The first step in the analysis is to determine the initial conditions or the energy stored in the inductor 
and capacitor. In order to find these values, analyze the circuit under steady-state conditions right before 
switching occurs (t = 0−). This circuit is shown in Figure 1.38. As previously stated, in this circuit, the induc-
tor is modeled as a short circuit and the capacitor is modeled as an open circuit. Since the capacitor is an 
open circuit, i(0−) is 0 V and since it is in parallel with a short circuit, v(0−) is 0 V. Finally, since the inductor is 
a short circuit and current follows the path of least resistance, iL(0−) = 2 A.
Next, the circuit must be analyzed right after switching occurs to find i(0+) (see Figure 1.39). In this 
circuit, the inductor is modeled as a 2 A current source and the capacitor is modeled as a 0 V voltage 
source or a wire. This circuit is shown in Figure 1.39. Since current is continuous for inductors and voltage 
is continuous for capacitors, these values do not change. However, the current through the capacitor 
changes to i(0+) = −2 A.
TABLE 1.4  Summary of Second-Order Circuit Responses
Overdamped 
response (α > ωo)
s1 and s2 are real
x t
A
A
x t
s t
s t
( )
(
)
=
+
+
→∞
1
2
1
2
e
e
Critically damped 
(α = (α = ωo)
s1 = s2
x(t) = A1te−αt + A2e−αt + x(t → ∞)
Underdamped 
response (α < ωo)
s1 and s2 are complex conjugates
x(t) = A1e−αt cos ωd t + A2e−αt 
sin ωdt + x(t → ∞)
ω
ω
α
d
o
=
+
2
2
© 2011 by Taylor and Francis Group, LLC

DC and Transient Circuit Analysis 
1-27
The next step in the analysis is to analyze the circuit at some point after switching occurs to derive the 
second-order differential equation. This circuit is shown in Figure 1.40, and the derivation of the equation 
using KCL is shown in (1.73):
	
i
i
i
R
L
C
 +  +  = 0
	
v
vdt
i
dv
dt
t
20
1
10
0
4
0
0
+
+
+
=
+
∫
(
)
m
	
1
20
1
10
4
0
2
2
dv
dt
v
d v
dt
+
+
=
m
	
d v
dt
dv
dt
v
d v
dt
dv
dt
v
o
2
2
2
2
2
12 5
25
2
0
+
+
=
+
+
=
.
α
ω
	
(1.73)
t=0
2 A
20 Ω
10 H
4 mF
v(t)
i(t)
+
–
FIGURE 1.37  Natural response of a parallel RLC circuit.
2 A
20 Ω
v(0–)
i(0–)
iL(0–)
+
–
FIGURE 1.38  Parallel RLC circuit at t = 0−.
2 A
20 Ω
v(0+)
i(0+)
iL(0+)
+
–
FIGURE 1.39  Parallel RLC circuit at t = 0+.
10 H
20 Ω
4 mF
v(t)
i(t)
+
–
FIGURE 1.40  Parallel RLC circuit 
for Example 1.16.
© 2011 by Taylor and Francis Group, LLC

1-28 
Fundamentals of Industrial Electronics
From examination of Equation 1.73, it is evident that α = 6.25 and ωo = 5 rad/s. Since α > ωo, the voltage 
and current response are overdamped. The roots of the characteristic equation (s2 + 12.5s + 25) are −2.5 and 
−10, and the general form of the response, v(t), is given in Equation 1.74:
	
v t
A
A
v t
A
A
s t
t
s
t
( )
(
)
.
=
+
+
→∞=
+
−
−
1
2
1
2
10
1
2 5
2
e
e
e
e
t
	
(1.74)
Note that since this is a natural response and the capacitor and inductor are discharging, v(∞) and i(∞) are 
zero. In order to find the values of A1 and A2, use the circuit’s initial conditions. The evaluation of Equation 
1.74 and its first derivative at t = 0+ yields
	
v
A
A
(
)
0
1
2
+ =
+
	
(1.75)
	
dv
dt
A
A
(
)
.
0
2 5
10
1
2
+
= −
−
Using the initial current through the inductor and the initial voltage across the capacitor with the results 
of (1.75), the values of A1 and A2 can be found as shown in Equation 1.76:
	
v
A
A
(
)
0
0
1
2
+ =
+
=
	
(1.76)
	
i
i
i
v
i
dv
dt
R
L
C
L
(
)
(
)
(
)
(
)
(
)
(
)
0
0
0
0
20
0
4
0
0
+
+
+
+
+
+
+
+
=
+
+
=
m
	
(1.77)
	
dv
dt
v
i
A
A
L
(
)
(
)
(
)(
)
(
)
.
0
0
20 4
0
4
2 5
10
500
1
2
+
+
+
= −
−
= −
−
= −
m
m
Solving the simultaneous set of Equations 1.76 and 1.77 yields A1 = −66.7 and A2 = 66.7. Finally, the solu-
tions to the example are
	
v t
t
t
t
( )
.
.
,
.
= −
+
>
−
−
66 7
66 7
0
2 5
10
e
e
V
	
(1.78)
	
i t
dv
dt
t
t
t
( )
.
,
.
=
=
−
>
−
−
4
667
2 667
0
2 5
10
m
e
e
mA
The reader is encouraged to verify that the solution for the transient response of the capacitors’ voltage 
and current does indeed obey the initial conditions.
Example 1.17:  Natural Response of an RLC Circuit
For the circuit in Figure 1.41, assume the switch has reached steady-state before the switch moves from 
position a to position b. If at time t = 0 the switch moves to position b, calculate i(t) and v(t) for t > 0.
Similar to Example 1.17, the first step in the solution process is to determine the stored energy in 
the inductor and capacitor. The circuit in Figure 1.42 illustrates the circuit under steady-state conditions 
before the switch moves from position “a” (t = 0−); the inductor is modeled as a short circuit (v(0−) = 0 V) 
and the capacitor is modeled as an open circuit. By observation, the voltage across the capacitor is also 
0 V and the current through the inductor can be found from Ohm’s law, i(0−) = 50/10 = 5 A.
© 2011 by Taylor and Francis Group, LLC

DC and Transient Circuit Analysis 
1-29
The next step in the analysis is to use the values found at t = 0− to 
model the initial conditions in the circuit right after switching occurs 
(see Figure 1.43). Since current cannot change instantaneously 
through the inductor, it is modeled as a 5 A current, and because 
voltage cannot change instantaneously across a capacitor, it is 
modeled as a 0 V source or wire.
Since the 20 Ω resistor is in parallel with the 5 A current source 
in Figure 1.43, they have the same voltage (v(0+) = −(20)(5) = −100 V). 
At any instant of time after the switch moves, observe that this cir-
cuit is a series RLC circuit and KVL can be used to derive the second-
order differential equation that describes it (see Figure 1.44 and 
Equation 1.79):
	
v
v
v
L
R
C
 + 
 + 
 = 0
	
100
20
1
1000
0
0
0
m di
dt
i
idt
v
t
+
+
+
=
+
∫
µ
(
)
	
100
20
1
1000
0
2
2
m d i
dt
di
dt
i
+
+
=
µ
	
d i
dt
di
dt
i
d i
dt
di
dt
i
2
2
2
2
2
200
10 000
2
0
+
+
=
+
+
=
,
α
ωo
	
(1.79)
50 V
10 Ω
20 Ω
1000 μF
100 mH
i(t)
v(t)
t =0
a
b
+
–
+
–
FIGURE 1.41  Natural response of a series RLC circuit.
50 V
10 Ω
20 Ω
i(0–)
v(0–)
+vc(0–)–
a
b
+
+
–
–
FIGURE 1.42  Series RLC circuit at t = 0−.
5 A
20 Ω
i(0+)
v(0+)
+ vc(0+)–
b
+
–
FIGURE 1.43  Series RLC circuit at 
t = 0+.
100 mH
20 Ω
i(t)
v(t)
1000 μF
b
+
–
FIGURE 1.44  Series RLC circuit 
at t = 0+.
© 2011 by Taylor and Francis Group, LLC

1-30 
Fundamentals of Industrial Electronics
From the examination of Equation 1.79, the Neper frequency, α = 100 rad/s and the resonant fre-
quency, ωo = 100 rad/s. By reviewing Table 1.4, since α = ωo, this is a critically damped circuit. The 
characteristic equation is s2 + 200s + 10,000 and there is one repeated root, 100. The general form 
of the solution for the current through the inductor is given in Equation 1.80. Note that since there 
is no active source on the circuit after the switch moves to position “b,” the inductor is discharging 
(i(t → ∞) = 0 A):
	
i t
A t
A
i t
A t
A
t
t
t
t
( )
(
)
1
2
1
2
=
+
+
→∞=
+
−
−
−
−
e
e
e
e
α
α
100
100
	
(1.80)
Once again, it is necessary to use the initial conditions to determine the values of A1 and A2. In order to 
do this, the equation in 1.80 and its first derivative must be evaluated at t = 0+. These equations are given 
in (1.81) and (1.82):
	
i
A
(
)
0
2
+ =
	
(1.81)
	
di
dt
A
A
(
)
1
2
0
100
+
=
−
	
(1.82)
Next, using the initial conditions found from Figures 1.42 and 1.43, KVL, and Equations 1.81 and 1.82, it is 
possible to solve for A1 and A2 (see Equations 1.83 and 1.84):
	
i
A
(
)
0
5
2
+ =
=
	
(1.83)
	
v
v
v
L
R
(0 ) + 
(0 ) + 
(0 ) = 0
+
+
+
C
	
100
0
20 0
0
0
m di
dt
i
vC
(
)
(
)
(
)
+
+
+
+
+
=
	
di
dt
i
v
A
A
C
(0 )
(
)
(
)
1
2
+
+
+
= −
−
=
−
= −
20 0
100
0
100
100
1000
m
m
	
(1.84)
By solving Equations 1.83 and 1.84 yields, A1 = −500 and A2 = 5. The specific solution for the inductor’s 
current and voltage are shown in Equations 1.85 and 1.86:
	
i t
t
t
t
t
( )
,
100
= −
+
>
−
−
500
5
0
100
e
e
A
	
(1.85)
	
v t
di
dt
t
t
t
t
( )
,
=
= −
+
>
−
−
100
100
5000
0
100
100
m
e
e
V
	
(1.86)
It is left to the reader to verify that Equations 1.85 and 1.86 are consistent with the initial conditions 
found from the circuit in Figure 1.43.
© 2011 by Taylor and Francis Group, LLC

DC and Transient Circuit Analysis 
1-31
Example 1.18:  Step Response of an RLC Circuit
The circuit in Figure 1.45 has been in position a for a long time, and at t = 0 it moves to position b. 
Determine the voltage, v(t), across and current, i(t), through the 25 Ω resistor.
In order to find the initial conditions for the inductor, capacitor, and resistor, the circuit in Figure 1.46 
must be analyzed. Since the inductor is a short circuit and the resistor does not have any current because 
of the break in the circuit v(0−), i(0−), and iL(0−) are zero. However, the capacitor is an open circuit and it 
is the same as the voltage across the 40 Ω resistor. Thus, the voltage can be found by using the voltage 
divider, vC (0−) = (40/50)(25) = 20 V.
The next step in the analysis is to model the initial voltage across the capacitor and the initial current 
through the inductor as independent sources right after it moves to position b (see Figure 1.47). The 
10 mH
40 Ω
25 V
50 V
t =0
25 Ω
10 Ω
i(t)
+ v(t) –
100 μF
b
a
+
–
+
–
FIGURE 1.45  Step response of an RLC circuit.
40 Ω
25 V
50 V
25 Ω
10 Ω
i(0+)
iL(0–)
vc(0–)
+ v(0–) –
b
+
–
a
+
–
+
–
FIGURE 1.46  Series RLC circuit at t = 0.
20 V
50 V
25 Ω
i(0+)
iL(0+)
vc(0+)
+ v(0+) –
b
+
–
+
–
+
–
FIGURE 1.47  Series RLC circuit at t = 0+.
© 2011 by Taylor and Francis Group, LLC

1-32 
Fundamentals of Industrial Electronics
capacitor is modeled as a 20 V voltage source, the inductor had 
an initial current of 0 A, so this is modeled as an open circuit. The 
resistor model remains the same because voltage across and cur-
rent through a resistor can change instantaneously. However, since 
there is a break in the circuit, the current, i(0+), and the voltage, 
v(0+), are still zero.
Since this circuit is a step response and the inductor and/or 
capacitor are storing energy, it is also necessary to analyze the cir-
cuit after the switch has been in position “b” for a long time. It is 
assumed that this circuit has reached steady-state conditions and 
the circuit model is shown in Figure 1.48. The analysis of this circuit 
indicates that after a long time, the capacitor has charged to 50 V 
(vC(∞) = 50). The current through the inductor and resistor is 0 A 
because of the open circuit. Finally, the voltage across the resistor 
is v(∞) = 0 V because there is no current flow.
The next step in the analysis is to derive the second-order dif-
ferential equation that describes this series RLC circuit after the 
switch moves to position “b.” The circuit is shown in Figure 1.49 
and it is analyzed in Equation 1.87:
	
v
v
v
L
R
 + 
 + 
 = 50
C
	
10
25
50
m di
dt
i
vc
+
+
=
	
substitute
i
dv
dt
c
=100 µ
	
(
)(
)
(
)(
))
10
100
25 100
50
2
m
µ
µ
d v
dt
dv
dt
v
C
C
C
+
+
=
	
(1.87)
	
d v
dt
dv
dt
Mv
M
C
C
C
2
2500
1
50
+
+
=
The Neper frequency can be found from Equation 1.87 to be α = 1.25 krad/s and the resonant frequency 
is ωo = 1 krad/s. Since the Neper frequency is greater than the resonant frequency, this is also an over-
damped response. The roots of the characteristics equation are −500 and −2000. The equation for the 
voltage across the capacitor is given by Equation 1.88:
	
v t
A
A
C
t
( )
500
=
+
+
−
−
1
2
2000
50
e
e
	
(1.88)
The variables, A1 and A2, will be found for the capacitor voltage and this equation will be used to find the 
resistor current and voltage. The initial conditions found earlier will be used to find A1 and A2, as shown 
in (1.89) and (1.90):
	
v
A
A
C(
)
0
50
20
1
2
+ =
+
+
=
	
(1.89)
	
i
dv
dt
L
C
(
)
(
)
0
100
0
+
+
=
µ
	
dv
dt
i
c
L
(
)
(
)
0
0
100
0
+
+
=
=
µ
50 V
25 Ω
i(∞)
iL(∞)
vc(∞)
+ v(∞) –
b
+
–
+
–
FIGURE 1.48  Series RLC circuit at 
t = ∞.
50 V
25 Ω
i(t)
10 mH
100 μF
+ v(t) –
b
+
–
FIGURE 1.49  Series RLC circuit.
© 2011 by Taylor and Francis Group, LLC

DC and Transient Circuit Analysis 
1-33
	
dv
dt
A
A
C(
)
0
500
2000
0
1
2
+
= −
−
=
	
(1.90)
Solving the simultaneous system of equations, (1.89) and (1.90), yields A1 = −40 and A2 = 10. Finally, the 
solution for all values is given in (1.91) through (1.93):
	
v t
t
C
t
t
( )
,
= −
+
+
>
−
−
40
10
50
0
500
2000
e
e
V
	
(1.91)
	
i t
i t
i t
dv
dt
t
L
C
C
t
t
( )
( )
( )
,
=
=
=
=
−
>
−
−
100
2
2
0
500
2000
µ
e
e
A
	
(1.92)
	
v t
i t
t
t
t
( )
( )
,
=
=
−
>
−
−
25
50
50
0
500
2000
e
e
V
	
(1.93)
The initial conditions for the solution can be verified by observing the graphs of the functions shown in 
Figure 1.50.
Example 1.19:  Step Response of an RLC Circuit
The switch in the circuit in Figure 1.51 has been opened for a long time and the circuit has reached 
steady-state conditions. If the switch closes at t = 0, determine v(t) and i(t) for t > 0.
The first step in the analysis is to determine the initial conditions. In order to simplify the analysis, 
a source transformation was performed on the 18 V source and 6 Ω resistor. The circuit is shown in 
Figure 1.52.
vc(t), V
Time, us
(a)
60
50
40
30
20
10
0
–2000
0
2000
4000
6000
8000 10000
iL(t), A
Time, us
1
0.8
0.6
0.4
0.2
0
–0.2
(b)
–2000
0
2000
4000
6000
8000 10000
v(t), V
Time, us
25
20
15
10
5
0
–5
(c)
–2000
0
2000
4000
6000
8000
10000
FIGURE 1.50  Graph of voltages and currents in Example 1.18. (a) Voltage across the capacitor, (b) current 
through the inductor, and (c) voltage across the 25Ω resistor.
© 2011 by Taylor and Francis Group, LLC

1-34 
Fundamentals of Industrial Electronics
Since the capacitor is an open circuit across the shorted out inductor, v(0−) = 0 V. The current divider 
can be used to find the current through the inductor i(0−) = [(4||5)5] = 1.33 A. Since current through induc-
tors is continuous and voltage across capacitors is continuous, these values remain the same after the 
switch closes (t = 0+). The next step in the analysis is to analyze the circuit in Figure 1.53 to determine the 
final values for the voltage and current. When the switch closes, it shorts out the 4 Ω resistor and it no 
longer has an effect on the circuit. Since current always follows the path of least resistance, i(∞) = 3 A and 
the voltage across the capacitor v(∞) = 0 V.
In order to derive the second-order equation that describes the response, the parallel RLC circuit in 
Figure 1.54 will be analyzed using KCL. This derivation is given in Equation 1.94.
	
i
i
i
L
R
 +  +  = 3
C
	
i
v
dv
dt
+
+
=
4
0 5
3
( . )
t = 0
5 Ω
6 Ω
12 Ω
0.5 H
0.5 F
i(t)
v(t)
18 V
+
+
–
–
FIGURE 1.51  Step response of a parallel RLC circuit.
5 Ω
4 Ω
i(0–)
v(0–)
3 A
+
–
FIGURE 1.52  Parallel RLC circuit at t = 0−.
3 A
(a)
4 Ω
i(∞)
v(∞)
+
–
(b)
3 A
4 Ω
5 Ω
1.33 A
i(0+)
v(0+)
+
–
FIGURE 1.53  Parallel RLC circuit initial and final values. (a) Parallel RLC circuit at t = 0+ and (b) parallel RLC 
circuit as t → ∞.
© 2011 by Taylor and Francis Group, LLC

DC and Transient Circuit Analysis 
1-35
	
substitute v
di
dt
= 0 5.
	
i
di
dt
d i
dt
+
+
=
0 5
4
0 5 0 5
3
2
.
( . )( . )
	
(1.94)
	
d i
dt
di
dt
i
2
0 5
4
3
+
+
=
.
From examination of Equation 1.94, this circuit’s behavior exhibits an underdamped response because 
α = 0.25 rad/s is less than ωo = 2 rad/s. The general form for this solution is given in Equation 1.95:
	
ω
ω
α
d =
−
=
0
2
2
1.98rad/s
	
i t
A
t
A
t
t
( ) = 3 +  e
 cos 1.98  + 
 e
 sin 
, 
 
l
0.25
−
−
t
2
0.25
1.98
t
> 0 	
(1.95)
It is necessary to use the initial conditions to solve for the constants, A1 and A2 in Equation 1.95. The analy-
sis to find the values for these constants is shown in (1.96) and (1.97):
	
i
A
(
)
.
0
3
1 33
1
+ =
+
=
	
(1.96)
	
v
di
dt
(
)
.
(
)
0
0 5
0
+
+
=
	
(1.97)
3 A
4 Ω
0.5 H
0.5 F
i(t)
v(t)
+
–
FIGURE 1.54  Parallel RLC circuit.
i(t), A
Time, s
4.5
3.5
2.5
2
1.5
1
0.5
0
–5
(a)
0
5
10
3
4
(b)
v(t), V
Time, s
2
1
0
–1
–2
–3
–5
0
5
10
3
4
FIGURE 1.55  Graph of v(t) and i(t). (a) Current through the inductor and (b) voltage across the capacitor.
© 2011 by Taylor and Francis Group, LLC

1-36 
Fundamentals of Industrial Electronics
	
di
dt
v
(
)
(
)
.
0
0
0 5
0
+
+
=
=
	
di
dt
A
A
(
)
.
.
0
0 25
1 98
0
1
2
+
= −
+
=
Solving this system of equations ( (1.96), (1.97) ) yields A1 = −1.67 and A2 = −0.211. The final solution for v(t) 
and i(t) are given as (1.98) and (1.99):
	
i
t
t
t
( ) = 3 
 1.67e
 cos 1.98  
 0.211
 sin 
 
0.25
0.25
t
t
−
−
−
−
e
1.98 A,
 > 0
t
	
(1.98)
	
v t
di
dt
t
t
t
t
t
( )
.
cos .
.
sin .
,
.
=
= −
+
>
−
−
0 5
280
1 98
3 36
1 98
0
0 25
µe
V
0.25
e
	
(1.99)
Finally, the graphs of these two equations are shown in Figure 1.55; the reader is encouraged to verify that 
they do indeed satisfy the initial conditions.
This section has presented the transient analysis of first- and second-order circuits using ordinary 
differential equations. It should be noted that there is an alternate method for solving these types of 
circuits. As the circuits become more complex, it may be advisable to use complex frequency (s = σ + jω) 
or Laplace analysis. This analysis technique converts the circuits to the complex frequency domain and 
simplifies the mathematics by using algebra with complex numbers to solve.
1.5  Conclusions
This chapter has presented the fundamental concepts related to DC circuit analysis, including ideal 
sources, active and passive circuit elements, the law of conservation of energy, and analysis techniques. 
Transient analysis for first-order circuits was also presented, including the step and natural responses 
to model the storing and releasing of energy for inductors and capacitors. Finally, transient analysis 
was presented for second-order circuits and the three types of responses, overdamped, underdamped, 
and critically damped, were reviewed. For further study, the reader is encouraged to review AC circuit 
analysis, frequency-selective circuits, and operational amplifiers.
Bibliography
J.W. Nilsson and S.E. Riedel, Electric Circuits, 8th edition, Upper Saddle River, NJ: Prentice Hall, 2007, 880 pp.
M.N.O. Sadiku and C.K. Alexander, Fundamentals of Electric Circuits, 3rd edition, New York: McGraw-
Hill, 2007, 901 pp.
© 2011 by Taylor and Francis Group, LLC

2-1
2.1  Introduction
Alternating current (AC) circuits are important to the field of electronics. AC signals can be found in 
power distribution systems or in common household electrical systems. The household wall outlet deliv-
ers AC power to loads such as lamps, televisions, refrigerators, stoves, washers, and dryers. A step-down 
transformer transmits AC power from the power plant to the house.
AC signals are based upon a sinusoidal source. A sinusoidal source produces a voltage or current that 
has the form of a cosine. The equation to represent the sinusoidal voltage source is
	
v t
V
t
V
m
( )
(
)
=
+
cos ω
φ
	
(2.1)
From Equation 2.1, it is evident that the source varies with time, t, in seconds; has maximum ampli-
tude, Vm, in volts; angular frequency, ω, in rad/s; and a phase, ϕ, in radians. Note that the angular 
frequency, ω, can also be related to the cyclic frequency, f, in hertz and period, T, in seconds, as shown 
in Equation 2.2:
	
ω
π
π
=
=
2
2
f
T 	
(2.2)
Figure 2.1 illustrates a phase-shifted sinusoidal voltage source V1 with respect to the positive cosine volt-
age source, V2. The amplitude, period, frequency, and phase are shown in the figure. Note that if V1 is 
shifted to the left with respect to V2, then the phase ϕ > 0 and V1 is leading V2. If V1 is shifted to the right 
with respect to V2, then ϕ < 0 and V1 is lagging with respect to V2.
2
AC Circuit Analysis
2.1	
Introduction....................................................................................... 2-1
2.2	
Circuit Elements................................................................................2-3
Passive Circuit Elements  •  Mutual Inductance  •  Ideal 
Transformer  •  Autotransformer
2.3	
Analysis Techniques..........................................................................2-8
Phasor Analysis  •  Frequency Response (Laplace) Analysis  •   
Impulse Response Example  •  Step Response Example  •      
Sinusoidal Steady-State Example  •  Complete Response Example
2.4	
Complex Power................................................................................2-28
Instantaneous, Average, and Reactive Power  •  Effective or RMS 
Value  •  Complex and Apparent Power  •  Maximum Average Power 
Transfer  •  Power Factor Correction
2.5	
Conclusions......................................................................................2-40
Bibliography.................................................................................................2-40
Carlotta A. Berry
Rose-Hulman Institute 
of Technology
Deborah J. Walter
Rose-Hulman Institute 
of Technology
© 2011 by Taylor and Francis Group, LLC

2-2 
Fundamentals of Industrial Electronics
A phasor is a complex number used to represent a sinusoid. The phasor representation includes 
the amplitude, Vm, and phase, ϕ, of the sinusoid. Phasor representation of a sinusoid is based upon 
Euler’s identity:
	
e
 cos
sin
j
j
φ
φ
φ
=
+
, 	
(2.3)
where j is the imaginary number −1. The real part of the identity is cos ϕ and e jϕ can be used to repre-
sent the sinusoid in Equation 2.1 as
	
v t
V
t
V
m
m
j
( )
(
)
=
+
→
=
cos
e
ω
φ
φ
V
	
(2.4)
Note that the phasor representation holds the magnitude and phase information but not the frequency. 
There are three forms of phasor representation: exponential form, polar form, and rectangular form. 
The exponential form is given in Equation 2.4, the polar form is shown in (2.5), and the rectangular 
form in (2.6):
	
V =
∠
Vm
φ 	
(2.5)
	
V =
+
a
jb 	
(2.6)
The formulas in (2.7) and (2.8) give the conversion between the exponential, angle, and rectangular 
forms:
	
V
a
b
b
a
m =
+
=




−
2
2
1
φ
tan
	
(2.7)
	
a
V
b
V
m
m
=
=
cos
sin
φ
φ 	
(2.8)
Another way to think of a phasor is as a vector representation of a 
complex number where the angle with respect to the real axis is ϕ 
and the magnitude of the vector is Vm (see Figure 2.2).
The phasor representation of the sinusoid V1 in Figure 2.1 in all 
three forms is shown in (2.9):
	
V =
∠
° =
=
+
 1
45
 le
 7 7 
7 7 V
4
j
j
π/
.
.
0 0
0 0
	
(2.9)
1
V1
V2
v(t), V
0.8
0.6
0.4
0.2
0.79 1.57 2.36 3.14 3.93 4.71 5.5 6.28 7.07 7.85 8.64 9.42
Time, s
0
–0.2
–0.4
–0.6
–0.8
–1
–1.2
0
Amplitude, Vm=1 V
Period, T=6.28 s=2π s
Angular frequency, ω=2π/T=1 rad/s
Cyclic frequency, f =1/T=0.159 Hz
Phase, φ=(1.57–0.79) ω=0.79=π/4 radians
FIGURE 2.1  Sinusoidal voltage source, v(t).
b
Imaginary axis
|Vm|
φ
a
Real axis
FIGURE 2.2  Phasor representation 
of a complex number.
© 2011 by Taylor and Francis Group, LLC

AC Circuit Analysis 
2-3
2.2  Circuit Elements
2.2.1  Passive Circuit Elements
The three passive circuit elements are resistors, inductors, and capacitors. A passive circuit element 
is incapable of delivering power to a circuit. However, inductors store energy in the form of current 
and capacitors store energy in the form of voltage so they can release energy previously stored back 
to the circuit.
How can we represent the voltage and current relationship for these three passive elements as pha-
sors? Examine the circuit in Figure 2.3 to find the voltage and current for the resistor, inductor, and 
capacitor.
The first step in the analysis is to use the voltage and current relationships to find the voltage across 
each element. These equations in the time domain are given in (2.10) through (2.12):
	
v t
iR
RI
t
R
m
( )
(
)
=
=
+
cos ω
φ 	
(2.10)
	
v t
L di
dt
LI
t
LI
t
L
m
m
( )
sin(
)
cos(
)
=
= −
+
=
+
+
°
ω
ω
φ
ω
ω
φ
90
	
(2.11)
	
v
t
C
id
I
C
t
I
C
t
C
m
m
( )
sin(
)
cos(
)
=
=
+
=
+
−
°
∫
1
90
τ
ω
ω
φ
ω
ω
φ
	
(2.12)
The phasor relationships for the resistor, inductor, and capacitor are derived from the prior equations 
as follows:
	
V
I
R =
=
RI
R
m
j
 e φ
	
(2.13)
	
V
I
L =
=
=
LI
j LI
j L
m
j
j
m
j
ω
ω
ω
φ
π
φ
e
e
e
2
/
	
(2.14)
	
V
I
C =
= −
= −
−
I
C
j
C I
j
C
m
j
j
m
j
ω
ω
ω
φ
π
φ
e e
e
/2
	
(2.15)
Table 2.1 summarizes the voltage and current relationships for resistors, inductors, and capacitors.
Based upon the prior derivation, in the phasor domain, the relationship between voltage and current 
is V = IZ, where Z is the impedance of the resistor, inductor, or capacitor in ohms (Ω).
R
i
Im cos (ωt+φ)A
vR(t)
– vC (t) +
vL(t)
+
+
C
–
–
L
FIGURE 2.3  Voltage and current phasor relationships for R, L, and C.
© 2011 by Taylor and Francis Group, LLC

2-4 
Fundamentals of Industrial Electronics
TABLE 2.1  Phasors and Passive Circuit Elements
Resistors
Inductors
Capacitors
R
I
+
v
–
I
jωL
+
v
–
1
jωC
I
+
v
–
V = IR
V = jωLI
I = jωCV
The voltage and current are in phase
The current lags the voltage by 90°
The current leads the voltage by 90°
v(t), V
0
2
4
6
i(t), A
Time, s
v(t), V
i(t), A
0
2
4
6
8
10
Time, s
v(t), V
i(t), A
0
Time, s
7
4
15
Imaginary axis
V
I
Real axis
φ
Imaginary axis
I
φ
Real axis
V
Imaginary axis
I
Real axis
V
φ
Z = R
Z = jωL
Z = 1/(jωC)
© 2011 by Taylor and Francis Group, LLC

AC Circuit Analysis 
2-5
2.2.2  Mutual Inductance
Another important circuit element is based upon the concept of mutual inductance. When the AC cur-
rent flows through a coil (inductor), it creates a changing magnetic field. Self-inductance, L, is the param-
eter that relates induced voltage across a coil to the current flowing through it (v = L di/dt). Since the 
time-varying current through an inductor creates a magnetic field, if a secondary coil is placed next to the 
primary coil then a portion of the magnetic flux will be coupled to the secondary coil thereby inducing a 
voltage across the secondary coil. Mutual inductance, M, is the parameter that relates the voltage induced 
in the second coil due to the current flowing through the first coil. Just like self-­inductance, the units for 
mutual inductance are also henrys (H). Figure 2.4 illustrates a mutual inductance circuit with two coils.
The relationship between the induced voltage in the second coil and the current flowing through the 
first coil is given in Equation 2.16:
	
v t
M di
dt
2
1
( ) = ±
	
(2.16)
In the phasor domain, the voltage across the secondary coil is given by
	
V
I
2 =  (
)
j
M
ω
	
(2.17)
Therefore, the impedance for the mutual inductance is Z = V/I = jωM. Note that the relationship in 
Equation 2.16 can be positive or negative and the polarity is based upon the dot convention for mutual 
inductors. The dot convention states that when the current enters the coil through the dot on the first 
coil, then the voltage induced on the second coil is positive at the dotted terminal. If the current leaves the 
coil through the dot on the first coil, then the voltage induced on the second coil is negative at the dotted 
terminal. Table 2.2 presents a summary of the two possible configurations of the voltages and currents.
The mutual inductance parameter, M, can also be described in terms of the coefficient of coupling, k. 
The range of values for k is between 0 and 1, where 0 represents no coupling and 1 represents a very tight 
coupling (i.e. transformer). The relationship between mutual inductance and the coefficient of coupling 
is shown in Equation 2.18:
	
M
k L L
=
1
2 	
(2.18)
In terms of phasor impedance Equation 2.18 becomes
	
j M
k
j L
j L
ω
ω
ω
=
(
)(
)
1
2 	
(2.19)
The total energy stored in the coupled inductors is given by
	
w
L i
L i
Mi t i
( )
5
( )
5
( )
( )
1
2
1
2
t
t
t
t
=
(
) +
(
) ±
0
0
1
2
2
2
.
.
( )
	
(2.20)
In the energy expression, use +Mi1(t)i2(t) if both currents enter or leave inductors through the dotted 
terminal, otherwise use the minus sign.
Secondary
Primary
+
+
+
–
–
–
v1
M
v2
L2
L1
i1
R1
vs
FIGURE 2.4  Mutual inductance circuit.
© 2011 by Taylor and Francis Group, LLC

2-6 
Fundamentals of Industrial Electronics
2.2.3  Ideal Transformer
One of the primary applications of ideal transformers is for 
energy transmission. The step-up ­transformer is used to increase 
the voltage for the power lines from the power plant. As previ-
ously mentioned, the step-down transformer is used to reduce 
the voltage for delivery to household outlets at 240 or 120 VAC. An 
ideal transformer consists of two magnetically coupled coils with 
the following characteristics:
	
1.	 The coils are perfectly coupled; therefore k = 1.
	
2.	 The self-inductance of each coil is infinite (L1 = L2 = ∞).
	
3.	 Coil losses due to resistance are negligible.
Figure 2.5 is the circuit symbol for an ideal transformer.
The left coil and its circuit are called the primary side of the transformer. The right coil and its circuit 
are called the secondary side of the transformer. The turns ratio, n, of a transformer is a ratio of the turns 
on the secondary coil to the turns on the primary coil:
	
n
N
N
=
2
1 	
(2.21)
There are two characteristics of the terminal behavior of an ideal transformer:
	
1
2
1
. V
nV
= ±
	
(2.22)
	
2
1
2
. I
nI
= ±
	
(2.23)
Note that the relationship in Equations 2.22 and 2.23 can be positive or negative and the polarity is 
based upon the dot convention for ideal transformers. For Equation 2.22, if the coil voltages V1 and V2 
are both positive or both negative at the dotted terminals, use a plus sign. If one voltage is positive and 
one voltage is negative at the dotted terminals, use a minus sign. For Equation 2.23, if both of the cur-
rents I1 and I2 enter or leave through the dotted terminal, use a minus sign. If one current enters and one 
current leaves through the dotted terminal then use a plus sign.
Table 2.3 presents two possible configurations for the dot convention.
TABLE 2.2  Dot Convention Configurations
i1
v1
v2
vs
R1
–
–
–
+
+
+
M
L1
L2
i1 enters the coil through the dot
So v2 is positive at the dot
v2 = +M di1/dt
R1
L1
L2
i1
v1
vs
v2
–
–
–
+
+
+
M
i1 leaves the coil through the dot
So v2 is negative at the dot
v2 = −M di1/dt
V1
1:n
V2
I2
I1
Primary
Secondary
–
–
+
+
FIGURE 2.5  Ideal transformer circuit.
© 2011 by Taylor and Francis Group, LLC

AC Circuit Analysis 
2-7
2.2.4  Autotransformer
An autotransformer is a single winding ideal transformer with a center tap. Alternately, the primary 
and secondary windings are connected in series to form an autotransformer. If a center tap is used, it 
is adjustable such that the turns ratio is variable to step up or step down to the desired voltage. In this 
configuration, there is an electrical coupling between the primary and secondary windings. The pri-
mary benefit of this configuration is that it is possible to deliver a larger apparent power to the load or 
to step a voltage up or down by a small amount. Apparent power will be described in Section 2.4 and an 
example shown with the autotransformer. However, one of the disadvantages of the autotransformer 
is the fact that there is no electrical isolation between the primary and secondary windings. Figure 
2.6 presents three different examples of autotransformer configurations and the voltage and current 
TABLE 2.3  Ideal Transformer Dot Convention
Circuit
Voltage Relationship
Current Relationship
I1
I2
V1
V2
1: n
+
+
–
–
Primary
Secondary
V2 = +nV1
I1 = +nI2
I1
V1
V2
I2
1:n
+
+
–
–
Primary
Secondary
V2 = −nV1
I1 = +nI2
N2
I2
+
+
(c)
V2
N1
–
–
V1
I1
I2
I1
N2
V2
N1
V1
+
+
–
–
(b)
I2
V2
N2
V1
(a)
N1
I1
+
+
–
–
=
V2
N2
N2+N1
V1
=
I2
N2
N2+N1
I1
=
V2
N1
N1
N2+ N1
N2+ N1
V1
=
I2
I1
=
V2
N1
N1
N2– N1
N2– N1
V1
=
I2
I1
FIGURE 2.6  Autotransformer configurations. (a) Step down, (b) step up, and (c) subtractive.
© 2011 by Taylor and Francis Group, LLC

2-8 
Fundamentals of Industrial Electronics
relationships. The first two represent a traditional step-down and step-up transformation. The last con-
figuration demonstrates the subtractive connection of an autotransformer.
2.3  Analysis Techniques
2.3.1  Phasor Analysis
The prior sections introduced sinusoidal sources, phasors, and the phasor representation of some 
common circuit elements. Phasor analysis also referred to as sinusoidal steady-state analysis involves 
representing voltage and sinusoidal waveforms as phasors in circuit analysis. Note that in sinusoidal 
steady-state analysis, all of the voltages and currents will have the same frequency; therefore, it is only 
necessary to find amplitudes and phase shifts. The steps of phasor analysis are
	
1.	 Convert the circuit to the phasor domain (sources to phasors, elements to impedances).
	
2.	 Use circuit analysis techniques to find relevant voltages and currents.
	
3.	 Convert the phasor values back to the time domain.
The phasor analysis technique will be demonstrated on several types of circuits.
Example 2.1:  Mesh-Current Method
For the circuit shown in Figure 2.7, use phasor analysis to find the current through the voltage source. 
This will be achieved by using the mesh-current method with phasor analysis to find the three unknown 
mesh currents.
The first step in phasor analysis is to convert the circuit to the phasor domain or the sinusoidal steady 
state. Note that the angular frequency, ω, of the source is 2π60 = 377 rad/s. Using this frequency, convert 
all of the sources and passive circuit elements to phasors and impedances. The voltage source becomes 
170∠0° V by using the polar form. The next step would be to convert all of the passive circuit elements to 
impedances. Recall that for resistors the impedance is the same in the time domain and phasor domain. 
The inductor and capacitor impedances become
	
Z
j L
j
j
L =
=
=
ω
(
)( )
377 3  
1131Ω	
(2.24)
	
Z
j
C
j
j
C = −
=
−
= −
ω
µ
(
)( .
)
377 2 2
1206 Ω
	
(2.25)
Using the results of (2.24), (2.25), the circuit in Figure 2.6 redrawn in the phasor domain is shown in Figure 2.8.
1 kΩ
1 kΩ
3 H
2.2 μF
170 cos (2π 60 t) V
+
–
R1
C
L
R2
i2
i3
R3
i1
1 kΩ
FIGURE 2.7  Mesh-current method using phasor analysis.
© 2011 by Taylor and Francis Group, LLC

AC Circuit Analysis 
2-9
The next step is to use the Kirchhoff’s voltage law (KVL) to solve for I1, I2, and I3. The KVL equations for 
meshes 1, 2, and 3 are given in Equations 2.26 through 2.28, respectively:
	
(
)
1
12 6
1
12 6
17
000
0
000
0
0
−
−
+
=
j
j
I
I
I
1
2
3
	
(2.26)
	
−
+
+
−
=
1
 2
 
1131
113
000
000
0
I
I
I
1
2
3
(
)
j
j
	
(2.27)
	
j
j
j
12 6
1131
 1
75
0
000
0
I
I
I
1
2
3
−
+
−
=
(
)
	
(2.28)
Solving Equations 2.26 through 2.28 yields the following solution for I1, I2 and I3:
	
I1 =
∠
°
15 16 
3625 mA
0.
.
	
(2.29)
	
I2 =
∠
°
1 136
1817 mA
0 .
.
	
(2.30)
	
I3 =
∠−
°
8 19
23 21 mA
0.
.
	
(2.31)
The final step involves converting the phasors I1 and I2 back to the time domain:
	
i t
t
1
15 16 cos 2 6
3625  mA
( )
.
(
.
)
=
+
°
0
0
π
	
(2.32)
	
i t
t
2
1 136 cos 2 6
1817  mA
( )
.
(
.
)
=
+
°
0
0
π
	
(2.33)
	
i t
t
3
8 19 cos 2 6
2321  mA
( )
.
(
.
)
=
−
°
0
0
π
	
(2.34)
Finally, the current through the voltage source is i1(t).
Example 2.2:  Example 2.1 Revisited Using T-π Transformations
An alternate method to find the unknown voltage and currents in an AC circuit is to use circuit simplifica-
tion along with the Ohm’s law, voltage divider, current divider, and Kirchhoff’s current (KCL) and voltage 
(KVL) laws. Circuit simplification involves combining impedances by using series/parallel combinations 
and T-π transformations to reduce the number of circuit elements. Figure 2.9 shows the relationship 
between the T and π configuration. It should be noted that since these configurations are equivalent, 
the voltage and current characteristics at the three terminals are the same. The terminals are the only 
locations where the voltage and current characteristics are the same.
1 kΩ
j1131 Ω
R3
I3
R1
ZC
ZL
I1
R2
I2
–j1206 Ω
170   0° V
+
1 kΩ
1 kΩ
–
FIGURE 2.8  Mesh-current circuit in phasor domain.
© 2011 by Taylor and Francis Group, LLC

2-10 
Fundamentals of Industrial Electronics
To convert from the π configuration to the T configuration, use the following relationships:
	
Z
Z Z
Z
Z
Z
Z
Z Z
Z
Z
Z
Z
Z Z
Z
Z
Z
A
B
A
B
C
B
C
A
B
C
C
A
A
B
C
1 =
+
+
=
+
+
=
+
+
2
3
	
(2.35)
The conversion from the T configuration to the π configuration are given by the following relationships:
	
Z
Z Z
Z Z
Z Z
Z
Z
Z Z
Z Z
Z Z
Z
Z
Z Z
Z Z
Z Z
Z
A
B
C
=
+
+
=
+
+
=
+
+
1
2
2
3
3
1
2
1
2
2
3
3
1
3
1
2
2
3
3
1
1
	
(2.36)
In order to use a T to π transformation to simplify the circuit in Example 2.1, let Z1 = −j1206 Ω, Z2 = j1131 Ω, 
and Z3 = R1 = 1000 Ω. Using the formulas in Equation 2.35 yields ZA = −66 − j1206 Ω, ZB = 1364 − j75 Ω, 
and ZC = 62 + j1131 Ω. The simplified circuit is shown in Figure 2.10.
Figure 2.10 can be simplified by combining ZB in parallel with R3 and ZC in parallel with R2. Equations 
show the values of these impedances after the parallel combinations:
	
Z
Z R
Z
R
j
B
B
B
’ =
+
=
−
3
3
577
13 Ω
	
(2.37)
	
Z
Z R
Z
R
j
C
C
C
’ =
+
=
+
2
2
559
470 Ω
	
(2.38)
a
c
(a)
d
b
Z2
Z1
Z3
a
c
ZB
ZA
ZC
b
(b)
d
FIGURE 2.9  (a) T and (b) π transformation configurations.
1 kΩ
1 kΩ
R3
R2
ZA
ZB
ZC
+
–
I3
I2
I1
170   0° V
FIGURE 2.10  Figure 2.8 simplified using a T to π transformation.
© 2011 by Taylor and Francis Group, LLC

AC Circuit Analysis 
2-11
Figure 2.11 shows the simplified circuit after the parallel combinations. By combining ZB' and ZC' in series, 
the circuit is reduced to a voltage source in parallel with ZA and the series combination (ZB' + ZC'). Finally, 
the last two impedances are put in parallel with the voltage source and this simplified circuit is used to 
find the source current (see Figure 2.12).
The solution for the final series and parallel combinations are given by
	
Z
Z
Z
j
B
C
series
456
=
′ +
′ =
+
1136
Ω	
(2.39)
	
Z
Z R
Z
Z
j
A
A
parallel
series
series
669
=
+
=
−
913
Ω	
(2.40)
Finally, the value for the source current is found by using Ohm’s law as shown in Equation 2.41 and it is 
consistent with Equation 2.29:
	
I
Z
1
170
150 16
36 25
=
=
∠
°
parallel
mA
.
.
	
(2.41)
Example 2.3:  Example 2.1 Revisited Using the Node-Voltage Method
For the circuit in Figure 2.7, use the node-voltage method to find the current through R2. The first step is 
to label all of the node voltages and the modified circuit is shown in Figure 2.13.
Performing KCL at nodes V2 and V3 yields
	
V1 =170 	
(2.42)
	
V
V
V
V
V
j
2
1
2
2
3
1000
1131
−
−
+
+
−
=
j1206
0
	
(2.43)
170   0° V
+
I1
Z΄A
Z΄C
ZB
–
FIGURE 2.11  Figure 2.8 simplified using parallel combinations.
170   0° V
+
–
I1
ZA
Zseries
Zparallel
FIGURE 2.12  Figure 2.8 simplified to a single node pair.
© 2011 by Taylor and Francis Group, LLC

2-12 
Fundamentals of Industrial Electronics
	
V
V
V
V
3
3
2
3
1
1000
1000
+
−
+
−
=
V
j1131
0 	
(2.44)
Solving Equations 2.42 through 2.44 for the node voltages yields
	
V2 =
∠
°
 6233 
6655 V
.
.
	
(2.45)
	
V3 =
∠
°
 1 136 1817 V
0 .
.
	
(2.46)
Converting the phasors in Equations 2.45 and 2.46 to the time domain yields the following:
	
v t
t
2
6233 cos 2 6
6655  V
( )
.
(
.
)
=
±
°
π 0
	
(2.47)
	
v t
t
3
1 136 cos 2 6
1817  V
( )
.
(
.
)
=
±
°
0
0
π
	
(2.48)
To confirm that the node-voltage method and the mesh-current method produce the same results use 
the relationship in Equation 2.49:
	
I2 =
=
∠
°
V3
1000
101 36
118 17
.
.
mA 	
(2.49)
Since I2 is the same as Equation 2.30, the two methods are consistent.
Example 2.4:  Mutual Inductance
For the mutual inductance circuit shown in Figure 2.14, phasor analysis and the mesh-current method 
(KVL) will be used to find the primary and secondary currents.
The first step in the analysis is to convert the circuit to the phasor domain. To find the mutual induc-
tance, M, from the coupling coefficient use the following formula:
	
M
k L
=
=
=
1
)(5600 )
L2
0 8
4700
4104
.
(
µ
µ
µH 	
(2.50)
In terms of phasor impedance, Equation 2.50 becomes
	
j M
k
j L
j L
j
ω
ω
ω
=
=
(
)(
)
1
2
1231Ω	
(2.51)
The circuit in Figure 2.10 converted to the phasor domain is shown in Figure 2.15.
1 kΩ
–j1206 Ω
j1131 Ω
1 kΩ
1 kΩ
170   0° V +
V1
V2
V3
I1
I2
I3
R1
C
L
R2
R3
–
FIGURE 2.13  Node-voltage circuit in the phasor domain.
© 2011 by Taylor and Francis Group, LLC

AC Circuit Analysis 
2-13
The next step in the analysis is to model the voltage induced by the mutual inductance as a current-
controlled voltage source. Current I1 enters the primary coil at the dot and induces a voltage equal to j1231 
I1 across the secondary coil, which is positive at the dot. Current I2 enters the secondary coil through the 
dot and induces a voltage equal to j1231 I2 across the secondary coil that is positive at the dot. Figure 2.16 
shows the mutual inductance circuit with the induced voltages modeled as dependent voltage sources.
The KVL equations for the two meshes are
	
Mesh 1
2
141
1231
7
1
1
2
1
2
:
(
)
(
)
R
j L
j MI
j
I
j
I
+
+
=
+
+
=
ω
ω
000
0
	
(2.52)
	
Mesh 2
 
1231
1
4 3
1
2
2
2
1
2
:
(
/(
))
(
)
j MI
R
j L
j
C I
j
I
j
I
ω
ω
ω
+
+
=
+
=
−
−
000
0
0 	
(2.53)
Solving Equations 2.52 and 2.53 yields
	
I1 =
∠−
°
183
3 36 mA
.
.0
	
(2.54)
	
I2 =
∠−
°
2 9
9841 mA
.
.
0
	
(2.55)
The final step involves converting the phasors I1 and I2 back to the time domain:
	
i t
kt
1
 
 183 cos 3
 3 36  mA
( )
.
(
.
)
=
°
00
0
−
	
(2.56)
	
i t
kt
2
 
 2 9 cos 3
 9841  mA
( )
.
(
.
)
=
°
0
00
−
	
(2.57)
2 kΩ
k= 0.8
4700 μH
+
–
5600 μH
1600 pF
1 kΩ
7 cos (300kt)V
i1
i2
FIGURE 2.14  Mutual inductance using phasor analysis.
R1
I1
Vs
jωM
jωC
R2
I2
1
+
7   0° V
jωL1
j1410 Ω
j1231 Ω
jωL2
j1680 Ω
–j2083 Ω
1000 Ω
2000 Ω
–
FIGURE 2.15  Mutual inductance circuit in the phasor domain.
R1
R2
2000 Ω
1000 Ω
j1410 Ω
j1680 Ω
–j2083 Ω
jωL2
jωC
jωMI2
jωMI1
+
+
j1231I1
j1231I2
jωL1
I2
I1
Vs
–
–
+
1
–
7   0° V
FIGURE 2.16  Mutual inductance circuit in the phasor domain.
© 2011 by Taylor and Francis Group, LLC

2-14 
Fundamentals of Industrial Electronics
Example 2.5:  Example 2.4 Revisited with T and 𝛑 Equivalent Circuits
An alternate approach to the dependent source model for mutual inductance is T or π equivalent con-
figuration. It should be noted that these configurations can only be used if the primary and secondary 
sides of the network have a common node, typically the reference or ground. In addition, the following 
analysis assumes that there is no energy initially stored in the circuit. For the circuit in Figure 2.11, it is pos-
sible to write the mesh equations as
The KVL equations for the two meshes are
	
Mesh 1
 
1
1
1
1
2
:
(
)
(
)
R
j L
j M I
j M I
I
Vs
+
+
−
−
=
ω
ω
ω
	
(2.58)
	
Mesh 2:
−
−
+
+
+
−




=
j M I
I
R
j L
j M
j
C
I
ω
ω
ω
ω
(
)
2
1
2
2
2
0 	
(2.59)
Note that these equations are equivalent to Equations 2.52 and 2.53 and thus the circuit in Figure 2.17 can 
also be used to solve for the mesh currents.
Since this is a T equivalent circuit, you can use the relationships in Equation 2.36 to create the π equiva-
lent circuit. In order to create the π equivalent circuit, let Z1 = R1 + jω (L1 + M) Ω, Z2 = R2 + jω (L2 + M) Ω, and 
Z3 = −jωM Ω (Figure 2.18). Substitution into Equation 2.36 yields the following:
	
Z
Z Z
Z Z
Z Z
Z
j
Z
Z Z
Z Z
Z Z
Z
j
A
B
=
+
+
=
+
=
+
+
= −
+
1
2
2
3
3
1
2
1
2
2
3
3
1
3
1587
151
3875
9
Ω
31
1357
593
1
2
2
3
3
1
1
Ω
Ω
Z
Z Z
Z Z
Z Z
Z
j
C =
+
+
=
+
	
(2.60)
It is important to note that this configuration is for modeling purposes only and a negative resistance is 
physically impossible.
R1
R2
I2
I1
2000 Ω
j2641 Ω
j2911 Ω
–j2083 Ω
–j1231
–jωM
jωC
1000 Ω
jω(L1+M)
jω (L2+ M)
Vs
–
+
1
7   0° V
FIGURE 2.17  T equivalent of mutual inductance circuit in Figure 2.15.
ZB
ZA
Vs
+
–
–j2083 Ω
7   0° V
ZC
I2
I1
FIGURE 2.18  π equivalent of mutual inductance circuit in Figure 2.15.
© 2011 by Taylor and Francis Group, LLC

AC Circuit Analysis 
2-15
Example 2.6:  Ideal Transformer
For the ideal transformer circuit in Figure 2.19, find the voltage, VL, delivered to the load. The load voltage 
can be found by using phasor analysis, reflection, and the mesh-current method.
Typically, the simplest way to analyze an ideal transformer circuit is to use reflection to simplify the 
circuit to a single mesh. In this case, the steps would include reflecting from the secondary to the middle 
or feeder, and reflecting from the middle to the primary. The characteristic equations for the secondary 
transformer are
	
V
V
4
3
= −n
	
(2.61)
	
I
I
L = −
2
n 	
(2.62)
Therefore, the impedance as seen from the feeder is the ratio of Equations 2.61 and 2.62:
	
Z
V
I
V
I
n
j
j
L
3
3
2
4
2
2
32
40
0 1
3200
4000
=
=
=
−
=
−
/
( . )
Ω	
(2.63)
The secondary reflected to the feeder is shown in Figure 2.20.
The next step will be to reflect the feeder to the primary using a similar approach to Equation 2.63:
	
Z
V
I
V
I
n
j
j
1
1
1
2
2
2
2
5200
4000
2
1300
1000
=
=
=
−
=
−
/
( )
Ω	
(2.64)
The feeder and secondary reflected to the primary side is shown in Figure 2.21.
Finally, use KVL around the single loop to find I1 and V1, and then use the transformer voltage and 
current relationships to find the voltages and currents in the feeder and secondary sides. This analysis is 
shown below:
	
I
j
1
7
400
500
800
1000
3 55 30 47
=
+
+
−
=
∠
°
.
.
mA
	
(2.65)
400 Ω
1:2
10:1
+
+
–
–
+
–
+
–
+
–
+
–
–j40 Ω
Primary
Feeder
Secondary
7   0° V
2000 Ω
32 Ω
I1
V1
V2
V3
V4
I2
IL
VL
FIGURE 2.19  Ideal transformer using phasor analysis.
400
7   0° V
1:2
2000
3200
–j4000
Primary
Feeder + secondary reﬂected to feeder
+
–
V2
+
+
–
–
V1
I2
I1
FIGURE 2.20  Ideal transformer reflection to the middle.
© 2011 by Taylor and Francis Group, LLC

2-16 
Fundamentals of Industrial Electronics
	
V
j
I
1
1
 5
 
 8
1
 582
71 V
=
+
−
=
∠−
°
(
)
.
.
00
00
000
	
(2.66)
	
V
nV
V
2
1
1
 2
 1164 
71 V
=
=
=
∠−
°
.
.
	
(2.67)
	
I
I
n
I
2
1
1
2
1 77 30 47
=
=
=
∠
°
.
.
mA
	
(2.68)
	
V
V
I
3
2
2
2
 9 9
2 87 V
=
−
=
∠−
°
(
)
.
.
000
0
0
	
(2.69)
	
V
nV
V
4
3
3
1
 9 9 15913 mV
= −
= −
=
∠
°
0
0
.
.
	
(2.70)
	
I
I
n
I
L = −
= −
=
∠−
°
2
2
10
17 75
149 53
.
.
mA
	
(2.71)
	
V
j
j
V
L =
−
−
=
∠
°
40
32
40
710 120 47
4
.
mV
	
(2.72)
Example 2.7:  Autotransformer
For the autotransformer in Figure 2.22, find the voltage VL delivered to the load. This transformer is in a 
step-up subtractive configuration and it can also be analyzed by using KCL and the ideal transformer 
relationships. Equations 2.73 and 2.74 present the results of the analysis:
	
V
N
N
N
V
L =
−
=
−
=
2
1
1
1
100
27
27
120
324
(
)
V 	
(2.73)
I2
V2
I1
V1
N2= 100
N1= 27
VL
+
+
+
+
–
–
–
–
120    0° V
j100 Ω
500 Ω
FIGURE 2.22  Subtractive step-up autotransformer.
400
+
+
V1
I1
–
–
7   0° V
–j1000
500
800
FIGURE 2.21  Ideal transformer reflection to the primary.
© 2011 by Taylor and Francis Group, LLC

AC Circuit Analysis 
2-17
	
I
V
j
L
2
500
100
635
11
=
+
=
∠−
°mA 	
(2.74)
In conclusion, this section has presented the basic theory of phasor analysis and demonstrated the tech-
nique on several types of circuits. The next section will also consider the transient response as well as 
the steady-state response. In order to analyze a circuit to get the transient and steady-state response, it is 
necessary to use Laplace (complex frequency, s = σ + jω) analysis.
2.3.2  Frequency Response (Laplace) Analysis
Phasor analysis is used to find the sinusoidal steady-state response of a circuit. The steady-state sinu-
soidal response is the forced response based upon the sinusoidal source. The transient and sinusoidal 
steady-state response of the circuit can be found by using frequency response (Laplace) analysis. The 
transient response is based upon the sudden application or removal of a source and the initial condi-
tions of the passive circuit elements. The transfer function of a circuit is the ratio of the output to the 
input of a circuit assuming zero initial conditions. Frequency response analysis is used to determine the 
behavior of the circuit as a function of frequency variation. This analysis is based upon using the Laplace 
transform of the differential equation that describes the circuit. The first step in the Laplace analysis is 
to convert the circuit from the time domain to the complex frequency or s-domain, where the complex 
frequency is represented by s = σ + jω. The benefit of the Laplace analysis is that it transforms differen-
tial equations to algebraic equations. Similar to phasor analysis, the next step is to use circuit analysis 
techniques to find relevant voltages and currents in the circuit. The final step is to convert the s-domain 
values back to the time domain.
2.3.2.1  Impedance
The first step in the Laplace analysis of circuits is to convert the circuit to the s-domain where 
V s( ) = L{ ( )}
v t  and I s( ) = L{ ( )}
i t . Table 2.4 provides a summary of the impedance conversions from the 
time domain to the complex frequency domain.
Note that the frequency domain circuits for the inductor and capacitor including initial conditions 
represent the Thevenin and Norton equivalent circuit with respect to the terminals. Because they are 
equivalent circuits, it is possible to convert from one to the other by using source transformations. 
Similar to phasor analysis, the voltage current relationship, V = IZ, still holds.
2.3.2.2  Initial and Final Conditions
It is evident from Table 2.4 that to model a circuit in the s-domain it is necessary to find the initial 
conditions. In order to find the initial voltage across a capacitor and the initial current through an 
inductor it is necessary to understand the properties of inductors and capacitors. The properties of 
an inductor are
	
1.	 The current through and inductor cannot change instantaneously.
	
2.	 The voltage across an inductor can change instantaneously.
	
3.	 At low frequencies (or DC conditions), an inductor models a short circuit.
	
4.	 At high frequencies, an inductor models an open circuit.
The properties of a capacitor are
	
1.	 The voltage across a capacitor cannot change instantaneously.
	
2.	 The current through a capacitor can change instantaneously.
	
3.	 At low frequencies (or DC conditions), a capacitor models an open circuit.
	
4.	 At high frequencies, a capacitor models a short circuit.
© 2011 by Taylor and Francis Group, LLC

2-18 
Fundamentals of Industrial Electronics
TABLE 2.4  Impedance Relationships for Laplace Analysis
Element
Time Domain
Voltage Current 
Relationships 
(Time Domain)
Laplace Transform 
(s-Domain)
Voltage Current Relationships 
(s-Domain)
Resistor
v = iR
i = v/R
i(t)
v(t)
R
+
–
V = IR
I = V/R
Z = R
I(s)
V(s)
R
+
–
Inductor
v
di
dt
= L
i
vd
Io
o
=
+
∫
1
L
τ
τ
i(t)
v(t)
L
+
–
V = sLI − LIo
I =
+
v
s
I
s
o
L
Z = sL
I(s)
sL
sL
LIo
V(s)
V(s)
I(s)
+
+
+
–
–
–
Io
s
Capacitor
i = C dv
dt
v
C
id
Vo
o
=
+
∫
1
τ
τ
i(t)
v(t)
C
+
–
I = sCV − CVo
V =
+
I
sC
V
s
o
Z
sC
= 1
I(s)
I(s)
V(s)
V(s)
sC
CVo
+
+
+
1
sC
1
–
–
–
Vo
s
© 2011 by Taylor and Francis Group, LLC

AC Circuit Analysis 
2-19
Example 2.8:   Initial and Final Conditions
The process of finding initial conditions and using Laplace analysis to find voltages and currents will be 
demonstrated on the circuit in Figure 2.23.
The switch under the 100 V source in Figure 2.23 opens at t = 0. Therefore, to find the initial conditions 
for the elements, analyze the circuit just before and right after the switch opens. At the instance of time right 
before the switch moves (t = 0−), assume that the circuit is in a steady-state or DC condition. In addition, 
assume as t approaches ∞ the circuit is in a steady-state or DC condition. Therefore, at t = 0−, the inductor 
acts like a short circuit (0 V) and the capacitor acts like an open circuit (0 A). At the instance of time right after 
the switch moves (t = 0+), the capacitor voltage and inductor current can be modeled as an independent 
source that is equal to the initial conditions. The three values for v1, v2, i1, and i2 are shown in Figure 2.24.
Example 2.9:  Laplace Circuit Analysis
The circuit in Figure 2.16 can be redrawn in the s-domain by using the initial conditions and the equiva-
lent impedances. This process involves modeling the sources, passive circuit elements, and their initial 
values using the t = 0+ values. Figure 2.25 presents the results of the circuit conversion.
It is possible to use KVL to solve for V1, V2, I1, and I2 and this is shown Equation 2.75:
	
0 1
17
160
0 4
32
1
1
1
.
.
sI
I
s I
s
+
+
=
+
	
(2.75)
Solving (2.75) for I1 yields
	
I
s
s
s
s
s
s
1
2
4
320
170
1600
4
320
10
160
=
+
+
+
=
+
+
+
(
)(
) 	
(2.76)
The inverse Laplace transform of (2.76) yields
	
i t
u t A
i t
t
t
1
1
16
2
187e
213e
( )
( .
.
) ( )
( )
=
+
= −
−
−
0
0
	
(2.77)
It is also possible to find V1 and V2 by using I1, I2, and Ohm’s law, and these are shown below:
	
V
I Z
LI
s I
s
s
s
s
o
1
1
1
2
0 1
0 4
0 4
32
10
160
0 4
=
−
=
−
=
+
+
+
−
( . )
.
.
(
)(
)
.
	
(2.78)
	
V
I Z
V
s
s
I
s
s
s s
s
s
o
2
2
2
160
32
640
51200
10
160
32
=
+
= 



+
= −
+
+
+
+
,
(
)(
)
	
(2.79)
8 Ω
R1
R2
17 Ω
+
+
+
–
–
–
100 V
9 Ω
100 mH
6.25 mF
t =0
i1
v1
v2
i2
FIGURE 2.23  Laplace analysis circuit.
© 2011 by Taylor and Francis Group, LLC

2-20 
Fundamentals of Industrial Electronics
8 Ω
9 Ω
17 Ω
100 V
v1
i1
i2
100 mH
6.25 mF
+
(a)
+
–
–
v2
+
–
i1(0–) =100/25= 4 A
v1(0–) =0 V (short circuit)
v2(0–) =4(8) = 32 V
i2(0–) =0 A (open circuit)
8 Ω
+
–
+
–
(c)
9 Ω
100 mH
6.25 mF
v1
v2
i1
i2
i1(∞)= 0 A
v2(∞)= 0 V
i2(∞)= 0 A
v1(∞)= 0 V
8 Ω
+
–
+ +
–
(b)
–
4 A
100 mH
32 V
6.25 mF
i1
v1
v2
i2
9 Ω
i1(0+) = 4 A
v1(0+) = 32 – 4(17) = –36 V
v2(0+) = 32 V
i2(0+) = –4 A
FIGURE 2.24  Initial conditions analysis circuits. (a) t = 0−, (b) t = 0+, and (c) t → ∝.
© 2011 by Taylor and Francis Group, LLC

AC Circuit Analysis 
2-21
Finding the inverse Laplace transform of (2.78) and (2.79) yields
	
v t
u t
t
t
1
16
1
3413e
 187e
V
( )
(
.
.
) ( )
= −
−
−
0
0
−
	
(2.80)
	
v t
u t
t
t
2
1
16
2987e
213e
V
( )
(
.
.
) ( )
=
+
−
−
0
0
	
(2.81)
It can be confirmed that the solutions do obey the initial and final values shown in Figure 2.17. If the 
circuit was given in the s-domain instead of the time domain, it is also possible to find the initial and final 
value for voltages and currents by using the initial and final value theorems. These theorems are given 
in Equations 2.82 and 2.83. Note that the solutions to these equations are also consistent with the condi-
tions presented in Figure 2.24.
	
Initial value theorem: lim ( )
lim
( )
t
s
f t
sF s
→
→∞
=
0
	
(2.82)
	
Final value theorem:
lim ( )
lim
( )
t
s
f t
sF s
→∞
→∞
=
	
(2.83)
Example 2.10:  Laplace Circuit Analysis
Now let us examine what happens if the 9 Ω resistor in Figure 2.16 is replaced with a wire. Notice that this 
resistor changes only one initial condition, v1(0+) is 0 V. Based upon this change to the circuit, the values 
of I1, I2, and V1, and V2 also change:
	
I
s
s
s
s
s
1
2
2
4
320
80
1600
4
320
40
=
+
+
+
=
+
+
(
) 	
(2.84)
	
V
I Z
LI
s I
s
s
s
o
1
1
1
2
2
0 1
0 4
0 4
32
40
0 4
=
−
=
−
==
+
+
−
( . )
.
.
(
)
.
	
(2.85)
	
V
I Z
V
s
s
I
s
s
s s
s
o
2
2
2
2
160
32
640
51200
40
32
=
+
= 



+
= −
+
+
+
,
(
)
	
(2.86)
The inverse Laplace transform of Equations 2.87 through 2.89 are completely different forms when com-
pared to the prior analysis. These values are presented in Equations 2.87 through 2.89:
	
i t
t u t
i t
t
1
4
2
4e
1 4
 A
( )
(
) ( )
( )
=
+
= −
−0
0
	
(2.87)
8 Ω
9 Ω
R1
R2
+
+
I1
V1
V2
I2
–
+
–
–
+
–
0.4
0.1 s
160
s
32
s
FIGURE 2.25  Figure 2.23 in the s-domain.
© 2011 by Taylor and Francis Group, LLC

2-22 
Fundamentals of Industrial Electronics
	
v t
t
u t
t
1
4
(
64 e
 V
)
(
) ( )
= −
−
0
0
	
(2.88)
	
v t
t u t
t
2
4
(
32e
1 2
 V
)
(
) ( )
=
+
−0
0
	
(2.89)
Example 2.11:  Laplace Circuit Analysis
Now let’s examine what happens if the 9 Ω resistor is still a wire and the 8 Ω resistor in Figure 2.16 is 
replaced with a 4.8 Ω resistor. The circuit now looks like that shown in Figure 2.26.
Notice that the removal of this resistor changes more than just the value of v1(0+). The new initial and 
final conditions and the new values are summarized in Table 2.5.
Based upon these changes to R1 and R2, the values of I1, I2, and V1, and V2 become
	
I
s
s
s
s
s
j
s
j
I
1
2
2
4 59
220
48
1600
4 59
220
24
32
24
32
=
+
+
+
=
+
+
−
+
+
= −
.
.
(
)(
)
	
(2.90)
	
V
I Z
LI
s I
s
s
s
j
s
j
o
1
1
1
2
0 1
0 459
0 459
22
24
32
24
32
=
−
=
−
=
+
+
−
+
+
−
( . )
.
.
(
)(
)
0 459
.
	
(2.91)
	
V
I Z
V
s
s
I
s
s
s s
j
s
o
2
2
2
160
32
73 4
35 200
24
32
24
=
+
= 



+
= −
+
+
−
+
+
.
,
(
)(
j
s
32
32
) +
	
(2.92)
The inverse Laplace transform of Equations 2.90 through 2.92 are completely different forms of responses 
than the prior analysis. These values are presented in Equations 2.93 through 2.95:
	
i t
t
u t
i t
t
1
24
2
( ) 
 573e
cos 32
3679
 A 
=
−
°
= −
−
.
(
(
.
) ( )
( ) 	
(2.93)
	
v t
t
u t
t
1
24
( ) 
 2293e
cos 32
9
 V
=
+
°
−
.
(
(
) ( )
0
	
(2.94)
	
v t
t
u t
t
2
24
( ) 
 2619e
cos 32
3285
 V
=
−
°
−
.
(
(
.
) ( )
	
(2.95)
TABLE 2.5  New Initial Conditions for Figure 2.26
t = 0−
t = 0+
t = ∞
i1(0−) = 100/21.8 = 4.59 A
i1(0+) = 4.59 A
i1(∞) = 0 A
v1(0−) = 0 V (short circuit)
v1(0+) = 22 − 4.49(4.8) = 0 V
v1(∞) = 0 V
i2(0−) = 0 A (open circuit)
i2(0+) = −4.59 A
i2(∞) = 0 A
v2(0−) = 4.8(4.59) = 22 V
v2(0+) = 22 V
v2(∞) = 0 V
4.8 Ω
17 Ω
t = 0
R1
100 V
100 mH
6.25 mF
+
+
+
–
–
–
i1
i2
v2
v1
FIGURE 2.26  Modified Figure 2.16 (R1 = 4.8 Ω, R2 = 0 Ω).
© 2011 by Taylor and Francis Group, LLC

AC Circuit Analysis 
2-23
Example 2.12:  Transfer Functions
Assuming zero initial conditions, the transfer function, H(s), of a system or circuit is the ratio of the output, 
Y(s), to the input, X(s), in the s-domain. The transfer function is very useful for characterizing the circuit 
behavior, stability, and responses. The transfer function is defined as
	
H s
Y s
X s
( )
( )
( )
=
=
output
input
	
(2.96)
Figure 2.27 presents a system description of the transfer function, input, and output.
The transfer function is a rational function of s, and the denominator of the transfer function is the 
characteristic equation of the system. The roots of this characteristic equation can be used to determine 
the system stability. The roots of the characteristic equation are called the poles. The roots of the numera-
tor of the transfer function are called zeros. The poles are used to identify the frequencies where the 
system will grow without being bound or becoming unstable. The graph of the poles of a system on the 
s-plane can be used to quickly identify whether a system is stable. On the s-plane, the zeros are presented 
as O’s and the poles are represented as X’s. If all of the poles of the system are on the open left-hand 
plane, then the system is stable. Another way of stating this criteria is that “if the real part of the pole is 
negative,” then the system will be stable. If the poles are purely imaginary, then the system is marginally 
stable, otherwise it is unstable. Figure 2.28 illustrates the graphical relationship between system poles and 
stability.
2.3.2.2.1  Types of Responses
It is evident from the examples of the Laplace analysis that there are three forms of the solutions for 
second-order circuits. Recall that a second-order circuit is one that can be described by a second order 
differential equation and these circuits have all three passive circuit elements: resistors, inductors, and 
capacitors. The three types of responses are overdamped, underdamped, and critically damped. The over-
damped response has a slow response and a long settling time. The critically damped response has a fast 
response and a short settling time. The underdamped response has the fastest response and long settling 
time. It is possible to determine the type of response a circuit will have by examining the roots of the 
characteristic equation. Equation 2.77 is an example of an overdamped response. Equation 2.87 is an 
example of a critically damped response. Equation 2.93 is an example of an underdamped response. 
Table 2.6 presents a summary of the three types of responses and roots of the characteristic equations as 
they relate to the Laplace analysis examples.
H(s)
X(s)
Y(s)
Input
Output
FIGURE 2.27  Transfer function representation of a system.
Stable
s-plane
σ±jω
Marginally stable
O
X
X
Unstable
Real axis, σ
FIGURE 2.28  Poles on the s-plane and stability.
© 2011 by Taylor and Francis Group, LLC

2-24 
Fundamentals of Industrial Electronics
TABLE 2.6  Types of Second Order Responses
Overdamped (Example 2.9)
Critically Damped (Example 2.10)
Underdamped (Example 2.11)
Slow rise time, long settling time
Fast rise time, short settling time
Fast rise time, long settling time
Characteristic equation has two distinct real roots, 
i.e., (s + 160)(s + 10)
Characteristic equation has repeated real roots, i.e., (s + 40)2
Characteristic equation has two complex conjugate roots, 
i.e., (s + 24 + j32)(s + 24 − j32)
4.5
i1(t), A
Time, s
4
3.5
3
2.5
2
1.5
1
0.5
0
0
0.1
0.2
0.3
0.4
0.5
1
4.5
i1(t), A
4
3.5
3
2.5
2
1.5
0.5
0
0
0.1
0.2
0.3
0.4
0.5
Time, s
i1(t), A
5
4
3
2
1
0 0
0.1
0.2
0.3
0.4
0.5
Time, s
–1
© 2011 by Taylor and Francis Group, LLC

AC Circuit Analysis 
2-25
2.3.2.2.2  Impulse Response
From Equation 2.96, it is evident that the output of a system can be found from the transfer function 
by using
	
Y s
H s X s
( )
( ) ( )
=
	
(2.97)
The impulse response of a system is the output, y(t), when the input is an impulse function, x(t) = δ(t). 
Since the Laplace transform of δ(t) is 1, X(s) = 1 so
	
Y s
H s
( )
( )
=
	
(2.98)
	
y t
L
H s
h t
( )
( )
( )
=
{
} =
−1
	
(2.99)
2.3.2.2.3  Step Response
The step response of a system is the output, y(t), when the input is a step function, x(t) = u(t). Since the 
Laplace transform of u(t) is 1/s, X(s) = 1/s so
	
Y s
s
H s
( )
( )
= 



1
	
(2.100)
	
y t
L
s
H s
( )
( )
=










−1
1
	
(2.101)
2.3.2.2.4  Sinusoidal Steady-State
Recall from the phasor analysis section that the steady-state sinusoidal response is the output when the 
input is x(t) = A cos (ωt + ϕ). The Laplace transform of the input, x(t), is
	
X s
As
s
A
s
A s
s
( )
cos
sin
( cos
sin )
=
+
−
+
=
−
+
φ
ω
ω
φ
ω
φ
ω
φ
ω
2
2
2
2
2
2
	
(2.102)
The output is
	
Y s
H s X s
H s A s
s
( )
( ) ( )
( )
( cos
sin )
=
=
−
+
φ
ω
φ
ω
2
2
	
(2.103)
and using partial fraction expansion,
	
Y s
H s
K
s
j
K
s
j
( )
( )
=
+
−
+
+
terms from poles of 
1
1
ω
ω
*
	
(2.104)
The complete response y(t) can be separated into the steady-state and transient response, or the natural 
response and forced response:
	
y t( ) 
 steady-state 
 transient response
=
+
	
(2.105)
© 2011 by Taylor and Francis Group, LLC

2-26 
Fundamentals of Industrial Electronics
	
y t( ) 
 natural 
 forced response
=
+
	
(2.106)
The natural response is due to the stored energy in the circuit being released and the forced response is due 
to the input or independent source suddenly applied. The transient response is the changing part of the 
response that decays exponentially as time increases. The steady-state response is the part that remains 
after all of the transient decays off. Therefore, only the input, X(s), terms in Equation 2.104 contribute to 
the steady-state response. The terms due to the transfer function, H(s), are transient and approach 
0 as t approaches ∞. The poles of the transfer function, H(s), are in the open left-half of the s-plane (they 
have to be for stability!). The poles of the sinusoidal input, X(s), are on the imaginary axis of the s-plane 
because they oscillate forever. Using partial fraction expansion to solve for K1 in Equation 2.104 yields
	
K
H s A s
s
j
H j
A
A H j
s
j
j
j
1
1
2
2
=
−
+
=
=
=
+
( ) ( cos
sin )
(
)
(
)
[ ( )
φ
ω
φ
ω
ω
ω
ω
φ
θ ω
φ
e
e
]
	
(2.107)
From these results, the response due to the steady-state is
	
Y
j
A
j
ss
e
(
)
(
(
))(
)
| (
)|
(
( ))
ω
φ θ ω
=
∠
=
+
H j
A
H j
ω
ϕ
ω
	
(2.108)
The steady-state solution for y(t) or the steady-state sinusoidal response is
	
y t
A
t
ss
cos
( )
|
(
)|
[
( )]
=
+
+
H jω
ω
φ
θ ω
	
(2.109)
The amplitude of the solution is equal to the amplitude of the source, A, times the magnitude of the 
transfer function, |H(jω)|. The phase angle of the response is equal to the phase angle of the source, ϕ, 
plus the phase angle of the transfer function, θ(ω), at the frequency of the source, ω.
2.3.2.2.5  Complete Response
It is also possible to find the complete response (steady-state and transient) due to an excitation by find-
ing the Laplace transform of the input and solving for the product H(s)X(s). The complete response, y(t), 
is the inverse Laplace transform of Y(s).
2.3.3  Impulse Response Example
For the circuit shown in Figure 2.29a, find the transfer function H(s) = Vo(s)/VS(s) and the impulse 
response. Recall that the transfer function assumes zero initial conditions. The first step in the solution 
is to convert the circuit to the s-domain and this is shown in Figure 2.29b.
Next, use the node-voltage method to find the voltage across the resistor:
	
sV
G
V
V
s
V
s
o
o
o
s
1
1000
1000
1000
+
+
=
	
(2.110)
0.001 s
(b)
Vs
Vo
+
+
1G
s
–
–
1 kΩ
1000 μH
(a)
1000 pF
+
+
–
–
vs
vo
1 kΩ
FIGURE 2.29  Transfer function example circuit. (a) Time domain and (b) s domain.
© 2011 by Taylor and Francis Group, LLC

AC Circuit Analysis 
2-27
Solving for Vo yields
	
V
T
s
Ms
T V
o
s
=
+
+
1
1
1
2
	
(2.111)
Finally solve for the transfer function, H(s) = V(s)/VS(s),
	
H s
V
V
T
s
Ms
T
o
S
( ) =
=
+
+
1
1
1
2
	
(2.112)
Recall that the impulse response is the output, y(t), when the input x(t) = δ(t), this is found from (2.113):
	
V s
H s V s
H s
T
s
Ms
T
o
s
( )
( )
( )
( )( )
=
=
=
+
+
1
1
1
1
2
	
(2.113)
The inverse Laplace of (2.113) yields the impulse response
	
h t
v t
M
kt
u t
o
kt
( )
( )
( .
(
)) ( )
=
=
−
°
−
 
 115
e
cos 866
9
 V
500
0
	
(2.114)
2.3.4  Step Response Example
It is also possible to use the transfer function in the equation in (2.112) to find the step response. If the 
input is vs(t) = u(t), then
	
V s
H s V s
H s
s
T
s s
Ms
T
o
s
( )
( )
( )
( )
(
)
=
=



=
+
+
1
1
1
1
2
	
(2.115)
The inverse Laplace of (2.115) yields the step response
	
v t
kt
u t
o
k
( )
.
(
) ( )
=
+
−
°
−
 1 115e
cos 866
9
 V
500
0
t
	
(2.116)
2.3.5  Sinusoidal Steady-State Example
To use the transfer function, H(s), to find the sinusoidal steady-state response, assume that the input vs(t) = 
5 cos (700kt) V. The first step in the solution is to find the value of the transfer function H(jω) at ω = 700 krad/s:
	
H j
H j
k
T
j
k
M j
k
T
(
)
(
)
(
)
(
)
.
.
ω =
=
+
+
=
∠−
°
700
1
700
1
700
1
1 15
53 92
2
	
(2.117)
Using Equation 2.108,
	
V
j
oss(
)
(
(
))(
.
)(
)
.
.
ω
ω
φ
=
∠
∠−
°
∠° =
∠−
°
H j
A
)= (1.15
53 92
5 0
5 75
53 92 V 	
(2.118)
Finally, the answer can be found from Equation 2.109:
	
v
t
kt
u t
oss( )
5 75 cos 7
53 92
 V
=
−
°
.
(
.
) ( )
00
	
(2.119)
© 2011 by Taylor and Francis Group, LLC

2-28 
Fundamentals of Industrial Electronics
2.3.6  Complete Response Example
It is also possible to find the complete response (steady-state and transient), vo(t), due to the input vs(t) = 
5 cos (700kt) V. The first step is to find the Laplace transform of vs(t):
	
V s
s
s
k
s( )
(
)
=
+
5
700
2
2 	
(2.120)
Then to find the output, Vo(s), use the following equation:
	
V s
H s V s
T
s
Ms
T
s
s
k
o
s
( )
( )
( )
(
)
=
=
+
+




+




1
1
1
5
700
2
2
2
	
(2.121)
In order to find vo(t), it is necessary to find the constants, C1 and K1, of the partial fraction expansion 
shown in (2.122):
	
V s
C
s
k
j
k
C
s
k
j
k
K
s
j
k
K
s
j
k
o( )
*
*
=
+
−
+
+
+
+
−
+
+
1
1
1
1
500
866
500
866
700
700
	
(2.122)
The constants for this expression are
	
C
T
s
k
j
k
s
s
k
s
k
j
k
1
2
2
2
500
866
1
500
866
5
700
3
=
+
+




+




=
=−
+
(
)
.333 120 66
∠
°
.
	
K
T
s
Ms
T
s
s
j
k
s
j
k
1
2
700
1
1
1
5
700
2 887
53 92
=
+
+




+




=
∠−
°
=
.
.
	
(2.123)
The answer for the complete response is found by using the formula in (2.124):
	
v t
C
t
K
t
o
t
C
K
( )
|
|
(
)
(
)
 
 2
e
cos
2
 cos
1
1
1
1
=
+ ∠
+
+ ∠
−α
ω
θ
ω
θ
	
(2.124)
Finally the answer for the complete response is
	
v t
kt
kt
o
kt
( )
.
(
.
)
.
(
.
 
 6 67e
cos 866
12 66
5 77 cos 1
53 92
5
=
+
° +
−
−00
0
00
°) ( )
u t  V 	
(2.125)
Notice that this equation is indeed the sum of the transient and steady-state response.
2.4  Complex Power
2.4.1  Instantaneous, Average, and Reactive Power
The instantaneous power for an AC circuit is given by the equation p = vi, where the units are watts (W). 
Since the source is a sinusoidal voltage or current source, this yields
	
p t
V I
t
m m
v
i
v
i
v
i
( ) =
−
+
−
−
−
 
 
cos
  cos
 cos 2
sin
s
1
2
(
(
)
(
)
(
)
(
)
θ
θ
θ
θ
ω
θ
θ
in 2
(
))
ωt
	
(2.126)
Recall that Vm and Im represent the maximum values or magnitude of the voltage and current sinusoids, 
respectively. This relationship is found by using trigonometric properties to rearrange the product of the 
two sinusoids. Note that this expression includes a constant term plus the sum of two sinusoids at fre-
quencies double the voltage and current frequency. Figure 2.30 illustrates the plot of the voltage, current, 
© 2011 by Taylor and Francis Group, LLC

AC Circuit Analysis 
2-29
and instantaneous power waveforms. During the positive portion of the power waveform, energy is 
being stored in an inductor and/or capacitor, and during the negative portion, energy is being released 
back into the circuit. Also, notice that the waveform is offset by a real positive number that represents 
the average (real) power, P. The average power is the useful output of a device typically transformed 
from electric to nonelectric energy. The reactive power, Q, represents the energy stored in an inductor 
or capacitor. The reactive power is the energy that is transferred back and forth in the circuit but is not 
converted into nonelectric energy.
The instantaneous power expression in (2.126) can be written in terms of the real and reactive 
power as
	
p t
P
P
t
Q
t
( )
(
)
(
)
]
 
cos 2
sin 2
 [W
=
+
−
ω
ω
	
(2.127)
where
	
P
V I
m m
v
i
=
−
1
2
cos(
)[
]
θ
θ
W
	
(2.128)
	
Q
V I
m m
v
i
=
−
1
2
sin(
)[
]
θ
θ
VAR
	
(2.129)
The angle, θv − θi, in the instantaneous power expression is the power factor angle. The cosine of the 
power factor angle is the power factor (pf = cos (θv − θi)). The power factor represents the effectiveness of 
a load to absorb the average power from a source. In other words, the higher the power factor, the more 
power will be delivered to the load. A power factor is lagging if the current lags the voltage (i.e., current 
peaks after the voltage). The current is leading if the current peaks before the voltage. Table 2.7 presents 
a summary of the relationships between instantaneous, average, reactive power, and power factor for 
purely resistive, inductive, and capacitive circuits.
2.4.2  Effective or RMS Value
The RMS (root mean square) value of a periodic function is given by
	
X
T
x t
dt
t
t
T
o
o
rms =
+∫
1
2
( )
	
(2.130)
Instantaneous power
Average power
Current
Time, s
Voltage
FIGURE 2.30  Instantaneous and average power.
© 2011 by Taylor and Francis Group, LLC

2-30 
Fundamentals of Industrial Electronics
TABLE 2.7  Ideal Transformer Dot Convention
Purely Resistive
Purely Inductive
Purely Capacitive
Circuit
i
+
–
v
R
i
v
L
+
–
i
v
C
+
–
Waveforms
Time, s
Instantaneous power
Average power
Current
Voltage
Time, s
Current
Instantaneous power Voltage
Average power
Time, s
Current
Instantaneous power
Voltage
Average power
Instantaneous 
power
p(t) = P + P cos(2ωt)
p(t) = −Q sin(2ωt)
p(t) = −Q sin(2ωt)
Average 
power, P
P > 0
P = 0
P = 0
Reactive 
power, Q
Q = 0
Q > 0
Q < 0
Power factor
pf = 1
pf lagging
pf leading
θv − θi = 0°
θv − θi > 0°
θv − θi < 0°
© 2011 by Taylor and Francis Group, LLC

AC Circuit Analysis 
2-31
However, if the periodic function is a sinusoid, then this expression reduces to
	
X
T
X
t
dt
X
m
t
t
T
m
o
o
rms =
+
(
)
=
+∫
1
2
2
2
cos
,
ω
φ
	
(2.131)
where T is the period.
The RMS value is also referred to as the effective value of a sinusoidal current or voltage source. The 
term effective value is based upon the fact that given an equivalent resistive load and an equivalent 
time period, the RMS value of a source delivers the same energy to the resistor as a DC source of the 
same value. Thus, the average and reactive power expression in Equations 2.128 and 2.129 can also be 
written in terms of the RMS value:
	
P
V
I
v
i
=
−
rms rmscos
 [W]
(
)
θ
θ
	
(2.132)
	
Q
V
I
v
i
=
−
rms rmssin
 [VAR]
(
)
θ
θ
	
(2.133)
Also, if a sinusoidal voltage or current source is supplied to a resistor, then the average power delivered 
to the resistor is
	
P
V
R
I
R
rms
rms
=
=
2
2
[W]	
(2.134)
2.4.3  Complex and Apparent Power
Complex Power, S, is the complex sum of the average and reactive power given by
	
S
V I
V
I
m m
rms rms
= P + jQ = 1
2
* =
* [
]
VA
	
(2.135)
As is evident from this expression, the complex power can also be found from the voltage and current 
phasors in the circuit. The magnitude of the complex power is the apparent power, |S|, and can be found 
from the following expression:
	
S =
+
P
Q
2
2 [
]
VA 	
(2.136)
The apparent power of a device represents the volt-ampere capacity to supply the average power. This 
value may be more useful in designing a device than the average power that represents the useful output 
of an energy-converting device. Thus, the power factor indicates the capability of a device to convert the 
apparent power supplied to the useful output or average power. To summarize the units of AC power 
are watts (W) for instantaneous and average power, Volts–Amperes Reactive (VARS) for reactive power, 
and volts–amperes (VA) for complex power and apparent power.
There is also a geometric relationship between average, reactive, apparent, complex power, power fac-
tor, and impedance. This relationship can be represented by the impedance and power triangles that are 
useful when performing complex power calculations. The power and impedance triangles are shown in 
Figure 2.31.
© 2011 by Taylor and Francis Group, LLC

2-32 
Fundamentals of Industrial Electronics
2.4.4  Maximum Average Power Transfer
When designing a power delivery system, the design goal is to transfer the maximum amount of volt-
age from the source to the load. However, in some communication and power electronic circuits, it 
is desired to design a system to deliver the maximum power to the load. This can be achieved with 
impedance matching or by setting the load impedance equal to the conjugate of the Thevenin equivalent 
impedance (ZL = Zth*) of the source circuit. The Thevenin equivalent impedance, Zth, of the source is the 
net equivalent impedance seen looking into the terminals of the source when all independent sources 
are disabled. The value of the maximum power transferred can be found by using the load resistance 
and the Thevenin equivalent voltage, Vth. The Thevenin equivalent voltage is the open circuit voltage 
found when looking back into the terminals of the source. The value for the maximum average power 
is given by
	
Pmax
th
L
th
L
V
R
V
R
=
2
2
4
8
(
(
)[
]
rms) =
peak
W
	
(2.137)
Sometimes there are restrictions on the load and it is not possible to set this value to the conjugate of 
the Thevenin equivalent impedance. One solution is to design the load impedance magnitude to equal 
the magnitude of the Thevenin impedance, |ZL| = |Zth|. Alternately, if there are restrictions on the values 
of the resistance or reactance, it is possible to design XL as close as possible to Xth and then adjust RL as 
close as possible to R
X
X
Th
L
Th
2
2
+
+
(
) . Lastly, when the load impedance is set and cannot be adjusted 
at all, an ideal transformer can be used to design for impedance matching. Impedance matching is the 
process of designing a system to match the source and load impedance in order to maximize the average 
power delivered to the load.
2.4.5  Power Factor Correction
Most industrial loads are inductive with a lagging power factor. Power factor correction is the method 
used to increase the power factor of a load for more effective delivery of the average power from the 
source. Increasing the load power factor can be achieved by placing a capacitor in parallel with the load. 
The addition of this capacitor will decrease the phase angle between the voltage and the current supplied 
to the load but the average power will not be changed. The load with the capacitor draws less current 
which reduces the average power loss in transmission. The ideal solution is to reduce the reactive power 
because this is the energy that is transferred back and forth, and that is not lost. A shunt capacitor across 
(b)
(a)
Apparent power
Average power
P, W
θ
θ
|S|, VA
Apparent power
Reactive power, VAR
Q >0 Inductive load
Q = 0 Resistive load
Q <0 Capacitive load
Impedance
θ
θ
Reactance,
Inductor
Capacitor
Resistance
R, Ω
XL> 0
XC < 0
Impedance
|Z|, Ω
|Z|, Ω
Z =R+ jX [Ω] 
S = P + jQ [VA] 
θ=θv – θi
θ=tan–1(X/R)=tan–1(Q/P)
pf=cos (θ) 
|S|, VA
FIGURE 2.31  (a) Impedance and (b) power triangles.
© 2011 by Taylor and Francis Group, LLC

AC Circuit Analysis 
2-33
the load will decrease this oscillating energy. Figure 2.32 presents a 
circuit and phasor diagram for an inductive load before and after the 
power factor correction.
The process of the power factor correction can also be illustrated 
using the power triangle where θ1 represents the original power fac-
tor angle and θ2 represents the corrected power factor angle. It is evi-
dent from Figure 2.33 that the addition of the capacitor only changes 
the reactive power and leaves the average power unchanged.
It is possible to use the power triangle in Figure 2.33 to determine the 
value of the capacitor that is necessary to adjust the load to the desired 
power factor angle of θ2. The equations found from the figure are
	
Q
P
1
1
tan
=
θ 	
(2.138)
	
Q
P
2
2
tan
=
θ 	
(2.139)
	
Q
Q
Q
P
C =
−
=
−
1
2
1
2
tan
tan 
(
)
θ
θ
	
(2.140)
Finally, the value of the shunt capacitance can be found from (2.133) and is given by
	
C
Q
V
C
= ω
rms
2
	
(2.141)
Example 2.13:  RMS and Average Power
The waveform in Figure 2.34 represents the voltage across a 10 Ω resistor. What is the average power 
absorbed by the resistor?
The first step in the solution is to find the RMS value of the voltage waveform by using Equation 2.130:
	
V
t dt
dt
rms =
+
=
∫
∫
1
2 120
1
2 120
120 2
3
2 2
0
1
2
1
2
	
(2.142)
Finally, the average power delivered to the resistor is found from Equation 2.134:
	
P
V
R
=
=
rms
2
960 W 	
(2.143)
θ1
S1
Q1
Q2
P
S2
QC
θ2
FIGURE 2.33  Power factor cor-
rection and the power triangle.
+
–
(b)
V
IL
IC
I
+
(a)
–
V
IL
θ2
θ1
(c)
V
IC
IL
I
FIGURE 2.32  Power factor correction. (a) Original load, (b) load with capacitor, and (c) phasor diagram.
© 2011 by Taylor and Francis Group, LLC

2-34 
Fundamentals of Industrial Electronics
Example 2.14:  Law of Conservation of Energy (Power Triangle)
For the system shown in Figure 2.35, the load consists of three devices. Device 
A includes ten 60 W light bulbs, device B is a 3 kW kitchen range with a 0.8 pf 
leading, and device C is a 700 VA television with a 0.4 pf lagging. Determine 
the complex power supplied by the source.
It is possible to create a power triangle for each of the devices and then 
use trigonometry to find the complex power delivered to each of them (see 
Figure 2.36). Based upon the law of conservation of energy, the complex 
power supplied by the source will be the sum of the complex power deliv-
ered to the load.
Since device A has only average power, there is no reactive power. In order 
to find QB, PC, and QC, use the following equations:
	
θ
θ
B
B
=
= −
°
<
−
 cos ( 8
3687
 for leading pf
1 0
0
. )
.
(
) 	
(2.144)
	
θ
θ
C
C
=
=
°
>
−
 cos
4
6642
 for lagging pf
1( . )
.
(
)
0
0
	
(2.145)
	
Q
P
B
B
B
=
= −
tan 
225 kVAR
(
)
.
θ
	
(2.146)
	
P
S
C
C
C
=
=
cos 
28  W
(
)
θ
0
	
(2.147)
	
Q
S
C
C
C
=
=
sin
64156 VAR
(
)
.
θ
	
(2.148)
θC
700 VA
SC
QC
PC
(c)
θB
PB
SB
QB
3 kW
(b)
Device A
Device B
Device C
PA=600 W
(a)
FIGURE 2.36  Device power triangles. (a) Resistive load, (b) capacitive load, and (c) inductive load.
0
0
120
1
v(t), V
2
3
Time, s
4
5
FIGURE 2.34  Voltage waveform.
+
–
V
A
C
B
I
FIGURE 2.35  Real and 
reactive power.
© 2011 by Taylor and Francis Group, LLC

AC Circuit Analysis 
2-35
Therefore, summing the complex power absorbed by each of the devices yields
	
S =
+
+
=
+
+
+
+
+
=
−
=
∠−
S
S
S
P
P
P
j Q
Q
Q
j
A
B
C
A
B
C
A
B
C
(
)
.
.
.
.
 
388
161 kVA
 42
2252 kVA
°
	
(2.149)
Example 2.15:  Average Power Line Losses
In order to compare power line losses for a power delivery system with and without an ideal transformer, 
the circuit in Figure 2.37 will be analyzed. If the power delivered to the load is 153 W at 120 Vrms, what is 
the average power lost in the line? This can be found by solving for the current, IL, using the power rating 
and voltage VL:
	
IL =
+
=
∠−
°
120
7 5
3 8
14 28
26 87
.
.
.
.
j
A
	
(2.150)
The average power lost in the line is given by
	
P
IL
=
=
 
2  
 4 74 W
2( . )
.
0
0
	
(2.151)
However, how does this compare to the power delivery system with the ideal transformer? The circuit 
in Figure 2.38 models a power delivery system with a source, transmission line, and load. One benefit of 
using a transformer is that it reduces the average power loss in the line by stepping up the voltage to the 
line and reducing the current. This method also saves costs because smaller wires can be used to carry 
the current. For the following figure, determine the average power lost in the line, the power delivered 
to the load, and the power factor. Finally, compare the average power lost in the line to a similar system 
without the transformer.
Source
Line
Load
IL
IL
Vs
Is
V3
–
+
V2
–
+
V1
–
+
VL
–
+
–
+
0.2 Ω
7.5 Ω
j3.8 Ω
1:10
10:1
FIGURE 2.38  Power delivery system with a transformer.
0.2 Ω
j3.8 Ω
7.5 Ω
+
Source
Is
IL
Vs
VL
Line
Load
+
–
–
FIGURE 2.37  Power delivery system without a transformer.
© 2011 by Taylor and Francis Group, LLC

2-36 
Fundamentals of Industrial Electronics
The first in the step would be to use reflection to determine the line current in the feeder:
	
I
IL
1 =
=
∠−
° =
∠−
°
 
1
 11428
2687
143
2687 A
( . )
. (
.
.
)
.
.
0
0
	
(2.152)
Notice that the line current is greatly reduced with the voltage stepped up from the source. The average 
power lost in the line is now given by
	
P
I
=
=
 
2
4 741 mW
2
| | ( . )
.
1
0
0
	
(2.153)
The loss of power in the line is significantly reduced by a magnitude of 100 as compared with the circuit 
in Figure 2.37. However, the power delivered to the load is still 153 W at 120 Vrms at 0.892 pf lagging.
Example 2.16:  Apparent Power (Autotransformers)
In order to compare the performance of an autotransformer and an ideal transformer with the same 
turns ratio, the circuits in Figures 2.39 and 2.40 will be analyzed to determine the voltage and apparent 
power delivered to the load. The process to find the voltage and apparent power involves using the ideal 
transformer terminal equations and KCL. For the circuit in Figure 2.39, reflection from the primary to the 
20 Ω
120    0° Vrms
+
–
+
–
+
–
7.5 Ω
j3.8 Ω
N2=1
N1=10
Source
Line
Load
V1
V2
I2
I1
IL
FIGURE 2.40  Autotransformer apparent power.
20 Ω
120   0° Vrms
Source
Line
Load
+
+
+
7.5 Ω
j 3.8 Ω
10:1
–
–
–
V1
V2
I1
I2
FIGURE 2.39  Ideal transformer apparent power.
© 2011 by Taylor and Francis Group, LLC

AC Circuit Analysis 
2-37
secondary is used to find the load current and the voltage, and apparent power. These values are shown 
in (2.154) through (2.156):
	
I2 =
+
+
=
∠−
°
12
0 2
7 5
3 8
1 4
26 27
.
.
.
.
.
j
A 	
(2.154)
	
V
I
2
2
=
+
=
∠
°
( .
. )
.
.
75 
38
1175
6 V
j
0
	
(2.155)
	
S
V I
L =
=
∠
°
=
+
2 2*
16 42 26 87
14 65
7 422
.
.
.
.
VA
VA
j
	
(2.156)
Therefore, the load has 11.75 V at 14.65 W delivered to it. The derivation of the load voltage and the 
apparent power for the autotransformer in Figure 2.40 involves creating the ideal transformer terminal 
relationships, performing KVL around the left and right mesh, and KCL at the autotransformer tap. This 
configuration is a step-down transformer with a subtractive connection. It is not possible to ­perform 
reflection on this circuit because the sides are not decoupled. This analysis yields the following five 
equations:
	
20
0
I
V
V
1
1
2
+
+
=12 	
(2.157)
	
( .
. )
75
38
+
−
=
j
I
V
L
2
0 	
(2.158)
	
I
I
IL
1
2
=
+
	
(2.159)
	
V
V
2
1
= −0.1
	
(2.160)
	
I
I
1
2
=  1
0.
	
(2.161)
Solving this system of five equations yields
	
IL =
∠
°
155 15387 V
.
.
	
(2.162)
	
V2 =
∠−
°
13
17926 V
.
	
(2.163)
	
S
V I
L =
=
∠
°
=
+
2 2*
20 08 26 87
17 91
9 07
.
.
.
.
VA
VA
j
	
(2.164)
Observe that the same transformer in the autotransformer configuration delivers a slightly higher volt-
age, power, and apparent power with the same power factor.
Example 2.17:  Power Factor Correction
In order to design a system for maximum efficiency of power delivery, it may be necessary to design the 
load to have a certain power factor. For example, the higher the power factor, the smaller the reactive 
power and the larger the average power delivered to the load. Since the reactive power, Q, represents 
energy that is exchanged back and forth between the source and the load, it would be ideal to reduce 
this. The power factor of a load can be corrected by putting a capacitor in parallel with it. This will be 
demonstrated by designing the circuit in Figure 2.41 to have a power factor of 0.95.
The first step would be to determine the power factor and average power delivered to the load of the 
original circuit. This can be done by using the following equations:
	
θold =
=
°
−
tan
38 75
2687
1( . / . )
.
	
(2.165)
© 2011 by Taylor and Francis Group, LLC

2-38 
Fundamentals of Industrial Electronics
	
pf
old
=
=
cos
892
(
)
.
θ
0
	
(2.166)
	
IL =
+
+
=
∠−
°
12
2
75
38
1398
2627 A
0
0
/ ( .
.
. )
.
.
j
	
(2.167)
	
V
I
L
L
=
+
=
∠
°
( .
. )
.
.
75
38
1175
6 V
j
0
	
(2.168)
	
S
V I
L
L L
=
=
∠
° =
+
*
1642 26 87
1465
742 17
.
.
j
VA 	
(2.169)
Thus, the average power delivered to the load is 1.47 kW at a 0.89 pf lagging. In order to increase the 
power factor without changing the average power, a shunt capacitor must be placed in parallel with the 
load. The formula to determine the value of the capacitor is
	
C
Q
V
P
V
C
old
new
=
=
−
ω
θ
θ
ω
rms
rms
2
2
(tan
tan
) 	
(2.170)
The desired power factor can be used to determine the new power factor angle and this value can be 
substituted into (2.169) to find the value of the capacitor:
	
θnew =
=
°
−
 cos
95
1819
1( .
)
.
0
	
(2.171)
	
C
P
V
old
new
=
−
=
° −
°
(tan
tan
)
(tan(
.
)
tan(
.
))
(
θ
θ
ω rms
2
1465
26 87
18 19
2π
µ
60 117 5
50
2
)(
. )
=
F 	
(2.172)
The redesigned circuit using power factor correction is shown in Figure 2.42.
0.2 Ω
+
–
+
–
120   0° Vrms
60 Hz
Source
Load
Line
7.5 Ω
j3.8 Ω
–j/(2π60(50 μ))
–j52.92 Ω
VL
IL
Zc
FIGURE 2.42  Power factor correction circuit with capacitor.
0.2 Ω
+
+
–
–
7.5 Ω
j3.8 Ω
120    0° Vrms
60 Hz
Source
Line
Load
VL
IL
FIGURE 2.41  Power factor correction circuit.
© 2011 by Taylor and Francis Group, LLC

AC Circuit Analysis 
2-39
The final step in the analysis involves verifying that the new circuit has the new power factor and the 
same average power delivered to the load:
	
Z
j
j
j
L =
+
−
=
+
 (75 
38)
5292
851
28
.
.
||(
.
)
.
. Ω	
(2.173)
	
IL =
+
=
∠−
°
120
0 2
13 12
17 8
.
.
.
ZL
A 	
(2.174)
	
V
I
L
L
=
=
∠
°
ZL
1175
39 V
.
.0
	
(2.175)
	
S
V I
L
L L
=
=
∠
° =
+
*
1542 18 19
1465
481 31
.
.
j
VA 	
(2.176)
Thus, the average power delivered to the load is 1.47 kW at 0.95 pf lagging, which confirms that the 
design meets the specifications.
Example 2.18:  Maximum Average Power Transfer (Impedance Matching)
In order to deliver the maximum average power to a load in a circuit, it is necessary to perform imped-
ance matching. Impedance matching is the process of designing the system such that the load imped-
ance is matched to the Thevenin equivalent impedance of the source. When there are limitations on 
the  source or load impedance, this can be accomplished by using an ideal transformer and designing 
for the appropriate turns ratio. This process will be demonstrated with the following two examples. Design 
the circuit in Figure 2.43 to deliver the maximum average power to the load and determine the value 
of the power delivered.
In order to deliver maximum power, determine the turns ratio to match the load impedance as close 
as possible to the source impedance:
	
n
R
R
L
s
=
= 20 	
(2.177)
	
P =
=
( .
) (
)
.
138
75
14348 W
2
	
(2.178)
Design the circuit in Figure 2.44 to deliver the maximum average power to the load when there are no 
limitations on the load. Finally, determine the average power delivered to the load selected.
The first step in the analysis is to determine the Thevenin equivalent voltage and impedance as seen 
from the load. The Thevenin equivalent voltage is the open circuit voltage across terminals a and b. 
0.2 Ω
+
+
+
–
–
–
12    0° Vrms
60 Hz
7.5 Ω
j3.8 Ω
j0.1 Ω
V1
I2
1:n
I1
V2
Source
Line
Load
FIGURE 2.43  Impedance matching.
© 2011 by Taylor and Francis Group, LLC

2-40 
Fundamentals of Industrial Electronics
The Thevenin equivalent impedance is the impedance across terminals a and b when the independent 
voltage source is disabled. These values are found using formulas (2.179) and (2.180):
	
Z
j
j
th =
+
=
+
1
1
5
5  
5
00
00
0
0
0
||
Ω	
(2.179)
	
Vth =
(
) =
∠°
 
12
6
1
2
0
0 0 Vrms 	
(2.180)
Therefore, for impedance matching, set the load ZL = Zth* and determine the maximum average power 
delivered to the load:
	
Z
j
th =
−
5
5
0
0Ω	
(2.181)
	
P
v
R
th
th
=
=
|
|2
4
18 W 	
(2.182)
2.5  Conclusions
This chapter has presented a brief summary of the fundamental concepts of AC circuits. These concepts 
included mutual inductance, transformers, phasor analysis, Laplace analysis, and complex power. Since 
many of these concepts were summarized, the reader is encouraged to extend their study to other topics 
related to AC circuits, including filters, operational amplifiers, three-phase power, and Fourier analysis.
Bibliography
J.W. Nilsson and S.E. Riedel, Electric Circuits, 8th edition, Upper Saddle River, NJ: Prentice Hall, 2007, 
880 pp.
M.N.O. Sadiku and C.K. Alexander, Fundamentals of Electric Circuits, 3rd edition, New York: McGraw-
Hill, 2007, 901 pp.
100 Ω
100 Ω
Source
Load
b
a
ZL
j50 Ω
+
–
120    0° Vrms
60 Hz
FIGURE 2.44  Maximum average power transfer.
© 2011 by Taylor and Francis Group, LLC

3-1
In this section, node and loop analysis are introduced as methods for computing voltages and currents 
in electrical circuits. Readers are assumed to have no previous knowledge of these methods. Therefore, 
the basic principles are first explained and applied to simple dc circuits. Following a few examples, ac 
circuits are introduced as well. As will become apparent, circuit analysis can quickly become too ardu-
ous when many nodes and loops are present. For this reason, a brief introduction to circuit simulation 
with MATLAB•, PSPICE, and Multisim concludes the section.
3.1  Node Analysis
In a node analysis, the node voltages are the variables in a circuit, and KCL is the vehicle used to determine 
them. Once a node in the network is selected as a reference node, then all other node voltages are defined 
with respect to that particular node. This reference node is typically referred to as ground using the symbol 
(⊥
−), indicating that it is at ground-zero potential. Consider the network shown in Figure 3.1. The network has 
three nodes, and the node at the bottom of the circuit has been selected as the reference node. Therefore, the 
two remaining nodes, labeled V1 and V2, are measured with respect to this reference node.
Suppose that the node voltages, V1 and V2, have somehow been determined, i.e., V1 = 4 V and V2 = −4 V. 
Once these node voltages are known, Ohm’s law can be used to find all branch currents. For example,
	
I
V
1
1
0
2
2
=
−
=
A
	
I
V
V
2
1
2
2
4
4
2
4
=
−
=
−
=
( )
A
	
I
V
3
2
0
1
4
1
4
=
−
= −
= −A
3
Computational Methods 
in Node and Loop 
Analyses
3.1	
Node Analysis.................................................................................... 3-1
3.2	
Mesh Analysis....................................................................................3-4
3.3	
An AC Analysis Example.................................................................3-6
3.4	
Computer Simulation of Networks.................................................3-8
3.5	
MATLAB• m-File............................................................................ 3-11
Defining Terms............................................................................................3-12
Bibliography.................................................................................................3-13
Stephen M. Haddock
Auburn University
J. David Irwin
Auburn University
© 2011 by Taylor and Francis Group, LLC

3-2 
Fundamentals of Industrial Electronics
Note that KCL is satisfied at every node, i.e.,
	
I
I
1
2
6
0
−+
=
	
−
+ +
=
I
I
2
3
8
0
	
−
+ −−
=
I
I
1
3
6
8
0
Therefore, as a general rule, if the node voltages are known, all branch currents in the network can be 
immediately determined.
In order to determine the node voltages in a network, we apply KCL to every node in the network 
except the reference node. Therefore, given an N-node circuit, we employ N − 1 linearly independent 
simultaneous equations to determine the N − 1 unknown node voltages. Graph theory can be used to 
prove that exactly N − 1 linearly independent KCL equations are required to find the N − 1 unknown 
node voltages in a network.
Let us now demonstrate the use of KCL in determining the node voltages in a network. For the 
network shown in Figure 3.2, the bottom node is selected as the reference and the three remaining 
nodes, labeled V1, V2, and V3, are measured with respect to that node. All unknown branch currents 
are also labeled. The KCL equations for the three non-reference nodes are
	
I
I
1
2
4
0
+
+
=
	
−+
+
=
4
0
3
4
I
I
	
−
−
−
=
I
I
1
4
2
0
2 Ω
1 Ω
2 Ω
V1=4 V
V2= –4 V
6 A
8 A
I1
I2
I3
FIGURE 3.1  A three-node network.
2 Ω
2 Ω
1 Ω
1 Ω
4 A
2 A
V2
V1
V3
I4
I3
I2
I1
FIGURE 3.2  A four-node network.
© 2011 by Taylor and Francis Group, LLC

Computational Methods in Node and Loop Analyses 
3-3
Using Ohm’s law, these equations can be expressed as
	
V
V
V
1
3
1
2
4
2
0
−
+
+
=
	
−+
+
−
=
4
1
1
0
2
2
3
V
V
V
	
−
−
−
−
−
=
V
V
V
V
1
3
2
3
2
1
2
0
Solving these equations, using any convenient method, yields V1 = −8/3 V, V2 = 10/3 V, and V3 = 8/3 V. 
Applying Ohm’s law, we find that the branch currents are I1 = −16/6 A, I2 = − 8/6 A, I3 = 20/6 A, and I4 = 4/6 A. 
A quick check indicates that KCL is satisfied at every node.
The circuits examined thus far have contained only current sources and resistors. In order to expand 
our capabilities, we next examine a circuit containing voltage sources. The circuit shown in Figure 3.3 
has three non-reference nodes labeled V1, V2, and V3. However, we do not have three unknown node 
voltages. Since known voltage sources exist between the reference node and nodes, V1 and V3, these two 
node voltages are known, i.e., V1 = 12 V and V3 = − 4 V. Therefore, we have only one unknown node volt-
age, V2. The equations for this network are then
	
V1
12
=
	
V2
4
= −
and
	
−
+
+
=
I
I
I
1
2
3
0
The KCL for node V2 written using Ohm’s law is
	
−
−
+
+
−−
=
12
1
2
4
2
0
2
2
2
V
V
V
(
)
Solving this equation yields V2 = 5 V, I1 = 7 A, I2 = 5/2 A, and I3 = 9/2 A. Therefore, KCL is satisfied at 
every node.
2 Ω
2 Ω
1 Ω
4 V
12 V
+
–
V1
V3
V2
I2
I1
I3
+
–
FIGURE 3.3  A four-node network containing voltage sources.
© 2011 by Taylor and Francis Group, LLC

3-4 
Fundamentals of Industrial Electronics
Thus, the presence of a voltage source in the network actually simplifies a node analysis. In an attempt 
to generalize this idea, consider the network in Figure 3.4. Note that, in this case, V1 = 12 V and the dif-
ference between node voltages, V3 and V2, is constrained to be 6 V. Hence, two of the three equations 
needed to solve for the node voltages in the network are
	
V1
12
=
	
V
V
3
2
6
−
=
To obtain the third required equation, we form what is called a supernode, indicated by the dotted 
enclosure in the network. Just as KCL must be satisfied at any node in the network, it must be satisfied 
at the supernode as well. Therefore, summing all the currents leaving the supernode yields the equation:
	
V
V
V
V
V
V
2
1
2
3
1
3
1
2
1
2
0
−
+
+
−
+
=
The three equations yield the node voltages, V1 = 12 V, V2 = 5 V, and V3 = 11 V, and therefore I1 = 1 A, 
I2 = 7 A, I3 = 5/2 A, and I4 = 11/2 A.
3.2  Mesh Analysis
In a mesh analysis, the mesh currents in the network are the variables and KVL is the mechanism used to 
determine them. Once all the mesh currents have been determined, Ohm’s law will yield the voltages any-
where in the circuit. If the network contains N independent meshes, then graph theory can be used to prove 
that N independent linear simultaneous equations will be required to determine the N mesh currents.
The network shown in Figure 3.5 has two independent meshes. They are labeled I1 and I2 as shown. If the 
mesh currents are known to be I1 = 7 A and I2 = 5/2 A, then all voltages in the network can be calculated. 
1 Ω
1 Ω
2 Ω
2 Ω
V1
V2
V3
6 V
12 V
+
–
–
I2
I4
I1
I3
+
FIGURE 3.4  A four-node network used to illustrate a supernode.
2 Ω
2 Ω
1 Ω
16 V
V2
V1
V3
I1= 7 A
I2= 5
2 A
4 V
+
+
–
–
FIGURE 3.5  A network containing two independent meshes.
© 2011 by Taylor and Francis Group, LLC

Computational Methods in Node and Loop Analyses 
3-5
For example, the voltage V1, i.e., the voltage across the 1 Ω resistor, is V1 = −I1R = −(7)(1) = −7 V. Likewise, 
V2 = (I1 − I2)R = (7 − 5/2)(2) = 9 V. Furthermore, we can check our analysis by showing that KVL is satisfied 
around every mesh. Starting at the lower left-hand corner and applying KVL to the left-hand mesh, we obtain
	
−
+
−
−




=
( )( )
( )
7 1
16
7
5
2
2
0
where we have assumed that increases in energy level are positive and decreases in energy level are negative.
Consider now the network in Figure 3.6. Once again, if we assume that an increase in energy level is 
positive and a decrease in energy level is negative, the three KVL equations for the three meshes defined are
	
−
−−
−
=
I
I
I
1
1
2
1
6
1
0
( )
(
)( )
	
+
−
−
−
−
=
12
1
2
0
2
1
2
3
(
)( ) (
)( )
I
I
I
I
	
−
−
+
−
=
(
)( )
( )
I
I
I
3
2
3
2
6
2
0
These equations can be written as
	
2
6
1
2
I
I
−
= −
	
−
+
−
=
I
I
I
1
2
3
3
2
12
	
−
+
=
2
4
6
2
3
I
I
Solving these equations using any convenient method yields I1 = 1 A, I2 = 8 A, and I3 = 5.5 A. Any voltage 
in the network can now be easily calculated, e.g., V2 = (I2 – I3)(2) = 5 V and V3 = I3(2) = 11 V.
Just as in the node analysis discussion, we now expand our capabilities by considering circuits that 
contain current sources. In this case, we will show that for mesh analysis, the presence of current sources 
makes the solution easier.
The network in Figure 3.7 has four meshes that are labeled I1, I2, I3, and I4. However, since two of these 
currents, i.e., I3 and I4, pass directly through a current source, two of the four linearly independent equa-
tions required to solve the network are
	
I3
4
=
	
I4
2
= −
2 Ω
1 Ω
1 Ω
2 Ω
12 V
V1
V2
6 V
V3
I1
I2
I3
–
+
–
+
FIGURE 3.6  A three-mesh network.
© 2011 by Taylor and Francis Group, LLC

3-6 
Fundamentals of Industrial Electronics
The two remaining KVL equations for the meshes defined by I1 and I2 are
	
+ −
−
−
−
=
6
1
2
0
1
2
1
3
(
)( )
(
)( )
I
I
I
I
	
−
−
−
−
−
=
(
)( )
( ) (
)( )
I
I
I
I
I
2
1
2
2
4
1
2
1
0
Solving these equations for I1 and I2 yields I1 = 54/11 A and I2 = 8/11 A. A quick check will show that KCL 
is satisfied at every node. Furthermore, we can calculate any node voltage in the network. For example, 
V3 = (I3 − I4)(1) = 6 V and V1 = V3 + (I1 − I2)(1) = 112/11 V.
3.3  An AC Analysis Example
Both node analysis and mesh analysis have been presented and discussed. Although the methods have 
been presented within the framework of dc circuits with only independent sources, the techniques are 
applicable to ac analysis and circuits containing dependent sources.
To illustrate the applicability of the two techniques to ac circuit analysis, consider the network in 
Figure 3.8. All voltages and currents are phasors and the impedance of each passive element is known.
In the node analysis case, the voltage, V4, is known and the voltage between V2 and V3 is constrained. 
Therefore, two of the four required equations are
	
V4
12 0
=
∠°
	
V
V
2
3
6 0
+ ∠° =
1 Ω
1 Ω
1 Ω
2 Ω
+
–
2 Ω
2 A
4 A
6 V
V4
V3
V1
V2
I2
I4
I3
I1
FIGURE 3.7  A four-mesh network containing current sources.
2 Ω
1 Ω
j2 Ω
–j1 Ω
V4
V3
V2
V1
I2
I4
I3
I1
+
–
+–
2
0° A
4
0° A
12
0° V
6
0° V
FIGURE 3.8  A network containing five nodes and four meshes.
© 2011 by Taylor and Francis Group, LLC

Computational Methods in Node and Loop Analyses 
3-7
KCL for the node labeled V1 and the supernode containing the nodes labeled V2 and V3 is
	
V
V
V
V
j
1
3
1
4
2
1
2 0
−
+
−
−
= ∠°
	
V
V
V
V
V
j
2
3
1
3
4
1
2 0
2
2
2 0
+ ∠°+
−
+
−
−
= ∠°
Solving these equations yields the remaining unknown node voltages:
	
V
j
1
11 9
0 88
11 93
4 22
=
−
=
∠−
°
.
.
.
.
V
	
V
j
2
3 66
1 07
3 91
16 34
=
−
=
∠−
°
.
.
.
.
V
	
V
j
3
9 66
1 07
9 72
6 34
=
−
=
∠−
°
.
.
.
.
V
In the mesh analysis case, the currents, I1 and I3, are constrained to be
	
I1
2 0
= ∠°
	
I
I
4
3
4 0
−
= −∠°
The two remaining KVL equations are obtained from the mesh defined by mesh current, I2, and the loop 
that encompasses the meshes defined by mesh currents, I3 and I4:
	
−
−
−−
−
−
=
2
1
2
0
2
1
2
2
4
(
) (
)
(
)
I
I
j I
j
I
I
	
−
+ ∠°−
−
−
∠° =
I
j
I
I
3
4
2
6 0
2
12 0
0
(
)
Solving these equations yields the remaining unknown mesh currents
	
I2
0 88
6 34
=
∠−
°
.
.
A
	
I2
3 91 163 66
=
∠
°
.
.
A
	
I4
1 13 72 35
=
∠
°
.
.
A
As a quick check we can use these currents to compute the node voltages. For example, if we calculate
	
V
I
2
3
1
= −( )
and
	
V
j I
1
2
12 0
= −
+
∠°
( )
we obtain the answer computed earlier.
© 2011 by Taylor and Francis Group, LLC

3-8 
Fundamentals of Industrial Electronics
Since both node and mesh analyses will yield all currents and voltages in a network, which technique 
should be used? The answer to this question depends upon the network to be analyzed. If the network 
contains more voltage sources than current sources, node analysis might be the easier technique. If, 
however, the network contains more current sources than voltages sources, mesh analysis may be the 
easiest approach.
3.4  Computer Simulation of Networks
While any network can be analyzed using mesh or nodal techniques, the required calculations are cum-
bersome for more than three loops or nodes. In these cases, computer simulation is an attractive alter-
native. As an example, we will solve for the current, I0, in the circuit in Figure 3.9 using first MATLAB, 
then PSPICE, and finally Multisim.
MATLAB requires a matrix representation of the network. Nodal analysis yields the equations
	
V
Z
Z
V
Z
V
Z
Z
1
1
2
2
1
3
2
4
1
1
1
1
1
+



+
−



+
−
−



+
 
V
Z
Z
Z
Z
V
Z
4
4
5
6
6
5
5
1
1
1
1
1
0
+
+
+



+
−



=
α
	
V
Vs
2
2
=
	
V
V
V
1
2
3
0
(
)
( )
−
+
+
=
β
β
	
−
+
=
V
V
Vs
1
4
1
	
V
Z
Z
V
Z
Z
4
5
6
5
5
7
1
1
1
1
0
−
−



+
+



=
α
Note the supernode between V1 and V2 and also that V2 is obtained from the voltage source, VS2. The 
values of these components have been left to variables because of the flexibility it will afford in MATLAB 
analysis. If the circuit is defined in this way in code, then changing a single variable will result in a uni-
versal change through the equations. The matrix equation that solves for the node voltages is
V1
Vs1=5.1962+j3
Vs2=6–j10.3923
α=2
β=2
Z1=1 Ω
Z2=–j1 Ω
Z3=1 Ω
Z4=1 Ω
Z5= 2 Ω
Z6= j1 Ω
Z7= 2 Ω
Ix
I0
Z6
Z4
Z3
Z2
V2
Vx
Vs2
(beta)Vx
+
+
–
–
+
–
+
–
Z1
V3
Z5
V5
(alpha)Ix
Z7
V4
Vs1
FIGURE 3.9  A network containing six nodes and six loops. Computer simulation is helpful in this analysis.
© 2011 by Taylor and Francis Group, LLC

Computational Methods in Node and Loop Analyses 
3-9
	
V
V
V
V
V
Z
Z
Z
Z
Z
Z
Z
Z
1
2
3
4
5
1
2
1
2
4
4
5
6
1
1
1
1
1
1
1
1
















=
+
−
−
−
+
+
+ α
β
β
α
1
1
0
1
0
0
0
1
0
0
1
0
0
1
0
0
0
0
1
1
1
1
6
5
5
6
5
7
Z
Z
Z
Z
Z
Z
−
−
−
−
−
+






































−1
2
1
0
0
0
V
V
s
s
Though MATLAB can be used at a command prompt, there are advantages to writing m-files that 
describe systems that need to be solved. One in particular is that changes can be made quickly. An 
m-file capable of solving this circuit for the current, I0, is given at the conclusion of this section. The 
results given by MATLAB are
Io_mag = 10.4756e+000
Io_phase = −152.0373e+000
In PSPICE, we draw the circuit using one of the accompanying schematic entry tools, either Schematics 
or Capture. The resulting Schematics file is shown in Figure 3.10. Note that capacitors and inductors 
must be specified in Farads and Henries, respectively. Therefore, any excitation frequency can be cho-
sen with the L and C values calculated from the known impedances. The most convenient frequency is 
ω = 1 rad/s or 0.1591 Hz. Figure 3.11 shows the ac sweep settings to produce a single frequency analysis 
at 0.1591 Hz. Also, the IPRINT part is required to load the simulation results into the OUTPUT file.
Finally, to preserve the clarity of the schematic, the BUBBLE part is used for connecting the control-
ling parameters into the dependent sources. This is accomplished by naming connecting BUBBLE parts 
with the same name. Figure 3.12 shows the relevant portion of the output file produced by PSPICE. 
PSPICE produces an answer that equals that given by MATLAB.
R1
R3
R4
V2
ACMAG = 6
ACPHASE = 30
ACMAG=12
ACPHASE=–60
F1
Gain =2
Gain = 2
f
R5
I+
I–
I+
I–
C1
V+
V+
E1
e
+
+~
–
–
+~–
V1
V–
V–
1
1
1
1
2
R2
iprint
AC = y
MAG = y
PHASE = y
L1
2
1
FIGURE 3.10  Circuit drawn in PSPICE.
© 2011 by Taylor and Francis Group, LLC

3-10 
Fundamentals of Industrial Electronics
10 481
152 0
.
.
−
°A, which matches the results given by MATLAB.
Multisim affords another method of computing the desired current in the circuit shown in Figure 
3.9. The interface for Multisim is similar to the one presented in PSPICE. The capacitors and inductors 
must again be input in units of Farads and Henries, respectively. Figure 3.13 shows the circuit drawn in 
Multisim.
The frequency ω = 1, f = 0.1591 Hz, is also used. Just as with PSPICE, Multisim must be told where 
to make measurements, so a measurement probe is placed on the branch where the current is to be 
FREQ
IM(V_PRINT1) IP(V_PRINT1)
1.591E–01
1.048E+01 –1.520E+02
FIGURE 3.12  Excerpt from the PSPICE output file.
FIGURE 3.11  AC Sweep setup window.
V–
R2
C1
1 F
R3
R4
R5
V2
V3
L1
1 H
2 V/V
2 A/A
V+
R1
1 Ω
1 Ω
1 Ω
2 Ω
2 Ω
I0
V1
12 Vpk
6 Vpk
1 Hz
30°
1 Hz
–60°
+
+
I+
I–
I–
I1
I+
+
~–
+
~
–
–
–
V+
V–
FIGURE 3.13  Circuit drawn in Multisim.
© 2011 by Taylor and Francis Group, LLC

Computational Methods in Node and Loop Analyses 
3-11
measured. There is no special part for connecting the dependent sources to their controlling values 
in Multisim; just name the connecting nodes with the same name to connect them. To find the cur-
rent, a single frequency ac analysis will be employed. The menu settings for this analysis are shown in 
Figure 3.14. Results are shown in Figure 3.15.
I0
10 475
152 05
=
−
.
.
°A. All simulation results match to four significant digits.
3.5  MATLAB® m-File
The following MATLAB code was used to compute the output current for the circuit in Figure 3.9.
% These lines clear all the previously used
% variables, close all figures, and clear the
% prompt window
clear all
close all
clc
% Use engineering numeric formatting
format short eng
% Define circuit values
    % Resistors
R1 = 1;	
G1 = 1/R1;
R2 = −1j; G2 = 1/R2;
R3 = 1;	
G3 = 1/R3;
R4 = 1;	
G4 = 1/R4;
R5 = 2;	
G5 = 1/R5;
R6 = 1j;	 G6 = 1/R6;
R7 = 2;	
G7 = 1/R7;
FIGURE 3.14  Single Frequency AC Analysis configuration window.
FIGURE 3.15  Output from Multisim.
© 2011 by Taylor and Francis Group, LLC

3-12 
Fundamentals of Industrial Electronics
    % Voltage sources
Vs1 = 5.1962 +3j;
Vs2 = 6 − 10.3923j;
    % Gain terms
alpha = 2;
beta = 2;
% Setup the G matrix
G =	
[G1+G2	 −G1	
−G2−G4	 G4 + G5 + G6 + alpha*G6	
−G5;
	
0	
1	
0	
0	
0;
	
−beta	 beta	 1	
0	
0;
	
−1	
0	
0	
1	
0;
	
0	
0	
0	
−G5−alpha*G6	
G5 + G7];
% Setup the I matrix
I = [0;
	
Vs2;
	
0;
	
Vs1;
	
0];
% Compute the V matrix
V = G\I;
% Use v5 from the V matrix to solve for Io
Io = V(5)*G7;
% display Io
Io_mag = abs(Io)
Io_phase = angle(Io)*180/pi
Defining Terms
ac: An abbreviation for alternating current.
dc: An abbreviation for direct current.
Kirchhoff’s current law (KCL): This law states that the algebraic sum of the currents either entering or 
leaving a node must be zero. Alternatively, the law states that the sum of the currents entering 
a node must be equal to the sum of the currents leaving that node.
Kirchhoff’s voltage law (KVL): This law states that the algebraic sum of the voltages around any loop 
is zero. A loop is any closed path through the circuit in which no node is encountered more 
than once.
MATLAB, PSPICE, Multisim: Computer-aided analysis techniques.
Mesh analysis: A circuit analysis technique in which KVL is used to determine the mesh currents in a 
network. A mesh is a loop that does not contain any loops within it.
Node analysis: A circuit analysis technique in which KCL is used to determine the node voltages in a 
network.
© 2011 by Taylor and Francis Group, LLC

Computational Methods in Node and Loop Analyses 
3-13
Ohm’s law: A fundamental law that states that the voltage across a resistance is directly proportional to 
the current flowing through it.
Reference node: One node in a network that is selected to be a common point, and all other node volt-
ages are measured with respect to that point.
Supernode: A cluster of nodes, interconnected with voltage sources, such that the voltage between any 
two nodes in the group is known.
Bibliography
J.D. Irwin and R.M. Nelms, Basic Engineering Circuit Analysis, 9th edn., New York: John Wiley & Sons, 2008.
© 2011 by Taylor and Francis Group, LLC

4-1
4.1  Introduction
Transistors are the fundamental building blocks of microelectronic circuits. They are used in both ana-
log and digital circuits. In digital circuits, they can be thought of as voltage-gated switches. In analog 
circuits, they can be thought of as transconductance (voltage-to-current) amplifiers. There are many 
different types of transistors, determined by the material it has been made from, the underlying physics 
of operation, and the primary carrier creating current in the device. However, they can all be used in the 
same types of circuits. The most commonly used transistors are made out of silicon: the metal-oxide-
semiconductor field-effect transistor (MOSFET) and the bipolar-junction transistor (BJT). Field-effect 
transistor (FET) operation is based upon an input generating an electromagnetic field to turn the device 
on and off. A junction transistor is controlled by turning a p–n junction diode within the device on 
and off. Both types of transistors have two subtypes determined by the dominant current carrier, holes 
(p-type), or electrons (n-type), resulting in four transistor types: MOSFETs (nFET and pFET) and BJTs 
(the npn and the pnp).
The rest of this chapter will discuss more details about these four transistor types, including the 
device operation, characteristic equations and curves, and modeling. While the underlying physics of 
these devices are different, the basic operation and circuits for which they are used are very similar. 
Discussion concerning the trade-offs between these devices are embedded throughout the chapter.
4.2  Transistor Operation and Characterization
4.2.1  MOSFET Operation and Characterization
The MOSFET contains four terminals: the gate (G), drain (D), source (S), and bulk/body/substrate (B). 
There are several common schematic symbols used for this device, shown in Figure 4.1a for a nFET and 
Figure 4.1b for a pFET with current directions labeled. Figure 4.2 shows the cross-sectional view of the 
nFET and pFET. The drain and source regions form a p–n junction diode with the substrate. A dielec-
tric, typically a thin layer of oxide, is placed between the gate, typically made from polysilicon, and the 
substrate forming a capacitor at the gate. As a result, the FET will exhibit zero gate current, as shown in 
Figure 4.1. The bulk is placed at a potential to guarantee that the drain and source p–n junction diodes 
are reverse biased so that excess current does not flow into the bulk.
4
Transistor Operation 
and Modeling
4.1	
Introduction.......................................................................................4-1
4.2	
Transistor Operation and Characterization..................................4-1 
MOSFET Operation and Characterization  •  BJT Operation 
and Characterization  •  FETs versus BJTs
Tina Hudson
Rose-Hulman Institute 
of Technology
© 2011 by Taylor and Francis Group, LLC

4-2 
Fundamentals of Industrial Electronics
The operation of the nFET is shown in Figure 4.3. The nFET is turned on by placing a voltage on 
the gate, G, relative to the bulk. The gate voltage attracts electrons to the gate. When enough charge 
has been attracted to the gate, a channel is formed, which creates a low-resistive connection between 
the drain and the source (Figure 4.3a). A higher gate voltage places more charge on the gate, resulting 
in more electron attraction, more charge in the channel, and thus more current through the channel 
(Figure 4.3b). Current flows through the channel when the drain voltage is greater than the source volt-
age, attracting electrons to the drain, resulting in positive current flow to the source (Figure 4.3c). As 
drain voltage increases, more electrons are attracted to the drain resulting in more current to the source. 
However, an increase in drain voltage also decreases the gate-drain voltage, which causes less chan-
nel charge on the drain side of the channel. When the gate-drain voltage is large enough, the channel 
pinches off at the drain limiting the channel current (Figure 4.3d).
The operation of the pFET is similar to the nFET as shown in Figure 4.4. However, because the domi-
nate carriers in a pFET are holes, the gate voltage must be lower than the substrate voltage to attract 
holes to the gate (Figure 4.4a and b). Similarly, the drain voltage must be lower than the source voltage 
to attract holes to the drain through the channel (Figure 4.4c and d). Pinch-off occurs for the same rea-
son as the nFET: a lower drain-gate voltage relative to the source-gate voltage, which lowers the channel 
charge at the drain. Like the nFET, when the pFET is in pinch-off, the channel current is limited.
D
G
S
D
G
S
D
G
S
B
(a)
ID
IS
IG=0
S
G
D
S
G
D
S
G
D
B
IS
ID
IG= 0
(b)
FIGURE 4.1  Schematic representations of (a) the nFET and (b) the pFET.
(a)
(b)
n+
p+
p+
p–
n–
G
D
B
G
D
B
Oxide
Oxide
polySi
polySi
n+
S
S
FIGURE 4.2  Cross-sectional views of (a) the nFET and (b) the pFET.
© 2011 by Taylor and Francis Group, LLC

Transistor Operation and Modeling 
4-3
The device operation leads to the characteristic equations of the device. To turn the nFET on, the gate 
voltage must be large enough to generate the channel. The voltage necessary to generate the channel is 
called the threshold voltage (Vt). If the gate-bulk voltage, VGB, is larger than the threshold voltage, the 
device is considered to be on and can allow current to flow through the channel. A larger VGB allows 
more current. However, even if 0 < VGB < Vt, the current through the channel is very small, but not zero, 
which can be a source of leakage current in some circuits.
Although VGB generates the channel, the characteristic curves typically use the gate-source voltage, 
VGS, in the equations to allow for more flexibility in the circuit designs. In discrete devices, the source is 
often connected to the bulk internal to the device, making VGB = VGS. In integrated circuits, the substrate 
is not always connected to the source. In these cases, this discrepancy is accounted for by increasing the 
(a) 
n+
p–
VG
+
+
+
VB
n+
e–
e–
e–
e–
e–
e–
n+
p–
VG
VB
n+
e–
e–
e–
e–
e–
e–
(b) 
+  +  +
+  +  +
VD
VS
n+
p–
VG
VB
n+
e–
e–
e–
e–
e–
e–
(c) 
+  +  +
+  +  +
+
e–
+  +  +
+  +  +
VD
VS
n+
p–
VG
VB
n+
e–
e–
e–
(d) 
++
e–
e–
e–
Pinch-off
FIGURE 4.3  Device operation of the nFET.
(a) 
p+
n–
–VG
VB
p+
h+
h+
h+
h+
h+
h+
–
–
–
p+
n–
–VG
VB
p+
h+
h+
h+
h+
h+
h+
(b) 
–
–
–
–
–
–
VD
VS
p+
n–
–VG
VB
p+
e–
(c) 
–
e–
–
–
–
–
–
–
h+ h+ h+ h+ h+
–
–
VD
VS
p+
n–
–VG
VB
p+
(d) 
Pinch-off
–
–
–
–
–
–
h+ h+ h+
h+
h+
FIGURE 4.4  Device operation of the pFET.
© 2011 by Taylor and Francis Group, LLC

4-4 
Fundamentals of Industrial Electronics
threshold voltage as a function of the source-bulk voltage, VSB. As a result, the threshold voltage may be 
larger for devices whose bulk is not at the same potential as the substrate.
As a consequence of the device operation, the channel current, or current from the drain to the source 
(IDS), depends on VGS − Vt. A larger VGS will generate a larger current by drawing more charge into the 
channel. If the channel is not pinched-off, the device is in the linear region and the current will also 
increase as a function of the drain-source voltage, VDS, as follows:
	
I
K
W
L
V
V V
V
DS
GS
t
DS
DS
=
′



−
−






(
)
2
2
	
(4.1)
In this equation, W is the width of the transistor (see Figure 4.5) and L is the length of the transis-
tor. A larger transistor width acts like a wider river allowing more water (or current) to flow. A larger 
transistor length causes more resistance in the channel, resisting current flow.
K′ depends on the mobility of the carrier and the capacitance of the oxide:
	
′ =
K
C
n
µ
OX 	
(4.2)
K′ determines how many electrons will be in the channel for a given VGS by indicating the effectiveness 
of the gate in generating the channel. A larger oxide capacitance will generate a larger electromagnetic 
field, pulling more charge into the channel for the same VGS. The carrier mobility, μ, indicates how many 
carriers will flow through the channel for a given electromagnetic field. Higher mobility results in more 
carrier movement for the same electromagnetic field, resulting in more current. However, the mobility 
is a fixed value for a given carrier type and material. Electrons always have a higher mobility than holes, 
resulting in larger K′ values for nFETs than pFETs that are otherwise the same. Additionally, mobility 
varies with material type: e.g., GaAs transistors have higher electron mobility than silicon, which is why 
many of the high-speed electronic devices use GaAs devices.
When VDS is large enough to pinch-off the channel, the FET is in the saturation region, where the 
current saturates (a further increase in VDS has little effect on the current) as follows:
	
I
K
W
L
V
V
DS
GS
t
=
′ 



−
2
2
(
) 	
(4.3)
The voltage that places the channel on the edge of pinch-off is called the saturation voltage (VDS,sat), and 
defined as follows:
	
V
V
V
DS,sat
GS
t
=
−
	
(4.4)
In the saturation region, there is a small increase in channel current due to an increase in VDS due to 
channel-length modulation. As VDS increases, the pinch-off region grows, effectively making the chan-
nel length shorter and producing a small increase in drain current. To account for this second-order 
n+
p–
n+
L
W
FIGURE 4.5  Three-dimensional sketch of FET showing W and L.
© 2011 by Taylor and Francis Group, LLC

Transistor Operation and Modeling 
4-5
effect, the saturation equation can be modified as follows; however, its most significant impact is felt in 
producing a finite output resistance for the transistor.
	
I
K
W
L
V
V
V
DS
GS
t
DS
=
′ 



−
+
2
1
2
(
) (
)
λ
	
(4.5)
In this equation, λ is the channel-length modulation parameter given in units of V−1.
The characteristic equations are depicted graphically in Figure 4.6. In the saturation region, the channel 
current increases as a square-law once VGS > Vt (Figure 4.6a). This square-law relationship determines how 
well the transistor converts a change in voltage into a change in current when the device is used in an ampli-
fier circuit. When the transistor is being used as an amplifier, VGS typically changes by a small amount (a small 
signal). As a result, the change in drain current, ID, is approximately linear and equal to the derivative of the 
square-law relationship at a particular point (shown in Figure 4.6a). This small-signal parameter, called 
the transconductance (gm) of the FET, is a direct measure of the amplification capability of the transistor. 
The transconductance is calculated as follows, where IDQ is the tangent point to the nonlinear curve. The 
derivation assumes that λVDS is small and can be ignored.
(a)
VGS
0 V 0.5 V 1.0 V 1.5 V 2.0 V 2.5 V 3.0 V 3.5 V 4.0 V 4.5 V
ID
0 A
200 mA
400 mA
500 mA
gm
(b)
Linear
region
gds
Increasing VGS
Saturation region
VDS
0 V
1 V
2 V
3 V
4 V
5 V
6 V
7 V
8 V
9 V
10 V
ID
0 A
100 mA
200 mA
300 mA
400 mA
FIGURE 4.6  (a) ID versus VGS characteristics curves for a FET. (b) ID versus VDS characteristic curves for a FET.
© 2011 by Taylor and Francis Group, LLC

4-6 
Fundamentals of Industrial Electronics
	
g
I
V
K
W
L
V
V
V
K
W
mFET
DS
GS IDQ
GS
t
GS
IDQ
= ∂
∂
≅
∂
′ 



−




∂
=
′
2
2 2
2
(
)
L
V
V




−
(
)
GS
t
IDQ
	
(4.6)
By noting that I
K
W L V
V
DQ
GSQ
t
=
′
−
(
/ )(
/ )(
)
2
, the equation can be rewritten in terms of the drain 
current as follows:
	
g
K W
L I
mFET
DQ
=
′
2
	
(4.7)
Figure 4.6b depicts the drain current as VGS and VDS change, showing the linear and saturation regions. 
Note that the transition from the linear to the saturation region changes with VGS. When the FET is 
being used as an amplifier, the goal is to keep it in the saturation region. When the FET is being used 
as a switch, the goal is to make the transistor switch from the saturation region to the linear region and 
vice versa.
Figure 4.6b also demonstrates the channel-length modulation in the saturation region, where ID 
increases slightly with VDS. The slope of the line in this region at a given point represents the output 
conductance of the transistor (gds), which indicates how the drain current changes when VDS changes. 
This parameter assumes that the input, VGS, is changing by a small amount (small signal), which keeps 
the transistor in the saturation region and thereby the slope of the line linear. The small-signal value 
of gds can be calculated in a similar manner as gm, except using the relationship between IDS and VDS. 
Clearly, to include the VDS relationship, the ID equation must include the channel-length modulation 
parameter:
	
g
I
V
K
W
L
V
V
V
V
ds
DS
DS IDQ
GS
t
DS
DS
IDQ
= ∂
∂
=
∂
′ 



−
+




∂
2
1
2
(
) (
)
λ
= λIDQ
	
(4.8)
Many designers prefer to use the inverse of this relationship, rds, which models the output resistance of 
the transistor when the input is a small signal. Ideally, a designer would like the rds = ∞. The predomi-
nant impact of a finite output resistance on an amplifier circuit includes a small decrease in voltage gain 
and a limited accuracy and reproducibility of current values in current mirrors.
The characteristic equations of the pFET are similar to the characteristic equations of the nFET, 
since the only difference in the basic operation is the polarity of the voltages required to account 
for the reverse in carrier types. The equations can be written identically with the polarity reversal 
as follows:
	
I
K
W
L
V
V V
V
SD
SG
t
SD
SD
=
′



−
(
)
−






2
2
	
(4.9)
	
I
K
W
L
V
V
SD
SG
t
=
′ 



−
(
)
2
2
	
(4.10)
	
V
V
V
SD sat
SG
t
,
=
−
	
(4.11)
© 2011 by Taylor and Francis Group, LLC

Transistor Operation and Modeling 
4-7
	
I
K
W
L
V
V
V
SD
SG
t
SD
=
′ 



−
+
2
1
2
(
) (
)
λ
	
(4.12)
The absolute value of the threshold voltage is used since the threshold voltage for pFETs is generally 
negative, reflecting that the gate voltage must be brought lower than the bulk to generate a channel. It 
is important to keep in mind that a large VSG producing a large drain current is generated by a low gate 
voltage relative to ground, and a small VSG producing small drain current is generated with a high 
gate voltage relative to ground.
Since the characteristic equations are identical to the n-devices with only polarity reversals, the deriv-
ative of these equations will result in the same small-signal equations as follows:
	
g
I
V
K W
L I
mFET
SD
SG IDQ
DQ
= ∂
∂
=
′
2
	
(4.13)
	
g
I
V
I
sd
SD
SD IDQ
DQ
= ∂
∂
= λ
	
(4.14)
4.2.2  BJT Operation and Characterization
The BJT contains three terminals, the base (B), the collector (C), and the emitter (E), and uses the 
schematic symbols shown in Figure 4.7a for an npn and Figure 4.7b for a pnp with current direc-
tions labeled. Figure 4.8 shows the cross-sectional view of the npn and pnp. Figure 4.8a shows the 
standard back-to-back p–n junction cross section, while Figure 4.8b presents the typical integrated 
circuit implementation. In the integrated circuit implementation, the collector of one transistor 
is isolated from the collectors of other transistors by placing the transistors into a substrate of 
opposite doping type. The substrate is held at a potential to keep the collector–substrate junction 
reverse-biased.
To turn on the BJT, the base–emitter junction diode must be forward-biased, using a positive VBE voltage 
for npn’s and a positive VEB voltage for pnp’s. If the base–collector junction diode is also forward-biased, 
the transistor is in the saturation region, and base current is shared between the two forward-biased diodes 
(see Figure 4.9a). If the base–emitter diode and the base–collector diode are on equally strong and the 
width of the base is small enough that electrons will not recombine, equal numbers of electrons will diffuse 
through the base region from the collector to the emitter and from the emitter to the collector, resulting in 
net current equal to zero. Holes will still diffuse from the base to both the collector and the emitter in equal 
numbers, thereby requiring base current in this condition; however, since net hole movement is equal in 
each case, net current from emitter to collector is still zero. This condition occurs in the npn when VCE = 0, 
which causes VBE = VBC, and in the pnp when VEC = 0, which causes VEB = VCB.
(b)
E
B
C
IE
IC
IB
C
B
E
(a)
IC
IE
IB
FIGURE 4.7  Schematic representations of (a) the npn and (b) the pnp.
© 2011 by Taylor and Francis Group, LLC

4-8 
Fundamentals of Industrial Electronics
n
p
C
E
B
n+
B
C
E
n+
p
n
p–
Substrate
npn
(a)
(b)
p+
n
E
C
B
p
B
C
E
p+
n
p
n–
Substrate
pnp
FIGURE 4.8  Cross-sectional views of (a) theoretical BJT (the npn) and (b) integrated circuit BJT (the pnp).
(a)
C
E
VB=0.7 V 
VBC=0.7 V
VBE=0.7 V
p
n
n+
C
E
IEC
ICE  thus net ICE= 0
e–
e–
e–
e–
VB
h+
h+
(b) 
VB=0.7 V 
C
E
VC=0.1 V
+
VBC=0.6 V
VBE=0.7 V
C
E
VC
+
VB
p
n
n+
e–
e– e–
IEC
ICE  thus net ICE> 0
h+
h+
FIGURE 4.9  Device operation of the npn in the saturation region.
© 2011 by Taylor and Francis Group, LLC

Transistor Operation and Modeling 
4-9
As VCE increases (Figure 4.9b), the base–collector diode is on less strongly, resulting in more electrons 
diffusing from the emitter to the collector than from the collector to the emitter. Since positive current 
flow is designated in the opposite direction of electron flow, this results in net positive current from 
the collector to the emitter. The number of electrons diffusing from the collector to the emitter drops 
exponentially as the collector voltage increases (basic diode relationship), so the net current from the 
collector to the emitter increases exponentially.
At the saturation point of the transistor, which usually occurs when VCE for an npn and VEC for a pnp is 
between 0.2 and 0.3 V, the base–collector diode becomes reverse biased and the BJT moves into the active 
region. In this region of operation, the device exhibits current amplification: small base current results in 
large collector current. In the active region, the reverse-biased junction (VBC) generates a depletion region 
that is significant in size relative to the base width (see Figure 4.10). The forward-biased base–emitter junc-
tion causes holes to diffuse from the base into the emitter and electrons to diffuse from the emitter into the 
base. However, if the base width is small enough, electrons will be swept into the collector by the electric 
field in the collector–base depletion region. As a result, few electrons recombine in the base. These carrier 
movements result in net positive current from the collector to the emitter. The hole diffusion current from 
the base to the emitter dominates the base current. The electron carrier movement from the emitter to the 
collector dominates the collector current. The emitter sees holes coming in from the base and electrons 
leaving for the collector, so it is a sum of the base and collector current that results in KCL applying to the 
devices as in Equation 4.15 with the current directions shown in Figure 4.8a and b:
	
I
I
I
E
C
B
=
+
	
(4.15)
In manufacturing, the emitter is more highly doped than the base (shown in the figures with the n+ as 
compared to the p). As a result of the higher doping, more electrons diffuse into the collector than holes 
diffuse from the base. Therefore, IC >> IB, resulting in current amplification. The number of carriers 
swept into the collector for every base carrier is called the forward common-emitter current gain, (β), 
and relates the base current to the collector current as follows:
	
I
I
C
B
= β *
	
(4.16)
The percentage of carriers received by the collector relative to the current in the emitter is called the 
common-base current gain (α), and relates the emitter current to the collector current as follows:
	
I
I
C
E
= α *
	
(4.17)
p
n
n+
B
C
E
e–
e–
e–
VC
VCE >VCE,SAT
VB
h+
h+
IC
=
+
I due
to e–, h+
I due
to h+
I due
to e–
IE
IB
_+
_+
_+
_+
FIGURE 4.10  Device operation of the npn in the active region.
© 2011 by Taylor and Francis Group, LLC

4-10 
Fundamentals of Industrial Electronics
Many designers use these current amplification equations to design their circuits. However, to under-
stand the operation of many circuits, it is important to keep in mind that the base–emitter voltage 
controls the base–emitter junction diode that controls the device. As a result, the base current changes 
exponentially with changes in the base–emitter voltage. Since the collector current is a scaled version of 
the base current, the collector current also changes exponentially with the base–emitter voltage, result-
ing in the following current–voltage relationship:
	
I
I
eV
V
CE
B
BE
T
for npn
=
−
β
0
1
(
)
/
	
(4.18)
	
I
I
eV
V
EC
B
EB
T
for pnp
=
−
β
0
1
(
)
/
	
(4.19)
In this equation, IB0 is the reverse-bias current of the base–emitter diode and VT is the thermal voltage, 
equal to approximately 26 mV at room temperature. The thermal voltage is more exactly defined by the 
following equation:
	
V
kT
q
T =
	
(4.20)
In this equation, k/q is Boltzmann’s constant and equal to 8.61738 × 10−5 eV/K, and T is the temperature 
in Kelvin. Similar to the FET equations, since the only difference in the basic operation of the npn and 
the pnp is the carrier type, the equations can be written identically using the reverse polarity on the 
voltages and current directions.
Due to the exponential relationship between IC and VBE, IC must change by a factor of 100 for VBE to 
change by 0.1 V. In normal amplifiers with typical rails of ±15 V or less, IC does not typically change by 
that large a factor. Therefore, the base–emitter voltage appears to be constant; however, it does change 
by a small amount.
Similar to FETs, in the active region, there is a small increase in collector current due to an increase 
in VCE for npn’s and VEC for pnp’s due to base-width modulation, or Early effect. As VCE increases, the 
reverse-bias voltage on the base–collector diode increases, resulting in a larger depletion region. This 
larger depletion region further narrows the base width and allows fewer carries to recombine in the 
base, producing a small increase in collector current. To account for this second-order effect, the active 
region equations can be modified as follows; however, similar to the FET, it’s most significant impact is 
felt in producing a non-infinite output resistance for the transistor:
	
I
I
e
V
V
V
V
CE
B
CE
A
BE
T
for npn
=
−
(
)
+




β
0
1
1
/
	
(4.21)
	
I
I
e
V
V
V
V
EC
B
EC
A
EB
T
for pnp
=
−
(
)
+




β
0
1
1
/
	
(4.22)
The characteristic equations of the BJT are depicted graphically in Figure 4.11. In the active region, 
the channel current increases exponentially as a function of VBE (Figure 4.11a). This exponential rela-
tionship determines how well the transistor converts a change in voltage into a change in current when 
the device is used in an amplifier circuit. Just like the FET, when the transistor is being used as an ampli-
fier, VBE typically changes by a small amount (a small signal). As a result, the change in collector current, 
IC, is approximately linear and equal to the derivative of the exponential relationship at a particular 
point (shown in Figure 4.11a). This small-signal parameter, called the transconductance of the BJT, 
© 2011 by Taylor and Francis Group, LLC

Transistor Operation and Modeling 
4-11
is calculated for the BJT as follows, where ICQ is the tangent point. The derivation assumes that VCE/VA is 
small and can be ignored, and that e
I
I e
V
V
V
V
BE
T
/
/
resulting in
>> 1,
CE
B
BE
T
≅β
0
.
	
g
I
V
I
e
V
I
e
V
V
V
V
V
mBJT
CE
BE
B
BE
B
CQ
BE
T
CQ
BE
T
= ∂
∂
≅
∂

∂
=
I
I
β
β
0
0
(
)
(
)
/
/
T
CQ
T
= I
V
	
(4.23)
This equation is true for both npn and pnp devices, since the polarity reversal is embedded in the 
definition of ICQ.
500 mA
(a)
VBE
0 V
0.5 V
1.0 V
1.5 V
2.0 V
2.5 V
3.0 V
3.5 V
4.0 V
4.5 V
IC
400 mA
 0 A
200 mA
gm
(b)
IC
450 mA
VCE
0 V
1 V
2 V
3 V
4 V
5 V
6 V
7 V
8 V
9 V
10 V
400 mA
0 A
200 mA
Increasing VBE
Saturation region
Active region
FIGURE 4.11  (a) IC versus VBE characteristic curves for an npn. (b) IC versus VCE characteristic curves for an npn.
© 2011 by Taylor and Francis Group, LLC

4-12 
Fundamentals of Industrial Electronics
Figure 4.11b depicts the collector current as VBE and VCE change, showing the saturation and active 
regions. Note that the transition from the saturation to the active region is approximately constant for 
varying VBE values. This effect occurs because the change in current is exponential with VCE. Identical 
to the FET, when the BJT is being used as an amplifier, the goal is to keep it in the active region. When 
the BJT is being used as a switch, the goal is to make the transistor switch from the active region to the 
saturation region and vice versa.
Figure 4.11b also demonstrates the base-width modulation in the active region, where IC increases 
slightly with VCE. Similar to the FET, the slope of the line in this region at a given point represents 
the output conductance of the transistor (gce), which indicates how the collector current changes 
when VCE changes. This parameter assumes that the input, VBE, is changing by a small amount (small 
signal), which keeps the transistor in the active region and thereby the slope of the line linear. The 
small-signal value of gce can be calculated in a similar manner as gm, including the Early effect in the 
IC equation:
	
g
I
V
I
e
V
V
V
I
V
V
V
ce
CE
CE
B
CE
A
CE
CQ
CQ
BE
T
CQ
= ∂
∂
≅
∂
(
)
+


∂
=
I
I
β
0
1
/
(
(
/
))
A
	
(4.24)
Like the FETs, many designers prefer to use the inverse of this relationship, rce, which models the output 
resistance of the transistor when the input is a small signal. While ideally rce = ∞, a finite output resis-
tance has the same impact on BJT circuits as FET circuits, including a small decrease in voltage gain and 
limited accuracy and reproducibility of current values in current mirrors.
4.2.3  FETs versus BJTs
Although the FET and BJT operation are based on different physical principles, the net result is similar: a 
small change in input voltage (FET = VGS, BJT = VBE) produces a large change in output current (FET = IDS, 
BJT = ICE). This is the fundamental principle that governs the use of these devices in amplifiers and switches. 
Note that both devices have a region of current saturation (FET = saturation region, BJT = active region), 
which is used in voltage amplification. In this region, the change in current is dominated by the change 
in the input voltage (gm >> gout = gds, gce), which helps to keep the voltage amplification linear. Additionally, 
500 mA
0 V
0.5 V
1.0 V
1.5 V
2.0 V
2.5 V
3.0 V
3.5 V
4.0 V
4.5 V
0 A
200 mA
400 mA
IC vesus VBE
ID versus VGS
gmBJT
gmFET
FIGURE 4.12  Comparison of FET and BJT input voltage–output current characteristic curves.
© 2011 by Taylor and Francis Group, LLC

Transistor Operation and Modeling 
4-13
both devices have a region in which the current changes with the output voltage (FET = linear region, BJT = 
­saturation region), which is used to turn current on and off in use as a switch.
While FETs and BJTs work similarly in the abstract sense, the difference in characteristic equations 
produce a difference in how well each of these devices performs these operations. The difference between 
the devices is depicted in Figure 4.12. This figure shows the current–voltage relationship for an FET 
(ID versus VGS) overlaid upon the current–voltage relationship of a BJT (IC versus VBE). Note how much more 
sharply the BJT curve changes than the FET curve. This graph demonstrates that a small change in input 
voltage will generate a much larger change in output current for the BJT than the FET (e.g., gmBJT > gmFET). 
This difference in operation between the two devices in the saturation region can be seen by looking at 
Figures 4.7 and 4.12. In these figures, the change in output current (FET = ID, BJT = IC) is shown as a func-
tion of output voltage (FET = VDS, BJT = VCE). Notice how the saturation voltage for a BJT is approximately 
constant while the saturation voltage for the FET changes with VGS. This will impact how the saturation 
voltage is approximated in Chapter 5.
© 2011 by Taylor and Francis Group, LLC

5-1
5.1  Introduction
An operational amplifier (op amp) is an electronic device or integrated circuit (IC) made of transistors 
and resistors used to amplify or attenuate inputs. The op amp can be used for mathematical opera-
tions such as addition, subtraction, multiplication, division, differentiation, integration, and filtering. 
Op amp applications include audio preamplifiers, voltage comparators, rectifiers, regulators, analog-
to-digital converters, oscillators, sensor transducers, and waveform generators. The five terminals of 
interest associated with an op amp are as follows:
•	 Inverting input (Vn)
•	 Non-inverting input (Vp)
•	 Output (Vo)
•	 Positive power supply (V+)
•	 Negative power supply (V−)
Figure 5.1 shows the op amp circuit symbol with the five terminals of interest labeled.
5
Application of 
Operational Amplifiers
5.1	
Introduction....................................................................................... 5-1
Ideal Op Amp Assumptions  •  Linear Range of Operation
5.2	
Node Voltage Analysis of Op Amp Circuits..................................5-3
Inverting Amplifier  •  Non-Inverting Amplifier  •  Difference 
Amplifier  •  Weighted Difference Amplifier  •  Output 
Current  •  Saturation  •  Differentiator  •  Bandpass 
Filter  •  Phase- Shift Oscillator
5.3	
Common Op Amp Circuits...........................................................5-12
5.4	
Circuit Design with Op Amps.......................................................5-12
Practical Considerations  •  Practical Applications  • 
Gain Bandwidth Limitation  •  Design Examples
5.5	
Realistic Op Amp Model................................................................5-27
Inverting Amplifier  •  Non-Inverting Amplifier  •  Input 
Offset Voltage  •  Input Bias and Offset Currents  •  Frequency 
Response  •  Slew Rate
5.6	
Conclusion........................................................................................5-29
Bibliography ................................................................................................5-30
Carlotta A. Berry
Rose-Hulman Institute 
of Technology
Deborah J. Walter
Rose-Hulman Institute 
of Technology
© 2011 by Taylor and Francis Group, LLC

5-2 
Fundamentals of Industrial Electronics
5.1.1  Ideal Op Amp Assumptions
The model for an ideal op amp has infinite gain (Vo/(Vn − Vp)), infinite input impedance, and zero 
output impedance. Based upon this model, there are two assumptions made for analysis of an ideal 
op amp:
The infinite input impedance assumption states that no current enters the op amp from the positive or 
negative terminal (Ip = In = 0 A).
The virtual short circuit assumption states that the voltage at the positive terminal is the same as the 
voltage at the negative terminal (Vn = Vp).
Figure 5.2 provides an illustration of the two ideal assumptions.
Note that these two assumptions are only valid when the op amp is used in a closed-loop configura-
tion where the output is fed back to the inverting input through a passive circuit element. This configu-
ration is referred to as negative feedback. With the negative feedback, the closed-loop gain is decreased 
based upon a portion of the output subtracting from the input so the infinite gain does not cause the 
output to grow without bound to the positive or negative power supply.
5.1.2  Linear Range of Operation
The output (Vo) of an ideal op amp is a product of the gain (A) and the input voltage (Vin). However, the 
output is only linear when the output is in the range between the positive (V+) and negative (V− ) power 
supplies. When the output is outside of this range, the output maximizes or minimizes at the power 
supply voltage, and the op amp is saturated. Figure 5.3 illustrates the linear and nonlinear region for an 
op amp. The curve in Figure 5.3 is also called the saturation curve.
V+
Vo
V –
Vp
Vn
–
+
FIGURE 5.1  Op amp IC symbol.
V+
Vo
V –
Vp
Vn
–
+
In=0 A
Ip=0 A
FIGURE 5.2  Op amp assumptions.
© 2011 by Taylor and Francis Group, LLC

Application of Operational Amplifiers 
5-3
5.2  Node Voltage Analysis of Op Amp Circuits
The most common analysis technique for an ideal op amp circuit is Kirchhoff’s current law (KCL). By 
using KCL and the two ideal op amp assumptions, it is possible to find the output voltage and current 
for any op amp circuit. The steps to analyze the circuit are as follows:
	
1.	 If the voltage is unknown, use the infinite input impedance assumption to write the KCL equation 
at the positive (Vp) and/or negative (Vn) terminals.
	
2.	 Use the virtual short circuit assumption to simplify the KCL equations and solve for the output 
voltage (Vo) or any other required values.
This analysis technique will be demonstrated on several op amp circuits using DC and AC circuit analysis 
techniques.
5.2.1  Inverting Amplifier
The op amp circuit shown in Figure 5.4 represents an inverting amplifier. Note that Rf is the feedback 
resistor that feeds a portion of the output Vo back to the inverting input Vn. It is an amplifier because 
the value of the output is based upon the ratio of the feedback resistor Rf and the input resistor Ri. It 
is an inverting amplifier because the polarity of the output voltage is the reverse of the polarity of the 
input voltage.
The first step in the analysis is to note that Vp is tied to ground, therefore Vp = 0 V.
Vo
Slope = A
Saturation
Vin
Saturation
Linear region
FIGURE 5.3  Op amp saturation curve.
Rf
Ri
RL
Vo
3.6 kΩ
Vin
Vn
Vp
–
–
+
+
+
–
V +
V –
Io
+15 V
–15 V
3.3 kΩ
2.2 kΩ
FIGURE 5.4  Inverting amplifier.
© 2011 by Taylor and Francis Group, LLC

5-4 
Fundamentals of Industrial Electronics
Using the infinite input impedance assumption to create the KCL equation at Vn yields
	
V
V
R
V
V
R
in
n
i
n
o
f
−
=
−
	
(5.1)
Using the fact that Vp = 0 V and the virtual short circuit assumption so Vn = 0 V, it is possible to solve 
Equation 5.1 for Vo.
	
V
R
R
V
V
V
o
f
i
in
in
in
= −




= −




=
3 3
2 2
1 5
.
.
.
	
(5.2)
	
A
V
V
o
in
=
= −



= −
R
R
f
i
1 5.
	
(5.3)
From Equation 5.3, it is evident that the gain is the ratio of the feedback resistor to the input resistor, 
and the output is inverted. Note that this circuit can also be an attenuator by making the value of Rf less 
than Ri.
5.2.2  Non-Inverting Amplifier
The op amp circuit shown in Figure 5.5 represents a non-inverting amplifier.
The first step in the analysis is to note that Vp = Vin. Then, using the infinite input impedance assump-
tion to write the KCL equation at Vn yields
	
V
R
V
V
R
n
i
o
n
f
−
=
−
0
	
(5.4)
Using the fact that Vp =Vin and the virtual short circuit assumption, it is possible to solve Equation 5.4 
for Vo and the gain, A.
	
V
R
R
V
V
V
o
f
i
in
in
in
=
+




=
+




=
1
1
5 6
2 0
3 8
.
.
.
	
(5.5)
	
A
V
V
R
R
o
in
f
i
=
=
+



=
1
3 8.
	
(5.6)
Rf
5.6 kΩ
+15 V
V +
Vn
Ri
2.0 kΩ
Vp
V –
Io
RL
3.6 kΩ
Vo
–15 V
Vin
+
+
+
–
–
–
FIGURE 5.5  Non-inverting amplifier.
© 2011 by Taylor and Francis Group, LLC

Application of Operational Amplifiers 
5-5
Note that this gain, A, is positive and therefore the op amp configuration in Figure 5.5 produces a non-
inverting amplifier. Also note that from Equation 5.6 it is not possible for this configuration of a non-
inverting amplifier to attenuate the input voltage.
5.2.3  Difference Amplifier
The circuit shown in Figure 5.6 is a difference amplifier and it will be analyzed using KCL.
	
V
V
V
R
V
V
R
V
V
V
R
V
R
n
n
a
i
n
o
f
p
p
b
i
p
f
:
:
−
+
−
=
−
+
−
=
0
0
0
	
(5.7)
Using the virtual short circuit condition and solving Equation 5.7 yields
	
V
R
R
V
V
V
V
o
f
i
b
a
b
a
= 



−
=
−
(
)
(
)
7
	
(5.8)
The differential amplifier has a differential input mode defined as the difference between the two 
input voltages. The second feature of a difference amplifier is the common mode input, the average of 
the two input voltages. Ideally, the common mode gain should be zero and only the differential input 
should be amplified. Typically, the common mode signal represents the noise found in most electric 
signals, which should be suppressed at the output. To design for this feature, the resistors used in the 
op amp must be well matched. The common mode rejection ratio (CMRR) is used to measure how 
well a difference amplifier performs. The CMRRR is the ratio of the differential mode gain to the 
common mode gain.
5.2.4  Weighted Difference Amplifier
The circuit shown in Figure 5.6 can be changed to a weighted difference amplifier by modifying the 
values of the resistors. This modified circuit is shown in Figure 5.7 and it will be analyzed using 
superposition.
Rf
Ri
Ri
Rf
Vp
Vb
Va
V+
Vn
+
–
–
–
+
+
V–
–15 V
Vo
+15 V
91 kΩ
13 kΩ
13 kΩ
91 kΩ
FIGURE 5.6  Difference amplifier.
© 2011 by Taylor and Francis Group, LLC

5-6 
Fundamentals of Industrial Electronics
Superposition involves turning on each of the voltage inputs one at a time and determining the 
output due only to that source. The principal of linearity then states that the total output voltage 
will be the sum of the voltage due to each source acting alone. Note that to turn off a voltage source, 
replace it with a short circuit that represents 0 Ω and 0 V. If only the voltage Va is turned on, then Vb 
becomes 0 V. Note that this configuration is the same as Figure 5.4 and is an inverting amplifier. So 
from Equation 5.2,
	
′ = −




= −




= −
V
R
R
V
V
V
o
b
a
a
a
a
33
11
3 0.
	
(5.9)
Now, if only the voltage Vb is turned on, then Va becomes 0 V. This configuration is similar to Figure 
5.5 and is a non-inverting amplifier. Vp can be found by using the voltage divider and substituting into 
Equation 5.5. This yields the following relationship:
	
V
R
R
R
V
V
V
p
d
c
d
b
b
b
=
+




=
+




=
91
13
91
7
8
	
(5.10)
	
′′ =
+




+




=
+








=
V
R
R
R
R
R
V
V
o
b
a
d
c
d
b
b
1
1
33
11
7
8
3.5Vb
	
(5.11)
Therefore, using the principle of superposition, the total output Vo would be the sum of the voltages 
given in Equations 5.9 and 5.11:
	
V
V
V
V
V
o
o
o
b
a
=
′ +
′′=
−
3 5
3 0
.
.
	
(5.12)
5.2.5  Output Current
For the difference amplifier shown in Figure 5.7, if Va = Vb = 5 V, the output voltage, Vo, can be found 
from Equation 5.12 as
	
V
V
V
o
a
b
=
−
=
−
=
3 5
3 0
3 5 5
3 0 5
2 5
.
.
. ( )
. ( )
. V 	
(5.13)
Rb
Ra
Rc
Rd
Vn
V+
Vo
V–
+
+
–
–
+
–
RL
24 kΩ
–15 V
+15 V
Vp
Vb
Va
33 kΩ
11 kΩ
13 kΩ
91 kΩ
FIGURE 5.7  Weighted difference amplifier.
© 2011 by Taylor and Francis Group, LLC

Application of Operational Amplifiers 
5-7
The output current, Io, can be found by using the following equation:
	
I
V
R
k
o
o
L
=
=
=
2 5
24
104
.
mA
	
(5.14)
One benefit of an op amp is the fact that the addition of the load does not change the output voltage, Vo. 
However, it is important when designing an op amp circuit to insure that the output current does not 
exceed the output current specifications for the specific device. This can be accomplished with proper 
selection of the load, feedback, and input resistors, typically in the kΩ range.
5.2.6  Saturation
For the circuit shown in Figure 5.5, if we assume that the non-inverting amplifier saturates exactly at the 
positive and negative power supply, the saturation curve is shown in Figure 5.8. This curve has a positive 
slope of 3.8 with a maximum voltage of 15 V and a minimum voltage of −15 V. The saturation curve for 
an inverting amplifier would be similar except with a negative slope.
5.2.7  Differentiator
The circuit shown in Figure 5.9 is a differentiator and can also be analyzed using KCL.
20
Vout, V
Vin, V
15
10
5
0
–8
–6
–4
–2
2
4
6
8
0
–10
–5
–15
–20
FIGURE 5.8  Saturation curve for a non-inverting amplifier.
Rf
100 kΩ
V+
V–
Vo
Vn
C
Vin
100 nF
Vp
–
–
+
+
+15 V
–15 V
FIGURE 5.9  Differentiator.
© 2011 by Taylor and Francis Group, LLC

5-8 
Fundamentals of Industrial Electronics
The first step in the analysis is to note that Vp = 0 V and therefore Vn = 0 V based upon the virtual 
short circuit assumption. Using the infinite input impedance assumption to create the KCL equation at 
Vn yields
	
C d V
V
dt
V
V
R
in
n
n
o
f
(
)
−
=
−
	
(5.15)
Substituting the numeric value of Vn = 0 V into Equation 5.15 yields
	
C dV
dt
V
R
in
o
f
= −
	
(5.16)
Solving Equation 5.16 for Vo yields
	
V
R C dV
dt
dV
dt
o
f
in
in
= −
= −0 01
.
	
(5.17)
From Equation 5.17, note that the output is the inverse of the derivative of the input with a gain of 
A = −RfC.
5.2.8  Bandpass Filter
The circuit shown in Figure 5.10 is a broadband bandpass filter.
A broadband bandpass filter is defined as one where ωc2 ≫ ωc1. Broadband means that the upper 
cutoff frequency is at least a magnitude or two greater than the lower cutoff frequency. It is possible 
to identify this circuit as a bandpass filter by using qualitative analysis. Intuitively, at low frequen-
cies (D.C. conditions), a capacitor models an open circuit, and at high frequencies it models a short 
circuit. Therefore at low frequencies, the output of the circuit in Figure 5.9 is zero volts because the 
input is zero volts. At high frequencies, the output of the circuit in Figure 5.9 is zero because of the 
Cf
Ci
Ri
Vin
100 kΩ
100 nF
10 nF
10 kΩ
Rf
V+
V–
Vo
–15 V
Vn
Vp
+15 V
+
+
–
–
FIGURE 5.10  Broadband bandpass filter.
© 2011 by Taylor and Francis Group, LLC

Application of Operational Amplifiers 
5-9
virtual short circuit assumption. At the resonance frequency, (ωo = ω ω
c
c
1
2 ), the transfer function 
is purely real and the gain of the circuit is ≅ Rf /Ri.
This circuit can also be analyzed quantitatively by using KCL and steady-state analysis. This yields an 
equation similar to Equation 5.2, because this circuit is still an inverting amplifier but with a feedback 
impedance and input impedance instead of resistors.
Recall that the impedance of a capacitor in the frequency domain is Z = 1/(jωC). The circuit in Figure 
5.10 redrawn in the phasor domain is shown in Figure 5.11.
Use the inverting amplifier relationship in Equation 5.2 to derive the output for Figure 5.10. The rela-
tionship in terms of the input and feedback impedance is shown in Equation 5.18, where Zi is the series 
combination of Ri and ZCi, and Zf is the parallel combination of Rf and ZCf.
	
V
Z
Z
V
o
f
i
in
= −




,
	
(5.18)
The expressions for Zi and Zf are given in Equations 5.19 and 5.20, respectively:
	
Z
R
j C
j C R
j C
kj
M
j
i
i
i
i
i
i
=
+
=
+
=
+
1
1
100
10
ω
ω
ω
ω
ω
	
(5.19)
	
Z
R
j C
R
j R C
k
j
f
f
f
f
f
f
=
=
+
=
+

1
1
10
1
100
ω
ω
ω
µ 	
(5.20)
By substituting Equations 5.19 and 5.20 into 5.18, the output equation becomes
	
V
Z
Z
V
R
j C R
j C R
j C
V
o
f
i
in
f
f
f
i
i
i
in
= −




= −
+
+




= −
/(
)
(
)/
ω
ω
ω
1
1
j C R
j C R
j C R
V
i
f
i
i
f
f
in
ω
ω
ω
(
)(
)
+
+




1
1
	
(5.21)
Rf
Zcf
jω
100 M
10 kΩ
V+
V–
Vo
Vn
ZCi
Ri
Vin
+
–
–
jω
10 M
100 kΩ
Vp
+15 V
–15 V
+
FIGURE 5.11  Broadband bandpass filter (frequency domain).
© 2011 by Taylor and Francis Group, LLC

5-10 
Fundamentals of Industrial Electronics
Equation 5.21 can be written as a transfer function in terms of the gain (K), bandwidth (β), and resonant 
frequency (ωo) as
	
H j
V
V
R
R
C R
j
j
RC
j
R C
o
i
f
i
f
f
i
i
f
f
(
)
ω
ω
ω
ω
=
= −
(
)(
)
+(
)
(
)
+(
)
(
)







1
1
1

= −
+
+




= −−
+
+



= −
K
j
j
j
K j
j
c
c
c
o
ω
ω
ω
ω
ω
ω
β ω
ω
β ω
ω
2
1
2
2
2
(
)(
)
(0 1 10
100
10
. )(
)
(
)(
)
k j
j
j
k
ω
ω
ω
+
+




	
(5.22)
From examination of Equation 5.22, the gain K is Rf /Ri = 0.1, the lower cutoff frequency ωc1 is 1/(RiCi) = 
100 rad/s, the upper cutoff frequency ωc2 is 1/(RfCf) = 10 krad/s, the resonant frequency ωo is ω ω
c
c
1
2  = 
1000 rad/s, and the bandwidth β is ωc2 + ωc1 = 10.1 krad/s. Note that the numerator is not exactly the 
bandwidth, thus the requirement that the upper cutoff frequency be much larger than the lower cutoff 
frequency. The Bode diagram for the magnitude of the gain of the bandpass filter is shown in Figure 
5.12. This is the ideal Bode diagram because it does not consider gain-bandwidth limitations; these and 
other practical considerations of op amp design will be addressed in Section 5.4.
5.2.9  Phase-Shift Oscillator
The circuit shown in Figure 5.13 is a phase-shift oscillator.
–10
–15
20 log10(0.1)
|H(jω)|, dB
–20
–25
–30
ωc1
ω0
ω, rad/s
ωc2
–35
–40
10
100
1000
10000
100000
FIGURE 5.12  Bandpass filter Bode diagram.
R
R
C
C
C
Rf
R
–
+
Vo
Vi
R
Va
Vb
FIGURE 5.13  Phase-shift oscillator.
© 2011 by Taylor and Francis Group, LLC

Application of Operational Amplifiers 
5-11
This design of this system is based upon the control theory that a feedback system such as an op amp 
will oscillate when it becomes marginally stable. It will become marginally stable when the poles of the 
transfer function are purely imaginary and the gain is 1 or 0 dB. Another way to express this require-
ment is that the phase shift at a certain frequency must be −180° or the frequency where the transfer 
function is purely real. The RC network will be used to get a phase shift of −180° or −60° per stage. The 
negative feedback gain (Rf  /Rδ) of the inverter will be used to compensate for the attenuation in the RC 
network to meet the gain specification of 1.
The first step in the design of the phase-shift oscillator is to find the transfer function of the RC net-
work, Vi(s)/Vo(s). The transfer function of the RC network is the feedback gain of the closed-loop control 
system. This gain can be found by applying KCL at the nodes Va, Vb, and Vi. The results of this analysis 
are shown in Equation 5.23.
	
V
V
V
R
V
V
R
sCV
V
V
V
R
V
V
R
sCV
V
V
V
R
V
a
a
b
a
o
a
b
b
i
b
a
b
i
i
b
i
:
:
:
−
+
−
+
=
−
+
−
+
=
−
+
0
0
−
+
=
0
0
R
sCVi
	
(5.23)
Solving the three equations in (Equation 5.23) yields
	
H s
V s
V s
s R C
s R C
sRC
i
o
( )
( )
( )
=
=
+
+
+
1
6
10
4
3
3
3
2
2
2
	
(5.24)
In order to design for the −180° phase shift, express the transfer function in Equation 5.24 as a function of jω:
	
H j
V j
V j
R C
j
RC
R C
i
o
(
)
(
)
(
)
(
)
ω
ω
ω
ω
ω
ω
=
=
−
+
−
1
4
6
10
2
2
2
3
3
3
	
(5.25)
The phase shift for the transfer function in Equation 5.25 is
	
φ
ω
ω
ω
ο
=
−
−
−




−
0
10
4
6
1
3
3
3
2
2
2
tan
RC
R C
R C
	
(5.26)
In order for the phase shift to be −180°, the imaginary part of the denominator must be equal to zero so 
that the denominator is purely real. Solving this expression for ω yields
	
ω =
10
RC 	
(5.27)
In order to find the gain of the inverting amplifier to satisfy the 0 dB gain specification, find the magni-
tude of the gain for the transfer function H(jωR), where ωR = 10/RC.
	
|
(
)|
H j
R C
R
R
ω
ω
=
−
=
1
4
6
1
56
2
2
2
	
(5.28)
To compensate for the attenuation in the RC network, the gain of the inverting amplifier should be the 
inverse of the gain in (5.28). Therefore, set
	
R
R
f = 56
	
(5.29)
© 2011 by Taylor and Francis Group, LLC

5-12 
Fundamentals of Industrial Electronics
5.3  Common Op Amp Circuits
Using KCL and the two ideal op amp assumptions it is possible to analyze and design many types of op 
amps. Table 5.1 presents a summary of some common op amp circuits and their output relationships.
5.4  Circuit Design with Op Amps
The prior section has summarized the analysis of several op amp circuits using the two ideal assump-
tions. However, in op amp design, these ideal assumptions may not always hold true and there are 
several practical considerations including selecting reasonable resistor values, finding input resistance, 
gain-bandwidth compensation, balancing inputs, input offset voltages, input bias and offset currents, 
slew rate, and frequency response. This section will discuss the practical consideration and design of op 
amp applications and the subsequent section will discuss the features of a more realistic op amp model.
5.4.1  Practical Considerations
One of the most fundamental considerations when designing an op amp circuit is the selection of the 
input, feedback, and load resistors. It is to select resistor sizes that do not require too much current 
from the op amp but supply sufficient current to drive a load. Small resistors may dissipate a great 
deal of power; however, larger resistors exhibit more noise. Therefore for op amp design, reasonable 
values of resistors would be between 1 kΩ and 1 MΩ. In addition, because capacitor values may be 
more limiting, it is important to select resistors first in a design and then choose standard capacitor 
values in the μF to pF range.
5.4.2  Practical Applications
One practical application for op amps is in audio systems. An op amp can be used to drive a speaker. 
The microphone converts acoustic pressure to a voltage typically in the mV range. The op amp is 
used to amplify the voltage to drive a headphone or speaker. In order for the amplifier not to load 
the output of the microphone, it must have high input impedance. This high input impedance can 
be accomplished by using a non-inverting amplifier that has higher input impedance than an invert-
ing amplifier. Op amps can also be used for signal conditioning to amplify and/or convert the signal 
from sensors such as temperature, force, pressure, acceleration, and light intensity. For a photocell 
amplifier, the output of a photocell is connected to a current-to-voltage converter to produce a value 
proportional to incident light. This solution works because it provides a constant terminal voltage to 
the photocell typically 0 V and low load impedance. To measure strain, a strain gauge can be used in 
a Wheatstone bridge to linearize the output resistance with respect to the strain. The output of the 
bridge is a voltage in the mV range that can be input into an instrumentation amplifier with high 
input impedance and low output impedance. The instrumentation amplifier is used to amplify the 
output, the voltage proportional to strain. Lastly, op amps can be used to filter out unwanted noise in 
communication signals, for example that caused by the power line in telemetry. In this case, a notch 
or band stop filter can be used to remove a 60 Hz signal.
5.4.3  Gain Bandwidth Limitation
An op amp typically has a closed-loop gain that rolls off at 20 dB/decade at a certain frequency. The 
op amp has an internal compensation network built in to improve performance. The fixed compen-
sation modifies the open-loop frequency response and is typically a passive RC low-pass filter. The 
transfer function for this RC compensation network is G(s) = Go/(1 + s/ωo), where Go is the open-loop 
gain and ωo is the cutoff frequency. The gain-bandwidth product (GBP) is a constant that is found by 
© 2011 by Taylor and Francis Group, LLC

Application of Operational Amplifiers 
5-13
TABLE 5.1  Common Op Amp Circuits
Amplifier Type
Circuit Configuration
Relationships
Voltage follower
Vo
Vin
–
+
Vo = Vin
Inverting
Rf
Ri
Vin
Vo
–
+
V
R
R
V
o
f
i
in
= −




Non-inverting
Rf
Ri
Vo
Vin
–
+
V
R
R
V
o
f
i
in
=
+




1
Summing
Ra
Va
Vb
Vc
Vo
Rb
Rc
+
–
Rf
V
R
R
V
R
R
V
R
R
V
o
f
a
a
f
b
b
f
c
c
= −




+ −




+ −




Difference
R2
R1
R3
R4
Vo
V2
V1
–
+
V
R
R
R
R
R
R
V
R
R
V
o =
+
+








−



1
2
3
4
4
1
2
2
1
1
(continued)
© 2011 by Taylor and Francis Group, LLC

5-14 
Fundamentals of Industrial Electronics
TABLE 5.1 (continued)  Common Op Amp Circuits
Amplifier Type
Circuit Configuration
Relationships
Instrumentation 
Amplifier 
(Type I)
R1
V1
V2
R2
Vo
R2
+
+
–
–
+
–
R1
V
R
R
V
V
o = 



−
2
1
2
1
(
)
Instrumentation 
Amplifier 
(Type II)
R
V1
V2
Vo
RG
R
R
R
R
R
+
–
+
–
+
–
V
R
R
V
V
o
G
=
+




−
1
2
2
1
(
)
Differentiator
R
C
Vin
Vo
–
+
V
RC dV
dt
o
in
= −
Integrator
R
C
Vo
–
+
Vin
V
RC
V d
o
in
= −
∫
1
τ
Lowpass filter
Ri
Rf
Vo
–
+
Cf
Vin
H s
V s
V
s
R R
R C
s
R C
o
in
f
i
f
f
f
f
( )
( )
( )
(
/ )(( /
))
( /
)
=
=
+
1
1
© 2011 by Taylor and Francis Group, LLC

Application of Operational Amplifiers 
5-15
TABLE 5.1 (continued)  Common Op Amp Circuits
Amplifier Type
Circuit Configuration
Relationships
Butterworth 
Lowpass filter
R
R
C2
Vo
+
–
C1
Vin
H s
V s
V
s
C C R
s
C R s
C C R
o
in
( )
( )
( )
/
( /
)
( /
)
=
=
+
+
1
2
1
1
2
2
2
1
1
2
2
Highpass filter
Ri
Vin
Rf
Vo
–
+
Ci
H s
V s
V
s
R R s
s
R C
o
in
f
i
i
i
( )
( )
( )
(
/ )
( /
)
=
=
+ 1
Butterworth 
Highpass filter
R1
R2
Vo
Vin
C
C
–
+
H s
V s
V
s
s
s
R C s
R R C
o
in
( )
( )
( )
( /
)
( /
)
=
=
+
+
2
2
2
1
2
2
2
1
Broadband 
Bandpass filter
ωc2 >> ωc1
Q < 0.5
Rf
Vo
Ri
Vin
Cf
Ci
–
+
H s
V s
V
s
R R
C R
s
s
R C
s
R C
o
in
f
i
f
f
i
i
f
f
( )
( )
( )
(
/ )( /
)
(
( /
))(
( /
))
=
=
+
+
1
1
1
Narrowband 
Bandpass filter
R1
Vin
R3
R2
Vo
–
+
C
C
H(s) = 
K s
s
s
o
β
β
ω
2
2
+
+
H(s) = 
−
+
+
s R C
s
R C s
R R C
eq
/(
)
/(
)
/(
)
1
2
3
3
2
2
1
β = 2/(R3C)
ωo
2 = 1/(ReqR3C 2)
Req = R1||R2
Kβ = −1/(R1C)
(continued)
© 2011 by Taylor and Francis Group, LLC

5-16 
Fundamentals of Industrial Electronics
TABLE 5.1 (continued)  Common Op Amp Circuits
Amplifier Type
Circuit Configuration
Relationships
Narrowband 
Bandreject filter
R
Vin
R/2
R
2C
Vo
(1 – σ)R
σR
+
–
+
–
C
C
H(s) = 
s
s
s
o
o
2
2
2
2
+
(
)
+
+
ω
β
ω
H(s) = 
s
R C
s
RC s
R C
2
2
2
2
2
2
1
4 1
1
+
+
−
+
/(
)
( (
)/
)
(
)
σ
β = 4(1 − σ)/(RC)
ωo
2 = 1/(R2C 2)
σ = 1 − β/(4ωo)
I–V Converter
Rf
Iin
Vo
–
+
Vo = −RfIin
V–I Converter
R
R
R
Va
Vb
R
RL
iL
–
+
i
V
V
R
L
a
b
=
−
Square-wave 
oscillator
R1
R3
Vo
R2
C
+
–
Period, T = (2R1C) ln 1
1
+
−




λ
λ
s
λ =
R
R
R
2
2
3
+
© 2011 by Taylor and Francis Group, LLC

Application of Operational Amplifiers 
5-17
multiplying the open-loop gain Go, with the bandwidth ωo. Figure 5.14 presents the gain-bandwidth 
curves for an op amp with a GBP of 106. The vertical axis is the open-loop gain Go, and each curve 
is a different closed-loop gain A. For design purposes, the op amp closed-loop gain should be 1/20th 
of the open-loop gain at a given frequency to avoid performance issues based upon gain-bandwidth 
limitations.
0.1
0
20
40
60
80
100
Go, dB
Open loop gain
Closed loop gain
|Av|, dB
GBP = 106
1
10
100
1,000
Frequency, Hz
10,000
100,000 1,000,000
FIGURE 5.14  Example closed-loop gain-bandwidth curves.
TABLE 5.1 (continued)  Common Op Amp Circuits
Amplifier Type
Circuit Configuration
Relationships
Phase-shift 
oscillator
R
R
Rf
–
+
Vo
Vin
R
R
C
C
C
H s
s
s
s R C
s R C
sRC
o
( )
( )
( )
= v
v
i
=
+
+
+
1
6
10
4
3
3
3
2
2
2
ω =




= −
10
56
RC
R
R
f
,
Gyrator
R1
R2
R3
R4
C
I
–
+
–
+
V
+
–
Vo
Z = V
I
s C
=
R R R
R
1
3
4
2
L
CR R R
R
H
=
1
3
4
2
© 2011 by Taylor and Francis Group, LLC

5-18 
Fundamentals of Industrial Electronics
5.4.4  Design Examples
Example 5.1:  Displacement Signal Conditioning
A potentiometer is used to measure the location and position of boxes on a conveyor system. The dis-
placement of the box moves the wiper of the potentiometer. The potentiometer converts the linear 
change in displacement to a resistance. The model for the system is shown in Figure 5.15.
If a 100 kΩ potentiometer is used to measure the displacement of a box from 0 to 50 feet, design a sig-
nal-conditioning circuit with a sensitivity of 0.25 V/ft by using an inverting amplifier. Note that the poten-
tiometer could be used in a voltage divider or bridge circuit to supply the input to the op amp; however, 
in both of these methods the linear relationship between displacement and resistance becomes nonlin-
ear. Therefore, the most feasible approach would be to use the potentiometer in the feedback loop of 
the op amp. In this configuration, the resistance of the potentiometer is directly proportional to the gain 
of the op amp. The resolution of the potentiometer is found by using Equation 5.30.
	
∆
Ω
=
=
100
50
2000
k
ft
/ ft
Ω
	
(5.30)
The inverting amplifier configuration was selected because the relationship between the feedback resis-
tor and the input is nonlinear for a non-inverting amplifier. Assume the input to the inverting amplifier 
is Vi = −1 V. When the box moves 1 foot, the potentiometer output is Rf = 2 kΩ based upon the required 
sensitivity of 0.25 V/ft. Ri can be found from the following equation:
	
R
R
V V
i
f
o
i
= −
= −
−=
2000
0 25
1
8
.
(
)
kΩ
	
(5.31)
Linear
displacement
Potentiometer
sensor
Ω
FIGURE 5.15  Box conveyor system.
Rpot
8 kΩ
–15 V
1.12 kΩ
80 Ω
Vi=–1 V
–
+
Vo
FIGURE 5.16  Inverting amplifier example.
© 2011 by Taylor and Francis Group, LLC

Application of Operational Amplifiers 
5-19
Figure 5.16 presents the final design of the displacement signal-conditioning circuit with Vi as the input 
from a voltage divider. Note that the resistor values for the voltage divider were selected in order to limit 
loading effects of the op amp input resistance.
To confirm that this design meets the specification equation it is necessary to find the potentiometer 
output, op amp output, and displacement sensitivity assuming a box moves 25 ft. The output of the 
potentiometer is
	
Rpot =
=
(
)(
/ )
25
2
50
 
 
ft
k
ft
k
Ω
Ω	
(5.32)
The output of the op amp is
	
V
k
k
o = −
= −
−=
R
R V
pot
i
in
50
8
1
6 25
(
)
.
V
	
(5.33)
	
Sensitivity
t
=
=
6 25
25
0 25
.
.
V
f
V/ft
	
(5.34)
Therefore, this design does meet the specification.
Example 5.2:  Current–Voltage (I–V) Converter Example
It is possible to design a photodiode signal-conditioning circuit with a sensitivity of 30 V/fc by using an 
I–V converter. Photodiodes are used for camera flash controls, headlight dimmers, bar code scanners, and 
laser printers. Assume that the photodiode outputs a small current that is proportional to the incident 
light intensity at a range of 30 μA to 30 pA for 1000–0.001 fc. Select resistor values for the circuit in 
Figure 5.17 to satisfy the design constraints.
The first step in the design is to determine the gain of each of the stages. If the sensitivity is 30 V/fc, 
then the sensitivity is (30 V/fc) (1000 fc/30 μA) = 1 mV/pA. This means that the overall gain for the condi-
tioning circuit is 1 × 109. It is possible to implement this gain with one stage, but that would require a 
1000 MΩ resistor, which is very noisy. Instead, a viable solution would be to convert the current to a volt-
age in nV and then use the inverting amplifier to amplify the signal to mV. Therefore,
	
V
I
o
d
f
1
1
=
=
MΩ
R
	
(5.35)
	
V
V
k
R
R
o
o1
2
1
100
= −
= −
	
(5.36)
Rf
R1
R2
Vo
Vo1
–
+
–
+
Id
FIGURE 5.17  Current–voltage converter example.
© 2011 by Taylor and Francis Group, LLC

5-20 
Fundamentals of Industrial Electronics
one set of reasonable resistor values that satisfy these design equations are Rf = 1 MΩ, R2 = 100 MΩ, and 
R1 = 1 kΩ. The one-stage solution for the design is shown in Figure 5.18.
The final step would be to confirm that the circuit designed satisfies the 30 V/fc sensitivity require-
ment. If the light intensity is 0.001 fc, then the photodiode current is 30 pA. The output of the I–V con-
verter would be (30 pA) (10 kV/A) = 300 nV/A. The output of the inverting amplifier would be (300 nV) 
(−100k) = −30 mV, so the design constraint is satisfied.
Example 5.3:  Difference Amplifier
It is possible to design a strain gauge signal-conditioning circuit with sensitivity 3 mV/(μm/m) by using 
a Wheatstone bridge and difference amplifier. Input buffers are added to the input of the difference 
amplifier to create an instrumentation amplifier that resolves the problem of low input impedance to the 
op amp. The 3 kΩ strain gauge is placed in one branch of the Wheatstone bridge and at full scale deflec-
tion, 3030 Ω indicates a 5000 μm/m strain. Therefore the strain or deflection is proportional to a change 
in resistance, ΔR. Note that when there is no strain, the bridge is at null where all four legs are 3 kΩ. 
Figure 5.19 presents the strain gauge signal-conditioning circuit.
Since a deflection of 30 Ω indicates a 5000 μm/m strain, the output voltage of the signal-conditioning 
circuit should be
	
(
)(
)
/ m/m
/
3
5000
15
mV
m m
 V
µ
µ
=
	
(5.37)
It is possible to find the output of the Wheatstone bridge when the strain gauge outputs 3030 Ω by using 
the voltage divider. Equations 5.38 and 5.39 present the result of this analysis.
	
V
R
R
k
k
a =
=
=
2 15
3
6 15
7 5. V
	
(5.38)
Rf
Id
1000 MΩ
Vo
–
+
FIGURE 5.18  Single-stage current–voltage converter.
R2
R
R
R
15 V
R+ΔR
strain
gauge
R2
R1
R1
Va
Vb
Vo
–
+
–
+
–
+
FIGURE 5.19  Difference (instrumentation) amplifier example.
© 2011 by Taylor and Francis Group, LLC

Application of Operational Amplifiers 
5-21
	
V
R
R
R
R
k
k
b =
+
+
=
=
∆
∆
2
15
3 03
6 03 15
7 537
.
.
.
V
	
(5.39)
Using the results of Equations 5.38 and 5.39, the differential voltage Vd is obtained:
	
V
V
V
d
a
b
=
=
−
0 037
.
V 	
(5.40)
The differential voltage can be used to find the op amp gain, which is
	
A
R
R
=
=
=
15
0 037
402
2
1
.
	
(5.41)
If we let R2 = 400 kΩ and R1 = 1 kΩ, this satisfies the design constraint. The final step would be to con-
firm that the circuit design satisfies the 3 mV/μm/m sensitivity requirement. If the strain is 1 μm/m, then 
the output of the gauge is 3000 + (30/5000)(1) = 3000.006 Ω. The output of the difference amplifier 
is Vd = 15(0.5000005−0.5) = 7.5 μV. The output of the difference amplifier is (400)(7.5 μV) = 3 mV so the 
design constraint is satisfied.
Example 5.4:  Broadband Bandpass Filter Design
If a communication signal is 1 Vrms at 1 kHz with 100 mVrms 60 Hz power line noise and 100 mVrms 100 kHz 
machine vibration noise, design a filter to amplify the communication signal to 20 dB with at least a 40 dB 
signal to noise ratio (SNR) for the power line and machine vibration noise. In order to meet this design 
specification, it is necessary to use the broadband bandpass filter shown in Figure 5.20.
The resonant frequency should be ωo = 2π(1000) = 6283 rad/s with a gain of 20 dB or K = 1020/20 = 10 
in order to meet the design specifications. These gain design specifications yield the following constraint 
equation:
	
|
|
K
R
R
f
i
=
=10
	
(5.42)
The other two constraint equations are set by the lower and upper cutoff frequencies. In order to 
attenuate the noise signals, set the lower cutoff ωc1 = 2π(500) = 3.14 krad/s and the upper cutoff to 
ωc2 = 2π(10k) = 62.83 krad/s. These two requirements yield the following two constraint equations:
	
ωc
i
i
R C
1
1
3 14
=
= .
krad s/
	
(5.43)
	
ωc
f
f
R C
2
1
62 83
=
=
.
krad s/
	
(5.44)
Rf
Vo
Ri
Vin
Cf
Ci
–
+
FIGURE 5.20  Broadband bandpass filter example.
© 2011 by Taylor and Francis Group, LLC

5-22 
Fundamentals of Industrial Electronics
Since there are four unknown component values and three constraint equations, choose one of the 
values. Since capacitors are typically more restrictive in the available values, set Cf = 1 nF. Using Equation 
2.35 yields Rf = 15.92 kΩ. Substituting Rf into Equation 5.42 yields Ri = 1.59 kΩ. Lastly, substitute the value 
for Ri into Equation 5.43 to calculate Ci. The calculation for Ci is
	
C
k
k
i =
=
1
3 14
1 59
0 2
( .
)( .
)
. µF
	
(5.45)
The final step would be to confirm that the design meets the specification. The transfer function for the 
designed filter is
	
H s
R R
C R s
s
R C
s
R C
k s
s
f
i
f
f
i
i
f
f
( )
/
/
/
( /
)
(
.
)
(
(
)(
)
(
)(
)
== −
+
+
= −
1
1
1
628 3
+
+
3 14
62 83
.
)(
.
)
k s
k
	
(5.46)
In order to verify the gain and SNR, substitute the frequencies of interest into Equation 5.46, which yields 
(5.47) through (5.49):
	
H j(
)
.
2 60
1 19
97
π
=
∠−
° 	
(5.47)
	
H j(
)
.
2 1000
8 9
160
π
=
∠−
° 	
(5.48)
	
H j
k
(
)
.
2 100
0 995 96
π
=
∠
° 	
(5.49)
To verify the gain at resonance, use the result in (5.48):
	
20
8 9 1
19
10
log ( . / ) =
dB 	
(5.50)
The SNR for the power line noise is found from the result of (5.47):
	
SNR =
=
20
8 9 0 119
37 5
10
log
. / .
.
(
)
dB
	
(5.51)
The SNR for the power line noise is found from the result of (5.49):
	
SNR =
=
20
8 9 0 0995
39
10
log
.
.
(
)
dB 	
(5.52)
Although not exact, the filter gain error is only 1 dB lower than specification and the low frequency noise 
SNR is 2 dB lower than specification. Figure 5.21 shows the signal before and after passing through the 
Bode diagram of the filter.
20
H(jω), dB
V, Vrms
V, Vrms
Time, s
Time, s
Signal with noise
Bandpass filter
Filtered signal
10
0
–10 1
10
100 1,000 10,000 100,000 1,000,000
Frequency, Hz
–20
–30
–40
FIGURE 5.21  Communication signal before and after filtering.
© 2011 by Taylor and Francis Group, LLC

Application of Operational Amplifiers 
5-23
An alternate solution for this problem would be to use a high-Q (narrowband) filter. The Sallen–Key 
filter shown in Figure 5.22 is a second-order high-Q filter. This filter has a quality factor (Q > 1/2), and unlike 
the prior broadband filter it does not have discrete real poles. It can be designed to meet the bandwidth 
and resonant frequency specifications and cascaded with an amplifier to meet the gain specification.
The transfer function for the filter is
	
H s
R C
s
s
s
o
( )
( / (
))
,
=
+
+
1
1 1
2
2
β
ω
where
	
(5.53)
	
ωo
R
R
R R R C C
R C
R C
R C
2
1
3
1 2 3
1 2
2
2
1 1
2
1
1
1
1
=
+
=
+
+
and β
	
(5.54)
In order to simplify the analysis, let R2 = 2R1, C1 = C2 = 0.1 μF, and Q = 1. Using this analysis yields R1 = 3.2 kΩ, 
R2 = 6.4 kΩ, and R3 = 455 Ω. The final step would be to confirm that the design meets the specification. 
The transfer function for the designed high-Q filter cascaded with an amplifier with a gain of 20 is
	
H s
R C
s
s
s
R
R
s
s
s
M
o
f
i
( )
( /(
))
(
)
=
+
+
=
+
+
1
3125
6250
40
20
1 1
2
2
2
β
ω x
x
	
(5.55)
In order to verify the gain and SNR, substitute the frequencies of interest into Equation 5.55, which yields 
(5.56) through (5.58):
	
H j(
)
.
2 60
0 6 87
π
=
∠
° 	
(5.56)
	
H j(
)
.
2 1000
10 0 8
π
=
∠
° 	
(5.57)
	
H j
k
(
)
.
2 100
0 1
89
π
=
∠−
° 	
(5.58)
To verify the gain at resonance, use the result in (5.48):
	
20
10 1
20
10
log (
/ ) =
dB 	
(5.59)
The SNR for the power line noise is found from the result of (5.60):
	
SNR =
=
20
10 0 06
44
10
log (
/ .
)
dB 	
(5.60)
R3
R2
R1
Vin
C2
C1
Vo
–
+
FIGURE 5.22  Sallen–Key bandpass filter.
© 2011 by Taylor and Francis Group, LLC

5-24 
Fundamentals of Industrial Electronics
The SNR for the machine vibration noise is found from the result of (5.61):
	
SNR =
=
20
10 0 01
60
10
log (
/ .
)
dB
	
(5.61)
The communications signal before and after the Sallen–Key filter is shown in Figure 5.23. It is evident from 
the results that this is a steeper and more accurate design.
Example 5.5:  Proportional-Integral-Derivative Controller
Op amps can be used for signal conditioning and also for controller design for a process control system 
(Figure 5.24). A proportional-integral-derivative (PID) controller is one type of controller that can be used 
to maintain a system at a given set point while reducing oscillations, offset error, and accumulation error 
(Figure 5.25). Figures 5.24 and 5.25 provide the block diagram of this system and the circuit schematic, 
respectively.
For example, if a thermostat is set to a certain temperature, a PID controller can be used to send an 
output to the heater based upon error between the set point and the room’s temperature. Assume that 
a thermostat is used to represent the temperature set point as a voltage from 0 to 5 V and that the 
output of the controller is a 0 to 10 V signal to the heater. Design a PID controller with a proportional gain 
of 3%/%, an integral gain of 10%/(% − min), and a derivative gain of 1%/(%/min) using 1000 μF capacitors.
The first step in the design is to determine the gain of the proportional, integral, and derivative con-
trollers. Equations 5.62 through 5.64 finds the gain for the three controllers by using the ratio of the per-
centage change of the output to the percentage change of the input multiplied by the gain.
	
K p =
=
3 0 01 10
0 01 5
6
( .
)(
)
( .
)( )
	
(5.62)
	
KI =
=
=
−
−
10 0 01 10
0 01 5
20
0 333
1
1
( .
)(
)
( .
)( )
.
min
s
	
(5.63)
	
KD =
=
=
10 01 10
0 01 5
2
120
( .
)(
)
( .
)( )
min
s
	
(5.64)
20
10
|H(jω)|, dB
Time, s
V, Vrms
Signal with noise
Bandpass filter
Filtered signal
0
–10 1
10
100
1,000 10,000100,000 1,000,000
Frequency, Hz
V, Vrms
Time, s
–20
–30
–40
–50
FIGURE 5.23  Communication signal before and after filtering (Sallen–Key).
Thermostat
set point
+–
Error
PID controller
Temperature sensor
and transducer
Heater
signal
FIGURE 5.24  Process control system.
© 2011 by Taylor and Francis Group, LLC

Application of Operational Amplifiers 
5-25
Since CD = CI = 1000 μF, RD and RI are found from the following formulas:
	
RI =
=
1
3
K C
I
I
kΩ
	
(5.65)
	
RD =
=
K
C
D
D
120kΩ
	
(5.66)
If we select R = RP1 = 1 kΩ, then RP2 can be found from
	
RP
p
2
1
6
=
=
K Rp
kΩ	
(5.67)
It is also possible to implement the PID controller with one op amp, and this is shown in Figure 5.26. 
This design would be more cost effective although it has the constraint that the controller gains are not 
decoupled, which may force the selection of nonstandard resistors or capacitors values.
RP1
RP2
–
+
–
+
–
+
CD
RD
R
R
R
CI
RI
Integral
Setpoint
error
–
+
Vo
Heater signal
R
Derivative
Proportional
FIGURE 5.25  PID controller.
R2
R1
–
+
C1
Vin
Setpoint
error
Vo
C2
Heater
signal
FIGURE 5.26  PID controller (one op amp).
© 2011 by Taylor and Francis Group, LLC

5-26 
Fundamentals of Industrial Electronics
The gains for the one op amp PID controller are
	
KP =
+
R
R
C
C
2
1
2
1 	
(5.68)
	
KI =
1
1 1
R C 	
(5.69)
	
KD = C R
1 2 	
(5.70)
By selecting C2 = 1000 μF, R1 = 3 kΩ, R2 = 17.6 kΩ, and C1 = 6.8 mF it is possible to meet the design con-
straints of the previous example.
Example 5.6:  Gyrator
The final example will use an op amp circuit to model an inductor or gyrator. Inductors can be very 
expensive to use in a design; therefore, if an engineer wishes to develop a circuit that produces a 5 H 
equivalent inductance using only 0.01 μF capacitors, resistors, and op amps, the solution to this problem 
is to use the gyrator circuit. The gyrator was shown in Table 5.1 and the equivalent inductance is repeated 
here in Equation 5.71.
	
L
CR R R
R
H
=
1 3 4
2
	
(5.71)
Solving equation for the resistances yields
	
500
1 3 4
2
M
R R R
R
=
	
(5.72)
By selecting R1 = R2 = 1 kΩ, the equation in (5.72) reduces to
	
500
3 4
M
R R
=
	
(5.73)
Finally, let R3 = 20 kΩ and R4 = 25 kΩ to satisfy the 5 H constraint. The final design for the gyrator is shown 
in Figure 5.27.
R1
R3
R2
R4
5 s
C
1 kΩ
1 kΩ
Vo
–
+
–
+
20 kΩ
0.01 μF
25 kΩ
FIGURE 5.27  Gyrator design.
© 2011 by Taylor and Francis Group, LLC

Application of Operational Amplifiers 
5-27
5.5  Realistic Op Amp Model
It should be noted that all of the designs in this chapter have assumed ideal op amps with the virtual 
short circuit and infinite input impedance assumptions. However, a more realistic model has a finite 
input impedance Ri, a finite open-loop gain G, and a nonzero output resistance Ro. The realistic op amp 
model is shown in Figure 5.28. Typical values for the input resistance, output resistance, and open-loop 
gain are 2 MΩ, 75 Ω, and 105, respectively.
5.5.1  Inverting Amplifier
How does the more realistic model of the op amp affect the analysis of the inverting amplifier in Figure 
5.4? The inverting amplifier with the more realistic model is shown in Figure 5.29. The KCL equations at 
the output and inverting terminals of this op amp are given in Equation 5.74.
	
KCL @
KCL @
V
V
V
R
V
V
R
V
R
V
V
V
R
V
G
V
R
n
n
i
n
o
n
i
o
o
n
o
n
o
:
:
(
)
−
+
−
+
=
−
+
−
−
=
1
2
2
0
0
	
(5.74)
Vp
Vn
ip
in
io
Ri
Ro
Vo
G(Vp– Vn)
+
+
–
–
FIGURE 5.28  Realistic op amp model.
R2
Ro
Vo
Ri
Vi
R1
–
Vin
–
–
–
+
+
+
+
3.3 kΩ
2.2 kΩ
G(Vp–Vn)
Ri= 2 MΩ
Ro= 75 Ω
G = 105
FIGURE 5.29  Inverting amplifier realistic model.
© 2011 by Taylor and Francis Group, LLC

5-28 
Fundamentals of Industrial Electronics
Note that there was not an equation at the output node for the ideal op amp analysis. Solving the set of 
equations in (5.74) yields
	
A = V
V
o
i
= −
+
+ +
+
+
+
G R R
R R
G
R R
R R
R R
R
o
i
i
o
o
(
/
)
(
/ )
(
(
/
))
(
/ )
(
/
)
(
/
2
1
2
1
2
1
1
Ri)
.



= −1 5
	
(5.75)
Since the gain for this model is the same as for the ideal model, it can be noted that as long as the input 
resistance and open-loop gain are relatively large and the output resistance is relatively small, the sim-
plifying assumptions are valid. However, the source resistance and load resistance have to be considered 
based upon realistic values of the input and output resistance.
5.5.2  Non-Inverting Amplifier
How does the more realistic model of the op amp affect the analysis of the non-inverting amplifier in 
Figure 5.5? The non-inverting amplifier with the more realistic model is shown in Figure 5.30.
	
KCL @
KCL @
V
V
R
V
V
R
V
V
R
V
V
V
R
G V
G V
V
R
n
n
n
o
n
i
i
o
o
n
o
i
n
o
:
:
(
)
1
2
2
0
+
−
+
−
=
−
+
−
−
= 0
	
(5.76)
Solving the KCL equations at the inverting terminal and output terminal yields the gain as
	
A
G
R R
R R
G
R R
R R
R R
o
i
i
o
= V
V
o
i
=
+
+
+ +
+
+
+
(
)
(
)
(
/
)
(
/
)
(
/
)
(
/
)
(
/
)
(
1
1
2
1
2
1
2
1
R
R
o
i
/
)
.



= 3 8
	
(5.77)
If the load resistor from Figure 5.5 is considered in the derivation, then the gain changes to
	
A
G
R
R
R
R
G
R R
R R
R R
o
i
i
o
=
= −
+
+
+ +
+
+
V
V
o
i
(
)
(
) (
(
/
)
(
/
)
(
/
)
(
/
)
(
/
)
1
1
2
1
2
1
2
1 +
+
+
+



=
(
/
)
(
/
)
(
/
)
(
/
)
.
) (
)
R R
R R
R R
R R
R R
R
R
y
o
i
o
i
L
o
L
o
L
2
2
1
3 8
	
(5.78)
Based upon a similar result, the same analysis conclusion found for the inverting amplifier holds here.
R2
Vo
Vin
Ri
Vi
R1
Ro
Ri= 2 MΩ
Ro= 75 Ω
G = 105
G (Vp –Vn)
5.6 kΩ
2.0 kΩ
–
–
–
–
+
+
+
+
FIGURE 5.30  Non-inverting amplifier realistic model.
© 2011 by Taylor and Francis Group, LLC

Application of Operational Amplifiers 
5-29
5.5.3  Input Offset Voltage
Unlike an ideal op amp, when the input voltage to the practical op amp is zero, the output is not zero. 
The input offset voltage is the differential input voltage that is needed to make the output zero when the 
input is zero. A typical value for the input offset voltage is 2 mV. The output when the input is zero is the 
output dc offset voltage. The way to compensate for this value in a realistic design is to add a small volt-
age source at the inverting or non-inverting amplifier of the opposite magnitude and polarity. It may be 
necessary to use a potentiometer with the op amp input set to zero to find the exact value to cancel out 
the input offset voltage.
5.5.4  Input Bias and Offset Currents
Unlike an ideal op amp, the current into the input terminals is not zero. This current value is typically 
2 μA. The bias current is the average of the current into the positive and negative input terminals. The 
input offset current is the difference between the input bias currents. The bias current has the most 
effect when the source impedance is large because it produces a large voltage. When the source imped-
ance is small, the bias current can be neglected. If the op amp is designed such that the DC resistance 
from the positive terminal to ground is the same as the DC resistance from the negative terminal to 
ground, then the effects of the input bias current are negligible. The way to create a design to resolve 
input bias currents is to select resistors to cancel out the output error. The smaller the resistor values, the 
smaller the error; however, there must be a tradeoff between resistor size and current and power require-
ments for the op amp. For design considerations, in order to cancel out input bias current, you could 
select the input resistance on the non-inverting terminal to be equivalent to the parallel combination 
of the feedback resistance(s) and input resistance(s) on the inverting input. In order to resolve the input 
offset current, you can follow a similar procedure to the input offset voltage and use a voltage source and 
potentiometer to cancel out the effects on the output.
5.5.5  Frequency Response
As previously stated, the GBP is a constant that determines the limitations of the op amps performance 
for a certain gain at a certain frequency. This constant must be considered when designing a filter to 
insure that the closed-loop gain is within the proper range for the given frequency.
5.5.6  Slew Rate
Another characteristic of a practical op amp is that it exhibits slew rate limiting. This means that the 
output due to a step input is not a perfect step function. This is due to the fact that the response is fre-
quency dependent as described in the prior section. Slewing happens when the input voltage to the op 
amp is so large that it causes it to saturate and the output curve cannot rise fast enough.
5.6  Conclusion
This chapter has presented a general introduction to the design of op amps including ideal assumptions, 
practical considerations, analysis, applications, and a more realistic model. Further study is encouraged 
in the component circuitry that make up the op amp IC. The basic building block of this circuitry is the 
differential amplifier. This study will also introduce a more in depth discussion of topics such as com-
mon mode and differential mode gains, level shifters, power supply rejection ratio, balanced inputs and 
outputs, and coupling between multiple inputs.
Additionally, there are many other op amp applications such as power audio op amps, bridge oscil-
lators, Chebyshev filters, and nonlinear circuits. There are also feedback limiter configurations that 
© 2011 by Taylor and Francis Group, LLC

5-30 
Fundamentals of Industrial Electronics
constrain a signal to be above or below a specific breakpoint. Op amps can also be used as comparators 
to determine which of the two voltages is larger. The next phase in comparators are Schmitt triggers, 
which provide feedback for steeper and more rapid transitions where the saturation states are held until 
a certain input is reached. It is also possible to design digital-to-analog and analog-to-digital converters 
using op amps. Table 5.1 presents a summary of some of these op amp configurations.
Bibliography
C.D. Johnson, Process Control and Instrumentation Technology, 8th edition, Upper Saddle River, NJ: 
Prentice Hall, 2006, 704 pp.
J.W. Nilsson and S.E. Riedel, Electric Circuits, 8th edition, Upper Saddle River , NJ: Prentice Hall, 2007, 
880 pp.
M.N.O. Sadiku and C.K. Alexander, Fundamentals of Electric Circuits, 3rd edition, New York: McGraw-
Hill, 2007, 901 pp.
© 2011 by Taylor and Francis Group, LLC

6-1
6.1  Introduction
The response of a system to an input can be characterized in a variety of formats. Most commonly, the 
response is given in either the time domain, by the impulse response, or in the frequency domain, by 
the frequency response. Of interest here is the frequency response, a measure of the relationship of a 
system’s output to a sinusoidal input as a function of the input frequency. While most commonly applied 
to electronic/electrical systems, frequency-response techniques are often used in mechanical, as well as 
biological, systems.
Frequency-response characteristics can commonly be found in the consumer market with respect 
to audio equipment, in particular, audio amplifiers, loudspeakers, and microphones. Radio-frequency 
response can refer to a variety of items such as amplifiers, receivers and transmitters, antennas, coaxial 
cables, video switchers, etc. Subsonic frequency-response characterizations can include earthquakes 
and brain waves.
Frequency-response techniques are most valuable when dealing with linear, time-invariant systems, 
where a sinusoidal input produces a sinusoidal output of the same frequency, where the response to a 
sum of inputs is the sum of the individual responses to each input, and where the response of the system 
does not depend on when the input was applied. Practically, a small amount of variation is allowed in 
these system constraints and is typically treated as distortion.
6.2  Theoretical Relationships
Linear, time-invariant systems can be characterized by the impulse response or the frequency response. 
These two response characterizations are directly related.
In the time domain, the response, xo(t), of such a system to an arbitrary input, xi(t), can be character-
ized, by a convolution of the input, xi(t) with the system-impulse response, h(t):
	
x t
h t
x
o
i
t
( )
(
) ( )
.
=
−
∫
τ
τ
τ
0
d
6
Frequency Response 
and Bode Diagrams
6.1	
Introduction.......................................................................................6-1
6.2	
Theoretical Relationships.................................................................6-1
6.3	
Measurement of the Frequency Response.....................................6-2
6.4	
Displaying the Frequency Response—The Bode Diagram..........6-3
Mathematical Derivations  •  Bode Plots of the Factors  •  Time 
Delay  •  Temporal Frequency versus Angular Frequency
References.....................................................................................................6-20
Thomas F. 
Schubert, Jr.
University of San Diego
Ernest M. Kim
University of San Diego
© 2011 by Taylor and Francis Group, LLC

6-2 
Fundamentals of Industrial Electronics
While this representation is useful in many situations, a frequency-domain representation of the 
system characteristics is also typical and highly useful. The frequency-domain spectrum of a system, 
Xo(ω), can be derived from the impulse response expression by performing the Fourier transform 
on the output, xo(t),
	
X
t
x t
o
o
o
j t
( )
{
( )}
( )
ω
ω
=
=
−∞
∞
−
∫
x
t
e
d
This operation reduces to the frequency-domain relationship,
	
X
H
X
o
i
( )
( )
( ).
ω
ω
ω
=
Simply stated, the spectrum of the output, Xo(ω), is the product of the input spectrum, Xi(ω), and the 
­frequency-domain transfer function of the system, H(ω). The impulse response and the frequency-
domain transfer function of a system are related by the Fourier transform,
	
H
h t
( )
{ ( )}.
ω = F
H(ω) is usually represented by its fundamental parts in polar form:
•	 |H(ω)|—the magnitude response
•		 ∠H(ω)—the phase response
6.3  Measurement of the Frequency Response
The frequency response of a system can be determined by measurements either in the time domain or in 
the frequency domain. Time-domain measurements will result in the system-impulse response, which 
is then transformed to the frequency response through the Fourier transform. Time-domain measure-
ments are obtained by either:
•	 Applying an impulse to the system and measuring its response, h(t), or
•	 Applying a signal with a wide frequency spectrum (e.g., digitally generated maximum length sequence 
noise, a step function, or analog-filtered white noise equivalent, like pink noise), and calculating the 
impulse response by a deconvolution of this input signal and the output signal of the system.
Frequency-domain measurements are more direct and consist of
•	 Sweeping a constant-amplitude pure sinusoid through the frequency range of interest and mea-
suring the output level and phase shift relative to the input.
While various devices exist for obtaining H(ω) automatically, manual determination is common. Such 
a determination requires two basic pieces of equipment:
•	 A source with sinusoidal output of variable frequency
•	 A device capable of measuring and/or displaying both amplitude and phase shift
An oscilloscope often serves well as the measurement device in electronic applications. A typical oscil-
loscope display of the input and output signals for a system under test is shown in Figure 6.1. At this 
particular frequency (f ), the magnitude of the system response is given by
	
H f
V
V
( ) =
2
1
© 2011 by Taylor and Francis Group, LLC

Frequency Response and Bode Diagrams 
6-3
The phase shift (in degrees) is determined as
	
θ =
°
(
) =
°
(
)
∆
∆
t
T
f
t
360
360
,
where
T is the period of the sinusoidal voltage
Δt is the delay time between the input (V1) wave, as reference, and the output (V2) wave as observed 
on the oscilloscope
Phase is positive if the output (V2) wave is to the left of (leads) the input V1 wave and is negative if V2 lags 
behind the V1 wave. Assuming the two signals shown in Figure 6.1 are on the same scale, the magnitude of 
system response at this frequency is approximately 3.6 (11.13 dB) and the phase shift is approximately −70° 
(−1.22 rad).
Measurements are typically performed in three stages: a broad frequency scan (often only one mea-
surement in each frequency decade) to determine the general frequency range of interest, a systematic 
frequency scan (often at as few as three frequencies in each decade) to determine the general shape of 
the response, and a focused frequency scan near points of interest. For the systematic frequency scan, 
multipliers of 1, 2, and 5 divide each frequency decade into approximately equal thirds and are easily 
located on a logarithmic grid.
In a noisy environment, automated measurement devices may give spurious estimations of ampli-
tude and phase. For example, for the signals shown in Figure 6.2, a peak-to-peak detector will output a 
value approximately 18% larger than the proper value for the noisy signal shown. All attempts must be 
made to visually filter out the noise in parameter estimation. For the signals shown, the gain is approxi-
mately 0.50 (−3.0 dB) and the phase shift about +150° (+2.6 rad).
6.4  Displaying the Frequency Response—The Bode Diagram
In the late 1930s, Hendrik Wade Bode (1905–1982) pioneered presenting the two fundamental 
response quantities, |H(ω)| and ∠H(ω), as a pair of plots [1]. The typical format for these plots is the 
magnitude (typically on a decibel scale, but occasionally on a linear scale) or the phase (in either radi-
ans or degrees) as the ordinate and frequency (on a logarithmic scale) as the abscissa. Each of these 
two plots is identified as a Bode plot in commemoration of Bode’s early work. The two plots together 
T
Δt
V1
V2
FIGURE 6.1  Gain and phase shift measurement.
© 2011 by Taylor and Francis Group, LLC

6-4 
Fundamentals of Industrial Electronics
form a Bode diagram. Originally used in the design of feedback amplifiers, magnitude, and phase 
plots, Bode diagrams have provided engineers with an intuitive tool useful in the design and analysis 
of a large variety of systems. In particular, Bode’s introduction of the concepts of gain margin and 
phase margin, each easily interpreted on a Bode plot, provided engineers with an especially valuable 
viewpoint in the investigation of the stability of systems [2,3].
While many computer simulation programs exist for the efficient creation of such plots directly from 
the frequency-response equations of the system, much insight into the functioning of a system (or any 
electronic circuit) and the dependence of the responses to individual system parameter variation can 
be gained by the manual creation of simple straight-line asymptotic magnitude and approximate phase 
plots. Similarly, a good approximation to system response can be generated by fitting straight-line plots 
to experimental or simulation data.
6.4.1  Mathematical Derivations
The response of a linear, time-invariant system to a sinusoidal input of varying frequency can, in most 
cases, be described as the ratio of two polynomials in frequency ω,*
	
H
K Z
P
m
n
( )
( )
( ) .
ω
ω
ω
=
0
	
(6.1)
Here, Zm(ω) is an mth-order polynomial whose roots identify the m zeroes of the response. The roots of 
the nth-order polynomial, Pn(ω), identify the n poles. For all real systems, the response must not become 
infinite as frequency approaches infinity; thus, there must be at least as many poles as zeroes, n ≥ m. 
Equation 6.1 can be rewritten in the format
	
H
K
j
a
j
a
j
a
j
b
j
b
j
b
m
m
n
( )
(
)
(
)
(
)
(
)
(
)
(
)
ω
ω
ω
ω
ω
ω
ω
=
+
+
+
+
+
+
+
+
0
1
2
2
1
2
2
1
1


n 	
*	 Many sources prefer to express the system response in Laplace domain, H(s). In the case of sinusoidal frequency 
response, H(s) reduces to H(jω) by replacing s with jω. Similarly, frequency can be expressed as either angular frequency, 
ω (in rad/s), or temporal frequency, f (in Hz), without any loss of generality.
V2
V1
Δt
FIGURE 6.2  Gain and phase shift measurement: noisy output signal.
© 2011 by Taylor and Francis Group, LLC

Frequency Response and Bode Diagrams 
6-5
The numerator and denominator polynomials, Zm(ω) and Pn(ω) respectively, can each be written as a 
factored product of multiples of four types of simple function, identified as the factors, { ( )}:
F ω
	
1.	 K—a constant
	
2.	 jω—a root at the origin
	
3.	1+ jω
ωo  
— a simple root at ω = ωo
	
4.	1
2
+
+ 



2
o
o
ζ ω
ω
ω
ω
j
j
—a complex conjugate root pair
Each of these four factors has a straight-line approximate Bode representation. The use of decibels 
(a logarithmic function) as the vertical scale for the magnitude plot and a linear vertical scale for phase 
converts the product of the factors into the sum of the factor magnitudes (in dB) and the sum of the 
factor phases: division becomes subtraction. Therefore, the total system response plot is obtained by 
algebraically summing the plots of the individual simple factors describing the system.
6.4.2  Bode Plots of the Factors
The Bode magnitude straight-line representation of each of the four simple factors is unique. The Bode 
phase straight-line representation is unique for two of the factors (a constant and a root at the origin) 
and universally standardized for a third (a simple root). However, a variety of approximate representa-
tions for the phase of a complex conjugate root pair exists in the literature [4–7]. The representation for 
a constant and for a root at the origin is exact: the other two factor representations are asymptotic in the 
case of magnitude, and approximate in the case of phase. The straight-line representation of each Bode 
factor follows; a summary can be found in Table 6.1.
6.4.2.1  Constant
A constant is the most simple of the factors:
	
FC( )
.
ω = K
The magnitude plot is constant at 20 log |K| if the factor is in the numerator, or −20 log |K| if in the 
denominator. The phase plot is also constant at θ = 0° or at θ = ±180° depending on the mathematical 
sign of K. Each plot is an exact representation of the factor.
6.4.2.2  Root at the Origin
Roots at the origin:
	
F
j
0( )
,
ω
ω
=
also have a simple, exact, Bode representation. The magnitude plot is a straight line with a slope 
of ±20 dB/decade*:
	
|
( )|
log |
|
log( )
F
j
0
20
20
ω
ω
ω
dB=
=
If the root is in the numerator (indicating a zero), the line has positive slope. Denominator roots (poles) 
have negative slope. In each case, the line passes through the point {0 dB, 1 rad/s}.
*	 A decade is a change in frequency by a factor of 10. A slope of 20 dB/decade is also identified in some sources as 6 dB/
octave (actually ≈ 6.0206 dB/octave), where “octave” is derived from the eight-tone musical scale and is a frequency 
change by a factor of 2.
© 2011 by Taylor and Francis Group, LLC

6-6 
Fundamentals of Industrial Electronics
The phase of a root at the origin is constant at θ = 90°. Consequently, the phase plot for a zero will be 
at +90° and at −90° for a pole.
6.4.2.3  Simple Root at ω = ωo
Simple roots not at the origin have more complex plots. The factor for a simple root is
	
F
j
1
o
o
,
1
(
)
,
ω ω
ω
ω
= +
where ωo is the frequency of the root. The magnitude of the factor (in dB) is given by
	
F1
o
dB
o
2
o
2
,
20
1+
10
1+
(
)
log
log
.
ω ω
ω
ω
ω
ω
=




=










The factor phase is given by
	
∠
=




−
F1
1
(
)
tan
ω ω
ω
ω
,
o
o
These two components of the factor are shown in Figure 6.3. Also shown in the figure are the standard 
Bode straight-line approximations. A factor in the denominator (representing a pole) will have plots that 
are the vertical mirror image of a factor in the numerator (representing a zero).
TABLE 6.1  Bode Factor Magnitude and Phase Plots
Factor
Bode Magnitude Plot
Bode Phase Plot
FC=K0
F0(ω)= jω
F1(ω, ωo)=1+ jω
ωo
F2(ω, ωo, ζ)= 
ω
0 dB
20 log (K0)
1
ω
0 dB
20 dB/decade
0 dB
20 dB/decade
ωo
ω
0 dB
ω
ωo
40 dB/
decade
0°
0°
0°
0°
ω
90°
ω
45°/decade
10
90°
ω
ω
0.1 ωo
ωo
10 ωo
180°
(90°/ζ)/
decade
10−ζωo
10ζωo
ωo
1+2ζ
+
jω
ωo
jω
ωo
Note:	 Factors are in the numerator, representing zeroes.
© 2011 by Taylor and Francis Group, LLC

Frequency Response and Bode Diagrams 
6-7
The Bode approximate plot of the magnitude is an asymptotic approximation and comprises two 
intersecting straight lines that form a piecewise continuous plot. If ω ≪ ωo, F1(ω, ωo) ≈ 1 and the mag-
nitude plot is asymptotically constant at 0 dB. If ω ≫ ωo,
	
F1
o
dB
o
2
o
,
0
20
20
(
)
log
log( )
log(
)
ω ω
ω
ω
ω
ω
≈









=
−
1
This asymptote is a straight line with a slope of 20 dB/decade that intersects the 0 dB line at the root 
frequency, ω = ωo. The Bode approximation transitions between the two asymptotic lines at the root fre-
quency, where the approximation has its greatest error (20 log(2) ≈ 3.01 dB).
As can be seen in Figure 6.3, the simple root phase never exceeds 90° and essentially all phase change 
takes place within ± one decade of the root frequency, ωo(∠F1(0.1ωo, ωo) = 5.71° and ∠F1(10ωo, ωo) = 
84.29°). The universally adopted Bode phase approximation is a continuous, three-segment, straight-
line plot that uses ± one decade as the transition points between segments. Beyond one decade from the 
root, ωo, the phase is approximated by a constant:
	
ω
ω
ω ω
<
⇒∠
= °
0 1
0
1
.
( ,
)
 
o
o
F
	
ω
ω
ω ω
>
⇒∠
=
°
10
90
1
 
o
o
F ( ,
)
Within one decade of ωo, the phase is approximated by a straight line of slope 45°/decade:
	
0 1
10
45
10
1
.
( ,
)
[log(
/
)]
ω
ω
ω
ω ω
ω ω
o
o
o
o
 
≤
≤
⇒∠
=
°
F
This straight-line Bode approximation has a maximum error of ∼5.71°.
The error introduced by the Bode straight-line approximations has distinct symmetry about ωo 
(Figure 6.4). Any corrections to the plots, if necessary, are accomplished by interpolation and compari-
son to standard plots. Some data points that are helpful in making accurate corrections are
0
5
10
15
20
25
30
35
40
–15
0
15
30
45
60
75
90
105
Magnitude 
Phase 
Approximate
phase
Approximate
magnitude
ωF1(ω, ωo) (deg)
|F1(ω, ωo)| (dB)
100 ωo
10 ωo
0.1 ωo
0.01 ωo
ωo
FIGURE 6.3  Simple root factor plots.
© 2011 by Taylor and Francis Group, LLC

6-8 
Fundamentals of Industrial Electronics
Magnitude plot
•	 The magnitude error at ωo is 3.01 dB
•	 The magnitude error at ± one octave (0.5ωo and 2ωo) is 0.97 dB
Phase plot
•	 Slope at ωo is ≈ 66°/decade
•	 The phase error is zero at 0.159ωo, ωo, and 6.31ωo
•	 The phase error at ± one decade is ±5.71°
6.4.2.4  Complex Conjugate Root Pair
Complex conjugate root pairs,
	
F
j
j
2
2
1
2
(
)
,
ω ω ζ
ζ ω
ω
ω
ω
,
,
o
o
o
= +
+ 



have a more complex relationship. Again, ωo is identified as the resonant frequency; ζ is identified as the 
damping factor.* A plot of the magnitude and phase of this factor with the damping factor as a param-
eter (0.2 ≤ ζ ≤ 0.9 in increments of 0.1) is shown in Figure 6.5. The Bode plots for a complex conjugate 
pair of poles will take the same shapes but will be vertical mirror images.
The variation of the plot with damping coefficient interferes with the accuracy of two-segment, 
straight-line magnitude approximations near the resonant frequency. Beyond half of a decade from the 
resonant frequency, asymptotic approximations of the magnitude plot have a high degree of validity. 
If ω ≪ ωo, F2(ω, ωo, ζ) ≈ 1; the asymptotic magnitude plot is constant at 0 dB. If ω ≫ ωo,
	
F
j
2
o
dB
0
o
,
,
40
40
(
)
log
log( )
log(
).
ω ω ζ
ω
ω
ω
ω
≈




=
−
20
2
In this region, the asymptotic magnitude plot is a line with a slope of 40 dB/decade and intersects to 
other asymptote at the resonant frequency, ω = ωo (as was the case for a simple root). Near the resonant 
*	 The damping factor lies in the range, 0 ≤ ζ < 1, for complex conjugate root pairs.
–4
–3
–2
–1
0
1
2
–6
–4
–2
0
2
4
6
ωo
100 ωo
0.1 ωo
10 ωo
0.01 ωo
Magnitude error (dB)
Phase error (deg) 
Magnitude error 
Phase error 
FIGURE 6.4  Bode straight-line errors: simple root.
© 2011 by Taylor and Francis Group, LLC

Frequency Response and Bode Diagrams 
6-9
frequency, there can be a large difference between the approximate Bode magnitude plot and the 
true magnitude plot. Depending on the application, corrections to the curve may be necessary. These 
­corrections can usually be accomplished with the addition of only a few data points and interpolation. 
Two helpful data points are the magnitude at the resonant frequency and the magnitude of the peak in 
the curve (if one exists). The magnitude at the resonant frequency is given by
	
F2
o
o
dB
,
,
log(
(
)
).
ω
ω
ζ
ζ
= 20
2
For damping coefficients less than 1
2
/
, a valley occurs in the magnitude of the factor. This valley will 
occur at the maximum difference between the true magnitude plot and the Bode straight-line approxi-
mation (Figure 6.6). Interestingly, this valley in the factor magnitude plot is usually encountered with 
the factor in the denominator and is consequently identified in the literature as a “peak.” If only the fac-
tor is considered, the valley (peak) occurs at a frequency somewhat lower than the resonant frequency:
	
ω
ω
ζ
peak
.
=
−
o
2
1
2
The magnitude of this valley (peak) is
	
F2
peak
o
dB
2
,
2
1
(
,
)
log
.
ω
ω
ζ
ζ
ζ
=
−
(
)
20
In cases where a complex conjugate pair of poles (or zeroes) cancels lower-frequency zeroes (or poles) so 
that the asymptotic plot is a constant for frequencies higher than the resonant frequency (see Example 6.3), 
the peak (valley), necessarily of the same magnitude, occurs at a frequency somewhat higher than the 
resonant frequency:
	
ω
ω
ζ
peak
.
=
−
o
2
1
2
0
20
40
60
80
100
120
140
160
180
F1(ω, ωo, ζ) (deg)
ωo
0.1 ωo
10 ωo
ζ=0.4 
ζ=0.2 
ζ=0.6 
ζ=0.8 
(b)
–10
–5
0
5
10
15
20
25
30
35
40
|F1(ω, ωo, ζ)| (dB)
ωo
0.1 ωo
10 ωo
ζ=0.2 
ζ=0.4 
ζ=0.6 
ζ=0.8 
(a)
FIGURE 6.5  Complex conjugate root factor plots: (a) magnitude and (b) phase.
© 2011 by Taylor and Francis Group, LLC

6-10 
Fundamentals of Industrial Electronics
The Bode phase plot for a complex root pair is also simplified into a three-segment, straight-line plot. 
However, the damping coefficient complicates the location of the transition between segments. At fre-
quencies much lower than the resonant frequency, the phase is near constant at 0°; at frequencies much 
higher than ωo, the phase is near constant at 180°. Near ωo the Bode approximate curve is a straight line 
joining the other segments.
The location of the transition points between the segments of the approximate Bode phase plot is not uni-
formly described in the literature; a ζ-independent approximation [4,5] and at least two approximations that 
depend on the value of ζ are to be found. The ζ-independent approximation chooses transition points at ± one 
decade, while the most prevalent of the ζ-dependent approximations vary the transition points (as a fraction 
of a decade) linearly with damping coefficient, ζ. Each approximation has its strong features. For example, 
the tangent-of-phase approximation [6] is useful in that it identifies the slope of the phase plot, mphase, at the 
resonant frequency, ωo, as
	
mphase
decade
= 






≈
≈
°
180
10
131 928
132
π
ln(
)
.
/
.
ζ
ζ
ζ
However, it has been shown that the decade-fraction approximation [7] more closely approximates the 
phase plot variation with damping coefficient under a variety of criteria [8].
The decade-fraction approximation identifies the transition frequencies as lying ±ζ decades from the 
resonant frequency. The constant phase regions are a function of ζ and are described as
	
ω
ω
ω ω
ζ
ζ
<
⇒∠
= °
−
o
2
o
10
,
,
F (
)
0
	
ω
ω
ω ω
ζ
ζ
>
⇒∠
=
°
o
2
o
10
,
,
F (
)
180
–6
–3
0
3
6
9
ωo
0.1 ωo
10 ωo
Magnitude error (dB)
Peaks 
ζ=0.2 
ζ=0.4 
ζ=0.6 
ζ=0.8 
FIGURE 6.6  Bode straight-line magnitude error: complex conjugate root pair.
© 2011 by Taylor and Francis Group, LLC

Frequency Response and Bode Diagrams 
6-11
The phase between the two constant phase regions is approximated by a straight line of slope (90/ζ)°/
decade passing through the point ωo, 90°:
	
ω
ω
ω
ω ω
ζ
ζ
ω
ω
ζ
ζ
o
o
2
o
o
10
10
,
,
−≤
≤
⇒∠
=
°







+
°
F (
)
log
90
90

As was the case in first-order factors, the error introduced by the Bode straight-line approximations has 
distinct symmetry about ωo. Any corrections to the plots, if necessary, are accomplished by interpola-
tion and comparison to standard plots. Some data points that are helpful in making accurate corrections 
to the phase plot are
•	 Phase plot slope at ωo is ≈ 132/ζ °/decade
•	 The phase error goes to zero at
•	 ω = ωo
•	 ω
ζ
ζ
=
±
+
10
0 3
0 49
2
( .
.
)
+0.01
The magnitude of the phase error at the transition points (ω = ωo10±ζ) is
•	 ≈ −15.8ζ + 27.2  for ζ ≥ 0.4
•	 = 10ζ3 − 22.8ζ2 − 0.7ζ + 23.5  (all values of ζ)
The decade-fraction ζ-dependent Bode phase approximation is shown in Figure 6.7 for two values of ζ along 
with the actual phase plots. Helpful data points, as identified above are marked with a “+” sign.
6.4.3  Time Delay
Systems with an inherent time delay, td, will experience a fifth factor, a phase shift that is linear with 
frequency
	
F
j t
D
e
d
( )
.
ω
ω
=
−
The delay factor has a Bode magnitude plot that is constant at 0 dB; the system Bode magnitude plot is 
unchanged by the factor. Unfortunately, the phase is linear with frequency {ϕ = −tdω} and does not have 
ωo
100 ωo
0.1 ωo
0.01 ωo
10 ωo
180
90
0
Phase (deg)
Helpful data points 
ζ= 0.4 
ζ=0.8  
FIGURE 6.7  The decade-fraction ζ-dependent Bode phase approximation.
© 2011 by Taylor and Francis Group, LLC

6-12 
Fundamentals of Industrial Electronics
a “nice” plot on a logarithmic frequency scale; each decade in frequency experiences ten times the phase 
variation of the decade directly lower in frequency. Typically, any system delay is treated separately from 
the Bode phase plots; in systems where the time delay is small compared to the period of the highest 
frequency present, delay effects are usually considered insignificant and, consequently, ignored. A Bode 
diagram of the delay factor is shown in Figure 6.8.
6.4.4  Temporal Frequency versus Angular Frequency
Theoretical derivations of Bode factors tend to utilize angular frequency (ω: rad/s). However, in the real 
world, it is likely that systems will be described using temporal frequency (f: Hz).
The functional form of the response, H(ω) or H(f), is identical and conversions can be made using ω = 2πf. 
The only other difference appears in a difference in the constant factor FC for a particular system. If there are 
simple roots at the origin (F0 = jω), the constant terms in H(ω) and H(f) for the system {Kω and Kf, respec-
tively} will differ by a factor
	
K
K
m n
f =(2 )
π
ω
−
where m–n is the number of simple roots at the origin in the numerator minus those in the denominator.
Example 6.1:  Drawing Bode Plots
Draw the Bode diagram for the following transfer function:
	
H
j
j
j
j
( )
[
][
]
[
(
/
)][
(
/
][
(
/
ω
×
ω
ω
ω
ω
×
=
1.7 10
1
) 1
500 10
3
2
3
−
+
+
+
1
120
700
)
((
) /
)]
+
jω
×
2
9
160 10
Solution
The Bode diagram consists of the Bode magnitude plot and the Bode phase plot. The given transfer 
function contains all of the primary factor types:
•	
A constant
•	
Two zeroes at the origin
•	
Two simple poles
•	
A complex conjugate pair of poles
0.01
0.1
1
10
100–420
–360
–300
–240
–180
–120
–60
0
60
Normalized frequency
Gain (dB)
Phase (deg)
ωtd 
0
Phase 
Gain 
FIGURE 6.8  Time delay factor Bode diagram.
© 2011 by Taylor and Francis Group, LLC

Frequency Response and Bode Diagrams 
6-13
The Bode magnitude plot for the constant is a horizontal line at
	
20
55 39
log[
]
.
1.7 10
dB
3
×
−
= −
The Bode magnitude plot for the two zeroes at the origin has a slope of +40 dB/decade (2 × 20 dB/
decade) and passes through (0 dB, 1 rad/s).
The simple poles each introduce a slope increment of −20 dB/decade beginning at the pole 
frequencies
	
ω
ω
p1
p2
rad/s
and
00rad/s
=
=
120
7
The complex pair of poles will introduce a slope increment of −40 dB/decade at the resonant frequency
	
ω
×
ω
×
o
2
9
o
3
10
00 10 rad/s
=
⇒
=
160
4
The pole pair damping coefficient is calculated to be
	
2
500 10
o
3
ζ
ω
×
ζ
=
⇒
=
1
0 4.
The magnitude at the resonant frequency can then be (optionally) corrected by determining
	
F2
0 4
2
0 4
0 8
1 94
(
, . )
.
.
.
ω
ω
×
o
o
,
dB
=
=
⇒
−
Since the damping coefficient is less than 1/ 2  and the factor cancels out lower-frequency zeroes, a peak 
in the magnitude response exists above the resonant frequency at
	
ω
ω
ζ
×
×
peak
(
)
.
.
=
−
=
=
o
2
3
2
00 10 0.825
rad/s
1
4
329 9 103
Consequently, the other optional correction point has value
	
F2
peak,
, 0.4
dB
(
)
( . )
.
.
.
ω
ω0
2
2 0 4
1 0 4
0 733
2 79
=
−
=
⇒
−
Since the complex conjugate pair are poles, the factor lies in the denominator, the slope is −40 dB/decade, 
and the signs of the magnitude corrections are reversed (making them both, in this case, positive).
The magnitude plot is constructed as follows:
•	
A low-frequency starting point is found, where the sum of all factors is known and below any pole 
(or zero) frequencies (other than those at the origin). Here ω = 10 is a good choice (evaluate the 
constant and the zeroes at the origin):
	
| (
)|
.
.
H 10
55 39
20
20
15 39
≈−
+
+
= −
 dB
 dB
 dB.
© 2011 by Taylor and Francis Group, LLC

6-14 
Fundamentals of Industrial Electronics
•	
The slope of the plot at the above point is 20 dB/decade × (number of poles at origin), i.e., 40 dB/
decade.
•	
The pole and zero frequencies are located and marked: simple poles (down) and zeroes (up) by an 
arrow. Similarly, complex conjugate pairs are marked by a double arrow.
•	
The plot slope is incremented at the arrow frequencies by 20 dB/decade in the direction of the 
arrow. Multiple arrows at the same frequency indicate a multiplicative change in slope.
•	
Any higher-order corrections are then made (if desired).
The resultant uncorrected Bode straight-line magnitude plot, four optional correction points (marked 
by “+”), and the exact magnitude plot for this system are shown in Figure 6.9.
The Bode phase plot for the constant and each of the zeroes at the origin are simple horizontal lines 
at 0° and 90°, respectively. Each simple pole will increment the phase by −45°/decade at one decade 
below the pole frequency and decrement the phase by the same quantity one decade above the pole 
frequency. For the complex conjugate pair phase plot, the frequency range where the phase changes 
must be calculated by determining the quantity
	
10
10
2 51
0 4
ζ =
=
.
.
The transition frequencies for the phase change are then determined:
	
ω
ω
ω
ω
o
o
2.51<
<
⇒
×
<
<
×
2 51
120 10
750 10
3
3
.
Since the factor is in the denominator, the phase plot between the transition frequencies has a slope 
increment of
	
−
= −
90
225
ζ
°/decade
–15
–10
–5
0
5
10
15
20
25
30
35
40
45
50
Magnitude (dB)
Frequency (rad/s) 
10 
Simple root (–3 dB) 
Peak (+2.79 dB) 
Resonance (+1.94 dB) 
20 dB/decade slope
increment arrows  
10 M 
100 k 
1k 
FIGURE 6.9  Magnitude of the frequency response for Example 6.1 with the Bode approximation overlay.
© 2011 by Taylor and Francis Group, LLC

Frequency Response and Bode Diagrams 
6-15
The phase plot is constructed as follows:
•	
A low-frequency starting point is found where the sum of all factors is known and at least one 
decade below any pole (or zero) frequencies (other than those at the origin); here ω = 0.1 is a good 
choice: ∠H(0.1) ≈ 0° + 90° + 90° − 0° − 0° − 0° = 180°.
•	
The phase-plot transition frequencies are located and marked: simple poles and zeroes by 
opposing arrow pairs at one tenth and ten times the pole or zero frequency (12 and 1200; 70 
and 7000); complex conjugate root pairs by opposing arrow pairs at the calculated slope transi-
tion frequencies (120 × 103 and 750 × 103).
•	
The phase-plot slope is changed at the arrow frequencies by the appropriate amount in the 
­direction of the arrow.
•	
Any higher-order corrections are then made (if desired).
The system uncorrected Bode straight-line approximate phase plot and the exact phase plot are 
shown in Figure 6.10. Six optional correction points (marked by “+”) are also shown. Note that while 
these optional correction points improve the curve in regions where roots are far apart, in regions 
where the root transition regions overlap (i.e., at 70 and 1200 rad/s), their usage may not improve the 
overall curve.
Example 6.2:  Drawing Bode Plots—Alternate Method
Draw the Bode diagram for the following transfer function:
	
H
j
j
j
j
( )
[
]
[
(
/
)][
(
/
)][
(
ω
ω
ω
ω
ω /
= 1
1
1
2
−
×
+
+
+
×
−
625 10
160
1000
200 10
6
3)][
(
/
)]
1+
×
jω 900 103
–180
–135
–90
–45
0
45
90
135
180
45°
45°
45°
45°
225°
225°
Slope (°/decade)
increment arrows  
Simple root (±5.7°) 
Root pair ζ= 0.4 (±20.1°)  
Phase (deg)
Frequency (rad/s) 
10
1 k
100 k
1 M
FIGURE 6.10  Phase of the frequency response for Example 6.1 with the Bode approximation overlay.
© 2011 by Taylor and Francis Group, LLC

6-16 
Fundamentals of Industrial Electronics
Solution
The Bode diagram consists of the Bode magnitude plot and the Bode phase plot. The given transfer 
function contains three of the primary factor types:
•	
A constant
•	
Two zeroes at the origin
•	
Four simple poles
•	
Two at low frequencies (160 and 1000 rad/s)
•	
Two at high frequencies (200 and 900 krad/s)
This particular form of the transfer function is quite common in electronic applications. Low-frequency 
poles (in this case, two) are canceled by the same number of zeroes at the origin resulting in a mid-
dle range of frequencies (the midband region) where the transfer function is essentially constant, and 
regions of decreasing gain as frequency varies from the midband region for both higher and lower fre-
quencies. Similarly, the phase is relatively constant in the midband region. In such a situation, the Bode 
plot can be begun in the midband region and can progress outward. One should note that this method 
is not dependent on the poles being simple; the presence of complex conjugate pole pairs does not 
change the method described as long as there is a midband region of essentially constant gain or phase.
The value of the transfer function in the midband region can be determined by assuming a midband 
frequency, ωmid, that is conceptually much larger than the largest of the low-frequency poles, but much 
smaller than the smallest of the high-frequency poles. Under that assumption, the pole factors take on a 
simpler form and result in an approximate transfer function value in the midband region:
	
H
j
j
j
(
)
[
]
(
/
) (
/
) [ ][ ]
ω
ω
ω
ω
mid
mid
2
mid
mid
≈
−
×
[
][
]
−
625 10
160
1000
1 1
6
= −100
The Bode magnitude plot for this example in the midband region becomes a horizontal line at
	
20 log | 100| = 40 dB.
−
The magnitude plot is constructed as follows:
•	
The plot begins in the midband region with a horizontal line at the midband gain value; here, 40 dB.
•	
The pole and zero frequencies are located and marked: simple poles (down) and zeroes (up) by an 
arrow. Similarly, complex conjugate pairs are marked by a double arrow.
•	
The plot slope is incremented at the arrow frequencies by 20 dB/decade in the direction of the 
arrow. Multiple arrows at the same frequency indicate a multiplicative change in slope.
•	
Any higher-order corrections are then made (if desired).
The resultant uncorrected Bode straight-line magnitude plot and the exact magnitude plot for this 
­system are shown in Figure 6.11.
The Bode phase plot can be similarly constructed from the midband outward. The phase plot is 
constructed as follows:
•	
The plot begins in the midband with a horizontal line at the midband phase value; here, ∠H(ωmid) ≈ 
∠(−100) = ±180°.
	
Since poles introduce negative angles, −180° is more commonly chosen.
•	
The phase-plot transition frequencies are located and marked: simple poles and zeroes by oppos-
ing arrow pairs at one tenth and ten times the pole or zero frequency; complex conjugate root 
pairs by opposing arrow pairs at the calculated slope transition frequencies with the appropriate 
slope increment noted.
•	
The phase plot slope is changed at the arrow frequencies by the appropriate amount in the direc-
tion of the arrow.
•	
Any higher-order corrections are then made (if desired).
The system uncorrected Bode straight-line approximate phase plot and the exact phase plot are shown 
in Figure 6.12.
© 2011 by Taylor and Francis Group, LLC

Frequency Response and Bode Diagrams 
6-17
Example 6.3:  Determining the System Response Using Bode Straight-Line Plots
In order to determine the system response, H(ω), the response of the system was determined through 
test as shown in Table 6.2. Initial tests indicated that the frequency range of interest was from 1 Hz to 
10 kHz. Further tests at three samples per decade yielded the data shown. The region from 5 to 10 Hz was 
determined to be a region of interest and two additional data points were taken at 6 and 8 Hz.
–15
–10
–5
0
5
10
15
20
25
30
35
40
45
Magnitude (dB)
Frequency (rad/s) 
10 
Simple root (–3 dB) 
20 dB/decade slope
increment arrows  
40 dB midband 
10 M 
100 k 
1 k 
FIGURE 6.11  Magnitude of the frequency response for Example 6.2 with the Bode approximation overlay.
–360
–315
–270
–225
–180
–135
–90
–45
0
45°
45°
45°
45°
 Slope (º/decade)
increment arrows 
Phase (deg)
Frequency (rad/s) 
10
1 k
100 k
1 M
45°
45°
45°
45°
Midband phase
–180° 
FIGURE 6.12  Phase of the frequency response for Example 6.2 with the Bode approximation overlay.
© 2011 by Taylor and Francis Group, LLC

6-18 
Fundamentals of Industrial Electronics
Solution
The data need to be plotted on an appropriate set of axis. The experimental data need to be converted 
to decibels and that column is added to Table 6.2. Working in temporal frequency will lead directly to H(f) 
which will be converted to H(ω).
Observations ⇒ Conclusions:
•	
The magnitude slope is +40 dB/decade at low frequencies
⇒ There are two zeroes at the origin
•	
The response levels out between 50 and 200 Hz at ∼50 (34 dB)
⇒ There are two low-frequency poles in the system
•	
There is only one low-frequency change in slope that is a multiple of 20 dB/decade
⇒ The system is described by a complex pole pair
•	
The low-frequency asymptote intersects the 34 dB line at f ≈ 8 Hz
⇒ fo = 8 Hz (ωo = 2πfo = 16π)
⇒ The system constant can be determined as (50 ⇔ 34 dB)
	
50
1
50
8
0 781
2
8
2
2
=
+
(
)








⇒
=
≈
→∞
lim
(
)
.
f
jf
K
jf
K
f
f
⇒ There is a peak in the magnitude of somewhat above +4.6 dB; assume it to be 4.7 dB (a factor 
of 1.72):
⇒ 2
1
2
ζ
ζ
−
 = 1/1.72 ⇒ ζ ≈ 0.30
•	
At the resonant frequency, f = 8 Hz, the magnitude is +4.6 dB over the nominal value of 34 dB 
(a factor of 1.7)
⇒ 2ζ = 1/1.7 ⇒ ζ ≈ 0.295
•	
The tangent-of-phase characterization can provide another approximation for the damping coef-
ficient by estimating the phase slope at the factor resonant frequency. The slope of the phase at 
the resonant frequency (Hz) is given by
	
mphase ≈
−
−
=
135
50
10
6
383 2
(
)
log(
)
log( )
.
⇒ ζ ≈ 132
383 2.  ≈ 0.34
TABLE 6.2  Experimental Data for Example 6.3
f (Hz)
|H( f )| 
Phase (°)
|H( f )|db
1
0.8
175
–1.9
2
3.4
170
10.6
5
28
145
28.9
10
85.5
55
38.6
20
58.5
15
35.3
50
52
5
34.3
100
51
–5
34.2
200
50
–10
34.0
500
45
–30
33.1
1k
34
–45
30.6
2k
21
–65
26.4
5k
9
–80
19.1
10k
4.5
–85
13.1
6
45
135
33.1
8
85
90
38.6
© 2011 by Taylor and Francis Group, LLC

Frequency Response and Bode Diagrams 
6-19
•	
At high frequencies the magnitude slope is −20 dB/decade and the phase is ≈ −90°
⇒ There is a single high-frequency pole in the system
•	
The high-frequency asymptote intersects the low-frequency asymptote at f ≈ 900 Hz
⇒ fo = 900 Hz (ωo = 2πfo = 1800π)
While there is a slight variation in the three estimates for the damping coefficient, the system response 
can be reasonably represented as an appropriate product of the factors. If one chooses the damping 
coefficient to be the average of the estimates (ζ = 0.31),
	
H f
jf
jf
jf
jf
(
.
(
)
( .
)
((
) /( ) )
(
)
)
1
8
8
/900
2
=
+
+




+
[
]
0 781
2 0 31
1
2
2
When converting to angular frequency (ω), the resonant frequencies are modified to be in radians per 
second and the system constant is altered (m−n = 2):
	
K
K
ω =
≈
f
(
)
.
2
0 0198
2
π
These changes yield the final system response:
	
H
j
j
j
j
( )
1
16
16
2
ω
ω
ω
π
ω
π
ω
=
+
+


+
0 0198
2 0 31
1
2
2
.
(
)
( .
)(
/
)
((
) /(
) )
(
/1800π)


Figure 6.13 is a plot of the data points, the uncorrected Bode straight-line approximate plots, and the 
experimentally derived H(f ), all on a temporal frequency (Hz) scale.
–5
0
5
10
15
20
25
30
35
40
–90
–60
–30
0
30
60
90
120
150
180
Experimental data points 
Magnitude straight-line fit 
Phase straight-line fit 
Resultant H( f )-magnitude 
Resultant H( f )-phase 
|H( f )| (dB) 
Frequency (Hz)
1
10 
100 
10 k 
1 k 
H( f ) (deg)
FIGURE 6.13  System Bode diagram—Example 6.3.
© 2011 by Taylor and Francis Group, LLC

6-20 
Fundamentals of Industrial Electronics
References
	
1.	 H.W. Bode, Network Analysis and Feedback Amplifier Design, Van Nostrand, Princeton, NJ, 1945.
	
2.	 T.J. Cavicchi, Phase Margin Revisited: Phase-Root Locus, Bode Plots, and Phase Shifters, IEEE 
Transactions on Education, 46(1), 168–176, February 2003.
	
3.	 G.F. Franklin, J.D. Powell, and A. Emami-Naeini, Feedback Control of Dynamic Systems, 3rd edn., 
Addison-Wesley, Reading, MA, 1994.
	
4.	 N.S. Nise, Control System Engineering, 4th edn., John Wiley & Sons, New York, 2003.
	
5.	 R.C. Dorf and R.H. Bishop, Modern Control Systems, 9th edn., Prentice Hall, Upper Saddle River, 
NJ, 2001.
	
6.	 J.W. Nilsson and S.A. Riedel, Electric Circuits, 8th edn., Prentice Hall, Upper Saddle River, NJ, 2008.
	
7.	 T.F. Schubert Jr. and E.M. Kim, Active and Non-Linear Electronics, John Wiley & Sons, New York, 1996.
	
8.	 T.F. Schubert Jr., A quantitative comparison of three Bode straight-line phase approximations for 
second-order, underdamped systems, IEEE Transactions on Education, 40(2), 135–138, May  1997.
© 2011 by Taylor and Francis Group, LLC

7-1
7.1  Introduction
In practice, many engineering and technology problems may be represented as integro-differential equa-
tions that need to be solved. Depending on the order of the equation, the solution may be simple or 
very complex, especially where the standard techniques of integral and differential calculus are used. An 
alternative is to use the Laplace transform. The Laplace transform allows us to carry out differentiation 
and integration using purely algebraic manipulations of addition and subtraction, respectively. This trans-
formation is analogous to taking the logarithm of a function [B82]. So, where we had multiplication and 
division, after “taking logs” of the function, the multiplication becomes addition, and division becomes 
subtraction. Then, after the various algebraic manipulations in the log form, the results can be transformed 
back to get the final result. This logarithmic transformation allows for ease and convenience of algebraic 
manipulation, and the same will be true for the Laplace transform for integro-differential equations. The 
Laplace transform itself is named after Pierre Simon Laplace (1749–1827), a French mathematician and 
astronomer, who first used such transforms [KH00].
The Laplace transform is defined for positive values of time, t (most often used independent variable 
in electrical engineering), and denoted as the function, f(t), with known initial conditions. The Laplace 
transform [S68] of f(t) is formally defined by
	
L f t
F s
e
f t dt
st
( )
( )
( )
{
} =
=
−
∞
∫
0
	
(7.1)
provided that the integral exists.
Note that this integral is defined in the range, 0 ≤ t < ∞, and that s may be real or complex. For most 
realizable systems in engineering and technology, s will be real [G88]. L{f(t)} is the Laplace transform of 
f(t), and F(s), is the Laplace transformation operator. The Laplace transform is a mathematical tool that 
can be used to solve linear initial-value problems that often occur in the form of ordinary and partial dif-
ferential equations [G88]. By convention, the function of time is written in lower-case letters (e.g., f(t)), 
7
Laplace Transforms
7.1	
Introduction........................................................................................7-1
7.2	
Properties of the Laplace Transform.............................................. 7-3
Linearity  •  s-Domain Shifting  •  Time-Domain Shifting  •  Periodic 
Functions  •  Initial and Final Value Theorems  •  Integrals 
(Integration)  •  Derivatives (Differentiation)
7.3	
The Inverse Transform......................................................................7-6
Partial Fractions
7.4	
Miscellaneous Examples....................................................................7-7
References..................................................................................................... 7-12
Dalton S. Nelson
The University of Alabama 
at Birmingham
© 2011 by Taylor and Francis Group, LLC

7-2 
Fundamentals of Industrial Electronics
Table 7.1  Laplace Transforms Pairs (Except for Impulse Functions, u(t) Is Understood)
 f (t)
F(s) = L{ f(t)}
1.
δ(t), unit impulse, at t = 0
1
2.
δ(t − T), unit impulse, at t = T
e−sT
3.
1 or u(t), unit step, at t = 0
1
s
4.
uT(t), unit step, at t = T
e
s
sT
−
5.
t, unit ramp, at t = 0
1
2s
6.
tn, nth order ramp, at t = 0
n
sn
!
+1
7.
e−at, exponential decay
1
s
a
+
8.
1 − e−at, exponential growth
a
s s
a
(
)
+
9.
te−at
1
2
(
)
s
a
+
10.
tn e−at
n
s
a n
!
(
)
+
+1
11.
1
1
1
(
)!
n
tn
−
−
1
sn
12.
Rectangular pulse, magnitude M, duration a
M
s
e as
(
)
1−
−
13.
Triangular pulse, magnitude M, duration 2a
M
as
e as
2
2
1(
)
−
−
14.
Sawtooth pulse, magnitude M, duration a
M
as
as
e as
2 1
1
[
(
)
]
−
+
−
15.
Sinusoidal pulse, magnitude M, duration π
a
Ma
s
a
e
s a
2
2 1
+
+
−
[
]
/
π
16.
sin ωt, a sine wave
ω
ω
s2
2
+
17.
cos ωt, a cosine wave
s
s2
2
+ ω
18.
e−at sin ωt, a damped sine wave
ω
ω
(
)
s
a
+
+
2
2
19.
e−at cos ωt, a damped cosine wave
s
a
s
a
+
+
+
(
)2
2
ω
20.
1 − cos ωt
ω
ω
2
2
2
s s(
)
+
21.
t sin ωt
2
2
2 2
ω
ω
s
s(
)
+
22.
sin(ωt + θ)
ω
θ
θ
ω
cos
sin
+
+
s
s2
2
23.
cos(ωt + θ)
s
s
cos
sin
θ
ω
θ
ω
+
+
2
2
24.
e−at sin(ωt + θ)
(
)sin
cos
(
)
s
a
s
a
+
+
+
+
θ
ω
θ
ω
2
2
25.
e−at cos(ωt + θ)
(
)cos
sin
(
)
s
a
s
a
+
−
+
+
θ
ω
θ
ω
2
2
© 2011 by Taylor and Francis Group, LLC

Laplace Transforms 
7-3
while the transformed values, that are now functions of s, are written in upper-case letters (e.g., F(s)). 
The real variable, s, for the Laplace transform is now in the s-domain or s-plane (also called the complex 
frequency domain). While the original function of time, t, is said to be in the time-domain. Assuming 
that we will be using the Cartesian coordinate system, there are two components in the s-domain: the 
y-component and the x-component. These are, respectively, the imaginary, or jω component; and the 
real part, or sigma, σ component. The transformation maps the time-domain function to the s-domain, 
and this process is reversible, so it is also possible to map an s-domain function to the corresponding 
time-domain description [GV91].
In Table 7.1, except for the impulse function item numbers, it should be understood that each overall 
function of t is multiplied by u(t).
7.2  Properties of the Laplace Transform
The fundamental mathematical properties of the Laplace transform are outlined in the following.
7.2.1  Linearity
The Laplace transform, L{f(t)} = F(s), is a linear operation. Therefore, if two time functions, f(t) and g(t), 
have Laplace transforms, then the transform of the algebraic sum of the time functions is the algebraic 
sum of the two separate Laplace transforms. That is,
	
L af t
bf t
aL f t
( )
( )
( ) .
+
{
} =
{
}
where a and b are constants.
7.2.2  s-Domain Shifting
This property is also referred to as the First shifting property, and it is used to determine the Laplace 
transform of functions that include exponential factors. If L{f(t)} = F(s) then
	
L e f t
F s
a
at ( )
(
)
{
} =
−
Example 7.1
Find the Laplace transform, L{e−attn}. From Table 7.1, Item #6, the Laplace transform pair is given as tn ↔ n!/
sn+1, therefore the Laplace transform for the function given will be
	
L e
t
n
s
a
at n
n
{
}
!
(
)
−
+
=
−
1
7.2.3  Time-Domain Shifting
This property is also referred as the second shift theorem, and is used when a signal is shifted in time by 
a factor of T. The result is that the Laplace transform is multiplied by e−sT. If F(s) is the Laplace transform 
of f(t), then
	
L f t
T u t
T
e
F s
st
(
) (
)
( )
−
−
{
} =
−
This time-domain shifting property can be applied to all Laplace transforms, and can be particularly 
useful in signal-processing applications.
© 2011 by Taylor and Francis Group, LLC

7-4 
Fundamentals of Industrial Electronics
7.2.4  Periodic Functions
Given a function f(t), which is periodic with period T, the Laplace transform of the function is
	
L f t
e
F s
sT
( )
( )
{
} =
−
−
1
1
1
where F1(s) is the Laplace transform of the function for the first period.
7.2.5  Initial and Final Value Theorems
The Initial Value Theorem states that if a function of time f(t) has a Laplace transform F(s) then, in the 
limit, as time tends to zero, the value of that function is given by the expression
	
lim ( )
lim
( )
t
t
f t
sF s
→
→∞
=
0
The Final Value Theorem states that if a function of time f(t) has a Laplace transform F(s) then in the 
limit as time tends toward infinity, the value of the function is given by the expression
	
lim ( )
lim
( )
t
t
f t
sF s
→∞
→
=
0
Example 7.2
For the function below, find (a) the initial value and (b) the final value of the function
	
X s
s s
( )
(
)
=
+
3
3
Solution
	
a.	 Initial value:
	
X
sX s
s s s
s
s
( )
lim
( )
lim
(
)
lim
0
3
3
3
3
0
=
=
+



=
+



=
→∞
→∞
→∞
s
s
	
b.	 Final value:
	
X
sX s
s s s
s
s
s
( )
lim
( )
lim
(
)
lim
∞=
=
+



=
+



=
=
→
→
→
s
0
0
0
3
3
3
3
3
3
1
7.2.6  Integrals (Integration)
The Laplace transform of the integral function, f(t), that has a transform, F(s), is given by
	
L
f t dt
s F s
t
( )
( )
0
1
∫






=
© 2011 by Taylor and Francis Group, LLC

Laplace Transforms 
7-5
This expression suggests that the original integral function of t, is simply the Laplace transformed ver-
sion of f(t), multiplied by the reciprocal of s, 1/s. The multiplicative “1/s” term is the equivalent of the 
first integral in the time domain. This property can be generalized to use higher integral functions. For 
example, the Laplace transform of a second integral is given by
	
L
f t dt
s F s
t
( )
( )
0
2
1
∫∫






=
And the Laplace transform of a triple integral is given by
	
L
f t dt
s F s
t
( )
( )
0
3
1
∫∫∫






=
Generally, it can be observed that the number of integrals used in the time domain description, n, is 
used as the power of s in the Laplace transform of the coefficient term 1/sn. Each 1/s term corresponds 
to a time-domain integral.
7.2.7  Derivatives (Differentiation)
The Laplace transform of the differential function time, f(t), that has a transform, F(s), is given by
	
L
d
dt f t
sF s
f
( )
( )
( )


=
−
0
where f(0) is the value of the function when t = 0 (often referred to as the initial conditions).
This expression suggests that the original differential function of t is the Laplace transform of the 
time function, multiplied by s. The multiplicative “s” term is the first differential equivalent in the time-
domain description. This property can be generalized for higher-order derivatives. For example, for a 
second derivative, we obtain
	
L
d
dt
f t
s F s
sf
d
dt f
2
2
2
0
0
( )
( )
( )
( )






=
−
−
where df(0)/dt is the value of the first derivative at t = 0.
The nth derivative is given by
	
L
d
dt
f t
s F s
s
f
s
f
sf
f
n
n
n
n
n
n
n
( )
( )
( )
( )
( )
(






=
−
−
−
−
−
−
−
−
−
1
2
2
1
0
0
0

0)
where the f i( )
0  terms are the initial conditions of the function, with n − 1 ≤ i ≤ 0.
If the initial conditions are zero, it becomes even simpler to state in general terms that
	
L
d
dt
f t
s F s
n
n
n
( )
( )






=
Of course, we must be very careful that these conditions are met, before using this form of the 
expression.
© 2011 by Taylor and Francis Group, LLC

7-6 
Fundamentals of Industrial Electronics
7.3  The Inverse Transform
The inverse Laplace transform allows us to convert the s-domain function, F(s), back to the correspond-
ing time-domain function, f(t). This operation can be expressed in algebraic terms as
	
L
F s
f t
−{
} =
1
( )
( )
Most often, the inverse can be found by simply using a table of Laplace transform pairs, as shown in 
Table 7.1. However, there is no standardized table of the pairs, and so you must either get a “good table,” 
or work out the value from first principles. Because of the linearity property of Laplace transforms, it 
is possible to work out the results for several parts of a sum of values, invert them, and sum the partial 
results. Hence, we have that
	
L
aF s
bG s
aL F s
bL G s
−
−
−
+
{
} =
+
1
1
1
( )
( )
( )
( )
where a and b are constants.
7.3.1  Partial Fractions
The partial fractions technique is a means of separating out the various components of a Laplace trans-
form expression, and transforming each term back to the time domain. This technique exploits the fact 
that the Laplace transform is a linear operation, and as such, the sum of the individual terms will be the 
overall result. Whether these results are obtained from a table of Laplace transform pairs, as in Table 
7.1, or worked out from first principles, this is nearly always required, and familiarity with the partial 
fraction technique is therefore essential.
If a given function, F(s), is a ratio of two polynomials, and is easily identifiable from a given table of 
Laplace transform pairs, say Table 7.1, then algebraic manipulations can be made to “make” the terms 
“look” like those in the table, with the appropriate fractional forms. This is the process of partial fractions. 
A major constraint on the technique is that the numerator term should not exceed the denominator term, 
i.e., if n is the numerator term, and m the denominator term, then n < m. The degree of the polynomial is, 
by definition, the highest power of s in the overall expression.
Five general forms of the partial fraction can be readily identified, as outlined below:
	
1.	 Those that contain non-repeated linear factors, such as a denominator of the form (s + a), (s + b), 
(s + c),…
	
2.	 Those that contain repeated linear factors of form (s − a)r in the denominator that corresponds to 
the partial fraction
	
A
s
a
A
s
a
A
s
a
A
s
a
r
r
1
2
2
3
3
(
)
(
)
(
)
(
)
−
+
−
+
−
+
+
−

	
3.	 Those that include a denominator that contains quadratic factors, but which also, when factor-
ized, contains imaginary terms. For example, if a1 = σ + jω is complex, then ω ≠ 0, and there will 
be imaginary terms that have complex conjugates. So, there will be a1 = σ + jω and the complex 
conjugate ā1 = σ + jω. If we take this complex conjugate to be the equivalent of the coefficient term 
A2 and the pole location, a2, as ā1, then the partial fraction expansion can proceed as follows:
	
A
s
a
A
s
a
A
s
a
A
s
a
n
n
1
1
1
1
3
3
(
)
(
)
(
)
(
)
−
+
−
+
−
+
+
−

© 2011 by Taylor and Francis Group, LLC

Laplace Transforms 
7-7
	
4.	 Those contain a non-repeated quadratic factor (s2 + as + b) in the denominator, which corresponds 
to the form
	
As
B
s
as
b
+
+
+
2
	
5.	 Those that include a repeated quadratic factor (s2 + as + b)r in the denominator, that correspond 
to partial fractions of the form
	
A s
B
s
as
b
A s
B
s
as
b
A s
B
s
as
b
A s
B
r
r
1
1
2
2
2
2
2
3
3
2
3
+
+
+
+
+
+
+
+
+
+
+
+
+
+
(
)
(
)
(
)

(
)
s
as
b r
2 +
+
7.4  Miscellaneous Examples
Several examples are shown below that will illustrate the use of Table 7.1, and some of the properties of 
the Laplace transform.
Example 7.3
Find the Laplace transform of
	
e–10t cos(3t–1)u(t)
Solution
Recall that cos(ωt + θ) = cos(ωt) · cos(θ) − sin(ωt) · sin(θ), so that the expression becomes
	
e
t
t u t
e
t
t
t
t
−
−
−
=
⋅
+
⋅
(
)


10
10
3
3
1
3
1
cos(
) ( )
cos(
) cos( )
sin(
) sin( ) 
=
⋅
(
)+
⋅
(
)


−
−
u t
e
t
e
t
u t
t
t
( )
cos(
) cos( )
sin(
) sin( )
( )
10
10
3
1
3
1
Using Items #18 and #19 from Table 7.1, we obtain
	
=
+
+
+



⋅
+
+
+



⋅
(
)
(
)
( )
cos( )
(
)
( )
sin(
s
s
s
10
10
3
1
3
10
3
1
2
2
2
2
)
cos( )(
)
(
)
sin( )
(
)
=
+
+
+



+
+
+




∴
−
1
10
10
9
3
1
10
9
2
2
1
s
s
s
L e
0
2
3
1
1
10
3
1
10
9
t
t
u t
s
s
cos(
) ( )
cos( )(
)
sin( )
(
)
−
{
} =
+
+
+
+




Example 7.4
Find the inverse transform of the following Laplace expression, using partial fraction expansion.
	
F s
s
s
s
s
s
( )
(
)
(
)(
)(
)
=
+
+
+
+
+
2
2
6
1
2
3
2
© 2011 by Taylor and Francis Group, LLC

7-8 
Fundamentals of Industrial Electronics
Solution
Expanding the numerator, the result is
	
F s
s
s
s
s
s
( )
(
)(
)(
)
=
+
+
+
+
+
2
4
12
1
2
3
2
This function has non-repeating linear terms, and so the expansion appears as follows:
	
F s
A
s
B
s
C
s
( ) =
+ +
+
+
+
1
2
3
Substituting to find the respective numerator terms
	
A
s
s
s
s
s
:
(
)(
)
2
4
12
2
3
5
2
1
+
+
+
+
=
=−
	
B
s
s
s
s
s
:
(
)(
)
2
4
12
1
3
12
2
2
+
+
+
+
= −
=−
	
C
s
s
s
s
s
:
(
)(
)
2
4
12
1
2
9
2
3
+
+
+
+
=
=−
	
F s
s
s
s
( ) =
+ −
+
+
+
5
1
12
2
9
3
Using Item #7 from Table 7.1, along with each coefficient, the final result is obtained as
	
∴
{
} =
=
−
+
≥
−
−
−
−
L
F s
f t
e
e
t
t
t
t
1
2
3
5
12
9
0
( )
( )
,
e
for
Example 7.5
Find the transfer function (i.e., the ratio of Y(s)/U(s), and by definition, the initial conditions are always 0) of 
the differential equation below.
	



y
y
y
u
u
+
+
=
+
5
6
2
3
Solution
Writing in differential notation, we obtain
	
d y t
dt
dy t
dt
y t
du t
dt
u t
2
2
5
6
2
3
( )
( )
( )
( )
( )
+
+
=
+
Using the Laplace transform for each term (see property in Section 7.2.7), the result is
	
s Y s
sY s
Y s
sU s
U s
2
5
6
2
3
( )
( )
( )
( )
( )
+
+
=
+
© 2011 by Taylor and Francis Group, LLC

Laplace Transforms 
7-9
Factorizing
	
Y s s
s
U s
s
Y
U s
s
s
s
Y s
U s
s
( )[
]
( )[
]
( )
( )
( )
( )
(
2
2
5
6
2
3
2
3
5
6
2
+
+
=
+
=
+
+
+
∴
=
+
s
3 2
3
2
/ )
(
)(
)
(
)
+
+
s
s
Example 7.6
Solve the following differential equation using Laplace transforms:
	
dy t
dt
y t
u t
y
( )
( )
( ),
( )
−
=
=
3
0
1
given that,
Solution
Using the Laplace transform for each term (see property in Section 7.2.7), and Item #3 from Table 7.1, the 
result is
	
[
( )
( )]
( )
sY s
y
Y s
s
−
−
=
0
3
1
	
sY s
Y s
s
y
( )
( )
( )
−
=
+
3
1
0
Substituting the initial value, and factoring, we obtain
	
(
) ( )
s
Y s
s
−
=
+
3
1
1
	
Y s
s s
s
( )
(
)
(
)
=
−
+
−
1
3
1
3
By partial fraction expansion
	
Y s
s
s
s
( )
/
(
)
/
(
)
=
−
−
+
−
1 3
3
1 3
1
3
Taking the inverse transform from Table 7.1, Item #7, the solution is found as
	
y t
L
Y s
e
e
u t
y t
e
t
t
t
( )
( )
( )
( )
(
)
=
[
]=
−
+




∴
=
−


−
−
−
−
1
3
3
3
1
3
1
3
1
3 4
1



≥
u t
t
( ),
for
0
© 2011 by Taylor and Francis Group, LLC

7-10 
Fundamentals of Industrial Electronics
Example 7.7
Solve the following differential equation using Laplace transforms:
	
dy t
dt
y t
e
u t
y
t
( )
( )
( ),
( )
+
=
=
−
10
8
0
0
10
given that,
Solution
Using Item #7 from Table 7.1, and Property in Section 7.2.7, the following expression is obtained:
	
[
( )
( )]
( )
sY s
y
Y s
s
−
+
=
+
0
10
8
10
Factorizing
	
(
) ( )
s
Y s
s
+
=
+
10
8
10
And solving for Y(s)
	
Y s
s
s
s
( )
((
)(
))
(
)
=
+
+
=
+
8
10
10
8
10 2
Finding the inverse transform, using Item #10 from Table 7.1, we obtain the following result:
	
∴
=
=
≥
−
−
y t
L
s
te
u t
t
t
( )
( )]
( ),
1
10
8
0
[Y
for
Example 7.8
Solve the following differential equation using Laplace transforms:
	
dy t
dt
t u t
y
( )
sin(
) ( ),
, ( )
+
=
=
10
4
2
0
1
given that
Solution
Using Items #16 from Table 7.1, and property in Section 7.2.7 the following expression is obtained:
	
[
( )
( )]
( )
(
)
sY s
y
Y s
s
−
+
=
+
0
10
8
4
2
Since
	
(
) ( )
(
)
( )
s
Y s
s
y
+
=
+
+
10
8
4
0
2
Substituting for y(0), the result is
	
(
) ( )
(
)
s
Y s
s
+
=
+
+
10
8
4
1
2
© 2011 by Taylor and Francis Group, LLC

Laplace Transforms 
7-11
Solving for Y(s)
	
Y s
s
s
s
( )
(
)(
)
(
)
=
+
+
+
+
8
10
4
1
10
2
By partial fraction expansion, the results are
	
Y s
s
s
s
s
( )
/
(
)
(
)
(
)
=
+
−
⋅
+
+
+
14 13
10
1
13
4
10
26
2
4
2
2
Finding the inverse transform, using Items #16 and #17 from Table 7.1, the solution is then complete.
	
∴
=
=
−
+




−
−
L Y s
y t
e
t
t
u t
t
1
10
14
13
1
13
2
10
26
2
[ ( )]
( )
cos(
)
sin(
)
( ),
for t ≥0
Example 7.9
Solve the following differential equation using Laplace transforms:
	
d y t
dt
dy t
dt
y
u t
y
y t
2
2
6
8
0
0
1
( )
( )
( ),
( )
; ( )
+
+
=
=
=
given that,

Solution
Using Items #16 from Table 7.1, and property in Section 7.2.7, the following expression is obtained:
	
[
( )
( )
( )]
[
( )
( )]
( )
s Y s
sy
y
sY s
y
Y s
s
2
0
0
6
0
8
1
−
−
+
−
+
=

Substituting values of the initial conditions
	
[
( )
]
[
( )
]
( )
s Y s
s
sY s
Y s
s
2
0
1
6
0
8
1
−
−
+
−
+
=
	
s Y s
sY s
Y s
s
2
1 6
8
1
( )
( )
( )
−+
+
=
	
[
] ( )
s
s
Y s
s
2
6
8
1
1
+
+
=
+
Factorizing and solving for Y(s)
	
Y s
s
s
s
s
s
( )
(
)(
)
(
)(
)
=
+
+
+
+
+
1
4
2
1
4
2
© 2011 by Taylor and Francis Group, LLC

7-12 
Fundamentals of Industrial Electronics
By partial fractions
	
Y s
s
s
s
( )
( / )
(
)
/
(
)
/
= −
+
+
+
3 8
4
1 4
2
1 8
+
Finding the inverse transform using Item #7 from Table 7.1, the following solution is obtained:
	
∴
=
= −
+
+




≥
−
−
−
L Y s
y t
e
e
u t
t
t
t
1
4
2
3
8
1
4
1
8
0
[ ( ) ]
( )
( ),
for
References
[B82] J. A. Bogart, Laplace Transforms and Control Systems Theory for Technology, John Wiley & Sons, 
New York, 1982.
[G88] M. D. Greenberg, Advanced Engineering Mathematics, Prentice-Hall, Upper Saddle River, NJ, 1988.
[GV91] J. Golten and A. Verwer, Control System Design and Simulation, McGraw-Hill International (UK) 
Ltd., London, U.K., 1991.
[KH00] E. W. Kamen and B. S. Heck, Fundamentals of Signals and Systems Using the Web and MATLAB 
(2nd edition), Prentice-Hall, Upper Saddle River, NJ, 2000.
[S68] M. R. Spiegel, Schaum’s Outline Series—Mathematical Handbook of Formulas and Tables, McGraw-
Hill, New York, 1968.
© 2011 by Taylor and Francis Group, LLC

8-1
The pn semiconductor junctions exhibit nonlinear current–voltage characteristics, and they are used 
to rectify and shape electrical signals ([1],[3],[4],[5]). Exponential current–voltage characteristics are 
sometimes used to build logarithmic amplifiers. The thickness of the depletion layer depends on applied 
reverse voltage, and the voltage-dependent capacitance can be used to tune frequency characteristics 
of electronic circuits [2]. There are over 20 different types of diodes using different properties of pn 
junctions or metal–semiconductor junction properties [7]. Some of these special diodes are described 
in Section 8.6.
8.1  Nonlinear Static I–V Characteristics
Typical I–V diode characteristics are shown in Figure 8.1. In the case of common silicon diode, the for-
ward direction current increases exponentially at first, and then it is limited by an ohmic resistance of the 
structure. A very small current in the reverse direction at first increases slightly with applied voltage and 
then starts to multiply near the breakdown voltage. The current at the breakdown is limited by the ohmic 
resistances of the structure. In germanium (small energy gap) diodes, the recombination–generation 
component of the current is much smaller than the diffusion components, and in a wide range of reverse 
voltages the current is almost constant. In the case of silicon diodes (larger energy gap), the diffusion com-
ponent of the reverse current is negligibly small, and the reverse current is caused by the recombination–
generation phenomena, and the current is proportional to the size of the depletion layer (which increases 
slightly with the voltage). The diode equation (8.6) is not valid for silicon diodes in the reverse direction. 
Typical reverse characteristics of germanium and silicon diodes are shown in Figure 8.2.
8
Semiconductor Diode
8.1	
Nonlinear Static I–V Characteristics..............................................8-1
pn Junction Equation  •  Forward I–V Diode 
Characteristics  •  Reverse I–V Characteristics
8.2	
Diode Capacitances...........................................................................8-6
Diffusion Capacitance  •  Depletion Capacitance
8.3	
Diode as a Switch...............................................................................8-8
8.4	
Temperature Properties....................................................................8-9
8.5	
Piecewise Linear Model.................................................................. 8-10
8.6	
Different Types of Diodes............................................................... 8-11
Switching Diodes  •  Zener Diodes  •  Tunnel Diodes 
(Esaki Diodes)  •  Backward Diodes  •  PIN Diodes  •  Schottky 
Diodes  •  Super Barrier Diodes  •  Step-Recovery Diodes  •   
Avalanche Diodes  •  Varicaps  •  Solar Batteries  •   
Photodiodes  •  LEDs  •  Laser Diodes  •  Gun Diodes  •   
IMPATT Diodes  •  Peltier Diodes
References.....................................................................................................8-15
Bogdan M. 
Wilamowski
Auburn University
© 2011 by Taylor and Francis Group, LLC

8-2 
Fundamentals of Industrial Electronics
8.1.1  pn Junction Equation
The n-type semiconductor material has a positive impurity charge attached to the crystal lattice struc-
ture. This fixed positive charge is compensated by free moving electrons with negative charges. Similarly, 
the p-type semiconductor material has a lattice with a negative charge, which is compensated by free 
moving holes, as is shown in Figure 8.3. The number of majority carriers (electrons in p-type and holes 
in n-type materials) are approximately equal to the donor or acceptor impurity concentrations, i.e., 
nn = ND and pp = NA. The number of minority carriers (electrons in p-type and holes in n-type) can be 
found using the equations
1 V
i
v
(a)
i
1 V
v
(b)
i
1 V
v
(c)
v
i
(f)
1 V
v
i
(e)
1 V
i
(d)
v
1 V
FIGURE 8.1  Forward current–voltage characteristics of various types of diodes: (a) germanium diode, (b) silicon 
diode, (c) Schottky diode, (d) tunnel diode, (e) backward diode, and (f) LED.
(a)
–10 
v
1 μA
(b)
–100 
v
1 nA 
FIGURE 8.2  Reverse current–voltage characteristics: (a) germanium diode, (b) silicon diode.
© 2011 by Taylor and Francis Group, LLC

Semiconductor Diode 
8-3
	
n
n
p
n
N
p
n
n
n
N
p
i
p
i
A
n
i
n
i
D
=
≈
=
≈
2
2
2
2
	
(8.1)
The intrinsic carrier concentration, ni, is given by
	
n
 T
V
V
V
kT
q
i
g
T
T
2
3
=
−




=
ξ
exp
;
	
(8.2)
where
VT = kT/q is the thermal potential (VT = 25.9 mV at 300 K)
T is the absolute temperature in K
q = 1.6 × 10−16 C is the electron charge
k = 8.62 × 10−5 eV/K is the Boltzmann’s constant
Vg is the potential gap (Vg = 1.1 V for silicon)
ξ is a material constant
For silicon the intrinsic concentration ni is given by
	
n
T
T
i =
×
−




3 88 10
7000
16
3 2
.
exp
/
	
(8.3)
For silicon at 300 K, ni = 1.5 × 1010 cm−2.
When a pn junction is formed, the fixed electrostatic lattice charges form an electrical field at the 
junction. Electrons are pushed by electrostatic forces deeper into the n-type region and holes into the 
p-type region, as illustrated in Figure 8.4. Between n-type and p-type regions there is a depletion layer 
with a built-in potential that is a function of impurity doping level and intrinsic concentration ni:
	
V
V
N N
n
V
n p
n
V
n
n
V
pn
T
A
D
i
T
n
p
i
T
n
p
T
=



=



=



=
ln
ln
ln
l
2
2
n p
p
p
n




	
(8.4)
The junction current as a function of biasing voltage is described by the diode equation
	
i
I
v
V
s
T
=



−






exp
1
	
(8.5)
Depletion region
p
n
FIGURE 8.3  Illustration of the pn junction.
© 2011 by Taylor and Francis Group, LLC

8-4 
Fundamentals of Industrial Electronics
where
	
I
Aqn V
n dx
p dx
s
i
T
p
n
L
n
p
L
p
n
=
+
∫
∫




2
0
0
µ
µ
	
(8.6)
where
nn ≈ ND
pp ≈ NA
μn and μp are the mobility of electrons and holes
Ln and Lp are the diffusion length for electron and holes
A is the device area
In the case of diodes made of silicon or other semiconductor material with a high energy gap, the 
reverse-biasing current cannot be calculated from the diode equation (8.5). This is due to the car-
rier generation–recombination phenomenon. Lattice imperfection and most impurities are acting as 
generation–recombination centers. Therefore, the more imperfections there are in the structure, the 
larger the deviation from ideal characteristics.
8.1.2  Forward I–V Diode Characteristics
The diode equation (8.5) was derived with an assumption that injected carriers are recombining on the 
other side of the junction. The recombination within the depletion layer was neglected. In forward-
biased diode, electrons and holes are injected through the depletion region, and they may recombine 
there. The recombination component of the forward-biased diode is given by
	
i
qwA n
v
V
I
v
V
rec
i
T
ro
T
=



=




2
2
2
0τ exp
exp
	
(8.7)
where
w is the depletion layer thickness
τ0 is the carrier lifetime in depletion region
log (i)
v
(b)
(a)
(c)
FIGURE 8.4  Current–voltage characteristics of the pn junction in forward direction: (a) diffusion current, 
(b) recombination current, and (c) high-level injection current.
© 2011 by Taylor and Francis Group, LLC

Semiconductor Diode 
8-5
The total diode current iT = iD + irec, where iD and irec are defined by Equations 8.5 and 8.7. The recombina-
tion component dominates at low current levels, as Figure 8.5 illustrates.
Also, in very high current levels the diode equation (8.5) is not valid. Two phenomena cause this 
deviation. First, there is always an ohmic resistance that plays an important role for large current 
values. Second, deviation is due to high concentration of injected minority carriers. For very high 
current levels, the injected minority carrier concentrations may approach, or even become larger 
than, the impurity concentration. An assumption of the quasi-charge neutrality leads to an increase 
of the majority carrier concentration. Therefore, the effective diode current is lower, as can be seen 
from Equation 8.6. The high current level in the diode follows the relation
	
i
I
v
V
h
ho
T
=




exp 2
	
(8.8)
Figure 8.4 shows the diode I–V characteristics, which include generation–recombination, dif-
fusion, and high current phenomena. For modeling purposes, the forward diode current can be 
approximated by
	
i
I
v
V
D
o
T
=




exp η
	
(8.9)
where η has a value between 1.0 and 2.0. Note that the η coefficient is a function of current, as shown in 
Figure 8.5. It has a larger value for small and large current regions and it is close to unity in the medium 
current region.
8.1.3  Reverse I–V Characteristics
The reverse leakage current in silicon diodes is mainly caused by the electron-hole generation in the 
depletion layer. This current is proportional to the number of generation–recombination centers. These 
centers are formed either by a crystal imperfection or deep impurities, which create energy states near 
the center of the energy gap. Once the reverse voltage is applied, the size of the depletion region and the 
number of generation–recombination centers increase. Thus, the leakage current is proportional to the 
thickness of the depletion layer w(v). For a step-abrupt junction
Lp
Ln
x
po = pn exp v
VT
no = np exp v
VT
p(x) = po exp
x
Lp
–
n(x) = no exp
x
Ln
–
FIGURE 8.5  Minority carrier distribution in the vicinity of the pn junction biased in forward direction.
© 2011 by Taylor and Francis Group, LLC

8-6 
Fundamentals of Industrial Electronics
	
w
V
v
qN
o
pn
eff
=
−
(
)
2εε
	
(8.10)
For other impurity profiles, w can be approximated by
	
w
K V
v
pn
m
=
−
(
)
1/ 	
(8.11)
The reverse diode current for small and medium voltages can therefore be approximated by
	
i
Aw v qn
rev
i
o
=
( ) 2τ 	
(8.12)
where ni is given by Equation 8.2 and w by Equation 8.10 or 8.11. The reverse current increases rapidly 
near the breakdown voltage. This is due to the avalanche multiplication phenomenon. The multiplica-
tion factor is often approximated by
	
M
v BV
m
=
−(
)
1
1
/
	
(8.13)
where
BV stands for the breakdown voltage
m is an exponent chosen experimentally
Note that for the reverse biasing, both v and BV have negative values and the multiplication factor M 
reaches an infinite value for v = BV.
8.2  Diode Capacitances
Two types of capacitances are associated with a diode junction. The first capacitance, known as diffusion 
capacitance, is proportional to the diode current. This capacitance exists only for the forward-biased 
condition and has the dominant effect there. The second capacitance, known as the depletion capaci-
tance, is a weak function of the applied voltage.
8.2.1  Diffusion Capacitance
In a forward-biased diode, minority carriers are injected into opposite sides of the junction. Those 
minority carriers diffuse from the junction and recombine with the majority carriers. Figure 8.6 
shows the distribution of minority carriers in the vicinity of the junction of uniformly doped n-type 
and p-type regions. The electron charge stored in the p-region corresponds to the area under the 
curve, and it is equal to Qn = qnoLn. Similarly, the charge of stored holes Qp = qpoLp. The storage 
charge can be also expressed as Qn = Inτn and Qp = Ipτp, where In and Ip are electron and hole currents 
at the junction, τn and τp are the lifetimes for minority carriers. Assuming τ = τn = τp and knowing 
that I = Ip + In the total storage charge at the junction is Q = Iτ. The diffusion capacitance can then 
be computed as
	
C
dQ
dv
d
dv
I
v
V
I
V
dif
o
T
B
T
=
=









=
τ
η
τ
η
exp
	
(8.14)
© 2011 by Taylor and Francis Group, LLC

Semiconductor Diode 
8-7
As one can see, the diffusion capacitance Cdif is proportional to the storage time τ and to the diode 
biasing current IB. Note that the diffusion capacitance does not depend on the junction area, but it only 
depends on the diode current. The diffusion capacitances may have very large values. For example, for 
100 mA current and τ = 1 μs, the junction diffusion capacitance is about 4 μF. Fortunately, this diffu-
sion capacitance is connected in parallel to the small-signal junction resistance r = ηVT/IB, and the time 
constant rCdif is equal to the storage time τ.
8.2.2  Depletion Capacitance
The reversed-biased diode looks like a capacitor with two “plates” formed of p-type and n-type regions 
and the dielectric layer (depletion region) between them. The capacitance of a reversed-biased junction 
can then be written as
	
C
A w
dep =
ε
	
(8.15)
where
A is a junction area
ε is the dielectric permittivity of semiconductor material
w is the thickness of the depletion layer
The depletion layer thickness w is a weak function of the applied reverse-biasing voltage. In the simplest 
case, with step-abrupt junction, the depletion capacitance is
	
C
qN
V
v
N
N
N
j
eff
o
pn
eff
D
A
=
−
=
+
εε
2
1
1
1
(
) ;
	
(8.16)
The steepest capacitance–voltage characteristics are in pn+n diodes with the impurity profiles shown in 
Figure 8.1f. In general, for various impurity profiles at the junction, the depletion capacitance Cj can be 
approximated by
	
C
C
V
v
j
jo
pn
m
=
−
(
) /
1
	
(8.17)
v
Cj
Cjo
Vjo
FIGURE 8.6  Capacitance–voltage characteristics for reverse-biased junction.
© 2011 by Taylor and Francis Group, LLC

8-8 
Fundamentals of Industrial Electronics
or using linear approximation, as shown in Figure 8.6
	
C
C
v
V
j
jo
jo
=
−






1
	
(8.18)
8.3  Diode as a Switch
The switching time of the pn junction is limited mainly by the storage charge of injected minority car-
riers into the vicinity of the junction (electrons injected in p-type region and holes injected in n-type 
region). When a diode is switched from forward to reverse direction, these carriers may move freely 
through the junction. Some of the minority carriers recombine with time. Others are moved away to the 
other side of the junction. The diode cannot recover its blocking capability as long as a large number of 
the minority carriers exist and can flow through the junction. An example of the current–time charac-
teristics of a diode switching from forward to reverse direction is shown in Figure 8.7. Few character-
istics that are shown in the figure are for the same forward current and different reverse currents. Just 
after switching, these reverse currents are limited only by external circuitry. In this example, shown in 
Figure 8.7, most of the minority carriers are moved to the other side of the junction by the reverse cur-
rent and the recombination mechanism is negligible. Note that the larger the reverse current flows after 
switching, the shorter time is required to recover the blocking capability. This type of behavior is typical 
for commonly used high-voltage diodes.
In order to shorten the switching time, diodes sometimes are doped with gold or other deep-level impu-
rities to create more generation centers and to increase the carrier recombination. This way, the minority 
carrier lifetimes of such switching diodes are significantly reduced. The switching time is significantly 
shorter, but it is almost independent of the reverse diode current after switching, as Figure 8.8 shows. 
t
FIGURE 8.7  Currents in diode with large minority carrier lifetimes after switching from forward to reverse 
direction.
t
i
FIGURE 8.8  Currents in diode with small minority carrier lifetimes after switching from forward to reverse 
direction.
© 2011 by Taylor and Francis Group, LLC

Semiconductor Diode 
8-9
This method of artificially increasing recombination rates has some severe disadvantages. Such switching 
diodes are characterized by very large reverse leakage current and small breakdown voltages.
The best switching diodes utilize metal–semiconductor contacts. They are known as the Schottky 
diodes. In such diodes there is no minority carrier injection phenomenon, therefore, these diodes 
recover the blocking capability instantaneously. The Schottky diodes are also characterized by a rela-
tively small (0.2–0.3 V) voltage drop in the forward direction. However, their reverse leakage current 
is larger, and the breakdown voltage rarely exceeds 20–30 V. Lowering the impurity concentration in 
the semiconductor material leads to slightly larger breakdown voltages, but at the same time, the series 
diode resistances increase significantly.
8.4  Temperature Properties
Both forward and reverse diode characteristics are temperature dependent. These temperature proper-
ties are very important for correct circuit design. The temperature properties of the diode can be used to 
compensate for the thermal effects of electronic circuits. Diodes can be used also as accurate tempera-
ture sensors. The major temperature effect in a diode is caused by the strong temperature dependence of 
the intrinsic concentration ni (Equations 8.2 and 8.3) and by the exponential temperature relationship 
of the diode equation (8.7). By combining Equations 8.2 and 8.7 and assuming the temperature depen-
dence of carrier mobilities, the voltage drop on the forward-biased diode can be written as
	
v
V
i
T
V
T
g
=



+






η
ξ
α
ln
	
(8.19)
or diode current
	
i
I
T
T
T
T
v
V
V
o
o
o
g
To
=




−




α
η
exp
( / )
	
(8.20)
where
Vg is the potential gap in semiconductor material
Vg = 1.1 V for silicon and Vg = 1.4 V for GaAs
α is a material coefficient ranging between 2.5 and 4.0
The temperature dependence of the diode voltage drop dv/dT can be obtained by calculating the 
derivative of Equation 8.19
	
dv
dT
v
V
V
T
g
T
=
−
+
η
α
(
)
	
(8.21)
For example, in the case of the silicon diode with a 0.6 V drop and assuming η = 1.1, α = 3.0, and 
T = 300 K, the dV/dT = 1.87 mV/°C.
The reverse diode current is a very strong function of the temperature. For diodes made of the semi-
conductor materials with a small potential gap, such as germanium, the diffusion component domi-
nates. In this case, the reverse current is proportional to
	
i
T
qV
kT
rev
g
∝
α exp −




	
(8.22)
© 2011 by Taylor and Francis Group, LLC

8-10 
Fundamentals of Industrial Electronics
For diodes made of silicon and semiconductors with a higher energy gap, the recombination is the 
dominant mechanism. In this case, reverse leakage current is proportional to
	
i
T
qV
kT
rev
g
∝
α/ exp
2
2
−




	
(8.23)
Using Equation 8.23, one may calculate that for silicon diodes at room temperatures, the reverse leakage 
current doubles for about every 10°C.
The breakdown voltage is also temperature dependent. The tunneling effect dominates in diodes 
with small breakdown voltages. This effect is often known in literature as the Zener breakdown. 
In such diodes, the breakdown voltage decreases with the temperature. The avalanche breakdown 
dominates in diodes with large breakdown voltages. When the avalanche mechanism prevails then 
the breakdown voltage increases 0.06%–0.1% per °C. For medium range breakdown voltages, one 
phenomenon compensates the other, and the temperature-independent breakdown voltage can be 
observed. This zero temperature coefficient exists for diodes with breakdown voltages equal to about 
5Vg. In the case of the silicon diode, this breakdown voltage, with a zero temperature coefficient, is 
equal to about 5.6 V.
8.5  Piecewise Linear Model
The nonlinear diode characteristics are often approximated by the piecewise linear model. There are a 
few possible approaches to linearize the diode characteristics, as shown in Figure 8.9. The parameters of 
the most accurate linearized diode model are shown in Figure 8.10a, and the linearized diode equivalent 
circuit is shown in Figure 8.10b
The modified diode equation (8.9) also can be written as
	
v
V
i
I
T
o
=




η
ln
	
(8.24)
For the biasing point VB and IB, the small-signal diode resistance dv/di can be computed from Equation 
8.24 as
	
r
dv
di
V
I
V
V
V
T
B
tho
B
T
=
=
=
−
η
;
	
(8.25)
and it is only the function of the thermal potential VT and the biasing current IB. Note that the small-
signal diode resistance is almost independent on the diode construction or semiconductor material 
used. If one requires that this linearized diode have the IB current for the VB voltage, then the piece-
wise diode characteristics should be as in Figure 8.10. The equivalent Thevenin and Norton circuits are 
i
v
v
i
v
i
v
i
FIGURE 8.9  Various ways of linearizing diode characteristics.
© 2011 by Taylor and Francis Group, LLC

Semiconductor Diode 
8-11
shown in Figure 8.11. In a case of large signal operation, the diode can be approximated by shifting the 
characteristics to the left by ΔV. In this case, the threshold voltage becomes Vtho = VB − 2VT instead of 
Vtho = VB − VT.
8.6  Different Types of Diodes
Using different phenomena in semiconductors, it is possible to develop many different types of diodes 
with specific characteristics. Different diodes have different symbols, as shown in Figure 8.11. Various 
types of diodes are briefly described in this section.
8.6.1  Switching Diodes
Switching diodes are usually small-power pn junction diodes that are designed for fast switching. In 
order to reduce the storage time (and diffusion capacitances), the lifetime of electron and holes were 
purposely reduced by introducing deep-level impurities such as gold or platinum.
8.6.2  Zener Diodes
Zener diodes use the reverse-breakdown voltage to stabilize voltages in electronic circuits. The break-
down voltage of pn junction decreases with an increase of the impurity level. When junction is heavily 
(a)
v
i
IB
VB
Vtho
VT
(b)
Vtho= VB–VT
rD= ηVT/IB
+
–
FIGURE 8.10  Linearization of the diode: (a) diode characteristics, (b) equivalent diagram.
Anode
Anode
Anode
Anode
Anode
Anode
Anode
Anode
Cathode
Cathode
Cathode
Cathode
Cathode
Cathode
Cathode
Cathode
Diode
Zener
diode
Schottky
diode
Tunnel
diode
LED
Photo
diode
Varicap
SCR
FIGURE 8.11  Commonly used symbols for various diodes.
© 2011 by Taylor and Francis Group, LLC

8-12 
Fundamentals of Industrial Electronics
doped, the breakdown voltage is controlled by the tunneling mechanism, and it decreases with tempera-
ture. With lightly doped junction and high breakdown voltages, the avalanche breakdown is the domi-
nant mechanism and the breakdown voltage increases with temperature. In other words, Zener diodes 
for small voltages have negative temperature coefficient, and Zener diodes for large voltages have posi-
tive temperature coefficient. It is worth noticing that for voltages equal about 5 energy gaps (about 5.6 V 
for silicon) Zener diodes have close to zero temperature coefficients. Such temperature-compensated 
Zener diodes are known as reference diodes.
8.6.3  Tunnel Diodes (Esaki Diodes)
When both sides of the junction are very heavily doped, then for small forward-biasing voltages 
(0.1–0.3 V) a large tunneling current may occur. For larger forward voltages (0.4–0.5 V), this tunneling 
­current vanishes. This way, the current–voltage characteristic has a negative resistance region some-
where between 0.2 and 0.4 V (Figure 8.1d). The germanium and other than silicon semiconductors are 
used to fabricate tunnel diodes.
8.6.4  Backward Diodes
The backward diode has slightly lower impurity concentrations than the tunnel diode, and the tun-
neling current in forward direction does not occur (Figure 8.1e). The backward diode is characterized 
by a very sharp knee near 0 V, and it is used for detection (rectifications) of signals with very small 
magnitudes.
8.6.5  PIN Diodes
Diodes with high breakdown voltage have the pin structure with an impurity profile shown in Figure 
8.12d. A similar pin structure is also used in microwave circuits as a switch or as an attenuating resis-
tor. For reverse biasing, such microwave pin diode represents an open circuit with a small parasitic 
junction capacitance. In the forward direction, this diode operates as a resistor whose conductance is 
proportional to the biasing current. At very high frequencies, electrons and holes will oscillate rather 
than flow. Therefore, the microwave pin diode exhibits linear characteristics even for large modulat-
ing voltages.
8.6.6  Schottky Diodes
The switching time of a pn junction from forward to reverse direction is limited by the storage time 
of minority carriers injected into the vicinity of the junction. Much faster operation is possible in the 
Schottky diode, where minority carrier injection does not exist. Another advantage of the Schottky 
diode is that the forward voltage drop is smaller (0.2–0.3 V) than in the silicon pn junction. This diode 
uses the metal–semiconductor contact for its operation. Schottky diodes are characterized by relatively 
small reverse-breakdown voltage, rarely exceeding 50 V.
8.6.7  Super Barrier Diodes
The major drawback of Schottky diodes is their low breakdown voltage. By combining pn junctions with 
Schottky contact, it is possible to make super barrier diodes where voltage drop in forward direction 
is determined by Schottky contact, but for reverse direction, specially profiled pn junction [6] lower 
electrical field Schottky contact, resulting in much larger breakdown voltages.
© 2011 by Taylor and Francis Group, LLC

Semiconductor Diode 
8-13
8.6.8  Step-Recovery Diodes
When pn junction is biased in forward detection, then minority carriers are injected to both sides of 
the junction. Holes are injected into the n-type region and electrons are injected into the p-type region. 
When diode switches into reverse directions, injected minority carriers flow back through the junction 
creating large temporary reverse current. This current decays with time as the number of minority car-
riers decreases with time. The step-recovery diodes have such impurity profile that the built-in poten-
tials push minority carriers away from the junction, so large reverse current flows only for a very short 
time after switching and then this current drops very rapidly generating very sharp current pulse. When 
RF signal is applied to this diode, many higher harmonic frequencies are generated. These step-recovery 
diodes are used for frequency multiplication.
8.6.9  Avalanche Diodes
The destructive thermal breakdown in high-power diodes occur when the leakage current, which is an 
exponential function of the temperature, starts to increase. Locally, larger current creates large local 
heat dissipation, which leads to further temperature increase and, as a consequence, the destructive 
thermal breakdown. When the breakdown is controlled by avalanche mechanism, the breakdown volt-
age increases locally with temperature. In the hotter part of the diode, the breakdown voltage increases, 
the current stops to flow in this region, and the region cools down. Therefore, high-power avalanche 
diodes can sustain large reverse currents without destruction. The avalanche mechanism is also used to 
generate truly random noise and, of course, these are low-power avalanche diodes.
n-type
(a)
log(N)
x
p-type
n-type
(c)
log(N)
x
n-type
p-type
(b)
log(N)
x
n-type
p-type
(d)
log(N)
x
p-type
(f)
log(N)
x
n-type
p-type
(e)
log(N)
x
n-type
p-type
FIGURE 8.12  Impurity profiles for various diodes: (a) step junction, (b) linear junction, (c) diffusion junction, 
(d) pin junction, (e) hyperabrupt junction, and (f) pipn junction.
© 2011 by Taylor and Francis Group, LLC

8-14 
Fundamentals of Industrial Electronics
8.6.10  Varicaps
The thickness of the depletion layer in pn junction depends on the applied voltage, and this phenomenon 
can be used as voltage-controlled capacitor to tune high-frequency electronic circuits. Capacitance–
voltage relationship depends on the impurity profile of the junction. In a typical junction with an impu-
rity profile as shown in Figure 8.12a or b, capacitance does not change much; but with the hyperabrupt 
junction, as shown in Figure 8.12e, the value of capacitance may change several times.
8.6.11  Solar Batteries
The semiconductor pn junction illuminated by light will generate a voltage on its terminals. Such a 
diode is known as a solar battery or photovoltaic cell. The maximum voltage of a solar cell is limited by 
forward pn junction characteristics.
8.6.12  Photodiodes
If pn junction is eliminated with light, then the reverse junction current is proportional to the light 
intensity at the junction. This phenomenon is used in photodiodes. If the reversely biased collector 
junction is illuminated with light, then this photocurrent is amplified beta times by the transistor and 
as a result phototransistor is beta times more sensitive than the photodiode. Phototransistors are slower 
than photodiodes, and as a result only photodiodes are used in optical communications.
8.6.13  LEDs
If a diode is biased in the forward direction, it may emit light. In order to obtain high emission efficiency, 
the light emitting diode (LED) should be made out of a semiconductor material with a direct energy 
band structure. This way electrons and holes can recombine directly between valence and conduction 
bands. The silicon diodes do not emit light because the silicon has indirect band structure and the 
probability of a direct band-to-band recombination is very small. Typically, LEDs are fabricated using 
various compositions of GayAl1−yAsxP1−x. The wavelength of generated light is inversely proportional to 
the potential gap of junction material.
8.6.14  Laser Diodes
When in LEDs the light intensity is enhanced by the addition of micromirrors, then laser action may 
occur. Laser diodes have a better efficiency and they generate coherent light.
8.6.15  Gun Diodes
These are other microwave diodes that generate microwave signals. The gun diode uses material like 
gallium arsenide, where for certain electrical field electron velocity decreases with electrical field. This 
phenomenon leads to grouping moving electrons in packs and to the generation of microwave frequen-
cies on its terminals.
8.6.16  IMPATT Diodes
Another interesting “diode” structure having the impurity profile is shown in Figure 8.12f. When 
reverse biasing exceeds the breakdown voltage, this element generates a microwave signal with a fre-
quency related to the electron transient time through structure. Such a diode is known as an IMPATT 
(IMPact Avalanche Transit Time) diode.
© 2011 by Taylor and Francis Group, LLC

Semiconductor Diode 
8-15
8.6.17  Peltier Diodes
Moving electrons and holes are also carrying thermal energy. In order to efficiently transfer heat, the 
semiconductor material must have large mobility and as small as possible thermal conductivity. Peltier 
diodes are composed of p-type and n-type bars connected in such a way that currents through p-type 
and n-type bars flow in opposite directions. Since holes move in the same direction as current, and elec-
trons move in the opposite direction of current, the majority of carriers (both electron and holes) move 
in the same direction in different bars carrying heat. Peltier diodes are used for thermoelectric cooling.
There are many other two-terminal bulk semiconductor devices that can be considered diodes. 
Thermistors are made out of semiconductors with small energy gap (0.2–0.3 eV), and their conduc-
tance increases exponentially with temperature. Photoresistors are made from semiconductors with 
large minority carrier lifetime and their resistances change with illumination. Photoresistors have very 
slow response. Piezoresistors are sensitive to the induced stress. They can be over 100 times more sensi-
tive than thin film tensometers. Magnetoresistors change their resistance with magnetic field. The most 
popular magnetoresistor structure is the Corbino ring.
References
	
1.	 S. M. Sze, Modern Semiconductor Device Physics, John Wiley & Sons, New York, 1998.
	
2.	 G. W. Neudeck, The PN Junction Diode, Vol. II, Modular Series on Solid-State Devices, Addison-
Wesley, Reading, MA, 1983.
	
3.	 R. S. Muller and T. I. Kamins, Device Electronics for Integrated Circuits, 2nd edn., John Wiley & Sons, 
New York, 1986.
	
4.	 B. G. Streetman, Solid State Electronic Devices, 4th edn., Prentice Hall, Englewood Cliffs, NJ, 1995.
	
5.	 D. A. Neamen, Semiconductor Physics and Devices, Irwin, Boston, MA, 1992.
	
6.	 B. M. Wilamowski, Solid-State Electronics, 26(5), 491–493, 1983.
	
7.	 B. L. Anderson and R. L. Anderson, Fundamentals of Semiconductor Devices, McGraw-Hill, Burr 
Ridge, IL, 2005.
© 2011 by Taylor and Francis Group, LLC

9-1
The bipolar junction transistor (BJT) is historically the first solid-state analog amplifier and digital 
switch, and formed the basis of integrated circuits (ICs) in the 1970s [6]. Starting in the early 1980s, the 
MOSFET had gradually taken over; particularly for mainstream digital ICs. However, in the 1990s, the 
invention of silicon–germanium base heterojunction bipolar transistor (SiGe HBT) brought the bipolar 
transistor back into high-volume commercial production, mainly for the now widespread wireless and 
wire line communications applications. Today, SiGe HBTs are used to design radio-frequency (RF) ICs 
and systems for cell phones, wireless local area network (WLAN), automobile collision avoidance radar, 
wireless distribution of cable television, millimeter wave radios, and many more applications, due to 
its outstanding high-frequency performance and ability to integrate with CMOS for realizing digital, 
analog, and RF functions on the same chip.
Below, we will first introduce the basic concepts of BJT using a historically important equivalent 
circuit model, the Ebers–Moll model [1]. Then the Gummel–Poon model [2] will be introduced, as it is 
widely used for computer-aided design, and is the basis of modern BJT models like the VBIC, Mextram, 
and HICUM models. Current gain, high current phenomena, fabrication technologies, and SiGe HBTs 
will then be discussed.
9.1  Ebers–Moll Model
An NPN BJT consists of two closely spaced PN junctions connected back to back sharing the same 
p-type region, as shown in Figure 9.1a. The drawing is not to scale. The emitter and base layers are 
thin, typically less than 1 μm, and the collector is much thicker to support a high output voltage 
swing. For forward mode operation, the emitter–base (EB) junction is forward biased, and the col-
lector-base (CB) junction is reverse biased. Minority carriers are injected from the emitter to base, 
9
Bipolar Junction Transistor
9.1	
Ebers–Moll Model............................................................................. 9-1
9.2	
Gummel–Poon Model.......................................................................9-3
9.3	
Current Gains of Bipolar Transistors.............................................9-5
9.4	
High Current Phenomena................................................................ 9-7
9.5	
Small Signal Model............................................................................9-8
9.6	
Technologies..................................................................................... 9-10
Integrated NPN Bipolar Transistor  •  Lateral and Vertical 
PNP Transistors
9.7	
Model Parameters............................................................................9-12
Thermal Sensitivity  •  Second Order Effects  •  SPICE Model 
of the Bipolar Transistor
9.8	
SiGe HBTs......................................................................................... 9-15
Operation Principle and Performance Advantages over 
Si BJT  •  Industry Practice and Fabrication Technology
References.....................................................................................................9-20
Bogdan M. 
Wilamowski
Auburn University
Guofu Niu
Auburn University
© 2011 by Taylor and Francis Group, LLC

9-2 
Fundamentals of Industrial Electronics
travel across the base, and are then collected by the reverse biased CB junction. Therefore, the collec-
tor current is transported from the EB junction, and thus is proportional to the EB junction current. 
In the forward–active mode, the current–voltage characteristic of the EB junction is described by the 
well-known diode equation
	
I  
I
V
V
EF
E
BE
T
=



−






0
1
exp
	
(9.1)
where
IE0 is the EB junction saturation current
VT = kT/q is the thermal potential (about 25 mV at room temperature)
The collector current is typically smaller than the emitter current is, ICF = αFIEF, where αF is the forward 
current gain.
Under reverse mode operation, the CB junction is forward biased and the EB junction is reverse 
biased. Like in the forward mode, the forward-biased CB junction current gives the collector current
	
I
I
V
V
CF
C
BC
T
=



−






0
1
exp
	
(9.2)
where IC0 is the CB junction saturation current. Similarly IER = αRIR, where αR is the reverse current 
gain. Under general biasing conditions, it can be proven that to first order, a superposition of the above-
described forward and reverse mode equivalent circuits can be used to describe the transistor opera-
tion, as shown in Figure 9.1b. The forward transistor operation is described by Equation 9.1, and the 
B
P
C
N
N
(a)
E
B
E
C
(b)
B
E
C
IEF
ICR
IER= αRIER
ICF = αFIEF
(c)
FIGURE 9.1  (a) Cross-sectional view of an NPN BJT, (b) circuit symbol, and (c) the Ebers–Moll equivalent 
circuit model.
© 2011 by Taylor and Francis Group, LLC

Bipolar Junction Transistor 
9-3
reverse transistor operation is described by Equation 9.2. From the Kirchoff’s current law, one can write 
IC = ICF − ICR, IE = IEF − IER, and IB = IE − IC. Using Equations 9.1 and 9.2 the emitter and collector currents 
can be described as
	
I
a
 
V
V
 
a
 
V
V
 
 I
a
 
V
E
BE
T
BC
T
C
=
−



−
−




=
11
12
21
1
1
exp
exp
exp
BE
T
BC
T
V
 
a
 
V
V
 
−



−
−




1
1
22
exp
	
(9.3)
which are known as the Ebers–Moll equations [1]. The Ebers–Moll coefficients aij are given as
	
a
I
a
I
a
I
a
I
11
12
21
22
=
=
=
=
E0
R C0
F E0
C0
α
α
	
(9.4)
The Ebers–Moll coefficients are a very strong function of the temperature
	
a
K T
V
V
ij
x
m
=
exp
go
T 	
(9.5)
where
Kx is proportional to the junction area and is independent of the temperature
Vgo = 1.21 V is the bandgap voltage in silicon (extrapolated to 0 K)
m is a material constant with a value between 2.5 and 4
When both EB and CB junctions are forward biased, the transistor is called to be working in the satura-
tion region. Current injection through the collector junction may activate the parasitic transistors in ICs 
by using a p-type substrate, where the base acts as the emitter, the collector as the base, and the substrate 
as the collector. In typical ICs, bipolar transistors must not operate in saturation. Therefore, for the inte-
grated bipolar transistor the Ebers–Moll equations can be simplified to the form
	
I
a
 
V
V
 
 I
a
 
V
V
 
E
BE
T
C
BE
T
=
−




=
−




11
21
1
1
exp
exp
	
(9.6)
where a21/a11 = αF. This equation corresponds to the circuit diagram shown in Figure 9.1c.
9.2  Gummel–Poon Model
In real bipolar transistors, the current–voltage characteristics are more complex than those described 
by the Ebers–Moll equations. Typical current–voltage characteristics of the bipolar transistor, plotted in 
semi-logarithmic scale, are shown in Figure 9.2. At small-base emitter voltages, due to the generation–
recombination phenomena, the base current is proportional to
	
I
V
V
BL
BE
T
∝exp 2
	
(9.7)
© 2011 by Taylor and Francis Group, LLC

9-4 
Fundamentals of Industrial Electronics
Also, due to the base conductivity modulation at high-level injections, the collector current for larger 
voltages can be expressed by the similar relation
	
I
V
V
CH
BE
T
∝exp 2
	
(9.8)
Note that the collector current for a wide range is given by
	
I
I
V
V
C
s
BE
T
=
exp
	
(9.9)
The saturation current is a function of device structure parameters
	
I
qAn V
N
x dx
i
w
s
T
B
B
B
=
∫
2
0
µ
( )
	
(9.10)
where
q = 1.6 × 10−19 C is the electron charge
A is the EB junction area
ni is the intrinsic concentration (ni = 1.5 × 1010 at 300 K)
μB is the mobility of the majority carriers in the transistor base
wB is the effective base thickness
NB(x) is the distribution of impurities in the base
Note that the saturation current is inversely proportional to the total impurity dose in the base. In the 
transistor with the uniform base, the saturation current is given by
	
I
qAn V
w N
i
s
T
B
B
B
=
2
µ
	
(9.11)
IC
IB
log (IC)
log (IB)
VBE
exp
exp
VBE
VT
VBE
2VT
FIGURE 9.2  Collector and base currents as a function of base–emitter voltage.
© 2011 by Taylor and Francis Group, LLC

Bipolar Junction Transistor 
9-5
When a transistor operates in the reverse-active mode (emitter and collector are switched), then the 
current of such a biased transistor is given by
	
I
I
V
V
E
s
BC
T
=
exp
	
(9.12)
Note that the Is parameter is the same for forward and reverse modes of operation. The Gummel–Poon 
transistor model [2] was derived from the Ebers–Moll model using the assumption that a12 = a21 = Is. For 
the Gummel–Poon model, Equations 9.3 are simplified to the form
	
I
I  
 
V
V
V
V
 I
I
V
V
 
V
E
s
F
BE
T
BC
T
C
s
BE
T
R
BC
=
−




=
−
1
1
α
α
exp
exp
exp
exp VT




	
(9.13)
These equations require only three coefficients, while the Ebers–Moll requires four. The saturation cur-
rent Is is constant for a wide range of currents. The current gain coefficients αF and αR have values 
smaller, but close to unity. Often instead of using the current gain as α = IC/IE, the current gain β as a 
ratio of the collector current to the base current β = IC/IB is used. The mutual relationships between α 
and β coefficients are given by
	
α
β
β
β
α
α
α
β
β
β
α
α
F
F
F
F
F
F
R
R
R
R
R
R
=
+
=
−
=
+
=
−
1
1
1
1
 
	
(9.14)
The Gummel–Poon model was implemented in SPICE [3] and other computer programs for circuit 
analysis. To make the equations more general, the material parameters ηF and ηR were introduced:
	
I
I  
V
V
V
V
C
s
BE
F
T
R
BC
R
T
=
−
+










exp
exp
η
β
η
1
1
	
(9.15)
The values of ηF and ηR vary from one to two.
9.3  Current Gains of Bipolar Transistors
The transistor current gain β, is limited by two phenomena: base transport efficiency and emitter injection 
efficiency. The effective current gain β can be expressed as
	
1
1
1
1
β
β
β
β
  
  
  
=
+
+
I
T
R 	
(9.16)
where
βI is the transistor current gain caused by emitter injection efficiency
βT is the transistor current gain caused by base transport efficiency
βR is the recombination component of the current gain
As one can see from Equation 9.16, smaller values of βI, βT, and βR dominate. The base transport efficiency 
can be defined as a ratio of injected carriers into the base, to the carriers that recombine within the base. 
© 2011 by Taylor and Francis Group, LLC

9-6 
Fundamentals of Industrial Electronics
This ratio is also equal to the ratio of the minority carrier’s lifetime to the transit time of carriers through 
the base. The carrier transit time can be approximated by an empirical relationship
	
τ
µ
η
η
transist
B
T
B
BE
BC
=
+
=




w
V
N
N
2
2
0 9
(
.
) ;
ln
	
(9.17)
where
μB is the mobility of the minority carriers in base
wB is the base thickness
NBE is the impurity doping level at the emitter side of the base
NBC is the impurity doping level at the collector side of the base
Therefore, the current gain due to the transport efficiency is
	
β
τ
τ
η
T
life
transit
B
B
=
=
+




(
.
)
2
0 9
2
L
w
	
(9.18)
where LB = √VTμBτlife is the diffusion length of minority carriers in the base.
The current gain βI, due to the emitter injection efficiency, is given by
	
β
µ
µ
I
B
Eeff
E
B
E
B
= ∫
∫
N
x dx
N
x dx
w
w
( )
( )
0
0
	
(9.19)
where
μB and μE are minority carrier mobilities in the base and in the emitter
NB(x) is the impurity distribution in the base
NEeff is the effective impurity distribution in the emitter
The recombination component of the current gain βR is caused by the different current–voltage rela-
tionship of base and collector currents as can be seen in Figure 9.2. The slower base current increase is 
due to the recombination phenomenon within the depletion layer of the base-emitter junction. Since 
the current gain is a ratio of the collector current to that of the base current the relation for βR can be 
found as
	
β
η
R
R0 C
R
=
−
K
I1
1( /
)
	
(9.20)
As can be seen from Figure 9.2, the current gain β is a function of the current. This gain-current rela-
tionship is illustrated in Figure 9.3. The range of a constant current gain is wide for bipolar transistors 
with a technology characterized by a lower number of generation–recombination centers.
With an increase of the CB voltage, the depletion layer penetrates deeper into the base. Therefore, the 
effective thickness of the base decreases. This leads to an increase of transistor current gain with applied 
collector voltages. Figure 9.4 illustrates this phenomenon known as Early’s effect. The extensions of 
transistor characteristics (dotted lines in Figure 9.4) are crossing the voltage axis at the point—VA, where 
VA is known as the Early voltage. The current gain β, as a function of the collector voltage is usually 
expressed by using the relation
© 2011 by Taylor and Francis Group, LLC

Bipolar Junction Transistor 
9-7
	
β
β
=
+




0 1
V
V
CE
A
	
(9.21)
A similar equation can be defined for the reverse mode of operation.
9.4  High Current Phenomena
The concentration of minority carriers increases with the rise of transistor currents. When the concen-
tration of moving carriers exceeds a certain limit, the transistor property degenerates. Two phenomena 
are responsible for this limitation. The first is related to the high concentration of moving carriers (elec-
trons in the npn transistor) in the base–collector depletion region. This is known as the Kirk effect. The 
second phenomenon is caused by a high level of carriers injected into the base. When the concentration 
of injected minority carriers in the base exceeds the impurity concentration there, then the base con-
ductivity modulation limits the transistor’s performance.
To understand the Kirk effect, consider the NPN transistor in the forward-active mode with the 
base–collector junction reversely biased. The depletion layer consists of the negative lattice charge of 
the base region and the positive lattice charge of the collector region. Boundaries of the depletion layer 
are such that the total positive and negative charges are equal. When a collector current that carries the 
negatively charged electrons flows through the junction, the effective negative charge on the base side of 
junction increases. Also, the positive lattice charge of the collector side of the junction is compensated 
by the negative charge of moving electrons. This way, the CB space charge region moves toward the 
collector, resulting in a thicker effective base. With a large current level, the thickness of the base may 
β
T
log (IC)
FIGURE 9.3  The current gain β as the function of the collector current.
VA
VCE
IC
FIGURE 9.4  Current–voltage characteristics of a bipolar transistor.
© 2011 by Taylor and Francis Group, LLC

9-8 
Fundamentals of Industrial Electronics
be doubled or tripled. This phenomenon, known as the Kirk effect, becomes very significant when the 
charge of moving electrons exceeds the charge of the lightly doped collector NC. The threshold current 
for the Kirk effect is given by
	
I
qA
NC
max =
νsat
	
(9.22)
where νsat is the saturation velocity for electrons (νsat = 107 cm/s for silicon).
The conductivity modulation in the base, or high-level injection, starts when the concentration of 
injected electrons into the base exceeds the lowest impurity concentration in the base NBmin. This occurs 
for the collector current Imax given by
	
I
qAN
qAV
N
w
max
max
max(
.
)
<
=
+
B
T
B
B
B
ν
µ
η
2
0 9
	
(9.23)
The above equation is derived using (9.17), for the estimation of the base transient time.
The high current phenomena are significantly enlarged by the current crowding effect. The typical 
cross section of the bipolar transistor is shown in Figure 9.5. The horizontal flow of the base current 
results in the voltage drop across the base region under the emitter. This small voltage difference on the 
base–emitter junction causes a significant difference in the current densities at the junction. This is due 
to the very nonlinear junction–current–voltage characteristics. As a result, the base–emitter junction 
has very nonuniform current distribution across the junction. Most of the current flows through the 
part of the junction closest to base contact. For transistors with larger emitter areas, the current crowd-
ing effect is more significant. This nonuniform transistor current distribution makes the high current 
phenomena, such as the base conductivity modulation and the Kirk effect, start for smaller currents 
than given by Equations 9.22 and 9.23. The current crowding effect is also responsible for the change of 
the effective base resistance with a current. As the base current increases, the larger part of the emitter 
current flows closer to the base contact, and the effective base resistance decreases.
9.5  Small Signal Model
Small signal transistor models are essential for the design of an AC circuit. The small signal equiva-
lent circuit of the bipolar transistor is shown in Figure 9.6a. The lumped circuit shown in Figure 9.6a 
is only an approximation. In real transistors, resistances and capacitances have a distributed char-
acter. For most design tasks, this lumped model is adequate, or even the simple equivalent transistor 
model shown in Figure 9.6b can be considered. The small signal resistances, rπ and ro, are inversely 
proportional to the transistor currents, and the transconductance gm is directly proportional to the 
transistor currents.
Base
Emitter
Collector
n
!
p
IB
n+
FIGURE 9.5  Current crowding effect.
© 2011 by Taylor and Francis Group, LLC

Bipolar Junction Transistor 
9-9
	
r
V
I
V
I
r
V
I
g
I
V
π
η
η
β
η
=
=
=
=
F
T
B
F
T
F
C
A
C
m
C
F
T
;
;
0
	
(9.24)
where
ηF is the forward emission coefficient, ranging form 1.0 to 2.0
VT is the thermal potential (VT = 25 mV at room temperature)
Similar equations to (9.24) can be written for the reverse transistor operation as well.
The series base, emitter, and collector resistances RB, RE, and RC are usually neglected for simple 
analysis (Figure 9.6b). However, for high-frequency analysis it is essential to use at least the base series 
resistance RB. The series emitter resistance RE usually has a constant and bias independent value. The 
collector resistance RC may significantly vary with the biasing current. The value of the series collec-
tor resistance may lower by one or two orders of magnitude if the collector junction becomes forward 
biased. A large series collector resistance may force the transistor into the saturation mode. Usually 
however, when the collector–emitter voltage is large enough, the effect of the collector resistance is not 
significant. The SPICE model assumes a constant value for the collector resistance RC.
The series base resistance RB may significantly limit the transistor performance at high frequencies. 
Due to the current crowding effect and the base conductivity modulation, the series base resistance is a 
function of the collector current IC [4]
	
R
R
R
R
I
I
B
B
B
B
C
KF
=
+
−
+
+
min
min
.
.
(
/
)
0
0 5
0 25
	
(9.25)
where
IKF is βF high-current roll-off current
RB0 is the base resistance at very small currents
RBmin is the minimum base resistance at high currents
Another possible approximation of the base series resistance RB, as the function of the base current IB, is [4]
	
R
R
R
z
z
z
z
R
z
I
I
B
B
B
B
B
RB
=
−
−
+
=
+
−
3
1
1 44
1
24
0
2
2
(
) tan
tan
( .
/
)
(
/
min
min
π
π2) (
/
)
I
I
B
RB
	
(9.26)
where IRB is the base current for which the base resistance falls halfway to its minimum value.
rπ
ro
gmv1
CBE
CBC
E
C
B
+
–
v1
(b)
RE
RB
rπ
ro
gmv1
CBE
CCS
RC
XCJCCBC
(1– XCJC) CBC
E
S
C
B
+
(a)
–
v1
FIGURE 9.6  Bipolar transistor equivalent diagrams: (a) SPICE model and (b) simplified model.
© 2011 by Taylor and Francis Group, LLC

9-10 
Fundamentals of Industrial Electronics
The base–emitter capacitance CBE is composed of two terms: the diffusion capacitance, which is pro-
portional to the collector current, and the depletion capacitance, which is a function of the base–emitter 
voltage VBE. The CBE capacitance is given by
	
C
I
V
C
V
V
m
BE
F
C
F
T
JE0
BE
JE
JE
=
+
−




−
τ η
1
0
	
(9.27)
where
VJE0 is the base–emitter junction potential
τF is the base transit time for the forward direction
CJE0 is base–emitter zero-bias junction capacitance
mJE is the base–emitter grading coefficient
The base–collector capacitance CBC is given by a similar expression as Equation 9.27. In the case when 
the transistor operates in the forward-active mode, it can be simplified to
	
C
C
V
V
m
BC
JC
BC
JC0
JC
=
−




−
0 1
	
(9.28)
where
VJC0 is the base–collector junction potential
CJC0 is the base–collector zero-bias junction capacitance
mJC is the base–collector grading coefficient
In the case when the bipolar transistor is in the integrated form, the collector–substrate capacitance 
CCS has to be considered
	
C
C
V
V
m
CS
JS
CS
JS0
JS
=
−




−
0 1
	
(9.29)
where
VJS0 is the collector–substrate junction potential
CJS0 the collector–substrate zero-bias junction capacitance
mJS is the collector–substrate grading coefficient
When the transistor enters saturation, or it operates in the reverse-active mode, Equations 9.27 and 
9.28 should be modified to
	
C
I
V
V
V
 C
V
V
m
BE
F
S
BE
F
T
F
T
JE0
BE
JE0
JE
=
+
−




−
τ
η
η
exp(
/
)
1
	
(9.30)
	
C
I
V
V
V
 C
V
V
m
BC
R
S
BC
R
T
R
T
JC0
BC
JC0
JC
=
(
) +
−




−
τ
η
η
exp
/
1
	
(9.31)
9.6  Technologies
The bipolar technology was used to fabricate the first ICs more than 40 years ago. A similar stan-
dard bipolar process is still used. In recent years, for high performance circuits and for BiCMOS 
technology, the standard bipolar process was modified by using the thick selective silicon oxidation 
© 2011 by Taylor and Francis Group, LLC

Bipolar Junction Transistor 
9-11
instead of the p-type isolation diffusion. Also, the diffusion process was substituted by the ion 
implantation process, low temperature epitaxy, and CVD.
9.6.1  Integrated NPN Bipolar Transistor
The structure of the typical integrated bipolar transistor is shown in Figure 9.7. The typical impurity 
profile of the bipolar transistor is shown in Figure 9.8. The emitter doping level is much higher than 
the base doping, so large current gains are possible (see Equation 9.19). The base is narrow and it has 
an impurity gradient, so the carrier transit time through the base is short (see Equation 9.17). Collector 
concentration near the base collector junction is low, therefore, the transistor has a large breakdown 
voltage, large Early voltage VAF, and CB depletion capacitance is low. High impurity concentration in 
the buried layer leads to a small collector series resistance. The emitter strips have to be as narrow as 
technology allows, reducing the base series resistance and the current crowding effect. If large emitter 
area is required, many narrow emitter strips interlaced with base contacts have to be used in a single 
transistor. Special attention has to be taken during the circuit design, so the base–collector junction is 
not forward biased. If the base–collector junction is forward biased, then the parasitic PNP transistors 
activate. This leads to an undesired circuit operation. Thus, the integrated bipolar transistors must not 
operate in reverse or in saturation modes.
5 μm
5 μm
n+-Buried layer 
p+
p+
p
n+
n+
n-Epi 
p– Substrate 
E
C
B
FIGURE 9.7  NPN bipolar structure.
1020
1019
1018
1017
1016
1
μm
N
Buried
Epi 
Base 
Emitter 
n+
p
n
n+
 4 
3
2 
FIGURE 9.8  Cross section of a typical bipolar transistor.
© 2011 by Taylor and Francis Group, LLC

9-12 
Fundamentals of Industrial Electronics
9.6.2  Lateral and Vertical PNP Transistors
The standard bipolar technology is oriented for the fabrication of the NPN transistors with the structure 
shown in Figure 9.7. Using the same process, other circuit elements, such as resistors and PNP transistors, 
can be fabricated as well.
The lateral transistor, shown in Figure 9.9a, uses the base p-type layer for both the emitter and collector fab-
rications. The vertical transistor, shown in Figure 9.9b, uses the p-type base layer for the emitter, and the p-type 
substrate as the collector. This transistor is sometimes known as the substrate transistor. In both transistors, the 
base is made of the n-type epitaxial layer. Such transistors with a uniform and thick base are slow. Also, the cur-
rent gain β of such transistors is small. Note that the vertical transistor has the collector shorted to the substrate 
as Figure 9.10b illustrates. When a PNP transistor with a large current gain is required, then the concept of the 
composite transistor can be implemented. Such a composite transistor, known also as the super-beta transistor, 
consists of a PNP lateral transistor, and the standard NPN transistor is connected, as shown in Figure 9.10c. 
The composed transistor acts as the PNP transistor and it has a current gain β approximately equal to βpnpβnpn.
9.7  Model Parameters
It is essential to use proper transistor models in the computer-aided design tools. The accuracy of 
simulation results depends on the model’s accuracy, and on the values of the model parameters used. 
In this section, the thermal sensitivity and second order effects in the transistor model are discussed. 
The SPICE bipolar transistor model parameters are also discussed.
n+-Buried layer 
p+
p+
n+
n-Epi 
p–-Substrate 
E
C
B
(a)
(b)
n+
p
p
p
B
C
p+
p+
n-Epi 
p–-Substrate 
E
n+
p
B
C
FIGURE 9.9  Integrated PNP transistors: (a) lateral PNP transistor and (b) substrate PNP transistor.
B
E
(b)
B
E
C
(a)
(c)
=~
B
B
E
E
C
C
β1β2
β2
β1
FIGURE 9.10  Integrated PNP transistors: (a) lateral transistor, (b) substrate transistor, and (c) composed transistor.
© 2011 by Taylor and Francis Group, LLC

Bipolar Junction Transistor 
9-13
9.7.1  Thermal Sensitivity
All parameters of the transistor model are temperature dependent. Some parameters are very strong 
functions of temperature. To simplify the model description, the temperature dependence of some 
parameters is often neglected. In this chapter, the temperature dependence of the transistor model 
is described based on the model of the SPICE program [3–5]. Deviations from the actual tempera-
ture dependence will also be discussed. The temperature dependence of the junction capacitance 
is given by
	
C T
C
m  
 T
T
V T
V
J
J
J
NOM
J
J
( )
.
( )
=
+
×
−
(
) +
−

















−
1
4 0 10
1
4



	
(9.32)
where TNOM is the nominal temperature, which is specified in the SPICE program in the .OPTIONS 
statement. The junction potential VJ(T) is a function of temperature
	
V T
V
T
T
V
T
T
E T
E
T
T
J
J
NOM
T
NOM
G
G
NOM
( )
ln
( )
=
−



−
+
3
	
(9.33)
The value of 3, in the multiplication coefficient of above equation is from the temperature dependence 
of the effective state densities in the valence and conduction bands. The temperature dependence of the 
energy gap is computed in the SPICE program from
	
E T
E
T
T
G
G
( )
.
=
−
×
+
−
7 02 10
1108
4
2
	
(9.34)
The transistor saturation current as a function of temperature is calculated as
	
I T = I  
T
T
E
T
T
V T
 
X
s
s
NOM
G
NOM
T
NOM
TI
( )
exp




−
(
)




	
(9.35)
where EG is the energy gap at the nominal temperature. The junction leakage currents ISE and ISC are 
calculated using
	
I
T = I  
T
T
E
T
T
V T
 
X
X
SE
SE
NOM
G
NOM
E
T
NOM
TI
TB
( )
exp




−
(
)




−
η
	
(9.36)
and
	
I
T = I
 
T
T
E
T
T
V T
 
X
X
SC
SC
NOM
G
NOM
C
T
NOM
TI
TB
( )
exp




−
(
)




−
η
	
(9.37)
The temperature dependence of the transistor current gains βF and βR are modeled in the SPICE as
	
β
β
β
β
F
F
NOM
R
R
NOM
( )
( )
T
 
T
T
T
 
T
T
X
X
=




=




TB
TB
	
(9.38)
© 2011 by Taylor and Francis Group, LLC

9-14 
Fundamentals of Industrial Electronics
The SPICE model does not give accurate results for the temperature relationship of the current gain β 
at high currents. For high current levels, the current gain decreases sharply with the temperature, as can 
be seen from Figure 9.3. Also, the knee current parameters IKF, IKR, IKB are temperature dependent, 
and this is not implemented in the SPICE program.
9.7.2  Second Order Effects
The current gain β is sometimes modeled indirectly by using different equations for the collector and 
base currents [4,5]
	
I
I T
Q
 
V
V
V
V
I T
T  
V
C
s
b
BE
F
T
BC
R
T
s
R
BC
R
=
−



−
( ) exp
exp
( )
( ) exp
η
η
β
η V
I
T  
V
V
T
SC
BC
C
T
−



−
−




1
1
( ) exp η
	
(9.39)
where
	
Q
Q
V
V
V
V
X
b
BC
AF
BE
AR
=
+
+
−
−
(
)
1
1
4
2 1
(
/
)
(
/
) 	
(9.40)
and
	
Q
I T
I
V
V
I T
I
V
V
X =
−



+
−




s
KF
BE
F
T
s
KR
BC
R
T
( ) exp
( ) exp
η
η
1
1
	
(9.41)
	
I
I  
V
V
I
V
V
I  
V
B
s
F
BE
F
T
SE
BE
E
T
s
R
=
−



+
−



+
β
η
η
β
exp
exp
exp
1
1
BC
R
T
SC
BC
C
T
η
η
V
I
V
V
−



+
−




1
1
exp
	
(9.42)
where
ISE is the base–emitter junction leakage current
ISC is the base–collector junction leakage current
ηE is the base–emitter junction leakage emission coefficient
ηC is the base–collector junction leakage emission coefficient
The forward transit time τF is a function of biasing conditions. In the SPICE program, the τF parameter 
is computed by using
	
τ
τ
F
F
TF
CC
CC
TF
BC
TF
CC
S
BE
=
+
+










=
0 1
1 44
X
I
I
I
V
V
I
I
V
exp .
exp ηF
T
V −



1
	
(9.43)
At high frequencies, the phase of the collector current shifts. This phase shift is computed in the 
SPICE program in the following way:
	
I
 I
j P
C
C
TF
F
( )
exp
ω
ω
τ
=
(
) 	
(9.44)
where PTF is a coefficient for excess phase calculation.
Noise is usually modeled as the thermal noise for parasitic series resistances, and as shot and flicker 
noise for collector and base currents
	
i   kT f
R
R
2
4
=
∆
	
(9.45)
© 2011 by Taylor and Francis Group, LLC

Bipolar Junction Transistor 
9-15
where KF and AF are the flicker noise coefficients. More detailed information about noise modeling
	
i
qI
K I
F
 
f
A
B
B
F B
F
2
2
=
+



∆
	
(9.46)
	
i  
qI
f
C
C
2
2
=
∆	
(9.47)
is given in the bipolar noise chapter of this handbook.
9.7.3  SPICE Model of the Bipolar Transistor
The SPICE model of the bipolar transistor uses similar or identical equations as described in this chapter 
[3–5]. Table 9.1 shows the parameters of the bipolar transistor model and its relation to the parameters 
used in this chapter.
The SPICE (Simulation Program with Integrated Circuit Emphasis [3]) was developed mainly for the 
analysis of ICs. During the analysis, it is assumed that the temperatures of all circuit elements are the 
same. This is not true for power ICs where the junction temperatures may differ by 30 K or more. This is 
obviously not true for circuits composed of the discrete elements where the junction temperatures may 
differ by 100 K and more. These temperature effects, which can significantly affect the analysis results, 
are not implemented in the SPICE program.
Although the SPICE bipolar transistor model uses more than 40 parameters, many features of the 
bipolar transistor are not included in the model. For example, the reverse junction characteristics are 
described by Equation 9.32. This model does not give accurate results. In the real silicon junction, the 
leakage current is proportional to the thickness of the depletion layer, which is proportional to V1/m. 
Also, the SPICE model of the bipolar transistor assumes that there is no junction breakdown voltage. 
A more accurate model of the reverse junction characteristics is described in the diode section of this 
handbook. The reverse transit time τR is very important to model the switching property of the lumped 
bipolar transistor, and it is a strong function of the biasing condition and the temperature. Both phe-
nomena are not implemented in the SPICE model.
9.8  SiGe HBTs
The performance of the Si bipolar transistor can be greatly enhanced with proper engineering of 
the base bandgap profile using a narrower bandgap material, SiGe, an alloy of Si and Ge. Structure 
wise, a SiGe HBT is essentially a Si BJT with a SiGe base. Its operation and circuit level performance 
advantages can be illustrated with the energy band diagram in Figure 9.11 [7]. Here the Ge content 
is linearly graded from the emitter toward the collector to create a large accelerating electric field 
that speeds up the minority carrier transport across the base, thus making the transistor speed 
much faster and the cutoff frequency much higher. Everything else being the same, the potential 
barrier for electron injection into the base is reduced, thus exponentially enhancing the collector 
current. The base current is the same for SiGe HBT and Si BJT, as the emitter is typically made the 
same. Beta is thus higher in SiGe HBT. Figure 9.12 confirms these expectations experimentally 
with the data from a typical first generation SiGe HBT technology. The measured doping and Ge 
profiles are shown in Figure 9.13. The metallurgical base width is only 90 nm, and the neutral base 
width is around 50 nm. Figure 9.14 shows the experimental cutoff frequency fT improvement from 
using a graded SiGe base, which also directly translates into maximum oscillation frequency fmax 
improvement.
© 2011 by Taylor and Francis Group, LLC

9-16 
Fundamentals of Industrial Electronics
TABLE 9.1  Parameters of SPICE Bipolar Transistor Model
Name 
Used
Equations
SPICE 
Name
Parameter Description
Unit
Typical 
Value
SPICE 
Default
Is
10, 11
IS
Saturation current
A
10−15
10−16
ISE
39
ISE
B–E leakage saturation current
A
10−12
0
ISC
39
ICS
B–C leakage saturation current
A
10−12
0
βF
14, 16, 21
BF
Forward current gain
—
100
100
βR 
14, 16, 21
BF
Reverse current gain
—
0.1
1
ηF
15, 24, 30, 
31, 39–41
NF
Forward current emission coefficient
—
1.2
1.0
ηR
15, 24, 30 31, 
39–42
NR
Reverse current emission coefficient
—
1.3
1.0
ηE
39
NE
B–E leakage emission coefficient
—
1.4
1.5
ηC
39
NC
B–C leakage emission coefficient
—
1.4
1.5
VAF
21, 40
VAF
Forward Early voltage
V
200
∞
VAR
21, 40
VAR
Reverse Early voltage
V
50
∞
IKF
22, 23, 40
IKF
βF high current roll-off corner
A
0.05
∞
IKR
22, 23, 40
IKR
βR high current roll-off corner
A
0.01
∞
IRB
26
IRB
Current where base resistance falls by half
A
0.1
∞
RB
25, 26
RB
Zero base resistance
Ω
100
0
RBmin
25, 26
RBM
Minimum base resistance
Ω
10
RB
RE
Figure 9.6
RE
Emitter series resistance
Ω
1
0
RC
Figure 9.6
RC
Collector series resistance
Ω
50
0
CJE0
27
CJE
B–E zero-bias depletion capacitance
F
10−12
0
CJC0
28
CJC
B–C zero-bias depletion capacitance
F
10−12
0
CJS0
29
CJS
Zero-bias collector–substrate capacitance
F
10−12
0
VJE0
27
VJE
B–E built-in potential
V
0.8
0.75
VJC0
28
VJC
B–C built-in potential
V
0.7
0.75
VJS0
29
VJS
Substrate junction built-in potential
V
0.7
0.75
mJE
27
MJE
B–E junction exponential factor
—
0.33
0.33
mJC
28
MJC
B–C junction exponential factor
—
0.5
0.33
mJS
29
MJS
Substrate junction exponential factor
—
0.5
0
XCJC
Figure 9.6
XCJC
Fraction of B–C capacitance connected to 
internal base node (see Figure 9.6)
—
0.5
0
τF
17, 28, 30, 42
TF
Ideal forward transit time
s
10−10
0
τR
31
TR
Reverse transit time
s
10−8
0
XTF
43
XTF
Coefficient for bias dependence of τF
—
0
VTF
43
VTF
Voltage for τF dependence on VBC
V
∞
ITF
43
ITF
Current where τF = f(IC,VBC) starts
A
0
PTF
44
PTF
Excess phase at freq = 1/(2πτF) Hz
deg
0
XTB
38
XTB
Forward and reverse beta temperature exponent
0
EG
34
EG
Energy gap
eV
1.1
1.11
XTI
35–37
XTI
Temperature exponent for effect on Is
—
3.5
3
KF
46
KF
Flicker-noise coefficient
—
0
AF
46
AF
Flicker-noise exponent
—
1
FC
FC
Coefficient for the forward-biased depletion 
capacitance formula
—
0.5
0.5
TNOM
32–38
TNOM
Nominal temperature specified in OPTION 
statement
K
300
300
© 2011 by Taylor and Francis Group, LLC

Bipolar Junction Transistor 
9-17
9.8.1  Operation Principle and Performance Advantages over Si BJT
In modern transistors, particularly with the use of polysilicon emitter, beta may be sufficient. If so, 
the higher beta potential of SiGe HBT can then be traded for reduced base resistance, using higher 
base doping. The unique ability of simultaneously achieving high beta, low base resistance, and 
high cutoff frequency makes SiGe HBT attractive for many RF circuits. Broadband noise is natu-
rally reduced, as low base resistance reduces transistor input noise voltage, and high beta as well as 
high fT reduces transistor input noise current [7]. Experimentally, 1/f noise at the same base cur-
rent was found to be approximately the same for SiGe HBT and Si BJT [8]. Consequently, 1/f noise 
is often naturally reduced in SiGe HBT circuits for the same biasing collector current, as the base 
current is often smaller due to a higher beta, as shown in Figure 9.15, by using the corner frequency 
as a figure-of-merit.
p-SiGe
base
Ge
h+
e–
ΔEg,Ge (x = 0)
ΔEg,Ge (x= Wb)
p-Si
n-Si
collector
n+ Si
emitter
Ec
Ev
FIGURE 9.11  Energy band diagram of a graded base SiGe HBT and a comparably constructed Si BJT.
EB voltage (v)
Collector and base currents (A)
0.4
10–10
10–8
4.51×
Si BJT
IB
IC
AE= 0.8 × 2.5 μm2
RBI= 5–8 kΩ/
VCB= 0.0 V
SiGe HBT
10–6
10–4
10–2
0.5
0.6
0.7
0.8
0.9
1.0
FIGURE 9.12  Experimental collector and base currents versus EB voltage for SiGe HBT and Si BJT.
© 2011 by Taylor and Francis Group, LLC

9-18 
Fundamentals of Industrial Electronics
These, together with circuit level optimization can lead to excellent low phase noise oscillators and 
frequency synthesizers suitable for both wireless and wire line communication circuits. Another less 
obvious advantage from grading Ge is the collector side of the neutral base that has less impact on the 
collector current than the emitter side of the neutral base. Consequently, as the collector voltage varies 
and the collector side of the neutral base is shifted toward the emitter due to increased CB junction-
depletion layer thickness, the collector current is increased to a much lesser extent than in a comparably 
constructed Si BJT, leading to a much higher output impedance or Early voltage. The β × VA product is 
thus much higher in SiGe HBT than in Si BJT.
9.8.2  Industry Practice and Fabrication Technology
The standard industry practice today is to integrate SiGe HBT with CMOS to form a SiGe BiCMOS 
technology. The ability to integrate with CMOS is also a significant advantage of SiGe HBT over III–V 
HBT. Modern SiGe BiCMOS combines the analog and RF performance advantages of the SiGe HBT, 
0
1016
1017
1018
1019
1020
1021
200
B
As
Poly
P
As
Ge
SiGe HBT (trapezoidal proﬁle)
Xj (EB) = 35 nm
WB(metallurgical) = 90 nm
400
Depth (nm)
Dopant concentration (cm–3)
Germanium (%)
600
800
0
2.5
5.0
7.5
10.0
FIGURE 9.13  Measured doping and Ge profiles of a modern SiGe HBT.
0.1
0
10
20
30
40
SiGe HBT
Si BJT
5.0×
1.7×
AE=0.5×2.5 μm2
RBI=5–8 kΩ/
VCB=1.0 V
50
60
0.2
0.3
0.5
Collector current (mA)
Cutoﬀ frequency (GHz)
1.0
2.0
3.0
FIGURE 9.14  Experimental cutoff frequency versus collector current for the SiGe HBT and Si BJT.
© 2011 by Taylor and Francis Group, LLC

Bipolar Junction Transistor 
9-19
and the lower power logic, high integration level, and memory density of Si CMOS, into a single cost 
effective system-on-chip (SoC) solution. Typically, SiGe HBTs with multiple breakdown voltages are 
offered through the selective collector implantation, to provide more flexibility in the circuit design.
The fabrication process of SiGe HBT and its integration with CMOS has been constantly evolving 
in the past two decades, and varies from company to company. Below are some common fabrication 
elements and modules shared by many, if not all, commercial first generation (also most widespread in 
manufacturing at present) SiGe technologies:
	
1.	 A starting N
+ subcollector around 5 Ω/square on a p-type substrate at 5 × 1015/cm3, typically pat-
terned to allow CMOS integration.
	
2.	 A high temperature, lightly doped n-type collector, around 0.4–0.6 μm thick at 5 × 1015/cm3.
	
3.	 Polysilicon filled deep trenches for isolation from adjacent devices, typically 1 μm wide and 
7–10 μm deep.
	
4.	 Oxide filled shallow trenches or LOCOS for local device isolation, typically 0.3–0.6 μm deep.
100
SiGe LN1
SiGe LN2
SiGe control
Si BJT
80
60
40
20
0
0
0.2
0.4
0.6
JC (mA/μm2)
fC (kHz)
0.8
1.0
1.2
FIGURE 9.15  Experimentally measured corner frequency as a function of collector current density for three SiGe 
HBTs with different base SiGe designs, and a comparatively constructed Si BJT.
Copper
Deep trench
isolation
Oxide
removed
N collector
E
N
P
SiGe
STI
Tungsten
B
C
N+ subcollector
P substrate
Dielectric
FIGURE 9.16  Structure of a modern SiGe HBT.
© 2011 by Taylor and Francis Group, LLC

9-20 
Fundamentals of Industrial Electronics
	
5.	 An implanted collector reaches through to the subcollector, typically at 10–20 Ωμm2.
	
6.	 A composite SiGe epilayer consisting of a 10–20 nm Si buffer, a 70–100 nm boron-doped SiGe 
active layer, with or without C doping to help suppress boron out diffusion, and a 10–30 nm Si cap. 
The integrated boron dose is typically 1–3 × 1013/cm2.
	
7.	 A variety of EB self-alignment scheme, depending on the device structure and SiGe growth 
approach. All of them utilize some sort of spacer that is 100–300 nm wide.
	
8.	 Multiple self-aligned collector implantations to allow multiple breakdown voltages on the same 
chip.
	
9.	 Polysilicon extrinsic base, usually formed during SiGe growth over shallow trench oxide, and 
additional self-aligned extrinsic implantation to lower base resistance.
	 10.	 A silicided extrinsic base.
	 11.	 A 100–200 nm thick heavily doped (>5 × 1020/cm3) polysilicon emitter, either implanted or in situ 
doped.
	 12.	 A variety of multiple level back-end-of-line metallization schemes using Al or Cu, typically 
borrowed from the parent CMOS process.
These technological elements can also be seen in the electronic image of a second generation SiGe HBT 
shown in Figure 9.16.
References
	
1.	 J. J. Ebers and J. M. Moll, Large signal behavior of bipolar transistors. Proceedings IRE 42(12), 
1761–1772, December 1954.
	
2.	 H. K. Gummel and H. C. Poon, An integral charge-control model of bipolar transistors. Bell System 
Technical Journal 49, 827–852, May 1970.
	
3.	 L. W. Nagel and D. O. Pederson, SPICE (Simulation Program with Integrated Circuit Emphasis). 
University of California, Berkeley, ERL Memo No. ERL M382, April 1973.
	
4.	 P. Antognetti and G. Massobrio, Semiconductor Device Modeling with SPICE, McGraw-Hill, 
New York, 1988.
	
5.	 A. Vadimiresku, The SPICE Book, John Wiley & Sons, Hoboken, NJ, 1994.
	
6.	 R. S. Muller and T. I. Kamins, Device Electronics for Integrated Circuits, 2nd edn., John Wiley & Sons, 
New York, 1986.
	
7.	 J. D. Cressler and G. Niu, Silicon–Germanium Heterojunction Bipolar Transistor, Artech House, 
Boston, MA, 2003.
	
8.	 G. Niu, Noise in SiGe HBT RF technology: Physics, modeling and circuit implications. Proceedings 
of the IEEE, 93(9), 1583–1597, September 2005.
© 2011 by Taylor and Francis Group, LLC

10-1
10.1  Introduction
There are several different types of field effect transistors (FETs), each of which has a different opera-
tional principle. For example, there are metal oxide semiconductor (MOS) transistors, junction field 
effect transistors (JFETs), static induction transistors (SITs), the punch-through transistors (PTTs), and 
others. All of these devices employ the flow of majority carriers. The most popular one among this group 
is the MOS transistor, which is primarily used in integrated circuits [T99,N06,S05]. In contrast, the 
JFET is not suitable for integration and so it is primarily fabricated as an individual device [E97,R99]. 
All FETs have very large input resistance on the order of 1012 Ω. The MOS transistor typically operates 
with very small currents [N02], and thus for power electronics applications, thousands of MOS transis-
tors are connected in parallel. A JFET usually operates with larger currents. Both JFET and MOS tran-
sistors have relatively small transconductances, and this means that they cannot control current flow 
as effectively as bipolar junction transistors (BJTs). Since the parasitic capacitors are of the same order 
of magnitude, BJTs can charge and discharge these capacitors much faster and so BJTs are more suit-
able for high-frequency operations. Because current flow in MOS transistors is very close to the silicon 
surface where surface states can fluctuate with time, MOS devices have a relatively higher noise level, 
especially at low frequencies.
10.2  MOS Transistor
The MOS transistor can be considered a capacitor in which the applied voltage to the gate G would 
attract carriers (elections in NMOS and holes in PMOS) from the semiconductor substrate. This layer 
of accumulated carriers near the surface conducts current between source and drain [T99]. If the volt-
age on the gate is increased, then more carries (electrons or holes) will be accumulated near the surface, 
causing a larger current to flow, as indicated in Figure 10.1. In order to better understand the process of 
carrier accumulation under the gate, the MOS structure must be analyzed in detail.
10
Field Effect Transistors
10.1	 Introduction.....................................................................................10-1
10.2	 MOS Transistor................................................................................10-1
MOS Structure and Threshold Voltage  •  MOS Transistor Current 
Characteristics  •  Second-Order Effects on a MOS Transistor
10.3	 Junction Field Effect Transistor...................................................10-10
10.4	 Static Induction Transistor...........................................................10-13
Theory of SIT Operation for Small Currents  •  Theory of SIT 
for Large Currents  •  Bipolar Mode of Operation of the SIT
10.5	 Lateral Punch-Through Transistor.............................................10-17
10.6	 Power MOS Transistors................................................................10-19
References����������������������������������對������������������������������������對����������������������������10-21
Bogdan M. 
Wilamowski
Auburn University
J. David Irwin
Auburn University
© 2011 by Taylor and Francis Group, LLC

10-2 
Fundamentals of Industrial Electronics
10.2.1  MOS Structure and Threshold Voltage
Figure 10.2 shows the cross section of the MOS band structure with a p-type silicon substrate. Note that 
the Fermi level has a different location in every material. In metals, there is no forbidden energy gap, 
and the Fermi level EFm is on the edge of the conduction band. Albert Einstein received his Nobel Prize 
for the photoelectric effect, in which he was able to measure the energy required to free an electron from 
metal to the vacuum. This energy is now known as the work function ϕm. Work functions for various 
materials are shown in Table 10.1.
It is important to note that the Fermi levels in semiconductors may depend on the doping level N 
and on the type of impurities present. In the n-type material, the Fermi level EFs is above the center of 
the energy gap Ei and in the p-type material, the Fermi level EFs is below Ei, as shown in Figure 10.2. 
The work function ϕs for intrinsic, i.e., undoped, silicon is 3.8 eV, as listed in Table 10.1, and the energy 
needed to free an electron from the p-type silicon is
	
φ
φ
φ
s
F
F
T
i
V
N
n
=
+
=




3 8.
ln
where
A
	
(10.1)
and this energy is dependent on the acceptor doping level NA and intrinsic carrier concentration ni. At 
room temperature in silicon ni = 1010 cm−3. Similarly, in the n-type silicon:
	
φ
φ
s
F
F
T
D
i
V
N
n
=
−
=




3 8.
ln
where φ
	
(10.2)
+
G
S
D
Figure 10.1  The principle of operation for an NMOS transistor, where electrons are accumulated by the positive 
gate voltage.
EFm
EFs
EC
Metal
Oxide
Silicon
p-type
EV
Evac
qφs
qφF
Ei
Evac
 
qφm
Figure 10.2  The location of Fermi levels in metal and in the silicon.
© 2011 by Taylor and Francis Group, LLC

Field Effect Transistors 
10-3
and ND is the donor doping level. When positive voltage VG is applied to the gate, the metal’s band 
structure will move down by qVG, as shown in Figure 10.3, and the depletion layer in the silicon will be 
formed.
Figure 10.3 shows the case with the gate (metal) biasing exactly at the threshold as the accumulation 
layer of carriers at the silicon surface is just being formed. This particular state, called strong inversion, 
is one in which the silicon surface is now an n-type level with the same electron concentration as the 
hole concentration in the bulk p-type silicon. It also means the voltage drop on the depletion layer is
	
Vd
F
= 2φ 	
(10.3)
Knowing the voltage drop Vd, the thickness w of the depletion layer can be found from
	
w
V
qN
qN
o
Si
d
o
Si
F
=
=
2
4
ε ε
ε ε φ
	
(10.4)
where
	
ε
ε
Si
o =
 
=
⋅
−
11.8
F/cm
8 85 10 14
.
	
(10.5)
and N is the impurity concentration in the silicon substrate. The charge of ionized impurities in the 
depletion layer is
	
 
4
6.68 10
 
31
Q
qNw
qN
N
d
Si
o
F
F
=
=
=
ε ε
−
φ
φ
.
	
(10.6)
EFm
E∞
qφs
qφs
qφm
qφF
qφF
qφF
Metal
Oxide
Silicon
depletion
layer
Silicon
p-type
qVG
dox
w
Figure 10.3  MOS band structure with positive voltage on the gate VG in p-type silicon.
Table 10.1  Work Functions ϕm for Various Materials
Si
p+Si
n+Si
Al
Mo
Au
Cu
ϕm (eV)
3.8
4.5
3.05
3.2
3.95
4.1
3.8
© 2011 by Taylor and Francis Group, LLC

10-4 
Fundamentals of Industrial Electronics
On top of the depletion layer charge, there exists a silicon surface charge Qss that depends on the silicon 
crystal orientation as indicated in Table 10.2.
Since the MOS structure can be considered as a capacitor, knowledge of the charge in silicon Qd + Qss 
yields the corresponding voltage
	
 V
Q
Q
C
 
d
ss
ox
=
+
	
(10.7)
The MOS structure unit capacitance is
	
ox
ox
o
ox
ox
d
d
C
3.45 10
( m)  
(F/cm )
9
2
=
=
>
ε ε
µ
.
−
-
	
(10.8)
where dox is the thickness of the oxide and εox = 3.9. In addition to the electrical charges, the voltage drop 
on the depletion layer Vd = 2ϕF and the difference in the work functions should also be considered in 
determining the threshold voltage
	
ms
m
s
m
F
m
F
=
s
s
φ
φ
φ
φ
φ
φ
φ
−
=
−
+
(
) =
−
−
3 8
3 8
.
.
	
(10.9)
where the symbol s indicates the sign, which is
	
s = 
 1
for n channel (p-type impurities)
1
for p channel (n-
−
type impurities)



 
	
(10.10)
In conclusion, the threshold voltage for a MOS structure is given by
	
th
d
ss
F
ms
V
sQ
Q
C
s
=
sqF
+
+
imp
ox
−
+
2φ
φ
	
(10.11)
Note that the effective charge can be controlled by ion implantation using Fimp dose (cm−2), which can be 
made from p-type or n-type impurities, and as a result, the threshold voltage can be properly adjusted.
Example 10.1
Calculate the threshold voltage Vth for a MOS transistor with a p+ polysilicon gate and a p-type substrate 
with NA = 1016 cm−3. Assume a <100> crystal orientation and a dox = 0.1 μm. Find the implantation dose 
required for adjusting the threshold voltage to Vth = +2 V. Specify if boron or phosphor should be used 
for implantation. The calculations required for this example are
	
F
T
i
F
 = V
N
n
φ
φ
ln
.
ln .
.
.
=
=
=
0 0258
10
1 5 10
0 347
2
0 694
16
10
	
Table 10.2  Surface Charges in Silicon for Various Crystal Orientations
Crystal Orientation
〈111〉
〈110〉
〈100〉
Number of surface states Qss/q (cm−2)
1.5 · 1011
1011
2 · 1010
Surface charge Qss (C)
2.4 · 10−8
1.6 · 10−8
3.2 · 10−9
© 2011 by Taylor and Francis Group, LLC

Field Effect Transistors 
10-5
	
s =
 1 for n channel (p- type substrate)
1 for p channel (n- typ
−
e substrate)



= +
=
1
3 8
4 5
3
 
=
=
+s
  
 
  
ms
m
s
s
F
ms
φ
φ
φ
φ
φ
φ
−
−
.
.
.
( 8
4
3 8
0 347
0 353
 + s
+
F
φ )
(
)
.
.
.
.
=
=
5−
	
	
 Q = qNw =
qN =
N
d
Si
o
F
F
4
6 68 10
6 68 10
0 347 10
4 8
31
31
16
ε ε φ
φ
.
.
.
.
⋅
=
⋅
⋅
⋅
=
−
−
145 10 8
⋅
− 	
	
SS
Q
<
>
−

→

⋅
100
9
3 3 10
.
	
	
ox
ox
o
ox
ox
C
=
d
=
d
 
ε ε
3 45 10
10
0 1
3 45 10
9
9
8
.
.
.
⋅
=
⋅
⋅
−
−
−
 ( m)
3.45
(F/cm
µ
2) 
	
	
th
d
ox
F
ms
ss
ox
V = s Q
C
+s
+
Q
C
2
4 8145
0 32
3 45
0 694
0 353
2 3
φ
φ
−
=
−
+
+
=
.
.
.
.
.
. 5
	
Since the requirement specifies a Vth = 2 V, this value must be lowered by 0.35 V:
	
∆
∆
V = qF
C
F
=
V C
th
imp
ox
imp
th ox
q
=
⋅
⋅
⋅
=
⋅
−
−
0 35 3 45 10
1 6 10
7 54 10
8
19
.
.
.
.
10
2
atm/cm
	
The threshold voltage obtained from Equation 10.11 is valid for the case in which the substrate has the 
same potential as the source for the MOS transistor. If the substrate is biased with an additional voltage 
VSB, then due to the substrate biasing, the threshold voltage will change by
	
∆V
qN
C
V
V
th
Si
o
ox
F
SB
F
F
SB
F
=
+
−
(
) =
+
−
(
)
2ε ε
φ
φ
γ
φ
φ
2
2
2
2
	
(10.12)
10.2.2  MOS Transistor Current Characteristics
Depending on the value of the drain-source voltage VDS, the MOS transistor characteristics are described 
by different formulas. For small values of VDS, known as the “linear” or “triode” region, the current is 
a strong function of the drain voltage, as shown in Figure 10.4. For large values of VDS known as the 
“current saturation” or “pentode” region, the current is almost independent of the drain voltage. The 
current–voltage characteristics are often approximated by the formula:
	
I =
K
V
+ V
K
V
V
D
DS
DS
DS
DS
DS
( )
0.5
1
for
for
∆
−
+
V
V
2
2
0 5
1


≤∆
∆
(
)
.
( ) (
)
λ
λ
DS
  
≥∆



	
(10.13)
© 2011 by Taylor and Francis Group, LLC

10-6 
Fundamentals of Industrial Electronics
where Δ shows how much the gate voltage VGS exceeds the threshold voltage Vth, i.e.,
	
∆=
GS
th
V
V  
−
	
(10.14)
	
 K
K W
L
C
W
L
ox
=
=
′
µ
	
(10.15)
The λ parameter describes the slope of the output characteristics in the current saturation region. The 
typical values of the λ parameter are 0.02 to 0.04 [V−1]. For small signal analysis, a MOS transistor in the 
current saturation region can be described by two parameters rm and ro:
	
r = g
I
= K
=
KI
  
m
m
D
D
1
2
1
1
2
= ∆
∆
	
(10.16)
	
r =
I
o
D
1
λ
	
(10.17)
Figure 10.5 shows a small-signal equivalent model of the MOS transistor. For the voltage-controlled 
circuit, the input capacitances need not to be included, i.e., input capacitance is a part of the previous 
stage. Assuming that the loading capacitance C is the capacitance of the identical transistor of the next 
stage C = CoxWL, the maximum frequency of operation is
	
max
f
=
r
r C
C
W
L I
2 C WL
I
C W
L
m
o
ox
D
ox
D
ox
1
2
2
2
2π
µ
π
µ
π
||
(
)
≈
=
	
(10.18)
Slope = λID
VGS
VGS–Vth= Δ > VDS
ID
VDS
Linear
region
Current
saturation
region
ID= 0.5 KV2
VGS–Vth= Δ <VDS
DS
Figure 10.4  Output characteristics for MOS transistors.
ro
gm VGS
VGS
VGS
rm
D
+
–
G
S
C
Figure 10.5  Small-signal equivalent model for a MOS transistor.
© 2011 by Taylor and Francis Group, LLC

Field Effect Transistors 
10-7
Example 10.2
Consider the NMOS transistor described in Example 10.1 with Vth = +2 V. Neglecting the channel-length 
modulation (), and assuming the following parameters: electron mobility λ = 0.03, μ = 600 cm2/Vs, L = 2 μm 
and W = 20 μm, calculate
	
a.	 Drain current for VGS = 4 V and VDS = 1 V
	
b.	 Drain current for VGS = 4 V and VDS = 10 V
	
c.	 Maximum frequency for VGS = 4 V and VDS = 10 V
	
a.
=
= 600 3.45 10
20
2 = 0.2 10
= 200 A/ V
8
3
2
K
C
W
L
ox
µ
µ
⋅
⋅
⋅
−
−
	
	
I
K
V
V V
V
 
V
=
D
GS
th
DS
DS
DS
=
−
−




+
⋅
⋅−




−
(
)
(
)
2
6
2
1
200 10
2 1
1
2
λ
(
)
.
1 0 3
30
+
=
0
9 A
µ
	
	
b.
A
I
K V
V
V
=
D
GS
th
DS
=
−
+
⋅
−
+
=
−
2
1
200 10
2
4
2
1 0 3
520
2
6
2
(
) (
)
(
) (
. )
λ
µ
	
	
c
k
.
.
r =
KI
m
D
1
2
1
2 200
520
2 19
=
⋅
⋅
=
µ
µ
Ω
	
	
r =
I
o
D
1
1
0 03 520
λ
µ
=
⋅
=
Ω
.
64.1k
	
	
C
C WL
ox
=
=
⋅
⋅⋅
⋅
⋅
=
−
−
−
3.45
fF
10
2 10
20 10
13 8
8
4
4
.
	
	
max
f
=
r
r C
m
o
1
1
2 19
64 1
13 8
5 45
2
2
k
k
fF
GHz
π(
)
(
)
||
||
.
.
.
.
=
Ω
=
π
Ω
	
Note that only the gate oxide capacitance was included. Since all other junction parasitic capacitances 
were ignored, the calculated maximum frequency fmax is significantly larger than the actual one.
10.2.3  Second-Order Effects on a MOS Transistor
There are a number of second-order effects that significantly affect the operation of a MOS transistor, such 
as channel-length modulation, carrier velocity limitation, surface mobility degradation, subthreshold con-
duction, etc. [T99]. These effects will now be described with some detail.
10.2.3.1  Channel-Length Modulation
The effect of channel-length modulation is shown in Figure 10.6. The thickness of the depletion layer d 
depends on the drain-substrate voltage and is described by an equation that is similar to Equation 10.4:
	
d
V
qN
o
Si
D
=
2 ε ε
	
(10.19)
© 2011 by Taylor and Francis Group, LLC

10-8 
Fundamentals of Industrial Electronics
As a consequence, the effective channel length Leff is shorter than the distance L between the implanted 
source and drain regions, and, therefore, instead of Equation 10.15, the transconductance coefficient K 
should be expressed as
	
 K
K W
L
K
W
L
V
qN
K W
L
L
V
K W
L
L
V
eff
o
Si
D
D
D
=
=
−
=
−




≈
+


′
′
′
′
2
1
1
1
ε ε
η
η


	
(10.20)
As indicated in Figure 10.6, the effect of channel-length modulation becomes more significant with the 
reduction in channel length. Thus, the textbook formula, i.e., Equation 10.13, using the λ parameter to 
describe the effect of channel-length modulation, and also employed in the basic Spice MOS transistor 
models (Level 2 and Level 3), is not correct. Equation 10.13 implies that for a given drain voltage, the 
ratio between d and Leff is always the same; however, clearly this cannot be true for different channel 
lengths. With longer transistor channels, the effect of channel-length modulation is less significant and 
the output resistance actually increases with the channel-length L.
As Equation 10.19 indicates, the channel-length modulation can be reduced only by increasing the 
impurity concentration N in the silicon. Without a significant increase in impurities, there would 
be a punch-through effect in a short channel transistor. Punch-through occurs when the depletion 
layer thickness d becomes equal to the channel length L, as illustrated in Figure 10.6. Unfortunately, 
a larger impurity concentration in the substrate leads to large parasitic capacitances, and therefore a 
reduction in the transistor size does not result in a similar reduction of the parasitic capacitances. For 
example, it is interesting to note that a significant reduction in the size of transistors in the last decade 
from 0.3 μm to 0.05 μm did not result in any noticeable increase in the computer clock frequencies. 
Of course, there are also other factors that are limiting clock frequencies. One of the most important 
limitations is an ability to dissipate heat, since power dissipation in computer chips is proportional to 
clock frequency.
10.2.3.2  Effect of Carrier Velocity Saturation
Most of the textbook equations are derived with an assumption that the mobility of carriers is con-
stant and independent of the electrical field. Actually, in silicon, the maximum carrier velocity for 
both electrons and holes is vsat = 107 cm/s =1011 μm/s. As indicated in Figure 10.7, the critical field in 
which the velocity saturates is about 1 V/μm. Note that the channel length in modern MOS transistors 
is significantly smaller than 1 μm. Therefore, even reducing the supply voltage below 2 V produces 
an average electrical field in MOS transistors, which is significantly larger than 1 V/μm. Fortunately, 
large electrical fields exist near the drain and significantly smaller electrical fields are near the source, 
and these smaller electric fields shape the transistor current characteristics, so Equations 10.13 are 
p-substrate
n+
n+
S
G
D
Depletion layer
L
Leﬀ
d
Figure 10.6  Channel-length modulation.
© 2011 by Taylor and Francis Group, LLC

Field Effect Transistors 
10-9
still in use even if the drain current in the current saturation region no longer is described by a qua-
dratic equation:
	
I
V
V
D
n
GS
th
~ (
)
−
	
(10.21)
where n has value between 1 and 2.
10.2.3.3  Carrier Mobility Degradation near the Surface
The key feature of MOS transistor operation is the fact that most of the current flows near the silicon 
surface and, as a result of crystal imperfections, carrier mobilities near the surface are reduced. This 
effect becomes even more significant with increased gate voltage when a large electrical field is created 
perpendicular to the direction of current flow. As a consequence, with larger gate voltages, a larger 
number of carriers are accumulated near the surface. However, these carriers are moving slower due 
to surface mobility degradation and the fact that the drain current is not increasing as fast as would 
be predicted by Equation 10.13 with a quadratic relationship. In addition to mobility degradation in 
the transverse electric field, i.e., the gate voltage, there is a strong degradation due to the longitudinal 
electric field, i.e., the drain voltage. As a result, experimental characteristics for short-channel MOS 
transistors exhibit almost linear dependence with gate voltage.
10.2.3.4  Subthreshold Conduction
As illustrated in Section 2.1, as the gate voltage increases, carriers gradually accumulate near the sur-
face. The assumption, that suddenly there is a strong surface inversion where the concentration of 
minority carriers near the surface is exactly the same as the concentration of carriers in the substrate, 
is very artificial. Below and near the threshold, the drain current in a MOS transistor is described by an 
exponential relationship:
	
I
V
V
V
D
ON
GS
th
T
T
GS
th
T
I
V
V
V
V
=
−
−




<
+
exp
for
η
η
η
	
(10.22)
where
	
I
K
V
ON
T
= 2
2
(
)
η
	
(10.23)
v = μE
v = vsat
v
E
s
V
V
1
s
vsat ≈ 1011
μm
μm
μm
μm
Figure 10.7  Carriers’ velocity as a function of the electrical field in silicon.
© 2011 by Taylor and Francis Group, LLC

10-10 
Fundamentals of Industrial Electronics
VT  = kT/q is the thermal potential and η depends on the device geometry and lies between 1.5 and 2.5 
(Figure 10.8). The subthreshold conduction is the reason why MOS transistors are actually never com-
pletely turned OFF and there is always some current leak through MOS transistors. When the popular 
CMOS technology was first developed, one of the underlying assumptions was that along the power 
path, there would never be even one MOS transistor in the OFF state, so power would not be taken 
from power supply. While a transistor can be in the OFF state, there is a leakage current caused by the 
subthreshold conduction in CMOS VLSI circuits, which can be very significant in situations where the 
number of MOS transistors exceeds one billion.
10.3  Junction Field Effect Transistor
The principle of operation for a JFET is quite different than that of a MOS transistor [S05,N06]. The cur-
rent flows through a thin semiconductor layer that is surrounded by a gate made of semiconductor mate-
rial of the opposite type, as shown in Figure 10.9. The gate–channel (source) junction is biased in the 
reverse direction, so there is no gate current. The thickness of the depletion regions controls current flow 
between source S and drain D. The thickness of the depletion regions is the function of the gate voltage:
	
d
V
qN
o
Si
=
2 ε ε
channel
	
(10.24)
As indicated in Figure 10.9a, the thickness of the depletion layer d is constant only if there is no voltage 
applied between source and drain. With applied drain voltage, this issue becomes much more compli-
cated because the channel width is a nonlinear function of distance, and there is a nonlinear voltage 
drop along the channel length. As a consequence, there is a different gate-channel voltage and a differ-
ent depletion layer thickness d along the channel, as shown in Figure 10.9b. With any further increase 
in the gate voltage, the channel is pinched off and only a depletion layer exists between point x in 
Figure 10.9c and the drain D. In that region, the operation of a JFET is very interesting. In the n-type 
JFET case shown in Figure 10.9, electrons in the channel close to the source are being pushed away by 
the negative gate voltage. This is why the depletion layer is formed. But the large positive drain volt-
age creates an electric field between point x and drain, and this electric field swipes all electrons that 
VGS
Subthreshold
conduction
Strong
inversion
Vth
ID
K
2
ID=
(VGS–Vth)2
K
2
ION =
(ηVT)2
VGS–Vth– ηVT
ID=ION exp
ηVT
ηVT
Figure 10.8  Drain current versus the gate-source voltage in subthreshold conduction and the strong inversion 
regions.
© 2011 by Taylor and Francis Group, LLC

Field Effect Transistors 
10-11
have reached point x through the pinch-off region near the drain. Interestingly, when in this mode of 
operation, the drain voltage does not have a direct effect on the drain current, and the drain current 
is determined by the triangular shape of the channel region to the left of point x. Of course, in a man-
ner analogous to that of the MOS transistor, the JFET also experiences second-order effects from the 
channel-length modulation. With an increase in drain voltage, the point x is moved to the left, which 
reduces the effective resistance of the “triangular-like channel region” and results in a slight increase 
in drain current.
The geometry of the JFET is usually more complicated than the one shown in Figure 10.9. Also, in 
most JFET devices, there is a nonlinear impurity distribution in the channel. Therefore, a derivation of 
the current–voltage characteristics would be either too simplistic or too complicated. As a consequence, 
various approximation formulas are being used. The most popular equations for determining JFET 
drain currents are
	
if V
V
I =   
GS
P
D
<
0 	
(10.25)
	
if V
V
I  =
I
 
V
V
V
V
 V
V
GS
P
D
DSS
GS
P
DS
P
DS
P
≥













2
1
2
−
−0.5



≤




 + V
V
V
V
I
V
V
+ V
V
DS
DS
GS
P
DSS
2
GS
P
DS
DS
(
)
(
)
1
for
1
for
λ
λ
−
−1
≥







GS
P
V
V
  
−
	
(10.26)
where VP is the pinch-off voltage and IDSS is the drain current for the case in which the gate is connected 
with source and a relatively large drain voltage is applied. Both VP and IDSS can be related to the JFET 
geometry as shown in Figure 10.9.
ID
ID
ID
D
S
D
(a)
(b)
(c)
S
D
S
VDS
VDS
VDS
p+
p+
p+
p+
p+
p+
n
n
n
x
2a
L
Figure 10.9  Cross sections of an n-channel JFET with fixed gate voltage and different drain-source voltages. 
Characteristics on the right side of the figure show the corresponding modes of operations.
© 2011 by Taylor and Francis Group, LLC

10-12 
Fundamentals of Industrial Electronics
The pinch-off voltage VP can be calculated as
	
V = qa N   
P
2
0
2εε
	
(10.27)
and the drain current IDSS can be calculated from Ohm’s law by dividing VP by the resistance of the 
channel between source and drain. The nonlinear distribution of the resistance is usually assumed to 
be many times larger than the resistance without the applied drain voltage, as shown in Figure 10.9a:
	
R
L
aW
channel = 3 2
ρ
	
(10.28)
where a is half of the thickness of the channel, L is the channel length, and W is the channel width:
	
I
V
aW
L
V
aW
L
V
aW
L q N
DDS
P
P
P
=
=
=
3
2
2
3
2
3
ρ
σ
µ
	
(10.29)
Example 10.3
An n-channel junction JFET has a uniformly doped channel 2 μm thick, 20 μm wide, and 20 μm long with 
ND = 0.5 · 1016 cm−3. Determine the pinch-off voltage as well as the drain current for VGS = −1 V and VDS = 10 V. 
Assume μn = 500 cm2/Vs. Neglect the channel-length modulation effects.
Since the gate concentration is not given, the increase in potential is neglected:
	
V = qa N
P
D
2
0
19
4 2
16
14
2
1 6 10
10
0 5 10
2 11 8 8 85 10
3 8
εε
=
⋅
⋅
⋅
⋅
⋅
=
−
−
.
(
)
.
.
.
.
−
3V  
	
	
I
V
aW
L q N
DDS
P
=
=
⋅
⋅
⋅
⋅
⋅
⋅
⋅
⋅
−
−
−
−
2
3
2 10
20 10
20 10
1 6 10
500 0 5 10
4
4
4
19
µ
( .
.
16 3 83
3
1 0
) .
.
=
mA
	
For VGS = −1 V in an n-channel JFET, the pinch-off voltage must be negative, e.g., VP = −3.83 V, and 
neglecting the channel-length modulation effect λ = 0:
	
I = I
V
V
D
DDS
GS
P
2
2
mA
mA
−1
1 0
1
3 83
3 83
0 55



=
−−−
−



=
.
(
.
)
.
.
	
Note the similarities in Equations 10.13 for the MOS transistor and Equation 10.26 for the JFET. 
Actually, if the pinch-off voltage VP and the drain initial current IDSS are replaced by
	
V
V
K
I
V
th
P
DSS
P
=
=
and
2
2
	
(10.30)
then, to calculate the drain current in a JFET, we need not employ the JFET equations (10.26) and use 
instead the well-known equations for MOS transistors working in the depletion mode:
	
I  =
K V
V
V
V
V
V
V
V
K V
D
GS
th
DS
DS
DS
DS
GS
th
GS
[
]
.
(
)
(
(
)
for
0.5
2
−
−
+
−
−
0 5
1
λ
≤
V
+ V
V
V
V
  
th
DS
DS
GS
th
) (
)
2 1
for
λ
≥



−
	
(10.31)
Because current flow in JFETs is far from the surface, JFETs have a significantly smaller 1/f noise level 
and they are a preferred choice for low-noise amplifiers. Another advantage of the JFET is that it is 
© 2011 by Taylor and Francis Group, LLC

Field Effect Transistors 
10-13
relatively safe to exceed gate-source or gate-drain break voltages. In the case of MOS transistors, large 
gate voltages may result in a permanent break-through of the oxide, leading to the destruction of the 
transistor. It is however very difficult to integrate several JFETs into one chip. Another disadvantage of 
the JFET is that the gate voltage should always have a polarity opposite that of the drain voltage, and this 
makes it almost impossible to fabricate digital circuits using JFETs.
10.4  Static Induction Transistor
Static induction devices were invented by J. Nishizawa [NTS75]. The device has characteristics similar 
to that of the vacuum triode. Its fabrication is relatively difficult, and Japan is actually the only country 
where a family of static induction devices was successfully fabricated [W99].
The cross section of the static induction transistor (SIT) is shown in Figure 10.10. In this n-channel 
structure, the gate is biased with a negative potential and the drain has a significantly large positive 
potential. There are two reverse-biased junctions; one between gate and source, and second between 
gate and drain. Because n− regions have a very low concentration of impurities (1014 cm−3 or below) with 
very small applied voltages or simply the junctions’ built-in potential, these n− regions are depleted of 
carriers. As a consequence, gate-drain voltages form a relatively complex potential surface. Samples of 
such surfaces for a gate voltage equal −10 V and a drain voltage equal +50 V are shown in Figure 10.11. 
Note that gate and drain voltages create opposite electric fields near the source. With an increase in gate 
voltage, the height of the potential barrier increases, as shown in Figure 10.11, while the larger drain 
n+
n+
p+
p+
p+
p+
n–
n–
Source
Drain
Gate
Figure 10.10  Cross section of the SIT.
–10
0
10
10
20
20
30
30
40
40
50
50
0
0
10
20
30
40
50
–10
0
0
0
10
10
10
20
20
20
30
30
30
40
40
40
50
Figure 10.11  Potential distribution in the SIT with a gate voltage of −10 V and a drain voltage of +50 V.
© 2011 by Taylor and Francis Group, LLC

10-14 
Fundamentals of Industrial Electronics
voltage leads to a lowering of the potential barrier. Typical current–voltage characteristics for the SIT 
are shown in Figure 10.12.
10.4.1  Theory of SIT Operation for Small Currents
Consider first a derivation of the formula for the one-dimensional electron current flow through a 
potential with a parabolic shape. In the n-channel device, the electron current is described by a differ-
ential equation that includes both drift and diffusion of carriers [N02,WSM92]:
	
J
qn x
d
x
dx
qD dn x
dx
n
n
n
= −
+
( )
( )
( )
µ
φ
	
(10.32)
where Dn = μnVT and V
kT
q
T =
. By multiplying both sides of the equation by [PW80]
	
exp
( )
−




φ x
VT
	
(10.33)
and rearranging
	
J
x
V
qD
d
dx n x
x
V
n
T
n
T
exp
( )
( )exp
( )
−



=
−










φ
φ
	
(10.34)
After integration from source xS to drain xD:
	
J
qD
n x
x
V
n x
x
V
x
n
n
D
D
T
S
S
T
=
−



−
−




−
(
)exp
(
)
(
)exp
(
)
exp
(
φ
φ
φ
)
V
dx
T
x
x
S
D




∫
	
(10.35)
0
–3
–4
–5
VGS
VDS
IDS (A)
–10
–15
–20
–25
(V)
2
3
1
100
200
300
400
–1 –2
Figure 10.12  Typical current–voltage characteristics for the SIT.
© 2011 by Taylor and Francis Group, LLC

Field Effect Transistors 
10-15
By inserting
	
φ
φ
(
)
(
)
(
)
(
)
x
n x
N
x
V
n x
N
S
S
S
D
D
D
D
=
=
=
=
0
	
(10.36)
Equation 10.35 reduces to
	
J
qD N
x
V
dx
n
n
S
T
x
x
S
D
=
−




∫
exp
( )
φ
	
(10.37)
Equation 10.37 is very general and it describes the current flow over a potential barrier with a shape 
given by φ(x). This equation can be used not only in SIT devices but also in bipolar transistors or it can 
be used to calculate the subthreshold conduction in a MOS transistor.
Note that because of this exponential relationship, only the shape of the potential distribution near 
the top of the potential barrier is important, and in the SIT, this shape can be approximated (see Figure 
10.11) by quadratic equations along the x direction and across the y direction of the channel:
	
φ( , )
y x
x
L
y
W
=



−









Φ
2
2
	
(10.38)
where L is the effective channel length, W is the effective channel width, and Φ is the height of the 
potential barrier in the center of the channel. Using (10.38) and integrating (10.37) first along the chan-
nel and then across it leads to a simple formula for the drain current of a SIT as a function of the height 
of potential barrier:
	
I
qD N Z W
L
V
D
p
S
T
=




exp
Φ
	
(10.39)
where Φ is the potential barrier height in reference to the source potential, and NS is the electron con-
centration at the source. The W/L ratio describes the shape of the potential saddle in the vicinity of the 
barrier, and Z is the length of the source strip.
Since the barrier height Φ can be a linear function of gate and drain voltages:
	
I
qD N Z W
L
aV
bV
V
D
p
S
GS
DS
T
=
+
+




exp
Φ0
	
(10.40)
The actual characteristics of the SIT device on a logarithmic scale are shown in Figure 10.13. Indeed, 
for a small current range, the characteristics have an exponential character, but this is not true for large 
currents where the space charge for moving electrons affects the potential distribution.
10.4.2  Theory of SIT for Large Currents
For large current levels, the SIT current is controlled by the space charge of the moving carriers 
[PW81,MW83]. In the one-dimensional case, the potential distribution is described by the Poisson equation:
	
d
dx
x
I
Av x
Si
o
DS
2
2
φ = −
=
ρ
ε ε
( )
( ) 	
(10.41)
© 2011 by Taylor and Francis Group, LLC

10-16 
Fundamentals of Industrial Electronics
where A is the effective device cross section and v(x) is the carrier velocity. For a small electrical field, 
v(x)=μE(x) and the solution of (10.41) is
	
I
V
A
L
D
DS
Si
o
= 9
8
2
3
µε ε
	
(10.42)
For a large electrical field, v(x) = vsat and
	
I
V v
A
L
D
DS
sat
Si
o
= 2
2
ε ε
	
(10.43)
where L is the channel length and vsat ≈ 1011 μm/s is the carrier saturation velocity. In practical devices, 
the current–voltage relationship is described by an exponential relationship (10.9) for small currents, a 
quadratic relationship (10.11), and finally for large voltages, by an almost linear relationship (10.12). SIT 
characteristics drawn in linear and logarithmic scales are shown in Figures 10.12 and 10.13, respectively.
10.4.3  Bipolar Mode of Operation of the SIT
The bipolar mode of operation for the SIT was first reported in 1977 [NW77a]. Several complex theories 
for the bipolar mode of operation were developed [NTT86,NOC82], but actually the simple formula 
(10.37) works well not only for the typical mode of SIT operation, but also for the bipolar mode as well. 
Furthermore, the same formula works very well for classical bipolar transistors. Typical characteristics 
of the SIT, operating in normal and in bipolar modes, are shown in Figure 10.14.
In a SIT, a virtual base is formed, not by impurity doping but rather by a potential barrier that is 
induced by the gate voltage. As a consequence, in the bipolar mode of operation, the SIT may have a 
VG= –15
–13
–11
–9
–7
–6
–5
–4
–3
–2
–1
0
10–3
10–1
10–2
10–4
10–5
10–6
10–7
600
200
400
VDS (V)
IDS (A)
Figure 10.13  Characteristics of the SIT for a small current range.
© 2011 by Taylor and Francis Group, LLC

Field Effect Transistors 
10-17
very large current gain β. Also, the SIT operates with a very low level of impurity concentration and 
its parasitic capacitances are very low. When a bipolar transistor in integrated injection logic (I⁜2L) was 
replaced by a SIT, the time-delay product of such a device was reduced almost 100 times [NW77]. Such 
a drastic improvement in the power-delay product is possible because the SITL structure has a signifi-
cantly smaller junction parasitic capacitance, and, furthermore, the voltage swing is reduced.
Another interesting application of the SIT is a replacement for Schottky diodes in the protection of a 
bipolar transistor against saturation, leading to a much faster switching time. The use of a SIT [WMS84] 
is more advantageous than that obtained with a Schottky diode since it does not require additional area 
on a chip and it does not introduce additional capacitance between the base and the collector.
10.5  Lateral Punch-Through Transistor
The fabrication of SITs is a very challenging endeavor. The channel area requires very low impurity 
concentration (N < 1014 cm−3), and, at least, a part of the channel near the source has to be made using an 
epitaxial layer, as shown in Figure 10.10, which should be about 100 times more pure than that which is 
considered an epitaxial layer with low impurity concentration (N = 1016 cm−3). The second difficult issue 
is the creation of a buried gate region. With high temperature epitaxial growth and subsequent diffusion 
processes, it is extremely difficult to concentrate gate impurity in one place without spreading it into the 
channel area and actually closing the channel. Only a couple of Japanese companies (Yamaha and Sony) 
were able to develop a fabrication process for SIT devices.
The lateral punch-through transistor (LPTT), which has characteristics that are similar to the SIT, 
can be fabricated with a very simple process [WJ82]. The cross section of the LPTT device is shown 
in Figure 10.15, and its characteristics are shown in Figure 10.16. The LPTT device, in contrast to SIT 
device, must use the same type of the impurity in the channel as is used in the gate. For the n-type chan-
nel, p− must be used instead of n−. With an increase in positive drain voltage, the thickness of the drain 
depletion region increases. Once the depletion layer reaches the source, the punch-through current will 
start to flow between source and drain. The current can be stopped by applying a negative voltage on the 
IDS  (μA) 
VDS  (V) 
2
4
 
100
50
VGS= 0.75 V
VGS= 0.7 V
VGS= 0.65 V
0.6 V
0.5 V
0.3 V
0 V
–1V
–2V
–3V
Figure 10.14  SIT transistor characteristic operating in both normal and the bipolar modes, ID  = f(VDS) with VGS 
as parameter.
© 2011 by Taylor and Francis Group, LLC

10-18 
Fundamentals of Industrial Electronics
gate. Eventually, the electrical field near the source will be affected by both the gate and source voltages. 
Because of its proximity to the source, the gate voltage can be much more effective in controlling the 
device current. Typical current–voltage characteristics are shown in Figure 10.16.
The concept of the LPTT can be extended to a punch-through MOS transistor (PTMOS), where 
the current is controlled by the MOS gate [W83a,WJF84]. The principle of operation of such a device 
is shown in Figure 10.17. In this device, instead of the implanted p-type gate, the gate is formed by an 
accumulation p-type layer under the MOS gate, as shown in Figure 10.17a, and the punch-through 
current can be controlled by a potential applied to the adjacent p-type region, which is normally 
p+
p+
p–
p–
n+
n+
Emitter
Gate
Drain
VG
VG
Depletion
 region
Depletion
 region
Depletion
 region
Drain
current
Figure 10.15  Cross section of an LPTT.
T=298K
T=400K
–2 V
–4 V
–6 V
–8 V
–10 V
–12 V
–14 V
–16 V
VG= 0 V
ID (mA)
VDS (V)
2
1
20
40
60
Figure 10.16  Characteristics of the LPTT.
© 2011 by Taylor and Francis Group, LLC

Field Effect Transistors 
10-19
biased with a large negative potential. With positive voltage on the MOS gate, the n-type accumula-
tion layer is formed under the gate and the current may flow easily from source to drain, as indicated 
in Figure 10.17b. Note that in typical CMOS technology, in order to prevent a punch-through phe-
nomenon between source and drain, a large impurity doping in the substrate must be used, which 
in turn leads to larger parasitic capacitances. In a MOS transistor with shorter channels, a larger 
impurity concentration must be used to prevent the punch-through phenomenon, and parasitic 
capacitances are also larger. The PTMOS takes advantage of the punch-through phenomenon and the 
substrate impurity concentration can be very low, which leads to very small parasitic capacitances 
and a significant reduction in power consumption for digital circuits operating with very large clock 
frequencies.
The PTMOS transistor has several advantages over the traditional MOS transistor:
	
1.	 The gate capacitance is very small.
	
2.	 The carrier move with a velocity close to saturation velocity.
	
3.	 The substrate doping is much lower and the existing depletion layer leads to a much smaller drain 
capacitance.
The device operates in a fashion that is similar to that of the MOS transistor in subthreshold conditions, 
but this process occurs at much higher current levels. Such a “bipolar mode” of operation may have 
many advantages in VLSI applications.
10.6  Power MOS Transistors
MOS transistors have a relatively small transconductance in comparison to bipolar transistors. Therefore, 
in power electronic applications, the integrated device structures usually should consist of thousands 
of transistors connected in parallel. There are two types of power MOS transistors: VMOS (shown in 
Figure 10.18a) and DMOS (shown in Figure 10.18b). In the VMOS structure, MOS gates and channels 
are formed on etched surfaces. This way many transistors can be efficiently connected together. VMOS 
uses the silicon surface very efficiently.
The DMOS transistor does not use the chip area as efficiently as the VMOS transistor, but it can be 
fabricated with much larger breakdown voltages. In DMOS, a fragile MOS structure is protected from 
a large electric field by a concept borrowed from the SIT [NTS75] and the high-voltage Schottky diode 
[W83]. The n− area under the gate, as illustrated in Figure 10.18b, is depleted from carriers, and neigh-
boring p-type regions work as electrostatic screens as is done in SIT devices. As a result, this transistor 
may withstand much larger drain voltages and also the effect of channel-length modulation is signifi-
cantly reduced. The latter effect leads to larger output resistances of the transistor. Therefore, the drain 
current is less sensitive to drain voltage variations. In fact, the DMOS structure can be considered as a 
composition of the MOS transistor and the SIT, as shown in Figure 10.19.
Emitter
(b)
(a)
Drain
p
n+
n+
n+
n+
Gate
–
–
p
Depletion
+
p–
Emitter
Drain
p
n+
n+
n+
n+
n
–
Depletion
+
p–
Gate
Figure 10.17  Punch-through MOS transistor: (a) transistor in the punch-through mode for a negative gate 
potential and (b) transistor in the on-state for a positive gate potential.
© 2011 by Taylor and Francis Group, LLC

10-20 
Fundamentals of Industrial Electronics
The major disadvantage of power MOS transistors is the relatively larger drain series resistance and 
much smaller transconductance in comparison to bipolar transistors. Both of these parameters can be 
improved dramatically if the n+ layer near the drain is replaced by p+ layer as is shown in Figure 10.19. 
This way an integrated structure is being built where its equivalent diagram consists of a MOS transistor 
integrated with a bipolar transistor, as shown in Figure 10.19. Such a structure has a transconductance 
that is β times larger, where β is the current gain of the PNP bipolar transistor, and a much smaller series 
resistance due to the conductivity modulation effect caused by holes injected into the lightly doped 
drain region. Such device is known as insulated gate bipolar transistor (IGBT). An IGBT can work with 
large currents and voltages. Its main disadvantage is a large switching time that is limited primarily by 
the poor switching performance of the bipolar transistor. Another difficulty is related to a possible latch-
up action of four layer n+pn−p+ structure. This undesired effect could be suppressed by using a heavily 
doped p+ region in the base of the NPN structure, which leads to a significant reduction in the current 
n+
n+
n+
n+
p+
p+
p+
p+
p+
p+
p+
p+
n–
n–
Poly gate
Poly gate
Source
Drain
NMOS
NMOS
PNP
p
NPN
RP
E
G
C
NPN
PNP
Figure 10.19  Cross section of an IGBT and its internal equivalent circuit.
n+
n+
n+
n–
p
p
Gate
Source
Source
Gate
Gate
Drain
S
G
D
NMOS
(a) 
n+
n+
n+
n+
n+
n–
n–
n–
Source
Drain
(b) 
p
p
Poly gate
Poly gate
p
SIT
S
G
D
SIT
SIT
NMOS
NMOS
NMOS
Figure 10.18  Cross section of power MOS transistors: (a) VMOS and (b) DMOS.
© 2011 by Taylor and Francis Group, LLC

Field Effect Transistors 
10-21
gain of this parasitic transistor, shown in Figure 10.19. The gain of the PNP transistor must be kept large 
so the transconductance of the entire device can be large. IGBT transistors may have breakdown volt-
ages over 1000 V, with turn-off times in the range from 0.1 to 0.5 μs. In addition, they may operate with 
currents above 100 A with a forward voltage drop of about 3 V.
References
[E97] R. Enderlein, Fundamentals of Semiconductor Physics and Devices, World Scientifics, New York, 
1997.
[MW83] R. H. Mattson and B. M. Wilamowski, Punch-through devices operating in space-charge-
limited modes, IEEE International Workshop on the Physics of Semiconductor Devices, Delhi, India, 
December 5–10, 1983.
[N02] Kwok K. Ng, The Complete Guide to Semiconductor Devices, Wiley-IEEE Press, New York, 2002.
[N06] D. Neamen, An Introduction to Semiconductor Devices, McGraw-Hill, New York, 2006.
[NOC82] J. Nishizawa, T. Ohmi, and H. L. Chen, Analysis of static characteristics of a bipolar-mode SIT 
(BSIT), IEEE Transactions on Electron Devices, 29, 8, 1233–1244, 1982.
[NTS75] J. Nishizawa, T. Terasaki, and J. Shibata, Field-effect transistor versus analog transistor 
(static induction transistor), IEEE Transactions on Electron Devices, 22, 4, 185–197, 1975.
[NTT86] Y. Nakamura, H. Tadano, M. Takigawa, I. Igarashi, and J. Nishizawa, Experimental study on 
current gain of BSIT, IEEE Transactions on Electron Devices, 33, 6, 810–815, 1986.
[NW77] J. Nishizawa and B. M. Wilamowski, Integrated logic—State induction transistor logic, 
International Solid State Circuit Conference, Philadelphia, PA, pp. 222–223, 1977.
[NW77a] J. Nishizawa and B. M. Wilamowski, Static induction logic—A simple structure with very low 
switching energy and very high packing density, International Conference on Solid State Devices, Tokyo, 
Japan, pp. 53–54, 1976; and Journal of Japanese Society of Applied Physics, 16-1, 158–162, 1977.
[PW80] P. Plotka and B. M. Wilamowski, Interpretation of exponential type drain characteristics of the 
SIT, Solid-State Electronics, 23, 693–694, 1980.
[PW81] P. Plotka and B. M. Wilamowski, Temperature properties of the static induction transistor, Solid-
State Electronics, 24, 105–107, 1981.
[R99] D. J. Roulston, Introduction to the Physics of Semiconductor Devices, Oxford University Press, 
New York, 1999.
[S05] B. Streetman, Solid State Electronic Devices, Prentice Hall, New York, 2005.
[T99] Y. Tsividis, Operation and Modeling the MOS Transistor, McGraw-Hill, New York, 1999.
[W83] B. M. Wilamowski, Schottky diodes with high breakdown voltage, Solid-State Electronics, 26, 5, 
491–493, 1983.
[W83a] B. M. Wilamowski, The punch-through transistor with MOS controlled gate, Physica Status Solidi (a), 
79, 631–637, 1983.
[W99] B. M. Wilamowski, High speed, high voltage, and energy efficient static induction devices, 12 
Symposium of Static Induction Devices—SSID’99, Tokyo, Japan, pp. 23–28, April 23, 1999.
[WJ82] B. M. Wilamowski and R. C. Jaeger, The lateral punch-through transistor, IEEE Electron Device 
Letters, 3, 10, 277–280, 1982.
[WJF84] B. M. Wilamowski, R. C. Jaeger, and J. N. Fordemwalt, Buried MOS transistor with punch-
through, Solid State Electronics, 27, 8/9, 811–815, 1984.
[WMS84] B. M. Wilamowski, R. H. Mattson, and Z. J. Staszak, The SIT saturation protected bipolar tran-
sistor, IEEE Electron Device Letters, 5, 263–265, 1984.
[WSM92] B. M. Wilamowski, Z. J. Staszak, and R. H. Mattson, An electrical network approach to the 
analyses of semiconductor devices, IEEE Transactions on Education, 35, 2, 144–152, 1992.
© 2011 by Taylor and Francis Group, LLC

11-1
11.1  Introduction
Noise (a spontaneous fluctuation in current or in voltage) is generated in all semiconductor devices. 
The intensity of these fluctuations depends on device type, its manufacturing process, and operating 
conditions. The resulted noise, as a superposition of different noise sources, is defined as an inherent 
noise. The equivalent noise models (containing all noise sources) are created for a particular device: for 
example, bipolar transistor (BJT), junction field effect transistor (JFET), or metal oxide semiconductor 
field effect transistor (MOSFET).
The inherent noise of semiconductor devices is considered as an undesired effect and sometimes is 
referred to as a useful signal. It is specially important for input (front-end) stages of electronic systems. 
However, the inherent noise can also be used for the quality assessment of semiconductor devices. Quite 
often it has been used as an important factor during the development of the production process of new 
semiconductor devices. Inherent noise is also used for the classification of semiconductor devices into 
groups with different quality and reliability.
The most important sources of noise are thermal noise, shot noise, generation-recombination noise, 
1/f noise (flicker noise), 1/f 2 noise, burst noise or random telegraph signal (RTS) noise, and avalanche 
noise. Detailed description of noise sources is presented in references [1–6].
11.2  Sources of Noise in Semiconductor Devices
11.2.1  Thermal Noise
Thermal noise is created by random motion of charge carriers due to thermal excitation. This noise is 
sometimes known as the Johnson noise. In 1905, Einstein presented his theory of fluctuating movement 
of charges in thermal equilibrium. This theory was experimentally verified by Johnson in 1928. The 
thermal motion of carriers creates a fluctuating voltage on the terminals of each resistive element. 
11
Noise in Semiconductor 
Devices
11.1	 Introduction..................................................................................... 11-1
11.2	 Sources of Noise in Semiconductor Devices............................... 11-1
Thermal Noise  •  Shot Noise  •  Generation-Recombination 
Noise  •  1/f Noise  •  Noise 1/f 2  •  Burst Noise/RTS Noise  •
Avalanche Noise
11.3	 Noise of BJTs, JFETs, and MOSFETs............................................11-6
Noise of BJTs  •  Noise of JFETs  •  Noise of MOSFETs  •  Low Noise 
Circuits for Low Frequency Range
References................................................................................................... 11-12
Alicja 
Konczakowska
Gdansk University 
of Technology
Bogdan M. 
Wilamowski
Auburn University
© 2011 by Taylor and Francis Group, LLC

11-2 
Fundamentals of Industrial Electronics
The average value of this voltage is zero, but the power on its terminals is not zero. The internal noise 
voltage source or current source is described by the Nyquist equation
	
νth
th
kTR f
i
kT f
R
2
2
4
4
=
=
∆
∆
	
(11.1)
where
k is the Boltzmann constant
T is the absolute temperature
4kT is equal to 1.61 · 10−20 V · C at room temperature
The thermal noise is proportional to the frequency bandwidth Δf. It can be represented by the voltage 
source in series with resistor R or by the current source in parallel to the resistor R. The maximum noise 
power can be delivered to the load when RL = R. In this case, maximum noise power in the load is kTΔf. 
The noise power density, dPn/df = kT, is independent of frequency. Thus, the thermal noise is the white 
noise. The RMS noise voltage and the RMS noise current are proportional to the square root of the fre-
quency bandwidth Δf. The thermal noise is associated with every physical resistor in the circuit.
The spectral density function of the equivalent voltage and current thermal noise are given by
	
S
kTR
thvR = 4
	
(11.2)
or
	
S
kTG
thiG = 4
	
(11.3)
These noise spectral densities are constant up to 1 THz and they are proportional to temperature and to 
resistance of elements, and as such can be used to indirectly measure the following:
•	 The device temperature
•	 The base-spreading resistance of BJT
•	 The quality of contacts and connections
11.2.2  Shot Noise
Shot noise is associated with a discrete structure of electricity and the individual carrier injection through 
the pn junction. In each forward-biased junction, there is a potential barrier that can be overcome by the 
carriers with higher thermal energy. This is a random process and the noise current is given by
	
i
qI f
sh
2
2
=
∆	
(11.4)
The noise spectral density function of the shot noise is temperature independent (white noise) and it is 
proportional to the junction current
	
S
qI
shi = 2
	
(11.5)
where
q is the electron charge
I is the forward junction current
Shot noise is usually considered as a current source connected in parallel to the small signal junction 
resistance. The measurement of shot noise in modern nanoscale devices is relatively difficult since mea-
sured values of current are in the range of 10–100 fA.
© 2011 by Taylor and Francis Group, LLC

Noise in Semiconductor Devices 
11-3
Shot noise has to be proportional to the current and any deviation from this relation can be used 
to evaluate parasitic leaking resistances. It can be used for diagnosis of photodiodes, Zener diodes, 
­avalanche diodes, and Schottky diodes.
11.2.3  Generation-Recombination Noise
Generation-recombination noise is caused by the fluctuation of number of carriers due to existence 
of the generation-recombination centers. Variation of number of carriers leads to changes of device 
conductance. This type of noise is a function of both temperature and biasing conditions. The spectral 
density function of the generation-recombination noise is described by
	
S
f
N
N
N
f
g r
−
=
⋅+
⋅
( )
(
)
(
)
2
2
2
2
4
1
2
∆
τ
π
τ
	
(11.6)
where
(
)
∆N 2 is the variance of the number of carriers N
τ is the carrier lifetime
Spectral density is constant up to the frequency fg−r = 1/(2πτ), and after that it decreases proportionally 
to 1/f 2.
In the case, when there are several types of generation-recombination centers with different car-
rier life time, the resultant noise spectrum will be a superposition of several distributions described 
by (11.6). Therefore, the spectral distribution of noise can be used to investigate various generation-
recombination centers. This is an alternative method to deep-level transient spectroscopy (DLTS) to 
study generation-recombination processes in semiconductor devices.
11.2.4  1/f Noise
1/f noise is the dominant noise in the low frequency range and its spectral density function is pro-
portional to 1/f. This noise is present in all semiconductor devices under biasing. This noise is usually 
associated with material failures or with imperfection of a fabrication process. Most of research results 
conclude that this noise exists even for very low frequencies up to 10−6 Hz (frequency period of several 
weeks). This noise is sometimes used to model fluctuation of device parameters with time. There are two 
major models of 1/f noise:
•	 Surface model developed by McWhorter in 1957 [7]
•	 Bulk model developed by Hooge in 1969 [8]
The simplest way to obtain 1/f characteristics is to superpose many different spectra of generation-
recombination noise, where free carriers are randomly trapped and released by centers with different 
life times. This was the basic concept behind the McWhorter model where it was assumed that
•	 In the silicon oxide near the silicon surface there are uniformly distributed trap centers.
•	 The probability of the carrier penetration to trap centers is decreasing exponentially with the 
distance from the surface.
•	 Time constants of trap centers increases with the distance from the surface.
•	 Trapping mechanisms by separate centers are independent.
The resulted noise spectral density function is given by
	
S
N
d
N
f
f
1
2
2
2
2
1
1
4
1
1
1
1
1
2
/
(
)
(
)
∝
+
⋅
=
⋅
<<
<<
∫
∆
∆
τ
τ
ωτ
τ
τ
ω
τ
τ
τ
for
	
(11.7)
© 2011 by Taylor and Francis Group, LLC

11-4 
Fundamentals of Industrial Electronics
The spectral density function is constant up to frequency f2 = 1/(2πτ2), then it is proportional to 1/f 
between f2 and f1 = 1/(2πτ1), and from frequency f1 it is proportional to 1/f 2. The McWhorter model is 
primarily used for MOSFET devices.
For BJT, the Hooge bulk model is more adequate. In this noise model, Hooge uses in the carrier trans-
port two scattering mechanisms of carries: scattering on the silicon lattice and scattering on impurities. 
He assumed that only scattering on the crystal lattice is the source of the 1/f noise, while scattering on 
the impurities has no effect on noise level. All imperfections of the crystal lattice leads to large 1/f noise.
The noise spectral density function for the Hooge model is
	
S
I
f
N
f
H
1/ =
⋅
⋅
α
α
γ
	
(11.8)
where
αH = 2 · 10−3 is the Hooge constant [8]
α and γ are material constants
N is the number of carriers
Later [9], Hooge proposed to use αH as variable parameter, which in the case of silicon devices may vary 
from 5 · 10−6 to 2 · 10−3.
The 1/f noise is increasing with the reduction of device dimensions and as such is becoming a real 
problem for devices fabricated in nanoscale. The level of 1/f noise is often used as the measure of the 
quality of devices and its reliability. Devices fabricated with well-developed technologies usually have a 
much smaller level of 1/f noise. The 1/f noise (flicker noise) sometimes is considered to be responsible for 
the long-term device parameter fluctuation.
11.2.5  Noise 1/f 2
Noise 1/f 2 is a derivative of 1/f noise and it is observed mainly in metal interconnections of integrated 
circuits. It has become more evident for very narrow connections where there is a possibility of electro-
migration due to high current densities. In aluminum, the electromigration begins at current densities 
of 200 μA/μm2 and noise characteristics changes from 1/f 2 to 1/f γ, where γ > 2. Also the noise level 
increases proportionally to the third power of the biasing current:
	
S
f
C J
f
T
E
k T
f
a
1
2
/ ( )
exp
=
⋅
⋅
⋅
−
⋅




β
γ
	
(11.9)
where
β ≥ 3, γ ≥ 2
C is the experimentally found constant
Ea is the activation energy of the electromigration
k = 8.62 · 10−5 eV/K is the Boltzmann constant
The degeneration of the metallic layer is described by
	
νd
n
a
J
E
k T
∝
−
⋅




exp
	
(11.10)
Since Equations 11.9 and 11.10 have a similar character, the 1/f 2 noise can be used as the measure of the 
quality of metal interconnections. This is a relatively fast and accurate method to estimate reliability of 
metal interconnections.
© 2011 by Taylor and Francis Group, LLC

Noise in Semiconductor Devices 
11-5
11.2.6  Burst Noise/RTS Noise
Burst noise is another type of noise at low frequencies. Recently, this noise was described as RTS noise. 
With given biasing condition of a device, the magnitude of pulses is constant, but the switching time is 
random. The burst noise looks, on an oscilloscope, like a square wave with the constant magnitude, but 
with random pulse widths (see Figure 11.1). In some cases, the burst noise may have not two but several 
different levels.
Noise spectral density function of the RTS noise has a similar form like generation-recombination 
noise:
	
S
f
C
I
f f
RTS
RTS
( )
(
)
(
/
)
=
⋅
+
4
1
2
2
2
∆
π
	
(11.11)
where
C
f
l
h
RTS
=
+
⋅
1
2
(
)
τ
τ
fRTS
l
h
l
h
h
l
=
=
+
=
+
⋅
1
1
1
τ
τ
τ
τ
τ
τ
τ
  RTS noise corner frequency, below this frequency spectrum of the 
RTS noise is flat. τ is observation time, τl is average time of pulses at low level, and τh is average 
time of pulses at high level
τ
τ
τ
τ
l
l p
i
P
h
h s
j
S
P
S
=
=
=
=
∑
∑
1
1
1
1
,
,
,
The intensity of the RTS noise depends on the location of the trap center with reference to the Fermi 
level. Only centers in the vicinity of Fermi levels are generating the RTS noise. These trapping centers, 
which are a source for RTS noise, are usually the result of silicon contamination with heavy metals or 
lattice structure imperfections.
In the SPICE program the burst noise is often approximated by
	
i
K
I
1 + f f
 f
RTS
B
A
RTS
B
2
2
=
( /
)
∆
	
(11.12)
where KB, AB, and fRTS are experimentally chosen parameters, which usually vary from one device to 
another. Furthermore, a few different sources of the burst noise can exist in a single transistor. In such a 
case, each noise source should be modeled by separate Equation 11.11 with different parameters (usually 
different noise RTS corner frequency fRTS).
i(t)
T
t
Δl
τl,p
τh,s
FIGURE 11.1  The RTS noise.
© 2011 by Taylor and Francis Group, LLC

11-6 
Fundamentals of Industrial Electronics
Kleinpenning [10] showed that RTS noise exists with devices with small number of carriers, where a 
single electron can be captured by a single trapping center. RTS noise is present in submicrometer MOS 
transistors and in BJTs with defective crystal lattice. It is present in modern SiGe transistors.
This noise has significant effect at low frequencies. It is a function of temperature, induced mechani-
cal stress, and also radiation. In audio amplifiers, the burst noise sounds as random shots, which are 
similar to the sound associated with making popcorn. Obviously, BJTs with large burst noise must 
not be used in audio amplifiers and in other analog circuitry. The burst noise was often observed in 
epiplanar BJTs with large β coefficients. It is now assumed that devices fabricated with well-developed 
and established technologies do not generate the RTS noise. This is unfortunately not true for modern 
nanotransistors and devices fabricated with other than silicon materials.
11.2.7  Avalanche Noise
Avalanche noise in semiconductor devices is associated with reverse-biased junctions. For large reverse 
junction voltages, the leakage current can be multiplied by the avalanche phenomenon. Carriers in 
the junctions gain energies in a high electrical field and then they collide with the crystal lattice. If the 
energy gained between collisions is large enough, then during collision another pair of carriers (electron 
and hole) can be generated. This way the revised biased current can be multiplied. This is a random pro-
cess and obviously the noise source is associated with the avalanche carrier generation. The intensity of 
the avalanche noise is usually much larger than any other noise component. Fortunately, the avalanche 
noise exists only in the pn junction biased with a voltage close to the breakdown voltage. The avalanche 
phenomenon is often used to build the noise sources.
Noise spectral density function of the avalanche noise is frequency independent:
	
S
f
qI
f
av( )
(
)
=
⋅
2
2
2
π
τ
	
(11.13)
where I is an average value of the reverse biasing current.
An avalanche phenomenon is in most cases reversible. Therefore, semiconductor devices, where the 
avalanche breakdown took place, are regaining their low noise properties once devices are no longer 
working at avalanche region.
11.3  Noise of BJTs, JFETs, and MOSFETs
11.3.1  Noise of BJTs
In Figure 11.2, the equivalent diagram of BJT with noise sources is presented. These are as follows: 
thermal noise of base-spreading resistance rb, shot noise and 1/f type noise of base bias current IB, and 
B
rb
ν 2
thrb
B΄
C
E
i 2
shc
i 2
shb+i 2
1/fb
FIGURE 11.2  Equivalent diagram of BJT with noise sources.
© 2011 by Taylor and Francis Group, LLC

Noise in Semiconductor Devices 
11-7
shot noise of collector current IC. Spreading resistance is shown as 
external resistor rb (noiseless resistor) between internal base B′ and 
external base B.
The intensities (mean-square values) of noise sources are given by 
the following relations:
	νr
b
b
kTr
f
r
2
4
=
⋅∆ thermal noise of base spreading resistance
b 	(11.14)
	
i
qI
f
I
shb
B
B
2
2
=
⋅∆shot noise of base bias current
	
(11.15)
	
i
k
I
f
f
I
fb
f
B
B
1
2
/ =
⋅
⋅
α
γ
∆flicker noise of base bias current 
	
(11.16)
	
i
qI
f
I
shc
C
C
2
2
=
⋅∆shot noise of collector bias current 
	
(11.17)
Coefficients α i γ in properly fabricated BJTs are close to 1. In silicon BJTs, the noise 1/f is caused by 
fluctuation of the recombination current in the depletion region of the base-emitter junction near the 
silicon surface. The npn transistors have usually higher levels of 1/f than pnp transistors.
Figure 11.3 shows the v
i
n
n
2
2
− amplifier model of the BJT with the equivalent input noise voltage and 
current vn
2 and in
2, respectively.
The equivalent input noise voltage and current (mean-square values) can be expressed by [4]
	
ν
β
α
γ
n
b
B
f
B
b
C
b
T
C
kTr
f
q I
f
K
I
f
f
r
qI
f
r
V
I
2
2
4
2
2
=
⋅
+
⋅
⋅
+
⋅



⋅
+
⋅
+
∆
∆
∆
∆



2
	
(11.18)
	
i
qI
f
K
I
f
f
qI
f
n
B
f
B
C
2
2
2
2
=
⋅
+
⋅
⋅
+
⋅
∆
∆
∆
α
γ
β
	
(11.19)
where β is the common-emitter current gain, VT = k · T0/q, for T0 = 290 K and VT = 25 mV.
In practice, the intensities of these noise sources versus frequency f have to be taken into account, 
and of course the 1/f noise sources in low frequency range are the main ones. For this reason, the flicker 
noise corner frequency fcor is one of the important parameters. The flicker noise corner frequency fcor is 
understood as being the frequency for which the 1/f noise and the white noise (thermal, shot) are equal 
to each other (see Figure 11.4).
C
E
B
ν22
n
i 2
n
FIGURE 11.3  The v
i
n
n
2
2
− ampli-
fier model of the bipolar transistor.
log S( f)
log f
fcor
FIGURE 11.4  Noise power spectral density function S(f) versus frequency f.
© 2011 by Taylor and Francis Group, LLC

11-8 
Fundamentals of Industrial Electronics
The shape of noise power spectral density function S(f) as a function of frequency f, representing 
intensity of input noise voltage or current sources v
f i
f
n
n
2
2
/
,
/
∆
∆, respectively, is the same. Function 
S(f) should have −10 dB/decade slope in the low frequency range below flicker noise corner fre-
quency fcor. For the f < fcor the 1/f noise is the dominant component and for f > fcor the white (thermal 
and shot) noise is prevailing. The flicker noise corner frequency fcor for i
f
n
2/∆ can be found from the 
relation [4]
	
f
K
q
cor
f
=
+
(
)
2
1 1/β 	
(11.20)
where parameters Kf and β are measured experimentally.
For BJTs, the fcor is in the range from tenth of Hz to several kHz. The value of the flicker noise corner 
frequency can be evaluated separately for both equivalent input noise sources, for equivalent input noise 
voltage, and equivalent input noise current. The values of fcor are not the same.
For evaluating a noise behavior of BJTs in a high and a very high frequency range the noise factor F 
can be applied. The noise factor F is given by the relation
	
F
v
kTR
f
ni
S
=
2
4
∆
	
(11.21)
where 
vni
2  is the mean-square equivalent noise input voltage for the CE or the CB configuration of BJT 
RS is the noise source resistance [4]
One way to reduce the thermal noise level of the base spreading resistance, rb, is the connection 
of several (N) BJTs in parallel and to assure that the total current of all transistors is the same as for 
one transistor. By this way, the level of shot noise stays on the same level and the thermal noise is 
reduced to rb/N.
11.3.2  Noise of JFETs
In Figure 11.5, the equivalent diagram of JFET with attached noise sources is presented. These are as fol-
lows: thermal noise of drain current ID, 1/f noise of drain current ID, and shot noise of gate current IG. At the 
normal operating conditions, the gate-source junction is reverse biased and the shot noise of gate current, 
IG, can be neglected.
D
S
G
i 2
shq
i 2
thd +i 2
1/fd
FIGURE 11.5  Equivalent diagram of JFET with noise sources.
© 2011 by Taylor and Francis Group, LLC

Noise in Semiconductor Devices 
11-9
The intensities (mean-square values) of noise sources are given 
by the following relations:
	
i
qI
f
I
shg
G
G
2
2
=
⋅∆shot noise of gate current
	
(11.22)
	
i
kT
g
f
I
thd
m
D
2
4
2
3
=



⋅∆thermal noise of drain current
	
(11.23)
	
i
K
I
f
f
I
fd
f
D
D
1
2
/
=
⋅
⋅
α
γ
∆flicker noise of drain current
	
(11.24)
Coefficients α i γ in properly fabricated JFETs are close to 1.
Figure 11.6 shows the v
i
n
n
2
2
− amplifier model of the JFET 
with the equivalent input noise voltage and current vn
2 and in
2, 
respectively.
The equivalent input noise voltage and current (mean-square values) can be expressed by [4]
	
ν
α
γ
n
thd
fd
m
m
f
D
m
i
i
g
kT
g
f
K
I
g
f
f
kT
2
2
1
2
2
2
4
2
3
4
=
+
=



⋅
+
⋅
⋅
⋅
=
⋅
/
∆
∆
∆f
I
K
f
f
D
f
3
4
β
β
⋅
+
⋅
⋅
∆
	
(11.25)
	
i
i
qI
f
n
shg
G
2
2
2
=
=
⋅∆	
(11.26)
where β is the transconductance coefficient.
As for BJTs, in the low frequency range, the flicker noise corner frequency fcor is one of the important 
parameter. The frequency fcor can be evaluated only for the power spectral density function S(f) repre-
senting the intensity of input noise voltage v
f
n
2/∆, because the equivalent input noise current does not 
include the 1/f noise. For JFETs, the flicker noise frequency fcor is understood as being the frequency for 
which the 1/f noise and thermal noise of v
f
n
2/∆ are equal to each other (see Figure 11.4).
Noise power spectral density function S(f) as function of frequency f (representing intensity of input 
noise voltage source) should have −10 dB/decade slope in the low frequency range below flicker noise 
corner frequency fcor. For the f < fcor, the 1/f noise of drain current is the dominant component; and for 
f > fcor, the thermal noise of drain current is prevailing.
The flicker noise corner frequency fcor for v
f
n
2 /∆ can be calculated from the relation
	
f
K
kT
I
cor
f
D
=
⋅
⋅
3
16
β 	
(11.27)
The typical flicker noise corner frequency fcor for JFETs is in the range of several kHz.
For high and very high frequency, the noise factor F for JFETs can be calculated using relation (11.21), 
where vni
2 is the mean-square equivalent noise input voltage for the CS or the CG configuration of JFET, 
and RS is the noise source resistance [4].
11.3.3  Noise of MOSFETs
In Figure 11.7, the equivalent diagram of MOSFET with attached noise sources is presented. These are as 
follows: thermal noise of drain current ID and 1/f noise of drain current ID.
G
i 2
n
ν2
n
S
D
FIGURE 11.6  The v
i
n
n
2
2
− amplifier 
model of the JFET.
© 2011 by Taylor and Francis Group, LLC

11-10 
Fundamentals of Industrial Electronics
The intensities (mean-square values) of noise sources are given by the following relations:
	
i
kT
g
f
I
thd
m
D
2
4
2
3
=



⋅∆thermal noise of drain current
	
(11.28)
	
i
K
I
L C
f
f
I
fd
f
D
ox
D
1
2
2
/
=
⋅
⋅
α
γ ∆flicker noise of drain current 
	
(11.29)
where
L is the channel length
Cox is the gate oxide capacitance per unit area
Coefficients α i γ in properly fabricated MOSFETs are close to 1
Figure 11.8 shows the v
i
n
n
2
2
− amplifier model of the MOSFET with the equivalent input noise voltage 
and current vn
2 and in
2, respectively.
The equivalent input noise voltage and current (mean-square values) can be expressed by [4]
	
ν
γ
n
thd
fd
m
D
f
ox
i
i
g
kT
f
K I
K
f
KL C
f
2
2
1
2
2
2
4
3
4
=
+
=
⋅
⋅
+
⋅
⋅
/
∆
∆
	
(11.30)
	
in
2
0
=
	
(11.31)
where K is the transconductance coefficient.
From the noise power spectral density function S(f) versus fre-
quency f (representing intensity of input noise voltage source), the 
flicker noise corner frequency fcor can be found (see Figure 11.4). 
This noise corner frequency fcor for v
f
n
2/∆ can be evaluated from 
the relation
	
f
K
kTL C
I
K
cor
f
ox
D
=
⋅
⋅
⋅
3
16
2
	
(11.32)
For the f < fcor, the 1/f noise of drain current is the dominant 
component; and for f > fcor, the thermal noise of drain current is 
prevailing.
D
B
i 2
thd + i 2
1/fd
S
G
FIGURE 11.7  Equivalent diagram of MOSFET with noise sources.
B
S
G
ν 2
n
D
FIGURE 11.8  The v
i
n
n
2
2
− amplifier 
model of the MOSFET.
© 2011 by Taylor and Francis Group, LLC

Noise in Semiconductor Devices 
11-11
The typical values of fcor in MOSFETs could be even larger than 10 MHz. The noise level at very high 
frequencies is very low.
11.3.4  Low Noise Circuits for Low Frequency Range
There are special semiconductor devices named “noiseless” that have very low levels of noise, espe-
cially in the low frequency range. These are transistors (bipolar and unipolar), transistor pairs, specially 
matched transistors, and amplifiers. For these devices, the equivalent input noise voltage source or the 
equivalent input noise current source (see Figure 11.3 for BJTs, Figure 11.6 for JFETs, Figure 11.8 for 
MOSFETs) at low frequency is given in technical data by manufacturers. Typically, this information is 
given for 1 kHz (sometimes for 10 Hz) at the given value of the device current. For these devices, the 1/f 
noise intensity and flicker noise corner frequency are important.
For low noise system, the input (front-end) stages are very important. For small source resistances, 
the BJTs are the preferred devices for these stages, and typically they have about 10 times lower level of 
equivalent input noise voltage than JFETs. In the selection of the BJT, the large value of the current gain 
β and the small value of the base spreading resistance rb is important. For example, BJTs npn 2SD786 i 
pnp 2SB737 of Japanese company ROHM have β = 400 and rb = 4 Ω. Transistors MAT-2 from Analog 
Devices (monolithic transistor pair) have β = 500 and rb below 1 Ω. Noise parameters of transistors 
MAT 02E are as follows: intensity of equivalent input noise voltage source at collector current of 1 mA 
at frequency 10 Hz is equal to 1 6 2
. /
/
 nV
Hz, at frequency 100 Hz is 0 9 1
. /
/
 nV
Hz, and at frequency 
1–100 kHz is 0 85 1
.
/
/
 nV
Hz.
For high source resistances, the JFETs are the preferred choice. It is important that JFET transistors 
have large transconductance gm and small gate capacitance. For transistors 2N5515 made by INTENSIL, 
the intensity of equivalent input noise current source at 10 Hz and 1.6 mA is smaller than 1 fA
Hz
/
, and 
is the same up to 10 kHz. Whereas, the intensity of equivalent input noise voltage source at drain cur-
rent of 600 μA is 10 nV
Hz
/
. This transistor has fcor = 10 kHz at drain current of 600 μA; it means that 
at 10 kHz the intensity of 1/f noise is equal to intensity of white noise.
For low frequencies, MOSFETs should not be used because of the high level of 1/f noise.
There are also special operational amplifiers for low noise applications. One such amplifier is manu-
factured by Precision Monolithics Inc. and it has the intensity of equivalent input noise voltage source 
in the range 3 5 5 5
. / .
/
nV
Hz at 10 Hz and 3 3 8
/ .
/
nV
Hz at 1 kHz. Whereas, the intensity of equivalent 
current noise source is 1 7 4
. /
/
pA
Hz at 10 Hz, and 0 4 0 6
. / .
/
pV
Hz at 1 kHz. This low noise OPAMP 
has very small flicker noise corner frequency, which is equal to 2.7 Hz for equivalent input noise voltage 
source and 140 Hz for equivalent input noise current source. This amplifier is specially suited for small 
source resistances (RS < 1 kΩ). For input resistances larger than 1 kΩ, better noise property have ampli-
fiers OP-07 i OP-08. For very large input resistances, the better choice is OPA-128, which has intensity 
of equivalent input noise voltage source equal to 27 nV
Hz
/
 at 1 kHz, and intensity of equivalent input 
noise current source is 0 12
.
/
fA
Hz in the frequency range from 0.1 Hz to 20 kHz. The low noise ampli-
fiers AD 797 from Analog Devices has the intensity of equivalent input noise voltage source equal to 
1 7.
/
nV
Hz at 10 Hz and 0 9.
/
nV
Hz at 1 kHz. Similar properties have low noise amplifiers LT 1028/LT 
1128 from LINEAR TECHNOLOGY. They have the intensity of equivalent input noise voltage source 
equal to 1nV
Hz
/
 at 10 Hz and 1 1.
/
nV
Hz at 1 kHz. The flicker noise corner frequency fcor is very low 
and it is equal to 3.5 Hz.
A special low noise amplifier for sources with large resistances is TLC 2201. It has, at 100 Hz, the 
intensity of equivalent input noise voltage source of 10 nV
Hz
/
, and the intensity of equivalent input 
noise current source of 0 6.
/
fA
Hz.
In practical applications, for very low noise circuits, usually in the first stage of the system, low noise 
transistor is applied and then at the next stages low noise amplifiers are used. Special care should also be 
taken for proper design of power supplies.
© 2011 by Taylor and Francis Group, LLC

11-12 
Fundamentals of Industrial Electronics
References
	
1.	 Ambrozy A. Electronic Noise. Akademiai Kiadó, Budapest, Hungary, 1982.
	
2.	 Konczakowska A. Szumy z zakresu małych częstotliwości. Akademicka Oficyna Wydawnicza EXIT, 
Warszawa, Poland, 2006.
	
3.	 Lukyanchikova N. Noise Research in Semiconductor Devices. B. K. Jones (Ed.), Gordon and Breach 
Science Publisher, Amsterdam, the Netherlands, 1996.
	
4.	 Marshall Leach W. Jr. Fundamentals of Low-Noise Electronics. Georgia Institute of Technology, 
School of Electrical and Computer Engineering, Atlanta, GA, 1999–2008.
	
5.	 Motchenbacher C. D., Fitchen F. C. Low-Noise Electronic System Design. A Wiley-Interscience 
Publication, John Wiley & Sons, Inc., New York, 1993.
	
6.	 Van der Ziel A. Noise in Solid State Devices and Circuits. John Wiley & Sons, New York, 1986.
	
7.	 McWhorter A. L. 1/f noise and germanium surface prosperities. In Semiconductor Surface Physics. 
R. H. Kingdton (Ed.), University of Pennsylvania Press, Philadelphia, PA, 1957, pp. 207–228.
	
8.	 Hooge F. N. 1/f noise is no surface effect. Physics Letters, 29A (3), 1969, 139–140.
	
9.	 Hooge F. N. The relation between 1/f noise and number of electrons. Physica B, 162, 1990, 334–352.
	 10.	 Kleinpenning T. G. M. On 1/f noise and random telegraph noise in very small electronic devices. 
Physica B, 164, 1990, 331–334.
© 2011 by Taylor and Francis Group, LLC

12-1
12.1  Introduction
A sensor is used to transform a nonelectrical stimulation to an electrical response that is suitable to 
be processed by electrical circuits [W91]. Sensors are related with everyday life, such as automobiles, 
airplanes, radios, and countless other applications [BR90,RPSW01]. Several transformation steps are 
required before the electric output signal can be generated. These steps involve changes of types of 
energy where the final step must produce an electrical signal of a desirable format. There are several 
physical effects that cause generation of electric signals in response to nonelectrical influences. In this 
chapter, the physical effects behind various sensor applications that can be used for conversion of stim-
uli into electric signals are introduced, including piezoresistive effect, thermoelectric effect, piezoelectric 
effect, pyroelectric effect, temperature effect in p-n junction, and Hall effect.
12.2  Piezoresistive Effect
Piezoresistive effect describes the changes of electrical resistance when the material is mechanically 
deformed. It occurs in crystals that have no polar axes and is well represented in semiconductors. 
Physically, piezoresistance comes from the anisotropic distribution of energy levels in the k-space of the 
angular wave vector. This phenomenon is successfully employed in sensors that are sensitive to stress.
The relationship between relative changes in resistance ΔR/R (where R is specific resistivity) and the 
mechanical stress applied is given by
	
∆R
R
E
= πσ
	
(12.1)
12
Physical Phenomena 
Used in Sensors
12.1	 Introduction.....................................................................................12-1
12.2	 Piezoresistive Effect.........................................................................12-1
12.3	 Thermoelectric Effect......................................................................12-5
12.4	 Piezoelectric Effect..........................................................................12-5
12.5	 Pyroelectric Effect............................................................................12-6
12.6	 Photoelectric Effect in Semiconductors.......................................12-8
12.7	 Photoelectric Effect in p-n Junctions............................................12-9
12.8	 Temperature Effect in p-n Junctions............................................12-9
12.9	 Hall Effect....................................................................................... 12-11
12.10	 Conclusion......................................................................................12-12
References...................................................................................................12-12
Tiantian Xie
Auburn University
Bogdan M. 
Wilamowski
Auburn University
© 2011 by Taylor and Francis Group, LLC

12-2 
Fundamentals of Industrial Electronics
where π is the so-called piezoresistive coefficient, which is dependent on the crystal orientation and the 
conditions of measurement, for example volume constancy.
The relationship between the stress σ and deformation of the material can be presented as
	
σ = E
L
L
∆
	
(12.2)
where E is Young’s modulus of the material.
It is known that the resistance of a conductor can be calculated by
	
R
L
W Rs
=
	
(12.3)
where
Rs is the unit surface resistance of the material
L and W are the length and the width of the area, respectively
Considering the volume of the material as a constant, Equation 12.3 can be rewritten as
	
R
L
A Rs
=
2
	
(12.4)
where A is the area of the material.
Differentiating Equation 12.4, the following is obtained:
	
∆
∆
R
L
R L
A
s
= 2
	
(12.5)
By combining Equations 12.2, 12.4, and 12.5, the normalized resistance change of the wire can be 
rewritten as a linear function of the stress σ:
	
∆
∆
R
R
L
L
E
=
=
2
2 σ
	
(12.6)
In reality, the piezoresistive coefficients π contain 21 components. In the cubic system, only three of the 
components, π11, π12, and π44 are independent of each other. The same is true of monocrystalline silicon. 
The values of these coefficients depend on the type of conductor and the dosing level.
Let us derive the equations for 〈100〉 and 〈111〉 surface in a silicon wafer. For 〈100〉 surface of silicon, 
the changes of resistance can be measured by
	
∆R
R =
+
+
+
+
−


+
+
0 5
0 5
11
12
44
11
11
12
44
22
2
11
.
(
)
(
)
cos
.
(
π
π
π
σ
π
π
π
σ
φ
π
π
π
σ
π
π
π
σ
φ
π σ
π
π
σ
12
44
11
11
12
44
22
2
12
33
11
12
12
−
+
+
+


+
+
−
)
(
)
sin
(
)
sin(
)
2φ
α
+
T
	
(12.7)
where
π11, π12, and π44 are geometry-dependent constants (see Table 12.1)
α is the temperature coefficient
σ11, σ22, σ33, and σ12 are geometry-dependent stresses
© 2011 by Taylor and Francis Group, LLC

Physical Phenomena Used in Sensors 
12-3
It can be simplified to
	
∆R
R
T
=
+
+
+
+
+
−
0 5
0 5
2
11
12
11
22
12
33
44
11
22
. (
)(
)
.
(
)cos(
)
π
π
σ
σ
π σ
α
π
σ
σ
φ +
−
(
)
sin(
)
π
π
σ
φ
11
12
12
2
	
(12.8)
For n-type resistors, using the data in Table 12.1,
	
∆R
R
T
= −
+
+
+
−
−
−
244
534
68
2
1556
11
22
33
11
22
12
(
)
(
)cos(
)
sin(
σ
σ
σ
α
σ
σ
φ
σ
2φ)
	
(12.9)
For p-type resistors, using the data in Table 12.1,
	
∆R
R
T
=
+
−
+
+
−
+
27
11
690
2
77
2
11
22
33
11
22
12
(
)
(
)cos(
)
sin(
)
σ
σ
σ
α
σ
σ
φ
σ
φ
	
(12.10)
A sum of two perpendicular resistors is not a function of angular location and
	
∆
∆
R
R
R
R
T
1
1
2
2
11
12
11
22
12
33
0 5
+
=
+
(
)
+
(
)+
+
.
π
π
σ
σ
π σ
α
	
(12.11)
A difference is a function of angular location:
	
∆
∆
R
R
R
R
1
1
2
2
44
11
22
11
12
12
2
2
2
−
=
−
(
)
(
)+
+
(
)
(
)
π
σ
σ
φ
π
π
σ
φ
cos
sin
	
(12.12)
To measure σ11 − σ22, ϕ = 0° and 90° should be used (preferably p-type); while to measure σ12, ϕ = −45° 
and 45° should be used (preferably n-type).
TABLE 12.1  Parameters for Silicon Wafer
n-Type [1/TPa]
p-Type [1/TPa]
π11
−1022
66
π12
534
−11
π44
−136
1381
π11 + π12
−488
55
π11 − π12
−1556
77
B1
−312
718
B2
297
−228
B3
61
−446
C1
−7
245
C2
−305
473
C3
670
615
© 2011 by Taylor and Francis Group, LLC

12-4 
Fundamentals of Industrial Electronics
For 〈111〉 surface of silicon,
	
∆R
R
B
B
B
B
B
B
B
B
=
+
+
+
−


+
+
+
1
11
2
22
3
33
2
3
23
2
2
11
1
22
3
2 2
σ
σ
σ
σ
φ
σ
σ
(
)
cos
σ
σ
φ
σ
σ
33
2
3
23
2
2
3
13
1
2
12
2 2
2 2
−
−


+
−
+
−


(
)
sin
(
)
(
)
sin(
B
B
B
B
B
B
2φ
α
) +
T
	
(12.13)
where
	
B
B
B
1
11
12
44
2
11
12
44
3
11
12
44
2
5
6
2
3
=
+
+
=
+
−
=
+
−
π
π
π
π
π
π
π
π
π
,
,
	
(12.14)
It can be simplified to
	
∆R
R
C
B
T
C
C
C
=
+
+
+
+
−
+
+
1
11
22
3
33
2
11
22
3
23
2
1
2
2
(
)
[
(
)
]cos(
)
[
σ
σ
σ
α
σ
σ
σ
φ
σ 2
3
13
2
+ C σ
φ
]sin(
)
	
(12.15)
where
	
C
C
C
1
11
12
44
2
11
12
44
3
11
12
44
2
4
6
2
6
2 2
6
=
+
+
=
−
+
=
−
+
+
π
π
π
π
π
π
π
π
π
,
,
	
(12.16)
For n-type resistors, using the data in Table 12.1,
	
∆R
R
T
= −
+
+
+
+ −
−
+
+ −
7
61
305
670
2
6
11
22
33
11
22
23
(
)
[
(
)
]cos(
)
[
σ
σ
σ
α
σ
σ
σ
φ
10
670
2
12
13
σ
σ
φ
+
]sin(
)
	
(12.17)
For p-type resistors, using the data in Table 12.1,
	
∆R
R
T
=
+
−
+
+
−
+
+
245
446
473
750
2
9
11
22
33
11
22
23
(
)
[
(
)
]cos(
)
[
σ
σ
σ
α
σ
σ
σ
φ
4
750
2
12
13
σ
σ
φ
+
]sin(
)
	
(12.18)
The sum of two perpendicular resistors is
	
∆
∆
R
R
R
R
C
B
T
1
1
2
2
1
11
22
3
33
+
=
+
(
)+
+
σ
σ
σ
α
	
(12.19)
For n-type resistor on 〈111〉 surface
	
∆
∆
∆
R
R
R
R
T
1
1
2
2
11
22
33
7
61
2000
+
= −
+
(
)+
+
σ
σ
σ
	
(12.20)
where σ is in MPa and ΔT is in °C.
© 2011 by Taylor and Francis Group, LLC

Physical Phenomena Used in Sensors 
12-5
For p-type resistor on 〈111〉 surface
	
∆
∆
∆
R
R
R
R
T
1
1
2
2
11
22
33
245
446
2000
+
=
+
(
)−
+
σ
σ
σ
	
(12.21)
As shown above, the piezoresistive effect in silicon can be several orders of magnitudes larger than in 
metals, making it a good member for piezoresistive sensors. However, the silicon is very sensitive to 
temperature. Additional methods should be adopted to counteract the temperature effect to make the 
sensor more accurate.
12.3  Thermoelectric Effect
Thermoelectric effect is also called Seebeck effect in honor of East Prussian scientist Thomas Johann 
Seebeck (1770–1831) [AE92]. He observed that an electrical current was present in a series circuit of two 
different metals that were contacted and at different temperatures.
When different conductors A and B are connected together, free electrons behave like an ideal gas. For 
different materials, the energies and densities of free electrons are different. Kinetic energy of electrons 
is a function of the temperature. At the same temperature, when two different materials contact, free 
electrons diffuse through the junction (contacting point). The electric potential of the material accept-
ing electrons becomes more negative at the interface, while the material emitting electrons becomes 
more positive. Different electronic concentrations across the junction set up an electric field that bal-
ances the diffusion process until equilibrium is established. When the two materials are at different 
temperatures, the voltage at the junction can be presented as (Figure 12.1)
	
dV
dT
S
S
AB
A
B
=
−
	
(12.22)
where SA and SB are the absolute Seebeck coefficients of the conductors A and B, respectively.
Conversely, when a voltage is applied to the conductors A and B in Figure 12.1, it creates a temperature 
difference between side A and side B.
The differential Seebeck coefficient SAB = SA − SB is called the sensitivity of a thermocouple junction. 
The Seebeck coefficient is independent on the characteristic of the junction, but only related with the 
materials. Therefore, to achieve the best sensitivity, the differential Seebeck 
coefficient of those junction materials should be as large as possible.
12.4  Piezoelectric Effect
Piezoelectric effect is the property of certain crystals that can generate a 
voltage subjected to a pressure and conversely generate a pressure due to an 
applied voltage [DN92]. The effect exists in crystals that do not have a sym-
metrical center.
Each molecule in piezoelectric crystal is polarized: one side is negatively 
charged while the other side is positively charged, which is also named as a 
dipole. This is due to the different atoms that make up the molecule, and the 
way in which the molecules are shaped. The polar axis runs through the cen-
ter of both charges in the molecule and the molecule is electrically neutral 
under non-stress conditions. When external force is applied, the lattice is 
deformed and the electric field is built up; conversely, when the piezoelectric 
T1
A
VAB
T2
B
FIGURE 12.1  Voltage of 
two conductors with dif-
ferent temperatures con-
nected in series.
© 2011 by Taylor and Francis Group, LLC

12-6 
Fundamentals of Industrial Electronics
crystal is under a strong electric field, most of the dipoles in the crystal are forced to line up in nearly the 
same direction, which results in mechanical stress.
Piezoelectricity is the combined effect of the electrical behavior of the crystal:
	
D
E
= ε
	
(12.23)
where
D is the electric charge density displacement (electric displacement)
ε is the permittivity
E is the electric field strength
Using Hooke’s law,
	
L
s
= σ 	
(12.24)
where
L is strain
s is compliance
σ is the stress
By combining Equations 12.7 and 12.8, the piezoelectric effect can be described as
	
{ }
[
]{ }
[
]{ }
{ }
[ ]{ }
[
]{ }
L
s
d
E
D
d
E
=
+
=
+
E
T
s
s
eσ
	
(12.25)
where
{} and [] standard for vector and matrix separately
d is the piezoelectric coefficient
[d] is the matrix for the direct piezoelectric effect
transposed [d T] is the matrix for the converse piezoelectric effect
the superscript E indicates under a zero or constant electric field
the superscript σ indicates under a zero or constant stress field
Piezoelectric crystals perform direct conversion between mechanical and electrical energy. Efficiency 
of the conversion is defined by the coupling coefficients k:
	
k
d
h
=
×
	
(12.26)
where h is the gradient of electric field E multiplied by Young’s modulus.
The k-coefficient is an important characteristic for applications where energy efficiency is of prime 
importance, like in acoustics and ultrasonics.
12.5  Pyroelectric Effect
Pyroelectric effect is the phenomenon of generating a temporary electrical potential when materials are 
heated or cooled [ZL78]. Different from thermoelectric devices that produce steady voltages, pyroelec-
tric devices generate dynamical charges corresponding to the change of temperatures. So a pyroelectric 
device is usually used as a heat flow detector rather than a heat detector.
© 2011 by Taylor and Francis Group, LLC

Physical Phenomena Used in Sensors 
12-7
Pyroelectric effect is very tightly connected to the piezoelectric effect. There are several mechanisms 
that will result in pyroelectricity. Temperature changes cause shortening or elongation of individual 
dipoles. It may also affect the randomness of the dipole orientations due to thermal agitation. This is 
the primary pyroelectricity. The second pyroelectricity is induced by the strain in material caused by 
thermal expansion, which may be described as a result of the piezoelectric effect. Of the classic 32 crystal 
structures, 10 of these exhibit pyroelectric properties.
The pyroelectric charge coefficient, PQ, is defined as
	
P
P
T
Q
S
= ∂
∂
	
(12.27)
and the pyroelectric voltage coefficient, PV, as
	
P
E
T
V = ∂
∂
	
(12.28)
where
PS is the spontaneous polarization
E is the electric field strength
T is the absolute temperature
By combining Equations 12.27 and 12.28,
	
P
P
P
E
Q
V
S
r
= ∂
∂
=
=
ε
ε ε0
	
(12.29)
where
ε0 is the electric permittivity of vacuum
εr is the electric permittivity of the materials
If a pyroelectric material is exposed to a heat source, its temperature rises by ΔT and the corresponding 
charge and voltage changes can be calculated by
	
∆
∆
∆
∆
Q
P A T
V
P L T
Q
V
=
=
	
(12.30)
where A and L is the area and thickness of the material separately.
Since the capacitance is defined as
	
C
Q
V
A
L
r
=
=
∆
∆
ε ε0
	
(12.31)
Integrating Equations 12.13 through 12.15, the relationship between ΔV and ΔT can be described as
	
∆
∆
V
T P L
Q
r
=
ε ε
0
	
(12.32)
© 2011 by Taylor and Francis Group, LLC

12-8 
Fundamentals of Industrial Electronics
One may notice that the output voltage is proportional to the sensor’s 
temperature change, pyroelectric charge coefficient, and its thickness.
The equivalent electrical circuit of the pyroelectric sensor is shown 
in Figure 12.2. It consists of three components: the current source gen-
erating a heat induced current i; the parasitic capacitance C, and the 
leakage resistance R.
12.6  Photoelectric Effect in Semiconductors
A photoelectric effect is any effect in which light energy is converted to electricity. When light strikes 
certain light-sensitive materials, it may cause them to give electrons, or change their ability to conduct 
electricity, or may cause them to develop an electrical potential or voltage across two surfaces.
When a surface is exposed to electromagnetic radiation above a certain threshold frequency, the radiation 
is absorbed and electrons are emitted. This is called photoelectric effect, which was discovered by A. Einstein. 
The required photon energy must equal or exceed the energy of a single photon, which is given by
	
E
hv
=
	
(12.33)
where
v is the frequency of light
h is Planck’s constant equal to 6.63 × 10−34 J·s
Considering the relationship between frequency and the wavelength, the energy in Equation 12.33 
can be written as the function of wavelength
	
E
hc
=
=
×
⋅
−
λ
λ
1 24
10 7
.
[
]
eV s 	
(12.34)
where
c is the light speed in materials
λ is the wavelength of light
For Si, the value of E at room temperature is 1.12 eV. However, in a real semiconductor crystal other 
excitation mechanisms are possible. These include absorption through transitions between the allowed 
bands and absorption through high levels of distortion in the forbidden band. However, the greatest 
excitation effect is still provoked by band-to-band absorption.
The electromagnetic radiation can be classified from low frequency to high frequency as infrared, 
visible, and ultraviolet, respectively. The electromagnetic frequency spectrum is shown in Figure 12.3.
i
C
R
FIGURE 12.2  Equivalent cir-
cuit of pyroelectric sensor.
1
1
Infrared
InSb
GaAs
GaP
CdSe
CdS
ZnS
Ge
Si
SiC
Visible
Ultraviolet
0.5
0.35
4
5
Eg (ev)
λ (um)
7
0
2
2
3
3
FIGURE 12.3  Electromagnetic frequency spectrum.
© 2011 by Taylor and Francis Group, LLC

Physical Phenomena Used in Sensors 
12-9
When light is absorbed by a semiconductor, a current can be induced and thus cause the change of 
resistance of the material. As shown in Figure 12.4, the semiconductor in thermal equilibrium contains 
free electrons and holes. The optical field to be detected is incident on and absorbed in the crystal, 
thereby exciting electrons into the conduction band or, in p-type semiconductors, holes into the valence 
band. The electronic deficiency thus created is acted upon by the electric field, and its drift along the field 
direction gives rise to the signal current.
12.7  Photoelectric Effect in p-n Junctions
When light strikes a semiconductor p-n junction, its energy is absorbed by electrons. Electrons and 
holes generated by light in the p-n junction are swept by the junction electrical field. As a result, the 
current flows though the junction. Figure 12.5 shows the process of generating current in photo diode.
Figure 12.5a is the p-n junction with a depletion layer without light. When the p-n junction is exposed 
to light, the impinging photons create electron–hole pairs everywhere in n-type area, p-type area, and 
depletion layer. In the depletion layer, the electric field accelerates electrons toward the n-layer and the 
holes toward the p-layer (Figure 12.5b).
For the electron–hole pairs generated in the n-layer, the electrons, along with electrons that have 
arrived from the p-layer, are left in the n-layer conduction band. The holes at this time are being dif-
fused through the n-layer up to the depletion layer while being accelerated, and collected in the p-layer 
valence band. In this manner, electron–hole pairs that are generated in proportion to the amount of 
incident light are collected in the n- and p-layers. This results in a positive charge in the p-layer and a 
negative charge in the n-layer. If an external circuit is connected between the p- and n-layers, electrons 
will flow away from the n-layer, and holes will flow away from the p-layer toward the opposite respective 
electrodes (Figure 12.5c). The current is thus generated.
12.8  Temperature Effect in p-n Junctions
The temperature effect of p-n junction can be utilized as a temperature sensor. The principal sensor is 
straightforward. The I–V characteristic of the diode is as follows:
	
I
I
qV
kT
D
S
D
=



−




exp
1
	
(12.35)
where
VD is the applied voltage
q is electronic charge equal to 1.60 × 10−19 C
k is Boltzmann’s constant equal to 1.38 × 10−23 J/K
T is absolute temperature
IS is the reverse saturation current of diode
Conduction band
Energy gap
Valence band
hv
–
+
FIGURE 12.4  Photoconductive effect in semiconductor.
© 2011 by Taylor and Francis Group, LLC

12-10 
Fundamentals of Industrial Electronics
	
I
Aqn
N D dx
N D dx
S
i
p
x
n
x
n
p
=
+










∫
∫
2
0
0
1
1
(
/
)
(
/
)
	
(12.36)
where ni is calculated by
	
n
N N T
E
kT
i
v
c
g
2
3
=
−




exp
	
(12.37)
By combining Equations 12.12 through 12.14, the voltage of the diode can be calculated by
	
V
kT
q
I
I
kT
q
I
I
D
D
S
D
S
=
+



≅




ln
ln
1
	
(12.38)
Since IS is proportional to ni
2 (Equation 12.13), taking the derivative with respect to temperature yields
	
∂
∂
=



−
∂
∂
=
−
−
V
T
k
q
I
I
kT
q I
I
T
V
kT q
E
q
T
D
D
S
S
S
D
g
ln
(
/ ) (
/ )
1
3
	
(12.39)
n-Type material
p-Type material
Depletion layer
(a)
Electrons
Holes
Space charge —positive 
Space charge—negative 
n-Type material
p-Type material
Depletion layer
(b)
Electrons
Holes
Space charge —positive 
Space charge —negative 
(c)
n-Type material
p-Type material
Depletion layer
Electrons
Holes
Space charge —positive 
Space charge —negative 
FIGURE 12.5  Photo diode: (a) p-n junction; (b) carrier generation in depletion layer associated with carrier sweep 
in electric field of depletion layer (fast process); (c) carrier generation in bulk material associated with minority carrier 
diffusion toward junction (slow process).
© 2011 by Taylor and Francis Group, LLC

Physical Phenomena Used in Sensors 
12-11
where Eg is the semiconductor bandgap energy. The relationship 
between dVD/dT and VD for a silicon diode is shown in Figure 
12.6. dVD/dT decreases with temperature increasing.
With a constant current applied, the voltage across a diode 
or p-n junction will decrease by approximately 1–2 mV/°C. The 
diode voltage vs. temperature can be characterized by placing 
the amplifier in a temperature chamber with a constant current 
applied to the diode junction.
12.9  Hall Effect
The Hall effect was discovered in 1879 in Johns Hopkins 
University by E.H. Hall. The effect is based on the interaction 
between moving electric carriers and an external magnetic field. 
When an electron moves through a magnetic field, it acts as a 
sideways force
	
F
qvB
=
	
(12.40)
where
q is an electronic charge
v is the speed of an electron
B is the magnetic field
When the electric current source I is perpendicular to the magnetic field B, as shown in Figure 12.7, 
the so called Hall voltage, VH, is produced in the direction perpendicular to both B and I. VH is given by
	
V
IB
qnd
H =
	
(12.41)
where
d is the thickness of the hall plate
n is the carrier density
2.5
–40°C
–25
–10
5
65
35
50
20
80
95
110
125
140
2
1.5
0.55
0.6
0.65
0.7
VD (V)
T
dVD/dT (mV/K)
0.75
0.8
1
FIGURE 12.6  Relationship between dVD/dT and VD for a silicon diode.
B
+
–
VH
I
FIGURE 12.7  Principle of Hall effect.
© 2011 by Taylor and Francis Group, LLC

12-12 
Fundamentals of Industrial Electronics
One very important feature of the Hall effect is that it differentiates between positive charges moving in 
one direction and negative charges moving in the opposite.
Hall effect devices produce a very low signal level and thus require amplification. The Hall sensors 
can be used to detect magnetic fields, position, and displacement of objects.
12.10  Conclusion
The physical phenomena described above are frequently used in various sensors. For example, piezoresis-
tive effect and piezoelectric effect can be used to measure both pressure and acceleration. Thermoelectric 
effect, pyroelectric effect, and temperature effect in p-n junction are usually applied in temperature sen-
sors, bolometers, and so on. Photoelectric effect is used in light detectors such as photodiodes and ther-
mal detectors. Hall effect is always used in measuring magnetic fields and sensing position and motion.
References
[AE92] Boyer, A. and Cisse, E., Properties of thin films thermoelectric materials: Application to sensors 
using the Seebeck effect, Materials Science & Engineering, 13, 103–111, 1992.
[BR90] Barshan, B. and Kuc, R., Differentiating sonar reflections from corners and planes by employing 
an intelligent sensor, IEEE Transactions on Pattern Analysis and Machine Intelligence, 12, 560–569, 
1990.
[DN92] Damjanovic, D. and Newnham, R. E., Electrostrictive and piezoelectric materials for actuator 
applications, Journal of Intelligent Material Systems and Structures, 3, 190–208, 1992.
[RPSW01] Leonhard, M. R., Alfred, P., Gerd, S., and Robert, W., SAW-based radio sensor systems, IEEE 
Sensors Journal, 1, 69–78, 2001.
[W91] White, R. W., A sensor classification scheme, In Microsensors, IEEE Press, New York, pp. 3–5, 1991.
[ZL78] Zook, J. D. and Liu, S. T., Pyroelectric effects in thin film, Journal of Applied Physics, 49, 4604, 1978.
© 2011 by Taylor and Francis Group, LLC

13-1
13.1  Introduction
Since the appearance of microelectromechanical systems (MEMS) technologies in the early 1950s, 
a traditional classification in two main classes, sensors and actuators, regarding the direction of its 
interaction with their surroundings, has been accepted. However, the large increase of new concepts 
and applications make this rather minimalist, and the increase in their functionality deserves a wider 
description.
It can be stated that MEMS functional development has two main limitations: actual technological 
constraints, which are improving quite fast, and engineering creativity. But we should not forget that, in 
the end, the market decides if a smart design should become a successful product.
In the case of sensor devices, miniaturization is quite a positive feature because the interface with 
the real world is greatly reduced. For example, only picoliters of samples and analytes are required 
in a lab-on-chip (LoC), making the mass and energy transportation more precise and faster. But the 
13
MEMS Devices
13.1	 Introduction.....................................................................................13-1
13.2	 Sensing and Measuring Principles................................................13-2
Capacitive Sensing  •  Resistive Sensing  •  Piezoelectric 
Sensing  •  Thermal Transducers  •  Optical Sensors  •  Magnetic 
Sensors
13.3	 MEMS Actuation Principles..........................................................13-9
Introduction  •  Electrostatic Actuation  •  Thermal 
Actuation  •  Piezoelectric Actuation  •  Magnetic Actuation
13.4	 MEMS Devices...............................................................................13-12
Inertial Sensors  •  Pressure Sensors  •  Radio Frequency 
MEMS: Capacitive Switches and Phase Shifters  •  Microfluidic 
Components  •  Optical Devices
References...................................................................................................13-30
José M. Quero
University of Seville
Antonio Luque
University of Seville
Luis Castañer
Polytechnic University 
of Catalonia
Angel Rodríguez
Polytechnic University 
of Catalonia
Adrian Ionescu
Ecole Polytechnique 
Fédérale de Lausanne
Montserrat 
Fernández-Bolaños
Ecole Polytechnique 
Fédérale de Lausanne
Lorenzo Faraone
University of Western 
Australia
John M. Dell
University of Western 
Australia
© 2011 by Taylor and Francis Group, LLC

13-2 
Fundamentals of Industrial Electronics
inherent small amount of energy that a miniature device can handle makes the interfacing with the 
external world a key issue in actuator design. A sort of amplification scheme is needed to make micro 
effects to be significative in the macroworld. This way of interaction explains the success of devices like 
displays or barcode readers based on micromirrors that deflect a laser beam creating large projections in 
the macroworld, or the aggregated action of fast multiple actuations, like those in ink-jet printers whose 
small drops become visible to the human eye.
Major MEMS sensing technologies include piezoresistive, capacitive, thermoelectric, or piezoelectric. 
The use of structures in resonant mode is commonly employed because it simplifies the circuitry and 
increases the sensitivity of the transducer [1–2].
A generic definition of MEMS actuators defines these devices as integrated energy converters, 
exchanging energy from one physical domain to another. The basic actuation principles are electro-
static, magnetic, thermal, piezoelectric, and optical, but nowadays we also include other devices like 
microbatteries and energy scavengers into this class.
In the following sections, a brief description of the main MEMS devices is included, with special 
emphasis on their basic functioning principles. However, we should keep in mind the basic MEMS defi-
nition that conceives these devices as smart systems that comprise all necessary building blocks to be 
self-contained. For this reason, actual research focuses on the increase of the integration level to include 
in a common package the MEMS device, controller, communication interface, and energy, and thus 
creates a full MEMS device (Figure 13.1).
13.2  Sensing and Measuring Principles
13.2.1  Capacitive Sensing
Two conductors placed at a given distance electrically isolated from each other form a capacitor. If the 
capacitor is formed by two flat, parallel conducting plates, i.e., rectangular of length L and width W 
separated by a distance d, L and W being much bigger than d, the capacitance is given by
	
C
W L
d
=
⋅
ε
	
(13.1)
where ε is the dielectric constant of the insulating material in between the plates.
Energy
External
interfacing
Packaging
MEMS
sensor/
actuator
Signal
processing/
controller
Communi-
cation
Macroworld
FIGURE 13.1  Block diagram of a full MEMS device.
© 2011 by Taylor and Francis Group, LLC

MEMS Devices 
13-3
Capacitors are frequently used in MEMS sensors as they can provide high sensitivity and linear-
ity, and they provide useful, easy to handle electrical signals. Any of the parameters of the capacitor 
can be used for sensing if adequately linked to the physical magnitude to detect. A variety of methods 
allow to precisely measure the capacitances, providing the information of the evolution of that physical 
magnitude.
An example of this is the capacitive monitorization of a mechanical vibration, where one of the plates 
of a capacitor is attached to the vibrating point, and the second one is fixed closely, i.e., in the direction of 
the vibration. The vibration changes the distance d between the plates and, therefore, the measurement of 
C gives precise information of the instantaneous position of the moving plate.
When a voltage V(t) is applied to a capacitor whose capacitance varies with time, the current of the 
device can be expressed as
	
i
C V
t
V
C
t
=
∂
∂
+
∂
∂
	
(13.2)
The first term is the current of a constant capacitor, while the second term provides information about 
the capacitance variation, and therefore of the parameter under study.
Usual values of capacitance of MEMS devices range from femto to pico Farads. The measurement 
of these low-capacitance values may involve the apparition of noise. The approximation of the capaci-
tance assuming flat parallel plates is very poor and more complicated expressions and simulations have 
to be used.
13.2.2  Resistive Sensing
Metallic and semiconductor resistors are frequently used in MEMS technology. They can be fabricated 
by deposition and lithography of the resistor material onto an insulating layer. Semiconductor resistors 
can also be obtained by selective doping of a semiconductor substrate [3].
The piezoresistive effect is the dependence of a resistor on the strain of the material in which it is fabri-
cated. Both metals and semiconductors can be used to make piezoresistors. Piezoresistors are frequently 
used in MEMS devices to measure stress, deformation, or bending, i.e., in vibrating structures such as 
membranes, bridges, and cantilevers.
In metals, piezoresistance is due to the geometrical changes caused by stress. In semiconductors, 
piezoresistance can be much higher than in metals because the stress induces changes in the band dia-
gram and this has a strong effect on the amount of free carriers available for conduction.
In semiconductors, piezoresitance depends on the type and dose of doping, and in crystalline semicon-
ductors, the piezoresistance effect also depends on the crystal orientation of the strain and of the resistor [4].
In a resistor deformed by a stress, the relative variation of resistance due to a deformation dL can be 
expressed as
	
dR
R
dL
L
d
=
+
+
(
)
1
2ν
ρ
ρ 	
(13.3)
where
ν is the Poison ratio
dρ/ρ is the relative variation of the resistivity of the material due to the deformation
The gauge factor is the measure of the strain sensitivity of a material. For a thin film device of length L, 
the gauge factor G is defined as the ratio
© 2011 by Taylor and Francis Group, LLC

13-4 
Fundamentals of Industrial Electronics
	
G
R R
L L
E
=
= +
+
∆
∆
/
/
1
2ν
π
	
(13.4)
where
E is the strain
π is the piezoresistance coefficient that relates the stress τ and the variation of resistivity of the mate-
rial (δρ/ρ=πτ)
To account for the three-dimensional components of the stress, the crystalline orientation and the 
crystal anisotropy π is in general a tensor of 21 parameters, but thanks to the symmetries in the case of 
crystalline silicon, it can be reduced to only three independent elements: π11, π12, and π44 [5].
The stresses and the piezoresistance coefficients can be defined as longitudinal πl (along the direction 
of the current flow), and transversal πt (perpendicular to the flow), and πs due to shear stress.
	
∆
∆
∆
=
=
+
+
R
R
t
l
l
t
s
s
,
π σ
π σ
π σ
	
(13.5)
Commonly, the resistor is a thin film, whose thickness is much smaller than its length L and its 
width W, and the shear component can be neglected.
Usually, piezoresistors are integrated as components of Wheatstone bridges initially designed to be 
balanced and therefore providing zero output voltage. The variation of one or more of the resistors of the 
bridge implies one output voltage related to the variation.
13.2.3  Piezoelectric Sensing
The piezoelectric transduction is an efficient way to convert mechanical vibrations into electrical sig-
nals and vice versa. The piezoelectric effect consists on the generation of electric charge by a material 
when subjected to a mechanical deformation. This is an anisotropic effect. The redistribution of elec-
trical charges in the piezoelectric material causes variations of the electrical field inside the material. 
Electrical voltages that are functions of the deformation appear in the surfaces of the crystal. In most 
occasions, this is a linear effect. The reverse piezoelectric effect consists on the appearance of a mechani-
cal deformation as reaction to the application of externally applied voltages.
Even though structures like diodes or bipolar transistors show piezoelectric properties, silicon is not 
a piezoelectric material; therefore, layers of piezoelectric materials are deposited to obtain this func-
tionality in integrated devices. Piezoelectric materials used in sensors are zinc oxide (ZnO), aluminium 
nitride (AlN), PZT, etc. They are deposited by RF sputtering, evaporation, etc.
Mechanical waves are easily produced in the piezoelectric material by using sinusoidal volt-
age excitation. This gives place to mechanical resonances at high enough frequencies. Mechanical 
resonances originate resonance peaks in the measured admittance between the electrodes of the 
capacitor.
Acoustic sensing frequently uses piezoelectric transducers. They can be used in viscous liquids. This 
is used to make microbalances and other types of sensors. In bulk acoustic wave (BAW), the mechanical 
wave propagates through the material. Resonances are found at frequencies at which the material thick-
ness is an integer number of half wavelengths.
Piezoelectric resonators often have high-quality factors Q, what is a measure of the sharpness of the 
resonance, defined as the quotient of the resonance frequency over the pass band width.
BAW resonators frequently work at moderate frequencies allowing the use of low-cost electronics. An 
important application of these devices is gravimetric sensing.
© 2011 by Taylor and Francis Group, LLC

MEMS Devices 
13-5
Gravimetric sensors measure variations of mass deposited on the 
surfaces of the resonator. Sawerbrey demonstrated that an increase 
of mass (Δm) causes a shift (Δf) of the resonant frequency (fres):
	
∆
∆
f
f
S
m
res
m
=
	
(13.6)
Changes of mass are then translated into frequency variations that can be easy and precisely mea-
sured. Sm is a negative number that depends on the material, physical dimensions, and operating 
frequency.
In surface acoustic wave (SAW) devices, mechanical waves propagate in regions close to the surface 
of the material. Usually, SAW devices work at RF frequencies. Woking as gravimetric sensors, they pro-
vide higher frequencial variations than BAW sensors. The fact that the energy of the propagating wave 
is concentrated near the surface makes these devices more sensitive to variations in the surface than 
BAW resonators. In SAW fabrication, wave emitters and receivers are placed in the surface of the piezo-
electric material. Fundamentally, their working mechanism is the same as in the case of BAW devices. 
SAW devices can be fabricated on piezoelectric and non-piezoelectric substrates, for instance, silicon 
or GaAs.
Different types of surface waves can be excited: Raileigh, Lamb, Love, STW, etc. The type of acoustic 
wave generated in a piezoelectric material depends mainly on the substrate material properties, the 
crystal cut, and the structure of the electrodes.
Wave excitation and detection is usually done with interdigitated electrodes, and then called inter-
digitated transducers (IDTs). They consist of a high number of parallel line electrodes (fingers) disposed 
perpendicularly to the desired direction of the propagation of the wave. Alternating fingers are con-
nected together so that half of them are connected to one contact, and the other half to the other, as in 
Figure 13.2.
Applying a sinusoidal voltage to the IDT generates a mechanical wave in the interdigital space between 
two neighbor electrodes. As this wave propagate interferes with the waves generated by other electrodes. 
Adequate electrode spacing makes generated waves interfere constructively. Therefore, the transduction 
efficiency is proportional to the number of fingers of the IDT. IDTs are fabricated by depositing a metal-
lic film onto the piezoelectric, and lithographically patterned to the desired shape.
Piezoelectric coefficients are temperature dependent. Temperature variation in sensors has to be 
compensated. Often, SAW sensors use pairs of devices, one of them actually sensing and the other act-
ing as reference. Even though semiconductors like silicon are not piezoelectric, SAW devices can be 
fabricated on silicon substrates.
Piezoelectric devices are often applied to sensors like gas or biosensors and to RF devices like filters. 
Designers have to pay attention to wave reflections at the borders of the device as they can introduce 
undesired resonances in the transfer function of the device. Reflecting structures can be added to the 
device to direct the generated waves to the desired regions.
13.2.4  Thermal Transducers
Different applications use thermal sensors. For instance, chemical or biological processes generate heat 
and, therefore, can be monitored by measuring their temperature; these thermal sensors are called 
Termistors. Bolometers are thermal transducers that measure radiation by absorbing the wavelengths 
of interest in small volumes of material well isolated thermally from the surroundings. MEMS technol-
ogy makes possible the integration of these devices in very small volumes and their thermal isolation; 
therefore, low powers may produce precisely measurable temperature variations.
IDT
Finger
+
FIGURE 13.2  Layout of an IDT.
© 2011 by Taylor and Francis Group, LLC

13-6 
Fundamentals of Industrial Electronics
13.2.4.1  Metallic Thermoresistors
The resistivity of metals varies with temperature. This is used to fabricate thermal sensors. Over a broad 
range of temperatures, the dependence of the resistivity of a metal film with T is almost linear. This 
dependence is mainly due to the dependence of the mobility of free carriers on T. Due to lattice vibra-
tion scattering, the free carriers suffer from high scattering and their mobility decreases as temperature 
increases, therefore increasing the resistivity. This is the dominant scattering process for pure metals 
at temperatures higher than about 100 K. At low temperatures, scattering is dominated by impurities, 
which are almost temperature independent.
Platinum is the most used metal in metallic thermoresistor fabrication as it provides highly precise 
and reliable devices. Alternative metals are tungsten, copper, or nickel, among others. The variation of 
platinum resistance is very linear with temperature dependence of up to 500°C.
In the range of temperatures from about 75 K to over 1100 K, the resistance of a platinum sensor is 
usually expressed as
	
R T
R
AT
BT
CT
T
( )
(
(
C))
=
+
+
+
−
°
0
2
3
1
100
	
(13.7)
where
A = 3.908 × 10−3 K−1
B = −5.775 × 10−7 K−2
C = −4.183 × 10−12 K−4
T in °C
Since in metals the resistively is low, to obtain useful devices, resistors are usually thin and long. 
Commonly, they are designed with meander shapes to concentrate on a given part of the chip. Common 
thicknesses are several tenths of micron.
The fabrication process involves the deposition (by sputtering or evaporation) of a thin film of the 
desired metal onto an oxidized silicon wafer, or other type of substrate, provided there is adequate 
electrical isolation from the bulk. Lithography and etching are used to shape the resistor. Their precise 
values can be tuned by laser trimming.
13.2.4.2  Semiconductor Thermoresistors
Semiconductor resistors may present positive or negative dependence with temperature depending on 
the semiconductor, doping concentration, and temperature of work. The conductivity of a semiconduc-
tor is a function of the concentration of free carriers (electrons and holes) and of their mobilities. In 
general, carrier mobilities decrease with temperature due to the increase in scattering; this alone would 
provide positive thermal dependence to the resistance. On the other hand, carrier concentrations ini-
tially clamped to nearly the doping concentration at high enough temperatures rise exponentially with 
T, as the intrinsic carrier concentration dominates over doping, then the resistivity decreases as temper-
ature increases. Semiconductor resistors can be obtained with polycrystalline or crystalline materials. 
In crystalline materials, resistivities are somewhat dependent on crystallographic orientation.
13.2.4.3  Semiconductor P-N Junction and BJT Thermal Sensors
Semiconductor P-N junctions or bipolar junction transistors (BJTs) have current–voltage relationships 
strongly dependent on temperature. This has been used for a long time in integrated electronics to ther-
mally compensate integrated circuits (ICs) or to measure temperature. The integration of these devices 
is generally easy, not only in control circuitry but also in membranes or cantilevers of a MEMS device.
Some circuital configurations are of special interest for temperature measurement. If the current of a 
diode is imposed by a current source, the voltage of the diode is related to the temperature of the junc-
tion. This voltage represents a very linear measurement of the temperature of the junction. Typically, for 
a silicon diode operated in the range from microamperes to several miliamperes, the voltage variation 
© 2011 by Taylor and Francis Group, LLC

MEMS Devices 
13-7
per degree of temperature has a value from −1 to −3 mV/°C. This sensitivity is somewhat dependent on 
the bias current. Semiconductor diodes have been used for a long time in ICs to regulate the temperature.
The thermal behavior of bipolar transistors and diodes is similar. Temperature sensing using bipolar 
transistors is based on the emitter current-to-voltage characteristic of the base-emitter junction. When 
base and collector terminals are short circuited, the transistor basically behaves as a diode. The use 
of several matched transistors in a circuit can give place to precise sensors such as the classical PTAT 
(proportional to absolute temperature).
13.2.4.4  Seebeck Effect
The thermoelectric Seebeck effect consists of the fact that a conductor subjected to a thermal gradient 
develops an electric voltage between its hot and cold sides. This voltage depends on the material and on 
the difference of temperatures of both sides. The voltage drop developed in a given material per unit of 
temperature is the Seebeck coefficient α(T) of that material. In semiconductors, Seebeck coefficients can 
be positive or negative depending on the dominant type of carriers (electrons or holes). Typical Seebeck 
coefficients are of several μV/°C.
A thermocouple is formed by two different conductors (metals or semiconductors) electrically con-
nected at the hot side at temperature T1, while the nonconnected ends of both conductors are at another 
temperature, T0. The thermal gradient in each conductor produces a different voltage variation between 
hot and cold points; therefore, a voltage can be measured between both conductors at the cold ends, and 
these are the two electrodes of the thermocouple.
	
V
T
T dT
T
T
=
−
∫(
( )
( ))
α
α
1
0
1
2
	
(13.8)
In the integration of thermocouples, special attention has to be paid to the thermal isolation between 
hot and cold pints. Thermocouples can be used as thermoelectric converters by connecting them to a load. 
To increase the output voltage, several thermocouples can be connected in a series to form thermopiles.
13.2.5  Optical Sensors
The optical properties of materials often involve measuring reflection, transmission, or optical absor-
bance in the films under characterization. Light detection can be done using different devices. The most 
common are photodiodes, phototransistors, and photoresistors [6].
Photodiodes consist of a semiconductor P–N junction. For their use, they are reversely biased; there-
fore, just a very small reverse saturation current flows. When light incides with adequate wavelength 
in the surface of the semiconductor, the transmitted part propagates in the semiconductor. Light in 
the semiconductor creates electron–hole pairs. Electrons in the conduction band start flowing to the 
positive biased terminal, while photogenerated holes flow to the negative biased terminal. This causes a 
noticeable increase of current of the diode proportional to the incident optical intensity.
Phototransistors are bipolar transistors. Commonly, bias is applied between collector and emitter, 
leaving the base terminal unconnected. In the absence of light, there is no base current. When light 
incides on the device, photogenerated carriers near the collector-base junction, one type of carriers is 
swept to the collector and the other to the base regions of the device, thus creating the base current. The 
base current causes injection from the emitter to the collector. Therefore, phototransistors provide a 
current gain and have a much higher sensitivity than photodiodes.
Photoresistors are semiconductor devices whose resistance changes when light incides onto the 
device. The dark resistance of the material is high because few free carriers are available for conduction. 
The absorption of light provokes the transition of electrons and holes to the bands, thus increasing the 
conductivity of the material.
© 2011 by Taylor and Francis Group, LLC

13-8 
Fundamentals of Industrial Electronics
13.2.6  Magnetic Sensors
13.2.6.1  Hall Effect
Hall effect is the consequence of the interaction of a moving charge carrier and a magnetic field. The 
force acting on a charge q traversing a position in which a magnetic field B⃗ exists is
	



F
q v
B
=
⋅
×
	
(13.9)
where
v⃗ being the speed of the charge
F⃗ is a lateral force deflecting the charge toward one side
For instance, in the case of a vertically placed metallic film, were charge carriers are electrons, 
if the magnetic field is perpendicular to the film directed to it, and the electron current flows in 
the downward direction, the magnetic force on the electrons pushes them to the right side. If con-
tacts are placed in the right and left sides of the strip, a difference of potential V can be measured 
between them:
	
V
KIB
=
sinα 	
(13.10)
where
I is the current flowing
α is the angle between the magnetic field vector and the plate
K is a coefficient sensitivity that depends on the material, geometry, and temperature
Typically, a Hall sensor has four terminals. A current flow is set between the two excitation terminals 
and a differential voltage proportional to the Hall effect is read between the two output ones.
A way to integrate a Hall sensor is by simply defining a square N-type doped region on a P substrate. 
Contacts are placed on the sides of this region. Two opposite contacts serve to establish the current flow; 
the other two are the output.
13.2.6.2  Magnetotransistors
These devices are bipolar transistors in which the collector current is modulated by an external mag-
netic field. Often, they consist of a bipolar transistor with a double collector. In the absence of magnetic 
field, the current of both collectors is the same. The magnetic field deflects carriers favoring their col-
lection in one of the two contacts unbalancing the collector currents. This difference in current provides 
a measure of the electric field.
13.2.6.3  Magnetoresistance
It is the property of a material carrying an electric current to change its electrical resistance in the pres-
ence of an external magnetic field. Ordinary magnetoresistance may produce resistance variations up 
to 5% of their original values due to the presence of the magnetic field. It is proportional to the square 
of the intensity of the magnetic field at low intensities. It is observed with H both parallel to and trans-
versal to the current flow. In semiconductors, magnetoresistance is large and is dependent on the rela-
tive angle between the field direction and the current flow. Stacks of alternating layers of magnetic and 
nonmagnetic metals may present very large, negative values of magnetoresistance. This is called giant 
magnetoresistance (GMR).
© 2011 by Taylor and Francis Group, LLC

MEMS Devices 
13-9
13.3  MEMS Actuation Principles
13.3.1  Introduction
It is recognized that main MEMS actuator devices are based on one of the following actuation principles: 
electrostatics, thermal, piezoelectric, and magnetic [8].
13.3.2  Electrostatic Actuation
Electrostatic actuation is based upon the application of an electric field between electrodes, one of 
which at least, can move in some direction, and normally working against a mechanical restoring 
force, Fm = −k(g0 − g) with a stiffness coefficient k. Figure 13.3 schematically shows a diagram of two 
electrodes of area A parallel plate geometry, with an initial gap g0 between them. A DC voltage V is 
applied between the plates and the resulting force, normal to the plates’ surface, makes the upper plate 
move, changing the gap to g. The electrostatic force is given by [7]
	
F
V C g
g
AV
g
e =
=
2
2
2
2
2
( )
ε
	
(13.11)
As can be seen, the force is always attractive, as it is independent of the sign of the applied voltage, 
and it increases nonlinearly as the gap narrows. Applying static and dynamic equilibrium conditions, 
it can be shown that there is a minimum gap that can be stably reached: gmin = (2/3)g0. An important 
parameter resulting from this analysis is the well known “pull-in voltage,” VPI, beyond which the mov-
able electrode is unstable and collapses toward the fixed electrode [9]. It is given by
	
V
kg
A
PI =
8
27
3
0
ε
	
(13.12)
where ε is the permittivity of the gas filling the gap. For practical designs, the values for VPI are gen-
erally larger than the standard supply voltage of ICs, hence requiring specific step-up converters. 
Pull-in maximum stable deflection limits the value of the ratio of ON/OFF capacitances in tunable 
analogue MEMS varactors [10].
The same geometry shown in Figure 13.3 can also be driven by directly injecting a charge to the 
MEMS capacitor and the movement becomes, ideally, stable beyond the pull-in instability [11]. A num-
ber of ways of achieving this operation mode have been reported and the effect of parasitics discussed 
[12]. It turns out that the transient dynamics developing after injecting a current pulse is equivalent to 
placing a capacitance in series with the MEMS switch [13].
Fixed plate
A
+
V
–
g
g0
Movable plate
FIGURE 13.3  Diagram of a two-electrode parallel plate geometry.
© 2011 by Taylor and Francis Group, LLC

13-10 
Fundamentals of Industrial Electronics
Lateral movement (Figure 13.4) can also be achieved electrostatically and, as the gap remains con-
stant, the pull-in instability is avoided. The electrostatic force is independent of the relative placement of 
the electrodes, the sign always tends to achieve maximum overlapping area and it is given by
	
F
WV
g
e = ε
2
0
2
	
(13.13)
This tangential force is usually much smaller than the normal force [14]. This operation mode is used 
to build lateral comb actuators and electrostatic motors. When the motor is a rotating motor, the torque 
is related to the angle by [15]
	
T
V dC
d
( )
( )
θ
θ
θ
=
2
2
	
(13.14)
13.3.3  Thermal Actuation
Heat can be used in different ways to provide thermally actuated MEMS devices, such as thermal 
expansion of beams or cantilevers, shape memory alloy (SMA), thermo neumatic expansion of a gas, 
or bimetal effect of two-layered materials of different thermal expansion coefficients. Among them, the 
simplest principle is the displacement that can be achieved from the thermal expansion of materials. 
Metals are the ones with larger expansion coefficient and hence capable to provide larger forces and 
larger displacements compared with silicon-based microdevices.
Using a simple one-dimensional model, the thermal expansion ΔL/L can be made proportional to 
the temperature increment ΔT. This strain relates to the thermal expansion stress through the Young 
modulus (E) of the material: σ = EΔL/L and, finally, the stress is converted in the force by multiplying 
by the cross section area: F = Aσ.
Being a thermal process, heating is usually very fast as the mass involved in microstructures is very 
small, but cooling depends basically on conduction to supports and ambient air and to a smaller extent 
on convection. Figure 13.5 shows a diagram of a typical thermal actuator structure, where a large 
Fixed plate
L
g0
W
Movable plate
FIGURE 13.4  Diagram of a two-electrode plate geometry with lateral displacement.
Hot arm
Cold arm
Flexure
FIGURE 13.5  Diagram of a typical thermal actuator structure.
© 2011 by Taylor and Francis Group, LLC

MEMS Devices 
13-11
difference can be seen in the transversal dimension of the hot and cold arms in order to get most of the 
Joule power dissipated in the hot arm. Despite these design precautions, in practice, a large part of the 
power is also dissipated in the combination of the flexure and cold arm, hence leading to typically low 
efficiency. The device shown in Figure 13.5 creates a nonlinear displacement of the tip that can be con-
verted to linear by changing the mechanical design of supporting legs, as, e.g., buckle-beam device [16].
The movement can be enhanced either by using layered structures of different thermal expansion 
coefficients (bimetal actuators) or by using SMA, which consists on NiTi wire, which undergoes a phase 
transition from martensitic to austenitic, entailing several percent of longitudinal change and produc-
ing forces in the newton range [17].
13.3.4  Piezoelectric Actuation
The piezoelectric effect is present in several natural materials such as quartz, but also in piezo ceramic 
materials with improved characteristics based on polyvinylidene fluoride (PVDF) and lead zirconate 
titanate (PZT). Zinc oxide has also been used to provide movement for AFM stages.
The displacement is a function of the applied electric field and the strain produced can be written as
	
∆L
L
d E
ij
=
	
(13.15)
where
dij is the piezoelectric strain coefficients
d33 stands for the strain parallel to the polarization plane
d31 for the orthogonal.
d33 is positive and d31 is negative, thereby indicating contraction. Strain values up to 0.2% are achiev-
able. To a first-order approximation, the actuator displacement is proportional to the stored charge and 
hence to the electrical capacitance, larger capacitances can be manufactured by stacking several layers 
of material connected in parallel. These actuators are capable of producing very large forces and small 
displacements. Typical applications are nanopositioning stages from some tens to some hundredths of 
micron travel range. They can also be used in tunneling and atomic force microscopes for nanometer-
range resolution.
13.3.5  Magnetic Actuation
Magnetic actuation in the microworld faces challenging issues because of the scaling rules for the 
Lorentz force, the difficulties of providing coils using mainstream micromachining techniques and the 
material compatibility. The two main families of magnetic actuators are based on the electromagnetic 
force and on magnetostrictive films.
The actuators having a movable cantilever or beam being attracted by a magnetic field created by an 
electrical current in a coil exert a force on it given by [18]
	
F
NI
d
dl
=
ℜ




ℜ
1
2
2
	
(13.16)
where
ℜ is the reluctance of the gap and core
N is the number of spires of the coil
I is the electrical current
© 2011 by Taylor and Francis Group, LLC

13-12 
Fundamentals of Industrial Electronics
The consequences of Equation 13.16 are that large values of the product Amp-turns and low reluctances 
are required to provide significant force. These requirements have to be faced with careful consider-
ations of the device dimensions, material permeability values to reach forces in the range of several 
hundred μN, and also the application of specific fabrication techniques for 2D or multilayer coils using 
micromachining or LIGA processes.
Magnetostriction stands for the deformation of an object when subject to an external magnetic field. 
This can be used to build remote actuators by depositing magnetostrictive material on top of cantilever 
or membrane structures. The action of the magnetic field makes the cantilever bend due to the existing 
mismatch between the two materials [19].
13.4  MEMS Devices
13.4.1  Inertial Sensors
Inertial sensors measure the state of movement of an object. Accelerometers measure linear acceleration, 
while gyroscopes measure angular rate movement. Historically, accelerometers were among the first 
MEMS devices to be successfully commercialized, mainly in the automotive industry. Nowadays, accel-
erometers and gyroscopes are being used in positioning and guidance systems in a variety of sectors.
13.4.1.1  Accelerometers
Accelerometers have a mass proof, which moves relatively to a fixed frame due to the acceleration of 
this frame, which is rigidly linked to the object whose acceleration is to be measured. By sensing the 
displacement between the mass proof and the fixed frame, the desired acceleration measurement can 
be obtained. Depending on the method used to sense the displacement, accelerometers are classified 
into capacitive, piezoresistive, thermal, or resonating. There exist accelerometers able to measure three-
dimensional movements, but most are limited to one or two axis. The most important accelerometer 
characteristics are sensitivity, bandwidth, operation range, resolution, and linearity.
Capacitive accelerometers, like the one depicted in Figure 13.6, have very good sensitivity: low-drift, 
low-noise, and low-temperature sensitivity. They are also inexpensive to fabricate. They can, however, be 
sensitive to EMI if properly shielded or not. A typical capacitive accelerometer can have a range of 50 g, 
10 bits of resolution, 10 kHz of bandwidth and 0.2% of nonlinearity.
Piezoresistive accelerometers sense the displacement of the proof mass by measuring the change in 
electrical resistance in the cantilevers that support it. They are simple to fabricate and have a low cost, 
but their sensitivity is not as good as that of capacitive devices. Range of 5 g, sensitivity of 5 mV/g and 5 kHz 
of resonant frequency are typical values for a piezoresistive accelerometer.
Different types of thermal accelerometers have been developed. One of the most widely used is the 
based on a bubble movement. The position of the bubble is sensed by measuring the amount of heat 
transferred from a heater to the liquid where the bubble is located.
Suspensions
Sense
electrodes
Acceleration
Mass
Anchors
FIGURE 13.6  Structure of a horizontal capacitive accelerometer.
© 2011 by Taylor and Francis Group, LLC

MEMS Devices 
13-13
Resonating accelerometers transfer the mass-proof movement to a series of beams, changing their 
oscillating frequency. They are most expensive than other types, but feature high resolution and 
sensitivity.
13.4.1.2  Gyroscopes
The principle of measuring angular rate variation in a gyroscope is to have a rotating or vibrating piece, 
which is affected by Coriolis pseudo-forces and thus has a relative movement with respect to the fixed 
frame. Like accelerometers, gyroscopes are classified according to the physical effect used to measure 
this displacement (piezoresistive, capacitive, etc.). In addition, the effect used to generate the movement 
of the proof mass can also differentiate gyroscopes, and it can be piezoelectricity, electromagnetism, 
electrostatics, etc.
Defining performance characteristics for gyroscopes are angle random walk, full scale range, band-
width, zero rate output, temperature sensitivity, and parasitic effects.
Vibrating (Figure 13.7), rotating, and levitating gyroscopes have been constructed using bulk- and 
surface-micromachining processes. Quartz and silicon are the most commonly used materials.
A typical rate-grade gyroscope could have an angle random walk of 0.6°/ h, a range of 500°/s, 
and a bandwidth of about 100 Hz.
13.4.2  Pressure Sensors
Nowadays, pressure sensors are MEMS devices with the greatest commercial success. Their application 
fields include automobile, medicine, and industry. We can find pressure sensors everywhere in the car: 
for fuel distribution, exhaust gases, tires, seats, etc. Very compact sensors are applied to patients to mea-
sure internal ocular or cranial pressure.
MEMS pressure sensors have been intensively studied because the manufacturing of membranes 
with an accurate thickness was developed in the beginning of these technologies. Bulk micromachin-
ing, as it has been presented in the previous chapter, is a process that produces membranes with differ-
ent shapes and widths very precisely. Additionally, there is a wafer that is bonded to the previous one to 
form a cavity (see Figure 13.8a). The deflection of a membrane due to the difference of pressures applied 
in their sides is the working principle that most pressure sensors use. This kind of device is called dif-
ferential or relative pressure sensor.
When one of the pressures is fixed in a closed cavity as a reference, we have an absolute pressure sen-
sor. Normally, this reference pressure is vacuum but if the reference pressure is the atmospheric one, 
this sensor is called a gauge. Maintaining this reference pressure inside this cavity is difficult due to the 
permeability of the materials and bonding methods that are employed in its fabrication.
Rotation
axis
Driving
electrodes
Measurement
axis
Sensing
electrodes
FIGURE 13.7  Structure of a vibrating electrostatic gyroscope.
© 2011 by Taylor and Francis Group, LLC

13-14 
Fundamentals of Industrial Electronics
Diaphragm sensors may work in two modes [20]: a normal mode when the membrane freely deflects 
depending on the difference of pressures, and touch mode that happens when the diaphragm stays in 
contact with the substrate, as depicted in Figure 13.8b. In the first mode, the device is more sensitive, but 
it presents higher linearity in the second mode.
But the detection of the deformation of a membrane is not straightforward, and an indirect phenom-
enon is used [21]. In the next paragraphs, the most relevant MEMS structures will briefly be described.
The main parameters to evaluate the performance of pressure sensors are sensitivity, linearity, 
dynamic range, and reliability. The sensitivity is the most relevant feature and it is defined as the change 
of the output signal (v) with respect to a pressure change, depending on the signal value itself:
	
s
v
v
P
=
∂
∂
1
	
(13.17)
The dynamic range in these devices depends on the weight of the membrane and the gap. Due to the 
fabrication of very small gaps, these sensors are designed for a narrow pressure band.
One of the most important drawbacks related with the MEMS processes that affect the performance 
of these devices is the residual stress that may appear when a membrane is released, because this perma-
nent stress would initially deflect it. This effect is even worse in multilayer membranes.
13.4.2.1  Capacitive Pressure Sensors
A capacitive pressure sensor uses the membrane as one plate of a capacitor, while the substrate is the 
other plate, as shown in Figure 13.9.
Obviously, a dielectric layer should be between the membrane and the substrate. This layer can be 
deposited or generated before the membrane layer, and it can be also used as a stopping layer for the 
bulk micromachining process. For instance, we can create an insulator layer of SiO2 on top of a silicon 
(b)
Pint
Pext
Membrane
Pext
Pint
(a)
Input port
FIGURE 13.8  (a) Pressure sensor based on the deflection of a membrane manufactured with MEMS technology. 
(b) Pressure sensor working in touch mode.
P
C
pref
FIGURE 13.9  Working principle of a capacitive pressure sensor.
© 2011 by Taylor and Francis Group, LLC

MEMS Devices 
13-15
wafer and then deposit polysilicon as a conductive layer. Many alternative fabrication processes have 
been proposed since the 1970s when they were first developed, but all of them make use of this basic 
scheme, which is very simple and can be easily implemented and scaled and also it has no DC power 
consumption. However, it suffers from several limitations: it has a nonlinear response because of the 1/g 
dependence of the capacitance value respect to the gap g; the existence of parasitic capacitance parallel 
to the sensing capacitance makes the relative changes of the total capacitance difficult to be measured. 
The auxiliary electronics that is employed for the capacitance-to-voltage conversion consist of a conven-
tional integrator or a switched capacitor charge integrator.
13.4.2.2  Piezoresistive Pressure Sensors
Nowadays, most of the commercially available pressure MEMS sensors are based on this transducing 
method. It basically consists of the fabrication of piezoresistors on the membrane by selectively doping 
special areas, as presented in Figure 13.10. These piezoresistors are placed in a symmetrical disposition 
with respect to the edges of the membrane.
These piezoresistors can be configured in a Wheatstone bridge. The piezoresistors’ resistance has a 
low value, thus permitting long connections to the readout circuit with minimum perturbation due 
to the impedance of the wires. But on the other hand, it also represents rather high continuous power 
consumption.
13.4.2.3  Compensated Pressure Sensors
As it has already been mentioned, the main drawback of pressure sensors based on membrane deflec-
tion is that they are nonlinear transducers with a rather low dynamic range. One way to circumvent 
this problem is the use of a variable reference pressure that balances the pressure on the other side of 
the membrane. An electronic servo-controller could feedback the signal loop to achieve this objective. 
However, this compensation scheme requires the application of an external force onto the membrane 
to be defected in the opposite way than the external pressure to be measured. Normally, an electrostatic 
actuator is used for this compensation because it generates attractive forces between the membrane and 
the substrate. This approach complicates the MEMS structure and adds external auxiliary electronics. 
Besides, the maximum applied voltage should be inferior to the pull-in voltage to prevent the membrane 
from collapsing.
13.4.2.4  Resonant Pressure Sensors
As it has been explained in the previous chapter, frequency measurements of a resonant structure are 
quite simple and accurate. For this reason, accurate pressure sensors based on this principle have a beam 
whose supports are on the membrane vibrating in resonant mode. When the pressure is applied, the 
membrane deflects creating a change in the resonant frequency due to the stress induced in the beam, 
Membrane
Piezoresistors
FIGURE 13.10  Piezoresistive pressure sensor layout.
© 2011 by Taylor and Francis Group, LLC

13-16 
Fundamentals of Industrial Electronics
thus providing an indirect measurement of the applied differential pressure. The main problem with 
this approach is that the manufacturing process is much more complicated than in previous sensors.
13.4.2.5  Other Pressure Sensors
There are other alternatives to pressure sensor transducing that should be mentioned. For instance, optical 
pressure sensors detect the deflection of the membrane by measuring the reflection angle of a laser beam. 
Other optical schemes include a membrane in the end of an optic fiber, acting the device as a Fabry–Perot 
interferometer. PCB-MEMS techniques also provide methods for the manufacturing of pressure sensors [22].
13.4.2.6  Microphones
A special case of pressure sensor is a microphone like the one depicted in Figure 13.11. The membrane 
is released via anisotropic etch of the substrate, while a backplate is formed by surface micromachining. 
The suspended backplate has holes to facilitate the vibration of the membrane. The capacitive transducer 
is formed by the membrane and the electrode backplate. This structure allows for the realization of com-
mercial low-cost miniature microphones.
13.4.3  Radio Frequency MEMS: Capacitive Switches and Phase Shifters
13.4.3.1  Introduction
MEMS are very attractive for wireless applications due to their excellent radiofrequency (RF) proper-
ties, high linearity, low power consumption, and low cost. A large variety of devices exist under the 
umbrella of RF MEMS, being categorized according to their main functionality: (1) capacitive and con-
tact switches, (2) tunable or programmable passives (capacitors and inductors), (3) resonators (mimick-
ing full circuit functions) for oscillator and mixer applications, and (4) micromachined transmission 
lines and antennas. In principle, any true RF MEMS device has a mechanically movable part using one 
of the four fundamental actuation principles: (1) electrostatic, (2) thermal, (3) magnetic, and (4) piezo-
electric. The most used actuation principles, essentially because of their reduced power consumption, 
are the electrostatic and piezoelectric ones. In this section, we present the state-of-the-art in electrostati-
cally actuated RF MEMS capacitive switches and their use in phase shifters for applications beyond 
10 GHz; we illustrate the chapter with some recent fabrication results and measured performances.
13.4.3.2  RF MEMS Capacitive Switches
The RF MEMS capacitive switch is made based on a movable conductive membrane suspended over 
an air-gap and another conductive electrode covered by a thin insulator. The movable membrane can 
be actuated electrostatically by applying a voltage between the two conductive electrodes. Figure 13.12 
describes the principle of such a capacitive switch: in the up-state (non-actuated switch) the capacitance 
between the two electrodes is very small (Coff, typically in the order of few fFs) and there is a good sig-
nal isolation, in the down-state (actuate switch) the value of the capacitance is substantially increased 
(Con, typically at least one order of magnitude higher than Coff, values of interest being in the order of 
hundreds of fFs to pFs) and a high-frequency signal can be coupled between the two electrodes.
Backplate
Membrane
Backplate
electrode
Air gap
Substrate
FIGURE 13.11  Structure of a condenser microphone.
© 2011 by Taylor and Francis Group, LLC

MEMS Devices 
13-17
The capacitance characteristic of an RF MEMS capacitive is qualitatively represented in Figure 13.13. 
One can distinguish as key parameters the actuation voltages, called pull-in (VPI) and pull-out (VPO) 
voltages. Their expressions can be analytically calculated as a function of the switch geometrical design 
parameter
	
V
kg
A
V
kg g
A
PI
eff
r
=
=
8
27
2
3
0
0
2
2
0
ε
ε ε
ε
,
PO
	
(13.18)
where
k is the spring elastic constant
g0 is the zero-voltage gap spacing
gε is the dielectric thickness
geff is the effective insulator thickness (=g0 + gε)
A is the membrane area
RF MEMS switches are used in wireless communication systems with two different device function-
alities that determine two different capacitive MEMS approaches that are described as it follows.
Electrostatic
Elastic
Thin
dielectric
g0
OFF
ON
Low loss
substrate
(a)
Lower electrode:
Signal (CPW)
(b)
C (pF)
Cdown
V=0 V
VPO
Hysteresis
VPI
V (V)
1.5Cup
Cup
FIGURE 13.12  (a) Capacitive RF MEMS switch with electrostatic actuation and the OFF and ON stable states. 
(b) Capacitance characteristics of electrostatically actuated RF MEMS capacitive switch showing ON state (Cdown) 
and OFF state (Cup) capacitances as well as VPI and VPO.
© 2011 by Taylor and Francis Group, LLC

13-18 
Fundamentals of Industrial Electronics
CMEM
MIM
High resistivity silicon>3 kΩ/cm
(a)
(b)
900 nm Au/Ni/Au
400 nm Ti/Pt/Au/Pt
300 nm AlN
2    m Au
2    m SiO2
mag
5 000×
9/15/2008
4:30:29 PM
(c)
(d)
tilt
52°
HV
5.00 kV
curr
1.6 nA
WD
5.0 mm
5 μm
mag
50 000×
9/15/2008
3:45:10 PM
tilt
60°
HV
5.00 kV
curr
1.6 nA
1.94 μm(s)
WD
5.0 mm
1 μm
FIGURE 13.13  Fabricated RF MEMS capacitive switch: (a) Cross section schematic view illustrating the different 
materials and thicknesses. CMEM and CMIM denoted the MEMS and the metal–insulator–metal capacitors. 
(b) Focused Ion Beam (FIB) cross section of the fabricated device. (c) A view of the Au/Ni/Au membrane showing 
the releasing holes. (d) A detail of the membrane showing the 2 μm air gap.
© 2011 by Taylor and Francis Group, LLC

MEMS Devices 
13-19
The first approach is the RF MEMS capacitive switch or analog MEMS capacitor with a high capaci-
tance ratio (Con/Coff > 50) is used as a high isolation switch for signal routing purpose in reconfigurable 
front-end or for antenna orientation. To achieve a high isolation, some successful capacitive switches 
based on shunt and series switches have been reported by Goldsmith et al. [23] and Muldavin and Rebeiz 
[24]. Other works concern switches with low spring constant meander anchoring [25,26] for low-voltage 
operation, inductively tuned switches [27], and single or cascaded multiple devices.
The second approach is the MEMS switch capacitor or digital MEMS capacitor that can have a low-
to-moderate capacitance ratio (<10) and it is generally used as a part of a tunable system as filters, phase 
shifters or reconfigurable networks with two well-defined capacitive states. This type of MEMS switch 
capacitor has been introduced by Hayden and Rebeiz [28] being based on a MEMS capacitive switch 
in series with a fix small capacitance; the implementations of this type of switch have been reported in 
metal–insulator–metal (MIM) capacitor, metal–air–metal (MAM) capacitor or interdigitated capacitor.
Today, reliability is still one of the main problems of RF MEMS switches, conditioning their final suc-
cess for commercialization. Reliability is directly related with the dielectric charging of silicon-dioxide 
and silicon-nitride layers, and it is the main responsible mechanism for failures in capacitive switches. 
Degradation mechanisms have been studied by Herfst et al. [29] and different solutions have been pro-
posed to reduce or avoid the charging effect: the dielectric-free capacitive switch architectures [30], the 
use of leaky dielectric as PZT or AlN [31] or switch miniaturizing to mitigate the effect of the dielectric, 
as well as decreasing the switching time [32].
In Figure 13.13, we show a recent RF MEMS capacitive switch fabricated in a seven-mask process on 
high resistivity silicon substrates (>3 kΩ/cm). The silicon substrate is isolated with a thick 2 μm ther-
mal oxide insulator to avoid the effect of free charge carriers in the substrate interface. The RF MEMS 
switches are loaded on a 78 Ω-high impedance coplanar waveguide (CPW) line consisting of 2.5 μm 
electroplated gold conductor, except under the MEMS bridge where a thin under-path layer of a sand-
wich of metals (Ti/Pt/Au/Pt) is employed instead. The thin metal signal line is covered in the actuation 
region by 300 nm of non-piezoelectric aluminum nitride (AlN), whose dielectric constant is 9.8. The 
total CPW width is 300 μm with G/W/G of 125/50/125 μm.
The suspended membrane is 900 nm thick consisting of AuNiAu (200/500/200 nm) multilayer and 
15 μm thick Ni for the MEMS meander or spring-type anchoring, supports, and stiff bars for avoiding 
membrane deformation due to multi-metal membrane fabrication–induced stress. The final air gap is 
around 2 μm.
Figure 13.13 depicts SEM images of three designed and fabricated capacitive shunt switches with the 
process previously described.
As a typical example, Table 13.1 reports the measured electrostatic and RF performances for the three 
devices fabricated and depicted in Figure 13.14; their performances are similar. However, the actuation 
voltage of the external bias switch (Figure 13.14c) is much higher (2.5 times higher) than the other two 
TABLE 13.1  Mechanical and RF Performances for Capacitive Switch 
Devices Shown in Figure 13.14
Analogue Capacitive Shunt RF MEMS Switch
String 
Type
Meander Type
External 
Actuation 
Spring Type
Actuation voltage, VPI (V)
15
13
20
40
33
Spring constant, k (N/m)
13
9
63
Insertion loss @ 40 GHz (dB)
−1.5
−1.1
−0.65
Return loss @ 40 GHz (dB)
−10
−12.5
−11.5
−10
−13
Isolation @ 40 GHz (dB)
−35
−30
−37.5
−35
−30
	
@ 20 GHz (dB)
−13.5
−12.5
−15
−17
−12
© 2011 by Taylor and Francis Group, LLC

13-20 
Fundamentals of Industrial Electronics
353 X
100 μm
EHT=3.00 kV
Signal A = SE2
Stage at T= 0.0°C
Date: 15 Nov 2007
EPFL-CMI
File name = April_22.1
WD=7 mm
(a)
(b)
=
20 μm
EHT=3.00 kV
Signal A= SE2
Date: 15 Nov 2007
EPFL-CMI
File name=Ami_38.tif
Stage at T= 50.9°C
WD=10 mm
Mag=682 X
Mag=259 X
(c)
100 μm
EHT=3.00 kV
Signal A= SE2
Date :15 Nov 2007
EPFL-CMI
File name = Ami_8.tif
Stage at T= 0.0°C
WD=7 mm
FIGURE 13.14  SEM images of three fabricated capacitive RF MEMS switches: (a) string-type, (b) meander-type 
anchoring with a DC voltage in line with the RF signal, and (c) stiffer spring-type anchoring with external DC volt-
age actuation.
© 2011 by Taylor and Francis Group, LLC

MEMS Devices 
13-21
(Figure 13.14a and b) due to a higher stiffness of the membrane. The achieved insertion loss of the exter-
nal DC bias string-type switch is relatively lower. Device characterization from 6 to 40 GHz is usually 
carried out on using Vector Analyzer and a calibration is performed using an external SOLT commer-
cial calibration kit.
13.4.3.3  Distributed MEMS Phase Shifters
RF MEMS capacitors have been investigated for application in distributed MEMS transmission lines 
(DMTLs) phase shifters, both analog [33] and digital approaches [34]. The idea is to periodically load 
a CPW with voltage-controlled varactors (two-state switch capacitors for digital DMTLs [35], in order 
to tune the distributed capacitance, the phase velocity and the propagation delay in the line. The main 
advantage of this kind of phase shifter is its constant time delay behavior over a wide band of frequencies.
The first optimized loaded-line phase shifter was implemented using diodes [36]. However, diodes 
present degraded performances at high frequencies (RF), especially in terms of losses, tuning linearity 
and intermodulation distortion. RF MEMS capacitors overcome these problems, although, they might 
have limited tuning range and slower switching; however, these are not limiting factors for most phase- 
shifter applications. Analog MEMS DMTL phase shifter are commonly limited by its low capacitance 
ratio (<1.5). Digital solutions based on MEMS switch capacitors achieved higher capacitance ratio (∼3) 
with the advantages of size reduction, lower insertion loss, less dependence on the fabrication technol-
ogy, but with a higher actuation voltage. For multistate phase shifter, the standard solution is to add bits 
to individually actuate groups of switch capacitor, which implies different actuation control commands 
as well as increasing substantially the complexity and usually the size of the device [37,38].
Reliability and temperature sensitivity in phase shifter have rarely been studied [39] as impor-
tant issues for airborne and space applications, which require operation within a large range of 
temperature.
RF-distributed MEMS phase shifter concept, DMTL [40] for beam-steering has the main advantage 
of achieving a true-time delay (TTD) over a wide band. DMTL phase shifters will play important roles 
in future airborne applications, adding many advantages over traditional mechanical steering phase 
shifters. These include decreased size, cost, and weight; increased flexibility; lower insertion loss and 
dispersion; and a good matching over a large bandwidth. Electronically, beam-steering the antenna 
involves dynamically switching the beam configurations of an antenna array by controlling the relative 
phases at the input of each element in order to change the orientation of the whole antenna beam [41].
Figure 13.15 illustrates a fabricate DMTL phase shifter [42] by the authors of this chapter; the perfor-
mances of the measured 5 mm digital DMTL phase shifter are very good in terms of repeatability, fab-
rication uniformity, reliability, and robustness after different tests in vacuum and in air and at various 
temperatures (from −130°C to 50°C). The pull-in of all the switches is around 24 V (slightly higher than 
a single digital capacitor to ensure the actuation of all 13 MEMS capacitors). Figure 13.16 depicts the 
typical C–V curve of a single digital capacitor and a full array of capacitors loaded on a CPW, namely, 
the DMTL phase shifter. One can observe a quasi-identical VPI for all the switches (∼22V) and a sym-
metrical curve around V = 0, which indicates that either no mobile residual charges exits on the dielec-
tric or that they are compensated. The pull-out is slightly higher than 10 V. The C–V curve appears to 
be symmetrical because the polarity of the applied voltage has no influence on the actuation since the 
electrostatic force is proportional to the voltage squared.
Figure 13.16a shows the measured S-parameter data for the phase shifter and Figure 13.16b illustrates 
the full characterization analysis of the reported DMTL. First, a constant TTD of 25 ps is achieved for 
a wide frequency band, this time delay corresponding to a phase delay of 125° at 14 GHz. Second, the 
characteristic impedance of the loaded line in the Up and Down states results in a quasi-adapted match-
ing line of 55 and 45 Ω, respectively. Both values are very close to the desired impedance reference of 
50 Ω resulting in a return loss (matching) better than −10 dB for all the states.
The reported results confirm the maturity of RF MEMS technology for phase-shifter applications and 
its promise for high-frequency applications.
© 2011 by Taylor and Francis Group, LLC

13-22 
Fundamentals of Industrial Electronics
13.4.4  Microfluidic Components
Microfluidic components are used in chemical, biomedical, and energy applications. A microfluidic 
system is composed of several components that extract, transport, pump, or process fluids at small 
scales [43,44].
13.4.4.1  Valves
Passive valves (also known as check-valves or one-way valves) are usually built by placing a membrane 
that can deflect in the direction of flow, but not in the opposite one. When the flow is perpendicular to 
wafer surface, they are usually fabricated using a combination of bulk micromachining and wafer bond-
ing, like in Figure 13.17. If the channel for fluid is coplanar with the wafer or chip, fabrication is more 
difficult and can involve several layers of structural photoresist, such as SU-8.
Mag=294 X
100 μm
(a)
EHT=3.00 kV
WD=14 mm
Signal A=SE2
Stage at T=50.9°C
Date: 15 Nov 2007
EPFL-CMI
File name=Ami_43.tif
8.0E−13
7.0E−13
Array of 13 MEMS switches
6.0E−13
5.0E−13
4.0E−13
3.0E−13
2.E−12
2.E−12
VPI
VPI
VPO
VPO
–
3.E−12
3.E−12
4.E−12
4.E−12
Voltage (V)
(b)
Single capacitance (F)
Array of capacitances (F)
FIGURE 13.15  (a) SEM image of the fabricated distributed MEMS digital phase shifter using 13-loaded RF 
MEMS digital capacitive switches (only four switches are shown in this figure). (b) Measured C–V curves of a single 
digital capacitor and the array of parallel loaded 13 MEMS capacitors forming the phase shifter.
© 2011 by Taylor and Francis Group, LLC

MEMS Devices 
13-23
Active microvalves include an external actuation to open or close them. The physical effect used for 
actuation can be any one of those described in Section 13.2.3. In particular, electrostatic or piezoelec-
tricity actuations are commonly used for microfluidic valves [45].
13.4.4.2  Nozzles and Diffusers
Nozzles and diffusers are easily built using surface micromachining or micromolding, and are used to 
speed up or slow down the flow at a particular point. Nozzles, e.g., can be used to accelerate a stream 
until it breaks down into droplets. This technique is used in many inkjet printer cartridges. A combina-
tion of a nozzle and a diffuser is used in Venturi devices, which are used in microfluidics to generate a 
low pressure from a higher one, and employ it to extract or pump a fluid.
13.4.4.3  Pumps
Displacement micropumps work by having a movable component that displaces the fluid. The type of 
actuation used to move the component can again be any one of the methods presented in Section 13.2.3. 
The most commonly employed ones are electrostatic (see Figure 13.18), piezoelectric, pneumatic, or 
thermopneumatic.
Other methods of providing impulsion to fluids have been tried. These include electroosmosis, elec-
trowetting, magnetohydrodynamics, and acoustic streaming [47].
0
–10
–20
–30
11
S22
Measured S-parameters
Down (24–40 V)
–40
2
Return loss (dB)
4
6
8
10
Up (0–21 V)
12
14
S12
S21
Insertion loss (dB)
Down
(a)
(b)
(c)
(24–40 V)
Frequency (GHz)
Loaded characteristic impendance
22 V
(0–21 V)
23 V
2
Zo up=55
22 V, 23 V
(24–40 V)
Up (0–21 V)
40
30
20
10
0
4
6
8
10
12
14
30
20
10
0
4
6
8
Down (24–40 V)
Time delay (ps)
10
12
FIGURE 13.16  (a) Measured S-parameters of the digital DMTLs of 13 nickel bridges spaced at 294 μm (total 
length 5 mm) with an actuation voltage of 24 V. (b) Illustration of the real impedance of the loaded digital phase 
shifter in all the states. (c) The time delay extracted from measurements at different actuation states.
FIGURE 13.17  Passive microvalve by bulk micromachining.
© 2011 by Taylor and Francis Group, LLC

13-24 
Fundamentals of Industrial Electronics
13.4.4.4  Flow Sensors
Sensors that measure flow rate can rely on different effects. Force flow sensors measure the force exerted 
by the fluid over a bendable cantilever; this force is measured using the change in electrical resistance 
suffered by a piezoresistive element included in the cantilever. Pressure flow sensors use the change in 
fluid pressure between two points in the flow path; again, pressure is measured using a piezoresistor. 
Thermal flow sensors provide a known amount of heat to the fluid using a resistor and measure the 
change in temperature at a second point downstream; measurement of temperature change is usually 
done with temperature-dependent resistors, or with thermistors.
All these types of flow sensors have been successfully micromachined, usually in silicon, and are 
commercially sold (see e.g., [48]).
13.4.4.5  Mixers
The difficulty of mixing at the microscale resides in the low Reynolds numbers that are usually present 
in the flow, due to the small length and size. The transition from laminar to turbulent regime (where 
mixing occurs most efficiently) is not easily accomplished. Complex geometries have to be employed in 
order to generate the turbulence. Examples can be found in [49] and [50].
13.4.5  Optical Devices
The development of microscale, reconfigurable MEMS optical components have opened a wide range of 
applications. The list of optical devices that have been realized is vast, and it is not possible to cover all of the 
structures that have been fabricated. Rather, this section will examine the core components of any MEMS-
based optical system. These are mirrors, lenses, optical gratings, and optical filters. Other components such 
as variable optical attenuators, optical switches and many optical sensors are variants of these structures. 
Important devices that are not covered are micro-optic components such as waveguides, resonators, cou-
plers, and micro-optical benches. In the following, the references given are examples rather than exhaustive.
13.4.5.1  Mirrors
Two major types of mirrors have been realized in MEMS structures; planar mirrors that allow tip, tilt, 
or piston motion (or a combination of all three); and deformable mirrors, primarily for aberration cor-
rection. Mirror dimensions that have been realized extend from a few tens of microns to millimeters. 
The most complex MEMS devices to date are based on large arrays of micromirrors used for digital 
projection [51]. Actuation of planar mirror structures is most commonly electrostatic [51], piezoelectric 
[52], or electromagnetic [53] (current through a coil in a permanent magnetic field) because of the high 
Actuation chamber
Pump diaphragm
Counterelectrode
Pump chamber
Isolation
layer
Actuation
unit
Valve unit
Outlet
Inlet
FIGURE 13.18  Bidirectional silicon micropump. (Modified from Zengerle, R. et al., A bidirectional silicon 
micropump, in Proceedings of the Microelectromechanical Systems (MEMS’95), Amsterdam, the Netherlands, 
January 29–February 2, 1995.)
© 2011 by Taylor and Francis Group, LLC

MEMS Devices 
13-25
speeds needed for most applications of these devices. Deformable mirrors are usually formed using flex-
ible membranes, which are either actuated at a discrete number of locations across the mirror [54] or in 
a spatially continuous manner (either around the edge or over the entire surface). Local displacement at 
an array of points can be used to form very complicated shapes for wavefront correction, but requires 
closely spaced actuators to give surfaces that are smooth on a scale comparable to the wavelength of 
light. Continuous actuation allows smooth mirror shapes such as variable focal length parabolic mir-
rors [55], but cannot form mirrors with complicated shapes. A wide range of actuation techniques have 
been used for deformable mirrors including electrostatic, piezoelectric, pneumatic, electromagnetic, 
and thermal. Figure 13.19 shows an example of a planar mirror structure that has both tip and tilt, for a 
miniature projector suitable for consumer electronics applications [53].
Figure 13.20 shows an example of a deformable mirror structure [56]. It consists of a continuous 
membrane mirror attached to an array of electrostatic actuators allowing the device to correct wavefront 
errors, improving focusing, and overcoming aberrations in optical systems. Such devices are used in 
biomedical, astronomical, and scientific instrumentation to improve resolution and decrease dispersion.
13.4.5.2  Lenses
MEMS lenses can be classified as being fixed focus, movable with fixed focus, variable focus, and movable 
with variable focus. Fixed focus microlenses [57] have been commercially available for many years and 
will not be discussed here. Virtually all variable focus and movable with variable focus microlenses rely on 
liquids, using either thermo/pneumatic actuation of microfluidic devices incorporating membranes [58], 
liquid droplets actuated using electrowetting [59], or a droplet of liquid crystal [60]. All of these technolo-
gies are being commercialized, with a major driver being the multilayer, high-density optical data storage 
applications. The principle of microfluidic lenses [58] is shown in Figure 13.21. Liquid is introduced into 
a micro-chamber covered by a thin, deformable membrane. By controlling the pressure in the chamber, 
the extent of deformation of the membrane, and hence the focal length of the lens formed is controlled. By 
combining several membranes with different liquids, excellent aberration control can be achieved.
Figure 13.22 shows the principle of electrowetting and an example of an electrowetting-based microlens 
[60]. When a drop of liquid is placed on a solid, the shape of the droplet is generally spherical. The spherical 
shape of the liquid can then be used to form a lens, and since the surface of the lens is flexible, there exist 
the possibility of changing the focal length of the lens, by changing the contact angle between the solid 
(a)
G3F_87×80×515_50×33×1000_au
MX
1
(b)
FIGURE 13.19  MEMS two-axis tilt mirror designed for use in a portable projector system. This system uses electromag-
netic actuation with the structure placed in a magnetic field and current passed through the coil. The actuation of both axes 
is achieved by driving currents through the coils at frequencies corresponding to the resonant frequency of central mirror 
and the outside gimbal: (a) An optical micrograph of the device. (b) Modeling when the device is driven at the resonant 
frequency of the centre mirror. (Modified from Davis, W.O. et al., MEMS-based pico projector display, in 2008 IEEE/LEOS 
International Conference on Optical MEMs and Nanophotonics, Freiburg, Germany, pp. 31–32, August, 11–14, 2008.)
© 2011 by Taylor and Francis Group, LLC

13-26 
Fundamentals of Industrial Electronics
Attachment
post
Mirror
Elecrostatic
actuator membrane
Electrostatic
actuator electrodes
Substrate
(a)
(b)
487
CM
200
–200
–400
–600
–800
–1000
–1250
0
FIGURE 13.20  (a) A cross section of a deformable mirror structure showing the elements of a 1 × 3 actuator array 
within an electrostatically actuated MEMS deformable mirror (DM). (b) In this image of an optical surface mea-
surement of a 144-element DM, a single pixel is actuated (left). The influence of the single element deflection extends 
only to its immediate neighbors, leaving the rest of the mirror surface unchanged. This local influence characteristic 
of the DM allows for high-order and otherwise arbitrary shapes on the DM (right). (Modified from Bierden, P. et al., 
MEMS deformable mirrors for high-performance AO applications, in Adaptive Optics for Industry and Medicine: 
Proceedings of the Sixth International Workshop, Dainty, C. (ed), Imperial College Press, London, U.K., 2008.)
Silicon
PDMS membrane
Liquid
Pyrex
Chromium aperture
Convex lens
Concave lens
f
f
FIGURE 13.21  Operation of a microfluidic lens, which consists of a chamber covered with a flexible membrane 
into which liquid is introduced. If the pressure is increased above ambient, a convex lens results, as shown on the 
left. In contrast, if the pressure in the chamber is less than ambient, the membrane is deformed so as to form a con-
cave lens. (Courtesy of Prof. Hans Zappe, IMTEK, University of Freiburg, Freiburg, Germany.)
© 2011 by Taylor and Francis Group, LLC

MEMS Devices 
13-27
and liquid. The contact angle between the solid and liquid is determined by the values of surface tension 
at the liquid–solid, liquid–vapor, and solid–vapor interfaces. Electrowetting is a physical effect in which 
the surface tension between a liquid and a solid can be controlled by a voltage applied across the interface.
Practical devices use a thin insulating layer between the electrode and the liquid, and often use two 
immiscible liquids, as shown in Figure 13.22. The use of two fluids allows one fluid to be used as the lens, 
while the other is used to control the surface tension around the lens, obviating the need for a contact 
to the lens liquid. If the region below the insulator is patterned with an array of electrodes, it also pos-
sible to move the lens across the surface by applying potentials at the edge of the lens liquid, making it 
energetically favorable for the lens droplet to move over the active electrode.
13.4.5.3  Gratings
Micro-optical gratings used to diffract or steer optical signals have been commercially available for some 
time, and are key components of many systems, most notably optical data storage. When combined with 
MEMS actuation, normally fixed gratings can be made tunable allowing controllable beam steering, tun-
able spectral separation, and wavefront control. The angle at which a particular incident wavelength is dif-
fracted by a grating is controlled by the incident angle and the pitch of the grating. Gratings in which the 
angle of incidence is controlled have been realized by mounting the grating on a movable structure similar 
to tip/tilt mirrors [62]. Gratings with adjustable pitch have been fabricated by either defining the grating on 
a flexible substrate and stretching the material to increase the separation of the lines [63], by concertinaing 
the lines of the grating [64], or by using fine-pitch arrays in which lines are removed from the field of view 
of the incoming optical signal [65]. An example of the tip-tilt approach is shown in Figure 13.23, while an 
example of the later stretched grating approach is shown in Figure 13.24.
Small droplet of partially
wetting liquid:
Zero applied voltage
Droplet with applied
voltage
Electrode
Tin insulator
Applied voltage
(a)
(b)
Shape B
Shape A
1
2
Counterelectrode
~
FIGURE 13.22  Operation of tunable microlenses based on electrowetting: (a) The principle of operation in which 
applying a voltage changes the surface tension of the liquid with respect to the planar surface on which it rests. (b) 
Shows how this effect can be used to form a variable focal length lens. The cell is filled with water 2. A drop 1 of 
an insulating and nonpolar liquid is deposited on the bottom wall, which is made of an insulating and transparent 
material, in gray. The central disc on the bottom wall surface is hydrophobic, in order to trap the drop. The outer 
zone, hatched in the figure, is hydrophilic. The optical axis is shown as a dashed line. (Modified from Berge, B. and 
Peseux, J., Eur. Phys. J. E, 3, 159, 2000.)
© 2011 by Taylor and Francis Group, LLC

13-28 
Fundamentals of Industrial Electronics
Comb
electrodes
Torsion
spring
Anchor
Driving
voltage
Grating mirror
plate
Frame
5 mm
1.6 μm
~
FIGURE 13.23  Movable grating showing the electrostatic comb-drive actuation, allowing the grating to be tilted. 
This structure was manufactured for use in microspectrometer. (Courtesy of Kraft, M. et al., Eur. Phys. J. E, 3, 159, 
2000.)
Relaxed
Stretched
3 μm
70 μm
FIGURE 13.24  Pitch-controlled grating structure that realizes an expandable grating in which the pitch of the grat-
ing is changed, thanks to the movement of the end point. In the figure a probe has been used to extend the accordion-
like structure. In the actual device, a thermal actuator drives a pawl and ratchet mechanism to control the extension 
of the structure. These structures were developed for use in large astronomical telescopes. (Courtesy of Konidaris, N.  
et al., Appl. Opt., 42(4), 621, February 2003.)
© 2011 by Taylor and Francis Group, LLC

MEMS Devices 
13-29
Aluminum
SiNx
p+ GaAs
AlGaAs
3 QW active
40.5 Period
AlGaAs DBR
n-Contact
Ge/Au/Ni/Au
(a)
n-Doped GaAs
substrate
Air gap
Gain
medium
Tunable laser
output
TiO2/SiO2
DBR pillar
(b)
VCSEL p-contact/
electrostatic actuator
lower electrode
Membrane
structure
Actuator top
contact
000002
3 kV
X500
60 μm
Suspended
TiO2/SiO2
DBR
FIGURE 13.25  Tunable vertical cavity surface-emitting laser structure. Changing the length of the optically 
resonant cavity, the emission wavelength can be controlled: (a) A cross-sectional schematic of the structure. (b) An 
SEM image of the structure. (Courtesy of Bond, T. et al., Two-state optical filter based on micromechanical diffrac-
tive elements, in 2007 IEEE/LEOS International Conference on Optical MEMs and Nanophotonics, Hualien, Taiwan, 
pp. 167–168, August 12–July 16, 2007.)
0.6
0.5
0.4
0.3
0.2
0.1
01400
1600
1800
2000
Wavelength (nm)
(b)
Normalized transmittance
2200
2400
2600
(a)
FIGURE 13.26  Electrostatically actuated MEMS tunable infrared Fabry–Perot filter structure: (a) An SEM image 
of the tunable filter (the circular filter area is 100 μm in diameter) and (b) the spectral characteristics of the device 
as the voltage is tuned. The pass transmission is limited because the substrate is not antireflection coated.
© 2011 by Taylor and Francis Group, LLC

13-30 
Fundamentals of Industrial Electronics
13.4.5.4  Filters
Tunable filter structures include variable attenuators, polarization filters, and spectral filters. All of these 
devices have been realized in MEMS using a variety of approaches. Of particular importance are tunable 
MEMS-based Fabry–Perot spectral filters because of their widespread use in tunable lasers and detec-
tors. In general, these devices use distributed Bragg reflectors for the mirrors that form the Fabry–Perot 
resonant cavity, and tuning has been achieved using thermal, piezoelectric, and electrostatic actuation. 
Compromises are made in the design of the Fabry–Perot filter to allow either high spectral resolution 
but limited tuning range (e.g., as required for dense wavelength-division multiplexing in optical fiber 
communications) or wide tuning range of up to one octave in wavelength, but limited spectral resolution 
(e.g., for application in near infrared spectroscopy). The compromise is needed because of mirror flat-
ness requirements and the need to operate in first order for wide spectral coverage. Figure 13.25 shows 
an example of a tunable vertical cavity surface-emitting laser diode that incorporates a tunable mir-
ror structure [66]. Figure 13.26 shows a tunable filter for spectroscopic applications in the near infrared 
region [67].
References
	
1.	 Sze, S. M., Semiconductor Sensors, Wiley, New York, 1994.
	
2.	 Korvink, J. and Paul, O., MEMS A Practical Guide to Design, Analysis and Applications, William 
Andrew Inc., Norwich, NY, 2006.
	
3.	 Smith, C. S., Piezoresistance effect in germanium and silicon, Phys. Rev., 94(1), 42–49, 1954.
	
4.	 Y. Kanda, Piezoresistance effect of silicon, Sens. Actuators A, 28(2), 83–91, 1991.
	
5.	 Middelhoek, S. and Audet, S. A., Silicon Sensors, Delft University Press, Delft, the Netherlands, 1994.
	
6.	 Fraden, J., Handbook of Modern Sensors, Physics, Designs, and Applications, Springer-Verlag, 
New York, 1996.
	
7.	 Senturia, S. D., Microsystem Design, Kluwer Academic Publishers, Norwell, MA, 2001.
	
8.	 Bell, D. J., Lu, T. J., Fleck, N. A., and Spearing, S. M., MEMS actuators and sensors: Observations on 
their performance and selection for purpose, J. Micromech. Microeng., 15, S153–S164, 2005.
	
9.	 Nathanson, H. C., Newell, W. E., Wickstrom, R. A., and Davis, J. R., The resonant gate transistor, 
IEEE Trans. Electon. Devices, 14(3), 117–133, 1967.
	 10.	 Rebeiz, G. M., RF MEMS: Theory, Design, and Technology, Wiley, New York, 2003.
	 11.	 Castañer, L., Pons, J., Nadal-Guardia, R., and Rodríguez, A., Analysis of the extended operation range 
of electrostatic actuators by current-pulse drive, Sens. Actuators: Phys. A, 90(3), 181–190, May 2001.
	 12.	 Seeger, J. I. and Crary, S. B., Stabilization of electrostatically actuated mechanical devices, in: 
Proceedings of the International Conference on Solid State Sensors and Actuators (Transducers ‘97), 
Vol. 2, Chicago, IL, pp. 1133–1136, June 16–19, 1997.
	 13.	 Pons, J., Rodriguez, A., and Castañer, L., Voltage and pull-in time in current drive of electrostatic 
actuators, J. Microelectromech. Syst., 11(3), 196–205, June 2002.
	 14.	 Bao, M.-H., Handbook of Sensors and Actuators, Vol. 8, Elsevier, New York, 2000.
	 15.	 Fan, L.-S., Tai, Y.-C., and Muller, R. S., IC processed electrostatic micromotors, in: IEEE International 
Electron Devices Meeting (IEDM), San Francisco, CA, pp. 666–669, December 11–14, 1988.
	 16.	 Sinclair, M. J., A high force low area MEMS thermal actuator, in: Proceedings of IEEE Intersociety 
Conference on Thermal and Thermomechanical Phenomena, Las Vegas, NV, pp. 127–132, May 23–26, 
2000.
	 17.	 Neukomm, P. A., Bornhauser, H. P., Hochuli, T., Paravicini, R., and Schwarz, G., Characteristics of 
thin wire shape memory actuators, Sens. Actuators A: Phys., 21(1–3), 247–252, 1990.
	 18.	 Wright, J. A., Tai, Y.-C., and Chang, S.-C., A large force fully integrated MEMS magnetic actuator, in: 
Proceedings of the International Conference on Solid-State Sensors and Actuators (Transducers ‘97), 
Vol. 2, Chicago, IL, pp. 793–796, June 16–19, 1997.
© 2011 by Taylor and Francis Group, LLC

MEMS Devices 
13-31
	 19.	 Niarchos, D., Magnetic MEMS: Key issues and some applications, Sens. Actuators A, 106, 255–262, 
2003.
	 20.	 Daigle, M., Corcos, J., and Wu, K., An analytical solution to circular touch mode capacitor, Sens. J., 
IEEE, 7(4), 502–505, April 2007.
	 21.	 Mohamed-el-Hak (Ed.), MEMS: Applications, CRC Press, Boca Raton, FL, 2006.
	 22.	 Palasagaram, J. N. and Ramadoss, R., MEMS-capacitive pressure sensor fabricated using printed-
circuit-processing techniques, Sens. J., IEEE, 6, 1374–1375, December 2006.
	 23.	 Goldsmith, C. L., Yao, Z., Eshelman, S., and Denniston, D., Performance of low loss RF MEMS 
capacitive switches, IEEE Microw. Guided Wave Lett., 8(8), 269–271, August 1998.
	 24.	 Muldavin, J. B. and Rebeiz, G. M., High-isolation CPW MEMS shunt switches – Part 1: Modeling, 
IEEE Trans. Microw. Theory Tech., 48(6), 1045–1052, June 2000.
	 25.	 Pacheco, S. P. et al., Design of low actuation voltage RF MEMS switch, in: 2000 IEEE MTT-S 
International Microwave Symposium Digest, Vol. 1, Boston, MA, pp. 165–168, November 5–8, 2000.
	 26.	 Peroulis, D., Pacheco, S., and Kaheti L. P. B., MEMS devices for high isolation switching and tunable 
filtering, in: IEEE MTT-S International Microwave Symposium Digest, Boston, MA, pp. 1217–1220, 
June 2000.
	 27.	 Muldavin, J. B. and Rebeiz G. M., High-isolation inductively-tuned X-band MEMS shunt switches, 
in: IEEE MTT-International Microwave Symposium Digest, Vol. 1, Boston, MA, pp. 169–172, June 
11–16, 2000.
	 28.	 Hayden, J. and Rebeiz, G. M., Low-loss cascadable MEMS distributed X-band phase shifter, IEEE 
Microw. Guided Wave Lett., 10(4), 142–144, April 2000.
	 29.	 Herfst, R.W, Steeneken, P.G., and Schmitz, J., Identifying degradation mechanisms in RF MEMS 
capacitive switches, in: Proceedings of the MEMS 2008, Tucson, AZ, pp. 168–171, January 13–17, 
2008.
	 30.	 Blondy, P., Crunteanu, D., Champeaux, C., Catherinot, A., Tristant, P., Vendier, O., Cazaux, J. L., and 
Marchand, L., Dielectric less capacitive MEMS switches, in: IEEE MTT-International Microwave 
Symposium Digest, Vol. 2, Fort Worth, TX, pp. 573–576, June 6–11, 2004.
	 31.	 Fernández-Bolaños, M., Tsamadós, D., Dainesi, P., and Ionescu, A. M., Reliability of RF MEMS 
capacitive switches and distributed MEMS phase shifters using AlN dielectric, in: 22nd International 
Conference on Micro Electro Mechanical Systems (MEMS), Sorrento, Italy, pp. 638–641, 2009.
	 32.	 Lakshminarayanan, B., Mercier, D., and Rebeiz, G. M., High-reliability miniature RF-MEMS 
switched capacitors, IEEE Trans. Microw. Theory Tech., 56(4), 971–981, April 2008.
	 33.	 Barker, N. S. and Rebeiz, G. M, Optimization of distributed MEMS transmission lines phase 
­shifters—U-band and W-band designs, IEEE Trans. Microw. Theory Tech., 48(11), 1957–1966, 
November 2000.
	 34.	 Perruisseau-Carrier, J. et al., Modeling of periodic distributed MEMS, application to the design of 
variable true-time delay lines, IEEE Trans. Microw. Theory Tech., 54(1), 383–392, 2006.
	 35.	 Borgioli, A. et al., Low-loss distributed MEMS phase shifter, IEEE Microw. Guided Wave Lett., 10, 
7–9, 2000.
	 36.	 Nagra, A. S. and York, R. A., Distributed analog phase shifter with low insertion loss, IEEE Trans 
Microw. Theory Tech., 47(9), 1705–1711, September 1999.
	 37.	 Kim, H.-T. et al., V-band 2-b and 4-b low-loss and low-voltage distributed MEMS digital phase 
shifter using metal-air-metal capacitors, IEEE Trans. Microw. Theory Tech., 50(12), 2918–2923, 
2002.
	 38.	 Hayden, J. S. and Rebeiz, G. M., 2-bit MEMS distributed X-band phase shifter, IEEE Microw. Guided 
Wave Lett., 10(12), 540–542, December 2000.
	 39.	 Fernández-Bolaños, M., Lisec, T., Dainesi, P., and Ionescu, A. M., Thermally stable distributed 
MEMS phase shifter for airborne and space applications, in: Proceeding of 38th European Microwave 
Conference, Amsterdam, the Netherlands, pp. 100–103, October 2008.
© 2011 by Taylor and Francis Group, LLC

13-32 
Fundamentals of Industrial Electronics
	 40.	 Barker, N. S. et al., Distributed MEMS true-time delay phase shifters and wide-band switches, IEEE 
Trans. Microw. Theory Tech., 46(11), 1881–1890, November 1998.
	 41.	 Vinoy, K. J. and Varadan, V. K., Design of reconfigurable fractal antennas and RF-MEMS for space-
based systems, Smart Mater. Struct., 10, 1211–1223, November 2001.
	 42.	 Fernández-Bolaños, M., Lisec, T., Dainesi, P., and Ionescu, A. M., Thermally stable distributed 
MEMS phase shifter for airborne and space applications, in: Proceeding of 38th European Microwave 
Conference, Amsterdam, the Netherlands, pp. 100–103, October 2008.
	 43.	 Koch, M., Evans, A., and Brunnschweiler, A., Microfluidic Technology and Applications, Research 
Studies Press, Baldock, U.K., 2000.
	 44.	 Samel, B., Nock, V., Russom, A., Griss, P., and Stemme, G., A disposable lab-on-a-chip platform with 
embedded fluid actuators for active nanoliter liquid handling, Biomed. Microdevices, 9, 61–67, 2007.
	 45.	 Braneberg, J. and Gravesen, P., A new electrostatic actuator providing improved stroke length and 
force, in: Proceedings of International Conference on Micro Electro Mechanical Systems, Travenmiinde, 
Germany, 1992.
	 46.	 Zengerle, R., Kluge, S., Richter, M. and Richter, A., A bidirectional silicon micropump, in: Proceedings 
of the Microelectromechanical Systems (MEMS’95), Amsterdam, the Netherlands, January 29–
February 2, 1995.
	 47.	 Laser D. J. and Santiago, J. G., A review of micropumps, J. Micromech. Microeng., 14, R35–R64, 2004.
	 48.	 Su, Y., Evans, A. G. R., and Brunnschweiler, A., Micromachined silicon cantilever paddles with 
piezoresistive readout for flow sensing, J. Micromech. Microeng., 6, 69–72, 1996.
	 49.	 Asgar, A, Bhagat, S., and Papautsky, I., Enhancing particle dispersion in a passive planar micromixer 
using rectangular obstacles, J. Micromech. Microeng., 18, 085005, 2008.
	 50.	 Suzuki, H., Ho, C.-M., and Kasagi, N., A chaotic mixer for magnetic bead-based micro cell sorter, 
J. Microelectromech. Syst., 13, 779–790, 2004,.
	 51.	 Van Kessel, P. F., Hornbeck, L. J., Meier, R. E., and Douglass, M. R., A MEMS-based projection 
display, Proc. IEEE, 86(8), 1687–1704, August 1998.
	 52.	 Maeda, R., Tsaur, J. J., Lee, S. H., and Ichiki, M., Piezoelectric microactuator devices, J. Electroceram., 
12(1–2), 89–100, January–March 2004.
	 53.	 Davis, W.O., Sprague, R., and Miller, J., MEMS-based pico projector display, in: 2008 IEEE/LEOS 
International Conference on Optical MEMs and Nanophotonics, Freiburg, Germany, pp. 31–32, 
August 11–14, 2008.
	 54.	 Doble, N. and Williams, D. R., The application of MEMS technology for adaptive optics in vision 
science, IEEE J. Sel. Top. Quantum Electron., 10(3), 629–635, May/June 2004.
	 55.	 Hokari, R. and Hane, K., A varifocal micromirror with pure parabolic surface using bending 
moment drive, in: 2008 IEEE/LEOS International Conference on Optical MEMs and Nanophotonics, 
Freiburg, Germany, pp. 92–93, August 11–14, 2008.
	 56.	 Bierden, P., Bifano, T., and Cornelissen, S., MEMS deformable mirrors for high-performance AO 
applications, in: Adaptive Optics for Industry and Medicine: Proceedings of the Sixth International 
Workshop, Dainty, C. (Ed.), Imperial College Press, London, U.K., 2008.
	 57.	 Sinzinger, S. and Jahns, J., Microoptics, Wiley-VCH, Weinheim, Germany, 2003.
	 58.	 Werber, A. and Zappe, H., Tunable microfluidic microlenses, Appl. Opt., 44, 3238–3245, June 2005.
	 59.	 Mugele, F. and Baret, J.-C., Electrowetting: From basics to applications, J. Phys.: Condens. Matter, 
17(28), R705–R774, July 2005.
	 60.	 Knittel, J., Richter, H., Hain, M., Somalingam, S., and Tschudi, T., A temperature controlled liquid 
crystal lens for spherical aberration compensation, Microsyst. Technol., 13(2), 161–164, January 2007.
	 61.	 Kraft, M., Berge, B., and Peseux, J., Variable focal lens controlled by an external voltage: An appli-
cation of electrowetting, Eur. Phys. J. E, 3, 159–163, 2000.
	 62.	 Kraft, M., Kenda, A., Frank, A., Scherf, W., Heberer, A., Sandner, T., Schenk, H., and Zimmer, F., 
Single-detector micro-electro-mechanical scanning grating spectrometer, Anal. Bioanal. Chem., 
385(5), 1259–1266, November 2006.
© 2011 by Taylor and Francis Group, LLC

MEMS Devices 
13-33
	 63.	 Konidaris, N., Wong, C. W., Jeon, Y., Barbastathis, G., and Kim, S.-G., Analog tunable gratings 
driven by thin-film piezoelectric microelectromechanical actuators, Appl. Opt., 42(4), 621–626, 
February 2003.
	 64.	 Konidaris, N. P., Kubby, J. A., and Sheinis, A. I., Small solutions to the large telescope problem: 
A massively replicated MEMS spectrograph, in: Advanced Optical and Mechanical Technologies in 
Telescopes and Instrumentation, Proceedings of SPIE, SPIE, Bellingham, Washington, 7018, 70182I-1–
70182I-9, August 2008.
	 65.	 Bog, T., Sagberg, H., Bakke, T., Johansen, l.-R., Lacolle, M., and Moe, S. T., Two-state optical filter 
based on micromechanical diffractive elements, in: 2007 IEEE/LEOS International Conference on 
Optical MEMs and Nanophotonics, Freiberg, Germany, pp. 167–168, August 12–July 16, 2007.
	 66.	 Bond, T. C., Cole, G. D., Goddard, L. L., and Behymer, E. M., Photonic MEMS for NIR in-situ 
gas detection and identification, in: Proceedings of IEEE 2007 Sensors Conference, pp. 1368–1371, 
Atlanta, GA, October 28–31, 2007.
	 67.	 Musca, C. A., Antoszewski, J., Winchester, K. J., Keating, A. J., Nguyen, T., Silva, K. K. M. B. D., Dell, 
J. M., et al., Monolithic integration of an infrared photon detector with a MEMS-based tunable filter, 
IEEE Electron Device Lett, 26(12), 888–890, December 2005.
© 2011 by Taylor and Francis Group, LLC

14-1
14.1  Introduction
The term “microelectro-mechanical systems” (MEMS) refers to any device whose characteristic dimen-
sion lies in the range of micrometers. This general definition encompasses not only devices whose main 
effects are electrical or mechanical, but also those that deal with optical, chemical, biological, or others. 
MEMS are usually referred to as “microsystems” in Europe or “micromachines” in Asia.
Although the term is general, it is usually used to name devices fabricated using micromachining 
techniques based on those used for microelectronics fabrication. Nevertheless, in recent years other 
fabrication techniques have been developed exclusively for MEMS, independently from microelectron-
ics industries.
After the inception of the silicon-based microelectronics industry in the 1950s and 1960s, several 
researchers studied the mechanical and piezoelectric properties of silicon and found that it was also 
suitable to build mechanical sensors. It was at that time that a now-classical speech was given by Nobel 
Prize winner Richard Feynman at the 1959 Annual Meeting of the American Physical Society. In that 
speech, called “There’s plenty of room at the bottom” [1], Feynman raised the question of whether it 
would be possible to construct extremely small machines, and explained how physics laws would allow 
that. It created a lot of enthusiasm in the matter and opened the way for the developments to come in 
the microscale.
14
MEMS Technologies
14.1	 Introduction.....................................................................................14-1
14.2	 Modeling and Scaling Laws...........................................................14-2
Scale in Size  •  Mechanical Properties  •  Modeling
14.3	 MEMS Materials..............................................................................14-5
Semiconductor Substrates: Silicon and Other 
Compound Materials  •  Silicon Oxide and Silicon 
Nitride  •  Insulating Substrates: Quartz, Glass, and 
Sapphire  •  Metals  •  Ceramics  •  Polymers
14.4	 Deposition.........................................................................................14-8
Material Deposition Techniques for MEMS  •  Classification 
of Deposition Techniques  •  Physical Deposition Techniques  • 
Physical Vapor Deposition  •  Sputtering  •   
Evaporation  •  Pulsed Laser Deposition  •  Spin Casting  •   
Chemical Deposition and Growth Techniques  •   
Thermal Oxidation  •  Chemical Vapor Deposition  •  Epitaxy  •   
Electroplating
14.5	 Etching.............................................................................................14-12
Wet Etching  •  Dry Etching
14.6	 Molding........................................................................................... 14-14
References...................................................................................................14-15
Antonio Luque
University of Seville
José M. Quero
University of Seville
Carles Cané
National Microelectronics 
Center
© 2011 by Taylor and Francis Group, LLC

14-2 
Fundamentals of Industrial Electronics
In the following decades, all kinds of MEMS devices were developed, including pressure and acceler-
ation sensors, inkjet printer heads, gyroscopes, RF components, optical elements, and chemical, micro-
fluidic, and biological devices.
The worldwide MEMS market is expected to grow up to 10,000 M$ in year 2011, and most estimations 
conclude that it will keep growing at least until 2020 [2].
Although it is a sector that already reached maturity in many aspects, still a lot of research is being 
directed toward developing new devices and applications or improving fabrication processes, making 
them less expensive and more reliable.
MEMS and nanotechnology are related fields, but the latter should not be viewed as a mere continu-
ation of the former, going beyond in the miniaturization. MEMS are usually built using a top-down 
approach (microdevices are constructed from macroscale materials using macroscale equipment), while 
nanotechnology-based components are usually built bottom-up (making complex systems by putting 
together molecules or simple elements). Many have come to see MEMS as the natural construction 
equipment for nanotechnology and nanodevices.
The rest of this chapter contains an introduction to the physical laws governing MEMS behavior, and 
the description of the fabrication techniques most commonly used in the development of these devices.
14.2  Modeling and Scaling Laws
Traditionally, MEMS devices are considered to have characteristic dimensions in the range of 
­0.1–100 μm. This is a very important miniaturization, relative to the traditional, macroscopic world, 
that will affect the relative importance of physical phenomena. For instance, in the macro world, at 
the human scale, the influence of gravitational forces is often considered, but in the micro world, at the 
micron scale, gravity has a very low incidence when compared with other forces. That is, MEMS lives in 
a zero-gravity world, and thus the performance of a mechanical MEMS device is independent of its rela-
tive position with respect to the Earth. This is just one example of the changes that appear when scaling 
down the physic laws, and special care should be taken when applying the intuition of our experience in 
macroscale engineering because many considerations will change.
In order to quantify the scaling effect, we will assume that there is a geometry scaling factor S. 
Normally, S will be in the range of 10−3 to 10−5. This means that a length Lo in the macro world will be 
scaled down to Ls = SLo in the micro world. In what follows, we present a brief comparative study of the 
scaling down of some physical phenomena.
14.2.1  Scale in Size
According to the definition of the scaling factor, a given length L in a device in the macroscale will be 
scaled by a factor of S, its surface is scaled by S2, and its volume by S3. The first conclusion we deduce 
is that the area to volume ratio will decrease from macro world expectations by a factor of S. Another 
conclusion is that there is a great reduction of volume with respect to its size. For example, if we have a 
scaling factor of S = 0.001, the volume of the corresponding MEMS device is reduced by 10−9. This fact 
implies a very large reduction of the volume of the devices compared to its surface or characteristic 
dimension. Therefore, any physical magnitude related to the volume will suffer a proportional reduc-
tion. For this reason, the weight of an object, which is proportional to its volume via the density of the 
material, will be reduced in the same proportion. This drastic reduction of volumetric properties will 
have very relevant impact in the behavior of MEMS devices.
14.2.2  Mechanical Properties
The stiffness is the ability of a mechanical system to resist an external force. This is the most important 
mechanical property because it determines the capability to support an external force. Let us consider 
a cantilever beam like the one depicted in Figure 14.1a.
© 2011 by Taylor and Francis Group, LLC

MEMS Technologies 
14-3
The reactive force F that appears in its free end when an external force F is applied can be expressed as
	
F x
EI
L
x
Eab
L
x
( ) =
=
3
3
12
3
3
3
	
(14.1)
where
E is the Young’s modulus
I is the moment of inertia of the beam’s section
x is the deflection in the free end of the beam
Assuming that E is constant during the reduction of size, we find that F decreases with S2. If we compare 
with an equivalent spring (Figure 14.1b), we have
	
F x
K
x
K
Eab
L
S
elastic
elastic
( ) =
⇒
=
∝
3
12
3
3
	
(14.2)
A similar analysis [3] can be generalized to any physical phenom-
ena, and we can obtain the scaling factors given in Table 14.1. There, 
a large exponent in S represents a high decrease of that effect. For 
this reason, we can deduce that magnetic forces drastically decrease 
or MEMS structures resonate at much higher frequencies that their 
counterparts in the macro world.
By comparing these laws in pairs more relevant results are pro-
duced. Table 14.2 presents the scaling effect on some ratios. A large 
S exponent means that forces in the numerator are relatively larger 
with respect to the ones in the denominator. In the above example, 
if we consider a cantilever beam of 1 m length that is scaled down 
to 1 mm, its reactive force decreases by a factor of 1,000,000. But 
what is relevant is the comparison to its weight, which decreases 
1,000,000,000. Consequently, the stiffness decreases 1,000 times 
than its weight when it is scaled down and therefore they have a more 
significant impact in the mechanical analysis. For this reason in the 
micro world, we will design our mechanical devices as if there is no 
gravity.
We can infer other important conclusions from these ratios. 
The use of very expensive and unusual materials for surface depo-
sition is possible because the mass we need is quite smaller com-
pared to their corresponding macroworld quantities. Conventional 
–F
F
x
–F
F
x
L
(a)
(b)
a
b
Cross
section
FIGURE 14.1  (a) Deformed cantilever beam when an external force −F is applied. (b) An equivalent spring.
TABLE 14.1  Scaling Factors of 
Some Physical Phenomena When a 
Device Size Is Scaled by a Factor S
Physical Property
Scaling 
Factor
Length
S
Surface
S2
Volume
S3
Mass
S3
Weight
S3
Elastic forces
S2
Electrostatic energy
S3
Electrostatic forces
S2
Magnetic energy
S5
Magnetic forces
S5
Surface tension force
S
Viscous friction
S
Mechanical time constant
S
Natural frequency
S−1
Thermal time constant
S
Electric resistance
S−1
Note:	 The smaller the S exponent, 
the larger its relative increase with 
respect to the macro world.
© 2011 by Taylor and Francis Group, LLC

14-4 
Fundamentals of Industrial Electronics
electromagnetic actuators like induction motors quite often used in everyday live are inefficient, and we 
usually apply electrostatic actuators in the microscale. Furthermore, as electrostatic and elastic forces 
decrease in the same proportion, they are the most appropriate pair for building mechanical actuators.
But not all ratios are beneficial. For example, viscous friction is a very strong inconvenient when 
designing movable parts, and mechanical structures can collapse due to surface tension forces when 
drying after a wet process. All these remarks, and even more, shall be considered when designing 
MEMS devices.
14.2.3  Modeling
Today, electronic engineers simulate complex VLSI circuits thanks to the availability of many com-
mercial computer-assisted design tools. However, MEMS are much more complex systems for several 
reasons. First, not only electronic processes are involved, but also mechanical, electrical, or fluidic 
domains interact in a coupled manner. Second, the reduction in size is very critical, and in many cases 
the hypothesis of continuous media is no longer valid because we are dealing with such thin layers 
of material that it is necessary to model them at the molecular level. For these reasons, the analytical 
description of the behavior of MEMS processes and devices is only possible in specific cases, and the use 
of simulation tools becomes a real need. But nowadays, MEMS engineers lack of a generic platform to 
make full-system simulations.
Modeling of system dynamics is normally done by Newtonian formulation, but Hamilton’s and 
Lagrange’s equations are two alternatives for the development of the equation of motion. Resonance 
mode of vibrating devices is quite convenient in mechanical design.
Fluidic modeling is normally performed using Navier–Stokes formulation. But the scaling process 
originates a dilution of fluids, especially in gases, and a molecular model for processes like mass or 
thermal transport is necessary.
Another problem is that nonlinear behavior commonly appears when working at small sizes. In these 
cases, a good alternative for the modeling of these phenomena is the use of neural networks.
In any case, the previous descriptions lead to very complex and coupled set of linear and nonlinear 
equations. Thus, the use of a numerical software package like MATLAB• or Simulink• is essential for 
their resolution.
Using analogies with electrical circuits [4] is another way to circumvent the modeling problem. In 
this way, we can apply the understanding of electrical circuits that electrical engineers have developed 
for years, and the use of conventional well-known simulators like SPICE becomes possible.
TABLE 14.2  Comparison of Physical Phenomena When a Device Size 
Is Scaled by a Factor S
Physical Property
Scaling 
Factor
Comment
Elastic forces/gravitational forces
S−1
Weight is negligible.
Electrostatic forces/magnetic forces
S−3
Depending on the actuators’ 
geometries; but electrostatic 
forces are generally larger 
than magnetic ones.
Electrostatic forces/elastic forces
1
Depending on the actuators’ 
geometries and actuation 
principles.
Inertial forces/viscous friction
S2
Reynolds number.
Surface tension force/gravity
S−2
Weber number.
Note:	 The larger the S exponent, the larger the force ratio is with respect to the 
macro world.
© 2011 by Taylor and Francis Group, LLC

MEMS Technologies 
14-5
But new problems arise at the microscale level and should be taken into account. For instance, that is 
the case of the Paschen’s effect; this law predicts an increase of the breakdown voltage of gases due to the 
decrease of the number of molecules when reducing the gap between plates. This fact allows for the use 
of higher polarization voltages in electrostatic actuators than expected.
14.3  MEMS Materials
Most of the interesting properties of MEMS devices are due to the fact that they can be manufactured 
using similar, if not the same, facilities than for integrated circuits. The same occurs for the materials, 
as silicon is the most important material for MEMS because it takes advantage of all the development 
done for microelectronics. However, in MEMS industry silicon is the first choice not only for its good 
electrical properties but also thanks to its mechanical properties. Other semiconductor materials, 
polymers, and ceramics are also being used in new devices. In MEMS, we find not only substrate and 
thin or thick layer materials that have a function on the device, but also sacrificial materials that are 
used as intermediate layers for defining the layout of the devices but are not part of the final product. 
In most cases, the properties of these sacrificial materials have to be rather different than the ones for 
bulk materials, and not only silicon-based semiconductors and dielectrics are used for this sacrificial 
purpose. Finally, while the complexity of MEMS devices have evolved to 3-D structures and to smart 
systems, new materials have appeared and have taken importance as a complement to silicon. In the 
next paragraphs, the most interesting semiconductor materials will be described along with others 
like glass, polymers, ceramics, and metals, which allow for low cost, easy manufacturing, and high 
quality packaging. Figure 14.2 graphically summarizes the most important materials for MEMS and 
their applications.
When selecting a material, it must be taken into account that properties like uniformity, electrical 
and mechanical quality, thermal and optical properties, etc., depend not only on the material itself 
but also on the process for growth or deposition and on if it is in bulk or in film format. In addition, 
parameters like inherent stress, bucking, roughness, etc., may vary between thick and thin films of 
the same material. In conclusion, material selection for MEMS highly depends on the requirements of 
the application.
Silicon
Compound
semiconductors
Quartz
Glass
Sapphire
Polymers
Ceramics
Sacriﬁcial materials
and thin layers
Silicon oxide/nitride
Metals
Polymer, polyimide,
photoresist
Polysilicon
Substrate materials
Materials for MEMS
FIGURE 14.2  Materials used in MEMS.
© 2011 by Taylor and Francis Group, LLC

14-6 
Fundamentals of Industrial Electronics
14.3.1  Semiconductor Substrates: Silicon and Other Compound Materials
Silicon is the most important bulk material and the elemental semiconductor for MEMS fabrication 
because it combines multiple convenient properties: electrical and optical quality; good mechanical 
properties based on its robustness and elasticity and high stiffness; and easy growth of a silicon oxide 
layer as a good dielectric material. Because of these characteristics, many MEMS structures and devices 
can be integrated on silicon alone or combined with other materials (glass, metals, polymers, and so on). 
Silicon can be chemically and physically etched, and as etch rates depend on the crystal orientation of 
silicon planes, it is easy to fabricate membranes, beams, and other complex 3-D structures that are the 
basics of many sensors and actuators.
Thanks to the huge use in microelectronics, silicon is an abundant and inexpensive material and can 
be obtained in the format of ultrapure crystalline double-side polished wafers for MEMS processing. 
Both N-type (electron-rich with intentionally added concentration of group V impurities) and P-type 
(hole-rich with intentionally added concentration of group III impurities) substrates are used depend-
ing on the application.
In addition, polysilicon (polycrystalline thin layer of silicon) is also interesting for microelectron-
ics and MEMS and it can be deposited by low-pressure chemical vapor deposition (LPCVD) with very 
good control. Amorphous silicon can be also deposited as thin or thick film of usually below 5 μm. 
Interesting moveable microstructures of polysilicon and amorphous silicon can be fabricated with spe-
cific techniques commonly called surface micromachining. Compared to bulk silicon, deposited layers 
show inherent stress, but this stress can be controlled with the deposition parameters and also with sub-
sequent annealing processes. Porous silicon is another interesting material for some niche applications. 
Silicon can be also porosified with chemical treatments by HF, and used as sacrificial layer, as a thermal 
insulator, as mechanical or chemical filter, and for optical devices.
Silicon on insulator (SOI) substrates are also popular for MEMS, despite their higher cost. They are 
silicon substrates with a buried layer of oxide, which can be used for micromachining silicon as the 
oxide is a natural etch stop for silicon wet etching. In this way, crystalline bulk silicon of the top layer 
can be used for creating moveable structures with low stress and uniform and controlled thickness. The 
main drawback of SOI is the high cost of the wafers, compared to pure silicon.
Silicon is also a good material for intermediate temperature operation, while for high-temperature 
MEMS, silicon carbide and diamond are more appropriate substrates. In addition, both materials offer 
advantages of higher hardness and stiffness and resistance to harsh environments, compared to pure 
silicon. Layers of crystalline and polycrystalline silicon carbide and amorphous synthetic diamond can 
be deposited by CVD and can be also used as good coating materials for MEMS packaging. The main 
drawbacks of these materials are the very high cost and the difficulty of growing substrates of a reason-
able size that makes it more convenient to work with deposited layers on a low-cost silicon substrate. 
Another drawback of these materials is the difficulty of etching them, as they are highly inert.
Finally, it has to be mentioned that for specific MEMS applications, such as for optical devices and 
lasers, high speed or wide band gap devices, the most appropriate materials are some compound semi-
conductors of groups III–V (GaAs, InP, GaN,…). Controlled layer deposition combined with microma-
chining techniques allow also for the creation of RF devices, antennas, and other interesting devices for 
wireless communications.
14.3.2  Silicon Oxide and Silicon Nitride
It is fully accepted that another crucial factor of success of silicon is the simplicity of forming a high 
quality and stable silicon oxide dielectric from a simple thermal oxidation process. Silicon oxide is a 
good electrical isolator in microelectronics and also plays an important role in MEMS, as sacrificial 
layers and also inter-metal films and planarization layers can be created with such a simple material. Its 
main drawback is that it is difficult to control the inherent stress of the materials when it is used in thin 
© 2011 by Taylor and Francis Group, LLC

MEMS Technologies 
14-7
film format. For such a reason, silicon nitride is commonly preferred for membrane and beam fabrica-
tion. Nitride can be deposited by CVD and is interesting also as material with good thermal isolation 
and for being used as etch stop for some silicon chemical reagents.
14.3.3  Insulating Substrates: Quartz, Glass, and Sapphire
Quartz wafers are mostly used as piezoelectric material for some acoustic and RF applications (i.e., 
SAW, BAW filters and sensors, and so on). Quartz can be found as pure crystalline and amorphous fused 
quartz wafers depending on the application. For some optical devices that need transparent access, 
quartz is also a good option.
Glass is a cheaper option that can be used for the same applications, but the potential problem of the 
impurities of this material has to be taken into account. Glass is also a good option for soft lithography 
processes, and depending on the material (e.g., Pyrex 7740) it can be strongly attached to silicon wafers 
via anodic bonding. This makes glass very useful for some microfluidics devices and 3-D integration 
and as for sensor packaging (e.g., pressure sensors and accelerometers).
Sapphire is a third option if MEMS devices require insulating and/or transparent substrates. 
Compared to glass and quartz, sapphire is stronger and wear resistant but much more expensive and 
difficult to etch. Sapphire is also compatible with CMOS manufacturing.
14.3.4  Metals
Compared to microelectronics, a much higher variety of metals is used in MEMS. It is mainly due to 
the fact that in this case, metals are not only necessary for interconnections but they can also have 
other important functionalities for the final MEMS device. Thus, the selection of the metal to be used 
highly depends on the application. Pure aluminum or alloys (Al-Cu, Al-Cu-Si) are the most traditional 
for low temperature operation devices if only connectivity between devices is required. Aluminum is 
also a good candidate for optical mirrors in the visible range. However, as its melting point is around 
450°C, it cannot be used for some specific devices and processing techniques and when the ambient is 
corrosive. Thus, for chemical and biochemical applications (i.e., microelectrodes and other chemical 
sensors), gold, platinum, or iridium are preferred. Platinum and palladium are also used for electro-
chemical devices because of their high chemical stability. Alloys and pure silver are used for stable 
counter electrodes. Chromium and titanium are suitable as very thin layers for promoting the adhesion 
of other metals over dielectric layers and silicon substrates. Finally, other more complex alloys (permal-
loy, NiCr, ITO, NiCr, and so on) are being integrated on MEMS for some specific magnetic, thermal, 
or optical devices.
The abovementioned metals can be deposited by sputtering or evaporation techniques. Stresses and 
other mechanical properties can be tuned with the deposition parameters, which are not only important 
for thin layer deposition but also for the case of using metals as sacrificial layers.
14.3.5  Ceramics
Ceramics are another family of interesting materials for MEMS. Nowadays different functional ceram-
ics, such as dielectric, piezoelectric, pyroelectric, ferroelectric, and conducting materials, can be very 
useful when combined with silicon for incorporating some functionalities that could not be reached by 
silicon alone. Many sensing devices can benefit from such properties.
Ceramics are of lower cost when compared to other already mentioned materials and are good for 
harsh environment applications as they usually are chemically inert, with good temperature stability 
and with different electric and magnetic properties. SiCN and PZT are the most common materials used 
nowadays for MEMS. Ceramics can be made both in bulk format and also as deposited layers.
© 2011 by Taylor and Francis Group, LLC

14-8 
Fundamentals of Industrial Electronics
14.3.6  Polymers
Apart from the already mentioned inorganic materials, another set of organic materials are becoming 
more and more important in MEMS fabrication. Polymers try to circumvent some of the main draw-
backs of the silicon-based structures, which are related to the difficulty of implementing high aspect 
ratio devices that are of main importance for most mechanical sensors and actuators. Polymers are 
more elastic, less stiff, and need lower actuating forces to create the same displacements.
On the other hand, polymers of low cost are very appropriate for fluidic applications and single-use 
medical devices. The good absorption properties of polymers make them interesting for humidity and 
vapor sensing, too. However, maximum operating temperature (normally below 200°C but up to 400°C 
for specific resists) of the organic materials is a limitation for some devices.
Polymers can be used in foil format or as thick layers usually deposited by spinning. 3-D structures 
can be also patterned by hot embossing and molding techniques. Many polymeric materials and com-
posites are being investigated for MEMS applications, and current research on material intends to 
improve characteristics by changing their chemical composition, looking for the appropriate character-
istics on chemical resistance, thermal characteristics, and optical properties from transparent to opaque 
materials. On the other hand, most polymers can be easily metalized, and thus it is feasible to integrate 
electrodes on the same structure.
Most well-known materials for MEMS are polyimides, photoresists, and silicones, being SU-8, 
PMMA, BCB, PDMS, Parylene, and liquid crystal polymers some of the most popular. Thicknesses can 
range from 1 μm for standard spin-coated photoresists up to 300 μm for thick SU-8 structures. Rigid 
structures can be obtained after subsequent hardening of the resists. Resistance to harsh environments 
depends also on the chemical composition of the polymer. Thus, the selection is again based on the 
application that can range from optical MEMS, BioMEMS, and microfluidics, to packaging and integra-
tion of complex sensor and actuator structures. In most cases, the low cost required for the devices of 
these applications make polymers to be the best solution for high volumes.
14.4  Deposition
As already stated, MEMS fabrication processes mostly rely on already developed processes for micro-
electronics. The development of planar technologies for integrated circuit fabrication was the break-
through that allowed the fabrication of huge amounts of integrated circuits at very low unitary cost. 
Planar technologies consist of a set of processes that allow the fabrication of thousands of chips at the 
same time on the same substrate following a set of deposition and geometrical definition and etching 
steps of different materials. In this section, the most interesting materials and deposition techniques for 
MEMS devices are shortly summarized.
14.4.1  Material Deposition Techniques for MEMS
Deposition techniques are additive processes of materials on substrates for the fabrication of functional 
electronic devices. For the specific MEMS fabrication, the most interesting materials are silicon as a basic 
substrate material and polysilicon and other semiconductors, metals, dielectrics, and polymers. These 
materials can be an active part of MEMS, but can be also isolators and sacrificial layers. Depending on 
the material and on its use, its addition to the substrate can be made by following physical and chemical 
techniques that are described below.
14.4.2  Classification of Deposition Techniques
In Figure 14.3, the main techniques are presented and classified according to its nature and characteris-
tics. For their selection for MEMS fabrication, it is important to know that not all of them allow for both 
front and back side process; electrical and mechanical properties, conformality, and residual stresses 
© 2011 by Taylor and Francis Group, LLC

MEMS Technologies 
14-9
of the layers deposited also vary among the different techniques. Thicknesses, deposition rates, and 
cost are also radically different. Thus, it is important to define the specific characteristics of the MEMS 
device to be fabricated prior to the selection of the deposition technique to be used [5].
14.4.3  Physical Deposition Techniques
The main physical deposition techniques are vapor- and plasma-deposition and spin casting. In these 
cases, the material to be deposited is transported by physical methods from a source of material to the 
surface of a substrate where it is deposited without the existence of a chemical reaction on that sur-
face. The main differences among the techniques are the types of materials that can be deposited, the 
thickness and growth rates that can be achieved, the temperature of operation, and the electrical and 
mechanical quality of the material.
14.4.4  Physical Vapor Deposition
With these techniques the material to be deposited is removed from a solid source, is transported to the 
substrate and is finally deposited on it. The main differences among the different physical techniques 
refer to the process of removing the material from the solid source, the directionality of the deposition 
and its cleanliness and potential contamination of the substrate with by-products. Compared to most 
chemical techniques, physical vapor deposition (PVD) is a low-temperature process that is very suitable 
for back-processes (steps done after metals and other low-melting temperature materials are added to the 
substrate). However, electrical quality and stresses may be worse because of the low temperature process-
ing. The two main PVD processes for MEMS are sputtering and evaporation, which are described below.
14.4.5  Sputtering
Sputtering is probably the most used technique of deposition of most of the materials used in integrated 
circuit fabrication and MEMS. With this technique, the desired atoms are physically removed from 
Classiﬁcation of deposition techniques
Chemical
Physical
Physical vapor
deposition (PVD)
Spin-casting
Termal oxidation
Chemical vapor
deposition (CVD)
Epitaxy
Electrodeposition 
(electroplating)
Evaporation
Sputtering
Pulsed laser deposition (PLD)  
Low pressure (LPCVD)
Atmospheric pressure (APCVD) 
Plasma enhanced (PECVD)
Atomic layer
deposition (ALD)
FIGURE 14.3  Classification of deposition techniques.
© 2011 by Taylor and Francis Group, LLC

14-10 
Fundamentals of Industrial Electronics
a target by energized ions Ar+ (plasma). Then, atoms are ejected and deposited onto the wafer. Energetic 
ions can be obtained by magnetron or plasma (PECVD) sources in processes that can be also low pres-
sure (LPCVD) but not high vacuum (P > 0.01 Torr) for increasing deposition rates. Thicknesses obtained 
range from hundreds of nanometers to some microns.
The main MEMS materials that can be sputtered are most metals, some dielectrics, and also some 
piezoelectric ceramics. The main advantages of the sputtering technique are the uniformity and good 
adhesion of the layers deposited, the speed of deposition, and the wide choice of materials that can be 
sputtered, being really a well-established production technique with a wide set of parameters to select, 
depending on the desired properties of the material. Another advantage is the low temperature required 
for the deposition process (<150°C) compared to other techniques. On the other hand, the main draw-
backs are complexity of the system, its cost, and also the potential damage of the substrates because of 
the bombardment damage.
14.4.6  Evaporation
In evaporation, the material to be deposited is heated in high vacuum until sublimation. Thus, the sub-
strate receives the material as hot source atoms are emitted in all directions and stick in any surface that 
is on their directional flux. For a better optimization of the process, different substrates are placed in a 
planetarium around the material source. The energy source can be a resistance (thermal evaporation) or 
from that of an e-beam (e-beam evaporation). Despite the additional complexity of the e-beam, in both 
cases the system is simpler than the sputtering.
On the other hand, the main limitation is on the materials that can be evaporated, as only metals 
can be heated until sublimation with thermal evaporation, although with e-beams some dielectrics can 
be evaporated. E-beams also allow higher evaporation rates and better material adhesion. Other draw-
backs of evaporation compared to sputtering are the poor conformity of the layer if there is no substrate 
rotation during the evaporation, and the possible substrate contamination from the filament used to 
heat the material during evaporation. Thicknesses obtained range from hundreds of nanometers 
to some microns with deposition rates in the range of 5–100 nm/min, which are slightly higher than for 
sputtering.
14.4.7  Pulsed Laser Deposition
Pulsed laser deposition (PLD) is a much newer technique of deposition compared to the other two tech-
niques already presented. In this technique, a thin film can be deposited on a hot substrate thanks to a 
high-power pulsed laser beam that is focused on the target under ultrahigh vacuum or a specific gas (i.e., 
oxygen). The target material is then vaporized in the form of a plume and deposited on the surrounding 
vacuum. The technique is well used for metals, oxides, and also other complex materials especially for 
very thin films, as the good control of the laser properties allows to obtain smoother and thinner films 
compared to sputtering.
14.4.8  Spin Casting
Spin casting or spin coating technique is used for forming thin or thick films of materials that are 
dissolved in a volatile liquid solvent that are spin coated onto a substrate. Then, the material is cured 
around 100°C. The main materials that can be spinned are organic photoresists and polyimides in 
the typical range of 1–20 μm (and up to 200 μm for epoxy like SU-8 resists). Such resists can be used 
as intermediate materials during processing but also as active materials for MEMS. In addition, spin 
casting is used for depositing thick (up to 100 μm) inorganic spin-on glass (SoG) layers for uniformly 
coating surfaces, for depositing thin (up to 0.5 μm) interlayer dielectrics between metal levels for some 
specific application.
© 2011 by Taylor and Francis Group, LLC

MEMS Technologies 
14-11
Films are of low quality and amorphous, and the thickness can be controlled with the density of the 
solution and with the spinner parameters (i.e., speed, acceleration, and time). Thicknesses can reach the 
order of 100 μm, depending on the material.
14.4.9  Chemical Deposition and Growth Techniques
The addition of materials on a substrate can also be done by chemical techniques, which became very 
popular at the beginning of the 1960s, when planar techniques were developed for microelectronics 
fabrication. Compared to physical deposition, now in chemical techniques the material to be deposited 
is not transported as it is finally deposited, but a chemical reaction occurs on the surface of the sub-
strate and the material is generated. As shown in Figure 14.3, the most important techniques are oxida-
tion, low-pressure and plasma-enhanced CVD, and epitaxy [6]. Fundamentals of these techniques are 
described in the next paragraphs.
14.4.10  Thermal Oxidation
The main chemical process is the one from which a silicon oxide (SiO2) is obtained from the high-
temperature oxidation of a silicon wafer. Thus, in fact it is not a deposition process but a growth 
process, as part of the SiO2 material is the own silicon of the substrate. The importance of this pro-
cess relies on the fact that the SiO2 shows very interesting properties, as it is the best natural amor-
phous insulator of high electrical quality. For that reason, SiO2 is commonly used as insulating layer 
between metal lines and within electronic devices. Silicon oxide is also used as a surface passivation 
layer or as a blocking layer to mask impurity atoms. Oxidation can be masked locally by an oxida-
tion barrier, such as silicon nitride. In MEMS, oxides are also good sacrificial layers for the definition 
of complex structures. Silicon oxidation followed by etching can be used for sharpening of silicon 
MEMS features.
Thermal oxidation is based on the transport and reaction of oxidation species on a silicon surface. 
Once oxidation starts, another process is necessary, which is the diffusion of oxygen through the exist-
ing oxide. Growth rate is determined by this diffusion of oxygen. Depending on if the reacting oxygen is 
pure gas or comes from water vapor, we can differentiate between dry oxide and wet oxide.
	
Dry oxide Si(s) + O (g)
SiO (s)
(dry)
2
2
→
	
	
Wet oxide Si(s) + 2H O(g)
SiO (s) + 2H (g)
(wet)
2
2
2
→
	
Oxide properties may be varied by controlling oxygen or water vapor flow and temperature during 
reaction. The pros and cons of both techniques are as follows: while dry oxide is denser, with higher 
dielectric strength, the oxidation rate is slow and is mainly dedicated to thin oxides (like for the gate 
oxide of a MOS transistor). On the contrary, wet oxides show faster growth rates as H2 speeds the diffu-
sion of oxygen, but the dielectric is of lower quality, being appropriate for field and sacrificial oxides. In 
both cases, cleanliness is essential as oxide charge is very detrimental for the electrical stability of MOS 
active devices.
14.4.11  Chemical Vapor Deposition
In CVD, species in vapor phase react at a hot surface to deposit solid films. Thus, unlike oxidation, it 
does not consume substrate material. CVD is a common MEMS tool for creating thick silicon oxide and 
silicon nitride films on the wafer surface. In practice, films are typically submicron thick but can be used 
as conformal coatings. Inherent stress of the deposited material can be reduced by optimizing process 
parameters or by post annealing.
© 2011 by Taylor and Francis Group, LLC

14-12 
Fundamentals of Industrial Electronics
Many different CVD techniques have been developed over the years, the most important being the 
low pressure (LPCVD), atmospheric pressure (APCVD), plasma-enhanced (PECVD), metal organic 
CVD (MOCVD), and more recently atomic layer deposition (ALD) for extremely thin coatings. In all 
cases the film composition, uniformity electrical and mechanical characteristics, and deposition rates 
can be varied by controlling the variables of the gas composition, pressure, and temperature of the 
substrate. CVD films can be polycrystalline or amorphous thin films. In microelectronics and MEMS, 
principal uses of CVD films are for passivation, insulation, but also for structural and sacrificial layers.
Compared to thermal oxidation, CVD is a faster process that allows not only obtaining layers of sili-
con oxide but also of other interesting materials such as Si3N4, polysilicon, some metals, phosphosilicate 
glass (PSG), etc., on substrates that do not need to be of silicon, as there is no material consumption. 
However, as the main drawback, there is the lower electrical and mechanical quality of the layer inher-
ent to the low temperature processing.
14.4.12  Epitaxy
Epitaxy is a chemical deposition technique that allows the deposition of crystalline layers over a crystal-
line substrate, as deposited atoms move to lattice sites. Thicknesses of epitaxial layers typically range 
from 1 to 20 μm. For the material to be crystalline it is necessary that the process is at slow (0.2–4 μm/
min) and at high temperature (>800°C) in order to have enough time and energy to move atoms to a 
lattice site.
When the material grown is the same as the substrate (i.e., Si on Si), the process is usually called 
homoepitaxy, while when the material grown is different (i.e., AlGaAs on GaAs) it is called heteroepi-
taxy. The most well-known technique for epitaxial growth is the molecular beam epitaxy (MBE).
14.4.13  Electroplating
Electroplating is a well-known technique for depositing thick metals (i.e., Cu, Au, Cr, Ni, permalloy, 
copper interconnect) that is also used in MEMS fabrication (e.g., magnetic devices and others), when 
sputtering or evaporation do not reach the desired thickness or step coverage. As an advantage com-
pared to other techniques, electroplating allows the deposition of metal on both vertical and horizontal 
surfaces at the same time and with the same deposition rate.
The electroplating method is based on the passing of current through an aqueous solution in which 
the metal to be deposited is dissolved. Positive metal ions from an anode travel to cathode on the 
­substrate and deposit there. The anode is made of the metal to be deposited, while the cathode is the 
conductive seed of the substrate. If electroplating is not desired on the whole surface of the substrate, 
the seed or adhesion layer can be previously masked, and if high aspect ration features are to be devel-
oped, then it is necessary to create a pattern on thick resist that can be used as a sort of mold for the 
platted metal.
14.5  Etching
Etching is the selective removal of material from the substrate. Selection is usually made by protecting 
some areas with a hard mask that has been previously patterned using a photolithographic technique. 
Etching is wet when this removal is performed in the presence of a liquid element, and dry if otherwise.
14.5.1  Wet Etching
Depending on the shape produced by the etching, it is classified as isotropic or anisotropic. In isotropic 
etching, all spatial directions are etched at the same speed, while in anisotropic etching one or more 
directions are etched much more slowly than the rest [7].
© 2011 by Taylor and Francis Group, LLC

MEMS Technologies 
14-13
Anisotropy can be caused by the etched material having an anisotropic internal structure, like in 
crystalline solids (crystallographic etching), or by a preference in the movement of the reactant ions 
(this is usually the case of dry etching, see below).
Figure 14.4 shows the difference between isotropic and anisotropic etching, in the same material and 
using the same mask.
As in an isotropic etching the etching speed is the same in all directions; a phenomenon known as 
underetching is common in these processes. A part of the material that is supposed to be protected by 
the mask is also etched away. After enough time, the etching profile will resemble a quarter-cylinder 
along the mask edge. In isotropic etching, it is not possible to create deep holes, only holes whose depth 
is equal to one half their width are possible. Usually, this is not a problem for surface micromachined 
devices (see below), where the thickness of the material to be etched is orders of magnitude smaller than 
the width of the patterns.
Anisotropy can be measured using a parameter known as anisotropy degree, η0. It is defined as func-
tion of the lateral etching rate vl and the perpendicular etching rate vn and it is calculated as follows:
	
η0
1
= −v
v
l
n 	
When vl > vn, η0 is assumed to be 1. Using η0 the underetching can be calculated as
	
l
d
u =
−
(
)
1
0
η
	
where d is material thickness or the depth to be etched.
In wet etching, atoms or molecules from the solid substrate are transferred to the liquid phase [8]. 
This way, it is possible to achieve a high precision in the etched depth, but at the same time the process 
is considerably slow.
A typical distinction in etching is that of surface and bulk micromachining [9,10]. In surface micro-
machining the material to be etched has a thickness much smaller than the other dimensions. This is the 
case, for example, of thin films that must be etched to reveal the material beneath, or when a thin layer 
is removed to leave a structure hanging (see Figure 14.4). In bulk micromachining real 3-D structures 
are formed, and holes whose depth is comparable to their width are possible. Figure 14.5 shows a bulk 
micromachining performed anisotropically on a substrate.
Etch rates for a given etchant on a specific material are widely known for most useful combinations 
[11], so the required time to achieve a desired depth can be calculated. Nevertheless, it is sometimes 
FIGURE 14.5  Surface micromachining.
(a)
Isotropic
Anisotropic
(b)
FIGURE 14.4  Etching: (a) isotropic (b) anisotropic.
© 2011 by Taylor and Francis Group, LLC

14-14 
Fundamentals of Industrial Electronics
desirable to have a method for stopping the etch at a predefined depth. Most commonly used etching-
stop techniques are electrochemical stopping, p+ doping, and material change detection [12].
14.5.2  Dry Etching
In dry etching the etchant is in vapor phase or, more commonly, in plasma phase. Etching is caused by 
a chemical reaction on the surface, by ion bombing over the substrate, or by a combination of both [13]. 
Sometimes plasma resides in the same chamber as the substrate (glow discharge), while at other times, 
it is generated in a separate chamber, and ions are extracted to make them collide against the substrate 
(ion beam).
Techniques of dry etching can be classified as chemical or physical, according to the effect that is used 
to remove the material [14].
In physical dry etching, inert ions are directed toward a surface. Ions do not react with the sub-
strate, but remove material from it by colliding with a high kinetic energy. If ion energy is too low, they 
will bounce against the surface, and if it is too high, ions will penetrate inside the material, generating 
ion implantation. Optimal energy for etching lies between 10 and 10,000 eV. The main inconvenient of 
physical dry etching is its low selectivity between materials, as all of them are etched roughly at the same 
rate. In addition, it is considerably slower than chemical dry etching.
In chemical dry etching, a chemical reaction is produced between the impacting ions and the surface, 
so the etch rate is higher. The right combination between physical and chemical etching usually gives 
the best results in terms of selectivity and etch rate.
Of particular interest is the technique known as deep reactive ion etching or DRIE, which uses a 
high-density plasma in a low-pressure chamber, and then can be employed to achieve near-vertical walls 
in the etching [15]. This can be achieved at low temperatures (cryogenic process), or at ambient tempera-
ture (Bosch process).
14.6  Molding
By using molding and casting, large quantities of devices can be fabricated at a low cost. Usually, molds 
are made of a hard material, like silicon or a thick photoresist, while the final devices are made out of a 
deformable material that can be cured or hardened in some way. Different types of polymers are com-
monly used for this purpose.
Also, fabrication of microdevices in polymeric materials is accomplished in a shorter time than, e.g., 
silicon, so they are often used for prototyping or small batches.
Among the polymers commonly used in MEMS, PMMA (poly-methyl-methacrylate) and PDMS 
(poly-dimethyl-siloxane) are the best known. PMMA is usually available in solid form, and to pat-
tern it, thermal casting or molding is used. After being molded, it exhibits very good structural 
properties [16].
PDMS is commercially sold as two liquid products: a prepolymer and a curing agent. When mixed 
in the right proportion, and left to cure, they will form a transparent, elastomeric solid. This process is 
particularly suitable for microfluidic prototyping, since channels and chambers are easily fabricated, 
and PDMS-to-PDMS bonding can be made irreversibly and with good hermetic sealing [17].
Typical PDMS processing begins with the fabrication of a mold, which will have the negative shape 
of the final device to be fabricated. This mold is usually made of SU-8 photoresist on silicon. The mix of 
PDMS prepolymer and curing agent is poured over the mold and left to cure for 1 h at 80°C. After this 
time, it solidifies and it can be easily peeled off the wafer. One added advantage of the process is that 
several layers of PDMS can be peeled before they are completely cured, and then put together to finish 
the curing. They will be cured together and will form an irreversible bond. This way, hermetically closed 
cavities can be constructed.
© 2011 by Taylor and Francis Group, LLC

MEMS Technologies 
14-15
The whole process can be finished in less than 4 h, making it extremely convenient for prototyping.
Both PMMA and PDMS are biocompatible and can be used in implants in the human body. Bonding 
of PMMA and PDMS to other materials is possible, but difficult to achieve after curing. Commonly, 
the surfaces have to be activated by oxygen plasma. However, the obtained bonds are not permanent, 
although they are able to withstand moderate pressures.
A different process that makes use of molding is LIGA, an abbreviation of LIthographie, 
Galvanoformung und Abformung (lithography, electroforming and molding) [18]. Using LIGA, high-
aspect ratio microstructures can be fabricated. The process starts by coating a substrate with a thick 
photoresist, which is subsequently exposed to radiation. Depending on the thickness of the photoresist 
layer, exposing will use traditional UV light, electron beams, or x-ray radiation. After photoresist has 
been patterned and developed, a thick metal layer is electrodeposited on top of it, filling all the gaps. 
The remaining of photoresist is then stripped off, leaving just the metal, which will be used as a mold to 
fabricate the final device (Figure 14.6).
The LIGA process has traditionally been the only possible way to achieve high-aspect ratio micro-
structures with submicrometer feature size, almost vertical sidewalls, and ample variety of materials 
[19]. The high cost that was associated with synchrotron light made the process too costly for pro-
totyping or small-volume production, but recently commercial scanners have been made available at 
lower cost. Nowadays, the major problem related to LIGA is uniformity in the thickness of the electro-
plated metal layer (usually nickel, gold, or NiFe). Electroplating equipment from DVD industry has been 
adapted to the LIGA process, providing better uniformity at a lower cost.
LIGA is often employed where high precision is required for the fabrication of mechanical, optical, or 
fluidic devices, usually to be integrated in more complex systems.
References
	
1.	 R. P. Feynman, There’s plenty of room at the bottom, J. Microelectromech. Syst., 1 (1992), 60–66.
	
2.	 Status of the MEMS Industry, Yole Développement Lyon, France, 2003.
	
3.	 J. J. Allen, Micro Electro Mechanical Systems Design, CRC Press, Berlin, Germany, 2005.
	
4.	 S. D. Senturia, Microsystem Design, Springer Science, New York, 2001.
	
5.	 R. C. Jaeger, Introduction to microelectronic fabrication, in Modular Series on Solid State Devices, 
vol. 5, G. W. Neudeck and R. F. Pierret (Eds.), Addison-Wesley, Reading, MA, 1993.
	
6.	 K. F. Jensen, Chemical vapor deposition, in Microelectronics Processing: Chemical Engineering 
Aspects, D. W. Hess and K. F. Jensen (Eds.), American Chemical Society, Washington, DC, 1989, 
pp. 199–263.
	
7.	 K. E. Bean, Anisotropic etching of silicon, IEEE Trans. Electron Dev., 25 (1978), 185–1193.
	
8.	 M. Köhler, Etching in Microsystem Technology, Wiley-VCH, Weinheim, Germany, 1999.
	
9.	 J. M. Bustillo, R. T. Howe, and R. S. Muller, Surface micromachining for microelectromechanical 
systems, Proc. IEEE, 86 (1998), 1552–1574.
	 10.	 G. T. A. Kovacs, N. I. Maluf, and K. E. Petersen, Bulk micromachining of silicon, Proc. IEEE, 86 
(1998), 1536–1551.
	 11.	 K. R. Williams and R. S. Muller, Etch rates for micromachining processing, J. Microelectromech. 
Syst., 5 (1996), 256–269.
FIGURE 14.6  Bulk micromachining.
© 2011 by Taylor and Francis Group, LLC

14-16 
Fundamentals of Industrial Electronics
	 12.	 C. M. A. Ashruf, F. J. French, H. M. Sarro, M. Nagao, and M. Esashi, Fabrication of micromechanical 
structures with a new electrodeless electrochemical etch stop, in International Conference on Solid 
State Sensors and Actuators (Transducers ,97), June 16–19, 1997, Chicago, IL, pp. 703–706.
	 13.	 D. M. Manos and D. L. Flamm, Plasma Etching: An Introduction, Academic Press, San Diego, CA, 1989.
	 14.	 H. Jansen, H. Gardeniers, M. de Boer, M. Elwenspoek, and J. Fluitman, A survey on the reactive ion 
etching of silicon on microtechnology, J. Micromech. Microeng., 6 (1996), 14–28.
	 15.	 M. Esashi, M. Takanami, Y. Wakabayashi, and K. Minami, High-rate directional deep dry etching 
for bulk silicon micromachining, J. Micromech. Microeng., 5 (1995), 5–10.
	 16.	 A. B. Frazier, Recent applications of polyimide to micromachining technology, IEEE Trans. Ind. 
Electron., 42 (1995), 442–448.
	 17.	 J. R. Anderson, D. T. Chiu, R. J. J. O. Cherniavskaya, J. C. McDonald, H. Wu, S. H. Whitesides, and 
G. M. Whitesides, Fabrication of topologically complex three-dimensional microfluidic systems in 
PDMS by rapid prototyping, Anal. Chem., 72 (2000), 3158–3164.
	 18.	 W. Menz, LIGA and related technologies for industrial application, Sens. Actuators A (Phys.), 54 
(1996), 785–789.
	 19.	 B. Loechel, J. Goettert, and Y. M. Desta, Direct LIGA service for prototyping: Status report, Microsyst. 
Technol., 13 (2007), 327–334.
© 2011 by Taylor and Francis Group, LLC

15-1
15.1  Introduction
This chapter presents the main sectors where microelectromechanical systems (MEMS) devices are 
currently being applied. Those sectors include automotive, communications, aerospace, industrial, and 
energy, among others [1]. MEMS foundries target many of their products to one or more of these fields. 
It is also expected that the share of each of these sectors in the global MEMS market will change in the 
coming years, and an estimation on how this may happen is included at the end of chapter.
15.2  Industrial
The ability of MEMS to measure physical parameters makes them particularly attractive to implement 
monitoring and control functions. In manufacturing environments, MEMS integrated into feedback 
loop systems contribute to keep process variables within acceptable limits and play a critical role in 
industrial automation. The monitoring of temperature, pressure, position, vibration, humidity, gas con-
tent, presence/absence, angular rate, etc., opens many opportunities for the use of MEMS in industrial 
contexts. It is relatively frequent to observe the utilization of MEMS developed in a particular appli-
cation field (communication, consumer, automotive) in industrial systems, once the specific require-
ments of the application (reliability, performance, cost) are met. This phenomenon is illustrated by 
MEMS inertial sensors, such as linear accelerometers and angular gyroscopes, initially developed for 
15
Applications of MEMS
15.1	 Introduction.....................................................................................15-1
15.2	 Industrial...........................................................................................15-1
15.3	 Automotive.......................................................................................15-2
15.4	 Biomedical........................................................................................15-4
15.5	 Communications.............................................................................15-6
MEMS Replacement of Existing System Components  •  Antenna, 
Filters, and Matching Network Step-Tuning Examples in PWB 
MEMS  •  RF Switches  •  Meso-MEMS Phase Shifters  •  Switched 
Line Phase Shifters  •  Reflective Hybrid Coupler with Shunt 
Switches  •  Lower Loss Cantilever and Fine Grain Variable MEMS 
Phase Shifters
15.6	 Aerospace........................................................................................15-10
Aeroplane Applications  •  Space Applications  •  Coarse and Fine 
Sun Sensors  •  Shutter for Reflective Control  •  Microthrusters
15.7	 Power and Energy..........................................................................15-14
Photovoltaic  •  Vibration  •  Thermal  •  Electromagnetic  • 
Fuel Cells  •  Microbatteries
15.8	 Market Trends................................................................................15-16
Current Status  •  MEMS Market Forecast  •  Future Trends
References...................................................................................................15-19
Antonio Luque
University of Seville
José M. Quero
University of Seville
Robert Lempkowski
Motorola Applied Research 
and Technology Center
Francisco Ibáñez
European Commission
© 2011 by Taylor and Francis Group, LLC

15-2 
Fundamentals of Industrial Electronics
automotive that at a later stage find their way into industrial applications (motion control and aware-
ness). Reliable, compact, and low-cost MEMS components are gradually replacing traditional bulky and 
costly sensing approaches for industry.
Inkjet printers are a very relevant case of MEMS “application transfer.” Disposable cartridges for 
inkjet printers have been one of the early market successes of MEMS. The emerging field of printed 
electronics opens new high-value professional opportunities for the area. Major progress has been made 
in the use of MEMS for printing and the versatility, resolution, and throughput achieved are expanding 
the application range well beyond consumer printers.
MEMS accelerometers are increasingly used for vibration detection in industrial applications. They 
usually serve two types of situations: precision machinery requiring accurate positioning of their 
moving parts, and vibration analysis of manufacturing equipment to prevent and anticipate failures 
in the shop floor. Vibration MEMS sensors are a particular type of 3D accelerometers, which can 
operate as a stand-alone transducers or integrated with a data-capture system. The operating princi-
ple varies from piezoelectric, capacitive, resonant frequency to magnetic induction. Recent advances 
in MEMS technologies allow the measurement of vibrations with high precision over a broad range of 
frequencies. Of particular interest are MEMS seismic sensors, able to detect vibrations of less than a 
millionth of the earth’s gravitational acceleration and used within seismic data–acquisition systems 
for oil and gas exploration.
MEMS technologies are entering into industrial application providing higher levels of performance 
than alternative sensing techniques. Examples that illustrate this trend are gas/air ultrasonic sensors 
replacing piezoelectric devices. Miniaturized ultrasonic sensors can emit high-frequency ultrasound 
and thus operate at frequencies ranging from 200 kHz to 5 MHz (most piezoelectric devices are limited 
to 200 kHz operation). Like other types of MEMS sensors (pressure, accelerometers), ultrasonic sensors 
make use of a suspended membrane on a silicon substrate. The cavity structure allows both to emit 
ultrasound waves (a voltage applied to the membrane makes it vibrate at the desired frequency) and to 
detect them (the received ultrasound affects the output electrode, which makes the membrane vibrate, 
changing the capacitive characteristics of the sensor). MEMS sensors are used for the nondestructive 
inspection of materials and structures with the added advantage that no contact with the inspected 
material is required, providing high versatility in a manufacturing line. Gas/air MEMS sensors are 
also applied for high accuracy gas flowmeters. Finally, for liquid immersion applications, MEMS sen-
sors provide high-resolution industrial imaging (also relevant in the medical environment) and high-
resolution liquid level sensing.
Finally, the combination of MEMS and wireless communications under the WSN (wireless sen-
sor network) concept addresses industrial monitoring and control applications for real-time opera-
tion. Air and climate control make use of MEMS to measure the level of critical elements (carbon 
dioxide, ammonia) and parameters (temperature, light) and take corrective actions to maintain 
them under the required limits. The monitoring of buildings’ and large constructions’ “health” 
is implemented by measuring and analysis of vibrations at key points of the structure. In a longer 
term, intelligent building systems will be based on the deployment of a large amount of MEMS 
with the combined abilities to capture information, to communicate wirelessly and to operate from 
ambient energy.
Reliable MEMS packaging is critical for industrial applications (e.g., see Figure 15.1).
15.3  Automotive
The automotive industry was among the first to make extensive use of MEMS [2] and still nowadays 
airbag deployment systems are one of the largest applications for which MEMS accelerometers are com-
mercialized. Many MEMS foundries sell capacitive accelerometers specifically designed to detect large 
decelerations, and their output is used to ignite the explosive device that makes the airbag inflate. Main 
© 2011 by Taylor and Francis Group, LLC

Applications of MEMS 
15-3
suppliers of accelerometers for airbag control include Robert Bosch GmbH, Analog Devices, Freescale 
Semiconductors, and NXP Semiconductors.
But MEMS are also used in occupant-detection systems that make airbags deploy or not depending on 
whether a person is sitting in the appropriate place. Different sensor configurations are used for this mat-
ter, one of the most advanced being an array of hundreds of pressure sensors in the bottom of the seat that 
can detect if a person is seated and what is their position (this is especially useful for the case of small chil-
dren). Other systems include infrared detectors, or a single-pressure sensor that monitors the total weight.
Pressure, temperature, and mass-flow sensors are used in different parts of the engine to monitor 
parameters in the air or gas fed to the engine, or in the engine case itself. By making use of them, intel-
ligent injection systems that adapt to the current conditions can be implemented.
Electronic stability control systems try to avoid the vehicle from overturning, and, if unavoidable, 
to trigger the deployment of appropriate airbags and/or pretense seat belts. This is accomplished by the 
use of different sensors, which include accelerometers, gyroscopes, and pressure and speed sensors for 
tires. Figure 15.2 shows a rollover sensor based on a gyroscope manufactured by Robert Bosch GmbH.
MEMS
MEMS
MEMS substrate
Capping chip
Cavity
Bond and seal
layer
Sealing cap
Bond and seal
Solder bumps
Solder
preform
0-level packaged or
bare MEMS component
Sealing layer
BGA balls
LTCC substrate with
vertical and horizontal
interconnections
LTCC lid
Tin ﬁlm
cap
Via
MEMS
FIGURE 15.1  MEMS packaging for industrial applications (MEMSPACK project).
© 2011 by Taylor and Francis Group, LLC

15-4 
Fundamentals of Industrial Electronics
15.4  Biomedical
In biomedical applications, MEMS are the solution of choice for performing local analysis at a small 
scale. Disposable analyzers for personal use are starting to be used, thanks to the low cost obtained by 
batch fabrication [3].
The measurement of glucose, lactose, and other substances in the blood torrent was one of the first 
applications of miniaturized devices in medicine. Personal glucometers are nowadays readily available. 
Most of the sensors in the market use an electrochemical method to measure the glucose content. An elec-
trolyte where the glucose will be dissolved is located between two electrodes. When an electrical potential 
is applied between both electrodes, the current flow will be proportional to the concentration of glucose 
(or other species) in the electrolyte. In order for the electrical effect to happen, a catalytic enzyme must be 
present that oxidizes or reduces the analyte molecule. For glucose, the catalyst is usually glucose-oxidase.
Most glucose sensors work by extracting a sample from the 
human body, and then analyzing it using the amperometric 
method described above. The fluid sample can come from the 
blood torrent, or, more commonly, from the interstitial fluid, 
which is present between live cells. Microfabrication processes 
present the advantage of being capable of constructing needles of a 
size, which makes the extraction painless, as their size and length 
avoids touching the nerves.
More complex systems intended for diabetes patient monitoring 
also include an insulin pump, which delivers the needed insulin when 
the measured glucose levels exceed the safety threshold. The glucose 
monitoring is made continuously at short intervals. Commercial 
systems include OneTouch Ping from Animas Corporation (see 
Figure 15.3) and GlucoDay from Menarini, among others.
The final goal of building a lab-on-chip, or micro-total-analy-
sis-system (μTAS), a chip where all the processes of sample extrac-
tion, pretreatment, biochemical analysis, and perhaps electronic 
processing of the results take place at a reasonable cost, is becom-
ing closer, thanks to the low-cost microfabrication processes that 
allow the use of biocompatible materials to construct disposable 
components. Most of the research in this direction is based on the 
use of polydimethylsiloxane (PDMS) for the microfluidic part (see 
Figure 15.4).
FIGURE 15.2  Rollover sensor by Robert Bosch GmbH.
FIGURE 15.3  OneTouch Ping con-
tinuous glucose monitor and insu-
lin dispenser. (Courtesy of Animas 
Corporation.)
© 2011 by Taylor and Francis Group, LLC

Applications of MEMS 
15-5
Microsystems for controlled drug delivery are also being employed nowadays. Apart from the minia-
turized insulin pumps mentioned above, other systems exist. One of them is the smart pill [4], a capsule 
filled with drug whose surface is perforated with multiple holes. Each hole is sealed by a material that 
can be dissolved in a controlled way. Some of these smart pills include a wireless interface to trigger the 
release of drugs into the body.
In other cases, drugs are delivered through transdermal needles [5]. Methods of impulsion to the fluid 
that contains the drug can include pressurized chambers, microexplosive devices, peristaltic pumps, 
and thermally expandable materials. An image of microneedles for transdermal drug delivery can be 
seen in Figure 15.5.
Microfluidic
multiplexer
Micro-
dispenser
Air-bursting detonators
FIGURE 15.4  Microfluidic system built in PDMS with air-bursting detonators for fluidic movement. (Reproduced 
from Ahn, C.H. et al., Proc. IEEE, 92, 154, 2004. With permission.)
100 μm
FIGURE 15.5  Microneedles for transdermal drug delivery. (Reproduced from Henry, S. et al., Micromachined 
needles for the transdermal delivery of drugs, in Proceedings of the IEEE Eleventh Annual International 
Workshop on Micro Electro Mechanical Systems, Heidelberg, Germany, 1998, IEEE, Piscataway, NJ, pp. 494–498. 
With permission.)
© 2011 by Taylor and Francis Group, LLC

15-6 
Fundamentals of Industrial Electronics
15.5  Communications
MEMS devices in the communications area started out with a promise of becoming resonators, and 
though it took awhile, are shipping now in volume as replacements for crystals. Television created by 
light projector technology has been shipping in consumer quantity for quite some time. MEMS speak-
ers have found their way into cell phones as well. MEMS RF switches have had a number of companies 
developing products, but at this time are only found in military or test-equipment areas, and have not 
been able to reach the cost, size, or some other aspect that has limited its widespread application. RF 
MEMS switches have lower insertion loss, good return loss, and very high linearity (lack of harmonics 
due to non-semiconducting junctions) compared to competitors in complementary metal oxide semi-
conductor (CMOS) and GaAs. They have reasonable switching speed (microseconds) for many appli-
cations, and some can handle high RF power. On the other hand, most designs require higher supply 
voltages than what is available for handheld devices, and must use converters for their control, though 
some have been built to function well on available batteries. Here are examples of the communications 
application of MEMS devices that should become commonplace in the coming years.
15.5.1  MEMS Replacement of Existing System Components
With the cell phone being one of the highest-volume consumer products, MEMS have more than 
one location in the RF hardware where they can provide a suitable alternative. From the antenna, 
one SP2T switch is a possible alternative, where its low insertion loss and linearity make it attrac-
tive. Since one or more bands of service require frequent and high-speed switching, most MEMS 
switches today either cannot meet the switching speed, lifetime reliability of 1012 switching cycles, 
or RF power handling during switching. The other applications are very well suited for today’s RF 
MEMS switch, a multi-throw switch in the receiver and transmit chain, and a two-throw switch 
monitoring transmit power. Other transceiver applications are very similar when it comes to band 
switching with low loss.
The second application is cable TV function, whereby multi-throw MEMS switches select a cascade 
of high-pass and low-pass filters, each with differing cutoff frequencies separated through multiple 
octaves of frequency operation. In this application, the desired channel is amplified through a broad-
band amplifier, with the high-pass filter selected and lower frequencies rejected. The second amplifier 
increases the signal and its harmonic, which is selected to reject the harmonic and pass the desired 
signal. This construction also can create a number of passbands of different widths, depending on the 
cutoff frequencies chosen.
15.5.2  Antenna, Filters, and Matching Network 
Step- Tuning Examples in PWB MEMS
Printed Wiring Board (PWB)-based MEMS RF switches were developed using modified processes and 
similar materials as used for high-density interconnect/embedded passives (HDI/EP) components. By 
constructing cantilever-beam electrostatic mechanisms, single-pole single throw through single-pole 
four-throw RF switches were developed with suitable performance in the microwave band (Table 15.1). 
Combining these switches with embedded lumped element filter components using the same substrate 
materials, a switched filter bank was simulated, fabricated, and measured results shown.
Typical PWB-based MEMS performance is shown in Table 15.1 for a single switch and multi-throw 
versions. Additional losses and frequency roll-offs occur due to the line length from the RF input transi-
tion (shown in Figure 15.6) to the individual switch throws, acting as distributed inductance and capaci-
tance. Since the same materials and processes are as used for the MEMS device as in PWB manufacture, 
construction can also be made on the core, with the outer layer of resin acting as the cover for the switch 
(as depicted in Figure 15.7).
© 2011 by Taylor and Francis Group, LLC

Applications of MEMS 
15-7
A switch/filter bank has been fabricated with individual packaged and tested switches on a substrate, 
which contained lumped-element LC filters, as shown in Figure 15.8. After the tests, the package covers 
were removed to show this early design version.
Similarly, a tunable antenna was demonstrated that used an SP3T switch in a cell phone form factor. 
A tuning element was added to a PIFA antenna, and the construction according to the scheme shown in 
Figure 15.9a. The prototype consisted of batteries, a DC-DC converter, control circuits, and the antenna 
Packaging build-up layers
Switch throw
RF input transition
from cpw on back
RF output transitions
Line length
FIGURE 15.6  SP3T MEMS switch on printed wiring board with RF in/out through vias to bottom of package.
TABLE 15.1  PWB-Based MEMS Performance
SPST
SP4T
Insertion loss
0.1 dB (2 GHz), 0.3 dB (10 GHz)
0.2 dB (1 GHz), 0.6 dB (2 GHz)
Isolation
>35 dB (2 GHz)
>35 dB (2 GHz)
RF Power handling
5 W (hot switching)
5 W (hot switching)
Speed
<50 μS ON and OFF
<50 μS ON and OFF
Actuation voltage
40–100 VDC
40–100 VDC
Life cycles
>1 × 107
>1 × 107
Operation frequency
<10 GHz
<6 GHz
Plated
thru hold
(core)
Buried
distributed
ﬁlter
Plated thru hole
Reﬂow pad I/O
Embedded
resistors
Embedded
inductors
Embedded
capacitors
Ground
plane
MEMS
switch
FIGURE 15.7  MEMS and embedded passives integration.
© 2011 by Taylor and Francis Group, LLC

15-8 
Fundamentals of Industrial Electronics
and ground plane, as in Figure 15.9b. The dual in-line package (DIP) switch controlled the switches indi-
vidually, allowing single or multiple shunt elements to be selected at any given time. Shunt capacitors 
were selected that provided a good match at three cell phone frequencies of interest. In addition, these 
capacitors were swapped out to determine the potential frequencies that this antenna could possibly be 
tuned to beyond the normal cell phone bands.
15.5.3  RF Switches
The PWB MEMS SPST (single-pole, single throw) RF switch uses an electrostatically controlled physical 
structure with a polymer isolation member separating an RF contact that connects the signal path. Multi-
throw switches use the same common switch structure, but have RF transmission line structures dividing the 
input signal to SP2T, SP3T, and SP4T switches [6], typically microstrip lines and coplanar waveguide lines.
Top side
Bottom side
Filters
2, 3, and 4
SP3T
MEMS
switches
FIGURE 15.8  Module of two MEMS SP3T switches and embedded passives filters.
RF input
PIFA with
tuning element
SP3T MEMS
switch
DC–DC
converter
(a)
(b)
Battery
DIP switch
select 
FIGURE 15.9  MEMS switching the same PIFA antenna structure with different shunt components. (a) Front of 
board showing PIFA and (b) back of board showing MEMS and other components.
© 2011 by Taylor and Francis Group, LLC

Applications of MEMS 
15-9
The polymer beam extending from the electrostatic actuator top is also stiffened with copper rigidizers, 
as part of the fabrication process [7].
15.5.4  Meso-MEMS Phase Shifters
Several types of discrete phase shifters are amenable to the topology used in fabricating MEMS struc-
tures in PWB technology. Some of the components have been already been developed with suitable 
performance through X-band, with the remaining portions requiring steps to smaller process rules for 
operation in the higher frequency bands.
The first type is a switched-line approach, relying on SPMT switch designs. The second type is a hybrid 
reflective phase shifter, which historically was a phase modulator with shunt p-i-n diodes to ground. That 
version has two forms, one that relies on SPMT switches, and the other that only needs SPST ones. Lastly, 
instead of stepped-switch phase shifters with large phase steps, a fine-grain phase shifter is described.
15.5.5  Switched Line Phase Shifters
The most straightforward phase shifter is one that uses back-to-back SPMT switches, with phase shift 
accomplished via switching in different line lengths corresponding to the desired phase step. This archi-
tecture is limited by high frequency performance of the switches. For a four-state switch, SP4T perfor-
mance for designs on common substrates would have about 2 dB loss at 8 GHz. This would provide a 
phase shifter with about 5–7 dB loss from 10 to 60 GHz. Alternatively, by using four SP2T switches, each 
with about 1 dB loss, that construction could yield less losses over the same range since they provide 
better high-frequency performance due to less parasitic stubs for switches in the open state. It remains 
to be seen whether the design shrink that is recommended to obtain higher frequency performance will 
improve the SP4T switches more than using multiple lower throw versions. Both architectures are 
recommended to determine the trade-offs in loss/frequency performance (see Figure 15.10).
15.5.6  Reflective Hybrid Coupler with Shunt Switches
A common method to provide phase shifting is to have a 90° hybrid coupler with the shunt arms provid-
ing differing phase shifts (Figure 15.11). In semiconductor technology, the coupler is typically a Lange 
180°
180°
0°
0°
0°
SP4T
SP4T
SPDT
SPDT
SPDT
SPDT
SPDT
SPDT
SPDT
SPDT
90°
90°
270°
FIGURE 15.10  Switched-line phase shifters.
0°
0°
90°
90°
180°
180°
270°
270°
SP4T
SP4T
FIGURE 15.11  Branchline hybrid coupler shown with shunt switched-line phase shifters (can substitute reactive 
elements).
© 2011 by Taylor and Francis Group, LLC

15-10 
Fundamentals of Industrial Electronics
coupler due to its small area, and wire bonding a part of the pro-
cesses. In PWB technology, since the switches are formed on the 
top metal layer, the input coupler is better suited to be a branchline 
hybrid type. SPMT switches are used for the shunt arms, and the 
desired electrical line lengths from each throw are terminated with 
a via to the ground on the backside. Once again, this structure relies 
on high-frequency performance of SPMT switches for the desired 
number of bits.
An alternative configuration is also available (Figure 15.12), which 
relies only on SPST switches in a cascade arrangement from the 
hybrid’s shunt arms. This configuration relies on the lowest losses 
possible, since the reflection mechanism of the open stub is utilized. 
As each low-loss switch is closed, the line lengths are made electri-
cally longer. At first glance, this approach might be expected to per-
form better at higher frequencies due to using single-throw switches. 
The trade-off here is in how well the open-circuit stubs provide a 
strong reflection considering the fringing of the open stubs and cou-
pling to adjacent structures. This would also be a trade-off in PWB 
thickness and could be addressed by simulation.
15.5.7  Lower Loss Cantilever and Fine Grain 
Variable MEMS Phase Shifters
The existing meso-MEMS switch design is a dual cantilever beam structure with the electrostatic capaci-
tor having a secondary RF-isolated beam to bridge a gap across the signal trace. The bottom side of the RF 
beam has a copper contact to perform this function, and is supported by a dielectric material.
The cantilever structure can be modified similar to the bridge designs, having the signal trace complete 
and the cantilever acting as a reflective shorting bar. Since the RF beam consists of a dielectric sandwiched 
between two copper layers, if the bottom copper layer that makes the contact is removed, a dielectric layer 
is applied to the signal trace, providing phase shift proportional to the width of the RF beam.
15.6  Aerospace
MEMS technology is having a significant influence on airspace systems design. The reason for this impact is 
the drastic reduction in size, mass, power, and cost of individual sensors and actuators used in air and space-
crafts. In space applications, this reduction also affects the launch cost of space systems. But there are some 
differences when using MEMS devices in aerospace with respect to other fields like industry. First, aerospace 
specificity demands a strict certification of new components, requiring a sourcing of 20 or 30 years with a 
rather small production. Second, the MEMS performances should remain stable for its life duration in order 
to avoid costly periodic ratings. And third, due to safety reasons, the reliability needs to be very high.
15.6.1  Aeroplane Applications
In aircrafts, the most relevant MEMS devices that can be found are inertial sensors (gyros and accel-
erometers) that combine data from digital magnetometers and GPS in the attitude heading reference 
system (AHRS). As the specific technical requirements are not so exigent for these applications, it is 
possible to import these sensors from the automotive market [8] and thus saving manufacturing costs. 
Another, more sophisticated application is the reduction of fuel consumption in airplanes. Air does not 
usually glide smoothly around a wing and fuselage; on the contrary, bubbles and roils create a turbu-
lence regime causing friction. To solve this problem, MEMS devices have already been used to cut skin 
SPST
SPST
SPST
SPST
SPST
SPST
OpeI
OpeI
φ1
φ1
φ2
φ2
φ2
φ2
φ2
φ2
FIGURE 15.12  Branchline hybrid 
coupler with open-stub switched-
line phase shifters. (From Osiander, 
R. et al., IEEE Sens. J., 4, 525, 2004. 
With permission.)
© 2011 by Taylor and Francis Group, LLC

Applications of MEMS 
15-11
drag by 5%–6% on an F-15 fighter, simply modifying the air flow on the surfaces. Another application 
field where MEMS are finding a niche is unmanned aerial vehicles (UAV), where the combination of 
the information generated by commercial off-the-shelf (COTS) MEMS sensors with Kalman filters for 
the attitude determination is being quite fruitful for the estimation of the state of the continuous-time 
model of the airplane [9].
15.6.2  Space Applications
It is in space applications where MEMS technology is currently being massively applied because they 
quite fit the satellite concept. But in this environment, MEMS devices have to operate under very severe 
conditions such as vacuum, vibrations, shocks, temperature gradients, EMC, etc. Having in mind these 
difficulties, NASA [10] edited some guidelines in order to facilitate the insertion of this technology into 
high-reliability applications. In this report, some specific problems in this field are identified, and they 
are summarized in Table 15.2.
ESA has shown a lot of concern on this technology and it is also interested in MEMS applications at 
space. In this context, it has started the NEOMEx (near earth object micro explorer) mission, which will 
provide a focus application for a microsystem-based spacecraft concept.
In the following paragraphs, some examples of MEMS applications in space are presented. They are 
not intended to be an exhaustive description of the state-of-the-art applications. Many other realiza-
tions, like those in communications (like micro-machined filters for RF) or attitude control (like gyros, 
accelerometers or micro-wheels), are not included due to their similarity with other application fields.
15.6.3  Coarse and Fine Sun Sensors
Solar sensors are used in space for satellite attitude determination. They determine the incident angle 
of the sun light, thus providing a reference for the position of the satellite. This information is normally 
complemented with a magnetometer that provides information about the relative position with respect 
to the earth’s magnetic field. An example of a sun sensor manufactured using MEMS technique, which 
has been used in NANOSAT 1B, is shown in Figure 15.13. This device has been successfully used [11] 
for the positioning of heliostats in solar power plants and its concept has been adapted for aerospace 
applications. It consists of a wafer with two photodiodes covered by a cover glass with a metal layer on 
top. The cover glass acts as a shield for the high energy particle radiation. The metal layer is patterned 
using lift-off to create an input window. These two wafers are glue-bonded using an optical epoxy resin 
qualified for space applications.
TABLE 15.2  NASA Classification of MEMS Failure Mechanisms
Mechanical Failure
Environmentally Induced Failure
• Stress-induced failure
• Vibration
• Point defects
• Shock
• Dislocations
• Humidity effects
• Precipitates
• Radiation effects
• Fracture strength
• Particulates
• Fatigue
• Temperature changes
• Electrostatic discharge
Stiction
Stray stresses
Wear
Parasitic capacitance
Delamination
Dampening effects
Source:  Courtesy of NASA/JPL-Caltech; Stark, B., MEMS Reliability 
Assurance Guidelines for Space Applications, JPL Publication 99-1, Jet 
Propulsion Laboratory, Pasadena, CA, 1999.
© 2011 by Taylor and Francis Group, LLC

15-12 
Fundamentals of Industrial Electronics
The incident light generates a photocurrent in each photodiode, being its value proportional to the 
normal irradiance and the photodiode illuminated area. Angle θ can be determined by means of the 
quotient of the difference and the sum of photocurrents:
	
I
I
I
I
H
L
G
f
f
f
f
1
2
1
2
2
−
+
=
⋅
=
⋅
tan( )
tan( ),
θ
θ
	
(15.1)
where
H is the weight of the cover glass
L is the length of the photodiode
It is remarkable that G can be regarded as a geometrical gain defined as 2H/L. So, the sensitivity of the 
device can be constructively modified by changing the weight of the glass. In Figure 15.14, there is a 
photograph of the sensor mounted on a PCB with auxiliary electronics and the final aluminum package 
for its installation.
15.6.4  Shutter for Reflective Control
The temperature stabilization of a satellite is crucial to guarantee its correct operation. For this reason, 
a balance between the incident radiation and the emitted radiation in the satellite surface should be 
(a)
(b)
FIGURE 15.14 
Example of a satellite sun sensor that has been used in satellite Nanosat 1B. (a) Sensor with 
auxiliary electronics and (b) encapsulated sensor.
Metal shield
Cover glass
Silicon wafer
θ
L
H
FIGURE 15.13  Cross section of a sun sensor manufactured using MEMS techniques. (From Zhang, K. et al., 
J. Microelectromech. Syst., 13, 165, 2004. With permission.)
© 2011 by Taylor and Francis Group, LLC

Applications of MEMS 
15-13
achieved. A MEMS device that works as a satellite skin that can vary its emissivity has been designed 
[12]. It consist of arrays of gold-coated sliding shutters (see Figure 15.15) manufactured via surface 
micromachining. The first generation of this active thermal management system will be demonstrated 
on NASA’s New Millennium Program ST-5 spacecraft.
15.6.5  Microthrusters
A micropropulsion system will be required in microspacecrafts for attitude control. A correct position-
ing is required to guarantee station keeping, gravitation compensation, and orbit adjust.
The schematic view of a solid propellant microthruster [13] is depicted in Figure 15.16. Its configu-
ration has no movable parts, like pumps, fuel lines, or valves to avoid leakage. In the design, a silicon 
layer is wet etched to fabricate the combustion chamber, a convergent-divergent nozzle, and an igni-
tion slot. A specific glass wafer is bonded on top of the silicon layer to form a closed structure. The 
chamber is then loaded with the solid propellant. Once ignited, the resultant gas expands producing 
the desired impulse.
(a)
Shutter
frame
Shutter
IR transparent
material
High-ε material 
Low-emissivity state
High-emissivity state
Shutters
Gold substrate
150 μm
(b)
3 μm
FIGURE 15.15  (a) Shutter concept for emissivity control in satellite. (b) High-resolution optical microscope 
image of the motors and shutters. (Reproduced from Osiander, R. et al., IEEE Sens. J., 4, 525, 2004.)
© 2011 by Taylor and Francis Group, LLC

15-14 
Fundamentals of Industrial Electronics
15.7  Power and Energy
MEMS technologies are allowing for an increase in the scale of integration of complex systems, includ-
ing not only sensing and actuation, but also control and communication. Nowadays, there is a tendency 
to develop the concept of “ambient intelligence,” where a network of sensors and actuators hidden in our 
surroundings will provide ubiquitous and valuable information, computing, and support to end users. 
But this concept demands the inclusion in microsystems of an energy source to became autonomous 
and guarantee its functionality for years. There are two possible solutions to supply power to these 
miniaturized systems: the use of a chemical power source or converting different forms of nonelectrical 
energy into electrical energy. In the next paragraphs, a review of the most important energy-scavenging 
alternatives is presented.
15.7.1  Photovoltaic
The most successful example of such energy-scavenging devices is solar cells. These devices takes 
advantage of MEMS processes as their surfaces are anisotropically etched to create a pyramidal shape 
Ignition slot
Wire
(a)
Pyrex-glass
Silicon
Propellant
Ejected plume
Fixed plate
Movable cover
(b)
Microthruster
FIGURE 15.16  (a) Schematic of a microthruster. (b) Microthruster firing. Images are acquired at 500 frames/s. 
(Reproduced from Zhang, K. et al., J. Microelectromech. Syst., 13, 165, 2004.)
© 2011 by Taylor and Francis Group, LLC

Applications of MEMS 
15-15
that increases light absorption, reducing its reflectivity. But there are a large number of applications 
where devices receive very limited or null radiation energy. In these cases, new types of scavengers 
are needed.
15.7.2  Vibration
One potential power source is the vibration of objects. For example, buildings suffer from very small 
amplitude vibration generated by air-conditioned systems or large machinery movement; human beings 
also provide a natural source of movement. In these cases, a MEMS device may include a suspended 
mass that vibrates and a piezoelectric, electromagnetic, or electrostatic generator would generate several 
microwatts [14]. The main drawback within this approach is that the generated power scales with mass. 
For this reason, numerous vibration-based generators have been reported in literature, but none of them 
have yet been commercialized in high-volume applications.
15.7.3  Thermal
There are many heat sources that maintain a difference of temperature with its environment. For 
instance, a lighting or an air-conditioning system, or even a human body [15], provides a temperature 
jump respect to its surroundings. The physical principle commonly used to convert heat into electric 
power is the Seebeck effect, which occurs when you form a circuit with two semiconductor junctions. In 
the presence of a temperature difference between the junctions, a small current flows around the circuit. 
The reverse phenomenon is called Peltier effect. Based on this principle, it is possible to fabricate ther-
moelectric generators capable of producing electric energy using MEMS technologies. But these energy 
scavengers suffer from the variation of the external environmental conditions and thus additional energy 
storage is required.
15.7.4  Electromagnetic
Another potential power source is the electromagnetic induction, a physical principle that generates 
voltage in a conductor by changing the magnetic field around it. Low frequency electromagnetic fields 
generated by power distribution lines are good candidates to provide energy remotely. However, the 
energy density is not sufficient for portable applications; also, the necessary antenna that is needed to 
obtain sufficient radiation would be too large to be used in real applications.
On the contrary, high-frequency electromagnetic fields, radio frequency transmission, for example, have 
been proved to be very appropriate to transfer energy in short range. That is the case of RFID tags, whose 
antenna receives sufficient energy to power up a sensor or microcontroller, including a radio communica-
tion interface. The main inconvenience of this energy exchange is that the irradiated energy decreases with 
the square of the distance between antennas, making this solution valid only in short distances.
Finally, it is worth mentioning that another effective way of producing electric energy is harvesting 
energy with the help of external permanent magnets and a resonating structure in the form of a canti-
lever or a membrane that contains a coil.
15.7.5  Fuel Cells
There exists a large variety of fuel cells that generate electricity from the chemical oxidation of hydro-
gen, producing water. Proton-exchange-membrane fuel cell (PEMFC) is one of the most successful alter-
natives, where a special membrane permeable to protons separates two volumes filled with H2 and O2, 
respectively. For this reason, electrons from ionized hydrogen atoms should flow through an external 
electrical circuit while their protons can go through the membrane to combine with oxygen molecules. 
The miniaturization of PEMFC is quite feasible, as the room temperature operation facilitates the simpli-
fication or even elimination of a cooling system. Basically, a MEMS PEMFC [16] consists of a sandwich of 
© 2011 by Taylor and Francis Group, LLC

15-16 
Fundamentals of Industrial Electronics
two electrodes with a membrane electrode assembly (MEA) in between. This MEA includes a thin plastic 
film permeable to hydrogen ions and two diffusion layers made out of carbon paper. In MEMS technolo-
gies, these electrodes are fabricated with a silicon wafer that is etched to create channels and thus facilitate 
the flow of chemical species. Usually, these cells only precise hydrogen as fuel, as self-breathing structures 
directly acquire oxygen from air.
But storing hydrogen as compressed gas or liquid presents significant explosion hazards. Nowadays, 
there is a clear tendency to use a reactor to extract hydrogen from a liquid hydrocarbon such as 
methanol. An example of such reactor implemented using MEMS technologies can be found in [17].
An interesting alternative to conventional fuel cells are photosynthetic electrochemical ones, which 
directly harnesses subcellular photosystems [18] isolated from plant cells to perform bioconversion of 
light energy into electricity.
15.7.6  Microbatteries
Finally, we should not forget microbatteries, and especially rechargeable ones, because they are based 
on a proven chemical technology for energy storage that will store the energy obtained by the aforemen-
tioned scavengers.
As a summary, a comparison of power density of different power sources and energy scavengers [19] 
is presented in Table 15.3.
15.8  Market Trends
15.8.1  Current Status
For MEMS—like for any other technological domain—the degree of current vitality and future poten-
tial is measured to a large extent by the market value generated and the market value projected. In 2007, 
the estimated size of the MEMS market was $7 billion. The supply chain of MEMS involves equipment 
and material suppliers, device manufacturers and OEM system integrators, and the $7 billion figure 
relates exclusively to the device-manufacturing part (packaged MEMS) of the value chain.
The main applications driving current market include pressure sensors, RF-MEMS, microdisplays, 
and inkjet cartridges.
TABLE 15.3  Comparison of Power Sources and Energy Scavengers
Power Density (μW/cm2)
1 Year Lifetime
10 Year Lifetime
Energy scavenging
Solar (outdoor)
15,000-direct sun
15,000-direct sun
150-cloudy day
150-cloudy day
Solar (indoor)
6
6
Vibration
100–200
100–200
Acoustic noise
0.003@75 dB
0.003@75 dB
Daily temperature
10
10
Temperature gradient
15@10°C gradient
15@10°C gradient
Power sources
Batteries (lithium)
89
7
Combustion (μ-engine)
403
40.3
Fuel cells (methanol)
560
56
Nuclear source
850,000 (8% efficiency)
850,000 (8% efficiency)
© 2011 by Taylor and Francis Group, LLC

Applications of MEMS 
15-17
The MEMS market is well consolidated as it is proven by the high interest with which large semi-
conductor manufacturers try to capture a part of it. Unlike other markets, the regional distribution of 
MEMS manufacturing is well balanced across the world. Among the leading suppliers, there are com-
panies headquartered in United States (Hewlett-Packard, Texas Instruments, Freescale), Europe (Bosch, 
STMicroelectronics), and Asia (Seiko, Canon).
15.8.2  MEMS Market Forecast
The MEMS market is expected to grow from the $7 billion in 2007 to $15 billion in 2012 [20]. This sub-
stantial growth would come from new market applications and from the extended market success of 
products requiring large-scale manufacturing of MEMS (see Figure 15.17).
In this 5 year period, motion sensing for electronics, silicon microphones, and biochips for diagnos-
tic and drug delivery will be within the fast-growing MEMS applications. RF-MEMS will be produced 
in very large quantities for wireless systems, once the perennial issues of reliability and packaging have 
found suitable solutions. RF switches for handsets is the application that will generate the largest part of 
the revenues.
There are MEMS applications under development for which the market acceptance is still uncertain but 
with a very high volume potential that can materialize in the coming years, for instance, the integration of 
micromirrors and light engines for microprojection in mobile electronics. Texas Instruments has domi-
nated this segment of MEMS with the DMD (digital micromirror device) technology, but new companies 
are emerging with alternative approaches, some (Microvision, Miradia) integrate micro/pico projectors 
in handheld/portable devices, others (Nippon Signal) develop stand-alone miniprojectors that fit in your 
pocket. MEMS-based displays for portable devices is another innovative approach to visualization.
15.8.3  Future Trends
A trend already perceived in 2007 is the increasing share of the consumer sector in the total MEMS 
market. Particularly important is the MEMS contribution to new functionalities in video games, 
MEMS market forecast 2007–2012 in volume (units)
9000
8000
7000
6000
5000
4000
3000
2000
1000
0
2004 2005 2006 2007
Million units
2008 2009 2010 2011 2012
Emerging MEMS
Micro fuel cells
Micro tips & probes
RF MEMS
Microﬂuidics for durg
delivery
Microﬂuidics for research
Microﬂuidics for 
diagnostics
Microdisplays
Microbolometers
MOEMS (ﬁberoptics
telco, μspectrometers)
Gyroscopes
FIGURE 15.17  MEMS market forecast for 2007–2012. (Reproduced from Status of the MEMS Industry, 2008 edi-
tion, Yole Développement, October 2008. With permission.)
© 2011 by Taylor and Francis Group, LLC

15-18 
Fundamentals of Industrial Electronics
mobile electronics, lifestyle, and sport applications. This is reflected in the strong growth of MEMS in 
these areas [20].
Major manufacturers of game consoles (Nintendo, Sony) have introduced in their latest product gen-
eration inertial sensors for motion sensing, providing a new experience to users from sport simulation to 
dance training. New game systems include one or more 3D accelerometers to register changes in direction, 
speed, and acceleration. The popular Nintendo Wii includes an accelerometer from STMicroelectronics 
(LIS3L02AL, Figure 15.18) and one from Analog Devices (ADXL330). They are very compact devices 
featuring low-power operation and high sensitivity and linearity.
Modern laptops and high-end mobile phones include hard disk drive (HDD) protection feature. 
Accelerometers can detect a drop and “park” the HDD head to avoid data loss. Smart telephones, such 
as the iPhone, integrate MEMS motion sensors for free-fall detection, plus additional motion-activated 
functions and gaming input. Image rotation and stabilization are implemented in digital still cameras 
and camcorders with MEMS accelerometers.
The combination of high product-added value (actual and perceived) and large volume manufac-
turing makes these applications extremely attractive for MEMS suppliers. Reduced cost to enter the 
consumer market has been, to a large extent, achieved through the use of larger wafer size (200 mm). 
More effort in the direction of cost reduction has to be made for MEMS to expand further in this mar-
ket segment. The growth of MEMS for consumer sector in the coming years will strongly contribute to 
the total MEMS market. It is estimated that by 2012, the consumer share will exceed 40% of the MEMS 
market value.
In a more modest way, applications of MEMS in life science and wireless communication will also 
contribute to the market growth in the next 5 years. The measurement of biological parameters creates 
many opportunities for medical diagnostic and patient monitoring but also to help individuals to conduct 
a healthier lifestyle (physical activity, nutrition). We will see in the coming years a substantial increase of 
MEMS-based smart devices to follow-up sport practice.
In MEMS manufacturing, a relevant trend is the increasing role of foundries. The share of foundry 
MEMS fabrication is expected to increase at an annual rate of 30%. MEMS companies created in the 
past years do not own a manufacturing line (fabless) or have an engineering line exclusively for process 
and product development (fablight), and both models need to outsource volume fabrication to found-
ries. These new business models (foundries and fables/fablight) will cover a substantial part of the future 
MEMS market. It is expected that out of the $18 billion market predicted for 2015, over $2 billion will be 
originated in foundries.
FIGURE 15.18  3D accelerometers from STMicroelectronics.
© 2011 by Taylor and Francis Group, LLC

Applications of MEMS 
15-19
References
	
1.	 Microsystems Project Portfolio 2007–2010. Seventh Research and Development Framework 
Programme 2007–2013, June 2010. Directorate-General Information Society and Media. Directorate 
“Components and Systems”. Unit Microsystems. http://cordis.europa.eu/fp7/ict/micro-nanosys-
tems/docs/microsystems-project-portfolio-21-06-2010.pdf.
	
2.	 D. S. Eddy and D. R. Sparks, Application of MEMS technology in automotive sensors and actuators, 
Proceedings of the IEEE, 86 (1998), 1747–1755; S. S. Saliterman, BioMEMS and Medical Microdevices, 
Bellingham, WA: The International Society for Optical Engineering, 2006.
	
3.	 C. H. Ahn, J.-W. Choi, G. Beaucage, J. H. Nevin, J.-B. Lee, A. Puntambekar, and J. Y. Lee, Disposable 
smart lab on a chip for point-of-care clinical diagnostics, Proceedings of the IEEE, 92 (2004), 154–173.
	
4.	 H.-K. A. Tsai, J. Zoval, and M. Madou, Bi-layer artificial muscle valves for drug delivery devices, in 
Device Research Conference Digest (DRC ‘05), Vol. 1, Santa Barbara, CA, June 22, 2005, pp. 129–130.
	
5.	 S. Henry, D. V. McAllister, M. G. Allen, and M. R. Prausnitz, Micromachined needles for the trans-
dermal delivery of drugs, in Proceedings of the IEEE Eleventh Annual International Workshop on 
Micro Electro Mechanical Systems, Heidelberg, Germany, 1998, Piscataway, NJ: IEEE, pp. 494–498.
	
6.	 R. Lempkowski, K. Lian, M. Eliacin, and P. Kulkarni, A PWB-based MEMS switched filter bank 
using lumped element embedded passives, in IEEE IECON05, Raleigh, NC, November 6–10, 2005.
	
7.	 R. Ramadoss, S. Lee, K. C. Gupta, Y. C. Lee, and V. M. Bright, RF MEMS capacitive switches for inte-
gration with printed circuits and antennas, in IEEE Antennas and Propagation Symposium Digest, 
Vol. 1, Columbus, OH, June 22–27, 2003, pp. 395–398.
	
8.	 L. Sherry, C. Brown, B. Motazed, and D. Vos, Automotive-grade MEMS sensors used for general 
aviation, Aerospace and Electronic Systems Magazine, IEEE, 16 (2004), 13–16.
	
9.	 J. Jang, and D. Liccardo, Small UAV automation using MEMS, Aerospace and Electronic Systems 
Magazine, IEEE, 22 (2007), 30–34.
	 10.	 B. Stark, MEMS Reliability Assurance Guidelines for Space Applications. JPL Publication 99-1, 
Pasadena, CA: Jet Propulsion Laboratory, 1999.
	 11.	 J. Quero, C. Aracil, L. Franquelo, J. Ricart, P. Ortega, M. Dominguez et al. Tracking control sys-
tem using an incident radiation angle microsensor, IEEE Transactions on Industrial Electronics, 54 
(2007), 1207–1216.
	 12.	 R. Osiander, S. Firebaugh, J. Champion, and D. A. Farrar, Microelectromechanical devices for satel-
lite thermal control, IEEE Sensors Journal, 4 (2004), 525–531.
	 13.	 K. Zhang, S. Chou, and S. Ang, MEMS-based solid propellant microthruster design, simulation, 
fabrication, and testing, Journal of Microelectromechanical Systems, 13 (2004), 165–175.
	 14.	 P. Mitcheson, E. Yeatman, G. Rao, A. Holmes, and T. Green, Energy harvesting from human and 
machine motion for wireless electronic devices, Proceedings of the IEEE, 96 (2008), 1457–1486.
	 15.	 V. Leonov, P. Fiorini, S. Sedky, T. Torfs, and C. Van Hoof, Thermoelectric MEMS generators as a power 
supply for a body area network, in Digest of Technical Papers of the 13th International Conference on 
Solid-State Sensors, Actuators and Microsystems, Vol. 1, Seoul, South Korea, 2005, pp. 291–294.
	 16.	 X. L. Cong Chen, A self-breathing proton-exchange-membrane fuel-cell pack with optimal design 
and microfabrication, Journal of Micromechanical Systems, 15 (2006), 1088–1097.
	 17.	 A. Pattekar and M. Kothare, A microreactor for hydrogen production in micro fuel cell applications, 
Journal of Microelectromechanical Systems, 13 (2004), 7–18.
	 18.	 K. Lam, E. Johnson, M. Chiao, and L. Lin, A MEMS photosynthetic electrochemical cell powered by 
subcellular plant photosystem, Journal of Microelectromechanical Systems, 15 (2006), 1243–1250.
	 19.	 H. Kulah and K. Najafi, Energy scavenging from low-frequency vibrations by using frequency 
up-conversion for wireless sensor applications, IEEE Sensors Journal, 8 (2008), 261–268.
	 20.	 Yole Développement, Status of the MEMS industry, 2008 edition. Yole Développement, Lyon, 
France, October 2008.
© 2011 by Taylor and Francis Group, LLC

16-1
16.1  Large- Signal Models: Use of a Transistor as a Switch
The transistor characteristic equations presented in Chapter 4 constitute the transistors’ “large-signal 
modeling,” which includes all modes of operation and a current–voltage relationship for any input. 
These equations must be used when operating the transistor as a switch [3]. When the transistor is oper-
ating as an amplifier, only small input signals are used, which are amplified to large output signals. In 
this case, simpler linear models can be used for the transistor.
When a transistor operates as a switch, the input changes from a high voltage to a low voltage and 
back, which causes the output to move from a low voltage to a high voltage and back. When the output 
moves between a high and low voltage, the transistor changes regions of operation, from saturation to 
linear, or active to saturation, depending on whether it is a FET or BJT [3]. Therefore, to model the device 
in this operation, or design a device for this operation, the large-signal characteristic equations must be 
considered.
16.2  BJTs as Switches
16.2.1  Basic Switch Using an npn
An example of an npn used as a switch is shown in Figure 16.1 [3]. When VIN is at a low voltage (less 
than VBE), the transistor produces very little current (see Figure 16.1a). With very little current running 
through RC, there is very little voltage drop across RC and VO is approximately at VCC. This operation 
requires that VIN be less than VBE in order to turn the transistor off and allow a high output voltage. As 
a consequence, some consideration should be given to the largest value of VIN that is considered a “low 
value” and the “turn-on” voltage of the BJT. The low value for VIN should be less than 0.5 V to guarantee 
that the transistor produces very little current in the “off” state.
16
Transistors in 
Switching Circuits
16.1	 Large-Signal Models: Use of a Transistor as a Switch................16-1
16.2	 BJTs as Switches...............................................................................16-1
Basic Switch Using an npn  •  Switch Circuit with a Resistive 
Load  •  Switch Driving an LED  •  Basic Switch Using a pnp
16.3	 MOSFETs as Switches.....................................................................16-8
Basic Switch Circuit Using an nFET  •  Switch Circuit with a 
Resistive Load  •  Switch Circuits Driving an LED  •  Basic Switch 
Circuit Using a pFET
16.4	 CMOS Switches..............................................................................16-13
CMOS Digital Switches  •  CMOS Pass-Gates
References...................................................................................................16-17
Tina Hudson
Rose-Hulman Institute 
of Technology
© 2011 by Taylor and Francis Group, LLC

16-2 
Fundamentals of Industrial Electronics
When VIN is at a high voltage, for example VCC, the transistor sources the maximum amount of cur-
rent (see Figure 16.1b). This current causes a large voltage drop across the resistor, RC, which causes 
the output voltage to drop. Because the output voltage is low, VCE is small, and the npn is placed in the 
saturation region [3]. In the saturation region, the base current increases, which requires more current 
to drive the switch [2]. To minimize this extra current, the base resistor, RB, is added to set the collector 
current at a value that will place the npn at the edge of the saturation-active region. The resistor, RC, and 
the transistor acting in the saturation mode will also further limit the amount of output current that the 
BJT can draw. The final resting voltage will occur where the current through RC is equal to the current 
through the npn transistor.
To find the resulting VO and IC values, the analysis proceeds with the assumption that the npn is at 
the edge of the active region, which places VCE = VCesat = 0.2 to 0.3 V [3]. The analysis proceeds as follows.
The value of IC that places the transistor in the saturation region must be calculated first as follows:
	
I
I
RC
C
=
	
(16.1)
By Kirchoff’s voltage law (KVL)
	
V
V
V
CC
RC
CE
−
=
	
(16.2)
To minimize base current in the low state, set VCE = VCE,SAT = 0.2 V and by Ohm’s law
	
V
I R
RC
C
C
=
	
(16.3)
Substitute and rearrange to get
	
I
V
V
R
C
CC
CE,SAT
C
=
−
	
(16.4)
Next, find the value of RB that will produce IC given the worst-case, or minimum, β value:
	
I
I
B
C
= β 	
(16.5)
VO=VCC
0 V
+
+
+
–
–
–
RC
VCC
(a)
IC=0
VBE
VCE
RB
IB
+
+
+
–
–
–
VO<VCE,SAT
VCC
RC
VCC
(b)
IC
IRC
VCE
VBE
RB
IB
FIGURE 16.1  Basic npn switch circuit. (a) Shows the circuit operation with VIN = 0 V and (b) shows the circuit 
operation with VIN = VCC.
© 2011 by Taylor and Francis Group, LLC

Transistors in Switching Circuits 
16-3
KVL at the input loop produces
	
V
V
V
IN
RB
BE
−
−
= 0 	
(16.6)
Set VRB = IBRB and VBE = VBE,ON (the turn-on voltage of the transistor) to get
	
V
I R
V
IN
B
BE,ON
−
−
=
B
0 	
(16.7)
Solve for RB to get
	
R
V
V
I
B
IN
BE,ON
B
=
−
	
(16.8)
A numerical example is presented to show how device tolerances affects the analysis. Assume 
RC = 5 kΩ, 100 < β < 300, VCE,SAT = 0.2 V and VBE,ON = 0.7 V, and 4.6 < VINHIGH < 5. Find the base resistor 
needed to guarantee that the transistor is saturated:
I
V
V
R
C
CC
CE,SAT
C
V
V
k
A
=
−
=
−
=
5
0 2
5
960
.
Ω
µ
I
I
B
C
A
A
=
=
=
β
µ
µ
960
100
9 6.
R
V
V
I
B
IN
BE,ON
B
V
V
A
k
=
−
=
−
=
4 6
0 7
9 6
406
.
.
. µ
Ω
Round RB to a realizable resistor that makes IB even larger to guarantee that the transistor is in the 
saturation region. If β is at the high end of the range, IC will be even larger and push the transistor even 
further into the saturation region. This will result in a higher current draw on the input, but a lower cur-
rent draw on the output. However, this solution will guarantee that VO is at a “low” value.
16.2.2  Switch Circuit with a Resistive Load
The previous analysis assumed that the load was purely capacitive or an open circuit. If the circuit drives 
a load resistor, shown in Figure 16.2, the analysis changes. When VIN is low (see part (a)), VO will not 
reach VCC. If VIN < VBE, IC ≈ 0; however current still flows through RC to the load resistor. If IC ≈ 0, the 
circuit acts as if the transistor is not there. Remove the transistor, and the final VO is the result of a volt-
age divider between RL and RC as follows:
	
V
V
R
R
R
O
CC
L
L
C
=
+
	
(16.9)
When VIN is high (see part (b)), the solution for RB becomes slightly more complex. To find IC, perform 
Kirchoff’s current law (KCL) at the VO node as follows:
	
I
I
I
RC
C
L
=
+
R 	
(16.10)
	
V
V
R
I
V
R
CC
O
C
C
O
L
−
=
+
	
(16.11)
© 2011 by Taylor and Francis Group, LLC

16-4 
Fundamentals of Industrial Electronics
To design this circuit at the edge of the saturation-active region, assume VO = VCEsat = 0.2 V and solve 
for IC:
	
I
V
V
R
V
R
C
CC
CEsat
C
CEsat
L
=
−
−
	
(16.12)
When IC is known, RB can be solved, as in the previous example, using the worst-case β and the worst-
case VIN:
	
I
I
B
C
= β 	
(16.13)
	
R
V
V
I
B
IN
BE,ON
B
=
−
	
(16.14)
If the design of this circuit requires a high value for VOHIGH and the load resistor is small, a constraint 
may be placed on RC. To keep VO at a high value, RC must be less than RL to minimize the loss of voltage 
across the voltage divider. However, a small RC will result in more current. Therefore, if the circuit must 
drive a small load resistor without an increase in power consumption, the design may require a CMOS 
implementation (see Section 16.4).
16.2.3  Switch Driving an LED
Another common switch example is shown in Figure 16.3, where the load is an LED (or transformer 
coil) with a current limiting resistor [3]. This circuit requires a similar analysis as shown in Section 
16.2.1, except that the diode drop across the LED must be considered and the transistor must produce 
enough current to turn the LED on when VIN is high. When VIN is low, IC is approximately zero, so the 
voltage across the LED as well as the voltage across RC are both zero (Figure 16.3a). As a result, VO is still 
approximately VCC and the LED will not be lit (or the transformer will not become activated).
When VIN is high, IC must be chosen to be a value that will turn the LED on to the desired brightness 
level (Figure 16.3b). If the LED requires 15 mA to emit light, RC and RB must be chosen such that the BJT 
Vo
0 V
+
–
+
–
RC
VCC
(a)
IC=0
RL
RB
Vo
VDD
RC
VCC
(b)
IC
IRC
RL
IRL
RB
FIGURE 16.2  An npn switch circuit with a resistive load. (a) Shows the circuit operation with VIN = 0 V and 
(b) shows the circuit operation with VIN = VCC.
© 2011 by Taylor and Francis Group, LLC

Transistors in Switching Circuits 
16-5
produces 15 mA in the saturation region [3]. Without RC and RB, the npn is likely to produce too much 
current and burn out the LED. Therefore, the analysis proceeds as follows:
KVL at the output yields
	
V
V
I R
V
CC
LED
C
C
CE,SAT
−
−
=
	
(16.15)
Rearrange and solve for RC to get
	
R
V
V
V
I
C
CC
LED
CE,SAT
C
=
−
−
	
(16.16)
where IC is the current necessary to illuminate the LED.
To find RB, follow the same procedure in Section 16.2.1. IC is the current necessary to illuminate the 
LED. From IC, find IB and by KVL, find RB.
The following example shows a numerical example to demonstrate how component tolerances should 
be handled. Find the resistor values to illuminate an LED requiring 15 mA if 100 < β < 300, VLED = 1.8 V, 
VCC = 5V, VCE,SAT = 0.2 V, VBE,ON = 0.7 V, and 4.6 < VINHIGH < 5:
R
V
V
V
I
C
CC
LED
CE,SAT
C
V
V
V
mA
=
−
−
=
−
−
=
5
1 8
0 2
15
866
.
.
Ω
I
I
B
C
mA
A
=
=
=
β
µ
15
100
150
R
V
V
I
B
IN
BE,ON
B
V
V
A
k
=
−
=
−
=
4 6
0 7
150
26
.
.
µ
Ω
Round RB and RC to realizable resistors that will guarantee at least 15 mA through LED and more than 
enough base current to saturate the transistor. To achieve this, round RB down so that IB, and thereby IC, 
will be larger than necessary and round RC up to push the transistor further into the saturation region.
Vo
0 V
RC
VCC
(a)
IC=0
VBE
VCE
RB
IB
VLED
+
+
+
–
+
–
–
–
Vo
VCC
RC
VCC
(b)
IC
IRC
VCE
VBE
RB
IB
VLED
+
+
–
+
–
–
+
–
FIGURE 16.3  An npn switch circuit driving an LED in the collector. (a) Shows the circuit operation with VIN = 0 V 
and (b) shows the circuit operation with VIN = VCC.
© 2011 by Taylor and Francis Group, LLC

16-6 
Fundamentals of Industrial Electronics
The circuit shown in Figure 16.3 can also be implemented with the LED in the emitter, as shown in 
Figure 16.4. Since IC ≈ IE, if the collector current can be turned on and off, so also can the emitter cur-
rent. KVL around the input loop helps to understand how this circuit works (see Figure 16.4a):
	
V
V
I R
V
IN
BE,ON
E
E
LED
−
−
−
= 0 	
(16.17)
Solving for VIN produces the following equation:
	
V
V
I R
V
IN
BE,ON
E
E
LED
=
+
+
	
(16.18)
To turn the circuit off, VIN should be set low enough to force IE = 0. This will occur when VIN < VBE,ON, 
as in the previous examples.
When VIN is high, as in Figure 16.4b, the LED is turned on as follows. By KVL, VE = VIN − VBE,ON. 
Therefore, as VIN rises, so does VE. As VE rises, the LED and RE see a larger voltage across them, resulting 
in more current draw. RE can be chosen to set the current through the LED at the desired level when VIN 
is at its lowest turn-on voltage as follows. Rearrange Equation 16.18 to solve for RE and set IE equal to the 
desired LED current:
	
R
V
V
V
I
E
IN
BE,ON
LED
E
=
−
−
	
(16.19)
Notice that there is no base resistor in this implementation. The circuit can turn the LED on and off 
without pushing the transistor into the saturation region; therefore, the base current limiting resis-
tor is unnecessary. In fact, the only way the transistor can be placed in the saturation region is when 
VIN > VCC. If VIN = VCC,
	
V
V
V
V
E
BE,ON
=
−
=
−
CC
CC
0 7. 	
(16.20)
Since VCE = VCC − VE, substituting Equation 16.20 results in
	
V
V
V
V
CE
CC
CC
CE,SAT
=
−
−
=
>
(
. )
.
0 7
0 7
	
(16.21)
This analysis shows the benefit of placing the LED in the emitter rather than the collector. The desired 
brightness can be achieved with one less resistor and potentially less power. It is important to note that 
+
+
+
–
–
–
VE
RE
VCC
(b)
IE
IRE
VCE
VBE
IB
VLED
+
–
VLED
VE
VIN=0 V
VIN= VCC
+
+
–
–
RE
VCC
(a)
IE=0
VBE
VCE
IB
+
–
+
–
FIGURE 16.4  An npn switch circuit driving an LED in the emitter. (a) Shows the circuit operation with VIN = 0 V 
and (b) shows the circuit operation with VIN = VCC.
© 2011 by Taylor and Francis Group, LLC

Transistors in Switching Circuits 
16-7
with this implementation, the transistor does not go into the saturation region. If RC is chosen to set 
VCE = VCE,sat, VBE will be less than the turn-on voltage, turning the BJT off and thereby turning the LED off.
To provide a final comparison of the two circuits, the specifications for the previous design are imple-
mented using this circuit: illuminate an LED requiring 15 mA if 100 < β < 300, VLED = 1.8 V, VCE,SAT = 
0.2 V, VBE,ON = 0.7 V, and 4.6 < VINHIGH < 5. Using worst-case VIN,
	
R
V
V
V
I
E
IN
BE,ON
LED
E
V
V
V
mA
=
−
−
=
−
−
=
4 6
0 7
1 8
15
140
.
.
.
Ω
	
(16.22)
Round RE down to the nearest realizable resistor value to ensure that enough current goes through 
the LED.
16.2.4  Basic Switch Using a pnp
Any of these circuits can be implemented using a pnp by simply flipping the circuit over as shown in 
Figure 16.5 and replacing the npn with a pnp [3]. When VIN is high such that VEB = VCC − VIN < VEB,ON, 
the transistor is off and produces very little current (Figure 16.5a). As a result, there is little voltage drop 
across RC and VO goes to approximately 0 V. When VIN is low, RB sets the base current, which sets the col-
lector current that drives VO high (Figure 16.5b). The collector current is chosen to drive the transistor 
into the saturation region to limit the DC power dissipation while the transistor is in the high state. The 
analysis of this circuit proceeds in the same manner as the npn circuit shown in Section 16.2.1.
KVL at the output yields
	
V
V
I R
CC
EC,SAT
C
C
−
=
	
(16.22a)
Rearrange and solve for the IC that is necessary to saturate the transistor:
	
I
V
V
R
C
CC
EC,SAT
C
=
−
	
(16.23)
Next, find the value of RB that will produce IC given the worst-case, or minimum, β value:
	
I
I
B
C
= β 	
(16.24)
+
+
+
–
–
–
(b)
VO
0 V
RC
VCC
IC
VEB
VEC<VEC,SAT
RB
IB
IRC
VO=0
VCC
+
+
+
–
–
–
RC
VCC
(a)
IC=0
VEB
VEC
RB
IB
FIGURE 16.5  Basic pnp switch circuit. (a) Shows the circuit operation with VIN = VCC and (b) shows the circuit 
operation with VIN = 0 V.
© 2011 by Taylor and Francis Group, LLC

16-8 
Fundamentals of Industrial Electronics
KVL at the input loop produces
	
V
V
V
V
CC
EB
IN
−
−
=
RB
	
(16.25)
Note that IB comes out of the base in a pnp, which changes the polarity of the voltage across RB.
Substitute VRB = IBRB and solve for RB to get
	
R
V
V
V
I
B
DD
EB
IN
B
=
−
−
	
(16.26)
16.3  MOSFETs as Switches
16.3.1  Basic Switch Circuit Using an nFET
FET switch operation is very similar to BJT switch operation. Any of the circuits presented for BJTs can 
be implemented using FETs. However, there are three primary differences in the analysis of the FET 
circuits and the BJT circuits: (1) since the gate current for a FET is zero, a base resistor is unnecessary; 
(2) the saturation voltage depends on the gate-source voltage as shown in Equation 16.27; and (3) because 
VDSsat and VGS depend on ID and cannot be approximated as a known value, the characteristic equations 
must be used.
	
V
V
V
DSsat
GS
t
=
−
	
(16.27)
An example of an nFET used as a switch is shown in Figure 16.6 [3]. When VIN is at a low voltage (less 
than Vt), the transistor produces very little current (see Figure 16.6a). With very little current running 
through RD, there is very little voltage drop across RD and so VO is approximately at VDD. This operation 
requires that VIN be less than Vt in order to turn the transistor off and allow a high output voltage. As 
a consequence, some consideration should be given to the largest value of VIN that is considered a “low 
value” and the threshold voltage of the FET. If a low value for VIN could be anywhere between 0.7 and 
1.2 V, the threshold voltage of the FET should be larger than 1.2 V. Conversely, if the threshold voltage of 
the FET is 1 V, the maximum “low” value for VIN should be less than 1 V.
When VIN is at a high voltage, for example VDD, the transistor sources the maximum amount of cur-
rent (see Figure 16.6b). This current causes a large voltage drop across the resistor, RD, which causes the 
output voltage to drop. Because the output voltage is low, VDS is small, and the FET is placed in the linear 
VO= VDD
0 V
RD
VDD
(a)
ID= 0
VGS
–
+
+
+
+
–
–
–
+
–
VDS
VO< VDS,SAT
VDD
RD
VDD
(b)
ID
IRD
VDS
–
+
VGS
FIGURE 16.6  Basic nFET switch circuit. (a) Shows the circuit operation with VIN = 0 V and (b) shows the circuit 
operation with VIN = VDD.
© 2011 by Taylor and Francis Group, LLC

Transistors in Switching Circuits 
16-9
region (note: this corresponds to the saturation region of the BJT) [3]. The resistor, RD, and the transistor 
acting in the saturation mode will limit the amount of current that the FET can draw. The final resting 
voltage will occur where the current through RD is equal to the current through the FET, which is deter-
mined by the linear region equation:
	
I
K
W
L
V
V V
V
DS
GS
t
DS
DS
=
′



−
−






(
)
2
2
	
(16.28)
Solving the two equations together yields
	
IRD = ID:
	
V
V
R
K
W
L
V
V V
V
DD
DS
D
GS
t
DS
DS
−
=
′



−
−






(
)
2
2
	
(16.29)
Substituting in for VGS = VDD − 0 and VDS = VO − 0 yields
	
V
V
R
K
W
L
V
V V
V
DD
O
D
DD
t
O
O
−
=
′



−
−






(
)
2
2
	
(16.30)
If the circuit has been designed, everything is known except VO, so the value of VO can be determined. 
For the example circuit in Figure 16.6, if Vt = 1 V, K′(W/L) = 10 mA/V2, VIN = 5 V and RD = 500 Ω, the 
analysis would proceed as follows:
5
500
10
5
1
2
2
2
−
=
−
−




V
V
V
O
O
O
mA/V
Ω
(
)
Solving for VO yields
VO
V
= 0 245
.
VO may be solved using the root function in a calculator or math function program, or solving for 
the quadratic equation by hand. If using a calculator, be sure to choose a root that makes sense in the 
circuit.
If the goal is to design the circuit, a desired VO must be chosen, and then a value for RD can be deter-
mined. A lower VO will push the transistor deeper into the linear region, further limiting the current 
through the transistor. If the circuit is driving a purely capacitive load, this condition is advantageous to 
limit the power consumption. Less current sourced from VDD to ground in the low state will require less 
power. However, it also requires a larger value for RD. For the example circuit in Figure 2.6, if Vt = 2 V, 
K′(W/L) = 20 mA/V2, and VIN = 4 V, the analysis would proceed as follows:
Choose VO = 0.1 V. The FET yields the following equation:
I
K
W
L
V
V V
V
D
DD
t
O
O
mA/V
V
V
V
=
′



−
−





=
−
−
(
)
(
) .
( .
2
2
2
20
4
2
0 1
0 1 V
mA
)
.
2
2
3 9








=
The resistor yields the following equation:
I
V
V
R
R
D
DD
O
D
D
V
V
=
−
=
−
5
0 1.
© 2011 by Taylor and Francis Group, LLC

16-10 
Fundamentals of Industrial Electronics
Setting the two equations equal to one another and solving for RD yields
RD
V
V
mA
k
=
−
=
5
0 1
3 9
1 25
.
.
.
Ω
Round RD to the nearest realizable resistor that will place the circuit even further into the linear region. 
To achieve this, round RD up to increase the voltage drop across RD and, thereby, to push the FET further 
into the saturation region. If the result does not give the necessary power consumption, choose a lower 
VO and repeat the process. Alternatively, if a required power consumption is known, find the VO that 
will produce the necessary power consumption using the linear equation and then find the value for RD.
16.3.2  Switch Circuit with a Resistive Load
Recall that the previous analysis assumes that the load is purely capacitive or an open circuit. Like the 
BJT analysis, if the circuit is driving a load resistor, as shown in Figure 16.7, the value of VO depends on 
the voltage divider set-up between RD and RL (see Figure 16.7a). If VIN < Vt, ID = 0; however, the current 
still flows through RD to the load resistor. The final VO is the result of a voltage divider between RL and 
RD as follows:
	
V
V
R
R
R
O
DD
L
L
D
=
+
	
(16.30a)
When VIN is high (see part (b)), the solution for VO also becomes slightly more complex. To find VO, 
perform the KCL at the VO node as follows:
	
I
I
I
RD
D
RL
=
+
	
(16.31)
	
V
V
R
K
W
L
V
V V
V
V
R
DD
O
D
DD
t
O
O
O
L
−
=
′



−
−





+
(
)
2
2
	
(16.32)
Rearranging produces
	
′ 



−
+
+
′ 



−



+
=
K
W
L
V
V
R
R
K
W
L
V
V
V
R
O
O
D
L
DD
t
DD
D
2
2
1
1
0
(
)
	
(16.33)
Vo
0 V
+
–
+
–
RD
VDD
(a)
 ID=0
RL
Vo
VDD
RD
VDD
(b)
ID
IRD
RL
IRL
FIGURE 16.7  An nFET switch circuit with a resistive load. (a) Shows the circuit operation with VIN = 0 V and 
(b) shows the circuit operation with VIN = VDD.
© 2011 by Taylor and Francis Group, LLC

Transistors in Switching Circuits 
16-11
VO can again be solved using a root function. If designing this circuit, the requirements on VOHIGH and 
value of the load resistor may place a constraint on RD. To keep VO at a high value, RD must be less than 
RL to minimize the loss of voltage across the voltage divider. However, a small RD will result in a higher 
VOLOW. Therefore, if the circuit must drive a small load resistor, the design may require a small transition 
region between VOH and VOL or a buffer to increase the load resistance seen by the switch.
16.3.3  Switch Circuits Driving an LED
The FET can also be used to drive an LED or transformer in a similar manner as the BJT. However, BJTs 
typically have stronger drive capability due to the exponential I–V relationship rather than the square-
law I–V relationship [3]. If a high current is necessary, either a BJT or a high-power MOSFET may be 
necessary.
Figure 16.8 shows the FET switch with an LED in the drain [3]. This circuit requires a similar analy-
sis as Section 16.3.1, except the diode drop across the LED must be considered and the transistor must 
produce enough current to turn the LED on when VIN is high. When VIN is low, ID is approximately zero, 
so the voltage across the LED as well as the voltage across RD are both zero (Figure 16.8a). As a result, 
VO is still approximately VDD.
When VIN is high, ID must be chosen to be a value that will turn the LED on (Figure 16.8b). If the LED 
requires 15 mA to emit light, VO must be chosen so that the FET produces 15 mA in the linear region.
	
15
2
2
mA
DD
t
O
O
=
′ 



−
−






K
W
L
V
V V
V
(
)
	
(16.34)
Solve for VO using a root function. Then, using KVL, find an equation for RD as follows:
	
V
V
R
V
DD
LED
D
O
mA
−
−
=
15
*
	
(16.35)
Solving for RD yields
	
R
V
V
V
D
DD
LED
O
mA
=
−
−
15
	
(16.36)
(b)
VO<VDS,SAT
VDD
RD
VDD
ID
IRD
VLED
+
–
+
–
(a)
VO
0 V
RD
VDD
ID
IRD
VLED
+
–
+
–
FIGURE 16.8  An nFET switch circuit driving an LED in the drain. (a) Shows the circuit operation with VIN = 0 V 
and (b) shows the circuit operation with VIN = VDD.
© 2011 by Taylor and Francis Group, LLC

16-12 
Fundamentals of Industrial Electronics
The LED can be placed in the source just like the BJT circuit (see Figure 16.9). When VIN < VGS, as 
shown in Figure 16.9a, the transistor produces little current making the voltage drop across the LED and 
the resistor approximately zero and the LED turns off. However, when VIN is high (see Figure 16.9b) the 
transistor produces maximum current, which turns the LED on. Like the BJT circuit, VS = VIN − VGS. As 
a result, the FET cannot be placed into the linear region unless VIN goes outside of the rails. The analysis 
of this fact follows, assuming that VIN is at the highest possible value within the rails: VDD.
	
V
V
V
V
V
GS
IN
S
DD
S
=
−
=
−
	
(16.37)
	
V
V
V
DS
DD
S
=
−
	
(16.38)
Therefore,
	
V
V
GS
DS
=
	
(16.39)
	
V
V
V
V
DS,sat
GS
t
GS
=
−
<
	
(16.40)
As a result, the FET will not be in the linear region, so the saturation region equations should be used 
for this circuit.
In both FET LED circuits, the current through the circuit is limited by a resistor, RD or RS. The analy-
sis for the circuit in Figure 16.9 proceeds as follows. Given a desired LED current (IS), a known voltage 
drop across the LED (VLED), and a known worst-case input voltage (VIN), the source resistor (RS) can be 
determined to set these conditions. The KVL at the input loop yields
	
V
V
I R
V
IN
GS
S
S
LED
−
−
−
= 0 	
(16.37a)
All values are known in this equation except VGS and RS. Since the transistor is in the saturation equa-
tion, VGS must be found using the characteristic equation in this region:
	
I
K
W
L
V
V
D
GS
t
=
′ 



−
2
2
(
)
	
(16.38a)
(a)
VS
0 V
RS
VDD
IS=0
VGS
VDS
VLED
+
–
+
+
–
–
+
–
(b)
VS
VDD
RS
VDD
IS
IRS
VDS
VGS
VLED
+
–
+
–
+
–
+
–
FIGURE 16.9  An nFET switch circuit driving an LED in the emitter. (a) Shows the circuit operation with VIN = 0 V 
and (b) shows the circuit operation with VIN = VDD.
© 2011 by Taylor and Francis Group, LLC

Transistors in Switching Circuits 
16-13
Rewriting for VGS yields
	
V
I L
K W
V
GS
D
t
=
′
+
2
	
(16.39a)
Once VGS is known, RS can be found as follows:
	
R
V
V
V
I
S
IN
GS
LED
S
=
−
−
	
(16.40a)
16.3.4  Basic Switch Circuit Using a pFET
Like the BJT circuits, any of the nFET circuits can be implemented using a pFET by simply flipping the 
circuit over, as shown in Figure 16.10 [3]. In this case, a high value of VIN (VDD–VIN < |Vt|) will turn the 
FET off (Figure 16.10a). With no ID, VO = 0. A low value of VIN, such as 0, will cause the transistor to 
source maximum current, placing a large voltage across RD, pushing VO high and placing the transistor 
into the linear region (Figure 16.10b). Just like the nFET circuit, VO settles where ID = IRD.
Setting the FET and resistor currents equal to one another yields
	
′



−
−





=
−
K
W
L
V
V V
V
V
R
(
)
SG
t
SD
SD
S
D
2
2
0
	
(16.41)
Replacing VSG and VSD with known node voltages produces
	
′



−
−
−
−





=
K
W
L
V
V
V
V
V
V
V
R
(
)(
)
(
)
DD
t
DD
O
DD
O
O
D
2
2
	
(16.42)
Using Equation 16.42, VO may be determined or RD may be solved in a manner similar to the example 
shown in Section 16.3.1.
16.4  CMOS Switches
Complementary MOS (CMOS) switches use both n and p devices to produce the switch. Such configura-
tions can improve power consumption in some circuits and prevent signal degradation in others. This 
section will present the circuits and analysis of some common CMOS switch circuits.
(b)
IRD
VO
0 V
RD
VDD
ID
VSG
VSD<VSD,SAT
+
+
+
–
–
–
(a)
VO=0
VDD
RD
VDD
ID=0
VSG
VSD
+
–
+
+
–
–
FIGURE 16.10  Basic pFET switch circuit. (a) Shows the circuit operation with VIN = VDD and (b) shows the circuit 
operation with VIN = 0 V.
© 2011 by Taylor and Francis Group, LLC

16-14 
Fundamentals of Industrial Electronics
16.4.1  CMOS Digital Switches
The switch circuits described in Sections 16.2 and 16.3 suffer from power consumption when the n-type 
switches have a high VIN or when the p-type switches have a low VIN. In this state (see Figure 16.11a), 
VDS = VDSsat. Since the drain is connected to the rail through RD, there is a small current going from VDD 
to the ground through RD and the transistor. This small current results in constant power consumption 
while the circuit is in this state [4]. The resistors are designed to place the transistors in the saturation 
region to minimize this current draw; however, it is nonzero for these circuits. When the switch is in the 
opposite state (e.g., VIN is low for the n-type or high for the p-type), the transistor is in off position. As a 
result, the current through the resistor has no place to go, so ID = 0, unless there is a resistive load. If the 
load is capacitive, the power consumption in this state is zero.
Using CMOS logic with a capacitive load, shown in Figure 16.11b and c, guarantees that one device or 
the other is turned off for each state which minimizes power consumption [4]. When VIN is high (Figure 
16.11b), VGSp = 0 which turns M2 off. M1 is strongly activated and will sink current off the capacitive 
load until VO = 0, VDS1 = 0, and ID1 = ID2 = 0. At this point, there is no further power consumption until 
the switch changes its state.
When VIN is low (Figure 16.11c), VGSn = 0, which turns M1 off. M2 is strongly activated and will source 
current on to the capacitive load until VO = VDD, VSD2 = 0, and ID1 = ID2 = 0. Once again, at this point 
there is no further power consumption until the switch changes its state. As a result, the only time this 
switching circuit draws power is when it switches states.
It is important to keep in mind that if there is a resistive load, even a CMOS circuit will continue to 
draw power when the circuit is in a steady-state [4]. Additionally, in this case VO does not necessarily 
+
+
+
+
–
–
–
–
VO
0 V
5 V
ID1
VDS1
VGSn=0
VGSp
M1
M2
ID2
(c)
+
+
–
–
VO
5 V
RD
5 V
(a)
ID small
VDS=VDSsat
+
+
+
+
–
–
–
–
VO
5 V
5 V
(b)
VGSn
VGSp= 0
M1
M2
ID2
ID1
VDS1
FIGURE 16.11  CMOS switch circuit with capacitive load. (a) Shows the power limitation of an nFET switch circuit, 
(b) shows the CMOS circuit operation with VIN = VDD = 5 V, and (c) shows the CMOS circuit operation with VIN = 0 V.
© 2011 by Taylor and Francis Group, LLC

Transistors in Switching Circuits 
16-15
reach the rails [4]. An example of a CMOS circuit driving a resistive load is shown in Figure 16.12. 
When VIN is high (Figure 16.12a), the load resistor, RL, and the source of M1 are both tied to the ground. 
In this case, VO can be pulled all the way to 0 V. If VO = 0 V, both sides of the resistor are effectively 
grounded so there is no load current to go through M1. As a result, the circuit does not consume power 
in this state. However, when VIN is low (Figure 13.12b), M2 will try to pull VO up to VDD. However, as VO 
rises, the current through RL rises as well. The final value for VO occurs when the current through M2 
(ID2) is equal to the current through the load resistor (IL). Assuming that the transistor is in the linear 
region at this point, the solution for VO is found using the following equation:
	
′



−
−





=
−
K
W
L
V
V V
V
V
R
(
)
SG
t
SD
SD
O
L
2
2
0
	
(16.43)
Knowing the VSG = VIN and VSD = VDD − VO, Equation 16.43 can be rewritten as follows:
	
′



−
−
−
−





=
−
K
W
L
V
V
V
V
V
V
V
R
(
)(
)
(
)
IN
t
DD
O
DD
O
O
L
2
2
0
	
(16.44)
VO can be found using a calculator root function. The current draw in this state can be determined 
by ID2 = IL = VO/RL.
It is important to note that the complementary logic with BJTs does not have the same power con-
sumption advantage as FETs. Even if the output current draw is reduced, the input current draw is 
increased, since BJTs absorb more base current when they are in the saturation region. In fact, the most 
base current draw occurs when VCE or VEC = 0, because the collector-base p–n junction diode is most 
strongly forward biased at this biasing level [2]. Therefore, the net power gain is insignificant. However, 
if the source can provide the base currents necessary, the advantage of VO swinging rail-to-rail with a 
capacitive load may still be a benefit.
16.4.2  CMOS Pass-Gates
The circuits presented so far are used for producing digital output levels (VO = high or low voltage) or 
driving current source loads, such as LEDs or transformers. Another common use for switches is to 
determine whether or not to pass a voltage based on a controlling input. The voltages passed can be 
digital voltages or analog voltages. The typical circuit used for this operation is called a pass-gate or 
transmission-gate. A single transistor can be used (a pass-gate), as in Figure 16.13, or a CMOS pair can 
be used (a transmission gate), as in Figure 16.14 [4]. In these example circuits, two pass-gates are used to 
select which input sets the value of a common output line.
(b)
ID2
VGSn= 0
VO
0 V
5 V
IL
VDS1
VGSp
M1
M2
RL
+
+
+
+
–
–
–
–
VO= 0
5 V
5 V
(a)
ID1= 0
VGSn
VGSp= 0
M1
M2
IL= 0
RL
+
+
–
–
–
–
+
+
VDS1
FIGURE 16.12  CMOS switch circuit with resistive load. (a) Shows the circuit operation with VIN = VDD = 5 V and 
(b) shows the circuit operation with VIN = 0 V.
© 2011 by Taylor and Francis Group, LLC

16-16 
Fundamentals of Industrial Electronics
In the single transistor pass-gate operation (Figure 16.13a), M1 and M2 are the two pass-gates [1,4]. 
VCA and VCB are typically driven with digital input values equal to the rails of the circuit, but ideally VINA 
and VINB can be any voltage within the rails. If VCA is set to a high voltage and VCB is set to a low voltage, 
M1 lets VINA “pass through” to VO so that VO = VINA. If VCA is set to a low voltage and VCB is set to a high 
voltage, M2 lets VINB “pass through” to VO so that VO = VINB. If VCA = VCB = 0, VO floats and typically 
maintains its value until leakage current through the transistors causes it to change [1,4]. If VCA and 
VCB are both high, both VINA and VINB try to drive the line to their voltages causing a short between two 
sources. This condition should be avoided.
In this schematic, the sources are not labeled in these transistors because the source changes accord-
ing to the voltage level of VIN [1,4]. For an nFET, the source is at a lower potential than the drain. If 
VO = 0 V and VIN = 5 V, the source would be at VO. If VO = 5 V and VIN = 0 V, the source would be at 
VIN. Since the pass-gate can allow any voltage through, the source location changes for each value that 
is passed through. If the pass-gates were implemented with pFETs, the source would change locations 
similarly, except that the source would at a higher potential than the drain. For a FET to be used as a 
pass-gate, it is essential that the bulk is NOT tied to the source such that the source can change locations. 
VO=VINA
VINA
M1n
M2n
VINB
VCA=VDD
M1p
M2p
VCA=0
VCB=0
VCB=VDD
FIGURE 16.14  A CMOS pass-gate.
VO= 0
VINA= VDD
VGS
M1
M2
VINB= 0
VCB= 0
VCA=VDD
(a)
–
+
VO= VDD
VINA= VDD
VGS
M1
M2
–
+
VINB=0
VCB= VDD
VCA=0
(b)
FIGURE 16.13  An nFET pass-gate. (a) Shows the nFET (M1) passing a high voltage (VDD) to VO and (b) shows the 
nFET (M2) passing a low voltage (0V) to VO.
© 2011 by Taylor and Francis Group, LLC

Transistors in Switching Circuits 
16-17
Otherwise, some conditions will connect the bulk to the wrong potential and forward bias the drain-
bulk and source-bulk n–p junctions. Therefore, if a discrete device is being used as a pass-gate, it must 
be a 4-­terminal MOSFET. Since BJTs are not bidirectional devices (the emitter and collector cannot be 
swapped without seriously degrading the value of β), they cannot be used for pass-gates either.
The limitation of the single-transistor pass-gate is shown in Figure 16.13b. In this example, VINA = 
VDD and VCA = VDD. If initially VO = 0 V, then the source is at VO. Therefore, VGS = VCA − VO. VINA charges 
the capacitor bringing VO up to VDD. However, as VO rises, VGS drops. Once VO tries to go higher than 
VDD − Vt, VGS < Vt and M1 turns off. Therefore, the pass-gate cannot drive VO > VCA − Vt. This limitation 
does not occur when the nFET is passing a low voltage. If initially VINB = 0, VCB = VDD, and VO = VDD, the 
nFET source is at VINB. Since VINB does not change values while VO is dropping, VGS remains constant 
and M2 remains on. A similar limitation exists for the pFET pass-gate; however, because the source for 
a pFET is at a potential higher than the drain, it cannot drive VO < |Vt|.
Since an nFET can pass a low voltage without turning off but not a high voltage, and a pFET can 
pass a high voltage without turning off but not a low voltage, this limitation can be overcome by using 
both types of devices in parallel. The same circuit is shown with CMOS transmission-gates in Figure 
16.14. In this circuit, both transistors in parallel must be turned on or off simultaneously to allow or 
block transmission [1,4]. Therefore, assuming digital values drive the gates, the pFET gate is driven with 
the inverse of the nFET gate. If VCA = VDD, VCA = 0, VCB = 0, and V
V
CB
DD
=
, then M1n and M1p will be 
turned on and M2n and M2p will be turned off. As a result, VO = VINA. If VCB = VDD, VCB = 0, VCA = 0, 
and V
V
CA
DD
=
, then M2n and M2p will be turned on and M1n and M1p will be turned off. In this case, 
VO = VINB. When the pass-gate tries to pass a high voltage, the nFET will turn off but the pFET will 
remain on and pass the value to VO. Conversely, when the pass-gate tries to pass a low voltage, the pFET 
will turn off but the nFET will remain on and pass the value to VO. This solution allows voltages from 
rail-to-rail to be passed.
References
	
1.	 P. E. Allen and D. R. Holberg, CMOS Analog Circuit Design (2nd edition). New York: Oxford 
University Press, 2002.
	
2.	 G. W. Neudeck, Modular Series on Solid State Devices: The Bipolar Junction Transistor (2nd edition), 
Vol. 3. Reading, MA: Addison-Wesley Publishing Co., 1989.
	
3.	 A. S. Sedra and K. C. Smith, Microelectronic Circuits (5th edition). New York: Oxford University 
Press, 2004.
	
4.	 J. P. Uyemura, Introduction to VLSI Circuits and Systems. New York: John Wiley & Sons, Inc., 2002.
© 2011 by Taylor and Francis Group, LLC

17-1
17.1  Using Linear Transistor Models for Amplifiers
When a transistor is being used as an amplifier, the typical operation involves a low-amplitude sinusoidal 
VIN producing a large-amplitude sinusoidal VO. Each sinusoidal voltage and current will oscillate around 
a DC bias point (e.g., VIN may oscillate ±10 mV around a 0 V bias point), while VO may oscillate ±3 V 
around a 5 V bias point (see Figure 17.1). The current, IC, performs similarly, oscillating ±0.3 mA around 
a 1 mA bias point, but note that IC does not go negative. To simplify analysis and design, superposition 
is applied to the amplifier circuit to isolate the DC component of the signal from the AC component. 
Therefore, a DC analysis, where all AC sources are turned off, is performed independently of the AC 
analysis, where all DC sources are turned off. The DC analysis will produce the bias points (otherwise 
known as DC points or quiescent points or Q-points). The AC analysis will provide an expression of the 
AC gain. The complete operation of the amplifier, as shown in Figure 17.1, is a recombination of the AC 
and DC components.
17
Transistors in 
Amplifier Circuits
17.1	 Using Linear Transistor Models for Amplifiers.......................... 17-1
17.2	 DC Analysis...................................................................................... 17-2
High-Gain Amplifier with Input Resistor Biasing  • 
Common-Emitter Amplifier with Emitter Resistor and Load 
Resistor  •  High-Gain Amplifier with Current Source Biasing 
and Capacitively Coupled Load  •  Alternative High-Gain 
Amplifier  •  Voltage Follower
17.3	 AC Analysis.....................................................................................17-14
Small-Signal Model  •  High-Gain Amplifier with Input Resistor 
Biasing  •  Common-Emitter Amplifier with Emitter Resistor 
and Load Resistor  •  High-Gain Amplifier with Current Source 
Biasing and Capacitively Coupled Load  •  Alternative High-Gain 
Amplifier  •  Voltage Follower
17.4	 Swing: Putting AC and DC Together......................................... 17-38
High-Gain Amplifier with Input Resistor Biasing  •  High-Gain 
Amplifier with Input Resistor Biasing and a Resistive Load  • 
High-Gain Amplifier with Current Source Biasing and Capacitively 
Coupled Resistive Load  •  Swing Nonlinearity
17.5	 Design Example.............................................................................17-47
High-Gain Amplifier with Input Resistor Biasing  •  High-Gain 
Amplifier with Current Mirror Biasing and Voltage Follower
Tina Hudson
Rose-Hulman Institute 
of Technology
© 2011 by Taylor and Francis Group, LLC

17-2 
Fundamentals of Industrial Electronics
17.2  DC Analysis
To perform the DC analysis, place the circuit in its DC state:
	
1.	 Turn off all AC sources. This means shorting AC voltage sources (making them have 0 V across 
them) and setting all AC current sources to an open circuit (making them have 0 A in them).
	
2.	 Capacitors are open at DC, so make all capacitors an open circuit.
	
3.	 Using the current-saturating equations (FET = saturation region, BJT = active region), find the 
key bias points. Common key bias points for a FET are IDQ and VOQ. Similarly, common key bias 
points for a BJT are ICQ and VOQ. Sometimes, IBQ is also a necessary bias point for BJTs.
For the transistor to be used in an amplifier circuit, it must remain in the current-saturating region. 
Therefore, when performing the DC analysis, assume that the transistor is operating in this region. If 
the assumption is wrong, the resulting bias points will indicate that the transistor is not in this region 
of operation (e.g., VDS < VDS,SAT or VCE < VCE,SAT). Important note: since the transistor is operating in the 
current-saturation region, the DC value for VDS and VCE are not known. As shown in Figures 4.6 and 
4.11 in Chapter 4, VDS and VCE can be set to many different values and, approximately, the same output 
current will be produced.
The following examples will show the DC bias process for some standard amplifier circuits. Each 
example will be worked for both a FET and a BJT.
17.2.1  High-Gain Amplifier with Input Resistor Biasing
17.2.1.1  MOSFET Implementation
The circuit shown in Figure 17.2a is a common-source amplifier with input resistor biasing. This circuit 
description means that the source is held constant (common-source) and that the bias points are set by 
the input resistors, RG1 and RG2. In this circuit, the input resistors set the DC value for VGS (called VGSQ), 
which sets the DC value for ID (called IDQ). IDQ sets the DC value of VO (called VOQ).
First, the circuit should be redrawn for DC biasing following the rules presented previously. The DC 
bias circuit is shown in Figure 17.2b. The AC voltage source is shorted and the gate capacitor is an open 
0 A
1.0 mA
2.0 mA
0.3 mA
0.3 mA
IC
–50 mV
0 V
50 mV
10 mV
10 mV
VIN
0 s
0 V
0.5 ms
1.0 ms
1.5 ms
2.0 ms
2.5 ms
3 V
3 V
10 V
VOUT
5 V
3.0 ms
Time
FIGURE 17.1  Decomposition of amplifier signals.
© 2011 by Taylor and Francis Group, LLC

Transistors in Amplifier Circuits 
17-3
circuit. It is evident at this point as to why the gate capacitor is necessary. The gate capacitor allows the 
input voltage to be capacitively coupled onto the gate on top of the DC bias point that is set by the gate 
resistors. Without the cap, in the DC, the gate would be tied to ground, which would prevent VGSQ from 
being set to a desired voltage to set a desired IDQ.
In order to obtain a clearer picture of how the gate resistors set VGSQ, the circuit in Figure 17.2b is 
redrawn in Figure 17.2c using the Thevenin equivalent circuit of the bias resistors. The Thevenin equiva-
lent voltage seen by the gate is just a voltage divider between RG1 and RG2, and can be solved as follows 
using superposition of each DC source:
	
V
V
V
V
V
TH
G
SS
G
DD
with
turned off
with
turned off
=
+
(
)
(
)
	
V
V
R
R
R
V
R
R
R
TH
DD
G
G
G
SS
G
G
G
=
+
+
+
2
1
2
1
1
2 	
(17.1)
The Thevenin equivalent resistance is found by turning off both DC sources (VDD and VSS) and find-
ing the equivalent resistance seen by the gate. In this case, if both DC sources are turned off and tied 
to ground, and the other side of both resistors is connected to the gate, the resistors are in parallel. 
Therefore, the Thevenin equivalent resistance is
	
R
R
R
EQ
G1
G2
=
||
	
(17.2)
With the circuit in Figure 17.2c, it is simple to find VGSQ by using KVL on the input loop:
	
V
V
V
V
TH
REQ
GSQ
SS
=
+
+
	
(17.3)
Since IG = 0, there is no voltage drop across REQ, therefore VGSQ = VTH − VSS. The calculation of REQ is 
unnecessary for the FET circuit since it has no impact on VGSQ. However, RG1 and RG2 are still required 
to set VTH and thereby VGSQ. Additionally, the complete Thevenin equivalent transformation process is 
presented here to show the parallels and differences between this circuit and the BJT equivalent circuit.
Continuing with the analysis, the value of IDQ can be found from VGSQ using the saturation equation:
	
I
K
W
L
V
Vt
DQ
GSQ
=
′ 



−
2
2
(
)
	
(17.4)
(c)
RD
IRD
REQ
VRD
+
+
–
–
ID
VDD
VSS
VGS
VTH
VO
(a)
C
RD
RG1
RG2
VDD
VDD
VSS
VSS
VIN
VO
(b)
RD
RG1
RG2
VDD
VDD
VSS
VSS
VO
Tev.
Equiv.
FIGURE 17.2  DC analysis of common-source amplifier. (a) Shows the complete circuit with an input voltage 
containing both AC and DC components, (b) shows the DC equivalent circuit, and (c) shows the Thevenin equiva-
lent circuit of the circuit in (b).
© 2011 by Taylor and Francis Group, LLC

17-4 
Fundamentals of Industrial Electronics
Once IDQ is found, VOQ can be found using circuit analysis at the output of the circuit. Recall, VDS can 
be one of a number of different values, so its value cannot be assumed. Therefore, VOQ must be found 
using Ohm’s law and KVL from the top supply voltage as follows:
	
V
V
V
DD
RD
OQ
−
=
	
(17.5)
By KCL at VO, IRD = IDQ, so
	
V
I
R
V
DD
DQ
D
OQ
−
=
	
(17.6)
The transistor device parameters, K′/2 and VT, depend on the fabrication process and therefore are 
typically known. W/L is a design parameter for integrated circuit designers. If a discrete transistor is 
being used, W/L is often included in the K′ parameter.
If the circuit has been designed, the bias points can be calculated by Equations 17.2 through 17.6 since 
RG1, RG2, RD, and VDD will all be known. If the goal is to design an amplifier, a value for VOQ and IDQ must 
be chosen first, then the resistors and supplies can be chosen using Equations 17.2 through 17.6. The 
method to design an amplifier will be covered in Section 17.5.
17.2.1.2  BJT Implementation
The circuit shown in Figure 17.3a is a BJT version of the same circuit, called a common-emitter ampli-
fier with input resistor biasing. In this case, the emitter is held constant (common-emitter) and that 
the bias points are set by the input resistors, RB1 and RB2. Similar to the FET circuit, the input resistors 
set the DC value for VBE (called VBEQ) that sets the DC value for IC (called ICQ). ICQ sets the DC value of 
VO (called VOQ). However, one difference in the analysis of the BJT circuit and FET circuit is due to the 
exponential relationship between VBE and IC. Since IC changes exponentially with VBE, a 0.1 V change in 
VBE causes a 100 times change in IC. As a result, obtaining an accurate calculation of ICQ as a function 
of VBEQ is difficult. Therefore, the circuit analysis will calculate for IBQ using an assumed value for VBE. 
Then, ICQ will be found from IBQ.
The basic steps are identical to the FET example. First, the circuit should be redrawn for DC biasing as 
shown in Figure 17.3b. The AC voltage source is shorted and the base capacitor is open circuited. In order to 
obtain a clearer picture of how the base resistors set IBQ, the circuit in Figure 17.3b is redrawn in Figure 17.3c 
using the Thevenin equivalent circuit of the bias resistors. To find the Thevenin equivalent circuit, break 
the circuit at the base. The Thevenin equivalent calculation is identical to the FET calculation as follows:
	
V
V
V
V
V
TH
B
EE
B
CC
with
turned off
with
turned off
=
+
(
)
(
)
(c)
IC
IB
RC
REQ
VCC
VRC
–
–+
–
+
+
VEE
VBE
VTH
VO
IRC
(b)
RC
RB1
RB2
VCC
VCC
VEE
VEE
VO
Tev.
Equiv.
(a)
RC
RB1
RB2
C
VCC
VCC
VIN
VEE
VEE
VO
FigURE 17.3  DC analysis of common-emitter amplifier. (a) Shows the complete circuit with an input voltage 
containing both AC and DC components, (b) shows the DC equivalent circuit, and (c) shows the Thevenin equiva-
lent circuit of the circuit in (b).
© 2011 by Taylor and Francis Group, LLC

Transistors in Amplifier Circuits 
17-5
	
V
V
R
R
R
V
R
R
R
TH
CC
B
B
B
EE
B
B
B
=
+
+
+
2
1
2
1
1
2 	
(17.7)
The Thevenin equivalent resistance is found in an identical manner as the FET circuit as well:
	
R
R
R
EQ
B1
B2
=
||
	
(17.8)
Using the circuit in Figure 17.3c, find IBQ using KVL on the input loop. Since current is going into the 
base, the voltage across REQ drops from VTH to VB, resulting in the following equation:
	
V
I
R
V
V
TH
BQ
EQ
BEQ
EE
=
+
+
	
(17.9)
A value for VBEQ must be assumed. If the circuit is expected to have an IC on the order of magnitude 
of 1 mA, VBE = 0.7 V is a common assumption. If the circuit is expected to produce an IC on the order of 
magnitude of 100 mA, VBE = 0.8 V can be used. Rearranging 17.9, IBQ can be solved for as follows:
	
I
V
V
R
BQ
TH
EE
EQ
=
−
−
0 7.
	
(17.10)
Once IBQ has been calculated, ICQ is found from the active region equation:
	
I
I
CQ
BQ
=
⋅
β
	
(17.11)
Once ICQ is found, VOQ can be found in the same manner as the FET circuit. Recall, VCE can be one of 
a number of different values, so its value cannot be assumed. Therefore, VOQ must be found using Ohm’s 
law and KVL from the top supply voltage as follows:
	
V
V
V
CC
RC
OQ
−
=
	
(17.12)
By KCL, IRC = ICQ, so
	
V
I
R
V
CC
CQ
C
OQ
−
=
	
(17.13)
17.2.2  Common-Emitter Amplifier with Emitter Resistor and Load Resistor
17.2.2.1  Implementation Using the npn
The circuit in Figure 17.3 works well when a single amplifier is needed. However, for the design to be 
replicated, device parameter variation can cause problems with the design. The parameter β can vary 
significantly from transistor to transistor due to manufacturing variation. If β varies from device to 
device, ICQ will change from circuit to circuit. The variation in ICQ will cause a variation in VOQ, and in 
the worst case, push a transistor into the saturation region in the DC condition, making the amplifier 
useless. In order to fix this problem, a resistor is added between the emitter and the negative supply, 
shown in Figure 17.4a, which provides negative feedback. If an increase in β causes an increase in ICQ, it 
also causes the increase in IEQ. The increase in IEQ causes a larger voltage drop across RE, which by KVL 
around the input loop, decreases VBE slightly. This decrease in VBE brings ICQ back down closer to the ICQ 
with the lower β value.
The process for the DC analysis follows the previous example identically, except now the emitter 
resistor must be accounted for. The DC circuit is drawn and the Thevenin equivalent circuit is found 
resulting in the circuit in Figure 17.4b. KVL around the input loop produces
© 2011 by Taylor and Francis Group, LLC

17-6 
Fundamentals of Industrial Electronics
	
V
I
R
V
V
V
TH
BQ
EQ
BEQ
RE
EE
=
+
+
+
	
(17.14)
If β is large, IEQ is approximately equal to ICQ, so Equation 17.14 can be rewritten as
	
V
I
R
V
I
R
V
TH
BQ
EQ
BEQ
CQ
E
EE
 
=
+
+
+
	
(17.15)
Using the active region equation for IC and IB, Equation 17.15 can be rewritten for IC as
	
V
I
R
V
I
R
V
TH
CQ
EQ
BEQ
CQ
E
EE
=
+
+
+
β
	
(17.16)
Using this equation, ICQ can be found and thereby VOQ. With no load resistor, finding VOQ would fol-
low the same procedure shown in Section 17.2.1. In this example, a load resistor was added to examine 
its impact on the circuit. With the load resistor, VOQ must be found using KCL at the output node as 
follows:
	
I
I
I
RC
CQ
RL
=
+
	
(17.17)
Using Ohm’s law, the equation can be rewritten as
	
V
V
R
I
V
R
CC
OQ
C
CQ
OQ
L
−
=
+
	
(17.18)
Rearranging yields
	
V
R
I
V
R
R
CC
C
CQ
OQ
C
L
−
=
+




1
1
	
(17.19)
Solving for VOQ yields
	
V
V
R
I
R
R
V
R
I
R
OQ
CC
C
CQ
C
L
CC
C
CQ
C
=
−




+



=
−




1
1
1
( /
)
( /
)
(
||
)
RL 	
(17.20)
(c)
IRC
IRL
VRC
VCC
VTH
RC
VEE
VO
RL
REQ
IB
IC
IE
RE
VRE
VBE
+
+
+
+
–
–
–
–
(b)
VCC
VCC
Tev.
Equiv.
RC
VO
RL
RB1
RB2
RE
VEE
VEE
(a)
C
VCC
RC
VO
RL
RB1
RB2
IC
IE
RE
VEE
VEE
VRE
VBE
+
+
–
–
VIN
VCC
FigURE 17.4  DC analysis of common-emitter amplifier with emitter resistor. (a) Shows the complete circuit with 
an input voltage containing both AC and DC components, (b) shows the DC equivalent circuit, and (c) shows the 
Thevenin equivalent circuit of the circuit in (b).
© 2011 by Taylor and Francis Group, LLC

Transistors in Amplifier Circuits 
17-7
17.2.2.2  Implementation Using the pnp
Figure 17.5a shows the same circuit using a pnp. Notice, to achieve the pnp version of the same circuit, 
the npn circuit is flipped vertically and the transistor is replaced with a pnp. Since it is effectively 
the same circuit, the procedure for the circuit analysis is identical to the npn; however, care must be 
given to voltage and current directions. To perform the DC analysis, the DC circuit should be drawn 
(Figure 17.5b), the Thevenin equivalent circuit determined (Figure 17.5c), and then the analysis should 
proceed as follows:
Recall that a positive VEB turns the transistor on and IBQ comes out of the base of a pnp, resulting in a 
voltage drop from the base to VTH. KVL around the input loop produces
	
V
V
V
I
R
V
CC
RE
EBQ
BQ
EQ
TH
−
−
−
=
	
(17.21)
Using the same large β assumption, Equation 17.21 can be rewritten as
	
V
I
R
V
I
R
V
CC
CQ
E
EBQ
CQ
EQ
TH
−
−
−
=
β
	
(17.22)
Once ICQ is calculated, VOQ can be found using KCL at the output node as follows:
	
I
I
I
CQ
RQ
RL
=
+
	
(17.23)
Using Ohm’s law, the equation can be rewritten as
	
I
V
V
R
V
R
CQ
OQ
EE
C
OQ
L
=
−
+
	
(17.24)
Solving for VOQ yields
	
V
I
V
R
R
R
OQ
CQ
EE
C
C
L
=
+



(
||
)
	
(17.25)
VCC
VEE
VTH
REQ
VRE
VEB
VRC
IRC
IRL
–
–
–
+
–
+
+
+
RE
IE
IC
VO
RL
RC
(c)
IB
(b)
VO
VEE VEE
VCC
VCC
RB1
RB2
RE
RL
RC
Thev.
Equiv.
(a)
C
VCC
VEE
VEE
VCC
VIN
RB1
RB2
VRE
VEB
–
–
+
+
RE
IE
IC
VO
RL
RC
FigURE 17.5  DC analysis of pnp common-source amplifier with emitter resistor. (a) Shows the complete circuit 
with an input voltage containing both AC and DC components, (b) shows the DC equivalent circuit, and (c) shows 
the Thevenin equivalent circuit of the circuit in (b).
© 2011 by Taylor and Francis Group, LLC

17-8 
Fundamentals of Industrial Electronics
17.2.3  High-Gain Amplifier with Current Source 
Biasing and Capacitively Coupled Load
17.2.3.1  MOSFET Implementation
The circuit shown in Figure 17.6a is called a common-source amplifier with current source biasing. 
This circuit also solves the parameter variation problem described in Section 17.2.2. In this circuit, the 
current source draws current, pulling charge off the source capacitor to drop VSQ until ISQ = IBIAS. As 
a result, VGSQ is set by the current source. Since the output current is set directly by the bias current, 
and not VGS, the output bias points (IDQ and VOQ) do not strongly depend on the transistor parameters. 
Therefore, the bias point problems associated with parameter variation disappear.
To analyze this circuit, draw the DC circuit as shown in Figure 17.6b. By KCL,
	
I
I
SQ
BIAS
=
Since IDQ = ISQ, for a FET
	
I
I
DQ
BIAS
=
	
(17.26)
Since the load capacitor is an open circuit in the DC condition, VCQ is found in the same manner as 
in Section 17.2.1:
	
V
V
I
R
DQ
DD
DQ
D
=
−
	
(17.27)
Since there is no current going through the load resistor:
	
VOQ
0
=
	
(17.28)
This circuit uses a capacitor to couple VDQ to the load resistor. The advantage of this configuration is that 
VOQ is equal to zero, which means the output will oscillate around zero. Additionally, the load resistor 
does not impact the DC biasing of the amplifier. Any of the previous circuits could use a similar load 
configuration and use the same analysis technique once IDQ has been determined.
17.2.3.2  BJT Implementation
The same circuit can be implemented using a BJT, shown in Figure 17.7a, which is called a common-
emitter amplifier with current source biasing. The circuit in DC configuration is shown in Figure 17.7b. 
The analysis of the circuit is very similar to the FET. By KCL
	
I
I
EQ
BIAS
=
	
(17.29)
(a)
VDD
RD
VD
VO
RL
CL
VGS
VIN
–
+
IBIAS
VSS
CS
VS
IS
(b)
RL
–
+
VDD
RD
VD
VO
IL= 0
IRD
VRD
IBIAS
VSS
IS
ID
FigURE 17.6  DC analysis of common-source circuit with current source biasing. (a) Shows the complete circuit 
with an input voltage containing both AC and DC components and (b) shows the DC equivalent circuit.
© 2011 by Taylor and Francis Group, LLC

Transistors in Amplifier Circuits 
17-9
Since ICQ = αIEQ = (IEQβ)/(β + 1), if β is large, then
	
I
I
CQ
BIAS
≅
	
(17.30)
The collector voltage, VCQ, and output voltage, VOQ, can be found identically to the FET example:
	
V
V
I
R
CQ
CC
CQ
C
=
−
	
(17.31)
	
VOQ = 0 	
(17.32)
17.2.3.3  Current Source Implementation
The current source can be implemented using a transistor biased with input resistors to produce the desired 
current, as shown in Figure 17.8a or a current mirror, shown in Figure 17.8b and c. The output voltage of 
the current mirror, VY in each schematic, would be connected to VS in Figure 17.6 or VE in Figure 17.7.
The circuit in Figure 17.8a uses bias resistors, RG1 and RG2, to set the value of VGS that sets IBIAS. The 
addition of RS is to modify VGS to account for process variations, similar to the emitter resistor in 
Section 17.2.2. These resistors are chosen using the Thevenin equivalent circuit, similar to the analysis 
in Section 17.2.1, except the voltage across RS must also be considered in the input loop:
	
V
I R
V
I R
V
TH
G
TH
GS
S
S
EE
−
−
−
=
	
(17.33)
(a)
VCC
VC
VO
RL
CL
CE
VE
IE
IBIAS
VBE
+
–
VIN
VEE
RC
(b)
VCC
VRC
IRC
VC
VO
RL
IE
IC
IBIAS
+
–
VEE
RC
IL=0
FigURE 17.7  DC analysis of common-emitter amplifier with current source biasing. (a) Shows the complete 
circuit with an input voltage containing both AC and DC components and (b) shows the DC equivalent circuit.
(a)
VEE
VY
RG1
RG2
RS
IBIAS
(b)
RX
VY
VRX
VGS
M1
M2
+
+
–
–
IBIAS
RX
VY
VRX
VBE
Q1
Q2
+
+
–
–
IBIAS
(c)
FigURE 17.8  Current source implementations. (a) Shows the common discrete resistor biasing implementation, 
(b) shows the integrated circuit current mirror implementation with nFETs, and (c) shows the integrated circuit 
current mirror implementation with BJTs.
© 2011 by Taylor and Francis Group, LLC

17-10 
Fundamentals of Industrial Electronics
Since IG = 0 and ID = IS = IBIAS, the equation can be simplified to
	
V
V
I
R
V
TH
GS
BIAS
S
EE
−
−
=
	
(17.34)
Note that one difference between this circuit and the circuits in Sections 17.2.1 and 17.2.2 is that 
the top supply for the bias resistor–voltage divider is connected to ground, not VCC, to minimize 
power consumption. This difference will impact the calculation of the Thevenin equivalent voltage 
as follows:
	
V
V
R
R
R
TH
EE
G
G
G
=
+
1
1
2 	
(17.35)
The current source in Figure 17.8a could be implemented using a MOSFET, BJT, or JFET. Often 
JFETs are used to implement the most accurate current mirrors. The process for designing a JFET 
mirror would be the same as the MOSFET, except the current–voltage relationship for a JFET 
(see Equation 17.36) would be used to find VGS instead of the current–voltage relationship of the 
MOSFET:
	
I
I
V
V
D
DSS
GS
P
=
−




1
2
	
(17.36)
where IDSS and VP are process parameters much like K′ and Vt for a MOSFET.
The current mirror in Figure 17.8b uses RX and a diode-connected transistor (M1) to set the value of 
IBIAS. Because M1 is diode-connected, the current through M1 sets the input voltage, VGS. Since the gates 
of M1 and M2 are connected together and the sources of M1 and M2 are connected to the same voltage 
(VEE), both transistors have the same VGS, which means they will have the same current (e.g., ID1 = ID2 = 
IBIAS). For the current mirror to work properly, the parameters for M1 must be closely matched to M2 so 
that ID1 will equal ID2.
To design this current mirror, choose a value for RX that sets the desired value for IBIAS in M1 as 
follows.
KVL around M1 produces
	
0 −
−
=
V
V
V
RX
GS
EE 	
(17.37)
The value for VGS can be found by knowing ID1, which is equal to IBIAS, and using the MOSFET current–
voltage relationship (ID = (K′/2)(W/L)(VGS − Vt)2) rewritten for VGS:
	
0
2
−
−
′
+





=
I
R
I
K W L
V
V
t
BIAS
D
EE
X
(
/ )
	
(17.38)
Rearranging produces
	
R
V
I
K W L
V
I
X
t
=
−
−
′
(
) +
(
)
EE
D
BIAS
2
(
/ )
	
(17.39)
The MOSFETs in the mirror can also be implemented using BJTs as shown in Figure 17.8c. This cur-
rent mirror acts similar to the FET mirror. RX sets the current through the diode-connected transistor 
(Q1) that sets VBE. Since VBE1 = VBE2, IC1 ≅ IC2 (if base currents are small).
© 2011 by Taylor and Francis Group, LLC

Transistors in Amplifier Circuits 
17-11
A similar analysis can be used to find the value for RX. KVL around Q1 produces
	
0 −
−
=
V
V
V
RX
BE
EE 	
(17.40)
If β is large, base currents are approximately zero and IC1 ≅ IBIAS. Using Ohm’s law on RX results in
	
0 −
−
=
I
R
V
V
BIAS
X
BE
EE 	
(17.41)
Rearranging produces
	
R
V
V
I
X = −
−
EE
BE
BIAS
	
(17.42)
where VBE is the turn-on voltage of the transistor, typically between 0.5 and 0.8 V.
17.2.4  Alternative High-Gain Amplifier
The next example shows another method of creating a high-gain amplifier.
17.2.4.1  MOSFET Implementation
The circuit shown in Figure 17.9a is called a common-gate amplifier. This circuit is similar to the com-
mon-source amplifier with current source biasing, except that gate is held constant while the source 
oscillates. A coupling capacitor, CS, is used to isolate the AC input signal from the DC biasing, which 
is set by the current source. The DC model of this circuit is shown in Figure 17.9b. Notice that the DC 
circuit looks identical to Figure 17.6b, where VD = VO. The analysis is identical to the analysis shown in 
Section 17.2.3. The fundamental differences between the common-source and the common-gate circuits 
will be discussed in the AC section, 17.3.4.
17.2.4.2  BJT Implementation
The circuit shown in Figure 17.10a is called a common-base amplifier, since the base is held constant. 
This circuit structure is the BJT equivalent of the common-gate amplifier. Like the common-gate ampli-
fier, the DC model of the circuit (Figure 17.10b) is identical to the common-emitter amplifier shown in 
Figure 17.7b, except VC = VO. The analysis follows the analysis shown in Section 17.2.3.
(a)
RD
IS
VS
CS
VO
VDD
VSS
VIN
VGS
+
–
IBIAS
(b)
IS
ID
RD
VO
VDD
VRD
IRD
VSS
+
–
IBIAS
FigURE 17.9  DC analysis of common-gate amplifier. (a) Shows the complete circuit with an input voltage con-
taining both AC and DC components and (b) shows the DC equivalent circuit.
© 2011 by Taylor and Francis Group, LLC

17-12 
Fundamentals of Industrial Electronics
17.2.5  Voltage Follower
17.2.5.1  MOSFET Implementation
The final circuit example is a voltage follower, shown in Figure 17.11a. In this circuit, VO follows VIN 
with a DC offset. This circuit is also commonly called a common-drain amplifier, since the drain is held 
constant. The DC configuration of this circuit is shown in Figure 17.11b.
To find the bias points, perform KCL at the output node:
	
I
I
I
I
DQ
SQ
BIAS
L
=
=
+
	
(17.43)
Using Ohm’s law, substitute for IL as follows:
	
I
I
V
R
DQ
BIAS
OQ
L
=
+
	
(17.44)
Find an expression for VOQ using KVL and the FET saturation equation:
	
V
V
OQ
GS
 0
=
−
	
(17.45)
(a)
CE
RC
IE
VE
VO
VCC
VEE
VIN
VBE
+
–
IBIAS
(b)
IC
IE
RC
VO
VCC
VEE
VRC
IRC
+
–
IBIAS
FigURE 17.10  DC analysis of common-base amplifier. (a) Shows the complete circuit with an input voltage 
containing both AC and DC components and (b) shows the DC equivalent circuit.
(a)
RL
IS
VO
VDD
VSS
VIN
VGS
+
–
IBIAS
(b)
RL
IL
IS
VO
VDD
VGS
+
–
VSS
IBIAS
FigURE 17.11  DC analysis of common-drain amplifier. (a) Shows the complete circuit with an input voltage 
containing both AC and DC components and (b) shows the DC equivalent circuit.
© 2011 by Taylor and Francis Group, LLC

Transistors in Amplifier Circuits 
17-13
By rewriting the FET saturation equation as follows:
	
V
I
K W L
Vt
GS
D
=
′
+
2
(
/ )
	
(17.46)
and substituting into Equation 17.45, an expression for VOQ can be found as follows:
	
V
I
K W L
Vt
OQ
DQ
= −
′
+






2
(
/ )
	
(17.47)
This expression for VOQ can substituted into Equation 17.44 to find IDQ as follows:
	
I
I
I
K W L
V
R
t
DQ
BIAS
DQ
L
=
−
′
(
) +
2
(
/ )
	
(17.48)
IDQ can be found using the root function on a calculator or math program or it can be solved iteratively. 
To perform the iterative solution, guess at a value for ID, place it into the right-hand side of the equation. 
Solve for ID. Use this answer as your next guess. Keep repeating this process until the answer converges. 
Since IDQ is under the square root, the equation will converge, and generally does so within a few itera-
tions. Once IDQ is determined, VOQ can be found using Equation 17.47.
17.2.5.2  BJT Implementation
The BJT implementation of the voltage follower, called the common-collector amplifier, is shown in 
Figure 17.12a. Like the FET common-drain amplifier, VO follows VIN with a DC offset. The DC configu-
ration of this circuit is shown in Figure 17.12b.
Like the FET circuit, the bias points are found by performing KCL at the output node:
	
I
I
V
R
EQ
BIAS
OQ
L
=
+
	
(17.49)
Find an expression for VOQ using KVL and the VBE assumption of 0.6–0.8 V:
	
V
V
OQ
BE
 
0.7 V
=
−
≅
0
−
	
(17.50)
Substitute Equation 17.50 into Equation 17.49 to get
	
I
I
R
EQ
BIAS
L
V
=
+ −0 7.
	
(17.51)
(b)
IE
IL
VO
VCC
VBE
+
–
RL
VEE
IBIAS
(a)
RL
IE
VO
VCC
VEE
VIN
VBE
+
–
IBIAS
FigURE 17.12  DC analysis of common-collector amplifier. (a) Shows the complete circuit with an input voltage 
containing both AC and DC components and (b) shows the DC equivalent circuit.
© 2011 by Taylor and Francis Group, LLC

17-14 
Fundamentals of Industrial Electronics
ICQ can be found from IEQ:
	
I
I
R
CQ
BIAS
L
=
+
−




β
β
1
0 7.
	
(17.52)
If β is large, ICQ ≅ IEQ:
	
I
I
R
CQ
BIAS
L
≅
−




0 7.
	
(17.53)
17.3  AC Analysis
17.3.1  Small-Signal Model
Amplification in an amplifier occurs when a small change in the input voltage causes a large change in 
output current. Because the input voltage (VGS for FETs and VBE for BJTs) changes by a small amount, the 
nonlinear I–V relationship (FET square-law, BJT exponential) can be approximated by a linear function. 
As a result, the design and analysis of transistors in amplifier circuits use a linear, “small-signal” model 
to represent the nonlinear “large-signal” model of the transistor. The linear, small-signal models for a 
FET and a BJT are shown in Figure 17.13a and b, respectively.
The input resistance of the transistor, rπ for the BJT, is found by approximating the input I–V rela-
tionship for the BJT as a linear function around the bias point (e.g., taking the derivative of IB versus 
VBE at IBQ) and inverting the result to get a resistance as follows:
	
r
I
V
V
I
π
β
= ∂
∂
=
1
B
BE
T
CQ 	
(17.54)
The input resistance of the FET is infinite since the gate current is zero.
The transconductance of the transistor (how well a change in the input voltage turns into a change in 
output current) is modeled by gm, which is found by approximating the transconductance of the BJT as 
a linear function evaluated at IDQ:
	
g
I
V
K W
L I
mFET
D
GS
D
= ∂
∂
=
′
2
	
(17.55)
	
g
I
V
I
V
mBJT
C
BE
CQ
T
= ∂
∂
=
	
(17.56)
The output resistance of the transistor, modeled by rO, is found by approximating the output 
I–V relationship as a linear function at ICQ and inverting the result to get a resistance. In the ideal 
case, the output current (ID or IC) does not change with output voltage (VDS or VCE). However, due to 
(b)
c
e
b
gmvπ
rπ
rO
vπ
+
–
(a)
d
rO
s
g
gmvgs
vgs
+
–
FigURE 17.13  Small signal model for a FET (a) and a BJT (b).
© 2011 by Taylor and Francis Group, LLC

Transistors in Amplifier Circuits 
17-15
channel-width and base-width modulation, a small linear change in output current is evident for a 
change in output voltage. As a result, the output resistance is finite and evaluated as a function of the 
channel-width/base-width parameters as follows:
	
r
I
V
I
OFET
D
DS
DQ
= ∂
∂
=
1
1
λ
	
(17.57)
	
r
I
V
V
I
OBJT
C
CE
A
CQ
= ∂
∂
=
1
	
(17.58)
This small-signal model is used to find an expression for the AC gain, input resistance, and output 
resistance. The small-signal model of a circuit is drawn using the following rules:
	
1.	 Replace the transistor with the small-signal model. Beginners should label the terminal nodes on 
the small-signal model and on the schematic to keep track of which node goes where in the model.
	
2.	 To find the maximum AC gain or resistance, assume that the circuit is operating at a sufficiently 
high enough frequency to short all capacitors, and a sufficiently low enough frequency that the 
internal device capacitors are still open circuits. Therefore, short all discrete capacitors.
	
3.	 Turn off all DC sources to apply superposition. As stated earlier, voltage sources become short 
circuits (V = 0) and current sources become open circuits (I = 0). Note: this means an “AC ground” 
still has a DC voltage, but the voltage never changes from the DC condition.
	
4.	 Draw all remaining components connected to each node of the transistor model.
The examples in the DC section will be used again to demonstrate the AC analysis. Each example will 
start with a general explanation or intuition of how the circuit produces gain using only the most basic 
circuit analysis and an understanding of how each device operates. Then, the small-signal analysis will 
provide an expression for the gain, which should reinforce the intuition. Input and output resistance 
examples will proceed as well.
17.3.2  High-Gain Amplifier with Input Resistor Biasing
17.3.2.1  MOSFET Implementation
The common-source amplifier with input resistor biasing is shown again in Figure 17.14a. In this circuit, 
the source is held constant by the negative supply. Therefore, any changes to the gate voltage directly 
impact VGS and therefore ID. vIN is coupled onto the gate through the gate capacitor. When vIN increases, 
VGS increases, causing an increase in ID. When vIN decreases, VGS decreases, causing a decrease in ID. An 
increase in ID causes a larger voltage drop across RD, which causes vO to drop. A decrease in ID causes a 
smaller voltage drop across RD, which causes vO to rise. As a result, an increase in vIN causes a decrease in 
vO, resulting in a phase inversion, or negative gain. The final gain depends on three things: (1) how well 
a change in vIN is translated to a change in VGS, (2) how well a change in VGS is translated into a change 
in ID, and (3) how well the change in ID is translated into a change in vO.
Figure 17.14b shows the small-signal model of the common-source amplifier. Both supplies are turned 
off, tying these nodes to ground. As a result, RG1 is in parallel with RG2 from the gate to ground. The input 
capacitor is shorted, connecting vIN to the gate. Since the negative supply is turned off, the source is con-
nected to ground. Since the positive supply is turned off, RD goes from the drain to ground.
Perform circuit analysis to find the desired AC parameter. The AC gain is determined by finding 
vO/vIN. To find the gain, start by finding an expression for vO in terms of known parameters (such as RD, 
gm, rO, RG1, RG2) and vIN. Once an expression is found where every term is a function of vO or vIN, algebraic 
manipulation can provide the gain. The analysis of this circuit proceeds as follows.
© 2011 by Taylor and Francis Group, LLC

17-16 
Fundamentals of Industrial Electronics
Find vO using KCL at vO to get
	
g v
i
i
m gs
RD
+
+
=
rO
0 	
(17.59)
Using Ohm’s law,
	
i
R
RD
O
D
= ν
	
(17.60)
	
i
v
r
rO
O
O
=
	
(17.61)
Substituting Equations 17.60 and 17.61 into Equation 17.59 produces
	
g v
v
R
r
m gs
O
D
O
+
+



=
1
1
0 	
(17.62)
Rearranging yields
	
v
g v
R
r
g v
R
r
O
m gs
D
O
m gs
D
O
= −
+
= −
1
1
1
( /
)
( /
)
(
||
)
	
(17.63)
The only unknown parameter in this equation is vgs. Next, find an expression for vgs. Since RG1 and RG2 
are in parallel with vIN, these resistors do not have an impact on the input voltage. Therefore,
	
v
v
gs
IN
=
	
(17.64)
Substituting Equation 17.64 into Equation 17.63 and solving for vO/vIN provides the gain as follows:
	
A
v
v
g
R
r
V
O
IN
m
D
O
=
= −
(
||
) 	
(17.65)
Note that the final expression of the gain supports the intuitive description provided earlier. The 
gain depended upon three components, all represented in the final gain equation. In this circuit, vIN is 
directly coupled into the gate, therefore vIN = vgs. The parameter gm represents how well a change in vgs 
(b)
RG2
RG1
d
s
vO
g
irO
vIN
rO
RD
iRD
gmvgs
vgs
+
–
(a)
RD
RG2
RG1
C
G
D
S
vO
VDD
VDD
VSS
VSS
vIN
FigURE 17.14  AC analysis of common-source amplifier. (a) Shows the complete circuit and (b) shows the AC 
small-signal model.
© 2011 by Taylor and Francis Group, LLC

Transistors in Amplifier Circuits 
17-17
translates into a change in ID. RD translates the change in ID into a change in vO. Therefore, the gain is a 
function of gm and RD.
The input resistance can be found using the same circuit shown in Figure 17.14b. However, to find an 
expression for this specification, replace vIN with a test voltage, VT, and find the current going through 
the test voltage, IT. An expression for the input resistance is found by solving for VT/IT. The analysis for 
rin follows.
First, simplify the circuit showing parallel resistor combinations (RG1/RG2 and RD/rO), as seen in 
Figure 17.15a.
Find an expression for IT using KCL and Ohm’s law at the input node:
	
I
V
R
R
T
T
G
G
=
1
2
||
	
(17.66)
Rearranging and solving for VT/IT yields
	
r
V
I
R
R
IN
T
T
G
G
=
=
1
2
||
	
(17.67)
The output resistance can be found in similar manner as the input resistance, except the test voltage 
is placed at the output node, as shown in Figure 17.15b, and the input voltage is turned off. The analysis 
for rOUT follows.
Find an expression for IT using KCL as the output node:
	
I
I
g v
V
R
r
g v
R
r
T
m gs
T
D
O
m gs
D
O
=
+
=
+
||
||
	
(17.68)
Since the input voltage is turned off, vg and vs are both tied to ground. Thereby, vgs = 0. As a result, 
gmvgs = 0. Using this relationship, rearranging, and solving for VT/IT yields
	
r
V
I
R
r
OUT
T
T
D
O
=
=
||
	
(17.69)
(a)
d
s
g
RG1||RG2
rO||RD
vT
IT
gmvgs
vgs
+
–
gmvgs
(b)
d
s
g
rO||RD
RG1||RG2
vT
IT
vgs
+
–
FigURE 17.15  AC model for input resistance (a) and output resistance (b) of common-source amplifier.
© 2011 by Taylor and Francis Group, LLC

17-18 
Fundamentals of Industrial Electronics
17.3.2.2  BJT Implementation
The equivalent BJT circuit, the common-emitter amplifier with input resistor biasing, is shown again 
in Figure 17.16a. The basic operation is identical to the FET example. The emitter is held constant by 
the negative supply allowing any changes to the base voltage to directly impact VBE and therefore IC. 
vIN is coupled onto the base through the base capacitor. A change in vIN causes a change in VBE causing 
a change in IC. A change in IC causes a change in voltage across RC, which causes vO to change. Similar 
to the FET circuit, the BJT amplifier will exhibit negative gain; e.g., an increase in vIN will cause an 
increase in IC, which causes a decrease in vO.
Figure 17.16b shows the small-signal model of the common-emitter amplifier. Note that the circuit 
looks identical to the FET small-signal model circuit, except that the transistor model uses the BJT 
small-signal model rather than the FET small-signal model. It is also interesting to note that the only 
significant difference between the FET and BJT small-signal model is the finite input resistance rπ.
Since the FET small-signal model and the BJT small-signal model circuit are so similar, the analysis 
is similar as well. To find the gain, note that RC and rO are in parallel and the current gmvπ runs through 
them. Given the direction that gmvπ goes, the voltage across RC is negative to vO. Evaluate vO as follows:
	
v
g v
R
r
O
m
C
O
= −
(
)
π
||
	
(17.70)
RB1, RB2, and rπ are in parallel with vIN and vπ resulting in
	
ν
ν
π 
IN
=
	
(17.71)
Substituting Equation 17.71 into Equation 17.70 yields the equivalent gain equation as the FET circuit:
	
A
v
v
g
R
r
V
O
IN
m
C
O
=
= −
(
||
) 	
(17.72)
The final expression of the gain for this circuit also supports the intuitive description. The gain 
depends upon how well ΔvIN translates to a ΔVBE, how well ΔVBE translates to a ΔIC (represented in the 
gain equation by gm), and how well a ΔIC translates into a ΔvO (represented in the gain equation by RC).
The simplified small-signal model for the input resistance is shown in Figure 17.17a. The analysis for 
input resistance is very similar to the FET, except the impact of rπ must be accounted for.
Find an expression for IT using KCL and Ohm’s law at the input node:
	
I
V
R
R
r
T
T
B
B
=
1
2
||
|| π 	
(17.73)
(a)
RB1
RB2
C
B
E
C
vO
RC
VCC
vIN
VEE
VEE
VCC
RB1
RB2
(b)
c
e
b
vπ
rπ
Parallel
Parallel
vO
vIN
rO
RC
gmvπ
+
–
FigURE 17.16  AC analysis of common-emitter amplifier. (a) Shows the complete circuit and (b) shows the AC 
small-signal model.
© 2011 by Taylor and Francis Group, LLC

Transistors in Amplifier Circuits 
17-19
Rearranging and solving for VT/IT yields the equivalent rin as the FET circuit with the inclusion of rπ:
	
r
V
I
R
R
r
IN
T
T
B
B
=
=
1
2
||
|| π 	
(17.74)
The small-signal model for the output resistance is shown in Figure 17.17b. Find an expression for IT 
using KCL and Ohm’s law at the output node:
	
I
V
R
r
g v
T
T
C
O
m
=
+
||
π 	
(17.75)
Since vπ = 0, gmvπ = 0. Rearranging and solving for VT/IT yields the same answer found in the FET circuit:
	
r
V
I
R
r
OUT
T
T
C
O
=
=
||
	
(17.76)
The trade-off between the FET and BJT circuits are now evident. Although the gain equations are 
identical for the FET and the BJT, gm for a BJT is typically much larger than the gm for a FET since this 
represents how well a change in input voltage translates to a change in output current. The fact that BJTs 
exhibit an exponential input voltage–output current relationship and FETs exhibit only a square-law 
input voltage–output current relationship typically makes gmBJT > gmFET for the same bias condition. 
However, the input resistance of the FET circuit is typically larger than the input resistance of the BJT 
circuit. RB1 and RB2 are typically chosen to be large values to minimize the power consumption, making 
rπ the dominant resistor in the parallel combination for the BJT. As a result, rin,FET > rin,BJT.
17.3.3  Common-Emitter Amplifier with Emitter Resistor and Load Resistor
17.3.3.1  Implementation Using a npn
The common-emitter amplifier with emitter resistor is shown again in Figure 17.18a. In this circuit, the 
emitter is not held constant, which will hurt the gain since vIN is not directly translated to VBE. However, 
the amount of vIN that is translated to VBE is turned into a voltage gain in the same manner as the 
common-emitter amplifier previously described: the change in VBE causes a change in IC. The change in 
IC causes a change in the voltage across RC. The change in voltage across RC causes a change in vO in the 
opposite direction of vIN.
(a)
c
e
b
rO||RC
RB1||RB2||rπ
vT
IT
gmvπ
vπ
+
–
(b)
c
e
b
rO||RC
RB1||RB2||rπ
vT
IT
gmvπ
vπ
+
–
FigURE 17.17  AC model for input resistance (a) and output resistance (b) of common-emitter amplifier.
© 2011 by Taylor and Francis Group, LLC

17-20 
Fundamentals of Industrial Electronics
Figure 17.18b shows the small-signal model of the common-emitter amplifier with an emitter resistor. 
The circuit looks identical to the previous common-emitter small-signal model circuit with the addition 
of the emitter resistor, RE, between the emitter and ground and the load resistor, RL, between the collec-
tor and ground. Because the change in current due to rO is small compared to the change in current due 
to gmvπ, and the analysis containing rO is significantly more complex and thereby loses intuition, rO will 
be neglected for this analysis.
The output of the circuit is very similar to the previous example. The current gmvπ goes through the 
parallel resistor combination of RC and RL to produce vO. Using KCL at vO and Ohm’s law, the following 
expression for vO can be obtained:
	
v
g v
R
R
O
m
C
L
= −
π(
||
) 	
(17.77)
To complete the gain equation, an expression for vπ must be found in terms of vIN and vO. However, 
the emitter resistor has a significant impact the expression for vπ, since it changes the manner that vIN 
translates into VBE. The analysis at the input node proceeds as follows.
By KVL at the input loop:
	
v
v
v
IN
E
=
+
π
	
(17.78)
An expression for vE can be found using KCL at vE and Ohm’s law:
	
v
r
g v
v
R
π
π
π
+
=
m
E
E 	
(17.79)
Rearranging, solve for vE to get
	
v
R
v
r
g v
E
E
m
=
+




π
π
π
	
(17.80)
(a)
vO
RC
C
VCC
VEE
VEE
VCC
B
E
C
RB1
RB2
vIN
RL
RE
(b)
c
e
b
Parallel
Parallel
RE
RB2
RB1
vπ
rπ
vO
vE
vIN
RC
RL
gmvπ
+
–
FigURE 17.18  AC analysis of common-emitter amplifier with emitter resistor. (a) Shows the complete circuit 
and (b) shows the AC small-signal model.
© 2011 by Taylor and Francis Group, LLC

Transistors in Amplifier Circuits 
17-21
Substituting Equation 17.80 into Equation 17.78 yields
	
v
v
R
v
r
g v
v
R
r
g
IN
E
m
E
m
=
+
+



=
+
+










π
π
π
π
π
π
1
1
	
(17.81)
Dividing Equation 17.77 by Equation 17.81 produces the final gain equation:
	
A
v
v
g
R
R
R
r
g
V
O
IN
m
C
L
E
m
=
=
−
+
+
(
||
)
(( / )
)
1
1
π
	
(17.82)
The final gain equation still depends upon gm and RC because ΔVBE translates to a ΔIC (represented in 
the gain equation by gm) and ΔIC translates into a ΔvO (represented in the gain equation by RC). However, 
because the emitter is not held constant, ΔvIN ≠ ΔVBE. Since a change in IC causes a change in VE through 
RE, the gain drops by (1 + RE (1/rπ + gm)).
The emitter resistor also impacts the input resistance, since rπ is no longer in parallel with RB1 and 
RB2. The simplified small-signal model for the input resistance is shown in Figure 17.19a. The analysis 
proceeds as follows.
Find an expression for IT using KCL and Ohm’s law at the input node:
	
I
V
R
R
v
r
T
T
B
B
=
+
1
2
||
π
π 	
(17.83)
KVL at the input loop provides the exact same expression for vπ that was found in Equation 17.78. 
Using the same analysis performed previously produces the same expression of VT as a function of vπ as 
in Equation 17.81. Rearrange this equation to solve for vπ as a function of VT:
	
v
V
R
r
g
π
π
=
+
+
T
E
m
1
1
(( / )
) 	
(17.84)
(b)
c
e
b
RE
rπ
RB1||RB2
RC||RL
vT
IT
gmvπ
vπ
+
–
(a)
vO
c
e
b
RE
rπ
RB1||RB2
RC||RL
vT
IT
gmvπ
vπ
+
–
FigURE 17.19  AC model for input resistance (a) and output resistance (b) of common-emitter amplifier with 
emitter resistance.
© 2011 by Taylor and Francis Group, LLC

17-22 
Fundamentals of Industrial Electronics
Substitute Equation 17.84 into Equation 17.83 and distribute rπ:
	
I
V
R
R
V
r
R
R r g
T
T
B
B
T
E
E
m
=
+
+
+
1
2
||
π
π
	
(17.85)
This equation can be further simplified by using the following relationship:
	
r g
V
I
I
V
π
β
β
m
t
CQ
CQ
t
=
⋅
=
	
(17.86)
Substituting Equation 17.86 into Equation 17.85 produces the following equation:
	
I
V
R
R
V
r
R
T
T
B
B
T
E
=
+
+
+
1
2
1
||
(
)
π
β 	
(17.87)
Solving for the input resistance results in the following relationship:
	
r
V
I
R
R
r
R
R
R
r
R
B
B
IN
T
T
E
B
B
E
=
=
+
+
+
=
+
1
1
1
1
1
2
1
2
( /(
||
))
( /(
(
)))
||
||[
π
π
β
(
)]
1+ β
	
(17.88)
Although the emitter resistor drops the gain, it increases the input resistance. Since RB1 and RB2 are 
typically chosen to be large resistors to minimize power consumption, (rπ + RE (β + 1)) typically domi-
nates the parallel equation. Recall that the input resistance for the common-emitter amplifier without 
an RE was RB1 ∥ RB2 ∥ rπ ≅ rπ. Therefore, the emitter resistor increases the input resistance by a factor of 
approximately RE (β + 1).
The small-signal model for the output resistance is shown in Figure 17.19b. RB1 and RB2 are shorted 
when the input source is turned off, leaving rπ in parallel with RE. However, voltage changes at vC have 
no impact on vE through the dependent current source, gmvπ, which can have any voltage across it and 
still produce the same current. Therefore, changes in VT will not cause any changes in vπ, resulting in gmvπ = 0. 
The circuit analysis proof of this concept can be found by performing KCL at vE:
	
g v
v
r
R
v
r
R
m
E
E
E
π
π
π
π
=
=
−
||
||
	
(17.89)
Rearranging produces
	
v
g
r
R
π
π
m
E
+





=
1
0
||
	
(17.90)
Since gm + (1/rπ∥RE) represent resistors that cannot be negative, Equation 17.90 can only be true if vπ 
is equal to 0.
With gmvπ = 0, the output resistance follows the following relationship:
	
r
V
I
R
R
OUT
T
T
C
L
=
=
||
	
(17.91)
17.3.3.2  Implementation Using a pnp
The common-emitter amplifier with an emitter resistor implemented with a pnp is redrawn in Figure 
17.20a. This circuit works identically to the npn circuit with voltages and currents reversed. vIN is coupled 
onto the base through the base capacitor. When vIN increases, VEB decreases, causing a decrease in IC. 
© 2011 by Taylor and Francis Group, LLC

Transistors in Amplifier Circuits 
17-23
When vIN decreases, VEB increases, causing an increase in IC. An increase in IC causes a larger voltage drop 
across RC, which causes vO to increase. A decrease in IC causes a smaller voltage drop across RC, which 
causes vO to drop. As a result, an increase in vIN causes a decrease in vO, resulting in a phase inversion, 
or negative gain. Since the emitter is not held constant due to the voltage changes across RE, vIN is not 
directly mapped onto VEB, which causes the gain to decline identically to the npn circuit.
To draw the small-signal mode for the pnp common-emitter amplifier, start with the small-signal mode 
for the BJT (the pnp and the npn small-signal models are identical), as shown in Figure 17.20b. Since VCC 
and VEE are turned off, RB1 and RB2 both go from the base to ground. The capacitor is a short circuit con-
necting vIN to the base. The emitter goes through RE to ground. The collector goes through RC to ground 
and through RL to ground. Notice, the resulting small-signal circuit is identical to the npn small-signal 
circuit. As a result, all small-signal model equations, AV, rin, and rOUT, are identical for npn and pnp circuits.
17.3.4  High-Gain Amplifier with Current Source 
Biasing and Capacitively Coupled Load
17.3.4.1  MOSFET Implementation
The common-source amplifier with current source biasing is shown again in Figure 17.21a. In this cir-
cuit, the source is held constant by the source capacitor, CS. Therefore, any changes to the gate voltage 
correspond directly to VGS and therefore ID. As a result, this circuit operates identically to the common-
source amplifier shown in Section 17.3.2. The gate is tied to vIN. Therefore, a ΔvIN causes a ΔVGS. A ΔVGS 
(a)
C
C
E
B
vO
RE
IC
RC
VCC
VCC
VEE
VEE
RB1
RB2
vIN
RL
(b)
c
e
b
Parallel
Parallel
RE
RB2
RB1
vπ
rπ
vO
vE
vIN
RC
RL
gmvπ
+
–
FigURE 17.20  AC analysis of pnp common-source amplifier with emitter resistor. (a) Shows the complete circuit 
and (b) shows the AC small-signal model.
(a)
D
S
G
IBIAS
RD
RL
CL
CS
vO
VDD
VSS
vIN
(b)
Parallel
d
s
g
vO
vIN
rO
RD
gmvgs
vgs
+
–
RL
FigURE 17.21  AC analysis of common-source amplifier with current source biasing. (a) Shows the complete 
circuit and (b) shows the AC small-signal model.
© 2011 by Taylor and Francis Group, LLC

17-24 
Fundamentals of Industrial Electronics
causes a ΔID. A ΔID causes a ΔVRD, which causes a ΔvO. This circuit exhibits the same phase inversion as 
the common-source amplifier with input resistor biasing.
Figure 17.21b shows the small-signal model of this common-source amplifier. vIN is connected to the 
gate. Since the source capacitor is shorted, the source is connected to ground. Recall that this means VS 
does no change in the AC. It does not mean VS = 0 in the DC. Since the positive supply is turned off, RD 
goes from the drain to ground. Since the load capacitor is shorted, RL is in parallel with RD. The resulting 
circuit is identical to the small-signal model from Section 17.3.2, without RG1 and RG2. Since RG1 and RG2 
have no impact on how vIN is translated to VGS, the gain analysis is identical to Section 17.3.2, with the 
addition of the load resistor that is in parallel with RD and rO. As a result, the AC analysis produces the 
following gain equation:
	
A
v
v
g
R
r
R
V
O
IN
m
D
O
L
=
= −
(
||
||
) 	
(17.92)
The simplified small-signal model for the input resistance is shown in Figure 17.22a. Without any bias 
resistors and an infinite gate resistance, the input resistance for this circuit is infinity:
	
r
V
I
V
IN
T
T
T
=
=
= ∞
0
	
(17.93)
The small-signal model for the output resistance is shown in Figure 17.22b. This circuit is identical 
to the common-source example in Section 17.3.2 and, therefore, produces the exact same output resis-
tance, with the addition of the load resistor in parallel with RD and rO:
	
r
V
I
R
r
R
OUT
T
T
D
O
L
=
=
||
||
	
(17.94)
The advantage of this circuit over the circuits in Sections 17.3.2 and 17.3.3 can now be appreciated. The 
current source biasing eliminates parameter variation while maintaining the largest possible gain and 
input resistance. As a result, this is the fundamental amplifier configuration that is used in integrated 
circuit implementations of amplifiers. However, the current source is difficult to make without matching 
devices. Therefore, discrete implementations may require the circuits from Sections 17.3.2 and 17.3.3.
17.3.4.2  BJT Implementation
The BJT common-emitter amplifier with current source biasing is shown in Figure 17.23a. This circuit 
operation is identical to the FET operation. A ΔvIN causes a ΔVBE, which causes a ΔIC. A ΔIC causes a 
ΔVRC, which causes a ΔvO. The small-signal model for the gain is shown in Figure 17.23b. Since rπ has no 
impact on the translation of vIN to VBE, the final AC gain is identical to the FET:
	
A
v
v
g
R
r
R
V
O
IN
m
C
O
L
=
= −
(
||
||
)
	
(17.95)
(b)
vO d
s
g
gmvgs
rO||RD||RL
vT
IT
vgs
+
–
(a)
vO
d
s
g
gmvgs
rO||RD||RL
vT
IT
vgs
+
–
FigURE 17.22  AC model for input resistance (a) and output resistance (b) of common-source amplifier with 
current source biasing.
© 2011 by Taylor and Francis Group, LLC

Transistors in Amplifier Circuits 
17-25
The simplified small-signal model for the input resistance is shown in Figure 17.24a. The only resis-
tance seen by the source is rπ. This result is actually similar to the input resistance in the circuit in 
Section 17.3.2 since rπ generally dominates the input resistance equation:
	
r
V
I
r
IN
T
T
=
=
π
	
(17.96)
The small-signal model for the output resistance is shown in Figure 17.24b. Since both sides of rπ 
are connected to ground, Vπ = 0, which makes gmVπ = 0. As a result, this circuit is identical to the FET 
example and therefore produces the exact same output resistance:
	
r
V
I
R
r
R
OUT
T
T
C
O
L
=
=
||
||
	
(17.97)
The trade-off between the FET and BJT circuits is identical to the trade-off presented in Section 
17.3.2. Although the FET circuit has a much greater input resistance, the BJT circuit typically has a 
larger gain due to the larger value for gm.
17.3.5  Alternative High-Gain Amplifier
17.3.5.1  MOSFET Implementation
Figure 17.25a shows once again the common-gate, high-gain amplifier configuration. In this circuit, 
changes in vIN are capacitively coupled onto VS. Since VG is held constant, changes in VS are equal 
and opposite in phase to changes in VGS. As a result, the circuit operates identically to the common-
source amplifier shown in Section 17.3.3 without the phase inversion between the input and the output. 
(a)
IBIAS
RL
CL
CE
VE
IE
vO
VCC
VEE
vIN
VBE
RC
VC
+
–
(b)
c
rO
e
b
Parallel
vO
rπ
vIN
RL
RC
gmvπ
vπ
+
–
FigURE 17.23  AC analysis of common-emitter amplifier with current source biasing. (a) Shows the complete 
circuit and (b) shows the AC small-signal model.
(b)
c
e
b
RC||RL
vT
IT
rπ
gmvπ
vπ
+
–
rO
(a)
c
e
b
RC||RL
vT
IT
vπ
rπ
gmvπ
+
–
rO
FigURE 17.24  AC model for input resistance (a) and output resistance (b) of common-emitter amplifier with 
current source biasing.
© 2011 by Taylor and Francis Group, LLC

17-26 
Fundamentals of Industrial Electronics
An increase in vIN causes a decrease in VGS, which causes a large decrease in ID. The decrease in ID causes 
a decrease in VRD, which causes an increase in vO. The in-phase operation of this amplifier is evident as 
a small increase in vIN causes a large increase in vO.
Figure 17.25b shows the small-signal model of the common-gate amplifier. To find the small-signal 
voltage gain for this circuit, first find an expression for vO as follows:
	
v
I
R
O
D
D
= −
⋅
	
(17.98)
ID is found using KCL at the drain as
	
I
g V
v
v
r
D
m
gs
O
IN
=
+
−
0
	
(17.99)
Substituting Equation 17.99 into Equation 17.98 yields
	
v
g V
v
v
r
R
O
m
gs
IN
O
D
= −
+
−



⋅
0
	
(17.100)
Inspection of the small-signal model shows that vIN = −Vgs. Substituting this expression into 17.100 
and rearranging produces
	
v
v
g R
R
r
R
r v
O
IN
m
D
D
D
O
=
+



−
0
0
	
(17.101)
Collecting terms yields
	
v
R
r
v
g
r
R
O
D
IN
m
D
1
1
0
0
+



=
+




	
(17.102)
Equation 17.102 can be used to solve for the small-signal gain of this amplifier as follows:
	
A
v
v
g R
R
r
R
r
V
O
IN
m
D
D
D
=
=
+
+
(
(
/ ))
(
/ )
0
0
1
	
(17.103)
(a)
CS
VDD
RD
vO
ID
VS
VSS
VGS
IBIAS
vIN
+
–
(b)
d
s
g
ID
RD
vO
vIN
rO
gmvgs
+
–
+
–
vgs
FigURE 17.25  AC analysis of common-gate amplifier. (a) Shows the complete circuit and (b) shows the AC small-
signal model.
© 2011 by Taylor and Francis Group, LLC

Transistors in Amplifier Circuits 
17-27
If rO ≫ RD, which is commonly true for good transistors, RD/rO will be very small resulting in the 
typically used approximation for the small-signal gain of the common-gate amplifier:
	
v
v
g R
O
IN
m
D
=
	
(17.104)
This expression of the gain follows the behavioral description provided earlier. Since vIN is equal in 
magnitude to vgs, the only two circuit elements that impact vO are (1) the amount that ID changes as a 
result of changes to vgs (e.g., gm of the transistor) and (2) the amount that vO changes as a result of changes 
to ID (which occurs due to RD).
The simplified small-signal model for the input resistance is shown in Figure 17.26a. The change in 
current due to rO is small compared to the change in current due to gmvgs, and the analysis containing rO 
is significantly more complex and thereby loses intuition, therefore rO will be neglected for this analysis. 
Notice in Figure 17.26a that the input connects directly to the transistor’s transconductor (voltage-gated 
current source) rather than the infinite input resistance of the gate. As a result, the input resistance is 
significantly smaller, as the analysis shows. Using KCL at the source yields
	
I
g v
T
m gs
= −
	
(17.105)
KVL around the input shows
	
v
v
T
gs
= −
	
(17.106)
Substituting Equation 17.106 into Equation 17.105 and solving for the VT/IT provides the standard 
equation for the input resistance:
	
r
v
I
g
in
T
T
m
=
= 1
	
(17.107)
This solution assumes that rO ≫ RD.
The small-signal model for the output resistance is shown in Figure 17.26b. This circuit is identical to 
the common-source example in Section 17.3.2 and therefore produces the exact same output resistance:
	
r
V
I
R
r
OUT
T
T
D
O
=
=
||
	
(17.108)
(b)
d
s
g
rO
RD
gmvgs
IT
vT
vgs
+
–
(a)
d
s
g
RD
gmvgs
vgs
IT
vT
+
–
FigURE 17.26  AC model for input resistance (a) and output resistance (b) of common-gate amplifier.
© 2011 by Taylor and Francis Group, LLC

17-28 
Fundamentals of Industrial Electronics
Although the magnitude of the small-signal gain is identical for the common-source amplifier with 
current source biasing and the common-gate amplifier, the input resistances are significantly different, 
which results in different uses for these two high-gain circuits. To demonstrate the difference in these 
two circuits, a general amplifier model is used, as shown in Figure 17.27. Once the input resistance, small-
signal gain, and output resistance have been determined, any amplifier can be modeled as shown inside 
the box. Figure 17.27a shows a voltage source driving the amplifier. If the voltage source contains any out-
put resistance (which is typical for sensors, previous stage amplifiers, or even test equipment), the input 
voltage to the amplifier (v1) is divided by the source resistor (RS) and the input resistance (rin), as follows:
	
v
V
r
R
r
1 =
+
IN
in
S
in 	
(17.109)
If rin is large, as in the case of the common-source circuit, the signal loss is small. However, if rin is 
small, as in the case of the common-gate circuit, the signal loss can be significant, which can greatly 
reduce the gain of the entire circuit.
On the other hand, if a current source is driving the amplifier, as in Figure 17.27b, the results are dif-
ferent. In this case, the current divides between the source resistance and the input resistance as follows:
	
I
I
R
R
r
1 =
+
in
S
S
in 	
(17.110)
To maximize the amount of current going into the amplifier, rin should be small as in the case of the 
common-gate circuit. Consequently, common-source amplifiers are typically used with voltage inputs 
and common-gate amplifiers are typically used with current inputs.
17.3.5.2  BJT Implementation
The equivalent BJT circuit, the common-base amplifier, is shown again Figure 17.28a. The basic opera-
tion is identical to the common-gate amplifier. Changes in the input voltage, vin, is capacitively cou-
pled onto VE causing VE to oscillate. Since the base is held constant, changes in VE result in changes in 
VBE, equal in magnitude and opposite in phase. If VE decreases, VBE increases, which causes a dramatic 
increase in IC. The increase in IC results in a larger voltage drop across RC, which causes vO to decrease. 
Therefore, a small decrease in vin results in a large decrease in vO, resulting in a positive gain.
(a)
amp model
rin
rin
rO
RS
RL
v1
vIN
AVv1
+
+
–
–
(b)
amp model
rO
RS
RL
iin
AVv1
v1
i1
+
–
+
–
FIGURE 17.27  Impact of small rin on voltage gain (a) versus current gain (b).
© 2011 by Taylor and Francis Group, LLC

Transistors in Amplifier Circuits 
17-29
Figure 17.28b shows the small-signal model for the common-base amplifier. This circuit is identical to 
the small-signal model of the common-gate amplifier, except the inclusion of rπ. As a result, the analysis 
is very similar. An alternative method of performing the same analysis follows. First, find an expression 
for vO using Ohm’s law:
	
v
i
R
O
C
C
= −
⋅
	
(17.111)
ic is found using KCL at the collector as
	
i
g V
v
v
r
c
m
O
IN
=
+
−
π
O
	
(17.112)
Rearranging 17.111 to solve for iC and substituting that result into 17.112 yields
	
−
=
+
−
v
R
g V
v
v
r
O
C
m
O
IN
π
O
	
(17.113)
Inspection of the small-signal model shows that vIN = −vπ. Substituting this expression into 17.113 and 
rearranging produces
	
v
R
r
v
g
r
O
C
O
IN
m
1
1
1
+



=
+




O
	
(17.114)
Solving for the gain produces
	
A
v
v
g
r
R
r
g
r
R
r
V
O
IN
m
O
C
O
m
O
C
O
=
=
+
+
=
+




(
/
)
( /
)
( /
)
||
1
1
1
1
	
(17.115)
If RC ≪ rO, RC will dominate the parallel connection so that RC ∥ rO is approximately equal to RC. 
The gain simplifies to the following expression:
	
v
v
g
r
R
g R
R
r
O
IN
m
O
C
m
C
C
≅
+




=
+
1
O 	
(17.116)
(a)
IC
CE
VE
IBIAS
vO
VCC
VEE
vIN
VBE
RC
+
–
(b)
c
e
b
rO
vO
rπ
vIN
RC
gmvπ
vπ
+
–
FIGURE 17.28  AC analysis of common-base amplifier. (a) Shows the complete circuit and (b) shows the AC 
small-signal model.
© 2011 by Taylor and Francis Group, LLC

17-30 
Fundamentals of Industrial Electronics
Holding the same assumption that RC ≪ rO, RC/rO will be very small, resulting in the typically used 
approximation for the small-signal gain of the common-base amplifier:
	
v
v
g R
O
IN
m
C
=
	
(17.117)
This expression of the gain supports the behavioral description, showing how the gain depends on 
how well the transistor converts a change in voltage into a change in current (gm) and how well the 
change in current is converted into a voltage using RC.
The simplified small-signal model for the input resistance is shown in Figure 17.29a. Like the com-
mon-gate circuit, the change in current due to rO is small compared to the change in current due to 
gmvπ, so rO will be neglected for this analysis to maintain intuition about the circuit. The input of this 
circuit connects to the transistor’s transconductor like the common-gate circuit rather than rπ, so the 
input resistance is expected to be small. The analysis proceeds in a similar manner to the common-gate 
circuit. Using KCL at the source yields
	
I
g v
v
r
T
m
= −
−
π
π
π 	
(17.118)
KVL around the input shows
	
v
v
T = −π 	
(17.119)
Substituting Equation 17.119 into Equation 17.118 produces
	
I
g v
v
r
v
g
r
v g
g r
v g
T
m T
IN
T
m
T
m
m
T
m
=
+
=
+



=
+



=
+


π
π
π
β
1
1
1
1
1
	
(17.120)
Assuming that β is large so that 1/β ≈ 0, the input resistance can be approximated to the same equa-
tion found for the common-gate amplifier:
	
r
v
I
g
in
T
T
m
=
= 1
	
(17.120a)
(a)
c
e
b
iC
IT
vT
rπ
RC
gmvπ
vπ
+
+
–
–
(b)
c
e
b
IT
vT
rO
rπ
RC
gmvπ
vπ
+
–
FIGURE 17.29  AC model for input resistance (a) and output resistance (b) of common-base amplifier.
© 2011 by Taylor and Francis Group, LLC

Transistors in Amplifier Circuits 
17-31
The small-signal model for the output resistance is shown in Figure 17.29b. This circuit is identical to 
the common-emitter example in Section 17.3.2 and therefore produces the exact same output resistance:
	
r
V
I
R
r
OUT
T
T
C
O
=
=
||
	
(17.121)
Just like the common-gate amplifier, the common-base amplifier demonstrates a significantly smaller 
rin than its high-gain counterpart, the common-emitter amplifier. As a result, this circuit is most com-
monly used with current source inputs, as is common with many sensors, for the same reason that was 
presented for the common-gate circuit.
Another use of the common-base amplifier is to obtain higher frequency response. A common-emitter 
amplifier can be combined with a common-base amplifier as shown in Figure 17.30b. To understand 
the high-frequency benefit, a discussion of the frequency limitations of the common-emitter circuit is 
essential. Figure 17.30a shows the common-emitter amplifier with the addition of two parasitic capaci-
tors, Cμ and Cπ. These internal capacitors come from the separation of charge due to the depletion region 
at the p-n junctions of the BJT. At the interface between the n-type emitter and the p-type base, the 
depletion region separates charge creating a junction capacitor (Cπ). Another junction capacitor exists 
at the interface between the p-type base and the n-type collector (Cμ). In AC operation, the transistor 
causes a small change in vIN to result in a large change in vO in the opposite direction. Cμ connects 
between vIN and vO. The large gain of the transistor causes a large voltage difference across the capaci-
tor, Cμ, which makes the capacitor act like it has a larger capacitance (called the Miller effect). A larger 
capacitor results in a smaller pole value, which limits the bandwidth at high frequency.
By combining the common-emitter amplifier with the common-base amplifier as shown in Figure 
17.30b, the Miller effect does not happen. This circuit works by a change in vin, resulting in a change in 
VBE1 since VE is held constant by CE. This change in VBE1 creates a large change in the collector current, 
IC1. By KCL, IC1 = IE2, so Q2 sees the same change in current. Since Q1 and Q2 see approximately the 
same change in current, they must also have the same change in VBE. Therefore, ΔVBE1 = ΔVBE2. Since VC1 
changes equal and opposite vin, the gain VC1/vin = −1. However, the large change in current is turned 
into a voltage by the resistor, RC. The net result is the same gain as a common emitter:
	
A
g R
V
m
C
≅−
	
(17.122)
(b)
VCC
IBIAS
Cµ2
Cµ1
Cπ2
Cπ1
CE
RC
vIN
VDC
vO
VC1
Q1
Q2
VEE
(a)
RC
VCC
IBIAS
Q1
Cµ
Cπ
CE
vO
vIN
VEE
FIGURE 17.30  Use of common-base amplifier for high frequency. (a) Shows intrinsic capacitor components in a 
standard common-emitter amplifier and (b) shows intrinsic capacitor components in a high-frequency common-
emitter amplifier.
© 2011 by Taylor and Francis Group, LLC

17-32 
Fundamentals of Industrial Electronics
The real advantage of this circuit is the improved high-frequency response. The common-emitter 
transistor (Q1) still has the base-collector capacitor, Cμ1, but the gain across the capacitor is −1. Therefore, 
the capacitor does not see a large change in voltage across it, so its value is not effectively increased. 
The junction capacitors around the common-base transistor (Q2) have 1 terminal tied to an AC ground. 
Therefore, they do not see a large voltage across them due to the gain of a circuit either. As a result, all 
poles will be at their highest possible values, resulting in the highest possible frequency response.
17.3.6  Voltage Follower
17.3.6.1  MOSFET Implementation
In the voltage-follower circuit, the output voltage follows the input voltage with the DC offset presented 
in Section 17.2.3, which results in a gain of approximately 1. The purpose of this amplifier is to isolate 
a high-gain stage from a low load resistance, as shown in Figure 17.31. As shown in Sections 17.3.2 and 
17.3.3, a load resistor in the AC model of a high-gain amplifier will be in parallel with the drain 
or collector resistor (RD or RC). If the load resistor is small, the parallel combination will be dominated 
by RL, which can decrease the gain significantly. By placing a voltage follower in between the high-gain 
amplifier and the small load resistor, the high-gain amplifier sees the input resistance of the voltage 
follower as a load, which is significantly higher than the load resistor. Thereby, the high-gain amplifier 
retains its high gain. The voltage follower is biased to provide sufficient current to the load.
The MOSFET version of the voltage follower, the common-drain amplifier, is shown in Figure 17.32. 
The operation of this amplifier can best be understood by looking initially at the circuit with no load 
resistance, as shown in Figure 17.32a. Given the purpose of the voltage follower, this circuit configura-
tion would never occur in reality; however it is easier to see why the circuit obtains unity gain. KCL at 
the output voltage of this circuit indicates that ID must always equal IBIAS even when vIN is oscillating. 
In order to maintain a constant ID, a constant VGS must be maintained. By KVL, vO = vIN − VGS. If VGS is 
constant, vO will follow vIN with a constant DC offset equal to the value VGS. Removing the DC compo-
nent of the signal results in unity AC gain.
Figure 17.32b shows the circuit with the load resistor added. In this circuit, as vO follows vIN, the voltage 
across the load resistor changes, which causes a change in the load current, IL. IS, which equals ID, is the 
sum of IL and IBIAS; therefore, if IL changes, ID must change as well. If ID changes, VGS must also change. 
However, the change in VGS is small due to the square-root relationship between VGS and ID. However, since 
VGS is not perfectly constant, vO does not follow vIN perfectly. As a result, the gain is a little less than 1.
High-gain ampliﬁer
Voltage-follower
Sees inﬁnite RL
IBIAS1
IBIAS2
RL
CS
vO
VDD
VDD
VSS
VSS
vIN
RD
FIGURE 17.31  Behavioral description of the voltage-follower. (a) Shows the behavior without a resistive load, result-
ing in vO following vIN and (b) shows the behavior with a resistive load to exhibit the small loss in small-signal gain.
© 2011 by Taylor and Francis Group, LLC

Transistors in Amplifier Circuits 
17-33
The small-signal model of the common-drain amplifier is shown in Figure 17.33a. vIN is connected 
directly to the gate. Since VDD is turned off, the drain is connected directly to ground. The bias current is 
turned off, resulting in an open circuit. However, the source is connected to ground through RL. Notice 
that vO is at VS, NOT VD as in the previous high-gain circuits.
To find the small-signal gain, first notice that rO and RL are in parallel and redraw the small-signal 
model as in Figure 17.33b. The solution for the AC gain follows.
Find an expression for vO using KCL at vO and Ohm’s law:
	
g v
v
R
r
m gs
O
L
O
=
||
	
(17.123)
An expression is now necessary for vgs as a function of vO or vIN or both. By KVL at the input node,
	
v
v
v
IN
O
gs
−
=
	
(17.124)
Substituting Equation 17.124 into Equation 17.123 yields
	
g
v
v
v
R
r
m
IN
O
O
L
O
(
)
||
−
=
	
(17.125)
Collecting terms for vO and vIN produces
	
g v
v
R
r
g
m IN
O
L
O
m
=
+






1
||
	
(17.126)
(a)
IS= ID
IBIAS
IBIAS
vO
VDD
VSS
vIN
VGS
+
–
(b)
IS
IL
IBIAS
IBIAS
RL
vO
VDD
VSS
vIN
VGS
+
–
FIGURE 17.32  Behavioral description of the voltage-follower. (a) Shows the behavior without a resistive load, result-
ing in vO following vIN and (b) shows the behavior with a resistive load to exhibit the small loss in small-signal gain.
(b)
RL||rO
d
s
g
vO
vIN
gmvgs
vgs
+
–
(a)
Parallel
d
s
g
rO
vO
vIN
RL
gmvgs
vgs
+
–
FIGURE 17.33  Small-signal model of common-drain amplifier. (a) Shows the complete small-signal model of the 
circuit and (b) shows the simplified model.
© 2011 by Taylor and Francis Group, LLC

17-34 
Fundamentals of Industrial Electronics
Solving for voltage gain results in
	
v
v
g
R
r
g
g
R
r
g
R
r
O
IN
m
L
O
m
m
L
O
m
L
O
=
+
=
+
( /(
||
))
(
||
)
(
||
)
1
1
	
(17.127)
If (RL ∥ rO) is large, gm(RL ∥ rO) ≫ 1, and the function approximates to 1. However, as the load resis-
tor decreases, the gain decreases from 1. This follows the intuition described previously, since a smaller 
load resistance will produce a larger change in ID as vO changes, which causes vO to follow vIN less closely.
The small-signal model for the input resistance is shown in Figure 17.34a. Since there is no gate cur-
rent, the input resistance is infinite. This result has a significant impact when it is used in conjunction 
with a high-gain amplifier. Rather than the high-gain amplifier seeing RL as a load, it sees an open cir-
cuit. As a result, the load resistor has no impact on the high-gain amplifier.
The small-signal model for the output resistance is shown in Figure 17.34b. Note that the output of 
this circuit is at VS, not VD, so the test source is placed at VS (see Figure 17.34b). The circuit analysis pro-
ceeds as follows.
RL is still in parallel with rO. To find an expression for IT, use KCL at the output node to get
	
I
g v
v
R
r
T
m gs
T
L
O
+
=
||
	
(17.128)
To get an expression for Vgs, use KVL at the input node to get
	
v
v
gs
T
 
=
−
0
	
(17.129)
Substituting Equation 17.129 into Equation 17.128 yields
	
I
g v
v
R
r
T
m T
T
L
O
−
=
||
	
(17.130)
Collecting terms yields
	
I
v
g
R
r
T
T
m
L
O
=
+






1
||
	
(17.131)
Rearranging produces the output resistance
	
r
V
I
g
R
r
OUT
T
T
m
L
O
=
=
+
1
1( /(
||
)) 	
(17.132)
(b)
vT
d
s
g
IT
rO
RL
vO
gmvgs
vgs
+
–
(a)
d
s
g
vT
IT
RL||rO
vO
gmvgs
vgs
+
–
FIGURE 17.34  AC model for input resistance (a) and output resistance (b) of common-drain amplifier.
© 2011 by Taylor and Francis Group, LLC

Transistors in Amplifier Circuits 
17-35
This equivalent resistance can be rewritten to show a group of parallel resistors as follows:
	
r
g
R
r
g
R
r
OUT
m
L
O
m
L
O
=
+
=
1
1 1
1
1
( /( /
))
( /(
||
))
( /
)||
||
	
(17.133)
17.3.6.2  BJT Implementation
The BJT version of the voltage follower, the common-collector amplifier, is shown in Figure 17.35a. This 
circuit operates on the same principle as the common-drain amplifier, except that vO follows vIN with a 
DC voltage drop of VBE instead of VGS. Similar to the common-drain amplifier, vO follows vIN perfectly if 
IC is held constant, which is true if RL is large. If RL is small, a change in vO causes a change in IRL, which 
changes IC and thereby VBE. However, due to the logarithmic relationship between VBE and IC, the change 
in VBE is small, keeping the gain close to 1.
Figure 17.35b shows the small-signal model for voltage gain. In this circuit, rO is in parallel with RL, 
simplifying the small-signal model as shown in Figure 17.35c. The analysis proceeds as follows.
Find an expression for vO using KCL at vO:
	
v
r
g v
v
R
r
π
π
π
+
=
m
O
L
O
||
	
(17.134)
An expression is now necessary for vπ as a function of vO or vIN or both. By KVL at the input node:
	
v
v
v
IN
O
−
=
π 	
(17.135)
rπ
c
e
b
(c)
vIN
RL||rO
gmvπ
vπ
+
–
(a)
IBIAS
RL
IRL
vO
VCC
VEE
vIN
VBE
+
–
(b)
Parallel
c
e
b
rπ
vIN
gmvπ
vπ
+
–
rO
vO
vO
RL
FIGURE 17.35  AC analysis of common-collector amplifier. (a) Shows the complete circuit, (b) shows the AC 
small-signal model, and (c) shows the simplified small-signal model.
© 2011 by Taylor and Francis Group, LLC

17-36 
Fundamentals of Industrial Electronics
Substituting Equation 17.135 into Equation 17.134 yields
	
v
v
r
g
v
v
v
R
r
IN
O
m
IN
O
O
L
O
−
+
−
=
π
(
)
||
	
(17.136)
Collecting terms for vO and vIN produces
	
v
g
r
v
r
R
r
g
IN
m
O
L
O
m
+



=
+
+






1
1
1
π
π
||
	
(17.137)
To simplify this equation, examine the relationship (gm + 1/rπ) by rewriting 1/rπ as a function of β:
	
g
r
g
g r
g
g
m
m
m
m
m
+
=
+



=
+



≅
1
1
1
1
1
π
π
β
	
(17.138)
Using this simplification and solving for voltage gain results in
	
v
v
g
R
r
g
g R
r
g R
r
O
IN
m
L
O
m
m
L
O
m
L
O
=
+
=
+
( /(
||
))
||
||
1
1
	
(17.139)
This gain equation is identical to the common-drain gain equation and follows the intuition similarly: 
smaller RL results gain less than unity because larger changes in IRL prevent vO from following vIN as well.
The small-signal model for the input resistance, shown in Figure 17.36a, is identical to the small-
signal model for the gain, with vIN replaced with VT. To find the input resistance, find an expression for 
IT using KCL at the input node and apply Ohm’s law:
	
I
v
r
T =
π
π 	
(17.140)
(a)
c
e
b
rπ
vO
IT
vT
RL||rO
gmvπ
vπ
+
–
c
e
b
(b)
Parallel
rO
rπ
vO
IT
vT
RL
gmvπ
vπ
+
–
c
e
(c)
vO
IT
vT
RL||rπ||rO
gmvπ
vπ
+
–
FIGURE 17.36  AC model for input resistance (a) and output resistance (b and c) of common-collector amplifier. 
(c) is a circuit simplification of part (b).
© 2011 by Taylor and Francis Group, LLC

Transistors in Amplifier Circuits 
17-37
From Equation 17.140, it is evident that an expression for vπ is necessary. Obtain this using KCL at 
the output node:
	
v
r
g v
v
R
r
π
π
π
+
=
m
O
L
O
||
	
(17.141)
While the test current could be written as a function of VT − vO or simply as IT, circuit simplifications 
will often result if the current is left in terms of vπ. Since vO is not a parameter in the input resistance, 
an expression for vO must be found and substituted into Equation 17.141. The expression for vO can be 
found by using KVL across rπ:
	
v
V
v
O =
−
T
π 	
(17.142)
Substituting Equation 17.142 into Equation 17.141 yields
	
v
r
g v
V
v
R
r
π
π
π
π
+
=
−
m
T
L
O
||
	
(17.143)
Rearranging produces
	
v
r
g
R
r
V
R
r
π
π
1
1
+
+





=
m
L
O
T
L
O
||
||
	
(17.144)
which can be used to solve for VT as follows:
	
v
R
r
r
g
V
π
π
(
||
)
L
O
m
T
1
1
+



+





=
	
(17.145)
Rearranging Equation 17.140 and substituting into Equation 17.145 yields
	
I r
R
r
r
g
V
T
L
O
m
T
π
π
(
||
) 1
1
+



+





=
	
(17.146)
Solving for rin results in
	
r
V
I
r
R
r
r
g
R
r
r g
r
IN
T
T
L
O
m
L
O
m
=
=
+



+





=
+
+
π
π
π
(
||
)
(
||
)(
)
1
1
1
π
π
β
=
+
+
(
||
)(
)
R
r
r
L
O 1
	
(17.147)
While this input resistance is not as large as the common-drain circuit, it is approximately β times 
larger than the load resistance. If β is large, say 100, the common-collector amplifier will make the load 
seen by the high-gain amplifier appear 100 times larger, preventing the drop in gain due to the small 
load resistor.
The small-signal model for the output resistance is shown in Figure 17.36b. In this circuit, rπ is in 
parallel with RL and rO, which is redrawn in Figure 17.36c. The analysis proceeds in a similar manner as 
the common-drain amplifier as follows.
© 2011 by Taylor and Francis Group, LLC

17-38 
Fundamentals of Industrial Electronics
Finding an expression for IT using KCL at the output node produces
	
I
g v
V
R
r
r
T
m
T
L
O
+
=
π
π
||
||
	
(17.148)
Using KVL and Ohm’s law,
	
νπ = −vT 	
(17.149)
Substituting Equation 17.149 into Equation 17.148 yields
	
I
g v
V
R
r
r
T
m T
T
L
O
−
=
||
||
π
	
(17.150)
Collecting terms results in
	
I
v
g
R
r
r
T
T
m
L
O
=
+






1
||
||
π
	
(17.151)
Rearranging produces the output resistance:
	
r
V
I
g
R
r
r
g
R
r
r
OUT
T
T
m
L
O
m
L
O
=
=
+
=
+
1
1
1
1 1
1
( /(
||
||
))
( /( /
))
( /(
||
||
)
π
π
)
( /
)||
||
||
= 1 g
R
r
r
m
L
O
π
	
(17.152)
This result is similar to the common-drain amplifier, with the exception that the equivalent resistance 
is also in parallel with rπ.
17.4  Swing: Putting AC and DC Together
Another key specification in amplifier operation is the largest output amplitude that the amplifier can 
produce while still producing a sinusoidal output wave. This parameter is called swing. The maximum 
swing depends on how far the output can swing while keeping the transistor in the current saturating 
region (e.g., FET = saturation region, BJT = active region). As a result, neither the AC nor DC compo-
nents can be ignored in this analysis.
If the input is pushed too high or too low, the output will stop changing as a sinusoid, resulting in 
some of the sinusoid clipped off. This phenomenon, called “clipping,” is shown in Figure 17.37a. If the 
transistor is pushed out of the current saturating region, clipping will occur. An explanation for clip-
ping in a high-gain amplifier is presented graphically in Figure 17.37b. This figure presents IC as a func-
tion of VCE for different values of VBE. Each curve represents the output current for a different value of 
VBE. A change in VIN causes a change in VBE, causing the amplifier to move from one curve to the next. 
However, the resistor transfers the change in current into a change in voltage, which causes the value 
for VCE to change as demonstrated by the line across the curves. Since the gain is negative, VCE decreases 
as VIN increases, which is shown by the negative slope of the line. As the input changes sinusoidally, the 
output moves along this line. If the change in VBE is large enough, the transistor will either (1) be pushed 
into the saturation region (A), where a change in VBE no longer produces a linear change in current or 
(2) be turned off (B), where a change in VBE produces zero current. In either case, a further change in VBE 
does not change VO, so the output appears clipped.
© 2011 by Taylor and Francis Group, LLC

Transistors in Amplifier Circuits 
17-39
In all cases, swing can be calculated as the worst-case condition between the maximum the output 
can swing relative to the bias point versus the minimum the output can swing relative to the bias point. 
This concept is presented graphically in Figure 17.38 and mathematically below:
	
V
V
V
SWING
OMAX
OQ
+
=
−
	
(17.153)
	
V
V
V
SWING
OQ
OMIN
−
=
−
	
(17.154)
The worst-case swing is the minimum between Equations 17.153 and 17.154. Even though the circuit 
may have the potential to swing higher in one direction (positive in Figure 17.38), the swing will clip 
on the other side (negative in Figure 17.38) before the potential is met. Therefore, the minimum swing 
limits the total swing. Although Equations 17.153 and 17.154 are consistent for every circuit, the calcula-
tion of VOQ, VOMAX, and VOMIN differ for every circuit. Therefore, several examples will demonstrate the 
calculation of swing using different transistor types and different load conditions.
0 s
0.5 ms
1.0 ms
1.5 ms
2.0 ms
2.5 ms
3.0 ms
–2.0 V
0 V
2.0 V
4.0 V
6.0 V
8.0 V
Clipping
VO
Time
(a)
0 V
1 V
2 V
3 V
4 V
5 V
6 V
7 V
8 V
9 V
10 V
0 A
1.0 mA
2.0 mA
IC
3.0 mA
4.0 mA
5.0 mA
B–Q turned oﬀ
Increasing VBE
A–Q saturated
VCE
(b)
FIGURE 17.37  Amplifier clipping. (a) Shows how the clipping will appear on the output in the time-domain and 
(b) shows the transistor characteristic curves to demonstrate regions of operation that can cause clipping.
© 2011 by Taylor and Francis Group, LLC

17-40 
Fundamentals of Industrial Electronics
17.4.1  High-Gain Amplifier with Input Resistor Biasing
17.4.1.1  MOSFET Implementation
The common-source amplifier with input resistor biasing is shown in Figure 17.39. In order to determine 
the swing, an expression for VOQ, VOMAX, and VOMIN must be obtained. An expression for VOQ was found 
in Section 17.2.1 and is repeated here for convenience:
	
V
V
I R
OQ
DD
D
D
=
−
	
(17.155)
The value for VOMAX is found by determining which condition, the transistor saturating or the transis-
tor turning off, limits the current (see Figure 17.39a). Due to the negative gain, VO increases when VIN 
decreases. Therefore, VOMAX will occur when VIN goes so low that the transistor turns off causing ID = 0. 
If ID = 0, the voltage across RD = 0, resulting in
	
V
V
OMAX
DD
=
	
(17.156)
0 s
0.5 ms
1.0 ms
1.5 ms
2.0 ms
2.5 ms
0 V
VSWING
VSWING
VOMIN
VOMAX
VOQ
15.5 V
12.0 V
VO
8.0 V
4.0 V
–2.0 V
3.0 ms
Time
+
–
FIGURE 17.38  Amplifier swing.
(a)
RG1
RG2
C
Small
ID=0
VDD
VDD
VSS
VSS
VIN
VGS
+
–
VO
RD
(b)
RG1
RG2
C
VDS= VDS,SAT
VDD
VDD
VSS
VSS
VIN
+
–
VO
RD
FIGURE 17.39  Swing in a common-source amplifier. (a) Shows the impact on VO when VIN is decreasing and 
(b) shows the impact on VO when VIN is increasing.
© 2011 by Taylor and Francis Group, LLC

Transistors in Amplifier Circuits 
17-41
The value of VOMIN (see Figure 17.39b) is found by determining which condition limits the current 
when VIN increases causing VO to decrease. VO can decrease until the transistor is pushed into the linear 
region and starts to clip. The limiting case is at the edge between the linear region and saturation region: 
VDS,SAT. Note: we normally do not know the value for VDS, except in this minimum condition. By KVL, 
VOMIN can be found relative to the negative supply.
	
V
V
V
V
V
V
OMIN
SS
DS,SAT
SS
GSQ
t
=
+
=
+
−
(
)	
(17.157)
With Equations 17.155 through 17.157, the maximum swing can be determined. The maximum swing 
will be
	
V
V
V
V
V
I R
I R
SWING
OMAX
OQ
DD
DD
D
D
D
D
+
=
−
=
−
−
=
(
)
	
(17.158)
	
V
V
V
V
I R
V
V
SWING
OQ
OMIN
DD
D
D
SS
DS,SAT
−
=
−
=
−
−
+
(
)
(
) 	
(17.159)
The smallest value calculated from Equations 17.158 and 17.159 will determine the maximum swing 
possible for the amplifier for a given bias point. The largest possible swing will occur if VOQ is biased 
exactly in between VOMAX and VOMIN.
17.4.1.2  BJT Implementation
Figure 17.40 demonstrates the BJT implementation of the same circuit, the common-emitter amplifier 
with input resistor biasing. The output loop of this circuit is identical to the FET equivalent circuit; 
therefore, the swing analysis is identical, except VCE,SAT is used rather than VDS,SAT. As a result, the final 
swing equations are
	
V
V
V
V
V
I R
I R
SWING
OMAX
OQ
CC
CC
C
C
C
C
+
=
−
=
−
−
=
(
)
	
(17.160)
	
V
V
V
V
I R
V
V
SWING
OQ
OMIN
CC
C
C
SS
CE,SAT
−
=
−
=
−
−
+
(
)
(
) 	
(17.161)
The maximum swing is the minimum value of Equations 17.160 and 17.161. Like the FET circuit, 
maximum swing will occur when VOQ is at the midpoint between VOMAX and VOMIN. However, looking 
(a)
C
IC=0
VO
VEE
VEE
VIN
VBE
RC
RB1
RB2
VCC
VCC
+
–
(b)
C
VCE= VCE,SAT
VO
VEE
VEE
VIN
RC
RB1
RB2
VCC
VCC
+
–
FIGURE 17.40  Swing in a common-emitter amplifier. (a) Shows the impact on VO when VIN is decreasing and 
(b) shows the impact on VO when VIN is increasing.
© 2011 by Taylor and Francis Group, LLC

17-42 
Fundamentals of Industrial Electronics
at the gain equation from Section 17.3.2, if RC ≪ rO (which is typically true), the gain equation can be 
approximated as follows:
	
A
g R
I R
V
V
m
C
C
C
T
= −
= −
	
(17.162)
Given this equation, the maximum gain occurs with a maximum value for ICRC. The bias point equa-
tion (17.13) reveals that a larger gain, requiring a larger ICRC, occurs simultaneously with a lower bias 
point, VOQ. Once VOQ drops below the midway point between VOMAX and VOMIN, there is a trade-off 
between gain and swing (e.g., to get a larger gain, maximum swing must drop).
17.4.2  High-Gain Amplifier with Input Resistor Biasing and a Resistive Load
The same circuit in Figure 17.39 is presented in Figure 17.41 using a pFET and a load resistor. Without 
the load resistor, the analysis would be identical to Section 17.4.1, except VOQ would be relative to the 
negative supply, and the VOMAX and VOMIN equations would be swapped. However, the load resistor 
changes VOQ and VOMIN. This example is presented to understand how the p-type device and load resis-
tor impacts the analysis. The analysis proceeds as follows.
As presented in Section 17.2.2, VOQ with a load resistor is determined by KCL at the output node:
	
I
V
V
R
V
R
D
OQ
SS
D
OQ
L
=
−
+
	
(17.163)
Rearranging produces
	
V
I
V
R
R
R
OQ
D
SS
D
D
L
=
+



(
||
)
	
(17.164)
VOMAX (see Figure 17.41a) occurs when VIN is decreasing, which increases VSG, so the transistor is not turning 
off to clip. However, as VO increases due to negative gain, the transistor may be pushed into the linear region 
causing the output voltage to clip. Therefore, the limiting case occurs when VSD = VSD,SAT as follows:
	
V
V
V
V
V
V
OMAX
DD
SD,SAT
DD
SG
t
=
−
=
−
−
(
) 	
(17.165)
(a)
C
RD
RL
RG1
RG2
VDD
VDD
VSS
VSS
VIN
VST=VST,SAT
VO
+
–
(b)
C
RD
RL
RG1
RG2
VDD
VDD
VSG
VSS
VSS
VIN
ID=0
VO
+
–
FIGURE 17.41  Swing in a pFET common-source amplifier with a load resistor. (a) Shows the impact on VO when 
VIN is decreasing and (b) shows the impact on VO when VIN is increasing.
© 2011 by Taylor and Francis Group, LLC

Transistors in Amplifier Circuits 
17-43
VOMIN (see Figure 17.41b) occurs when VIN is increasing, which decreases VSG, potentially causing the 
transistor to turn off. If the transistor turns off, ID = 0. However, unlike the previous example, even if ID = 0, 
there is still current flowing through RD and RL. If ID = 0, RD and RL are left in series, so the expression 
for VOMIN can be found using a voltage divider between RD and RL as follows:
	
V
V
R
R
R
OMIN
SS
L
D
L
=
+



	
(17.166)
Using the expressions in Equations 17.164 through 17.166, the final swing equations are evaluated as 
follows:
	
V
V
V
V
V
I
V
R
R
R
SWING
OMAX
OQ
DD
SD,SAT
D
SS
D
D
L
+
=
−
=
−
−
+




(
)
(
||
)
	
(17.167)
	
V
V
V
I
V
R
R
R
V
R
R
R
SWING
OQ
OMIN
D
SS
D
D
L
SS
L
D
L
−
=
−
=
+




−
+




(
||
)
	
(17.168)
If RD is significantly larger than RL, the load resistor can severely limit the allowable swing in addi-
tion to dropping the gain. The benefit of placing a voltage follower in between the high-gain stage 
and a small load resistor, which allows the high-gain stage to see a larger load resistor, is once again 
evident.
17.4.3  High-Gain Amplifier with Current Source Biasing 
and Capacitively Coupled Resistive Load
17.4.3.1  MOSFET Implementation
The common-source amplifier with a current source bias is shown in Figure 17.42. In addition to 
demonstrating the impact of the current source on the swing, this section will also demonstrate 
the analysis for a capacitively coupled resistive load. Due to the load capacitor, VOQ does not equal 
VDQ. However, in the AC case, VD is equal to VO. If VD clips, VO will clip. If VD does not clip, VO will 
not clip. In the previous two sections, this difference was easily extracted apart using superposition. 
However, in the case of swing, the AC and DC must be considered simultaneously. Clearly, the bias 
points will be different as demonstrated in Section 17.2.3. However, in the minimum and maximum 
swing case, the circuit is in AC, so the drain sees the impact of the load resistor. In summary, in the 
DC case, VD ≠ VO. In the AC case, VD = VO. In swing, the AC and DC must be added back together, 
resulting in VOQ changing identically to VDQ, but maintaining a DC offset. To include both the AC 
and DC components in the swing analysis, VDQ and VOQ must be found in the DC case, with the 
capacitor acting as an open circuit. The difference between VDQ and VOQ is the voltage stored across 
the capacitor. VDMAX and VDMIN are found in the AC case, assuming that the capacitor is a short 
circuit. VOMAX and VOMIN will be expressed as VDMAX and VDMIN minus the voltage stored across the 
capacitor.
The bias points for this circuit were found in Section 17.2.3 with the following result:
	
V
V
I R
DQ
DD
D
D
=
−
	
(17.169)
	
VOQ
V
= 0
	
(17.170)
© 2011 by Taylor and Francis Group, LLC

17-44 
Fundamentals of Industrial Electronics
The voltage stored across the capacitor is found by
	
V
V
V
V
CAP
DQ
OQ
DQ
=
−
=
	
(17.171)
Since this amplifier exhibits negative gain, the value for VDMAX is found when VIN is decreasing, turn-
ing the transistor off (Figure 17.42a). Therefore, VDMAX is found when ID = 0. At peak swing, VD sees the 
impact of the load. Since ID = 0, RD is in series with RL and VDMAX is found from a voltage divider:
	
V
V
R
R
R
DMAX
DD
L
D
L
=
+



	
(17.172)
VOMAX is found by subtracting the voltage stored across the capacitor from VDMAX:
	
V
V
V
V
V
OMAX
DMAX
CAP
DMAX
DQ
=
−
=
−
	
(17.173)
The value of VDMIN is found when VIN is increasing (Figure 17.42b). VDMIN drops until the transistor 
is pushed into the linear region, causing the output to clip. Recall that the capacitor holds the source 
at a constant DC voltage. Therefore, the transistor is pushed into the linear region when VD is within a 
VDS,SAT from VSQ:
	
V
V
V
DMIN
SQ
DS,SAT
=
+
	
(17.173a)
VSQ is found from the DC circuit, where VIN is turned off and VG = 0. KVL around the input loop produces
	
V
V
V
V
SQ
G
GS
GS
=
−
= −
	
(17.174)
Recall the definition of VDS,SAT from Chapter F12:
	
V
V
V
DS,SAT
GS
t
=
−
	
(17.175)
Substituting Equations 17.174 and 17.175 into Equation 17.173 yields
	
V
V
V
V
V
DMIN
GS
GS
t
t
= −
+
−
= −
(
)
(
)
	
(17.176)
(a)
IBIAS
RL
CL
CS
VO
VD
ID= 0
VDD
VSS
VIN
VGS
RD
+
+
–
–
(b)
IBIAS
RL
CL
CS
VS=–VGS
VDD
VSS
VIN
RD
VGS
VDS,SAT
+
+
–
–
VO
VD
+
–
FIGURE 17.42  Swing in a common-source amplifier with current mirror biasing and a capacitively coupled 
resistive load. (a) Shows the impact on VO when VIN is decreasing and (b) shows the impact on VO when VIN is 
increasing.
© 2011 by Taylor and Francis Group, LLC

Transistors in Amplifier Circuits 
17-45
To obtain VOMIN, subtract the voltage stored across the load capacitor to get
	
V
V
V
V
V
V
V
OMIN
DMIN
CAP
DMIN
DQ
t
DQ
=
−
=
−
= −
−
	
(17.177)
Using the expressions in Equations 17.170, 17.173, and 17.177, the final swing equations are evaluated 
as follows:
	
V
V
V
V
R
R
R
V
V
V
R
R
R
V
SWING
OMAX
OQ
DD
L
D
L
DQ
OQ
DD
L
D
L
DQ
+
=
−
=
+
−



−
=
+
−




	
(17.178)
	
V
V
V
V
V
V
V
V
SWING
OQ
OMIN
OQ
t
DQ
t
DQ
−
=
−
=
−−
−
=
+
+
(
)
0
	
(17.179)
One of the limitations of the current source biasing becomes evident from this analysis. Although the 
circuit eliminates the impact of process variation, since VSQ is close to ground, the swing is limited to 
approximately half the difference in supply voltages.
17.4.3.2  BJT Implementation
The same circuit implemented with a BJT, the common-emitter amplifier with a current source bias, is 
shown in Figure 17.43. Since the load resistor is attached through a capacitor, the analysis will proceed in 
a similar manner as the FET example. The minimum and maximum swing will be found for VC assum-
ing the AC condition and then the minimum and maximum of VO will be found by subtracting the DC 
voltage stored across the capacitor.
The bias points for this circuit were found in Section 17.2.3 with the following result:
	
V
V
I R
CQ
CC
C
C
=
−
	
(17.180)
	
VOQ
 V
= 0
	
(17.181)
The voltage stored across the capacitor is found by
	
V
V
V
V
CAP
CQ
OQ
CQ
=
−
=
	
(17.182)
(b)
RL
RC
IBIAS
CL
CE
VE= –VBE
VCC
VEE
VIN
VBE
VCS,SAT
+
+
–
–
–VO
VC
(a)
IC= 0
RC
IBIAS
RL
CL
CE
VCC
VEE
VIN
+
VBE
+
–
–VO
VC
FIGURE 17.43  Swing in a common-emitter amplifier with current mirror biasing and a capacitively coupled resis-
tive load. (a) Shows the impact on VO when VIN is decreasing and (b) shows the impact on VO when VIN is increasing.
© 2011 by Taylor and Francis Group, LLC

17-46 
Fundamentals of Industrial Electronics
The value for VCMAX is found when the transistor is turning off (Figure 17.43a). Therefore, VCMAX is 
found from a voltage divider:
	
V
V
R
R
R
CMAX
CC
L
D
L
=
+



	
(17.183)
VOMAX is found by subtracting the voltage stored across the capacitor from VCMAX:
	
V
V
V
OMAX
CMAX
CQ
=
−
	
(17.184)
The value of VCMIN (Figure 17.43b) is found when the transistor is pushed into the saturation region. 
Therefore, VCMIN is found when VC is within a VCE,SAT from VEQ:
	
V
V
V
CMIN
EQ
CE,SAT
=
+
	
(17.185)
VEQ is found from the DC circuit, where VIN is turned off and VB = 0. KVL around the input loop produces
	
V
V
V
V
EQ
B
BE
BE
=
−
= −
	
(17.186)
Substituting Equation 17.186 into Equation 17.185 and using the standard values for VBE and VCE,SAT yields
	
V
V
V
CMIN
BE
CE,SAT
V
V
V
= −
+ (
) = −
+
= −
(
)
.
.
.
0 7
0 2
0 5
	
(17.187)
To obtain VOMIN, subtract the voltage stored across the load capacitor to get
	
V
V
V
V
OMIN
CMIN
CQ
CQ
V
=
−
= −
−
0 5.
	
(17.188)
Using the expressions in Equations 17.181, 17.184, and 17.188, the final swing equations are evaluated 
as follows:
	
V
V
V
V
R
R
R
V
V
V
R
R
R
V
SWING
OMAX
OQ
CC
L
D
L
CQ
OQ
CC
L
D
L
CQ
+
=
−
=
+
−



−
=
+
−




	
(17.189)
	
V
V
V
V
V
V
SWING
OQ
OMIN
OQ
CQ
CQ
−
=
−
=
−−
−
=
+
+
(
.
)
.
0 5
0
0 5
	
(17.190)
The maximum swing would be the minimum of Equations 17.189 and 17.190. These results are very 
similar to the FET circuit.
17.4.4  Swing Nonlinearity
The swing results assume that the transistor is behaving linearly all the way to the point of maximum 
swing. However, these equations often overestimate the swing since the small-signal model often breaks 
down at the large input values required to reach maximum swing. The small-signal model assumes that 
the input voltage (VGS or VBE) is changing with an amplitude that is small enough to approximate the 
nonlinear input–output characteristic equation (ID − VGS for FETs and IC − VBE for BJTs) as a linear line. 
Maximum output swing requires a larger input voltage, which may cause the input to swing beyond the 
linear approximation (see Figure 17.44a). As a result, a linear change in VIN causes a nonlinear change 
in ID or IC, resulting in a nonlinear change in VO. This effect is exaggerated in the BJT. As VIN increases, 
IC increases exponentially rather than linearly. This nonlinear relationship results in an expansion of VO 
when VO goes negative (see Figure 17.44b). As VIN decreases by an equal amount, IC does not decrease 
linearly, causing a compression of the VO waveform when VO goes positive. As a result, the waveform 
is not exactly sinusoidal. Due to the expansion of VO on the negative side and the compression of VO 
© 2011 by Taylor and Francis Group, LLC

Transistors in Amplifier Circuits 
17-47
on the positive side, the output voltage will often clip on the negative side before the positive side can 
reach the expected swing. Many amplifiers will exhibit nonlinearity before they clip. Although some 
applications will still work with the harmonic distortion that this nonideal waveform introduces, some 
applications require a pure sinusoid, which may further limit the maximum swing.
17.5  Design Example
This section will walk through the process of designing an amplifier. The equations derived in the previ-
ous sections will be used for the purposes of meeting a design specification.
17.5.1  High-Gain Amplifier with Input Resistor Biasing
Figure 17.45 shows the schematic of a common-source amplifier using a pFET. Design this amplifier to 
produce AV > 150 and swing >6 V. Assume K′(W/L) = 10 mA/V2, |Vt| = 1 V, and λ = 0.01.
(a)
500 mV
550 mV
600 mV
650 mV
700 mV
750 mV
800 mV
850 mV
900 mV
0 A
50 mA
100 mA
150 mA
32 mA: compression of IC
44 mA: expansion of IC
ICQ
VBE
IC
(b)
Time
0 s
0.5 ms
1.0 ms
1.5 ms
2.0 ms
2.5 ms
3.0 ms
2 V
4 V
6 V
8 V
10 V
12 V
VOQ
VO
FIGURE 17.44  Swing nonlinearity. (a) Shows the nonlinear change in IC as VBE changes linearly which causes the 
output swing characteristic shown in (b).
© 2011 by Taylor and Francis Group, LLC

17-48 
Fundamentals of Industrial Electronics
The gain and the swing determine a range of VOQ values that will allow the amplifier to meet the 
specifications. Start by using these equations to determine the allowable range of VOQ.
The swing constraints can be determined as follows. First, find a value for VOMAX and VOMIN.
VOMAX occurs when VO swings high enough to push the transistor into the saturation region:
	
V
V
V
V
V
V
OMAX
DD
SD SAT
DD
SGQ
t
 
 
 
 
=
−
=
−
−
,
(
) 	
(17.191)
VOMIN occurs when VEB goes small enough to turn the transistor off and sets ID = 0:
	
V
V
OMIN
SS
=
	
(17.192)
VOQ can be set to any value that is 6 V less than VOMAX or 6 V greater than VOMIN (see Figure 17.46):
	
V
V
V
V
V
SS
OQ
DD
SGQ
t
6 V
6 V
+
<
<
−
+
−
[
]
	
(17.193)
This inequality can be rewritten for IDRD using the equation for VOQ. Using Ohm’s law across RD, VOQ 
is written as
	
V
V
I R
OQ
SS
D
D
=
+
	
(17.194)
RG1
RG2
VO
RD
C
VSS
VIN
VSS
VDD
VDD
FIGURE 17.45  pFET common-source amplifier design problem.
VOMIN
VOMAX
Room to swing high
Room to swing low
Possible values 
for VOQ
FIGURE 17.46  Swing conditions for design problem.
© 2011 by Taylor and Francis Group, LLC

Transistors in Amplifier Circuits 
17-49
Substitute Equation 17.194 into Equation 17.193 and rearrange to get an expression for IDRD:
	
V
V
I R
V
V
V
SS
SS
D
D
DD
SGQ
t
V
6 V
+
<
+
<
−
+
−
6
	
(17.195)
	
6
2
6
V
V
D
D
DD
D
SS
<
<
−
′
+
−
−








I R
V
I
K W L
V
V
t
/
	
(17.196)
Choosing supply voltages as ±12 V and substituting in the transistor parameters yields
	
6
17
20
2
V
mA/V
D
D
D
<
<
−
I R
I
	
(17.197)
Lower supplies will use less power, but limit the gain and/or swing.
The gain equation will set the next constraint on IDRD, and thereby VOQ. Figure 17.47 shows the small-
signal model for the circuit, which looks just like the equivalent nFET circuit shown in Section 17.3.1. 
Since this is a design problem, simplify the circuit by removing rO. Typically, RD ≪ rO, so RD dominates 
the gain equation. However, if this simplification is made, the design must beat, not barely meet, the gain 
specification, or rO will pull the gain below the requirement.
The gain analysis results in the following equation:
	
A
g R
R
K W
L I
V
m
D
D
D
= −
= −
′
>
2
150
	
(17.198)
Rearranging and substituting in the parameters yields
	
R
I
K W L
D
D >
′
=
150
2
1060
/
	
(17.199)
By multiplying both sides of the equation by ID, Equation 17.199 can also be written as
	
R I
I
D D
D
>1060
	
(17.200)
Using Equations 17.197 and 17.200, a value for ID can be chosen and a value for RD can be determined 
that satisfies both equations. Since the circuit is unloaded, the choice of a smaller ID consumes less 
power, increases rO, minimizing its impact on the gain, and provides a higher gain. However, if the 
circuit has a load resistor, RD should be chosen to be less than the load resistor, if possible, to minimize 
the impact of the load resistor on gain and VOMIN. Choose ID = 100 μA to maximize gain and minimize 
power. Solving Equation 17.200 yields
	
R I
D D
10.6 V
>
	
(17.201)
d
s
vO
RG1
RG2
g
rO
VIN
RD
gmvgs
vgs
+
–
FIGURE 17.47  Small-signal circuit of pFET common-source amplifier.
© 2011 by Taylor and Francis Group, LLC

17-50 
Fundamentals of Industrial Electronics
The gain equation places a tighter constraint on the lower bound of IDRD. To satisfy both gain and 
swing, use a combination of Equations 17.197 and 17.201, resulting in the following:
	
10 6
16 9
.
.
V
 V
D
D
<
<
I R
	
(17.201a)
Choose a value for IDRD within the range and solve for RD. Try not to choose a value too close to either 
bound. If the choice is too close to the gain boundary (10.6 V), rO may keep the amplifier from meeting 
the gain specification. If the choice is too close to the upper boundary, any nonlinearity on the swing 
may cause clipping. Choose IDRD = 14 V. Since ID = 100 μA, RD = 140 kΩ.
Now that the values for ID and VOQ have been determined to meet the specifications, the input bias 
network must be designed to obtain the desired ID. Performing the analysis presented in Section 17.2.2 
yields the following design equation:
	
V
V
V
V
I
K W L
V
TH
DD
SG
DD
D
t
=
−
=
−
′
+






/
	
(17.202)
Solving for VTH yields
	
VTH
V
A
mA/V
V
=
−
+





=
12
100
10
1
10 9
2
µ
.
	
(17.203)
The design equation to find the input resistors from the Thevenin equivalent voltage was derived in 
Section 17.2.2 and shown here:
	
V
V
R
R
R
V
R
R
R
TH
DD
G
G
G
SS
G
G
G
=
+
+
+
2
1
2
1
1
2 	
(17.204)
Since the gate voltage is close to the top supply, choose a large resistive value for RG2, which also mini-
mizes DC power consumption, and solve for RG1. Choose RG2 = 100 kΩ.
	
11
12
100
100
12
100
1
2
1
V
V
k
k
V
k
G
G
G
=
+
−
+
Ω
Ω
Ω
R
R
R
	
(17.205)
Solve for RG1 = 4.8 kΩ.
The design is complete. Using the analysis equations, verify the results meet specification. Eliminate 
approximations for the verification.
Bias points:
	
VTH
V
k
k
k
V
k
k
k
=
+
−
+
=
12
100
100
4 8
12
4 8
100
4 8
10 9
Ω
Ω
Ω
Ω
Ω
Ω
.
.
.
.
	
I
K W
L V
V
D
SG
T
mA/V
V
V
A
=
′
−
=
−
−
=
(
)
(
.
)
2
2
2
10
12
10 9
1
100 µ
	
V
V
I R
OQ
SS
D
D
V
A
k
V
=
+
= −
+
Ω=
12
100
140
2
(
)(
)
µ
© 2011 by Taylor and Francis Group, LLC

Transistors in Amplifier Circuits 
17-51
Gain – be sure to include the impact of rO to make sure the amplifier will meet the gain specification 
with this parameter included:
	
A
g R
r
V
m
D
O
k
A
mA/V
A
= −
= −




||
|| ( .
)(
)
(
)(
)
140
1
0 01 100
2 10
100
2
Ω
µ
µ
=
>
173
150
Swing:
	
V
V
V
V
V
OMAX
DD
SD,SAT
SG
t
V
V
=
−
=
−
−
(
) =
−
−
−
=
12
12
12
10 9
1
10 9
(
.
)
.
	
V
VSS
OMIN
V
=
= −12
	
VSWING
V
+
=
−
=
10 9
2
8 9
.
.
	
VSWING
V
−
=
−−
=
2
12
14
(
)
	
Max swing
V
V
=
>
8 9
6
.
Design meets all specifications. The design should be simulated, particularly for swing, to make sure 
that nonlinearity of the transistor does not prevent the design from meeting the specifications.
17.5.2  High-Gain Amplifier with Current Mirror Biasing 
and Voltage Follower
Figure 17.48 shows the schematic of a common-emitter amplifier driving a voltage follower. Design this 
amplifier to produce AV >200 and swing > 5 V. Assume β = 100, VBE = 0.7 V, VCE,SAT = 0.2 V, and VA = 75.
The design process for this circuit is very similar to the previous circuit. One primary difference is 
the impact of voltage follower on the common-emitter amplifier. Since the voltage follower has a gain of 
RL=1kΩ
Q1
Q2
Common-emitter
Voltage-follower
IBIAS1
IBIAS2
CE
VO
VCC
VCC
VEE
VEE
VIN
RC
VC
FIGURE 17.48  Two-stage amplifier design problem.
© 2011 by Taylor and Francis Group, LLC

17-52 
Fundamentals of Industrial Electronics
approximately 1, the common-emitter amplifier must meet both the gain and swing specification on its 
own. The input resistance of the voltage follower acts like a resistive load to the common-emitter ampli-
fier. Section 17.3.5 showed that the input resistance of a common-collector amplifier is approximately 
βRL. Therefore, the circuit can be simplified to a common emitter driving a load = 100(1 kΩ) = 100 kΩ.
Similar to the previous example, the gain and swing set a range for VCQ that will allow the amplifier to 
meet the specifications. Both gain and swing must be looked at simultaneously to make sure that both 
specifications are met.
The swing for this circuit was derived in Section 17.4.3. VCMAX is found when VIN is so low that the 
transistor is turned off setting IC1 = 0. The resulting circuit yields a voltage divider between RC and RL, 
where RL = rin of the voltage follower = rINVF = 100kΩ.
	
V
V
r
R
r
CMAX
CC
INVF
C
INVF
=
+
	
(17.206)
VCMIN is found when the transistor is pushed into the saturation region. The emitter capacitor holds 
the emitter at the bias point, resulting in the following equation for VCMIN:
	
V
V
V
V
V
CMIN
EQ
CE,SAT
BE
CE,SAT
 
V
=
+
=
−
+
= −
+
= −
(
)
.
.
.
0
0 7
0 2
0 5
	
(17.207)
To achieve the 5 V swing, VOQ must be at least 5 V below VCMAX and 5 V above VCMIN, resulting in the 
following inequality:
	
(
.
)
CC
−
+
<
<
+
−




0 5
5
5
V
V
V
CQ
INVF
C
INVF
V
V
r
R
r
	
(17.208)
VCQ was derived in Section 17.2.2 for a load resistor using KCL at the output node:
	
V
V
R
I
V
r
CC
CQ
C
Q
CQ
INVF
−
=
+
C1
	
(17.209)
which can be rearranged to produce
	
V
V
R
I
R
r
CQ
CC
C
C Q
C
INVF
=
−




1
(
||
)
	
(17.210)
The gain for this circuit was derived in Section 17.3.5 and found to be
	
A
g R
r
r
V
m
C
O
INVF
= −
||
||
	
(17.211)
To simplify the design equation, assume that rO ≫ RC to make the gain equation:
	
A
g R
R
I
V
R
r
V
m
C
L
C Q
T
C
INVF
= −
= −
>
||
||
1
200
	
(17.212)
Rearranging and substituting VT = 26 mV yields
	
I
R
r
V
C1Q
INVF
T
 V
C ||
.
(
) >
=
200
5 2
	
(17.213)
© 2011 by Taylor and Francis Group, LLC

Transistors in Amplifier Circuits 
17-53
Using Equations 17.208, 17.210, and 17.213, a range of VCQ values that satisfies both swing and gain 
can be found. However, these equations cannot be solved simply in their current form. To simplify the 
equations, a value for RC is chosen first. To keep the load resistor from dropping the gain and VOMAX 
high, choose a value of RC that is less than rINVF. If possible, without producing an RC value that is too low 
and thereby an IC that is too high, choose RC = rINVF/10. Given the value of rINVF, this relationship results 
in an RC = 10 kΩ. Assume the supplies are connected to ±15 V. If the design results in a wide range for 
VCQ, a lower rail may be chosen. Using these chosen values in Equations 17.208, 17.210, and 17.213 yields 
the following equations:
	
4.5 V
8.6 V
CQ
<
<
V
	
(17.214)
	
V
V
R
I
R
R
I
CQ
CC
C
C Q
C
L
C Q
13.6 V
9.1 k
=
−




=
−
⋅
I
I
(
||
)
Ω
	
(17.215)
	
ICIQ
9.1 k
5.2 V
*
Ω>
	
(17.216)
Combining Equations 17.214 through 17.216 results in
	
4 5
13 6
9 1
8 6
.
.
.
*
.
V
V
k
V
CIQ
<
Ω
<
−
I
	
(17.217)
Rearranging provides a limit on ICIQ:
	
1
0 549
mA
mA
CIQ
>
>
I
.
	
(17.218)
Rearranging Equation 17.216 results in the gain constraint on IC1Q:
	
ICIQ
mA
> 0 571
.
	
(17.219)
The gain further constrains the swing inequality, so the final inequality that satisfies both gain and 
swing follows:
	
1
0 571
mA
mA
CIQ
>
>
I
.
	
(17.220)
Choosing a value of ICIQ within the inequality and using RC = 10 kΩ will set a value for VCQ that meets 
both swing and gain. To ensure that rO will not cause the gain to fall under the specification and to 
ensure that nonlinear swing will not cause VC to clip, choose a value near the center of the range. Choose 
ICIQ = 0.75 mA. To set ICIQ = 0.75 mA, choose IBIAS1 = 0.75 mA.
To complete the design, IBIAS2 must be chosen so that VO can swing 5 V. When VO is positive, Q2 pro-
vides current to the load. When VO is negative, the load current is supplied by IBIAS2. The value of IBIAS2 
must be chosen to bring the output voltage negative. In order to determine the most negative value 
for VO, a value for VOQ must be found. The value of VOQ is found by KVL from VCQ to VOQ through the 
transistor:
	
V
V
V
OQ
CQ
BE
=
−
	
(17.221)
Using Equation 17.215, VCQ can be determined and then VOQ:
	
V
V
R
I
R
R
CQ
CC
C
C Q
C
L
V
=
−




=
I
(
||
)
.6 8
	
(17.222)
© 2011 by Taylor and Francis Group, LLC

17-54 
Fundamentals of Industrial Electronics
By Equation 17.221:
	
VOQ
V
=
−
=
6 8
0 7
6 1
.
.
.
	
(17.223)
Given that VO must swing 5 V, VOMIN can be found by
	
V
V
OMIN
OQ
V
V
V
V
=
−
=
−
=
5
6 1
5
1 1
.
.
In this case, VO never goes negative for the 5 V swing, so IBIAS2 can be chosen to be any value that will 
turn Q2 on. I will choose IBIAS2 = 100 μA to save power. However, if VOMIN had been negative, IBIAS2 should 
have been set to a value large enough to sink the current necessary to bring VO down to the negative 
value. The minimum current necessary to do this is
	
I
V
R
BIAS2MIN
OMIN
L
= −
	
(17.224)
Often, the final value is chosen to be a factor of 2 larger than Equation 17.224 to give headroom.
One final consideration is to ensure that ICIQ is large enough that it will not be swamped by IB2. If IB2 
is approximately the same as ICIQ, then much of the change in IC due to a change in VIN will be lost to IB2, 
causing the swing to be nonlinear. A rule of thumb is to ensure that ICIQ > 10 * IB2. In this circuit,
	
I
I
B
BIAS
A
A
2
2
100
100
1
=
=
=
β
µ
µ
	
ICIQ
mA
IB
A
=
>
=
0 75
10
2
100
.
(
)
µ
The design is complete. Using the circuit components chosen, ensure that the circuit meets the speci-
fications. Minimize the use of assumptions when verifying the answers.
Bias points:
	
I
I
CQ
BIAS1
mA
=
= 0 75
.
	
VCQ
V
= 6 8.
Gain:
AV = AV1 * AV2; where the input resistance of stage 2 = the load of stage 1
	
A
g
R
R
r
V
m
C
L
O
mA
mV
k
k
mA
1
0 75
26
10
100
75
0 75
=
=






(
||
||
)
.
||
|| .
Ω
Ω
= 240
From the gain equation in Section 17.3.4,
	
A
g
R
r
g
R
r
V
m
L
O
m
L
O
A
mV
k
A
2
1
100
26
1
75 100
1
=
+
=
+
(
||
)
(
||
)
(
/
)(
||(
/
))
µ
µ
Ω
(
/
)(
||(
/
))
.
100
26
1
75 100
0 793
µ
µ
A
mV
k
A
Ω
=
AV = AV1 * AV2 = 240 * 0.793 = 190, which is less than the required gain.
The gain specification was not met due to the impact of rO and the gain on the voltage follower being a 
good bit less than 1. To solve this problem, either the value of ICIQ must be raised to increase the gain or 
the gain of the voltage follower must be improved. Since ICIQ has such a tight constraint, improving the 
voltage follower gain will be investigated initially.
© 2011 by Taylor and Francis Group, LLC

Transistors in Amplifier Circuits 
17-55
To improve the gain of the voltage follower, increase the value of IBIAS2. If the load current is too large 
compared to the bias current, changes in VO cause significant changes in IC2, which prevents VBE from 
remaining constant. Increasing IBIAS2 will improve this situation. Increase IBIAS2 = 500 μA and recalculate:
	
A
g
R
r
g
R
r
V
m
L
O
m
L
O
A
mV
k
A
2
1
500
26
1
75 500
1
=
+
=
+
(
||
)
(
||
)
(
/
)(
||(
/
))
µ
µ
Ω
(
/
)(
||(
/
))
.
500
26
1
75 500
0 95
µ
µ
A
mV
k
A
Ω
=
AV = AV1 * AV2 = 240 * 0.95 = 228, which is greater than 200
Swing:
	
V
V
R
R
R
CMAX
CC
L
C
L
V
k
k
k
V
=
+



=
+





=
15
100
10
100
13 6
Ω
Ω
Ω
.
	
V
V
CMIN
SS
V
=
= −0 5.
	
VSWING
V
6.1 V
V
+
=
−
=
13 6
7 5
.
.
	
VSWING
V
V
−
=
−−
=
6 1
0 5
6 6
.
(
. )
.
	
Max swing
V
V
=
>
6 6
5
.
, which is
All specifications are now met. Again, the circuit should be simulated to ensure that transistor non-
linearity does not compromise the swing specification.
© 2011 by Taylor and Francis Group, LLC

18-1
18.1  Introduction
The traditional approach to the small-signal analysis of transistor amplifiers employs the transistor 
models with dependent sources, illustrated in Figure 18.1, for both the metal-oxide-silicon (MOS) and 
bipolar junction transistor (BJT) devices [1,2,4].
In this chapter, techniques for the analysis of transistor circuits will be demonstrated without the use 
of a small-signal equivalent circuit containing dependent sources [3]. Because of the similarities inher-
ent in the two circuit configurations shown in Figure 18.1, the following analyses will address both MOS 
and BJT devices in unison.
As a general rule, the small-signal parameters are calculated as a function of the transistor currents. 
In view of that fact, consider now each type of device.
18.1.1  MOS Transistors
In this case,
	
r
g
I K
m
m
D
=
=
1
1
2
	
(18.1)
where ID is the drain biasing current
	
 K
C
W
L
K W
L
ox
=
=
′
µ
	
(18.2)
18
A Simplistic Approach 
to the Analysis of 
Transistor Amplifiers
18.1	 Introduction.....................................................................................18-1
MOS Transistors  •  Bipolar Junction Transistors
18.2	 Calculating Biasing Currents.........................................................18-3
18.3	 Small-Signal Analysis.....................................................................18-6
Common-Source and Common-Emitter Configurations  •   
Common-Drain and Common-Collector Configurations  •   
Common-Gate and Common-Base Configurations
18.4	 Circuits with PNP and PMOS Transistors................................18-13
18.5	 Analysis of Circuits with Multiple Transistors.........................18-15
References...................................................................................................18-20
Bogdan M.
Wilamowski
Auburn University
J. David Irwin
Auburn University
© 2011 by Taylor and Francis Group, LLC

18-2 
Fundamentals of Industrial Electronics
where
K is the transconductance parameter for a specific transistor with channel length L and channel 
width W
K′ is a parameter that characterizes the fabrication process and is the same for all transistors in the 
circuit
The output resistance is given by the expression
	
r  =
V
I
I
o
DS
D
D
( / )
1
1
λ
λ
+
≈
	
(18.3)
where the λ parameter describes the slope of the transistor output characteristics.
18.1.2  Bipolar Junction Transistors
In this case,
	
r
g
V
I
m
m
T
C
=
=
1
	
(18.4)
and
	
r
rm
π
β
=
+
(
)
1
	
(18.5)
where
IC is the collector biasing current
VT is the thermal potential that is equal to about 25 mV at room temperature, as indicated by the 
expression
	
V
kT
q
T =
≈25 mV 	
(18.6)
The output resistance is
	
r
V
V
I
V
I
o
A
CE
C
A
C
=
+
≈
|
|
	
(18.7)
where VA represents the Early voltage that characterizes the slope of the bipolar transistor’s output 
characteristics.
(a)
(b)
D
S
ro
iD=gmvGS=
+
–
vGS
vGS
rm
B
C
E
ro
rπ
iC= gmvBE=
+
–
vBE
vBE
rm
Figure 18.1  Small signal equivalent models for: (a) MOS transistor and (b) BJT transistor.
© 2011 by Taylor and Francis Group, LLC

A Simplistic Approach to the Analysis of Transistor Amplifiers 
18-3
18.2  Calculating Biasing Currents
With MOS transistors, it is assumed that the device operates in the current saturation region. In this 
region, where VDS > VGS − Vth, the drain current is given by the expression
	
I
K
K W
L
D =
=
′
2
2
2
2
∆
∆
	
(18.8)
where “Δ” = VGS − Vth indicates the amount by which the control voltage VGS exceeds the threshold 
voltage Vth.
Example 18.1
Consider the following circuit with the specified parameters (Figure 18.2).
Assuming the gate current is negligible, the gate voltage can be determined from the voltage divider 
consisting of the resistors R1 and R2. Thus, VG can be calculated as
	
V
R
R
R V
G
DD
=
+
=
2
1
2
1V
	
(18.9)
	
K
K W
L
=
′
=1
2
mA/ V
	
(18.10)
	
∆=
−
=
−
−
=
V
V
V
V
V
GS
th
G
S
th
0 4. V 	
(18.11)
Therefore, the biasing drain current is
	
I
K
D =
=
2
80
2
∆
µA 	
(18.12)
When the MOS transistor has a series resistor, RS, connected to the source, determination of the biasing 
drain current is slightly more complicated. Therefore, this situation is analyzed in Example 18.2.
R1
RD
R2
1 MΩ
4 MΩ
VDD=5 V
30 kΩ
W
L
= 20
K΄= 50 μA/V2
Vth= 0.6 V
Figure 18.2  Circuit for Example 18.1.
© 2011 by Taylor and Francis Group, LLC

18-4 
Fundamentals of Industrial Electronics
Example 18.2
The primary difference between this case and the previous one is the presence of RS (Figure 18.3).
Once again, using the voltage divider consisting of R1 and R2, the gate voltage VG can be found from 
the expression
	
V
R
R
R V
G
DD
=
+
=
2
1
2
2 V
	
(18.13)
	
K
K W
L
=
′
=1
2
mA/V
	
(18.14)
and by definition
	
∆=
−
=
−
−
V
V
V
V
V
GS
th
G
S
th 	
(18.15)
Employing Ohm’s law and using (18.8) yields
	
V
I R
K
R
S
D
S
S
=
= 2
2
∆
	
(18.16)
Combining Equations 18.15 and 18.16 produces
	
∆
∆
=
−
−
V
K
R
V
G
S
th
2
2
	
(18.17)
which can be written as
	
KR
V
V
S
G
th
2
0
2
∆
∆
+
−
−
=
(
)
	
(18.18)
This is a quadratic equation, the solution of which is
	
∆= −±
+
−
1
1 2KR V
V
KR
S
G
th
S
(
)
	
(18.19)
R2
R1
RD
RS
2 MΩ
10 kΩ
30 kΩ
3 MΩ
VDD=5V
W
L = 20
–—
K΄= 50 μA/V2
Vth= 0.6 V
Figure 18.3  Circuit for Example 18.2.
© 2011 by Taylor and Francis Group, LLC

A Simplistic Approach to the Analysis of Transistor Amplifiers 
18-5
Since Δ must be positive, then
	
∆=
+
−
−
(
) =
+ ⋅
−
(
) =
1
1 2
1
1
10
1 2 10 1 4
1
0 43385
KR
KR V
V
S
S
G
th
(
)
( . )
.
V
	
(18.20)
and thus the drain current is
	
I
K
I
V
V
R
D
D
G
th
S
=
=
=
−
−
=
2
96 615
96 615
2
∆
∆
.
.
µ
µ
A
or
A 	
(18.21)
Other methods could be used to solve the quadratic equation; e.g., ID or VS could serve as unknowns. 
However, in these cases, it would be difficult to decide which root is the correct answer. This problem 
does not arise when Δ is selected as the unknown.
Consider now determining the biasing currents for BJTs. In this case, a different tack is needed and will 
be demonstrated in Example 18.3. The following assumptions are usually made:
	
VBE ≈0 7. V 	
(18.22)
	
I
I
C
B
= β
	
(18.23)
	
I
I
E
C
≈
	
(18.24)
Example 18.3
A BJT common-emitter circuit is shown in Figure 18.4, together with 
the transistor parameters.
First of all, it is assumed that the base current is negligible and the 
base voltage VB can be determined using the voltage divider consisting 
of R1 and R2. This assumption yields the following voltages and currents:
	
V
R
R
R V
B
CC
=
+
=
2
1
2
3 V
	
(18.25)
	
V
V
V
E
B
BE
=
−
=
−
=
3
0 7
2 3
.
. 	
(18.26)
	
I
I
V
R
V
R
C
E
E
E
B
E
≈
=
=
−
=
0 7
1
.
mA 	
(18.27)
It is important to note that with this approximate approach, the 
current gain β is not needed. In situations where this approxima-
tion does not hold, i.e., the base current cannot be neglected, then 
the resistor divider of Figure 18.4 must be replaced by the Thevenin 
equivalent circuit, shown in Figure 18.5, where
	
R
R
R
R R
R
R
V
R
R
R V
TH
TH
CC
=
=
+
=
+
1
1 2
1
2
2
1
2
||
and
	
(18.28)
Applying Kirchhoff’s voltage law to the circuit in Figure 18.5 yields 
the equation
	
V
R I
V
I R
TH
TH B
BE
E
E
=
+
+
	
(18.29)
R2
R1
60 kΩ
30 kΩ
2.3 kΩ
RE
RC
5 kΩ
VCC=9 V
VT =25 mV
β=100
Figure 18.4  Circuit for Example 
18.3.
RTH
RE
VTH
+
–
RC
3 V
20 kΩ
2.3 kΩ
5 kΩ
β=100
VCC=9 V
VT =25 mV
Figure 18.5  Equivalent circuit 
for Example 18.3.
© 2011 by Taylor and Francis Group, LLC

18-6 
Fundamentals of Industrial Electronics
Using Equations 18.22 through 18.24, Equation 18.29 can be rewritten as
	
I
V
R
R
C
TH
TH
E
=
−
+
=
0 7
0 92
.
(
/ )
.
β
mA
	
(18.30)
18.3  Small-Signal Analysis
Given the transistor currents, the small-signal parameters rm and ro can be determined using Equations 
18.1 and 18.3 for MOS transistors and Equations 18.4 and 18.7 for bipolar transistors. MOS transis-
tors can operate in one of three configurations: CS—common source, CD—common drain, and 
CG—­common gate. In a similar manner, bipolar transistors operate in one of the following three con-
figurations: CE—common emitter, CC—common collector, and CB—common base. These different 
configurations will now be analyzed.
18.3.1  Common-Source and Common-Emitter Configurations
Figure 18.6 illustrates a transistor in the common-emitter configuration. The biasing current for this 
structure was determined in Example 18.3. An inspection of the circuit indicates that the incremental 
collector/emitter current ΔiC can be found from Ohm’s law as
	
∆
∆
i
v
r
R
C
in
m
E
=
+
	
(18.31)
Furthermore, this incremental current, ΔiC, will create an incremental output voltage of
	
∆
∆
v
i R
out
C
C
= −
	
(18.32)
Substituting Equation 18.30 into Equation 18.32 yields
	
∆
∆
v
v
R
r
R
out
in
C
m
E
= −
+
	
(18.33)
Therefore, the voltage gain of this single stage amplifier is
	
A
v
v
R
r
R
V
out
in
C
m
E
=
= −
+
∆
∆
	
(18.34)
R2
RE
rm
VCC
Δvout
Δvin
R1
RC
Figure 18.6  Small signal analysis of common emitter amplifier.
© 2011 by Taylor and Francis Group, LLC

A Simplistic Approach to the Analysis of Transistor Amplifiers 
18-7
If the transistor circuit of Figure 18.6 is modified to contain the additional elements shown in 
Figure 18.7, then Equation 18.31 must be modified as follows:
	
∆
∆
i
v
r
R
R
C
in
m
E
E
=
+
||
2 	
(18.35)
and the effective load resistance would be the parallel combination of RC and RL. As a consequence, the 
new form for Equation 18.32 is
	
∆
∆
v
i
R
R
out
C
C
L
= −
(
)
||
	
(18.36)
and the transistor voltage gain is
	
A
v
v
R
R
r
R
R
V
out
in
C
L
m
E
E
=
= −
+
∆
∆
||
||
2 	
(18.37)
At this point, it is important to note that the traditional lengthy derivation of the gain, which 
employs the transistor model with a dependent current source as shown in Figure 18.1b, yields the 
voltage gain AV:
	
A
g
R R
R
R
g
R R
R
R
V
m
C
L
C
L
m
E
E
E
E
= −
+
+
+
(
)
(
)
1
2
2 	
(18.38)
which is, of course, the same as Equation 18.36. If circuit configuration has an additional series base 
resistance, RB, then Equation 18.35 should be rewritten as
	
∆
∆
i
v
R
r
R
R
C
in
B
m
E
E
=
+
+
(
/ )
||
β
2 	
(18.39)
and then
	
A
v
v
R
R
R
r
R
R
V
out
in
C
L
B
m
E
E
=
= −
+
+
∆
∆
||
(
/ )
||
β
2 	
(18.40)
RE
RL
VCC
RC
R1
R2
RE2
rm
Δvin
Figure 18.7  Small signal analysis of the modified common emitter amplifier.
© 2011 by Taylor and Francis Group, LLC

18-8 
Fundamentals of Industrial Electronics
In the foregoing analysis, the transistor output resistance roo was ignored. If this output resistance should 
be included in the calculations, then Equation 18.36 must be slightly modified to include it as follows:
	
A
v
v
R
R
r
r
R
R
V
out
in
C
L
oo
m
E
E
=
= −
+
∆
∆
||
||
||
2 	
(18.41)
The calculation of roo is relatively complicated and requires the use of the traditional small-signal analy-
sis using dependent sources. Figure 18.8 provides the results of this analysis in which slightly different 
equations must be used for bipolar and MOS transistors. The output resistance of the BJT with RS con-
nected to its emitter is
	
r
r
r R
r
r
R
r
r
R
r
r
oo
o
o
S
m
S
o
S
m
=
+
(
) +
≈
+




||
||
||
π
π
π
1
	
(18.42)
where rπ = (β + 1)rm. In this case, the MOS transistor can be considered as a BJT with rπ = ∞ and thus,
	
r
r
r R
r
R
r
R
r
oo
o
o
S
m
S
o
S
m
=
+
+
≈
+




1
	
(18.43)
Calculation of an amplifier’s input and output resistances are also an important part of small-signal 
analysis. The circuit in Figure 18.6 indicates that the input resistance is
	
r
R
R
r
R
in
m
E
=
+
(
)
(
)
1
2
||
|| β
	
(18.44)
Note that the assumption that β + 1 ≈ β is consistently employed to simplify the equations. This assump-
tion is based upon the fact that there is no good reason to use β + 1 because the actual value of β is never 
really known, and furthermore, β fluctuates with temperature (about 1% per °C). Thus, an analysis of 
the circuit in Figure 18.7 indicates that
	
r
R
R
r
R
R
in
m
E
E
=
+
(
)
(
)
1
2
2
||
||
||
β
	
(18.45)
Clearly, if the BJT in Figure 18.6 or Figure 18.7 is replaced by a MOS device (β = ∞), then the input 
resistance would simply be
	
r
R
R
in =
1
2
||
	
(18.46)
vin
vout
rm
ro
roo
iC
iC
iC
RS
vin
rm
roo
vout
iC
RS
roo
roo= ro
roo= ro
rπ= (β + 1)rm≈βrm
1 +
1 +
For BJT
For MOS
RS || rπ
RS
rm
rm
Figure 18.8  Evaluation of the output resistance of a transistor.
© 2011 by Taylor and Francis Group, LLC

A Simplistic Approach to the Analysis of Transistor Amplifiers 
18-9
18.3.2  Common-Drain and Common-Collector Configurations
Figure 18.9 illustrates a BJT in the common-collector configuration. An inspection of this circuit indi-
cates that the incremental collector/emitter current ΔiC is
	
∆
∆
i
v
r
R
C
in
m
E
=
+
	
(18.47)
and the output voltage is
	
∆
∆
v
i R
out
C
E
=
	
(18.48)
Therefore, the voltage gain is
	
A
v
v
R
R
r
V
out
in
E
E
m
=
=
+
∆
∆
	
(18.49)
Note carefully that Equation 18.48 is simply the equation for a voltage divider with resistors RE and rm:
In the event that a base resistance is present, as shown in Figure 18.10, then using Kirchhoff voltage law:
	
∆
∆
∆
∆
v
R
i
r
R
i
R
r
R
i
in
B
B
m
E
C
B
m
E
C
=
+
+
(
)
=
+
+
(
)




β
	
(18.50)
R2
R1
RE
VCC
rm
Δvin
Δvout
Figure 18.9  Transistor circuit in the common collector configuration.
R1
RB
R2
RE
VCC
rm
Δvin
Δvout
Figure 18.10  Transistor circuit in the common collector configuration.
© 2011 by Taylor and Francis Group, LLC

18-10 
Fundamentals of Industrial Electronics
and thus
	
∆
∆
i
v
R
r
R
C
in
B
m
E
=
+
+
(
/ )
β
	
(18.51)
	
∆
∆
v
i R
out
C
E
=
	
(18.52)
and once again, the voltage gain is determined from the resistor divider equation
	
A
v
v
R
R
r
R
V
out
in
E
B
m
E
=
=
+
+
∆
∆
(
/ )
β
	
(18.53)
18.3.3  Common-Gate and Common-Base Configurations
Figure 18.11 is an illustration of a transistor in the common-collector configuration. Note that in this 
case, the incremental collector/emitter current ΔiC is
	
∆
∆
i
v
r
C
in
m
=
	
(18.54)
The small-signal analysis for this situation ignores the resistor RE since it is connected in parallel with 
the ideal voltage source. The voltage drop across resistor RC is
	
∆
∆
v
i R
out
C
C
=
	
(18.55)
and thus the voltage gain is the ratio of two resistors:
	
A
v
v
R
r
V
out
in
C
m
=
=
∆
∆
	
(18.56)
The addition of a base resistor, as indicated in Figure 18.12, makes the circuit slightly more complicated, 
and in this case, Equation 18.56 must be modified to include this RB resistor. The resulting equation is
	
A
v
v
R
r
R
V
out
in
C
m
B
=
=
+
∆
∆
(
/ )
β 	
(18.57)
Δvout
R2
R1
RC
RE
VCC
rm
Δvin
Figure 18.11  Transistor circuit in the common base configuration.
© 2011 by Taylor and Francis Group, LLC

A Simplistic Approach to the Analysis of Transistor Amplifiers 
18-11
Note that voltage drop across RB is ΔvRB = iBRB and since iC = βiB then ΔvRB = iCRB/β. The voltage drop 
across rm is iCrm. Since the denominator in Equation 18.57 represents the sum of these two voltage drops, 
Equation 18.57 indicates that the voltage gain is also equal to the ratio of two resistors.
In a small-signal analysis, MOS transistors and BJTs are treated basically the same, even though their 
small-signal parameters rm and ro are calculated differently. One may also treat a MOS transistor as a 
BJT with a current gain β = ∞
Example 18.4
Consider now the use of the proposed method for the same circuits that were analyzed in a classical way 
in Chapter 17 of this book. Figure 17.14a of the previous chapter is repeated in Figure 18.13.
An inspection of the circuit indicates that
	
r
R
R
R R
R
R
in =
=
+
1
2
1 2
1
2
||
	
(18.58)
where rin is the parallel combination of the two biasing resistors R1 and R2. In the MOS transistor case, 
its input resistance can be neglected. The output resistance is again a parallel combination of RD and ro
	
r
R
r
R r
R
r
out
D
o
D o
D
o
=
=
+
||
	
(18.59)
R2
RB
RC
RE
R1
VCC
rm
Δvin
Δvout
Figure 18.12  Transistor circuit in common base configuration with series resistance in the base.
R2
R1
RD
rm
roo
Δvin
Δvout
Figure 18.13  MOS transistor circuit in the common source configuration.
© 2011 by Taylor and Francis Group, LLC

18-12 
Fundamentals of Industrial Electronics
The gain of the amplifier is then the ratio of the output resistance to rm, provided that there is no series 
resistance connected to the source:
	
A
R
r
r
V
D
o
m
= −
||
	
(18.60)
This same result would require several pages of analysis using the traditional approach.
Example 18.5
Consider now the circuit shown in Figure 18.14a, which is identical to the one in Figure 17.18a in Chapter 17. 
The amplifier gain, and the input and output resistances can be found using the approach presented 
here. In this case, the amplifier gain is
	
A
R
R
r
r
R
V
C
L
oo
m
E
= −
+
||
||
	
(18.61)
where roo is given by Equation 18.43, in which RS is replaced with RE.
The traditional approach, outlined in the previous chapter where the effect of ro was ignored, yielded 
the gain equation
	
A
g
R
R
R
r
g
V
m
C
L
E
m
=
−
+
+
(
||
)
( /
)
(
)
1
1
π
	
(18.62)
With the substitutions gm = 1/rm and rπ = β rm the gain becomes
	
A
R
R
r
R
r
r
R
R
r
R
V
C
L
m
E
m
m
C
L
m
E
=
−
+
+
=
−
+
+
||
( /
)
( /
)
||
( / )
(
)
(
)
(
)
(
)
1
1
1
1
1
β
β
≈−
+
R
R
r
R
C
L
m
E
||
	
(18.63)
The input resistance of rin of the circuit shown in Figure 18.14a represents the parallel combination of the 
two biasing resistors R1, R2 and β(rm + RE)
	
r
R
R
r
R
in
m
E
=
+
1
2
||
|| (
)
β
	
(18.64)
The output resistance is the parallel combination of RC, RL, and roo
	
r
R
R
r
R
R
r
R
r
r
out
C
L
oo
C
L
o
E
m
m
=
=
+
(
)








||
||
||
||
||
1
β
	
(18.65)
(a)
R2
RE
RL
R1
RC
rm
roo
Δvin
Δvout
(b)
R2
RE
RL
R1
RD
rm
roo
Δvin
Δvout
Figure 18.14  Common emitter/source configurations (a) Bipolar transistor and (b) MOS transistor.
© 2011 by Taylor and Francis Group, LLC

A Simplistic Approach to the Analysis of Transistor Amplifiers 
18-13
In the MOS transistor case (Figure 18.14b), the input resistance of the transistor can be neglected, and the 
output resistance is once again a parallel combination of RD, RL, and roo, so
	
r
R
R
in =
1
2
||
	
(18.66)
The output resistance is the parallel combination of RC, RL, and roo
	
r
R
R
r
R
R
r
R
r
out
D
L
oo
D
L
o
S
m
=
=
+








||
||
||
||
1
	
(18.67)
18.4  Circuits with PNP and PMOS Transistors
Circuits with PNP and PMOS transistors can be handled in a manner similar to that employed for 
circuits with NPN and NMOS transistors. In order to avoid confusion, the best approach is the use of 
mirrored circuits, as shown in Figure 18.15. Note that the mirror image circuit is exactly the same as the 
original one, but simply drawn differently. In the mirror image circuit, the reference voltage is changed 
so that the bottom node is at 0 V potential and the top node is at −8 V potential. With this configuration, 
the dc analysis for the mirror image circuit is now essentially identical to that of the NPN transistor in 
Example 18.3. The approximate solution for this case yields
	
VB =
+
−
=
4
4
14
9
2
k
k
k
V
V
Ω
Ω
Ω(
)
	
(18.68)
	
V
V
V
E
B
BE
=
−
= −−−
(
) = −
2
0 7
1 3
.
. V 	
(18.69)
	
I
I
V
R
C
E
E
E
≈
=
= −
= −
1 3
1 3
1
.
.
V
k
mA
Ω
	
(18.70)
With the more accurate approach, the resistor divider consisting of the 4 and 12 kΩ resistors must be 
replaced by a Thevenin equivalent circuit in which
	
R
V
TH
TH
=
=
⋅
+
=
=
+
−
4
14
4
14
4
14
3 111
4
4
14
k
k
k
k
k
k
k
and
k
k
k
Ω
Ω
Ω
Ω
Ω
Ω
Ω
Ω
Ω
Ω
||
.
( 9
2
V
V
) =
	
(18.71)
Now the accurate value of current can be determined as
	
I
V
R
R
C
TH
TH
E
=
−
+
=
−
+
=
0 7
2
0 7
3 111
100
1 3
0 977
.
(
/ )
.
( .
/
)
.
.
β
k
k
mA
Ω
Ω
	
(18.72)
If the mirror image circuit, shown in Figure 18.16, is used, the small-signal analysis can also be used in a 
manner similar to that employed for NPN transistors. First, the small-signal parameters are calculated as
	
r
V
I
m
T
C
=
=
=
25
1
25
mV
mA
Ω
	
(18.73)
© 2011 by Taylor and Francis Group, LLC

18-14 
Fundamentals of Industrial Electronics
1 kΩ
+
–
4 kΩ
6 kΩ
4 kΩ
1 kΩ
14 kΩ
4 kΩ
14 kΩ
1.3 kΩ
1.3 kΩ
4 kΩ
6 kΩ
VIN
VEE= 0
VEE=0
VIN
+
–
VCC= 9 V
VOUT
VOUT
VCC=–9 V
VT= 0.025 V
VA= 100 V
β = 100
Figure 18.15  Circuit with the PNP bipolar transistor and it mirror image above.
VIN
1 kΩ
β=100
VA=100 V
VT=0.025 V
14 kΩ
4 kΩ
1.3 kΩ
4 kΩ
VEE=0
VCC= –9V
6 kΩ
VOUT
rm
roo
+
–
Figure 18.16  Mirrored circuit from Figure 18.15 with the inclusion of the small signal parameters.
© 2011 by Taylor and Francis Group, LLC

A Simplistic Approach to the Analysis of Transistor Amplifiers 
18-15
	
r
V
I
o
A
C
=
=
=
100
1
100
V
mA
kΩ	
(18.74)
Then, the input and load resistances are computed. The input resistance, as seen by input capacitor, is
	
r
r
in
m
=
⋅
=
=
14
4
14
4
2 5
1 386
k
k
k
k
k
k
Ω
Ω
Ω
Ω
Ω
Ω
||
||(
)
||
|| .
.
β
	
(18.75)
Because the emitter of the PNP transistor is grounded, roo = ro. The load resistance, i.e., the resistance 
between the collector and ground, is
	
r
r
L
oo
=
=
=
6
4
6
4
100
2 344
k
k
k
k
k
k
Ω
Ω
Ω
Ω
Ω
Ω
||
||
||
||
.
	
(18.76)
Because of the presence of the 1 kΩ series source resistance, the gain calculation must be done in two 
steps. First, the gain (loss) from the signal source to the transistor base is calculated using the resistor 
divider:
	
A
r
r
V
in
in
1
1
1 386
1 386
1
0 581
=
+
=
+
=
k
k
k
k
Ω
Ω
Ω
Ω
.
.
.
	
(18.77)
The voltage gain of the transistor from base to collector is
	
A
r
r
V
L
m
2
2 344
25
93 76
=
=
=
.
.
kΩ
Ω
	
(18.78)
Then, the total circuit gain is
	
A
A A
V
V
V
=
=
⋅
=
1
2
0 581 93 76
54 5
.
.
. 	
(18.79)
18.5  Analysis of Circuits with Multiple Transistors
In integrated circuits, especially MOS technology, it is much easier, and cheaper, to fabricate transistors 
than resistors. Therefore, a new concept in circuit design was developed resulting in a circuit in which 
the number of transistors is typically larger than the number of resistors. In addition, in integrated cir-
cuits, it is not possible to use large values of capacitance. Figure 18.17 shows how the blocking capacitor 
can be replaced by an additional transistor. The circuit in Figure 18.17a has the voltage gain of
	
A
R
r
r
R
r
V
D
oo
m
D
m
= −
≈−
||
	
(18.80)
In this case, it is assumed that the signal frequency is large enough so that the capacitor C shorts the 
resistor RS. This assumption is, of course, invalid if the signal frequency is lower than 1/RSC. In the 
modified circuit, i.e., Figure 18.17b, the resistance seen by the source is equal to parallel combination of 
RS and the rm of the M2 transistor. Note that circuit of Figure 18.17b also works well at low frequencies. 
The voltage gain is then
	
A
R
r
r
r
R
R
r
V
D
oo
m
m
S
D
m
= −
+
≈−
||
||
1
2
2
	
(18.81)
© 2011 by Taylor and Francis Group, LLC

18-16 
Fundamentals of Industrial Electronics
Proceeding up a notch, consider the circuit shown in Figure 18.18. The 
voltage gain from the input to the drain of M1 is given by Equation 18.81. 
The gain calculation from the input to the drain of M2 should be done 
in two steps. First, the common-drain approach is used to calculate the 
gain from the input to the node associated with the transistor sources:
	
A
r
R
r
r
R
V
m
S
m
m
S
1
2
1
2
0 5
= −
+
≈
||
||
.
	
(18.82)
Then, the gain from the source to the drain of M2 is determined using 
the common gate configuration, which yields
	
A
R
r
r
R
r
V
D
oo
m
D
m
2
2
2
2
= +
≈
||
	
(18.83)
Finally, the total voltage gain is
	
A
A A
R
r
V
V
V
D
m
=
=
1
2
2
2
	
(18.84)
The next example is an analysis of a simple amplifier with a current mirror as shown in Figure 18.19. The 
current mirror is composed of the transistors M3 and M4, and it is assumed that current i3 is equal to 
current i1. A popular technique used to analyze the differential amplifier employs the assumption that 
half of the input voltage is applied at input 1 and another half, with opposite sign, is applied at input 2. 
This voltage on the nodes associated with the sources of M1 and M2 is not changing and is considered to 
be a virtual ground. Therefore, the input 1 signal, which is equal to 0.5vin, drives rm1:
	
∆
∆
i
v
r
in
m
1
1
0 5
= .
	
(18.85)
and the other half of the input signal, with opposite sign, drives rm2:
	
∆
∆
i
v
r
in
m
2
2
0 5
= −.
	
(18.86)
RD1
RS
RD2
M2
M1
VDD
Figure 18.18  A simple dif-
ferential pair.
(a)
RD
RS
C
M1
rm
roo
(b)
VDD
VDD
RD
RS
M1
M2
rm
rm
roo
Figure 18.17  Replacement of the blocking capacitor in the traditional circuit (a) by a transistor in (b) which is 
the configuration for integrated circuit design.
© 2011 by Taylor and Francis Group, LLC

A Simplistic Approach to the Analysis of Transistor Amplifiers 
18-17
Since i3 = i1, then
	
∆
∆
∆
∆
∆
∆
∆
i
i
i
i
i
v
r
r
v
r
out
in
m
m
in
m
=
−
=
−
=
+



=
3
2
1
2
1
2
0 5
1
1
.
	
(18.87)
and the incremental output voltage is
	
∆
∆
∆
v
i
R
R
r
v
out
out
L
L
m
in
=
=
	
(18.88)
Hence, the voltage gain is
	
A
v
v
R
r
v
out
in
L
m
=
=
∆
∆
	
(18.89)
If the output resistance, ro, of each transistor must be considered, then these resistances should be con-
nected in parallel with the loading resistor RL. Under this condition,
	
A
v
v
R
r
r
r
v
out
in
L
oP
oN
m
=
=
∆
∆
||
||
	
(18.90)
The next example considers the analysis of the two-stage amplifier shown in Figure 18.20. Assuming all 
transistors are the same size, one finds that the drain currents of transistors M5, M6, M7, and M8 are 
equal to IS. In addition, the drain currents of transistors M1, M2, M3, and M4 are equal to 0.5IS, assum-
ing an equal division of biasing currents between M1 and M2. From this knowledge of the transistor 
currents, the small signal parameters, rm and ro, can be found using Equations 18.1 and 18.3. An inspec-
tion of this circuit, and use of Equation 18.88, yields the voltage gain of the first stage as
	
A
r
r
r
r
r
r
v
oP
oN
m
o
o
m
1
4
2
=
=
||
||
	
(18.91)
M2
M4
VDD
M3
M1
in1
i1
i2
i3
iout
Out
RL
in2
IS
Figure 18.19  Amplifier with a current mirror.
© 2011 by Taylor and Francis Group, LLC

18-18 
Fundamentals of Industrial Electronics
Note that in this stage there is no RL. In addition, it is assumed that the source current was equally 
divided and rm1 = rm2 = rm.
The second stage of the circuit in Figure 18.20 is the common-source amplifier consisting of transistor 
M7 with transistor M8 acting as the load. Therefore, the voltage gain of the second stage is
	
A
r
r
r
v
o
o
m
2
7
8
7
=
||
	
(18.92)
The total voltage gain is
	
A
A A
r
r
r
r
r
r
v
v
v
o
o
m
o
o
m
=
=
1
2
4
2
1
7
8
7
||
||
	
(18.93)
If this circuit is considered to be a transconductance amplifier, then the transconductance parameter, Gm, is
	
G
r
r
r
r
m
o
o
m
m
=
4
2
1
7
1
||
	
(18.94)
and the output resistance of the circuit is
	
r
r
r
out
o
o
=
7
8
||
	
(18.95)
Obviously, for MOS input stages, the input resistance is rin = ∞.
It can be shown that other key parameters of the amplifier of Figure 18.20 can also be found using 
the simplistic analysis method. For example, the location of the first pole, i.e., the first-corner frequency 
shown in Figure 18.21, is given by the expression
	
ω0
1
1
2
1
1
1
=
=
A r C
A A r C
v m
C
v
v
m
C 	
(18.96)
M2
CC
M6
M8
M5
M1
M3
M4
M7
IS
Figure 18.20  Two stage amplifier.
© 2011 by Taylor and Francis Group, LLC

A Simplistic Approach to the Analysis of Transistor Amplifiers 
18-19
Then the Gain-Bandwidth product, GB, for the amplifier is equal to the cutoff frequency defined by the 
time constant rm1CC
	
GB
A A
C r
v
v
T
C m
=
=
=
1
2
0
1
1
ω
ω
	
(18.97)
The second pole is located in the high frequency range above ωT, and it can usually be ignored because 
the amplifier gain at this frequency is smaller than one. If this is not the case, then the value of CC should 
be chosen large enough that the ratio between the second and first pole frequencies is larger than AV.
The Slew Rate, SR, is dependent upon the speed with which the capacitor CC can be charged. With the 
largest possible input voltage difference, the maximum charging current would be the source current of 
M6 that is approximately equal to IS. Therefore,
	
SR
I
C
S
C
=
	
(18.98)
The circuit in Figure 18.20 has a relatively large output resistance, given by Equation 18.94, and should be 
considered an Operational Transconductance Amplifier (OTA), rather than an Operational Amplifier 
(OPAMP). An OTA can be converted into an OPAMP by adding a unity gain buffer to the circuit. This 
additional element could be a simple voltage follower, as shown in Figure 18.22a, or more advanced 
push–pull amplifier, as shown in Figure 18.22b.
Av
Av
ω0
ωT
Figure 18.21  Frequency response of the amplifier of Figure 18.20.
(a)
M8
M10
M9
M7
M7
M9
M11
M12
M10
M8
(b)
Figure 18.22  Output buffers used to reduce the output resistance of the amplifier in Figure 18.20.
© 2011 by Taylor and Francis Group, LLC

18-20 
Fundamentals of Industrial Electronics
References
	
1.	 Allen, P. and D. Holberg, CMOS Analog Circuit Design, Oxford University Press, Oxford, U.K., 2002, 
ISBN 0-19-511644-5.
	
2.	 Jaeger, R. C. and T. N. Blalock, Microelectronic Circuit Design, 3rd edition, McGraw-Hill, New York, 
2008.
	
3.	 Wilamowski, B. M., Simple way of teaching transistor amplifiers, in ASEE 2000 Annual Conference, 
St. Louis, MO, June 18–21, 2000, CD-ROM session 2793.
	
4.	 Wilamowski, B. M. and R. C. Jaeger, Computerized Circuit Analysis Using SPICE Programs, McGraw-
Hill, New York, 1997.
© 2011 by Taylor and Francis Group, LLC

19-1
19.1  Introduction
Very-large-scale integration (VLSI) is a term used to describe integrated circuit designs using thou-
sands, or more, of field effect transistors (FETs) [Mead79]. VLSI chips can be implemented using several 
methods, including gate arrays, standard cells, and full-custom design [Baker08]. In this short tutorial, 
we will focus on full-custom design or design at the transistor level. We will use complementary metal-
oxide semiconductor (CMOS) technology that includes an n-type metal-oxide FET, n-type MOSFET or 
NMOS for short, and a p-type MOSFET or PMOS.
19.2  CMOS Devices and Layout
Figure 19.1 shows the schematic symbol and layout of NMOS and PMOS devices. When the body of the 
MOSFET is not drawn, it is assumed to be connected to ground, for the NMOS device, and to VDD, 
for the PMOS device. For digital design, we think of the MOSFET as a switch. When the gate of the 
NMOS is driven to VDD, the switch is closed. When the gate of the NMOS is at ground, the switch is 
open. When the gate of the PMOS is connected to ground, the switch turns on, hence the reason for 
19
Analog and Digital 
VLSI Design
19.1	 Introduction.....................................................................................19-1
19.2	 CMOS Devices and Layout............................................................19-1
19.3	 Electrical Behavior for Digital Design.........................................19-3
19.4	 Electrical Behavior for Analog Design.........................................19-4
19.5	 Digital VLSI Design........................................................................19-5
Logic Gate Design
19.6	 Complex Logic Gate Design...........................................................19-8
19.7	 Latches and Flip-Flops....................................................................19-8
19.8	 Analog VLSI Design........................................................................19-9
19.9	 Biasing for Analog Design............................................................19-10
19.10	 Differential Amplifier.................................................................... 19-11
19.11	 Op-Amp..........................................................................................19-12
19.12	 Comparator..................................................................................... 19-14
19.13	Data Converters.............................................................................19-15
19.14	Conclusion...................................................................................... 19-18
References...................................................................................................19-18
Vishal Saxena
Boise State University
R. Jacob Baker
Boise State University
© 2011 by Taylor and Francis Group, LLC

19-2 
Fundamentals of Industrial Electronics
the bubble on the MOSFET’s gate, and when the PMOS gate is high 
(at VDD), the switch is open. This complementary behavior is why 
the technology is called CMOS.
Figure 19.2 shows the layout of the PMOS and NMOS devices. 
The NMOS device sits in a p-type material called a p-well while 
the PMOS device sits in an n-well. The active areas for NMOS 
and PMOS devices are heavily doped n+ and p+, respectively. 
Connections to the wells are made from metal through a contact 
to n+, for the n-well, or p+, for the p-well. These connections are 
called the body, B, of the MOSFET, see Figure 19.3. For digital 
design, in most situations, again, the body of the NMOS is con-
nected to ground while the body of the PMOS is connected to 
VDD. The gate of the MOSFET is made using polysilicon (poly). 
Poly crossing active forms a MOSFET.
Width
 
Length
BN
SN
GN
NMOS
PMOS
DN
BP
SP
GP
DP
FIGURE 19.2  Layout of NMOS and PMOS devices.
n-well
p-well
p+
p+
p+
n+
n+
n+
Metal
Polysilicon (poly)
BN
BP
SN
SP
GN
GP
DP
DN
Contacts
NMOS
PMOS
FIGURE 19.3  Three-dimensional views of NMOS and PMOS devices.
G
D
B
S
NMOS
PMOS
2
20
2
20
2
20
2
20
FIGURE 19.1  Schematic symbols 
for NMOS and PMOS devices.
© 2011 by Taylor and Francis Group, LLC

Analog and Digital VLSI Design 
19-3
19.3  Electrical Behavior for Digital Design
The current that flows in the NMOS device when the source is connected to ground and the drain/gate 
are connected to VDD is the MOSFET’s on current, Ion,n. The resistance between the source and drain 
can be estimated using
	
R
VDD
I
L
W
n
on n
=
⋅
,
	
(19.1)
where
L is the length of the MOSFET
W is the MOSFET’s width, see Figure 19.2
Generally, in digital design, the MOSFET’s length is set to the minimum while the width is increased to 
reduce the MOSFET’s switching resistance. Figure 19.4 shows how the NMOS is thought of as a resistor 
for digital design when its gate is driven high to VDD.
For the PMOS device, Figure 19.5, the switch turns on when the gate is connected to ground. The 
effective switching resistance is determined by measuring the PMOS on current, Ion,p, with the gate and 
drain at ground with the source connected to VDD and is given by
	
R
VDD
I
L
W
p
on p
=
⋅
,
	
(19.2)
Again, notice the complementary behavior of the NMOS and PMOS devices.
D
D
When gate, G, is high the
MOSFET is a resistor.
G
S
S
Rn = VDD
L
W
Ion,n
L
W
FIGURE 19.4  Digital model of an NMOS device.
D
D
When gate, G, is low the
MOSFET is a resistor.
G
S
S
Rp= VDD
L
W
Ion,n
L
W
FIGURE 19.5  Digital model of a PMOS device.
© 2011 by Taylor and Francis Group, LLC

19-4 
Fundamentals of Industrial Electronics
19.4  Electrical Behavior for Analog Design
Characterizing the electrical behavior of the MOSFET for analog design is considerably more compli-
cated than it is for digital design. Figure 19.6 shows a schematic for extracting the drain current varia-
tion with changes in drain-source voltage, VDS, and gate-source voltage, VGS. Typical current–voltage 
curves are seen in Figure 19.7. The gate-source voltage is held constant and greater than the threshold 
voltage, VTHN (here 800 mV), while the drain source is varied from 0 to 5 V. The change in drain current 
is then plotted.
When the drain current varies linearly with VDS, the reciprocal of the slope of the curve is the resis-
tance between the MOSFET’s drain and source. In this region, the MOSFET is said to be operating in 
the triode region (aka linear or ohmic region). When the drain current curves flatten out, or saturate, 
20
2
NMOS
Voltage = 0 V
VGS
.include spice_models.txt
.dc VVDS 0 5 1m VVGS 0 5 1
VDS
Voltage=0 V
+
+
–
–
FIGURE 19.6  SPICE schematic for plotting the ID–VDS characteristics of a MOSFET.
Saturation
ID[Mnmos@0]
Triode
2.7 mA
2.4 mA
2.1 mA
1.8 mA
1.5 mA
1.2 mA
0.9 mA
0.6 mA
0.3 mA
0.0 mA
0.0 V 0.5 V 1.0 V 1.5 V 2.0 V 2.5 V 3.0 V 3.5 V 4.0 V 4.5 V 5.0 V
VDS
VGS= 1 V
VGS= 2 V
VGS= 3 V
VGS= 4 V
VGS= 5 V
ID
FIGURE 19.7  ID–VDS characteristics of a MOSFET.
© 2011 by Taylor and Francis Group, LLC

Analog and Digital VLSI Design 
19-5
the MOSFET is operating in the saturation region. The drain current at the border between satura-
tion and triode is called ID,sat. The drain-source voltage at this border point is called VDS,sat. When the 
MOSFET is operating in the saturation region, it behaves like a current source of ID,sat in parallel with 
a resistor, ro. Again, the reciprocal of the slope of the drain current in the saturation region tells us the 
resistance between the drain and source, ro, or
	
r
I
o
D sat
=
⋅
1
λ
,
	
(19.3)
where λ has units of V−1 and generally ranges from 0.01 to 0.2 V−1. The behavior of the NMOS device 
operating in the saturation region can be described using
	
I
V
V
V
V
D
n
GS
THN
DS
DS sat
=
⋅
−
⋅
−
−
β
λ
2
1
2
(
)
(
)
(
)
,
	
(19.4)
for
	
V
V
V
V
V
V
GS
THN
DS
GS
THN
DS sat
>
≥
−
=
and
,
	
(19.5)
Note also that
	
I
V
V
D sat
n
GS
THN
,
(
)
=
⋅
−
β
2
2
	
(19.6)
While these equations were specified for the NMOS device, by swapping VGS with VSG, VDS with VSD, and 
VTHN with VTHP they can also characterize the behavior of the PMOS device (all quantities are positive).
While ro is used to characterize how ID changes with changes in VDS, we also need to characterize how 
ID varies with AC changes, vgs, around a fixed DC VGS (the device’s transconductance, gm). Using
	
d i
I
dv
d
dv
v
V
V
d
D
gs
gs
n
gs
GS
THN
(
)
(
)
+
=
+
−




β
2
2
	
(19.7)
or, assuming vgs << VGS (small-signal approximation)
	
g
V
V
I
m
n
GS
THN
D
n
=
⋅
−
=
β
β
(
)
2
	
(19.8)
This equation is useful because it tells us that if we turn the MOSFET on with a VGS > VTHN and apply a 
small AC signal on top of this, vgs, then the current that flows, id is gm · vgs.
19.5  Digital VLSI Design
The most basic element used in digital VLSI design is the inverter, Figures 19.8 and 19.9. When the input 
is a logic “1” or VDD, the PMOS device is off while the NMOS device is on (behaves like a resistor). When 
the input goes low, to ground or logic “0,” the PMOS turns on, while the NMOS shuts off. The delay 
associated with driving a capacitive load, Cload, is
© 2011 by Taylor and Francis Group, LLC

19-6 
Fundamentals of Industrial Electronics
	
t
R C
PHL
n
load
=
⋅
0 7.
	
(19.9)
for a high-to-low delay, and
	
t
R C
PLH
p
load
=
⋅
0 7.
	
(19.10)
for a low-to-high delay.
19.5.1  Logic Gate Design
The power of CMOS digital VLSI is the ease with which logic functions can be implemented. Figure 
19.10 shows how NMOS devices are used to implement NAND and NOR functions. For the NAND 
function when all inputs, A AND B AND C, are high, the output is pulled to 
ground. In the NOR implementation, any of the inputs A OR B OR C pull the 
output to ground. Figure 19.11 shows the PMOS implementation of NAND 
and NOR functions. For the NAND function, the output goes high when the 
inputs are all low. For the NOR function, only one input need be high to pull 
the output high. Notice how the NMOS and PMOS circuits and inputs are 
complementary (hence, again, the name CMOS).
Figure 19.12 shows the schematic of a 3-input NAND gate. The NAND gate 
is the preferred topology for VLSI design using CMOS technology because the 
switching resistance of the PMOS devices is larger than the switching resis-
tance of the NMOS. Putting the NMOS devices in series is thus more desirable 
than putting the PMOS devices in series for fast switching speeds. For a 3-input 
NAND gate, the delay associated with driving a load capacitance from VDD to 
ground (high-to-low propagation delay) is
	
t
R C
PHL
n
load
=
⋅
0 7 3
.
	
(19.11)
while the delay associated charging a capacitive load is
	
t
R C
PLH
p
load
=
⋅
0 7 3
.
	
(19.12)
In
PMOS
In
NMOS
Out
Icon view
Out
40
2
20
2
FIGURE 19.8  A CMOS inverter and icon.
Out
In
Gnd
VDD
FIGURE 19.9  Layout 
of a CMOS inverter.
© 2011 by Taylor and Francis Group, LLC

Analog and Digital VLSI Design 
19-7
ABC
A
A
B
C
A + B + C
NOR output
20
2
20
2
20
2
20
2
20
2
20
2
B
C
NAND output
FIGURE 19.10  NAND and NOR implementation using NMOS devices.
A
B
C—
—
—
ABC = A + B + C
NOR output
2 40
2 40
2 40
–
–
–
A
B
C
A+B + C = ABC
—
—
—
NAND output
2 40
2 40
2 40
–––
FIGURE 19.11  NAND and NOR implementation using PMOS devices.
2 20
2 40
2 40
2 40
2 20
2 20
A
B
C
ABC
Out
Out
A
B
C
NAND output
FIGURE 19.12  A CMOS NAND gate.
© 2011 by Taylor and Francis Group, LLC

19-8 
Fundamentals of Industrial Electronics
19.6  Complex Logic Gate Design
More complex logic functions can easily be implemented using CMOS technology. Consider a single 
logic gate to implement the logic function:
	
Z
A
BC
=
+
	
(19.13)
The schematic to implement this logic function is seen in Figure 19.13. Notice how the parallel connection 
of NMOS devices, those connected to B− and C−, for example are implemented with a series combina-
tion of PMOS devices. The series combination of NMOS, the NMOS controlled by A in series with the 
NMOS connected to B− and C−, is implemented using a parallel combination of PMOS. The implemen-
tation of the logic function is complementary. Note that the more inputs to the gate, the larger the delay 
associated with driving a load capacitance. This limits the complexity of a single gate in a practical 
situation.
19.7  Latches and Flip-Flops
The CMOS logic gates presented in the last section are used to implement combinatorial logic. On 
the other hand, latches and flip-flops are used for realizing sequential logic with storage elements. 
A latch is a storage circuit whose output changes when the clock (CLK) signal is high. Latch imple-
mentation in CMOS is based on the cross-coupled inverter circuit shown in Figure 19.14a. The posi-
tive feedback in the cross-coupled latch recirculates and stores the input signal until it is forced to 
change again. Figure 19.14b shows a level-sensitive latch. When the clock is high, the data input D drives 
the inverters and the input data is registered. When the clock goes low, the input is disconnected 
and the inverters are connected in the cross-coupled manner. At this instance, the value of the input 
D is stored in the latch.
B
C—
—
—
—
—
B
A
A
A + BC
C
2 20
2 20
2
20
2 40
2 40
2 40
FIGURE 19.13  A complex CMOS logic gate.
© 2011 by Taylor and Francis Group, LLC

Analog and Digital VLSI Design 
19-9
In practical digital systems, it is desirable for perfect synchronization that system state changes 
exactly on the clock edges instead of depending on the clock levels. This is achieved by employing 
edge-triggered D-flip-flops (D-FF) for storage. A D-FF is realized by cascading two level-sensitive 
latches as shown in Figure 19.15. When the clock is low, the first “master” stage tracks the D input 
whiles the second “slave” stage holds the previous input. At the instance, when the clock goes high, 
the master captures the input and transfers it to the slave. This causes the output Q to change with 
the input D only when the clock transitions high. When the clock goes back low again, the value of 
Q recirculates around the cross-coupled inverters in the slave. The output state Q can change again, 
following the input D, when the clock goes back high again and thus forming a positive edge-triggered 
flip-flop. Similarly, a negative edge-triggered flip-flop can be realized by swapping CLK and CLK sig-
nals in the positive edge-triggered D-FF.
19.8  Analog VLSI Design
When we do digital VLSI design, we treat the MOSFET as a switch. When we do analog design, we treat 
the MOSFET, as mentioned in Section 19.4, as a transconductance amplifier (voltage input, vgs, and current 
output, id). In other words, we can think of the gain of the NMOS device as
	
g
i
v
m
d
gs
=
	
(19.14)
This equation assumes that the drain is connected to a low resistance, a voltage source to keep the 
MOSFET in saturation, Figure 19.6. If the MOSFET drives its own resistance, ro, so the output voltage is 
vout = id · ro we can re-write Equation 19.14 as
	
v
v
g
r
i
r
v
out
in
m
o
d
o
gs
=
⋅
=
⋅
	
(19.15)
The term gm · ro is often called the MOSFET’s open-circuit gain.
D
Q—
(a)
D
CLK
CLK
CLK
Q
—
Q
(b)
CLK
FIGURE 19.14  (a) A basic latch formed using cross-coupled inverters and (b) a CMOS level-sensitive latch.
CLK
Master
CLK
CLK
CLK
CLK
CLK
Slave
Q
Q
—
A
D
CLK
CLK
FIGURE 19.15  A positive edge-triggered D-Flip-Flop.
© 2011 by Taylor and Francis Group, LLC

19-10 
Fundamentals of Industrial Electronics
19.9  Biasing for Analog Design
For analog design, the drain current, ID, the gate-source voltage, VGS, and, in some cases, the drain-
source voltage, VDS, must be set. The proper selection of these electrical characteristics is said to bias the 
MOSFETs. The equations governing MOSFET operation were given earlier (19.4) through (19.6). Figure 
19.16 shows a biasing circuit that can be used in analog design. The PMOS device is a long-length device 
to drop a significant voltage. The gate-source voltage of the NMOS is, for general design, set so that it is 
the threshold voltage plus 5% of VDD.
The output of the circuit, bias_N, is used in a current mirror, Figure 19.17. Note that the voltage 
bias_N is also the VGS of the NMOS device. This controls the current in the device noting that the device 
must be operating in the saturation region, Equation 19.5.
NMOS
PMOS
Long L device
Biasn_N
2 20
FIGURE 19.16  A simple analog bias circuit.
NMOS
NMOS
Out
Out
NMOS
Bias_N
Bias_N
Simpliﬁed circuit
(No bias circuit shown)
Bias circuit
Long L device
PMOS
2 20
2 20
2 20
FIGURE 19.17  Biasing a current mirror.
© 2011 by Taylor and Francis Group, LLC

Analog and Digital VLSI Design 
19-11
19.10  Differential Amplifier
Figure 19.18 shows the schematic of a differential amplifier, or diff-amp for short. The inputs to the diff-
amp are applied to the gates of M1 and M2, the gates of the diff-pair. The input common-mode range of 
the diff-amp is set by the minimum and maximum input voltages required to keep all MOSFETs operat-
ing in saturation. We will call the difference in the input signals, vin, or
	
v
v
v
in
ip
im
=
−
	
(19.16)
The average of the inputs is the common-mode voltage, vcm:
	
v
v
v
cm
ip
im
=
+
2
	
(19.17)
The minimum input vcm is limited by the minimum voltage across the current sink, VDS,sat added to 
M1/M2’s VGS or
	
v
V
V
V
V
cm
GS
DS sat
DS sat
THN
,min
,
,
=
+
=
+
2
	
(19.18)
When the common-mode voltage starts to fall below this minimum voltage, the devices start to shut 
off. For the maximum input common-mode voltage, M1 and M2 must be kept in the saturation region. 
Their drains are held at VDD − VSG where VSG is the source-gate voltage of the PMOS current mirror 
load. Using Equation 19.5,
	
v
VDD
V
V
VDD
V
cm
SG
THP
SD sat
,max
,
=
−
+
≈
−
	
(19.19)
M4
M2
vim
M1
NMOS
NMOS
NMOS
M3
vip
vgs1
vgs2
2 20
2 20
2 40
2 40
2 40
Bias_N
+
+
–
–
Out
FIGURE 19.18  Schematic of a differential-amplifier (diff-amp).
© 2011 by Taylor and Francis Group, LLC

19-12 
Fundamentals of Industrial Electronics
The AC performance of the diff-amp can be characterized by applying an AC voltage, vip, between the 
gates of M1 and M2:
	
v
v
v
in
gs
gs
=
+
1
2 	
(19.20)
The AC currents in M1 and M2 must be equal but opposite since ideally, no AC current will flow in the 
current sink used to bias the diff-pair. The current in the NMOS current sink is fixed (DC) and thus 
does not vary. Therefore, we can write
	
i
i
v
v
v
d
d
gs
gs
in
1
2
1
2
2
= −
→
= −
=
	
(19.21)
The current id1 is mirrored via M3 over to M4, so the total current driven into the output node is 2id1. 
The AC output voltage is thus
	
v
i
r
r
out
d
on
op
=
⋅
2
1
||
	
(19.22)
or knowing vin = vgs1/2 = id1 · 2/gm
	
v
v
g
r
r
out
in
m
on
op
=
⋅
||
	
(19.23)
19.11  Op-Amp
Figure 19.19 shows the basic two-stage op-amp formed with a diff-amp and a common-source output 
stage. The DC gain of this op-amp is
	
A
g
R
g
R
g
r
r
g
r
r
v
m
m
mn
op
on
mp
op
on
= −
⋅
= −
⋅
1
1
2
2
1
1
1
2
2
2
(
)
(
)


	
(19.24)
M3
M1
2 20
2 20
2 40
2 40
2 40
2 20
2 40
M2
vip
M4
M4
NMOS
Bias_N
NMOS
NMOS
NMOS
Out
Cc
vim
FIGURE 19.19  Schematic of a basic two-stage operational-amplifier (op-amp).
© 2011 by Taylor and Francis Group, LLC

Analog and Digital VLSI Design 
19-13
where
R1 is the net resistance attached to the node-1 (output of the first stage)
R2 is the net resistance attached to node-2 (output of the second stage)
The transconductances for the first- and second-stage amplifiers are gm1 and gm2, respectively. In 
Equation 24, gm1 is equal to the transconductance of the NMOS M1 and M2 (i.e., gmn1) in Figure 19.19, 
while gm2 is the transconductance of the PMOS M4 (i.e., gmp2). Since the op-amp has two prominent 
nodes with large capacitive loading, the op-amp has two poles associated with its frequency response. 
A pole in frequency domain causes the magnitude response to decrease by 20 dB per decade in fre-
quency, and the net phase decreases by 90°. Now, if the op-amp has two poles, located close to each 
other on the frequency axis, a net phase change of 180° occurs. If for any frequency, the gain is greater 
than unity and the net phase difference across the op-amp is close to 180°, the op-amp will act like an 
oscillator and display oscillations in the time-domain transient response. Thus, to stabilize the op-amp, 
the two poles are separated from each other by employing frequency compensation. This is achieved by 
employing Miller’s effect, where a large capacitance, called the compensation capacitor, is connected 
between the outputs of the first and second stages of the op-amp. This leads to pole-splitting whereby 
the dominant pole associated with the output node is pushed close to DC, and the second pole is pushed 
out to a higher frequency. Also at higher frequencies, the compensation capacitor shorts the input and 
the output of the op-amp, leading to a zero in the frequency response. Analytically, it can be shown that 
the zero is located on the right half s-plane (RHP) and leads to an increase in the magnitude response 
by +20 dB/decade and causes a decrease in the phase response by 90°. The frequency location of the RHP 
zero is given by
	
f
g
C
z
m
c
=
2
2π
	
(19.25)
The dominant pole that also sets the 3 dB bandwidth of the open-loop response is located at
	
f
g
R C
m
c
1
2
2
1
2
≈π
	
(19.26)
while the nondominant pole location is given as
	
f
g
C
C C
C C
C C
m
c
c
c
2
2
1
1
2
2
2
≈
+
+
π (
) 	
(19.27)
The resulting AC transfer function of the op-amp is
	
A
f
v
f
v
f
g
R
g
R
j f f
j f f
j f f
v
out
in
m
m
z
( )
( )
( )
(
/ )
(
/ )(
/ )
=
=
⋅
−
+
+
1
1
2
2
1
2
1
1
1
	
(19.28)
Figure 19.20 shows the pole-splitting in the s-plane when Miller compensation is employed in the op-
amp. The resulting frequency response after compensation is shown in Figure 19.21.
An important parameter for an op-amp is its unity-gain frequency or gain bandwidth. It is defined 
as the frequency at which the op-amp’s open-loop magnitude response has unity gain. The location of 
unity-gain frequency is estimated as
	
f
g
C
un
m
c
=
1
2π
	
(19.29)
© 2011 by Taylor and Francis Group, LLC

19-14 
Fundamentals of Industrial Electronics
The stability of the op-amp is characterized by two parameters, namely phase margin (PM) and gain 
margin (GM). To determine the PM, we look at the net phase shift when the gain of the op-amp is unity. 
The amount of phase shift away from 180° is defined as the PM. GM is the difference (in dB) between the 
open-loop gain and the unity gain, when the phase is equal to 180°. Ideally, the op-amp should look like 
a single-pole response with a PM of 90°. A PM of 90° signifies an R-C circuit like first-order transient 
response for the op-amp. As the RHP zero and the second pole come closer to the unity-gain frequency, 
the PM decreases from the ideal value of 90°. A PM of 60° or higher is considered reasonable for a stable 
op-amp. Op-amp design involves multiple trade-offs between the op-amp gain, unity-gain frequency, 
PM, power consumption, and layout area for given specifications. Additional information on op-amp 
compensation methods and design trade-offs is found in [Baker08].
19.12  Comparator
A comparator is a decision-making circuit that compares two analog voltages and generates a corre-
sponding digital output. The output is high if the analog input at the positive terminal (vin+) is larger 
than the signal at the negative input terminal (vin−) and low for the opposite case. Figure 19.22 shows 
jω
s-plane
σ
gm2
gm2
p2≈–
p1≈–
1
1
1
–
– R1C1
R2C2
C1+C2
gm2R2R1C1
Pole splitting
Cc
z1=
FIGURE 19.20  Pole-zero plot showing pole-splitting in a Miller-compensated two-stage op-amp.
dB
0
0°
f1
f2
f
f
fun
fz
–90°
Gain margin
–20 dB/dec
–20 dB/dec
Phase margin
–180°
–270°
20 . log|A( f )|
A( f )
FIGURE 19.21  Frequency response of a Miller-compensated two-stage op-amp.
© 2011 by Taylor and Francis Group, LLC

Analog and Digital VLSI Design 
19-15
the implementation of a clocked comparator realized from a basic cross-coupled latch. If an imbalance 
is created between the two nodes, A and B, the voltage difference between the two is amplified by the 
inverters. Thus, if initially node A is at higher voltage than node B, the voltage at node A will continue to 
increase until it settles close to VDD and node B settles near the ground. The latch is modified to make 
decision when the clock (CLK) goes high by adding a clocked switch to turn the latch on when the clock 
is high. Another switch is employed to erase the comparator memory from the previous decision by 
equilibrating the nodes A and B when CLK is low.
A complete clocked comparator is shown in Figure 19.23. Here, a pair of common-source amplifiers is 
used to amplify the input signal and create an imbalance in the latch. The digital output of the compara-
tor is further amplified and stored by an SR (set-reset) flip-flop that is constructed by two cross-coupled 
NAND gates.
19.13  Data Converters
Data converters form the interface boundary between the analog and digital domains. An analog-to-
digital converter (ADC) samples an analog signal at a given clock rate, quantizes it, and represents it 
in its equivalent digital code. On the other hand, a digital-to-analog converter (DAC) converts a digital 
A
B
A
B
(a)
(b)
A
B
CLK
A
CLK
B
(c)
(d)
FIGURE 19.22  Implementation of a clocked comparator: (a) latch using cross-coupled inverters, (b) transistor 
implementation of (a), (c) addition of a clocked switch, and (d) using a PMOS switch to erase latch memory.
A
Vin+
Vin–
Vout–
Vout+
Out+
Out–
CLK
B
FIGURE 19.23  A complete clocked comparator.
© 2011 by Taylor and Francis Group, LLC

19-16 
Fundamentals of Industrial Electronics
input code into its analog representation. ADCs can be categorized into two broad categories, namely 
Nyquist rate and oversampling data converters. Nyquist-rate ADCs operate at a sampling frequency, 
set by Nyquist’s sampling theorem, which is double the bandwidth of the input analog signal. A wide 
variety of Nyquist-rate ADC architectures are available spanning the spectrum of speed and resolution: 
flash, pipelined, subranging, folding, integrating, and successive approximation.
Flash or parallel ADCs offer the highest sampling speed at low resolution. A Flash ADC employs 2N−1 
comparators in parallel for N-bit resolution. The comparators compare the input signal with equally 
spaced voltage references generated by a string of resistors as shown in Figure 19.24. The resulting out-
put code of the comparators, called a thermometer code, is then converted to its digital equivalent out-
put. Flash converters have been typically limited to a maximum of 8 bit resolution and operate at speeds 
up to 1–4 GHz in CMOS technology.
For moderate resolution of 10–13 bits and moderate sampling speeds (100–400 MHz in CMOS), pipe-
lined ADCs are utilized. A pipelined ADC employs N digitizing stages connected in series. Each of the 
pipelined stages carries out 1 bit conversion using a comparator and passes on the unconverted residue 
on to the next stages. Each stage of the pipelined converter follows the following algorithm, as illustrated 
in Figure 19.25:
	
1.	 Sample the input and compare it with the voltage reference VREF/2, where VREF is the reference 
voltage for data converter typically equal to the supply voltage range. The output of the compara-
tor is the resulting output bit for that stage.
	
2.	 If the input vin is greater than VREF/2 (i.e., comparator output is one), subtract VREF/2 from vin and 
pass the result to the amplifier. If vin is smaller than VREF/2, pass the original input to the amplifier. 
The output after the each stage is called the residue and is passed on to the next stage for subse-
quent conversion.
	
3.	 Multiply the summed output by a fixed gain of two and pass the result to the sample and hold of 
the next stage.
Vin
VREF
R
R
R
R
(2N–1) to N
decoder
Thermometer
code
DN–1
D2
D1
D0
Digital
output
R
–
+
–
+
–
+
–
+
FIGURE 19.24  Block diagram of a flash ADC.
© 2011 by Taylor and Francis Group, LLC

Analog and Digital VLSI Design 
19-17
The successive approximation ADC searches through all the possible digital codes by successively com-
paring them with the sampled analog input. A DAC is employed to cycle through the digital codes using 
binary search. Each time, the DAC output is compared with the sampled input and the result stored in 
a successive approximation register (SAR). The content of the SAR represents the digital output code 
corresponding to the analog input. The successive approximation ADCs are simple to implement and is 
the architecture of choice for high-speed and high-resolution data conversion. However, the resolution 
of these ADCs is limited by the accuracy of the DAC employed.
The oversampling ADCs employ digital signal processing (DSP) to achieve much higher resolution 
(up to 24 bits) than the Nyquist-rate data converters. A basic oversampling ADC block diagram is shown 
in Figure 19.26.
The oversampling ADC operates at a sampling frequency that is a large multiple of the input signal 
bandwidth and constitutes of a delta-sigma (ΔΣ) modulator followed by a digital filter. The ΔΣ modula-
tor incorporates a loop filter, H(z), a pair of lower-resolution ADC and DAC connected in a feedback 
loop as seen in Figure 19.26. The ΔΣ modulator operating at a higher oversampling frequency effectively 
pushes (or shapes) the quantization noise of the low-resolution ADC to the higher frequencies beyond 
the input signal bandwidth. This shaped-out out-of-band quantization noise is filtered out by the digital 
filter, leading to a higher signal-to-noise ratio (SNR) and hence, higher bit resolution. The ratio of the 
sampling frequency to the signal bandwidth is defined as the oversampling ratio (OSR). If the order of 
the ΔΣ loop filter, H(z), is M, the effective increase in bit resolution is roughly given as
	
N
M
OSR
inc =
+



⋅
(
)
1
2
2
log
	
(19.30)
Thus, the maximum possible signal bandwidth is traded with higher resolution using DSP techniques. 
The ΔΣ ADCs are gaining prominence with further advancement in the speed of the CMOS technol-
ogies. The feedback structure of the ΔΣ modulator desensitizes the SNR to the errors arising due to 
manufacturing mismatches across the transistors. Also, the ΔΣ modulation techniques push much of 
the signal processing to the digital domain from the analog domain, which is favorable for manufactur-
ability in nano-scale CMOS technologies.
Vin
S/H
S/H
S/H
+
+
+
+
+
DN–1
MSB
D0
LSB
DN–2
+
+
–
+
–
+
–
–
–
–
–
VREF
VN
VN–1
2
VREF
VREF
2
2
×2
×2
FIGURE 19.25  Block diagram of a pipelined ADC.
Vin
H(z)
ADC
VDSM
Digital filter
Vout
DAC
ΔΣ Modulator
+
+
–
FIGURE 19.26  Block diagram of an oversampling ADC.
© 2011 by Taylor and Francis Group, LLC

19-18 
Fundamentals of Industrial Electronics
The DAC architectures are simpler when compared to the ADCs. Here, the digital code representing 
the signal is interpolated to its equivalent analog representation. Similar to the ADCs, a wide variety of 
DAC architectures are available. An example of DAC employing R-2R ladder is shown in Figure 19.27. 
The R-2R ladder is a compact structure that generates the binary-weighted references (=VREF/2i) by volt-
age division. The input digital bits control whether the resistors in the ladder are connected to ground or 
to the summing amplifier. The amplifier sums up the individual binary-weighted digital input bits and its 
output (vout) represents the analog equivalent of the digital input code. Other DAC architectures include 
current steering, charge scaling, cyclic, pipelined and delta-sigma topologies. The reader is referred to 
[Baker08,Baker09] for a detailed exposition on data converters.
19.14  Conclusion
An introduction to transistor-level Analog and Digital VLSI design has been presented. The CMOS 
devices are first characterized using the models presented in the chapter and then they are used to 
design circuits with the desired performance specifications. Digital circuits like logic gates and clocked 
storage elements are utilized to build complex data paths. On the other hand, analog circuit blocks like 
op-amps and comparators are used to construct signal processing systems including the data convert-
ers. ADCs are categorized into various architectures that offer a trade-off between the conversion band-
width and the resolution. A brief tutorial on ADC architectures has been presented in this chapter along 
with an example of DAC.
References
[Baker08] R.J. Baker, CMOS Circuit Design, Layout and Simulation, revised 2nd edition, Wiley-IEEE, 
New York, 1039pp., 2008.
[Baker09] R.J. Baker, CMOS Mixed-Signal Circuit Design, 2nd edition, Wiley-IEEE, Hoboken, NJ, 329pp., 
2009.
[Mead79] C. Mead and L. Conway, Introduction to VLSI Systems, Addison-Wesley Pub, Reading, MA, 
396pp., 1979.
R
VREF
2R
DN–1
MSB
D0
LSB
DN–2
DN–3
D1
2R
2R
2R
2R
2R
R
R
R
R
Vout
+
–
FIGURE 19.27  A DAC using R-2R ladder network.
© 2011 by Taylor and Francis Group, LLC

20-1
20.1  Introduction
Digital design has become the most modern and efficient way of implementing a wide variety of elec-
tronic systems. These systems are the heart of today’s computer, wireless, and multimedia technology 
and are becoming more ubiquitous in nature where they are often embedded in an ever-increasing 
range of appliances from toasters to automobiles. A major property of digital systems is that they utilize 
finite size number representation and discrete state behavior to implement the desired functionality 
to the needed degree of precision. To be useful, such systems must be interfaced through analog-to-
digital (A/D) and digital-to-analog (D/A) converters, because the real world is actually analog in nature 
(i.e., real-world parameters such as time, voltage, current, temperature, etc., have an infinite number of 
possible values). The focus of the this chapter and the next (sequential logic) are to introduce the basic 
concepts associated with digital logic and describe how the basic digital logic building blocks can be 
designed and combined together to perform the required task. Digital logic is most effectively classified 
as being composed of two main types of logic circuitry: combinational and sequential. In combinational 
sections of a digital design, the values of the outputs are a function of the current values associated with 
the inputs, whereas in sequential logic, the outputs will not only depend upon the current set of inputs 
but on the past values of the inputs. The focus of this chapter is to introduce the basic concepts associ-
ated with combinational digital logic circuitry with the important aspects associated with sequential 
logic being explored in Chapter 21.
20.2  Number Representation
Digital circuitry is implemented using semiconductor technology that utilizes a very large number of 
transistors that are placed in silicon integrated circuits, ICs. The most natural way for us humans to 
represent numbers is decimal, but most digital circuitry represents numbers in binary. This is because 
transistor-level designers have been more successful in implementing reliable and area efficient two-
state (on/off) circuitry than in implementing multistate circuitry. The most common signed number 
representation in binary is called two’s complement. Two’s complement is an expanded version of the 
20
Digital Design—
Combinational Logic
20.1	 Introduction.....................................................................................20-1
20.2	 Number Representation..................................................................20-1
20.3	 Two-Valued Boolean Logic.............................................................20-2
20.4	 Logic Minimization........................................................................20-4
20.5	 Common Combinational Elements..............................................20-6
20.6	 Modern Combinational Design Practices...................................20-8
References.....................................................................................................20-9
Buren Earl Wells
The University of 
Alabama in Huntsville
Sin Ming Loo
Boise State University
© 2011 by Taylor and Francis Group, LLC

20-2 
Fundamentals of Industrial Electronics
standard binary positional notation in which the position of each bit is related to the position of the next 
bit by the multiplier of 2. In two’s complement notation, the multiplier for the most significant bit is 
negative while the multiplier of all other bits is positive. Figure 20.1 gives an example of basic positive 
and negative integer representation in two’s complement binary.
The standard two’s complement notation is easily made to account for fractions by extending the posi-
tional notation to allow for integer powers less than 0. This is called fixed point. Fixed point often suffers 
from the finite number of bit positions reserved for the integer or fraction (or both). This has lead to the 
development of floating point formats that allow the exponent to be adjusted in a manner that allows the 
most significant number of bits to always be maintained. It should also be noted that humans rarely interface 
with digital hardware using binary. Rather users interact with the system using standard decimal (which is 
usually transmitted in ASCII character format), which is then converted into binary before being processed 
by the digital system with the output being conversely converted back into human-readable format. The use 
of such data and number formats of ASCII and Binary Coded Decimal (BCD) facilitate this process.
20.3  Two-Valued Boolean Logic
Boolean algebra is a branch of mathematics that adapts many of the concepts used in traditional philo-
sophical propositional logic to a form that can be easily implemented in digital hardware. It utilizes a set 
of statements that are made up of variables and constants, which are acted upon by a set of operators to 
produce the outputs that can serve as an input variable to other Boolean statements. The values of the 
Boolean variables and constants are restricted to one of two possible values (True or False, or 0 or 1), 
which corresponds to two specified voltage ranges.
It can be shown that any combinational function can be implemented using a combination of the 
basic AND, OR, and NOT operators. The corresponding set of gates is easily implemented in digital 
hardware in a manner that is dependent upon the underlying device technology. In Boolean algebra, a 
truth table can be used to show the values of the output for all possible values of the set of inputs. An 
example of the truth tables for all three of these main types of gates is shown in Figure 20.2. An AND 
gate is characterized by the fact that all inputs must be at a logic 1 before the output is a 1. An OR gate is 
characterized by the fact that if any of the inputs are at a logic 1, then the output is also at a logic 1, and 
a NOT gate simply inverts (switches) the value of its logic input. The functionality of applying the logic 
operations on the set of inputs to produce an output can also be expressed using Boolean algebra nota-
tion. In this notation, the input and outputs of a logical network are represented as variables or constants 
in much the same way as conventional algebraic statements. The operations performed by these three 
gates are expressed using standard algebraic symbols, where the AND operation represents Boolean 
multiplication, and the OR operation represents Boolean addition. By definition, the NOT operation is 
a unary operator. It is expressed by putting a line over the variable of interest.
Positional notation Bn−1Bn−2 … B1B0
where Bi = {0,1} and n = number of bits used in representation
Value
2
0
0
=
−
+
+
−
−
B
B
B
n
n
n
n
−
−
)+
…
+
1
1
2
2
1
1
2
2
2
(
B
For n = 4 bit representation
5
0( 2 )
1(2 )
0(2 )
1(2 )
0101
10
3
2
1
0
2
=
−
+
+
+
⇒
−
=
−
5
1( 2 )
0(2 )
1(2 )
1(2 )
1011
10
3
2
1
0
2
+
+
+
⇒
FIGURE 20.1  An example of positive and negative representation in 2’s complement.
© 2011 by Taylor and Francis Group, LLC

Digital Design—Combinational Logic 
20-3
The set of three, AND, OR, and NOT gates is logically complete, meaning that all combinational 
Boolean expressions can be expressed using some combination of these gates. It is often more conve-
nient to use other Boolean logic gates and operators that are derived from these basic gates. Figure 20.3 
illustrates the NAND, NOR, and XOR (exclusive OR) gate symbols, equivalent representations, truth 
tables, and Boolean expressions.
Boolean algebraic expressions exhibit standard associative and commutative properties. There are 
many laws, theorems, and definitions that are present in Boolean algebra some of which are shown in 
Figure 20.4.
F=A+B
Boolean equation:
A
B
F
0
0
0
0
1
1
1
0
1
1
1
1
Truth table:
Logic symbol:
A
B
F
+
Logic symbol:
A
F
F= A–
Boolean equation:
Truth table:
A
F
0
1
1
0
A
B
F
Logic symbol:
Boolean equation:
A
B
F
0
0
0
0
1
0
1
0
0
1
1
1
Truth table:
or
F =AB
F=A  B
FIGURE 20.2  Digital logic basic operators (AND, OR, and NOT). The truth table and Boolean equations are 
shown in the figure.
Logic symbol:
Boolean equation:
A
F =AB
B
F
0
0
1
0
1
1
1
0
1
1
1
0
Truth table:
A
B
F
Equivalent representations:
Logic symbol:
Equivalent representations:
A
B
F
+
Logic symbol:
Equivalent representations:
A
B
F
.
or
A
B
F
+
or
A
B
F
+
A
B
F
.
A
B
.
F
+
.
Boolean equation:
A
B
F
0
0
1
0
1
0
1
0
0
1
1
0
Truth table:
F=A+B
Boolean equation:
A
B
F
0
0
0
0
1
1
1
0
1
1
1
0
Truth table:
F= AB + AB= A    B
A
B
F
FIGURE 20.3  NAND, NOR, and XOR gates with their equivalent implementations and truth tables.
© 2011 by Taylor and Francis Group, LLC

20-4 
Fundamentals of Industrial Electronics
20.4  Logic Minimization
A Boolean expression can be placed directly in a canonical form 
where it can then be minimized in terms of the number of gates 
and the number of inputs required for each gate. Such minimi-
zation often results in an easier-to-understand logical expres-
sion that can result in less underlying digital circuitry being 
needed to implement the desired logic function.
There are two main conical forms for combinational Boolean 
functions. The disjunctive form is the Boolean sum (OR-ing) of 
the set of minterms present in the function whereas the con-
junctive form is the Boolean product (AND-ing) of the set of 
maxterms present in the function. A minterm is a product term 
that contains a single copy of all the function’s input variables in their true or complemented form. 
Each minterm is a logic 1 for one distinct set of input combinations, which forces the overall disjunc-
tive Boolean Function to logic 1 at these input values. Minterms are constructed by determining what 
combination of inputs will result in the function being a logic 1. Each of these input combinations will 
generate a separate minterm. Each minterm then is simply the product of all the true or complemented 
input variables, with the true form being present whenever that variable is a logic 1 when the minterm 
is present, and the complemented form being present whenever the variable is a logic 0. Conversely, 
maxterms are constructed by determining what combination of input will result in the overall logic 
function being a logic 0. Each maxterm is simply the sum of all the true or complemented input vari-
ables, with the true form being present whenever the variable is a logic 0 when the maxterm is present, 
and the complemented form being present whenever the variable is a logic 1. Minterms and maxterms 
are given numbers based upon the row of the corresponding truth table where they occur. This of 
course assumes that the set of input variables obtain a specified ordering from most significant to least 
significant bit.
The canonical forms of Boolean expressions most often can be simplified. This requires that one 
consider the set of minterms that differ from one another only at a single variable position. This vari-
able can then be eliminated from the expression using the simplification theorem shown above and 
the two terms replaced by a single reduced term. The process can then be continued until there are 
no more possible groupings. A grouping that is composed of the largest possible number of minterms 
is called a prime implicant. If a prime implicant contains a midterm that is not present in any other 
prime implicant, it is considered to be essential and must be part of any valid solution. If not, it is con-
sidered to be nonessential and a minimal solution may be possible that does not include this implicant.
The Quine–McCluskey algorithm [1] represents an ordered/tabular way of accomplishing this pro-
cess that is amenable to automation. The Karnaugh map method [1] is an equivalent graphical method 
that is easier to apply to smaller four to six variable Boolean functions. Both methods employ two main 
steps as shown in Figure 20.5 where an unoptimized function is simplified. The first step is to find the set 
of prime implicants that make up the function by applying the simplification theorem to product terms 
that differ from one another at only one variable position. Prime implicants that were uniquely formed 
from one or more minterms are then declared to be essential. The second step is utilizing a minimum 
number of the nonessential prime implicants in the final solution. From this example, one can note that 
the complexity of the canonical form expression is significantly reduced and that there can be more than 
one equivalent minimal expression.
Original function in disjunctive conical (sum of products) form:
	
F
ABCD
ABCD
ABCD
ABCD
ABCD
ABCD
ABCD
ABCD
ABCD
=
+
+
+
+
+
+
+
+
⇒Nine 4-inputt AND gates   and  One 9-input OR gate
,
	
DeMorgan s laws :
(
)
)
Simplification theorem:
′
AB
A
B
A
AB
XY
XY
+
+
+
=
+
(
B
=
=
+
X
X
A
B
B
A
(
)
Exclusive OR definition:

⊕
=
X
A
B
FIGURE 20.4  DeMorgan’s law, sim-
plification theorem, and exclusive OR 
definition.
© 2011 by Taylor and Francis Group, LLC

Digital Design—Combinational Logic 
20-5
Truth table for
original function
Step 1: Finding prime implicants:
                            repeated application of xy+ xy΄ = x
                           to combine terms and reduce size
A
0
0
0
0
0
0
0
0
1
1
1
1
1
1
1
1
0
0
0
0
1
1
1
1
0
0
0
0
1
1
1
1
0
0
1
1
0
0
1
1
0
0
1
1
0
0
1
1
0
1
0
1
0
1
0
1
0
1
0
1
0
1
0
1
0
0
1
1
0
0
1
1
1
1
0
0
1
1
1
0
(a)
m14
m13
m12
m9
m8
m7
m6
m3
m2
0 0 1 0 m2
0 0 1 _ m2,m3
0 _ 1 0 m2,m6
0 _ 1 1 m3,m7
1 0 0 _ m8,m9
0 1 1 _ m6,m7
0 _ 1_ m2,m3,m6,m7
1 _ 0_ m8,m9,m12,m13
m2m3m6m7
m8m9m12m13
Essential prime implicants
BCD
ABD
AC
AC
*
*
*
*
*
*
*
*
*
*
*
*
*—
—
—
—
Prime implicates
m2 m3 m6
m6m14
m12m14
m7 m8 m9 m12 m13 m14
1 _ 0 0 m8,m12
1 _ 0 1 m9,m13
_ 1 1 0 m6,m14
1 1 _ 0 m12,m14
1 0 0 0 m8
0 0 1 1 m3
0 1 1 0 m6
1 0 0 1 m9
1 1 0 0 m12
0 1 1 1 m7
1 1 0 1 m13
1 1 1 0 m14
Step 2: Selection of nonessential prime implicants
B
C
D
F
(b)
CD
AB
00
00
01
11
10
01
11
10
1
1
1
Prime implicant BCD’
(Nonessential)
Prime implicant ABD’
(Nonessential)
Prime implicant AC’
(Essential, because of
m8, m9, and m13)
Prime implicant A’C
(Essential, because of
m2, m3, and m7)
Step 1: Finding prime implicants:
                            re peated application of xy + xy΄= x
                            to combine terms and reduce size 
Step 2: Selection of nonessential 
                      prime implicants (Either BCD’
                or ABD’ need to be in final 
        solution but not both)
1
1
0
0
1
1
1
1
0
0
0
0
0
 of operators
of operators
FIGURE 20.5  Logic simplification methods: (a) a logic minimization example using Quine–McCluskey tech-
nique and (b) Karnaugh map method.
© 2011 by Taylor and Francis Group, LLC

20-6 
Fundamentals of Industrial Electronics
Reduced function:
	
F
AC
AC
BCD
F
AC
AC
ABD
=
+
+
=
+
+
⇒
      or     
Two 2-input AND gates, One 3-input AND gate  and One 3-input OR gate
,
	
20.5  Common Combinational Elements
In addition to the derived gates (XOR, NAND, etc.), it is often useful to utilize larger combinational 
devices. As with the derived gates, each of these devices can be created from the basic set of logic opera-
tors. One such combination element is the multiplexer, which can be used to choose from a set of inputs, 
one input to connect to the output. Such multiplexers often have ZN inputs that are controlled by N select 
lines. In addition to their use as data selectors, multiplexers can be used to implement arbitrary Boolean 
functions (see Figure 20.6).
Another higher-level combinational device is the decoder. Decoders often are used to produce a 
one-hot encoded output that responds to the input in a manner where only one of the output lines 
is a logic 1 at a time and the particular line that is active corresponds to the output whose index 
value is the same and that placed on the select line. Figure 20.7 illustrates the functionality of a 
3-to-8 decoder.
An encoder is in many ways the reverse of a decoder. It converts the one-hot encoding that occurs 
when one of the inputs is active (logic 1) into a binary number that corresponds to the index of the input 
where this has occurred. The case where more than one input is active at a time can be handled by giving 
the higher-indexed inputs priority over the lower-indexed inputs as shown in the truth table of Figure 
20.7. Of course, these higher-level objects are actually constructed using the lower-level logic as also 
shown in the figure.
Adders are examples of other combinational modules that can be constructed using logical gates. 
These can be defined hierarchically by first developing single-bit half and full adder modules. A half 
adder is one that adds 2 bits to produce a sum and a carry. A full adder adds two bits together along with 
a carry to produce a sum and a carry. The truth table and its logic implementation for these 1 bit adders 
are shown in Figure 20.8.
Once the half and full adders have been constructed, they can be combined and replicated in a hier-
archical manner to form a multibit (ripple) adder by connecting the carry outs to carry in of subsequent 
bit stages, as shown in Figure 20.9.
4-to-1
Multiplexer
I0
I1
I2
I3
S1
S0
F
– –
–
–
F= I0S1S0+ I1S1S0+ I2S1S0+ I3S1S0
FIGURE 20.6  4-to-1 Multiplexer. The F function specifies which data input will be selected with the use of selec-
tor inputs.
© 2011 by Taylor and Francis Group, LLC

Digital Design—Combinational Logic 
20-7
Truth table (3-to-8 decoder) 
S2
S1
S0
O0
O1
O2
O3
O4
O5
O6
O7
0
0
0
0
1
1
1
1
0
0
1
1
0
0
1
1
0
1
0
1
0
1
0
1
1
0
0
0
0
0
0
0
0
1
0
0
0
0
0
0
0
0
1
0
0
0
0
0
0
0
0
1
0
0
0
0
0
0
0
0
1
0
0
0
0
0
0
0
0
1
0
0
0
0
0
0
0
0
1
0
0
0
0
0
0
0
0
1
O0
O1
O2
O3
O4
O5
O6
O7
S0
S1
S2
3-to-8
decoder
Truth table (8-to-3 encoder) 
I0
I1
I2
I3
I4
I5
I6
I7
O2
O1
O0
1
×
×
×
×
×
×
×
0
1
×
×
×
×
×
×
0
0
1
×
×
×
×
×
0
0
0
1
×
×
×
×
0
0
0
0
1
×
×
×
0
0
0
0
0
1
×
×
0
0
0
0
0
0
1
×
0
0
0
0
0
0
0
1
0
0
0
0
1
1
1
1
0
0
1
1
0
0
1
1
0
1
0
1
0
1
0
1
I0
I1
I2
I3
I4
I5
I6
I7
O0
O1
O2
8-to-3
priority
encoder
Highest-to-
lowest
priority
(a)
(b)
I1
I2
I4
I6
I3
I4
I6
O0
I5
I6
–
–
–
–
–
I7
O1
I3
I4
I5
I6
I7
–
–
I2
I4
I5–
–
O2
I4
I5
I6
I7
S0
S1
S2
–
–
–
–
–
–
–
–
–
S0
S1
S2
S0
S1
S2
S0
S1
S2
O3
(c)
O2
O1
O0
S0
S1
S2
–
–
S0
S1
S2
–
–
S0
S1
S2
S0
S1
S2
O4
O5
O6
O7
FIGURE 20.7  Decoder and encoder: (a) decoder and encoder block diagrams, (b) encoder implementation, and 
(c) decoder implementation.
© 2011 by Taylor and Francis Group, LLC

20-8 
Fundamentals of Industrial Electronics
20.6  Modern Combinational Design Practices
A basic knowledge of Boolean algebra is very helpful to digital design engineers [1], but most of the 
low-level design optimization is now handled using complex software tools that synthesize the design 
into logic circuitry and allow one to simulate the functionality of the design before it is implemented. 
These tools often support design entry using modeling languages where the functionality of circuitry 
is specified, not at the gate level but at a very high level of abstraction. These languages are called hard-
ware description languages (HDLs) and modern HDLs include VHDL [2], Verilog [3], System C [4], 
and Impulse C [5]. These tools allow for the design engineer to effectively manage the complexity of 
designs that contain logic circuitry that often contain millions of gates. It is also common for design 
engineers to prototype their designs using reconfigurable hardware before implementing their designs 
in application-specific hardware.
A3
A2
A1
A0
B0
B1
B2
B3
Half adder
Full adder
Full adder
Full adder
Sum/Dif0
Sum/Dif1
Sum/Dif2
Sum/Dif3
A
B
Sum
Cout
A
B
Sum
Cout
A
B
Sum
Cout
A
B
Sum
Cout Cout
Cin
Cin
Cin
FIGURE 20.9  A 4 bit adder design using the 1 bit adders shown in Figure 20.8.
Sum
Cout
Truth table (half adder)
A
B
Sum
0
0
0
0
0
1
0
1
1
0
0
1
1
1
1
0
Cout
A
B
Half adder
Sum
Cout
A
B
Cin
Full adder
Truth table (full adder)
Cout
Cin A
B
Sum
0
0
0
0
1
1
1
1
0
0
1
1
0
0
1
1
0
1
0
1
0
1
0
1
0
0
0
1
0
1
1
1
0
1
1
0
1
0
0
1
A
B
Sum
Cout
Cout
Cin
B
Sum
.
A
.
.
+
FIGURE 20.8  Half adder and full adder.
© 2011 by Taylor and Francis Group, LLC

Digital Design—Combinational Logic 
20-9
References
	
1.	 C. H. Roth, Fundamentals of Logic Design, 5th edition, ISBN: 0534378048, Thomson Learning, 
Belmont, CA, 2001.
	
2.	 S. Brown and Z. Vranesic, Fundamentals of Digital Logic with VHDL Design, 2nd edition, McGraw 
Hill, New York, 2005.
	
3.	 S. Brown and Z. Vranesic, Fundamentals of Digital Logic with Verilog Design, 2nd edition, McGraw 
Hill, New York, 2003.
	
4.	 T. Grötker, S. Liao, G. Martin, and S. Swan, System Design with SystemC, Kluwer Academic 
Publishers, Norwell, MA, 2004.
	
5.	 D. Pellerin and S. Thibault, Practical FPGA Programming in C, Prentice Hall, Englewood Cliffs, NJ, 
2005.
© 2011 by Taylor and Francis Group, LLC

21-1
21.1  Combinational and Sequential Logic
Memory is the difference between combinational and sequential logic. With combinational logic, the 
output is generated from inputs (after some gate propagation delays through the logic gates). Propagation 
delay is the length of time from when the input to a logic gate is valid, to the time when the output of 
that logic gate is valid. The propagation time will determine how soon a new set of inputs can be pro-
cessed with the output correctly generated. A sequential logic design has memory elements. The output 
is dependent on not only the current inputs, but also on the state. This means that sequential logic needs 
to know where it was and where it is now in order to determine where it is going with the current set of 
inputs. For example, a full adder is a combinational logic component as it adds input A and B to produce 
the sum. However, an up-down counter is a sequential logic component because the counter knows the 
current value; depending on the up-down control input, it will determine the next count value. Figure 
21.1 shows an illustration of the differences between combinational and sequential logic.
In addition to memory, sequential logic requires a clock. This clock controls the operation of the 
sequential circuit. Since all operations’ progress is based on a common clock, such a circuit is called a 
synchronous circuit.
21.2  Memory Elements
A memory element can maintain a binary state (0 or 1) as long as the power to the circuit is maintained. 
There are two basic types of memory elements: latch and flip-flop [1,2,3]. As described in the definitions 
below, latches are level sensitive and flip-flops are edge sensitive. In this write-up, D latches and 
D flip-flops are described and are shown in Figure 21.2. The information at data input D is the next state 
value. The value at output Q is the current state value. Knowing the locations of the current and next 
state values is important in wiring up a state machine.
Latch—For latches, the information presented at data input D is transferred to output Q when the 
enable (en) is asserted (active-low or active-high). This is termed level sensitive.
21
Digital Design—
Sequential Logic
21.1	 Combinational and Sequential Logic........................................... 21-1
21.2	 Memory Elements............................................................................ 21-1
21.3	 Designing an Up Counter.............................................................. 21-2
21.4	 Designing a Sequence Detector.....................................................21-8
21.5	 Summary......................................................................................... 21-10
References................................................................................................... 21-10
Sin Ming Loo
Boise State University
Arlen Planting
Boise State University
© 2011 by Taylor and Francis Group, LLC

21-2 
Fundamentals of Industrial Electronics
Flip-flop—For flip-flops, the information presented at the data input D is transferred to output Q 
when the clock (clk) is transitioning from low-to-high (positive-edge) or high-to-low (negative-edge). 
This is termed edge sensitive.
The difference between a latch and flip-flop can be demonstrated using a simple timing diagram (see 
Figure 21.3). As shown in the timing diagram, the latch (l_out) output continues to change as the data 
changes when clk = “1.” This is not the case for flip-flop (ff_out) output, which only changes during posi-
tive clock edge and holds the value until the next edge.
21.3  Designing an Up Counter
The simplest example of a sequential circuit is a counter design [3]. In this section, counter design using 
state machine method is demonstrated (see Figure 21.4). For this state machine design, the example 
shows the steps of using the state diagram, state table, and state encoding to design a 2 bit up counter 
D latch
D latch
D flip-flop
D flip-flop
en
en
clk
clk
Q
D
D
Q
D
Q
D
Q
FIGURE 21.2  D latch versus D flip-flop. The (gray) highlighted areas show when the latches or flip-flops are active.
D
l_out
l_out
ff_out
ﬀ_out
data_in
data_in
en
Q
D
clk
clk
clk
Q
FIGURE 21.3  Timing diagrams showing the difference between latch and flip-flop.
(a)
Combinational
logic
Inputs
Outputs
(b)
Combinational
logic
clk
…
…
…
…
…
Inputs
Outputs
Memory element
FIGURE 21.1  (a) Combination and (b) sequential logic examples.
© 2011 by Taylor and Francis Group, LLC

Digital Design—Sequential Logic 
21-3
(00 → 01 → 10 → 11 → 00…) that will reset to 00 when 11 is reached. The state diagram of this counter 
is shown in Figure 21.4. It has four states: A, B, C, and D. The output of each state is indicated inside 
the oval. States A, B, C, and D have outputs of “00,” “01,” “10,” and “11,” respectively. It is important to 
know the status of the state machine when the reset button is pressed, which is why the reset is in the 
state diagram. In this state machine design, whenever it is reset, it will always go to State A. There is no 
special condition for transitioning between states; only a clock edge (in this case, positive edge with the 
use of positive-edge D flip-flop) is necessary.
From the state diagram, a state table can be generated. This state table (see Table 21.2) presents the 
information in the state diagram in a simple table format.
With the above state table, an encoding scheme is needed for the 
state variables A, B, C, and D. Since we have four states, two bits 
will be enough for the representation. This is called minimized bit 
encoding. With this encoding scheme, A will be encoded as “00,” B 
as “01,” C as “10,” and D as “11.” A new table (Table 21.2) is gener-
ated for this encoding scheme. The output column is the same as in 
Table 21.1.
Now, the question is how are the present state (y1y0), next state 
(Y1Y0), and output (z1z0) interpreted in hardware (Figure 21.5). These 
can be determined using the values from Table 21.2.
Using a logic minimization technique, one can determine the 
next-state equations (Y1Y0) feeding into the D input of flip-flops, and 
the output equations (z1z0). This can be determined by using y1 and 
y0 as the variables or as an index in the K-map method. The logic 
minimizing technique will have the following equations:
	
Y
y y
y y
y
y
Y
y
1
1
0
1
0
1
0
0
0
=
+
=
⊕
=
,
	
	
z
y
z
y
1
1
0
0
=
=
,
	
Reset
A/00
D/11
C/10
B/01
FIGURE 21.4  State diagram of an up counter. Each node indicates the state name and the output produced by 
the state.
TABLE 21.1  State Table for 
Up Counter in Figure 21.4
Present 
State
Next 
State
Output
A
B
00
B
C
01
C
D
10
D
A
11
TABLE 21.2  State-Assigned Table 
with Minimized Bit Encoding
Present State
y1y0
Next State
Y1Y0
Output
z1z0
00
01
00
01
10
01
10
11
10
11
00
11
Next
state
Current
state
?
D
clk
clk
(Y1Y0)
(y1y0)
Output
(z1z0)
Q
?
FIGURE 21.5  D flip-flop.
© 2011 by Taylor and Francis Group, LLC

21-4 
Fundamentals of Industrial Electronics
Since we used two bits to encode the state machine (state machine 
representation), we will use exactly two D flip-flops. Using the above 
equations, we can obtain this counter design (see Figure 21.6). The 
simulation results for this counter are shown in the same figure.
Now, let’s try another state machine encoding technique. This 
encoding technique—called one-hot coding—will use more resources 
but has the potential to be faster. This encoding technique is called 
one-hot encoding because for X number of states, you will need X flip-
flops with one active at a time. With one-hot encoding, Table 21.1 can 
be encoded as shown in Table 21.3, with A as “0001,” B as “0010,” C as 
“0100,” and D as “1000.”
From Table 21.3, one can tell that there are many don’t-care states, which is how one-hot coding takes 
advantage in order to obtain an implementation with simpler next-state logic gates. The logic circuit 
implementation and simulation results are shown in Figure 21.7. Note that for this simulation to func-
tion correctly, it is necessary to preset the first flip-flop for the first clock cycle (using start_signal):
	
Y
y
Y
y
Y
y
Y
y
3
2
2
1
1
0
0
3
=
=
=
=
,
,
,
	
	
z
y
y
z
y
y
1
3
2
0
3
1
=
+
=
+
,
	
Name
[0]
[1]
[2]
[3]
[0]
[1]
[2]
[3]
[0]
[0]
[1]
[2]
[3]
20.0 ns
0 ps
40.0 ns
60.0 ns
80.0 ns
100.0 ns
120.0 ns
clk
reset_
z
z[1]
0
1
2
3
4
z[0]
(a)
(b)
clk
Input
Input
VCC
XOR
NOT
DFF
DFF
inst3
inst1
inst
D
Q
CLRN
y[0]
Output
Output
z[0]
y[1]
z[1]
PRN
D
Q
CLRN
PRN
inst4
VCC
reset_
FIGURE 21.6  The up counter state machine as designed and simulated in Altera Quartus II. (a) Counter logic 
circuit implementation. (b) Simulation results. The counter is reset at the beginning (using reset low signal). The 
output counts up to “11” and rolls over “00” to start over.
TABLE 21.3  State-Assigned 
Table with One-Hot Encoding
Present State
y3y2y1y0
Next State
Y3Y2Y1Y0
Output
z1z0
0001
0010
00
0010
0100
01
0100
1000
10
1000
0001
11
© 2011 by Taylor and Francis Group, LLC

Digital Design—Sequential Logic 
21-5
Let’s get back to the original counter (Figure 21.4), but with an up/down (ud) control bit added. When 
ud = 0, the counter counts up. When ud = 1, the counter counts down. This newly modified state dia-
gram is shown in Figure 21.8. The state table for Figure 21.8 is shown in Table 21.4. For this state table, 
the Next State portion has two columns, with ud to differentiate the state transition. The state table with 
minimized bit encoding (with A encoded as “00,” B encoded as “01,” C encoded as “10,” and D encoded 
as “11”) is shown in Table 21.5.
The next state and output equations can be determined by using y1, y0, and ud as the variables or as an 
index in the K-map method. The logic minimizing technique will have the following equations:
	
Y
y
y
ud
Y
y
1
1
0
0
0
=
⊕
⊕
=
,
	
	
z
y
z
y
1
1
0
0
=
=
,
	
start_
reset_
clk
Input
VCC
Input
VCC
Input
VCC
DFF
inst
D
Q
PRN
CLRN
DFF
inst1
inst5
inst4
OR2
OR2
Output
Output
z[0]
z[1]
D
Q
PRN
CLRN
DFF
inst2
D
Q
PRN
CLRN
DFF
inst3
D
Q
PRN
CLRN
(a)
(b)
Name
[0]
[1]
[2]
[3]
[0]
[1]
[2]
[3]
[0]
[0]
[1]
[2
[1]
[2]
[3]
20.0 ns
0 ps
40.0 ns
60.0 ns
80.0 ns
100.0 ns
120.0 ns
140.0 ns
clk
reset_
start_
z
z[1]
0
1
2
3
4
5
z[0]
FIGURE 21.7  One-hot implementation of Figure 21.4. (a) Counter logic circuit implementation, one-hot. 
(b) Simulation results. The counter is reset (using reset_, an active low signal) and preset (using start_, an active low 
signal) at the start of simulation. The output counts up to “11” and rolls over “00” to start over.
© 2011 by Taylor and Francis Group, LLC

21-6 
Fundamentals of Industrial Electronics
Let’s try the one-hot encoding. With one-hot encoding, Table 21.6 can be encoded as follows, with A 
as “0001,” B as “0010,” C as “0100,” and D as “1000.”
The next state and output equations are
	
Y
udy
udy
Y
udy
udy
Y
udy
udy
Y
udy
udy
3
2
0
2
1
3
1
0
2
0
3
1
=
+
=
+
=
+
=
+
,
,
,
	
	
z
y
y
z
y
y
1
2
3
0
1
3
=
+
=
+
,
	
TABLE 21.4  State Table for Moore Implementation 
of Up/Down Counter (Figure 21.8)
Present State
Next State
Output
ud = 0
ud = 1
A
B
D
00
B
C
A
01
C
D
B
10
D
A
C
11
Reset
A/00
ud = 0
ud = 0
ud = 0
ud=0
ud=1
ud = 1
ud = 1
ud = 1
C/10
B/01
D/11
FIGURE 21.8  Up/down counter (Moore implementation).
TABLE 21.5  State Table with Minimized 
Bit Encoding
Next State
Present State
(y1y0)
ud = 0
(Y1Y0)
ud = 1
(Y1Y0)
Output
(z1z0)
00
01
11
00
01
10
00
01
10
11
01
10
11
00
10
11
TABLE 21.6  State Table with One-Hot Encoding
Next State
Output
Present State
y3y2y1y0
ud = 0
Y3Y2Y1Y0
ud = 1
Y3Y2Y1Y0
0001
0010
1000
00
0010
0100
0001
01
0100
1000
0010
10
1000
0001
0100
11
© 2011 by Taylor and Francis Group, LLC

Digital Design—Sequential Logic 
21-7
The above is a Moore state machine; we can modify the same counter design so that it will work as a 
Mealy state machine. With a Moore state machine, the output depends only on the state. However, a Mealy 
state machine depends on not only the state, but also on the present value of inputs. Thus, we modify the 
counter to the following. The output is at the edge, not at the node (see Figure 21.9)! Note that the output of 
a Mealy state machine should be registered so that the output will change synchronously.
The state table and the encoded state table (with A encoded as “00,” B encoded as “01,” C encoded as 
“10,” and D encoded as “11”) are shown in Tables 21.7 and 21.8, respectively. One can also see clearly the 
difference between a Moore and a Mealy state machine implementation. The output column depends on 
ud. The Moore implementation as shown in Table 21.5 doesn’t depend on ud.
The next state and output equations are
	
Y
y
y
ud
Y
y
1
1
0
0
0
=
⊕
⊕
=
,
	
	
z
udy
y y
y y ud
z
udy
udy
1
1
1
0
1
0
0
0
0
=
+
+
=
+
,
	
Reset
A
ud= 0/00
ud= 0/10
ud = 0/01
ud=0/11
ud=1/11
ud= 1/00
ud = 1/01
ud= 1/10
C
B
D
FIGURE 21.9  Up/down counter (Mealy implementation).
TABLE 21.7  State Table for Mealy Implementation 
of Up/Down Counter (Figure 21.9)
Present State
Next State
Output
ud = 0
ud = 1
ud = 0
ud = 1
A
B
D
00
11
B
C
A
01
00
C
D
B
10
01
D
A
C
11
10
TABLE 21.8  State Table with Minimized Bit 
Encoding for Mealy Implementation of Up/Down 
Counter
Next State
Output
Present State
(y1y0)
ud = 0
(Y1Y0)
ud = 1
(Y1Y0)
ud = 0
(z1z0)
ud = 1
(z1z0)
00
01
11
00
11
01
10
00
01
00
10
11
01
10
01
11
00
10
11
10
© 2011 by Taylor and Francis Group, LLC

21-8 
Fundamentals of Industrial Electronics
21.4  Designing a Sequence Detector
What if you want to watch for a 3 bit sequence in a serial input data stream? How does one go about 
designing a sequential logic circuit to watch for the expected sequence? Can a state machine be used to 
design such a logic circuit for detecting a sequence? Let’s show an example that will detect “101” in a 
serial input data stream. It is important to note that an overlapping sequence is allowed, meaning that 
“10101” has two sequences. If it is a fixed windowing sequence, there is only one sequence in “10101.” 
Figure 21.10 describes the state machine we are about to design.
Since the sequence to be detected is “101,” three states will be necessary. Figure 21.11 shows the state 
diagram. This state diagram may look like scratches without any order. In fact, there is a systematic way 
to complete such a state diagram. First, one needs to determine the number of states necessary. In this 
example, we need a reset state (Init state) so that all reset events including initial startup will be directed 
to this state. The design will be a Moore state machine. This means that the outputs are determined 
by just the state. In addition to the Init state, we need a state when 1 is detected (Got1), one when 10 is 
detected (Got10), and one for when 101 is detected (Got101).
What about the transition edges—how would one go about adding those edges? The strategy is to add 
those transition edges that will get to the desired output—in this case, when 101 is detected. These edges 
are shown with dashed lines—there are three in this case. To complete the design, all the other edges 
will need to be added. Note that since we are dealing with binary logic, each state will have two output 
transitions (0, 1).
Table 21.9 shows the state table for the sequence detector in Figure 21.11. Table 21.10 shows the 
encoded state table, with Init encoded as “00,” Got1 encoded as “01,” Got10 encoded as “10,” and Got101 
encoded as “11.”
Output is high for
one clock cycle
when the sequence
is detected
[...110010010101...]
Serial data input
Sequence detector
Clock
Reset
FIGURE 21.10  Sequence detector for detecting sequence “101.”
Reset
1
1
1
1
0
0
0
0
Init
/0
Got1
/0
Got10
/0
Got101
/1
FIGURE 21.11  State diagram of sequence detector shown in Figure 21.10.
© 2011 by Taylor and Francis Group, LLC

Digital Design—Sequential Logic 
21-9
Using SI and y1y0 as indexes or variables, the next state and output equations are as follows (the logic 
circuit and simulation results are shown in Figure 21.12):
	
Y
y SI
SIy y
Y
SI
1
0
1
0
0
=
+
=
,
	
	
z
y y
=
1
0 	
TABLE 21.9  State Table for Sequence Detector
Present State
Next State
Output
SI = 0
SI = 1
Init
Init
Got1
0
Got1
Got10
Got1
0
Got10
Init
Got101
0
Got101
Got10
Got1
1
TABLE 21.10  State Table with Minimized 
Bit Encoding for Sequence Detector
Present State
(y1y0)
Next State
Output
(z)
SI = 0
(Y1Y0)
SI = 1
(Y1Y0)
00
00
01
0
01
10
01
0
10
00
11
0
11
10
01
1
0
1
1
1
0
clk
Name
0 ps
clk
NOT
NOT
inst9
inst6
inst1
inst10
inst
PRM
PRM
CLRN
CLRN
OR2
DFF
DFF
D
D
Q
Q
inst8
Input
inst5
inst4
Input
VCC
Input
VCC
SI
AND2
AND2
z
Output
AND3
VCC
reset_
40.0 ns
80.0 ns
120.0 ns
160.0 ns
V.
2–
reset_
SI
z
1
2
3
FIGURE 21.12  A sequence detector implementation with simulation results.
© 2011 by Taylor and Francis Group, LLC

21-10 
Fundamentals of Industrial Electronics
21.5  Summary
This chapter presents an overview of sequential logic design. Different methods to design state machines 
were demonstrated. In this chapter, the state machine’s next state and output equations were determined 
manually. As of the writing of this chapter, there are tools, such as Xilinx State Diagram Editor, that will 
translate a state diagram to hardware with the help of synthesis tools. The use of hardware description 
language (Verilog or VHDL) can also simplify the implementation of sequential logic. Instead of imple-
menting the design manually, the design can be put together by describing it using HDL constructs 
such as the case statement. This chapter does not attempt to be complete in presenting sequential logic 
design, but it makes an effort to present state machine design that is one of the most important concepts 
in sequential logic design.
References
	
1.	 C. H. Roth, Fundamentals of Logic Design, 3rd edition, ISBN: 0-314-85292-1, Nest Publishing Co., 
St. Paul, MN, 1985.
	
2.	 M. M. Mano and M. D. Ciletti, Digital Design, 4th edition, ISBN: 0131989243, Prentice Hall, Upper 
Saddle River, NJ, 2007.
	
3.	 S. Brown and Z. Vranesic, Fundamental of Digital Logic with Verilog Design, 2nd edition, ISBN: 
9780073380339, McGraw Hill, Boston, MA, 2008.
© 2011 by Taylor and Francis Group, LLC

22-1
22.1  Introduction [1–6]
A soft-core processor is a microprocessor core that can be implemented entirely by using digital logic 
synthesis. It is typically instantiated on programmable hardware such as a field programmable gate 
array (FPGA). (The main feature of an FPGA is that it is reconfigurable with different digital designs, 
allowing functionality to be changed an unlimited number of times by downloading a new file without 
physically changing the chip.)
In order to better understand what a soft-core processor is, it might be beneficial to consider the basic 
elements of construction and usage. Since a typical environment for creation of soft-core processors is 
on an FPGA, let’s review the development cycle of digital designs with FPGAs. First, a digital design is 
encoded via schematic capture or a hardware description language. Then, the design is synthesized and 
transformed into a form that can be used to configure the FPGA. This form is usually called the configu-
ration file. The configuration file is then used to configure the FPGA, which transforms the FPGA into 
the required digital solution (Figure 22.1a).
If the required digital design for the first input file above is that of a microprocessor, then the result-
ing transformation of the FPGA yields a microprocessor (Figure 22.1b). This type of microprocessor is 
called a soft-core processor.
Once an FPGA has been transformed into a microprocessor, its usage patterns mirror those of a 
traditional (discrete) microprocessor. The processor must still be programmed using traditional pro-
gramming languages and methods (Figure 22.2).
Many traditional devices that are interfaced to discrete microprocessors (such as memory, switches, 
buttons, LEDs, etc.) can also be connected to soft-core processors. The interface logic that is typically 
produced in the form of discrete components can be realized as logic instantiated in the FPGA along 
with the soft-core processor (Figure 22.3).
The interface logic typically supplied by vendors of commercial soft-core processors includes gpio 
(general purpose input/output), Universal Asynchronous Receiver/Transmitter (UART), Inter-Integrated 
Circuit (I2C), Serial Peripheral Interface (SPI), and others. These packages of device logic are also referred 
22
Soft-Core Processors
22.1	 Introduction.....................................................................................22-1
22.2	 Processor Core Options..................................................................22-3
22.3	 Processor Definition Process.........................................................22-3
22.4	 Software Development Aspects.....................................................22-3
22.5	 Utilization of Soft-Core Processors..............................................22-4
22.6	 Custom Instructions.......................................................................22-5
22.7	 Soft-Core Processor on an ASIC vs. FPGA..................................22-5
22.8	 Design Issues....................................................................................22-5
22.9	 Applications for Soft-Core Processors.........................................22-6
References.....................................................................................................22-6
Arlen Planting
Boise State University
Sin Ming Loo
Boise State University
© 2011 by Taylor and Francis Group, LLC

22-2 
Fundamentals of Industrial Electronics
(a)
(b)
Target board 
Design 
HDL 
Design 
configuration 
FPGA 
Synthesis 
process 
Configure
Design
Target board 
μP design 
HDL 
μP design
configuration
FPGA 
Synthesis
process
Configure
μP
FIGURE 22.1  (a) Typical FPGA design flow. (b) Soft-core processor design flow for FPGA.
Target board 
Software 
language 
source
Executable 
machine 
code 
FPGA 
Compile 
process 
Programmer
μP
FIGURE 22.2  Programming of soft-core processor.
Target board 
FPGA 
μP softcore
processor
Device 
logic 
Device 
logic 
Bus 
Device 
Device 
Discrete
device logic 
FIGURE 22.3  Device interfacing to soft-core processor.
© 2011 by Taylor and Francis Group, LLC

Soft-Core Processors 
22-3
to as intellectual property or IP cores. Open-source IP cores can be found and custom in-house solutions 
can be developed. This interface logic is sometimes referred to as glue logic, which, on an FPGA, is often in 
the form of a hardware definition language (HDL).
22.2  Processor Core Options
There are many soft microprocessor cores available, both closed and open source. Xilinx and Altera are 
the two major vendors; other vendors include Lattice, Actel, and Quicklogic. The leading 32 bit soft-core 
processors include Altera Nios II [7] and Xilinx Microblaze [8]. The LatticeMico32 [9] is a 32 bit soft-
core microprocessor available for free with an open IP core licensing agreement. Many of the open cores 
are porting older processor designs to FPGA technology, and are good sources for studying soft-core 
processor design and architecture. Commercially available soft-core processors are particularly useful 
for integration into existing designs, plus projects and courses that focus on the use of processors rather 
than processor architecture.
22.3  Processor Definition Process
In the previous discussion of soft-core processor design flow (as shown in Figure 22.1a), it was assumed that 
a microprocessor (μP) definition was available. This μP Design HDL file can be developed in-house from 
scratch (custom), or obtained from open core sources. The custom method could take many man-years of 
effort. In many cases, these methods for the creation of the processor description are not cost-effective. 
The vendors of FPGA technology have invested in the development of software tools to streamline the pro-
cess of soft-core definition. As is common in the software industry, the tools hide the proprietary aspects 
(source) of the processor but provide the capability to create one or more instances of the processor.
Just as the basic logic gate building blocks such as AND, OR, NOT, NAND, NOR, etc. are provided 
by the vendor for inclusion in digital designs, the vendors also provide a variety of processor models 
to be instantiated into projects. The ability to create a custom processor configuration design element 
for inclusion is usually done with a separate tool (e.g., EDK for Xilinx, SOPC for Altera). The processor 
design tool allows for drag-and-drop inclusion of the processor model and glue logic for specific attached 
devices. For each component, optional parameters may be specified for custom situations. Features such 
as a device memory address (memory mapped devices) and IRQ numbering may be specified. Cache 
sizes, clock sources, and bus connections are also available for inclusion.
The components available for inclusion can come from a variety of sources. Many times, these com-
ponents are the device logic referred to in Figure 22.3. The soft-core vendor supplies many of the basic 
components such as the processor and its primary bus, but many of the other components can come 
from third-party vendors, open-source entities, or from in-house development.
The result of the processor design tool is a module that is created by compiling the selected items into 
a form that can be instantiated into a standard HDL design (Figure 22.4). (The highlighted portion of 
Figure 22.4 shows the processor definition process; the grayed-out portion is the standard hardware 
synthesis process.)
22.4  Software Development Aspects
Hardware components selected as part of the processor definition also have software aspects, in that the 
components often integrate software device drivers to support the selected devices (Figure 22.5).
For custom in-house developed soft cores, an accompanying assembler/compiler will need to be 
developed (unless the user likes to create machine code by hand). The creation of an assembler/com-
piler is not for the faint-hearted! For commercially provided soft cores, the vendors provide ready-made 
software development tools, including assemblers, C compilers, and debuggers, usually in an integrated 
development environment (IDE). These tools are often gcc-based and are generally free.
© 2011 by Taylor and Francis Group, LLC

22-4 
Fundamentals of Industrial Electronics
The basic difference between software development for a soft-core processor and for a discrete proces-
sor arises from the fact that the soft-core processor can (and does) change. With such a moving target, 
the work involved with translating each hardware change into an appropriate change of software to 
accommodate the hardware can be daunting. To reduce this chore, vendors have provided processes that 
allow the software to track with the hardware changes.
22.5  Utilization of Soft-Core Processors
Up to this point, our discussion has been from the perspective of the development cycles. During those 
cycles, the target system is connected to a desktop workstation running development software to con-
figure the FPGA with a soft-core processor and then download and run or debug the software. Interface 
between the target device and the development workstation is generally via the JTAG connection. Once 
the development has been completed, the target device must be untethered from the development work-
station and made to work independently. Without the connection to the development workstation, 
μP design 
HDL 
μP module
Synthesis
process
HDL design IDE
Processor
design
tool
μP design
conﬁguration
Target board 
FPGA 
Conﬁgure
μP
FIGURE 22.4  Processor definition process.
Software 
Application
program
UART
device
μP
Timer
device
PIO
device
Other
device
Timer
device
driver
PIO
device
driver
Other
device
driver
UART
device
driver
FIGURE 22.5  Integrated device drivers.
© 2011 by Taylor and Francis Group, LLC

Soft-Core Processors 
22-5
another way must be found to place executable code into memory at the system reset address/program 
start location and transfer control to that code (boot the system).
To boot the system, traditional computer systems typically have a flash-based (random access flash) 
device containing executable code at the program start location. Since flash is too slow for large systems, 
the code in the flash device is used only to retrieve the remaining executable system code and place it in 
the much faster RAM for execution. This process is termed boot strapping or initial program load (IPL). 
Microcontroller systems often have all of the executable code contained in random flash memory, and 
are essentially instant-on as system reset immediately starts executing the code directly from the flash 
memory. The practice of running from flash restricts the speed at which these systems run, but also 
contributes to their lower power requirements.
If the target device for the soft-core processor is an FPGA (usually RAM-based), both the processor 
and the programming are lost when power is removed. This means that the soft-core processor must 
first be instantiated on the FPGA before the boot process can be carried out. Sequential flash memory 
is usually used to store the configuration file (as shown in Figure 22.1b), which is used at power on to 
configure the FPGA and re-establish the soft-core processor when power is applied.
Once the soft-core processor has been re-established, it must address the same issue that other micropro-
cessors face; i.e., how to load the executable code into memory and transfer control to that code. A variety 
of solutions exist for soft-core processors in addition to those available for traditional processors, and the 
appropriate solution may depend on which devices are already attached to the system. Binding a memory 
image of the executable code to the processor configuration is one solution. Partitioning a flash device with 
one section for the processor configuration and another for executable code is another.
22.6  Custom Instructions
With a hardware-based microprocessor, the only possible change is the software that the processor 
executes. Providing custom instructions for a discrete processor requires a large investment in hard-
ware. The capability to add custom instructions to a soft-core processor allows the designer to provide 
new functionality without having to replace the underlying hardware. This provides a means for moving 
many software solutions into hardware on the FPGA platform, which may actually have better perfor-
mance than a discrete processor with the solution in software.
22.7  Soft-Core Processor on an ASIC vs. FPGA
A soft-core processor can be implemented via different semiconductor devices, such as an application-
specific integrated circuit (ASIC) or FPGA. An ASIC is customized for a specific application, while the 
FPGA’s programmable logic blocks and interconnects allow a single FPGA to be used and reused in 
many different applications.
On an ASIC, the soft core and other design logic can be synthesized into a gate-level netlist that 
describes connectivity of the electronic design. Logic gates are placed and routed according to the 
netlist, and turned into photomasks to create the chip. The final product is hardwired logic gates formed 
from transistors and their interconnections. For an FPGA, the netlist is used to generate a configuration 
file that will be used to program lookup tables and configurable logic blocks within the FPGA.
22.8  Design Issues
Design considerations when choosing a processor include power usage, speed (performance), flexibility, 
device support, nonrecurring engineering (NRE) costs, and development time.
Traditional discrete microprocessors—such as x86 families, ARM, and PowerPC—are usually opti-
mized for a wide range of applications, and the hardware features are fixed at the foundry during fabri-
cation. The functionality of a discrete processor is changed by changing the software. In a sense, a discrete 
© 2011 by Taylor and Francis Group, LLC

22-6 
Fundamentals of Industrial Electronics
processor is software programmable. Dedicated boards require that a connection resource be perma-
nently allocated for a specific purpose.
Processor cores can be classified as hard or soft. A hard-core processor is a processor embedded into 
a programmable device. It is called “hard” because it is in the silicon. Since it is part of the silicon, it 
offers better predictability than a soft core in terms of timing performance and area. Hard-core pro-
cessors added to an FPGA offer performance trade-offs somewhere between an ASIC and an FPGA. 
A hard-core processor is more flexible than a discrete processor because it has access to the surrounding 
programmable logic resources, but less configurable than a soft-core processor because the silicon area 
taken up by the core cannot be reprogrammed.
Soft-core processors can be customized to the particular application in the field. In conjunction with 
an FPGA, the soft-core processor is constructed with look-up tables, multipliers, dividers, and on-chip 
memory. Due to direct access to the on-chip programmable logic resources and a customizable general-
purpose bus, a soft-core processor is easily extendable.
Though soft-core processors implemented in an FPGA generally have higher power consumption 
and lower performance characteristics than discrete microprocessors, they provide much greater flex-
ibility and reconfigurable device support. Since the design is in digital form, the processor character-
istics can be altered simply by changing the code and reprogramming the device. The designer can 
specify memory width, ALU functionality, number and types of peripherals, and memory address space 
parameters at compile time. For projects requiring a hardware implementation, the soft-core proces-
sor implemented on an FPGA is faster and more economical than an ASIC in low to medium quantity 
production.
22.9  Applications for Soft-Core Processors
Soft-core processors are often used as building blocks in a larger digital design, with the goal of simplify-
ing data processing of the overall system (i.e., hardware/software codesign). In a sense, the design is not 
fixed. That’s why a soft-core processor is very well suited for use in FPGA designs.
Soft-core processors are suitable for educational purposes (such as courses on microprocessors, hard-
ware/software codesign, and rapid prototyping). They are also valuable for commercial prototyping and 
testing uses. The integration of soft-core processors into existing digital designs provides the capability 
to rapidly add functionality.
Some vendors are also adding memory management units (MMU) that allow for the full-blown 
implementation of linux (most soft-core processors can handle uClinux, which doesn’t require 
MMU).
References
	
1.	 D. Arbinger and J. Erdmann, Designing with an embedded soft-core processor, Embedded Systems 
Conference Silicon Valley 2006. Available: http://www.embedded.com.
	
2.	 Soft Microprocessor, http://en.wikipedia.org/wiki/Soft_processor, Date visited: December 11, 
2008.
	
3.	 Listing of Soft Core Microprocessors at Opencores.com, http://www.opencores.com/projects?cat=10&
lang=0&stage=0&lic=0, Date visited: December 11, 2008 and June 23, 2010.
	
4.	 Field-Programmable Gate Array, http://en.wikipedia.org/wiki/Field-programmable_gate_array, 
Date visited: December 11, 2008.
	
5.	 Soft Core Processor, http://encyclopedia2.thefreedictionary.com/Softcore, Date visited: December 11, 
2008.
	
6.	 J.O. Hamblen, T.S. Hall, and M.D. Furman, 2008. Rapid Prototyping of Digital Systems, SOPC Edition. 
Springer Massachusetts.
© 2011 by Taylor and Francis Group, LLC

Soft-Core Processors 
22-7
	
7.	 Altera Nios II Soft-core Processor Website, http://www.altera.com/products/ip/processors/nios2/
ni2-index.html, Date visited: December 14, 2008.
	
8.	 Xilinx Microblaze Soft-core Processor Website, http://www.xilinx.com/products/design_resources/
proc_central/microblaze.htm, Date visited: December 14, 2008.
	
9.	 Lattice Semiconductor LatticeMico32 Open Source Soft-core Processor Website, http://www.
latticesemi.com/products/intellectualproperty/ipcores/mico32/index.cfm?source=topnav, 
Date visited: December 14, 2008.
© 2011 by Taylor and Francis Group, LLC

23-1
A digital computer is a device capable of solving problems and manipulating information under the 
direction of a given program of instructions. The hardware of a digital computer is a set of digital logic 
circuits that receives information from one or more sources, processes this information, and sends the 
results to one or more destinations. Digital computers allow the automation of arithmetic operations 
and provide an inexpensive way to solve complex numeric problems; store, retrieve, and communicate 
information; and control robots, appliances, automobiles, games, manufacturing plants, and a variety 
of other processes and machines.
In this chapter, we introduce the basic hardware and software elements of a digital computer and 
examine different computer architectures constructed from these elements. As examples, we will con-
sider the architectures of two general-purpose microprocessors, the Intel Pentium and ARM7DMI, and 
two microcontrollers, from the Freescale HCS12 device family and the Intel 8051-compatible device 
families.
23.1  Hardware Organization
The primary hardware elements of a digital computer are a central processing unit (CPU), memory, and 
assorted input and output (I/O) devices, as illustrated in Figure 23.1. The CPU comprises a control unit, 
which coordinates the actions of the other elements in the computer; one or more arithmetic and logic 
units (ALUs), which are digital logic circuits that manipulate data as instructed by the control unit; and 
a set of registers, which are high-speed storage locations used to temporarily store data, addresses, and 
23
Computer Architecture
23.1	 Hardware Organization..................................................................23-1
23.2	 Computer Software..........................................................................23-4
Programming Languages  •  Operating Systems
23.3	 Information Representation in Digital Computers....................23-6
23.4	 Computer Programming Model.................................................23-10
CPU Registers  •  Immediate Operands  •  Memory 
Organization  •  Memory Addressing  •  Computer Instruction 
Types  •  Interrupts and Exceptions
23.5	 Evaluating Instruction Set Architectures..................................23-25
23.6	 Computer System Design.............................................................23-26
23.7	 Hierarchical Memory Systems....................................................23-29
Memory Characteristics  •  Semiconductor Memory 
Technologies  •  Memory System Organization  •  Cache 
Memory  •  Virtual Memory Management
23.8	 Interfaces to Input/Output Devices............................................23-36
23.9	 Microcontroller Architectures....................................................23-37
23.10	 Multiple Processor Architectures...............................................23-39
References����������������������������������對������������������������������������對����������������������������23-43
Victor P. Nelson
Auburn University
© 2011 by Taylor and Francis Group, LLC

23-2 
Fundamentals of Industrial Electronics
other information within the CPU. The ALU, registers, memory, and I/O devices make up the data path 
of the computer.
Each ALU is unique in the types of data that it can manipulate and the set of operations that it can 
perform on these data. Most ALUs support operations on binary integers of various sizes. Some also 
include operations to manipulate floating-point numbers, decimal numbers, and various nonnumeric 
data. Typical ALU operations include
•	 Arithmetic (add, subtract, multiply, divide, compare)
•	 Logical (AND, OR, Exclusive-OR [XOR], complement, bit test/set/clear)
•	 Shift and rotate data
The control unit of a CPU is responsible for fetching program instructions from memory, interpreting 
or decoding the instruction codes, and executing instructions by issuing control signals to the elements 
of the data path. The control unit coordinates all operations of the ALU, memory, and I/O devices by 
continuously cycling through a set of operations that cause instructions to be fetched from the memory 
and executed. This sequence of events is called the instruction cycle of the computer, and is illustrated 
in Figure 23.2. An instruction cycle includes five basic steps:
	
1.	 An instruction is fetched from the memory into the control unit of the CPU.
	
2.	 The control unit decodes the instruction, i.e., determines from the instruction code what opera-
tions to perform.
	
3.	 Any data, called operands, needed to perform these operations are accessed from CPU storage 
registers, retrieved from memory, or read from input devices.
	
4.	 The operation is performed on these operands.
	
5.	 The result is saved in a register, written to a memory location, or sent to an output device.
Program instructions and data are stored and retrieved from the memory of the computer. If a single 
memory is used for both, as is the case in most general-purpose computers and illustrated in Figure 
23.3a, the computer is said to have a Von Neumann architecture, after Jon Von Neumann who is credited 
CPU
Registers
Control unit
ALU
Data path
Control signals
Memory
Input/output
devices
FIGURE 23.1  Computer hardware organization.
Fetch
instruction
Decode
instruction
Fetch
operands
Perform
operation
Save
results
FIGURE 23.2  Instruction fetch and execute cycle.
© 2011 by Taylor and Francis Group, LLC

Computer Architecture 
23-3
with developing the first stored program computer. A computer that uses one memory for instructions 
and a separate memory for data, as shown in Figure 23.3b, is referred to as having a Harvard architec-
ture. Many microcontrollers fall into this category. In addition, a number of high-performance CPUs 
use Harvard architectures to enable instruction and data memories to be accessed concurrently.
The instruction set architecture of a computer refers to the organization of a computer instruction 
set as seen from a programmer’s point of view. Every instruction set architecture is unique in how it 
supports different data types; operations on data; and access to information in registers, memories, and 
I/O devices.
Information is transferred between a computer and the outside world through various I/O devices. 
Programs are usually transferred into the memory of a computer from such peripheral equipment as 
magnetic, optical, or flash memory peripheral storage devices. Data to be used by a program can like-
wise be transferred into the memory from keyboards, scanners, magnetic disks, analog-to-digital con-
verters, communication channels, and other input devices. A program may output data to several types 
of peripherals. Cathode-ray tubes (CRTs), liquid crystal display (LCD) panels, and light-emitting diodes 
(LEDs) are often used to display the results of a program’s calculations, and various types of printers are 
used to produce permanent results. Digital-to-analog converters, motor drivers, communication chan-
nels, plotters, magnetic disks, and other recording equipment are a few commonly used output devices.
Computers are often classified according to levels of integration. A mainframe computer is a large 
machine whose circuitry is typically contained on several circuit boards or cabinets of circuit boards. 
A microprocessor is an integrated circuit (IC) chip containing a complete CPU. Personal computers 
(PCs) are typically built around microprocessors and include a video display system, a keyboard for 
data entry, and disk drives for information storage. Common PC add-ons include printers; point-
ing devices, such as mice, track balls, and joysticks; CDROMs (compact disk read-only memory) 
and tape drives for mass storage of information; sound generators for multimedia applications; and 
modems and network interface hardware for communication with other computers. Engineering 
workstations are similar to PCs, although workstations are oriented more toward intensive graphics 
applications and networking.
To improve performance, some processors incorporate high-speed memory, called cache memory, 
within the CPU itself. Superscalar processors further improve performance by integrating multiple 
ALUs and other functional units within a single CPU to allow multiple instructions to be executed 
concurrently.
A microcontroller is a complete computer on a single IC chip, comprising CPU, memory, and vari-
ous peripheral functions, such as timers, digital-to-analog converters, display drivers, communica-
tion functions, and interfaces to external sensors, actuators, and other devices. To make room for 
these elements on the chip and keep the cost low, microcontroller CPUs often have fewer capabilities 
than general-purpose microprocessors. Microcontrollers are primarily used in embedded control 
systems, in which the computer is embedded within the hardware of such products as automobile 
(a)
Results
Memory
CPU
Data
Instructions
(b)
Results
Instructions
Data
Data
memory
CPU
Program
memory
FIGURE 23.3  Computer system memory architectures: (a) Von Neumann architecture and (b) Harvard 
architecture.
© 2011 by Taylor and Francis Group, LLC

23-4 
Fundamentals of Industrial Electronics
engines, kitchen appliances, cell phones, electronic games, music players, communication equip-
ment, and industrial control systems.
23.2  Computer Software
Computer software comprises programs of instructions that specify how the computer hardware is to be 
utilized to manipulate data. Programs can be classified as application or system programs. An application 
program is a set of instructions, specified in one or more programming languages, designed to perform 
a given task according to a specified algorithm. System programs comprise all of the support software 
provided on a computer system to aid programmers in developing and executing application programs.
23.2.1  Programming Languages
The individual steps of an algorithm or task to be performed by a program must be expressed using the 
statements of a programming language. Every CPU has a unique native machine language that is recog-
nized by its hardware. Machine language is a set of binary codes that inform the CPU of the operations 
to be performed and operands (data items) to be used in these operations. All digital computer instruc-
tions must be represented by these binary codes before the computer can interpret them.
Rather than writing programs directly as sequences of binary codes, a symbolic representation of a 
CPU’s machine language, called assembly language, is often used to develop programs, especially for 
applications that require very small or very efficient programs, such as control systems embedded into 
such products as home appliances and automobiles. The assembly language allows a programmer to 
symbolically specify operations to be performed on the data stored in the internal registers and in the 
memory of a processor without becoming bogged down in creating binary code sequences. A system 
program called an assembler translates the symbolic assembly language instructions into a machine 
language so that the program code can be interpreted by the CPU.
The following is an 8051 assembly language instruction and its equivalent machine language:
Assembly language:
ADD A,#25
Machine language:
00100100 00011001
This instruction tells the 8051 CPU to add 25 to the contents of its accumulator (A register) and 
replace the contents of the accumulator with the computed sum. The first 8 bits of the machine language 
code indicate that the operation is ADD, that register A is to be used, and that an 8-bit data value follows 
as the second byte of the instruction code.
An assembly language programmer must be intimately familiar with the architecture of the spe-
cific CPU being programmed to efficiently design algorithms for a given application in the assembly 
language of that CPU. In contrast, high-level languages allow a programmer to express an algorithm 
for a given application in a more natural way, independent of any particular computer architecture. 
Hundreds of different high-level languages have been developed, many tailored to specific applica-
tions. Among the first were FORmula TRANslation (FORTRAN), developed for numeric applications, 
COBOL (COmputer Business Oriented Language) for business applications, and PROLOG and LISP 
to support artificial intelligence and expert system applications. Some languages, such as BASIC, Perl, 
PHP, Java, C, and C++, are more general purpose, supporting a wide variety of different applications.
Before a computer can execute a program written in a compiled high-level language, such as C and 
C++, the program must first be translated to the native machine language of that computer by a sys-
tem program called a compiler. One of the primary benefits of using a high-level language to write a 
program is that the program can be targeted at different computer architectures by simply recompiling 
it into each architecture’s machine language, as illustrated in Figure 23.4. Thus, a high-level language 
© 2011 by Taylor and Francis Group, LLC

Computer Architecture 
23-5
program is portable across different computer architectures. The process of recompiling a program for a 
different computer architecture is referred to as porting the program to the new architecture.
The following example of a C language statement is a natural way to indicate that the value of variable 
g is to be set to the sum of the values of variables b and c:
	
g = b + c;	
This statement might be translated by a C compiler to the following sequence of assembly language 
instructions for a Freescale HCS12 microcontroller:
LDD
b
;load variable b into accumulator D (ACCD)
ADDD
c
;add variable c to the value in ACCD
STD
g
;store the value in ACCD into variable g
The same C instruction might be translated to the following for an ARM processor:
LDR
r0, = b
;point to variable b
LDR
r1, [r0]
;load variable b into register r1
LDR
r0, = c
;point to variable c
LDR
r2, [r0]
;load variable c into register r2
ADD
r3, r1, r2
;write the sum r1 + r2 into register r3
LDR
r0, = g
;point to variable g
STR
r2, [r0]
;store the sum in variable g
In addition to assemblers and compilers, other system programs assist in the development of application 
programs. These include text editors to create and alter the text of a program, linkers to link together 
multiple program segments, including subprograms from software libraries, and program debugging 
tools. An integrated development environment (IDE) incorporates all of these tools within a single user 
interface, including editing, assembly/compilation, and debugging for a family of CPUs.
Some programming languages, such as BASIC, Perl, PHP, and Javascript, are interpreted rather than 
compiled. Instead of compiling the entire program into the machine language prior to execution, each 
instruction of an interpreted language is individually read, translated to machine language instructions, 
and executed at run time. This occurs each time the instruction is executed, making it slower than a 
compiled program. However, since a program written in an interpreted language does not need to be 
compiled in advance, programs can be written, changed, and tested quickly.
Compiler
Compiler
High-level
language
program
Machine
language
program
Machine
language
program
CPU 1
CPU 2
FIGURE 23.4  Compilation of a high-level language program for two different CPU architectures.
© 2011 by Taylor and Francis Group, LLC

23-6 
Fundamentals of Industrial Electronics
23.2.2  Operating Systems
When a computer is dedicated to one specific task, the application program can be stored permanently 
in the memory of the computer and executed with no other support software. General-purpose comput-
ing systems, however, execute many different programs, which change from day to day and from user to 
user. In addition, multiple users may need to share a single system, or a single user may wish to concur-
rently perform multiple tasks on a single system. In such cases, a control program called an operating 
system is used to coordinate the usage of the facilities of the computer.
An operating system is a program that interprets user commands typed at a keyboard, selected by 
clicking on an icon with a mouse, or read from a file. Some commands are executed by programs built 
into the operating system, while other commands correspond to programs that reside on a disk or are 
otherwise supplied by a user. An operating system also manages the file system on the computer, which 
comprises a directory of files stored on a disk or tape and programs that locate and access these files 
when requested by a program. Operating systems also coordinate access to printers, networks, and 
other I/O devices, and manage CPU time and memory space.
The first PCs were controlled by single-user operating systems, such as MSDOS. A single-user operat-
ing system interprets one command at a time from the user, executes the corresponding program, and 
then waits for another command to be entered. No other program may be executed until the current one 
is finished. Once a user has control of the computer, the user may modify and re-execute programs, or 
execute several different programs before turning the machine over to the next user.
In the single-user environment, much time can be spent idling while waiting for user inputs or data 
transfers involving slow I/O devices. To exploit this idle time, multitasking and multiuser operating 
systems allow CPU time to be shared by multiple programs. The operating system passes control of 
the CPU from program to program, with each program allowed to execute for a small allotment of 
time or until it becomes stalled waiting for input/output. In this manner, the execution of a program 
is interleaved with the execution of other programs until it has completed. The end result is that pro-
grams execute concurrently with each program appearing to have exclusive control of the CPU. Linux 
[1] is an example of a multiuser, multitasking operating system used in a wide variety of embedded 
systems, PCs, workstations, and larger systems. Multiple users can issue commands to the operating 
system of one computer from different terminals, with each user running several programs at the 
same time.
Process control and many other embedded system applications require real-time operation, in 
which the computer must respond to various events and perform designated actions within the given 
time constraints as the events occur. In such applications, a real-time operating system (RTOS) can 
be used to coordinate the execution of processes in response to these events, including scheduling 
and synchronization of processes, controlling access to resources, and managing communication 
between processes.
23.3  Information Representation in Digital Computers
All information in a computer must be represented in patterns of 1’s and 0’s. The assignment of a mean-
ing to a bit pattern is called coding. In general, an n-bit pattern of information can represent 2n unique 
items. CPUs generally support a limited number of pattern lengths. In most general-purpose comput-
ers, the smallest pattern size is 8 bits, referred to as a byte, although some of the early microcontrollers 
worked primarily with 4-bit nibbles of information, and some application-specific CPUs (such as digital 
signal processors, or DSPs) work exclusively with larger pattern sizes. In general, the primary pattern 
length supported by a CPU is referred to as its word size, which is usually an integral number of bytes. 
For example, the word size is 32 bits in the Pentium, PowerPC, and ARM CPUs; 16 bits in the Freescale 
HCS12 and Microchip PIC24F; and 8 bits in the Atmel AVR and 8051-compatible microcontrollers. 
Some advanced processors support 64-bit and larger information patterns.
© 2011 by Taylor and Francis Group, LLC

Computer Architecture 
23-7
Figure 23.5 shows the taxonomy of different information types found in a computer. Addresses 
are pointers to storage locations in memory or I/O device interfaces. Instruction codes tell the CPU 
what operation to perform in a given program step. Data are items to be manipulated by computer 
instructions.
An n-bit data pattern has 2n unique codes, allowing up to 2n items to be represented. Data types 
can be classified as numeric or nonnumeric. Numeric data formats can vary widely from application 
to application, although, in many situations, simple binary integers are sufficient. Binary integers can 
be unsigned or signed. In an n-bit unsigned (ordinal) number, bn−1bn−2…b1b0, each bit is weighted by a 
power of 2, representing the number bn−1 × 2n−1 + bn−2 × 2n−2 + … + b1 × 21 + b0 with values in the range 
[0…(2n − 1)] (see Table 23.1).
Signed integers can be represented in several ways. An n-bit sign-magnitude number format uses the 
leftmost bit to represent the sign of the number and the remaining n − 1 bits to represent the magnitude or 
absolute value of the number. A sign bit of 0 indicates a positive value and 1 indicates a negative value. 
An n-bit sign-magnitude number can represent numbers in the range [−(2n−1 − 1)… + (2n−1 − 1)]. Note 
that there are two representations for the number 0, namely, +0 and −0 (see Table 23.1).
Digital logic circuits that add and subtract numbers in the sign-magnitude format are inefficient. 
Therefore, digital computers normally use the two’s complement number system to represent signed 
numbers. In an n-bit two’s complement number system, positive numbers are represented as they are in 
the sign-magnitude format; the most significant bit is 0 and the remaining n − 1 bits indicate the magni-
tude. The negative of a value A is represented by its two’s complement, defined as 2n − A. This simplifies 
arithmetic hardware by allowing one to compute A − B by forming the two’s complement of B and then 
adding it to A, i.e., A − B = A + (−B), thereby eliminating the need for special subtraction circuits.
Information
Address
Data
Instruction codes
Numeric
Nonnumeric
Floating-point
Fixed-point
Character
Ordinal
(unsigned)
Integer
Sign-magnitude
Two’s complement
Other codes
(graphics, etc.)
FIGURE 23.5  Taxonomy of information representation.
TABLE 23.1  Integer Number Ranges for Different Coding Methods
Bits
Ordinal
Sign-Magnitude
Two’s Complement
4
0…15
−7…+7
−8…+7
8
0…255
−127…+127
−128…+127
16
0…65,535
−32,767…+32,767
−32,768…+32,767
32
0…4,294,967,295
−2,147,483,647…+2,147,483,647
−2,147,483,648…+2,147,483,647
© 2011 by Taylor and Francis Group, LLC

23-8 
Fundamentals of Industrial Electronics
The two’s complement is fairly easy to compute; one method is to complement all of the bits and then 
add 1 to the result. For example, the 8-bit two’s complement number system representation of the value 
−510 would be computed as follows:
	
1.	 Write the 8-bit binary code for + 510 = 000001012.
	
2.	 Complement the bits: 00000101
11110
= 1
10.
	
3.	 Add one to the result: 11111010 + 1 = 11111011.
Therefore, the 8-bit code 11111011 represents the value −510 in the two’s complement number system. 
In contrast, the sign-magnitude code for the value −510 is 10000101, which is the code for +510 with the 
leftmost bit set to 1 to indicate a negative value. The reader is referred to [2] for additional algorithms 
and examples involving signed numbers.
Financial and other applications may require the manipulation of decimal, rather than binary, num-
bers. In such cases, a binary-coded decimal (BCD) coding is used, in which each decimal digit is repre-
sented independently by its 4-bit binary equivalent. Generally, two BCD digits are packed into an 8-bit 
byte; this is referred to as packed BCD. For example, the packed BCD representation of 2510 is coded by 
packing into 8 bits the binary code for 2 (0010) and the binary code for 5 (0101). The result is the packed 
BCD code 00100101. Many general-purpose CPUs provide special arithmetic hardware and instructions 
to assist in manipulating BCD numbers without requiring conversions to and from binary.
If both integer and fractional numbers are needed, a fixed-point or floating-point number format is 
used. The fixed-point notation partitions the n bits used to represent a number into two fixed-length 
parts: k bits to represent the fraction part and n − k bits to represent the integer part, as illustrated in 
Figure 23.6. A binary point is assumed to be at a fixed position between the two parts. An n-bit fixed-
point number is said to have n bits of precision, and can accurately represent a value to within 2−k, the 
value of the least significant (leftmost) bit.
The range of a set of numbers is the span between the largest and smallest magnitudes. For the num-
ber format in Figure 23.6, the largest value is approximately 2n−k, as determined by the number of integer 
bits, and the smallest value is 2−k, which is a function of the number of fraction bits. Integers are special 
cases of fixed-point numbers, with the binary point to the immediate right of the least significant bit.
Scientific and many other applications require very wide ranges of numeric values. In these cases, 
floating-point number formats are used. A floating-point number is generally written in the form 
±m × re, where m is the mantissa, r the radix, and e the exponent of the number. Floating-point 
numbers are represented in a computer system by packing the codes for e and m into a single stor-
age location, as illustrated in Figure 23.7, with the sign of the mantissa usually stored in the leftmost 
bit. The code for radix r need not be stored, since it is always known. The most common radix value is 
r = 2, corresponding to binary numbers. The IBM 360 mainframe architecture used a floating-point 
format based on r = 16.
Prior to the mid-1980s, each computer manufacturer developed its own scheme for encoding floating-
point numbers, making it difficult to transfer data from one computer architecture to another. In 1985, 
American National Standards Institute (ANSI) and the IEEE developed the IEEE Standard for Binary 
Floating-Point Arithmetic, ANSI/IEEE Standard 754-1985 [3], which defines standard single-precision 
(32-bit) and double-precision (64-bit) floating-point formats, shown in Figure 23.7, and related operations 
that are now used in most computer systems.
n–1
Integer
Binary point
Fraction
0
k k–1
FIGURE 23.6  Fixed-point number format.
© 2011 by Taylor and Francis Group, LLC

Computer Architecture 
23-9
The mantissa is stored in a normalized sign-magnitude format. The sign bit is placed in the leftmost 
bit of the 32-bit code, allowing a number to be easily identified as positive or negative. The magnitude 
of the mantissa is of the form 1.F, where F is a 23-bit binary fraction stored in bits 22-0 for the single-
precision format, and a 53-bit fraction stored in bits 52-0 for the double-precision format. Normalized 
forms are characterized by their most significant digits being nonzero, and are used to ensure a single 
unique representation for each floating-point number. For example, the following are a few of the many 
possible representations of the number 1408.
	
10.11 
 
1.011 
 2
0.1011 
 2
0.01011 
 2
9
10
11
12
×
×
×
×
2
	
Requiring the mantissa to be normalized to the form 1.F forces the unique code 1.011 × 210 to be used to 
represent this number.
The 8-bit exponent is stored in the biased, excess-127 format. In the excess-N number format, a bias 
of N is added to each value to force numbers in the range [−N… +(N − 1)] to be represented by a lin-
early increasing number sequence [0…(N − 1)]. In the IEEE Standard 754-1985 format, a bias of 127 is 
added to each exponent value, with the result stored in bits 30–23. Exponents in the range [−127… +126] 
are therefore represented by increasing binary codes from [00000001…11111110]. The exponent codes 
00000000 and 11111111 are reserved to indicate special conditions. For example, the constant zero is 
represented by the all-0’s word, and +/− infinity by an exponent of all 1’s and a mantissa of all 0’s.
Nonnumeric data is represented in a computer by designing a coding scheme that assigns a unique 
binary code to each data item. Alphanumeric and special character information is commonly repre-
sented by the American Standard Code for Information Interchange (ASCII) code, listed in Table 23.2. 
Each printable character has a unique 7-bit code recognized by most devices that send or receive alpha-
numeric information, such as printers and terminals. For example, suppose that we want to encode the 
message “ADD 1.” This message has five characters, the fourth being a space or blank. In the ASCII code, 
our message becomes
A
D
D
space
1
1000001
1000100
1000100
0100000
0110001
Single-precision format
31
30
Exponent E
(excess-127)
Sign of mantissa
Double-precision format
Mantissa M
(fraction)
Exponent E
(excess-1023)
SM
SM
63
62
52 51
Sign of mantissa
Mantissa M
(fraction)
23
22
0
0
FIGURE 23.7  IEEE Standard 754-1985 floating-point formats. (Reproduced from IEEE Standard for Binary 
Floating-Point Arithmetic, ANSI/IEEE Std. 754-1985, IEEE, Inc., New York, 1985. With permission.)
© 2011 by Taylor and Francis Group, LLC

23-10 
Fundamentals of Industrial Electronics
ASCII characters are often padded with an extra zero on the left to allow each code to fit exactly into one 
8-bit byte of memory, or the 8th bit might be used to extend the code to 128 additional symbols.
Many other codes have been developed to represent graphical information, special symbols, audio 
signals, and a wide variety of other information.
23.4  Computer Programming Model
The programming model of a computer system refers to the assembly language programmer’s view of 
the system. From the programmer’s perspective, a computer is a collection of registers and memory for 
storing information, a set of instructions to manipulate data and control program flow, and various 
types of data that can be manipulated by the instruction set.
A computer instruction specifies to the control unit what operation is to be performed, where to 
obtain operands for the operation, and where to store the result of the operation, if a result is produced. 
As with other information, an instruction must be encoded into patterns of ones and zeros. Instruction 
codes are generally subdivided into separately coded fields, as illustrated in Figure 23.8. These fields 
include the operation code (opcode), which specifies what the instruction is to do, and one or more 
operand specifiers, which indicate the operands to be used for the instruction.
The number of operand specifiers encoded in an instruction differs between CPUs. Most reduced 
instruction set computer (RISC) processors, such as ARM [4], Sparc [5], PowerPC [6], and MIPS [7], use 
a three-operand format for all ALU instructions, specifying two source operands and a destination. For 
example, the following ARM instruction tells the CPU to read two operands from registers R2 and R3, 
add the operands, and store the sum in register R1:
ADD
R1,R2,R3
;(R2)+(R3)→R1
TABLE 23.2  Seven-Bit ASCII Character Codes (c6c5c4c3c2c1c0)
c6 c5 c4
c3c2c1c0
*000
001
010
011
100
101
110
111
0000
NUL
DLE
SP
0
@
P
’
p
0001
SOH
DC1
!
1
A
Q
a
q
0010
STX
DC2
“
2
B
R
b
r
0011
ETX
DC3
#
3
C
S
c
s
0100
EOT
DC4
$
4
D
T
d
t
0101
ENQ
NAK
%
5
E
U
e
u
0110
ACK
SYN
&
6
F
V
f
v
0111
BEL
ETB
‘
7
G
W
g
w
1000
BS
CAN
(
8
H
X
h
x
1001
HT
EM
)
9
I
Y
i
y
1010
LF
SUB
*
;
J
Z
j
z
1011
VT
ESC
+
;
K
[
k
{
1100
FF
FS
‘
<
L
\
l
|
1101
CR
GS
-
=
M
]
m
}
1110
S0
RS
.
>
N
∧
n
∼
1111
S1
US
/
?
O
_
o
DEL
Operand
specifier 2
. . .
Operand
specifier 1
Operation
code
FIGURE 23.8  Instruction code format.
© 2011 by Taylor and Francis Group, LLC

Computer Architecture 
23-11
Pentium ALU instructions use a two-operand format [8]. Both operand sources are specified, and the 
left-hand operand is also the destination for the result. The following instruction adds the operands in 
registers AX and BX and stores the sum in AX:
ADD
AX,BX
;(AX)+(BX)→ AX
The source operand that was originally in AX is replaced with the computed sum. Therefore, if the 
programmer wishes to retain the original source operand, it must be copied from AX to some other place 
before executing the above instruction. This provides less flexibility for the programmer than the three-
operand format, but instructions can be more compact, since they require only two operand specifiers.
The HCS12 [9] is one of a number of CPUs that use a one-operand format. The programmer specifies 
one of the source operands. The other source operand comes from a default location, with that location 
also receiving the result. The following instruction adds the constant 15 to the accumulator register A, 
with the sum stored in A, replacing the source operand:
ADDA
#15
;(A)+ 15→ A
The opcode ADDA tells the CPU that accumulator A provides the second source operand and is the 
destination. The operand must be moved into accumulator A by a previous instruction, and the result 
may need to be stored elsewhere to allow A to be used for a subsequent instruction. This provides less flex-
ibility for the programmer, but instructions can be shorter since there is only one operand specifier. Note 
that the 8051 and Pentium specify the source of the data as the right-hand operand and the destination 
as the left-hand operand, while the HCS12 specifies one operand as part of the instruction mnemonic.
Instruction operands may be embedded within the instruction code, retrieved from CPU registers, 
or read from external memory locations. Some CPUs also recognize special I/O device addresses; others 
access information from I/O devices via their memory address space. RISC architectures restrict ALU 
operands to register immediate values only; memory may only be accessed by special load and store 
instructions that move data between registers and memory.
23.4.1  CPU Registers
A register is simply an n-bit binary storage element. CPU registers are used to temporarily hold data and 
memory address values that might be needed in the near future. Being located within the CPU, registers 
can be accessed more quickly and more efficiently than external memory. In addition, since the num-
ber of registers is relatively small, operand specifiers need only be a few bits, as compared to memory 
addresses that require considerably more bits to represent. For example, a 32-bit ARM instruction code 
contains two or three 4-bit operand specifiers, each of which identifies one of 16 registers (R0–R15) to be 
used as operands. In contrast, ARM memory addresses are 32-bits each, so it is not possible to include a 
memory address within a 32-bit instruction code.
Every instruction set architecture has its own distinctive set of program-accessible registers that may 
be used to store data, addresses, and control or status information. Figure 23.9 shows the register sets of 
four popular microprocessors.
Every CPU contains one register called a program counter (PC) or instruction pointer (IP) that 
always contains the address in the memory of the next program instruction to be executed. The PC/IP 
register is updated automatically as each instruction is executed, so that it points to the next instruction 
to be fetched from memory.
One or more CPU registers are available to the programmer to hold memory addresses or information 
used to compute addresses. All 16 ARM registers (R0–R15) can hold either data or addresses. Likewise, 
Pentium registers EBX, ESI, EDI, and EBP can be used for both addresses and data. In contrast, 8- and 
16-bit microcontrollers usually have very limited memory-addressing capabilities. For example, the 
© 2011 by Taylor and Francis Group, LLC

23-12 
Fundamentals of Industrial Electronics
31
0
R0
R1
R2
R3
R4
R5
R6
R7
R8
R9
R10
R11
R12
Flages
CS
DS
ES
SS
FS
GS
Instruction pointer
Flags
Code segment
Data segment
Extra segment
Stack segment
R13
R14
R15 (PC)
CPSR
(c)
(d)
Accumulator
Base index
Count
Data
Stack pointer
Base pointer
Destination index
Source index
AH
BH
CH
DH
DX
SP
BP
DI
SI
IP
CX
BX
AX
AL
BL
CL
DL
31
16 15
8
16-bit
names
8-bit
names
7
0
EAX
EBX
ECX
EDX
ESP
EBP
EDI
ESI
EIP
EFLAGS
32-bit
names
15
15
0
Index register X
15
15
15
0
7
Program counter PC
Stack pointer SP
Index register Y
CCR
0
(b)
0
0
0
D
A
B
7
0
Accumulators
0
7
7
0
R0
R1
R2
R3
R4
R5
R6
R7
DPTR
15
8 7
0
0
0
7
Scratchpad
registers
(a)
7
7
15
PC
PSW
SP
0
0
0
Accumulator
A
B
DPL
DPH
7
FIGURE 23.9  Register sets of four common CPUs: (a) 8051/8052, (b) Freescale HCS12 (From Cady, F.M., Software 
and Hardware Engineering: Assembly and C Programming for the Freescale HCS12 Microcontroller, 2nd edn., Oxford 
University Press, New York, 2008. With permission.), (c) Intel Pentium (From Brey, B.B., The Intel Microprocessors: 
8086/8088, 80286, 80386, 80486, Pentium, Pentium Pro Processor, Pentium II, Pentium III, Pentium 4: Architecture, 
Programming and Interfacing, 7th edn., Pearson-Prentice Hall, Upper Saddle River, NJ, 2006. With permission.), and 
(d) ARM. (From Hohl, W., ARM Assembly Language: Fundamentals and Techniques, CRC Press, Boca Raton, 
FL, 2009. With permission.)
© 2011 by Taylor and Francis Group, LLC

Computer Architecture 
23-13
HCS12 has only two registers, index registers X and Y, that can be used in memory addressing. Methods 
for addressing memory will be discussed in Section 23.4.4.
The 8051 and HCS12 microcontrollers are similar to some older computers in that arithmetic and logic 
operations utilize accumulator registers, i.e., registers in which results are “accumulated.” The 8051 has a 
single accumulator, labeled A in Figure 23.9a, and the HCS12 has two accumulators, labeled A and B in 
Figure 23.9b. In the HCS12, the two 8-bit accumulators can be concatenated into a double accumulator, 
labeled D in Figure 23.9b, for 16-bit operations. Arithmetic operations such as addition and subtraction 
combine the number in the accumulator with a second operand and write the result back to the accumula-
tor, overwriting the original accumulator contents. The second operand can be an immediate value or the 
contents of another register or memory location. To combine two data values from memory, one of them 
must be moved to the accumulator prior to the operation. After the operation, the result can be moved to 
a memory location if desired. In the HCS12, most instructions can use either the A or the B accumulator, 
and the A and B accumulators can be used together as a single 16-bit accumulator, referred to as register D.
The Pentium and ARM CPUs give more flexibility to a programmer by providing a number of general-
purpose registers, any of which can supply operands for, or receive the results of, arithmetic and logical oper-
ations. In the ARM, any of its 16 registers, 32 bits each, R0–R15, may be a source and/or a destination in 
any instruction. Likewise, the Pentium provides eight general-purpose registers that can be used as operand 
sources/destinations. Pentium supports 8-bit, 16-bit, and 32-bit ALU operations, using the corresponding reg-
ister names shown in Figure 23.9c. For example, an 8-bit operation might use the AL or AH register, a 16-bit 
operation the AX register, and a 32-bit operation the EAX register. All four are located within the same 32-bit 
register. AL is the low 8 bits, AH the next 8 bits, and AX the low 16 bits of the EAX register. The following 
illustrate 8-, 16-, and 32-bit addition operations in the Pentium; the data size is implied by the register names:
ADD
AL,BH
;AL + BH → AL (8-bit bytes)
ADD
AX,BX
;AX + BX → AX (16-bit words)
ADD
EAX,EBX
;EAX + EBX → EAX (32-bit long words)
While the eight Pentium general registers can be used in all arithmetic and logical instructions, most 
of these registers also have additional special functions and are named accordingly. The four general-
purpose registers EAX, EBX, ECX, and EDX are used by some instructions as an accumulator, a base 
address register, a count register, and an I/O-addressing register, respectively. The four index and pointer 
registers ESI, EDI, ESP, and EBP are used in memory addressing. Each half of the four general registers 
can be used independently in 8-bit operations, and hence the high and low parts of these registers are 
labeled AH/AL, BH/BL, CH/CL, and DH/DL.
Most CPUs contain a processor status register (PSR), sometimes called a condition code register, 
that contains information about internal CPU conditions and about ALU operations that have been 
performed. PSRs usually contain one or more condition code bits, or flags, which characterize the result 
of a previous arithmetic or logical operation performed in the ALU. These allow decisions to be made 
based on the outcomes of these operations. Table 23.3 lists the condition code flags of the HCS12, which 
TABLE 23.3  HCS12 Condition Code Flags
Flag
Status of Last Result if Flag = 1
Z (Zero)
Result zero
N (Sign)
Result negative
C (Carry)
Carry out of the most significant bit of the result
V (Overflow)
Result out of range for the given number of bits
H (Half Carry)
Carry from bit 3 to bit 4 of result
Source:	 Cady, F.M., Software and Hardware Engineering: Assembly and 
C Programming for the Freescale HCS12 Microcontroller, 2nd edn., Oxford 
University Press, New York, 2008.
© 2011 by Taylor and Francis Group, LLC

23-14 
Fundamentals of Industrial Electronics
are typical of those found in most CPUs. The half carry flag is used to support operations on BCD values, 
representing a carry from one decimal digit to the next within a byte.
In addition to regular memory addressing, many CPUs support a special last-in/first-out data struc-
ture in memory called a push-down stack. A stack is a convenient place to temporarily save information 
and subsequently restore it. A CPU running a program may be temporarily interrupted to execute some 
other program. The state of the running program is saved temporarily on a stack while the other pro-
gram is executed, and then restored from the stack when that program is finished, allowing the original 
program to continue where it left off.
A dedicated stack pointer (SP) register contains the address of the top element on the stack. An operation 
called PUSH adds an element to the stack, and an operation called POP or PULL removes an element from 
the stack, as illustrated in Figure 23.10. The SP automatically increments and decrements as elements are 
added to and removed from the stack. ARM does not have dedicated PUSH/PULL instructions, although the 
memory-addressing capabilities of the memory load and store instructions can perform basic stack opera-
tions, using any of the 16 registers as an SP. In lieu of a stack, ARM saves its program counter and the current 
PSR in registers R14 and SPSR (saved processor status register), respectively, for subroutine calls and interrupts.
23.4.2  Immediate Operands
A constant to be used as an operand for an instruction may be encoded directly within the instruction 
as the operand specifier. Such a data value is referred to as an immediate operand, because it is imme-
diately available to the CPU from the fetched instruction, without having to access additional storage 
locations. The following instructions add the immediate operand 5 to a designated CPU register:
8051:
ADD
A,#5
;A + 5 → A
HCS12:
ADDA
#5
;ACCA + 5 → ACCA
Pentium:
ADD
EAX,5
;EAX + 5 → EAX
ARM:
ADD
R1,R2,#5
;R2 + 5 → R1
In general, immediate values are encoded with the same number of bits as the other operand(s) of 
the instruction, and appended to the instruction code. In ARM and other RISC processors, however, all 
instructions are encoded in 32-bits, which must include the opcode and all operand specifiers. Hence, 
ARM limits an immediate operand to an 8-bit value, with an optional left or right shift. This value will 
be extended by the CPU to 32 bits before performing the operation.
23.4.3  Memory Organization
A computer system utilizes memory elements for storing program instructions, data, and other infor-
mation. From the viewpoint of the instruction set, memory is an array of words, each identified by a 
B
C
A
A
A
B
C
X
X
A
A
B
C
B
C
Y
X
B
C
SP
SP
SP
SP
SP
POP X
POP Y
PUSH Y
PUSH X
Initial
stack
FIGURE 23.10  Push-down stack PUSH and POP operations.
© 2011 by Taylor and Francis Group, LLC

Computer Architecture 
23-15
unique address that indicates its location within the memory. The concept of a memory address is equiv-
alent to that of a telephone number. Every telephone is assigned a unique number comprising an area 
code, an exchange, and a number within that exchange. Similarly, each memory location is assigned 
a unique address that identifies a memory module and a specific storage location within that module.
Each memory word contains one or more addressable bytes, as illustrated in Figure 23.11. The num-
ber of bits in the data path of the CPU determines the number of bytes per word of the memory. For 
example, the 8051 has an 8-bit data path and, thus, has a byte-wide memory organization, as in Figure 
23.11a. The HCS12 has a 16-bit data path and supports operations on both bytes and words. Therefore, 
memory must be byte-addressable, i.e., each byte of memory must have a unique address. Figure 23.11b 
shows two 16-bit memory formats. The HCS12 uses the little endian format, i.e., the least significant 
byte of data is placed in the lower numbered address. The Motorola 68000 uses the big endian format, in 
which the least significant byte of data is placed in the higher numbered address.
The Pentium has a 32-bit data path and supports operations on 32-bit words, 16-bit half-words, and 
8-bit bytes. The ARM likewise has a 32-bit data path, but all arithmetic and logical operations are per-
formed exclusively on 32-bit data. Bytes, half-words, and words can be transferred between the ARM 
CPU registers and memory, but a byte or half-word read from memory is converted into 32 bits before 
being placed in the target register. Memory for these CPUs is organized as 4 bytes per word, as shown 
in Figure 23.11c. Both CPUs can access one, two, or all 4 bytes of a memory word with a single read or 
write operation. While the Pentium uses the little endian format, the ARM processor is unique in that 
it can be configured at power-up for either big or little endian format, as desired by the system designer.
The number of addressable memory locations in a computer is a function of the number of bits used 
by the CPU to represent memory addresses. An N-bit address can address 2N locations. For example, 
the 8051 and HCS12 use a 16-bit address, allowing them to address 216 = 64 kB of memory. The ARM 
uses 32 address bits, and can address 232 = 4 GB of memory, organized as 4 bytes per word for a total of 
230 = 1 G words.
0
1
2N–1
(a)
(b) Little endian format
3
2
2
3
1
0
0
1
Big endian format
2N–1
2N– 2
2N– 2
2N– 1
(c)
Big endian format
Little endian format
2N– 4
2N– 3
2N– 2
2N– 1
4
5
6
7
3
2
1
0
2N–1
2N–2
2N–3
2N–4
3
2
1
0
4
5
6
7
FIGURE 23.11  Byte-addressable memory organizations (2N bytes): (a) byte-wide, (b) word-wide, and (c) double-
word-wide organizations.
© 2011 by Taylor and Francis Group, LLC

23-16 
Fundamentals of Industrial Electronics
23.4.4  Memory Addressing
To retrieve an operand from memory or write a result to memory, the address of that memory location 
must be specified by the instruction being executed. In most CPUs, memory addresses may be specified 
directly or indirectly.
23.4.4.1  Direct Addressing
The location of the operand is explicitly specified either numerically or symbolically when writing the 
instruction. The operand address is embedded within the assembled instruction code, as illustrated in 
Figure 23.12. The following are examples of direct addresses specified by assembly language instruc-
tions. (The ARM does not support direct addressing.)
HCS12:
STAA
103
;contents register A to M[103]
8051:
LD
R0,103
;contents of M[103] to register R0
Pentium:
MOV
AL,BOB
;BOB represents memory address 103
The last example uses the symbolic label BOB to represent the memory address 103. The actual address 
of BOB is determined by the assembler and inserted into the instruction code when the instruction is 
assembled.
23.4.4.2  Indirect Addressing
It is often the case that a programmer does not know in advance where a particular operand will be 
located in memory at the time an instruction is executed; in such cases, the operand address is deter-
mined while the program is running. Examples include arrays of numbers that are accessed using a 
starting address of the array and an index into the array, and data accessed using pointers. In these 
cases, the address is specified indirectly. The CPU is either told where to find the address, in a register or 
memory location, or how to calculate the address.
Figure 23.13 illustrates register indirect addressing of the data in memory location 103. The operand 
specifier in the instruction code indicates that the operand address is contained in register R. Since there 
are relatively few registers in a CPU, as compared to the number of addressable memory locations, the oper-
and specifier is only a few bits. The following are examples of register indirect addressing for several CPUs:
Pentium:
MOV
AL,[BX]
;address 103 in register BX
HCS12:
LDAA
X
;address 103 in index register X
8051:
MOV
@R1,A
;address 103 in register R1
ARM:
LDRB
R2,[R3]
;address 103 in register R3
Instruction
Opcode
103
Memory
25
105
104
103 (BOB)
102
101
100
FIGURE 23.12  Direct memory addressing.
© 2011 by Taylor and Francis Group, LLC

Computer Architecture 
23-17
The ARM and HCS12 support special auto-increment and auto-decrement modes of register indi-
rect addressing, in which the address register is automatically incremented after, or decremented 
before, a memory access. This simplifies access to tables of data in which the elements are to be 
accessed sequentially, as illustrated in the following example, which computes the sum of a list of 
32-bit numbers in a table:
LDR
R0,#100
;Load size of TABLE into R0
LDR
R1,=TABLE
;Load address of TABLE into R1
LDR
R2,#0
;Initialize SUM to 0 in R2
Loop:
LDR
R3,[R1],#4
;Read element TABLE(I) and increment pointer
ADD
R2,R2,R3
;SUM = SUM + TABLE(I)
DBEQ
R0,Loop
;Decrement R0 and repeat above until R0 = 0
The LDR instruction at location Loop adds 4 to the address in register R1 (called post-increment) after 
reading the 4-byte (32-bit) data word, leaving R1 pointing to the next element of the table.
The HCS12 and a few other CPUs also support memory indirect addressing modes, in which the 
address of an operand is contained in a designated memory location. This requires two memory accesses: 
one to fetch the operand address and another to fetch the operand itself.
23.4.4.3  Base/Indexed Addressing
Data are often stored in tables, lists, records, or other data structures for which addresses are specified in 
two parts: a base (beginning) address of the data structure and an offset, or index, from the beginning. 
The operand specifier either directly or indirectly identifies the base address and the index.
The base address, the index, or both are usually retrieved from registers. The following example 
instructions, illustrated in Figure 23.14, designate an address register for the base address and specify 
a constant index of 3. This form of base-indexed addressing is useful for accessing records and similar 
data structures in which each element is at a known offset from the beginning of the structure.
Pentium:
MOV
AX,3[BX]
;address = (BX) + 3
ARM:
LDRB
R0,[R1,#3]
;address = (R1) + 3
HCS12:
LDAA
3,X
;address = (X) + 3
For accessing linear arrays of data, it may be more convenient to explicitly specify the base address as 
a constant, and then designate a register containing an index as shown in Figure 23.15 and the following 
Instruction
Opcode
R
103
Register R
Memory
25
105
104
103
102
101
100
FIGURE 23.13  Indirect memory addressing.
© 2011 by Taylor and Francis Group, LLC

23-18 
Fundamentals of Industrial Electronics
instructions. ARM limits the constant to a 12-bit number, to fit within the 32-bit instruction code, so 
not all base addresses can be written as constants.
Pentium:
MOV
AX,100[BX]
;address = 100 + (BX)
ARM:
LDRB
R0,[R1,#100]
;address = 100 + (R1)
6805:
LDAA
100,X
;address = 100 + (X)
Alternatively, some CPUs allow a base address to be in one register and an index in a second register, 
as shown in Figure 23.16 and in the following examples:
Pentium:
MOV
AX,[BX][SI]
;address = (BX) + (SI)
ARM:
LDR
R1,[R2,R3]
;address = (R2) + (R3)
HCS12:
LDY
D,X
;address = (D) + (X)
The following program shows how to store a data word in an indexed array variable, TABLE(I), in the 
ARM, where I is a variable to be used as the array index:
LDR
R0,=TABLE
;R0 points to TABLE
LDR
R1,=I
;R1 points to index I
LDR
R2,[R1]
;Load index I into R2
STRB
R3,[R0,R1]
;Store R3 at TABLE(I)
ARM and Pentium support a scaled index addressing mode, in which the index is multiplied by a 
scale factor corresponding to the number of bytes in the accessed data item. This allows a simple index 
Instruction
Opcode
3
R
Index
Base
+
100
Register R
Array base
25
Memory
105
104
103
102
100
101
Array
index
FIGURE 23.14  Addressing a record element with variable base and constant offset.
Instruction
3
25
Memory
105
104
103
102
101
100
Array
index
Opcode
R
100
Base
+
Index
Array base
Register R
FIGURE 23.15  Addressing an array with constant base and variable offset.
© 2011 by Taylor and Francis Group, LLC

Computer Architecture 
23-19
to be automatically converted into a displacement from the beginning of a table of values, as illustrated 
in Figure 23.17 and in the following examples, where ARM and Pentium registers R2 and ECX, respec-
tively, contain index value 3. Note that the array index 3 corresponds to an offset of 12 bytes from the 
base of the array. In the ARM instruction, the designation SHL #2 tells the CPU to shift the number in 
R2 to the left by 2 bit positions, effectively multiplying that value by 4.
ARM:
LDR
R0,[R1,R2,SHL #2]
;Memory address = (R1) + (4*R2)
Pentium:
MOV
EAX,[EBX + 4*ECX]
;Memory address = (EBX) + (4*ECX)
23.4.4.4  Program-Counter-Relative Addressing
It is often necessary to jump or branch from one point in a program to another. Instead of specifying the 
target address within the branch instruction, most CPUs compute the target address by adding to the 
program counter a displacement from the current instruction to the target instruction. This is referred 
to as program-counter-relative addressing. The advantage of doing this is that the code can be made 
position independent and relocatable. This means that the program can be loaded in any location in 
memory without reassembling or recompiling it, since branch instructions are only dependent on the 
distance to each target address and not on the absolute value of the address.
23.4.5  Computer Instruction Types
Digital computer instructions can be organized into seven basic categories: data transfer, arithmetic, 
logical, shift/rotate, control transfer, input/output, and processor control.
+
Base
N(5)
Memory
N(4)
N(3)
N(2)
N(1)
N(0)
Array N
100
104
108
112
116
120
Oﬀset =
4 × index
Instruction
Opcode
R1
R2
100
×4
3
R2-Index
R1-Base
FIGURE 23.17  Scaled index for an array of 4-byte data values.
Instruction
Opcode
R1
R2
3
+
Array base
25
Memory
105
104
103
102
101
100
Array
index
100
R1-Base
R2-Index
FIGURE 23.16  Addressing an array using both base and index registers.
© 2011 by Taylor and Francis Group, LLC

23-20 
Fundamentals of Industrial Electronics
23.4.5.1  Data Transfer Instructions
Data transfer instructions load a CPU register with data from a memory location, store the contents of 
a CPU register into a memory location, and move data from one CPU register to another, or from one 
memory location to another. The following are example data transfer instructions:
8051:
MOV
R0,#5
;move constant 5 into R0
MOV
A,R0
;register R0 to accumulator A
MOV
R0,A
;accumulator A to register R0
XCH
A,R0
;exchange/swap contents of A and R0
HCS12:
LDAA
MEMY
;memory to accumulator A
STAA
MEMY
;accumulator A to memory
TBA
;accumulator B to accumulator A
Pentium:
MOV
AX,MEMY
;memory to register AX
MOV
MEMY,AX
;register AX to memory
MOV
AX,BX
;register BX to register AX
XCHG
AX,BX
;exchange/swap contents of AX and BX
ARM:
LDR
R0,[R1]
;load R0 from memory
STR
R0,[R1]
;store R0 into memory
SWP
R0,[R1]
;swap words between R0 and memory
Other examples of data transfer instructions are PUSH and POP operations using the SP register, as 
described earlier, and instructions to load address registers with the computed operand addresses. The 
following instructions compute the sum of a base address and an index, and place the result into an 
address register, to be used as a pointer:
Pentium:
LEA
DI,TABLE[SI]
;DI points to TABLE + (SI)
HCS12:
LEAX
TABLE,X
;X points to TABLE + (X)
23.4.5.2  Arithmetic Instructions
Instructions such as add, subtract, multiply, and divide perform binary arithmetic on integer operands. 
Not all CPUs provide all four functions. Some simple microcontrollers provide only add and subtract 
instructions and leave it to the programmer to write short programs to perform multiplication or divi-
sion. Some CPUs include additional instructions to increment and decrement binary numbers to facili-
tate counting operations and the modification of memory addresses.
CPUs that support decimal number formats provide special instructions to perform binary arith-
metic on BCD numbers, either directly or indirectly. The Motorola 68000 and the IBM 360 had special 
BCD add and subtract instructions, while most other CPUs, including Pentium, HCS12, and 8051, sup-
port the addition of BCD numbers by using the normal binary ADD instruction followed by a special 
decimal adjust instruction to correct the result. The following example illustrates the addition of two 
packed BCD numbers:
HCS12:
ADDA
N
;binary sum of A + N in A
DAA
;decimal adjust result in AL
One must often perform arithmetic on multi-precision numbers, which have more bits than the word 
size of the CPU. This is done as with pencil and paper, where one adds the two least significant digits of 
a pair of numbers, producing a digit and possibly a carry. If there is a carry, 1 is added to the next pair 
of digits and so on. CPU add and subtract operations set the carry flag in the PSR to 0 or 1 to indicate 
© 2011 by Taylor and Francis Group, LLC

Computer Architecture 
23-21
that a carry was generated, or a borrow was required, to complete the operation. An add-with-carry or 
subtract-with-borrow instruction uses the carry flag to adjust the next pair of digits accordingly. The 
following example illustrates the computation of H = H + G on a Pentium, where H and G are 32-bit 
numbers and CF is the carry flag:
	
+
CF
G G
H H
H H
1
0
1
0
1
1
*
*
MOV
AX,G
;Get low word of G
ADD
H,AX
;Add to low word of H and set CF (CF, H*0 = G0 + H0)
MOV
AX,G + 2
;Get high word of G
ADC
H + 2,AX
;Add with carry to high word of H (H*1 = G1 + H1 + CF)
23.4.5.3  Logical Instructions
Logical instructions apply the Boolean AND, OR, and XOR operators to the corresponding bits of two 
operands. This gives the computer the ability to selectively set, clear, complement, or test individual 
bits, or groups of bits, within a memory location or I/O device register. Table 23.4 summarizes the three 
Boolean operators applied to a 1-bit Boolean variable.
The AND operator can be used to force selected bits of a word to 0, as illustrated in Figure 23.18a. The 
second operand is a bit pattern called a mask that contains a 0 in each bit position that is to be forced 
to 0, and a 1 in each bit position that is to be left unchanged. Similar masks can be created for the OR 
operator to force selected bits to 1, and for the XOR operator to force selected bits to be complemented. 
These are illustrated in Figure 23.18b and c, respectively. The corresponding HCS12 logical instructions 
are also shown in Figure 23.18 for each case.
Many I/O devices contain a status register whose bits reflect the readiness of the device to perform 
an operation. The AND operator can be used to isolate a selected bit of a byte read from a status register 
to determine if that bit is 0 or 1. This is illustrated in Figure 23.19, which shows the HCS12 logical AND 
instruction ANDA #%00000010.
The mask 00000010 forces all bits to 0 except for bit b1. If the result is 00000000, then the zero 
flag is set and it follows that b1 = 0; otherwise, the zero flag is cleared, indicating a nonzero result, 
from which it can be implied that b1 = 1. The result of a logical AND 
instruction can be tested by a conditional jump instruction, such as 
the following HCS12 instruction, which jumps to location B1_ZERO 
if the zero flag is set, or otherwise continues with the next sequential 
instruction:
BEQ
B1 _ ZERO
;Jump if zero flag set (b1 = 0)
b0
b2 b1
b3
b4
b5
b6
b7
b0
b1
b2
b3
b4
b5
b6
b7
0
1
0
0
0
0
0
0
XORB #%00000010
1 b0
b2
b3
b4
b5
b6
b7
b0
b1
b2
b3
b4
b5
b6
b7
<
0
1
0
0
0
0
0
0
ORAB #%00000010
0
1
0
1
1
1
1
1
1
b0
b2
b3
b4
b5
b6
b7
b0
b1
b2
b3
b4
b5
b6
b7
<
ANDB #%11111101
(a)
(b)
(c)
FIGURE 23.18  Logical operations used to alter a selected bit: (a) Clear b1, (b) Set b1, and (c) Toggle b1.
TABLE 23.4  Boolean Operations 
on Bit Variable b
AND
OR
XOR
b • 0 = 0
b + 0 = b
b ⊕ 0 = b
b • 1 = b
b + 1 = 1
b ⊕ 1 = b−
© 2011 by Taylor and Francis Group, LLC

23-22 
Fundamentals of Industrial Electronics
For example, assume that a printer interface contains a status register 
in which the rightmost bit indicates whether the printer is ready to accept 
another character to print. The following Pentium program loop will repeat 
continuously as long as the “printer ready” bit is 0. The CPU will exit the 
loop and continue as soon as the ready bit becomes 1.
Check:
IN
AL,PrintStatus
;read printer status register
AND
AL,00000010
;isolate “printer ready” bit
JZ
Check
;go back to check if printer not ready
The HCS12 and some other microcontrollers provide extensions of the logical operators to explicitly 
set, clear, and test bits of a byte. These are illustrated in the following examples:
BCLR
PortA,%00000101
;clear bits 2 and 0 of the byte at PortA
BSET
PortA,%10000000
;set bit 7 of the byte at PortA
Wait:
BRCLR
PortA,%00000010,Wait
;branch to Wait if bit 1 of PortA is 0
Note that the third instruction effectively performs the same function as the printer status check loop 
above. It reads the byte at PortA, masks all but bit 1, and branches to address Wait if the bit is clear (0). 
This instruction would therefore repeat until the bit is eventually not clear (1).
23.4.5.4  Shift and Rotate Instructions
Shift and rotate instructions slide bits right or left within a register or memory location, as illustrated in 
Figure 23.20. These can be used for extracting or combining bit fields within an operand, to convert data 
between parallel and serial forms, and to perform multiplication and division by powers of 2.
A logical shift operation shifts the bits right or left by one bit position, with the vacated bit replaced by 
a 0. For unsigned numbers, this is equivalent to dividing or multiplying the number by 2. An arithmetic 
right shift implements a divide-by-2 operation on a two’s complement number by preserving the sign bit 
as the operand is shifted. Some CPUs allow an operand to be shifted by more than 1 bit position with a 
single instruction. The following HCS12 example packs two BCD digits into a single byte by shifting one 
digit 4 bits to the left, and then combining the two digits:
LSLA
;shift BCD digit to upper nibble of A
LSLA
LSLA
LSLA
ORAA
Memy
;combine two BCD digits from A and Memy
0
0
0
0
0
0
0
0
1
0
0
0
0
0
0
b1
b0
b1
b2
b3
b4
b5
b6
b7
<
FIGURE 23.19  Using logi-
cal AND to isolate 1 bit.
(a)
0
0
(c)
(d)
(b)
FIGURE 23.20  Shift and rotate operations: (a) logical shift, (b) arithmetic shift right, (c) circular rotate, and 
(d) circular rotate through carry.
© 2011 by Taylor and Francis Group, LLC

Computer Architecture 
23-23
A circular rotate instruction performs a shift operation while replacing the vacated bit with the bit 
shifted out of the other end of the operand. An alternate rotate operation is often provided that rotates the 
number through the carry flag of the PSR. In most CPUs, the bit shifted out of an operand is copied to the 
carry flag of the PSR, where it can be tested or used to support multi-precision shift operations. A multi-
precision number can be shifted by using the carry flag as a link between parts of the number, allowing a 
bit shifted out of one part to be shifted into the other using a rotate-through-carry operation. The follow-
ing Pentium example multiplies a 32-bit number by 2, by shifting 1 byte at a time 1 bit to the left:
SHL
NUMBER
;shift memory byte 1 bit left
RLC
NUMBER + 1
;shift carry and 2nd byte 1 bit left
RLC
NUMBER + 2
;shift carry and 3rd byte 1 bit left
RLC
NUMBER + 3
;shift carry and 4th byte 1 bit left
23.4.5.5  Control Transfer Instructions
The normal flow of a program is to execute instructions in the order listed in the program, fetched from 
sequential memory addresses. To control this flow, the program counter increments automatically after 
each instruction. Jump, branch, and subroutine call instructions interrupt the normal flow by transfer-
ring the control of the program to some instruction other than the next one in sequence. This supports 
the design of looping and decision-making programs, as well as supporting procedure and function 
calls. The following are examples of instructions that unconditionally transfer the control of a program 
to location X within the current program:
8051/Pentium:
JMP Target
HCS12:
JMP Target or BRA Target
ARM:
B Target
Decision making and looping require conditional branch instructions that jump only if a given con-
dition is true, but continue with the next sequential instruction if the condition is false. Conditional 
branch instructions test selected bits of the PSR, which reflect the result of a previous arithmetic or 
logical operation. The following Pentium program adds a list of four numbers in memory, decrementing 
the SI register at the end of each iteration and repeating the ADD, DEC, and JGE instructions as long as 
SI is greater than or equal to 0:
MOV
SI,3
;set counter to 3
MOV
AL,0
;clear accumulator
Start:
ADD
AL,TABLE[SI]
;add next element of TABLE
DEC
SI
;subtract 1 from SI
JGE
Start
;repeat if SI ≥ 0
The relationship between two operands can be tested by subtracting them and then testing the resulting 
condition codes according to Table 23.5. Most CPUs provide a compare instruction (CMP) that performs 
the subtraction and sets the condition code flags, but does not save the actual result in a destination. The 
following HCS12 program branches to location RICK if the unsigned number in accumulator A is less 
than or equal to 10, using the “branch if less or same” instruction to test the result of the CMP.
Check:
CMP
#10
;subtract 10 from A
BLS
RICK
;go to RICK if A lower than or same as 10
© 2011 by Taylor and Francis Group, LLC

23-24 
Fundamentals of Industrial Electronics
Modular programming requires the ability to partition software into subroutines, such as procedures 
and functions, which can be invoked as needed. This is supported by special subroutine call instructions 
that jump from a main program to the start of a subroutine after saving a pointer to the next instruction 
in the main program, allowing a return to the main program after completing the subroutine.
A subroutine call (CALL) or jump to subroutine (JSR) instruction typically pushes the current pro-
gram counter onto the system stack to save the address of the next instruction in the main program, 
and then loads the program counter with the address of the subroutine. A return (RET) or return from 
subroutine (RTS) is executed as the last instruction of the subroutine to pop the program counter from 
the stack and, thus, return to the main program. The ARM does not support a system stack; a subroutine 
is called with a jump and link (JAL) instruction, which saves the program counter in register R14 before 
loading the PC with the target address. The subroutine returns to the main program by moving the 
saved return address from register R14 to the program counter as in the following instructions:
MOV
PC,R14
;copy R14 to PC
BX
R14
;branch (indirect) to the address in R14
23.4.5.6  Input/Output Instructions
A few CPUs utilize separate address spaces for memory and I/O devices. Hence, there is both a memory 
address 0 and an I/O address 0. In these cases, special instructions are provided to read information into 
the CPU from an input device and to write information from the CPU to an output device. The Intel 
CPUs support an isolated I/O address space that can be accessed only by the two special instructions IN 
and OUT as follows:
IN
AL,25
;data from IO address 25 to AL register
OUT
25,AL
;data from AL register to IO address 25
23.4.5.7  Processor Control Instructions
These instructions manipulate various hardware elements within the CPU, and are therefore CPU spe-
cific. The reader is referred to [4–10] for descriptions of processor control instructions for specific CPUs.
23.4.6  Interrupts and Exceptions
Events often occur that require the interruption of normal instruction processing to perform some spe-
cial action. Such exceptional events, or exceptions, can be triggered by signals from devices external to 
the CPU, or by conditions detected within the CPU.
TABLE 23.5  Condition Codes for Relational Operators
Condition
Symbol
Relation
Number Type
Boolean Condition
Zero
Z
A = B
Both
Z
Not zero
NZ
A ≠ B
Both
Z−
Greater than
G
A > B
Signed
(
)
N
V
Z
⊕
+
Greater than or equal
GE
A ≥ B
Signed
N
V
⊕
Less than
L
A < B
Signed
N ⊕ V
Less than or equal
LE
A ≤ B
Signed
(N ⊕ V) + Z
Above
A
A > B
Unsigned
C
Z
+
Above or equal
AE
A ≥ B
Unsigned
C−
Below
B
A < B
Unsigned
C
Below or equal
BE
A ≤ B
Unsigned
C + Z
© 2011 by Taylor and Francis Group, LLC

Computer Architecture 
23-25
For example, a cell phone microcontroller might use a timer to interrupt the CPU once per second 
to make it update an image of a clock displayed on the screen. Microcontrollers used in process control 
are typically interrupted by sensors that detect various conditions in the plant that require immediate 
attention. An example of an internally detected condition is an attempt to divide a number by 0, which 
cannot produce a valid result. This type of exceptional condition should suspend normal processing to 
abort the operation and send a warning message to the user.
A primary advantage of an external interrupt is that a CPU may work in parallel with one or more 
external processes, such as printing a document, and be interrupted only when the process requires 
attention. The alternative is to continuously monitor the process by checking a status register in the 
device to detect when the device requires attention. Such monitoring would prevent the CPU from 
doing other work while waiting for the device to be ready, whereas with interrupts the CPU can do other 
jobs until interrupted.
When an exception condition is detected, a CPU typically responds as follows:
	
1.	 Complete the instruction currently in progress to reach a convenient stopping point.
	
2.	 Save the current program counter on the system stack or in a designated register, preserving 
a pointer to the next instruction that would have been executed had the program not been 
interrupted.
	
3.	 Determine the condition that requested the interrupt. Many CPUs execute a special interrupt 
acknowledgment operation to allow an external interrupting device to identify itself with a 
unique number called an interrupt vector.
	
4.	 Load the program counter with the starting address of a program to perform the service requested 
by the interrupting device. This program is called an interrupt service routine (ISR). Where used, 
an interrupt vector points to a memory location containing the starting address of the ISR. Some 
CPUs restrict the ISR starting address to a fixed address in memory, while others require that the 
ISR address be stored in one specific memory location.
	
5.	 Fetch and execute the instructions of the ISR.
	
6.	 Upon completion of the ISR, execute an interrupt return instruction to restore the original pro-
gram counter from the stack, allowing the CPU to return to the point in the original program at 
which it was interrupted.
Since a running program may be interrupted at any time, the ISR should begin by saving any registers 
that will be modified within the ISR, and then restore them before returning to the main program. This 
will allow the main program to continue as if the interrupt had not occurred.
23.5  Evaluating Instruction Set Architectures
Many different metrics are used as indicators of computer performance. Perhaps the most commonly 
cited is MIPS, which stands for millions of instructions per second. Unfortunately, MIPS figures do 
not indicate how much work is done by each CPU instruction. In some CPUs, instructions perform 
very primitive operations, while in others, each instruction may do a considerable amount of work. 
Therefore, simply knowing how many instructions a CPU can execute per second provides only a partial 
picture of how fast a computer can perform.
As the computer architecture evolved from the first computers in the 1940s through the machines 
of the 1970s and 1980s, the sizes of the instruction sets grew as designers became able to incorporate 
more circuit devices on a single IC chip. High-level languages became widespread, and emphasis was 
placed on making compiled programs as efficient as possible. For this reason, CPU instruction sets were 
expanded to include any instruction that might be needed to implement a high-level language state-
ment. Thus, instructions became more powerful, with compilers producing fewer instructions per pro-
gram. However, this growth in the number and power of instructions required larger and more complex 
CPU control units, slowing down the entire processor.
© 2011 by Taylor and Francis Group, LLC

23-26 
Fundamentals of Industrial Electronics
In 1970, researchers at IBM designed the model 801 computer, in which the instruction set was reduced 
to only those that were used frequently. Later, researchers at Stanford and Berkeley observed that only a 
small core of computer instruction sets were executed for the majority of the time. They developed RISCs 
that could execute programs faster than complex instruction set computers (CISC) by streamlining CPU 
designs. These efforts evolved to the Sparc, MIPS, PowerPC, ARM, and other RISC processors.
The true performance of a CPU can be measured by the time, Texec, that it takes to execute a given 
program:
	
T
C
I
T
C
CPI
exec
CLK
I
P
T
= 


× 


× 


=
×
×
(#
)
Instructions
	
where
I/P is the number of instructions in the program
C/I = CPI is the average number of CPU clock cycles required to execute an instruction
T/C = TCLK is the CPU clock period (time per clock cycle), which is the inverse of the clock frequency
CISC designs strive to minimize Texec by reducing the number of machine instructions needed to 
execute a high-level language program, minimizing I/P. Designers of CPUs like the Digital Equipment 
Corporation’s VAX minicomputer, and the Intel 80x86 and Motorola MC680x0 microprocessors 
attempted to anticipate the needs of compiler writers and provided as many instructions as might be 
needed. However, the cost of providing a large number of instructions is increased hardware complex-
ity, which increases the factors CPI and TCLK.
RISC designs target the CPI and TCLK factors at the expense of increased numbers of instructions 
(I/P). Simplifying the instruction set can reduce the number of clock cycles required to execute each 
instruction. The target of most RISC processors is a single clock cycle per instruction. In addition, sim-
plifying the hardware often enables the clock period to be shortened. However, more instructions are 
required to perform a given task than for an equivalent CISC machine.
With transistor-switching-time improvements slowing down, computer architects have turned to 
parallelism to obtain additional improvements. One method of utilizing parallelism is a superscalar 
design, in which multiple functional units are contained in the CPU and multiple instructions fetched 
and executed in parallel. For example, the Intel Pentium includes two integer and one floating-point 
ALU that can be used concurrently. The Pentium control unit fetches multiple instruction codes at one 
time from memory, and can simultaneously initiate operation in one, two, or all three of these units, 
instead of executing the instructions sequentially. Likewise, the SUN Super Sparc and the Motorola 
PowerPC 601 CPUs each contain an integer unit, a floating-point unit, and a branch processing unit that 
can be used to execute multiple instructions concurrently.
References [7,11,12] provide thorough discussions of computer performance and the effects of archi-
tectural features on program execution times.
23.6  Computer System Design
Figure 23.21 illustrates the basic interconnection of memory and I/O devices to a CPU. Information is 
transferred between a CPU and selected memory or I/O devices via a data bus, which is a set of parallel 
signal lines, each carrying one data bit. The CPU selects one memory location or I/O device to receive or 
provide data by broadcasting its address to all devices in the system over an address bus. Logic circuits 
in each device interface compare the address on the bus to its assigned value to determine if it is the one 
being addressed. This is called decoding the address.
Data transfers are coordinated by the CPU, using one or more control signals to indicate the type, 
direction, and timing of each data transfer. The direction of a data transfer is either device-to-CPU (a CPU 
read cycle) or CPU-to-device (a CPU write cycle). Freescale processors and many other CPUs issue a 
© 2011 by Taylor and Francis Group, LLC

Computer Architecture 
23-27
control signal R W
/
 at the beginning of the cycle, setting it high to designate a read cycle and low to indi-
cate a write cycle. Some CPUs, such as the Intel processors, use two control lines to indicate the type of 
cycle: RD to signify a read cycle and WR to signify a write cycle. (The overbar indicates that these signals 
are active-low, i.e., a logic 0 level signals that the indicated operation is active.)
The timing of a data transfer is critical. The CPU must signal a device when it is time to begin and 
when it is time to end each data transfer. The Freescale processors issue an enable (E) or a data strobe 
signal (DS) that activates when the transfer is to begin and returns to the inactive level when the transfer 
is finished. In the Intel processors, RD and WR act as data strobes for read and write cycles, respectively.
Figure 23.22 illustrates the read and write cycle bus timing for CPUs that use control signals compat-
ible with those of the Freescale CPUs, Figure 23.22a, and for CPUs that use Intel-compatible control 
signals, Figure 23.22b.
Data bus
CPU
Address bus
Control signals
Decode
logic
Select
Memory
or
I/O device
FIGURE 23.21  Computer system address and data buses.
(b)
Write cycle
Read cycle
Data
bus
WR
RD
Address
bus
Device
address
Device
address
Data from
device
Data to
device
(a)
Data
bus
Data from
device
Device
address
Device
address
Write cycle
Read cycle
Data to
device
DS
R/W
Address
bus
FIGURE 23.22  Data transfer timing between CPU and memory for: (a) Freescale-compatible control signals and 
(b) Intel-compatible control signals.
© 2011 by Taylor and Francis Group, LLC

23-28 
Fundamentals of Industrial Electronics
The number of bits in a data bus may or may not match the width of the internal data path of the 
CPU. For example, the Intel 8086 CPU has internal and external 16-bit data buses. The Intel 8088 CPU 
is identical to the 8086, including the 16-bit internal data path, but it has an 8-bit external data bus. The 
Intel Pentium has a 32-bit internal data path and a 64-bit external data bus.
The rate at which data can be transferred between a CPU and an external device is referred to as the 
bandwidth (BW) of the bus, and is a function of the bus speed (number of data transfers per second) and 
the number of bits per transfer:
	
BW  =  
 
 
(transfers second)
(bits transfer)
/
/
×
	
Given identical bus speeds, the external bus BW of an 8088 CPU would be half of that of an 8086, even 
though they have identical internal data paths.
For CPUs that support byte-addressable memory with 16-bit and wider buses, control signals are pro-
vided to indicate which byte or bytes of the bus are to be used to transfer data. The memory controller of 
the NXP LPC2292 microcontroller [13], based on an ARM CPU, generates four “byte lane” select lines, 
BLS
BLS
BLS
[ ],
[ ],
[ ]
3
2
1 , and BLS[ ]0 , corresponding to sets of eight data lines (byte lanes), D31–24, D23–16, 
D15–8, and D7–0, respectively. Each byte lane select signal activates if that “byte lane” is to be used for the 
data transfer. So, all four would activate during a 32-bit data transfer, two during a 16-bit transfer, and 
one during an 8-bit transfer. Likewise, the 32-bit data buses of the Intel 80386 and 80486 have four byte-
enabled control lines: BE
BE
BE
3
2
1
,
,
, and BE0, corresponding to data bus lines D31–24, D23–16, D15–8, and 
D7–0, respectively. The Pentium has eight such control lines for its 64-bit bus.
HCS12 microcontrollers, which have 16-bit external buses, activate a special control line, LSTRB 
(lower byte strobe), when the low byte of the data bus is to be used for a data transfer. The address line 
A0 indicates a byte within a 16-bit word. A0 = 1 indicates that the low byte is to be used and A0 = 0 indi-
cates that the high byte is to be used. However, for a 16-bit data transfer, both A0 = 0 and LSTRB = 0, 
to access both bytes. This is summarized in Table 23.6, which compares the HCS12 to the low 16 bits of 
the Pentium data bus. Note that the HCS12 uses the big endian format, while the Pentium uses the little 
endian format.
Reliable data transfers require synchronization of the CPU and the device being accessed. A synchro-
nous bus implies that the data transfer is synchronized to the clock signal that drives the CPU, and must 
be completed within a designated number of clock periods. A designer must select memory and I/O 
devices whose access times are short enough to fit within this constraint.
In contrast, an asynchronous bus does not synchronize data transfers to a reference clock. Instead, 
the CPU signals the device to begin the transfer and the device signals the CPU when it has completed 
the data transfer. This allows each data transfer to take as much or as little time as required for the device 
being accessed, and therefore allows slower devices to be used. The Motorola 68000 has an input signal 
called DTACK (data transfer acknowledge) that must be activated by each accessed device to signal the 
CPU that the transfer has been completed.
A semisynchronous bus synchronizes data transfers to the system clock, as in the synchronous case, 
but allows a slow device to signal the CPU that it needs more time to complete a data transfer. For 
example, the 8086 has an input called READY that would nor-
mally be held high, but can be pulled low by a device until it is 
ready to complete a data transfer. When the CPU sees READY = 0, 
it enters a special wait state for one clock cycle and checks the 
READY signal again, repeating this wait state indefinitely until 
READY has been activated by the device.
On most microcontrollers and some older microprocessors, 
chip package sizes have a limited number of signal pins. In these 
cases, it is impractical to allocate a separate pin for each address, 
TABLE 23.6  Byte and Word 
Transfers on a 16-Bit Bus
Data Transfer 
Type
Pentium
HCS12
BE BE
1
0
LSTRB
A0
Byte: D7−0
1
0
0
1
Byte: D15−8
0
1
1
0
Word: D15−0
0
0
0
0
© 2011 by Taylor and Francis Group, LLC

Computer Architecture 
23-29
data, and control signal. To reduce the pin count, a single pin may be used for two or more different 
functions, i.e., two or more signals are time-multiplexed over one signal line. It is common for expand-
able microcontrollers to use a set of signal pins to transmit an address to external memory, and then use 
the same pins to transfer data. The CPU provides a control signal to indicate when each type of informa-
tion is on the pins, allowing the bus to be demultiplexed.
For example, the HCS12 multiplexes its 16-bit data bus DB15–0 and address bits ADR15–0 on signal pins 
ADR/DB15–0, as illustrated in Figure 23.23a. For each data transfer, the CPU first broadcasts an address 
on ADR15–0 and then uses the same pins to transfer the data, as illustrated in the timing diagram of 
Figure 23.23b. A signal called ECS (external chip select) is set activated by the CPU whenever an address 
is present on ADR15–0, and low otherwise. Since the CPU removes the address before the data is trans-
ferred, a latch must be provided external to the CPU chip, as shown in Figure 23.23a, to save the address 
while ECS = 0 and hold it for the duration of the data transfer.
23.7  Hierarchical Memory Systems
General-purpose computer systems often utilize a hierarchy of memory devices, as shown in Figure 
23.24. Memory devices differ in how they are accessed, their storage capacity, volatility, cost per bit, and 
access time.
Computer memory is classified as primary memory if any storage location within the memory can be 
accessed directly by the CPU; otherwise, it is classified as secondary memory. Primary or direct-access 
memories comprise a set of numbered storage locations that are accessed by supplying the address of the 
location to be accessed, along with one or more control signals to indicate whether information is to be 
read from memory or written to memory.
(a)
CPU
Multiplexed
address/data bus
Data bus
Address
latch
Address bus
External
chip select
(b)
Address/data
bus
Address
ECS
Data
FIGURE 23.23  Multiplexed address and data buses: (a) Address is latched to demultiplex the bus and (b) Timing 
of the multiplexed bus.
CPU
Cache
memory
Main
memory
Mass storage
(disk, flash)
Archival
memory
Secondary memory
Primary memory
FIGURE 23.24  Computer system memory hierarchy.
© 2011 by Taylor and Francis Group, LLC

23-30 
Fundamentals of Industrial Electronics
Secondary memory devices are used for bulk or mass storage of programs and data, and include 
rotating magnetic devices, such as disks and magnetic tapes, flash memory devices, optical devices 
such as CDROMs, and a variety of other devices. In contrast to primary memory, the information in 
secondary memory devices is not accessed directly. The CPU accesses the device through a special 
controller that searches the device to locate the desired item. When found, an entire block of informa-
tion is usually transferred into primary memory, where the desired items can be accessed in a more 
convenient fashion.
23.7.1  Memory Characteristics
Volatility refers to the permanence of data stored in a memory. A read-only memory (ROM) preserves 
information permanently and cannot be rewritten. This is useful for storing programs and data values 
that will not change. Read-write memories can be erased and/or rewritten. Some read-write memories 
retain information only while powered up, while others, like disk or flash, can retain data indefinitely 
until erased or rewritten.
The capacity of a memory refers to the total number of bits of information that can be stored. Capacity 
is a function of the mechanism used to access the memory. A direct access memory is limited in size by 
the number of address bits provided by the CPU. The capacity of a disk drive is determined partially by 
its physical characteristics and control circuitry, and the ability of the operating system software to keep 
track of the information on the disk. Archival secondary storage devices with removable media provide 
virtually unlimited capacity.
The cost per bit of storage decreases as one moves farther from the CPU in Figure 23.24. High-speed 
cache memories are more expensive than slower main memories, while storage on most disk drives is 
often orders of magnitude less expensive per bit. Archival storage allows large quantities of information 
to be saved on inexpensive tapes or diskettes with minimal cost.
As the capacity increases and the cost per bit goes down in the memory hierarchy, the performance 
parameters, or access and cycle times, of the memory become longer. Memory access time is the length 
of time required to retrieve (read) a word from the memory, and memory cycle time is the minimum 
interval of time required between successive memory operations. The access time of a memory deter-
mines how quickly information can be obtained by the CPU, while the cycle time determines the rate at 
which successive memory accesses may be made. In general, direct access devices can be accessed more 
quickly and more often than secondary devices.
23.7.2  Semiconductor Memory Technologies
Most computers built prior to 1970, some of which are still in operation today, utilized arrays of mag-
netic cores as their primary memory elements, while a few specialized systems, particularly in space 
vehicles, utilized plated wire as a replacement for magnetic core in applications where radiation hard-
ness was required. In today’s digital computers, primary memories are constructed of semiconductor 
IC chips.
Semiconductor memories are available as read-only or read-write devices. ROM is used to store pro-
grams, tables, and other data that will not be modified while the computer is operating. Table 23.7 lists 
several ROM technologies, which differ in how the devices are programmed and/or erased. ROMs are 
programmed when they are manufactured, while PROMs are field-programmable, i.e., they are pro-
grammed by the system designers that use them. Neither ROMs nor PROMs are alterable; they must be 
discarded when their contents are no longer valid.
EPROM, EEPROM, and FLASH memories are field-programmable devices that can also be erased 
and reprogrammed. EPROMs are erased by exposing the storage cells to ultraviolet light to free electri-
cal charge trapped in the memory cells, while EEPROM and FLASH memories are erased electrically. 
Selected locations can be erased and reprogrammed in an EEPROM, while with a FLASH memory, an 
© 2011 by Taylor and Francis Group, LLC

Computer Architecture 
23-31
entire block of bits in the device must be erased before a location in that block can be reprogrammed. 
Ferroelectric RAM (FeRAM) technology utilizes ferromagnetic material to retain information when 
power is removed. While not as dense as FLASH memory, FeRAM devices are faster, consume less 
power, and allow more read/write cycles.
Read-write memory is commonly referred to as RAM, which is an acronym for random access mem-
ory. In reality, both ROM and RAM are random access memories since their contents can be accessed 
in any random order. Nonetheless, the term RAM has become associated with read and write memory.
RAM chips are further classified as static or dynamic. Once written, a static RAM retains infor-
mation until its power is removed; the RAM cells will be in random states when power is restored. 
Each memory cell contains the equivalent of a digital flip-flop circuit to achieve this static storage. 
In contrast, a dynamic RAM retains information for only a short time as charge stored on a capaci-
tor associated with a single transistor. This charge slowly leaks away over a short period of time. 
Therefore, to retain information, the contents of a dynamic RAM must be periodically refreshed, i.e., 
read and rewritten.
Because more transistors are used for each storage cell, static RAM devices have a higher cost per bit 
than dynamic RAMs, and can hold fewer bits than a dynamic RAM chip fabricated with a comparable 
technology. However, extra control circuitry is required for dynamic RAMs to refresh the memory, and 
dynamic RAMs are typically slower than comparable static devices. For small systems, the complexity 
and cost of the extra control circuitry for dynamic RAMs make them less attractive than static RAMs. 
However, for systems that use large amounts of RAM, the extra cost of the refresh circuitry is negligible 
compared to the lower cost per bit of dynamic RAM devices. Therefore, most PCs, workstations, and 
larger computers use dynamic RAMs for their main memories.
23.7.3  Memory System Organization
The organization of a primary memory system is determined primarily by the address and data buses of 
the host CPU. A memory chip is organized as 2K × N, which means that there are K address input lines 
and N data I/O lines, and thus a total of 2K addressable N-bit locations. An address decoder within the 
chip selects one location corresponding to each K-bit address and either sends the information from that 
location off the chip or writes new information into that location.
Using memory devices organized as 2K × N in a system that has J total address lines, where J ≥ K, 
means that the system can accommodate 2J/2K = 2J−K devices. These devices are usually organized hier-
archically into banks, as illustrated in Figure 23.25, with the memory address partitioned into a bank 
number, a chip number, and an on-chip address, as shown. Each part of the address is decoded at a dif-
ferent level of the hierarchy. One level of address decoding selects one of the banks, another selects a chip 
within the bank, and the on-chip decoder selects one location within the selected chip.
If the system data bus width B is wider than the number of data pins D on the memory chip, then B/D 
chips must be used to create one addressable block of memory, with each chip connected to a different 
D-bit section of the data bus.
TABLE 23.7  Nonvolatile Memory Technologies
Acronym
Device Type
ROM
Read-only memory
PROM
Programmable read-only memory
EPROM
Erasable programmable read-only memory
EEPROM
Electrically erasable programmable read-only memory
FLASH
Flash memory—EEPROM that is erased by erasing the entire memory array
FeRAM
Ferroelectric RAM—ferroelectric material enables device to retain data while power is removed
© 2011 by Taylor and Francis Group, LLC

23-32 
Fundamentals of Industrial Electronics
For example, consider a CPU bus interface that comprises 16 data lines and 24 address lines, using a 
big endian format. If a 16 MB memory system is to be constructed of 1 MB RAM chips (220 × 8), then 
chips must be connected to the data bus in pairs, one connected to data bus lines D7–0, containing odd-
numbered bytes, and one to data bus lines D15–8, containing even-numbered bytes, for a total of 2 MB 
of RAM. 16 MB of RAM requires 16/2 = 8 pairs of chips. Three address bits A23–21 must be decoded to 
select a pair of chips, with 20 address bits A20–1 decoded within each chip. The remaining address bit A0 
is used within the CPU to determine whether the even- or odd-numbered byte or both are to take part 
in the data transfer.
If only four pairs of chips fit on one circuit board, then two boards are used, with address bit A23 
selecting one of the boards and A22–21 selecting a pair of chips within the board, as illustrated in Figure 
23.25, where the boards are labeled “banks.”
23.7.4  Cache Memory
CPU speeds have increased at dramatic rates from year to year. As a result, the design of memory systems 
that can keep information moving in and out of the CPU, without making it wait, is becoming more dif-
ficult. Memory chips with short access times are expensive. An alternative to building a large memory out 
of expensive high-speed RAM chips is to use a small high-speed memory to hold the information most 
likely to be used by a CPU, with the remaining information kept in the main memory. The main memory 
can be built with lower-speed and, therefore, less expensive RAM chips.
Memory accesses often exhibit a property called locality of reference. Spatial locality of reference 
means that if a memory location is accessed, then there is a high probability of accessing the next 
sequential location in memory. Programs tend to exhibit high degrees of spatial locality of reference, 
because instructions are fetched from sequential memory locations until a jump or branch is executed. 
Temporal locality of reference means that if an address has been accessed, then there is a high likelihood 
that it will be accessed again in the near future. Data variables often exhibit good temporal locality of 
reference, as do instructions that are contained in loops.
A cache memory exploits locality of reference by holding, in high-speed memory, a subset of the main 
memory locations most likely to be needed by the CPU. Each memory reference is sent first to the cache. 
Bank
Decode
Bank
selection
Bank 0
Chip 0
Decode
Chip 1
Decode
Chip N
Decode
Chip 0
Decode
Chip 1
Decode
Chip N
Decode
Bank 1
Decode
Decode
Chip
selection
Chip
selection
Chip
On-chip
Memory address
FIGURE 23.25  Hierarchical decoding of memory addresses.
© 2011 by Taylor and Francis Group, LLC

Computer Architecture 
23-33
If the requested information is there, a cache hit is said to occur and the information is passed quickly 
to the CPU. If a cache miss occurs, i.e., if the information is not found in the cache, then the slower main 
memory must be accessed. The average access time is given by
	
T
HT
H T
T
access
cache
cache
main
=
+ (1
)(
+
−
) 	
where
H is the hit ratio of the cache, i.e., the percentage of cache accesses that result in hits
Tcache and Tmain are the access times of the cache and main memories, respectively
For example, a memory system with a 90% hit ratio with Tcache = 20 ns and Tmain = 100 ns would have 
an average access time of Taccess = 30 ns, which is much closer to that of the higher-speed cache memory 
than the slower main memory.
Writes to memory can be handled in two different ways in systems with cache memory. In a write 
through strategy, each item is written directly to the main memory on every write cycle, with the cache 
updated concurrently. In a write back strategy, all writes are done only to the cache, leaving the cache and 
main memory contents temporarily inconsistent. Later, when information must be replaced in the cache, 
all modified cache entries are copied back to the main memory. This reduces the total number of main 
memory accesses when multiple updates are made to a single data item.
Cache memory designs and performance are examined extensively in [7,11,12].
23.7.5  Virtual Memory Management
Increasing program sizes and workload demands for PCs, workstations, handheld computers, and 
larger systems have made it impractical to provide enough primary memory to store a user’s entire pro-
gram and data. This is especially true in multiuser and multitasking environments in which memory 
and CPU time are shared by multiple programs. Referring to the locality of reference principle described 
in Section 23.7.4, it is usually the case that a CPU does not need immediate access to all instructions and 
data of a program at any given time. Therefore, it is sufficient to make a subset of this information avail-
able in memory, with the rest held on a disk or other secondary storage device until needed. This allows 
a program’s address space to be much larger than the available or allocated physical memory.
This is achieved by using two different address spaces: a virtual or logical address space that specifies 
locations within a program, and a physical address space that identifies physical storage locations in 
the main memory. Since different portions of a program are placed in memory at different times, each 
location from the logical address space must be mapped to the current physical address containing 
that information, as illustrated in Figure 23.26. This mapping is handled by a memory management 
unit (MMU), which is a hardware element that translates each logical address to the corresponding 
physical address.
A common method for translating logical to physical addresses is paging, in which a user’s program 
is partitioned into fixed-length blocks called pages. Physical memory is likewise partitioned into fixed-
length blocks, usually of the same length as the logical pages, so that each logical page fits exactly into 
one physical page of memory. Each logical address is divided into an n-bit page number and a k-bit 
offset within the page, as illustrated in Figure 23.27. The n-bit logical page number is mapped to an 
m-bit page number in the physical address space. Since logical and physical page sizes are the same, the 
offset portion of the logical address is used directly as the offset portion of the physical address without 
going through the translation process. Only the address bits corresponding to the page number need 
to be translated.
As logical pages are placed in the physical memory, a page table is created and updated. As illustrated 
in Figure 23.27, the page table contains a descriptor for each logical page containing a present bit (P) to 
© 2011 by Taylor and Francis Group, LLC

23-34 
Fundamentals of Industrial Electronics
indicate whether that page is currently resident in memory and, if so, the corresponding physical page 
number (PPN). The page descriptor may also contain a modified bit (M) to indicate whether the page 
has been modified since being loaded into memory; an accessed bit (A) to indicate if the page has been 
accessed; and possible restrictions on how the page may be used, such as a writeable bit (W) to indicate 
that the page may be altered. These bits are used by the operating system to help manage the pages in 
memory.
To perform an address mapping, the MMU uses the logical page number as an index into the page 
table, as shown in Figure 23.27, to fetch the page descriptor. If the page is present in memory, the physi-
cal page number is retrieved from the page descriptor and concatenated with the page offset to produce 
the physical address. If the page is not present in memory, a page fault is said to occur. The CPU is inter-
rupted and the operating system called to find the requested page on the disk and load it into memory. 
Then the page table is updated and the original memory request is repeated.
Logical address
space
X
Y
Logical
address
Address
map
Physical
address
Physical address
space
FIGURE 23.26  Mapping logical address X to physical address Y.
Logical address
Page
Oﬀset
n
Logical
page #
Page table
base register
Page table
Page descriptor
P
M
A
W
PPN
m
Page
Oﬀset
Physical
page #
Physical address
k
FIGURE 23.27  Address mapping through a page table.
© 2011 by Taylor and Francis Group, LLC

Computer Architecture 
23-35
In a multiuser or multitasking system, each process has its own page table. This is illustrated in Figure 
23.28, which shows two processes sharing CPU time. Pages A and B of Process 1 are currently in memory 
along with pages L and N of Process 2. The page table of each process keeps track of which pages are in mem-
ory. When Process 1 is running, logical address 1, corresponding to page B, is mapped to page 0 of physical 
memory. When Process 2 is running, page L is accessed by mapping logical address 1 into page 1 of physi-
cal memory. If Process 1 attempts to access page D, which is not currently in memory, it will be suspended to 
allow the operating system to retrieve page D from the disk and replace one of the current pages in memory. 
Then Process 1 will be allowed to repeat the access to page D and continue processing.
An alternative method of address translation is segmentation, in which information is organized by 
the programmer into segments of items that share common characteristics. Each segment has a segment 
number and an offset within the segment. Segment numbers are translated in the same manner as page 
numbers, indexing into a segment table to retrieve a segment descriptor that points to the beginning 
of a physical memory area. Unlike pages, segments can be of arbitrary size, and can be loaded at any 
memory address.
The segment size is stored in the segment descriptor and compared to each segment offset to ensure 
that the requested information is not outside the bounds of the segment. The segment offset is then 
added to the starting memory address to form the complete physical address. The use of arbitrary seg-
ment sizes allows a programmer to use only as much memory as needed, although memory allocation is 
difficult, since the operating system is not working with fixed-sized blocks, and therefore free memory 
may become fragmented as segments are moved in and out of memory. There may be a sufficient amount 
of free memory to accommodate a new segment, but if the free memory is not contiguous, the segment 
cannot be loaded.
Occasionally, a combination of segmentation and paging is used. In this case, information is orga-
nized by the programmer into segments, with protection information placed in the segment descriptor. 
Then each segment is partitioned, transparent to the programmer, into fixed-sized pages, simplifying 
the memory allocation process, since logical and physical pages will be the same size, preventing frag-
mentation. Each logical address comprises a segment number, a page number, and a page offset. The 
segment number is used to access a segment descriptor in a segment table.
Process 1 logical pages
Process 2 logical pages
0
1
2
3
3
2
1
0
3
3
2
1
1
0
1
2
0
1
0
---
---
---
---
0
0
1
0
1
0
1
2
3
D
Process 1
Page table
Process 2
Page table
K
B
0
1
2
3
Physical memory pages
L
A
N
L
M
N
C
B
A
FIGURE 23.28  Address mapping in a multitasking environment.
© 2011 by Taylor and Francis Group, LLC

23-36 
Fundamentals of Industrial Electronics
The segment descriptor points to a page table containing descriptors of the pages of that segment. The 
page number is then used to access a page descriptor from the selected page table, which provides the 
physical page number. Finally, this page number is concatenated with the original page offset to form 
the physical memory address.
23.8  Interfaces to Input/Output Devices
An external device must be interfaced to a CPU’s data bus so that data can be transferred by program 
instructions between the external device and the CPU. As is the case with memory, each I/O device 
interface must be addressable and respond to bus control signals issued by the CPU. The most common 
approach is to use one or more registers in the I/O device interface as buffers between the device and 
the CPU, as illustrated in Figure 23.29. Data is sent to a device by writing it to a register in the device 
interface, from where it is sent to the external device. Likewise, data from an external device is accessed 
by the CPU by reading a register in the device interface.
An external device may require data in some format other than the parallel binary digits provided by the 
CPU. For example, the transmission of data over a telephone line via a modem requires that each byte be 
converted into a serial stream of bits, with additional control bits prepended and appended to each trans-
mitted byte. Data from temperature, pressure, and other sensors is often produced as continuous analog 
voltages or currents. To be processed by a digital computer, analog values must be sampled and represented 
by digital values that can be read by the CPU. A similar function must be provided by digital-to-analog 
converters to send information from a CPU to an analog device. There are many different device interface 
chips that automatically convert data from one format to another. In most of these, the CPU simply trans-
fers parallel digital data to and from registers in the device interface. The conversion and transmission of 
data between these registers and the external devices is handled automatically by circuits in the interface.
Interfaces to disk drives, graphics display terminals, communication links, and other complex I/O 
devices operate in a similar manner. Despite the significant differences between the characteristics of 
different types of peripheral devices, most of them are viewed by the CPU as a set of addressable reg-
isters. These device interfaces incorporate intelligent control circuits that respond to commands sent 
by a CPU to special command registers within the device interface. Parameters and data are likewise 
transferred to and from registers in these interface circuits.
The operation of these circuits is monitored by reading the status information from registers in 
the device interfaces. For example, the following HCS12 and Pentium program segments read and 
test the rightmost bit of a device status register. If that bit is 1, the device is known to be busy and 
the program repeats the test. If the bit is 0, the device is not busy, and new data can be sent to a data 
register in the device interface.
From CPU
Register
Data
conversion
To output device
From input device
Data
conversion
Register
To CPU
CPU–device
interface
CPU–device
interface
FIGURE 23.29  External I/O device interfaces.
© 2011 by Taylor and Francis Group, LLC

Computer Architecture 
23-37
HCS12:
Check:
BRSET
Status,$01,Check
;test bit 0 of device status 
register
STAA
Data
;Send new data to device 
when not busy
Pentium:
Check:
IN
AL,Status
;read device status register
TEST
AL,01H
;mask all but busy bit
JNZ
Check
;repeat if busy = 1
MOV
AL,BL
;get byte to send
OUT
Data,AL
;send data to device
23.9  Microcontroller Architectures
Microcontrollers are used in applications that require low cost and chip count, combining on a single 
chip a CPU, a ROM, a RAM, and various peripheral functions and I/O interfaces. Typical applications 
include embedded controllers for kitchen appliances, automotive electronics, cellular phones, home 
electronics (TVs, VCRs, etc.), process control, and many other applications. In general, it has proven 
cost effective to use a single microcontroller chip to replace circuitry that would otherwise require sev-
eral digital and/or analog ICs. In addition, the programmability of microcontrollers allows features to 
be changed or added with very little extra cost.
Microcontroller CPUs are available with data path sizes from 4 to 32 bits. On-chip RAM is 
generally small compared to on-chip ROM, usually 64-4 Kbytes. In embedded applications, RAM 
is used primarily to store a few temporary variables and perform “scratch” work; hence, on-chip 
RAM is commonly referred to as scratchpad memory. Microcontrollers generally provide a num-
ber of parallel I/O pins. These are used to send control signals to LEDs, actuators, displays, etc., to 
receive signals from switches, sensors, and other devices, and to pass data to/from other external 
devices. Most microcontrollers also offer programmable serial communication interfaces. Other 
special I/O interfaces may be found in selected chips. I/O interfaces and other special functions 
are accessed by the instruction set via control, status, and data registers with permanently assigned 
addresses.
Programmable timers/counters are among the most common functions included in microcontrollers. 
These are used to provide timing for digital alarm clocks, cooking cycle times in microwave ovens, auto-
mobile engine control timing, generation of periodic waveforms, timing of bit transmissions for serial 
I/O, measurement of time periods between signal changes detected on external I/O line events, and 
counting signal changes.
Figure 23.30 shows a block diagram of an 8051-compatible microcontroller [10,15]. In addition to 
the CPU, 128 bytes of RAM, 4 Kbytes of ROM, and four 8-bit parallel I/O ports, the 8051 includes two 
programmable timers, a serial communication port, interrupt control logic, and an external bus inter-
face. When activated, parallel ports P0 and P2 are disabled and these pins become the external data and 
address buses. Data is multiplexed with the low address byte on the 8 pins of port P0, with the remaining 
address bus bits on the eight pins of port P2. Additional memory and I/O function interface chips can 
be accessed via this external bus to expand the capabilities of the microcontroller. The Freescale HCS12 
microcontrollers can be expanded off-chip in a similar manner.
The basic architecture of the Freescale MC9S08 family of devices is shown in Figure 23.31 [14]. As in the 
8051, devices in the MC9S08 family include CPU, RAM, Flash, general-purpose I/O pins, a program-
mable timer, serial communication interfaces, and interrupt support logic. Unlike the 8051 and the 
HCS12, the MC9S08 is not expandable; the data bus cannot be accessed external to the chip. Therefore, 
no additional memory may be used other than what is provided on chip, and all signals to and from the 
© 2011 by Taylor and Francis Group, LLC

23-38 
Fundamentals of Industrial Electronics
outside world must go through the provided parallel, serial, or other special I/O pins. Because applica-
tions differ in their memory and I/O requirements, dozens of different configurations of the MC9S08 
are offered. Table 23.8 summarizes eight members of the MC9S08 family. As can be seen in this table, 
members of the MC9S08 family differ in the amounts of on-chip RAM and FLASH memory, number 
and types of communication modules, analog-to-digital converters, timer channels, I/O pins, package 
sizes, and other special functions. In addition, versions are available that operate at different power 
supply voltages and clock speeds, and most devices are available in several packages. A system designer 
must select a device from the MC9S08 family that most closely matches the needs of his or her applica-
tion. Many other manufactures also supply single-chip microcontrollers as families of nonexpandable 
devices.
Microcontroller instruction sets generally support smaller memory spaces and provide fewer arith-
metic and other high-level functions than general-purpose CPUs. However, many microcontroller 
CPUs include special instructions to facilitate I/O operations and to manipulate individual bits of I/O 
data, since these operations typically dominate microcontroller applications more so than arithmetic 
computations.
For designers needing more computation power in their embedded applications, or who wish to take 
advantage of the vast quantity of system and application software available for popular general-purpose 
CPUs, several IC manufacturers have developed microcontrollers around general-purpose 16- and 
32-bit CPUs. One such device is the NXP LPC2000 microcontroller family [13], which is built around the 
basic 32-bit ARM7 CPU, with typical microcontroller memory and I/O device interfaces.
A number of microcontrollers are also available with instruction sets tailored to specific applications. 
For example, microcontrollers are available whose instructions sets have been designed specifically for 
digital signal processing (DSP), which relies heavily on multiply-accumulate and other mathematical 
computations.
A recent trend in microcontroller design is to create custom system-on-chip (SoC) devices for 
customers from libraries of intellectual property (IP) “cores.” IC cores range from predesigned and 
characterized layouts of such functions as CPUs, RAMs, ROMs, I/O interface ports, and other special 
External
interrupts
Interrupt
control
CPU
OSC
Bus
control
4K ROM
128-byte
RAM
Timer 1
Timer 2
Timer
inputs
4 I/O ports
T×D
Serial
port
R×D
P0 P1 P2
Address/
data
P3
FIGURE 23.30  8051-compatible microcontroller block diagram. (Reprinted from Intel Corporation, Embedded 
Microcontrollers, Chapter 2, pp. 2–3, Figure 1, Intel order number 270646. With permission.)
© 2011 by Taylor and Francis Group, LLC

Computer Architecture 
23-39
functions, to register-transfer-level models of these functions that can be synthesized into a target 
technology. A designer creates an SoC by specifying the desired CPU(s) and exactly the types and 
amounts of memory I/O devices needed for the intended application. The chip layout is then created by 
the designer or the manufacturer by placing and interconnecting the IP cores, and the chip is fabricated 
for the customer in a relatively short time.
23.10  Multiple Processor Architectures
System designers have long been faced with applications requiring more computing power than can 
be provided by a single computer. Computing throughput requirements can be orders of magnitude 
greater than can be provided by even the fastest computers, despite the fact that CPU performances have 
increased dramatically over the years. Such high-throughput requirements can only be met by the use of 
User FLASH
32K
User EEPROM
512 bytes
User RAM
1024 bytes
Analog comparator
(ACMP1)
2-channel timer/
PWM module
Serial 
communications
interface (SCI)
Serial peripheral
interface (SPI)
IIC module (I2C)
4-channel timer/
PWM module
Oscillator
Voltage regulator
In-circuit emulator,
debug module
CPU
HCS08 core
Analog comparator
(ACMP2)
16
16-channel, 10-bit 
analog-to-digital 
converter
Slave interface 
controller (SLIC)
Real-time counter
HCS08 system 
control
Port B
Port B
Port A
Connection routing
internal clock 
source
FIGURE 23.31  Freescale MC9S08EL32 block diagram. (Modified from MC9S08EL3, MC9S08EL16, MC9S08SL16, 
MC9S08SL8, Data Sheet, Rev. 3, Freescale Semiconductors, Austin, TX, July 2008.)
© 2011 by Taylor and Francis Group, LLC

23-40 
Fundamentals of Industrial Electronics
parallel processing, in which applications are partitioned into multiple tasks that are executed concur-
rently by multiple processors.
Multiple processor system architectures vary widely in the numbers of processors used, the methods 
in which applications are partitioned and mapped onto an architecture, and the methods for inter-
connecting processors to communicate and share information. Flynn [16] proposed a commonly used 
method for classifying computer architectures, based on the number of instruction and data streams 
that can be processed concurrently. The Von Neumann and Harvard architectures described in Section 
23.1 are examples of single-instruction stream, single-data stream (SISD) architectures. One stream of 
instructions is fetched from memory by the CPU, which also fetches a stream of data from memory as 
needed.
Throughputs in some computationally intensive applications can be increased by performing a single 
operation concurrently on an entire set of data. This is especially true for computations involving vectors 
and matrices. This type of parallel processing can be performed on a single instruction stream, multiple data 
stream (SIMD) architecture, as illustrated in Figure 23.32. In an SIMD architecture, a control processor 
TABLE 23.8  Sample Freescale Semiconductor MC9S08 Microcontroller Configurations
Familya
KA1
QD2
QG8
EL32
SH32
JM60
LC60
QE128
FLASH
1K
2K
8K
32K
32K
60K
60K
128K
RAM
62
128
512
1K
1K
4K
4K
8K
SCI (UART)
0
0
1
1
1
2
1
2
SPI modules
0
0
1
1
1
2
2
2
I2C modules
0
1
1
1
1
1
1
2
Comparators
1
0
1
1
1
1
1
2
ADC bits/channels
0
10/4
10/8
10/16
10/16
12/12
12/8
12/24
16-bit timer channels
1
5
2
6
4
8
4
9
Package pins
6–8
8
8–24
20–28
16–28
44–64
64–80
44–80
Max GPIO pins
4
4
13
13
26
26
Other modules
USB
LCD
Source:	 PowerPCtm Microprocessor Family: The Programmer’s Reference Guide, Motorola Inc., 1995, 
International Business Machines Inc., 1991–1995. (http://www.cebix.net/downloads/bebox/PRG.pdf)
a	Part name = MC9S08 + family + package option (for example, MC9S08QD2CSC).
PE1
D1
D2
DN
MN
M2
M1
Shared memory
I
Control
CPU
PE2
PEN
FIGURE 23.32  SIMD architecture: instruction I performed on N data items.
© 2011 by Taylor and Francis Group, LLC

Computer Architecture 
23-41
fetches program instructions and identifies those instructions that involve computations on sets of 
numbers. As shown in Figure 23.32, each such instruction, I, is broadcast to N processing elements 
(PE1, PE2, …, PEN), which perform that operation concurrently on N data items (D1, D2, …, DN) accessed 
from a shared memory. SIMD architectures are commonly referred to as array processors. The reader 
is referred to Hwang’s textbook [17], which discusses the architectural features of a number of SIMD 
machines.
A multiple instruction stream, single data stream (MISD) architecture comprises N processing ele-
ments, each of which performs a different operation (I1, I2, …, IN) on a single data item, D, in an assembly-
line fashion, as shown in Figure 23.33. MISD principles have found their way into single processor 
architectures in the form of pipelining. In a pipelined CPU, the steps needed to process each instruction 
are performed by separate hardware modules. As each module completes its part, the module passes 
the instruction on to the next module and begins processing the next instruction. If there are N such 
modules, then up to N instructions can be processed at one time within a CPU, producing one new 
result every clock period rather than one every N clock periods. Pipelined CPU designs are discussed 
extensively in [9,11,12].
MISD principles have also been applied to experimental data flow computers, in which data is passed 
from processor to processor. Whenever a processor receives all the data items required for an operation, 
it performs that operation and passes the results on to other processors. In this manner, computations 
are triggered by the flow of data through the system.
The most widely used multiple processor architectures are multiple instruction stream, multiple 
data stream (MIMD) configurations. In an MIMD system, each processor performs its own assigned 
tasks, and accesses its own stream of data. Consequently, MIMD architectures can be applied to a much 
broader range of problems than the more specialized SIMD and MISD configurations.
There are numerous ways to configure an MIMD system. The number of processors can range from 
as few as two to hundreds or even thousands of elements. The most significant differences between 
MIMD architectures are related to the manner in which processors cooperate in solving problems. In 
general, MIMD architectures can be classified according to the degree of coupling between processors. 
In a loosely coupled system, the processors are autonomous and communicate primarily by exchanging 
messages through a communication network. In a tightly coupled system, the processors are closely 
synchronized and work closely with each other in solving problems. The required degree of coupling 
will determine how the processors should be interconnected.
The simplest MIMD interconnection method is the shared bus, as illustrated in Figure 23.34. Multiple 
CPUs can cooperate in solving problems by sharing information in a global memory that is accessed via 
D
Data
memory
PE1
PE2
I1
I2
IN
PEN
M1
M2
MN
FIGURE 23.33  MISD architecture: each PE performs a different operation on one data item.
© 2011 by Taylor and Francis Group, LLC

23-42 
Fundamentals of Industrial Electronics
a shared bus. Because the available bus BW is limited, each processing element typically uses a private 
local memory as a cache for non-shared programs and data. The majority of each processor’s memory 
accesses are to this local memory, with traffic on the system bus, limited to accessing data that must be 
shared between processes. Many commercial microprocessors contain special bus interface signals and 
functions to support connections to shared buses. Therefore, many multiprocessor systems have been 
developed using off-the-shelf CPU and memory boards.
A number of shared-bus standards have been developed to support networks of low-cost microcon-
trollers in automobiles and other embedded applications. Two of the more widely used are the I2C bus 
(Inter-Integrated Circuit) and the CAN bus (Controller Area Network) [18], both of which are serial 
buses, and supported by modules built into many microcontrollers. A physical I2C bus comprises a serial 
data line (SDL) and a serial clock line (SCL), supporting data rates of 100 to 400 Kb/s. The bus master is 
responsible for transmitting both data bits and clock. The bus is a multimaster bus, which means that 
any module connected to the bus may act as the master at any time. A bus transaction may begin any 
time the bus is idle (when SDL and SCL both are high), with the master sending a start bit, a 7-bit slave 
address, and then one or more data bytes. If a master detects that the level of SDL is not what was trans-
mitted, it stops transmitting. This ensures that if multiple devices start transmitting simultaneously, 
all but one will stop, thereby allowing the highest priority message to be completed. The CAN bus uses 
a similar protocol to support multiple masters, but with more options and higher potential data rates.
If a single bus is unable to provide sufficient BW to handle all of the shared-memory accesses, proces-
sors will be forced to wait for access to the bus, degrading system performance. In such cases, the BW 
can be improved by using multiple buses. In the extreme, maximum memory BW can be achieved by 
interconnecting processors and memories with a crossbar switch, as shown in Figure 23.35. A sepa-
rate switch and bus are provided between each processing element and each shared-memory module. 
Therefore, any permutation of N processing elements concurrently accessing N shared memories can be 
achieved. Conflicts occur only when two processors must access the same shared memory.
To reduce the number of switches and buses, many other connection networks have been proposed 
for shared-memory multiprocessors [16,17]. Many of these networks allow a limited number of per-
mutations of concurrent connections between N processing elements and N shared-memory modules. 
However, since there are fewer switches, conflicts often occur in the connection network that block 
the progress of one processor while the other accesses memory, even though the processors may be 
attempting to access different memory modules. The tutorial by Wu and Feng [19] provides an excellent 
overview of interconnection networks for multiprocessor systems.
Global
shared
memory
Global
shared
memory
Bus
interface
Bus
interface
Local
memory
Local
memory
Local
memory
Processing
element
PEN
Local
memory
Processing
element
PE1
FIGURE 23.34  Shared-bus, shared-memory multiprocessor.
© 2011 by Taylor and Francis Group, LLC

Computer Architecture 
23-43
Networks of PCs, workstations, and industrial computers are typical examples of loosely coupled sys-
tems. Loosely coupled systems contain autonomous processing elements with no shared resources. The 
processors share information by exchanging messages through a communication network. The most 
common interconnection methods for computer networks are buses and rings.
Ethernet is one of the most widely used interconnection buses for computer networks. Similar to the 
shared-bus configuration of Figure 23.34, the Ethernet bus is accessed using a carrier-sense, multiple-
access with collision detection (CSMA/CD) protocol. All processors continuously “listen” to the bus. 
When any processor wishing to transmit a message senses that the bus is free, it may begin transmitting 
preliminary information, followed by the message. If multiple processors begin transmitting at the same 
time, a collision is said to occur and the information on the bus becomes garbled, allowing the collision 
to be detected by all processors on the bus. When a collision is detected, all processors back off and wait 
a random amount of time before attempting to transmit again. Each processor makes its own decisions 
regarding access to the bus. Consequently, processors can be added to and removed from the bus with-
out disturbing the rest of the network.
Many other communication network topologies and protocols have been developed for multiple pro-
cessor systems. The interested reader is referred to [16,17] for further information.
References
	
1.	 Linux Online, http://www.linux.org/info
	
2.	 Nelson, V.P. et al., Digital Logic Circuit Analysis & Design, Prentice-Hall, Englewood Cliffs, NJ, 1995.
	
3.	 IEEE Standard for Binary Floating-Point Arithmetic, ANSI/IEEE Std. 754-1985, IEEE, Inc., New York, 
1985.
	
4.	 Hohl, W. ARM Assembly Language: Fundamentals and Techniques, CRC Press, Boca Raton, FL, 
2009.
	
5.	 The SPARC Architecture Manual, Version 8, SPARC International Inc., Menlo Park, CA, 1992 
(http://www.sparc.com/standards/V8.pdf).
	
6.	 PowerPC tm Microprocessor Family: The Programmer’s Reference Guide, Motorola Inc., 1995, 
International Business Machines Inc., 1991–1995 (http://www.cebix.net/downloads/bebox/PRG.pdf).
	
7.	 Patterson, D.A. and Hennessy, J.L., Computer Organization & Design: The Hardware/Software 
Interface, 3rd edn, Morgan Kaufmann Publishers, Borlington, MA, 2005.
M1
PE1
PE2
PEN
Switch
M2
MN
FIGURE 23.35  MIMD architecture based on a crossbar switch.
© 2011 by Taylor and Francis Group, LLC

23-44 
Fundamentals of Industrial Electronics
	
8.	 Brey, B.B., The Intel Microprocessors: 8086/8088, 80286, 80386, 80486, Pentium, Pentium Pro 
Processor, Pentium II, Pentium III, Pentium 4: Architecture, Programming, and Interfacing, 7th edn, 
Pearson-Prentice Hall, Upper Saddle River, NJ, 2006.
	
9.	 Cady, F.M., Software and Hardware Engineering: Assembly and C Programming for the Freescale 
HCS12 Microcontroller, 2nd edn., Oxford University Press, New York, 2008.
	 10.	 Stewart, J.W., The 8051 Microcontroller: Hardware, Software and Interfacing, Regents/Prentice-Hall, 
Englewood Cliffs, NJ, 1993.
	 11.	 Hennessy, J.L. and Patterson, D.A., Computer Architecture: A Quantitative Approach, 3rd edn., 
Morgan Kaufmann Publishers, San Francisco, CA, 2002.
	 12.	 Stone, H.S., High-Performance Computer Architecture, 3rd edn., Addison-Wesley Publishing Co., 
Boston, MA, 1993.
	 13.	 LPC21xx and LPC22xx User Manual, Rev. 03, NXP Semiconductors, Netherlands B.V., April 2008.
	 14.	 MC9S08EL3, MC9S08EL16, MC9S08SL16, MC9S08SL8, Data Sheet, Rev. 3, Freescale Semiconduc­
tors, Austin, TX, July 2008.
	 15.	 Atmel, Low Pin Count 8-bit Microcontroller with A/D Converter and 16 KBytes Flash Memory, 
T89C5115, AT89C5115, Rev. 4128G-8051-02/08, Atmel Corporation, San Jose, CA, September 2008.
	 16.	 Flynn, M.J., Very high-speed computing systems, Proc. IEEE, 54(12), December 1966, 1901–1909.
	 17.	 Hwang, K., Advanced Computer Architecture: Parallelism, Scalability, Programmability, McGraw-
Hill, Inc., New York, 1993.
	 18.	 Wolf, W. Computers as Components: Principles of Embedded Computing System Design, 2nd edn., 
Chapter 8, Morgan Kaufman Publishers, San Francisco, CA, 2008.
	 19.	 Wu, C. and Feng, T., Tutorial: Interconnection Networks for Parallel and Distributed Processing, IEEE 
Computer Society Press, Silver Spring, MD, 1984.
	 20.	 Intel Corporation, Embedded Microcontrollers, Chapter 2, pp. 2–3, Figure 1, Intel order number 
270646, ISBN1-55512-203-5.
© 2011 by Taylor and Francis Group, LLC

24-1
24.1  Introduction
Since their advent, microprocessors were for years the only efficient way to provide electronic sys-
tems with programmable functionality. Although the hardware structure of microprocessors is 
fixed, they are capable of executing different sequences of basic operations (instructions). The pro-
gramming process mainly consists of choosing the right instructions and sequences for the target 
application.
Another way of achieving programmable functionality is to use devices whose internal hardware 
resources and interconnects are not totally configured by default. In this case, the programming process 
(generically called configuration) consists of choosing, configuring, and interconnecting the resources 
to be used. Programmable logic matrices, whose basic structure is shown in Figure 24.1, were the first 
attempts to implement this second approach for programmability. However, for a number of years their 
use was quite limited, mainly due to technological reasons.
Currently, programmable matrices can be found in programmable logic devices (PLDs), whose main 
application is in glue logic and finite state machines. The basic structure of PLDs is shown in Figure 24.2. 
Configuration consists of creating the connections between rows and columns of the programmable 
matrices, and of configuring the macrocells.
24
FPGAs and 
Reconfigurable Systems
24.1	 Introduction.....................................................................................24-1
24.2	 Advanced Hardware Resources in FPGAs..................................24-4
Integrated Functional Blocks  •  I/O Signal 
Conditioning  •  Special Devices
24.3	 IP Cores.............................................................................................24-5
24.4	 Software Tools for FPGAs..............................................................24-5
SoC Design Tools  •  DSP Design Tools  •  Software and Hardware 
Debugging Tools  •  Power Management Tools  •  Signal Integrity 
and Mixed-Signal Design Tools
24.5	 Role of FPGAs in Reconfigurable Systems..................................24-7
FPGAs as Reconfigurable Elements
24.6	 Applications....................................................................................24-13
Configurable Computing  •  Rapid System Prototyping  •   
Communication Processors and Interfaces  • 
Digital Signal Processing and Digital Control  •  IP Protection  • 
Fault Tolerance
24.7	 Conclusions....................................................................................24-16
References...................................................................................................24-17
Juan J. 
Rodriguez-Andina
University of Vigo
Eduardo de la Torre
Polytechnic University 
of Madrid
© 2011 by Taylor and Francis Group, LLC

24-2 
Fundamentals of Industrial Electronics
The extension of the gate array technique to post-manufacturing customization, based on the idea of 
using arrays of custom logic blocks (LBs) surrounded by a perimeter of I/O blocks (IOBs), all of which 
could be assembled arbitrarily (Xilinx 2004), gave rise to the field programmable gate array (FPGA) 
concept, depicted in Figure 24.3a. LBs are relatively low-complexity elements, capable of providing basic 
combinational and sequential functionality, as shown by the example in Figure 24.3b, which corre-
sponds to the most usual, SRAM-based, FPGAs. On them, logic functions are mainly implemented 
using look-up tables (LUTs), which are 2n × 1 SRAM blocks, and the configuration bits (those that define 
the configuration of the device) are also stored in SRAM cells.
The original application of FPGAs in rapid prototyping has been complemented with new applica-
tions that take advantage of the characteristics of current devices, such as high speed, very large number 
of components and supported protocols, or the availability of intellectual property (IP) cores. While 
application-specific integrated circuits (ASICs) are usually the preferred implementation platform for 
final production, mainly because of their high-performance and low-power possibilities, as well as their 
low cost for high volume production, there are some problems associated with them: longer develop-
ment times and increasing non-recurring costs. In this context, FPGAs have become a main player even 
for deployment in mass production quantities, particularly when time-to-market constraints are high, 
or some reconfiguration capabilities in the hardware are needed.
In this chapter, the main characteristics and structure of modern FPGAs are described, together with 
the software resources that enable the efficient exploitation of their many capabilities. It is not intended to 
provide a comprehensive list of resources, tools, and their corresponding devices and vendors [readers can 
refer to specialized literature for this (Rodriguez-Andina et al. 2007)]. After that, the main concepts related 
to reconfigurable systems are presented, with emphasis on their FPGA implementation. Finally, the most 
significant current application domains of FPGAs are discussed.
1
1
&
Programmable
connection
(a)
≥1
≥1
&
&
&
&
&
1
1
≥1
≥1
(b)
Programmable
connection
FIGURE 24.1  Programmable matrices: (a) programmable logic array (PLA) and (b) programmable array logic (PAL).
© 2011 by Taylor and Francis Group, LLC

FPGAs and Reconfigurable Systems 
24-3
1
Inputs
(a)
1
PAL/PLA
Outputs
Configurable
macrocell
Configurable
macrocell
(b)
1D
C1
1
1
/1
G1
EN
1
1
1
/1
G1
MUX
MUX
Matrix
Δ
FIGURE 24.2  (a) Basic PLD structure and (b) sample basic macrocell.
LUT
Control
logic
D
R
C
Q
(b)
Interconnect
matrix
Interconnect
matrix
Interconnect
matrix
Interconnect
matrix
Logic
block
Logic
block
Logic
block
Logic
block
IOB
IOB
IOB
IOB
IOB
(a)
IOB
IOB
IOB
FIGURE 24.3  (a) FPGA concept and (b) sample basic LB.
© 2011 by Taylor and Francis Group, LLC

24-4 
Fundamentals of Industrial Electronics
24.2  Advanced Hardware Resources in FPGAs
FPGA devices have reached a level of development that puts them on the edge of microelectronics fab-
rication technology advancements. This has enabled an impressive amount of resources to be readily 
available on a single chip. Apart from the standard LBs, hardware resources implemented in FPGAs 
greatly differ depending on the manufacturer and, for a given manufacturer, on the architecture/family 
of devices. The resources that provide most advantages to designers can be classified as follows: inte-
grated functional blocks, I/O signal conditioning and special (e.g., radiation-tolerant) devices. Due to its 
significance, reconfiguration is addressed in Section 24.5.1.
24.2.1  Integrated Functional Blocks
The most usual functional blocks that can be found in current FPGAs are as follows:
	
1.	 Memories, which allow processing speed to be increased, I/O pins to be more efficiently used, and 
the design of the system at the board level to be simplified. Large amounts of internal memory are 
available in current FPGAs, in many different arrangements: RAM (single port, simple dual-port, 
true dual-port and bidirectional dual-port), ROM, or shift registers. From these structures, it is also 
possible to implement others such as FIFOs or content addressable memories (CAMs). Advantage 
can also be taken of internal memory blocks to build complex functions, such as arbitrary waveform 
generators, whose values can be obtained from a table stored in memory.
	
2.	 Clock managers. Phase-locked loops (PLLs) and delay-locked loops (DLLs), can be used to compen-
sate clock propagation delays throughout the FPGA, to correct clock duty cycle or phase shifts, or to 
multiply/divide clock frequency.
	
3.	 Arithmetic circuits. Some devices incorporate a relatively large amount of low-complexity arith-
metic blocks. Complex arithmetic blocks (DSP blocks) are found in advanced FPGAs. Multipliers 
with non-standard 9, 18, or 36 bit data inputs (available in some devices) allow performance to be 
improved, because DSP functions not often require exact 16, 24, or 32 bit precision.
	
4.	 Transceivers. In some devices, standard as well as user-defined communication protocols can be 
easily implemented by means of blocks that encode/decode and serialize/deserialize data, include 
transmission and reception buffers, and can perform clock synchronization.
	
5.	 Integrated processors. Embedded processors and peripherals are available in complex FPGA archi-
tectures, in order to support system-on-chip (SoC) solutions. Processors include RISC or 8051-based 
microcontroller cores. Soft processors (i.e., processing cores built from standard FPGA resources) 
are available from Xilinx (PicoBlaze, MicroBlaze) and Altera (Nios, Nios II). The PicoBlaze core is 
a basic 8 bit microcontroller implemented using a reduced number of logic blocks. The MicroBlaze 
core corresponds to a 32 bit RISC microprocessor including a standard set of peripherals. The Nios 
processor provides a more complex but flexible solution. For example, register bank, instruction, 
and data sizes can be configured and the user can add custom instructions to the CPU. Peripherals 
include universal asynchronous receivers/transmitters (UARTs), timers, compare and capture units, 
multiply–divide units, memory controllers, Ethernet media access controllers, or even analog-to-
digital converters (ADCs).
24.2.2  I/O Signal Conditioning
Specific resources associated to the I/O pins allow FPGAs to be connected to other devices operating at 
different voltages, without the need for additional interface circuitry and, therefore, significantly 
simplify PCBs and reduce costs. I/O pins are usually grouped in banks, each one of which can be used 
with a different I/O standard. Some architectures also include internal terminating resistors, which 
allow signal integrity (and therefore bandwidth) to be improved and ease the design of the PCBs.
© 2011 by Taylor and Francis Group, LLC

FPGAs and Reconfigurable Systems 
24-5
24.2.3  Special Devices
24.2.3.1  Nonvolatile FPGAs
One-time programmable (OTP) devices are available, providing advantages in some applications, 
mainly because they do not need auxiliary external resources for configuration at power-on, their 
switch resistance and capacitance (and usually their power consumption) are lower, and their noise 
immunity larger than those of their SRAM-based competitors. Antifuse is the main technology used 
in nonvolatile FPGAs, but there also exist SRAM-based devices with internal nonvolatile configuration 
memory, as well as flash-based devices.
24.2.3.2  Low-Power Devices
Current handheld and portable electronics demand low-power devices and small, cheap, efficient power 
converters, and batteries. In addition, the reduction in power consumption simplifies thermal manage-
ment and improves reliability. FPGAs are usually not power-efficient due to the overhead required to 
provide configurability. Moreover, technology scaling down leads to increasing leakage current, there-
fore increasing static power consumption. To overcome these problems, low-power FPGAs have been 
developed. Low-power operating modes can be efficiently implemented in antifuse devices, which, in 
addition, usually dissipate less dynamic power than SRAM-based ones, as mentioned above. Several 
techniques can be used to reduce power consumption in SRAM-based FPGAs (Khan 2006). On one 
hand, transistors with different sizes can be distributed throughout the devices in order to have them 
used for high- or low-speed sub circuits as needed, thus optimizing dynamic power consumption. Thick 
oxide can be used in “slow” transistors, therefore reducing static consumption. Further reductions 
can be achieved by using low-k dielectrics and increasing the amount of local interconnecting resources. 
The amount of interconnects can be reduced by using increasingly complex logic blocks, with which 
more complex functions can be implemented, and embedded specialized blocks (as described in 
Section 24.2.1).
24.2.3.3  Radiation-Tolerant Devices
FPGAs are being increasingly used in aerospace applications. Antifuse radiation-hardened FPGAs, are 
inherently more radiation-tolerant than SRAM-devices. However, radiation-hardened versions of the 
latter are also available, providing significant advantages for aerospace applications, because of their 
higher performance and reconfiguration capabilities, with respect to antifuse devices.
24.2.3.4  Mixed-Signal FPGAs
Analog I/O blocks and configurable analog blocks for signal conditioning are available in some devices, 
including analog multiplexers, gate drivers, and ADCs.
24.3  IP Cores
These are pre-designed (in many cases parameterizable) and verified functions that allow design-
synthesis-verification time to be reduced. They should (unfortunately not all do) provide predefined and 
highly optimized performance. They cover application domains such as communications, multimedia, 
signal processing, and automotive.
24.4  Software Tools for FPGAs
Specific powerful software tools are needed to take advantage of the many different complex hardware 
resources included in current FPGAs. In fact, the lack of suitable design tools can make advanced fea-
tures useless. Although many efforts are still needed in this area, some resources are already available, 
which are described in Sections 24.4.1 through 24.4.5.
© 2011 by Taylor and Francis Group, LLC

24-6 
Fundamentals of Industrial Electronics
24.4.1  SoC Design Tools
The implementation of FPGA-based SoCs or embedded systems results in very complex tasks involving 
software and hardware developers. From the hardware point of view, the main problem is efficient IP 
integration, including design, synthesis, simulation, and verification. From the software point of view, 
the main problem is to debug the software system (made up of a real-time operating system (RTOS), 
drivers, and custom software), in real hardware.
There are tools that support the design based on soft or hard embedded processor cores. In general, 
they include peripheral IPs, soft processor cores customization tools, software development tools, hard-
ware/software debuggers, hardware verification tools, libraries, and software and hardware code down-
loads to development boards. On the other hand, traditional tools used for ASIC implementations have 
been adapted for FPGA.
Finally, some existing tools support FPGA-based SoC design from C language, by translating the C code 
to synthesizable hardware descriptions.
24.4.2  DSP Design Tools
There are software design tools to implement DSP applications on FPGAs, which accelerate the migra-
tion from traditional software algorithms to faster hardware implementations. Existing tools automati-
cally translate Simulink• models to synthesizable hardware descriptions that are to be used with FPGA 
implementation tools. Those tools provide Simulink libraries including common DSP, arithmetic, bus 
manipulation, control logic, storage, imaging, and communication functions. Advanced options like 
HDL co-simulation and hardware-in-the-loop are also supported.
24.4.3  Software and Hardware Debugging Tools
Debugging complex real-time embedded designs that take advantage of the many different resources 
available in today’s FPGAs can be a non-trivial, highly time-consuming task. As a consequence, efficient 
in-circuit FPGA verification tools are needed. These tools can be either implemented in hardware (using 
the device’s logic resources) or software (using either hard or soft embedded processors). Debugging 
capabilities are needed for both hardware- and software-implemented subsystems.
The main component of any FPGA debugging tool is the measurement instrumentation, which must 
be capable of capturing logic values of signals while the application is running in-system at operational 
speed. The basic operation is as follows: the internal nodes to be observed are defined, their activity is 
monitored, and the sequence of values is transmitted in real time to a host.
Most debugging tools are based on IP blocks (which could therefore be instantiated several times) 
implementing logic analyzer functionalities.
24.4.4  Power Management Tools
In addition to the manufacturing techniques and special operation modes to reduce power consumption 
discussed in Section 24.2.3.2, tools are needed to manage power in two basic directions. On one hand, 
design tools (i.e., synthesis, place and route, etc.) must include strategies to minimize consumption. On 
the other hand, it is necessary to estimate the power that a given design will dissipate in practice.
In order to be feasible, power-aware design strategies need to be supported by tools that provide 
power consumption estimates as accurate as possible, which could be used to support design decisions. 
Currently, power calculator tools are available from FPGA vendors.
As many complex designs are based on IP blocks, these can be responsible for a significant part of the 
power consumption. IP power modeling is currently an important research area, in which promising 
© 2011 by Taylor and Francis Group, LLC

FPGAs and Reconfigurable Systems 
24-7
results are being obtained. In some cases, different versions of a given IP functionality are available 
(Khan 2006), each one optimized for different requirements (e.g., performance, logic usage, balanced, 
and others) and therefore exhibiting different power consumption, which should be carefully examined.
24.4.5  Signal Integrity and Mixed-Signal Design Tools
The use of FPGAs in high-speed and/or mixed-signal applications is increasing. Because of the complex-
ity of such systems, modeling languages and tools are often used to accelerate behavioral simulation and 
PCB implementation tasks.
Most FPGA vendors provide IBIS (I/O buffer information specification) and HSPICE models of their 
devices, in order to allow board-level signal integrity analysis within EMC guidelines, crosstalk, and 
timing analysis.
Recently, other modeling languages oriented to the design and simulation of mixed-signal systems 
(like VHDL-AMS, Verilog-AMS, and MAST) have been introduced in applications where FPGAs are 
used as digital support. The advantage of mixed-signal languages is that designers can easily design and 
simulate with both analog and digital components from the same environment, enabling a top-down 
mixed-signal design methodology.
24.5  Role of FPGAs in Reconfigurable Systems
When hardware reconfiguration capabilities are required for a given application, using FPGAs offers 
many advantages and opportunities. Although reconfigurable systems are not limited to FPGAs, these 
are the most significant devices at the commercial level. Other possibilities exist, based on custom 
devices with specific reconfiguration features, mainly oriented towards hardware reconfigurable com-
puting systems. However, these devices are intended to overcome some problems of FPGAs in very 
specific areas, like ultra-fast reconfiguration time (one clock cycle to reconfigure a complete device). 
Therefore, the focus herein is on the use of FPGAs, the advantages of applying their reconfiguration 
capabilities in-field, the different reconfiguration alternatives, commercial and industrial approaches, 
and, finally, on what the future role of FPGAs in reconfigurable systems will be. It should be noted that 
not all FPGAs are reconfigurable, but some are OTP devices. Obviously, this section deals with recon-
figurable FPGAs.
Configurable devices are configured, with sequences of bits arranged in configuration files called bit-
streams. Some years ago, FPGAs could only be reconfigured by using a full bitstream that programmed 
all configuration bits in the device. This configuration had to be static, typically immediately after sys-
tem power-up. However, an increasing number of FPGA technologies are permitting the reconfigura-
tion of portions of the FPGA, even while the rest of the device is kept working normally. This possibility 
is referred to as partial reconfiguration, whereas if the device can be reconfigured at run-time, it is 
referred to as a run-time reconfigurable system (RTRS). A special subset within RTRSs is composed of 
systems that can reconfigure themselves, which are referred to as self-reconfigurable systems (SRSs).
Granularity is another important aspect in reconfiguration. It is defined as the size of the functional 
elements that are reconfigured at the same time. Large granularity reconfiguration applies to systems 
where complex IP cores are replaced in the logic and, in this case, size is related to large portions of 
the FPGA and referred to as a percentage of their area. This way, there are reconfigurable systems that 
reconfigure a significant part (e.g., one half) of the FPGA, or use a slot-based approach, where the FPGA 
is divided into several (normally equal) slots, each of which can be reconfigured separately. Medium 
granularity applies to a portion of an IP core, and it is typically used to reconfigure functionality at 
register level. Finally, small granularity refers to the reconfiguration of a small number of configuration 
bits, applying typically to the values in a LUT, to the content of a flip-flop, or to an interconnection.
One of the major problems derived from the use of reconfiguration capabilities in FPGAs is the match-
ing between the reconfiguration granularity that is desired and the granularity supported by the 
© 2011 by Taylor and Francis Group, LLC

24-8 
Fundamentals of Industrial Electronics
specific FPGA technology. The smallest reconfigurable area in FPGAs is a variable factor that depends 
on the manufacturer technology and family. Some FPGA families support column reconfiguration, that 
is, the minimum reconfigurable unit is a column of LBs. Other (newer) families support rectangular 
reconfiguration (the portion being reconfigured does not necessarily have to span a whole column), but 
the rectangle size is not restricted to a single element of the FPGA. Even though some reconfiguration 
techniques in commercial FPGAs claim that run-time reconfiguring an area with the same program-
ming than it had (before reprogramming) is a glitch-less operation, there are many restrictions derived 
from the atomic reconfiguration unit that can be handled. For instance, if the content of a flip-flop has 
to be modified, all flip-flop contents in the same column for a column-based reconfigurable FPGA 
have to be modified. In order to do this, system execution has to be stopped, a read-back operation has to 
be produced to read the content of all flip-flops in the same column, then the desired flip-flop value 
has to be modified, and all flip-flops reprogrammed back. This does not allow real run-time reconfigu-
ration but, if the atomic reconfiguration unit had been a single flip-flop, operation at run-time would 
have been possible. This, together with faster reconfiguration times are the main claims of the research 
community.
There are many reconfigurable system models, although most of them rely on the use of microproces-
sors and reconfigurable fabric. According to Al-Hashimi (2006) and Compton and Hauck (2002), there 
are several types of coupling between both parts, as shown in Figure 24.4:
•	 External standalone: The reconfigurable hardware is a fully independent device connected to the 
inputs and outputs of the microprocessor.
•	 Coprocessor unit or attached processor unit: In both cases, the reconfigurable hardware is closer 
to the microprocessor than in the previous case. In the coprocessor case, the reconfigurable 
hardware is closest to the microprocessor, and it can operate as a functional resource of the 
microprocessor itself. In the second case, the reconfigurable hardware is accessed after the 
cache memories, that is, in the secondary bus.
•	 Reconfigurable functional unit: The reconfigurable hardware is embedded into the microprocessor. 
This structure is the easiest to define custom instructions in the processor with its associated 
functional hardware.
•	 Microprocessor embedded in the reconfigurable hardware: In this case, the microprocessor could 
be a hard core, embedded in the reconfigurable fabric, or a soft core, placed using a part of the 
reconfigurable fabric itself.
The partial reconfiguration topic has started to produce applications which benefit from it. The main 
benefits of disruptive (non real-time) partial reconfiguration are reduced programming time and the 
Cache
I/O
Reconf.
logic
μP core
(c)
Reconf.
logic
μP core
(d)
Reconf.
logic
μP core
(e)
Cache
I/O
Reconf.
logic
μP core
(a)
Cache
I/O
Reconf.
logic
μP core
(b)
FIGURE 24.4  Different coupling alternatives: (a) external standalone, (b) coprocessor unit, (c) attached processor 
unit, (d) reconfigurable functional unit, and (e) embedded microprocessor.
© 2011 by Taylor and Francis Group, LLC

FPGAs and Reconfigurable Systems 
24-9
possibility of silicon reuse, since the same device can be used for different tasks. In addition to these, the 
added benefits of using PRTRS, instead of conventional reconfigurable devices, are briefly summarized 
as follows:
•	 Increased system performance: The system stays operative, while a portion is being reconfigured. 
Therefore, as the system does not need to be stopped, there is no theoretical loss of performance.
•	 Enhanced system updates: By modifying only a portion of the device, system updates do not affect 
the remaining devices, connected to the FPGA, which can keep functioning normally.
•	 Hardware sharing: Partial reconfiguration permits not only having several applications sharing 
the same FPGA, allowing a smaller and cheaper device to be selected (like full reconfiguration), 
but also running them in parallel. This characteristic is gaining importance with the increasing 
FPGA integration level.
•	 Shorter reconfiguration energy: Partial reconfiguration deals with smaller configuration times 
compared to full device updates. This results in reduced configuration times and therefore in 
reduced power consumption during reconfiguration.
•	 Less storage resources: Partial configuration files require smaller storage sizes for programming, 
and this is important for resource-restricted devices.
Partial reconfiguration is valuable for devices that operate in environments where applications cannot 
be interrupted while the system is being adapted. It is also suitable for highly parallel systems that can 
time-share the same piece of the FPGA resources. Without this capability, it would be necessary to stop 
the system during device updates and to reconfigure the entire FPGA to support a different application, 
losing all previous configurations.
24.5.1  FPGAs as Reconfigurable Elements
The design of an FPGA-based PRTRS system involves several issues that need to be analyzed. The first 
one is to select a device that supports these reconfiguration techniques. Related to this, the partial 
reconfiguration possibilities of some commercial FPGAs are shown in Section 24.5.1.1.
The device needs to be logically partitioned into fixed and reconfigurable areas, so that reconfigurable 
cores, stored as partial bitstreams, can safely fit into the target position. The definition of this reconfigu-
ration architecture is important, because it is necessary to match the size of reconfigurable areas and the 
targeted reconfiguration granularity, a process which requires good knowledge of the internal FPGA 
architecture. Hardware partitioning issues will be reviewed in Section 24.5.1.2.
Partial reconfiguration, especially at run-time, also requires tool support. In some cases, these tools 
have to run in restricted devices that need to autonomously handle reconfiguration themselves. Tools 
for reprogramming, adding, deleting, or relocating pieces of hardware into FPGA silicon areas have to 
be considered. This issue will be covered in Section 24.5.1.3.
Finally, it is also important to take into account that the communication between the microprocessor 
and the reconfigurable element, or among several reconfigurable elements in case there is more than 
one, could be a bottleneck, and the coupling between all software and hardware tasks must fulfill com-
munication requirements. For an ASIC approach, the problem of choosing a suitable communication 
scheme is a challenge, but this problem is even harder when considering a reconfigurable environment, 
since communication requirements may be unknown before deciding the communication infrastruc-
ture. In this sense, reconfigurable communications may be a solution to solve the problem, and this 
topic will be presented in Section 24.5.1.4. Special attention is given to networks on chip (NoCs), more 
specifically to reconfigurable NoC approaches.
24.5.1.1  Commercial FPGAs with Partial Reconfiguration Support
The Altera Excalibur devices allow dynamic configuration of the FPGA while the on-chip processor is 
active for other tasks, such as running an operating system. The user can modify the device functionality 
© 2011 by Taylor and Francis Group, LLC

24-10 
Fundamentals of Industrial Electronics
by storing the configurable system function in an external nonvolatile memory, and use the processor 
to configure the hardware without the need to reboot. This results in systems with a single reconfigu-
rable coprocessor that is composed of the entire reconfigurable array. Additionally, more recently, some 
Altera’s FPGAs permit the reconfiguration of some elements, like serializers/deserializers or PLLs.
Differently, Atmel’s FPGAs have the ability to implement cache logic designs, where part of the FPGA 
can be reprogrammed without loss of register data, while the remainder of the FPGA continues to oper-
ate without disruption, which is real-time partial reconfiguration. The main drawback of these FPGAs 
is their small size and the bit-based reconfiguration access method, which permits the highest flexibility, 
but requires very low-level reconfiguration control.
Xilinx’ FPGAs can also be partially reconfigured. The configuration bitstream format allows a 
designer to modify one or more configuration packets and perform partial reconfiguration by accessing 
some portions of the FPGA reconfiguration memory. However, each device family has different recon-
figuration features: the low-cost Spartan 3 series permit the reconfiguration of entire device columns 
that span from the FPGA top side to the bottom side, including top and bottom I/O blocks. When a 
single device row has to be changed, the information for the entire column has to be sent. The first 
Spartan 3 family does not include an internal configuration access port (ICAP, a mechanism to inter-
nally access the configuration memory), and thus it is not well suited for designing self-reconfigurable 
systems. Some subfamilies like the Spartan 3A, 3AN, and 3ADSP one, include such a port. On the 
other side, all Xilinx high-performance FPGA families permit glitch-less reconfiguration and include 
an ICAP configuration port. Virtex II and Virtex II Pro families require column-based reconfiguration, 
while in the newer families, Virtex 4 and Virtex 5, reconfiguration frames do not span the entire FPGA 
height, but several FPGA rows (16 in Virtex 4 and 10 in Virtex 5) instead. They also have double ICAP 
support. These improvements in new families are probably a result of the push of the research commu-
nity that has put efforts in designing architectures, tools, and applications. Nevertheless, migration to 
the new platforms is being relatively slow, although new research is being based on these devices.
24.5.1.2  Virtual Architecture FPGA Partitions for Partial Reconfiguration
The selection of a suitable reconfigurable device is conditioned not only by the aforementioned recon-
figuration features and restrictions, but also by the internal architecture. The internal topology of the 
FPGA has to be analyzed, and a partition into several areas has to be done. Basically, these are fixed area, 
reconfigurable area, and communications infrastructure.
The fixed area of the FPGA is the portion of the logic that does not change in any configuration. It 
is normally devoted to external off-chip communications, internal communications management, and 
self-reconfiguration. It is typically placed in FPGA regions where irregularities prevent them from being 
mapped as reconfigurable areas. For column-based FPGAs, these blocks are placed in the leftmost or 
rightmost sides of the FPGAs, and only I/O blocks close to these areas are used for off-chip interconnects.
The reconfigurable area has to have a fixed position for the connections with the fixed area, but the 
rest of the logic inside can be freely reconfigured. Several architectures have been proposed with dif-
ferent numbers of reconfigurable areas, with different sizes, but for most column-based reconfigurable 
FPGAs, column-based reconfigurable areas are defined.
Some approaches define just two regions (fixed and reconfigurable), with different geometries and 
proportions. There are also quite a few slot-based approaches, where the reconfigurable area is divided 
into equal-size portions of logic, with the possibility of programming individual IP cores in each of 
these slots. In many of these approaches most of the slots are column-based, following a 1D organiza-
tion, although there are a more reduced number of approaches that follow a 2D organization. Figure 24.5 
shows examples of 1D and 2D partitions.
Washington University has created a platform for partial run-time reconfigurable systems oriented to 
telecommunications, called field programmable port eXtender (FPX) (Horta et al. 2002), with applica-
tions in rapid prototyping of telecommunication routers and firewalls. It uses a two-slot partition, which 
is connected through a ring network.
© 2011 by Taylor and Francis Group, LLC

FPGAs and Reconfigurable Systems 
24-11
The term slot for general 1D partitions was first used in (Ullmann et al. 2004). A 1D multi-slot archi-
tecture has been proposed that uses a 1 bit serial bus for communications in the first versions (Palma 
et al. 2002), and a NoC in the most recent ones (Moller et al. 2006). Another 1D approach is described by 
Walder and Platzner (2004), where partial reconfiguration is performed in a fully transparent way by the 
use of a so-called hardware operating system. The influence on hardware reconfiguration as an operat-
ing system task has also been addressed in (Becker et al. 2007), where hardware–software multitasking 
needs are analyzed. It is also important to mention the Erlangen slot machine (Bobda et al. 2005), where 
local and shared memory access and off-chip interconnections by using top and bottom I/O blocks of a 
1D column-based partition approach are presented.
More recent developments follow 2D partition approaches, like the dynamically reconfigurable NoC 
(DRNoC) approach (Krasteva et  al. 2008) where a method to implement partial reconfigurable 
partitions is presented, and the communication infrastructure is a reconfigurable NoC.
A sensitive slot-based partition should take into account the possibility of reallocating a core into 
any slot position, being capable of using IP cores that could span through more than one slot, while still 
achieving real-time reconfiguration, if required.
It is common that FPGAs have some non-regular regions dedicated to memories, DSP blocks, embed-
ded hard microprocessor cores, etc. In this case, the slot partition is not trivial, and the compromise 
between reconfiguration granularity and number of slots has to be solved.
The communication infrastructure is in charge of linking slots between them, as well as slots with the 
fixed area. As for the ASIC intra-communication problem, bus approaches and NoC approaches are the 
solutions more frequently implemented.
24.5.1.3  Tool Support for Partial Reconfiguration
The complexity of partially reconfigurable systems requires the support of tools to automate several 
design and in-field operation tasks. They can be classified into the following categories:
•	 Tools to support design flows for the creation of partial reconfiguration bitstreams.
•	 Tools to manipulate partial reconfiguration bitstreams, so that a core can be placed into any slot 
position in the FPGA.
•	 Toolsets, which may also be embedded and packed as hardware-aware operating systems, to 
support reconfiguration during device operation.
FPGA
Interconnection logic
Slot
1,0
Slot
0,0
Slot
0,1
Slot
0,2
Slot
0,3
Slot
1,1
Slot
1,2
Slot
1,3
(b)
Fixed
area
Slot
1
Slot
2
Slot
3
PLL
PLL
PLL
External
connections
FPGA
Intra-core
comm.
(a)
PLL
I/Os
I/Os
External switch matrix
Interconnection logic
Unused I/Os
Unused I/Os
FIGURE 24.5  Examples of (a) 1D partition showing possible interconnection mechanisms and (b) 2D partition.
© 2011 by Taylor and Francis Group, LLC

24-12 
Fundamentals of Industrial Electronics
Regarding the design flows for partial bitstream generation, there are several commercially available 
solutions integrated in the manufacturers’ proprietary tools. However, these approaches are not flexible 
enough, in the sense that they do not handle repetitive tasks in a friendly manner, they do not per-
form any kind of bitstream manipulation, and deep partial reconfiguration knowledge is required. Also, 
these tools do not help in reconfigurable systems simulation and debug.
Partial bitstream manipulation for core reallocation is a need for multi-slot-based architecture parti-
tions. These tools read a bitstream that corresponds to a core placed in a specific slot position, and pro-
duce another bitstream for another slot position. There are many tools of this kind that are derived from 
the JBits application, but since this library is Java based, it is difficult to have implementations able to 
run on feature-restricted devices like embedded reconfigurable systems. However, the possibility of fine 
grain reconfiguration by using low-level reconfiguration routines (mainly for LUT modification and 
wire rerouting) produces very complete and good results. On the other side, tools than can run without 
JBits underneath are able to be executed with low CPU cost on a restricted embedded microprocessor.
Regarding reconfiguration support at run-time, available commercial solutions seldom cover the most 
basic tasks of programming and reading back configuration files. Therefore, several academic solutions 
have been adopted, from simple control systems implemented either in hardware or in software run-
ning in the embedded processor, to complete hardware operating system-based solutions. Furthermore, 
some solutions extend already existing operating systems, like Linux.
24.5.1.4  On-Chip Communications in Reconfigurable Systems
On-chip communications are an important challenge for all SoC designs, but this problem is even more 
important for reconfigurable systems, since the communication needs may change, and even may be 
unknown for future hardware configurations. Therefore, scalable and flexible communication struc-
tures are needed.
Hardware tasks need to exchange data between them, as well as with off-chip components. Normally, 
the fixed area of the internal FPGA architecture partition is used for this last purpose.
Hardware tasks, placed in slots or whatever arrangement is used, need to be designed with fixed 
position connections. These connections are generally called bus macros, following the name defined 
by Xilinx in their design flow. However, these macros are not the only solution, and many alternatives 
have been proposed in order to increase the connectivity of modules. They allow either bus or point-to-
point connections, which are useful for either real point-to-point links or to provide access to a NoC 
infrastructure.
The move from the bus to the NoC approach has been followed also in the reconfigurable systems 
area. The number of slots for past FPGA technologies was not high enough to justify, in most cases, the 
need of a NoC, because buses are a simple and flexible solution for a low number of cores. However, as 
FPGA capacity is increasing, the number of cores allowed in a simple FPGA is higher, and NoCs are 
being considered as a promising solution for these larger systems.
NoC approaches in reconfigurable systems are typically associated with 2D FPGA partition 
approaches, and regular meshes and heterogeneous networks are being analyzed. Work is being con-
ducted on the possibility of reconfiguring the communication infrastructure, apart from the cores 
themselves, so that the available communication resources can be fitted to the variable communication 
needs for a given configuration with a set of hardware and software tasks.
The solution in Ullmann et al. (2004) has switch matrixes that can be reconfigured. The latest works 
on the Erlangen machine (Bobda et al. 2005) show the use of a reconfigurable NoC, called DyNoC, 
which allows core grouping and the network reconfiguration to bypass the portions of the NoC that are 
used by the merging of two adjacent cores. The CoNoChi (Pionteck et al. 2006) and DRNoC (Krasteva 
et al. 2008) NoCs are more flexible solutions since network interfaces and some parts of the routers can 
be modified. DRNoC may reconfigure switch matrixes, network interfaces and routers’ parameters, 
allowing not only NoC communications but a combination of these ones with point-to-point connections 
and bus-based solutions.
© 2011 by Taylor and Francis Group, LLC

FPGAs and Reconfigurable Systems 
24-13
24.6  Applications
The way in which digital systems have been implemented over the years has been strongly influenced 
by the evolution of the programmability capabilities described in Section 24.1. For many years, com-
plex digital processing and control systems have been based on architectures whose processing cores 
are microprocessors or, more recently, microcontrollers or DSPs. Currently, FPGAs have become an 
interesting alternative to these structures, because of their flexibility, abundance of resources (which, as 
described above, include embedded and soft processors), advanced features, and low cost. The system-
atic use of HDLs and high-level synthesis tools dramatically simplifies the design process and reduces 
time to market. Besides, the possibility to integrate in a single device several functionalities that previ-
ously required dedicated ICs led to the SoC concept. Although microprocessors, microcontrollers, and, 
to a lesser extent, DSPs keep being devices of paramount importance for industrial electronics, there are 
three main reasons that boost the widespread use of FPGAs:
•	 To take advantage of the possibility of readily and efficiently implementing complex functional-
ities in hardware, outperforming their software counterparts.
•	 To take advantage of the reconfiguration capabilities of FPGAs.
•	 To take advantage of SoCs for saving area and power, as well as for simplifying board design.
In Sections 24.6.1 through 24.6.6, the apparently limitless applications of FPGAs are grouped in generic 
fields, which are associated with the resources that justify the use of FPGAs on them.
24.6.1  Configurable Computing
In many applications, general-purpose microprocessor hosts need to be complemented with specialized 
coprocessors. The host supports system-level operation as well as the low-level tasks it is able to perform 
efficiently, whereas specific algorithms are run on the coprocessor. Configurable computing can help 
area and power consumption to be reduced, for instance by correctly choosing the right operator for-
mats for each operating mode or application.
In this area, FPGAs provide the possibility for the coprocessor hardware to be adapted to changes 
affecting the algorithms or the data flow. The use of integrated processors as hosts, in a SoC structure, 
greatly simplifies the implementation of such solutions, particularly because it simplifies the communi-
cation between the host and the coprocessor. The availability of embedded memory also contributes to 
achieve efficient implementations in this area. In addition, partial reconfiguration allows resource usage 
to be optimized. The main issue in the development of these kinds of systems is the efficient partition of 
tasks in hardware and software, which involves co-design, co-simulation, and co-debug.
A hardware accelerator for computation of shortest paths for mobile robots is presented in Sridharan 
and Priya (2007), where an efficient FPGA implementation is achieved by taking advantage of embed-
ded memory blocks. In Kung et al. (2009), a Nios II-embedded soft processor is combined with a hard-
ware implementation of current vector controllers for permanent-magnet synchronous motor drives, 
providing an advantageous solution in terms of performance, complexity, and cost. By using an FPGA 
instead of a computer with a RTOS, the sampling period of force measurements in a bilateral tele-
operation system can be reduced one order of magnitude (Ishii et al. 2007), improving performance 
accordingly. Advantages of FPGA hardware acceleration can also be obtained in the control of power 
converters.
FPGA reconfiguration and hardware acceleration capabilities are particularly useful in applications 
such as neural and fuzzy controllers. Another interesting application field is that of configurable data 
acquisition and signal generation systems. Advantage can be taken for their design of embedded pro-
cessors and memory, transceivers, and configurable I/O interfaces. Educational platforms can also take 
advantage of configurability, allowing students to use them in different courses and experiments in the 
same platform, whose structure and operation is adapted accordingly.
© 2011 by Taylor and Francis Group, LLC

24-14 
Fundamentals of Industrial Electronics
24.6.2  Rapid System Prototyping
In FPGA-based prototyping systems, a digital circuit is mapped onto one or more programmable 
devices. This hardware prototype can be connected to an external system for in-circuit functional veri-
fication. This approach has two main advantages:
•	 Low cost and easy modification and/or bug fixing, because no prototype is actually fabricated.
•	 Short design cycle through relatively simple simulation and verification.
On the other hand, there are also some minor drawbacks as follows:
•	 The operation is slower due to the programmable interconnects. However, given the high perfor-
mance of current devices, this is not a limiting factor for many applications.
•	 For complex prototypes, several interconnected FPGAs are needed. In this case, prototyp-
ing platforms are very complex not only from the hardware but also from the software point 
of view.
Many FPGA-based flexible prototyping solutions are increasingly available. FPGA prototyping 
allows control algorithms to be validated before being applied to physical systems, by taking advan-
tage of the possibility of efficiently carrying out computation-intensive tasks in hardware through 
the use of FPGAs. In a study by Bieser and Muller-Glaser (2005), an FPGA is used as part of an 
automotive prototyping system, taking advantage of its reconfigurability and parallel processing 
capabilities. The FPGA is used to support the output signal generation and input signal process-
ing at the logic level, allowing hardware modules to be reused according to the specifications of 
each automotive system. An experience on testing complex pulse patterns for power switches is 
presented in Fernandez et al. (2006), where complex real-time calculations, for instance those of 
switching angles in a three-phase inverter, are carried out from values previously calculated off-
line and stored in RAM blocks.
Rapid prototyping capabilities are significantly enhanced by the use of hardware-in-the-loop plat-
forms, which allow designs to be verified directly in hardware. For instance, the FPGA implementation 
of a control system can be combined with a simulated plant.
24.6.3  Communication Processors and Interfaces
Communications applications are characterized by strong requirements regarding speed, power con-
sumption, quality, and adaptability to new emerging standards or rapidly evolving protocols. Using 
FPGAs in this area allows time to market to be reduced and systems to be updated according to stan-
dards evolution, without modifying PCBs, and also to be remotely configured. Embedded processors and 
Ethernet controllers allow remote upgrades or maintenance to be carried out. IP protection (discussed in 
Section 24.6.5) is a very important capability in this case.
FPGAs are widely used for connecting complex, high-speed peripherals to general-purpose proces-
sors in embedded real-time systems. In this case, the FPGA acts as an interface, providing a standard 
communication among many different components and a processor. The availability of integrated RAM 
and the I/O compatibility of electrical levels are key features in these applications.
An application domain in which the use of FPGAs is significantly advantageous is that of fieldbuses. 
Being dominated by proprietary systems, it is difficult to guarantee compatibility between devices from 
different manufacturers. In addition, standards (and, in particular, protocols) in this area are continu-
ously evolving. Reconfiguration becomes a suitable solution to adapt these systems to this diversity of 
approaches without the need for changes in the hardware to be made. Another interesting application 
field is that of FPGA-based upconverters/downconverters for digital transmitters/receivers. Integrated 
PLLs/DLLs ease the design of these systems.
© 2011 by Taylor and Francis Group, LLC

FPGAs and Reconfigurable Systems 
24-15
24.6.4  Digital Signal Processing and Digital Control
Despite its easy high-level programming, the application of DSPs in systems with high-speed and 
processing power requirements is limited by their fixed architecture, due to the following reasons:
•	 Fixed memory and data sizes
•	 Low number of multiply-accumulate (MAC) units
•	 Low number and limited performance of buses
•	 Limited I/O resources
The use of several DSPs increases cost and complexity and also reduces performance. On the other 
hand, FPGAs provide a much more flexible and configurable architecture. Even if more difficult to pro-
gram, some advanced features are making them a viable alternative to DSPs:
•	 Embedded multipliers and DSP blocks, which allow complex arithmetic operations to be per-
formed. Currently, DSPs containing several MAC units are available, but are still far from what 
can be achieved using FPGAs, and at a very high cost.
•	 Parallel processing capabilities.
•	 Integrated memory blocks, which ease data storage.
•	 Processing support for higher bandwidth data streams.
•	 Large number of I/O pins and compatibility of electrical levels.
DSP blocks are extensively used in Mato et al. (2008) which, together with the implementation of pre-
distortion functions in internal RAM blocks, allow the efficient correction of nonlinear effects in power 
amplifiers for digital television broadcasting to be achieved in real time. In Salcic et al. (2006), the FPGA 
implementation of an adaptive digital controller allows the performance and accuracy problems associ-
ated with DSP implementations (due to sequential program execution and limited computing power) to 
be overcome. In that work, advantage is taken of internal RAM blocks to store intermediate results, and 
complex functions (floating-point divisions by a constant, responsible for the maximum delay in the cir-
cuit) are implemented in LUTs. Specific algorithm functionalities can be developed and stored in librar-
ies of IP blocks for reuse in different applications. An example of such an approach applied to sensorless 
control in induction motor drives is reported in Charaabi et al. (2005). A three-phase synchronous 
PWM generator, in which frequency division and arithmetic operations (e.g., 4 bit multiplications) are 
efficiently performed in an FPGA is presented in (Omar et al. 2004). High-precision, high-speed motor 
control is addressed in Wen et al. (2006), where sine/cosine waveform generation, fault protection, and 
other control-related functions are implemented in an FPGA and the configuration capabilities of I/O 
blocks allow a direct actuation on a driver IC from FPGA pins to be performed. The online measure-
ment and estimation of electrical magnitudes in power converters can be efficiently moved to the digital 
domain by using FPGAs, as demonstrated in Acero et al. (2007), in which mixed-signal designs are sup-
ported by VHDL-AMS-based tools. In Chan et al. (2007), a MATLAB®/Simulink modular approach is 
used for the design of embedded feedback controllers. It is shown that the implementation of distributed 
arithmetic, taking advantage of the parallel computing capabilities of FPGAs, results in a reduction of 
both complexity and power consumption.
A subject of increasing interest is the digital generation of control signals for electronic switches in 
power converters. While traditional power conversion systems use analog control schemes, the increas-
ing complexity of power systems, motivated by the growing number of subsystems to supply energy, 
the growth in number of supply outputs, the existence of hybrid systems which imply energy being 
taken from several alternative points (hybrid cars, for instance), and the use of new topologies with 
complex control (for instance, multistage power converters for microprocessors or multilevel convert-
ers), is producing a rapid change from analog to digital control. Digital control has the possibility of 
exchanging information with the load, in case this one is digital, allowing complex voltage regulations 
as well as increasing energy efficiency awareness. Additionally, digital control is more immune to noise 
© 2011 by Taylor and Francis Group, LLC

24-16 
Fundamentals of Industrial Electronics
than their analog counterparts. Possibilities of loop programming, monitoring, logging and remote 
operation, soft start/stops, programmable control algorithms, fault detection, output voltage trimming, 
multiphase synchronization, are all new fields in the power conversion area because of the use of digital 
control. The main drawbacks of digital control applied to power conversion are the need of (fast) ADCs 
for control algorithms and regulation, and the associated problems of limited signal resolution, which 
is common to many other digital processing applications. The use of DSPs is a solution for a reduced 
number of applications in this area, whereas the most speed demanding ones rely on the use of ASICs 
or FPGAs. There is a continuous growth in the number of companies which offer integrated products 
for digital control applications, but FPGAs are also a good opportunity for custom control solutions. 
The benefits are the possibility of implementing complex algorithms, with a high number of inputs and 
outputs, with increased flexibility and reprogramming capabilities.
Finally, it is worth mentioning other applications like active filters and the control of AC machine 
drives where FPGAs are being successfully and advantageously used. In the latter, the use of mixed-
signal FPGAs provides significant advantages.
24.6.5  IP Protection
FPGAs can be used to preserve IP, providing solutions that are not only effective but also cheaper than 
ASIC ones. In nonvolatile FPGAs, security bits are available to prevent users from reading the con-
figuration of the devices back, therefore avoiding the details of the system becoming accessible. In very 
complex systems that do not fit, or are not intended to be implemented, on FPGAs, a nonvolatile FPGA 
could be added to provide IP protection.
Encryption is available in some volatile devices, which have to be configured at power-on, as well as at any 
time a reconfiguration is needed, in order to prevent the configuration bitstream from being read by third 
parties. The security key is stored in the FPGA and used during configuration to decrypt the bitstream.
In low-cost FPGAs, where bitstream encryption is not available, the handshaking token technique 
(Feng and Seely 2005) can be used. It works by disabling the functionality of a design within the FPGA, 
until handshaking tokens are passed to it from a secure external device, in a similar way software licens-
ing works.
24.6.6  Fault Tolerance
As can be clearly noticed in Figure 24.3a, the structure of FPGAs is inherently redundant, particularly 
taking into account that in many applications a non-negligible amount of resources remains unused. 
Advantage can be taken of these facts by using spare logic and interconnect resources to replace those 
affected by faults, through a reconfiguration process. In this way, FPGA-based designs can be provided 
with fault tolerance capabilities. Obviously, the applicability of fault tolerance approaches is limited by 
the reconfiguration capabilities of the devices, discussed in a Section 24.5.
Fault tolerance is particularly important in some application domains of electronic systems, for 
example, whenever safety of people or the environment can be compromised by the occurrence of faults 
in the system. Other examples are in space or automotive applications, where transient faults like single-
event upsets (SEUs) are very prone to occur. Due to this, much research is being conducted for the char-
acterization of the effects of SEUs, particularly in SRAM-based FPGAs.
24.7  Conclusions
Although it is clear that programmable logic cannot compete with the higher performance of other 
hardware-based solutions, like ASICs, the added flexibility of FPGAs or its lower cost for low volume 
can be a primary decision factor. Also, it is a real competitor sector, with undisputed benefits, when it 
is compared with software-based approaches. In some application areas like high-end DSP processing, 
© 2011 by Taylor and Francis Group, LLC

FPGAs and Reconfigurable Systems 
24-17
the natural concurrent execution of hardware offers highest results. However, the need for many of these 
applications to adapt to time-varying high-level conditions (let us think, for instance, about a filter for a 
receiver in a communication channel with variable conditions) may make the software-based solutions 
more attractive because of its flexibility in being reprogrammed. But, when both requirements coexist, 
that is, high-performance execution and adaptability or flexibility are required together, programmable 
hardware solutions have a significant niche market.
If microprocessors have been a key player for control systems for years, and many applications 
are based on this technology due to its flexibility, FPGAs are a key piece in the reconfigurable, high-
performance world. FPGA vendors, aware of this tendency and conscious about the higher integration 
obtained because of the microelectronic technology improvements, are integrating more and more cus-
tom blocks, like memories, microprocessor cores, DSP blocks, or custom communication peripherals. 
So, a new concept is appearing, which is being well accepted by industry, that deals with integrated 
systems on a programmable chip. There are tools that try to match with this concept, capable of inte-
grating microprocessor cores with a high variety of peripherals, with reduced design efforts. There are 
also remarkable advances in debugging tools for this type of systems, which also reduce time to market. 
Nevertheless, the immature status of the tools intended to support these new paradigms is probably the 
main limiting factor for a faster evolution of hardware reconfiguration technologies.
The area of reconfigurable computing devices, which are slowly being introduced in the supercom-
puting facilities, is covered with two different approaches: either by using custom, reconfiguration-
specific devices, or commercial FPGAs. Within this last approach, dynamic and partial reconfiguration 
capabilities are being explored by research centers to offer even higher flexibility for reprogramming 
these devices, although this path has lower penetration for industry.
There are still some other areas where opportunities for improvement exist. Power consumption, or 
even more important, computing performance per energy consumed, needs to be reduced so that the 
flexibility of reprogramming does not include this penalty. Tools need to improve in both the design 
of integrated complex SoCs, as well as for run-time reconfigurable systems management. Even though 
these problems are still far from being solved, the perception of the benefits of programmable devices, as 
well as the increasing costs competitiveness, is producing a good momentum for the use of this technol-
ogy, which can be measured, for instance, in terms of new designs per year or new products adopting it.
References
Acero, J., Navarro, D., Barragan, L.A., Garde, I., Artigas, J.I., and Burdio, J.M. 2007. FPGA-based power 
measuring for induction heating appliances using sigma–delta A/D conversion. IEEE Transactions 
on Industrial Electronics 54: 1843–1852.
Al-Hashimi, B.M. (ed.) 2006. System-on-Chip: Next Generation Electronics. IET Press, London, U.K.
Becker, J., Donlin, A., and Hubner, M. 2007. New tool support and architectures in adaptive reconfigu-
rable computing. In Proceedings of the IFIP International Conference on Very Large Scale Integration 
2007, October 15–17, Atlanta, GA.
Bieser, C. and Muller-Glaser, K.D. 2005. COMPASS—A novel concept of a reconfigurable platform for 
automotive system development and test. In Proceedings of the 16th IEEE International Workshop on 
Rapid System Prototyping, June 8–10, Montreal, Canada.
Bobda, C., Majer, M., Ahmadinia, A., Haller, T., Linarth, A., and Teich, J. 2005. The Erlangen slot machine: 
Increasing flexibility in FPGA-based reconfigurable platforms. In Proceedings of the 2005 IEEE 
International Conference on Field-Programmable Technology, December 11–14, Singapore.
Chan, Y.F., Moallem, M., and Wang, W. 2007. Design and implementation of modular FPGA-based PID 
controllers. IEEE Transactions on Industrial Electronics 54: 1898–1906.
Charaabi, L., Monmasson, E., Naassani, A., and Slama-Belkhodja, I. 2005. FPGA-based implementation of 
DTSFC and DTRFC algorithms. In Proceedings of the 31st Annual Conference of the IEEE Industrial 
Electronics Society, November 6–10, Raleigh, NC.
© 2011 by Taylor and Francis Group, LLC

24-18 
Fundamentals of Industrial Electronics
Compton, K. and Hauck, S. 2002. Reconfigurable computing: A survey of systems and software. ACM 
Computing Surveys 34:171–210.
Feng, J. and Seely, J.A. 2005. Design security with waveforms. In Proceedings of the 2005 Software Defined 
Radio Technical Conference and Product Exposition, November 14–18, Orange County, CA.
Fernandez, C., Zumel, P., Sanz, M., Lazaro, A., Lopez, C., and Barrado, A. 2006. Fast prototyping of control 
circuits for power electronics, based on FPGA. In Proceedings of the 32nd Annual Conference of the 
IEEE Industrial Electronics Society, November 6–10, Paris, France.
Horta, E.L., Lockwood, J.W., Taylor, D.E., and Parlour, D. 2002. Dynamic hardware plugins in an FPGA 
with partial run-time reconfiguration. In Proceedings of the 39th Design Automation Conference, 
June 10–14, New Orleans, LA.
Ishii, E., Nishi, H., and Ohnishi, K. 2007. Improvement of performances in bilateral teleoperation by using 
FPGA. IEEE Transactions on Industrial Electronics 54: 1876–1884.
Khan, M. 2006. Power optimization in FPGA designs. In Proceedings of the Synopsys Users Group—SNUG 
San Jose, March, San Jose, CA.
Krasteva, Y.E., de la Torre, E., and Riesgo, T. 2008. Virtual architectures for partial runtime reconfigurable 
systems. Application to Network on Chip based SoC emulation. In Proceedings of the 34th Annual 
Conference of the IEEE Industrial Electronics Society, November 10–13, Orlando, FL.
Kung, Y.-S., Fung, R.-F., and Tai, T.-Y. 2009. Realization of a motion control IC for X–Y table based on 
novel FPGA technology. IEEE Transactions on Industrial Electronics 56: 43–53.
Mato, J.L., Pereira, M., Rodriguez-Andina, J.J., Farina, J., Soto, E., and Perez, R. 2008. Distortion mitigation 
in RF power amplifiers through FPGA-based amplitude and phase predistortion. IEEE Transactions 
on Industrial Electronics 55: 4085–4093.
Moller, L., Soares, R., Carvalho, E., Grehs, I., Calazans, N., and Moraes, F. 2006. Infrastructure for dynamic 
reconfigurable systems: choices and trade-offs. In Proceedings of the 19th Annual Symposium on 
Integrated Circuits and Systems Design, August 28–September 1, Ouro Preto, Brazil.
Omar, A.M., Rahim, N.A., and Mekhilef, S. 2004. Three-phase synchronous PWM for flyback converter with 
power-factor correction using FPGA ASIC design. IEEE Transactions on Industrial Electronics 51: 96–106.
Palma, J.C., de Mello, A.V., Moller, L., Moraes, F., and Calazans, N. 2002. Core communication interface 
for FPGAs. In Proceedings of the 15th Annual Symposium on Integrated Circuits and Systems Design, 
September 9–14, Porto Alegre, Brazil.
Pionteck, T., Koch, R., and Albrecht, C. 2006. Applying partial reconfiguration to Networks-on-Chips. 
In Proceedings of the 16th International Conference on Field-Programmable Logic and Applications, 
August 28–30, Madrid, Spain.
Rodriguez-Andina, J.J., Moure, M.J., and Valdes, M.D. 2007. Features, design tools, and application 
domains of FPGAs. IEEE Transactions on Industrial Electronics 54: 1810–1823.
Salcic, Z., Cao, J., and Nguang, S.K.. 2006. A floating-point FPGA-based self-tuning regulator. IEEE 
Transactions on Industrial Electronics 53: 693–704.
Sridharan, K. and Priya, T.K. 2007. A hardware accelerator and FPGA realization for reduced visibility 
graph construction using efficient bit representation. IEEE Transactions on Industrial Electronics 54: 
1800–1804.
Ullmann, M., Hubner, M., Grimm, B., and Becker, J. 2004. An FPGA run-time system for dynamical on-
demand reconfiguration. In Proceedings of the 18th International Parallel and Distributed Processing 
Symposium, April 26–30, Santa Fe, NM.
Walder, H. and Platzner, M. 2004. A runtime environment for reconfigurable hardware operating systems. 
In Proceedings of the 14th International Conference on Field-Programmable Logic and Applications, 
August 30–September 1, Leuven, Belgium.
Wen, Z., Chen, W., Xu, Z., and Wang, J. 2006. Analysis of two-phase stepper motor driver based on FPGA. 
In Proceedings of the 2006 IEEE International Conference on Industrial Informatics, August 16–18, 
Singapore.
Xilinx Staff. 2004. Celebrating 20 years of innovation. Xcell Journal 48: 14–16.
© 2011 by Taylor and Francis Group, LLC

25-1
25
Signal Processing
25.1	 Introduction.....................................................................................25-2
25.2	 Continuous-Time Signals...............................................................25-2
Common Signals  •  Periodic Signals
25.3	 Time-Domain Analysis of Continuous-Time Signals...............25-4
Basic Operations on Signals  •  Convolution
25.4	 Frequency-Domain Analysis of Continuous-Time Signals......25-5
Fourier Series  •  Fourier Transforms  •  Laplace Transforms
25.5	 Continuous-Time Signal Processors...........................................25-12
25.6	 Time-Domain Analysis of Continuous-Time Signal 
Processors............................................................................... 25-13
25.7	 Frequency-Domain Analysis of Continuous-Time Signal 
Processors.......................................................................................25-14
25.8	 Continuous-Time (Analog) Filters.............................................25-15
Common Filter Types  •  Filter Design
25.9	 Sampling.........................................................................................25-18
25.10	 Discrete-Time Signals...................................................................25-19
Common Signals  •  Periodic Signals  •  Finite-Duration Signals
25.11	 Time-Domain Analysis of Discrete-Time Signals....................25-21
Basic Operations on Signals  •  Convolution  •  Periodic Convolution
25.12	 Frequency-Domain Analysis of Discrete-Time Signals...........25-22
Discrete Fourier Series  •  Discrete Fourier Transforms  • 
Fast Fourier Transforms  •  Discrete-Time Fourier 
Transforms  •  z-Transforms
25.13	 Discrete-Time Signal Processors.................................................25-31
25.14	Time-Domain Analysis of Discrete-Time Signal 
Processors...................................................................................25-31
25.15	 Frequency-Domain Analysis of Discrete-Time Signal 
Processors.......................................................................................25-32
25.16	 Discrete-Time (Digital) Filters.....................................................25-34
Common Filter Types  •  FIR Filter Design  •  IIR Filter Design
25.17	 Discrete-Time Analysis of Continuous-Time Signals..............25-38
25.18	 Discrete-Time Processing of Continuous-Time Signals..........25-39
References.................................................................................................. 25-40
James A. Heinen
Marquette University
Russell J. 
Niederjohn
Marquette University
© 2011 by Taylor and Francis Group, LLC

25-2 
Fundamentals of Industrial Electronics
25.1  Introduction
Signal processing is a very broad field. Examples include filtering of electrical signals to remove 60 Hz 
interference, equalization of audio signals, processing of electrocardiograms to determine features 
of the heartbeat, enhancement of noisy speech signals to improve intelligibility, and enhancement of 
images to emphasize edges.
A signal is a function of one or more independent variables (usually time in the case of one-dimensional 
signals). Only real-valued, one-dimensional signals will be considered here. This rules out, e.g., images, 
which are two dimensional. Furthermore, only deterministic signals will be considered, ruling out 
random signals, which may be described only in a probabilistic sense. Both continuous-time (“analog”) 
and discrete-time (“digital”) signals will be described, as will the sampling (analog-to-digital conver-
sion) process. These signals will be studied directly in the time domain and indirectly in the frequency 
(transform) domain. Both continuous-time and discrete-time systems (“signal processors”) will be 
discussed as well.
Because of the vast amount of information available on signal processing, only that deemed most fun-
damental will be discussed here. Several excellent texts on signal processing (Ambardar, 2007; Baher, 
2001; Ingle and Proakis, 2007; Kuo and Gan, 2005; McClellan et al., 2003; Mitra, 2006; Oppenheim and 
Schafer, 1989, 2010; Proakis and Manolakis, 2007; Stearns, 2003), linear systems (Chen, 2004; ElAli, 
2004; Gajić, 2003; Lathi, 2005; Sherrick, 2005), and filters (Antoniou, 1993; Lam, 1979; Paarmann, 2001; 
Schlichthärle, 2000) are listed in the references at the end of this discussion.
25.2  Continuous-Time Signals
Continuous-time signals are functions of the form x(t), −∞ < t < ∞, where t is an independent variable, 
normally time. Only physically meaningful signals, or those reasonably approximated as such, will be 
considered in this discussion. Signals with infinite discontinuities will not be allowed. Also disallowed 
will be signals with an infinite number of finite discontinuities and/or maxima and minima in a finite 
time range. Impulses (defined below) and signals with finite discontinuities will be considered, even 
though they are not physically meaningful.
25.2.1  Common Signals
Some continuous-time signals often encountered in practice, and/or which may be easily described 
mathematically, are described below and illustrated in Figure 25.1.
The unit step is the signal:
	
u t
t
t
( )
,
,
.
=
≥
<



1
0
0
0
Its integral is the unit ramp:
	
r t
t
t
t
u
d
t
( )
,
,
( )
.
=
≥
<






=
−∞∫
0
0
0
τ
τ
The derivative (appropriately defined) of the unit step is the unit impulse:
	
δ( )
,
,
( ).
t
t
t
du t
dt
= ∞
=
≠






=
0
0
0
© 2011 by Taylor and Francis Group, LLC

Signal Processing 
25-3
To completely define the unit impulse, it is necessary to impose the condition that
	
δ( )
.
t dt =
−∞
∞
∫
1
This leads to the so-called “sampling property” of the impulse, namely,
	
x t
t
t dt
x t
o
o
( ) (
)
(
δ
−
=
−∞
∞
∫
),
provided that x(t) is continuous at to.
Sinusoids may be written in the form
	
x t
A
t
( )
cos(
),
=
+
ω
θ
where
A is the amplitude
ω = 2πf is the angular frequency (f being the frequency)
θ is the phase
1.5
1
0.5
0
–0.5 –2 –1
0
1
2
3
(a)
Amplitude
4
5
6
7
8
Time
9
8
7
6
5
4
3
2
1
0
–1
Time
(c)
Amplitude
–2 –1
0
1
2
3
4
5
6
7
8
1.5
1
0.5
Amplitude
0
–0.5
–2 –1
0
1
2
3
Time
(b)
4
5
6
7
8
2.5
–2.5
–2
–1.5
–1
–0.5
0
0.5
1
1.5
2
Time
(d)
–2 –1
0
1
2
3
4
5
6
7
8
Amplitude
FIGURE 25.1  Illustration of four common continuous-time signals: (a) δ(t), (b) u(t), (c) r(t), and (d) 2cos(2πt + π/4).
© 2011 by Taylor and Francis Group, LLC

25-4 
Fundamentals of Industrial Electronics
A very general signal that is important physically is
	
x t
At e
t
u t
p
at
( )
cos(
) ( ),
=
+
−
ω
θ
where p ≥ 0. This signal includes steps, ramps, sinusoids, and damped sinusoids as special cases.
25.2.2  Periodic Signals
Periodic continuous-time signals are those satisfying the condition
	
x t
T
x t
t
(
)
( ),
,
+
=
−∞< < ∞
for some fixed T > 0. It is noted that if this condition is satisfied for a given T, it is also satisfied for all 
integer multiples of T. The smallest T for which it is satisfied is called the period. The frequency of a 
periodic signal with period T is given by f = 1/T. Its angular frequency is ω = 2πf = 2π/T. Normally, T is 
specified in units of seconds, ω in radians/second, and f in Hertz. Sinusoids are simple but fundamental 
examples of periodic signals. Signals that are not periodic are said to be aperiodic.
25.3  Time-Domain Analysis of Continuous-Time Signals
25.3.1  Basic Operations on Signals
Various mathematical operations may be performed on a signal or a combination of signals. Obvious 
ones include differentiating or integrating a signal, and combining two or more signals using addition, 
subtraction, multiplication, or division. Other operations are also important in the context of signal 
analysis. Amplitude scaling a signal x(t) produces a modified signal
	
y t
Ax t
( )
( ),
=
where A ≠ 0 is a constant. Time shifting produces
	
y t
x t
to
( )
,
=
−
(
)
where to is fixed. Time reversal results in
	
y t
x
t
( )
(
),
=
−
and time scaling leads to
	
y t
x at
( )
(
),
=
where a > 0 is a constant.
25.3.2  Convolution
As will be seen later, a very important operation used to combine two continuous-time signals is convo-
lution. The convolution of the signals x1(t) and x2(t) is defined as
	
y t
x t
x t
x
x t
d
t
( )
( )*
( )
( )
(
)
,
.
=
=
−
−∞< < ∞
−∞
∞
∫
1
2
1
2
 
τ
τ
τ
© 2011 by Taylor and Francis Group, LLC

Signal Processing 
25-5
This involves the time reversal and time shifting of the signal x2(τ) to produce x2(t − τ). (It is noted that 
unless interpreted carefully, the notation y(t) = x1(t) * x2(t) can lead to confusion. For instance, y(t − to) = 
x1(t) * x2(t − to), not x1(t − to) * x2(t − to), as might be expected.
A positive-time signal is one satisfying the condition
	
x t
t
( )
,
.
=
<
0
0
Steps and ramps are clearly examples of positive-time signals. If the signals x1(t) and x2(t) are positive 
time, their convolution is also positive time and may be simplified to the form
	
y t
x t
x t
x
x t
d
t
t
t
( )
( ) *
( )
( )
(
)
,
,
.
=
=
−
≥
<


∫
1
2
1
2
0
0
0
0
τ
τ
τ
25.4  Frequency-Domain Analysis of Continuous-Time Signals
It is often both convenient and informative to study continuous-time signals in the frequency (or trans-
form) domain. The original signal is transformed by some appropriate mathematical operation to result 
in a frequency-domain quantity (often complex valued in nature). This frequency-domain quantity 
allows for the interpretation of the signal in terms of the basic constituent components of various fre-
quencies. The particular frequency-domain representation used will, at least in part, depend on the 
characteristics of the signal being studied.
25.4.1  Fourier Series
Suppose x(t) is a periodic signal with period To and angular frequency ωo = 2π/To. Then x(t) may be con-
sidered as consisting of a (possibly infinite) linear combination of sinusoids with angular frequencies at 
integer multiples of ωo. Specifically
	
x t
a
a
k
t
b
k
t
o
k
o
k
o
k
( )
(
cos(
)
sin(
)).
=
+
+
=
∞
∑
ω
ω
1
Written this way, x(t) is called a (trigonometric) Fourier series with coefficients, ao, ak, bk, k = 1, 2, …. 
These coefficients may be calculated from the original signal using the formulas
	
a
T
x t dt
o
o
To
= ∫
1
0
( )
,
	
a
T
x t
k
t dt
k
k
o
o
To
=
=
…
∫
2
1 2
0
 
( )cos(
)
,
, ,
,
ω
	
b
T
x t
k
t dt
k
k
o
o
To
=
=
…
∫
2
1 2
0
( )sin(
)
,
, ,
.
ω
© 2011 by Taylor and Francis Group, LLC

25-6 
Fundamentals of Industrial Electronics
It is noted that, because the integrands are periodic, these integrals may be calculated over any range 
of t values of length To, e.g., −To/2 to To/2. It is also noted that ao is the average (or “dc”) value of the signal 
x(t), as may be seen from its definition. The kth term in the series is referred to as the kth harmonic, with 
the first harmonic also called the fundamental.
If x(t) is an even signal (i.e., one satisfying x(−t) = x(t), −∞ < t < ∞), then bk = 0, k = 1, 2, …. On the 
other hand, if x(t) is an odd signal (i.e., one satisfying x(−t) = −x(t), −∞ < t < ∞), then ak = 0, k = 0, 1, 2, …. 
Thus, an even signal consists only of cosine components (the cosine is even) and an odd signal consists 
only of sine components (the sine is odd).
Using trigonometric identities, the trigonometric Fourier series may be rewritten as an exponential 
(or complex) Fourier series. This takes the form, using j to represent −1,
	
x t
X e
k
jk
t
k
o
( )
,
=
=−∞
∞
∑
ω
where
	
X
T
x t e
dt
k
k
o
jk
t
T
o
o
=
= … −
…
−
∫
1
1 0 1 2
0
( )
,
,
, , , ,
.
ω
It is observed that Xk is complex-valued. The coefficients of these two Fourier series representations are 
related by the formulas
	
a
X
o
o
=
,
	
a
Re X
k
k
k
=
=
2
1 2
{
},
, ,
,
…
	
b
Im X
k
k
k
= −
=
2
1 2
{
},
, ,
..
…
While it is not always expressed this way, it is instructive to think of Xk and x(t) as forming a trans-
form pair, i.e., a representation in which Xk is uniquely determined by x(t) and vice versa. Thus,
	
X
FS x t
k =
{
}
( )
and
	
x t
FS
Xk
( )
.
=
{
}
−1
In this context, it is clear that Xk and x(t) contain exactly the same information, but in a different form.
As an example, consider the signal x(t), which is assumed to be periodic with period To, and which is 
defined over one period by
	
x t
t
T
T
t
T
o
o
o
( )
,
,
.
=
≤<
≤<






1
0
2
0
2
 
Using the defining relation, it is easily determined that the exponential Fourier series coefficients are
	
X
X
j
k
k
o
k
k
=
=
−
−
≠
1
2
1
1
2
0
;
(
)
,
.
π
© 2011 by Taylor and Francis Group, LLC

Signal Processing 
25-7
The trigonometric Fourier series coefficients are likewise easily found to be
	
a
a
k
b
k
k
o
k
k
k
=
=
>
=
−−
>
1
2
0
0
1
1
0
;
,
(
) ,
.
π
Being complex valued, Xk may be written as
	
X
X
X e
k
k
k
k
j
k
=
∠
=
ϕ
ϕ ,
where φk = arg{Xk}. Under our assumption that x(t) is real-valued, |Xk| is an even function of k and φk is 
an odd function of k, i.e., respectively,
	
X
X
k
k
k
k
−
−
=
= −
,
.
ϕ
ϕ
Thus, the information contained in Xk, k < 0 is redundant. When plotted versus k (the frequency index), 
|Xk| is called the magnitude spectrum and φk the phase spectrum of x(t), illustrated in Figure 25.2 for 
the example under consideration. These spectra aid in visualizing the frequency-domain characteristics 
of the periodic signal under consideration.
1.5
1
0.5
Amplitude
0
–0.5
–2
–1
0
1
Time
2
3
4
(a)
Magnitude
–0.1
0.3
0.2
0.1
0
0.4
0.5
Frequency index
–10 –8 –6 –4 –2
0
2
4
6
8
10
(b)
2.5
2
1.5
1
0.5
0
Phase
–0.5
–1
–1.5
–2
–2.5
–10 –8 –6 –4 –2
0
2
4
6
8
10
Frequency index
(c)
FIGURE 25.2  Illustration of (a) a periodic signal (To = 2), and (b) its magnitude spectrum and (c) phase spectrum.
© 2011 by Taylor and Francis Group, LLC

25-8 
Fundamentals of Industrial Electronics
Some important properties of the exponential Fourier series are summarized in the following table.
Periodic Signals
Fourier Series Coefficients
Ax1(t) + Bx2(t)
AX1,k + BX2,k
x(t − to)
X e
k
jk
t
o o
−
ω
x(− t)
X−k
x(at)+, a > 0
Xk
dx t
dt
( )
jkωoXk
x(t), x1(t), x2(t) are arbitrary periodic signals with period 
To and angular frequency ωo, and with Fourier series coeffi-
cients Xk, X1,k, X2,k, respectively. A, B, a, to are arbitrary 
constants.
Note that x(at) has period To/a and angular frequency aωo.
The Fourier series of a signal having finite discontinuities will necessarily contain an infinite num-
ber of terms. It is often necessary to approximate such a Fourier series by a truncated series containing 
only a finite number of terms. Of course, this truncation may take place at any point in the series. 
Fortunately, including an additional term will never increase the mean-squared error between the 
truncated series and the true signal. On the other hand, it is very difficult for a Fourier series to repre-
sent a discontinuity. Regardless of the number of terms included, the truncated Fourier series exhibits 
oscillations near each discontinuity. As additional terms are included, these oscillations move closer 
to the discontinuity, but they never disappear. The existence of these oscillations is known as Gibb’s 
phenomenon.
25.4.2  Fourier Transforms
Fourier series are useful only for analyzing periodic signals. In addition to periodic signals, certain 
aperiodic signals may be studied using the Fourier transform. This representation may loosely be con-
sidered as arising from the Fourier series representation when the fundamental period is allowed to 
approach infinity.
A continuous-time signal x(t) will have a Fourier transform if it is absolutely integrable, i.e., if
	
x t dt
( )
.
< ∞
−∞
∞
∫
With proper interpretation, certain signals not satisfying this condition will also have Fourier trans-
forms. These include steps, constants, and all periodic signals.
The Fourier transform of x(t) is defined as
	
X j
FT x t
x t e
dt
j t
(
)
{ ( )}
( )
,
.
ω
ω
=
=
−∞<
< ∞
−
−∞
∞
∫
ω
x(t) may be recovered uniquely from X(jω) using the inverse Fourier transform given by
	
x t
FT
X j
X j
e
d
j t
( )
(
)
(
)
.
=
{
} =
−
∞
∞
∫
1
1
2
ω
ω
ω
ω
π  
© 2011 by Taylor and Francis Group, LLC

Signal Processing 
25-9
Note that while X(jω) is considered as a function of ω, for convenience it is often written, as we have 
done, as a function of jω. While periodic signals have all their energy concentrated at only certain values 
of frequency (multiples of the fundamental frequency), other signals allowed by the Fourier transform 
have their energy spread out over, in general, all frequencies. Some common Fourier transforms are 
listed in the following table:
x(t)
X(jω)
δ(t)
1
1
2πδ(ω)
u(t)
πδ ω
ω
( ) + 1
j
e−atu(t),  a > 0
1
a
j
+ ω
te−atu(t),  a > 0
1
2
(
)
a
j
+ ω
sin(ωot)
jπ[δ(ω + ωo) − δ(ω − ωo)]
cos(ωot)
π[δ(ω + ωo) + δ(ω − ωo)]
As is true for the exponential Fourier series coefficients Xk, the Fourier transform X( jω) is, in general, 
complex-valued, i.e.,
	
X j
X j
j
X j
e
j
j
(
)
(
)
(
)
(
)
,
(
)
ω
ω
ω
ω
ω
=
∠
=
ϕ
ϕ
where φ(jω) = arg{X(jω)}. For our assumed real-valued x(t), |X(jω)| is an even function of ω and φ(jω) 
is an odd function of ω, i.e., respectively
	
| (
)|
| (
)|,
(
)
(
).
X
j
X j
j
j
−
=
−
= −
ω
ω
ϕ
ω
ϕ ω
Thus, the information contained in X(jω), ω < 0, is redundant. When plotted versus ω, |X(jω)| is 
called the magnitude spectrum and φ(jω) the phase spectrum of x(t). An example is shown in Figure 
25.3. While the spectra based on the Fourier series exist only at integer values of the frequency index k, 
the Fourier transform spectra exist, in general, at all frequencies.
Signals not satisfying the absolute integrability condition stated above, will, if they are Fourier 
transformable, normally contain frequency-domain impulses in their Fourier transforms. As a spe-
cific case, if x(t) is a periodic signal with fundamental angular frequency ωo and with Fourier series 
Xk = FS{x(t)}, then its Fourier transform is given by
	
X j
X
k
k
o
k
(
)
(
),
ω
δ ω
ω
=
−
=−∞
∞
∑
with all energy clearly still concentrated (now, mathematically, by means of impulse functions) at inte-
ger multiples of ωo.
© 2011 by Taylor and Francis Group, LLC

25-10 
Fundamentals of Industrial Electronics
Some important properties of the Fourier transform are summarized in the following table:
Signals
Fourier Transforms
Ax1(t) + Bx2(t)
AX1(jω) + BX2(jω)
x(t − to)
X j
e
j to
(
)
ω
ω
−
x(−t)
X(−jω)
x(at),  a > 0
1
a X
j a
ω




dx t
dt
( )
jωX(jω)
x
d
t
( )τ
−∫
∝
τ
X j
j
X
(
)
( ) ( )
ω
ω
π
δ ω
+
0
x1(t) * x2(t)
X1(jω)X2(jω)
x(t), x1(t), x2(t) are arbitrary signals with 
Fourier transforms X(jω), X1(jω), X2(jω), 
respectively. A, B, a, to are arbitrary constants.
2
1
0
0
2
4
Time
(a)
Amplitude
6
8
2.5
2
1.5
1
0.5
0
–0.5
–6
–4
–2
0
2
4
6
Frequency
(b)
Magnitude
–6
–4
–2
0
2
4
6
Frequency
2.5
2
1.5
1
0.5
0
–0.5
–1
–1.5
–2
–2.5
(c)
Phase
FIGURE 25.3  Illustration of (a) a signal (x(t) = 2e−0.5tu(t)), and (b) its magnitude spectrum and (c) phase spectrum.
© 2011 by Taylor and Francis Group, LLC

Signal Processing 
25-11
25.4.3  Laplace Transforms
As seen above, the Fourier transform is a generalization of the Fourier series, in that it allows for the 
analysis of a broader range of continuous-time signals than does the Fourier series. The (single-sided) 
Laplace transform is likewise a generalization of the Fourier transform, but with the restriction that the 
signal must be positive time, i.e., zero for t < 0.
A positive-time signal x(t) will have a Laplace transform if
	
x t e
dt
t
( )
−
−
∞
< ∞
∫
σ
0
for some real σ. (The notation 0− is used to indicate that the lower limit of the integral is taken “just to the 
left of 0.” In practice, this means that impulses at t = 0 are to be included entirely in the integral.) Since 
σ = 0 is allowed in this condition, if x(t) is a positive-time signal with a Fourier transform, it will also have 
a Laplace transform, but the converse is not true. For example, a unit ramp has a Laplace transform but not 
a Fourier transform. On the other hand, nontrivial periodic signals and constants (which are necessarily 
nonzero for t < 0) do not have Laplace transforms even though they have Fourier transforms.
The Laplace transform of the positive-time signal x(t) is defined as
	
X s
LT x t
x t e
dt
st
( )
{ ( )}
( )
=
=
−
−
∞
∫
0
 ,
where s = σ + jω is a complex variable. In general, this integral will converge only for certain choices of σ. 
x(t) may be recovered uniquely from X(s) using the inverse Laplace transform given by
	
x t
LT
X s
j
X s e ds
st
j
j
( )
{ ( )}
( )
=
=
−
−∞
+ ∞
∫
1
1
2
1
1
π
σ
σ
 ,
where σ1 is appropriately chosen. (This formula is rarely directly used in practice because of its complexity. 
Instead, tables of Laplace transform pairs are used, with complicated transforms first being decomposed 
into simpler ones using partial fraction expansion techniques.) Some common Laplace transforms are 
listed in following table:
x(t)
X(s)
δ(t)
1
u(t)
1
0
s
Re s
,
{ } >
e−atu(t)
1
s
a
Re s
a
+
> −
,
{ }
te−atu(t)
1
2
(
) ,
{ }
s
a
Re s
a
+
> −
sin(ωot)u(t)
ω
ω
o
o
s
Re s
2
2
0
+
>
,
{ }
cos(ωot)u(t)
s
s
Re s
o
2
2
0
+
>
ω ,
{ }
© 2011 by Taylor and Francis Group, LLC

25-12 
Fundamentals of Industrial Electronics
For a positive-time signal x(t) having a Fourier transform X(jω), it is the case that
	
FT x t
LT x t
( )
( ) |
{
} =
{
}
=
σ 0
or
	
X j
X s
s
j
(
)
( )|
,
ω
ω
=
=
where X(s) is the Laplace transform of x(t). (This explains our choice of notation for the Fourier trans-
form.) Thus, in this case, the Fourier transform is simply the Laplace transform evaluated on the jω 
(imaginary) axis in the s (complex) plane.
Some important properties of the Laplace transform are summarized in the following table:
Signals
Laplace Transforms
Ax1(t) + Bx2(t)
AX1(s) + BX2(s)
x(t − to),  to ≥ 0
X s e sto
( ) −
x(at), a > 0
1
a X
s
a




dx t
dt
( )
sX(s) − x(0 −)
x
d
t
( )τ
τ
−∞∫
X s
s
( )
x1(t) * x2(t)
X1(s)X2(s)
x(t), x1(t), x2(t) are arbitrary signals with 
Laplace transforms X(s), X1(s), X2(s), respec-
tively. A, B, a, to are arbitrary constants.
25.5  Continuous-Time Signal Processors
A continuous-time signal processor (system) is a device (see Figure 25.4) that acts on an input signal 
x(t), modifying it in some manner to produce an output signal y(t). This may be represented abstractly as
	
y t
x t
( )
{ ( )}.
= H
(Here, x(t) and y(t) should be thought of in their totality, rather than at specific instants t. Just as in the 
case of convolution, this notation can lead to confusion. It does not imply that y(t) is a function of x(t) at 
only the same instant t. y(t) could, e.g., depend on all past values of x(τ), τ ≤ t.)
This abstract definition is very broad. In practice, because 
of mathematical tractability, only certain relatively simple 
classes of signal processors are considered. In this treatment, 
we will discuss only those continuous-time signal processors 
that can be described by linear constant-coefficient ordinary 
differential equations. Such signal processors are of neces-
sity linear, time-invariant, and casual. (In the familiar case of 
x(t)
y(t)
{  }
FIGURE 25.4  Continuous-time sig-
nal processing system.
© 2011 by Taylor and Francis Group, LLC

Signal Processing 
25-13
electrical circuits, they can be built using resistors, capacitors, inductors, and operational ampli-
fiers.) A ­system is linear if
	
H
H
H
{
( )
( )}
{ ( )}
{
( )},
Ax t
Bx t
A
x t
B
x t
t
1
2
1
2
+
=
+
−∞< < ∞
for all signals x1(t), x2(t), and all constants A, B. It is time-invariant if
	
y t
t
x t
t
t
o
o
(
)
{ (
)},
,
−
=
−
−∞< < ∞
H
for all input signals x(t) and corresponding output signals y(t) and all constants to. A system is casual if 
H{x(t)} depends only on x(τ), τ ≤ t for all signals x(t).
25.6  Time-Domain Analysis of Continuous-Time 
Signal Processors
Under our assumptions, a continuous-time signal processor may be represented by a linear constant-
coefficient ordinary differential equation. That is,
	
a d y t
dt
b d x t
dt
r
r
r
r
N
r
r
r
r
M
( )
( ).
=
=
∑
∑
=
0
0
Ordinarily, M ≤ N and, often, this equation is normalized so that aN = 1. This describes an implicit 
relationship between the input x(t) and output y(t). In specific cases, for a known input x(t) and initial 
conditions on y(t) and its derivatives at t = 0, it may be solved for x(t), t ≥ 0. Laplace transforms may be 
used for this purpose, as may other techniques.
An alternative means for describing our signal processor, in the form of an explicit relationship 
between input and output, is based on the use of its impulse response. The impulse response is defined as
	
h t
t
( )
{ ( )},
= H δ
i.e., the output when the input is a unit impulse. Since we have assumed causality, it may be shown 
that h(t) is a positive-time signal, i.e., that h(t) = 0, t < 0. Because the signal processor is linear and time 
invariant, it may additionally be shown that for any input x(t) the corresponding output is given by the 
convolution of h(t) and x(t), namely,
	
y t
x t
h t
x t
( )
{ ( )}
( )* ( ).
=
=
H
This is a very significant result, since it shows that all information regarding the signal processor 
(at least from an input–output viewpoint) is contained in its impulse response.
A very desirable property of signal processors is stability. A system is said to be (bounded-input 
bounded-output) stable if whenever x(t) is bounded (i.e., |x(t)| ≤ Kx < ∞, −∞ < t < ∞ for some Kx) then the 
corresponding y(t) is also bounded (i.e., |y(t)| ≤ Ky < ∞, −∞ < t < ∞ for some Ky). (The alternative would 
normally be undesirable.) It is possible to easily determine stability directly from h(t). Specifically, the 
signal processor is stable if and only if h(t) is absolutely integrable, i.e., if and only if
	
h t dt
( )
.
< ∞
−∞
∞
∫
© 2011 by Taylor and Francis Group, LLC

25-14 
Fundamentals of Industrial Electronics
25.7  Frequency-Domain Analysis 
of Continuous-Time Signal Processors
In the frequency (transform) domain, a signal processor is characterized by its transfer function H(s). 
H(s) may be determined by Laplace transforming the convolution relationship to obtain
	
Y s
H s X s
( )
( ) ( ),
=
where
	
H s
LT h t
( )
( ) .
=
{
}
Thus, the transfer function is the Laplace transform of the impulse response, well defined since h(t) 
is a positive-time signal.
Alternatively, the input–output differential equation may be Laplace transformed (assuming zero ini-
tial conditions) to obtain
	
a s Y s
b s X s
r
r
r
N
r
r
r
M
( )
( ),
=
=
∑
∑
=
0
0
from which
	
H s
b s
a s
r
r
r
M
r
r
r
N
( )
.
=
=
=
∑
∑
0
0
Thus, H(s) is a rational function (ratio of polynomials) in s. The impulse response h(t), being the 
inverse Laplace transform of a rational function, will necessarily consist only of terms of the form
	
At e
t
u t
p
t
−
+
a cos(
) ( ),
ω
θ
where p ≥ 0.
The roots of the numerator polynomial are called the zeros of H(s) and the roots of the denominator poly-
nomial are called the poles of H(s). It may be shown that a signal processor is stable if and only if M ≤ N 
and all poles lie strictly in the left half of the complex s plane (i.e., have strictly negative real parts).
Fourier transforming the convolution relationship leads to
	
Y j
H j
X j
(
)
(
) (
),
ω
ω
ω
=
where
	
H j
FT h t
(
)
( ) .
ω =
{
}
H(jω) is called the frequency response of the signal processor, and is the Fourier transform of the impulse 
response. The magnitude of H(jω) is the magnitude response and its angle is the phase response. It is 
seen that
	
H j
H s
s
j
(
)
( )
ω
ω
=
=
,
© 2011 by Taylor and Francis Group, LLC

Signal Processing 
25-15
where H(s) is the transfer function. That is, the frequency response is the transfer function evaluated on 
the jω (imaginary) axis in the complex s plane. Thus, we may also write
	
H j
b j
a j
r
r
r
M
r
r
r
N
(
)
(
)
(
)
.
ω
ω
ω
=
=
=
∑
∑
0
0
The frequency response of a signal processor is also useful for determining its output in the case of a 
periodic input. If x(t) is a periodic input signal with Fourier series coefficients Xk, then the output signal 
y(t) will also be periodic (with the same fundamental angular frequency ωo) and will have Fourier series 
coefficients given by
	
Y
H jk
X
k
o
k
=
(
)
.
ω
This relationship may also be used for the steady-state analysis of systems, i.e., systems that have been 
operating for a sufficiently long time that all transient terms may be neglected.
It is thus clear that the way a signal processor processes an input signal (either aperiodic or periodic) 
is determined by its frequency response. It is thus very informative to have this quantity available, par-
ticularly in visual form as embodied in its magnitude and phase spectra.
25.8  Continuous-Time (Analog) Filters
A continuous-time (analog) filter is a signal processor designed to allow input signal components of 
certain frequencies to pass through to the output while preventing input signal components of other 
frequencies from doing so. Ideally, the frequency response H(jω) of a filter should have magnitude one 
at those frequencies we wish to allow to pass through to the output and magnitude zero at those frequen-
cies disallowed.
25.8.1  Common Filter Types
The most common types of filters are lowpass, highpass, bandpass, and bandstop. In the ideal case, these 
are described, respectively, by the following relationships (see Figure 25.5):
	
H
j
lp
c
(
)
,
,
,
ω
ω
ω
=
≤



1
0
otherwise
	
H
j
hp
c
(
)
,
,
,
ω
ω
ω
=
<



0
1
otherwise
	
H
j
bp
l
u
(
)
,
,
,
ω
ω
ω
ω
=
≤
≤



1
0
otherwise
	
H
j
bs
l
u
(
)
,
,
.
ω
ω
ω
ω
=
<
<



0
1
otherwise
© 2011 by Taylor and Francis Group, LLC

25-16 
Fundamentals of Industrial Electronics
The values ωc, ωl, and ωu are the cutoff frequencies. Those ranges of frequencies for which the fre-
quency response is 1 are the passbands, and those for which it is 0 are the stopbands. The bandwidth is 
defined as ωc for a lowpass filter and ωu − ωl for a bandpass filter.
Unfortunately, ideal filters are noncausal and are thus not physically realizable. They may, however, 
be quite closely approximated in practice. In the nonideal (practical) case, the frequency response values 
are not identically 1 in the passbands and not identically 0 in the stopbands. Furthermore, the response 
does not abruptly change from 1 to 0 between passbands and stopbands. Instead, it gradually changes 
in transition bands, which separate the passbands and stopbands. While cutoff frequencies are uniquely 
defined for ideal filters, in the case of practical filters, any frequency within a transition band may appro-
priately be called a cutoff frequency. Often, those frequencies at which the magnitude response is 1
2
/
 
(approximately −3 dB) are chosen as the cutoff frequencies.
In many instances, the phase response of a filter is of little consequence. In certain applications, however, 
it is required that the phase response be linear, i.e., that the phase be linearly related to frequency in the 
passbands. Again, this may only be approximated in practice. Linear phase ensures that the shape of a signal 
within the passband of a filter, rather than simply its frequency content, is preserved in the filtering process.
25.8.2  Filter Design
The design of a filter normally begins by specifying the locations of the passbands and stopbands, the 
allowable variations from the ideal values in these bands (tolerances), and the locations and widths of 
1.5
1
0.5
Magnitude
0
–0.5 –2
–1.5
–1
–0.5
Frequency
(a)
0
0.5
1
1.5
2
Magnitude
–0.5
0
1
0.5
1.5
Frequency
(b)
–2
–1
0
1
2
1.5
1
0.5
Magnitude
0
–0.5
(c)
1.5
1
0.5
Magnitude
0
–0.5
(d)
–2
–1.5
–1
–0.5
Frequency
0
0.5
1
1.5
2
–2
–1.5
–1
–0.5
Frequency
0
0.5
1
1.5
2
FIGURE 25.5  Illustration of four ideal filter types: (a) lowpass filter, (b) highpass filter, (c) bandpass filter, and 
(d) bandstop filter.
© 2011 by Taylor and Francis Group, LLC

Signal Processing 
25-17
the transition bands. Generally, the tighter the tolerances and the narrower the transition bands, the 
higher the filter order will have to be to meet the specifications. Normally, our goal will be to meet the 
specifications with the lowest-order filter possible.
Despite the type of filter desired, an appropriate prototype lowpass filter Hp(s), with a cutoff 
frequency of one, is often designed first. Design formulas exist for translating the original specifi-
cations to the prototype filter. Various standard lowpass prototypes are available. The simplest of 
these is perhaps the Butterworth filter. The transfer function of an Nth-order Butterworth filter is 
given by
	
H
s
B
s
B
N
N ( )
( )
=
1
,
where BN(s) is a Butterworth polynomial. The following table lists expressions for the first four of these:
N
BN(s)
1
s + 1
2
s2 + 1.414s + 1
3
s3 + 2s2 + 2s + 1
4
s4 + 2.613s3 + 3.414s2 + 2.613s + 1
The poles of H
s
BN( ) are evenly spaced on the unit circle in the left half of the complex plane. The 
magnitude response of a Butterworth filter monotonically decreases from one to zero and has a value 
of 1
2
3
1
/
dB at
(
)
−
=
ω
. Figure 25.6 shows the magnitude and phase responses of a typical lowpass 
Butterworth filter.
Chebyshev filters are equiripple in the passband (i.e., their magnitude response oscillates between 
certain tolerance limits) and monotonic in the stopband. These characteristics are interchanged in the 
case of inverse Chebyshev filters. Elliptic (Cauer) filters are equiripple in both the passband and the 
stopband. Bessel filters achieve very nearly linear phase in the passband. In each case, various design 
formulas exist for choosing the appropriate filter order and other filter parameters.
Once the prototype lowpass filter Hp(s) (with cutoff frequency of one) is determined, an appropriate 
frequency transformation is employed to result in the final filter design H(s) as follows:
	
H s
H
s
p
s T s
( )
( )
.
( )
=
=
1
0.8
0.6
0.4
0.2
0
–0.5
0
0.5
1
1.5
2
Frequency
2.5
3
3.5
Magnitude
–4
–3
–2
–1
0
1
2
3
4
–0.5
0
0.5
1
1.5
2
Frequency
2.5
3
3.5
Phase
FIGURE 25.6  Third-order Butterworth filter magnitude and phase responses.
© 2011 by Taylor and Francis Group, LLC

25-18 
Fundamentals of Industrial Electronics
That is, s is replaced by T(s) in the expression for Hp(s). These transformations are summarized in the 
following table for cutoff frequencies of ωc ωl, and ωu:
Filter Type
T(s)
Lowpass
s
c
ω
Highpass
ωc
s
Bandpass
ω
ω
ω ω
u
l
u
l
s
s
−
(
)
+
2
Bandstop
s
s
u
l
u
l
2 +
−
(
)
ω ω
ω
ω
25.9  Sampling
Sampling is the process of converting a continuous-time signal into a discrete-time signal. This may be 
represented abstractly by
	
x n
S x t
[ ]
{ ( )},
=
	
where x(t), −∞ < t < ∞, is the original continuous-time signal and x[n], −∞ < n < ∞, n being integer-
valued, is a discrete-time signal consisting of samples of x(t) (see Figure 25.7). More precisely,
	
x n
x nT
x t
s
t nTs
[ ]
( )
= (
) =
=
,
where Ts > 0 is called the sampling period, assumed here to be fixed. The sampling frequency is fs = 1/Ts 
and the angular sampling frequency is ωs = 2πfs = 2π/Ts. It is noted that n is really a time index, but will 
usually be referred to as time. x[n] is thus seen to be simply a sequence of numbers. (The square-bracket 
notation, which will be used throughout to distinguish discrete-time from continuous-time quantities, 
follows that used by Oppenheim and Schafer (1989).)
The actual process of sampling a physical signal is considerably more complicated than what is implied 
by this abstract description. The final result, namely, a sequence of numbers, is however quite meaning-
ful if, say, these numbers are fed to a digital computer for further processing. The physical sampling 
(or analog-to-digital conversion) process may be modeled by a switch that closes instantaneously, or 
more realistically, very briefly, at instants separated by Ts units of time. This produces narrow pulses of 
height x(nTs), which may further be considered as impulses. This leads to the “impulse-sampled” signal
	
x t
x nT
t
nT
x n
t
nT
s
s
s
n
s
n
( )
(
) (
)
[ ] (
).
=
−
=
−
=−∞
∞
=−∞
∞
∑
∑
δ
δ
Oddly enough, this impulse-sampled signal xs(t) is in fact a continuous-time signal. Clearly, from an 
information content viewpoint, the signal xs(t) and the sequence x[n] are equivalent. Depending on the 
task at hand, one or the other of these representations may be the 
most convenient to consider.
In practice, when we sample a signal we wish to do it in such 
a manner that the samples comprise a reasonably accurate repre-
sentation of the original continuous-time signal. Intuitively this 
suggests that we take a great many samples (Ts small, fs large), 
especially if the signal is changing rapidly, so as not to lose any 
significant information. On the other hand, efficiency (both in 
x(t)
S {  }
x[n]
FIGURE 25.7  Sampling a continuous-
time signal to produce a discrete-time 
signal.
© 2011 by Taylor and Francis Group, LLC

Signal Processing 
25-19
how fast we must sample and perhaps how many samples we must store) dictates that we not take too 
large a number of samples. Trade-offs must therefore be made in choosing an appropriate sampling 
frequency for a given signal.
It is instructive to consider the sampling process in the frequency domain. If x(t) is a continuous-time 
signal with Fourier transform X(jω), then its impulse-sampled counterpart xs(t) will have Fourier transform
	
X j
T
X j
m
s
s
s
m
(
)
( (
)).
ω
ω
ω
=
−
=−∞
∞
∑
1
That is, Xs(jω) consists of copies of X(jω), shifted by all possible multiples of the angular sampling 
frequency ωs, added together and scaled by 1/Ts. Xs(jω) is thus seen to be periodic with period ωs.
In general, the various copies of X(jω) will overlap each other, a phenomenon called aliasing. This 
prevents the recovery of X(jω) from Xs(jω), implying that information is lost in the sampling process. 
On the other hand, if x(t) is bandlimited to half the sampling frequency, i.e., if
	
X j
s
(
)
,
,
ω
ω
ω
=
≥
0
2
then no aliasing or overlap occurs, and the original signal may be recovered from its samples. This may 
be summarized in the form of a theorem, the “sampling theorem,” which states that no information 
is lost in the sampling process if the sampling frequency is at least twice that of the highest frequency 
component present in the original signal. This minimum sampling frequency is called the Nyquist rate. 
The sampling theorem provides a quantitative basis for the choice of sampling frequency, and validates 
our intuition that rapidly varying signals must be sampled more frequently than slowly varying ones.
25.10  Discrete-Time Signals
Discrete-time signals are functions (sequences) of the form x[n], −∞ < n < ∞, where n is an independent 
integer-valued variable, normally a time index (usually, simply referred to as “time”). For our purposes, 
we will assume x[n] to be real valued.
25.10.1  Common Signals
Some discrete-time signals often encountered in practice, and/or which may be easily described math-
ematically, are described below and illustrated in Figure 25.8.
The unit step is the signal
	
u n
n
n
[ ]
,
,
.
=
≥
<



1
0
0
0
Its first difference is the unit impulse
	
δ[ ]
,
,
[ ]
[
].
n
n
n
u n
u n
=
=
≠






=
−
−
1
0
0
0
1
The unit ramp is given by
	
r n
n
n
n
[ ]
,
,
.
=
≥
<



0
0
0
© 2011 by Taylor and Francis Group, LLC

25-20 
Fundamentals of Industrial Electronics
Discrete-time sinusoids may be written in the form
	
x n
A
n
[ ]
cos(
).
=
+
ω
θ 	
A very general signal that is important physically is
	
x n
An a
n
u n
p
n
[ ]
cos(
) [ ],
=
+
ω
θ
where p ≥ 0.
25.10.2  Periodic Signals
Periodic discrete-time signals are those satisfying the condition
	
x n
N
x n
n
[
]
[ ],
,
+
=
−∞<
< ∞
for some fixed integer N > 0. As is the case for continuous-time periodic signals, if this condition is satis-
fied for a given N, it is also satisfied for all integer multiples of N. The smallest such N is called the period. 
Its frequency is 1/N and its angular frequency is 2π/N.
Oddly enough, not all discrete-time sinusoids are periodic. The sinusoid A cos(ωn + θ) is periodic if 
and only if ω = 2πf, where f is a rational number (ratio of integers). In this case, the period N is the small-
est integer that is an integer multiple of 1/f.
1.5
1
0.5
0
–0.5 –2 –1
0
1
Time
(a)
2
3
4
5
6
7
8
–2 –1
0
1
Time
2
3
4
5
6
7
8
Amplitude
1.5
1
0.5
0
–0.5
(b)
Amplitude
8
7
6
5
4
3
2
1
0
–2.5
–2
–1.5
–1
–0.5
0
0.5
1
1.5
2
2.5
–2 –1
0
1
Time
(c)
2
3
4
5
6
7
8
–2 –1
0
1
Time
(d)
2
3
4
5
6
7
8
Amplitude
Amplitude
FIGURE 25.8  Illustration of four common discrete-time signals: (a) δ[n], (b) u[n], (c) r[n], and (d) 2cos(2πn + π/4).
© 2011 by Taylor and Francis Group, LLC

Signal Processing 
25-21
25.10.3  Finite-Duration Signals
As the name implies, finite-duration signals are signals that are nonzero for only a finite range of time 
values. We will be somewhat restrictive and define x[n] to be a finite-duration signal if it satisfies the 
condition
	
x n
n
n
N
[ ]
,
.
=
<
>
−
0
0
1
 
and
This signal thus has, at most, N nonzero values and will be said to be of length N.
There is a close relationship between finite-duration signals and periodic signals. Specifically, if x[n] 
is periodic with period N, then
	
y n
x n
n
N
[ ]
[ ],
,
=
≤
≤
−



0
1
0
otherwise
is a finite-duration signal of length N. On the other hand, if x[n] is a length-N finite-duration signal, then
	
y n
x n
mN
m
[ ]
[
]
=
−
=−∞
∞
∑
is periodic with period N. Each therefore contains the same information, but in a different form.
25.11  Time-Domain Analysis of Discrete-Time Signals
25.11.1  Basic Operations on Signals
Just as in the case of continuous-time signals, various mathematical operations may be performed on 
a discrete-time signal or a combination of signals. Basic ones include combining two or more signals 
using addition, subtraction, multiplication, or division.
The (backward) difference of a signal x[n] is given by
	
y n
x n
x n
x n
[ ]
[ ]
[ ]
[
].
=
=
−
−
∆
1
The accumulation of a signal x[n] is given by
	
y n
x m
m
n
[ ]
[ ].
=
=−∞∑
The difference and accumulation operations are inverses of each other, and may be thought of as 
discrete-time analogs of differentiation and integration, respectively.
Other operations important in signal analysis include amplitude scaling a signal x[n] to produce
	
y n
Ax n
[ ]
[ ],
=
where A ≠ 0 is a constant. Time shifting produces
	
y n
x n
no
[ ]
[
],
=
−
where no is a fixed integer. Finally, time reversal results in
	
y n
x
n
[ ]
[
].
=
−
	
© 2011 by Taylor and Francis Group, LLC

25-22 
Fundamentals of Industrial Electronics
25.11.2  Convolution
The discrete-time convolution of the two signals x1[n] and x2[n] is defined as
	
y n
x n
x n
x m x n
m
n
m
[ ]
[ ]*
[ ]
[ ] [
],
.
=
=
−
−∞<
< ∞
=−∞
∞
∑
1
2
1
2
This involves time reversal and time shifting of the signal x2[m] to produce x2[n − m]. (It is once again 
noted that caution must be exercised in interpreting the notation y[n] = x1[n] * x2[n]. For instance, y[n − no] = 
x1[n] * x2[n − no].)
A positive-time signal is one satisfying the condition
	
x n
n
[ ]
,
=
<
0
0.
Unit steps, ramps, and impulses are positive time. If the signals x1[n] and x2[n] are both positive time, 
then their convolution is also positive time and may be written in the simplified form
	
y n
x n
x n
x m x n
m
n
n
m
n
[ ]
[ ]*
[ ]
[ ] [
],
,
.
=
=
−
≥
<





=∑
1
2
1
2
0
0
0
0
25.11.3  Periodic Convolution
If x1[n] and x2[n] are two periodic signals with period N, their convolution would clearly not be mean-
ingful. Such signals may be combined, instead, using the operation of periodic convolution, defined by
	
y n
x n
x n
x m x n
m
n
m
N
[ ]
[ ]*
[ ]
[ ] [
],
.
=
=
−
−∞<
< ∞
=
−
∑
1
2
1
2
0
1
~
The resulting signal y[n] is also periodic with period N. It should be noted that periodic convolu-
tion is not ordinarily something we would wish to do—rather, it is an operation forced upon us by the 
mathematics.
25.12  Frequency-Domain Analysis of Discrete-Time Signals
As is also true for continuous-time signals, much can be gained by studying discrete-time signals in the 
frequency (or transform) domain. Again, various transforms are used, depending on the nature of the 
signal and the task at hand.
25.12.1  Discrete Fourier Series
Suppose x[n] is a periodic discrete-time signal with period N. Then x[n] may be considered as consisting 
of a finite linear combination of discrete-time complex exponentials. Specifically, it takes N such signals 
to represent x[n], which can be written as
	
x n
N
X k e j
N kn
k
N
[ ]
[ ]
(
/
)
=
=
−
∑
1
2
0
1
π
.
© 2011 by Taylor and Francis Group, LLC

Signal Processing 
25-23
The coefficients X[k] of the discrete Fourier series may be obtained from the original signal using the formula
	
X k
x n e
k
N
j
N kn
n
N
[ ]
[ ]
,
, , , ...,
.
(
/
)
=
=
−
−
=
−
∑
2
0
1
0 1 2
1
π
It is noted that X[k] is itself a (generally complex) periodic signal with period N, and as such is defined 
for all integers k. However, only N values of X[k] are required to determine (or represent) x[n].
X[k] and x[n] form a transform pair with X[k] uniquely determined by x[n] and vice versa. Thus, we write
	
X k
DFS x n
[ ]
[ ]
=
{
}
and
	
x n
DFS
X k
[ ]
[ ] .
=
{
}
−1
X[k] and x[n] thus contain exactly the same information, but in a different form.
As an example, consider the signal x[n], which is assumed to be periodic with period N (where N is 
even), and which is defined over one period by
	
x n
n
N
N
n
N
[ ]
,
,
.
=
≤
<
≤
<






1
0
2
0
2
Using the defining relation, it is easily determined that the discrete Fourier series coefficients are
	
X k
e
k
j
N k
[ ]
(
)
(
/
)
=
−−
−
−
1
1
1
2π
for all integers k.
Being complex valued, X[k] may be written as
	
X k
X k
k
X k e j
k
[ ]
[ ]
[ ]
[ ]
,
[ ]
=
∠
=
ϕ
ϕ
where φ[k] = arg{X[k]}. Under our assumption that x[n] is real valued, ⏐X[k]⏐ is an even function of 
k and φ[k] is an odd function of k, i.e., respectively,
	
X
k
X k
k
k
[
]
[ ],
[
]
[ ].
−
=
−
= −
ϕ
ϕ
Thus, the information contained in X[k], k <0, is redundant. In addition, since X[k] is periodic, all but 
N consecutive values of X[k] are redundant. Combining these two results leads to the conclusion that 
X[k] is completely determined by X[k], 0 ≤ k ≤ M, where M = N/2 for N even and M = (N − 1)/2 for N odd. 
When plotted versus k (the frequency index), |X[k]| is called the magnitude spectrum and φ[k] the phase 
spectrum. The spectra for this example are illustrated in Figure 25.9.
© 2011 by Taylor and Francis Group, LLC

25-24 
Fundamentals of Industrial Electronics
Some important properties of the discrete Fourier series are summarized in the following table:
Discrete-Time
Periodic Signals
Discrete
Fourier Series Coefficients
Ax1[n] + Bx2[n]
AX1[k] + BX2[k]
x[n − no]
X k e
j
N kno
[ ]
(
/
)
−
2π
x[−n]
X[−k]
x n
x n
1
2
[ ]*
[ ]

X1[k]X2[k]
x[n], x1[n], x2[n] are arbitrary discrete-time periodic 
signals with period N and with discrete Fourier series 
coefficients X[k], X1[k], X2[k], respectively. A, B are arbi-
trary constants and no is an arbitrary integer constant.
25.12.2  Discrete Fourier Transforms
As seen earlier, from an information content viewpoint, there is no essential difference between a periodic 
signal and a finite duration signal. The discrete Fourier series is the frequency-domain representation of 
1.5
0.5
–0.5
0
1
2
3
4
5
Amplitude
Magnitude
–2
0
2
4
Time
(a)
(b)
6
8
10
12
–8
–6
–4
–2
0
Frequency index
2
4
6
8
1
0
–2
–1.5
–1
–0.5
0
0.5
1
2
1.5
Phase
(c)
–8
–6
–4
–2
0
Frequency index
2
4
6
8
FIGURE 25.9  Discrete Fourier series of a periodic signal: (a) signal, (b) magnitude spectrum, and (c) phase spectrum.
© 2011 by Taylor and Francis Group, LLC

Signal Processing 
25-25
a periodic signal. The frequency-domain representation of a length-N finite-duration signal x[n] is the 
discrete Fourier transform given by
	
X k
DFT x n
x n e
k
N
j
N kn
n
N
[ ]
[ ]
[ ]
,
, , , . . . ,
,
(
/
)
=
{
} =
=
−
−
=
−
∑
2
0
1
0 1 2
1
0
π
otheerwise



.
	
The inverse discrete Fourier transform is given by
	
x n
DFT
X k
N
X k e
n
N
j N kn
k
N
[ ]
{ [ ]}
[ ]
,
, , ,
,
,
=
=
=
−
−
=
−
∑
1
2
0
1
1
0 1 2
1
0
π
…
otherwwise



.
	
As an example, consider the finite-duration signal x[n], which is defined by
	
x n
n
N
[ ]
,
,
,
=
≤
<



1
0
2
0
otherwise 	
where N is even. Using the defining relation, it is easily determined that the discrete Fourier transform is
	
X k
e
k
N
k
j
N k
[ ]
(
)
,
, , ,
,
,
.
(
/
)
=
−−
−
=
−



−
1
1
1
0 1 2
1
0
2π
…
otherwise
	
This is shown in Figure 25.10.
It is seen that there is no fundamental difference between the discrete Fourier series and the discrete 
Fourier transform (justifying the use of the same notation for both). Whether one is dealing with the discrete 
Fourier series or the discrete Fourier transform is thus a matter of interpretation. If x[n] and X[k] are both 
assumed to be periodic, then the X[k] are the discrete Fourier series coefficients of x[n]. On the other hand, 
if x[n] and X[k] are both assumed to be finite duration, then X[k] is the discrete Fourier transform of x[n].
Since from a formal viewpoint the quantities involved are periodic, the discrete Fourier series is 
perhaps the more fundamental interpretation. The properties of the discrete Fourier transform thus 
follow from those of the discrete Fourier series, and in a given situation are best interpreted by making 
all quantities periodic, invoking the corresponding property of the discrete Fourier series, and then 
making all quantities finite duration again.
25.12.3  Fast Fourier Transforms
The calculation of the discrete Fourier transform would appear to be very straightforward and, indeed, 
it is. However, the number of arithmetic operations (additions and multiplications) necessary to com-
pute even a moderately large discrete Fourier transform can be quite excessive. To overcome this dif-
ficulty, various clever algorithms have been developed for the efficient calculation of the discrete Fourier 
transform. These algorithms are collectively known as fast Fourier transforms (FFTs).
The simplest FFT is probably the decimation-in-time algorithm. In this algorithm N is required to be 
a power of two. In deriving this FFT algorithm, the length-N transform is decomposed into two length-
N/2 transforms. Each of these is decomposed into two length-N/4 transforms. This process is continued 
until one obtains all length-2 transforms. Because of their shape when represented in flow graph form, 
these simple length-2 calculations are known as butterflies. For the decimation-in-time FFT algorithm, 
the number of arithmetic calculations is proportional to N log2 N. This compares with N2 in the case of 
© 2011 by Taylor and Francis Group, LLC

25-26 
Fundamentals of Industrial Electronics
the direct evaluation of the discrete Fourier transform. For large N, the savings in computation can be 
very significant. For instance, for N = 210 = 1024, the number of computations is reduced by a factor of 
more than 100.
25.12.4  Discrete-Time Fourier Transforms
Periodic discrete-time signals may be represented by the discrete Fourier series and finite-duration 
discrete-time signals by the discrete Fourier transform. A larger class of discrete-time signals may be 
represented by the discrete-time Fourier transform.
A discrete-time signal x[n] will have a discrete-time Fourier transform if it is absolutely summable, i.e., if
	
x n
n
[ ]
.
< ∞
=−∞
∞
∑
	
With proper interpretation, certain signals not satisfying this property will also have discrete-time 
Fourier transforms. These include steps, constants, and all periodic signals.
The discrete-time Fourier transform of x[n] is defined as
	
X e
DTFT x n
x n e
j
j n
n
(
)
{ [ ]}
[ ]
,
.
ω
ω
ω
=
=
−∞<
< ∞
−
=−∞
∞
∑
	
1.5
0.5
–0.5
0
1
2
3
4
5
Amplitude
Magnitude
–2
0
2
4
Time
(a)
(b)
6
8
10
12
–2
0
2
4
Frequency index
6
8
10
12
1
0
–2
0
2
4
6
8
10
12
–2
–1.5
–1
–0.5
0
0.5
1
2
1.5
Phase
(c)
Frequency index
FIGURE 25.10  Discrete Fourier transform of a finite-duration signal: (a) signal, (b) magnitude spectrum, and 
(c) phase spectrum.
© 2011 by Taylor and Francis Group, LLC

Signal Processing 
25-27
It is noted that ω is a continuously varying real quantity, not an integer, despite the fact that x[n] is a 
discrete-time signal. x[n] may be recovered uniquely from X(e jω) using the inverse discrete-time Fourier 
transform given by
	
x n
DTFT
X e
X e
e
d
j
j
j n
[ ]
{ (
)}
(
)
.
=
=
−
−∫
1
1
2
ω
ω
ω
π
π
π
ω
	
Note that we have written X(e jω) as a function of e jω for convenience, rather than as a function of ω. 
Some common discrete-time Fourier transforms are listed in the following table.
x[n]
X(e jω)
δ[n]
1
1
2
2
π
δ ω
π
(
)
−
=−∞
∞
∑
m
m
u[n]
1
1
2
−
+
−
−
=−∞
∞
∑
e
m
j
m
ω
π
δ ω
π
(
)
anu[n],  |a|<1
1
1−
−
ae
jω
nanu[n],  |a| < 1
ae
ae
j
j
−
−
−
ω
ω
(
)
1
2
sin(ωon)
j
m
m
o
o
m
π
δ ω
ω
π
δ ω
ω
π
[
]
(
)
(
)
+
−
−
−
−
=−∞
∞
∑
2
2
cos(ωon)
π
δ ω
ω
π
δ ω
ω
π
[
]
(
)
(
)
+
−
+
−
−
=−∞
∞
∑
o
o
m
m
m
2
2
The quantity X(e jω) is periodic in ω with a period of 2π. In fact, the expression for X(e jω) is seen to be 
an exponential Fourier series with coefficients x[−n] and with ω interpreted as the independent variable. 
While periodic and finite-duration signals have all their energy concentrated at N distinct frequencies, 
other signals allowed by the discrete-time Fourier transform have their energy spread out over, in gen-
eral, all angular frequencies in the range −π to π (or any range of width 2π).
The discrete-time Fourier transform is, in general, complex valued and may, thus, be written as
	
X e
X e
e
X e
e
j
j
j
j
j
e j
(
)
(
)
(
)
(
)
,
(
)
ω
ω
ω
ω
ω
=
∠
=
ϕ
ϕ
	
where φ(e jω)  = arg{X(e jω)}. For our assumed real-valued x[n], |X(e jω)| is an even function of ω and 
φ(e jω) is an odd function of ω, i.e., respectively,
	
X e
X e
e
e
j
j
j
j
(
)
(
) ,
(
)
(
).
−
−
=
= −
ω
ω
ω
ω
ϕ
ϕ
	
Thus, the information contained in X(e jω) , ω < 0, is redundant. In addition, since X(e jω) is periodic with 
period 2π, it may be concluded that X(e jω) is completely determined by X(e jω), 0 ≤ ω ≤ π. When plotted 
© 2011 by Taylor and Francis Group, LLC

25-28 
Fundamentals of Industrial Electronics
versus ω, ⏐X(e jω)⏐ is called the magnitude spectrum and φ(e jω) the phase spectrum. An example is shown 
in Figure 25.11.
Signals not satisfying the absolute summability condition stated above will, if they are discrete-time 
Fourier transformable, normally contain frequency-domain impulses in their transforms. As a spe-
cific case, if x[n] is a periodic signal with period N and with discrete Fourier series coefficients X[k] = 
DFS{x[n]}, then its discrete-time Fourier transform is given by
	
X e
N
X k
N k
m
j
k
N
m
(
)
[ ]
.
ω
π
δ ω
π
π
=
−
+




=
−
=−∞
∞
∑
∑
2
2
2
0
1
	
For ω in the range 0 ≤ ω < 2π, this reduces to
	
X e
N
X k
N k
j
k
N
(
)
[ ]
,
ω
π
δ ω
π
=
−




=
−
∑
2
2
0
1
	
0.8
0.6
0.4
0.2
0
–0.2
0
0.5
–0.5
1.5
1
2
2.5
3.5
3
4.5
4
Amplitude
Magnitude
–2
0
2
4
Time
(a)
(b)
6
8
10
12
–2
0
2
4
Frequency
6
8
10
12
–2
0
2
4
6
8
10
12
1
–1
–0.6
–0.8
–0.4
0
–0.2
0.2
0.4
0.6
1
0.8
Phase
(c)
Frequency
FIGURE 25.11  Discrete-time Fourier transform of x[n] = (0.75)nu[n]: (a) signal, (b) magnitude spectrum, and 
(c) phase spectrum.
© 2011 by Taylor and Francis Group, LLC

Signal Processing 
25-29
with all energy clearly still concentrated (now, mathematically, by means of impulse functions) at the N 
frequencies 2πk/N, k = 0, 1, 2, …, N − 1.
Some important properties of the discrete-time Fourier transform are summarized in the follow-
ing table:
Discrete-Time
Signals
Discrete-Time
Fourier Transforms
Ax1[n] + Bx2[n]
AX1(e jω) + BX2(e jω)
x[n − no]
X e
e
j
j no
(
)
ω
ω
−
x[−n]
X(e−jω)
x1[n] * x2[n]
X1(e jω)X2(e jω)
x[n], x1[n], x2[n] are arbitrary discrete-time signals 
with discrete Fourier transforms X(e jω), X1(e jω), X2(e jω), 
respectively. A, B are arbitrary constants and no is an 
arbitrary integer constant.
25.12.5  z-Transforms
As seen above, the discrete-time Fourier transform is a generalization of the discrete Fourier series, in 
that it allows for the analysis of a broader range of discrete-time signals than does the discrete Fourier 
series. The z-transform is likewise a generalization of the discrete-time Fourier transform.
A signal x[n] will have a z-transform if
	
x n r n
n
[ ] −
=−∞
∞
∑
< ∞	
for some real r > 0. Since r = 1 is allowed in this condition, if x[n] has a discrete-time Fourier transform, 
it will also have a z-transform, but the converse is not true.
The z-transform of a signal x[n] is defined as
	
X z
ZTx n
x n z n
n
( )
[ ]
[ ]
=
=
−
=−∞
∞
∑
 ,
	
where z = re jω is a complex variable. In general, this sum will converge only for certain choices of r. x[n] 
may be recovered uniquely from X(z) using the inverse z-transform given by
	
x n
ZT X z
j
X z z
dz
n
C
[ ]
( )
( )
,
=
=
−
−
∫
1
1
1
2π 
	
where C is an appropriately chosen contour in the complex z plane. (This formula is rarely directly 
used in practice because of its complexity. Instead, tables of z-transform pairs are used, with compli-
cated transforms first being decomposed into simpler ones using partial fraction expansion techniques.) 
Some common z-transforms are listed in the following table:
© 2011 by Taylor and Francis Group, LLC

25-30 
Fundamentals of Industrial Electronics
x[n]
X(z)
δ[n]
1
u[n]
z
z
z
−
>
1
1
,
anu[n]
z
z
a
z
a
−
,
>
nanu[n]
az
z
a
z
a
(
) ,
>
2
−
sin(ωon)u[n]
z
z
z
z
o
o
sin(
)
cos(
)
ω
ω
2
2
1
−
+ ,
>1
cos(ωon)u[n]
z
z
z
z
z
o
o
2
2
2
1
1
−
−
+
>
cos(
)
cos(
)
,
ω
ω
For a signal x[n] having a discrete-time Fourier transform X(e jω), it is the case that
	
DTFT x n
ZT x n
r
[ ]
[ ]
{
} =
{
} =1 	
or
	
X e
X z
j
z e j
(
)
( )
,
ω
ω
=
=
	
where X(z) is the z-transform of x[n]. (This explains our choice of notation for the discrete-time Fourier 
transform.) Thus, the discrete-time Fourier transform is simply the z-transform evaluated on the unit 
(radius one) circle in the z (complex) plane.
If the signal x[n] is additionally assumed to be finite duration with length N, then
	
DFT x n
DTFT x n
N k
[ ]
[ ]
(
/
)
{
} =
{
}
=
ω
π
2
	
or
	
X k
X e j
N k
[ ]
(
)
,
(
/
)
=
=
ω
ω
π
2
	
where X[k] is the discrete Fourier transform of x[n]. That is, the discrete Fourier transform is the dis-
crete-time Fourier transform evaluated at equally spaced frequency values (or the z-transform evaluated 
at equally spaced points around the unit circle).
Some important properties of the z-transform are summarized in the following table:
Discrete-Time
Signals
z-Transforms
Ax1[n] + Bx2[n]
AX1(z) + BX2(z)
x[n − no]
X z z no
( )
−
x[−n]
X(z−1)
x1[n] * x2[n]
X1(z)X2(z)
x[n], x1[n], x2[n] are arbitrary discrete-
time signals with z-transforms X(z), X1(z), 
X2(z), respectively. A, B are arbitrary con-
stants and no is an arbitrary integer constant.
© 2011 by Taylor and Francis Group, LLC

Signal Processing 
25-31
25.13  Discrete-Time Signal Processors
A discrete-time signal processor (system) is a device or algorithm 
(see Figure 25.12) that acts on an input signal x[n], modifying it 
in some manner to produce an output signal y[n]. This may be 
represented abstractly as
	
y n
x n
[ ]
{ [ ]}.
= H
(Here, x[n] and y[n] should be thought of in their totality, rather than at specific instants n. Despite 
appearances, this notation does not imply that y[n] is a function of x[n] at only the same instant n. y[n] 
could, e.g., depend on all past values of x[m], m ≤ n.)
Only certain relatively simple classes of discrete-time signal processors are considered in practice. In 
this treatment, we will discuss only those that can be described by linear constant-coefficient difference 
equations. Such signal processors are of necessity linear, time invariant, and causal. They may be imple-
mented, in hardware or software, using only summers, constant multipliers, and delay (or memory) 
elements. A system is linear if
	
H
H
H
{
[ ]
[ ]}
{ [ ]}
{
[ ]},
,
Ax n
Bx n
A
x n
B
x n
n
1
2
1
2
+
=
+
−∞<
< ∞
for all signals x1[n], x2[n] and all constants A,B. It is time invariant if
	
y n
n
x n
n
n
o
o
[
]
{ [
]},
,
−
=
−
−∞<
< ∞
H
	
for all input signals x[n] and corresponding output signals y[n] and all integer constants no. A system is 
casual if H{x[n]} depends only on x[m], m ≤ n, for all signals x[n].
25.14  Time-Domain Analysis of Discrete-Time Signal Processors
Under our assumptions, a discrete-time signal processor may be represented by a linear constant-­
coefficient difference equation. It may seem natural to write such an equation in terms of the differences 
in the input and output, and this may be done. However, it is customary, and more convenient, to simply 
use delayed versions of the input and output. The equation then takes the form
	
a y n
r
b x n
r
r
r
N
r
r
M
[
]
[
]
−
=
−
=
=
∑
∑
0
0
.
	
Often, this equation is normalized so that a0 = 1. The equation may thus be solved for y[n] in terms 
of current and past values of x[n] and past values of y[n]. As such, it may be implemented directly and 
solved for y[n] recursively, provided that x[n] and a sufficient number of initial values of y[n] are known. 
This equation may also be solved using z-transforms and other techniques.
An alternative means for describing our signal processor is based on the use of its impulse response. 
The impulse response is defined as
	
h n
n
[ ]
{ [ ]},
= H δ
	
i.e., the output when the input is a unit impulse. Since we have assumed causality, it may be shown that 
h[n] is a positive-time signal, i.e., that h[n] = 0, n < 0. Because the signal processor is linear and time 
invariant, it may additionally be shown that for any input x[n], the corresponding output y[n] is given by 
the convolution of h[n] and x[n], namely,
	
y n
x n
h n
x n
[ ]
{ [ ]}
[ ]* [ ].
=
=
H
	
x[n]
y[n]
{  }
FIGURE 25.12  Discrete-time signal 
processing system.
© 2011 by Taylor and Francis Group, LLC

25-32 
Fundamentals of Industrial Electronics
This is a very significant result, since it shows that all information regarding the signal processor (at 
least, from an input–output viewpoint) is contained in its impulse response.
A very desirable property of signal processors is stability. A system is said to be (bounded-input 
bounded-output) stable if whenever x[n] is bounded (i.e., |x[n]| ≤ Kx < ∞, −∞ < n < ∞, for some Kx), 
then the corresponding y[n] is also bounded (i.e., |y[n]| ≤ Ky < ∞, −∞ < n < ∞, for some Ky). (The alter-
native would normally be undesirable.) It is possible to easily determine stability directly from h[n]. 
Specifically, the signal processor is stable if and only if h[n] is absolutely summable, i.e., if and only if
	
h n
n
[ ]
.
< ∞
=−∞
∞
∑
	
Unlike continuous-time systems, there are two distinctly different types of discrete-time systems, 
depending on the nature of h[n]. If h[n] is a finite-duration signal, then the system is said to be FIR (i.e., 
to have a finite impulse response). If this is not the case, then the system is IIR (i.e., having an infinite 
impulse response). For an FIR system, the difference equation reduces to
	
y n
b x n
r
r
r
M
[ ]
[
]
=
−
=∑
0
,
	
and h[n] is a finite-duration signal of length M + 1 with
	
h n
b
n
M
n
[ ]
,
,
.
=
≤
≤



0
0
otherwise 	
Since their impulse responses are clearly always absolutely summable, FIR signal processors are 
always stable.
25.15  Frequency-Domain Analysis of Discrete-Time 
Signal Processors
In the frequency (transform) domain, a signal processor is characterized by its transfer function H(z). 
H(z) may be determined by z-transforming the convolution relationship to obtain
	
Y z
H z X z
( )
( ) ( )
=
, 	
where
	
H z
ZT h n
( )
[ ] .
=
{
} 	
Thus, the transfer function is the z-transform of the impulse response.
Alternatively, the input–output difference equation may be z-transformed to obtain
	
a z Y z
b z
X z
r
r
r
N
r
r
r
M
−
=
−
=
∑
∑
=
( )
( )
0
0
,
	
© 2011 by Taylor and Francis Group, LLC

Signal Processing 
25-33
from which
	
H z
b z
a z
r
r
r
M
r
r
r
N
( )
.
=
−
=
−
=
∑
∑
0
0
	
Thus, H(z) is a rational function in z−1, which, if preferred, may also be written as a rational function 
in z. As such, the impulse response h[n] will necessarily consist only of terms of the form
	
An a
n
u n
p
n cos(
) [ ],
ω
θ
+
	
where p ≥ 0.
When written as polynomials in z, the roots of the numerator are the zeros of H(z) and those of the 
denominator are the poles of H(z). It may be shown that a signal processor is stable if and only if all of 
its poles lie strictly inside the unit circle in the complex z plane (i.e., have magnitudes less than one). It is 
noted that all poles of an FIR signal processor are at the origin, which is thus seen to be consistent with 
our previous comment that such systems are always stable.
Discrete-time Fourier transforming the convolution relationship leads to
	
Y e
H e
X e
j
j
j
(
)
(
) (
)
ω
ω
ω
=
, 	
where
	
H e
DTFT h n
j
(
)
[ ] .
ω =
{
} 	
H(e jω) is called the frequency response of the signal processor, and is the discrete-time Fourier transform 
of the impulse response. The magnitude of H(e jω) is the magnitude response and its angle is the phase 
response. It is seen that
	
H e
H z
j
z e j
(
)
( )
,
ω
ω
=
=
	
where H(z) is the transfer function. That is, the frequency response is the transfer function evaluated on 
the unit circle in the complex z plane. Thus, we may also write
	
H e
b e
a e
j
r
j r
r
M
r
j r
r
N
(
)
.
ω
ω
ω
=
−
=
−
=
∑
∑
0
0
	
The frequency response of a signal processor is also useful for determining its output in the case of 
a periodic input. If x[n] is a periodic input signal with period N (not the same N used in the difference 
equation) and with discrete Fourier series coefficients X[k], then the output signal will also be periodic 
with period N. Its discrete Fourier series coefficients will be given by
	
Y k
H e
X k
j
N k
[ ]
(
) [ ]
(
/
)
=
2π
. 	
This relationship may also be used for the steady-state analysis of systems, i.e., systems that have been 
operating for a sufficiently long time that all transient terms may be neglected.
© 2011 by Taylor and Francis Group, LLC

25-34 
Fundamentals of Industrial Electronics
It is thus clear that the way a signal processor processes an input signal (either aperiodic or periodic) 
is determined by its frequency response. It is thus very informative to have this quantity available, par-
ticularly in visual form as embodied in its magnitude and phase spectra.
25.16  Discrete-Time (Digital) Filters
Just as in the case of continuous-time (analog) filters, a discrete-time (digital) filter is a signal processor 
designed to allow signal components of certain frequencies to pass through to the output while prevent-
ing input signal components of other frequencies from doing so. The frequency response H(e jω) should 
ideally have magnitude 1 in the passbands and magnitude 0 in the stopbands.
25.16.1  Common Filter Types
The common types of discrete-time filters are the same as those for continuous-time filters, the only 
difference being that the frequency response H(e jω) is completely specified by its values in the frequency 
range 0 ≤ ω ≤ π as opposed to 0 ≤ ω < ∞. The comments made regarding ideal and nonideal (practical) 
continuous-time filters apply directly to discrete-time filters as well.
Some significant differences with continuous-time filters exist regarding linear phase. Again, linear 
phase ensures that the shape of a signal is preserved in the filtering process. In discrete-time filters, how-
ever, true linear phase may in fact be achieved, but only if the filter is FIR. The FIR filter
	
H z
b z
r
r
r
M
( ) =
−
=∑
0
	
will have linear phase if and only if
	
b
b
r
M
r
M r
=
≤
≤
−,
,
0
	
i.e., if and only if the coefficients br are symmetric. It is important to point out that if M is odd, then H(z) 
will have a zero at z = −1, or equivalently H(e jω) will be zero at ω = π. This rules out the use of odd values 
of M in this situation if it is desired to construct a highpass or bandstop filter.
25.16.2  FIR Filter Design
Different techniques are employed for the design of FIR and IIR discrete-time filters, so these will be 
discussed separately. For simplicity, in the case of FIR filters, we will only consider linear-phase filters 
with M even.
One method for designing FIR filters is known as windowing. This procedure begins by specifying the 
impulse response hi[n] of the desired ideal filter, assumed to have zero phase. Anticipating an even M, this 
quantity is given in the following table for the common filter types, with cutoff frequencies ωc, ωl, and ωu.
Filter Type
hi[0]
hi[n], n ≠ 0
Lowpass
ω
π
c
sin(
)
n
n
c
ω
π
Highpass
1−ω
π
c
−sin(
)
n
n
c
ω
π
Bandpass
ω
ω
π
u
l
−
sin(
)
sin(
)
n
n
n
u
l
ω
ω
π
−
Bandstop
1−
−
ω
ω
π
u
l
sin(
)
sin(
)
n
n
n
l
u
ω
ω
π
−
© 2011 by Taylor and Francis Group, LLC

Signal Processing 
25-35
A simple way to obtain an FIR filter from hi[n] is to truncate it at n = ±M and then shift the response to 
the right by M/2 to result in a casual linear-phase FIR filter. However, since it is recalled that the hi[n] (actu-
ally hi[−n]) are the Fourier series coefficients of Hi(e jω) (with ω interpreted as the independent variable), 
this process amounts to Fourier series truncation, with its attendant Gibb’s phenomenon oscillations.
Since these oscillations are normally unacceptable, a better approach is to reduce the effects of Gibb’s 
phenomenon by multiplying the ideal impulse response by a tapered function known as a window, after 
first shifting the response to the right to produce causality. The impulse response h[n] of the resulting 
filter is given by
	
h n
h n
M w n
n
i
[ ]
[ ],
,
=
−




−∞<
< ∞
2
	
where w[n] is a symmetric window satisfying
	
w n
w M
n
n
M
[ ]
[
],
,
.
=
−
≤
≤



0
0
otherwise 	
The resulting filter is then
	
H z
b z
r
r
r
M
( )
,
=
−
=∑
0
	
where br = h[r], 0 ≤ r ≤ M.
Numerous choices for windows exist. Some commonly used windows are listed in the following table and 
shown in Figure 25.13:
Window
w[n],  0 ≤ n ≤ M
Rectangular
1
Bartlett
1
2
2
−
−
M n
M
Hanning
1
2
1
2
2
−




cos
πn
M
Hamming
0 54
0 46
2
.
.
cos
−




πn
M
Note that w[n] = 0 outside of this range.
It is noted that the use of a rectangular window is equivalent to simply truncating the Fourier series. 
As we move down in the table, the windows are increasingly better at reducing the oscillations caused 
by Gibb’s phenomenon. Generally, windows that are good in reducing these oscillations do so at the 
expense of increased transition bandwidths.
As an example of using windowing to design a linear-phase FIR filter, suppose we wish to construct a 
highpass filter with a cutoff frequency ωc = π/4 and a length M = 30. Choosing a Hanning window and 
following the procedure just discussed results in the filter
	
H z
b z
r
r
r
( ) =
−
=∑
,
0
30
	
where
	
b
r
r
r
r
r =
−
(
)
−



−




=
…
sin (
)( / )
(
)
cos
,
, ,
,
15
4
2
15
15
1
0 1
3
π
π
π
0
15
,
,
r ≠
	
and b15 = 3/4. Figure 25.14 illustrates the results of this design procedure.
© 2011 by Taylor and Francis Group, LLC

25-36 
Fundamentals of Industrial Electronics
While windowing has the advantage of being very simple, it has some significant drawbacks. There 
is the fact that there is no direct link with the tolerances specified by the designer and the fact that the 
tolerances in the various filter bands are not independently controllable.
A very popular method for FIR filter design, which does not suffer from these drawbacks, is the 
Parks-McClellan algorithm. Readily available and easy-to-use computer implementations of this 
algorithm exist. The Parks-McClellan algorithm results in FIR filters that are equiripple in all pass-
bands and stopbands. The designer simply specifies the passband and stopband edges, the desired 
magnitude response in each band, the relative tolerances, and the filter order. The algorithm produces 
the resulting filter coefficients. Since the magnitude response in the transition bands is not the con-
cern of the algorithm, the magnitude response in these regions must be separately checked to ensure 
acceptability.
25.16.3  IIR Filter Design
The design of an IIR discrete-time filter usually involves the design of a continuous-time lowpass pro-
totype filter, its transformation to a lowpass IIR discrete-time filter, and, if necessary, a frequency trans-
formation to produce the desired filter type. When simultaneously discussing continuous-time and 
discrete-time quantities, we will use Ω to represent continuous-time angular frequency while retaining 
ω for discrete-time angular frequency.
1.5
1
0.5
0
1.5
1
0.5
0
1.5
1
0.5
0
1.5
1
0.5
0
–4
0
–2
2
4
(a)
Amplitude
6
8
10
12
14
–4
0
–2
2
4
6
8
10
12
14
–4
0
–2
2
4
6
8
10
12
14
–4
0
–2
2
4
6
8
10
12
14
Amplitude
Time
Time
(b)
Time
(c)
Amplitude
Time
(d)
Amplitude
FIGURE 25.13  Four popular windows (shown for M = 10): (a) rectangular, (b) Bartlett, (c) Hanning, and (d) 
Hamming.
© 2011 by Taylor and Francis Group, LLC

Signal Processing 
25-37
The design process begins by establishing the discrete-time filter specifications in precisely the same 
manner as in the case of continuous-time filters. These specifications are then translated to equivalent 
specifications on the continuous-time filter using the formula
	
Ω=




tan ω
2
	
to translate specific frequency values such as cutoff frequencies and band edges. Using techniques 
discussed earlier, a continuous-time lowpass prototype filter Hp(s) is designed to meet the trans-
lated specifications. This filter is then transformed to a lowpass IIR discrete-time filter using the 
formula
	
H
z
H
s
lp
p
s B z
( )
( )
,
( )
=
=
	
where
	
B z
z
z
( )
.
=
−
+
1
1 	
B(z) is known as a bilinear transformation.
If a lowpass filter is desired, the design process is complete. If a highpass discrete-time filter Hhp(z) is 
desired, it may easily be determined using the frequency transformation formula
	
H
z
H
z
hp
lp
( )
(
)
=
−. 	
Assuming that the cutoff frequency of Hlp(z) is ωc, this results in Hhp(z) having a cutoff frequency of π–ωc. 
Bandpass and bandstop filters may also be obtained in this manner, but these require considerably more 
complicated frequency transformations that double the order of the filter.
1
0.5
0
–0.5
0
Magnitude
0.5
1
Frequency
1.5
2
2.5
3
3.5
4
4
2
0
–2
–4
Phase
–0.5
0
0.5
1
Frequency
1.5
2
2.5
3
3.5
4
FIGURE 25.14  Highpass FIR linear-phase filter magnitude and phase responses.
© 2011 by Taylor and Francis Group, LLC

25-38 
Fundamentals of Industrial Electronics
25.17  Discrete-Time Analysis of Continuous-Time Signals
Because of their convenience and efficiency, discrete-time techniques are often employed in the analysis 
of continuous-time signals. In particular, an FFT is often used as a spectral analysis tool to determine 
the frequency content of a continuous-time signal. It is thus important to consider the relationship 
between continuous-time and discrete-time Fourier transforms. As in the previous section, Ω will be 
used for continuous-time angular frequency and ω for discrete-time angular frequency.
As discussed earlier, if the continuous-time signal x(t), with Fourier transform X(jΩ), is impulse 
sampled with an angular sampling frequency Ωs, a continuous-time signal xs(t) is produced with Fourier 
transform
	
X j
T
X j
m
s
s
s
m
(
)
( (
)),
Ω
Ω
Ω
=
−
=−∞
∞
∑
1
	
where
Ωs = 2π/Ts
Ts is the sampling period
Now, x[n] = S{x(t)} = x(nTs), i.e., the sampled version of x(t), is a discrete-time signal. As such it will have 
a discrete-time Fourier transform X(e jω), which may be shown to be given by
	
X e
X
j T
T
X j T
m
j
s
s
s
s
s
m
(
)
.
ω
ω
ω
=



=
−








=−∞
∞
∑
1
Ω
	
As is true of all discrete-time Fourier transforms, X(e jω) is periodic with period 2π, and is hence 
completely specified by its values in the range −π ≤ ω ≤ π. Thus, if the original signal is bandlimited 
and if sampling is carried out at the Nyquist rate or greater, no aliasing will occur and this expression 
reduces to
	
X e
X
j T
T X j T
j
s
s
s
s
(
)
,
.
ω =



=




−
≤
≤
ω
ω
π
ω
π
1
	
This is justified since, as a result of the absence of overlap, only the m = 0 term in the infinite sum will be 
present in this frequency range. This shows that, under the circumstances stated (namely, no aliasing), 
the discrete-time Fourier transform X(e jω) of the discrete-time signal x[n] = x(nTs) is simply an ampli-
tude- and a frequency-scaled version of the Fourier transform X(jΩ) of the continuous-time signal x(t), 
with the frequencies related by Ω = ω/Ts.
Now, if the discrete-time signal x[n] = x(nTs) is additionally assumed to be of finite duration with 
length N, then, as stated earlier, the discrete Fourier transform X[k] of x[n] is given by
	
X k
X e
k
N
j
N k
[ ]
(
),
, , ,
,
,
(
/
)
=
=
…
−
2
0 1 2
1
π
	
and hence
	
X k
T X j NT k
k
N
s
s
[ ]
,
, , ,...,
.
=




=
−
1
2
0 1 2
1
π
	
© 2011 by Taylor and Francis Group, LLC

Signal Processing 
25-39
That is, the discrete Fourier transform values are amplitude-scaled samples of the continuous-time 
Fourier transform X(jΩ) at the frequency values
	
Ω=
=
…
−
2
0 1 2
1
π
NT k
k
N
s
,
, , ,
,
. 	
(Because of redundancy, only the first half of these values, for k = 0,1,2,…,(N/2)−1, are useful. Here N is 
assumed to be even.) This relationship clearly justifies the utility of using an FFT (to evaluate the discrete 
Fourier transform) in performing the spectral analysis of a continuous-time signal.
Unfortunately, the assumption that x[n] is of finite duration is at odds with the assumption that x(t) is 
bandlimited. If x(t) is bandlimited, it, and hence x[n], must be of infinite duration. Thus, in reality, the expres-
sion for X[k] is an approximation. However, this approximation may still be quite useful if applied carefully.
Several comments are in order regarding the use of an FFT for spectral analysis. Prior to sampling, it is 
often beneficial to pass the original signal through a continuous-time lowpass filter. Such an “anti-alias-
ing” filter helps to ensure that the signal to be sampled is bandlimited and free of high-frequency noise.
Additional zero-valued samples are sometimes appended to the end of the discrete-time signal 
obtained by the sampling process. This “zero padding” may be done to provide a signal length equal to 
a power of two for use with an FFT. It may also be done to increase the resolution of the Fourier trans-
form. This may be seen by observing that, in the expression for X[k], increasing N both provides more 
frequency samples and more closely spaced frequency samples.
Prior to taking an FFT, the discrete-time signal x[n] may first be multiplied by a window, w[n], of the 
type discussed earlier. While this certainly alters the frequency content of the signal, this effect may be 
outweighed by the benefit gained due to the tapered nature of the window, which reduces unnatural 
discontinuities introduced by artificially time limiting the signal.
Because of the frequency sampling that occurs when using an FFT, a phenomenon known as “leak-
age” may sometimes occur. This happens when a frequency component of the original signal falls 
between two frequencies of the FFT. The “energy” in this component is then distributed (“leaks”) to 
nearly frequencies, thereby somewhat obscuring the true frequency component.
Finally, it should be noted that other more sophisticated and generally better methods for spectral 
analysis exist, but these are beyond the scope of this discussion.
25.18  Discrete-Time Processing of Continuous-Time Signals
Because of the desirable properties of discrete-time systems, they are often used in circumstances in 
which the goal is to process (filter) a continuous-time input to produce a continuous-time output. This 
involves sampling to produce a discrete-time signal, discrete-time filtering, and, finally, the conversion 
of the resulting discrete-time signal to a continuous-time signal. Since the input and output signals are 
continuous time, the process is, in fact, equivalent to continuous-time filtering (even though it is imple-
mented in discrete time).
Ordinarily, such a process begins by passing the original signal through a continuous-time anti-alias-
ing filter to ensure that the signal x(t) to be processed is bandlimited (or, at least, nearly so). The signal 
x(t) is then sampled at the Nyquist rate (or greater) to produce the discrete-time signal x[n] = x(nTs). This 
signal is then passed through the discrete-time filter H(e jω) to produce an output y[n]. The signal y[n] 
is then converted to a continuous-time signal y(t) in such a manner that y(nTs) = y[n]. This process (of 
digital-to-analog conversion) may be viewed as consisting of first generating ys(t), an impulse-sampled 
version of y[n]. The frequency response of ys(t) is given by
	
Y j
T
Y j
m
s
s
s
m
(
)
( (
)).
Ω
Ω
Ω
=
−
=−∞
∞
∑
1
	
© 2011 by Taylor and Francis Group, LLC

25-40 
Fundamentals of Industrial Electronics
To complete the process, the signal ys(t) is passed through a “reconstruction” filter (a continuous-time 
lowpass filter with a gain of Ts in the passband) to remove all but the m = 0 term in the above expression.
Under these circumstances, it may be shown that the equivalent continuous-time filter He(jΩ) (with 
input x(t) and output y(t)) has frequency response
	
H
j
H e
T
T
e
j T
s
s
s
(
)
(
),
,
.
Ω
Ω
Ω
=
−
<
<



π
π
0
otherwise
	
That is, in the range −(π/Ts) < Ω < (π/Ts), He(jΩ) is simply a frequency-scaled version of the discrete-time 
frequency response H(e jω), where the frequencies are related by ω = ΩTs or Ω = ω/Ts. It is noted that 
because of the requirement for bandlimiting, true highpass and bandstop filters cannot be constructed 
in this manner.
References
Ambardar, A. 2007. Digital Signal Processing: A Modern Introduction, Nelson-Thomson Canada, Toronto, 
Canada.
Antoniou, A. 1993. Digital Filters: Analysis, Design, and Applications, 2nd edn., McGraw-Hill, New York.
Baher, H. 2001. Analog and Digital Signal Processing, 2nd edn., Wiley, Hoboken, NJ.
Chen, C.-T. 2004. Signals and Systems, 3rd edn., Oxford University Press, New York.
ElAli, T. S. 2004. Discrete Systems and Digital Signal Processing with MATLAB®, CRC Press, Boca 
Raton, FL.
Gajić, Z. 2003. Linear Dynamic Systems and Signals, Pearson Higher Education, Upper Saddle River, NJ.
Ingle, V. J. and Proakis, J. G. 2007. Digital Signal Processing Using MATLAB®, 2nd edn., Nelson-Thomson 
Canada, Toronto, Canada.
Kuo, S. M. and Gan, W.-S. 2005. Digital Signal Processors: Architectures, Implementations, and Applications, 
Pearson Higher Education, Upper Saddle River, NJ.
Lam, H. Y.-F. 1979. Analog and Digital Filters: Design and Realization, Prentice-Hall, Englewood Cliffs, NJ.
Lathi, B. P. 2005. Linear Systems and Signals, 2nd edn., Oxford University Press, New York.
McClellan, J. H., Schafer, R. W., and Yoder, M. A. 2003. Signal Processing First, Pearson Higher Education, 
Upper Saddle River, NJ.
Mitra, S. J. 2006. Digital Signal Processing: A Computer Based Approach, 3rd edn., McGraw-Hill, New York.
Oppenheim, A. V. and Schafer, R. W. 1989. Discrete-Time Signal Processing, Prentice-Hall, Englewood 
Cliffs, NJ.
Oppenheim, A. V. and Schafer, R. W. 2010. Discrete-Time Signal Processing, 3rd edn., Pearson Higher 
Education, Upper Saddle River, NJ.
Paarmann, L. D. 2001. Design and Analysis of Analog Filters: A Signal Processing Perspective, Springer, 
Berlin, Germany.
Proakis, J. G. and Manolakis, D. G. 2007. Digital Signal Processing: Principles, Algorithms, and Applications, 
4th edn., Pearson Higher Education, Upper Saddle River, NJ.
Schlichthärle, D. 2000. Digital Filters: Basics and Design, Springer, Berlin, Germany.
Sherrick, J. D. 2005. Concepts in Systems and Signals, 2nd edn., Prentice-Hall, Englewood Cliffs, NJ.
Stearns, S. D. 2003. Digital Signal Processing with Examples in MATLAB®, CRC Press, Boca Raton, FL.
© 2011 by Taylor and Francis Group, LLC

26-1
26.1  Introduction
Analog filters are essential in many different systems that electrical engineers are required to design 
in their engineering career. Filters are widely used in communication technology as well as in other 
applications. Although we discuss and talk a lot about digital systems nowadays, these systems always 
contain one or more analog filters internally or an interface with the analog world [SV01].
There are many different types of filters such as Butterworth filter, Chebyshev filter, inverse Chebyshev 
filter, Cauer elliptic filter, etc. The characteristic responses of these filters are different. The Butterworth 
filter is flat in the stop-band but does not have a sharp transition from the pass-band to the stop-band 
while the Chebyshev filter has a sharp transition from the pass-band to the stop-band but it has the 
ripples in the pass-band. Oppositely, the inverse Chebyshev filter works almost the same way as the 
Chebyshev filter, but it does have the ripples in the stop-band rather than the pass-band. The Cauer filter 
has ripples in both pass-band and stop-band; however, it has lower order [W02,KAS89]. The analog 
filter is a broad topic, and this chapter will focus more on the methodology of synthesizing analog filters 
only (Figures 26.1 and 26.2).
Section 26.2 will present methods to synthesize four different types of these low-pass filters. Then 
we will go through design example of a low-pass filter that has 3 dB attenuation in the pass-band, 30 dB 
attenuation in the stop-band, the pass-band frequency at 1000 rad/s and the stop-band frequency at 
3000 rad/s to see four different results corresponding to four different synthesizing methods.
26.2  Methods to Synthesize Low-Pass Filter
26.2.1  Butterworth Low-Pass Filter
ωp—pass-band frequency
ωs—stop-band frequency
αp—attenuation in pass-band
αs—attenuation in stop-band
26
Analog Filter Synthesis
26.1	 Introduction.....................................................................................26-1
26.2	 Methods to Synthesize Low-Pass Filter........................................26-1
Butterworth Low-Pass Filter  •Chebyshev Low-Pass Filter  •  Inverse 
Chebyshev Low-Pass Filter  •  Cauer Elliptic Low-Pass Filter
26.3	 Frequency Transformations.........................................................26-10
Frequency Transformations Low-Pass to High-Pass  •  Frequency 
Transformations Low-Pass to Band-Pass  •  Frequency 
Transformations Low-Pass to Band-Stop  •  Frequency 
Transformation Low-Pass to Multiple Band-Pass
26.4	 Summary and Conclusion............................................................26-13
References...................................................................................................26-14
Nam Pham
Auburn University
Bogdan M. 
Wilamowski
Auburn University
© 2011 by Taylor and Francis Group, LLC

26-2 
Fundamentals of Industrial Electronics
Butterworth response (Figure 26.3):
	
T j
n
n
(
)
/
ω
ω
ω
2
2
0
2
1
1
=
+(
)
There are three basic steps to synthesize any type of low-pass filters. The first step is calculating the 
order of a low-pass filter. The second step is calculating poles and zeros of a low-pass filter. The third step 
is designing circuits to meet pole and zero locations; however, this part is another topic of analog filters, 
so it will be not be covered in this work [W90,WG05,WLS92].
Following are steps to design Butterworth low-pass filter:
Step 1—Calculate order of filter:
	
n
n
s
p
s
p
=
−
−
log[(
)(
)]
log(
/
)
/
/
/
10
1 10
1
10
10
1 2
α
α
ω ω
(  needs to be roounded up to integer value)
[dB]
–20
–40
Magnitude
[dB]
–20
–40
Magnitude
FIGURE 26.1  Butterworth filter (left), Chebyshev filter (right).
[dB]
–20
–40
Magnitude
[dB]
–20
–40
Magnitude
FIGURE 26.2  Inverse Chebyshev filter (left), Cauer elliptic filter (right).
© 2011 by Taylor and Francis Group, LLC

Analog Filter Synthesis 
26-3
Step 2—Calculate pole and zero locations:
Angle if n is odd:
	
Ω= ±
°
=
−
k
n
k
n
180
0 1
1
2
;
, ,
,
…
Angle if n is even:
	
Ω= ±
+




°
=
−
0 5
180
0 1
2
2
.
;
, ,
,
k
n
k
n
…
Normalized pole locations:
	
a
b
k
k
= −
= ±
=
cos( );
sin( );
(
)
Ω
Ω
ω0
1
	
ω
ω ω
α
α
0
1 2
10
10
1 4
10
1
10
1
1
2
=
−
−
=
(
)
[(
)/(
)]
;
/
/
/
/(
)
p
s
n
k
k
s
p
Q
a
Step 3—Design circuits to meet pole and zero locations (not covered in this work) (Figure 26.4).
Example 26.1:  Design the Low-Pass Butterworth Filter Assuming 
𝛂p = 3 dB, 𝛂s = 30 dB, 𝛚p = 1000 rad/s, 𝛚s = 3000 rad/s
Step 1—Calculate order of filter:
	
n
n
=
−
−
=
⇒
=
log[(10
1)(10
1)]
log(3000 1000)
3.1456
4
30/10
3/10
1/2
/
Step 2—Calculate pole and zero locations.
Normalized values of poles and ω0 and Q:
−0.38291 + 0.92443i
1.00059
1.30656
−0.38291 − 0.92443i
1.00059
1.30656
−0.92443 + 0.38291i
1.00059
0.54120
−0.92443 − 0.38291i
1.00059
0.54120
Normalized values of zeros ⇒ none.
0 dB
αs
ωs
αp
ωp
FIGURE 26.3  Butterworth filter characteristic.
© 2011 by Taylor and Francis Group, LLC

26-4 
Fundamentals of Industrial Electronics
26.2.2  Chebyshev Low-Pass Filter
ωp—pass-band frequency
ωs—stop-band frequency
αp—attenuation in pass-band
αs—attenuation in stop-band
Chebyshev response (Figure 26.5):
	
T j
Cn
(
)
/(
( ))
ω
ε
ω
2
2
2
1
1
=
+
	
Step 1—Calculate order of filter:
	
n
s
p
s
p
s
p
=
−
−
+
−
ln[ *(
)/(
)]
log[(
)
((
)
/
/
/
/
/
4
10
1
10
1
1
10
10
1 2
2
2
α
α
ω ω
ω
ω
)
]
/
1 2
(  needs to be roundedup to integer value)
n
	
Magnitude
Phase
s-plane
[dB]
–20
–40
–90
–180
–270
FIGURE 26.4  Pole-zero locations, magnitude response, and phase of Butterworth filter.
Frequencies at which
Cn= 0
Frequencies at which
|Cn| = 1
|T6(jω)|
Is here
Is here
1
0
0
1/√1+ε2
FIGURE 26.5  Chebyshev filter characteristic.
© 2011 by Taylor and Francis Group, LLC

Analog Filter Synthesis 
26-5
Step 2—Calculate pole and zero locations:
	
Ω=
° +
° +
−
°
90
90
1 180
n
k
n
(
)
	
	
ε
γ
ε
α
=
−


=
−
10
1
1
10
1 2
1
p
n
/
/
;
sinh ( / )
	
	
a
b
a
b
Q
a
k
k
k
k
k
K
k
k
=
=
=
+
=
sinh( )cos( );
cosh( )sin( );
;
γ
γ
ω
ω
Ω
Ω
2
2
2
	
Step 3—Design circuits to meet pole and zero locations (not covered in this work) (Figure 26.6).
Example 26.2:  Design the Low-Pass Chebyshev Filter Assuming 
𝛂p = 3 dB, 𝛂s = 20 dB, 𝛚p = 1000 rad/s, 𝛚s = 3000 rad/s
Step 1—Calculate order of filter:
	
n =
−
−
+
ln[4*(10
1) (10
1)]
log[(3000 1000)
((3000 1
30/10
3/10
1/2
2
/
/
/
000 ) 1)
]
2.3535
3
2 −
=
⇒
=
1/2
n
	
Step 2—Calculate pole and zero locations.
Normalized values of poles and ω0 and Q:
−0.14931 + 0.90381i
0.91606
3.06766
−0.14931 − 0.90381i
0.91606
3.06766
−0.29862
Normalized values of zeros ⇒ none.
s-plane
Magnitude
Phase
[dB]
–30
–40
–90
–180
FIGURE 26.6  Pole-zero locations, magnitude response, and phase of Chebyshev filter.
© 2011 by Taylor and Francis Group, LLC

26-6 
Fundamentals of Industrial Electronics
26.2.3  Inverse Chebyshev Low-Pass Filter
ωp—pass-band frequency
ωs—stop-band frequency
αp—attenuation in pass-band
αs—attenuation in stop-band
Inverse Chebyshev response (Figure 26.7):
	
T
j
C
C
IC
n
n
(
)
( / )
( / )
ω
ε
ω
ε
ω
2
2
2
2
2
1
1
1
=
+
	
The method to design the inverse Chebyshev low-pass filter is almost the same as the Chebyshev low-
pass filter. It is just slightly different.
Step 1—Calculate order of filter.
n = order of the Chebyshev filter
Step 2—Calculate pole and zero locations:
	
P
a
b
i
n
i
k
np
ic
k
k
i
=
+
=
=
−
<
1
1
2
2
1 1 3 5
,
cos[
* /(
)];
: , ,
find zeros
ω
Π
…
	
Note: two conjugate poles on the imaginary axis.
Step 3—Design circuits to meet pole and zero locations (not covered in this work) (Figure 26.8).
Example 26.3:  Design the Low-Pass Inverse Chebyshev Filter Assuming 
𝛂p = 3 dB, 𝛂s = 30 dB, 𝛚p = 1000 rad/s, 𝛚s = 3000 rad/s
Step 1—Calculate order of filter:
	
n =
−
−
+
ln[4*(10
1) (10
1)]
log[(3000 1000)
((3000 1
30/10
3/10
1/2
2
/
/
/ 000 ) 1)
]
2.3535
3
2
1/2
−
=
⇒
=
n
	
Passband
Stopband
Gain=
c
√1 + c2
FIGURE 26.7  Inverse Chebyshev filter characteristic.
© 2011 by Taylor and Francis Group, LLC

Analog Filter Synthesis 
26-7
Step 2—Calculate pole and zero locations.
Normalized values of poles and ω0 and Q:
−0.6613 + 1.29944i
1.45803
1.10240
−0.6613 − 1.29944i
1.45803
1.10240
−1.60734
Normalized values of zeros:
3.4641i
3.4641i
3.4641
−3.4641i
−3.4641i
3.4641
26.2.4  Cauer Elliptic Low-Pass Filter
Cauer elliptic response (Figure 26.9):
	
T jw
R w L
n
(
)
( , )
2
2
2
1
1
=
+ ε
	
Designing the Cauer elliptic filter is more complicated than designing the three previous filters. 
In order to calculate the transfer function of this filter, a mathematical process is summarized as below. 
Although the low-pass Cauer elliptic filter has ripples in both stop-band and pass-band, it has lower 
order than the three previous filters (Figure 26.10), that is, the advantage of the Cauer elliptic filter:
	
k
p
s
= ω
ω 	
(26.1)
	
′ =
−
k
k
1
2
	
(26.2)
	
q
k
k
0
0 5 1
1
=
−
′
+
′
. (
)
(
)
	
(26.3)
s-plane
Phase
Magnitude
[dB]
–20
–40
–180
–90
FIGURE 26.8  Pole-zero locations, magnitude response, and phase of inverse Chebyshev filter.
© 2011 by Taylor and Francis Group, LLC

26-8 
Fundamentals of Industrial Electronics
	
q
q
q
q
q
=
+
+
+
0
0
5
0
9
0
13
2
15
150
	
(26.4)
	
D
s
p
=
−
−
10
1
10
1
0 1
0 1
.
.
α
α
	
(26.5)
	
n
D
q
≥log(
)
log( / )
16
1
	
(26.6)
	
Λ =
+
−
1
2
10
1
10
1
0 05
0 05
n
p
p
ln
.
.
α
α
	
(26.7)
Magnitude
Phase
[dB]
–20
–40
–90
0
s-plane
FIGURE 26.10  Pole-zero locations, magnitude response, and phase of Cauer elliptic filter.
1
G=
√1+ε2
1
G=
√1+ε2Li
2
FIGURE 26.9  Cauer elliptic filter characteristic.
© 2011 by Taylor and Francis Group, LLC

Analog Filter Synthesis 
26-9
	
σ0
1 4
1
0
2
1
2
1
1
2
1
2
2
=
−
+
+
−
+
=
∞
∑
q
q
m
q
m
m
m m
m
m
m
/
(
)
(
)
sinh[(
) ]
(
)
cosh(
)
Λ
Λ
m=
∞
∑
1
	
(26.8)
	
ω
σ
σ
=
+
(
)
+






1
1
0
2
0
2
k
k
	
(26.9)
	
Ωi
m
m m
m
m
m
q
q
m
n
q
m
=
−
+
+
−
+
=
∞
∑
2
1
2
1
1
2
1
2
1 4
1
0
2
/
(
)
(
)
sinh((
)
/ )
(
)
cosh
πµ
πµ
n
m




=
∞
∑
1
	
(26.10)
	
µ =
−



=
i
n
i
n
i
r
for odd 
for even 
1
2
1 2, , ...,
	
(26.11)
	
V
k
k
i
i
i
=
−
−






(
)
1
1
2
2
Ω
Ω
	
(26.12)
	
A
i
01
2
1
= Ω	
(26.13)
	
B
V
i
i
i
i
0
0
2
2
0
2
2 2
1
=
+
+
(
)
(
)
(
)
σ
ω
σ
Ω
Ω
	
(26.14)
	
B
V
i
i
i
1
0
0
2
2
2
1
=
+
σ
σ Ω	
(26.15)
	
H
B
A
B
A
i
i
i
r
i
i
i
r
p
0
0
0
0
1
0 05
0
0
1
10
=



=
−
=
∏
∏
σ
α
for odd 
for even 
n
n
.




	
(26.16)
Example 26.4:  Design the Low-Pass Cauer Elliptic Filter Assuming 
𝛂p = 3 dB, 𝛂s = 30 dB, 𝛚p = 1000 rad/s, 𝛂s = 3000 rad/s
n = 1.9713 ⇒ n = 2. This filter is the second order low pass filter.
Normalized values of poles and ω0 and Q:
−0.31554 + 0.97313i
0.85360
1.35259
−0.31554 + 0.97313i
0.85360
1.35259
Normalized values of zeros:
4.18154i
4.18154i
4.18154
−4.18154i
−4.18154i
4.18154
© 2011 by Taylor and Francis Group, LLC

26-10 
Fundamentals of Industrial Electronics
26.3  Frequency Transformations
Four typical methods of deriving a low-pass transfer function that satisfies a set of given specifications 
are presented. However, there are a lot of applications in the real world of designing, which require not 
only the low-pass filters but also the band-pass filters, the high-pass filters, and the band-rejection fil-
ters. A designer can design any type of filter by designing a low-pass filter first. When a low-pass filter 
is achieved, the desired filter can be derived by “frequency transformation.” In other words, the under-
standing of methods to design a low-pass filter is the basic but not the trivial task.
26.3.1  Frequency Transformations Low-Pass to High-Pass
Z s
S
s
j
j
( )
;
;
=
=
=
⇒
−≤
≤
−
1
1
1
1
1
Ω
Ω
Ω
ω
ω
frequency of low-pass passband
1
1
≤
≤
ω
frequency of high-pass passband
Frequency transformation transforms the pass-band of the low-pass, centered around Ω = 0, into that 
of the high-pass, centered around ω = ∞ (Figure 26.11). Similarly, it transforms the low-pass stop-band 
that is centered around Ω = ∞ into that of the high pass, centered around ω = 0. Consequently, the fre-
quency transformation function Z(s) has a zero in the center of the pass-band of the high-pass (at ω = ∞) 
and a pole in the center of the high-pass, stop-band (at ω = 0) [SV01]:
T S
S
S Q
T s
s
Qs
s
( )
(
/ )
( )
( / )
(
/
)
( /
=
+
+
⇒
=
+
+
=
ω
ω
ω
ω
ω
ω
ω
0
2
2
0
0
2
0
2
2
0
0
2
2
0
2
1
1
)
( /
)
+
+
s
Q
s
ω0
2
2
T(S): low-pass transfer function; T(s): high-pass transfer function.
26.3.2  Frequency Transformations Low-Pass to Band-Pass
Z s
S
s
Bs
s
B
s
B
B
c
c
c
c
c
c
( )
(
)
;
;
=
=
+
=
+
⇒
=
−
=
=
−
2
2
2
2
2
1
2
2
1
ω
ω
ω
ω
ω
ω
ω
ω
ω ω
ω
ω
Ω
Frequency transformation transforms the pass-band of the low-pass, centered around Ω = 0, into 
that of the band-pass, centered around ω = ωc. Similarly, it transforms the low-pass stop-band that is 
1
ω
1
Ω
–1
–1
1
s
S=
FIGURE 26.11  Frequency transformations low-pass to high-pass.
© 2011 by Taylor and Francis Group, LLC

Analog Filter Synthesis 
26-11
centered around Ω = ∞ into that of the band-pass, centered around ω = 0 (Figure 26.12). Consequently, 
the frequency transformation function Z(s) has zeros in the center of the pass-band of the band-pass 
(at ω = ± ωc) and poles in the center of the band-pass, stop-band (at ω = 0 and ω = ∞) [SV01]:
T S
S
S Q
T s
s B
s
Bs Q
B
c
( )
(
/ )
( )
(
/ )
(
=
+
+
⇒
=
+
+
+
ω
ω
ω
ω
ω
ω
ω
0
2
2
0
0
2
2
2
0
2
4
0
3
2
2
0
2
2
2
0
2
4
)
(
/ )
s
B
s Q
c
c
+
+
ω
ω
ω
T(S): low-pass transfer function; T(s): band-pass transfer function.
26.3.3  Frequency Transformations Low-Pass to Band-Stop
Z s
S
Bs
s
B
B
c
c
c
( )
;
;
=
=
+
⇒
=
−
−
=
=
−
2
2
2
2
2
1
2
2
1
ω
ω
ω
ω
ω
ω ω
ω
ω
Ω
Frequency transformation transforms the pass-band of the low-pass, centered around Ω = 0, into 
that of the band-stop, centered around ω = 0 and ω = ∞ (Figure 26.13). Similarly, it transforms the 
low-pass, stop-band that is centered around Ω = ∞ into that of the band-stop, centered around ω = ωc. 
B
Ω
ω
ω1
ωc
ω2
Ω0
–Ω0
FIGURE 26.13  Frequency transformations low-pass to band-stop.
B
Ω
ω
ω1
ωc
ω2
Ω0
–Ω0
FIGURE 26.12  Frequency transformations low-pass to band-pass.
© 2011 by Taylor and Francis Group, LLC

26-12 
Fundamentals of Industrial Electronics
Consequently, the frequency transformation function Z(s) has zeros in the center of the pass-band of the 
band-stop (at ω = 0 and ω = ∞) and poles in the center of the band-stop, stop-band (at ω = ± ωc) [SV01]:
T S
S
S Q
T s
s
s
s
c
c
( )
(
/ )
( )
(
=
+
+
⇒
=
+
+
+
ω
ω
ω
ω
ω ω
ω ω
ω
ω
0
2
2
0
0
2
0
2 4
0
2
2 2
0
2
4
0
2 4
2
0
3
2
0
2
2
2
0
2
4
0
2
2
Bs Q
B s
B
s Q
c
c
c
/ )
(
)
(
/ )
+
+
+
+
ω ω
ω
ω
ω ω
26.3.4  Frequency Transformation Low-Pass to Multiple Band-Pass
Frequency transformation transforms the pass-band of the low-pass, centered around Ω = 0, into that 
of the multiple band-pass, centered around ω = 0 and ω = ωz1. Similarly, it transforms the low-pass, 
stop-band that is centered around Ω = ∞ into that of the multiple band-pass, centered around ω = ωp1 
and ω = ∞. Consequently, the frequency transformation function Z(s) has zeros in the center of the pass-
band of multiple band-pass and at ωz1 (at ω = 0 and ω = ±ωz1) and poles in the center of the band-stop of 
multiple pass-band (at ω = ±ωc and ω = ∞) [SV01] (Figure 26.14):
Z s
S
s s
B s
B
z
P
z
P
( )
(
)
(
)
(
)
(
)
=
=
+
+
⇒
=
−
−
2
1
2
2
1
2
2
1
2
2
1
2
ω
ω
ω ω
ω
ω
ω
Ω
Transfer functions from the low-pass frequency S to the frequency s of other types of filters are recog-
nized and can be written under the following form:
Z s
H s
s
s
s
s
s
z
z
zn
p
p
( )
(
)(
)
(
)
(
)(
)
(
=
+
+
+
+
+
+
2
1
2
2
2
2
2
2
2
1
2
2
2
2
2
ω
ω
ω
ω
ω
ω
…
…
pn
2 )
or
Ω( )
(
)(
)
(
)
(
)(
)
(
ω
ω
ω
ω
ω
ω
ω
ω
ω
ω
ω
ω
ω
=
−
−
−
−
−
−
H
z
z
zn
p
p
2
1
2
2
2
2
2
2
2
1
2
2
2
2
2
…
…
pn
2 )
Z(s) has zeros where the desired filter has pass-bands and poles where it has stop-bands. The function 
Z(s) is called Foster Reactance function.
Ω
ω
ω1
ωz0
ωz1
ωp1
ω2
ω3
Ω0
–Ω0
FIGURE 26.14  Frequency transformation low-pass to multiple band-pass.
© 2011 by Taylor and Francis Group, LLC

Analog Filter Synthesis 
26-13
Example 26.5:  Writing Transfer Function of the Filter in Figure 26.15 
Assuming 𝛂p = 2 dB, 𝛂s = 30 dB, 𝛚1 = 1 KHz, 𝛚2 = 4 KHz, 𝛚3 = 6 KHz
We can write the transfer function of the filter Figure 26.15 as following
	
Z s
Hs s
s
H
z
p
z
p
( )
(
)
(
)
( )
(
)
(
)
=
+
+
=
−
−
2
2
2
2
2
2
2
2
ω
ω
ω
ω ω
ω
ω
ω
or
Ω
The transfer function has zeros at ω = 0, ω = ωz, and poles at ω = ωp and ω = ∞.
At corner frequencies ω1 = 1 kHz, ω2 = 4 kHz, and ω3 = 6 kHz, the values of Ω(ω) are equal to 1, −1, 
and  1, respectively. Therefore, the transformation Ω(ω) can be rewritten into multi-equations corre-
sponding to ω = ω1, ω2, ω3. Three equations with three unknowns always have solutions
1
1
1
2
2
1
2
2
=
−
−
H
Z
p
ω ω
ω
ω
ω
(
)
−=
−
−
1
2
2
2
2
2
2
2
H
Z
p
ω ω
ω
ω
ω
(
)
1
3
3
2
2
3
2
2
=
−
−
H
Z
p
ω ω
ω
ω
ω
(
)
ω
ω
z
p
H
2
2
22
8
1
3
=
=
=








; so the Foster Transfer Function is S
s
s
s
=
+
+
( / )
(
/ )
1 3
22 3
8
3
2
26.4  Summary and Conclusion
Analog filters have been used broadly in communication. Understanding the methods to synthesizing ana-
log filters is extremely important and is the basic step in designing analog filters. Four different ­synthesizing 
methods were presented, each method will result in different characteristics of filters. This chapter also pre-
sented steps to design other types of filters from the low-pass filter by writing the frequency transfer function.
1 kHz
30 dB
2 dB
4 kHz
ωp
ωz
6 kHz
FIGURE 26.15  Frequency transformation by foster reactance function.
© 2011 by Taylor and Francis Group, LLC

26-14 
Fundamentals of Industrial Electronics
References
[KAS89] M.R. Kobe, J. Ramirez-Angulo, and E. Sanchez-Sinencio, FIESTA—A filter educational synthesis 
teaching aid, IEEE Trans. Educ., 32(3), 280–286, August 1989.
[SV01] R. Schaumann and M.E. Van Valkenburg, Analog Filter Design, Oxford University Press, Oxford, 
U.K., 2001.
[W02] S. Winder, Analog and Digital Filter Design, Newnes, Woburn, MA, 2002.
[W90] B.M. Wilamowski, A filter synthesis teaching-aid, in: Proceedings of the Rocky Mountain ASEE 
Section Meeting, Golden, CO, April 6, 1990.
[WG05] B.M. Wilamowski and R. Gottiparthy, Active and passive filter design with MATLAB, Int. J. Eng. 
Educ., 21(4), 561–571, 2005.
[WLS92] B.M. Wilamowski, S.F. Legowski, and J.W. Steadman, Personal computer support for teaching 
analog filter analysis and design courses, IEEE Trans. Educ., E-35(4), 351–361, 1992.
© 2011 by Taylor and Francis Group, LLC

27-1
27.1  Introduction
There are many ways to implement filters. These could be passive LC filters [JW09], cascade active fil-
ters using operational amplifiers (op-amps), active filters using operational transconductance amplifiers 
(OTAs) [AWD07,TDU03], or switched capacitor or switched current filters [J76,P08]. As a part of the 
design process, the desired high-pass, band-pass, or band-stop prototype must be often converted to the 
low-pass filter prototype [B74].
Many different circuits can be used to realize any given transfer function. For purposes of this chap-
ter, several of the most popular types of realizations are presented. Much more detailed information on 
various circuit realizations and the advantages of each may be found in the literature, in particular Van 
Valkenburg [V82], Huelseman and Allen [HA80], and Chen [C86]. Generally, the design trade-offs in 
making the choice of the circuit to be used for the realization involve considerations of the number of 
elements required, the sensitivity of the circuit to changes in component values, and the ease of tuning 
the circuit to given specifications. Accordingly, limited information is included about these characteris-
tics of the example circuits in this chapter.
Each of the circuits described here is commonly used in the realization of active filters. When 
implemented as shown and used within the appropriate gain and bandwidth specifications of the 
amplifier, they will provide excellent performance. Computer-aided filter design programs are avail-
able that simplify the process of obtaining proper element values and simulation of the resulting 
circuits [KAS89,MLS92].
27
Active Filter 
Implementation
27.1	 Introduction..................................................................................... 27-1
27.2	 Circuit Realization........................................................................... 27-2
First-Order Low-Pass  •  First-Order High-Pass  •   
Two Popular Second-Order Low-Pass Circuits  •   
Second-Order High-Pass Filter
27.3	 Circuits with Placement of Poles and Zeros................................27-4
High-Pass Filter  •  High-Pass Filter  •  Low-Pass Filter  •  High-Pass 
Filter  •  Band-Pass Filter  •  Band-Pass Filter  •  Band-Stop Filter  •   
Band-Stop Filter
27.4	 Design Example...............................................................................27-8
27.5	 Summary and Conclusion............................................................ 27-15
References................................................................................................... 27-15
Nam Pham
Auburn University
Bogdan M. 
Wilamowski
Auburn University
John W. Steadman
University of South 
Alabama
© 2011 by Taylor and Francis Group, LLC

27-2 
Fundamentals of Industrial Electronics
27.2  Circuit Realization
Various electronic circuits can be found to implement any given transfer function. Cascade filters and lad-
der filters are two of the basic approaches for obtaining a practical circuit. Cascade realizations are much 
easier to design and to tune, but ladder filters are less sensitive to element variations. In cascade realiza-
tions, the transfer function is simply factored into first- and second-order parts. Circuits are built for the 
individual parts and then cascaded to produce the overall filter. For simple to moderately complex filter 
designs, this is the most common method, and the remainder of this section is devoted to several examples 
of the circuits used to obtain the first- and second-order filters. For very high-order transfer functions, 
ladder filters should be considered, and further information can be obtained by consulting the literature.
In order to simplify the circuit synthesis procedure, very often ω0 is assumed to be equal to one, and 
then after a circuit is found, the values of all capacitances in the circuit are divided by ω0. In general, the 
following magnitude and frequency transformations are allowed:
	
R
K R
C
C
K K
L
K
L
K
new
M
old
new
old
F
M
new
M
old
F
=
=
=
or
or
	
(27.1)
where KM and KF are magnitude and frequency scaling factors, respectively.
Cascade filter designs require the transfer function to be expressed as a product of first- and second-
order terms. For each of these terms, a practical circuit can be implemented. Examples of these circuits 
are presented. In general, the following first- and second-order terms can be distinguished.
27.2.1  First-Order Low-Pass (Figure 27.1)
27.2.2  First-Order High-Pass
While several passive realizations of first-order filters are possible (low-pass, high-pass, and lead-lag), 
the active circuits shown here are inexpensive and avoid any loading of the other filter sections when 
the individual circuits are cascaded. Consequently, these circuits are preferred unless there is some rea-
son to avoid the use of the additional op-amp. Note that a second-order filter can be realized using one 
op-amp as shown in the following paragraphs; so, it is common practice to choose even-order transfer 
functions, thus avoiding the use of any first-order filters (Figure 27.2).
27.2.3  Two Popular Second-Order Low-Pass Circuits
This filter is non-inverting, and unity gain, i.e., H must be one, and the scaling factors shown in Equation 
27.1 should be used to obtain reasonable element values. This is a very popular filter for realizing second-
order functions because it uses a minimum number of components, and since the operation amplifier is 
in the unity gain configuration, it has very good bandwidth (Figure 27.3).
Another useful configuration for second-order low-pass filters uses the op-amp in its inverting 
“infinite gain” mode, as shown in Figure 27.4.
r1
c1
s+ω
–ω
σ
jω
×
Assumption: r1=1  then  c1= 1/ω0; r2= |H|ω0.
Hω0
T(s)=
r2
–
+
FIGURE 27.1  Low-pass circuit with one real pole. (This filter is inverting, i.e., H must be negative, and the scaling 
factors shown in Equation 27.1 should be used to obtain reasonable values for the components.)
© 2011 by Taylor and Francis Group, LLC

Active Filter Implementation 
27-3
This circuit has the advantage of relatively low sensitivity of ω0 and Q to variations in component val-
ues. In this configuration, the op-amp’s gain-bandwidth product may become a limitation for high-Q and 
high-frequency applications [B74]. There are several other circuit configurations for low-pass filters. The 
references given at the end of the chapter will guide the designer to alternatives and the advantages of each.
27.2.4  Second-Order High-Pass Filter
Second-order high-pass filters may be designed using circuits very much like those shown for the low-
pass realizations. For example, the Sallen–Key high-pass filter is shown (Figures 27.5 through 27.7).
r1
c1
s + ω
–ω
σ
jω
×
Hs
T(s) =
r2
Assumption: r1= 1  then  c1= 1/ω0; r2= |H|ω0.
–
+
FIGURE 27.2  High-pass circuit with one real pole and one zero at the origin. (This filter is inverting, i.e., H must be 
negative, and the scaling factors shown in Equation 27.1 should be used to obtain reasonable values for the components.)
r1
c1
c2
s2+ (ω0s/Q)+
*
*
σ
jω
Assumption: r1=r2=1   then   c1=2Q/ω0: r2=1/(2Qω0).
Hω0
2
ω0
2
T(s)=
r2
–
+
FIGURE 27.3  Low-pass circuit with two conjugate poles.
r1
r3
c1
c2
σ
jω
r2
–
+
*
*
Assumption: r1= r2=r3=1  then   c1=3Q/ω0: r2=1/(3Qω0).
Hω0
2
T(s) =
s2+ (ω0s/Q)+ ω0
2
FIGURE 27.4  Low-pass circuit with two conjugate poles.
c1
c2
r2
r1
Assumption: r3=1; r1= r2= 1/ω0   then   r4= 2 – 1/Q; c1= c2= 1.
r4
–
+
r3
Hs2
T(s)=
*
*
σ
jω
s2+ (ω0s/Q)+ω0
2
FIGURE 27.5  High-pass circuit with two conjugate poles and two zeros at the origin.
© 2011 by Taylor and Francis Group, LLC

27-4 
Fundamentals of Industrial Electronics
The foregoing circuits provide a variety of useful first- and second-order filters. For higher order 
filters, these sections are simply cascaded to realize the overall transfer function desired. Additional 
detail about these circuits as well as other circuits used for active filters may be found in the references.
27.3  Circuits with Placement of Poles and Zeros
Assume that the low-pass filter function was already found. The next step to design filters is how circuits 
with different locations of pole and zeros are recognized. The list below are some typical circuits with 
their poles and zero locations.
27.3.1  High-Pass Filter (Figure 27.8)
	
T s
s
s
s Q
a
Q
Q
r
a
R
r
a
R
z
z
( )
(
/ )
;
;
;
;
=
+
+
+
=
+
+
=
+
=
=
2
2
2
0
0
2
2
2
0
1
1
1
4
2
1
ω
ω
ω
ω
ω
ω
2
3
4
1
2
2
2
3
4
2
1
1
1
1
2
1
=
=
+
=
=
=
−




=
=
r
R
r
a
R
r
C
C
C
C
;
;
;
;
;
ω
ω
c1
Assumption: c1= c2= 1; r1= 1/2Qω0)  then  r3= 1/Qω0);
c2
r2
r2= r4= 2Q/ω0.
r1
r3 r4
+
*
*
σ
jω
–
H (s2+ωz
2)
T(s)=
s2+ (ω0s/Q)+ω0
2
FIGURE 27.6  Band-stop circuit with two conjugate poles and two conjugate zeros. (The primary advantage of 
this circuit is that it requires a minimum number of components. For applications where no tuning is required and 
the Q is low, this circuit works very well. When the band-stop filter must be tuned, the three-operational-amplifier 
circuit is preferable.)
c2
Assumption: c1= c2= 1/ω0; r1= 1  then  r2= H; r5= r6= 2Q;
r3=Hω0
2/(2Qωz
2)
c1
r1
r3
r5
r4
r6
r2
+
–
–
+
–
+
H (s2+ωz
2)
T(s)=
s2+ (ω0s/Q)+ω0
2
FIGURE 27.7  Band-stop circuit with two conjugate poles and two conjugate zeros.
© 2011 by Taylor and Francis Group, LLC

Active Filter Implementation 
27-5
27.3.2  High-Pass Filter (Figure 27.9)
	
T s
K s
s
s Q
a
b
a
e
Q
z
Z
z
( )
(
)
(
/ )
;
.
.
;
(
=
+
+
+
>
=
= −
+
+
=
2
2
2
0
0
2
0
0
1 5
1 25
ω
ω
ω
ω
ω
ω
ω
b
C
C
eC
r
C C
r
r
b
d
r
e
r
e
R
r
R
a
b
a
a
b
b
+
=
=
=
=
=
+
+
=
2
1
1
1 1
2
1
2
1
0
1
2
1
2
)
;
;
;
(
/ )
;
ω
=
=
=
=
=
r
R
R
r
R
R
d
R
r
b
a
a
;
;
;
;
3
4
5
3
6
1
27.3.3  Low-Pass Filter (Figure 27.10)
	
T s
s
s Q
R
R
R
R
C
Q
C
Q
( )
(
/ )
;
;
;
;
=
+
+
=
=
=
=
=
=
ω
ω
ω
ω
ω
0
2
2
0
0
2
1
2
3
6
4
1
0
2
1
1
10
1
3
1
3
0
C3
C1
C4
R4
R1
R2
jω
σ
*
*
R3
+
–
C2
FIGURE 27.8  Circuit with two conjugate poles and two zeros at the origin.
C2
–
+
R3
R4
jω
σ
*
*
R5
R2
R1
R6
C1
FIGURE 27.9  Circuit with two conjugate poles and two zeros at the origin.
© 2011 by Taylor and Francis Group, LLC

27-6 
Fundamentals of Industrial Electronics
27.3.4  High-Pass Filter (Figure 27.11)
	
T s
s
s
s Q
a
Q
R
R
R
R
a
C
C
( )
(
/ )
;
;
=
+
+
=
−
=
=
=
=
−
=
=
2
2
0
0
2
1
2
0
3
4
1
2
3
1
1
1
1
1
ω
ω
ω
27.3.5  Band-Pass Filter (Figure 27.12)
	
T s
K
s
s
s Q
r
c
R
Q
R
( )
(
/ )
:
;
=
+
+
=
=
=
=
ω
ω
ω
ω
0
2
2
0
0
2
0
1
2
1
1
Assumption
and
then
r
R
Q
K
R
R
R
r
C
C
c
;
;
|
|
3
4
5
6
1
2
=
=
=
=
=
=
C1
C2
R4
R2
R1
jω
σ
*
*
R3
+
–
FIGURE 27.10  Circuit with two conjugate poles.
C2
C1
R1
R2
R3
R4
jω
σ
*
*
+
–
FIGURE 27.11  Circuit with two conjugate poles and two zeros at the origin.
© 2011 by Taylor and Francis Group, LLC

Active Filter Implementation 
27-7
27.3.6  Band-Pass Filter (Figure 27.13)
	
T s
H
s Q
s
s Q
C
C
R
R
Q
( )
(
/ )
(
/ )
(
/
=
+
+
=
=
=
=
ω
ω
ω
0
2
0
0
1
2
5
1
1
4
Assumption:
then
2
1
2
4
2
1
4
2
1
3
2
2
3
0
4
6
0
)
;
;
(
/
)
(
/
)
;
−
=
=
=
−
−−
=
−
H
R
R
R
Q
Q
H
R
ω
ω
27.3.7  Band-Stop Filter (Figure 27.14)
	
T s
s
s
s Q
C
C
C
a
Q
z
( )
(
/ )
;
=
+
+
+
=
=
=
=
+
ω
ω
ω
2
2
0
0
2
1
2
3
2
1
2
1
2
Assumption:
then
1
4
4
1
1
1
1
2
4
0
0
2
3
+
=
+
=
>
=
+
−
=
Q
Q
r
a
r
r
r
R
r
r
r
a
r
R
r
a
b
z
a
a
a
b
b
a
;
;
*
;
*
(
)
;
ω
ω
ω
a
a
a
R
r
R
r
a
;
;
4
5
2
=
=
C1
R3
R1
R5
R6
R2
R4
jω
σ
*
*
+
+
–
+
–
–
C2
FIGURE 27.12  Circuit with two conjugate poles and one zero at the origin.
jω
σ
*
*
R1
R4
R3
R2
+
–
R6
R5
C2
C1
FIGURE 27.13  Circuit with two conjugate poles and one zero at the origin.
© 2011 by Taylor and Francis Group, LLC

27-8 
Fundamentals of Industrial Electronics
27.3.8  Band-Stop Filter (Figure 27.15)
	
T s
s
w
s
s Q
a
b
c
Q b
z
z
p
z
p
( )
(
/ )
;
.
. ;
(
=
+
+
+
=
=
+
−
=
+
2
2
0
0
2
2
2
2
2
2
1 25
1 5
ω
ω
ω
ω
ω
ω
2
1
1
1
2
1
2
1
4
1
2
1
4
2
1
3
5
3
4
2
) ;
;
*
;
;
;
;
(
/
)
C
C
c C
R
C C
R
R
b
R
R
R
R
R
R R
P
=
=
=
=
=
=
=
ω
(
( / ))
( / ) ;
1
1
2
6
4
+
+
=
c
c
R
R
27.4  Design Example
Example 27.1
Design a low-pass Chebyshev filter that satisfies the following attenuation and gain specification αp = 
0.5 dB, αs = 40 dB, fp = 1000 Hz, fs = 2000 Hz and implement this design using second-order low-pass 
Sallen–Key non-inverting filters.
Step 1:
	
n
s
p
s
p
s
p
=
−
−
+ (
)−
(
)
ln[ *(
)/(
)]
log (
/
)
/
/
/
/
4
10
1 10
1
1
10
10
1 2
2
2
α
α
ω ω
ω
ω
1 2
0 5 10
40 10
1 2
4
10
1
10
1
2000 1000
/
. /
/
/
ln[ *(
)/(
)]
log[(
/




=
−
−
)
((
/
)
)
]
.
/
+
−
=
2000 1000
1
4 82
2
2
1 2
n = 5 = >. This is the fifth-order filter.
jω
σ
*
*
R4
R1
R5
R3
R2
C2
C6
+
–
C1
FIGURE 27.14  Circuit with two conjugate poles and two zeros.
jω
σ
*
*
R3
R6
R5
R4
R1
R2
C2
C1
+
–
FIGURE 27.15  Circuit with two conjugate poles and two zeros.
© 2011 by Taylor and Francis Group, LLC

Active Filter Implementation 
27-9
Step 2:
	
ε
γ
ε
α
=
−
=
−
=
=
=
−
−
[
]
[
]
.
;
sinh
/
sinh
/
/
. /
/
10
1
10
1
0 3493
1
10
1 2
0 5 10
1 2
1
p
n
11 3 493
5
0 3548
/ .
.
=
	
Ω=
° +
° +
−
° =
90
90
1180
1 885 2 5133 3 1416 3 7699 4 3982
n
k
n
(
)
.
, .
, .
, .
, .
(rad)
	
a
b
a
b
Q
a
k
k
k
k
k
k
k
k
=
=
=
+
=
sinh( )cos(
);
cosh( )sin(
);
;
γ
γ
ω
ω
Ω
Ω
2
2
2
Pole locations: −0.11196 ± j1.0116, −0.29312 ± j0.62518, −0.36232.
	
Qk
k
=
=
4 5450 1 1778 1 1778 4 5450
5
1 0177 0 69048 0 690
.
, .
, .
, .
, . ;
.
, .
, .
0
ω
48 1 0177 0 36232
, .
, .
.
This filter has two pairs of conjugate poles and one real pole. To design this filter, two circuits that have con-
jugate poles and another circuit having only one pole are needed. By picking up the proper circuits from 
the table above and cascading them together, the desired filter will be designed (Figures 27.16 and 27.17).
R2
R3
R4
R5
+
+
–
–
+
–
R1
1/(2Qω)
1/(2Qω)
2Q/ω
2Q/ω
k/p1
1/K
FIGURE 27.16  Cascading low-pass filter.
1.0 V
0.9 V
0.8 V
0.7 V
0.6 V
0.5 V
0.4 V
0.3 V
0.2 V
0.1 V
0.0 V
V [n002]
200°
160°
120°
80°
40°
0°
–40°
–80°
–120°
–160°
–200°
–240°
–280°
100 Hz
10 Hz
1 Hz
100 mHz
10 mHz
1 mHz
FIGURE 27.17  Output without scaling.
© 2011 by Taylor and Francis Group, LLC

27-10 
Fundamentals of Industrial Electronics
As a result from the p-spice simulation, the cut-off frequency is 1 Hz that was not scaled yet. Therefore, 
in order to get the cut-off frequency at 1 kHz, the values of capacitors and/or resistors have to be scaled 
by dividing and/or multiplying by a factor that is equal to the value of cut-off frequency (Figure 27.18).
Example 27.2
Two fundamental methods are the cascade approach and the simulation of lossless ladders. The fun-
damental reasons behind cascade realization are lower sensitivities to component tolerances, and the 
simplicity and flexibility of the design of low-order modules rather than of the complete high-order 
filter. The only condition to be satisfied for the approach to be valid is that the cascaded stages do not 
load each other so that they do not interact. However, the use of op-amps generally limits the frequency 
range over which our designs could be employed with predictable results. A problem arises with low-
frequency op-amp-based active RC filters because integrated capacitors are limited to around 30 pF. 
Much larger values consume too much silicon area on the integrated circuit chip. As a consequence, 
the design calls for huge resistors that also consume too much area and cause considerable noise. And 
another method that is also usable from the low audio range, but extends to applications at hundreds 
of megahertz, avoids op-amps altogether and instead obtains the required gain from transconductance 
amplifiers by using the concept of state variables.
Design the given Chebyshev low-pass filter and implement this filter by using transconductance 
amplifiers (Figures 27.19 and 27.20).
Step 1:  To implement this circuit by the transconductance amplifier, the state equations need to be writ-
ten and all current variables have to be converted into voltage variables by using R0 = 1 and IX = VX  /R0.
1.1 V
1.0 V
0.9 V
0.8 V
0.7 V
0.6 V
0.5 V
0.4 V
0.3 V
0.2 V
0.1 V
0.0 V
1 Hz
10 Hz
100 Hz
V [n002]
1 kHz
10 kHz
100 kHz
–280°
–240°
–200°
–160°
–120°
–80°
–40°
40°
80°
120°
160°
200°
0°
FIGURE 27.18  Output with scaling.
Chebyshev low-pass filter
Rin
AC ~
C1
C3
L2
L4
Rout
FIGURE 27.19  Low-pass filter.
© 2011 by Taylor and Francis Group, LLC

Active Filter Implementation 
27-11
	
V
V
V
R
I
SC
V
SC
R
V
R
I
V
1
1
2
1
1
1
2
1
1
1
=
−
−




⇒
=
+
−




⇒
in
in
in
in
in
( /
)
1
1
2
02
1
1
=
+
−




SC
R
V
R
V
R
( /
)
in
in
in
	
I
SL V
V
V
R
SL V
V
V
R
SL V
V
2
2
1
3
2
02
2
1
3
2
02
2
1
3
1
1
=
−
⇒
=
−
⇒
=
−
(
)
(
)
(
)
	
V
SC
I
I
V
SC
V
R
V
R
3
3
2
4
3
3
2
02
4
04
1
1
=
−
⇒
=
−




(
)
	
I
SL V
I R
I
SL
R
V
V
R
SL
R
V
out
out
out
4
4
3
4
4
4
3
4
04
4
3
1
1
=
−
⇒
=
+
⇒
=
+
(
)
Step 2:  Draw the circuit (Figure 27.21 and 27.22).
0 dB
–20 dB
–40 dB
–60 dB
–80 dB
–100 dB
–120 dB
–140 dB
–160 dB
–180 dB
10 mHz
100 mHz
1 Hz
V [4]
10 Hz
–360°
–330°
–300°
–270°
–240°
–210°
–180°
–150°
–120°
–90°
–60°
–30°
0°
FIGURE 27.20  Output of LC low-pass filter.
L2
V2
V3
V4
L4
Rout
~
Vin/Rin
+
+
+
+
V1
C1
C3
Rin
–
–
–
–
FIGURE 27.21  Low-pass filter with OTAs.
© 2011 by Taylor and Francis Group, LLC

27-12 
Fundamentals of Industrial Electronics
Example 27.3
Design the band-pass filter from the given Chebyshev low-pass filter and implement this filter by using 
transconductance amplifiers.
Step 1:  To transfer a low-pass filter to a band-pass filter, each passive element has to be converted. An 
inductor in a low-pass filter will become an inductor in series with a capacitor in a band-pass filter. And 
a capacitor in a low-pass filter will become an inductor in parallel with a capacitor in a band-pass filter 
(Figures 27.23 and 27.24).
Step 2:  To implement this circuit by the transconductance amplifiers the state equations need to be writ-
ten and all current variables have to be converted into voltage variables by using R0 = 1 and IX = VX/R0.
	
I
V
SL
I R
V R
SL
V
V
S L R
1
2
1
1 01
2 01
1
1
2
1
01
=
⇒
=
⇒
= ( /
)
	
V
SC
V
V
R
I
I
V
SC
V
V
R
V
R
V
R
2
2
2
1
3
2
2
2
1
01
3
03
1
1
=
−
−−




⇒
=
−
−
−

in
in
in
in



⇒
= +
−
−




V
R
SC R
V
R
V
R
V
R
2
2
1
01
3
03
1
in
in
in
in
	
I
SL V
V
V
I R
SL V
V
V R
V
S L
R
V
3
3
2
4
6
3 03
3
2
4
6
03
3
3
03
2
1
1
1
=
−
−
⇒
=
−
−
⇒
=
(
)
(
)
(
/
) (
−
−
V
V
4
6)
Rin
Rin
L1
L3
C4
C2
C6
L5
Rout
C
Chebyshev low-pass filter
Chebyshev band-pass filter
C
Rout
AC
AC ~
~
FIGURE 27.23  Low-pass filter and band-pass filter.
0 dB
–20 dB
–40 dB
–60 dB
–80 dB
–100 dB
–120 dB
–140 dB
–160 dB
–180 dB
10 mHz
100 mHz
V [4]
1 Hz
10 Hz
–180°
–150°
–120°
–90°
–60°
–30°
0°
30°
60°
90°
120°
150°
180°
FIGURE 27.22  Output of band-pass filter with OTAs.
© 2011 by Taylor and Francis Group, LLC

Active Filter Implementation 
27-13
	
V
I
SC
V
V
S R C
4
3
4
4
3
03
4
=
⇒
= (
)
	
I
V
SL
I R
V R
SL
V
V
S L
R
5
6
5
5 05
6
05
5
5
6
5
05
=
⇒
=
⇒
= (
/
)
	
V
R
R
SC
I
I
V
R
SR
C
V
R
V
R
out
out
out
out
6
6
3
5
6
6
3
03
5
05
1
1
= +
−
⇒
= +
−




(
)
Step 3:  Draw schematic (Figures 27.25 and 27.26).
As discussed in this example, the ladder circuits can be implemented by the transconductance ampli-
fiers. In the same manner, the ladder circuits can also be implemented by the op-amps. However, the 
circuits with op-amps normally require more components, so it is not the optimum design.
Besides some fundamental methods to implement filters by using op-amps, transconductance 
amplifiers, and LC ladders, there is another way to implement filters by using switched capacitors to 
0 dB
–20 dB
–40 dB
–60 dB
–80 dB
–100 dB
–120 dB
–140 dB
–160 dB
–180 dB
–300°
–250°
–200°
–150°
–100°
–50°
0°
50°
100°
150°
200°
250°
300°
100 μHz
1 mHz
10 mHz
100 mHz
1 Hz
10 Hz
100 Hz
V [n004]
FIGURE 27.24  Output of LC band-pass filter.
L1
V1
V2
~
Vin/Rin
C2
Rin
V3
L3
L5
V5
V6
C6
Rout
V4
C4
+
+
–
+
–
–
+
–
+
–
–
+
–
–
FIGURE 27.25  Band-pass filter with OTAs.
© 2011 by Taylor and Francis Group, LLC

27-14 
Fundamentals of Industrial Electronics
simulate resistance. Switched-capacitor filters were developed to be able to design accurate analog fil-
ters at voice-band frequencies economically in fully integrated form. Furthermore, these filters provide 
reduced power, compact design, and compatibility with digital systems. The advantage of this technol-
ogy is that it allows us to realize accurate RC time constants without the use of resistors by using switches. 
Note that it is not easy to implement good resistors in integrated circuit technologies.
The capacitor is connected to the voltage v1 during the phase φ1, it stores the charge q1 = Cv1. 
Thereafter, in the phase φ2, the capacitor is connected to the voltage v2, the capacitor recharges to 
q2 = Cv2. Therefore, the charge transferred from v1 to v2 is
	
∆q
q
q
C v
v
=
−
=
−
1
2
( 1
2)
The switch is flipped periodically with a clock frequency fc = 1/T that is very large compared to the 
signal frequency ω = 2πf of the two voltage sources v1 and v2. Then the average transferred charge can 
be considered as a current
	
i
q
T
qf
f C v
v
c
c
≈
=
=
−
∆
∆
(
)
1
2
As long as the condition fc >> f is valid, the switched capacitor behaves approximately like an equiva-
lent resistor (Figure 27.27):
	
R
v
v
i
f C
equ
c
≈
−
=
1
2
1
0 dB
–30 dB
–20 dB
–10 dB
–50 dB
–40 dB
–60 dB
–90 dB
–80 dB
–70 dB
–100 dB
–110 dB
–120 dB
–130 dB
–140 dB
–450°
–400°
–350°
–300°
–250°
–200°
–150°
–100°
–50°
0°
50°
100°
1 mHz
10 mHz
100 mHz
V [b]
1 Hz
10 Hz
FIGURE 27.26  Output of band-pass filter with OTAs.
v1 
v1
v2
v2
–
–
+
(a)
(b)
–
+
–
+
1
2
+
C
FIGURE 27.27  (a) A switch capacitor and (b) its resistor equivalent.
© 2011 by Taylor and Francis Group, LLC

Active Filter Implementation 
27-15
27.5  Summary and Conclusion
There are many methods to implement filters. Filters can be implemented by using op-amps, LC ladder 
circuits, transconductance amplifiers, as well as switched capacitors. Method of cascade realization can 
lower the sensitivity of the circuit on account of the component tolerance. This method is also simple 
and flexible. LC ladder circuits are also recognized to implement filters. The limit of this type of circuit 
is the loss of component because inductors and capacitors are not ideal. Transconductance amplifiers 
are also used to implement the prototype of LC ladder circuit by writing state variables. With this type 
of concept, LC ladder circuit can be implemented in integrated circuits. Generally, to implement filters, 
we have to consider all factors: sensitivity, power, compatibility, accuracy, etc.
References
[AWD07] W.M. Anderson, B.M. Wilamowski, and G. Dundar, Wide band tunable filter design imple-
mented in CMOS, in: Proceedings of the 11th INES 2007—International Conference on Intelligent 
Engineering Systems, Budapest, Hungary, pp. 219–223, June 29–July 1, 2007.
[B74] Budak, Passive and Active Network Analysis and Synthesis, Boston, MA: Houghton Mifflin, 1974.
[C86] W.K. Chen, Passive and Active Filters, Theory and implementations, New York: Wiley, 1986.
[HA80] L.P. Huelsernan and P.E. Allen, Introduction to the Theory and Design of Active Filters, New York: 
McGraw-Hill, 1980.
[J76] D.E. Johnson, Introduction to Filter Theory, Englewood Cliffs, NJ: Prentice Hall, 1976.
[JW09] M. Jagiela and B. M. Wilamowski, A methodology of synthesis of lossy ladder filters, in: Proceedings 
of the 13th IEEE Intelligent Engineering Systems Conference, INES 2009, Barbados, April 16–18, 2009.
[KAS89] M.R. Krobe, J. Ramirez-Angulo, and E. Sanchez-Sinencio, FIESTA-A filter educational synthesis 
teaching aid, IEEE Trans. Educ. 12(3), 280–286, August 1989.
[MLS92] B.M. Wilamowski, S.P. Legowski, and J.W. Steadman, Personal computer support for teaching 
analog filter analysis and design, IEEE Trans. Educ. 35(4), 144–152, November 1992.
[P08] S.A. Pactitis, Active Filters Theory and Design, Boca Raton, FL: CRC Press, 2008.
[TDU03] W. Tangsrirat, T. Dumawipata, and S. Unhavanich, Realization of lowpass and bandpass leap-
frog filters using OAs and OTAs, in: SICE 2003 Annual Conference, Vol. 3, Fukui University, Fukui 
City, Japan, pp. 4–6, 2003.
[V82] M.E. Van Valkenburg, Analog Filter Design, New York: Holt, Rinehart & Winston, 1982.
© 2011 by Taylor and Francis Group, LLC

28-1
28.1  Introduction
The role of filters in many electrical and microwave systems cannot be overestimated. The frequency 
response of a filter can impact significantly on the performance of a whole system. The continuously 
evolving communication systems demand high-performance filters with the characteristics as close to 
the ideal as possible. The lack of ideal reactive elements makes all the classical design methods insuf-
ficient in practical application. High-Q components are often large in size, which results in larger and 
heavier filters. The most advanced high-Q technologies are expensive (e.g., multimode dielectric resona-
tor filters) or require cooling systems (superconducting filters). On the other hand, using low-Q reac-
tive elements, particularly inductors, affects the response of the filter in a variety of ways. Apart from 
increasing passband insertion loss and decreasing stopband attenuation, passband edges of the filter 
response become rounded which strongly affects the selectivity of the filter. The deterioration in the 
example of Chebychev filter characteristic due to element losses is shown in Figure 28.1.
Since a certain amount of additional passband loss can often be compensated for by the amplifiers 
existing in the system, the main objective when designing a lossy filter is to maintain a prescribed selec-
tivity of the filter. Thus, a method of design is needed where losses are taken into account and compen-
sated for [1,2].
28.2  Background
The general structure of a lossless ladder filter is shown in Figure 28.2.
Every branch of the ladder consists of an inductor, a capacitor, or a resonant circuit. Hence, admit-
tances Y1 and impedances Zk are purely imaginary.
The transfer function of the passive network of Figure 28.2 built with lossless reactive elements is the 
ratio of two polynomials (28.1):
	
H s
N s
D s
a s
a
s
a s
a
b s
b
s
b s
b
m
m
m
m
n
n
n
n
( )
( )
( )
=
=
+
+
+
+
+
+
+
+
−
−
−
−
1
1
1
0
1
1
1
0


	
(28.1)
28
Designing Passive Filters 
with Lossy Elements
28.1	 Introduction.....................................................................................28-1
28.2	 Background.......................................................................................28-1
28.3	 Method..............................................................................................28-4
28.4	 Solving the System of Equations...................................................28-6
28.5	 Limitations for Losses.....................................................................28-7
28.6	 Conclusion........................................................................................28-8
References����������������������������������對������������������������������������對������������������������������28-8
Marcin Jagiela
University of Information 
Technology and 
Management in Rzeszów
Bogdan M. 
Wilamowski
Auburn University
© 2011 by Taylor and Francis Group, LLC

28-2 
Fundamentals of Industrial Electronics
where constant coefficients ai and bk are real positive numbers. Now, consider the filter of Figure 28.2 
built with lossy elements. Each lossy inductor can be represented by an ideal inductor L in series with 
resistance RL and each lossy capacitor can be represented by an ideal capacitor C in parallel with a 
­conductance Gs, as shown in Figure 28.3.
In order to use the models of Figure 28.3, it is assumed that the resistance RL and conductance GC are 
constants, that is, they do not depend on the frequency.
The transfer function (28.2) of the lossy filter differs from the transfer function of its lossless prototype:
	
′
= ′
+ ′
+
+ ′ + ′
′
+ ′
+
+ ′ + ′
−
−
−
−
H s
a s
a
s
a s
a
b s
b
s
b s
b
m
m
m
m
n
n
n
n
( )
1
1
1
0
1
1
1
0


	
(28.2)
Its poles and zeros are shifted to the left on the complex plane, as shown in Figure 28.4, and the magnitude 
function is deformed, particularly near the passband edges.
1.0
0.8
0.6
0.4
0.2
Q = ∞
Q = 100
Q = 50
Q = 20
Normalized frequency (rad/s)
Magnitude function
Magnitude function
of 14 order Chebychev
filter made with inductors
with different values 
of Q-factor
0.5
1.0
2.0
FIGURE 28.1  Magnitude functions of 14-order Chebychev filter made with inductors with different values of 
Q-factors.
R1
Zn–1
Z2–1
Yn–2
R2
Y1
Yn
FIGURE 28.2  The general structure of ladder filter.
L
RL
GC
C
FIGURE 28.3  Models of lossy inductor and lossy capacitor.
© 2011 by Taylor and Francis Group, LLC

Designing Passive Filters with Lossy Elements 
28-3
Coefficients ′bk in (28.2) are functions of filter elements and of added losses. With fixed values of 
losses, the coefficients ′bk are multilinear functions of filter elements. Provided the added losses are small 
enough, it is possible to perturb the element values of the lossy filter so as to move the poles of (28.2) to 
their original places. It is done by comparing coefficients ′bk to bk and solving the system of equations 
(28.3) obtained in this way:
	
′ =
′ =
′ =






b
b
b
b
b
b
n
n
0
0
1
1

	
(28.3)
Despite the fact that the position of zeros cannot be restored, the magnitude function of the lossy filter 
with the element values modified in this way can be almost ideal.
To express losses of reactive elements in terms of Q-factor rather than in terms of resistance and 
­conductance, one can use the lossy models shown in Figure 28.5.
To use models shown in Figure 28.5, it is assumed that Q varies linearly with the frequency. If more 
detailed models have to be used, for example, with distributed capacitance for inductors and/or with 
frequency-dependant resistance, optimization methods are recommended to improve the characteris-
tics of a lossy filter [3].
Zeros of real filter built with lossy elements 
Poles of prototype 
Complex plane
Poles of real filter built with lossy elements  
Zeros of prototype 
FIGURE 28.4  Movement of poles and zeros due to losses of reactive elements.
L
L
Q
R =
Z(s) =L(s + 1/Q)
(a)
C
Q
C
G =
Y(s) =C(s + 1/Q)
(b)
FIGURE 28.5  Losses of inductor (a) and capacitor (b) expressed in terms of Q-factor (ω = 1 for prototype filters).
© 2011 by Taylor and Francis Group, LLC

28-4 
Fundamentals of Industrial Electronics
28.3  Method
In the first step of designing the lossy filter, requirements for the filter are determined, such as type of 
filter (lowpass, highpass, etc.), edge frequencies, necessary attenuations, and the filter order. A good 
starting point is a prototype filter, normalized to ω0 = 1, obtained by the traditional methods [4–6]. 
Thus, with the aid of the existing formulas or tables, based on the classical approach, filter circuit, its 
transfer function, and element values are computed. Example of prototype filter is shown in Figure 28.6.
The obtained filter is not yet feasible, since the ideal reactive elements were assumed during the 
­process of synthesis.
Now, the prototype circuit has to be redrawn in order to include losses. Each inductor in the circuit is 
replaced by its lossy model shown in Figure 28.5a and, if it is necessary, each capacitor is replaced by its 
lossy model shown in Figure 28.5b. As an example, filter of Figure 28.6 with the losses added is shown 
in Figure 28.7.
After introducing losses, the transfer function of the lossy filter has to be calculated. The simplest 
algorithm to determine the transfer function of a ladder is to start from the right side of a ladder and 
work toward the left, determining the currents and the voltages in the series and shunt branches alter-
nately. The impedances and admittances shown in Table 28.1 are useful when obtaining the transfer 
function.
R2
R1
C1
L2
C3
R1= 1
R2= 1
C1= 1.86369
L2= 1.28036
C3= 1.86369
H(s)=1/(2 + 5.0774s+ 4.772s2+ 4.448s3)
FIGURE 28.6  Example of prototype filter with element values and transfer function.
R1
L2
L2/Q2
C3/Q3
C1/Q1
C1
C3
R2
FIGURE 28.7  Filter of Figure 28.6 with losses added.
TABLE 28.1  Impedances and Admittances of Lossy Elements 
and Resonant Circuits
Lossy inductor
Z(s) = L(s + 1/QL)
Lossy capacitor
Y(s) = C(s + 1/QC)
Lossy parallel resonant circuit
Z s
LQ
Q s
CL
Q Q
CL Q
Q s
CLQ Q s
C
L
C
L
C
L
C
L
( )
(
)
(
)
=
+
+
+
+
+
1
2
Lossy series resonant circuit
Y s
CQ
Q s
CL
Q Q
CL Q
Q s
CLQ Q s
L
C
C
L
C
L
C
L
( )
(
)
(
)
=
+
+
+
+
+
1
2
© 2011 by Taylor and Francis Group, LLC

Designing Passive Filters with Lossy Elements 
28-5
Values of QC and QL can be different for each reactive element. Often it is possible to assume infinite 
values of Q-factor for capacitors. Then, the formulas shown in Table 28.1 become a little bit simpler, and 
are shown in Table 28.2.
As an example of a process of introducing losses to the ladder and recalculating its transfer function, 
consider a three-order lowpass filter shown in Figure 28.6.
The circuit obtained after replacing the reactive elements with their lossy models is shown in Figure 
28.7. Now, let us determine its transfer function, assuming Q1 = Q2 = Q3 = Q and denoting P = (1/Q). 
This process is very awkward and performing it by hand is very complicated, so one of the available tools 
(e.g., Mathematica, or freeware such as Maxima, etc.) is recommended to obtain the results. Below, the 
consecutive Mathematica commands are presented with output to show the whole process of calculating 
the transfer function of lossy filter from Figure 28.7:
Input:
Iout=Vout/R2
VC3=Vout
IC3=VC3*C3*(s+P)
IL2=IC3+Iout
VL2=IL2*L2*(s+P)
VC1=VL2+VC3
IC1=VC1*C1*(s+P)
IR1=IC1+IL2
VR1=IR1*R1
Vin=VR1+VC1
Tf=Vout/Vin
Output (Transfer function of the lossy filter)
R2/(L2P+R1+C1L2R1P2+R2+C3L2R2P2+C1R1R2P+C3R1R2P+C1C3L2R1R2P3
+(L2+2C1L2R1P+2C3L2R2P+C1R1R2+C3R1R2+3C1C3L2R1R2P2)s
+(C1L2R1+C3L2R2+3C1C3L2R1R2P)s2+C1C3L2R1R2s3)	
(28.4)
After obtaining the transfer function, the system of equations is created. It is done by comparing 
denominator coefficients from the transfer function of the lossy filter and from the transfer function 
of the prototype. Before solving the system, all the values of Q-factors have to be established. For a 
singly terminated structure, the system has then n + 1 unknowns and n + 1 equations, where n is the 
filter order. For a doubly terminated ladder, the system has one degree of freedom, since the number of 
unknowns is n + 2 (n reactive elements and two terminating resistors).
In order to solve the obtained system of equations, numerical methods are recommended, since an 
analytical approach is complicated even for low filter orders and for higher orders it is simply impossible.
For every numerical method, an initial point is needed to start iterations. For all the lossy filters 
designed with the presented method, a satisfactory initial point is made of element values of a proto-
type filter.
TABLE 28.2  Impedances and Admittances of Lossy 
Elements and Resonant Circuits (QC = ∞)
Lossy inductor
Z(s) = L(s + 1/QL)
Lossy parallel resonant circuit
Z s
L
Q s
Q
CLs
CLQ s
L
L
L
( )
(
)
=
+
+
+
1
2
Lossy series resonant circuit
Y s
CQ s
Q
CLs
CLQ s
L
L
L
( ) =
+
+
2
© 2011 by Taylor and Francis Group, LLC

28-6 
Fundamentals of Industrial Electronics
As an example, consider a system of equations created by comparing the coefficients of transfer func-
tion of the lossy filter (28.4) to the transfer function of the prototype filter shown in Figure 28.5. Setting 
values of P = 0.067 (Q = 15) and R2 = 1.25, we get a system
0 45
0 067 1
0
1
0
2
0
2
0
1
0
.
.
+
+
+
+
+
+
+
L
C L
L
C L L
C R
.002 1
.067
.0003 1 1
1
.03 1
.
R
004
1 2 1
1
0.06 1 1
2
0.0133333 1 1 2
0.45 1 1
0.1333
C L R
=
+
+
+
+
+
2L
C L
L
C L L
C R
33 1 2 1
5.0074 0.45 1 1
0.2 1 1 2
1 2 1= 4.77239
C L R
C L
C L L
C L
=
+
+
R
C1L L
Initial point L
C
L
1 2
4 44713
1
1 86369
1 1 28036
2
1 86369
=
=
=
=
.
(
.
,
.
,
.
,
)
R1
1
=








	
(28.5)
After solving system (28.4) using prototype elements as the initial point, solution (28.5) determines the 
element values of the lossy filter
	
L
C
L
R
1
1.7,
1
1.29,
2 
.0267,
1
0.436
=
=
=
=






2
	
(28.6)
Each reactive element of the filter has Q-factor 15. Magnitude functions of the prototype filter and lossy 
filter are shown in Figure 28.8.
28.4  Solving the System of Equations
When solving the system (28.3) to find element values of a lossy filter, several problems can occur. When 
using a Newton method, it may happen that the Jacobian matrix is singular. This problem can be easily 
fixed by perturbing slightly the initial point by trial and error.
When using Mathematica, the commands shown below can be used to solve system (28.5) and to 
obtain solution (28.6) using the Newton method with command FindRoot. It is assumed that commands 
(28.4) have been already performed.
Magnitude
Normalized frequency (rad/s)
0.0
0.2
0.4
0.6
0.5
Lossy filter of Figure 28.7 (Q = 15)
Ideal, unfeasible filter of Figure 28.6 (Q = 8)
Filter of Figure 28.6, made with lossy elements (Q= 15)
1.0
1.5
2.0
2.5
FIGURE 28.8  Magnitude functions for different configurations of filter of Figure 28.6.
© 2011 by Taylor and Francis Group, LLC

Designing Passive Filters with Lossy Elements 
28-7
Input:
P=1./15; R2=1.25;
InitialPoint={{L1,1.86369},{C1,1.28036},{L2,1.86369},{R1,1}}
LeftSide=CoefficientList[Denominator[Tf],s]
RightSide={2,5.00774,4.77239,4.44713}
FindRoot[LeftSide==RightSide,InitialPoint]
Output:
{L1 → 1.70086,C1 → 1.29011,L2 → 2.02668,R1 → 0.436044}
(28.7)
For the singly terminated filter, the system has no degrees of freedom, that is, the number of unknowns 
matches the number of equations. If the introduced losses are not too large, the solution can always 
be found. For the lossy filter, the obtained solution has to be real and positive. As it was mentioned, 
the right sides of the system of equations (28.3) are coefficients of prototype transfer function (28.1). 
This function may be written in several equivalent ways, since one can always multiply or divide the 
numerator and the denominator by the same factor. The question that appears now is: does the solu-
tion depend on the chosen factor? The answer is positive, which means that with the factor chosen 
improperly, a positive solution may not be found. For example, it may happen that ′ = +
+
b0
1
R1
L2C3 
and b0 = 0.5 which obviously will not lead us to the positive solution. Instead of looking for the appro-
priate factor to reduce the transfer function (28.1), one can transform the system of equations (28.3) in 
the following way:
	
′
=
′
′
=
′
′
=
′






b b
b b
b b
b b
b b
b b
n
n
0 0
0 0
1 0
1 0
0
0

	
(28.8)
In system (28.8), all the left sides are multiplied by b0 and all the right sides are multiplied by ′b0. In this 
way, the first equation is always true and can be omitted. The solution of (28.8) obtained numerically 
will not necessarily satisfy system (28.3), but it will always satisfy system (28.9):
	
′ =
′ =
′ =






b
kb
b
kb
b
kb
n
n
0
0
1
1

	
(28.9)
where k is a constant. Such a solution, if it is positive, is sufficient to build a lossy filter. This method can 
also be used for the doubly terminated network, where the system of equations has one degree of freedom.
28.5  Limitations for Losses
From the filter designer’s point of view, some of the most important issues that have to be considered 
when designing a lossy filter are how the introduced losses affect the filter response and what are the 
limitations for losses. Unfortunately, there is no simple answer for these questions and every type of 
filter requires special consideration. When designing a singly terminated lossy filter, the minimal value 
of reactive elements Q-factor can be determined numerically. It is done by setting Q-factors big enough 
to find the solution of system (28.3) and next by lowering the Q-factors as long as system (28.3) has real 
positive solution. There is a general rule concerning the limit for Q. The higher the order of the filter, 
© 2011 by Taylor and Francis Group, LLC

28-8 
Fundamentals of Industrial Electronics
the higher the Q demanded to find the solution. Moreover, if Q reaches its limit, it may happen that the 
attenuation of the filter is not acceptable or the shape of the magnitude function is much too degraded 
due to shifting of zeros. In that case, it is enough to introduce a slightly bigger Q than minimal needed 
to obtain a solution.
As was mentioned, for the doubly terminated filters, system (28.3) has one degree of freedom, which 
means that one of the unknown lossy filter elements may be fixed. The choice is arbitrary, but if one 
of the terminating resistors is chosen to establish, one can try to introduce the losses, and watch their 
influence on the ratio of these terminating resistors. Lower the values of Q-factor, the more asymmetric 
the filter becomes.
As an example, consider the filter of Figure 28.7. The relationship between the introduced Q-factor 
and the ratio R1/R2 is shown in Figure 28.9.
This relationship may be considered as the trade-off between the level of the introduced losses and the 
symmetry of the doubly terminated filter.
28.6  Conclusion
The method described above is based on poles restoring approach. Along with its simplicity, it gives 
good results and the obtained filters can be implemented as traditional ladders as well as into microelec-
tronic form, where inductors are simulated by active circuits. Other issues concerning designing lossy 
filters, particularly focused on microwave filters, are widely described in the literature [7]. The coupling 
matrix synthesis method based on a lossy transversal network model is presented in [8]. An effective 
optimization method for lossy ladders is described in detail in the classical paper [9].
References
	
1.	 M. Jagiela and B. Wilamowski, A methodology of synthesis of lossy ladder filters, in: INES 2009, 
International Conference on Intelligent Engineering Systems, April 16–18, 2009, Barbados, pp. 45–50.
	
2.	 B.S. Senior, I.C. Hunter, and J.D. Rhodes, Synthesis of lossy filters, in: 32nd European Microwave 
Conference, October 2002, Milan, Italy, pp. 1–4.
	
3.	 C. Fu and H. Wang, An efficient optimization for passive filter design, in: INDIN 2008, 6th IEEE 
International Conference on Industrial Informatics, July 13–16, Daejeon, Korea, 2008, pp. 631–634.
1.10
1.00
0.90
0.80
0.70
0.60
0.50
0.40
0.30
0.20
0.10
0.00
10
100
1,000
10,000
Q-factor
Ratio R1/R2
FIGURE 28.9  Relationship between ratio R1/R2 and Q-factor of reactive elements for filter of Figure 28.7.
© 2011 by Taylor and Francis Group, LLC

Designing Passive Filters with Lossy Elements 
28-9
	
4.	 B.M. Wilamowski and R. Gottiparthy, Active and passive filter design with MATLAB, International 
Journal on Engineering Educations, 21(4), 561–571, 2005.
	
5.	 R. Koller and B. Wilamowski, LADDER—A microcomputer tool for advanced analog filter design 
and simulation, IEEE Transactions on Education, 39(4), 478–487, November 1996.
	
6.	 B.M. Wilamowski, S.F. Legowski, and J.W. Steadman, Personal computer support for teaching ana-
log filter analysis and design courses, IEEE Transactions on Education, E-35(4), 351–361, 1992.
	
7.	 R. Levy, R.V. Snyder, and G. Matthaei, Design of microwave filters, IEEE Transactions on Microwave 
Theory and Techniques, 50(3), 783–793, March 2002.
	
8.	 V. Miraftab and M. Yu, Generalized lossy microwave coupling matrix synthesis and design using 
mixed technologies, IEEE Transactions on Microwave Theory and Techniques, 56(12, Part 2), 3016–
3027, December 2008.
	
9.	 C.A. Desoer and S.K. Mitra, Design of lossy ladder filters by digital computer, IRE Transactions on 
Circuit Theory, 8(3), 192–201, September 1961.
© 2011 by Taylor and Francis Group, LLC

29-1
29.1  Introduction
In this chapter, we shall study two important phenomena, electricity and magnetism, and show how 
these two phenomena combine to give rise to electromagnetism. Electricity and magnetism have been 
known to mankind since ancient times. Thales of Miletus, a Greek mathematician who lived almost 
600 years before Christ, reported that amber produces sparks when rubbed with silk cloth and attracts 
fluff. He also noted that a certain natural material, called landstone, has attractive powers. The names 
electricity and magnetism owe their existence to these discoveries. The word electricity was derived 
after electron, the Greek word for amber, and magnetism was derived from Magnesia, the place where 
landstone was found. Over the next twenty-five centuries, scientists, as well as ordinary folk, observed 
electricity and magnetism in a variety of situations. However, in 1831, Michael Faraday, a British sci-
entist, experimentally demonstrated that these two seemingly different phenomena, in fact, originate 
from the same source, that is, from charge. Thus, our study of electricity and magnetism begins with 
charge, and current, which is yet another important quantity that gets generated when the charge is 
varied with time.
29.2  Charge, Current, and Continuity Equation
In this section, we study two fundamental quantities, charge and current, and the relationship between 
these two quantities.
29
Electromagnetic Fields I
29.1	 Introduction.....................................................................................29-1
29.2	 Charge, Current, and Continuity Equation................................29-1
Electric Charge  •  Electric Current  •  Continuity Equation
29.3	 Electrostatic and Magnetostatic Fields.........................................29-4
Coulomb’s Law and Electric Field  •  Biot–Savart Law and Magnetic 
Flux Density  •  Illustrative Examples
29.4	 Potential Theory.............................................................................29-13
Concept of Potential Energy  •  Electric Potential  •  Relationship 
between E and V  •  Potential Function for a Given Charge 
Distribution  •  Vector Potential  •  Illustrative Examples
29.5	 Gauss’ Law and Ampere’s Law.....................................................29-18
Gauss’ Law  •  Ampere’s Circutal Law  •  Applications
29.6	 Material Interaction......................................................................29-27
Polarization  •  Magnetization  •  Boundary Conditions
29.7	 Faraday’s Law, Displacement Current, and Maxwell’s 
Equations........................................................................................29-29
Faraday’s Law  •  Displacement Current  •  Maxwell’s Equations
29.8	 Summary.........................................................................................29-30
Sadasiva M. Rao
Auburn University
Tyler N. Killian
Auburn University
Michael E. Baginski
Auburn University
© 2011 by Taylor and Francis Group, LLC

29-2 
Fundamentals of Industrial Electronics
29.2.1  Electric Charge
There are four fundamental quantities in nature: mass, length, 
time, and charge. Like other quantities, charge also preserves the 
principle of conservation which implies that charge can neither be 
created nor destroyed. The unit for charge is the coulomb, named 
after the scientist who quantified the force between charges.
We know from basic high school physics that all matter is com-
posed of molecules and each molecule consists of several atoms. 
Furthermore, we know that each atom, no matter what mate-
rial it constitutes, consists of electrons, protons, and neutrons. 
Electrons are negatively charged particles while protons are posi-
tively charged. Finally, neutrons, as the name indicates, are electri-
cally neutral. Thus, we know that charge can be either positive or 
negative.
Since electrons and protons are so tiny in size, we refer them as 
point charges. Mathematically, any charge with zero mass and zero 
volume may be called a point charge. Usually, the point charge is 
denoted by the Q.
Next, we take a look at various charge distributions. If we arrange several point charges, both positive 
and negative, over a certain region of space, as shown in Figure 29.1, then we have a discrete charge distri-
bution. The total charge (QT) in this charge distribution is given by the summation of all the individual 
charges. Thus, we can write
	
Q
Q
T
i
N
i
=
=∑
1
(C)
	
(29.1)
However, if the charge is distributed over a region in a continuous manner, then we can have a linear 
charge distribution (ql ), a surface charge distribution (qs ), or a volume charge distribution (qv ). For the 
linear charge distribution, the charge is spread over a line such as a wire. For the surface charge distribu-
tion, the charge is painted over a surface such as a plate. Finally, for the volume charge distribution, the 
charge is assembled in a finite volume such as a container. All these cases are depicted in Figure 29.2.
For the continuous case, the total charge (QT) for a given charge distribution is given by
	
Q
q dl
q ds
q dv
T
l
l
s
S
v
v
=
=
=
∫
∫
∫
	
Next, we will look at the concept of current. Generally, while studying circuit theory, electrical engi-
neering students are introduced to current as the rate of change of charge. In the following section, we 
present a more general definition of current applicable for field theory as well as circuit theory.
Q1
Q2
Q3
Q7
Q6
Q5
Q4
FIGURE 29.1  Discrete charges in 
free space.
qI
qs
qv
FIGURE 29.2  Charge distributions in free space.
© 2011 by Taylor and Francis Group, LLC

Electromagnetic Fields I 
29-3
29.2.2  Electric Current
Generally speaking, current is the result of charges in motion. 
Whenever charges move from one position to another, we have cur-
rent. However, the charge transport can happen in a variety of ways 
and as a result we have different types of current.
First, consider the situation as shown in Figure 29.3. Here, we have 
a charge cloud moving in space. Since the charges are moving, we have 
current. Also, note that the charges are moving in empty space. Such a 
current is known as convection current.
Next, we can have charges moving in a material medium and causes 
current flow. In the material medium, charge transport takes place due 
to the external forces. This type of current is known as conduction cur-
rent. In circuit theory, we mostly deal with conduction currents since 
the current is mainly flowing in the wires.
There is also yet another of type of current known as displacement 
current which occurs due to a displacement of charges. We shall study 
this phenomenon a little later.
Regardless of the nature of current, let us consider a charge 
­distribution moving at a velocity U, as shown in Figure 29.3. The 
charge density is equal to qv C/m3. The current density J may be 
defined as
	
J
U
=
.
qv
	
(29.2)
Next, we allow this charge cloud to pass through a surface S, as shown in Figure 29.4. Then, we can 
calculate the total current I passing through the surface S as
	
I
ds
n
S
=
⋅∫J a
	
(29.3)
where an is the unit vector normal to the surface. Here, we note that the current density J is a vector 
quantity, whereas the current I is a scalar quantity. Also note that the current I is maximum when J and 
an are pointing in same direction. Further, we know that the current is measured in amperes, which 
implies that J is measured in A/m2.
It is clear from the previous discussion that charges and current are 
interrelated. This is an important observation that has profound implica-
tions as we shall see in the following sections.
29.2.3  Continuity Equation
We have stated earlier that charge can neither be created nor destroyed. So, 
let us consider the following situation as shown in Figure 29.5.
Here, we have a certain amount of charge Q enclosed in a container of 
volume V. Let S be the surface bounding the volume. The amount of charge 
in the container may be increased or decreased by making the charge flow 
into or out of the container, respectively. Since the charge flow results in 
current, from the principle of conservation, we have
	
I
dQ
dt
= −
	
(29.4)
Q
u
FIGURE 29.3  Charge cloud 
moving in free space.
J
s
an
Q
FIGURE 29.4  Charge cloud 
passing through a surface.
V
Q
S
FIGURE 29.5  Charge con-
servation 
and 
continuity 
equation.
© 2011 by Taylor and Francis Group, LLC

29-4 
Fundamentals of Industrial Electronics
The minus sign in Equation 29.4 signifies that the level of charge inside the container is decreasing 
when there is a positive outward current flow. Furthermore, using Equations 29.2 and 29.3, Equation 
29.4 may be written as
	
J a
⋅
= −
∂
∂
∫
∫
n
S
v
V
ds
q
t dv
	
(29.5)
Finally, using the vector identity given by
	
∇⋅
=
⋅
∫
∫
A
A a
dv
ds
V
n
S
	
(29.6)
where
A is any arbitrary vector in a volume V
an represents the unit outward normal vector to the surface S bounding the volume*
We can write Equation 29.5 as
	
∇⋅
= −∂
∂
J
q
t
v
	
(29.7)
Equations 29.5 and 29.7 represent the continuity equation in integral and differential form, respectively.
29.3  Electrostatic and Magnetostatic Fields
In this section, our study is focused on the concept of static fields, viz., electrostatic and magnetostatic 
fields. Before we undertake such a task, however, we first need to know the meaning of the word static. 
We define a quantity as static quantity when it does not change with respect to time, for example, static 
charge. Obviously, the static charge has no velocity and, consequently, does not generate current. On 
the other hand, if the charge varies with time, then it is no longer a static quantity. Plus, we also have 
current in this situation.
The current generated by a time-varying charge can be static, however. This is due to the fact that cur-
rent flow can be steady, which implies that the rate of change of charge is constant. Of course, in a more 
general situation, neither charge nor current is static.
The moral of this story is that we can have static charges and static currents, although, not at the 
same time. In the following subsection, we discuss what the static charges do when situated in an 
open empty space.
29.3.1  Coulomb’s Law and Electric Field
Let us consider an infinite space filled with an only one type of material (or even an empty space like a 
vacuum). Such a space may be defined as a homogeneous space. Next, let us consider a simple situation 
where two point charges Q1 and Q2 are located in this infinite, homogeneous space, as shown in Figure 29.6. 
We assume that there are no other charges in the whole space. Then, Coulomb’s law states that The electric 
force F21 exerted on Q2 by Q1 is proportional to the magnitude of the charges, Q1 and Q2, and inversely 
proportional to the square of the distance R separating them.
*	 Equation 29.6 is, in fact, the well-known divergence theorem in vector calculus.
© 2011 by Taylor and Francis Group, LLC

Electromagnetic Fields I 
29-5
Mathematically, referring to Figure 29.6, Coulomb’s law may 
be given by
	
21
1
2
2
21
21
1
2
2
21
F
a
F
a
∝
⇒
=
Q Q
R
k Q Q
R
	
(29.8)
where
k is a proportionality constant which depends on the surrounding medium
a21 is the unit vector along the line joining Q1 and Q2 and pointing away from Q2
It is very important to note the direction of a21 as one cannot afford to make a mistake at this stage. In 
the rationalized meters-kilogram-seconds (RMKS) system, the constant k for air (or vacuum) is given by
	
k =
.
= .
×
−
1 0
4
8 854
10
0
0
12
πε
and
ε
	
(29.9)
Coulomb’s law may be interpreted in two ways. One way of understanding the law is to imagine that 
the charge Q1 is directly exerting the force on Q2 given by Equation 29.8. However, we can also interpret 
the law in another way. Here, we say that the charge Q1 merely creates a field, known as electric field (E) 
around it and this field, in turn, causes the force on Q2. Thus, we can see, according the second interpre-
tation, the charge Q2 is merely required to detect the presence of the electric field E. In fact, the presence 
of charge Q1 is sufficient for the creation of an electric field.
Although both arguments are valid, the second argument is more appealing and accepted by the 
scientific community at large. Thus, following the second line of argument and referring to Figure 29.7, 
we define the electric field E, measured in volts per meter (V/m), at a point P as
	
E
a
=
Q
R
R
4
0
2
πε
	
(29.10)
In Equation 29.10, E is the electric field at P due to the point charge located at a distance R meters. 
Further, aR is the unit vector along the line joining the location of the point charge and the point of 
observation and is pointing away from the point charge. It is very important to note all these quantities 
since they are fundamental to what we will learn later.
Note that in Equation 29.10, we dropped all the subscripts and refer to the point charge Q developing 
a field E surrounding it. However, we can always calculate the electrostatic force using the relation
	
F
E
= q
	
(29.11)
where q is the test charge required to detect the electric field.
Next, we consider the electric field for a given charge distribution. In Figures 29.1 and 29.2, we have 
shown discrete charges and other different types of charge distributions. In all these cases, the total elec-
tric field is obtained using the principle of superposition, that is, calculating the field from individual 
charges and performing vector addition. Mathematically, we have
	
T
i
i
R
i
N
l
R
l
s
R
S
v
Q
R
q dl
R
q ds
R
q dv
i
E
a
a
=
=
=
=
=∑
∫
∫
4
4
4
4
0
2
1
0
2
0
2
π
π
π
π
ε
ε
ε
ε
a
0
2
R
R
V
a
∫
	
(29.12)
R
Q1
Q2
a21
FIGURE 29.6  Two point charges in 
free space.
aR
Q
P
x
R
FIGURE 29.7  Definition of 
electric field.
© 2011 by Taylor and Francis Group, LLC

29-6 
Fundamentals of Industrial Electronics
In the following, we consider some important facts about the electric field:
•	 The sources for the electric field are charges.
•	 The charges can be both positive and negative.
•	 The charges of opposite polarities attract each other. Similarly, charges of same polarity repel each 
other.
•	 The electric field emanates from the positive charge and terminates on the negative charge. If we 
have positive (negative) charge at some place and no negative (positive) charge in the vicinity, then 
we assume that the negative (positive) charge is at infinity.
29.3.2  Biot–Savart Law and Magnetic Flux Density
First, let us consider the concept of a current element. Mathematically, we may define a current element I dl 
as a piece of wire of length dl carrying current I and pointing in the direction of the arrow. According 
to this definition, we may consider a current loop as a summation of current elements as shown in 
Figure 29.8. Thus, the current element forms the basic building block for a current distribution just like 
a point charge forms the building block for a charge distribution. In fact, we may consider any current 
distribution as a collection of current elements.
However, a word of caution is necessary. Unfortunately, the current element is not a physical quan-
tity, that is, we cannot have an isolated current element sitting in an empty space like point charges do. 
Current elements must form a closed loop so that there can be a current flow. We all know that if the 
loop is broken, the current through the wire is zero.
Next, we consider two current elements I1dl1 and I2dl2 located in infinite homogenous space, as shown 
in Figure 29.9. Then, Biot–Savart law states that the magnetic force dF21 exerted on current element I2dl2 
by I1dl1 is proportional to the magnitude of the currents, I1 and I2, and inversely proportional to the 
square of the distance R separating them.
Mathematically, referring to Figure 29.9, Biot–Savart law may be given by
	
d
I
I
R
d
k I
I
R
F
dl
dl
a
F
dl
dl
a
21
1
1
2
2
21
2
21
1
1
2
2
21
2
∝
×
×
⇒
=
×
×
(
)
(
)
	
(29.13)
where
k is a proportionality constant that depends on the surrounding medium
a21 is the unit vector along the line joining the centers of I1dl1 and I2dl2 and pointing away from I2dl2
FIGURE 29.8  An arbitrary loop formed by current elements.
© 2011 by Taylor and Francis Group, LLC

Electromagnetic Fields I 
29-7
Further, note that the sign “×” in Equation 29.13 represents vector 
cross product not multiplication.
In the RMKS system, the constant k for air (or vacuum) is given by
	
k =
=
×
−
µ
π
µ
π
0
0
7
4
4
10
and
	
(29.14)
Again, Biot–Savart law may be interpreted in two ways just like Coulombs’ law. One way of under-
standing the law is to imagine that the current element I1dl1 is directly inducing the force on I2dl2 given 
by Equation 29.13. However, we can also interpret the law in another way. Here, we say that the current 
element I1dl1 merely creates a field, known as magnetic flux density around it and this field, in turn, 
causes the force on I2dl2. Thus, we can see, according to the second interpretation, that the current ele-
ment I2dl2 is only required to detect the presence of the magnetic flux density B.
Following the second line of argument, we define the magnetic flux density B, measured in Webers 
per square meter (Wb/m2), at a point P as
	
B
dl
a
=
×
∫
µ
π
0
2
4
I
R
R
l
	
(29.15)
Note that, in Equation 29.15, we dropped all the subscripts and introduced an integral. The integra-
tion appears due to the fact that the current element must belong to a closed loop.
In the following, we list some important facts about the magnetic flux density:
•	 The sources for the magnetic flux density are currents that flow in a closed path.
•	 The current element is a vector quantity.
•	 The magnetic flux lines always form closed loops implying that the flux lines have no beginning 
or end.
Again, it is very important to study Figure 29.9 and note all the quantities. Particularly, note the 
direction of the unit vectors. In order to illustrate the importance of these quantities, we present a few 
examples in the following.
29.3.3  Illustrative Examples
Example 29.1
Consider three point charges Q1 = Q2 = Q3 = Q located at (a, 0, 0), (0, a, 0), and (0, 0, a), as shown in Figure 
29.10a. (1) Calculate the total electric field ET at the origin (0, 0, 0). (2) If the charges are replaced by current 
elements, as shown in Figure 29.10b, calculate the magnetic flux density BT at the origin.
Solution
The total electric field ET at (0, 0, 0) is the sum of the electric fields from each charge. Notice that the dis-
tance from each charge to the point of observation is a. Thus, using Equation 29.10,
	
E
E
E
E
T =
+
+
=
−
+
−
+
−
=
−
1
2
3
0
2
0
2
0
2
0
4
4
4
4
Q
a
Q
a
Q
a
Q
a
x
y
z
πε
πε
πε
πε
(
)
(
)
(
)
a
a
a
2
V/m
a
a
a
x
y
z
+
+


	
I1dl1
I2dl2
R
a21
FIGURE 29.9  Two current ele-
ments in free space.
© 2011 by Taylor and Francis Group, LLC

29-8 
Fundamentals of Industrial Electronics
Next, let us calculate the magnetic flux density. Using Equation 29.15, we have
	
B
a
a
a
B
a
1
2
0
2
2
4
(
)
(
)
4
(
)
4
(
)
(
=
−
× −
=
−
=
−
× −
µ
π
µ
π
µ
π
0
0
2
Idl
a
Idl
a
Idl
a
y
x
z
z
a
a
B
a
a
a
y
x
x
z
y
Idl
a
Idl
a
Idl
a
)
4
(
)
4
(
)
(
)
4
(
)
2
3
2
0
2
=
−
=
−
× −
=
−
µ
π
µ
π
µ
π
0
0
	
Thus, we have
	
B
a
a
a
T = −
+
+


µ
π
0
2
2
4
Idl
a
x
y
z
(
)
Wb/m
	
Example 29.2
Consider a straight wire of length 2l meters carrying a uniform charge density ql C/m, as shown in Figure 
29.11a. (1) Calculate the electric field E at a point P, located d meters from the axis of the wire. (2) If the 
wire is carrying uniform current, as shown in Figure 29.11b, then calculate the magnetic flux density at 
the point P.
X
Y
Z
(a, 0 . 0)
(0, a, 0)
(0, 0, a)
(b)
X
Y
Z
(a, 0 . 0)
(0, a, 0)
(0, 0, a)
(a)
X
X
FIGURE 29.10  Three point charges and three current elements in free space.
α
P
Y
X
X
(0, I)
qI  (C/m)
(0, –I)
(d, 0)
(a)
Y
X
X
(0, I)
I (A)
(0, –I)
(b)
(d, 0)
P
α
(c)
FIGURE 29.11  A finite line charge and a finite line current.
© 2011 by Taylor and Francis Group, LLC

Electromagnetic Fields I 
29-9
Solution
In this example, we again use the principle of superposition as applied in Example 29.1. In order to do this, 
we subdivide the wire into very small segments. Note that, however small the segment may be, it still has 
some finite length given by δl. We attack this problem by viewing each small segment as a point charge. 
Then we know how to compute the electric field due to this approximated point charge. Finally, the total 
electric field is the summation of fields from the charge located on each segment.
However, there is one important difference. Since we do not have isolated charges, the final step in 
the solution procedure is not summation but integration.
Referring to Figure 29.11c, the charge dQ on each segment is given by
	
dQ =
=
q dl
q dy
l
l
	
	
R
d
y
=
+
2
2
	
	
a
a
a
R
x
y
d
y
R
=
−
+
−
(
)
(
)
0
0
	
Thus, we have
	
E
a
a
a
=
−
+
=
+
−
/
/
−
∫
q dy
d
y
d
y
q
d
dy
d
y
l
l
l
x
y
l
x
l
l
4
4
0
3 2
2
2
0
3 2
2
2
πε
πε
(
)
(
)
(
)
∫
∫
−
+








/
−
ay
l
l
ydy
d
y
3 2
2
2
(
)
(V/m)
	
The two integrals in the previous step may be evaluated using simple substitutions or, alternatively, 
using Tables of Integration. Notice that the second integral, after substituting the limits, is equal to zero. 
Thus, we have
	
E
a
a
=
+





=
x
l
x
l
q
d
d
q
d
4
2
2
0
2
2
0
πε
πε
α
ℓ
ℓ
cos
	
where α is the angle as shown in Figure 29.11a.
For part (b), referring to Figure 29.11b, we define each current element as
	
I
dy
y
dl
a
= I
	
	
R
d
y
=
+
2
2
	
	
a
a
a
R
x
y
d
y
R
=
−
+
−
(
)
(
)
0
0
	
Thus, we have
	
d
Idy
d
y
d
y
Id
dy
d
y
y
x
y
z
B
a
a
a
a
=
×
−
+
= −
+
/
µ0
3 2
2
2
0
2
2 3 2
4
4
π
µ
π
(
)
(
)
(
)
(
) /
	
© 2011 by Taylor and Francis Group, LLC

29-10 
Fundamentals of Industrial Electronics
and
	
B
a
a
a
= −
+
= −




= −
/
∫
(
)
(
)
(
)
cos
(
z
l
l
z
z
Id
dy
d
y
Id
d
µ
π
µ
π
α
0
3 2
2
2
0
2
4
4
2
)
cos
(
)
µ
π
α
0
2
2
I
d
W/m
	
Now, we use the result of the previous example to derive an important result. Let us consider the 
situation where the finite length is changed to infinite length, that is, l → ∞. For this case, α = 0 and 
cos α = 1. Thus, for an infinite line along the y-axis, the fields at a point d meters away along the x-axis 
are given by
	
E
a
B
a
=
= −
x
l
z
q
d
I
d
2
2
0
0
2
πε
µ
π
(
(
)
(
)
V/m) and
W/m
	
(29.16)
Further, we note the following:
•	
ax is the radial vector from the axis of the wire to the point of observation, which may be referred 
to, in general, as ad.
•	
−az is actually the vector obtained by taking the cross product of the current vector, ay, with the 
radial vector ax. For a general case, this may be written as ai × az.
Thus, in general, for an infinite wire, the electric field and the magnetic flux density are given by
	
E
a
=
q
d
l
d
2
0
πε
(V/m)
	
(29.17)
	
B
a
a
=
×
µ
π
0
2
2
I
d
l
d (
)
W/m
	
(29.18)
Example 29.3
Consider a circular plate of radius a meters carrying a uniform surface charge density qs C/m2, as shown 
in Figure 29.12a.
	
1.	 Calculate the electric field E at a point P(0,0,d).
	
2.	 If the plate is carrying uniform current with surface current density Js = J0ay A/m, as shown in 
Figure 29.12b, then calculate the magnetic flux density at the point P.
Solution
Again, following the procedures of previous examples, let us divide the circular plate into elemental 
pieces as shown in the figure. The area of each piece is dS = (dρ)(ρ dϕ). Thus, we have
	
dQ
q dS
q d
d
s
s
=
=
(
)(
)
ρ ρ φ 	
	
R
d
=
+
2
2
ρ 	
	
a
a
a
a
a
a
R
z
z
x
y
R
d
R
=
−
=
−
−
d
ρ
ρ
φ
ρ
φ
ρ
cos
sin
	
© 2011 by Taylor and Francis Group, LLC

Electromagnetic Fields I 
29-11
Therefore,
	
d
q d d
d
d
s
z
x
y
E
a
a
a
=
−
−
+
ρ ρ φ
π
ρ
φ
ρ
φ
ρ
4
0
2
2 3 2
ε
cos
sin
(
) /
	
Now, to calculate the electric field E, we need to integrate the above expression. Note that we need 
to perform a double integration with the limits ρ → 0 to a and ϕ → 0 to 2π. It is easy to prove that the 
integrals along ax and ay directions are zero. Thus, we have
	
E
a
a
=
+
=
+
/
=
=
/
∫
∫
z
s
a
z
s
q d
d d
d
q d
d
d
4
2
0
3 2
2
2
0
2
0
0
3 2
2
2
πε
ρ ρ φ
ρ
ε
ρ ρ
ρ
φ
π
ρ
(
)
(
)
(
ρ
ε
ρ
ε
=∫
=
−
+








=
−
+






0
0
0
2
2
0
2
2
2
1
2
1
1
a
z
s
a
z
s
q d
d
q d
d
d
a
a
a
V/m)
	
In the above expression, the integral on ρ is evaluated using tables of integration.
For part (b), referring to Figure 29.12b, we have
	
I
J d
d
y
dl
a
=
0(
)(
)
ρ ρ φ
	
	
R
d
=
+
2
2
ρ 	
	
a
a
a
a
a
a
R
z
z
x
y
d
R
d
R
=
−
=
−
−
ρ
ρ
φ
ρ
φ
ρ
cos
sin
	
Y
X
Z
x (0, 0, d)
qs (C/m2)
(a)
X
Y
Z
x (0, 0, d)
Js (A/m)
(b)
FIGURE 29.12  A disk of (a) surface charge and (b) ϕ-directed current density.
© 2011 by Taylor and Francis Group, LLC

29-12 
Fundamentals of Industrial Electronics
Thus,
	
d
J d
d
d
d
J
y
z
x
y
B
a
a
a
a
=
×
−
−
+
=
µ
π
ρ ρ φ
ρ
φ
ρ
φ
ρ
µ
0
0
2
2 3 2
0
4
(
)(
)(
)
(
cos
sin
)
(
) /
0
2
2 3 2
4
ρ ρ φ
π
ρ
ρ
φ
d d
d
d
x
z
(
)
[
cos
]
+
+
/
a
a
	
To obtain the total magnetic flux density, we integrate the previous expression between the limits 
ϕ from 0 to 2π and ρ from 0 to a. Note that the first part of the expression, that is, the x-component, is 
same as that of part (a). Also, the z-component vanishes since the integration of cos ϕ over 0 to 2π is zero. 
Thus, we have
	
B
a
=
−
+






(
)
(
)
x
J d
d
d
a
µ0 0
2
2
2
2
1
1
W/m
	
Now, we use the result of the previous example to derive another important result. Let us consider 
the situation where the radius of the plate is extended to infinity, that is, a → ∞. Thus, for an infinite plate 
situated at z = 0, the fields at a point d meters away from the plate along the z-axis are given by
	
E
a
a
=
=
z
s
x
q
B
J
2
2
0
0 0
2
ε (
(
)
(
)
V/m) and
W/m
µ
	
Further, we note the following:
• 
az is the normal vector from the plane of the plate to the point of observation, which may be 
referred to, in general, as an.
• 
ax is actually the vector obtained by taking a cross product of the current direction vector, ay, with 
the normal vector an = az.
Thus, in general, for an infinite plate, the electric field and the magnetic flux density are given by
	
E
a
B
J
a
=
=
×
qs
s
2
2
0
0
2
ε
n
n
(
(
)
V/m) and
W/m
µ
	
(29.19)
Also, note that in Equation 29.19, the normal vector an is pointing into the region where the fields are 
observed.
Before closing this section, we note the following important observations:
	
1.	 The sources for the electric field and magnetic flux density are charges and currents, respectively.
	
2.	 The basic building blocks for the case of electric field and magnetic flux density are point charges 
and elemental currents, respectively.
	
3.	 The total fields for discrete or continuous source distributions are obtained using the principle of 
superposition.
	
4.	 For elemental sources (i.e., point charges and elemental currents), the fields vary as the inverse of 
the square of the distance.
	
5.	 For infinitely long line sources, the fields vary as the inverse of the distance.
	
6.	 For infinite surface source distributions, the fields are constant no matter how far the observation 
point is located.
© 2011 by Taylor and Francis Group, LLC

Electromagnetic Fields I 
29-13
29.4  Potential Theory
In the previous section, we have learned a general technique to calculate E and B at any observation 
point once the source distribution is given. The technique presented is applicable to all situations, at 
least in theory. However, the method is cumbersome when the source distribution is complicated. 
This is because the procedure involves developing three integrals, one for each component, and eval-
uating them. Furthermore, all operations are vector operations, which are somewhat tricky. Thus, 
there is a need to develop alternate methods that may provide mathematically easier solution pro-
cedures. It is widely believed that potential theory, as discussed in the following sections, provides 
such a method.
29.4.1  Concept of Potential Energy
We begin our study by taking a closer look at the concept of potential energy. From fundamental phys-
ics, we are all familiar with the concept of objects being moved by a force field, viz., the gravitational 
field. The fundamental concept that should be borne in mind is that whenever there is work done on the 
system, such as moving an object in a force field, the amount of work done is transferred to the system 
as potential energy.
This concept is also valid for force fields E and B, which we are presently studying. Thus, if we move a 
point charge either in an electric field or a flux field, work must be done to counter the force exerted by 
these fields. Obviously, the work done is stored in the system as the potential energy for the point charge 
in the presence of the field. Now this system is capable of performing some useful functions. In other 
words, the system acquires certain potential or capability to perform given tasks.
Mathematically, we may express incremental work done or the potential energy stored as
	
dW
F dl
= −⋅
	
(29.20)
where dl is the incremental displacement along the direction of the movement. It is obvious that since 
the force fields are vector fields, the amount of work done depends on the direction of movement. Also, 
the negative sign in Equation 29.20 implies that work must be done to counter the force exerted by the 
fields.
Next, the total work done when a point charge moved from point A to point B is given by
	
WAB
A
B
= −
⋅
∫F dl (J)
	
(29.21)
29.4.2  Electric Potential
We define electric potential, or simply potential, as the work done per unit charge and it is given by
	
V
W
Q
Q
Q
Q
AB
AB
A
B
A
B
A
B
=
= −
⋅
= −
⋅
= −
⋅
∫
∫
∫
1
1
F dl
E dl
E dl
	
(29.22)
© 2011 by Taylor and Francis Group, LLC

29-14 
Fundamentals of Industrial Electronics
Notice that potential is, in reality, the potential difference between two points, that is, A and B. Thus, 
we always measure potential as a difference between two given points, that is, the initial point and the 
final point. The initial point is also known as reference point. If the reference point is at infinity, then the 
potential is known as absolute potential. The units of potential are volts (V).
If we carry out the integral in Equation 29.22 over a closed loop, we notice that the initial and final 
points are same. Obviously, the result is then zero. This implies that the potential difference between two 
points that are identical to each other is zero. Thus, we have
	
E dl
⋅
=
∫
l
0
	
(29.23)
Equation 29.23 is also telling us that the electrostatic field is conservative, which implies that the work 
done in this force field is independent of the path. Note that, in general, all force fields are not conserva-
tive. We just happened to get lucky.
Using Stoke’s theorem, we can rewrite Equation 29.23 as
	
∇×
=
E
0 	
(29.24)
which says that the electrostatic field is curl-free or irrotational.
29.4.3  Relationship between E and V
We have already seen in the previous section the relationship between the electric field E and the poten-
tial V, which is given by Equation 29.22. This equation is useful when we need to calculate the potential 
difference between two points in a given electric field. However, in many situations, we need to compute 
the electric field once the potential is known. Thus, in the following, we derive another relationship 
between E and V, which enables us to do just that.
From Equation 29.22, we can write the following equation as
	
dV = −⋅
E dl 	
(29.25)
Now, consider the left hand side of Equation 29.25. Using basic calculus involving partial derivatives, 
we have
	
dV
V
x dx
V
y dy
V
z dz
V
= ∂
∂
+ ∂
∂
+ ∂
∂
= ∇
⋅dl
	
(29.26)
Using Equation 29.26, we can write Equation 29.25 as
	
E dl
dl
E
⋅
= −∇
⋅
⇒
= −∇
V
V 	
(29.27)
Thus, we see that we can calculate the electric field by taking the gradient of the potential function. 
This is an important result and provides us the new method for which we are looking. In this new 
method, we compute the potential function for a given charge distribution and then obtain the electric 
© 2011 by Taylor and Francis Group, LLC

Electromagnetic Fields I 
29-15
field by taking the gradient. Although this is an indirect method of calculating the electric field, it is 
definitely an easier one because of the following reasons:
•	 Computing V is straightforward and relatively easy because we are dealing with scalar quantities.
•	 For a given charge distribution, we only need to evaluate one integral, that is, potential integral.
•	 The electric field is obtained by differentiating the potential function, which is comparatively easy.
•	 No computation of unit vectors.
•	 Method is general and applicable to all situations.
29.4.4  Potential Function for a Given Charge Distribution
Before we develop the potential function for a given charge distribution, we calculate the potential func-
tion for a point charge located at the origin.
Consider a point charge Q located at the origin, as shown in Figure 29.13.
The absolute potential at R meters from the point charge is given by
	
V
Q
r
dr
Q
dr
r
Q
R
R
r
r
R
R
= −
⋅
= −
⋅
= −
=
∞
∞
∞
∫
∫
∫
E dl
a
a
4
4
4
0
2
0
2
0
πε
πε
πε
	
(29.28)
Thus, the potential function of a point charge varies as the inverse of the distance from its location.
Next, we consider the potential function for a given charge distribution. Referring to Figures 29.1 
and 29.2, the potential function is obtained using the principle of superposition, that is, calculating the 
potential from individual charges and obtaining the sum. Mathematically, we have
	
V
Q
R
q dl
R
q ds
R
q dv
R
i
i
i
N
l
l
s
S
v
v
=
=
=
=
=∑
∫
∫
∫
4
4
4
4
0
1
0
0
0
πε
πε
πε
πε
	
(29.29)
29.4.5  Vector Potential
Now let us take a look at the calculation of B. Unfortunately, for this case we do not have a physical 
quantity, such as potential, which is a scalar. The primary reason for this difficulty is our sources, which, 
for this case, are vectors. Since the sources (currents) are vectors, all the quantities directly related to 
these sources must necessarily be vectors. Thus, we define a quantity 
known as Vector potential A, with the following characteristics:
•	 The quantity, vector potential A, is analogous to the potential 
function V with one difference, that is, it is a vector function. 
Also, the direction of A is simply the direction of the current 
source.
•	 The magnetic flux density B is obtained by the relation
	
B
A
= ∇×
	
(29.30)
•	 The units for A are Wb/m.
•	 The most important concept to notice is, unlike V, A is not a 
physical quantity. It is only a mathematical tool to compute B.
x
X
Y
Z
Q
R
FIGURE 29.13  Potential of a 
point charge.
© 2011 by Taylor and Francis Group, LLC

29-16 
Fundamentals of Industrial Electronics
Keeping these facts in mind, we write A for current distributions as follows:
•	 For a current element I dl, we have
	
A
dl
= µ
π
o I
R
4
	
(29.31)
•	 For a linear current distribution, we have
	
A
dl
=
∫
µ
π
o
l
I
R
4
	
(29.32)
•	 For a surface current distribution Js, we have
	
A
J
=
∫
µ
π
o
s
s
ds
R
4
	
(29.33)
•	 For a volume current distribution Jv, we have
	
A
J
=
∫
µ
π
o
v
v
dv
R
4
	
(29.34)
29.4.6  Illustrative Examples
Example 29.4
Consider three point charges Q1 = Q2 = Q3 = Q located at (a, 0, 0), (0, a, 0), and (0, 0, a), as shown in Figure 
29.10a.
	
1.	 Calculate the total potential VT at the origin.
	
2.	 If the charges are replaced by current elements, as shown in Figure 29.10b, calculate the vector 
potential AT at the origin.
Solution
The total potential VT(0, 0, 0) is the sum of the potentials from each charge. Notice that the distance from 
each charge to the point of observation is a. Thus, using Equation 29.28,
	
V
V
V
V
Q
a
Q
a
Q
a
Q
a
T =
+
+
=
+
+
=
1
2
3
0
0
0
0
4
4
4
3
4
πε
πε
πε
πε
(V)
	
Using Equation 29.30, we have
	
A
a
1
0
4
=
−
µ
π
Idl
a
y
(
)
	
© 2011 by Taylor and Francis Group, LLC

Electromagnetic Fields I 
29-17
	
A
a
2
0
4
=
−
µ
π
Idl
a
z
(
)
	
	
A
a
3
0
4
=
−
µ
π
Idl
a
x
(
)
	
Thus, we have
	
A
a
a
a
T
y
z
x
Idl
a
= −
+
+
µ
π
0
4
[
] (Wb/m)
	
Example 29.5
Consider a straight wire of length 2l meters carrying a uniform charge density q1 C/m, as shown in Figure 
29.11a. (1) Calculate the potential V at a point P, located x meters from the axis of the wire. Then, calculate 
the electric field E using this result. (2) If the wire is carrying uniform current, as shown in Figure 29.11b, 
then calculate A and B at the point P.
Solution
In this example also, we use the principle of superposition as applied in Example 29.2.
Referring to Figure 29.11c, the charge dQ on each segment is given by
	
dQ
q dl
q dy
l
l
=
=
	
	
R
x
y
=
+
2
2
	
and
	
dV
q dy
x
y
l
=
+
4
0
2
2
πε
	
The integration is straightforward and we have
	
V
q
dy
x
y
l
l
l
=
+
−∫
4
0
2
2
πε
	
The integral in the previous step may be evaluated using simple substitutions or tables of integration. 
Thus, we have
	
V
q
x
y
y
q
x
l
l
x
l
l
l
l
l
l
=
+
+
(
)




=
+
+
(
)−
+
−
(
)
−
4
4
0
2
2
0
2
2
2
2
πε
πε
ln
ln
ln



	
© 2011 by Taylor and Francis Group, LLC

29-18 
Fundamentals of Industrial Electronics
Next, the electric field E may be calculated as
	
E
a
a
a
= −∇
= −∂
∂
=
+





=
V
V
x
q
x
l
x
l
q
x
x
x
l
x
l
4
2
2
0
2
2
0
πε
πε
α
cos
	
For part (b), referring to Figure 29.11b, we define each current element as
	
Idl
Idyay
=
	
	
R
x
y
=
+
2
2
	
	
dA
a
=
+
µ
π
0
2
2
4
Idy
x
y
y
	
and
	
A
a
a
a
=
+
=
+
+
(
)




=
−
−
∫
y
l
l
y
l
l
y
I
dy
x
y
I
x
y
y
I
µ
π
µ
π
µ
π
0
2
2
0
2
2
0
4
4
4
ln
ln
x
l
l
x
l
l
2
2
2
2
+
+
(
)−
+
−
(
)




ln
	
To obtain B, we carry out the following steps:
	
B
A
a
a
a
= ∇×
=
∂
∂
= −
+





= −
z
y
z
z
A
x
I
x
l
x
l
I
x
µ
π
µ
π
α
0
2
2
0
4
2
2
cos
	
29.5  Gauss’ Law and Ampere’s Law
In this section, we shall study yet another method to calculate the electric field and magnetic flux den-
sity from a given source distribution. Admittedly, this new method is not as general as the previous two 
techniques and is applicable to some selected problems only. Although the method is a restricted one, 
it is very easy to understand and also simple to evaluate. The pro-
cedure is based on simple intuitive concepts and provides a lot of 
insight in understanding the field concepts. We begin the study by 
looking at the electrostatic case.
29.5.1  Gauss’ Law
Gauss’ law may be stated as follows:
The charge residing inside a closed surface is proportional to the 
electric field emanating from the surface.
The Gauss’ law may be explained as follows:
Consider a lump of positive charge placed inside a box, as shown 
in Figure 29.14. The box can be of any shape. However, we assume 
+Q
Gaussian surface
s
FIGURE 29.14  Positive charge 
inside a box made of electrically 
transparent material.
© 2011 by Taylor and Francis Group, LLC

Electromagnetic Fields I 
29-19
that the box is made of an electrically transparent material. Because the box is transparent, we have an 
electric field coming out of the box. Remember that positive charge produces an electric field that will 
terminate somewhere on the negative charge. If we collect all the electric field coming out of the box and 
sum it up, then Gauss’ law states that the result is proportional to the charge inside the box.
Now, consider another situation, as shown in Figure 29.15. Here we have both positive charge and 
negative charge. Note that, for this case, the electric field coming out of the positive charge is terminat-
ing on the negative charge. Now let us consider a box that encloses both charges. If we sum up all the 
electric field emanating from and entering into this surface, Gauss’ law states that the summation would 
be zero. This is because same amount of electric field emanating from one side of the box is entering 
from other side and summation always turns out to be zero.
Mathematically, we can write Gauss’ law as
	
E a
⋅
∫
n
enclosed
S
dsα Q

	
where
E a
⋅
∫
n
S
ds

 gives us the summation of the electric field over the closed surface S
Qenclosed is the net charge inside the box
Note that the net charge is actually the sum of all positive and negative charges residing in the box. The 
variational relation may be converted into an equation by introducing a constant. Thus, we have
	
E a
⋅
=
∫
n
enclosed
S
ds
Q
ε0

	
(29.35)
Notice that the surface S must necessarily be a closed surface.
One of the simple applications of Gauss’ law is if we know the electric field, even if we do not know 
the actual charge producing it, we can enclose the electric field in a closed box and replace the actual 
source by an equivalent charge. We may consider this application as somewhat analogous to Thevenin’s 
theorem in circuit theory.
Next, we look at an alternate form of Gauss’ law. We know that Qenclosed may be written as
	
Q
q dv
enclosed
v
v
=∫
	
+Q
S
–Q
Gaussian surface
FIGURE 29.15  Positive and negative charges inside a box made of electrically transparent material.
© 2011 by Taylor and Francis Group, LLC

29-20 
Fundamentals of Industrial Electronics
Then, using the Divergence theorem, we can write Equation 29.35 as
	
∇⋅
=
E
qv
ε0 	
(29.36)
which is known as the differential form of Gauss’ law.
29.5.2  Ampere’s Circutal Law
Just like Gauss’ law for the electric field, we also have Ampere’s law for the magnetic flux density, which 
may be stated as follows:
The total current crossing a surface is proportional to the line integral of the magnetic flux density 
enclosing the surface.
Mathematically, Ampere’s law may be written as
	
B dl
⋅
∝Icrossing
C∫
	
where C is the contour enclosing the surface S.
The variational relation may be changed into an equation by introducing a constant. Thus, we have
	
B dl
⋅
=
∫
µ0Icrossing
C
	
(29.37)
Next, we derive an alternate form of Ampere’s law. We know that Icrossing may be written as
	
I
ds
crossing
n
S
=
⋅∫J a
	
Then, using Stoke’s theorem, we can write Equation 29.37 as
	
∇×
=
B
J
µ0 	
(29.38)
which is known as the differential form of Ampere’s law.
29.5.3  Applications
Gauss’ law and Ampere’s law may be used to calculate the electric field and magnetic flux density, respec-
tively, from a given source distribution. However, the method we are going to discuss is not a general 
method and is applicable only for specific situations. In order to use either Gauss’ law or Ampere’s law to 
calculate the field distribution, the source distribution must have the following property:
The source distribution should be such that the field component of interest can be a function of one 
variable only.
If the field varies as a function of more than one variable, this method cannot be applied and we have 
to use the methods discussed in the previous section. Further, we remark that for a given problem, it 
is not always obvious whether this method is applicable or not. A good amount of experience is called 
for before we start seeing the light. Despite all these limitations, the method turns out to be very simple 
when applicable. In the following, we consider some illustrative examples to understand the method.
© 2011 by Taylor and Francis Group, LLC

Electromagnetic Fields I 
29-21
Example 29.6
Consider an infinite length of wire carrying a uniform charge density ql C/m, as shown in Figure 29.16a.
	
1.	 Calculate the electric field E at a point P, located ρ meters from the axis of the wire.
	
2.	 If the infinite wire is carrying current along the z-direction, as shown in Figure 29.16b, then calcu-
late B using Ampere’s law.
Solution
Since the wire is infinitely long, we can safely divide the wire into two semi-infinite halves along the 
point of observation, as shown in Figure 29.16a. If we consider two elemental charges, one above the 
xy-plane and one below at equal distances, it is very easy to prove that the axial components cancel 
and only the radial component survives. Since we can apply this procedure for any point of observa-
tion, we say that, in general, only the radial component is non-zero. Further, we note that, due to sym-
metry, the radial component is only a function of the radial distance from the axis of the wire. Thus, 
we have E = Eρaρ, and Eρ is a function of ρ only for this problem. We will calculate Eρ using Gauss’ law.
1. In order to use Gauss’ law, we must have a closed surface (box). Since we do not have any surface 
around the line charge, we simply draw a cylindrical surface, closed at both ends, around the line charge, 
as shown in Figure 29.17a. Now, we apply Gauss’ law using this surface.
Note that we can draw a surface of any shape. However, the solution will be easier if we draw a surface 
that fits into the coordinate system. The cylindrical surface, which we imagined, is known as a Gaussian 
surface, in general.
P
(b)
Y
ρ
To infinity
Z
IL
P
X
X
ρ
(a)
To infinity
Z
Y
qL
FIGURE 29.16  (a) Infinite line charge and (b) infinite line current.
X
Y
Z
To infinity
qL
(a)
Gaussian surface
Y
IL
X
Z
To infinity
(b)
Amperean loop
FIGURE 29.17  (a) Gaussian surface and infinite line charge and (b) Amperean loop and infinite line current.
© 2011 by Taylor and Francis Group, LLC

29-22 
Fundamentals of Industrial Electronics
Referring to Equation 29.35, we have
	
E a
a
a
l
⋅
⋅
∫
∫
n
S
S
ds
E
ds
E


=
=
π
ρ
ρ
ρ
ρ2
	
and
	
Q
q l
enclosed
l
=
	
Thus, we have
	
E
l
q ll
ρ πρ
ε
2
0
=
	
which implies
	
E
ql
ρ
πε ρ
= 2
0
	
2. The method using Ampere’s law has the same restrictions as the method using Gauss’ law. Here, we 
define an Amperean loop around the wire, as shown in Figure 29.17b, and apply Ampere’s law. For this 
case, we have B = Bϕaϕ only. Referring to Equation 29.37, we have
	
B dl
a
a
C
C
B
dl
B


∫
∫
⋅
=
⋅
=
φ
φ
φ
φ
ρ
2π
	
and
	
I
I
crossing = 	
Thus, we have
	
Bφ πρ
µ
2
0
=
I 	
which implies
	
B
I
o
φ
µ
πρ
= 2
	
Example 29.7
Consider an infinite plate carrying a uniform surface charge density qs C/m2, as shown in Figure 29.18a. 
(1) Calculate the electric field E at a point P, located h meters from the plane of the plate. (2) If the 
infinite plate is carrying current density Js = J0ay, as shown in Figure 29.18b, then calculate B using 
Ampere’s law.
© 2011 by Taylor and Francis Group, LLC

Electromagnetic Fields I 
29-23
Solution
(1) For this case, it is easy to prove that the electric field has only z-component and it is independent of x 
and y. Drawing a cylindrical box, closed at both ends, as in the Gaussian surface, we have the following:
Referring to Equation 29.35, we have
	
E a
a
a
⋅
=
⋅
=
+
=
∫
∫
n
S
z
z
z
z
z
z
ds
E
E A
E A
E A


2
	
and
	
Q
q A
enclosed
s
=
	
In the previous equation, A is the area of the cross section of the cylindrical box. Note that we need 
to evaluate the closed surface integral on both ends of the box and hence we have the factor 2 in the 
equation. Thus, we have
	
E
A
q A
z
s
(
)
2
0
= ε
	
which implies,
	
E
q
z
s
= 2 0ε
	
(2) For this case, it is easy to prove that B = Bxax above the plate and B = Bx(−ax) below the plate. This 
can be done by either using the right hand rule or considering two infinitely long filament currents at 
equal distance on either side of the x-axis. Considering an Amperean loop, as shown in the figure and 
referring to Equation 29.37, we have
	
B dl
a
dl
⋅
C
x
x
x
x
x
C
B
B l
B l
B l


∫
∫
=
⋅
=
+
= 2
	
and
	
I
J l
crossing =
0 	
Thus, we have
	
B
l
J l
x( )
2
0 0
= µ
	
which implies,
	
B
J
x = µ0 0
2
	
(a)
Z
qs
Y
X
Gaussian surface
(b)
Z
JS
Y
X
Amperean loop
FIGURE 29.18  (a) Gaussian surface and infinite plane charge. (b) Amperean loop and infinite plane current.
© 2011 by Taylor and Francis Group, LLC

29-24 
Fundamentals of Industrial Electronics
Example 29.8
Consider a charge Q C distributed uniformly over the surface of a sphere of radius a, as shown in Figure 
29.19a. Calculate the electric field E at a point P, located r meters from the center of the sphere. Consider 
both cases, that is, (1) r < a, and (2) r > a.
Solution
For this case, it is easy to prove that the electric field has only a r-component and it is independent of θ 
and ϕ due to the symmetrical nature of the charge distribution.
Case (1): Let us consider the situation r < a. Drawing a sphere with radius r as the Gaussian surface, 
shown with dotted lines in Figure 29.19b, we note that the charge enclosed by the Gaussian 
surface is zero. Hence, we have Er = 0 for r < a.
Case (2): Again, let us consider a Gaussian sphere of radius r and r > a, shown with dotted lines in 
Figure 29.19c. Now, we see that all the charge is enclosed by the Gaussian sphere. Thus, we 
have
	
Q
Q
enclosed =
	
Next, we have
	
E a
a a
E
⋅
=
⋅
=
∫
∫
n
S
r
r
r
r
S
ds
E
ds
r
4π 2

	
Then, using Equation 29.35, we have
	
E
Q
r = 4
0
2
πε r 	
Example 29.9
Consider a current I A flowing over the surface of an infinitely long circular cylinder of radius a, as shown 
in Figure 29.20a. Calculate the magnetic flux density B at a point P, located ρ meters from the axis of the 
cylinder. Consider both cases, that is, (1) ρ < a and (2) ρ > a.
Solution
For this case, it is easy to prove that B has only ρ-component and it is independent of z and ϕ due to the 
symmetrical nature of the current distribution.
+
Z
X
Y
+
+
+
+
+
+
+
Q
Q
Q
+
+
+
+
+
(a)
Z
X
Y
Y
(b)
Z
X
(c)
FIGURE 29.19  (a) Charge on a spherical surface. (b) Internal problem. (c) External problem.
© 2011 by Taylor and Francis Group, LLC

Electromagnetic Fields I 
29-25
Case (1): Let us consider the situation ρ < a. Drawing an Amperean loop of radius ρ, as shown in 
Figure 29.20b, we note that the current crossing the surface formed by the Amperean loop 
is zero. Hence, we have Bρ= 0 for ρ < a.
Case (2): Again, let us consider an Amperean loop of radius ρ > a, as shown in Figure 29.20c. Now, 
we see that all the current is crossing the surface enclosed by the Amperean loop. Thus, 
we have
	
I
I
crossing = 	
Next, we have
	
Bdl
a
a
C
B
dl
B


∫
∫
=
⋅
=
φ
φ
φ
φ
ρ
2π
	
Then, using Equation 29.37, we have
	
B
I
φ
µ
πρ
=
0
2
	
Example 29.10
Consider a charge Q C distributed uniformly over the volume of a sphere, of radius a, as shown in Figure 
29.21a. Calculate the electric field E at a point P, located r meters from the center of the sphere. Consider 
both cases, that is, (1) r > a and (2) r > a
Solution
Case (1): Let us consider the situation r < a. Drawing a sphere with radius r as the Gaussian surface, 
shown with dotted lines in Figure 29.21b, we note that the charge enclosed by the Gaussian 
surface is proportional to the ratio of volumes of the Gaussian sphere and the charged 
sphere. Thus, we have
	
Q
Q r
a
enclosed =
3
3 	
X
Y
Z
To 
infinity
I
(a)
To 
infinity
X
Y
Z
I
(b)
To 
infinity
X
Y
Z
I
(c)
FIGURE 29.20  (a) Infinitely long circular cylinder with radius a carrying current I. (b) Amperean loop inside the 
cylinder. (c) Amperean loop outside the cylinder.
© 2011 by Taylor and Francis Group, LLC

29-26 
Fundamentals of Industrial Electronics
Next, we have
	
E a
a a
⋅
=
⋅
=
∫
∫
n
r
r
r
r
ds
E
ds
E
r
S
S


4
2
π
	
Then, using Equation 29.35, we have
	
E
Qr
a
r = 4
0
3
πε
	
Case (2): Again, let consider a Gaussian sphere of radius r and r > a. Now, referring to Figure 29.21c, we 
see that all the charge is enclosed by the Gaussian sphere. Thus, we have
	
Q
Q
enclosed =
	
Next, we have
	
E a
a a
⋅
=
⋅
=
∫
∫
n
r
r
r
r
ds
E
ds
E
r
S
S


4
2
π
	
Then, using Equation 29.35, we have
	
E
Q
r
r = 4
0
2
πε
	
Example 29.11
Consider a current I A flowing along the volume of an infinitely long circular cylinder of radius a, as shown 
in Figure 29.22a. Calculate the magnetic flux density B at a point P, located ρ meters from the axis of the 
cylinder. Consider both cases, that is, (1) ρ < a and (2) ρ > a.
Solution
Case (1): Let us consider the situation ρ < a. Drawing an Amperean loop of radius ρ, we note that the 
current crossing the surface formed by the Amperean loop is given by
	
I
I a
crossing = ρ2
2 	
X
Y
Z
(a)
X
Y
Z
(b)
X
Y
Z
(c)
FIGURE 29.21  (a) Charge distributed inside a spherical volume. (b) Internal problem. (c) External problem.
© 2011 by Taylor and Francis Group, LLC

Electromagnetic Fields I 
29-27
Next, we have,
	
Bdl
a
a
C
B
dl
B


∫
∫
=
⋅
=
φ
φ
φ
φ
ρ
2π
	
Then, using Equation 29.37, we have
	
B
I
a
φ
µ ρ
π
=
0
2
2
	
Case (2): Again, let us consider an Amperean loop of radius ρ > a. Now, referring to the figure, we see 
that all the current is crossing the surface enclosed by the Amperean loop. Thus, we have
	
I
I
crossing = 	
Next, we have
	
Bdl
a
a
C
B
dl
B


∫
∫
=
⋅
=
φ
φ
φ
φ
ρ
2π
	
Then, using Equation 29.37, we have
	
B
I
φ
µ
πρ
=
0
2
	
29.6  Material Interaction
In this section, we study the interaction of materials with electric field and magnetic flux density. Recall 
that so far we have assumed the sources are located in a homogeneous medium. However, in a practical 
situation, the electric field or the magnetic flux cross from one medium to other and we need to examine 
this phenomenon in more detail.
X
Y
Z
To
infinity
I
(a)
To
infinity
X
Y
Z
I
(b)
To
infinity
X
Y
Z
I
(c)
FIGURE 29.22  (a) Current flowing inside a cylindrical volume. (b) Internal problem. (c) External problem.
© 2011 by Taylor and Francis Group, LLC

29-28 
Fundamentals of Industrial Electronics
29.6.1  Polarization
From the electric field point of view, one may classify all the materials into two categories: conductors 
and dielectrics. For both materials, the material parameter, conductivity (σ), which depends on the 
number of electrons situated in the outermost orbit of respective atoms, plays a significant role. If σ is 
very large (>105), the material is classified as a conductor, otherwise as a dielectric.
For conductors, we note that the field penetrating the material is zero. However, for a dielectric, the 
field penetration is significant given by a phenomenon called polarization (P).
It is noted that when a dielectric material is subjected to an electric field, each atom behaves like a 
small dipole (defined as two equal and opposite charges separated by a small distance) and net effect of 
all these dipoles result in polarization.
Mathematically, the total field is the applied field plus the field induced due to polarization. It is cus-
tomary to define a new quantity, in the presence of dielectrics, to take care of the polarization phenom-
enon, known as electric flux density (D), measured in C/m2, given by
	
D
E
P
=
+
εo
	
(29.39)
Another way of taking care of polarization is to define a quantity known as relative permittivity (εr), 
which is equal to unity for free-space (air) and greater than 1 for all other dielectric materials. Using this 
quantity, we define the following relationships, given by
	
P
E
D
E
=
−
=
(
)
ε
ε
ε ε
r
o
r
o
1
and
	
(29.40)
29.6.2  Magnetization
In a similar way, from the magnetic flux point of view, it is noted that when a magnetic material is sub-
jected to magnetic flux, each atom behaves like small magnet and the net effect of all these dipoles result 
in magnetization (M).
Mathematically, the total magnetic flux is the applied flux plus the flux induced due to magnetization. 
It is customary to define a new quantity, in the presence of magnetic materials to take care of the magne-
tization phenomenon, known as magnetic field (H), measured in A/m, and is given by
	
H
B
M
=
−
µo
	
(29.41)
Another way of taking care of magnetization is to define a quantity known as relative permeability 
(μr), which is equal to unity for free-space (air) and for most materials except ferromagnetic materials 
(∼106). Using this quantity, we define the following relationships, given by
	
M
H
B
H
=
−
=
(
)
µ
µ µ
r
r
o
1
and
	
(29.42)
29.6.3  Boundary Conditions
We note that the electric and magnetic fields must satisfy certain boundary conditions when propagat-
ing from one material medium to another material medium. Assuming the material interface is locally 
© 2011 by Taylor and Francis Group, LLC

Electromagnetic Fields I 
29-29
planar, it is customary to define the boundary conditions in terms of the tangential and normal compo-
nents with respect to the interface. Assuming there are no sources on the interface, we have
	
E
E
H
H
t
t
t
t
1
2
1
2
=
=
and
	
(29.43)
	
D
D
B
B
n
n
n
n
1
2
1
2
=
=
and
	
(29.44)
where the subscripts “t” and “n” refer to tangential and normal components, respectively.
However, if the interface contains sources, then we have
	
D
D
q
H
H
J
n
n
s
t
t
s
2
1
2
1
−
=
−
=
and
	
(29.45)
where qs and Js represent the surface charge density and surface current density of the sources located on 
the interface, respectively, and the normal points into medium #2 from medium #1.
The derivation of Equations 29.43 through 29.45 is trivial and may be found in any elementary text-
book on electromagnetic theory.
29.7  Faraday’s Law, Displacement Current, 
and Maxwell’s Equations
In 1820, Hans Christian Oersted demonstrated experimentally that electric current can produce mag-
netic fields. Soon after, Michael Faraday devised experiments to produce electric current from magnetic 
field. His initial experiments were not successful because he used steady magnetic fields that produced 
no electrical phenomenon. Then, almost by accident, he discovered that if a device generates a time-
changing magnetic field, then it can produce current in a neighboring circuit even when there is no 
physical contact between the two. His experimental observations have become famous and known 
today as Faraday’s law.
29.7.1  Faraday’s Law
The Faraday’s law may be stated as any time-varying magnetic flux linking a neighboring loop would 
cause currents in the loop. Mathematically, the law can be stated as
	
E dl
B a
⋅
= −
⋅
∫
∫
C
n
S
d
dt
ds


	
(29.46)
where S represents any arbitrary, open surface enclosed by the contour C.
In Equation 29.46, the negative sign eliminates the impossible situation of developing infinite fields, 
introduced by Henri Frederic Emile Lenz.
Using the Stoke’s theorem, Faraday’s law can be transformed into an alternate form, given by
	
∇×
= −∂
∂
E
B
t 	
(29.47)
© 2011 by Taylor and Francis Group, LLC

29-30 
Fundamentals of Industrial Electronics
29.7.2  Displacement Current
Soon after the discovery of Faraday’s law, Maxwell proved mathematically that Ampere’s law is incon-
sistent when the time-varying situation is considered. The proof is as follows.
Since ∇ · ∇ × A = 0 for any vector A, using Ampere’s law given by Equation 29.38, it can be shown that
	
∇⋅∇×
= ∇⋅
=
⇒
∇⋅
=
H
J
J
0
0 	
(29.48)
However, the continuity equation given by Equation 29.7 shows that ∇ · J need not be zero always. 
Hence, to remove this inconsistency, Maxwell modified Ampere’s law by adding another term to 
Equation 29.38 as
	
∇×
=
+ ∂
∂
H
J
D
t 	
(29.49)
where ∂D/∂t is referred to as the displacement current density.
29.7.3  Maxwell’s Equations
Once the inconsistency in Ampere’s law was removed, Maxwell wrote down his famous four equations as
	
∇×
= −∂
⇒
⋅
= −
⋅
∫
∫
E
B
E dl
B a
∂
t
d
dt
ds
C
n
S

	
(29.50)
	
∇×
=
+ ∂
∂
⇒
⋅
=
⋅
+
⋅
∫
∫
∫
H
J
D
H dl
J a
D a
t
ds
d
dt
ds
C
n
S
n
S
	
(29.51)
	
∇⋅
=
⇒
⋅
=
∫
D
D a
q
ds
Q
v
n
S
	
(29.52)
	
∇⋅
=
⇒
⋅
=
∫
B
B a
0
0
n
S
ds

	
(29.53)
and claimed that all the electromagnetic phenomenon must satisfy these four equations along with the 
continuity equation (Equation 29.7).
29.8  Summary
In this chapter, we defined electric field and magnetic flux density using Couloumb’s law and Biot–Savart 
law. We have also developed three methods to compute the E and B fields for a given source distribution.
The first method is based on the definition of fields from elemental sources and uses superposition 
to obtain the fields at any point of observation. Although this method is general, unfortunately, it is 
cumbersome.
The second method is based on the potential theory. This method is general and applicable to all situ-
ations. Actually, this is the preferred method in most situations.
Lastly, we developed yet another method based on Gauss/Ampere’s law. This method is easy and con-
ceptually simple to apply. Unfortunately, this method is applicable to very few situations only.
We have described Faraday’s law, which establishes the connection between electric and magnetic 
fields and briefly described the contribution of Maxwell to the electromagnetic phenomenon.
© 2011 by Taylor and Francis Group, LLC

30-1
30.1  Maxwell’s Equations in the Time Domain 
and Phasor Domain
In this chapter, we will begin by investigating electromagnetic wave propagation in complex media via 
a solution of the Maxwell’s equations. This will be followed by a section that focuses on analyzing wave 
propagation on terminated transmission lines and typical impedance-matching techniques. Next, electro-
magnetic wave propagation inside rectangular waveguides, dielectric waveguides, and optical fiber is char-
acterized. The final section is an overview of the transmission and reception characteristics of antennas.
30.1.1  Maxwell’s Equations in Complex (Phasor) Domain
Maxwell’s Equations are the governing equations that describe all macroscopic electromagnetic field 
behavior. They may be stated in either the differential or integral form and are associated with earlier 
work by Faraday, Ampere, and Gauss, as shown below.
Faraday’s law of induction (Maxwell’s first equation):
	
∇×
= −∂
∂
E
B
t 	
(30.1)
30
Propagating 
Electromagnetic Fields
30.1	 Maxwell’s Equations in the Time Domain and Phasor 
Domain..............................................................................................30-1
Maxwell’s Equations in Complex (Phasor) Domain  •  Maxwell’s 
Equations in Complex (Phasor) Domain  •  Uniform Plane 
Waves  •  Propagation in a Lossless Media  •  Propagation 
in a Low-Loss Dielectric  •  Propagation in a Good 
Conductor  •  Reflection and Transmission of Plane Waves
30.2	 Transmission Lines..........................................................................30-9
Overview  •  Analysis  •  Lossless Transmission Lines  •  Terminated 
Transmission Lines  •  Smith Chart  •  Impedance Matching
30.3	 Waveguides.....................................................................................30-18
Hollow Conducting Cylinders  •  Transverse Electric TEm,n 
Waves  •  Transverse Electric TMm,n Waves  •  Dielectric 
Waveguides  •  Fiber Optics
30.4	 Antennas.........................................................................................30-27
Differential or Hertzian Dipole  •  Dipole of Length L  •  Half-Wave 
Dipole  •  Antenna Characteristics
30.5	 Summary.........................................................................................30-31
Michael E. Baginski
Auburn University
Sadasiva M. Rao
Auburn University
Tyler N. Killian
Auburn University
© 2011 by Taylor and Francis Group, LLC

30-2 
Fundamentals of Industrial Electronics
	
E dl
B
t dS
C
S
⋅
= −
∂
∂⋅
∫
∫


	
(30.2)
Ampere’s law (Maxwell’s second equation):
	
∇×
= + ∂
∂
H
J
D
t 	
(30.3)
	
H dl
J
D
t
dS
C
S
⋅
=
+ ∂
∂



⋅
∫
∫

	
(30.4)
Gauss’ law (Maxwell’s third equation):
	
∇⋅
=
D
qv 	
(30.5)
	
D dS
q dv
S
v
v
⋅
=
∫
∫

	
(30.6)
Conservation of magnetic flux (Maxwell’s fourth equation):
	
∇⋅
=
B
0 	
(30.7)
	
B dS
S
⋅
=
∫
0 	
(30.8)
Current continuity equation can then be obtained by taking the divergence of Equation 30.3 and 
­substituting qv = ∇ · D:
	
∇⋅+ ∂
∂
=
J
q
t
v
0 	
(30.9)
	
J dS
q
t dv
S
v
v
⋅
= −
∂
∂
∫
∫

	
(30.10)
The equations indicate that a time-varying magnetic field gives rise to a time-varying electric field 
(Equations 30.1 and 30.2), and time-varying electric fields or current densities induce time-varying 
magnetic fields (Equations 30.3 and 30.4). Equations 30.5 and 30.6 show the relationship between charge 
density and the total electric flux. Finally, Equations 30.7 and 30.8 mathematically state that magnetic 
charges (monopoles) do not exist.
30.1.2  Maxwell’s Equations in Complex (Phasor) Domain
The differential form of Maxwell’s Equations depends on three spatial coordinates and time. However, in 
many circumstances, the source of the electromagnetic phenomena is sinusoidal or time harmonic at a fre-
quency of f or radian frequency ω = 2π f. If the medium is linear, then all field quantities vary sinusoidally, 
and we may express the behavior in terms of complex or phasor quantities using the definitions shown below:
	
A
A
A
A
A
A
=
+
=
=
(
)cos(
)
Re{
}
(
)
x,y,z
t
e
x,y,z e
j t
j
ω
φ
ω
φ


© 2011 by Taylor and Francis Group, LLC

Propagating Electromagnetic Fields 
30-3
Here, A and Ã represent vector quantities, but the relationship holds for scalar terms as well. All 
temporal derivatives in Maxwell’s equations can therefore be expressed in the phasor domain by simply 
multiplying the quantity by jω, as shown below:
	
∂
∂
⇔


A
A
t
jω
The differential form of Maxwell’s equations may then be expressed in the phasor domain, as shown 
in Equations 30.11 through 30.15:
	
∇×
= −


E
B
jω
	
(30.11)
	
∇×
=
+



H
D
J
jω
	
(30.12)
	
∇⋅
=
D
qv 	
(30.13)
	
∇⋅
=
B
0 	
(30.14)
	
∇⋅= −
J
j qv
ω
	
(30.15)
Equation 30.11 can be defined in terms of E˜ and H˜ using the relationships J˜  = σE˜ and D˜ = εE˜, and 
expressed as
	
∇×
=
+


H
E
(
)
σ
ωε
j
	
(30.16)
At a given frequency f, a material can be classified as a good conductor if the conduction current 
­density is much larger than the displacement current density (σ ≫ ωε) or a lossy dielectric if the oppo-
site is true (σ ≪ ωε).
30.1.3  Uniform Plane Waves
Maxwell demonstrated that electric and magnetic fields travel through space in the form of waves at the 
velocity of light in the medium. This is mathematically demonstrated by developing the wave equation 
for a linear medium.
By assuming that an electromagnetic field is present in a linear, charge-free medium, we can derive 
the wave equation in the phasor domain using the two curl Equations 30.11 and 30.12. We begin by 
­taking the curl of Equation 30.17 and use the identity B˜ = μH˜ , as shown below:
	
∇×
= −


E
B
jω
	
(30.17)
	
∇×∇×
= −
∇×


E
B
jω
	
(30.18)
	
∇×∇×
= −
∇×


E
H
jωµ
	
(30.19)
© 2011 by Taylor and Francis Group, LLC

30-4 
Fundamentals of Industrial Electronics
By using substituting Equation 30.16 into Equation 30.19, the equation becomes
	
∇×∇×
= −
+



E
E
E
j u
ω σ
ω µε
2
	
(30.20)
A vector identify is then used to reduce the ∇ × ∇ × E˜ into two parts, as shown below:
	
∇×∇×
= ∇∇⋅
−∇



E
E
E
2
	
(30.21)
Since the region is assumed to be homogenous and charge free (qv = 0), a simplification can be made 
(∇· E˜ = 0) resulting in the final form of the wave equation in the phasor domain, as shown below:
	
∇
+
−
=
2
2
0


E
E
(
)
ω µε
ω σ
j u
	
(30.22)
An identical equation can be developed for the H˜  field using the same mathematical operations. This 
is achieved by taking the curl of Equation 30.16 ∇ × ∇ × H˜ = (σ + jωε) ∇ × E˜ and substituting (30.11) 
resulting in
	
∇
+
−
=
2
2
0


H
H
(
)
ω µε
ω σ
j u
	
(30.23)
These equations are more commonly expressed in a more compact form known as the Helmholtz 
equations (Equations 30.24 and 30.25), as shown below:
	
∇
−
=
2
2
0


E
E
γ
	
(30.24)
	
∇
−
=
2
2
0


H
H
γ
	
(30.25)
where γ is the propagation constant, defined as
	
γ
ωµ σ
ωε
=
+
.
j
j
(
)
The real part of γ is referred to as the attenuation constant α and the imaginary part the phase 
­constant β:
	
γ
ωµ σ
ωε
α
β
=
+
=
+
j
j
j
(
)
	
(30.26)
If we assume that propagation is limited to waves traveling in the az direction having only an 
ax-oriented electric field (Ex) and an ay-oriented magnetic field Hy, Equations 30.24 and 30.25 become
	
∂
∂
−
=
2
2
2
0
E
z
E
x
x
γ
	
(30.27)
	
∂
∂
−
=
2
2
2
0
H
z
H
y
y
γ
	
(30.28)
© 2011 by Taylor and Francis Group, LLC

Propagating Electromagnetic Fields 
30-5
Solutions to Equations 30.27 and 30.28 are given in (30.29) and (30.30):
	
E
E e
E e
x
z
z
=
+
+
−
−
(
)
0
0
γ
γ
ax 	
(30.29)
	
H
H e
H e
y
z
z
=
+
+
−
−
(
)
0
0
γ
γ
ay 	
(30.30)
The first terms of each equation describe a plane wave propagating in the az direction having 
­magnitudes of E
H
0
0
+
+
,
, respectively, with the second term depicting a plane wave propagating in the az 
direction having magnitudes of E
H
0
0
−
−
,
, respectively.
The above equations can be expressed in the time domain using the relationship given in Equations 
30.11 and 30.26 and is shown below:
	
E z,t
E e
t
z
E e
t
z
H z,t
z
E
z
E
(
)
(
cos(
)
cos(
))
(
=
−
+
+
+
+
+
−
−
+
−
0
0
a
a
x
a
ω
β
θ
ω
β
θ
)
(
cos(
)
cos(
))
=
−
+
+
+
+
+ −
−
+
−
H e
t
z
H e
t
z
y
z
H
y
z
H
a
a
y
a
ω
β
θ
ω
β
θ
where θE and θH are the angles associated with the  E˜ x and E˜ y , respectively.
Both electric and associated magnetic fields propagate with a phase velocity vp that is given as
	
vp = ω
β 	
(30.31)
The characteristic impedance of the region (η) is defined as the ratio of the electric field to the mag-
netic field, as shown below:
	
η =


E
H 	
(30.32)
For a wave traveling in the positive az direction, the simplest method to determine η is by taking the 
curl of the electric field and using Equation 30.17 and the identify B˜ = μH˜ . This results in an expression 
for η that is dependent on only the constitutive parameters of the media (30.35):
	
∇×
= −
= −
+
−


E
H
j
E e
x
z
ωµ
γ
γ ay 	
(30.33)
	
or


H
E
= ∇×
= −
+ −
j
j E e
x
z
ωµ
γ
ωµ
γ
	
(30.34)
	
η
ωµ
γ
ωµ
σ
ωε
=
=
+
j
j
j
	
(30.35)
Using the same mathematical procedure, the impedance of waves traveling in the −az direction is 
given as
	
E
H
j
0
0
−
−= −
= −
ωµ
γ
η	
(30.36)
© 2011 by Taylor and Francis Group, LLC

30-6 
Fundamentals of Industrial Electronics
Two very useful relationships that relate the η and the direction of propagation aR to E˜ and H˜ are 
shown below:
	


H
a
E
=
×
1
η
R
	
(30.37)
	


E
a
H
= −
×
η
R
	
(30.38)
where aR is a unit vector in the direction of propagation. It should be noted that the above relationships 
(30.37) and (30.38) are only valid for propagating waves.
30.1.4  Propagation in a Lossless Media
In lossless (σ = 0), charge-free (∇ · E˜ = 0) media, γ is equal to the propagation constant jβ and Equations 
30.27 and 30.28 become
	
∂
∂
+
=
2
2
2
0
E
z
E
x
x
β
	
(30.39)
	
∂
∂
+
=
2
2
2
0
H
z
H
y
y
β
	
(30.40)
The solutions to these equations are
	
E
E e
E e
x
j z
j z
=
+
+
−
−
(
)
0
0
β
β
ax 	
(30.41)
	
H
H e
H e
y
j z
j z
=
+
+
−
−
(
)
0
0
β
β
ay 	
(30.42)
and the phase velocity vp and intrinsic impedance η of the media are given as
	
vp =
=
ω
β
µε
1 	
(30.43)
	
η
µ
ε
=
	
(30.44)
30.1.5  Propagation in a Low-Loss Dielectric
In the electrostatics section, we discussed how power losses are associated with both conduction and 
polarization currents. Waves propagating in a lossy medium induce conduction current J˜cond = σE˜ and 
a displacement (polarization) current J˜disp = jωD˜ = jωεE˜ . The total current density is the sum of each of 
these and sometimes referred to as the Maxwell current density:
	
total
cond
disp




J
H
J
J
= ∇×
=
+
	
(30.45)
© 2011 by Taylor and Francis Group, LLC

Propagating Electromagnetic Fields 
30-7
The quantities σ and ε may be frequency dependent. However, over a relatively small frequency band, 
we may assume the conductivity σ and permittivity ε are constant. The permittivity of the dielectrics is 
complex and given by
	
ε
ε
ε
ε
ε
σ
ω
c
r
j
j
=
−
′′ =
−
′′ +




′
	
(30.46)
Therefore, (30.45) may be expressed simply as
	
∇×
=
=



H
J
E
total
c
jωε
	
(30.47)
30.1.6  Propagation in a Good Conductor
If the conduction current is much greater than the displacement current (σ ≫ ωε), then the material 
is considered a good conductor and several simplifying assumptions can be made. Since σ ≫ ωε, the 
propagation constant (γ) becomes
	
γ
ωµσ
ωµσ
=
=
+
j
j
(
)(
)
1
2
and therefore α and β are equal and given as
	
α
ωµσ
β
ωµσ
=
=
2
2
and
	
(30.48)
The total current density is approximately equal to the conduction current density J˜total = σ E˜ . For a 
wave propagating in the +az direction, the magnitude of the E˜  and J˜cond rapidly decay and are given as
	


E
J
=
=
+
−
+
−
E
E
0
0
ε
σ
ε
a
a
z
z
The point at which the magnitude of the electric field has decreased to e−1 is commonly referred to as 
the skin depth (δ) expressed as
	
δ
π µσ
=
1
f
	
(30.49)
30.1.7  Reflection and Transmission of Plane Waves
When electromagnetic waves are normally incident on a planar region (E˜, H˜ are perpendicular to 
each other and parallel to the planar region) having different constitutive parameters (ε, μ, σ), a 
transmitted wave and a reflected wave are created. The analysis of this behavior begins by assuming 
a normally incident wave (E˜ i, H˜ i) in region (1) propagating in the at direction resulting in a transmit-
ted wave (E  t, H˜ t) in region (2) and reflected wave (E˜ r, H˜ r) wave in region (1), as shown in Figure 30.1 
and given by
© 2011 by Taylor and Francis Group, LLC

30-8 
Fundamentals of Industrial Electronics
	
i
i


E
H
=
=
−
−
E e
e
i
z
i
z
0
0
1
1
γ
γ
a
a
x
y
and
H
	
(30.50)
	
r
r
z
r
r
z
E e
e


E
H
=
=
0
0
1
1
γ
γ
a
a
x
y
and
H
	
(30.51)
	
t
t
z
t
t
z
E e
H e


E
H
=
=
−
−
0
0
2
2
γ
γ
a
a
x
y
and
	
(30.52)
The differential voltage (dV) and current drop that occurs over the length dz are given by
	
dV
dz
IR
L dI
dt
= −
−
	
(30.53)
	
dI
dz
VG
C dV
dt
= −
−
. 	
(30.54)
Equations 30.50 through 30.52 can be stated in terms of the electric field by making use of Equations 
30.35 and 30.36, as shown below:
	
i
i
z
i
i
z
E e
E e


E
H
=
=
−
−
0
0
1
1
γ
γ
η
and
	
(30.55)
	
r
r
z
r
r
z
E e
E e


E
H
=
= −
0
0
1
1
γ
γ
η
and
	
(30.56)
	
t
t
z
t
t
z
E e
E e


E
H
=
=
.
−
−
0
0
2
2
γ
γ
η
and
	
(30.57)
The total field of each region is given as
	
1
0
0
1
0
0
1
1
1
1


E
H
=
+
=
+
−
−
E e
E e
H e
H e
i
z
r
z
i
z
r
z
γ
γ
γ
γ
a
a
y
y
and
	
(30.58)
E i
E r
Region 1
ε1, μ1,σ1
Region 2
ε2, μ2,σ2
E t
FIGURE 30.1  Incident, transmitted, and reflected electric fields at a boundary.
© 2011 by Taylor and Francis Group, LLC

Propagating Electromagnetic Fields 
30-9
	
2
0
2
0
2
2


E
H
=
=
−
−
E e
H e
t
z
t
z
γ
γ
a
a
y
y
and
	
(30.59)
At the interface between medium 1 and medium 2, the tangent component of the electric and mag-
netic fields must be equal, and therefore we can relate the transmitted and reflected field at the interface 
(z = 0), as shown below:
	
1
2
0
0
0


E
E
=
;
+
=
E
E
i
r
	
(30.60)
	
1
2
0
0
0
0
0


H
H
=
;
+
=
=
−
H
H
E
E
i
r
i
r
η
η 	
(30.61)
This enables us to define the reflection (Γ) and transmission (τ) coefficients at the boundary in terms 
of the constitutive properties of each medium:
	
E
E
E
r
i
i
0
0
1
2
1
2
0
=
−
+
=
η
η
η
η
Γ
	
(30.62)
	
E
E
E
t
i
i
0
0
2
1
2
0
2
=
+
=
η
η
η
τ
	
(30.63)
	
τ
η
η
η
η
η
η
η
=
=
+
=
=
−
+
E
E
E
E
t
i
r
i
0
0
2
1
2
0
1
2
1
2
2
and
Γ
	
(30.64)
Therefore, Equation 30.59 becomes
	
1
0
1
0
1
1
1
1


E
H
=
+
=
−
−
−
E e
e
H e
e
i
z
z
i
z
z
(
)
(
)
γ
γ
γ
γ
Γ
Γ
and
	
(30.65)
	
2
0
2
0
2
2


E
H
=
=
−
−
τ
τ
γ
γ
E e
H e
i
z
i
z
and
	
(30.66)
30.2  Transmission Lines
30.2.1  Overview
The term “transmission line” usually refers to two or more parallel conducting lines that allow the 
transmission of electrical power or energy between systems. Common examples of transmission lines 
include coaxial cables, high-power lines, and telephone lines. The transmission lines discussed in this 
chapter only allow a transverse electromagnetic (TEM) wave to propagate. A TEM is unique in that the 
electric and magnetic fields are perpendicular to each other and the direction of propagation. This dif-
fers from the behavior that occurs in Waveguides, which will be discussed in the subsequent chapter. 
It also allows us to use a bulk parameter (R, L, C, G per unit length) or distributed model for the elec-
tromagnetic analysis.
30.2.2  Analysis
It is generally assumed that any multiconductor line must be analyzed as a transmission line if its length 
is greater than a tenth of the wavelength (λ/10). The analysis begins by considering a per unit meter bulk 
parameter equivalent of a two conductor line shown in Figure 30.2.
© 2011 by Taylor and Francis Group, LLC

30-10 
Fundamentals of Industrial Electronics
The differential voltage (dV) and current drop that occurs over the length dz are given by
	
dV
dz
IR
L dI
dt
= −
−
	
(30.67)
	
dI
dz
VG
C dV
dt
= −
−
	
(30.68)
or in the phasor domain as
	
dV
dz
I R
j L
= −
+
(
)
ω
	
(30.69)
	
dI
dz
V G
j C
= −
+
(
).
ω
	
(30.70)
In the phasor domain, a single equation that depends only on V can be developed by taking the 
derivative of (30.69) with respect to z and substituting Equation 30.70 for dI/dz, as shown below:
	
d V
dz
dI
dz R
j L
2
2 = −
+
(
)
ω
	
(30.71)
	
d V
dz
G
j C R
j L V
2
2 =
+
+
(
)(
)
ω
ω
	
(30.72)
Equation 30.72 is usually written as
	
d V
dz
V
2
2
2
0
−
=
γ
	
(30.73)
dI
dV
V
+
+
–
–
dz
G
R
L
C
FIGURE 30.2  Bulk parameter representation of a transmission line.
© 2011 by Taylor and Francis Group, LLC

Propagating Electromagnetic Fields 
30-11
where γ
ω
ω
α
β
=
+
+
=
+
(
)(
)
G
j C R
j L
j , α being the attenuation constant and β the propagation 
­constant. An analogous equation for the current waveform on a transmission line can be developed 
by taking the derivative of (30.70) with respect to z and substituting Equation 30.69. The solutions 
for the voltage and current waveforms on a transmission line are therefore given in the phasor 
domain as
	
V
V e
V e
z
z
=
+
+
−
−
(
)
0
0
γ
γ
	
(30.74)
	
I
I e
I e
z
z
=
+
+
−
−
(
)
0
0
γ
γ
	
(30.75)
and time domain as
	
V z t
V e
t
z
V e
t
z
I z t
z
V
z
V
(
)
(
cos(
)
cos(
)
(
)
(
,
=
−
+
+
+
+
,
=
+
−
−
+
−
0
0
α
α
ω
β
θ
ω
β
θ
I e
t
z
I e
t
z
z
I
z
I
+
−
−
−
+
+
+
+
+
−
α
α
ω
β
θ
ω
β
θ
cos(
)
cos(
)
The characteristic impedance of the region Z0 can be found for a positively propagating wave by 
­taking the derivative of the voltage (V
V e
z
=
+ −
0
γ ) with respect to z and solving for (Z0 = V/I), as shown 
below:
	
dV
dz
I R
j L
V e
V
z
= −
+
= −
= −
+ −
(
)
ω
γ
γ
γ
0
	
(30.76)
	
Z
R
j L
R
j L
G
j C
0 =
+
=
+
+
ω
γ
ω
ω
.
	
(30.77)
For waves traveling in the −z-direction, the relationship between current and voltage is
	
V
I
Z
−
−= −
0.
	
(30.78)
30.2.3  Lossless Transmission Lines
Several of the relationships for lossy transmission lines can be simplified if the line is assumed lossless. 
They include the phase velocity vp, characteristic impedance Z0, the propagation constant γ, and the 
phasor and temporal description of the voltage and current waveform (only voltage waveform shown) 
among others.
	
Z
L
C
0 =
	
(30.79)
	
γ
β
ω
=
=
j
j
LC 	
(30.80)
© 2011 by Taylor and Francis Group, LLC

30-12 
Fundamentals of Industrial Electronics
	
v
LC
p =
=
ω
β
1
	
(30.81)
	
V
V e
V e
j z
j z
=
+
+ −
−
0
0
β
β
	
(30.82)
	
V z t
V
t
z
V
t
z
(
)
cos(
)
cos(
)
,
=
−
+
+
+
−
0
0
ω
β
ω
β
	
(30.83)
There is also a relationship between the per unit length capacitance C and inductance L, the phase 
velocity vp, and the constitutive parameters of the region:
	
LC
vp
=
=
εµ
µε
and
1
.
	
(30.84)
30.2.4  Terminated Transmission Lines
Transmission lines used to transmit electromagnetic waves are usually terminated in loads, which cause 
a reflected wave to occur. The loads are typically modeled as lumped elements at z = 0, as shown in 
Figure 30.3. The load impedance (ZL) is the ratio of the voltage to current at the load and given as
	
Z
V z
I z
V e
V e
I e
I e
V
V
I
L =
=
=
=
+
+
=
+
+
−
−
+
−
−
+
−
(
)
(
)
(
)
(
)
0
0
0
0
0
0
0
0
0
0
0
0
0
γ
γ
γ
γ
+
−
+ I0
	
(30.85)
Therefore, by rearranging the terms in Equation 30.78, ZL and V0
− can be expressed in terms of 
Z V
V
0
0
0
,
,
+
− as
	
Z
Z V
V
V
V
L =
+
−
+
−
+
−
0
0
0
0
0 	
(30.86)
	
V
Z
Z
Z
Z V
L
L
0
0
0
0
−
+
=
−
+
	
(30.87)
This allows us to define the reflection coefficient at the load (ΓL) as
	
ΓL
L
L
V
V
Z
Z
Z
Z
=
=
−
+
−
+
0
0
0
0 	
(30.88)
V0
Z0
ZL
Vs
Rs
+
+
–
z=–L
z = 0
FIGURE 30.3  Schematic representation of a transmission line.
© 2011 by Taylor and Francis Group, LLC

Propagating Electromagnetic Fields 
30-13
Γ is generally a complex number that describes both the magnitude and the phase of the reflected wave. 
Some of the simplest cases are when the transmission line is terminated into a short circuit, open circuit, 
or it’s characteristic impedance Z0, as shown below:
	
ΓL = −:
1 maximum negative value of
reflection coefficient when the line is short-circuited
no reflection on positive traveling
w
ΓL =
:
0
ave when the line is terminated into 
this is known as a matched co
Z0;
ndition
maximum positive reflection when the line is open-c
ΓL = + :
1
ircuited 	
or at any point on the line as
	
Γ
Γ
=
L
j
z
e 2γ
	
(30.89)
Equations 30.9 and 30.10 can therefore be expressed as
	
V
V
e
e
z
L
z
=
+
+
−
0 (
)
γ
γ
Γ
	
(30.90)
	
I
I
e
e
z
L
z
=
−
.
+
−
0 (
)
γ
γ
Γ
	
(30.91)
Another common quantity that describes how effectively a transmission line is delivering power to a 
load is the voltage standing wave ratio (VSWR). The VSWR is defined as the ratio of the maximum volt-
age amplitude to the minimum voltage amplitude that occurs on a transmission line. Figure 30.4 shows 
how the peak value of the sinusoidally varying voltage waveform varies versus position z. The maximum 
and minimum values of the voltage waveform are V
V
V
V
max
L
min
L
=
+ |
| ;
=
−|
|
+
+
0
0
1
1
(
)
(
)
Γ
Γ
. Therefore, the 
standing wave ratio is a strictly positive number that varies between 1 for a perfectly matched load 
to ∞ for either an open- or a short-circuit load. Equation 30.27 defines the VSWR of a transmission line 
terminated into a load ZL:
	
VSWR
V
V
L
L
=
= + |
|
−|
|
max
min
1
1
Γ
Γ
	
(30.92)
Vave
Vmin
Vmax
z
|V|
FIGURE 30.4  VSWR on a transmission line.
© 2011 by Taylor and Francis Group, LLC

30-14 
Fundamentals of Industrial Electronics
The input impedance (Zin) at any distance from the load (−l) can be found using Equations 30.25 and 
30.26, as shown below:
	
Z
l
V e
V e
I e
I e
Z Z
Z
l
in
L
L
L
L
L
(
)
(
)
(
)
tanh( )
−
=
+
+
=
+
+ +
−−
+ +
−−
0
0
0
0
0
0
γ
γ
γ
γ
γ
Z
Z
l
L
0 +
tanh( )
γ
	
(30.93)
or for a lossless transmission line the equation becomes
	
Z
l
Z Z
jZ
l
Z
jZ
l
in
L
L
(
)
tan( )
tan( ) .
−
=
+
+
0
0
0
β
β
	
(30.94)
30.2.5  Smith Chart
Prior to the advent of high-speed digital computers, the most common technique employed to ana-
lyze transmission line behavior required a graphical solution using a Smith chart (shown in Figure 
30.5). The Smith chart was created by Phillip H. Smith as a tool for electrical and electronic engi-
neers to assist them in solving problems with transmission lines and matching networks. Use of 
the Smith chart is still very popular today for both problem solving and as a graphical aid demon-
strating how the behavior of an electrical system changes as a function of frequency. Even though 
a Smith chart can be used for the analysis of a lossy transmission line, only the lossless case will be 
discussed here.
The Smith chart is a polar plot of the complex reflection coefficient (Γ) and the normalized line 
impedance (Zin) at all points on the transmission line. A derivation of the Smith chart begins by 
defining the normalized load impedance zL and calculating the complex reflection coefficient ΓL, as 
shown below:
	
z
Z
Z
L
L
=
0 	
(30.95)
	
ΓL
L
L
z
z
=
−
+
1
1 	
(30.96)
The reflection coefficient any distance from the load z is given in Equation 30.24, and for a lossless 
line it becomes
	
Γ
Γ
z
in
in
L
j
z
z
z
e
=
−
+
=
1
1
2β
	
(30.97)
and may be expressed in terms of rectangular components as
	
Γ
Γ
Γ
( )
z
j
Re
Im
=
+
	
(30.98)
The normalized input impedance (zin) can be solved for in terms of Γ(z), as shown below:
	
z
r
jx
j
j
in
Re
Im
Re
Im
=
+
=
+
+
−
−
1
1
Γ
Γ
Γ
Γ
	
(30.99)
By multiplying the last term in (30.34) through by the complex conjugate (1−ΓRe+jΓIm) and rearrang-
ing the terms (30.34), r and jx are given as
	
r
Re
Im
Re
Im
=
−
−
−
+
1
1
2
2
2
2
Γ
Γ
Γ
Γ
(
)
	
(30.100)
© 2011 by Taylor and Francis Group, LLC

Propagating Electromagnetic Fields 
30-15
	
jx
j
Im
Re
Im
=
−
+
2
1
2
2
Γ
Γ
Γ
(
)
	
(30.101)
Equations 30.35 and 30.36 can easily be formulated as circular functions, which, when plotted, consti-
tute the Smith chart:
	
Γ
Γ
Re
Im
r
r
r
−
+



+
=
+




1
1
1
2
2
2
	
(30.102)
Smith chart 
0.1
0.1
0.1
0.2
0.2
0.2
0.3
0.3
0.3
0.4
0.4
0.4
0.5
0.5
0.5
0.6
0.6
0.6
0.7
0.7
0.7
0.8
0.8
0.8
0.9
0.9
0.9
1.0
1.0
1.0
1.2
1.2
1.2
1.4
1.4
1.4
1.6
1.6
1.6
1.8
1.8
1.8
2.0
2.0
2.0
3.0
3.0
3.0
4.0
4.0
4.0
5.0
5.0
5.0
10
10
10
20
20
20
50
50
50
0.2
0.2
0.2
0.2
0.4
0.4
0.4
0.4
0.6
0.6
0.6
0.6
0.8
0.8
0.8
0.8
1.0
1.0
1.0
1.0
20
–20
30
–30
40
–40
50
–50
60
–60
70
–70
80
–80
90
–90
100
–100
110
–110
120
–120
130
–130
140
–140
150
–150
160
–160
170
–170
±180
90
–90
85
–85
80
–80
75
–75
70
–70
65
–65
60
–60
55
–55
50
–50
45
–45
40
–40
35
–35
30
–30
25
–25
20
–20
15
–15
10
0.04
0.04
0.05
0.05
0.06
0.06
0.07
0.07
0.08
0.08
0.09
0.09
0.1
0.1
0.11
0.11
0.12
0.12
0.13
0.13
0.14
0.14
0.15
0.15
0.16
0.16
0.17
0.17
0.18
0.18
0.19
0.19
0.2
0.2
0.21
0.21
0.22
0.22
0.23
0.23
0.24
0.24
0.25
0.25
0.26
0.26
0.27
0.27
0.28
0.28
0.29
0.29
0.3
0.3
0.31
0.31
0.32
0.32
0.33
0.33
0.34
0.34
0.35
0.35
0.36
0.36
0.37
0.37
0.38
0.38
0.39
0.39
0.4
0.4
0.41
0.41
0.42
0.42
0.43
0.43
0.44
0.44
0.45
0.45
0.46
0.46
0.47
0.47
0.48
0.48
0.49
0.49
0.0
0.0
—>
Resistance component (R/ZO), or conductance component (G/YO)
Radially scaled parameters 
Toward load —>
<— Toward generator 
1.1
1.2
1.4
1.6
1.8
2
2.5
3
4
5
10
20
6
9
8
7
5
4
3
2
1
0
∞10040
SWR
1
1
2
3
4
5
6
8
10
15
20
30
dBS
1
∞40
1
2
3
4
5
7
10
15
ATTEN. [dB]
1.1
1.2
1.3 1.4
1.6 1.8 2
3 4
5
10 20
10
S.W. LOSS COEFF
1
∞
10
12
14
20
30
RTN. LOSS [dB]
∞
0.01
0.05
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
RFL. COEFF, P
0
0.1
0.2
0.4
0.6 0.8 1
1.5
2
3
3
4
4
5
5
6
15∞
RFL. LOSS[dB]
0
1.1
1.2
1.3
1.4
1.5 1.6 1.7 1.81.9 2
2.5
10
S.W. PEAK (CONST. P)
0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1
0
RFL. COEFF, E or I
0.99
0.95
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2 0.1
0
TRANSM. COEFF, P
1
Center
1
1.1
1.2
1.3
1.4
1.5
1.6
1.7
1.8
1.9
2
TRANSM. COEFF, E or I
0.0
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
Origin
<— WA
VELEN
GTHS 
TOW
ARD
 LO
AD
 <
—
IND
UCT
IVE 
REA
CTA
NCE 
COM
PON
ENT
(+JX
/Zo)
, OR
 CA
PAC
ITIV
E SU
SCEP
TAN
CE (+
JB/Yo
) 
  CA
PACI
TIVE
 REA
CTA
NCE 
COM
PON
ENT
 (–jX
/Zo)
, OR
 IND
UCT
IVE 
SUS
CEPT
ANC
E (–jB
/Yo) 
ANGL
E OF T
RANS
MISSIO
N CO
EFFIC
IEN
T IN
 DE
GRE
ES
ANGL
E OF R
EFLEC
TION 
COEF
FICIE
NT I
N DE
GRE
ES
–10
∞
—> WAVE
LENGTH
S TOW
ARD 
GEN
ERA
TO
R
FIGURE 30.5  The Smith chart.
© 2011 by Taylor and Francis Group, LLC

30-16 
Fundamentals of Industrial Electronics
	
(
)
Γ
Γ
Re
Im
x
x
−
+
−



= 



1
1
1
2
2
2
	
(30.103)
The real part of the normalized load impedance r forms complete circles and the imaginary part jx 
circular arcs.
Figure 30.6 shows a simple example of the normalized load impedance of zL = 0.8 + j1.2 plotted 
on the Smith chart with the reflection coefficient shown. Moving away from the load toward the 
Toward load—>
<—Toward generator
∞100
∞40
40 20
20
30
10
10
5
5
5
5
5
5
15
4
4
4
4
4
4
3
8
7
9
10
12
14
20
30∞
∞
∞
∞
8
6
6
10
20
10
10
15
6
3
3
3
3
3
2.5
2
2
2
2
2
2
2
2.5
1.8
1.6
1.4
1.2 1.1 1
15
10
7
5
4
3
2
1
1
1
1
1
1
1
1
1
0.9
0.9
0.9
0.8
0.8
0.8
0.7
0.99
1.1
1.1
1.1
1.2
1.2
1.2
1.3
1.3
1.3
1.4
1.4
1.4
1.5
1.5
1.5
1.6
1.6
1.6
1.7
1.7
1.8
1.8
1.8
1.9
1.9
0.95
0.9
0.8
0.7
0.7
0.7
0.8
0.6
0.6
0.6
0.6
0.6
0.5
0.5
0.5
0.5
0.4
0.4
0.4
0.4
0.4
0.3
0.3
0.3
0.3
0.2
0.2
0.2
0.2
0.2
0.1
0.1
0.1
0.1
0.1
0.05
0.01
0
0
0
0
0
0
0.0
1
SWR
dBS
S.W. LOSS COEFF
RFL. LOSS [dB]
ATTEN.[dB]
RTN. LOSS[dB]
RFL. COEFF, P
S.W. PEAK (CONST. P)
RFL. COEFF, E or I
TRANSM. COEFF, P
CENTER
TRANSM. COEFF, E or I
ORIGIN
Smith chart
ZL= 0.8 +j1.2
Radially scaled parameters
0.32
50
40
30
20
0.31
0.3
0.29
0.28
0.27
0.26
0.25
0.24
0.23
0.22
–20
–30
–40
–50
–60
–70
–80
–90
–100
–110
–120
–130
–140
–150
–160
–170
170
150
140
130
120
110
100
90
80
70
90
80
75
70
65
60
55
50
45
40
35
–+180
–10
–15
–20
–25
–30
–35
–40
–45
–50
–55
–60
–65
–70
–75
–80
–85
–90
5.0
4.0
3.0
2.0
1.8
1.6
1.4
1.2
1.0
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1.0
1.2
1.4
1.6
1.8
2.0
3.0
4.0
5.0
0.21
0.2
0.19
0.18
0.17
0.16
0.15
0.14
0.13
0.12
0.11
0.1
0.09
0.08
0.07
0.06
0.05
0.04
0.18
0.19
0.2
0.21
0.22
0.23
0.24
0.25
0.26
0.27
0.28
0.29
0.3
0.31
0.32
0.33
0.34
0.35
0.36
0.37
0.38
0.39
0.4
0.41
0.42
0.43
0.44
0.45
0.46
0.47
0.48
0.48
0.45
0.44
0.43
0.42
0.41
0.4
0.39
0.38
0.37
0.36
0.35
0.34
0.33
0.05
0.07
0.08
0.09
0.1
0.11
0.12
0.13
0.14
0.15
0.16
0.17
60
30
25
20
15
10
0.49
0.49
0.0
0.0
<—W
avele
ngths 
towar
d load
<—
—>W
avelen
gths to
ward 
ANG
LE OF
 REFL
ECTI
ON C
OEFF
ICIE
NT I
N DE
GRE
ES
ANG
LE OF
 TRA
NSMI
SSIO
N CO
EFFI
CIEN
T IN
 DE
GRE
ES
10
5.0
20
50
50
20
10
Resistance component (R/Zo), or conductance component (G/Yo) 
0.2
0.4
0.6
0.8
1.0
1.0
0.8
0.6
0.4
0.2
0.1
0.2
0.3
0.4
0.5
0.6
0.8
0.9
1.0
1.2
1.4
1.6
1.8
2.0
3.0
4.0
5.0
10
20
50
0.7
0.2
0.4
0.6
0.8
1.0
1.0
0.8
0.6
0.4
0.2
Δ
r (real part)
jx (imaginary part)
yL
yin
zin
zin
ΓL
zL
CAPA
CITIV
E REA
CTAN
CE C
OMP
ONEN
T (–J
X/Zo)
, OR 
INDU
CTIV
E SUS
CEPT
ANCE
 (–JB/
Yo)
Induc
tive re
actan
ce co
mpon
ent (+
JX/Zo
), or c
apacit
ive su
scept
ance (
+JB/Y
o)
FIGURE 30.6  Plot of ZL and ΓL.
© 2011 by Taylor and Francis Group, LLC

Propagating Electromagnetic Fields 
30-17
generator, a distance of 0.058 wavelengths (λ) is equivalent to moving in the clockwise direction 
around a circular arc centered at the origin, as indicated on Figure 30.6. Note the information 
on the rim of the Smith chart. The magnitude of the reflection coefficient stays constant but the 
phase changes Δϕ = 2βz. Since the original position corresponded to a reading on the outer rim of 
the Smith chart of 0.16λ, we need to add 0.058λ to get the final point located at d = 0.218λ. The 
input impedance at that point is indicated zin. It is also important to note that the normalized 
admittance (y) that corresponds to each point in the normalized impedance domain is located at a 
­conjugate point 180° away.
There are several features of a Smith chart that are important to note:
	
1.	 Moving in the clockwise direction around the Smith chart corresponds to moving away from the 
load or toward the generator.
	
2.	 Likewise, moving in the counterclockwise direction around the Smith chart corresponds to 
­moving away from the generator or moving toward the load.
	
3.	 Moving one full circle around the Smith chart corresponds to moving a half-wavelength (λ/2), or 
180°, in either direction.
30.2.6  Impedance Matching
The goal of impedance matching is to couple all of the transmitted power to the load. There exist a num-
ber different methods used to create impedance-matching networks. One of the most common is stub 
matching. Stub matching requires a short segment of the transmission line be cut to a predetermined 
length (ds) and placed in parallel with the transmission line a given distance from the load (dL). The stub 
may be terminated in either a short or open circuit, as shown in Figure 30.7.
The length of the stub and distance from the load are determined by first plotting the normal-
ized load admittance on the Smith chart. Next, move around the arc of constant |Γ| toward the 
generator until you reach the r = 1 ± s circle. Since there are two points where the circles intersect, 
you are free to choose which distance form the load you prefer. Once this point is determined, the 
value of the normalized stub admittance will be equal to ystub = −s and connected in parallel to the 
transmission line.
This is best understood by a simple example. Assume you have load 0. The normalized load imped-
ance is zL = 0.4 + j1 and normalized load admittance yL = 0.345 − j1.842, as shown in Figure 30.8. By 
working in the admittance domain, we move away from the load until we reach the point yL = 1 + 
j1.867s and add a shunt stub having a value ysub = −j1.867, making the total normalized admittance and 
­normalized impedance equal to 1. This effectively sets the reflection coefficient (Γ = 0) to the left of the 
stub equal to 0.
ds
Zin
Zo
Zo
Zin=Zo
dL
YL
FIGURE 30.7  Impedance matching using a short-circuit stub.
© 2011 by Taylor and Francis Group, LLC

30-18 
Fundamentals of Industrial Electronics
30.3  Waveguides
A waveguide refers to any structure that directs electromagnetic energy down a specific path. In most 
cases, the cross-sectional area of a waveguide is invariant with the direction of propagation. However, 
there are exceptions to this generalization including the natural waveguide formed by the earth–­
ionosphere boundary. Transmission lines are a specific type of waveguide that allow a TEM wave to 
propagate and can therefore be treated in terms of bulk or distributed parameters (i.e., R, L, C, G). 
However, the waveguides discussed in this chapter operate in the transverse magnetic (TM) or trans-
verse electric (TE) mode and act as high-pass filters.
0.09
0.1
0.11
0.39
0.38
0.37
0.36
0.35
0.34
0.33
0.32
0.31
0.3
0.12
0.13
0.14
0.15
0.16
0.17
0.18
0.19
0.2
0.21
0.29
0.28
0.27
0.26
0.25
0.24
0.23
0.22
0.21
0.2
0.19
0.18
0.17
0.22
0.23
0.24
0.25
0.26
0.28
0.29
0.3
0.31
0.32
0.33
0.34
0.35
0.36
0.37
0.38
0.39
0.4
0.41
0.42
0.43
0.09
0.08
0.07
0.44
0.45
0.46
0.47
0.48
0.49
0.0
0.0
0.49
0.48
0.47
0.46
0.04
0.05
0.06
0.07
0.08
0.45
0.44
0.43
0.42
0.41
0.4
0.06
0.05
0.04
0.1
0.16
0.15
0.14
–80
–70
–60
–50
–40
–30
–20
–90
–100
–110
–120
–130
–140
–150
–160
–170
170
160
150
140
130
120
110
100
90
80
70
60
50
40
30
20
90
80
75
70
65
60
55
50
45
40
35
30
25
20
15
10
85
–+180
–40
–35
–30
–25
–20
–15
–10
–45
–50
–55
–60
–65
–70
–75
–80
–85
–90
0.13
0.12
0.11
0.27
ANG
LE OF
 TRA
NSMI
SSION
 COE
FFICI
ENT I
N DE
GREE
S
ANG
LE OF
 REFL
ECTIO
N CO
EFFIC
IENT
 IN D
EGRE
ES
—>W
AVEL
ENGT
H TO
WARD
 GEN
ERAT
OR—
>
—>W
AVEL
ENGT
H TO
WARD
 LOA
D—>
Induc
tive r
eacta
nce c
ompo
nent 
(+jX/
Zo), 
or ca
pacit
ive s
usce
ptan
ce (+
jB/Y
o)
Capac
itive r
eacta
nce c
ompo
nent 
(–jX/
Zo), 
or in
ducti
ve su
scep
tanc
e (–j
B/Yo
)
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1.0
1.2
1.4
1.6
1.8
2.0
3.0
4.0
5.0
10
20
50
0.2
0.2
0.2
0.2
0.4
0.4
0.4
0.4
0.6
0.6
0.6
0.8
0.8
0.6
0.8
0.8
1.0
1.0
1.0
1.0
4.0
3.0
5.0
10
10
20
50
50
20
10
5.0
4.0
3.0
2.0
1.8
1.6
1.4
1.2
1.0
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0.1
0.2
0.3
0.4
0.5
0.6
0.7
0.8
0.9
1.0
1.2
1.4
1.6
1.8
2.0
Smith chart YI=0.345–j0.862 
Distance from load to r =1 circle=[(0.186–0.382) + 0.5]λ = 0.304λ
Short circuit stub length=0.078λ
0.186λ
0.382λ
dstub= 0.078λ
yd= 1 +j1.867
ystub= –j1.867
yd
yL
∞100
∞40
40 20
20
30
10
10
5
5
5
5
5
15
4
4
4
4
4
3
8
7
9 10
12
14
20
30∞
∞
∞
∞
8
6
6
10
10
15
6
3
3
3
3
2.5
2
2
2
2
2
2
2.5
1.8 1.6
1.4
1.2 1.1 1
1
1 1
1
1.5
1
1
1
1
0.9
0.9
0.9
0.8
0.8
0.8
0.7
0.99
1.1
1.1
1.2
1.2
1.3
1.3
1.4
1.4
1.5
1.5
1.6
1.6
1.7
1.7
1.8
1.8
1.9
1.9
0.95
0.9
0.8
0.7
0.7
0.7
0.8
0.6
0.6
0.6
0.6
0.6
0.5
0.5
0.5
0.5
0.4
0.4
0.4
0.4
0.4
0.3
0.3
0.3
0.3
0.2
0.2
0.2
0.2
0.2
0.1
0.1
0.1
0.1
0.1
0.05
0.01
0
0
0
0
0
0
0.0
1
S dBS
S.W. LOSS COEFF
RTN.  [dB]
RFL. COEFF, P
S.W. PEAK (CONST. P)
RFL. COEFF, E or I
TRANSM. COEFF, P
CENTER
TRANSM. COEFF, E or I
ORIGIN
Resistance component (R/Zo), or conductance component (G/Yo) 
radially scaled paramet
FIGURE 30.8  Impedance matching yL = 0.345−j8862 using a short-circuit stub.
© 2011 by Taylor and Francis Group, LLC

Propagating Electromagnetic Fields 
30-19
Some of the most common types of waveguides include the hollow conducting cylinders, dielectric 
waveguides, and optical fibers. The analysis of waveguides begins by formulating the problem in terms 
of Maxwell’s equations and applying the appropriate boundary conditions.
30.3.1  Hollow Conducting Cylinders
The analysis described in this section may be applied to any hollow conducting cylinder; however, we 
will only consider waveguides having a rectangular cross section. Figure 30.9 shows a typical rectan-
gular waveguide section. To begin the analysis, consider the cross-sectional diagram of a waveguide, as 
shown in Figure 30.10. The waveguide is filled with a dielectric material having constitutive parameters 
(ε, μ). The electric and magnetic fields may therefore be expressed in terms of E˜ = E0(x, y)e−γz, and 
H˜ = H0(x, y)e−γz where γ is the propagation coefficient in the z direction. By applying Maxwell’s equa-
tions to the expressions for E˜ and H˜ , we obtain
	
E
E
x
j
H
y
x
z
z
= −
∂
∂
+
∂
∂






1
2
ζ
γ
ωµ
	
(30.104)
	
E
E
y
j
H
x
y
z
z
= −
∂
∂
−
∂
∂






1
2
ζ
γ
ωµ
	
(30.105)
	
H
j
E
y
H
x
x
z
z
= −
−
∂
∂
+
∂
∂






1
2
ζ
ωε
γ
	
(30.106)
	
H
j
E
x
H
y
y
z
z
= −
∂
∂
+
∂
∂






1
2
ζ
ωε
γ
	
(30.107)
where ζ2 = γ2 + β2 and β2 = ω2με.
The propagation coefficient γ and six of the field components are 
not known. They may be determined by solutions to the differential 
FIGURE 30.9  Rectangular waveguide section with flanges.
a
Z
Y
b
X
FIGURE 30.10  Diagram of rect-
angular waveguide.
© 2011 by Taylor and Francis Group, LLC

30-20 
Fundamentals of Industrial Electronics
equations given in (30.104) through (30.107) and applying the appropriate electromagnetic boundary 
conditions. In general, the propagation constant is given by γ
ωµ σ
εω
=
+
j
j
(
), but for the remainder of 
this section, we will assume the waveguide is lossless and γ = jβ.
30.3.2  Transverse Electric TEm,n Waves
TEm,n waves or modes have no electric field and only a magnetic field in the direction of propagation 
(Hz). To solve for the field components, we use the boundary condition ∂Htan/∂n = 0 on all conducting 
surfaces and construct solutions based on (30.25) for Hz as shown below:
	
∇
+
=
2
2
0


H
H
ω µε
	
(30.108)
	
∂
∂
+ ∂
∂
+ ∂
∂
+
=
2
2
2
2
2
2
2
0
H
x
H
y
H
z
H
z
z
z
z
ω µε
	
(30.109)
The solution to Equation 30.109 is found using the separation of variables shown below:
	
H
X x Y y Z z
X YZ
XY Z
XYZ
XYZ
X
X
Y
Y
Z
z =
+
+
′′ +
=
′′
+
′′ +
′′
′′
( ) ( ) ( )
 
 
 
 
 
ω µε
2
0
′′
+
=
−
−
−
+
=
 
Z
k
k
k
x
y
z
ω µε
ω µε
2
2
2
2
2
0
0
where
X
X
kx
′′
= −
 /
2
Y
Y
ky
′′
= −
 /
2
Z
Z
kz
′′
= −
 /
2
Each of the differential equations has a solution of the same for form: X x
k x
k x e
x
x
jk x
x
( )
sin(
) cos(
)
;
∼
;
±
 
Y y
k y
k y
e
y
y
jk y
y
( )
sin(
)cos(
)
∼
;
±
; Z(z)∼sin(kzz), cos(
)
k z e
z
jk z
z
±
. The exact solution is dependant on the 
dimensions of the guide, as shown below:
	
X x
m x
a
Y y
n y
b
( )
cos
( )
cos
=



;
=




π
π
	
(30.110)
	
H
H
m x
a
n y
b
e
z
jk z
z
=








±
0 cos
cos
π
π
	
(30.111)
The propagation constant kz is given as
	
k
m
a
n
b
z
2
2
2
2
=
−


−



ω µε
π
π
	
(30.112)
	
k
m
a
n
b
z = ±
−


−



ω µε
π
π
2
2
2
	
(30.113)
© 2011 by Taylor and Francis Group, LLC

Propagating Electromagnetic Fields 
30-21
The radian frequency at which the argument 
ω µε
π
π
2
2
2
−(
) −(
)
m
a
n
b
/
/
 becomes negative is known as 
the cutoff frequency (ωc or fc). Waves having a frequency lower than cutoff frequency will not propagate. 
The cutoff frequency in radians per second and hertz are given below:
	
ω
µε
π
π
c
m
a
n
b
=



+ 



1
2
2
	
(30.114)
	
f
m
a
n
b
c =



+ 



1
2
2
2
µε
	
(30.115)
and m, n are known as the mode numbers. It is important to note that for a TEm,n wave, the lowest order 
mode is the TE1,0 mode corresponding to a cutoff frequency of fc
a
1 0
1 2
, = /
µε .
This also allows us to reduce all relative equations to a more simplified form in terms of the cutoff 
frequency for the respective mode.
The remainder of the field components can be found by solving Maxwell’s equations with the given 
value of Hz and are shown below:
TE case
	
E
j un
b
H
m x
a
n y
b
e
x
jk z
z
=








−
ω
π
ζ
π
π
2
0 cos
sin
	
(30.116)
	
E
j um
a
H
m x
a
n y
b
e
y
jk z
z
= −








−
ω
π
ζ
π
π
2
0 sin
cos
	
(30.117)
	
H
m
a H
m x
a
n y
b
e
x
jk z
z
=








−
γ π
ζ
π
π
2
0 sin
cos
	
(30.118)
	
H
n
b H
m x
a
n y
b
e
y
jk z
z
=








−
γ π
ζ
π
π
2
0 cos
sin
	
(30.119)
where ζ
ω µε
2
2
2
=
−kz .
The wave impedance for TE modes is given as
	
ZTE = −
=
=
−(
)
(
)
E
H
E
H
fc f
y
x
x
y
µ
ε
1
2
/
	
(30.120)
30.3.3  Transverse Electric TMm,n Waves
TMm,n waves or modes have no magnetic field and only an electric field in the direction of propagation 
(Ez). The solution for these modes follows in the same manner as the TE case. We begin by starting with 
the Helmholtz equation for the electric field and then apply the appropriate boundary conditions:
	
∇
+
=
2
2
0


E
E
ω µε
	
(30.121)
© 2011 by Taylor and Francis Group, LLC

30-22 
Fundamentals of Industrial Electronics
	
∂
∂
+ ∂
∂
+ ∂
∂
+
=
2
2
2
2
2
2
2
0
E
x
E
y
E
z
E
z
z
z
z
ω εµ
	
(30.122)
The solution to Equation 30.109 is found using the separation of variables shown below:
	
E
X x Y y Z z
X YZ
XY Z
XYZ
XYZ
X
X
Y
Y
Z
Z
z =
′′
+
′′ +
′′ +
=
′′ +
′′ +
′′ +
( ) ( ) ( )
ω µε
ω
2
0
2
2
2
2
2
0
0
µε
ω µε
=
−
−
−
+
=
k
k
k
x
y
z
	
(30.123)
where
′′
= −
X
X
kx
/
2
′′
= −
Y
Y
ky
/
2
′′
= −
Z
Z
kz
/
2
Each of the differential equations has the same form of the solution as the TE mode: 
X x
k x
k x e
Y y
k y
k y e
x
x
jk x
y
y
jk y
x
y
( )
sin(
) cos(
)
;
( )
sin(
)cos(
)
;
∼
∼
;
;
±
±
Z z
k z
k z e
z
z
jk z
z
( )
sin(
) cos(
)
∼
,
±
. The exact 
solution is found by enforcing the boundary conditions Etan = 0 at all conducting surfaces. The final 
form of the solution is shown below:
	
E
E
m x
a
n y
b
e
z
jk z
z
=








±
0 sin
sin
π
π
	
(30.124)
The remainder of the equations are found by solving Maxwell’s equations using the EZ and are given as
TM case:
	
E
jk
h
m
a
E
m x
a
n y
b
e
x
z
jk z
z
= −












−
2
0
π
π
π
cos
sin
	
(30.125)
	
E
jk
h
n
b
E
m x
a
n y
b
e
y
z
jk z
z
= −












−
2
0
π
π
π
sin
cos
	
(30.126)
	
H
j
h
n
b
E
m x
a
n y
b
e
x
jk z
z
=












−
ωε
π
π
π
2
0 sin
cos
	
(30.127)
	
H
j
h
m
b
E
m x
a
n y
b
e
y
jk z
z
= −












−
ωε
π
π
π
2
0 cos
sin
	
(30.128)
where
	
h
m
a
n
b
2
2
2
= 


+ 



π
π
	
(30.129)
and
	
k
f
f
z
c
=
−





ωµε
2
1
	
(30.130)
© 2011 by Taylor and Francis Group, LLC

Propagating Electromagnetic Fields 
30-23
The wave impedance for TM modes is given as
	
ZTM = −
=
=
−( )




E
H
E
H
y
x
x
y
fc
f
µ
ε
1
2
	
(30.131)
For both TE and TM modes, the phase velocity along the guide may approach infinity, while the 
velocity of energy propagation is always less than the speed of light in the medium. Both of these quanti-
ties along with the wavelength along the guide are given below:
	
vp
fc
f
=
−( )
(
)
1
1
2
µε
	
(30.132)
	
v
fc
f
e =
−











1
1
2
µε
	
(30.133)
	
λ
λ
µε
λ
µε
guide
u
fc
f
=
−( )




=
1
1
2 ,
.
where
f
u
	
(30.134)
30.3.4  Dielectric Waveguides
Hollow metallic waveguides are useful as waveguides over a frequency range of ∼1–40 GHz. Beyond 
these frequencies, the dimensions of the guide become prohibitively small and cannot be easily fabri-
cated. Dielectric slab waveguides overcome this problem but do have evanescent fields existing outside 
the guide. Typical applications for these structures include planar light guides used in optical integrated 
circuits.
The investigation of wave propagation in dielectric materials is based on a solution of Maxwell’s equa-
tions with the appropriate boundary conditions applied. A difficulty arises in the analysis due to the 
existence of evanescent or non-propagating fields outside the dielectric material. However, the behavior 
may be understood in an uncomplicated manner by first considering an obliquely incident wave striking 
a dielectric interface and applying Snell’s law. In Figure 30.11, a wave is shown incident from medium 
1 toward region 2. The incident wave results in a transmitted and reflected wave. The incident (θi), 
reflected (θr), and transmitted (θt) angles are related by Snell’s law of refraction 30.137, as shown below:
	
θ
θ
i
r
=
	
(30.135)
	
µ ε
θ
µ ε
θ
1 1
2
2
sin( )
sin(
)
i
t
=
	
(30.136)
Considering only nonmagnetic materials where the incident wave is in a dielectric having εr1 > εr2, 
then transmitted wave is at a larger angle than the incident wave (θt > θi). Furthermore, there is an inci-
dent angle at which the entire wave is reflected, the critical angle θc. The critical angle can be expressed 
in terms of the permittivities of each region as
	
θ
ε
ε
c
r
r
=






arcsin
2
2
	
(30.137)
© 2011 by Taylor and Francis Group, LLC

30-24 
Fundamentals of Industrial Electronics
A more traditional method of expressing Snell’s law is to do so in terms of the index of refraction of 
the medium n:
	
n
r
=
ε 	
(30.138)
Snell’s law then becomes
	
n
n
i
t
1
2
sin( )
sin(
)
θ
θ
=
	
(30.139)
and
	
θc =




arcsin n
n
1
2
	
(30.140)
For dielectric slab waveguide (Figure 30.12), only waves at angles greater than the critical angle will 
propagate if constructive interference is present. Additionally, you will have both TE and TM modes 
that include TE0 and TM0 modes. It can be shown that for only one mode to propagate, the following 
inequality must exist:
	
a
n
n
λ0
1
2
2
2
1
2
1
=
−






	
(30.141)
Medium 2 
ε2 μ2
Medium 1 
ε1 μ1
b
a
FIGURE 30.12  Dielectric waveguide.
Medium 2 
ε2 μ2
Medium 1 
ε1 μ1
θi
θr
θt
FIGURE 30.11  Wave obliquely incident on boundary of two different dielectric materials.
© 2011 by Taylor and Francis Group, LLC

Propagating Electromagnetic Fields 
30-25
30.3.5  Fiber Optics
Fiber optic technology is rapidly replacing copper as the backbone of the telecommunication ­industry. 
Optical fiber has enormous advantages over existing copper wire in long-distance applications due to 
its much lower attenuation and immunity to electromagnetic interference. There are three primary 
­frequency-transmission windows used by industry centered at 850, 1300, and 1550 nm wavelengths.
There are two main types of optical fibers used in telecommunications: (1) multimode optical fiber 
and (2) single-mode optical fiber. Multimode optical fiber typically has a larger core (∼50 μm) that results 
in less expensive transmitters, receivers, and connectors. The major problem associated with multimode 
fiber is the fact that it introduces intermodal dispersion, which limits the bandwidth and length of 
the link. Additionally, because of its higher dopant content, multimode fibers are more expensive and 
have higher attenuation than single-mode fibers. The core of a single-mode fiber is smaller (∼10 μm) 
but they require more expensive components and interconnection methods, but do allow much longer, 
higher-performance links.
A typical step-index fiber consists of an inner core of radius a surrounded by an outer cladding and 
jacket, as shown in Figure 30.13. The inner core and surrounding cladding create a cylindrical dielectric 
waveguide that guides incident light down the fiber at all angles less than the acceptance angle. This is 
commonly referred to as the cone of acceptance and is shown as the gray region. A common term that 
quantifies how effectively any type of optical fiber accepts light is the “numerical aperture” (NA).
The NA of a given optical fiber determines this maximum acceptance angle of light entering the fiber 
(Figure 30.14). Assuming that angle θc is the critical angle for light in the core striking the interface 
between the inner core and cladding, it can be defined by
	
sin(
)
θc
c
f
n
n
=
	
(30.142)
Acceptance
cone
Outer cladding
Inner core
nf
no
θc
nc
FIGURE 30.13  Cut-away view of a typical fiber optic cable.
θc
θt
no
nf
nc
θi
FIGURE 30.14  Cross-sectional view of fiber for determining acceptance angle.
© 2011 by Taylor and Francis Group, LLC

30-26 
Fundamentals of Industrial Electronics
and by inspection, it is obvious that sin(θc) = cos(θt). Furthermore,
	
sin (
)
cos (
)
2
2
1
θ
θ
t
t
+
= 	
(30.143)
	
sin(
)
cos (
)
θ
θ
t
t
=
−
1
2
	
(30.144)
	
sin(
)
sin (
)
θ
θ
t
c
=
−
1
2
	
(30.145)
	
sin(
)
.
θt
c
f
n
n
=
−



1
2
	
(30.146)
By applying Snell’s law to the air–fiber interface we see that
	
n
n
o
i
f
t
sin( )
sin(
)
θ
θ
=
	
(30.147)
	
n
n
n
n
o
i
f
c
f
sin( )
θ =
−





1
2
	
(30.148)
	
sin( )
θi
f
c
n
n
n
=
−
2
2
0
	
(30.149)
	
NA =
−
n
n
n
f
c
2
2
0
.
	
(30.150)
As was true in the dielectric slab waveguide, the TE0 and the TM0 mode propagate in fiber optic cable 
due to the existence of an evanescent external electric field. Each of these modes has no associated cutoff 
frequency. For step-index fiber optic cables, the free space wavelength required for only one mode to 
propagate is given by
	
λ
π
0
2
2
01
2
>
−






a
n
n
k
f
c
	
(30.151)
where k01 is the first root of the zeroth order Bessel function (k01 = 2.405). It should be noted that single 
mode propagation requires keeping (nf − nc) small for realistic core diameters.
Additionally, for multimode step-index fiber, the number of modes is given as
	
N
a
n
n
f
c
= 



−




2
2
0
2
2
2
π
λ
	
(30.152)
© 2011 by Taylor and Francis Group, LLC

Propagating Electromagnetic Fields 
30-27
30.4  Antennas
Antennas are a class of devices specifically developed to radiate or receive electromagnetic waves. They 
do so by converting alternating currents into electromagnetic waves when radiating and electromag-
netic waves into currents when receiving. Some typical applications for antennas are wireless phones, 
airport radars, all AM and FM broadcast transmissions, and radio astronomy. Antennas are used in a 
variety of environments, but we will restrict our analysis to propagation in free space
Antennas usually consist of an arrangement of conductors. Several of the more common types are 
shown in Figure 30.15. They generate a radiating electromagnetic field in response to an applied alter-
nating electric current or develop induced currents in response to an incident electromagnetic wave.
30.4.1  Differential or Hertzian Dipole
Analysis of antennas typically begins by considering the simple, electrically short dipole (l ≪ λ), 
­commonly referred to as a differential or Hertzian dipole (Figure 30.16), centered at the origin and 
oriented in the az direction. It consists of a wire of length l or dl electrically driven at the center. The radi-
ated electric and magnetic field propagates in the r-direction and is given as the following:
	
E r
j Il
r
e
j r
θ
β
θ
β
θ
π
µ
ε
( , )
sin( )
=
−
4
	
(30.153)
	
H r
j Il
r
e
j r
φ
β
θ
β
θ
π
( , )
sin( )
=
−
4
	
(30.154)
The waves propagate in phase, and the ratio of the electric to magnetic field is equal to the characteristic 
impedance of free space (η0):
	
η
µ
ε
θ
φ
=
=


E
H
	
(30.155)
It is interesting to note that the field strengths from these finite structures fall off as ∼(1/r) rather than 
∼(1/r2) as static fields or quasi-static fields would. This behavior is true for all propagating waves from 
finite antennas.
Loop
Horn
Dipole
Patch
Parabolic
FIGURE 30.15  Several typical antenna classes.
© 2011 by Taylor and Francis Group, LLC

30-28 
Fundamentals of Industrial Electronics
An additional noteworthy feature of the Hertzian dipole is that no electric or magnetic fields radi-
ate along the antenna’s axis. The relative field strengths are a maximum at θ = 90° and are azimuthally 
­symmetric. A normalized polar plot of the field strength magnitude is shown in Figure 30.17.
The Hertzian dipole is important to understand since all radiating antennas can be approximated as 
a large number of short (or differential) dipoles. This allows the total field to be calculated by summing 
or integrating the total field resulting from all differential dipoles.
r
Eθ, H
r΄
r
|r–r΄|
I(z΄)
×
FIGURE 30.16  Dipole antenna of arbitrary length.
0.2
0.4
0.8
0.6
1
30
210
60
240
90
270
120
300
150
330
180
0
En
Dipol e
FIGURE 30.17  Normalized E-field plot from short dipole antenna oriented in z-direction.
© 2011 by Taylor and Francis Group, LLC

Propagating Electromagnetic Fields 
30-29
30.4.2  Dipole of Length L
The general expression for the fields from a dipole of arbitrary length centered at the origin and oriented 
in the az direction can be found by integrating the value of the differential field over the length of the 
antenna. In order to do this, the current distribution must be known with a high degree of accuracy. For 
a center feed dipole having a given current distribution, I(Z), the differential magnetic field is given as
	
I z
I
l
z
( )
sin
|
|
′ =
−
′








0
2
β
	
(30.156)
	
dH
j I z e
r
r
L
z
j r r
φ
β
β
π
β
=
′
−′
−
′








−
−′
( )
|
|
sin
|
|
|
|
4
2
	
(30.157)
where r is the distance from the origin to the point of observation of the field and rʹ is the distance from 
the origin to the differential current element (30.16). The total magnetic field is given by
	
H
j I a
e
r
r
L
z
dz
L
L
j r r
φ
φ
β
β
π
β
=
−′
−
′




′


−
−
−′
∫
0
2
2
4
2
/
/
|
|
|
| sin
|
|


	
(30.158)
	
H
jI e
a
r
BL
BL
j r
φ
β
φ
π
θ
θ
=
(
) −
(
)
−
0
2
2
2
cos (
/ )cos( )
cos(
/ )
sin( )
	
(30.159)
30.4.3  Half-Wave Dipole
Another very common antenna is the half-wave dipole antenna. Its total length in practice is usu-
ally slightly less than λ/2 in order to eliminate the imaginary part on the driving point impedance 
(L = 0.485λ). The impedance becomes Zin ~ 73 Ω and the current distribution is approximated as 
resulting in a magnetic field:
	
H
jI e
a
r
j r
φ
β
φ
π
π
θ
θ
=
(
)
(
)
−
0
2
2
cos ( / )cos( )
sin( )

(30.160)
30.4.4  Antenna Characteristics
30.4.4.1  Power Density and Total Radiated Power
Determining the total radiated power from any antenna system requires the integration of the 
­time-average power density P over a surface enclosing the antenna. The time-average power density is 
defined as
	
P r
E
H
(
)
Re
, ,
=
×






θ φ
1
2
* 	
(30.161)
The radiated power density is commonly normalized and plotted versus (θ, ϕ):
	
P r
P r
P
n
max
(
)
(
)
, ,
=
, ,
θ φ
θ φ 	
(30.162)
© 2011 by Taylor and Francis Group, LLC

30-30 
Fundamentals of Industrial Electronics
and the total radiated power may therefore be found by integrating the power density:
	
P
P r
dS
rad
S
=
⋅
∫
( , , )
θ φ

	
(30.163)
	
P
P r
r
d d
rad
S
= ∫
( , , )
sin( )
θ φ
θ
θ φ
2

	
(30.164)
	
P
P
P r
r
d
rad
n
S
=
∫
max
( , , )
sin( )
.
θ φ
θ
θ
2

	
(30.165)
30.4.4.2  Beam Solid Angle and Directivity
A major goal of antenna design is to create antennas that transmit most of their power in a particu-
lar direction. Since antennas have identical transmitting and receiving patterns, they are preferentially 
­sensitive to radiation incident from the same direction.
To quantify the degree of beam focusing that occurs for a given antenna system, we introduce the 
concept of a pattern solid angle (Ωp). This is defined by
	
Ωp
n
S
P r
d d
= ∫∫
( , , )sin( )
θ φ
θ
θ φ

	
(30.166)
The directivity of an antenna is defined as the ratio of the maximum value of the power radiated in a 
given direction to the average power radiated by the antenna per steradian:
	
D
P
r
P
max
ave
=
, ,
(
)
θ φ 	
(30.167)
	
D
p
= 4π
Ω
	
(30.168)
	
where P
P
ave
rad
= 4π
The radiation resistance of an antenna can be determined using the total power radiated according 
to Equation 30.18:
	
1
2
0
2I R
P
rad
rad
=
	
(30.169)
	
R
P
I
rad
rad
= 2
0
2
	
(30.170)
© 2011 by Taylor and Francis Group, LLC

Propagating Electromagnetic Fields 
30-31
30.5  Summary
This chapter included the study of four basic areas:
	
1.	 The general solution of Maxwell’s equations for plane waves for a variety of typically encountered 
scenarios was investigated. The behavior of waves normally incident on a surface was character-
ized including the effects of lossy materials.
	
2.	 A characterization of the behavior of electromagnetic wave propagation in transmission lines 
with terminating impedances was presented. It included a discussion of Smith charts and typical 
methods used for impedance matching including stub tuning.
	
3.	 An overview of the electromagnetic behavior in waveguides via a solution of the Helmholtz equa-
tion was discussed. A section was also included describing the behavior of light in optical fiber.
	
4.	 Lastly, a discussion of basic antenna characteristics was provided including a mathematical 
description of the currents and fields resulting from a dipole of arbitrary length. The radiated 
electromagnetic field, power density, total radiated power, directivity, and radiation resistance 
were found for several typical antennas.
© 2011 by Taylor and Francis Group, LLC

31-1
31.1  Introduction
Transmission lines are two or more uniform, parallel conductors able to transmit signals and power 
along their length. Two conductors connecting a source to a load is the basic picture taken in this chap-
ter. The study of transmission lines is important in a variety of fields, from the performance of commu-
nication systems to signal integrity in printed circuit boards [EEM03,ME04,HSDD09].
Understanding the characteristics of transmission lines is necessary where wave behaviors such as 
propagation, reflection, and interference are important factors. In the time domain, this can be quanti-
fied by comparing propagation time to rise or fall times of the signals propagating. Whenever propa-
gation times are not much shorter than rise times, wave behavior can no longer be ignored. Consider 
the system shown in Figure 31.1. If the rise time (tr) associated with the source voltage is much longer 
than the propagation delay time (td) for the line connecting the source and load, then wave behavior 
is not important. In this case, all time variations are gradual compared to the propagation delay, and 
understanding transmission lines is not an important factor in understanding system behavior. These 
lines could simply be treated as nodes connecting the source and load. If the electrically short line’s 
resistance, capacitance, or inductance were important, then the lines could be represented in a lumped 
element model. On the other hand, at higher speeds, where tt is not much longer than td, reflections can 
play an important role. The source could see waves that have been reflected from the load and which 
could be re-reflected from the source, and so on. For this case, wave behavior is clearly important and a 
sound understanding of transmission lines becomes essential to understanding how the system works.
Speaking more generally, study of quasi-statics shows that transmission line models are not needed if 
the electrical length of the conductors is short. In the frequency-domain, electrical length is proportional 
31
Transmission Line 
Time-Domain Analysis 
and Signal Integrity
31.1	 Introduction..................................................................................... 31-1
31.2	 EM Fundamentals........................................................................... 31-2
31.3	 Transmission-Line Modeling........................................................ 31-3
31.4	 Reflection and Transmission at Boundaries................................ 31-7
31.5	 Transient Analysis........................................................................... 31-8
31.6	 Multiple Transmission Line Sections......................................... 31-12
31.7	 Transmission Line Junctions....................................................... 31-13
31.8	 Reactive Loads.................................................................................31-14
31.9	 Nonlinear Loads............................................................................ 31-19
31.10	 Conclusion...................................................................................... 31-23
References................................................................................................... 31-23
Edward Wheeler
Rose-Hulman Institute 
of Technology
Jianjian Song
Rose-Hulman Institute 
of Technology
David R. Voltmer
Rose-Hulman Institute 
of Technology
© 2011 by Taylor and Francis Group, LLC

31-2 
Fundamentals of Industrial Electronics
to the ratio of conductor length (l) to wavelength (λ). [EETR60] In the time domain, it is proportional to 
the ratio propagation delay-to-signal rise time. For lines that are electrically short—that is, when λ ≫ l 
or when tr ≫ td—wave effects are negligible and transmission line models are unnecessary.
31.2  EM Fundamentals
We begin our discussion with some electromagnetic fundamentals that can be omitted without loss of 
continuity.
Transverse electromagnetic (TEM) waves, in which the electrical and magnetic waves are perpen-
dicular to the direction of propagation, are the principal type of electromagnetic wave that propagates 
along transmission lines. The TEM character of the fields is important as it allows a unique definition of 
voltage and current [PAEMF61].
TEM waves traveling in the +az-direction can be written in terms of a transverse vector which varies 
in the x–y plane and a wave function g:
	
E
H
E
H
(
)
(
)
x,y,z
x, y,z
 = 
x,y g t
z
v
x,y g t
z
v
t
t



(
)
−




(
)
−










These waves are solutions of Maxwell’s equations. Below, the del operator is split into two parts, one 
along z and the other acting in the x–y plane. Using this notation with Faraday’s law,
	
∇×
= ∇+
∂
∂



×
= −∂
∂
E
a
E
B
t
z
z
t
Substituting the wave functions assumed for E and H,
	
∇+
∂
∂



×
−



= −
∂
−






t
z
t
t
z
(x,y)g t
z
v
(x,y)g t
z
v
a
E
H
µ


∂t
	
∇×
−



−
×
−



= −
∂
t
t
z
t
t
(x,y)g t
z
v
1
v
(x,y)g t
z
v
(x,y)g t
E
a
E
H
µ
−








∂
z
v
t
 
In this expression, since both ∇t and Et are directed in the tangential plane, which implies their cross 
product must be along the z-direction, ∇t × Et(x, y)g(t − (z/v)) must too be in the z-direction. On the other 
td=ℓ/v
ℓ
Load
+
–
Source
v=speed of propagation
FIGURE 31.1  Transmission line connecting source to load.
© 2011 by Taylor and Francis Group, LLC

Transmission Line Time-Domain Analysis and Signal Integrity 
31-3
hand, the right-hand side is purely in the transverse direction in the x–y plane. Therefore, equating 
tangential and longitudinal components, it is clear that Et(x,y) satisfies the electrostatic equation:
	
∇×
−
=
t
t(x,y)g t
(z/v)
0
E
(
)
	
∇×
=
t
t(x,y)
0
E
Following a similar tack with Ampere’s law, one readily finds that the transverse magnetic field satisfies 
the magnetostatic equation:
	
∇×
=
t
t(x,y)
z
H
J
Therefore, if the waves are TEM in character, the tangential fields can be found from statics. This is 
of utmost importance since the resulting tangential fields—being those found from the electrostatic 
and magnetostatic equations—are independent of frequency. Their direction and relative amplitude 
are determined solely by the cross-sectional geometry and material properties. Because the transverse 
fields are independent of frequency, unique relationships exist between Et and the line voltage (V), and 
between Ht and the line current (I).
This result provides the foundation for developing transmission line models in terms of V and I rather 
than in terms of field quantities. Due to a unique relation existing between the Et and V and between Ht 
and I, for TEM waves traveling on the transmission line, voltage and current may just as well be used 
to represent the traveling waves as the electric and magnetic vectors. Moreover, because the relative 
amplitudes of the electric and magnetic fields are determined by the intrinsic impedance, and since the 
relationships between Et and V and between Ht and I follow solely from the cross-sectional geometry 
and material properties, a unique and unambiguous relation can be defined between the voltage and 
current waves. This relation between the voltage and current waves is denoted as the transmission line’s 
characteristic impedance (Zc).
	
Z
V t
(z/v)
I t
(z/v)
V
g t
(z/v)
I
g t
(z/v)
c
m
m
=
−
−
=
−


−


(
)
(
)
(
)
(
)
In addition, TEM wave solutions exist for the lossless lines considered here and for lossy lines when the 
loss is confined to dielectric loss. TEM wave solutions are strictly no longer possible if the finite conduc-
tivity of the conductors is considered since a z-component of the electric field is required to sustain a 
current. For good conductors, however, the z-component is sufficiently small that the fields are still very 
nearly transverse and the wave is essentially TEM in character. It should also be noted that the waves are 
precisely TEM in character only for lines that are perfect electrical conductors (PEC) and that are sur-
rounded by a homogeneous dielectric—a coaxial cable and a stripline for example. For a microstrip, the 
transmission line model is an excellent approximation [FME92]. Multiple transmission lines are treated 
by techniques similar to single transmission lines [MTL08].
31.3  Transmission-Line Modeling
Once it is established that transmission lines can be described in terms of traveling voltage and current 
waves, circuit-based models are a natural development. Starting by applying Faraday’s law for the sta-
tionary dashed closed loop in Figure 31.2, a relation between current and the rate of change in voltage 
can be established, where φ is the magnetic flux penetrating the closed path of the E-field integral:
	
E dl
t
⋅
= −∂
∂
∫
φ
© 2011 by Taylor and Francis Group, LLC

31-4 
Fundamentals of Industrial Electronics
	
V z
z
V z
RI
t
I
I  
+ ∆
(
) −
( ) +
= −∂
∂








φ
The ratio of magnetic flux to current is simply the self-inductance of the transmission line section and 
is not a function of time. Taking the limit as Δz grows small, a differential equation is obtained relating 
the spatial rate of change for voltage to current and where R is the resistance per unit length and L is 
the inductance per unit length:
	
V z
z
V z
RI
L I
t
+ ∆
(
) −( ) = −
−
∂
∂
	
lim
V z
z
V z
z
lim
R
z I
L
z
I
t
z
0
z
0
∆→
∆→
+ ∆
(
) −( )
∆








=
−∆
−∆
∂
∂




	
∂
∂
= −
−
∂
∂
V
z
I
I
t
R
L
A similar relation can be found between the spatial rate of change in current to voltage by applying 
charge conservation to the cylindrical region in Figure 31.2 around the top conductor. The current out 
of a closed surface is equal to the rate that the charge stored within it decreases:
	
J
s
⋅
= −∂
∂
∫∫
d
q
t
surface

	
I z
z
I z
GV
t
q
V V  
+ ∆
(
) −( ) +
= −∂
∂








The ratio of charge to voltage is simply the capacitance of the transmission line section and is not a 
function of time. Taking the limit as Δz grows small, a differential equation is obtained relating the 
spatial rate of change for current to voltage and where G is the conductance per unit length and C is the 
capacitance per unit length:
	
I z
z
I z
GV
C V
t
(
)
( )
+ ∆
−
= −
−
∂
∂
+
v(z)
–
+
V(z + Δz)
–
I(z)
I(z + Δz)
Δz
z
ds
dl
x
FIGURE 31.2  Transmission line.
© 2011 by Taylor and Francis Group, LLC


Transmission Line Time-Domain Analysis and Signal Integrity 
31-5
	
lim I z
z
I z
z
lim
G
z V
C
z
V
t
z
0
z
0
∆→
∆→
+ ∆
(
) −( )
∆








=
−∆
−∆
∂
∂




	
∂
∂
= −
−
∂
∂
I
z
V
V
t
G
C
Applying KVL and KCL to the circuit model shown in Figure 31.3 results in these two relations and 
therefore closely models TEM wave propagation on lossy transmission lines where R represents Joule 
losses in the conductors, which dominate at lower frequencies; and where G represents dielectric loss, 
which often dominates at higher frequencies.
For lossless lines considered in this chapter, R and G are taken to be zero as shown in Figure 31.4.
The equations describing the relation between the voltage and current waves on lossless transmission 
lines can be combined to obtain wave equations for V and I:
	
∂
∂
= −
∂
∂
∂
∂= −∂
∂
V
z
I
t
I
z
V
t
L
C
	
∂
∂
= −
∂
∂
∂
∂= −
∂
∂
−
∂
∂




2
2
V
z
t
I
z
t
V
t
L
L
C
	
∂
∂
=
∂
∂
2
2
2
2
V
z
V
t
LC
Solving for V, we obtain the solution that has been assumed, where the minus sign signifies travel in the 
+az direction and the plus sign indicates travel in the −az direction:
	
V t
z
v
where the speed of propagation, v
1
±




=
LC
dz
dz
V(z)
I(z)
I(z + dz)
dz
dz
dz
+
–
V(z + dz)
+
–
FIGURE 31.3  Lossy TL circuit model.
dz
dz
I(z)
I(z + dz)
dz
V(z)
+
V(z + dz)
+
–
–
FIGURE 31.4  Lossless TL circuit model.
© 2011 by Taylor and Francis Group, LLC

31-6 
Fundamentals of Industrial Electronics
Given this voltage wave, the corresponding current wave can be found using one of the transmission 
line equations:
	
∂
∂= −
∂
∂
I
z
V
t
C
	
∂
∂
±














= −
∂
∂
±









z I
g t
z
v
t V
g t
z
v
m
m
C





Letting α be the temporal-spatial argument of the wave functions, one obtains, using the chain rule,
	
∂
∂


{
} = −
∂
∂


{
}
z I
g
t V
g
m
m
( )
( )
α
α
C
	
±
∂
∂
= −
∂
∂
I
v
g
V
g
m
m
α
α
C
	
V
I
1
v
Z
m
m
c
=
=
=
∓
∓
∓
C
L
C
The ratio between the voltage and current waves is the transmission line’s characteristic impedance:
	
Z
V t
/v
I t
/v
V
g t
/v
I
g t
/v
V
c
m
m
=
±
(
)
±
(
)
=
±
(
)


±
(
)


=
(
)
(
)
(
)
(
)
z
z
z
z
m
m
I
 
= ∓L
C
The relation involves a minus sign, which simply reflects the fact that the direction of the current is 
reversed for waves traveling in the −az direction, as indicated in Figure 31.5.
The remainder of the chapter will discuss applications and examples illustrating the analysis of sys-
tems involving transmission lines. Aside from the common coaxial transmission line, two types of 
transmission lines should be mentioned and are shown in Figure 31.6.
Coaxial cables find widespread use in communication systems and a variety of test and diagnostic 
equipment. The microstrip and stripline configurations in Figure 31.6 are particularly amenable to pla-
nar deposition techniques, and find wide use in printed circuit boards and in integrated circuits.
V(t–z/v)
–
+
+
–
z
+az
–az
I(t–z/v)
I(t + z/v)
V(t + z/v)
FIGURE 31.5  Waves traveling in ±az directions.
Signal trace
Dielectric
Reference planes
(b)
Signal trace
Dielectric (PCB laminate, SiO2)
Reference plane
(a)
FIGURE 31.6  Transmission lines: (a) microstrip and (b) stripline.
© 2011 by Taylor and Francis Group, LLC

Transmission Line Time-Domain Analysis and Signal Integrity 
31-7
31.4  Reflection and Transmission at Boundaries
Two types of waves are possible on a transmission line: waves moving away from the source toward the 
load and those moving in the opposite direction. When a single source excites a transmission line, it 
initiates a wave moving away from the source toward the load, here taken to be in the positive direc-
tion. Since the positive-going voltage wave is incident on the load, it is denoted as Vi. A corresponding 
incident current wave or Ii = Vi/Zc accompanies the incident voltage wave. The waves propagate along 
the transmission line unaltered until a change (or discontinuity) in impedance is encountered. Such a 
discontinuity would be created, for example, if a transmission line were joined to a second transmission 
line with a different characteristic impedance. At a discontinuity, part of the wave is reflected from the 
discontinuity and a part is transmitted across the discontinuity. An infinitely long transmission line 
would have no discontinuities and there would be no reflected wave.
To better understand the cause and nature of reflections consider Figure 31.7, which shows the bound-
ary connecting two transmission lines. A voltage–current wave propagates to the right toward the junc-
tion; this is known as an incident wave and is characterized by Vi/Ii = Zc1. The second transmission line 
carries the wave transmitted across the boundary and has a characteristic impedance value of Zc2 = Vt/It. 
There is also a reflected wave, in transmission line 1 traveling in the negative direction. This is the wave 
that has been reflected at the boundary. This wave is characterized by Vr/Ir = −Zc1. At the junction, the 
total voltage across each transmission line must be equal at the boundary (KVL holds).
	
V
V
V
t
i
r
=
+
	
Τ
Γ
Vi
i
=
+
V (
)
1
	
Τ
Γ
= +
1
In the relations above, the reflection coefficient, Γ = Vr/Vi, has been defined as the ratio of reflected 
voltage to incident voltage, and the transmission coefficient, T = Vt/Vi, has been defined as the ratio of 
transmitted voltage to incident voltage. Another relationship can be found using the fact that the cur-
rent is continuous at the boundary (KCL holds):
	
I
I
i
r
tI
−
=
	
V
V
V
i
c1
r
c1
t
c2
Z
Z
Z
−
=
	
1
Z
Z
Z
c1
c1
c2
−
=
Γ
Τ
Ii
Vi
+
+
–
+
–
–
Vr
Ir
Ir
It
It
Vt
Zc1
Ii
TL 1
Zc2
TL 2
FIGURE 31.7  Reflection and transmission at the boundary between two transmission lines.
© 2011 by Taylor and Francis Group, LLC

31-8 
Fundamentals of Industrial Electronics
The result is two equations involving Γ and T, which can be solved for Γ and T:
	
Γ =
−
+
Z
Z
Z
Z
c2
c1
c2
c1
	
T
c
c
c
=
+
2
2
2
1
Z
Z
Z
The reflection coefficient (and reflected voltage) vanishes when Zc1 = Zc2. In this case, the lines are 
matched and no reflected wave exists. Lines that are not matched result in reflected waves that propagate 
back toward the source to the left.
What is done in other situations, perhaps in which a line is terminated by lumped elements or in 
which lumped elements are present at the boundary between two transmission lines? In such cases, we 
may add to the principles outlined above (continuity of voltage and current) the fact that the V–I rela-
tionships of the lumped elements must hold. These situations will be discussed below.
31.5  Transient Analysis
How do voltages and currents move from their initial to final values? That is, what is their transient 
signature? The general question regarding the time evolution of voltage and current waveforms is a 
central question in signal integrity. To begin, consider the system in Figure 31.8 with a source and load 
connected by a transmission line. We seek a technique by which v(t) can be found at any position along 
the line.
Considering the source to be off (zero) for t < 0, perhaps the first question to be answered is what 
happens just as the source is turned on? What happens at t = 0+? Since no time has elapsed, the wave 
cannot have traveled any finite distance. For example, the load resistance will experience no effects from 
the source turning on until the wave has had time to propagate to the load. Before t = td, conditions at 
the load will be just as they were when the source was off. At t = 0+, the effect of the source turning on is 
confined to just one location, and that is where the source connects to the line, at z = 0.
At z = 0, the ratio between the voltage and current waveforms being introduced to the line is deter-
mined by Zc. Moreover, this ratio is independent of frequency. For all frequencies, the ratio of voltage 
to current waves is Zc. Therefore, if one is only interested in what happens at z = 0, and there are no 
reflected waves to be considered, the transmission line can be replaced with a resistance R = Zc, as shown 
in Figure 31.9. This will allow the determination of the positive-traveling waveform being injected into 
the transmission line at z = 0. This wave will subsequently travel down the transmission line as traveling 
step function. At t = td, the step’s edge will encounter the resistive load. But for now, we are only inter-
ested in one instant in time (t = 0+) and one location in place (z = 0).
So, clearly, the initial voltage wave at t = 0+ and z = 0 can be determined by voltage division.
	
V
Z
R
Z V
+
z 0, t 0
c
s
c
s  t 0
+
+
=
=
=
=
+
td= /v
+
–
Rs
Zc
RL
Vs
z=0
z =
FIGURE 31.8  System of source, line, and load.
© 2011 by Taylor and Francis Group, LLC

Transmission Line Time-Domain Analysis and Signal Integrity 
31-9
In general, the voltage injected into the transmission line at z = 0 is 
given by this equation. One must be careful when t > 2td; however, since 
the voltage being injected from the source may not be the total volt-
age, or even the total positive-going voltage. This is due to the fact that 
additional reflections can be present from the source. When t > 2td, it is 
possible that waves that have been reflected from the load are present. 
These waves can then be re-reflected from the source that can add to or 
subtract from the positive-going waves.
For waves traveling in the +az-direction on a transmission line, the 
ratio is Zc. For waves traveling in the −az-direction on a transmission 
line, the ratio is −Zc. The important concept to keep in mind is that the 
characteristic impedance is the ratio of traveling voltage and current waves; it is not the ratio of total 
voltage to total current. Total voltage and current are a combination of positively and negatively travel-
ing waves. The resulting total voltage and total current are not related simply as Zc or −Zc. When both 
incident and reflected waves are present, they can constructively or destructively interfere with each 
other, and their relationship is not simply Zc. It is not true for t > 2td that the ratio of total voltage to total 
current is Zc, since there might be reflected waves present.
With that caution in mind, it is nevertheless true that, even when t > 2td, the voltage (the positive-
going wave) being injected into the line at z = 0 in Figure 31.9 can be expressed as a voltage divider. This 
does not include any positive-traveling voltage wave resulting from being reflected from the load and 
then again from the source. It is just the voltage being injected into the line from the source:
	
V
t
Z
R
Z V t
+
z=0
c
s
c
s
( )
=
+
( )
The incident voltage waveform from the source traveling on the transmission line is therefore
	
V t z
V
t
z
v
Z
R
Z V
t
z
v
i
z=0
+
c
s
c
s
,
(
)
=
−



=
+
−




Again, it should be stressed that this is not the total voltage, but is rather only the voltage waveform that 
is injected from the source. To determine the total voltage on the line, the effects of reflection must be 
included as discussed below.
Upon being injected onto the transmission line, the voltage wave travels to the resistive load. What 
happens when it encounters the resistor can be found by invoking the resistance’s v–i relation, Ohm’s 
law, which gives the ratio that must exist between the total voltage and the total current across a resistor:
	
V
IR
V
V
V
Z
V
Z
R
L
i
r
i
c
r
c
L
=
→
+
=
−




	
1
R
1
Z
Z
R
Z
R
Z
L
L
c
L
c
L
L
c
L
c
+
=
−



→
=
−
+
Γ
Γ
Γ
When the wave reflected from the load reaches the source, part of this 
reflected wave is then reflected from the source and subsequently travels 
to the load, where a part is reflected, and so on (Figure 31.10). The expres-
sion for the source reflection coefficient is similar to that of the load:
	
Γs
s
c
s
c
R
Z
R
Z
=
−
+
+
–
Rs
Zc
Vs
Vi
+
–
FIGURE 31.9 
System at z = 0.
RL
Ir
+
Vr
–
Ii
+
Vi
–
Zc
I
+
V
–
z=
FIGURE 31.10  Reflection from 
load.
© 2011 by Taylor and Francis Group, LLC

31-10 
Fundamentals of Industrial Electronics
At any particular time and position, the total voltage is the sum of the incident and all the reflected 
waves that are present at the particular time and location in question. This challenging bookkeeping 
task is eased by the use of bounce diagrams as illustrated in Figure 31.11.
Bounce diagrams are plots of time versus location in which the reflected waves are individually 
tracked. In Figure 31.11, Vi is the initial wave injected from the source and its propagation toward the 
load is indicated by the slanted line that arrives at the load in one delay time.
Example  31.1
Find Vin(t) and VL(t).
For the system shown in Figure 31.12, Vi, td, Γs, and ΓL can readily be found.
	
V
2.88 V
0.72 V
i z 0, t
+
(
)
=
=
=
+
=
0
50
150
50
	
t
 m
2 10  m/s
0.5 ns
d
8
=
=
0 1.
(
)
	
Γ
Γ
s
L
150
50
150
50
2
25
50
25
50
3  
=
−
−
=
=
−
−
= −
1
1
With these parameters, a bounce diagram for the system can be completed. Since the source is a step 
function and therefore constant for t > 0, the reflected waves are particularly simple, and all that is 
required is that their wave fronts be tracked, which the bounce diagram readily does (Figure 31.13).
z = 0
z=I
td
2td
3td
Vi (t–z/v)
ΓLVi (t– I/v – (I–z)/v)
z
t
ΓsΓLVi[t–(2I+z)/v]
ΓsΓL
2Vi [t– (4I –z)/v]
ΓsΓL
2Vi [t–(4I+z)/v]
FIGURE 31.11  Generic bounce diagram.
+
–
150 Ω
Zc=50 Ω
2.88 u(t)
25 Ω
v = 2(108) m/s
10 cm
+
–
b
Vab= Vin
a
+
–
VL
FIGURE 31.12  System with resistive load and 10 cm TL.
© 2011 by Taylor and Francis Group, LLC

Transmission Line Time-Domain Analysis and Signal Integrity 
31-11
Having constructed the bounce diagram, voltage vs. time plots are readily developed for any loca-
tion along the line as the sum of all voltage waves that have passed the location. This is a function of 
time as more reflections must be included with increasing time. See Figure 31.14 for Vin = V(z=0), and for 
VL = V(z=10cm).
Example  31.2
Pulses are a signal type common in digital systems and much of our previous work can be utilized if we 
recognize that constant-valued pulses can be expressed as the difference of step functions. Given the 
system and the measured input voltage, Vab(t), as shown in Figure 31.15, determine the transmission line’s 
characteristic impedance and propagation speed. Also find L, C, and RL.
Zc can be determined from the z = 0 equivalent circuit and the measured value of Vab for 0 < t < 1 ns. 
The speed of propagation can be determined from the time at which the reflected pulse is seen at the 
source, having traveled to the load and then back to the source. Knowing Zc and v fixes L and C since 
these four quantities are related through two equations. Knowing the reflected pulse determines RL:
	
10 V
Z
50
Z 20 V
Z
50
v
2(0.3m)
s
2(10 )m/s
c
c
c
9
8
=
+
→
=
=
=
−
Ω
Ω
3 10
(
)
	
	
Z
v
0.25 H/m,
100pF/m
c =
=



→
=
=
L C
LC
L
C
/
/
1
µ
	
0
10
0.5
1.0
1.5
2.0
2.5
0.72 V
–0.24 V
z (cm)
t (ns)
0
Γs=1/2
ΓL= –1/3
–0.12 V
0.04 V
0.02 V
FIGURE 31.13  Bounce diagram.
0.5
1
1.5
2.0
250
500
750
400
480
VL (mV)
t (ns)
0.5
1
1.5
2.0
250
500
750
720
360
420
Vin (mV)
t (ns)
FIGURE 31.14  Vin(t) and VL(t).
© 2011 by Taylor and Francis Group, LLC

31-12 
Fundamentals of Industrial Electronics
Since Zc = Rs, and the source reflection coefficient Γs = 0, the source is said to be matched, which is 
meant to convey that the source impedance is equal, or matched, to the line’s characteristic impedance. 
From the resulting bounce diagram in Figure 31.16, the reflected wave seen at the source is purely due to 
reflection from the load and no portion is “re-reflected” from the source (since Γs = 0):
	
Γ
Ω
Ω
Ω
L
L
L
L
R
50
R
50 
2
10
R
33 1
3
=
−
+
= −→
=
	
31.6  Multiple Transmission Line Sections
Consider the system in Figure 31.17 with two transmission line segments of differing impedances 
but with identical propagation speeds. This is a common occurrence with PCBs where the dielectric 
is unchanged (resulting in the same speed of propagation) but where the microstrip trace geometry 
changes resulting in a discontinuity for Zc. Since the trace-reference separation often remains unchanged 
10
–2
Vab (volts)
t (ns)
1
...
...
...
...
3
10
–2
Vab (volts)
t (ns)
...
...
...
...
1
3
v
50 Ω
Zc
20[u(t) – u(t– 10 –9)]V
Vab
a
b
+
–
z = 0
z = 30 cm
RL
VL
+
–
FIGURE 31.15  System with a pulse input.
0
30
1.5
3.0
4.5
0
Γs=0
ΓL
0 V
z (cm)
0.5 Vs(t–z/v)
0.5 ΓLVs[t–(2I+z)/v]
FIGURE 31.16  Bounce diagram for system with pulse input.
© 2011 by Taylor and Francis Group, LLC

Transmission Line Time-Domain Analysis and Signal Integrity 
31-13
in PCBs, the change in characteristic impedance is most often due to a change in trace width, e.g., wider 
traces result in higher C and lower L giving a lower Zc.
The resulting bounce diagram is shown in Figure 31.18.
Plots of the line voltage at the junction between the two lines (z = 10 cm) and at the 50 Ω load are 
shown in Figure 31.19.
31.7  Transmission Line Junctions
When a junction between two transmission lines involves lumped elements, whether due to intentional 
loads or to unintended parasitics, the reflection and transmission coefficients at the junction can readily 
be determined by enforcing continuity of current and voltage and the element v–i relations.
10 cm
+
–
75 Ω
v = 2(108) m/s
+
–
Vin
Zc= 75 Ω
vp= 2(108) m/s
Zc= 150 Ω
50 Ω
5 cm
Γs= 0
Γ = 1/3
T = 4/3
Γ = –1/3
T = 2/3
ΓL= –1/2
720 u(t) mV
FIGURE 31.17  System with multiple TL sections.
Γs= 0
Γ=1/3
T=4/3
Γ=–1/3
T=2/3
ΓL=–1/2
360 mV
480 mV
–240 mV
120 mV
–160 mV
–26.67 mV
–40 mV
80 mV
13.33 mV
…
…
t (ns)
0.5
1.0
1.5
2.0
FIGURE 31.18  Bounce diagram for a multiple TL section system.
0.5
1
1.5
250
500
480
320
293.3
Vjnct (mV)
t (ns)
0.5
1
1.5
250
500
VL (mV)
t (ns)
240
280 286.7
FIGURE 31.19  Vjnct(t) and VL(t).
© 2011 by Taylor and Francis Group, LLC

31-14 
Fundamentals of Industrial Electronics
Example  31.3
Consider the junction in Figure 31.20 and assume the wave is coming from TL 1 on the left and with the 
meaning of the effective reflection and transmission coefficients as given below. Assuming that lumped 
element analysis is valid at the junction, Γ and Τ can be found by enforcing KVL and KCL at the junction. 
The assumption underlying the analysis is that the junction’s length can be neglected, Δl = 0:
	
Definitions
V
1
V
V
TV
I
V
Z
V
Z
I
TV
Z
1
i
2
i
1
i
c1
i
c1
2
i
c2
=
+
=
=
−
=







(
)
Γ
Γ


	
	
Continuity of V
V
V
R I
1
2
2
=
+
{
2 	
	
Continuity of I
I
V
R
I
1
1
1
−
=

2
	
From the six equations, V1, V2, I1, and I2 can be eliminated resulting in two equations giving Γ and T in 
terms of Zc1, Zc2, R1, and R2 (Vi is common to all terms and can be divided out):
	
V
V
R I
1
T
R
T
Z
1
2
2
c2
=
+
→+
=
+
2
2
Γ
	
	
I
V
R
I
1
Z
Z
1
R
T
Z
1
1
1
c1
c1
1
c2
−
=
→
−
−+
=
2
Γ
Γ
	
For Zc1 = R1 = R2 = 50 Ω and Zc2 = 100 Ω, Γ = −1/7 and T = 4/7.
31.8  Reactive Loads
The preceding analysis involved transmission line junctions and resistances where the v–i relations were 
algebraic. When energy storage elements such as capacitances or inductances are present, v–i relations 
become differential equations. The electric and magnetic energies stored within these elements cannot 
be changed instantaneously but require a finite interval of time for any finite change in energy:
	
I
C dV
dt
dI
=
=
V
L dt 	
Zc1
Zc2
R1
R2
I1
V1
+
–
–
I2
V2
+
ΔI= 0
FIGURE 31.20  Transmission line junction with discontinuity.
© 2011 by Taylor and Francis Group, LLC

Transmission Line Time-Domain Analysis and Signal Integrity 
31-15
Let’s begin simply with a single capacitance terminating a transmission line with a characteristic imped-
ance Zc that is fed by a step-function source as shown in Figure 31.21.
At z = 0, the step-function VS excites a voltage step at the input of the line, which can be calculated by 
using voltage division. This voltage wave is accompanied by a current wave:
	
V
Z
R
Z V
i z 0
c
s
c
s
= =
+
	
	
I
Z
R
Z
V
Z
i z 0, t=0
c
s
c
s
c  t 0
+
+
=
=
=
+
	
The voltage and current waves propagate toward the capacitive load with velocity vp and arrive after a 
propagation time delay:
	
t
vp
d = l
	
The total voltage and current at the capacitance must be related via the capacitance’s v–i relation. We 
assume here that the capacitance is uncharged prior to the arrival of the wave from the source:
	
I
C dV
dt
=
	
	
V
V
Z
C d V
V
dt
i
r
c
i
r
−
=
+
(
)
	
The total voltage is the sum of the incident (which, in this case, is a time-invariant step from the step 
source) and the reflected wave. The sum of the incident and reflected voltages must satisfy the capaci-
tance’s element relation:
	
V
Z
R
Z V
i
c
s
c
s
=
+
	
The resulting differential equation reads
	
V
V
Z
C dV
dt
i
r
c
r
−
=
	
	
Z C dV
dt
V
V
c
r
r
i
+
=
	
+
–
Rs
Vs u(t) V
z=0
V = Vi+ Vr
+
–
C
I = (Vi+ Vr)/Zc
td=  /v
Zc
z =
FIGURE 31.21  Capacitor-terminated transmission line.
© 2011 by Taylor and Francis Group, LLC

31-16 
Fundamentals of Industrial Electronics
This differential equation is subject to the initial condition for the capacitance’s voltage:
	
V
V
V
0
z
i
r
z
=
=
=
+
=
L
L
(
)
	
The resulting solution of the first-order differential equation for the reflected voltage wave is
	
V
V 1
2e
u t
t
r
i
t t
Z C
d
d
c
=
−
−
−
−
(
) (
)
(
/
)
	
The preceding analysis uses the principles outlined above—that current and voltage continuity together 
with element v–i relationships can be used to determine reflections. Let us now approach this same 
problem with an alternative analysis. The result will be a time-dependent reflection coefficient for the 
capacitor, which must be the case since the ratio of the incident to reflected voltages is time-dependent. 
We will find nothing new but may discover a different way of looking at the problem (Figure 31.22).
So, beginning with the system shown in Figure 31.21, one can recognize that the voltage across 
the capacitance cannot change instantly. This requires that, at the instant of incidence, there must 
be a reflected voltage step equal to the incident voltage step; the total voltage is composed of the sum 
of the incident and reflected waves, and by KVL this must be equal to the capacitor terminal voltage 
according to
	
V
V
=
+
Vi
r 	
Simultaneously, the incident current step initiates a reflected current step; the incident is directed 
toward the load into the upper terminal of the capacitor, the reflected is directed away from the load out 
of the upper terminal:
	
I
I
I
=
−
i
r 	
	
I
V
Z
V
Z
i
C
r
C
=
−
	
V (z =I)
t
Vi
2Vi
–Vi
td
V = Vi+ Vr
Vi
τ=ZcC
FIGURE 31.22  Total and reflected load voltage for a capacitive termination.
© 2011 by Taylor and Francis Group, LLC

Transmission Line Time-Domain Analysis and Signal Integrity 
31-17
But rather than a linear constant relating the terminal voltage and current as in a resistor, the capacitor 
terminal voltage and current are related by a differential equation:
	
I
C
=
dV
dt 	
	
V
Z
C d V
dt
C
i
r
i
r
V
V
−
=
+
(
)
	
Both sides of this equation can be divided by Vi, where the reflection coefficient is defined as usual as the 
ratio of the reflected and incident voltages at the capacitor terminals:
	
1
1
1
1
−
=
+
−
=
+
(
/
)
(
(
/
))
(
)
V
V
or
r
i
r
i
V
Z
C d
V
dt
Z
C d
dt
c
c
Γ
Γ
	
This reflection coefficient must vary with time if it is to satisfy the differential equation. Even though the 
incident voltage is a step function, the reflected voltage is time varying as indicated by the time-varying 
reflection coefficient:
	
d
dt
Z C
Z C
c
c
Γ
Γ
+
=
1
	
The initial condition requires that Vc(td) = 0. Solving the above differential equation subject to this initial 
condition is sufficient for us to solve for a time-varying reflection coefficient:
	
Γ =
−




−
−−
1
2e
u t
t
t t
Z C
c
d
(
)
(
)
d
	
where the (t − td) term accounts for the time required for the incident wave to travel from the source to 
the capacitance. The incident voltage is from the voltage divider at the source:
	
Vi
t t
z
d
V Z
R
Z
s
c
s
c
=
=
=
+
L,
	
The reflected voltage at the capacitive load is the product of the incident voltage and the reflection coef-
ficient. The total voltage at the capacitive load is the sum of the incident and reflected voltages. It can 
readily be seen that the voltages are the same as those found above:
	
V
V
V Z
R
Z
e
u t
t
c
s
c
s
c
d
t t
Z C
d
c
r
i
=
=
+
−




−
−−
Γ
1
2
(
)
(
)
	
	
V
V
V
V
V
r
c
=
+
=
+
i
i
i
Γ
	
	
V
V Z
R
Z
e
u t
t
s
c
s
c
d
t t
Z C
d
c
=
+
−




−
−−
1
2
(
)
(
)
	
© 2011 by Taylor and Francis Group, LLC

31-18 
Fundamentals of Industrial Electronics
The physical basis of the mathematical relations is summarized in the following points:
	
1.	 The reflection coefficient has an initial value of −1 since the uncharged capacitor initially, at the 
instant the incident wave arrives, acts as a short circuit.
	
2.	 The reflection coefficient has a final value of +1 since, for sufficiently long times, the capacitor is 
fully charged and acts as an open circuit.
	
3.	 The transition of the reflection coefficient from −1 to +1 proceeds with a time constant of τc = ZcC.
Based upon these physical principles, we can sidestep the mathematics associated with an inductive 
load with no initial current flow. Since the current in an inductance cannot change instantaneously, the 
inductance initially appears as an open circuit with a reflection coefficient of +1. For this step source, 
the steady-state current will be constant and the response of an inductance will be like a short circuit; so 
after a suitably long time, the reflection coefficient will be −1. The time constant of this transition is that 
of an inductance L and Zc, τ = L/Zc. Plots of the terminal voltages of an inductive load on a transmission 
line are shown in Figure 31.23.
V (z = I)
t
Vi
2Vi
–Vi
td
V = Vi+ Vr
Vr
τ=L/Zc
FIGURE 31.23  Total and reflected load voltage for an inductive termination.
V (z = I)
t
Vi
2Vi
–Vi
td
R<Zc
Vr
R>Zc
R=Zc
R>Zc
R=Zc
R<Zc
V = Vi+ Vr
τ = (R||Zc)C
FIGURE 31.24  Total and reflected load voltage for a parallel RC termination.
© 2011 by Taylor and Francis Group, LLC

Transmission Line Time-Domain Analysis and Signal Integrity 
31-19
With a step input, loads that contain a single capacitor or inductor and several resistors can be ana-
lyzed in a similar manner. Consider a capacitance in parallel with a resistance. This combination will 
initially act as a short circuit (the capacitor acting as a short will dominate) and will end acting as just 
the resistance (the capacitance acting as an open). The time constant will be (R∥Zc)C. Typical responses 
appear in Figure 31.24.
Consider, again with a step input, an RL series load. In this case, the load will initially act as an open 
(the inductance acting as an open will dominate) and will end as just the resistance (the inductance act-
ing as a short). The time constant will be L/(R + Zc). Typical responses appear in Figure 31.25.
31.9  Nonlinear Loads
Finally, what are the effects of a nonlinear element such as a diode or a logic circuit element as a load? 
The question cannot be determined with the techniques used in the previous sections since the tech-
niques are valid for linear systems only. Linear elements and solution methods are based upon a con-
stant relationship between the voltage and current. Nonlinear elements have varying proportionality 
between the terminal current and voltage. Consequently, we can understand their behavior more read-
ily by using their voltage–current characteristics and using graphical methods. Additional details of this 
method, i.e., the method of Bergeron, are available online [TIBD96].
To explain the process, consider a linear source and load. The source VS with a source resistance RS 
excites a transmission line characterized by Zc and time delay td = l/vp and terminated by load RL as 
shown in Figure 31.26.
td=I/v
+
–
RS
Zc
RL
VS
z=0
z=l
FIGURE 31.26  Step excitation of terminated transmission line.
t
τ = L/(R + Zc)
V (z = I)
Vi
2Vi
–Vi
td
R < Zc
Vr
R > Zc
R = Zc
R > Zc
R = Zc
R < Zc
V = Vi+ Vr
FIGURE 31.25  Total and reflected load voltage for a series RL termination.
© 2011 by Taylor and Francis Group, LLC

31-20 
Fundamentals of Industrial Electronics
We must determine the incident voltage from the source toward the load, Vi. The terminal character-
istic of the source is a linear I–V relationship, curve 1 in Figure 31.27:
	
I
I
V
RS
=
−
o
	
The input terminal characteristic of the input of the transmission line is given by its characteristic 
impedance and is shown as curve 2 in Figure 31.27. Note the slope of the Vi–Ii curve is 1/Zc:
	
V
I Z
i
i
=
c 	
When the source is connected to the transmission line input, the terminal voltages and currents must 
be equal; these conditions are satisfied at point A where the two curves intersect. Voltage and current at 
point A and time t = 0 are VA = Vi and IA = Ii, respectively. In this example of a step function, the volt-
age and current were both zero for t < 0, so the initial point of curve 2 is the origin of the I–V plane. In 
general, the starting point for the curve 2 is (Io, Vo) with curve 2 connected to curve 1 with slope 1/Zc as 
for the step function.
The transient voltage Vi propagates to the load and arrives at time t = td. The incident voltage excites a 
reflected voltage when it is incident upon the load RL. At the resistive load, the total voltage and current 
are related by RL = VL/IL, which is represented by curve 3 in Figure 31.27. This load voltage, composed of 
both incident and reflected voltages, must lie on curve 3 at some point B where curves 1 and 3 intersect 
and must be determined. Therefore, the load voltage at t = td is expressed as
	
V
V
V
V
V
V
B
i
r
A
r
L =
=
+
=
+
	
and can be rewritten as
	
V
V
V
r
A
B
= −
−
(
) 	
Likewise, the load current is expressed as
	
I
I
I
I
I
I
L
B
i
r
A
r
=
=
−
=
−
	
Io
I
V
VS
(Io,Vo)
B
D
m=–1/Zc
m = 1/Zc
Curve 1: I=Io–Vs/Zc
Curve 3: IL= VL/RL
Curve 2: Ii= Vi/Zc
Z
C
A
VB VD VZ
VC
VA
FIGURE 31.27  Bergeron diagram for step-excited transmission line.
© 2011 by Taylor and Francis Group, LLC

Transmission Line Time-Domain Analysis and Signal Integrity 
31-21
and can be rewritten as
	
I
I
I
r
A
B
=
−
. 	
Recall that the ratio of the reflected voltage and current waves is given by the characteristic impedance, 
the negative already accounted for in the equation above (IL = Ii − Ir):
	
Z
V
I
V
V
I
I
c
r
r
A
B
A
B
=
= −
−
−
	
The “two-point” form of a straight line is expressed as
	
I
mV
I
I
I
V
V V
I
A
B
A
B
=
+
=
−
−
+
0
0
	
where m is the slope of the line and I0 is the I-axis intercept. Comparing the forms of the two previous 
equations, we see a line with slope m = −1/ZC that passes through points A and B. We can find point B 
as the intersection of the load line (curve 3) and a line of slope −1/ZC that passes through point A. The 
initial transient pulse VA initiates this load voltage VL = VB at time t = td.
This process continues ad infinitum as the wave undergoes repeated reflections. The voltages at the 
intersection points of the lines with slope m = 1/ZC and the source line are the input voltages of the trans-
mission line at t = 2ntd intervals. The voltages at the intersection points of the lines with slope m = −1/Zc are 
the output voltages of the transmission line at t = (2n + 1)td intervals. These voltages can be plotted with 
respect to time as shown in Figure 31.28. Note that after many reflections, the input and output voltages 
asymptotically approaches point Z. This is expected since each reflection is smaller than the previous. 
The transients grow smaller and, after many reflections, it is as if the source was connected directly to 
the load. Since the source resistance is less than the characteristic impedance in Figure 31.27 and has 
a greater slope, all reflections occur in the region below the source load line with monotonic voltage 
changes at both the input and output of the transmission line.
In the above example, the Bergeron method was demonstrated for a case that was simplified by the 
linear nature of the source and the load impedances. However, this technique brings the power to treat 
nonlinear elements with a positive sloped line (m = 1/Zc) intersecting the source I–V curve at points 
that represent the line input voltages—points A, C, E, and so on. A negative sloped (m = −1/Zc) line, 
V
t
td
2td
3td
4td
5td
6td
. . .
. . .
VZ
VA
VC
VE
VB
VD
FIGURE 31.28  Input and output voltages of step-excited transmission line.
© 2011 by Taylor and Francis Group, LLC

31-22 
Fundamentals of Industrial Electronics
representing negatively traveling waves, intersects the load I–V curve at points that represent the line 
output voltages—points B, D, F, and so on.
The following example is for a transmission line with a matched source and a diode load. The source 
switches from a low state to a high state at t = 0 and so can be represented as a step function. Vs = 5u(t) 
and the source resistance Rs = 100 Ω. The line has Zc = 50 Ω with a delay time of td = 10 μs. The diode can 
be approximated by a 0.7 V source in series with a 5 Ω resistance. The diode-terminated transmission 
line and the resulting Bergeron diagram are shown below (Figures 31.29 and 31.30).
The time-domain plot of the resulting input and output voltages is given in Figure 31.31.
V (volts)
t (μs)
10
20
30
40
...
... VZ
VA
VC
VB
VD
0.25
0.5
0.75
1.0
1.25
1.5
FIGURE 31.31  Input and load voltages for diode-terminated transmission line.
I (mA)
V (volts)
5
0
B
D
Curve 2: TL input
C
A
25
50
1
2
3
4
Curve 1: source
Curve 3: diode
0
FIGURE 31.30  Bergeron diagram for diode-terminated transmission line.
td= 10 μs
+
–
Zc= 50 Ω
100 Ω
5 u(t)
+
–
Vin
+
–
VL
FIGURE 31.29  Diode-terminated transmission line.
© 2011 by Taylor and Francis Group, LLC

Transmission Line Time-Domain Analysis and Signal Integrity 
31-23
Note that the source impedance is greater than the characteristic impedance for this example and 
the reflections encircle the final point with the resulting voltage differences alternating in sign. When 
the source is matched to the line, there is only one reflection from the load, and point B and point Z are 
identical.
31.10  Conclusion
Whenever the propagation delay for a transmission is not negligible compared to the rise or fall time of 
the signal being propagated, wave effects such as reflection and interference can be of crucial importance 
in determining overall system performance. A sound understanding of transmission line behavior can 
be of crucial importance in a variety of contexts, from the performance of communication systems to 
signal integrity in printed circuit boards.
References
[EEM03] N. Ida, Engineering Electromagnetics (2nd edition), Springer-Verlag, New York, 2003.
[EETR60] R.B. Adler, L.J. Chu, and R.M. Fano, Electromagnetic Energy Transmission and Radiation, John 
Wiley & Sons, Inc., New York, 1960.
[FME92] R.E. Collins, Foundations for Microwave Engineering (2nd edition), McGraw-Hill Inc., New York, 
1992.
[HSDD09] S.H. Hall and H.L. Heck, Advanced Signal Integrity for High-Speed Digital Designs, John Wiley 
& Sons, Inc., Hoboken, NJ, 2009.
[ME04] D.M. Pozar, Microwave Engineering (3rd edition), Wiley-Interscience, Hoboken, NJ, 2004.
[MTL08] C.R. Paul, Analysis of Multiconductor Transmission Lines (2nd edition), Wiley-Interscience, 
New York, 2008.
[PAEMF61] R. Plonsey and R.E. Collins, Principles and Applications of Electromagnetic Fields, McGraw-Hill 
Book Company, Inc., New York, 1961.
[TIBD96] Texas Instruments Bergeron Method: A Graphic Method for Determining Line Reflections in 
Transient Phenomena, Texas Instruments Inc., Dallas, TX, 1996 (available online).
© 2011 by Taylor and Francis Group, LLC

