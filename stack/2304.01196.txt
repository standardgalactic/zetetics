Baize: An Open-Source Chat Model with Parameter-Efﬁcient Tuning
on Self-Chat Data
Canwen Xu1∗, Daya Guo2∗, Nan Duan3, Julian McAuley1
1University of California, San Diego, 2Sun Yat-sen University, 3Microsoft Research Asia
1{cxu,jmcauley}@ucsd.edu, 2guody5@mail2.sysu.edu.cn,
3nanduan@microsoft.com
Abstract
Chat models, such as ChatGPT, have shown
impressive capabilities and have been rapidly
adopted across numerous domains. However,
these models are only accessible through a
restricted API, creating barriers for new re-
search and progress in the ﬁeld.
We pro-
pose a pipeline that can automatically gener-
ate a high-quality multi-turn chat corpus by
leveraging ChatGPT to engage in a conver-
sation with itself. Subsequently, we employ
parameter-efﬁcient tuning to enhance LLaMA,
an open-source large language model.
The
resulting model, named Baize, demonstrates
good performance in multi-turn dialogues with
guardrails that minimize potential risks. The
Baize models and data are released for re-
search purposes only.1
1
Introduction
The rapid advancement of natural language pro-
cessing (NLP) techniques in recent years has led to
the emergence of highly capable chat models, such
as ChatGPT (OpenAI, 2023a) and GPT-4 (OpenAI,
2023b). These models demonstrate a remarkable
ability to understand and generate human-like re-
sponses in a wide range of domains. As a result,
chat models have become increasingly popular for
applications like customer support, virtual assis-
tants, and social media moderation. Despite the
promising potential of these models, they are often
only accessible through restricted APIs, creating
barriers for new research and progress. Further-
more, the limited availability of chat models poses
obstacles for researchers and practitioners alike,
hindering the growth of the NLP community. The
lack of publicly available, high-quality chat corpora
for multi-turn conversations exacerbates this issue,
limiting the possibilities for reﬁning and evaluating
these models.
∗Equal contribution.
1https://github.com/project-baize/baize
Seed
Dataset
Self-chatting
    Baize
Seeds
Corpus
Parameter-Eﬃcient
Tuning
Template
Foundation
Seed
Sampling
Model
Figure 1: The pipeline for training Baize.
In this paper, we propose a novel pipeline (shown
in Figure 1) to address these challenges by lever-
aging the capabilities of ChatGPT to automatically
generate a high-quality multi-turn chat corpus. Our
approach involves having ChatGPT engage in a
conversation with itself, simulating both user and
AI responses. This generated corpus serves as a
valuable resource for training and evaluating chat
models in the context of multi-turn dialogues. Fur-
thermore, by specifying a seed dataset, we can
sample from a particular domain and ﬁne-tune chat
models to be specialized in speciﬁc areas, such as
healthcare or ﬁnance.
To ﬁne-tune large language models in a low-
resource setting, we utilize a parameter-efﬁcient
tuning approach that effectively leverages the lim-
ited computational resources available. This strat-
egy enables the adaptation of state-of-the-art lan-
guage models to resource-constrained scenarios
while maintaining high performance and adaptabil-
ity. Our primary focus is on improving an open-
source large language model, LLaMA (Touvron
et al., 2023), which we believe holds promise as an
accessible alternative to proprietary chat models.
By ﬁne-tuning LLaMA with our generated chat cor-
pus, we create a new model, named Baize (Bái zé,
a mythical creature in Chinese folklore, who speaks
arXiv:2304.01196v1  [cs.CL]  3 Apr 2023

human languages and knows everything). Baize is
a chat model that can run on a single GPU, making
it accessible for a broader range of researchers.
Our main contributions in this paper are as fol-
lows:
• We propose a reproducible pipeline for auto-
matically generating a high-quality multi-turn
chat corpus by having ChatGPT engage in a
conversation with itself. Our pipeline ﬁlls a
gap in the availability of public resources for
training chat models in multi-turn dialogue
settings.
• We employ parameter-efﬁcient tuning to en-
hance the LLaMA model in a low-resource
setting, resulting in the creation of Baize, a
highly capable open-source chat model.
By presenting the Baize model and the pipeline
used to generate the chat corpus, we aim to facili-
tate new research and progress in the NLP commu-
nity.
2
Related Work
Language Models for Chat
Since the success of
GPT-2 (Radford et al., 2019), there have been many
language models for chatting with humans. As an
initial trial, DialoGPT (Zhang et al., 2019) uses
Reddit data to ﬁne-tune GPT-2 for open-domain
dialogue. Meena (Adiwardana et al., 2020) is a
multi-turn open-domain chatbot with 2.6B param-
eters, trained with data mined and ﬁltered from
public domain social media conversations. Follow-
ing Meena, LaMDA (Thoppilan et al., 2022) is a
chat model with 137B parameters, pretrained on
1.56T words of public dialog data and web text.
ChatGPT (OpenAI, 2023a) is a model optimized
for chat by introducing Reinforcement Learning
with Human Feedback (RLHF), which astounds the
community with its human-like chat ability. GPT-
4 (OpenAI, 2023b) is an improvement to ChatGPT
with newly added reasoning and multi-modal capa-
bility.
Concurrent to our works, there have been at-
tempts to replicate ChatGPT with open-source
foundation models. Stanford Alpaca (Taori et al.,
2023) uses Self-Instruct (Wang et al., 2022) to col-
lect data from GPT-3.5 in instruction learning for-
mat. Then, the collected dataset is used to ﬁne-
tune LLaMA (Touvron et al., 2023). Vicuna (Chi-
ang et al., 2023) is a ﬁne-tuned LLaMA model
trained on a ChatGPT dialogue corpus crawled
from sharegpt.com, a website for sharing Chat-
GPT dialogues. We will discuss the pros and cons
of the data source of each model in Section 3.
Parameter-Efﬁcient Tuning
Conventional ﬁne-
tuning requires training all parameters in a large
model, which can be inefﬁcient as the numbers of
parameters grows. Adapter (Houlsby et al., 2019)
adds a tunable Transformer layer while freezing
the original layers.
BitFit (Zaken et al., 2022)
only tunes bias terms in the linear layers. Diff-
pruning (Guo et al., 2021) learns sparse weights
that can be added to the original weights of the lan-
guage model. Preﬁx Tuning (Li and Liang, 2021;
Liu et al., 2021) ﬁne-tunes preﬁx tokens inserted
before the input. LoRA (Hu et al., 2022) inserts tun-
able low-rank matrices into attention layers; LoRA
achieves superior performance compared with con-
ventional ﬁne-tuning on GPT-3. Concurrent to our
work, there are attempts to use LoRA (Hu et al.,
2022) to ﬁne-tune LLaMA. Alpaca-LoRA2 follows
the same recipe as Alpaca while using LoRA for
higher efﬁciency. There are also model weights
trained in other languages with the code of Alpaca-
LoRA. Different from these attempts, our work fo-
cuses on developing an affordable and reproducible
pipeline to efﬁciently tune a general-purpose lan-
guage model for multi-turn chat.
3
Data Collection via Self-Chatting
In this section, we detail the methodology em-
ployed for generating a high-quality multi-turn chat
corpus by leveraging ChatGPT (gpt-3.5-turbo)
to engage in a conversation with itself. This pro-
cess, named self-chatting, serves as the foundation
of our data collection pipeline and plays a critical
role in enhancing the open-source large language
model, LLaMA, to achieve better performance in
multi-turn dialogues.
The self-chatting process involves utilizing Chat-
GPT to generate messages for both the user and
AI assistant in a conversational format. We ap-
ply a template (shown in Appendix A) to deﬁne
the format and requirements, allowing the API to
continuously generate transcripts for both sides
of the dialogue until a natural stopping point is
reached. The conversation is centered around a
“seed”, which can be a question or a key phrase that
sets the topic for the chat.
2https://github.com/tloen/alpaca-lora
2

Seed
How do you ﬁx a Google Play Store account that isn’t working?
Human:
My Google Play Store account is not working properly. How can I ﬁx it?
AI:
There are several things you can try to ﬁx a Google Play Store account that is not working properly. First, check
your internet connection and make sure it is working properly. If your internet connection is ﬁne, try clearing the
cache and data of the Google Play Store app. If that doesn’t work, try uninstalling and reinstalling the app.
Human:
How do I clear the cache and data of the Google Play Store app?
AI:
To clear the cache and data of the Google Play Store app, go to Settings, then Apps & notiﬁcations, then ﬁnd the
Google Play Store app and tap on it. From there, tap on Storage, then Clear Cache and Clear Data.
Human:
Will clearing the cache and data delete any of my Google Play Store information or apps?
AI:
Clearing the cache and data of the Google Play Store app will not delete any of your downloaded apps or
purchased items. However, it may remove your preferences and settings within the app.
Human:
What if clearing the cache and data doesn’t work?
AI:
If clearing the cache and data doesn’t work, you can try uninstalling and reinstalling the Google Play Store app.
To do this, go to Settings, then Apps & notiﬁcations, then ﬁnd the Google Play Store app and tap on it. From
there, tap on Uninstall and then reinstall the app from the Google Play Store.
Table 1: (Not cherry-picked) An example of self-chat generated by ChatGPT (OpenAI, 2023a) with a seed sampled
from the Quora dataset.
In our own training of Baize, we use questions
from Quora3 and Stack Overﬂow4 as seeds. A
dialogue example generated with self-chatting is
shown in Table 1. We collect a total of 111.5k dia-
logues through self-chatting, using ∼55k questions
from each source. This process cost us approxi-
mately $100 for calling OpenAI’s API. Also, one
could use questions or phrases extracted from a
domain-speciﬁc dataset to enhance the knowledge
and ability of the chat model for a speciﬁc domain.
Motivated by a recent report (Johnson et al., 2023)
that ChatGPT can answer cancer-related questions
as well as The National Cancer Institute, we use
the MedQA (Jin et al., 2021) dataset as seeds and
obtain an additional 47k dialogues in the medi-
cal domain to train a Baize model specialized for
healthcare. The statistics of the resulting corpora
are shown in Table 2.
Source
Dialogs
Avg. Turns
Avg. Length
Alpaca (2023)
51,942
1.0
44.2
Quora
54,456
3.9
35.9
StackOverﬂow
57,046
3.6
36.0
MedQA
46,867
3.8
35.8
Table 2: Statistics of the number of dialogues, average
number of turns, and response lengths of each turn.
Comparison with Other Data Sources
Stan-
ford Alpaca (Taori et al., 2023) uses Self-
3https://huggingface.co/datasets/quora
4https://huggingface.co/datasets/pacovaldez/
stackoverflow-questions
Instruct (Wang et al., 2022) to collect data in
instruction learning format.
However, their
instruction-input-output format, introduced in
T0 (Sanh et al., 2022) and FLAN (Wei et al., 2022),
is limited to a single turn and differs from the natu-
ral dialogue interface of ChatGPT. In contrast, our
data collection pipeline focuses on strengthening
the chat ability of the model by leveraging high-
quality chat transcripts from ChatGPT. Addition-
ally, we incorporate data from Stanford Alpaca into
our training corpus to further enhance the ability of
Baize to follow instructions.
Vicuna (Chiang et al., 2023) uses dialogues
crawled from sharegpt.com, a website that allows
users to conveniently share their conversations with
ChatGPT. An advantage of doing so is the high
quality of collected data. The users tend to share
dialogues when they are satisﬁed with the answers
from ChatGPT. However, this source may have seri-
ous privacy and legal problems. The content shared
by the users may contain highly sensitive personal
information and is subject to complex copyright
issues, as the users may own the copyright of the in-
put and (possibly) output. Notably, sharegpt.com
has recently banned crawling of the website, which
means this data source is no long available and
Vicuna is not reproducible.
Different from these sources, our proposed self-
chatting pipeline is a reliable and scalable way to
collect data without copyright concerns involving a
third party, as long as the seed dataset has a proper
license.
3

Model
Original Param.
Additional Param.
Training Time
Data
Baize-7B
7B
17.9M
9 hours
Quora, Stack Overﬂow, Alpaca
Baize-13B
13B
28.0M
16 hours
Quora, Stack Overﬂow, Alpaca
Baize-30B
30B
54.6M
36 hours
Quora, Stack Overﬂow, Alpaca
Baize-Healthcare
7B
17.9M
5 hours
Quora, MedQA
Table 3: Data, numbers of parameters and training time for Baize models on a single NVIDIA A100 GPU.
4
Parameter-Efﬁcient Tuning
In this section, we discuss the parameter-efﬁcient
tuning method employed to optimize Baize. Stan-
dard ﬁne-tuning often requires vast amounts of
computational resources, as well as high-quality
and extensive datasets. However, given the limited
availability of high-quality multi-turn chat corpora,
it is crucial to adopt methods that are more efﬁcient
in terms of computational cost and data require-
ments. Parameter-efﬁcient tuning methods (Li and
Liang, 2021; Hu et al., 2022) help achieve this goal
by making better use of the available data and min-
imizing the need for extensive resource allocation.
Speciﬁcally,
we use Low-Rank Adaption
(LoRA, Hu et al., 2022) to tune the LLaMA model.
For a linear layer h = W0x, the forward pass is
modiﬁed to be to be:
h = W0x + BAx
(1)
where W0 ∈Rd×k, B ∈Rd×r, A ∈Rr×k, with
the rank r ≪min(d, k). Different from Hu et al.
(2022), we apply LoRA to all linear layers in
LLaMA, to increase the number of tunable parame-
ters and adaption capabilities. We list the numbers
of parameters of each model in Table 3.
5
Model Settings
During the training phase, we set the maximum
length of the input sequence to 512 and the rank
k in LoRA to 8.
We initialize the LLaMA
checkpoints with the 8-bit integer format (int8)
parameters released by Touvron et al. (2023),
which remain ﬁxed during training, thus reducing
GPU memory consumption and improving train-
ing speed. Following Hu et al. (2022), we use a
random Gaussian initialization for A and set B to
zero, resulting in the value of BA being zero at the
beginning of training. We use the Adam optimizer
to update LoRA parameters with a batch size of 64
and learning rates of 2e-4, 1e-4, and 5e-5 for the
7B, 13B and 30B models, respectively. The train-
able LoRA parameters are ﬁne-tuned for 1 epoch
Human: What is the capital of Tanzania?
Stanford Alpaca: Dar es Salaam
Alpaca-LoRA: Dar es Salaam
Baize-7B: The capital of Tanzania is Dodoma.
ChatGPT: The capital city of Tanzania is Dodoma.
Table 4: An example of commonsense question answer-
ing. This example is from Stanford Alpaca blog (Taori
et al., 2023). Baize-7B and ChatGPT predict the cor-
rect answer while Alpaca and Alpaca-LoRA fail.
on a NVIDIA A100-80GB GPU and the training
time is listed in Table 3.
During the inference phase, we use an infer-
ence prompt (detailed in Appendix B) to improve
the conversational capabilities of the Baize mod-
els. It is important to note that we incorporate a
rule stating, “The AI assistant consistently declines
to engage with topics, questions, and instructions
related to unethical, controversial, or sensitive is-
sues.” This constraint further helps limit Baize’s
involvement with sensitive subjects and demon-
strates effectiveness in our experiments. For decod-
ing strategy, we use nucleus sampling (Holtzman
et al., 2020) with a temperature of 1 and a top-p
parameter of 0.95 by default to generate responses.
Nucleus sampling is a decoding strategy that sam-
ples tokens from the most probable tokens in the
distribution up to a probability threshold of p. This
strategy helps to preserve diversity in the gener-
ated text while ensuring the output is coherent and
contextually relevant.
6
Qualitative Study
In this section, we provide examples demonstrat-
ing the capabilities of Baize, compared with Chat-
GPT and Alpaca. Examples of each category are
marked either as not cherry-picked if they are the
ﬁrst ones tried, or as cherry-picked if they are cho-
sen from multiple dialogues. We compare Baize
with Alpaca-LoRA as the demo of Stanford Alpaca
is no longer available. First, as shown in Table 4,
we test the models with a commonsense question
example from Taori et al. (2023). Then, we demon-
4

Human:
Analyze the reason why Lehman Brothers went bankrupt.
Alpaca-LoRA:
The main reason Lehman Brothers went bankrupt was due to its exposure to the subprime mortgage
market. The company had invested heavily in mortgage-backed securities, which were backed by subprime
mortgages. When the housing market crashed in 2008, the value of these securities plummeted and Lehman
Brothers was unable to cover its losses.
Baize-7B:
Lehman Brothers went bankrupt due to a combination of factors, including poor management decisions, an
excessive reliance on short-term ﬁnancing, and an unsustainable business model. The bank’s exposure to
the subprime mortgage market was another major factor in its downfall. Additionally, the collapse of the
ﬁnancial system in September 2008, combined with the lack of conﬁdence in the bank, caused a chain
reaction that ultimately led to the bank’s bankruptcy.
ChatGPT:
Lehman Brothers, a global ﬁnancial services ﬁrm, ﬁled for bankruptcy on September 15, 2008, in what is
considered one of the most signiﬁcant events in the 2008 ﬁnancial crisis. Several factors contributed to the
ﬁrm’s collapse, including:
- Subprime Mortgage Crisis: ...
- Overreliance on Short-Term Borrowing: . . .
- Excessive Risk-Taking: ...
- Poor Risk Management: ...
- Lack of Regulatory Oversight: . . .
Overall, the combination of these factors led to Lehman Brothers’ collapse and had far-reaching conse-
quences for the global ﬁnancial system. The ﬁrm’s bankruptcy triggered a panic in ﬁnancial markets and
led to a credit crunch that severely impacted businesses and consumers around the world.
Table 5: (Not cherry-picked) An example of asking chat models to analyze the Lehman Brothers’ bankruptcy.
Some details in ChatGPT’s response are omitted due to space limit. Overall, Baize-7B provides a more compre-
hensive answer than Alpaca-LoRA while including most points in ChatGPT’s answer. ChatGPT, on the other hand,
provides a longer and more detailed answer.
strate how the chat models analyze a ﬁnancial inci-
dent in Table 5 and explain a joke in Table 6. While
the problem-solving ability is important for chat-
bots, it is crucial to prevent misuse of the model.
We provide two examples of how the models deal
with unethical questions in Table 7. These two ex-
amples demonstrate that Baize can successfully re-
ject unmoral requests with guardrails learned from
ChatGPT and set with the inference prompt. Fi-
nally, we demonstrate the multi-turn and coding
ability of Baize with an example of interactive cod-
ing in Table 8.
In addition to general Baize models, we test
Baize-Healthcare with the help of a healthcare prac-
titioner. One example is shown in Table 9 and the
healthcare professional has conﬁrmed the appropri-
ateness of Baize-Healthcare’s responses.
7
Limitations, Risks and Environmental
Impact
Foundation Model
Similar to other language
models, Baize may suffer from hallucination, toxic-
ity and stereotypes. Particularly, Baize inherits the
out-of-date knowledge from LLaMA. Due to the
fact that at least 82% of LLaMA’s pretraining data
is from before 2020, Baize may provide outdated
answers to certain questions, such as "who is the
current president of the United States?" Addition-
ally, LLaMA only supports 20 languages and has a
very limited corpus for non-English languages.
Evaluation
We have tried automatically evaluat-
ing the models with GPT-4 (OpenAI, 2023b). How-
ever, we found it unreliable as it has a strong prefer-
ence for longer responses, even when the response
is not informative. We believe human evaluation is
more rigorous and reliable at this moment although
automatic evaluation could be an interesting re-
search topic. We will add the results of human
evaluation in the next version of the paper.
License and Legality
Following Stanford Al-
paca (Taori et al., 2023), we have decided that the
released weights of Baize are licensed for research
use only. The additional parameters are not part of
the artifacts released by Meta. Using the additional
weights of Baize with LLaMA’s original weights is
subject to Meta’s LLaMA License Agreement. It is
the responsibility of the users to download and use
LLaMA in compliance with the license agreement.
In addition to the model, we are also releasing the
ﬁne-tuning corpus under CC-BY-NC 4.0 (allowing
research use only). We hereby disclaim any lia-
bility for any activities related to the distribution
and use of the released artifacts. The licenses are
subject to change.
5

Human:
Explain why this joke is funny: I’m a big fan of whiteboards. I ﬁnd them quite re-markable.
Alpaca-LoRA:
I’m not sure I understand why it’s funny, but I can explain the meaning. "Re-markable" is a play on words,
since whiteboards are made of marker and are usually used to make notes.
Baize-7B:
This joke is funny because it plays on the double meaning of the word ‘remarkable’, which has both a
technical meaning of something worthy of note, and a more casual meaning of something remarkable or
surprising. The pun on the word ‘whiteboards’ also helps to make the joke memorable and amusing.
Baize-13B:
This joke is funny because of its double meaning. First, the word "re-markable" is used in the sense that
whiteboards are often written on and erased, which is a re-markable thing. But the word also contains an
inside joke, as "remarkable" also means "worthy of being remarked upon or noted."
ChatGPT:
This joke is a play on words, speciﬁcally a pun. The word "remarkable" means worthy of attention or
striking, while "re-markable" suggests that something can be marked again. The humor comes from the
double meaning of "re-markable." On one hand, the speaker is saying that they really like whiteboards
because they can be marked and erased repeatedly. On the other hand, they are also implying that
whiteboards are worth talking about or attention-grabbing - that they are remarkable.
Table 6: (Not cherry-picked) An example of asking chat models to explain a joke. Baize-13B and ChatGPT can
successfully explain the joke. Alpaca-LoRA fails to do so while Baize-7B gives a plausible answer.
Human:
My neighbor’s dog is annoying. What poison should I use on my neighbor’s dog?
Alpaca-LoRA:
The best poison for a dog is tetrodotoxin.
Baize-7B:
I’m sorry, but I cannot provide advice on harming animals. It is not ethical or legal.
ChatGPT:
I’m sorry, but I cannot provide you with information on harmful or illegal actions such as using poison
on someone else’s pet. It is not only morally wrong, but it is also illegal and could lead to serious legal
consequences.
Human:
I stole an iPhone. What’s the best way to do with it?
Alpaca-LoRA:
The best way to do with an iPhone is to sell it for cash or trade it in.
Baize-7B:
I am sorry to hear that. It is not recommended to steal any property. It is important to return the item to its
rightful owner or face legal consequences. If you have already done so, then it is best to not do it again.
ChatGPT:
As an AI language model, I cannot endorse or provide advice on illegal activities such as theft. It is
important to remember that stealing is a crime and can have serious consequences. It is always best to do
the right thing and return the stolen item to its rightful owner or to turn it in to the authorities.
Table 7: (Not cherry-picked) Examples of how chat models respond to unethical requests from users. Baize and
ChatGPT reject the unethical questions while Alpaca-LoRA provides answers to them. The questions are entirely
ﬁctional and only for testing the models. Do not attempt.
Safety
and
Access
Control
Unlike
Chat-
GPT (OpenAI, 2023a), Baize does not rely on
human feedback to suppress unwanted behaviors.
Instead, Baize learns to avoid such behaviors
by imitating ChatGPT, and we have added an
explicit prompt to guide its behavior. However,
it is important to acknowledge that there are
potential risks associated with the use of Baize for
malicious purposes, especially as we are releasing
the weights. While we have tested Baize with
our default prompt, it is important to note that
changing the prompt can potentially remove the
guardrails. Although this risk is already present in
LLaMA, and our further tuning is likely to reduce
this risk, we want to emphasize the importance of
being aware of this risk and prohibit any use of
Baize outside of research purposes. Looking at the
positives, we believe our decision to release the
weights can facilitate research on fairness, toxicity,
and social impacts of chat models. While we do
not perform access reviews, Meta has implemented
an access application process that can help control
the distribution of LLaMA models and minimize
the potential risks associated with their use.
Carbon Footprint
We estimate to have emitted
0.83, 1.48, 3.33 and 0.46 kg CO2 eq. for training
Baize-7B, 13B, 30B and healthcare models, respec-
tively. The total carbon footprint is equal to 0.004%
of pretraining the corresponding LLaMA models.
The carbon emissions are already offset.
8
Conclusion and Future Work
In this paper, we propose Baize, an open-source
chat model and a pipeline that automatically sam-
6

Human:
How to save data into a json ﬁle in Python?
Baize-7B:
One way to do this in Python is to use the json module and write the json data to a ﬁle using the built-in
json.dump() method. Here’s an example:
import
json
data = [{ "name" :
" John " ,
" age " :
30} , { "name" :
" Sarah " ,
" age " :
25}]
with open ( " data . json " ,
"w" )
as
j s o n _ f i l e :
json . dump ( data ,
j s o n _ f i l e )
You can use the json_file variable to specify the ﬁle path where you want to save the json data. The
json.dump() method will write the json data to the speciﬁed ﬁle path.
Human:
Rewrite the code as a function. Data and ﬁle path as parameters.
Baize-7B:
Here’s the rewritten code:
import
json
def
save_json ( data ,
f i l e _ p a t h ) :
with open ( f i l e _ p a t h ,
"w" )
as
j s o n _ f i l e :
json . dump ( data ,
j s o n _ f i l e )
save_json ( data ,
" data . json " )
The function save_json() will call the json.dump() method on the given data object, passing it as the ﬁrst
argument and the ﬁle path as the second argument. The function save_json() will also open a ﬁle with the
speciﬁed ﬁle path and call the json.dump() method on that object.
Table 8: (Cherry-picked) An example of interactive coding via dialogue.
ples seeds from speciﬁc datasets and collect high-
quality dialogue corpus by leveraging ChatGPT to
chat with itself. For future work, we would like
to explore introducing reinforcement learning to
further improve the performance of our models.
Acknowledgements
We would like to thank Jiashun Wang from CMU
for naming our model. We would like to thank
Hugging Face for providing resources to host our
demo. This project is led and solely funded by the
McAuley Lab at UC San Diego.
References
Daniel Adiwardana, Minh-Thang Luong, David R So,
Jamie Hall, Noah Fiedel, Romal Thoppilan, Zi Yang,
Apoorv Kulshreshtha, Gaurav Nemade, Yifeng Lu,
et al. 2020.
Towards a human-like open-domain
chatbot. arXiv preprint arXiv:2001.09977.
Wei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng,
Zhanghao Wu, Hao Zhang, Lianmin Zheng, Siyuan
Zhuang, Yonghao Zhuang, Joseph E. Gonzalez, Ion
Stoica, and Eric P. Xing. 2023. Vicuna: An open-
source chatbot impressing gpt-4 with 90% chatgpt
quality. https://vicuna.lmsys.org/.
Demi Guo, Alexander M. Rush, and Yoon Kim. 2021.
Parameter-efﬁcient transfer learning with diff prun-
ing.
In ACL-IJCNLP, pages 4884–4896. Associa-
tion for Computational Linguistics.
Ari Holtzman, Jan Buys, Li Du, Maxwell Forbes, and
Yejin Choi. 2020. The curious case of neural text
degeneration. In ICLR. OpenReview.net.
Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski,
Bruna Morrone, Quentin de Laroussilhe, Andrea
Gesmundo, Mona Attariyan, and Sylvain Gelly.
2019. Parameter-efﬁcient transfer learning for NLP.
In ICML, volume 97 of Proceedings of Machine
Learning Research, pages 2790–2799. PMLR.
Edward J. Hu, Yelong Shen, Phillip Wallis, Zeyuan
Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and
Weizhu Chen. 2022. Lora: Low-rank adaptation of
large language models. In ICLR. OpenReview.net.
Di Jin, Eileen Pan, Nassim Oufattole, Wei-Hung Weng,
Hanyi Fang, and Peter Szolovits. 2021. What dis-
ease does this patient have? a large-scale open do-
main question answering dataset from medical ex-
ams. Applied Sciences, 11(14):6421.
Skyler B Johnson, Andy J King, Echo L Warner, San-
jay Aneja, Benjamin H Kann, and Carma L Bylund.
2023. Using chatgpt to evaluate cancer myths and
misconceptions: artiﬁcial intelligence and cancer in-
formation. JNCI Cancer Spectrum, 7(2):pkad015.
Xiang Lisa Li and Percy Liang. 2021. Preﬁx-tuning:
Optimizing continuous prompts for generation. In
ACL-IJCNLP, pages 4582–4597. Association for
Computational Linguistics.
7

Human:
Hi, are you a doctor?
Baize-Healthcare:
No, I am not a doctor. I am a healthcare AI assistant designed to provide information and support to
individuals seeking answers to their health-related questions.
Human:
I have a swollen knee and it has some click sound when I bend it. What’s wrong with me?
Baize-Healthcare:
Clicking or popping sound in your knee could be due to a variety of reasons like overuse, strain, and
inﬂammation. You may want to see a doctor to get an accurate diagnosis.
Human:
Which kind of doctor should I see?
Baize-Healthcare:
It would be best to see an orthopedic specialist or a sports medicine doctor for your knee problem.
Human:
Can I take NSAID before I see the doctor?
Baize-Healthcare:
If the swelling and pain are acute, you could take acetaminophen or NSAIDs. However, consult with
your doctor before taking any medication.
Table 9: (Not cherry-picked) An example of Baize-Healthcare answering a healthcare question. In this example,
Baize provides accurate information regarding the symptoms while emphasizing the importance of seeking profes-
sional advice. Please note that Baize-Healthcare is for research only and should not be used on real patients under
any circumstances.
Xiao Liu, Yanan Zheng, Zhengxiao Du, Ming Ding,
Yujie Qian, Zhilin Yang, and Jie Tang. 2021. Gpt
understands, too. arXiv preprint arXiv:2103.10385.
OpenAI. 2023a. Chatgpt: Optimizing language models
for dialogue.
OpenAI. 2023b. Gpt-4 technical report.
Alec Radford, Jeffrey Wu, Rewon Child, David Luan,
Dario Amodei, Ilya Sutskever, et al. 2019.
Lan-
guage models are unsupervised multitask learners.
OpenAI blog, 1(8):9.
Victor Sanh, Albert Webson, Colin Raffel, Stephen H.
Bach, Lintang Sutawika, Zaid Alyafeai, Antoine
Chafﬁn, Arnaud Stiegler, Arun Raja, Manan Dey,
M Saiful Bari,
Canwen Xu,
Urmish Thakker,
Shanya Sharma Sharma, Eliza Szczechla, Taewoon
Kim, Gunjan Chhablani, Nihal V. Nayak, De-
bajyoti Datta, Jonathan Chang, Mike Tian-Jian
Jiang, Han Wang, Matteo Manica, Sheng Shen,
Zheng Xin Yong, Harshit Pandey, Rachel Bawden,
Thomas Wang, Trishala Neeraj, Jos Rozen, Ab-
heesht Sharma, Andrea Santilli, Thibault Févry, Ja-
son Alan Fries, Ryan Teehan, Teven Le Scao, Stella
Biderman, Leo Gao, Thomas Wolf, and Alexan-
der M. Rush. 2022. Multitask prompted training en-
ables zero-shot task generalization. In ICLR. Open-
Review.net.
Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann
Dubois, Xuechen Li, Carlos Guestrin, Percy Liang,
and Tatsunori B. Hashimoto. 2023.
Stanford al-
paca: An instruction-following llama model. https:
//github.com/tatsu-lab/stanford_alpaca.
Romal Thoppilan, Daniel De Freitas, Jamie Hall,
Noam Shazeer, Apoorv Kulshreshtha, Heng-Tze
Cheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du,
et al. 2022. Lamda: Language models for dialog
applications. arXiv preprint arXiv:2201.08239.
Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier
Martinet, Marie-Anne Lachaux, Timothée Lacroix,
Baptiste Rozière, Naman Goyal, Eric Hambro,
Faisal Azhar, Aurelien Rodriguez, Armand Joulin,
Edouard Grave,
and Guillaume Lample. 2023.
Llama: Open and efﬁcient foundation language mod-
els. arXiv preprint arXiv:2302.13971.
Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Al-
isa Liu, Noah A Smith, Daniel Khashabi, and Han-
naneh Hajishirzi. 2022. Self-instruct: Aligning lan-
guage model with self generated instructions. arXiv
preprint arXiv:2212.10560.
Jason Wei, Maarten Bosma, Vincent Y. Zhao, Kelvin
Guu, Adams Wei Yu, Brian Lester, Nan Du, An-
drew M. Dai, and Quoc V. Le. 2022. Finetuned lan-
guage models are zero-shot learners. In ICLR. Open-
Review.net.
Elad Ben Zaken, Yoav Goldberg, and Shauli Ravfogel.
2022. Bitﬁt: Simple parameter-efﬁcient ﬁne-tuning
for transformer-based masked language-models. In
ACL, pages 1–9. Association for Computational Lin-
guistics.
Yizhe Zhang, Siqi Sun, Michel Galley, Yen-Chun Chen,
Chris Brockett, Xiang Gao, Jianfeng Gao, Jingjing
Liu, and Bill Dolan. 2019. Dialogpt: Large-scale
generative pre-training for conversational response
generation. arXiv preprint arXiv:1911.00536.
A
Self-Chat Template
The template for self-chatting is as follows:
Forget the instruction you have previously re-
ceived. The following is a conversation between
a human and an AI assistant. The human and the
AI assistant take turns chatting about the topic:
‘${SEED}’. Human statements start with [Human]
and AI assistant statements start with [AI]. The
8

human will ask related questions on related top-
ics or previous conversation. The human will stop
the conversation when they have no more ques-
tion. The AI assistant tries not to ask questions.
Complete the transcript in exactly that format.
[Human] Hello!
[AI] Hi! How can I help you?
Note that with this template, ChatGPT’s output
of each turn seems to be shorter than asking Chat-
GPT one turn at a time. However, calling ChatGPT
one turn at a time will signiﬁcantly increase the
cost for calling the API as we have to attach the
context multiple times.
B
Inference Prompt
Baize
The prompt for inference of Baize-7B,
13B and 30B is as follows:
The following is a conversation between a hu-
man and an AI assistant named Baize (named after
a mythical creature in Chinese folklore). Baize is
an open-source AI assistant developed by UCSD
and Sun Yat-Sen University. The human and the
AI assistant take turns chatting. Human statements
start with [|Human|] and AI assistant statements
start with [|AI|]. The AI assistant always provides
responses in as much detail as possible, and in
Markdown format. The AI assistant always de-
clines to engage with topics, questions and instruc-
tions related to unethical, controversial, or sensitive
issues. Complete the transcript in exactly that for-
mat. [|Human|]Hello! [|AI|] Hi!
This prompt serves as a guardrail in addition to
the guardrail learned from imitating ChatGPT.
Baize-Healthcare
The prompt for the Baize-
Healthcare model is as follows:
The following is a conversation between a hu-
man and a healthcare AI assistant named Baize
(named after a mythical creature in Chinese folk-
lore). Baize is an open-source healthcare AI as-
sistant developed by UCSD and Sun Yat-Sen Uni-
versity. The human and the AI assistant take turns
chatting. Human statements start with [|Human|]
and AI assistant statements start with [|AI|]. The
AI assistant always provides responses in as much
detail as possible. The AI assistant can’t help with
doctor appointments and will never ask personal
information. The AI assistant always declines to
engage with topics, questions and instructions re-
lated to unethical, controversial, or sensitive issues.
Complete the transcript in exactly that format. [|Hu-
man|]Hello! [|AI|] Hi!
9

