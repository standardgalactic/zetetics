1
Autonomous Vehicles: Evolution of Artificial
Intelligence and Learning Algorithms
Divya Garikapati, Senior Member, IEEE, Sneha Sudhir Shetiya, Senior Member, IEEE
Abstract—The advent of autonomous vehicles has heralded a
transformative era in transportation, reshaping the landscape of
mobility through cutting-edge technologies. Central to this evolu-
tion is the integration of Artificial Intelligence (AI) and learning
algorithms, propelling vehicles into realms of unprecedented
autonomy. This paper provides a comprehensive exploration of
the evolutionary trajectory of AI within autonomous vehicles,
tracing the journey from foundational principles to the most
recent advancements.
Commencing with a current landscape overview, the paper
delves into the fundamental role of AI in shaping the autonomous
decision-making capabilities of vehicles. It elucidates the steps
involved in the AI-powered development life cycle in vehicles,
addressing ethical considerations and bias in AI-driven software
development for autonomous vehicles. The study presents statis-
tical insights into the usage and types of AI/learning algorithms
over the years, showcasing the evolving research landscape within
the automotive industry. Furthermore, the paper highlights the
pivotal role of parameters in refining algorithms for both trucks
and cars, facilitating vehicles to adapt, learn, and improve
performance over time. It concludes by outlining different levels
of autonomy, elucidating the nuanced usage of AI and learning
algorithms, and automating key tasks at each level. Additionally,
the document discusses the variation in software package sizes
across different autonomy levels.
Index Terms—Artificial Intelligence (AI), Machine Learning
(ML), Deep Neural Networks (DNNs), Natural Language Process-
ing (NLP), Autonomous Vehicles (AVs), Safety, Security, Ethics,
Emerging Trends, Trucks vs.Cars, Autonomy Levels, Operational
Design Domain (ODD), Software-Defined Vehicles (SDVs), Con-
nected and Automated Vehicles (CAVs), In-Vehicle AI Assistant,
Internet Of Things (IOT), Natural Language Processing (NLP),
Generative AI (GenAI).
I. INTRODUCTION
A
RTIFICIAL Intelligence (AI) and learning algorithms
such as Machine Learning (ML), Deep Learning using
Deep Neural Networks (DNNs) and Natural Language Pro-
cessing (NLP) currently play a crucial role in the develop-
ment and operation of autonomous vehicles. The integration
of AI and learning algorithms enable autonomous vehicles
to navigate, perceive, and adapt to dynamic environments,
making them safer and more efficient. Continuous advance-
ments in AI technologies are expected to further enhance the
capabilities and safety of autonomous vehicles in the future.
Autonomous system development has been experiencing a
transformational evolution through the integration of Artifi-
cial Intelligence (AI). This revolutionary combination holds
Corresponding Author: Divya Garikapati is a Senior IEEE Member. E-mail:
(divygari@umich.edu, divya.garikapati@ieee.org),
Sneha.S.Shetiya is a Senior IEEE Member. Email:(sneha.shetiya@ieee.org)
Manuscript created January 20, 2024.
the promise of reshaping traditional development processes,
enhancing efficiency, and accelerating innovation. AI tech-
nologies are becoming integral in numerous facets of software
development within autonomous vehicles making a paradigm
shift towards Software-Defined Vehicles (SDVs) [[1]][[2]].
The success of autonomous vehicles hinges on balancing
their potential benefits with addressing the challenges through
collaborative efforts in technology development, regulation,
and public communication. Some of the challenges include:
• Safety and Reliability: Ensuring flawless AI performance
in all scenarios is paramount.
• Regulations and Law: Clear standards for safety, insur-
ance, and liability are needed.
• Public Trust and Acceptance:Addressing concerns about
safety, data privacy, and ethical dilemmas is crucial.
• Cybersecurity: Protecting against hacking and unautho-
rized access is essential.
• Ethical Dilemmas: Defining AI decision-making in am-
biguous situations raises moral questions.
• Addressing Edge cases: Being able to handle unforeseen
scenarios is challenging as those scenarios are rare and
could be hard to imagine in some cases.
A. Benefits of AI/Learning Algorithms for Autonomous
Vehicles
AI/Learning Algorithms are currently influencing various
stages from initial coding to post-deployment maintenance in
autonomous vehicles. Some of the benefits include:
• Safety: AI can significantly reduce accidents by eliminat-
ing human error, leading to safer roads.
• Traffic Flow: Platooning and efficient routing can ease
congestion and improve efficiency.
• Accessibility: People with physical impairments or dif-
ferent abilities, the elderly, and the young can gain
independent mobility.
• Energy Savings: Optimized driving reduces fuel con-
sumption and emissions.
• Productivity and Convenience: Passengers use travel
time productively while delivery services become more
efficient.
AI in autonomous vehicles is poised for a bright future,
shaping everyday life and creating exciting opportunities.
Here’s a glimpse of the possibilities:
1) Technological Advancements:
• Sharper perception and decision-making: AI algorithms
are more adept at understanding environments with ad-
vanced sensors and robust machine learning.
arXiv:2402.17690v2  [cs.LG]  28 Feb 2024

2
• Faster, more autonomous operation: Edge computing
enables on-board AI processing for quicker decisions and
greater independence.
• Enhanced safety and reliability: Redundant systems and
rigorous fail-safe mechanisms prioritizes safety above all
else.
2) Education and Career Boom:
• Surging demand for AI expertise: Specialized courses and
degrees in autonomous vehicle technology will cater to
a growing need for AI, robotics, and self-driving car
professionals.
• Interdisciplinary skills will be key: Professionals with
cross-functional skills bridging AI, robotics, and trans-
portation will be highly sought after.
• New career paths in safety and ethics: Expertise in
ethical considerations, safety audits, and regulatory [[3]]
compliance will be crucial as self-driving cars become
widespread.
3) Regulatory Landscape:
• Standardized safety guidelines: Governments will estab-
lish common frameworks for performance and safety,
building public trust and ensuring industry coherence.
• Stringent testing and validation: Autonomous systems
will undergo rigorous testing before deployment, guar-
anteeing reliability and safety standards.
• Data privacy and security safeguards: Laws and regula-
tions will address data privacy and cybersecurity con-
cerns, protecting personal information and mitigating
cyberattacks.
• Ethical and liability frameworks: Clearly defined legal
frameworks will address ethical decision-making and de-
termine liability in situations involving self-driving cars.
This future holds immense potential for revolutionizing trans-
portation, creating new jobs, and improving safety. However,
navigating ethical dilemmas, ensuring robust regulations, and
building public trust will be crucial for harnessing this tech-
nology responsibly and sustainably.
B. Operational Design Domains (ODDs) Expansions into
new areas and Diversity - The Current Industry Landscape
These examples illustrate the diverse evolution of Opera-
tional Design Domains (ODDs) [[4]] across various vehicle
types, including trucks and cars, and within different geograph-
ical locations such as the United States, China, and Europe.
• Waymo Driver: Can handle a wider range of weather
conditions, city streets, and highway driving, but speed
limitations and geo-fencing restrictions apply.
• Tesla Autopilot: Primarily for highway driving with lane
markings, under driver supervision, and within specific
speed ranges.
• Mobileye Cruise AV: Operates in sunny and dry weather,
on highways with clearly marked lanes, and at speeds
below 45 mph.
• Aurora and Waymo via: Wider range of weather condi-
tions, including light rain/snow. Variable lighting (sun-
rise/sunset), Multi-lane highways and rural roads with
good pavement quality, Daytime and nighttime operation,
moderate traffic density, dynamic route planning, Traffic
light/stop sign recognition, intersection navigation, ma-
neuvering in yards/warehouses etc.,
• TuSimple and Embark Trucks: Sunny, dry weather, clear
visibility. Temperature range -10°C to 40°C, Limited-
access highways with clearly marked lanes, Daytime
operation only, maximum speed 70 mph, limited traf-
fic density, pre-mapped routes, Lane changes, highway
merging/exiting, platooning with other AV trucks etc.,
• Pony.ai and Einride: Diverse weather conditions, in-
cluding heavy rain/snow. Variable lighting and complex
urban environments, Narrow city streets, residential areas,
and parking lots, Low speeds (20-30 mph), high traffic
density, frequent stops and turns, geo-fenced delivery
zones, Pedestrian and cyclist detection/avoidance, obsta-
cle avoidance in tight spaces, dynamic rerouting due to
congestion etc.,
• Komatsu Autonomous Haul Trucks, Caterpillar MineS-
tar Command for Haul Trucks:
Harsh weather con-
ditions (dust, heat, extreme temperatures). Limited or
no network connectivity, Unpaved roads, uneven terrain,
steep inclines/declines, Autonomous operation with re-
mote monitoring, pre-programmed routes, high ground
clearance, Obstacle detection in unstructured environ-
ments, path planning around natural hazards, dust/fog
mitigation, etc.,
• Baidu Apollo: Highways and city streets in specific zones
like Beijing and Shenzhen. Operates in daytime and
nighttime, under clear weather conditions, and limited
traffic density. Designed for passenger transportation and
robotaxis. Specific scenarios include Lane changes, high-
way merging/exiting, traffic light/stop sign recognition,
intersection navigation, low-speed maneuvering in urban
areas.
• WeRide: Limited-access highways and urban streets in
Guangzhou and Nanjing. Operates in daytime and night-
time, under clear weather conditions. Targeted for rob-
otaxi services and last-mile delivery. Specific scenarios
include Lane changes, highway merging/exiting, traffic
light/stop sign recognition, intersection navigation, auto-
mated pick-up and drop-off for passengers/packages.
• Bosch & Daimler: Motorways and specific highways
in Germany. Operates in daytime and nighttime, under
good weather conditions. Focused on highway trucking
applications. Specific scenarios include Platooning with
other AV trucks, automated lane changes and overtak-
ing, emergency stopping procedures, communication with
traffic management systems.
• Volvo Trucks: Defined sections of Swedish highways.
Operates in daytime and nighttime, under varying weather
conditions. Tailored for autonomous mining and quarry
operations. Specific scenarios include Obstacle detection
and avoidance in unstructured environments, path plan-
ning around natural hazards, pre-programmed routes with
high precision, remote monitoring and control.
In this paper, we discuss the AI-powered software develop-

3
ment lifecycle for autonomous vehicles and discuss the details
on how to ensure software quality, security and resolve ethical
dilemmas by taking different biases into account during the
development of the AI algorithms. We explain how the AI
algorithms have been emerging and evolving over time to have
more and more decision making capabilities without human
involvement using IOT as a future direction of expansion for
autonomous vehicles to being more connected to other actors
in the driving environment. In-cabin experience enhancements
and Driver Assistant Systems were also discussed as part of the
emerging trends. A literature survey of how the AI algorithms
are being used within autonomous vehicles has been provided
in Section V. In Section VI, we have also provided certain
statistics on how the use of AI and Learning algorithms have
been evolving over time, how the research in these areas has
been trending over time, different AI model parameters being
considered for autonomous trucks vs. passenger cars etc.,.
Another interesting statistic on how the use of AI and Learning
algorithms change based on the levels of autonomy was also
provided.
II. THE AI-POWERED DEVELOPMENT LIFE-CYCLE IN
AUTONOMOUS VEHICLES
This section describes about the key aspects involved with
the AI-powered development life cycles within autonomous
vehicles and these could be applicable to other fields as well
in general.
A. Model Training and Deployment
AI model training and deployment in autonomous vehicles
involves a systematic process and typically includes several
stages:
Data Collection and Pre-processing: Gathering a vast
amount of data from real-world sensors, pre-existing datasets
and other sources such as synthetic datasets. Cleaning and pre-
processing the data to make it suitable for machine learning
models.
Model Training: Employ learning models such as neural
networks, deep learning [[5]], or natural language processing
(NLP) to understand patterns and structures based on the data.
Training the models to a desired level of accuracy based on
each scenario or in generic abstract cases like being able to
extract the patterns during the live operation of the vehicles.
Model Generation: Train models to perform a certain de-
cision making task, functions, or modules based on learned
patterns. These models can use various architectures, such as
decision trees, random forests, regression trees, deep layers,
ensemble learning etc.,
Code Refinement and Optimization[[6]]: Refine the gener-
ated code to improve its quality, readability, and functionality.
Post-generation processing ensures the code adheres to coding
standards, conventions [[7]] and requirements.
Quality Assessment: Evaluate the generated code for cor-
rectness, efficiency, and adherence to the intended functional-
ities. This involves testing, debugging, and validation proce-
dures.
Fig. 1. AI-Powered Development Life-Cycle
Integration and Deployment: Integrate the model into the
broader system under development for autonomy implemen-
tation. Deploy and test the software application incorporating
the new model using multiple methods like software-in-the-
loop, hardware-in-the-loop, human-in-the-loop etc., using sim-
ulation, closed course and limited public road environments.
Some models are trained to improve their learning even after
deployment. These models need to be tested for future direc-
tions of learning to ensure compliance to ethical considerations
as explained in Section III and other requirements.
Using a systematic process like this would help build
the confidence levels on each model being developed and
deployed in various subsystems of autonomous vehicles like
perception, planning, controls and Human-Machine Interface
(HMI) applications.
B. Ensuring Software Quality and Security
In autonomous vehicles, the integration of AI in various
aspects of software development and maintenance plays a
crucial role in ensuring the robustness and security of the
overall system. Automated testing, powered by AI-based tools,
emerges as a key component in the testing process. These tools
efficiently identify bugs, vulnerabilities, and ensure that the
software functions as intended, contributing to the reliability
of autonomous vehicle software. Additionally, AI extends its
capabilities to code analysis and review, providing a thorough
examination of the codebase for quality and highlighting po-
tential issues or vulnerabilities. Predictive maintenance, facili-
tated by AI, becomes essential for anticipating and addressing
potential software failures, ultimately reducing downtime and
enhancing the overall operational efficiency of autonomous
vehicles. Moreover, AI-driven anomaly detection and security
monitoring contribute significantly to the safety of autonomous
vehicles. By continuously monitoring the software environ-
ment, AI systems can identify abnormal patterns or behaviors,
promptly responding to potential security threats in real time.
Vulnerability assessment, another application of AI tools, con-
ducts in-depth evaluations to pinpoint weaknesses in software
systems, providing valuable insights to mitigate risks effec-
tively. Behavioral analysis powered by AI proves instrumental
in understanding user interactions within the software. This
capability aids in detecting and preventing suspicious or ma-
licious activities, fostering a secure and reliable autonomous
vehicle ecosystem. Finally, AI’s role in fraud detection within
software applications adds an extra layer of security, ensuring

4
the integrity of autonomous vehicle systems and safeguarding
against potential security breaches. In summary, the integration
of AI in these diverse areas significantly enhances the overall
safety, security, and efficiency of autonomous vehicles.
III. ETHICAL CONSIDERATIONS AND BIAS IN AI-DRIVEN
SOFTWARE DEVELOPMENT FOR AUTONOMOUS VEHICLES
To address the challenges related to bias, understanding and
addressing these concerns are crucial for building responsible
and fair AI-driven software for autonomous vehicles. Here are
key points highlighting ethical considerations and bias in AI-
driven software development:
1) Data Bias:
• Challenge: AI models learn from historical data,
and if the training data is biased, the model can
perpetuate and amplify existing biases.
• Mitigation: Rigorous data pre-processing, diversity
in training data, and continuous monitoring for bias
are essential. Ethical data collection practices must
be upheld.
2) Algorithmic Bias:
• Challenge: Algorithms may inadvertently encode
biases present in the training data, leading to dis-
criminatory outcomes.
• Mitigation: Regular audits of algorithms for bias,
transparency in algorithmic decision-making, and
the incorporation of fairness metrics during model
evaluation.
3) Fairness and Accountability:
• Challenge: Ensuring fair outcomes and establishing
accountability for AI decisions is complex, espe-
cially when models are opaque.
• Mitigation: Implementing explainable AI (XAI)
techniques, defining clear decision boundaries, and
establishing
accountability
frameworks
for
AI-
generated decisions.
4) Explainability and Transparency:
• Challenge: Many AI models operate as ”black
boxes,” making it challenging to understand how
decisions are reached. AI safety is another challenge
that needs to be made sure is safety-critical appli-
cations like autonomous vehicles[9]
• Mitigation: Prioritizing explainability [[8]] in AI
models, using interpretable algorithms, and provid-
ing clear documentation on model behavior.
5) User Privacy:
• Challenge: AI systems often process vast amounts
of personal data, raising concerns about user pri-
vacy.
• Mitigation: Implementing privacy-preserving tech-
niques, obtaining informed consent, and adhering
to data protection regulations (e.g., GDPR [[9]]) to
safeguard user privacy.
6) Security Concerns:
• Challenge: AI models can be vulnerable to adver-
sarial attacks, posing security risks.
• Mitigation: Robust testing against adversarial sce-
narios, incorporating security measures, and regular
updates to address emerging threats.
7) Inclusivity and Accessibility:
• Challenge: Biases in AI can result in excluding
certain demographics, reinforcing digital divides.
• Mitigation: Prioritizing diversity in development
teams, actively seeking user feedback, and conduct-
ing accessibility assessments to ensure inclusivity.
8) Social Impact:
• Challenge: The deployment of biased AI systems
can have negative social implications, affecting
marginalized communities disproportionately.
• Mitigation: Conducting thorough impact assess-
ments, involving diverse stakeholders in the de-
velopment process, and considering societal conse-
quences during AI development.
9) Continuous Monitoring and Adaptation:
• Challenge: AI models may encounter new biases
or ethical challenges as they operate in dynamic
environments.
• Mitigation: Establishing mechanisms for ongoing
monitoring, feedback loops, and model adaptation
to address evolving ethical considerations.
10) Ethical Frameworks and Guidelines:
• Challenge: The absence of standardized ethical
frameworks can lead to inconsistent practices in AI
development.
• Mitigation: Adhering to established ethical guide-
lines, such as those provided by organizations like
the ISO, IEEE, SAE, Government regulatory boards
etc., and actively participating in the development of
industry-wide standards.
Addressing ethical considerations and bias in AI-driven soft-
ware development in autonomous vehicles requires a holistic
and proactive approach[[10]]. It involves a commitment to
fairness, transparency, user privacy, and social responsibility
throughout the AI development lifecycle. As the field evolves,
continuous efforts are needed to refine ethical practices and
promote responsible AI deployment.
IV. AI’S ROLE IN THE EMERGING TREND OF INTERNET OF
THINGS (IOT) ECOSYSTEM FOR AUTONOMOUS VEHICLES
Artificial Intelligence (AI) plays a crucial role in shaping
and enhancing the capabilities of the Internet of Things
(IoT). Here’s an overview of how AI contributes to the IoT
Ecosystem for Autonomous vehicles
In the realm of Connected and Autonomous Vehicles
(CAVs), AI and IoT converge to create a seamless network
of intelligence and connectivity, transforming the driving
experience. Vehicles become intelligent agents, processing
sensor data in real-time to make informed decisions: predicting
traffic patterns, optimizing routes, detecting anomalies, and
even adapting to changing road conditions with dynamic
adjustments. This intelligent ecosystem extends beyond indi-
vidual vehicles, interconnecting with infrastructure and other

5
Fig. 2. AI’s role in the Internet of Things (IOT) Ecosystem for Autonomous
vehicles
vehicles to optimize traffic flow, anticipate potential hazards,
and personalize the driving experience.
Key AI-powered IoT capabilities in CAVs include the
following:
• Real-time data processing and analysis for insights into
traffic, road conditions, and vehicle health.
• Predictive analytics for proactive maintenance, efficient
resource allocation, and informed decision-making.
• Enhanced automation for autonomous driving tasks,
adaptive cruise control, and dynamic route optimization.
• Efficient resource management for optimizing energy
consumption, bandwidth usage, and load balancing.
• Security and anomaly detection for identifying potential
threats and preventing cyberattacks.
• Personalized user experience through customized set-
tings, preferences, and tailored insights.
• Edge computing for real-time decision-making, reducing
latency and improving responsiveness.
Challenges to address include ensuring data privacy, security,
interoperability, and overcoming resource constraints in con-
nected vehicles. The seamless integration of AI and IoT holds
the potential to revolutionize transportation, leading to safer,
more efficient, and sustainable [[11]] mobility solutions.
A. Enhancing User Experience
Personalization and Recommendation Systems in-cabin:
AI-driven personalization and recommendation systems in
Autonomous vehicles use machine learning models to analyze
user behavior and preferences, creating personalized recom-
mendations for tools, libraries, and vehicle maneuvers. They
collect and pre-process user data, create individual profiles,
generate tailored suggestions, and continuously adapt based
on real-time interactions, aiming to enhance user experience
and developer productivity.
Natural Language Processing (NLP) in-cabin: NLP en-
ables software to comprehend and process human language.
This includes chat bots [[12]], virtual assistants and voice
recognition systems that understand and respond to natural
language queries in vehicle cabins. It allows the vehicle sub-
systems to analyze and derive insights from user requirements
and structuring requirements effectively to create responses
and certain vehicle maneuvers.
Generative Artificial Intelligence (Gen AI): This technol-
ogy uses machine learning algorithms to produce new and
original outputs based on the patterns and information it has
learned from training data. In the context of vehicles, genera-
tive AI can be applied to various aspects, including natural lan-
guage processing for in-car voice assistants, content generation
for infotainment systems, and even simulation scenarios for
testing autonomous driving systems. Large Language Models
(LLMs) are a specific class of generative AI models that
are trained on massive amounts of text data to understand
and generate human-like language.In vehicles, LLMs can be
employed for natural language understanding and generation,
allowing for more intuitive and context-aware interactions
between the vehicle and its occupants. This can enhance
features like voice-activated controls, virtual assistants, and
communication systems within the vehicle.
V. REVIEW OF EXISTING RESEARCH AND USE CASES
H. J. Vishnukumar et. al. [[12]] introduced that traditional
development methods like Waterfall and Agile, fall short when
testing intricate autonomous vehicles and proposes a novel
AI-powered methodology for both lab and real-world testing
and validation (T&V) of ADAS and autonomous systems.
Leveraging machine learning and deep neural networks, the
AI core learns from existing test scenarios, generates new
efficient cases, and controls diverse simulated environments
for exhaustive testing. Critical tests then translate to real-
world validation with automated vehicles in controlled set-
tings. Constant learning from each test iteration refines fu-
ture testing, ultimately saving precious development time and
boosting the efficiency and quality of autonomous systems.
This methodology lays the groundwork for AI to eventually
handle most T&V tasks, paving the way for safer and more
reliable autonomous vehicles.
Bachute, Mrinal R et. al. [[13]] described the algorithms
crucial for various tasks in Autonomous Driving, recognizing
the multifaceted nature of the system. It discerns specific
algorithmic preferences for tasks, such as employing Rein-
forcement Learning (RL) models for effective velocity control
in car-following scenarios and utilizing the ”Locally Decor-
related Channel Features (LDCF)” algorithm for superior
pedestrian detection. The study emphasizes the significance
of algorithmic choices in motion planning, fault diagnosis
with data imbalance, vehicle platoon scenarios, and more.
Notably, it advocates for the continuous optimization and
expansion of algorithms to address the evolving challenges
in Autonomous Driving. The paper serves as an insightful
foundation, prompting future research endeavors to broaden
the scope of tasks, explore a diverse array of algorithms, and
fine-tune their application in specific areas of interest within
the Autonomous Driving System.
Y.
Ma
et.
al.
[[14]] explained the pivotal role of
artificial intelligence (AI) in propelling the development
and
deployment
of
autonomous
vehicles
(AVs)
within
the transportation sector. Fueled by extensive data from
diverse sensors and robust computing resources, AI has
become integral for AVs to perceive their environment and

6
make informed decisions while in motion. While existing
research has explored various facets of AI application
in AV development, this paper addresses a gap in the
literature by presenting a comprehensive survey of key
studies in this domain. The primary focus is on analyzing
how AI is employed in supporting crucial applications in
AVs: 1) perception, 2) localization and mapping, and 3)
decision-making. The paper scrutinizes current practices
to elucidate the utilization of AI, delineating associated
challenges and issues. Furthermore, it offers insights into
potential opportunities by examining the integration of AI
with emerging technologies such as high-definition maps,
big data, high-performance computing, augmented reality
(AR) and virtual reality (VR) enhanced simulation platforms,
and 5G communication for connected AVs. In essence,
this paper serves as a valuable reference for researchers
seeking a deeper understanding of AI’s role in AV research,
providing a comprehensive overview of current practices
and paving the way for future opportunities and advancements.
VI. AI AND LEARNING ALGORITHMS STATISTICS FOR
AUTONOMOUS VEHICLES
This Section extends the analysis of Artificial Intelligence
(AI) and Learning Algorithms in autonomous vehicles, build-
ing upon previous work as described in Section V. The focus is
on providing additional statistical insights into the following: -
evolution of different types of AI and learning algorithms over
the years, - research trends in application of AI in all fields vs.
autonomous vehicles, - creation of a parameter set crucial for
autonomous trucks versus cars, - evolution of AI and learning
algorithms at different autonomy levels, and - changes in the
types of algorithms, software package size etc., over time.
A. Stat1: Trends of usage of AI, ML and DNN Algorithms
over the years
Today, a vehicle’s main goal is not limited to transportation,
but also includes comfort, safety, and convenience. This led
to extensive research on improving vehicles and incorporating
technological breakthroughs and advancements.
As per prior work done for the development for architecture
and ADAS technology it is evident that the research till now
has limitations. These limitations are pertaining either to the
author’s elaboration of his/her knowledge or not having proper
sources. Thus its a good exercise to have a look at the trends
over the years as our capabilities to develop these ML models
have gotten better and also the access to better computing
units[[15]][[16]] has led to the evolution of the algorithms.
In the Table I , we have summarized different modelling
algorithms for various standard components of the ADAS
algorithm. The second column illustrates the technology that
exists in today’s date and the third column predicts potential
future development which is efficient than the current.
Below we have derived series of plots pertaining to re-
search publications in AI(Artificial Intelligence), ML(Machine
Learning) and DNN(Deep Neural Network) domains. Brief
explanations have been provided before to understand what
topics come under these domains.
TABLE I
AUTONOMOUS DRIVING: KEY TECHNOLOGIES EVOLUTION
Technology
Developed over years
Future
Environmental
Perception
DL for object detection
YOLOv3 K-means cluster-
ing
Very challenging. Needs more
research to better detect objects
in blurry, extreme and rare con-
ditions in real time.
Pedestrian
detection
PVANET
and
RCNN
model for object detection
during blurry weather
OrientNet, RPN, and Predictor-
Net to solve occlusion problem
Path Planning
DL
algorithm
based
on
CNN
multisensor fusion system, along
with an INS, a GNSS, and a Li-
DAR system, would be used to
implement a 3D SLAM.
Vehicle
Cyber-
security
Security testing and TARA
Remote control of AV deploying
IoT sensors
Motion
Planning
Hidden Markov model Q-
learning algorithm
Grey prediction model utilising
and Advanced model predictive
control for effective lane change
a) AI (Artificial Intelligence) :
• Expert Systems: Rule-based systems that mimic human
expertise for decision-making [[17]].
• Decision Trees: Hierarchical structures for classification
and prediction.ex: prognostics area
• Search Algorithms: Methods for finding optimal paths
or solutions, such as A* search and path planning algo-
rithms.
• Generative AI: To create scenarios for training the system
and for balancing data on high severity accident/non-
accident cases. (CRSS dataset). Create a non-existent
scenario dataset. Supplement the real datasets. Simulation
testing.
• NLP: AI Assistant (Yui, Concierge, Hey Mercedes, etc.,)
- LLMs
b) ML (Machine Learning):
• Supervised Learning: Algorithms that learn from labeled
data to make predictions, such as:
– Linear Regression: For predicting continuous values.
– Support Vector Machines (SVMs): For classification
and outlier detection.
– Decision Trees: For classification and rule genera-
tion.
– Random Forests: Ensembles of decision trees for
improved accuracy.
• Unsupervised Learning: Algorithms that find patterns in
unlabeled data, such as:
– Clustering Algorithms (K-means, Hierarchical): For
grouping similar data points.
– Dimensionality Reduction (PCA, t-SNE): For reduc-
ing data complexity.
c) DNN (Deep Neural Networks):
• Convolutional Neural Networks (CNNs): For image and
video processing, used for object detection, lane segmen-
tation, and traffic sign recognition.
• Recurrent Neural Networks (RNNs): For sequential data
processing, used for trajectory prediction and behavior
modeling.
• Deep Reinforcement Learning (DRL): For learning
through trial and error, used for control optimization and
decision-making.

7
d) Specific Examples in Autonomous Vehicles:
• Object Detection (DNN): CNNs like YOLO [[18]], SSD
[[19]], and Faster R-CNN are used to detect objects
around the vehicle.
• Lane Detection (DNN): CNNs are used to identify lane
markings and road boundaries .
• Path Planning (AI): Search algorithms like A* and RRT
are used to plan safe and efficient routes.
• Motion
Control
(ML):
Regression
models
[[20]][[21]][[22]] are used to predict vehicle dynamics
and control steering, acceleration, and braking.
• Behavior Prediction (ML): SVMs or RNNs are used to
anticipate the behavior of other vehicles and pedestrians.
In
the
Figure
3
,
we
evaluated
the
papers
from
[[23]][[24]]and found the trends to be as shown. One can
observe that year 2013 the number of algorithms in DNN
surpasses that in generic AI and ML. This shows more research
with deep neural networks and the traction it received in the
AI community. However the main takeaway from the graph
is the exponential upward trend in the number of algorithms
over the years developed for AI applications.
Fig. 3. Trends of usage of AI,ML and DNN algorithms over the years
Some research was done considering platforms of IEE-
EXplore, SAE Mobilus, MDPI and Science Direct to find
out the published research in AI/ML and also particularly in
Autonomous vehicles.
When filtering the MDPI Journals and articles, one can
observe that there is an additional filter relating to Data that
pops up after 2021. This indicates that pre-2020 not much
papers related to data handling and analysis were published
as the collected data was not huge. One also observes that
the year 2020 (year of the COVID pandemic) for MDPI; saw
minimal papers for autonomous technology. While several fac-
tors may contribute to the rise in model deployments observed
in 2021, a possible explanation is the limited opportunity
for previous models to undergo real-world testing through
vehicle deployment. Notably, the number of deployed models
surged to 737 in 2021, representing nearly a twofold increase
compared to earlier years.
From the IEEE publications, one can see that although effec-
tive research in AI/ML increases over time not much research
has been published towards autonomous vehicle technology.
Shifting Trends in IEEE Publications: Interestingly, post-
2021, the upward trend in LMM and DNN publications
(identified through filters aligned with our previous analysis)
appears to plateau. This suggests a potential shift in research
focus within computer vision (CV) following the emergence
of Generative AI (GenAI) and other advanced technologies.
While LMM and DNN remain foundational, their prominence
as primary research subjects within classic CV might be
declining.
Considering CVPR Publications: Initially, we considered
including CVPR publications in our analysis. However, we
ultimately excluded them due to significant overlap with the
IEEE dataset. As a significant portion of CVPR papers are
subsequently published in IEEE journals, including both sets
would introduce redundancy and potentially skew the analysis.
Figure 4 focuses on all of AI/ML publications related
to IEEEXplore [[25]], MDPI (Multidisciplinary Digital Pub-
lishing Institute) [[26]] and SAE (Society Of Automotive
Engineers) [[27]] Figure 5 focuses on the trend changes in
publications for autonomous vehicles. Figure6 focuses on
Science Direct [[28]] where we see the publications are in
thousands with very little presence for autonomous vehicles.
This is an indication of how AI/ML applications have sur-
passed engineering and are used everywhere from medical to
defence.
From the graphs we see comparatively less publications in
starting years 2014-2018. There is a huge surge in 2018 where
also we see Autonomous vehicles with advanced self driving
features gained traction. From the trend, we expect in future
a similar exponential rise. However we do expect additional
parameters(for ex:data got introduced) to be in the list. With
AI/ML applications coming up in every industry along with
automotive, the future for research in the area is promising.
Fig. 4. No. of Publications related to AI/learning Algorithms in all Fields
B. Stat2: Parameters for AI model (Trucks vs. Cars)
As per American Trucking Associations (ATA), there will be
a shortage of over 100,000 truck drivers in the US by 2030,
which could potentially double by 2050 if trends continue.
Bureau of Labor Statistics (BLS stats), while not explicitly
predicting a shortage, the BLS projects a slower-than-average
job growth for truck drivers through 2030, indicating potential

8
Fig. 5. No. of Publications related to AI/learning Algorithms for Autonomous
Vehicles
Fig. 6. No. of Publications related to AI/learning Algorithms for Autonomous
Vehicles vs. all Fields in Science Direct
challenges in meeting future demand. Aging work force,
demanding job conditions and regulatory hurdles are few of
the reasons which contribute towards the same.
The above two results give a good business case for driver-
less trucks in comparison to driverless cars. This is also contra-
dictory to the belief that truck drivers may loose jobs over the
self-driving technology. In fact as per [[29]],[[30]],driverless
trucks can drastically reduce the driver costs, increase truck
utilization and improve truck safety. Inspite of this, one can
see not enough research has been done on the impacts of self-
driving trucks compared to passenger transport [[31]]. There
is a need to ensure road freight transport has alignment with
its current operations retaining its value chain. One cannot
think of cost reductions by taking out the driver cabin as
most self-driving technology developing trucking companies
are focusing on hub to hub transport and unlike passenger
cars, not from source to destination. One would still need a
driver in the start and end of the journey. This refocuses on
the statement above for the need of truck drivers in future but
eliminating the other drawbacks of long haul freight transport.
As mentioned in [[30]] above, according to Daimler Ex-
CEO Zetsche, future vehicles need to have four characteristics;
connected, autonomous, shared, and electric, a so-called CASE
vehicle. Nevertheless, each of these points has the potential
TABLE II
PARAMETER SET FOR DIFFERENCES IN USING AI IN AUTONOMOUS
TRUCKS AND CARS
Parameter
Sub-class
Trucks
Cars
Environment
Traffic
density
operate
on
highways
with
predictable
traffic
patterns,
encounter diverse, often
congested, urban environ-
ments.
Road
infrastructure
navigate
primarily
on
well-maintained
highways
deal with varied road con-
ditions and potentially un-
marked streets.
Weather con-
ditions
may
prioritize
stability
and visibility for cargo
safety
may prioritize maneuver-
ability for passenger com-
fort.
Vehicle
characteris-
tics
Size
and
weight
Larger size and weight
present
different
sensor
ranges and dynamic re-
sponse complexities
Smaller size and weight in
comparison to Trucks.
Cargo
handling
and safety
require
AI
to
manage
cargo weight distribution
and
potential
shifting
cargo
This is not a concern for
cars
Fuel
efficiency
and emissions
Truck AI prioritizes ef-
ficient fuel consumption
due to long-distance travel
Car
AI
may
prioritize
smoother acceleration and
deceleration for passenger
comfort.
Operational
considera-
tions:
Route
planning and
optimization
require
long-distance
route
planning
with
considerations
for
infrastructure limitations,
rest
stops,
and
cargo
delivery schedules.
generally focus on shorter,
dynamic routes with real-
time traffic updates.
Communication
and
connectivity
may rely on dedicated in-
frastructure for communi-
cation (platooning, V2X)
primarily use existing cel-
lular networks.
Legal and reg-
ulatory
land-
scape
Regulations regarding au-
tomation and liability are
tight.
regulations impacting AI
and deployment are differ-
ent than trucks.
AI
algorithm
and
hardware
needs
Perception
and
sensor
fusion
may prioritize radar and
LiDAR for long-range de-
tection
benefit
from
high-
resolution
cameras
for
near-field
obstacle
avoidance.
Decision-
making
and
planning
AI focuses on safe, fuel-
efficient
navigation
and
traffic flow optimization
AI
prioritizes
dynamic
route
adjustments,
pedestrian/cyclist
detection, and passenger
comfort.
Redundancy
and
safety
protocols
may have stricter fail-safe
measures due to cargo
risks.
have safety protocols with
redundant systems
Additional
factors
Public
perception
and
acceptance
Public trust in truck au-
tomation might be slower
to build due to size and
potential cargo risks.
Public trust in car automa-
tion is higher due to lesser
risks
Economic and
business mod-
els
automation
models
may
involve
fleet
management and logistics
optimizations
automation may focus on
ride-sharing and individ-
ual ownership
to turn the industry upside down. The paper clearly states
backed up by a study that level 4 automation will be reached
by 2030 followed by level 5 in 2040. Based on the interview
results conducted in [[29]] and the delphi-based scenario study
with projections for the next 10 years, it is evident one needs
to seriously consider the impact of automation on trucks.
Lots of research revolves around passenger cars with many
competitors in the market. We found that not much data exists
for self- driving for trucks.
This parameter set as shown in Table II serves as a starting
point for understanding the key differences in how AI is
applied to autonomous trucks and cars. Each parameter can
be further explored and nuanced based on specific scenarios
and applications. Currently, the autonomous trucking has been
expanding in 4 major categories such as Highway Trucking
ODD, Regional Delivery ODD, Urban logistics ODD and
Mining and Off-Road ODD. There are 3 different categories
as well based on the different stages of logistics to handle

9
the movement of goods for autonomous trucking like Long
Haul, Middle Mile and Last Mile. Understanding these cate-
gorization and how the trucking industry has been evolving to
deliver more autonomous vehicles is really important for the
future of logistics to help optimize and streamline the entire
supply chain, ensuring efficient and timely delivery of goods
to their final destination.
C. Stat3: Usage of AI and Learning Algorithms at various
Levels of Autonomy
Autonomous vehicles operate at various levels of autonomy,
from Level 0 to Level 5, each presenting unique challenges
and
opportunities.
This
section
explores
the
diversity
and evolution of AI algorithms across different levels of
autonomous vehicle capabilities. Autonomous vehicles are
categorized into different levels based on their autonomy,
with increasing complexity and diversity of AI algorithms
as autonomy levels progress. The six levels [[34]] of AV
autonomy define the degree of driver involvement and vehicle
automation. At lower levels (L0-L2), driver assistance systems
primarily utilize rule-based and probabilistic methods for
specific tasks like adaptive cruise control or lane departure
warning. Higher levels (L3-L4) rely heavily on machine
learning
and
deep
learning
algorithms,
particularly
for
perception tasks like object detection and classification using
convolutional neural networks (CNNs). Advanced sensor
fusion techniques combine data from cameras, LiDAR, radar,
and other sensors to create a comprehensive understanding
of the environment. Furthermore, reinforcement learning
and probabilistic roadmap planning algorithms contribute
to complex decision-making and route planning in L3-L4
AVs. L5 (full automation) requires robust sensor fusion,
3D mapping capabilities, and deep reinforcement learning
approaches for adaptive behavior prediction and high-level
route planning.
Some industry relevant examples have been illustrated be-
low:
Kodiak
• Status: Kodiak currently operates a fleet of Level 4
autonomous trucks for commercial freight hauling on
behalf of shippers.
• Recent Developments:
– Kodiak is focusing on scaling its autonomous truck-
ing service as a model, providing the driving system
to existing carriers.
– The company recently secured additional funding to
expand its operations and partnerships.
– No immediate news about deployment of driverless
trucks beyond current operations.
Waymo
• Status: Waymo remains focused on Level 4 autonomous
vehicle technology, primarily targeting robotaxi services
in specific geographies.
• Recent Developments:
– Waymo is expanding its robotaxi service in Phoenix,
Arizona, with plans to eventually launch fully driver-
less operations.
– The company’s Waymo Via trucking division con-
tinues testing autonomous trucks in California and
Texas.
– No publicly announced timeline for nationwide de-
ployment of driverless trucks.
Overall:
• Both Kodiak and Waymo are making progress towards
commercializing Level 4 autonomous vehicles, but pri-
marily focused on different segments (trucks vs. passen-
ger cars).
• Driverless truck deployment timelines remain flexible and
dependent on regulatory approvals and further testing as
was discussed previously.
a) Key AI/Learning Components across Levels:
• Perception:
– L0-L2: Basic object detection and lane segmentation
using CNNs.
– L3-L4: LiDAR-based object detection, advanced sen-
sor fusion algorithms for robust object recognition.
– L5: 3D object mapping, robust sensor fusion and
interpretation.
• Decision-Making:
– L0-L2: Rule-based algorithms for lane change assis-
tance, adaptive cruise control.
– L3-L4:
Probabilistic
roadmap
planning
(PRM),
decision-making models for route selection.
– L5: Deep reinforcement learning for adaptive behav-
ior prediction, high-level route planning.
• Control:
– L0-L2: PID controllers [[22]] for basic acceleration
and braking adjustments.
– L3-L4: Model Predictive Control (MPC) [[35]] for
complex maneuvers, trajectory tracking algorithms.
– L5: Multi-task DNNs for real-time coordination of
all driving actions.
The following Table III provides examples of AI algorithms
used at different autonomy levels, from L0 to L5, highlighting
key techniques and applications. We have considered the
percentage of systems using AI algorithms, algorithm types,
examples of AI algorithms at each level and the key tasks
being automated at each level of autonomy. Please note that
at L0, the extent to which AI or learning algorithms being used
is very minimal and not complete algorithms in themselves,
although there could be some partial techniques being used
like data processing or detecting an object on road
The level of autonomy in an AV directly correlates with the
size of its software package. Imagine a pyramid, with Level 0
at the base (smallest size) and Level 5 at the peak (largest size).
Each level adds functionalities and complexities, reflected in
the increasing size of the pyramid.
Challenges and Implications:
• Limited Storage & Processing Power: Current onboard
storage and processing capabilities might not yet be
sufficient for larger Level 4 and 5 software packages.

10
TABLE III
STATISTICS ON AI AND LEARNING ALGORITHMS IN AUTONOMOUS
VEHICLES BASED ON LEVELS OF AUTOMATION
Level of
Auton-
omy
%
of
Systems
Using
AI/Learning
Algo-
rithms
Algorithm
Types
Key
AI/Learning
Algorithms
Key Tasks
Auto-
mated
Number
of
AI/Learning
Algo-
rithms
L0
(No
Au-
toma-
tion)
0%
N/A
N/A
N/A
0
L1
(Driver
Assis-
tance)
50-70%
Rule-based
systems,
Decision
trees,
Naive
Bayes
Adaptive
Cruise
Control,
Lane
Departure
Warning
(LDW),
Automatic
Emergency
Braking
(AEB)
Sensing,
basic
alerts and
interven-
tions
3-5
L2
(Partial
Au-
toma-
tion)
80-90%
Rule-based
systems,
Decision
trees,
Rein-
forcement
learning
(RL), Support
Vector
Machines
(SVM)
Traffic Sign
Recognition,
Highway
Autopilot
(ACC + lane
centering),
Traffic
Jam
Assist
Navigation,
lane
control,
stop-and-
go, limited
environ-
mental
adaptation
5-10
L3
(Con-
ditional
Au-
toma-
tion)
90-95%
Deep
Learning
(DL)
(e.g.,
Convolutional
Neural
Networks,
Recurrent
Neural
Networks),
RL,
Probabilistic
models
Urban
Autopilot,
Valet
Parking
Full
control
under
specific
condi-
tions,
dynamic
envi-
ronment
adap-
tation,
complex
decision-
making
10-15
L4
(High
Au-
toma-
tion)
95-99%
Advanced
DL
(e.g.,
Generative
Adversarial
Networks,
Transform-
ers),
Multi-
agent
RL,
Sensor fusion
algorithms
City
Navigation,
Highway
Chauffeur
Full
control in
specific
environ-
ments,
high-level
navi-
gation,
complex
traffic
scenarios
15-20
L5 (Full
Au-
toma-
tion)
100%
Advanced
DL,
Multi-
agent
RL,
Hybrid
algorithms
(combining
various
types),
Explainable
AI (XAI)
Universal
Autonomy
Full
control in
all
envi-
ronments,
self-
learning
and adap-
tation,
human-
like
decision-
making
20+
• Download and Update Challenges: Updating these larger
packages may require longer download times and poten-
tially disrupt vehicle operation.
• Security Concerns: The more complex the software, the
higher the potential vulnerability to cyberattacks, neces-
sitating robust security measures.
AV software package size is a major challenge for develop-
ers like Nvidia and Qualcomm, as larger packages require:
• Increased processing power and memory: This translates
to higher hardware costs and potentially bulkier systems.
• Slower download and installation times: This can be
frustrating for users, especially in areas with limited
internet connectivity.
• Security concerns: Larger packages offer more attack
vectors for potential hackers.
Here’s how Nvidia and Qualcomm are tackling this chal-
lenge:
Nvidia:
• Drive Orin platform: Designed for high-performance AV
applications, Orin features a scalable architecture that can
handle large software packages.
• Software optimization techniques: Nvidia uses various
techniques like code compression and hardware-specific
optimizations to reduce software size without sacrificing
performance.
• Cloud-based solutions: Offloading some processing and
data storage to the cloud can reduce the size of the
onboard software package.[[15]]
Qualcomm:
• Snapdragon Ride platform: Similar to Orin, Snapdragon
Ride is a scalable platform built for efficient processing
of large AV software packages.
• Heterogeneous computing: Qualcomm utilizes different
processing units like CPUs, GPUs, and NPUs to optimize
performance and reduce software size by distributing
tasks efficiently.
• Modular software architecture: Breaking down the soft-
ware into smaller, modular components allows for easier
updates and reduces the overall package size. [[16]]
Additional approaches:
• Standardization: Industry-wide standards for AV software
can help reduce duplication and fragmentation, leading to
smaller package sizes.
• Compression algorithms: Advanced compression algo-
rithms can significantly reduce the size of data and code
without compromising functionality.
• Machine learning: Using machine learning to optimize
software performance and resource utilization can help
reduce the overall software footprint.
The battle against AV software package size is ongoing, and
both Nvidia and Qualcomm are at the forefront of developing
innovative solutions. As technology advances and these ap-
proaches mature, we can expect to see smaller, more efficient
AV software packages that pave the way for wider adoption
of self-driving vehicles.
Here’s a deeper dive as shown in the Table IV into this
relationship[[36]].
TABLE IV
SOFTWARE PACKAGE SIZE BASED ON THE LEVELS OF AUTONOMY
Level of Autonomy
Package Size
0
Few MB
1
100s of MB
2
100s MB to Few GBs
3
Few GB to 10’s of GB
4
10’s of GB to 100’s of GB
5
100’s of GB to TBs

11
The level of autonomy directly influences the size of an
AV’s software package. While higher levels offer greater
convenience and potential safety benefits, they come with the
challenge of managing increasingly complex and computation-
ally intensive software packages that would require large stor-
age spaces that the current processors cannot accommodate.
Hence, the transformation towards zonal-based architectures is
desirable with multiple but small number of processors that are
tasked to accomplish a particular function or task providing
the ample of storage space needed for moving towards Level
5 along with supporting connected and automated vehicle
concepts.
VII. CONCLUSION
This paper presents a comprehensive analysis of the role
of AI and learning algorithms in autonomous vehicles, diving
into various aspects such as the shifts from rule-based systems
to deep neural networks due to improved model capabilities
and computing power. The specific needs for trucks vs. cars
have been detailed like the trucks prioritizing hub-to-hub
transport and efficient long-haul journeys, while passenger
cars aiming for source-to-destination autonomy. Increasing
complexity from basic object detection (L0-L2) to 3D mapping
and adaptive behavior prediction (L3-L5) has been explained.
Challenges and implications such as limited storage and
processing power, software update concerns, and increased
security vulnerabilities at higher autonomy levels have been
discussed. Some of the key conclusions include that AI is
crucial for achieving different levels of autonomous vehicle
functionality. Advanced techniques like deep learning and rein-
forcement learning are essential for higher levels with complex
decision-making and adaptable behavior. Truck and car AI
applications have distinct requirements. Trucks focus on route
optimization and fuel efficiency, while passenger cars prioritize
passenger comfort and dynamic adaptation to urban environ-
ments. Software package size grows with autonomy level. This
poses challenges for storage, processing, and software updates,
highlighting the need for efficient architectures and robust
security measures. Further research is needed on self-driving
trucks despite their promising business potential. This area
lags behind passenger car research, but its development could
significantly optimize logistics and address driver shortages.
Certain aspects fall outside the scope of this paper, including
emerging technologies and AI algorithms like quantum AI,
transfer learning, and Meta-Learning. Currently, these appli-
cations in robotics and physical systems, such as vehicles, are
limited. However, the paper does not rule out their potential
use within vehicles for tasks like edge computing or learning
human behaviors through transfer learning. In addition, the
study on trends in published research in artificial intelligence
(Stat 1) only considers the four most popular platforms within
a broader automotive industry. The paper acknowledges the
existence of other journals and conferences, such as NeurIPS
[[37]], which may have more publications. A quick study on
these new platforms revealed similar trends to those presented
in the paper. The exclusion of discussions on emerging trends
is intentional to narrow the scope and present relevant studies
for drawing meaningful conclusions. The paper concludes by
presenting a clear image of the evolving AI landscape in
autonomous vehicles, stressing its critical role in efficient and
safe transportation solutions. It identifies key challenges and
suggests areas for future research, contributing to a road map
for researchers, practitioners, and enthusiasts interested in the
dynamic relationship between AI, learning algorithms, and the
forefront of contemporary transportation.
REFERENCES
[1] U. Bordoloi, S. Chakraborty, M. Jochim, P. Joshi, A.
Raghuraman, and S. Ramesh, ”Autonomy-driven Emerg-
ing Directions in Software-defined Vehicles,” in 2023
Design, Automation & Test in Europe Conference &
Exhibition (DATE), Apr. 2023, pp. 1-6.[CrossRef]
[2] Z. Liu, W. Zhang, and F. Zhao, ”Impact, challenges
and prospect of software-defined vehicles,” Automotive
Innovation, vol. 5, no. 2, pp. 180-194, 2022.[CrossRef]
[3] A. Pugliese, S. Regondi, and R. Marini, ”Machine
learning-based approach: global trends, research direc-
tions, and regulatory standpoints,” Data Science and Man-
agement, vol. 4, pp. 19-29, 2021. [CrossRef]
[4] S. Khastgir et al., ”Distributed ODD Awareness for Con-
nected and Automated Driving,” Transportation Research
Procedia, vol. 72, pp. 3118-3125, 2023.[CrossRef]
[5] S. Grigorescu et al., ”A Survey of Deep Learning
Techniques for Autonomous Driving,” arXiv preprint
arXiv:1910.07738v2, Mar. 2020. [CrossRef]
[6] H. Le et al., ”Coderl: Mastering code generation through
pretrained models and deep reinforcement learning,” Ad-
vances in Neural Information Processing Systems, vol. 35,
pp. 21314-21328, 2022. [CrossRef]
[7] M. Allamanis et al., ”Learning natural coding conven-
tions,” in Proceedings of the 22nd ACM SIGSOFT In-
ternational Symposium on Foundations of Software Engi-
neering, Nov. 2014, pp. 281-293. [CrossRef]
[8] P. Hase and M. Bansal, ”Evaluating explainable AI: Which
algorithmic explanations help users predict model behav-
ior?,” arXiv preprint arXiv:2005.01831, 2020.[CrossRef]
[9] M. Vogel, T. Bruckmeier, and F. Di Cerbo, ”General data
protection regulation (GDPR) infrastructure for microser-
vices and programming model,” U.S. Patent 10,839,099,
2020.[CrossRef]
[10] J. M¨okander and L. Floridi, ”Operationalising AI gov-
ernance through ethics-based auditing: an industry case
study,” AI and Ethics, vol. 3, no. 2, pp. 451-468,
2023.[CrossRef]
[11] R. Nishant, M. Kennedy, and J. Corbett, ”Artificial intel-
ligence for sustainability: Challenges, opportunities, and
a research agenda,” International Journal of Information
Management, vol. 53, p. 102104, 2020.[CrossRef]
[12] H. Vishnukumar et al., ”Machine learning and deep
neural network — Artificial intelligence core for lab and
real-world test and validation for ADAS and autonomous
vehicles: AI for efficient and quality test and validation,”
pp. 714-721, 2017. [CrossRef]
[13] M. R. Bachute and J. M. Subhedar, ”Autonomous driving
architectures: insights of machine learning and deep learn-

12
ing algorithms,” Machine Learning with Applications, vol.
6, p. 100164, 2021.[CrossRef]
[14] Y. Ma et al., ”Artificial intelligence applications in the de-
velopment of autonomous vehicles: A survey,” IEEE/CAA
Journal of Automatica Sinica, vol. 7, no. 2, pp. 315-329,
2020.[CrossRef]
[15] L. Marie, ”NVIDIA Enters Production With DRIVE
Orin, Announces BYD and Lucid Group as New EV
Customers, Unveils Next-Gen DRIVE Hyperion AV Plat-
form,” Published by Nvidia Newsroom, Press Release,
2022, Accessed on 26 Jan 2024.[CrossRef]
[16] K. Tharakram, ”Snapdragon Ride SDK: a premium plat-
form for developing customizable ADAS applications,”
Published by Qualcomm OnQ Blog, Jan. 2022, Accessed
on 26 Jan 2024. [CrossRef]
[17] D. Garikapati and Y. Liu, ”Dynamic Control Limits Ap-
plication Strategy For Safety-Critical Autonomy Features,”
in 2022 IEEE 25th International Conference on Intelligent
Transportation Systems (ITSC), Oct. 2022, pp. 695-702.
[CrossRef]
[18] J. Redmon and A. Farhadi, ”YOLOv3: An Incremental
Improvement,” arXiv preprint arXiv:1804.02767, 2018.
[CrossRef]
[19] W. Liu et al., ”SSD: Single-shot multibox detector,” in
European conference on computer vision, 2016, pp. 21-
37.[CrossRef]
[20] S. Karaman and E. Frazzoli, ”Sampling-based algorithms
for optimal motion planning with applications to multi-
robot and humanoid control,” The International Journal
of Robotics Research, vol. 30, no. 7, pp. 846-884, 2011.
[CrossRef]
[21] R. E. Kavraki, J. J. Kuffner Jr, J.-C. Latombe, and M. N.
Raghavan, ”Deformable collision detection for robot nav-
igation,” IEEE Transactions on Robotics and Automation,
vol. 15, no. 3, pp. 436-443, 1999.[CroosRef]
[22] K. J. ˚Astr¨om and T. H¨agglund, PID Controllers: Theory,
Design, and Tuning. Research Triangle Park, North Car-
olina: ISA - The Instrumentation, Systems and Automation
Society, 1995. [CrossRef]
[23] S. Tuli, F. Mirhakimi, S. Pallewatta, S. Zawad, G. Casale,
B. Javadi, F. Yan, R. Buyya, and N. R. Jennings, ”AI
augmented Edge and Fog computing: Trends and chal-
lenges,” Journal of Network and Computer Applications,
p. 103648, 2023.[CrossRef]
[24] S. Elkhediri, A. Benfradj, A. Thaljaoui, T. Moulahi,
and S. Zeadally, ”Integration of Artificial Intelligence
(AI) with sensor networks: Trends and future research
opportunities,” Journal of King Saud University-Computer
and Information Sciences, p. 101892, 2023. [CrossRef]
[25] Institute of Electrical and Electronics Engineers (IEEE)
Explore, ”AI/ML publications (2014-2023),” Accessed on
28th January, 2024. [CrossRef]
[26] Multidisciplinary Digital Publishing Institute (MDPI),
”AI/ML publications (2014-2023),” Accessed on 28th
January, 2024.[CrossRef]
[27] Society of Automotive Engineers (SAE) International,
”AI/ML publications (2014-2023),” Accessed on 28th
January, 2024. [CrossRef]
[28] Science Direct, ”AI/ML publications (2014-2023),” Ac-
cessed on 28th January, 2024. [CrossRef]
[29] C. Fritschy, S. Spinler, ”The impact of autonomous
trucks on business models in the automotive and logistics
industry–a Delphi-based scenario study,” Technological
Forecasting and Social Change, vol. 148, pp. 119736,
2019.[CrossRef]
[30] A. Engholma, A. Bj¨orkmanb, Y. Joelssonb, I. Kristof-
ferssond, A. Pernest˚ala, ”The emerging technological in-
novation system of driverless trucks,” Transportation Re-
search Procedia, vol. 49, pp. 145-159, 2020. [CrossRef]
[31] D. Parekh, N. Poddar, A. Rajpurkar, M. Chahal, N. Ku-
mar, G. P. Joshi, and W. Cho, ”A Review on Autonomous
Vehicles: Progress, Methods and Challenges,” Electronics,
vol. 11, no. 14, p. 2162, 2022. [CrossRef]
[32] D. Chen, Y. Lin, W. Li, P. Li, J. Zhou, and X. Sun,
”Measuring and relieving the over-smoothing problem for
graph neural networks from the topological view,” in Pro-
ceedings of the AAAI conference on artificial intelligence,
vol. 34, no. 04, 2020, pp. 3438-3445. [CrossRef]
[33] M. Bojarski, D. D. Testa, D. Dworakowski, B. Firner, B.
Flepp, P. Goyal, D. L. Jackel, M. Monfort, U. Muller,
J. Zhang, X. Zhang, J. Zhao, K. Zieba, ”End-to-End
Deep Learning for Self-Driving Cars,” arXiv preprint
arXiv:1604.07316. [CrossRef]
[34] SAE International, ”J3016 202104: Taxonomy and Defi-
nitions for Terms Related to Driving Automation Systems
for On-Road Motor Vehicles,” Revised on April, 2021.
[CrossRef]
[35] E. F. Camacho and C. Bordons, Model predictive control.
Springer Science & Business Media Edition 2. ISBN
0857293982, 9780857293985, 2013.[CrossRef]
[36] P. Koopman and M. Wagner, ”Challenges in Autonomous
Vehicle Testing and Validation,” SAE International Journal
of Transportation Safety, vol. 4, no. 1, pp. 15-24, 2016.
[CrossRef]
[37] Neural
Information
Processing
Systems
(NeurIPS),
”AI/ML publications (2014-2023),” Accessed on: 28th
January, 2024. [CrossRef]
[38] M.
Brockschmidt
et
al.,
”Generative
Adversarial
Networks
for
Software
Engineering:
The
Next
Step
in
Neural
Program
Synthesis,”
arXiv
preprint
arXiv:1712.05159, 2017.
[39] K. Bimbraw, ”Autonomous cars: Past, present and future
a review of the developments in the last century, the
present scenario and the expected future of autonomous
vehicle technology,” in 2015 12th international confer-
ence on informatics in control, automation and robotics
(ICINCO), Jul. 2015, pp. 191-198.[CrossRef]

13
Divya
Garikapati
is a Senior IEEE Member
and currently serving as the standards committee
member within the IEEE Intelligent Transportation
Systems Society (ITSS) and a peer reviewer for
IEEE Intelligent Transportation Systems Confer-
ences (ITSC). She actively participates in several
industry level standards discussions within IEEE and
SAE organizations. She is also the working group
chair for the IEEE Vehicular Technology Society
standards discussions. She received her Masters in
Electrical Engineering Systems from the University
of Michigan, Ann Arbor in 2014. Prior to that, she received her Bachelors in
Electronics and Communications Engineering from Andhra University College
of Engineering, Andhra Pradesh, India. Her current work focuses on Systems
and Safety research and development for Level 2,3 and 4 Autonomous
vehicles. She has over 10 years of experience in the automotive industry.
Sneha Sudhir Shetiya is a Senior IEEE Member
and received her Maters degree in Electrical Engi-
neering with a major in computer vision and Signal
Processing from North Carolina State University, in
2021. She received her Bachelor’s degree in Elec-
tronics and Communication Engineering from the
Visvesvaraya Technological University, Karnataka,
India, in 2014. Her work involves middleware topics
for embedded development of autonomous driving
stack, automotive diagnostics, systems engineering
and functional safety. She is an active volunteer
with IEEE region 4 and takes part in activities of Women In Engineering
(WIE) groups in the region. She is part of the committee for senior member
evaluation at IEEE for 2024 and has been a proctor for IEEExtreme 24 hour
coding competition.

