Multistability and Perceptual Inference
The MIT Faculty has made this article openly available. Please share 
how this access benefits you. Your story matters.
Citation
Gershman, Samuel J., Edward Vul, and Joshua B. Tenenbaum.
“Multistability and Perceptual Inference.” Neural Computation 24.1
(2012): 1–24. Web.© 2012 Massachusetts Institute of Technology.
As Published
http://dx.doi.org/10.1162/NECO_a_00226
Publisher
MIT Press
Version
Final published version
Citable link
http://hdl.handle.net/1721.1/70125
Terms of Use
Article is made available in accordance with the publisher's
policy and may be subject to US copyright law. Please refer to the
publisher's site for terms of use.

ARTICLE
Communicated by Nando de Freitas
Multistability and Perceptual Inference
Samuel J. Gershman
sjgershm@princeton.edu
Department of Psychology and Neuroscience Institute, Princeton University,
Princeton, NJ, U.S.A.
Edward Vul
evul@ucsd.edu
Department of Psychology, University of California, San Diego, CA 92093, U.S.A.
Joshua B. Tenenbaum
jbt@mit.edu
Department of Brain and Cognitive Sciences, MIT, Cambridge, MA 02139, U.S.A.
Ambiguous images present a challenge to the visual system: How can un-
certainty about the causes of visual inputs be represented when there are
multiple equally plausible causes? A Bayesian ideal observer should rep-
resent uncertainty in the form of a posterior probability distribution over
causes. However, in many real-world situations, computing this distribu-
tion is intractable and requires some form of approximation. We argue
that the visual system approximates the posterior over underlying causes
with a set of samples and that this approximation strategy produces per-
ceptual multistability—stochastic alternation between percepts in con-
sciousness. Under our analysis, multistability arises from a dynamic
sample-generating process that explores the posterior through stochas-
tic diffusion, implementing a rational form of approximate Bayesian in-
ference known as Markov chain Monte Carlo (MCMC). We examine in
detail the most extensively studied form of multistability, binocular ri-
valry, showing how a variety of experimental phenomena—gamma-like
stochastic switching, patchy percepts, fusion, and traveling waves—can
be understood in terms of MCMC sampling over simple graphical mod-
els of the underlying perceptual tasks. We conjecture that the stochastic
nature of spiking neurons may lend itself to implementing sample-based
posterior approximations in the brain.
1 Introduction
We perceive the world through our senses, but any stream of sense
data is a fundamentally impoverished source of information about the
external world. To take the most familiar example, retinal images are
Neural Computation 24, 1–24 (2012)
c⃝2011 Massachusetts Institute of Technology

2
S. Gershman, E. Vul, and J. Tenenbaum
two-dimensional, while the external world is three-dimensional. Our brains
must go beyond what is directly available in the sensory data through a pro-
cess of interpretation to achieve the rich percepts of conscious awareness.
Bayesian statistics has provided a powerful framework for understanding
this inferential process (Knill & Richards, 1996); its central postulate is that
percepts represent hypotheses about the external world whose degree of
belief (the posterior probability) is determined by a combination of sensory
evidence (the likelihood) and background assumptions about a priori plau-
sible world structures (the prior). Numerous experiments have conﬁrmed
the explanatory reach of Bayesian models in perception as well as cognition,
motor control, and other areas of brain function (Brainard & Freeman, 1997;
Weiss, Simoncelli, & Adelson, 2002; Kording & Wolpert, 2004; Grifﬁths &
Tenenbaum, 2006). Computer vision and artiﬁcial intelligence researchers
have shown how Bayesian inference operating over networks of random
variables known as probabilistic graphical models can solve many real-
world perceptual inference and higher-level reasoning tasks (Geman &
Geman, 1984; Koller & Friedman, 2009). Computational neuroscientists
have formulated hypotheses about how populations of neurons can en-
code, transform, and decode posterior distributions (Knill & Pouget,
2004).
Despite these successes arguing for a unifying Bayesian view of the brain,
a major computational obstacle remains: Bayesian inference in large-scale
graphical models needed to capture real-world perceptual tasks is compu-
tationally intractable. Posterior degrees of belief in these models cannot,
in general, be calculated exactly by any resource-limited computational
device. Bayesian statisticians and researchers in computer vision and arti-
ﬁcial intelligence (AI) routinely use a range of approaches and algorithms
for approximating ideal Bayesian inference in graphical models (Koller &
Friedman, 2009). Thus, Bayesian theories of perceptual inference remain
incomplete until they can explain how the brain approximates posterior
inference effectively and quickly.
Early Bayesian models of human perception proposed that instead of
calculating the full posterior distribution, the brain ﬁnds only the point
estimate with highest posterior probability (the maximum a posteriori, or
MAP, estimate). Although MAP estimation provides a remarkably good
account of many experimental phenomena (Schrater & Kersten, 2000; Weiss
et al., 2002), it is not sufﬁcient to account for human behavior. Not only is
MAP estimation suboptimal because it fails to represent uncertainty about
perceptual interpretations, but more important, it can not account for recent
evidence that humans and other animals represent their uncertainty in
perceptual tasks (Grinband, Hirsch, & Ferrera, 2006; Kiani & Shadlen, 2009).
Thus, we must consider alternative approximate inference strategies the
brain might adopt.
Here we argue that perceptual multistability—alternation between
conscious percepts in response to ambiguous sensory inputs (Blake &

Multistability and Perceptual Inference
3
Logothetis, 2002)—provides both qualitative and quantitative evidence for
a different and more powerful approach to approximate Bayesian inference
in the brain, which can be formalized in terms of algorithms from Bayesian
statistics, computer vision, and AI. Speciﬁcally, we show how perceptual
multistability can be naturally explained as a consequence of Monte Carlo
inference, approximating Bayesian posterior distributions with a set of sam-
ples (Robert & Casella, 2004). An emerging literature suggests that Monte
Carlo approximations might be employed in human (Sanborn, Grifﬁths,
& Navarro, 2006; Levy, Reali, & Grifﬁths, 2009; Vul, Goodman, Grifﬁths,
& Tenenbaum, 2009) and animal (Daw & Courville, 2007) cognition, and
several authors have proposed that the spiking activity of neurons might
be interpreted as a set of samples (Hoyer & Hyv¨arinen, 2003; Lee & Mum-
ford, 2003; Shi & Grifﬁths, 2009; Fiser, Berkes, Orb´an, & Lengyel, 2010).
We suggest that Markov chain Monte Carlo (MCMC) methods are partic-
ularly well suited to modeling perceptual multistability. These methods
provide state-of-the-art engineering performance on the large-scale graphi-
cal models needed in computer vision. Moreover, when MCMC algorithms
are applied to graphical models, they produce spatiotemporal dynamics
in inference that correspond to experimentally observed phenomena of
multistability, as we explore below. Prior work has argued that stochas-
tic sampling produces perceptual multistability (Schrater & Sundareswara,
2007; Sundareswara & Schrater, 2008) in the case of the Necker cube. We
go beyond this work by showing that a rational MCMC algorithm for ap-
proximate Bayesian inference in graphical models produces a broad range
of perceptual multistability phenomena while approximating a rational so-
lution to a real vision problem: inferring the correct image interpretation
from noisy binocular inputs.
We focus on the most extensively studied form of perceptual multi-
stability, binocular rivalry, in which incompatible images (e.g., orthogonal
gratings) are presented dichoptically to the eyes. Under most (but not all)
conditions, this results in a percept that switches stochastically between
the two images (see Blake, 2001, for a review). We ﬁrst formulate a sim-
ple graphical model for retinal images, such that inference in this model
using Bayes’s rule recovers the latent scene underlying sensory inputs.
We then show how approximate Bayesian inference in this model using
MCMC can reproduce a variety of psychophysical phenomena. Finally, we
discuss the connections between MCMC computations and possible neural
implementations.
Our model is at present a caricature of the visual processing pathway
that gives rise to multistable perception, and binocular rivalry in particular.
We have endeavored to simulate only a handful of the numerous phenom-
ena for which quite sophisticated and neurally realistic models have been
developed (Laing & Chow, 2002; Freeman, 2005; Moreno-Bote, Rinzel, &
Rubin, 2007; Noest, van Ee, Nijs, & Van Wezel, 2007; Wilson, 2007). Our
goal in this article is not to supplant the existing theoretical work but rather

4
S. Gershman, E. Vul, and J. Tenenbaum
Latent image
Outlier process
Renal image
Figure 1: Generative model. Schematic illustrating the probabilistic process by
which retinal images are generated. Shaded nodes denote observed variables;
unshaded nodes denote unobserved (latent) variables. Arrows denote causal
dependencies.
to supplement it by providing a normative statistical motivation for the
dynamical processes posited by these models. We believe these ideas are
best illustrated in a simpliﬁed setting, in which their mechanistic principles
are relatively transparent. The idea of sampling over a graphical model
structure is very general and can be applied to more sophisticated versions
of the model we present.
2 A Probabilistic Model of Binocular Rivalry
Our starting point is a probabilistic generative model of retinal images
that represents the brain’s assumptions about how its sensory inputs were
generated (see Figure 1). Formally, this model is a variant of a Markov Ran-
dom Field (MRF), one of the most standard forms of probabilistic graphical
model used in computer vision (Geman & Geman, 1984). In the appendix,
we describe this model mathematically, but here we focus on the basic in-
tuitions behind this model. The model posits two sets of latent variables:
a latent scene and an eye-speciﬁc outlier process that governs whether a
given patch of retina observes the latent scene. The goal of the visual system
is to infer the underlying image given the observed retinal input.
We represent the latent scene and the two retinal images as arrays of
luminance values (e.g., a 32 × 32 grayscale pixel image), while the outlier
processes are represented as binary arrays of the same size. The luminance
values for the pixels in each eye are the noise-perturbed luminance of the

Multistability and Perceptual Inference
5
corresponding pixels of the scene. However, if a pixel from one eye is
deemed to be an outlier, then the luminance at that pixel is meaningless and
contains no information with respect to the scene. As we discuss below, this
scene representation is admittedly highly simpliﬁed, but it is adequate for
our goal of studying the dynamics of inference in multistable perception
rather than scene perception per se.
This outlier process allows the possibility that sometimes the retinal
signal does not correspond to the scene at all—for instance, if an occluder
blocks a portion of one eye’s ﬁeld of view (Shimojo & Nakayama, 1990) or
if a portion of the cornea or retina of one eye is damaged. Thus, the outlier
process captures the notion that if, for one of these reasons, a portion of the
retinal image does not correspond to the scene, it should simply be ignored
(suppressed). This aspect of our model allows the two retinal images to
compete in rivalry for representation in the inferred scene: if the two eyes
see conﬂicting images, at least one of them must not represent the actual
scene present in the world.
The psychological and neural plausibility of the outlier process is mo-
tivated by evidence that suppression during binocular rivalry is accompa-
nied by a general loss in visual sensitivity (Blake, 2001). For example, target
detection performance is lower (Wales & Fox, 1970; Fukuda, 1981) and re-
action times are longer (Fox & Check, 1968; O’Shea, 1987) for probe stimuli
presented to the suppressed eye compared to probe stimuli presented to
the dominant eye. Moreover, single-unit recordings (Leopold & Logothetis,
1996) and functional magnetic resonance imaging (fMRI) studies (Polonsky,
Blake, Braun, & Heeger, 2000) have demonstrated inhibition of responses in
primary visual cortex during suppression periods. These ﬁndings indicate
that the visual system is engaged not only in inferring the latent causes of its
sensory inputs, but also inferring the reliability of its measurement devices.
Crucially, this outlier process is spatially smooth, so that two adjacent
pixels are more likely to have the same outlier status. This corresponds to
the idea that if a given portion of retina is not receiving a signal correspond-
ing to the scene, its neighbors are also not likely to represent the scene,
since occlusion, macular degeneration, retinitis pigmentosa, cataracts, or
something else disrupts the ﬁeld of view in a spatially smooth manner.
Thus far, we have described a probabilistic graphical model designed to
infer the luminance value of each pixel of an underlying two-dimensional la-
tent scene independently. However, the visual system has a much more am-
bitious goal: inferring a complete, semantically coherent, three-dimensional
latent scene. A full generative model of the scenes that the visual system
considers would involve many complex constraints and incompletely un-
derstood assumptions; developing such a model would be hard to do with-
out a complete account of human vision and visual cognition. Instead, as
a proxy for such a rich model, we assume an image-like scene represen-
tation with luminance values that correspond to some combination of the
luminance values of the real images that comprise the stimulus and that the

6
S. Gershman, E. Vul, and J. Tenenbaum
degree to which pixels correspond to one stimulus or another is spatially
smooth. This smooth “latent image” prior is a simple way to encode the
idea of spatially organized semantic coherence in the inferred latent scene.
Speciﬁcally, we approximate a rich hypothesis space of latent images
without having to specify a complete distribution over natural images,
by assuming that each latent scene pixel sn is a linear combination of the
corresponding real images pixels (xL
n and xR
n) in the stimulus: sn = wnxL
n +
(1 −wn)xR
n, where wn can theoretically range over the entire real line and is
assumed to be spatially smooth. This can be understood as an “empirical”
approximation to the distribution over natural images, using only linear
combinations of the observed images. In practice, this heuristic will work
nearly as well, since the posterior distribution will be strongly concentrated
around the two retinal images.
3 Approximate Inference by Sampling
Given an observed pair of retinal images, Bayes’s rule can be used to invert
the generative model and recover the latent scene:
P(s|x) = 1
ZP(s)

π
P(x|s, π)P(π),
(3.1)
where Z is a normalizing constant and π denotes the outlier process. Because
it is generally intractable to calculate the normalizing constant, approxima-
tions must be considered. Monte Carlo methods (Robert & Casella, 2004)
approximate the posterior with a set of M samples:
P(s|x) ≈1
M
M

m=1
δ

s(m), s

,
(3.2)
where δ[·, ·] is the Kronecker delta function whose value is 1 when its argu-
ments are equal, and 0 otherwise. The challenge is to draw samples from
the posterior; in most cases, the posterior cannot be sampled from directly.
The key idea behind MCMC methods is that a sequence of distributions
(comprising a Markov chain) can be constructed that eventually converges
to the posterior. This means that after a burn-in period, samples from this
Markov chain will be distributed according to the posterior. Gibbs sam-
pling (Geman & Geman, 1984), perhaps the best-known MCMC method,
was originally developed for MRFs similar to our model. It proceeds by
performing sweeps over the latent variables (scene and outlier nodes), sam-
pling each variable from its conditional distribution while holding all the
other variables ﬁxed (see the appendix for details). In our implementation,
the order in which nodes are updated in each sweep is randomized. Due to
the topology of the MRF, each conditional distribution depends on only a

Multistability and Perceptual Inference
7
subset of the latent variables (see the appendix), and hence Gibbs sampling
can be done using only information that is local to each latent variable.
4 Results
We now illustrate the behavior of our sampling model using several key
paradigms from the binocular rivalry literature. Our goal is to highlight
the conceptual principle underlying our explanation of multistable percep-
tion: stochastic perceptual dynamics arise from approximate inference in
a graphical model of visual inputs. Details about parameter selection and
robustness can be found in the appendix.
4.1 Dynamics of Perceptual Switches. In a typical binocular rivalry
experiment, subjects are asked to say which of two images corresponds to
their global percept. To make the same query of the current state of our
simulated Markov chain, we deﬁned a perceptual switch to occur when
at least 9/10 of the scene nodes take on the same value. Figure 2A shows
a sample time course. It may seem surprising that the model spends rel-
atively little time near the extremes and that switches are fairly gradual.
This phenomenonology is consistent with several experiments showing
that substantial time is spent in transition periods (Mueller & Blake, 1989;
Brascamp, van Ee, Noest, Jacobs, & van den Berg, 2006; Kang, 2009).
One of the most robust ﬁndings in the literature on binocular rivalry
is that switching times between different stable percepts tend to follow
a gamma-like distribution (Blake, 2001). In other words, the dominance
durations of stability in one mode tend to be neither overwhelmingly short
nor long. Figure 2B shows the histogram of dominance durations and the
maximum-likelihood ﬁt of a gamma distribution to our simulations and
real data, demonstrating that the durations produced by MCMC are well
described by a gamma distribution.
To account for this gamma-like switching behavior, many papers have
described neural circuits that could produce switching oscillations with
the right stochastic dynamics by suggesting a competition between mu-
tual inhibition and adaptation (Moreno-Bote et al., 2007; Wilson, 2007).
Similarly, existing rational process models of multistability (Dayan, 1998;
Schrater & Sundareswara, 2007; Sundareswara & Schrater, 2008) add spe-
ciﬁc adaptation- or memory-like constraints to produce this effect. In our
model, these additional memory constraints are unnecessary because the
spatial coupling of adjacent nodes in the latent scene creates a form of
memory in the inference.
The gamma distribution arises in MCMC on an MRF because each hid-
den node takes an approximately exponentially distributed amount of time
to switch, but these switches must co-occur in sequence. So the total amount
of time until enough nodes switch to one mode will be the sum of exponen-
tial random variables, or a gamma distribution. Thus, gamma-distributed

8
S. Gershman, E. Vul, and J. Tenenbaum
50
100
150
200
250
300
350
400
5
10
15
20
25
Time
Perceptual state
A
0
0.5
1
1.5
2
2.5
0
0.5
1
Dominance duration
Probability
B
α=1.44
β=0.69
Simulated
Empirical
Figure 2: Perceptual switching dynamics. (A) Simulated time course of bista-
bility. Plotted on the y-axis is the number of nodes with value greater than 0.5.
The horizontal lines show the thresholds for a perceptual switch. (B) Distribu-
tion of simulated dominance durations (mean-normalized) for MRF with lattice
topology. Curves show gamma distributions ﬁtted to simulated (with parame-
ter values shown on the right) and empirical data, replotted from Mamassian
and Goutcher (2005).
dominance durations fall naturally out of MCMC operating on a spatially
smooth MRF.
4.2 Piecemeal Rivalry and Traveling Waves. Another empirical obser-
vation about spatiotemporal dynamics in rivalry is that stability is often
incomplete across the visual ﬁeld, producing piecemeal rivalry, in which
one portion of the visual ﬁeld looks like the image in one eye, while another
portion looks like the image in the other eye (Mueller & Blake, 1989). One
intriguing feature of these piecemeal percepts is the phenomenon known
as traveling waves: subjects tend to perceive a perceptual switch as a wave
propagating over the visual ﬁeld (Wilson, Blake, & Lee, 2001; Lee, Blake, &
Heeger, 2005): the suppressed stimulus becomes dominant in an isolated lo-
cation of the visual ﬁeld and then gradually spreads. These traveling waves
reveal an interesting local dynamics during an individual switch itself.
Demonstrating the dynamics of traveling waves within patches of the
percept requires a different method of probing perception instead of asking

Multistability and Perceptual Inference
9
Figure 3: Traveling waves. (A) Annular stimuli used by Lee et al. (2005)
(left and center panels) and the subject percept reported by observers (right
panel), in which the low-contrast stimulus was seen to spread around the annu-
lus, starting at the top. Figure reprinted with permission from Lee et al. (2005).
(B) Propagation time as a function of distance around the annulus, replotted
from Wilson et al. (2001). Filled circles represent radial gratings, and open
circles represent concentric gratings. A transient increase in contrast of the sup-
pressed stimulus induces a perceptual switch at the location of contrast change.
The propagation time for a switch at a probe location increases with distance
(around the annulus) from the switch origin. (C) Simulated propagation time
(measured by the time to switch percept following a switch at varying distances
around the annulus). (D) Average simulated propagation time between nodes
separated by a gap compared to nodes without a gap.
subjects to evaluate the “global percept.” Wilson et al. (2001) used annular
stimuli (see Figure 3A) and probed a particular patch along the annulus.
They showed that the time at which the suppressed stimulus in the test patch
becomes dominant is a function of the distance (around the circumference
of the annulus) between the test patch and the patch where a dominance
switch was induced by transiently increasing the contrast of the suppressed
stimulus (see Figure 3B). This dependence of switch time on distance sug-
gested to Wilson et al. that stimulus dominance was propagating around the
annulus. Wilson et al. made two additional observations about the nature

10
S. Gershman, E. Vul, and J. Tenenbaum
Figure 4: Piecemeal rivalry. (A) Exclusive visibility as a function of stimulus size
for a single subject. Replotted from O’Shea et al. (1997). (B) Simulated fraction
exclusivility as a function of stimulus size.
of traveling waves: (1) propagation is faster along a collinear (concentric)
contour compared to an orthogonal (radial) contour, and (2) introducing a
gap in the annulus substantially slows or halts propagation. Subsequently,
using fMRI, Lee et al. (2005) showed that the propagation of this traveling
wave can be observed in primary visual cortex.
To simulate such traveling waves within the percept of a stimulus, we
constructed a 7 × 7 MRF with annular topology and measured the propa-
gation time at different nodes along the annulus. We computed pairwise
correlation between nodes and converted this to propagation time by ex-
ponentially transforming the negative correlation and then rescaling it to
match the empirical propagation times. Figure 3C shows the simulated
propagation time between image nodes increasing as a function of distance
around the annulus. Since the spatial coupling induces local dependencies
in the MRF, nodes will be more likely to switch once their neighbors have
switched, thus producing a domino effect around the ring. We can account
for faster propagation of traveling waves in the concentric rings condi-
tion by increasing the strength of spatial coupling for such collinear stimuli
(following the observed greater coupling of dominance in collinear patches;
see Alais & Blake, 1999). Moreover, since a missing node disrupts the
domino effect of spatial coupling, we can reproduce the disruptive effect of
a gap on traveling wave propagation (Wilson et al., 2001) by removing one
of the nodes in the annulus and comparing propagation with and without
the gap (see Figure 3D).
Another factor inﬂuencing piecemeal rivalry is the size of the rivaling
stimuli. Several experiments have reported that exclusivity (the amount of
time spent in a stable percept) decreases as a function of stimulus size (see
Figure 4A; Blake, O’Shea, & Mueller, 1992; O’Shea, Sims, & Govan, 1997). We
simulated this ﬁnding by manipulating the proportion of the retinal images

Multistability and Perceptual Inference
11
occupied by the stimuli. Figure 4B shows the results of this simulation,
consistent with the experimental ﬁndings. The intuitive explanation for this
phenomenon is that larger stimuli require more individual node switches to
achieve stable percepts; thus, there will be longer periods in which the scene
conﬁguration occupies local minima of the energy landscape corresponding
to piecemeal percepts.
4.3 Binocular Fusion. In addition to the mode-hopping behavior that
characterizes binocular rivalry, bistable percepts often produce other states.
In some conditions, the two percepts are known to fuse rather than ri-
val: the percept then becomes a composite or superposition of the two
stimuli (Brascamp et al., 2006). This fused perceptual state can be induced
most reliably by decreasing the distance in feature space between the two
stimuli (Knapen, Kanai, Brascamp, van Boxtel, & van Ee, 2007) or decreas-
ing the contrast of both stimuli (Liu, Tyler, & Schor, 1992; Burke, Alais, &
Wenderoth, 1999).
Fusion is documented in experiments where subjects are given three
options to report their percept: one of two global percepts or something
in between. We deﬁne such a fused percept as a perceptual state lying be-
tween the two bistable modes—that is, an interpretation between the two
rivalrous, high-probability interpretations. On our account, manipulation
of distance in feature space amounts to varying the distance between the
two modes, and reduction of contrast corresponds to an increase in the
variance around the modes. By making the modes closer together or in-
creasing the variance parameter (σ 2
i ) in the model, greater probability mass
is assigned to the intermediate interpretation—a fused percept. Thus, these
manipulations shift the energy landscape so as to systematically increase
the odds of fused percepts, matching the phenomenology of these stimuli
(see Figure 5).
4.4 Contrast Dependence of Dominance Durations. A classic obser-
vation in the psychophysics of binocular rivalry is that when the contrast
in one eye (the variable-contrast eye) is increased, the dominance durations
in the other (ﬁxed-contrast) eye decrease while the dominance durations
in the variable-contrast eye stay relatively unchanged. This phenomenon is
often referred to as Levelt’s second proposition (Levelt, 1965) and has been
a key target for many models of binocular rivalry (Dayan, 1998; Lankheet,
2006; Moreno-Bote et al., 2007; Wilson, 2007). A standard explanation of
this phenomenon appeals to the interaction between two dynamic pro-
cesses: short-timescale changes in mutual inhibition between monocular
neural populations and long-timescale changes in adaptation. The neurons
representing the currently dominant stimulus inhibit the neurons repre-
senting the currently suppressed stimulus, but adaptation of the inhibiting
neurons causes this suppression to wane over time, allowing the previously

12
S. Gershman, E. Vul, and J. Tenenbaum
Figure 5: Fusion of binocular images. Simulated (A) and empirical (B) frac-
tion of exclusive percepts as a function of feature space distance between the
binocular stimuli. Data replotted from Knapen et al. (2007). Simulated (C) and
empirical (D) fraction of exclusive percepts as a function of stimulus contrast.
Model contrast is measured by the inverse of the variance parameter, σ 2
i . Data
replotted from Burke et al. (1999).
inhibited neurons to accumulate enough activation to cause a perceptual
switch.
Brascamp et al. (2006) have observed that Levelt’s second proposition is
valid only when the stimulus presented to the ﬁxed-contrast eye is relatively
high contrast. Under low-contrast conditions, the proposition actually re-
verses (see Figure 6). Brascamp et al. (2006) suggested amending Levelt’s
second proposition to: “Changes to one of the two contrasts mainly affect
dominance durations in the higher contrast eye.”
Our model captures the contrast dependence of dominance durations
under both high and low ﬁxed-contrast conditions (see Figure 6). On our ac-
count, this effect arises from transitions between several inference regimes:
1. When contrast to both eyes is (equally) low, then the data in both eyes
are uncertain and easy to discount; therefore, the modes correspond-
ing to one or another eye being dominant are easy to escape, fused
percepts are common (see section 4.3), and dominance durations in
both eyes will be brief.

Multistability and Perceptual Inference
13
Figure 6: Effect of stimulus contrast on dominance durations. Simulated (A)
and experimental (B) dominance durations as a function of stimulus contrast
in the variable contrast eye (x-axis), when the stimulus presented to the ﬁxed-
contrast eye is high contrast (the maximum of the contrast range presented
to the variable contrast eye). Simulated (C) and experimental (D) dominance
durations as a function of stimulus contrast in the variable-contrast eye when
the stimulus presented to the ﬁxed-contrast eye is low contrast (the minimum of
the contrast range presented to the variable contrast eye). Data replotted from
Brascamp et al. (2006).
2. When contrast is low in one eye but high in the other, the low-contrast
mode is easy to escape; moreover, the high-contrast eye is hard to
discount as an outlier in favor of the low-contrast eye. Altogether, the
higher-contrast eye enjoys long dominance durations.
3. When the contrast in both eyes is high, fused or mixed percepts are
unlikely and do not last long (Hollins, 1980). Moreover, neither eye is
easier to discount: therefore, the advantage that the relatively high-
contrast eye had in regime 2 no longer exists, and dominance durations
in both eyes will again be brief.
Thus, when the ﬁxed-contrast eye has high contrast and the contrast of
the variable-contrast eye is increased to match it, the system transitions from
regime 2 to regime 3 and consequently will increase the posterior proba-
bility that the inputs to the ﬁxed-contrast eye are outliers. This effectively
suppresses the ﬁxed-contrast eye and reduces its dominance durations.
When the ﬁxed-contrast eye sees a low-contrast image and the contrast of
the variable-contrast eye is increased to be higher, the system transitions

14
S. Gershman, E. Vul, and J. Tenenbaum
from regime 1 to regime 2, thereby increasing the dominance duration of
the variable-contrast eye.
5 Discussion
Perceptual multistability is perhaps the most compelling evidence available
that the brain attempts to approximately represent a posterior distribution,
rather than just a point estimate, about the latent causes underlying sen-
sory inputs. The theory developed in this article, though incomplete in
many ways, is proof of concept that sampling-based posterior approxima-
tions on simple but realistic graphical models can reproduce a variety of
psychophysical phenomena, including the rich spatiotemporal dynamics
observed in binocular rivalry experiments. Importantly, these psychophys-
ical phenomena arise in our model from an approximately rational solution
to the fundamental problem of inferring the correct image interpretation
from noisy sensory inputs.
5.1 Related Work. The idea that perceptual multistability can be con-
strued in terms of sampling in a Bayesian model was ﬁrst proposed by
Sundareswara and Schrater (Schrater & Sundareswara, 2007; Sundareswara
& Schrater, 2008), and our work follows theirs closely in several respects.
However, we believe our work offers several additional theoretical in-
sights. First, Sundareswara and Schrater’s model requires sampling from
the known full posterior; thus, it is not clear whether their model reﬂects an
effective approximate inference algorithm when the posterior is not known.
In contrast, we show that this behavior need not require sampling from the
full posterior, but emerges from a simple, common, and effective sampling
method for approximate inference in graphical models, demonstrating that
multistable perception can be understood as the consequence of the engi-
neering principles responsible for recent progress in computer vision and
artiﬁcial intelligence (Geman & Geman, 1984; Koller & Friedman, 2009).
Second, our model offers an explanation for the memory decay on the lat-
est best sample postulated by Sundareswara and Schrater: this apparent
persistence and decay of sampled states is a natural consequence of the
principled coupling of adjacent eye and image nodes.
These principles highlight a more general point of divergence between
our model and other Bayesian models of multistable perception (Dayan,
1998; Hohwy, Roepstorff, & Friston, 2008). Other models postulate in-
trinsically stochastic neurophysiological processes such as noisy sensory
detection, adaptation, inhibition, and so on, to account for the stochastic
dynamics of multistability. In contrast, we show that these stochastic dy-
namics fall out naturally from a rational approach to approximate Bayesian
inference in graphical models. To be clear, we do not mean to suggest that
the details of stochastic neurophysiological processes are unimportant (see
section 5.2), but our goal here is to show how the stochastic dynamics

Multistability and Perceptual Inference
15
of perceptual multistability could arise from rational algorithms for ap-
proximate probabilistic inference, independent of—and at a more abstract
level of analysis than—any speciﬁc mechanism for implementing inference
algorithms in the brain. Relating our proposals at the algorithmic level to
the details of neural processing is an important avenue for future work.
Successful dynamic neural models of binocular rivalry have argued that
dominance arises from inhibitory connections between monocular neurons
that suppress one eye or the other, while switching arises from adaptation
of those inhibitory neurons, reducing suppression of one eye and allowing
it to suppress the formerly dominant eye in turn (Wilson, 2003; Noest, van
Ee, Nijs, & Van Wezel, 2007). Such models are supported by the observation
that suppression and dominance are complementary (Alais, Cass, O’Shea,
& Blake, 2010): gradual loss of visual sensitivity in one eye is accompanied
by gradual gain in the other eye. Our model suggests a rationale for such
behavior: when the inferred latent image is inconsistent with the sensory
signals in one eye, the visual system must explain away those sensory sig-
nals by ascribing them to a noise process. Thus, while an eye is suppressed,
signals to that eye are interpreted as arising from noise, resulting in a loss
of sensitivity and suppression of input to that eye. Moreover, this outlier
process is coupled between eyes because inferring an outlier in both eyes
is less parsimonious than simply explaining away the sensory input in one
eye; thus, it is sensible for the two eyes to alternate and for the dominance
of one to co-occur with the suppression of the other. Which outlier process
is preferred depends on local propagation dynamics, and shifts from one
state to another are enabled by stochastic changes in the surrounding nodes
as well as in the latent image nodes. Thus, adaptation-like dynamics can
arise from simple network dynamics. Of course, these two explanations
are not mutually exclusive, and adaptation might be a neural heuristic for
approximating the appropriate propagation dynamics.
Another important explanatory principle employed by a number of
recent models is a hierarchy of processing levels at which perceptual
competition can occur (Wilson, 2003; Freeman, 2005). This principle is
motivated by ﬁndings from psychophysical experiments showing that com-
petition occurs both between eyes and between objects. For example, rapid
swapping of ﬂickering orthogonal monocular gratings between the eyes
results in perceptual dominance durations that exceed the rate of swapping
(Logothetis, Leopold, & Sheinberg, 1996), suggesting that rivalry is at
the level of perceptual objects rather than the eye of origin. However, in
experiments where monocular stimuli are swapped after the subject reports
exclusive dominance in one eye, the suppressed perceptual object imme-
diately becomes dominant and the dominant pattern becomes suppressed
(Blake, Westendorf, & Overton, 1980), suggesting that rivalry is at the
level of eyes rather than objects. These conﬂicting ﬁndings are somewhat
resolved by brain imaging studies providing evidence for competition
in both V1 and in extrastriate areas (see Tong, Meng, & Blake, 2006, for

16
S. Gershman, E. Vul, and J. Tenenbaum
a review): rivalry in the brain appears to occur at the level of both the
monoocular sensory input and the binocular perceptual object. Our model
also captures this notion of hierarchical competition: rivalry at the ocular
level arises from the spatial coupling of the eye-speciﬁc noise process MRFs,
thus encouraging one or another eye to be dominant. In turn, rivalry at the
image level arises from the coupling of the latent image MRFs, which cap-
tures binocular extrastriate representations and encourages single coherent
images to be dominant. Because the sampling dynamics operate over MRFs
at both levels, the multistable stochastic alternations are driven by changes
at the eye and pattern level and reﬂect both ocular and pattern rivalry.
5.2 Neural Implementation. Many neurally plausible models have
been proposed that emulate binocular rivalry (Laing & Chow, 2002;
Freeman, 2005; Moreno-Bote et al., 2007; Noest et al., 2007; Wilson, 2007). We
have set out to address a slightly different question that does not challenge
the validity of these models: What does such a neural architecture accom-
plish? Our work in this article can be seen as a rational statistical analysis
that gives insight into the neural dynamics of these models why they work
as they do. In this section, we bring the focus back to neural architecture,
highlighting the similarity between our model and previously proposed ar-
chitectures. Explicit links can be established between the rational dynamics
of inference in an MRF and the dynamics in classic neural network models,
including models of rivalry.
There is an intimate connection between the MRF model presented
here and classical neural networks in computational neuroscience, such
as the Hopﬁeld net (Hopﬁeld, 1982) and the Boltzmann machine (Ackley,
Hinton, & Sejnowski, 1985). In fact, both the Hopﬁeld net and the Boltzmann
machine are examples of MRFs. The latent scene nodes in our model can
be thought of as neuron-like units whose “ﬁring” signals the presence of
a particular image feature and whose “synaptic input” is the negative en-
ergy potential contributed by local neurons and sensory inputs (the retinal
image nodes). This local connectivity structure is characteristic of primary
visual cortex (Das & Gilbert, 1999). Another interesting aspect of this model
is that the negative energy potential integrated by each neuron is a loga-
rithmic function of probability; such logarithmic coding has been widely
implicated in cortical systems (Gold & Shadlen, 2002). Furthermore, the
stochastic nature of neural ﬁring makes it well suited for implementing
sample-based approximations (Hoyer & Hyv¨arinen, 2003).
Gibbs sampling operating over the MRF gives rise to what is known
as Glauber dynamics (Glauber, 1963), a well-studied phenomenon in the
neural networks literature (Amit, 1989). The hallmark of Glauber dynamics
(as applied here) is spatiotemporal autocorrelation in neural responses (e.g.,
traveling waves) as the network diffuses stochastically toward low-energy
stable states. Importantly, once a stable state is reached, the stochastic nature
of the dynamics ensures that eventually the network will leave that state

Multistability and Perceptual Inference
17
and temporarily settle in a new one, thereby anticipating the dynamics of
perceptual multistability.
To make these connections more explicit and show the link to neurally
based models of rivalry, consider the simpliﬁed setting where sn ∈{xL
n, xR
n},
which is equivalent to assuming that wn ∈{0, 1}, and πn = 1, ∀n. That
is, wn = 1 if the left eye is dominant at pixel n, and 0 otherwise. The
Gibbs sampling updates presented in the appendix can be computed by
a stochastic network of neurons. Let yn denote a binary neuron whose ﬁr-
ing (yn = 1) signals that the left eye is dominant in the latent image at
pixel n. This neuron receives net synaptic input an and emits a spike with
probability
P(yn = 1) =
1
1 + e−τan ,
(5.1)
where
an = −

bn −xL
n
2 −

bn −xR
n
2 −β

j∈Cn
(2wj −1).
(5.2)
The synaptic inputs consist of lateral connections from neighboring binoc-
ular neurons (wj) and monocular retinal inputs (xL
n and xR
n). To a ﬁrst ap-
proximation, the net synaptic input reﬂects competition between eyes as
well as between stimulus patterns (as in Wilson, 2003). In particular, the
contrastive terms in the activation function can be interpreted as mutually
inhibitory connections.
Another property embodied by these equations is the stochastic nature
of spike generation that enables transitions between attractor states. The
role of noise-induced transitions in multistability has been emphasized by
several recent models (Moreno-Bote et al., 2007; van Ee, 2009). Our rational
analysis elucidates the role that such transitions might play in allowing the
visual system to sample statistically optimal percepts in a computationally
tractable fashion.
It is straightforward to verify that sampling from equation 5.1 is equiv-
alent to sampling from equation A.5 in the appendix. Thus, perceptual
inference in our model can be mapped approximately onto a linear-
nonlinear Poisson cascade (Schwartz, Pillow, Rust, & Simoncelli, 2006):
(1) a linear integration of synaptic inputs, (2) a nonlinear transformation of
the net input into a scalar ﬁring rate, and (3) stochastic spike generation ac-
cording to a Poisson process, approximated in discrete time by a Bernoulli
process. The linear-nonlinear Poisson cascade is a canonical building block
of neural models, particularly in early vision (Carandini et al., 2005); our
model provides a functional interpretation of the cascade in terms of rational
perceptual inference.

18
S. Gershman, E. Vul, and J. Tenenbaum
5.3 Limitations and Extensions. MRFs are just one of many kinds of
probabilistic graphical model that have been successfully applied in recent
computer vision and AI research. They are well suited to lower-level per-
ceptual tasks but not to more causally structured higher-level problems of
scene understanding; there, directed models such as Bayesian networks are
more appropriate (Yuille & Kersten, 2006). Likewise, multistability occurs in
other perceptual contexts besides binocular rivalry, such as depth reversals
in the perception of three-dimensional objects (Blake & Logothetis, 2002).
It would be interesting to see if phenomena of multistability occurring in
higher-level perceptual contexts can also be explained in terms of MCMC
inference on appropriately structured graphical models.
While our account emphasizes the algorithmic dynamics of sampling,
an alternative perspective, explored by Bialek & DeWeese (1995), is that
multistability arises from the dynamics of the sensory inputs themselves.
This perspective holds that multistability is a normative adaptation to a
nonstationary world. Although intuitively appealing given that natural
sensory inputs really are nonstationary, a limitation of this persepctive is
that it does not apply as congenially to situations where ambiguity is due
to static causes, for example, occlusion of one eye.
A more fundamental weakness of our model pertains to its represen-
tation of uncertainty. MCMC methods represent uncertainty through the
ensemble of samples generated over time, yet we have portrayed the per-
ceptual system as essentially keeping track of only the most recent sample.
One way to rehabilitate the normativity of the model’s output would be to
posit a downstream area (e.g., in extrastriate or inferior temporal cortex)
that compiles the samples or estimates statistics in an online fashion. We
leave development of such a theory to future work.
Although we have focused on perceptual multistability, other cognitive
processes may also be amenable to a similar analysis. For example, it has
been suggested that the acquisition of logical concepts could arise from
MCMC-based diffusion through a space of grammars (Ullman, Goodman,
& Tenenbaum, 2010). Anchoring and adjustment effects, in which people
seem to incrementally adjust their numerical estimates away from an
anchor (Epley & Gilovich, 2006), could arise from a similar process.
Generally MCMC methods make inductive inference practical in many
different kinds of hypothesis spaces, and their characteristic dynamics lead
to testable predictions.
In conclusion, we have argued that MCMC algorithms provide a
psychologically and biologically plausible explanation for perceptual
multistability where traditional point estimation schemes fail. It is worth
emphasizing that purely computational-level analyses will not sufﬁce to ex-
plain this phenomenon; the explanatory power of our model derives from
its algorithmic-level analysis. Although incomplete in many ways, it points
toward the fruitfulness of bringing algorithmic ideas into rational statistical
theories of cognition.

Multistability and Perceptual Inference
19
Appendix: Model Details
A.1 Image Model. We formulate the posterior distribution over image
and outlier variables using a Gibbs distribution:
P(s, π|x) ∝exp

−τ
N

n=1
Es
n −τ

i

Exi
n + Eπi
n


,
(A.1)
where i ∈{L, R} indexes the eyes, τ is a global inverse temperature pa-
rameter (which we set to 1/250), and the energy functions are deﬁned as
follows:
Exi
n = πi
n

xi
n −sn
2
2σ 2
i
,
(A.2)
Es
n = (bn −sn)2 + β

j∈Cn
(wn −wj)2,
(A.3)
Eπi
n =

j∈Cn
γ

πi
n −πi
j
2 + απi
j,
(A.4)
where sn = wnxL
n + (1 −wn)xR
n and Cn denotes the subset of pixel locations
neighboring n. The parameters β and γ control the smoothness of the image
and outlier MRFs, respectively; we set both of these to 10 in our simulations.
The parameter α is a sparsity parameter that penalizes outliers; we set this
parameter to 500. The parameter bn is a bias term for the nth pixel, encoding
prior knowledge about the latent surface at each location, which is set to 0
except where noted otherwise. The variance parameter σ 2
i was set to 0.005
except where noted otherwise.
A.2 Conditional Distributions. In the Gibbs sampler, nodes are up-
dated asynchronously by drawing their values from the following condi-
tional distributions:
P(wn|x, π, w/n) ∝exp

−τEs
n −τ

i
Exi
n

,
(A.5)
P

πi
n|x, πi
/n, wn

∝exp
	
−τExi
n −τEπi
n

,
(A.6)
where s/n denotes all the nodes except the nth node (and likewise for π).
Note that because sn is a deterministic function of wn and xn, sampling from
P(wn|x, π, w/n) is equivalent to sampling from P(sn|x, π, s/n).

20
S. Gershman, E. Vul, and J. Tenenbaum
Figure 7: Sensitivity to sparsity level and outlier smoothness. Simulated trav-
eling waves (cf. Figure 3) at different settings of α (top) and γ (bottom).
A.3 Parameter Selection and Robustness. The parameters of our
model were chosen heuristically so as to approximately match the statistics
of the empirically observed dominance duration distribution (see Figure 2).
These parameters were then used in all other simulations, except where
explicitly manipulated. In principle, one could use stochastic approxima-
tion techniques (Swersky, Chen, Marlin, & de Freitas, 2010) to optimize the
parameters, but the computation time required to obtain a sufﬁciently large
set of samples makes that approach prohibitively expensive.
To illustrate robustness to variations in parameter settings, we recalcu-
lated the predicted traveling waves under different values of α (the sparsity
parameter) and γ (outlier smoothness parameter).1 Figure 7 shows the re-
sults of these simulations. While the quantitative speed of propagation
changes slightly as a function of α and γ , the qualitative pattern shown in
Figure 3 remains unchanged; the only exception is for γ = 100, where the
difference between concentric and radial propagation times reverses (this
is a somewhat degenerate case where the coupling of the outlier process
is an order of magnitude greater than the cost of inducing an outlier, α).
Thus, model predictions appear to be relatively insensitive to variations in
the sparsity level and outlier smoothness.
1Note that we have already explicitly manipulated β in explaining the difference
between radial and concentric propagation times.

Multistability and Perceptual Inference
21
Acknowledgments
We thank Noah Goodman for helpful discussions, as well as Peter Dayan
and Christopher Summerﬁeld for comments on the manuscript. S.J.G. was
supported by a Quantitative Computational Neuroscience fellowship from
the National Institutes of Health. E.V. was supported by ONR MURI:
Complex Learning and Skill Transfer with Video Games N00014-07-1-0937
(PI: Daphne Bavelier), an NDSEG fellowship and an NSF DRMS Disserta-
tion grant.
References
Ackley, D., Hinton, G., & Sejnowski, T. (1985). A learning algorithm for Boltzmann
machines. Cognitive Science, 9(1), 147–169.
Alais, D., & Blake, R. (1999). Grouping visual features during binocular rivalry. Vision
Research, 39(26), 4341–4353.
Alais, D., Cass, J., O’Shea, R., & Blake, R. (2010). Visual sensitivity underlying changes
in visual consciousness. Current Biology, 20, 1362–1367.
Amit, D. (1989). Modeling brain function: The world of attractor neural networks. Cam-
bridge: Cambridge University Press.
Bialek, W., & DeWeese, M. (1995). Random switching and optimal processing in the
perception of ambiguous signals. Physical Review Letters, 74(15), 3077–3080.
Blake, R. (2001). A primer on binocular rivalry, including current controversies. Brain
and Mind, 2(1), 5–38.
Blake, R., & Logothetis, N. (2002). Visual competition. Nature Reviews Neuroscience,
3(1), 13–21.
Blake, R., O’Shea, R. P., & Mueller, T. J. (1992). Spatial zones of binocular rivalry in
central and peripheral vision. Visual Neuroscience, 8, 469–478.
Blake, R., Westendorf, D., & Overton, R. (1980). What is suppressed during binocular
rivalry? Perception, 9(2), 223–231.
Brainard, D., & Freeman, W. (1997). Bayesian color constancy. Journal of the Optical
Society of America A, 14(7), 1393–1411.
Brascamp, J., van Ee, R., Noest, A., Jacobs, R., & van den Berg, A. (2006). The time
course of binocular rivalry reveals a fundamental role of noise. Journal of Vision,
6(11), 8.
Burke, D., Alais, D., & Wenderoth, P. (1999). Determinants of fusion of dichoptically
presented orthogonal gratings. Perception, 28, 73–88.
Carandini, M., Demb, J., Mante, V., Tolhurst, D., Dan, Y., Olshausen, B., et al. (2005).
Do we know what the early visual system does? Journal of Neuroscience, 25(46),
10577–10587.
Das, A., & Gilbert, C. (1999). Topography of contextual modulations mediated
by short-range interactions in primary visual cortex. Nature, 399(6737), 655–
661.
Daw, N., & Courville, A. (2007). The pigeon as particle ﬁlter. In J. C. Platt, D. Koller,
Y. Singer, & S. Roweis (Eds.), Advances in neural information processing systems, 20
(pp. 369–376). Cambridge, MA: MIT.

22
S. Gershman, E. Vul, and J. Tenenbaum
Dayan, P. (1998). A hierarchical model of binocular rivalry. Neural Computation, 10(5),
1119–1135.
Epley, N., & Gilovich, T. (2006). The anchoring-and-adjustment heuristic. Psycholog-
ical Science, 17(4), 311–318.
Fiser, J., Berkes, P., Orb´an, G., & Lengyel, M. (2010). Statistically optimal perception
and learning: From behavior to neural representations. Trends in Cognitive Sciences,
14, 119–130.
Fox, R., & Check, R. (1968). Detection of motion during binocular rivalry suppression.
Journal of Experimental Psychology, 78(3), 388–395.
Freeman, A. (2005). Multistage model for binocular rivalry. Journal of Neurophysiology,
94(6), 4412–4420.
Fukuda, H. (1981). Magnitude of suppression of binocular rivalry within the invisible
pattern. Perceptual and Motor Skills, 53(2), 371–375.
Geman, S., & Geman, D. (1984). Stochastic relaxation, Gibbs distributions, and the
Bayesian restoration of images. IEEE Transactions of Pattern Analysis and Machine
Intelligence, 6, 721–741.
Glauber, R. (1963). Time-dependent statistics of the Ising model. Journal of Mathemat-
ical Physics, 4, 294–307.
Gold, J., & Shadlen, M. (2002). Banburismus and the brain: Decoding the rela-
tionship between sensory stimuli, decisions, and reward. Neuron, 36(2), 299–
308.
Grifﬁths, T., & Tenenbaum, J. (2006). Optimal predictions in everyday cognition.
Psychological Science, 17(9), 767–773.
Grinband, J., Hirsch, J., & Ferrera, V. (2006). A neural representation of categorization
uncertainty in the human brain. Neuron, 49(5), 757–763.
Hohwy, J., Roepstorff, A., & Friston, K. (2008). Predictive coding explains binocular
rivalry: An epistemological review. Cognition, 108(3), 687–701.
Hollins, M. (1980). The effect of contrast on the completeness of binocular rivalry
suppression. Attention, Perception, and Psychophysics, 27(6), 550–556.
Hopﬁeld, J. (1982). Neural networks and physical systems with emergent collective
computational abilities. Proceedings of the National Academy of Sciences of the United
States of America, 79(8), 2254–2258.
Hoyer, P., & Hyv¨arinen, A. (2003). Interpreting neural response variability as Monte
Carlo sampling of the posterior. In S. Becker, S. Thr¨un, & K. Obermayer (Eds.),
Advances in neural information processing systems, 15 (pp. 277–284). Cambridge,
MA: MIT Press.
Kang, M. (2009). Size matters: A study of binocular rivalry dynamics. Journal of
Vision, 9(1), 1–11.
Kiani, R., & Shadlen, M. (2009). Representation of conﬁdence associated with a
decision by neurons in the parietal cortex. Science, 324(5928), 759–764.
Knapen, T., Kanai, R., Brascamp, J., van Boxtel, J., & van Ee, R. (2007). Distance
in feature space determines exclusivity in visual rivalry. Vision Research, 47(26),
3269–3275.
Knill, D., & Pouget, A. (2004). The Bayesian brain: The role of uncertainty in neural
coding and computation. Trends in Neurosciences, 27(12), 712–719.
Knill, D., & Richards, W. (1996). Perception as Bayesian inference. Cambridge: Cam-
bridge University Press.

Multistability and Perceptual Inference
23
Koller, D., & Friedman, N. (2009). Probabilistic graphical models: Principles and tech-
niques. Cambridge, MA: MIT Press.
Kording, K., & Wolpert, D. (2004). Bayesian integration in sensorimotor learning.
Nature, 427(6971), 244–247.
Laing, C., & Chow, C. (2002). A spiking neuron model for binocular rivalry. Journal
of Computational Neuroscience, 12(1), 39–53.
Lankheet, M. (2006). Unraveling adaptation and mutual inhibition in perceptual
rivalry. Journal of Vision, 6(4), 304–310.
Lee, S., Blake, R., & Heeger, D. (2005). Traveling waves of activity in primary visual
cortex during binocular rivalry. Nature Neuroscience, 8(1), 22–23.
Lee, T., & Mumford, D. (2003). Hierarchical Bayesian inference in the visual cortex.
Journal of the Optical Society of America A, 20(7), 1434–1448.
Leopold, D., & Logothetis, N. (1996). Activity changes in early visual cortex reﬂect
monkeys’ percepts during binocular rivalry. Nature, 379(6565), 549–553.
Levelt, W. (1965). On binocular rivalry. Soesterberg, Netherlands: Institute for Percep-
tion Rvo-Tno.
Levy, R., Reali, F., & Grifﬁths, T. (2009). Modeling the effects of memory on human
online sentence processing with particle ﬁlters. In D. Koller, D. Schuurmans, Y.
Bengio, & L. Bottou (Eds.), Advances in neural information processing systems, 21
(pp. 937–944). Cambridge, MA: MIT Press.
Liu, L., Tyler, C., & Schor, C. (1992). Failure of rivalry at low contrast: Evidence
of a suprathreshold binocular summation process. Vision Research, 32(8), 1471–
1479.
Logothetis, N., Leopold, D., & Sheinberg, D. (1996). What is rivalling during binoc-
ular rivalry? Nature, 380(6575), 621–624.
Mamassian, P., & Goutcher, R. (2005). Temporal dynamics in bistable perception.
Journal of Vision, 5(4), 361–375.
Moreno-Bote, R., Rinzel, J., & Rubin, N. (2007). Noise-induced alternations in an
attractor network model of perceptual bistability. Journal of Neurophysiology, 98(3),
1125–1139.
Mueller, T., & Blake, R. (1989). A fresh look at the temporal dynamics of binocular
rivalry. Biological Cybernetics, 61(3), 223–232.
Noest, A., van Ee, R., Nijs, M., & Van Wezel, R. (2007). Percept-choice sequences
driven by interrupted ambiguous stimuli: A low-level neural model. Journal of
Vision, 7(8), 1–14.
O’Shea, R. (1987). Chronometric analysis supports fusion rather than suppression
theory of binocular vision. Vision Research, 27(5), 781–791.
O’Shea, R., Sims, A., & Govan, D. (1997). The effect of spatial frequency and ﬁeld size
on the spread of exclusive visibility in binocular rivalry. Vision Research, 37(2),
175–183.
Polonsky, A., Blake, R., Braun, J., & Heeger, D. (2000). Neuronal activity in human
primary visual cortex correlates with perception during binocular rivalry. Nature
Neuroscience, 3(11), 1153–1159.
Robert, C., & Casella, G. (2004). Monte Carlo statistical methods. New York: Springer.
Sanborn, A., Grifﬁths, T., & Navarro, D. (2006). Rational approximations to ratio-
nal models: Alternative algorithms for category living. Psychological Review, 117,
1144–1167.

24
S. Gershman, E. Vul, and J. Tenenbaum
Schrater, P., & Kersten, D. (2000). How optimal depth cue integration depends on
the task. International Journal of Computer Vision, 40(1), 71–89.
Schrater, P., & Sundareswara, R. (2007). Theory and dynamics of perceptual bista-
bility. In B. Sch¨olkopf, J. Platt, & T. Hoffman (Eds.), Advances in neural information
processing systems, 19 (pp. 1217–1224). Cambridge, MA: MIT Press.
Schwartz, O., Pillow, J., Rust, N., & Simoncelli, E. (2006). Spike-triggered neural
characterization. Journal of Vision, 6(4), 484–507.
Shi, L., & Grifﬁths, T. (2009). Neural implementation of hierarchical Bayesian infer-
ence by importance sampling. In Y. Bengio, D. Schuurmans, J. Lafferty, C. K. I.
Williams, & A. Culotta (Eds.), Advances in neural information processing systems, 22
(pp. 1669–1677). Cambridge, MA: MIT Press.
Shimojo, S., & Nakayama, K. (1990). Real world occlusion constraints and binocular
rivalry. Vision Research, 30(1), 69–80.
Sundareswara, R., & Schrater, P. (2008). Perceptual multistability predicted by search
model for Bayesian decisions. Journal of Vision, 8(5), 1–19.
Swersky, K., Chen, B., Marlin, B., & de Freitas, N. (2010). A tutorial on stochas-
tic approximation algorithms for training restricted Boltzmann machines and
deep belief nets. In Information Theory and Applications Workshop, 2010 (pp. 1–10).
Piscataway, NJ: IEEE.
Tong, F., Meng, M., & Blake, R. (2006). Neural bases of binocular rivalry. Trends in
Cognitive Sciences, 10(11), 502–511.
Ullman, T., Goodman, N., & Tenenbaum, J. (2010). Theory acquisition as stochastic
search. In Proceedings of the 32nd Annual Cognitive Science Society. Cognitive Science
Society.
van Ee, R. (2009). Stochastic variations in sensory awareness are driven by noisy
neuronal adaptation: Evidence from serial correlations in perceptual bistability.
JOSA A, 26(12), 2612–2622.
Vul, E., Goodman, N., Grifﬁths, T., & Tenenbaum, J. (2009). One and done? Optimal
decisions from very few samples. In Proceedings of the 31st Annual Meeting of the
Cognitive Science Society. Cognitive Science Society.
Wales, R., & Fox, R. (1970). Increment detection thresholds during binocular rivalry
suppression. Perception and Psychophysics, 8(2), 90–94.
Weiss, Y., Simoncelli, E., & Adelson, E. (2002). Motion illusions as optimal percepts.
Nature Neuroscience, 5(6), 598–604.
Wilson, H. (2003). Computational evidence for a rivalry hierarchy in vision. Pro-
ceedings of the National Academy of Sciences of the United States of America, 100(24),
14499–14503.
Wilson, H. (2007). Minimal physiological conditions for binocular rivalry and rivalry
memory. Vision Research, 47(21), 2741–2750.
Wilson, H., Blake, R., & Lee, S. (2001). Dynamics of travelling waves in visual per-
ception. Nature, 412(6850), 907–910.
Yuille, A., & Kersten, D. (2006). Vision as Bayesian inference: Analysis by synthesis?
Trends in Cognitive Sciences, 10(7), 301–308.
Received April 3, 2011; accepted July 29, 2011.

This article has been cited by:

