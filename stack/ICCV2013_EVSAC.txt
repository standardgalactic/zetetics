EVSAC: Accelerating Hypotheses Generation by Modeling Matching Scores
with Extreme Value Theory
Victor Fragoso
Pradeep Sen
Sergio Rodriguez
Matthew Turk
University of California, Santa Barbara
{vfragoso@cs, psen@ece, srodriguez@pstat, mturk@cs}.ucsb.edu
Abstract
Algorithms based on RANSAC that estimate models us-
ing feature correspondences between images can slow down
tremendously when the percentage of correct correspon-
dences (inliers) is small. In this paper, we present a prob-
abilistic parametric model that allows us to assign conﬁ-
dence values for each matching correspondence and there-
fore accelerates the generation of hypothesis models for
RANSAC under these conditions.
Our framework lever-
ages Extreme Value Theory to accurately model the statis-
tics of matching scores produced by a nearest-neighbor fea-
ture matcher. Using a new algorithm based on this model,
we are able to estimate accurate hypotheses with RANSAC
at low inlier ratios signiﬁcantly faster than previous state-
of-the-art approaches, while still performing comparably
when the number of inliers is large. We present results of ho-
mography and fundamental matrix estimation experiments
for both SIFT and SURF matches that demonstrate that our
method leads to accurate and fast model estimations.
1. Introduction
Many applications in computer vision use image corre-
spondences to estimate important model parameters such
as homographies, fundamental matrices, and others. How-
ever, these correspondences can often be “corrupted” by
measurement noise or features that do not comply with the
“true” model to be estimated, i.e., outliers. Random Sample
Consensus (RANSAC) [7] has been the method of choice
to estimate model parameters in the presence of outliers,
and many improvements have been proposed to increase its
speed and its accuracy, e.g., [6, 14, 15, 16, 20].
Many methods improve RANSAC by exploiting prior in-
formation such as matching scores [2, 5, 9, 19] or geomet-
rical cues [4, 13, 16] in order to bias the generation of hy-
potheses (models) with matches that are more likely to be
correct, hence avoiding outliers as much as possible. How-
ever, even these state-of-the-art approaches are slow when
the percentage of inliers in the correspondences is low (e.g.,
< 10%), as can happen in many real-world situations. This
slowdown is caused by a substantial increase in the number
of iterations required for convergence.
In this work, we focus on the problem of increasing the
speed of RANSAC in these conditions. Our method extracts
information from the matching scores that are available in
many computer vision applications to compute a correct-
ness conﬁdence for the matches. Speciﬁcally, our contribu-
tions are:
1. A new probabilistic parametric model for matching
scores generated by a nearest-neighbor matcher that
is based on extreme value theory [3] and which accu-
rately models the distribution of the lowest scores.
2. EVSAC, a novel algorithm that leverages our proba-
bilistic framework to assign conﬁdence values to each
match in order to accelerate accurate hypothesis gen-
eration in RANSAC.
2. Previous work
In this section we review previous approaches that tackle
the problem of generating good hypotheses in RANSAC.
Since our method uses matching scores, we focus on ap-
proaches that do the same.
Given the image correspon-
dences and their matching scores (typically computed us-
ing a distance or similarity metric), these methods model
the statistics of the scores to assess the “correctness” of a
match. Note we use the term “match” to refer to a feature
correspondence between the query and reference images.
Several approaches that speed up the generation of hy-
potheses compute a correctness conﬁdence by attempting
to model the distributions of matching scores produced by
correct and incorrect matches.
Tordoff and Murray [19]
model these distributions in Guided-MLESAC (GMLE-
SAC) from data pre-labeled as correct and incorrect by ﬁt-
ting appropriate curves in an ofﬂine stage.
Goshen and
Shimshoni [9] model these distributions in BEEM by using
a non-parametric kernel density estimation and considering
Lowe’s ratio [11] as the random variable.
Brahmachari and Sarkar [2] compute a conﬁdence for
every match on the ﬂy by using the closest matching scores.
2013 IEEE International Conference on Computer Vision
1550-5499/13 $31.00 © 2013 IEEE
DOI 10.1109/ICCV.2013.307
2472
2013 IEEE International Conference on Computer Vision
1550-5499/13 $31.00 © 2013 IEEE
DOI 10.1109/ICCV.2013.307
2472

Their BLOGS algorithm assigns a higher correctness con-
ﬁdence when the best matching score is far from the two
second-best scores. Chum and Matas [5] take a different
approach in PROSAC, where promising models are gener-
ated and tested earlier by sampling from a subset containing
ranked correspondences by a quality measure. PROSAC
starts with a subset of good matches and progressively ex-
pands it until convergence. Although PROSAC requires a
good quality measure to rank correspondences for success,
it is guaranteed to perform no worse than random sampling.
Fragoso and Turk [8] also compute a conﬁdence on the
ﬂy by using the closest-matching scores. Speciﬁcally, they
employ a heuristic that models the correct matches using
information from a tail distribution and use this simple con-
ﬁdence metric to guide sampling. While we use their con-
ﬁdence values to preclassify correct/incorrect matches as
input to our approach, our algorithm takes a different ap-
proach, focusing on modeling the entire nearest-neighbor
matching process from all the data. By leveraging extreme
value theory, we can accurately model the minima for all
features and use it effectively for accelerating the hypothe-
sis generation.
Finally, there is also work that uses extreme value the-
ory (EVT) for modeling the tail of the underlying distribu-
tion to predict the correctness of a classiﬁer, such as Meta-
Recognition of Scheirer et al. [17]. In contrast, we propose
a fundamentally different application of EVT that models
the minimum scores produced by a nearest-neighbor fea-
ture matcher, which we represent as a stochastic process.
We show that EVT can be used to estimate the distributions
for both correct and incorrect matches using our proposed
mixture model, which then can be used to compute conﬁ-
dence values to accelerate hypothesis generation.
3. Modeling the matching scores
3.1. The matching process
Given a pair of images, i.e., a query and a reference im-
age, we ﬁrst detect image features (interest points or key-
points) on both using standard techniques (e.g., [1, 11]). For
each feature, we then compute its descriptor (SIFT [11] or
SURF [1]) and use the photometric information captured
in these descriptors to obtain matches or correspondences
between the query image and the reference. Formally, for
every query feature i we ﬁrst compute the distance between
the query descriptor qi and each of the reference descrip-
tors rj to get a matching score si,j = d(qi, rj). We then
select the reference feature with the minimum score as the
best match, satisfying the nearest-neighbor rule:
j⋆= arg min
j
{si,j}m
j=1 .
(1)
When using a similarity metric instead of a distance, the
algorithm seeks the maximum score; in this paper we will
focus on the distance metric since several descriptors are
compared using a Euclidean distance.
It is well known that the matching process given by Eq. 1
can return either correct or incorrect matches. An inlier
(correct) match is one where the associated reference and
query features both specify to the same physical location in
the scene, while outlier (incorrect) matches are those that
refer to different features in the scene yet produced a lower
matching score. Incorrect matches could be due to several
factors, such as repeating textures in the scene, features in
the query image that are not visible in the reference, changes
of lighting or shading, and others. Although descriptors are
typically designed to be as invariant as possible to these ef-
fects, this problem still occurs quite often. In fact, the ma-
jority of nearest matches found for features in real-world
images are typically outliers.
The processes that corrupt matches are complex and hard
to model. Hence, we take a stochastic approach and model
the probabilistic behavior of the matching scores. We rep-
resent the nearest-neighbor matching process as comprising
two random processes: one that produces correct matches
and another that produces incorrect matches for each query
feature. These correct and incorrect matching scores are
then merged together into the sequence {si,j}m
j=1, where
the matching score of the correct match (if it exists) may or
may not be the smallest in the list. We now describe our
probabilistic framework to model these distributions.
3.2. Our probabilistic model
Formally, the nearest-neighbor matcher can be modeled
with two stochastic processes, one producing independent
correct matching scores with a distribution Fc and another
producing independent incorrect matching scores with a
distribution F¯c (see Fig. 1). Note we write probability den-
sities (pdf’s) with lower case letters and distribution func-
tions (cdf’s) with capital letters.
Because incorrect matches can have lower scores than
correct matches, there is overlap between Fc and F¯c. There-
fore, the minimum score from a nearest-neighbor matcher
might be produced by either Fc or F¯c. If we could tell which
of these two distributions produced the minimum, we would
know if the minimum corresponds to a correct match or not.
First, we consider the distribution of incorrect matches.
If we have m features in our reference image and assume
that there is only one correct matching feature, then the
matching process will produce m −1 “incorrect” scores
drawn from distribution F¯c for each query feature. Since
our nearest-neighbor matcher will only consider the mini-
mum score, if an incorrect score is selected as the minimum
then it will follow a distribution that models the minimum
of F¯c. But what is this distribution? To answer this ques-
tion, we draw insight from one of the classical theorems in
extreme value theory (see, e.g., [3]):
2473
2473

nearest match process
correct matching
scores
Fc
incorrect matching
scores
Fc
Gc
1
m - 1
1
qi
min
min
rj
{   }1
m
si,j
correct matches (inliers)
Query
Reference
incorrect matches (outliers)
Query
Reference
Figure 1. Overview of the matching process. (top) Given query
and reference images where correct matches have been pre-
identiﬁed, we show the pdf’s of the matching scores for both cor-
rect (fc) and incorrect matches (g¯c). (bottom) We pose the pro-
cess of matching a query descriptor qi to a set of reference de-
scriptors {rj}m
j=1 in a probabilistic framework. First, a random
process generates at most one correct matching score using cdf
Fc. Another random process generates at least m −1 incorrect
matching scores using distribution F¯c. From this last set of in-
correct matches the minimum is taken, modeled by distribution
G¯c. Finally, the minimum of these two outputs is the best match-
ing score si,j⋆. This process therefore models a nearest-neighbor
matcher. Our work leverages extreme value theory to model this
matching process without knowing the distributions a priori, and
computes the conﬁdence that score si,j⋆is from a correct match.
Theorem: 1. Let Xi be a sequence of i.i.d. random vari-
ables and let Mn = max {X1, . . . , Xn} denote the max-
imum.
If there exist sequences of normalizing constants
an > 0, bn ∈R, and a non-degenerate probability dis-
tribution function, G, such that
P(a−1
n (Mn −bn) ≤x) →G(x) as n →∞
(2)
then G(x) is of the same type as one of the three extremal-
type distributions: Gumbel, Fr´echet, and Weibull.
Intuitively, Theorem 1 states that the statistics of max-
ima Mn converges to distribution G (which can be Gum-
bel, Fr´echet, or Weibull) asymptotically when the size of
the sequence goes to inﬁnity (i.e., a large sequence). Al-
though the theorem considers the maximum of a sequence,
it can be trivially applied to the minimum as well, since
a minimization problem can be recast as a maximization:
maxi {−Xi} = mini {Xi}. Therefore, we can apply this
theorem to model the minima of F¯c as distribution G¯c.
In order to derive analytically which of the three
extremal-type distributions to use for G¯c, we technically
need full knowledge of F¯c which we do not have a pri-
ori in our application. However, we can use the General-
ized Extreme Value distribution (GEV), which uniﬁes the
0
100
200
300
400
0
20
40
60
80
Matching Score
Density
f
0
0.2
0.4
0.6
0.8
0
20
40
60
80
Matching Score
Density
f
Figure 2. (left) Fitted Gamma distributions to matching scores
from pre-identiﬁed correct matches. (center) Fitted GEV distri-
butions to matching scores from pre-identiﬁed incorrect matches.
(right) The histograms show the distribution of all the best match-
ing scores (which include both correct and incorrect matches) and
the continuous curve shows that our mixture model of the two den-
sities is a good ﬁt. In all cases, SIFT matches are shown on top and
SURF matches on the bottom.
three extremal-type distributions, to address this issue, so
G¯c(s) = GEV(s; μ, σ, ξ) (see [3] or supp. material).
To model the correct matching distribution Fc, we as-
sume that the statistics of the correct matching scores will
be skewed towards the minimum since many of the state-
of-the-art descriptors such as SIFT or SURF are designed to
be as invariant as possible, resulting in low scores. There-
fore, we can expect distributions with longer right-tails,
and so we pose that the correct matching scores follow a
Gamma distribution, i.e., Fc(s) = Gamma(s; α, β). Fig. 2
shows ﬁtted corresponding distributions to a set of pre-
identiﬁed correct/incorrect matching scores for SIFT and
SURF matches to demonstrate that the models we have se-
lected for Fc and G¯c are reasonable in practice.
So now we have distribution Fc that produces the inlier
scores and G¯c that produces the best outlier score for each
feature. The nearest neighbor matcher then selects between
the two depending on which one is smaller. We observe
that the probability of selecting one distribution or the other
is given by the inlier ratio ε, which states the percentage
of the nearest matches that are actually inliers for all query
features. Therefore, the statistics of nearest-neighbor score
si,j⋆can be modeled by the following mixture distribution:
F = εFc + (1 −ε)G¯c
(3)
where we use the inlier ratio ε as the mixing parameter be-
tween the two distributions. The plots on the right in Fig.
2 show that this mixture model ﬁts the measured minimum
values for each feature reasonably in real examples.
We can then use this mixture model to calculate weights
or correctness conﬁdences as a function of a matching score
for every correspondence by computing the posterior prob-
ability from Eq. (3):
2474
2474

p(c|s)
=
p(s|c)p(c)
p(s|c)p(c) + p(s|¯c)p(¯c)
=
εfc
εfc + (1 −ε)g¯c
(4)
where p(c) = ε, p(s|c) = fc, and p(s|¯c) = g¯c. In the
section that follows, we describe an algorithm that automat-
ically estimates the necessary parameters for our model in
order to use it to accelerate model generation.
3.3. Building the probabilistic model from the data
We now introduce the EVSAC algorithm (summarized in
Algorithm 1), which was inspired by BEEM’s prior search
method [9] and which estimates the parameters for our theo-
retical model from real image data. EVSAC requires the im-
age feature correspondences {x ↔x′}n
i=1, and the k near-
est neighbor matching scores {si,1:k}n
i=1 sorted in an as-
cending order for every i-th correspondence. We denote the
r-th element in the sorted sequence si,1:k for the i-th match
as si,(r), then si,(1) = si,j⋆. The goal of EVSAC is to pro-
duce the set of weights {w}n
i=1 for every correspondence,
which will be used for generating hypotheses.
Our algorithm begins by computing the distributions for
correct and incorrect matches for the data provided. In or-
der to start the process, we need a correct-match predic-
tor to preliminarily label each match as correct or incorrect
(e.g., Lowe’s ratio [11] or MR-Rayleigh [8]). We then ﬁt a
two-parameter Gamma distribution to the data identiﬁed as
correct to estimate Fc. Subsequently, we use all the second
nearest matching scores, i.e., si,(2), ∀i = 1, . . . , n, to ﬁnd
the three parameters of the GEV distribution for G¯c. We
use the second nearest matching scores (instead of all the
matches labeled incorrect by the predictor) since in practice
this results in a better approximation of the true GEV, as if
we had a perfect incorrect match detector (see Fig. 3).
Next, we estimate ε, which is the mixing parameter be-
tween these two computed distributions. To ﬁnd this pa-
rameter, we build the empirical cdf of F, see Eq. (3), using
all the lowest matching scores, i.e., si,(1). Subsequently, we
then solve the following constrained least-squares problem:
minimize
y
1
2∥Ay −b∥2
2
subject to
1Ty = 1
0 ⪯y ⪯u
(5)
where the symbol ⪯indicates entrywise comparison, and
A =
⎡
⎢⎣
Fc(s1)
G¯c(s1)
...
...
Fc(sL)
G¯c(sL)
⎤
⎥⎦,
b =
⎡
⎢⎣
F(s1)
...
F(sL)
⎤
⎥⎦,
y =

ε
ε′
	
, and u =

τ
1
	
.
Algorithm 1 EVSAC
Require: {x ↔x′}n
i=1 and {si,1:k}n
i=1
Ensure: {wi}n
i=1 and {pi}n
i=1
1: v ←Predict

{si,1:k}n
i=1

2: (α, β) ←FitGamma


si,(1) such that vi = 1

3: (μ, σ, ξ) ←FitGEV


si,(2)

4: Calculate the empirical cdf using si,j⋆
5: Find ε by solving (5)
6: Calculate posterior-weights pi using Eq. (4)
7: Calculate weights wi using Eq. (6)
8: Use the weights wi for generating hypotheses
The ﬁrst entry of vector u, i.e., τ, is the inlier ratio com-
puted by the predictor in step 1. We set this upper bound
to the estimate of ε as in practice the predictor introduces
some false-positives (false-alarms) and so the true inlier ra-
tio must be less than or equal to this number.
Intuitively, the solution to (5) is the mixture parameter
that produces the lowest error between the observations (the
minimum scores returned by the nearest-neighbor matcher
for all query features) and the mixture model that com-
bines our estimates for the correct and incorrect distribu-
tions. Once this has been found, we can use Bayes’ theorem
in Eq. (4) to calculate a correctness conﬁdence for each cor-
respondence (step 6). Although the conﬁdences determined
by the posterior lead to speed ups in the convergence of the
model estimation, we noticed that the overlap between dis-
tributions causes some incorrect matches to be assigned a
high conﬁdence, costing extra iterations in RANSAC. To al-
leviate this problem, we calculate an “agreement” between
the predictor in step 1 and the posterior. Assuming that the
predictor returns a binary vector v where 1 denotes correct
match and 0 otherwise, we calculate the ﬁnal weights as
wi = pivi,
(6)
where pi is the posterior for the i-th match. In the case
where no agreement exists, i.e., all weights are zero, or
when the agreement within some number of iterations did
not converge to a solution, then the conﬁdences pi com-
puted with the posterior can be used.
Finally, we use
weights wi to sample matches to generate hypotheses.
4. Experiments
We present in this section two different experiments to
assess the performance of EVSAC. The ﬁrst experiment
evaluates the accuracy of calculating the parameters of
our probabilistic framework, i.e., the distribution parame-
ters and the mixing parameter ε. The second experiment
measures the performance of our approach against well-
established non-uniform sampling algorithms for the es-
timation task of homographies and fundamental matrices.
2475
2475

Table 1. Estimation of ε comparison: ˆε is the estimation with τ
set as an upper bound (see Eq. (5)), and ˜ε is without. The upper
bounded estimate tends to provide more accurate estimations.
Image Pairs
ε
ˆε
˜ε
Oxford-Bark (1-4 SURF)
0.0131
0.0141
0.1870
Oxford-Boat (1-6 SURF)
0.0257
0.0270
0.1429
Oxford-Bark (1-3 SIFT)
0.0479
0.0438
0.1291
Oxford-Trees (1-6 SIFT)
0.1028
0.1119
0.2467
Strecha-Brussel (2-3 SIFT)
0.1855
0.2067
0.2263
Strecha-Brussel (1-2 SURF)
0.2964
0.3115
0.3632
The estimation experiments consider cases ranging from a
very low inlier-ratio to cases where the inlier ratio is larger,
which are more commonly presented in previous work.
Datasets:
We use Oxford datasets [12] and Strecha’s
multi-view stereo datasets [18] for our experiments. Each
Oxford dataset contains a reference image and ﬁve query
images, as well as ﬁve homographies that relate the ref-
erence image and the query images. The three Strecha’s
datasets provide the set of camera parameters, i.e., intrinsic
and extrinsic matrices, for every image.
To generate the ground truth of image feature correspon-
dences, we ﬁrst detected approximately a thousand key-
points per image by using OpenCV’s Hessian keypoint de-
tector and also computed their SIFT [11] and SURF [1]
descriptors using OpenCV’s implementation. For the Ox-
ford datasets, we exploited the homographies provided and
mapped the reference image keypoints onto every query im-
age. Subsequently, we then selected for every query key-
point the closest mapped reference keypoint with a mini-
mum Euclidean distance less than ﬁve pixels. When no ref-
erence keypoint was found with this process, then that query
keypoint did not have a true match. We then manually veri-
ﬁed the result of this process, and used it as our ground truth
for the Oxford datasets.
For the multi-view dataset, we calculated the fundamen-
tal matrices between subsequent images (ﬁrst and second
image, second and third image, and so on) using the pro-
vided intrinsic and extrinsic matrices (see [10], pg. 246).
We then matched the keypoints on the subsequent images
using their descriptors, and ﬁltered out those query key-
points that produced a distance greater than or equal to 3
pixels from the epiline. The resulting set of matches was
veriﬁed manually to ensure that only correct matches were
left.
4.1. Parameter estimation experiment
We now present an evaluation of the performance of our
algorithm to ﬁnd the parameters of our probabilistic frame-
work: ε, and the distribution parameters using the predic-
tor from [8] only as the predictor in step 1. We compared
the estimated parameters against the parameters obtained
assuming that we had a perfect correct match detector.
ˆfc
ˆgc
fc
gc
ˆp
p
0
100
200
300
400
500
0
1
2
3
4
5 x 10
−3
Matching Score
Density
0
100
200
300
0
0.2
0.4
0.6
0.8
1
Matching Score
Posterior Probability
0
0.2
0.4
0.6
0.8
0
0.5
1
1.5
2
2.5
3
Matching Score
Density
0
0.2
0.4
0.6
0
0.2
0.4
0.6
0.8
1
Matching Score
Posterior Probability
Figure 3. Comparison of the mixture of densities and posterior
probability computed using EVSAC against the ground truth for
a pair of images with SIFT matches (top row) and SURF matches
(bottom row). Our density estimations ˆfc and ˆg¯c are close to the
densities fc and g¯c computed with an oracle. In the second col-
umn, we compare our estimated posterior probability ˆp with the
posterior p computed with the oracle.
We ﬁrst examine the accuracy of the estimation of ε in
Table 1. The estimate of ε using the upper bound in vector u
used in (5), ˆε, tends to be closer to the real value, while the
estimate without the upper bound (˜ε) can overshoot some-
times.
Next, we examine the quality of our estimation of the
different probability densities and the posterior we use to
compute the weights wi. In the ﬁrst column of Fig. 3, we
can observe that our algorithm (continuous curves) is able
to approximate with a good accuracy the mixture of densi-
ties obtained with the ground truth data (dashed curves). In
the second column, we present the posterior probabilities
computed from the estimated model (continuous curves)
and the posterior obtained from the ground truth (dashed
curves). This means that our algorithm estimates an accu-
rate posterior that essentially maximizes the information in
the matching score when computing a conﬁdence value.
4.2. Homography experiment
In this experiment we assess the performance of our
non-uniform sampling algorithm for estimating homogra-
phies. We implemented the probabilistic model parame-
ter estimation in Matlab, and produced the set of weights
for every correspondence. We also computed the weights
produced by BEEM, BLOGS, and GMLESAC in Matlab.
These weights were then read by our C++/OpenCV imple-
mentation of the respective algorithms: RANSAC (guided
by our weights), Guided-MLESAC [19], BEEM’s prior esti-
mation step [9], and BLOGS’ global search mechanism [2].
All these sampling algorithms (along with PROSAC [5]
and classical RANSAC) were then included in a classical
hypothesis-test loop, where the support was always being
2476
2476

maximized, and a solution was considered “good” if it sat-
isﬁed the maximality constraint, i.e., the constraint that a
good hypothesis was generated within a certain number of
iterations (see [5] for more details on this constraint). The
homography was computed using the OpenCV ﬁndHomog-
raphy( ) function without the RANSAC option. An inlier
was considered if the reprojection error of the homogra-
phy was less than 5 pixels. The algorithms were allowed to
run until a maximum number of iterations (hypothesis-test
loops) calculated adaptively is reached, and the algorithm
converged when 90% of the inliers (correct-matches) were
detected. The found hypothesis was reﬁned afterwards us-
ing a non-linear method.
The results of this experiment are summarized in Table 2.
The Oxford datasets used for the experiment presented very
challenging scenarios, where the inlier-ratios ε ranged from
1-10% for SIFT and SURF matches. The experiments were
run 300 times. We present the average number of inliers
detected; the average RMS reprojection error in pixels w.r.t.
to the error achieved by the ground truth data; the average
number of models/hypotheses generated; the average time
in milliseconds; the average Frobenius norm of the error
between estimated homography and the computed homog-
raphy with the ground truth (f-error); and the percentage of
“good” runs where each algorithm converged. The results
are sorted in ascending order by the inlier-ratio. We can ob-
serve that our algorithm (EVSAC) tends to perform overall
faster when the inlier ratio is very low (see rows A, B, C, D,
and E), and performs equivalent or faster than BEEM and
BLOGS as soon as the inlier-ratio increased (see rows F, G,
H, I). PROSAC and GMLESAC struggled to converge fast
when the inlier-ratio was very low (ε < 11%).
To measure the effect of the inlier-ratio on the conver-
gence time, we used the entire Oxford-Trees dataset, where
we observed that the inlier-ratio decreased as the blurring
increased in a systematic manner. In Fig. 4 we present a plot
of the convergence time as a function of the inlier-ratio. We
only considered BEEM, BLOGS, and EVSAC because the
other methods did not converge when the inlier ratio was
low. We can observe that EVSAC tends to converge faster
when the inlier-ratio is less than 0.1 and performs equiva-
lently when the inlier-ratio starts to increase.
4.3. Fundamental matrix experiment
In this experiment, we assess the performance of EVSAC
in estimating fundamental matrices. We have the same im-
plementation as in the homography experiment using Mat-
lab and C++/OpenCV implementation. The fundamental
matrix was computed using the 7-point algorithm provided
by the OpenCV ﬁndFundamentalMat( ) function without
the RANSAC option.
When the function returned more
than one solution, we kept the matrix that had the biggest
inlier support. A match was considered to be an inlier when
0.1
0.15
0.2
0.25
0
5
10
15
Inlier Ratio
Time [msec]
 
 
BEEM
BLOGS
EVSAC
0.05
0.1
0.15
0
500
1000
1500
Inlier Ratio
Time [msec]
 
 
BEEM
BLOGS
EVSAC
Figure 4. Convergence time as a function of the inlier ratio for
SIFT matches (left) and SURF matches (right) on the Oxford-
Trees dataset.
the distance between a query keypoint and the epiline was
less than a pixel.
The results of this experiment are shown in Table 3.
Strecha’s multi-view dataset provided different relatively
high inlier ratios; ranging from 29-43% for SIFT and SURF
matches.
The experiments were run 300 times, and we
present the same quantities as in the homography experi-
ment. We can observe that in all the experiments our algo-
rithm (EVSAC), BEEM, BLOGS, and PROSAC were the
fastest regardless of the descriptor used. GMLESAC was
the second fastest algorithm and RANSAC was the slow-
est. All of the algorithms converged in all the trials, and
provided an accurate estimation as the Frobenius norm indi-
cates. This conﬁrms that our algorithm can perform equiv-
alently to other methods when the inlier-ratio is not so low.
5. Conclusions and future directions
We have introduced a probabilistic framework that uses
extreme value theory to model the statistics of the best
matching scores selected by a nearest-neighbor feature
matcher. We then use the posterior probability of our mix-
ture model to compute the correctness weight for every
correspondence and thereby accelerate model generation.
Our homography and fundamental matrix estimation ex-
periments showed that our algorithm (EVSAC) performs
robustly and is faster than existing state-of-the-art meth-
ods (BEEM, BLOGS, PROSAC, and GMLESAC) when the
inlier-ratio is low (< 11%).
Moreover, the experiments
also demonstrated that EVSAC is comparable to these other
methods when the inlier-ratio increases (> 20%). The re-
sults suggest that EVSAC is a very useful algorithm for ap-
plications that require fast and robust model estimation in
complex environments where the number of inliers is low.
This work opens the possibility of using extreme value
theory for developing models for related problems that in-
volve a minimum (or maximum) which can be cast as
stochastic processes. For example, we are interested in ex-
tending this work to similarity metrics and to develop statis-
tical tools for analyzing and designing descriptors/metrics
for these applications.
2477
2477

Table 2. Homography estimation results for SIFT and SURF matches. The results are sorted by inlier-ratio (ε) in ascending order. EVSAC
performed well when the inlier-ratio is low, and performed equivalently when the inlier-ratio increased.
RANSAC
BEEM
BLOGS
PROSAC
GMLESAC
EVSAC
A: ε = 0.01, n = 992, SURF
inliers
NA
14 ± 0
14 ± 0
14 ± 0
14 ± 0
14 ± 0
error
NA
0 ± 0
0 ± 0
0 ± 0
0 ± 0
0 ± 0
models
NA
1443
2524
4
1521
11
time
NA
563.1
1008.3
2
511
4.2
f-error
NA
0
0
0
0
0
good runs
0 %
100%
96%
0.33%
0.33%
100%
B: ε = 0.02, n = 992, SIFT
inliers
10 ± 2
12 ± 3
12 ± 2
10 ± 2
11 ± 3
12 ± 2
error
0.36 ± 0.1
0.1± 0.02
0.1 ± 0.04
0.37 ± 0.03
0.24 ± 0.04
0.16 ± 0.03
models
2436910
41
17
2752900
10044
10
time
338618
13.3
5.3
375482
1446.4
3.3
f-error
94.4
6.6
10.7
136.7
37.8
12.1
good runs
37%
100%
100%
100%
100%
100%
C: ε = 0.035, n = 992, SURF
inliers
27 ± 4
24 ± 2
22 ± 4
27 ± 4
29 ± 2
24 ± 2
error
0.1 ± 0.03
0.1 ± 0.01
0.1 ± 0.01
0.1 ± 0.02
0.03 ± 0.05
0.2 ± 0.1
models
1313580
3741
4072
1458250
209963
1965
time
286881
1172.3
1509.5
284838
28092.1
572.3
f-error
2.5
2
9
3.2
2.9
4.2
good runs
89%
100%
99%
100%
100%
100%
D: ε = 0.04, n = 981, SURF
inliers
38 ± 6
39 ± 2
39 ± 2
38 ± 6
38 ± 9
39 ± 2
error
0.01 ± 0.1
0.04 ± 0.02
0.01 ± 0.001
0.02 ± 0.1
0.01 ± 0.2
0.02 ± 0.01
models
697832
39
82
655073
4151
4
time
155067
10.9
21.5
145207
838.4
1.3
f-error
1.1
0
0.1
1.3
3.9
0.1
good runs
91.33%
100%
100%
98%
99%
100%
E: ε = 0.05, n = 807, SURF
inliers
38 ± 6
40 ± 2
40 ± 2
38 ± 6
33 ± 9
40 ± 2
error
1.5 ± 0.2
0.04 ± 0.03
0.002 ± 0.001
0.45 ± 0.53
0.02 ± 0.13
0.02 ± 0.01
models
304532
149
355
321952
4713
92
time
61170.4
42.9
98.5
56176.5
2111.9
26.3
f-error
0.3
0.3
0.2
0.6
35.7
0.8
good runs
100%
100%
100%
100%
100%
100%
F: ε = 0.05, n = 807, SIFT
inliers
37 ± 6
41 ± 3
41 ± 4
36 ± 6
41 ± 3
41 ± 3
error
2.08 ± 0.3
0.08 ± 0.02
0.002 ± 0.01
0.17 ± 0.04
0.05 ± 0.02
0.04 ± 0.02
models
221667
71
14
218811
341
22
time
42002.5
15.7
3.5
40750.7
67.5
5.4
f-error
8.4
1.7
0.7
8.4
1.1
0.1
good runs
100%
100%
100%
100%
100%
100%
G: ε = 0.10, n = 992, SURF
inliers
58 ± 23
81 ± 8
81 ± 9
60 ± 23
81 ± 8
82 ± 7
error
0.003 ± 0.06
0.02 ± 0.01
0.03 ± 0.009
0.02 ± 0.06
0.02 ± 0.006 0.03 ± 0.004
models
4899
177
193
4507
918
73
time
1738.9
49.6
53.6
1616.2
226.5
21.9
f-error
16
0.8
0.7
13.3
0.6
0.4
good runs
100%
100%
100%
100%
100%
100%
H: ε = 0.103, n = 992, SIFT
inliers
62 ± 16
82 ± 9
82 ± 9
69 ± 16
80 ± 8
82 ± 8
error
0.1 ± 0.05
0.02 ± 0.016
0.05 ± 0.008
0.09 ± 0.04
0.03 ± 0.003 0.03 ± 0.003
models
4727
72
26
3649
773
8
time
1183.3
13.9
5.5
834
120.1
4.1
f-error
8.9
0.7
1.1
4.5
1
0.8
good runs
100%
100%
100%
100%
100%
100%
I: ε = 0.103, n = 992, SIFT
inliers
70 ± 15
81 ± 11
81 ± 10
77 ± 13
80 ± 12
82 ± 10
error
0.09 ± 0.02
0.03 ± 0.007 0.003 ± 0.002 0.05 ± 0.001 0.02 ± 0.015 0.002 ± 0.02
models
4675
13
13
1961
89
13
time
1032.4
3.4
3.3
507.2
18.4
3.4
f-error
5.5
0.4
0.8
3.3
1.4
1.3
good runs
100%
100%
100%
100%
100%
100%
2478
2478

Table 3. Fundamental matrix estimation results for SIFT and SURF matches. The results are sorted by inlier-ratio (ε) in ascending order.
EVSAC performed as fast as BEEM, BLOGS, and PROSAC.
RANSAC
BEEM
BLOGS
PROSAC
GMLESAC
EVSAC
A: ε = 0.29, n = 992, SURF
inliers
221 ± 30
236 ± 32
241 ± 34
237 ± 34
229 ± 31
237 ± 34
error
0.5 ± 1.5
0.4 ± 2.2
0.3 ± 0.7
0.4 ± 1.0
1.0 ± 7
0.3 ± 0.4
models
160
3
3
3
16
2
time
1349
69
64
67
497
64
f-error
0.07
0.05
0.1
1.0
0.06
0.08
good runs
100%
100%
100%
100%
100%
100%
B: ε = 0.33, n = 992, SURF
inliers
261 ± 44
278 ± 39
283 ± 38
288 ± 35
262 ± 43
279 ± 38
error
0.8 ± 5
0.4 ± 1.8
0.3 ± 0.6
0.4 ± 1.3
0.4 ± 1.4
0.4 ± 2
models
18
1
1
1
15
1
time
214
60
61
59
95
51
f-error
0.002
0.002
0.002
0.001
0.001
0.002
good runs
100%
100%
100%
100%
100%
100%
C: ε = 0.40, n = 992, SIFT
inliers
306 ± 34
321 ± 42
335 ± 42
331 ± 41
305 ± 36
330 ± 40
error
0.3 ± 0.5
0.3 ± 0.6
0.2 ± 0.8
0.2 ± 0.3
0.6 ± 5
0.2 ± 0.4
models
59
3
3
3
44
3
time
593
83
75
78
410
81
f-error
1.0
0.3
0.1
0.1
0.1
0.1
good runs
100%
100%
100%
100%
100%
100%
D: ε = 0.43, n = 992, SIFT
inliers
340 ± 55
368 ± 50
380 ± 38
387 ± 36
353 ± 51
373 ± 50
error
0.1 ± 0.25
0.08 ± 0.13
0.07 ± 0.15
0.06 ± 0.07
0.13 ± 0.32
0.08 ± 0.11
models
5
1
1
1
4
1
time
117
78
76
80
108
78
f-error
0.002
0.003
0.002
0.002
0.002
0.002
good runs
100%
100%
100%
100%
100%
100%
Acknowledgments.
VF and SR would like to thank UC MEXUS-
CONACYT (Fellowships 212913 and 311443) for the funding. This re-
search was supported in part by NSF under award number 1219261.
References
[1] H. Bay, A. Ess, T. Tuytelaars, and L. Van Gool. Speeded-up ro-
bust features (SURF). Comput. Vis. Image Underst., 110(3):346–
359, June 2008. 2, 5
[2] A. S. Brahmachari and S. Sarkar. BLOGS: Balanced local and global
search for non-degenerate two view epipolar geometry.
In Proc.
IEEE Intl. Conf. on Computer Vision, 2009. 1, 5
[3] E. Castillo, A. S. Hadi, N. Balakrishnan, and J. M. Sarabia. Extreme
value and related models with applications in engineering and sci-
ence. Wiley-Interscience, 2005. 1, 2, 3
[4] T.-J. Chin, J. Yu, and D. Suter. Accelerated hypothesis generation
for multistructure data via preference analysis. IEEE Trans. Pattern
Anal. Mach. Intell., 43(4):625–638, 2012. 1
[5] O. Chum and J. Matas. Matching with PROSAC – progressive sam-
ple consensus. In Proc. IEEE Computer Vision and Pattern Recogni-
tion, 2005. 1, 2, 5, 6
[6] O. Chum, J. Matas, and J. Kittler. Locally optimized RANSAC. In
Proc. Pattern Recognition (DAGM Symposium), 2003. 1
[7] M. A. Fischler and R. C. Bolles.
Random sample consensus: a
paradigm for model ﬁtting with applications to image analysis and
automated cartography. Commun. ACM, 24(6):381–395, June 1981.
1
[8] V. Fragoso and M. Turk. SWIGS: A Swift Guided Sampling Method.
In Proc. IEEE Computer Vision and Pattern Recognition, 2013. 2, 4,
5
[9] L. Goshen and I. Shimshoni. Balanced exploration and exploitation
model search for efﬁcient epipolar geometry estimation. IEEE Trans.
Pattern Anal. Mach. Intell., 30(7):1230–1242, July 2008. 1, 4, 5
[10] R. Hartley and A. Zisserman. Multiple View Geometry in Computer
Vision. Cambridge University Press, 2003. 5
[11] D. G. Lowe. Distinctive image features from scale-invariant key-
points. Intl. Journal of Computer Vision, 60(2):91–110, Nov. 2004.
1, 2, 4, 5
[12] K. Mikolajczyk, T. Tuytelaars, C. Schmid, A. Zisserman, J. Matas,
F. Schaffalitzky, T. Kadir, and L. V. Gool. A Comparison of Afﬁne
Region Detectors. Intl. Journal of Computer Vision, 65(1-2):43–72,
Nov. 2005. 5
[13] K. Ni, H. Jin, and F. Dellaert. GroupSAC: Efﬁcient consensus in the
presence of groupings. In Proc. IEEE Intl. Conf. in Computer Vision,
2009. 1
[14] R. Raguram and J.-M. Frahm. RECON: Scale-adaptive robust esti-
mation via residual consensus. In Proc. IEEE Intl. Conf. in Computer
Vision, 2011. 1
[15] R. Raguram, J.-M. Frahm, and M. Pollefeys. A Comparative Analy-
sis of RANSAC Techniques Leading to Adaptive Real-Time Random
Sample Consensus. In Proc. European Conf. on Computer Vision,
2008. 1
[16] T. Sattler, B. Leibe, and L. Kobbelt.
SCRAMSAC: Improving
RANSAC’s efﬁciency with a spacial consistency ﬁlter. In Proc. IEEE
Intl. Conf. on Computer Vision, 2009. 1
[17] W. J. Scheirer, A. Rocha, R. J. Micheals, and T. E. Boult. Meta-
Recognition: The Theory and Practice of Recognition Score Analy-
sis. IEEE Trans. Pattern Anal. Mach. Intell., 33(8):1689–1695, Aug.
2011. 2
[18] C. Strecha, R. Fransens, and L. Van Gool. Combined depth and out-
lier estimation in multi-view stereo. In Proc. IEEE Computer Vision
and Pattern Recognition, 2006. 5
[19] B. Tordoff and D. W. Murray. Guided sampling and consensus for
motion estimation. In Proc. European Conf. on Computer Vision,
2002. 1, 5
[20] P. H. S. Torr and A. Zisserman. MLESAC: A new robust estimator
with application to estimating image geometry. Comput. Vis. Image
Underst., 78(1):138–156, Apr. 2000. 1
2479
2479

