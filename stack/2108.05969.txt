arXiv:2108.05969v1  [cs.DC]  12 Aug 2021
Scalable3-BO: Big Data meets HPC - A scalable
asynchronous parallel high-dimensional
Bayesian optimization framework on
supercomputers
Anh Tran∗
Optimization and Uncertainty Quantiﬁcation
Sandia National Laboratories
Albuquerque, NM 87123
Email: anhtran@sandia.gov
Bayesian optimization (BO) is a ﬂexible and powerful
framework that is suitable for computationally expensive
simulation-based applications and guarantees statistical
convergence to the global optimum. While remaining as
one of the most popular optimization methods, its capa-
bility is hindered by the size of data, the dimensionality of
the considered problem, and the nature of sequential op-
timization. These scalability issues are intertwined with
each other and must be tackled simultaneously. In this
work, we propose the Scalable3-BO framework, which
employs sparse GP as the underlying surrogate model
to scope with Big Data and is equipped with a random
embedding to efﬁciently optimize high-dimensional prob-
lems with low effective dimensionality. The Scalable3-BO
framework is further leveraged with asynchronous paral-
lelization feature, which fully exploits the computational
resource on HPC within a computational budget. As a
result, the proposed Scalable3-BO framework is scalable
in three independent perspectives: with respect to data
size, dimensionality, and computational resource on HPC.
The goal of this work is to push the frontiers of BO be-
yond its well-known scalability issues and minimize the
wall-clock waiting time for optimizing high-dimensional
computationally expensive applications. We demonstrate
the capability of Scalable3-BO with 1 million data points,
10,000-dimensional problems, with 20 concurrent work-
ers in an HPC environment.
1
Introduction
Bayesian optimization (BO) is an efﬁcient optimiza-
tion method for computationally expensive and complex
real-world engineering applications. It is constructed up
∗Corresponding author: Anh Tran (anhtran@sandia.gov)
on an underlying Gaussian process (GP), which is adap-
tively reﬁned as the optimization process advances. Al-
though BO has been used extensively in the literature,
there are multiple drawbacks that limits the capability of
BO methods, mainly because of different scalability is-
sues. First, it is well-known that training GP costs O(n3)
ﬂops to compute the inverse of the covariance matrix,
which limits the number of observations to 102-104 de-
pending on the speciﬁc implementation. This is usually
referred to as the data scalability issue. Second, GP does
not typically perform well in high-dimensional problems
because training a GP is, again, an optimization problem
on high-dimensional space to search for the best hyper-
parameters. Third, the classical BO algorithm is sequen-
tial; that is, it only queries one simulation or one func-
tional evaluation at a time, which in turn creates a com-
putational bottleneck for computationally expensive prob-
lems.
In this paper, we propose a robust and scalable ap-
proach to solve a high-dimensional Bayesian optimization
for computationally expensive applications by exploiting
the computational resources on supercomputers. The pro-
posed BO algorithm, called Scalable3-BO, is scalable in
three distinct directions. First, it is scalable with respect
to the dataset. Second, it is scalable with respect to the
dimensionality of the problem. Third, it is scalable with
respect to the computational resource. This problem is im-
portant in so many aspects, as it leverages the capability of
the classical BO methods and expands the applicability to
a broader domain, particularly for computationally expen-
sive high-dimensional modeling and simulation applica-
tions. While the idea of scalability seems to be disjoint in
three different directions, they are closely related to each
other. For example, optimizing in HPC will presumably
generate a lot of data, so parallelization in HPC is tied

to data scalability issue. High-dimensional problems also
requires exponentially more data points to learn, typically,
so it is also related to data scalability issue. Finally, it is
difﬁcult to solve a high-dimensionaloptimization problem
without the usage of HPC, especially for computationally
expensive applications in the era of computers. These in-
tertwined issues therefore requires a comprehensive ap-
proach that deals with all scalability problems simultane-
ously.
Local GP approaches is arguably the most popular
choice for addressing data scalability due to its ease in
implementation. Bostanabad et al. [1] proposed a glob-
ally approximate local GP (GAGP) and demonstrated up
to ∼90k data points. Zhang et al. [2] proposed a locally
weighted scheme, similarly to van Stein et al. [3,4], where
the weights are derived by minimizing the weighted pos-
terior variance, and demonstrate to 100k data points. Tran
et al. [5,6] proposed a local GP approach with Wasserstein
distance to model the potential energy surface and mixed-
integer BO problems [7]. Nguyen et al. [8] proposed to
tune the weights adaptively as a function of inputs and
cluster centers and demonstrated up to ∼15k data points.
Keyes et al. [9, 10, 11, 12] proposed and employed a tile
algorithm with hierarchical low-rank Cholesky approxi-
mation and demonstrated up to ∼2M data points with het-
erogeneous computing, i.e. CPU+GPU. Recently, Chen
et al. [13] proposed to use stochastic gradient descent to
train GP and demonstrated with 2M data points. Eriks-
son et al. [14] also used local surrogate model to scale the
global surrogate model. Liu et al. [15] provided a compre-
hensive review of scalable GPs for Big Data.
High-dimensional GP is also an interesting topic,
which has attracted many researchers. Due to the lim-
ited space, we only select a few notable works, but much
more have been done in the literature. Bach [16] proposed
a hierarchical kernel learning to select a hull of interac-
tion terms. Duvenaud et al. [17,18] proposed additive ker-
nels, which strikingly resembles high-dimensional model
representation and ANOVA decomposition. Wang et al.
[19,20] proposed REMBO, which draws a normal random
matrix and optimizes the high-dimensional function in an
embedded low-dimensional subspace. Nayebi et al. [21]
proposed HeSBO, which can be considered as an exten-
sion of REMBO but differs in the embedding function. Li
et al. [22] coupled Dropout to randomly select active vari-
ables. Li et al. [23] proposed a restricted projection pur-
suit model that has a similar ﬂavor to active subspaces.
Parallelism in BO also offers another boost to increas-
ing optimization efﬁciency on high-performance comput-
ing (HPC) platforms. Relevant to this work, Desautels et
al. [24] proposed GP-BUCB and GP-AUCB framework
that focuses on the acquisition function, whereas Contal
et al. [25] proposed a GP-UCB-PE. [26] to promote ex-
ploration.
In this work, we take the sparse GP approach instead
of the local GP approach as an underlying GP due to its
solid theoretical foundation. While the complexity is more
expensive compared to the local GP approach (O(nm2)
versus O(m3)), it allows better approximation accuracy in
high-dimensional problems. We combine several aspects
of scalability into a uniﬁed framework that is suitable for a
wide range of single-objective expensive applications. In
this paper, we propose Scalable3-BO algorithm, which
- is scalable with respect to the size of data by adopt-
ing the sparse GP,
- is equipped with a random embedding to solve high-
dimensional problems with low-dimensional active
subspace,
- is fully parallelized with an asynchronous par-
allelism for computationally expensive simulation-
based problems on HPC platforms.
This high-dimensional research direction is motivated by
the promising results of active subspace, where even high-
ﬁdelity and computationally expensive simulations are
shown to have active subspaces and low intrinsic dimen-
sionality [27]. However, instead of ﬁnding the active sub-
space and accurately approximating the high-dimensional
function, in this paper, we narrow the scope of our inter-
est to optimize a high-dimensional problem that has an
unknown low-dimensional active subspace as efﬁciently
as possible. We benchmarked and demonstrated the opti-
mization results in 10,000D and 1M dataset, with a smart
scheduler and tracker in HPC environments with 20 con-
current workers.
2
Bayesian optimization: Methodology
For the sake of clarity and consistency, the following
symbols are used and annotated throughout the paper.
x ∈X ⊂RD: inputs,
z ∈Z ⊂Rd: random embedded inputs,
Xu ∈X ⊂RD: inducing inputs,
Zu ∈Z ⊂Rd: random embedded inducing inputs,
u ∈R : inducing random embedded outputs,
y ∈R: outputs,
D: dimensionality of x (before embedding),
d ≪D: dimensionality of z (after embedding),
A ∈RD×d: normal random matrix.
2.1
Classical Gaussian Process and Bayesian opti-
mization
Assume that f is a function of x, where x ∈X is a D-
dimensional input, and y is the observation. Let the dataset
D = (xi,yi)n
i=1, where n is the number of observations. A
GP regression assumes that f = f1:n is jointly Gaussian,
and the observation y is normally distributed given f,
f|x1,...,xn ∼N (m,K),
(1)

y|f,σ2 ∼N (f,σ2I),
(2)
where the element of m is µi := m(xi) and Ki,j := k(xi,x j).
The covariance kernel K is a choice of modeling co-
variance between inputs. At an unknown sampling loca-
tion x, the predicted response is described by a posterior
Gaussian distribution, where the posterior mean is
µn(x) = m(x)+ k(x)⊤(K+ σ2I)−1(y −m),
(3)
and the posterior variance is
σ2
n = k(x,x)−k(x)⊤(K+ σ2I)−1k(x),
(4)
where k(x) is the covariance vector between the query
point x and x1:n. The classical GP formulation assumes
stationary covariance matrix, which only depends on the
distance r = ∥x −x′∥. Several most common kernels for
GP include [28]
kMat´ern1(x,x′) = θ2
0 exp(−r),
kMat´ern3(x,x′) = θ2
0 exp(−
√
3r)(1 +
√
3r),
kMat´ern5(x,x′) = θ2
0 exp(−
√
5r)

1 +
√
5r + 5
3r2

,
ksq-exp(x,x′) = θ2
0 exp

−1
2r2

.
The log-likelihood function can be written as
log p(y|x1:n,θ) = −n
2 log(2π)−1
2 log|Kθ + σ2I|
−1
2(y −m)⊤(Kθ + σ2I)−1(y −m).
(5)
Optimizing the log marginal likelihood function yields the
hyper-parameter θ at the computational cost of O(n3) due
to the cost to compute the inverse of the covariance matrix.
We adopt the notation from Qui˜nonero-Candela et
al. [29, 30] but reinstate the non-zero mean assumption1.
Denote the training and testing function values as f and
f∗, respectively, the joint GP prior could be rewritten in a
probabilistic manner, i.e.
p(f,f∗) = N

m
m

,

Kf,f K∗,f
Kf,∗K∗,∗

,
(6)
which leads to the Gaussian predictive distribution by
1Qui˜nonero-Candela et al. [30] assumed m = 0.
Bayes’ rule,
p(f∗|y) =
Z
p(f,f∗|y)df
=
1
p(y)
Z
p(y|f)p(f,f∗)df
= N (m+ K∗,f[Kf,f + σ2I]−1(y −m),
K∗,∗−K∗,f[Kf,f + σ2I]−1Kf,∗),
(7)
as any conditional of a Gaussian distribution is also Gaus-
sian 2.
Denote µ(x), σ2(x), and θ as the posterior mean, the
posterior variance, and the hyper-parameters of the objec-
tive GP model, respectively. θ is obtained by maximiz-
ing the log likelihood estimation over a plausible chosen
range. Let φ(·) and Φ(·) be the standard normal probabil-
ity distribution function and cumulative distribution func-
tion, respectively, and xbest = argmax
1≤i≤n
f(xi) be the best-so-
far sample. Rigorously, the acquisition function should
be written as a(x;{xi,yi}n
i=1,θ), but for the sake of sim-
plicity, we drop the dependence on the observations and
simply write as a(x) and E(·) is implicitly understood as
Ey∼p(y|Dn,x)(·).
The PI acquisition function [31] is deﬁned as
aPI(x) = Pr(y > f(xbest)) = E

1y> f(xbest)

= Φ(γ(x)),
(8)
where
γ(x) = µ(x)−f(xbest)
σ(x)
,
(9)
indicates the deviation away from the best sample. The
PI acquisition function is constructed based on the idea of
binary utility function, where a unit reward is received if
a new best-so-far sample is found, and zero otherwise.
The EI acquisition function [32,33,34,35] is deﬁned
as
aEI(x) = σ(x)·(γ(x)Φ(γ(x))+ φ(γ(x)).
(10)
The EI acquisition is constructed based on an improve-
ment utility function, where the reward is the relative dif-
ference if a new best-so-far sample is found, and zero oth-
erwise. A closely related generalization of the EI acquisi-
tion function, called knowledge-gradient (KG) acquisition
function, has been suggested in [36]. Under the assump-
tions of noise-free and the sampling function is restricted,
2If P(f,g) = N
a
b

,
 A C
C⊤B

then P(f|g) = N (a + CB−1(y −
b),A−CB−1C⊤) (cf. Appendix A [29]).

the EI acquisition function is recovered from the KG ac-
quisition function. If the EI acquisition function is rewrit-
ten as
aEI(x) = E[max(y, f(xbest))−f(xbest)]
= E[max(y−f(xbest,0)]
= E

(y−f(xbest)+
,
(11)
then the KG acquisition function is expressed as
aKG(x) = E[maxµn+1(x)|xn+1 = x]−max(µn(x)) (12)
for one-step look-ahead acquisition function.
The UCB acquisition function [37, 38, 39] is deﬁned
as
aUCB(x) = µ(x)+ κσ(x),
(13)
where κ is a hyper-parameter describing the acquisition
exploitation-exploration balance. Here, we adopt the κ
computation from Daniel et al. [40], where
κ = √νγn,
ν = 1,
γn = 2log
 
nD/2+2π2
3δ
!
,
(14)
and D is the dimensionality of the problem, and δ ∈(0,1)
[39].
2.2
Sparse Gaussian process
We brieﬂy review different approaches presented by
Qui˜nonero-Candela et al. [29, 30] before adopting the
fully independent condition (FIC) as the underlying sparse
GP for BO, which approximates the covariance matrix
using the low-rank Nystr¨om approximation K ≈eK =
Kn×mK−1
m×mKm×n (cf.
Section 8.1 [41]) and scales as
O(nm2 + m3) instead of O(n3). For n ≫m, this method
scales as O(nm2).
Qui˜nonero-Candela et al. [30] provided an extensive
discussion and theoretical comparison between different
sparse GP approaches. Following Qui˜nonero-Candela et
al. [29, 30] and Chalupka et al. [42], Vanhatalo et al. [43,
44], we introduce the inducing variables u as values of the
GP (as also f and f∗) and marginalize u in the predictive
distribution as
p(f∗,f) =
Z
p(f∗, f,u)du =
Z
p(f∗,f|u)p(u)du,
(15)
where p(u) = N (m,Ku,u). In sparse GP approximations,
the joint prior is approximated by assuming that f∗and f
are conditionally independent given u, i.e.
p(f∗,f) ≈q(f∗,f) =
Z
q(f∗|u)q(f|u)p(u)du.
(16)
In the noise-free settings, the training conditional is
p(f|u) = N (m+ Kf,uK−1
u,u(u−m), Kf,f −Qf,f)
(17)
whereas the test conditional is
p(f∗|u) = N (m+ K∗,uK−1
u,u(u−m), K∗,∗−Q∗,∗), (18)
where Q·,· is deﬁned as
Qa,b := Ka,uK−1
u,uKu,b.
(19)
It is noted that K∗,∗−Q∗,∗= K∗,∗−K∗,uK−1
u,uKu,∗is a
Schur complement of K, i.e. K/Ku,u (cf. Rasmussen [41]
Section 8.6). The exact likelihood and inducing prior re-
main the same, i.e.
p(y|f) = N (f,σ2I),
(20)
and
p(u) = N (m,Ku,u).
(21)
2.2.1
Subset of regressors (Deterministic Inducing
Conditional approximation)
The Subset of Regressors (SoR) approximate condi-
tional distributions are given by
qSoR(f|u) = N (m+ Kf,uK−1
u,u(u−m),0),
(22)
and
qSoR(f∗|u) = N (m+ Kf,uK−1
∗,u(u−m),0),
(23)
with zero conditional covariance. Following Equation 16,
the effective prior is therefore
qSoR(f,f∗) = N
m
m

,
Qf,f Qf,∗
Q∗,f Q∗,∗

,
(24)
where Q·,· is deﬁned in Equation 19. The predictive dis-
tribution is computed as
qSoR(f∗|y) = N (m+ Q∗,f[Qf,f + σ2I]−1(y −m),
Q∗,∗−[Q∗,f + σ2I]−1Qf,∗)
= N (m+ σ−2K∗,uΣKu,f(y −m), K∗,uΣKu,∗),
(25)
where
Σ = [σ2Ku,fKf,u + Ku,u]−1.
(26)

2.2.2
Deterministic Training Conditional approxi-
mation (DTC)
Let the projection f = m+ Kf,uK−1
u,u(u−m), then
p(y|f) ≈q(y|u) = N (m+ Kf,uK−1
u,u(u−m),σ2I)
(27)
By imposing a deterministic training conditional and re-
taining the usual likelihood and the exact test conditional,
qDTC(f|u) = N (m+ Kf,uK−1
u,u(u−m),0)
(28)
and
qDTC(f∗|u) = p(f∗|u),
(29)
under the joint prior implied by DTC as
qDTC(f,f∗) = N

m
m

,

Qf,f Qf,∗
Q∗,f K∗,∗

,
(30)
the predictive distribution is given by
qDTC(f∗|y) = N (m+ Q∗,f[Qf,f + σ2I]−1(y −m),
K∗,∗−Q∗,f[Qf,f + σ2I]−1Qf,∗)
, (31)
where Σ is deﬁned in Equation 26. It is noted that K∗,∗−
Q∗,∗is positive semideﬁnite and that the variance of DTC
is always larger or equal to that of SoR and the DTC does
not correspond exactly to a GP.
2.2.3
Partially Independent (Training) Conditional
(PIC)
The Partially Independent (Training) Conditional
(PIC) approximations assumes the training conditional
qPIC(f|u) = N (m+Kf,uK−1
u,u(u−m),BlockDiag[Kf,f−Qf,f]),
(32)
and testing conditional
qPIC(f∗|u) = p(f∗|u),
(33)
where BlockDiag[·] is a block-diagonal matrix. The effec-
tive prior implied by PIC is
qPIC(f,f∗) = N

m
m

,

Qf,f −BlockDiag[Qf,f −Kf,f] Qf,∗
Q∗,f
K∗,∗

,
(34)
which leads to the predictive distribution of
qPIC(f∗|y) = N (m+ Q∗,f[Qf,f + Λ]−1(y −m),
K∗,∗−Q∗,f[Qf,f + Λ]−1Qf,∗)
= N (m+ K∗,uΣKu,fΛ−1(y −m),
K∗,∗−Q∗,∗+ K∗,uΣKu,∗)
,
(35)
where
Σ = [Ku,u + Ku,fΛ−1Kf,u]−1
and
Λ =
BlockDiag[Kf,f −Qf,f + σ2I] by utilizing the Sherman-
Morrison-Woodbury formula.
2.2.4
Fully Independent (Training) Conditional ap-
proximation (FIC)
If the BlockDiag[·] is replaced by Diag[·], then the
PIC prior becomes the Fully Independent (Training) Con-
ditional (FIC) prior
qFIC(f,f∗) = N
m
m

,
Qf,f −Diag[Qf,f −Kf,f] Qf,∗
Q∗,f
K∗,∗

.
(36)
which leads to the predictive distribution of
qFIC(f∗|y) = N (m+ K∗,uΣKu,fΛ−1(y −m),
K∗,∗−Q∗,∗+ K∗,uΣKu,∗)
,
(37)
where Σ = [Ku,u + Ku,fΛ−1Kf,u]−1 and Λ = Diag[Kf,f −
Qf,f + σ2I], which is nearly identical with Equation 35
except for the deﬁnition of Λ.
With this formulation,
we recover the SSGP approach proposed by Snelson and
Ghahramani [45].
2.2.5
Training sparse GP
Following Qui˜nonero-Candela et al. [29, 30], the
marginal likelihood conditioned on the inducing inputs is
given by
q(y|Xu) =
Z Z
p(y|f)q(f|u)p(u|Xu)dudf
=
Z
p(y|f)q(f|Xu)df.
(38)
Using the corresponding deﬁnitions of Λ (depending on
the choice of sparse GP models3), the log marginal likeli-
hood is
logq(y|Xu,θ) = −n
2 log(2π)−1
2 log|Qf,f + Λ|
−1
2(y −m)⊤[Qf,f + Λ]−1(y −m),
(39)
3ΛSoR = ΛDTC = σ2I, ΛPITC = BlockDiag[Kf,f −Qf,f]+σ2I, ΛFIC =
Diag[Kf,f −Qf,f]+σ2I.

which is strikingly similar to the case of classical GP as in
Equation 5. Invoking Sherman-Morrison-Woodbury for-
mula4 and realizing that Qf,f = Kf,uK−1
u,uKu,u by Equation
19, then
[Qf,f + Λ]−1 = [Λ+ Kf,uK−1
u,uKu,f]−1
= Λ−1 −Λ−1Kf,u[Ku,u + Ku,fΛ−1Kf,u]−1
Ku,fΛ−1.
(40)
Optimizing the log marginal likelihood yields the hyper-
parameters θ as in the case of the classical GP.
An alternative training approach is to maximize the
(variational) evidence lower bound (ELBO) [46,47] of the
true log marginal likelihood in Equation 39 as
ELBO(θ,Xu) = log[N (y|m,σ2I+ Qf,f)]
−1
2σ2 Tr

Kf,f −Kf,uK−1
u,uKu,f

(41)
In either approach, the overall computational cost is
O(nm2) to compute Σ [48], O(m) and O(m2) to compute
the posterior mean and variance, respectively [30]. This is
to contrast with the complexity of O
1
3n3

for Cholesky,
O
2
3n3

for LU, and O
4
3n3

for QR decomposition
algorithms (cf. Table C.2 [49]).
2.3
High-dimensional Bayesian optimization via ran-
dom embeddings
We adopt the random embeddings proposed by Wang
et al. [19, 20] for reducing the dimensionality by rotat-
ing the input with a random matrix A.
Of similar yet
distinct idea is the active subspace method by Constan-
tine et al [50, 27]. It is worthy to mention that there has
been some signiﬁcant efforts to reduce the dimensionality
in Bayesian optimization using active subspace [51, 52].
However, the true difﬁculty lies in the approximation of
the high-dimensional gradients in the classical GP ap-
proach, which is originally gradient-free, in order to ob-
tain an optimal rotation matrix on the Stiefel [51, 52] or
Grassmann manifolds5 [54,55] in the active subspace ap-
proach. This, unnecessarily, complicates the optimization
problem (by assigning the additional task of discovering
the active subspace, which is usually treated as a con-
strained manifold optimization problem) that is already
challenging in high-dimensional space.
Random embeddings [19, 20], on another hand, do
not suffer from the task of obtaining the active subspace.
4(A+UBV⊤)−1 = A−1 −A−1U(B−1 +V ⊤A−1U)−1V ⊤A−1.
5If A ∈RD×d with aij
i.i.d
∼N (0,1), then Q = A(A⊤A)−1/2 (i.e. A =
QR) is uniformly distributed on the Stiefel manifold Vd,D (cf Theorem
2.2.1 [53]).
It turns out that one does not completely require a pri-
ori knowledge of the active subspace for optimization pur-
poses. The random embeddings approach completely ig-
nores the task of discovering the active subspace, but in-
stead focuses on exploiting the existence of an (unknown)
active subspace to reduce the dimensionality of the prob-
lem. As explained by Letham et al. [56], random embed-
dings comes with a strong theoretical guarantee (Theorem
3) because by the Johnson-Lindenstrauss lemma [57], ran-
dom projections can approximately preserve ℓ2-distance
preserved, up to a (1 ± ε)-factor [21], without requiring
data to learn the embedding.
It is noted that alterna-
tive embedding approach is also discussed in HeSBO by
Nayebi et al [21] based on hashing.
Algorithm 1 REMBO algorithm [20] with deviation from
BO highlighted.
1: draw a random matrix A ∈RD×d : aij
i.i.d
∼N (0,1)
2: choose the bounded region set Z ⊂Rd
3: D0 ←∅
4: for i = 1,2,··· do
5:
locate
next
sampling
point
zi+1 ←argmax
z∈Z
a(z) ∈Rd
6:
query Di+1 ←Di ∪{zi+1, f(pX (Azi+1))}
7:
update GP
8: end for
Following Wang et al. [19,20], we brieﬂy summarize
REMBO formulation in Algorithm 1.
Deﬁnition 1. A function f : RD →R is said to have ef-
fective dimensionality de with de ≤D if
there exists a linear subspace T of dimension de such
that for all x⊤∈T ⊂RD and x⊥∈T ⊥⊂RD, where
T ⊥denotes the orthogonal complement of T ; and
de is the smallest integer with this property.
T is called the effective subspace of f and T ⊥the con-
stant subspace.
Theorem 2 (cf. Theorem 2 [20]). Assume that we are
given a function f : RD →R with effective dimensionality
de and a random matrix A ∈RD×d where aij
i.i.d
∼N (0,1)
and d ≥de. Then, with probability 1, for any x ∈RD, there
exists a z ∈Rd such that f(x) = f(Az).
A signiﬁcant corollary of Theorem 2 is the exis-
tence of z∗∈Rd such that f(x∗) = f(Az∗), where x∗=
argmax
x∈X
f(x) is the global optimum. Therefore, instead
of optimizing f(x) in the high-dimensional space X ⊂
RD, one could optimize the function f(Az) in the low-
dimensional space Z ⊂Rd, which is the main idea of
REMBO [20]. To resolve the topology and magnitude

difference between X and AZ, one actually optimizes the
function f(pX (Az)), where pX (Az) = argmin
x∈X
∥x −Az∥2
is projection operator. This also suggests choosing Z =

−1
ε max{log(de),1}, 1
ε max{log(de),1}
de
, as described
in Theorem 3.
We follow Wang et al. [20] to choose
ε = logd
d
, which implies Z ⊆[−
√
d,
√
d]d, conserva-
tively.
Theorem 3 (cf. Theorem 3 [20]). Suppose we want to
optimize a function f : RD →R with effective dimension
de ≤d subject to the box constraint X ⊂RD, where X is
centered around 0. Suppose further that the effective sub-
space T of f is such that T is the span of de basis vectors,
and let x∗
⊤∈T ∩X be an optimizer of f inside T . If A is
a D × d random matrix with independent standard Gaus-
sian entries, there exists an optimizer z∗∈Rd such that
f(Az∗) = f(x∗
⊤) and ∥z∗∥2 ≤
√de
ε ∥x∗
⊤∥2 with probability
at least 1 −ε.
Technical proof of Theorem 3 relies on Edelman’s
theorem (cf.
Theorem 3.4 [58] and the original pa-
per [59]), which is built upon the framework of Gaussian
random projection. This work would be incomplete with-
out stating the Johnson-Lindenstrauss lemma in this pa-
per’s notation.
Theorem 4 (Johnson-Lindenstrauss lemma (cf. Lemma
15 [60])). Given n points {xi}n
i=1, each of which is in RD,
A ∈RD×d be such that aij
i.i.d
∼
1
√
d N (0,1), and let z ∈
Rd deﬁned as z = A⊤x. Then, if d ≥9logn
ε2 −ε3 , for some
ε ∈

0, 1
2

, then with probability at least 1
2, all pairwise
distances are preserved, i.e. for all i, j, we have
(1−ε)∥xi −x j ∥2
2 ≤∥zi −zj∥2
2 ≤(1+ε)∥xi −x j ∥2
2 (42)
2.4
Asynchronous parallelism
We adopt the asynchronous parallel BO framework
in Tran et al. [62], which leverages the idea of batch-
sequential parallel BO in Tran et al.
pBO-2GP-3B
[61] and fully desynchronizes the workers across the
batch. However, in this work, to demonstrate the idea of
Scalable3-BO, we exclude the GP-Hedge algorithm [63],
as well as the constraint module, and focus on the numer-
ical Scalable3-BO method with different acquisition func-
tions. Figure 1 highlights the difference between batch-
sequential parallel and asynchronous parallel BO meth-
ods, where in the asynchronous parallel, workers do not
need to wait for others to ﬁnish their jobs in order to
launch their next jobs. In the nutshell, the asynchronous
feature is implemented by constantly checking if any job
has been ﬁnished, and subsequently assigns idle worker(s)
with corresponding task and batch, whether it is to ex-
ploit/explore or purely explore. The asynchronous parallel
feature is implemented on SLURM and PBS schedulers,
as well as regular multi-core workstations.
The main idea of parallel BO methods proposed by
Tran et al. [61, 62] is built on top of previous works of
GP-BUCB-AUCB by Desautels et al. [24] and GP-UCB-
PE by Contal et al [25]., where the underlying GP is tem-
porarily “hallucinated” by the GP posterior mean. The
hallucination is removed and the underlying GP is up-
dated whenever the true response is available. To include
constraints, another GP or probabilistic binary classiﬁer is
used to distinguish feasible versus infeasible inputs. How-
ever, in the scope of this paper, constraints are not con-
sidered, and thus, there are only two batches: one batch
for maximizing the acquisition function, whereas another
batch for maximizing the GP posterior variance. Algo-
rithm 2 summarizes GP-UCB-PE algorithm proposed by
Contal et al. [25], where the second For loop iterates
through the batch and wait until the last worker ﬁnishes
its job, as illustrated in Figure 1a.
2.5
Proposed
method:
Scalable3-Bayesian-
Optimization
GPstuff [43, 44] is used as the underlying sparse GP
implementation, where ELBO is used to train sparse GP
as described in Equation 41. Even though we could also
optimize the inducing variable Xu in the sparse GP formu-
lation, in this paper, Xu is obtained using Latin hypercube
sampling as a quasi-Monte Carlo approach to further relax
the computational cost to train the sparse GP.
Without loss of generality, we assume that f(·) is
rescaled in Z = [−
√
d,
√
d]d, otherwise, it could be
rescaled by 2
√
d
d x −x
x−x −
√
d
d6, where x and x are the
lower- and upper-bound of x, respectively. Algorithm 3
summarizes the Scalable3-BO approach proposed in this
paper. We note that there is always a chance for the em-
bedding contains or does not contains the optimum, thus
multiple runs are required. Choosing the dimensionality
d also has an effect on this probability, as larger d corre-
sponds to higher chance of containing the optimum and
slower to converge and vice versa [56].
Figure 2 illustrates the concept of embedding from
a low-dimensional space Z to a high-dimensional space
X . Since x = Az, we could consider xi = 1
d
d
∑
j=1
aijzj, with
1 ≤i ≤D. For d = 1, because aij
i.i.d
∼N (0,1) and zj ∼
U[−1,1], it is easy to show that E[xi] = 0 and V[xi] = 1
3.
Indeed, the probability density function of x is fX(x) =
1
√
8πΓ

0, x2
2

for x > 0 and fX(x) = fX(−x) for x < 0,
6The function (b−a) x−x
x−x +a is an afﬁne map from [x,x] to [a,b].

(a) Batch-sequential parallel.
(b) Asynchronous parallel.
Fig. 1: Difference between batch-sequential and asynchronous parallelizations. In batch-sequential parallelization [61]
(Figure 1a), all workers need to wait until the batch is ﬁnished before moving on to the next batch. In asynchronous
parallelization [62] (Figure 1b), all the workers receive the most up-to-date information and work independently with
each other. Asynchronous parallelization is more efﬁcient than batch-sequential parallelization because it reduces idle
time for workers.
Algorithm 2 GP-UCB-PE [25].
1: for i = 0,1,··· do
2:
update GP
3:
locate next sampling point xi+1 ←argmax
x∈X
a(x)
4:
for j = 0,··· ,BatchSize−1 do
5:
update GP
6:
locate next sampling point xi+1 ←argmax
x∈X
σ2(x)
7:
end for
8: end for
Algorithm 3 Scalable3-BO algorithm.
Input: dataset Dn = (x,y)n
i=1, dimensionality d > de, max number of inducing points m, f(·) with scaled input in
[−
√
d,
√
d]d, bounds [x,x]
1: draw a random matrix A ∈RD×d : aij
i.i.d
∼N (0,1)
⊲A is a Gaussian random matrix
2: set Z ⊂Rd = [−
√
d,+
√
d]d
3: D0 ←∅
4: while convergence criteria not met do
5:
while computational budget is not available do
⊲threshold the computational budget
6:
wait and check periodically if there is any update
7:
end while
8:
update input, output, and status for all cases
⊲if not complete then hallucinate
9:
update dataset Di
10:
determine batch to ﬁll
⊲exploit/explore or purely explore
11:
locate next sampling point: zi+1 = argmax
z∈Z
a(z) ∈Rd
12:
embed, normalize, scale, and translate: x∗
i+1 ←x+
1
d Azi+1 +
√
d
d
2(
√
d)d
⊙(x−x)
⊲⊙is Hadamard product
13:
project xi+1 to X : xi+1 ←pX (x∗
i+1)
⊲pX (z) = argmin
x∈X
∥x −z∥2
14:
query Di+1 ←Di ∪{zi+1, f(xi+1)}
⊲decouple the query and the main optimizer
15:
hallucinate the sparse GP
16:
sample inducing inputs Zu, where |Zu| = min{|X|,m}
⊲Latin hypercube sampling, |·| denotes cardinality
17:
update the sparse GP
⊲fully independent condition sparse GP (Section 2.2.4)
18: end while

x ∈RD
1
=
D rows
A
d cols
z ∈Rd
1
Fig. 2: A random embedding or a random projection x =
Az is built as a corollary from the Johnson-Lindenstrauss
lemma, where A is a random normal matrix.
where Γ(·) is the upper incomplete Gamma function. For
d > 1, if zj ∼U[−
√
d,
√
d]d, then V[xi] = dd
3 , but the
probability density function of x does not have any closed-
form representation.
Therefore, we perform a Monte
Carlo simulation with 106 samples to check what the prob-
abilities of x ∈[−1,1] and x ∈[−
√
d,
√
d]d are as a func-
tion of d, under the assumption that z ∼U[−
√
d,
√
d]d is
uniformly distributed.
Fig. 3: Probability of x ∈[−1,1] and x ∈[−
√
d,
√
d]d
for x = 1
d Az (scaled) and x = Az (unscaled) for z ∈Z =
[−
√
d,
√
d]d is uniformly distributed.
Figure 3 shows the results of the Monte Carlo sim-
ulation, where nearly all the options are associated with
zero probability.
This means after the convex projec-
tion pX (·), nearly all the inputs will be located at bound-
aries, which is undesirable.
Figure 3 also justiﬁes the
bounds of [−
√
d,
√
d]d for X before scaling and transla-
tion to the real bounds of [x,x]. Indeed, the probability of
x = 1
d Az ∈[−
√
d,
√
d]d is approximately 90.6%, which
means approximately 9.4% of the evaluation (under uni-
form prior assumption) will need the convex projection
operator pX (·), which is not ideal but it is the best and
stable choice compared to others, as shown Figure 3.
3
Numerical benchmark
We consider the second objective function in several
problems of the ZDT test suite [64] for multi-objective op-
timization problems, where the goal is to minimize f2(x),
as well as a modiﬁed sphere function. We set the dimen-
sionality D = 10,000 to test out the capability of the pro-
posed method.
3.1
Single-objective (modiﬁed) ZDT test suite
To make the input space X centered around 0, we re-
place
D
∑
i=2
xi with
 
D
∑
i=2
xi
!2
to shift the domain from [0,1]D
to [−1,1]D. It is noted that in the ZDT test suite, there are
only two active directions: [1,0,··· ,0] and [0,1,··· ,1],
which correspond to x1 and
D
∑
i=2
xi.
The global optimal
point for the unscaled ZDT test suite is f(x∗) = 0, where
the optimizer is x∗= [1,0,··· ,0] ∈[0,1]D.
3.1.1
ZDT1
For a D-dimensional input x ∈[0,1]D, a more general
ZDT1 second-objective function can be described as [64]
f2(x) = g

1 −
rx1
g

,
(43)
where g = 1 + 9
D
∑
i=2
xi
D−1.
The modiﬁed ZDT1 function, which is deﬁned on
[−1,1]D, is
f2(x) = g

1 −
s
x2
1
g

,
(44)
where g = 1 + 9
 
D
∑
i=2
xi
D−1
!2
.

3.1.2
ZDT2
For a D-dimensional input x ∈[0,1]D, the second-
objective ZDT2 function can be described as [64]
f2(x) = g
"
1 −
x1
g
2#
,
(45)
where g = 1 + 9
D
∑
i=2
xi
D−1.
The modiﬁed ZDT2 function, which is deﬁned on
[−1,1]D, is
f2(x) = g
"
1 −
x1
g
2#
,
(46)
where g = 1 +
 
9
D
∑
i=2
xi
!2
.
3.1.3
ZDT3
For a D-dimensional input x ∈[0,1]D, the second-
objective ZDT3 function can be described as [64]
f2(x) = g

1 −
rx1
g −
x1
g sin(10πx1)

,
(47)
where g = 1 + 9
D
∑
i=2
xi
D−1.
The modiﬁed ZDT3 function, which is deﬁned on x ∈
[0,1]D, is
f2(x) = g

1 −
s
x2
1
g −
x2
1
g sin(10πx2
1)

,
(48)
where g = 1 + 9
 
D
∑
i=2
xi
!2
3.2
Sphere function
We consider a valley-shaped parabolic function
f(x) =
 
D
∑
i=1
xi
!2
(49)
on [0,1]D, which has a 1d effective dimension of
D
∑
i=1
xi
along the direction (1,··· ,1). The test function 49 could
be more generalized to
f(x) =
de
∏
j=1
 
D
∑
i=1
w(j)
i xi
!2
(50)
with de effective dimension in the direction of ej, 1 ≤j ≤
de, where ej = [w(j)
1 ,··· ,w(j)
d ].
4
Numerical results
4.1
Data scalability – Effect of data size
Here we conduct a simple stress test for the FIC
sparse GP framework used in this paper by considering
the sphere function described in Equation 49, where both
the size of the dataset as well as the number of inducing
points are varied. We compare both the training time, test-
ing time, and testing accuracy to expose their trade-offs.
The benchmark is conducted on Intel Xeon Platinum 8160
CPU @ 2.10GHz supported by RHEL 7.1 (Maipo) with
180 GB of memory. To be fair, the same test set of 1,000
points are held separately with respect the number of data
points, where the training points and inducing points are
chosen via Latin hypercube sampling. The dimensional-
ity of the test is 3 on the domain of [−1,1]3. The number
of data points varies as 101,102,...,106, with the max-
imum number of data points is set at 1M. The number
of inducing points varies from 10,50,100,...,300, which
is the rank of the low-rank matrix Ku,u. Figures 4, 5,
and 6 present the training time, testing time, and accu-
racy of the underlying sparse GP used in this Scalable3-
BO framework, respectively. At the extreme of n = 106
and m = 300, it takes approximately 49 minutes to ﬁt the
sparse GP. The root mean square error (RMSE) does not
seem to decrease signiﬁcantly for this particular 3D test-
ing function and seem to have reached its limit at 10−5.
However, more tests are needed before a conclusion can
be drawn.
4.2
Effect of dimensionality
The proposed Scalable3-BO method is benchmarked
using the modiﬁed ZDT test suite, as well as the sphere
function described in Section 3. Here, the Mat´ern kernel
ν = 3/2, k(x,x′) = θ2
0 exp(−
√
3r)(1+
√
3r), is used. Fig-
ures 7, 8, 9, and 10 describe the convergence plot of the
modiﬁed ZDT1, ZDT2, ZDT3, and sphere benchmarking
functions, respectively. For the ZDT test suite, the dom-
inant factor is g, and while the global optimum could be
close to 0, we are more interested in the convergence rate
and how well the proposed framework performs in pes-
simistically high-dimensional problems. In that sense, a
fast convergence to 100 on the scale of the objective func-
tion in a short time can be considered as a fair achieve-
ment.

Fig. 4: Benchmark of training time.
Fig. 5: Benchmark of testing time.
4.3
Effect of batch size – Computing scalability
In this section, we examine the scalability and perfor-
mance of the asynchronous parallel feature in Scalable3-
BO with a standard 4D Hartmann function. The objective
function is described as
f(x) =
1
0.839
"
1.1 −
4
∑
i=1
αi exp
 
−
3
∑
j=4
Aij(xj −Pij)2
!#
,
(51)
Fig. 6: Benchmark of accuracy.
Fig. 7: ZDT1 (Equation 44) convergence plot with D =
10,000, d = 10.
Fig. 8: ZDT2 (Equation 46) convergence plot with D =
10,000, d = 3.
where
A
=




10
3
17 3.50 1.7 8
0.05 10
17
0.1
8 14
3
3.5 1.7
10
17 8
17
8 0.05 10 0.1 14



,
P
=
10−4




1312 1696 5569 124 8283 5886
2329 4135 8307 3736 1004 9991
2348 1451 3522 2883 3047 6650
4047 8828 8732 5743 1091 381



,
and

Fig. 9: ZDT3 (Equation 48) convergence plot with D =
10,000, d = 3.
Fig. 10: Sphere (Equation 49) convergence plot with D =
10,000, d = 10.
α = (1.0,1.2,3.0,3.2)T on the domain of [0,1]4.
To
mimic the computational expensive cost of real-world
engineering simulations, we impose a uniformly dis-
tributed random computational cost, i.e. t ∼U[t,t]. In
this example, we set t = 30s, t = 900s, and study the
convergence behavior as a function of workers.
We
compare the performance in terms of physical wall-clock
waiting time. To be fair, all runs start with the exactly
same number (i.e. two) and locations of initial sampling
points.
Figure 11 shows the superior numerical performance
as larger batch size yield a better optimization perfor-
mance in term of time, statistically speaking. The clas-
sical sequential BO (with batch size of 1) simply takes
much longer compared to its parallel variant for a slightly
expensive application. Figure 12 shows a typical sched-
ule for asynchronous parallel BO with batch size of 10,
where workers is nearly continuously assigned jobs, ex-
cept for the small downtime of ﬁtting GP and searching
for the next sampling point. Therefore, the idle time for
workers is minimized, further enhancing the effectiveness
and efﬁciency of BO algorithms.
Fig. 11: Effect of batch size on the wall-clock time.
Fig. 12: Worker schedule for asynchronous parallel BO
with batch size of 10.
5
Discussion
To some extent, Scalable3-BO fully enables computa-
tionally expensive applications, if there is sufﬁcient com-
puting resources. With the usage of the sparse GP, the
number of data points is no longer a primary issue with
expensive applications. However, one should be careful
when encountering high-dimensional applications, as the
employment of the sparse GP alone does not guarantee
optimization efﬁciency on high-dimensional problems.
The Scalable3-BO framework can be considered as
the generalized parallel extension of the classical BO. To
recover the classical and sequential BO algorithm, one can
- set A = ID×D to not use the random embedding fea-
ture,
- set number of worker to 1,
- assign the inducing points to be exactly the same
with the training inputs.
Also, it is non-trivial to consider the impact for each of

these cases.
Some theoretical results provided by De-
sautels et al. [24], Contal et al. [25] and Gupta et al.
[65] gave more insight to the batch cumulative regrets
at the order of O
 r
T logT
B
!
for GP-UCB-PE and of
O
 r
T log(TB)
B
!
for GP-BUCB, where T is the num-
ber of iterations and B is the batch size. Therefore, the
cumulative regret is sublinear, and because GP-BUCB is
a no-regret algorithm, Scalable3-BO is also a no-regret al-
gorithm as well since it is derived from GP-BUCB and
GP-UCB-PE.
Comparing to the local GP approaches, so called the
subset of data approach [29, 30], the low-rank sparse GP
approximation is more competitive in terms of theoretical
formulation and predictive accuracy, with computational
complexity of O(nm2). The loss of accuracy in local GP
approaches is mainly attributed to the vague correlation
between data in different clusters or subsets of data. Nev-
ertheless, both approaches remain interesting and beg for
further research.
BO is a ﬂexible optimization framework that natu-
rally lends itself to multi-ﬁdelity [66,67], multi-objective
[68, 69] optimization problems with applications to com-
putational solid mechanics [70, 71, 72] and ﬂuid mechan-
ics [73].
It is also worthy to mention that the asyn-
chronous parallel feature for HPC is currently supported
in DAKOTA [74].
A closely related method for linearly reducing dimen-
sionality is active subspace, which carefully investigates
the spectral decomposition of E[∇f(x)∇f(x)⊤] by singu-
lar value decomposition. Typically, how fast the eigen-
spectrum of E[∇f(x)∇f(x)⊤] decays can be revealed by
the singular value decomposition, where eigenvalues are
arranged in descending order. Theoretical guarantees al-
low truncation of eigenvalues and subsequently dimen-
sionality reduction within a controlled tolerance as usu-
ally done in active subspace [50, 27]. However, the goal
of active subspace is to accurately approximate a function
using a reduced basis, whereas the goal of random embed-
ding in BO is to optimize under an unknown subspace.
While these two concepts can be cross-cutting, random
embedding is arguably more efﬁcient because it does not
require the BO method to discover the active subspace on-
the-ﬂy. Additive GP for high-dimensional problems offer
a similar ﬂavor, but this method directly targets the kernel
k(x,x′) instead of the inputs x itself.
6
Conclusion
In this work, we introduce Scalable3-BO – a robust
and scalable BO framework implemented with the sparse
GP, random embedding, and asynchronous parallelization
– to tackle data scalability issue, high-dimensional prob-
lems on HPC platforms for computationally expensive ap-
plication. We demonstrate the scalability of the proposed
framework up to 1M data points, 10,000D problems with
small effective dimensionality, and 20 workers in HPC en-
vironment.
Acknowledgment
This work was supported by the US Department of
Energy, Ofﬁce of Advanced Scientiﬁc Computing Re-
search, Field Work Proposal 20-023231. Sandia National
Laboratories is a multimission laboratory managed and
operated by National Technology and Engineering So-
lutions of Sandia, LLC., a wholly owned subsidiary of
Honeywell International, Inc., for the U.S. Department of
Energy’s National Nuclear Security Administration under
contract DE-NA-0003525. The views expressed in the ar-
ticle do not necessarily represent the views of the U.S.
Department of Energy or the United States Government.
References
[1] Bostanabad, R., Chan, Y.-C., Wang, L., Zhu, P.,
and Chen, W., 2019. “Globally approximate Gaus-
sian processes for Big Data with application to data-
driven metamaterials design”. Journal of Mechani-
cal Design, 141(11).
[2] Zhang, Y., Ghosh, S., Pandita, P., Subber, W., Khan,
G., and Wang, L., 2020. “Remarks for scaling up a
general Gaussian process to model large dataset with
sub-models”. In AIAA Scitech 2020 Forum, p. 0678.
[3] van Stein, B., Wang, H., Kowalczyk, W., B¨ack, T.,
and Emmerich, M., 2015. “Optimally weighted clus-
ter kriging for big data regression”. In International
Symposium on Intelligent Data Analysis, Springer,
pp. 310–321.
[4] van Stein, B., Wang, H., Kowalczyk, W., Emmerich,
M., and B¨ack, T., 2016. “Fuzzy clustering for opti-
mally weighted cluster kriging”. In 2016 IEEE inter-
national conference on fuzzy systems (FUZZ-IEEE),
IEEE, pp. 939–945.
[5] Tran, A., Liu, D., He-Bitoun, L., and Wang, Y.,
2020. “Data-driven acceleration of ﬁrst-principles
saddle point and local minimum search based on
Gaussian processes”. In Uncertainty Quantiﬁcation
in Multiscale Materials Modeling, Elsevier.
[6] Tran, A., He, L., and Wang, Y., 2018.
“An efﬁ-
cient ﬁrst-principles saddle point searching method
based on distributed kriging metamodels”. ASCE-
ASME Journal of Risk and Uncertainty in Engineer-
ing Systems, Part B: Mechanical Engineering, 4(1),
p. 011006.
[7] Tran, A., Tran, M., and Wang, Y., 2019.
“Con-
strained mixed-integer Gaussian mixture Bayesian
optimization and its applications in designing frac-
tal and auxetic metamaterials”. Structural and Mul-
tidisciplinary Optimization, pp. 1–24.

[8] Nguyen-Tuong, D., Seeger, M., and Peters, J., 2009.
“Model learning with local Gaussian process regres-
sion”. Advanced Robotics, 23(15), pp. 2015–2034.
[9] Abdulah, S., Ltaief, H., Sun, Y., Genton, M. G., and
Keyes, D. E., 2017. “ExaGeoStat: A high perfor-
mance uniﬁed framework for geostatistics on many-
core systems”. arXiv preprint arXiv:1708.02835.
[10] Akbudak, K., Ltaief, H., Mikhalev, A., and Keyes,
D., 2017.
“Tile low rank Cholesky factorization
for climate/weather modeling applications on many-
core architectures”. In International Supercomputing
Conference, Springer, pp. 22–40.
[11] Abdulah, S., Ltaief, H., Sun, Y., Genton, M. G., and
Keyes, D. E., 2018. “Parallel approximation of the
maximum likelihood estimation for the prediction
of large-scale geostatistics simulations”.
In 2018
IEEE International Conference on Cluster Comput-
ing (CLUSTER), IEEE, pp. 98–108.
[12] Litvinenko, A., Sun, Y., Genton, M. G., and Keyes,
D. E., 2019. “Likelihood approximation with hierar-
chical matrices for large spatial datasets”. Computa-
tional Statistics & Data Analysis, 137, pp. 115–132.
[13] Chen, H., Zheng, L., Al Kontar, R., and Raskutti,
G., 2020. “Stochastic gradient descent in correlated
settings: A study on Gaussian processes”. Advances
in Neural Information Processing Systems, 33.
[14] Eriksson, D., Pearce, M., Gardner, J., Turner, R. D.,
and Poloczek, M., 2019.
“Scalable global opti-
mization via local Bayesian optimization”. In Ad-
vances in Neural Information Processing Systems,
pp. 5497–5508.
[15] Liu, H., Ong, Y.-S., Shen, X., and Cai, J., 2020.
“When Gaussian Process meets Big Data: A review
of scalable GPs”. IEEE transactions on neural net-
works and learning systems, 31(11), pp. 4405–4423.
[16] Bach, F., 2009. “High-dimensional non-linear vari-
able selection through hierarchical kernel learning”.
arXiv preprint arXiv:0909.0844.
[17] Duvenaud, D., Nickisch, H., and Rasmussen, C. E.,
2011. “Additive Gaussian processes”. arXiv preprint
arXiv:1112.4394.
[18] Durrande, N., Ginsbourger, D., and Roustant, O.,
2012.
“Additive covariance kernels for high-
dimensional Gaussian process modeling”.
In An-
nales de la Facult´e des sciences de Toulouse:
Math´ematiques, Vol. 21, pp. 481–499.
[19] Wang, Z., Zoghi, M., Hutter, F., Matheson, D., Fre-
itas, N., et al., 2013.
“Bayesian optimization in
high dimensions via random embeddings”. AAAI
Press/International Joint Conferences on Artiﬁcial
Intelligence.
[20] Wang, Z., Hutter, F., Zoghi, M., Matheson, D., and
de Feitas, N., 2016. “Bayesian optimization in a bil-
lion dimensions via random embeddings”. Journal
of Artiﬁcial Intelligence Research, 55, pp. 361–387.
[21] Nayebi, A., Munteanu, A., and Poloczek, M., 2019.
“A framework for Bayesian optimization in embed-
ded subspaces”. In International Conference on Ma-
chine Learning, PMLR, pp. 4752–4761.
[22] Li, C., Gupta, S., Rana, S., Nguyen, V., Venkatesh,
S., and Shilton, A., 2018.
“High dimensional
bayesian optimization using dropout”.
arXiv
preprint arXiv:1802.05400.
[23] Li, C.-L., Kandasamy, K., P´oczos, B., and Schnei-
der, J., 2016. “High dimensional Bayesian optimiza-
tion via restricted projection pursuit models”. In Ar-
tiﬁcial Intelligence and Statistics, PMLR, pp. 884–
892.
[24] Desautels, T., Krause, A., and Burdick, J. W., 2014.
“Parallelizing exploration-exploitation tradeoffs in
Gaussian process bandit optimization”. The Jour-
nal of Machine Learning Research, 15(1), pp. 3873–
3923.
[25] Contal, E., Buffoni, D., Robicquet, A., and Vayatis,
N., 2013. “Parallel Gaussian process optimization
with upper conﬁdence bound and pure exploration”.
In Joint European Conference on Machine Learning
and Knowledge Discovery in Databases, Springer,
pp. 225–240.
[26] Kandasamy, K., Krishnamurthy, A., Schneider, J.,
and Poczos, B., 2017.
“Asynchronous parallel
Bayesian optimisation via Thompson sampling”.
arXiv preprint arXiv:1705.09236.
[27] Constantine, P. G., 2015. Active subspaces: Emerg-
ing ideas for dimension reduction in parameter stud-
ies. SIAM.
[28] Shahriari, B., Swersky, K., Wang, Z., Adams, R. P.,
and de Freitas, N., 2016. “Taking the human out of
the loop: A review of Bayesian optimization”. Pro-
ceedings of the IEEE, 104(1), pp. 148–175.
[29] Qui˜nonero-Candela, J., and Rasmussen, C. E., 2005.
“A unifying view of sparse approximate Gaussian
process regression”. Journal of Machine Learning
Research, 6(Dec), pp. 1939–1959.
[30] Qui˜nonero-Candela, J., Rasmussen, C. E., and
Williams, C. K., 2007.
“Approximation methods
for Gaussian process regression”. Large-scale ker-
nel machines, pp. 203–224.
[31] Kushner, H. J., 1964. “A new method of locating the
maximum point of an arbitrary multipeak curve in
the presence of noise”. Journal of Basic Engineer-
ing, 86(1), pp. 97–106.
[32] Mockus, J., 1975. “On Bayesian methods for seek-
ing the extremum”. In Optimization Techniques IFIP
Technical Conference, Springer, pp. 400–404.
[33] Mockus, J., 1982. “The Bayesian approach to global
optimization”. System Modeling and Optimization,
pp. 473–481.
[34] Bull, A. D., 2011. “Convergence rates of efﬁcient
global optimization algorithms”. Journal of Machine

Learning Research, 12(Oct), pp. 2879–2904.
[35] Snoek, J., Larochelle, H., and Adams, R. P., 2012.
“Practical Bayesian optimization of machine learn-
ing algorithms”. In Advances in Neural Information
Processing Systems, pp. 2951–2959.
[36] Scott, W., Frazier, P., and Powell, W., 2011. “The
correlated knowledge gradient for simulation opti-
mization of continuous parameters using Gaussian
process regression”. SIAM Journal on Optimization,
21(3), pp. 996–1026.
[37] Auer, P., 2002.
“Using conﬁdence bounds for
exploitation-exploration trade-offs”. Journal of Ma-
chine Learning Research, 3(Nov), pp. 397–422.
[38] Srinivas, N., Krause, A., Kakade, S. M., and Seeger,
M., 2009.
“Gaussian process optimization in the
bandit setting: No regret and experimental design”.
arXiv preprint arXiv:0912.3995.
[39] Srinivas, N., Krause, A., Kakade, S. M., and Seeger,
M. W., 2012. “Information-theoretic regret bounds
for Gaussian process optimization in the bandit set-
ting”.
IEEE Transactions on Information Theory,
58(5), pp. 3250–3265.
[40] Daniel, C., Viering, M., Metz, J., Kroemer, O., and
Peters, J., 2014.
“Active reward learning.”.
In
Robotics: Science and Systems.
[41] Rasmussen, C. E., 2006. Gaussian processes in ma-
chine learning. MIT Press.
[42] Chalupka, K., Williams, C. K., and Murray, I., 2013.
“A framework for evaluating approximation meth-
ods for Gaussian process regression”.
Journal of
Machine Learning Research, 14(Feb), pp. 333–350.
[43] Vanhatalo, J., Riihim¨aki, J., Hartikainen, J., Jyl¨anki,
P., Tolvanen, V., and Vehtari, A., 2012. “Bayesian
modeling with Gaussian processes using the GPstuff
toolbox”. arXiv preprint arXiv:1206.5754.
[44] Vanhatalo, J., Riihim¨aki, J., Hartikainen, J., Jyl¨anki,
P., Tolvanen, V., and Vehtari, A., 2013.
“GP-
stuff: Bayesian modeling with Gaussian processes”.
Journal of Machine Learning Research, 14(Apr),
pp. 1175–1179.
[45] Snelson, E., and Ghahramani, Z., 2005.
“Sparse
Gaussian processes using pseudo-inputs”.
Ad-
vances in neural information processing systems, 18,
pp. 1257–1264.
[46] Titsias, M., 2009. “Variational learning of inducing
variables in sparse Gaussian processes”. In Artiﬁcial
Intelligence and Statistics, pp. 567–574.
[47] Titsias, M. K., 2009. “Variational model selection
for sparse gaussian process regression”.
Report,
University of Manchester, UK.
[48] Qui˜nonero-Candela, J., and Hansen, L. K., 2004.
“Learning with uncertainty-gaussian processes and
relevance vector machines”. Technical University of
Denmark, Copenhagen.
[49] Higham, N. J., 2008. Functions of matrices: Theory
and computation. SIAM.
[50] Constantine, P. G., Dow, E., and Wang, Q., 2014.
“Active subspace methods in theory and practice:
applications to kriging surfaces”. SIAM Journal on
Scientiﬁc Computing, 36(4), pp. A1500–A1524.
[51] Tripathy, R., Bilionis, I., and Gonzalez, M., 2016.
“Gaussian processes with built-in dimensionality re-
duction: Applications to high-dimensional uncer-
tainty propagation”.
Journal of Computational
Physics, 321, pp. 191–223.
[52] Gautier, R., Pandita, P., Ghosh, S., and Mavris, D.,
2020.
“A fully Bayesian gradient-free supervised
dimension reduction method using Gaussian pro-
cesses”. arXiv preprint arXiv:2008.03534.
[53] Chikuse, Y., 2012. Statistics on special manifolds,
Vol. 174. Springer Science & Business Media.
[54] Seshadri, P., Yuchi, S., and Parks, G. T., 2019. “Di-
mension reduction via Gaussian ridge functions”.
SIAM/ASA Journal on Uncertainty Quantiﬁcation,
7(4), pp. 1301–1322.
[55] Hokanson, J. M., and Constantine, P. G., 2018.
“Data-driven polynomial ridge approximation using
variable projection”.
SIAM Journal on Scientiﬁc
Computing, 40(3), pp. A1566–A1589.
[56] Letham, B., Calandra, R., Rai, A., and Bakshy, E.,
2020. “Re-examining linear embeddings for high-
dimensional Bayesian optimization”. Advances in
Neural Information Processing Systems, 33.
[57] Johnson, W. B., and Lindenstrauss, J., 1984. “Ex-
tensions of Lipschitz mappings into a Hilbert space”.
Contemporary mathematics, 26(189-206), p. 1.
[58] Sankar, A., Spielman, D. A., and Teng, S.-H., 2006.
“Smoothed analysis of the condition numbers and
growth factors of matrices”. SIAM Journal on Ma-
trix Analysis and Applications, 28(2), pp. 446–476.
[59] Edelman, A., 1988.
“Eigenvalues and condition
numbers of random matrices”. SIAM journal on ma-
trix analysis and applications, 9(4), pp. 543–560.
[60] Mahoney, M. W.,
2016.
“Lecture notes on
randomized
linear
algebra”.
arXiv
preprint
arXiv:1608.04481.
[61] Tran, A., Sun, J., Furlan, J. M., Pagalthivarthi, K. V.,
Visintainer, R. J., and Wang, Y., 2019. “pBO-2GP-
3B: A batch parallel known/unknown constrained
Bayesian optimization with feasibility classiﬁcation
and its applications in computational ﬂuid dynam-
ics”. Computer Methods in Applied Mechanics and
Engineering, 347, pp. 827–852.
[62] Tran, A., McCann, S., Furlan, J. M., Pagalth-
ivarthi, K. V., Visintainer, R. J., Wildey, T., and
Eldred, M., 2020.
“aphBO-2GP-3B: A bud-
geted asynchronous-parallel multi-acquisition for
known/unknown constrained Bayesian optimization
on high-performing computing architecture”. arXiv
preprint arXiv:2003.09436.

[63] Hoffman, M., Brochu, E., and de Freitas, N., 2011.
“Portfolio allocation for bayesian optimization”. In
Proceedings of the Twenty-Seventh Conference on
Uncertainty in Artiﬁcial Intelligence, UAI’11, AUAI
Press, pp. 327–336.
[64] Zitzler, E., Deb, K., and Thiele, L., 2000. “Com-
parison of multiobjective evolutionary algorithms:
Empirical results”. Evolutionary computation, 8(2),
pp. 173–195.
[65] Gupta, S., Shilton, A., Rana, S., and Venkatesh, S.,
2018. “Exploiting strategy-space diversity for batch
Bayesian optimization”.
In International Confer-
ence on Artiﬁcial Intelligence and Statistics, PMLR,
pp. 538–547.
[66] Tran, A., Wildey, T., and McCann, S., 2020.
“sMF-BO-2CoGP: A sequential multi-ﬁdelity con-
strained Bayesian optimization for design applica-
tions”. Journal of Computing and Information Sci-
ence in Engineering, 20(3), pp. 1–15.
[67] Tran, A., Wildey, T., and McCann, S., 2019. “sBF-
BO-2CoGP: A sequential bi-ﬁdelity constrained
Bayesian optimization for design applications”.
In Proceedings of the ASME 2019 IDETC/CIE,
Vol. Volume 1: 39th Computers and Information
in Engineering Conference of International De-
sign Engineering Technical Conferences and Com-
puters and Information in Engineering Confer-
ence, American Society of Mechanical Engineers.
V001T02A073.
[68] Tran, A., Eldred, M., Wang, Y., and McCann, S.,
2020.
“srMO-BO-3GP: A sequential regularized
multi-objective constrained Bayesian optimization
for design applications”.
In Proceedings of the
ASME 2020 IDETC/CIE, Vol. Volume 1: 40th Com-
puters and Information in Engineering Conference
of International Design Engineering Technical Con-
ferences and Computers and Information in Engi-
neering Conference, American Society of Mechan-
ical Engineers.
[69] Tran,
A.,
Eldred,
M.,
Wang,
Y.,
and
Mc-
Cann, S.
“srMO-BO-3GP: A sequential regu-
larized multi-objective constrained Bayesian opti-
mization for design applications”.
arXiv preprint
arXiv:2007.03502.
[70] Tran, A., Tranchida, J., Wildey, T., and Thomp-
son, A. P., 2020. “Multi-ﬁdelity machine-learning
with uncertainty quantiﬁcation and Bayesian opti-
mization for materials design: Application to ternary
random alloys”. The Journal of Chemical Physics,
153, p. 074705.
[71] Tran, A., and Wildey, T., 2020. “Solving stochastic
inverse problems for property-structure linkages us-
ing data-consistent inversion and machine learning”.
JOM, 73, pp. 72–89.
[72] Tran, A., Mitchell, J. A., Swiler, L. P., and Wildey,
T., 2020.
“An active-learning high-throughput
microstructure calibration framework for process-
structure linkage in materials informatics”. Acta Ma-
terialia, 194, pp. 80–92.
[73] Tran, A., Furlan, J. M., Pagalthivarthi, K. V.,
Visintainer, R. J., Wildey, T., and Wang, Y.,
2019.
“WearGP: A computationally efﬁcient ma-
chine learning framework for local erosive wear pre-
dictions via nodal Gaussian processes”. Wear, 422,
pp. 9–26.
[74] Dalbey, K., Eldred, M. S., Geraci, G., Jakeman,
J. D., Maupin, K. A., Monschke, J. A., Seidl,
D. T., Swiler, L. P., Tran, A., Menhorn, F., et al.,
2020.
DAKOTA A Multilevel Parallel Object-
Oriented Framework for Design Optimization Pa-
rameter Estimation Uncertainty Quantiﬁcation and
Sensitivity Analysis: Version 6.12 Theory Manual.
Tech. rep., Sandia National Lab.(SNL-NM), Albu-
querque, NM (United States).

