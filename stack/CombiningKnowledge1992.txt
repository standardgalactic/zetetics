COMBINING KNOWLEDGE BASES CONSISTING OF 
FIRST-ORDER THEORIES 
CHITTA BARAL, SARIT 
KRAUS, JACK MINKER, AND v. s. SUBRAHMANIAN 
Department of Computer Science and 
University of Maryland Institute for Advanced Computer Studies, University of Maryland, 
College Park, MD 20742, U.S. 
Consider the construction of an expert system by encoding the knowledge of different experts. 
Suppose the knowledge provided by each expert is encoded into a knowledge base. Then the process 
of combining the knowledge of these different experts is an important and nontrivial problem. We 
study this problem here when the expert systems are considered to be first-order theories. We present 
techniques for resolving inconsistencies in such knowledge bases. We also provide algorithms for 
implementing these techniques. 
Key words: knowledge bases, first-order theories. 
1. INTRODUCTION 
Consider the construction of an expert system by encoding the knowledge of different 
experts. Suppose that the knowledge provided by each expert is encoded into a knowledge 
base. Then the process of combining the knowledge of these different experts is an 
important and nontrivial problem. 
The problem is important because the user of the expert system so constructed should 
have access to the knowledge of each of the experts. In particular, he/she should be able 
to use the knowledge of two different experts to jointly derive a fact that neither of the 
experts, individually, knew. In other words, one important feature involved in consulting 
multiple experts is to p o d  their knowledge together and thus obtain knowkdge that no 
individual expert previously had. 
The problem is nontrivial because individual experts can, and often do, hold conflicting 
views on their domain of expertise. Two attorneys involved in a legal defense may well 
hold conflicting views on the best possible defense strategy, just as two doctors may well 
differ in their assessment of a patient’s malady. In a logic knowledge base, these conflicting 
opinions manifest themselves in the form of inconsistencies. Classical logic would then 
indicate that the resulting knowledge base is meaningless-a 
state of affairs that is clearly 
inappropriate in this context. Just as the attorneys and doctors would work together to 
reconcile their views in the interests of the defendant or patient, so should a knowledge 
base management system reconcile these inconsistencies and allow sensible decisions to 
be drawn. The key problem here is: how should these inconsistencies be reconciled? This 
is the problem addressed in this paper. 
Baral, Kraus, and Minker (1989) formalize the notion of combining knowledge bases 
when each knowledge base is a normal Horn logic program (set of rules with only atoms 
allowed in the head) and assume that the union of the knowledge bases is stratified (no 
recursion through negation). They assume the presence of world knowledge in the form 
of integrity constraints, which all the individual knowledge bases satisfy, and the combined 
knowledge base is required to satisfy. They present methods to obtain a maximally com- 
bined knowledge base with respect to the union of knowledge bases that is consistent with 
respect to the integrity constraints. Since they consider each knowledge base to be a 
normal Horn logic program, the union of the knowledge bases is always consistent and 
the combined knowledge base they obtain is maximal with respect to it. 
Computational Inielligence, Volume 8 ,  Number 1 ,  1992 
45 

46 
COMPUTATIONAL INTELLIGENCE 
In this paper, we consider each knowledge base as a first-order theory. All knowledge 
is expressed in the same underlying logical language.' The set of integrity constraints is 
also assumed to be a first-order theory. In this case, the union of the knowledge bases is 
not necessarily consistent. Because of this, in the absence of integrity constraints, to have 
the combined knowledge base as the union of the knowledge bases, we need a semantics 
for inconsistent theories. Many such semantics have been suggested in the past (Blair and 
Subrahmanian 1988, 1989, da Costa, Subrahmanian, and Vago 1991, Gelfond and Lifschitz, 
Grant 1974, 1975, 1977, 1978, Kowalski and Sadri, and Subrahmanian 1989). In this paper, 
we use the cautious approach of Grant and Subrahmanian (1990) to characterize the 
semantics of inconsistent theories. In the cautious approach, the semantics of an incon- 
sistent theory is the semantics obtained by considering all maximally consistent subsets 
of the inconsistent theory. A sentence is considered true (false) if it is true (false) in all 
maximally consistent subsets of the original theory. 
In the next section, we will present a scenario that will be used throughout the paper 
to illustrate the basic intuitions behind our technical development. In section 3 of the 
paper, we discuss the cautious semantics of inconsistent theories in the presence of 
integrity constraints. In the subsequent section, we formalize combining a set of theories 
having the same priority, in the presence of integrity constraints and its relationship with 
view update approaches (Fagin, Kuper, Ullman, and Vardi 1986 and Fagin, Ullman, and 
Vardi 1983). We then allow the theories to be prioritized and formalize the notion of 
combining a set of prioritized theories. 
2. A MOTIVATING SCENARIO 
Inconsistencies can easily arise when multiple reasoning agents each amve at a par- 
ticular view of the world. While these individual views are usually self-consistent, they 
often tend to conflict with one another. We now present a simple scenario that we will use 
over and over again to motivate the basic ideas in the paper. 
The Scenario: At 1:00 A.M. on January 14, 1990, Don was shot outside the Good Times 
Bar in Washington. The street was more or less deserted (it being late in the night) except 
for four people: Don (who got shot), the murderer, and two rather drunk individuals, John 
and Bill, who were on the street. John is an 85-year-old man who was about 100 yards 
away from the shooting, while Bill is 30 years old. Bill was about 75 yards away from the 
shooting. Their stories follow. 
John's story: 
1. The murderer wore an orange coat. 
2. The murderer wore no hat. 
3. John knows the murderer got away in a car (as he heard the engine revving up and 
the car taking off), but he was hiding in a doorway and was too scared to look, and 
hence cannot tell us anything about the car. 
Bill's story: 
1. The murderer wore a dark (probably black) coat. 
2. The murderer wore no hat. 
3. The murderer drove off in a pink Mercedes. 
'Bard, Kraus, and Minker (1990) present methods to translate between knowledge bases expressed in 
different logical languages. 

COMBINING KNOWLEDGE BASES 
47 
If we look at John’s story and Bill’s story, they are self-consistent. If Bill had not been 
around, we would probably have accepted John’s version of the story (and vice versa). 
However, their stories conflict with each other (if we make the reasonable assumption that 
the murderer wore only one coat). This assumption has the status of an integrity constraint: 
for the purposes of the story, it is a statement that all parties are willing to accept. 
Integrity constraints: 
1. The murderer wore only one coat at the time of the murder. 
2. Based on other evidence, the police present a convincing case that the murderer knew 
3. Don’s close cronies are Jeff, Ed, and Tom. 
4. There is no evidence that any of these three individuals had either borrowed or bought 
5. Jeff and Ed each own a pink Mercedes. Tom doesn’t know how to drive. 
6. Jeff has an orange coat. 
7. Ed has a black coat. 
8. There is no possibility of any collusion between Jeff and Ed. 
the victim well. 
a coat recently; so the only coats they could have worn were their own. 
Based on the above story, we are led to suspect Ed or Jeff, but not both. Only one of 
them was the murderer. If we accept John’s story, then Jeff is the murderer. If we accept 
Bill’s story, then Ed is the murderer. We are faced with the following problem: Who did 
it? There are numerous alternatives. 
Alternative 1: In a court of law, the guilt of a person must be established beyond all 
reasonable doubt. This cannot be established in this case. For example, if Jeff is on trial 
for the murder of Don, then a reasonable doubt can be cast on his guilt by the defense. A 
similar situation would occur if Ed were on trial. This situation corresponds to the case 
where one views each and every possibility in the correctness of the witnesses’ statements. 
We accept a person as guiity if heishe turns out to be guilty in all of these different possible 
worlds. Thus, according to alternative 1, we can conclude that Jeff or Ed is guilty, but we 
can neither prove that Jeff is guilty nor can we prove that Ed is guilty. 
Alternative 2: We may be led to doubt the correctness of John’s statements. After all, 
he is 85 years old, as compared to Bill’s 30 years, and hence, presumably, Bill’s eyesight 
is better. Furthermore, Bill was much closer to the scene of the crime, and hence, one 
may feel that his evidence is more credible. In deciding who to prosecute (Ed or Jeff), 
the police may well decide that they can make a more compelling case against Ed based 
on Bill’s evidence. This alternative corresponds to the assignment of a priority to Bill’s 
evidence, rather than to John’s. 
Alternative 3: The third alternative is simply to conclude that the evidence is incon- 
sistent and to use the semantics of classical logic to conclude everything. 
These are only three possible scenarios. Each of these represents a reasonable way of 
reasoning about the body of evidence in front of us. We will illustrate the technical 
development of the paper by frequent reference to this example. 
3. CAUTIOUS SEMANTICS FOR INCONSISTENT THEORIES 
We consider a theory to be a set of well-formed formulas. Unless explicitly mentioned 
otherwise, theories will always be assumed to be finite. Several semantics for inconsistent 
theories have been discussed in Grant and Subrahmanian (1990). One of the approaches 
to characterize an inconsistent theory is to consider the maximally consistent subsets of 
the inconsistent theory. A maximally consistent subset of an inconsistent theory T is a 

48 
COMPUTATIONAL INTELLIGENCE 
theory that is a consistent subset of T, and that becomes inconsistent if any other sentence 
of T is added to it. Intuitively, each maximally consistent subset of T corresponds to a 
consistent state of the world that T is trying to characterize. In the presence of a set of 
worlds, one can either be bold and pick one of them as the “real” state of the world or 
one can be cautious (some call it skeptical) and consider all of them. Hence, in the cautious 
characterization of inconsistent theories, the truth value of a sentence L corresponds to 
the intuition: “Is L true WRT each and every maximally consistent state of affairs?” 
Maximal consistent’ subsets correspond to the normal default theories (Reiter 1980, Eth- 
erington 1988), and the cautious and bold approaches are similar to the characterizations 
of default theories based on truth in all its extensions and truth in a particular extension, 
respectively, due to Etherington (1988). 
Consider a theory T whose maximal consistent subsets are T I ,  . . . , T,. In the presence 
of integrity constraints (world knowledge that every theory has to satisfy), we have to 
consider only those worlds that are consistent with respect to the integrity constraints. 
The bold approach to doing this would be to consider only those Ti’s, 
1 I 
i I 
n, that 
satisfy the integrity constraints. Thus, maximal consistent subsets of T that do not satisfy 
the integrity constraints would be discarded. The cautious approach, on the other hand, 
would look at each Ti, 1 I 
i 5 n, and then find maximal subsets of Ti that are consistent 
with the integrity constraints. An example may clarify this point. 
Example 3.1. Suppose that our theory T consists of the following sentences: 
1. P + 9  
2. p - 1 4  
3. r 
4. P 
T has three maximally consistent sets: 
Ti = {1,2,3} 
T2 = {1,3,4) 
T3 = {2,3,4) 
Suppose that we have as an integrity constraint the single formula l ( r  & p ) .  TI satisfies 
ZC, but neither T2 nor T3 do. Thus, the “bold” approach would discard TZ and T3 and select 
TI. 
The cautious approach would also pick T I ,  but it would not discard T2 and T3. It 
would, instead, try to find maximal consistent subsets of TZ and T3 that satisfy the integrity 
constraint. In the case of each of T2, T3, this is achieved by discarding either 3 or 4. Hence, 
the cautious approach would look at the five sets: 
Ti 
T4 = {1,3} (obtained by discarding 4) from Tz) 
T5 = {2,3} (obtained by discarding 4) from T3) 
T6 = { 1,4} (obtained by discarding 3) from T2) 
T7 = {2,4} (obtained by discarding 3) from T3) 
0 
Example 3.2. With respect to the murder example described in the previous section, the 
cautious semantics would accept the conclusion “X is the murderer” iff X were the 
murderer irrespective of whether we chose to believe John or Bill. Thus, according to the 
cautious semantics, there would be no such individual X. However, the cautious semantics 

COMBINING KNOWLEDGE BASES 
49 
would allow us to conclude the sentence “Either Ed is the murderer or Jeff is the murderer” 0 
because this follows irrespective of whether we believe John or Bill. 
In the following definitions MAXCONS(P) and MAXCONS(P,IC) are maximal con- 
sistent subsets of P and maximal consistent subsets of P with priority to ZC. By maximal 
consistent subsets of P with priority to IC, we mean maximal consistent subsets of P U 
IC, which contain all elements of IC. 
Dejinition 3.1 (Maximal Consistency). Let P be a theory, and ZC be a set of integrity 
constraints. A subset Q C P is said to be maximally consistent with priority to ZC iff Q U 
ZC is consistent, and for every theory Q’ such that Q C Q’ C P, it is the case that Q’ U 
IC is inconsistent. MAXCONS(P,ZC) is the set of maximally consistent subsets of P with 
priority to ZC. When ZC is an empty set, then MAXCONS(P,ZC) is called MAXCONS(P) 
and is the set of maximally consistent subsets of P. 
Theorem 3.1 below shows that all theories possess at least one maximal consistent 
subset with respect to any consistent set of integrity constraints. 
Theorem 3.1. Suppose that P is any (possibly infinite) first-order theory and IC is any 
consistent set of integrity constraints. Then P U IC has at least one (possibly infinite) 
maximally consistent subset P‘ such that ZC C P’. (If P is finite, then its maximal consistent 
subsets are obviously finite.) 
Proof. P U ZC has at least one consistent subset that is a superset of ZC, namely ZC 
itself. Thus, iet CONS(P,IC) denote the set {qX C P U IC and X is consistent and ZC C 
X}, and let CONS(P) be defined as CONS(P, 0). Thus, CONS(P,ZC) f 0 because ZC E 
CONS(P,ZC). We show below that every ascending chain of elements in CONS(P) has an 
upper bound in CONS(P). The result then follows from Zorn’s lemma. 
Suppose that M I  C M2 C M3 C . . . is an ascending sequence of members of CONS(P), 
that is, each M, is a consistent subset of P U ZC and ZC G M,. Then M = U7=,Mi is an 
upper bound for this ascending sequence. Moreover, M is consistent, IC C M and M C 
P U ZC, that is, M E CONS(P). The only nonobvious part is the consistency of M. 
To see this, suppose that M is not consistent. Then, by the compactness theorem, 
there is a finite subset M’ C M such that M‘ is inconsistent. Let M’ = {yl, . . . , yn} for 
some integer n. Hence, for each 1 5 i 5 n, there is an integer, denoted cti such that yi E 
Mu(;). Let OL = max{a(l>, . . . , a(n)}. Then M’ C Mu. Hence, as M’ is inconsistent, Ma is also 
inconsistent, thus contradicting our assumption that each Mj, j 2 1, is in CONS(P). 
0 
A weaker version of the above theorem has been established by Grant and Subrah- 
manian (1990) (see corollary 3.1 below). An important point to note about MAXCONS(P) 
is that it depends upon the syntactic nature of P. For instance, if we take PI = {a,b, l a }  
and Pz = {(a & b), Tall then MAXCONS(PJ = {(a&}, {Ta,b}}, and so it is perfectly 
reasonable to cautiously conclude b from P1. On the other hand, MAXCONS(PZ) = {{(a 
& b)}, {-a}} from which we cannot cautiously conclude 6. Even though the theory {(a & 
b)} is logically equivalent to the theory {a,b} according to classical logic, this equivalence 
does not hold when we treat inconsistent theories nonclassically. 
The following corollary of Theorem 1 shows that all theories have at least one maxi- 
mally consistent subset. 

50 
COMPUTATIONAL INTELLIGENCE 
Corollary 3.1 (Grant and Subrahmanian 1990). 
consistent subset. 
Every theory P has at least one maximally 
Proof. Take IC to be the empty set in the proof of theorem 1. 
We now define a notion of entailment based on the cautious approach. 
Definirion 3.2 (t-v-Entailment) (Grant and Subrahmanian 1990). Suppose that P is a theory 
and F is a formula. A notion of entailment, I-v based on the cautious approach is defined 
as follows: P t-v F iff P‘ b F for every maximal consistent subset P’ C P .  
We now state some basic properties of h-entailment. 
Theorem 3.2 (Grant and Subrahmanian 1990). 
ground literals. Then: 
Suppose that P is a theory and L,L1,Lz are 
1. For all ground literals L, it is not the case that P t-v L and P t-v 4. 
2. P t v  (LI & Lz) iff P t-v LI and P I-V Lz. 
3. P kv F for all tautologies F of classical logic. 
0 
Example 3.3 Let P be: 
P v 14 
7 P  v 1 4  
r 
4 
In this case, MAXCONS(P) consists of three elements: 
b V 1 q  ; r ; q l ,  
b P  v 14 ; r ; 41. 
b V -4 ; TP V 74 ; 4. 
In this case, P FV r. But P fv q and P fv p and P f v  l q  and P VV 1p. 
The appendix contains algorithms that compute MAXCONS(P) and MAX- 
CONS(P,IC). The algorithms assume that the theories have a finite Herbrand base. Func- 
tion-free databases satisfy this condition. It is possible to determine the Herbrand consis- 
tency of function-free databases. A database is Herbrand consistent iff it has a Herbrand 
model. Note that Herbrand-consistent databases are always consistent in the usual sense 
of logic, though the converse is not necessarily true. However, it has become a standard 
practice in the deductive database (or “Datalog”) community to consider Herbrand con- 
sistency instead of ordinary first-order logical consistency. Throughout the rest of this 
paper, we will use the word “consistent” to refer to Herbrand consistency. 
When an inconsistent theory P consists of n sentences, the algorithm MAXCONSI(P) 
given in the appendix (Algorithm A .  l), constructs its maximal consistent subsets by 
determining the consistency of each subset of P of cardinality n - 1. All such consistent 
subsets are stored in a set S. For each inconsistent subset, its maximal consistent subsets 
are added to S. The set of maximal elements of S is MAXCONS(P). The algorithm 
MAXCONSl(P,IC), which is also in the appendix (Algorithm A.2), extends 
MAXCONSl(P) by allowing integrity constraints to be present. MAXCONSl(P,IC) tests 

COMBINING KNOWLEDGE BASES 
51 
the consistency of the union of ZC with each subset of P and designates some of these 
subsets as being maximally consistent with respect to ZC. 
Theorem 3.3 below proves that algorithm MAXCONSl(P) correctly computes the 
maximal consistent subsets of P. 
Theorem 3.3. 
Proof. [MAXCONS(P) C MAXCONSl(P)] Suppose X E MAXCONS(P). Then X = P - 
{CI, . . . , C,} for some integer r 3 0 where {CI, . . . , C,} C P. We proceed by induction 
on r. 
MAXCONS(P) = MAXCONS 1 (P) 
Base case: (r = 0). In this case, MAXCONS(P) = {P} = MAXCONSl(P). 
Inductive case: (r = k + 1) Consider P’ = P - {C.t+,}. Then Xis a maximal consistent 
subset of P’, and furthermore, X = P‘ - {C, . . . , C k } .  Therefore, by the induction 
hypothesis, X E MAXCONSl(P’). As X U {Ck+1} is inconsistent, Xis in MAXCONSl(P). 
[MAXCONSl(P) C MAXCONS(P)] Similar. 
0 
The following theorem demonstrates that algorithm MAXCONS I(P,ZC) correctly com- 
putes the maximal consistent subsets of P with respect to integrity constraints ZC. 
Theorem 3.4. 
Proof. Proceeds along exactly the same lines as the proof of Theorem 3. 
MAXCONS(P,ZC) = MAXCONS l(P,IC) 
0 
Returning to the motivating murder example in Section 2 ,  if we take P to be the union 
of John’s evidence and Bill’s evidence, then MAXCONS(P,ZC) consists of two theories 
TI and Tz. TI contains: 
I .  All integrity constraints and 
2. Sentences 1,2, 3 of John’s story and sentences 2 ,  3 of Bill’s story. 
Likewise, Tz contains: 
1. All integrity constraints and 
2. Sentences 2 and 3 of John’s story and sentences, 1,2, 3 of Bill’s story. 
Thus, using the MAXCONS(P,ZC) semantics, we may conclude that the murderer wore 
no hat (this being true in both TI and T2 above). However, we may not conclude anything 
about the color of the murderer’s coat. We may also conclude that the murderer drove 
away in a pink Mercedes. 
We now discuss a technique for computing MAXCONS(P) in cases when P is a finite 
set of clauses (a clause is a disjunction of literals). Throughout the rest of this section, we 
consider only sets of clauses. 
Definition 3.3 (Refutations). Suppose that T is a consistent set of clauses and D is a 
clause such that T U {D} 
is inconsistent. A refutation of D from T is a sequence C1, . . . , 
C, such that: 
I. C, is the empty clause 0 
and 
2. Each Ci, 1 I 
i 5 n is either in T U {D} or is a resolvent of two clauses C,C’ E T U 
CI, . . . , C, is called a minimal refutation of D from T if there is no strict subsequence of 
CI, . . . , C, which is also a refutation of D from T, that is, there is no sequence D1. . . . , 
D, such that {Dl, . . . , D,} C {Cl, . . . , C,} and if Di = Cj and Di+l = Cb, t h e n j  < k. 
{D} U {CI, . . . 9 Ci-1). 

52 
COMPUTATIONAL INTELLIGENCE 
Definition 3.4 (Potential Causes). Suppose that T is a consistent set of clauses and D is 
a clause such that T U {D} 
is inconsistent. Let % be some minimal refutation of D from 
T. Then the set 3 n T is said to be a potential cause of D. 
Example 3.4. 
Suppose that T is the following set of clauses: 
C1: a V  b 
C2: 
a V 7 b  
C3: a V  c 
C4: a V I C  
and D = l a .  There are two minimal refutations %I and 3
2
 of D from T where: 
9Il = C1, C2, a, D, 0 
a2 = C3, C4, a, D, 0 
(Actually, a few more minimal refutations may be obtained by rearranging the occurrences 
of some of the clauses in 
Thus, the potential causes of D are: PCI = {Cl,C2,} and 
0 
PC2 = {C3,C4} 
corresponding to %,a2, 
respectively. 
In the context of the murder scenario outlined in section 2, there is only one potential 
cause of the inconsistency, to wit, the following three sentences: 
1. John: The murderer wore an orange coat. 
2. Bill: The murderer wore a black coat. 
3. IC: The murderer wore only one coat at the time of the murder. 
If T is itself inconsistent, we may talk of refutations of the empty clause, 0, 
from T. This 
refers simply to different refutations of I7 from T. In this case, each minimal refutation of 
T gives rise to a potential cause of the inconsistency of T ,  to wit, the potential cause of 0 
WRT, the refutation we are currently considering. Given theorem T, MINS(T) is the set 
of minimal (WRT inclusion) potential causes of the inconsistency of T. 
Algorithm MAXCONS2, which is given in the appendix (Algorithm A.3), presents a 
different way of computing maximal consistent subsets of P. It performs this computation 
by identifying potential causes of inconsistencies and deleting some of them. In the re- 
maining lemma and theorems of this section, any unexplained notation will refer to the 
notation used in the MAXCONS2 algorithm. 
Theorem 3.5 below shows that algorithm MAXCONS2 correctly computes maximal 
consistent subsets of P. We first prove Lemma 3.1 and then use it to prove Theorem 3.5. 
Lemma 3.1 shows that, when we remove a minimal potential cause of an inconsistency 
from P, then the remaining theory is consistent. 
Lemma 3.1. 
Suppose that P is a set of clauses and Z E MINS(P). Then (P - Z) is 
consistent. 
Proof. Suppose (P - Z) is inconsistent. Then there is a minimal refutation of (P - 2). 
Let zl, . . . , z,,, be the members of (P - Z) (and hence of P) occumng in this refutation. 
Therefore, there exists an 1 5 i 5 n such that Si = {zl, . . . , z,,,}. 
But then, as 2 E MINS, 
there must exist a 1 5 j 5 m such that zj E 2. This implies that zj @ (P - 2)-a 
contradiction. 
Theorem 3.5. MAXCONS(P) = MAXCONS2(P) 

COMBINING KNOWLEDGE BASES 
53 
Proof. 
show that (P - X) E MINS. To do this, we need to show two things. 
EMAXCONS(P) C MAXCONS2(P)]. Suppose X E MAXCONS(P). It suffices to 
I. First we show that (P - X) n S, # 0 for all 1 I 
i 5 n. Suppose (P - X) n S, = 0 
for some 1 5 i I 
n. Then S, C X which contradicts the assumption that X is consistent. 
11. Next, we show that (P - X) is a minimal element of S' WRT inclusion. Suppose not. 
Then there is a 2 E MINS such that Z C (P - X). In particular, there exists an a E 
(P - X) - Z. But then, by lemma 3.1, (P - Z) would be a consistent subset of P .  But 
X C (P - Z), thus contradicting the maximality of X. 
[MAXCONS2(P) c MAXCONS(P)] Suppose X E MAXCONS2(P). Let SI, . . . , S, be 
all the potential causes of the inconsistency of P. If n = 0, then X = P E MAXCONS2(P). 
So assume IZ > 0. Then X = (P - Y) where Y = { a l ,  . . . , a,} and for all 1 5 i 5 n, 
a, E S, and Y E MINS. 
Claim 1: X is consistent. 
Proof of Claim 1: Suppose not. Then there exists an I 5 i 5 n such that S, c X .  In 
addition, a, E S,. But a, ($ X because X = (P - r). But this contradicts the statement that 
s, c x. 
Claim 2: X is maximally consistent. 
Proof of Claim 2: Suppose that, instead, there exists a maximal consistent X such that 
X C X c P .  Let X = (P - Y) and X' = ( P  - Y'). As X C X ,  Y' C Y. As X' is a maximal 
consistent subset of P ,  by the [MAXCONS(P) c MAXCONS2(P)] part of the proof, X' E 
MAXCONS2(P). Thus, Y' E MINS. But Y E MINS also. But this is a contradiction 
because Y' C Y. 
0 
Algorithm MAXCONS2(P,ZC), which is also in the appendix (Algorithm A.4), extends 
MAXCONS2(P) to the case when integrity constraints are present. The theorem below 
establishes that MAXCONS2(P,IC) correctly computes the maximal consistent subsets of 
P with respect to integrity constraints IC. 
Theorem 3.6. MAXCONS(P,ZC) = MAXCONS2(P,ZC) 
Proof. Similar to the proof of Theorem 3.5. 
0 
We now prove some results on the complexity of cautious entailment for propositional 
theories. 
Remark. 
cardinality of MAXCONS(T) is O(2"). 
Proof. 
For any n ,  there exists a propositional theory T of cardinality 2n such that the 
For any value of n consider the theory T, = {al, 1a1, . . . , a,, -IU,}. 
It can easily 
be proved that the cardinality of MAXCONS(T,) is 2". 
In order to place complexity results in context, we reiterate the following result due 
to Plaisted and Vardi. 
Theorem 3.7 (Plaisted 1984, Vardi 1982). The Herbrand satisfiability problem for clause 
form formulas is EXPTIME-complete. 
An immediate corollary is the following. 

54 
COMPUTATIONAL INTELLIGENCE 
Corollary 3.2. The problem: Given (as input) finite sets T and T’ of function-free wffs 
such that T C T’ , determining whether T is a maximal consistent subset of T’ is EXPTIME- 
hard. 
Hence, the problem of combining multiple theories seems to be one for which algorithms 
tend to be exponential in nature. 
4. 
COMBINING GENERAL THEORIES 
The problem of combining general theories is formalized as follows. We have a set of 
consistent theories and a set of integrity constraints.2 Each theory satisfies the integrity 
constraints. We would like to combine the given set of theories so that the combined 
theory is also consistent with respect to the integrity constraints and contains as much 
consistent information as possible. 
The combination of several theories often leads to a multiplicity of resulting theories. 
Hence, we need to set up a mechanism to work with sets of theories. 
Definition 4.1 (Flock). A flock (a term borrowed from Fagin, Kuper, Ullman, and Vardi 
(1986)) is a set of theories. The flock corresponding to a theory T is a set of subtheories 
of T. 
Usually, when we consider an inconsistent theory T, the flock of interest is the flock of 
all maximal consistent subsets of T. In order to define combinations of theories, we need 
to specify the properties that combination functions must satisfy. 
Definition 4.2 (Relation between jocks). Let F1 and F2 be flocks. F1 51 F2 iff (VT E 
F1)(3T’ E Fz): T C T’.3 
Definition 4.3 (Consistency). A flock F is said to be consistent with respect to a set of 
0 
integrity constraints ZC iff, for every theory T present in F, T U ZC is consistent. 
Definition 4.4 (Correctness). A flock F is said to be sl-correct with respect to 
theories Ti, - 
, Tk, if F 5 1  MAXCONS(T1 U 
. U Tk). 
0 
Using the properties of consistency and correctness defined above, we now present the 
concept of combination functions. 
Definition 4.5 (Combination of Theories). Let T1, - * * , T k  be a set of theories and ZC a 
set of integrity constraints, where each T1 satisfies ZC. A combination function C is a 
mapping from a set of theories and a set of integrity constraints into a flock satisfying the 
following three criteria. 
1. (Identity) C({T}, ZC) = {T). 
2. (Consistency) C((T1, * . - , Tk}, ZC) is consistent with respect to ZC. 
*Throughout this paper, we assume that, whenever we are combining theories TI, 
. . . , T, and WRT, the 
set IC of integrity constraints, then each Ti, 1 c i r n, is consistent. Note, however, that different Ti,T, 
may be 
mutually inconsistent for 1 5 i , j  5 n, i # j .  
3Many other orderings between flocks can also be defined. One such ordering is defined as: FI 5 2  F2 iff 
(VT E f)(3T’ E F2) : Cn(T) C Cn(T‘), where Cn(T) is the set of classical logic consequences of T. We do not 
explore this in this paper. 

COMBINING KNOWLEDGE BASES 
55 
3. (Correctness) C({T1, 
. . , Tk}, ZC) is -cl-correct with respect to the theories 
Ti * ’ * , Tk. 
Another useful property is associativity, which is defined as follows. 
 TI, . 
* , T,, C((&+I, . * 
* , Tk), IC)}, IC) 
= mm C((C((T1, * 
* 
a , T,}, IC), T,+17 * . . 9 Tk}, ZC 
= mm C((T1, . . . , Tk}, ZC); where P = rnm Q means Cn(P) = Cn(Q). 
0 
We now define three combination functions. The first two are skeptical in nature. The 
first combination function takes the union of the theories and the integrity constraints and 
looks at the maximal consistent subsets of this union with priority to the integrity con- 
straints. More formally, 
We now show that Comb1 is a valid combination function. 
Theorem 4.1. Combl is a combination function, that is, it satisfies the identity, consis- 0 
tency, and correctness criteria. Furthermore, CombI is associative. 
Note that the combination function CombI takes the union of theories TI, . . . , Tk and 
then finds the maximal subsets that are consistent with the integrity constraints, ZC. We 
now apply Combl to the murder example. 
Example 4.1 (Murder Example on CombI). Returning to the murder example. In this 
case, Comb, would take the two witness accounts (John and Bill) as two theories. Let us 
consider John’s three statements to constitute theory TI and Bill’s three statements to 
constitute theory TZ. In addition the set of eight integrity constraints is denoted ZC. Comb1 
would try to identify maximal subsets of TI U TZ that are consistent with IC. There would 
be two maximal consistent subsets, and the flock Comb~((Tl,T~},ZC) 
would consist of these 
two sets. The difference between the two is that one of these maximal sets contains the 
statement “The murderer wore an orange coat” (this set would tend to imp1ic;te Jeff as 
the murderer), while the other contains the statement “The murderer wore a dark coat” 0 
(this set would implicate Ed). 
The second combination function takes the union of the theories and finds its maximal 
consistent subsets. It then looks at all the theories in MAXCONS(Yi,ZO for all Yi E 
MAXCONS(Ti, U * 
U Tk). 
DeJinition 4.7. 
MAXCONS(Yi,ZC) where Yj E MAXCONS(T1 U * 
* 
* U Tk)}. 
Comb2({Tl, 9 
9 . , Tk},ZC) ’Sf maximal elements of S, where S = {X : X E 
The following example illustrates the two approaches. 
Example 4.2 Let the union of the theories T be: 
a 
b 
i a  V Tb 
C 

56 
COMPUTATIONAL INTELLIGENCE 
and the set of integrity constraints be ZC = {la V l c }  
MAXCONS(T,IC) = {{a, b}, {a, i a  V ~ b } ,  
{b, C, 
MAXCONS(T) = {Ti = { u , ~ , c } ,  Tz = {a, C ,  la V lb}, T3 = {b, C ,  la V ~ b } }  
MAXCONS(T1,IC) = {{a, b}, {c, b}} 
MAXCONS(T2,IC) = {{a, i a  V ib}, {c, i~ 
V ib}} 
MAXCONS(T3,IC) = {{b, C ,  i~ 
V lb}} 
V ib}} 
Hence, in this example, MAXCONS(T, IC) = maximal members of the set 
UT, 
E MAXCONS(T) MAXCONS(Ti,IC). 
a V b is true in all models of members of MAXCONS(T,ZC) and hence it is true with 
0 
respect to the combination of these theories. 
We now use the murder example to illustrate the behavior of Combz. 
Example 4.3 (Murder Example on Combz). Consider how Comb2 behaves WRT the 
murder scenario of section 2. Comb? would first construct MAXCONS(P) where P is the 
union of John's story and Bill's story. Note that P is perfectly consistent and hence 
MAXCONS(P) = {P}. 
(The fact that the murderer wore only one coat at the time of the 
murder is necessary for the inconsistency to arise.) Comb2 now computes the maximal 
elements of {X 1 X E MAXCONS(Y;,ZC) where Yi E MAXCONS(P)}. In this case, this 
0 
leads to exactly the same results as Combl. 
That these two seemingly different combination functions lead to the same results is 
not an accident, as shown in the following theorem. 
Theorem 4.2 MAXCONS(T,IC) = maximal members of the set S where S = {X : X E 
MAXCONS(Ti,ZC) where Ti E MAXCONS(T)} 
Proof. 
c 
Let X E MAXCONS(T,ZC). Then there exists a Y in MAXCONS(7') such that: (1) X n T 
c Y and (2) X E MAXCONS(Y,ZC). 
Consider such a Y. Suppose X @ MAXCONS(Y,ZC). Since X U ZC is consistent, this 
means that there is an X such that X C X ,  and such that X E MAXCONS(Y,ZC), but 
then our assumption that X E MAXCONS(T,ZC) is contradicted. Hence, X E MAX- 
CONS( Y,ZC). 
This proves that X E S. Since, X E MAXCONS(T,ZC), it has to be a maximal member 
of s. 
2 
Suppose X is a maximal element of S. Then there is a Ti E MAXCONS(7') such that X E 
MAXCONS(Ti,lC') and no Y such that X C Y and Y E MAXCONS(T,.,ZC) for some T j  E 
MAXCONS(T). This implies that X is consistent with IC. 
Suppose X @ MAXCONS(T,IC). Then there is an a such that X C a and OL E 
MAXCONS(T,IC). By the first part of the theorem, this means that 01 E MAXCONS 
(T,,IC), for some Ti E MAXCONS(T). This violates our initial assumption about X ,  which 
says that no such 
exists: a contradiction. Hence, X E MAXCONS(T,ZO. 

COMBINING KNOWLEDGE BASES 
57 
Corollary 4.1. Combz is an associative combination function. 
0 
The third function uses a bold approach. Here we consider any maximal consistent 
subset of the union of the given theories that satisfies the integrity constraints. It is defined 
as follows. 
Dejinition 4.8. 
IC is consistent.} 
Comb3({T1, . . , Tk},ZC sf {X : X E MAXCONS(Tl U - 
* U Tk) and X U 
Considering Example 4.2, we have MAXCONS(T) = {T1 = {a,b,c},Tz = {a,c,la V 
-b},T3 = {b,c,Ta V lb}}. 
Of the three theories in MAXCONS(T), only T3 is consistent with respect to IC = 
{ l a ,  V lc}. Hence, the third approach considers only T3. 
Unlike Combl and Combz, Comb3 is not associative. 
Theorem 4.3. Comb3 is a nonassociative combination funciton. 
0 
The proof that Comb3 is a combination function is a simple verification of the three 
conditions that a combination function must satisfy. The example below demonstrates the 
nonassociative nature of Comb3. 
Example 4.4. 
below: 
Consider the theories T1,T2,T3 and the set ZC of integrity constraints shown 
Tl = {(a v b),c} 
T2 = {la} 
T3 = {a,-c} 
IC = {-lb} 
In this case, combining Tl and TZ first and then combining the result with T3 yields a flock 
consisting of one set only: 
C({C({Ti Tz),IC), T3)JC) = {{a ,lc>>. 
the result with TI yields a flock containing three sets: 
However, combining T1 with the combination of T2 and T3 first and then combining 
C({Ti7C({T2,T3},IC>},zC) 
= {{a V b),a,c}, {(a V b)ta,-c}7 {c,ia>>. 
This shows that combining the theories Tl,T2,T3 in different orders leads to different 
results. 
0 
One may wonder what the relationship between combining theories using Comb1 and 
using Comb3 is. The theorem below shows that Comb3 may be viewed as a “bolder” 
combination strategy than Combl. 
Theorem 4.4. Let {T1, 
. . . , Tk} be a flock and IC a set of integrity constraints. Then: 
Combs((T1, . . . , Tk},ZO C Cornbd(T1, . . . , Tk},ZC). 
Proof. 
Suppose T E Comb3({Tl, . . . , Tk},ZC). Then T E MAXCONS(T1 U * 
* U Tk) 
and T U ZC is consistent. Consequently, T E MAXCONS(T1 U * 
* - U Tk,ZC). Hence, T 
0 
E Combl{T1, . . . , Tk},ZC). 

58 
COMPUTATIONAL INTELLIGENCE 
The distinction between Combl and Comb3 may be illustrated further by the following 
example: 
Example 4.5. 
below: 
Consider the theories T1,Tz, and the set of integrity constraints ZC shown 
TI = ((a v b),(- v c)) 
IC = {IC} 
{1c,(a v b),(-la v c)} 
{lC,CU v b),lb) 
{7c,(- v c),+) 
Tz = {Tb} 
In this case, Combl({T1 ,Tz},ZC) consists of the following three theories: 
On the other hand, Comb3({Tl,Tz},ZC) is the empty flock. 
0 
Comb3, when applied to the murder example, yields a different result than Combl and 
Combz. 
Example 4.6 (Murder Example WRT Comb3). Using Comb3, the murder example would 
result in the empty flock. This is because the union of John’s story and Bill’s story is 
consistent; however, the union is no longer consistent with ZC and hence is rejected by 
Comb3. 
The salient difference between Comb3 and Combl (and hence also Comb*) is that the 
is nonassociative and 
is bolder than Combl as it picks a subset of the set of theories picked by Combl. 
The nonassociativity o€ Comb3 restricts the applicability of Comb3 to situations where we 
want to combine theories according to a particular ordering. Such a situation may arise, 
for instance, if all theories are ranked, and we always combine them, starting from the 
lowest rank upwards. On the other hand, it appears to be easier, in practice, to compute 
Comb, than it is to compute Camp]. In the case of Comb3, we simply check if the maximally 
consistent subsets of TI U - 
- U Tk are consistent with the integrity constraints. Let Yl, 
. . . , Y, 
be these maximal consistent subsets. Those Yi’s, 1 5 i 4 m that are not consistent 
with ZC are discarded. The remainder are retained. In the case of Comb*, however, we 
would first (as before) find the maximal consistent subsets Y1, . . . , Y, of T, U * 
* 
* U Tk. 
We would then try to find maximal subsets of each of the Yi’S that are consistent with ZC. 
This is a more time consuming and laborious operation than simply checking if the Yi’s 
are consistent with ZC. Thus, we would recommend that, in time-critical situations, Comb3 
could be first computed to give a quick “forecast” of the results. If time remains to do a 
more detailed analysis, then Combl could be used. 
former: 
4.1 A More Practical Approach 
In the previous combination functions, we searched for all the maximally consistent 
subsets of the inconsistent theories. This is an extremely time-consuming process since it 

COMBINING KNOWLEDGE BASES 
59 
requires consistency checks in each step of the algorithm (Algorithm A.2). In this section, 
we would like to present a more practical algorithm. 
In addition, we are motivated by the following argument. We are combining several 
theories. Each of them is consistent, and the inconsistency arose from the union of the 
theories. We do not know which of the theories being combined contains erroneous 
information. We would like to search for a combination function that will include as much 
information as possible from the original theories. By “as much,” we mean as many clauses 
as possible, that is, theories that are maximal WRT cardinality rather than with respect to 
inclusion. 
The algorithm MAXCONS3 given in the appendix (Algorithm A.5) serves both pur- 
poses. Given theories T1, . . . , T k  and a set ZC of integrity constraints, it computes the 
largest possible subset (in terms of cardinality) of (TI U . 
U Tk) that are consistent with 
zc. 
Definition 4.9. Comb4({T1, - . , Tk},ZC) ‘2%f MAXCONS3(Tl U . . . U Tk,ZC). 
The intuitive motivation behind Comb4 is that “every time we discard something, we are 
(implicitly) saying that the discarded object constitutes a mistake made by the expert. As 
this information is obtained from experts, it seems appropriate to assume that they don’t 
make too many mistakes; hence we want to pick those maximal consistent subsets where 
the number of mistakes is minimized.” Comb4 thus seems to be suitable in situations where 
it is appropriate to make this assumption. The theorem below shows that Comb4 is bolder 
than Combl. 
Theorem 4.5. Comb4({T1, . - 
* , Tk},ZC) = maximal sets WRT cardinality of Combl 
({TI, * . . , Tk},ZC). 
Comb4 coincides with Combl on the murder example. The following example illustrates 
the difference between this approach and the MAXCONS(P) approach. 
Example 4.7. Consider the theory P below: 
d 
d - e  
d -  l e  
Td 
MAXCONS(P) contains exactly one element, { l d  + e;d + 7e;Td). Note, however, that, 
0 
in addition to this set, MAXCONS(P) contains {d + e;d), {d + le;d), {d,d + e}. 
The following result is easy to establish. 
Corollary 4.2. Let P be any first-order theory. MAXCONS3(P) C MAXCON(P). 
0 
We note that the inferences of MAXCONS3 are less cautious and more optimistic 
than those of MAXCONS: that is, everything that is inferred from MAXCONS is also 
inferred from MAXCONS3, but there is more information that is inferred from 
MAXCONS3 than from MAXCONS. A straightforward verification demonstrates that 
Comb4 is a combination function. 

60 
COMPUTATIONAL INTELLIGENCE 
Comb3 
Comb1 
II 
Comb4 C Comb2 
FIGURE 1. Subset Relationships of Different Combination Functions. 
Theorem 4.6. 
1. Comb4 is a combination function. 
2. Furthermore, for all theories T1, . . . , T,, and any set ZC of integrity constraints, 
Comb4({ T I ,  . . . , Tn},ZC) C Combl({ T I ,  . . . , T,},IC). 
An important point to note is that there is no obvious “subsetlike” relationship of the 
sort proved in Theorem 4.6 that links Comb, to Comb4. The following two examples 
confirm this. Example 4.8 shows that it may not always be the case that Comb3({Tl,T2),ZC) 
C Comb4({TI,T2),ZC), and Example 4.9 demonstrates that the reverse inclusion does not 
hold either. 
Example 4.8. Suppose TI,T2,1C are as given below: 
Ti = {*, 
u V b, TC} 
Tz = {lb, u V b} 
IC = { l C }  
In this case, MAXCONS(T1 U T2) = {{u V b,lc,4,u V c}, {ia,ib,ic}, {la,a V b,ic}} 
Comb3({T1,T2},ZC) = MAXCONS (TI U T2). 
However, Comb4({T1,T2},ZC) = {{a V b),lc,l(b, u V c}}. 
Thus, in this case, Comb3({T1,Tz},ZC) 
CO~~~({TI,T~},IC). 
0 
Example 4.9. Suppose Tl,T2,ZC are as given below: 
TI = {(a V b)} 
T2 = {la} 
IC = {Tb} 
In this case, Comb3({TI,Tz),ZC) = 0 whereas CO~~~({TI,TZ)JC) 
= {{(a V b)},{--d}- 
Thus, this example demonstrates that CO~~~({TI,T~},ZC) 
may not be a subset of 
Combd{T1,T2},ZC). 
El 
We say that combination function Combi is a subset of Comb,, denoted Combi C 
Combj, iff, for all theories T1, . . . , T,, and integrity constraints ZC, it is the case that 
Combi({TI, . . . , T,),ZC) 
Comb,{{Tl, . . . , T,),ZO. 
Figure 1 shows the complete “subset” relationships between the four different combination 
functions we have defined so far. All subset relationships are shown in Figure 1; the 
absence of a subset relationship means it does not hold. 
From the point of view of ease of implementation, we believe that Combl and Comb2 
are the hardest to implement, while Comb, and Comb4 are relatively easier to implement. 
Suppose TI, . . . , T,, are the first-order theories and ZC is a set of integrity constraints. In 
the case of Comb,, we find the maximal consistent subsets of (TI U * 
* - U Tn) and then 
simply delete those that violate the integrity constraints. 

COMBINING KNOWLEDGE BASES 
61 
In the case of Comb2 and hence of Comb,, we need to perform some additional work. 
Those maximal consistent subsets that are not deleted when computing Comb3 must be 
further examined: Suppose that Ui is one such maximally consistent subset of (TI U * 
U Tn) that violates ZC. Then we need to find maximal subsets of Yi 
that are consistent with 
ZC. This may involve a great deal of additional work. 
Implementing Comb4 is different. We compute maximally consistent subsets of 
(TI U * 
* . U T,, U ZC) that contain ZC. It is easy to see that this is of the same order of 
complexity as computing the maximal consistent subsets of (TI U . - . U Tn). We then 
simply retain those maximal subsets that are of the greatest cardinality. A detailed discus- 
sion of the complexity of these problems, however, is beyond the scope of the paper. 
4.2 Relationship with Updating of Theories 
The problem of updating theories and revising beliefs has been studied extensively 
(Fagin, Ullman, and Vardi 1986, Fagin, Kuper, Ullman, and Vardi 1986, Gardenfors 1988, 
Dalal 1988, Katsuno and Mendelzon 1989, Gardenfors and Makinson 1988, and Satoh 
1988). In brief, an update may take one of two forms: 
1. An insertion: In this, some new information is added to T. 
2. A deletion: Here, either a formula F in T is deleted, or a formula entailed by T is 
deleted. 
Inserting a formula F into T may lead to an inconsistency. In this case, the result of the 
insertion must be defined in such a way that the inconsistency is properly handled. 
Deletions do not give rise to inconsistencies (unless T was already inconsistent). 
There is some resemblance between insertions and the combination of theories we 
have discussed earlier. Insertions into theories may be viewed as a special case of our 
framework: Take the sentence F to be inserted to be an integrity constraint, that is, ZC = 
{F} and now compute MAXCONS(T,ZC). This is the gist of Theorem 4.7 below. 
One may wonder whether combining theory TI with theory Tz may be accomplished 
by inserting each element of T2 into T 1 .  This is not true in general (see Example 4.10 
below). The reason for this is that we do not have any priorities over the set of the 
combined t h e ~ r i e s . ~  
For example, when we insert elements of T2 into TI one by one, then 
the last element of T2 to be inserted is accorded the status of an integrity constraint, even 
though this last element of T2 may not be present in all maximal consistent subsets of TI 
Fagin, Ullman, and Vardi (1983) present a theory of updating theories. Before dis- 
cussing the relationship between updating and combining, we discuss the theory-updating 
approach of Fagin, Ullman, and Vardi (1983). 
U T2. 
Definition 4.10 (Insertion and Deletion) (Fagin, Ullman, and Vardi 1983). Let T be a 
theory and P be the set of clauses logically implied by T. A theory S is said to accomplish 
the insertion of a clause u into T if u E S. A theory S is said to accomplish the deletion 
of a clause u into T if u 4 S*. 
Definition 4.11 (Fagin, Ullman, and Vardi 1983). Let T, TI, and T2 be theories. TI has 
fewer insertions than T2, if TI - T C T2 - T. TI has no more insertions than T2, with 
respect to T, if TI - T C T2 - T. T1 has the same insertions as T2, with respect to T, if 
Wsing Gardenfors’s terminology, our combination functions do not satisfy axiom K: (Gardenfors 1988, p. 
48). 

62 
COMPUTATIONAL INTELLIGENCE 
TI - T = T2 - T. TI has fewer deletions than Tz, if T - T I  C T - Tz. TI has nu more 
deletions than T2, with respect to T, if T - TI C T - Tz. TI has the same deletions as T2, 
with respect to T, if T - TI C T - T2. 
Dejinition 4.12 (Fagin, Ullman, and Vardi 1983). Let T, T I ,  and T2 be theories. TI accom- 
plishes an update u (could be an insertion or a deletion) of T with a smaller change than 
T2 if both T I  and TZ accomplish u, and either TI has fewer deletions than T2 or TI has the 
same deletions as T2 but TI has fewer insertions than Tz. 
Definition 4.13 Minimal Updating (Fagin, Ullman, and Vardi 1983). A theory S accom- 
plishes an update u of a theory T minimally if there is no theory S' that accomplishes u 
with a smaller change than S. 
In the following theorem, Fagin, Ullman, and Vardi (1983) present a different char- 
acterization of minimal updating of theories. This new characterization can be used to 
construct algorithms that can minimally update a theory. 
Theorem 4.7 (Fagin, Ullman, and Vardi 1983). 
sentence. Then, 
Let S and T be theories and let u be a 
1. S accomplishes the deletion of u from T minimally if and only if S is a maximal subset 
2. S accomplishes the insertion of u from T minimally if and only if S n T is a maximal 0 
of T that is consistent with ~ c r ,  
and 
subset of T that is consistent with u. 
The following theorem describes a relationship between combining theories and up- 
dating theories when the union of the theories to be combined is consistent. 
Theorem 4.8. Let T1, . * - , Tk be theories to be combined in the presence of a finite set 
ZC of integrity constraints. Let uiC be the conjunction of the integrity constraints in ZC. If 
T1 U 
- 
U Tk is consistent then, CombI({T1, 
- - - , Tk},{Uic}) = (AX accomplishes the 0 
insertion ulc into TI U * . - U Tk minimally.} 
Proof. 
U Tk minimally}]. Suppose X E Combl({T1, 
set such that {uic} C X C Tl U * 
that X is a maximally consistent subset of T I  U 
E {XlX accomplishes the insertion of uic into TI U 
[Combl({T1, - * - , Tk},urc) C {XlX accomplishes the insertion of (Tic into TI U * - 
+ , Tk},crrc). Then X is a maximally consistent 
* U Tk U {alc}. Hence, Uic E X. It now suffices to show 
- * Tk U {uic}. But this is true. Hence X 
* . U Tk minimally}. 
[{AX accomplishes the insertion of ulc into T1 U 
* 
* 
* U Tk minimally} C Comb, 
0 
({Ti, * 
* 
* , Tk},~ic)]. 
The proof is similar. 
Theorem 4.8 above demonstrates that the Fagin, Kuper, Ullman, and Vardi (1986) 
framework for inserting sentences into theories may be captured in our framework. The 
example below shows that successive insertions of sentences of theory T2 into theory T I  
does not correctly capture the combination of theories. 
Example 4.10. 
Suppose 
TI = {a 3 c, a + l b ,  a + b}, 

COMBINING KNOWLEDGE BASES 
63 
and TZ = {a}. Inserting a into T1 causes inconsistency as a += Tb and a + b entail lu. 
There are two sets that accomplish the insertion: 
and 
c is true in both S1 and S2. Note, however, that, according to MAXCONS(T1 U Tz), c is 0 
not true in T1, which is maximally consistent of TI U T2. 
We now use the theory developed by Fagin, Kuper, Ullman, and Vardi (1986) for 
updates in flocks to compare with our problem of combining theories. 
Definition 4.14 Minimal Flock Updating (Fagin, Kuper, Ullman, and Vardi 1986). 
S’ = {S1, 
Let 
, T,} accomplishes an update u of S’ 
0 
. * , S,} be a flock. A flock T = {T1, . * 
minimally if T1 accomplishes the update of S1 minimally. 
Fagin, Kuper, Ullman, and Vardi (1986) defined the updating of a flock as follows: 
Definition 4.15 (Fagin, Kuper, Ullman, and Vardi 1986). Let S’ be a flock and St, . . . , 
SL be the flocks that accomplish an update if of S’ minimally. Then the result of u is the 
flock U l s i s k  SI. 
0 
We would like to change Definition 4.15 so that the resulting flock consists of maximal 
elements only. Formally, 
De3nition 4.16. Let S’ be a flock and S ; ,  * . . , SL be the flocks that accomplish an update 
u of S‘ minimally. Then the result of u is the flock consisting maximal elements of 
U l s i s k  Sf. 
0 
The following result relating combining theories with updating flocks of theories is 
immediate. It uses the modified definition of updating a flock as defined in definition 4.16. 
Theorem 4.9. Let Tl, . . * , Tk be a set of theories and let ZC be a finite set of integrity 
constraints. Let 9 
be the flock MAXCONS(TIU * 
* UTk). Let uic be the conjunction of 
the integrity constraints in IC. Combl({T1, * - * , Tk}, {ad) = the flock obtained by updating 
0 
9 
with uic by using definition 4.16. 
5. COMBINING PRIORITIZED THEORIES 
The different knowledge bases that have to be combined might have different priorities 
associated with them. Intuitively, there might be compelling reasons that cause one knowl- 
edge base to be preferable to another. In such a case, we would like to use this priority 
information while combining the knowledge bases. For example, if a knowledge base with 
higher priority or believability directly contradicts another knowledge base with a lower 
priority with respect to a certain aspect, we might want the combined theory to contain 
the point of view of the knowledge base with the higher priority. In this section, we 
formalize what we mean by combining prioritized theories. 

64 
COMPUTATIONAL INTELLIGENCE 
In the context of the murder example of section 2, the information provided by Bill 
(the younger witness who was also closer to the scene of action) may seem more credible 
to the police who may then pursue further investigations based on his version of events, 
as opposed to John’s version. 
As a first step, suppose we have theories TI, * - * Tk to be combined with the priority 
relation (a total order) where the priority of Ti is less than the priority of T j  iff i < j .  With 
a slight abuse of notation, it can be written as, TI < T2 < 
< Tk. As always, the 
integrity constraints have the highest priority, that is, Tk < ZC. There are two distinct 
approaches to combine the theories that come to mind immediately: bottom-up and top- 
down. 
In the bottom-up approach, we start by combining TI and TZ with preference to T2. 
The combined theory is then a set of theories defined as {T : TZ C T and T - TZ is a 
maximal subset of TI such that T is consistent). The result is then combined with T3 with 
preference to T3. This means that each theory in the result is combined with T3, and the 
final result is the set that is the union of particular resuIts (each result is a set). This 
continues until Tk. The result is then combined with ZC with preference to ZC. 
. 
Algorithm 5.1 Procedure. Comb-botup 
(Comb;, TI S . - - 6 Tk,zc) 
Tk+l = zc 
Comb = {TI} 
For i = 1 to k do 
begin 
Temp = 0 
For all T in Comb do 
Temp = Temp U Comb;((T),Ti+~) 
Comb = maximal elements of Temp 
end 
Output(Comb) 
In the top-down approach, we start with combining Tk and ZC with preference to ZC. 
The result is combined with Tk-l with preference to the theories in the result. This is 
continued until TI. 
Algorithm 5.2 Procedure. Comb-topdn(Comb;,T~ < * 
* S Tk,zc) 
Comb = {Tk+l} 
For i = k to 1 do 
T k + l  = ZC 
begin 
Temp = 0 
For all T in Comb do 
Temp = Temp U Combi({T;},T) 
Comb = maximal elements of Temp 
end 
Output(Comb) 
The following example demonstrates the difference between bottom-up and top-down 
combining. 

COMBINING KNOWLEDGE BASES 
65 
Example 5.1 (“Flying Snakes”). 
constraints given below: The priority ordering we have is TI 4 T2 < T3 .< IC. 
Consider the theories TI,T2,T3 and the set IC of integrity 
TI = {lhave-wings(snakes)} 
T2 = {-have-wings(snakes) + lfly(snakes); fly(snakes)} 
T3 = {lfly(snakes)} 
IC = 0 
Thus, if we consider Tl,T2,T3 to have been provided by three different experts El,Ez,&, 
the ordering TI < T2 < T3 denotes that we have more faith in EZ than in El and we have 
the greatest degree of belief in E3. El tells us that snakes don’t have wings. E2 tells us two 
things: first, that “things that don’t have wings don’t fly” and he also tells us that “snakes 
fly.”5 T3 tells us that “snakes don’t fly.” Bottom-up and top-down combination (using 
Combl) with priorities leads to two different results: 
Top-down: 
Combining T3 and T2, we obtain 
T32 = {{Thave-wings( snakes) -+ lfly(snakes); lfly(snakes))}. 
Combining T32 with T1, we obtain 
T321 = {{Thave-wing(snakes) + lfly(snakes);-d7y(snakes);7have-wings(snakes)}}. 
Bottom-up: 
Combining TI and T2, we obtain 
TIZ = {{-have-wings(snakes) -+ lfly(snakes); fly(snakes)}}. 
Combining T12 with T3, we obtain 
T123 = {{Thave-wings(snakes) -+ lflyfsnakes); -dy(snakes))}. 
Hence, in this case, the result obtained by the top-down approach is different from the 
result obtained by the bottom-up approach. 
An (artificial) objection may be raised that our assignment of priorities may actually 
be inappropriate because expert E2 provides the patently false piece of information that 
snakes can fly. However, this objection assumes that we assign priorities to the experts’ 
credibility after they provide their advice. Furthermore, in this example, it is easy to see 
that the statement “snakes can fly” is false because all of us know something about snakes. 
On the other hand, if the experts were providing information about a domain of which the 
reader had little knowledge (such as the history of ancient Egypt, say), he may make a 
patently false statement such as “Tutankhamen was Pharaoh before Akhenaton” without 
this being readily identifiable as a falsehood. Finally, it may be possible that the proposition 
“snakes fly” is not given as an objective fact by expert E2, but is derived from a collection 
of a thousand rules (not listed in TZ above), of which 999 are correct, and one is incorrect. 
In such cases, it may make perfect sense to prefer Ez’s advice over El’s because only one 
0 
of 1000 rules provided by him is flawed. 
example would be more forceful if we actually modify T2 so that expert EZ tells us that “all things that 
don’t have wings don’t fly” and then goes on to give a long list of things that don’t have wings-for 
example, 
cats, dogs, lizards, crocodiles, elephants, etc. However, physically describing the combination of these theories 
would then be more cumbersome, and this is why we restrict ourselves to this small example. 

66 
COMPUTATlONAL INTELLIGENCE 
Example 5.2 (Murder Example Revisited). Let us revisit the murder example. Here, we 
may give priority to the facts reported by Bill instead of those reported by Ed because 
Bill was closer to the scene of the murder, and, in addition, he has better eyesight (as he 
is much younger). In this case, both bottom-up and top-down combinations result in the 
same conclusions: one where Bill’s first statement (“the murderer wore a dark coat”) is 
0 
discarded, and everything else is accepted. 
In general, top-down combining is more informative than bottom-up combining. This 
is because top-down combining results in a combination with more information than the 
bottom-up approach. This is evident from the “flying snakes” example. In general, if we 
are combining theories T I ,  . . . , T, and integrity constraints IC, what may happen in the 
bottom-up combination is the following. We start by combining TI and TZ to get a new 
theory  TI^. In the process, we may discard a wff WI from TI because it is inconsistent 
with a wff or set of wffs in T2. When we combine the T12 with T3 (call the result Tlzs), we 
may discard that part of T2 that causes W1 to be discarded. The combination of T1z would 
not, then, restore WI even though WI may be consistent with the new combination T123. 
Thus WI would be “lost.” 
But why then consider both approaches? It is because both approaches have parallels 
in real-life decision making. The bottom-up approach corresponds to the following scen- 
ario. Consider an organization with a strict hierarchical employee structure. When the 
employee at the bottom of the hierarchy proposes an idea to his supervisor, his supervisor 
combines the employee’s idea with his beliefs (with more priority to his beliefs) and passes 
it on to his supervisor. This goes on till it reaches the highest authority. This passing of 
an idea corresponds to the bottom-up approach. In fact, this mimics precisely what happens 
in bottom-up combination: Employee El’s supervisor E2 may never pass on some of El’s 
input to his supervisor E3. Thus, that input would never trickle up the hierarchy and would 
be “lost.” Similarly, the top-down corresponds to the case when the topmost manager 
passes an idea or order to his subordinate and he to his subordinate and so on. 
Coming back to the problem of updating, one may wonder whether the combining of 
prioritized theories is similar to the updating problem. Since the motivations for the two 
problems are different, so are the results. The updating problem can be simulated by the 
botrom-up procedure for combining prioritized theories, which is different from both the 
top-down procedure and the procedure for combining nonprioritized theories. 
While speaking of the combination of prioritized theories, we briefly mention that it is 
possible that we have prioritized groups of theories GI, . . . , G,. Any two theories in the 
same group have the same priority; however, the groups themselves have priorities GI < 
Gz < * - - < G,. The most straightforward way of combining the resulting multitude of 
theories is to proceed as follows: 
Algorithm 5.3. Combining Prioritized Groups of Theories 
Step 1. For all 1 5 i .I n, set S, = MAXCON(TE~,T). 
Thus, at this stage, for any 1 I 
i 5 n, all theories in the group G, have been combined together. Each Si is thus a 
set of theories. 
Step 2. Construct S = (S1 x 
- . x S,), that is, S is the Cartesian product of the Sa. 
Step 3. Let S = {Vl, . . . , Vk} where each Vi 
is of the form (sl, . . . , s,) where s, E 
S, for all 1 s j  5 n. 
Step 4. Combine theories sl, . . . , with priorities sl < s2 < - . < Sn. Do this for all 
Vi E S. Let the resulting theories be {THI, . . . , THk). 
Step 5. Choose the maximal elements of {TH,, . . . , THk). 

COMBINING KNOWLEDGE BASES 
67 
A detailed discussion about combining prioritized groups of theories is beyond the scope 
of this paper. 
In order to see how the work described thus far relates to existing work on reasoning 
with inconsistency, consider the following program P :  
P 
TP 
p - 4  
TP - 4 
p and 71, 
r 
Using the annotated logic semantics of Blair and Subrahmanian (1988, 1989) and later 
improved by Kifer and Lozinskii (1989), it would be possible to infer r even though r 
depends on a somewhat shaky justification: ( p  and l p ) .  However, the annotated logic 
Semantics does not allow us to conclude l r  or l q .  Clearly, the fact that l r  and l q  cannot 
be inferred corresponds quite well with our intuition. The MAXCONS(P) approach would 
allow us to conclude r. At the same time, neither l r  nor 14 can be concluded. 
Considering the same program P ,  the semantics of Gelfond and Lifschitz (1990) and 
Kowalski and Sadri (1990) allows us to conclude everything. In particular, r can be 
concluded (in the same way as in Blair and Subrahmanian (1988, 1989), but in addition, 
both l r  and 14 may be concluded. 
One advantage of the Blair and Subrahmanian (1988, 1989; Kifer and Lozinskii 1989) 
approach is that, in the case of programs containing function symbols, their semantics 
leads to a semidecidable consequence relation. When fuction symbols are present, this 
does not appear to be true for the MAXCONS(P) semantics. 
6. DISCUSSION AND CONCLUSIONS 
Expert database systems are traditionally built by a team of knowledge engineers who 
elicit knowledge from multiple experts in the domain of interest. Each of these experts 
provides information (which we will assume is represented in first-order logic). As the 
people being asked for information are experts in the domain of interest, one would usually 
assume that the information they provide is correct and usually this is the case. However, 
two phenomena that makes the problem of coalescing the information provided by multiple 
experts much harder are: 
An expert provides some information that is incorrect (false). In such a case, it may 
be possible to detect and correct the error; the expert will usually be quick to change 
hidher mind when the mistake is pointed out. However, the database may be in use 
for quite some time before the mistake is ever detected. 
Two experts may disagree. In this case, there is no easy way to rectify the problem. 
The disagreement of the two experts manifests itself as an inconsistency, and one 
is forced to continue reasoning despite the presence of the inconsistency. 
Hence, the process of combining multiple knowledge bases is a genuine problem that arises 
frequently. In this paper, we have provided four ways of combining multiple knowledge 
bases when these knowledge bases all have the same priority, that is, they are all considered 
to have been obtained from equally credible sources. These four ways are based on the 
functions Combl,Comb2,Combs, and Comb4. We prove various relationships between these 

68 
COMPUTATIONAL INTELLIGENCE 
four combination techniques. All these techniques deal with methods to manipulate “max- 
imal” consistent subsets. The differences arise depending upon: 
Step 1. Which is the set of formulas whose maximal consistent subsets are being 
Step 2. Having made a selection in the previous step (above), which maximal consistent 
It turns out that Combl and Comb2 give the same results, but compute the results differ- 
ently. Comb3 and Comb4 are “bolder” than Comb, in the sense that they may discard more 
maximal consistent subsets in step 2 than Combl does. Comb3 acts on the philosophy that 
the integrity constraints (if any) play a role only in determining which maximal consistent 
subsets should be chosen. Thus, in step 1, Comb3 ignores the integrity constraints and 
finds various maximal subsets and then, in step 2 ,  discards some (possibly none) of the 
maximal consistent subsets. The great danger with Comb3 is that it may choose to discard 
everything generated in step 1. Comb4, on the other hand, never discards everything. 
What it does is to simply pick all of the maximal consistent subsets of the highest possible 
cardinality. As stated earlier, the intuitive motivation behind Comb4 is that “every time 
we discard something, we are (implicitly) saying that the discarded object constitutes a 
mistake made by the expert. As this information is obtained from experts, it may be 
advisable to assume that they don’t make too many mistakes; hence, we want to pick 
those maximal consistent subsets where the number of mistakes is minimized.” Comb4 
thus seems to be suitable in situations where it is appropriate to make this assumption. 
Comb3, on the other hand, is more appropriate in situations where the integrity constraints 
do not play a role in computing maximal consistent subsets. This may arise if the experts 
are providing advice about a domain, but they are not fully aware of some of the constraints 
that the individual seeking the advice has. For instance, in an expert system for putting 
out oil fires that may be used by many different companies engaged in this task, a user 
may have the constraint “Our company can make an initial financial outlay of only $274,000 
towards fighting this fire.” This is a constraint that the experts don’t have. However, this 
constraint limits the company in the range of choices it can adopt. If the maximal consistent 
subsets correspond to the range of choices available, then this user constraint limits the 
choices the company has to those maximal consistent subsets that satisfy the $274,000 
constraint. Thus, Comb3 may find applications in situations where the user (not the expert) 
keeps adding additional constraints. Combl, which coincides with Comb2 is the most 
conservative of all the combination functions. It generates all possibilities and does not 
ignore any piece of information. It is an appropriate combination function to use in 
situations where it is essential to consider all possibilities (such as in life-threatening 
situations and in medical expert systems). 
Combl ,Comb2,Comb3,Comb4 all assume that the experts providing different data are 
all equally credible. This is not always an appropriate assumption to make because we 
often have different “degrees of faith” in the credibility of the experts providing informa- 
tion. For instance, we may give greater weight to an economic forecast made by a Nobel 
Laureate in economics than by a graduate student in economics. When we have a linearly 
ordered set of theories (where the linear order reflects the prioritization of the theories), 
we have presented two prioritized combination schemes top-down and bottom-up. In the 
bottom-up approach, some information may be ‘‘lost,’’ while in the top-down approach, 
this infomation may not be lost. Nonetheless, the bottom-up approach, despite the loss 
of information, mirrors the way strict administrative hierarchies, such as in companies, 
often work; some informatiodideas from the lower rungs of the hierarchy are “lost” when 
they propagate upward. 
considered? and 
subsets do we retain as “acceptable” and which do we discard? 

COMBINING KNOWLEDGE BASES 
69 
These are some of the guidelines that a database designer may choose when deciding 
which algorithms to use. It is really up to the individual researcher to decide which 
semantics are most appropriate for hislher use. We do not believe that there is one all- 
encompassing way of combining multiple knowledge bases. 
We are currently extending this work in different directions. One direction is related 
to the question “How should we combine multiple knowledge bases consisting, not of first- 
order theories, but nonmonotonic theories like default theories or autoepistemic theories?”. 
Another important direction is a kind of hybrid reasoning: How do we integrate knowledge 
bases expressed in different formalisms? 
ACKNOWLEDGMENTS 
The authors wish to express their appreciation to the National Science Foundation for 
support of their work under grant numbers IRI-86-09170 and IRI-91-09755 as well as the 
Army Research Office under grant number DAAG-29-85-K-0- 177. Sarit Kraus was partially 
supported by National Science Foundation grant IRI-8907122. Thanks go to Daniel Leh- 
mann and to the referees for providing useful comments. The paper has been strengthened 
by their constructive criticism. Thanks to Lev Novik for helping with the diagram. 
REFERENCES 
BARAL, C., S. KRAUS, and J. MINKER. 1989. Combining multiple knowledge bases. Technical Report 
UMIACS TR 89-90, CS TR 2316, Department of Computer Science and UMIACS, University 
of Maryland, College Park, MD, September 1989. Also in IEEE transactions on data and 
knowledge engineering, 3(2): 200-220, June 1991. 
. 1990. Communicating between multiple knowledge-based systems with different languages. 
In S. M. Deen, editor, Proceedings of the Working Conference on Cooperating Knowledge 
Based Systems, England, p. 121-124. 
BLAIR, H. A. and V. S. SUBRAHMANIAN. 
1988. Paraconsistent foundations for logic programming. 
Journal of non-classical logic, 5(2): 45-73. 
. 1989. Paraconsistent logic programming. Theoretical computer science, 68: 135-154. 
DA COSTA, N. c. A., V. S. SUBRAHMANIAN, 
and C. VAGO. 1991. The paraconsistent logics PT. 
DALAL, M. 1988. Investigations into a theory of knowledge base, revision, preliminary report. In 
ETHERINGTON, 
D. 1988. Reasoning with incomplete information. Morgan Kaufmann Publishers, CA. 
FAGIN, R., G. KUPER, J. ULLMAN, and M. VARDI. 1986. Updating logical databases. In Advances 
FAGIN, R., J. D. ULLMAN, and M. Y. VARDI. 1983. On the semantics of updates in databases. In 
GARDENFORS, 
P. 1988. Knowledge in flux: modeling the dynamics of epistemic states. MIT Press. 
GARDENFORS, 
P. and D. MAKINSON. 1988. Revisions of knowledge systems using epistemic en- 
trenchment. In Proceedings 2nd Conference on Theoretical Aspects of Reasoning about Knowl- 
edge. Pp. 83-95. 
GELFOND, M. and V. LIFSCHITZ. 
1990. Logic programs with classical negation. In Proceedings 7th 
International Conference on Logic Programming. MIT Press. Pp. 579-597. 
GRANT, J. 1974. Incomplete models. Notre Dame journal of formal logic, XV(4):601-607. 
Zeitschrift fur Mathematische Logik und Grundlagen der Mathematik, 37: p. 139-148. 
AAAI, p. 475-479. 
in Computing Research. Vol. 3, p. 1-18. 
ACM SIGACT/SIGMOD symposium on principles of database systems, p. 352-365. 
. 1975. Inconsistent and incomplete logics. Mathematics magazine of mathematical association 
. 1977. Incompleteness and inconsistency in propositional logic. Relevant logic newsletter. 
of america, 48(3): 154-159. 

70 
COMPUTATIONAL INTELLIGENCE 
. 1978. Classifications for inconsistent theories. Notre Dame journal of formal logic, 
XIX(3) :435-444. 
GRANT, J. and V. S. SUBRAHMANIAN. 
1990. Reasoning in inconsistent databases. Manuscript. 
KATSUNO, H. and A. MENDELZON. 1989. A unified view of propositional knowledge base updates. 
In Eleventh International Joint Conference on AI, Detroit, August 1989, p. 1413-1419. 
KIFER, M. and E. LOZINSKII. 
1989. A logic for reasoning with inconsistency. To appear in Journal 
of automated reasoning. Preliminary version in Proceedings Logic in computer science, pp. 253- 
262. 
KOWALSKI, R. and F. SADRI. Logic programs with exceptions. I n  Proceedings 7th International 
Conference on Logic Programming. MIT Press. Pp. 598-613. 
PLAISTED, D. 1984. Complete problems in the first order predicate calculus. Journal of computer 
and systems sciences, 293-35. 
REITER, R. 1980. A logic for default reasoning. Artificial intelligence, 13:81-132. 
KEN SATOH. 1988. Non-monotonic reasoning by belief revision. I n  Proceedings of the International 
SUBRAHMANIAN, 
V. S. 1992. Paraconsistent disjunctive deductive databases. To appear in Theoret- 
VARDI, M. 1982. The complexity of relational query languages. Proceedings ACM symposium on 
conference on fifth generation computer systems. Pp. 455-462. 
ical computer Science. 
theory of computing, pp. 137-146. 
APPENDIX: DESCRIPTION OF ALGORITHMS 
Algorithm A.l Procedure. MAXCONSI(P) 
MAXCON = 0 
I f  P in consistent, then MAXCONSl(P) = {P}. 
e l s e  
begin 
{** Let P be the set of sentences {Cl, - 
For i = 1 * 
* . n do Pi:= P - {Ci} od 
MAXCONSl(P) := maximal elements of MAXCON. 
end 
* , Cn}- **} 
For i = 1 * 
* * n do MAXCON:= MAXCON U MAXCONSl(Pi) Od 
Algorithm A.2 Procedure. MAXCONS I(P,ZC) 
MAXCON = 0 
If P U ZC is consistent, then MAXCONSI(P,ZC) = {P}. 
e l s e  
begin 
{** Let P be the set of sentences {Cl, . - , Cn}. **} 
For i = 1 - * n do Pi:= P - {Ci} od 
For i = 1 - - * n do MAXCON:= MAXCON U MAXCONS1(Pi,ZC) od 
MAXCONSI(P,IC): = maximal elements of MAXCON. 
end 
Algorithm A .3 Procedure. 
MAXCONS2(P) 
Let there be n potential causes of the inconsistency of P. 
I f  n = 0, then MAXCONS2(P) = {P}. 
else 
begin 

COMBINING KNOWLEDGE BASES 
71 
For i = 1 * . * n do Si:= the ith potential cause of the inconsistency of P od 
S:= S ]  x ’ . . x s, 
MINS:= minimal elements of S’ WRT inclusion 
MAXCONS2(P) = {P - Y. I Y E MINS} 
end 
S’:= {{a, . . . , a,} I ( a ] ,  . . . , a,) E s> 
Algorithm A.4 Procedure. MAXCONS2(P,ZC) 
Let there be n potential causes of the inconsistency of P U ZC 
I f  n = 0, then MAXCONS2(P,ZC) = {P}. 
else 
begin 
For i = 1 * 
s:= s, x - . . x s, 
MINS: = minimal elements of S’ WRT inclusion 
end 
n do Si:= (the ith potential cause of the inconsistency) - ZC od 
S’:= {{a*, . . . , a,} 1 (a,, . * . , a,) E s> 
MAXCONS2(P,ZC) = {(P - Y) I YE MINS} 
Algorithm A S  Procedure. MAXCONS3(P,ZC) 
MAXCON = 0. 
CHECK = {P}. 
Found = false 
While not Found 
TEMP = 0. 
begin 
F o r  all Pi E CHECK do 
begin 
I f  Pi U ZC is consistent then 
begin 
Found = True. 
end 
begin 
{** Let Pi be the set of sentences {C~I, . * . , C;,. 
**} 
Forj = 1 . 
end 
MAXCON = MAXCON U {Pi U IC}. 
e l s e  
- n do TEMP = TEMP U {Pi - {C,}} 
od 
end CHECK = TEMP. 
end 
MAXCONS3(P,ZC): = maximal elements of MAXCON. 
end 

