TO APPEAR IN THE IEEE TRANSACTIONS ON IMAGE PROCESSING
1
A Gaussian mixture model representation of
endmember variability in hyperspectral unmixing
Yuan Zhou, Student Member, IEEE, Anand Rangarajan, Member, IEEE, and Paul D. Gader, Fellow, IEEE
Abstract‚ÄîHyperspectral unmixing while considering endmem-
ber variability is usually performed by the normal compositional
model (NCM), where the endmembers for each pixel are assumed
to be sampled from unimodal Gaussian distributions. However,
in real applications, the distribution of a material is often not
Gaussian. In this paper, we use Gaussian mixture models (GMM)
to represent endmember variability. We show, given the GMM
starting premise, that the distribution of the mixed pixel (under
the linear mixing model) is also a GMM (and this is shown
from two perspectives). The Ô¨Årst perspective originates from the
random variable transformation and gives a conditional density
function of the pixels given the abundances and GMM param-
eters. With proper smoothness and sparsity prior constraints
on the abundances, the conditional density function leads to a
standard maximum a posteriori (MAP) problem which can be
solved using generalized expectation maximization. The second
perspective originates from marginalizing over the endmembers
in the GMM, which provides us with a foundation to solve for
the endmembers at each pixel. Hence, compared to the other
distribution based methods, our model can not only estimate the
abundances and distribution parameters, but also the distinct
endmember set for each pixel. We tested the proposed GMM on
several synthetic and real datasets, and showed its potential by
comparing it to current popular methods.
Index Terms‚Äîendmember extraction, endmember variability,
hyperspectral image analysis, linear unmixing, Gaussian mixture
model
I. INTRODUCTION
T
HE formation of hyperspectral images can be simpliÔ¨Åed
by the linear mixing model (LMM), which assumes that
the physical region corresponding to a pixel contains several
pure materials, so that each material contributes a fraction
of its spectra based on area to the Ô¨Ånal spectra of the pixel.
Hence, the observed spectra yn ‚ààRB, n = 1, . . . , N (B is
the number of wavelengths and N is the number of pixels)
is a (non-negative) linear combination of the pure material
(called endmember) spectra mj ‚ààRB, j = 1, . . . , M (M is
the number of endmembers), i.e.
yn =
M
X
j=1
mjŒ±nj + nn, s.t. Œ±nj ‚â•0,
M
X
j=1
Œ±nj = 1,
(1)
The authors are with the Department of Computer and Information Sci-
ence and Engineering, University of Florida, Gainesville, FL, USA. E-
mail: yuan,anand,pgader@cise.uÔ¨Ç.edu. This paper has supplementary down-
loadable material available at http://ieeexplore.ieee.org., provided by the
author. The material includes a proof of Theorem 2 in the paper. Contact
zhouyuanzxcv@gmail.com for further questions about this work.
where Œ±nj is the proportion (called abundance) for the jth
endmember at the nth pixel (with the positivity and sum-
to-one constraint) and nn ‚ààRB is additive noise. Here,
the endmember set {mj : j = 1, . . . , M} is Ô¨Åxed for all the
pixels. This model simpliÔ¨Åes the unmixing problem to a matrix
factorization one, leading to efÔ¨Åcient computation and simple
algorithms such as iterative constrained endmembers (ICE),
vertex component analysis (VCA), piecewise convex multiple-
model endmember detection (PCOMMEND) [1], [2], [3] etc.,
which receive comprehensive reviews in [4], [5].
However, in practice the LMM may not be valid in many
real scenarios. Even for a pure pixel that only contains one
material, its spectra may not be consistent over the whole
image. This is due to several factors such as atmospheric
conditions, topography and intrinsic variability. For example,
in vegetation, multiple scattering and biotic variation (e.g.
differences in biochemistry and water content) cause different
reÔ¨Çectances among the same species. For urban scenes, the
incidence and emergence angles could be different for the
same roof, causing different reÔ¨Çectances. For minerals, the
spectroscopy model developed by Hapke also considers the
porosity and roughness of the material as variable [6].
In
the
Ô¨Årst
and
third
example
above,
Eq.
(1)
can
be
generalized
to
a
more
abstract
form
yn
=
F ({mj, Œ±nj : j = 1, . . . M}),
which
leads
to
nonlinear mixing models. For example, in [7] the authors
used bilinear models to handle the vegetation case, which was
also investigated using several different nonlinear functions
[8]. In [9], the Hapke model was used to model intimate
interaction among minerals. There are also works that use
kernels for Ô¨Çexible nonlinear mixing [10], [11]. A panoply
of nonlinear models can be found in the review article [12].
We note that in these models, a Ô¨Åxed endmember set is still
assumed while using a more complicated unmixing model.
While nonlinear models abound lately, it is still difÔ¨Åcult to
account for all the scenarios. On the contrary, the LMM still
has physical signiÔ¨Åcance with the intuitive area assumption. To
model real scenarios more accurately, researchers have taken
another route by generalizing Eq. (1) to
yn =
M
X
j=1
mnjŒ±nj + nn,
(2)
where

mnj ‚ààRB : j = 1, . . . , M
	
, n = 1, . . . , N could be
different for each n, i.e. the endmember spectra for each
pixel could be different. This is called endmember variability,
and has also received a lot of attention in the community
0000‚Äì0000/00$00.00 c‚Éù2018 IEEE
arXiv:1710.00075v2  [cs.CV]  15 Jan 2018

TO APPEAR IN THE IEEE TRANSACTIONS ON IMAGE PROCESSING
2
[13], [14]. Note that given {yn}, inferring {mnj, Œ±nj} is
a much more difÔ¨Åcult problem than inferring {mj, Œ±nj} in
Eq. (1). Hence, in many papers {mnj} are assumed to be
from a spectral library, which is usually called supervised
unmixing [15], [16], [17]. On the other hand, if the endmember
spectra are to be extracted from the image, we call them
unsupervised unmixing models [18], [19], [20]. Obviously,
unsupervised unmixing is more challenging than its supervised
counterpart and hence more assumptions are used in this case,
such as the spatial smoothness of abundances and endmember
variability [21], [22], [23], small mutual distance between the
endmembers [22], small magnitude or spectral smoothness of
the endmember variability [22], [23].
We can also categorize the papers on endmember variability
by how this variability is modeled. In the review paper [14], it
can be modeled as a endmember set [20], [17] or as a distribu-
tion [24], [25], [26]. One of the widely used set based methods
is multiple endmember spectral mixture analysis (MESMA)
[17], which tries every endmember combination and selects
the one with the smallest error. There are many variations to
the original MESMA. For example, the multiple-endmember
linear spectral unmixing model (MELSUM) solves the linear
equations directly using the pseudo-inverse and discards the
solutions with negative abundances [27]; automatic Monte
Carlo unmixing (AutoMCU) picks random combinations for
unmixing and averages the resulting abundances as the Ô¨Ånal
results [28], [29]. Besides MESMA variants, there are also
many other set based methods. For example, endmember
bundles form bundles from automated extracted endmembers,
take minimum and maximum abundances from bundle based
unmixing, and average them as Ô¨Ånal abundances [20]; sparse
unmixing imposes a sparsity constraint on the abundances
based on endmembers composed of all spectra from the
spectral library [30]. A comprehensive review can be found in
[13], [14]. One disadvantage of set based methods is that their
complexity increases exponentially with increasing library size
hence in practice a laborious library reduction approach may
be required [31].
The distribution based approaches assume that the endmem-
bers for each pixel are sampled from probability distributions
[e.g. Gaussian, a.k.a. normal compositional model (NCM)],
and hence embrace large libraries while being numerically
tractable [15], [32]. Here, we give an overview of NCM
because of its simplicity and popularity [19], [18], [16].
Suppose the jth endmember at the nth pixel follows a Gaussian
distribution p (mnj) = N
 mnj|¬µj, Œ£j

where ¬µj ‚ààRB and
Œ£j ‚ààRB√óB, and the additive noise also follows a Gaussian
distribution p (nn) = N (nn|0, D) where D is the noise
covariance matrix. The random variable transformation (r.v.t.)
(2) suggests that the probability density function of yn can be
derived as
p (yn|Œ±n, Œò, D) = N
Ô£´
Ô£≠yn|
M
X
j=1
Œ±nj¬µj,
M
X
j=1
Œ±2
njŒ£j + D
Ô£∂
Ô£∏,
(3)
where Œ±n := [Œ±n1, . . . , Œ±nM]T , Œò :=

¬µj, Œ£j : j = 1, . . . , M
	.
The conditional density function in (3) is usually embedded
Figure 1.
(a) Original Pavia University image and selected ROI with its
ground truth image. (b) Mean spectra of the identiÔ¨Åed 5 endmembers and
histograms of meadows and painted metal sheets (shadow is termed as
endmember to conform with the LMM though the area under shadow can
be any material). PCA is used to project the multidimensional pixels to
single values which are counted in the histograms. Although the histogram
of meadows may appear to be a Gaussian distribution, that of painted metal
sheets is obviously neither a unimodal Gaussian or Beta distribution.
in a Bayesian framework such that we can incorporate priors
and also estimate hyperparameters. Then, NCM uses different
optimization approaches, e.g. expectation maximization [32],
sampling methods [19], [25], [18], particle swarm optimization
[24], to determine the parameters

¬µj, Œ£j
	
and {Œ±nj}.
There are few papers that use other distributions. In [15],
Xiaoxiao Du et al. note that the Gaussian distribution may
allow negative values which are not realistic. In addition,
the real distribution may be skewed. Hence, they introduce
a Beta compositional model (BCM) to model the variability.
The problem is that the true distribution may not be well
approximated by any unimodal distribution. Consider the Pavia
University dataset shown in Fig. 1, where the multidimensional
pixels are projected to one dimension to afford better visu-
alization. Among the manually identiÔ¨Åed materials, we can
see that although the histogram of meadows may look like a
Gaussian distribution, that of painted metal sheets has multiple
peaks and cannot be approximated by either a Gaussian or Beta
distribution. This is due to different angles of these sheets on
the roof. Since each piece of metal sheet is tilted, it forms
a cluster of reÔ¨Çectances which contributes to a peak in the
histogram. This example shows that we should use a more
Ô¨Çexible distribution to represent the endmember variability.
In this paper, we use a mixture of Gaussians to approximate
any distribution that an endmember may exhibit, and solve the
LMM by considering endmember variability. In a nutshell, the
Gaussian mixture model (GMM) models p (mnj) by a mixture

TO APPEAR IN THE IEEE TRANSACTIONS ON IMAGE PROCESSING
3
of Gaussians, say p (mnj) = P
k œÄjkN
 mnj|¬µjk, Œ£jk

, and
then obtains the distribution of yn by the r.v.t. (2), which turns
out to be another mixture of Gaussians and can be used for
inference of the unknown parameters. Here, we brieÔ¨Çy explain
how GMM works intuitively by comparing it to the NCM
with the details given later. The maximum likelihood estimate
(MLE) of NCM (using (3)) aims to Ô¨Ånd

¬µj
	
such that its
linear combination matches yn. Contrary to NCM, GMM aims
to Ô¨Ånd

¬µjk
	
such that all of its linear combinations match
yn. Suppose we have ¬µ11, ¬µ21, ¬µ22, ¬µ31, ¬µ32, ¬µ33: then there
are 6 combinations as explained in Fig. 2, but with emphasis
weighted by {œÄjk} which determines the prior probability of
each linear combination.
Based on the GMM formulation, we propose a supervised
version and an unsupervised version for unmixing. The su-
pervised version takes a library as input and estimates the
abundances. The unsupervised version assumes that there are
regions of pure pixels, hence segments the image Ô¨Årst to get
pure pixels and then performs unmixing. Another advantage
over the other distribution based methods is that we can also
estimate the endmembers for each pixel, which is not achiev-
able by NCM or BCM. Note that estimating endmembers for
each pixel is generally common in non-distribution methods,
both from the signal processing community [22], [21], [23]
or the remote sensing community [17], [27]. But it is often
achieved in the context of least-squares based unmixing [33],
[34], [35], unlike what we propose here using distribution
based unmixing.
Notation: As usual, N (x|¬µ, Œ£) denotes the multivariate
Gaussian density function with center ¬µ and covariance matrix
Œ£. Let A
‚àà
Rm√ón be a matrix with m rows and n
columns. The Hadamard product of two matrices (elementwise
multiplication) is denoted by ‚ó¶while the Kronecker product
is denoted by ‚äó. (A)jk denotes the element at the jth row
and kth column of matrix A. (A)j denotes the jth row of A
transposed (treating A as a vector), i.e. for A = [a1, . . . an]T ,
(A)j = aj. vec (A) denotes the vectorization of A, i.e.
concatenating the columns of A. Œ¥jk = 1 when j = k and
0 otherwise. Ex (f (x)) is the expected value of f (x) given
random variable x. We use i = ‚àö‚àí1 instead of as an index
throughout the paper.
II. MATHEMATICAL PRELIMINARIES
A. Linear combination of GMM random variables
To use the Gaussian mixture model to model endmember
variability, we start by assuming that mnj follows a Gaussian
mixture model (GMM) and the noise also follows a Gaussian
distribution. The distribution of yn is obtained using the
following theorem.
Theorem 1. If the random variable mnj has a density
function
p (mnj|Œò) := fmj (mnj) =
Kj
X
k=1
œÄjkN
 mnj|¬µjk, Œ£jk

,
(4)
s.t.
œÄjk
‚â•
0, PKj
k=1 œÄjk
=
1,
with
Kj
being
the
number
of
components,
œÄjk
(¬µjk
‚àà
RB
or
Œ£jk
‚àà
RB√óB)
being
the
weight
(mean
or
covariance
matrix)
of
its
kth
Gaussian
component,
Œò
:=

œÄjk, ¬µjk, Œ£jk : j = 1, . . . , M, k = 1, . . . , Kj
	
,
{mnj : j = 1, . . . , M} are independent, and the random
variable nn has a density function p (nn) := N (nn|0, D),
then
the
density
function
of
yn
given
by
the
r.v.t.
yn = PM
j=1 mnjŒ±nj + nn is another GMM
p (yn|Œ±n, Œò, D) =
X
k‚ààK
œÄkN (yn|¬µnk, Œ£nk) ,
(5)
where K := {1, . . . , K1}√ó{1, . . . , K2}√ó¬∑ ¬∑ ¬∑√ó{1, . . . , KM} is
the Cartesian product of the M index sets, k := (k1, . . . kM) ‚àà
K, œÄk ‚ààR, ¬µnk ‚ààRB, Œ£nk ‚ààRB√óB are deÔ¨Åned by
œÄk :=
M
Y
j=1
œÄjkj, ¬µnk :=
M
X
j=1
Œ±nj¬µjkj, Œ£nk :=
M
X
j=1
Œ±2
njŒ£jkj+D.
(6)
The proof is detailed using a characteristic function (c.f.)
approach.
We Ô¨Årst consider the distribution of the intermediate variable
zn = PM
j=1 mnjŒ±nj. The c.f. of fmj in (4), œÜmj (t) : RB ‚Üí
C, is given by
œÜmj (t) = Emj

eitT x
=
Z
RB eitT xfmj (x) dx
=
Kj
X
k=1
œÄjk
Z
RB eitT xN
 x|¬µjk, Œ£jk

dx
=
Kj
X
k=1
œÄjkœÜjk (t) ,
(7)
where œÜjk (t) denotes the c.f. of the Gaussian distribution
N
 x|¬µjk, Œ£jk

as
œÜjk (t) := exp

itT ¬µjk ‚àí1
2tT Œ£jkt

.
(8)
Assuming mn1, . . . , mnM are independent, we can obtain the
c.f. of the linear combination of these mnj by multiplying (7)
as
œÜzn (t) = œÜmn1Œ±n1+¬∑¬∑¬∑+mnMŒ±nM (t) =
M
Y
j=1
œÜmj (Œ±njt)
=
K1
X
k1=1
¬∑ ¬∑ ¬∑
KM
X
kM=1
œÄ1k1 ¬∑ ¬∑ ¬∑ œÄMkM œÜ1k1 (Œ±n1t) ¬∑ ¬∑ ¬∑ œÜMkM (Œ±nMt) .
Let K, k, œÄk be deÔ¨Åned as in Theorem 1. We can write the
above multiple summations in an elegant way:
œÜzn (t) =
X
k‚ààK
œÄkœÜnk (t) ,
(9)
where œÄk ‚â•0, P
k‚ààK œÄk = 1 and
œÜnk (t) := œÜ1k1 (Œ±n1t) ¬∑ ¬∑ ¬∑ œÜMkM (Œ±nMt)
= exp
Ô£±
Ô£≤
Ô£≥itT
Ô£´
Ô£≠
M
X
j=1
Œ±nj¬µjkj
Ô£∂
Ô£∏‚àí1
2tT
Ô£´
Ô£≠
M
X
j=1
Œ±2
njŒ£jkj
Ô£∂
Ô£∏t
Ô£º
Ô£Ω
Ô£æ,

TO APPEAR IN THE IEEE TRANSACTIONS ON IMAGE PROCESSING
4
Figure 2. Comparison of the mechanisms among LMM, NCM and GMM. We have 3 endmembers represented by the darken gray areas. LMM tries to Ô¨Ånd
a set of endmembers that Ô¨Åt the pixel data. NCM tries to Ô¨Ånd a set of Gaussian centers that Ô¨Åt the pixel data, with error weighted by the covariance matrices.
GMM tries to Ô¨Ånd Gaussian centers such that all their linear combinations Ô¨Åt the pixel data, with each weighted by the prior œÄk. We may use 6 endmembers
with NCM, but then the prior information is lost.
where (8) is used. Since œÜnk (t) also has a form of c.f. of
a Gaussian distribution, the corresponding distribution turns
out to be N

x| P
j Œ±nj¬µjkj, P
j Œ±2
njŒ£jkj

. Hence, the dis-
tribution of zn can be obtained by the Fourier transform of
(9)
fzn (zn) =
1
(2œÄ)B
Z
RB e‚àíitT znœÜzn (t) dt
=
1
(2œÄ)B
Z
RB e‚àíitT zn X
k‚ààK
œÄkœÜnk (t) dt
=
X
k‚ààK
œÄkN
Ô£´
Ô£≠zn|
M
X
j=1
Œ±nj¬µjkj,
M
X
j=1
Œ±2
njŒ£jkj
Ô£∂
Ô£∏,
(10)
which is still a mixture of Gaussians.
After Ô¨Ånding the distribution of the linear combination, we
can add the noise term to Ô¨Ånd the distribution of yn. Suppose
the noise also follows a Gaussian distribution, p (nn) :=
fnn (nn) = N (nn|0, D) , where D is the noise covariance
matrix. We assume that the noise at different wavelengths is
independent (œÉ2
k being the noise variance of the kth band), i.e.
D = diag
 œÉ2
1, œÉ2
2, . . . , œÉ2
B

‚ààRB√óB (if it is not independent,
the noise can actually be easily whitened to be independent
as in [36]). Its c.f. has the following form
œÜnn (t) = exp

‚àí1
2tT Dt

(11)
by (8). Then the c.f. of yn can be obtained by multiplying (9)
and (11) (as zn and nn are independent)
œÜyn (t) = œÜzn (t) œÜnn (t) =
X
k‚ààK
œÄkœÜnn (t) œÜnk (t)
=
X
k‚ààK
œÄk exp

itT ¬µnk ‚àí1
2tT Œ£nkt

,
where ¬µnk and Œ£nk are deÔ¨Åned in (6). Finally, the distribution
of y can be shown to be (5) by the Fourier transform again
as in (10).
If K = {1}√ó{1}√ó¬∑ ¬∑ ¬∑√ó{1}, i.e. each endmember has only
one Gaussian component, we have œÄ11 = 1, . . . , œÄM1 = 1,
then œÄk = œÄ11 ¬∑ ¬∑ ¬∑ œÄM1 = 1. The distribution of yn becomes
p (yn|Œ±n, Œò, D) = N
Ô£´
Ô£≠yn|
M
X
j=1
Œ±nj¬µj1,
M
X
j=1
Œ±2
njŒ£j1 + D
Ô£∂
Ô£∏,
(12)
which is exactly the NCM in (3).
B. Another perspective
Theorem 1 obtains the density of each pixel by directly
performing a r.v.t. based on the LMM, which can be used to
estimate the abundances and distribution parameters. Here, we
will obtain the density from another perspective, which pro-
vides a foundation to estimate the endmembers for each pixel.
Again, let the noise follow the density function p (nn) :=
N (nn|0, D). Considering {mnj} and {Œ±nj} as Ô¨Åxed values,
the r.v.t. yn = P
j mnjŒ±nj + nn implies that the density of
yn is given by
p (yn|Œ±n, Mn, D) = N
Ô£´
Ô£≠yn|
X
j
mnjŒ±nj, D
Ô£∂
Ô£∏
(13)
where Mn = [mn1, . . . , mnM]T ‚ààRM√óB are the endmem-
bers for the nth pixel. We have the following theorem which
gives the same result as in Theorem 1.
Theorem 2. If the random variables {mnj : j = 1, . . . , M}
follow GMM distributions
p (mnj|Œò) :=
Kj
X
k=1
œÄjkN
 mnj|¬µjk, Œ£jk

,
and they are independent, i.e.
p (Mn|Œò) =
M
Y
j=1
p (mnj|Œò) ,
(14)

TO APPEAR IN THE IEEE TRANSACTIONS ON IMAGE PROCESSING
5
Table I
VALUES FOR THE VARIOUS QUANTITIES IN THE SIMPLE EXAMPLE.
k
œÄk
¬µnk in (6)
(1, 1, 1, 1)
0.06
Œ±n1¬µ11 + Œ±n2¬µ21 + Œ±n3¬µ31 + Œ±n4¬µ41
(1, 2, 1, 1)
0.14
Œ±n1¬µ11 + Œ±n2¬µ22 + Œ±n3¬µ31 + Œ±n4¬µ41
(1, 1, 2, 1)
0.12
Œ±n1¬µ11 + Œ±n2¬µ21 + Œ±n3¬µ32 + Œ±n4¬µ41
(1, 2, 2, 1)
0.28
Œ±n1¬µ11 + Œ±n2¬µ22 + Œ±n3¬µ32 + Œ±n4¬µ41
(1, 1, 3, 1)
0.12
Œ±n1¬µ11 + Œ±n2¬µ21 + Œ±n3¬µ33 + Œ±n4¬µ41
(1, 2, 3, 1)
0.28
Œ±n1¬µ11 + Œ±n2¬µ22 + Œ±n3¬µ33 + Œ±n4¬µ41
then the conditional density p (yn|Œ±n, Œò, D) obtained by
marginalizing Mn in p (yn, Mn|Œ±n, Œò, D) has the same form
as in Theorem 1:
p (yn|Œ±n, Œò, D) =
Z
p (yn|Œ±n, Mn, D) p (Mn|Œò) dMn
=
X
k‚ààK
œÄkN (yn|¬µnk, Œ£nk) ,
where p (yn|Œ±n, Mn, D) = N

yn| P
j mnjŒ±nj, D

.
The proof is much more complicated (in terms of algebra)
and therefore relegated to the supplemental material of the
paper.
C. An example
We give an example to illustrate the basic idea of this
paper. Suppose we have M = 4 endmembers with K1 = 1,
K2 = 2, K3 = 3, K4 = 1. Their distributions follow (4) with
¬µjk, Œ£jk, j = 1, 2, 3, 4, k = 1, ..., Kj. Let the weights of
these components be œÄ11 = œÄ41 = 1, œÄ21 = 0.3, œÄ22 = 0.7,
œÄ31 = 0.2, œÄ32 = 0.4, œÄ33 = 0.4. Then, K has 6 entries
from the Cartesian product, {1} √ó {1, 2} √ó {1, 2, 3} √ó {1}.
We list the values for œÄk, ¬µnk in Table I. For example, for
k = (1, 2, 3, 1), œÄk = œÄ11œÄ22œÄ33œÄ41 = 0.28. The value of
¬µnk is a linear combination of ¬µjk (pick one component for
each j) based on the conÔ¨Åguration k. Hence, the distribution
of yn in (5) is a Gaussian mixture of 6 components with œÄk,
¬µnk given in Table I (Œ£nk can be derived similar to ¬µnk).
Recalling the intuition in Fig. 2, we will show that applying
it to hyperspectral unmixing will force each pixel to match all
the ¬µnks, but with emphasis determined by œÄnk.
III. GAUSSIAN MIXTURE MODEL FOR ENDMEMBER
VARIABILITY
A. The GMM for hyperspectral unmixing
Based on the analysis in Section II, we can model the
conditional distribution of all the pixels Y := [y1, . . . , yN]T ‚àà
RN√óB given all the abundances A := [Œ±1, . . . , Œ±N]T
‚àà
RN√óM (Œ±n := [Œ±n1, . . . , Œ±nM]T ) and GMM parameters,
which leads to a maximum a posteriori (MAP) problem. Using
the result in (5) and assuming the conditional distributions
of yn are independent, the distribution of Y given A, Œò, D
becomes
p (Y|A, Œò, D) =
N
Y
n=1
p (yn|Œ±n, Œò, D) .
(15)
Based on the hyperspectral unmixing context, we can set the
priors for A. Suppose we use the same prior on A as in [37],
i.e.
p (A)
‚àù
exp

‚àíŒ≤1
2 Tr
 AT LA

+ Œ≤2
2 Tr
 AT A

=
exp

‚àíŒ≤1
2 Tr
 AT KA

,
(16)
where L is a graph Laplacian matrix constructed from
wnm, n, m = 1, . . . , N with wnm = e‚àí‚à•yn‚àíym‚à•2/2BŒ∑2 for
neighboring pixels and 0 otherwise. We have Tr
 AT LA

=
1
2
P
n,m wnm‚à•Œ±n ‚àíŒ±m‚à•2), K = L‚àíŒ≤2
Œ≤1 IN (suppose Œ≤1 Ã∏= 0)
with Œ≤1 controlling smoothness and Œ≤2 controlling sparsity of
the abundance maps.
From the conditional density function and the priors, Bayes‚Äô
theorem says the posterior is given by
p (A, Œò|Y, D) ‚àùp (Y|A, Œò, D) p (A) p (Œò) ,
(17)
where p (Œò) is assumed to follow a uniform distribu-
tion. Maximizing p (A, Œò|Y, D) is equivalent to minimizing
‚àílog p (A, Œò|Y, D), which reduces to the following form by
combining (5), (15), (16) and (17):
E (A, Œò) = ‚àí
N
X
n=1
log
X
k‚ààK
œÄkN (yn|¬µnk, Œ£nk) + Eprior(A),
(18)
s.t. œÄk ‚â•0,
X
k‚ààK
œÄk = 1, Œ±nj ‚â•0,
M
X
j=1
Œ±nj = 1, ‚àÄn
where Eprior(A) = Œ≤1
2 Tr
 AT KA

, and ¬µnk, Œ£nk are deÔ¨Åned
in (6).
B. Relationships to least-squares, NCM and MESMA
Let us focus on the Ô¨Årst term in (18) and call it the data
Ô¨Ådelity term. We can relate it to NCM and the least-squares
term P
n ‚à•yn ‚àíP
j Œ±njmj‚à•2 as used in previous research.
The data Ô¨Ådelity term in NCM follows (3) and is based on
minimizing the negative log-likelihood
‚àílog p (Y) = ‚àílog
N
Y
n=1
p (yn) = ‚àí
N
X
n=1
log N (yn|¬µn1, Œ£n1)
(19)
by assuming yns are independent, where ¬µn1 := P
j Œ±nj¬µj,
Œ£n1 := P
j Œ±2
njŒ£j + œÉ2IB. Expanding (19) using the form
of the Gaussian distribution leads to the objective function
N
X
n=1
log |Œ£n1| +
N
X
n=1
(yn ‚àí¬µn1)T Œ£‚àí1
n1 (yn ‚àí¬µn1) .
(20)
We can see that the least-squares minimization is a special case
of NCM with ‚à•Œ£j‚à•F ‚Üí0, i.e. when there is little endmember
variability.
The proposed GMM further generalizes NCM from a sta-
tistical perspective. Since œÄjk represents the prior probability
of the latent variable in a GMM, œÄk represents the prior
probability of picking a combination. If we see k as a

TO APPEAR IN THE IEEE TRANSACTIONS ON IMAGE PROCESSING
6
(discrete) random variable whose sample space is K, (5) can
be seen as
p (yn|Œ±n, Œò, D) =
X
k‚ààK
p (k) p (yn|k, Œ±n, Œò, D) ,
where
p (k)
=
œÄk
and
p (yn|k, Œ±n, Œò, D)
=
N (yn|¬µnk, Œ£nk). From this perspective, each pixel is
generated by Ô¨Årst sampling k, then sampling a Gaussian
distribution determined by k, Œò. Unlike NCM that tries to
make each yn close to ¬µn1 which is a linear combination of
a Ô¨Åxed set

¬µj
	
, GMM further generalizes it by trying to
make yn close to every ¬µnk which are all the possible linear
combinations of

¬µjk
	
. It makes sense that the summation
in (18) is weighted by œÄk in a way that if one combination
has a high probability to appear, i.e. œÄk is larger for a certain
k, the effort is biased to make yn closer to this particular
¬µnk. Fig. 2 shows the differences among these.
The widely adopted MESMA takes a library of endmember
spectra as input, tries all the combinations and pick the
combination with least reconstruction error. The philosophy
is similar to our model despite the fundamental difference
that MESMA is explicit whereas we are implicit in terms
of linear combinations. Compared to MESMA, the GMM
approach separates the library into M groups where each
group represents a material and is clustered into several
centers, such that the combination can only take place by
picking one center from each group. Also, the size of each
cluster affects the probability of picking its center. Hence, our
model can adapt to very large library sizes as long as the
number of clusters does not increase too much.
C. Optimization
Estimating the parameters of GMMs has been studied ex-
tensively, from early expectation maximization (EM) from the
statistical community to projection based clustering from the
computer science community [38], [39]. There are simple and
deterministic algorithms, which usually require the centers of
Gaussian be separable. However, we face a more challenging
problem since each pixel is generated by a different GMM
determined by the coefÔ¨Åcients Œ±n. Since EM can be seen as
a special case of Majoriziation-Minimization algorithms [40],
which is more Ô¨Çexible, we adopt this approach. Considering
that we have too many parameters A, Œò to update in the M
step, they are updated sequentially as long as the complete
data log-likelihood increases. This is also called generalized
expectation maximization (GEM) [41].
Following the routine of EM, the E step calculates the
posterior probability of the latent variable given the observed
data and old parameters
Œ≥nk =
œÄkN (yn|¬µnk, Œ£nk)
P
k‚ààK œÄkN (yn|¬µnk, Œ£nk).
(21)
The M step usually maximizes the expected value of the
complete data log-likelihood. Here, we have priors in the
Bayesian formulation. Hence, we need to minimize
EM = ‚àí
N
X
n=1
X
k‚ààK
Œ≥nk {log œÄk + log N (yn|¬µnk, Œ£nk)}+Eprior.
(22)
This leads to a common update step for œÄk as
œÄk = 1
N
N
X
n=1
Œ≥nk.
(23)
We now focus on updating

¬µjk, Œ£jk
	
and A. To achieve this,
we require the derivatives of EM in (22) w.r.t. ¬µjk, Œ£jk, Œ±nj.
After some tedious algebra using (6), we get
‚àÇEM
‚àÇ¬µjl
= ‚àí
N
X
n=1
X
k‚ààK
Œ¥lkjŒ±njŒªnk
(24)
‚àÇEM
‚àÇŒ£jl
= ‚àí
N
X
n=1
X
k‚ààK
Œ¥lkjŒ±2
njŒ®nk,
(25)
‚àÇEM
‚àÇŒ±nj
= ‚àí
X
k‚ààK
ŒªT
nk¬µjkj ‚àí2Œ±nj
X
k‚ààK
Tr

Œ®T
nkŒ£jkj

+ Œ≤1 (KA)nj ,
(26)
where Œªnk ‚ààRB√ó1 and Œ®nk ‚ààRB√óB are given by
Œªnk = Œ≥nkŒ£‚àí1
nk (yn ‚àí¬µnk) ,
(27)
Œ®nk = 1
2Œ≥nkŒ£‚àíT
nk (yn ‚àí¬µnk) (yn ‚àí¬µnk)T Œ£‚àíT
nk ‚àí1
2Œ≥nkŒ£‚àíT
nk .
(28)
It is better to represent the derivatives in matrix forms for the
sake of implementation convenience. Considering the multiple
summations in (24), (25) and (26), we can write them as
‚àÇEM
‚àÇ¬µjl
= ‚àí
X
k‚ààK
Œ¥lkj
 AT Œõk

j ,
(29)
‚àÇEM
‚àÇvec (Œ£jl) = ‚àí
X
k‚ààK
Œ¥lkj

(A ‚ó¶A)T Œ®k

j ,
(30)
‚àÇEM
‚àÇA = ‚àí
X
k‚ààK
ŒõkRT
k ‚àí2A ‚ó¶
X
k‚ààK
Œ®kST
k + Œ≤1KA,
(31)
where Œõk ‚ààRN√óB, Œ®k ‚ààRN√óB2 denote the matrices
formed by {Œªnk, Œ®nk} as follows
Œõk := [Œª1k, Œª2k, . . . , ŒªNk]T ,
Œ®k := [vec (Œ®1k) , vec (Œ®2k) , . . . , vec (Œ®Nk)]T ,
and Rk ‚ààRM√óB, Sk ‚ààRM√óB2 are deÔ¨Åned by
Rk :=

¬µ1k1, ¬µ2k2, . . . , ¬µMkM
T ,
(32)
Sk := [vec (Œ£1k1) , vec (Œ£2k2) , . . . , vec (Œ£MkM )]T .
(33)
The minimum of EM corresponds to
‚àÇEM
‚àÇ¬µjl = 0,
‚àÇEM
‚àÇŒ£jl = 0,
and ‚àÇEM
‚àÇA = 0 if the optimization problem is unconstrained.
However, since we have the non-negativity and sum-to-one
constraint to Œ±nj and positive deÔ¨Ånite constraint of Œ£jk,
minimizing EM is very difÔ¨Åcult. Therefore, in each M step,
we only decrease this objective function by projected gradient
descent (please see Section 2.3 in [42], [43]) using (29), (30)
and (31), where the projection functions for A and {Œ£jk} are
the same as in [37].
Finally, from the estimated œÄk, we can recover the sets of
weights as œÄjl = P
k‚ààK Œ¥lkjœÄk.

TO APPEAR IN THE IEEE TRANSACTIONS ON IMAGE PROCESSING
7
D. Model selection
The number of components Kj can be speciÔ¨Åed or es-
timated from the data. For the latter case, we have some
pure pixels and estimate Kj by deploying a standard model
selection method. Suppose we have Nj pure pixels Yj :=
h
yj
1, yj
2, . . . , yj
Nj
iT
‚àà
RNj√óB
for the jth endmember,
fmj (y|Œòj) is the estimated density function with Œòj :=

œÄjk, ¬µjk, Œ£jk : k = 1, . . . , Kj
	
, gmj (y) is the true density
function. The information criterion based model selection
approach tries to Ô¨Ånd Kj that minimizes their difference, e.g.
the Kullback-Leibler (KL) divergence
DKL
 gmj‚à•fmj

=
Z
RB gmj (y) log
gmj (y)
fmj (y|Œòj)dy
‚âà
‚àí1
Nj
Nj
X
n=1
logfmj
 yj
n|Œòj

+ const,
where the approximation of
R
gmj (y) log fmj (y|Œòj) dy by
the log-likelihood is usually biased as the empirical distribu-
tion function is closer to the Ô¨Åtted distribution than the true
one. Akaike‚Äôs information criterion is one way to approximate
the bias. Here, we use the cross-validation-based information
criterion (CVIC) to correct for the bias [44], [45]. Let
LYj (Œòj) =
Nj
X
n=1
logfmj
 yj
n|Œòj

.
(34)
The V-fold cross validation (we use V = 5 here) divides the
input set Yj into V subsets

Y1
j, Y2
j, . . . , YV
j
	
with equal
sizes. Then for each subset Yv
j , v = 1, . . . , V , the remaining
data are used to replace Yj in (34) such that (34) is maximized
by Œòv
j. Then LKj = P
v LYv
j
 Œòv
j

is evaluated and the
optimal ÀÜ
Kj = arg maxKj LKj.
E. Implementation details
The algorithm can be implemented in a supervised or
unsupervised manner. In both cases, because of the large com-
putational cost, we project the pixel data to a low dimensional
space by principal component analysis (PCA) and perform
the optimization, the result then projected back to the original
space. Let E ‚ààRB√ód be the projection matrix and c ‚ààRB
be the translation vector, then
ET (yn ‚àíc) =
M
X
j=1
ET (mnj ‚àíc) Œ±nj + ET nn.
This means that for the projected pixels, the jth endmember
m‚Ä≤
nj = ET (mnj ‚àíc) follows a distribution
p
 m‚Ä≤
nj|Œò

=
Kj
X
k=1
œÄjkN
 m‚Ä≤
nj|ET  ¬µjk ‚àíc

, ET Œ£jkE

and the noise n‚Ä≤
n = ET nn follows N
 n‚Ä≤
n|0, ET DE

.
In the supervised unmixing scenario, we assume that a
library of endmember spectra is known. After estimating the
number of components following Section III-D, and calcu-
lating Œò using the standard EM algorithm, we only need
to update Œ≥nk by (21) and A by (31) with œÄk, ¬µjk and
Œ£jk Ô¨Åxed. The initialization of A can utilize the multiple
combinations of means. For each Œ±n, we Ô¨Årst set Œ±nk ‚Üê
 RkRT
k + œµIM
‚àí1 Rkyn, then project it to the simplex space,
and Ô¨Ånally set Œ±n
‚ÜêŒ±nÀÜk with ÀÜk = arg mink ‚à•yn ‚àí
RT
k Œ±nk‚à•2, i.e. choose the Œ±nk that minimizes the reconstruc-
tion error.
In the unsupervised unmixing scenario, we will assume the
resolution is high enough such that the hyperspectral image
can be segmented into several regions where the interior pixels
in each region are pure pixels. The optimization is performed
in several steps, where we Ô¨Årst obtain a segmentation result,
then use CVIC to determine the number of components, and
Ô¨Ånally estimate A with Œò Ô¨Åxed. The details are given as
follows.
Step 1: Initialization. We start with Kj = 1, ‚àÄj and use
K-means to Ô¨Ånd the initial means R1. The initial A is set
to A ‚ÜêYRT
1
 R1RT
1 + œµIM
‚àí1 (by minimizing ‚à•Y ‚àí
AR1‚à•2
F ), then projected to the valid simplex space as in [37].
The initial covariance matrices are set to Œ£j1 ‚Üê0.12IB, ‚àÄj.
For the noise matrix D, although there is research focused
on noise estimation [46], [47], endmember variability was
not considered and validation was performed only for the
simple LMM assumption. Hence, we use an empirical value
D = 0.0012IB, which is usually much less than the variability
of covariance matrices in (6).
Step 2: Segmentation. Given the initial conditions, we use
the GEM algorithm to iteratively update Œ≥nk by (21), œÄk by
(23), ¬µjk by (29), A by (31) while keeping Œ£jk Ô¨Åxed. For
Œ≥nk and œÄk, a direct update equation is available. For ¬µjk,
we can use gradient descent. For A, since we have the non-
negativity and sum-to-one constraints, a projected gradient
descent similar to the one used in [37] can be applied. To
ensure a segmentation effect, a large Œ≤2 is used in this step.
Step 3: Model selection and abundance estimation. Using
the segmentation-like abundance maps from the previous step,
we can obtain the interior pixels Yj (assumed pure) by
thresholding the abundances (e.g. Œ±nj > 0.99) and performing
image erosion to trim the boundaries with structure element
size rse (can be decreased gradually if large enough to trim
all the pixels). Following Section III-D, we can determine
the number of components Kj and further calculate Œòj by
standard EM. Since Œ≤2 is relatively large in the previous step,
it is reduced by Œ≤2 ‚ÜêŒ∂Œ≤2 where Œ∂ = 0.05. Then we restart
the optimization to estimate the abundances with Œò Ô¨Åxed.
F. Complexity analysis
The abundance estimation algorithm is an iterative pro-
cess. Since we used projected gradient descent with adaptive
step sizes, the number of iterations is usually not large
as shown in [48], [43]. For each iteration, it starts with
calculating ¬µnk and Œ£nk in (6), where storing all ¬µnk
(Œ£nk) requires O (|K| NB) (O
 |K|NB2
), the computation
takes O (|K|NMB) (O
 |K| NMB2
). Suppose the Cholesky
factorization and the matrix inversion of a B by B matrix
both take O
 B3
time, and N ‚â´B > M. Evaluating
log N (yn|¬µnk, Œ£nk) by the Cholesky factorization will take

TO APPEAR IN THE IEEE TRANSACTIONS ON IMAGE PROCESSING
8
O
 B3
, hence updating all the Œ≥nk takes O
 |K| NB3
, which
is also the required time for evaluating the objective function
(18). The calculation of Œªnk, Œ®nk (in (27) and (28)) will
be dominated by the inversion of Œ£nk which takes O
 B3
,
hence the overall calculation takes O
 |K| NB3
with storage
the same as ¬µnk and Œ£nk. Then if we move to calculating
the derivatives in (29), (30) and (31), it is easy to verify that
the computational costs are O (|K| NMB), O
 |K| NMB2
,
O
 |K| NMB2
respectively (Note that K is a banded matrix
so the computation involving it is linear). Reviewing the above
process, we conclude that the spatial complexity is dominated
by O
 |K| NB2
and the time complexity is dominated by
O
 |K| NB3
.
G. Estimation of endmembers for each pixel
While
the
previous
sections
discuss
the
estimation
of
the
abundances
and
endmember
distribution
param-
eters,
they
do
not
actually
estimate
the
endmembers
{mnj : n = 1, . . . , N, j = 1, . . . , M} for each pixel. In this
Section, we will discuss this additional problem and note its
absence in the previous NCM literature.
Theorem 2 implies that we can view the proposed con-
ditional density (5) as modeling the noise as a Gaussian
random variable followed by marginalizing over Mn, which
is usually achieved by the evidence approximation in the
machine learning literature due to the intractability of the
integral (Section 3.5 in [49]). Since we have A, Œò obtained
from the previous Sections, we can get the posterior of Mn
from this model:
p (Mn|yn, Œ±n, Œò, D) ‚àùp (yn, Mn|Œ±n, Œò, D)
= p (yn|Œ±n, Mn, D) p (Mn|Œò) .
(35)
Maximizing log p (Mn|yn, Œ±n, Œò, D) gives us another mini-
mization problem
E (Mn)
=
1
2
 yn ‚àíMT
nŒ±n
T D‚àí1  yn ‚àíMT
nŒ±n

‚àí
M
X
j=1
log
Kj
X
k=1
œÄjkN
 mnj|¬µjk, Œ£jk

(36)
obtained by plugging (13) and (14) into (35). Note that this
objective function has an intuitive interpretation as the Ô¨Årst
term minimizes the reconstruction error while the second term
forces the endmembers close to the centers of each GMM. The
weight factor between the two terms is the noise. From an
algebraic perspective, since there are also logarithms of sums
of Gaussian functions in this objective, we can also use the
EM algorithm for ease of optimization. In the E step, the soft
membership is calculated by
Œ≥njk =
œÄjkN
 mnj|¬µjk, Œ£jk

P
k œÄjkN
 mnj|¬µjk, Œ£jk
, k = 1, . . . , Kj.
In the M step, the derivative w.r.t. mnj is obtained as
‚àÇE
‚àÇmnj
= ‚àíD‚àí1  yn ‚àíMT
nŒ±n

Œ±nj
+
Kj
X
k=1
Œ≥njkŒ£‚àí1
jk
 mnj ‚àí¬µjk

.
Instead of deploying gradient descent in the M step for
estimating the abundances, combining the derivatives for all j
actually leads to a closed form solution
vec
 MT
n

=

Œ±nŒ±T
n ‚äóD‚àí1 + diag (Cn1, . . . , CnM)
	‚àí1

vec
 D‚àí1ynŒ±T
n

+ dn
	
where Cnj ‚ààRB√óB and dn :=
 dT
n1, . . . , dT
nM
T ‚ààRMB√ó1
are deÔ¨Åned as
Cnj :=
Kj
X
k=1
Œ≥njkŒ£‚àí1
jk , dnj :=
Kj
X
k=1
Œ≥njkŒ£‚àí1
jk ¬µjk.
In practice, despite the need to estimate a large M √ó B √ó N
tensor, the time cost is actually much less than the estimation
of abundances because of the closed form update equation
in the M step. An interesting fact is that Œ≥njk measures the
closeness of estimated endmembers to clusters centers, hence
may provide a clue on which cluster is sampled to generate
an endmember.
IV. RESULTS
In the following experiments, we implemented the algorithm
in MATLAB R
‚Éùand compared the proposed GMM with NCM,
BCM (spectral version with quadratic programming) [15] on
synthetic and real images. As mentioned previously, for GMM,
the original image data were projected to a subspace with
10 dimensions to speed up the computation for abundance
estimation 1. NCM was implemented as a supervised algorithm
wherein we input the ground truth pure pixels (in the image
with extreme abundances), modeled them by Gaussian distri-
butions, and obtained the abundance maps by maximizing the
log-likelihood. We considered two versions of NCM, one in
the same subspace as GMM (referred to as NCM), the other in
the original spectral space (referred to as NCM without PCA).
Since BCM is also a supervised unmixing algorithm, ground
truth pure pixels were again taken as input and the results
were the abundance maps. For GMM and the two versions
of NCM, using the algorithm in Section III-G we can obtain
the endmembers for each pixel. All the parameters of GMM
(except the structure element size rse) were set to Œ≤1 = 5,
Œ≤2 = 5 unless speciÔ¨Åed throughout the experiments.
For comparison of endmember distributions, we calculated
the L2 distance
 R
|f (x) ‚àíg (x) |2dx
1/2 between the Ô¨Åtted
distribution and the ground truth one, where the latter was only
available for the synthetic dataset. For comparison of abun-
dances, we calculated the root mean squared error (RMSE)
  1
N
P
n |Œ±GT
nj ‚àíŒ±est
nj |21/2 where Œ±GT
nj
are the ground truth
abundances and Œ±est
nj are the estimated values. Since only some
1The
code
of
GMM
is
available
on
GitHub
(https://github.com/
zhouyuanzxcv/Hyperspectral).

TO APPEAR IN THE IEEE TRANSACTIONS ON IMAGE PROCESSING
9
pure pixels were identiÔ¨Åed as ground truth in the real datasets,
we calculated errorj =

1
|I|
P
n‚ààI |Œ±GT
nj ‚àíŒ±est
nj |21/2
given
the pure pixel index set I. For comparison of endmembers,
the same error formula and overall schema were used, i.e. for
an index set Ij of pure pixels for the jth endmember (in the
real datasets), errorj =
1
|Ij|
P
n‚ààIj
  1
B ‚à•mGT
nj ‚àímest
nj ‚à•21/2.
A. Synthetic datasets
The algorithms were tested for two cases of synthetic
images, a supervised case and an unsupervised case.
Supervised. In this case, a library of ground truth end-
members were input and the abundances were estimated.
The images were of size 60 √ó 60 with 103 wavelengths
from 430 nm to 860 nm (‚â§5 nm spectral resolution) and
created with two endmember classes, meadows and painted
metal sheets, whose spectra were drawn randomly from the
ground truth of the Pavia University dataset (shown in Fig. 1,
meadows have 309 samples and painted metal sheets have
941 samples in the ROI). Since painted metal sheets have
multiple modes in the distribution, it should reÔ¨Çect a true
difference between GMM and the other distributions. The
abundances were sampled from a Dirichlet distribution so each
pixel had random values. Also, an additive noise sampled from
N (nn|0, D) was added to the mixed spectra, where the noise
was assumed to be independent at different wavelengths, i.e.
D = diag
 œÉ2
1, . . . , œÉ2
B

while œÉk was again sampled from a
uniform distribution on [0, œÉY ].
We tested the algorithms for different œÉY . The effects of
priors were all removed in this case, i.e. Œ≤1 = 0, Œ≤2 = 0.
Fig. 3 shows the box plots of abundance and endmember
errors. We can see that GMM has small errors in general for
different noise levels. NCM also has relatively small errors
in most cases, but tends to produce large errors occasionally
(4 out of 20 runs). NCM without PCA has very good results
except for large noise, where it performed worst among all
the methods. BCM has the largest errors overall. For the
endmembers, although NCM or NCM without PCA sometimes
has less errors than GMM, the difference is less than 0.005
hence negligible.
Unsupervised. We created two synthetic images in this
case, the Ô¨Årst was used to validate the ability to estimate the
distribution parameters on scenes with regions of pure pixels,
the second was used to validate the segmentation strategy on
images with insufÔ¨Åcient pure pixels. They were both of size
60 √ó 60 pixels and constructed from 4 endmember classes:
limestone, basalt, concrete, asphalt, whose spectral signatures
were highly differentiable. We assumed that the endmembers
were sampled from GMMs following the example in Sec-
tion II-C. The means of the GMMs were from the ASTER
spectral library [50] (see Fig. 4(c) for their spectra) with slight
constant changes, which determined a spectral range from 0.4
¬µm to 14 ¬µm, re-sampled into 200 values. The covariance
matrices were constructed by a2
jkIB + b2
jkujkuT
jk where ujk
was a unit vector controlling the major variation direction.
For the Ô¨Årst image, we assumed the 4 materials occupied the
4 quadrants of the square image as pure pixels. Then Gaussian
smoothing was applied on each abundance map to make the
Table II
L2 DISTANCE BETWEEN THE FITTED DISTRIBUTIONS (GMM, NCM) AND
THE GROUND TRUTH DISTRIBUTIONS FOR THE FIRST IMAGE OF THE
UNSUPERVISED SYNTHETIC DATASET.
√ó106
Limestone
Basalt
Concrete
Asphalt
Mean
GMM
4.45
3.46
3.41
4.28
3.85
NCM
4.27
5.86
4.95
4.02
4.77
Table III
ABUNDANCE ERRORS FOR THE UNSUPERVISED SYNTHETIC DATASET.
√ó10‚àí4
GMM
NCM
NCM w/o PCA
BCM
Image 1
Limestone
50
107
92
126
Basalt
40
74
67
158
Concrete
41
66
62
186
Asphalt
69
141
123
292
Mean
59
97
86
190
Image 2
Limestone
157
1086
396
231
Basalt
126
445
270
204
Concrete
103
985
229
206
Asphalt
225
170
706
445
Mean
153
671
400
272
boundary pixels of each quadrant be mixed by the neighboring
materials. For the second image, we made the Ô¨Årst material
as background, the other materials randomly placed on this
background. The procedure of generating the abundance maps
followed [37]: for each material (not as background), 150
Gaussian blobs were randomly placed, whose location and
shape width were both sampled from Gaussian distributions.
Finally, noise produced similar to above with œÉY = 0.001
was added to the generated pixels. Fig. 4 shows the abun-
dance maps, the original spectra of these materials, and the
resulting color images by extracting the bands corresponding
to wavelengths 488 nm, 556 nm, 693 nm.
The parameters of GMM were rse = 5 for the two images,
Œ≤1 = 0.1, Œ≤2 = 0.1 for the second image. Fig. 5 shows
the histograms of ground truth pure pixels and the estimated
distributions for the Ô¨Årst image. The ground truth distribution
is barely visible as most of the time it coincides with GMM.
For limestone and asphalt, all the distributions are similar
since the pure pixels are generated by a unimodal Gaussian.
However, for basalt and concrete, GMM provides a more
accurate estimation while the two NCMs seem inferior due to
the single Gaussian assumption. The quantitative analysis in
Table II implies a similar result by calculating the L2 distance
between the estimated distribution and the ground truth.
Table III shows the comparison of abundance errors from
the two images. Since the second image is much more chal-
lenging than the Ô¨Årst one, we can expect increased errors from
all the methods. In general, the results of BCM and the two
NCMs show slightly inferior abundances compared to GMM
despite the fact that they have access to pure pixels in the
image to train their models.
B. Pavia University
The Pavia University dataset was recorded by the ReÔ¨Çective
Optics System Imaging Spectrometer (ROSIS) during a Ô¨Çight
over Pavia, northern Italy. The dimension is 340 by 610 with
a spatial resolution of 1.3 meters/pixel. It has 103 bands with

TO APPEAR IN THE IEEE TRANSACTIONS ON IMAGE PROCESSING
10
GMM
NCM
NCM w/o PCA
BCM
Y = 0.0001
0.05
0.1
0.15
0.2
0.25
Error of abundances
GMM
NCM
NCM w/o PCA
BCM
Y = 0.001
0.05
0.1
0.15
0.2
Error of abundances
GMM
NCM
NCM w/o PCA
BCM
Y = 0.01
0.05
0.1
0.15
0.2
Error of abundances
GMM
NCM
NCM w/o PCA
Y = 0.0001
0.025
0.03
0.035
0.04
Error of endmembers
GMM
NCM
NCM w/o PCA
Y = 0.001
0.025
0.03
0.035
0.04
Error of endmembers
GMM
NCM
NCM w/o PCA
Y = 0.01
0.04
0.06
0.08
0.1
Error of endmembers
Figure 3. Abundance and endmember error statistics from 20 synthetic images for each noise level in the supervised unmixing scenario.
wavelengths ranging from 430 nm to 860 nm. As Fig. 1
shows, the original image contains several man-made and
natural materials. Considering that the whole dataset contains
many different objects, we only performed experiments on
the exemplar ROI (47 by 106) shown in Fig. 1, in which
5 endmembers, meadows, bare soil, painted metal sheets,
shadows and pavement, are manually identiÔ¨Åed.
The parameter of GMM was rse = 2. Fig. 6 shows the
GMM in the wavelength-reÔ¨Çectance space, where we can see
the centers and the major variations of the Gaussians. Fig. 7
shows the scatter plot of the results in the projected space.
The scatter plot shows that the identiÔ¨Åed Gaussian components
cover the ground truth pure pixels very well. For painted metal
sheets, which has a broad range of pure pixels, it estimated 4
components to cover them. For shadows, only one component
was estimated. Fig. 8 shows the histograms of pure pixels
and the estimated distributions of GMM and NCMs. We can
see that GMM matches the background histogram better than
NCMs.
Fig. 9 shows the abundance map comparison. Comparing
them with the ground truth shown in Fig. 1(a), we can see that
BCM failed to estimate the pure pixels of painted metal sheets,
although ground truth pure pixels were used for training.
For example, the third and fourth abundance maps of BCM
show that the pixels in the lower part of painted metal sheets
are mixed with shadows, while the reduced reÔ¨Çectances are
only caused by angle variation. The result of GMM not only
shows sparse abundances for that region, but also interprets the
boundary as a combination of neighboring materials. Since this
dataset has a spatial spacing of 1.3 meters/pixel, we think this
soft transition is more realistic than a simple segmentation.
Although the results of NCMs look good in general, the
abundances in a pure material region are inconsistent. The
errors of abundances and endmembers for these algorithms
are shown in Table IV, which implies that GMM performed
Table IV
ABUNDANCE AND ENDMEMBER ERRORS FOR PAVIA UNIVERSITY.
√ó10‚àí4
GMM
NCM
NCM w/o PCA
BCM
Meadow
187 \ 44a
405 \ 113
378 \ 114
711
Soil
175 \ 30
581 \ 68
507 \ 66
1049
Metal
476 \ 49
1236 \ 237
917 \ 349
1285
Shadow
44 \ 44
736 \ 48
914 \ 34
1287
Pavement
473 \ 39
1064 \ 114
333 \ 103
612
Mean
271 \ 41
804 \ 116
610 \ 133
989
a the numbers in ".\." denote the abundance and endmember errors.
best overall.
C. Mississippi Gulfport
The dataset was collected over the University of Southern
Mississippis-Gulfpark Campus [51]. It is a 271 by 284 image
with 72 bands corresponding to wavelengths 0.368 ¬µm to
1.043 ¬µm. The spatial resolution is 1 meter/pixel. The scene
contains several man-made and natural materials including
sidewalks, roads, various types of building roofs, concrete,
shrubs, trees, and grasses. Since the scene contains many
cloths for target detection, we tried to avoid the cloths and
selected a 58 by 65 ROI that contains 5 materials [52].
The original RGB image and the selected ROI are shown in
Fig. 10(a) while the identiÔ¨Åed materials and the mean spectra
are shown in (b).
The parameter of GMM was rse = 1. Fig. 11 shows
the GMM result in the wavelength-reÔ¨Çectance space and
Fig. 12 shows the scatter plot. We can see that the estimated
Gaussian components successfully cover the identiÔ¨Åed pure
pixels. Fig. 13 shows the estimated distributions. Although
there are no multiple peaks in any of the histograms, NCMs
still do not Ô¨Åt the histograms of shadow and gray roof. In
contrast, GMM gives a much better Ô¨Åt for these 2 endmember
distributions.

TO APPEAR IN THE IEEE TRANSACTIONS ON IMAGE PROCESSING
11
Figure 4. Unsupervised synthetic dataset. (a) and (b) are abundance maps for
two images. (c) shows original spectra from the ASTER library. (d) and (e)
show the color images.
Fig. 14 shows the abundance maps from different algo-
rithms. We can see that GMM matches the ground truth in
Fig. 10(b) best, followed by NCM without PCA. This is also
veriÔ¨Åed in the quantitative analysis in Table V. Although NCM
and BCM take ground truth pure pixels as input, the scattered
dots for trees (fourth abundance map) in both of them and the
incomplete region of grass for NCM (asphalt for BCM) show
their insufÔ¨Åciency in this case.
V. DISCUSSION AND CONCLUSION
In this paper, we introduced a GMM approach to represent
endmember variability, by observing that the identiÔ¨Åed pure
pixels in real applications usually can not be well Ô¨Åtted by a
unimodal distribution as in NCM or BCM. We solved several
Figure 5. Histograms of pure pixels for the 4 materials (when projected to
a 1-dimensional space determined by performing PCA on the pure pixels of
each material) and the ground truth and estimated distributions (also projected
to the same direction) for the Ô¨Årst image of the unsupervised synthetic dataset.
The probability of each distribution is calculated by multiplying the value of
the density function at each bin location with the bin size.
0.5
0.6
0.7
0.8
Wavelength (micrometer)
Meadows
0
0.5
1
Reflectance
0.66
0.34
0.5
0.6
0.7
0.8
Wavelength (micrometer)
Bare Soil
0
0.5
1
Reflectance
0.46
0.42
0.12
0.5
0.6
0.7
0.8
Wavelength (micrometer)
Painted Metal Sheets
0
0.5
1
Reflectance
0.3
0.25
0.25
0.2
0.5
0.6
0.7
0.8
Wavelength (micrometer)
Shadows
0
0.5
1
Reflectance
1
0.5
0.6
0.7
0.8
Wavelength (micrometer)
Pavement
0
0.5
1
Reflectance
0.76
0.24
Figure 6. Estimated GMM in the wavelength-reÔ¨Çectance space for the Pavia
University dataset. The background gray image represents the histogram
created by placing the pure pixel spectra into the reÔ¨Çectance bins at each
wavelength. The different colors represent different components, where the
solid curve is the center ¬µjk, the dashed curves are ¬µjk ¬± 2œÉjkvjk (œÉjk is
the square root of the large eigenvalue of Œ£jk while vjk is the corresponding
eigenvector), and the legend shows the prior probabilities.

TO APPEAR IN THE IEEE TRANSACTIONS ON IMAGE PROCESSING
12
-1.5
-1
-0.5
0
0.5
1
1.5
2
2.5
3
-1.5
-1
-0.5
0
0.5
1
1.5
2
Pixels
Meadows
Bare Soil
Painted Metal Sheets
Shadows
Pavement
Figure 7.
Scatter plot of the Pavia University dataset with the estimated
GMM. The gray dots are the projected pixels by PCA. The darkened dots
with a color represent the ground truth pure pixels for a material. The ellipses
with the same color represent the projected Gaussian components (twice the
standard deviation along the major and minor axes, covering 86% of the total
probability mass) for one endmember.
-1
0
1
2
Meadows
0
0.1
0.2
Probability
-0.5
0
0.5
1
Bare Soil
0
0.1
0.2
Probability
-4
-2
0
2
Painted Metal Sheets
0
0.1
0.2
Probability
-0.4
-0.2
0
0.2
Shadows
0
0.1
0.2
Probability
-1
-0.5
0
0.5
Pavement
0
0.1
0.2
Probability
GMM
NCM
NCM w/o PCA
Figure 8. Histograms of pure pixels for the Pavia University dataset and the
estimated distributions from GMM and NCM when projected to 1 dimension.
Table V
ABUNDANCE AND ENDMEMBER ERRORS FOR THE GULFPORT DATASET.
√ó10‚àí4
GMM
NCM
NCM w/o PCA
BCM
Asphalt
205 \ 52a
1693 \ 94
939 \ 59
1420
Grass
169 \ 58
1982 \ 121
558 \ 65
2145
Shadow
499 \ 49
1294 \ 68
921 \ 43
1315
Tree
1029 \ 89
2194 \ 234
1106 \ 185
2279
Roof
908 \ 76
2143 \ 174
1234 \ 104
1657
Mean
562 \ 65
1861 \ 138
952 \ 91
1763
a the numbers in ".\." denote the abundance and endmember errors.
Figure 9. Abundance maps for the Pavia University dataset. The correspond-
ing endmembers from left to right are meadows, bare soil, painted metal
sheets, shadows and pavement.
obstacles in linear unmixing using this distribution, including
(i) deriving the conditional probability density function of
the mixed pixel given each endmember modeled as GMM
from two perspectives; (ii) estimating the abundances and
endmember distributions by maximizing the log-likelihood
with a prior enforcing abundance smoothness and sparsity;
(iii) estimating the endmembers for each pixel given the abun-
dances and distribution parameters. The results on synthetic
and real datasets show superior accuracy compared to current
popular methods like NCM, BCM. Here we have some Ô¨Ånal
remarks.
Complexity. As analyzed in Section III-F, each itera-
tion in the estimation of abundances has spatial complexity

TO APPEAR IN THE IEEE TRANSACTIONS ON IMAGE PROCESSING
13
Figure 10. (a) Original RGB image of the Mississippi Gulfport dataset with
selected ROI and (b) Ground truth materials in the ROI with their mean
spectra.
0.4
0.6
0.8
1
Wavelength (micrometer)
Asphalt
0
0.5
1
Reflectance
1
0.4
0.6
0.8
1
Wavelength (micrometer)
Grass
0
0.5
1
Reflectance
0.42
0.39
0.2
0.4
0.6
0.8
1
Wavelength (micrometer)
Shadow
0
0.5
1
Reflectance
0.83
0.17
0.4
0.6
0.8
1
Wavelength (micrometer)
Tree
0
0.5
1
Reflectance
1
0.4
0.6
0.8
1
Wavelength (micrometer)
Grey Roof
0
0.5
1
Reflectance
0.82
0.18
Figure 11.
Estimated GMM in the wavelength-reÔ¨Çectance space for the
Mississippi Gulfport dataset. The background gray image and the curves have
the same meaning as in Fig. 6.
-1
-0.5
0
0.5
1
1.5
2
-2
-1.5
-1
-0.5
0
0.5
Pixels
Asphalt
Grass
Shadow
Tree
Grey Roof
Figure 12. Scatter plot of the Mississippi Gulfport dataset with the estimated
GMM. The ellipses and the dots have the same meaning as in Fig. 7.
-0.5
0
0.5
Asphalt
0
0.1
0.2
Probability
-0.5
0
0.5
1
Grass
0
0.1
0.2
Probability
-0.2
0
0.2
0.4
0.6
Shadow
0
0.2
0.4
Probability
-2
-1
0
1
Tree
0
0.1
0.2
Probability
-1
0
1
2
Grey Roof
0
0.5
Probability
GMM
NCM
NCM w/o PCA
Figure 13.
Histograms of pure pixels for the Gulfport dataset and the
estimated distributions from GMM and NCM when projected to 1 dimension.
O
 |K| NB2
and time complexity O
 |K| NB3
. For compar-
ison, the implemented NCM has the same complexity but with
|K| = 1. For the supervised synthetic dataset which contains
60 images, the total running time of GMM was 9709 seconds,
on a desktop with a Intel Core i7-3820 CPU and 64 GB mem-
ory. For comparison, the running time of NCM, NCM without
PCA, and BCM was 941, 50751, 62525 seconds respectively.
In real applications, running GMM on the Pavia University
and Mississippi Gulfport ROIs required 734 seconds and 97
seconds respectively for abundance estimation (24 seconds and
17 seconds for endmember estimation), compared to 40 and
34 seconds from NCM, 1389 and 396 seconds from NCM
without PCA, 1170 and 616 seconds from BCM. As analyzed,
the main factors affecting the efÔ¨Åciency of GMM and NCMs
are |K| and B.
Limitation. The complexity analysis leads to one limitation
of the method. That is, the complexity grows exponentially

TO APPEAR IN THE IEEE TRANSACTIONS ON IMAGE PROCESSING
14
Figure 14.
Abundance maps for the Gulfport dataset. The corresponding
endmembers from left to right are asphalt, grass, shadow, tree and grey roof.
with increasing numbers of components. This could cause
problems for a large amount of pure pixels. To overcome this
shortcoming, there are some empirical workarounds, such as
reducing the number of components by introducing thresholds,
or reducing the number of pure pixels to a Ô¨Åxed number
by random sampling. Another limitation is that the proposed
unsupervised version assumes presence of regions of pure
pixels, which mostly happens in urban scenes. For scenes with
a lot of mixed pixels, this assumption may not hold. Note that
unsupervised unmixing is a very challenging problem. The
previous works for this problem all assume several properties
on the abundances and endmembers [21], [22], [23]. Hence,
this limitation exists more or less in all the works on this
problem. Finally, the method was only evaluated on real urban
datasets with only ground truth on pure pixels: it is therefore
unclear if the abundance estimation on mixed pixels is also
accurate. This is due to lack of datasets and ground truth in
the hyperspectral community. We plan to validate it on a more
comprehensive dataset given in [31] in the future.
Future work. The proposed GMM formulation has several
applications that we can investigate in the future. First, in
target detection, endmember variability may interfere with
the target as well as the background [53]. By modeling the
target or the background as spectra sampled from GMM
distributions, we may devise more sophisticated and accurate
target detection algorithms. Second, in fusion of hyperspectral
and multispectral images, the LMM is usually used to over-
come the underdetermined nature of the problem [54], [55].
However, the LMM does not hold in real scenarios as shown
in this work. If we use the LMM with endmember variability,
which is modeled by samples from GMM distributions, we
may have a fusion algorithm that better Ô¨Åts the data. Finally,
in estimating the noise or intrinsic dimension of hyperspectral
images, simulated data are generated to quantify the results
[46]. When these simulated data are created, usually the LMM
is used without considering the endmember variability. Using
the GMM formulation, we may generate distinct endmembers
for each pixel and create more realistic synthetic data.
REFERENCES
[1] M. Berman, H. Kiiveri, R. Lagerstrom, A. Ernst, R. Dunne, and J. F.
Huntington, ‚ÄúICE: A statistical approach to identifying endmembers in
hyperspectral images,‚Äù IEEE Trans. on Geoscience and Remote Sensing,
vol. 42, no. 10, pp. 2085‚Äì2095, 2004.
[2] J. M. Nascimento and J. M. Bioucas Dias, ‚ÄúVertex component analysis:
A fast algorithm to unmix hyperspectral data,‚Äù
IEEE Trans. on
Geoscience and Remote Sensing, vol. 43, no. 4, pp. 898‚Äì910, 2005.
[3] A. Zare, P. D. Gader, O. Bchir, and H. Frigui,
‚ÄúPiecewise convex
multiple-model endmember detection and spectral unmixing,‚Äù
IEEE
Trans. on Geoscience and Remote Sensing, vol. 51, no. 5, pp. 2853‚Äì
2862, 2013.
[4] J. M. Bioucas-Dias, A. Plaza, N. Dobigeon, M. Parente, Q. Du, P. D.
Gader, and J. Chanussot, ‚ÄúHyperspectral unmixing overview: Geomet-
rical, statistical, and sparse regression-based approaches,‚Äù IEEE Journal
of Selected Topics in Applied Earth Observations and Remote Sensing,
vol. 5, no. 2, pp. 354‚Äì379, 2012.
[5] N. Keshava and J. F. Mustard,
‚ÄúSpectral unmixing,‚Äù
IEEE Signal
Processing Magazine, vol. 19, no. 1, pp. 44‚Äì57, 2002.
[6] B. Hapke, ‚ÄúBidirectional reÔ¨Çectance spectroscopy: 1. theory,‚Äù Journal
of Geophysical Research: Solid Earth (1978‚Äì2012), vol. 86, no. B4, pp.
3039‚Äì3054, 1981.
[7] A. Halimi, Y. Altmann, N. Dobigeon, and J.-Y. Tourneret, ‚ÄúNonlinear
unmixing of hyperspectral images using a generalized bilinear model,‚Äù
IEEE Trans. on Geoscience and Remote Sensing, vol. 49, no. 11, pp.
4153‚Äì4162, 2011.
[8] B. Somers, K. Cools, S. Delalieux, J. Stuckens, D. Van der Zande, W. W.
Verstraeten, and P. Coppin, ‚ÄúNonlinear hyperspectral mixture analysis
for tree cover estimates in orchards,‚Äù Remote Sensing of Environment,
vol. 113, no. 6, pp. 1183‚Äì1193, 2009.
[9] R. Heylen and P. D. Gader, ‚ÄúNonlinear spectral unmixing with a linear
mixture of intimate mixtures model,‚Äù
IEEE Geoscience and Remote
Sensing Letters, vol. 11, no. 7, pp. 1195‚Äì1199, 2014.
[10] J. Broadwater and A. Banerjee,
‚ÄúA generalized kernel for areal and
intimate mixtures,‚Äù in 2nd Workshop on Hyperspectral Image and Signal
Processing: Evolution in Remote Sensing (WHISPERS). IEEE, 2010, pp.
1‚Äì4.
[11] J. Broadwater, R. Chellappa, A. Banerjee, and P. Burlina, ‚ÄúKernel fully
constrained least squares abundance estimates,‚Äù in IEEE International
Geoscience and Remote Sensing Symposium (IGARSS). IEEE, 2007, pp.
4041‚Äì4044.
[12] R. Heylen, M. Parente, and P. D. Gader,
‚ÄúA review of nonlinear
hyperspectral unmixing methods,‚Äù IEEE Journal of Selected Topics in
Applied Earth Observations and Remote Sensing, vol. 7, no. 6, pp. 1844‚Äì
1868, 2014.
[13] B. Somers, G. P. Asner, L. Tits, and P. Coppin, ‚ÄúEndmember variability
in spectral mixture analysis: A review,‚Äù Remote Sensing of Environment,
vol. 115, no. 7, pp. 1603‚Äì1616, 2011.
[14] A. Zare and K. Ho, ‚ÄúEndmember variability in hyperspectral analysis:
Addressing spectral variability during spectral unmixing,‚Äù IEEE Signal
Processing Magazine, vol. 31, no. 1, pp. 95‚Äì104, 2014.
[15] X. Du, A. Zare, P. D. Gader, and D. Dranishnikov,
‚ÄúSpatial and
spectral unmixing using the Beta compositional model,‚Äù IEEE Journal
of Selected Topics in Applied Earth Observations and Remote Sensing,
vol. 7, no. 6, pp. 1994‚Äì2003, 2014.
[16] A. Zare and P. D. Gader, ‚ÄúPCE: Piecewise convex endmember detec-
tion,‚Äù IEEE Trans. on Geoscience and Remote Sensing, vol. 48, no. 6,
pp. 2620‚Äì2632, 2010.
[17] D. A. Roberts, M. Gardner, R. Church, S. Ustin, G. Scheer, and
R. Green, ‚ÄúMapping chaparral in the Santa Monica Mountains using
multiple endmember spectral mixture models,‚Äù
Remote Sensing of
Environment, vol. 65, no. 3, pp. 267‚Äì279, 1998.
[18] A. Halimi, N. Dobigeon, and J.-Y. Tourneret, ‚ÄúUnsupervised unmixing
of hyperspectral images accounting for endmember variability,‚Äù IEEE
Trans. on Image Processing, vol. 24, no. 12, pp. 4904‚Äì4917, 2015.

TO APPEAR IN THE IEEE TRANSACTIONS ON IMAGE PROCESSING
15
[19] O. Eches, N. Dobigeon, C. Mailhes, and J.-Y. Tourneret,
‚ÄúBayesian
estimation of linear mixtures using the normal compositional model:
Application to hyperspectral imagery,‚Äù IEEE Trans. on Image Process-
ing, vol. 19, no. 6, pp. 1403‚Äì1413, 2010.
[20] C. A. Bateson, G. P. Asner, and C. A. Wessman, ‚ÄúEndmember bundles:
A new approach to incorporating endmember variability into spectral
mixture analysis,‚Äù
IEEE Trans. on Geoscience and Remote Sensing,
vol. 38, no. 2, pp. 1083‚Äì1094, 2000.
[21] L. Drumetz, M.-A. Veganzones, S. Henrot, R. Phlypo, J. Chanussot,
and C. Jutten, ‚ÄúBlind hyperspectral unmixing using an extended linear
mixing model to address spectral variability,‚Äù
IEEE Transactions on
Image Processing, vol. 25, no. 8, pp. 3890‚Äì3905, 2016.
[22] P.-A. Thouvenin, N. Dobigeon, and J.-Y. Tourneret,
‚ÄúHyperspectral
unmixing with spectral variability using a perturbed linear mixing
model,‚Äù IEEE Transactions on Signal Processing, vol. 64, no. 2, pp.
525‚Äì538, 2016.
[23] A. Halimi, P. Honeine, and J. M. Bioucas-Dias, ‚ÄúHyperspectral unmixing
in presence of endmember variability, nonlinearity, or mismodeling
effects,‚Äù IEEE Transactions on Image Processing, vol. 25, no. 10, pp.
4565‚Äì4579, 2016.
[24] B. Zhang, L. Zhuang, L. Gao, W. Luo, Q. Ran, and Q. Du, ‚ÄúPSO-EM:
A hyperspectral unmixing algorithm based on normal compositional
model,‚Äù IEEE Trans. on Geoscience and Remote Sensing, vol. 52, no.
12, pp. 7782‚Äì7792, 2014.
[25] O. Eches, N. Dobigeon, and J.-Y. Tourneret, ‚ÄúEstimating the number
of endmembers in hyperspectral images using the normal compositional
model and a hierarchical Bayesian algorithm,‚Äù IEEE Journal of Selected
Topics in Signal Processing, vol. 4, no. 3, pp. 582‚Äì591, 2010.
[26] C. Song, ‚ÄúSpectral mixture analysis for subpixel vegetation fractions
in the urban environment: How to incorporate endmember variability?,‚Äù
Remote Sensing of Environment, vol. 95, no. 2, pp. 248‚Äì263, 2005.
[27] J.-P. Combe, S. Le Mouelic, C. Sotin, A. Gendrin, J. Mustard, L. Le Deit,
P. Launeau, J.-P. Bibring, B. Gondet, Y. Langevin, et al., ‚ÄúAnalysis of
omega/mars express data hyperspectral data using a multiple-endmember
linear spectral unmixing model (melsum): Methodology and Ô¨Årst re-
sults,‚Äù Planetary and Space Science, vol. 56, no. 7, pp. 951‚Äì975, 2008.
[28] G. P. Asner and D. B. Lobell,
‚ÄúA biogeophysical approach for
automated SWIR unmixing of soils and vegetation,‚Äù Remote sensing
of environment, vol. 74, no. 1, pp. 99‚Äì112, 2000.
[29] G. P. Asner and K. B. Heidebrecht, ‚ÄúSpectral unmixing of vegetation,
soil and dry carbon cover in arid regions: comparing multispectral and
hyperspectral observations,‚Äù International Journal of Remote Sensing,
vol. 23, no. 19, pp. 3939‚Äì3958, 2002.
[30] A. Castrodad, Z. Xing, J. B. Greer, E. Bosch, L. Carin, and G. Sapiro,
‚ÄúLearning discriminative sparse representations for modeling, source
separation, and mapping of hyperspectral imagery,‚Äù IEEE Transactions
on Geoscience and Remote Sensing, vol. 49, no. 11, pp. 4263‚Äì4281,
2011.
[31] E. B. Wetherley, D. A. Roberts, and J. P. McFadden,
‚ÄúMapping
spectrally similar urban materials at sub-pixel scales,‚Äù Remote Sensing
of Environment, vol. 195, pp. 170‚Äì183, 2017.
[32] D. Stein, ‚ÄúApplication of the normal compositional model to the analysis
of hyperspectral imagery,‚Äù in IEEE Workshop on Advances in Techniques
for Analysis of Remotely Sensed Data, 2003, pp. 44‚Äì51.
[33] L. Tits, B. Somers, and P. Coppin, ‚ÄúThe potential and limitations of a
clustering approach for the improved efÔ¨Åciency of multiple endmember
spectral mixture analysis in plant production system monitoring,‚Äù IEEE
Transactions on Geoscience and Remote Sensing, vol. 50, no. 6, pp.
2273‚Äì2286, 2012.
[34] M.-D. Iordache, L. Tits, J. M. Bioucas-Dias, A. Plaza, and B. Somers, ‚ÄúA
dynamic unmixing framework for plant production system monitoring,‚Äù
IEEE Journal of Selected Topics in Applied Earth Observations and
Remote Sensing, vol. 7, no. 6, pp. 2016‚Äì2034, 2014.
[35] L. Tits, B. Somers, W. Saeys, and P. Coppin,
‚ÄúSite-speciÔ¨Åc plant
condition monitoring through hyperspectral alternating least squares un-
mixing,‚Äù IEEE Journal of Selected Topics in Applied Earth Observations
and Remote Sensing, vol. 7, no. 8, pp. 3606‚Äì3618, 2014.
[36] J. B. Lee, A. S. Woodyatt, and M. Berman,
‚ÄúEnhancement of high
spectral resolution remote-sensing data by a noise-adjusted principal
components transform,‚Äù IEEE Transactions on Geoscience and Remote
Sensing, vol. 28, no. 3, pp. 295‚Äì304, 1990.
[37] Y. Zhou, A. Rangarajan, and P. D. Gader, ‚ÄúA spatial compositional model
for linear unmixing and endmember uncertainty estimation,‚Äù
IEEE
Trans. on Image Processing, vol. 25, no. 12, pp. 5987‚Äì6002, 2016.
[38] D. Achlioptas and F. McSherry, ‚ÄúOn spectral learning of mixtures of
distributions,‚Äù in Learning Theory, pp. 458‚Äì469. Springer, 2005.
[39] N. Vlassis and A. Likas, ‚ÄúA greedy EM algorithm for gaussian mixture
learning,‚Äù Neural Processing Letters, vol. 15, no. 1, pp. 77‚Äì87, 2002.
[40] K. Lange, Optimization, Springer, 2013.
[41] X.-L. Meng and D. B. Rubin, ‚ÄúMaximum likelihood estimation via the
ECM algorithm: A general framework,‚Äù Biometrika, vol. 80, no. 2, pp.
267‚Äì278, 1993.
[42] D. P. Bertsekas, Nonlinear programming, Athena ScientiÔ¨Åc, 1999.
[43] C.-J. Lin, ‚ÄúProjected gradient methods for nonnegative matrix factor-
ization,‚Äù Neural Computation, vol. 19, no. 10, pp. 2756‚Äì2779, 2007.
[44] G. J. McLachlan and S. Rathnayake, ‚ÄúOn the number of components
in a Gaussian mixture model,‚Äù Wiley Interdisciplinary Reviews: Data
Mining and Knowledge Discovery, vol. 4, no. 5, pp. 341‚Äì355, 2014.
[45] P. Smyth,
‚ÄúModel selection for probabilistic clustering using cross-
validated likelihood,‚Äù Statistics and Computing, vol. 10, no. 1, pp. 63‚Äì
72, 2000.
[46] L. Gao, Q. Du, B. Zhang, W. Yang, and Y. Wu, ‚ÄúA comparative study
on linear regression-based noise estimation for hyperspectral imagery,‚Äù
IEEE Journal of Selected Topics in Applied Earth Observations and
Remote Sensing, vol. 6, no. 2, pp. 488‚Äì498, 2013.
[47] R. Roger, ‚ÄúPrincipal components transform with simple, automatic noise
adjustment,‚Äù International Journal of Remote Sensing, vol. 17, no. 14,
pp. 2719‚Äì2727, 1996.
[48] N. Guan, D. Tao, Z. Luo, and B. Yuan,
‚ÄúManifold regularized dis-
criminative nonnegative matrix factorization with fast gradient descent,‚Äù
IEEE Trans. on Image Processing, vol. 20, no. 7, pp. 2030‚Äì2048, 2011.
[49] C. M. Bishop, Pattern recognition and machine learning, springer New
York, 2006.
[50] A. Baldridge, S. Hook, C. Grove, and G. Rivera, ‚ÄúThe ASTER spectral
library version 2.0,‚Äù Remote Sensing of Environment, vol. 113, no. 4,
pp. 711‚Äì715, 2009.
[51] P. Gader, A. Zare, R. Close, J. Aitken, and G. Tuell, ‚ÄúMUUFL Gulfport
hyperspectral and LiDAR airborne data set,‚Äù Tech. Rep. REP-2013-570,
Univ. Florida, Gainesville, FL, USA, 2013.
[52] X. Du and A. Zare, ‚ÄúTechnical report: Scene label ground truth map
for MUUFL Gulfport data set,‚Äù Tech. Rep. 20170417, Univ. Florida,
Gainesville, FL, USA, 2017.
[53] C. Jiao and A. Zare, ‚ÄúFunctions of multiple instances for learning target
signatures,‚Äù IEEE Transactions on Geoscience and Remote Sensing, vol.
53, no. 8, pp. 4670‚Äì4686, 2015.
[54] N. Yokoya, T. Yairi, and A. Iwasaki,
‚ÄúCoupled nonnegative matrix
factorization unmixing for hyperspectral and multispectral data fusion,‚Äù
IEEE Transactions on Geoscience and Remote Sensing, vol. 50, no. 2,
pp. 528‚Äì537, 2012.
[55] Q. Wei, N. Dobigeon, and J.-Y. Tourneret, ‚ÄúFast fusion of multi-band
images based on solving a sylvester equation,‚Äù IEEE Transactions on
Image Processing, vol. 24, no. 11, pp. 4109‚Äì4121, 2015.
Yuan Zhou received the B.E degree in Soft-
ware Engineering (2008), the M.E. degree in Com-
puter Application Technology (2011), both from
Huazhong University of Science and Technology,
Wuhan, Hubei, China. Then he worked in Shanghai
UIH as a software engineer for two years. Since
2013, he has been a Ph.D. student in the Department
of CISE, University of Florida, Gainesville, FL,
USA. His research interests include image process-
ing, computer vision and machine learning.
Anand Rangarajan is in the Department of Com-
puter and Information Science and Engineering,
University of Florida, Gainesville, FL, USA. His
research interests are machine learning, computer
vision and the scientiÔ¨Åc study of consciousness.

TO APPEAR IN THE IEEE TRANSACTIONS ON IMAGE PROCESSING
16
Paul
Gader
(M‚Äô86‚ÄìSM‚Äô09‚ÄìF‚Äô11)
received
the
Ph.D. degree in mathematics for image-processing-
related research from the University of Florida,
Gainesville, FL, USA, in 1986. He was a Se-
nior Research Scientist with Honeywell, a Research
Engineer and a Manager with the Environmental
Research Institute of Michigan, Ann Arbor, MI,
USA, and a Faculty Member with the University
of Wisconsin, Oshkosh, WI, USA, the University of
Missouri, Columbia, MO, USA, and the University
of Florida, FL, USA, where he is currently a Pro-
fessor of Computer and Information Science and Engineering. He performed
his Ô¨Årst research in image processing in 1984 working on algorithms for
the detection of bridges in forward-looking infrared imagery as a Summer
Student Fellow at Eglin Air Force Base. He has since worked on a wide
variety of theoretical and applied research problems including fast computing
with linear algebra, mathematical morphology, fuzzy sets, Bayesian meth-
ods, handwriting recognition, automatic target recognition, biomedical image
analysis, landmine detection, human geography, and hyperspectral and light
detection, and ranging image analysis projects. He has authored/co-authored
hundreds of refereed journal and conference papers.

