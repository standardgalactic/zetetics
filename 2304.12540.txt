1
Opinion Control under Adversarial Network
Perturbation: A Stackelberg Game Approach
Yuejiang Li, Zhanjiang Chen, H. Vicky Zhao
Abstractâ€”The emerging social network platforms enable users
to share their own opinions, as well as to exchange opinions with
others. However, adversarial network perturbation, where mali-
cious users intentionally spread their extreme opinions, rumors
and misinfomration to others, is ubiquitous in social networks.
Such adversarial network perturbation greatly inï¬‚uences the
opinion formation of the public, and threatens our societies. Thus,
it is critical to study and control the inï¬‚uence of adversarial
network perturbation. Although tremendous efforts have been
made in both academia and industry to guide and control the
public opinion dynamics, most of these works assume that the
network is static, and ignore such adversarial network perturba-
tion. In this work, based on the well-accepted Friedkin-Johnsen
opinion dynamics model, we model the adversarial network
perturbation, and analyze its impact on the networksâ€™ opinion.
Then, from the adversaryâ€™s perspective, we analyze its optimal
network perturbation, which maximally changes the networksâ€™
opinion. Next, from the network defenderâ€™s perspective, we
formulate a Stackelberg game, and aim to control the networkâ€™s
opinion even under such adversarial network perturbation. We
device a projected subgradient algorithm to solve the formualted
Stackelberg game. Extensive simulations on real social networks
validate our analysis of the advesarial network perturbationâ€™s
inï¬‚uence and the effectiveness of the proposed opinion control
algorithm.
I. INTRODUCTION
The emerging online social network (OSN) platforms, such
as Facebook, Twitter, and WeChat, etc., greatly strengthen the
connections among people around the world and ultimately
shaped the way of how people form their opinions. People
can easily share their own information anywhere and anytime,
and they can also exchange opinions through comments, likes,
or reposts. In addition, users in social network platforms can
not only interact with their own known friends. They can
also exploit the recommendation function in OSN platforms,
interact with those they did not know, and expand their circles
all the time.
It is a controversial issue that people can gain other strangers
information and opinions in such a convenient way. On the
one hand, governments can use OSN platforms to spread
their public statements. One the other hand, some malicious
users and partisan media inject their extreme opinions [1],
inï¬‚uence other innocent users, and trigger severe social riots.
A recent example is the â€œstorming of U.S. Capitolâ€ in Jan.
2021. Inï¬‚amed by President Trumpâ€™s speech and tweets, â€œï¬‚ag-
waving, chanting and cursing throngs overwhelmed security
Y.
Li,
Z.
Chen
and
H.
V.
Zhao
was
with
the
Department
of
Automation, Tsinghua University, Beijing, 10084 P. R. China e-mail:
lyj18,czj17@mails.tsinghua.edu, vzhao@tsinghua.edu.cn.
Manuscript received April 19, 2005; revised August 26, 2015.
barriers, and the whole building was lockdown [2].â€ Thus, it
is critical to investigate the inï¬‚uence of such extreme opinions,
evaluate their impact on the OSN platforms, and further design
effective defense mechanism to control the spread of such
extreme opinions.
A. Literature Review
Opinion Dynamics Models. Modeling and analyzing opin-
ion dynamics in social networks have received research atten-
tion from different disciplines. In the literature, there were two
lines of works that modeled and analyzed opinion dynamics in
social networks. The ï¬rst studied the discrete-valued opinion
scenario, A line of works built discrete opinion dynamics
models and studied binary opinion scenario, for example, to
support the Democrats or the Republicans. In the discrete
models, users imitated their neighborsâ€™ opinions to update their
own. Popular imitation rules included random imitation rule
in the voter model [3], the local majority rule [4], and the
linear threshold rule [5], etc. The imitation in the discrete
models resulted in usersâ€™ opinions to change to change from
one extreme to the other. To model how users opinions
were changed and formed in a gradual process, the other
continuous-valued opinion dynamics models were proposed.
In the continuous models, opinion values were in a certain
range, with two endpoints representing two extreme opinions.
One of the fundamental works of the continuous model was
the DeGroot model [6], where users updated their opinions by
averaging those of his/her neighbors. In the DeGroot model,
it would reach the opinion consensus state where all agents
held the same opinion. Hegselmann and Krause assumed that
users would ignore opinions that were too far from theirs when
updating opinions, and they found that usersâ€™ opinions would
converge to different clusters at equilibrium [7]. The Friedkin-
Johnsen (FJ) model incorporated usersâ€™ intrinsic beliefs and
their stubbornness into the DeGroot model, and it was shown
in [8], [9] that such stubbornness could cause opinion polar-
ization where users held different opinions at the equilibrium.
In addition, the FJ model was validated by small and medium
group of social experiments [10].
Opinion Control. Based on the above opinion dynamics
models, there were many works studying how to control public
opinion. These works mainly focused on two objectives: the
total opinion and the opinion polarization. The total opinion
characterized the overall stance of the whole population.
The work in [11] ï¬rst studied the problem of maximizing
total opinion in the discrete opinion dynamics models. They
proposed a greedy algorithm to select a certain number of
arXiv:2304.12540v1  [cs.CY]  25 Apr 2023

2
â€œseed usersâ€ that can maximized the total opinion. The work
in [12] further extended this algorithm to the continuous
opinion dynamics models. The total opinion was optimized by
controlling usersâ€™ stubbornness in [13] and by manipulating
usersâ€™ intrinsic beliefs through persuasion in [14]. Opinion
polarization quantiï¬ed the discrepancies among usersâ€™ opin-
ions. The work in [15] minimized the opinion polarization by
controlling usersâ€™ intrinsic believes. Furthermore, the works
in [16] and [17] studied how network structure inï¬‚uence the
opinion polarization, respectively. Chen et al.. studied how
to maximize the opinion polarization from the adversaryâ€™s
perspective [18], [19]. Although the above algorithms could
efï¬ciently control the total opinion or the opinion polarization,
they were developed based on the assumption that the network
structure was static. That is, the connections and inï¬‚uence
strength among all users did not change during the opinion
dynamics process.
Dynamic Network Structure. In reality, the network struc-
ture may change from time to time [20], [21]. The work
in [22] proposed the preferential attachment algorithm that
the newly added user were more likely to follow those with
more followers. The preferential attachment could explain the
power-law degree distribution of social networks in reality.
Some works explored the data from social network platforms
and analyzed how real social networks changed over time.
The work in [23] showed that the recommending algorithms
in social network platforms tended to connect users with
similar interests together. This could further resulted in the
â€œï¬lter bubbleâ€ effect [24] that the opinion polarization was
increased. The work in [25] proposed perturbation centrality
based on the perturbation analysis of the network structure.
Furthermore, the perturbation centrality was used in graph-
based optimization problem, which was proved to be robust
against edge failure.
Different from the prior works on opinion control, which
assumed that the network structure is static, in this work, we
consider the scenario where some attackers can perturb the
network structure by spread their extreme opinions to other
target users. We model such adversarial network perturbation.
From the adversaryâ€™s perspective, we aim to analyze the
optimal strategy for the adversary to choose the attackers
and the corresponding target users. Then, from the network
defenderâ€™s perspective, we device a opinion control scheme
which is robust to the adversarial network perturbation. Our
investigation is important to the development of robust online
social networks.
B. Our Contribution
Our contributions can be summarized as follows:
1) We model the network perturbation and theoretically
analyze its impact on the total opinion.
2) We consider the scenario where the adversary can exploit
the network perturbation to maximize the total opinion,
while the network defender aims to minimize the total
opinion under such adversarial network perturbation. We
model such scenario as a Stackelberg game, played
between the network defender and the adversarial.
3) From the adversaryâ€™s perspective, we theoretically ana-
lyze the optimal strategy to choose the attacker and the
corresponding target users, so that the total opinion is
maximized.
4) From the network defenderâ€™s perspective, we formulate
a min-max game which aims to minimize the total
opinion, even if the network is perturbed by the adversary
with their optimal strategy. We further device a project
subgradient method to efï¬ciently solve the formulated
min-max game.
5) We conduct extensive experiments on real social networks
to validate the analysis of the network perturbation, and
the optimal strategy for the adversary. We also use real
social networks to test the defense algorithms.
The rest of this paper is organized as follows. In Section II,
we introduce the basics of the Friedkin-Johnsen opinion
dynamics models and opinion control. In Section III, we
model the network perturbation, and formulate the Stackelberg
game played between the adversary and the network defender.
Then, in Section IV, we analyze the optimal strategy for the
adversary to maximize the total opinion. Next, in Section V,
from the defenderâ€™s perspective, we solve the stackelberg
game to minimize the total opinion under the adversarial
network perturbation. The simulation and experiments results
are summarized in Section VI, and the conclusion is drawn in
Section VII.
II. PRELIMINARY
In this section, we brieï¬‚y review the Friedkin-Johnsen (FJ)
opinion dynamics model, and introduce the opinion minimiza-
tion problem studied in this paper.
A. The Friedkin-Johnsen Model
In this work, we consider the scenario that there are n users
in network, discussing a topic that is harmful to public security.
The network can be modeled as a graph, where nodes represent
users, and an directed edge (i, j) indicates that user-j can
inï¬‚uence user-i. Let W
W
W be the adjacency matrix of the graph,
whose entry Wij > 0 shows the inï¬‚uence weight of user j on
user i if there is an directed edge (i, j); otherwise, Wij = 0.
Following the original FJ model [8], for any user i, the total
inï¬‚uence weight of all other users on user v are uniï¬ed to 1.
That is, W
W
W111 = 111.
In the FJ model, user i holds internal opinion si which
shows his/her intrinsic belief on the discussed topic. Let
sss = [s1, Â· Â· Â· , sn]T be all usersâ€™ internal opinions. The opinion
formation process is divided into discrete time steps. At
time step t, the expressed opinions of users are zzz(t) =
[z1(t), Â· Â· Â· , zn(t)]T . Each user aggregates his/her neighborsâ€™
expressed opinions together with his/her own internal opinion,
and updates the expressed opinion at the next time step as
zi(t + 1) = Î±isi + (1 âˆ’Î±i) Â·
X
j
Wijzj(t),
(1)
where 0 < Î±i < 1 is the stubbornness of user i. The larger Î±i
is, user i is more stubborn and follows his/her own intrinsic
belief more.

3
The expressed opinions of the whole population evolve as
the above updating process, and ï¬nally reach the equilibrium
state [8]
zzzâˆ—= BBBAAAsss, where
(2)
BBB = [III âˆ’(III âˆ’AAA)W
W
W]âˆ’1 and AAA = Diag (Î±i) .
(3)
From (2), the equilibrium expressed opinions depends on the
network structure W
W
W, all users internal opinions sss, and their
stubbornness AAA.
B. Opinion Control
As the total opinion shows the whole populationâ€™s support
of the discussed topic, following the previous works in [13],
[14], [26], we aim to minimize the total opinion at equilibrium,
that is
f = 111Tzzzâˆ—= 111TBBBAAAsss
(4)
In the following, we refer to f as total opinion for short
when no confusions are made. We adopt the â€œMin-Totalâ€
algorithms in [14] as the baseline methods. In the â€œMin-
Totalâ€ algorithm, users internal opinions can be controlled
through e.g., persuasion, but limited to a certain budget Âµ.
Consequently, the total opinion minimization problem can be
formulated as
min
xxx
111TBBBAAAxxx
s.t.

111T (sss âˆ’xxx) â‰¤Âµ,
000 â‰¤xxx â‰¤sss.
(5)
The formulated minimization is convex, and can be solved
efï¬ciently using linear searching algorithm [14]. The above
algorithm can obtain the optimal control when the network
structure W
W
W is static and unchanged. However, both evidence
in literature [22] and real data [20], [21] have shown that the
network structure may change during the opinion formation
process. In the following, we model the change of network
structure, and analyze its impact on the total opinion.
III. ADVERSARIAL NETWORK PERTURBATION AND
PROBLEM FORMULATION
In online social network platforms, a user v can easily
explore other users opinion, e.g., trending tweets on the ex-
ploration page of Twitter and private messages from strangers
on Instagram, even though they are not vâ€™s neighbors. Some
malicious users may exploit this nature of online social net-
work platforms and intentionally spread their own ideas to the
public. We deï¬ne this intentional change in network structure
as adversarial network perturbation. In this section, we model
the adversarial network perturbation, and formulate the robust
opinion minimization problem under such perturbation.
A. Adversarial Network Perturbation Model
In this work, we consider the scenario where the adversary
aims to promote the support of the discussing harmful topic,
and try to maximize the total opinion of the network. We
assume that the adversary can manipulate at most m users
as the attackers, and push the expressed opinions of these
attackers to some target users. Let A and T be the set of
attackers and that of target users, respectively. For an attacker
u âˆˆA, the target user of him/her is denoted by Tu. In this
work, we assume that each attacker can push his/her expressed
opinions to at most k target users, that is, |Tu| â‰¤k âˆ€u âˆˆA.
For a target user v âˆˆT , let Av be the attackers that inï¬‚uences
this target user. Consequently, we have
[
uâˆˆA
Tu = A, and
[
vâˆˆT
Av = T .
(6)
For a target user v âˆˆT , when an attacker u âˆˆAv pushes
his/her expressed opinion to v, we assume that it inï¬‚uences
the target user v with weight p. We also deï¬ne p as the
perturbation coefï¬cient. To ensure that the total inï¬‚uence
weights of other users on the target user v is uniï¬ed to 1,
the inï¬‚uence weights of vâ€™s original neighbors is discounted
by (1 âˆ’|Av|p), and |Av|p â‰¤1. Consequently, the inï¬‚uence
weights on target user v becomes
ËœWvu =
(
(1 âˆ’|Av|p) Â· Wvu
u /âˆˆAv;
(1 âˆ’|Av|p) Â· Wvu + p
u âˆˆAv.
(7)
For other users Â¯v /âˆˆT , others usersâ€™ inï¬‚uence weights on
him/her do not change. The adjacency matrix after perturbation
becomes
Ëœ
W
W
W = W
W
W + p Ã— âˆ†
âˆ†
âˆ†W , where
(8)
âˆ†
âˆ†
âˆ†W =
X
vâˆˆT
eeev
X
uâˆˆAv
eeeT
u âˆ’
X
vâˆˆT
|Av|eeeveeeT
v W
W
W.
(9)
Since the adjacency matrix has changed to Ëœ
W
W
W, with (2), the
expressed opinion at equilibrium becomes
Ëœzzzâˆ—= ËœBBBAAAsss, where ËœBBB = (III âˆ’(III âˆ’AAA) Ëœ
W
W
W)âˆ’1,
(10)
and the total opinion becomes
Ëœf = 111T ËœBBBAAAsss.
(11)
B. Network Defense under Adversarial Perturabtion
Owing to the existence of the potential adversarial network
perturbation, in this work, we formulate the following network
defense problem.
min
xxx
max
A,Tu 111T ËœBBBAAAxxx
s.t.
ï£±
ï£´
ï£´
ï£²
ï£´
ï£´
ï£³
111T (sss âˆ’xxx) â‰¤Âµ,
000 â‰¤xxx â‰¤sss,
|A| â‰¤m,
|Tu| â‰¤k, âˆ€u âˆˆA.
(12)
The formulated network defense problem in (12) can be
interpreted as a zero-sum game played between the adversary
and the defender. The adversary can perturb the network
as analyzed in Section III-A to maximize the total opinion.
This corresponds to the inner maximization of the objective
function in (12). For the defender, similar to the prior works in
[14], [17], we assume that they control usersâ€™ innate opinions
with a certain budget to minimize the total opinion. Different
from the opinion minimization problem in (5), here, the
defender is aware of the existence of the adversary, and assume
that the adversary is rational to maximize the total opinion.

4
Thus, the objective of the defender in (12) is the maximized
total opinion by the adversary.
To solve the proposed network defense problem under the
adversarial network perturbation, in the following, we ï¬rst
analyze from the adversaryâ€™s perspective to ï¬nd the optimal
solution to the inner maximization of (12). Then, based on
the analytical solution to the inner maximization problem, we
further develop efï¬cient algorithm to solve (12).
IV. OPTIMAL ADVERSARIAL NETWORK PERTURBATION
In this section, from the adversaryâ€™s perspective, given
that the controlled internal opinions are sss, we study how to
maximize the total opinion by selecting attackers A and the
corresponding target users Tu for u âˆˆA. That is, we solve
the following problem
max
A,Tu
111T ËœBBBAAAsss
s.t.

|A| â‰¤m,
|Tu| â‰¤k, âˆ€u âˆˆA.
(13)
The ï¬rst constraint in the above shows that the adversary can
select up to m attackers, while the second constraints indicates
that each attacker u âˆˆA can perturb up to k target users.
Note that the above maximization problem is a combina-
torial problem. In addition, the optimization variables A and
Tu are included in ËœBBB. From (10), the outer inverse further
hinder the solution of the maximization. A direct method is
to use the greedy algorithm as in [11], to iteratively select the
attackers and the target users. However, computational cost is
substantial, and it is unacceptable when the network size is
sufï¬ciently large.
In the following of this section, we ï¬rst approximate the
objective function in (13). Then, based on the approximated
objective function, we develop a linear search algorithm to
solve the approximated maximization problem.
A. Approximation of Objective
Note that in real social network, users are often less likely to
be inï¬‚uenced by users who are not their friends. Consequently,
the impact of the adversarial network perturbation is limited.
In our model, this corresponds to the perturbation coefï¬cient
p is sufï¬cient small, that is, p â†’0. Based on the assumption
that p â†’0, we have the following proposition.
Proposition 1. when the network structure changed to Ëœ
W
W
W, the
total opinion with perturbation can be approximated as
Ëœf â‰ˆ111TBBBAAAsss + p Ã— 111TBBB(III âˆ’AAA)âˆ†
âˆ†
âˆ†WBBBAAAsss
(14)
Proof. Using the Taylor series, we have
Ëœf = Ëœf

p=0 + p Ã— d Ëœf
dp

p=0
+ O(p2).
When p = 0, with Ëœ
W
W
W in (8), Ëœf = f = 111TBBBAAAsss. To calculate
the second term in the above, we ï¬rst calculate d Ëœ
f
dp.
d Ëœf
dp = d(111T ËœBBBAAAsss)
dp
= 111T d ËœBBB
dp AAAsss.
As ËœBBB = (IIIâˆ’(IIIâˆ’AAA) Ëœ
W
W
W)âˆ’1, and we have ËœBBBÂ·(IIIâˆ’(IIIâˆ’AAA) Ëœ
W
W
W) =
III. Taking derivatives w.r.t. p on both sides, we have
d ËœBBB(III âˆ’(III âˆ’AAA) Ëœ
W
W
W) âˆ’ËœBBB(III âˆ’AAA)d Ëœ
W
W
W = 000.
With Ëœ
W
W
W in (9), we have d Ëœ
W
W
W = âˆ†
âˆ†
âˆ†W dp. Then, we have
d ËœBBB(III âˆ’(III âˆ’AAA) Ëœ
W
W
W) âˆ’ËœBBB(III âˆ’AAA)âˆ†
âˆ†
âˆ†W dp = 000
â‡’d ËœBBB
dp = ËœBBB(III âˆ’AAA)âˆ†
âˆ†
âˆ†W (III âˆ’(III âˆ’AAA) Ëœ
W
W
W)âˆ’1
= ËœBBB(III âˆ’AAA)âˆ†
âˆ†
âˆ†W ËœBBB
With the above derivatives we have
d Ëœf
dp

p=0
= 111T
 
d ËœBBB
dp
!
p=0
AAAsss = 111TBBB(III âˆ’AAA)âˆ†
âˆ†
âˆ†WBBBAAAsss.
Ignoring the O(p2) term, we have (14)
Note that the ï¬rst term in (14) is the total opinion f when
there is no adversarial network perturbation. Therefore, the
total opinion with network perturbation can be regarded as f
plus a perturbation term related to how network structure is
changed, i.e., âˆ†
âˆ†
âˆ†W . The contribution of the perturbation term
to the total opinion is controlled by the perturbation coefï¬cient
p. When p is larger, the total opinion at equilibrium deviates
more from the original one.
B. Optimal Selection of the Attackers and the Target Users
With the above approximation, in this section, we derive
the optimal adversarial network perturbation. That is, we ï¬nd
the optimal set of attackers Aâˆ—. Furthermore, for each optimal
attacker u âˆˆAâˆ—, we ï¬nd uâ€™s optimal target user set T âˆ—
u .
In (14), the ï¬rst term is neither related to the selection of
attackers nor target users. Thus, the maximization in (13) is
equivalent to maximizing the perturbation term, that is,
max
A,Tu
111TBBB(III âˆ’AAA)âˆ†
âˆ†
âˆ†WBBBAAAsss
s.t.

|A| â‰¤m,
|Tu| â‰¤k, âˆ€u âˆˆA.
(15)
Then, with the change of adjacency matrix in (9), the above
objective can be further written as
111TBBB(III âˆ’AAA)âˆ†
âˆ†
âˆ†WBBBAAAsss
(16)
=111TBBB(III âˆ’AAA)
 X
vâˆˆT
eeev
X
uâˆˆAv
eeeT
u âˆ’
X
vâˆˆT
|Av|eeeveeeT
v W
W
W
!
BBBAAAsss
=
X
vâˆˆT
111TBBB(III âˆ’AAA)eeev
X
uâˆˆAv
eeeT
uBBBAAAsss
(17)
âˆ’
X
vâˆˆT
|Av|111TBBB(III âˆ’AAA)eeeveeeT
v W
W
WBBBAAAsss
Note that from (2), we have zzzâˆ—= BBBAAAsss. We further deï¬ne
ccc1 â‰œ(111TBBB(III âˆ’AAA))T , and
ccc2 â‰œW
W
Wzzzâˆ—= W
W
WBBBAAAsss.
(18)

5
Consequently, the above objective can be further simpliï¬ed as
111TBBB(III âˆ’AAA)âˆ†
âˆ†
âˆ†WBBBAAAsss
(19)
=
X
vâˆˆT
c1(v)
X
uâˆˆAv
zâˆ—(u) âˆ’
X
vâˆˆT
|Av|c1(v)c2(v)
=
X
vâˆˆT
c1(v) Â·
 X
uâˆˆAv
zâˆ—(u) âˆ’|Av|c2(v)
!
=
X
vâˆˆT
c1(v) Â·
X
uâˆˆAv
 zâˆ—(u) âˆ’c2(v)

=
X
vâˆˆT
X
uâˆˆAv
c1(v) Â·
 zâˆ—(u) âˆ’c2(v)

(20)
=
X
uâˆˆA
X
vâˆˆTu
c1(v) Â·
 zâˆ—(u) âˆ’c2(v)

.
(21)
From (20) to (21), we use the relationships in (6) and exchange
the summation order. From (21), when an attacker u inï¬‚uences
a target user v, such perturbation contributes Î´u,v â‰œc1(v) Â·
 zâˆ—(u)âˆ’c2(v)

to the change of total opinion. Thus, we deï¬ne
Î´u,v as the meta-inï¬‚uence. Furthermore, for the attacker u,
his/her total inï¬‚uence on the change of total opinion is
Î´u â‰œ
X
vâˆˆTu
Î´u,v =
X
vâˆˆTu
c1(v) Â·
 zâˆ—(u) âˆ’c2(v)

(22)
We also call Î´u the individual inï¬‚uence of user u, if he/she is
selected as the attacker.
With the derivation in (21), the maximization in (15) can
be transformed as
max
A,Tu
111TBBB(III âˆ’AAA)âˆ†
âˆ†
âˆ†WBBBAAAsss
= max
A,Tu
X
uâˆˆA
X
vâˆˆTu
c1(v) Â·
 zâˆ—(u) âˆ’c2(v)

= max
A
X
uâˆˆA
 
max
Tu
X
vâˆˆTu
c1(v) Â·
 zâˆ—(u) âˆ’c2(v)

!
= max
A
X
uâˆˆA
max
Tu Î´u.
To this end, the maximization in (15) can be decoupled
as a two-step maximization problem. The ï¬rst step is to
maximize the user uâ€™s individual inï¬‚uence and choose his/her
corresponding target user set T âˆ—
u, if he/she is selected as the
attacker. That is,
max
Tu
Î´u =
X
vâˆˆTu
c1(v) Â·
 zâˆ—(u) âˆ’c2(v)

s.t.
|Tu| â‰¤k.
(23)
By solving (23) for each user u, we obtain his/her optimal
target user set T âˆ—
u
as well as his/her optimal individual
inï¬‚uence Î´âˆ—
u. Then, the second step is to solve
max
A
X
uâˆˆA
max
Tu Î´u =
X
uâˆˆA
Î´âˆ—
u
s.t.
|A| â‰¤m,
(24)
to obtain the optimal attacker set Aâˆ—. In the following, we
analyze the solutions to (23) and (24).
1) Optimal Selection of Target User: According to the
above analysis, selecting the users with the largest meta-
inï¬‚uence c1(v) Â· (zâˆ—(u) âˆ’c2(v)) as the target user Tu can
maximize the individual inï¬‚uence Î´u. Recall the deï¬nition
that c1 = (111TBBB(III âˆ’AAA))T . Since 0 < Î±i < 1, the diagonal of
(III âˆ’AAA) is always positive. From (3), using the matrix identity,
we have
BBB = [III âˆ’(III âˆ’AAA)W
W
W]âˆ’1 = I+(III âˆ’AAA)W
W
W +
 (III âˆ’AAA)W
W
W
2+Â· Â· Â· .
(25)
Consequently, all entries of BBB and 111TBBB are positive. Thus
c1(v) is always positive. Let Ë†bi be the sum of the i-th column
of BBB. We can have c1(v) = Ë†bv Â· (1 âˆ’Î±v). Therefore, if user
v is easily inï¬‚uenced by others and has a smaller Î±v, he/she
can have a larger value of c1(v), and thus, be selected as the
target user.
Next, we analyze the second term (zâˆ—(u) âˆ’c2(v)). With
(18), we can see that c2(v) = P Wvjzâˆ—(j) is the weighted
average of user vâ€™s original neighbors opinions. If the neigh-
bors of user v have smaller expressed opinions (smaller c2(v)),
user v is more likely to be selected as the target user by the
attackers. Note that if a user u is selected as the attacker, the
size of his/her optimal target users |T âˆ—
u | may be less than the
constraint k. That is, selecting more target user can not always
increase the individual inï¬‚uence Î´âˆ—
u. This is because that zâˆ—(u)
can be less than c2(v). Consequently, the term (zâˆ—(u)âˆ’c2(v))
and the meta-inï¬‚uence c1(v)Â·(zâˆ—(u)âˆ’c2(v)) can be negative.
In this sense, the individual inï¬‚uence Î´u may decrease if we
select this user v as target user.
An extreme case is the user u, who own the smallest
expressed opinion when there is no adversarial perturbation,
that is, zâˆ—(u) â‰¤zâˆ—(u), âˆ€u. We can have (zâˆ—(u)âˆ’c2(v)) â‰¤0.
Thus, user u can never be selected as the attacker. The other
extreme case is the user u, who owns the largest expressed
opinion when there is no adversarial perturbation, that is,
zâˆ—(u) â‰¥zâˆ—(u), âˆ€u. We can have (zâˆ—(u) âˆ’c2(v)) â‰¥0.
Therefore, if user u will always select k target users, it he/she
is selected as the attacker. In fact, as we can see next, user u
is always selected as the attacker.
2) Optimal Selection of Attacker: Given the optimal target
user selection criterion above, we can decide the optimal target
user set T âˆ—
u and the optimal individual inï¬‚uence Î´âˆ—
u for each
user u. Then, we can select the users with the largest optimal
individual inï¬‚uence Î´âˆ—
u as the optimal attackers Aâˆ—to solve
(24). Note that, through this method, we ï¬rst need to solve (23)
for each user, and the complexity is O(N Â·N log k). Next, we
need to solve (24) with complexity N log m. Then, the total
computational complexity is O(NÂ·(N log k+log m)). We next
analyze the properties of the selected attackers, and reduce the
computtaional complexity.
Proposition 2. For a pair of users users u1, u2 âˆˆV, if
zâˆ—(u1) â‰¥zâˆ—(u2), then we have Î´âˆ—
u1 â‰¥Î´âˆ—
u2.
Proof. Let T âˆ—
u1 and T âˆ—
u2 be the optimal target user set of u1
and u2, respectively. Since T âˆ—
u1 is the optimal target user set,

6
we have
Î´âˆ—
u1 =
X
vâˆˆT âˆ—
u1
c1(v) Â·
 zâˆ—(u1) âˆ’c2(v)

â‰¥
X
vâˆˆT âˆ—
u2
c1(v) Â·
 zâˆ—(u1) âˆ’c2(v)

.
Note that zâˆ—(u1) â‰¥zâˆ—(u2) and c1(v) â‰¥0 from the previous
section, we have
Î´âˆ—
u1 â‰¥
X
vâˆˆT âˆ—
u2
c1(v) Â·
 zâˆ—(u1) âˆ’c2(v)

â‰¥
X
vâˆˆT âˆ—
u2
c1(v) Â·
 zâˆ—(u2) âˆ’c2(v)

= Î´âˆ—
u2.
Here, we have Î´âˆ—
u1 â‰¥Î´âˆ—
u2.
From Proposition. 2, we can see that if a user with a
larger expressed opinion zâˆ—(u) withou perturbation, he/she can
have a larger optimal individual inï¬‚uence, even without the
knowledge of his/her optimal target user set. Consequently,
we can have the following corollary.
Corollary 1. Let A[m] be the set of top-m users who own
the largest expressed opinion without perturbation. That is,
A[m] = {u[1], u[2], Â· Â· Â· , u[m]}, and zâˆ—([1]) â‰¥zâˆ—([2]) â‰¥Â· Â· Â· â‰¥
zâˆ—([m]) â‰¥zâˆ—(v), for any v /âˆˆA[m]. Then, Aâˆ—âŠ†A[m].
Proof. From Proposition. 2, if zâˆ—([1]) â‰¥zâˆ—([2]) â‰¥Â· Â· Â· â‰¥
zâˆ—([m]) â‰¥zâˆ—(v), we have Î´âˆ—
u[1] â‰¥Î´âˆ—
u[2] â‰¥Â· Â· Â· â‰¥Î´âˆ—
u[m] â‰¥Î´âˆ—
v,
for any v /âˆˆA[m]. Note that from the analysis in the above
section, a user uâ€²
âˆˆA[m] can have negative individual
inï¬‚uence Î´âˆ—
uâ€² if
 zâˆ—(uâ€²)âˆ’c2(v) < 0 for all v âˆˆV. In this case,
uâ€² should not be included in Aâˆ—. Therefore, Aâˆ—âŠ†A[m].
With Proposition. 2 and Corollary. 1, we can simplify the
searching process by ï¬rst deciding the candidates of attackers
A[m] with the sorted expressed opinion zâˆ—(u). The complexity
of this step is O(N log m).Then, we only need to search
for the target user set of each candidate attacker, and decide
their optimal individual inï¬‚uence with (23). The complexity
of this step is O(m Ã— N log k). The overall complexity is
O(N log m + m Ã— N log k) = O(N Ã— (log m + m log k)),
which is signiï¬cantly smaller than O(N Â· (N log k + log m)),
when m and k are not comparable to N. The algorithm for
optimal attacking strategy is summarized in Algorithm 1.
V. NETWORK DEFENSE
Based on the above discussion of the optimal attacking by
the adversary, in this section, we consider how to minimize
the total opinion in (12) under such adversarial network
perturbation. Here, we also relax the objective function with
(14) as in Section IV, and formulate the following defense
problem.
min
sss
max
A,Tu
111TBBBAAAsss + p Ã— 111TBBB(III âˆ’AAA)âˆ†
âˆ†
âˆ†WBBBAAAsss
s.t.
ï£±
ï£´
ï£´
ï£²
ï£´
ï£´
ï£³
111T (sss0 âˆ’sss) â‰¤Âµ,
000 â‰¤sss â‰¤sss0,
|A| â‰¤m,
|Tu| â‰¤k, âˆ€u âˆˆA.
(26)
Algorithm 1: Linear search algorithm for (15)
Input: ccc1,ccc2,zzzâˆ—and constraints of m and k
Output: Optimal attacker set Aâˆ—and optimal target
user set T âˆ—
u for u âˆˆAâˆ—
1 Sorted zâˆ—(u) in descending order an pick top m of it
as the candidate attackers A[m];
2 Aâˆ—â†âˆ…;
3 for u âˆˆA[m] do Searching for optimal attackers.
4
Calculate Î´uv = c1(v) Â·
 zâˆ—(u) âˆ’c2(v)

for each v;
5
Sorted Î´uv in descending order and pick top k of it
as Tu;
6
T âˆ—
u â†âˆ…, Î´âˆ—
u â†0;
7
for v âˆˆTu do Searching for optimal target users.
8
if Î´uv > 0 then
9
Î´âˆ—
u â†Î´âˆ—
u + Î´uv, T âˆ—
u â†T âˆ—
u âˆª{v}
10
else
11
break;
12
end
13
end
14
if Î´âˆ—
u â‰¤0 then
15
break;
16
end
17
Aâˆ—â†Aâˆ—âˆª{u};
18 end
We next show the convexity of the relaxed network defense
problem in (26).
Theorem 1. The problem in (26) is convex.
Proof. Let A be the set of all possible attacker sets. That is,
for any |A| â‰¤m, âˆ€A âˆˆA. Similarly, let Tu be the set of all
possible target user set of attacker u. That is, for any |Tu| â‰¤
k, âˆ€Tu âˆˆTu. Note that the variable of the inner maximization,
i.e., A and Tu are only related to âˆ†
âˆ†
âˆ†W . Thus, we also denote
âˆ†
âˆ†
âˆ†W by âˆ†
âˆ†
âˆ†W (A, Tu) for clarity here.
Note that when A and Tu are given, the function
111TBBBAAAsss + p Ã— 111TBBB(III âˆ’AAA)âˆ†
âˆ†
âˆ†W (A, Tu)BBBAAAsss
is a linear function with respect to the decision variable sss.
Consequently, the inner maximization of (26) is the supremum
of all possible linear function of sss, when A is taken from A and
Tu is taken from Tu. Thus, the objective of the minimization
is convex with respect to sss. In terms of the constraints, both
111T (sss0 âˆ’sss) â‰¤Âµ and 000 â‰¤sss â‰¤sss0 are convex set with respect
to sss. Therefore, (26) is a convex problem.
From Theorem. 1, a direct method to solve (26) is to
introduce the upper bound ub, and transform the problem in
(26) as
min
sss,ub
ub
s.t.
ï£±
ï£´
ï£´
ï£²
ï£´
ï£´
ï£³
111T (sss0 âˆ’sss) â‰¤Âµ,
000 â‰¤sss â‰¤sss0,
111TBBBAAAsss + p111TBBB(III âˆ’AAA)âˆ†
âˆ†
âˆ†W (A, Tu)BBBAAAsss â‰¤ub,
âˆ€A âˆˆA, and âˆ€Tu âˆˆTu
(27)

7
Algorithm 2: Projected subgradient method for (26)
Input: BBB,W
W
W,AAA,sss0 and constraints of m, k, Âµ
Parameters: Initial step size Î·0 and number of
interation Tmax
Output: Optimal controlled innate opinions sssâˆ—
1 f âˆ—â†+âˆ, sssâˆ—â†sss0, ccc1 = (111TBBB(III âˆ’AAA))T , T â†0;
2 while T < Tmax do
// Attacking step: choose Aâˆ—and T âˆ—
u
3
zzzâˆ—â†BBBAAAsss, ccc2 â†W
W
Wzzzâˆ—;
4
Aâˆ—, T âˆ—
u â†Algorithm 1(ccc1,c2
c2
c2, zâˆ—, m, k);
5
Calculate âˆ†
âˆ†
âˆ†W with (9) using Aâˆ—and T âˆ—
u ;
6
f â†111TBBBAAAsss + p Ã— 111TBBB(III âˆ’AAA)âˆ†
âˆ†
âˆ†WBBBAAAsss;
7
if f âˆ—< f then
8
f âˆ—â†f, sssâˆ—â†sss;
9
end
// Defense adjustment: update sss
10
Calculate subgradient ggg with (28);
11
Î· = Î·0/
âˆš
k;
12
Update sss â†Proj(sss âˆ’Î· Â· ggg);
13
T â†T + 1;
14 end
The above transformed problem is a linear programming and
can be solved with interior-point method [27]. However, the
challenge is that there are too many constraints, because we
need to check every possible attacker set A and Tu. Therefore,
we directly solve (26).
A. Project Subgradient Algorithm for Network Defense
The challenge of directly solving (26) is that the inner max-
imization function introduces non-differentiability. Note that
there are also constraints on the variable sss. To address these
challenges, we devise a projected subgradient algorithm [28]
to solve (26). The algorithm is summarized in Algorithm 2. In
the next, we elaborate the details of the designed algorithm.
The algorithm starts from the uncontrolled innate opinions
sss0. The core idea is to update the controlled innate opinions sss
iteratively with the guidance of subgradient. In each iteration
T, We ï¬rst calculate the subgradient of the objective function
in (26). Thanks to our analysis in Section IV, we can ï¬rst
efï¬ciently solve the inner maximization with Algorithm 1,
when sss is given. This corresponds to line 3 and line 4 in
Algorithm 2.
Then, according to [28], we calculate the subgradient (line
10 in Algorithm 2) as
ggg = (BBBAAA)T111 + p Ã—
 BBB(III âˆ’AAA)âˆ†
âˆ†
âˆ†WBBBAAA
T111.
(28)
where âˆ†
âˆ†
âˆ†W is calculated with the optimal attacker set Aâˆ—and
optimal target user sets T âˆ—
u (line 5 in Algorithm 2). Here, we
also record the optimal variable sssâˆ—and optimal objective f âˆ—
during the iteration (line 6-9 in Algorithm 2), since subgradient
algorithm is not a descent method [28].
Finally, with the calculated subgradient ggg in (28), we
update the controlled innate opinions sss as in the line 12 of
Algorithm 2. We adopt the nonsummable diminishing rule [28]
for the choice of step size Î·, which guarantees the convergence
and the optimality of the subgradient method. The discussion
of convergence and optimality will be shown Section V-B. In
addition, since we have two constraints on sss in problem (26),
we need to project sssâˆ’Î· Â·ggg on the feasible set when updating.
Here, we denote the projection function (algorithm) as Proj(Â·).
Note that, in (26), the ï¬rst constratint is one sinlge equality
constraint on the total control budget, while the second one is
a box constraint on the range of controlled innate opinion sss.
Thus, the feasible set of (26) is the intersection of a hyperplane
and a box area. In this work, we implement the projection
algorithm in [29] whose time complexity is O(n). To this end,
the time complexity of one single iteration of Algorithm 2 is
O(N Ã— (log m + m log k + 1)).
Game-Theoretical Interpretation. The above process it-
erates until the maximal interation Tmax is reached. We can
also divide one single iteration in Algorithm 2 as two part.
The ï¬rst part includes line 3-5, which solves the optimal
attacking strategy for the adversarial network perturbation,
given the current controlled innate opinion sss. We deï¬ne this
part as the attacking step. The second part includes line 10-
12, where the defender adjusts the variable sss according to
current optimal attacking strategy Aâˆ—and T âˆ—
u . We deï¬ne this
part as the defense adjustment. Consequently, the iterations in
Algorithm 2 can be regarded as a game played between the
adversary and the defender. The adversary and the defender
update their actions in turn. The updating criterion for the
adversary is Algorithm 1, while the updating policy for the de-
fender is based on the subgradient in (28). Since Algorithm 2 is
guaranteed to converge to the optimal solution, the converged
results can be regarded as the Nash equilibrium in the above
game.
B. Convergence of the Proposed Algorithm
Given the network defense algorithm in Algorithm 2, we
next analyze the convergence of it, and have the following
theorem
Theorem 2. Let f âˆ—be the optimal value of problem (26), and
f âˆ—
alg be the optimal value given by Algorithm 2 with Tmax
iterations in total. We have
f âˆ—
alg âˆ’f âˆ—â‰¤
Âµ2 + Î¾2N Â·

1 + 2mkp2 Â·

1
Î±min âˆ’1
2
Î¾1
(29)
where Î¾1 = PTmax
i=1
1/
âˆš
i, Î¾2 = PTmax
i=1
1/i, and Î±min =
mini Î±i is the smallest stubbornness value of all users.
Proof. see Appendix A
From Theorem. 2, as Tmax â†’âˆ, the right hand side of
(29) â†’0, and thus, f âˆ—
alg â†’f âˆ—. This indicates that when the
number of iteration Tmax is sufï¬ciently large, Algorithm 2
converge the optimal solution of problem (26).
Theorem. 2 shows the convergence speed of Algorithm 2.
That is, in practice, we can use Theorem. 2 to decide the
number of iterations Tmax for a desired optimality f âˆ—
alg âˆ’f âˆ—.
From (29), we can see that when the network size is large (i.e.,
a larger N), Algorithm 2 needs more iterations to converge
to a desired optimality. We can also see that when there are

8
TABLE I
NETWORK STATISTICS
Network
Nodes : |V|
Edges|E|
Avg. Degree
Reddit [30]
553
8969
32.4
Collaboration [31]
679
1687
4.97
Facebook [32]
4039
88234
43.6
more attackers (i.e., a larger m), and when the attackers can
inï¬‚uence more target users (i.e., a larger k), the convergence
of Algorithm 2 is also slower. In addition, the convergence of
(2) is more sensitive to the strength of perturbation coefï¬cient
p due to the square term p2 in the right hand side of (29).
When the perturbation strength is small (i.e., a smaller p), the
inï¬‚uence of the adversarial network perturbation is limited,
and thus, the convergence speed of Algorithm 2 is faster. We
can also see that userâ€™s stubbonrness value plays a critical
role in the convergence speed of Algorithm 2. When users
have a larger stubbornness value (i.e., a larger Î±min), they
are less inï¬‚uenced by others, and the inï¬‚uence of network
perturbation is also smaller. Therefore, Algorithm 2 can have
a faster convergence speed.
VI. EXPERIMENTS
In this section, we run simulation on real social networks to
validate our analysis and the proposed control algorithm. We
use the network of online discussion forum Reddit (Reddit
network for short) in [30], the collaboration network of â€œData
Miningâ€ (Collaboration network for short) in [31], and the
online social network of Facebook (Facebook network for
short) in [32]. The basic information of the above networks
are listed in Table I. For the Collaboration network and the
Facebook network, we randomly generated the usersâ€™ initial
internal opinions sss0 in range (0.6, 1). For the Reddit network,
we use the initial innate opinions that are provided in the
original dataset [30]. For all networks, we randomly generate
usersâ€™ stubbonrness value Î±i in range (0, 1). We also randomly
generate the inï¬‚uence weights of the adjacency matrix W
W
W, and
unify each row of W
W
W so that it is a row stochastic matrix. To
avoid inï¬‚uence of randomness, we repeat each experiment for
10 times, and report the mean results in the following.
A. Validation of the Approximation in Proposition. 1
As the main results of this paper are based on the approxi-
mation in Proposition. 1, we ï¬rst verify the correctness of it.
We ï¬rst calculate the total opinion f with the initial internal
opinions sss0, usersâ€™ stubbornness Î±i, and the adjacency matrix
W
W
W according to (2). Then, we generate the optimal attackers
Aâˆ—and the optimal target users T âˆ—
u as in Section IV-B, and
use them to perturb the networks as described in Section III-A
to obtain the perturbed network strucutre Ëœ
W
W
W. Next, with usersâ€™
initial internal opinions sss0, stubbornness Î±i, and the network
structure Ëœ
W
W
W, we simulate the FJ opinion dynamics model, and
obtain the total opinion with adversarial network perturbtion
Ëœf. We also calculate the approximate total opinion Ëœfest as
in Proposition. 1. We show the increase of the total opinion
Number of Attackers: ğ‘šğ‘š
Theoretical
Simulation
ğ‘ğ‘: Perturbation Coeff.
ğ‘ğ‘â†‘
ğ‘ğ‘= 0.02
ğ‘ğ‘= 0.04
ğ‘ğ‘= 0.06
ğ‘ğ‘= 0.08
ğ‘ğ‘= 0.10
Increase of Total Opinion: Ìƒğ‘“ğ‘“âˆ’ğ‘“ğ‘“or Ìƒğ‘“ğ‘“ğ‘’ğ‘’ğ‘’ğ‘’ğ‘’ğ‘’âˆ’ğ‘“ğ‘“
(a) Reddit, k = 100
Increase of Total Opinion: Ìƒğ‘“ğ‘“âˆ’ğ‘“ğ‘“or Ìƒğ‘“ğ‘“ğ‘’ğ‘’ğ‘’ğ‘’ğ‘’ğ‘’âˆ’ğ‘“ğ‘“
Number of Target Users: ğ‘˜ğ‘˜
Theoretical
Simulation
ğ‘ğ‘: Perturbation Coeff.
ğ‘ğ‘â†‘
ğ‘ğ‘= 0.02
ğ‘ğ‘= 0.04
ğ‘ğ‘= 0.06
ğ‘ğ‘= 0.08
ğ‘ğ‘= 0.10
(b) Reddit, m = 8
Number of Attackers: ğ‘šğ‘š
Theoretical
Simulation
ğ‘ğ‘: Perturbation Coeff.
ğ‘ğ‘â†‘
ğ‘ğ‘= 0.02
ğ‘ğ‘= 0.04
ğ‘ğ‘= 0.06
ğ‘ğ‘= 0.08
ğ‘ğ‘= 0.10
Increase of Total Opinion: Ìƒğ‘“ğ‘“âˆ’ğ‘“ğ‘“or Ìƒğ‘“ğ‘“ğ‘’ğ‘’ğ‘’ğ‘’ğ‘’ğ‘’âˆ’ğ‘“ğ‘“
(c) Collaboration, k = 100
Increase of Total Opinion: Ìƒğ‘“ğ‘“âˆ’ğ‘“ğ‘“or Ìƒğ‘“ğ‘“ğ‘’ğ‘’ğ‘’ğ‘’ğ‘’ğ‘’âˆ’ğ‘“ğ‘“
Number of Target Users: ğ‘˜ğ‘˜
Theoretical
Simulation
ğ‘ğ‘: Perturbation Coeff.
ğ‘ğ‘â†‘
ğ‘ğ‘= 0.02
ğ‘ğ‘= 0.04
ğ‘ğ‘= 0.06
ğ‘ğ‘= 0.08
ğ‘ğ‘= 0.10
(d) Collaboration, m = 8
Number of Attackers: ğ‘šğ‘š
Theoretical
Simulation
ğ‘ğ‘: Perturbation Coeff.
ğ‘ğ‘â†‘
ğ‘ğ‘= 0.02
ğ‘ğ‘= 0.04
ğ‘ğ‘= 0.06
ğ‘ğ‘= 0.08
ğ‘ğ‘= 0.10
Increase of Total Opinion: Ìƒğ‘“ğ‘“âˆ’ğ‘“ğ‘“or Ìƒğ‘“ğ‘“ğ‘’ğ‘’ğ‘’ğ‘’ğ‘’ğ‘’âˆ’ğ‘“ğ‘“
(e) Facebook, k = 100
Increase of Total Opinion: Ìƒğ‘“ğ‘“âˆ’ğ‘“ğ‘“or Ìƒğ‘“ğ‘“ğ‘’ğ‘’ğ‘’ğ‘’ğ‘’ğ‘’âˆ’ğ‘“ğ‘“
Number of Target Users: ğ‘˜ğ‘˜
Theoretical
Simulation
ğ‘ğ‘: Perturbation Coeff.
ğ‘ğ‘â†‘
ğ‘ğ‘= 0.02
ğ‘ğ‘= 0.04
ğ‘ğ‘= 0.06
ğ‘ğ‘= 0.08
ğ‘ğ‘= 0.10
(f) Facebook, m = 8
Fig. 1. Increase of total opinion on different social networks. (Left) Number
of target users is k = 100. (Right) Number of attackers is m = 8.
( Ëœf âˆ’f) and the estimated one, that is, ( Ëœfest âˆ’f) on three
networks in Figure 1.
From Figure 1, we can see that our theoretical approx-
imated results match well with the simulation results on
four networks with different perturbation coefï¬cient p, the
number of attackers m, and the number target users k. We
can see that when there are more attackers and when the
attackers can inï¬‚uence more target users, the increase of total
opinion is larger. In addition, we can also see that when the
perturbation coefï¬cient p is larger, the increase of total opinion
is also larger. This observation validates the inï¬‚uence of the
perturbation coefï¬cient p on the change of total opinion.
B. Validation of Optimal Choice of Attackers and Target Users
In this section, we validate the performance of the selection
criterion of attackers and target users in Section IV.

9
Attackers with Alg.1
Internal Opinion
PageRank
Outdegree
Random
Number of Attackers: ğ‘šğ‘š
Increase of Total Opinion: Ìƒğ‘“ğ‘“âˆ’ğ‘“ğ‘“
(a) Reddit
Number of Attackers: ğ‘šğ‘š
Attackers with Alg.1
Internal Opinion
PageRank
Outdegree
Random
Increase of Total Opinion: Ìƒğ‘“ğ‘“âˆ’ğ‘“ğ‘“
(b) Collaboration
Number of Attackers: ğ‘šğ‘š
Attackers with Alg.1
Internal Opinion
PageRank
Outdegree
Random
Increase of Total Opinion: Ìƒğ‘“ğ‘“âˆ’ğ‘“ğ‘“
(c) Facebook
Fig. 2. Increase of total opinion ( Ëœf âˆ’f) when using different criterion to choose attackers.
Increase of Total Opinion: Ìƒğ‘“ğ‘“âˆ’ğ‘“ğ‘“
Number of Target Users: ğ‘˜ğ‘˜
Target Users with Alg.1
Internal Opinion
Neighborsâ€™ Average Opinion
Stubbornness
PageRank
Outdegree
Random
(a) Reddit
Increase of Total Opinion: Ìƒğ‘“ğ‘“âˆ’ğ‘“ğ‘“
Number of Target Users: ğ‘˜ğ‘˜
Target Users with Alg.1
Internal Opinion
Neighborsâ€™ Average Opinion
Stubbornness
PageRank
Outdegree
Random
(b) Collaboration
Increase of Total Opinion: Ìƒğ‘“ğ‘“âˆ’ğ‘“ğ‘“
Number of Target Users: ğ‘˜ğ‘˜
Target Users with Alg.1
Internal Opinion
Neighborsâ€™ Average Opinion
Stubbornness
PageRank
Outdegree
Random
(c) Facebook
Fig. 3. Increase of total opinion ( Ëœf âˆ’f) when using different criterion to choose target users.
1) Choose of Attackers: We ï¬rst validate the selection of
optimal attackers in Algorithm 1. We choose the following
heuristic criterion as baseline.
â€¢ Internal Opinion which selects users with the largest
internal opinion si as the attacker;
â€¢ PageRank which selects users with the largest PageRank
value as the attacker;
â€¢ Outdegree which selects users with the largest outdegree
and can inï¬‚uence more users as the attacker; and
â€¢ Random which randomly selects users as the attackers.
For each selected attacker u, we use the proposed selection
rule of target user in Section IV-B to decide his/her optimal
target user set T âˆ—
u . The perturbation coefï¬cient is set to p =
0.1, and the number of target user for each attacker is set to
k = 100. We change the number of attacker m, and show the
increase of total opinion Ëœf âˆ’f on three networks in Figure 2.
When we select more attackers (i.e., a larger m), the increase
of total opinion ( Ëœf âˆ’f) becomes larger. This shows that more
attackers can cause a large perturbation in terms of the total
opinion.
We also can see that the proposed selection criterion of
the attackers outperforms other heuristics criterion by a large
extent. We empirically ï¬nd that choosing users with large
internal opinion performs better than other two heuristics
that only use network structure information and randomly
selection. This indicates that users with larger internal opinions
can cause a larger perturbation on the total opinion.
2) Choose of Target Users: Next, we validate the selection
of optimal target users in Algorithm 1. We also adopt the four
heuristic criterions in the above as the baseline methods to
select the target users for each attacker. In addition, according
to our analysis in Section IV, we add the following two
heuristic criterions:
â€¢ Stubbornness which selects users with the smallest stub-
bornness value as target user;
â€¢ Neighborsâ€™ Average Opinion which selects users with
the largest neighborsâ€™ average opinion (W
W
Wzzzâˆ—)i as target
user.
We select m = 5 attackers according to the criterion as in
Section IV, and set the strength of perturbation coefï¬cient
p = 0.1. The increase of total opinion ( Ëœf âˆ’f) with different
number of target user k is shown in Figure 3
From Figure 3, we can see that the selection criterion of
target user in Algorithm 1 performs better than all heuristic
baseline methods. When the attackers can inï¬‚uence more
target users (i.e., a larger k), the their inï¬‚uence on the increase
of total opinion is larger. In addition, we can also see that, the
stubbornness criterion performs better than other heuristics
methods on Reddit network. However, on Citation network
and Facebook network, heuristic criterions related to net-
work structure (PageRank critertion and Outdegree criterion)
performs better than other baselines. This indicates that the
network structure plays a more critical role on the perturbation
of these two networks.
C. Validation of Network Defense
In this secion, we validate the proposed network defense
algorithm in Section V. We set the perturbation coefï¬cient

10
Total Opinion: ğ‘“ğ‘“or Ìƒğ‘“ğ‘“
Total Opinion Without
Perturbation Using Alg. 2
Total Opinion Without
Perturbation Using
â€œMin-Totalâ€
Total Opinion With
Perturbation Using Alg. 2
Total Opinion With
Perturbation Using 
â€œMin-Totalâ€
Control Budget: ğœ‡ğœ‡
(a) Reddit
Control Budget: ğœ‡ğœ‡
Total Opinion: ğ‘“ğ‘“or Ìƒğ‘“ğ‘“
Total Opinion Without
Perturbation Using Alg. 2
Total Opinion Without
Perturbation Using
â€œMin-Totalâ€
Total Opinion With
Perturbation Using Alg. 2
Total Opinion With
Perturbation Using 
â€œMin-Totalâ€
(b) Collaboration
Total Opinion: ğ‘“ğ‘“or Ìƒğ‘“ğ‘“
Total Opinion Without
Perturbation Using Alg. 2
Total Opinion Without
Perturbation Using
â€œMin-Totalâ€
Total Opinion With
Perturbation Using Alg. 2
Total Opinion With
Perturbation Using 
â€œMin-Totalâ€
Control Budget: ğœ‡ğœ‡
(c) Facebook
Fig. 4. The total opinion with and without network perturbation using different control strategy.
p = 0.15. The number of attackers and the number of target
users for each attacker are set to m = 6 and k = 100,
respectively, for three networks. We can observe the similar
results with other parameters settings, and omit them. With
the initial internal opinions sss0, we ï¬rst use the proposed
algorithm in Section V to obtain the controlled internal opinion
sss. The number of iteration Tmax is calculated with (29)
by setting the error tolerence to 0.01. Then, we use (4)
to obtain the total opinion f when there is no adversarial
network perturbation. Next, we perturb the network structure
as described in Section IV, and simulate the FJ opinion
dynamics to obtain the total opinion Ëœf after the adversarial
network perturbation. In Figure 4, We plot the total opinion
with and without the adversarial network perturbation in
Figure 4, respectively, when the control budget Âµ changes.
We also compare the proposed defense algorithm with the
â€œMin-Totalâ€ control strategy as in [14]. That is, We use â€œMin-
Totalâ€ algorithm to derive the controlled internal opinions, and
repeat the above process to obtain the total opinion with and
without the adversarial network perturbation. The results are
also shown in Figure 4.
From Figure 4, when there is no network perturbation, the
total opinion given by â€œMin-Totalâ€ is slightly lower than that
given by our defense algorithm. This is because that â€œMin-
Totalâ€ focus on minimizing the total opinion when there is no
network perturbation, and can obtain the optimal solution [14].
However, when the adversarial network perturbation exists, the
total opinion given by the proposed network defense algorithm
is signiï¬cantly lower than that given by â€œMin-Totalâ€ algorithm.
When using the â€œMin-Totalâ€ control algorithm, we can see
that the total opinion increases dramatically after the network
perturbation. Furthermore, the increase in the total opinion
becomes larger when the control budget Âµ is larger. For the
Facebook network, when the control budget is Âµ = 2000, the
total opinion surprisingly increases 200% compared to the one
without adversarial network perturbation, even if there is only
six attackers and each attackers can only inï¬‚uence 2.5% users
in the whole network. Nevertheless, when using the proposed
network defense algorithm, the increase of total opinion is
negaliable. These observations show that the proposed network
defense algorithm is more robust to the adversarial network
perturbation, and thus, can obtain a lower total opinion with
the perturbation.
VII. CONCLUSION
In this work, we consider the adversarial network perturba-
tion, where the adversary can let some attackers spread their
extreme opinions to target users. We theoreticaly analyze such
adversarial network perturbationâ€™s inï¬‚uence on the networkâ€™s
total opinion. From the adversaryâ€™s perspective, we analyze the
optimal strategy to choose the attackers and the target users, so
that the total opinion is maximized. Then, from the network
defenderâ€™s perspective, we formualte a Stackelberg game to
minimize the total opinion under such adversarial network
perturbation, and device an projected subgradient algorithm
to solve the fromulated game. Simulations on real social
networks validate our analysis of the network perturbation and
the effectiveness of the proposed opinion contorl algorithm.
REFERENCES
[1] A. M. Guess, P. BarberÂ´a, S. Munzert, and J. Yang, â€œThe consequences
of online partisan media,â€ Proc. Natl. Acad. Sci. U.S.A., vol. 118, no. 14,
2021.
[2] T.
T.
E.
BOARD,
â€œEditorial:
Trump
is
responsible
for
the
violent
storming
of
u.s.
capitol,â€
[Online],
https://www.latimes.com/opinion/
story/2021-01-06/trump-supporters-
storming-capitol-pence-biden.
[3] T. M. Liggett, Stochastic interacting systems: contact, voter and exclu-
sion processes.
Springer Science & Business Media, 2013, vol. 324.
[4] P. L. Krapivsky and S. Redner, â€œDynamics of majority rule in two-state
interacting spin systems,â€ Phys. Rev. Lett., vol. 90, no. 23, p. 238701,
2003.
[5] M. Granovetter, â€œThreshold models of collective behavior,â€ Am. J.
Sociol., vol. 83, no. 6, pp. 1420â€“1443, 1978.
[6] M. H. DeGroot, â€œReaching a consensus,â€ J. Am. Stat. Assoc., vol. 69,
no. 345, pp. 118â€“121, 1974.
[7] R. Hegselmann and U. Krause, â€œOpinion dynamics and bounded conï¬-
dence models, analysis, and simulation,â€ J. Artif. Soc. Soc. Simul., vol. 5,
no. 3, 2002.
[8] N. E. Friedkin and E. C. Johnsen, â€œSocial inï¬‚uence and opinions,â€ J.
Math. Sociol., vol. 15, no. 3-4, pp. 193â€“206, 1990.
[9] D. Bindel, J. Kleinberg, and S. Oren, â€œHow bad is forming your own
opinion?â€ Games Econ. Behav., vol. 92, pp. 248â€“265, 2015.
[10] N. E. Friedkin, â€œA formal theory of reï¬‚ected appraisals in the evolution
of power,â€ Adm. Sci. Q., vol. 56, no. 4, pp. 501â€“529, 2011.
[11] D. Kempe, J. Kleinberg, and Â´E. Tardos, â€œMaximizing the spread of
inï¬‚uence through a social network,â€ in Proc. 9th ACM Int. Conf. Knowl.
Discovery and Data Min. (SIGKDD), 2003, pp. 137â€“146.
[12] A. Gionis, E. Terzi, and P. Tsaparas, â€œOpinion maximization in social
networks,â€ in Proc. 13th SIAM Int. Conf. Data Min. (SDM).
SIAM,
2013, pp. 387â€“395.
[13] R. Abebe, J. Kleinberg, D. Parkes, and C. E. Tsourakakis, â€œOpinion
dynamics with varying susceptibility to persuasion,â€ in Proc. 24th ACM
Int. Conf. Knowl. Discovery and Data Min. (SIGKDD), 2018, pp. 1089â€“
1098.

11
[14] P. Xu, W. Hu, J. Wu, and W. Liu, â€œOpinion maximization in social
trust networks,â€ in Proceedings of the 29th Int. Joint Conf. Artiï¬. Intell.
(IJCAI), 2020, pp. 1251â€“1257.
[15] A. Matakos, E. Terzi, and P. Tsaparas, â€œMeasuring and moderating
opinion polarization in social networks,â€ Data Min. Knowl. Discov.,
vol. 31, no. 5, pp. 1480â€“1505, 2017.
[16] X. Chen, J. Lijfï¬jt, and T. De Bie, â€œQuantifying and minimizing risk
of conï¬‚ict in social networks,â€ in Proc. 24th ACM Int. Conf. Knowl.
Discovery and Data Min. (SIGKDD), 2018, pp. 1197â€“1205.
[17] C. Musco, C. Musco, and C. E. Tsourakakis, â€œMinimizing polarization
and disagreement in social networks,â€ in Proc. 27th Conf. World Wide
Web (WWW), 2018, pp. 369â€“378.
[18] M. F. Chen and M. Z. Racz, â€œAn adversarial model of network dis-
ruption: Maximizing disagreement and polarization in social networks,â€
IEEE Transactions on Network Science and Engineering, 2021.
[19] J. Gaitonde, J. Kleinberg, and E. Tardos, â€œAdversarial perturbations of
opinion dynamics in networks,â€ in Proc. of 21st ACM Conf. Econ. and
Comput., 2020, pp. 471â€“472.
[20] D. Greene, D. Doyle, and P. Cunningham, â€œTracking the evolution of
communities in dynamic social networks,â€ in Proc. 2010 Int. Conf. Adv.
Soc. Netw. Anal. Mining.
IEEE, 2010, pp. 176â€“183.
[21] F. Pereira, S. De Amo, and J. Gama, â€œEvolving centralities in temporal
graphs: a twitter network analysis,â€ in 2016 17th IEEE international
conference on mobile data management (MDM), vol. 2.
IEEE, 2016,
pp. 43â€“48.
[22] A.-L. BarabÂ´asi and R. Albert, â€œEmergence of scaling in random net-
works,â€ Science, vol. 286, no. 5439, pp. 509â€“512, 1999.
[23] U. Chitra and C. Musco, â€œAnalyzing the impact of ï¬lter bubbles on
social network polarization,â€ in Proc. 13th ACM Int. Conf. Web Search
and Data Min., 2020, pp. 115â€“123.
[24] E. Pariser, The ï¬lter bubble: What the Internet is hiding from you.
Penguin UK, 2011.
[25] E. C. and S. B., â€œSmall perturbation analysis of network topologies,â€ in
Proc. 43th IEEE Int. Conf. Acoust., Speech, Signal Process. (ICASSP).
IEEE, 2018, pp. 4194â€“4198.
[26] T. H. H. Chan, Z. Liang, and M. Sozio, â€œRevisiting opinion dynamics
with varying susceptibility to persuasion via non-convex local search,â€
in Proc. 28th Conf. World Wide Web (WWW), 2019, pp. 173â€“183.
[27] S. Boyd and L. Vandenberghe, Convex optimization.
Cambridge
university press, 2004.
[28] S. Boyd, L. Xiao, and A. Mutapcic, â€œSubgradient methods,â€ lecture
notes of EE392o, Stanford University, Autumn Quarter, vol. 2004, pp.
2004â€“2005, 2003.
[29] N. Maculan, C. P. Santiago, E. M. Macambira, and M. H. C. Jardim,
â€œAn o (n) algorithm for projecting a vector on the intersection of a
hyperplane and a box in rn,â€ J. Optim. Theory Appl., vol. 117, no. 3,
pp. 553â€“574, 2003.
[30] A. De, S. Bhattacharya, P. Bhattacharya, N. Ganguly, and S. Chakrabarti,
â€œLearning a linear inï¬‚uence model from transient opinion dynamics,â€
in Proc. 23rd ACM Int. Conf. Inf. and Knowl. Manage. (CIKM), 2014,
pp. 401â€“410.
[31] J. Tang, J. Sun, C. Wang, and Z. Yang, â€œSocial inï¬‚uence analysis
in large-scale networks,â€ in Proceedings of the 15th ACM SIGKDD
international conference on Knowledge discovery and data mining,
2009, pp. 807â€“816.
[32] J. Leskovec and J. Mcauley, â€œLearning to discover social circles in ego
networks,â€ Advances in neural information processing systems, vol. 25,
2012.
APPENDIX A
PROOF OF THEOREM. 2
To prove Theorem. 2, we ï¬rst present the following lemma.
Lemma 1 (Convergence of Project Subgradient Method). Let
sssâˆ—be the optimal solution to the problem in (26), and sss0 is
the initial point of Algorithm 2. If âˆ¥sss0 âˆ’sssâˆ¥2 â‰¤R and the
subgradient in (28) satisï¬es that âˆ¥gggâˆ¥2 â‰¤G, then we have
f âˆ—
alg âˆ’f âˆ—â‰¤R2 + Î·2
0G2Î¾2
2Î·0Î¾1
,
(30)
where f âˆ—
alg is the optimal value given by Algorithm 2 with
Tmax iterations, Î·0 is the initial step size of Algorithm 2,
Î¾1 = PTmax
i=1
1/
âˆš
i, and Î¾2 = PTmax
i=1
1/i.
Proof. See Section 3.2 and Section 6 in [28].
Now, with Lemma. 1, to prove Theorem. 2, we need to ï¬nd
the upper bound R2 and G2. We ï¬rst calculate R2, which is
the upper bound of the Euclidean distance between the initial
innate opinions sss0 and the optimal controlled innate opinion
sss. Consequently, we have the following lemma
Lemma 2.
âˆ¥sss0 âˆ’sssâˆ—âˆ¥2
2 â‰¤Âµ2,
(31)
where Âµ is the control budget.
Proof. Let ddd = sss0 âˆ’sssâˆ—, and di = s0(i) âˆ’sâˆ—
i . Since sssâˆ—is the
optimal solution to problem (26), it is also a feasible solution.
Thus, 000 âª¯sssâˆ—âª¯sss0, and 000 âª¯ddd âª¯sss0, that is, 0 â‰¤di â‰¤s0(i). In
addition, with the control budget constraint 111Tsss0 âˆ’111Tsssâˆ—= Âµ,
we also have 111Tddd = Âµ, that is, P
i di = Âµ. Note that
Âµ2 = (d1 + Â· Â· Â· + dN)2 =
X
i
d2
i + 2 Ã—
X
iÌ¸=j
didj
= âˆ¥dddâˆ¥2
2 + 2 Ã—
X
iÌ¸=j
didj
â‡’âˆ¥dddâˆ¥2
2 = âˆ¥sss0 âˆ’sssâˆ—âˆ¥2
2 = Âµ2 âˆ’2 Ã—
X
iÌ¸=j
didj.
With di â‰¥0 for each i, we have 2 Ã— P
iÌ¸=j didj â‰¥0.
Consequently, we haveâˆ¥dddâˆ¥2
2 â‰¤Âµ2. This ends the proof.
Next, we analyze G, which is the upper bound of subgra-
dient gggâ€™s length, and have the following lemma
Lemma 3.
âˆ¥gggâˆ¥2
2 â‰¤Nâˆ¥BBBâˆ¥2
2
 1 + p2mk Â· âˆ¥BBBâˆ¥2
2(1 + âˆ¥W
W
Wâˆ¥2
2)

.
(32)
where W
W
W is the adjacency matrix, and BBB = [III âˆ’(III âˆ’AAA)W
W
W]âˆ’1.
Proof. With the deï¬nition of subgradient in (28), we ï¬rst have
âˆ¥gggâˆ¥2
2 = âˆ¥(BBBAAA)T111 + p Ã—
 BBB(III âˆ’AAA)âˆ†
âˆ†
âˆ†WBBBAAA
T111âˆ¥2
2
â‰¤âˆ¥(BBBAAA)T111âˆ¥2
2 + p2 Ã— âˆ¥
 BBB(III âˆ’AAA)âˆ†
âˆ†
âˆ†WBBBAAA
T111âˆ¥2
2.
We ï¬rst analyze the ï¬rst term âˆ¥(BBBAAA)T111âˆ¥2
2, and we can have
âˆ¥(BBBAAA)T111âˆ¥2
2 â‰¤âˆ¥(BBBAAA)T âˆ¥2
2 Â· âˆ¥111âˆ¥2
2 = N Â· âˆ¥BBBAAAâˆ¥2
2
â‰¤N Â· âˆ¥BBBâˆ¥2
2âˆ¥AAAâˆ¥2
2 = Î±2
maxNâˆ¥BBBâˆ¥2
2 â‰¤Nâˆ¥BBBâˆ¥2
2,
where Î±max is the largest stubbornness of the whole popula-
tion and Î±max â‰¤1.
Next, we analyze âˆ¥
 BBB(IIIâˆ’AAA)âˆ†
âˆ†
âˆ†WBBBAAA
T111âˆ¥2
2. We ï¬rst rewrite
this term as
âˆ¥
 BBB(III âˆ’AAA)âˆ†
âˆ†
âˆ†WBBBAAA
T111âˆ¥2
2 = âˆ¥AAABBBTâˆ†
âˆ†
âˆ†T
W (III âˆ’AAA)BBBT111âˆ¥2
2
â‰¤âˆ¥AAAâˆ¥2
2 Â· âˆ¥BBBT âˆ¥4
2 Â· âˆ¥âˆ†
âˆ†
âˆ†T
W âˆ¥2
2 Â· âˆ¥III âˆ’AAAâˆ¥2
2 Â· âˆ¥111âˆ¥2
2
= NÎ±2
max Â· (1 âˆ’Î±min)2âˆ¥BBBâˆ¥4
2 Â· âˆ¥âˆ†
âˆ†
âˆ†W âˆ¥2
2
â‰¤Nâˆ¥BBBâˆ¥4
2 Â· âˆ¥âˆ†
âˆ†
âˆ†W âˆ¥2
2
(33)
where Î±min is the smallest stubbornness of the whole popu-
lation, and 1 âˆ’Î±min â‰¤1.

12
Next, we anlayze the term âˆ¥âˆ†
âˆ†
âˆ†W âˆ¥2
2. With the deï¬nition of
âˆ†
âˆ†
âˆ†W in (9), we have
âˆ¥âˆ†
âˆ†
âˆ†W âˆ¥2
2 =

X
vâˆˆT
eeev
X
uâˆˆAv
eeeT
u âˆ’
X
vâˆˆT
|Av|eeeveeeT
v W
W
W

2
2
=

X
vâˆˆT
X
uâˆˆAv
eeeveeeT
u âˆ’
X
vâˆˆT
X
uâˆˆAv
eeeveeeT
v W
W
W

2
2
=

X
vâˆˆT
X
uâˆˆAv
 eeeveeeT
u âˆ’eeeveeeT
v W
W
W


2
2
=

X
uâˆˆA
X
vâˆˆTu
 eeeveeeT
u âˆ’eeeveeeT
v W
W
W


2
2
â‰¤
X
uâˆˆA
X
vâˆˆTu
eeeveeeT
u âˆ’eeeveeeT
v W
W
W
2
2
â‰¤
X
uâˆˆA
X
vâˆˆTu
eeeveeeT
u
2
2 +
eeeveeeT
v
2
2 Â· âˆ¥W
W
Wâˆ¥2
2
For the term eeeveeeT
u , its Frobenius norm satisï¬es âˆ¥eeeveeeT
u âˆ¥2
F =
tr(eeeveeeT
ueeeueeeT
v ) = 1. According to the relation that âˆ¥CCCâˆ¥2 â‰¤
âˆ¥CCCâˆ¥F for any square matrix CCC, we can have âˆ¥eeeveeeT
u âˆ¥2 â‰¤
âˆ¥eeeveeeT
u âˆ¥F = 1. Thus, âˆ¥eeeveeeT
u âˆ¥2
2 â‰¤1. Similarly, we can also
have âˆ¥eeeveeeT
v âˆ¥2
2 â‰¤1. Consequently, we have
âˆ¥âˆ†
âˆ†
âˆ†W âˆ¥2
2 â‰¤
X
uâˆˆA
X
vâˆˆTu
eeeveeeT
u
2
2 +
eeeveeeT
v
2
2 Â· âˆ¥W
W
Wâˆ¥2
2
â‰¤
X
uâˆˆA
X
vâˆˆTu
(1 + âˆ¥W
W
Wâˆ¥2
2) â‰¤mk Â· (1 + âˆ¥W
W
Wâˆ¥2
2).
(34)
With âˆ¥âˆ†
âˆ†
âˆ†W âˆ¥2
2 in (34) and the derivation in (33), we have
âˆ¥
 BBB(III âˆ’AAA)âˆ†
âˆ†
âˆ†WBBBAAA
T111âˆ¥2
2 â‰¤Nâˆ¥BBBâˆ¥4
2âˆ¥âˆ†
âˆ†
âˆ†W âˆ¥2
2
â‰¤Nmkâˆ¥BBBâˆ¥4
2âˆ¥(1 + âˆ¥W
W
Wâˆ¥2
2),
Consequently, we have the upper bound of subgradient ggg, that
is,
âˆ¥gggâˆ¥2
2 â‰¤âˆ¥(BBBAAA)T111âˆ¥2
2 + p2 Ã— âˆ¥
 BBB(III âˆ’AAA)âˆ†
âˆ†
âˆ†WBBBAAA
T111âˆ¥2
2
â‰¤Nâˆ¥BBBâˆ¥2
2
 1 + p2mk Â· âˆ¥BBBâˆ¥2
2(1 + âˆ¥W
W
Wâˆ¥2
2)

This ends the proof.
With the above lemmas, we can replace R2 and G2 in (30)
with Âµ2 and

1 + 2mkp2 Â·

1
Î±min âˆ’1
2
, respectively. This
leads to the convergence in (29).

