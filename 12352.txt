See discussions, stats, and author profiles for this publication at: https://www.researchgate.net/publication/221909570
Swarm Robotics: An Extensive Research Review
Chapter · November 2010
DOI: 10.5772/10361 · Source: InTech
CITATIONS
29
READS
1,885
2 authors:
Mohan Yogeswaran
Universiti Tunku Abdul Rahman
16 PUBLICATIONS   453 CITATIONS   
SEE PROFILE
Ponnambalam S.G.
Vellore Institute of Technology (VIT)
242 PUBLICATIONS   4,737 CITATIONS   
SEE PROFILE
All content following this page was uploaded by Ponnambalam S.G. on 21 May 2014.
The user has requested enhancement of the downloaded file.

14 
Swarm Robotics:  
An Extensive Research Review 
Yogeswaran M. and Ponnambalam S. G. 
School of Engineering, Monash University, Sunway Campus. 
46150 Petaling Jaya, Selangor,  
Malaysia 
1. Introduction 
Swarm robotics is a new approach to the coordination of large numbers of relatively simple 
physically embodied robots, that are autonomous, not controlled centrally, capable of local 
communication and operates based on some sense of biological inspiration (Sharkey & 
Sharkey, 2006a). Swarm robotic systems have become a major research area since 1980’s, as 
new solution approaches are being developed and validated, it is often possible to realize 
the advantages of swarm robotic systems. Table 1 shows the key advantages of swarm  
  
BENEFITS  
DESCRIPTIONS  
Parallelism  
In task-decomposable application domains, robots can accom-
plish a given task more quickly than a single robot by dividing 
the task into sub tasks and executing them concurrently.  
Robustness  
No single point of failure for the system. This is an important 
characteristic since many of the applications rely on continued 
progress even if some components in the system fail.  
Scalability  
As the swarm of robots becomes larger, its relative performance 
in comparison to a centralized system becomes better.  
Heterogeneousness  
Since a group of robots may be heterogeneous, it can utilize 
“specialists” -robots whose physical properties enable them to 
perform efficiently certain well defined tasks.  
Flexibility  
Easily adaptable for different applications as different applica-
tions will have different requirements, a general architecture 
will need the ability to be easily reconfigured for the different 
problems it proposes to solve.  
Complex Tasks  
Tasks may be inherently too complex (or impossible) for a 
single robot to accomplish or performance benefits can be 
gained from using a swarm of robots.  
Cheap Alternative  
Building and using several simple robots can be easier, cheaper, 
more flexible and more fault tolerant than having a single pow-
erful robot for each separate task.  
Table 1. Characteristics of swarm robotic systems. 

 
Advanced Knowledge Application in Practice 
 
260 
robotic systems (Cao et al., 1997; Altshuler et al., 2006; De le Torre & Stentz, 2001; Bruemmer 
et al., 2002): The early work on classification of research areas of swarm robotic systems was 
done by Dudek et al. (1993). The paper classified the areas into five areas which are swarm 
size, communication range, communication topology, communication bandwidth, swarm 
reconfigurability and swarm unit processing ability. Cao et al. (1997) presented the survey of 
cooperative robotics in a hierarchical way. They split the publications into five main axes: 
group architecture, resource conflicts, origins of cooperation, learning and geometric 
problems. Group architecture is further divided into centralization/decentralization, 
differentiation (denotes the homogeneous or heterogeneous robot groups), communication 
structure and modeling of other agents dimensions. Modeling of other agents dimension 
contains studies which models the intentions, beliefs, actions, capabilities, and states of 
other agents to obtain more effective cooperation between robots (Bayindir & Sahin, 2007). 
Iocchi et al. (2001) presented an analysis of multi robot systems by looking at their 
cooperative aspects. They have also proposed taxonomy of multi robot systems and a 
characterization of reactive and social deliberative behaviors of the multi robot system as a 
whole. Rather than summarizing the research area of swarm robots into a taxonomy of 
cooperating systems, Parker (2003) has organized the areas by the principal topics that have 
generated significant levels of research. The categorization done in this paper has the main 
structure as in the work of Parker (2003). The research axes are biological inspiration, 
communication, control approach, mapping and localization, object transportation and 
manipulation, reconfigurable robotics, motion coordination, learning and task allocation. 
Each of the research axes are further separated into sub-categories for in detailed discussion. 
2. Research axes 
2.1 Biological inspiration 
Swarm robotics and the related concept of swarm intelligence, is inspired by an 
understanding of the decentralized mechanisms that underlie the organization of natural 
swarms such as ants, bees, birds, fish, wolfs and even humans. Jung & Zelinsky (2000) 
described the implementation of a heterogeneous cooperative multi-robot system that was 
designed with a goal of engineering a grounded symbolic representation which was 
inspired by the communication methods employed by biological systems. 
Social insects provide one of the best-known examples of biological self organized behavior. 
By means of local and limited communication, they are able to accomplish impressive 
behavioral feats: maintaining the health of the colony, caring for their young, responding to 
invasion and so on (Sharkey, 2006b). Labella et al. (2006) has analyzed the behavior of a 
group of robots involved in an object retrieval task where the robots’ control system is 
inspired by a model of ants’ foraging behaviors. The sub-tasks assigned to the robots are 
extracted from simple behavior of ant swarms such as search, retrieve, deposit, return and 
rest. Ideas inspired from such collective behaviors have led to the use of pheromones (Panait 
& Luke, 2004), a chemical substance deposited by ants and similar social insects in order to 
mark the environment with information to assist other ants at a later time. 
Similarly Payton et al. (2003) and Cazangi et al. (2005) used pheromones to achieve inter-
robot communication mechanism in their research. Pheromones in swarm robotics can be 
viewed as a mechanism for inter-robot communication that can help reduce the complexity 
of individual agents. Pheromone communication adopted from necrophoric bee behavior 
was introduced in (Purnamadjaja & Russell, 2004) to develop interaction between the 

Swarm Robotics: An Extensive Research Review   
 
261 
members of a robot swarm. The term “Necrophoric” signifies the removal of bee corpses 
from inside of the hive. Nevertheless, the introduction of pheromones has driven the 
research exploitation in communication and localization in the studies of swarm robotics. 
A higher level of studies in this area leads to exploit the cooperation and interaction abilities 
in mammals. Unlike insects, mammals behave differently toward individual social partners, 
rather than interacting with all entities in the same way. Tomlinson & Blumberg (2002) 
created an interactive virtual multi-agent system based on the behavior of packs of gray 
wolves. Their virtual wolves are able to form social relationships with each other via the 
mechanism of social relationship formation involves emotion, perception, and learning. 
Fong et al. (2003) have modeled their robots to adopt human’s social interactions. As 
research progresses in this area, more sophisticated teamwork architectures are being 
explored into to cater the increase in problem complexity. Such sophisticated teamwork 
architectures was demonstrated by Kitano et al. (1998). Robocup is an attempt to foster 
intelligent robotics by including design principles of autonomous agents, multi agent 
collaboration, strategy acquisition, real-time reasoning, robotics and sensor fusion. 
2.2 Communication 
The role of communication among mobile robots remains one of the most important 
research issues in swarm robotics system design. When a task requires cooperation, there is 
a need for some form of communication between the participating agents. Cooperation 
work requires communication whenever one agent’s actions depend critically on knowledge 
that is accessible only from other agents. There has been much debate about the level of 
communication that should be allowed between such systems. Most of the open literatures 
have made distinctions between implicit/indirect and explicit/direct communications. 
Implicit communication (also referred to as stigmergy (Trianni et al., 2004)) is a method of 
communicating through the environment. 
Mir & Amavasai (2007) have modeled an autonomous swarm which is able to make 
decentralized decisions and demonstrate implicit communication. The paper also stressed 
that the swarm exhibits behavior based cooperation in the absence of explicit 
communication. White & Pagurek (1998) presented a new architectural description for an 
agent that is based on ants’ stigmergy behavior for inter-swarm communication is 
introduced. Ramos et al. (2005) discusses several concepts related to self-organization, 
stigmergy and social foraging in animals. The paper also suggested and stressed the role 
played not only by the environmental media as a driving force for societal learning, as well 
as by positive and negative feedbacks produced by the many interactions among agents. 
Pheromone signal plays an important role in communication domain as its capability of 
establishing communication between a sender and a receiver when there is no direct clear 
path between them. Pheromone communication is a type of implicit communication. There 
a many papers that have explored the use of pheromone signal to convey messages to other 
robots in a swarm such as the work by Purnamadjaja & Russell (2004) and Purnamadjaja et 
al. (2007). An improved form of pheromone communication method called “virtual 
pheromone” was used by (Payton et al., 2003; Meng et al., 2007) to employ simple 
communication and coordination to achieve large scale results in the areas of surveillance, 
reconnaissance, hazard detection, and path finding. More implementations of implicit 
communication in robots swarm has been reported by D’Angelo & Pagello (2005) and 
Bruemmer et al. (2004). 

 
Advanced Knowledge Application in Practice 
 
262 
Explicit communication is the type of communication in which the robots directly pass 
messages to each other and/or to the human operator. McPartland et al. (2005) has made 
comparison between implicit and explicit communications theory by applying it to two 
different swarms of robot which is assigned to explore a given environment in the shortest 
period of time. Rybski et al. (2007) introduced and explored simple communication 
strategies which implemented implicit and explicit communication. 
Trianni et al. (2004) studied the use of direct communication in order to achieve a reaction to 
the detection of a hole. Hayes et al. (2003) described a distributed algorithm for solving the 
full odor localization task, and shown that group performance can exceed that of a single 
robot using explicit communication. Christodoulopoulos et al. (2007) implemented an ad 
hoc wireless network communication to exchange information between all its individual 
agents within the swarm. Ad-hoc mode is a method for wireless devices to directly 
communicate with each other. Operating in ad-hoc mode allows all wireless devices within 
range of each other to discover and communicate in peer-to-peer fashion without involving 
central access points. 
Communication between robots can multiply their capabilities and increase the efficiency. 
This has been shown in simulation and on real robots. The amount of communication has 
also been studied. Sometimes even little communication will enhance the performance of 
the system (Adolfsson, 2001). Even though there is no clear conclusion on what type of 
communication is better for robot swarms, but most of the current research is aiming 
towards implicit communication for its robust characteristics. 
2.3 Control approach 
In general, swarm robot coordination strategies assume either a centralized approach, where 
a single robot plans for the group, or a distributed approach, where each robot is responsible 
for its own planning (De le Torre & Stentz, 2001). Iocchi et al. (2001) has clearly 
distinguished between centralized and distributed control as: 
• 
Centralized: the organization of a system having a robotic agent (a leader) that is in 
charge of organizing the work of the other robots; the leader is involved in the 
decisional process for the whole team, while the other members act according to the 
directions of the leader. 
• 
Distributed: the organization of a system composed by robotic agents which are 
completely autonomous in the decisional process with respect to each other; in this class 
of systems a leader does not exist. 
Table 2 shows the advantages and disadvantages of centralized and distributed control 
approach. Parker (1993) experimented on the advantages and the disadvantages of the 
control approaches and reported that deciding the proper balance between centralized and 
distributed control is the key to achieve the desired emergent group behavior in a swarm of 
robots. Steele Jr & Thomas (2007) introduced “Directed Stigmergy-Based Control” which 
incorporates the advantages of distributed control and centralized control. The aim of the 
paper is to stress the need of a supervisor in useful tasks that require searching large areas 
such as planetary science exploration, urban search and rescue, or land mine remediation. 
However, both distributed and centralized control approaches have contributed 
individually to the study of swarm robotics and have generated interesting experimental 
results. Extensive studies in distributed control approaches (Spaan et al., 2006; Shen et al., 
2002) lead to implementation of control laws or force laws (Gazi & Passino, 2002; 

Swarm Robotics: An Extensive Research Review   
 
263 
Dimarogonas & Kyriakopoulos, 2007) incorporating both attraction and repulsion features. 
On the other hand, centralized control approach (Li et al., 2007) has contributed in 
supporting several capabilities of swarm robotic systems such as hierarchical planning, 
concurrent planning, execution and perception, reactivity to environmental changes, error 
recovery, and coordination of multiple tasks. 
 
APPROACH 
CRITERIA 
DESCRIPTION 
Advantages  
Optimal plans can be produced. The leader can take 
into account all the relevant information conveyed by 
the members of the team and generate an optimal plan 
for the team.  
Strongly rely on communication. Thus, when a com-
munication failure takes place, it results in a failure of 
the entire system.  
A strongly centralized system can fail in accomplish-
ing its task when its leader goes out of order.  
Centralized  
Disadvantages  
System response to changes in the environment is 
sluggish since all relevant information must be con-
veyed to the leader before any action can be taken.  
Do not have a single point of failure. The loss of a 
single agent will not cripple the system, as can be the 
case in single-agent or centrally controlled systems.  
Can achieve complex results with relatively simple 
system design. The designer need only create simple, 
low level behaviors, instead of a single, computation-
ally intense control system to govern all possible situ-
ations.  
Advantages  
Are inherently parallel, which allows for extremely 
scalable systems and faster task completion.  
Often result in highly sub-optimal solutions because 
all plans are based solely on local information.  
Distributed  
Disadvantages  
Independent task execution by the system compo-
nents causes problems in the area of coordination be-
tween the system agents.  
Table 2. Advantages and disadvantages of control approaches (Iocchi et al., 2001; Steele Jr & 
Thomas, 2007). 
2.4 Mapping and localization 
Mapping and localization is an exceedingly well-studied problem in swarm robotics which 
gathered a lot of research papers the last two decades. Mapping is a representation of the 
physical environments through the mobile robots sensory data into spatial models (Thrun, 
2002). Localization is defined as finding the absolute or rational location of robot in the 
spatial models generated. Since the development of research in mapping and localization 
progressed, the problems that addresses mapping and localization has been referred to as 
simultaneous localization and mapping (SLAM) or concurrent mapping and localization 
(CML). 

 
Advanced Knowledge Application in Practice 
 
264 
SLAM or CML is the problem of acquiring a map of an unknown environment with a 
moving robot, while simultaneously localizing the robot relative to this map (Thrun, 2002). 
The SLAM problem addresses situations where the robot lacks a global positioning sensor. 
Instead, it has to rely on a sensor (e.g., laser scanner, sonar and vision) of incremental 
egomotion for robot position estimation (e.g., odometry). To solve the problem of odometry 
in SLAM, many approaches have been made thru the application of various filters 
introduced in (Thrun, 2001; Se et al., 2002; Thrun et al., 2004; Howard, 2006). 
There are two distinct mapping approaches available namely topological mapping and 
geometric mapping. A topological map is an abstract encoding of the structural 
characteristics of an environment. Often, topological maps (Kuipers & Byun, 1991; Fabrizi & 
Saffiotti, 2000; Choset & Nagatani, 2001) represent the environment as a set of distinctive 
places using points (e.g., rooms), connected by sequences of robot behaviors using lines 
(e.g., wall-following). A geometric map, on the other hand, is a representation of the precise 
geometric characteristics of the environment, much like a floor plan (Wolter et al., 2004). 
This area also covers the studies in the type of terrains (Seraji, 1999; Triebel et al., 2006) and 
dynamic environments (Wolf & Sukhatme, 2004). 
2.5 Object transportation and manipulation 
 
 
 
 
                         (a) Force closure.                                                      (b) Form closure. 
 
 
                      (c) Conditional closure.                                             (d) Object closure. 
Fig. 1. Closure techniques for object manipulation. 

Swarm Robotics: An Extensive Research Review   
 
265 
Researches in this area of swarm robotics have drafted three types object manipulation 
method which are namely grasping, pushing and caging. In grasping, all robots are 
arranged so that the total robots system is grasping the object (Wang et al., 2007; 
Agassounon, 2004). Grasping incorporates form closure (refer to Fig.1(b)) and force closure 
(refer to Fig.1(a)) techniques. Force closure is a condition that implies that the grasp can 
resist any external force applied to the object. Form closure can be viewed as the condition 
guaranteeing force closure, without requiring the contacts to be frictional. In general, robots 
are the agents that induce contacts with the object, and are the only source of grasp forces. 
Pushing (Miyata et al., 1997; Yamada & Saito, 2001) on the other hand doesn’t guarantee 
form closure or force closure, but requires external forces to be applied to the object such as 
gravity and friction. For this type of object manipulation, conditional closure (refer to 
Fig.1(c)) is introduced. Pushing behaviors gives an advantage where any objects that can’t 
be grasped to be moved and to perform pushing to multiple objects as well. The main 
difficulty on object manipulation via pushing is that the robots cannot pull the object 
directly when it needs to slow down or move back the object. 
Caging (Pereira et al., 2003; Wang & Kumar, 2002; Wang et al., 2004) introduces a bounded 
movable area for the object. Then, the contact between object and robotics mechanism need 
not be maintained by robot’s control. This makes motion planning and control of each 
robotic mechanism become simple and robust. This condition is called object closure (refer 
to Fig.1(d)). Caging has been widely used in manipulation of swarm robotics because this 
makes motion planning and control of each robotic mechanism simple and robust. 
A leader-follower type multiple robot system was addressed by Wang et al. (2007) where 
the proposed system consists of a pushing leader, a robot without grasping mechanisms, 
and multiple follower robots. During the object transportation, a desired trajectory is given 
to the leader robot only, and follower robots estimate the trajectory of the leader based on 
force/moment from the object. In Behavior-based Multiple Robot System with Host for 
Object Manipulation (BeRoSH) (Wang et al., 1996), the unit which processes all common 
tasks is named the host. The host is incorporated into one of the robots, by giving the robot 
the ability to organize other robots and generate motivations/goals for the other robots. 
More papers reporting leader-follower implementations can be found in (GroB et al., 2006; 
Song & Kumar, 2002). 
2.6 Reconfigurable robotics 
Modular self-reconfiguring robotic systems or self-reconfigurable modular robots are 
autonomous kinematic machines with variable morphology. Beyond conventional actuation, 
sensing and control typically found in fixed-morphology robots, self-reconfiguring robots 
are also able to deliberately change their own shape by rearranging the connectivity of their 
parts, in order to adapt to new circumstances, perform new tasks, or recover from damage. 
Modular self-reconfigurable robotic systems can be generally classified into several 
architectural groups by the geometric arrangement of their units (Mark et al., 2007; 
Østergaard et al., 2006; Tuci et al., 2006). 
• 
Lattice Architectures (refer to Fig.2(a)): have units that are arranged and connected in 
some regular, three-dimensional pattern, such as a simple cubic or hexagonal grid. 
Control and motion can be executed in parallel. Lattice architectures usually offer 
simpler reconfiguration, as modules move to a discrete set of neighboring locations in 
which motions can be made open-loop. The computational representation can also be 
more easily scaled to more complex systems. 

 
Advanced Knowledge Application in Practice 
 
266 
 
 
 
(a) Lattice type. (Brandt et 
al., 2007) 
(b) Chain type. (Yim et al., 
2007) 
(c) Mobile type. (Mondada 
et al., 2003) 
Fig. 2. Architectural group. 
• 
Chain Architectures (refer to Fig.2(b)): have units that are connected together in a string 
or tree topology. This chain or tree can fold up to become space filling, but the 
underlying architecture is serial. Through articulation, chain architectures can 
potentially reach any point or orientation in space, and are therefore more versatile but 
computationally more difficult to represent and analyze and more difficult to control. 
• 
Mobile Architectures (refer to Fig.2(c)): have units that use the environment to 
maneuver around and can either hook up to form complex chains or lattices or form a 
number of smaller robots that execute coordinated movements and together form a 
larger “virtual” network. 
The types of modular self-reconfigurable robotic systems reported in the gathered 
literatures have been classified into their architectural groups and is presented in Table 3. 
Self-reconfigurable robots hold potential to be able to move robotics into new areas of 
application. In addition to traditional mass production environments, self-reconfigurable 
robots may become useful in real-world environments. These environments are 
characterized by being unstructured, complex, dynamic, and unknown. Self-reconfigurable 
robots have an advantage over fixed-shape robots in these environments because of their 
special abilities which include versatility, robustness, adaptability, scale extensibility and 
even self-repair. 
2.7 Motion coordination 
Exploring into this domain, path-planning in swarm robotics has attracted a lot of attention 
in the past two decades. The problem of mobile robots path-planning is defined as follows: 
“for a given robot and an environment description, plan a route between two specific 
locations, which must be clear of obstacles and attend all the optimizations criteria” (Langer 
et al., 2007). Studies in path-planning can be divided to local path-planning and global path-
planning. In local path-planning, the planning is based on the information given by sensors 
installed on the robot, which provide details about the unknown environment (Lei et al., 
2006; Lei & Li, 2007). In the global planning case, the environment’s model is precisely 
defined (Kang et al., 2007), and the navigation is performed with the information known in 
priori. 

Swarm Robotics: An Extensive Research Review   
 
267 
SYSTEM  
CLASS  
DOF  
REFERENCE(s)  
CEBOT  
Mobile  
various  
Fukuda et al. (1989)  
Polypod  
Chain  
2  
Yim (1993)  
Metamorphic  
Lattice  
3  
Chirikjian et al. (1996)  
3d Fracta  
Lattice  
6  
Murata et al. (1998)  
Molecule  
Lattice  
4  
Kotay & Rus (1998)  
CONRO  
Chain  
2  
Castano et al. (2002)  
Polybot  
Chain  
1  
Golovinsky et al. (2004)  
Telecube  
Lattice  
6  
Suh et al. (2002)  
Vertical  
Lattice  
2  
Hosokawa et al. (1999)  
Crystal  
Lattice  
4  
Rus & Vona (2000)  
I-Cube  
Lattice  
3  
Unsal & Khosla (2001)  
Pneumatic  
Lattice  
2  
Inou et al. (2002)  
Uni Rover  
Mobile  
2  
Damoto et al. (2001)  
M-TRAN  
Hybrid  
2  
Murata et al. (2002)  
Atron  
Lattice  
1  
Brandt et al. (2007)  
Swarm-bot  
Mobile  
3  
Groß et al. (2006)  
Superbot  
Hybrid  
3  
Shen et al. (2006)  
Catom  
Lattice  
0  
Kirby et al. (2005)  
Molecube  
Chain  
1  
Studer & Lipson (2006)  
YaMoR  
Chain  
1  
Upegui et al. (2005)  
Miche  
Lattice  
0  
Gilpin et al. (2008)  
Proteo  
Hybrid  
0  
Bojinov et al. (2000)  
ACM  
Chain  
various  
Hirose & Mori (2004)  
Fractum  
Hybrid  
0  
Tomita et al. (1999)  
Miniturized  
Lattice  
2  
Yoshida et al. (1999)  
Semi-Cylindrical  
Hybrid  
2  
Murata et al. (2000)  
M-TRAN II  
Hybrid  
2  
Kurokawa et al. (2003)  
RIKEN Vertical  
Lattice  
2  
Hosokawa et al. (1999)  
Table 3. List of self reconfigurable modular systems (Mark et al., 2007; Jantapremjit & 
Austin, 2001; Østergaard et al., 2006) 
The basic path-planning problem deals with static environments (Garro et al., 2007; Li et al., 
2007), in which the workspaces solely containing stationary obstacles of which the geometry 
is known. A natural extension to the basic path planning problem is planning in dynamic 
environments (Van Den Berg et al., 2006; Tian et al., 2007), in which besides stationary 
obstacles, also moving obstacles are present. Planning in such environment is challenging as 
in many cases the motions of the moving obstacles are not known beforehand, so often their 
future trajectories are estimated by extrapolating current speed in order to plan a path. This 
path may become invalid when some obstacle changes its speed, so then a new path should 
be planned. However, there is actually no time for planning; as the world is continuously 
changing, the computation would already be outdated even before it is finished 
(Smierzchalski & Michalewicz, 2007). 
Various algorithms has been introduced to tackle the problems in path-planning for 
example fuzzy-logics (Lei & Li, 2007), particle-swarm optimization (PSO) (Rigatos, 2008), 

 
Advanced Knowledge Application in Practice 
 
268 
distributed gradient (Rigatos, 2008), ant-colony optimization (ACO) (Garro et al., 2007), 
genetic algorithm (GA) (Lei et al., 2006), D*(Van Den Berg et al., 2006) and K-Bug(Langer et 
al., 2007). Most of the algorithms aim to solve the shortest path (Garro et al., 2007) problem 
in path-planning. Nearly all the previous work has been aimed at 2D environment; only 
some papers considered 3D environments such as the work presented by Kitamura et al. 
(1995) and Yamashita et al. (2000). 
Nonholonomic path-planning is also covered in this category. Nonholonomic systems are 
characterized by constraint equations involving the time derivatives of the system 
configuration variables. These equations are non integrable; they typically arise when the 
system has less controls than configuration variables. For instance a car-like robot has two 
controls (linear and angular velocities) while it moves in a 3-dimensional configuration 
space (Laumond et al., 1998). Nonholonomic constraint generally exists in wheeled system. 
Under the nonholonomic constraint, the vehicles and wheeled mobile robots can only run 
along the tangential direction of trajectory within the steering angle limit, and the motion is 
non-slipping and pure rolling (Liu et al., 2007). In another word, the robot can instantly 
move forward and backward, but cannot move sideward. 
Formation or pattern generation is another area in motion coordination that received a lot of 
author’s attention. The formation generation problem is defined as the coordination of a 
group of robots to get into and maintain a formation with a certain shape, such as circle 
(Defago & Konagaya, 2002), line (Arkin & Balch, 1999) or even arbitrary shapes (Sahin et al., 
2002). Current application areas of pattern formation include search and rescue operations, 
landmine removal, remote terrain and space exploration, control of arrays of satellites and 
unmanned aerial vehicles (UAVs). Bahceci et al. (2003) has divided formation generation 
into two groups. The first group includes studies where the coordination is done by a 
centralized (Belta & Kumar, 2002) unit that can oversee the whole group and command the 
individual robots accordingly. The second group contains distributed (Pavone & Frazzoli, 
2007) strategies for achieving the coordination. Chen & Wang (2005) discussed various 
control strategies in formation generation such as behavior-based approach (Arkin & Balch, 
1999), potential field approach (Bruemmer et al., 2002), leader-follower approach (Desai et 
al., 2001) and more. 
2.8 Learning 
At present most learning algorithms can be classified as supervised and unsupervised 
learning. Supervised learning requires the use of an external supervisor. With supervised 
learning the robot knows what the best output is in a certain situation as the supervisor 
provides the corrective information to the learner. Unsupervised learning is a method of 
learning with minor or without any external corrective feedback from the environment 
(Alpaydin, 2004). This method allows for automated design of efficient, robust controllers, 
which saves much design time and effort. Furthermore, it is useful for allowing robots to 
adapt to situations where the task/environment is unknown beforehand or is constantly 
changing (Pugh & Martinoli, 2006). 
There are many paradigms in supervised learning that have been identified in the open 
literatures. Inductive learning is one of the supervised learning paradigms which is a 
method that generalize from observed training examples by identifying features that 
empirically distinguish positive from negative training examples (Mitchell & Mitchell, 1997). 
Decision tree learning (Quinlan, 1986), neural network learning (Pomerleau, 1990) and 
inductive logic programming (Konik & Laird, 2002) are all examples of inductive methods 

Swarm Robotics: An Extensive Research Review   
 
269 
that operate in this fashion. Another well studied paradigm would be explanation-based 
learning (EBL) (Mitchell & Thrun, 1993) where prior knowledge is used to analyze, or 
explain, how each observed training examples satisfies the target concept. This explanation 
is then used to distinguish the relevant features of the training example from the irrelevant, 
so that examples can be generalized based on logical reasoning (Mitchell & Mitchell, 1997). 
EBL studies how domain knowledge about the function being learned can be used to speed 
up learning (Mahadevan, 1996). Other common paradigms that have been applied to robot 
learning are case-based learning (CBL) and memory-based learning (MBL) which were 
reported by Sim et al. (2003). 
Similarly, in unsupervised learning, paradigms such as evolutionary learning and 
reinforcement learning (RL) received massive attention from the researchers recently. 
Genetic algorithms (Ram et al., 1994) and genetic programming (Koza, 1994) are the most 
prominent computational techniques for evolutionary learning. Evolutionary learning starts 
with a population of policies, and combines them to produce better policies till an optimal 
policy is found. The evolutionary learning paradigm is normally set with a good set of 
policies to start which helps to accelerate the learning process. 
Reinforcement leaning (RL) (Fernandez et al., 2005) is defined as learning what to do, how 
to map situations to actions so as to maximize a numerical reward signal. The learner is not 
told which actions to take, as in most forms of machine learning, but instead must discover 
which actions yield the most reward by trying them. Actions may affect not only the 
immediate reward but also the next situation and, through that, all subsequent rewards 
(Sutton & Barto, 1998). Trial-and-error search and delayed reward are two most important 
distinguishing features of RL. 
Among RL algorithms, Q-learning has attracted a great deal of attention in research. Q-
learning (Yang et al., 2007; Ahmadabadi & Asadpour, 2002) is a recently explored RL 
algorithm that stores the expected reinforcement values associated with each state-action 
pair usually in a lookup table. In a survey conducted by Yang & Gu (2004) on multi-agent 
reinforcement learning, they have highlighted that traditional Q-learning is not directly 
applicable in swarm robots application as involvement of multiple robots in the 
environment makes the environment dynamic. Due to that reason, many researchers have 
put efforts to modify the Q-learning framework to suit dynamic environment involving 
multiple robots. Algorithms such as Minimax-Q learning (Littman, 1994), Nash-Q learning 
(Hu&Wellman, 2003), Friend-or-Foe Q-learning (Littman, 2001), rQ-learning (Suh et al., 
1997), Fictitious Play (Claus & Boutilier, 1998), SARSA learning (Sutton & Barto, 1998) and 
Policy Hill Climbing (Ng & Jordan, 2000) were gathered and reported by Yang & Gu (2004). 
As far as robot learning is concern, it is still at the infant stage of research and is one of the 
interesting and difficult machine learning problems. This domain can be further explored by 
exploiting more paradigms and scaling the algorithms to solve more problems related to 
robot learning. 
2.9 Task allocation 
Task allocation means assigning tasks among the robots in swarm in a productive and 
efficient manner. Task allocation must ensure that not only the global mission is achieved, 
but also the tasks are well distributed among the robots. An effective task allocation 
approach considers the available resources, the entities to optimize (time energy, quality 
and etc.), the capabilities of the deployable robots and appropriately allocates the tasks 
accordingly (Baghaei & Agah, 2002). Task refers to a sub-goal that is necessary for achieving 

 
Advanced Knowledge Application in Practice 
 
270 
the overall goal of the system. Tasks can be discrete or continuous and also can vary in a 
number of other ways, including time scale, complexity and specificity (Gerkey & Mataric, 
2004). 
Often in task allocation problems, the comparison between heterogeneous system and 
homogeneous systems are made. Heterogeneous system consists of a team of robots whose 
members have a difference either in the hardware devices or in the software control 
procedures. Homogeneous system consists of a team of robots whose members are exactly 
the same both in the hardware and in the control software (Iocchi et al., 2001). Such 
comparison results can be found in papers presented by Goldberg & Mataric (2002). 
The problem of multi-robot task allocation (MRTA) has been investigated using different 
techniques such as physical modeling (Parker, 2002), distributed planning (Ortiz et al., 
2005), market-based techniques (Dias et al., 2006), auction based techniques (Bertsekas & 
Castanon, 1991) and ALLIANCE (Parker, 2001). One of the first algorithms for market based 
solutions for the MRTA problem was described in the MURDOCH system developed by 
Gerkey & Mataric (2002). The implemented methodologies served as design guidelines to 
allow swarm robot systems to gain more efficiency. 
3. Conclusion 
A state of the art survey of swarm robotic research is presented in this paper. The research 
in the area of swarm in these nine research axes are critically reviewed and reported for the 
benefit of researchers in this field. Swarm robotic systems have a very high potential in 
solving highly complex tasks as they are competent of parallelism, robustness, scalability 
and low cost. It is clear that since the initiation of the field of swarm robotics, significant 
progress has been made on domains such as biological inspiration, communication, control 
approach, mapping and localization, object transportation and manipulation, reconfigurable 
robotics, motion coordination, learning, and task allocation. Most of the research conducted 
was based on the biological inspirations adopted from the behaviors of ants, bees and birds. 
Implicit communication seems to give more robustness in the communication architecture 
of swarm robotics. Distributed control architecture was preferred compared to centralized 
architecture to prevent single point failures. As far as mapping and localization is 
concerned, work is still being carried out to fine tune the problems faced in this domain. In 
object transportation and manipulation, caging is preferred over the available methods as 
the constraints in the domain can be reduced and kept simple. In last two decades, research 
in reconfigurable robotics has taken a good progress. Even so, this domain is still at its infant 
stage. Path-planning and formation generation is one of the main domains that received a 
lot of attention from the authors. A lot of new heuristics and algorithms were introduced to 
solve the problems in this domain. In the learning domain, reinforcement learning (RL) was 
given much interest by the researchers. In task allocation domain, heterogeneous and 
homogeneous systems are widely discussed. This domain has contributed in development 
of various techniques as listed in the paper. 
4. References 
Adolfsson, V. (2001). The State of the Art in Distributed Mobile Robotics. 
Agassounon, A. (2004). Modeling Swarm Robotic Systems: A Case Study in Collaborative 
Distributed Manipulation, The International Journal of Robotics Research 23(4-5). 

Swarm Robotics: An Extensive Research Review   
 
271 
Ahmadabadi, M. & Asadpour, M. (2002). Expertness based cooperative Q-learning, IEEE 
Transactions on Systems, Man, and Cybernetics, Part B: Cybernetics 32(1): 66–76. 
Alpaydin, E. (2004). Introduction to machine learning, The MIT Press. 
Altshuler, Y., Yanovsky, V., Wagner, I. & Bruckstein, A. (2006). Swarm Intelligence-
Searchers, Cleaners and Hunters, Swarm Intelligent Systems pp. 93–132. 
Arkin, R. & Balch, T. (1999). Behavior-based formation control for multi-robot teams. 
Baghaei, K. & Agah, A. (2002). Task allocation methodologies for multi-robot systems, 
Technical report, Citeseer. 
Bahceci, E., Soysal, O. & Sahin, E. (2003). A review: Pattern formation and adaptation in 
multirobot systems, Robotics Institute, Carnegie Mellon University, Pittsburgh, PA, 
Tech. Rep. CMU-RI-TR-03-43. 
Bayindir, L. & Sahin, E. (2007). A Review of Studies in Swarm Robotics, Turkish Journal of 
Electrical Engineering 15(2): 115–147. 
Belta, C. & Kumar, V. (2002). Trajectory design for formations of robots by kinetic energy 
shaping, Proceedings- IEEE International Conference on Robotics and Automation, Vol. 
3, Citeseer, pp. 2593–2598. 
Bertsekas, D. & Castanon, D. (1991). Parallel synchronous and asynchronous 
implementations of the auction algorithm*, Parallel Computing 17(6-7): 707–732. 
Bojinov, H., Casal, A. & Hogg, T. (2000). Emergent structures in modular self-reconfigurable 
robots, IEEE International Conference on Robotics and Automation, Vol. 2, Citeseer, pp. 
1734–1741. 
Brandt, D., Christensen, D. & Lund, H. (2007). ATRON robots: Versatility from self-
reconfigurable modules, International Conference on Mechatronics and Automation, 
2007. ICMA 2007, pp. 26–32. 
Bruemmer, D., Dudenhoeffer, D., Anderson, M. & McKay, M. (2004). Components of Swarm 
Intelligence, Proceedings of the American Nuclear Society 10th International Conference 
on Robotics and Remote Systems for Hazardous Environments. 
Bruemmer, D., Dudenhoeffer, D., McKay, M. & Anderson, M. (2002). A robotic swarm for 
spill finding and perimeter formation. 
Cao, Y., Fukunaga, A. & Kahng, A. (1997). Cooperative Mobile Robotics: Antecedents and 
Directions, Autonomous robots 4(1): 7–27. 
Castano, A., Behar, A. & Will, P. (2002). The Conro modules for reconfigurable robots, 
IEEE/ASME transactions on mechatronics 7(4): 403–409. 
Cazangi, R., Von Zuben, F. & Figueiredo, M. (2005). Autonomous Navigation System 
Applied to Collective Robotics with Ant-inspired Communication, Proceedings of the 
2005 conference on Genetic and evolutionary computation, ACM, p. 128. 
Chen, Y. & Wang, Z. (2005). Formation control: a review and a new consideration, 2005 
IEEE/RSJ International Conference on Intelligent Robots and Systems, 2005.(IROS 2005), pp. 
3181–3186. 
Chirikjian, G., Pamecha, A. & Ebert-Uphoff, I. (1996). Evaluating efficiency of self-
reconfiguration in a class of modular robots, Journal of robotic systems 13(5): 317–338. 
Choset, H. & Nagatani, K. (2001). Topological simultaneous localization and mapping 
(SLAM): towardexact localization without explicit localization, IEEE Transactions on 
Robotics and Automation 17(2): 125–137. 
Christodoulopoulos, C., Kyriakopoulos, C. & Kanatas, A. (2007). A Realistic Approach to 
Source Localization using a Wireless Robotic Network, Proceedings of the 1st 
international conference on Robot communication and coordination, IEEE Press, p. 46. 

 
Advanced Knowledge Application in Practice 
 
272 
Claus, C. & Boutilier, C. (1998). The dynamics of reinforcement learning in cooperative 
multiagent systems, Proceedings of the National Conference on Artificial Intelligence, 
JOHN WILEY & SONS LTD, pp. 746–752. 
Damoto, R., Kawakami, A. & Hirose, S. (2001). Study of super-mechano colony: concept and 
basic experimental set-up, Advanced Robotics 15(4): 391–408. 
D’Angelo, A. & Pagello, E. (2005). Making Collective Behaviours to Work Through Implicit 
Communication, Robotics and Automation, 2005. ICRA 2005. Proceedings of the 2005 
IEEE International Conference on, pp. 81–86. 
De le Torre, M. & Stentz, A. (2001). A Market Approach to Multirobot Coordination, Robotics 
Institute p. 157. 
Defago, X. & Konagaya, A. (2002). Circle formation for oblivious anonymous mobile robots 
with no common sense of orientation, Proceedings of the secondACM international 
workshop on Principles of mobile computing, ACM, p. 104. 
Desai, J., Ostrowski, J. & Kumar, V. (2001). Modeling and control of formations of 
nonholonomic mobile robots, IEEE transactions on Robotics and Automation 17(6): 
905–908. 
Dias, M., Zlot, R., Kalra, N. & Stentz, A. (2006). Market-based multirobot coordination: A 
survey and analysis, Proceedings of the IEEE 94(7). 
Dimarogonas, D. & Kyriakopoulos, K. (2007). Decentralized swarm aggregation with static 
communication links, Proceedings of the 1st international conference on Robot 
communication and coordination, IEEE Press, p. 8. 
Dudek, G., Jenkin, M., Milios, E. & Wilkes, D. (1993). A Taxonomy for Swarm Robots, Intelligent 
Robots and Systems’ 93, IROS’93. Proceedings of the 1993 IEEE/RSJ International 
Conference on, Vol. 1. 
Fabrizi, E. & Saffiotti, A. (2000). Extracting topology-based maps from gridmaps, IEEE 
International Conference on Robotics and Automation, Vol. 3, Citeseer, pp. 2972–2978. 
Fernandez, F., Borrajo, D. & Parker, L. (2005). A reinforcement learning algorithm in 
cooperative multi-robot domains, Journal of Intelligent and Robotic Systems 43(2): 
161–174. 
Fong, T., Nourbakhsh, I. & Dautenhahn, K. (2003). A Survey of Socially Interactive Robots, 
Robotics and autonomous systems 42(3-4): 143–166. 
Fukuda, T., Nakagawa, S., Kawauchi, Y. & Buss, M. (1989). Structure decision method for 
self organizing robots based on cell structure-CEBOT, Proceedings of International 
Conference on Robotics and Automation, Vol. 89. 
Garro, B., Sossa, H. & Vazquez, R. (2007). Evolving ant colony system for optimizing path 
planning in mobile robots, Electronics, Robotics and Automotive Mechanics Conference, 
2007. CERMA 2007, pp. 444–449. 
Gazi, V. & Passino, K. (2002). Stability analysis of swarms in an environment with an 
attractant/ repellent profile, American Control Conference, 2002. Proceedings of the 
2002, Vol. 3. 
Gerkey, B. & Mataric, M. (2002). Pusher-watcher: An approach to fault-tolerant tightly-
coupled robot coordination, Proceedings- IEEE International Conference on Robotics 
and Automation, Vol. 1, Citeseer, pp. 464–469. 
Gerkey, B. & Mataric, M. (2004). A formal analysis and taxonomy of task allocation in 
multirobot systems, The International Journal of Robotics Research 23(9): 939. 
Gilpin, K., Kotay, K., Rus, D. & Vasilescu, I. (2008). Miche: Modular shape formation by self-
disassembly, The International Journal of Robotics Research 27(3-4): 345. 

Swarm Robotics: An Extensive Research Review   
 
273 
Goldberg, D. & Mataric, M. (2002). Design and evaluation of robust behavior-based 
controllers, Robot Teams: From Diversity to Polymorphism pp. 315–344. 
Golovinsky, A., Yim, M., Zhang, Y., Eldershaw, C. & Duff, D. (2004). PolyBot and PolyKinetic 
System: a modular robotic platform for education, 2004 IEEE International Conference 
on Robotics and Automation, 2004. Proceedings. ICRA’04, pp. 1381–1386. 
GroB, R., Mondada, F. & Dorigo, M. (2006). Transport of an object by six pre-attached robots 
interacting via physical links, Proc. of the 2006 IEEE Int. Conf. on Robotics and 
Automation, IEEE Computer Society Press, Los Alamitos, CA, Citeseer, pp. 1317–1323. 
Groß, R., Bonani, M., Mondada, F. & Dorigo, M. (2006). Autonomous self-assembly in 
swarm-bots, IEEE Transactions on Robotics 22(6): 1115–1130. 
Hayes, A., Martinoli, A. & Goodman, R. (2003). Swarm Robotic Odor Localization: Off-line 
Optimization and Validation with Real Robots, Robotica 21(04): 427–441. 
Hirose, S. & Mori, M. (2004). Biologically inspired snake-like robots, IEEE International 
Conference on Robotics and Biomimetics, 2004. ROBIO 2004, pp. 1–7. 
Hosokawa, K., Fujii, T., Kaetsu, H., Asama, H., Kuroda, Y. & Endo, I. (1999). Self-organizing 
collective robots with morphogenesis in a vertical plane, JSME INTERNATIONAL 
JOURNAL SERIES C 42: 195–202. 
Howard, A. (2006). Multi-robot simultaneous localization and mapping using particle filters, 
The International Journal of Robotics Research 25(12): 1243. 
Hu, J. & Wellman, M. (2003). Nash Q-learning for general-sum stochastic games, The Journal 
of Machine Learning Research 4: 1039–1069. 
Inou, N., Kobayashi, H. & Koseki, M. (2002). Development of pneumatic cellular robots 
forming a mechanical structure, International Conference on Control Automation, 
Robotics And Vision (ICARCV),(CD-ROM, Paper ID 1457), pp. 63–68. 
Iocchi, L., Nardi, D. & Salerno, M. (2001). Reactivity and Deliberation: A Survey on 
Multirobot Systems, Balancing Reactivity and Social Deliberation in Multi-Agent 
Systems pp. 9–32. 
Jantapremjit, P. & Austin, D. (2001). Design of a modular self-reconfigurable robot, 
Australian Conf. on Robotics and Automation, Sydney, Australia, Citeseer. 
Jung, D. & Zelinsky, A. (2000). Grounded Symbolic Communication Between 
Heterogeneous Cooperating Robots, Autonomous Robots 8(3): 269–292. 
Kang, J., Kim, S., Chung, M., Myung, H., Park, J. & Bang, S. (2007). Path planning for 
complete and efficient coverage operation of mobile robots, Mechatronics and 
Automation, 2007. ICMA 2007. International Conference on, pp. 2126–2131. 
Kirby, B., Campbell, J., Aksak, B., Pillai, P., Hoburg, J., Mowry, T. & Goldstein, S. (2005). 
Catoms: Moving robots without moving parts, PROCEEDINGS OF THE 
NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, Vol. 20, Menlo Park, 
CA; Cambridge, MA; London; AAAI Press; MIT Press; 1999, p. 1730. 
Kitamura, Y., Tanaka, T., Kishino, F. & Yachida, M. (1995). 3-D path planning in a dynamic 
environment using an octree and anartificial potential field, 1995 IEEE/RSJ 
International Conference on Intelligent Robots and Systems 95.’Human Robot Interaction 
and Cooperative Robots’, Proceedings, Vol. 2. 
Kitano, H., Asada, M., Noda, I. & Matsubara, H. (1998). RoboCup: Robot World Cup, IEEE 
Robotics & Automation Magazine 5(3): 30–36. 
Konik, T. & Laird, J. (2002). Hierarchical Procedural Knowledge Learning Through 
Observation using Inductive Logic Programming, an Extended Abstract. 

 
Advanced Knowledge Application in Practice 
 
274 
Kotay, K. & Rus, D. (1998). Motion synthesis for the self-reconfiguring molecule, IEEE Intl. 
Conf. on Robotics and Automation, pp. 843–851. 
Koza, J. (1994). Genetic programming II: automatic discovery of reusable programs. 
Kuipers, B. & Byun, Y. (1991). A robot exploration and mapping strategy based on a semantic 
hierarchy of spatial representations, Robotics and Autonomous Systems 8(1-2): 47–63. 
Kurokawa, H., Kamimura, A., Yoshida, E., Tomita, K., Kokaji, S. & Murata, S. (2003). M-TRAN 
II: Metamorphosis from a four-legged walker to a caterpillar, Proceedings of the 2003 
IEEE/RSJ International Conference on Intelligent Robots and Systems, pp. 2454–2459. 
Labella, T., Dorigo, M. & Deneubourg, J. (2006). Division of Labor in a Group of Robots 
Inspired by Ants Foraging Behavior, ACM Transactions on Autonomous and Adaptive 
Systems (TAAS) 1(1): 25. 
Langer, R., Coelho, L. & Oliveira, G. (2007). K-Bug, A New Bug Approach for Mobile 
Robot’s Path Planning, IEEE International Conference on Control Applications, 2007. 
CCA 2007, pp. 403–408. 
Laumond, J., Sekhavat, S.&Lamiraux, F. (1998). Guidelines in nonholonomic motion 
planning for mobile robots, Robot motion planning and control pp. 1–53. 
Lei, B. & Li, W. (2007). A Fuzzy Behaviours Fusion Algorithm for Mobile Robot Real-time 
Path Planning in Unknown Environment, IEEE International Conference on 
Integration Technology, 2007. ICIT’07, pp. 173–178. 
Lei, L., Wang, H. & Wu, Q. (2006). Improved genetic algorithms based path planning of 
mobile robot under dynamic unknown environment, Mechatronics and Automation, 
Proceedings of the 2006 IEEE International Conference on, pp. 1728–1732. 
Li, M., Alvarez, A., De Pellegrini, F., Prabhakaran, B. & Chlamtac, I. (2007). ROBOTRAK: a 
centralized real-time monitoring, control, and coordination system for robot 
swarms, Proceedings of the 1st international conference on Robot communication and 
coordination, IEEE Press, p. 37. 
Littman, M. (1994). Markov games as a framework for multi-agent reinforcement learning, 
Proceedings of the eleventh international conference on machine learning, Vol. 157, 
Citeseer, p. 163. 
Littman, M. (2001). Friend-or-foe Q-learning in general-sum games, MACHINE 
LEARNINGINTERNATIONAL WORKSHOP THEN CONFERENCE-, pp. 322–328. 
Liu, H., Sun, Y., Liu, Z., Yang, Q. & Lin, T. (2007). Nonholonomic Path Planning Based on 
Virtual Obstacle in Circuit Map, IEEE International Conference on Integration 
Technology, 2007. ICIT’07, pp. 809–813. 
Mahadevan, S. (1996). Machine learning for robots: A comparison of different paradigms, 
Proceedings of the Workshop on Towards Real Autonomy, IEEE/RSJ Internaltional 
Conference on Intelligent Robots and Systems (IROS96), Citeseer. 
Mark, Y., Shen, W., Salemi, B., Daniela, R., Moll, M., Lipson, H., Klavis, E. & Gregory, S. 
(2007). Modular Self-Reconfigurable Robot Systems-Challenges and Opportunities 
for the Future, IEEE Robotics & Automation Magazine 14(1): 43–52. 
McPartland, M., Nolfi, S. & Abbass, H. (2005). Emergence of Communication in Competitive 
Multi-agent Systems: a Pareto Multi-objective Approach, Proceedings of the 2005 
conference on Genetic and evolutionary computation, ACM, p. 58. 
Meng, Y., Kazeem, O. & Muller, J. (2007). A Hybrid ACO/PSO Control Algorithm for 
Distributed Swarm Robots, IEEE Swarm Intelligence Symposium, 2007. SIS 2007, pp. 
273– 280. 

Swarm Robotics: An Extensive Research Review   
 
275 
Mir, I. & Amavasai, B. (2007). A Fully Decentralized Approach for Incremental Perception, 
Proceedings of the 1st international conference on Robot communication and coordination, 
IEEE Press, p. 10. 
Mitchell, T. & Mitchell, T. (1997). Machine learning, McGraw-hill series in computer science. 
Mitchell, T. & Thrun, S. (1993). Explanation-based neural network learning for robot control, 
Advances in Neural information processing systems pp. 287–287. 
Miyata, N., Ota, J., Aiyama, Y., Sasaki, J. & Arai, T. (1997). Cooperative transport system 
with regrasping car-like mobile robots, Intelligent Robots and Systems, 1997. 
IROS’97., Proceedings of the 1997 IEEE/RSJ International Conference on, Vol. 3. 
Mondada, F., Guignard, A., Bonani, M., Bar, D., Lauria, M. & Floreano, D. (2003). Swarmbot: 
From concept to implementation, Proceedings of the 2003 IEEE/RSJ International 
Conference on Intelligent Robot and Systems (IROS 2003), Citeseer, pp. 1626–1631. 
Murata, S., Kurokawa, H., Yoshida, E., Tomita, K. & Kokaji, S. (1998). A 3-D self-
reconfigurable structure, IEEE International Conference on Robotics and Automation, 
INSTITUTE OF ELECTRICAL ENGINEERS INC (IEEE), pp. 432–439. 
Murata, S., Yoshida, E., Kamimura, A., Kurokawa, H., Tomita, K.&Kokaji, S. (2002). M-
TRAN: Self-reconfigurable modular robotic system, IEEE/ASME transactions on 
mechatronics 7(4): 431–441. 
Murata, S., Yoshida, E., Tomita, K., Kurokawa, H., Kamimura, A. & Kokaji, S. (2000). 
Hardware design of modular robotic system, Proc. of the Intl Conf. on Intelligent 
Robots and Systems, pp. 2210–7. 
Ng, A. & Jordan, M. (2000). PEGASUS: A policy search method for large MDPs and 
POMDPs, Proceedings of the 16th Conference on Uncertainty in Artificial Intelligence, 
Citeseer, pp. 406–415. 
Ortiz, C., Vincent, R. & Morisset, B. (2005). Task inference and distributed task management 
in the Centibots robotic system, Proceedings of the fourth international joint conference 
on Autonomous agents and multiagent systems, ACM, p. 867. 
Østergaard, E., Kassow, K., Beck, R. & Lund, H. (2006). Design of the ATRON lattice-based 
self-reconfigurable robot, Autonomous Robots 21(2): 165–183. 
Panait, L. & Luke, S. (2004). A Pheromone-based Utility Model for Collaborative Foraging, 
Proceedings of the Third International Joint Conference on Autonomous Agents and 
Multiagent Systems, Vol. 1, IEEE Computer Society, p. 43. 
Parker, L. (1993). Designing control laws for cooperative agent teams, 1993 IEEE International 
Conference on Robotics and Automation, 1993. Proceedings., pp. 582–587. 
Parker, L. (2001). Evaluating success in autonomous multi-robot teams: experiences from 
ALLIANCE architecture implementations, Journal of Experimental & Theoretical 
Artificial Intelligence 13(2): 95–98. 
Parker, L. (2002). Distributed algorithms for multi-robot observation of multiple moving 
targets, Autonomous robots 12(3): 231–255. 
Parker, L. (2003). Current Research in Multirobot Systems, Artificial Life and Robotics 7(1): 1–5. 
Pavone, M. & Frazzoli, E. (2007). Decentralized policies for geometric pattern formation and 
path coverage, Journal of Dynamic Systems, Measurement, and Control 129: 633. 
Payton, D., Estkowski, R.&Howard, M. (2003). Compound Behaviors in Pheromone 
Robotics, Robotics and Autonomous Systems 44(3-4): 229–240. 
Pereira, G., Kumar, V. & Campos, M. (2003). Decentralized algorithms for multirobot 
manipulation via caging, Algorithmic Foundations of Robotics V pp. 257–274. 

 
Advanced Knowledge Application in Practice 
 
276 
Pomerleau, D. (1990). Neural network based autonomous navigation, Vision and Navigation. 
The Carnegie Mellon Navlab pp. 83–93. 
Pugh, J. & Martinoli, A. (2006). Multi-robot learning with particle swarm optimization, 
Proceedings of the fifth international joint conference on Autonomous agents and 
multiagent systems, ACM, p. 448. 
Purnamadjaja, A., Iskandar, J. & Russell, R. (2007). Pheromone Communication Simulation 
for Mobile Robots Using Java 3D, 6th IEEE/ACIS International Conference on 
Computer and Information Science, 2007. ICIS 2007, pp. 261–266. 
Purnamadjaja, A. & Russell, R. (2004). Pheromone Communication: Implementation of 
Necrophoric Bee Behaviour in a Robot Swarm, 2004 IEEE Conference on Robotics, 
Automation and Mechatronics, Vol. 2. 
Quinlan, J. (1986). Induction of decision trees, Machine learning 1(1): 81–106. 
Ram, A., Boone, G., Arkin, R. & Pearce, M. (1994). Using genetic algorithms to learn reactive 
control parameters for autonomous robotic navigation, Adaptive Behavior 2(3): 277. 
Ramos, V., Fernandes, C. & Rosa, A. (2005). Social Cognitive Maps, Swarm Collective 
Perception and Distributed Search on Dynamic Landscapes, Brains, Minds & Media–
Journal of New Media in Neural and Cognitive Science, NRW, Germany . 
Rigatos, G. (2008). Distributed gradient and particle swarm optimization for multi-robot 
motion planning, Robotica 26(03): 357–370. 
Rus, D. & Vona, M. (2000). A basis for self-reconfiguring robots using crystal modules, 
IEEE/RSJ Intelligent Robots and Systems 3: 2184–2193. 
Rybski, P., Larson, A., Veeraraghavan, H., LaPoint, M. & Gini, M. (2007). Communication 
Strategies in Multi-Robot Search and Retrieval: Experiences with Mindart, 
Distributed Autonomous Robotic Systems 6 pp. 317–326. 
Sahin, E., Labella, T., Trianni, V., Deneubourg, J., Rasse, P., Floreano, D., Gambardella, L., 
Mondada, F., Nolfi, S. & Dorigo, M. (2002). SWARM-BOT: Pattern formation in a 
swarm of self-assembling mobile robots, Proceedings of the IEEE International 
Conference on Systems, Man and Cybernetics, Hammamet, Tunisia, Citeseer. 
Se, S., Lowe, D. & Little, J. (2002). Mobile robot localization and mapping with uncertainty 
using scale-invariant visual landmarks, The International Journal of Robotics Research 
21(8): 735. 
Seraji, H. (1999). Traversability Index: A new concept for planetary rovers, 1999 IEEE 
International Conference on Robotics and Automation, 1999. Proceedings, Vol. 3. 
Sharkey, A. (2006b). Robots, Insects and Swarm Intelligence, Artificial Intelligence Review 
26(4): 255–268. 
Sharkey, A. & Sharkey, N. (2006a). The Application of Swarm Intelligence to Collective 
Robots, Advances in Applied Artificial Intelligence p. 157. 
Shen,W., Krivokon, M., Chiu, H., Everist, J., Rubenstein, M. & Venkatesh, J. (2006). 
Multimode locomotion via SuperBot reconfigurable robots, Autonomous Robots 
20(2): 165–177. 
Shen, W., Salemi, B. & Will, P. (2002). Hormone-inspired adaptive communication and 
distributed control for conro self-reconfigurable robots, IEEE transactions on Robotics 
and Automation 18(5): 700–712. 
Sim, S., Ong, K. & Seet, G. (2003). A Foundation for Robot Learning, The Fourth International 
Conference on Control and Automation, pp. 10–12. 
Smierzchalski, R. & Michalewicz, Z. (2007). Path planning in dynamic environments, 
Innovations in Robot Mobility and Control pp. 135–153. 

Swarm Robotics: An Extensive Research Review   
 
277 
Song, P. & Kumar, V. (2002). A potential field based approach to multi-robot manipulation, 
Proceedings- IEEE International Conference on Robotics and Automation, Vol. 2, 
Citeseer, pp. 1217–1222. 
Spaan, M., Gordon, G. & Vlassis, N. (2006). Decentralized planning under uncertainty for 
teams of communicating agents, Proceedings of the fifth international joint conference 
on Autonomous agents and multiagent systems, ACM, p. 256. 
Steele Jr, F. & Thomas, G. (2007). Directed stigmergy-based control for multi-robot systems, 
Proceedings of the ACM/IEEE international conference on Human-robot interaction, 
ACM, p. 230. 
Studer, G. & Lipson, H. (2006). Spontaneous emergence of self-replicating structures in 
mole-cube automata, Proc. of the 10th Int. Conf. on the Simulation and Synthesis of 
Living Systems (Artificial Life X), MIT Press, Cambridge, MA, pp. 227–233. 
Suh, I., Kim, J. & Oh, S. (1997). Region-based Q-learning for intelligent robot systems, IEEE 
Int. Symp. on Computational Intelligence in Robotics & Automation, pp. 172–178. 
Suh, J., Homans, S. & Yim, M. (2002). Telecubes: Mechanical design of a module for self-
reconfigurable robotics, IEEE International Conference on Robotics and Automation, 
2002. Proceedings. ICRA’02, Vol. 4. 
Sutton, R. & Barto, A. (1998). Introduction to reinforcement learning. 
Thrun, S. (2001). A probabilistic on-line mapping algorithm for teams of mobile robots, The 
International Journal of Robotics Research 20(5): 335. 
Thrun, S. (2002). Robotic mapping: A survey, Exploring artificial intelligence in the new 
millennium pp. 1–35. 
Thrun, S., Liu, Y., Koller, D., Ng, A., Ghahramani, Z. & Durrant-Whyte, H. (2004). 
Simultaneous localization and mapping with sparse extended information filters, 
The International Journal of Robotics Research 23(7-8): 693. 
Tian, J., Gao, M. & Lu, E. (2007). Dynamic Collision Avoidance Path Planning for Mobile 
Robot Based on Multi-sensor Data Fusion by Support Vector Machine, Mechatronics 
and Automation, 2007. ICMA 2007. International Conference on, pp. 2779–2783. 
Tomita, K., Murata, S., Kurokawa, H., Yoshida, E. & Kokaji, S. (1999). Self-assembly and self-
repair method for a distributed mechanical system, IEEE Transactions on Robotics 
and Automation 15(6): 1035. 
Tomlinson, B. & Blumberg, B. (2002). Using Emotional Memories to Form Synthetic Social 
Relationships, Retrieved April 1: 2005. 
Trianni, V., Labella, T. & Dorigo, M. (2004). Evolution of Direct Communication for a 
Swarmbot Performing Hole Avoidance, Ant Colony, Optimization and Swarm 
Intelligence pp. 130–141. 
Triebel, R., Pfaff, P. & Burgard, W. (2006). Multi-level surface maps for outdoor terrain 
mapping and loop closing, 2006 IEEE/RSJ International Conference on Intelligent 
Robots and Systems, pp. 2276–2282. 
Tuci, E., Groß, R., Trianni, V., Mondada, F., Bonani, M. & Dorigo, M. (2006). Cooperation 
through self-assembly in multi-robot systems, ACM Transactions on Autonomous and 
Adaptive Systems (TAAS) 1(2): 150. 
Unsal, C. & Khosla, P. (2001). A multi-layered planner for self-reconfiguration of a uniform 
group of i-cube modules, Proc. 2001 IEEE/RSJ Int. Conf. on Intelligent Robots and 
Systems, Citeseer.  

 
Advanced Knowledge Application in Practice 
 
278 
Upegui, A., Moeckel, R., Dittrich, E., Ijspeert, A. & Sanchez, E. (2005). An FPGA dynamically 
reconfigurable framework for modular robotics,Workshop Proceedings of the 18th 
International Conference on Architecture of Computing Systems, Citeseer, pp. 83–9. 
Van Den Berg, J., Ferguson, D. & Kuffner, J. (2006). Anytime path planning and replanning 
in dynamic environments, Proceedings of the IEEE International Conference on Robotics 
and Automation (ICRA), Citeseer, pp. 2366–2371. 
Wang, Z., Hirata, Y. & Kosuge, K. (2004). Control a rigid caging formation for cooperative 
object transportation by multiple mobile robots, 2004 IEEE International Conference 
on Robotics and Automation, 2004. Proceedings. ICRA’04, Vol. 2. 
Wang, Z. & Kumar, V. (2002). Object closure and manipulation by multiple cooperating 
mobile robots, IEEE International Conference on Robotics and Automation, 2002. 
Proceedings. ICRA’02, Vol. 1. 
Wang, Z., Nakano, E. & Matsukawa, T. (1996). Realizing cooperative object manipulation 
using multiplebehaviour-based robots, Intelligent Robots and Systems’ 96, IROS 96, 
Proceedings of the 1996 IEEE/RSJ International Conference on, Vol. 1. 
Wang, Z., Takano, Y., Hirata, Y. & Kosuge, K. (2007). Decentralized cooperative object 
transportation by multiple mobile robots with a pushing leader, Distributed 
Autonomous Robotic Systems 6 pp. 453–462. 
White, T. & Pagurek, B. (1998). Towards Multi-swarm Problem Solving in Networks, Multi 
Agent Systems, 1998. Proceedings. International Conference on, pp. 333–340. 
Wolf, D. & Sukhatme, G. (2004). Online simultaneous localization and mapping in dynamic 
environments, 2004 IEEE International Conference on Robotics and Automation, 2004. 
Proceedings. ICRA’04, Vol. 2. 
Wolter, D., Latecki, L., Lakamper, R. & Sun, X. (2004). Shape-based robot mapping, KI 2004: 
Advances in Artificial Intelligence pp. 439–452. 
Yamada, S. & Saito, J. (2001). Adaptive action selection without explicit communication for 
multirobot box-pushing, Systems, Man and Cybernetics, Part C, IEEE Transactions 
on 31(3): 398–404. 
Yamashita, A., Fukuchi, M., Ota, J., Arai, T. & Asama, H. (2000). Motion planning for 
cooperative transportation of a large object by multiple mobile robots in a 3D 
environment, 
IEEE 
INTERNATIONAL 
CONFERENCEONROBOTICS 
AND 
AUTOMATION, Vol. 4, Citeseer, pp. 3144–3151. 
Yang, E. & Gu, D. (2004). Multiagent reinforcement learning for multi-robot systems: A 
survey, Dep. Comput. Sci., Univ. Essex, Colchester, UK, Tech. Rep. CSM-404 . 
Yang, Y., Tian, Y. & Mei, H. (2007). Cooperative Q Learning Based on Blackboard 
Architecture, International Conference on Computational Intelligence and Security 
Workshops, 2007. CISW 2007, pp. 224–227. 
Yim, M. (1993). A reconfigurable modular robot with many modes of locomotion, Proc. of 
Intl. Conf. on Advanced Mechatronics, pp. 283–288. 
Yim, M., Shen, W., Salemi, B., Rus, D., Moll, M., Lipson, H., Klavins, E. & Chirikjian, G. 
(2007). Modular self-reconfigurable robot systems [grand challenges of robotics], 
IEEE Robotics & Automation Magazine 14(1): 43–52. 
Yoshida, E., Kokaji, S., Murata, S., Kurokawa, H. & Tomita, K. (1999). Miniaturized self-
reconfigurable system using shape memory alloy, 1999 IEEE/RSJ International 
Conference on Intelligent Robots and Systems, 1999. IROS’99. Proceedings, Vol. 3. 
 
View publication stats

